<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.wat">
  <volume id="1" ingest-date="2020-12-02">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Asian Translation</booktitle>
      <editor><first>Toshiaki</first><last>Nakazawa</last></editor>
      <editor><first>Hideki</first><last>Nakayama</last></editor>
      <editor><first>Chenchen</first><last>Ding</last></editor>
      <editor><first>Raj</first><last>Dabre</last></editor>
      <editor><first>Anoop</first><last>Kunchukuttan</last></editor>
      <editor><first>Win Pa</first><last>Pa</last></editor>
      <editor><first>Ondřej</first><last>Bojar</last></editor>
      <editor><first>Shantipriya</first><last>Parida</last></editor>
      <editor><first>Isao</first><last>Goto</last></editor>
      <editor><first>Hidaya</first><last>Mino</last></editor>
      <editor><first>Hiroshi</first><last>Manabe</last></editor>
      <editor><first>Katsuhito</first><last>Sudoh</last></editor>
      <editor><first>Sadao</first><last>Kurohashi</last></editor>
      <editor><first>Pushpak</first><last>Bhattacharyya</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Suzhou, China</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="e4d5969c">2020.wat-1.0</url>
      <bibkey>wat-2020-asian</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Meta Ensemble for Japanese-Chinese Neural Machine Translation : Kyoto-U+ECNU Participation to WAT 2020<fixed-case>J</fixed-case>apanese-<fixed-case>C</fixed-case>hinese Neural Machine Translation: <fixed-case>K</fixed-case>yoto-<fixed-case>U</fixed-case>+<fixed-case>ECNU</fixed-case> Participation to <fixed-case>WAT</fixed-case> 2020</title>
      <author><first>Zhuoyuan</first><last>Mao</last></author>
      <author><first>Yibin</first><last>Shen</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <author><first>Cheqing</first><last>Jin</last></author>
      <pages>64–71</pages>
      <abstract>This paper describes the Japanese-Chinese Neural Machine Translation (NMT) system submitted by the joint team of Kyoto University and East China Normal University (Kyoto-U+ECNU) to WAT 2020 (Nakazawa et al.,2020). We participate in APSEC Japanese-Chinese translation task. We revisit several techniques for NMT including various architectures, different data selection and augmentation methods, denoising pre-training, and also some specific tricks for Japanese-Chinese translation. We eventually perform a meta ensemble to combine all of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> into a single <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. BLEU results of this meta ensembled model rank the first both on 2 directions of ASPEC Japanese-Chinese translation.</abstract>
      <url hash="e7252315">2020.wat-1.5</url>
      <bibkey>mao-etal-2020-meta</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimatrix">WikiMatrix</pwcdataset>
    </paper>
    <paper id="8">
      <title>HW-TSC’s Participation in the WAT 2020 Indic Languages Multilingual Task<fixed-case>HW</fixed-case>-<fixed-case>TSC</fixed-case>’s Participation in the <fixed-case>WAT</fixed-case> 2020 Indic Languages Multilingual Task</title>
      <author><first>Zhengzhe</first><last>Yu</last></author>
      <author><first>Zhanglin</first><last>Wu</last></author>
      <author><first>Xiaoyu</first><last>Chen</last></author>
      <author><first>Daimeng</first><last>Wei</last></author>
      <author><first>Hengchao</first><last>Shang</last></author>
      <author><first>Jiaxin</first><last>Guo</last></author>
      <author><first>Zongyao</first><last>Li</last></author>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Liangyou</first><last>Li</last></author>
      <author><first>Lizhi</first><last>Lei</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <author><first>Ying</first><last>Qin</last></author>
      <pages>92–97</pages>
      <abstract>This paper describes our work in the WAT 2020 Indic Multilingual Translation Task. We participated in all 7 language pairs (En-Bn / Hi / Gu / Ml / Mr / Ta / Te) in both directions under the constrained conditionusing only the officially provided data. Using <a href="https://en.wikipedia.org/wiki/Transformer">transformer</a> as a baseline, our Multi-En and En-Multi translation systems achieve the best performances. Detailed data filtering and data domain selection are the keys to performance enhancement in our experiment, with an average improvement of 2.6 BLEU scores for each language pair in the En-Multi system and an average improvement of 4.6 BLEU scores regarding the Multi-En. In addition, we employed language independent adapter to further improve the <a href="https://en.wikipedia.org/wiki/System">system</a> performances. Our submission obtains competitive results in the final evaluation.</abstract>
      <url hash="3d3cf08c">2020.wat-1.8</url>
      <bibkey>yu-etal-2020-hw</bibkey>
    </paper>
    <paper id="11">
      <title>Multimodal Neural Machine Translation for English to Hindi<fixed-case>E</fixed-case>nglish to <fixed-case>H</fixed-case>indi</title>
      <author><first>Sahinur Rahman</first><last>Laskar</last></author>
      <author><first>Abdullah Faiz Ur Rahman</first><last>Khilji</last></author>
      <author><first>Partha</first><last>Pakray</last></author>
      <author><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>109–113</pages>
      <abstract>Machine translation (MT) focuses on the <a href="https://en.wikipedia.org/wiki/Machine_translation">automatic translation</a> of text from one natural language to another natural language. Neural machine translation (NMT) achieves state-of-the-art results in the task of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> because of utilizing advanced deep learning techniques and handles issues like long-term dependency, and context-analysis. Nevertheless, NMT still suffers low translation quality for <a href="https://en.wikipedia.org/wiki/Linguistic_conservatism">low resource languages</a>. To encounter this challenge, the multi-modal concept comes in. The multi-modal concept combines textual and visual features to improve the translation quality of low resource languages. Moreover, the utilization of monolingual data in the pre-training step can improve the performance of the <a href="https://en.wikipedia.org/wiki/System">system</a> for low resource language translations. Workshop on Asian Translation 2020 (WAT2020) organized a translation task for multimodal translation in <a href="https://en.wikipedia.org/wiki/English_language">English</a> to <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>. We have participated in the same in two-track submission, namely text-only and multi-modal translation with team name CNLP-NITS. The evaluated results are declared at the WAT2020 translation task, which reports that our multi-modal NMT system attained higher scores than our text-only NMT on both challenge and evaluation test set. For the challenge test data, our multi-modal neural machine translation system achieves <a href="https://en.wikipedia.org/wiki/Bilingual_Evaluation_Understudy">Bilingual Evaluation Understudy (BLEU) score</a> of 33.57, Rank-based Intuitive Bilingual Evaluation Score (RIBES) 0.754141, Adequacy-Fluency Metrics (AMFM) score 0.787320 and for evaluation test data, BLEU, RIBES, and, AMFM score of 40.51, 0.803208, and 0.820980 for English to Hindi translation respectively.</abstract>
      <url hash="aa3f66e3">2020.wat-1.11</url>
      <bibkey>laskar-etal-2020-multimodal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hindi-visual-genome">Hindi Visual Genome</pwcdataset>
    </paper>
    <paper id="14">
      <title>WT : Wipro AI Submissions to the WAT 2020<fixed-case>WT</fixed-case>: Wipro <fixed-case>AI</fixed-case> Submissions to the <fixed-case>WAT</fixed-case> 2020</title>
      <author><first>Santanu</first><last>Pal</last></author>
      <pages>122–126</pages>
      <abstract>In this paper we present an EnglishHindi and HindiEnglish neural machine translation (NMT) system, submitted to the Translation shared Task organized at WAT 2020. We trained a multilingual NMT system based on transformer architecture. In this paper we show : (i) how effective pre-processing helps to improve performance, (ii) how synthetic data through <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> from available monolingual data can help in overall translation performance, (iii) how language similarity can aid more onto it. Our submissions ranked 1st in both English to Hindi and Hindi to English translation achieving <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> 20.80 and 29.59 respectively.</abstract>
      <url hash="d5c0308a">2020.wat-1.14</url>
      <bibkey>pal-2020-wt</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="17">
      <title>The ADAPT Centre’s Neural MT Systems for the WAT 2020 Document-Level Translation Task<fixed-case>ADAPT</fixed-case> Centre’s Neural <fixed-case>MT</fixed-case> Systems for the <fixed-case>WAT</fixed-case> 2020 Document-Level Translation Task</title>
      <author><first>Wandri</first><last>Jooste</last></author>
      <author><first>Rejwanul</first><last>Haque</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>142–146</pages>
      <abstract>In this paper we describe the ADAPT Centre’s submissions to the WAT 2020 document-level Business Scene Dialogue (BSD) Translation task. We only consider translating from <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a> for this task and we use the MarianNMT toolkit to train Transformer models. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters. This paper outlines the experiments we ran to train our <a href="https://en.wikipedia.org/wiki/System">systems</a> and report the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> achieved through these various experiments.</abstract>
      <url hash="5ac897bd">2020.wat-1.17</url>
      <bibkey>jooste-etal-2020-adapt</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/business-scene-dialogue">Business Scene Dialogue</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jesc">JESC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    <title_ar>أنظمة الترجمة الآلية العصبية التابعة لمركز ADAPT لمهمة ترجمة المستندات على مستوى WAT 2020</title_ar>
      <title_pt>Sistemas de MT Neural do Centro ADAPT para a Tarefa de Tradução em Nível de Documento WAT 2020</title_pt>
      <title_es>Los sistemas de MT neuronal del Centro ADAPT para la tarea de traducción a nivel de documento WAT 2020</title_es>
      <title_fr>Les systèmes de magnétoscopie neuronale du centre ADAPT pour la tâche de traduction au niveau du document WAT 2020</title_fr>
      <title_ja>WAT 2020文書レベルの翻訳タスクのためのADAPTセンターのニューラルMTシステム</title_ja>
      <title_zh>ADAPT 中心神经机器翻译系统于 WAT 2020 文档级译</title_zh>
      <title_ru>Нейронные системы MT центра ADAPT для задачи перевода на уровне документов WAT 2020</title_ru>
      <title_hi>WAT 2020 दस्तावेज़-स्तर अनुवाद कार्य के लिए ADAPT केंद्र के तंत्रिका MT सिस्टम</title_hi>
      <title_ga>Córais Néaracha MT an Ionaid ADAPT don Tasc Aistriúcháin ar Leibhéal Doiciméad WAT 2020</title_ga>
      <title_ka>ADAPT ცენტრის ნეირალური MT სისტემები WAT 2020 დოკუმენტის თავისუფალის სამუშაო</title_ka>
      <title_el>Νευρικά συστήματα ΜΤ του Κέντρου ADAPT για το έργο μετάφρασης σε επίπεδο εγγράφου</title_el>
      <title_hu>Az ADAPT Központ idegrendszerei a WAT 2020 dokumentumszintű fordítási feladathoz</title_hu>
      <title_kk>ADAPT орталығының WAT 2020 құжат деңгейінің аудару тапсырмасы</title_kk>
      <title_lt>ADAPT centro neurologinės MT sistemos, skirtos „WAT 2020“ dokumentų lygio vertimo darbui</title_lt>
      <title_it>Sistemi MT neurali del Centro ADAPT per il compito di traduzione a livello di documento WAT 2020</title_it>
      <title_mk>Неуралните МТ системи на Центарот АДАПТ за задачата WAT 2020 за преведување на документи</title_mk>
      <title_ms>Sistem MT Neural Pusat ADAPT untuk Tugas Terjemahan Aras-Dokumen WAT 2020</title_ms>
      <title_ml>WAT 2020 രേഖകള്‍- നില പരിഭാഷപ്രഭാഷണ ജോലി</title_ml>
      <title_mt>Is-Sistemi MT Newrali taċ-Ċentru ADAPT għall-Kompitu tat-Traduzzjoni fil-Livell tad-Dokumenti tal-WAT 2020</title_mt>
      <title_mn>ADAPT Центр's Neural MT Systems for the WAT 2020 Document-Level Translation Task</title_mn>
      <title_no>ADAPT Center's Neural MT Systems for the WAT 2020 Document-Level Translation Task</title_no>
      <title_pl>Neuronowe systemy MT Centrum ADAPT dla zadania tłumaczenia na poziomie dokumentów WAT 2020</title_pl>
      <title_ro>Sistemele MT neurale ale Centrului ADAPT pentru sarcina de traducere la nivel de document WAT 2020</title_ro>
      <title_sr>ADAPT Centra neurološki MT sistemi za zadatak za prevod dokumenta na nivou WAT 2020</title_sr>
      <title_si>ADAPT මධ්‍යපද්ධතියේ න්‍යූරාල් MT පද්ධති</title_si>
      <title_so>Xarunta ADAPT Neural MT Systems for the WAT 2020 Document-Level Translation Task</title_so>
      <title_ta>WAT 2020 ஆவணம்- மட்டம் மொழிபெயர்ப்பு பணிக்கான ADAPT மையம் நெயுரல் MT அமைப்புகள்</title_ta>
      <title_sv>ADAPT-centrets neurala MT-system för översättningsuppgiften WAT 2020 på dokumentnivå</title_sv>
      <title_ur>ADAPT سینٹر کی نیورال MT سیسٹم WAT 2020 ڈکومکینٹ-سطح ترجمہ ٹاکس کے لئے</title_ur>
      <title_uz>WAT 2020 hujjat- daraja tarjima vazifasi uchun ADAPT markazi neyural MT tizimi</title_uz>
      <title_vi>Hệ thống lắp thần kinh Trung tâm hình s ự cho công tác dịch cấp tài liệu WAT 2020</title_vi>
      <title_bg>Нервните МТ системи на Центъра АДАПТ за задачата за превод на ниво документи</title_bg>
      <title_hr>ADAPT Centra neurološki MT sustavi za zadatak za prevod dokumenta na nivou WAT 2020</title_hr>
      <title_nl>De neuronale MT-systemen van het ADAPT-centrum voor de vertaaltaak WAT 2020 op documentniveau</title_nl>
      <title_da>ADAPT-centrets Neurale MT-systemer til oversættelsesopgaven WAT 2020 på dokumentniveau</title_da>
      <title_de>Neuronale MÜ-Systeme des ADAPT-Zentrums für die Übersetzung auf Dokumentenebene WAT 2020</title_de>
      <title_id>The ADAPT Centre's Neural MT Systems for the WAT 2020 Document-Level Translation Task</title_id>
      <title_fa>سیستم‌های MT عصبی مرکز ADAPT برای ترجمه سطح سند ۲۰۰۲</title_fa>
      <title_ko>센터의 WAT 2020 파일 레벨 번역 임무에 적합한 신경 기계 번역 시스템</title_ko>
      <title_tr>ADAPT Merkezi Nural MT Systemleri for the WAT 2020 Document-Level Translation Task</title_tr>
      <title_sw>Mfumo wa MT wa Neural MT wa Kituo cha ADAPT kwa ajili ya Task la Tafsiri la Document-Level 2020</title_sw>
      <title_af>Die ADAPT sentrum se neurale MT stelsels vir die WAT 2020 dokument-vlak vertaling taak</title_af>
      <title_sq>Sistemet neuronale MT të Qendrës ADAPT për detyrën e përkthimit të nivelit të dokumentit WAT 2020</title_sq>
      <title_am>Document-Level translation Task</title_am>
      <title_hy>ADAPT-ի կենտրոնի նյարդային MT համակարգերը փաստաթղթի վերադարձման աշխատանքի համար</title_hy>
      <title_az>ADAPT Merkezinin nöral MT Sistemləri WAT 2020 Document-Level Translation Taski üçün</title_az>
      <title_bn>WAT ২০২০০ ডকুমেন্ট- স্তরের অনুবাদ কাজের জন্য ADAPT কেন্দ্রের নিউরাল MT সিস্টেম</title_bn>
      <title_bs>Neuralni MT sustavi ADAPT Centra za zadatak za prevod dokumenta na nivou WAT 2020</title_bs>
      <title_ca>Els Sistemes de MT Neural s del Centre ADAPT per a la tasca de traducció a nivell documental WAT 2020</title_ca>
      <title_cs>Neurální MT systémy střediska ADAPT pro úlohu překladu na úrovni dokumentů WAT 2020</title_cs>
      <title_et>ADAPT keskuse neuraalsed MT süsteemid WAT 2020 dokumenditasandi tõlketöö jaoks</title_et>
      <title_fi>ADAPT-keskuksen hermomittausjĂ¤rjestelmĂ¤t WAT 2020 -dokumenttitason kĂ¤Ă¤nnĂ¶styĂ¶hĂ¶n</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Nevralni MT sistemi Centra ADAPT za prevajanje na ravni dokumentov WAT 2020</title_sk>
      <title_he>מערכות MT העצביות של מרכז ADAPT עבור משימה התרגום רמת המסמכים WAT 2020</title_he>
      <title_jv>The WAT center's Neral MT System for the WAT 2020 document-evel translation task</title_jv>
      <title_bo>ADAPT དབྱིབས་དབྱིབས་གནས་སྟངས་་MT Systems for the WAT 2020 Document-Level Translation Task</title_bo>
      <abstract_ar>في هذه الورقة ، نصف ما قدمه مركز ADAPT إلى مهمة ترجمة حوار مشهد الأعمال (BSD) على مستوى الوثائق WAT 2020. نحن ننظر فقط في الترجمة من اليابانية إلى الإنجليزية لهذه المهمة ونستخدم مجموعة أدوات MarianNMT لتدريب نماذج Transformer. من أجل تحسين جودة الترجمة ، استخدمنا كل من البيانات الداخلية والخارجية لتدريب أنظمة الترجمة الآلية (MT) لدينا ، بالإضافة إلى العديد من تقنيات زيادة البيانات لضبط معلمات النموذج. توضح هذه الورقة التجارب التي أجريناها لتدريب أنظمتنا والإبلاغ عن الدقة التي تحققت من خلال هذه التجارب المختلفة.</abstract_ar>
      <abstract_fr>Dans cet article, nous décrivons les soumissions du Centre ADAPT à la tâche de traduction BSD (Business Scene Dialogue) au niveau du document WAT 2020. Nous envisageons uniquement de traduire du japonais vers l'anglais pour cette tâche et nous utilisons la boîte à outils MariannMT pour entraîner les modèles Transformer. Afin d'améliorer la qualité de la traduction, nous avons utilisé des données internes et externes au domaine pour la formation de nos systèmes de traduction automatique (TA), ainsi que diverses techniques d'augmentation des données pour affiner les paramètres du modèle. Cet article décrit les expériences que nous avons menées pour entraîner nos systèmes et rend compte de la précision atteinte grâce à ces différentes expériences.</abstract_fr>
      <abstract_es>En este artículo describimos las presentaciones del Centro ADAPT a la tarea de traducción del Diálogo de la Escena Empresarial (BSD) a nivel de documento WAT 2020. Solo consideramos traducir del japonés al inglés para esta tarea y utilizamos el kit de herramientas MariannMT para entrenar modelos Transformer. Con el fin de mejorar la calidad de la traducción, utilizamos datos dentro y fuera del dominio para entrenar nuestros sistemas de traducción automática (MT), así como varias técnicas de aumento de datos para ajustar los parámetros del modelo. Este documento describe los experimentos que realizamos para entrenar nuestros sistemas e informa de la precisión lograda a través de estos diversos experimentos.</abstract_es>
      <abstract_pt>Neste artigo, descrevemos os envios do Centro ADAPT para a tarefa de tradução do Business Scene Dialogue (BSD) em nível de documento do WAT 2020. Consideramos apenas traduzir do japonês para o inglês para esta tarefa e usamos o kit de ferramentas MarianNMT para treinar os modelos do Transformer. Para melhorar a qualidade da tradução, usamos dados no domínio e fora do domínio para treinar nossos sistemas de tradução automática (MT), bem como várias técnicas de aumento de dados para ajustar os parâmetros do modelo. Este artigo descreve os experimentos que realizamos para treinar nossos sistemas e relata a precisão alcançada por meio desses vários experimentos.</abstract_pt>
      <abstract_ja>この論文では、WAT 2020文書レベルのビジネスシーン対話（ BSD ）翻訳タスクに対するADAPTセンターの提出物について説明します。このタスクでは日本語から英語への翻訳のみを検討しており、MarianNMTツールキットを使用してトランスフォーマーモデルをトレーニングしています。翻訳品質を向上させるために、私たちは、機械翻訳（ MT ）システムのトレーニングのためのドメイン内データとドメイン外データの両方、ならびにモデルパラメータを微調整するためのさまざまなデータ拡張技術を利用しました。本稿では、システムをトレーニングし、これらのさまざまな実験を通じて達成された精度を報告するために実施した実験について概説する。</abstract_ja>
      <abstract_zh>本文中,ADAPT中心向WAT 2020文档级商量对话(BSD)译任提交之材。 惟日语翻译成英语是图,惟MarianNMT工具包是训Transformer。 所以重译质,吾以域内、域外数教吾机器翻译(MT)统,及诸数增强以调参数。 本文概述吾实验,告以实验准确性。</abstract_zh>
      <abstract_ru>В этой статье мы описываем поданные Центром ADAPT заявки на выполнение задачи по переводу на уровне документа WAT 2020 Business Scene Dialogue (BSD). Мы рассматриваем только перевод с японского на английский для этой задачи и используем набор инструментов MarianNMT для обучения моделей трансформаторов. Для улучшения качества перевода мы использовали как внутридоменные, так и внедоменные данные для обучения наших систем машинного перевода (MT), а также различные методы дополнения данных для тонкой настройки параметров модели. В этой статье описываются эксперименты, которые мы проводили для обучения наших систем и сообщения о точности, достигнутой в ходе этих различных экспериментов.</abstract_ru>
      <abstract_hi>इस पेपर में हम WAT 2020 दस्तावेज़-स्तरीय व्यवसाय दृश्य संवाद (BSD) अनुवाद कार्य के लिए ADAPT केंद्र की प्रस्तुतियों का वर्णन करते हैं। हम केवल इस कार्य के लिए जापानी से अंग्रेजी में अनुवाद करने पर विचार करते हैं और हम ट्रांसफॉर्मर मॉडल को प्रशिक्षित करने के लिए MarianNMT टूलकिट का उपयोग करते हैं। अनुवाद की गुणवत्ता में सुधार करने के लिए, हमने अपने मशीन अनुवाद (एमटी) प्रणालियों के प्रशिक्षण के लिए इन-डोमेन और आउट-ऑफ-डोमेन डेटा दोनों का उपयोग किया, साथ ही साथ मॉडल पैरामीटर को ठीक करने के लिए विभिन्न डेटा संवर्धन तकनीकों का भी उपयोग किया। यह पेपर उन प्रयोगों को रेखांकित करता है जिन्हें हमने अपने सिस्टम को प्रशिक्षित करने और इन विभिन्न प्रयोगों के माध्यम से प्राप्त सटीकता की रिपोर्ट करने के लिए चलाया था।</abstract_hi>
      <abstract_ga>Sa pháipéar seo déanaimid cur síos ar aighneachtaí an Ionaid ADAPT don tasc Aistriúcháin Idirphlé Radharc Gnó (BSD) ag leibhéal doiciméad WAT 2020. Ní smaoinímid ach ar aistriú ón tSeapáinis go Béarla don tasc seo agus úsáidimid foireann uirlisí MarianNMT chun samhlacha Trasfhoirmeora a oiliúint. Chun cáilíocht an aistriúcháin a fheabhsú, bhaineamar úsáid as sonraí laistigh agus as an bhfearann araon chun ár gcórais Aistriúcháin Meaisín (MT) a oiliúint, chomh maith le teicnící éagsúla méadaithe sonraí chun na paraiméadair mhúnla a mhionchoigeartú. Imlíníonn an páipéar seo na turgnaimh a ritheamar chun ár gcórais a oiliúint agus tuairisc a thabhairt ar an gcruinneas a baineadh amach trí na turgnaimh éagsúla seo.</abstract_ga>
      <abstract_ka>ამ დოკუმენტში ჩვენ აღწერეთ ADAPT ცენტრის გადაწყვეტილება WAT 2020 დოკუმენტის სამუშაო სენის დიალოგის (BSD) გადაწყვეტილება. ჩვენ მხოლოდ იაპონეთიდან ანგლისურად გადაწყენება ამ რაოდენობისთვის და ჩვენ MarianNMT ხელსაწყოთა ხელსაწყოთა ხელსაწყოთა კიტის გამოყენებთ ტრანფორ ჩვენ მოდილის პარამეტრებისთვის გარგება (MT) სისტემებისთვის, და განსხვავებული მონაცემების აგგენტირების ტექნოგიების გამოყენება. ეს დოკუმენტი გამოსახულებს ექსპერიმენტები, რომელიც ჩვენ გავაგრძნეთ სისტემებს და შეტყობინეთ განსხვავებული ექსპერიმენტებით.</abstract_ka>
      <abstract_el>Στην παρούσα εργασία περιγράφουμε τις υποβολές του Κέντρου ADAPT στο έργο μετάφρασης σε επίπεδο εγγράφου του WAT 2020 για τον Διάλογο Επιχειρηματικής Σκηνής (BSD). Εξετάζουμε μόνο τη μετάφραση από τα ιαπωνικά στα αγγλικά για αυτό το έργο και χρησιμοποιούμε την εργαλειοθήκη για να εκπαιδεύσουμε μοντέλα μετασχηματιστών. Προκειμένου να βελτιωθεί η ποιότητα της μετάφρασης, χρησιμοποιήσαμε τόσο δεδομένα εντός όσο και εκτός τομέα για την εκπαίδευση των συστημάτων μηχανικής μετάφρασης (ΜΤ) μας, καθώς και διάφορες τεχνικές αύξησης δεδομένων για τον συντονισμό των παραμέτρων του μοντέλου. Αυτή η εργασία περιγράφει τα πειράματα που κάναμε για να εκπαιδεύσουμε τα συστήματά μας και να αναφέρουμε την ακρίβεια που επιτυγχάνεται μέσω αυτών των διαφόρων πειραμάτων.</abstract_el>
      <abstract_hu>Ebben a tanulmányban bemutatjuk az ADAPT Központ beadványait a WAT 2020 dokumentumszintű Business Scene Dialogue (BSD) fordítási feladathoz. Ehhez a feladathoz csak japánról angolra fordítunk, és a MarianNMT eszköztárat használjuk a Transformer modellek képzésére. A fordítási minőség javítása érdekében a gépi fordítás (MT) rendszereink képzéséhez domain belüli és domain kívüli adatokat, valamint a modell paramétereinek finomhangolásához különböző adatbővítési technikákat használtunk fel. Ez a tanulmány felvázolja azokat a kísérleteket, amelyeket rendszereink képzésére végeztünk, és jelentést tesz a különböző kísérletek során elért pontosságról.</abstract_hu>
      <abstract_it>In questo articolo descriviamo i contributi del Centro ADAPT al compito di traduzione BSD (Business Scene Dialogue) a livello di documento WAT 2020. Consideriamo solo la traduzione dal giapponese all'inglese per questo compito e utilizziamo il toolkit MarianNMT per formare i modelli Transformer. Al fine di migliorare la qualità della traduzione, abbiamo utilizzato dati sia in-domain che out-domain per la formazione dei nostri sistemi di traduzione automatica (MT), nonché varie tecniche di aumento dei dati per la messa a punto dei parametri del modello. Questo articolo descrive gli esperimenti che abbiamo eseguito per addestrare i nostri sistemi e riporta l'accuratezza raggiunta attraverso questi vari esperimenti.</abstract_it>
      <abstract_mk>Во овој документ ги опишуваме поднесувањата на Центарот АДАПТ на задачата за преведување на бизнис сцена на ниво на документот WAT 2020. Размислуваме само за преведување од јапонски на англиски за оваа задача и ја користиме MarianNMT алатката за обука на трансформските модели. За да го подобриме квалитетот на преводот, искористивме податоци во домен и надвор од домен за обука на нашите системи за машинска превод (MT), како и различни техники за зголемување на податоците за подобрување на параметрите на моделот. Овој весник ги опишува експериментите кои ги спроведовме за да ги обучиме нашите системи и да ја известиме точноста постигната преку овие различни експерименти.</abstract_mk>
      <abstract_lt>Šiame dokumente apibūdiname ADAPT centro pateiktus pranešimus apie „WAT 2020“ dokumentų lygmens verslo scenos dialogo vertimo užduotį. Mes svarstome vertimą iš japonų į anglų tik šiam uždaviniui ir naudojame MarianNMT įrankių rinkinį mokymui Transformer modeliams. Siekdami pagerinti vertimo kokybę, naudojome tiek domeninius, tiek ne domeninius duomenis mokymui mūsų mašin ų vertimo (MT) sistemas, taip pat įvairius duomenų didinimo metodus modelio parametrams patobulinti. Šiame dokumente apibūdinami eksperimentai, kuriuos atlikome, kad apmokytume savo sistemas ir praneštume apie tikslumą, pasiektą atliekant šiuos įvairius eksperimentus.</abstract_lt>
      <abstract_kk>Бұл қағазда ADAPT орталығының WAT 2020 құжат деңгейіндегі бизнес сценары диалогына (BSD) аудару тапсырмасына жіберілгенін таңдаймыз. Біз тек жапондықтан ағылшын тіліне ағылшын тіліне аудару үшін ойлаймыз. Біз MarianNMT құралдарын түрлендіруші үлгілерін оқыту үшін қолданамыз. Аудару сапатын жақсарту үшін, біз машина аудару (MT) жүйелерімізді оқыту үшін доменде және доменде тыс деректерді қолдандық, мәліметтерді дұрыс түзету үшін әртүрлі деректерді жақсарту техникаларын қолдандық Бұл қағаз жүйелерімізді оқыту үшін жұмыс істеген тәжірибелерді түсіндіреді және бұл түрлі тәжірибелер арқылы жеткізген дұрыстығын хабарлап бер</abstract_kk>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങള്‍ എഡിഎപ്പിറ്റ് സെന്‍റിന്‍റെ കീഴടങ്ങള്‍ വ്യാട്ട് 2020 രേഖയിലെ ബിസിനസ് സ്കൈന്‍ ഡയലോഗിന്‍ ജാപ്പാനില്‍ നിന്നും ഇംഗ്ലീഷിലേക്കും പരിഭാഷപ്പെടുത്തുന്നത് മാത്രമാണ് ഞങ്ങള്‍ വിചാരിക്കുന്നത്. ഈ ജോലിക്ക് മ പരിഭാഷക്കുറിച്ച് മെച്ചപ്പെടുത്താന്‍ വേണ്ടി നമ്മുടെ മെഷീന്‍ പരിഭാഷ (എംടി) സിസ്റ്റത്തെ പരിശീലിപ്പിക്കുന്നതിനും മാതൃകയുടെ പരിപാടികള്‍ക്കും വ്യത്യസ ഈ പത്രത്തില്‍ നമ്മുടെ സിസ്റ്റം പരിശീലനം പരീക്ഷിക്കാന്‍ ഞങ്ങള്‍ ഓടിയ പരീക്ഷണങ്ങള്‍ വെളിപ്പെടുത്തുന്നു. ഈ വ്യത്</abstract_ml>
      <abstract_ms>Dalam kertas ini kami menggambarkan penghantaran Pusat ADAPT kepada tugas terjemahan dialog bisnes (BSD) aras dokumen WAT 2020. Kami hanya mempertimbangkan menerjemahkan dari Jepun ke Inggeris untuk tugas ini dan kami menggunakan alat MarianNMT untuk melatih model Transformer. Untuk meningkatkan kualiti terjemahan, kami menggunakan data dalam domain dan luar domain untuk melatih sistem Terjemahan Mesin (MT) kami, serta berbagai teknik peningkatan data untuk menyesuaikan parameter model. Kertas ini menggambarkan eksperimen yang kami jalankan untuk melatih sistem kami dan melaporkan ketepatan yang dicapai melalui eksperimen-eksperimen ini.</abstract_ms>
      <abstract_mt>F'dan id-dokument niddeskrivu s-sottomissjonijiet taċ-Ċentru ADAPT għall-kompitu tat-traduzzjoni tax-xena tan-negozju (BSD) fil-livell tad-dokument WAT 2020. Aħna nikkunsidraw it-traduzzjoni biss mill-Ġappuniż għall-Ingliż għal dan il-kompitu u aħna nużaw is-sett tal-għodod MarianNMT biex inħarrġu mudelli Transformer. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters.  Dan id-dokument jiddeskrivi l-esperimenti li għamilna biex inħarrġu s-sistemi tagħna u nirrappurtaw il-preċiżjoni miksuba permezz ta’ dawn l-esperimenti varji.</abstract_mt>
      <abstract_mn>Энэ цаасан дээр бид ADAPT Центрийн WAT 2020-ийн баримт түвшинд бизнес сценийн диалог (BSD) хөрөнгө оруулах ажлыг тайлбарлаж байна. Бид зөвхөн Япониас Англи хэл руу энэ ажлын тулд орчуулахыг бодож байгаа ба Мариан NMT хэрэгсэл кутийг Трансформерийн загварыг сургахын тулд ашигладаг. Компьютерийн чанарыг сайжруулахын тулд бид машины хөгжүүлэх (MT) систем болон загварын параметрыг сайжруулахын тулд өөр олон өгөгдлийн нэмэлт техник ашигласан. Энэ цаас бидний хийсэн туршилтуудыг бидний системийг суралцаж, эдгээр олон туршилтуудын тухай зөв тодорхойлолтыг тайлбарладаг.</abstract_mn>
      <abstract_no>I denne papiret beskriver vi om ADAPT-senteret sendingar til dokumentnivået «WAT 2020»-omsetjingsprogrammet (BSD). Vi ser berre på å omsetja frå japansk til engelsk for denne oppgåva, og vi bruker MarianNMT- verktøykassa for å trenja transformeringsmodeller. For å forbetra omsetjingskvaliteten, brukte vi både i domene og ut- domenedata for å trenga maskineomsetjingssystemet (MT) våre, og forskjellige dataaugmentasjonsteknologikar for å finne opp modeller. Denne papiret viser eksperimentene vi kjørte for å trene systemet våre og rapportera nøyaktigheten oppnådd gjennom desse ulike eksperimentene.</abstract_no>
      <abstract_ro>În această lucrare descriem înscrierile Centrului ADAPT la sarcina de traducere a scenei de afaceri (BSD) WAT 2020 la nivel de document. Pentru această sarcină luăm în considerare traducerea din japoneză în engleză și folosim setul de instrumente MarianNMT pentru a instrui modele Transformer. Pentru a îmbunătăți calitatea traducerii, am utilizat atât datele din domeniu, cât și cele din afara domeniului pentru instruirea sistemelor noastre de traducere automată (MT), cât și diverse tehnici de mărire a datelor pentru reglarea fină a parametrilor modelului. Această lucrare prezintă experimentele pe care le-am făcut pentru a ne instrui sistemele și a raporta precizia obținută prin aceste experimente diferite.</abstract_ro>
      <abstract_pl>W artykule opisano zgłoszenia Centrum ADAPT do zadania tłumaczeniowego na poziomie dokumentów WAT 2020 Business Scene Dialog (BSD). Do tego zadania rozważamy tylko tłumaczenie z japońskiego na angielski i używamy zestawu narzędzi MarianNMT do treningu modeli Transformera. W celu poprawy jakości tłumaczenia wykorzystaliśmy zarówno dane wewnątrz, jak i poza domeną do szkolenia naszych systemów tłumaczenia maszynowego (MT), jak również różne techniki powiększania danych służące dostosowaniu parametrów modelu. Niniejszy artykuł przedstawia eksperymenty, które przeprowadziliśmy w celu treningu naszych systemów i raportuje dokładność osiągniętą przez te różne eksperymenty.</abstract_pl>
      <abstract_si>මේ පත්තරේ අපි ADAPT මධ්‍යපත්තරයේ WAT 2020වාර්තාව ප්‍රවේශනය සඳහා ව්‍යාපාර ස්කේන් සංවාදය (BSD) වාර්තාව වැඩකට විවේශන අපි ජාපානියෙන් ඉංග්‍රීසියෙන් මේ වැඩේ වෙනුවෙන් වාර්තා කරන්න පුළුවන් හිතන්නේ. අපි මාරියන් NMT උපකරණ කි අපි පරිවාදය විශේෂතාවක් වැඩ කරන්න, අපේ මැෂින් පරිවාදය (MT) පද්ධතියට ප්‍රයෝජනය කරන්න සඳහා විවිධිය දත්ත විශේෂණය ප්‍රයෝජනය සඳහා ප්‍ර මේ පැත්තේ අපි පද්ධතියට දුවන්න ප්‍රයෝජනය කරනවා අපේ පද්ධතියට පරීක්ෂණය කරන්න සහ සාක්ෂිතත්වය පුළුවන්</abstract_si>
      <abstract_sr>U ovom papiru opisujemo podatke ADAPT Centra na zadatak za prevod dokumenta na razini poslovne scene (BSD) na razini WAT 2020. Razmišljamo o prevodu iz Japana na engleski za ovaj zadatak i koristimo MarianNMT alat za obuku modela transformera. Da bismo poboljšali kvalitet prevoda, iskoristili smo podatke iz domena i izvan domena za obuku našeg sustava za prevod mašine (MT), kao i različite tehnike povećanja podataka za finaliziranje modelnih parametara. Ovaj papir ukazuje na eksperimente koje smo trčali da obučimo naše sisteme i prijavimo tačnost postignuta kroz ove različite eksperimente.</abstract_sr>
      <abstract_sv>I denna uppsats beskriver vi ADAPT-centrets bidrag till översättningsuppgiften WAT 2020 Business Scene Dialogue (BSD) på dokumentnivå. Vi överväger endast att översätta från japanska till engelska för denna uppgift och vi använder MarianNMT verktygslåda för att utbilda Transformer modeller. För att förbättra översättningskvaliteten använde vi oss av både in-domain och out-domain data för att utbilda våra maskinöversättningssystem (MT), samt olika datatekniker för att finjustera modellparametrarna. Denna uppsats beskriver de experiment vi genomförde för att träna våra system och redovisar noggrannheten som uppnåtts genom dessa olika experiment.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் நாம் ADAPT மையம் WAT 2020 ஆவணம்- நிலை வணிக வரை உரையாடல் (BSD) மொழிபெயர்ப்பு பணியை விவரிக்கிறோம். இந்த பணிக்கு மொழிபெயர்ப்பு மட்டுமே ஜாப்பானியிலிருந்து ஆங்கிலத்திற்கு மொழிபெயர்ப்பு மாற்றும் மாதிரி மா In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters.  இந்த காகிதம் எங்கள் கணினிகளை பயிற்சி செய்ய நாங்கள் இயங்கிய சோதனைகளை வெளிப்படுத்துகிறது மற்றும் இந்த வித்தியா</abstract_ta>
      <abstract_ur>اس کاغذ میں ہم نے ADAPT سنٹر کے منظورات WAT 2020 دفتر-سطح تجارت سکین دیالوگ (BSD) کی ترجمہ کا کام کرتا ہے. ہم صرف اس کام کے لئے ژاپنی سے انگلیسی کی ترجمہ کرنا سمجھتے ہیں اور ہم مریان NMT تولکیٹ کا استعمال کرتے ہیں ترفنسر موڈل کی ترکین کرنے کے لئے۔ ہم نے اپنے ماشین ترجمہ (MT) سیستموں کی آموزش کے لئے دونوں ڈومین میں اور بیرون ڈومین کے اندر بھی استعمال کیا تھا، اور طرح طرح طرح طرح طرح طرح کے ڈاٹ افزایش تکنیک کے لئے موڈل پارامیٹروں کو نیک ترجمہ کرنے کے لئے استعمال کیا تھا۔ یہ کاغذ ان آزمائش کو واضح کرتا ہے جنہیں ہم نے اپنے سیستموں کی تعلیم کے لئے دوڑا تھا اور ان مختلف آزمائش کے ذریعے حاصل ہونے والی دقیقیت کو راپور کرتا ہے.</abstract_ur>
      <abstract_so>Warqadan waxaan ku qoraynaa warqaddan hoose u soo diritaanka xarunta ADAPT ee WAT 2020 dukument-level Business Scene (BSD). Waxaynu ka fekernaa turjumista Japoniya ilaa Ingiriiska, waxaynu isticmaalnaa qalabka qalabka MarianNMT si aan u tababarinno modelalka turjumista. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters.  Kanu wuxuu qoraa imtixaanada aan u ordnay si aan u tababarinno nidaamka iyo wargeliyo saxda lagu soo gaadhay imtixaankan kala duduwan.</abstract_so>
      <abstract_uz>Bu hujjatda biz ADAPT markaziga WAT 2020 hujjat darajasi biz Business Scen Dialog (BSD) tarjima qilish vazifasini anglatamiz. Biz faqat Yaponchadan Inglizchaga tarjima qilishni tasavvur qilamiz va bu vazifa uchun MarianNMT asboblar kitobini ishlatamiz, Transformer modellarini o'rganish uchun. Tarjima sifatini oshirish uchun, biz hamma domen va domen tarjima qilish (MT) tizimlarimizni tahrirlash uchun foydalanamiz, va modelning parametrlarini yaxshi bogʻlash uchun muloqat maʼlumot qoʻshish techniquesi. Bu gaz biz tizimimizni o'rganish uchun mashhur qilayotgan imtiyozlarni anglatadi va bu turli tizimlar orqali ishlab chiqaradigan tasavvur haqida xabar beradi.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi mô tả những chương trình mà Trung tâm ADAP đã trình bày cho buổi dịch thuật của WAT 2020. Chúng tôi chỉ xem xét việc dịch từ Nhật sang Anh để thực hiện nhiệm vụ này và chúng tôi sử dụng toolbox để huấn luyện các mô hình biến hình. Để nâng cao chất lượng dịch, chúng tôi đã sử dụng cả trong và ngoài miền dữ liệu để huấn luyện hệ thống Dịch Cỗ Máy (MTV) cũng như các kỹ thuật gia tăng dữ liệu khác nhau để sửa chữa các thông số mô hình. Tờ giấy này phác thảo các thí nghiệm chúng tôi đã tiến hành để huấn luyện hệ thống và báo cáo sự chính xác được thực hiện qua các thí nghiệm khác nhau.</abstract_vi>
      <abstract_bg>В настоящата статия описваме постъпленията на Центъра АДАПТ към задачата за превод на диалога на бизнес сцената на ниво документ ВАТ 2020. За тази задача обмисляме превод само от японски на английски език и използваме инструментариума за обучение на модели трансформатори. За да подобрим качеството на превода, ние използвахме както вътрешни, така и извън домейна данни за обучение на нашите системи за машинен превод (МТ), както и различни техники за увеличаване на данните за фино настройване на параметрите на модела. Тази статия очертава експериментите, които проведохме, за да обучим нашите системи и да докладваме точността, постигната чрез тези различни експерименти.</abstract_bg>
      <abstract_hr>U ovom papiru opisujemo podatke Centra ADAPT-a na zadatak za prevod razine poslovne scene na razini dokumenta WAT 2020. Razmišljamo o prevodu iz Japana na engleski samo za ovaj zadatak i koristimo MarianNMT alatkit za obuku modela transformera. Da bismo poboljšali kvalitet prevoda, iskoristili smo podatke iz domena i izvan domena za obuku našeg sustava prevoda strojeva (MT), kao i različite tehnike povećanja podataka za finaliziranje modelnih parametara. Ovaj papir pokazuje eksperimente koje smo trčali da obučimo naše sustave i prijavimo preciznost postignuta kroz te različite eksperimente.</abstract_hr>
      <abstract_nl>In dit artikel beschrijven we de inzendingen van het ADAPT Centre voor de vertaaltaak WAT 2020 Business Scene Dialogue (BSD) op documentniveau. We overwegen alleen vertalen van Japans naar Engels voor deze taak en we gebruiken de MarianNMT toolkit om Transformer modellen te trainen. Om de vertaalkwaliteit te verbeteren, hebben we zowel in-domain als out-of-domain data gebruikt voor het trainen van onze Machine Translation (MT) systemen, evenals verschillende data augmentation technieken voor het finetunen van de modelparameters. Deze paper schetst de experimenten die we hebben uitgevoerd om onze systemen te trainen en rapporteert de nauwkeurigheid die we hebben bereikt door deze verschillende experimenten.</abstract_nl>
      <abstract_da>I denne artikel beskriver vi ADAPT-centrets indlæg til WAT 2020-dokumentoversættelsesopgaven Business Scene Dialogue (BSD). Vi overvejer kun at oversætte fra japansk til engelsk til denne opgave, og vi bruger MarianNMT værktøjssættet til at træne Transformer modeller. For at forbedre oversættelseskvaliteten anvendte vi både in-domain og out-of-domain data til træning af vores maskinoversættelsessystemer (MT) samt forskellige datateknikker til finjustering af modelparametrene. Denne artikel beskriver de eksperimenter, vi kørte for at træne vores systemer og rapportere nøjagtigheden opnået gennem disse forskellige eksperimenter.</abstract_da>
      <abstract_de>In diesem Beitrag beschreiben wir die Einreichungen des ADAPT Zentrums für die Übersetzungsaufgabe WAT 2020 für Business Scene Dialogue (BSD) auf Dokumentenebene. Für diese Aufgabe erwägen wir nur Übersetzungen aus dem Japanischen ins Englische und verwenden das MarianNMT Toolkit, um Transformer Modelle zu trainieren. Um die Übersetzungsqualität zu verbessern, nutzten wir sowohl In-Domain- als auch Out-of-Domain-Daten für die Schulung unserer Machine Translation (MT)-Systeme sowie verschiedene Datenaufbautechniken zur Feinabstimmung der Modellparameter. Dieses Papier skizziert die Experimente, die wir durchgeführt haben, um unsere Systeme zu trainieren, und berichtet über die Genauigkeit, die durch diese verschiedenen Experimente erreicht wurde.</abstract_de>
      <abstract_ko>본고에서 우리는 ADAPT센터가 WAT 2020 문서급 업무 장면 대화(BSD) 번역 임무에 제출한 파일을 묘사했다.우리는 일본어를 영어로 번역해서 이 임무를 완성하는 것만 고려하고, 우리는 Marian NMT 도구 패키지를 사용하여 변압기 모형을 훈련한다.번역의 질을 높이기 위해 우리는 역내와 역외 데이터를 이용하여 우리의 기계번역(MT) 시스템을 훈련하고 각종 데이터 강화 기술을 이용하여 모델 파라미터를 미세하게 조정한다.본고는 우리가 우리의 시스템을 훈련시키기 위한 실험을 개괄하고 이러한 서로 다른 실험을 통해 얻은 정밀도를 보고한다.</abstract_ko>
      <abstract_fa>در این کاغذ ما تحویل مرکز ADAPT را به وظیفه ترجمه صحیح تجارت سند ۲۰۰۲ توصیف می‌کنیم. ما فقط برای این کار ترجمه کردن از ژاپنی به انگلیسی فکر می کنیم و از کیت ابزار MarianNMT برای آموزش مدل ترجمه کننده استفاده می کنیم. تا کیفیت ترجمه را بهتر کنیم، ما از داده های خارج از دومین و خارج از دومین برای آموزش سیستم های ترجمه ماشین (MT) ما استفاده کردیم، همچنین تکنیک افزایش داده های مختلف برای تنظیم پارامترهای مدل استفاده کردیم. این کاغذ آزمایش‌هایی را که ما فرار کرده‌ایم برای آموزش سیستم‌هایمان و گزارش داده‌ایم دقیقاتی که در این آزمایش‌های مختلف به دست آورده‌ایم.</abstract_fa>
      <abstract_id>In this paper we describe the ADAPT Centre's submissions to the WAT 2020 document-level Business Scene Dialogue (BSD) Translation task.  Kami hanya mempertimbangkan terjemahan dari Jepang ke Inggris untuk tugas ini dan kami menggunakan alat MarianNMT untuk melatih model Transformer. Untuk meningkatkan kualitas terjemahan, kami menggunakan data di domain dan di luar domain untuk melatih sistem Translation Mesin (MT) kami, serta berbagai teknik peningkatan data untuk memperbaiki parameter model. Kertas ini menggambarkan eksperimen yang kami jalankan untuk melatih sistem kami dan melaporkan akurasi yang dicapai melalui eksperimen-eksperimen berbeda ini.</abstract_id>
      <abstract_sw>Katika karatasi hii tunaelezea ujumbe wa kituo cha ADAPT kwa juhudi la Tafsiri ya kiwango cha dokumentari cha WAT 2020 (BSD). Tunafahamu kutafsiri tu kutoka Kijapani hadi Kiingereza kwa kazi hii na tunatumia vifaa vya MarianNMT ili kufundisha mifano ya Kifaransa. Ili kuongeza kiwango cha kutafsiri, tulitumia takwimu za ndani na nje ya ndani kwa ajili ya kufundisha mfumo wetu wa Tafsiri ya Mashine (MT), pamoja na mbinu mbalimbali za kuongeza taarifa kwa ajili ya kuboresha vipimo vya mifano. Gazeti hili linaelezea majaribio tuliyoyakimbia kufundisha mfumo wetu na kuripoti ukweli uliotekelezwa kupitia majaribio haya mbalimbali.</abstract_sw>
      <abstract_sq>Në këtë letër ne përshkruajmë paraqitjet e Qendrës ADAPT në detyrën e përkthimit të skenës s ë biznesit (BSD) në nivelin e dokumentit WAT 2020. Ne konsiderojmë vetëm përkthimin nga japonezë në anglisht për këtë detyrë dhe ne përdorim paketën e mjeteve MarianNMT për të trajnuar modelet Transformer. Me qëllim që të përmirësojmë cilësinë e përkthimit, ne përdorëm si të dhënat në domeni, ashtu edhe jashtë domeni për trajnimin e sistemeve tona të përkthimit të makinave (MT), si dhe teknikat e ndryshme të rritjes së të dhënave për rregullimin e parametrave të modelit. Kjo letër përshkruan eksperimentet që kemi bërë për të trajnuar sistemet tona dhe për të raportuar saktësinë e arritur nëpërmjet këtyre eksperimenteve të ndryshme.</abstract_sq>
      <abstract_am>በዚህ ገጽ የADAPT ማዕከል ለWAT 2020 ሰነድ-ደረጃ የንግድ ነጥብ ጥያቄ (BSD) ትርጉም አድራሻ ስራ እናሳውቃለን፡፡ ከጃፓንኛ ወደ ኢንግሊዝኛ መተርጓሜን ብቻ እናስባለን ለዚህ ስራ ማርያንNMT ቱልባር እናስተማርናለን፡፡ ለመትርጉም ጥሩ ለማሻሻል፣ በዶሜን እና ከዶሜን ዳታዎችን ለመግለጽ የመስኮታችንን ትርጉም (MT) ስርዓት እና በሞዴል parameters ለመማጠቀም የተለያዩ የዳታ ማጨመር ጥቅምቶችን ለመጠቀም ጠቅመን ነበር፡፡ ይህ ፕሮግራም ሲስተምሮቻችንን ለማስተማር የሮጥነውን ፈተናዎች እና እነዚህን በተለያዩ ፈተናዎች የደረሰችውን እርግጠኛ ውሰጥ ያሳያል፡፡</abstract_am>
      <abstract_az>Bu kağızda ADAPT Merkezinin WAT 2020 s əviyyəsi Business Scene Dialogu (BSD) tərcümə işlərinə təsdiqlənməsini təsdiqləyirik. Biz yalnız Japonca dilindən İngilizce dilində bu işin üçün tercümə etməyi düşünürük və MarianNMT alet kitabını Transformer modellerini təhsil etmək üçün istifadə edirik. Tərcümə keyfiyyətini yaxşılaşdırmaq üçün, maşın Çeviri (MT) sistemlərimizi təhsil etmək üçün, modeli parametrləri düzgün təhsil etmək üçün də müxtəlif məlumat yükselmə tekniklərini istifadə etdik. Bu kağıt sistemlərimizi təhsil etmək üçün çalışdığımız və bu müxtəlif təcrübələr vasitəsilə başa çatdığımız doğruluğu bildirir.</abstract_az>
      <abstract_hy>Այս թղթի մեջ մենք նկարագրում ենք ADAPT-ի կենտրոնի ներկայացումները ԱՎԱT 2020-ի փաստաթղթի մակարդակի բիզնես Scene-ի (ԲՍԴ) թարգմանման խնդիրը: Մենք մտածում ենք պարզապես ճապոներեց անգլերեն թարգմանել այս խնդրի համար և օգտագործում ենք ՄարիանՆՄԹ գործիքների շարքը Թանֆորմերի մոդելների ուսուցանման համար: Թարգմանության որակը բարելավելու համար մենք օգտագործեցինք արտաքին և արտաքին տվյալներ մեր մեքենայի թարգմանման (MT) համակարգերի ուսումնասիրելու համար, ինչպես նաև տարբեր տվյալների աճի մեթոդներ մոդելի պարամետրերի բարելավման համար: Այս հոդվածը ներկայացնում է այն փորձերը, որոնք մենք կատարեցինք մեր համակարգերի ուսուցման համար և տեղեկացնել ճշգրիտությունը, որը ստացվել է այս տարբեր փորձերի միջոցով:</abstract_hy>
      <abstract_bn>এই কাগজটিতে আমরা এডএপিট কেন্দ্রের তথ্য ব্যবসা ব্যবসা স্কেন ডায়ালগ (বিএসডি) অনুবাদের কাজের বিষয়টি বর্ণনা করি। আমরা শুধুমাত্র জাপানী থেকে ইংরেজী থেকে অনুবাদ বিবেচনা করি এই কাজের জন্য এবং আমরা মারিয়ানএমটি টুলিকিট ট ট্রান্সফ্র অনুবাদের মান উন্নত করার জন্য আমরা ডোমেইন এবং ডোমেইনের বাইরে তথ্য ব্যবহার করেছি আমাদের মেশিন অনুবাদ (এমটি) সিস্টেমের প্রশিক্ষণের জন্য, আর মডেলের প্যারামিটার ভালোভ এই পত্রিকাটি আমাদের সিস্টেম প্রশিক্ষণের জন্য দৌড়ানোর পরীক্ষাগুলো তুলে ধরেছে এবং এই বিভিন্ন পরীক্ষার মাধ্যমে য</abstract_bn>
      <abstract_bs>U ovom papiru opisujemo podatke Centra ADAPT-a na zadatak za prevod razine poslovne scene na nivou WAT 2020. Razmišljamo o prevodu iz Japana na engleski samo za ovaj zadatak i koristimo MarianNMT alat za obuku modela transformera. Da bismo poboljšali kvalitet prevoda, iskoristili smo podatke u domenu i izvan domena za obuku našeg sustava za prevod mašine (MT), kao i različite tehnike povećanja podataka za finaliziranje modelnih parametara. Ovaj papir pokazuje eksperimente koje smo trčali da obučimo naše sisteme i prijavimo preciznost postignuta kroz ove različite eksperimente.</abstract_bs>
      <abstract_tr>Bu kagyzda ADAPT Merkeziniň WAT 2020-nji sened derejesi Business Scene Dialoga (BSD) terjime göresini tassyýarys. Biz diňe Japonça iňlisçe bu işiň üçin terjime edip pikir edýäris we MarianNMT araç çykyşlaryny Transformer nusgalaryny öwretmek üçin ulanýarys. Tercüme kalitesini geliştirmek için, makine tercüme (MT) sistemlerimize ve modelleri düzeltmek için her iki domenin ve dış domenin verilerini kullandık. Bu kagyz sistemamyzy öwretmek üçin çykan deneylerimizi we bu dürli deneylerimiz bilen ýetişimizi bildirýär.</abstract_tr>
      <abstract_af>In hierdie papier beskryf ons die ADAPT Sentrum se onderskrywings na die WAT 2020 dokument- vlak Besigheidsgene Dialoog (BSD) Vertaling taak. Ons beskou slegs om te vertaling van Japaanse na Engels vir hierdie taak en ons gebruik die MarianNMT nutsbalk om transformer modele te trein. In order to improve the translation quality, we made use of both in-domain and out-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters. Hierdie papier uitduidelik die eksperimente wat ons hardloop om ons stelsels te oefen en rapporteer die presisie wat deur hierdie verskillende eksperimente bereik is.</abstract_af>
      <abstract_cs>V tomto článku popisujeme příspěvky centra ADAPT k překladatelskému úkolu na úrovni dokumentů WAT 2020 Business Scene Dialog (BSD). Pro tento úkol uvažujeme pouze o překladu z japonštiny do angličtiny a k tréninku modelů Transformeru používáme nástrojovou sadu MarianNMT. Abychom zlepšili kvalitu překladu, využili jsme pro školení našich systémů strojového překladu (MT), jakož i různé techniky rozšíření dat pro jemné ladění parametrů modelu. Tento článek nastíní experimenty, které jsme provedli k tréninku našich systémů a nahlásil přesnost dosažené těmito různými experimenty.</abstract_cs>
      <abstract_ca>En aquest paper descrivim les presentacions del Centre ADAPT a la tasca de traducció del Diàleg d'Escena de Negocis (BSD) a nivell documental WAT 2020. Només considerem traduir de japonès a anglès per aquesta tasca i utilitzem el conjunt d'eines MarianNMT per formar models Transformer. In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters.  Aquest paper esboça els experiments que vam fer per entrenar els nostres sistemes i informar de la precisió aconseguida a través d'aquests diversos experiments.</abstract_ca>
      <abstract_et>Käesolevas dokumendis kirjeldame ADAPT keskuse ettepanekuid WAT 2020 dokumenditasandil Business Scene Dialogue (BSD) tõlketööle. Selle ülesande jaoks kaalume tõlkimist ainult jaapani keelest inglise keelde ja kasutame MarianNMT tööriistakomplekti Transformeri mudelite koolitamiseks. Tõlkekvaliteedi parandamiseks kasutasime masintõlke (MT) süsteemide koolitamiseks nii domeenisiseseid kui ka domeeniväliseid andmeid, samuti erinevaid andmete suurendamise meetodeid mudeli parameetrite täpsustamiseks. Käesolevas dokumendis kirjeldatakse katseid, mida me tegime oma süsteemide koolitamiseks ja kirjeldatakse nende erinevate katsete läbi saavutatud täpsust.</abstract_et>
      <abstract_fi>T채ss채 artikkelissa kuvataan ADAPT-keskuksen ehdotuksia WAT 2020 -dokumenttitason Business Scene Dialogue (BSD) -k채채nn철steht채v채채n. Harkitsemme t채ss채 teht채v채ss채 vain k채채nt채mist채 japanista englanniksi ja k채yt채mme MarianNMT-ty철kalupakkia Transformer-mallien kouluttamiseen. K채채nt채misen laadun parantamiseksi k채ytimme konek채채nn철sj채rjestelmiemme (MT) koulutuksessa sek채 verkkotunnuksen sis채isi채 ett채 ulkopuolisia tietoja sek채 erilaisia datan lis채ystekniikoita mallin parametrien hienos채채t철철n. T채ss채 artikkelissa kuvataan kokeita, joita teimme j채rjestelmiemme kouluttamiseksi ja raportoidaan n채iden eri kokeiden tarkkuudesta.</abstract_fi>
      <abstract_jv>Nang pemilih iki, kita sambarang nggawe tarjamahan kanggo ngerasahan barang DEATT center kanggo kelas WAT 2020, gambar Entrepresan scene Dialog (GSD) Terjamahan. Awak dhéwé isih ngubah itjamahan kanggo ingkang Japang kanggo nggambar barang iki bakal ning gambar kelas marianNMT kanggo ngelakon model Transformer. In order to refresh the translation quality, we make use of all in-domain and out-of-domain data for Learning the Masculine translation (MT) System, as long as Variable data aging Methods for Fin-tuning the model parameters. Awak dhéwé éntuk nglebok perbudhakan winih sing mlayu kanggo luwih sistem awak dhéwé lan batawak dhéwé nggawe barang nggawe barang iki dadi sing apik perbudhakan.</abstract_jv>
      <abstract_sk>V prispevku opisujemo prispevke centra ADAPT k prevajalski nalogi WAT 2020 na ravni dokumentov Business Scene Dialogue (BSD). Za to nalogo razmišljamo samo o prevajanju iz japonščine v angleščino in za usposabljanje modelov transformatorjev uporabljamo orodje MarianNMT. Za izboljšanje kakovosti prevajanja smo za usposabljanje naših sistemov strojnega prevajanja (MT) uporabili domenske in zunajdomenske podatke ter različne tehnike povečanja podatkov za natančno nastavitev parametrov modela. V tem članku so opisani poskusi, ki smo jih izvedli za usposabljanje naših sistemov in poročali o natančnosti, doseženi s temi različnimi poskusi.</abstract_sk>
      <abstract_ha>A cikin wannan takardan, Munã bayyana masu saka na ADPAT Centre zuwa the WAT 2020 documentation-level s Businesce San Ana Fassar Dialog (BSD). Kana yin fassarar tarjima kawai daga Jabaniya zuwa Ingiriya zuwa wannan aikin, kuma munã amfani da zanen aikin MarianNMT dõmin ka yi kõri misãlai na Transformer. Dõmin ya kyautata sifar fassarar, mun yi amfani da duk data cikin-Domen da ba-komai ba dõmin ya yi amfani da tsarin tarjifanmu na MT, da kuma zanen ƙari ko-zane ga tsarin misalin ayuka. Gagon wannan na ƙarfafa da jarraboyin da muka yi tafiya dõmin ya sanar da masu tsari na'uranmu kuma ya faɗi taƙaitaccen da aka kamfata cikin wannan jarrabai dabam.</abstract_ha>
      <abstract_he>בעיתון הזה אנו מתארים את ההעברות של מרכז ADAPT למשימת התרגום במסמכים של WAT 2020. We only consider translating from Japanese to English for this task and we use the MarianNMT toolkit to train Transformer models.  כדי לשפר את איכות התרגום, השתמשנו גם בנתונים בתחום וגם מחוץ לתחום לאימון מערכות התרגום המכונית שלנו (MT), כמו גם טכניקות מגדלות נתונים שונות לתאים את הפרמטרים של המודל. הנייר הזה מציין את הניסויים שרצנו כדי לאמן את המערכות שלנו ולדווח על מדויקת השיגה דרך הניסויים השונים האלה.</abstract_he>
      <abstract_bo>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་གི་ADAPT དབྱིབས་ཡུལ་གྱི་གནད་སྡུད་ནང་དུ་WAT 2020་ཡིག་ཆའི་སྐྱེལ་གྱི་དཔེ་རིགས་སྒྲོམ་ཚོགས་དབྱེ་རིགས ( འུ་ཅག་གིས་ལས་ཉེ་ཧོང་གི་ཡིག་ཆ་ལ་དབྱིན་ཡིག་ཆ་འདི་བསམ་བློ་གཏོང In order to improve the translation quality, we made use of both in-domain and out-of-domain data for training our Machine Translation (MT) systems, as well as various data augmentation techniques for fine-tuning the model parameters. ཤོག་བྱང་འདིས་ང་ཚོའི་མ་ལག་ལུགས་སྒོ་འབྱེད་དུ་སྟོན་པའི་བརྟག་ཞིབ་བྱེད་བཞིན་པའི་དུས་ཚོད་བདེན་སྟངས་རྟོགས་</abstract_bo>
      </paper>
    <paper id="19">
      <title>Improving NMT via Filtered Back Translation<fixed-case>NMT</fixed-case> via Filtered Back Translation</title>
      <author><first>Nikhil</first><last>Jaiswal</last></author>
      <author><first>Mayur</first><last>Patidar</last></author>
      <author><first>Surabhi</first><last>Kumari</last></author>
      <author><first>Manasi</first><last>Patwardhan</last></author>
      <author><first>Shirish</first><last>Karande</last></author>
      <author><first>Puneet</first><last>Agarwal</last></author>
      <author><first>Lovekesh</first><last>Vig</last></author>
      <pages>154–159</pages>
      <abstract>Document-Level Machine Translation (MT) has become an active research area among the NLP community in recent years. Unlike sentence-level MT, which translates the sentences independently, document-level MT aims to utilize <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> while translating a given source sentence. This paper demonstrates our submission (Team ID-DEEPNLP) to the Document-Level Translation task organized by WAT 2020. This task focuses on translating texts from a business dialog corpus while optionally utilizing the context present in the dialog. In our proposed approach, we utilize publicly available <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a> from different domains to train an open domain base NMT model. We then use monolingual target data to create filtered pseudo parallel data and employ <a href="https://en.wikipedia.org/wiki/Back-translation">Back-Translation</a> to fine-tune the base model. This is further followed by <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> on the domain-specific corpus. We also ensemble various <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> to improvise the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> achieve a <a href="https://en.wikipedia.org/wiki/BLEU">BLEU score</a> of 26.59 and 22.83 in an <a href="https://en.wikipedia.org/wiki/BLEU">unconstrained setting</a> and 15.10 and 10.91 in the <a href="https://en.wikipedia.org/wiki/BLEU">constrained settings</a> for <a href="https://en.wikipedia.org/wiki/BLEU">En-Ja &amp; Ja-En direction</a>, respectively.</abstract>
      <url hash="29250156">2020.wat-1.19</url>
      <bibkey>jaiswal-etal-2020-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/jesc">JESC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mtnt">MTNT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimatrix">WikiMatrix</pwcdataset>
    </paper>
    <paper id="20">
      <title>A Parallel Evaluation Data Set of <a href="https://en.wikipedia.org/wiki/Software_documentation">Software Documentation</a> with Document Structure Annotation</title>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Miriam</first><last>Exel</last></author>
      <pages>160–169</pages>
      <abstract>This paper accompanies the software documentation data set for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, a parallel evaluation data set of data originating from the SAP Help Portal, that we released to the machine translation community for research purposes. It offers the possibility to tune and evaluate <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation systems</a> in the domain of corporate software documentation and contributes to the availability of a wider range of evaluation scenarios. The data set comprises of the language pairs English to Hindi, <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a>, <a href="https://en.wikipedia.org/wiki/Malay_language">Malay</a> and <a href="https://en.wikipedia.org/wiki/Thai_language">Thai</a>, and thus also increases the test coverage for the many low-resource language pairs. Unlike most evaluation data sets that consist of plain parallel text, the segments in this <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> come with additional metadata that describes structural information of the document context. We provide insights into the origin and creation, the particularities and characteristics of the <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> as well as <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> results.</abstract>
      <url hash="9f2ed0b7">2020.wat-1.20</url>
      <bibkey>buschbeck-exel-2020-parallel</bibkey>
      <pwccode url="https://github.com/SAP/software-documentation-data-set-for-machine-translation" additional="false">SAP/software-documentation-data-set-for-machine-translation</pwccode>
    </paper>
    </volume>
</collection>