<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.eamt">
  <volume id="1" ingest-date="2020-08-11">
    <meta>
      <booktitle>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</booktitle>
      <editor><first>André</first><last>Martins</last></editor>
      <editor><first>Helena</first><last>Moniz</last></editor>
      <editor><first>Sara</first><last>Fumega</last></editor>
      <editor><first>Bruno</first><last>Martins</last></editor>
      <editor><first>Fernando</first><last>Batista</last></editor>
      <editor><first>Luisa</first><last>Coheur</last></editor>
      <editor><first>Carla</first><last>Parra</last></editor>
      <editor><first>Isabel</first><last>Trancoso</last></editor>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <editor><first>Arianna</first><last>Bisazza</last></editor>
      <editor><first>Joss</first><last>Moorkens</last></editor>
      <editor><first>Ana</first><last>Guerberof</last></editor>
      <editor><first>Mary</first><last>Nurminen</last></editor>
      <editor><first>Lena</first><last>Marg</last></editor>
      <editor><first>Mikel L.</first><last>Forcada</last></editor>
      <publisher>European Association for Machine Translation</publisher>
      <address>Lisboa, Portugal</address>
      <month>November</month>
      <year>2020</year>
      <url hash="7d46b928">2020.eamt-1</url>
    </meta>
    <frontmatter>
      <url hash="ab0a7709">2020.eamt-1.0</url>
      <bibkey>eamt-2020-european</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Efficiently Reusing Old Models Across Languages via Transfer Learning</title>
      <author><first>Tom</first><last>Kocmi</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>19–28</pages>
      <abstract>Recent progress in neural machine translation (NMT) is directed towards larger <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> trained on an increasing amount of hardware resources. As a result, NMT models are costly to train, both financially, due to the electricity and hardware cost, and environmentally, due to the <a href="https://en.wikipedia.org/wiki/Carbon_footprint">carbon footprint</a>. It is especially true in <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> for its additional cost of training the parent model before transferring knowledge and training the desired <a href="https://en.wikipedia.org/wiki/Child_model">child model</a>. In this paper, we propose a simple method of re-using an already trained <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> for different language pairs where there is no need for modifications in <a href="https://en.wikipedia.org/wiki/Statistical_model">model architecture</a>. Our approach does not need a separate parent model for each investigated language pair, as it is typical in NMT transfer learning. To show the applicability of our method, we recycle a Transformer model trained by different researchers and use it to seed models for different language pairs. We achieve better translation quality and shorter <a href="https://en.wikipedia.org/wiki/Convergence_of_random_variables">convergence times</a> than when training from random initialization.</abstract>
      <url hash="dc6b5b55">2020.eamt-1.3</url>
      <bibkey>kocmi-bojar-2020-efficiently</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2018">WMT 2018</pwcdataset>
    </paper>
    <paper id="4">
      <title>Efficient <a href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer Learning</a> for Quality Estimation with Bottleneck Adapter Layer</title>
      <author><first>Hao</first><last>Yang</last></author>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Ning</first><last>Xie</last></author>
      <author><first>Ying</first><last>Qin</last></author>
      <author><first>Yao</first><last>Deng</last></author>
      <pages>29–34</pages>
      <abstract>The Predictor-Estimator framework for quality estimation (QE) is commonly used for its strong performance. Where the predictor and <a href="https://en.wikipedia.org/wiki/Estimator">estimator</a> works on <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a> and <a href="https://en.wikipedia.org/wiki/Quality_assurance">quality evaluation</a>, respectively. However, training the <a href="https://en.wikipedia.org/wiki/Prediction">predictor</a> from scratch is computationally expensive. In this paper, we propose an efficient transfer learning framework to transfer knowledge from NMT dataset into <a href="https://en.wikipedia.org/wiki/Quantum_electrodynamics">QE models</a>. A Predictor-Estimator alike model named BAL-QE is also proposed, aiming to extract high quality features with pre-trained NMT model, and make classification with a fine-tuned Bottleneck Adapter Layer (BAL). The experiment shows that BAL-QE achieves 97 % of the SOTA performance in WMT19 En-De and En-Ru QE tasks by only training 3 % of parameters within 4 hours on 4 Titan XP GPUs. Compared with the commonly used NuQE baseline, BAL-QE achieves 47 % (En-Ru) and 75 % (En-De) of performance promotions.</abstract>
      <url hash="44ec6031">2020.eamt-1.4</url>
      <bibkey>yang-etal-2020-efficient</bibkey>
    </paper>
    <paper id="6">
      <title>Incorporating External Annotation to improve Named Entity Translation in NMT<fixed-case>NMT</fixed-case></title>
      <author><first>Maciej</first><last>Modrzejewski</last></author>
      <author><first>Miriam</first><last>Exel</last></author>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <pages>45–51</pages>
      <abstract>The correct translation of named entities (NEs) still poses a challenge for conventional neural machine translation (NMT) systems. This study explores methods incorporating <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition (NER)</a> into <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">NMT</a> with the aim to improve <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity translation</a>. It proposes an annotation method that integrates <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> and insideoutsidebeginning (IOB) tagging into the neural network input with the use of source factors. Our experiments on EnglishGerman and English Chinese show that just by including different NE classes and IOB tagging, we can increase the BLEU score by around 1 point using the standard test set from WMT2019 and achieve up to 12 % increase in NE translation rates over a strong baseline.</abstract>
      <url hash="a639a645">2020.eamt-1.6</url>
      <bibkey>modrzejewski-etal-2020-incorporating</bibkey>
    </paper>
    <paper id="8">
      <title>A multi-source approach for BretonFrench hybrid machine translation<fixed-case>B</fixed-case>reton–<fixed-case>F</fixed-case>rench hybrid machine translation</title>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <pages>61–70</pages>
      <abstract>Corpus-based approaches to machine translation (MT) have difficulties when the amount of parallel corpora to use for training is scarce, especially if the languages involved in the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> are highly inflected. This problem can be addressed from different perspectives, including <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>, and the use of additional resources, such as those used in rule-based MT. This paper focuses on the hybridisation of rule-based MT and neural MT for the BretonFrench under-resourced language pair in an attempt to study to what extent the rule-based MT resources help improve the translation quality of the neural MT system for this particular under-resourced language pair. We combine both translation approaches in a multi-source neural MT architecture and find out that, even though the rule-based system has a low performance according to automatic evaluation metrics, using it leads to improved translation quality.</abstract>
      <url hash="428bc35d">2020.eamt-1.8</url>
      <bibkey>sanchez-cartagena-etal-2020-multi</bibkey>
    </paper>
    <paper id="9">
      <title>Leveraging Multilingual Resources for Language Invariant Sentiment Analysis</title>
      <author><first>Allen</first><last>Antony</last></author>
      <author><first>Arghya</first><last>Bhattacharya</last></author>
      <author><first>Jaipal</first><last>Goud</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>71–79</pages>
      <abstract>Sentiment analysis is a widely researched NLP problem with state-of-the-art solutions capable of attaining human-like accuracies for various languages. However, these methods rely heavily on large amounts of labeled data or sentiment weighted language-specific lexical resources that are unavailable for low-resource languages. Our work attempts to tackle this data scarcity issue by introducing a neural architecture for language invariant sentiment analysis capable of leveraging various monolingual datasets for training without any kind of cross-lingual supervision. The proposed architecture attempts to learn language agnostic sentiment features via adversarial training on multiple resource-rich languages which can then be leveraged for inferring sentiment information at a sentence level on a low resource language. Our model outperforms the current state-of-the-art methods on the Multilingual Amazon Review Text Classification dataset [ REF ] and achieves significant performance gains over prior work on the low resource Sentiraama corpus [ REF ]. A detailed analysis of our research highlights the ability of our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> to perform significantly well in the presence of minimal amounts of training data for low resource languages.</abstract>
      <url hash="fb4c0580">2020.eamt-1.9</url>
      <bibkey>antony-etal-2020-leveraging</bibkey>
    </paper>
    <paper id="12">
      <title>Double Attention-based Multimodal Neural Machine Translation with Semantic Image Regions</title>
      <author><first>Yuting</first><last>Zhao</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <pages>105–114</pages>
      <abstract>Existing studies on multimodal neural machine translation (MNMT) have mainly focused on the effect of combining visual and textual modalities to improve translations. However, it has been suggested that the <a href="https://en.wikipedia.org/wiki/Visual_system">visual modality</a> is only marginally beneficial. Conventional visual attention mechanisms have been used to select the visual features from equally-sized grids generated by convolutional neural networks (CNNs), and may have had modest effects on aligning the visual concepts associated with textual objects, because the grid visual features do not capture semantic information. In contrast, we propose the application of semantic image regions for MNMT by integrating visual and textual features using two individual attention mechanisms (double attention). We conducted experiments on the Multi30k dataset and achieved an improvement of 0.5 and 0.9 BLEU points for English-German and English-French translation tasks, compared with the MNMT with grid visual features. We also demonstrated concrete improvements on <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance benefited from semantic image regions.</abstract>
      <url hash="fb521973">2020.eamt-1.12</url>
      <bibkey>zhao-etal-2020-double</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="14">
      <title>Fine-grained Human Evaluation of Transformer and Recurrent Approaches to <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> for English-to-Chinese<fixed-case>E</fixed-case>nglish-to-<fixed-case>C</fixed-case>hinese</title>
      <author><first>Yuying</first><last>Ye</last></author>
      <author><first>Antonio</first><last>Toral</last></author>
      <pages>125–134</pages>
      <abstract>This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese. To this end, we develop an error taxonomy compliant with the Multidimensional Quality Metrics (MQM) framework that is customised to the relevant phenomena of this translation direction. We then conduct an <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error annotation</a> using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019’s news test set. The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31 % reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories. We also note that two of the <a href="https://en.wikipedia.org/wiki/System">systems</a> evaluated do not produce any error for a category that was relevant for this translation direction prior to the advent of NMT systems : Chinese classifiers.</abstract>
      <url hash="42195dd4">2020.eamt-1.14</url>
      <bibkey>ye-toral-2020-fine</bibkey>
      <pwccode url="https://github.com/yy-ye/mqm-analysis" additional="false">yy-ye/mqm-analysis</pwccode>
    <title_ar>التقييم البشري الدقيق للمحول والنُهج المتكررة للترجمة الآلية العصبية للغة الإنجليزية إلى الصينية</title_ar>
      <title_pt>Avaliação Humana Refinada de Transformadores e Abordagens Recorrentes à Tradução de Máquina Neural para Inglês para Chinês</title_pt>
      <title_es>Evaluación humana detallada de los enfoques transformadores y recurrentes para la traducción automática neuronal para el inglés al chino</title_es>
      <title_fr>Évaluation humaine fine des approches transformatrices et récurrentes de la traduction automatique neuronale de l'anglais vers le chinois</title_fr>
      <title_ja>英語から中国語へのニューラルマシン翻訳のためのトランスフォーマーとリカレントアプローチの細かい人間評価</title_ja>
      <title_zh>中英互译神经机器翻译变压器与循环之法细粒度人工评估</title_zh>
      <title_hi>अंग्रेजी-से-चीनी के लिए न्यूरल मशीन अनुवाद के लिए ट्रांसफॉर्मर और आवर्तक दृष्टिकोण के ठीक-ठाक मानव मूल्यांकन</title_hi>
      <title_ru>Тонкозернистая человеческая оценка трансформаторных и рекуррентных подходов к нейронному машинному переводу для перевода с английского на китайский</title_ru>
      <title_ga>Meastóireacht Dhaonna Mhín ar Chur Chuige Trasfhoirmeora agus Athfhillteach maidir le haistriúchán meaisín néarach don Bhéarla go Sínis</title_ga>
      <title_el>Εξειδικευμένη ανθρώπινη αξιολόγηση μετασχηματιστών και επαναλαμβανόμενων προσεγγίσεων στη νευρωνική μηχανική μετάφραση για Αγγλικά-Κινέζικα</title_el>
      <title_hu>A transzformátor finomszemcséjű emberi értékelése és ismétlődő megközelítések a neurális gépi fordításhoz angol-kínai nyelvre</title_hu>
      <title_ka>ტრანფორმეტრის და განმეორებული პროგრამეტს ნეიროლური მაქინის გასაგულისხმებისთვის ადამიანის განსაზღვრება</title_ka>
      <title_kk>Трансформация және қайталанған қайталанған қасиеттерді ағылшын- қытайшаға аудару үшін нейрондық машинаның аудару</title_kk>
      <title_it>Valutazione umana a grana fine del trasformatore e degli approcci ricorrenti alla traduzione automatica neurale per inglese-cinese</title_it>
      <title_mk>Фино-обезбедена човечка евалуација на трансформирањето и повторните пристапи до превод на неврални машини за англиски-кинески</title_mk>
      <title_lt>Fine-grained Human Evaluation of Transformer and Recurrent Approaches to Neural Machine Translation for English-to-Chinese</title_lt>
      <title_ms>Evaluasi Manusia Berbentuk-baik Penukar dan Pendekatan Sekali-Sekali ke Penerjemahan Mesin Neural untuk Bahasa Inggeris-Cina</title_ms>
      <title_ml>നെയുറല്‍ മെഷീന്‍ പരിഭാഷക്കുകള്‍ക്കും വീണ്ടും ചൈനീസിലേക്കുള്ള മനുഷ്യന്‍ പരിശോധിയ്ക്കുന്നതിനും നല്ല കൈക്കൊള്ളുക</title_ml>
      <title_mn>Хүн төрөлхтөн шилжүүлэгч болон дахин дахин дахин ойлголт Англи-т Хятад хэлний мэдрэлийн машин хөрөнгө оруулах</title_mn>
      <title_no>Eksempel menneskelig evaluering av transformeringa og gjentakelige tilnærmingar til neuralmaskinsomsetjing for engelsk til kinesisk</title_no>
      <title_mt>Evalwazzjoni tal-Bniedem bi ħbub irfinati ta’ Approċċi ta’ Trasformazzjoni u Approċċi Rikorrenti għat-Traduzzjoni ta’ Magni Newrali għall-Ingliż-Ċiniż</title_mt>
      <title_pl>Dokładna ocena transformatorów i powtarzających się podejść do neuronowego tłumaczenia maszynowego dla języka angielskiego na chiński</title_pl>
      <title_ro>Evaluarea umană fină a transformatorului și abordările recurente ale traducerii automate neurale pentru limba engleză-chineză</title_ro>
      <title_si>හොඳ ග්‍රේන්ඩ් මිනිස්සු විශ්ලේෂණය සහ ආපහු ප්‍රවේශකය අවශ්‍යාවක් ඉංග්‍රීසිය- ටි- චීනියාවට නිර්මා</title_si>
      <title_sr>Dobra ljudska ocjena transformera i povratnih pristupa neurološkom prevodu za engleski na kineski</title_sr>
      <title_so>Turjumista afka Ingiriiska- iyo Shiino</title_so>
      <title_sv>Finkornig mänsklig utvärdering av transformatorer och återkommande metoder för neural maskinöversättning för engelsk-kinesiska</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>انگلیسی سے چینی کے لئے نیورل ماشین ترجمہ کے لئے نیورل ماشین کے لئے نیک دانے انسان کی ارزش</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Giỏi tiến trình đánh giá nhân loại cho chế biến hình và tiếp tục tiếp cận tới máy thần kinh dịch cho người Anh-Trung Quốc</title_vi>
      <title_hr>Dobra ljudska procjena transformera i povratnih pristupa neurološkom prevodu strojeva za engleski na kineski</title_hr>
      <title_da>Finkornet menneskelig evaluering af transformatorer og tilbagevendende tilgange til neural maskinoversættelse til engelsk-kinesisk</title_da>
      <title_id>Evaluasi Manusia Berbentuk Baik dari Transformer dan Pendekatan Sekali-Sekali untuk Translation Mesin Neural untuk bahasa Inggris-ke-Cina</title_id>
      <title_ko>변압기의 세립도 인간 평가와 영한 신경기계 번역의 귀속 방법</title_ko>
      <title_bg>Финозърнеста човешка оценка на трансформаторните и повтарящите се подходи към невралния машинен превод за английски-китайски</title_bg>
      <title_nl>Fijnkorrelige menselijke evaluatie van transformator en terugkerende benaderingen voor neuronale machinevertaling voor Engels-Chinees</title_nl>
      <title_fa>ارزیابی انسانی با دانه‌های نیکو از تغییر‌دهنده و تقریبا دوباره به ترجمه ماشین عصبی برای انگلیسی به چینی</title_fa>
      <title_sw>Tathmini za Binadamu zilizotolewa vizuri za Kutafsiri na Kupitia Karibu kwa Kiingereza na Kichina</title_sw>
      <title_de>Feingranulare menschliche Bewertung von Transformatoren und wiederkehrenden Ansätzen zur neuronalen maschinellen Übersetzung für Englisch-Chinesisch</title_de>
      <title_af>Fine-graad menslike evaluering van Transformeerder en Herhaalde toegang na Neurale Masjien Vertaling vir Engels-na-Sjinese</title_af>
      <title_sq>Vlerësimi i mirëkuptuar njerëzor i metodave të transformueshme dhe të përsëritura të përkthimit të makinave nervore për anglisht-në-kinez</title_sq>
      <title_hy>Անգլերեն-չինական թարգմանման նյարդային մեքենայի վերաբերյալ վերադարձվող և վերադարձվող մոտեցումների մարդկային գեղեցիկ գնահատումը</title_hy>
      <title_az>캻ngiliz톛-칂inl톛 캻ngiliz톛 il톛 캻ngiliz톛 il톛 캻ngiliz톛 t톛rc칲m톛 ed톛n N칬ral Makina 쿮lav톛 Et</title_az>
      <title_tr>캅nsan Ta첵첵arlama</title_tr>
      <title_am>Transfer and Recent Approaches to Neural machine translation for English-to-Chinese</title_am>
      <title_ca>Evaluació humana fina d'enfocaments transformadors i recurrents a la traducció de màquines neuronals per anglès a xinès</title_ca>
      <title_cs>Jemnozrnné lidské hodnocení transformátorů a opakovaných přístupů k neuronovému strojovému překladu pro angličtinu do čínštiny</title_cs>
      <title_bn>ট্রান্সফার্ন এবং পুনরাবারের সাথে নিউরাল মেশিন অনুবাদের ভালো গ্রেফতার করা মানুষ মানুষের মূল্যায়ন</title_bn>
      <title_et>Transformerite ja korduvate lähenemisviiside hindamine neuroaalsele masintõlkele inglise-hiina jaoks</title_et>
      <title_bs>Dobra ljudska procjena transformera i povratnih pristupa neurološkom prevodu za engleski na kineski</title_bs>
      <title_fi>Muuntajan hienorakeinen arviointi ja toistuvat lähestymistavat hermojen konekäännökseen englanniksi kiinaksi</title_fi>
      <title_jv>Ngucap Unique ora nggambar uwong sing paling apik karo Transformer karo Ngucap Perintah Pangan Perintah Njugal kanggo Terjamahan Inggiles karo Cines</title_jv>
      <title_sk>Drobnozrnato človeško ocenjevanje transformatorjev in ponavljajočih se pristopov k živčnemu strojnemu prevajanju za angleško-kitajsko</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>Fine-grained Human Evaluation of Transformer and Recurrent Approaches to Neural Machine Translation for English-to-Chinese</title_he>
      <title_bo>ཆད་འགྱུར་བ་དང་བསྐྱར་རིམ་གྱི་ཉེར་སྤྱོད་ལ་ཉེར་སྤྱོད་མིན་ཆས་གཞུང་གི་ཡིག་གཟུགས་འགྲོ་བ་དང་།</title_bo>
      <abstract_ar>يقدم هذا البحث تقييمًا بشريًا دقيقًا لمقارنة المحولات والمقاربات المتكررة للترجمة الآلية العصبية (MT) ، في اتجاه الترجمة من الإنجليزية إلى الصينية. تحقيقا لهذه الغاية ، قمنا بتطوير تصنيف خطأ متوافق مع إطار عمل مقاييس الجودة متعددة الأبعاد (MQM) الذي تم تخصيصه للظواهر ذات الصلة لاتجاه الترجمة هذا. نجري بعد ذلك تعليقًا توضيحيًا للخطأ باستخدام تصنيف الخطأ المخصص هذا على إخراج أنظمة MT الحديثة القائمة على المحولات والمتكررة في مجموعة فرعية من مجموعة اختبار الأخبار الخاصة بـ WMT2019. يوضح التعليق التوضيحي الناتج أنه ، مقارنةً بأفضل نظام متكرر ، يؤدي أفضل نظام محول إلى تقليل إجمالي عدد الأخطاء بنسبة 31٪ ، كما ينتج عنه أخطاء أقل بشكل ملحوظ في 10 من فئات الخطأ 22. نلاحظ أيضًا أن اثنين من الأنظمة التي تم تقييمها لا ينتج عنها أي خطأ لفئة كانت ذات صلة باتجاه الترجمة هذا قبل ظهور أنظمة NMT: المصنفات الصينية.</abstract_ar>
      <abstract_fr>Cette recherche présente une évaluation humaine fine pour comparer les approches Transformer et récurrentes de la traduction automatique neuronale (MT), sur le sens de la traduction de l'anglais vers le chinois. À cette fin, nous développons une taxonomie des erreurs conforme au framework MQM (Multidimensional Quality Metrics) qui est personnalisée en fonction des phénomènes pertinents de cette direction de traduction. Nous effectuons ensuite une annotation d'erreur à l'aide de cette taxonomie d'erreurs personnalisée sur la sortie de systèmes de TA récurrents et basés sur transformateur de pointe sur un sous-ensemble de l'ensemble de tests de nouvelles du WMT2019. L'annotation qui en résulte montre que, par rapport au meilleur système récurrent, le meilleur système de transformateur entraîne une réduction de 31 % du nombre total d'erreurs et qu'il a produit beaucoup moins d'erreurs dans 10 des 22 catégories d'erreurs. Nous notons également que deux des systèmes évalués ne produisent aucune erreur pour une catégorie qui était pertinente pour cette direction de traduction avant l'avènement des systèmes NMT : les classificateurs chinois.</abstract_fr>
      <abstract_es>Esta investigación presenta una evaluación humana detallada para comparar el Transformer y los enfoques recurrentes de la traducción automática neuronal (MT), en la dirección de la traducción del inglés al chino. Con este fin, desarrollamos una taxonomía de errores que cumple con el marco Multidimensional de Métricas de Calidad (MQM) que se personaliza para los fenómenos relevantes de esta dirección de traducción. A continuación, realizamos una anotación de errores utilizando esta taxonomía de errores personalizada en la salida de los sistemas de MT recurrentes y basados en transformadores de última generación en un subconjunto del conjunto de pruebas de noticias de WMT2019. La anotación resultante muestra que, en comparación con el mejor sistema recurrente, el mejor sistema Transformer da como resultado una reducción del 31% del número total de errores y produjo significativamente menos errores en 10 de las 22 categorías de error. También observamos que dos de los sistemas evaluados no producen ningún error para una categoría que era relevante para esta dirección de traducción antes de la llegada de los sistemas NMT: los clasificadores chinos.</abstract_es>
      <abstract_pt>Esta pesquisa apresenta uma avaliação humana refinada para comparar as abordagens Transformer e recorrente para tradução automática neural (MT), na direção da tradução inglês-chinês. Para isso, desenvolvemos uma taxonomia de erros compatível com o framework Multidimensional Quality Metrics (MQM) customizada para os fenômenos relevantes dessa direção de tradução. Em seguida, realizamos uma anotação de erro usando essa taxonomia de erro personalizada na saída de sistemas MT recorrentes e baseados em transformador de última geração em um subconjunto do conjunto de testes de notícias do WMT2019. A anotação resultante mostra que, comparado ao melhor sistema recorrente, o melhor sistema Transformador resulta em uma redução de 31% do número total de erros e produziu significativamente menos erros em 10 das 22 categorias de erros. Notamos também que dois dos sistemas avaliados não produzem nenhum erro para uma categoria que era relevante para esta direção de tradução antes do advento dos sistemas NMT: classificadores chineses.</abstract_pt>
      <abstract_ja>この研究は、英語から中国語への翻訳方向について、トランスフォーマーとニューラル機械翻訳（ MT ）への再帰的アプローチを比較するための細かい人間評価を提示している。このために、この翻訳方向の関連現象に合わせてカスタマイズされた多次元品質指標（ mqm ）フレームワークに準拠したエラー分類を開発します。次に、このカスタマイズされたエラー分類を使用して、WMT 2019のニューステストセットのサブセット上の最先端のリカレントおよびトランスフォーマーベースのMTシステムの出力でエラーアノテーションを行います。結果として得られた注釈によると、ベストリカレントシステムと比較して、ベストトランスフォーマーシステムはエラーの総数を31 ％削減し、22のエラーカテゴリのうち10のエラーを大幅に削減しました。また、評価されたシステムのうちの2つは、NMTシステムが登場する前にこの翻訳方向に関連していたカテゴリにエラーを生じさせないことにも注目しています：中国語の分類子。</abstract_ja>
      <abstract_zh>本论一细粒度之人,以较变形金刚神经机器翻译(MT)之循环,在英译韩方上。 发一合多维质量指标(MQM)框架之误分类法,框架以译方相关也。 然后用此自定义之谬分类法WMT2019新闻试集子集上最先进之循环,基于变压器之MT系统之误注。 由此注释,比之至循环系统,最佳变压器统,可使总谬减31%,而于22非类10类之误明减。 又注意于 NMT 统之前,所评两统不为翻译之别,中文分类器。</abstract_zh>
      <abstract_hi>यह शोध ट्रांसफॉर्मर और न्यूरल मशीन अनुवाद (एमटी) के लिए आवर्तक दृष्टिकोण की तुलना करने के लिए एक ठीक-ठाक मानव मूल्यांकन प्रस्तुत करता है, अनुवाद दिशा अंग्रेजी-से-चीनी पर। इस अंत के लिए, हम बहुआयामी गुणवत्ता मैट्रिक्स (MQM) ढांचे के साथ एक त्रुटि वर्गीकरण अनुरूप विकसित करते हैं जो इस अनुवाद दिशा की प्रासंगिक घटनाओं के लिए अनुकूलित है। फिर हम WMT2019 के समाचार परीक्षण सेट के सबसेट पर अत्याधुनिक आवर्तक और ट्रांसफॉर्मर-आधारित एमटी सिस्टम के आउटपुट पर इस अनुकूलित त्रुटि वर्गीकरण का उपयोग करके एक त्रुटि एनोटेशन का संचालन करते हैं। परिणामी एनोटेशन से पता चलता है कि, सबसे अच्छी आवर्तक प्रणाली की तुलना में, सबसे अच्छा ट्रांसफॉर्मर सिस्टम त्रुटियों की कुल संख्या में 31% की कमी के परिणामस्वरूप होता है और इसने 22 त्रुटि श्रेणियों में से 10 में काफी कम त्रुटियों का उत्पादन किया। हम यह भी ध्यान देते हैं कि मूल्यांकन किए गए सिस्टम में से दो एक श्रेणी के लिए कोई त्रुटि उत्पन्न नहीं करते हैं जो एनएमटी सिस्टम के आगमन से पहले इस अनुवाद दिशा के लिए प्रासंगिक था: चीनी क्लासिफायर।</abstract_hi>
      <abstract_ru>В этом исследовании представлена мелкозернистая оценка человека для сравнения трансформаторного и рекуррентного подходов к нейронному машинному переводу (МП) в направлении перевода с английского на китайский. С этой целью мы разрабатываем систематику ошибок, соответствующую структуре многомерных показателей качества (mqm), которая адаптирована к соответствующим явлениям этого направления перевода. Затем мы проводим аннотацию ошибок, используя эту настроенную таксономию ошибок на выходе современных рекуррентных и основанных на трансформаторах систем MT на подмножестве набора тестов новостей WMT2019. Полученная аннотация показывает, что по сравнению с лучшей повторяющейся системой, лучшая система трансформатора приводит к сокращению общего количества ошибок на 31% и дает значительно меньше ошибок в 10 из 22 категорий ошибок. Мы также отмечаем, что две из оцениваемых систем не дают какой-либо ошибки для категории, которая была бы релевантной для этого направления перевода до появления систем НМТ: китайские классификаторы.</abstract_ru>
      <abstract_ga>Cuireann an taighde seo luacháil dhaonna i láthair chun comparáid a dhéanamh idir an Claochladán agus na cineálacha cur chuige athfhillteacha maidir le haistriúchán meaisín néarach (MT), ar threo an aistriúcháin Béarla go Sínis. Chuige sin, forbraímid tacsanomaíocht earráide a chomhlíonann an creat Méadracht Cháilíochta Iltoiseach (MQM) atá saincheaptha do na feiniméin ábhartha de threoir an aistriúcháin seo. Déanaimid anótáil earráide ansin ag baint úsáide as an tacsanomaíocht earráide saincheaptha seo ar aschur na gcóras MT athfhillteach agus Trasfhoirmeoir den scoth ar fhothacar de thacar tástála nuachta WMT2019. Léiríonn an nóta a d’eascair as sin, i gcomparáid leis an gcóras athfhillteach is fearr, go dtagann laghdú 31% ar líon iomlán na n-earráidí mar thoradh ar an gcóras Trasfhoirmeora is fearr agus chruthaigh sé i bhfad níos lú earráidí i 10 gcinn as 22 chatagóir earráide. Tugaimid faoi deara freisin nach gcruthaíonn dhá cheann de na córais a ndearnadh meastóireacht orthu aon earráid do chatagóir a bhí ábhartha don treo aistriúcháin seo roimh theacht ar chórais NMT: Aicmitheoirí Síneacha.</abstract_ga>
      <abstract_el>Η έρευνα αυτή παρουσιάζει μια λεπτή ανθρώπινη αξιολόγηση για τη σύγκριση του μετασχηματιστή και των επαναλαμβανόμενων προσεγγίσεων της νευρωνικής μηχανικής μετάφρασης (ΜΤ), στην κατεύθυνση της μετάφρασης Αγγλικά-Κινέζικα. Για το σκοπό αυτό, αναπτύσσουμε μια ταξινομία σφαλμάτων σύμφωνη με το πλαίσιο Πολυδιάστατων Μετρικών Ποιότητας (ΜQM) που προσαρμόζεται στα σχετικά φαινόμενα αυτής της μεταφραστικής κατεύθυνσης. Στη συνέχεια, διεξάγουμε μια παρατήρηση σφάλματος χρησιμοποιώντας αυτή την προσαρμοσμένη ταξινομία σφαλμάτων στην έξοδο των σύγχρονων συστημάτων ΜΤ επαναλαμβανόμενων και μετασχηματιστών βασισμένων σε ένα υποσύνολο του σετ δοκιμών ειδήσεων του WMT2011. Η προκύπτουσα παρατήρηση δείχνει ότι, σε σύγκριση με το καλύτερο επαναλαμβανόμενο σύστημα, το καλύτερο σύστημα έχει ως αποτέλεσμα 31% μείωση του συνολικού αριθμού σφαλμάτων και παράγει σημαντικά λιγότερα σφάλματα σε 10 από 22 κατηγορίες σφαλμάτων. Σημειώνουμε επίσης ότι δύο από τα συστήματα που αξιολογήθηκαν δεν παράγουν κανένα σφάλμα για μια κατηγορία που ήταν σχετική με αυτή την κατεύθυνση μετάφρασης πριν από την εμφάνιση των συστημάτων NMT: Κινέζοι ταξινομητές.</abstract_el>
      <abstract_hu>A kutatás egy finomszemcsés emberi értékelést mutat be a transzformátor és az idegi gépi fordítás (MT) visszatérő megközelítéseinek összehasonlítására az angol-kínai fordítási irányban. Ennek érdekében egy olyan hibataxonómiát dolgozunk ki, amely megfelel a Multidimensional Quality Metrics (MQM) keretrendszernek, és amely a fordítási irány releváns jelenségeihez igazított. Ezt követően hibajegyzést végzünk e testreszabott hibataxonómia segítségével a WMT2019 hírkészletének egy részhalmazán a legkorszerűbb visszatérő és transzformátor alapú MT rendszerek kimenetén. Az így kapott megjegyzés azt mutatja, hogy a legjobb visszatérő rendszerhez képest a legjobb Transformer rendszer a teljes hibák számának 31%-os csökkenését eredményezi, és 22 hibakategóriából 10-ben jelentősen kevesebb hibát okozott. Megjegyezzük továbbá, hogy az értékelt rendszerek közül kettő nem okoz hibát egy olyan kategóriában, amely az NMT rendszerek megjelenése előtt releváns volt a fordítási irány szempontjából: a kínai osztályozók.</abstract_hu>
      <abstract_ka>ამ შესწავლობაში ადამიანის განსაზღვრება, რომელიც ტრანფორმეტრის და რეკურენტის გადაწყვებას ნეიროლური მაქინის განსაზღვრებას (MT) განსაზღვრებას ინგლისურ- ჩინეთიდან. ამისთვის, ჩვენ შეცდომის რაკონომის განვითარებით, რომელიც მრავამენტიური კვალტიფიკაციის მეტრიკის (MQM) ფრამეტრიკის კონფიგურაცია, რომელიც ამ შეცდომის მისამართლო ფექ შემდეგ ჩვენ შეცდომა ანტორიაციას გამოყენებთ ამ კონფიგურაციული შეცდომა რაკონიომის გამოყენება WMT2019 წინატების ტესტის სუბსეტესტის შემდეგ შეცდომა და გადატანსტრებერის MT სისტემის შემდეგ ანოტრაცია ჩვენებს, რომ ყველაფერი შეცდომის რაოდენობას 31% გამოწვება და 22 შეცდომის კატეგორიდან 10-ზე უფრო ცოტა გამოწვება. ჩვენ ასევე აღმოჩნეთ, რომ ორი განსაზღვრებული სისტემები არ გამოვიყენებს კატეგორია, რომელიც ამ განსაზღვრების მიერ შესახებ NMT სისტემების შესახებ: ჩინეთი კლასიფიკაციების შე</abstract_ka>
      <abstract_it>Questa ricerca presenta una valutazione umana a grana fine per confrontare il Transformer e gli approcci ricorrenti alla traduzione automatica neurale (MT), sulla direzione di traduzione inglese-cinese. A tal fine, sviluppiamo una tassonomia degli errori conforme al framework Multidimensional Quality Metrics (MQM) che è personalizzata ai fenomeni rilevanti di questa direzione di traduzione. Eseguiamo quindi un'annotazione di errore utilizzando questa tassonomia di errore personalizzata sull'output di sistemi MT ricorrenti e basati su Transformer all'avanguardia su un sottoinsieme del set di test di WMT22019. L'annotazione risultante mostra che, rispetto al miglior sistema ricorrente, il miglior sistema Transformer si traduce in una riduzione del 31% del numero totale di errori e ha prodotto significativamente meno errori in 10 categorie di errore su 22. Notiamo inoltre che due dei sistemi valutati non producono errori per una categoria rilevante per questa direzione di traduzione prima dell'avvento dei sistemi NMT: i classificatori cinesi.</abstract_it>
      <abstract_kk>Бұл зерттеулердің түрлендіруші мен қайталанатын қайталанатын түрлендірушісін (MT) қайталау үшін, ағылшын- қытайшаға аудару бағытты адамның бағалауын көрсетеді. Бұл үшін біз қатенің таксономиясын бірнеше өлшемі сапалық метрикалық (MQM) рамкасына сәйкес келеді. Бұл аудармалы бағыттың маңызды пайдалануларына бапталған. Содан кейін WMT2019 жаңалық сынақтарының астындағы MT жүйелерін қайталау және транформациялау жүйелерінің шығысындағы бапталған қатенің таксономиясын қолданып қатені жазып берік. Сондағы жағдайларды қайталану жүйесіне салыстыру үшін ең жақсы түрлендіруші жүйесінің жалпы қателер санын 31% азайту және ол 22 қателер санынан 10 деген қатеге дейін өте кішіреді. Біз сонымен қатар, бағалатын жүйелердің екі қатесі NMT жүйелерінің алдында бұл аудармалы бағыттамасына қатынау үшін қатесі жоқ: Қытай классификаторы.</abstract_kk>
      <abstract_lt>Šiuose tyrimuose pateikiamas smulkiai apdorotas žmogaus vertinimas, siekiant palyginti Transformuotojo ir pakartotinius metodus nervinių mašinų vertimui (MT) vertimo anglų kalba į kinų kalbą kryptimi. Šiuo tikslu sukuriame klaidų taksonomiją, atitinkančią daugiametės kokybės metrikos (MQM) sistemą, pritaikytą prie atitinkamų šios vertimo krypties reiškinių. Tada atliksime klaidų anotaciją naudojant šią pritaikytą klaidų taksonomiją, susijusią su naujausios pažangiausios kartotinės ir transformuojančios MT sistemų išėjimu WMT2019 naujienų bandymų rinkinio pogrupyje. Iš gautos anotacijos matyti, kad palyginti su geriausia pasikartojančia sistema, geriausia Transformer sistema 31 % sumažin a bendrą klaidų skaičių ir 10 iš 22 klaidų kategorijų sukėlė gerokai mažiau klaidų. Taip pat pažymime, kad dvi iš įvertintų sistemų nesukelia jokių klaidų kategorijai, kuri buvo svarbi šioje vertimo kryptimi prieš atsirandant NMT sistemoms: Kinijos klasifikatoriams.</abstract_lt>
      <abstract_mk>This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese.  За ова, развиваме таксономија на грешки во согласност со рамката за мултидимензионални квалитетни метрики (MQM), која е прилагодена на релевантните феномени на оваа насока на превод. Потоа спроведуваме анотација на грешка користејќи ја оваа прилагодена таксономија на грешки на излезот на најсовремените рецидентни и трансформни MT системи на подгрупа од текстовите на WMT2019. Резултатот на анатацијата покажува дека, во споредба со најдобриот рецидентен систем, најдобриот трансформен систем резултира со 31 отсто намалување на вкупниот број грешки и предизвика значително помалку грешки во 10 од 22 категории грешки. Исто така, истакнуваме дека двајца од проценетите системи не создаваат никаква грешка за категорија која беше релевантна за оваа насока на превод пред појавата на НМТ системите: Кинеските класификатори.</abstract_mk>
      <abstract_ms>Penelitian ini menghasilkan penilaian manusia yang baik untuk membandingkan pendekatan Transformer dan pendekatan berulang kepada terjemahan mesin saraf (MT), pada arah terjemahan bahasa Inggeris-ke-Cina. Untuk tujuan ini, kita mengembangkan taksonomi ralat yang sesuai dengan kerangka Metrik Kualiti Berberbilang Dimensi (MQM) yang disesuaikan kepada fenomena relevan arah terjemahan ini. Kemudian kita buat anotasi ralat menggunakan taksonomi ralat tersendiri ini pada output sistem MT terkadang dan berasaskan Transformer pada subset set ujian berita WMT2019. Anotasi yang menghasilkan menunjukkan bahawa, dibandingkan dengan sistem berulang terbaik, sistem Transformer terbaik menghasilkan pengurangan 31% jumlah ralat dan ia menghasilkan lebih kurang ralat dalam 10 daripada 22 kategori ralat. Kami juga memperhatikan bahawa dua sistem yang diteliti tidak menghasilkan sebarang ralat untuk kategori yang relevan untuk arah terjemahan ini sebelum muncul sistem NMT: klasifikasi Cina.</abstract_ms>
      <abstract_ml>ട്രാന്‍സ്ഫോര്‍മാര്‍ മാറ്റുന്നതിനെക്കുറിച്ചും തിരിച്ചറിയുന്നതിനെക്കുറിച്ച് ന്യൂറല്‍ മെഷീന്‍ പരിഭാഷണത്തിന്‍റെ പരിഭാഷണങ്ങള്‍ ഈ പരിഭാഷത്തിന്റെ പ്രധാനപൂര്‍ണ്ണമായ മെറ്റിമെറ്റിക്സുകളുടെ (എംക്യൂഎം) ഫ്രെയിമെറ്റിക്കുകളോടൊപ്പം ഞങ്ങള്‍ പിശക് ടാക്സോനോമി ന പിന്നീട് ഞങ്ങള്‍ ഈ സ്വന്തം പിശക് ടാക്സോനോമിയെ ഉപയോഗിക്കുന്നതില്‍ ഒരു പിശക് പ്രവര്‍ത്തിപ്പിക്കുന്നു. വിഎംടി2019യുടെ വാര്‍ത്ത പരീക്ഷണസെറ്റിന The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31% reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories.  NMT സിസ്റ്റത്തിന്റെ അഭിപ്രായത്തിനു മുമ്പുള്ള ഈ പരിഭാഷത്തിന്റെ തിരിച്ചറിയുന്ന രണ്ട് സിസ്റ്റത്തില്‍ നിന്നും ഒരു പിശക് ഉണ്ടാക്ക</abstract_ml>
      <abstract_mt>Din ir-riċerka tippreżenta evalwazzjoni umana fina biex tqabbel l-approċċi tat-Transformer u rikorrenti għat-traduzzjoni tal-magni newrali (MT), dwar id-direzzjoni tat-traduzzjoni Ingliż-Ċiniż. Għal dan il-għan, niżviluppaw tassonomija ta’ żbalji konformi mal-qafas tal-Metriki ta’ Kwalità Multidimensjonali (MQM) li huwa adattat għall-fenomeni rilevanti ta’ din id-direzzjoni ta’ traduzzjoni. Imbagħad nagħmlu annotazzjoni ta’ żball bl-użu ta’ din it-tassonomija ta’ żball personalizzata fuq il-produzzjoni ta’ sistemi MT rikorrenti u bbażati fuq Transformer state-of-the-art fuq sottosett tat-test tal-a ħbarijiet tad-WMT2019. L-annotazzjoni li tirriżulta turi li, meta mqabbla mal-a ħjar sistema rikorrenti, l-aħjar sistema ta’ Trasformer tirriżulta fi tnaqqis ta’ 31 % tan-numru totali ta’ żbalji u pproduċiet b’mod sinifikanti inqas żbalji f’10 minn 22 kategorija ta’ żbalji. Ninnutaw ukoll li tnejn mis-sistemi evalwati ma jipproduċu l-ebda żball għal kategorija li kienet rilevanti għal din id-direzzjoni ta’ traduzzjoni qabel il-ħolqien ta’ sistemi NMT: klassifikaturi Ċiniżi.</abstract_mt>
      <abstract_pl>Badania te przedstawiają precyzyjną ocenę człowieka w celu porównania transformatora i powtarzających się podejść do neuronowego tłumaczenia maszynowego (MT), w kierunku tłumaczenia angielsko-chiński. W tym celu opracowujemy taksonomię błędów zgodną z wielowymiarowymi wskaźnikami jakości (MQM), dostosowaną do odpowiednich zjawisk tego kierunku tłumaczenia. Następnie przeprowadzamy adnotację błędów przy użyciu tej spersonalizowanej taksonomii błędów na wyjściu najnowocześniejszych systemów MT opartych na Transformerze opartych na podzbiorze zestawu testów wiadomości WMT2011. Wynikająca z nich adnotacja pokazuje, że w porównaniu do najlepszego systemu powtarzającego, najlepszy system Transformera skutkuje 31% zmniejszeniem całkowitej liczby błędów i spowodował znacznie mniejszą liczbę błędów w 10 z 22 kategorii błędów. Zauważamy również, że dwa z ocenianych systemów nie powodują żadnego błędu dla kategorii istotnej dla tego kierunku tłumaczenia przed pojawieniem się systemów NMT: chińskich klasyfikatorów.</abstract_pl>
      <abstract_ro>Această cercetare prezintă o evaluare umană cu granule fine pentru a compara Transformer și abordările recurente ale traducerii automate neurale (MT), pe direcția de traducere engleză-chineză. În acest scop, dezvoltăm o taxonomie a erorilor conformă cu cadrul Multidimensional Quality Metrics (MQM), personalizată la fenomenele relevante ale acestei direcții de traducere. Apoi efectuăm o adnotare de eroare folosind această taxonomie personalizată a erorilor pe rezultatele sistemelor MT recurente și bazate pe Transformer de ultimă generație pe un subset al setului de testare de știri WMT22019. Adnotarea rezultată arată că, în comparație cu cel mai bun sistem recurent, cel mai bun sistem Transformer duce la o reducere cu 31% a numărului total de erori și a produs semnificativ mai puține erori în 10 din 22 categorii de erori. De asemenea, observăm că două dintre sistemele evaluate nu produc nicio eroare pentru o categorie care a fost relevantă pentru această direcție de traducere înainte de apariția sistemelor NMT: clasificatorii chinezi.</abstract_ro>
      <abstract_no>Denne forskningen viser eit fint menneskelig evaluering for å samanlikna transformeringa og gjentakelig tilnærmingar til omsetjinga av neuralmaskin (MT) på omsetjingsreksten engelsk til kinesisk. I denne slutten utviklar vi ein feiltaxonomi som passar med rammeverket med fledimensjonale kvalitetsmetrikk (MQM) som er tilpassa til dei relevante fenomenane i denne omsetjingsreksten. Vi gjer derfor ein feilnotasjon ved å bruka denne tilpassa feiltaxonomien på utdata av rekurserande og transformeringssystemet med tilstanden på MT- basert på ein undergruppe av WMT2019- nyhetsstesten. Det følgjande notasjonen viser at det beste transformeringssystemet i sammenligning med den beste gjentakingssystemet resulterer i ein 31% reduksjon av totalt tal på feil, og det produserer mykje mindre feil i 10 av 22 feilkategoriar. Vi legg også merke til at to av evaluerte systema ikkje produserer nokon feil for ein kategori som var relevant for denne omsetjingsreksten før innkomsten av NMT-systemet: kinesiske klassifiserar.</abstract_no>
      <abstract_si>මේ පරීක්ෂණය පෙනුවන් මිනිස්සු ග්‍රේන්ඩ් විශ්ලේෂණයක් පෙනුවෙන් ප්‍රවර්තනය සහ ආපහු ප්‍රවර්තනය විශ්ලේෂණය සඳහා නියුර මේ අවසානයෙන්, අපි වැරදි ක්‍රියාත්මක ක්‍රියාත්මක විශේෂතාවය (MQM) ක්‍රියාත්මක පරීක්ෂණය සමඟ අවස්ථාවක් වෙන්නේ මේ වාර් අපි ඊට පස්සේ මෙම වැරදිලි වැරදිලි තියාගන්නේ WMT2019 ගේ වාර්තාව පරීක්ෂණ සැකසුම් සඳහා මෙම වැරදිලි තියාගන්න ප්‍රයෝජනයක් භාවිත කරනවා. ප්‍රතිචාරණය පෙන්වන්නේ හොඳම ප්‍රතිචාරණ පද්ධතිය සමග, හොඳම ප්‍රතිචාරණ පද්ධතියෙන් ප්‍රතිචාරණ පද්ධතිය 31% වැරදි සංඛ්යාව අපි දැනගන්නවා විශ්වාස කරපු පද්ධතියෙන් දෙන්නෙක් නිර්මාණය කරන්නේ නැහැ NMT පද්ධතියෙන් පිළිගත්ත කලින් මේ වාර්ථාව</abstract_si>
      <abstract_sr>Ova istraživanja predstavlja odličnu ljudsku procjenu kako bi usporedila transformator i rekonstruirani pristup prevodu neuralne mašine (MT) na prijevoznom smjeru engleskog na kineskog. Za taj cilj, razvijamo taksonomiju greške u skladu s okvirom metrika Multidimenzionalne kvalitete (MQM) koji je prilagođen relevantnim fenomenima ovog prijevoznog smjera. Potom ćemo obaviti oznaku greške koristeći ovu prilagođenu taksonomiju greške na izlazu povratnih i transformacijskih MT sistema na podskupini test a WMT2019-a. Rezultatna annotacija pokazuje da, u usporedbi sa najboljim rekonstruiranim sistemom, najbolji sustav transformera rezultira smanjenju ukupnog broja grešaka od 31% i proizvela je značajno manje grešaka u 10 od 22 kategorija grešaka. Takođe primjećujemo da dve od procjenjenih sustava ne proizvode grešku za kategoriju koja je bila relevantna za ovu smjeru prevođenja pre dolaska NMT sistema: kineske klasifikatore.</abstract_sr>
      <abstract_sv>Denna forskning presenterar en finkornig mänsklig utvärdering för att jämföra Transformer och återkommande ansatser till neural maskinöversättning (MT), på översättningsriktningen engelska-till-kinesiska. För detta ändamål utvecklar vi en feltaxonomi som överensstämmer med ramverket Multidimensional Quality Metrics (MQM) som är anpassad till relevanta fenomen i denna översättningsriktning. Vi utför sedan en felannotering med hjälp av denna anpassade feltaxonomi på resultatet av toppmoderna återkommande- och transformerbaserade MT-system på en delmängd av WMT2019s nyhetstestset. Den resulterande noteringen visar att det bästa Transformersystemet jämfört med det bästa återkommande systemet resulterar i en 31% minskning av det totala antalet fel och det gav betydligt färre fel i 10 av 22 felkategorier. Vi noterar också att två av de utvärderade systemen inte ger några fel för en kategori som var relevant för denna översättningsriktning före tillkomsten av NMT-system: kinesiska klassificerare.</abstract_sv>
      <abstract_ta>@ info இந்த மொழிபெயர்ப்பு திசையின் தொடர்பு பொருத்தமான பிழை வரிசையை நாம் உருவாக்குகிறோம். @ info The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31% reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories.  இந்த மொழிபெயர்ப்பு திசைக்கு தேவையான இந்த மொழிபெயர்ப்பு திசைக்கு எந்த பிழையையும் கொண்டிருக்கவில்லை என்று நாம் குறிப்பிடுகிற</abstract_ta>
      <abstract_so>This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese.  Taas darteed waxaynu horumarinnaa cashuur qalad oo ku waafaqsan qashinka nooca badan (MQM) oo loo isticmaalayo xaaladaha ku saabsan hagitaan turjumistan. Markaas waxaynu sameynaa dhibaato khalad ah oo isticmaalaya canshuurahan khaladda lagu isticmaalay soo bixinta dowlada-of-the-art-recurrence- and Transformer MT systems on a subset of WMT2019's news set. Taararka sababtu waxay tusaysaa in, barbardhig ahaan nidaamka ugu fiican ee dib u soo socda, nidaamka ugu wanaagsan ee turjumista ayaa ka soo baxa 31% oo ka go'aya tirada khaladaha oo dhan, waxaana soo saaray qalad aad u yar 10 kooxaha qaladka oo 22 ka mid ah. Sidoo kale waxaynu fiirinnaa in labada nidaam oo qiimeynaya aan khalad u keenin kooxo ay u muhiimsan hagitaan turjumistan ka hor imaatin nidaamka NMT: Shiinaha fasaxa.</abstract_so>
      <abstract_mn>Энэ судалгаанд хүн төрөлхтний тооцооллоог харьцуулахын тулд Трансформатор болон дахин дахин дахин ойлгох ойлголтыг мэдрэлийн машин хөрөнгө оруулах (MT) болон Англи хэл-Хятадад харьцуулахын тулд Энэ төгсгөлд бид олон хэмжээст хэмжээст метрик (MQM) хэмжээтэй хамааралтай алдааны татекономийг хөгжүүлнэ. Дараа нь бид WMT2019 оны мэдээллийн туршилтын давхар багш дээр өөрчлөгдсөн алдааны татекономикийг ашиглан алдаа гаргаж байдаг. Үүний үр дүнд харуулсан нь хамгийн сайн дахин дахин дахин дахин дахин дахин дахин системтэй харьцуулахад хамгийн шилдэг Трансфер систем нь нийт алдааны тоо 31% багасгаж, энэ нь 22 алдааны категориудын 10-д маш бага алдаа гаргасан. Мөн бид үнэлэх системийн хоёр нь NMT системийн ирэхээс өмнө энэ хөрөнгө оруулалтын хэлбэрийн тухай ямар ч алдаа гаргахгүй гэдгийг анзаарсан.</abstract_mn>
      <abstract_ur>یہ تحقیقات ایک اچھا دانہ انسان کا ارزیابہ پیش کرتا ہے کہ تغییرات اور دوبارہ تغییرات کے مطابق نیورال ماشین ترجمہ (MT) کے مطابق مطابق انگلیسی سے چین کی ترجمہ کرے۔ اس کے لئے ہم ایک خطا تاکسونومی کو پیدا کرتے ہیں جو اس ترجمہ دیگر کی تعلق والی مٹریک (MQM) کے مطابق مطابق ہے۔ اس کے بعد ہم اس خطا کا اظہار کریں گے جو WMT2019 کے نیویٹ ٹیسٹ سٹ پر اس خطا ٹاکنومیٹ کی استعمال کرتا ہے۔ نتیجہ کا انٹوریٹ دکھاتا ہے کہ بہترین دوبارہ ریٹوریٹ سیسٹم کے مقابلہ میں بہترین ترفنٹر سیسٹم نے 31% کی کمی کی اور اس نے 22 خطا کائٹیوں میں 10 سے زیادہ کم خطا پیدا کیا۔ ہم نے بھی یاد رکھا ہے کہ ان دو سیستموں میں سے جو ارزش کیا گیا تھا ان کے لئے کوئی خطا نہیں ہے جو NMT سیستموں کے آجانے سے پہلے ان کی ترجمہ کی طرف متعلق ہوئی تھی: چینی کلیسائر۔</abstract_ur>
      <abstract_uz>@ info: whatsthis Va shunday qilib, biz bu tarjima tizimning muhit bogʻliq holatga qoʻllaniladigan Multidimensional Quality Metrics (MQM) freymi bilan bog'liq boʻlgan xato taxonomi yaratishmiz. @ info The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31% reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories.  Biz shunday ko'rib chiqqatgan ikki tizimlar NMT tizimlarni boshqarishdan oldin, bu tarjima tizimga muhim boʻlgan kategoriga yetishmaydi.</abstract_uz>
      <abstract_vi>Nghiên cứu này đưa ra một bài đánh giá nhân loại hoàn hảo để so sánh các phương pháp biến hình và thường xuyên của dịch dịch thiết bị thần kinh (MTV) về hướng dịch (Anh-sang-Trung Quốc). Để đạt được mục đích này, chúng tôi phát triển một loại lỗi taxonomy khớp với bộ phận đa chiều chất lượng Metrics (MQM) mà được tận dụng để phục tùng các hiện tượng liên quan của hướng dịch này. Sau đó chúng tôi thực hiện một chú thích lỗi bằng cách s ử dụng lỗi này, taxonomy (taxonomy) trên xuất của các-of-the-art-of-the-art nổi-lưu lại- và transformer-based MTV hệ thống thống thống thống thống thống thống thống lượng tin tức của WM2Pt99. Kết quả ghi chú cho thấy, so với hệ thống được dựng lại tốt nhất, hệ thống transformer hiệu quả là một giảm 311=.='của tổng số lỗi và nó gây ra một số lỗi lớn hơn nhiều trong hạng lỗi 10 bên ngoài 22. Chúng tôi cũng lưu ý rằng hai hệ thống đánh giá không gây ra lỗi cho một loại có liên quan tới hướng dịch này trước khi hệ thống NMB tới: phân loại người Trung Quốc.</abstract_vi>
      <abstract_da>Denne forskning præsenterer en finkornet menneskelig evaluering for at sammenligne Transformer og tilbagevendende tilgange til neural maskinoversættelse (MT), på oversættelsesretningen engelsk-til-kinesisk. Med henblik herpå udvikler vi en fejltaksonomi, der er i overensstemmelse med Multidimensional Quality Metrics (MQM) framework, der er skræddersyet til de relevante fænomener i denne oversættelsesretning. Vi udfører derefter en fejlnotering ved hjælp af denne skræddersyede fejltaksonomi på output af state-of-the-art tilbagevendende og Transformer-baserede MT-systemer på en delmængde af WMT2019s nyhedstest. Den resulterende notering viser, at det bedste Transformer-system i forhold til det bedste tilbagevendende system resulterer i en 31% reduktion af det samlede antal fejl, og det producerede betydeligt færre fejl i 10 ud af 22 fejlkategorier. Vi bemærker også, at to af de evaluerede systemer ikke producerer nogen fejl for en kategori, der var relevant for denne oversættelsesretning før fremkomsten af NMT-systemer: Kinesiske klassificeringssystemer.</abstract_da>
      <abstract_de>Diese Forschung präsentiert eine feingranulare menschliche Evaluation, um den Transformer und wiederkehrende Ansätze der neuronalen maschinellen Übersetzung (MT) auf der Übersetzungsrichtung Englisch-Chinesisch zu vergleichen. Zu diesem Zweck entwickeln wir eine Fehlertaxonomie gemäß dem Framework Multidimensional Quality Metrics (MQM), die auf die relevanten Phänomene dieser Übersetzungsrichtung zugeschnitten ist. Anschließend führen wir eine Fehlerannotation mithilfe dieser benutzerdefinierten Fehlertaxonomie auf der Ausgabe modernster wiederkehrender und transformerbasierter MÜ-Systeme auf einer Teilmenge des WMT201s News-Testsets durch. Die resultierende Annotation zeigt, dass das beste Transformer-System im Vergleich zum besten wiederkehrenden System zu einer 31% Reduzierung der Gesamtfehlerzahl führt und deutlich weniger Fehler in 10 von 22 Fehlerkategorien verursacht. Wir stellen auch fest, dass zwei der untersuchten Systeme für eine Kategorie, die vor dem Aufkommen der NMT-Systeme für diese Übersetzungsrichtung relevant war, keinen Fehler erzeugen: chinesische Klassifikatoren.</abstract_de>
      <abstract_nl>Dit onderzoek presenteert een fijnkorrelige menselijke evaluatie om de Transformer en terugkerende benaderingen van neurale machinevertaling (MT) te vergelijken op de vertaalrichting Engels-naar-Chinees. Hiervoor ontwikkelen we een fouttaxonomie conform het Multidimensionale Kwaliteitsmetricks (MQM) framework dat is aangepast aan de relevante fenomenen van deze vertaalrichting. Vervolgens voeren we een foutannotatie uit met behulp van deze aangepaste fouttaxonomie op de uitvoer van state-of-the-art terugkerende en Transformer-gebaseerde MT-systemen op een subset van WMT201s nieuwstestset. De resulterende annotatie toont aan dat, vergeleken met het best terugkerende systeem, het beste Transformer systeem resulteert in een 31% vermindering van het totale aantal fouten en het aanzienlijk minder fouten produceerde in 10 van 22 foutcategorieën. We merken ook op dat twee van de geëvalueerde systemen geen fouten opleveren voor een categorie die relevant was voor deze vertaalrichting vóór de komst van NMT-systemen: Chinese classificatoren.</abstract_nl>
      <abstract_bg>Това изследване представя фина човешка оценка за сравнение на трансформаторните и повтарящите се подходи към невронния машинен превод (МТ) в посоката на превода от английски на китайски. За тази цел разработваме таксономия на грешките, съответстваща на Многоизмерната рамка за измерване на качеството (МQM), която е персонализирана спрямо съответните явления в тази посока на превода. След това провеждаме анотация на грешки, използвайки тази персонализирана таксономия за грешки върху изхода на най-съвременните повтарящи се и трансформаторни системи МТ върху поднабор от тестове за новини на WMT2019. Получената анотация показва, че в сравнение с най-добрата повтаряща се система най-добрата трансформаторна система води до 31% намаление на общия брой грешки и значително по-малко грешки в 10 от 22 категории грешки. Отбелязваме също, че две от оценените системи не произвеждат никаква грешка за категория, която е била релевантна за тази посока на превод преди появата на НМТ системи: китайски класификатори.</abstract_bg>
      <abstract_hr>Ova istraživanja predstavlja odličnu ljudsku procjenu kako bi usporedila transformator i rekonstruirani pristup prevodu neuralnih strojeva (MT) na prijevoznom smjeru engleskog i kineskog. Za taj cilj razvijamo taksonomiju greške u skladu s okvirom metrika Multidimenzionalne kvalitete (MQM) koji je prilagođen relevantnim fenomenima ovog prijevoznog smjera. Zatim ćemo obaviti oznake o greški koristeći ovu prilagođenu taksonomiju greške na izlazu povratnih i transformacijskih sustava MT-a na podskupini testa WMT2019-a. Najbolji sustav transformera rezultira smanjenju ukupnog broja grešaka u usporedbi s najboljim rekonstruiranim sustavom od 31% i proizvela je značajno manje greške u 10 od 22 kategorija grešaka. Također primjećujemo da dvoje procjenjenih sustava ne proizvode grešku za kategoriju koja je bila relevantna za ovu smjeru prevođenja prije dolaska NMT sustava: kineske klasifikatore.</abstract_hr>
      <abstract_id>Penelitian ini mempersembahkan evaluasi manusia yang sempurna untuk membandingkan pendekatan Transformer dan pendekatan yang berulang-ulang untuk terjemahan mesin saraf (MT), pada arah terjemahan bahasa Inggris-ke-Cina. Untuk tujuan ini, kami mengembangkan taksonomi kesalahan yang sesuai dengan kualitas Metrik Multidimensional (MQM) kerangka yang disesuaikan dengan fenomena relevan dari arah terjemahan ini. Kemudian kita melakukan anotasi kesalahan dengan menggunakan taksonomi kesalahan tersendiri ini pada output dari sistem MT berbasis state-of-the-art dan Transformer pada subset dari set tes berita WMT2019. Anotasi yang menghasilkan menunjukkan bahwa, dibandingkan dengan sistem berkurang terbaik, sistem Transformer terbaik menghasilkan pengurangan 31% dari jumlah total kesalahan dan menghasilkan lebih sedikit kesalahan dalam 10 dari 22 kategori kesalahan. Kami juga memperhatikan bahwa dua dari sistem yang diteliti tidak menghasilkan kesalahan apapun untuk kategori yang relevan untuk arah terjemahan ini sebelum muncul sistem NMT: klasifikasi Cina.</abstract_id>
      <abstract_tr>Bu araştyrma transformatöri we ýene-de näyral maşynyň terjime edilmesine (MT) golaýlaşyk üçin gowy adamlaryň çykyşyny görkezýär. Bu üçin, bu terjime daýasynyň wajyp bolan çykyşyna (MQM) çerçewletlere uyumlaýan hata taksadoniň düzümlenmesini çykarýarys. Sonra WMT2019'in haber testinde bu görkezilmiş hata taksitesini kullanarak hata s özleşdirdik. Sonuçta sözleşme ýaly iň gowy ýygnan sisteme karşılaşsa, iň gowy Transformer sistemi ýagdaýynda 31% hasaplanyň toplam hatalaryň sanyny azaltýar we ol 22 hata kategoriýasynda 10-dan az hata çykýar Munuň üçin deňlenen sistemleriň ikisi NMT sistemlerinin gelişmesinden öň bu terjime edilişinde hiç hili hata ýok.</abstract_tr>
      <abstract_fa>این تحقیقات برای مقایسه کردن ترجمه‌کننده و بازگشت به ترجمه‌های ماشین‌های عصبی (MT) در جهت ترجمه انگلیسی به چینی یک ارزیابی انسان را نشان می‌دهد. برای این قسمت، ما تاکسونوم خطایی را توسعه می کنیم که با چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچها سپس با استفاده از این تاکسونومی خطای تنظیم روی خروج سیستم‌های MT بر اساس تغییر‌دهنده‌ی ایالت‌های هنر و تغییر‌دهنده بر اساس مجموعه‌ی آزمایش خبری WMT2019 انجام می‌دهیم. توضیح نتیجه نشان می‌دهد که در مقایسه با بهترین سیستم تکرار، بهترین سیستم تبدیل کننده‌ی تبدیل کننده‌ی سیستم ۱۳ درصد کاهش تعداد کل اشتباه‌ها و در ۱۰ از ۲۲ kategoriه خطا به طور معنی خطاهای کمتری تولید می‌کند. ما همچنین یاد می‌گیریم که دو از سیستم‌های ارزیابی برای یک گروهی که قبل از آینده سیستم‌های NMT مربوط به این ترجمه است، هیچ اشتباهی برای یک گروهی پیدا نمی‌کند.</abstract_fa>
      <abstract_sw>Utafiti huu unaonyesha tathmini nzuri ya binadamu kwa kulinganisha mbinu za Transfer na zinazoendelea kwa mara kwa kutumia tafsiri za mashine ya kijamii (MT), katika muelekeo wa kutafsiri kwa Kiingereza-kwa-Kichina. Kwa mwisho huu, tunatengeneza utamaduni wa makosa unaohusiana na mfumo wa utaratibu wa aina mbalimbali (MQM) unaotumiwa katika hali inayohusiana na mwelekeo huu wa tafsiri. We then conduct an error annotation using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019's news test set.  Matangazo hayo yanaonyesha kuwa, ukilinganishwa na mfumo mzuri wa kurudi tena, mfumo bora wa Transfer unasababisha kupungua asilimia 31 ya idadi ya makosa ya jumla na ilisababisha makosa makubwa zaidi katika makundi 10 kati ya makundi ya makosa 22. Pia tunagundua kuwa mifumo miwili iliyopigwa hazijatoa makosa yoyote kwa makundi ambayo yalikuwa na umuhimu kwa mwelekeo huu wa tafsiri kabla ya kutolewa kwa mfumo wa NMT: wataalamu wa China.</abstract_sw>
      <abstract_ko>본 연구는 세립도의 인류 평가 방법을 제시하여 신경기계번역(MT)의 전환 방법과 귀속 방법이 영한 번역 방향에서의 차이를 비교하고자 한다.이를 위해 우리는 다차원 품질 도량(MQM) 프레임워크에 부합되는 오류 분류법을 개발했는데 이 프레임워크는 이 번역 방향과 관련된 현상을 맞춤형으로 제작했다.그리고 우리는 WMT2019 뉴스 테스트 집합의 하위 집합에서 이러한 맞춤형 오류 분류법을 사용하여 가장 선진적인 중복과 변압기를 바탕으로 하는 MT시스템의 출력에 대해 오류 주석을 한다.이로 인해 발생한 주석에 따르면 최적 순환 시스템에 비해 최적 변압기 시스템은 총 오류 수를 31% 감소시켰고 22개의 오류 유형 중 10개에서 발생한 오류가 현저히 감소했다.또한 NMT 시스템이 등장하기 전에 평가된 두 시스템은 이 번역 방향과 관련된 유형에 대해 어떠한 오류도 발생하지 않을 것이다. 그것이 바로 중국어 양사이다.</abstract_ko>
      <abstract_sq>Ky kërkim paraqet një vlerësim njerëzor të hollë për të krahasuar metodat e Transformuesve dhe të përsëritura të përkthimit të makinave nervore (MT), në drejtimin e përkthimit anglez-kinez. Për këtë qëllim, ne zhvillojmë një taksonomi gabimesh në përputhje me kualitetin Metrik Multidimensional (MQM) të kualitetit që është personalizuar me fenomenet e duhura të këtij drejtimi përkthimi. Pastaj kryejmë një anotacion gabimi duke përdorur këtë taksonomi të gabimeve të personalizuar në daljen e sistemeve MT me bazë në state-of-the-art dhe Transformer në një nëngrup të grupit të testit të lajmeve të WMT2019. Anotacioni që rezulton tregon se krahasuar me sistemin më të mirë të përsëritur, sistemi më i mirë Transformer rezulton në një reduktim 31% të numrit të përgjithshëm të gabimeve dhe prodhoi më pak gabime në 10 nga 22 kategori gabimesh. Ne gjithashtu vëmë në dukje se dy nga sistemet e vlerësuar nuk prodhojnë asnjë gabim për një kategori që ishte e rëndësishme për këtë drejtim përkthimi përpara shfaqjes së sistemeve NMT: klasifikuesit kinezë.</abstract_sq>
      <abstract_am>ትርጉም-ወደ ቻይና በተርጓሚው መሪና ላይ የናውራዊ መኪን ትርጓሜ (MT) ለማስተካከል እንደተካፈለ የሰው ማህበረሰብ ውጤት ያሳያል፡፡ ለዚህ መግለጫ የዚህ ትርጓሜ መንገድ በተገኘው የብዙአዊ ጥያቄ (MQM) ፍሬም የተደገመ የስህተት ስርዓት እናሳድጋለን፡፡ የዚያን ጊዜም ይህ የተጠቃሚ ስህተት ስህተት ስህተት ስህተት በመጠቀም እና በWMT2019 ዜና ፈተና ማውጣት ክፍል ላይ የግዛት-የ-ዓርት-ሰዓት-ውጤት እና የTransformer-based MT-systems. ፍጥረቱ ማስታወቂያው፣ ከመልካም ተሳካሚ ስርዓት ካስተካከለ፣ የተሻለ ተርጓሚ ስርዓት የሙሉ ስህተት ቁጥር 31 በመቶ ያሳስላል፡፡ እናም ከሁለቱ ተሟጋቾች ሁለት ስርዓቶች ከNMT ስርዓቶች ከመጠቀም በፊት ወደዚህ ትርጉም መግለጫ የሚያስፈልጋቸው ክፍል ምንም ስህተት እንዳያሳስቡ እናስታውቃለን፤ ቻይና መፍረጫዎች፡፡</abstract_am>
      <abstract_hy>Այս հետազոտությունը ներկայացնում է մարդկային հատուկ գնահատականը, որպեսզի համեմատենք թարգմանման ուղղությամբ անգլերեն-չինարեն թարգմանվող թարգմանման և կրկնօրինակ մոտեցումները: Այսպիսով, մենք զարգանում ենք սխալ տաքսոնոմիա, որը համապատասխանում է բազմաչափ որակային մետրիկայի (MQM) շրջանակին, որը պատրաստված է այս թարգմանման ուղղության նշանակալի երևույթներին: Այնուհետև մենք սխալներ ենք կատարում օգտագործելով այս պատրաստված սխալների տաքսոնոմիան ամենաբարձր վերադարձ և վերադարձ տեխնոլոգիական համակարգերի արտադրման վրա, աշխարհի MT2019 նորությունների թեստերի ենթախումբի վրա: The resulting annotation shows that, compared to the best recurrent system, the best Transformer system results in a 31% reduction of the total number of errors and it produced significantly less errors in 10 out of 22 error categories.  Մենք նաև նկատում ենք, որ գնահատված երկու համակարգերից ոչ մի սխալ չեն առաջացնում մի կատեգորիայի համար, որը կարևոր էր թարգմանման ուղղության համար նախքան NMT համակարգերի հայտնագործությունը՝ չինական դասակարգերը:</abstract_hy>
      <abstract_af>Hierdie ondersoek stel 'n fyn-koring menslike evaluering om die Transformer en herhaalde toegang te vergelyk na neurale masjien vertaling (MT) op die vertaling rigting Engels-na-Sinees. Na hierdie einde ontwikkel ons 'n fout taksonomie met die Multidimensional Kwaliteit Metrike (MQM) raamwerk wat pasmaak word aan die relevante fenomene van hierdie vertaling rigting. Ons het dan 'n fout annotasie gedoen met die gebruik van hierdie pasmaakte fout taxonomie op die uitvoer van state- of- the- art recurrent- en Transformer- gebaseerde MT stelsels op 'n subartikel van WMT2019 se nuus toets stel. Die resulteerde notasie vertoon dat, vergelyk met die beste herhaalde stelsel, die beste Transformer stelsel resultaat in 'n 31% verduur van die totaal aantal foute en dit produseer betekenlik minder foute in 10 van 22 fout kategories. Ons het ook not a dat twee van die uitgewerde stelsels nie enige fout vir 'n kategorie wat relevant was vir hierdie vertaling rigting voor die aankoms van NMT stelsels: Sjinese klassifiseerders.</abstract_af>
      <abstract_bs>Ova istraživanja predstavlja odličnu ljudsku procjenu kako bi usporedila transformator i ponovni pristup prevodu neuralne mašine (MT) na prijevoznom smjeru engleskog na kineskog jezika. Za taj cilj razvijamo taksonomiju greške u skladu s okvirom metrika za multidimenzionalne kvalitete (MQM) koji je prilagođen relevantnim fenomenima ovog prijevoznog smjera. Potom ćemo obaviti oznake greške koristeći ovu prilagođenu taksonomiju greške na izlazu rekonstruiranog stanja umjetnosti i sustava MT-a na transformatoru na podskupu testa WMT2019-e. U rezultativnoj annotaciji pokazuje da, u usporedbi sa najboljim rekonstruiranim sistemom, najbolji sustav transformera rezultira na 31% smanjenje ukupnog broja grešaka i proizvela je značajno manje grešaka u 10 od 22 kategorija grešaka. Također primjećujemo da dvije od procjenjenih sustava ne proizvode grešku za kategoriju koja je bila relevantna za ovu smjeru prevođenja prije dolaska NMT-ovih sustava: kineske klasifikatore.</abstract_bs>
      <abstract_cs>Tento výzkum představuje jemné lidské hodnocení pro porovnání transformátoru a recidivujících přístupů k neuronovému strojovému překladu (MT) ve směru překladu z angličtiny do čínštiny. Za tímto účelem vyvíjíme taxonomii chyb v souladu s rámcem Multidimenzionálních metrik kvality (MQM), která je přizpůsobena relevantním jevům tohoto směru překladu. Následně provedeme anotaci chyb pomocí této přizpůsobené taxonomie chyb na výstupu nejmodernějších rekurentních a transformátorových MT systémů na podmnožině testovací sady WMT2011. Výsledná anotace ukazuje, že ve srovnání s nejlepším opakovaným systémem dochází k 31% snížení celkového počtu chyb a výrazně méně chyb v deseti z 22. Dále poznamenáváme, že dva z hodnocených systémů nevyvolávají žádnou chybu pro kategorii, která byla relevantní pro tento směr překladu před nástupem NMT systémů: čínské klasifikátory.</abstract_cs>
      <abstract_et>Käesolevas uuringus esitatakse inimese hindamine, et võrrelda Transformeri ja korduvaid lähenemisviise neuromasintõlkele (MT) tõlke suunas inglise-hiina keelde. Selleks töötame välja veataksonoomia, mis vastab mitmemõõtmelistele kvaliteedimeetritele (MQM), mis on kohandatud vastavalt selle tõlkesuunaga seotud nähtustele. Seejärel teostame veaannotatsiooni, kasutades seda kohandatud veataksonoomiat uusimate korduvate ja transformaatoripõhiste MT-süsteemide väljundi kohta WMT22019 uudistestistiku alamhulgas. Tulemusest saadud märkused näitavad, et parima korduva süsteemiga võrreldes vähendab parim transformaatorsüsteem vigade koguarvu 31% ja tekitas märkimisväärselt vähem vigu kümnes veakategoorias 22-st. Samuti märgime, et kaks hinnatud süsteemi ei tekita viga kategooria puhul, mis oli asjakohane selle tõlkesuunaga enne NMT süsteemide tekkimist: Hiina klassifitseerijad.</abstract_et>
      <abstract_az>Bu araştırma İngilizə-Çincə çeviriş yönəlməsində transformer və yenidən təkrarlanan nöral maşına çevirilən yaxınlıqları ilə qarşılaşdırmaq üçün gözəl dənəli insan değerlendirməsini göstərir. Bu məqsədilə, biz bu çeviriş yönündə müəyyən edilən çox ölçülük kaliteli metrikləri (MQM) frameworklərinə uyğun xəta taxonomiya düzəldirik. Sonra WMT2019'nin xəbər s ınaması qurulduğu vaxtlarda müəyyən edilmiş xəta taxonomiya istifadəsində xəta bildiririk. Sonuçlarının nəticəsi göstərir ki, ən yaxşı təkrar sistemi ilə salıb, ən yaxşı Transformer sisteminin toplam hataların sayını 31%-dən azaldığını və 22 xəta kategoriyalarından 10-dan daha az xəta yaratdığını göstərir. Biz də bildiririk ki, NMT sistemlərinin gəlməsindən əvvəl bu çeviri yönəltməsi üçün olan bir kategoriya üçün heç bir xəta yaratmaz: Çin klasifikatçıları.</abstract_az>
      <abstract_bn>এই গবেষণা অনুবাদের দিকে ইংরেজী থেকে চীনের অনুবাদের তুলনায় ট্রান্সফার্নার এবং পুনরাবর্তন মেশিন অনুবাদের (এমটি) তুলনা করার জন্য একটি ভাল এই পর্যন্ত আমরা একটি ভুল ট্যাক্সোনোমি তৈরি করি বহুমাত্রিক মাত্রিক (এমকিউএম) ফ্রেমের সঙ্গে যা এই অনুবাদের দিকের প্রয়োজনীয় পরিস্থিতির কাছ তারপর আমরা উইএমটি২০১৯ এর সংবাদ পরীক্ষার সাবস্টেটে রাষ্ট্র-অফ-শিল্প- এবং ট্রান্সফ্রান্স ভিত্তিক এমটি সিস্টেম ব্যবহার করে এই স্বনির্বাচিত ত ত্র ফলাফলের বিস্তারিত বিষয়টি দেখাচ্ছে যে সেরা পুনরাবর্তনের সিস্টেমের তুলনায় সর্বোচ্চ ট্রান্সফ্রান্সফার্ম সিস্টেমের সংখ্যার ৩১% কমে যায় এবং  এছাড়াও আমরা লক্ষ্য করেছি যে এনএমটি সিস্টেমের প্রতিযোগিতার পূর্বে এই অনুবাদের দিকের জন্য কোন সমস্যা তৈরি করে না: চীনা বিভাগ।</abstract_bn>
      <abstract_ca>Aquesta investigació presenta una evaluació human a fina per comparar els enfocaments Transformer i recurrents a la traducció neuromàtica (MT), en la direcció de traducció anglès-xinès. A aquest efecte, desenvolupem una taxonomia d'errors conforme amb el marc multidimensional quality meterrics (MQM) adaptat als fenomens pertinents d'aquesta direcció de traducció. We then conduct an error annotation using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019's news test set.  La anotació resultant mostra que, comparat amb el millor sistema recurrent, el millor sistema Transformer resulta en una reducció del 31% del nombre total d'errors i va produir significativament menys errors en 10 de cada 22 categories d'errors. També observem que dos dels sistemes evaluats no produeixen cap error per a una categoria que era rellevant per aquesta direcció de traducció abans de l'aparició de sistemes NMT: classificadors xinesos.</abstract_ca>
      <abstract_fi>Tämä tutkimus esittelee hienorakeisen ihmisen arvioinnin muuntajan ja toistuvien lähestymistapojen vertailemiseksi neurokonekäännökseen (MT) käännössuunnassa englanti-kiina. Tätä varten kehitämme Multidimensional Quality Metrics (MQM) -viitekehyksen mukaisen virhetaksonomian, joka on räätälöity käännössuuntaan liittyviin ilmiöihin. Tämän jälkeen teemme virheilmoituksen käyttämällä tätä mukautettua virhetaksonomiaa uusimpien toistuvien ja muuntajapohjaisten MT-järjestelmien tuotokseen WMT2019:n uutistestisarjan osajoukkoon. Tuloksena saatu huomautus osoittaa, että paras muuntajajärjestelmä vähentää virheiden kokonaismäärää 31% verrattuna parhaaseen toistuvaan järjestelmään ja tuottaa huomattavasti vähemmän virheitä kymmenessä 22 virheluokasta. Huomautamme myös, että kaksi arvioitua järjestelmää ei tuota virhettä luokkaan, joka oli merkityksellinen tälle käännössuunnalle ennen NMT-järjestelmien tuloa: kiinalaiset luokittelijat.</abstract_fi>
      <abstract_jv>Wuraning iki trus menehi kelompok uwong sing nggawe geraraning nggawe Transformer karo suk karo perintah kanggo tarjamahan de perintah (MT), nganggep tarjamahan ingkang karo Cino. Mawe iki, awak dhéwé iso nggawe tasi kanggo eror sing mengko karo akeh Multidimensial Quality Metric (MqM) nggawe gerakno sing apik dadi kanggo ngerasakno sing dibutuhke tarjamahan iki. Awak dhéwé éntuk kesempatan kanggo nggawe eror tentang nggawe gerakan kanggo mulasai sistem sing perusahaan state-of-the-art s Perintah sing dipuangkat wong ne, nggerusahaan mên sistem sing gak bener, sistem Transformer sing paling dhéwé sing beraksi kut ntaangen error sing gak 31% mburu sing beraksi perusahaan bakal terusahaan error sing beraksi kanggo 10 sak kategori 22. Awak dhéwé ngerasakno karo sistem sing dipunangé gak bener kanggo kategori sing berarti kanggo tarjamahan iki sampek bantuan kanggo ngelarang sistem NMT: kelas Chinese</abstract_jv>
      <abstract_ha>Wannan fitina na bãyar da qiymatin mutum mai kyau-grafen kuma yana samfanar Transformer da yana da sauri zuwa fassarar maɓallin neural (MT), a kan shirin fassarar-zuwa-China. Haƙĩƙa, Munã buɗe wani taxenomi na kure da cikakken firam na Mumbanci Metrics (MQM) wanda ake amfani da zuwa wani abu na muhimman na shiryarwa wannan fassarar. Sa'an nan kuma Mu aiki wani shiri mai ɓarna da ke amfani da wannan taxenomi na ɓata wanda aka buɗa da shi a kan fitarwa na-state-of-the-art- and Transformer-based MT kan a ƙarƙashin jarraba na WMT2019. Ana nuna cewa, a sami da tsarin da aka sake mafi kyãwo na tsarin da aka sake koma, tsarin Transformer na ƙari da yawan ɓarna a 31% kuma ta sami ɓarna mai girma cikin 10 na kategori ɓata 22. Tuna gane cewa duk biyu na'urar ayuka da aka evaluce, bã su sami wani ɓarna wa wani category wanda ya kasance mai amfani da wa wannan shirin fassarar ta gaba ga matarwa na tsarin NMT: Shiryai na China.</abstract_ha>
      <abstract_sk>Ta raziskava predstavlja drobnozrnato človeško oceno za primerjavo transformatorskih in ponavljajočih se pristopov k nevronskemu strojnemu prevajanju (MT) v smeri prevajanja angleščine v kitajščino. V ta namen razvijamo taksonomijo napak, skladno z okvirom Multidimenzionalnih meril kakovosti (MQM), ki je prilagojena relevantnim pojavom te smeri prevajanja. Nato izvedemo opombo napak z uporabo te prilagojene taksonomije napak na izhodu najsodobnejših sistemov MT, ki temeljijo na ponavljajočih in transformatorjih, na podmnožici testiranja novic WMT22019. Dobljena opomba kaže, da najboljši sistem transformatorjev v primerjavi z najboljšim ponavljajočim se sistemom prinaša 31-odstotno zmanjšanje skupnega števila napak in bistveno manj napak v 10 od 22 kategorij napak. Ugotavljamo tudi, da dva od ocenjenih sistemov ne povzročata napake za kategorijo, ki je bila pomembna za to smer prevajanja pred nastopom sistemov NMT: kitajski klasifikatorji.</abstract_sk>
      <abstract_bo>This research presents a fine-grained human evaluation to compare the Transformer and recurrent approaches to neural machine translation (MT), on the translation direction English-to-Chinese. To this end, we develop an error taxonomy compliant with the Multidimensional Quality Metrics (MQM) framework that is customised to the relevant phenomena of this translation direction. We then conduct an error annotation using this customised error taxonomy on the output of state-of-the-art recurrent- and Transformer-based MT systems on a subset of WMT2019's news test set. དབྱེ་བ་ཡོད་པའི་གསལ་བཤད་ནི་ཡར་རྒྱས་འགྱུར་བའི་མ་ལག་དང་མཐུན ང་ཚོས་རིམ་ལྟ་བུའི་མ་ལག་གི་གཉིས་ཀྱིས་དབྱེ་རིམ་གྱི་གནས་ཚུལ་འདིའི་སྔོན་དུ་ཚོར</abstract_bo>
      <abstract_he>המחקר הזה מציג עריכה אנושית מעולה כדי לשוות את הגישויים המפורסמים ומחזורים לתרגום מכונות עצביות (MT), בכיוון התרגום אנגלי לסיני. למטרה זו, אנחנו מפתחים טקסונומיה של טעות שמתאימה למטריקה איכותית רבמימדית (MQM) המסגרת שמתאימה לתופעות הרלוונטיות של כיוון התרגום הזה. ואז אנו מבצעים ציון שגיאות בשימוש במקסנומיה זו של שגיאות מוגדרת על יציאה של מערכות MT המחוזרות ומבוססת על מערכת חדשות של WMT2019. ההערכה הנוצאה מראה כי, בהשוואה למערכת המחזרה הטובה ביותר, מערכת הטרנספורטר הטובה ביותר תובילה להפחית ב-31% של מספר הכולל של שגיאות והיא יצרה הרבה פחות שגיאות ב-10 מתוך 22 קטגוריות שגיאות. אנחנו גם שמים לב ששתי המערכות שהערכו לא יוצרות שום טעות לקטגוריה שהייתה רלוונטית לכיוון התרגום הזה לפני ההופעה של מערכות NMT: קלאספים סינים.</abstract_he>
      </paper>
    <paper id="15">
      <title>Correct Me If You Can : Learning from Error Corrections and Markings</title>
      <author><first>Julia</first><last>Kreutzer</last></author>
      <author><first>Nathaniel</first><last>Berger</last></author>
      <author><first>Stefan</first><last>Riezler</last></author>
      <pages>135–144</pages>
      <abstract>Sequence-to-sequence learning involves a trade-off between <a href="https://en.wikipedia.org/wiki/Signal_strength_in_telecommunications">signal strength</a> and annotation cost of training data. For example, machine translation data range from costly expert-generated translations that enable <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, to weak quality-judgment feedback that facilitate <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>. We present the first user study on annotation cost and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learnability</a> for the less popular annotation mode of error markings. We show that error markings for translations of TED talks from <a href="https://en.wikipedia.org/wiki/English_language">English</a> to <a href="https://en.wikipedia.org/wiki/German_language">German</a> allow precise credit assignment while requiring significantly less human effort than correcting / post-editing, and that error-marked data can be used successfully to fine-tune neural machine translation models.</abstract>
      <url hash="e7af16b9">2020.eamt-1.15</url>
      <bibkey>kreutzer-etal-2020-correct</bibkey>
      <pwccode url="https://github.com/StatNLP/mt-correct-mark-interface" additional="false">StatNLP/mt-correct-mark-interface</pwccode>
    </paper>
    <paper id="17">
      <title>Fine-Grained Error Analysis on English-to-Japanese Machine Translation in the Medical Domain<fixed-case>E</fixed-case>nglish-to-<fixed-case>J</fixed-case>apanese Machine Translation in the Medical Domain</title>
      <author><first>Takeshi</first><last>Hayakawa</last></author>
      <author><first>Yuki</first><last>Arase</last></author>
      <pages>155–164</pages>
      <abstract>We performed a detailed <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error analysis</a> in domain-specific neural machine translation (NMT) for the English and Japanese language pair with fine-grained manual annotation. Despite its importance for advancing NMT technologies, research on the performance of domain-specific NMT and non-European languages has been limited. In this study, we designed an error typology based on the error types that were typically generated by NMT systems and might cause significant impact in technical translations : <a href="https://en.wikipedia.org/wiki/Addition">Addition</a>, Omission, <a href="https://en.wikipedia.org/wiki/Mistranslation">Mistranslation</a>, <a href="https://en.wikipedia.org/wiki/Grammar">Grammar</a>, and <a href="https://en.wikipedia.org/wiki/Terminology">Terminology</a>. The <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error annotation</a> was targeted to the <a href="https://en.wikipedia.org/wiki/Medicine">medical domain</a> and was performed by experienced professional translators specialized in <a href="https://en.wikipedia.org/wiki/Medicine">medicine</a> under careful quality control. The <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> detected 4,912 errors on 2,480 sentences, and the frequency and distribution of errors were analyzed. We found that the major errors in NMT were <a href="https://en.wikipedia.org/wiki/Mistranslation">Mistranslation</a> and Terminology rather than <a href="https://en.wikipedia.org/wiki/Addition">Addition</a> and Omission, which have been reported as typical problems of NMT. Interestingly, more errors occurred in documents for professionals compared with those for the general public. The results of our annotation work will be published as a parallel corpus with error labels, which are expected to contribute to developing better NMT models, automatic evaluation metrics, and quality estimation models.</abstract>
      <url hash="9555cccb">2020.eamt-1.17</url>
      <bibkey>hayakawa-arase-2020-fine</bibkey>
    </paper>
    <paper id="21">
      <title>Modelling Source- and Target- Language Syntactic Information as Conditional Context in Interactive Neural Machine Translation</title>
      <author><first>Kamal Kumar</first><last>Gupta</last></author>
      <author><first>Rejwanul</first><last>Haque</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>195–204</pages>
      <abstract>In interactive machine translation (MT), human translators correct errors in automatic translations in collaboration with the MT systems, which is seen as an effective way to improve the productivity gain in <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. In this study, we model source-language syntactic constituency parse and target-language syntactic descriptions in the form of supertags as conditional context for interactive prediction in neural MT (NMT). We found that the supertags significantly improve productivity gain in <a href="https://en.wikipedia.org/wiki/Translation">translation</a> in interactive-predictive NMT (INMT), while syntactic parsing somewhat found to be effective in reducing human effort in <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. Furthermore, when we model this source- and target-language syntactic information together as the conditional context, both types complement each other and our fully syntax-informed INMT model statistically significantly reduces human efforts in a FrenchtoEnglish translation task, achieving 4.30 points absolute (corresponding to 9.18 % relative) improvement in terms of word prediction accuracy (WPA) and 4.84 points absolute (corresponding to 9.01 % relative) reduction in terms of word stroke ratio (WSR) over the baseline.</abstract>
      <url hash="4554ca33">2020.eamt-1.21</url>
      <bibkey>gupta-etal-2020-modelling</bibkey>
    </paper>
    <paper id="28">
      <title>Evaluating the usefulness of <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> for the Polish translators in the European Commission<fixed-case>P</fixed-case>olish translators in the <fixed-case>E</fixed-case>uropean Commission</title>
      <author><first>Karolina</first><last>Stefaniak</last></author>
      <pages>263–269</pages>
      <abstract>The mission of the Directorate General for Translation (DGT) is to provide high-quality translation to help the European Commission communicate with EU citizens. To this end <a href="https://en.wikipedia.org/wiki/Deutsche_Gesellschaft_für_Internationale_Zusammenarbeit">DGT</a> employs almost 2000 translators from all EU official languages. But while the demand for <a href="https://en.wikipedia.org/wiki/Translation">translation</a> has been continuously growing, following a global trend, the number of translators has decreased. To cope with the demand, DGT extensively uses a CAT environment encompassing <a href="https://en.wikipedia.org/wiki/Translation_memory">translation memories</a>, terminology databases and recently also <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. This paper examines the benefits and risks of using <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> to augment the productivity of inhouse DGT translators for the EnglishPolish language pair. Based on the analysis of a sample of NMTtranslated texts and on the observations of the working practices of Polish translators it is concluded that the possible productivity gain is still modest, while the risks to <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> are quite substantial.</abstract>
      <url hash="79c3e33d">2020.eamt-1.28</url>
      <bibkey>stefaniak-2020-evaluating</bibkey>
    </paper>
    <paper id="29">
      <title>Terminology-Constrained Neural Machine Translation at SAP<fixed-case>SAP</fixed-case></title>
      <author><first>Miriam</first><last>Exel</last></author>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Lauritz</first><last>Brandt</last></author>
      <author><first>Simona</first><last>Doneva</last></author>
      <pages>271–280</pages>
      <abstract>This paper examines approaches to bias a neural machine translation model to adhere to terminology constraints in an industrial setup. In particular, we investigate variations of the <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> by Dinu et al. (2019), which uses inline annotation of the target terms in the source segment plus source factor embeddings during <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training</a> and <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>, and compare them to constrained decoding. We describe the challenges with respect to terminology in our usage scenario at SAP and show how far the investigated methods can help to overcome them. We extend the original study to a new language pair and provide an in-depth evaluation including an <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error classification</a> and a <a href="https://en.wikipedia.org/wiki/Evaluation">human evaluation</a>.</abstract>
      <url hash="199ff6ff">2020.eamt-1.29</url>
      <bibkey>exel-etal-2020-terminology</bibkey>
    </paper>
    <paper id="31">
      <title>Bifixer and Bicleaner : two open-source tools to clean your parallel data</title>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <author><first>Jaume</first><last>Zaragoza-Bernabeu</last></author>
      <author><first>Marta</first><last>Bañón</last></author>
      <author><first>Sergio Ortiz</first><last>Rojas</last></author>
      <pages>291–298</pages>
      <abstract>This paper shows the utility of two open-source tools designed for parallel data cleaning : Bifixer and Bicleaner. Already used to clean highly noisy parallel content from crawled multilingual websites, we evaluate their performance in a different scenario : cleaning publicly available corpora commonly used to train machine translation systems. We choose four EnglishPortuguese corpora which we plan to use internally to compute <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> at a later stage. We clean the four <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a> using both <a href="https://en.wikipedia.org/wiki/Tool">tools</a>, which are described in detail, and analyse the effect of some of the cleaning steps on them. We then compare machine translation training times and <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> before and after cleaning these <a href="https://en.wikipedia.org/wiki/Text_corpus">corpora</a>, showing a positive impact particularly for the noisiest ones.</abstract>
      <url hash="c45fb6c6">2020.eamt-1.31</url>
      <bibkey>ramirez-sanchez-etal-2020-bifixer</bibkey>
      <pwccode url="https://github.com/bitextor/bicleaner" additional="false">bitextor/bicleaner</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimatrix">WikiMatrix</pwcdataset>
    </paper>
    <paper id="32">
      <title>An English-Swahili parallel corpus and its use for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> in the <a href="https://en.wikipedia.org/wiki/News_media">news domain</a><fixed-case>E</fixed-case>nglish-<fixed-case>S</fixed-case>wahili parallel corpus and its use for neural machine translation in the news domain</title>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last></author>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last></author>
      <author><first>Andrew</first><last>Secker</last></author>
      <author><first>Susie</first><last>Coleman</last></author>
      <author><first>Julie</first><last>Wall</last></author>
      <pages>299–308</pages>
      <abstract>This paper describes our approach to create a neural machine translation system to translate between <a href="https://en.wikipedia.org/wiki/English_language">English</a> and Swahili (both directions) in the news domain, as well as the process we followed to crawl the necessary parallel corpora from the Internet. We report the results of a pilot human evaluation performed by the news media organisations participating in the H2020 EU-funded project GoURMET.</abstract>
      <url hash="a78dd32d">2020.eamt-1.32</url>
      <bibkey>sanchez-martinez-etal-2020-english</bibkey>
    </paper>
    <paper id="34">
      <title>A User Study of the <a href="https://en.wikipedia.org/wiki/Incremental_learning">Incremental Learning</a> in NMT<fixed-case>NMT</fixed-case></title>
      <author><first>Miguel</first><last>Domingo</last></author>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Álvaro</first><last>Peris</last></author>
      <author><first>Alexandre</first><last>Helle</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <pages>319–328</pages>
      <abstract>In the translation industry, human experts usually supervise and post-edit machine translation hypotheses. Adaptive neural machine translation systems, able to incrementally update the underlying models under an online learning regime, have been proven to be useful to improve the efficiency of this <a href="https://en.wikipedia.org/wiki/Workflow">workflow</a>. However, this incremental adaptation is somewhat unstable, and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> may lead to undesirable side effects. One of them is the sporadic appearance of made-up words, as a byproduct of an erroneous application of subword segmentation techniques. In this work, we extend previous studies on on-the-fly adaptation of neural machine translation systems. We perform a <a href="https://en.wikipedia.org/wiki/User_study">user study</a> involving professional, experienced post-editors, delving deeper on the aforementioned problems. Results show that adaptive systems were able to learn how to generate the correct translation for task-specific terms, resulting in an improvement of the user’s productivity. We also observed a close similitude, in terms of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>, between made-up words and the words that were expected.</abstract>
      <url hash="bb6d3db2">2020.eamt-1.34</url>
      <bibkey>domingo-etal-2020-user</bibkey>
    </paper>
    <paper id="42">
      <title>How do LSPs compute MT discounts? Presenting a company’s pipeline and its use<fixed-case>LSP</fixed-case>s compute <fixed-case>MT</fixed-case> discounts? Presenting a company’s pipeline and its use</title>
      <author><first>Randy</first><last>Scansani</last></author>
      <author><first>Lamis</first><last>Mhedhbi</last></author>
      <pages>393–401</pages>
      <abstract>In this paper we present a <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> developed at Acolad to test a Machine Translation (MT) engine and compute the <a href="https://en.wikipedia.org/wiki/Discounting">discount</a> to be applied when its output is used in production. Our <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> includes three main steps where <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> and <a href="https://en.wikipedia.org/wiki/Productivity">productivity</a> are measured through automatic metrics, manual evaluation, and by keeping track of editing and temporal effort during a post-editing task. Thanks to this approach, it is possible to evaluate the output quality and compute an engine-specific discount. Our test pipeline tackles the complexity of transforming productivity measurements into discounts by comparing the outcome of each of the above-mentioned steps to an estimate of the average productivity of translation from scratch. The <a href="https://en.wikipedia.org/wiki/Discounting">discount</a> is obtained by subtracting the resulting coefficient from the per-word rate. After a description of the <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a>, the paper presents its application on four engines, discussing its results and showing that our method to estimate post-editing effort through manual evaluation seems to capture the actual productivity. The <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> relies heavily on the work of professional post-editors, with the aim of creating a mutually beneficial cooperation between users and developers.</abstract>
      <url hash="bfc11647">2020.eamt-1.42</url>
      <bibkey>scansani-mhedhbi-2020-lsps</bibkey>
    </paper>
    <paper id="45">
      <title>Comparing <a href="https://en.wikipedia.org/wiki/Post-editing">Post-editing</a> based on Four Editing Actions against Translating with an Auto-Complete Feature</title>
      <author><first>Félix Do</first><last>Carmo</last></author>
      <pages>421–430</pages>
      <abstract>This article describes the results of a workshop in which 50 translators tested two experimental translation interfaces, as part of a project which aimed at studying the details of editing work. In this work, <a href="https://en.wikipedia.org/wiki/Editing">editing</a> is defined as a selection of four actions : deleting, inserting, moving and replacing words. Four texts, machine-translated from English into <a href="https://en.wikipedia.org/wiki/European_Portuguese">European Portuguese</a>, were post-edited in four different sessions in which each translator swapped between texts and two work modes. One of the <a href="https://en.wikipedia.org/wiki/Mode_(user_interface)">work modes</a> involved a typical auto-complete feature, and the other was based on the four actions. The participants answered surveys before, during and after the workshop. A descriptive analysis of the answers to the surveys and of the logs recorded during the experiments was performed. The four editing actions mode is shown to be more intrusive, but to allow for more planned decisions : although they take more time in this mode, translators hesitate less and make fewer edits. The article shows the usefulness of the <a href="https://en.wikipedia.org/wiki/Methodology">approach</a> for research on the <a href="https://en.wikipedia.org/wiki/Editing">editing task</a>.</abstract>
      <url hash="1b512029">2020.eamt-1.45</url>
      <bibkey>carmo-2020-comparing</bibkey>
    </paper>
    <paper id="49">
      <title>Document-Level Machine Translation Evaluation Project : Methodology, Effort and Inter-Annotator Agreement</title>
      <author><first>Sheila</first><last>Castilho</last></author>
      <pages>455–456</pages>
      <abstract>Document-level (doc-level) human eval-uation of machine translation (MT) has raised interest in the community after a fewattempts have disproved claims of human parity (Toral et al., 2018 ; Laubli et al.,2018). However, little is known about bestpractices regarding doc-level human evalu-ation. The goal of this project is to identifywhich methodologies better cope with i)the current state-of-the-art (SOTA) humanmetrics, ii) a possible complexity when as-signing a single score to a text consisted of‘good’ and ‘bad’ sentences, iii) a possibletiredness bias in doc-level set-ups, and iv)the difference in inter-annotator agreement(IAA) between sentence and doc-level set-ups.</abstract>
      <url hash="8bd5f97e">2020.eamt-1.49</url>
      <bibkey>castilho-2020-document</bibkey>
    </paper>
    <paper id="51">
      <title>CEF Data Marketplace : Powering a Long-term Supply of Language Data<fixed-case>CEF</fixed-case> Data Marketplace: Powering a Long-term Supply of Language Data</title>
      <author><first>Amir</first><last>Kamran</last></author>
      <author><first>Dace</first><last>Dzeguze</last></author>
      <author><first>Jaap</first><last>van der Meer</last></author>
      <author><first>Milica</first><last>Panic</last></author>
      <author><first>Alessandro</first><last>Cattelan</last></author>
      <author><first>Daniele</first><last>Patrioli</last></author>
      <author><first>Luisa</first><last>Bentivogli</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>459–460</pages>
      <abstract>We describe the CEF Data Marketplace project, which focuses on the development of a trading platform of translation data for language professionals : translators, machine translation (MT) developers, language service providers (LSPs), translation buyers and government bodies. The CEF Data Marketplace platform will be designed and built to manage and trade data for all languages and domains. This project will open a continuous and longterm supply of <a href="https://en.wikipedia.org/wiki/Language_structure">language data</a> for MT and other machine learning applications.</abstract>
      <url hash="5d7cdf1a">2020.eamt-1.51</url>
      <bibkey>kamran-etal-2020-cef</bibkey>
    </paper>
    <paper id="59">
      <title>MICE : a middleware layer for MT<fixed-case>MICE</fixed-case>: a middleware layer for <fixed-case>MT</fixed-case></title>
      <author><first>Joachim</first><last>Van den Bogaert</last></author>
      <author><first>Tom</first><last>Vanallemeersch</last></author>
      <author><first>Heidi</first><last>Depraetere</last></author>
      <pages>475–476</pages>
      <abstract>The MICE project (2018-2020) will deliver a middleware layer for improving the output quality of the eTranslation system of EC’s Connecting Europe Facility through additional services, such as domain adaptation and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. It will also deliver a <a href="https://en.wikipedia.org/wiki/Web_portal">user portal</a>, allowing for <a href="https://en.wikipedia.org/wiki/Post-editing">human post-editing</a>.</abstract>
      <url hash="e078908c">2020.eamt-1.59</url>
      <bibkey>van-den-bogaert-etal-2020-mice</bibkey>
    </paper>
    <paper id="60">
      <title>Neural Translation for the European Union (NTEU) Project<fixed-case>E</fixed-case>uropean <fixed-case>U</fixed-case>nion (<fixed-case>NTEU</fixed-case>) Project</title>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Aleix</first><last>Cerdà-i-Cucó</last></author>
      <author><first>Hans</first><last>Degroote</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <author><first>Alejandro</first><last>Kohan</last></author>
      <author><first>Maite</first><last>Melero</last></author>
      <author><first>Tony</first><last>O’Dowd</last></author>
      <author><first>Sinéad</first><last>O’Gorman</last></author>
      <author><first>Mārcis</first><last>Pinnis</last></author>
      <author><first>Roberts</first><last>Rozis</last></author>
      <author><first>Riccardo</first><last>Superbo</last></author>
      <author><first>Artūrs</first><last>Vasiļevskis</last></author>
      <pages>477–478</pages>
      <abstract>The Neural Translation for the European Union (NTEU) project aims to build a neural engine farm with all European official language combinations for eTranslation, without the necessity to use a high-resourced language as a pivot. NTEU started in September 2019 and will run until August 2021.</abstract>
      <url hash="cb823ed0">2020.eamt-1.60</url>
      <bibkey>bie-etal-2020-neural</bibkey>
    </paper>
    <paper id="62">
      <title>OCR, Classification &amp; Machine Translation (OCCAM)<fixed-case>OCR</fixed-case>, Classification

&amp; Machine Translation (<fixed-case>OCCAM</fixed-case>)</title>
      <author><first>Joachim</first><last>Van den Bogaert</last></author>
      <author><first>Arne</first><last>Defauw</last></author>
      <author><first>Frederic</first><last>Everaert</last></author>
      <author><first>Koen</first><last>Van Winckel</last></author>
      <author><first>Alina</first><last>Kramchaninova</last></author>
      <author><first>Anna</first><last>Bardadym</last></author>
      <author><first>Tom</first><last>Vanallemeersch</last></author>
      <author><first>Pavel</first><last>Smrž</last></author>
      <author><first>Michal</first><last>Hradiš</last></author>
      <pages>481–482</pages>
      <abstract>The OCCAM project (Optical Character recognition, ClassificAtion &amp; Machine Translation) aims at integrating the CEF (Connecting Europe Facility) Automated Translation service with image classification, Translation Memories (TMs), Optical Character Recognition (OCR), and Machine Translation (MT). It will support the automated translation of scanned business documents (a document format that, currently, can not be processed by the CEF eTranslation service) and will also lead to a tool useful for the Digital Humanities domain.</abstract>
      <url hash="f3a2980e">2020.eamt-1.62</url>
      <bibkey>van-den-bogaert-etal-2020-ocr</bibkey>
    </paper>
    <paper id="64">
      <title>Assessing the Comprehensibility of Automatic Translations (ArisToCAT)<fixed-case>A</fixed-case>ris<fixed-case>T</fixed-case>o<fixed-case>CAT</fixed-case>)</title>
      <author><first>Lieve</first><last>Macken</last></author>
      <author><first>Margot</first><last>Fonteyne</last></author>
      <author><first>Arda</first><last>Tezcan</last></author>
      <author><first>Joke</first><last>Daems</last></author>
      <pages>485–486</pages>
      <abstract>The ArisToCAT project aims to assess the comprehensibility of ‘raw’ (unedited) MT output for readers who can only rely on the MT output. In this project description, we summarize the main results of the project and present future work.</abstract>
      <url hash="f231fd46">2020.eamt-1.64</url>
      <bibkey>macken-etal-2020-assessing</bibkey>
    </paper>
    <paper id="69">
      <title>MTrill project : <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> impact on language learning<fixed-case>MT</fixed-case>rill project: Machine Translation impact on language learning</title>
      <author><first>Natália</first><last>Resende</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>497–498</pages>
      <abstract>Over the last decades, massive research investments have been made in the development of machine translation (MT) systems (Gupta and Dhawan, 2019). This has brought about a paradigm shift in the performance of these language tools, leading to widespread use of popular MT systems (Gaspari and Hutchins, 2007). Although the first MT engines were used for gisting purposes, in recent years, there has been an increasing interest in using MT tools, especially the freely available online MT tools, for language teaching and learning (Clifford et al., 2013). The literature on MT and Computer Assisted Language Learning (CALL) shows that, over the years, MT systems have been facilitating <a href="https://en.wikipedia.org/wiki/Language_education">language teaching</a> and also <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learning</a> (Nin o, 2006). It has been shown that MT tools can increase awareness of <a href="https://en.wikipedia.org/wiki/Grammaticality">grammatical linguistic features</a> of a foreign language. Research also shows the positive role of MT systems in the development of writing skills in <a href="https://en.wikipedia.org/wiki/English_language">English</a> as well as in improving communication skills in English(Garcia and Pena, 2011). However, to date, the cognitive impact of MT on <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> and on the syntactic aspects of language processing has not yet been investigated and deserves further scrutiny. The MTril project aims at filling this gap in the literature by examining whether MT is contributing to a central aspect of <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> : the so-called <a href="https://en.wikipedia.org/wiki/Language_binding">language binding</a>, i.e., the ability to combine single words properly in a grammatical sentence (Heyselaar et al., 2017 ; Ferreira and Bock, 2006).</abstract>
      <url hash="3cc666fd">2020.eamt-1.69</url>
      <bibkey>resende-way-2020-mtrill</bibkey>
    </paper>
  </volume>
</collection>