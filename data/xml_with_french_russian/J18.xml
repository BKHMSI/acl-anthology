<?xml version='1.0' encoding='utf-8'?>
<collection id="J18">
  <volume id="1">
    <meta>
      <booktitle>Computational Linguistics, Volume 44, Issue 1 - <fixed-case>A</fixed-case>pril 2018</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>April</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2018-linguistics</bibkey>
    </frontmatter>
    <paper id="3">
      <title>A Notion of Semantic Coherence for Underspecified Semantic Representation</title>
      <author><first>Mehdi</first><last>Manshadi</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <author><first>James F.</first><last>Allen</last></author>
      <abstract>The general problem of finding satisfying solutions to constraint-based underspecified representations of quantifier scope is NP-complete. Existing frameworks, including Dominance Graphs, <a href="https://en.wikipedia.org/wiki/Minimal_recursion_semantics">Minimal Recursion Semantics</a>, and Hole Semantics, have struggled to balance expressivity and tractability in order to cover real natural language sentences with efficient algorithms. We address this trade-off with a general principle of <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence</a>, which requires that every variable introduced in the <a href="https://en.wikipedia.org/wiki/Domain_of_discourse">domain of discourse</a> must contribute to the overall <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of the sentence. We show that every underspecified representation meeting this criterion can be efficiently processed, and that our set of <a href="https://en.wikipedia.org/wiki/Representation_theory">representations</a> subsumes all previously identified tractable sets.</abstract>
      <pages>39–83</pages>
      <doi>10.1162/COLI_a_00307</doi>
      <url hash="2b8bd05e">J18-1003</url>
      <bibkey>manshadi-etal-2018-notion</bibkey>
    </paper>
    <paper id="4">
      <title>Cache Transition Systems for <a href="https://en.wikipedia.org/wiki/Graph_traversal">Graph Parsing</a></title>
      <author><first>Daniel</first><last>Gildea</last></author>
      <author><first>Giorgio</first><last>Satta</last></author>
      <author><first>Xiaochang</first><last>Peng</last></author>
      <abstract>Motivated by the task of <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>, we describe a transition system that generalizes standard transition-based dependency parsing techniques to generate a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a> rather than a <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree</a>. Our system includes a <a href="https://en.wikipedia.org/wiki/Cache_(computing)">cache</a> with fixed size m, and we characterize the relationship between the parameter m and the class of <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> that can be produced through the graph-theoretic concept of tree decomposition. We find empirically that small cache sizes cover a high percentage of sentences in existing semantic corpora.</abstract>
      <pages>85-118</pages>
      <doi>10.1162/COLI_a_00308</doi>
      <url hash="be0917d7">J18-1004</url>
      <bibkey>gildea-etal-2018-cache</bibkey>
    </paper>
    <paper id="5">
      <title>Weighted DAG Automata for Semantic Graphs<fixed-case>DAG</fixed-case> Automata for Semantic Graphs</title>
      <author><first>David</first><last>Chiang</last></author>
      <author><first>Frank</first><last>Drewes</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Giorgio</first><last>Satta</last></author>
      <abstract>Graphs have a variety of uses in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, particularly as representations of linguistic meaning. A deficit in this area of research is a formal framework for creating, combining, and using models involving graphs that parallels the frameworks of <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite automata</a> for <a href="https://en.wikipedia.org/wiki/String_(computer_science)">strings</a> and <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite tree automata</a> for <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">trees</a>. A possible starting point for such a framework is the formalism of directed acyclic graph (DAG) automata, defined by Kamimura and Slutzki and extended by Quernheim and Knight. In this article, we study the latter in depth, demonstrating several new results, including a practical recognition algorithm that can be used for <a href="https://en.wikipedia.org/wiki/Inference">inference</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning">learning</a> with <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> defined on DAG automata. We also propose an extension to <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> with unbounded node degree and show that our results carry over to the extended <a href="https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)">formalism</a>.</abstract>
      <pages>119-186</pages>
      <doi>10.1162/COLI_a_00309</doi>
      <url hash="25f7186d">J18-1005</url>
      <bibkey>chiang-etal-2018-weighted</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/amr-bank">AMR Bank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    </volume>
  <volume id="2">
    <meta>
      <booktitle>Computational Linguistics, Volume 44, Issue 2 - June 2018</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>June</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2018-linguistics-44</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Dependency Perspective on RST Discourse Parsing and Evaluation<fixed-case>RST</fixed-case> Discourse Parsing and Evaluation</title>
      <author><first>Mathieu</first><last>Morey</last></author>
      <author><first>Philippe</first><last>Muller</last></author>
      <author><first>Nicholas</first><last>Asher</last></author>
      <abstract>Computational text-level discourse analysis mostly happens within Rhetorical Structure Theory (RST), whose structures have classically been presented as constituency trees, and relies on data from the RST Discourse Treebank (RST-DT) ; as a result, the RST discourse parsing community has largely borrowed from the syntactic constituency parsing community. The standard evaluation procedure for RST discourse parsers is thus a simplified variant of PARSEVAL, and most RST discourse parsers use techniques that originated in syntactic constituency parsing. In this article, we isolate a number of conceptual and computational problems with the constituency hypothesis. We then examine the consequences, for the implementation and evaluation of RST discourse parsers, of adopting a dependency perspective on RST structures, a view advocated so far only by a few approaches to discourse parsing. While doing that, we show the importance of the notion of headedness of RST structures. We analyze RST discourse parsing as dependency parsing by adapting to RST a recent proposal in syntactic parsing that relies on head-ordered dependency trees, a representation isomorphic to headed constituency trees. We show how to convert the original trees from the RST corpus, RST-DT, and their binarized versions used by all existing RST parsers to head-ordered dependency trees. We also propose a way to convert existing simple dependency parser output to <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">constituent trees</a>. This allows us to evaluate and to compare approaches from both constituent-based and dependency-based perspectives in a unified framework, using constituency and dependency metrics. We thus propose an evaluation framework to compare extant approaches easily and uniformly, something the RST parsing community has lacked up to now. We can also compare parsers’ predictions to each other across frameworks. This allows us to characterize families of parsing strategies across the different frameworks, in particular with respect to the notion of <a href="https://en.wikipedia.org/wiki/Headedness">headedness</a>. Our experiments provide evidence for the conceptual similarities between dependency parsers and shift-reduce constituency parsers, and confirm that dependency parsing constitutes a viable approach to RST discourse parsing.</abstract>
      <pages>197–235</pages>
      <doi>10.1162/COLI_a_00314</doi>
      <url hash="23e320b3">J18-2001</url>
      <bibkey>morey-etal-2018-dependency</bibkey>
    </paper>
    <paper id="2">
      <title>Unrestricted Bridging Resolution</title>
      <author><first>Yufang</first><last>Hou</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <abstract>In contrast to identity anaphors, which indicate <a href="https://en.wikipedia.org/wiki/Coreference">coreference</a> between a noun phrase and its antecedent, bridging anaphors link to their antecedent(s) via lexico-semantic, frame, or encyclopedic relations. Bridging resolution involves recognizing bridging anaphors and finding links to antecedents. In contrast to most prior work, we tackle both <a href="https://en.wikipedia.org/wiki/Problem_solving">problems</a>. Our work also follows a more wide-ranging definition of bridging than most previous work and does not impose any restrictions on the type of bridging anaphora or relations between <a href="https://en.wikipedia.org/wiki/Anaphora_(linguistics)">anaphor</a> and antecedent. We create a corpus (ISNotes) annotated for information status (IS), bridging being one of the IS subcategories. The annotations reach high <a href="https://en.wikipedia.org/wiki/Reliability_(statistics)">reliability</a> for all categories and marginal reliability for the bridging subcategory. We use a two-stage statistical global inference method for bridging resolution. Given all mentions in a document, the first stage, bridging anaphora recognition, recognizes bridging anaphors as a subtask of learning fine-grained IS. We use a cascading collective classification method where (i) collective classification allows us to investigate relations among several mentions and autocorrelation among IS classes and (ii) cascaded classification allows us to tackle class imbalance, important for minority classes such as bridging. We show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> outperforms current methods both for <a href="https://en.wikipedia.org/wiki/Computer_vision">IS recognition</a> overall as well as for bridging, specifically. The second stage, bridging antecedent selection, finds the antecedents for all predicted bridging anaphors. We investigate the phenomenon of semantically or syntactically related bridging anaphors that share the same antecedent, a phenomenon we call sibling anaphors.</abstract>
      <pages>237–284</pages>
      <doi>10.1162/COLI_a_00315</doi>
      <url hash="7a778b3c">J18-2002</url>
      <bibkey>hou-etal-2018-unrestricted</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="3">
      <title>Spurious Ambiguity and Focalization</title>
      <author><first>Glyn</first><last>Morrill</last></author>
      <author><first>Oriol</first><last>Valentín</last></author>
      <abstract>Spurious ambiguity is the phenomenon whereby distinct derivations in <a href="https://en.wikipedia.org/wiki/Grammar">grammar</a> may assign the same structural reading, resulting in redundancy in the parse search space and inefficiency in <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>. Understanding the problem depends on identifying the essential <a href="https://en.wikipedia.org/wiki/Derivation_(differential_algebra)">mathematical structure of derivations</a>. This is trivial in the case of <a href="https://en.wikipedia.org/wiki/Context-free_grammar">context free grammar</a>, where the parse structures are <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">ordered trees</a> ; in the case of type logical categorial grammar, the parse structures are <a href="https://en.wikipedia.org/wiki/Proof_net">proof nets</a>. However, with respect to multiplicatives, intrinsic proof nets have not yet been given for displacement calculus, and <a href="https://en.wikipedia.org/wiki/Proof_net">proof nets</a> for additives, which have applications to <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">polymorphism</a>, are not easy to characterize. In this context we approach here multiplicative-additive spurious ambiguity by means of the proof-theoretic technique of focalization.</abstract>
      <pages>285–327</pages>
      <doi>10.1162/COLI_a_00316</doi>
      <url hash="02f0cd37">J18-2003</url>
      <bibkey>morrill-valentin-2018-spurious</bibkey>
    </paper>
    <paper id="4">
      <title>The Influence of Context on the Learning of Metrical Stress Systems Using <a href="https://en.wikipedia.org/wiki/Finite-state_machine">Finite-State Machines</a></title>
      <author><first>Cesko</first><last>Voeten</last></author>
      <author><first>Menno</first><last>van Zaanen</last></author>
      <abstract>Languages vary in the way stress is assigned to syllables within words. This article investigates the learnability of <a href="https://en.wikipedia.org/wiki/Stress_(linguistics)">stress systems</a> in a wide range of <a href="https://en.wikipedia.org/wiki/Language">languages</a>. The stress systems can be described using <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite-state automata</a> with symbols indicating levels of stress (primary, secondary, or no stress). Finite-state automata have been the focus of research in the area of <a href="https://en.wikipedia.org/wiki/Grammatical_inference">grammatical inference</a> for some time now. It has been shown that <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite-state machines</a> are learnable from examples using <a href="https://en.wikipedia.org/wiki/Finite-state_machine">state-merging</a>. One such approach, which aims to learn k-testable languages, has been applied to <a href="https://en.wikipedia.org/wiki/Stress_(linguistics)">stress systems</a> with some success. The family of k-testable languages has been shown to be efficiently learnable (in polynomial time). Here, we extend this approach to k, l-local languages by taking not only left context, but also right context, into account. We consider empirical results testing the performance of our learner using various amounts of context (corresponding to varying definitions of phonological locality). Our results show that our approach of learning stress patterns using <a href="https://en.wikipedia.org/wiki/State-merging">state-merging</a> is more reliant on left context than on right context. Additionally, some stress systems fail to be learned by our learner using either the left-context k-testable or the left-and-right-context k, l-local learning system. A more complex merging strategy, and hence <a href="https://en.wikipedia.org/wiki/Grammar">grammar representation</a>, is required for these <a href="https://en.wikipedia.org/wiki/Stress_(linguistics)">stress systems</a>.</abstract>
      <pages>329–348</pages>
      <doi>10.1162/COLI_a_00317</doi>
      <url hash="630b0499">J18-2004</url>
      <bibkey>voeten-van-zaanen-2018-influence</bibkey>
    </paper>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Computational Linguistics, Volume 44, Issue 3 - September 2018</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>September</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2018-linguistics-44-issue</bibkey>
    </frontmatter>
    <paper id="2">
      <title>A Structured Review of the Validity of BLEU<fixed-case>BLEU</fixed-case></title>
      <author><first>Ehud</first><last>Reiter</last></author>
      <abstract>The BLEU metric has been widely used in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> for over 15 years to evaluate <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP systems</a>, especially in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> and <a href="https://en.wikipedia.org/wiki/Natural-language_generation">natural language generation</a>. I present a structured review of the evidence on whether <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> is a valid evaluation techniquein other words, whether <a href="https://en.wikipedia.org/wiki/BLEU">BLEU scores</a> correlate with real-world utility and user-satisfaction of NLP systems ; this review covers 284 correlations reported in 34 papers. Overall, the evidence supports using BLEU for diagnostic evaluation of MT systems (which is what it was originally proposed for), but does not support using BLEU outside of MT, for evaluation of individual texts, or for scientific hypothesis testing.</abstract>
      <pages>393–401</pages>
      <doi>10.1162/coli_a_00322</doi>
      <url hash="91d6edf1">J18-3002</url>
      <bibkey>reiter-2018-structured</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="3">
      <title>Native Language Identification With Classifier Stacking and Ensembles</title>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Mark</first><last>Dras</last></author>
      <abstract>Ensemble methods using multiple <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifiers</a> have proven to be among the most successful approaches for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble architectures</a> such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on several large data sets, evaluated in both intra-corpus and cross-corpus modes.</abstract>
      <pages>403–446</pages>
      <doi>10.1162/coli_a_00323</doi>
      <url hash="86ee80bd">J18-3003</url>
      <bibkey>malmasi-dras-2018-native</bibkey>
    <title_fr>Identification de la langue maternelle avec empilage et ensembles de classificateurs</title_fr>
      <title_ar>تحديد اللغة الأصلية مع تصنيف التراص والمجموعات</title_ar>
      <title_es>Identificación del idioma nativo con apilamiento de clasificadores y conjuntos</title_es>
      <title_pt>Identificação de idioma nativo com empilhamento e conjuntos de classificadores</title_pt>
      <title_zh>以类器积成母语识</title_zh>
      <title_hi>क्लासिफायर स्टैकिंग और Ensembles के साथ मूल भाषा पहचान</title_hi>
      <title_ja>クラシファイアスタッキングとアンサンブルによるネイティブ言語の識別</title_ja>
      <title_ru>Идентификация родного языка с классификатором стекирования и ансамблей</title_ru>
      <title_ga>Aitheantas Teanga Dúchais Le Cruachta Aicmitheora agus Ensembles</title_ga>
      <title_ka>კლასიფიკატორის კონფიგურაცია და კონსმებით</title_ka>
      <title_hu>Az anyanyelv azonosítása a hirdető halmozásával és együtteseivel</title_hu>
      <title_el>Αναγνώριση μητρικής γλώσσας με τη στοίβα και τα σύνολα ταξινομητών</title_el>
      <title_it>Identificazione della lingua nativa con l'impilamento e gli insiemi degli annunci</title_it>
      <title_lt>Native Language Identification With Classifier Stacking and Ensembles</title_lt>
      <title_kk>Классификаторды қадамдастыру және қадамдастыру тілдер идентификациясы</title_kk>
      <title_ms>Pengenalan Bahasa asli Dengan Stacking Pengklasifikasi dan Ensembles</title_ms>
      <title_ml>സാധാരണ ഭാഷ തിരിച്ചറിയുക</title_ml>
      <title_mk>Идентификација на роден јазик</title_mk>
      <title_mt>Identifikazzjoni tal-Lingwa Nativa bi Stacking u Ensembles tal-Klassifikatur</title_mt>
      <title_mn>Түүнчлэн хэл тодорхойлогч хэлбэртэй</title_mn>
      <title_pl>Identyfikacja języka ojczystego z układaniem klasyfikacji i zespołami</title_pl>
      <title_ro>Identificarea limbii native cu stivuirea clasificatorului și ansamblurile</title_ro>
      <title_no>Native språk- identifisering med klassifiseringar- stappar og slått av</title_no>
      <title_sr>Identifikacija porodičnog jezika sa klasifikatorskim stavljanjem i uključivanjem</title_sr>
      <title_so>Aqoonsiga luqada hooyo ee la xiriira tababarka iyo waxqabadka</title_so>
      <title_sv>Native Language Identifiering med Classifier Stacking och Ensembles</title_sv>
      <title_si>ක්‍ලාසිෆාර් ස්ටැක් සහ සම්බන්ධය සමග ස්ථානය භාෂාව පරීක්ෂණය</title_si>
      <title_ta>Name</title_ta>
      <title_ur>کلاس سٹکینگ اور انزومبل کے ساتھ ملک کی زبان شناسایی</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Số tự động bản địa</title_vi>
      <title_bg>Идентификация на родния език с подреждане на класификатори и ансамбли</title_bg>
      <title_da>Native Language Identifikation med Classifier stabling og Ensembles</title_da>
      <title_nl>Native Language Identificatie met Classifier Stacking en Ensembles</title_nl>
      <title_hr>Identifikacija prirodnog jezika sa klasifikatorskim stavljanjem i uključivanjem</title_hr>
      <title_de>Native Language Identification mit Classifier Stacking und Ensembles</title_de>
      <title_fa>شناسایی زبان طبیعی با قطعه‌بندی و فصل‌بندی‌کننده‌ها</title_fa>
      <title_sw>Utambulisho wa lugha ya asili kwa Makosa</title_sw>
      <title_id>Native Language Identification With Classifier Stacking and Ensembles</title_id>
      <title_ko>분류기 중첩과 통합을 바탕으로 하는 모국어 식별</title_ko>
      <title_tr>Sınıfçylar we Girişmeler bilen ýerli diller Kimligi</title_tr>
      <title_sq>Identifikimi i gjuhës vendase me gjuhë klasifikuese dhe Ensembles</title_sq>
      <title_af>Name</title_af>
      <title_hy>Ծննդյան լեզվի հայտնաբերումը դասակարգչային հետևանքներով և հավասարումներով</title_hy>
      <title_am>ቋንቋ</title_am>
      <title_az>S캼n캼f칞캼 S톛tirl톛ri v톛 S톛tirl톛ri il톛 Nativ Dil Kimlik</title_az>
      <title_ca>Identificació del llenguatge natiu amb rastreig i ensembles classificadors</title_ca>
      <title_bn>ক্লাসিফায়ার স্ট্যাকিং এবং এনসেম্বেলের সাথে স্থানীয় ভাষা পরিচয়</title_bn>
      <title_bs>Identifikacija porodičnog jezika sa klasifikatorskim stavljanjem i uključivanjem</title_bs>
      <title_cs>Identifikace rodného jazyka s klasifikátorem Stacking a soubory</title_cs>
      <title_et>Emakeele identifitseerimine klassifikaatori virnastamise ja ansamblitega</title_et>
      <title_fi>Native Language Identification With Classifier Stacking ja Ensembles</title_fi>
      <title_jv>name-of-ssh-key</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Identifikacija maternega jezika s klasifikatorjem zlaganje in ansambeli</title_sk>
      <title_bo>སྔོན་འཛུགས་ཅན་གྱི་སྐད་རིགས་དམིགས་འཛུགས་ཀྱིས་བཅད་དང་མཚོན་རྟགས་ཀྱིས</title_bo>
      <title_he>זיהוי שפת מקומית עם עקבות מסווגים ואונסמלים</title_he>
      <abstract_ar>أثبتت طرق التجميع باستخدام المصنفات المتعددة أنها من بين أكثر الأساليب نجاحًا لمهمة تحديد اللغة الأصلية (NLI) ، وتحقيق الوضع الحالي للفن. ومع ذلك ، لا يزال يتعين إجراء فحص منهجي لطرق التجميع لـ NLI. بالإضافة إلى ذلك ، لم يتم تقييم معماريات المجموعات الأعمق مثل تكديس المصنف عن كثب. نقدم مجموعة من التجارب باستخدام ثلاثة نماذج قائمة على المجموعات ، ونختبر كل منها بتكوينات وخوارزميات متعددة. يتضمن ذلك تطبيقًا صارمًا لنماذج التصنيف التلوي لـ NLI ، وتحقيق أحدث النتائج على العديد من مجموعات البيانات الكبيرة ، والتي تم تقييمها في كل من أوضاع المجموعة الداخلية والمجموعة المشتركة.</abstract_ar>
      <abstract_pt>Métodos ensemble usando múltiplos classificadores provaram estar entre as abordagens mais bem sucedidas para a tarefa de Identificação de Língua Nativa (NLI), alcançando o estado da arte atual. No entanto, um exame sistemático de métodos de conjunto para NLI ainda não foi realizado. Além disso, arquiteturas de conjunto mais profundas, como empilhamento de classificadores, não foram avaliadas de perto. Apresentamos um conjunto de experimentos usando três modelos baseados em ensemble, testando cada um com várias configurações e algoritmos. Isso inclui uma aplicação rigorosa de modelos de meta-classificação para NLI, alcançando resultados de última geração em vários grandes conjuntos de dados, avaliados nos modos intra-corpus e cross-corpus.</abstract_pt>
      <abstract_es>Los métodos de conjunto que utilizan clasificadores múltiples han demostrado ser uno de los enfoques más exitosos para la tarea de Identificación de Lenguas Nativas (NLI), alcanzando el estado actual de la técnica. Sin embargo, aún no se ha llevado a cabo un examen sistemático de los métodos conjuntos para el NLI. Además, las arquitecturas de conjuntos más profundas, como el apilamiento de clasificadores, no se han evaluado de cerca. Presentamos un conjunto de experimentos que utilizan tres modelos basados en conjuntos, que prueban cada uno con múltiples configuraciones y algoritmos. Esto incluye una aplicación rigurosa de modelos de meta-clasificación para NLI, logrando resultados de vanguardia en varios conjuntos de datos de gran tamaño, evaluados tanto en modo intra-corpus como cross-corpus.</abstract_es>
      <abstract_fr>Les méthodes d'ensemble utilisant plusieurs classificateurs se sont révélées être parmi les approches les plus efficaces pour la tâche d'identification de la langue maternelle (NLI), atteignant ainsi l'état actuel de la technique. Cependant, un examen systématique des méthodes d'ensemble pour le NLI n'a pas encore été mené. De plus, les architectures d'ensemble plus profondes, telles que l'empilement de classificateurs, n'ont pas été évaluées de près Nous présentons un ensemble d'expériences utilisant trois modèles basés sur des ensembles, testant chacun avec de multiples configurations et algorithmes. Cela comprend une application rigoureuse de modèles de méta-classification pour l'INN, l'obtention de résultats de pointe sur plusieurs grands ensembles de données, évalués à la fois en modes intra-corpus et inter-corpus.</abstract_fr>
      <abstract_ja>複数の分類子を使用するアンサンブル方法は、ネイティブ言語識別（ ＮＬＩ ）のタスクのための最も成功したアプローチの一つであることが証明されており、現在の最先端を達成している。しかしながら、NLIのためのアンサンブル方法の体系的な検討はまだ行われていない。さらに、クラシファイヤスタッキングのようなより深いアンサンブルアーキテクチャは、綿密に評価されていない。私たちは、3つのアンサンブルベースのモデルを使用した実験のセットを提示し、それぞれが複数の構成とアルゴリズムでテストします。これには、NLIのメタ分類モデルの厳密な適用が含まれ、いくつかの大規模データセットで最先端の結果を達成し、コーパス内およびクロスコーパスモードの両方で評価されます。</abstract_ja>
      <abstract_zh>用数器之法成母语知(NLI)之最成,成于今技术水平。 然未有系统于NLI者。 此外更深层次集成架构(如类器堆叠)未得细评。 吾以三实验之,各以多方试之。 此严用NLI元分类模型,于数大集上最先进者,于语料库内与跨语料库式下评之。</abstract_zh>
      <abstract_hi>कई क्लासिफायरका उपयोग करने वाले कलाकारों की टुकड़ी के तरीके मूल भाषा पहचान (एनएलआई) के कार्य के लिए सबसे सफल दृष्टिकोणों में से एक साबित हुए हैं, जो कला की वर्तमान स्थिति को प्राप्त करते हैं। हालांकि, एनएलआई के लिए पहनावा विधियों की एक व्यवस्थित परीक्षा अभी तक आयोजित नहीं की गई है। इसके अतिरिक्त, क्लासिफायर स्टैकिंग जैसे गहरे पहनावे वाले आर्किटेक्चर का बारीकी से मूल्यांकन नहीं किया गया है। हम तीन पहनावा-आधारित मॉडल का उपयोग करके प्रयोगों का एक सेट प्रस्तुत करते हैं, प्रत्येक को कई कॉन्फ़िगरेशन और एल्गोरिदम के साथ परीक्षण करते हैं। इसमें एनएलआई के लिए मेटा-वर्गीकरण मॉडल का एक कठोर अनुप्रयोग शामिल है, जो कई बड़े डेटा सेटों पर अत्याधुनिक परिणाम प्राप्त करता है, जिसका मूल्यांकन इंट्रा-कॉर्पस और क्रॉस-कॉर्पस मोड दोनों में किया जाता है।</abstract_hi>
      <abstract_ru>Ансамблевые методы, использующие несколько классификаторов, оказались одними из наиболее успешных подходов к задаче идентификации родного языка (NLI), достигая современного уровня техники. Вместе с тем систематический анализ комплексных методов для НИЛ еще не проводился. Кроме того, более глубокие ансамблевые архитектуры, такие как стекирование классификаторов, не подвергались тщательной оценке. Мы представляем набор экспериментов с использованием трех моделей на основе ансамблей, каждая из которых тестируется с несколькими конфигурациями и алгоритмами. Это включает в себя строгое применение моделей мета-классификации для NLI, достижение самых современных результатов на нескольких больших наборах данных, оцениваемых как в внутрикорпусном, так и в межкорпусном режимах.</abstract_ru>
      <abstract_ga>Tá sé cruthaithe go bhfuil modhanna Ensemble ina n-úsáidtear aicmitheoirí iolracha ar cheann de na cineálacha cur chuige is rathúla maidir le tasc Aitheantas na dTeangacha Dúchais (NLI), ag baint amach an úrscothacht faoi láthair. Mar sin féin, tá scrúdú córasach fós le déanamh ar mhodhanna ensemble don LNÉ. Ina theannta sin, ní dhearnadh dianmheasúnú ar ailtireachtaí ensemble níos doimhne ar nós cruachta aicmitheora. Cuirimid sraith turgnamh i láthair ag baint úsáide as trí mhúnla bunaithe ar ensemble, ag tástáil gach ceann le cumraíochtaí agus halgartaim iolracha. Áiríonn sé seo cur i bhfeidhm dian ar shamhlacha meitea-aicmiúcháin do LNÉ, ag baint amach torthaí den scoth ar roinnt tacair mhóra sonraí, arna measúnú ar mhodhanna inchorpais agus traschorpais araon.</abstract_ga>
      <abstract_ka>მრავალ კლასიფიკაციების გამოყენება გამოყენებული მეტოვები დაკავშირებულია, რომ უფრო წარმატებულია მსოფლიო წარმატების მოწყობილობა, რომელიც მიმდინარე ენის იდენტიფიკაციის (N მაგრამ, NLI-ს სხვა სისტემატიკური შემოწმება უნდა იქნება. დამატებით, უფრო დიდი ანსტემბლის აქტიქტიქტურები, როგორც კლასიფიკაციური სტატიქტირება, არ იყო ძალიან განსაზღვრებული. ჩვენ გამოყენებთ ექსპერიმენტები სამი ანსტემბლის მოდელების გამოყენებით, ყოველთვის განრავლებული კონფიგურაციებით და ალგორიტებით გამოყენებით. ეს არის მეტა-კლასიფიკაციის მოდელების ძალიან სწორი პროგრამა, რომელიც NLI-სთვის მიიღება მრავალ დიდი მონაცემების შესახებ, რომელიც ინტერე-კორპუს და კრესიკორპუს რეჟიმის შესახებ.</abstract_ka>
      <abstract_el>Οι μέθοδοι συνόλων που χρησιμοποιούν πολλαπλούς ταξινομητές έχουν αποδειχθεί μεταξύ των πιο επιτυχημένων προσεγγίσεων για το έργο της ταυτοποίησης της μητρικής γλώσσας, επιτυγχάνοντας την τρέχουσα κατάσταση της τεχνολογίας. Ωστόσο, δεν έχει ακόμη διεξαχθεί συστηματική εξέταση των μεθόδων συνόλων για το NLI. Επιπλέον, οι βαθύτερες αρχιτεκτονικές συνόλων όπως η στοίβαξη ταξινομητών δεν έχουν αξιολογηθεί στενά. Παρουσιάζουμε ένα σύνολο πειραμάτων χρησιμοποιώντας τρία μοντέλα βασισμένα σε σύνολα, δοκιμάζοντας το καθένα με πολλαπλές διαμορφώσεις και αλγόριθμους. Αυτό περιλαμβάνει μια αυστηρή εφαρμογή μοντέλων μετα-ταξινόμησης για την επίτευξη αποτελεσμάτων τελευταίας τεχνολογίας σε αρκετά μεγάλα σύνολα δεδομένων, τα οποία αξιολογούνται τόσο σε ενδοσωμικούς όσο και σε διασταυρούμενους τρόπους.</abstract_el>
      <abstract_hu>A több osztályozót alkalmazó egyesített módszerek bizonyították, hogy az anyanyelv azonosítása (NLI) feladatának legsikeresebb megközelítései közé tartoznak, elérve a technika jelenlegi állását. Azonban az NLI együttes módszereinek szisztematikus vizsgálata még nem történt. Továbbá a mélyebb együttes architektúrákat, mint például az osztályozók halmozását nem értékelték alaposan. Kísérletek sorozatát mutatjuk be három együttes alapú modellel, mindegyiket több konfigurációval és algoritmussal teszteljük. Ez magában foglalja a metaosztályozási modellek szigorú alkalmazását az NLI esetében, amelyek korszerű eredményeket érnek el számos nagy adatkészleten, mind a korpuszon belüli, mind a korpuszon keresztüli módban értékelve.</abstract_hu>
      <abstract_lt>Įrodyta, kad vienas iš sėkmingiausių metodų, kaip atlikti gimtosios kalbos identifikavimo (NLI) užduotį, yra įvairūs klasifikatoriai, siekiant dabartinės pažangos. Tačiau dar nereikia sistemingai išnagrinėti NLI komplekso metodų. Be to, nebuvo atidžiai įvertintos gilesnės kompleksų architektūros, pavyzdžiui, klasifikatorių surinkimas. Pateikiame eksperimentų rinkinį naudojant tris komplektu pagrįstus modelius, kiekvieną bandydami įvairiomis konfigūracijomis ir algoritmais. Tai apima griežtą NLI metaklasifikavimo modelių taikymą, siekiant pažangiausių rezultatų keliuose dideliuose duomenų rinkiniuose, vertinamuose tiek korpuso, tiek tarpkorpuso būdais.</abstract_lt>
      <abstract_it>I metodi di assemblaggio che utilizzano più classificatori hanno dimostrato di essere tra gli approcci di maggior successo per il compito di identificazione della lingua nativa (NLI), raggiungendo lo stato attuale dell'arte. Tuttavia, un esame sistematico dei metodi di ensemble per NLI deve ancora essere condotto. Inoltre, le architetture di ensemble più profonde come l'accatastamento dei classificatori non sono state attentamente valutate. Presentiamo una serie di esperimenti utilizzando tre modelli basati su ensemble, testando ciascuno con configurazioni e algoritmi multipli. Ciò include una rigorosa applicazione di modelli di meta-classificazione per NLI, ottenendo risultati all'avanguardia su diversi set di dati di grandi dimensioni, valutati sia in modalità intra-corpus che cross-corpus.</abstract_it>
      <abstract_kk>Бірнеше классификаторларды қолдану әдістері Түпнұсқа тіл идентификациясының (NLI) тапсырмасының ең сәтті жағдайда болып көрсетілген. Бірнеше классификаторларды қолдану әдістері Бірақ NLI үшін жүйеге аспан әдістерін тексеру қажет болмады. Қосымша, классификациялық стектеу секілді архитектуралар жақын бағаламады. Біз бірнеше тәжірибелерді үш енсембле негіздеген үлгілерді қолдануға арналған, әрбірін бірнеше баптаулар мен алгоритмдермен сынақтауға арналған. Бұл NLI үшін мета-классификациялау үлгілерінің қатты қолданбаларын қолданып, оның бірнеше үлкен деректер жиындарының нәтижесін жеткізу үшін, интрокорпус және көпкорпус режімдерінде тең.</abstract_kk>
      <abstract_ml>സ്വാഭാവ ഭാഷ തിരിച്ചറിയുന്നതിനുള്ള ഏറ്റവും വിജയകരമായ വഴികളിലായിരിക്കുന്നു എന്‍ലിയുടെ ജോലിയുടെ (NLI) നിലവിലുള്ള സ്ഥിതിയില്‍  എന്നാലും NLI-ന്റെ സിസ്റ്റമിക്ക് രീതികളുടെ പരിശോധന നടത്തിയിട്ടില്ല. കൂടുതലായി, ക്ലാസ്ഫിഫയര്‍ സ്റ്റാക്കിങ്ങ് പോലുള്ള ആഴത്തിലുള്ള ആഴത്തിലുള്ള ആര്‍ക്കിട്ടറുകള്‍ അടുത്ത് വി മൂന്നു എണ്‍സ്പെല്‍ അടിസ്ഥാനത്തിലുള്ള മോഡലുകള്‍ ഉപയോഗിച്ച് ഒരു കൂട്ടം പരീക്ഷണങ്ങള്‍ ഞങ്ങള്‍ കൊണ്ടുവരുന്നു. ഓരോരുത ഇതില്‍ NLI-ന്റെ മേറ്റ-ക്ലാസ്ഫിക്ഷന്‍ മാതൃകങ്ങളുടെ പ്രയോഗത്തില്‍ ഒരു കഠിനമായ പ്രയോഗത്തിനുള്ള പ്രയോഗത്തിലുണ്ട്. കുറച്ചു വലിയ വിവരങ്ങളുടെ അവസ്ഥ നി</abstract_ml>
      <abstract_ms>Kaedah bergabung menggunakan pengklasifikasi berbilang telah terbukti menjadi salah satu pendekatan yang paling berjaya untuk tugas Identifikasi Bahasa asli (NLI), mencapai keadaan semasa. However, a systematic examination of ensemble methods for NLI has yet to be conducted.  Lagipun, arkitektur ensemble yang lebih dalam seperti penumpang klasifikasi belum diteliti dengan teliti. Kami memperkenalkan set eksperimen menggunakan tiga model berdasarkan ensemble, menguji masing-masing dengan berbilang konfigurasi dan algoritma. Ini termasuk aplikasi ketat bagi model klasifikasi meta untuk NLI, mencapai keputusan state-of-the-art pada beberapa set data yang besar, diteliti dalam modus intra-corpus dan cross-corpus.</abstract_ms>
      <abstract_no>Måtar som brukar fleire klassifikatorar har vist å vera mellom dei mest vellykke tilnærmingane for oppgåva av Native Language Identification (NLI), som gjer den gjeldande tilstanden til kunsten. Men eit systematisk eksaminering av ensemblemmetodar for NLI må enno gjerast. I tillegg er ikkje dypere ensemblerarkitekturar som klassifiserer stakk nærare evaluert. Vi presenterer eit sett eksperimenter med tre ensembelbaserte modeller, testar kvar med fleire oppsett og algoritmer. Dette inkluderer ein sterk program av metaklassifikasjonsmodular for NLI, som gjer tilstand til kunsten på fleire store datasett, evaluert i både intra-corpus og cross-corpus-modus.</abstract_no>
      <abstract_mk>Сембелните методи со користење на повеќе класификатори се докажаа дека се меѓу најуспешните пристапи за задачата на Идентификацијата на родниот јазик (NLI), постигнувајќи ја сегашната техничка состојба. Сепак, сé уште не е спроведено систематско испитување на ансемболните методи за НЛИ. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated.  Презентираме сет експерименти користејќи три модели базирани на ансамбл, тестирајќи ги секој со повеќе конфигурации и алгоритми. Ова вклучува регуларна апликација на метакласификациските модели за НЛИ, постигнувајќи најсовремени резултати на неколку големи податоци, оценети во интеркорпусни и кроскорпусни режими.</abstract_mk>
      <abstract_mt>Metodi uniformi li jużaw klassifikaturi multipli wrew li huma fost l-approċċi l-aktar ta’ suċċess għall-kompitu tal-Identifikazzjoni tal-Lingwi Nazzjonali (NLI), li jiksbu l-aħħar avvanz attwali. Madankollu, għad irid isir eżami sistematiku tal-metodi ta’ ġabra għall-NLI. Barra minn hekk, arkitetturi aktar profondi ta’ ensembles bħal stacking ta’ klassifikaturi ma ġewx evalwati mill-qrib. Aħna nippreżentaw sett ta’ esperimenti bl-użu ta’ tliet mudelli bbażati fuq l-ensemble, li kull wieħed jiġi ttestjat b’konfigurazzjonijiet u algoritmi multipli. Dan jinkludi applikazzjoni rigoruża ta’ mudelli ta’ meta-klassifikazzjoni għall-NLI, li jiksbu riżultati l-aktar avvanzati fuq diversi settijiet kbar ta’ dejta, evalwati kemm fil-modalitajiet intra-corpus kif ukoll cross-corpus.</abstract_mt>
      <abstract_ro>Metodele de ansamblare folosind clasificatori multipli s-au dovedit a fi printre cele mai de succes abordări pentru sarcina identificării limbii native (NLI), atingând stadiul actual al tehnologiei. Cu toate acestea, o examinare sistematică a metodelor ansamblului pentru NLI nu a fost încă efectuată. În plus, arhitecturile ansamblurilor mai profunde, cum ar fi stivuirea clasificatorului, nu au fost evaluate îndeaproape. Vă prezentăm un set de experimente folosind trei modele bazate pe ansamblu, testand fiecare cu mai multe configurații și algoritmi. Aceasta include o aplicare riguroasă a modelelor de meta-clasificare pentru NLI, obținând rezultate de ultimă generație pe mai multe seturi de date mari, evaluate atât în modul intra-corpus, cât și în modul cross-corpus.</abstract_ro>
      <abstract_mn>Ихэнх хэлбэрийг ашиглаж буй аргыг олон хэлбэрээр ашиглаж буй орнуудын хэлний идентификацийн (NLI) ажлын хамгийн амжилттай арга барилгын хооронд баталсан. Гэвч NLI-ийн загварын систематикийн шалгалт хийгдэхгүй байна. Үүнээс илүү гүн гүнзгий архитектуруудыг хэлбэрээр дүгнэхгүй. Бид хэдэн туршилтуудыг гурван энземблийн суурь загварыг ашиглаж, олон загвар, алгоритмыг шалгаж байна. Энэ нь NLI-ийн мета-классификацийн загваруудын хүчтэй хэрэглээ, олон том өгөгдлийн хэмжээний уламжлалт, интрокорпус болон cross-corpus хэлбэрээр дүгнэгдсэн олон том өгөгдлийн хэмжээний үр дүнг хүртэл байдаг.</abstract_mn>
      <abstract_sr>Među najuspešnijim pristupima za zadatak identifikacije porodičnog jezika (NLI), ostvarili su metode uključujući više klasifikatora. Međutim, sistematsko ispitivanje metoda ensemble za NLI još uvek se ne smije provesti. Osim toga, nisu bliže procenili dublje arhitekture kao što je klasifikovanje stakla. Predstavljamo niz eksperimenata koristeći tri modela na osnovu ensembla, testirajući svakog sa višestrukim konfiguracijama i algoritmima. To uključuje tešku primjenu metaklasifikacijskih modela za NLI, ostvarivši rezultate umetnosti na nekoliko velikih seta podataka, procijenjenih i na intra-korpusu i preko korpusa.</abstract_sr>
      <abstract_so>Dhaqdooyinka ku haboon isticmaalka fasaxyada kala duduwan waxay caddeysaa inay ka mid tahay mid ka mid ah qaabab liibaansan ee shaqada aqoonsiga luqada asalka (NLI), si uu u helo xaaladda farshaxanka. Si kastaba ha ahaatee waxaa weli la sameeyaa baaritaanka nidaamka ah ee NLI. Sidoo kale waxaa kaloo lagu qiimeynayaa dhismaha aad u dheer, tusaale ahaan xarunta fasaxa laguma baahan karo. Waxaynu soo bandhignaa jirrabo badan oo ku isticmaalaya saddex tusaale, mid walbana waxaan ku imtixaamaynaa koonfureed kala duduwan iyo algorithm. Taas waxaa ku jira dalbasho si adag ah oo sameynta qaababka qoraalka meta-fasaxa ee NLI, oo ku sameynaya arimaha farshaxanka oo ku qoran sawirada farshaxanka badan, oo lagu qiimeeyay labada midibood oo interna-corpus iyo korpus.</abstract_so>
      <abstract_pl>Metody zespołowe wykorzystujące wiele klasyfikatorów okazały się jednym z najbardziej udanych podejść do zadania identyfikacji języka ojczystego (NLI), osiągając aktualny stan techniki. Jednak systematyczne badanie metod zespołowych dla NLI nie zostało jeszcze przeprowadzone. Ponadto głębsze architektury zespołów, takie jak układanie klasyfikatorów, nie zostały dokładnie ocenione. Przedstawiamy zestaw eksperymentów z wykorzystaniem trzech modeli opartych na zespole, testujących każdy z wieloma konfiguracjami i algorytmami. Obejmuje to rygorystyczne stosowanie modeli metaklasyfikacji dla NLI, uzyskanie najnowocześniejszych wyników na kilku dużych zbiorach danych, ocenianych zarówno w trybie wewnątrz korpusu, jak i między korpusem.</abstract_pl>
      <abstract_sv>Ensemble metoder som använder flera klassificerare har visat sig vara bland de mest framgångsrika tillvägagångssätten för uppgiften Native Language Identification (NLI), vilket uppnår den nuvarande tekniken. En systematisk undersökning av ensemblemetoder för NLI har dock ännu inte genomförts. Dessutom har djupare ensemblearkitekturer såsom klassificeringssamling inte utvärderats noggrant. Vi presenterar en uppsättning experiment med hjälp av tre ensemblebaserade modeller, som testar var och en med flera konfigurationer och algoritmer. Detta inkluderar en rigorös tillämpning av metaklassifikationsmodeller för NLI, vilket ger toppmoderna resultat på flera stora datamängder, utvärderade i både intra-corpus och cross-corpus lägen.</abstract_sv>
      <abstract_si>භාෂාවික භාෂාවිතය (NLI) වලින් භාෂාවිත විශ්වාස කරන විදියට සාක්ෂිත වෙලා තියෙන්නේ නැති භාෂාව පරික්ෂාවිත වැ නමුත්, NLI වෙනුවෙන් ඇන්ස්ම්බුල් විදියට පරීක්ෂණයක් තාමත් කරන්න ඕනේ. තවත්, ගොඩක් ගොඩක් ඇන්සෙම්බල් ස්ටැකින්ග් වගේ ස්ටැකින්ග් වගේ විශ්වාස කරලා නැහැ. අපි පරීක්ෂණයක් පෙන්වන්නේ සංවිධානය තුනක් පරීක්ෂණයක්, සංවිධානය තුනක් පරීක්ෂණය සහ ඇල්ගෝරිතම් ව මේකෙන් NLI වෙනුවෙන් මෙටා-විශේෂණ මොඩේල්ස් ගැන ශ්‍රේෂිත වැඩසටහන් සම්බන්ධයක් තියෙනවා, ලොකු දත්ත සටහන් වලින් විශේෂ විශේෂ</abstract_si>
      <abstract_ta>பல வகுப்பாளர் எனினும், NLI க்கான முறைமைகளை ஒரு அமைப்பில் பரிசோதிப்பு இன்னும் செயல்படுத்த வேண்டியிருக்கிறது. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated.  நாம் மூன்று முறையான மாதிரிகளை பயன்படுத்தி ஒரு சில சோதனைகளை காண்பிக்கிறோம், ஒவ்வொரு முறையான வடிவமைப்புகளையும Name</abstract_ta>
      <abstract_ur>بہت سی کلاسیفوں کے مطابق مطابق مطابق مطابق مطابق مطابق ملتی زبان شناسایی (NLI) کے کام کے زیادہ موفق مطابق موجود ہونے کے لئے ثابت کئے گئے ہیں۔ However, a system examination of ensemble methods for NLI has not yet been conducted. اور اضافہ، عمیق انسبیل معماری جیسے کلاسپیر سٹک کینگ کے مطابق زیادہ مطابق نہیں کی گئی ہے. ہم ایک مجموعہ آزمائش کے ساتھ تین انسمبل بنیادی موڈل کے مطابق پیش کرتے ہیں، ہر ایک کو بہت سی سازور اور الگوریتم کے ساتھ آزمائش کرتے ہیں. اس میں NLI کے لئے مٹا-کلاسی موڈل کی ایک سخت کاربری ہے، بہت سے بڑے ڈیٹ سٹ کے موجود پر موجود ہوتے ہیں، جو ان کے اندر کورپوس اور کروس کورپوس موڈوں میں ارزش کیا گیا ہے.</abstract_ur>
      <abstract_uz>Name Lekin, NLI uchun bunday foydalanuvchi tizim tizimini tekshirish kerak. Qo'shimcha, klassifiser stabilish kabi eng yuqori maktablarni yaxshi qiymatmaydi. Biz uchta ensembli modellar bilan bir necha moslamalar va algoritlar bilan imtiyozmaymiz. Name</abstract_uz>
      <abstract_vi>Những phương pháp chắc chắn dùng nhiều loại phân loại đã được chứng minh là một trong những phương pháp thành công nhất cho nhiệm vụ Xác nhận Ngôn ngữ Native (NLl), đạt được trạng thái hiện đại của nghệ thuật. Tuy nhiên, chưa có một cuộc kiểm tra hệ thống các phương pháp hoà hợp với RNL. Thêm vào đó, kiến trúc kết hợp sâu hơn như kiểu xếp phân loại chưa được đánh giá kỹ. Chúng tôi cung cấp một loạt thí nghiệm, sử dụng ba mô hình kết hợp, thử nghiệm với nhiều cấu hình và thuật toán. Tính năng này bao gồm một ứng dụng cẩn thận các mô hình phân loại meta-classification cho Njala, cung cấp kết quả hiện đại trên nhiều tập tin lớn, được đánh giá cả trong nội tạng và trong các phương pháp kinh tế khác.</abstract_vi>
      <abstract_bg>Ансамбулните методи, използващи множество класификатори, се оказаха сред най-успешните подходи за задачата за идентификация на родния език (НЛИ), постигайки настоящото състояние на техниката. Все още предстои систематично изследване на ансамбълните методи за НЛИ. Освен това, по-дълбоките ансамбълни архитектури като подреждане на класификатори не са оценени отблизо. Представяме набор от експерименти, използващи три ансамбълно базирани модела, тестващи всеки с множество конфигурации и алгоритми. Това включва стриктно прилагане на мета-класификационни модели за НЛИ, постигане на най-съвременни резултати върху няколко големи набора от данни, оценени както в режим вътрекорпус, така и в режим кръстосан корпус.</abstract_bg>
      <abstract_nl>Ensemblemethodes met behulp van meerdere classificatoren hebben bewezen een van de meest succesvolle benaderingen te zijn voor de taak van Native Language Identification (NLI), waarmee de huidige stand van de techniek bereikt wordt. Een systematisch onderzoek van ensemblemethoden voor NLI moet echter nog worden uitgevoerd. Bovendien zijn diepere ensemblearchitecturen zoals classificator stacking niet nauwkeurig geëvalueerd. We presenteren een reeks experimenten met behulp van drie ensemble-gebaseerde modellen, die elk testen met meerdere configuraties en algoritmes. Dit omvat een rigoureuze toepassing van metaclassificatiemodellen voor NLI, het bereiken van state-of-the-art resultaten op verschillende grote datasets, geëvalueerd in zowel intra-corpus als cross-corpus modi.</abstract_nl>
      <abstract_de>Ensemble-Methoden mit mehreren Klassifikatoren haben sich als einer der erfolgreichsten Ansätze für die Aufgabe der Native Language Identification (NLI) erwiesen und den aktuellen Stand der Technik erreicht. Eine systematische Auseinandersetzung mit Ensemblemethoden für NLI steht jedoch noch aus. Darüber hinaus wurden tiefere Ensemblearchitekturen wie Klassifikator Stacking nicht genau untersucht. Wir präsentieren eine Reihe von Experimenten mit drei ensemblebasierten Modellen, die jeweils mit mehreren Konfigurationen und Algorithmen getestet werden. Dies beinhaltet eine rigorose Anwendung von Meta-Klassifikationsmodellen für NLI, um State-of-the-Art Ergebnisse auf mehreren großen Datensätzen zu erzielen, die sowohl im intrakorpus- als auch korpusübergreifenden Modus ausgewertet werden.</abstract_de>
      <abstract_hr>Proizvodnja metoda koristeći višestruke klasifikatore pokazala se da su među najuspješnijim pristupima za zadatak identifikacije domaćih jezika (NLI), ostvarivanje trenutnog stanja umjetnosti. Međutim, sistematsko ispitivanje metoda ensemble za NLI još se ne smije provesti. Osim toga, nisu bliže procjenjivane dublje arhitekture za ensemble poput klasifikacije. Predstavljamo niz eksperimenata koristeći tri modela na osnovu ensembla, testirajući svakog sa višestrukim konfiguracijama i algoritmima. To uključuje tešku primjenu metaklasifikacijskih modela za NLI-a, ostvarivanje rezultata umjetnosti na nekoliko velikih kompeta podataka, procijenjenih kako u intra-korpusu, tako i kroz korpus.</abstract_hr>
      <abstract_da>Ensemble metoder ved hjælp af flere klassificeringer har vist sig at være blandt de mest vellykkede tilgange til opgaven med Native Language Identification (NLI), der opnår den aktuelle state of te art. Der er dog endnu ikke gennemført en systematisk undersøgelse af ensemblemetoder for NLI. Derudover er dybere ensemble arkitekturer såsom klassificering stabling ikke blevet nøje evalueret. Vi præsenterer et sæt eksperimenter ved hjælp af tre ensemble-baserede modeller, der tester hver med flere konfigurationer og algoritmer. Dette omfatter en streng anvendelse af metaklassifikationsmodeller for NLI, der opnår state-of-the-art resultater på flere store datasæt, evalueret i både intra-corpus og cross-corpus mode.</abstract_da>
      <abstract_ko>여러 분류기를 사용하는 통합 방법은 가장 성공적인 모국어 식별(NLI) 방법 중 하나로 현재의 기술 수준에 이르렀다는 것이 증명되었다.그러나 NLI의 통합 방법은 아직 시스템 검사를 하지 않았습니다.분류기 중첩 등 더 깊은 집적 구조에 대한 세밀한 평가도 이뤄지지 않았다.우리는 세 개의 집적 모델을 바탕으로 한 그룹의 실험을 실시했고 다양한 설정과 알고리즘을 사용하여 모든 모델을 테스트했다.이는 NLI 메타데이터 분류 모델의 엄격한 응용을 포함하여 여러 개의 대형 데이터 집합에서 가장 선진적인 결과를 실현하고 원료 라이브러리 내와 크로스 원료 라이브러리 모델에서 평가한다.</abstract_ko>
      <abstract_fa>روش‌هایی که با استفاده از چند تنظیم‌کننده‌ها ثابت شده‌اند در میان بهترین روش‌هایی موفقیت برای کار شناسایی زبان‌های طبیعی (NLI) باشند، به رسیدن وضعیت فعلی هنر ثابت شده‌اند. با این حال، هنوز یک تحقیق سیستماتی از روش‌هایی که برای NLI انتخاب می‌کنند باید انجام شود. به اضافه، معماری‌های عمیق‌تری مثل ترکیب‌های مختلف نزدیک ارزیابی نشده است. ما یک مجموعه آزمایش را با استفاده از سه مدل بنیاد اسمبل نشان می دهیم، هر کدام را با پیکربندی‌های متعدد و الگوریتم آزمایش می‌کنیم. این شامل یک کاربرد سخت از مدل‌های مختصات متا برای NLI است، تا نتیجه‌های وضعیت هنری بر مجموعه‌های داده‌های بزرگ برسد، در حالی که در حالی‌های داخل کورپوس و کروکورپوس ارزیابی می‌شود.</abstract_fa>
      <abstract_sw>Utawala wa kutosha kwa kutumia wataalamu kadhaa wamethibitisha kuwa ni miongoni mwa hatua za mafanikio zaidi kwa ajili ya kazi ya utambulisho wa lugha za asili (NLI), ili kufikia hali ya sasa ya sanaa. Hata hivyo, uchunguzi wa mfumo wa njia za ndani za NLI bado haujafanya. Zaidi ya hayo, majengo ya ndani kama vile vifaa vya kutangaza vizuri havijapatikana kwa karibu. Tunaonyesha majaribio mengi kwa kutumia mifano mitatu yenye msingi, tunajaribu kila mmoja kwa miundombi kadhaa na algorithi. Hii inajumuisha matumizi makubwa ya mifano ya usambazaji wa meta kwa ajili ya NLI, kutekeleza matokeo ya hali ya sanaa kwenye seti mbalimbali za data, inayothibitishwa katika njia za ndani na kupitia korpus.</abstract_sw>
      <abstract_id>Metode Ensemble menggunakan banyak klasifikasi telah terbukti menjadi salah satu pendekatan yang paling sukses untuk tugas Identifikasi Bahasa asli (NLI), mencapai keadaan sekarang. Namun, pemeriksaan sistematis dari metode ensemble untuk NLI belum dilakukan. Selain itu, arsitektur ensemble yang lebih dalam seperti stacking klasifikasi belum diteliti secara dekat. Kami mempersembahkan set eksperimen menggunakan tiga model berdasarkan ensemble, menguji masing-masing dengan berbagai konfigurasi dan algoritma. Ini termasuk aplikasi ketat dari model meta-klasifikasi untuk NLI, mencapai hasil terbaik pada beberapa set data besar, diteliti dalam modus intra-corpus dan cross-corpus.</abstract_id>
      <abstract_tr>Birnäçe klassifikatçi ullanýan yöntemler Native Diller Kimligi (NLI) täblisaň iň üstünlikli ýagdaýlaryň arasynda tassyklanýar. Ýöne, NLI üçin sistematik bir syýasy çözümler barlamaly. Diňe, klasifikatçy stacking ýaly daňky arhitektarlar deňlenmedi. Biz üç ensemble tabanly nusgalary ulanýan bir topar deneyleri görkeýäris, her biri birnäçe yapılandyrmalar we algoritmalar bilen synanyşýarys. Bu NLI üçin meta</abstract_tr>
      <abstract_af>Ensembleerde metodes gebruik veelvuldige klassifiseerders het bevestig om onder die mees suksesvolle toegang te wees vir die taak van Natiewe Taal Identifikasie (NLI), tot die huidige toestand van die kuns te bereik. Maar 'n sistematiese ondersoek van ensemblemmetode vir NLI moet nog gedoen word. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. Ons stel 'n stel eksperimente met drie ensemble-gebaseerde modele te gebruik, te testeer elkeen met veelvuldige konfigurasies en algoritme. Hierdie insluit 'n rigte toepassing van metaklassifikasie modele vir NLI, die staat-van-kuns-resultate van verskeie groot data stelle wat in intra-corpus en cross-corpus moduse evalueer word.</abstract_af>
      <abstract_hy>Բազմաթիվ դասակարգում օգտագործվող համակարգչային մեթոդները ապացուցել են, որ ամենահաջողակ մոտեցումները են եղել բնիկ լեզվի հայտնաբերման (ՆԼԻ) խնդրի համար, հասնելով ներկայիս տեխնոլոգիայի կարգավիճակը: Այնուամենայնիվ, ՆԼԻ-ի համար համակարգչային մեթոդների սիստեմատիկ ուսումնասիրությունը դեռևս պետք է կատարվի: Ավելին, ավելի խորը համակարգչային ճարտարապետությունները, ինչպիսիք են դասակարգչային կառուցվածքները, մոտավորապես չեն գնահատվել: Մենք ներկայացնում ենք մի շարք փորձարկումներ, որոնք օգտագործում են երեք համակարգչային մոդել, յուրաքանչյուրը փորձարկում է բազմաթիվ կառուցվածքներով և ալգորիթմներով: Սա ներառում է ՆԼԵ-ի մետադասակարգման մոդելների խիստ կիրառումը, որպեսզի ստանանք ամենահետագա արդյունքներ մի քանի մեծ տվյալների համակարգերի վրա, որոնք գնահատվում են նաև ինտեր-կորպոս, նաև միջկորպոս մոդելներում:</abstract_hy>
      <abstract_am>የአብዛዊ ቋንቋ ማውቀት (NLI) ስራ ለማግኘት የአሁኑን አርእስት ሁኔታ እንዲደርስ በመጠቀም የሚችል ሥርዓቶች በሁለት ክፍሎች የሚጠቅሙ ሥርዓቶች ናቸው፡፡ ነገር ግን የNLI ሥርዓት የስርዓት ፈተና ሳይፈጸም ነው፡፡ በተጨማሪም፣ እንደተጨማሪው ግንኙነት ግንኙነት በአቅራቢያ መዝገብ ግንኙነት በአቅራቢያ ላይ አልተመለከቱም፡፡ በሦስት ምሳሌ በሚያሳየው ምሳሌዎችን እናስፈትናለን፣ እያንዳንዳቸውም በብዙ ምርጫዎች እና አሌጎሪትምን እናሞክራለን፡፡ ይህ የኢንሊ መተላለፊያ ዓይነቶች የ-የ-art ፍሬዎችን በብዙ ትልቅ ዳታዎች ላይ ለማግኘት የሀብት ክፍል እና በክሮፕስ ዓይነቶች ውስጥ በተመሳሳይ የክፍለ ሥርዓት አግኝቷል፡፡</abstract_am>
      <abstract_sq>Metodat e përbashkëta që përdorin klasifikuesit e shumëfishtë kanë provuar të jenë midis metodave më të suksesshme për detyrën e Identifikimit të Gjuhave Kombëtare (NLI), duke arritur gjendjen aktuale të artit. Megjithatë, ende nuk duhet kryer një shqyrtim sistematik të metodave të grupit për NLI. Përveç kësaj, arkitektura më të thella të ansamblit të tilla si stacking klasifikues nuk janë vlerësuar nga afër. Ne paraqesim një sërë eksperimentesh duke përdorur tre modele bazuar në ansamble, duke testuar secilin me konfigurime të shumta dhe algoritme. Kjo përfshin një aplikim rigoroz të modeleve të meta-klasifikimit për NLI, duke arritur rezultate më të larta në disa grupe të dhënash të mëdha, të vlerësuara si në modalitetet brenda korpusit ashtu dhe ndër-korpusit.</abstract_sq>
      <abstract_az>Birçoxlu klasifikatçıları istifadə etmək məqsədillərinin NLI vəzifəsi üçün ən müvəffəqiyyətli tərzlərin arasında olduğunu göstərdi. Ancaq NLI üçün ensemble metodların sistematik sınaması hələ də edilməli. Daha da, klassifikat stacking kimi daha derin ensemble arhitektarları yaxınlaşdırılmamışdır. Biz üç ensembli modelləri istifadə edirik, hər birini çoxlu konfigurasiya və algoritmi ilə imtahana çəkirik. Bu NLI üçün meta-klasifikasiya modellərinin a ğır bir uyğulamasını daxil edir, bir neçə böyük məlumat qurğuları ilə müəyyən edilmiş, intra-corpus və cross-corpus modularda değerlənir.</abstract_az>
      <abstract_bn>স্থানীয় ভাষা পরিচিতির (NLI) কাজের জন্য বেশী সফল পদ্ধতি ব্যবহার করে অনেক শ্রেণীর বর্তমান অবস্থা পৌঁছানোর প্রমাণিত হয়েছে। কিন্তু এনলির জন্য এনসিবেল পদ্ধতির ব্যবস্থা পরীক্ষা এখনো করা যায়নি। এছাড়াও, ক্লাসাফিয়ার স্ট্যাকিং এর মত গভীর গভীর প্রতিষ্ঠানগুলো কাছাকাছি মূল্যায়ন করা হয়নি। আমরা তিনটি এনস্পেল ভিত্তিক মডেল ব্যবহার করে এক ধরনের পরীক্ষা উপস্থাপন করি, প্রত্যেকেই বেশ কনফিগারেশন এবং অ্যালগরিদম দি এনলির জন্য মেটা-ক্লাস্ফিকেশন মডেলের একটি কঠিন অ্যাপ্লিকেশন রয়েছে, বেশ কয়েকটি বিশাল ডাটা সেটে রাষ্ট্র-অফ-শিল্পের ফলাফল পাওয়া যাচ্ছে, যা ইন্টার কোর্</abstract_bn>
      <abstract_ca>Els mètodes agrupables que utilitzen múltiples classificadors han demostrat ser entre els enfocaments més exitosos per a la tasca d'Identificació de Llingua Indígena (NLI), aconseguint l'estat actual d'art. No obstant això, encara no s'ha fet un examen sistemàtic dels mètodes conjunts de la NLI. A més, arquitectures de conjunts més profunds com la pila de classificadors no han estat apreciades de prop. Presentam un conjunt d'experiments utilitzant tres models basats en conjunts, testant cada un amb múltiples configuracions i algoritmes. Això inclou una aplicació rigorosa de models de meta-classificació per a l'INL, aconseguint resultats més avançats en diversos grans conjunts de dades, evaluats tant en mods intra corpus com transcorpus.</abstract_ca>
      <abstract_cs>Souborové metody využívající více klasifikátorů se ukázaly jako jedny z nejúspěšnějších přístupů k úkolu identifikace rodného jazyka (NLI), které dosahují současného stavu techniky. Systematické zkoumání souborových metod pro NLI však dosud nebylo provedeno. Navíc hlubší architektury souborů, jako je klasifikátor stohování, nebyly důkladně hodnoceny. Představujeme sadu experimentů s využitím tří souborových modelů, které testují každý s několika konfiguracemi a algoritmy. To zahrnuje přísné uplatnění metaklasifikačních modelů pro NLI, dosažení nejmodernějších výsledků na několika velkých datových sadách, hodnocených jak v intrakorpusovém, tak crosskorpusovém režimu.</abstract_cs>
      <abstract_et>Mitut klassifitseerijat kasutavad ansambli meetodid on osutunud üheks edukamaks lähenemiseks emakeele identifitseerimise ülesandeks, saavutades praeguse tehnika taseme. NLI ansambli meetodite süstemaatiline uurimine tuleb siiski veel läbi viia. Lisaks ei ole põhjalikult hinnatud sügavamaid ansambli arhitektuure, näiteks klassifitseerijate virnastamist. Esitleme kolme ansamblil põhinevat mudelit, testides igaüht mitme konfiguratsiooni ja algoritmiga. See hõlmab NLI metaklassifikatsiooni mudelite ranget rakendamist, saavutades tipptasemel tulemusi mitme suure andmekogumi puhul, mida hinnatakse nii korpusesiseses kui korpusesiseses režiimis.</abstract_et>
      <abstract_bs>Među najuspješnijim pristupima za zadatak identifikacije porodičnog jezika (NLI), ostvarili su metode proizvodnje višestrukih klasifikatora. Međutim, sistematsko ispitivanje metoda ensemble za NLI još se ne smije provesti. Osim toga, nisu bliže procjenjivane dublje arhitekture za ensemble poput klasifikacije. Predstavljamo niz eksperimenata koristeći tri modela na osnovu ensembla, testirajući svakog sa višestrukim konfiguracijama i algoritmima. To uključuje tešku primjenu metaklasifikacijskih modela za NLI, ostvarivanje rezultata umjetnosti na nekoliko velikih seta podataka, procijenjenih i u obliku korpusa i preko korpusa.</abstract_bs>
      <abstract_fi>Useita luokittelijoita hyödyntävät Ensemble-menetelmät ovat osoittautuneet yhdeksi onnistuneimmista lähestymistavoista Native Language Identification (NLI) -tehtävässä saavuttaen nykytekniikan. NLI:n kokoonpanomenetelmien systemaattinen tarkastelu on kuitenkin vielä kesken. Lisäksi syvempiä kokoonpanoarkkitehtuuria, kuten luokittelijoiden pinoamista, ei ole arvioitu tarkasti. Esitämme joukon kokeiluja käyttäen kolmea ensemblepohjaista mallia, joista jokainen testataan useilla konfiguraatioilla ja algoritmeilla. Tähän sisältyy NLI:n metaluokitusmallien tiukka soveltaminen ja huippuluokan tulosten saavuttaminen useista suurista aineistoista, joita arvioidaan sekä korpusen sisäisessä että korpusen välisessä tilassa.</abstract_fi>
      <abstract_sk>Skupinske metode, ki uporabljajo več klasifikatorjev, so se izkazale za med najuspešnejšimi pristopi za nalogo identifikacije maternega jezika (NLI), ki dosegajo sedanje stanje tehnike. Vendar pa je treba sistematično preučiti metode ansambla za NLI. Poleg tega globlje arhitekture ansambla, kot je zlaganje klasifikatorjev, niso bile natančno ocenjene. Predstavljamo sklop eksperimentov s tremi ansambelnimi modeli, ki testirajo vsak z več konfiguracijami in algoritmi. To vključuje strogo uporabo metaklasifikacijskih modelov za NLI in doseganje najsodobnejših rezultatov na več velikih podatkovnih nizih, ocenjenih v načinu znotraj korpusa in med korpusom.</abstract_sk>
      <abstract_he>שיטות מסוימות בשימוש מסווגים רבים הוכיחו להיות בין הגישות המצליחות ביותר למשימה של זיהוי שפת מקומית (NLI), להשיג את המצב הנוכחי של האמנות. עם זאת, עדיין לא ניהלה בדיקה מערכתית של שיטות אנסמבל עבור NLI. בנוסף, ארכיטקטורות אנסמבלים עמוקות יותר, כמו ערכות קלאסיפור, לא הוערכו מקרוב. אנחנו מציגים קבוצת ניסויים בשימוש בשלושה דוגמנים מבוססים באנסמבל, מבחנים כל אחד עם תצורות רבות ואלגוריתמים. זה כולל שימוש rigorous של מודלים מטה-מסווגים עבור NLI, להשיג תוצאות מוקדמות על מספר קבוצות נתונים גדולות, הערכו בשני הצרכים בתוך הקורפוס וגם בתוך הקורפוס.</abstract_he>
      <abstract_jv>Slackfree Nanging, sistematik énsuri sistem kanggo ngerasar sistem kanggo NLI isih durung bisa ditambah. politenessoffpolite"), and when there is a change ("assertive Awak dhéwé éntuk sistem karo perbudhakan ning telu model sing basa gambar ensembedle, nggunakake saben karo sistem lan Algorithms. Iki lak nglebokake sistem sing dibenalke perusahaan meta-klasik model kanggo NLI, ditambahake perusahaan-perusahaan bukane dadi akeh akeh dhéwé, gekasakno iki dadi shape karo perusahaan sampeyan karo perusahaan</abstract_jv>
      <abstract_ha>@ info: status A lokacin da, ba za'a samar da wata jarraba na'ura na embemble wa NLI ba. Da haka, ba a ƙaddara wasu matsayin da ke ƙaranci kamar mai fassarawa ba. Tuna gabatar da wasu fitina masu amfani da misãlai uku a kan fanel, domin jarraba kowansu da wasu tsaro da algoritori. Wannan yana ƙunsa da shirin ayuka mai inganci wa misãlai na meta-classified wa NLI, mai sãmun matsalar-halin-sanarta a kan tsarin data masu yawa, wanda aka ƙaddara cikin shirin-korbus da tsumarni-korbas.</abstract_ha>
      <abstract_bo>ནུས་ཡོད་པའི་སྐད་རིགས་དམིགས་འཛུགས་ཀྱི་བྱ་འགུལ་ལས་དབྱེ་རིམ་གཞན་ལས་ཕན་ཚུལ་ཆེ་ཤོས་ཡོད། ཡིན་ནའང་། NLI་ལ་མཚོན་རྟགས་ཀྱི་ལམ་ལུགས་ཞིབ་དཔྱད་བྱེད་དགོས་མེད། ད་དུང་། དབྱེ་བ་ཁང་བཟོས་ཀྱི་མཚོན་རྟགས་སྒྲིག་བཀོད་འདི་ཁག་པོ་ཞིག་བྱས་མེད། ང་ཚོས་མཚོན་རྟགས་ལ་གཞི་བྱས་པའི་མིག་དཔེ་ལེན་གསུམ་ཀྱི་སྒྲིག་སྟངས་དང་སྒྲིག་སྟངས་སྣ་ཚོགས་ཀྱི་བརྟག་ཞིབ This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on several large data sets, evaluated in both intra-corpus and cross-corpus modes.</abstract_bo>
      </paper>
    <paper id="5">
      <title>Using <a href="https://en.wikipedia.org/wiki/Semantics">Semantics</a> for Granularities of Tokenization</title>
      <author><first>Martin</first><last>Riedl</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <abstract>Depending on downstream applications, it is advisable to extend the notion of <a href="https://en.wikipedia.org/wiki/Lexical_analysis">tokenization</a> from low-level character-based token boundary detection to identification of meaningful and useful language units. This entails both identifying units composed of several single words that form a several single words that form a, as well as splitting single-word compounds into their meaningful parts. In this article, we introduce unsupervised and knowledge-free methods for these two <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>. The main novelty of our research is based on the fact that methods are primarily based on distributional similarity, of which we use two flavors : a sparse count-based and a dense neural-based distributional semantic model. First, we introduce DRUID, which is a method for detecting MWEs. The evaluation on MWE-annotated data sets in two languages and newly extracted evaluation data sets for 32 languages shows that DRUID compares favorably over previous methods not utilizing distributional information. Second, we present SECOS, an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> for decompounding close compounds. In an evaluation of four dedicated decompounding data sets across four languages and on data sets extracted from <a href="https://en.wikipedia.org/wiki/Wiktionary">Wiktionary</a> for 14 languages, we demonstrate the superiority of our approach over unsupervised baselines, sometimes even matching the performance of previous language-specific and supervised methods. In a final experiment, we show how both decompounding and MWE information can be used in <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval</a>. Here, we obtain the best results when combining <a href="https://en.wikipedia.org/wiki/Word">word information</a> with MWEs and the <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">compound parts</a> in a bag-of-words retrieval set-up.</abstract>
      <pages>483–524</pages>
      <doi>10.1162/coli_a_00325</doi>
      <url hash="cde4859a">J18-3005</url>
      <bibkey>riedl-biemann-2018-using</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
    </paper>
    <paper id="6">
      <title>Feature-Based Decipherment for <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a></title>
      <author><first>Iftekhar</first><last>Naim</last></author>
      <author><first>Parker</first><last>Riley</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <abstract>Orthographic similarities across languages provide a strong signal for unsupervised probabilistic transduction (decipherment) for closely related language pairs. The existing decipherment models, however, are not well suited for exploiting these orthographic similarities. We propose a <a href="https://en.wikipedia.org/wiki/Log-linear_model">log-linear model</a> with <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a> that incorporates orthographic similarity features. Maximum likelihood training is computationally expensive for the proposed <a href="https://en.wikipedia.org/wiki/Log-linear_model">log-linear model</a>. To address this challenge, we perform <a href="https://en.wikipedia.org/wiki/Approximate_inference">approximate inference</a> via Markov chain Monte Carlo sampling and <a href="https://en.wikipedia.org/wiki/Contrastive_divergence">contrastive divergence</a>. Our results show that the proposed <a href="https://en.wikipedia.org/wiki/Log-linear_model">log-linear model</a> with <a href="https://en.wikipedia.org/wiki/Contrastive_divergence">contrastive divergence</a> outperforms the existing generative decipherment models by exploiting the orthographic features. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> both scales to large vocabularies and preserves <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> in low- and no-resource contexts.</abstract>
      <pages>525–546</pages>
      <doi>10.1162/coli_a_00326</doi>
      <url hash="4060e909">J18-3006</url>
      <bibkey>naim-etal-2018-feature</bibkey>
    </paper>
    <paper id="7">
      <title>Survey : <a href="https://en.wikipedia.org/wiki/Anaphora_(linguistics)">Anaphora</a> With Non-nominal Antecedents in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">Computational Linguistics</a> : a Survey<fixed-case>S</fixed-case>urvey: Anaphora With Non-nominal Antecedents in Computational Linguistics: a <fixed-case>S</fixed-case>urvey</title>
      <author><first>Varada</first><last>Kolhatkar</last></author>
      <author><first>Adam</first><last>Roussel</last></author>
      <author><first>Stefanie</first><last>Dipper</last></author>
      <author><first>Heike</first><last>Zinsmeister</last></author>
      <abstract>This article provides an extensive overview of the literature related to the phenomenon of non-nominal-antecedent anaphora (also known as abstract anaphora or discourse deixis), a type of <a href="https://en.wikipedia.org/wiki/Anaphora_(linguistics)">anaphora</a> in which an <a href="https://en.wikipedia.org/wiki/Anaphora_(linguistics)">anaphor</a> like that refers to an antecedent (marked in boldface) that is syntactically non-nominal, such as the first sentence in It’s way too hot here. That’s why I’m moving to Alaska. Annotating and automatically resolving these cases of <a href="https://en.wikipedia.org/wiki/Anaphora_(linguistics)">anaphora</a> is interesting in its own right because of the complexities involved in identifying non-nominal antecedents, which typically represent abstract objects such as <a href="https://en.wikipedia.org/wiki/Event_(philosophy)">events</a>, facts, and propositions. There is also practical value in the resolution of non-nominal-antecedent anaphora, as this would help computational systems in <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, and <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>, as well as, conceivably, any other task dependent on some measure of text understanding. Most of the existing approaches to anaphora annotation and resolution focus on nominal-antecedent anaphora, classifying many of the cases where the antecedents are syntactically non-nominal as non-anaphoric. There has been some work done on this topic, but it remains scattered and difficult to collect and assess. With this article, we hope to bring together and synthesize work done in disparate contexts up to now in order to identify fundamental problems and draw conclusions from an overarching perspective. Having a good picture of the current state of the art in this field can help researchers direct their efforts to where they are most necessary. Because of the great variety of theoretical approaches that have been brought to bear on the problem, there is an equally diverse array of terminologies that are used to describe it, so we will provide an overview and discussion of these <a href="https://en.wikipedia.org/wiki/Terminology">terminologies</a>. We also describe the linguistic properties of non-nominal-antecedent anaphora, examine previous annotation efforts that have addressed this topic, and present the computational approaches that aim at resolving non-nominal-antecedent anaphora automatically. We close with a review of the remaining open questions in this area and some of our recommendations for future research.</abstract>
      <pages>547–612</pages>
      <doi>10.1162/coli_a_00327</doi>
      <url hash="a9bff1ee">J18-3007</url>
      <bibkey>kolhatkar-etal-2018-survey</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/new-york-times-annotated-corpus">New York Times Annotated Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/parcorfull">ParCorFull</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
  </volume>
  <volume id="4">
    <meta>
      <booktitle>Computational Linguistics, Volume 44, Issue 4 - <fixed-case>D</fixed-case>ecember 2018</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>December</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2018-linguistics-44-issue-4</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Squib : The Language Resource Switchboard<fixed-case>S</fixed-case>quib: The Language Resource Switchboard</title>
      <author><first>Claus</first><last>Zinn</last></author>
      <abstract>The CLARIN research infrastructure gives users access to an increasingly rich and diverse set of language-related resources and tools. Whereas there is ample support for searching resources using metadata-based search, or <a href="https://en.wikipedia.org/wiki/Full-text_search">full-text search</a>, or for aggregating resources into virtual collections, there is little support for users to help them process resources in one way or another. In spite of the large number of tools that process texts in many different languages, there is no single point of access where users can find tools to fit their needs and the resources they have. In this squib, we present the Language Resource Switchboard (LRS), which helps users to discover tools that can process their resources. For this, the LRS identifies all applicable tools for a given resource, lists the tasks the tools can achieve, and invokes the selected tool in such a way so that processing can start immediately with little or no prior tool parameterization.</abstract>
      <pages>631–639</pages>
      <doi>10.1162/coli_a_00329</doi>
      <url hash="43002422">J18-4002</url>
      <bibkey>zinn-2018-squib</bibkey>
    </paper>
    <paper id="3">
      <title>Squib : Reproducibility in Computational Linguistics : Are We Willing to Share?<fixed-case>S</fixed-case>quib: Reproducibility in Computational Linguistics: Are We Willing to Share?</title>
      <author><first>Martijn</first><last>Wieling</last></author>
      <author><first>Josine</first><last>Rawee</last></author>
      <author><first>Gertjan</first><last>van Noord</last></author>
      <abstract>This study focuses on an essential precondition for reproducibility in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> : the willingness of authors to share relevant source code and data. Ten years after Ted Pedersen’s influential Last Words contribution in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">Computational Linguistics</a>, we investigate to what extent researchers in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> are willing and able to share their data and code. We surveyed all 395 full papers presented at the 2011 and 2016 ACL Annual Meetings, and identified whether links to data and code were provided. If working links were not provided, authors were requested to provide this information. Although data were often available, code was shared less often. When working links to code or data were not provided in the paper, authors provided the <a href="https://en.wikipedia.org/wiki/Source_code">code</a> in about one third of cases. For a selection of ten papers, we attempted to reproduce the results using the provided data and code. We were able to reproduce the results approximately for six papers. For only a single paper did we obtain the exact same results. Our findings show that even though the situation appears to have improved comparing 2016 to 2011, <a href="https://en.wikipedia.org/wiki/Empiricism">empiricism</a> in <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> still largely remains a matter of faith. Nevertheless, we are somewhat optimistic about the future. Ensuring reproducibility is not only important for the field as a whole, but also seems worthwhile for individual researchers : The median citation count for studies with working links to the source code is higher.</abstract>
      <pages>641–649</pages>
      <doi>10.1162/coli_a_00330</doi>
      <url hash="ccff6a48">J18-4003</url>
      <bibkey>wieling-etal-2018-squib</bibkey>
    </paper>
    <paper id="7">
      <title>Interactional Stancetaking in Online Forums</title>
      <author><first>Scott F.</first><last>Kiesling</last></author>
      <author><first>Umashanthi</first><last>Pavalanathan</last></author>
      <author><first>Jim</first><last>Fitzpatrick</last></author>
      <author><first>Xiaochuang</first><last>Han</last></author>
      <author><first>Jacob</first><last>Eisenstein</last></author>
      <abstract>Language is shaped by the relationships between the speaker / writer and the audience, the object of discussion, and the talk itself. In turn, <a href="https://en.wikipedia.org/wiki/Language">language</a> is used to reshape these relationships over the course of an interaction. Computational researchers have succeeded in operationalizing <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a>, <a href="https://en.wikipedia.org/wiki/Formality">formality</a>, and <a href="https://en.wikipedia.org/wiki/Politeness">politeness</a>, but each of these constructs captures only some aspects of social and relational meaning. Theories of interactional stancetaking have been put forward as holistic accounts, but until now, these <a href="https://en.wikipedia.org/wiki/Theory">theories</a> have been applied only through detailed qualitative analysis of (portions of) a few individual conversations. In this article, we propose a new computational operationalization of interpersonal stancetaking. We begin with annotations of three linked stance dimensionsaffect, investment, and alignmenton 68 conversation threads from the online platform Reddit. Using these annotations, we investigate thread structure and linguistic properties of stancetaking in online conversations. We identify lexical features that characterize the extremes along each stancetaking dimension, and show that these stancetaking properties can be predicted with moderate accuracy from bag-of-words features, even with a relatively small labeled training set. These <a href="https://en.wikipedia.org/wiki/Quantitative_research">quantitative analyses</a> are supplemented by extensive <a href="https://en.wikipedia.org/wiki/Qualitative_research">qualitative analysis</a>, highlighting the compatibility of computational and qualitative methods in synthesizing evidence about the creation of interactional meaning.</abstract>
      <pages>683–718</pages>
      <doi>10.1162/coli_a_00334</doi>
      <url hash="c38d05fd">J18-4007</url>
      <bibkey>kiesling-etal-2018-interactional</bibkey>
    </paper>
    <paper id="8">
      <title>A Joint Model of Conversational Discourse Latent Topics on Microblogs</title>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <abstract>Conventional <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a> are ineffective for topic extraction from <a href="https://en.wikipedia.org/wiki/Microblogging">microblog messages</a>, because the data sparseness exhibited in short messages lacking structure and contexts results in poor message-level word co-occurrence patterns. To address this issue, we organize microblog messages as conversation trees based on their reposting and replying relations, and propose an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised model</a> that jointly learns word distributions to represent : (1) different roles of conversational discourse, and (2) various latent topics in reflecting content information. By explicitly distinguishing the probabilities of messages with varying discourse roles in containing topical words, our model is able to discover clusters of discourse words that are indicative of topical content. In an automatic evaluation on large-scale microblog corpora, our joint model yields topics with better <a href="https://en.wikipedia.org/wiki/Coherence_(statistics)">coherence scores</a> than competitive topic models from previous studies. Qualitative analysis on model outputs indicates that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> induces meaningful <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> for both discourse and topics. We further present an empirical study on microblog summarization based on the outputs of our joint model. The results show that the jointly modeled discourse and topic representations can effectively indicate summary-worthy content in microblog conversations.</abstract>
      <pages>719–754</pages>
      <doi>10.1162/coli_a_00335</doi>
      <url hash="4afbe32b">J18-4008</url>
      <bibkey>li-etal-2018-joint-model</bibkey>
    </paper>
    <paper id="9">
      <title>Sarcasm Analysis Using Conversation Context</title>
      <author><first>Debanjan</first><last>Ghosh</last></author>
      <author><first>Alexander R.</first><last>Fabbri</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <abstract>Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, the speaker’s sarcastic intent is not always apparent without additional context. Focusing on social media discussions, we investigate three issues : (1) does modeling conversation context help in sarcasm detection? (2) can we identify what part of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversation context</a> triggered the <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcastic reply</a>? and (3) given a sarcastic post that contains multiple sentences, can we identify the specific sentence that is sarcastic? To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the current turn. We show that LSTM networks with sentence-level attention on context and current turn, as well as the conditional LSTM network, outperform the LSTM model that reads only the current turn. As <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversation context</a>, we consider the prior turn, the succeeding turn, or both. Our <a href="https://en.wikipedia.org/wiki/Computational_model">computational models</a> are tested on two types of <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a> : <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and <a href="https://en.wikipedia.org/wiki/Internet_forum">discussion forums</a>. We discuss several differences between these <a href="https://en.wikipedia.org/wiki/Data_set">data sets</a>, ranging from their size to the nature of the gold-label annotations. To address the latter two issues, we present a qualitative analysis of the attention weights produced by the LSTM models (with attention) and discuss the results compared with human performance on the two tasks.</abstract>
      <pages>755–792</pages>
      <doi>10.1162/coli_a_00336</doi>
      <url hash="ddccfa9f">J18-4009</url>
      <bibkey>ghosh-etal-2018-sarcasm</bibkey>
    </paper>
    <paper id="10">
      <title>We Usually Do n’t Like Going to the Dentist : Using Common Sense to Detect Irony on Twitter<fixed-case>T</fixed-case>witter</title>
      <author><first>Cynthia</first><last>Van Hee</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <author><first>Véronique</first><last>Hoste</last></author>
      <abstract>Although common sense and connotative knowledge come naturally to most people, computers still struggle to perform well on tasks for which such extratextual information is required. Automatic approaches to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and irony detection have revealed that the lack of such <a href="https://en.wikipedia.org/wiki/World_knowledge">world knowledge</a> undermines <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance. In this article, we therefore address the challenge of modeling implicit or prototypical sentiment in the framework of automatic irony detection. Starting from <a href="https://en.wikipedia.org/wiki/Lexical_analysis">manually annotated connoted situation phrases</a> (e.g., flight delays, sitting the whole day at the doctor’s office), we defined the <a href="https://en.wikipedia.org/wiki/Implicit_stereotype">implicit sentiment</a> held towards such situations automatically by using both a <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexico-semantic knowledge base</a> and a data-driven method. We further investigate how such implicit sentiment information affects irony detection by assessing a state-of-the-art irony classifier before and after it is informed with implicit sentiment information.</abstract>
      <pages>793–832</pages>
      <doi>10.1162/coli_a_00337</doi>
      <url hash="d45e20a3">J18-4010</url>
      <bibkey>van-hee-etal-2018-usually</bibkey>
    </paper>
    <paper id="11">
      <title>Combining <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> and Argumentative Reasoning for the Analysis of Social Media Textual Content Using Small Data Sets</title>
      <author><first>Oana</first><last>Cocarascu</last></author>
      <author><first>Francesca</first><last>Toni</last></author>
      <abstract>The use of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> has become a regular habit for many and has changed the way people interact with each other. In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information. Concretely, we define a deep learning method for relationbased argument mining to extract argumentative relations of attack and support. We then use this method for determining whether news articles support <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness. Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive. We show experimentally that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> performs well in both settings. In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> in standard <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classifiers</a>, outperforms the latter even on small data sets.</abstract>
      <pages>833–858</pages>
      <doi>10.1162/coli_a_00338</doi>
      <url hash="bf75fd2d">J18-4011</url>
      <bibkey>cocarascu-toni-2018-combining</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    </volume>
</collection>