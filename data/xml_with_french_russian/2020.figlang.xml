<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.figlang">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Figurative Language Processing</booktitle>
      <editor><first>Beata Beigman</first><last>Klebanov</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <editor><first>Patricia</first><last>Lichtenstein</last></editor>
      <editor><first>Smaranda</first><last>Muresan</last></editor>
      <editor><first>Chee</first><last>Wee</last></editor>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Debanjan</first><last>Ghosh</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="5a671364">2020.figlang-1</url>
    </meta>
    <frontmatter>
      <url hash="567b9601">2020.figlang-1.0</url>
      <bibkey>fig-lang-2020-figurative</bibkey>
    </frontmatter>
    <paper id="7">
      <title>Sarcasm Detection in Tweets with BERT and GloVe Embeddings<fixed-case>BERT</fixed-case> and <fixed-case>G</fixed-case>lo<fixed-case>V</fixed-case>e Embeddings</title>
      <author><first>Akshay</first><last>Khatri</last></author>
      <author><first>Pranav</first><last>P</last></author>
      <pages>56–60</pages>
      <abstract>Sarcasm is a form of communication in which the person states opposite of what he actually means. In this paper, we propose using machine learning techniques with BERT and GloVe embeddings to detect <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is preprocessed before extracting the <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> also uses all of the context provided in the dataset to which the user is reacting along with his actual response.</abstract>
      <url hash="060f0261">2020.figlang-1.7</url>
      <doi>10.18653/v1/2020.figlang-1.7</doi>
      <video href="http://slideslive.com/38929697" />
      <bibkey>khatri-p-2020-sarcasm</bibkey>
    </paper>
    <paper id="8">
      <title>C-Net : Contextual Network for Sarcasm Detection<fixed-case>C</fixed-case>-Net: Contextual Network for Sarcasm Detection</title>
      <author><first>Amit</first><last>Kumar Jena</last></author>
      <author><first>Aman</first><last>Sinha</last></author>
      <author><first>Rohit</first><last>Agarwal</last></author>
      <pages>61–66</pages>
      <abstract>Automatic Sarcasm Detection in <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, <a href="https://en.wikipedia.org/wiki/C-Net">C-Net</a>, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0 % <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> on the Twitter dataset and 66.3 % <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> on Reddit dataset.</abstract>
      <url hash="5ca7edd9">2020.figlang-1.8</url>
      <doi>10.18653/v1/2020.figlang-1.8</doi>
      <video href="http://slideslive.com/38929698" />
      <bibkey>kumar-jena-etal-2020-c</bibkey>
    </paper>
    <paper id="10">
      <title>Sarcasm Identification and Detection in Conversion Context using BERT<fixed-case>BERT</fixed-case></title>
      <author><first>Kalaivani</first><last>A.</last></author>
      <author><first>Thenmozhi</first><last>D.</last></author>
      <pages>72–76</pages>
      <abstract>Sarcasm analysis in user conversion text is automatic detection of any irony, insult, hurting, painful, caustic, <a href="https://en.wikipedia.org/wiki/Humour">humour</a>, vulgarity that degrades an individual. It is helpful in the field of sentimental analysis and <a href="https://en.wikipedia.org/wiki/Cyberbullying">cyberbullying</a>. As an immense growth of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, sarcasm analysis helps to avoid insult, hurts and <a href="https://en.wikipedia.org/wiki/Humour">humour</a> to affect someone. In this paper, we present traditional machine learning approaches, deep learning approach (LSTM -RNN) and BERT (Bidirectional Encoder Representations from Transformers) for identifying <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a>. We have used the approaches to build the model, to identify and categorize how much conversion context or response is needed for sarcasm detection and evaluated on the two social media forums that is twitter conversation dataset and reddit conversion dataset. We compare the performance based on the approaches and obtained the best F1 scores as 0.722, 0.679 for the <a href="https://en.wikipedia.org/wiki/Twitter">twitter forums</a> and <a href="https://en.wikipedia.org/wiki/Reddit">reddit forums</a> respectively.</abstract>
      <url hash="4c82ea89">2020.figlang-1.10</url>
      <doi>10.18653/v1/2020.figlang-1.10</doi>
      <video href="http://slideslive.com/38929700" />
      <bibkey>a-d-2020-sarcasm</bibkey>
    </paper>
    <paper id="11">
      <title>Neural Sarcasm Detection using Conversation Context</title>
      <author><first>Nikhil</first><last>Jaiswal</last></author>
      <pages>77–82</pages>
      <abstract>Social media platforms and <a href="https://en.wikipedia.org/wiki/Internet_forum">discussion forums</a> such as <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>, <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, etc. are filled with <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">figurative languages</a>. Sarcasm is one such category of <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">figurative language</a> whose presence in a conversation makes <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding</a> a challenging task. In this paper, we present a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural architecture</a> for sarcasm detection. We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset. We experiment with a variety of PLRMs either on the twitter utterance in isolation or utilizing the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> along with the utterance. Our findings indicate that by taking into consideration the previous three most recent utterances, the model is more accurately able to classify a conversation as being sarcastic or not. Our best performing <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble model</a> achieves an overall <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 0.790, which ranks us second on the leaderboard of the Sarcasm Shared Task 2020.</abstract>
      <url hash="64c8a878">2020.figlang-1.11</url>
      <doi>10.18653/v1/2020.figlang-1.11</doi>
      <video href="http://slideslive.com/38929701" />
      <bibkey>jaiswal-2020-neural</bibkey>
    </paper>
    <paper id="14">
      <title>A Novel Hierarchical BERT Architecture for Sarcasm Detection<fixed-case>BERT</fixed-case> Architecture for Sarcasm Detection</title>
      <author><first>Himani</first><last>Srivastava</last></author>
      <author><first>Vaibhav</first><last>Varshney</last></author>
      <author><first>Surabhi</first><last>Kumari</last></author>
      <author><first>Saurabh</first><last>Srivastava</last></author>
      <pages>93–97</pages>
      <abstract>Online discussion platforms are often flooded with opinions from users across the world on a variety of topics. Many such posts, comments, or utterances are often sarcastic in nature, i.e., the actual intent is hidden in the sentence and is different from its literal meaning, making the detection of such utterances challenging without additional context. In this paper, we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts ina hierarchical manner. We have used <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> from two online discussion platforms-Twitter and Reddit1for our experiments. Experimental and error analysis shows that the hierarchical models can make full use of history to obtain a better representation of contexts and thus, in turn, can outperform their sequential counterparts.</abstract>
      <url hash="3be522ec">2020.figlang-1.14</url>
      <doi>10.18653/v1/2020.figlang-1.14</doi>
      <video href="http://slideslive.com/38929704" />
      <bibkey>srivastava-etal-2020-novel</bibkey>
    </paper>
    <paper id="15">
      <title>Detecting Sarcasm in Conversation Context Using Transformer-Based Models<fixed-case>D</fixed-case>etecting <fixed-case>S</fixed-case>arcasm in <fixed-case>C</fixed-case>onversation <fixed-case>C</fixed-case>ontext <fixed-case>U</fixed-case>sing <fixed-case>T</fixed-case>ransformer-<fixed-case>B</fixed-case>ased <fixed-case>M</fixed-case>odels</title>
      <author><first>Adithya</first><last>Avvaru</last></author>
      <author><first>Sanath</first><last>Vobilisetty</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>98–103</pages>
      <abstract>Sarcasm detection, regarded as one of the sub-problems of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> in one single sentence and there is very limited research to detect <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without <a href="https://en.wikipedia.org/wiki/Attention">attention</a> to detect <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> in conversations. We showed that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</abstract>
      <url hash="f21683bd">2020.figlang-1.15</url>
      <doi>10.18653/v1/2020.figlang-1.15</doi>
      <bibkey>avvaru-etal-2020-detecting</bibkey>
    </paper>
    <paper id="16">
      <title>Using Conceptual Norms for Metaphor Detection</title>
      <author><first>Mingyu</first><last>Wan</last></author>
      <author><first>Kathleen</first><last>Ahrens</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Menghan</first><last>Jiang</last></author>
      <author><first>Qi</first><last>Su</last></author>
      <author><first>Rong</first><last>Xiang</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <pages>104–109</pages>
      <abstract>This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate in all four phases of competition with both <a href="https://en.wikipedia.org/wiki/Digital_data">datasets</a>, i.e. Verbs and AllPOS on the VUA and the TOFEL datasets. We use the modality exclusivity and embodiment norms for constructing a conceptual representation of the nodes and the context. Our <a href="https://en.wikipedia.org/wiki/System">system</a> obtains an <a href="https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry">F-score</a> of 0.652 for the VUA Verbs track, which is 5 % higher than the strong baselines. The experimental results across models and datasets indicate the salient contribution of using modality exclusivity and modality shift information for predicting <a href="https://en.wikipedia.org/wiki/Metaphor">metaphoricity</a>.</abstract>
      <url hash="d539dd53">2020.figlang-1.16</url>
      <doi>10.18653/v1/2020.figlang-1.16</doi>
      <video href="http://slideslive.com/38929723" />
      <bibkey>wan-etal-2020-using</bibkey>
    </paper>
    <paper id="18">
      <title>Character aware models with <a href="https://en.wikipedia.org/wiki/Similarity_learning">similarity learning</a> for metaphor detection</title>
      <author><first>Tarun</first><last>Kumar</last></author>
      <author><first>Yashvardhan</first><last>Sharma</last></author>
      <pages>116–125</pages>
      <abstract>Recent work on automatic sequential metaphor detection has involved <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a> initialized with different pre-trained word embeddings and which are sometimes combined with hand engineered features. To capture lexical and orthographic information automatically, in this paper we propose to add character based word representation. Also, to contrast the difference between <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">literal and contextual meaning</a>, we utilize a similarity network. We explore these components via two different architectures-a BiLSTM model and a Transformer Encoder model similar to BERT to perform metaphor identification. We participate in the Second Shared Task on Metaphor Detection on both the VUA and TOFEL datasets with the above models. The experimental results demonstrate the effectiveness of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> as it outperforms all the <a href="https://en.wikipedia.org/wiki/System">systems</a> which participated in the previous shared task.</abstract>
      <url hash="50d48c2c">2020.figlang-1.18</url>
      <doi>10.18653/v1/2020.figlang-1.18</doi>
      <video href="http://slideslive.com/38929724" />
      <bibkey>kumar-sharma-2020-character</bibkey>
    </paper>
    <paper id="20">
      <title>Recognizing Euphemisms and Dysphemisms Using <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a></title>
      <author><first>Christian</first><last>Felt</last></author>
      <author><first>Ellen</first><last>Riloff</last></author>
      <pages>136–145</pages>
      <abstract>This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, <a href="https://en.wikipedia.org/wiki/Dysphemism">dysphemisms</a> refer to sensitive topics in a harsh or rude way. For example, passed away and departed are <a href="https://en.wikipedia.org/wiki/Euphemism">euphemisms</a> for death, while croaked and six feet under are <a href="https://en.wikipedia.org/wiki/Dysphemism">dysphemisms</a> for death. Our work explores the use of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as <a href="https://en.wikipedia.org/wiki/Euphemism">euphemistic</a>, dysphemistic, or neutral using <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical sentiment cues</a> and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <url hash="e06ee38a">2020.figlang-1.20</url>
      <doi>10.18653/v1/2020.figlang-1.20</doi>
      <video href="http://slideslive.com/38929717" />
      <bibkey>felt-riloff-2020-recognizing</bibkey>
    </paper>
    <paper id="23">
      <title>Generating Ethnographic Models from Communities’ Online Data</title>
      <author><first>Tomek</first><last>Strzalkowski</last></author>
      <author><first>Anna</first><last>Newheiser</last></author>
      <author><first>Nathan</first><last>Kemper</last></author>
      <author><first>Ning</first><last>Sa</last></author>
      <author><first>Bharvee</first><last>Acharya</last></author>
      <author><first>Gregorios</first><last>Katsios</last></author>
      <pages>165–175</pages>
      <abstract>In this paper we describe computational ethnography study to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence. Specifically, we leverage the use of <a href="https://en.wikipedia.org/wiki/Figurative_language">figurative language</a> (i.e., the choice of metaphors) in <a href="https://en.wikipedia.org/wiki/Online_and_offline">online text</a> (e.g., <a href="https://en.wikipedia.org/wiki/News_media">news media</a>, blogs) produced by distinct communities to obtain models of community worldviews that can be shown to be distinctly biased and thus different from other communities’ models. We automatically construct metaphor-based community models for two distinct scenarios : <a href="https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States">gun rights</a> and <a href="https://en.wikipedia.org/wiki/Same-sex_marriage_in_the_United_States">marriage equality</a>. We then conduct a series of experiments to validate the hypothesis that the <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a> found in each community’s online language convey the bias in the community’s worldview.</abstract>
      <url hash="10dcef0a">2020.figlang-1.23</url>
      <attachment type="Software" hash="3084e139">2020.figlang-1.23.Software.zip</attachment>
      <doi>10.18653/v1/2020.figlang-1.23</doi>
      <attachment type="Dataset" hash="5d983303">2020.figlang-1.23.Dataset.pdf</attachment>
      <video href="http://slideslive.com/38929711" />
      <bibkey>strzalkowski-etal-2020-generating</bibkey>
    </paper>
    <paper id="28">
      <title>Augmenting Neural Metaphor Detection with Concreteness</title>
      <author><first>Ghadi</first><last>Alnafesah</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <pages>204–210</pages>
      <abstract>The idea that a shift in <a href="https://en.wikipedia.org/wiki/Concreteness">concreteness</a> within a sentence indicates the presence of a <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a> has been around for a while. However, recent methods of detecting metaphor that have relied on <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural models</a> have ignored <a href="https://en.wikipedia.org/wiki/Concreteness">concreteness</a> and related psycholinguistic information. We hypothesis that this <a href="https://en.wikipedia.org/wiki/Information">information</a> is not available to these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and that their addition will boost the performance of these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> in detecting <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a>. We test this hypothesis on the Metaphor Detection Shared Task 2020 and find that the addition of concreteness information does in fact boost <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural models</a>. We also run tests on data from a previous <a href="https://en.wikipedia.org/wiki/Task_(computing)">shared task</a> and show similar results.</abstract>
      <url hash="7777f0bb">2020.figlang-1.28</url>
      <doi>10.18653/v1/2020.figlang-1.28</doi>
      <bibkey>alnafesah-etal-2020-augmenting</bibkey>
    </paper>
    <paper id="33">
      <title>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</title>
      <author><first>Jennifer</first><last>Brooks</last></author>
      <author><first>Abdou</first><last>Youssef</last></author>
      <pages>244–249</pages>
      <abstract>In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms. Some of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> were trained on all parts of speech. Each of the other models was trained on one of four categories for <a href="https://en.wikipedia.org/wiki/Part_of_speech">parts of speech</a> : <a href="https://en.wikipedia.org/wiki/Noun">nouns</a>, <a href="https://en.wikipedia.org/wiki/Verb">verbs</a>, <a href="https://en.wikipedia.org/wiki/Adjective">adverbs / adjectives</a>, or other. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> were combined into voting pools and the voting pools were combined using the logical OR operator.</abstract>
      <url hash="f68d3dff">2020.figlang-1.33</url>
      <doi>10.18653/v1/2020.figlang-1.33</doi>
      <video href="http://slideslive.com/38929728" />
      <bibkey>brooks-youssef-2020-metaphor</bibkey>
    <title_fr>Détection de métaphore au moyen d'ensembles de réseaux neuronaux récurrents bidirectionnels</title_fr>
      <title_pt>Detecção de metáforas usando conjuntos de redes neurais recorrentes bidirecionais</title_pt>
      <title_ar>الكشف المجازي باستخدام مجموعات الشبكات العصبية المتكررة ثنائية الاتجاه</title_ar>
      <title_es>Detección de metáforas mediante conjuntos de redes neuronales recurrentes bidireccionales</title_es>
      <title_ja>双方向再帰ニューラルネットワークのアンサンブルを使用した比喩検出</title_ja>
      <title_zh>用双向递归神经网络合隐喻检</title_zh>
      <title_hi>रूपक का पता लगाना द्विदिश आवर्तक तंत्रिका नेटवर्क के Ensembles का उपयोग कर</title_hi>
      <title_ru>Обнаружение метафор с помощью ансамблей двунаправленных рекуррентных нейронных сетей</title_ru>
      <title_ga>Brath Meafar ag úsáid Ensembles de Líonraí Néaracha Athfhillteacha Déthreo</title_ga>
      <title_hu>Metafór detektálás kétirányú ismétlődő ideghálózatok együtteseivel</title_hu>
      <title_el>Ανίχνευση μεταφορών χρησιμοποιώντας σύνολα αμφίδρομης επαναλαμβανόμενης νευρωνικής δικτύωσης</title_el>
      <title_ka>Name</title_ka>
      <title_it>Rilevamento della metafora utilizzando gruppi di reti neurali ricorrenti bidirezionali</title_it>
      <title_kk>Екі бағытты қайталанатын невралдық желілердің кеңейтулерін қолданып метафорды анықтау</title_kk>
      <title_lt>Metaforų aptikimas naudojant dvikrypčius pakartotinius nervinius tinklus</title_lt>
      <title_ms>Pengesanan Metafora menggunakan Ensembles of Bidirectional Recurrent Neural Networks</title_ms>
      <title_ml>ബൈഡിഡയല്‍ ആവര്‍ത്തിക്കുന്ന നെയുറല്‍ നെറ്റ്വര്‍ക്കുകളുടെ എന്‍സെമ്പിളുകള്‍ ഉപയോഗിച്ച് മെറ്റാപ്പറ</title_ml>
      <title_mt>Detezzjoni ta’ Metafori bl-użu ta’ Ensembles ta’ Netwerks Newrali Rikorrenti Bidirezzjonali</title_mt>
      <title_mn>Дөрвөлжингийн дахин дахин дахин сэтгэл мэдрэлийн сүлжээний шинжлэх ухаан</title_mn>
      <title_no>Metaforoppdaging ved å bruka Ensembler av divretning gjentaande neuralnettverk</title_no>
      <title_pl>Wykrywanie metaforów przy użyciu zespołów dwukierunkowych powtarzających się sieci neuronowych</title_pl>
      <title_ro>Detectarea metaforelor folosind ansambluri de rețele neurale recurente bidirecționale</title_ro>
      <title_sr>Metaforska otkrića koristeći proizvode dvosmjernih ponovnih neuronskih mreža</title_sr>
      <title_si>මෙටාෆෝර් හොයාගන්න පුළුවන් ප්‍රවේශයෙන් ප්‍රවේශනය සඳහා ප්‍රවේශනය</title_si>
      <title_mk>Детектирање на метафори користејќи енсембли од дводрекционални рекурентни неврални мрежи</title_mk>
      <title_so>Aqoonshaha midowga ee Ensembles of Bidirectional Neural Network</title_so>
      <title_sv>Metafordetektering med hjälp av ensembler av dubbelriktade återkommande neurala nätverk</title_sv>
      <title_ta>இருதிசையில் நிகழ்ந்த நெயுரல் வலைப்பின்னல்களை பயன்படுத்தி மெட்போர் கண்டுபிடிப்பு</title_ta>
      <title_ur>دودئیرسیٹنی دودئیرسیٹنی نیورال نٹورک کے مطابق مٹافور پتچا</title_ur>
      <title_vi>Phát hiện siêu hình bằng thang của mạng thần kinh sẵn định hướng</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Откриване на метафори с помощта на ансамбли от двупосочни повтарящи се неврални мрежи</title_bg>
      <title_nl>Metaforedetectie met behulp van ensembles van bidirectionele recurrente neurale netwerken</title_nl>
      <title_hr>Metaforska otkrića koristeći primjene dvosmjernih ponovnih neuronskih mreža</title_hr>
      <title_da>Metaphor Detection ved hjælp af Ensembler af bidirektionelle tilbagevendende neurale netværk</title_da>
      <title_id>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</title_id>
      <title_ko>쌍방향 귀속 신경 네트워크 기반의 은유 검출</title_ko>
      <title_fa>شناسایی متفاوری با استفاده از انفجار شبکه‌های عصبی دورانی</title_fa>
      <title_de>Metaphernerkennung mit Ensembles von bidirektionalen wiederkehrenden neuronalen Netzwerken</title_de>
      <title_sq>Detektimi i metaforës duke përdorur Ensembles të Rrjeteve Neurale Rekurente Dydrejtuese</title_sq>
      <title_af>Name</title_af>
      <title_tr>KCharselect unicode block name</title_tr>
      <title_sw>Utafiti wa Kampuni kwa kutumia Sehembe za Mtandao wa Nyasiri Zisizo Kadiria</title_sw>
      <title_am>ምርጫዎች</title_am>
      <title_az>ńįki t…ôr…ôfli N√∂ral AńülarńĪnńĪn Ensembl…ôri il…ô Metaforlar KeŇüfeti</title_az>
      <title_bn>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</title_bn>
      <title_hy>Մետաֆորի հայտնաբերումը, օգտագործելով երկաուղղակի կրկնվող նյարդային ցանցերի նշանները</title_hy>
      <title_bs>Metaforska otkrića koristeći primjene dvosmjernih ponovnih neuronskih mreža</title_bs>
      <title_ca>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</title_ca>
      <title_et>Metafoori tuvastamine kahesuunaliste korduvate neurovõrkude ansamblite abil</title_et>
      <title_cs>Detekce metaforů pomocí souborů obousměrných recidivních neuronových sítí</title_cs>
      <title_fi>Metaforin tunnistus kaksisuuntaisten toistuvien hermoverkkojen kokoonpanojen avulla</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>גילוי מטאפורות בשימוש באנסמלים של רשתות נוירוליות שתיים כיוונים</title_he>
      <title_sk>Zaznavanje metafore z uporabo kompletov dvosmernih ponavljajočih se živčnih omrežij</title_sk>
      <title_bo>ཕྱིར་འདྲ་བ་ཞེས་བྱེད་སྤྱད་ནས་འདྲ་བ་གཉིས་གཤམ་གྱི་རྩིས་འབྲེལ་མཐུད་དྲ་རྒྱ་སྤྱོད་བཞིན་པ</title_bo>
      <title_jv>metaphor</title_jv>
      <abstract_ar>نقدم في هذه الورقة نتائجنا من المهمة المشتركة الثانية حول اكتشاف الاستعارة ، والتي استضافتها ورشة العمل الثانية حول معالجة اللغة التصويرية. نحن نستخدم مجموعة من نماذج RNN مع LSTMs ثنائية الاتجاه وآليات الانتباه ثنائية الاتجاه. تم تدريب بعض النماذج على جميع أجزاء الكلام. تم تدريب كل من النماذج الأخرى على واحدة من أربع فئات لأجزاء الكلام: "الأسماء" ، "الأفعال" ، "الظروف / الصفات" ، أو "أخرى". تم دمج النماذج في مجموعات تصويت وتم دمج مجموعات التصويت باستخدام عامل التشغيل المنطقي "OR".</abstract_ar>
      <abstract_es>En este artículo presentamos los resultados de la Segunda tarea compartida sobre detección de metáforas, organizada por el Segundo Taller sobre Procesamiento del Lenguaje Figurativo. Utilizamos un conjunto de modelos RNN con LSTM bidireccionales y mecanismos de atención bidireccionales. Algunos de los modelos fueron entrenados en todas las partes del habla. Cada uno de los otros modelos se entrenó en una de las cuatro categorías para las partes del discurso: «sustantivos», «verbos», «adverbos/adjetivos» u «otros». Los modelos se combinaron en grupos de votación y los grupos de votación se combinaron utilizando el operador lógico «OR».</abstract_es>
      <abstract_pt>Neste artigo apresentamos nossos resultados da Segunda Tarefa Compartilhada sobre Detecção de Metáforas, organizada pelo Segundo Workshop sobre Processamento de Linguagem Figurativa. Usamos um conjunto de modelos RNN com LSTMs bidirecionais e mecanismos de atenção bidirecionais. Alguns dos modelos foram treinados em todas as partes do discurso. Cada um dos outros modelos foi treinado em uma das quatro categorias para partes do discurso: “substantivos”, “verbos”, “advérbios/adjetivos” ou “outros”. Os modelos foram combinados em grupos de votação e os grupos de votação foram combinados usando o operador lógico “OR”.</abstract_pt>
      <abstract_fr>Dans cet article, nous présentons les résultats de la deuxième tâche partagée sur la détection de métaphore, organisée par le Second Workshop on Figurative Language Processing. Nous utilisons un ensemble de modèles RNN avec des LSTM bidirectionnels et des mécanismes d'attention bidirectionnels. Certains modèles ont été formés sur toutes les parties du discours. Chacun des autres modèles a été formé à l'une des quatre catégories de parties du discours : « noms », « verbes », « adverbes/adjectifs » ou « autres ». Les modèles ont été combinés en groupes de vote et les pools de vote ont été combinés à l'aide de l'opérateur logique « OU ».</abstract_fr>
      <abstract_ja>本稿では、第2回比喩言語処理ワークショップ主催の第2回比喩検出共有タスクの結果を紹介する。双方向LSTMと双方向注目メカニズムを備えたRNNモデルのアンサンブルを使用しています。モデルの中には、音声のあらゆる部分について訓練を受けた者もいた。他の各モデルは、「名詞」、「動詞」、「副詞/形容詞」、または「その他」の4つのカテゴリのうちの1つについて訓練を受けました。モデルを投票プールに組み合わせ、投票プールを論理的な「OR」演算子を使用して組み合わせた。</abstract_ja>
      <abstract_zh>本文中,再喻言处研讨会主隐喻检第二。 用双向 LSTM 与双向 RNN 合。 诸模形于诸词性,皆加训练。 其他皆于词性四之一而教之:曰名词,曰动词,曰副词/形容词,曰其他。 并入投票池中,投票池以逻辑"OR"运算符合之。</abstract_zh>
      <abstract_ru>В этой статье мы представляем наши результаты из Второй общей задачи по обнаружению метафор, принимающей стороной которой является Второй семинар по обработке образного языка. Мы используем ансамбль моделей RNN с двунаправленными LSTM и двунаправленными механизмами внимания. Некоторые модели были обучены по всем частям речи. Каждая из других моделей обучалась по одной из четырех категорий для частей речи: «существительные», «глаголы», «наречия/прилагательные» или «другие». Модели были объединены в пулы для голосования, а пулы для голосования были объединены с помощью логического оператора «или».</abstract_ru>
      <abstract_hi>इस पेपर में हम रूपक का पता लगाने पर दूसरे साझा कार्य से हमारे परिणाम प्रस्तुत करते हैं, जो आलंकारिक भाषा प्रसंस्करण पर दूसरी कार्यशाला द्वारा आयोजित किया गया है। हम द्विदिश LSTMs और द्विदिश ध्यान तंत्र के साथ RNN मॉडल की एक टुकड़ी का उपयोग करें। कुछ मॉडलों को भाषण के सभी हिस्सों पर प्रशिक्षित किया गया था। अन्य मॉडलों में से प्रत्येक को भाषण के कुछ हिस्सों के लिए चार श्रेणियों में से एक पर प्रशिक्षित किया गया था: "संज्ञा", "क्रिया", "क्रियाविशेषण / विशेषण", या "अन्य"। मॉडल को मतदान पूल में जोड़ा गया था और मतदान पूल को तार्किक "या" ऑपरेटर का उपयोग करके जोड़ा गया था।</abstract_hi>
      <abstract_ga>Sa pháipéar seo cuirimid ár dtorthaí ón Dara Tasc Comhroinnte ar Bhrath Meafar i láthair, arna óstáil ag an Dara Ceardlann ar Phróiseáil Fíorúil Teanga. Bainimid úsáid as ensemble de shamhlacha RNN le LSTManna déthreocha agus meicníochtaí déthreoracha aird. Cuireadh oiliúint ar chuid de na múnlaí ar gach cuid cainte. Cuireadh oiliúint ar gach ceann de na múnlaí eile ar cheann de cheithre chatagóir do chodanna cainte: “ainmfhocail”, “briathra”, “adverbs/aidiachtaí”, nó “eile”. Cuireadh na samhlacha le chéile i gcomhthiomsaithe vótála agus cuireadh na comhthiomsaithe vótála le chéile ag baint úsáide as an oibreoir loighciúil “NÓ”.</abstract_ga>
      <abstract_ka>ამ დოკუნეში ჩვენ ჩვენი შედეგი მეორე გაყოფილი დავალების მეტაფორის განახლების შესახებ, რომელიც მეორე სამუშაო ფიგურატიური ენის პროცესის შესახებ დავწერა. ჩვენ გამოყენებთ RNN მოდელების სენემბელი, რომლებიც ორიდერექციონალური LSTMs და ორიდერექციონალური დაახლოების მექანემისთვის. ზოგიერთი მოდელები ყველა სიტყვების ნაწილში მოსწავლია. ყველა მეორე მოდელეების ერთ-ერთი 4 კატეგორიაში იყო სიტყვების ნაწილებისთვის: 'სახელი', 'გერბები', 'adverbs/adjectives', ან 'სხვა'. მოდელები შეიძლება გადაწყვეტილი ბასში და გადაწყვეტილი ბასენები შეიძლება ლოგიკური 'OR' ოპერატორის გამოყენებით.</abstract_ka>
      <abstract_el>Στην παρούσα εργασία παρουσιάζουμε τα αποτελέσματά μας από τη Δεύτερη Κοινή Εργασία για την Ανίχνευση Μεταφορών, που φιλοξενείται από το Δεύτερο Εργαστήριο Επεξεργασίας Εικαστικής Γλώσσας. Χρησιμοποιούμε ένα σύνολο μοντέλων με αμφίδρομες και αμφίδρομες προσοχής μηχανισμούς. Μερικά από τα μοντέλα εκπαιδεύτηκαν σε όλα τα μέρη της ομιλίας. Κάθε ένα από τα άλλα μοντέλα εκπαιδεύτηκε σε μία από τις τέσσερις κατηγορίες για τμήματα λόγου: "ουσιαστικά", "ρήματα", "επίθετα" ή "άλλα". Τα μοντέλα συνδυάστηκαν σε ομάδες ψηφοφορίας και οι ομάδες ψηφοφορίας συνδυάστηκαν χρησιμοποιώντας το λογικό χειριστή "OR".</abstract_el>
      <abstract_hu>Ebben a tanulmányban bemutatjuk a második közös feladat Metafór detektálásával kapcsolatos eredményeit, amelynek házigazdája a Figuratív Nyelvfeldolgozás Második Workshop. RNN modellek együttesét használjuk kétirányú LSTM-ekkel és kétirányú figyelem mechanizmusokkal. Néhány modellt képeztek a beszéd minden részére. A többi modellt a beszédrészek négy kategóriájának egyikére képezték: "főnevek", "igék", "határozók/melléknévek" vagy "más". A modelleket szavazócsoportokká alakították, és a szavazócsoportokat a logikus "OR" operátor használatával kombinálták.</abstract_hu>
      <abstract_it>In questo articolo presentiamo i risultati del Secondo Task Condiviso sulla Metaphor Detection, ospitato dal Secondo Workshop sull'elaborazione del linguaggio figurativo. Usiamo un insieme di modelli RNN con LSTMs bidirezionali e meccanismi di attenzione bidirezionali. Alcuni dei modelli sono stati addestrati su tutte le parti del discorso. Ciascuno degli altri modelli è stato addestrato su una delle quattro categorie per parti del discorso: "sostantivi", "verbi", "avverbi/aggettivi" o "altro". I modelli sono stati combinati in pool di voto e i pool di voto sono stati combinati utilizzando l'operatore logico "OR".</abstract_it>
      <abstract_kk>Бұл қағазда біз, фигурациялық тіл процессіндегі Екінші жұмыс істеу үшін, Екінші бөлшекті тапсырманың нәтижесін келтіреміз. Біз RNN үлгілерін қолдануға арналған LSTMs және екі директориялық қатынау механизмтерімен қолданамыз. Кейбір моделдер сөйлеу бөлігінде оқылған. Басқа үлгілердің бірі сөйлеу үшін төрт санаттарының бірінде оқылған: 'атаулар', 'вертолар', 'adverbs/adjectives', немесе 'басқа' деген бөліктерінің бірінде оқылған. Үлгілер санау көмегімен біріктірілген және санау көмегімен логикалық 'OR' операторымен біріктірілген.</abstract_kk>
      <abstract_lt>Šiame dokumente pristatome savo rezultatus iš Antrosios bendros užduoties metaforų aptikimo srityje, kurią surengė Antrasis grafinio kalbų apdorojimo seminaras. Naudojame RNN modelių rinkinį su dvikryptiniais LSTM ir dvikryptiniais dėmesio mechanizmais. Kai kurie modeliai buvo apmokyti visose kalbos dalyse. Kiekvienas kitas modelis buvo apmokytas vienoje iš keturių kategorijų kalbos dalims: „vardai“, „žodžiai“, „reklamos/priedai“ arba „kiti“. Modeliai buvo sujungti į balsavimo grupes, o balsavimo grupės buvo sujungtos naudojant logišką „AR“ operatorių.</abstract_lt>
      <abstract_mk>Во овој весник ги претставуваме нашите резултати од втората заедничка задача за детекција на метафорите, домаќин на втората работилница за фигуративно јазичко процесирање. Користиме ансембл на РНН модели со двојно ЛСТМ и двојно внимание механизми. Некои од моделите беа обучени на сите делови од говорот. Each of the other models was trained on one of four categories for parts of speech: 'nouns', 'verbs', 'adverbs/adjectives', or 'other'.  Моделите беа комбинирани во гласачки групи и гласачките групи беа комбинирани користејќи го логичкиот оператор „ОР“.</abstract_mk>
      <abstract_ms>Dalam kertas ini kami memperkenalkan keputusan kami dari Tugas Berkongsi Kedua untuk Pengesanan Metafora, ditempatkan oleh Workshop Kedua untuk Pemprosesan Bahasa Figuratif. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms.  Beberapa model telah dilatih dalam semua bahagian ucapan. Setiap model lainnya dilatih pada salah satu dari empat kategori untuk bahagian-bahagian ucapan: 'nama', 'verbs', 'adverbs/adjectives', atau 'other'. Model ini digabungkan ke kolam suara dan kolam suara digabungkan menggunakan operator 'OR' logik.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ നമ്മള്‍ രണ്ടാമത്തെ പങ്കാളിയുള്ള ജോലിയില്‍ നിന്നും നമ്മുടെ ഫലങ്ങള്‍ കാണിച്ചുകൊണ്ടിരിക്കുന്നു. മെറ്റാപ്പോര്‍ ഡി We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms.  സംസാരിക്കുന്ന എല്ലാ ഭാഗങ്ങളിലും ചില മോഡലുകള്‍ പരിശീലിക്കപ്പെട്ടിരുന്നു. വാക്കിന്റെ ഭാഗങ്ങളില്‍ നാലു വിഭാഗങ്ങളില്‍ ഒരാള്‍ക്കും മറ്റൊരു മോഡല്‍ പരിശീലനം നല്‍കപ്പെട്ടിരുന്നു: “നിര്‍മ്മിക്കുന്നു”വ മോഡലുകള്‍ വോട്ട് പൂളിലേക്ക് കൂട്ടിയിരുന്നു. വോട്ട് ചെയ്യുന്ന പൂളുകള്‍ ലോഗിക്കല്‍ 'OR' ഓപ്പറേറ്റര്‍ ഉപയോഗ</abstract_ml>
      <abstract_mn>Энэ цаасан дээр бид хоёр дахь хуваалтын ажлын үр дүнг Metaphor Detection-ын хоёр дахь ажлын талаар тайлбарлаж байна. Бид ДНХ загварын загварыг хоёр дахь LSTMs болон хоёр дахь анхаарлын механизмтай ашигладаг. Зарим загварууд ярианы бүх хэсэгт суралцагдсан. Өөр загварын нэг нь хэлэлцээний нэг хэсэгт 4 хэсэгт суралцагдсан: нэр, үг, adverbs/adjectives, эсвэл нөгөө хэсэгт суралцагдсан. Загварууд нь сонголтын цуглуулга болон сонголтын цуглуулга нь логикийн 'OR' операторыг ашиглан холбогдсон.</abstract_mn>
      <abstract_no>I denne papiret viser vi resultatet våre frå den andre delte oppgåva om metafordeteksjon, vert vert av den andre arbeidsområdet på figurativ språk. Vi bruker en ensembel av RNN-modeller med bidireksjonale LSTMs og bidireksjonale oppmerksmekanisme. Noen av modellen ble trent på alle taledeler. Kvar av dei andre modelane var trengd på ein av fire kategoriar for deler av tale: namn", "verbar", "adverbs/adjectives" eller "andre". Modellene vart kombinerte i stemmepoolar og stemmepoolane vart kombinerte med den logiske « OR »-operatoren.</abstract_no>
      <abstract_pl>W niniejszym artykule przedstawiamy nasze wyniki drugiego wspólnego zadania dotyczącego wykrywania metaforów, prowadzonego przez Drugie Warsztaty Przetwarzania Języka Obrazowego. Wykorzystujemy zespół modeli RNN z dwukierunkowymi LSTMami i dwukierunkowymi mechanizmami uwagi. Niektóre z modeli zostały przeszkolone we wszystkich częściach mowy. Każdy z pozostałych modeli został przeszkolony na jednej z czterech kategorii dla części mowy: "rzeczowników", "czasowników", "przysłówek/przymiotników" lub "inny". Modele zostały połączone w pule głosów, a pule głosów zostały połączone przy użyciu logicznego operatora "OR".</abstract_pl>
      <abstract_ro>În această lucrare prezentăm rezultatele celei de-a doua sarcini comune privind detectarea metaforelor, găzduite de cel de-al doilea atelier privind procesarea limbajului figurativ. Folosim un ansamblu de modele RNN cu LSTMs bidirecționale și mecanisme bidirecționale de atenție. Unele dintre modele au fost instruite în toate părțile vorbirii. Fiecare dintre celelalte modele a fost instruit pe una din cele patru categorii pentru părți de vorbire: "substantive", "verbe", "adverbs/adjective" sau "altele". Modelele au fost combinate în grupuri de vot, iar grupurile de vot au fost combinate folosind operatorul logic "RUP".</abstract_ro>
      <abstract_sr>U ovom papiru predstavljamo rezultate drugog zajedničkog zadatka o detekciji metafora, domaćin drugog radionice o procesu figurativnog jezika. Koristimo ensemble RNN modela sa dvodirektivnim LSTMs-om i mehanizama za dvodirektivnu pažnju. Neki od modela su obučeni na svim dijelovima govora. Svaki od ostalih modela je obučen na jednoj od četiri kategorije za dijelove govora: "imena", "verbe", "adverbs/adjektives", ili "druge". Modeli su bili kombinirani u bazenima glasanja i bazeni glasanja su kombinirani koristeći logički operator OR-a.</abstract_sr>
      <abstract_si>මේ පත්තරේ අපි අපේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිපරීක්ෂණය සඳහා දෙවෙනි කාර්යාලයේ  අපි RNN මොඩල් එකක් පාවිච්චි කරනවා දෙන්න පුළුවන් LSTMs සහ දෙන්න පුළුවන් අවධානයක් තියෙනවා. මොඩල් එක්කෙන් සියළුම් කතාවේ සියළු කොටස් වලින් ඉගෙන ගත්තා. අනිත් මෝඩල් එක්කෙනෙක්ම කතාවේ කොටස් හතරක් එක්කෙනෙක්ට ප්‍රශ්නය කරලා තියෙනවා: 'නම්', 'වර්ගස්', 'adverts/adiectives', නැත්තම් මොඩේල් එකතු වුනා බෝට් පුල් එක්ක සම්බන්ධ වුනා ඒ වගේම බෝට් පුල් එකතු වුනා ලෝජික 'OR' ඔපරේටර් එකතු වු</abstract_si>
      <abstract_so>Warqaddan waxaan ka keenaynaa resultiyadeena ee shaqada labaad ee la sharciyey ku saabsan baaritaanka Metaphor, waxaana hosted ka dhigay warqada labaad ee ku saabsan Processing Figurative Luqada. Waxaynu isticmaalnaa muusiko RNN ah oo ay leedahay bidirectional LSTMs iyo mechanisyo booqan. Tusaale kamid ah waxaa lagu tababaray qeybaha hadalka oo dhan. Tusaale kale waxaa laga baray mid ka mid ah afarta kooxood oo hadal ah, noocyada, afka, ganacsiga/iskuwiya ama 'kale'. Tusaalada waxaa lagu isku darsaday balliyada codeynta, balliyada codeynta waxaa lagu soo ururiyey isticmaalka qofka maamulka la xiriira 'OR'.</abstract_so>
      <abstract_sv>I den här uppsatsen presenterar vi våra resultat från den andra gemensamma uppgiften om metaphor detection, värd för den andra workshopen om figurativ språkbehandling. Vi använder oss av en uppsättning RNN-modeller med dubbelriktade LSTMs och dubbelriktade uppmärksamhetsmekanismer. Några av modellerna tränades i alla delar av tal. Var och en av de andra modellerna tränades i en av fyra kategorier för taldelar: "substantiv", "verb", "adverb/adjektiv" eller "andra". Modellerna kombinerades till röstpooler och röstpoolerna kombinerades med hjälp av den logiska operatören "OR".</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் நாம் மெட்போர் கண்டுபிடிப்பதில் இரண்டாவது பகிர்ந்த பணியில் இருந்து முடிவு நாங்கள் RNN மாதிரிகளின் ஒரு ஒதுக்கீட்டை பயன்படுத்துகிறோம் பிடிட்டர் எஸ்டிஎஸ் மற்றும் பிடிவின் கவனம் முறைமை சில மாதிரிகள் பேச்சின் அனைத்து பகுதிகளிலும் பயிற்சி செய்யப்பட்டது. பேச்சின் பகுதிகளில் நான்கு வகுப்பில் ஒவ்வொரு மாதிரியிலும் பயிற்சி செய்யப்பட்டுள்ளது 'நூன்' , 'வார்ப்புகள்', 'வார்புகள இந்த மாதிரிகள் வாக்குதல் குளிகளில் சேர்க்கப்பட்டுள்ளது மற்றும் வாக்குதல் குளிகள் தொகுதியில் 'OR' செயல்பாட</abstract_ta>
      <abstract_ur>ہم اس کاغذ میں اپنے نتائج کو متفاوری شناسی کے بارے میں دوسرے شریک ٹاکس سے پیش کریں گے، جسے دوسرا کارشاپ فیگوریٹی زبان پردازی کے بارے میں حاضر کیا گیا ہے. ہم نے RNN نمڈلوں کا ایک انڈیلس استعمال کرتا ہے جو دوسری مسائل LSTMs اور دوسری مسائل توجه کی مکانیزوں کے ساتھ ہے. کچھ موڈل کلام کے تمام قسموں پر آموزش کی گئی تھی۔ اور ایک دوسرے نمونوں میں سے چار قسموں میں سے ایک کی تعلیم کی گئی تھی کہ زبان کی قسموں کے لئے نام، verbs، adverbs/adjectives، یا دوسرے قسموں کے لئے۔ نمڈلے ٹوٹنگ پول میں جمع کئے گئے اور وٹنگ پول منطقی 'OR' اپراتر کے مطابق جمع کئے گئے۔</abstract_ur>
      <abstract_mt>F’dan id-dokument nippreżentaw ir-riżultati tagħna mit-Tieni Kompitu Konġunt dwar id-Detezzjoni tal-Metafori, ospitat mit-Tieni Workshop dwar l-Ipproċessar tal-Lingwi Figurattivi. Aħna nużaw ensemble ta’ mudelli RNN b’LSTMs bidirezzjonali u mekkaniżmi ta’ attenzjoni bidirezzjonali. Xi wħud mill-mudelli ġew imħarrġa fuq il-partijiet kollha tad-diskors. Kull wieħed mill-mudelli l-oħra ġie mħarreġ f'waħda minn erba' kategoriji għal partijiet ta' diskors: 'nomi', 'verbs', 'adverbs/adjectives', jew 'oħrajn'. Il-mudelli ġew ikkombinati f’gruppi ta’ votazzjoni u l-gruppi ta’ votazzjoni ġew ikkombinati bl-użu tal-operatur loġiku “OR”.</abstract_mt>
      <abstract_uz>Bu hujjatda biz birinchi qidirilgan Vazifaning natijalarimizni o'rganimiz, Figurativ tillar jarayonini boshqarish uchun ikkinchi qanday ishni o'rganamiz. Biz birinchi LSTMs va bir qanchalik taqdimot mechanislari bilan RNN modellaridan foydalanamiz. Ba'zi modellar hamma gapirish qismlarida o'rgandi. Boshqa modellarning biri to'rt turdagi qismlardan o'rganilgan edi: ‘nuts’, ‘‘verbs’, ‘‘ishlab chiqaruvchilar’ yoki boshqa qismlarda. Modellar voting qoidalariga birlashtirilgan va voting qoidalari "OR" operator yordamida birlashtirilgan.</abstract_uz>
      <abstract_vi>Trong tờ giấy này chúng tôi giới thiệu kết quả của công việc chia sẻ về trinh sát siêu dẫn, được tổ chức bởi Xưởng Công nghệ Tiếng Anh thứ hai. Chúng tôi sử dụng một kết hợp các mô hình RNN với LSTM di động và các biện pháp gây chú ý trực tiếp. Một số người mẫu được huấn luyện trong tất cả các bộ phận nói. Mỗi loại mẫu khác được đào tạo trên một trong bốn loại cho các bộ phận văn bản: "danh từ, động từ, từ tính, hay'khác'. Các mẫu được kết hợp trong các hồ sơ bầu cử và các hồ sơ bầu cử được kết hợp với hệ thống "OR" logic.</abstract_vi>
      <abstract_bg>В настоящата статия представяме резултатите от Втората споделена задача за откриване на метафори, домакин на Втората работна среща за обработка на фигуративни езици. Използваме ансамбъл от модели с двупосочни ЛСТМ и двупосочни механизми за внимание. Някои от моделите бяха обучени по всички части на речта. Всеки от другите модели е обучен по една от четири категории за части от речта: "съществителни", "глаголи", "adverbs/прилагателни" или "други". Моделите бяха комбинирани в групи за гласуване, а пуловете за гласуване бяха комбинирани с помощта на логичния оператор "ОР".</abstract_bg>
      <abstract_hr>U ovom papiru predstavljamo rezultate drugog zajedničkog zadatka o detekciji metafora, domaćin Drugog radionica o procesu figurativnog jezika. Koristimo ensemble RNN modela s bidirektivnim LSTMs-om i mehanizama za dvodirektivnu pažnju. Neki od modela su obučeni na svim dijelovima govora. Svaki od ostalih modela je obučen na jednoj od četiri kategorije za dijelove govora: 'imena', 'verbi', 'adverbs/adjectives', ili 'drugi'. Modeli su bili kombinirani u bazenima glasanja i bazeni glasanja su kombinirani koristeći logički operator OR-a.</abstract_hr>
      <abstract_da>I denne artikel præsenterer vi vores resultater fra Second Shared Task on Metaphor Detection, afholdt af Second Workshop on Figurative Language Processing. Vi bruger et ensemble af RNN modeller med to retninger LSTMs og to retninger opmærksomhedsmekanismer. Nogle af modellerne blev trænet i alle dele af tale. Hver af de andre modeller blev uddannet i en af fire kategorier for taledele:"substantiver", "verber", "adverbs/adjektiver" eller "andet". Modellerne blev kombineret i stemmepuljer, og stemmepuljer blev kombineret ved hjælp af den logiske operatør"OR".</abstract_da>
      <abstract_nl>In dit artikel presenteren we onze resultaten van de Tweede Gedeelde Task on Metafore Detection, georganiseerd door de Tweede Workshop on Figurative Language Processing. We gebruiken een ensemble van RNN modellen met bidirectionele LSTMs en bidirectionele aandachtsmechanismen. Sommige modellen werden getraind op alle delen van spraak. Elk van de andere modellen werd getraind op een van de vier categorieën voor delen van spraak: 'zelfstandige naamwoorden', 'werkwoorden', 'bijwoorden/bijvoeglijke naamwoorden' of 'ander'. De modellen werden gecombineerd tot stempools en de stempools werden gecombineerd met behulp van de logische operator 'OR'.</abstract_nl>
      <abstract_de>In diesem Beitrag stellen wir unsere Ergebnisse der zweiten gemeinsamen Aufgabe zur Metaphernerkennung vor, die vom zweiten Workshop zur Bildsprachverarbeitung veranstaltet wird. Wir verwenden ein Ensemble von RNN-Modellen mit bidirektionalen LSTMs und bidirektionalen Aufmerksamkeitsmechanismen. Einige der Modelle wurden in allen Teilen der Sprache trainiert. Jedes der anderen Modelle wurde auf eine der vier Kategorien für Sprachteile trainiert: "Substantive", "Verben", "Adverbien/Adjektive" oder "Andere". Die Modelle wurden zu Voting Pools kombiniert und die Voting Pools mit dem logischen Operator OR kombiniert.</abstract_de>
      <abstract_ko>본고에서 우리는 두 번째 은유 검측 공유 임무의 결과를 보여 주었는데 이 임무는 두 번째 비유 언어 처리 세미나에서 주최한다.양방향 LSTM과 양방향 주의 메커니즘을 갖춘 RNN 모델 세트를 사용했습니다.일부 모델들은 모든 단어의 훈련을 받았다.다른 모든 모델은 어류의 네 가지 유형 중 하나인'명사','동사','부사/형용사'또는'기타'의 훈련을 받았다.모델이 투표지에 통합되고 투표지는 논리적인'OR'조작부호를 사용하여 조합된다.</abstract_ko>
      <abstract_id>Dalam kertas ini kami memperkenalkan hasil kami dari Tugas Berkongsi Kedua untuk Deteksi Metafora, diterima oleh Workshop Kedua tentang Proses Bahasa Figuratif. Kami menggunakan ensemble model RNN dengan LSTM bidireksi dan mekanisme perhatian bidireksi. Beberapa model dilatih dalam semua bagian pidato. Masing-masing model lainnya dilatih pada salah satu dari empat kategori untuk bagian-bagian pidato: 'nama', 'verb', 'adverbs/adjectives', atau 'lain'. Modelnya dikombinasikan ke kolam pemilihan dan kolam pemilihan dikombinasikan menggunakan operator 'OR' logis.</abstract_id>
      <abstract_sw>In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing.  Tunatumia mfumo wa mifano ya RNN yenye utaratibu wa LSTMs na mfumo wa ufuatiliaji. Baadhi ya mifano ilifundishwa katika maeneo yote ya hotuba. Kila mifano mingine ilifundishwa kwa moja ya makundi minne kwa ajili ya hotuba Mfano huo uliunganishwa kwenye vituo vya kupigia kura na vituo vya kura viliunganishwa kwa kutumia operereta ya kilogical 'OR'.</abstract_sw>
      <abstract_tr>Bu kagyzda çykyşlarymyzy Metaforyň 2-nji Paýlaşy Görevinden tanyşdyrýarys, figurativ dil işleýişinde 2-nji Çykyş tarapyndan bellenilýäris. Biz RNN nusgalarynyň köp görkezilişi LSTM we ikinji dikkati meýdançalary bilen ulanýarys. Käbir nusgalar çykyş bölgelerinde bilim alypdyr. Beýleki nusgalaryň biri "isim", "verb", "adverbs/adjectives" dört sanlaryň birinde okalýardy. Modeller ses poollerine birleşildi we saýlaw poolleri logik 'OR' operatörüni ulanyp birleşildi.</abstract_tr>
      <abstract_af>In hierdie papier voorsien ons resultate van die tweede Gedeelde Opdrag op Metafordeteksie, bediener deur die tweede Werkshop op Figurasietaal Prosessering. Ons gebruik 'n ensemble van RNN modele met bidirectional LSTMs en bidirectional attention mechanisms. Sommige van die modele is opgelei op alle dele van praat. Elkeen van die ander modele is onderwerp op een van vier kategorie vir dele van spreek: noume, 'verbe', 'adverbs/adjectives', of 'ander'. Die modele was gekombineer in stem pools en die stem pools was gekombineer met die logiese 'OR' operator.</abstract_af>
      <abstract_sq>Në këtë letër ne paraqesim rezultatet tona nga Detyra e Dytë e Përbashkët për Detektimin e Metaforës, pritur nga Workshop i Dytë për Procesimin e Gjuhave Figurative. Ne përdorim një grup modelesh RNN me LSTM dy drejtues dhe mekanizma vëmendje dy drejtues. Disa nga modelet u trajnuan në të gjitha pjesët e fjalimit. Secili nga modelet e tjerë u trajnua në një nga katër kategoritë për pjesë të fjalimit: "emra", "verbe", "adverbs/adjectives" ose "tjetër". Modelet u kombinuan në grupe votimi dhe grupet votuese u kombinuan duke përdorur operatorin logjik 'OR'.</abstract_sq>
      <abstract_am>በዚህ ፕሮግራም በሁለተኛው የተሰራጨውን ስራዎችን በመፍጠር ላይ እናቀርባታለን፡፡ የ.ኤን.ን ዓይነቶች እና የ.ኤስቴሲ እና የጥያቄ አካሄድ አካባቢዎችን እናስቀምጣለን፡፡ አንዳንዶቹ በንግግር ሁሉ ተማሩ:: ሌሎቹ ዓይነቶች አንዱ በአራቱ ክፍል ላይ ተማርቷል ‹ንቱ›› ንግግር፣ ‹መዝገብ›› ወይም ‹ሌላ›› ምሳሌዎቹ ወደ ድምፅ አዋቂዎች ተደጋግመው ነበር፣ የድምፅ ጉዳዮቹ የሎጂካዊ 'OR' ተሟጋቾችን በመጠቀም ተደጋግመው ነበር፡፡</abstract_am>
      <abstract_fa>در این کاغذ ما نتیجه‌هایمان را از کار دوم مشترک در مورد بازرسی متافور نشان می‌دهیم، که توسط کارگاه دوم در مورد پرداخت زبان تصاویر مهمان شده است. ما از نمونه های RNN استفاده می کنیم با مکانیسم های توجه دوم‌ترکیب LSTMs و مکانیسم‌های توجه دوم‌ترکیب. بعضی از مدلها در تمام قسمت سخنرانی آموزش داده شدند. هر یک از مدلهای دیگر بر یکی از چهار کلاس برای بخشی از گفتار آموزش داده شد: اسم‌ها، کلمه‌ها، تبلیغ‌ها، یا دیگر. مدل‌ها در استخره‌های رای دادن ترکیب شده‌اند و استخره‌های رای با استفاده از عملکرد منطقی OR ترکیب شده‌اند.</abstract_fa>
      <abstract_az>Bu kağızda, ikinci paylaşılmış işimizi Metaforlar keşfetməsi barəsində, Figurative Dil İşləməsi barəsində qonaqbaylıq edən İkinci İşləşmiş işimizdən göstəririk. Bizim RNN modellərini ikidiktiraqlı LSTMs və ikidiktiraqlı gözləmə mehanizmiləri ilə istifadə edirik. Bazı modellərdən sözlərin bütün hissələrində təhsil edildi. Diğer modellərin hər biri dörd kategoriyada sözlərin bir hissəsi üçün təhsil edildi: "Adlar", "verblər", "adverbs/adjectives" və ya "digər qismi". Modellər səslənmə poollara birləşdirildi və səslənmə poolları lojik 'OR' operatörü ilə birləşdirildi.</abstract_az>
      <abstract_hy>Այս թղթի մեջ մենք ներկայացնում ենք մեր արդյունքները Մետաֆորայի հայտնագործման երկրորդ հանձնարարության արդյունքներից, որը կազմակերպել է Ֆիգերատիվ լեզվի մշակույթի երկրորդ աշխատասենյակում: Մենք օգտագործում ենք ՌՆԹ մոդելների համակարգ, որը ունի երկու ուղղությամբ ԼՍԹՄ-ներ և երկու ուղղությամբ ուշադրության մեխանիզմներ: Մոդելներից ոմանք սովորեցրել են խոսքի բոլոր մասերում: Մյուս մոդելներից յուրաքանչյուրը սովորեցրել է խոսակցության չորս կատեգորիաներից մեկի վրա՝ «անուններ», «բայեր», «արձագանքներ», «բայեր», կամ «այլ»։ The models were combined into voting pools and the voting pools were combined using the logical 'OR' operator.</abstract_hy>
      <abstract_bn>এই কাগজটিতে আমরা দ্বিতীয় শেয়ার করা কাজের ফলাফল উপস্থাপন করছি মেটাপোর ডিটেক্টরের উপর, যা ফিগারেটিভ ভাষা প্রক্রিয়ার দ্বিতীয় ওয়ার আমরা RNN মডেল ব্যবহার করি বিদ্যুৎ এলস্টিএমএস এবং বিদ্যুৎ মনোযোগ মেক্সিমের সাথে। কিছু মডেল প্রশিক্ষণ প্রদান করা হয়েছিল বাক্যালের সকল অংশে। Each of the other models was trained on one of four categories for parts of speech: 'nouns', 'verbs', 'adverbs/adjectives', or 'other'.  মডেলগুলো ভোট পুলে একত্রিত হয়েছিল এবং ভোট দিয়েছিল ভোট পুল ব্যবহার করেছিল 'OR' অপারেটর।</abstract_bn>
      <abstract_et>Käesolevas dokumendis tutvustame oma tulemusi teisest ühisest ülesandest metafoori tuvastamiseks, mida korraldab teine kujutava keele töötlemise seminar. Kasutame RNN mudelite ansamblit kahesuunaliste LSTMde ja kahesuunaliste tähelepanumehhanismidega. Mõned mudelid olid koolitatud kõigile kõnedele osadele. Kõiki teisi mudeleid koolitati ühes neljast kõneosade kategooriast: "nimisõnad", "tegusõnad", "adverbid/omadussõnad" või "muu". Mudelid kombineeriti hääletamiskogumiteks ja hääletamiskogumid kombineeriti loogilise OR operaatori abil.</abstract_et>
      <abstract_cs>V tomto článku prezentujeme naše výsledky Druhého sdíleného úkolu na detekci metaforem, který pořádá Druhý workshop o zpracování obrazového jazyka. Používáme soubor RNN modelů s obousměrnými LSTMs a obousměrnými pozornostními mechanismy. Některé modely byly trénovány na všech částech řeči. Každý z ostatních modelů byl trénován na jedné ze čtyř kategorií pro části řeči: "podstatná jména", "slovesa", "přísloví/přídavná jména" nebo "jiná". Modely byly kombinovány do hlasovacích fondů a hlasovací fondy byly kombinovány pomocí logického operátora OR.</abstract_cs>
      <abstract_ca>En aquest article presentem els nostres resultats de la Segona Task Compartida sobre la Detecció de Metafòries, que va aconseguir la Segona Workshop sobre Procesament de Llingues Figuratius. Utilitzem un conjunt de models RNN amb LSTMs bidireccionals i mecanismes d'atenció bidireccionals. Alguns dels models van ser entrenats en totes les parts del discurs. Cada un dels altres models va ser entrenat en una de les quatre categories per parts de discurs: "noms", "verbs", "adverbs/adjectius" o "altres". Els models van ser combinats en grups de votació i els grups de votació van ser combinats utilitzant l'operador lògic "OR".</abstract_ca>
      <abstract_fi>Tässä artikkelissa esittelemme tulokset toisesta metaforin havaitsemista koskevasta jaetusta tehtävästä, jota isännöi toinen kuvitteellisen kielen prosessointia käsittelevä työpaja. Käytämme RNN-malleja, joissa on kaksisuuntaiset LSTMs:t ja kaksisuuntaiset huomiomekanismit. Osa malleista koulutettiin puheen kaikkiin osiin. Kukin muu malli koulutettiin yhteen neljästä puheen osasta kategoriasta: "substantiivit", "verbit", "adverbit/adjektiivit" tai "muut". Mallit yhdistettiin äänestyspooleiksi ja äänestyspoolit yhdistettiin loogisella OR-operaattorilla.</abstract_fi>
      <abstract_bs>U ovom papiru predstavljamo rezultate drugog zajedničkog zadatka o detekciji metafora, domaćin drugog radionice o procesu figurativnog jezika. Koristimo ensemble RNN modela sa dvodirektivnim LSTMs-om i mehanizama za dvodirektivnu pažnju. Neki od modela su obučeni na svim dijelovima govora. Svaki od ostalih modela je obučen na jednoj od četiri kategorije za dijelove govora: "imena", "verba", "adverbs/adjectives", ili "drugi". Modeli su bili kombinirani u bazenima glasanja i bazeni glasanja su kombinirani koristeći logički operator OR-a.</abstract_bs>
      <abstract_he>בעיתון הזה אנחנו מציגים את התוצאות שלנו מהמשימה המשותפת השנייה על גילוי מטאפורה, מארחת על ידי העבודה השנייה על תהליך שפה פיגורטיבי. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms.  חלק מהדוגמנים היו מאומנים בכל חלקי הנאום. כל אחד מהדוגמנים האחרים היה מאומן באחד מארבע הקטגוריות לחלקים של דיבור: "שמות", "פרחים", "פרחים/אדיקטיבים", או "אחרים". הדוגמנים שולבו לבריכות הצבעה ובריכות הצבעה שולבו באמצעות המפעיל "OR" הגיוני.</abstract_he>
      <abstract_sk>V tem prispevku predstavljamo rezultate druge skupne naloge o zaznavanju metafore, ki jo gosti druga delavnica o obdelavi figurativnega jezika. Uporabljamo ansambel RNN modelov z dvosmernimi LSTMi in dvosmernimi mehanizmi pozornosti. Nekateri modeli so bili usposobljeni za vse dele govora. Vsak od drugih modelov je bil usposobljen za eno od štirih kategorij za dele govora: "samostalniki", "glagoli", "adverbi/pridevniki" ali "drugi". Modeli so bili združeni v glasovalne skupine, glasovalne skupine pa so bile združene z uporabo logičnega operaterja "OR".</abstract_sk>
      <abstract_ha>A cikin wannan takarda, Munã bãyar da matsalayinmu daga Filin aiki na biyu wanda aka Shara wa Tafiyar da Metafor Tuna amfani da wata misãlai na RNN da kuma masu sakan aikin muhimmanci. Some of the models were trained on all parts of speech.  Kuma an sanar wa kõwa daga misalin na daban a kan ɗayan ƙungiyõyi huɗu wa rabon magana, 'na'ya', 'kunnuwa', 'abubuwa', 'masu shawara', 'masu shawara', ko 'na'yan'... An haɗa misalin su cikin basuɗun sauti, kuma aka haɗa samun sunãyen kura da aka yi amfani da afaretan 'OR' na fasa.</abstract_ha>
      <abstract_bo>འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོའི་རྒྱབ་སྐྱོར་མིང་ཐོག་ལས་རྐྱེན་ཚོར་བ་མང་པོ་ཞིག་གི་ནང་དུ་བཏུབ་པ ང་ཚོས་དཔལ་མཐོང་ནུས་པའི་རྣམ་པ་གྱི་དཔེ་དབྱིབས་ཞིག་སྤྱོད་ཀྱི་གཟུགས་རིས། སྨྲ་བརྗོད་ཀྱི་ཆ་ཤས་གཅིག་ནི་སློབ་བརྗོད་ཀྱི་གོ་སྐབས་མཉམ་དུ་آموزش སོང་བ་རེད། སྐད་བརྗོད་ཀྱི་མིག The models were combined into voting pools and the voting pools were combined using the logical 'OR' operator.</abstract_bo>
      <abstract_jv>mi Awak dhéwé éntuk sistem karo model R-N sing dibenalke nggo barang-barang LTT M lan mekanihan sing dibenalke nggawe barang. Bapak model sing ditambah kelas segala saiki banget Sampeyan nganggo model sing wis arep ditambah ning sampeyan kat kategori sing gawe barang kelas 'nambah', 'verbs', 'Advrbs/adiectivers', 'wis ala saiki. Validity</abstract_jv>
      </paper>
    <paper id="35">
      <title>Testing the role of <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a> in metaphor identification</title>
      <author><first>Egon</first><last>Stemle</last></author>
      <author><first>Alexander</first><last>Onysko</last></author>
      <pages>256–263</pages>
      <abstract>This paper describes the adaptation and application of a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network system</a> for the automatic detection of metaphors. The LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a> given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a> influence the <a href="https://en.wikipedia.org/wiki/System">system</a> performance in the task of automatic metaphor identification. The <a href="https://en.wikipedia.org/wiki/System">system</a> is available under the APLv2 open-source license.</abstract>
      <url hash="b5fcbc81">2020.figlang-1.35</url>
      <doi>10.18653/v1/2020.figlang-1.35</doi>
      <video href="http://slideslive.com/38929730" />
      <bibkey>stemle-onysko-2020-testing</bibkey>
    </paper>
    </volume>
</collection>