<?xml version='1.0' encoding='utf-8'?>
<collection id="S19">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*<fixed-case>SEM</fixed-case> 2019)</booktitle>
      <url hash="da651103">S19-1</url>
      <editor><first>Rada</first><last>Mihalcea</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <editor><first>Lun-Wei</first><last>Ku</last></editor>
      <editor><first>Kilian</first><last>Evang</last></editor>
      <editor><first>Soujanya</first><last>Poria</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="5ccfc31b">S19-1000</url>
      <bibkey>semeval-2019-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>SURel : A Gold Standard for Incorporating Meaning Shifts into Term Extraction<fixed-case>SUR</fixed-case>el: A Gold Standard for Incorporating Meaning Shifts into Term Extraction</title>
      <author><first>Anna</first><last>Hätty</last></author>
      <author><first>Dominik</first><last>Schlechtweg</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>1–8</pages>
      <abstract>We introduce SURel, a novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with human-annotated meaning shifts between general-language and domain-specific contexts. We show that meaning shifts of term candidates cause errors in <a href="https://en.wikipedia.org/wiki/Term_extraction">term extraction</a>, and demonstrate that the SURel annotation reflects these errors. Furthermore, we illustrate that SURel enables us to assess optimisations of term extraction techniques when incorporating meaning shifts.</abstract>
      <url hash="cd5e172d">S19-1001</url>
      <doi>10.18653/v1/S19-1001</doi>
      <bibkey>hatty-etal-2019-surel</bibkey>
    </paper>
    <paper id="7">
      <title>Second-order contexts from lexical substitutes for few-shot learning of word representations</title>
      <author><first>Qianchu</first><last>Liu</last></author>
      <author><first>Diana</first><last>McCarthy</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>61–67</pages>
      <abstract>There is a growing awareness of the need to handle rare and unseen words in word representation modelling. In this paper, we focus on few-shot learning of emerging concepts that fully exploits only a few available contexts. We introduce a substitute-based context representation technique that can be applied on an existing word embedding space. Previous context-based approaches to modelling unseen words only consider bag-of-word first-order contexts, whereas our method aggregates contexts as second-order substitutes that are produced by a sequence-aware sentence completion model. We experimented with three <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> that aim to test the modelling of emerging concepts. We found that these tasks show different emphasis on first and second order contexts, and our substitute-based method achieves superior performance on naturally-occurring contexts from corpora.</abstract>
      <url hash="33028942">S19-1007</url>
      <doi>10.18653/v1/S19-1007</doi>
      <bibkey>liu-etal-2019-second</bibkey>
    </paper>
    <paper id="8">
      <title>Pre-trained Contextualized Character Embeddings Lead to Major Improvements in Time Normalization : a Detailed Analysis</title>
      <author><first>Dongfang</first><last>Xu</last></author>
      <author><first>Egoitz</first><last>Laparra</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>68–74</pages>
      <abstract>Recent studies have shown that pre-trained contextual word embeddings, which assign the same word different vectors in different contexts, improve performance in many tasks. But while contextual embeddings can also be trained at the character level, the effectiveness of such <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> has not been studied. We derive character-level contextual embeddings from Flair (Akbik et al., 2018), and apply them to a time normalization task, yielding major performance improvements over the previous state-of-the-art : 51 % error reduction in news and 33 % in clinical notes. We analyze the sources of these improvements, and find that pre-trained contextual character embeddings are more robust to term variations, infrequent terms, and cross-domain changes. We also quantify the size of context that pre-trained contextual character embeddings take advantage of, and show that such embeddings capture features like part-of-speech and <a href="https://en.wikipedia.org/wiki/Capitalization">capitalization</a>.</abstract>
      <url hash="12f5adfe">S19-1008</url>
      <doi>10.18653/v1/S19-1008</doi>
      <bibkey>xu-etal-2019-pre</bibkey>
    </paper>
    <paper id="9">
      <title>Bot2Vec : Learning Representations of Chatbots<fixed-case>B</fixed-case>ot2<fixed-case>V</fixed-case>ec: Learning Representations of Chatbots</title>
      <author><first>Jonathan</first><last>Herzig</last></author>
      <author><first>Tommy</first><last>Sandbank</last></author>
      <author><first>Michal</first><last>Shmueli-Scheuer</last></author>
      <author><first>David</first><last>Konopnicki</last></author>
      <pages>75–84</pages>
      <abstract>Chatbots (i.e., bots) are becoming widely used in multiple domains, along with supporting bot programming platforms. These <a href="https://en.wikipedia.org/wiki/Computing_platform">platforms</a> are equipped with novel testing tools aimed at improving the quality of individual <a href="https://en.wikipedia.org/wiki/Chatbot">chatbots</a>. Doing so requires an understanding of what sort of <a href="https://en.wikipedia.org/wiki/Internet_bot">bots</a> are being built (captured by their underlying conversation graphs) and how well they perform (derived through analysis of conversation logs). In this paper, we propose a new model, Bot2Vec, that embeds <a href="https://en.wikipedia.org/wiki/Internet_bot">bots</a> to a compact representation based on their structure and usage logs. Then, we utilize Bot2Vec representations to improve the quality of two bot analysis tasks. Using conversation data and <a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">graphs</a> of over than 90 bots, we show that Bot2Vec representations improve detection performance by more than 16 % for both tasks.</abstract>
      <url hash="20055270">S19-1009</url>
      <doi>10.18653/v1/S19-1009</doi>
      <bibkey>herzig-etal-2019-bot2vec</bibkey>
    </paper>
    <paper id="11">
      <title>A Semantic Cover Approach for Topic Modeling</title>
      <author><first>Rajagopal</first><last>Venkatesaramani</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <author><first>Bradley</first><last>Malin</last></author>
      <author><first>Yevgeniy</first><last>Vorobeychik</last></author>
      <pages>92–102</pages>
      <abstract>We introduce a novel topic modeling approach based on constructing a semantic set cover for clusters of similar documents. Specifically, our approach first clusters documents using their Tf-Idf representation, and then covers each cluster with a set of topic words based on <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>, defined in terms of a <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a>. Computing a topic cover amounts to solving a minimum set cover problem. Our evaluation compares our topic modeling approach to Latent Dirichlet Allocation (LDA) on three metrics : 1) qualitative topic match, measured using evaluations by Amazon Mechanical Turk (MTurk) workers, 2) performance on classification tasks using each topic model as a sparse feature representation, and 3) topic coherence. We find that qualitative judgments significantly favor our approach, the method outperforms LDA on topic coherence, and is comparable to LDA on document classification tasks.</abstract>
      <url hash="27db580a">S19-1011</url>
      <doi>10.18653/v1/S19-1011</doi>
      <bibkey>venkatesaramani-etal-2019-semantic</bibkey>
    </paper>
    <paper id="12">
      <title>MCScript2.0 : A Machine Comprehension Corpus Focused on Script Events and Participants<fixed-case>MCS</fixed-case>cript2.0: A Machine Comprehension Corpus Focused on Script Events and Participants</title>
      <author><first>Simon</first><last>Ostermann</last></author>
      <author><first>Michael</first><last>Roth</last></author>
      <author><first>Manfred</first><last>Pinkal</last></author>
      <pages>103–117</pages>
      <abstract>We introduce MCScript2.0, a machine comprehension corpus for the end-to-end evaluation of <a href="https://en.wikipedia.org/wiki/Scripting_language">script knowledge</a>. MCScript2.0 contains approx. 20,000 questions on approx. 3,500 texts, crowdsourced based on a new collection process that results in challenging questions. Half of the questions can not be answered from the reading texts, but require the use of commonsense and, in particular, script knowledge. We give a thorough analysis of our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and show that while the task is not challenging to humans, existing machine comprehension models fail to perform well on the <a href="https://en.wikipedia.org/wiki/Data">data</a>, even if they make use of a commonsense knowledge base. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is available at http://www.sfb1102. uni-saarland.de/?page_id=2582</abstract>
      <url hash="7ca6a86e">S19-1012</url>
      <doi>10.18653/v1/S19-1012</doi>
      <bibkey>ostermann-etal-2019-mcscript2</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
    </paper>
    <paper id="13">
      <title>Deconstructing <a href="https://en.wikipedia.org/wiki/Multimodality">multimodality</a> : <a href="https://en.wikipedia.org/wiki/Visual_system">visual properties</a> and <a href="https://en.wikipedia.org/wiki/Context_(language_use)">visual context</a> in human semantic processing</title>
      <author><first>Christopher</first><last>Davis</last></author>
      <author><first>Luana</first><last>Bulat</last></author>
      <author><first>Anita Lilla</first><last>Vero</last></author>
      <author><first>Ekaterina</first><last>Shutova</last></author>
      <pages>118–124</pages>
      <abstract>Multimodal semantic models that extend linguistic representations with additional perceptual input have proved successful in a range of natural language processing (NLP) tasks. Recent research has successfully used <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural methods</a> to automatically create <a href="https://en.wikipedia.org/wiki/Mental_image">visual representations</a> for words. However, these works have extracted visual features from complete images, and have not examined how different kinds of visual information impact performance. In contrast, we construct multimodal models that differentiate between internal visual properties of the objects and their external visual context. We evaluate the models on the task of decoding brain activity associated with the meanings of nouns, demonstrating their advantage over those based on complete images.</abstract>
      <url hash="196a7bc7">S19-1013</url>
      <doi>10.18653/v1/S19-1013</doi>
      <bibkey>davis-etal-2019-deconstructing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="15">
      <title>Neural User Factor Adaptation for Text Classification : Learning to Generalize Across Author Demographics</title>
      <author><first>Xiaolei</first><last>Huang</last></author>
      <author><first>Michael J.</first><last>Paul</last></author>
      <pages>136–146</pages>
      <abstract>Language use varies across different <a href="https://en.wikipedia.org/wiki/Demography">demographic factors</a>, such as <a href="https://en.wikipedia.org/wiki/Gender">gender</a>, <a href="https://en.wikipedia.org/wiki/Ageing">age</a>, and <a href="https://en.wikipedia.org/wiki/Location">geographic location</a>. However, most existing document classification methods ignore demographic variability. In this study, we examine empirically how text data can vary across four <a href="https://en.wikipedia.org/wiki/Demography">demographic factors</a> : <a href="https://en.wikipedia.org/wiki/Gender">gender</a>, age, country, and <a href="https://en.wikipedia.org/wiki/Region">region</a>. We propose a multitask neural model to account for <a href="https://en.wikipedia.org/wiki/Demography">demographic variations</a> via <a href="https://en.wikipedia.org/wiki/Adversarial_system">adversarial training</a>. In experiments on four English-language social media datasets, we find that <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance improves when adapting for user factors.</abstract>
      <url hash="4eb7c418">S19-1015</url>
      <doi>10.18653/v1/S19-1015</doi>
      <bibkey>huang-paul-2019-neural</bibkey>
      <pwccode url="https://github.com/xiaoleihuang/NUFA" additional="false">xiaoleihuang/NUFA</pwccode>
    </paper>
    <paper id="16">
      <title>Abstract Graphs and Abstract Paths for Knowledge Graph Completion</title>
      <author><first>Vivi</first><last>Nastase</last></author>
      <author><first>Bhushan</first><last>Kotnis</last></author>
      <pages>147–157</pages>
      <abstract>Knowledge graphs, which provide numerous facts in a machine-friendly format, are incomplete. Information that we induce from such <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a>   e.g. entity embeddings, relation representations or patterns   will be affected by the imbalance in the information captured in the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>   by biasing representations, or causing us to miss potential patterns. To partially compensate for this situation we describe a method for representing <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a> that capture an intensional representation of the original extensional information. This representation is very compact, and it abstracts away from individual links, allowing us to find better path candidates, as shown by the results of link prediction using this information.</abstract>
      <url hash="486c5ef4">S19-1016</url>
      <doi>10.18653/v1/S19-1016</doi>
      <bibkey>nastase-kotnis-2019-abstract</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nell">NELL</pwcdataset>
    </paper>
    <paper id="18">
      <title>Enthymemetic Conditionals</title>
      <author><first>Eimear</first><last>Maguire</last></author>
      <pages>168–177</pages>
      <abstract>To model conditionals in a way that reflects their acceptability, we must include some means of making judgements about whether antecedent and consequent are meaningfully related or not. Enthymemes are non-logical arguments which do not hold up by themselves, but are acceptable through their relation to a <a href="https://en.wikipedia.org/wiki/Topos">topos</a>, an already-known general principle or <a href="https://en.wikipedia.org/wiki/Pattern">pattern</a> for reasoning. This paper uses <a href="https://en.wikipedia.org/wiki/Enthymeme">enthymemes</a> and <a href="https://en.wikipedia.org/wiki/Theory_of_forms">topoi</a> as a way to model the world-knowledge behind these judgements. In doing so, it provides a reformalisation (in TTR) of enthymemes and topoi as <a href="https://en.wikipedia.org/wiki/Flow_network">networks</a> rather than <a href="https://en.wikipedia.org/wiki/Function_(mathematics)">functions</a>, and information state update rules for <a href="https://en.wikipedia.org/wiki/Conditional_(computer_programming)">conditionals</a>.</abstract>
      <url hash="040ebad9">S19-1018</url>
      <doi>10.18653/v1/S19-1018</doi>
      <bibkey>maguire-2019-enthymemetic</bibkey>
    </paper>
    <paper id="19">
      <title>Acquiring Structured Temporal Representation via <a href="https://en.wikipedia.org/wiki/Crowdsourcing">Crowdsourcing</a> : A Feasibility Study</title>
      <author><first>Yuchen</first><last>Zhang</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>178–185</pages>
      <abstract>Temporal Dependency Trees are a structured temporal representation that represents temporal relations among time expressions and events in a text as a dependency tree structure. Compared to traditional pair-wise temporal relation representations, temporal dependency trees facilitate efficient <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>, higher inter-annotator agreement, and efficient computations. However, <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> on temporal dependency trees so far have only been done by expert annotators, which is costly and time-consuming. In this paper, we introduce a method to crowdsource temporal dependency tree annotations, and show that this representation is intuitive and can be collected with high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and <a href="https://en.wikipedia.org/wiki/Consensus_decision-making">agreement</a> through <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>. We produce a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of temporal dependency trees</a>, and present a baseline temporal dependency parser, trained and evaluated on this new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>.</abstract>
      <url hash="ffc41e32">S19-1019</url>
      <doi>10.18653/v1/S19-1019</doi>
      <bibkey>zhang-xue-2019-acquiring</bibkey>
    </paper>
    <paper id="21">
      <title>Improving Generalization in <a href="https://en.wikipedia.org/wiki/Coreference_resolution">Coreference Resolution</a> via Adversarial Training</title>
      <author><first>Sanjay</first><last>Subramanian</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>192–197</pages>
      <abstract>In order for coreference resolution systems to be useful in practice, they must be able to generalize to new text. In this work, we demonstrate that the performance of the state-of-the-art system decreases when the names of PER and GPE named entities in the CoNLL dataset are changed to names that do not occur in the training set. We use the technique of adversarial gradient-based training to retrain the state-of-the-art system and demonstrate that the retrained system achieves higher performance on the CoNLL dataset (both with and without the change of named entities) and the GAP dataset.</abstract>
      <url hash="ec76392c">S19-1021</url>
      <doi>10.18653/v1/S19-1021</doi>
      <bibkey>subramanian-roth-2019-improving</bibkey>
    </paper>
    <paper id="22">
      <title>Improving Human Needs Categorization of Events with Semantic Classification</title>
      <author><first>Haibo</first><last>Ding</last></author>
      <author><first>Ellen</first><last>Riloff</last></author>
      <author><first>Zhe</first><last>Feng</last></author>
      <pages>198–204</pages>
      <abstract>Human Needs categories have been used to characterize the reason why an <a href="https://en.wikipedia.org/wiki/Affect_(psychology)">affective event</a> is positive or negative. For example, I got the flu and I got fired are both negative (undesirable) events, but getting the flu is a Health problem while getting fired is a Financial problem. Previous work created learning models to assign <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">events</a> to Human Needs categories based on their words and contexts. In this paper, we introduce an intermediate step that assigns words to relevant semantic concepts. We create lightly supervised models that learn to label words with respect to 10 semantic concepts associated with Human Needs categories, and incorporate these labels as features for event categorization. Our results show that recognizing relevant semantic concepts improves both the <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> and <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of Human Needs categorization for <a href="https://en.wikipedia.org/wiki/Event_(philosophy)">events</a>.</abstract>
      <url hash="69a87a25">S19-1022</url>
      <doi>10.18653/v1/S19-1022</doi>
      <bibkey>ding-etal-2019-improving</bibkey>
    </paper>
    <paper id="24">
      <title>Automatic Accuracy Prediction for AMR Parsing<fixed-case>AMR</fixed-case> Parsing</title>
      <author><first>Juri</first><last>Opitz</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>212–223</pages>
      <abstract>Abstract Meaning Representation (AMR) represents sentences as directed, acyclic and rooted graphs, aiming at capturing their meaning in a machine readable format. AMR parsing converts natural language sentences into such <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a>. However, evaluating a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on new data by means of comparison to manually created AMR graphs is very costly. Also, we would like to be able to detect <a href="https://en.wikipedia.org/wiki/Parsing">parses</a> of questionable quality, or preferring results of alternative systems by selecting the ones for which we can assess good quality. We propose AMR accuracy prediction as the task of predicting several metrics of correctness for an automatically generated AMR parse   in absence of the corresponding gold parse. We develop a neural end-to-end multi-output regression model and perform three case studies : firstly, we evaluate the model’s capacity of predicting AMR parse accuracies and test whether it can reliably assign high scores to gold parses. Secondly, we perform parse selection based on predicted parse accuracies of candidate parses from alternative systems, with the aim of improving overall results. Finally, we predict system ranks for submissions from two AMR shared tasks on the basis of their predicted parse accuracy averages. All experiments are carried out across two different domains and show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is effective.</abstract>
      <url hash="899db651">S19-1024</url>
      <doi>10.18653/v1/S19-1024</doi>
      <bibkey>opitz-frank-2019-automatic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bio">Bio</pwcdataset>
    </paper>
    <paper id="25">
      <title>An Argument-Marker Model for Syntax-Agnostic Proto-Role Labeling</title>
      <author><first>Juri</first><last>Opitz</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>224–234</pages>
      <abstract>Semantic proto-role labeling (SPRL) is an alternative to semantic role labeling (SRL) that moves beyond a categorical definition of roles, following Dowty’s feature-based view of proto-roles. This <a href="https://en.wikipedia.org/wiki/Theory">theory</a> determines agenthood vs. patienthood based on a participant’s instantiation of more or less typical agent vs. patient properties, such as, for example, <a href="https://en.wikipedia.org/wiki/Volition_(psychology)">volition</a> in an event. To perform SPRL, we develop an ensemble of hierarchical models with self-attention and concurrently learned predicate-argument markers. Our method is competitive with the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the art</a>, overall outperforming previous work in two formulations of the task (multi-label and multi-variate Likert scale pre- diction). In contrast to previous work, our results do not depend on gold argument heads derived from supplementary gold tree banks.</abstract>
      <url hash="bb5ee966">S19-1025</url>
      <doi>10.18653/v1/S19-1025</doi>
      <bibkey>opitz-frank-2019-argument</bibkey>
    </paper>
    <paper id="29">
      <title>Bayesian Inference Semantics : A Modelling System and A Test Suite<fixed-case>B</fixed-case>ayesian Inference Semantics: A Modelling System and A Test Suite</title>
      <author><first>Jean-Philippe</first><last>Bernardy</last></author>
      <author><first>Rasmus</first><last>Blanck</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <author><first>Shalom</first><last>Lappin</last></author>
      <author><first>Aleksandre</first><last>Maskharashvili</last></author>
      <pages>263–272</pages>
      <abstract>We present BIS, a <a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian Inference Semantics</a>, for probabilistic reasoning in natural language. The current <a href="https://en.wikipedia.org/wiki/System">system</a> is based on the framework of Bernardy et al. (2018), but departs from <a href="https://en.wikipedia.org/wiki/It_(2017_film)">it</a> in important respects. BIS makes use of <a href="https://en.wikipedia.org/wiki/Bayesian_inference">Bayesian learning</a> for inferring a hypothesis from premises. This involves estimating the probability of the hypothesis, given the data supplied by the premises of an argument. It uses a syntactic parser to generate typed syntactic structures that serve as input to a model generation system. Sentences are interpreted compositionally to probabilistic programs, and the corresponding truth values are estimated using <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">sampling methods</a>. BIS successfully deals with various probabilistic semantic phenomena, including frequency adverbs, generalised quantifiers, generics, and vague predicates. It performs well on a number of interesting probabilistic reasoning tasks. It also sustains most classically valid inferences (instantiation, <a href="https://en.wikipedia.org/wiki/De_Morgan’s_laws">de Morgan’s laws</a>, etc.). To test BIS we have built an experimental test suite with examples of a range of probabilistic and classical inference patterns.</abstract>
      <url hash="6d97b949">S19-1029</url>
      <doi>10.18653/v1/S19-1029</doi>
      <bibkey>bernardy-etal-2019-bayesian</bibkey>
      <pwccode url="https://github.com/GU-CLASP/bbclm2019" additional="false">GU-CLASP/bbclm2019</pwccode>
    </paper>
    <paper id="31">
      <title>Incivility Detection in Online Comments</title>
      <author><first>Farig</first><last>Sadeque</last></author>
      <author><first>Stephen</first><last>Rains</last></author>
      <author><first>Yotam</first><last>Shmargad</last></author>
      <author><first>Kate</first><last>Kenski</last></author>
      <author><first>Kevin</first><last>Coe</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>283–291</pages>
      <abstract>Incivility in public discourse has been a major concern in recent times as it can affect the quality and tenacity of the <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a> negatively. In this paper, we present neural models that can learn to detect <a href="https://en.wikipedia.org/wiki/Name_calling">name-calling</a> and <a href="https://en.wikipedia.org/wiki/Vulgarity">vulgarity</a> from a <a href="https://en.wikipedia.org/wiki/Internet_forum">newspaper comment section</a>. We show that in contrast to prior work on detecting toxic language, fine-grained incivilities like <a href="https://en.wikipedia.org/wiki/Name_calling">namecalling</a> can not be accurately detected by simple models like <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>. We apply the models trained on the newspaper comments data to detect uncivil comments in a Russian troll dataset, and find that despite the change of domain, the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> makes accurate predictions.</abstract>
      <url hash="1303b586">S19-1031</url>
      <doi>10.18653/v1/S19-1031</doi>
      <bibkey>sadeque-etal-2019-incivility</bibkey>
    </paper>
    <paper id="32">
      <title>Generating Animations from Screenplays</title>
      <author><first>Yeyao</first><last>Zhang</last></author>
      <author><first>Eleftheria</first><last>Tsipidi</last></author>
      <author><first>Sasha</first><last>Schriber</last></author>
      <author><first>Mubbasir</first><last>Kapadia</last></author>
      <author><first>Markus</first><last>Gross</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>292–307</pages>
      <abstract>Automatically generating animation from <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language text</a> finds application in a number of areas e.g. movie script writing, instructional videos, and <a href="https://en.wikipedia.org/wiki/Public_security">public safety</a>. However, translating <a href="https://en.wikipedia.org/wiki/Natural_language">natural language text</a> into <a href="https://en.wikipedia.org/wiki/Animation">animation</a> is a challenging task. Existing text-to-animation systems can handle only very simple sentences, which limits their applications. In this paper, we develop a text-to-animation system which is capable of handling <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">complex sentences</a>. We achieve this by introducing a text simplification step into the <a href="https://en.wikipedia.org/wiki/Process_(computing)">process</a>. Building on an existing animation generation system for <a href="https://en.wikipedia.org/wiki/Screenwriting">screenwriting</a>, we create a robust NLP pipeline to extract information from <a href="https://en.wikipedia.org/wiki/Screenplay">screenplays</a> and map them to the system’s knowledge base. We develop a set of linguistic transformation rules that simplify complex sentences. Information extracted from the simplified sentences is used to generate a rough storyboard and video depicting the text. Our sentence simplification module outperforms existing systems in terms of BLEU and SARI metrics. We further evaluated our <a href="https://en.wikipedia.org/wiki/System">system</a> via a user study : 68 % participants believe that our <a href="https://en.wikipedia.org/wiki/System">system</a> generates reasonable <a href="https://en.wikipedia.org/wiki/Animation">animation</a> from input <a href="https://en.wikipedia.org/wiki/Screenplay">screenplays</a>.</abstract>
      <url hash="d2d97949">S19-1032</url>
      <doi>10.18653/v1/S19-1032</doi>
      <bibkey>zhang-etal-2019-generating</bibkey>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 13th International Workshop on Semantic Evaluation</booktitle>
      <url hash="c6884df0">S19-2</url>
      <editor><first>Jonathan</first><last>May</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <editor><first>Aurelie</first><last>Herbelot</last></editor>
      <editor><first>Xiaodan</first><last>Zhu</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Saif M.</first><last>Mohammad</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="8fc0fb1a">S19-2000</url>
      <bibkey>semeval-2019-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>SemEval-2019 Task 1 : Cross-lingual Semantic Parsing with UCCA<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 1: Cross-lingual Semantic Parsing with <fixed-case>UCCA</fixed-case></title>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Zohar</first><last>Aizenbud</last></author>
      <author><first>Leshem</first><last>Choshen</last></author>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Ari</first><last>Rappoport</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <pages>1–10</pages>
      <abstract>We present the SemEval 2019 shared task on Universal Conceptual Cognitive Annotation (UCCA) parsing in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/French_language">French</a>, and discuss the participating systems and results. UCCA is a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. The shared task has yielded improvements over the state-of-the-art <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> in all languages and settings. Full results can be found in the task’s website.<url>https://competitions.codalab.org/competitions/19160</url>.</abstract>
      <url hash="73466e5e">S19-2001</url>
      <attachment type="presentation" hash="bcbfd565">S19-2001.Presentation.pdf</attachment>
      <doi>10.18653/v1/S19-2001</doi>
      <revision id="1" href="S19-2001v1" hash="800901b3" />
      <revision id="2" href="S19-2001v2" hash="73466e5e" date="2020-07-07">Content update to reflect a disqualified participant.</revision>
      <bibkey>hershcovich-etal-2019-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>ANA at SemEval-2019 Task 3 : Contextual Emotion detection in Conversations through hierarchical LSTMs and BERT<fixed-case>ANA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Contextual Emotion detection in Conversations through hierarchical <fixed-case>LSTM</fixed-case>s and <fixed-case>BERT</fixed-case></title>
      <author><first>Chenyang</first><last>Huang</last></author>
      <author><first>Amine</first><last>Trabelsi</last></author>
      <author><first>Osmar</first><last>Zaïane</last></author>
      <pages>49–53</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> submitted by ANA Team for the SemEval-2019 Task 3 : EmoContext. We propose a novel Hierarchi- cal LSTMs for Contextual Emotion Detection (HRLCE) model. It classifies the emotion of an utterance given its conversational con- text. The results show that, in this task, our HRCLE outperforms the most recent state-of- the-art text classification framework : BERT. We combine the results generated by BERT and HRCLE to achieve an overall score of 0.7709 which ranked 5th on the final leader board of the competition among 165 Teams.</abstract>
      <url hash="8c794dd4">S19-2006</url>
      <doi>10.18653/v1/S19-2006</doi>
      <bibkey>huang-etal-2019-ana</bibkey>
      <pwccode url="https://github.com/chenyangh/SemEval2019Task3" additional="false">chenyangh/SemEval2019Task3</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="7">
      <title>SemEval-2019 Task 5 : Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in <fixed-case>T</fixed-case>witter</title>
      <author><first>Valerio</first><last>Basile</last></author>
      <author><first>Cristina</first><last>Bosco</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <author><first>Debora</first><last>Nozza</last></author>
      <author><first>Viviana</first><last>Patti</last></author>
      <author><first>Francisco Manuel</first><last>Rangel Pardo</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <author><first>Manuela</first><last>Sanguinetti</last></author>
      <pages>54–63</pages>
      <abstract>The paper describes the organization of the SemEval 2019 Task 5 about the detection of hate speech against immigrants and women in Spanish and English messages extracted from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. The task is organized in two related classification subtasks : a main binary subtask for detecting the presence of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, and a finer-grained one devoted to identifying further features in hateful contents such as the aggressive attitude and the target harassed, to distinguish if the incitement is against an individual rather than a group. HatEval has been one of the most popular tasks in SemEval-2019 with a total of 108 submitted runs for Subtask A and 70 runs for Subtask B, from a total of 74 different teams. Data provided for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> are described by showing how they have been collected and annotated. Moreover, the paper provides an analysis and discussion about the participant systems and the results they achieved in both subtasks.</abstract>
      <url hash="fb60c578">S19-2007</url>
      <doi>10.18653/v1/S19-2007</doi>
      <bibkey>basile-etal-2019-semeval</bibkey>
    </paper>
    <paper id="10">
      <title>SemEval-2019 Task 6 : Identifying and Categorizing <a href="https://en.wikipedia.org/wiki/Offensive_language">Offensive Language</a> in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> (OffensEval)<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media (<fixed-case>O</fixed-case>ffens<fixed-case>E</fixed-case>val)</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Sara</first><last>Rosenthal</last></author>
      <author><first>Noura</first><last>Farra</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <pages>75–86</pages>
      <abstract>We present the results and the main findings of SemEval-2019 Task 6 on Identifying and Categorizing Offensive Language in Social Media (OffensEval). The task was based on a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, the Offensive Language Identification Dataset (OLID), which contains over 14,000 English tweets, and it featured three sub-tasks. In sub-task A, systems were asked to discriminate between offensive and non-offensive posts. In sub-task B, systems had to identify the type of offensive content in the post. Finally, in sub-task C, systems had to detect the target of the offensive posts. OffensEval attracted a large number of participants and <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> was one of the most popular <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> in SemEval-2019. In total, nearly 800 teams signed up to participate in the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and 115 of them submitted results, which are presented and analyzed in this report.</abstract>
      <url hash="752ced44">S19-2010</url>
      <doi>10.18653/v1/S19-2010</doi>
      <bibkey>zampieri-etal-2019-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="13">
      <title>DANGNT@UIT.VNU-HCM at SemEval 2019 Task 1 : Graph Transformation System from Stanford Basic Dependencies to Universal Conceptual Cognitive Annotation (UCCA)<fixed-case>DANGNT</fixed-case>@<fixed-case>UIT</fixed-case>.<fixed-case>VNU</fixed-case>-<fixed-case>HCM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2019 Task 1: Graph Transformation System from <fixed-case>S</fixed-case>tanford Basic Dependencies to <fixed-case>U</fixed-case>niversal <fixed-case>C</fixed-case>onceptual <fixed-case>C</fixed-case>ognitive <fixed-case>A</fixed-case>nnotation (<fixed-case>UCCA</fixed-case>)</title>
      <author><first>Dang</first><last>Tuan Nguyen</last></author>
      <author><first>Trung</first><last>Tran</last></author>
      <pages>97–101</pages>
      <abstract>This paper describes the graph transfor-mation system (GT System) for SemEval 2019 Task 1 : Cross-lingual Semantic Parsing with Universal Conceptual Cognitive Annotation (UCCA)1. The input of GT System is a pair of text and its unannotated xml, which is a layer 0 part of UCCA form. The output of GT System is the corresponding full UCCA xml. Based on the idea of graph illustration and transformation, we perform four main tasks when building GT System. At the first task, we illustrate the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph form</a> of stanford dependencies2 of input text. We then transform into an <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">intermediate graph</a> in the second task. At the third task, we continue to transform into ouput graph form. Finally, we create the output UCCA xml. The evaluation results show that our method generates good-quality UCCA xml and has a meaningful contribution to the semantic represetation sub-field in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>.</abstract>
      <url hash="c80dfdfd">S19-2013</url>
      <doi>10.18653/v1/S19-2013</doi>
      <bibkey>tuan-nguyen-tran-2019-dangnt</bibkey>
    </paper>
    <paper id="15">
      <title>MaskParse@Deskin at SemEval-2019 Task 1 : Cross-lingual UCCA Semantic Parsing using Recursive Masked Sequence Tagging<fixed-case>M</fixed-case>ask<fixed-case>P</fixed-case>arse@Deskin at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 1: Cross-lingual <fixed-case>UCCA</fixed-case> Semantic Parsing using Recursive Masked Sequence Tagging</title>
      <author><first>Gabriel</first><last>Marzinotto</last></author>
      <author><first>Johannes</first><last>Heinecke</last></author>
      <author><first>Géraldine</first><last>Damnati</last></author>
      <pages>107–112</pages>
      <abstract>This paper describes our recursive system for SemEval-2019 Task 1 : Cross-lingual Semantic Parsing with UCCA. Each recursive step consists of two parts. We first perform <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> using a sequence tagger to estimate the probabilities of the UCCA categories in the sentence. Then, we apply a decoding policy which interprets these probabilities and builds the <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">graph nodes</a>. Parsing is done recursively, we perform a first inference on the sentence to extract the main scenes and links and then we recursively apply our model on the sentence using a masking features that reflects the decisions made in previous steps. Process continues until the <a href="https://en.wikipedia.org/wiki/Terminal_(telecommunication)">terminal nodes</a> are reached. We chose a standard neural tagger and we focus on our recursive parsing strategy and on the cross lingual transfer problem to develop a robust model for the <a href="https://en.wikipedia.org/wiki/French_language">French language</a>, using only few training samples</abstract>
      <url hash="14b9d317">S19-2015</url>
      <doi>10.18653/v1/S19-2015</doi>
      <bibkey>marzinotto-etal-2019-maskparse</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bio">Bio</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="17">
      <title>UC Davis at SemEval-2019 Task 1 : DAG Semantic Parsing with Attention-based Decoder<fixed-case>UC</fixed-case> <fixed-case>D</fixed-case>avis at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 1: <fixed-case>DAG</fixed-case> Semantic Parsing with Attention-based Decoder</title>
      <author><first>Dian</first><last>Yu</last></author>
      <author><first>Kenji</first><last>Sagae</last></author>
      <pages>119–124</pages>
      <abstract>We present an encoder-decoder model for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> with UCCA SemEval 2019 Task 1. The <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> is a Bi-LSTM and the <a href="https://en.wikipedia.org/wiki/Codec">decoder</a> uses recursive self-attention. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> alleviates challenges and <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a> in traditional transition-based and graph-based parsers. The resulting <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> is simple and proved to effective on the semantic parsing task.</abstract>
      <url hash="e84d7927">S19-2017</url>
      <doi>10.18653/v1/S19-2017</doi>
      <bibkey>yu-sagae-2019-uc</bibkey>
    </paper>
    <paper id="20">
      <title>BrainEE at SemEval-2019 Task 3 : Ensembling Linear Classifiers for Emotion Prediction<fixed-case>B</fixed-case>rain<fixed-case>EE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Ensembling Linear Classifiers for Emotion Prediction</title>
      <author><first>Vachagan</first><last>Gratian</last></author>
      <pages>137–141</pages>
      <abstract>The paper describes an ensemble of linear perceptrons trained for <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classification</a> as part of the SemEval-2019 shared-task 3. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> uses a matrix of probabilities to weight the activations of the base-classifiers and makes a final prediction using the sum rule. The base-classifiers are multi-class perceptrons utilizing character and word n-grams, <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tags</a> and sentiment polarity scores. The results of our experiments indicate that the <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> outperforms the base-classifiers, but only marginally. In the best scenario our model attains an F-Micro score of 0.672, whereas the base-classifiers attained scores ranging from 0.636 to 0.666.</abstract>
      <url hash="e5618f72">S19-2020</url>
      <doi>10.18653/v1/S19-2020</doi>
      <bibkey>gratian-2019-brainee</bibkey>
    </paper>
    <paper id="21">
      <title>CAiRE_HKUST at SemEval-2019 Task 3 : Hierarchical Attention for Dialogue Emotion Classification<fixed-case>CA</fixed-case>i<fixed-case>RE</fixed-case>_<fixed-case>HKUST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Hierarchical Attention for Dialogue Emotion Classification</title>
      <author><first>Genta Indra</first><last>Winata</last></author>
      <author><first>Andrea</first><last>Madotto</last></author>
      <author><first>Zhaojiang</first><last>Lin</last></author>
      <author><first>Jamin</first><last>Shin</last></author>
      <author><first>Yan</first><last>Xu</last></author>
      <author><first>Peng</first><last>Xu</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>142–147</pages>
      <abstract>Detecting emotion from <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a> is a challenge that has not yet been extensively surveyed. One could consider the <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a> of each dialogue turn to be independent, but in this paper, we introduce a hierarchical approach to classify <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, hypothesizing that the current emotional state depends on previous latent emotions. We benchmark several feature-based classifiers using pre-trained word and emotion embeddings, state-of-the-art end-to-end neural network models, and Gaussian processes for automatic hyper-parameter search. In our experiments, hierarchical architectures consistently give significant improvements, and our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a 76.77 % <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> on the test set.</abstract>
      <url hash="e115bd37">S19-2021</url>
      <revision id="1" href="S19-2021v1" hash="5238764f" />
      <revision id="2" href="S19-2021v2" hash="e115bd37">We corrected a reference by adding a booktitle to fix the bibliography.Before: Pascale Fung, Dario Bertero, Peng Xu, Ji Ho Park, Chien-Sheng Wu, and Andrea Madotto. 2018. Empathetic dialog systems.After: Pascale Fung, Dario Bertero, Peng Xu, Ji Ho Park, Chien-Sheng Wu, and Andrea Madotto. 2018. Empathetic dialog systems. In The International Conference on Language Resources and Evaluation. European Language Resources Association.</revision>
      <doi>10.18653/v1/S19-2021</doi>
      <bibkey>winata-etal-2019-caire</bibkey>
    </paper>
    <paper id="23">
      <title>CLaC Lab at SemEval-2019 Task 3 : Contextual Emotion Detection Using a Combination of Neural Networks and SVM<fixed-case>CL</fixed-case>a<fixed-case>C</fixed-case> Lab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Contextual Emotion Detection Using a Combination of Neural Networks and <fixed-case>SVM</fixed-case></title>
      <author><first>Elham</first><last>Mohammadi</last></author>
      <author><first>Hessam</first><last>Amini</last></author>
      <author><first>Leila</first><last>Kosseim</last></author>
      <pages>153–158</pages>
      <abstract>This paper describes our system at SemEval 2019, Task 3 (EmoContext), which focused on the contextual detection of emotions in a dataset of 3-round dialogues. For our final system, we used a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> with pretrained ELMo word embeddings and POS tags as input, GRUs as hidden units, an attention mechanism to capture representations of the dialogues, and an SVM classifier which used the learned network representations to perform the task of multi-class classification. This system yielded a micro-averaged F1 score of 0.7072 for the three emotion classes, improving the baseline by approximately 12 %.</abstract>
      <url hash="0410d267">S19-2023</url>
      <doi>10.18653/v1/S19-2023</doi>
      <bibkey>mohammadi-etal-2019-clac</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="24">
      <title>CLARK at SemEval-2019 Task 3 : Exploring the Role of Context to Identify Emotion in a Short Conversation<fixed-case>CLARK</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Exploring the Role of Context to Identify Emotion in a Short Conversation</title>
      <author><first>Joseph</first><last>Cummings</last></author>
      <author><first>Jason</first><last>Wilson</last></author>
      <pages>159–163</pages>
      <abstract>With text lacking valuable information avail-able in other modalities, <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> may provide useful information to better detect <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a>. In this paper, we do a systematic exploration of the role of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> in <a href="https://en.wikipedia.org/wiki/Emotion_recognition">recognizing emotion</a> in a <a href="https://en.wikipedia.org/wiki/Conversation">conversation</a>. We use a Naive Bayes model to show that inferring the mood of the conversation before classifying individual utterances leads to better performance. Additionally, we find that using <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> while train-ing the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly decreases performance. Our approach has the additional bene-fit that its performance rivals a baseline LSTM model while requiring fewer resources.</abstract>
      <url hash="7793352c">S19-2024</url>
      <doi>10.18653/v1/S19-2024</doi>
      <bibkey>cummings-wilson-2019-clark</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="26">
      <title>CoAStaL at SemEval-2019 Task 3 : Affect Classification in Dialogue using Attentive BiLSTMs<fixed-case>C</fixed-case>o<fixed-case>AS</fixed-case>ta<fixed-case>L</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Affect Classification in Dialogue using Attentive <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>s</title>
      <author><first>Ana Valeria</first><last>González</last></author>
      <author><first>Victor</first><last>Petrén Bach Hansen</last></author>
      <author><first>Joachim</first><last>Bingel</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>169–174</pages>
      <abstract>This work describes the system presented by the CoAStaL Natural Language Processing group at University of Copenhagen. The main <a href="https://en.wikipedia.org/wiki/System">system</a> we present uses the same <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a> presented in (Yang et al., 2016). Our overall model architecture is also inspired by their hierarchical classification model and adapted to deal with classification in dialogue by encoding information at the turn level. We use different encodings for each turn to create a more expressive representation of dialogue context which is then fed into our classifier. We also define a custom preprocessing step in order to deal with language commonly used in interactions across many social media outlets. Our proposed system achieves a micro F1 score of 0.7340 on the test set and shows significant gains in performance compared to a system using dialogue level encoding.</abstract>
      <url hash="a92b0b56">S19-2026</url>
      <revision id="1" href="S19-2026v1" hash="dcce302d" />
      <revision id="2" href="S19-2026v2" hash="a92b0b56">No description of the changes were recorded.</revision>
      <doi>10.18653/v1/S19-2026</doi>
      <bibkey>gonzalez-etal-2019-coastal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="28">
      <title>CX-ST-RNM at SemEval-2019 Task 3 : Fusion of Recurrent Neural Networks Based on Contextualized and Static Word Representations for Contextual Emotion Detection<fixed-case>CX</fixed-case>-<fixed-case>ST</fixed-case>-<fixed-case>RNM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Fusion of Recurrent Neural Networks Based on Contextualized and Static Word Representations for Contextual Emotion Detection</title>
      <author><first>Michał</first><last>Perełkiewicz</last></author>
      <pages>180–184</pages>
      <abstract>In this paper, I describe a fusion model combining contextualized and static word representations for approaching the EmoContext task in the SemEval 2019 competition. The model is based on two <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a>, the first one is fed with a state-of-the-art ELMo deep contextualized word representation and the second one is fed with a static Word2Vec embedding augmented with 10-dimensional affective word feature vector. The proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is compared with two baseline models based on a static word representation and a contextualized word representation, separately. My approach achieved officially 0.7278 microaveraged F1 score on the test dataset, ranking 47th out of 165 participants.</abstract>
      <url hash="3b122af4">S19-2028</url>
      <doi>10.18653/v1/S19-2028</doi>
      <bibkey>perelkiewicz-2019-cx</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="30">
      <title>E-LSTM at SemEval-2019 Task 3 : Semantic and Sentimental Features Retention for Emotion Detection in Text<fixed-case>E</fixed-case>-<fixed-case>LSTM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Semantic and Sentimental Features Retention for Emotion Detection in Text</title>
      <author><first>Harsh</first><last>Patel</last></author>
      <pages>190–194</pages>
      <abstract>This paper discusses the solution to the problem statement of the SemEval19 : EmoContext competition which is Contextual Emotion Detection in Texts. The paper includes the explanation of an architecture that I created by exploiting the embedding layers of Word2Vec and GloVe using <a href="https://en.wikipedia.org/wiki/Linear_time-invariant_system">LSTMs</a> as memory unit cells which detects approximate emotion of chats between two people in the <a href="https://en.wikipedia.org/wiki/English_language">English language</a> provided in the textual form. The set of <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> on which the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> was trained was Happy, Sad, Angry and Others. The paper also includes an analysis of different conventional <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> in comparison to E-LSTM.</abstract>
      <url hash="2a9e70cf">S19-2030</url>
      <doi>10.18653/v1/S19-2030</doi>
      <bibkey>patel-2019-e</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="31">
      <title>ELiRF-UPV at SemEval-2019 Task 3 : Snapshot Ensemble of Hierarchical Convolutional Neural Networks for Contextual Emotion Detection<fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Snapshot Ensemble of Hierarchical Convolutional Neural Networks for Contextual Emotion Detection</title>
      <author><first>José-Ángel</first><last>González</last></author>
      <author><first>Lluís-F.</first><last>Hurtado</last></author>
      <author><first>Ferran</first><last>Pla</last></author>
      <pages>195–199</pages>
      <abstract>This paper describes the approach developed by the ELiRF-UPV team at SemEval 2019 Task 3 : Contextual Emotion Detection in Text. We have developed a Snapshot Ensemble of 1D Hierarchical Convolutional Neural Networks to extract features from 3-turn conversations in order to perform contextual emotion detection in text. This Snapshot Ensemble is obtained by averaging the models selected by a <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">Genetic Algorithm</a> that optimizes the evaluation measure. The proposed <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> obtains better results than a single model and it obtains competitive and promising results on Contextual Emotion Detection in Text.</abstract>
      <url hash="bc7fa2a2">S19-2031</url>
      <doi>10.18653/v1/S19-2031</doi>
      <bibkey>gonzalez-etal-2019-elirf</bibkey>
    </paper>
    <paper id="35">
      <title>EPITA-ADAPT at SemEval-2019 Task 3 : Detecting emotions in textual conversations using deep learning models combination<fixed-case>EPITA</fixed-case>-<fixed-case>ADAPT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Detecting emotions in textual conversations using deep learning models combination</title>
      <author><first>Abdessalam</first><last>Bouchekif</last></author>
      <author><first>Praveen</first><last>Joshi</last></author>
      <author><first>Latifa</first><last>Bouchekif</last></author>
      <author><first>Haithem</first><last>Afli</last></author>
      <pages>215–219</pages>
      <abstract>Messaging platforms like <a href="https://en.wikipedia.org/wiki/WhatsApp">WhatsApp</a>, <a href="https://en.wikipedia.org/wiki/Facebook_Messenger">Facebook Messenger</a> and <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> have gained recently much popularity owing to their ability in connecting users in real-time. The content of these textual messages can be a useful resource for <a href="https://en.wikipedia.org/wiki/Text_mining">text mining</a> to discover and unhide various aspects, including <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a>. In this paper we present our submission for SemEval 2019 task ‘EmoContext’. The task consists of classifying a given textual dialogue into one of four <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classes</a> : Angry, Happy, Sad and Others. Our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> is based on the combination of different deep neural networks techniques. In particular, we use Recurrent Neural Networks (LSTM, B-LSTM, GRU, B-GRU), Convolutional Neural Network (CNN) and Transfer Learning (TL) methodes. Our final <a href="https://en.wikipedia.org/wiki/System">system</a>, achieves an F1 score of 74.51 % on the subtask evaluation dataset.</abstract>
      <url hash="4b26a04a">S19-2035</url>
      <doi>10.18653/v1/S19-2035</doi>
      <bibkey>bouchekif-etal-2019-epita</bibkey>
    </paper>
    <paper id="36">
      <title>Figure Eight at SemEval-2019 Task 3 : Ensemble of Transfer Learning Methods for Contextual Emotion Detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Ensemble of Transfer Learning Methods for Contextual Emotion Detection</title>
      <author><first>Joan</first><last>Xiao</last></author>
      <pages>220–224</pages>
      <abstract>This paper describes our transfer learning-based approach to contextual emotion detection as part of SemEval-2019 Task 3. We experiment with <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> using pre-trained language models (ULMFiT, OpenAI GPT, and BERT) and fine-tune them on this task. We also train a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning model</a> from scratch using pre-trained word embeddings and BiLSTM architecture with attention mechanism. The ensembled model achieves competitive result, ranking ninth out of 165 teams. The result reveals that ULMFiT performs best due to its superior fine-tuning techniques. We propose improvements for future work.</abstract>
      <url hash="e67e7db3">S19-2036</url>
      <doi>10.18653/v1/S19-2036</doi>
      <bibkey>xiao-2019-figure</bibkey>
    </paper>
    <paper id="42">
      <title>LIRMM-Advanse at SemEval-2019 Task 3 : Attentive Conversation Modeling for Emotion Detection and Classification<fixed-case>LIRMM</fixed-case>-Advanse at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Attentive Conversation Modeling for Emotion Detection and Classification</title>
      <author><first>Waleed</first><last>Ragheb</last></author>
      <author><first>Jérôme</first><last>Azé</last></author>
      <author><first>Sandra</first><last>Bringay</last></author>
      <author><first>Maximilien</first><last>Servajean</last></author>
      <pages>251–255</pages>
      <abstract>This paper addresses the problem of modeling <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual conversations</a> and <a href="https://en.wikipedia.org/wiki/Emotion_detection">detecting emotions</a>. Our proposed model makes use of 1) deep transfer learning rather than the classical shallow methods of word embedding ; 2) self-attention mechanisms to focus on the most important parts of the texts and 3) turn-based conversational modeling for classifying the emotions. The approach does not rely on any <a href="https://en.wikipedia.org/wiki/Handicraft">hand-crafted features</a> or <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>. Our model was evaluated on the data provided by the SemEval-2019 shared task on contextual emotion detection in text. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> shows very competitive results.</abstract>
      <url hash="06ee0a13">S19-2042</url>
      <doi>10.18653/v1/S19-2042</doi>
      <bibkey>ragheb-etal-2019-lirmm</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="44">
      <title>MoonGrad at SemEval-2019 Task 3 : Ensemble BiRNNs for Contextual Emotion Detection in Dialogues<fixed-case>M</fixed-case>oon<fixed-case>G</fixed-case>rad at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Ensemble <fixed-case>B</fixed-case>i<fixed-case>RNN</fixed-case>s for Contextual Emotion Detection in Dialogues</title>
      <author><first>Chandrakant</first><last>Bothe</last></author>
      <author><first>Stefan</first><last>Wermter</last></author>
      <pages>261–265</pages>
      <abstract>When reading I do n’t want to talk to you any more, we might interpret this as either an angry or a sad emotion in the absence of context. Often, the utterances are shorter, and given a short utterance like Me too !, it is difficult to interpret the emotion without context. The lack of prosodic or visual information makes it a challenging problem to detect such <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> only with text. However, using contextual information in the <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a> is gaining importance to provide a context-aware recognition of linguistic features such as <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue act</a>, <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a> etc. The SemEval 2019 Task 3 EmoContext competition provides a dataset of three-turn dialogues labeled with the three <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classes</a>, i.e. Happy, Sad and Angry, and in addition with Others as none of the aforementioned emotion classes. We develop an ensemble of the recurrent neural model with character- and word-level features as an input to solve this problem. The system performs quite well, achieving a microaveraged F1 score (F1) of 0.7212 for the three emotion classes.</abstract>
      <url hash="4641733c">S19-2044</url>
      <doi>10.18653/v1/S19-2044</doi>
      <bibkey>bothe-wermter-2019-moongrad</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="45">
      <title>NELEC at SemEval-2019 Task 3 : Think Twice Before Going Deep<fixed-case>NELEC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Think Twice Before Going Deep</title>
      <author><first>Parag</first><last>Agrawal</last></author>
      <author><first>Anshuman</first><last>Suri</last></author>
      <pages>266–271</pages>
      <abstract>Existing Machine Learning techniques yield close to human performance on text-based classification tasks. However, the presence of multi-modal noise in chat data such as <a href="https://en.wikipedia.org/wiki/Emoticon">emoticons</a>, <a href="https://en.wikipedia.org/wiki/Slang">slang</a>, spelling mistakes, code-mixed data, etc. makes existing <a href="https://en.wikipedia.org/wiki/Deep_learning">deep-learning solutions</a> perform poorly. The inability of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep-learning systems</a> to robustly capture these <a href="https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors">covariates</a> puts a cap on their performance. We propose NELEC : Neural and Lexical Combiner, a system which elegantly combines textual and deep-learning based methods for sentiment classification. We evaluate our <a href="https://en.wikipedia.org/wiki/System">system</a> as part of the third task of ‘Contextual Emotion Detection in Text’ as part of SemEval-2019. Our system performs significantly better than the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>, as well as our deep-learning model benchmarks. It achieved a micro-averaged F1 score of 0.7765, ranking 3rd on the test-set leader-board. Our code is available at https://github.com/iamgroot42/nelec</abstract>
      <url hash="218c89ca">S19-2045</url>
      <doi>10.18653/v1/S19-2045</doi>
      <bibkey>agrawal-suri-2019-nelec</bibkey>
      <pwccode url="https://github.com/iamgroot42/nelec" additional="false">iamgroot42/nelec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="47">
      <title>NTUA-ISLab at SemEval-2019 Task 3 : Determining emotions in contextual conversations with <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a><fixed-case>NTUA</fixed-case>-<fixed-case>ISL</fixed-case>ab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Determining emotions in contextual conversations with deep learning</title>
      <author><first>Rolandos Alexandros</first><last>Potamias</last></author>
      <author><first>Georgios</first><last>Siolas</last></author>
      <pages>277–281</pages>
      <abstract>Sentiment analysis (SA) in texts is a well-studied Natural Language Processing task, which in nowadays gains popularity due to the explosion of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, and the subsequent accumulation of huge amounts of related data. However, capturing <a href="https://en.wikipedia.org/wiki/Emotion">emotional states</a> and the <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment polarity</a> of written excerpts requires knowledge on the events triggering them. Towards this goal, we present a computational end-to-end context-aware SA methodology, which was competed in the context of the SemEval-2019 / EmoContext task (Task 3). The proposed system is founded on the combination of two neural architectures, a deep recurrent neural network, structured by an attentive Bidirectional LSTM, and a deep dense network (DNN). The <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 0.745 micro f1-score, and ranked 26/165 (top 20 %) teams among the official task submissions.</abstract>
      <url hash="6fcf387c">S19-2047</url>
      <doi>10.18653/v1/S19-2047</doi>
      <bibkey>potamias-siolas-2019-ntua</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="49">
      <title>PKUSE at SemEval-2019 Task 3 : <a href="https://en.wikipedia.org/wiki/Emotion_detection">Emotion Detection</a> with Emotion-Oriented Neural Attention Network<fixed-case>PKUSE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Emotion Detection with Emotion-Oriented Neural Attention Network</title>
      <author><first>Luyao</first><last>Ma</last></author>
      <author><first>Long</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Ye</last></author>
      <author><first>Wenhui</first><last>Hu</last></author>
      <pages>287–291</pages>
      <abstract>This paper presents the system in SemEval-2019 Task 3, EmoContext : Contextual Emotion Detection in Text. We propose a deep learning architecture with bidirectional LSTM networks, augmented with an emotion-oriented attention network that is capable of extracting emotion information from an utterance. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms its variants and the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>. Overall, this <a href="https://en.wikipedia.org/wiki/System">system</a> has achieved 75.57 % for the microaveraged F1 score.</abstract>
      <url hash="107cbe3c">S19-2049</url>
      <doi>10.18653/v1/S19-2049</doi>
      <bibkey>ma-etal-2019-pkuse</bibkey>
    </paper>
    <paper id="50">
      <title>Podlab at SemEval-2019 Task 3 : The Importance of Being Shallow<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: The Importance of Being Shallow</title>
      <author><first>Andrew</first><last>Nguyen</last></author>
      <author><first>Tobin</first><last>South</last></author>
      <author><first>Nigel</first><last>Bean</last></author>
      <author><first>Jonathan</first><last>Tuke</last></author>
      <author><first>Lewis</first><last>Mitchell</last></author>
      <pages>292–296</pages>
      <abstract>This paper describes our linear SVM system for <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classification</a> from conversational dialogue, entered in SemEval2019 Task 3. We used off-the-shelf tools coupled with <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a> and parameter tuning to create a simple, interpretable, yet high-performing, <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification model</a>. Our system achieves a micro F1 score of 0.7357, which is 92 % of the top score for the competition, demonstrating that shallow classification approaches can perform well when coupled with detailed fea- ture selection and <a href="https://en.wikipedia.org/wiki/Statistical_inference">statistical analysis</a>.</abstract>
      <url hash="56101b03">S19-2050</url>
      <doi>10.18653/v1/S19-2050</doi>
      <bibkey>nguyen-etal-2019-podlab</bibkey>
    </paper>
    <paper id="51">
      <title>SCIA at SemEval-2019 Task 3 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in Textual Conversations Using <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a><fixed-case>SCIA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Sentiment Analysis in Textual Conversations Using Deep Learning</title>
      <author><first>Zinedine</first><last>Rebiai</last></author>
      <author><first>Simon</first><last>Andersen</last></author>
      <author><first>Antoine</first><last>Debrenne</last></author>
      <author><first>Victor</first><last>Lafargue</last></author>
      <pages>297–301</pages>
      <abstract>In this paper we present our submission for SemEval-2019 Task 3 : EmoContext. The task consisted of classifying a textual dialogue into one of four <a href="https://en.wikipedia.org/wiki/Emotion_classification">emotion classes</a> : happy, sad, angry or others. Our approach tried to improve on multiple aspects, preprocessing with an emphasis on spell-checking and ensembling with four different models : Bi-directional contextual LSTM (BC-LSTM), categorical Bi-LSTM (CAT-LSTM), binary convolutional Bi-LSTM (BIN-LSTM) and Gated Recurrent Unit (GRU). On the leader-board, we submitted two systems that obtained a micro F1 score (F1) of 0.711 and 0.712. After the competition, we merged our two <a href="https://en.wikipedia.org/wiki/System">systems</a> with ensembling, which achieved a F1 of 0.7324 on the test dataset.</abstract>
      <url hash="e4fe256a">S19-2051</url>
      <doi>10.18653/v1/S19-2051</doi>
      <bibkey>rebiai-etal-2019-scia</bibkey>
    </paper>
    <paper id="52">
      <title>Sentim at SemEval-2019 Task 3 : <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> For Sentiment in Conversations<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Convolutional Neural Networks For Sentiment in Conversations</title>
      <author><first>Jacob</first><last>Anderson</last></author>
      <pages>302–306</pages>
      <abstract>In this work <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> were used in order to determine the <a href="https://en.wikipedia.org/wiki/Sentimentality">sentiment</a> in a conversational setting. This paper’s contributions include a method for handling any sized input and a method for breaking down the conversation into separate parts for easier processing. Finally, <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a> was shown to improve results and that such a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for handling sentiment in conversations is both fast and accurate.</abstract>
      <url hash="697b23d3">S19-2052</url>
      <doi>10.18653/v1/S19-2052</doi>
      <bibkey>anderson-2019-sentim</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="58">
      <title>TDBot at SemEval-2019 Task 3 : Context Aware Emotion Detection Using A Conditioned Classification Approach<fixed-case>TDB</fixed-case>ot at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Context Aware Emotion Detection Using A Conditioned Classification Approach</title>
      <author><first>Sourabh</first><last>Maity</last></author>
      <pages>335–339</pages>
      <abstract>With the system description it is shown how to use the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context information</a> while detecting the <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a> in a <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>. Some guidelines about how to handle <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> was also laid out. While developing this system I realized the importance of pre-processing in conversational text data, or in general NLP related tasks ; it can not be over emphasized.</abstract>
      <url hash="a6c337ff">S19-2058</url>
      <doi>10.18653/v1/S19-2058</doi>
      <bibkey>maity-2019-tdbot</bibkey>
    </paper>
    <paper id="60">
      <title>THU-HCSI at SemEval-2019 Task 3 : Hierarchical Ensemble Classification of Contextual Emotion in Conversation<fixed-case>THU</fixed-case>-<fixed-case>HCSI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Hierarchical Ensemble Classification of Contextual Emotion in Conversation</title>
      <author><first>Xihao</first><last>Liang</last></author>
      <author><first>Ye</first><last>Ma</last></author>
      <author><first>Mingxing</first><last>Xu</last></author>
      <pages>345–349</pages>
      <abstract>In this paper, we describe our hierarchical ensemble system designed for the SemEval-2019 task3, EmoContext. In our system, three sets of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> are trained for different sub-targets and the predicted labels of these base classifiers are combined through three steps of voting to make the final prediction. Effective details for developing base classifiers are highlighted.</abstract>
      <url hash="9ac0f968">S19-2060</url>
      <doi>10.18653/v1/S19-2060</doi>
      <bibkey>liang-etal-2019-thu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="61">
      <title>TokyoTech_NLP at SemEval-2019 Task 3 : Emotion-related Symbols in Emotion Detection<fixed-case>T</fixed-case>okyo<fixed-case>T</fixed-case>ech_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Emotion-related Symbols in Emotion Detection</title>
      <author><first>Zhishen</first><last>Yang</last></author>
      <author><first>Sam</first><last>Vijlbrief</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>350–354</pages>
      <abstract>This paper presents our contextual emotion detection system in approaching the SemEval2019 shared task 3 : EmoContext : Contextual Emotion Detection in Text. This system cooperates with an emotion detection neural network method (Poria et al., 2017), emoji2vec (Eisner et al., 2016) embedding, word2vec embedding (Mikolov et al., 2013), and our proposed emoticon and emoji preprocessing method. The experimental results demonstrate the usefulness of our emoticon and emoji prepossessing method, and representations of emoticons and emoji contribute model’s emotion detection.</abstract>
      <url hash="4c3af2ba">S19-2061</url>
      <doi>10.18653/v1/S19-2061</doi>
      <bibkey>yang-etal-2019-tokyotech</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="62">
      <title>UAIC at SemEval-2019 Task 3 : Extracting Much from Little<fixed-case>UAIC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 3: Extracting Much from Little</title>
      <author><first>Cristian</first><last>Simionescu</last></author>
      <author><first>Ingrid</first><last>Stoleru</last></author>
      <author><first>Diana</first><last>Lucaci</last></author>
      <author><first>Gheorghe</first><last>Balan</last></author>
      <author><first>Iulian</first><last>Bute</last></author>
      <author><first>Adrian</first><last>Iftene</last></author>
      <pages>355–359</pages>
      <abstract>In this paper, we present a system description for implementing a sentiment analysis agent capable of interpreting the state of an interlocutor engaged in short three message conversations. We present the results and observations of our work and which parts could be further improved in the future.</abstract>
      <url hash="f6498324">S19-2062</url>
      <doi>10.18653/v1/S19-2062</doi>
      <bibkey>simionescu-etal-2019-uaic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/emocontext">EmoContext</pwcdataset>
    </paper>
    <paper id="65">
      <title>ABARUAH at SemEval-2019 Task 5 : Bi-directional LSTM for Hate Speech Detection<fixed-case>ABARUAH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5 : Bi-directional <fixed-case>LSTM</fixed-case> for Hate Speech Detection</title>
      <author><first>Arup</first><last>Baruah</last></author>
      <author><first>Ferdous</first><last>Barbhuiya</last></author>
      <author><first>Kuntal</first><last>Dey</last></author>
      <pages>371–376</pages>
      <abstract>In this paper, we present the results obtained using bi-directional long short-term memory (BiLSTM) with and without attention and Logistic Regression (LR) models for SemEval-2019 Task 5 titled HatEval : Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter. This paper presents the results obtained for Subtask A for <a href="https://en.wikipedia.org/wiki/English_language">English language</a>. The results of the BiLSTM and LR models are compared for two different types of preprocessing. One with no <a href="https://en.wikipedia.org/wiki/Stemming">stemming</a> performed and no <a href="https://en.wikipedia.org/wiki/Stopword">stopwords</a> removed. The other with <a href="https://en.wikipedia.org/wiki/Stemming">stemming</a> performed and stopwords removed. The BiLSTM model without attention performed the best for the first test, while the LR model with character n-grams performed the best for the second test. The BiLSTM model obtained an <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 0.51 on the test set and obtained an official ranking of 8/71.</abstract>
      <url hash="bf0ed437">S19-2065</url>
      <doi>10.18653/v1/S19-2065</doi>
      <bibkey>baruah-etal-2019-abaruah</bibkey>
    </paper>
    <paper id="67">
      <title>CIC at SemEval-2019 Task 5 : Simple Yet Very Efficient Approach to Hate Speech Detection, Aggressive Behavior Detection, and Target Classification in Twitter<fixed-case>CIC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Simple Yet Very Efficient Approach to Hate Speech Detection, Aggressive Behavior Detection, and Target Classification in <fixed-case>T</fixed-case>witter</title>
      <author><first>Iqra</first><last>Ameer</last></author>
      <author><first>Muhammad Hammad Fahim</first><last>Siddiqui</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <author><first>Alexander</first><last>Gelbukh</last></author>
      <pages>382–386</pages>
      <abstract>In recent years, the use of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> has in-creased incredibly. Social media permits Inter-net users a friendly platform to express their views and opinions. Along with these nice and distinct communication chances, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> also allows bad things like usage of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>. Online automatic hate speech detection in various aspects is a significant scientific problem. This paper presents the Instituto Politcnico Nacional (Mexico) approach for the Semeval 2019 Task-5 [ Hateval 2019 ] (Basile et al., 2019) competition for Multilingual Detection of Hate Speech on Twitter. The goal of this paper is to detect (A) <a href="https://en.wikipedia.org/wiki/Hate_speech">Hate speech</a> against immigrants and women, (B) <a href="https://en.wikipedia.org/wiki/Aggression">Aggressive behavior</a> and target classification, both for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. In the proposed approach, we used a <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag of words model</a> with preprocessing (stem-ming and stop words removal). We submitted two different systems with names : (i) CIC-1 and (ii) CIC-2 for Hateval 2019 shared task. We used TF values in the first <a href="https://en.wikipedia.org/wiki/System">system</a> and TF-IDF for the second <a href="https://en.wikipedia.org/wiki/System">system</a>. The first system, CIC-1 got 2nd rank in subtask B for both <a href="https://en.wikipedia.org/wiki/English_language">English and Spanish languages</a> with EMR score of 0.568 for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 0.675 for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. The second system, CIC-2 was ranked 4th in sub-task A and 1st in subtask B for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language</a> with a macro-F1 score of 0.727 and EMR score of 0.705 respectively.</abstract>
      <url hash="ebf50cc8">S19-2067</url>
      <doi>10.18653/v1/S19-2067</doi>
      <bibkey>ameer-etal-2019-cic</bibkey>
    </paper>
    <paper id="68">
      <title>CiTIUS-COLE at SemEval-2019 Task 5 : Combining Linguistic Features to Identify Hate Speech Against Immigrants and Women on Multilingual Tweets<fixed-case>C</fixed-case>i<fixed-case>TIUS</fixed-case>-<fixed-case>COLE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Combining Linguistic Features to Identify Hate Speech Against Immigrants and Women on Multilingual Tweets</title>
      <author><first>Sattam</first><last>Almatarneh</last></author>
      <author><first>Pablo</first><last>Gamallo</last></author>
      <author><first>Francisco J. Ribadas</first><last>Pena</last></author>
      <pages>387–390</pages>
      <abstract>This article describes the strategy submitted by the CiTIUS-COLE team to SemEval 2019 Task 5, a task which consists of binary classi- fication where the system predicting whether a tweet in English or in Spanish is hateful against women or immigrants or not. The proposed strategy relies on combining linguis- tic features to improve the classifier’s perfor- mance. More precisely, the method combines textual and lexical features, embedding words with the bag of words in Term Frequency- Inverse Document Frequency (TF-IDF) repre- sentation. The system performance reaches about 81 % F1 when it is applied to the training dataset, but its F1 drops to 36 % on the official test dataset for the <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 64 % for the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language</a> concerning the hate speech class</abstract>
      <url hash="99d94ef8">S19-2068</url>
      <doi>10.18653/v1/S19-2068</doi>
      <bibkey>almatarneh-etal-2019-citius</bibkey>
    </paper>
    <paper id="69">
      <title>Grunn2019 at SemEval-2019 Task 5 : Shared Task on Multilingual Detection of Hate<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Shared Task on Multilingual Detection of Hate</title>
      <author><first>Mike</first><last>Zhang</last></author>
      <author><first>Roy</first><last>David</last></author>
      <author><first>Leon</first><last>Graumans</last></author>
      <author><first>Gerben</first><last>Timmerman</last></author>
      <pages>391–395</pages>
      <abstract>Hate speech occurs more often than ever and polarizes society. To help counter this polarization, SemEval 2019 organizes a shared task called the Multilingual Detection of Hate. The first task (A) is to decide whether a given tweet contains hate against immigrants or women, in a multilingual perspective, for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. In the second task (B), the system is also asked to classify the following sub-tasks : hateful tweets as aggressive or not aggressive, and to identify the target harassed as individual or generic. We evaluate multiple <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, and finally combine them in an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble setting</a>. This <a href="https://en.wikipedia.org/wiki/Ensemble_cast">ensemble setting</a> is built of five and three <a href="https://en.wikipedia.org/wiki/Model_(art)">submodels</a> for the English and Spanish task respectively. In the current setup it shows that using a bigger <a href="https://en.wikipedia.org/wiki/Musical_ensemble">ensemble</a> for English tweets performs mediocre, while a slightly smaller <a href="https://en.wikipedia.org/wiki/Musical_ensemble">ensemble</a> does work well for detecting <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> in Spanish tweets. Our results on the test set for <a href="https://en.wikipedia.org/wiki/English_language">English</a> show 0.378 macro F1 on task A and 0.553 macro F1 on task B. For <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> the results are significantly higher, 0.701 <a href="https://en.wikipedia.org/wiki/Macro_(computer_science)">macro F1</a> on task A and 0.734 <a href="https://en.wikipedia.org/wiki/Macro_(computer_science)">macro F1</a> for task B.</abstract>
      <url hash="9bd73a34">S19-2069</url>
      <doi>10.18653/v1/S19-2069</doi>
      <bibkey>zhang-etal-2019-grunn2019</bibkey>
    </paper>
    <paper id="72">
      <title>HATERecognizer at SemEval-2019 Task 5 : Using Features and Neural Networks to Face Hate Recognition<fixed-case>HATER</fixed-case>ecognizer at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Using Features and Neural Networks to Face Hate Recognition</title>
      <author><first>Victor</first><last>Nina-Alcocer</last></author>
      <pages>409–415</pages>
      <abstract>This paper presents a detailed description of our participation in task 5 on SemEval-2019. This task consists of classifying English and Spanish tweets that contain hate towards women or immigrants. We carried out several experiments ; for a finer-grained study of the task, we analyzed different <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and designing architectures of neural networks. Additionally, to face the lack of hate content in tweets, we include <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> as a technique to in- crease hate content in our <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>.</abstract>
      <url hash="a97a8493">S19-2072</url>
      <doi>10.18653/v1/S19-2072</doi>
      <bibkey>nina-alcocer-2019-haterecognizer</bibkey>
    </paper>
    <paper id="73">
      <title>GL at SemEval-2019 Task 5 : Identifying hateful tweets with a deep learning approach.<fixed-case>GL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Identifying hateful tweets with a deep learning approach.</title>
      <author><first>Gretel Liz</first><last>De la Peña</last></author>
      <pages>416–419</pages>
      <abstract>This paper describes the system we developed for SemEval 2019 on Multilingual detection of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> against immigrants and women in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> (HatEval-Task 5). We use an approach based on an Attention-based Long Short-Term Memory Recurrent Neural Network. In particular, we build a Bidirectional LSTM to extract information from the word embeddings over the sentence, then apply <a href="https://en.wikipedia.org/wiki/Attention">attention</a> over the hidden states to estimate the importance of each word and finally feed this context vector to another LSTM model to get a representation. Then, the output obtained with this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is used to get the prediction of each of the sub-tasks.</abstract>
      <url hash="4150b04f">S19-2073</url>
      <doi>10.18653/v1/S19-2073</doi>
      <bibkey>de-la-pena-2019-gl</bibkey>
    </paper>
    <paper id="74">
      <title>INF-HatEval at SemEval-2019 Task 5 : Convolutional Neural Networks for Hate Speech Detection Against Women and Immigrants on Twitter<fixed-case>INF</fixed-case>-<fixed-case>H</fixed-case>at<fixed-case>E</fixed-case>val at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Convolutional Neural Networks for Hate Speech Detection Against Women and Immigrants on <fixed-case>T</fixed-case>witter</title>
      <author><first>Alison</first><last>Ribeiro</last></author>
      <author><first>Nádia</first><last>Silva</last></author>
      <pages>420–425</pages>
      <abstract>In this paper, we describe our approach to detect <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> against women and immigrants on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> in a multilingual context, <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. This challenge was proposed by the SemEval-2019 Task 5, where participants should develop models for <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech detection</a>, a two-class classification where systems have to predict whether a tweet in English or in Spanish with a given target (women or immigrants) is hateful or not hateful (Task A), and whether the <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> is directed at a specific person or a group of individuals (Task B). For this, we implemented a Convolutional Neural Networks (CNN) using pre-trained word embeddings (GloVe and FastText) with 300 dimensions. Our proposed model obtained in Task A 0.488 and 0.696 <a href="https://en.wikipedia.org/wiki/F-score">F1-score</a> for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, respectively. For Task B, the <a href="https://en.wikipedia.org/wiki/CNN">CNN</a> obtained 0.297 and 0.430 <a href="https://en.wikipedia.org/wiki/English_language">EMR</a> for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, respectively.</abstract>
      <url hash="e34af83d">S19-2074</url>
      <doi>10.18653/v1/S19-2074</doi>
      <bibkey>ribeiro-silva-2019-inf</bibkey>
    </paper>
    <paper id="77">
      <title>LT3 at SemEval-2019 Task 5 : Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (hatEval)<fixed-case>LT</fixed-case>3 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants and Women in <fixed-case>T</fixed-case>witter (hat<fixed-case>E</fixed-case>val)</title>
      <author><first>Nina</first><last>Bauwelinck</last></author>
      <author><first>Gilles</first><last>Jacobs</last></author>
      <author><first>Véronique</first><last>Hoste</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>436–440</pages>
      <abstract>This paper describes our contribution to the SemEval-2019 Task 5 on the detection of hate speech against immigrants and women in Twitter (hatEval). We considered a supervised classification-based approach to detect <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> in English tweets, which combines a variety of standard lexical and syntactic features with specific <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for capturing offensive language. Our experimental results show good <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance on the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a>, but a considerable drop in <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a> on the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">held-out test set</a>.</abstract>
      <url hash="e950a437">S19-2077</url>
      <doi>10.18653/v1/S19-2077</doi>
      <bibkey>bauwelinck-etal-2019-lt3</bibkey>
    </paper>
    <paper id="79">
      <title>MineriaUNAM at SemEval-2019 Task 5 : Detecting Hate Speech in Twitter using Multiple Features in a Combinatorial Framework<fixed-case>M</fixed-case>ineria<fixed-case>UNAM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Detecting Hate Speech in <fixed-case>T</fixed-case>witter using Multiple Features in a Combinatorial Framework</title>
      <author><first>Luis Enrique</first><last>Argota Vega</last></author>
      <author><first>Jorge Carlos</first><last>Reyes-Magaña</last></author>
      <author><first>Helena</first><last>Gómez-Adorno</last></author>
      <author><first>Gemma</first><last>Bel-Enguix</last></author>
      <pages>447–452</pages>
      <abstract>This paper presents our approach to the Task 5 of Semeval-2019, which aims at detecting <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> against immigrants and women in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. The task consists of two sub-tasks, in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a> : (A) detection of hate speech and (B) classification of hateful tweets as aggressive or not, and identification of the target harassed as individual or group. We used linguistically motivated features and several types of n-grams (words, characters, functional words, punctuation symbols, POS, among others). For task A, we trained a <a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machine</a> using a combinatorial framework, whereas for task B we followed a multi-labeled approach using the Random Forest classifier. Our approach achieved the highest F1-score in sub-task A for the <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language</a>.</abstract>
      <url hash="c9718937">S19-2079</url>
      <doi>10.18653/v1/S19-2079</doi>
      <bibkey>argota-vega-etal-2019-mineriaunam</bibkey>
    </paper>
    <paper id="82">
      <title>STUFIIT at SemEval-2019 Task 5 : Multilingual Hate Speech Detection on Twitter with MUSE and ELMo Embeddings<fixed-case>STUFIIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Multilingual Hate Speech Detection on <fixed-case>T</fixed-case>witter with <fixed-case>MUSE</fixed-case> and <fixed-case>ELM</fixed-case>o Embeddings</title>
      <author><first>Michal</first><last>Bojkovský</last></author>
      <author><first>Matúš</first><last>Pikuliak</last></author>
      <pages>464–468</pages>
      <abstract>We present a number of <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a> used for hate speech detection for Semeval 2019 Task-5 : Hateval. We evaluate the viability of <a href="https://en.wikipedia.org/wiki/Multilingualism">multilingual learning</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We also experiment with <a href="https://en.wikipedia.org/wiki/Adversarial_learning">adversarial learning</a> as a means of creating a multilingual model. Ultimately our multilingual models have had worse results than their monolignual counterparts. We find that the choice of word representations (word embeddings) is very crucial for <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> as a simple switch between <a href="https://en.wikipedia.org/wiki/MUSE">MUSE</a> and ELMo embeddings has shown a 3-4 % increase in accuracy. This also shows the importance of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> when dealing with <a href="https://en.wikipedia.org/wiki/Online_content">online content</a>.</abstract>
      <url hash="8b6f8cd8">S19-2082</url>
      <doi>10.18653/v1/S19-2082</doi>
      <bibkey>bojkovsky-pikuliak-2019-stufiit</bibkey>
    </paper>
    <paper id="87">
      <title>The binary trio at SemEval-2019 Task 5 : Multitarget Hate Speech Detection in Tweets<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Multitarget Hate Speech Detection in Tweets</title>
      <author><first>Patricia</first><last>Chiril</last></author>
      <author><first>Farah</first><last>Benamara Zitoune</last></author>
      <author><first>Véronique</first><last>Moriceau</last></author>
      <author><first>Abhishek</first><last>Kumar</last></author>
      <pages>489–493</pages>
      <abstract>The massive growth of <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated web content</a> through <a href="https://en.wikipedia.org/wiki/Blog">blogs</a>, <a href="https://en.wikipedia.org/wiki/Internet_forum">online forums</a> and most notably, <a href="https://en.wikipedia.org/wiki/Social_media">social media networks</a>, led to a large spreading of hatred or abusive messages which have to be moderated. This paper proposes a supervised approach to hate speech detection towards immigrants and women in English tweets. Several <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have been developed ranging from feature-engineering approaches to <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural ones</a>.</abstract>
      <url hash="6350a720">S19-2087</url>
      <doi>10.18653/v1/S19-2087</doi>
      <bibkey>chiril-etal-2019-binary</bibkey>
    </paper>
    <paper id="88">
      <title>The Titans at SemEval-2019 Task 5 : Detection of hate speech against immigrants and women in Twitter<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Detection of hate speech against immigrants and women in <fixed-case>T</fixed-case>witter</title>
      <author><first>Avishek</first><last>Garain</last></author>
      <author><first>Arpan</first><last>Basu</last></author>
      <pages>494–497</pages>
      <abstract>This system paper is a description of the system submitted to SemEval-2019 Task 5 Task B for the <a href="https://en.wikipedia.org/wiki/English_language">English language</a>, where we had to primarily detect <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> and then detect aggressive behaviour and its target audience in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. There were two specific target audiences, immigrants and women. The language of the tweets was English. We were required to first detect whether a tweet is containing <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>. Thereafter we were required to find whether the tweet was showing aggressive behaviour, and then we had to find whether the targeted audience was an individual or a group of people.</abstract>
      <url hash="28f7a6de">S19-2088</url>
      <doi>10.18653/v1/S19-2088</doi>
      <bibkey>garain-basu-2019-titans</bibkey>
    </paper>
    <paper id="89">
      <title>TuEval at SemEval-2019 Task 5 : LSTM Approach to Hate Speech Detection in English and Spanish<fixed-case>T</fixed-case>u<fixed-case>E</fixed-case>val at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: <fixed-case>LSTM</fixed-case> Approach to Hate Speech Detection in <fixed-case>E</fixed-case>nglish and <fixed-case>S</fixed-case>panish</title>
      <author><first>Mihai</first><last>Manolescu</last></author>
      <author><first>Denise</first><last>Löfflad</last></author>
      <author><first>Adham Nasser</first><last>Mohamed Saber</last></author>
      <author><first>Masoumeh</first><last>Moradipour Tari</last></author>
      <pages>498–502</pages>
      <abstract>The detection of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, especially in online platforms and <a href="https://en.wikipedia.org/wiki/Internet_forum">forums</a>, is quickly becoming a hot topic as anti-hate speech legislation begins to be applied to public discourse online. The HatEval shared task was created with this in mind ; participants were expected to develop a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> capable of determining whether or not input (in this case, Twitter datasets in English and Spanish) could be considered <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> (designated as Task A), if they were aggressive, and whether the tweet was targeting an individual, or speaking generally (Task B). We approached this task by creating an <a href="https://en.wikipedia.org/wiki/Linear_time-invariant_system">LSTM model</a> with an <a href="https://en.wikipedia.org/wiki/Embedding">embedding layer</a>. We found that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performed considerably better on <a href="https://en.wikipedia.org/wiki/English_language">English language input</a> when compared to <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish language input</a>. In <a href="https://en.wikipedia.org/wiki/English_language">English</a>, we achieved an <a href="https://en.wikipedia.org/wiki/Standard_score">F1-Score</a> of 0.466 for Task A and 0.462 for Task B ; In <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</abstract>
      <url hash="df9516c2">S19-2089</url>
      <doi>10.18653/v1/S19-2089</doi>
      <bibkey>manolescu-etal-2019-tueval</bibkey>
    <title_ar>TuEval في SemEval-2019 المهمة 5: نهج LSTM للكشف عن الكلام الذي يحض على الكراهية باللغتين الإنجليزية والإسبانية</title_ar>
      <title_fr>TuEval au SEMEVAL-2019 Tâche 5 : Approche LSTM de la détection des discours haineux en anglais et en espagnol</title_fr>
      <title_pt>TuEval no SemEval-2019 Tarefa 5: Abordagem LSTM para Detecção de Discurso de Ódio em Inglês e Espanhol</title_pt>
      <title_es>TuEval en SemEval-2019 Tarea 5: Enfoque de LSTM para la detección del discurso de odio en inglés y español</title_es>
      <title_ja>SemEval -2019のTuEvalタスク5 ：英語とスペイン語でのヘイトスピーチ検出へのLSTMアプローチ</title_ja>
      <title_zh>周一在SemEval-2019务5:LSTM英语与西班牙语仇言检法</title_zh>
      <title_ru>TuEval на SemEval-2019 Задача 5: Подход LSTM к обнаружению ненавистнической речи на английском и испанском языках</title_ru>
      <title_hi>SemEval-2019 कार्य 5 में TuEval: अंग्रेजी और स्पेनिश में हेट स्पीच डिटेक्शन के लिए LSTM दृष्टिकोण</title_hi>
      <title_ga>TuEval ag SemEval-2019 Tasc 5: Cur Chuige LSTM i leith Brath Cainte i mBéarla agus i Spáinnis</title_ga>
      <title_el>Εργασία 5: Προσέγγιση για την ανίχνευση ομιλίας μίσους στα Αγγλικά και Ισπανικά</title_el>
      <title_hu>TuEval a SemEval-2019 5. feladat: LSTM megközelítés a gyűlölet beszédfelismerésére angol és spanyol nyelven</title_hu>
      <title_kk>TuEval at semiEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_kk>
      <title_it>TuEval al SemEval-2019 Task 5: L'approccio LSTM al rilevamento del parlato in inglese e spagnolo</title_it>
      <title_lt>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_lt>
      <title_mk>TuEval на SemEval-2019 задача 5: LSTM Approach to Hate Speech Detection на англиски и шпански</title_mk>
      <title_ms>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_ms>
      <title_ka>TuEval semiEval-2019 პარამეტრი 5: LSTM დახმარება წარმოდგენისთვის სიტყვების განახსნა ინგლისური და სპანელი</title_ka>
      <title_ml>സെമ്എവാല്‍- 2019 ടാസ്ക് 5: എംഎസ്റ്റിം ഇംഗ്ലീഷും സ്പാനിഷും ഇംഗ്ലീഷും വെറുപ്പുള്ള സംസാര ഡിറ്റീഷന്‍</title_ml>
      <title_mt>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_mt>
      <title_mn>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_mn>
      <title_no>TuEval ved semiEval-2019 oppgåve 5: LSTM-tilnærming til hatt-taleoppdaging på engelsk og spansk</title_no>
      <title_pl>Zadanie 5: Podejście LSTM do wykrywania mowy nienawiści w języku angielskim i hiszpańskim</title_pl>
      <title_ro>TuEval la SemEval-2019 Sarcina 5: Abordarea LSTM pentru detectarea vorbirii urâte în limba engleză și spaniolă</title_ro>
      <title_sr>TuEval na semiEval-2019 Task 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</title_sr>
      <title_si>Tueval at semeval-2019 Job 5: LSTM approach to Hate Talk Detection in English and Sphere</title_si>
      <title_so>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in Ingiriis and Isbanish</title_so>
      <title_ta>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_ta>
      <title_sv>TuEval på SemEval-2019 Uppgift 5: LSTM-metoden för att hata taldetektering på engelska och spanska</title_sv>
      <title_ur>ٹوئوئل-2019 ٹاکس 5 میں ٹوئوئل: LSTM انگلیسی اور اسپانیایی میں دشمنی بات شناسایے کے لئے تقریبا ہے</title_ur>
      <title_uz>SemEval- 2019 Vazifa 5: LSTM Approach to Hate Speech Detection Ingliz va Ispanchaga</title_uz>
      <title_vi>TuEval tại SemEvl-209 Task 5: LSTM tiếp cận đến ghét diễn văn bằng tiếng Anh và Tây Ban Nha</title_vi>
      <title_hr>TuEval na semiEval-2019 zadatak 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</title_hr>
      <title_nl>TuEval op SemEval-2019 Taak 5: LSTM aanpak van haatspraakdetectie in het Engels en Spaans</title_nl>
      <title_da>TuEval på SemEval-2019 Opgave 5: LSTM tilgang til hade tale detektering på engelsk og spansk</title_da>
      <title_bg>Задача 5: Подход към откриването на речта на омразата на английски и испански език</title_bg>
      <title_de>TuEval bei SemEval-2019 Aufgabe 5: LSTM Ansatz zur Hassspracherkennung in Englisch und Spanisch</title_de>
      <title_id>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_id>
      <title_ko>SemEval-2019의 TuEval 퀘스트 5: LSTM 방법으로 영어와 스페인어에서 증오의 음성을 검출</title_ko>
      <title_fa>TuEval at SemEval-2019 Task 5: LSTM Approach to hate speech detection in English and Spanish</title_fa>
      <title_sw>TuEval katika kazi ya SemEval-2019 5: LSTM Kuelekea Kutambua Hotuba ya Hati kwa Kiingereza na Kihispania</title_sw>
      <title_tr>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_tr>
      <title_af>TuEval by SemEval-2019 Opdrag 5: LSTM toegang na Hate Speech Deteksie in Engels en Spaanse</title_af>
      <title_am>አድራሻ</title_am>
      <title_sq>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_sq>
      <title_hy>Tuewal-ը սեմյալ 2019-ի 5. հանձնարարությունում. LSMT մոտեցումը ատելության խոսքի հայտնաբերելուն անգլերենով և իսպաներենով</title_hy>
      <title_bn>সেমইভাল-২০১৯ কাজের টুইভাল: এলএসএম ইংরেজি ও স্প্যানিশ ভাষায় ঘৃণা প্রকাশের জন্য যাওয়ার পথ</title_bn>
      <title_bs>TuEval na semiEval-2019 Task 5: LSTM pristup otkrivanju govora mržnje na engleskom i španjolskom</title_bs>
      <title_az>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_az>
      <title_ca>TuEval a SemEval-2019 tasca 5: LSTM Approach to Hate Speech Detection en anglès i espanyol</title_ca>
      <title_cs>Úkol 5: LSTM přístup k detekci nenávisti řeči v angličtině a španělštině</title_cs>
      <title_et>TuEval SemEval-2019 Ülesanne 5: LSTM lähenemine vihkamise kõne tuvastamisele inglise ja hispaania keeles</title_et>
      <title_fi>TuEval SemEval-2019 Tehtävä 5: LSTM-lähestymistapa vihapuheen havaitsemiseen englanniksi ja espanjaksi</title_fi>
      <title_jv>Tuinval nang seminval-2011 task 5: LTT M Method to Dese Speakch detection in French and Spanish</title_jv>
      <title_ha>QScriptBreakpointsModel</title_ha>
      <title_sk>TuEval na SemEval-2019 Naloga 5: pristop LSTM k odkrivanju sovražnega govora v angleščini in španščini</title_sk>
      <title_he>TuEval ב SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_he>
      <title_bo>TuEval at SemEval-2019 Task 5: LSTM Approach to Hate Speech Detection in English and Spanish</title_bo>
      <abstract_ar>أصبح الكشف عن خطاب الكراهية ، لا سيما في المنصات والمنتديات عبر الإنترنت ، موضوعًا ساخنًا سريعًا حيث بدأ تطبيق تشريعات مكافحة خطاب الكراهية على الخطاب العام عبر الإنترنت. تم إنشاء مهمة HatEval المشتركة مع وضع ذلك في الاعتبار ؛ كان من المتوقع أن يطور المشاركون نموذجًا قادرًا على تحديد ما إذا كانت المدخلات (في هذه الحالة ، مجموعات بيانات Twitter باللغتين الإنجليزية والإسبانية) يمكن اعتبارها كلامًا يحض على الكراهية (تم تحديدها كمهمة أ) ، إذا كانت عدوانية ، وما إذا كانت التغريدة تستهدف فردي ، أو يتحدث بشكل عام (المهمة ب). لقد تعاملنا مع هذه المهمة من خلال إنشاء نموذج LSTM بطبقة التضمين. وجدنا أن نموذجنا كان يعمل بشكل أفضل في إدخال اللغة الإنجليزية عند مقارنته بإدخال اللغة الإسبانية. في اللغة الإنجليزية ، حققنا درجة F1 من 0.466 للمهمة A و 0.462 للمهمة B ؛ في الإسبانية ، حققنا درجات 0.617 و 0.612 في المهمة أ والمهمة ب ، على التوالي.</abstract_ar>
      <abstract_pt>A detecção de discurso de ódio, especialmente em plataformas e fóruns on-line, está rapidamente se tornando um tema quente à medida que a legislação anti-discurso de ódio começa a ser aplicada ao discurso público on-line. A tarefa compartilhada HatEval foi criada com isso em mente; Esperava-se que os participantes desenvolvessem um modelo capaz de determinar se a entrada (neste caso, conjuntos de dados do Twitter em inglês e espanhol) poderia ou não ser considerada discurso de ódio (designado como Tarefa A), se fosse agressivo e se o tweet tinha como alvo um indivíduo, ou falando em geral (Tarefa B). Abordamos essa tarefa criando um modelo LSTM com uma camada de incorporação. Descobrimos que nosso modelo teve um desempenho consideravelmente melhor na entrada em inglês quando comparado à entrada em espanhol. Em inglês, obtivemos um F1-Score de 0,466 para a Tarefa A e 0,462 para a Tarefa B; Em espanhol, obtivemos pontuações de 0,617 e 0,612 na Tarefa A e na Tarefa B, respectivamente.</abstract_pt>
      <abstract_es>La detección de la incitación al odio, especialmente en plataformas y foros en línea, se está convirtiendo rápidamente en un tema candente a medida que la legislación contra la incitación al odio comienza a aplicarse al discurso público en línea. La tarea compartida HatEval se creó con esto en mente; se esperaba que los participantes desarrollaran un modelo capaz de determinar si los aportes (en este caso, los conjuntos de datos de Twitter en inglés y español) podían considerarse discurso de odio (designado como Tarea A), si eran agresivos y si el tuit era dirigirse a una persona o hablar en general (Tarea B). Abordamos esta tarea creando un modelo LSTM con una capa de incrustación. Descubrimos que nuestro modelo tuvo un rendimiento considerablemente mejor en la entrada del idioma inglés en comparación con la entrada en español. En inglés, logramos una puntuación F1 de 0.466 para la Tarea A y 0.462 para la Tarea B; en español, logramos puntuaciones de 0.617 y 0.612 en la Tarea A y la Tarea B, respectivamente.</abstract_es>
      <abstract_fr>La détection des discours de haine, en particulier sur les plateformes et les forums en ligne, devient rapidement un sujet brûlant alors que la législation anti-discours de haine commence à s'appliquer au discours public en ligne. La tâche partagée HatEval a été créée dans cet esprit ; les participants devaient développer un modèle capable de déterminer si les entrées (dans ce cas, les ensembles de données Twitter en anglais et en espagnol) pouvaient être considérées comme des discours haineux (désigné comme tâche A), s'ils étaient agressifs, et si le tweet était cibler un individu, ou parler de manière générale (tâche B). Nous avons abordé cette tâche en créant un modèle LSTM avec une couche d'intégration. Nous avons constaté que notre modèle fonctionnait considérablement mieux sur la saisie en anglais que sur la saisie en espagnol. En anglais, nous avons obtenu un score F1 de 0,466 pour la tâche A et de 0,462 pour la tâche B ; en espagnol, nous avons obtenu des scores de 0,617 et 0,612 pour la tâche A et la tâche B, respectivement.</abstract_fr>
      <abstract_ja>ヘイトスピーチの検出、特にオンラインプラットフォームやフォーラムでのヘイトスピーチの検出は、ヘイトスピーチ防止法がオンラインの公開講演に適用され始めると、すぐにホットな話題になり始めています。HatEval共有タスクは、これを念頭に置いて作成されました。参加者は、入力（この場合、英語とスペイン語のTwitterデータセット）がヘイトスピーチと見なされるかどうか（タスクAとして指定）、攻撃的であるかどうか、ツイートが個人を対象としているかどうか、または一般的に話しているかどうか（タスクB ）を判断できるモデルを開発することが期待されています。埋め込みレイヤーを持つLSTMモデルを作成することで、このタスクにアプローチしました。私たちのモデルは、スペイン語入力と比較して、英語入力でかなり優れたパフォーマンスを発揮することがわかりました。英語では、タスクAで0.466、タスクBで0.462のF 1スコアを達成しました。スペイン語では、タスクAとタスクBでそれぞれ0.617、0.612のスコアを達成しました。</abstract_ja>
      <abstract_zh>随仇立法,始用于在线公共语,仇言之检,特在在线台论坛中,速成一热门话题。 HatEval共享之务,虑及此而创之; 参与者期发一模,定输(于此,英语与西班牙语之Twitter数集)可以为仇言(指为任A),苟有攻击性,与推文为私言(任B)。 开创带嵌 LSTM 模以行之。 吾见西班牙语之输也,吾形于英语者多矣。 其在英语也,AF1分为0.466,B为0.462。 西班牙语之于事,A之于事B各得其0.6170.612之数。</abstract_zh>
      <abstract_hi>नफरत भाषण का पता लगाना, विशेष रूप से ऑनलाइन प्लेटफार्मों और मंचों में, जल्दी से एक गर्म विषय बन रहा है क्योंकि विरोधी नफरत भाषण कानून को ऑनलाइन सार्वजनिक प्रवचन पर लागू किया जाना शुरू हो जाता है। HatEval साझा कार्य को इस बात को ध्यान में रखते हुए बनाया गया था; प्रतिभागियों को यह निर्धारित करने में सक्षम एक मॉडल विकसित करने की उम्मीद थी कि इनपुट (इस मामले में, अंग्रेजी और स्पेनिश में ट्विटर डेटासेट) को हेट स्पीच (टास्क ए के रूप में नामित) माना जा सकता है या नहीं, अगर वे आक्रामक थे, और क्या ट्वीट किसी व्यक्ति को लक्षित कर रहा था, या आम तौर पर बोल रहा था (टास्क बी)। हमने एक एम्बेडिंग परत के साथ एक एलएसटीएम मॉडल बनाकर इस कार्य से संपर्क किया। हमने पाया कि हमारे मॉडल ने स्पेनिश भाषा इनपुट की तुलना में अंग्रेजी भाषा इनपुट पर काफी बेहतर प्रदर्शन किया। अंग्रेजी में, हमने कार्य A के लिए 0.466 और कार्य B के लिए 0.462 का F1-स्कोर प्राप्त किया; स्पेनिश में, हमने टास्क ए और टास्क बी पर क्रमशः 0.617 और 0.612 का स्कोर हासिल किया।</abstract_hi>
      <abstract_ru>Обнаружение ненавистнических высказываний, особенно на онлайн-платформах и форумах, быстро становится горячей темой, поскольку законодательство о борьбе с ненавистническими высказываниями начинает применяться к публичному дискурсу в Интернете. Общая задача HatEval была создана с учетом этого; участники должны были разработать модель, позволяющую определить, могут ли вводимые данные (в данном случае наборы данных Twitter на английском и испанском языках) рассматриваться в качестве высказываний, разжигающих ненависть (обозначенных как Задача A), если они являются агрессивными, и нацелен ли твит на отдельного человека, или говорящих в целом (Задача B). Мы подошли к этой задаче, создав модель LSTM со слоем встраивания. Мы обнаружили, что наша модель показала значительно лучшие результаты при вводе английского языка по сравнению с вводом испанского языка. На английском языке мы достигли показателя F1 - 0,466 для задачи A и 0,462 для задачи B; На испанском языке мы достигли показателей 0,617 и 0,612 для задачи A и задачи B, соответственно.</abstract_ru>
      <abstract_ga>Tá braite fuathchaint, go háirithe ar ardáin agus fóraim ar líne, ag éirí go han-tapa mar ábhar mór le rá de réir mar a thosaíonn reachtaíocht cainte frith-fuath a chur i bhfeidhm ar dhioscúrsa poiblí ar líne. Cruthaíodh an tasc roinnte HatEval leis seo san áireamh; bhíothas ag súil go bhforbródh rannpháirtithe samhail a bheadh in ann a chinneadh an bhféadfaí nó nach bhféadfaí ionchur (sa chás seo, tacair sonraí Twitter i mBéarla agus i Spáinnis) a mheas mar fhuathchaint (ainmnithe mar Thasc A), má bhí siad ionsaitheach, agus an raibh an tweet dírithe ar duine aonair, nó ag labhairt go ginearálta (Tasc B). Thugamar faoin tasc seo trí mhúnla LSTM a chruthú le ciseal leabaithe. Fuaireamar amach gur fheidhmigh ár samhail i bhfad níos fearr ar ionchur Béarla i gcomparáid le hionchur sa Spáinnis. I mBéarla, bhaineamar amach Scór F1 de 0.466 do Thasc A agus 0.462 do Thasc B; Sa Spáinnis, bhaineamar scóir 0.617 agus 0.612 amach ar Thasc A agus ar Thasc B, faoi seach.</abstract_ga>
      <abstract_ka>სხვადასხვა მპატის სიტყვას, განსაკუთრებით ინტერნეტი პლატორმებში და ფორმებში, სწრაფად იქნება სამყარო თემა, როგორც ანტი მპატის სიტყვას საკუთარი საკუთარი ინტერ HatEval სხვადასხვა საქმე იყო შექმნა ამით. მომხმარებელი იქნება მოდელის განვითარება, რომელიც შეუძლებელია განვითარება თუ არა შეიძლებელია მოდელის შესაძლებლობა (ამ შემთხვევაში, Twitter მონაცემები ინგლისური და სპანელი) შეიძლება იყოს წინაწინაწინაწინაწინაწინაწინაწინ ჩვენ ამ სამუშაო დავიწყეთ LSTM მოდელის შექმნა, რომელიც შეიძლება დავყენება. ჩვენ მივიღეთ, რომ ჩვენი მოდელი ინგლისური ენის შენახვედზე უკეთესი გავაკეთე, როდესაც სპანელი ენის შენახვედზე. ანგლისურად, ჩვენ მივიღეთ F1-Score 0.466 დავალებისთვის A და 0.462 დავალებისთვის B დავალებისთვის; სპანუალურად ჩვენ მივიღეთ 0.617 და 0.612 დავალებით A და B დავალებით.</abstract_ka>
      <abstract_hu>A gyűlöletbeszéd felismerése, különösen az online platformokon és fórumokon, gyorsan forró témává válik, mivel a gyűlöletbeszéd elleni jogszabályok kezdenek alkalmazni az online nyilvános diskurzusra. A HatEval megosztott feladatot ezzel szem előtt tartva hozták létre; A résztvevőktől elvárták, hogy olyan modellt dolgozzanak ki, amely meghatározza, hogy a bevitel (ebben az esetben angol és spanyol Twitter adatkészletek) gyűlöletbeszédnek tekinthető-e (A feladatként jelölt), agresszív-e, és hogy a tweet egy személyt céloz-e, vagy általánosan beszél (B feladat). Ezt a feladatot egy beágyazó réteggel ellátott LSTM modell létrehozásával közelítettük meg. Megállapítottuk, hogy modellünk jelentősen jobban teljesített az angol nyelvű bevitel tekintetében, mint a spanyol nyelvű bevitel. Angolul 1 pontszámot értünk el az A feladatnál, a B feladatnál pedig 0,462 pontszámot; Spanyolul 0,617 és 0,612 pontszámot értünk el az A és B feladaton.</abstract_hu>
      <abstract_el>Η ανίχνευση της ρητορικής μίσους, ειδικά σε διαδικτυακές πλατφόρμες και φόρουμ, γίνεται γρήγορα καυτό θέμα καθώς η νομοθεσία περί ρητορικής μίσους αρχίζει να εφαρμόζεται στον δημόσιο διάλογο στο διαδίκτυο. Το κοινό έργο της HatEval δημιουργήθηκε με αυτό κατά νου. Αναμένεται από τους συμμετέχοντες να αναπτύξουν ένα μοντέλο ικανό να καθορίσει αν η εισαγωγή (σε αυτή την περίπτωση, σύνολα δεδομένων Twitter στα αγγλικά και ισπανικά) θα μπορούσε να θεωρηθεί ρητορική μίσους (που ορίζεται ως εργασία Α), αν ήταν επιθετική και αν το tweet στόχευε ένα άτομο ή μιλούσε γενικά (εργασία Β). Προσεγγίσαμε αυτό το έργο δημιουργώντας ένα μοντέλο με ένα στρώμα ενσωμάτωσης. Διαπιστώσαμε ότι το μοντέλο μας αποδίδει σημαντικά καλύτερα στην εισαγωγή της αγγλικής γλώσσας σε σύγκριση με την εισαγωγή της ισπανικής γλώσσας. Στα αγγλικά, πετύχαμε έναν δείκτη F1 0.466 για την εργασία A και 0.462 για την εργασία B. Στα ισπανικά, πετύχαμε βαθμολογίες 0.617 και 0.612 για την εργασία Α και την εργασία Β αντίστοιχα.</abstract_el>
      <abstract_it>L'individuazione del discorso d'odio, soprattutto nelle piattaforme e nei forum online, sta rapidamente diventando un argomento caldo, poiché la legislazione anti-odio del discorso inizia ad essere applicata al discorso pubblico online. Il compito condiviso di HatEval è stato creato con questo in mente; Ci si aspettava che i partecipanti sviluppassero un modello in grado di determinare se l'input (in questo caso, i dataset di Twitter in inglese e spagnolo) potessero essere considerati discorsi di odio (designati come Task A), se fossero aggressivi, e se il tweet fosse rivolto a un individuo, o parlando in generale (Task B). Abbiamo affrontato questo compito creando un modello LSTM con un livello embedding. Abbiamo scoperto che il nostro modello ha funzionato notevolmente meglio sull'input in lingua inglese rispetto all'input in lingua spagnola. In inglese, abbiamo ottenuto un F1-Score di 0,466 per Task A e 0,462 per Task B; In spagnolo, abbiamo ottenuto punteggi di 0,617 e 0,612 rispettivamente sul Task A e sul Task B.</abstract_it>
      <abstract_lt>Neapykantos kalbos aptikimas, ypač internetinėse platformose ir forumuose, greitai tampa karšta tema, nes kovos su neapykanta kalbos teisės aktai pradedami taikyti viešajai kalbai internete. HatEval bendra užduotis buvo sukurta atsižvelgiant į tai; tikėtasi, kad dalyviai parengs model į, galintį nustatyti, ar įvestis (šiuo atveju Twitter duomenų rinkiniai anglų ir ispanų kalbomis) gali būti laikomas neapykantos kalba (vadinama A užduotimi), jei jie yra agresyvūs, ir ar Twitter skirtas asmeniui, ar kalbama apskritai (B užduotis). Atlikome šią užduotį sukūrėme LSTM model į su įterpiamuoju sluoksniu. Nustatėme, kad mūsų modelis gerokai geriau atliko anglų kalbos įnašus, palyginti su ispanų kalbos įnašais. In English, we achieved an F1-Score of 0.466 for Task A and 0.462 for Task B;  Ispanų kalba pasiekėme atitinkamai 0,617 ir 0,612 rezultatų A ir B užduotyse.</abstract_lt>
      <abstract_kk>Жұмыс сөйлеуді, әсіресе онлайн платформаларда және форумдарда, жылдам жетістік сөйлеуді қарсы сөйлеу заң онлайн істеу үшін қолданылады. HatEval ортақ тапсырмасы оқылған. Қатысушыларға қатысушылардың келтірілмегенін анықтауға мүмкіндік беретін үлгісін жасау үшін күту болды (бұндай болса, Twitter деректер қорлары ағылшын және испан тілінде) қатысу сөзі (A тапсырма ретінде анықталған), егер олар агрессивне болса, және Біз осы тапсырманы ендіру қабатты LSTM үлгісін құрып келдік. Біз үлгіміздің ағылшын тілінің келтіріміне сәйкес Испан тілінің келтіріміне салыстырып жатыр деп ойладық. Ағылшын тілінде, B тапсырмасына A және 0,462 тапсырма үшін F1-Score жеткіздік. Испан тілінде Б тапсырмасында 0,617 және 0,612 нәтижелерін жеткіздік.</abstract_kk>
      <abstract_mk>Детектирањето на говорот за омраза, особено на онлајн платформи и форуми, брзо станува жешка тема бидејќи легислативата против омразата почнува да се применува на јавниот дискурс онлајн. Со ова беше создадена заедничката задача на HatEval; учесниците се очекуваа да развијат модел кој може да одреди дали влогот (во овој случај, датотеките на Твитер на англиски и шпански) може да се смета за говор на омраза (назначен како задача А), ако бил агресивен, и дали твитот бил насочен кон индивидуал или зборувал генерално (задача Б). Се приближивме до оваа задача со создавање на LSTM модел со вграден слој. Најдовме дека нашиот модел успеа значително подобро на влогот на англискиот јазик во споредба со влогот на шпанскиот јазик. На англиски, постигнавме F1-Score од 0,466 за задачата А и 0,462 за задачата Б; На шпански, постигнавме оценки од 0,617 и 0,612 за задачата А и задачата Б, односно.</abstract_mk>
      <abstract_ms>Pengesanan ucapan kebencian, terutama dalam platform dan forum online, cepat menjadi topik yang panas kerana undang-undang ucapan anti-kebencian bermula untuk dilaksanakan pada diskors awam online. Tugas berkongsi HatEval dicipta dengan ini dalam fikiran; peserta dijangka untuk mengembangkan model yang mampu menentukan sama ada input (dalam kes ini, set data Twitter dalam bahasa Inggeris dan Sepanyol) boleh dianggap pidato kebencian (ditentukan sebagai Tugas A), jika mereka agresif, dan sama ada tweet adalah sasaran individu, atau bercakap secara umum (Tugas B). Kami mendekati tugas ini dengan mencipta model LSTM dengan lapisan penyembedding. Kami mendapati bahawa model kami dilakukan jauh lebih baik pada input bahasa Inggeris apabila dibandingkan dengan input bahasa Sepanyol. Dalam bahasa Inggeris, kita mencapai nilai F1 0.466 untuk Tugas A dan 0.462 untuk Tugas B; Dalam bahasa Sepanyol, kami mencapai skor 0.617 dan 0.612 pada Tugas A dan Tugas B, berdasarkan itu.</abstract_ms>
      <abstract_ml>വെറുപ്പ് സംസാരം കണ്ടുപിടിക്കുന്നത്, പ്രത്യേകിച്ച് ഓണ്‍ലൈന്‍ പ്ലാറ്റ്ഫോമുകളിലും ഫോര്‍മുകളിലും പ്രത്യേകിച്ച് ചൂടുള്ള വിഷയത്തിലാ ഹാറ്റെവാല്‍ പങ്കാളിയുള്ള ജോലി ഇതിന്‍റെ മനസ്സില്‍ സൃഷ്ടിച്ചിരിക്കുന്നു; participants were expected to develop a model capable of determining whether or not input (in this case, Twitter datasets in English and Spanish) could be considered hate speech (designated as Task A), if they were aggressive, and whether the tweet was targeting an individual, or speaking generally (Task B).  ഞങ്ങള്‍ ഈ ജോലിയിലേക്ക് എത്തിയപ്പോള്‍ ഒരു എംഎസ്റ്റം മോഡല്‍ ഉണ്ടാക്കുന്നത് കൊണ്ടാണ്. സ്പാനിഷ് ഭാഷ ഇന്‍പുട്ടിനെക്കുറിച്ച് താല്‍പ്പര്യമായി ഞങ്ങളുടെ മോഡല്‍ ഇംഗ്ലീഷ് ഭാഷ അകത്തില്‍ വളരെ നല്ലത് പ ഇംഗ്ലീഷില്‍ ഞങ്ങള്‍ ഒരു എഫ്‌1-സ്കോര്‍ നേടിയെടുത്തു. ടാസ്ക് ബിന് വേണ്ടി ടാസ്ക് A എന്നും 0.462 എന്നിവയ്ക്കും; സ്പാനിഷില്‍ ഞങ്ങള്‍ നിര്‍ണ്ണയിക്കപ്പെട്ട സ്കോര്‍ 0.617, 0.612 ടാസ്ക് A, ടാസ്ക് ബിയില്‍ എത്തി.</abstract_ml>
      <abstract_mt>Is-sejba tad-diskors tal-mibegħda, speċjalment fil-pjattaformi u l-forums onlajn, qed issir malajr suġġett sħun hekk kif il-leġiżlazzjoni kontra d-diskors tal-mibegħda tibda tiġi applikata għad-diskors pubbliku onlajn. The HatEval shared task was created with this in mind;  il-parteċipanti kienu mistennija jiżviluppaw mudell li jkun kapaċi jiddetermina jekk l-input (f’dan il-każ, settijiet ta’ dejta Twitter bl-Ingliż u bl-Ispanjol) jistax jitqies bħala diskors ta’ mibegħda (magħżul bħala Task A), jekk dawn kienu aggressivi, u jekk it-tweet kienx immirat lejn individwu, jew jitkellmu b’mod ġenerali (Task B). Aċċettajna dan il-kompitu billi nħolqu mudell LSTM b’saff ta’ inkorporazzjoni. Instabna li l-mudell tagħna sar konsiderevolment aħjar fuq l-input tal-lingwa Ingliża meta mqabbel mal-input tal-lingwa Spanjola. Bil-Ingliż, inkisbu Punteġġ F1 ta’ 0.466 għal Kompitu A u 0.462 għal Kompitu B; Bl-Ispanjol, kisbu punteġġi ta’ 0.617 u 0.612 fuq il-Kompitu A u l-Kompitu B, rispettivament.</abstract_mt>
      <abstract_mn>Харамсалтай яриаг олох нь, ялангуяа онлайн платформ болон форумууд, хурдан үзэн ядуурлын ярианы эсрэг хууль нь нийтийн ярианы онлайн үеэр хэрэглэгдэх болно. HatEval-ын хуваалтын ажил үүнийг бодолд бий болгосон. Хэрэв оролцогчдын оролцогчдын оролцогчдын оролцоог тодорхойлох боломжтой загвар хөгжүүлэхийг хүсэж байлаа (энэ тохиолдолд Твиттер өгөгдлийн сангууд Англи болон Испан хэлний хэлний хэлний хэлний үзэн ядах хэлний хэлний хэлний хэлний хэлний хэлний хэлбэр Бид үүнийг LSTM загвар бий болгож ойртсон. Бид өөрсдийн загварын загвар Испанийн хэлний оролцоос харьцуулахад Англи хэлний оролцоонд маш сайн ажиллаж байгааг олж мэдсэн. Англи хэлний хэлээр бид Task A болон 0.462 Task B-д F1-Score хүртлээ. Испанид бид 0.617, 0.612 Task A болон Task B-ийн тоонуудыг олсон.</abstract_mn>
      <abstract_no>Oppdaging av hatespråk, spesielt i nettplattformar og forummer, er raskt å bli eit vart tema, sidan anti-hatespråk-lovgivnaden begynner å bli brukt på offentlige diskursar på nettet. HatEval delt oppgåve vart oppretta med dette i sinn. Forventa deltakarar å utvikle eit modell som kan bestemme om inndata (i dette tilfellet kan Twitter- datasett i engelsk og spansk) bli kalla som hatspråk (designert som oppgåve A), dersom dei var aggressiv, og om tweetet målet på ein individuell eller snakket vanlegvis (oppgåve B). Vi har nærmet denne oppgåva ved å laga eit LSTM-modell med eit innebygd lag. Vi fann at modellen vårt utførte mykje bedre på inndata av engelsk språk når det sammenlignet med inndata frå spansk språk. I engelsk oppnådd vi eit F1-poeng med 0,466 for oppgåve A og 0,462 for oppgåve B; I spansk oppnådd vi poeng 0,617 og 0,612 om oppgåve A og oppgåve B.</abstract_no>
      <abstract_pl>Wykrywanie mowy nienawiści, zwłaszcza na platformach internetowych i forach, szybko staje się gorącym tematem, ponieważ ustawodawstwo dotyczące mowy nienawiści zaczyna być stosowane w dyskursie publicznym online. Wspólne zadanie HatEval zostało stworzone z myślą o tym; Oczekiwano, że uczestnicy opracowali model zdolny do określenia, czy wejście (w tym przypadku zbiory danych Twittera w języku angielskim i hiszpańskim) można uznać za mowę nienawiści (określoną jako zadanie A), czy były agresywne i czy tweet był skierowany do osoby, czy mówiąc ogólnie (zadanie B). Podejśliśmy do tego zadania tworząc model LSTM z warstwą osadzania. Stwierdziliśmy, że nasz model działał znacznie lepiej na wprowadzeniu języka angielskiego w porównaniu z wprowadzeniem języka hiszpańskiego. W języku angielskim osiągnęliśmy wynik F1 0.466 dla zadania A i 0.462 dla zadania B; W języku hiszpańskim osiągnęliśmy wyniki 0.617 i 0.612 odpowiednio w zadaniu A i zadaniu B.</abstract_pl>
      <abstract_ro>Detectarea discursului la ură, în special în platformele și forumurile online, devine rapid un subiect fierbinte, deoarece legislația anti-ură începe să fie aplicată discursului public online. Sarcina comună HatEval a fost creată având în vedere acest lucru; Se aștepta ca participanții să dezvolte un model capabil să determine dacă introducerea (în acest caz, seturile de date Twitter în limbile engleză și spaniolă) ar putea fi considerate discursuri la ură (desemnate ca sarcina A), dacă acestea erau agresive și dacă tweetul viza o persoană sau vorbea în general (sarcina B). Am abordat această sarcină prin crearea unui model LSTM cu un strat de încorporare. Am constatat că modelul nostru a performat considerabil mai bine la introducerea limbii engleze în comparație cu introducerea limbii spaniole. În limba engleză, am obținut un scor F1 de 0,466 pentru Task A și 0,462 pentru Task B; În limba spaniolă, am obținut scoruri de 0,617 și 0,612 la Task A și, respectiv, Task B.</abstract_ro>
      <abstract_sr>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval je podijeljen zadatak stvoren na umu s tim; Očekivalo se da će sudionici razviti model sposoban za određivanje da li ulaz (u ovom slučaju, Twitter podaci na engleskom i španjolskom jeziku) mogli biti smatrani govorem mržnje (izraženim kao Task A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (Task B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Pronašli smo da je naš model mnogo bolji u odnosu na engleski jezik u usporedbi sa španjolskim jezikom. Na engleskom jeziku, postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</abstract_sr>
      <abstract_si>විශේෂයෙන් ඉන්ලයින් ප්‍රවේශනය සහ ප්‍රවේශනයේ විශේෂ කතාවක් හොයාගන්න, ඉක්මනින් වේගයෙන් විශේෂ ප්‍රවේශයක් වෙනවා  Hateval කොටස් එක්ක මේක මතකයෙන් නිර්මාණය කරලා තියෙනවා; අංශිකාරීන්ට ප්‍රමාණයක් හොයාගන්න බලාපොරොත්තු වුනා ප්‍රමාණයක් නිර්මාණය කරන්න පුළුවන් (මේ විදියට, Twitter දත්ත සේට් ඉංග්‍රීසි සහ ස්පැනිස් වලින්) විරෝ අපි මේ කාර්යය සම්බන්ධ කරනවා LSTM මොඩල් හදන්න. අපි හොයාගත්තා අපේ මොඩල් ඉංග්‍රීසි භාෂාව ඇතුලට ගොඩක් හොඳයි කියලා ස්පැනිස් භාෂාව ඇතුල ඉංග්‍රීසියෙන්, අපිට F1-Score of 0.466 for Job A and 0.462 for Job B; ස්පැනිස් වලින්, අපි 0.617 සහ 0.612 වැඩ A වලින් වැඩ B වලින් ප්‍රමාණයක් ලැබුනා.</abstract_si>
      <abstract_so>Dhaqso u noqonaya mada kulul, sababtoo ah sharciga aan nebcaan ka jeedo ayaa laga bilaabaa in lagu codsado hadalka bulshada internetka. Shaqada HatEval la qaybsaday waxaa lagu abuuray maankan; Kuwii ka qeybqaaday waxaa la rajaynayay inuu horumariyo model awoodo inuu ogaado input ama input (taas darteed, taariikhda Twitterka ee Ingiriis iyo Isbanish) waxaa looga xisaabin karaa hadal nacayb ah (taas oo loo qoray shaqo A), haddii ay xadgudub leeyihiin iyo in twitterigu uu ku hagaajiyey mid gaar ah ama uu ku hadli karo sida caadiga ah (Task B). Waxan u dhawaaqnay sameynta model LSTM oo leh darajada burka ah. We found that our model performed considerably better on English language input when compared to Spanish language input.  Ingiriiska, waxaynu helnay qiimaha F1-scorta 0.466 ee shaqo A iyo 0.462 shaqo B; Isbanishka waxaan ku gaadhnay kooxo u eg 0.617 iyo 0.612 shaqo A iyo shaqo B.</abstract_so>
      <abstract_sv>Upptäckten av hatpropaganda, särskilt i onlineplattformar och forum, håller snabbt på att bli ett hett ämne eftersom anti-hatpropaganda lagstiftning börjar tillämpas på offentlig debatt på nätet. HatEval delade uppgift skapades med detta i åtanke; Deltagarna förväntades utveckla en modell som kunde avgöra om inmatning (i detta fall Twitter-dataset på engelska och spanska) kunde betraktas som hatpropaganda (benämnd som uppgift A), om de var aggressiva, och om tweeten riktade sig till en individ eller talade generellt (uppgift B). Vi närmade oss denna uppgift genom att skapa en LSTM-modell med ett inbäddningslager. Vi fann att vår modell presterade betydligt bättre på engelska språkinput jämfört med spanska språkinput. På engelska uppnådde vi en F1-poäng på 0,466 för uppgift A och 0,462 för uppgift B; På spanska uppnådde vi poäng på 0,617 respektive 0,612 på uppgift A respektive uppgift B.</abstract_sv>
      <abstract_ta>வெறுப்பு பேச்சை கண்டுபிடிப்பது, குறிப்பாக இணைய தளங்களில் மற்றும் தளங்களில், விரைவாக ஒரு சூடான தலைப்பாடு ஆகிவிடுகிறது, ஏனெனில் வெறுப HatEval பகிர்ந்த பணி இந்த மனதில் உருவாக்கப்பட்டது; பங்கீட்டாளர்கள் ஒரு மாதிரி உருவாக்க வேண்டும் என்று எதிர்பார்க்கப்பட்டுள்ளார்கள் (இந்த நிலையில், ஆங்கிலம் மற்றும் ஸ்பானிஷ் மொழியில் இருந்த Twitter தரவுத்தளங்கள்) வெறுப் நாங்கள் இந்த செயலை அணுகின்றோம் ஒரு உள்ளீட்டு அடுக்கு ஒரு LSTM மாதிரி உருவாக்கினோம். ஸ்பானிஷ் மொழி உள்ளீட்டை ஒப்பிடும்போது எங்கள் மாதிரி மொழி உள்ளீட்டில் மிகவும் நல்ல செயல்பட்டது என்பதை நா ஆங்கிலத்தில், நாங்கள் பணி A மற்றும் 0. 462 பணி B க்கு ஒரு F1- மதிப்பு அடைந்தோம். ஸ்பானிஷில், நாங்கள் வேலை A மற்றும் பணி B மீது 0.617 மற்றும் 0.612 மதிப்புகளை அடைந்தோம்.</abstract_ta>
      <abstract_ur>ناپسندیدہ بات کی تلاش، مخصوصاً آنلاین پلٹورم اور فورمز میں، جلد ایک گرم موضوع ہو رہی ہے جس طرح ناپسندیدہ بات کا قوانین آنلاین کی صحبت پر قائم ہوتا ہے. اس کے ذریعہ سے ہٹوئل کا کام بنایا گیا ہے شرکت کرنے والوں کی انتظار کی گئی تھی کہ ایک موڈل ایجاد کریں جس کا اختیار رکھتا تھا کہ ان کے سوال کیا جائے یا نہ ہو (اس صورت میں توئیٹ ڈاٹسٹ انگلیسی اور اسپانیایی میں) نفرت کی بات سمجھ سکتی تھی (تابع A کے نام کا نام) اگر وہ نازل ہوتی تھی، اور اگر توئیٹ ایک شخص کی هدف رکھتا تھا ہم نے اس کام کے پاس ایک ایمبڈینگ لائر کے ساتھ LSTM موڈل پیدا کر دیا۔ ہم نے پایا کہ ہمارا مدل انگلیسی زبان انپیٹ پر بہتر عمل کیا جب اسپانیایی زبان انپیٹ کے مقابلہ میں۔ انگلیسی میں ہم نے Task A اور Task B کے لئے 0.466 کی F1-Score کو پہنچا دیا۔ اسپانیایی میں ہم نے 0.617 اور 0.612 کو Task A اور Task B کے ذریعہ پہنچایا۔</abstract_ur>
      <abstract_uz>The detection of hate speech, especially in online platforms and forums, is quickly becoming a hot topic as anti-hate speech legislation begins to be applied to public discourse online.  HatEval shu miya bilan birlashtirilgan vazifa yaratildi; Bu tilda ishlatilgan shaklni ishlatish mumkin. Bu tilda, ingliz va Ispanchada Twitterning maʼlumotlar soni aniqlash mumkin (Vazifa A deb aniqlangan) deb hisoblanadi. Biz bu vazifani eng qatlam bilan LSTM modelini yaratish bilan keldik. Bizning modelimiz Ispancha tili ichiga o'xshash tilda ingliz tili ichida juda yaxshi ishlayotgan edi. Ingliz tilida biz Vazifa B uchun 0.466 vazifasi 0.462 va 0.462 uchun F1-scori topdik; Ispanchada biz vazifa A va vazifa B bilan 0.617 va 0.612 darajalarini topdik.</abstract_uz>
      <abstract_vi>Việc phát hiện ngôn ngữ căm ghét, đặc biệt trong các diễn đàn trực tuyến, đang nhanh chóng trở thành một chủ đề nóng bỏng vì dự luật chống ghét ngôn ngữ bắt đầu được áp dụng vào các buổi diễn thuyết trên mạng. Đội HatEvol đã tham gia nhiệm vụ được tạo ra với ý tưởng này; Người tham dự dự sẽ phát triển một mô hình có khả năng xác định xem nội dung của Twitter (trong trường hợp này, dữ liệu trên Twitter bằng tiếng Anh và tiếng Tây B an Nha) có thể được coi là biểu diễn căm ghét (được gọi là Nhiệm vụ A), nếu họ hung hăng, và rằng tweet đã nhắm vào một cá nhân, hay nói chung (Nhiệm vụ B). Chúng tôi đã tiếp cận nhiệm vụ này bằng cách tạo một mô hình LSD với một lớp nhúng. Chúng tôi thấy mẫu của chúng tôi diễn đạt tốt hơn rất nhiều trong việc nhập tiếng Anh so với nhập ngôn ngữ Tây Ban Nha. Nói tiếng Anh, chúng tôi đã đạt được một F1-Score of 0.46 for Task A và 0.46 for Task B; Ở Tây Ban Nha, chúng tôi đã đạt được điểm số 0.67 và 0.62 về Hợp đồng A và Task B.</abstract_vi>
      <abstract_bg>Откриването на речта на омразата, особено в онлайн платформи и форуми, бързо се превръща в гореща тема, тъй като законодателството против речта на омразата започва да се прилага към публичния дискурс онлайн. Споделената задача на ХатЕвал е създадена с това предвид; от участниците се очаква да разработят модел, който да определи дали въвеждането (в този случай набори от данни на английски и испански език) може да се счита за реч на омразата (определена като задача А), дали те са агресивни и дали туитът е насочен към индивид или говори общо (задача Б). Ние подходихме към тази задача чрез създаване на модел с вграден слой. Открихме, че нашият модел се представя значително по-добре при въвеждането на английски език в сравнение с въвеждането на испански език. На английски език постигнахме оценка от 0,466 за задача А и 0,462 за задача Б; На испански език постигнахме резултати от 0,617 и 0,612 съответно по задача А и задача Б.</abstract_bg>
      <abstract_da>Afsløringen af hadefulde taler, især i onlineplatforme og fora, er hurtigt ved at blive et varmt emne, da anti-hadefulde talelovgivninger begynder at blive anvendt på den offentlige diskurs online. HatEval delte opgave blev skabt med dette i tankerne; Deltagerne forventedes at udvikle en model, der kunne afgøre, om input (i dette tilfælde Twitter-datasæt på engelsk og spansk) kunne betragtes som hadefuld tale (betegnet som opgave A), om de var aggressive, og om tweetet var rettet mod en person eller generelt (opgave B). Vi nåede denne opgave ved at skabe en LSTM model med et integreringslag. Vi fandt ud af, at vores model fungerede betydeligt bedre på engelsk sproginput sammenlignet med spansk sproginput. På engelsk opnåede vi en F1-score på 0,466 for opgave A og 0,462 for opgave B; På spansk opnåede vi scorer på henholdsvis 0,617 og 0,612 på opgave A og opgave B.</abstract_da>
      <abstract_hr>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval zajednički zadatak je stvoren na umu s tim; Očekivalo se da će učesnici razviti model sposoban za utvrđivanje da li ulaz (u tom slučaju, Twitter podaci na engleskom i španjolskom) smatrati govorem mržnje (izraženim kao zadatak A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (zadatak B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Našli smo da je naš model izvršio značajno bolje u odnosu na ulaz engleskog jezika u usporedbi s ulazom španjolskog jezika. Na engleskom jeziku postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</abstract_hr>
      <abstract_de>Die Erkennung von Hassreden, insbesondere in Online-Plattformen und Foren, wird schnell zu einem heißen Thema, da Anti-Hass-Redegesetzgebung beginnt, auf den öffentlichen Diskurs online anzuwenden. Die gemeinsame Aufgabe von HatEval wurde in diesem Sinne geschaffen; Von den Teilnehmern wurde erwartet, dass sie ein Modell entwickeln, das bestimmen kann, ob Eingaben (in diesem Fall Twitter-Datensätze auf Englisch und Spanisch) als Hassrede (als Aufgabe A bezeichnet) angesehen werden können, ob sie aggressiv sind und ob der Tweet auf eine Person abzielt oder allgemein gesprochen wurde (Aufgabe B). Wir näherten uns dieser Aufgabe, indem wir ein LSTM-Modell mit einer Einbettungsebene erstellt haben. Wir fanden heraus, dass unser Modell wesentlich besser auf Englisch eingegeben wurde als auf Spanisch. Auf Englisch erreichten wir einen F1-Score von 0.466 für Aufgabe A und 0.462 für Aufgabe B; Auf Spanisch erreichten wir Punkte von 0.617 und 0.612 bei Task A bzw. Task B.</abstract_de>
      <abstract_nl>Het opsporen van haatspraak, met name in online platforms en fora, wordt snel een hot topic aangezien anti-haatspraak wetgeving begint te worden toegepast op het publieke discours online. De HatEval gedeelde taak is met dit in gedachten gecreëerd; Van de deelnemers werd verwacht dat zij een model zouden ontwikkelen dat kan bepalen of invoer (in dit geval Twitter-datasets in het Engels en Spaans) als haatspraak (aangeduid als Taak A) kon worden beschouwd, of ze agressief waren en of de tweet gericht was op een individu, of in het algemeen sprak (Taak B). We benaderden deze taak door een LSTM model te maken met een embedding laag. We vonden dat ons model aanzienlijk beter presteerde op invoer in de Engelse taal in vergelijking met invoer in de Spaanse taal. In het Engels behaalden we een F1-Score van 0.466 voor Taak A en 0.462 voor Taak B; In het Spaans behaalden we scores van 0.617 en 0.612 op respectievelijk Taak A en Taak B.</abstract_nl>
      <abstract_id>Deteksi pidato kebencian, terutama di platform dan forum online, cepat menjadi topik panas karena undang-undang pidato anti kebencian mulai diaplikasikan pada pidato publik online. Tugas bersama HatEval diciptakan dengan ini dalam pikiran; peserta diharapkan untuk mengembangkan model yang mampu menentukan apakah input (dalam kasus ini, set data Twitter dalam bahasa Inggris dan Spanyol) dapat dianggap pidato kebencian (ditentukan sebagai Tugas A), jika mereka agresif, dan apakah tweet menargetkan individu, atau berbicara secara umum (Tugas B). Kami mendekati tugas ini dengan menciptakan model LSTM dengan lapisan penerbangan. We found that our model performed considerably better on English language input when compared to Spanish language input.  Dalam bahasa Inggris, kami mencapai nilai F1 0,466 untuk Tugas A dan 0,462 untuk Tugas B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</abstract_id>
      <abstract_ko>혐오 언론 입법이 온라인 공공 언어에 적용되기 시작하면서 혐오 언론의 검측은 특히 온라인 플랫폼과 포럼에서 빠르게 화제가 되고 있다.HatEval 공유 작업은 이 점을 바탕으로 만들어진 것이다.참가자들은 입력(이 예에서 영어와 스페인어의 트위터 데이터 집합)이 증오 발언(퀘스트 a로 지정)으로 볼 수 있는지, 공격성이 있는지, 이 트위터가 개인을 겨냥했는지 아니면 동일시(퀘스트 B)로 볼 수 있는지를 확인할 수 있는 모델을 개발해야 한다.내장 레이어가 있는 LSTM 모델을 생성하여 이 작업을 완료했습니다.우리는 스페인어 입력에 비해 우리의 모델이 영어 입력에 있어서 더욱 잘 표현되는 것을 발견했다.영어에서는 미션 A의 F1 성적이 0.466이고 미션 B의 F1 성적이 0.462이다.스페인어에서는 미션 A와 미션 B에서 각각 0.617, 0.612의 점수를 받았다.</abstract_ko>
      <abstract_fa>کشف سخنرانی از نفرت، مخصوصا در platformهای آنلاین و فورموس، سریع به عنوان قوانین ضد نفرت سخنرانی شروع می‌کند که بر صحبت عمومی آنلاین کاربرد می‌شود. این کار را با این ذهن آفریده شده است. شرکتگران انتظار داشته بودند که یک مدل قادر به تصمیم گرفتن ورودی (در این مورد، مجموعه داده‌های توئیتر به انگلیسی و اسپانیایی) سخنرانی ناخوشایند (نامیده شده به عنوان وظیفه A) را توسعه کنند، و اگر توئیت یک فرد را هدف می‌دهد یا در کلی صحبت می‌کند (وظیفه B). ما با ایجاد یک مدل LSTM با یک لایه وارد کردن به این کار نزدیک شدیم. ما فهمیدیم که مدل ما در ورودی زبان انگلیسی با ورودی زبان اسپانیایی بسیار بهتر انجام داده است. در انگلیسی، ما یک نمونه F1-از 0.466 برای وظیفه A و 0.462 برای وظیفه B رسیدیم. در اسپانیایی، به طور مستقیما امتیاز 0.617 و 0.612 در کار A و کار B رسیدیم.</abstract_fa>
      <abstract_af>Die opdekking van haatspraak, veral in onlineplatforme en forume, word gou 'n warm onderwerp as anti-haatspraat wetgewing begin toepassing word op openbare diskursie online. Die HatEval gedeelde taak is geskep met hierdie in gedagte; Deelnaders was verwag om 'n model te ontwikkel wat moontlik is om te bepaal of nie invoer (in hierdie geval, Twitter datastelle in Engels en Spaanse) van haatspraak (as Opdrag A aangestel word), as hulle aggressief was, en of die tweet 'n individueel, of gewoonlik (Taak B) te doen. Ons het hierdie taak toegekom deur 'n LSTM model te skep met 'n inbêer laag. Ons het gevind dat ons model beter uitgevoer het op Engels taal ingevoer wanneer vergelyk word met Spaanse taal ingevoer. In Engels het ons 'n F1-Telling van 0.466 bereik vir Taak A en 0.462 vir Taak B; In Spaanse, ons het rekening 0.617 en 0.612 op Opdrag A en Opdrag B, respektief.</abstract_af>
      <abstract_tr>Hat çykyşyň sözlerini tanamak, ýöne-da internet platformlarynda we forumlarda, ýüzüniň ýigrenýän sözleriniň kanunlarynyň üstine ýakynlanmasyna başlaýar. Hateval bu zady aklynda bölýän zady bilen döredildi. Sahypalar üçin girişi tanamak üçin bir nusga çykarmak üçin gözlenýärdi (şu ýagdaýda, Twitter veri setirleri iñlis we español dilinde) ýigrenýän çykyşy diýip kabul edilýärdi (görev A diýip kabul edilýärdi), eger olar agresif bolsadylar we tweet bir adama maksady bolmady ýa-da umumy(B görev). Biz bu zady içeri girişi bilen LSTM nusgasyny bejererek goll etdik. Biziň nusgymyz iňlisçe dil girişinde espaňol dil girişinde has gowy gazandygyny görerdik. Iňlisçe, biz 0.466 Taýka A we 0.462 Taýka B üçin bir F1-Score ýetip bardyk; Ispanýolça 0.617 we 0.612 hasaplaryny bar.</abstract_tr>
      <abstract_sw>Kugundua hotuba ya chuki, hasa kwenye majukwaa na majukwaa ya mtandaoni, kwa haraka inakuwa mada yenye moto kwani sheria ya kupinga hotuba ya chuki inaanza kutumika katika mazungumzo ya umma mtandaoni. Kazi ya HatEval ilitengenezwa kwa akili hii; Washiriki walitarajiwa kutengeneza muundo wa uwezo wa kuamua ikiwa na maandishi (kwa mukhtadha huu, seti za taarifa za Twita kwa Kiingereza na Kihispania) zinaweza kuchukuliwa kuwa hotuba ya chuki (inayotengenezwa kama Task A), kama walikuwa na kibaguzi, na kama twiti hiyo ililenga mtu binafsi au kuongea kwa ujumla (Kazi B). Tumekaribia kazi hii kwa kutengeneza Mfano wa LSTM wenye kiwango cha ndani. Tumegundua kuwa muundo wetu ulifanya vizuri zaidi kwenye input wa lugha ya Kiingereza ukilinganisha na input wa lugha ya Kihispania. Kwa Kiingereza, tulipata kiwango cha F1 cha 0.466 kwa ajili ya kazi A na 0.462 kwa ajili ya kazi B; Kwa lugha ya Kihispania, tulipata vipimo vya 0.617 na 0.612 kwenye kazi A na kazi B.</abstract_sw>
      <abstract_sq>Zbulimi i fjalimit të urrejtjes, veçanërisht në platforma dhe forume online, po bëhet shpejt një temë e nxehtë ndërsa legjislacioni kundër fjalimit të urrejtjes fillon të aplikohet në diskursin publik online. Detyra e përbashkët e HatEval u krijua me këtë në mendje; pjesëmarrësit priteshin të zhvillonin një model të aftë për të përcaktuar nëse input (në këtë rast, të dhënat e Twitter në anglisht dhe spanjoll) mund të konsideroheshin fjalim urrejtjeje (të caktuar si Task A), në qoftë se a to ishin agresive dhe në qoftë se tweeti ishte drejtuar në një individ apo fliste përgjithësisht (Task B). Ne iu afruam kësaj detyre duke krijuar një model LSTM me një shtresë të përfshirë. Ne zbuluam se modeli ynë u bë më mirë në hyrjen e gjuhës angleze kur krahasohet me hyrjen e gjuhës spanjolle. Në anglisht, arritëm një F1-Score prej 0.466 për Task A dhe 0.462 për Task B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</abstract_sq>
      <abstract_am>የጥል ንግግር፣ በተለይም የበይነመረብ መድረክ እና ፎርማቶች ውስጥ፣ የጥል ንግግር ሕግ በመስመር የህዝብ ንግግር ለመጠቀም ሲጀምር ፈጥኖ ትኩሳት ጉዳይ ሆነዋል፡፡ የሐቴዌል ስራ በዚህ ምክንያት ተፈጠረ፤ ተጋሪዎቹ የኢንጂልኛ እና ስፓኒሽ ቋንቋ ውስጥ የTwitter ዳታተር ቋንቋ (ስክ A) የተጠቃሚ ንግግር (ማድረግ A) ቢሆኑ፣ ትዊተር አንድ ሰው ወይም በሙሉ የሚናገር ቢሆን (ስራ B) የጥል ንግግር መሆኑን ማረጋገጥ የሚችል ምሳሌ መፍጠር ተስፋ ያደርጋል፡፡ አዲስ ደረጃን በመፍጠር የLSTM ምሳሌ አቀረብን፡፡ ምሳሌያችን ከስፓኒሽ ቋንቋ ጥያቄ በተደረገ ጊዜ በንግግሊዘኛ ቋንቋ ውስጥ እጅግ የበለጠ እንደተደረገ አግኝተናል፡፡ በንግግሊዝኛ የስራ አ እና 0.462 ለስራ B F1-ነጥብ አግኝተናል፡፡ In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</abstract_am>
      <abstract_hy>ատելության խոսքի հայտնաբերումը, հատկապես առցանց պլատֆորմերում և ֆորմերում, արագ դառնում է տաք թեմա, քանի որ ատելության դեմ խոսքի օրենսդրությունը սկսում է կիրառվել առցանց հանրային խոսքի համար: Հաթեվալ ընդհանուր խնդիրը ստեղծվել է այս մտքում, մասնակիցները ակնկալում էին, որ կզարգացնեն մոդել, որը կկարողանա որոշել, թե արդյոք ներմուծը (այս դեպքում Թվիթերի տվյալների համակարգերը անգլերենում և իսպաներեն) կարելի է համարվել ատելության ելույթ (որը կոչվում է Ա-ի առաջադրանք), եթե նրանք ագրեսիվ են, և արդյոք Թվիթերը նպատակ Մենք մոտեցանք այս խնդիրը ստեղծելով LSMT մոդել ներգրավված շերտի հետ: Մենք հայտնաբերեցինք, որ մեր մոդելը շատ ավելի լավ էր աշխատում անգլերեն լեզվի ներմուծների վրա, համեմատած իսպաներեն լեզվի ներմուծների վրա: Անգլերենում մենք հասանք 0.466-ի F1-գնահատականի A-ի և 0.462-ի B-ի համար: Իսպաներեն մենք հասանք 0,617 և 0,612 գնահատականների A և B խնդիրներում:</abstract_hy>
      <abstract_bs>Otkrivanje govora mržnje, posebno na internetskim platformama i forumima, brzo postaje vruća tema jer se zakonodavstvo o govoru protiv mržnje počinje primjenjivati na javne diskursije na internetu. HatEval je podijeljen zadatak stvoren na umu s tim; Očekivalo se da će učesnici razviti model sposoban za utvrđivanje da li ulaz (u tom slučaju, Twitter podaci na engleskom i španjolskom) mogli biti smatrani govorom mržnje (izrađenim kao Task A), ako su agresivni, i da li je tweet ciljao pojedincu ili govoreći općenito (Task B). Prišli smo ovom zadatku stvarajući LSTM model sa ugrađenim slojem. Pronašli smo da je naš model izvršio mnogo bolje u odnosu na ulaz engleskog jezika u usporedbi sa ulazom španjolskog jezika. Na engleskom jeziku, postigli smo F1-Score od 0,466 za zadatak A i 0,462 za zadatak B; Na španjolskom smo postigli rezultate 0,617 i 0,612 na zadatku A i zadatku B.</abstract_bs>
      <abstract_ca>La detecció del discurs d'odi, especialment en plataformes i fòrums en línia, s'està convertint ràpidament en un tema calent, mentre la llei contra l'odi comença a aplicar-se al discurs públic en línia. La tasca compartida HatEval va ser creata amb això a la ment; s'esperava que els participants desenvolupin un model capaç de determinar si les entrades (en aquest cas, els conjunts de dades de Twitter en anglès i espanyol) podrien ser considerades discursos d'odi (designats com a tasca A), si eren agressives, i si la tweet mirava a un individu o parlava en general (tasca B). Vam abordar aquesta tasca creant un model LSTM amb una capa incorporadora. Vam descobrir que el nostre model va funcionar considerablement millor en l'entrada en anglès en comparació amb l'entrada en espanyol. En anglès, vam aconseguir una puntuació F1 de 0,466 per la tasca A i 0,462 per la tasca B; In Spanish, we achieved scores of 0.617 and 0.612 on Task A and Task B, respectively.</abstract_ca>
      <abstract_az>Nefrət sözlərinin, özlərinə də onlayn platformlarında və forumlarda, tezliklə nifrət sözlərinin qarşısındaki qanunların online sözlərinə uyğunlanmasına başladığı üçün isti bir məsəl olar. HatEval bu işi düşünüb yaratdı. İşkilərin daxil olmasını müəyyən edə biləcəyi bir modeli təmizləməsi gözlənilmişdi (bu halda, Twitter veri quruları İngilis və İspanyol dilində, İngilis və İspanyol dilində, İngilis dilində və İspanyol dilində) nifrət sözləri (A Task kimi təşkil edilmişdi), əgər təşkil edilmiş olsalar və ya tweet individu Biz bu işə yaxınlaşdıq, LSTM modeli inşa etmək üçün. Bizim modellərimiz İspanyol dili girişi ilə qarşılaşdığı zaman İngiliz dili girişində çox yaxşı işlədi. İngilizce dilində, B işi üçün A və 0.462 işi üçün F1-Score nəsib etdik. İspanyolca, işin A və Task B barəsində 0.617 və 0.612 nöqtələrini qəbul etdik.</abstract_az>
      <abstract_bn>বিশেষ করে অনলাইন প্লাটফর্ম এবং ফোরামে ঘৃণা ভাষণের আবিষ্কার হচ্ছে তারা দ্রুত একটি গরম বিষয়ে পরিণত হচ্ছে যেহেতু ঘৃণা বিরোধী বক্তৃতা বিরোধী  হাটিভাল শেয়ার কর্মসূচি এই মাথায় তৈরি করা হয়েছে; অংশগ্রহণকারীদের আশা করা হয়েছিল যে একটি মডেল তৈরি করতে পারে যা সিদ্ধান্ত নির্ধারণ করতে সক্ষম হবে কিনা (এই ক্ষেত্রে টুইটার ডাটাটাসেট ইংরেজী ও স্প্যানিশ ভাষায়) ঘৃণা ভাষণ বিবেচন আমরা এলস্টিএম মডেল তৈরি করে এই কাজের কাছে এসেছিলাম, যেখানে একটি বিভিন্ন স্তর তৈরি করেছিলাম। আমরা পেয়েছি যে স্প্যানিশ ভাষার ইনপুটের তুলনায় আমাদের মডেল অনেক ভালো করেছিল। ইংরেজি ভাষায় আমরা কাজ A এবং 0.462 টাকা বির জন্য একটি F1-স্কোর অর্জন করেছি; স্প্যানিশ ভাষায় আমরা কাজ A এবং কাজ বিরুদ্ধে ০. 617 এবং 0.612 স্কোর অর্জন করেছি।</abstract_bn>
      <abstract_cs>Odhalování nenávistných projevů, zejména na online platformách a fórech, se rychle stává žhavým tématem, protože legislativa proti nenávistným projevům se začíná aplikovat na veřejný diskurz online. Společný úkol HatEval byl vytvořen s tímto ohledem; Od účastníků se očekávalo, že vyvinou model schopný určit, zda lze vstup (v tomto případě datové sady Twitteru v angličtině a španělštině) považovat za nenávistnou řeč (označené jako úkol A), zda jsou agresivní a zda se tweet zaměřil na jednotlivce, nebo obecně mluví (Úkol B). K tomuto úkolu jsme přistupovali vytvořením LSTM modelu s vkládací vrstvou. Zjistili jsme, že náš model vedl výrazně lepší na vstupu anglického jazyka ve srovnání se španělským jazykem. V angličtině jsme dosáhli F1 skóre 0.466 pro úkol A a 0.462 pro úkol B; Ve španělštině jsme dosáhli bodů 0.617 a 0.612 u úkolu A a úkolu B.</abstract_cs>
      <abstract_fi>Vihanpuheen havaitsemisesta erityisesti verkkoalustoilla ja foorumeilla on nopeasti tulossa kuuma aihe, kun vihapuheen vastaista lainsäädäntöä aletaan soveltaa julkiseen keskusteluun verkossa. HatEvalin yhteinen tehtävä luotiin tätä silmällä pitäen; Osallistujien odotettiin kehittävän malli, jolla pystytään määrittämään, voidaanko syöttöä (tässä tapauksessa Twitterin englannin- ja espanjankieliset tietoaineistot) pitää vihapuheena (nimetty tehtäväksi A), ovatko he aggressiivisia ja kohdistuuko tweetti yksilöön vai puhuuko yleisesti (tehtävä B). Lähestyimme tätä tehtävää luomalla LSTM-mallin upotuskerroksella. Havaitsimme, että mallimme suoriutui huomattavasti paremmin englannin kielen syötteessä kuin espanjan kielen syötteessä. Englanniksi saavutimme F1-pisteet 0,466 tehtävässä A ja 0,462 tehtävässä B. Espanjaksi saavutimme pisteet 0,617 tehtävässä A ja 0,612 tehtävässä B.</abstract_fi>
      <abstract_et>Vihakõne avastamine, eriti veebiplatvormides ja foorumites, on kiiresti muutumas kuumaks teemaks, kuna vihakõne vastu võitlevaid õigusakte hakatakse kohaldama avaliku diskursuse suhtes internetis. Seda silmas pidades loodi HatEvali jagatud ülesanne; osalejatelt oodati, et nad töötaksid välja mudeli, mis võimaldaks kindlaks määrata, kas sisestust (antud juhul Twitteri andmekogumeid inglise ja hispaania keeles) võib pidada vihakõneks (nimetatud ülesandeks A), kas nad on agressiivsed ja kas säuts on suunatud üksikisikule või räägib üldiselt (ülesanne B). Me lähenesime sellele ülesandele, luues LSTM mudeli koos manustamiskihiga. Leidsime, et meie mudel oli inglise keele sisestuses oluliselt parem kui hispaania keele sisestus. Inglise keeles saavutasime F1-skoori 0,466 ülesande A ja 0,462 ülesande B puhul; Hispaania keeles saavutasime tulemused vastavalt 0,617 ja 0,612 ülesandes A ja B.</abstract_et>
      <abstract_jv>Alpha Heh, Debian nganggo perusahaan Debian kang dipun nggo kuwi iki; mengko kuwi sawalih Display brightness Awak dhéwé ngewehi nggo nggawe task iki di nggawe modèl LTT M nganggo alat sing basa batir. Awak dhéwé éntuk ono model sing paling nggambar luwih apik, yakuwis seneng nggambar tarjamahan karo ingkang spanyol. Nanging Inggris, kita wis gunakake F1-Point of 0.4x6 kanggo task A lan 0.4x2 kanggo task B; Anyone</abstract_jv>
      <abstract_sk>Odkrivanje sovražnega govora, zlasti na spletnih platformah in forumih, hitro postaja vroča tema, saj se začne uporabljati zakonodaja proti sovražnemu govoru na spletu. Skupna naloga HatEval je bila ustvarjena s tem v mislih; Od udeležencev se je pričakovalo, da bodo razvili model, ki bo lahko določil, ali se vnos (v tem primeru nabor podatkov Twitterja v angleščini in španščini) lahko šteje za sovražni govor (imenovan kot naloga A), ali so agresivni in ali je tvit namenjen posamezniku ali govori na splošno (naloga B). K tej nalogi smo pristopili z ustvarjanjem modela LSTM s plastjo vdelave. Ugotovili smo, da je naš model znatno boljši pri vnosu angleškega jezika v primerjavi z vnosom španskega jezika. V angleščini smo dosegli rezultat F1 0,466 za nalogo A in 0,462 za nalogo B; V španščini smo pri nalogi A dosegli oceno 0,617 oziroma 0,612 oziroma nalogi B.</abstract_sk>
      <abstract_ha>Ana gane magana na ƙi, da haske cikin majalan da jama'a masu haske, sai yana fara zama madaidaici mai hot, kamar yadda sharciyar ta fara a Apply wa magana na jamii a kusa. An halitta aikin Hateval da aka raba shi a kan wannan. Ana ƙayyade mushirikai ya motsar wani misali wanda yake iya iya ƙayyade shi, ko kuma ba a iya iya gane (a cikin wannan case, za'a iya ƙayyade mutane ta cikin Ingiriya da Kispanish) da magana na ƙyãma (aka ƙayyade su kamar Tashin A), idan sun kasance ana yi ƙyãma, kuma idan Twitter na yi amfani da wani mutum, ko kuwa ya yi magana a jumla (Taaikin B). Mun kusantar wannan aikin da Muka sami wani misali na LSSM da wani mai shiga Mun gane cewa misalinmu ya sami mai kyau a cikin cikin harshen Ingiriya idan da aka sammenliki da tsarin harshen Isspanish. @ item Spelling dictionary Ga Isbaniya, muka sami score 0,617 da 0,612 a kan aikin A da aikin B.</abstract_ha>
      <abstract_he>גילוי הנאום לשנאה, במיוחד בתחנות ופורומים באינטרנט, הופך במהירות לנושא חם כאשר חוקי הנאום נגד השנאה מתחילים להתייחס לדיוח ציבורי באינטרנט. המשימה המשותפת של האטאוול נוצרה עם זה בראש; השתתפים צפו לפתח מודל מסוגל לקבוע אם תוכנית (במקרה הזה, קבוצות מידע טוויטר באנגלית וספרדית) יכולות להיחשב נאום שנאה (נקבע בתור משימה A), אם הן היו אגרסיביות, ואם הטוויטר היתה מטרה לאדם או דיברה באופן כללי (משימה B). הגענו למשימה הזו על ידי יצירת דוגמנית LSTM עם שכבה מעורבת. מצאנו שהמודל שלנו הצליח הרבה יותר טוב בהכניסה של שפה אנגלית בהשוואה להכניסה של שפה ספרדית. באנגלית השגנו נקודת F1 של 0.466 למשימה A ו-0.462 למשימה B; בספרדית, השגנו נקודות של 0.617 ו-0.612 על משימה A וממשימה B, בהתאם.</abstract_he>
      <abstract_bo>དྲ་ཐོག་དང་གླེང་སྡོམ་དང་འཆར་བརྗོད་ཀྱི་གཏམ་བཤེར་གྱི་རྟོགས་བཤེར་ནི་འགྱུར་མཁན་དུ་ཆགས་པ་དང་། ཁོང་གིས་ཤེས་བྱ་རྣམས་གཅིག་མཐུན་གྱི་ལས་འགུལ་དེ་སེམས་སུ་འཇུག་བྱས་པ་ཡིན། ཞུགས་མི་མང་གིས་གསལ་བཤད་ན་མིན་པའི་མིག་ལམ་ཞིག་དཔག་འཛིན་བྱེད་རྒྱུ་དང་མིན་འདུག ང་ཚོས་ཀྱིས་མཐུད་སྒྲིག་བང་རིམ་ལ་LSTM་རྣམ་པ ང་ཚོས་རང་གི་མ་དབྱིབས་དབྱིབས་ཡིག་གི་སྐད་རིགས་ནང་བཙུགས་སྐབས་སུ་མཐུན་རྐྱེན་བྱས་པ་ཡིན། In English, we achieved an F1-Score of 0.466 for Task A and 0.462 for Task B; for Task B སྐད་ཡིག་གི་ནང་དུ་ང་ཚོ་རྒྱལ་ཁབ་འགྲོ་བ་ཡིན། འགྲོ་བ་དང་ལས་འགུལ་བཞིན་པའི་གྲངས་ཀ་འགྲོ་བ་ཡིན།</abstract_bo>
      </paper>
    <paper id="90">
      <title>Tw-StAR at SemEval-2019 Task 5 : N-gram embeddings for Hate Speech Detection in Multilingual Tweets<fixed-case>S</fixed-case>t<fixed-case>AR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: N-gram embeddings for Hate Speech Detection in Multilingual Tweets</title>
      <author><first>Hala</first><last>Mulki</last></author>
      <author><first>Chedi</first><last>Bechikh Ali</last></author>
      <author><first>Hatem</first><last>Haddad</last></author>
      <author><first>Ismail</first><last>Babaoğlu</last></author>
      <pages>503–507</pages>
      <abstract>In this paper, we describe our contribution in SemEval-2019 : subtask A of task 5 Multilingual detection of hate speech against immigrants and women in Twitter (HatEval). We developed two hate speech detection model variants through Tw-StAR framework. While the first model adopted one-hot encoding ngrams to train an NB classifier, the second generated and learned n-gram embeddings within a <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward neural network</a>. For both <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, specific terms, selected via MWT patterns, were tagged in the input data. With two feature types employed, we could investigate the ability of n-gram embeddings to rival one-hot n-grams. Our results showed that in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, n-gram embeddings outperformed one-hot ngrams. However, representing Spanish tweets by one-hot n-grams yielded a slightly better performance compared to that of n-gram embeddings. The official ranking indicated that Tw-StAR ranked 9th for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and 20th for <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>.</abstract>
      <url hash="92985795">S19-2090</url>
      <doi>10.18653/v1/S19-2090</doi>
      <bibkey>mulki-etal-2019-tw</bibkey>
    </paper>
    <paper id="91">
      <title>UA at SemEval-2019 Task 5 : Setting A Strong Linear Baseline for Hate Speech Detection<fixed-case>UA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Setting A Strong Linear Baseline for Hate Speech Detection</title>
      <author><first>Carlos</first><last>Perelló</last></author>
      <author><first>David</first><last>Tomás</last></author>
      <author><first>Alberto</first><last>Garcia-Garcia</last></author>
      <author><first>Jose</first><last>Garcia-Rodriguez</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <pages>508–513</pages>
      <abstract>This paper describes the system developed at the University of Alicante (UA) for the SemEval 2019 Task 5 : Shared Task on Multilingual Detection of Hate. The purpose of this work is to build a strong baseline for hate speech detection, using a traditional machine learning approach with standard <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">textual features</a>, which could serve in a near future as a reference to compare with <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning systems</a>. We participated in both task A (Hate Speech Detection against Immigrants and Women) and task B (Aggressive behavior and Target Classification). Despite its simplicity, our <a href="https://en.wikipedia.org/wiki/System">system</a> obtained a remarkable <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 72.5 (sixth highest) and an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 73.6 (second highest) in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> (task A), outperforming more complex neural models from a total of 40 participant systems.</abstract>
      <url hash="6564c845">S19-2091</url>
      <doi>10.18653/v1/S19-2091</doi>
      <bibkey>perello-etal-2019-ua</bibkey>
    </paper>
    <paper id="92">
      <title>UNBNLP at SemEval-2019 Task 5 and 6 : Using Language Models to Detect Hate Speech and Offensive Language<fixed-case>UNBNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5 and 6: Using Language Models to Detect Hate Speech and Offensive Language</title>
      <author><first>Ali</first><last>Hakimi Parizi</last></author>
      <author><first>Milton</first><last>King</last></author>
      <author><first>Paul</first><last>Cook</last></author>
      <pages>514–518</pages>
      <abstract>In this paper we apply a range of approaches to language modeling   including word-level n-gram and neural language models, and character-level neural language models   to the problem of detecting hate speech and offensive language. Our findings indicate that <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> are able to capture knowledge of whether text is hateful or offensive. However, our findings also indicate that more conventional <a href="https://en.wikipedia.org/wiki/Comparison_and_contrast_of_classification_schemes_in_linguistics_and_metadata">approaches</a> to text classification often perform similarly or better.</abstract>
      <url hash="313e3d79">S19-2092</url>
      <doi>10.18653/v1/S19-2092</doi>
      <bibkey>hakimi-parizi-etal-2019-unbnlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech-and-offensive-language">Hate Speech and Offensive Language</pwcdataset>
    </paper>
    <paper id="93">
      <title>UTFPR at SemEval-2019 Task 5 : Hate Speech Identification with Recurrent Neural Networks<fixed-case>UTFPR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Hate Speech Identification with Recurrent Neural Networks</title>
      <author><first>Gustavo Henrique</first><last>Paetzold</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <pages>519–523</pages>
      <abstract>In this paper we revisit the problem of automatically identifying hate speech in posts from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. We approach the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> using a <a href="https://en.wikipedia.org/wiki/System">system</a> based on minimalistic compositional Recurrent Neural Networks (RNN). We tested our approach on the SemEval-2019 Task 5 : Multilingual Detection of Hate Speech Against Immigrants and Women in Twitter (HatEval) shared task dataset. The dataset made available by the HatEval organizers contained English and Spanish posts retrieved from <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> annotated with respect to the presence of hateful content and its target. In this paper we present the results obtained by our <a href="https://en.wikipedia.org/wiki/System">system</a> in comparison to the other entries in the shared task. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved competitive performance ranking 7th in sub-task A out of 62 systems in the <a href="https://en.wikipedia.org/wiki/English_language">English track</a>.</abstract>
      <url hash="a5998468">S19-2093</url>
      <doi>10.18653/v1/S19-2093</doi>
      <bibkey>paetzold-etal-2019-utfpr</bibkey>
    </paper>
    <paper id="95">
      <title>YNU NLP at SemEval-2019 Task 5 : Attention and Capsule Ensemble for Identifying Hate Speech<fixed-case>YNU</fixed-case> <fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5: Attention and Capsule Ensemble for Identifying Hate Speech</title>
      <author><first>Bin</first><last>Wang</last></author>
      <author><first>Haiyan</first><last>Ding</last></author>
      <pages>529–534</pages>
      <abstract>This paper describes the system submitted to SemEval 2019 Task 5 : Multilingual detection of hate speech against immigrants and women in Twitter (hatEval). Its main purpose is to conduct hate speech detection on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, which mainly includes two specific different targets, immigrants and women. We participate in both subtask A and subtask B for <a href="https://en.wikipedia.org/wiki/English_language">English</a>. In order to address this task, we develope an ensemble of an attention-LSTM model based on HAN and an BiGRU-capsule model. Both <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> use fastText pre-trained embeddings, and we use this model in both subtasks. In comparison to other participating teams, our system is ranked 16th in the Sub-task A for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, and 12th in the Sub-task B for <a href="https://en.wikipedia.org/wiki/English_language">English</a>.</abstract>
      <url hash="182cb66b">S19-2095</url>
      <doi>10.18653/v1/S19-2095</doi>
      <bibkey>wang-ding-2019-ynu</bibkey>
    </paper>
    <paper id="99">
      <title>BNU-HKBU UIC NLP Team 2 at SemEval-2019 Task 6 : Detecting Offensive Language Using BERT model<fixed-case>BNU</fixed-case>-<fixed-case>HKBU</fixed-case> <fixed-case>UIC</fixed-case> <fixed-case>NLP</fixed-case> Team 2 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Detecting Offensive Language Using <fixed-case>BERT</fixed-case> model</title>
      <author><first>Zhenghao</first><last>Wu</last></author>
      <author><first>Hao</first><last>Zheng</last></author>
      <author><first>Jianming</first><last>Wang</last></author>
      <author><first>Weifeng</first><last>Su</last></author>
      <author><first>Jefferson</first><last>Fong</last></author>
      <pages>551–555</pages>
      <abstract>In this study we deal with the problem of identifying and categorizing offensive language in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. Our group, BNU-HKBU UIC NLP Team2, use <a href="https://en.wikipedia.org/wiki/Supervised_classification">supervised classification</a> along with multiple version of data generated by different ways of pre-processing the data. We then use the state-of-the-art model Bidirectional Encoder Representations from Transformers, or BERT (Devlin et al, 2018), to capture linguistic, syntactic and semantic features. Long range dependencies between each part of a sentence can be captured by BERT’s bidirectional encoder representations. Our results show 85.12 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and 80.57 % F1 scores in Subtask A (offensive language identification), 87.92 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and 50 % F1 scores in Subtask B (categorization of offense types), and 69.95 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and 50.47 % F1 score in Subtask C (offense target identification). Analysis of the results shows that distinguishing between targeted and untargeted offensive language is not a simple task. More work needs to be done on the unbalance data problem in Subtasks B and C. Some future work is also discussed.</abstract>
      <url hash="92467cc0">S19-2099</url>
      <doi>10.18653/v1/S19-2099</doi>
      <bibkey>wu-etal-2019-bnu</bibkey>
    </paper>
    <paper id="102">
      <title>ConvAI at SemEval-2019 Task 6 : Offensive Language Identification and Categorization with Perspective and BERT<fixed-case>C</fixed-case>onv<fixed-case>AI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Offensive Language Identification and Categorization with Perspective and <fixed-case>BERT</fixed-case></title>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Nithum</first><last>Thain</last></author>
      <author><first>Lucas</first><last>Dixon</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>571–576</pages>
      <abstract>This paper presents the application of two strong baseline systems for toxicity detection and evaluates their performance in identifying and categorizing offensive language in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. PERSPECTIVE is an <a href="https://en.wikipedia.org/wiki/Application_programming_interface">API</a>, that serves multiple <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> for the improvement of conversations online, as well as a toxicity detection system, trained on a wide variety of comments from platforms across the Internet. BERT is a recently popular language representation model, fine tuned per task and achieving state of the art performance in multiple NLP tasks. PERSPECTIVE performed better than BERT in detecting <a href="https://en.wikipedia.org/wiki/Toxicity">toxicity</a>, but BERT was much better in categorizing the offensive type. Both baselines were ranked surprisingly high in the SEMEVAL-2019 OFFENSEVAL competition, PERSPECTIVE in detecting an offensive post (12th) and BERT in categorizing it (11th). The main contribution of this paper is the assessment of two strong baselines for the identification (PERSPECTIVE) and the categorization (BERT) of offensive language with little or no additional training data.</abstract>
      <url hash="7b91d480">S19-2102</url>
      <doi>10.18653/v1/S19-2102</doi>
      <bibkey>pavlopoulos-etal-2019-convai</bibkey>
    </paper>
    <paper id="104">
      <title>DeepAnalyzer at SemEval-2019 Task 6 : A deep learning-based ensemble method for identifying offensive tweets<fixed-case>D</fixed-case>eep<fixed-case>A</fixed-case>nalyzer at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: A deep learning-based ensemble method for identifying offensive tweets</title>
      <author><first>Gretel Liz</first><last>De la Peña</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>582–586</pages>
      <abstract>This paper describes the system we developed for SemEval 2019 on Identifying and Categorizing Offensive Language in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> (OffensEval-Task 6). The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> focuses on offensive language in tweets. It is organized into three sub-tasks for offensive language identification ; automatic categorization of offense types and offense target identification. The approach for the first subtask is a deep learning-based ensemble method which uses a Bidirectional LSTM Recurrent Neural Network and a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a>. Additionally we use the information from <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a> of tweets for target identification and combine previous results for categorization of offense types.</abstract>
      <url hash="52e79ec1">S19-2104</url>
      <doi>10.18653/v1/S19-2104</doi>
      <bibkey>de-la-pena-rosso-2019-deepanalyzer</bibkey>
    </paper>
    <paper id="106">
      <title>Duluth at SemEval-2019 Task 6 : Lexical Approaches to Identify and Categorize Offensive Tweets<fixed-case>D</fixed-case>uluth at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Lexical Approaches to Identify and Categorize Offensive Tweets</title>
      <author><first>Ted</first><last>Pedersen</last></author>
      <pages>593–599</pages>
      <abstract>This paper describes the Duluth systems that participated in SemEval2019 Task 6, Identifying and Categorizing Offensive Language in Social Media (OffensEval). For the most part these systems took traditional Machine Learning approaches that built <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> from <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">lexical features</a> found in manually labeled training data. However, our most successful system for classifying a tweet as offensive (or not) was a rule-based blacklist approach, and we also experimented with combining the training data from two different but related SemEval tasks. Our best systems in each of the three OffensEval tasks placed in the middle of the comparative evaluation, ranking 57th of 103 in task A, 39th of 75 in task B, and 44th of 65 in task C.</abstract>
      <url hash="a8819816">S19-2106</url>
      <doi>10.18653/v1/S19-2106</doi>
      <bibkey>pedersen-2019-duluth</bibkey>
    </paper>
    <paper id="110">
      <title>Ghmerti at SemEval-2019 Task 6 : A Deep Word- and Character-based Approach to Offensive Language Identification<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: A Deep Word- and Character-based Approach to Offensive Language Identification</title>
      <author><first>Ehsan</first><last>Doostmohammadi</last></author>
      <author><first>Hossein</first><last>Sameti</last></author>
      <author><first>Ali</first><last>Saffar</last></author>
      <pages>617–621</pages>
      <abstract>This paper presents the models submitted by Ghmerti team for subtasks A and B of the OffensEval shared task at SemEval 2019. OffensEval addresses the problem of identifying and categorizing offensive language in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> in three subtasks ; whether or not a content is offensive (subtask A), whether it is targeted (subtask B) towards an individual, a group, or other entities (subtask C). The proposed approach includes character-level Convolutional Neural Network, word-level Recurrent Neural Network, and some preprocessing. The performance achieved by the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is 77.93 % macro-averaged F1-score.</abstract>
      <url hash="d0d70f2e">S19-2110</url>
      <doi>10.18653/v1/S19-2110</doi>
      <bibkey>doostmohammadi-etal-2019-ghmerti</bibkey>
      <pwccode url="https://github.com/edoost/offenseval" additional="false">edoost/offenseval</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="111">
      <title>HAD-Tbingen at SemEval-2019 Task 6 : Deep Learning Analysis of Offensive Language on Twitter : Identification and Categorization<fixed-case>HAD</fixed-case>-<fixed-case>T</fixed-case>übingen at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Deep Learning Analysis of Offensive Language on <fixed-case>T</fixed-case>witter: Identification and Categorization</title>
      <author><first>Himanshu</first><last>Bansal</last></author>
      <author><first>Daniel</first><last>Nagel</last></author>
      <author><first>Anita</first><last>Soloveva</last></author>
      <pages>622–627</pages>
      <abstract>This paper describes the submissions of our team, HAD-Tbingen, for the SemEval 2019-Task 6 : OffensEval : Identifying and Categorizing Offensive Language in Social Media. We participated in all the three sub-tasks : Sub-task A-Offensive language identification</abstract>
      <url hash="4464b2a5">S19-2111</url>
      <doi>10.18653/v1/S19-2111</doi>
      <bibkey>bansal-etal-2019-tubingen</bibkey>
    </paper>
    <paper id="112">
      <title>HHU at SemEval-2019 Task 6 : Context Does Matter-Tackling Offensive Language Identification and Categorization with ELMo<fixed-case>HHU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Context Does Matter - Tackling Offensive Language Identification and Categorization with <fixed-case>ELM</fixed-case>o</title>
      <author><first>Alexander</first><last>Oberstrass</last></author>
      <author><first>Julia</first><last>Romberg</last></author>
      <author><first>Anke</first><last>Stoll</last></author>
      <author><first>Stefan</first><last>Conrad</last></author>
      <pages>628–634</pages>
      <abstract>We present our results for OffensEval : Identifying and Categorizing <a href="https://en.wikipedia.org/wiki/Offensive_language">Offensive Language</a> in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> (SemEval 2019-Task 6). Our results show that context embeddings are important features for the three different sub-tasks in connection with classical machine and with <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> reached place 3 of 75 in sub-task B with a macro F_1 of 0.719. Our approaches for <a href="https://en.wikipedia.org/wiki/Task_(computing)">sub-task</a> A and C perform less well but could also deliver promising results.<tex-math>F_1</tex-math> of 0.719. Our approaches for sub-task A and C perform less well but could also deliver promising results.</abstract>
      <url hash="1e357b3c">S19-2112</url>
      <doi>10.18653/v1/S19-2112</doi>
      <bibkey>oberstrass-etal-2019-hhu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech-and-offensive-language">Hate Speech and Offensive Language</pwcdataset>
    </paper>
    <paper id="114">
      <title>INGEOTEC at SemEval-2019 Task 5 and Task 6 : A Genetic Programming Approach for Text Classification<fixed-case>INGEOTEC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 5 and Task 6: A Genetic Programming Approach for Text Classification</title>
      <author><first>Mario</first><last>Graff</last></author>
      <author><first>Sabino</first><last>Miranda-Jiménez</last></author>
      <author><first>Eric</first><last>Tellez</last></author>
      <author><first>Daniela Alejandra</first><last>Ochoa</last></author>
      <pages>639–644</pages>
      <abstract>This paper describes our participation in HatEval and OffensEval challenges for English and Spanish languages. We used several approaches, B4MSA, <a href="https://en.wikipedia.org/wiki/FastText">FastText</a>, and EvoMSA. Best results were achieved with EvoMSA, which is a multilingual and domain-independent architecture that combines the prediction of different knowledge sources to solve text classification problems.</abstract>
      <url hash="c14e019c">S19-2114</url>
      <doi>10.18653/v1/S19-2114</doi>
      <bibkey>graff-etal-2019-ingeotec</bibkey>
    </paper>
    <paper id="117">
      <title>JTML at SemEval-2019 Task 6 : Offensive Tweets Identification using <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a><fixed-case>JTML</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Offensive Tweets Identification using Convolutional Neural Networks</title>
      <author><first>Johnny</first><last>Torres</last></author>
      <author><first>Carmen</first><last>Vaca</last></author>
      <pages>657–661</pages>
      <abstract>In this paper, we propose the use of a Convolutional Neural Network (CNN) to identify offensive tweets, as well as the type and target of the offense. We use an <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end model</a> (i.e., no preprocessing) and fine-tune pre-trained embeddings (FastText) during training for learning words’ representation. We compare the proposed CNN model to a baseline model, such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a>, and several neural models. The results show that CNN outperforms other <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, and stands as a simple but strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> in comparison to other <a href="https://en.wikipedia.org/wiki/System">systems</a> submitted to the Shared Task.</abstract>
      <url hash="25d2016f">S19-2117</url>
      <doi>10.18653/v1/S19-2117</doi>
      <bibkey>torres-vaca-2019-jtml</bibkey>
    </paper>
    <paper id="120">
      <title>LaSTUS / TALN at SemEval-2019 Task 6 : Identification and Categorization of Offensive Language in Social Media with Attention-based Bi-LSTM model<fixed-case>L</fixed-case>a<fixed-case>STUS</fixed-case>/<fixed-case>TALN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Identification and Categorization of Offensive Language in Social Media with Attention-based <fixed-case>B</fixed-case>i-<fixed-case>LSTM</fixed-case> model</title>
      <author><first>Lutfiye Seda</first><last>Mut Altin</last></author>
      <author><first>Àlex</first><last>Bravo Serrano</last></author>
      <author><first>Horacio</first><last>Saggion</last></author>
      <pages>672–677</pages>
      <abstract>We present a bidirectional Long-Short Term Memory network for identifying <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. Our system has been developed in the context of the SemEval 2019 Task 6 which comprises three different sub-tasks, namely A : Offensive Language Detection, B : Categorization of Offensive Language, C : Offensive Language Target Identification. We used a pre-trained Word Embeddings in tweet data, including information about <a href="https://en.wikipedia.org/wiki/Emoji">emojis</a> and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a>. Our <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a> achieves good performance in the three <a href="https://en.wikipedia.org/wiki/Task_(project_management)">sub-tasks</a>.</abstract>
      <url hash="54124408">S19-2120</url>
      <doi>10.18653/v1/S19-2120</doi>
      <bibkey>mut-altin-etal-2019-lastus</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech-and-offensive-language">Hate Speech and Offensive Language</pwcdataset>
    </paper>
    <paper id="121">
      <title>LTL-UDE at SemEval-2019 Task 6 : BERT and Two-Vote Classification for Categorizing Offensiveness<fixed-case>LTL</fixed-case>-<fixed-case>UDE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: <fixed-case>BERT</fixed-case> and Two-Vote Classification for Categorizing Offensiveness</title>
      <author><first>Piush</first><last>Aggarwal</last></author>
      <author><first>Tobias</first><last>Horsmann</last></author>
      <author><first>Michael</first><last>Wojatzki</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <pages>678–682</pages>
      <abstract>We present results for Subtask A and C of SemEval 2019 Shared Task 6. In Subtask A, we experiment with an embedding representation of postings and use BERT to categorize postings. Our best result reaches the 10th place (out of 103). In Subtask C, we applied a two-vote classification approach with minority fallback, which is placed on the 19th rank (out of 65).</abstract>
      <url hash="f92564e7">S19-2121</url>
      <doi>10.18653/v1/S19-2121</doi>
      <bibkey>aggarwal-etal-2019-ltl</bibkey>
    </paper>
    <paper id="122">
      <title>MIDAS at SemEval-2019 Task 6 : Identifying Offensive Posts and Targeted Offense from Twitter<fixed-case>MIDAS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Identifying Offensive Posts and Targeted Offense from <fixed-case>T</fixed-case>witter</title>
      <author><first>Debanjan</first><last>Mahata</last></author>
      <author><first>Haimin</first><last>Zhang</last></author>
      <author><first>Karan</first><last>Uppal</last></author>
      <author><first>Yaman</first><last>Kumar</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <author><first>Simra</first><last>Shahid</last></author>
      <author><first>Laiba</first><last>Mehnaz</last></author>
      <author><first>Sarthak</first><last>Anand</last></author>
      <pages>683–690</pages>
      <abstract>In this paper we present our approach and the system description for Sub Task A and Sub Task B of SemEval 2019 Task 6 : Identifying and Categorizing Offensive Language in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a>. Sub Task A involves identifying if a given tweet is offensive and Sub Task B involves detecting if an offensive tweet is targeted towards someone (group or an individual). Our models for Sub Task A is based on an ensemble of <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a> and Bidirectional LSTM, whereas for Sub Task B, we rely on a set of <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> derived from the training data. We provide detailed analysis of the results obtained using the trained <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>. Our team ranked 5th out of 103 participants in Sub Task A, achieving a <a href="https://en.wikipedia.org/wiki/Macro_(computer_science)">macro F1 score</a> of 0.807, and ranked 8th out of 75 participants achieving a <a href="https://en.wikipedia.org/wiki/Macro_(computer_science)">macro F1</a> of 0.695.</abstract>
      <url hash="542419fa">S19-2122</url>
      <doi>10.18653/v1/S19-2122</doi>
      <bibkey>mahata-etal-2019-midas</bibkey>
    </paper>
    <paper id="123">
      <title>Nikolov-Radivchev at SemEval-2019 Task 6 : Offensive Tweet Classification with BERT and Ensembles<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Offensive Tweet Classification with <fixed-case>BERT</fixed-case> and Ensembles</title>
      <author><first>Alex</first><last>Nikolov</last></author>
      <author><first>Victor</first><last>Radivchev</last></author>
      <pages>691–695</pages>
      <abstract>This paper examines different approaches and <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> towards offensive tweet classification which were used as a part of the OffensEval 2019 competition. It reviews Tweet preprocessing, techniques for overcoming unbalanced class distribution in the provided test data, and comparison of multiple attempted <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a>.</abstract>
      <url hash="5a46fd99">S19-2123</url>
      <doi>10.18653/v1/S19-2123</doi>
      <bibkey>nikolov-radivchev-2019-nikolov</bibkey>
    </paper>
    <paper id="124">
      <title>NIT_Agartala_NLP_Team at SemEval-2019 Task 6 : An Ensemble Approach to Identifying and Categorizing Offensive Language in Twitter Social Media Corpora<fixed-case>NIT</fixed-case>_<fixed-case>A</fixed-case>gartala_<fixed-case>NLP</fixed-case>_<fixed-case>T</fixed-case>eam at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: An Ensemble Approach to Identifying and Categorizing Offensive Language in <fixed-case>T</fixed-case>witter Social Media Corpora</title>
      <author><first>Steve Durairaj</first><last>Swamy</last></author>
      <author><first>Anupam</first><last>Jamatia</last></author>
      <author><first>Björn</first><last>Gambäck</last></author>
      <author><first>Amitava</first><last>Das</last></author>
      <pages>696–703</pages>
      <abstract>The paper describes the systems submitted to OffensEval (SemEval 2019, Task 6) on ‘Identifying and Categorizing Offensive Language in Social Media’ by the ‘NIT_Agartala_NLP_Team’. A Twitter annotated dataset of 13,240 English tweets was provided by the task organizers to train the individual <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, with the best results obtained using an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble model</a> composed of six different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>. The <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble model</a> produced macro-averaged F1-scores of 0.7434, 0.7078 and 0.4853 on Subtasks A, B, and C, respectively. The paper highlights the overall low predictive nature of various <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> and surface level count features, as well as the limitations of a traditional machine learning approach when compared to a Deep Learning counterpart.</abstract>
      <url hash="f5a81cb9">S19-2124</url>
      <doi>10.18653/v1/S19-2124</doi>
      <bibkey>swamy-etal-2019-nit</bibkey>
    </paper>
    <paper id="125">
      <title>NLP@UIOWA at SemEval-2019 Task 6 : Classifying the Crass using Multi-windowed CNNs<fixed-case>NLP</fixed-case>@<fixed-case>UIOWA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Classifying the Crass using Multi-windowed <fixed-case>CNN</fixed-case>s</title>
      <author><first>Jonathan</first><last>Rusert</last></author>
      <author><first>Padmini</first><last>Srinivasan</last></author>
      <pages>704–711</pages>
      <abstract>This paper proposes a <a href="https://en.wikipedia.org/wiki/System">system</a> for OffensEval (SemEval 2019 Task 6), which calls for a <a href="https://en.wikipedia.org/wiki/System">system</a> to classify <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> into several categories. Our system is a text based CNN, which learns only from the provided training data. Our system achieves 80-90 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for the binary classification problems (offensive vs not offensive and targeted vs untargeted) and 63 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for trinary classification (group vs individual vs other).</abstract>
      <url hash="04380059">S19-2125</url>
      <doi>10.18653/v1/S19-2125</doi>
      <bibkey>rusert-srinivasan-2019-nlp</bibkey>
    </paper>
    <paper id="127">
      <title>nlpUP at SemEval-2019 Task 6 : A Deep Neural Language Model for Offensive Language Detection<fixed-case>UP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: A Deep Neural Language Model for Offensive Language Detection</title>
      <author><first>Jelena</first><last>Mitrović</last></author>
      <author><first>Bastian</first><last>Birkeneder</last></author>
      <author><first>Michael</first><last>Granitzer</last></author>
      <pages>722–726</pages>
      <abstract>This paper presents our submission for the SemEval shared task 6, sub-task A on the identification of offensive language. Our proposed model, C-BiGRU, combines a Convolutional Neural Network (CNN) with a bidirectional Recurrent Neural Network (RNN). We utilize <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> to capture the semantic similarities between words. This composition allows us to extract long term dependencies in tweets and distinguish between offensive and non-offensive tweets. In addition, we evaluate our approach on a different dataset and show that our model is capable of detecting online aggressiveness in both English and German tweets. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved a macro F1-score of 79.40 % on the <a href="https://en.wikipedia.org/wiki/SemEval">SemEval dataset</a>.</abstract>
      <url hash="7b778ccd">S19-2127</url>
      <doi>10.18653/v1/S19-2127</doi>
      <bibkey>mitrovic-etal-2019-nlpup</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="132">
      <title>TECHSSN at SemEval-2019 Task 6 : Identifying and Categorizing Offensive Language in Tweets using Deep Neural Networks<fixed-case>TECHSSN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Identifying and Categorizing Offensive Language in Tweets using Deep Neural Networks</title>
      <author><first>Angel</first><last>Suseelan</last></author>
      <author><first>Rajalakshmi</first><last>S</last></author>
      <author><first>Logesh</first><last>B</last></author>
      <author><first>Harshini</first><last>S</last></author>
      <author><first>Geetika</first><last>B</last></author>
      <author><first>Dyaneswaran</first><last>S</last></author>
      <author><first>S Milton</first><last>Rajendram</last></author>
      <author><first>Mirnalinee</first><last>T T</last></author>
      <pages>753–758</pages>
      <abstract>Task 6 of SemEval 2019 involves identifying and categorizing <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. The <a href="https://en.wikipedia.org/wiki/System">systems</a> developed by TECHSSN team uses multi-level classification techniques. We have developed two <a href="https://en.wikipedia.org/wiki/System">systems</a>. In the first system, the first level of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> is done by a multi-branch 2D CNN classifier with Google’s pre-trained Word2Vec embedding and the second level of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> by string matching technique supported by offensive and bad words dictionary. The second system uses a multi-branch 1D CNN classifier with Glove pre-trained embedding layer for the first level of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and string matching for the second level of classification. Input data with a probability of less than 0.70 in the first level are passed on to the second level. The misclassified examples are classified correctly in the second level.</abstract>
      <url hash="52900fbd">S19-2132</url>
      <doi>10.18653/v1/S19-2132</doi>
      <bibkey>suseelan-etal-2019-techssn</bibkey>
    </paper>
    <paper id="133">
      <title>The Titans at SemEval-2019 Task 6 : Offensive Language Identification, <a href="https://en.wikipedia.org/wiki/Categorization">Categorization</a> and Target Identification<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Offensive Language Identification, Categorization and Target Identification</title>
      <author><first>Avishek</first><last>Garain</last></author>
      <author><first>Arpan</first><last>Basu</last></author>
      <pages>759–762</pages>
      <abstract>This system paper is a description of the <a href="https://en.wikipedia.org/wiki/System">system</a> submitted to SemEval-2019 Task 6, where we had to detect offensive language in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. There were two specific target audiences, immigrants and women. The language of the tweets was English. We were required to first detect whether a tweet contains offensive content, and then we had to find out whether the tweet was targeted against some individual, group or other entity. Finally we were required to classify the targeted audience.</abstract>
      <url hash="5e5b23da">S19-2133</url>
      <doi>10.18653/v1/S19-2133</doi>
      <bibkey>garain-basu-2019-titans-semeval</bibkey>
    </paper>
    <paper id="134">
      <title>TKaSt at SemEval-2019 Task 6 : Something Old, Something Neu(ral): Traditional and Neural Approaches to Offensive Text Classification<fixed-case>T</fixed-case>ü<fixed-case>K</fixed-case>a<fixed-case>S</fixed-case>t at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Something Old, Something Neu(ral): Traditional and Neural Approaches to Offensive Text Classification</title>
      <author><first>Madeeswaran</first><last>Kannan</last></author>
      <author><first>Lukas</first><last>Stein</last></author>
      <pages>763–769</pages>
      <abstract>We describe our <a href="https://en.wikipedia.org/wiki/System">system</a> (TKaSt) submitted for Task 6 : Offensive Language Classification, at SemEval 2019. We developed multiple SVM classifier models that used sentence-level dense vector representations of tweets enriched with <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment information</a> and term-weighting. Our best results achieved F1 scores of 0.734, 0.660 and 0.465 in the first, second and third sub-tasks respectively. We also describe a neural network model that was developed in parallel but not used during evaluation due to time constraints.</abstract>
      <url hash="248be486">S19-2134</url>
      <doi>10.18653/v1/S19-2134</doi>
      <bibkey>kannan-stein-2019-tukast</bibkey>
    </paper>
    <paper id="135">
      <title>TUVD team at SemEval-2019 Task 6 : Offense Target Identification<fixed-case>TUVD</fixed-case> team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Offense Target Identification</title>
      <author><first>Elena</first><last>Shushkevich</last></author>
      <author><first>John</first><last>Cardiff</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <pages>770–774</pages>
      <abstract>This article presents our approach for detecting a target of offensive messages in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, including Individual, Group and Others classes. The model we have created is an ensemble of simpler models, including <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a>, <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a>, Support Vector Machine and the <a href="https://en.wikipedia.org/wiki/Interpolation">interpolation</a> between <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> and <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes</a> with 0.25 coefficient of interpolation. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> allows us to achieve 0.547 macro F1-score.</abstract>
      <url hash="bd19f2e5">S19-2135</url>
      <doi>10.18653/v1/S19-2135</doi>
      <bibkey>shushkevich-etal-2019-tuvd</bibkey>
    </paper>
    <paper id="136">
      <title>UBC-NLP at SemEval-2019 Task 6 : Ensemble Learning of Offensive Content With Enhanced Training Data<fixed-case>UBC</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Ensemble Learning of Offensive Content With Enhanced Training Data</title>
      <author><first>Arun</first><last>Rajendran</last></author>
      <author><first>Chiyu</first><last>Zhang</last></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <pages>775–781</pages>
      <abstract>We examine learning offensive content on <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> with limited, imbalanced data. For the purpose, we investigate the utility of using various data enhancement methods with a host of classical <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble classifiers</a>. Among the 75 participating teams in SemEval-2019 sub-task B, our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 6th (with 0.706 macro F1-score). For sub-task C, among the 65 participating teams, our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 9th (with 0.587 macro F1-score).</abstract>
      <url hash="608e3264">S19-2136</url>
      <doi>10.18653/v1/S19-2136</doi>
      <bibkey>rajendran-etal-2019-ubc</bibkey>
    </paper>
    <paper id="137">
      <title>UHH-LT at SemEval-2019 Task 6 : Supervised vs. Unsupervised Transfer Learning for Offensive Language Detection<fixed-case>UHH</fixed-case>-<fixed-case>LT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Supervised vs. Unsupervised Transfer Learning for Offensive Language Detection</title>
      <author><first>Gregor</first><last>Wiedemann</last></author>
      <author><first>Eugen</first><last>Ruppert</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>782–787</pages>
      <abstract>We present a neural network based approach of <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> for offensive language detection. For our <a href="https://en.wikipedia.org/wiki/System">system</a>, we compare two types of <a href="https://en.wikipedia.org/wiki/Knowledge_transfer">knowledge transfer</a> : supervised and unsupervised pre-training. Supervised pre-training of our bidirectional GRU-3-CNN architecture is performed as multi-task learning of parallel training of five different tasks. The selected tasks are supervised classification problems from public NLP resources with some overlap to offensive language such as sentiment detection, emoji classification, and aggressive language classification. Unsupervised transfer learning is performed with a thematic clustering of 40 M unlabeled tweets via <a href="https://en.wikipedia.org/wiki/Linear_predictive_coding">LDA</a>. Based on this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, pre-training is performed by predicting the main topic of a tweet. Results indicate that unsupervised transfer from large datasets performs slightly better than <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised training</a> on small ‘near target category’ datasets. In the SemEval Task, our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 14 out of 103 participants.</abstract>
      <url hash="b137e040">S19-2137</url>
      <doi>10.18653/v1/S19-2137</doi>
      <bibkey>wiedemann-etal-2019-uhh</bibkey>
    </paper>
    <paper id="138">
      <title>UM-IU@LING at SemEval-2019 Task 6 : Identifying Offensive Tweets Using BERT and SVMs<fixed-case>UM</fixed-case>-<fixed-case>IU</fixed-case>@<fixed-case>LING</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: Identifying Offensive Tweets Using <fixed-case>BERT</fixed-case> and <fixed-case>SVM</fixed-case>s</title>
      <author><first>Jian</first><last>Zhu</last></author>
      <author><first>Zuoyu</first><last>Tian</last></author>
      <author><first>Sandra</first><last>Kübler</last></author>
      <pages>788–795</pages>
      <abstract>This paper describes the UM-IU@LING’s system for the SemEval 2019 Task 6 : Offens-Eval. We take a mixed approach to identify and categorize <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. In subtask A, we fine-tuned a BERT based classifier to detect abusive content in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>, achieving a macro F1 score of 0.8136 on the test data, thus reaching the 3rd rank out of 103 submissions. In subtasks B and C, we used a linear SVM with selected character n-gram features. For subtask C, our system could identify the target of abuse with a macro F1 score of 0.5243, ranking it 27th out of 65 submissions.</abstract>
      <url hash="361e7717">S19-2138</url>
      <doi>10.18653/v1/S19-2138</doi>
      <bibkey>zhu-etal-2019-um</bibkey>
      <pwccode url="https://github.com/zytian9/SemEval-2019-Task-6" additional="false">zytian9/SemEval-2019-Task-6</pwccode>
    </paper>
    <paper id="143">
      <title>YNUWB at SemEval-2019 Task 6 : K-max pooling CNN with average meta-embedding for identifying offensive language<fixed-case>YNUWB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 6: K-max pooling <fixed-case>CNN</fixed-case> with average meta-embedding for identifying offensive language</title>
      <author><first>Bin</first><last>Wang</last></author>
      <author><first>Xiaobing</first><last>Zhou</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>818–822</pages>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> submitted to SemEval 2019 Task 6 : OffensEval 2019. The task aims to identify and categorize <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a> in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, we only participate in Sub-task A, which aims to identify <a href="https://en.wikipedia.org/wiki/Profanity">offensive language</a>. In order to address this task, we propose a system based on a K-max pooling convolutional neural network model, and use an argument for averaging as a valid meta-embedding technique to get a metaembedding. Finally, we also use a cyclic learning rate policy to improve <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a Macro F1-score of 0.802 (ranked 9/103) in the Sub-task A.</abstract>
      <url hash="a4a5db4a">S19-2143</url>
      <doi>10.18653/v1/S19-2143</doi>
      <bibkey>wang-etal-2019-ynuwb</bibkey>
    </paper>
    <paper id="147">
      <title>SemEval-2019 Task 7 : RumourEval, Determining Rumour Veracity and Support for Rumours<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: <fixed-case>R</fixed-case>umour<fixed-case>E</fixed-case>val, Determining Rumour Veracity and Support for Rumours</title>
      <author><first>Genevieve</first><last>Gorrell</last></author>
      <author><first>Elena</first><last>Kochkina</last></author>
      <author><first>Maria</first><last>Liakata</last></author>
      <author><first>Ahmet</first><last>Aker</last></author>
      <author><first>Arkaitz</first><last>Zubiaga</last></author>
      <author><first>Kalina</first><last>Bontcheva</last></author>
      <author><first>Leon</first><last>Derczynski</last></author>
      <pages>845–854</pages>
      <abstract>Since the first RumourEval shared task in 2017, interest in automated claim validation has greatly increased, as the danger of fake news has become a mainstream concern. However automated support for rumour verification remains in its infancy. It is therefore important that a shared task in this area continues to provide a focus for effort, which is likely to increase. Rumour verification is characterised by the need to consider evolving conversations and news updates to reach a verdict on a rumour’s veracity. As in RumourEval 2017 we provided a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of dubious posts and ensuing conversations in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, annotated both for stance and veracity. The social media rumours stem from a variety of <a href="https://en.wikipedia.org/wiki/Breaking_news">breaking news stories</a> and the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is expanded to include <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a> as well as new <a href="https://en.wikipedia.org/wiki/Twitter">Twitter posts</a>. There were two concrete tasks ; rumour stance prediction and rumour verification, which we present in detail along with results achieved by participants. We received 22 system submissions (a 70 % increase from RumourEval 2017) many of which used state-of-the-art methodology to tackle the challenges involved.</abstract>
      <url hash="40ecd9c8">S19-2147</url>
      <doi>10.18653/v1/S19-2147</doi>
      <bibkey>gorrell-etal-2019-semeval</bibkey>
    </paper>
    <paper id="148">
      <title>eventAI at SemEval-2019 Task 7 : Rumor Detection on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> by Exploiting Content, User Credibility and Propagation Information<fixed-case>AI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: Rumor Detection on Social Media by Exploiting Content, User Credibility and Propagation Information</title>
      <author><first>Quanzhi</first><last>Li</last></author>
      <author><first>Qiong</first><last>Zhang</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>855–859</pages>
      <abstract>This paper describes our system for SemEval 2019 RumorEval : Determining rumor veracity and support for rumors (SemEval 2019 Task 7). This track has two tasks : Task A is to determine a user’s stance towards the source rumor, and Task B is to detect the veracity of the rumor : true, false or unverified. For stance classification, a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network model</a> with <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">language features</a> is utilized. For rumor verification, our approach exploits information from different dimensions : rumor content, source credibility, user credibility, user stance, event propagation path, etc. We use an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble approach</a> in both tasks, which includes <a href="https://en.wikipedia.org/wiki/Neural_network">neural network models</a> as well as the traditional <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification algorithms</a>. Our system is ranked 1st place in the rumor verification task by both the macro F1 measure and the RMSE measure.</abstract>
      <url hash="7509f0a1">S19-2148</url>
      <doi>10.18653/v1/S19-2148</doi>
      <bibkey>li-etal-2019-eventai</bibkey>
    </paper>
    <paper id="150">
      <title>AUTOHOME-ORCA at SemEval-2019 Task 8 : Application of BERT for Fact-Checking in Community Forums<fixed-case>AUTOHOME</fixed-case>-<fixed-case>ORCA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 8: Application of <fixed-case>BERT</fixed-case> for Fact-Checking in Community Forums</title>
      <author><first>Zhengwei</first><last>Lv</last></author>
      <author><first>Duoxing</first><last>Liu</last></author>
      <author><first>Haifeng</first><last>Sun</last></author>
      <author><first>Xiao</first><last>Liang</last></author>
      <author><first>Tao</first><last>Lei</last></author>
      <author><first>Zhizhong</first><last>Shi</last></author>
      <author><first>Feng</first><last>Zhu</last></author>
      <author><first>Lei</first><last>Yang</last></author>
      <pages>870–876</pages>
      <abstract>Fact checking is an important task for maintaining high quality posts and improving user experience in Community Question Answering forums. Therefore, the SemEval-2019 task 8 is aimed to identify factual question (subtask A) and detect true factual information from corresponding answers (subtask B). In order to address this task, we propose a <a href="https://en.wikipedia.org/wiki/System">system</a> based on the BERT model with meta information of questions. For the subtask A, the outputs of fine-tuned BERT classification model are combined with the feature of length of questions to boost the performance. For the subtask B, the predictions of several variants of BERT model encoding the meta information are combined to create an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble model</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved competitive results with an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.82 in the subtask A and 0.83 in the subtask B. The experimental results validate the effectiveness of our <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <url hash="71bbcacf">S19-2150</url>
      <doi>10.18653/v1/S19-2150</doi>
      <bibkey>lv-etal-2019-autohome</bibkey>
    </paper>
    <paper id="154">
      <title>AiFu at SemEval-2019 Task 10 : A Symbolic and Sub-symbolic Integrated System for SAT Math Question Answering<fixed-case>A</fixed-case>i<fixed-case>F</fixed-case>u at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 10: A Symbolic and Sub-symbolic Integrated System for <fixed-case>SAT</fixed-case> Math Question Answering</title>
      <author><first>Yifan</first><last>Liu</last></author>
      <author><first>Keyu</first><last>Ding</last></author>
      <author><first>Yi</first><last>Zhou</last></author>
      <pages>900–906</pages>
      <abstract>AiFu has won the first place in the SemEval-2019 Task 10-Math Question Answeringcompetition. This paper is to describe how <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> works technically and to report and analyze some essential experimental results</abstract>
      <url hash="3d968da9">S19-2154</url>
      <doi>10.18653/v1/S19-2154</doi>
      <bibkey>liu-etal-2019-aifu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/math23k">Math23K</pwcdataset>
    </paper>
    <paper id="159">
      <title>Clark Kent at SemEval-2019 Task 4 : Stylometric Insights into Hyperpartisan News Detection<fixed-case>C</fixed-case>lark <fixed-case>K</fixed-case>ent at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Stylometric Insights into Hyperpartisan News Detection</title>
      <author><first>Viresh</first><last>Gupta</last></author>
      <author><first>Baani Leen</first><last>Kaur Jolly</last></author>
      <author><first>Ramneek</first><last>Kaur</last></author>
      <author><first>Tanmoy</first><last>Chakraborty</last></author>
      <pages>934–938</pages>
      <abstract>In this paper, we present a news bias prediction system, which we developed as part of a SemEval 2019 task. We developed an XGBoost based system which uses character and word level n-gram features represented using TF-IDF, count vector based correlation matrix, and predicts if an input news article is a hyperpartisan news article. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> was able to achieve a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> of 68.3 % on the test set provided by the contest organizers. We also run our model on the BuzzFeed corpus and find <a href="https://en.wikipedia.org/wiki/XGBoost">XGBoost</a> with simple character level N-Gram embeddings to be performing well with an accuracy of around 96 %.</abstract>
      <url hash="0a86af79">S19-2159</url>
      <doi>10.18653/v1/S19-2159</doi>
      <bibkey>gupta-etal-2019-clark</bibkey>
    </paper>
    <paper id="160">
      <title>Dick-Preston and Morbo at SemEval-2019 Task 4 : Transfer Learning for Hyperpartisan News Detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Transfer Learning for Hyperpartisan News Detection</title>
      <author><first>Tim</first><last>Isbister</last></author>
      <author><first>Fredrik</first><last>Johansson</last></author>
      <pages>939–943</pages>
      <abstract>In a world of <a href="https://en.wikipedia.org/wiki/Information_Operations_(United_States)">information operations</a>, influence campaigns, and <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>, classification of news articles as following hyperpartisan argumentation or not is becoming increasingly important. We present a deep learning-based approach in which a pre-trained language model has been fine-tuned on domain-specific data and used for classification of news articles, as part of the SemEval-2019 task on hyperpartisan news detection. The suggested approach yields <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and <a href="https://en.wikipedia.org/wiki/F-number">F1-scores</a> around 0.8 which places the best performing <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> among the top-5 systems in the competition.</abstract>
      <url hash="2485d756">S19-2160</url>
      <doi>10.18653/v1/S19-2160</doi>
      <bibkey>isbister-johansson-2019-dick</bibkey>
    </paper>
    <paper id="165">
      <title>Harvey Mudd College at SemEval-2019 Task 4 : The Clint Buchanan Hyperpartisan News Detector<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: The Clint Buchanan Hyperpartisan News Detector</title>
      <author><first>Mehdi</first><last>Drissi</last></author>
      <author><first>Pedro</first><last>Sandoval Segura</last></author>
      <author><first>Vivaswat</first><last>Ojha</last></author>
      <author><first>Julie</first><last>Medero</last></author>
      <pages>962–966</pages>
      <abstract>We investigate the recently developed Bidi- rectional Encoder Representations from Transformers (BERT) model (Devlin et al. 2018) for the hyperpartisan news detection task. Using a subset of hand-labeled articles from <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a> as a validation set, we test the performance of different parameters for BERT models. We find that <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> from two different BERT models using different proportions of the articles is consistently high, with our best-performing <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the validation set achieving 85 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and the best-performing <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the test set achieving 77 %. We further determined that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> exhibits strong consistency, labeling independent slices of the same article identically. Finally, we find that randomizing the order of word pieces dramatically reduces validation accuracy (to approximately 60 %), but that shuffling groups of four or more word pieces maintains an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of about 80 %, indicating the model mainly gains value from local context.</abstract>
      <url hash="b3a582c6">S19-2165</url>
      <doi>10.18653/v1/S19-2165</doi>
      <bibkey>drissi-etal-2019-harvey</bibkey>
      <pwccode url="https://github.com/hmc-cs159-fall2018/final-project-team-mvp-10000" additional="false">hmc-cs159-fall2018/final-project-team-mvp-10000</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="166">
      <title>Harvey Mudd College at SemEval-2019 Task 4 : The D.X. Beaumont Hyperpartisan News Detector<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: The <fixed-case>D</fixed-case>.<fixed-case>X</fixed-case>. Beaumont Hyperpartisan News Detector</title>
      <author><first>Evan</first><last>Amason</last></author>
      <author><first>Jake</first><last>Palanker</last></author>
      <author><first>Mary Clare</first><last>Shen</last></author>
      <author><first>Julie</first><last>Medero</last></author>
      <pages>967–970</pages>
      <abstract>We use the 600 hand-labelled articles from SemEval Task 4 to hand-tune a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> with 3000 <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for the Hyperpartisan News Detection task. Our final system uses features based on bag-of-words (BoW), analysis of the article title, language complexity, and simple <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in a <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">naive Bayes classifier</a>. We trained our final <a href="https://en.wikipedia.org/wiki/System">system</a> on the 600,000 articles labelled by publisher. Our final <a href="https://en.wikipedia.org/wiki/System">system</a> has an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.653 on the hand-labeled test set. The most effective features are the <a href="https://en.wikipedia.org/wiki/Automated_Readability_Index">Automated Readability Index</a> and the presence of certain words in the title. This suggests that hyperpartisan writing uses a distinct <a href="https://en.wikipedia.org/wiki/Writing_style">writing style</a>, especially in the title.</abstract>
      <url hash="e0760bc0">S19-2166</url>
      <doi>10.18653/v1/S19-2166</doi>
      <bibkey>amason-etal-2019-harvey</bibkey>
    </paper>
    <paper id="170">
      <title>Spider-Jerusalem at SemEval-2019 Task 4 : Hyperpartisan News Detection<fixed-case>J</fixed-case>erusalem at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Hyperpartisan News Detection</title>
      <author><first>Amal</first><last>Alabdulkarim</last></author>
      <author><first>Tariq</first><last>Alhindi</last></author>
      <pages>985–989</pages>
      <abstract>This paper describes our system for detecting hyperpartisan news articles, which was submitted for the shared task in SemEval 2019 on Hyperpartisan News Detection. We developed a Support Vector Machine (SVM) model that uses TF-IDF of tokens, Language Inquiry and Word Count (LIWC) features, and structural features such as number of paragraphs and hyperlink count in an article. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> was trained on 645 articles from two classes : mainstream and hyperpartisan. Our system was ranked seventeenth out of forty two participating teams in the binary classification task with an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy score</a> of 0.742 on the blind test set (the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the top ranked system was 0.822). We provide a detailed description of our preprocessing steps, discussion of our experiments using different combinations of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, and analysis of our results and prediction errors.</abstract>
      <url hash="5fbe5431">S19-2170</url>
      <doi>10.18653/v1/S19-2170</doi>
      <bibkey>alabdulkarim-alhindi-2019-spider</bibkey>
    </paper>
    <paper id="171">
      <title>Steve Martin at SemEval-2019 Task 4 : Ensemble Learning Model for Detecting Hyperpartisan News<fixed-case>M</fixed-case>artin at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Ensemble Learning Model for Detecting Hyperpartisan News</title>
      <author><first>Youngjun</first><last>Joo</last></author>
      <author><first>Inchon</first><last>Hwang</last></author>
      <pages>990–994</pages>
      <abstract>This paper describes our submission to task 4 in SemEval 2019, i.e., hyperpartisan news detection. Our model aims at detecting hyperpartisan news by incorporating the style-based features and the content-based features. We extract a broad number of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature sets</a> and use as our learning algorithms the GBDT and the n-gram CNN model. Finally, we apply the <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted average</a> for effective learning between the two <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.745 on the <a href="https://en.wikipedia.org/wiki/Set_(mathematics)">test set</a> in subtask A.</abstract>
      <url hash="4b5936a3">S19-2171</url>
      <attachment type="supplementary" hash="fcfbfd16">S19-2171.Supplementary.pdf</attachment>
      <doi>10.18653/v1/S19-2171</doi>
      <bibkey>joo-hwang-2019-steve</bibkey>
    </paper>
    <paper id="173">
      <title>Team Fernando-Pessa at SemEval-2019 Task 4 : Back to Basics in Hyperpartisan News Detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Back to Basics in Hyperpartisan News Detection</title>
      <author><first>André</first><last>Cruz</last></author>
      <author><first>Gil</first><last>Rocha</last></author>
      <author><first>Rui</first><last>Sousa-Silva</last></author>
      <author><first>Henrique</first><last>Lopes Cardoso</last></author>
      <pages>999–1003</pages>
      <abstract>This paper describes our submission to the SemEval 2019 Hyperpartisan News Detection task. Our <a href="https://en.wikipedia.org/wiki/System">system</a> aims for a linguistics-based document classification from a minimal set of interpretable features, while maintaining good performance. To this goal, we follow a feature-based approach and perform several experiments with different machine learning classifiers. Additionally, we explore feature importances and <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributions</a> among the two classes. On the main <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> achieved an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 71.7 %, which was improved after the task’s end to 72.9 %. We also participate on the meta-learning sub-task, for classifying documents with the <a href="https://en.wikipedia.org/wiki/Binary_classification">binary classifications</a> of all submitted systems as input, achieving an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 89.9 %.</abstract>
      <url hash="d541abb7">S19-2173</url>
      <doi>10.18653/v1/S19-2173</doi>
      <bibkey>cruz-etal-2019-team</bibkey>
    </paper>
    <paper id="176">
      <title>Team Jack Ryder at SemEval-2019 Task 4 : Using BERT Representations for Detecting Hyperpartisan News<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Using <fixed-case>BERT</fixed-case> Representations for Detecting Hyperpartisan News</title>
      <author><first>Daniel</first><last>Shaprin</last></author>
      <author><first>Giovanni</first><last>Da San Martino</last></author>
      <author><first>Alberto</first><last>Barrón-Cedeño</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>1012–1015</pages>
      <abstract>We describe the system submitted by the Jack Ryder team to SemEval-2019 Task 4 on Hyperpartisan News Detection. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> asked participants to predict whether a given article is hyperpartisan, i.e., <a href="https://en.wikipedia.org/wiki/Far-left_politics">extreme-left</a> or <a href="https://en.wikipedia.org/wiki/Far-right_politics">extreme-right</a>. We proposed an approach based on BERT with fine-tuning, which was ranked 7th out 28 teams on the distantly supervised dataset, where all articles from a hyperpartisan / non-hyperpartisan news outlet are considered to be hyperpartisan / non-hyperpartisan. On a manually annotated test dataset, where human annotators double-checked the labels, we were ranked 29th out of 42 teams.</abstract>
      <url hash="4146e431">S19-2176</url>
      <doi>10.18653/v1/S19-2176</doi>
      <bibkey>shaprin-etal-2019-team</bibkey>
    </paper>
    <paper id="178">
      <title>Team Kit Kittredge at SemEval-2019 Task 4 : LSTM Voting System<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: <fixed-case>LSTM</fixed-case> Voting System</title>
      <author><first>Rebekah</first><last>Cramerus</last></author>
      <author><first>Tatjana</first><last>Scheffler</last></author>
      <pages>1021–1025</pages>
      <abstract>This paper describes the approach of team Kit Kittredge to SemEval-2019 Task 4 : Hyperpartisan News Detection. The goal was binary classification of news articles into the categories of biased or unbiased. We had two software submissions : one a simple bag-of-words model, and the second an LSTM (Long Short Term Memory) neural network, which was trained on a subset of the original dataset selected by a voting system of other LSTMs. This method did not prove much more successful than the baseline, however, due to the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>’ tendency to learn publisher-specific traits instead of general bias.</abstract>
      <url hash="1aa432e3">S19-2178</url>
      <doi>10.18653/v1/S19-2178</doi>
      <bibkey>cramerus-scheffler-2019-team</bibkey>
    </paper>
    <paper id="180">
      <title>Team Peter Brinkmann at SemEval-2019 Task 4 : Detecting Biased News Articles Using Convolutional Neural Networks<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Detecting Biased News Articles Using Convolutional Neural Networks</title>
      <author><first>Michael</first><last>Färber</last></author>
      <author><first>Agon</first><last>Qurdina</last></author>
      <author><first>Lule</first><last>Ahmedi</last></author>
      <pages>1032–1036</pages>
      <abstract>In this paper, we present an approach for classifying <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> as biased (i.e., hyperpartisan) or unbiased, based on a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>. We experiment with various embedding methods (pretrained and trained on the training dataset) and variations of the convolutional neural network architecture and compare the results. When evaluating our best performing approach on the actual test data set of the SemEval 2019 Task 4, we obtained relatively low <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> and accuracy values, while gaining the highest <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall rate</a> among all 42 participating teams.</abstract>
      <url hash="3dfbdeff">S19-2180</url>
      <doi>10.18653/v1/S19-2180</doi>
      <bibkey>farber-etal-2019-team</bibkey>
      <pwccode url="https://github.com/michaelfaerber/SemEval2019-Task4" additional="false">michaelfaerber/SemEval2019-Task4</pwccode>
    </paper>
    <paper id="181">
      <title>Team Peter-Parker at SemEval-2019 Task 4 : BERT-Based Method in Hyperpartisan News Detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: <fixed-case>BERT</fixed-case>-Based Method in Hyperpartisan News Detection</title>
      <author><first>Zhiyuan</first><last>Ning</last></author>
      <author><first>Yuanzhen</first><last>Lin</last></author>
      <author><first>Ruichao</first><last>Zhong</last></author>
      <pages>1037–1040</pages>
      <abstract>This paper describes the team peter-parker’s participation in Hyperpartisan News Detection task (SemEval-2019 Task 4), which requires to classify whether a given news article is bias or not. We decided to use <a href="https://en.wikipedia.org/wiki/JAVA">JAVA</a> to do the article parsing tool and the BERT-Based model to do the bias prediction. Furthermore, we will show experiment results with analysis.</abstract>
      <url hash="525caeb8">S19-2181</url>
      <doi>10.18653/v1/S19-2181</doi>
      <bibkey>ning-etal-2019-team</bibkey>
    </paper>
    <paper id="183">
      <title>Team Xenophilius Lovegood at SemEval-2019 Task 4 : Hyperpartisanship Classification using Convolutional Neural Networks<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Hyperpartisanship Classification using Convolutional Neural Networks</title>
      <author><first>Albin</first><last>Zehe</last></author>
      <author><first>Lena</first><last>Hettinger</last></author>
      <author><first>Stefan</first><last>Ernst</last></author>
      <author><first>Christian</first><last>Hauptmann</last></author>
      <author><first>Andreas</first><last>Hotho</last></author>
      <pages>1047–1051</pages>
      <abstract>This paper describes our system for the SemEval 2019 Task 4 on hyperpartisan news detection. We build on an existing deep learning approach for sentence classification based on a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a>. Modifying the original <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with additional layers to increase its expressiveness and finally building an ensemble of multiple versions of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, we obtain an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 67.52 % and an <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> of 73.78 % on the main test dataset. We also report on additional experiments incorporating handcrafted features into the CNN and using it as a <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extractor</a> for a linear SVM.</abstract>
      <url hash="8a20b7c0">S19-2183</url>
      <doi>10.18653/v1/S19-2183</doi>
      <bibkey>zehe-etal-2019-team</bibkey>
    </paper>
    <paper id="185">
      <title>The Sally Smedley Hyperpartisan News Detector at SemEval-2019 Task 4<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4</title>
      <author><first>Kazuaki</first><last>Hanawa</last></author>
      <author><first>Shota</first><last>Sasaki</last></author>
      <author><first>Hiroki</first><last>Ouchi</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>1057–1061</pages>
      <abstract>This paper describes our system submitted to the formal run of SemEval-2019 Task 4 : Hyperpartisan news detection. Our system is based on a <a href="https://en.wikipedia.org/wiki/Linear_classifier">linear classifier</a> using several <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, i.e., 1) embedding features based on the pre-trained BERT embeddings, 2) article length features, and 3) embedding features of informative phrases extracted from by-publisher dataset. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 80.9 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the test set for the formal run and got the 3rd place out of 42 teams.</abstract>
      <url hash="5070a922">S19-2185</url>
      <doi>10.18653/v1/S19-2185</doi>
      <bibkey>hanawa-etal-2019-sally</bibkey>
    </paper>
    <paper id="186">
      <title>Tintin at SemEval-2019 Task 4 : Detecting Hyperpartisan News Article with only Simple Tokens<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Detecting Hyperpartisan News Article with only Simple Tokens</title>
      <author><first>Yves</first><last>Bestgen</last></author>
      <pages>1062–1066</pages>
      <abstract>Tintin, the system proposed by the CECL for the Hyperpartisan News Detection task of SemEval 2019, is exclusively based on the tokens that make up the documents and a standard supervised learning procedure. It obtained very contrasting results : poor on the main task, but much more effective at distinguishing documents published by hyperpartisan media outlets from unbiased ones, as <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> ranked first. An analysis of the most important <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> highlighted the positive aspects, but also some potential limitations of the approach.</abstract>
      <url hash="c68f0cc5">S19-2186</url>
      <doi>10.18653/v1/S19-2186</doi>
      <bibkey>bestgen-2019-tintin</bibkey>
    </paper>
    <paper id="189">
      <title>Vernon-fenwick at SemEval-2019 Task 4 : Hyperpartisan News Detection using Lexical and Semantic Features<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 4: Hyperpartisan News Detection using Lexical and Semantic Features</title>
      <author><first>Vertika</first><last>Srivastava</last></author>
      <author><first>Ankita</first><last>Gupta</last></author>
      <author><first>Divya</first><last>Prakash</last></author>
      <author><first>Sudeep Kumar</first><last>Sahoo</last></author>
      <author><first>Rohit</first><last>R.R</last></author>
      <author><first>Yeon Hyang</first><last>Kim</last></author>
      <pages>1078–1082</pages>
      <abstract>In this paper, we present our submission for SemEval-2019 Task 4 : Hyperpartisan News Detection. Hyperpartisan news articles are sharply polarized and extremely biased (onesided). It shows blind beliefs, opinions and unreasonable adherence to a party, idea, faction or a person. Through this task, we aim to develop an automated system that can be used to detect hyperpartisan news and serve as a prescreening technique for fake news detection. The proposed <a href="https://en.wikipedia.org/wiki/System">system</a> jointly uses a rich set of handcrafted textual and semantic features. Our system achieved 2nd rank on the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">primary metric</a> (82.0 % accuracy) and 1st rank on the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">secondary metric</a> (82.1 % F1-score), among all participating teams. Comparison with the best performing <a href="https://en.wikipedia.org/wiki/System">system</a> on the leaderboard shows that our <a href="https://en.wikipedia.org/wiki/System">system</a> is behind by only 0.2 % absolute difference in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <url hash="70a20b90">S19-2189</url>
      <doi>10.18653/v1/S19-2189</doi>
      <bibkey>srivastava-etal-2019-vernon</bibkey>
    </paper>
    <paper id="191">
      <title>BLCU_NLP at SemEval-2019 Task 7 : An Inference Chain-based GPT Model for Rumour Evaluation<fixed-case>BLCU</fixed-case>_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: An Inference Chain-based <fixed-case>GPT</fixed-case> Model for Rumour Evaluation</title>
      <author><first>Ruoyao</first><last>Yang</last></author>
      <author><first>Wanying</first><last>Xie</last></author>
      <author><first>Chunhua</first><last>Liu</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <pages>1090–1096</pages>
      <abstract>Researchers have been paying increasing attention to rumour evaluation due to the rapid spread of unsubstantiated rumours on <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a>, including SemEval 2019 task 7. However, labelled data for learning rumour veracity is scarce, and labels in rumour stance data are highly disproportionate, making it challenging for a model to perform <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised-learning</a> adequately. We propose an inference chain-based system, which fully utilizes conversation structure-based knowledge in the limited data and expand the training data in minority categories to alleviate <a href="https://en.wikipedia.org/wiki/Social_class">class imbalance</a>. Our <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a> obtains 12.6 % improvement upon the baseline system for subtask A, ranks 1st among 21 systems in subtask A, and ranks 4th among 12 systems in subtask B.</abstract>
      <url hash="f419313f">S19-2191</url>
      <doi>10.18653/v1/S19-2191</doi>
      <bibkey>yang-etal-2019-blcu</bibkey>
    </paper>
    <paper id="193">
      <title>CLEARumor at SemEval-2019 Task 7 : ConvoLving ELMo Against Rumors<fixed-case>CLEAR</fixed-case>umor at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: <fixed-case>C</fixed-case>onvo<fixed-case>L</fixed-case>ving <fixed-case>ELM</fixed-case>o Against Rumors</title>
      <author><first>Ipek</first><last>Baris</last></author>
      <author><first>Lukas</first><last>Schmelzeisen</last></author>
      <author><first>Steffen</first><last>Staab</last></author>
      <pages>1105–1109</pages>
      <abstract>This paper describes our submission to SemEval-2019 Task 7 : RumourEval : Determining Rumor Veracity and Support for Rumors. We participated in both subtasks. The goal of subtask A is to classify the type of interaction between a rumorous social media post and a reply post as support, query, deny, or comment. The goal of subtask B is to predict the veracity of a given <a href="https://en.wikipedia.org/wiki/Rumor">rumor</a>. For subtask A, we implement a CNN-based neural architecture using ELMo embeddings of post text combined with auxiliary features and achieve a F1-score of 44.6 %. For subtask B, we employ a MLP neural network leveraging our estimates for subtask A and achieve a F1-score of 30.1 % (second place in the competition). We provide results and analysis of our <a href="https://en.wikipedia.org/wiki/System">system</a> performance and present ablation experiments.</abstract>
      <url hash="049a561a">S19-2193</url>
      <doi>10.18653/v1/S19-2193</doi>
      <bibkey>baris-etal-2019-clearumor</bibkey>
      <pwccode url="https://github.com/lschmelzeisen/clearumor" additional="false">lschmelzeisen/clearumor</pwccode>
    </paper>
    <paper id="195">
      <title>GWU NLP at SemEval-2019 Task 7 : Hybrid Pipeline for Rumour Veracity and Stance Classification on Social Media<fixed-case>GWU</fixed-case> <fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: Hybrid Pipeline for Rumour Veracity and Stance Classification on Social Media</title>
      <author><first>Sardar</first><last>Hamidian</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>1115–1119</pages>
      <abstract>Social media plays a crucial role as the main resource news for information seekers online. However, the unmoderated feature of <a href="https://en.wikipedia.org/wiki/Social_media">social media platforms</a> lead to the emergence and spread of untrustworthy contents which harm individuals or even societies. Most of the current automated approaches for automatically determining the veracity of a rumor are not generalizable for novel emerging topics. This paper describes our hybrid system comprising <a href="https://en.wikipedia.org/wiki/Rule-based_system">rules</a> and a <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning model</a> which makes use of replied tweets to identify the veracity of the source tweet. The proposed system in this paper achieved 0.435 F-Macro in stance classification, and 0.262 F-macro and 0.801 <a href="https://en.wikipedia.org/wiki/RMSE">RMSE</a> in rumor verification tasks in Task7 of SemEval 2019.</abstract>
      <url hash="bf5545ce">S19-2195</url>
      <doi>10.18653/v1/S19-2195</doi>
      <bibkey>hamidian-diab-2019-gwu</bibkey>
    </paper>
    <paper id="196">
      <title>SINAI-DL at SemEval-2019 Task 7 : Data Augmentation and Temporal Expressions<fixed-case>SINAI</fixed-case>-<fixed-case>DL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: Data Augmentation and Temporal Expressions</title>
      <author><first>Miguel A.</first><last>García-Cumbreras</last></author>
      <author><first>Salud María</first><last>Jiménez-Zafra</last></author>
      <author><first>Arturo</first><last>Montejo-Ráez</last></author>
      <author><first>Manuel Carlos</first><last>Díaz-Galiano</last></author>
      <author><first>Estela</first><last>Saquete</last></author>
      <pages>1120–1124</pages>
      <abstract>This paper describes the participation of the SINAI-DL team at RumourEval (Task 7 in SemEval 2019, subtask A : SDQC). SDQC addresses the challenge of rumour stance classification as an indirect way of identifying potential <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>. Given a tweet with several replies, our system classifies each reply into either supporting, denying, questioning or commenting on the underlying <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>. We have applied <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, temporal expressions labelling and <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> with a four-layer neural classifier. We achieve an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.715 with the official run over reply tweets.</abstract>
      <url hash="c2dad255">S19-2196</url>
      <doi>10.18653/v1/S19-2196</doi>
      <bibkey>garcia-cumbreras-etal-2019-sinai</bibkey>
    </paper>
    <paper id="197">
      <title>UPV-28-UNITO at SemEval-2019 Task 7 : Exploiting Post’s Nesting and Syntax Information for Rumor Stance Classification<fixed-case>UPV</fixed-case>-28-<fixed-case>UNITO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 7: Exploiting Post’s Nesting and Syntax Information for Rumor Stance Classification</title>
      <author><first>Bilal</first><last>Ghanem</last></author>
      <author><first>Alessandra Teresa</first><last>Cignarella</last></author>
      <author><first>Cristina</first><last>Bosco</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <author><first>Francisco Manuel</first><last>Rangel Pardo</last></author>
      <pages>1125–1131</pages>
      <abstract>In the present paper we describe the UPV-28-UNITO system’s submission to the RumorEval 2019 shared task. The approach we applied for addressing both the subtasks of the contest exploits both classical <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, and it is based on diverse groups of features : stylistic, lexical, emotional, sentiment, meta-structural and Twitter-based. A novel set of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">features</a> that take advantage of the syntactic information in texts is moreover introduced in the paper.</abstract>
      <url hash="cfe2890a">S19-2197</url>
      <doi>10.18653/v1/S19-2197</doi>
      <bibkey>ghanem-etal-2019-upv</bibkey>
    </paper>
    <paper id="200">
      <title>ColumbiaNLP at SemEval-2019 Task 8 : The Answer is Language Model Fine-tuning<fixed-case>C</fixed-case>olumbia<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 8: The Answer is Language Model Fine-tuning</title>
      <author><first>Tuhin</first><last>Chakrabarty</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <pages>1144–1148</pages>
      <abstract>Community Question Answering forums are very popular nowadays, as they represent effective means for communities to share information around particular topics. But the information shared on these <a href="https://en.wikipedia.org/wiki/Internet_forum">forums</a> are often not authentic. This paper presents the ColumbiaNLP submission for the SemEval-2019 Task 8 : Fact-Checking in Community Question Answering Forums. We show how fine-tuning a language model on a large unannotated corpus of old threads from Qatar Living forum helps us to classify question types (factual, opinion, socializing) and to judge the factuality of answers on the shared task labeled data from the same forum. Our system finished 4th and 2nd on Subtask A (question type classification) and B (answer factuality prediction), respectively, based on the official metric of accuracy.</abstract>
      <url hash="9c353085">S19-2200</url>
      <doi>10.18653/v1/S19-2200</doi>
      <bibkey>chakrabarty-muresan-2019-columbianlp</bibkey>
    </paper>
    <paper id="203">
      <title>Fermi at SemEval-2019 Task 8 : An elementary but effective approach to Question Discernment in Community QA Forums<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 8: An elementary but effective approach to Question Discernment in Community <fixed-case>QA</fixed-case> Forums</title>
      <author><first>Bakhtiyar</first><last>Syed</last></author>
      <author><first>Vijayasaradhi</first><last>Indurthi</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Manish</first><last>Gupta</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>1160–1164</pages>
      <abstract>Online Community Question Answering Forums (cQA) have gained massive popularity within recent years. The rise in users for such <a href="https://en.wikipedia.org/wiki/Internet_forum">forums</a> have led to the increase in the need for automated evaluation for <a href="https://en.wikipedia.org/wiki/Sentence_processing">question comprehension</a> and <a href="https://en.wikipedia.org/wiki/Fact-checking">fact evaluation</a> of the answers provided by various participants in the forum. Our team, Fermi, participated in sub-task A of Task 8 at SemEval 2019-which tackles the first problem in the pipeline of factual evaluation in cQA forums, i.e., deciding whether a posed question asks for a factual information, an opinion / advice or is just socializing. This information is highly useful in segregating factual questions from non-factual ones which highly helps in organizing the questions into useful categories and trims down the problem space for the next task in the pipeline for fact evaluation among the available answers. Our system uses the embeddings obtained from Universal Sentence Encoder combined with <a href="https://en.wikipedia.org/wiki/XGBoost">XGBoost</a> for the classification sub-task A. We also evaluate other combinations of embeddings and off-the-shelf machine learning algorithms to demonstrate the efficacy of the various representations and their combinations. Our results across the evaluation test set gave an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 84 % and received the first position in the final standings judged by the organizers.<b>Fermi</b>, participated in sub-task A of Task 8 at SemEval 2019 - which tackles the first problem in the pipeline of factual evaluation in cQA forums, i.e., deciding whether a posed question asks for a factual information, an opinion/advice or is just socializing. This information is highly useful in segregating factual questions from non-factual ones which highly helps in organizing the questions into useful categories and trims down the problem space for the next task in the pipeline for fact evaluation among the available answers. Our system uses the embeddings obtained from Universal Sentence Encoder combined with XGBoost for the classification sub-task A. We also evaluate other combinations of embeddings and off-the-shelf machine learning algorithms to demonstrate the efficacy of the various representations and their combinations. Our results across the evaluation test set gave an accuracy of 84% and received the first position in the final standings judged by the organizers.</abstract>
      <url hash="a2b7b8cd">S19-2203</url>
      <doi>10.18653/v1/S19-2203</doi>
      <bibkey>syed-etal-2019-fermi</bibkey>
    </paper>
    <paper id="206">
      <title>TueFact at SemEval 2019 Task 8 : <a href="https://en.wikipedia.org/wiki/Fact-checking">Fact checking</a> in community question answering forums : context matters<fixed-case>T</fixed-case>ue<fixed-case>F</fixed-case>act at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2019 Task 8: Fact checking in community question answering forums: context matters</title>
      <author><first>Réka</first><last>Juhász</last></author>
      <author><first>Franziska Barbara</first><last>Linnenschmidt</last></author>
      <author><first>Teslin</first><last>Roys</last></author>
      <pages>1176–1179</pages>
      <abstract>The SemEval 2019 Task 8 on Fact-Checking in community question answering forums aimed to classify questions into categories and verify the correctness of answers given on the QatarLiving public forum. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> was divided into two subtasks : the first classifying the question, the second the answers. The TueFact system described in this paper used different approaches for the two subtasks. Subtask A makes use of word vectors based on a bag-of-word-ngram model using up to <a href="https://en.wikipedia.org/wiki/Trigram">trigrams</a>. Predictions are done using multi-class logistic regression. The official SemEval result lists an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.60. Subtask B uses vectorized character n-grams up to <a href="https://en.wikipedia.org/wiki/Trigram">trigrams</a> instead. Predictions are done using a LSTM model and achieved an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.53 on the final SemEval Task 8 evaluation set.</abstract>
      <url hash="d35e7342">S19-2206</url>
      <doi>10.18653/v1/S19-2206</doi>
      <bibkey>juhasz-etal-2019-tuefact</bibkey>
    </paper>
    <paper id="207">
      <title>YNU-HPCC at SemEval-2019 Task 8 : Using A LSTM-Attention Model for Fact-Checking in Community Forums<fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 8: Using A <fixed-case>LSTM</fixed-case>-Attention Model for Fact-Checking in Community Forums</title>
      <author><first>Peng</first><last>Liu</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>1180–1184</pages>
      <abstract>We propose a system that uses a long short-term memory with attention mechanism (LSTM-Attention) model to complete the task. The LSTM-Attention model uses two LSTM to extract the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> of the question and answer pair. Then, each of the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> is sequentially composed using the <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanism</a>, concatenating the two vectors into one. Finally, the concatenated vector is used as input for the <a href="https://en.wikipedia.org/wiki/Machine_learning">MLP</a> and the <a href="https://en.wikipedia.org/wiki/Machine_learning">MLP’s output layer</a> uses the softmax function to classify the provided answers into three categories. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is capable of extracting the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> of the question and answer pair well. The results show that the proposed <a href="https://en.wikipedia.org/wiki/System">system</a> outperforms the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline algorithm</a>.</abstract>
      <url hash="1d3d6714">S19-2207</url>
      <doi>10.18653/v1/S19-2207</doi>
      <bibkey>liu-etal-2019-ynu</bibkey>
    </paper>
    <paper id="213">
      <title>MIDAS at SemEval-2019 Task 9 : Suggestion Mining from Online Reviews using ULMFit<fixed-case>MIDAS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Suggestion Mining from Online Reviews using <fixed-case>ULMF</fixed-case>it</title>
      <author><first>Sarthak</first><last>Anand</last></author>
      <author><first>Debanjan</first><last>Mahata</last></author>
      <author><first>Kartik</first><last>Aggarwal</last></author>
      <author><first>Laiba</first><last>Mehnaz</last></author>
      <author><first>Simra</first><last>Shahid</last></author>
      <author><first>Haimin</first><last>Zhang</last></author>
      <author><first>Yaman</first><last>Kumar</last></author>
      <author><first>Rajiv</first><last>Shah</last></author>
      <author><first>Karan</first><last>Uppal</last></author>
      <pages>1213–1217</pages>
      <abstract>In this paper we present our approach to tackle the Suggestion Mining from Online Reviews and Forums Sub-Task A. Given a review, we are asked to predict whether the review consists of a suggestion or not. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is based on Universal Language Model Fine-tuning for <a href="https://en.wikipedia.org/wiki/Text_classification">Text Classification</a>. We apply various pre-processing techniques before training the <a href="https://en.wikipedia.org/wiki/Language">language</a> and the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification model</a>. We further provide analysis of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Our <a href="https://en.wikipedia.org/wiki/Team">team</a> ranked 10th out of 34 participants, achieving an F1 score of 0.7011.</abstract>
      <url hash="a42ef3c3">S19-2213</url>
      <doi>10.18653/v1/S19-2213</doi>
      <bibkey>anand-etal-2019-midas</bibkey>
    </paper>
    <paper id="215">
      <title>NTUA-ISLab at SemEval-2019 Task 9 : Mining Suggestions in the wild<fixed-case>NTUA</fixed-case>-<fixed-case>ISL</fixed-case>ab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Mining Suggestions in the wild</title>
      <author><first>Rolandos Alexandros</first><last>Potamias</last></author>
      <author><first>Alexandros</first><last>Neofytou</last></author>
      <author><first>Georgios</first><last>Siolas</last></author>
      <pages>1224–1230</pages>
      <abstract>As online customer forums and product comparison sites increase their societal influence, users are actively expressing their opinions and posting their recommendations on their fellow customers online. However, <a href="https://en.wikipedia.org/wiki/System">systems</a> capable of recognizing suggestions still lack in stability. Suggestion Mining, a novel and challenging field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>, is increasingly gaining attention, aiming to track user advice on <a href="https://en.wikipedia.org/wiki/Internet_forum">online forums</a>. In this paper, a carefully designed <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to identify customer-to-company and customer-to-customer suggestions is presented. The <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> implements a rule-based classifier using heuristic, lexical and syntactic patterns. The approach ranked at 5th and 1st position, achieving an f1-score of 0.749 and 0.858 for SemEval-2019 / Suggestion Mining sub-tasks A and B, respectively. In addition, we were able to improve performance results by combining the rule-based classifier with a recurrent convolutional neural network, that exhibits an <a href="https://en.wikipedia.org/wiki/F-number">f1-score</a> of 0.79 for subtask A.</abstract>
      <url hash="ce3f5cce">S19-2215</url>
      <doi>10.18653/v1/S19-2215</doi>
      <bibkey>potamias-etal-2019-ntua</bibkey>
    </paper>
    <paper id="217">
      <title>SSN-SPARKS at SemEval-2019 Task 9 : Mining Suggestions from Online Reviews using Deep Learning Techniques on Augmented Data<fixed-case>SSN</fixed-case>-<fixed-case>SPARKS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Mining Suggestions from Online Reviews using Deep Learning Techniques on Augmented Data</title>
      <author><first>Rajalakshmi</first><last>S</last></author>
      <author><first>Angel</first><last>Suseelan</last></author>
      <author><first>S Milton</first><last>Rajendram</last></author>
      <author><first>Mirnalinee</first><last>T T</last></author>
      <pages>1237–1241</pages>
      <abstract>This paper describes the work on mining the suggestions from <a href="https://en.wikipedia.org/wiki/Review_site">online reviews</a> and forums. Opinion mining detects whether the comments are positive, negative or neutral, while suggestion mining explores the review content for the possible tips or advice. The system developed by SSN-SPARKS team in SemEval-2019 for task 9 (suggestion mining) uses a rule-based approach for feature selection, SMOTE technique for data augmentation and deep learning technique (Convolutional Neural Network) for classification. We have compared the results with Random Forest classifier (RF) and MultiLayer Perceptron (MLP) model. Results show that the CNN model performs better than other <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for both the subtasks.</abstract>
      <url hash="892abf9f">S19-2217</url>
      <doi>10.18653/v1/S19-2217</doi>
      <bibkey>s-etal-2019-ssn</bibkey>
    </paper>
    <paper id="218">
      <title>Suggestion Miner at SemEval-2019 Task 9 : Suggestion Detection in Online Forum using Word Graph<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Suggestion Detection in Online Forum using Word Graph</title>
      <author><first>Usman</first><last>Ahmed</last></author>
      <author><first>Humera</first><last>Liaquat</last></author>
      <author><first>Luqman</first><last>Ahmed</last></author>
      <author><first>Syed Jawad</first><last>Hussain</last></author>
      <pages>1242–1246</pages>
      <abstract>This paper describes the suggestion miner system that participates in SemEval 2019 Task 9-SubTask A-Suggestion Mining from Online Reviews and Forums. The <a href="https://en.wikipedia.org/wiki/System">system</a> participated in the subtasks A. This paper discusses the results of our <a href="https://en.wikipedia.org/wiki/System">system</a> in the development, evaluation and post evaluation. Each class in the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is represented as <a href="https://en.wikipedia.org/wiki/Directed_graph">directed unweighted graphs</a>. Then, the comparison is carried out with each <a href="https://en.wikipedia.org/wiki/Class_graph">class graph</a> which results in a vector. This <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vector</a> is used as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> by a <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithm</a>. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is evaluated on hold on strategy. The organizers randomly split (8500 instances) training set (provided to the participant in training their system) and testing set (833 instances). The test set is reserved to evaluate the performance of participants systems. During the evaluation, our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 31 in the Coda Lab result of the subtask A (binary class problem). The binary class system achieves evaluation value 0.34, <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> 0.87, <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">recall</a> 0.73 and <a href="https://en.wikipedia.org/wiki/F-number">F measure</a> 0.78.</abstract>
      <url hash="6476fdf0">S19-2218</url>
      <doi>10.18653/v1/S19-2218</doi>
      <bibkey>ahmed-etal-2019-suggestion</bibkey>
    </paper>
    <paper id="220">
      <title>ThisIsCompetition at SemEval-2019 Task 9 : BERT is unstable for out-of-domain samples<fixed-case>T</fixed-case>his<fixed-case>I</fixed-case>s<fixed-case>C</fixed-case>ompetition at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: <fixed-case>BERT</fixed-case> is unstable for out-of-domain samples</title>
      <author><first>Cheoneum</first><last>Park</last></author>
      <author><first>Juae</first><last>Kim</last></author>
      <author><first>Hyeon-gu</first><last>Lee</last></author>
      <author><first>Reinald Kim</first><last>Amplayo</last></author>
      <author><first>Harksoo</first><last>Kim</last></author>
      <author><first>Jungyun</first><last>Seo</last></author>
      <author><first>Changki</first><last>Lee</last></author>
      <pages>1254–1261</pages>
      <abstract>This paper describes our system, Joint Encoders for Stable Suggestion Inference (JESSI), for the SemEval 2019 Task 9 : Suggestion Mining from Online Reviews and Forums. JESSI is a combination of two sentence encoders : (a) one using multiple pre-trained word embeddings learned from log-bilinear regression (GloVe) and translation (CoVe) models, and (b) one on top of word encodings from a pre-trained deep bidirectional transformer (BERT). We include a domain adversarial training module when training for out-of-domain samples. Our experiments show that while BERT performs exceptionally well for in-domain samples, several runs of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> show that it is unstable for out-of-domain samples. The problem is mitigated tremendously by (1) combining BERT with a non-BERT encoder, and (2) using an RNN-based classifier on top of BERT. Our final <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> obtained second place with 77.78 % <a href="https://en.wikipedia.org/wiki/F-score">F-Score</a> on Subtask A (i.e. in-domain) and achieved an <a href="https://en.wikipedia.org/wiki/F-score">F-Score</a> of 79.59 % on Subtask B (i.e. out-of-domain), even without using any additional <a href="https://en.wikipedia.org/wiki/Data_(computing)">external data</a>.</abstract>
      <url hash="c9669a8f">S19-2220</url>
      <doi>10.18653/v1/S19-2220</doi>
      <bibkey>park-etal-2019-thisiscompetition</bibkey>
    </paper>
    <paper id="222">
      <title>Yimmon at SemEval-2019 Task 9 : Suggestion Mining with Hybrid Augmented Approaches<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Suggestion Mining with Hybrid Augmented Approaches</title>
      <author><first>Yimeng</first><last>Zhuang</last></author>
      <pages>1267–1271</pages>
      <abstract>Suggestion mining task aims to extract tips, <a href="https://en.wikipedia.org/wiki/Advice_(opinion)">advice</a>, and recommendations from <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured text</a>. The task includes many challenges, such as <a href="https://en.wikipedia.org/wiki/Social_class">class imbalance</a>, <a href="https://en.wikipedia.org/wiki/Literal_and_figurative_language">figurative expressions</a>, <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context dependency</a>, and long and complex sentences. This paper gives a detailed system description of our submission in SemEval 2019 Task 9 Subtask A. We transfer Self-Attention Network (SAN), a successful model in machine reading comprehension field, into this task. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> concentrates on modeling long-term dependency which is indispensable to parse long and complex sentences. Besides, we also adopt techniques, such as contextualized embedding, <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a>, and auxiliary loss, to augment the <a href="https://en.wikipedia.org/wiki/System">system</a>. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves a performance of F1=76.3, and rank 4th among 34 participating systems. Further ablation study shows that the techniques used in our <a href="https://en.wikipedia.org/wiki/System">system</a> are beneficial to the performance.</abstract>
      <url hash="613c2b7e">S19-2222</url>
      <doi>10.18653/v1/S19-2222</doi>
      <bibkey>zhuang-2019-yimmon</bibkey>
    </paper>
    <paper id="223">
      <title>YNU_DYX at SemEval-2019 Task 9 : A Stacked BiLSTM for Suggestion Mining Classification<fixed-case>YNU</fixed-case>_<fixed-case>DYX</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: A Stacked <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> for Suggestion Mining Classification</title>
      <author><first>Yunxia</first><last>Ding</last></author>
      <author><first>Xiaobing</first><last>Zhou</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>1272–1276</pages>
      <abstract>In this paper we describe a deep-learning system that competed as SemEval 2019 Task 9-SubTask A : Suggestion Mining from Online Reviews and Forums. We use Word2Vec to learn the distributed representations from sentences. This system is composed of a Stacked Bidirectional Long-Short Memory Network (SBiLSTM) for enriching word representations before and after the sequence relationship with context. We perform an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> to improve the effectiveness of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Our official submission results achieve an F1-score 0.5659.</abstract>
      <url hash="a808aaff">S19-2223</url>
      <doi>10.18653/v1/S19-2223</doi>
      <bibkey>ding-etal-2019-ynu-dyx</bibkey>
    </paper>
    <paper id="225">
      <title>Zoho at SemEval-2019 Task 9 : Semi-supervised Domain Adaptation using Tri-training for Suggestion Mining<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 9: Semi-supervised Domain Adaptation using Tri-training for Suggestion Mining</title>
      <author><first>Sai</first><last>Prasanna</last></author>
      <author><first>Sri Ananda</first><last>Seelan</last></author>
      <pages>1282–1286</pages>
      <abstract>This paper describes our submission for the SemEval-2019 Suggestion Mining task. A simple Convolutional Neural Network (CNN) classifier with contextual word representations from a pre-trained language model was used for sentence classification. The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is trained using tri-training, a semi-supervised bootstrapping mechanism for labelling unseen data. Tri-training proved to be an effective technique to accommodate domain shift for cross-domain suggestion mining (Subtask B) where there is no hand labelled training data. For in-domain evaluation (Subtask A), we use the same technique to augment the training set. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks thirteenth in Subtask A with an F1-score of 68.07 and third in Subtask B with an F1-score of 81.94.</abstract>
      <url hash="1b986c2e">S19-2225</url>
      <attachment type="software" hash="af26406c">S19-2225.Software.zip</attachment>
      <attachment type="poster" hash="2c18a839">S19-2225.Poster.pdf</attachment>
      <doi>10.18653/v1/S19-2225</doi>
      <bibkey>prasanna-seelan-2019-zoho</bibkey>
    </paper>
    <paper id="231">
      <title>UniMelb at SemEval-2019 Task 12 : Multi-model combination for toponym resolution<fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>elb at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 12: Multi-model combination for toponym resolution</title>
      <author><first>Haonan</first><last>Li</last></author>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Martin</first><last>Tomko</last></author>
      <author><first>Maria</first><last>Vasardani</last></author>
      <pages>1313–1318</pages>
      <abstract>This paper describes our submission to SemEval-2019 Task 12 on toponym resolution over <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific articles</a>. We train separate NER models for toponym detection over text extracted from tables vs. text from the body of the paper, and train another auxiliary model to eliminate misdetected toponyms. For toponym disambiguation, we use an SVM classifier with hand-engineered features. The best setting achieved a strict micro-F1 score of 80.92 % and overlap micro-F1 score of 86.88 % in the toponym detection subtask, ranking 2nd out of 8 teams on F1 score. For toponym disambiguation and end-to-end resolution, we officially ranked 2nd and 3rd, respectively.</abstract>
      <url hash="0a5963db">S19-2231</url>
      <doi>10.18653/v1/S19-2231</doi>
      <bibkey>li-etal-2019-unimelb</bibkey>
    </paper>
    <paper id="232">
      <title>University of Arizona at SemEval-2019 Task 12 : Deep-Affix Named Entity Recognition of Geolocation Entities<fixed-case>U</fixed-case>niversity of <fixed-case>A</fixed-case>rizona at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2019 Task 12: Deep-Affix Named Entity Recognition of Geolocation Entities</title>
      <author><first>Vikas</first><last>Yadav</last></author>
      <author><first>Egoitz</first><last>Laparra</last></author>
      <author><first>Ti-Tai</first><last>Wang</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>1319–1323</pages>
      <abstract>We present the Named Entity Recognition (NER) and disambiguation model used by the University of Arizona team (UArizona) for the SemEval 2019 task 12. We achieved fourth place on tasks 1 and 3. We implemented a deep-affix based LSTM-CRF NER model for task 1, which utilizes only character, word, pre- fix and suffix information for the identification of geolocation entities. Despite using just the training data provided by task organizers and not using any <a href="https://en.wikipedia.org/wiki/Lexicon">lexicon features</a>, we achieved 78.85 % strict micro F-score on task 1. We used the unsupervised population heuristics for task 3 and achieved 52.99 % strict micro-F1 score in this task.</abstract>
      <url hash="e63fb91c">S19-2232</url>
      <doi>10.18653/v1/S19-2232</doi>
      <bibkey>yadav-etal-2019-university</bibkey>
    </paper>
  </volume>
</collection>