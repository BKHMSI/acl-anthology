<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.nlp4prog">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Natural Language Processing for Programming (NLP4Prog 2021)</booktitle>
      <editor><first>Royi</first><last>Lachmy</last></editor>
      <editor><first>Ziyu</first><last>Yao</last></editor>
      <editor><first>Greg</first><last>Durrett</last></editor>
      <editor><first>Milos</first><last>Gligoric</last></editor>
      <editor><first>Junyi Jessy</first><last>Li</last></editor>
      <editor><first>Ray</first><last>Mooney</last></editor>
      <editor><first>Graham</first><last>Neubig</last></editor>
      <editor><first>Yu</first><last>Su</last></editor>
      <editor><first>Huan</first><last>Sun</last></editor>
      <editor><first>Reut</first><last>Tsarfaty</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="f287d5ec">2021.nlp4prog-1</url>
    </meta>
    <frontmatter>
      <url hash="a66f82be">2021.nlp4prog-1.0</url>
      <bibkey>nlp4prog-2021-natural</bibkey>
    </frontmatter>
    <paper id="2">
      <title>ConTest : A Unit Test Completion Benchmark featuring Context<fixed-case>C</fixed-case>on<fixed-case>T</fixed-case>est: A Unit Test Completion Benchmark featuring Context</title>
      <author><first>Johannes</first><last>Villmow</last></author>
      <author><first>Jonas</first><last>Depoix</last></author>
      <author><first>Adrian</first><last>Ulges</last></author>
      <pages>17–25</pages>
      <abstract>We introduce CONTEST, a <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark</a> for NLP-based unit test completion, the task of predicting a test’s assert statements given its setup and focal method, i.e. the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> to be tested. ConTest is large-scale (with 365k datapoints). Besides the test code and tested code, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> also features context code called by either. We found <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> to be crucial for accurately predicting assertions. We also introduce baselines based on transformer encoder-decoders, and study the effects of including <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a> and <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>. Overall, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> achieve a BLEU score of 38.2, while only generating unparsable code in 1.92 % of cases.</abstract>
      <url hash="0bb865de">2021.nlp4prog-1.2</url>
      <doi>10.18653/v1/2021.nlp4prog-1.2</doi>
      <bibkey>villmow-etal-2021-contest</bibkey>
    </paper>
    <paper id="3">
      <title>CommitBERT : Commit Message Generation Using Pre-Trained Programming Language Model<fixed-case>C</fixed-case>ommit<fixed-case>BERT</fixed-case>: Commit Message Generation Using Pre-Trained Programming Language Model</title>
      <author><first>Tae Hwan</first><last>Jung</last></author>
      <pages>26–33</pages>
      <abstract>Commit message is a document that summarizes source code changes in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>. A good commit message clearly shows the source code changes, so this enhances collaboration between developers. Therefore, our work is to develop a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> that automatically writes the commit message. To this end, we release 345 K datasets consisting of code modification and commit messages in six programming languages (Python, PHP, <a href="https://en.wikipedia.org/wiki/Go_(programming_language)">Go</a>, <a href="https://en.wikipedia.org/wiki/Java_(programming_language)">Java</a>, <a href="https://en.wikipedia.org/wiki/JavaScript">JavaScript</a>, and Ruby). Similar to the neural machine translation (NMT) model, using our dataset, we feed the code modification to the encoder input and the commit message to the decoder input and measure the result of the generated commit message with BLEU-4. Also, we propose the following two training methods to improve the result of generating the commit message : (1) A method of preprocessing the input to feed the code modification to the encoder input. (2) A method that uses an initial weight suitable for the code domain to reduce the gap in contextual representation between programming language (PL) and natural language (NL).</abstract>
      <url hash="dd9303f1">2021.nlp4prog-1.3</url>
      <doi>10.18653/v1/2021.nlp4prog-1.3</doi>
      <bibkey>jung-2021-commitbert</bibkey>
      <pwccode url="https://github.com/graykode/commit-autosuggestions" additional="false">graykode/commit-autosuggestions</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/codesearchnet">CodeSearchNet</pwcdataset>
    </paper>
    <paper id="4">
      <title>Time-Efficient Code Completion Model for the <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R Programming Language</a><fixed-case>R</fixed-case> Programming Language</title>
      <author><first>Artem</first><last>Popov</last></author>
      <author><first>Dmitrii</first><last>Orekhov</last></author>
      <author><first>Denis</first><last>Litvinov</last></author>
      <author><first>Nikolay</first><last>Korolev</last></author>
      <author><first>Gleb</first><last>Morgachev</last></author>
      <pages>34–39</pages>
      <abstract>In this paper we present a deep learning code completion model for the <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R language</a>. We introduce several <a href="https://en.wikipedia.org/wiki/Software_development_process">techniques</a> to utilize <a href="https://en.wikipedia.org/wiki/Language_model">language modeling based architecture</a> in the <a href="https://en.wikipedia.org/wiki/Autocomplete">code completion task</a>. With these techniques, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> requires low resources, but still achieves high quality. We also present an evaluation dataset for the <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R language completion task</a>. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> contains multiple autocompletion usage contexts that provides robust validation results. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is publicly available.</abstract>
      <url hash="319fba13">2021.nlp4prog-1.4</url>
      <doi>10.18653/v1/2021.nlp4prog-1.4</doi>
      <bibkey>popov-etal-2021-time</bibkey>
      <pwccode url="https://github.com/arti32lehtonen/rcompletion_evaluation_dataset" additional="false">arti32lehtonen/rcompletion_evaluation_dataset</pwccode>
    </paper>
    <paper id="7">
      <title>Shellcode_IA32 : A Dataset for Automatic Shellcode Generation<fixed-case>S</fixed-case>hellcode_<fixed-case>IA</fixed-case>32: A Dataset for Automatic Shellcode Generation</title>
      <author><first>Pietro</first><last>Liguori</last></author>
      <author><first>Erfan</first><last>Al-Hossami</last></author>
      <author><first>Domenico</first><last>Cotroneo</last></author>
      <author><first>Roberto</first><last>Natella</last></author>
      <author><first>Bojan</first><last>Cukic</last></author>
      <author><first>Samira</first><last>Shaikh</last></author>
      <pages>58–64</pages>
      <abstract>We take the first step to address the task of <a href="https://en.wikipedia.org/wiki/Shellcode">automatically generating shellcodes</a>, i.e., small pieces of code used as a payload in the exploitation of a <a href="https://en.wikipedia.org/wiki/Vulnerability_(computing)">software vulnerability</a>, starting from <a href="https://en.wikipedia.org/wiki/Comment_(computer_programming)">natural language comments</a>. We assemble and release a novel dataset (Shellcode_IA32), consisting of challenging but common assembly instructions with their natural language descriptions. We experiment with standard methods in neural machine translation (NMT) to establish baseline performance levels on this task.</abstract>
      <url hash="6895273b">2021.nlp4prog-1.7</url>
      <doi>10.18653/v1/2021.nlp4prog-1.7</doi>
      <bibkey>liguori-etal-2021-shellcode</bibkey>
      <pwccode url="https://github.com/dessertlab/Shellcode_IA32" additional="false">dessertlab/Shellcode_IA32</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/shellcode-ia32">Shellcode_IA32</pwcdataset>
    </paper>
    <paper id="8">
      <title>Reading StackOverflow Encourages Cheating : Adding Question Text Improves Extractive Code Generation<fixed-case>S</fixed-case>tack<fixed-case>O</fixed-case>verflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation</title>
      <author><first>Gabriel</first><last>Orlanski</last></author>
      <author><first>Alex</first><last>Gittens</last></author>
      <pages>65–76</pages>
      <abstract>Answering a programming question with only its title is difficult as salient contextual information is left out. To address this, we present a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of over 40,000 StackOverflow question texts to be used in conjunction with the corresponding intents from the CoNaLa dataset (Yin et al., 2018). Using both the <a href="https://en.wikipedia.org/wiki/Intention">intent</a> and the question body, we use <a href="https://en.wikipedia.org/wiki/Bay_Area_Rapid_Transit">BART</a> to establish a baseline BLEU score of 34.35 for this new task. We then find further improvements of 2.8 % by combining the mined CoNaLa data with the labeled data to achieve a 35.32 BLEU score. We then evaluate the prior state-of-the-art CoNaLa models with this additional <a href="https://en.wikipedia.org/wiki/Data">data</a>. We find that our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> of using the body and mined data beats that of the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> by a 71.96 % BLEU score. Finally, we perform ablations that prove that BART is an unsupervised multimodal learner and examine its extractive behavior.</abstract>
      <url hash="959970d3">2021.nlp4prog-1.8</url>
      <doi>10.18653/v1/2021.nlp4prog-1.8</doi>
      <bibkey>orlanski-gittens-2021-reading</bibkey>
      <pwccode url="https://github.com/gabeorlanski/stackoverflow-encourages-cheating" additional="false">gabeorlanski/stackoverflow-encourages-cheating</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conala-ext">CoNaLa-Ext</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conala">CoNaLa</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/codesearchnet">CodeSearchNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/juice">JuICe</pwcdataset>
    </paper>
    <paper id="9">
      <title>Text-to-SQL in the Wild : A Naturally-Occurring Dataset Based on Stack Exchange Data<fixed-case>SQL</fixed-case> in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data</title>
      <author><first>Moshe</first><last>Hazoom</last></author>
      <author><first>Vibhor</first><last>Malik</last></author>
      <author><first>Ben</first><last>Bogin</last></author>
      <pages>77–87</pages>
      <abstract>Most available semantic parsing datasets, comprising of pairs of natural utterances and logical forms, were collected solely for the purpose of training and evaluation of <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding systems</a>. As a result, they do not contain any of the richness and variety of natural-occurring utterances, where humans ask about data they need or are curious about. In this work, we release <a href="https://en.wikipedia.org/wiki/Stack_Exchange">SEDE</a>, a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with 12,023 pairs of utterances and <a href="https://en.wikipedia.org/wiki/SQL">SQL queries</a> collected from real usage on the <a href="https://en.wikipedia.org/wiki/Stack_Exchange">Stack Exchange website</a>. We show that these pairs contain a variety of real-world challenges which were rarely reflected so far in any other semantic parsing dataset, propose an evaluation metric based on comparison of partial query clauses that is more suitable for real-world queries, and conduct experiments with strong baselines, showing a large gap between the performance on SEDE compared to other common datasets.</abstract>
      <url hash="54167235">2021.nlp4prog-1.9</url>
      <doi>10.18653/v1/2021.nlp4prog-1.9</doi>
      <bibkey>hazoom-etal-2021-text</bibkey>
      <pwccode url="https://github.com/hirupert/sede" additional="false">hirupert/sede</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sede">SEDE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/atis">ATIS</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/spider-1">SPIDER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="10">
      <title>Bag-of-Words Baselines for Semantic Code Search</title>
      <author><first>Xinyu</first><last>Zhang</last></author>
      <author><first>Ji</first><last>Xin</last></author>
      <author><first>Andrew</first><last>Yates</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <pages>88–94</pages>
      <abstract>The task of semantic code search is to retrieve <a href="https://en.wikipedia.org/wiki/Snippet_(programming)">code snippets</a> from a <a href="https://en.wikipedia.org/wiki/Text_corpus">source code corpus</a> based on an information need expressed in <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. It is a common assumption that traditional bag-of-words IR methods are poorly suited for semantic code search : our work empirically investigates this assumption. Specifically, we examine the effectiveness of two traditional IR methods, namely <a href="https://en.wikipedia.org/wiki/BM25">BM25</a> and <a href="https://en.wikipedia.org/wiki/RM3">RM3</a>, on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets. We find that the two keyword-based methods outperform several pre-BERT neural models. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract>
      <url hash="3f972535">2021.nlp4prog-1.10</url>
      <doi>10.18653/v1/2021.nlp4prog-1.10</doi>
      <bibkey>zhang-etal-2021-bag</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/codesearchnet">CodeSearchNet</pwcdataset>
    <title_ar>حقيبة من الكلمات الأساسية للبحث عن الشفرة الدلالية</title_ar>
      <title_fr>Lignes de base de sacs de mots pour la recherche de code sémantique</title_fr>
      <title_pt>Linhas de base do saco de palavras para pesquisa de código semântico</title_pt>
      <title_es>Líneas base de bolsa de palabras para la búsqueda de código semántico</title_es>
      <title_ja>セマンティックコード検索のための言葉のバッグベースライン</title_ja>
      <title_ru>Базовые линии Bag-of-Sords для поиска семантического кода</title_ru>
      <title_zh>以语义代码索词袋基线</title_zh>
      <title_hi>सिमेंटिक कोड खोज के लिए बैग-ऑफ-वर्ड्स बेसलाइन</title_hi>
      <title_ga>Bunlínte Bag-of-Ford le haghaidh Cuardach Cód Séimeantach</title_ga>
      <title_el>Γραμμές βάσης λέξεων για την αναζήτηση σημασιολογικού κώδικα</title_el>
      <title_hu>A szemantikus kód keresésének alapjai</title_hu>
      <title_kk>Semantic код іздеу үшін сөздер негізгі сызықтары</title_kk>
      <title_it>Base Bag-of-Words per la ricerca di codice semantico</title_it>
      <title_lt>Semantinio kodo paieškos žodžių maišelio bazės</title_lt>
      <title_mk>Базични линии за семантично пребарување на кодот</title_mk>
      <title_ms>Baris asas beg-perkataan untuk Carian Kod Semantik</title_ms>
      <title_mt>Linji bażi tal-borża tal-kliem għat-tiftix tal-Kodiċi Semantiku</title_mt>
      <title_ml>സെമാന്റിക് കോഡിനുള്ള വാക്കുകളുടെ അടിസ്ഥാനങ്ങള്‍</title_ml>
      <title_mn>Semantic Code Search</title_mn>
      <title_pl>Podstawy worka słów dla wyszukiwania kodu semantycznego</title_pl>
      <title_ro>Pungă de cuvinte de referință pentru căutarea codului semantic</title_ro>
      <title_si>Name</title_si>
      <title_ka>სიტყვების ბაზი ხაზები სემანტიკური კოდის ძებნა</title_ka>
      <title_no>Ordbaselinjer for semiantisk kodsøk</title_no>
      <title_so>Qoraalka codsiga Semantic</title_so>
      <title_sv>Baslinjer för ordsäck för semantisk kod Sök</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>سیمنٹی کوڈ تلاش کے لئے بات-of-Words Baselines</title_ur>
      <title_sr>Prazne linije za semantički pretragu kodova</title_sr>
      <title_uz>Name</title_uz>
      <title_vi>Tìm kiếm mật mã trung thành</title_vi>
      <title_hr>Pravne linije za pretragu semantičkog koda</title_hr>
      <title_bg>Базови линии за търсене на семантичен код</title_bg>
      <title_da>Bag-of-Words basislinjer for semantisk kodesøgning</title_da>
      <title_nl>Basislijnen voor semantische code zoeken</title_nl>
      <title_de>Wortbeutel-Baselines für die Suche nach semantischem Code</title_de>
      <title_ko>의미 코드 검색에 사용되는 단어 패키지 기선</title_ko>
      <title_id>Garis dasar tas-kata untuk Pencarian Kode Semantik</title_id>
      <title_sw>Maelezo ya maneno kwa ajili ya kutafuta Sheria ya Semantic</title_sw>
      <title_fa>خطوط بنیادی کلمات برای جستجوی کد سیمانتیک</title_fa>
      <title_sq>Bag-of-Words Baselines for Semantic Code Search</title_sq>
      <title_hy>Comment</title_hy>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_bn>Name</title_bn>
      <title_tr>Semantik Kod Arama üçin sözleriň esasy hatlary</title_tr>
      <title_af>Name</title_af>
      <title_cs>Sáček slov Základní linie pro vyhledávání sémantického kódu</title_cs>
      <title_az>Semantik Kod Araması</title_az>
      <title_ca>Llinies de base de la borsa de paraules per a la búsqueda de codi semàntic</title_ca>
      <title_et>Semantilise koodi otsingu sõnadekott</title_et>
      <title_fi>Laukku-of-Words Baselines for Semantic Code Search</title_fi>
      <title_bs>Prtljažne linije za pretragu semantičkog koda</title_bs>
      <title_jv>Vag-of-words</title_jv>
      <title_ha>Bag-of-Words Baselines for Semantic Code Search</title_ha>
      <title_sk>Izhodišča vrečke besed za iskanje semantičnih kod</title_sk>
      <title_bo>སྔོན་འཛུགས་ཀྱི་གསལ་འཚོལ་བཤེར་ལ་བརྗོད་ཐོག་གི་གནད་དོན་གཞི་རྟེན་འབྲི་བ</title_bo>
      <title_he>קווי התיק של מילים לחפש קוד סמנטי</title_he>
      <abstract_ar>تتمثل مهمة البحث عن الشفرة الدلالية في استرداد مقتطفات التعليمات البرمجية من مجموعة التعليمات البرمجية المصدر بناءً على الحاجة إلى المعلومات التي يتم التعبير عنها بلغة طبيعية. لطالما اعتبرت الفجوة الدلالية بين اللغة الطبيعية ولغات البرمجة واحدة من أهم العقبات التي تحول دون فعالية طرق استرجاع المعلومات (IR) القائمة على الكلمات الرئيسية. من الافتراض الشائع أن أساليب IR "التقليدية" لأكياس الكلمات ليست مناسبة تمامًا للبحث عن الكود الدلالي: يقوم عملنا بالتحقيق في هذا الافتراض تجريبيًا. على وجه التحديد ، نحن ندرس فعالية طريقتين تقليديتين للأشعة تحت الحمراء ، وهما BM25 و RM3 ، على CodeSearchNet Corpus ، والتي تتكون من استعلامات لغة طبيعية مقترنة بمقتطفات التعليمات البرمجية ذات الصلة. نجد أن الطريقتين المستندة إلى الكلمات الرئيسية تتفوقان على العديد من النماذج العصبية قبل BERT. نقوم أيضًا بمقارنة العديد من استراتيجيات المعالجة المسبقة للبيانات الخاصة بالشفرة ووجدنا أن الترميز المتخصص يحسن الفعالية.</abstract_ar>
      <abstract_fr>La tâche de la recherche de code sémantique est de récupérer des extraits de code à partir d'un corpus de code source en fonction d'un besoin d'information exprimé en langage naturel. L'écart sémantique entre le langage naturel et les langages de programmation a longtemps été considéré comme l'un des obstacles les plus importants à l'efficacité des méthodes de récupération d'informations basées sur des mots clés (IR). Il est courant de penser que les méthodes IR « traditionnelles » de sacs de mots sont mal adaptées à la recherche de code sémantique : notre travail étudie empiriquement cette hypothèse. Plus précisément, nous examinons l'efficacité de deux méthodes IR traditionnelles, à savoir BM25 et RM3, sur le Corpus CodeSearchNet, qui consiste en des requêtes en langage naturel associées à des extraits de code pertinents. Nous trouvons que les deux méthodes basées sur des mots clés surpassent plusieurs modèles neuronaux pré-BERT. Nous comparons également plusieurs stratégies de prétraitement de données spécifiques au code et constatons que la tokenisation spécialisée améliore l'efficacité.</abstract_fr>
      <abstract_pt>A tarefa da pesquisa de código semântico é recuperar trechos de código de um corpus de código-fonte com base em uma necessidade de informação expressa em linguagem natural. A lacuna semântica entre linguagem natural e linguagens de programação tem sido considerada por muito tempo como um dos obstáculos mais significativos para a eficácia dos métodos de recuperação de informações (IR) baseados em palavras-chave. É uma suposição comum que os métodos de RI “tradicionais” de saco de palavras são pouco adequados para busca de código semântico: nosso trabalho investiga empiricamente essa suposição. Especificamente, examinamos a eficácia de dois métodos tradicionais de RI, a saber, BM25 e RM3, no CodeSearchNet Corpus, que consiste em consultas em linguagem natural emparelhadas com trechos de código relevantes. Descobrimos que os dois métodos baseados em palavras-chave superam vários modelos neurais pré-BERT. Também comparamos várias estratégias de pré-processamento de dados específicos de código e descobrimos que a tokenização especializada melhora a eficácia.</abstract_pt>
      <abstract_es>La tarea de la búsqueda semántica de código es recuperar fragmentos de código de un corpus de código fuente basándose en una necesidad de información expresada en lenguaje natural. La brecha semántica entre el lenguaje natural y los lenguajes de programación se ha considerado durante mucho tiempo como uno de los obstáculos más importantes para la eficacia de los métodos de recuperación de información (IR) basados en palabras clave. Es una suposición común que los métodos «tradicionales» de IR de bolsa de palabras no son adecuados para la búsqueda de código semántico: nuestro trabajo investiga empíricamente esta suposición. Específicamente, examinamos la eficacia de dos métodos de IR tradicionales, a saber, BM25 y RM3, en el Corpus CodeSearchNet, que consiste en consultas de lenguaje natural combinadas con fragmentos de código relevantes. Encontramos que los dos métodos basados en palabras clave superan a varios modelos neuronales anteriores a BERT. También comparamos varias estrategias de preprocesamiento de datos de código específico y descubrimos que la tokenización especializada mejora la eficacia.</abstract_es>
      <abstract_zh>语义代码搜索者,以自然语言言求源代码语料库索代码片段。 久之,自然语言、编程语言之间语义相去直以为关键字信息检索(IR)法有效性之大障也。 常设者,古法也词袋IR法非其宜语义代码搜之:吾事究之。 具体来说于CodeSearchNet语料库上究二旧IR法(即BM25、RM3)之有效性,当语料库自然语言询代码片段配对成。 二者关键字优于前BERT神经。 又校数特定于代码之数预处理策,见专记可提高效率。</abstract_zh>
      <abstract_ja>セマンティックコード検索のタスクは、自然言語で表現された情報ニーズに基づいてソースコードコーパスからコードスニペットを取得することです。自然言語とプログラミング言語との間の意味的ギャップは、キーワードベースの情報検索（ IR ）方法の有効性に対する最も重大な障害の1つと長い間見なされてきた。「従来の」言葉のIR方法がセマンティックコード検索に適していないというのが一般的な仮定です。私たちの研究はこの仮定を実証的に調査します。具体的には、関連するコードスニペットとペアリングされた自然言語クエリで構成されるCodeSearchNet Corpus上の2つの従来のIR方法、すなわちBM 25とRM 3の有効性を検討します。2つのキーワードベースの方法は、いくつかのBERT前のニューラルモデルよりも優れていることがわかりました。また、いくつかのコード固有のデータ前処理戦略を比較すると、特殊なトークン化が有効性を向上させることがわかります。</abstract_ja>
      <abstract_hi>शब्दार्थ कोड खोज का कार्य प्राकृतिक भाषा में व्यक्त की गई जानकारी की आवश्यकता के आधार पर स्रोत कोड कॉर्पस से कोड स्निपेट को पुनः प्राप्त करना है। प्राकृतिक भाषा और प्रोग्रामिंग भाषाओं के बीच शब्दार्थ अंतर को लंबे समय से कीवर्ड-आधारित सूचना पुनर्प्राप्ति (आईआर) विधियों की प्रभावशीलता के लिए सबसे महत्वपूर्ण बाधाओं में से एक माना जाता है। यह एक आम धारणा है कि "पारंपरिक" बैग-ऑफ-वर्ड्स आईआर विधियां शब्दार्थ कोड खोज के लिए खराब रूप से अनुकूल हैं: हमारा काम अनुभवजन्य रूप से इस धारणा की जांच करता है। विशेष रूप से, हम CodeSearchNet Corpus पर दो पारंपरिक IR विधियों, अर्थात् BM25 और RM3 की प्रभावशीलता की जांच करते हैं, जिसमें प्रासंगिक कोड स्निपेट के साथ युग्मित प्राकृतिक भाषा क्वेरी शामिल हैं। हम पाते हैं कि दो कीवर्ड-आधारित तरीके कई पूर्व-BERT तंत्रिका मॉडल से आगे निकल जाते हैं। हम कई कोड-विशिष्ट डेटा पूर्व-प्रसंस्करण रणनीतियों की भी तुलना करते हैं और पाते हैं कि विशेष टोकनीकरण प्रभावशीलता में सुधार करता है।</abstract_hi>
      <abstract_ru>Задача поиска семантического кода заключается в извлечении фрагментов кода из корпуса исходного кода на основе информационной потребности, выраженной на естественном языке. Семантический разрыв между естественным языком и языками программирования уже давно рассматривается как одно из наиболее существенных препятствий для эффективности методов поиска информации по ключевым словам (IR). Общепринято предположение, что «традиционные» методы ИК-мешков плохо подходят для семантического поиска кода: наша работа эмпирически исследует это предположение. В частности, мы изучаем эффективность двух традиционных методов ИК, а именно BM25 и RM3, на корпусе CodeSearchNet, который состоит из запросов на естественном языке в паре с соответствующими фрагментами кода. Мы обнаружили, что два метода, основанные на ключевых словах, превосходят несколько нейронных моделей до BERT. Мы также сравниваем несколько кодовых стратегий предварительной обработки данных и обнаруживаем, что специализированная токенизация повышает эффективность.</abstract_ru>
      <abstract_ga>Is é an tasc a bhaineann le cuardach cód séimeantach ná gearrthóga cód a aisghabháil ó chorpas cód foinse bunaithe ar riachtanas faisnéise a chuirtear in iúl i dteanga nádúrtha. Breathnaíodh le fada ar an mbearna shéimeantach idir teanga nádúrtha agus teangacha ríomhchlárúcháin mar cheann de na constaicí is suntasaí ar éifeachtacht modhanna aisghabhála faisnéise eochairfhocal-bhunaithe (IR). Is toimhde coitianta é nach bhfuil modhanna IR mála focal “traidisiúnta” oiriúnach go dona do chuardach cód shéimeantach: déanann ár gcuid oibre imscrúdú eimpíreach ar an mbonn tuisceana seo. Go sonrach, scrúdaímid éifeachtacht dhá mhodh IR thraidisiúnta, eadhon BM25 agus RM3, ar an CodeSearchNet Corpus, atá comhdhéanta d'fhiosrúcháin teanga nádúrtha atá péireáilte le gearrthóga cód ábhartha. Faighimid amach go sáraíonn an dá mhodh eochairfhocal-bhunaithe roinnt samhlacha néaracha réamh-BERT. Déanaimid comparáid freisin idir roinnt straitéisí réamhphróiseála sonraí a bhaineann go sonrach le cód agus faighimid go bhfeabhsaítear éifeachtúlacht sainchomharthaíochta.</abstract_ga>
      <abstract_ka>სიმენტიკური კოდის ძიება არის კოდის სნეპტების კოპორსდან მიღება ინფორმაციის საჭიროა, რომელიც ნაირადი ენაში გამოსახულებული ინფორმაცია. სიმენტიკური სიტყვის და პროგრამის ენების შორის განსხვავება ძალიან განმავლებული იყო, როგორც ერთი უფრო მნიშვნელოვანი განსხვავებაში გასაღების ინფორმაციის მიღება (IR) მეტოვების ეფექტიურობ ჩვენი სამუშაო მუშაობა იქნება, რომ სამუშაო სიტყვების შესაძლებლობისთვის, რომელიც IR სიტყვების შესაძლებლობისთვის ძალიან ძალიან მუშაობელია: ჩვენი სამუშაო ე განსაკუთრებულია, ჩვენ შევხედავთ ორი ტრადიციონალური IR მეტოვების ეფექტიურობა, რომელიც BM25 და RM3, CodeSearchNet კორპოსში, რომელიც შექმნის ნაირადი ენის კითხვების შესახებ, რომელიც შესახებ შესა ჩვენ აღმოჩნეთ, რომ ორი კლავიტური სიტყვების გარეშე მეტივები უფრო მეტი BERT ნეირალური მოდელების გარეშე. ჩვენ ასევე კოდის სპექტიფიკური მონაცემების პრესპროცესის სტრატიგიების შემდგენება და აღმოჩნეთ, რომ სპექციალური ტოკენიზაცია უფრო მეტი</abstract_ka>
      <abstract_hu>A szemantikus kódkeresés feladata a természetes nyelven kifejezett információigény alapján egy forráskód korpuszból történő lekérdezése. A természetes nyelv és a programozási nyelvek közötti szemantikai szakadékot már régóta a kulcsszóalapú információvisszakeresési (IR) módszerek hatékonyságának egyik legjelentősebb akadályának tekintik. Gyakori feltételezés, hogy a "hagyományos" szavazsákos IR módszerek nem alkalmasak a szemantikai kódkeresésre: munkánk empirikusan vizsgálja ezt a feltételezést. Konkrétan két hagyományos IR módszer, nevezetesen a BM25 és RM3 hatékonyságát vizsgáljuk meg a CodeSearchNet Corpus-on, amely természetes nyelvű lekérdezésekből áll és releváns kódrészletekből áll. Úgy találtuk, hogy a két kulcsszó alapú módszer több BERT előtti neurális modellt felülmúl. Számos kódspecifikus adatfeldolgozási stratégiát is összehasonlítunk, és úgy találjuk, hogy a speciális tokenizáció javítja a hatékonyságot.</abstract_hu>
      <abstract_el>Το καθήκον της αναζήτησης σημασιολογικού κώδικα είναι να ανακτήσει αποσπάσματα κώδικα από ένα σώμα πηγαίου κώδικα με βάση μια ανάγκη πληροφοριών που εκφράζεται σε φυσική γλώσσα. Το σημασιολογικό χάσμα μεταξύ της φυσικής γλώσσας και των γλωσσών προγραμματισμού θεωρείται εδώ και καιρό ένα από τα σημαντικότερα εμπόδια στην αποτελεσματικότητα των μεθόδων ανάκτησης πληροφοριών βάσει λέξεων-κλειδιών. Είναι κοινή υπόθεση ότι οι "παραδοσιακές" μέθοδοι υπέρυθρων λέξεων δεν είναι κατάλληλα για την αναζήτηση σημασιολογικού κώδικα: η εργασία μας διερευνά εμπειρικά αυτή την υπόθεση. Συγκεκριμένα, εξετάζουμε την αποτελεσματικότητα δύο παραδοσιακών μεθόδων IR, δηλαδή BM25 και RM3, στο Σώμα το οποίο αποτελείται από ερωτήματα φυσικής γλώσσας σε συνδυασμό με σχετικά αποσπάσματα κώδικα. Διαπιστώνουμε ότι οι δύο μέθοδοι που βασίζονται σε λέξεις-κλειδιά ξεπερνούν αρκετά νευρικά μοντέλα προ-BERT. Συγκρίνουμε επίσης διάφορες στρατηγικές προεπεξεργασίας δεδομένων ειδικά για κώδικα και διαπιστώνουμε ότι η εξειδικευμένη επισήμανση βελτιώνει την αποτελεσματικότητα.</abstract_el>
      <abstract_it>Il compito della ricerca semantica del codice è quello di recuperare frammenti di codice da un corpus di codice sorgente basato su un bisogno di informazioni espresso in linguaggio naturale. Il divario semantico tra linguaggio naturale e linguaggi di programmazione è stato a lungo considerato uno degli ostacoli più significativi all'efficacia dei metodi di recupero delle informazioni basati su parole chiave (IR). È un presupposto comune che i metodi IR "tradizionali" siano poco adatti alla ricerca semantica del codice: il nostro lavoro indaga empiricamente questa ipotesi. Nello specifico, esaminiamo l'efficacia di due metodi IR tradizionali, vale a dire BM25 e RM3, sul CodeSearchNet Corpus, che consiste in query in linguaggio naturale accoppiate con frammenti di codice pertinenti. Troviamo che i due metodi basati su parole chiave superano diversi modelli neurali pre-BERT. Confrontiamo anche diverse strategie di pre-elaborazione dei dati specifiche per codice e scopriamo che la tokenizzazione specializzata migliora l'efficacia.</abstract_it>
      <abstract_lt>Semantinio kodo paieškos užduotis – paimti kodo fragmentus iš išorinio kodo korpuso, pagrįstus natūralia kalba išreikštu informacijos poreikiu. Semantinis natūralios kalbos ir programavimo kalbų skirtumas ilgai buvo laikomas viena svarbiausių kliūčių pagrindiniais žodžiais pagrįstų informacijos gavimo (IR) metodų veiksmingumui. Bendra prielaida, kad "tradiciniai" žodžių maišelio IR metodai netinka semantiniam kodų paieškai: mūsų darbas empiriniu būdu tiria šią prielaidą. Konkrečiai, mes nagrinėjame dviejų tradicinių IR metodų, būtent BM25 ir RM3, veiksmingumą CodeSearchNet Corpus, kurį sudaro natūralūs kalbos klausimai, susiję su atitinkamomis kodo pjūklėmis. Matome, kad du pagrindiniais žodžiais pagrįsti metodai viršija keletą prieš BERT nervų modelių. Taip pat palyginame keletą kodui būdingų duomenų išankstinio apdorojimo strategijų ir nustatome, kad specializuota tokenizacija pagerina veiksmingumą.</abstract_lt>
      <abstract_mk>The task of semantic code search is to retrieve code snippets from a source code corpus based on an information need expressed in natural language.  Семантичката разлика помеѓу природниот јазик и програмирачките јазици долго време се смета за една од најзначајните пречки за ефикасноста на методите на преземање информации базирани на клучните зборови (IR). Тоа е заедничка претпоставка дека „традиционалните“ методи на ИР-вреќа се лошо соодветни за семантичко пребарување на кодот: нашата работа емпирички ја истражува оваа претпоставка. Специфично, ја испитуваме ефективноста на двата традиционални ИР методи, имено БМ25 и РМ3, на CodeSearchNet Corpus, кој се состои од природни јазички прашања парирани со релевантни кодови. Најдовме дека двата методи базирани на клучни зборови надминуваат неколку нервни модели пред BERT. Исто така, споредуваме неколку стратегии за преобработување на податоци специфични за код и откриваме дека специјализираната токенизација ја подобрува ефективноста.</abstract_mk>
      <abstract_ms>Tugas pencarian kod semantik adalah untuk mendapatkan snippets kod dari korpus kod sumber berdasarkan keperluan maklumat yang diungkapkan dalam bahasa semulajadi. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods.  Ia adalah asumsi umum bahawa kaedah IR 'tradisional' beg-of-words tidak sesuai untuk mencari kod semantik: kerja kita secara empirik menyelidiki asumsi ini. Secara khusus, kami memeriksa keefektivitas dua kaedah IR tradisional, iaitu BM25 dan RM3, pada CodeSearchNet Corpus, yang terdiri dari pertanyaan bahasa semulajadi berpasangan dengan snippets kod berkaitan. Kami mendapati bahawa dua kaedah berdasarkan kata kunci melebihi beberapa model saraf pre-BERT. Kami juga membandingkan beberapa strategi pra-proses data khusus kod dan mencari bahawa tokenization khusus meningkatkan keefektivitas.</abstract_ms>
      <abstract_ml>The task of semantic code search is to retrieve code snippets from a source code corpus based on an information need expressed in natural language.  സ്വാഭാവ ഭാഷകള്‍ക്കും പ്രോഗ്രാമിങ്ങ് ഭാഷകള്‍ക്കും തമ്മിലുള്ള സെമാന്റിക്ക് വേര്‍പ്പെട്ടിരിക്കുന്നു. കീവോര്‍ഡ് അടിസ്ഥാനമായ വിവരങ് സെമാന്റിക് കോഡ് തെരയുന്നതിനായി നമ്മുടെ പ്രവര്‍ത്തിക്കുന്നത് സാമ്പത്തികമായി അന്വേഷിക്കുന്നതാണെന്ന് കരുതുന്നു. പ്രത്യേകിച്ച്, നമ്മള്‍ രണ്ട് പാരമ്പര്യമായ ഐആര്‍ രീതികളുടെ പ്രകൃതിയെ പരിശോധിക്കുന്നു, BM25, RM3, കോഡ് തെരച്ചിലെ നെറ്റ് കോര്‍പ്സില്‍, സ്വാഭാവിക ഭാഷ ക നമുക്ക് കണ്ടെത്തുന്നത് കീവോര്‍ഡ് അടിസ്ഥാനത്തിലുള്ള രണ്ട് രീതികളാണെന്നാണ്. നമ്മള്‍ കുറച്ചു കോഡ് പ്രത്യേക വിവരങ്ങള്‍ക്കും മുമ്പ് പ്രവര്‍ത്തിപ്പിക്കുന്ന ക്രായേജ്യം തുല്യമാക്കുകയും പ്രത്</abstract_ml>
      <abstract_mt>Il-kompitu tat-tiftix semantiku tal-kodiċi huwa li jinkisbu snippets tal-kodiċi minn korpus tal-kodiċi tas-sors ibbażat fuq ħtieġa ta’ informazzjoni espressa f’lingwa naturali. Id-distakk semantiku bejn il-lingwa naturali u l-lingwi ta’ programmazzjoni ilu meqjus għal żmien twil bħala wieħed mill-aktar ostakli sinifikanti għall-effettività tal-metodi ta’ ġbir ta’ informazzjoni bbażata fuq il-kliem ewlieni (IR). Huwa suppożizzjoni komuni li l-metodi tal-IR “tradizzjonali” tal-borża tal-kliem mhumiex adattati sew għat-tiftix tal-kodiċi semantiku: ix-xogħol tagħna jinvestiga din is-suppożizzjoni b’mod empiriku. Specifically, we examine the effectiveness of two traditional IR methods, namely BM25 and RM3, on the CodeSearchNet Corpus, which consists of natural language queries paired with relevant code snippets.  Issibu li ż-żewġ metodi bbażati fuq kliem ewlieni jaqbżu diversi mudelli newrali ta’ qabel BERT. Aħna nqabblu wkoll diversi strateġiji speċifiċi għall-ipproċessar minn qabel tad-dejta skont il-kodiċi u nsibu li t-tokenizzazzjoni speċjalizzata ttejjeb l-effettività.</abstract_mt>
      <abstract_kk>Семантикалық код іздеудің тапсырмасы - көздегі код корпусынан кодты түрде белгіленген мәліметтің негізінде алу. Табиғи тіл мен бағдарлама тілдерінің арасындағы семантикалық қашықтығы ұзындық уақытта перне сөздерді негіздеген мәліметті (IR) алу әдістерінің ең маңызды бұл болып қалады. Бұл 'әдетті' сөздердің IR әдістері семантикалық код іздеу үшін жалпы сәйкес келеді деп ойлаймыз: жұмыс мұны империялық түрде зерттейді. Ескерілі, біз екі әдімгі IR әдістерінің эффектілігін, мысалы BM25 және RM3 кодтамасындағы CodeSearchNet корпусында тексереміз. Бұл табиғи тіл сұрауларының қатынасы бар. Біз екі кілттің сөздерді негіздеген әдістер бірнеше BERT невралдық моделдерінің өзгертілген. Біз сондай-ақ бірнеше код арқылы деректерді алдын- ала өңдеу стратегияларын салыстырып, специализиялық токенизацияның эффективнілігін жақсартады.</abstract_kk>
      <abstract_ro>Sarcina căutării de coduri semantice este de a recupera fragmente de cod dintr-un corpus de cod sursă bazate pe o nevoie de informații exprimată în limbaj natural. Diferența semantică dintre limbajul natural și limbajele de programare a fost considerată de mult timp ca fiind unul dintre cele mai semnificative obstacole în calea eficacității metodelor de recuperare a informațiilor bazate pe cuvinte cheie (IR). Este o presupunere comună că metodele IR "tradiționale" sunt slab potrivite pentru căutarea codurilor semantice: munca noastră investighează empiric această presupunere. Mai exact, examinăm eficacitatea a două metode IR tradiționale, și anume BM25 și RM3, pe CodeSearchNet Corpus, care constă în interogări în limbaj natural asociate cu fragmente de cod relevante. Considerăm că cele două metode bazate pe cuvinte cheie depășesc mai multe modele neurale pre-BERT. De asemenea, comparăm mai multe strategii de pre-procesare a datelor specifice codului și constatăm că tokenizarea specializată îmbunătățește eficiența.</abstract_ro>
      <abstract_pl>Zadaniem wyszukiwania kodu semantycznego jest pobieranie fragmentów kodu źródłowego z korpusu kodu źródłowego w oparciu o potrzebę informacyjną wyrażoną w języku naturalnym. Przepaść semantyczna między językiem naturalnym a językami programowania od dawna uważana jest za jedną z najważniejszych przeszkód w skuteczności metod odzyskiwania informacji opartych na słowach kluczowych (IR). Powszechne jest założenie, że "tradycyjne" metody IR źle nadają się do wyszukiwania kodu semantycznego: nasza praca bada to założenie empirycznie. W szczególności badamy skuteczność dwóch tradycyjnych metod IR, a mianowicie BM25 i RM3, w korpusie CodeSearchNet, który składa się z zapytań językowych naturalnych połączonych z odpowiednimi fragmentami kodu. Odkrywamy, że te dwie metody oparte na słowach kluczowych przewyższają kilka modeli neuronowych pre-BERT. Porównujemy również kilka strategii wstępnego przetwarzania danych specyficznych dla kodu i stwierdzamy, że specjalistyczna tokenizacja poprawia skuteczność.</abstract_pl>
      <abstract_mn>Земантик код хайлтын ажил бол байгалийн хэл дээр илэрхийлэгдсэн мэдээлэл дээр эх үүсвэрийн код корпус-аас код снип авах юм. Байгалийн хэл болон програмчлалын хэл хоорондын семантик ялгаа урт хугацаанд хамгийн чухал бэрхшээл гэсэн үг дээр суурилсан мэдээлэл авах (IR) аргын үр дүнтэй байдал гэж үздэг. Энэ бол уламжлалт үгний IR арга баримтууд шийдвэрлэхэд зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөвхөн зөв Ялангуяа бид хоёр уламжлалтай IR аргын үр дүнг, мөн BM25 болон RM3, CodeSearchNet Corpus дээр шалгаж үздэг. Энэ нь байгалийн хэлний кверитүүд нь холбоотой кодын хэлбэртэй холбоотой. Бид хоёр түлхүүр үг суурилсан арга нь хэдэн өмнө БЕРТ-ын мэдрэлийн загваруудыг хийдэг. Мөн бид хэдэн кодын тодорхойлолтой мэдээллийн өмнө үйлдвэрлэх стратегийг харьцуулж, мэргэжлийн тодорхойлолтын үр дүнг сайжруулдаг.</abstract_mn>
      <abstract_no>Oppgåva til semantisk kode- søk er å henta kode- snippet frå ei kjeldekode- korpus basert på ei informasjon som treng uttrykt i naturspråk. Det semantiske avstanden mellom naturspråk og programmeringspråk er for lang kalla til ein av dei viktigste hindringane til effektiviteten av nøkkelordbaserte informasjonshenting (IR) metodar. Det er ein vanleg antar at «tradisjonelle» søk av ord IR-metodar er slik passande for semantisk søk: arbeidet vårt er empirisk undersøkt denne antasen. Spesielt er vi undersøk effektiviteten av to tradisjonelle IR-metodar, dvs. BM25 og RM3, på kodeSearchNet-korpusen, som inneheld av naturspråksspørjingar som er saman med relevante kodsnippet. Vi finn at dei to nøkkelordbaserte metodane utfører fleire før BERT-neuralmodeller. Vi sammenliknar også fleire dataspesifikke forehandlingsstrategiar og finn at spesialiserte tokenisering forbetrar effektivitet.</abstract_no>
      <abstract_sv>Uppgiften med semantisk kodsökning är att hämta kodutdrag från en källkodskorpus baserat på ett informationsbehov uttryckt i naturligt språk. Den semantiska klyftan mellan naturligt språk och programmeringsspråk har länge ansetts vara ett av de viktigaste hindren för effektiviteten av nyckelordsbaserade informationsinsamlingsmetoder. Det är ett vanligt antagande att "traditionella" IR-metoder är dåligt lämpade för semantisk kodsökning: vårt arbete undersöker empiriskt detta antagande. Specifikt undersöker vi effektiviteten av två traditionella IR-metoder, nämligen BM25 och RM3, på CodeSearchNet Corpus, som består av naturliga språkfrågor ihopkopplade med relevanta kodutdrag. Vi finner att de två sökordsbaserade metoderna överträffar flera pre-BERT neurala modeller. Vi jämför också flera kodspecifika databehandlingsstrategier och finner att specialiserad tokenisering förbättrar effektiviteten.</abstract_sv>
      <abstract_so>Shaqada raadinta kooxda ah waa in laga soo celiyo kooxda codsiga ee asalka ah oo lagu saleynayo macluumaad looga baahan yahay luqada asalka ah. Dhaqdhaqaaqa afka asalka ah iyo afka programka waxaa wakhti dheer looga tiriyey mid ka mid ah dhibaatooyinka ugu muhiimsan qaababka helitaanka macluumaadka ee keyword-based (IR). Waa sida caadiga ah in qaababka caadiga ah oo ay u habboon yihiin hababka IR in loo baahdo raadinta kooxda ah: shaqadayadu si fiican ayuu u baaraandegaa malayaashan. Si gaar ah, waxaynu baaritaan waxqabadka labada qaababka caadiga ah ee IR, tusaale ahaan BM25 iyo RM3, taas oo ka mid ah koodeSearchNet Corpus, kaas oo ku qoran qoraalo luuqadaha dabiiciga ah oo la xiriira kooxda codsiga. We find that the two keyword-based methods outperform several pre-BERT neural models.  Sidoo kale waxaynu isbarbardhignaa qalabka kooban ee macluumaadka ka hor baaraandegista, waxaana ognahay in calaamad gaar ah uu hagaajiyo faa'iido.</abstract_so>
      <abstract_ta>பெமான்டிக் குறியீடு தேடும் செயல் இயல்பான மொழியில் தெரியும் தகவல் தேவை இயல்பான மொழி மற்றும் நிரல் மொழிகளுக்கிடையிலுள்ள பெரிய இடைவெளிப்பாடு விசைவார்த்தை தகவல் மீட்டெடுப்பு (IR) முறைமைகளின் விளைவுகள இது ஒரு பொது யூகமாக இருக்கிறது என்றால் 'மரபாரமான' சொற்களின் பாக்-வார்த்தைகள் ஐஆர் முறைமைகள் பொருத்தமாக தேடுவதற்கு பொருத்தமானது: எங குறிப்பிட்டு, நாம் இரண்டு மரபார்ந்த IR முறைமைகளின் விளைவை பரிசோதிக்க வேண்டும், பிஎம்25 மற்றும் RM3, கோடு தேடும் வலை கோர்புஸ் மீது, அது இயல்பான மொ இரண்டு விசைவார்த்தை அடிப்படையான முறைமை BERT புதிய மாதிரிகளை செயல்படுத்தும் என்பதை நாம் கண்டுபிடிக்கி We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract_ta>
      <abstract_sr>Zadatak semantičkog pretraživanja koda je da uzmete snippet koda iz izvornog koda korpusa na osnovu informacijske potrebe izražene na prirodnom jeziku. Semantički praznik između prirodnog jezika i jezika programiranja dugo se smatra jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" reèi IR metode loše odgovarajuće za pretragu semantičkih kodova: naš rad empirièki istražuje ovu pretpostavku. Posebno, istražujemo učinkovitost dva tradicionalna IR metoda, a to je BM25 i RM3, na kodesetarchNet korpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih sa relevantnim kodskim snippetama. Nalazimo da dve metode na temelju ključnih reči iznose nekoliko pre-BERT neuralnih modela. Takođe uspoređujemo nekoliko strategija predobrađivanja podataka specifičnih kodova i saznamo da specijalizovana tokenizacija poboljšava učinkovitost.</abstract_sr>
      <abstract_si>සෙමැන්ටික් කෝඩ් හොයාගැනීමේ වැඩය තමයි ප්‍රාකෘතික භාෂාවට ප්‍රතිකෘති තොරතුරු අවශ්‍ය භාෂාවක් නිසා  ස්වභාවික භාෂාවය සහ ව්‍යාප්තිකරණය භාෂාවය අතර සිමාන්තික අවශ්‍ය විදිහට පරීක්ෂා කරලා තියෙන්නේ ලොකු වචන පරීක්ෂණය සඳ ඒක සාමාන්‍ය විශ්වාස කරනවා කියලා 'පාරමාන්‍ය' බෑග් වචන IR විධානයක් සෙමාන්ටික කෝඩ් සොයාගන්න වැරදියි: අපේ වැඩේ සාමාන විශේෂයෙන්, අපි පරාධික IR පද්ධතිය දෙකක් ගැන පරීක්ෂණය කරනවා, මේකයි BM25 සහ RM3, CodeSearchNet Corpus වල, ඒක සම්බන්ධ කෝඩ ස්නිපෙට්ට් එක්ක සම්බ අපිට හොයාගන්න පුළුවන් වචන දෙකක් විදිහට පරිස්සම් BERT න්‍යූරල් මොඩේල් වලින් විදිහට ප්‍රතිකා අපි කෝඩ් විශේෂ දත්ත ප්‍රතික්‍රියාත්මක විදිහට සම්බන්ධ කරනවා ඒ වගේම විශේෂ විදිහට ප්‍රතික්‍රියා</abstract_si>
      <abstract_ur>سیمنٹی کوڈ تلاش کا کام یہ ہے کہ ایک سورس کوڈ کورپوس سے کوڈ اسنیپٹوں کو اٹھانے کی ضرورت طبیعی زبان میں واضح کیا جاتا ہے. طبیعی زبان اور پروگرامینگ زبانوں کے درمیان سیمنٹی فاصلہ بہت مدت تک ایک بڑی مضبوط روش کے ساتھ سمجھا گیا ہے کہ کلیدر کی بنیادی معلومات (IR) حاصل کرنے کے مطابقت کے مطابقت کے لئے۔ یہ ایک معمولی فرض ہے کہ 'سنتی' کلمات کے بغل IR طریقے سیمنٹی کوڈ تلاش کے لئے برابر مطابق ہیں: ہمارا کام اس فرض کو مطابق تحقیق کرتا ہے۔ ویسے ہی ہے کہ ہم دو سنتی IR طریقے کے مطابق تحقیق کرتے ہیں، یعنی BM25 اور RM3، CodeSearchNet Corpus پر، جو متعلق کیڈ سنپیٹوں کے ساتھ جوڑے ہوئے طبیعی زبان کے سوال میں سے ہے. ہم کو معلوم ہے کہ دو کلیدر بنیادی طریقے بہت سے پہلے BERT نیورال موڈل سے کام لیتے ہیں۔ ہم نے بہت سی کوڈ مخصوص ڈیٹا پرپروسیس کے استراتژیکوں کے مطابق مقایسہ کر دیا ہے اور دیکھتے ہیں کہ مخصوص ٹوکنیزی کے مطابق اثرات کو اثر دیتی ہے.</abstract_ur>
      <abstract_uz>Seymantik kodi qidirish vazifasi asl tilda koʻrsatilgan maʼlumot uchun manba kodi kodlash usulini aniqlash. Oddiy tillar va dastur qilish uchun semantik gap uzoqda, kalit asosida maʼlumot olish (IR) usullarining foydalanishiga eng muhim hammasidan deb hisoblanadi. Bu umumiy g'oyalar, oddiy "traditional" so'zlar sohasi IR usullari semantik kod qidirish uchun juda yetarli qiymatdir: bizning ishimiz bu g'oyatni qidirishda juda qidiriladi. Kodlash tarkibida biz ikkita traditional IR metodlarining effektligini tekshirishingiz mumkin, BM25 va RM3, kodSearchNet Korpusida, bu tilning asl soʻrovlari bilan bog'liq kodlash qoidalari bilan bog'liq qoʻllangan. Biz o'rganamiz, ikkita tugmalar asosida bir necha BERT neyrol modellarini bajaradi. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract_uz>
      <abstract_vi>Nhiệm vụ của việc tìm kiếm mật mã ngữ nghĩa là lấy đoạn mã từ một tập thể chứa mật mã gốc dựa trên nhu cầu thông tin được bày tỏ bằng ngôn ngữ tự nhiên. Khoảng cách ngữ pháp giữa ngôn ngữ tự nhiên và ngôn ngữ lập trình đã được coi là một trong những trở ngại quan trọng nhất với hiệu quả của các phương pháp truy tìm thông tin từ khoá (IR). Đó là một giả thuyết phổ biến rằng phương pháp IR'truyền thống'không phù hợp với việc tìm kiếm theo bí mật ngữ nghĩa. Công việc của chúng ta nghiên cứu cơ bản này. Chúng tôi đặc biệt nghiên cứu tính hiệu quả của hai phương pháp IR truyền thống, cả BM25 và RM3, trên the CodeinNet Corpus, which consists of natural language queries ghép với các đoạn mã liên quan. Chúng tôi thấy rằng hai phương pháp từ khoá đạt giới hạn sử dụng nhiều mô hình thần kinh trước BERT. Chúng tôi cũng so sánh các chiến lược xử lý dữ liệu đặc biệt và phát hiện ra hiệu quả cải tiến.</abstract_vi>
      <abstract_bg>Задачата на семантичното търсене на код е да извлича откъси от код от корпус на изходен код въз основа на информационна нужда, изразена на естествен език. Сентичната пропаст между естествения език и програмните езици отдавна се разглежда като една от най-значимите пречки за ефективността на методите за извличане на информация, базирани на ключови думи. Често срещано е предположението, че "традиционните" методи за ИР с торба с думи са слабо подходящи за семантично търсене на кодове: нашата работа емпирично изследва това предположение. По-конкретно, изследваме ефективността на два традиционни IR метода, а именно БМ25 и РМ3, върху Корпуса който се състои от заявки за естествен език, съчетани със съответните кодови фрагменти. Откриваме, че двата метода, базирани на ключови думи, превъзхождат няколко невронни модела преди BERT. Също така сравняваме няколко специфични за кода стратегии за предварителна обработка на данни и откриваме, че специализираната токенизация подобрява ефективността.</abstract_bg>
      <abstract_da>Opgaven med semantisk kodesøgning er at hente kodeudstryk fra et kildekodekorpus baseret på et informationsbehov udtrykt i naturligt sprog. Den semantiske kløft mellem naturligt sprog og programmeringssprog har længe været betragtet som en af de væsentligste hindringer for effektiviteten af søgeordsbaserede informationssøgningsmetoder (IR). Det er en almindelig antagelse, at 'traditionelle' taske-of-word IR metoder er dårligt egnede til semantisk kodesøgning: vores arbejde undersøger empirisk denne antagelse. Specielt undersøger vi effektiviteten af to traditionelle IR metoder, nemlig BM25 og RM3, på CodeSearchNet Corpus, som består af natursprogforespørgsler parret med relevante kodeudstryk. Vi finder ud af, at de to søgeordsbaserede metoder overgår flere pre-BERT neurale modeller. Vi sammenligner også flere kodespecifikke databehandlingsstrategier og finder ud af, at specialiseret tokenisering forbedrer effektiviteten.</abstract_da>
      <abstract_hr>Zadatak pretraživanja semantičkog koda je uzeti snippet koda iz izvornog koda korpusa na temelju informacijske potrebe izražene na prirodnom jeziku. Semantički razmak između prirodnog jezika i programiranja jezika dugo se smatra jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" vrećice riječi IR metode loše odgovarajuće za pretragu semantičkih kodova: naš rad empirički istražuje ovu pretpostavku. Posebno, pregledamo učinkovitost dvije tradicionalne IR metode, a to je BM25 i RM3, na KodeSearchNet Corpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih s relevantnim kodskim snippetama. Nalazimo da su dva metoda temeljena na ključnim riječima iznosila nekoliko pre-BERT neuralnih modela. Također uspoređujemo nekoliko strategija predobrađivanja podataka o specifičnim kodovima i otkrijemo da je specijalizovana tokenizacija poboljšala učinkovitost.</abstract_hr>
      <abstract_nl>De taak van semantische codezoeken is om codefragmenten uit een broncodecorpus op te halen op basis van een informatiebehoefte uitgedrukt in natuurlijke taal. De semantische kloof tussen natuurlijke taal en programmeertalen wordt al lang beschouwd als een van de belangrijkste obstakels voor de effectiviteit van keyword-based information retrieval (IR)-methoden. Het is een algemene veronderstelling dat 'traditionele' zak-met-woorden IR methoden slecht geschikt zijn voor semantische code zoeken: ons werk onderzoekt deze veronderstelling empirisch. In het bijzonder onderzoeken we de effectiviteit van twee traditionele IR-methoden, namelijk BM25 en RM3, op het CodeSearchNet Corpus, dat bestaat uit natuurlijke taalqueries gekoppeld aan relevante codefragmenten. We vinden dat de twee op trefwoorden gebaseerde methoden beter presteren dan verschillende pre-BERT neurale modellen. We vergelijken ook verschillende code-specifieke data pre-processing strategieën en vinden dat gespecialiseerde tokenizatie de effectiviteit verbetert.</abstract_nl>
      <abstract_de>Die Aufgabe der semantischen Codesuche besteht darin, Codeschnipsel aus einem Quellcodekorpus abzurufen, basierend auf einem Informationsbedarf, der in natürlicher Sprache ausgedrückt wird. Die semantische Lücke zwischen natürlicher Sprache und Programmiersprachen gilt seit langem als eines der größten Hindernisse für die Effektivität keyword-based information retrieval (IR)-Methoden. Es ist eine gängige Annahme, dass "traditionelle" Bag-of-Words-IR-Methoden für die semantische Codesuche schlecht geeignet sind: Unsere Arbeit untersucht diese Annahme empirisch. Konkret untersuchen wir die Wirksamkeit zweier traditioneller IR-Methoden, nämlich BM25 und RM3, auf dem CodeSearchNet Corpus, das aus natursprachlichen Abfragen gepaart mit relevanten Code-Snippets besteht. Wir stellen fest, dass die beiden keywordbasierten Methoden mehrere neuronale Modelle vor BERT übertreffen. Wir vergleichen auch mehrere code-spezifische Daten-Vorverarbeitungsstrategien und stellen fest, dass spezialisierte Tokenisierung die Effektivität verbessert.</abstract_de>
      <abstract_id>Tugas pencarian kode semantis adalah untuk mendapatkan snippets kode dari kode sumber corpus berdasarkan kebutuhan informasi yang diungkapkan dalam bahasa alam. Lubang semantis antara bahasa alam dan bahasa pemrograman telah lama dianggap sebagai salah satu halangan yang paling signifikan untuk efektivitas metode pengembalian informasi berdasarkan kata kunci (IR). Ini adalah asumsi umum bahwa 'tradisional' tas-kata IR metode tidak cocok untuk pencarian kode semantis: pekerjaan kita secara empiris menyelidiki asumsi ini. Secara spesifik, kami memeriksa efektivitas dua metode IR tradisional, yaitu BM25 dan RM3, pada CodeSearchNet Corpus, yang terdiri dari pertanyaan bahasa alami berpasangan dengan snippets kode relevan. Kami menemukan bahwa dua metode berdasarkan kata kunci melebihi beberapa model saraf pre-BERT. Kami juga membandingkan beberapa strategi pre-proses data khusus kode dan menemukan bahwa tokenisasi khusus meningkatkan efektivitas.</abstract_id>
      <abstract_ko>의미 코드 검색의 임무는 자연 언어가 표현하는 정보 수요에 따라 원본 코드 라이브러리에서 코드 세션을 검색하는 것이다.오랫동안 자연 언어와 프로그래밍 언어 간의 의미 갭은 키워드 기반의 정보 검색(IR) 방법의 유효성에 영향을 주는 가장 중요한 장애 중 하나로 여겨져 왔다.흔히 볼 수 있는 가설은'전통적인'패키지 IR 방법이 의미 코드 검색에 적합하지 않다는 것이다. 우리의 작업은 이 가설을 실증적으로 연구했다.구체적으로 말하자면 우리는 CodeSearchNet 자료 라이브러리에서 두 가지 전통적인 IR 방법, 즉 BM25와 RM3의 유효성을 검증했다. 이 자료 라이브러리는 자연 언어 조회와 관련 코드 세션으로 구성되어 있다.우리는 이 두 가지 키워드를 바탕으로 하는 방법이 몇 가지 전버트 신경 모델보다 우수하다는 것을 발견했다.우리는 코드에 특정된 몇 가지 데이터 예처리 전략을 비교한 결과 전문적인 표기화가 효율을 높인 것을 발견했다.</abstract_ko>
      <abstract_sw>Kazi ya kutafuta mfumo wa kanuni za kimapenzi ni kupata vifaa vya kodi kutoka kwenye makampuni ya kanuni yenye msingi wa mahitaji ya taarifa yanayoelezwa kwa lugha ya asili. Ugaji wa kimapenzi kati ya lugha za asili na lugha za programu kwa muda mrefu umechukuliwa kama moja ya vikwazo muhimu zaidi katika ufanisi wa upatikanaji wa taarifa za muhimu (IR). It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  Kwa hakika, tunachunguza ufanisi wa mbinu mbili za utamaduni wa IR, yaani BM25 na RM3, kwenye Corpus ya CodeSearchNet, ambayo ni pamoja na maswali ya lugha ya asili yanayohusiana na vikosi vinavyohusiana. Tunapata kwamba mbinu mbili za msingi za neno zinazotumia mifano kadhaa ya ubongo wa BERT. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract_sw>
      <abstract_sq>Detyra e kërkimit të kodit semantik është të marrësh copat e kodit nga një kod burimi korpus bazuar në një nevojë informacioni të shprehur në gjuhën natyrore. Ndryshimi semantik midis gjuhës natyrore dhe gjuhëve të programimit është konsideruar për një kohë të gjatë si një nga pengesat më të rëndësishme në efektshmërinë e metodave të marrjes së informacionit bazuar në fjalë kyçe (IR). Është një supozim i përbashkët se metodat 'tradicionale' të çantës së fjalëve IR janë keq të përshtatshme për kërkimin e kodit semantik: puna jonë empirikisht heton këtë supozim. Veçanërisht, ne e shqyrtojmë efektshmërinë e dy metodave tradicionale të IR, në emër BM25 dhe RM3, në CodeSearchNet Corpus, i cili përbëhet nga pyetje natyrore gjuhësh të paluara me copa kodi të duhura. Ne zbulojmë se dy metodat bazuar në fjalë kyçe kalojnë disa modele neuronale para-BERT. We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract_sq>
      <abstract_am>የsemantic code search job is to retrieve the code code from a source code corpus based on an information that is useful in natural language. በአፍሪካዊ ቋንቋ እና በፕሮግራም ቋንቋዎች መካከል የsemantic ውጤት ከረጅም ዘመን ጀምሮ የቁልፍ ቃላት ማግኘት (IR) ዓይነት አካባቢ መሆኑን (IR) ማግኘት ከሚያሰኘው ትልቅ ግንኙነት አንዱ ነው፡፡ የ'ትምህርት' የኢ.ஆர ቃላት አካባቢ ቃላት የሆኑት አካባቢ ማድረግ የተጠቃሚ ነው፤ ሥራችን በትክክል ይሞክራል፡፡ በተለያይነት፣ የሁለት ባሕላዊ IR ሥርዓት፣ BM25 እና RM3፣ በኮዲስመር ኔት ኮርፓስ ላይ ጥያቄን እናመርምረዋለን፡፡ የሁለት የቁልፎች ቃላት-መሠረቶች ብዙዎችን የBERT የነጥብ ዓይነቶች የሚያደርጉትን እናገኛለን፡፡ እና ብዙ የሥርዓት ዳታዎችን አስቀድሞ ለመሥራት strategieን እናስተያየዋለን፣ የግንኙነት ማስታወቂያው ፍጥረትን ያሻላል፡፡</abstract_am>
      <abstract_fa>وظیفه جستجوی کد سیمانتیک این است که اسنکت‌های کد را از یک کورپوس منبع بر اساس یک نیاز اطلاعاتی که در زبان طبیعی توضیح داده می‌شود برگیرد. فاصله semantic بین زبان طبیعی و برنامه‌ریزی زبان‌های برنامه‌ریزی برای مدت طولانی به عنوان یکی از مهمترین مانع‌های فعالیت روش‌های بازیابی اطلاعات (IR) بر اساس کلید به نظر گرفته شده است. این فرض معمولی است که روش‌های کلمه‌های "سنتی" IR برای جستجوی کد‌های semantic به بدی مناسب می‌شوند: کار ما به طور عمومی این فرض را تحقیق می‌کند. به طور خاص، ما فعالیت دو روش IR سنتی را تحقیق می‌کنیم، یعنی BM25 و RM3، روی Corpus CodeSearchNet، که از سوالات زبان طبیعی که با اسنیپت‌های کد مربوط به هم جور شده است. ما فهمیدیم که دو روش کلیدی بر اساس کلید چند مدل عصبی قبل از BERT را انجام می دهند. ما همچنین چندین استراتژی پیش‌پردازش داده‌های مخصوص کد را مقایسه می‌کنیم و پیدا می‌کنیم که توکینز مخصوص فعالیت را بهتر می‌کند.</abstract_fa>
      <abstract_hy>Սեմանտիկ կոդի որոնման խնդիրն է վերցնել կոդի կտորները աղբյուր կոդի կոդի կորպուսից, հիմնված բնական լեզվով արտահայտված ինֆորմացիայի կարիքի վրա: Բնական լեզուների և ծրագրավորման լեզուների միջև սեմանտիկ տարբերությունը երկար ժամանակ համարվում է ամենակարևոր խոչընդոտներից մեկը, որոնք առաջացնում են ստեղծաբառերով հիմնված տեղեկատվության վերադարձման (RI) մեթոդների արդյունավետության վրա: Սա ընդհանուր ենթադրություն է, որ "ավանդական" բառերի արտահայտության մեթոդները վատ համապատասխանում են սեմանտիկ կոդի որոնման համար: Մեր աշխատանքը էմպրիկապես ուսումնասիրում է այս ենթադրությունը: Հատկապես, մենք ուսումնասիրում ենք երկու ավանդական ԻՌ մեթոդի արդյունավետությունը, այն է' BM25 և ՌՄ3-ը, ԿոդեՍերքNet Կորպուսի վրա, որը կազմված է բնական լեզվի հարցերից, որոնք զույգված են համապատասխանատու կոդի կտորների հետ Մենք հայտնաբերեցինք, որ երկու հիմնական բառերով հիմնված մեթոդները գերազանցում են BER նախաբեռ նյարդային մոդելներին: Մենք նաև համեմատում ենք մի քանի կոդի-հատուկ տվյալների նախավերաբերյալ ռազմավարություններ և հայտնաբերում ենք, որ հատուկ թոկենիզացիան բարելավում է արդյունավետությունը:</abstract_hy>
      <abstract_tr>Semantik köd araştyrmasynyň göresi tebigy dilde ifade edilen maglumaty üçin köd köd ködlemelerini a çmak. Doýal diller we programlemek diller arasyndaky semantik gaplaryň (IR) täsirli sözler üçin iň möhüm engellerden biri diýip kabul edildi. Däpli sanat eserleşmek üçin 'dünýäpli' sözleri IR metodlaryň semantik ködleme gözlemesi üçin ýeterli däl. Biziň işimiz bu pikirlemi empiriýaly barýar. Adatça, biz 2 däpli IR metodlaryň, ady BM25 we RM3, KodeSearchNet Korpusynda, tebigy dil soraglarynyň barlygyny barlaýarys. Biz iki aç kelime tabanly yöntemler BERT öňünden näral nusgalaryny çykarýar. Biz hem birnäçe köd taýýarlanmaky önünde işleýän maglumaty karşılaştyrýarys we özellikle tokenizaçy etkinlik täsirini gowylaşdyrýar.</abstract_tr>
      <abstract_bn>সেমেন্টিক কোড অনুসন্ধানের কাজ হচ্ছে প্রাকৃতিক ভাষায় প্রকাশিত তথ্য প্রকাশিত একটি সোর্স কোড কোর্পাস থেকে কোড স্নি প্রাকৃতিক ভাষা এবং প্রোগ্রামিং ভাষার মধ্যে সেমেন্টিক বিভ্রান্তিক বিভ্রান্তি অনেক দীর্ঘদিন ধরে বিবেচনা করা হয়েছে কীওয়ার্ড ভিত্তিক এটা একটা সাধারণ ধারণা যে 'ঐতিহ্যবাহী' ব্যাগ-অফ-শব্দের আইআর-এর পদ্ধতি সেমেন্টিক কোড অনুসন্ধানের জন্য খুব খারাপ: আমাদের কাজ এই ধারণার জন্ বিশেষ করে আমরা দুই ঐতিহ্যবাহী আইআর পদ্ধতির কার্যক্রম পরীক্ষা করি, যেমন বিএম২৫ এবং আরএম৩, কোড সার্চ নেট কোর্পাসে যা প্রাকৃতিক ভাষার অনুসন্ধানের প্রশ্নের আমরা খুঁজে পাচ্ছি যে বিবের্টের পূর্বে নিউরেল মডেলের দুটি কীওয়ার্ড ভিত্তিক পদ্ধতিগুলো বেশ কয়েকটি প্ We also compare several code-specific data pre-processing strategies and find that specialized tokenization improves effectiveness.</abstract_bn>
      <abstract_ca>La tasca de la búsqueda de codi semàntic és recuperar fragments de codi d'un corpus de codi font basat en una necessitat d'informació expressada en llenguatge natural. The semantic gap between natural language and programming languages has for long been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods.  It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  En concret, examinem l'eficacia de dos mètodes tradicionals de IR, a saber, BM25 i RM3, al CodeSearchNet Corpus, que consisteix en preguntes de llenguatge natural parellades amb fragments de codi pertinents. Trobem que els dos mètodes basats en paraules clau superen varis models neurals pre-BERT. També comparem diverses estratègies de pré-processament de dades específices per codi i descobrim que la tecenització especialitzada millora l'eficacia.</abstract_ca>
      <abstract_az>Semantik kodu araştırmasının görevi, doğal dildə ifadə edilən məlumatlar üçün mənbə kodu korpusundan kodu snippet almaqdır. Təbiətli dil və programlama dillərin arasındakı semantik boşluğu uzun zamandır anahtar sözlərinə dayanan məlumat alma (IR) metodlarının ən möhkəm səbəbi kimi hesab edildi. Həmçinin 'tradicional' sözlərin IR metodları semantik kodu araması üçün pis uyğun deyildir: işimiz bu iddiayı imkansız olaraq araşdırır. Özellikle, biz iki nəticə IR metodlarının, həmçinin BM25 və RM3, KodeSearchNet Corpus üzerində olan təbiətli dil soruşmalarından olub. İki anahtar sözlərə dayanan metodların BERT-dən əvvəl nöral modellərini təqdim edir. Biz həmçinin çoxlu kodu müəyyən məlumatları ön işləmə stratejiləri ilə qarşılaşdırırıq və təhsil edilmiş tokenizasyon efektivitəti daha yaxşılaşdırır.</abstract_az>
      <abstract_cs>Úkolem vyhledávání sémantického kódu je získat úryvky kódu ze zdrojového kódu na základě informační potřeby vyjádřené v přirozeném jazyce. Sémantická propast mezi přirozeným jazykem a programovacími jazyky je dlouho považována za jednu z nejvýznamnějších překážek efektivity metod vyhledávání informací založených na klíčových slovech (IR). Je běžným předpokladem, že "tradiční" sáčkové IR metody jsou špatně vhodné pro vyhledávání sémantického kódu: naše práce empiricky zkoumá tento předpoklad. Konkrétně zkoumáme efektivitu dvou tradičních IR metod, jmenovitě BM25 a RM3, na CodeSearchNet Corpus, který se skládá z dotazů přirozeného jazyka spárovaných s relevantními úryvky kódu. Zjistili jsme, že tyto dvě metody založené na klíčových slovech překonávají několik pre-BERT neuronových modelů. Porovnáváme také několik strategií předzpracování dat specifických pro kód a zjišťujeme, že specializovaná tokenizace zlepšuje efektivitu.</abstract_cs>
      <abstract_bs>Zadatak pretraživanja semantičkog koda je da uzmete snippet koda iz izvornog koda korpusa na temelju informacijske potrebe izražene na prirodnom jeziku. Semantički praznik između prirodnog jezika i jezika programiranja dugo je smatrao jednim od najznačajnijih prepreka učinkovitosti metoda prikupljanja informacija na ključnim riječima (IR). To je zajednička pretpostavka da su "tradicionalne" metode riječi IR loše odgovarajuće za pretragu semantičkih kodova: naš posao empirički istražuje ovu pretpostavku. Posebno, pregledamo učinkovitost dvije tradicionalne IR metode, a to je BM25 i RM3, na KodeSearchNet korpusu, koja se sastoji od prirodnih ispitivanja jezika povezanih sa relevantnim kodskim snippetama. Nalazimo da su dva metoda temeljena na ključnim riječima iznosila nekoliko pre-BERT neuralnih modela. Također uspoređujemo nekoliko strategija predobrađivanja podataka specifičnih kodova i saznamo da specijalizovana tokenizacija poboljšava učinkovitost.</abstract_bs>
      <abstract_fi>Semanttisen koodihaun tehtävänä on hakea koodinpätkyjä lähdekoodikorpusta luonnollisella kielellä ilmaistun tietotarpeen pohjalta. Luonnonkielen ja ohjelmointikielten semanttista kuilua on pitkään pidetty yhtenä avainsanoihin perustuvien tiedonhakumenetelmien tehokkuuden suurimmista esteistä. On yleistä olettamusta, että 'perinteiset' sana-pussi IR-menetelmät eivät sovellu semanttiseen koodihakuun: tutkimuksemme tutkii tätä olettamusta empiirisesti. Tarkastelemme erityisesti kahden perinteisen IR-menetelmän, BM25:n ja RM3:n, tehokkuutta CodeSearchNet Corpus -järjestelmässä, joka koostuu luonnollisista kielikyselyistä ja asiaankuuluvista koodinpätköistä. Havaitsemme, että nämä kaksi avainsanapohjaista menetelmää ovat parempia kuin useat BERT-neuromallit. Vertaamme myös useita koodikohtaisia tietojen esikäsittelyn strategioita ja huomaamme, että erikoistunut tokenisointi parantaa tehokkuutta.</abstract_fi>
      <abstract_et>Semantilise koodiotsingu ülesanne on hankida koodilõiked lähtekoodikorpusest looduskeeles väljendatud infovajaduse põhjal. Looduskeele ja programmeerimiskeelte semantilist lõhet on pikka aega peetud üheks olulisemaks takistuseks märksõnapõhise teabehankimise (IR) meetodite tõhususele. Tavaline eeldus on, et traditsioonilised IR-meetodid sobivad semantilise koodi otsinguks halvasti: meie töö uurib seda eeldust empiiriliselt. Konkreetselt uurime kahe traditsioonilise IR meetodi, nimelt BM25 ja RM3 efektiivsust CodeSearchNet Corpuses, mis koosneb looduskeelsetest päringutest, mis on seotud asjakohaste koodilõigetega. Leiame, et kaks märksõnapõhist meetodit ületavad mitmeid BERT-eelseid närvimudeleid. Võrdleme ka mitmeid koodipõhiseid andmete eeltöötlusstrateegiaid ja leiame, et spetsiaalne tokeniseerimine parandab efektiivsust.</abstract_et>
      <abstract_af>Die taak van semantiese kode soek is om kode snippets uit 'n bronkode korpus te ontvang wat op 'n inligting nodig in natuurlike taal uitgevoer word. Die semantiese spans tussen natuurlike taal en programma tale is vir lank aangesien as een van die mees betekende hinders tot die effektiviteit van sleutelwoord-gebaseerde inligting ontvang (IR) metodes. Dit is 'n gemeenskaplike aanvaar dat 'tradisionele' sak van woorde IR metodes verkeerd geskik is vir semantiese kode soek: ons werk empiriese hierdie aanvaar ondersoek. Spesifieke, ons ondersoek die effektiviteit van twee tradisionele IR metodes, bedoel BM25 en RM3, op die CodeSearchNet Corpus, wat bestaan van natuurlike taal vrae wat met relevante kode snippets paar is. Ons vind dat die twee sleutelwoord-gebaseerde metodes verskeie voor-BERT neurale modele uitvoer. Ons vergelyk ook verskeie kode-spesifieke data-voorafverwerking strategies en vind dat spesialiseerde tokenisasie effektiviteit verbeter.</abstract_af>
      <abstract_jv>Sampeyan kelas sematik bukane dadi nggawe kelas kode seneng pisan kelas nang kode perbudhakan Tarjamahan sematik langkung banjur idiomat lan program sing dumadhi iki bakal terusah bantuan ing ngupakan karo perbudhakan sing apik bantuan kanggo nggawe informasi sing basa gambar na kelas Mungkin ngerti, nggunakake 'Traditional' bags-of-words IR kuwi ngerasah kanggo nguasai kode sematik: lan barang awak dhéwé empires menehi kuwi. Kowe nguasai, awak dhéwé ngerasakno efek karo hal-hal ngerasakno IR sing wis ambang, nambah EM5 lan Rm3, lan kode-suarangknet Awak dhéwé ngerti, kuwi gambarang langgar sampek dadi sing bisa model sing bisa BERT nggawe Awak dhéwé pisan karo paketen nggambar akeh operasi layang-pakan karo perusahaan gambar nggawe barang nggawe aturan tokenisaan sing bisa nguasai efek.</abstract_jv>
      <abstract_ha>Kayan aikin search na kodi na semantic is to retrieve kode ɗin kodi daga wata kode na source based on wani maɓalli wanda aka buɗe da shi cikin harshen asimi. Kifin sakanti da ke tsakanin harshen asimi da shiryoyin ayukan ayuka da aka ƙayyade wa zaman zuwa aka ƙaddara shi kamar ɗayan hanyõyin mafi girma wa amfani da motsar masu tsari ga maɓallin maganar (IR). Wannan yana da ɗabi'a da za'a buƙata-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane-zane A ƙayyade, tuna ƙidãya masu amfani da shiryoyin IR biyu na zamani, kamar BM25 da RM3, a kan KCode SearchNet, wanda ke ƙunsa da askari na cikin harshen asili wanda aka haɗa da kodi masu husũma. Tuna gane cewa hanyõyin biyu masu sala ga maɓallin ayuka da ke samar wasu misãlai masu gaba-BERT. Kayya, Munã daidaita ko da wasu taki masu ƙayyade kodi masu cikin takilaikin da ke gabatar da aiki, kuma Munã gane cewa alama masu ƙayyade, yana ƙara mafiya amfani.</abstract_ha>
      <abstract_sk>Naloga semantičnega iskanja kode je pridobiti delčke kode iz korpusa izvorne kode na podlagi informacijske potrebe, izražene v naravnem jeziku. Semantična vrzel med naravnim jezikom in programskimi jeziki je že dolgo veljala za eno najpomembnejših ovir za učinkovitost metod pridobivanja informacij na podlagi ključnih besed (IR). Pogosta domneva je, da so "tradicionalne" metode IR vrečke besed slabo primerne za semantično iskanje kod: naše delo empirično raziskuje to domnevo. Natančneje preučujemo učinkovitost dveh tradicionalnih IR metod, in sicer BM25 in RM3, na CodeSearchNet Corpus, ki je sestavljen iz poizvedb v naravnem jeziku, povezanih z ustreznimi delčki kode. Ugotovili smo, da sta obe metodi, ki temeljita na ključnih besedah, boljši od več pred-BERT nevronskih modelov. Primerjamo tudi več strategij predobdelave podatkov, specifičnih za kodo, in ugotavljamo, da specializirana žetonizacija izboljšuje učinkovitost.</abstract_sk>
      <abstract_bo>སྔོན་ལྟར་ཞིབ་ཀྱི་འཚོལ་བཤེར་ཀྱི་བྱ་འགུལ་ནི་རང་བཞིན་སྐད་ནང་གསལ་བཤད་ཀྱི་ཆ་འཕྲིན་ཡིག The semantic gap between natural language and programming languages has been regarded as one of the most significant obstacles to the effectiveness of keyword-based information retrieval (IR) methods. འདི་ལྟ་བུའི་མཐུན་ལམ་ལུགས་ཀྱི་གནད་སྡུད་གནད་མིན་ཡོད་པའི་ཐབས་ལམ་ཞིག་ཉེན་པ་ཞིག་ཡིན། དམིགས་འཛུགས་ཀྱིས། ང་ཚོའི་རྒྱུན་སྲོལ་གྱི་IR ཐབས་ལམ་གཉིས་ཀྱི་ལྟ་བུ་ཞིབ་དཔྱད་དགོས་པ་དེ་མིན BM25 དང་RM3(CodeSearchNet Corpus)ནང་དུ་ཡོད། དེ་ནི་སྤྱིར་བཏང་བའི་སྐད ང་ཚོས་བྱ་ཚིག་དང་གཙོ་ཚིག་གཞི་རྟེན་པའི་ཐབས་ལམ་གཉིས་ཀྱིས་BERT སྔོན་གྱི་དཔེ་དབྱིབས་མང་པོ་ཞིག ང་ཚོས་ཀྱང་གསལ་བཤད་ཀྱི་སྔོན་སྒྲིག་འགོད་བྱེད་པའི་གནས་ཚུལ་གསལ་བཀལ་བ་མང་ཙམ་བཟོ་བྱེད་ཀྱི་ཡོད།</abstract_bo>
      <abstract_he>המשימה של חיפוש קוד סמנטי היא להשיג חתיכות קוד ממקור קוד קורפוס מבוסס על צורך מידע מוביע בשפה טבעית. הפער הסמנטי בין שפת טבעית לשפת תוכנית כבר זמן רב נחשב כאחד המעכבים הכי משמעותיים ביותר לעובדות שיטות השיג מידע מבוסס על מילים מפתחות (IR). It is a common assumption that 'traditional' bag-of-words IR methods are poorly suited for semantic code search: our work empirically investigates this assumption.  במיוחד, אנחנו בודקים את היעילות של שתי שיטות IR מסורתיות, כלומר BM25 ו-RM3, על CodeSearchNet Corpus, אשר מורכבת משאלות שפות טבעיות זוגות עם חתיכות קוד רלוונטיות. אנחנו מוצאים ששתי השיטות המבוססות על מילים מפתחות מעליפות מספר דוגמנים עצביים לפני BERT. אנחנו משוותים גם מספר אסטרטגיות מעבדה מוקדמת של נתונים מסויימים לקוד ומצאים שטוקניזציה מומחית משפר את היעילות.</abstract_he>
      </paper>
  </volume>
</collection>