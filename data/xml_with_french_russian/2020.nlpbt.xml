<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.nlpbt">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the First International Workshop on Natural Language Processing Beyond Text</booktitle>
      <editor><first>Giuseppe</first><last>Castellucci</last></editor>
      <editor><first>Simone</first><last>Filice</last></editor>
      <editor><first>Soujanya</first><last>Poria</last></editor>
      <editor><first>Erik</first><last>Cambria</last></editor>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="54cecc5a">2020.nlpbt-1.0</url>
      <bibkey>nlpbt-2020-international</bibkey>
    </frontmatter>
    <paper id="7">
      <title>MAST : Multimodal Abstractive Summarization with Trimodal Hierarchical Attention<fixed-case>MAST</fixed-case>: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention</title>
      <author><first>Aman</first><last>Khullar</last></author>
      <author><first>Udit</first><last>Arora</last></author>
      <pages>60–69</pages>
      <abstract>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities   text, audio and video   in a multimodal video. Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities. We examine the usefulness and challenges of deriving information from the <a href="https://en.wikipedia.org/wiki/Audio_signal">audio modality</a> and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> pay more attention to the text modality. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract>
      <url hash="a8bf05bd">2020.nlpbt-1.7</url>
      <doi>10.18653/v1/2020.nlpbt-1.7</doi>
      <video href="https://slideslive.com/38939781" />
      <bibkey>khullar-arora-2020-mast</bibkey>
      <pwccode url="https://github.com/amankhullar/mast" additional="false">amankhullar/mast</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/how2">How2</pwcdataset>
    <title_ar>MAST: تلخيص تجريدي متعدد الوسائط مع اهتمام هرمي ثلاثي الوسائط</title_ar>
      <title_es>MAST: Resumen abstractivo multimodal con atención jerárquica trimodal</title_es>
      <title_pt>MAST: Resumo Abstrativo Multimodal com Atenção Hierárquica Trimodal</title_pt>
      <title_fr>MAST : Synthèse abstraite multimodale avec attention hiérarchique trimodale</title_fr>
      <title_ja>MAST ：三相階層的な注意を伴う多相抽象的な要約</title_ja>
      <title_zh>MAST:三模态多模态抽摘要</title_zh>
      <title_ru>MAST: Мультимодальное абстрактное обобщение с тримодальным иерархическим вниманием</title_ru>
      <title_hi>मस्तूल: Trimodal पदानुक्रमित ध्यान के साथ मल्टीमॉडल अमूर्त Summarization</title_hi>
      <title_ga>MAST: Achoimre Ilmhódach Teibí le Aird Ordlathach Trimodal</title_ga>
      <title_ka>MAST: მულტიმედიალური აბსტრაქტიური კომპანიზაცია რრიმოდეალური hiერაქტიური დაახლოებით</title_ka>
      <title_kk>MAST: Үш модел гиерархикалық назардағы көптеген абстрактивті тұжырымдамасы</title_kk>
      <title_lt>MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention</title_lt>
      <title_hu>MAST: Multimodális Absztraktív Összefoglalás Trimodális Hierarchikus Figyelemmel</title_hu>
      <title_el>Πολυmodale αφηρημένη Σύνοψη με Τριmodale Ιεραρχική Προσοχή</title_el>
      <title_ml>MAST: ട്രിമോഡാല്‍ ഹീരാര്‍ക്കിക്കല്‍ ശ്രദ്ധ കൊണ്ട് മള്‍മോഡല്‍ അബ്ട്രാക്ട്രാക്ടിവിന്‍റെ ചുരുക്കം</title_ml>
      <title_mt>MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention</title_mt>
      <title_it>MAST: Sintesi astratta multimodale con attenzione gerarchica trimodale</title_it>
      <title_ms>Perhatian Hierarkik Trimodal</title_ms>
      <title_no>MAST: Multimodal abstraktiv samandrag med trimodal hierarkisk merking</title_no>
      <title_mn>МАСТ: Олон моделийн абстрактив хэмжээ гурван гиерархик анхаарал</title_mn>
      <title_sr>MAST: Multimodalna abstraktivna sažetka sa trimodalnom hijerarhičkom pažnjom</title_sr>
      <title_si>MAST: ත්‍රිමෝඩාල් හියාර්චිකල් අවධානය සමග ග ගොඩක් අවධානය</title_si>
      <title_mk>MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention</title_mk>
      <title_pl>MAST: Multimodalna abstrakcyjna streszczenie z uwagą hierarchiczną trimodalną</title_pl>
      <title_sv>MAST: Multimodal Abstraktiv Sammanfattning med Trimodal Hierarkisk Uppmärksamhet</title_sv>
      <title_ta>MAST: Trimodal Hierarchical Attention with Multimodal Abstractive Summary</title_ta>
      <title_ur>ماسٹ: ٹریموڈال حیرارشیک حفاظت کے ساتھ بہت سی مڈیل آب تراکٹیو جماریز</title_ur>
      <title_ro>MAST: Rezumat abstractiv multimodal cu atenție ierarhică trimodală</title_ro>
      <title_so>MAST: Multimodal Abstractive Summary with Trimodal Hierarchical Attention</title_so>
      <title_uz>Name</title_uz>
      <title_vi>Sơ suất đa phương với kính thiên hà ba chiều chú ý</title_vi>
      <title_bg>МАСТ: Мултимодално абстрактивно обобщение с тримодално йерархично внимание</title_bg>
      <title_da>MAST: Multimodal Abstraktiv Resumé med Trimodal Hierarkisk Opmærksomhed</title_da>
      <title_hr>MAST: Multimodalna abstraktivna sažetka s tromodalnom hijerarskom pažnjom</title_hr>
      <title_nl>MAST: Multimodale abstracte samenvatting met trimodale hiërarchische aandacht</title_nl>
      <title_de>MAST: Multimodale abstrakte Zusammenfassung mit trimodaler hierarchischer Aufmerksamkeit</title_de>
      <title_id>MAST: Multimodal Abstractive Summarization dengan Trimodal Hierarchical Attention</title_id>
      <title_ko>MAST: 삼모드 차원 주의가 있는 다중모드 추상 요약</title_ko>
      <title_fa>MAST: جمع‌آوری بیش‌modal abstractive with Trimodal Hierarchical Attention</title_fa>
      <title_sw>MAST: Ujumbe wa mfululizo wa kidini na uangalizi wa Taifa</title_sw>
      <title_af>MAST: Multimodal Abstractive Opsomming met Trimodal Hierarchical Aangaande</title_af>
      <title_am>Multimodal Abstractive Summary with Trimodal Hierarchical Attention</title_am>
      <title_tr>MAST: Üç modal Hiyerarşik Dikkati ile Çoklumodal Abstraktiv Toplaşum</title_tr>
      <title_sq>MAST: Summarization Multimodal Abstractive with Trimodal Hierarchical Attention</title_sq>
      <title_hy>ՄԱՍՏ. Մոլիմոդալ Աբլաստրատիվ համառոտագրություն, որը ունի Երիմոդալ Հիերախիկ ուշադրություն</title_hy>
      <title_bs>MAST: Multimodalna abstraktivna sažetka sa trimodalnom hijerarhičkom pažnjom</title_bs>
      <title_az>MAST: Trimodal Hierarchical Attention ilə Multimodal Abstractive Summarization</title_az>
      <title_bn>MAST: ত্রিমোডাল হিরেরার্কিক মনোযোগ দিয়ে বহুমোডাল আবত্ত্রিক সামারিজেশন</title_bn>
      <title_ca>MAST: Resumen Abstractiu Multimodal amb Atenció Hierarquica Trimodal</title_ca>
      <title_fi>MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention</title_fi>
      <title_cs>MAST: Multimodální abstraktní shrnutí s trimodální hierarchickou pozorností</title_cs>
      <title_et>MAST: Multimodaalne abstraktne kokkuvõte koos kolmemodaalse hierarhilise tähelepanuga</title_et>
      <title_jv>MASTA: Multimodal absolutetraction Cummariation with Trimodal Hiaradical Attention</title_jv>
      <title_sk>MAST: Multimodalni abstraktivni povzetek s trimodalno hierarhično pozornostjo</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>MAST: Trimodal Hierarchical Attention</title_bo>
      <title_he>סדרה מורכבת אסטרקטיבית עם תשומת לב הייררכית טרימודלית</title_he>
      <abstract_ar>تقدم هذه الورقة MAST ، نموذج جديد لتلخيص النص التجريدي متعدد الوسائط الذي يستخدم المعلومات من جميع الأساليب الثلاثة - النص والصوت والفيديو - في فيديو متعدد الوسائط. العمل المسبق على تلخيص النص التجريدي متعدد الوسائط استخدم فقط المعلومات من طرائق النص والفيديو. ندرس فائدة وتحديات استخلاص المعلومات من الطريقة الصوتية ونقدم نموذجًا متسلسلًا متسلسلًا هرميًا قائمًا على الاهتمام يتغلب على هذه التحديات من خلال السماح للنموذج بإيلاء مزيد من الاهتمام لطريقة النص. يتفوق MAST على الحالة الحالية للنموذج الفني (نص الفيديو) بمقدار 2.51 نقطة من حيث درجة المحتوى F1 و 1.00 نقطة من حيث درجة Rouge-L على مجموعة بيانات How2 لفهم اللغة متعددة الوسائط.</abstract_ar>
      <abstract_es>Este artículo presenta MAST, un nuevo modelo de resumen de texto abstractivo multimodal que utiliza información de las tres modalidades (texto, audio y vídeo) en un vídeo multimodal. Los trabajos anteriores sobre la sumarización de textos abstractivos multimodales solo utilizaban información de las modalidades de texto y video. Examinamos la utilidad y los desafíos de derivar información de la modalidad de audio y presentamos un modelo jerárquico trimodal basado en la atención de secuencia a secuencia que supera estos desafíos al permitir que el modelo preste más atención a la modalidad de texto. MAST supera al modelo actual de vanguardia (video-texto) en 2,51 puntos en términos de puntuación de Content F1 y 1,00 puntos en términos de puntuación Rouge-L en el conjunto de datos How2 para la comprensión multimodal del lenguaje.</abstract_es>
      <abstract_pt>Este artigo apresenta o MAST, um novo modelo de sumarização de texto abstrato multimodal que utiliza informações de todas as três modalidades – texto, áudio e vídeo – em um vídeo multimodal. Trabalhos anteriores sobre sumarização de texto abstrato multimodal utilizaram apenas informações das modalidades de texto e vídeo. Examinamos a utilidade e os desafios de derivar informações da modalidade de áudio e apresentamos um modelo baseado em atenção hierárquica trimodal sequência a sequência que supera esses desafios, permitindo que o modelo preste mais atenção à modalidade de texto. O MAST supera o atual modelo de última geração (vídeo-texto) em 2,51 pontos em termos de pontuação F1 de conteúdo e 1,00 pontos em termos de pontuação Rouge-L no conjunto de dados How2 para compreensão de linguagem multimodal.</abstract_pt>
      <abstract_fr>Cet article présente MAST, un nouveau modèle de synthèse de texte abstrait multimodal qui utilise des informations provenant des trois modalités — texte, audio et vidéo — dans une vidéo multimodale. Les travaux antérieurs sur la synthèse de textes abstraits multimodaux n'utilisaient que les informations provenant des modalités texte et vidéo. Nous examinons l'utilité et les défis liés à la dérivation d'informations à partir de la modalité audio et présentons un modèle hiérarchique trimodal basé sur l'attention séquence-à-séquence qui surmonte ces défis en laissant le modèle accorder plus d'attention à la modalité texte. MAST surpasse le modèle actuel de pointe (vidéo-texte) de 2,51 points en termes de score Content F1 et de 1,00 point en termes de score Rouge-L sur le jeu de données How2 pour la compréhension multimodale des langues.</abstract_fr>
      <abstract_ja>本稿では、マルチモーダルビデオにおいて、テキスト、オーディオ、ビデオの3つのモダリティすべてからの情報を利用する、マルチモーダル抽象的テキスト要約の新しいモデルであるMASTを紹介する。マルチモーダル抽象的テキストの要約に関する以前の仕事は、テキストおよびビデオモードからの情報のみを利用していた。私たちは、オーディオモダリティから情報を導き出すことの有用性と課題を検討し、モデルがテキストモダリティにより注意を払うことによって、これらの課題を克服するシーケンスツーシーケンスのトリモーダル階層的注意ベースのモデルを提示します。MASTは、マルチモーダル言語の理解のために、コンテンツF 1スコアで2.51ポイント、How 2データセットのRouge - Lスコアで1.00ポイント、現在の最先端モデル（ビデオテキスト）を上回る。</abstract_ja>
      <abstract_zh>本文言MAST,此多模态象摘要之新模也,可于多模态视频中利用三文(本,音频视频)信息。 前此多模抽象摘要惟用文本及视频文信息。 论音频模态之有用性挑战性者获取信息,为次第之三模态以为形势,使模形多模态以胜之。 多模态言解者How2数集上,MAST先F1得分者(视频文本)高2.51分,Rouge-L得分先1.00分。</abstract_zh>
      <abstract_hi>यह पेपर MAST प्रस्तुत करता है, मल्टीमॉडल अमूर्त पाठ सारांशीकरण के लिए एक नया मॉडल जो सभी तीन तौर-तरीकों से जानकारी का उपयोग करता है - पाठ, ऑडियो और वीडियो - एक बहुआयामी वीडियो में। Multimodal abstractive text summarization पर पहले का काम केवल पाठ और वीडियो तौर-तरीकों से जानकारी का उपयोग करता है। हम ऑडियो रूपरेखा से जानकारी प्राप्त करने की उपयोगिता और चुनौतियों की जांच करते हैं और एक अनुक्रम-से-अनुक्रम ट्राइमोडल पदानुक्रमित ध्यान-आधारित मॉडल प्रस्तुत करते हैं जो मॉडल को पाठ पद्धति पर अधिक ध्यान देकर इन चुनौतियों को दूर करता है। MAST सामग्री F1 स्कोर के संदर्भ में 2.51 अंक और मल्टीमॉडल भाषा की समझ के लिए How2 डेटासेट पर रूज-एल स्कोर के संदर्भ में 1.00 अंकों द्वारा कला मॉडल (वीडियो-टेक्स्ट) की वर्तमान स्थिति को मात देता है।</abstract_hi>
      <abstract_ru>В этой статье представлена МАЧТА, новая модель для мультимодального абстрактного текстового суммирования, которая использует информацию из всех трех способов – текста, аудио и видео – в мультимодальном видео. В предыдущей работе по мультимодальному абстрактному обобщению текста использовалась только информация из текстовых и видеомодулей. Мы изучаем полезность и проблемы извлечения информации из аудиомодальности и представляем тримодальную иерархическую модель, основанную на иерархическом внимании, которая преодолевает эти проблемы, позволяя модели уделять больше внимания текстовой модальности. MAST опережает текущую современную модель (видеотекст) на 2,51 балла по оценке Content F1 и на 1,00 балла по оценке Rouge-L в наборе данных How2 для мультимодального понимания языка.</abstract_ru>
      <abstract_ga>Cuireann an páipéar seo i láthair MAST, samhail nua le haghaidh Achoimriú Ilmhódúil Téacs Teibí a úsáideann faisnéis ó na trí mhódúlacht - téacs, fuaime agus físe - i bhfíseán ilmhódach. Níor úsáideadh réamhobair ar achoimriú téacs ilmhódach teibí ach amháin as faisnéis ó na módúlachtaí téacs agus físe. Scrúdaímid a úsáidí agus na dúshláin a bhaineann le faisnéis a fháil ón modhúlacht fuaime agus cuirimid i láthair múnla ordlathach aird-bhunaithe triantánach seicheamh-go-seicheamh a sháraíonn na dúshláin seo trí ligean don mhúnla aird níos mó a thabhairt ar mhodhúlacht an téacs. Tá 2.51 pointe níos fearr ag MAST ná an tsamhail úrscothach (fístéacs) i dtéarmaí scór Ábhar F1 agus 1.00 pointe i dtéarmaí scór Rouge-L ar thacar sonraí How2 maidir le tuiscint teanga ilmhódach.</abstract_ga>
      <abstract_ka>ამ დოკუმენტი MAST- ს ახალი მოდელი მულტიმოდიალური აბსტრაქტიგური ტექსტის კომპანიზაციაში, რომელიც ყველა სამი მოდიალური ინფორმაციის გამოყენება - ტექსტი, ასეთო და ვიდეო -  მულტიმოდიალური აბსტრაქტიური ტექსტის კუნძიზაციაზე მხოლოდ ტექსტის და ვიდეო მოდილიტების გამოყენებული ინფორმაცია. ჩვენ აუდიო მოდიალობიდან ინფორმაციის გამოიყენება და გამოსახულებების გამოყენება და აუდიო მოდიალობიდან მივიღეთ სიკეცემალური თერაქტიკური ინფორმაციის მოდელი, რომელიც ამ გამოსახულებების გამოსახულება, რომელი MAST მოდელის მიმდინარე სტატის მოდულის (ვიდეო- ტექსტის) სტატის განმავლობაზე 2. 51 წერტილით Content F1 წერტილის და 1. 00 წერტილის განმავლობაში Rouge- L წერტილის განმავლობაში How2 მონაცემების მონაცემების მოდულებ</abstract_ka>
      <abstract_hu>A tanulmány bemutatja a MAST-t, a multimodális absztraktív szövegösszefoglaló új modelljét, amely mindhárom módszerből származó információkat használ fel multimodális videóban. A multimodális absztraktív szövegösszefoglalással kapcsolatos korábbi munkák kizárólag a szövegből és a videóból származó információkat használták fel. Vizsgáljuk az audiomódszerből származó információk hasznosságát és kihívásait, és bemutatunk egy szekvenciás, hierarchikus figyelem-alapú trimodális modellt, amely ezeket a kihívásokat leküzdi azzal, hogy a modell nagyobb figyelmet fordít a szövegmódszerre. A MAST 2,51 ponttal haladja meg a jelenlegi korszerű modellt (videó-szöveg) az F1 tartalom és 1,00 ponttal a Rouge-L pontszám tekintetében a How2 adatkészleten a multimodális nyelvértés érdekében.</abstract_hu>
      <abstract_el>Η παρούσα εργασία παρουσιάζει ένα νέο μοντέλο για την Πολυmodale Περίληψη Κειμένου που χρησιμοποιεί πληροφορίες και από τις τρεις λειτουργίες του κειμένου, του ήχου και του βίντεο σε ένα πολυμοδικό βίντεο. Προηγουμένες εργασίες για την πολυπροπική αφηρημένη σύνοψη κειμένου χρησιμοποιούσαν μόνο πληροφορίες από τις λεπτομέρειες κειμένου και βίντεο. Εξετάζουμε τη χρησιμότητα και τις προκλήσεις της απόκτησης πληροφοριών από την ακουστική τροπικότητα και παρουσιάζουμε ένα τριμοντικό ιεραρχικό μοντέλο που βασίζεται στην προσοχή ακολουθίας-ακολουθίας που ξεπερνά αυτές τις προκλήσεις αφήνοντας το μοντέλο να δώσει μεγαλύτερη προσοχή στην τροπικότητα κειμένου. Το MAST ξεπερνά το σημερινό μοντέλο (βίντεο-κείμενο) κατά 2.51 πόντους όσον αφορά την βαθμολογία περιεχομένου F1 και 1.00 πόντους όσον αφορά την βαθμολογία Rouge-L στο σύνολο δεδομένων How2 για την κατανόηση της πολυμορφικής γλώσσας.</abstract_el>
      <abstract_it>Questo articolo presenta MAST, un nuovo modello di sintesi multimodale del testo astratto che utilizza informazioni provenienti da tutte e tre le modalità - testo, audio e video - in un video multimodale. I lavori precedenti sulla sintesi multimodale astratta del testo utilizzavano solo informazioni provenienti dalle modalità testuali e video. Esaminiamo l'utilità e le sfide di ricavare informazioni dalla modalità audio e presentiamo un modello gerarchico di attenzione trimodale sequenza-sequenza che supera queste sfide lasciando che il modello presti maggiore attenzione alla modalità testuale. MAST supera lo stato dell'arte attuale del modello (video-testo) di 2,51 punti in termini di punteggio Content F1 e di 1,00 punti in termini di punteggio Rouge-L sul set di dati How2 per la comprensione multimodale della lingua.</abstract_it>
      <abstract_kk>Бұл қағаз MAST, көпModal Абстрактивті мәтін тұжырымдамасының жаңа үлгісін көрсетеді. Бұл көпModal видеонда мәліметті - мәтін, аудио және видео - барлық үш әдістерден қолданаты Көптеген абстрактивті мәтін тұжырымдамасындағы алдыңғы жұмыс тек мәтін мен видео әдістерінен қолданылған мәліметтер. Мәліметті аудио модулінен алу үшін пайдаланушы мен өзгерістерді тексереміз және реттеу үшін тримодалдық иерархиялық түрінде негізделген үлгісін таңдаймыз. Бұл өзгерістерді өзгерту үшін модулінің мәтін модулін MAST Сурет үлгісінің қазіргі күйі (видео- мәтін) 2. 51 нүкте Content F1 нүктесі мен 1. 00 нүкте бірнеше тілді ойлау үшін How2 деректер жиынындағы Rouge- L нүктесі жоғарылады.</abstract_kk>
      <abstract_lt>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Ankstesniame daugiarūšio pobūdžio abstrakcinio teksto santraukos darbe buvo naudojama tik teksto ir vaizdo būdų informacija. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_lt>
      <abstract_mt>Dan id-dokument jippreżenta MAST, mudell ġdid għas-Sommarju tat-Test Abstrattiv Multimodali li juża l-informazzjoni mit-tliet modalitajiet kollha - test, awdjo u vidjo - f’vidjo multimodali. Ħidma preċedenti dwar is-sommarju tat-test astrattiv multimodali użat biss informazzjoni mit-test u l-modalitajiet tal-vidjo. Aħna teżamina l-utilità u l-isfidi tad-derivazzjoni tal-informazzjoni mill-modalità awdjo u nippreżentaw mudell trimodali b’sekwenza għal sekwenza bbażat fuq l-attenzjoni ġerarkika li jegħleb dawn l-isfidi billi l-mudell jitħalla jagħti aktar attenzjoni lill-modalità tat-test. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_mt>
      <abstract_mk>Овој документ претставува MAST, нов модел за мултимодилна апстрактивна резултатација на текстот кој користи информации од сите три модели - текст, аудио и видео - во мултимодилно видео. Претходната работа за мултимодална апстрактивна резултатација на текстот користеше само информации од текстот и видео моделите. Ние ја испитуваме корисноста и предизвиците од извлекувањето информации од аудио модијалноста и претставуваме тримодален хиерархички модел базиран на секвенца на внимание кој ги надминува овие предизвици со дозвола моделот да привлече поголемо внимание на текстот модијалноста. МАСТ го надминува сегашниот најнов модел (видео-текст) за 2,51 поени во поглед на резултатот на Содржината F1 и 1,00 поени во поглед на резултатот на Руџ-Л на податоците How2 за мултимодилно разбирање на јазикот.</abstract_mk>
      <abstract_mn>Энэ цаас MAST-г олон моделийн бичлэгээс мэдээллийг хэрэглэдэг олон моделийн Abstractive Text Summarization-ийн шинэ загвар болгодог. Бид олон моделийн абстрактив текст цуглуулалт дээр өмнөх ажил зөвхөн текст болон видео хувилбараас хэрэглэгдсэн мэдээлэл. Бид аудио хувилбараас мэдээллийг гаргах хэрэгтэй болон сорилтуудыг шалгаж, дарааллаар дарааллаар давтагдсан гурван төрлийн анхаарал төвлөрүүлэх загварыг илүү анхаарлаа хандуулж, эдгээр сорилтуудыг даван авч, загварыг текст хувилбарт илүү анха MAST Урлагийн загварын орчин үеийг 2.51 цэгээр үржүүлдэг. Content F1 score болон 1.00 цэгээр олон модель хэлний ойлголтын How2 өгөгдлийн сангийн тоо хэлбэрээр Rouge-L score дээр гаргадаг.</abstract_mn>
      <abstract_ms>Kertas ini memperkenalkan MAST, model baru untuk Penapisan Teks Abstratif Multimodal yang menggunakan maklumat dari semua tiga modaliti - teks, audio dan video - dalam video multimodal. Kerja terdahulu pada pengringkasan teks abstraktif multimodal hanya digunakan maklumat dari modaliti teks dan video. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ മൂന്നു രീതികളില്‍ നിന്നും വിവരങ്ങള്‍ ഉപയോഗിക്കുന്ന എല്ലാ വിവരങ്ങളില്‍ നിന്നും മുള്‍ട്ടിമോഡല്‍ അബ്ട്രാക്ട്രാക്ടിവിന്റെ പു പദാവലിയും വീഡിയോ മോഡിറ്റുകളില്‍ നിന്നും വിവരങ്ങളില്‍ നിന്നും ഉപയോഗിക്കുന്ന വിവരങ്ങള്‍ മുമ്പുള്ള ജോലി ഓഡിയോ മോഡിയില്‍ നിന്നും വിവരങ്ങള്‍ ലഭ്യമാക്കുന്നതിന്റെ ഉപയോഗവും വ്യാല്‍ക്രവങ്ങളും ഞങ്ങള്‍ പരിശോധിക്കുന്നു. ട്രിമോണിക്ക് ട്രിമോഡാല്‍ ഹിയെരാര്‍ക്കിക്കല മുള്‍ട്ടിമോഡാല്‍ എഫ്1 സ്കോരും 1. 00 പോയിന്റുകളും ഹൌ2 ഡാറ്റാസ്റ്റേറ്റ് ഗ്രഹിക്കുന്നതിനുള്ള മാതൃകയില്‍ നിലവിലുള്ള സ്ഥിതിയില്‍ 2. 51 പോയിന്റുകള്‍ 2. 51 പ</abstract_ml>
      <abstract_ro>Această lucrare prezintă MAST, un nou model de Rezumare Multimodală a Textului Abstractiv care utilizează informații din toate cele trei modalități - text, audio și video - într-un video multimodal. Lucrările anterioare privind rezumarea textului multimodal abstractiv utilizează doar informații din modalitățile text și video. Examinăm utilitatea și provocările obținerii informațiilor din modalitatea audio și prezentăm un model ierarhic secvență la secvență bazat pe atenție trimodală, care depășește aceste provocări permițând modelului să acorde mai multă atenție modalității text. MAST depășește modelul actual de ultimă generație (video-text) cu 2,51 puncte în ceea ce privește scorul F1 conținut și 1,00 puncte în ceea ce privește scorul Rouge-L pe setul de date How2 pentru înțelegerea limbilor multimodale.</abstract_ro>
      <abstract_pl>W artykule przedstawiono MAST, nowy model multimodalnego podsumowania tekstu abstrakcyjnego, który wykorzystuje informacje ze wszystkich trzech modalności tekstu, audio i wideo w multimodalnym wideo. Wcześniejsze prace nad multimodalną abstrakcyjną streszczeniem tekstu wykorzystywały jedynie informacje z modalności tekstu i wideo. Badamy przydatność i wyzwania związane z pozyskiwaniem informacji z modalności audio i przedstawiamy trimodalny model oparty na uwadze sekwencji na hierarchicznym modelu, który pokonuje te wyzwania poprzez pozwolenie modelowi zwrócić większą uwagę na modalność tekstową. MAST przewyższa aktualny model (wideo-tekst) o 2,51 punkty pod względem wyniku Content F1 oraz 1,00 punkty pod względem wyniku Rouge-L na zbiorze danych How2 dla zrozumienia języka multimodalnego.</abstract_pl>
      <abstract_so>Warqaddaas wuxuu MAST, model cusub oo u qoran qoraalka hoose-dhexe ee multimodal Abstractive, kaas oo macluumaadka ka isticmaalaya saddexda qaab oo dhan - text, audio iyo fiidiyo ah fiidiyo badan. Shaqo horay ah oo ku saabsan qoraalka la'aanta oo kala duduwan oo la isticmaalay macluumaad la isticmaalay qoraalka iyo fiidiyowga. Waxaan baaraynaa faa'iidada iyo dhibaatooyin ku saabsan helitaanka macluumaadka qaababka codka, waxaana keenaynaa model aad u fiirsaneyso marxaladda hierarchiga ah oo ka adkaysanaya dhibaatooyinkaas si aad u fiirsato qaababka qoraalka. MAST wuxuu ku soo bandhigaa xaaladda muusikada farshaxanka (fiidiyo-text) 2.51 barxad oo ku qoran kooxda F1 iyo 1.00 barxad oo lagu qorayo kooxda Rouge-L ee kooxda aqoonta luuqada kala duduwan ee How2.</abstract_so>
      <abstract_sv>Denna uppsats presenterar MAST, en ny modell för multimodal abstraktiv textsammanfattning som använder information från alla tre modaliteterna - text, ljud och video - i en multimodal video. Tidigare arbete med multimodal abstraktiv textsammanfattning utnyttjade endast information från text- och videomodaliteter. Vi undersöker nyttan och utmaningarna med att härleda information från ljudmodaliteten och presenterar en sekvens-till-sekvens trimodal uppmärksamhetsbaserad modell som övervinner dessa utmaningar genom att låta modellen ägna mer uppmärksamhet åt textmodaliteten. MAST överträffar den nuvarande toppmoderna modellen (video-text) med 2,51 poäng när det gäller Content F1 poäng och 1,00 poäng när det gäller Rouge-L poäng på How2 datauppsättningen för multimodal språkförståelse.</abstract_sv>
      <abstract_ta>இந்த தாள் MAST, ஒரு புதிய மாதிரியை கொடுக்கும் பல மாதிரி Abstractive Text சுருக்கமாக்கும் அது அனைத்து மூன்று வகைகளிலிருந்தும் தகவலை பயன்படுத்துகிறது -  பலவிதமான செயல்பாடு உரை சுருக்கம் மட்டும் உரை மற்றும் வீடியோ வகைகளிலிருந்து பயன்படுத்தப்பட்ட தகவல் முன்னிருப்பு பணி கேட்பொலி வகையிலிருந்து தகவல் பெறுவதற்கான பயன்பாட்டுகளையும் சவால்களையும் நாம் பரிசோதிக்கிறோம் மற்றும் ஒரு வரிசையில் இருந்து மூன்று தொடர்ந்து மூன்று ம MAST தற்போதைய கலைப்பாட்டு மாதிரியின் தற்போதைய நிலையை 2. 51 புள்ளிகளால் செயல்படுத்தும் உள்ளடக்க F1 மதிப்பு மற்றும் 1. 00 புள்ளி</abstract_ta>
      <abstract_sr>Ovaj papir predstavlja MAST, novi model za sažetak multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom video. Prije rad na sažetku multimodalnog abstraktivnog teksta korišteno je samo informacije iz teksta i video modaliteta. Ispitujemo korisnost i izazove izvlačenja informacija iz audio modaliteta i predstavljamo sekvencu trimodalnog hijerarhičkog model a baziranog na sekvenci, koji prevlada te izazove tako što omogućavamo model da obratite više pažnje na tekstualnu modalitetu. MAST iznosi trenutno stanje umjetničkog modela (video-tekst) sa 2,51 poena u smislu rezultata Content F1 i 1,00 poena u smislu rezultata Rouge-L na setu podataka How2 za razumevanje multimodalnog jezika.</abstract_sr>
      <abstract_no>Denne papiret viser MAST, eit ny modell for multimodal abstraktiv tekstsamandrag som brukar informasjon frå alle tre modular – tekst, lyd og video – i eit multimodal video. Førre arbeid på multimodal abstraktiv tekstsammendering er berre brukt informasjon frå teksten og videomodusane. Vi undersøker nødvendigheten og utfordringar for å få informasjon frå lyd-modulitet og presenterer ein trimodal hierarkisk oppmerksbasert modell som overfører desse utfordringane ved å la modellen få meir oppmerksomhet til tekstmodulitet. MAST utfører den gjeldande tilstanden til kunstmodellen (video-tekst) med 2,51 punkt i forhold til innhaldet F1- poeng og 1,00 punkt i forhold til Rouge- L- poeng på How2- datasettet for multimodal språksforståelse.</abstract_no>
      <abstract_ur>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that uses information from all three modalities - text, audio and video - in a multimodal video. multimodal abstractive text summarization پر پہلے کام صرف متن اور ویڈیو موڈلیٹ سے استعمال کی جاتی ہے. ہم آڈیو موڈلیٹ سے اطلاعات اٹھانے کے کامیابی اور چالوں کے مطابق تحقیق کرتے ہیں اور آڈیو موڈلیٹ سے اٹھانے کے لئے تیموڈالی توجه کی مدل کو پیش کرتے ہیں جو ان چالوں پر غالب آتا ہے اور مدل کو متن موڈلیٹ کے لئے زیادہ توجه کرنا اجازت دیتے ہیں. MAST آرت موڈل (ویڈیو-ٹکسٹ) کی موجود موجود موجود موجود کو 2.51 پوینٹ کے مطابق موجود F1 پوینٹ اور 1.00 پوینٹ کے مطابق موجود زبان سمجھنے کے لئے Hauge-L پوینٹ کے مطابق موجود موجود ہے.</abstract_ur>
      <abstract_si>මේ පැත්ත MAST වෙනුවෙන්, අළුත් මොඩියෝල් අවස්ථාවක් පැත්තක් සංවේදනය සඳහා අළුත් මොඩියෝල් එකක් පෙනුවෙන් පෙනුවෙන් ති පාළුවන් සහ විඩියෝ මොඩියෝල් විධානයෙන් විතරයි ප්‍රභාවිත විතරයි. අපි ප්‍රයෝජනය සහ අවධානය පරීක්ෂා කරනවා ඔඩියෝ මෝඩියෝලියෙන් තොරතුරු ගන්න සහ ප්‍රයෝජනය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ත්‍රිමෝඩාල MAST ප්‍රස්තූති විද්‍යාත්මක (විඩියෝ- පාට්ස්) 2.51 පින්තුවක් වලින් විද්‍යාත්මක F1 ස්කෝර් වලින් සහ 1.00 පින්තුවක් වලින් Rouge- L ස්කෝර් වලි</abstract_si>
      <abstract_vi>Tờ giấy này giới thiệu MAST, một mô hình mới cho Sơ sài Văn bản đa phương, dùng thông tin từ ba phương thức - văn bản, âm thanh và video- trong một đoạn video đa phương. Việc tổng hợp văn bản trừu tượng đa phương chỉ sử dụng thông tin từ phương thức văn bản và đoạn video. Chúng tôi xem xét sự hữu ích và thử thách của việc lấy thông tin từ chế độ âm thanh và trình bày một mô hình cấp độ phân cấp cấp ba phân loại theo quy trình sắp xếp phân loại để vượt qua những thử thách này bằng cách để mô hình chú ý nhiều hơn đến kiểu văn bản. MAST thực hiện hiện hiện trạng thái hiện thời của mô hình nghệ thuật (đoạn video) bởi 2.51 Point theo như vẫn còn trong nội dung F1.00 theo giá trị ghi số Rouge-L trên tập tin Howl2 để hiểu ngôn ngữ đa phương.</abstract_vi>
      <abstract_uz>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Name Biz audio modulidan maʼlumotni olish uchun foydalanuvchi va muammolarni tekshirib ko'rib chiqaramiz va bu muammolarni matn moduliga qo'llash mumkin, bu muammolarni oshirish mumkin. MAST multimodal tilni tushunish uchun Joriy sanam modeli (video- text) 2. 51 нуқтаи bilan ishga tushiriladi.</abstract_uz>
      <abstract_nl>Deze paper presenteert MAST, een nieuw model voor multimodale abstracte tekstsamenvatting dat informatie uit alle drie de modaliteiten van tekst, audio en video in een multimodale video gebruikt. Voorafgaand werk aan multimodale abstracte tekstsamenvatting gebruikte alleen informatie uit de tekst- en videomodaliteiten. We onderzoeken het nut en de uitdagingen van het afleiden van informatie uit de audiomodaliteit en presenteren een sequentie-to-sequence trimodaal hiërarchisch aandachtsgebaseerd model dat deze uitdagingen overwinnt door het model meer aandacht te laten besteden aan de tekstmodaliteit. MAST overtreft het huidige state-of-the-art model (video-tekst) met 2.51 punten in termen van Content F1 score en 1.00 punten in termen van Rouge-L score op de How2 dataset voor multimodaal taalbegrip.</abstract_nl>
      <abstract_bg>Настоящата статия представя нов модел за мултимодално абстрактивно обобщаване на текста, който използва информация от трите модала - текст, аудио и видео - в мултимодално видео. Предишната работа по мултимодалното абстрактно обобщаване на текста използва само информация от текстовите и видео модалите. Проучваме полезността и предизвикателствата при извличането на информация от аудио модалността и представяме тримодален йерархичен модел последователност към последователност, базиран на вниманието, който преодолява тези предизвикателства, като позволява на модела да обърне повече внимание на текстовия модал. МАСТ превъзхожда съвременния модел (видео-текст) с 2.51 точки по отношение на резултата Съдържание 1 и 1.00 точки по отношение на резултата Руж-Л в набора данни за мултимодално разбиране на езика.</abstract_bg>
      <abstract_hr>Ovaj papir predstavlja MAST, novi model za sažetak multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom snimku. Prije rad na sažetku multimodalnog abstraktivnog teksta korišteno je samo informacije iz teksta i video modaliteta. Provjeravamo korisnost i izazove izvlačenja informacija iz zvukovnog modaliteta i predstavljamo trimodalni model na osnovu tri modalne hijerarhijske pažnje koji prevlada te izazove tako što omogućavamo model obratiti više pažnje na modalitet teksta. MAST iznosi trenutno stanje umjetničkog modela (video-teksta) za 2,51 bodova u smislu rezultata Content F1 i 1,00 bodova u smislu rezultata Rouge-L na kompletu How2 podataka za razumijevanje multimodalnog jezika.</abstract_hr>
      <abstract_de>Dieser Beitrag stellt MAST vor, ein neues Modell für multimodale abstrakte Textzusammenfassung, das Informationen aus allen drei Modalitäten Text, Audio und Video in einem multimodalen Video nutzt. Bisherige Arbeiten zur multimodalen abstraktiven Textzusammenfassung nutzten ausschließlich Informationen aus den Text- und Videomodalitäten. Wir untersuchen die Nützlichkeit und Herausforderungen der Ableitung von Informationen aus der Audiomodalität und stellen ein sequenz-zu-sequenz trimodales hierarchisches aufmerksamkeitsbasiertes Modell vor, das diese Herausforderungen überwindet, indem das Modell mehr Aufmerksamkeit auf die Textmodalität lenkt. MAST übertrifft den aktuellen Stand der Technik Modell (Video-Text) um 2,51 Punkte in Bezug auf Content F1 Score und 1,00 Punkte in Bezug auf Rouge-L Score auf dem How2 Datensatz für multimodales Sprachverständnis.</abstract_de>
      <abstract_da>Denne artikel præsenterer MAST, en ny model for multimodal abstraktiv tekst summering, der bruger information fra alle tre modaliteter - tekst, lyd og video - i en multimodal video. Tidligere arbejde med multimodal abstraktiv tekst resuméering anvendte kun oplysninger fra tekst og video modaliteter. Vi undersøger nytten og udfordringerne ved at udlede information fra lydmodaliteten og præsenterer en sekvens-til-sekvens trimodal hierarkisk opmærksomhedsbaseret model, der overvinder disse udfordringer ved at lade modellen være mere opmærksom på tekstmodaliteten. MAST overgår den aktuelle state of te art model (video-tekst) med 2,51 point i form af Content F1 score og 1,00 point i form af Rouge-L score på How2 datasættet til multimodal sprogforståelse.</abstract_da>
      <abstract_id>Kertas ini mempersembahkan MAST, model baru untuk Penapisan Teks Abstraktif Multimodal yang menggunakan informasi dari tiga modalitas - teks, audio dan video - dalam video multimodal. Pekerjaan sebelumnya pada penghasilan teks abstraktif multimodal hanya menggunakan informasi dari modalitas teks dan video. Kami memeriksa kebaikan dan tantangan untuk mendapatkan informasi dari modalitas audio dan mempersembahkan model berkurunan-ke-urutan yang berdasarkan perhatian trimodal yang mengatasi tantangan-tantangan ini dengan membiarkan model memperhatikan modalitas teks lebih banyak. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_id>
      <abstract_fa>این کاغذ MAST را نشان می‌دهد، یک مدل جدید برای جمع کردن متن آب‌تراکتی چندیmodal که اطلاعات را از همه سه حالت - متن، صدا و ویدئو - در یک ویدئو چندیmodal استفاده می‌کند. کارهای پیشینه روی جمع کردن متن متن چندmodal abstractive تنها اطلاعات استفاده از متن و modalities ویدئو استفاده می‌شود. ما مطالبی و چالش‌های استفاده از دسترسی اطلاعات از مدل صدا را تحقیق می‌کنیم و یک مدل توجه به مدل سه مدل از مدل‌های مختلف به عنوان مدل توجه به مدل متن را پیشنهاد می‌کنیم که این چالش‌ها را از دست می‌دهد، با اجازه دادن مدل توجه بیشتری به مدل مت MAST موقعیت فعلی مدل هنر (ویدئو-متن) با 2.51 نقطه به عنوان نقطه محتوای F1 و 1.00 نقطه به عنوان نقطه‌ای Rouge-L بر روی مجموعه داده‌های How2 برای درک زبان‌های متعددی بیشتر انجام می‌دهد.</abstract_fa>
      <abstract_ko>본고는 다중모드 추상적 텍스트 요약 모델인 MAST를 제시했는데 다중모드 영상의 모든 세 가지 모드(텍스트, 오디오, 영상)의 정보를 이용했다.이전에 다중모드 추상적인 텍스트 요약에 대한 작업은 텍스트와 영상 모드의 정보만 이용했다.우리는 오디오 모드에서 정보를 추출하는 유용성과 도전을 연구했고 서열을 바탕으로 하는 삼모드 차원 주의 모델을 제시했다. 이 모델은 모델이 텍스트 모드에 더욱 관심을 가지게 함으로써 이러한 도전을 극복한다.다중모드 언어 이해에 사용되는 How2 데이터 집합에서 MAST는 콘텐츠 F1 득점 면에서 현재 가장 선진적인 모델(영상 텍스트)보다 2.51점, Rouge-L 득점 면에서 현재보다 1.00점 높았다.</abstract_ko>
      <abstract_sw>Makala hii inaonyesha MAST, mfano mpya kwa ajili ya Ujumbe wa Matambo ya Kimulmodal Abstractive unaotumia taarifa kutoka katika a in a tatu - maandishi, sauti na video - katika video mbalimbali. Kazi ya awali kuhusu muhtasari wa ujumbe wa maandishi yasiyo na maandishi mengi yaliyotumika tu kwa kutumia taarifa kutoka kwenye njia za maandishi na video. Tunajaribu matumizi na changamoto za kupata taarifa kutoka katika mfumo wa sauti na kuweka muundo wa ufuatiliaji wa mifumo ya mitatu kwa mfululizo ambao unashinda changamoto hizi kwa kuruhusu model kusikiliza zaidi kwa namna ya maandishi. MAST inaonyesha hali ya sasa ya muundo wa sanaa (ujumbe wa video-text) kwa pointi 2.51 kwa maana ya score F1 na pointi 1.00 kwa mujibu wa score ya Rouge-L kwenye seti ya data ya How2 kwa ajili ya kuelewa lugha nyingine.</abstract_sw>
      <abstract_tr>Bu käze MAST'i, Multimodal Abstraktiw Metin Toplaýyşy üçin täze bir nusga görkezýär ki bu multimodal wideoda maglumat ullanýar. Multimodal abstraktiv metin holasasy üstünde öňki işlem diňe metin we video modlerden ullanýar Biz ses modalitatyndan informasiýa çykarmak üçin ullanlygyny we çözgütlerini barlaýarys we bu kynçylyklaryň üstüne çykan trimodal iýerarhiýa tabanly nusgasyny çykarýarys we modaliýasyna köp üns ber. MAST sanat düzümleriniň häzirki durumyny 2.51 puç diýipdir. Mazmunlar F1 अ'da we 1.00 puç diýipdir.</abstract_tr>
      <abstract_am>ይህ ገጽ አዲስ የፊደል አዲስ ምሳሌ ለመብሎዶል Abstractive ጽሑፍ ማጠቃለያ ነው፡፡ የጽሑፍ እና የቪዲዮ ድርጅቶች በተጠቃሚ የጽሑፍ ማስታወሻ ብቻ ነው፡፡ የድምፅ አካባቢ መረጃዎችን ለማግኘት ጥቅም እና ውቀቶችን እናፈትናለን፡፡ የፊደል ቅርጽ</abstract_am>
      <abstract_sq>Ky dokument paraqet MAST, një model i ri për përmbledhjen e tekstit abstraktiv multimodal që përdor informacionin nga të tre modalitetet - teksti, audio dhe video - në një video multimodal. Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities.  Ne shqyrtojmë dobinë dhe sfidat e marrjes së informacionit nga modaliteti audio dhe paraqesim një model trimodal sekuencë-në-sekuencë të bazuar në vëmendjen hierarkike që i kapërcen këto sfida duke lejuar modelit të kushtojë më shumë vëmendje modalitetit të tekstit. MAST ekzekuton gjendjen aktuale të modelit të artit (video-text) me 2.51 pikë lidhur me pikën e përmbajtjes F1 dhe 1.00 pikë lidhur me pikën e kuqe-L në kompletin e të dhënave How2 për kuptimin multimodal të gjuhës.</abstract_sq>
      <abstract_af>Hierdie papier vertoon Mast, 'n nuwe model vir Multimodal Abstractive Teks Opsomming wat inligting gebruik van alle drie modaliteite - teks, oudio en video - in 'n multimodaal video. Vorige werk op multimodale abstraktiewe teks opsomming slegs gebruikte inligting van die teks en video modaliteite. Ons ondersoek die bruikbaarheid en uitdagings van afgeleide inligting van die oudio modaliteit en voorsien 'n volgorde-na-volgorde trimodaal hierarkiese aandag-gebaseerde model wat hierdie uitdagings oorwin deur die model meer aandag aan die teks modaliteit te laat maak. Mas uitvoer die huidige staat van die kuns model (video- text) deur 2. 51 punte in terms van Inhoud F1 telling en 1. 00 punte in terms van Rouge- L telling op die How2 datastel vir multimodale taal verstanding.</abstract_af>
      <abstract_hy>Այս հոդվածը ներկայացնում է MASTA-ը, մի նոր մոդել, որը օգտագործում է բազմամոդալ վերացական տեքստի համառոտացման համար տեղեկատվությունը բոլոր երեք մոդելներից՝ տեքստից, ձայնից և տեսահոլովակից, բազմամոդալ տեսահոլովակում: Անցյալ աշխատանքը բազմամոդալ վերացական տեքստի համառոտագրման վրա օգտագործեց միայն տեքստի և տեսագրական մեթոդների տեղեկատվությունը: Մենք ուսումնասիրում ենք հնչյունների միջոցով տեղեկատվության ստանալու օգտակարությունը և մարտահրավերները և ներկայացնում ենք հաջորդականությունից հաջորդականություն առնող տրամոդային հիերարխիկ ուշադրության հիմնված մոդել, որը հաղթահարում է այս մարտահրավերները, թույլ տալով մոդելը ավելի ու MASTA-ն արտադրում է ներկայիս ամենահարվեստի մոդելը (տեսագրական տեքստը) 2.51 միավորով F1-ի պարունակության և 1.00 միավորով Rուգ-L-ի պարունակության առումով, որը կազմում է բազմամոդալ լեզվի հասկանալու մասին Հոյ2 տվյալների համակարգում:</abstract_hy>
      <abstract_az>Bu kağıt çoxlu modal Abstraktiv Metin Toplaşdırması üçün yeni bir modeli MAST'i göstərir ki, çoxlu modal videoda məlumatları - metin, audio və video ilə istifadə edir. Çoxlu modal abstraktiv metin qeyd edilməsindən əvvəlki işlər yalnız metin və video modüllərindən istifadə edilmişdir. Biz audio modaliyyətindən məlumatların faydalanılığını və çətinliklərini incidirik və sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama-sıralama modelini göstəririk ki, bu çətinliklərə üstün gəlir MAST sanat model in in (video-text) ağımdaki durumunu 2.51 pünkt ilə Content F1 score ilə və çox modal dil anlaşılması üçün How2 veri qutusu ilə Rouge-L score ilə 1.00 pünkt göstərir.</abstract_az>
      <abstract_bn>এই পত্রিকাটি মাল্টিমোডাল আবট্রাক্টিভ টেক্সট সামারিজেশনের জন্য একটি নতুন মডেল মাস্টিকে উপস্থাপন করেছে, যা সব তিন মোডেল থেকে তথ্য ব্যবহার করে -  মাল্টিমোডাল অক্ষরিক টেক্সট সংক্ষেপের প্রাথমিক কাজ শুধুমাত্র লেখা এবং ভিডিও মডেল থেকে তথ্য ব্যবহার করা হয় আমরা অডিও মোডেল থেকে তথ্য পাওয়ার কার্যকর এবং চ্যালেঞ্জ পরীক্ষা করি এবং ত্রিমোডাল হিয়ারার্কিকাল ভিত্তিক মডেল উপস্থাপন করি যা এই চ্যালেঞ্জের উপর জয়ী হয়েছে এবং মড মাস্টির বর্তমান শিল্প মডেল (ভিডিও- টেক্সট) দ্বারা ২. 51 পয়েন্ট প্রদর্শন করে বিষয়বস্তু F1 স্কোর এবং ১. ০০ পয়েন্টের মাধ্যমে রোউজ- L স্কোর বিভিন্ন মানুষে</abstract_bn>
      <abstract_et>Käesolevas töös tutvustatakse MAST-i, uut mudelit multimodaalse teksti kokkuvõtmiseks, mis kasutab informatsiooni kõigist kolmest mudelist - teksti, heli ja video - multimodaalses videos. Mitmeliigilise abstraktse teksti kokkuvõtte varasem töö kasutas ainult teksti- ja videomudelite infot. Uurime audiomodaalsusest teabe saamise kasulikkust ja väljakutseid ning esitame järjestusest järjestuseni trimodaalse hierarhilise tähelepanu põhineva mudeli, mis lahendab need väljakutsed, lubades mudelil pöörata rohkem tähelepanu tekstimodaalsusele. MAST ületab praeguse tehnika mudeli (video-tekst) 2,51 punkti võrra sisu F1 skoori ja 1,00 punkti Rouge-L skoori How2 andmekogumi mitmeliigilise keele mõistmise kohta.</abstract_et>
      <abstract_ca>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities.  We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_ca>
      <abstract_cs>Tento článek představuje MAST, nový model multimodální abstrakční textové shrnutí, který využívá informace ze všech tří modalit textu, audio a videa v multimodálním videu. Předchozí práce na multimodální abstraktivní shrnutí textu využívaly pouze informace z textových a video modalit. Zkoumáme užitečnost a výzvy odvození informací z audio modality a představujeme trimodální hierarchický model založený na pozornosti, který tyto výzvy překonává tím, že model nechá věnovat větší pozornost modalitě textu. MAST překonává současný model (video-text) o 2,51 body z hlediska skóre obsahu F1 a 1,00 bodů z hlediska skóre Rouge-L na datové sadě How2 pro multimodální porozumění jazyků.</abstract_cs>
      <abstract_fi>Tässä artikkelissa esitellään MAST, uusi malli multimodaalisen abstraktin tekstin yhteenvetoon, joka hyödyntää tietoa kaikista kolmesta modaalista - teksti, ääni ja video - multimodaalisessa videossa. Aikaisemmassa multimodaalisessa abstraktiivisessa tekstiyhteenvedossa hyödynnettiin vain teksti- ja videomodaaleista saatavaa tietoa. Tutkimme audiomodaalista tiedon tuottamisen hyödyllisyyttä ja haasteita ja esittelemme sekvenssi-sekvenssiin trimodaalisen hierarkkisen huomiopohjaisen mallin, joka voittaa nämä haasteet antamalla mallin kiinnittää enemmän huomiota tekstimodaalisuuteen. MAST ylittää nykytekniikan mallin (video-teksti) 2,51 pisteellä Content F1 -pisteellä ja Rouge-L-pisteellä multimodaalisen kielen ymmärtämisen How2-aineistossa 1,00 pisteellä.</abstract_fi>
      <abstract_bs>Ovaj papir predstavlja MAST, novi model za rezervaciju multimodalnog abstraktivnog teksta koji koristi informacije iz svih tri moda - tekst, audio i video - u multimodalnom video. Prije rad na sažetku multimodalnog abstraktivnog teksta koristio je samo informacije iz teksta i video modaliteta. Provjeravamo korisnost i izazove izvlačenja informacija iz audio modaliteta i predstavljamo trimodalni model na osnovu tri-sekvence na osnovu hijerarhijske pažnje koji prevlada te izazove tako što omogućavamo modelu da obratite više pažnje na tekstualnu modalitetu. MAST iznosi trenutno stanje umjetničkog modela (video-teksta) sa 2,51 bodova u smislu rezultata Content F1 i 1,00 bodova u smislu rezultata Rouge-L na setu podataka How2 za razumijevanje multimodalnog jezika.</abstract_bs>
      <abstract_jv>Gambar iki nambah MART, model sing bagu kanggo Multimodal absolute Text Samurasi sing nggawe informasi ning saben telu modalitat - teks, video lan video - ning video multimodal. Samsul Awak dhéwé éntuk sistem usahaan lan susahé awak dhéwé nggambar informasi ning modalité surat lan gabung ning acara sekène-to-sekène trimodal karo akeh nyong lanjut model sing isiné berarti dhéwé kuwi nggawe modalité teka. MART iso nggambar kalagayet coro Mulalat (video-text) 2.31 punti, ditambalo Content F1 punti lan 1.00 punti</abstract_jv>
      <abstract_sk>Ta prispevek predstavlja MAST, nov model za multimodalno povzetek besedila, ki uporablja informacije iz vseh treh modalitet - besedila, avdio in video - v multimodalnem videu. Predhodno delo na multimodalnem abstraktivnem povzetku besedila je uporabljalo le informacije iz besedilnih in video modalih. Preučujemo uporabnost in izzive pridobivanja informacij iz avdio modalnosti in predstavljamo trimodalni hierarhični model, ki temelji na pozornosti, ki te izzive premaga tako, da model več pozornosti nameni besedilni modalnosti. MAST presega trenutno najsodobnejši model (video-besedilo) za 2,51 točke v smislu rezultata vsebine F1 in 1,00 točke v smislu rezultata Rouge-L na naboru podatkov How2 za razumevanje multimodalnega jezika.</abstract_sk>
      <abstract_ha>Wannan takardar gaske na gaurar MAS, wata wata shekara na ƙarami wa masu multi-modal Abtractive Text Summariɗar da ke amfani da information daga duk tsari uku - rubutu, sauna da video - cikin wani video mai yawa. Kayyar aikin aiki na multi-multi-dural separation of text only used in amfani da information from modalities na text and video. Tuna jarraba amfani da masu kanana ga motsi daga tsari na saurãre kuma muna gaura wata misali mai sauri-sauri-sauri-dubi-sauri, wanda ke rinjãya masu hanyoyin wannan, da kuma ya yarda motel ya zama masu sauna ga tsarin matsayin. MASA na ƙididdige halin da ke yanzu kamar misalin sanar (video-text) da 2.51 points cikin muhimman F1 score da 1.0 points cikin muhimman kwanan rubutun Rouge-L kan tsarin maɓallin How2 wa gane multi-multi-language.</abstract_ha>
      <abstract_bo>ཤོག་བྱང་འདིས་ MAST སྟོན་པ་དང་རྣམ་གྲངས་འདྲ་བའི་སྣ་ཚོགས་རྣམ་གྲངས་སྒྲིག་མཛོད་ཁུངས་ཀྱི་མ་དབྱིབས་གསར་པ་ཞིག་སྟོན་ཐུབ་པའི་ཐབས་ལམ་གསུམ Multimodal abstractive text summarization་གི་སྔོན་གྱི་ལས་སྤྱོད་རྒྱུ་དངོས་ཡིག་གེ་དང་བརྙན་རིས་ཐབས་ལམ་ནང་ལས་ལག་ལེན་འཐབ་པའི་བརྡ་སྟོན་དགོས We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality. MAST outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.</abstract_bo>
      <abstract_he>This paper presents MAST, a new model for Multimodal Abstractive Text Summarization that utilizes information from all three modalities - text, audio and video - in a multimodal video.  עבודה קודמת על סדרת טקסט מולטלמודלית אוסטרקטיבית השתמשה רק במידע מהטקסט והוידאו מודליות. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality.  MAST מציג את המצב הנוכחי של מודל האומנות (וידאו-טקסט) ב-2.51 נקודות במונחים של תוכן F1 ו-1.00 נקודות במונחים של תואר רוג-L על קבוצת נתונים How2 להבנה multimodal לשפה.</abstract_he>
      </paper>
    <paper id="9">
      <title>Reasoning Over History : Context Aware Visual Dialog</title>
      <author><first>Muhammad</first><last>Shah</last></author>
      <author><first>Shikib</first><last>Mehri</last></author>
      <author><first>Tejas</first><last>Srinivasan</last></author>
      <pages>75–83</pages>
      <abstract>While neural models have been shown to exhibit strong performance on single-turn visual question answering (VQA) tasks, extending VQA to a multi-turn, conversational setting remains a challenge. One way to address this challenge is to augment existing strong neural VQA models with the mechanisms that allow them to retain information from previous dialog turns. One strong VQA model is the <a href="https://en.wikipedia.org/wiki/Medium_access_control">MAC network</a>, which decomposes a <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> into a series of attention-based reasoning steps. However, since the <a href="https://en.wikipedia.org/wiki/Medium_access_control">MAC network</a> is designed for single-turn question answering, it is not capable of referring to past dialog turns. More specifically, it struggles with <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> that require reasoning over the dialog history, particularly <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>. We extend the MAC network architecture with Context-aware Attention and Memory (CAM), which attends over control states in past dialog turns to determine the necessary reasoning operations for the current question. MAC nets with CAM achieve up to 98.25 % accuracy on the CLEVR-Dialog dataset, beating the existing state-of-the-art by 30 % (absolute). Our <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error analysis</a> indicates that with <a href="https://en.wikipedia.org/wiki/Computer-aided_manufacturing">CAM</a>, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s performance particularly improved on questions that required <a href="https://en.wikipedia.org/wiki/Coreference">coreference resolution</a>.</abstract>
      <url hash="6697a871">2020.nlpbt-1.9</url>
      <doi>10.18653/v1/2020.nlpbt-1.9</doi>
      <video href="https://slideslive.com/38939783" />
      <bibkey>shah-etal-2020-reasoning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr-dialog">CLEVR-Dialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visdial">VisDial</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
  </volume>
</collection>