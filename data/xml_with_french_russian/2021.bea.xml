<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.bea">
  <volume id="1" ingest-date="2021-04-19">
    <meta>
      <booktitle>Proceedings of the 16th Workshop on Innovative Use of NLP for Building Educational Applications</booktitle>
      <editor><first>Jill</first><last>Burstein</last></editor>
      <editor><first>Andrea</first><last>Horbach</last></editor>
      <editor><first>Ekaterina</first><last>Kochmar</last></editor>
      <editor><first>Ronja</first><last>Laarmann-Quante</last></editor>
      <editor><first>Claudia</first><last>Leacock</last></editor>
      <editor><first>Nitin</first><last>Madnani</last></editor>
      <editor><first>Ildikó</first><last>Pilán</last></editor>
      <editor><first>Helen</first><last>Yannakoudakis</last></editor>
      <editor><first>Torsten</first><last>Zesch</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>April</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="8a6b2c7d">2021.bea-1.0</url>
      <bibkey>bea-2021-innovative</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Text Simplification by Tagging<fixed-case>T</fixed-case>ext <fixed-case>S</fixed-case>implification by <fixed-case>T</fixed-case>agging</title>
      <author><first>Kostiantyn</first><last>Omelianchuk</last></author>
      <author><first>Vipul</first><last>Raheja</last></author>
      <author><first>Oleksandr</first><last>Skurzhanskyi</last></author>
      <pages>11–25</pages>
      <abstract>Edit-based approaches have recently shown promising results on multiple monolingual sequence transduction tasks. In contrast to conventional sequence-to-sequence (Seq2Seq) models, which learn to generate text from scratch as they are trained on parallel corpora, these methods have proven to be much more effective since they are able to learn to make fast and accurate transformations while leveraging powerful pre-trained language models. Inspired by these ideas, we present TST, a simple and efficient Text Simplification system based on sequence Tagging, leveraging pre-trained Transformer-based encoders. Our system makes simplistic data augmentations and tweaks in training and <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a> on a pre-existing system, which makes it less reliant on large amounts of parallel training data, provides more control over the outputs and enables faster <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference speeds</a>. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves near state-of-the-art performance on benchmark test datasets for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Since <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is fully non-autoregressive, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> achieves faster inference speeds by over 11 times than the current state-of-the-art text simplification system.</abstract>
      <url hash="065ea94e">2021.bea-1.2</url>
      <bibkey>omelianchuk-etal-2021-text</bibkey>
      <pwccode url="https://github.com/grammarly/gector" additional="false">grammarly/gector</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/asset">ASSET</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/turkcorpus">TurkCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikilarge">WikiLarge</pwcdataset>
    </paper>
    <paper id="5">
      <title>Broad Linguistic Complexity Analysis for Greek Readability Classification<fixed-case>G</fixed-case>reek Readability Classification</title>
      <author><first>Savvas</first><last>Chatzipanagiotidis</last></author>
      <author><first>Maria</first><last>Giagkou</last></author>
      <author><first>Detmar</first><last>Meurers</last></author>
      <pages>48–58</pages>
      <abstract>This paper explores the linguistic complexity of Greek textbooks as a readability classification task. We analyze textbook corpora for different school subjects and textbooks for <a href="https://en.wikipedia.org/wiki/Greek_language">Greek</a> as a Second Language, covering a very wide spectrum of school age groups and proficiency levels. A broad range of quantifiable linguistic complexity features (lexical, morphological and syntactic) are extracted and calculated. Conducting experiments with different <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">feature subsets</a>, we show that the different linguistic dimensions contribute orthogonal information, each contributing towards the highest result achieved using all linguistic feature subsets. A readability classifier trained on this basis reaches a <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">classification accuracy</a> of 88.16 % for the <a href="https://en.wikipedia.org/wiki/Greek_language">Greek</a> as a Second Language corpus. To investigate the generalizability of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification models</a>, we also perform cross-corpus evaluations. We show that the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> trained on the most varied text collection (for <a href="https://en.wikipedia.org/wiki/Ancient_Greek">Greek</a> as a school subject) generalizes best. In addition to advancing the state of the art for Greek readability analysis, the paper also contributes insights on the role of different feature sets and training setups for generalizable readability classification.</abstract>
      <url hash="8904c1b6">2021.bea-1.5</url>
      <bibkey>chatzipanagiotidis-etal-2021-broad</bibkey>
    </paper>
    <paper id="10">
      <title>Parsing Argumentative Structure in English-as-Foreign-Language Essays<fixed-case>E</fixed-case>nglish-as-Foreign-Language Essays</title>
      <author><first>Jan Wira Gotama</first><last>Putra</last></author>
      <author><first>Simone</first><last>Teufel</last></author>
      <author><first>Takenobu</first><last>Tokunaga</last></author>
      <pages>97–109</pages>
      <abstract>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy. The <a href="https://en.wikipedia.org/wiki/Parsing">parsing process</a> consists of two steps, linking related sentences and then labelling their relations. We experiment with several deep learning architectures to address each <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> independently. In the sentence linking task, a biaffine model performed the best. In the relation labelling task, a fine-tuned BERT model performed the best. Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. We trained our models using two types of parallel texts : original noisy EFL essays and those improved by annotators, then evaluate them on the original <a href="https://en.wikipedia.org/wiki/Essay">essays</a>. The experiment shows that an end-to-end in-domain system achieved an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of.341. On the other hand, the cross-domain system achieved 94 % performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.</abstract>
      <url hash="6ccc28c6">2021.bea-1.10</url>
      <bibkey>putra-etal-2021-parsing</bibkey>
      <pwccode url="https://github.com/wiragotama/bea2021" additional="false">wiragotama/bea2021</pwccode>
    <title_ar>تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية</title_ar>
      <title_fr>Analyse De La Structure Argumentative En Anglais Langue Étrangère Essais</title_fr>
      <title_pt>Analisando a estrutura argumentativa em ensaios de inglês como língua estrangeira</title_pt>
      <title_es>Análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera</title_es>
      <title_ja>英語と外国語のエッセイにおける議論構造の解析</title_ja>
      <title_zh>解析英语为外语论文证结</title_zh>
      <title_ru>Анализ аргументативной структуры в эссе на английском и иностранном языках</title_ru>
      <title_ga>Struchtúr Argóinteach a Pharsáil i mBéarla-mar-Earrach-Aistí</title_ga>
      <title_hi>पार्सिंग तर्कपूर्ण संरचना में अंग्रेजी के रूप में विदेशी भाषा निबंध</title_hi>
      <title_ka>აპდუმენტეტიური სტრუქტურაცია ანგლისური-as-Foreign-Language Essays</title_ka>
      <title_hu>Argumentatív struktúra értelmezése angol mint idegen nyelvű esszékben</title_hu>
      <title_el>Ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικής ως ξένης γλώσσας</title_el>
      <title_it>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_it>
      <title_kk>Аргументтік құрылғыны ағылшын тілінде талдау</title_kk>
      <title_lt>Argumentacinės struktūros analizavimas anglų kalbos testuose</title_lt>
      <title_mk>Аргументација на аргументативната структура во тестовите на англиски како странски јазик</title_mk>
      <title_ms>Menghurai Struktur Argumentatif dalam Ujian Bahasa Inggeris-sebagai-Luar-Bahasa</title_ms>
      <title_mt>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_mt>
      <title_ml>ഇംഗ്ലീഷ്- as- വിദേശ- ഭാഷ എസ്സില്‍ അര്‍ഗമെന്റിവ് സ്ട്രൂട്ടേറ്റ്</title_ml>
      <title_mn>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_mn>
      <title_no>Tolking av argumentativ struktur i engelsk-as-Foreign-Language Essays</title_no>
      <title_pl>Analiza struktury argumentatywnej w esejach o języku angielskim jako obcym</title_pl>
      <title_sr>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_sr>
      <title_ro>Analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină</title_ro>
      <title_si>ප්‍රශ්ණාත්මක සංස්කරණය ඉංග්‍රීසිය-as-බාර්ජික-භාෂාවයේ ප්‍රශ්ණය</title_si>
      <title_so>Barsashada jardiinada hagitaanka ku qoran Ingiriis-as-Foreign-language Essays</title_so>
      <title_sv>Tolkning av argumentativ struktur i engelska-som-främmande-språk essäer</title_sv>
      <title_ta>ஆங்கிலம்- as- Foreign- Language Essays</title_ta>
      <title_ur>انگلیسی-as-Foreign-Language Essays میں آرگومنٹیٹ ساختاری پارسینگ</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Cấu trúc Argumentive in English-as-Foreign-Language Essays</title_vi>
      <title_bg>Разглеждане на аргументативната структура в английски-чуждоезикови есета</title_bg>
      <title_hr>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_hr>
      <title_nl>Analyse van argumentatieve structuur in essays over Engels als vreemde taal</title_nl>
      <title_da>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_da>
      <title_de>Analyse der argumentativen Struktur in englischsprachigen Essays</title_de>
      <title_id>Menganalisis Struktur Argumentatif dalam Ujian Bahasa Inggris-sebagai-Bahasa asing</title_id>
      <title_ko>영어 의논문 의논문 구조 해석</title_ko>
      <title_fa>تحلیل ساختار Argumentative in English-as-Foreign-Language Essays</title_fa>
      <title_sw>Mradi wa Kiingereza kwa lugha ya Kigeni na Kigeni Essa</title_sw>
      <title_tr>Argumentatik Structure in English-as-Foreign-Language Essays</title_tr>
      <title_af>Verwerking Argumentatiewe struktuur in Engels-as-Foreign-Language Essays</title_af>
      <title_sq>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_sq>
      <title_hy>Արգեմենտատիվ կառուցվածքը վերլուծում անգլերեն-որպես-արտաքին-լեզվի թեսսերում</title_hy>
      <title_am>አርማኔት</title_am>
      <title_az>İngilizce-as-Foreign-Language Essays olaraq Argumentative Structure analizə edilir</title_az>
      <title_bn>ইংরেজি- as-পররাষ্ট্র ভাষায় আর্গুমেন্টিভ ক্ষেত্র পার্সিং করা হচ্ছে</title_bn>
      <title_ca>Analitzar l'estructura argumentativa en els exàmens anglès-com-estranger</title_ca>
      <title_cs>Analýza argumentativní struktury v esejích angličtiny jako cizího jazyka</title_cs>
      <title_bs>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_bs>
      <title_et>Argumentatiivse struktuuri parsimine inglise keelena võõrkeelsetes esseetes</title_et>
      <title_fi>Argumentatiivisen rakenteen jäsentäminen englanninkielisissä esseissä</title_fi>
      <title_jv>Parasing argument structural in French-as-Remote-Language Associations</title_jv>
      <title_he>מעבדת מבנה מסכים במבחנים בשפה זרה אנגלית</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Razdelava argumentativne strukture v angleškem jeziku kot tujem jeziku</title_sk>
      <title_bo>Parsing Argumentative Structure in English-as-Foreign-Language Essays</title_bo>
      <abstract_ar>تقدم هذه الورقة دراسة حول تحليل البنية الجدلية في مقالات اللغة الإنجليزية كلغة أجنبية (EFL) ، والتي هي بطبيعتها صاخبة. تتكون عملية التحليل من خطوتين ، ربط الجمل ذات الصلة ثم تصنيف العلاقات بينهما. نجرب العديد من بنيات التعلم العميق لمعالجة كل مهمة على حدة. في مهمة ربط الجملة ، كان أداء نموذج بيافيني هو الأفضل. في مهمة وضع العلامات على العلاقة ، كان أداء نموذج BERT الدقيق هو الأفضل. يتم استخدام جملتين من التشفير ، ولاحظنا أن النماذج غير الدقيقة كانت تؤدي بشكل عام أداءً أفضل عند استخدام Sentence-BERT بدلاً من مشفر BERT. قمنا بتدريب نماذجنا باستخدام نوعين من النصوص المتوازية: مقالات اللغة الإنجليزية كلغة أجنبية الصاخبة الأصلية وتلك التي تم تحسينها بواسطة المعلقين ، ثم قم بتقييمهم على المقالات الأصلية. تُظهر التجربة أن نظام النطاق الشامل قد حقق دقة 341. من ناحية أخرى ، حقق النظام عبر المجال أداء 94٪ للنظام داخل المجال. يشير هذا إلى أن النصوص المكتوبة جيدًا يمكن أن تكون مفيدة أيضًا في تدريب نظام التنقيب عن الحجج للنصوص المزعجة.</abstract_ar>
      <abstract_es>Este artículo presenta un estudio sobre el análisis de la estructura argumentativa en ensayos de inglés como lengua extranjera (EFL), que son inherentemente ruidosos. El proceso de análisis consta de dos pasos, vincular oraciones relacionadas y luego etiquetar sus relaciones. Experimentamos con varias arquitecturas de aprendizaje profundo para abordar cada tarea de forma independiente. En la tarea de vinculación de oraciones, un modelo biafín obtuvo el mejor rendimiento. En la tarea de etiquetado de relaciones, un modelo BERT ajustado fue el que mejor funcionó. Se emplean codificadores de dos oraciones, y observamos que los modelos sin ajuste fino generalmente funcionan mejor cuando se usa el codificador Sentence-BERT en lugar del codificador BERT. Entrenamos nuestros modelos utilizando dos tipos de textos paralelos: ensayos originales de EFL ruidosos y aquellos mejorados por anotadores, y luego los evaluamos en los ensayos originales. El experimento muestra que un sistema de dominio de extremo a extremo logró una precisión de .341. Por otro lado, el sistema entre dominios logró un rendimiento del 94% del sistema dentro del dominio. Esto indica que los textos bien escritos también pueden ser útiles para entrenar el sistema de minería de argumentos para textos ruidosos.</abstract_es>
      <abstract_fr>Cet article présente une étude sur l'analyse de la structure argumentative dans les dissertations en anglais langue étrangère (EFL), qui sont intrinsèquement bruyantes. Le processus d'analyse se compose de deux étapes : relier les phrases associées et étiqueter leurs relations. Nous testons plusieurs architectures de deep learning pour traiter chaque tâche de manière indépendante. Dans la tâche de liaison de phrases, c'est un modèle biaffine qui a donné les meilleurs résultats. Dans la tâche d'étiquetage des relations, c'est un modèle BERT affiné qui a donné les meilleurs résultats. Deux encodeurs de phrases sont utilisés, et nous avons observé que les modèles sans réglage fin donnaient généralement de meilleurs résultats avec l'encodeur Sentence-BERT par opposition au codeur BERT. Nous avons formé nos modèles à l'aide de deux types de textes parallèles : les essais originaux bruités EFL et ceux améliorés par des annotateurs, puis nous les évaluons sur les dissertations originales. L'expérience montre qu'un système dans le domaine de bout en bout a atteint une précision de 0,341. D'autre part, le système inter-domaines a atteint 94 % de performances du système dans le domaine. Cela indique que des textes bien écrits peuvent également être utiles pour entraîner le système d'exploration d'arguments pour les textes bruyants.</abstract_fr>
      <abstract_pt>Este artigo apresenta um estudo sobre a análise da estrutura argumentativa em ensaios de inglês como língua estrangeira (EFL), que são inerentemente barulhentos. O processo de análise sintática consiste em duas etapas, vinculando sentenças relacionadas e, em seguida, rotulando suas relações. Experimentamos várias arquiteturas de aprendizado profundo para abordar cada tarefa de forma independente. Na tarefa de ligação de frases, um modelo biafino teve o melhor desempenho. Na tarefa de rotulagem de relação, um modelo BERT ajustado teve o melhor desempenho. Dois codificadores de sentença são empregados e observamos que os modelos sem ajuste fino geralmente tiveram melhor desempenho ao usar o codificador Sentence-BERT em oposição ao codificador BERT. Treinamos nossos modelos usando dois tipos de textos paralelos: ensaios originais de EFL barulhentos e aqueles aprimorados por anotadores, então os avaliamos nos ensaios originais. O experimento mostra que um sistema no domínio de ponta a ponta alcançou uma precisão de 0,341. Por outro lado, o sistema cross-domain alcançou 94% de desempenho do sistema in-domain. Isso sinaliza que textos bem escritos também podem ser úteis para treinar o sistema de mineração de argumentos para textos ruidosos.</abstract_pt>
      <abstract_ja>本稿では、本質的に騒がしい英語-外国語（ EFL ）エッセイにおける議論構造の構文解析に関する研究を紹介する。 構文解析プロセスは、関連する文をリンクし、それらの関係をラベル付けする2つのステップで構成されています。 私たちは、それぞれの課題に独立して対処するために、いくつかの深層学習アーキテクチャを実験しています。 文のリンクタスクでは、バイアフィンモデルが最高のパフォーマンスを発揮しました。 関係ラベリングタスクでは、微調整されたBERTモデルが最良のパフォーマンスを発揮しました。 ２つの文章エンコーダが採用されており、非微調整モデルは一般的に、ＢＥＲＴエンコーダとは対照的に、Ｓｅｎｔｅｎｃｅ － ＢＥＲＴを使用する場合により良いパフォーマンスを発揮することが観察された。 私たちは、オリジナルのノイズの多いEFLエッセイと、アノテーターによって改善されたものの2種類のパラレルテキストを使用してモデルをトレーニングし、オリジナルのエッセイで評価しました。 この実験では、エンドツーエンドのドメイン内システムが.341の精度を達成したことが示されています。 一方、クロスドメインシステムは、インドメインシステムの94 ％のパフォーマンスを達成しました。 これは、よく書かれたテキストが、ノイズの多いテキストのための引数マイニングシステムをトレーニングするのにも役立つことを示しています。</abstract_ja>
      <abstract_zh>本文引解析英语为外语(EFL)论证结构,其质嘈杂。 解析两步驿,链接关句,然后志之。 尝试数深学架构以自立也。 句链接事,字母模形为上。 在於事,微BERT为最。 用二句编码器,吾观之,比于BERT编码器,用句BERT时,非调形常善也。 吾以两体并行本教我模样:原始嘈杂EFL论文及由注者改进论文,然后于原始论文上对其评估。 实验者,端到端域内之0.341精也。 其一,跨域统成域94%之性也。 此明文本亦可用于训练嘈杂文本者参数掘而系之。</abstract_zh>
      <abstract_ru>В данной работе представлено исследование по анализу аргументативной структуры в эссе на английском языке как иностранном (EFL), которые по своей сути являются шумными. Процесс синтаксического анализа состоит из двух этапов, соединяющих соответствующие предложения, а затем обозначающих их отношения. Мы экспериментируем с несколькими архитектурами глубокого обучения, чтобы решать каждую задачу самостоятельно. В задаче связывания предложений модель биаффина показала лучшие результаты. В задаче маркировки отношений лучше всего работала тонко настроенная модель BERT. Используются два кодера предложений, и мы заметили, что модели без точной настройки, как правило, работают лучше при использовании Sentence-BERT в отличие от кодера BERT. Мы обучали наши модели, используя два типа параллельных текстов: оригинальные шумные эссе EFL и улучшенные аннотаторами, а затем оценивали их по оригинальным эссе. Эксперимент показывает, что сквозная внутридоменная система достигла точности .341. С другой стороны, междоменная система достигла 94% производительности внутридоменной системы. Это сигнализирует о том, что хорошо написанные тексты также могут быть полезны для обучения системы майнинга аргументов для шумных текстов.</abstract_ru>
      <abstract_hi>यह पेपर अंग्रेजी-विदेशी-भाषा (ईएफएल) निबंधों में तर्कसंगत संरचना को पार्स करने पर एक अध्ययन प्रस्तुत करता है, जो स्वाभाविक रूप से शोर कर रहे हैं। पार्सिंग प्रक्रिया में दो चरण होते हैं, संबंधित वाक्यों को जोड़ना और फिर उनके संबंधों को लेबल करना। हम स्वतंत्र रूप से प्रत्येक कार्य को संबोधित करने के लिए कई गहरे सीखने के आर्किटेक्चर के साथ प्रयोग करते हैं। वाक्य जोड़ने के कार्य में, एक biaffine मॉडल ने सबसे अच्छा प्रदर्शन किया। संबंध लेबलिंग कार्य में, एक ठीक-ठाक BERT मॉडल ने सबसे अच्छा प्रदर्शन किया। दो वाक्य एनकोडर नियोजित हैं, और हमने देखा कि गैर-ठीक-ट्यूनिंग मॉडल ने आमतौर पर BERT एन्कोडर के विपरीत वाक्य-BERT का उपयोग करते समय बेहतर प्रदर्शन किया। हमने दो प्रकार के समानांतर ग्रंथों का उपयोग करके अपने मॉडल को प्रशिक्षित किया: मूल शोर ईएफएल निबंध और एनोटेटर द्वारा सुधार किए गए, फिर मूल निबंधों पर उनका मूल्यांकन करें। प्रयोग से पता चलता है कि एक एंड-टू-एंड इन-डोमेन सिस्टम ने .341 की सटीकता हासिल की। दूसरी ओर, क्रॉस-डोमेन सिस्टम ने इन-डोमेन सिस्टम का 94% प्रदर्शन हासिल किया। यह संकेत देता है कि अच्छी तरह से लिखे गए ग्रंथों को शोर ग्रंथों के लिए तर्क खनन प्रणाली को प्रशिक्षित करने के लिए भी उपयोगी हो सकता है।</abstract_hi>
      <abstract_ga>Cuireann an páipéar seo i láthair staidéar ar an struchtúr argóinteach in aistí Béarla mar theanga iasachta (EFL) a pharsáil, atá fuaimiúil go bunúsach. Tá dhá chéim sa phróiseas parsála, ag nascadh abairtí gaolmhara agus ansin ag lipéadú a gcaidreamh. Bainimid triail as roinnt ailtireachtaí domhainfhoghlama chun tabhairt faoi gach tasc go neamhspleách. Sa tasc nascadh abairtí, samhail biaifín ab fhearr. Maidir leis an tasc maidir le lipéadú an choibhneasa, múnla BERT mionchoigeartaithe ab fhearr. Fostaítear dhá ionchódóir pianbhreithe, agus thugamar faoi deara gur éirigh níos fearr le samhlacha neamh-mhionchoigeartaithe go ginearálta nuair a bhí Pianbhreithe-BERT in úsáid seachas ionchódóir CRET. Chuireamar oiliúint ar ár múnlaí ag baint úsáide as dhá chineál téacs comhthreomhar: bun-aistí torannacha EFL agus iad siúd a d'fheabhsaigh anótálaithe, ansin déan iad a mheas ar na bun-aistí. Léiríonn an turgnamh gur bhain córas in-fhearainn ceann go ceann amach cruinneas .341. Ar an láimh eile, bhain an córas tras-fearainn feidhmíocht 94% den chóras in-fearainn amach. Léiríonn sé seo gur féidir le téacsanna dea-scríofa a bheith úsáideach freisin chun córas mianadóireachta argóintí a oiliúint le haghaidh téacsanna callánacha.</abstract_ga>
      <abstract_hu>Ez a tanulmány bemutatja az angol mint idegen nyelvű (EFL) esszék argumentációs struktúrájának elemzését, amelyek eredendően zajosak. Az elemzési folyamat két lépésből áll, összekapcsolja a kapcsolódó mondatokat, majd megjelöli a kapcsolataikat. Számos mélytanulási architektúrával kísérletezünk, hogy minden feladatot önállóan kezeljük. A mondatkötési feladatban a biaffine modell teljesítette a legjobbat. A kapcsolatcímkézési feladat során egy finomhangolt BERT modell teljesített a legjobban. Két mondatkódolót alkalmazunk, és megfigyeltük, hogy a nem finomhangoló modellek általában jobban teljesítenek a Sentence-BERT használatával szemben a BERT kódolóval. Modelljeinket kétféle párhuzamos szövegből készítettük: eredeti zajos EFL esszék és kommentátorok által fejlesztett esszék segítségével, majd értékeltük őket az eredeti esszékben. A kísérlet azt mutatja, hogy egy teljes körű domain rendszer .341 pontosságot ért el. Másrészről a cross-domain rendszer 94%-os teljesítményt ért el az in-domain rendszer. Ez azt jelzi, hogy a jól megírt szövegek hasznosak lehetnek a zajos szövegek argumentumbányászati rendszerének kiképzéséhez.</abstract_hu>
      <abstract_el>Η παρούσα εργασία παρουσιάζει μια μελέτη για την ανάλυση της επιχειρηματολογικής δομής σε δοκίμια αγγλικά-ως-ξένης γλώσσας (EFL), τα οποία είναι εγγενώς θορυβώδη. Η διαδικασία ανάλυσης αποτελείται από δύο βήματα, που συνδέουν σχετικές προτάσεις και στη συνέχεια επισημαίνουν τις σχέσεις τους. Πειραματιζόμαστε με διάφορες αρχιτεκτονικές βαθιάς μάθησης για να αντιμετωπίσουμε κάθε εργασία ανεξάρτητα. Στην εργασία σύνδεσης της πρότασης, ένα μοντέλο διφίνης πέτυχε το καλύτερο. Στην εργασία επισήμανσης σχέσης, ένα εκλεπτυσμένο μοντέλο πέτυχε καλύτερα. Χρησιμοποιούνται δύο κωδικοποιητές προτάσεων και παρατηρήσαμε ότι τα μοντέλα μη συντονισμού γενικά αποδίδουν καλύτερα όταν χρησιμοποιούν πρόταση-BERT σε αντίθεση με τον κωδικοποιητή BERT. Εκπαιδευτήκαμε τα μοντέλα μας χρησιμοποιώντας δύο τύπους παράλληλων κειμένων: πρωτότυπα θορυβώδη δοκίμια και αυτά που βελτιώθηκαν από σχολιαστές και μετά τα αξιολογήσαμε στα πρωτότυπα δοκίμια. Το πείραμα δείχνει ότι ένα ολοκληρωμένο σύστημα στον τομέα πέτυχε ακρίβεια .341. Από την άλλη πλευρά, το σύστημα μεταξύ τομέων πέτυχε 94% απόδοση του συστήματος εντός τομέα. Αυτό σηματοδοτεί ότι τα καλά γραπτά κείμενα μπορούν επίσης να είναι χρήσιμα για την εκπαίδευση του συστήματος εξόρυξης επιχειρημάτων για θορυβώδη κείμενα.</abstract_el>
      <abstract_ka>ეს დოკუმენტი აჩვენებს აპრინტიგური სტრუქტურის პარასუზაციის შესახებ ინგლისური ენის (EFL) ესესიში, რომლებიც არსებობით ბუნდა. პროცესი განაწერების შეფარდება ორი ნაწილის შეფარდება, შემდეგ შეფარდებული სიტყვების დაკავშირება და შემდეგ მათი შესახებ. ჩვენ ექსპერიმენტირებით რამდენიმე ძალიან სწავლის აქტიქტიკურებით, რომელიც ყოველ რაოდენობას განცემულად გადავუწყ ბიფინის მოდელეში ყველაზე უკეთესი მონაცემები გავაკეთეთ. შესაბამისი მარტიკის დავალებაში, BERT მოდელის შესაბამისი შესაბამისი შესაბამისი შესაბამისი მოდელია. ორი სიტყვების კოდერები მომხმარებულია, და ჩვენ დავხედავთ, რომ არაფერი კოდერების მოდელები უფრო უფრო მუშაობენ, როდესაც გამოყენება ბერტი კოდერების განმავლობაში. ჩვენ ჩვენი მოდელების შესწავლით ორი ტიპის პარალელი ტექსტის გამოყენებით: ორიგინალური ფუნქციური EFL ესეები და ისინი, რომლებიც ანტოტოტორიების შესაძლებელება, შემდეგ დავამუშავ ექსპერიმენტი ჩვენებს, რომ საკუთარი დასრულებული დომინის სისტემა დასრულებულია.341. მეორე მხოლოდ, კრესომინის სისტემა 94% მოქმედება დომინის სისტემას. ეს სიგნალეები, რომლებიც ძალიან წერტილი ტექსტი შეუძლია იყოს საჭირო სისტემის მინდომის სისტემის შესაბამისთვის.</abstract_ka>
      <abstract_it>Questo articolo presenta uno studio sull'analisi della struttura argomentativa nei saggi inglese come lingua straniera (EFL), che sono intrinsecamente rumorosi. Il processo di analisi consiste in due fasi, collegando frasi correlate e poi etichettando le loro relazioni. Sperimentiamo diverse architetture di deep learning per affrontare ogni compito in modo indipendente. Nell'attività di collegamento delle frasi, un modello biaffine ha eseguito il meglio. Nel compito di etichettatura delle relazioni, un modello BERT perfezionato ha dato il meglio. Vengono impiegati due encoder di frase e abbiamo osservato che i modelli non-fine-tuning generalmente hanno prestazioni migliori quando si utilizza Sentence-BERT rispetto all'encoder BERT. Abbiamo formato i nostri modelli utilizzando due tipi di testi paralleli: saggi EFL originali rumorosi e quelli migliorati dagli annotatori, per poi valutarli sui saggi originali. L'esperimento mostra che un sistema end-to-end in-domain ha raggiunto una precisione di .341. D'altra parte, il sistema cross-domain ha raggiunto il 94% delle prestazioni del sistema in-domain. Questo indica che i testi ben scritti possono anche essere utili per addestrare il sistema di estrazione di argomenti per i testi rumorosi.</abstract_it>
      <abstract_lt>Šiame dokumente pateikiamas tyrimas dėl argumentacinės struktūros analizavimo anglų-kaip-užsienio kalbos (EFL) egzaminuose, kurie iš esmės yra triukšmingi. The parsing process consists of two steps, linking related sentences and then labelling their relations.  Eksperimentuojame su keliomis gilaus mokymosi architektūromis, kad kiekviena užduotis būtų sprendžiama nepriklausomai. Kalbant apie užduotį, susijusią su sakiniu, biffino modelis atliko geriausią rezultatą. In the relation labelling task, a fine-tuned BERT model performed the best.  Naudojami du sakiniai koduojantys kodai ir pastebėjome, kad nereguliuojantys modeliai paprastai geriau veikia naudojant sentence-BERT, o ne BERT koduojantį kodą. Mokėjome savo modelius naudojant dviejų rūšių lygiagrečius tekstus: originalius triukšmingus EFL esejus ir tuos, kuriuos patobulino anotatoriai, tada juos vertiname pagal originalius esejus. Eksperimentas rodo, kad iš vienos srities į kitą sistema pasiekė .341 tikslumą. Kita vertus, tarpdomeninė sistema pasiekė 94 % domeninės sistemos veiklos rezultatų. Tai rodo, kad gerai rašyti tekstai taip pat gali būti naudingi argument ų gavybos sistemai apmokyti triukšmingiems tekstams.</abstract_lt>
      <abstract_kk>Бұл қағаз ағылшын тілі (EFL) ретінде аргументациялық құрылғыны талдау туралы зерттеулерді көрсетеді. Бұл аргументалдық құрылғылар әдетте дыбыс болып тұрады. Бұл талдау процесі екі қадам болып, сілтемелерді сілтемелеу және оның қатынасын жарлықтау. Біз әрбір тапсырманы тәуелді өзгерту үшін бірнеше түсінік оқыту архитектураларымен тәжірибедік. Тапсырманы сілтемелеу үшін биафин үлгісі ең жақсы орындалды. Қатысушылық жарлықтау тапсырмасында BERT үлгісін жақсы орындады. Екі сөз кодері жұмыс істейді. Біз BERT кодеріне қарсы сөз- BERT кодеріне қарсы жақсы орындалатын үлгілер үлгілерін көрдік. Біз үлгілерімізді екі түрлі параллель мәтінді қолдануға үйрендік: бастапқы дыбыс EFL ессейлері және жаңартушылары жасалды, содан кейін оларды бастапқы ессейлерде оқу. Тәжірибе домендегі соңындағы соңындағы жүйе .341 деген дұрыстығын жеткізді. Біріншіден, домен жүйесінің 94% жылдамдығын жеткізді. Бұл мәтіндердің жақсы жазылған сигналдары, сондай-ақ, дыбыс мәтіндер үшін аргументтің бағыттау жүйесін оқыту үшін пайдалы болады.</abstract_kk>
      <abstract_ml>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  പാര്‍സിംഗ് പ്രക്രിയയില്‍ രണ്ടു പടികള്‍ ഉണ്ട്, ബന്ധപ്പെട്ട വാക്കുകള്‍ ബന്ധപ്പെടുത്തുന്നു, പിന്നെ അവരുടെ ബന എല്ലാ ജോലിയെയും സ്വാതന്ത്ര്യമായി സംസാരിക്കാന്‍ ആഴമുള്ള പഠിക്കുന്ന ആര്‍ക്കിട്ടുകള്‍ കൊണ് വാക്കില്‍ ബന്ധപ്പെടുത്തുന്ന ജോലിയില്‍ ഒരു ബിഫിന്‍ മോഡല്‍ ഏറ്റവും നല്ലത് പ്രവര്‍ത്തിച്ചു. ബന്ധപ്പെടുത്തുന്ന ജോലിയില്‍, നല്ലൊരു ബെര്‍ട്ടി മോഡല്‍ ഏറ്റവും നല്ലത് പ്രവര്‍ത്തിച്ചു. രണ്ട് വാക്കുകളുടെ കോഡോര്‍ഡുകള്‍ ഉപയോഗിച്ചിരിക്കുന്നു, ബെര്‍ട്ടി കോഡോര്‍ഡിനെതിരെ ഉപയോഗിക്കുമ്പോള്‍ സെന്‍സ്-ബെര്‍ട്ടി ഉപയോ നമ്മുടെ മോഡലുകള്‍ രണ്ടു തരം പാരാലില്‍ ടെക്സ്റ്റുകള്‍ ഉപയോഗിച്ച് ഞങ്ങള്‍ പരിശീലിപ്പിച്ചു: ആദ്യമായ യെഎഫ്എല്‍ ലേസ്സുകള്‍ ഉയര്‍ത്തുന്നതും അ പരീക്ഷണം കാണിച്ചുകൊണ്ടിരിക്കുന്നത് ഡൊമെയിന്‍ സിസ്റ്റത്തിന്റെ അവസാനത്തിലേക്ക് അവസാനിക്കുന്നതാ മറുവശത്ത്, ക്രിസ്റ്റ് ഡൊമെയിന്‍ സിസ്റ്റം 94% പ്രവര്‍ത്തിപ്പിച്ചു. നല്ല എഴുതിയ ടെക്സ്റ്റുകള്‍ ശബ്ദമുള്ള വാക്കുകള്‍ക്ക് വേണ്ടി ആര്‍ഗ്യുമിനിങ്ങ് മൈനിങ്ങ് സിസ്റ്റം പരി</abstract_ml>
      <abstract_ms>Kertas ini memperkenalkan kajian mengenai hurai struktur argumensif dalam esei bahasa Inggeris-sebagai-asing (EFL), yang secara nyata bunyi. Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat berkaitan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arkitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam perkataan yang menghubungkan tugas, model biaffin melakukan yang terbaik. Dalam tugas penandaan hubungan, model BERT ditetapkan yang terbaik dilakukan. Dua pengekod kalimat digunakan, dan kami memperhatikan bahawa model bukan-penyesuaian biasanya dilakukan lebih baik bila menggunakan pengekod kalimat-BERT daripada pengekod BERT. Kami melatih model kami menggunakan dua jenis teks selari: esei EFL bunyi asal dan yang diperbaiki oleh annotator, kemudian menilainya pada esei asal. Eksperimen menunjukkan bahawa sistem domain akhir-akhir mencapai ketepatan .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% sistem dalam-domain. Ini memberi isyarat bahawa teks yang ditulis dengan baik juga boleh berguna untuk melatih sistem pertambangan argumen untuk teks bunyi.</abstract_ms>
      <abstract_mk>Овој весник претставува студија за анализирање на аргументативната структура на есеите на англиски-како-странски јазик (ЕФЛ), кои се природно гласни. Процесот на анализирање се состои од два чекори, поврзувајќи ги поврзаните реченици и потоа означувајќи ги нивните односи. Експериментираме со неколку архитектури за длабоко учење за да се справиме со секоја задача независно. Во реченицата која ја поврзува задачата, биафинскиот модел беше најдобар. Во врска со задачата за етикетирање на односите, фино прилагоден модел BERT го изврши најдоброто. Употребени се два кодери на реченици, и ние забележавме дека нефинетираните модели генерално работеа подобро кога се користи реченица-BERT во спротивност на BERT кодерот. Ги трениравме нашите модели користејќи два вида паралелни тексти: оригинални бучни есеи ЕФЛ и оние подобрени од анотаторите, потоа ги проценуваме на оригиналните есеи. Експериментот покажува дека системот од крај до крај во домен постигнал точност од .341. Од друга страна, крстодомениот систем постигна 94 отсто од резултатите на системот во домените. Ова сигнализира дека добро напишаните тексти, исто така, можат да бидат корисни за обука на системот за рудање аргументи за бучни тексти.</abstract_mk>
      <abstract_mt>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  Il-proċess ta’ analiżi jikkonsisti f’żewġ passi, li jgħaqqdu sentenzi relatati u mbagħad jikkettaw ir-relazzjonijiet tagħhom. Aħna ninsperimentaw b’diversi arkitetturi ta’ tagħlim profond biex nindirizzaw kull kompitu b’mod indipendenti. Fis-sentenza li tgħaqqad il-kompitu, mudell biffin wettaq l-a ħjar. Fil-kompitu tat-tikkettar tar-relazzjoni, mudell BERT irfinat wettaq l-a ħjar. Jintużaw żewġ kodifikaturi tas-sentenzi, u osservajna li mudelli mhux ta’ rfinar ġeneralment kienu aħjar meta ntużaw Sentenza-BERT minflok l-kodifikatur BERT. Taħriġna l-mudelli tagħna bl-użu ta’ żewġ tipi ta’ testi paralleli: essays oriġinali storbjużi tal-EFL u dawk imtejba mill-annotaturi, imbagħad ivvalutawhom fuq l-essays oriġinali. L-esperiment juri li sistema f’dominju minn tarf sa tarf kisbet preċiżjoni ta’ .341. Min-naħa l-oħra, is-sistema cross-domain kisbet prestazzjoni ta’ 94% tas-sistema in-domain. Dan jindika li testi miktuba sew jistgħu jkunu utli wkoll biex titħarreġ is-sistema tal-minjieri tal-argumenti għal testi storbjużi.</abstract_mt>
      <abstract_pl>W artykule przedstawiono badanie analizy struktury argumentatywnej w esejach o języku angielskim jako obcym (EFL), które są z natury hałaśliwe. Proces parsowania składa się z dwóch etapów, łączenia powiązanych zdań, a następnie oznaczania ich relacji. Eksperymentujemy z kilkoma architekturami głębokiego uczenia, aby rozwiązać każde zadanie niezależnie. W zadaniu łączącym zdanie najlepiej sprawdził się model biafinowy. W zadaniu etykietowania relacji najlepiej sprawdził się dopracowany model BERT. Zastosowane są dwa kodery zdań, a my zauważyliśmy, że modele niedostrajające się zazwyczaj sprawdzają się lepiej przy użyciu kodera zdań-BERT w przeciwieństwie do kodera BERT. Szkoliliśmy nasze modele z wykorzystaniem dwóch rodzajów tekstów równoległych: oryginalnych szumownych esejów EFL oraz tych ulepszonych przez adnotatorów, a następnie oceniamy je na oryginalnych esejach. Eksperyment pokazuje, że kompleksowy system w domenie osiągnął dokładność .341. Z drugiej strony system między domenami osiągnął 94% wydajności systemu wewnątrz domeny. Sygnalizuje to, że dobrze napisane teksty mogą być również przydatne do treningu systemu wydobywania argumentów dla głośnych tekstów.</abstract_pl>
      <abstract_ro>Lucrarea prezintă un studiu privind analizarea structurii argumentative în eseurile de limbă engleză ca limbă străină (EFL), care sunt inerent zgomotoase. Procesul de analizare constă în două etape, care leagă propozițiile conexe și apoi etichetează relațiile lor. Experimentăm cu mai multe arhitecturi de învățare profundă pentru a aborda fiecare sarcină independent. În sarcina de legătură a propozițiilor, un model de biafine a performat cel mai bine. În sarcina de etichetare a relațiilor, un model BERT reglat fin a performat cel mai bine. Sunt utilizate două codificatoare de propoziții și am observat că modelele non-reglare fină au performat în general mai bine atunci când utilizați Sentence-BERT, spre deosebire de codificatorul BERT. Ne-am instruit modelele folosind două tipuri de texte paralele: eseurile EFL originale zgomotoase și cele îmbunătățite de adnotatori, apoi le-am evaluat pe eseurile originale. Experimentul arată că un sistem end-to-end în domeniu a atins o precizie de .341. Pe de altă parte, sistemul cross-domeniu a obținut o performanță de 94% a sistemului in-domeniu. Acest lucru semnalează că textele bine scrise pot fi, de asemenea, utile pentru instruirea sistemului de mining de argumente pentru texte zgomotoase.</abstract_ro>
      <abstract_mn>Энэ цаас Англи хэл болон гадаад хэл (EFL) эссийн аргументын бүтцийг хуваалцах талаар судалж байна. Энэ нь үнэхээр чимээгүй. Тайлбарлах процесс нь хоёр алхам, харилцааны өгүүлбэр холбоотой, дараа нь харилцааныг тэмдэглэдэг. Бид олон гүн гүнзгий суралцах архитектурууддаа ажил бүрийг өөрсдөө зохицуулахын тулд туршилт хийдэг. Үүний дараа ажлыг холбох үед биефин загвар хамгийн сайн хийсэн. Хариулт маркингийн ажил дээр BERT загвар хамгийн сайн хийсэн. Хоёр өгүүлбэр коддогч ажиллаж байгаа. Бид BERT коддогч эсрэгээр Sentence-BERT-ийг ашиглах үед илүү сайн ажиллаж байгааг анзаарсан. Бид моделуудыг хоёр төрлийн параллел текст ашиглан сургалтын загвар өгсөн. Үнэндээ чимээгүй EFL эссийг ашиглаж байлаа. Энэ туршилт нь холбооны төгсгөл-төгсгөл систем нь .341-ийн тодорхойлолтой болсон. Нөгөө талаар, холбоотой систем нь холбоотой системийн 94% ажиллагааг гаргасан. Үнэндээ сайн бичигдсэн бичигдсэн мөн аргументын хөрөнгө оруулах системийг сонсогдож чадна.</abstract_mn>
      <abstract_no>Denne papiret viser ein studie om tolking av argumentativ strukturen i engelske som fremst språk (EFL), som er eigentleg støy. Tolkingsprosessen inneheld to steg, lenkjer relaterte setningar og så merker forholdet sine. Vi eksperimenterer med fleire dype læringsarkitektur for å handtera kvar oppgåve uavhengig. I setningen som lenkjer oppgåva, utførte ein biaffinmodell den beste. I forhold til merkelappen utførte ein fint BERT-modell best. To setningskooderar er arbeida, og vi observerte at ikkje-finnstillingsmodeller vanlegvis utførte bedre når sentences-BERT brukar i motsetning til BERT-kodar. Vi treng modellen våre med to typar parallelle tekstar: originale støy EFL-essane og dei forbetra av annotatorar, og deretter evaluer dei på originale essane. Eksperimentet viser at ein ende- til- slutt- domenesystemet oppnådd eit nøyaktig av .341. På den andre siden oppnådd krysdomenesystemet 94% utviklinga i domenesystemet. Dette signaler at skrivne tekstar kan også vera nyttig for å trena argument-miningssystem for støytekstar.</abstract_no>
      <abstract_sr>Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno buke. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se obratimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro napravljeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, i primetili smo da modeli koji nisu ispravni, u običaju su bolje izvršili kada koriste kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dve vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procenili na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem prekršnog domena postigao je 94% učinkovitosti sistema u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sistema argumentacija za bučne tekstove.</abstract_sr>
      <abstract_sv>Denna uppsats presenterar en studie om tolkning av argumentationsstrukturen i engelsk-som-främmande-språk (EFL) essäer, som är i sig bullriga. Analysprocessen består av två steg, länka relaterade meningar och sedan märka deras relationer. Vi experimenterar med flera djupinlärningsarkitekturer för att hantera varje uppgift självständigt. I meningssänkningsuppgiften presterade en biaffinmodell bäst. I relationsmärkningsuppgiften presterade en finjusterad BERT-modell bäst. Två meningskoder används, och vi observerade att icke-finjusterande modeller generellt presterade bättre när man använder Sentence-BERT i motsats till BERT-encoder. Vi tränade våra modeller med två typer av parallella texter: original bullriga EFL essäer och de som förbättrats av kommentatorer, och utvärderade dem sedan på de ursprungliga essäerna. Experimentet visar att ett heltäckande domänsystem uppnådde en noggrannhet på .341. Å andra sidan uppnådde det domänöverskridande systemet 94% prestanda jämfört med domänsystemet. Detta signalerar att välskrivna texter också kan vara användbara för att träna argument mining system för bullriga texter.</abstract_sv>
      <abstract_si>මේ පත්තු ප්‍රදේශයක් ඉංග්‍රීසි භාෂාවක් වලින් ප්‍රශ්නයක් විශ්ලේෂණය කරනවා, ඒ වගේම ප්‍රශ්නයක් විශ්ලේෂණය ක විශ්ලේෂණ ප්‍රක්‍රියාව සම්බන්ධතාවක් දෙකක් තියෙනවා, සම්බන්ධතාවක් සම්බන්ධතාවක් සම්බන්ධ අපි ගොඩක් ගොඩක් ඉගෙන ගන්න සිද්ධ විද්‍යාපාරයෙන් පරීක්ෂණය කරනවා හැම වැඩක්ම ස්වයංක්‍ර වාක්ය සම්බන්ධ වෙන්න වැඩේ බියාෆින් නිර්මාණයක් හොඳම වැඩ කළා. සම්බන්ධ ලේබිල් කාර්යයෙන්, හොඳම BERT මොඩල් එකක් වැඩ කරනවා. වාක්යෙන් කෝඩාර් දෙකක් වැඩ කරලා තියෙනවා, ඒ වගේම අපි බලාපොරොත්තු කරලා තියෙනවා කියලා කියලා, සමාන්‍යයෙන්ම නොවිශ්වාසික අපි අපේ මොඩල් එක්ක ප්‍රකාර දෙකක් ප්‍රයෝජනය කරන්න පුළුවන් විදිහට ප්‍රයෝජනය කරලා තියෙන්නේ: ප්‍රධාන ශබ්ද EFL විදිහට සහ අනු පරීක්ෂණය පෙන්වන්නේ අවසානයෙන් අවසානයෙන් අවසානයෙන් ඉවරයි. ඩොමේන් පද්ධතියෙන් හරියට .341 වලින්  අනිත් පැත්තෙන්, ක්‍රීස් ඩෝමින් පද්ධතියේ ප්‍රවේශ පද්ධතියේ 94% ක්‍රියාත්මක පරීක්ෂණය ලබාගත මේ සංඥානය හොඳට ලියපු පාළුවත් ප්‍රයෝජනය වෙන්න පුළුවන් විදිහට විශ්වාස කරන්න පුළුවන්</abstract_si>
      <abstract_so>Qoraalkan waxaa lagu qoraa waxbarasho ku saabsan baaritaanka dhismaha arrimaha ku saabsan afka Ingiriiska oo kale oo afka ajnabiga ah (EFL) oo aad u dhawaaqdaan. Baaritaanka baarlamaanka waxaa ka mid ah labo tallaabo, ku xiriira qoraalka la xiriira, markaasna la xiriira xiriirkooda. Waxaynu tijaabinaynaa meelo waxbarasho oo mool dheer ah si aan u sheekeyno shaqa kasta si xor ah. Shaqada isku xiran waxaa lagu sameeyay qaab baabuur ah oo aad ugu wanaagsan. Xiriirka sameynta shaqada, model aad u fiican BERT ayaa sameynaya waxa ugu wanaagsan. Waxaa la isticmaalaa labo qodob ah, waxaana aragnay in tusaalo aan hab-wanaagsanayn lagu sameeyo si ka fiican marka lagu isticmaalo Sentence-BERT si ka gees ah codka BERT. Tusaalooyinkayada waxaan ku tababarinnay laba nooc oo kala duduwan qoraal lambarka ah: qoraalka asalka ah ee EFL iyo kuwa horumariyey oo ka kordhisay qoraalka asalka ah, kadibna waxan ku qiimeynay qoraalka asalka ah. Imtixaanka waxaa muuqda in nidaamka ugu dhammaadka gudaha lagu dhamaado uu gaadhay saxda .341. On the other hand, the cross-domain system achieved 94% performance of the in-domain system.  Xilliyadaasu waxay faa’iido u leedahay in qoraal-qoraal oo wanaagsan ay u faa’iido karto in lagu tababaro nidaamka dayactirka ee qoraalka qaylada ah.</abstract_so>
      <abstract_ta>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  பாடல் செயல்பாடு இரண்டு படிகளாக இருக்கும், தொடர்புடைய வாக்கியங்களை இணைத்து பின்னர் அவர்களுடைய உறவுகளை குறிப் நாம் ஒவ்வொரு செயலையும் தனித்தனியாக பேசுவதற்கு பல ஆழமான கற்றுக்கொள்ளும் அட்டவணைகளைக் கொண்டு சோ வாக்கியத்தில் இணைக்கப்பட்ட பணியில், ஒரு பிபிபின் மாதிரி சிறந்ததை செய்தார். தொடர்பு அறிவிப்பு பணியில், ஒரு நன்றாக குறிப்பிட்ட பிரெட் மாதிரி சிறந்ததை செய்தார். இரண்டு வாக்கிய குறியீடுகள் பயன்படுத்தப்படுகின்றன, பிரெட் குறியீட்டை எதிர்பார்த்து வாக்கியம்-பிரெட்டை பயன்படுத்தும் போது பொ நாங்கள் இரண்டு வகையான இணைப்பு உரைகளை பயன்படுத்தி எங்கள் மாதிரிகளுக்கு பயிற்சி செய்தோம்: இந்த சோதனையில் உள்ள முடிவு முடிவு கணினியில் சரியான .341 கிடைத்தது என்பதை காட்டுகிறது. மறுபக்கத்தில், குறுக்கும் களம் கணினியில் 94% செயல்படுத்தப்பட்டது. இந்த குறிப்புகள் ஆச்சரியமான உரைகளுக்கு ஆராய்ச்சியின் கட்டுப்பாட்டு மையம் பயிற்சிக்க பயனுள்ளதாக இருக்க</abstract_ta>
      <abstract_ur>یہ کاغذ انگلیسی زبان (EFL) کے مطابق بحث کی ساختاری مطالعہ کے بارے میں ایک تحقیق پیش کرتا ہے جو اس میں آواز ہے۔ پارسینگ پرسس دو قدم سے ہے، ارتباط کے کلمات کو متصل کرتا ہے اور پھر ان کے ارتباط کا لیبل کرتا ہے. ہم بہت سی عمیق سیکھنے کی معماری کے ساتھ آزمائش کرتے ہیں ہر کام کو آزاد کے ساتھ استعمال کرنے کے لئے۔ بات کی تعلق میں ایک بیفن مدل بہترین کام کیا گیا۔ رابطہ لیبلینگ کے کام میں ایک ٹھیک تنظیم BERT موڈل بہترین عمل کرتا تھا۔ Two sentence encoders are employed, and we observed that non-fine-tuning models generally performed better when using Sentence-BERT as opposed to BERT encoder. ہم نے ہمارے مدلکوں کو دو قسم کے متعادل متقابل متقابل استعمال کر دیا تھا: اصلی صدا کی EFL رسی اور ان لوگوں کو جو annotators کے ذریعہ بہتر ہوئے تھے، پھر ان کو اصلی رسی پر ارزش کر لیا تھا. آزمائش دکھاتا ہے کہ ایک ڈومین سیسٹم میں آخر-to-end کے طور پر .341 کی دقیق پہنچ گئی۔ دوسری طرف، کرس ڈومین سیسٹم نے ڈومین سیسٹم کی 94% فعالیت پائی۔ یہ نشانیاں ہیں کہ بہترین لکھی ہوئی پیغام بھی مفید ہو سکتے ہیں کہ آواز کے پیغام کے لئے آواز منڈ سیسٹم کی تعلیم کرنے کے لئے۔</abstract_ur>
      <abstract_uz>Bu qoʻllar ingliz tilida (EFL) tilida argumentative tizimni ajratish uchun o'qituvchi o'rganishni tahrirlaydi. Bu bizning huddi hamma holatdir. Name Biz har bir vazifani o'xshash o'rganish maktablari bilan o'rganamiz. Bogʻliq vazifani bir so'zda biffin modeli eng yaxshi bajarildi. Maʼlumot bajarayotganda yaxshi BERT modeli eng yaxshi bajarildi. Ikki so'zlar kodlash qoidalari ishlaydi, va biz bir necha bogʻ'liq modellarni BERT kodlash bilan foydalanayotganda umuman yaxshi bajarish mumkin. Biz modellarimizni ikki turli parallel textlardan foydalanib o'rganimiz: asl EFL maslahatlari va taʼminlovchilar orqali o'zgartirdi, keyin ularni asl yozlarida qiymatish mumkin. Imtiyozni koʻrsatish mumkin, domen tizimining oxirigi oxirigi tizimi faqat .341 tizimga yetishdi. Бошқа тарафда, cross-domen tizimi domen tizimning 94% bajarishga erishildi. Name</abstract_uz>
      <abstract_vi>Tờ giấy này cung cấp một nghiên cứu về các bài luận văn của ngôn ngữ Anh-như-ngôn ngữ-ngoại-Anh (EFL) mà có âm tính rất ồn ào. Cách phân tích gồm hai bước, nối các câu liên quan và sau đó khắc định quan hệ. Chúng tôi thử vài kiến trúc về học sâu để giải quyết mọi nhiệm vụ một cách độc lập. Trong câu kết nối câu này, mô hình hai cam đã làm tốt nhất. Trong nhiệm vụ gắn kết, mô hình BERT được chỉnh cẩn thận đã làm tốt nhất. Hai câu mã hóa phần tử được sử dụng, và chúng tôi quan sát rằng các mô hình chưa được tinh chỉnh thông thường hoạt động tốt hơn khi sử dụng. Chúng tôi đã đào tạo các mẫu bằng hai loại văn bản song song song: các bài thi EFL nguyên bản và những bài viết được sửa chữa, sau đó đánh giá chúng bằng các bài luận gốc. Thí nghiệm cho thấy rằng hệ thống miền-cuối-tới-kết đã đạt độ chính xác của.341. Mặt khác, hệ thống lãnh thổ đạt được tỉ lệ ứng dụng của hệ thống nội bộ. Đây là tín hiệu cho thấy văn bản viết tốt cũng có ích để đào tạo hệ thống khai thác tranh luận cho các văn bản ồn ào.</abstract_vi>
      <abstract_bg>Настоящата статия представя проучване за анализиране на аргументативната структура в есетата на английски като чужд език (ЕФЛ), които по своята същност са шумни. Процесът на анализиране се състои от две стъпки, свързване на свързаните изречения и след това етикетиране на техните взаимоотношения. Експериментираме с няколко архитектури за дълбоко обучение, за да се справим самостоятелно с всяка задача. В задачата за свързване на изречения биафинов модел се представи най-добре. В задачата по отношение на етикетирането най-добре се представи фино настроеният модел BERT. Използват се два кодера на изречения и забелязахме, че моделите с нефина настройка обикновено се представят по-добре при използване на кодера за разлика от кодера за изречение. Обучихме моделите си, използвайки два типа паралелни текстове: оригинални шумни есета и тези подобрени с анотатори, след което ги оценяваме на оригиналните есета. Експериментът показва, че система от край до край е постигнала точност от 0,341. От друга страна, междудомейнната система постига 94% производителност на вътрешната система. Това сигнализира, че добре написаните текстове също могат да бъдат полезни за обучение на система за аргументи за шумни текстове.</abstract_bg>
      <abstract_da>Denne artikel præsenterer en undersøgelse af analyse af argumentationsstrukturen i engelsk-som-fremmedsprog (EFL) essays, som i sig selv er støjende. Analyseprocessen består af to trin, der forbinder relaterede sætninger og derefter mærker deres relationer. Vi eksperimenterer med flere deep learning arkitekturer for at løse hver opgave uafhængigt. I sætningsforbindelsesopgaven klarede en biaffine model sig bedst. I forbindelse med mærkning af relationer klarede en finjusteret BERT-model sig bedst. Der anvendes to sætningskodere, og vi bemærkede, at ikke-finjusterende modeller generelt klarede sig bedre ved brug af Sentence-BERT i modsætning til BERT encoder. Vi trænede vores modeller ved hjælp af to typer parallelle tekster: originale støjende EFL essays og dem forbedret af kommentatorer, og derefter evaluere dem på de originale essays. Eksperimentet viser, at et end-to-end in-domain system opnåede en nøjagtighed på .341. På den anden side opnåede systemet på tværs af domæner 94% ydeevne af det in-domæne system. Dette signalerer, at velskrevne tekster også kan være nyttige til at træne argument mining system til støjende tekster.</abstract_da>
      <abstract_nl>Dit artikel presenteert een studie over het parsen van de argumentatieve structuur in Engels-als-vreemde-taal (EFL) essays, die inherent luidruchtig zijn. Het parsing proces bestaat uit twee stappen, het koppelen van verwante zinnen en vervolgens het labelen van hun relaties. We experimenteren met verschillende deep learning architecturen om elke taak onafhankelijk aan te pakken. In de zinskoppelingstaak presteerde een biaffine model het beste. Bij de relatielabelstructuur presteerde een verfijnd BERT-model het beste. Er worden twee zinnencoders gebruikt, en we zagen dat niet-fine-tuning modellen over het algemeen beter presteerden bij het gebruik van Sentence-BERT in tegenstelling tot BERT encoder. We hebben onze modellen getraind met behulp van twee soorten parallelle teksten: originele noise EFL essays en die verbeterd door annotators, en ze vervolgens geëvalueerd op de originele essays. Het experiment toont aan dat een end-to-end in-domein systeem een nauwkeurigheid van .341 bereikte. Aan de andere kant behaalde het domeinoverschrijdende systeem 94% prestaties van het in-domein systeem. Dit geeft aan dat goed geschreven teksten ook nuttig kunnen zijn om argument mining systeem te trainen voor lawaaierige teksten.</abstract_nl>
      <abstract_hr>Ovaj papir predstavlja ispitivanje o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces razmatranja sastoji se od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo s nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, najbolje je izvršio dobar model BERT-a. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni prilagođavali općenito ispunjavaju bolje kada koriste kaznu-BERT suprotno koderu BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne eseje EFL-a i one koje su poboljšale annotatori, a onda ih procijeniti na originalnim esejima. Eksperiment pokazuje da je sustav kraja do kraja u domenu postigao to čnost od .341. S druge strane, sustav prekršnog domena postigao je 94% učinkovitosti sustava domena. Ovi signali su da dobro napisani teksti mogu biti korisni i za obuku rudarskog sustava argumentacija za bučne tekste.</abstract_hr>
      <abstract_de>Diese Arbeit stellt eine Studie zur Analyse der argumentativen Struktur in Englisch-als-Fremdsprache (EFL) Essays vor, die inhärent lauter sind. Der Parsing-Prozess besteht aus zwei Schritten, die verwandte Sätze verknüpfen und dann ihre Beziehungen kennzeichnen. Wir experimentieren mit mehreren Deep Learning Architekturen, um jede Aufgabe unabhängig zu lösen. In der Satzverknüpfungsaufgabe zeigte sich ein Biaffinmodell am besten. Bei der Beziehungsbeschriftung zeigte sich ein fein abgestimmtes BERT-Modell am besten. Es werden zwei Satzkodierer eingesetzt, und wir haben beobachtet, dass nicht-Feinabstimmungsmodelle im Allgemeinen besser abschneiden, wenn SatzBERT verwendet wird als BERT-Kodierer. Wir trainierten unsere Modelle mit zwei Arten von parallelen Texten: Original-geräuschvolle EFL-Essays und diejenigen, die durch Annotatoren verbessert wurden, und evaluieren sie dann auf den Originalessays. Das Experiment zeigt, dass ein End-to-End In-Domain System eine Genauigkeit von .341 erreicht hat. Auf der anderen Seite erzielte das domänenübergreifende System 94% Leistung des Domänensystems. Dies signalisiert, dass gut geschriebene Texte auch nützlich sein können, um Argument Mining System für laute Texte zu trainieren.</abstract_de>
      <abstract_id>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  Proses penghuraian terdiri dari dua langkah, menghubungkan kalimat yang berhubungan dan kemudian mengetikkan hubungan mereka. Kami eksperimen dengan beberapa arsitektur belajar dalam untuk mengatasi setiap tugas secara independen. Dalam kalimat yang menghubungkan tugas, model biaffine melakukan yang terbaik. Dalam tugas etiket hubungan, model BERT yang disesuaikan lebih baik. Dua pengkode kalimat digunakan, dan kami memperhatikan bahwa model non-fine-tuning biasanya berhasil lebih baik ketika menggunakan Sentence-BERT daripada BERT pengekode. Kami melatih model kami menggunakan dua jenis teks paralel: essai EFL bunyi asli dan yang diperbaiki oleh annotator, kemudian mengevaluasinya pada essai asli. Eksperimen menunjukkan bahwa sistem domain akhir-akhir mencapai akurasi .341. Di sisi lain, sistem cross-domain mencapai prestasi 94% dari sistem in-domain. Sinyal ini bahwa teks yang ditulis dengan baik juga dapat berguna untuk melatih sistem pertambangan argumen untuk teks yang berisik.</abstract_id>
      <abstract_ko>본고는 영어가 외국어(EFL)로서의 문장 중의 논문 구조를 분석 연구하였다.해석 과정은 두 가지 절차를 포함하여 관련 문장을 연결한 다음에 그것들의 관계를 표시한다.우리는 각 임무를 독립적으로 해결하기 위해 몇 가지 심도 있는 학습 체계 구조를 시도했다.문장 연결 작업 중 아분 모형보다 표현이 가장 좋다.관계 표기 작업 중 미세한 버트 모형이 가장 잘 나타난다.우리는 두 개의 문장 인코더를 사용했고, 문장 BERT 인코더가 아닌 문장 BERT를 사용할 때, 비미세 모형이 일반적으로 더 잘 표현되는 것을 관찰했다.우리는 두 가지 평행 텍스트를 사용하여 우리의 모델을 훈련시켰다. 그것이 바로 원시 시끄러운 EFL 문장과 주석자가 개선한 문장이다. 그리고 원시 문장에서 그것들을 평가한다.실험에 의하면 끝에서 끝까지 시스템의 정밀도는 0.341에 이르렀다.다른 한편, 도메인 간 시스템의 성능은 도메인 내 시스템의 94%에 달한다.좋은 텍스트를 쓰는 것도 소음 텍스트를 훈련하는 파라미터 발굴 시스템에 사용될 수 있다는 뜻이다.</abstract_ko>
      <abstract_sw>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  mchakato wa wimbo huo unajumuisha hatua mbili, ukiunganisha hukumu zinazohusiana na kisha kuonyesha mahusiano yao. Tunajaribu na majengo kadhaa ya kujifunza yenye muhimu ili kuzungumza kila kazi kwa uhuru. Katika hukumu inayounganisha kazi hiyo, muundo wa upinzani uliofanya vizuri zaidi. Katika jukumu la kutangaza, modeli yenye ujuzi mzuri ya BERT ilifanya vizuri zaidi. Watu wawili wa hukumu wanatumiwa, na tuliona kuwa mifano yasiyo na mafanikio mazuri kwa ujumla ulifanya vizuri wakati wakitumia Hukumu-BERT kinyume na mfumo wa BERT. Tulifunza mifano yetu kwa kutumia aina mbili ya maandishi ya usambazaji: masomo ya asili ya EFL na zile zile zile zilizobadilishwa na wataalamu, kisha kutathmini katika matoleo ya awali. Tatizo hilo linaonyesha kwamba mwisho wa mwisho wa mfumo wa ndani ulipata ukweli wa .341. Kwa upande mwingine, mfumo wa ndani ulipata asilimia 94 ya utendaji wa mfumo wa ndani. Hii inaonyesha kuwa maandishi yaliyoandikwa vizuri yanaweza pia kuwa na manufaa ya kufundisha mfumo wa madini ya uchimbaji wa hoja kwa ajili ya ujumbe wa sauti.</abstract_sw>
      <abstract_fa>این کاغذ یک مطالعه در مورد بررسی ساختار مطمئنی در امتحان انگلیسی به عنوان زبان خارجی (EFL) را نشان می دهد که در اصل صدا است. فرایند جدا کردن از دو قدم است که جمله‌های ارتباطی را ارتباط می‌دهد و بعدش رابطه‌هایشان را برچسب می‌کند. ما با چند معماری عمیق یادگیری آزمایش می کنیم تا هر کار را به خصوصی بررسی کنیم. در جمله مرتبط کار، یک مدل طبیعی بهترین عمل کرد. در وظیفه برچسب ارتباط، یک مدل BERT خوب تنظیم شده بهترین عمل کرد. دو تنظیم‌کننده‌ی عبارت استفاده می‌شوند، و ما متوجه شدیم که مدل‌های غیر تنظیم‌کننده‌ای عموماً بهتر انجام می‌دهند وقتی استفاده از عبارت-BERT در مقابل رمز‌کننده BERT انجام می‌دهند. ما مدل‌هایمان را با استفاده از دو نوع متن parallel آموزش دادیم: رسی‌های صوتی EFL و آن‌ها که توسط آهنگ‌کنندگان بهتر شده‌اند، سپس آنها را در رسی‌های اصلی ارزیابی می‌کنیم. این آزمایش نشان می دهد که یک سیستم پایان و پایان در دومین دقیقاتی از .341 رسیده است. از طریق دیگر، سیستم‌های مختلف دامنه‌ای 94 درصد عملکرد سیستم دامنه‌ای را به دست آورد. این سیگنال‌ها که متن‌های خوب نوشته می‌توانند برای آموزش سیستم خریدن مدارک برای متن‌های صوتی استفاده کنند.</abstract_fa>
      <abstract_tr>Bu kagyz iňlis dilinde (EFL) surat çykyşynyň (argümat) eserlerini çykyp biljek bir arzuw görkezýär. Açmak prosesi iki adımdır, sözleri baglaýar we soňra olaryň ilişkilerini etiketleýändir. Biz her zady özbaşdak çykmak üçin birnäçe derin öwrenme arhitekturmalary bilen synanyşýarys. Sözlemde işi baglaşdyrmak üçin, bir biaffin nusgasy iň gowy etdi. etiket täblisasynda, eňleýin etiket täblisasynda BERT nusgasy iň gowy edipdi. Iki sözlem kodçysy işledildi we biz bejerdik ki, sözlem-BERT kodçysynyň tersine ol işe yaramaz nusgalary gowurak etýändigini görnüşdik. Modellerimizi iki tür paralel metin kullanarak eğitirdik: orijinal ses EFL eserleri ve annotatorlar tarafından geliştirilen eserleri üzerinde değerlendirdik. Denemek bolup domeniň soňunda soňunda bir sistemasyň .341-yň dogrylygyny ýetip bardygyny görkezýär. On the other hand, the cross-domain system achieved 94% performance of the domain system. Bu işaretler, gowy ýazylan metinler goş metinler üçin argüm taýýarlama sistemasyny trenlemek üçin faydaly bolup biler.</abstract_tr>
      <abstract_sq>Ky dokument paraqet një studim mbi analizimin e strukturës argumentuese në esejat angleze-si-gjuhë-e huaj (EFL), të cilat janë natyrisht zhurmëshme. Procesi i analizimit përbëhet nga dy hapa, duke lidhur frazat e lidhura dhe pastaj duke etiketuar marrëdhëniet e tyre. Ne eksperimentojmë me disa arkitektura mësimi të thellë për të trajtuar çdo detyrë në mënyrë të pavarur. Në fjalimin që lidh detyrën, një model biffin bëri më të mirën. In the relation labelling task, a fine-tuned BERT model performed the best.  Dy koduesit e fjalëve janë të përdorur dhe ne vëzhguam se modelet jo të rregulluara në përgjithësi funksiononin më mirë kur përdornin Sentence-BERT në vend të koduesit BERT. We trained our models using two types of parallel texts: original noisy EFL essays and those improved by annotators, then evaluate them on the original essays.  Eksperimenti tregon se një sistem në domeni arriti një saktësi prej .341. Nga ana tjetër, sistemi transdomenik arriti 94% performancë të sistemit brenda domenit. Kjo sinjalizon se tekstet e shkruara mirë mund të jenë gjithashtu të dobishme për të trajnuar sistemin e minierave të argumenteve për tekste zhurmëshme.</abstract_sq>
      <abstract_af>Hierdie papier stel 'n studie op die verwerking van die argumentatiewe struktuur in Engelske as-vreemde-taal (EFL) essays, wat inherent geluid is. Die verwerking proses bestaan van twee stappe, verbind verwante setnings en dan etiket hulle verwante. Ons eksperimenteer met verskeie diep leer arkitektuur om elke taak onveilig te adres. In die seting wat die taak verbind het, het 'n biaffine model die beste uitgevoer. In die verwanting etiketting taak, het 'n fyn- tuned BERT model die beste uitgevoer. Twee setkoders word gebruik, en ons het aanhou dat nie-fin-tuning-modele generelik beter uitgevoer het wanneer Sentence-BERT gebruik word as teen BERT-koder. Ons het ons modele opgelei met twee tipes parallele teks: oorspronklike geluide EFL eseë en die wat deur annotators verbeter is, dan evalueer hulle op die oorspronklike eseë. Die eksperiment vertoon dat 'n end- to- end in- domain stelsel ' n presies van .341 bereik het. Op die ander kant het die kruisdomein stelsel 94% effektuur van die in-domein stelsel bereik. Hierdie signale wat goed geskrywe teks ook nuttig kan wees om argument mining stelsel te tref vir geluide teks.</abstract_af>
      <abstract_am>ይህ ገጽ የኢንጂልኛ-እንደ እንግዳ ቋንቋ (EFL) የግል ቋንቋ-ቋንቋ-የቋንቋ-ቋንቋን የግንኙነት አካባቢ ግንኙነትን ማግኘት የሚያስፈልገውን ትምህርት ያቀርባል፡፡ የፓርላማው ፕሮጀክት ሁለት ደረጃዎች ነው፣ የግንኙነት ቃላትን እና ግንኙነታቸውን በማሳመር ነው፡፡ ለሁሉም ስራ ነፃ ለማነጋገር በብዙ ጥልቅ ትምህርት መሠረታዎችን እናሞክራለን፡፡ በቁጥጥር የሚታያየው ስራ፣ የፊፊን ሞዴል የተሻለ ነው፡፡ በተግባር ስራ ላይ የተሻለ የBERT ሞዴል የተሻለ ነው፡፡ ሁለትም የፍርድ የፊደል ቀለሞች ይሞክራሉ፣ የBERT ኮድ በተቃወመ ጊዜ የፍርድ-BERT ኮድ በተደረገ ጊዜ የተሻለ የፊደል ሞዴል እንደተደረገ አየን፡፡ የሁለት ዓይነት መልዕክቶች በተለያዩ ጽሑፎችን አስተማርነው፤ የኢ.አ.አ.አ.ለ.አ.ለ.አ.አ.ለ.አ.አ.አ.ለ.አ.አ.አ.አ.አ.አ.ለ.አ.አ.አ. The experiment shows that an end-to-end in-domain system achieved an accuracy of .341.  በሌላው ክፍል የዶሜን ስርዓት 94 በመቶ ድምፅ አግኝቷል፡፡ ይህች ሲልክ መልካም የተጻፈ ጽሑፎች እና የድምፅ ጽሑፎችን ለመጠቀም የአጋራጆች ዋና ማጭበር ሲስተም ይጠቅማል፡፡</abstract_am>
      <abstract_bn>এই পত্রিকাটি ইংরেজী হিসেবে বিদেশী ভাষায় যুক্তিগত কাঠামো পার্স করার বিষয়টি একটি গবেষণা উপস্থাপন করেছে, যা অন্তর্ভুক্ত শব্দ। পার্সিং প্রক্রিয়ার মধ্যে দুই পদক্ষেপ রয়েছে, যার সাথে সম্পর্কিত শাস্তি লিঙ্ক করে এবং তারপর তাদের সম্পর্কের আমরা বেশ কয়েকটি গভীর শিক্ষা শিক্ষা প্রতিটি কাজের স্বাধীন ভাবে কথা বলার পরীক্ষা করছি। এই বাক্যে লিঙ্ক করা কাজে একটি বিফিন মডেল সবচেয়ে ভালো করেছে। সম্পর্কের ল্যাবেলিং কাজের মধ্যে একটি ভালো ভালো ভালো ভাবে বেরেট মডেল শুরু করেছে। দুই শাস্তি এনকোডার ব্যবহার করা হয়েছে এবং আমরা দেখেছি যে শাস্তি বিবের্ট এনকোডার বিরুদ্ধে ব্যবহার করার বিরুদ্ধে সাধারণত ভালো কাজ করা ন আমরা আমাদের মডেল দুটি ধরনের প্যারালেল লেখা ব্যবহার করে প্রশিক্ষণ প্রশিক্ষণ দিয়েছি: প্রাথমিক শব্দ ইএফএল প্রসেস এবং যারা শিক্ষার্থীদের এই পরীক্ষাটি দেখাচ্ছে যে ডোমেইনের শেষ পর্যন্ত শেষ ব্যবস্থা সঠিকভাবে পৌঁছেছে। অন্যদিকে, ক্রিস্ট ডোমেইন সিস্টেমের ৯৪% পালন করেছে। এই সিগন্যালটি দেখাচ্ছে যে ভাল লিখিত লেখাগুলো শব্দ লেখার জন্য যুক্ত মিনিং সিস্টেম প্রশিক্ষণের জন্যে উপ</abstract_bn>
      <abstract_az>Bu kağıt İngilis dilində-Dışarı dilində (EFL) essaylarında müzakirçi strukturlarını ayırmaq haqqında bir təhsil göstərir. Analizasyon prosesi iki adımdır, əlaqəsiz cümlələri bağlayır və sonra onların əlaqələrini etiketləyir. Biz hər işi təmizlə çəkmək üçün çox derin öyrənmə arhitektarlarıyla imtahana çəkirik. İşləri bağlayıb cümlədə, bir biafin modeli ən yaxşı işlədi. İlişkisi etiketləmə işində, BERT modeli ən yaxşı işlədi. İki cümləlik kodlayıcısı istifadə edilir, və biz BERT kodlayıcısı ilə əlavə etdikdə çox yaxşı işlədiklərini gördük. Biz modellərimizi iki türü paralel metin vasitəsilə təhsil etdik: orijinal səslü EFL essayları və annotatorların təhsil edilənlər, sonra onları orijinal essaylarda təhsil edirik. Bu təcrübə göstərir ki, domeinin sonu-sonu sisteminin .341 dəqiqliyinə nail oldu. Digər tərəfindən, çox domena sistemi domena sisteminin 94% performansını qəbul etdi. Bu sinyallər, yaxşı yazılmış mətnlər də səsl mətnlər üçün arqümət madenci sistemini təhsil etmək üçün faydalı olar.</abstract_az>
      <abstract_hy>Այս հոդվածը ներկայացնում է մի ուսումնասիրություն անգլերեն-օտար-լեզու (EFL) էսսեների արտահայտության վերլուծության մասին, որոնք բնական աղմուկ են: Փորձարկման գործընթացը կազմված է երկու քայլ, կապելով կապված նախադասությունները և հետո պիտակելով նրանց հարաբերությունները: Մենք փորձում ենք մի քանի խորը ուսուցման ճարտարապետությունների հետ յուրաքանչյուր խնդիր անկախ լուծելու համար: Արտահայտությունը կապված նախադասության մեջ երկաֆինի մոդելը լավագույնն արեց: Ինչ վերաբերում է պիտակավորման խնդրին, լավագույնը կատարեց բարձրացված BERT մոդելը: Երկու նախադասություն կոդավորիչներ են օգտագործվում, և մենք նկատեցինք, որ ոչ բարձրակարգման մոդելները սովորաբար ավելի լավ են աշխատում օգտագործելով նախադասություն-BER-ը, ի հակադրություն BER-ի կոդավորիչը: Մենք ուսուցանում էինք մեր մոդելները երկու տեսակի զուգահեռ տեքստերի օգտագործելով' սկզբնական աղմկոտ EFL էսսեները, որոնք բարելավվել են annoտորների կողմից, հետո գնահատում ենք դրանք սկզբնական էսսերի վրա: Փորձը ցույց է տալիս, որ տիեզերքի վերջ-վերջ համակարգը հասավ .341 ճշգրիտության: Մյուս կողմից, տիեզերական համակարգը հասավ տիեզերական համակարգի 94 տոկոսի արդյունավետության: Սա ազդանշան է տալիս, որ լավ գրված տեքստերը կարող են օգտակար լինել նաև աղմկոտ տեքստերի համար բանավեճերի հանքային համակարգի ուսումնասիրելու համար:</abstract_hy>
      <abstract_bs>Ovaj papir predstavlja studiju o razmatranju argumentativne strukture na esejima engleskog kao stranog jezika (EFL), koje su inherentno bučne. Proces analize se sastoji od dva koraka, povezujući povezane rečenice i onda označavajući njihove odnose. Eksperimentiramo sa nekoliko dubokih arhitektura učenja da se riješimo svakom zadatku nezavisno. U rečenici povezujući zadatak, model biafina je izvršio najbolje. U zadatku označavanja odnosa, dobro određeni model BERT izvršio je najbolje. Dva kodera rečenice su zaposlena, a mi smo primijetili da modeli koji nisu ispravni, obično su bolje izvršili kada su koristili kaznu-BERT u suprotnosti sa koderom BERT-a. Obučavali smo naše modele koristeći dvije vrste paralelnih tekstova: originalne bučne EFL eseje i one koje su poboljšale annotatori, a onda ih procjenjivali na originalnim esejima. Eksperiment pokazuje da je sistem kraja do kraja u domenu postigao tačnost od .341. S druge strane, sistem krstodomena postigao je 94% učinkovitosti sustava u domenu. Ovi signali su da dobro napisani teksti mogu biti korisni i za treniranje rudarskog sustava argumenta za bučne tekstove.</abstract_bs>
      <abstract_ca>Aquest paper presenta un estudi sobre l'analització de l'estructura argumentativa en els assats anglès-com-estrangers (EFL), que són inherentment sorollosos. El procés d'analització consisteix en dos passos, enllaçant frases relacionades i etiquetant les seves relacions. Experimentem amb diverses arquitectures d'aprenentatge profund per abordar cada tasca de manera independent. In the sentence linking task, a biaffine model performed the best.  En la tasca d'etiquetar les relacions, un model BERT ajustat va fer el millor. S'utilitzen dos codificadors de frases, i vam observar que els models no fins ajustes generalment van funcionar millor quan utilitzen Sentence-BERT en comptes del codificador BERT. Vam treinar els nostres models fent servir dos tipus de textos parallels: els assaig original sorollós EFL i els millorats pels anotators, i després els vam evaluar en els assaig originals. L'experiment mostra que un sistema de domini final a final va aconseguir una precisió de .341. D'altra banda, el sistema transdomínic va aconseguir un 94% de rendiment del sistema intradomínic. Això indica que els textos ben escrits també poden ser útils per entrenar el sistema de mineria d'arguments per a textos ruidosos.</abstract_ca>
      <abstract_et>Käesolevas töös esitatakse uuring inglise kui võõrkeele esseede argumentatiivse struktuuri parsimise kohta, mis on olemuslikult lärmakad. Parsimisprotsess koosneb kahest etapist, sidudes seotud laused ja märgistades seejärel nende suhted. Me eksperimenteerime mitme sügavõppe arhitektuuriga, et iga ülesande lahendada iseseisvalt. Lausete sidumise ülesandes oli parim biafiin mudel. Märgistamisega seotud ülesande puhul oli parim tulemus täpsustatud BERTi mudel. Kasutatakse kahte lausekodeerijat ja täheldasime, et mittepeenhäälestuslikud mudelid toimivad üldiselt paremini Sentence-BERT kasutamisel kui BERT kodeerija. Koolitasime oma mudeleid kahte tüüpi paralleelsete tekstide abil: originaalsed mürakad EFL esseed ja parandatud annotatorid, seejärel hindame neid originaalsete esseede põhjal. Katse näitab, et domeenisisene süsteem saavutas täpsuse 0,341. Teisest küljest saavutas valdkondadevaheline süsteem 94% jõudluse valdkonnasisest süsteemist. See annab märku, et hästi kirjutatud tekstid võivad olla kasulikud ka argumentide kaevandamise süsteemi koolitamiseks mürakate tekstide jaoks.</abstract_et>
      <abstract_cs>Tento článek představuje studii o analýze argumentativní struktury v esejích angličtiny jako cizího jazyka (EFL), které jsou z podstaty hlučné. Proces parsování se skládá ze dvou kroků, propojení souvisejících vět a následně označení jejich vztahů. Experimentujeme s několika architekturami hlubokého učení, abychom řešili každý úkol nezávisle. Ve větě propojující úkol, biafinový model vedl nejlépe. Při úkolu označování vztahů nejlépe fungoval jemně vyladěný model BERT. Používají se dva snímače vět a pozorovali jsme, že modely bez jemného ladění většinou fungují lépe při použití Sentence-BERT než BERT snímač. Naše modely jsme trénovali pomocí dvou typů paralelních textů: originálních hlučných EFL esejí a těch, které vylepšují anotátory, a poté je vyhodnocují na originálních esejích. Experiment ukazuje, že end-to-end in-domain systém dosáhl přesnosti .341. Na druhou stranu, cross-domain systém dosáhl 94% výkonnosti in-domain systému. To signalizuje, že dobře napsané texty mohou být také užitečné pro trénink argument mining systému pro hlučné texty.</abstract_cs>
      <abstract_fi>Tämä artikkeli esittelee tutkimuksen argumentatiivisen rakenteen jäsentämisestä englanti vieraana kielenä -esseissä, jotka ovat luonnostaan meluisia. Analysointiprosessi koostuu kahdesta vaiheesta, jotka yhdistävät toisiinsa liittyvät lauseet ja merkitsevät niiden suhteet. Kokeilemme useita syväoppimisen arkkitehtuureja kunkin tehtävän käsittelemiseksi itsenäisesti. Lausekkeen linkitystehtävässä biafiinimalli suoriutui parhaiten. Suhteeseen merkitsemistä koskevassa tehtävässä parhaiten suoriutui hienosäädetty BERT-malli. Käytössä on kaksi lauseenkooderia, ja havaitsimme, että ei-hienosäätömallit suoriutuivat yleensä paremmin Sentence-BERT-kooderilla kuin BERT-kooderilla. Koulutimme mallit kahdentyyppisillä rinnakkaisilla teksteillä: alkuperäisillä noisy EFL esseillä ja kommentaattoreilla parannelluilla esseillä, minkä jälkeen arvioimme niitä alkuperäisillä esseillä. Koe osoittaa, että kokonaisvaltainen verkkotunnusjärjestelmä saavutti tarkkuuden 0,341. Toisaalta toimialojen välinen järjestelmä saavutti 94% suorituskykyä toimialojen sisäisestä järjestelmästä. Tämä osoittaa, että hyvin kirjoitetut tekstit voivat olla hyödyllisiä myös argumenttien louhintajärjestelmän kouluttamisessa meluisille teksteille.</abstract_fi>
      <abstract_ha>Wannan takardan na bãyar da wani littãfi a kan parse muhimmanci cikin harshen Ingiriya-as-kigenre (EFL), wanda ke cikin sauti. @ action: button We experiment with several deep learning architectures to address each task independently.  A cikin aikin da ke haɗi zuwa maganar, wata misali mai biyafi ya sami mafi kyaun. In the related labelin job, a mai kyau-tuned BERT Model ya samar da mafi kyaun. An yi amfani da kodi biyu na maganar, kuma ba mu gani ba cewa misãlai masu tunkuɗe wa-mai kyau a samu'a da mafiya kyau idan an yi amfani da Cincin-BERT kamar da ya motsa kodi na BERT. Kuma ba mu sanar da misalinmu da misalin misalin misalin biyu masu daidaita: makaranti na farko na EFL da waɗanda aka samar da su, sa'an nan kuma ka ƙaddara su a cikin takardar farko. Tafiyar da ke nuna cewa ƙari zuwa-ƙari cikin-guda ya sami tsari na .341. Ga da hagu, na'urar-ɗamfyuta ta sãmu 94% na'urar tsarin da ke cikin guda. Wannan ayukan ayuka da aka rubũta rubutu masu iya amfani da shi, ya zama mai amfani ga tunkuɗe tsarin sundin da aka yi wa matsayin sauti.</abstract_ha>
      <abstract_sk>V prispevku je predstavljena študija razčlenitve argumentativne strukture v esejih angleščine kot tuji jezik (EFL), ki so po sebi hrupni. Postopek razčlenitve je sestavljen iz dveh korakov, povezovanja povezanih stavkov in nato označevanja njihovih odnosov. Eksperimentiramo z več arhitekturami globokega učenja, da bi vsako nalogo obravnavali samostojno. Pri nalogi povezovanja stavkov je bil biafinski model najboljši. Pri nalogi označevanja povezav je bil najboljši prilagojen model BERT. Uporabljena sta dva kodirnika stavkov in opazili smo, da so modeli brez natančnega nastavljanja na splošno boljši pri uporabi kodirnika Sentence-BERT kot BERT. Naše modele smo usposabljali z dvema vrstama vzporednih besedil: originalnimi hrupnimi eseji EFL in tistimi, ki so jih izboljšali z opotatorji, nato pa jih ocenili na originalnih esejih. Poskus je pokazal, da je sistem od konca do konca dosegel natančnost 0,341. Po drugi strani pa je meddomenski sistem dosegel 94% zmogljivosti notranjega sistema. To kaže, da so dobro napisana besedila lahko koristna tudi za usposabljanje sistema rudarjenja argumentov za hrupna besedila.</abstract_sk>
      <abstract_he>This paper presents a study on parsing the argumentative structure in English-as-foreign-language (EFL) essays, which are inherently noisy.  תהליך המחקר מורכב משני צעדים, הקשר משפטים קשורים ואז סימן את מערכת היחסים שלהם. אנחנו מנסים עם כמה ארכיטקטורות למידה עמוקה כדי להתמודד עם כל משימה באופן עצמאי. במשפט הקשר משימה, דוגמנית ביאפין ביצעה את הטוב ביותר. במשימת התיקון, מודל BERT מעוצבן ביצע את הטוב ביותר. שני קודדים משפטים משתמשים, ואנחנו שמנו לב שדוגמנים לא מתאימים בדרך כלל ביצעו טוב יותר כשהשתמשו בשימוש בשימוש בשימוש בשימוש בשימוש במקום קודד BERT. אימנו את הדוגמנים שלנו באמצעות שני סוגים של טקסטים מקבילים: מאמרים מקוריים רעשים EFL ואלה ששותפים על ידי ציונים, ואז מעריכים אותם על המאמרים המקוריים. הניסוי מראה שמערכת בתחום של סוף אל סוף השיגה מדויקה של .341. מצד שני, מערכת התחום השיגה 94% ביצועים של מערכת התחום. זה מסמן שטקסטים נכתבים היטב יכולים להיות שימושיים גם לאמן מערכת כירות טיעונים לטקסטים רעשים.</abstract_he>
      <abstract_bo>ཤོག་བྱང་འདིས་ཨིན་ཡིག་གི་སྐད་ཡིག་ནང་གི་སྒྲུབ་གཏོང་གི་བཟོ་བསམ་ཞིག་བྱེད་སྐབས་ལྟ་བུ་མངོན་འཆར་ཡོད། དབྱེ་ཞིབ་ཀྱི་ལས་སྦྱོར་དེའི་གྲལ་ཐེངས་གཉིས་ལས་འབྲེལ་བ་ཡིན་པའི་ཚིག་རྟགས་དང་ཁོང་གི་འབྲེལ་བ ང་ཚོས་རེ་བོ་སོ་སོའི་ལས་འགུལ་གྱི་ཁྱད་ཆོས་སོ་སོའི་བཟོ་བརྩིས་གཞི་འདྲ་བྱེད་མ་ཐུབ། ཚིག མཐུན་འབྲེལ་གྱི་ཤོག་བྱང་ཀི་ལས་འགུལ་གྱི་ནང་དུ། ཚད་ལྡན་པའི་BERT མིག་དཔེ་ཞིག་ནི་སྐྱོན་ཤོས་ཡོད། ཚིག ང་ཚོས་མིག་གཟུགས་རིས་འདི་དག་གི་དབྱེ་བ་གཉིས་དབྱེ་བ་གི་ཡིག སྒེར་ཞུ་གིས་domain་ཐོག་མཐའ་མཇུག་གསུམ་དུ་མཐོང་བ་ཡིན།341 On the other hand, the cross-domain system achieved 94% performance of the in-domain system. This signals that well-written texts can also be useful to train argument mining system for noisy texts.</abstract_bo>
      <abstract_jv>Perkara iki nambah urip nggambar kelas pirsak nggawe tarjamahan seneng nggagal-ingkang kaya-nglanggar sapa-kenir (eFL). Genjer Awak dhéwé éntuk karo akeh akeh juter architecture kanggo sabên seneng nggawe gerakan sakjane. Nang papat nggambar task, supoyo biaFin nambah sing luwih apik. Nambah tengahane nggambar nggambar, model BERT wis ngawe barang apik. Yo wis rampung koder sing nggunakake ditambah, lan ampuhi awak dhéwé ngerasah model sing gak bener-ne-tuning nggawe barang luwih dumadhi kanggo nggunakake Sentense-BERT dumadhi karo koder BERT. Awak dhéwé éntuk sistem sing beraksi perusahaan dengané sampeyan kelangan iki: iso nggawe barang kegambar uwong, lan uwong sing nyebutaké awak dhéwé, njuk ujarané awak dhéwé sisayé surat sing uwong. The pilot show that an end-to-end in-domain System success an exact of .34 1. In the second hand, the inter-domain System met 1994% success of the in-domain System. structural navigation</abstract_jv>
      </paper>
    <paper id="11">
      <title>Training and Domain Adaptation for Supervised Text Segmentation</title>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Ananya</first><last>Ganesh</last></author>
      <author><first>Swapna</first><last>Somasundaran</last></author>
      <pages>110–116</pages>
      <abstract>Unlike traditional unsupervised text segmentation methods, recent supervised segmentation models rely on <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a> as the source of large-scale segmentation supervision. These models have, however, predominantly been evaluated on the in-domain (Wikipedia-based) test sets, preventing conclusions about their general segmentation efficacy. In this work, we focus on the domain transfer performance of supervised neural text segmentation in the educational domain. To this end, we first introduce K12Seg, a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for evaluation of supervised segmentation, created from educational reading material for grade-1 to college-level students. We then benchmark a hierarchical text segmentation model (HITS), based on RoBERTa, in both in-domain and domain-transfer segmentation experiments. While HITS produces state-of-the-art in-domain performance (on three Wikipedia-based test sets), we show that, subject to the standard full-blown fine-tuning, it is susceptible to domain overfitting. We identify adapter-based fine-tuning as a remedy that substantially improves transfer performance.</abstract>
      <url hash="c3e4e112">2021.bea-1.11</url>
      <bibkey>glavas-etal-2021-training</bibkey>
    </paper>
    <paper id="19">
      <title>C-Test Collector : A Proficiency Testing Application to Collect Training Data for C-Tests<fixed-case>C</fixed-case>-Test Collector: A Proficiency Testing Application to Collect Training Data for <fixed-case>C</fixed-case>-Tests</title>
      <author><first>Christian</first><last>Haring</last></author>
      <author><first>Rene</first><last>Lehmann</last></author>
      <author><first>Andrea</first><last>Horbach</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <pages>180–184</pages>
      <abstract>We present the C-Test Collector, a <a href="https://en.wikipedia.org/wiki/Web_application">web-based tool</a> that allows <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learners</a> to test their proficiency level using c-tests. Our tool collects anonymized data on test performance, which allows teachers to gain insights into common error patterns. At the same time, it allows NLP researchers to collect training data for being able to generate c-test variants at the desired difficulty level.</abstract>
      <url hash="2f718d2d">2021.bea-1.19</url>
      <bibkey>haring-etal-2021-c</bibkey>
    </paper>
    <paper id="22">
      <title>Sharks are not the threat humans are : Argument Component Segmentation in School Student Essays</title>
      <author><first>Tariq</first><last>Alhindi</last></author>
      <author><first>Debanjan</first><last>Ghosh</last></author>
      <pages>210–222</pages>
      <abstract>Argument mining is often addressed by a <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline method</a> where segmentation of text into argumentative units is conducted first and proceeded by an argument component identification task. In this research, we apply a token-level classification to identify claim and premise tokens from a new corpus of argumentative essays written by middle school students. To this end, we compare a variety of state-of-the-art models such as discrete features and deep learning architectures (e.g., BiLSTM networks and BERT-based architectures) to identify the argument components. We demonstrate that a BERT-based multi-task learning architecture (i.e., token and sentence level classification) adaptively pretrained on a relevant unlabeled dataset obtains the best results.</abstract>
      <url hash="825b3481">2021.bea-1.22</url>
      <bibkey>alhindi-ghosh-2021-sharks</bibkey>
    </paper>
    </volume>
</collection>