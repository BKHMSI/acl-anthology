<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.privatenlp">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Privacy in NLP</booktitle>
      <editor><first>Oluwaseyi</first><last>Feyisetan</last></editor>
      <editor><first>Sepideh</first><last>Ghanavati</last></editor>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Patricia</first><last>Thaine</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="aa9e39bf">2020.privatenlp-1.0</url>
      <bibkey>privatenlp-2020-privacy</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Surfacing Privacy Settings Using Semantic Matching</title>
      <author><first>Rishabh</first><last>Khandelwal</last></author>
      <author><first>Asmit</first><last>Nayak</last></author>
      <author id="yao-yao-uwisc"><first>Yao</first><last>Yao</last></author>
      <author><first>Kassem</first><last>Fawaz</last></author>
      <pages>28–38</pages>
      <abstract>Online services utilize privacy settings to provide users with control over their data. However, these privacy settings are often hard to locate, causing the user to rely on provider-chosen default values. In this work, we train privacy-settings-centric encoders and leverage them to create an interface that allows users to search for privacy settings using free-form queries. In order to achieve this goal, we create a custom Semantic Similarity dataset, which consists of real user queries covering various privacy settings. We then use this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> to fine-tune a state of the art <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a>. Using this fine-tuned encoder, we perform <a href="https://en.wikipedia.org/wiki/Semantic_matching">semantic matching</a> between the <a href="https://en.wikipedia.org/wiki/Information_retrieval">user queries</a> and the privacy settings to retrieve the most relevant setting. Finally, we also use the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> to generate embeddings of privacy settings from the top 100 websites and perform unsupervised clustering to learn about the online privacy settings types. We find that the most common type of privacy settings are ‘Personalization’ and ‘Notifications’, with coverage of 35.8 % and 34.4 %, respectively, in our dataset.</abstract>
      <url hash="af9252e1">2020.privatenlp-1.4</url>
      <doi>10.18653/v1/2020.privatenlp-1.4</doi>
      <video href="https://slideslive.com/38939773" />
      <bibkey>khandelwal-etal-2020-surfacing</bibkey>
      <pwccode url="https://github.com/wi-pi/surface_privacy_dataset" additional="false">wi-pi/surface_privacy_dataset</pwccode>
    </paper>
    <paper id="5">
      <title>Differentially Private Language Models Benefit from Public Pre-training</title>
      <author><first>Gavin</first><last>Kerrigan</last></author>
      <author><first>Dylan</first><last>Slack</last></author>
      <author><first>Jens</first><last>Tuyls</last></author>
      <pages>39–45</pages>
      <abstract>Language modeling is a keystone task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. When training a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> on <a href="https://en.wikipedia.org/wiki/Information_sensitivity">sensitive information</a>, differential privacy (DP) allows us to quantify the degree to which our <a href="https://en.wikipedia.org/wiki/Personal_data">private data</a> is protected. However, training algorithms which enforce <a href="https://en.wikipedia.org/wiki/Differential_privacy">differential privacy</a> often lead to degradation in model quality. We study the feasibility of learning a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> which is simultaneously high-quality and privacy preserving by tuning a public base model on a private corpus. We find that DP fine-tuning boosts the performance of language models in the private domain, making the training of such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> possible.</abstract>
      <url hash="85aa5c44">2020.privatenlp-1.5</url>
      <doi>10.18653/v1/2020.privatenlp-1.5</doi>
      <video href="https://slideslive.com/38939774" />
      <bibkey>kerrigan-etal-2020-differentially</bibkey>
    <title_ar>تستفيد النماذج اللغوية الخاصة التفاضلية من التدريب المسبق العام</title_ar>
      <title_pt>Modelos de linguagem diferencialmente privados se beneficiam do pré-treinamento público</title_pt>
      <title_fr>Les modèles linguistiques privés bénéficient différemment de la pré-formation publique</title_fr>
      <title_es>Los modelos lingüísticos diferencialmente privados se benefician de la capacitación previa pública</title_es>
      <title_ja>公共の事前トレーニングの恩恵を受ける差別的私立言語モデル</title_ja>
      <title_zh>差异化私语模形受益于公共预培训</title_zh>
      <title_hi>विभेदक रूप से निजी भाषा मॉडल सार्वजनिक पूर्व प्रशिक्षण से लाभ</title_hi>
      <title_ru>Различные модели частного языка получают выгоду от государственного предварительного обучения</title_ru>
      <title_ga>Baineann Múnlaí Teanga Príobháideacha Difreálacha tairbhe as Réamhoiliúint Phoiblí</title_ga>
      <title_ka>განსხვავებული პირადი ენის მოდელების გამოსახულება სახელსაწყისი წინატრიქციისგან</title_ka>
      <title_hu>A különböző magánnyelvi modellek előnyei a nyilvános előképzésből</title_hu>
      <title_el>Διαφορετικά ιδιωτικά γλωσσικά μοντέλα επωφελούνται από τη δημόσια προεκπαίδευση</title_el>
      <title_it>Modelli linguistici differentemente privati Beneficiare della pre-formazione pubblica</title_it>
      <title_kk>Жалпы алдындағы жеке тіл үлгілерінің пайдалануы</title_kk>
      <title_mk>Друференцијално приватни јазички модели користат од јавното преобука</title_mk>
      <title_lt>Įvairių privačių kalbų modelių nauda iš viešojo parengiamojo mokymo</title_lt>
      <title_mt>Benefiċċju ta’ mudelli ta’ lingwa privata b’mod differenzjat minn taħriġ pubbliku minn qabel</title_mt>
      <title_ml>വ്യത്യസ്ത്രീയ ഭാഷ മോഡലുകളില്‍ നിന്നും പൊതു പരിശീലനത്തില്‍ നിന്നും</title_ml>
      <title_ms>Mudah Model Bahasa Pribadi Dari Latihan Awam</title_ms>
      <title_mn>Хувь хэл загваруудыг олон нийтийн өмнөх сургалтын ашиглах</title_mn>
      <title_ro>Modelele lingvistice diferenţial private beneficiază de pregătirea publică</title_ro>
      <title_pl>Różnicowo prywatne modele językowe korzystają z publicznego przedszkolenia</title_pl>
      <title_no>Forskjellig privat språk- modeller nyttar frå offentleg føreøving</title_no>
      <title_sr>Razlièno privatne jezičke modele koristi od javne predobuke</title_sr>
      <title_si>වෙනස් පුද්ගලික භාෂා මොඩේල් ප්‍රශ්නයක් ප්‍රශ්නයක් සාමාන්‍ය ප්‍රධාන ප්‍රශ්නයක්</title_si>
      <title_so>Kaalmada waxbarashada dadweynaha</title_so>
      <title_sv>Olika privata språkmodeller Dra nytta av offentlig fortbildning</title_sv>
      <title_ta>பொது முன் பயிற்சியிலிருந்து வேறு தனிப்பட்ட மொழி மாதிரிகளின் உதவி</title_ta>
      <title_ur>مختلف مختلف خصوصی زبان موڈل جن کی پیشتربینی سے فائدہ اٹھائی جاتی ہے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_da>Differentielt private sprogmodeller drager fordel af offentlig foruddannelse</title_da>
      <title_nl>Verschillende private taalmodellen profiteren van openbare pre-training</title_nl>
      <title_bg>Диференциално частните езикови модели се възползват от публичното предобучение</title_bg>
      <title_hr>Različiti privatni jezički modeli koristi od javnog predobuka</title_hr>
      <title_de>Unterschiedlich private Sprachmodelle profitieren von öffentlichen Vortrainings</title_de>
      <title_id>Berbeda-beda Model Bahasa Pribadi Benefitnya dari Pre-pelatihan Publik</title_id>
      <title_ko>서로 다른 개인 언어 모델이 공공 예비 교육에서 이익을 얻다</title_ko>
      <title_fa>مدل های مختلف زبان خصوصی استفاده از پیش آموزش عمومی</title_fa>
      <title_sw>Kitofauti cha Modeli za Lugha Binafsi Utetezi kutoka mafunzo ya Umma</title_sw>
      <title_sq>Modelet e gjuhës private në mënyrë të ndryshme përfitojnë nga parastërvitja publike</title_sq>
      <title_tr>Aýratyn gizli diller</title_tr>
      <title_af>Verskillende Private Taal Modelle Benefinieerd van Publieke Voorvoering</title_af>
      <title_hy>Համաշխարհային նախապատրաստման առավելությունը</title_hy>
      <title_am>የግል ቋንቋ ሞዴል</title_am>
      <title_az>Q칲dr톛tli 칐n-t톛hsilind톛n faydalan캼r</title_az>
      <title_bn>পাবলিক প্রশিক্ষণের পূর্ব থেকে প্রাইভেট ভাষা মোডেল</title_bn>
      <title_bs>Različiti privatni jezički modeli koristi od javne predobuke</title_bs>
      <title_ca>Models de llenguatge diferencialment privat beneficien de la pré-capacitació pública</title_ca>
      <title_cs>Odlišně soukromé jazykové modely těží z veřejného předškolení</title_cs>
      <title_et>Erinevalt erakeele mudelid saavad kasu avalikust eelkoolitusest</title_et>
      <title_fi>Eri yksityiset kielimallit hyötyvät julkisesta esikoulutuksesta</title_fi>
      <title_jv>politenessoffpolite"), and when there is a change ("assertive</title_jv>
      <title_sk>Različno zasebni jezikovni modeli imajo koristi od javnega predusposabljanja</title_sk>
      <title_ha>Phonon:: MMF:: EffectFactory</title_ha>
      <title_he>מודלים שפות פרטיים שונים, תועלת מהאימון הקדמי הציבורי</title_he>
      <title_bo>སྤྱི་ཚོགས་གྱི་སྔོན་ལྟར་གྱི་སྒེར་གྱི་སྐད་ཆ་དབྱིབས་རིགས་ཀྱི་རྣམ་པ</title_bo>
      <abstract_ar>نمذجة اللغة مهمة أساسية في معالجة اللغة الطبيعية. عند تدريب نموذج لغوي على المعلومات الحساسة ، تتيح لنا الخصوصية التفاضلية (DP) تحديد درجة حماية بياناتنا الخاصة. ومع ذلك ، غالبًا ما تؤدي خوارزميات التدريب التي تفرض الخصوصية التفاضلية إلى تدهور جودة النموذج. ندرس جدوى تعلم نموذج لغة يتميز بجودة عالية ويحافظ على الخصوصية في نفس الوقت من خلال ضبط نموذج قاعدة عامة على مجموعة خاصة. نجد أن الضبط الدقيق لـ DP يعزز أداء نماذج اللغة في المجال الخاص ، مما يجعل تدريب مثل هذه النماذج ممكنًا.</abstract_ar>
      <abstract_es>El modelado del lenguaje es una tarea clave en el procesamiento del lenguaje natural. Al entrenar un modelo lingüístico sobre información confidencial, la privacidad diferencial (DP) nos permite cuantificar el grado de protección de nuestros datos privados. Sin embargo, los algoritmos de entrenamiento que aplican la privacidad diferencial a menudo conducen a la degradación de la calidad del modelo. Estudiamos la viabilidad de aprender un modelo lingüístico que sea simultáneamente de alta calidad y preserve la privacidad ajustando un modelo de base pública en un corpus privado. Observamos que el ajuste fino del PD aumenta el rendimiento de los modelos lingüísticos en el dominio privado, haciendo posible la formación de dichos modelos.</abstract_es>
      <abstract_pt>A modelagem de linguagem é uma tarefa fundamental no processamento de linguagem natural. Ao treinar um modelo de linguagem em informações confidenciais, a privacidade diferencial (DP) nos permite quantificar o grau em que nossos dados privados são protegidos. No entanto, algoritmos de treinamento que impõem privacidade diferencial geralmente levam à degradação da qualidade do modelo. Estudamos a viabilidade de aprender um modelo de linguagem que seja simultaneamente de alta qualidade e preservação da privacidade, ajustando um modelo de base pública em um corpus privado. Descobrimos que o ajuste fino de DP aumenta o desempenho de modelos de linguagem no domínio privado, tornando possível o treinamento de tais modelos.</abstract_pt>
      <abstract_fr>La modélisation du langage est une tâche clé dans le traitement du langage naturel. Lors de la formation d'un modèle linguistique sur des informations sensibles, la confidentialité différentielle (DP) nous permet de quantifier le degré de protection de nos données privées. Cependant, les algorithmes d'apprentissage qui appliquent la confidentialité différentielle entraînent souvent une dégradation de la qualité du modèle. Nous étudions la possibilité d'apprendre un modèle linguistique qui soit à la fois de haute qualité et de préservation de la vie privée en ajustant un modèle de base publique sur un corpus privé. Nous constatons que le réglage fin du Programme du diplôme améliore les performances des modèles linguistiques dans le domaine privé, ce qui rend possible la formation de tels modèles.</abstract_fr>
      <abstract_zh>言语者建模自然语言治之要务也。 敏感训言,差分隐私(DP)使我辈得量化吾私数保护如此。 然强制执行差分阴教算法常致模样。 吾论学一言之可行性,当因私语料库上以持高质量私之护。 吾见DP微调增私有域语言模形之性,使可得而教也。</abstract_zh>
      <abstract_hi>भाषा मॉडलिंग प्राकृतिक भाषा प्रसंस्करण में एक कीस्टोन कार्य है। संवेदनशील जानकारी पर एक भाषा मॉडल को प्रशिक्षित करते समय, विभेदक गोपनीयता (डीपी) हमें उस डिग्री को मापने की अनुमति देती है जिस पर हमारे निजी डेटा की रक्षा की जाती है। हालांकि, प्रशिक्षण एल्गोरिदम जो विभेदक गोपनीयता को लागू करते हैं, अक्सर मॉडल की गुणवत्ता में गिरावट का कारण बनते हैं। हम एक भाषा मॉडल सीखने की व्यवहार्यता का अध्ययन करते हैं जो एक साथ एक निजी कॉर्पस पर एक सार्वजनिक आधार मॉडल को ट्यून करके उच्च गुणवत्ता और गोपनीयता संरक्षण है। हम पाते हैं कि डीपी ठीक ट्यूनिंग निजी डोमेन में भाषा मॉडल के प्रदर्शन को बढ़ाती है, जिससे ऐसे मॉडलों का प्रशिक्षण संभव हो जाता है।</abstract_hi>
      <abstract_ja>言語モデリングは、自然言語処理における重要なタスクです。機密情報に関する言語モデルをトレーニングする場合、差分プライバシー（ DP ）により、プライベートデータがどの程度保護されているかを定量化できます。しかし、差分プライバシーを強制するトレーニングアルゴリズムは、多くの場合、モデルの品質の低下につながります。私たちは、プライベートコーパス上のパブリックベースモデルをチューニングすることによって、同時に高品質でプライバシーを保つ言語モデルを学習することの実現可能性を研究しています。DPの微調整は、プライベートドメインにおける言語モデルのパフォーマンスを向上させ、そのようなモデルのトレーニングを可能にすることがわかります。</abstract_ja>
      <abstract_ru>Языковое моделирование является ключевой задачей в обработке естественного языка. При обучении языковой модели конфиденциальной информации дифференциальная конфиденциальность (DP) позволяет нам количественно оценить степень защиты наших личных данных. Тем не менее, обучающие алгоритмы, обеспечивающие дифференциальную конфиденциальность, часто приводят к ухудшению качества модели. Мы изучаем возможность изучения языковой модели, которая одновременно является высококачественной и сохраняет конфиденциальность, настраивая публичную базовую модель на частном корпусе. Мы обнаружили, что точная настройка DP повышает производительность языковых моделей в частной сфере, делая возможным обучение таких моделей.</abstract_ru>
      <abstract_ga>Príomhthasc i bpróiseáil nádúrtha teanga is ea samhaltú teanga. Nuair a chuirtear oiliúint ar mhúnla teanga ar fhaisnéis íogair, ligeann príobháideacht dhifreálach (DP) dúinn a mhéid a chosnaítear ár sonraí príobháideacha a chainníochtú. Mar sin féin, is minic go dtiocfaidh díghrádú ar cháilíocht na samhla as halgartaim oiliúna a fhorfheidhmíonn príobháideacht dhifreálach. Déanaimid staidéar ar an bhféidearthacht atá ann múnla teanga a fhoghlaim atá ar ardchaighdeán agus ag caomhnú príobháideachta ag an am céanna trí mhúnla bunáit phoiblí a oiriúnú ar chorpas príobháideach. Feictear dúinn go gcuireann mionchoigeartú DP le feidhmíocht na múnlaí teanga sa réimse príobháideach, rud a fhágann gur féidir na samhlacha sin a oiliúint.</abstract_ga>
      <abstract_el>Η γλωσσική μοντελοποίηση είναι μια βασική εργασία στην επεξεργασία φυσικής γλώσσας. Όταν εκπαιδεύουμε ένα γλωσσικό μοντέλο για ευαίσθητες πληροφορίες, η διαφορική ιδιωτικότητα (DP) μας επιτρέπει να ποσοτικοποιήσουμε τον βαθμό στον οποίο προστατεύονται τα προσωπικά μας δεδομένα. Ωστόσο, οι αλγόριθμοι κατάρτισης που επιβάλλουν τη διαφορετική ιδιωτικότητα συχνά οδηγούν σε υποβάθμιση της ποιότητας των μοντέλων. Μελετάμε τη σκοπιμότητα της εκμάθησης ενός γλωσσικού μοντέλου που είναι ταυτόχρονα υψηλής ποιότητας και διαφυλάσσεται της ιδιωτικής ζωής, συντονίζοντας ένα μοντέλο δημόσιας βάσης σε ένα ιδιωτικό σώμα. Διαπιστώνουμε ότι ο συντονισμός DP ενισχύει την απόδοση των γλωσσικών μοντέλων στον ιδιωτικό τομέα, καθιστώντας δυνατή την εκπαίδευση τέτοιων μοντέλων.</abstract_el>
      <abstract_ka>ენის მოდელირება არის სახელსაწყოთა ენის პროცესის კლავისტური დავალება. როცა ენის მოდელის შემწავლობა სიგრძნობითი ინფორმაციის შესახებ, განსხვავებული პრივიაცია (DP) მოგვიძლია ჩვენ კონტაქტირება სიგრძნობა, რომელიც ჩვენი პრივი მაგრამ განსწავლება ალგორიტემი, რომელიც განსხვავებული პრივისატების გამოყენებას ზოგიერთად მოდეგრადიაციას მოდეგრადის კაalitეში. ჩვენ ვისწავლით ენის მოდელის შესაძლებლობა, რომელიც ერთადერთად უფრო დიდი კაalitეტი და პრივიაციის შესაძლებლობა, რომელიც საშუალო ბაზის მოდელის შესაძლებლობად პრივიაციული კორ ჩვენ ვიფიქრობთ, რომ DP-ს სწორად კონფიგურაცია იქნება ენის მოდელების გამოსახულებას პირადი დემონიში, რომლებიც ასეთი მოდელების შესაძლებლობა შექმნა.</abstract_ka>
      <abstract_hu>A nyelvmodellezés kulcsfontosságú feladat a természetes nyelv feldolgozásában. Az érzékeny információkra vonatkozó nyelvi modellek képzésekor a differenciális adatvédelem (DP) lehetővé teszi számunkra, hogy számszerűsítsük a személyes adataink védelmének mértékét. Ugyanakkor a differenciális adatvédelmet érvényesítő képzési algoritmusok gyakran a modellminőség romlásához vezetnek. Tanulmányozzuk egy olyan nyelvi modell elsajátításának megvalósíthatóságát, amely egyidejűleg magas színvonalú és a magánélet megőrzését biztosítja egy nyilvános alapmodell magánkorpuszra történő hangolásával. Úgy találjuk, hogy a DP finomhangolás növeli a nyelvi modellek teljesítményét a magánterületen, lehetővé téve az ilyen modellek képzését.</abstract_hu>
      <abstract_it>La modellazione linguistica è un compito fondamentale nell'elaborazione del linguaggio naturale. Quando si addestra un modello linguistico sulle informazioni sensibili, la privacy differenziale (DP) ci consente di quantificare il grado di protezione dei nostri dati privati. Tuttavia, gli algoritmi di formazione che impongono la privacy differenziale spesso portano a un degrado della qualità del modello. Studiamo la fattibilità dell'apprendimento di un modello linguistico che sia allo stesso tempo di alta qualità e tutela della privacy sintonizzando un modello di base pubblica su un corpus privato. Troviamo che la messa a punto DP migliora le prestazioni dei modelli linguistici nel settore privato, rendendo possibile la formazione di tali modelli.</abstract_it>
      <abstract_lt>Kalbų modeliavimas yra pagrindinė gamtos kalbų apdorojimo užduotis. Mokant kalbos model į jautrios informacijos klausimais, diferencinis privatumas (DP) leidžia mums kiekybiškai įvertinti, kokiu mastu mūsų privatūs duomenys yra apsaugoti. Tačiau mokymo algoritmai, kuriais užtikrinamas diferencinis privatumas, dažnai lemia modelio kokybės blogėjimą. Mes tiriame galimybę mokytis kalbos modelio, kuris kartu yra aukštos kokybės ir privatumo išsaugojimas, pritaikydami viešojo pagrindo model į prie privataus korpuso. Mes manome, kad DP patobulinimas didina kalbų modelių privačioje srityje veiksmingumą, todėl tokių modelių mokymas yra įmanomas.</abstract_lt>
      <abstract_mk>Моделирањето јазик е клучна задача во природното обработување јазик. Кога тренираме јазички модел за чувствителни информации, диференцијалната приватност (ДП) ни овозможува да го квантификуваме степенот на заштита на нашите приватни податоци. Сепак, обуката на алгоритмите кои спроведуваат различен приватност честопати води до деградација во квалитетот на моделот. Ние ја проучуваме физибилитетот на учењето јазички модел кој е истовремено висок квалитет и зачувување на приватноста со прилагодување на јавниот модел на база на приватен корпус. Најдовме дека финетизирањето на ДП ја зголемува изведбата на јазичките модели во приватниот домен, што овозможува обука на вакви модели.</abstract_mk>
      <abstract_kk>Тіл моделі - табиғи тілді өңдеу үшін перне тапсырмасы. Тілді мәлімет үлгісін оқыту кезінде, әртүрлі жеке мәліметтеріміздің қай деңгейіне қорғалған градусын анықтауға мүмкіндік береді. Бірақ айырмашылық жұмыс істеу алгоритмдері үлгі сапасында деградациялауға көбірек болады. Біз тіл үлгісін оқыту мүмкіндігін зерттейміз. Бірақ жеке корпус үшін көпшілік негізінің үлгісін баптау арқылы көпшілік үлгісін және жеке сақтау үлгісін са Біз ДП жақсы баптаулары жеке доменде тіл үлгілерінің әдістерін көтереді. Бұл үлгілерді оқытуға мүмкін болады.</abstract_kk>
      <abstract_ms>Pemodelan bahasa adalah tugas batu kunci dalam pemprosesan bahasa alami. Apabila melatih model bahasa pada maklumat sensitif, privasi berbeza (DP) membolehkan kita kuantifikasikan darjah yang mana data peribadi kita dilindungi. Namun, algoritma latihan yang memaksa privasi perbezaan sering menyebabkan kerosakan dalam kualiti model. Kami mempelajari kemudahan belajar model bahasa yang bersamaan kualiti tinggi dan memelihara privasi dengan tuning model pangkalan awam pada korpus peribadi. Kami mendapati bahawa penyesuaian DP meningkatkan prestasi model bahasa dalam domain peribadi, membuat latihan model tersebut mungkin.</abstract_ms>
      <abstract_ml>ഭാഷ മോഡലിങ്ങ് സ്വാഭാവിക ഭാഷയുടെ പ്രവര്‍ത്തനത്തില്‍ ഒരു കീസ്റ്റണ്‍ ജോലിയാണ്. സെന്‍സിറ്റീവ് വിവരങ്ങളെക്കുറിച്ച് ഒരു ഭാഷ മോഡല്‍ പരിശീലിക്കുമ്പോള്‍, വ്യത്യസ്ത സ്വകാര്യം (ഡിപിപി) നമ്മുടെ സ്വകാര്യ എന്നാലും, വ്യത്യസ്ത്രീയ സ്വകാര്യം പ്രവര്‍ത്തിപ്പിക്കുന്ന ആല്‍ഗോരിത്മുകള്‍ പലപ്പോഴും മോഡലിന്റെ ഗുണവി ഒരു ഭാഷ മോഡല്‍ പഠിപ്പിക്കുന്നതിന്റെ സ്വകാര്യം നമ്മള്‍ പഠിക്കുന്നു. അത് ഒരേ സമയത്ത് ഒരു പൊതുവിലെ ബേസ് മോഡലിനെ സംരക്ഷിക്കുന സ്വകാര്യ ഡോമെയിനിലെ ഭാഷ മോഡലുകളുടെ പ്രദര്‍ശനത്തിന്റെ പ്രദര്‍ശനത്തിന് നമുക്ക് കണ്ടെത്താനാണ് ഡിപിപി നല്ല ടൂണ</abstract_ml>
      <abstract_mt>L-immudellar tal-lingwi huwa kompitu ewlieni fl-ipproċessar tal-lingwi naturali. Meta jitħarreġ mudell lingwistiku dwar informazzjoni sensittiva, il-privatezza differenzjali (DP) tippermettilna nikkwantifikaw il-grad sa fejn id-dejta privata tagħna hija protetta. Madankollu, algoritmi ta’ taħriġ li jinfurzaw il-privatezza differenzjali spiss iwasslu għal degradazzjoni fil-kwalità tal-mudell. Aħna nistudjaw il-fattibbiltà tat-tagħlim ta’ mudell lingwistiku li fl-istess ħin huwa ta’ kwalità għolja u l-preservazzjoni tal-privatezza billi naġġustaw mudell ta’ bażi pubblika fuq korpus privat. Aħna nsibu li l-aġġustament tad-DP isaħħaħ il-prestazzjoni tal-mudelli lingwistiċi fid-dominju privat, u dan jagħmel it-taħriġ ta’ mudelli bħal dawn possibbli.</abstract_mt>
      <abstract_mn>Холын модель бол байгалийн хэл үйлдвэрлэлийн түлхүүр чулуун ажил. Хэдий хэл загварыг мэдрэмжтэй мэдээллийн тухай суралцах үед, ялгаатай хувийн байдал (ДП) бидэнд хувийн өгөгдлийн хамгаалах хэмжээг тодорхойлж чадна. Гэхдээ өөр өөр өөрийн гэр бүлийн амьдралд хүргэх сургалтын алгоритм нь загварын сайн чанарын бууруулалттай болдог. Бид хэл загварыг сурах боломжтой байдлыг судалж, хувийн корпус дээр олон нийтийн суурь загварын загварын тулд хадгалах өндөр чанартай, хувийн амьдралыг хадгалах боломжтой. Бид ДП-ын хувийн хэл загварын үйл ажиллагааг нэмэгдүүлж, ийм загварын сургалтыг боломжтой болгодог.</abstract_mn>
      <abstract_pl>Modelowanie języka jest kluczowym zadaniem w przetwarzaniu języka naturalnego. Podczas szkolenia modelu językowego dotyczącego informacji wrażliwych, różnicowa prywatność (DP) pozwala nam określić stopień ochrony naszych danych prywatnych. Jednak algorytmy szkoleniowe, które wymuszają różnicę prywatności, często prowadzą do degradacji jakości modelu. Badamy możliwość nauki modelu językowego, który jest jednocześnie wysokiej jakości i zachowania prywatności poprzez dostrojenie publicznego modelu bazy na korpusie prywatnym. Uważamy, że dopracowanie DP zwiększa wydajność modeli językowych w domenie prywatnej, umożliwiając szkolenie takich modeli.</abstract_pl>
      <abstract_no>Språk- modellering er ein nøkkelstone- oppgåve i naturspråk- handsaming. Når opplæring av eit språk-modell på sensitivt informasjon, kan forskjellige privat (DP) bruka oss å kvantifisera kor grad privat data våre skal beskyttast. Men øvingsalgoritme som gjer forskjellige privat fører ofte til degradasjon i modellkvalitet. Vi studerer feilighet for å lære eit språk-modell som er samtidig høg kvalitet og privat som lagrar ved å tunera ein offentleg basemodell på ein privat korpus. Vi finn at DP finnstilling styrer utviklinga av språk-modeller i den private domenet, gjer opplæring av slike modeller mogleg.</abstract_no>
      <abstract_ro>Modelarea limbajului este o sarcină cheie în procesarea limbajului natural. Atunci când instruim un model lingvistic privind informațiile sensibile, confidențialitatea diferențială (DP) ne permite să cuantificăm gradul în care datele noastre private sunt protejate. Cu toate acestea, algoritmii de formare care impun confidențialitatea diferențială duc adesea la degradarea calității modelului. Studiem fezabilitatea învățării unui model lingvistic care să fie simultan de înaltă calitate și păstrarea confidențialității prin ajustarea unui model de bază publică pe un corpus privat. Considerăm că ajustarea DP sporește performanța modelelor lingvistice în domeniul privat, făcând posibilă instruirea unor astfel de modele.</abstract_ro>
      <abstract_sr>Modeliranje jezika je ključni zadatak u procesu prirodnog jezika. Kada obučavamo jezički model o osjetljivim informacijama, diferencijalna privatnost (DP) nam omogućava da kvantificiramo stupnju zaštite naših privatnih podataka. Međutim, algoritmi obuke koji primjenjuju diferencijalnu privatnost često vode do degradacije u kvaliteti modela. Proučavamo mogućnost učenja jezičkog model a koja je istovremeno visoka kvaliteta i privatnost koja čuva, uspoređujući javni model baze na privatnom korpusu. Našli smo da je DP-ova fino-tuning povećala izvodnju jezičkih modela u privatnom domenu, čineći obuku takvih modela mogućim.</abstract_sr>
      <abstract_si>භාෂාව මොඩිල් කරන්නේ ස්වාභාවික භාෂාව ප්‍රක්‍රියාසයේ යතුරු ස්ටෝන් වැඩක්. භාෂාව ප්‍රශ්නයක් සංවේදනය තොරතුරු ගැන, වෙනස් පුද්ගලිකතාවය (DP) අපිට පුද්ගලික දත්ත ආරක්ෂා කරන්න පුළුව නමුත්, ප්‍රධානය ඇල්ගෝරිත්ම්ස් වලින් වෙනස් පුද්ගලිකතාවට ප්‍රශ්නයක් ප්‍රශ්නයක් වෙනුවෙන්  අපි භාෂා මොඩල් ඉගෙන ගන්න පුළුවන් විදියට අධ්‍යානය කරනවා ඒ වගේම පුළුවන් විශේෂතාවක් සහ පුළුවන් විශේෂතාව අපිට හොයාගන්න පුළුවන් කියලා DP හොඳ සංවේදනය විශේෂයෙන් භාෂා මොඩේල්ස් එක්ක පුළුවන් වෙන්න පුළු</abstract_si>
      <abstract_so>Tusaale ahaan luuqadu waa shaqada dhagaxa ah oo ku qoran baaraandegista afka dabiicadda ah. Markii aad sameyneyso tusaale ahaan luqada oo ku saabsan macluumaadka jilicsan, gaarka loo leeyahay (DP) ayaa noogu ogolaa inaynu qiyaasto shahaadada ay macluumaadkayaga gaarka loo leeyahay. Si kastaba ha ahaatee tababaridda algorityada ku takhasusa gaarka kala duwan waxay inta badan ku hoggaamiyaan tusaale ahaan hoosaysiinta. Waxaynu baranaynaa awoodda barashada tusaale ahaan luqada, kaas oo isla markaasna la ilaaliyaa qiimo sare iyo gaar ahaanshaha, marka lagu sameynayo muusikada aasaaska dadweynaha oo gaarka ah. Waxaynu heli nahay in DP-ku kordhiyo sameynta noocyada luuqada ee gaarka loo leeyahay, in lagu tababariyo tusaalooyinkaas oo suurtagal ah.</abstract_so>
      <abstract_sv>Språkmodellering är en nyckeluppgift i naturlig språkbearbetning. När vi tränar en språkmodell på känslig information kan vi kvantifiera i vilken grad våra privata data skyddas. Utbildningsalgoritmer som upprätthåller differentierad integritet leder dock ofta till försämring av modellkvaliteten. Vi studerar möjligheten att lära sig en språkmodell som samtidigt håller hög kvalitet och bevarar integriteten genom att anpassa en offentlig basmodell på en privat korpus. Vi finner att DP finjustering ökar prestandan hos språkmodeller inom den privata domänen, vilket gör utbildning av sådana modeller möjlig.</abstract_sv>
      <abstract_ta>மொழி மாதிரி வடிவமைப்பு இயல்பான மொழி செயல்பாடு உணர்வுடைய தகவலின் மொழி மாதிரி பயிற்சி செய்யும் போது, வேறுபட்ட தனிப்பட்ட தனிப்பட்ட (DP) எங்கள் தனிப்பட்ட தரவுகள் எதை பாதுகாக்கப ஆயினும், வேறுபட்ட தனியார்ச்சியை செயல்படுத்தும் பயிற்சி பட்டியல்கள் பெரும்பாலும் மாதிரி தரமாக குறைக நாங்கள் ஒரு மொழி மாதிரி கற்றுக் கொள்ளும் சூழ்நிலையில் கற்றுக்கொள்ளும் சூழ்நிலை மற்றும் தனிப்பட்ட தனிப்பட்ட மாதிரியை ஒரு தன நாங்கள் கண்டுபிடிப்போம் என்று டிபிடி நன்றாக முன்னேறுதல் தனிப்பட்ட களத்தில் மொழி மாதிரிகளின் செயல்பாட்டை அதிகர</abstract_ta>
      <abstract_ur>زبان موڈلینگ طبیعی زبان پرسس میں ایک کلی سنگ کام ہے. جب ایک زبان موڈل کی تعلیم کرتی ہے جو حساس معلومات کے بارے میں ہے، مختلف خصوصیت (DP) ہمیں اجازت دیتا ہے کہ درجہ کی مقدار کریں جس پر ہماری خصوصی ڈائٹی محافظت کی جاتی ہے. لیکن تعلیم الگوریتم جن کی مختلف خصوصیت کو مضبوط کر رہی ہے اکثر موڈل کی کیفیت میں دھوکا ہوا ہے۔ ہم ایک زبان موڈل کی تعلیم کے امکانات کو پڑھتے ہیں جو ایک دفعہ میں بہت بڑی کیفیت اور خصوصی کی حفاظت کرتی ہے ایک خصوصی کورپوس پر ایک عمومی بنی موڈل کو تنظیم کرتی ہے۔ ہم دیکھتے ہیں کہ ڈی.پی.ٹ.پی.ٹ.پی.ٹ.ٹ. کی زبان مدل کی عملکرد خصوصی دامین میں بڑھتی ہے، اس طرح طرح کی مدل کی آموزش ممکن بناتی ہے.</abstract_ur>
      <abstract_uz>Language modeling is a keystone task in natural language processing.  Til modelini sensitiv maʼlumot haqida o'rganishda, ajoyib shaxsiylik (DP) bizga shaxsiy maʼlumotni saqlashga ruxsat beradi. Lekin, to'g'ri shaxsiy shaxsiyatlarni ishlatish algoritlarini ko'p doim model sifatida o'zgartiradi. Biz tillar modelini o'rganish imkoniyatini o'rganamiz. Bu samtida o'sha shaxsiy darajada o'rganish va shaxsiylikni saqlash imkoniyatini o'rganamiz. Biz o'rganamiz, DDP yaxshi tuzilishi mumkin, shaxsiy domenadagi tilning modellarini bajarishini bajaradi, bu modellarni o'rganish imkoniyatlarini bajaradi.</abstract_uz>
      <abstract_vi>Lựa chọn ngôn ngữ là việc then chốt trong việc xử lý ngôn ngữ tự nhiên. Khi huấn luyện mô hình ngôn ngữ về thông tin nhạy cảm, DP cho phép chúng tôi xác định mức độ bảo vệ dữ liệu cá nhân. Tuy nhiên, thuật to án huấn luyện tác động đến tính riêng tư khác thường dẫn đến việc làm xấu chất lượng mô hình. Chúng tôi nghiên cứu khả năng học một mô hình ngôn ngữ có cùng chất lượng cao và bảo vệ sự riêng tư bằng cách thiết lập một cơ sở cá nhân. Chúng tôi thấy nền Tuyệt hảo của DP thúc đẩy khả năng của các mô hình ngôn ngữ trong lĩnh vực riêng tư, làm cho việc huấn luyện các mô hình như vậy có thể.</abstract_vi>
      <abstract_bg>Езиковото моделиране е ключова задача в обработката на естествения език. Когато обучаваме езиков модел за чувствителна информация, диференциалната поверителност (ДП) ни позволява да определим количествено степента, до която нашите лични данни са защитени. Обаче алгоритмите за обучение, които налагат диференциалната поверителност, често водят до влошаване на качеството на модела. Изследваме осъществимостта на изучаване на езиков модел, който едновременно е висококачествен и запазва неприкосновеността на личния живот чрез настройване на модел на публична база върху частен корпус. Установяваме, че фината настройка на ДП подобрява ефективността на езиковите модели в частната сфера, което прави обучението на такива модели възможно.</abstract_bg>
      <abstract_da>Sprogmodellering er en nøgleopgave i naturlig sprogbehandling. Når vi træner en sprogmodel om følsomme oplysninger, giver differentieret privatliv (DP) os mulighed for at kvantificere, i hvilket omfang vores private data er beskyttet. Men træningsalgoritmer, der håndhæver differentieret privatliv, fører ofte til forringelse af modelkvaliteten. Vi undersøger muligheden for at lære en sprogmodel, der samtidig er af høj kvalitet og beskyttelse af privatlivets fred ved at justere en offentlig grundmodel på et privat korpus. Vi finder ud af, at DP finjustering øger ydeevnen af sprogmodeller i det private domæne, hvilket gør uddannelse af sådanne modeller mulig.</abstract_da>
      <abstract_hr>Modeliranje jezika je ključni zadatak u procesu prirodnog jezika. Kada obučavamo jezički model o osjetljivim informacijama, diferencijalna privatnost (DP) nam omogućava kvantificirati stupnju zaštite naših privatnih podataka. Međutim, algoritmi obuke koji primjenjuju diferencijalnu privatnost često vode do degradacije u kvaliteti modela. Proučavamo mogućnost učenja jezičkog model a koja je istovremeno visoka kvaliteta i privatnost očuvajući, uspostavljajući javni model baze na privatnom korpusu. Pronašli smo da se DP-ova finalna prilagodba povećava učinkovitost jezičkih modela u privatnom domenu, čineći mogućnost obuke takvih modela.</abstract_hr>
      <abstract_nl>Taalmodellering is een sleuteltaak in de verwerking van natuurlijke taal. Bij het trainen van een taalmodel over gevoelige informatie stelt differential privacy (DP) ons in staat om te kwantificeren in hoeverre onze persoonlijke gegevens worden beschermd. Trainingsalgoritmes die differentiële privacy afdwingen leiden echter vaak tot aantasting van de modelkwaliteit. We bestuderen de haalbaarheid van het leren van een taalmodel dat tegelijkertijd hoogwaardig is en privacy behoudt door een openbaar basismodel af te stemmen op een privé corpus. We vinden dat DP fine-tuning de prestaties van taalmodellen in het privédomein verhoogt, waardoor het trainen van dergelijke modellen mogelijk wordt.</abstract_nl>
      <abstract_id>Modeling bahasa adalah tugas batu kunci dalam proses bahasa alami. When training a language model on sensitive information, differential privacy (DP) allows us to quantify the degree to which our private data is protected.  Namun, algoritma latihan yang memaksa privasi diferensial sering menyebabkan degradasi dalam kualitas model. Kami mempelajari feasibilitas belajar model bahasa yang secara bersamaan kualitas tinggi dan memelihara privasi dengan mengatur model dasar publik pada korpus pribadi. Kami menemukan bahwa penyesuaian DP meningkatkan prestasi model bahasa di domain pribadi, membuat pelatihan model tersebut mungkin.</abstract_id>
      <abstract_fa>مدل زبان یک کار سنگ کلید در پردازش زبان طبیعی است. وقتی یک مدل زبانی در مورد اطلاعات حساسی آموزش می‌کند، خصوصی مختلف (DP) اجازه می‌دهد که درجه‌ای که داده‌های خصوصی ما در آن محافظت می‌شود مقدار تعداد کنیم. ولی الگوریتم‌های آموزش که محرمانیت متفاوتی را اجرا می‌کنند، اغلب به نابودی در کیفیت مدل می‌رسد. ما قابلیت یادگیری مدل زبانی را مطالعه می کنیم که همزمان کیفیت بالا و خصوصی محافظت می کند، با تنظیم یک مدل پایگاه عمومی روی یک جسد خصوصی. ما پیدا می‌کنیم که دانشگاه نیک تنظیم نمونه‌های زبان را در دامنه خصوصی بیشتر می‌دهد، و آموزش این مدل‌ها را امکان می‌دهد.</abstract_fa>
      <abstract_de>Sprachmodellierung ist eine Schlüsselaufgabe in der Verarbeitung natürlicher Sprache. Beim Training eines Sprachmodells zu sensiblen Informationen ermöglicht Differential Privacy (DP) es uns, den Grad zu quantifizieren, in dem unsere privaten Daten geschützt sind. Trainingsalgorithmen, die differentielle Privatsphäre erzwingen, führen jedoch häufig zu einer Verschlechterung der Modellqualität. Wir untersuchen die Machbarkeit, ein Sprachmodell zu lernen, das gleichzeitig qualitativ hochwertig und privat ist, indem wir ein öffentliches Basismodell auf einem privaten Korpus abstimmen. Wir stellen fest, dass DP-Feinabstimmung die Leistung von Sprachmodellen im privaten Bereich steigert und das Training solcher Modelle ermöglicht.</abstract_de>
      <abstract_ko>언어 모델링은 자연 언어 처리의 중요한 임무이다.민감한 정보의 언어 모델을 교육할 때, 차별화된 프라이버시 (DP) 는 우리의 개인 데이터가 보호되는 정도를 계량화할 수 있도록 한다.그러나 프라이버시를 차별화하는 훈련 알고리즘을 실시하면 모델의 질이 떨어지는 경우가 많다.우리는 사유 자료 라이브러리에서 공공 기초 모델을 조정함으로써 고품질과 프라이버시 보호를 동시에 가진 언어 모델의 타당성을 연구했다.우리는 DP 마이크로스피커가 개인 영역에서 언어 모델의 성능을 향상시켜 이런 모델의 훈련을 가능하게 하는 것을 발견했다.</abstract_ko>
      <abstract_sw>Utengenezaji wa lugha ni kazi ya msingi katika upasuaji wa lugha asili. Wakati tukifundisha muundo wa lugha kuhusu taarifa za kiuchumi, faragha tofauti (DP) hutupatia kuhakikisha kiwango ambacho taarifa zetu binafsi zinalindwa. Hata hivyo, takwimu za mafunzo zinazolazimisha faragha tofauti mara nyingi hupelekea kupungua kwa kiwango cha mifano. Tunafundisha uwezekano wa kujifunza muundo wa lugha ambao kwa wakati ule unaohifadhi ubora wa juu na faragha kwa kutumia muundo wa msingi wa umma kwenye makampuni binafsi. Tunapata kwamba mafunzo ya vizuri ya DP yanaongezea utendaji wa mifano ya lugha katika eneo binafsi, na kufanya mafunzo ya mifano kama hiyo inawezekana.</abstract_sw>
      <abstract_af>Taal modellering is 'n sleutelbestel taak in natuurlike taal verwerking. Wanneer 'n taal model op sensitiewe inligting onderwerp, laat ons verskillende privateit (DP) toe om die grad waarin ons privaat data beskerm word om te kvantifiseer. Maar onderwerp algoritme wat verskillende privaatheid vervolg het, dikwels lei na degradasie in model kwaliteit. Ons studeer die feilikheid van die leer van 'n taal model wat simultaanlik hoë-kwaliteit en privateit bewaar word deur 'n publieke basis model op 'n privaat korpus te stel. Ons vind dat DP fyn-tuning die prestasie van taal modele in die privaat domein verhoog, maak die opvoering van sodanige modele moontlik.</abstract_af>
      <abstract_sq>Modelimi i gjuhës është një detyrë kryesore në procesimin natyror të gjuhës. Kur trajnojmë një model gjuhësh për informacion të ndjeshëm, privatësia diferenciale (DP) na lejon të kuantifikojmë shkallën në të cilën të dhënat tona private janë të mbrojtura. Megjithatë, stërvitja e algoritmeve që zbatojnë privatësinë diferenciale shpesh çon në degradim në kualitetin e modelit. Ne studiojmë realizueshmërinë e mësimit të një modeli gjuhësh që është njëkohësisht e cilësisë së lartë dhe ruajtjes së privatësisë duke rregulluar një model bazë publike në një korpus privat. Ne gjejmë se përmirësimi i DP rrit performancën e modeleve gjuhësore në fushën private, duke bërë të mundur trajnimin e modeleve të tilla.</abstract_sq>
      <abstract_am>ቋንቋ ምረጡ የፊደል ቋንቋ ማቀናጃ ነው፡፡ የቋንቋ ምሳሌ በተለየ መረጃ ላይ ባስተማርን ጊዜ የልዩ የግል ግለፅ (DP) የግል መረጃችን የሚጠበቀበትን ክፍተት ማረጋገጥን ይፈቅዳል፡፡ ነገር ግን የግዛት ብሔራዊነት የሚያስፈልገውን አሌጎርቲም ብዙ ጊዜ በሞዴል ጥሩ ላይ የሚያሳፍር ነው፡፡ የቋንቋን ምሳሌ ለመማር ስልጣን እናስተምራለን፡፡ የDP ደብዳቤ የቋንቋ ምሳሌዎችን የግል ድምፅ ማድረግ እናገኘዋለን፤ እንደዚህ ዓይነቶች ማስተምር የሚችል ነው፡፡</abstract_am>
      <abstract_tr>Dil modellerlemesi tebigy diller işlemekde bir taýdan täze täze. Dil nusgasyny hasaplanjak maglumaty barada okuw görkezilýän zaman, üýtgeşik hususiyetimiz (DP) bize häzirki maglumatymyzyň gaýd edilen derejesini bejermek üçin mümkin edýär. Ýöne, üýtgeşik wajyplygyny üýtgeden algoritmalar nusgasynda köplenç nusgasyna degradýar. Biz dil nusgasyny öwrenmek mümkinçiligini öwrenip otyrýarys. Şu wagt hem ýük-kaliwatly we ýüzünlik nusgasyny hususit korpusa düzenleyerek jemi baz nusgasyny çykarýarys. Biz DP ajaýyp şeklinde düzenlemek isleýän nusgalaryň üýtgetmegini özbaşdaky domandan üýtgedýäris we şol nusgalary mümkin edip biler.</abstract_tr>
      <abstract_hy>Լեզու մոդելը գլխավոր խնդիր է բնական լեզուների վերամշակում: Երբ լեզվի մոդելը սովորեցնում է զգայուն ինֆորմացիայի վերաբերյալ, տարբերակային գաղտնիությունը (ԴՊ) թույլ է տալիս մեզ չափել այն քանակը, որի չափով են պաշտպանվում մեր անձնական տվյալ Այնուամենայնիվ, ալգորիթմները, որոնք պաշտպանում են տարբերակային գաղտնիքը, հաճախ հանգեցնում են մոդելի որակի դեգրադացիայի: Մենք ուսումնասիրում ենք լեզվի մոդելի սովորելու հնարավորությունը, որը միևնույն ժամանակ բարձր որակի և գաղտնիքի պահպանության միջոցով կազմակերպում է հասարակական հիմքի մոդելը սեփական կորպոսի վրա: Մենք հայտնաբերեցինք, որ ԴՊ-ի բարելավումը բարձրացնում է լեզվի մոդելների արտադրողությունը մասնավոր ոլորտում, դարձնելով հնարավոր այդ մոդելների ուսումնասիրությունը:</abstract_hy>
      <abstract_az>Dil modelləri təbii dil işləməsində anahtar taş işləridir. Sensitif məlumatlar haqqında dil modelini təhsil etdikdə, fərqli xüsusiyyət (DP) bizə xüsusi məlumatlarımızın qorunub saxlanıldığı dərəcəsini qədər təhsil edir. Ancaq, fərqli təhsil təhsil etmək üçün müxtəlif təhsil algorizmi modellərin keyfiyyətində degradasyona yol açar. Biz bir dil modelini öyrənmək mümkünlüyünü təhsil edirik ki, eyni zamanda çox yüksək kaliteli və gizli təhlükəsizlik təhlükəsizlik edir, özgür korpus üzərində halkı baz modelini düzenləyirik. Bu modellərin təhsil edilməsini mümkün edərək DP-nin düzgün təhsil modellərinin performansını özlərinə kömək edir.</abstract_az>
      <abstract_bs>Modeliranje jezika je ključni zadatak u procesu prirodnog jezika. Kada obučavamo jezički model o osjetljivim informacijama, diferencijalna privatnost (DP) nam omogućava da kvantificiramo stupnju zaštite naših privatnih podataka. Međutim, algoritmi obuke koji primjenjuju diferencijalnu privatnost često vode do degradacije u kvaliteti modela. Proučavamo mogućnost učenja jezičkog model a koji je istovremeno visoka kvaliteta i privatnost očuvajući, uspostavljajući javni model baze na privatnom korpusu. Nalazimo da je DP-ova fino-tuning povećala učinkovitost jezičkih modela u privatnom domenu, čineći mogućnost obuke takvih modela.</abstract_bs>
      <abstract_bn>ভাষা মডেলিং হচ্ছে প্রাকৃতিক ভাষা প্রক্রিয়ায় একটি কী পাথর কাজ। যখন সংবেদনশীল তথ্য সম্পর্কে ভাষার মডেল প্রশিক্ষণ করা হয়, তখন বৈচিত্র্যকভাবে গোপনীয়তা (ডিপিপি) আমাদের সুযোগ দেয় যে ডিগ্রি যে ডি However, training algorithms which enforce differential privacy often lead to degradation in model quality.  আমরা একটি ভাষার মডেল শিখার ব্যাপারে গবেষণা করছি যা একই সাথে উচ্চমান এবং গোপনীয়তা রক্ষা করে একটি ব্যক্তিগত কোর্পাসে একটি পাবলিক ভেস মডেল প্রদান আমরা খুঁজে পাচ্ছি যে ডিপি ভাষার মডেল বাড়িয়ে দিচ্ছে, ব্যক্তিগত ডোমেইনে ভাষার মডেলের প্রতিষ্ঠান বাড়িয়ে দিয়েছে, য</abstract_bn>
      <abstract_ca>La modelació de llengües és una tasca clau en el processament natural de llengües. Quan entrenem un model de llenguatge en informació sensible, la privacitat diferencial (DP) ens permet quantificar el grau en què es protegeixen les nostres dades privades. Però els algoritmes de formació que enforten la privacitat diferencial sovint provoquen degradació en la qualitat del model. We study the feasibility of learning a language model which is simultaneously high-quality and privacy preserving by tuning a public base model on a private corpus.  Trobem que la perfeccionació del DP augmenta el rendiment dels models de llenguatge en el domini privat, fent possible l'entrenament d'aquests models.</abstract_ca>
      <abstract_cs>Jazykové modelování je klíčovým úkolem ve zpracování přirozeného jazyka. Při školení jazykového modelu citlivých informací nám diferenciální ochrana osobních údajů (DP) umožňuje kvantifikovat stupeň ochrany našich soukromých údajů. Nicméně tréninkové algoritmy, které vynucují diferenciální soukromí, často vedou ke zhoršení kvality modelu. Studujeme proveditelnost učení se jazykového modelu, který je současně vysoce kvalitní a zachovává soukromí laděním veřejného základního modelu na soukromý korpus. Zjišťujeme, že DP jemné ladění zvyšuje výkon jazykových modelů v soukromé doméně, což umožňuje trénink těchto modelů.</abstract_cs>
      <abstract_et>Keele modelleerimine on loodusliku keele töötlemise keskne ülesanne. Tundliku teabe keelemudeli koolitamisel võimaldab diferentsiaalne privaatsus (DP) meil kvantifitseerida, mil määral meie isikuandmeid kaitstakse. Erinevat privaatsust rakendavad koolitusalgoritmid põhjustavad sageli mudeli kvaliteedi halvenemist. Uurime samaaegselt kvaliteetse ja privaatsuse säilitava keelemudeli õppimise teostatavust, häälestades avaliku baasi mudeli erakorpusele. Leiame, et DP peenhäälestus suurendab keelemudelite jõudlust eravaldkonnas, muutes selliste mudelite koolitamise võimalikuks.</abstract_et>
      <abstract_fi>Kielimuodostus on keskeinen tehtävä luonnollisen kielen käsittelyssä. Kun koulutamme kielimallia arkaluonteisista tiedoista, differential privacy (DP) antaa meille mahdollisuuden kvantifioida, missä määrin yksityisiä tietojamme suojataan. Erilaista yksityisyyttä vahvistavat koulutusalgoritmit johtavat kuitenkin usein mallin laadun heikkenemiseen. Tutkimme mahdollisuutta oppia samanaikaisesti laadukasta ja yksityisyyttä säilyttävää kielimallia virittämällä julkisen perusmallin yksityiseen korpuseen. Havaitsemme, että DP hienosäätö parantaa kielimallien suorituskykyä yksityisellä alalla, mikä mahdollistaa tällaisten mallien koulutuksen.</abstract_fi>
      <abstract_jv>Tambah Ora kudu nggawe sistem sistem sing dibutuhke informasi susahe, nggambar perusahaan (PP) iso diangkat dhéwé kuwi tindang nggawe datain pribadi sing ngejaraké awak dhéwé. politenessoffpolite"), and when there is a change ("assertive Awak dhéwé ngerasah perbudhakan kanggo ngerasah model luwih dumadhi sak ngono nggawe barang-sistem sing ngewehi kuwi nggawe modèl kuwi nggawe barang pengguna nêmêr, kuwi nggawe gerakan akeh dumadhi sak kudu Awak dhéwé éntuk depan ngono nggawe model sing luwih nggawe barang pengguna kuwi, nik nggawe barang pengguna kuwi tindakan.</abstract_jv>
      <abstract_ha>Masana'antar harshe na zama wani aikin maɓalli cikin shirin aiki na fassarar harshe. Idan an kõre wani misali na harshe a kan information mai fasahawa, yana yarda mu ƙayyade tsarin daraja da za'a tsare data masu kanana da shi. A lokacin da, algoritori waɗanda ke lazimtar da farafinka masu ɓarna, ko da yawa, yana ƙara wa taƙaitarwa a cikin sifar misali. Tuna karanta abincin da za'a sanar da wani misalin harshe wanda ke sami sami da tsari mai nauyi da farat ɗaya da za'a tsare wani misalin jama'a a kan wani matabbaci na faransa. Tuna gane cewa DD na ƙara cikakken misãlai na harshe a cikin wuri farat ɗaya, kuma ya sami tsarin misãlai masu yiwuwa.</abstract_ha>
      <abstract_he>דוגמניות שפות היא משימה אבן מפתח בעבודת שפות טבעית. כשאימונים מודל שפה על מידע רגיש, פרטיות דיפרנציאלית (DP) מאפשרת לנו לקוונטיב את התמונה שבה הנתונים הפרטיים שלנו מוגנים. עם זאת, אלגוריתמים אימונים שמכריחים פרטיות דיפרנציאלית לעתים קרובות מובילים לשפלה באיכות מודל. We study the feasibility of learning a language model which is simultaneously high-quality and privacy preserving by tuning a public base model on a private corpus.  We find that DP fine-tuning boosts the performance of language models in the private domain, making the training of such models possible.</abstract_he>
      <abstract_sk>Jezikovno modeliranje je ključna naloga v obdelavi naravnega jezika. Pri usposabljanju jezikovnega modela o občutljivih informacijah nam diferencialna zasebnost (DP) omogoča količinsko opredelitev stopnje zaščite naših zasebnih podatkov. Vendar pa algoritmi usposabljanja, ki uveljavljajo različno zasebnost, pogosto vodijo v poslabšanje kakovosti modela. Preučujemo izvedljivost učenja jezikovnega modela, ki je hkrati visokokakovosten in ohranja zasebnost, z uglaševanjem javnega baznega modela na zasebnem korpusu. Ugotavljamo, da fino nastavitev DP povečuje učinkovitost jezikovnih modelov v zasebni domeni, kar omogoča usposabljanje takšnih modelov.</abstract_sk>
      <abstract_bo>སྐད་རིགས་མ་དབྱིབས་བཟོ་བྱས་ནི་རང་བཞིན་པའི་སྐད་རིགས་ཀྱི་ལས་འགུལ་ལྡན་དག་ཆེ་བ་ཞིག་རེད། སྐད་རིགས་ཀྱི་མ་དབྱིབས་དཔྱད་དབྱིབས་ཆེན་དང་སྤྱིར་བཏང་བའི་གསལ་བཤད་ཀྱི་ཆ་འཕྲིན་(DP)དེ་གིས་ང་ཚོའི་སྒེར་གྱི་ཆ་འཕྲིན ཡིན་ནའང་། སྒེར་དབང་གི་སྒེར་ཚུལ་སྔོན་སྒྲིག་གི་སྒྲིག་སྟངས་རྣམས་མེད་དུ་བསམ་མཐུན་རྐྱེན་སྐྱིད་དང་། ང་ཚོས་སྐད་ཡིག་གི་མ་དབྱིབས་དཔྱད་པར་ལྟ་བུ་མཐུན་ནུས་མེད་པར་མཐུན་རིམ་དང་རང་དབང་སྒེར་གྱི་རིགས ང་ཚོས་DP་ལྟ་བུའི་མཐུན་བཟོ་བྱས་ན་སྒེར་གྱི་dominio་ནང་གི་སྐད་ཡིག་ཆའི་མིག་དཔེ་དབུས་ཡོད་ཚད་ལྟར་ཡར་སྒྲིག</abstract_bo>
      </paper>
  </volume>
</collection>