<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.cl">
  <volume id="1">
    <meta>
      <booktitle>Computational Linguistics, Volume 47, Issue 1 - March 2021</booktitle>
      <month>March</month>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <year>2021</year>
    </meta>
    <paper id="2">
      <title>Formal Basis of a Language Universal</title>
      <author><first>Miloš</first><last>Stanojević</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <doi>10.1162/coli_a_00394</doi>
      <abstract>Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the separable permutations. This <a href="https://en.wikipedia.org/wiki/Class_(set_theory)">class of permutations</a> is exactly the <a href="https://en.wikipedia.org/wiki/Class_(set_theory)">class</a> that can be expressed in combinatory categorial grammars (CCGs). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in <a href="https://en.wikipedia.org/wiki/Word_order">word order</a> in nominal and verbal constructions. The number of <a href="https://en.wikipedia.org/wiki/Permutation">permutations</a> that are separable grows in the number n of lexical elements in the construction as the Large Schrder Number Sn1. Because that <a href="https://en.wikipedia.org/wiki/Number">number</a> grows much more slowly than the n ! number of all permutations, this <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> is also of considerable practical interest for computational applications such as <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. The present article examines the mathematical and computational origins of this <a href="https://en.wikipedia.org/wiki/Restriction_(mathematics)">restriction</a>, and the reason it is exactly captured in CCG without the imposition of any further constraints.</abstract>
      <pages>9–42</pages>
      <url hash="f68d3f5d">2021.cl-1.2</url>
      <bibkey>stanojevic-steedman-2021-formal</bibkey>
    </paper>
    <paper id="4">
      <title>Semantic Data Set Construction from Human Clustering and <a href="https://en.wikipedia.org/wiki/Spatial_analysis">Spatial Arrangement</a></title>
      <author><first>Olga</first><last>Majewska</last></author>
      <author><first>Diana</first><last>McCarthy</last></author>
      <author><first>Jasper J. F.</first><last>van den Bosch</last></author>
      <author><first>Nikolaus</first><last>Kriegeskorte</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <doi>10.1162/coli_a_00396</doi>
      <abstract>Abstract Research into representation learning models of <a href="https://en.wikipedia.org/wiki/Lexical_semantics">lexical semantics</a> usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments. Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguity</a>, or provide very specific sentential contexts that can not then be used to generate a larger lexical resource. Furthermore, <a href="https://en.wikipedia.org/wiki/Similarity_(psychology)">similarity</a> between more than two items is not considered. We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase. The <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> uses a spatial multi-arrangement approach proposed in the field of <a href="https://en.wikipedia.org/wiki/Cognitive_neuroscience">cognitive neuroscience</a> for capturing multi-way similarity judgments of visual stimuli. We have adapted this <a href="https://en.wikipedia.org/wiki/Methodology">method</a> to handle polysemous linguistic stimuli and much larger samples than previous work. We specifically target verbs, but the method can equally be applied to other parts of speech. We perform <a href="https://en.wikipedia.org/wiki/Cluster_analysis">cluster analysis</a> on the data from the first phase and demonstrate how this might be useful in the construction of a comprehensive verb resource. We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity. We demonstrate how the resultant data set can be used for fine-grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>. In particular, we find that stronger static word embedding methods still outperform lexical representations emerging from more recent pre-training methods, both on word-level similarity and <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clustering</a>. Moreover, thanks to the data set’s vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as Heat or Motion.</abstract>
      <pages>69–116</pages>
      <url hash="d83daca3">2021.cl-1.4</url>
      <bibkey>majewska-etal-2021-semantic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="6">
      <title>Supervised and Unsupervised Neural Approaches to Text Readability</title>
      <author><first>Matej</first><last>Martinc</last></author>
      <author><first>Senja</first><last>Pollak</last></author>
      <author><first>Marko</first><last>Robnik-Šikonja</last></author>
      <doi>10.1162/coli_a_00398</doi>
      <abstract>Abstract We present a set of novel neural supervised and unsupervised approaches for determining the readability of documents. In the <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised setting</a>, we leverage neural language models, whereas in the <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised setting</a>, three different neural classification architectures are tested. We show that the proposed neural unsupervised approach is robust, transferable across languages, and allows adaptation to a specific readability task and <a href="https://en.wikipedia.org/wiki/Data_set">data set</a>. By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to <a href="https://en.wikipedia.org/wiki/Readability">readability</a>, which in most cases still rely on extensive <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>, and propose possibilities for improvements.</abstract>
      <pages>141–179</pages>
      <url hash="266db4eb">2021.cl-1.6</url>
      <bibkey>martinc-etal-2021-supervised</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
    </paper>
    <paper id="7">
      <title>Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition<fixed-case>PCFG</fixed-case> Induction as a Model of Human Grammar Acquisition</title>
      <author><first>Lifeng</first><last>Jin</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <author><first>Finale</first><last>Doshi-Velez</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <doi>10.1162/coli_a_00399</doi>
      <abstract>Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech. The article then explores the idea that the difference between simple grammars exhibited by child learners and fully <a href="https://en.wikipedia.org/wiki/Recursive_grammar">recursive grammars</a> exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the <a href="https://en.wikipedia.org/wiki/Recursive_grammar">recursive grammars</a>. An implementation of these memory bounds as limits on <a href="https://en.wikipedia.org/wiki/Center_embedding">center embedding</a> in a depth-specific transform of a <a href="https://en.wikipedia.org/wiki/Recursive_grammar">recursive grammar</a> yields a significant improvement over an equivalent but unbounded baseline, suggesting that this arrangement may indeed confer a learning advantage.</abstract>
      <pages>181–216</pages>
      <url hash="189ce55d">2021.cl-1.7</url>
      <bibkey>jin-etal-2021-depth</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    </volume>
  <volume id="2">
    <meta>
      <booktitle>Computational Linguistics, Volume 47, Issue 2 - June 2021</booktitle>
      <month>June</month>
      <year>2021</year>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
    </meta>
    <paper id="9">
      <title>Approximating Probabilistic Models as Weighted Finite Automata</title>
      <author><first>Ananda Theertha</first><last>Suresh</last></author>
      <author><first>Brian</first><last>Roark</last></author>
      <author><first>Michael</first><last>Riley</last></author>
      <author><first>Vlad</first><last>Schogol</last></author>
      <doi>10.1162/coli_a_00401</doi>
      <abstract>Abstract Weighted finite automata (WFAs) are often used to represent probabilistic models, such as n-gram language models, because among other things, they are efficient for recognition tasks in time and space. The probabilistic source to be represented as a WFA, however, may come in many forms. Given a generic probabilistic model over sequences, we propose an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> to approximate it as a WFA such that the <a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence">Kullback-Leibler divergence</a> between the source model and the WFA target model is minimized. The proposed <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> involves a counting step and a difference of convex optimization step, both of which can be performed efficiently. We demonstrate the usefulness of our approach on various tasks, including distilling n-gram models from neural models, building compact language models, and building open-vocabulary character models. The <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> used for these experiments are available in an open-source software library.</abstract>
      <pages>221–254</pages>
      <url hash="390ee738">2021.cl-2.9</url>
      <bibkey>suresh-etal-2021-approximating</bibkey>
    </paper>
    <paper id="12">
      <title>RYANSQL : Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases<fixed-case>RYANSQL</fixed-case>: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-<fixed-case>SQL</fixed-case> in Cross-Domain Databases</title>
      <author><first>DongHyun</first><last>Choi</last></author>
      <author><first>Myeong Cheol</first><last>Shin</last></author>
      <author><first>EungGyun</first><last>Kim</last></author>
      <author><first>Dong Ryeol</first><last>Shin</last></author>
      <doi>10.1162/coli_a_00403</doi>
      <abstract>Abstract Text-to-SQL is the problem of converting a user question into an <a href="https://en.wikipedia.org/wiki/SQL">SQL query</a>, when the question and database are given. In this article, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of non-nested SELECT statements ; a sketch-based slot-filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further. RYANSQL achieved competitive result of 58.2 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the challenging Spider benchmark. At the time of submission (April 2020), RYANSQL v2, a variant of original RYANSQL, is positioned at 3rd place among all systems and 1st place among the systems not using database content with 60.6 % exact matching accuracy. The source code is available at https://github.com/kakaoenterprise/RYANSQL.</abstract>
      <pages>309–332</pages>
      <url hash="69a55600">2021.cl-2.12</url>
      <bibkey>choi-etal-2021-ryansql</bibkey>
      <pwccode url="https://github.com/kakaoenterprise/RYANSQL" additional="false">kakaoenterprise/RYANSQL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/spider-1">SPIDER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="13">
      <title>CausaLM : Causal Model Explanation Through Counterfactual Language Models<fixed-case>C</fixed-case>ausa<fixed-case>LM</fixed-case>: Causal Model Explanation Through Counterfactual Language Models</title>
      <author><first>Amir</first><last>Feder</last></author>
      <author><first>Nadav</first><last>Oved</last></author>
      <author><first>Uri</first><last>Shalit</last></author>
      <author><first>Roi</first><last>Reichart</last></author>
      <doi>10.1162/coli_a_00404</doi>
      <abstract>Abstract Understanding predictions made by <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> is notoriously difficult, but also crucial to their dissemination. As all machine learningbased methods, they are as good as their training data, and can also capture unwanted biases. While there are tools that can help understand whether such biases exist, they do not distinguish between <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation</a> and <a href="https://en.wikipedia.org/wiki/Causality">causation</a>, and might be ill-suited for text-based models and for reasoning about high-level language concepts. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology. To bridge that gap, we propose CausaLM, a framework for producing causal model explanations using counterfactual language representation models. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the <a href="https://en.wikipedia.org/wiki/Causal_graph">causal graph</a> of the problem. Concretely, we show that by carefully choosing auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data.1</abstract>
      <pages>333–386</pages>
      <url hash="5bd824ae">2021.cl-2.13</url>
      <bibkey>feder-etal-2021-causalm</bibkey>
    </paper>
    <paper id="14">
      <title>Analysis and Evaluation of <a href="https://en.wikipedia.org/wiki/Language_model">Language Models</a> for Word Sense Disambiguation</title>
      <author><first>Daniel</first><last>Loureiro</last></author>
      <author><first>Kiamehr</first><last>Rezaee</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <doi>10.1162/coli_a_00405</doi>
      <abstract>Abstract Transformer-based language models have taken many fields in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> by storm. BERT and its derivatives dominate most of the existing evaluation benchmarks, including those for Word Sense Disambiguation (WSD), thanks to their ability in capturing context-sensitive semantic nuances. However, there is still little knowledge about their capabilities and potential limitations in encoding and recovering word senses. In this article, we provide an in-depth quantitative and qualitative analysis of the celebrated BERT model with respect to <a href="https://en.wikipedia.org/wiki/Ambiguity">lexical ambiguity</a>. One of the main conclusions of our analysis is that BERT can accurately capture high-level sense distinctions, even when a limited number of examples is available for each word sense. Our analysis also reveals that in some cases language models come close to solving coarse-grained noun disambiguation under ideal conditions in terms of availability of training data and computing resources. However, this scenario rarely occurs in real-world settings and, hence, many practical challenges remain even in the coarse-grained setting. We also perform an in-depth comparison of the two main language model-based WSD strategies, namely, <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> and <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a>, finding that the latter approach is more robust with respect to sense bias and it can better exploit limited available training data. In fact, the simple feature extraction strategy of averaging contextualized embeddings proves robust even using only three training sentences per word sense, with minimal improvements obtained by increasing the size of this training data.</abstract>
      <pages>387–443</pages>
      <url hash="20cc9d3c">2021.cl-2.14</url>
      <bibkey>loureiro-etal-2021-analysis</bibkey>
      <pwccode url="https://github.com/danlou/bert-disambiguation" additional="false">danlou/bert-disambiguation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coarsewsd-20">CoarseWSD-20</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/superglue">SuperGLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Computational Linguistics, Volume 47, Issue 3 - November 2021</booktitle>
      <month>November</month>
      <year>2021</year>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
    </meta>
    <paper id="16">
      <title>The Taxonomy of Writing Systems : How to Measure How Logographic a System Is</title>
      <author><first>Richard</first><last>Sproat</last></author>
      <author><first>Alexander</first><last>Gutkin</last></author>
      <doi>10.1162/coli_a_00409</doi>
      <abstract>Taxonomies of writing systems since Gelb (1952) have classified systems based on what the written symbols represent : if they represent words or morphemes, they are logographic ; if syllables, syllabic ; if segments, alphabetic ; and so forth. Sproat (2000) and Rogers (2005) broke with tradition by splitting the logographic and phonographic aspects into two dimensions, with <a href="https://en.wikipedia.org/wiki/Logography">logography</a> being graded rather than a categorical distinction. A system could be syllabic, and highly logographic ; or alphabetic, and mostly non-logographic. This accords better with how <a href="https://en.wikipedia.org/wiki/Writing_system">writing systems</a> actually work, but neither author proposed a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for measuring <a href="https://en.wikipedia.org/wiki/Logography">logography</a>. In this article we propose a novel measure of the degree of <a href="https://en.wikipedia.org/wiki/Logography">logography</a> that uses an attention-based sequence-to-sequence model trained to predict the spelling of a token from its pronunciation in context. In an ideal <a href="https://en.wikipedia.org/wiki/Phonogram_(linguistics)">phonographic system</a>, the model should need to attend to only the current token in order to compute how to spell it, and this would show in the attention matrix activations. In contrast, with a <a href="https://en.wikipedia.org/wiki/Logogram">logographic system</a>, where a given <a href="https://en.wikipedia.org/wiki/Pronunciation">pronunciation</a> might correspond to several different spellings, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> would need to attend to a broader context. The ratio of the activation outside the token and the total activation forms the basis of our <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measure</a>. We compare this with a simple lexical measure, and an entropic measure, as well as several other neural models, and argue that on balance our attention-based measure accords best with intuition about how logographic various systems are.</abstract>
      <pages>477–528</pages>
      <url hash="e822a20d">2021.cl-3.16</url>
      <bibkey>sproat-gutkin-2021-taxonomy</bibkey>
    </paper>
    <paper id="20">
      <title>Decoding Word Embeddings with Brain-Based Semantic Features</title>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Enrico</first><last>Santus</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <doi>10.1162/coli_a_00412</doi>
      <abstract>Word embeddings are vectorial semantic representations built with either counting or predicting techniques aimed at capturing shades of meaning from word co-occurrences. Since their introduction, these <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representations</a> have been criticized for lacking interpretable dimensions. This property of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> limits our understanding of the <a href="https://en.wikipedia.org/wiki/Semantic_feature">semantic features</a> they actually encode. Moreover, it contributes to the black box nature of the tasks in which they are used, since the reasons for <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a> performance often remain opaque to humans. In this contribution, we explore the semantic properties encoded in word embeddings by mapping them onto interpretable vectors, consisting of explicit and neurobiologically motivated semantic features (Binder et al. Our exploration takes into account different types of embeddings, including factorized count vectors and predict models (Skip-Gram, GloVe, etc.), as well as the most recent contextualized representations (i.e., ELMo and BERT). In our analysis, we first evaluate the quality of the <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mapping</a> in a retrieval task, then we shed light on the semantic features that are better encoded in each embedding type. A large number of probing tasks is finally set to assess how the original and the mapped embeddings perform in discriminating semantic categories. For each probing task, we identify the most relevant semantic features and we show that there is a correlation between the <a href="https://en.wikipedia.org/wiki/Embedding">embedding</a> performance and how they encode those <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. This study sets itself as a step forward in understanding which aspects of meaning are captured by <a href="https://en.wikipedia.org/wiki/Vector_space">vector spaces</a>, by proposing a new and simple method to carve human-interpretable semantic representations from <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional vectors</a>.</abstract>
      <pages>663–698</pages>
      <url hash="945a1b8b">2021.cl-3.20</url>
      <bibkey>chersoni-etal-2021-decoding</bibkey>
    </paper>
    </volume>
  <volume id="4">
    <meta>
      <booktitle>Computational Linguistics, Volume 47, Issue 4 - December 2021</booktitle>
      <month>December</month>
      <year>2021</year>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
    </meta>
    <paper id="27">
      <title>Abstractive Text Summarization : Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization</title>
      <author><first>Panagiotis</first><last>Kouris</last></author>
      <author><first>Georgios</first><last>Alexandridis</last></author>
      <author><first>Andreas</first><last>Stafylopatis</last></author>
      <doi>10.1162/coli_a_00417</doi>
      <abstract>Abstract Nowadays, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. In this direction, this work presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies. The proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> is capable of dealing with the problem of out-of-vocabulary or rare words, improving the performance of the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>. The overall <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries. The <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> is composed of three key elements : (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task. The pre-processing task is a knowledge-based approach, based on ontological knowledge resources, <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a>, and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, along with content generalization, that transforms ordinary text into a generalized form. A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form. The post-processing task utilizes knowledge resources, <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a>, and <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)">heuristic algorithms</a> based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form.</abstract>
      <pages>813–859</pages>
      <url hash="57d76055">2021.cl-4.27</url>
      <bibkey>kouris-etal-2021-abstractive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    <title_es>Resumen de texto abstracto: mejora de los modelos secuencia a secuencia mediante la desambiguación del sentido de las palabras y la generalización de contenido semántico</title_es>
      <title_ar>تلخيص النص التجريدي: تعزيز نماذج التسلسل إلى التسلسل باستخدام توضيح معنى الكلمات وتعميم المحتوى الدلالي</title_ar>
      <title_pt>Resumo Abstrativo de Texto: Aprimorando Modelos de Sequência a Sequência Usando Desambiguação de Sentido de Palavras e Generalização de Conteúdo Semântico</title_pt>
      <title_fr>Résumé de texte abstrait : amélioration des modèles séquence à séquence à l'aide de la désambiguïsation du sens des mots et de la généralisation de contenu sémantique</title_fr>
      <title_ja>抽象的テキストの要約：単語センスの曖昧さ解消とセマンティックコンテンツの一般化を使用したシーケンス間モデルの強化</title_ja>
      <title_zh>抽象文本摘要:用字感消歧义语义泛化增序至序</title_zh>
      <title_ru>Абстрактное текстовое обобщение: совершенствование моделей последовательности в последовательности с использованием словосочетания смысла и семантического контента</title_ru>
      <title_hi>Abstractive Text Summarization: Word Sense Disambiguation और Semantic Content Generalization का उपयोग करके अनुक्रम-से-अनुक्रम मॉडल को बढ़ाना</title_hi>
      <title_ga>Achoimriú Téacs Teibí: Samhlacha Seicheamh-go-Seicheamh a Fheabhsú Ag Úsáid Dídhébhríocht Focal Sense agus Ginearálú Séimeantach Ábhar</title_ga>
      <title_ka>აბსტრაქტიური ტექსტის კომპანიზაცია: შემდეგ- შემდეგ- შემდეგ მოდელების უფრო მეტირება გამოყენება სიტყვის სიტყვის გამოყენება</title_ka>
      <title_el>Περίληψη κειμένου: Ενίσχυση μοντέλων αλληλουχίας σε αλληλουχίας χρησιμοποιώντας την αποσαφήνιση και τη γενίκευση σημασιολογικού περιεχομένου</title_el>
      <title_hu>Absztraktív szövegösszefoglalás: A szekvencia-szekvencia modellek javítása a Word Sense szétérthetőségével és a szemantikus tartalom általánosításával</title_hu>
      <title_it>Sintesi astratta del testo: miglioramento dei modelli sequenziali utilizzando la disambiguazione del senso delle parole e la generalizzazione dei contenuti semantici</title_it>
      <title_lt>Abstraktyvi teksto santrauka: iš eilės į eilę modelių tobulinimas, naudojant žodžio jausmą ir semantinio turinio generalizaciją</title_lt>
      <title_kk>Абстрактивті мәтін тұжырымдамасы: Сөздердің сезімін бұғаттауын және бөлшектердің мазмұнын жасау үлгілерін көтеру</title_kk>
      <title_ms>Penapisan Teks Abstraktif: Menyukur Model Sejukan-ke-Sejukan Mengguna Pengesahan Sensa Perkataan dan Penjanaan Kandungan Semantik</title_ms>
      <title_ml>അബ്ട്രാക്ട്രേക്ഷന്‍ വാക്ക് സെന്‍സിന്റെ അസംഭാഷണം ഉപയോഗിക്കുന്ന സെക്കന്‍സ് മോഡലുകള്‍ കൂടുതല്‍ വര്‍ദ്ധിപ്പിക്കുക</title_ml>
      <title_mk>Апстрактивна резултатација на текстот: подобрување на моделите од секвенција до секвенција со користење на раздвојување на зборовите и генерализација на семантичната содржина</title_mk>
      <title_mt>Sommarju tat-Test Abstrattiv: It-Titjib tal-Mudelli Sekwenti-Sekwenti bl-Użu tad-Diżambiguazzjoni tas-Sens tal-kliem u l-Ġeneralizzazzjoni tal-Kontenut Semantiku</title_mt>
      <title_pl>Abstrakcyjne podsumowanie tekstu: ulepszanie modeli sekwencji do sekwencji przy użyciu rozjasnienia tekstu Word Sense i uogólniania treści semantycznych</title_pl>
      <title_mn>Абстрактив текст цуглуулга: Дараагийн-дараагийн загваруудыг нэмэгдүүлэх</title_mn>
      <title_ro>Rezumat text abstract: îmbunătățirea modelelor secvență-secvență folosind dezambiguizarea sensului Word și generalizarea conținutului semantic</title_ro>
      <title_no>Abstraktiv tekstsamandrag: Forstørring av sekvens- til- sekvens- modeller ved bruk av forstørring av tekstfølelser og generering av semiantisk innhald</title_no>
      <title_sr>Abstraktivna sažetka teksta: Povećavanje modela sekvence do sekvence koristeći dezambigaciju osjećaja riječi i generalizaciju semantičnog sadržaja</title_sr>
      <title_so>Highlighting: Enhancing Sequence-to-Sequence Models Using Word Sense Disambition and Semantic Content General</title_so>
      <title_si>ප්‍රතික්‍රීය පාළුව සංශ්‍ය: ප්‍රතික්‍රීය- වල සංශ්‍ය සංශ්‍ය සංශ්‍ය සංශ්‍ය භාවිත කරනවා වචන සංශ්‍ය සහ සංශ්‍</title_si>
      <title_ta>சுருக்கம்:</title_ta>
      <title_ur>Abstractive Text Summarization: Enhancing Sequence- to- Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization</title_ur>
      <title_sv>Abstraktiv textsammanfattning: Förbättra sekvens-till-sekvensmodeller med hjälp av ordsinnesdistribution och semantisk innehållsgenerering</title_sv>
      <title_uz>Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization</title_uz>
      <title_vi>Tóm tắt tập tin âm bản: Chế độ lặp lặp nhanh/ nhanh</title_vi>
      <title_hr>Abstraktivna sažetka teksta: poboljšanje modela sekvence do sekvence koristeći disambigaciju osjećaja riječi i generalizaciju semantičkog sadržaja</title_hr>
      <title_da>Abstraktiv tekst summering: Forbedring af sekvens-til-sekvensmodeller ved hjælp af Word Sense Disambiguation og semantisk indholdsgeneralisering</title_da>
      <title_bg>Обобщение на абстрактния текст: Подобряване на моделите последователност към последователност, използвайки дисамбигуация на чувството на словото и генериране на семантично съдържание</title_bg>
      <title_nl>Abstracte samenvatting van tekst: Verbetering van sequentiemodellen met behulp van Word Sense Disambiguation en semantische inhoudsverzameling</title_nl>
      <title_id>Persingkatan Teks Abstraktif: meningkatkan Model Sekuensi-ke-Sekuensi Menggunakan Pengambiguasi Sensi Kata dan Generalisasi Konten Semantik</title_id>
      <title_de>Abstraktive Textzusammenfassung: Verbesserung von Sequenz-zu-Sequenz-Modellen mithilfe von Word Sense Disambiguation und semantischer Inhaltsverallgemeinerung</title_de>
      <title_fa>جمع کردن متن abstractive: افزایش مدل‌های سعادت به سعادت</title_fa>
      <title_ko>추상적 텍스트 요약: 단어의 의미 변조와 의미 내용의 범용화 강화 서열을 서열 모델로 사용</title_ko>
      <title_sw>Ujumbe wa maandishi ya kusitisha: Kuongezea Mitandao ya Kuzungumzwa kwa mara kwa mara kwa kutumia Utoaji wa Sensi na Ujumbe wa Maudhui</title_sw>
      <title_tr>Abstraktif Metin Toplaýyşy: Diňe-tä-sıralama Modelleri Keçirmek ve Orta Mazmunlar Üzerinde Ullanýar</title_tr>
      <title_af>Abstraktiewe Teks Opsomming: Verbeter Sequence- to- Sequence Models gebruik word Sense Ontbreking en Semantiese Inhoud Generalisering</title_af>
      <title_sq>Përshkrimi abstraktiv i tekstit: përmirësimi i modeleve nga sekuenca në sekuencë duke përdorur çambiguacionin e ndjerjes së fjalës dhe gjeneralizimin e përmbajtjes Semantike</title_sq>
      <title_hy>Աբստրակտիվ տեքստի համառոտագրություն. բարելավել հաջորդականություն հաջորդականության մոդելները՝ օգտագործելով բառերի զգացմունքի անբացատրությունը և սեմանտիկ պարունակության ընդհանուր ընդհանուր ընդլայնումը</title_hy>
      <title_bn>আবত্ত্রিক টেক্সট সামারিজেশন: শব্দের সেন্স বিচ্ছিন্ন এবং সেম্যান্টিক বিষয়বস্তু সাধারণ</title_bn>
      <title_az>Abstraktiv Metin Toplaşdırılması: Sözlük Duyurulması və Semantik Məzmun Generalizasyonu Əlavə Et</title_az>
      <title_am>ማጠቃለያ</title_am>
      <title_bs>Abstraktivna sažetka teksta: poboljšanje modela sekvence do sekvence koristeći disambigaciju osjećaja riječi i generalizaciju semantičnog sadržaja</title_bs>
      <title_ca>Resumen abstractiu del text: millorar els models de seqüència a seqüència utilitzant desambiguació de sentit de paraula i generalització de continguts Semàtics</title_ca>
      <title_cs>Abstraktivní shrnutí textu: zlepšení modelů sekvence na sekvenci pomocí disambiguace Word Sense a zobecnění sémantického obsahu</title_cs>
      <title_et>Kokkuvõtlik teksti kokkuvõte: järjestuse mudelite tõhustamine, kasutades sõnatunne disambigeerimist ja semantilist sisu generaliseerimist</title_et>
      <title_fi>Abstrakti tekstin yhteenveto: sekvenssimallien tehostaminen sekvenssimallien avulla sanaaistin hajottamisen ja semanttisen sisällön generoinnin avulla</title_fi>
      <title_jv>Samurasi tèks apasitsi: Inchanging Seyense-to-Seyense Modes Using Word Sense disabled mbiguation and semanti Content Generalization</title_jv>
      <title_he>סאמר טקסט אסטרקטיבי: שיפור מודלים רצף-לרצף באמצעות ניתוח משמעות מילים וגנרליזציה של תוכן סמנטי</title_he>
      <title_ha>@ action</title_ha>
      <title_sk>Povzetek besedila: izboljšanje modelov zaporedja v zaporedje z razjasnitvijo besednega smisla in generalizacijo semantične vsebine</title_sk>
      <title_bo>Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization</title_bo>
      <abstract_ar>الملخص في الوقت الحاضر ، تركز معظم الأبحاث التي أجريت في مجال تلخيص النص التجريدي على النماذج القائمة على العصبية وحدها ، دون النظر إلى دمجها مع الأساليب القائمة على المعرفة التي يمكن أن تعزز كفاءتها. في هذا الاتجاه ، يقدم هذا العمل إطارًا جديدًا يجمع بين تلخيص النص المعتمد على التسلسل العصبي جنبًا إلى جنب مع الهيكل والمنهجيات القائمة على الدلالات. إن الإطار المقترح قادر على التعامل مع مشكلة الكلمات غير المطابقة للمفردات أو الكلمات النادرة ، وتحسين أداء نماذج التعلم العميق. تعتمد المنهجية الشاملة على نموذج نظري محدد جيدًا لتعميم المحتوى القائم على المعرفة وتنبؤات التعلم العميق لتوليد ملخصات تجريدية. يتكون إطار العمل من ثلاثة عناصر رئيسية: (1) مهمة ما قبل المعالجة ، (2) منهجية التعلم الآلي ، و (3) مهمة ما بعد المعالجة. مهمة ما قبل المعالجة هي نهج قائم على المعرفة ، يعتمد على موارد المعرفة الأنطولوجية ، وتوضيح معنى الكلمة ، والتعرف على الكيان المسمى ، إلى جانب تعميم المحتوى ، الذي يحول النص العادي إلى نموذج معمم. يتم تدريب نموذج التعلم العميق لمعمارية وحدة فك التشفير اليقظة ، والتي يتم توسيعها لتمكين آلية المواجهة والتغطية ، بالإضافة إلى التعلم المعزز والبنى القائمة على المحولات ، على نسخة معممة من أزواج ملخص النص ، وتعلم التنبؤ بالملخصات في شكل معمم. مهمة ما بعد المعالجة تستخدم المعرفة
الموارد ، وتضمينات الكلمات ، وتوضيح معنى الكلمة ، وخوارزميات الكشف عن مجريات الأمور على أساس طرق تشابه النص من أجل تحويل النسخة المعممة من الملخص المتوقع إلى شكل نهائي يمكن قراءته من قبل الإنسان. يقوم إجراء تجريبي مكثف على ثلاث مجموعات بيانات شائعة بتقييم الجوانب الرئيسية للإطار المقترح ، بينما تُظهر النتائج التي تم الحصول عليها أداءً واعدًا ، مما يؤكد قوة النهج المقترح.</abstract_ar>
      <abstract_es>Resumen Hoy en día, la mayoría de las investigaciones realizadas en el campo de la síntesis de textos abstractivos se centran únicamente en modelos neuronales, sin considerar su combinación con enfoques basados en el conocimiento que podrían mejorar aún más su eficiencia. En esta dirección, este trabajo presenta un marco novedoso que combina la sumarización de texto basada en neuronas de secuencia a secuencia junto con metodologías basadas en la estructura y la semántica. El marco propuesto es capaz de abordar el problema de las palabras raras o fuera de vocabulario, mejorando el rendimiento de los modelos de aprendizaje profundo. La metodología general se basa en un modelo teórico bien definido de generalización de contenido basada en el conocimiento y predicciones de aprendizaje profundo para generar resúmenes abstractivos. El marco se compone de tres elementos clave: (i) una tarea de preprocesamiento, (ii) una metodología de aprendizaje automático y (iii) una tarea de posprocesamiento. La tarea de preprocesamiento es un enfoque basado en el conocimiento, basado en recursos de conocimiento ontológico, desambiguación del sentido de las palabras y reconocimiento de entidades nombradas, junto con la generalización de contenido, que transforma el texto ordinario en una forma generalizada. Un modelo de aprendizaje profundo de arquitectura de codificador-decodificador atento, que se amplía para permitir un mecanismo de afrontamiento y cobertura, así como arquitecturas basadas en transformadores y aprendizaje de refuerzo, se entrena en una versión generalizada de pares de resumen de texto, aprendiendo a predecir resúmenes de forma generalizada. La tarea de posprocesamiento utiliza el conocimiento
recursos, incrustaciones de palabras, desambiguación del sentido de las palabras y algoritmos heurísticos basados en métodos de similitud de texto para transformar la versión generalizada de un resumen predicho en una forma final legible por humanos. Un extenso procedimiento experimental en tres conjuntos de datos populares evalúa los aspectos clave del marco propuesto, mientras que los resultados obtenidos muestran un rendimiento prometedor, lo que valida la solidez del enfoque propuesto.</abstract_es>
      <abstract_fr>Résumé De nos jours, la plupart des recherches menées dans le domaine de la synthèse de textes abstraits se concentrent uniquement sur les modèles neuronaux, sans tenir compte de leur combinaison avec des approches fondées sur la connaissance qui pourraient améliorer encore leur efficacité. Dans cette direction, ce travail présente un nouveau cadre qui combine la synthèse de textes neuronaux séquence-à-séquence avec des méthodologies basées sur la structure et la sémantique. Le cadre proposé est capable de traiter le problème du hors vocabulaire ou des mots rares, améliorant ainsi les performances des modèles d'apprentissage profond. La méthodologie globale est basée sur un modèle théorique bien défini de généralisation de contenu basé sur les connaissances et de prédictions d'apprentissage profond pour générer des résumés abstraits. Le cadre est composé de trois éléments clés : (i) une tâche de pré-traitement, (ii) une méthodologie d'apprentissage automatique et (iii) une tâche de post-traitement. La tâche de prétraitement est une approche basée sur les connaissances, basée sur des ressources de connaissances ontologiques, la désambiguïsation du sens des mots et la reconnaissance d'entités nommées, ainsi que la généralisation du contenu, qui transforme le texte ordinaire en une forme généralisée. Un modèle d'apprentissage profond d'architecture codeur-décodeur attentif, qui est étendu pour permettre un mécanisme d'adaptation et de couverture, ainsi que des architectures d'apprentissage par renforcement et basées sur des transformateurs, est entraîné sur une version généralisée de paires texte-résumé, apprenant à prédire des résumés sous une forme généralisée. La tâche de post-traitement utilise les connaissances
ressources, intégrations de mots, désambiguïsation des sens des mots et algorithmes heuristiques basés sur des méthodes de similarité de texte afin de transformer la version généralisée d'un résumé prédit en une forme finale lisible par l'homme. Une procédure expérimentale approfondie sur trois ensembles de données populaires évalue les aspects clés du cadre proposé, tandis que les résultats obtenus présentent des performances prometteuses, validant la robustesse de l'approche proposée.</abstract_fr>
      <abstract_zh>摘要今于抽象摘要领域者多究其神经形,而不虑其合进一步提高效率可知也。 于是建一新框架,框架合神经文本摘要及构语义之法。 所建框架能处词汇量不足罕见之单词,以崇深学模范之性。 体法基于知识泛化深学明义,以成抽象摘要。 其框架三要:(i)预处理任,(ii)机器学术,及(iii)后处理务。 预处理务者,知识之术也,本体论知识之资,词义消歧义名实识泛化,转为广义之文。 细心编码器-解码器架构之深,学以广之,应对覆盖,及化学基于转换器架构,练之以文本摘要练之以广义,习之以广义占摘要。 后处理任以知
资源、词销、词义消歧义与文本相似性法之启发式算法,以转占摘要广义版本为人可读之终文。 三行数集上博实验程评所发框架要,而得所望,验其所鲁棒性。</abstract_zh>
      <abstract_pt>Resumo Atualmente, a maioria das pesquisas realizadas na área de sumarização de texto abstrativa concentra-se apenas em modelos baseados em neurônios, sem considerar sua combinação com abordagens baseadas em conhecimento que poderiam aumentar ainda mais sua eficiência. Nessa direção, este trabalho apresenta um novo framework que combina sumarização de texto baseado em neurais sequência-a-sequência juntamente com metodologias baseadas em estrutura e semântica. O framework proposto é capaz de lidar com o problema de falta de vocabulário ou palavras raras, melhorando o desempenho dos modelos de deep learning. A metodologia geral é baseada em um modelo teórico bem definido de generalização de conteúdo baseado em conhecimento e previsões de aprendizado profundo para gerar resumos abstratos. A estrutura é composta por três elementos principais: (i) uma tarefa de pré-processamento, (ii) uma metodologia de aprendizado de máquina e (iii) uma tarefa de pós-processamento. A tarefa de pré-processamento é uma abordagem baseada em conhecimento, baseada em recursos de conhecimento ontológico, desambiguação de sentido de palavra e reconhecimento de entidade nomeada, juntamente com generalização de conteúdo, que transforma o texto comum em uma forma generalizada. Um modelo de aprendizado profundo de arquitetura de codificador-decodificador atento, que é expandido para permitir um mecanismo de enfrentamento e cobertura, bem como aprendizado de reforço e arquiteturas baseadas em transformador, é treinado em uma versão generalizada de pares de resumo de texto, aprendendo a prever resumos em uma forma generalizada. A tarefa de pós-processamento utiliza o conhecimento
recursos, incorporação de palavras, desambiguação de sentido de palavra e algoritmos heurísticos baseados em métodos de similaridade de texto para transformar a versão generalizada de um resumo previsto em uma forma final legível por humanos. Um extenso procedimento experimental em três conjuntos de dados populares avalia aspectos-chave do framework proposto, enquanto os resultados obtidos apresentam desempenho promissor, validando a robustez da abordagem proposta.</abstract_pt>
      <abstract_hi>सार आजकल, अमूर्त पाठ सारांशीकरण के क्षेत्र में किए गए अधिकांश शोध अकेले तंत्रिका-आधारित मॉडल पर केंद्रित हैं, ज्ञान-आधारित दृष्टिकोणों के साथ उनके संयोजन पर विचार किए बिना जो उनकी दक्षता को और बढ़ा सकते हैं। इस दिशा में, यह काम एक उपन्यास रूपरेखा प्रस्तुत करता है जो संरचना और शब्दार्थ-आधारित तरीकों के साथ अनुक्रम-से-अनुक्रम तंत्रिका-आधारित पाठ सारांशीकरण को जोड़ता है। प्रस्तावित ढांचा आउट-ऑफ-शब्दावली या दुर्लभ शब्दों की समस्या से निपटने में सक्षम है, जिससे गहरे सीखने के मॉडल के प्रदर्शन में सुधार होता है। समग्र पद्धति अमूर्त सारांश उत्पन्न करने के लिए ज्ञान-आधारित सामग्री सामान्यीकरण और गहरी सीखने की भविष्यवाणियों के एक अच्छी तरह से परिभाषित सैद्धांतिक मॉडल पर आधारित है। फ्रेमवर्क तीन प्रमुख तत्वों से बना है: (i) एक पूर्व-प्रसंस्करण कार्य, (ii) एक मशीन सीखने की पद्धति, और (iii) एक पोस्ट-प्रोसेसिंग कार्य। प्री-प्रोसेसिंग कार्य एक ज्ञान-आधारित दृष्टिकोण है, जो ontological ज्ञान संसाधनों, शब्द भावना disambiguation, और नामित इकाई मान्यता पर आधारित है, सामग्री सामान्यीकरण के साथ, जो सामान्य पाठ को एक सामान्यीकृत रूप में परिवर्तित करता है। चौकस एनकोडर-डिकोडर आर्किटेक्चर का एक गहरा सीखने का मॉडल, जिसे एक मुकाबला और कवरेज तंत्र, साथ ही सुदृढीकरण सीखने और ट्रांसफॉर्मर-आधारित आर्किटेक्चर को सक्षम करने के लिए विस्तारित किया जाता है, पाठ-सारांश जोड़े के एक सामान्यीकृत संस्करण पर प्रशिक्षित किया जाता है, जो एक सामान्यीकृत रूप में सारांश की भविष्यवाणी करना सीखता है। पोस्ट-प्रोसेसिंग कार्य ज्ञान का उपयोग करता है
संसाधनों, शब्द एम्बेडिंग, शब्द भावना disambiguation, और heuristic एल्गोरिदम पाठ समानता विधियों पर आधारित क्रम में एक अंतिम, मानव पठनीय रूप के लिए एक अनुमानित सारांश के सामान्यीकृत संस्करण को बदलने के लिए। तीन लोकप्रिय डेटा सेटों पर एक व्यापक प्रयोगात्मक प्रक्रिया प्रस्तावित ढांचे के प्रमुख पहलुओं का मूल्यांकन करती है, जबकि प्राप्त परिणाम प्रस्तावित दृष्टिकोण की मजबूती को मान्य करते हुए आशाजनक प्रदर्शन प्रदर्शित करते हैं।</abstract_hi>
      <abstract_ja>今日、抽象的なテキスト要約の分野で行われているほとんどの研究は、ニューラルベースのモデルだけに焦点を当てており、それらと効率をさらに向上させることができる知識ベースのアプローチとの組み合わせを考慮することはありません。 この方向性では、この研究は、構造と意味ベースの方法論とともに、シーケンス間ニューラルベースのテキスト要約を組み合わせた斬新なフレームワークを提示する。 提案されたフレームワークは、語彙外または希少な単語の問題に対処し、ディープラーニングモデルのパフォーマンスを向上させることができる。 全体的な方法論は、抽象的な要約を生成するための知識ベースのコンテンツの一般化と深層学習予測の十分に定義された理論モデルに基づいている。 フレームワークは、（ ｉ ）前処理タスク、（ ｉ ｉ ）機械学習方法論、及び（ ｉｉｉ ）後処理タスクの３つの主要な要素から構成される。 前処理タスクは、オントロジー知識リソース、単語センスの曖昧さ解消、およびコンテンツの一般化とともに、通常のテキストを一般化された形式に変換する名前付きエンティティ認識に基づく知識ベースのアプローチである。 注意深いエンコーダデコーダアーキテクチャのディープラーニングモデルは、対応とカバレッジのメカニズム、ならびに強化学習とトランスベースのアーキテクチャを可能にするように拡張され、テキストサマリーペアの一般化されたバージョンで訓練され、一般化された形式で要約を予測することを学習します。後処理タスクは、知識を利用します
リソース、ワード埋め込み、ワードセンスの曖昧さ解消、およびテキスト類似性メソッドに基づくヒューリスティックアルゴリズムを使用して、予測された要約の一般化されたバージョンを最終的な人間が読み取り可能な形式に変換します。3つの人気のあるデータセットに関する広範な実験手順は、提案されたフレームワークの主要な側面を評価し、取得された結果は有望なパフォーマンスを示し、提案されたアプローチの堅牢性を検証する。</abstract_ja>
      <abstract_ru>В настоящее время большинство исследований, проводимых в области абстрактного обобщения текста, фокусируется только на нейронных моделях, не рассматривая их сочетание с наукоемкими подходами, которые могли бы еще больше повысить их эффективность. В этом направлении данная работа представляет собой новую структуру, которая сочетает в себе последовательность за последовательностью нейронное обобщение текста наряду со структурой и семантическими методологиями. Предлагаемая система способна решить проблему внесловных или редких слов, повышая эффективность моделей глубокого обучения. Общая методология основана на четко определенной теоретической модели обобщения контента на основе знаний и прогнозов глубокого обучения для генерирования абстрактных сводок. Эта система состоит из трех ключевых элементов: i) задачи предварительной обработки, ii) методологии машинного обучения и iii) задачи последующей обработки. Задача предварительной обработки - это основанный на знаниях подход, основанный на онтологических ресурсах знаний, дезагрегировании смысла слова и распознавании именованных сущностей, наряду с обобщением содержания, который преобразует обычный текст в обобщенную форму. Модель глубокого обучения внимательной архитектуры кодер-декодер, которая расширяется, чтобы обеспечить механизм совмещения и охвата, а также обучение подкреплению и архитектуры на основе трансформаторов, обучается на обобщенной версии пар текст-суммирование, обучаясь предсказывать сводки в обобщенной форме. Задача постобработки использует знания
ресурсы, вложения слов, дезагрегирование смысла слов и эвристические алгоритмы, основанные на методах текстового сходства, чтобы преобразовать обобщенную версию прогнозируемого резюме в окончательную, читаемую человеком форму. Обширная экспериментальная процедура по трем популярным наборам данных оценивает ключевые аспекты предлагаемой основы, а полученные результаты демонстрируют многообещающие результаты, подтверждая надежность предлагаемого подхода.</abstract_ru>
      <abstract_ga>Abstract Sa lá atá inniu ann, díríonn an chuid is mó den taighde a dhéantar i réimse an achoimrithe téacs teibí ar mhúnlaí néarbhunaithe amháin, gan smaoineamh ar a dteaglaim le cineálacha cur chuige eolas-bhunaithe a d'fhéadfadh a n-éifeachtúlacht a fheabhsú tuilleadh. Sa treo seo, cuireann an saothar seo creat nua i láthair a chomhcheanglaíonn achoimriú téacs néarbhunaithe ó sheicheamh go seicheamh agus le modheolaíochtaí struchtúrtha agus shéimeantacha. Tá an creat atá beartaithe in ann déileáil le fadhb na bhfoclóra as-focal nó na bhfocal neamhchoitianta, ag feabhsú feidhmíocht na múnlaí domhainfhoghlama. Tá an mhodheolaíocht fhoriomlán bunaithe ar mhúnla teoiriciúil dea-shainithe maidir le ginearálú ábhair eolas-bhunaithe agus tuar domhainfhoghlama chun achoimrí teibí a ghiniúint. Tá trí phríomhghné sa chreat: (i) tasc réamhphróiseála, (ii) modheolaíocht mheaisínfhoghlama, agus (iii) tasc iar-phróiseála. Is cur chuige eolasbhunaithe é an tasc réamhphróiseála, bunaithe ar acmhainní eolais ontological, dí-athbhrí ar chiall na bhfocal, agus ar aithint aonáin ainmnithe, mar aon le ginearálú ábhair, a athraíonn gnáth-théacs ina fhoirm ghinearálaithe. Déantar samhail foghlama domhain d’ailtireacht ionchódóra-díchódóra aireach, a leathnaítear chun meicníocht dhéileála agus chumhdaigh a chumasú, chomh maith le foghlaim athneartaithe agus ailtireachtaí bunaithe ar chlaochladán, a oiliúint ar leagan ginearálaithe de phéirí téacs-achoimre, ag foghlaim conas achoimrí a thuar i. foirm ghinearálaithe. Úsáideann an tasc iar-phróiseála eolas
acmhainní, neadú focal, dí-athbhrí ar chiall na bhfocal, agus algartaim heorastúla bunaithe ar mhodhanna cosúlachta téacs chun an leagan ginearálaithe den achoimre réamh-mheasta a athrú go foirm dheiridh, inléite ag an duine. Déanann nós imeachta turgnamhach fairsing ar thrí thacar sonraí móréilimh meastóireacht ar phríomhghnéithe an chreata atá beartaithe, agus léiríonn na torthaí a fuarthas feidhmíocht mhaith, ag bailíochtú stóinseacht an chur chuige atá beartaithe.</abstract_ga>
      <abstract_it>Oggi, la maggior parte delle ricerche condotte nel campo della sintesi astratta del testo si concentra solo su modelli basati su neurali, senza considerare la loro combinazione con approcci basati sulla conoscenza che potrebbero migliorare ulteriormente la loro efficienza. In questa direzione, questo lavoro presenta un nuovo framework che combina la sintesi del testo neurale sequenziale-sequenziale insieme a strutture e metodologie semantiche-based. Il quadro proposto è in grado di affrontare il problema dell'out-of-vocabulary o delle parole rare, migliorando le prestazioni dei modelli di deep learning. La metodologia complessiva si basa su un modello teorico ben definito di generalizzazione dei contenuti basati sulla conoscenza e previsioni di deep learning per generare riassunti astratti. Il quadro è composto da tre elementi chiave: (i) un compito di pre-elaborazione, (ii) una metodologia di apprendimento automatico e (iii) un compito di post-elaborazione. Il compito di pre-elaborazione è un approccio basato sulla conoscenza, basato sulle risorse di conoscenza ontologica, sulla disambiguazione del senso delle parole e sul riconoscimento delle entità denominate, insieme alla generalizzazione dei contenuti, che trasforma il testo ordinario in una forma generalizzata. Un modello di deep learning di attenta architettura encoder-decoder, che è ampliato per consentire un meccanismo di coping e copertura, così come l'apprendimento di rinforzo e architetture basate su trasformatori, è formato su una versione generalizzata di coppie testo-riepilogo, imparando a prevedere i riassunti in forma generalizzata. Il compito di post-elaborazione utilizza conoscenze
Risorse, incorporazioni di parole, disambiguazione del senso delle parole e algoritmi euristici basati su metodi di somiglianza del testo al fine di trasformare la versione generalizzata di un riassunto previsto in una forma finale, leggibile dall'uomo. Un'ampia procedura sperimentale su tre set di dati popolari valuta gli aspetti chiave del framework proposto, mentre i risultati ottenuti mostrano prestazioni promettenti, convalidando la robustezza dell'approccio proposto.</abstract_it>
      <abstract_ka>აბსტრაქტიკური დღეში, ბევრად აბსტრაქტიური ტექსტის კუნძრაციაციის პანელში გავაკეთებულია მხოლოდ ნეიროლური მოდელზე, რომლებიც უფრო მეტად შეიძლება იმ ეფექტიკურობას გააკეთებო ამ მხარეს, ეს სამუშაო ახალგაზრდება პრომენტიკური ფრამეტრი, რომელიც კომბიუნციაცია ნეიროლური დაბათი ტექსტის კომბიზაცია სტრუქტურა და სმენტიკური მეტოლო პროგრამეტრები შეუძლებელია გარეშე სიტყვებლის ან რეტალური სიტყვების პრობლემების შესახებ, გარეშე ძალიან ძალიან სწავლის მოდელების შესახებ. ყველა მეტოლოგია ძალიან განსაზღვრებულია ცნობიერების გენერალზაციის შესახებ და ძალიან სწავლების განსაზღვრებების განსაზღვრებისთვის თეორეტიკური მოდელზე. პარამეტრის შექმნა სამი გასაღების ელემენტებით: i) პროცესირების დავალება, ii) მაქინის სწავლების მეტოლოგია და iii) პროცესირების დავალება. ოპვეპროცესი დავალება არის ცნობიერების მიზეზი, რომელიც კონტოლოგიური ცნობიერების რესურსებზე, სიტყვის განსხვავება, და სახელი ინტერტის განაცნობა, რომელიც განსხვავებული ინტერტის გენერალიზაციათან მნიშვნელოვანი სწავლების მოდელი, რომელიც გაფართებულია კოდირების და კოდირების მექანიზმის შესაძლებლობად, და სწავლების და ტრანფორმების განმავლობაზე აღმოჩენა ტექსტური კოდირების გერძალური ვერტიქტიფიკაში, რომელიც სწავლობულია, რომელიც სწ პროცესის შემდეგ დავალება უცნობის გამოყენება
რესურსები, სიტყვების შებრუნება, სიტყვების სიტყვების განსხვავება, და ჰეურისტიური ალგორიტიმები ტექსტის სხვადასხვა მეტოვების დაბაზეული ტექსტის სხვადასხვა მეტოვების განსხვავება, რომ გადაწყვეტილი სი სამი პოლუბური მონაცემების კონფიგური პროცემები განსაზღვრებას გასაკეთება საკუთარ პოლუბური მონაცემების გასაკეთებელი აპექტები, მაგრამ მიღებული შედეგი გამოიყენება გვ</abstract_ka>
      <abstract_hu>Absztrakt Napjainkban az absztraktív szövegösszefoglalás területén végzett kutatások többsége önmagában a neurális modellekre összpontosít, anélkül, hogy figyelembe vennék azokat a tudásalapú megközelítésekkel való kombinációjukat, amelyek tovább növelhetik hatékonyságukat. Ebben az irányban a munka olyan új keretrendszert mutat be, amely ötvözi a szekvencia-szekvencia neurális szövegösszefoglalást a szerkezet és a szemantikai módszerek mellett. A javasolt keret képes kezelni a szókincsen kívüli vagy ritka szavak problémáját, javítva a mélytanulási modellek teljesítményét. Az általános módszertan a tudásalapú tartalom általánosításának jól meghatározott elméleti modelljén és az absztraktív összefoglalók készítésére szolgáló mélytanulási előrejelzéseken alapul. A keretrendszer három kulcsfontosságú elemből áll: (i) előfeldolgozási feladat, (ii) gépi tanulási módszertan és (iii) utófeldolgozási feladat. Az előfeldolgozási feladat egy olyan tudásalapú megközelítés, amely ontológiai tudás erőforrásokon, szóérzékek egyértelműsítésén és nevezett entitás felismerésén alapul, valamint a tartalom általánosításán alapul, amely a hétköznapi szöveget általánosított formává alakítja. A figyelmes kódoló-dekóder architektúra mélytanulási modelljét, amely kiterjesztett, hogy lehetővé tegye a leküzdési és lefedettségi mechanizmust, valamint a megerősítő tanulás és transzformátor alapú architektúrák, a szöveg-összefoglaló párok általános verziójára képezik, megtanulva az összefoglalókat általános formában megjósolni. Az utófeldolgozási feladat ismereteket használ fel
Az előrejelzett összefoglaló általánosított változatát végleges, emberi olvasható formává alakítják. Három népszerű adatkészleten végzett kiterjedt kísérleti eljárás értékeli a javasolt keretrendszer kulcsfontosságú aspektusait, míg az elért eredmények ígéretes teljesítményt mutatnak, igazolva a javasolt megközelítés robusztusságát.</abstract_hu>
      <abstract_el>Σήμερα, η περισσότερη έρευνα που διεξάγεται στον τομέα της αφηρημένης σύνοψης κειμένου επικεντρώνεται μόνο σε νευρωνικά μοντέλα, χωρίς να εξετάζεται ο συνδυασμός τους με προσεγγίσεις βασισμένες στη γνώση που θα μπορούσαν να βελτιώσουν περαιτέρω την αποτελεσματικότητά τους. Προς αυτή την κατεύθυνση, η παρούσα εργασία παρουσιάζει ένα νέο πλαίσιο που συνδυάζει την αλληλουχία-σε-αλληλουχία σύνοψη κειμένου με βάση τη δομή και τις σημασιολογικές μεθοδολογίες. Το προτεινόμενο πλαίσιο είναι ικανό να αντιμετωπίσει το πρόβλημα των μη λεξιλογίων ή σπάνιων λέξεων, βελτιώνοντας την απόδοση των μοντέλων βαθιάς μάθησης. Η συνολική μεθοδολογία βασίζεται σε ένα καλά καθορισμένο θεωρητικό μοντέλο γενικοποίησης περιεχομένου βασισμένου στη γνώση και προβλέψεων βαθιάς μάθησης για τη δημιουργία αφηρημένων περιλήψεων. Το πλαίσιο αποτελείται από τρία βασικά στοιχεία: (i) μια εργασία προεπεξεργασίας, (ii) μια μεθοδολογία μηχανικής μάθησης και (iii) μια εργασία μετεπεξεργασίας. Η εργασία προεπεξεργασίας είναι μια προσέγγιση βασισμένη στη γνώση, βασισμένη σε οντολογικούς πόρους γνώσης, αποσαφήνιση λέξεων και αναγνώριση ονομαστικών οντοτήτων, μαζί με τη γενίκευση περιεχομένου, που μετατρέπει το συνηθισμένο κείμενο σε μια γενικευμένη μορφή. Ένα μοντέλο βαθιάς μάθησης με προσεκτική αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή, το οποίο επεκτείνεται για να επιτρέψει έναν μηχανισμό αντιμετώπισης και κάλυψης, καθώς και ενισχυτική μάθηση και αρχιτεκτονικές βασισμένες σε μετασχηματιστές, εκπαιδεύεται σε μια γενικευμένη έκδοση ζευγαριών κειμένου-σύνοψης, μαθαίνοντας να προβλέπουν περιλήψεις σε μια γενικευμένη μορφή. Η εργασία μετεπεξεργασίας χρησιμοποιεί γνώση
πόρους, ενσωμάτωση λέξεων, αποσαφήνιση λέξεων και heuristικοί αλγόριθμοι βασισμένοι σε μεθόδους ομοιότητας κειμένου προκειμένου να μετατραπεί η γενικευμένη έκδοση μιας προβλεπόμενης περίληψης σε μια τελική, αναγνώσιμη από τον άνθρωπο μορφή. Μια εκτεταμένη πειραματική διαδικασία σε τρία δημοφιλή σύνολα δεδομένων αξιολογεί βασικές πτυχές του προτεινόμενου πλαισίου, ενώ τα αποτελέσματα που προκύπτουν παρουσιάζουν ελπιδοφόρα απόδοση, επικυρώνοντας την ανθεκτικότητα της προτεινόμενης προσέγγισης.</abstract_el>
      <abstract_kk>Қазіргі абстракты, абстрактивті мәтін тұжырымдамасындағы зерттеулердің көпшілігі невралдық негізделген моделдеріне жалғыз көмектеседі, білім негізделген тұжырымдамасымен біріктіріп, олардың ефективті Осы бағытта, бұл жұмыс құрылғы мен семантикалық методологияларды бірге реттеу мен реттеу негіздеген мәтінді жинақтау ретінде жазылады. Келтірілген қоршауы сөздердің немесе сөздердің тығыс мәселелерін өзгертуге болады, терең оқыту үлгілерін жақсартуға болады. Барлық методология білім негіздеген мазмұның жалпы теоретикалық моделіне негізделген және абстрактивтік тұжырымдамасын құру үшін түсінікті оқыту үшін түсінікті түсінікті. Бұл қоршауы үш кілт элементінен құрылады: i) алдын- ала өңдеу тапсырмасы, ii) машиналық оқыту методологиясы және iii) өңдеу тапсырмасы. Алдын- ала өңдеу тапсырмасы - онтологиялық білім ресурстарына негізделген білім негізделген тәсілдік, сөздердің сезімі бұғаттауына негізделген, мәтінді жалпы пішімге аударады. Ақырымды кодер- декодер архитектурасының түсінікті оқыту үлгісі. Бұл көшірмелеу мен мәтін- тұжырымдамасының механизмін рұқсат ету үшін, оқыту мен түрлендіру архитектурасының жалпы нұсқасында, жалпы түрлендіру үшін оқыту үшін көтері Орындау кейін тапсырмасы білімдерді қолдану
ресурстар, сөздерді ендіру, сөздердің сезімін өзгерту және мәтін ұқсас тәсілдеріне негізделген хиуристік алгоритмдері, мәтін ұқсас тәсілдерінің жалпы нұсқасын соңғы, адамды оқу мүмкіндігіне Үш мәліметтік деректер бағдарламасындағы эксперименталдық процедурасы ұсынылған қоршау бағдарламасының негізгі аспекттерін бағалады. Алған нәтижелері ұсынылған әрекеттерді көрсетеді, ұсынылған тәсілдің құндыл</abstract_kk>
      <abstract_lt>Abstract Today, most research conducted in the field of abstract text summary focuses on neural-based models alone, not considering their combination with knowledge-based approaches that could further enhance their efficiency. Šiuo požiūriu šiame darbe pateikiama nauja sistema, kuria sujungiama iš eilės į eilę pagrįsta teksto santrauka su struktūra ir semantine metodika. Siūloma sistema gali spręsti ne žodyno ar retų žodžių problem ą ir pagerinti gilaus mokymosi modelių veiksmingumą. Bendroji metodika grindžiama gerai apibrėžtu teoriniu turinio generalizacijos, pagrįstos žiniomis, modeliu ir išsamaus mokymosi prognozėmis, kad būtų galima parengti abstraktines santraukas. Ši ą sistemą sudaro trys pagrindiniai elementai: i) išankstinio apdorojimo užduotis, ii) mašininio mokymosi metodika ir iii) išankstinio apdorojimo užduotis. Išankstinio apdorojimo užduotis – žiniomis pagrįstas metodas, grindžiamas ontologiniais žinių ištekliais, žodžių supratimo nesuderinimu ir pavadinimu subjekto pripažinimu kartu su turinio generalizacija, kuris paprastąjį tekstą paverčia bendra form a. Atidžiaus kodavimo ir dekoderių architektūros mokymosi model is, kuris išplėstas siekiant sudaryti galimybę įveikti ir aprėpti priemones, taip pat stiprinti mokymąsi ir transformatoriais grindžiamas architektūras, mokomas bendra teksto santraukų porų versija, mokomas prognozuoti santraukas bendra form a. Po perdirbimo atliekama užduotis naudoja žinias
ištekliai, žodžių įdėjimai, žodžių supratimo išaiškinimas ir heuristiniai algoritmai, pagrįsti teksto panašumo metodais, siekiant paversti bendrą numatomos santraukos versiją galutine, žmogui skaitoma form a. Išsami eksperimentinė trijų populiarių duomenų rinkinių procedūra vertina pagrindinius siūlomos sistemos aspektus, o gauti rezultatai rodo žadančius rezultatus ir patvirtina siūlomo metodo patikimumą.</abstract_lt>
      <abstract_ms>Hari ini, kebanyakan kajian yang dilakukan dalam bidang penghuraian teks abstraktif fokus pada model berdasarkan saraf sahaja, tanpa mempertimbangkan kombinasi mereka dengan pendekatan berdasarkan pengetahuan yang boleh meningkatkan efisiensi mereka lebih lanjut. Dalam arah ini, kerja ini menghasilkan kerangka baru yang menggabungkan penghuraian teks berasaskan saraf turutan ke turutan bersama dengan struktur dan metodologi berasaskan semantik. Bingkai cadangan yang direncanakan mampu menghadapi masalah luar-vocabulari atau perkataan langka, meningkatkan prestasi model belajar dalam. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries.  kerangka ini terdiri dari tiga unsur kunci: (i) tugas pra-proses, (ii) metodologi pembelajaran mesin, dan (iii) tugas pos-proses. Tugas pra-pemprosesan adalah pendekatan berdasarkan pengetahuan, berdasarkan sumber pengetahuan ontologi, penyelesaian perasaan perkataan, dan pengenalan entiti bernama, bersama dengan pengenalisan kandungan, yang mengubah teks biasa menjadi bentuk yang terkalahkan. Model pembelajaran dalam arkitektur pengekod-dekoder perhatian, yang dikembangkan untuk memungkinkan mekanisme pengendalian dan penyamaran, serta pembelajaran kuasa dan arkitektur berasaskan pengubah, dilatih pada versi umum pasangan teks-ringkasan, belajar untuk meramalkan ringkasan dalam bentuk umum. Tugas selepas pemprosesan menggunakan pengetahuan
sumber, penyambungan perkataan, penyelesaian perasaan perkataan, dan algoritma heuristik berdasarkan kaedah persamaan teks untuk mengubah versi umum ringkasan dijangka ke bentuk terakhir yang boleh dibaca oleh manusia. Prosedur percubaan ekstensif pada tiga set data populer menilai aspek utama kerangka yang direncanakan, sementara keputusan yang diperoleh menunjukkan prestasi yang berjanji, mengesahkan kepekatan pendekatan yang direncanakan.</abstract_ms>
      <abstract_ml>ഇപ്പോള്‍ അസ്ട്രാക്ട്രാക്ക് ചെയ്യുന്നതില്‍ ഏറ്റവും പ്രധാനപ്പെട്ട പദാവലിയുടെ കാലത്ത് നിര്‍മ്മിക്കപ്പെട്ട നെയൂറല്‍ അടിസ്ഥാനമായ മോഡലുകളില്‍ മാത് ഈ വഴിയില്‍, ഈ പ്രവര്‍ത്തിപ്പിക്കുന്ന ഒരു നോവല്‍ ഫ്രെയിമാര്‍ക്ക് കാണിക്കുന്നു. അതിന്റെ സെക്കന്‍സ്-മുതല്‍ സെക്കന്‍സ് അടിസ്ഥാനമായ നെയുറല്‍  പ്രൊദ്ദേശിക്കപ്പെട്ട ഫ്രെയിമെക്ക് വാക്കുകളുടെ പ്രശ്നത്തെക്കുറിച്ച് കൈകാര്യം ചെയ്യാന്‍ കഴിയും, ആഴത്തെ പഠിക്കുന മൊത്തം രീതിയില്‍ നിര്‍ണ്ണയിക്കപ്പെട്ട വിജ്ഞാനത്തിലുള്ള വസ്തുക്കളുടെ ജനറലേഷനും ആഴത്തെ പഠിപ്പിക്കുന്ന പ്രവചനങ്ങളും അടിസ്ഥാ ഫ്രെയിമെന്‍റ് മൂന്ന് മൂന്ന് മൂലകങ്ങളില്‍ ഉണ്ടാക്കിയിരിക്കുന്നു: (i) മുന്‍പ് പ്രവര്‍ത്തിപ്പിക്കുന്ന ജോലി, (ii) ഒരു യന്ത്ര പഠ മുമ്പ് പ്രവര്‍ത്തിപ്പിക്കുന്ന ജ്ഞാനത്തിന്റെ അടിസ്ഥാനത്തിലായ ഒരു പരിജ്ഞാനവും വാക്കിന്റെ വിഭവങ്ങള്‍ അടിസ്ഥാനത്തിലാണ്, വാക്കിന്റെ മനസ്സില്‍ വി ഒരു കോപ്പിങ്ങ് ചെയ്യുന്നതിനും കറയ്ക്കുന്നതിനും പ്രാവര്‍ത്തികമാക്കാനും ഒരു ആഴത്തില്‍ പഠിക്കുന്ന ഒരു കോഡെര്‍ ഡെക്കോഡേര്‍ ആര്‍ക്കിട്ടറിന്റെ മാതൃകയും, പഠിപ്പിക്കുന്നതിനും അടിസ്ഥാനമാക്ക The post-processing task utilizes knowledge
വിഭവങ്ങള്‍, വാക്കുകള്‍ അകത്തേക്ക് ചേര്‍ക്കുന്നത്, വാക്കിന്റെ മനസ്സിന്റെ അസംബന്ധം, വാക്കുകളുടെ ആല്‍ഗോരിത്രത്തിന്റെ മാര്‍ഗങ്ങളില്‍ അടിസ്ഥാനമാക്കിയ ആ മൂന്നു പ്രിയപ്പെട്ട ഡേറ്റാ സജ്ജീകരണങ്ങളില്‍ ഒരു വിശാലമായ പരീക്ഷണപ്രക്രിയയുണ്ട്, പ്രൊദ്ദേശിച്ച ഫ്രെയിമ്പിന്റെ താക്കോലുകള്‍ പരിശോധി</abstract_ml>
      <abstract_mk>Апстрактни денови, повеќето истражувања спроведени во областа на апстрактивната резултатација на текстот се фокусираат само на модели на нервна основа, без да се разгледува нивната комбинација со пристапи на основа на знаење кои би можеле понатаму да ја зголемат нивната ефи Во оваа насока, оваа работа претставува нова рамка која ја комбинира резултатацијата на текстот базиран на нерви од секвенца до секвенца заедно со структурата и семантичките методологии. Предложената рамка е способна да се справи со проблемот на надворешниот речник или ретките зборови, подобрувајќи ја изведбата на моделите на длабоко учење. Целокупната методологија се базира на добро дефиниран теоретски модел на генерализација на содржината базирана на знаење и предвидувања за длабоко учење за генерирање апстрактивни резултати. Рамката се состои од три клучни елементи: (i) задача за преобработување, (ii) методологија за машинско учење и (iii) задача за постобработување. Препроцесорската задача е пристап базиран на знаење, базиран на онтологичките ресурси на знаење, раздвојување на зборовите чувства и препознавање на именуваните ентитети, заедно со генерализацијата на содржината, кој го трансформира обичниот текст во генерализирана форма Модел на длабоко учење на внимателна архитектура на кодер-декодер, која е проширена за да овозможи механизам за справување и покривање, како и зајакнување на учењето и архитектурите базирани на трансформатори, е обучен на генерализирана верзија на парови текст-резултат, учејќи се да предвидат резултат Оваа задача користи знаење
ресурси, вложувања на зборови, раздвојување на зборовите, и хеористички алгоритми базирани на методи на сличност на текст со цел да ја трансформираат генерализираната верзија на предвидено резултат во финална, човечки читлива форма. Експерименталната процедура на три популарни податоци ги проценува клучните аспекти на предложената рамка, додека добиените резултати покажуваат ветувачки перформанси, потврдувајќи ја силноста на предложениот пристап.</abstract_mk>
      <abstract_mt>Illum il-ġurnata, il-biċċa l-kbira tar-riċerka mwettqa fil-qasam tas-sommarju tat-test astrattiv tiffoka fuq mudelli bbażati fuq in-newrali waħedhom, mingħajr ma tikkunsidra l-kombinazzjoni tagħhom ma’ approċċi bbażati fuq l-għarfien li jistgħu jkomplu jtejbu l-effiċjenza tagħhom. F’din id-direzzjoni, dan ix-xogħol jippreżenta qafas ġdid li jikkombina sommarju tat-test ibbażat fuq it-testi newrali minn sekwenza għal sekwenza flimkien ma’ metodoloġiji bbażati fuq l-istruttura u s-semantika. Il-qafas propost huwa kapaċi jindirizza l-problema ta’ kliem barra mill-vokabulari jew rari, u jtejjeb il-prestazzjoni tal-mudelli ta’ tagħlim profond. Il-metodoloġija globali hija bbażata fuq mudell teoretiku definit sew ta’ ġeneralizzazzjoni tal-kontenut ibbażat fuq l-għarfien u tbassir ta’ tagħlim profond għall-ġenerazzjoni ta’ sommarji astratti. The framework is composed of three key elements: (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task.  The pre-processing task is a knowledge-based approach, based on ontological knowledge resources, word sense disambiguation, and named entity recognition, along with content generalization, that transforms ordinary text into a generalized form.  Mudell ta’ tagħlim profond ta’ arkitettura attenta ta’ kodifikatur-dekoder, li huwa estiż biex jippermetti mekkaniżmu ta’ coping u kopertura, kif ukoll tagħlim rinfurzat u arkitetturi bbażati fuq trasformaturi, huwa mħarreġ fuq verżjoni ġeneralizzata ta’ pari ta’ sommarju tat-test, li jitgħallem jipprevedi sommarji f’form a ġeneralizzata. Il-kompitu ta’ wara l-ipproċessar juża l-għarfien
riżorsi, inkorporazzjonijiet tal-kliem, diżambiguazzjoni tas-sens tal-kliem, u algoritmi ħewristiċi bbażati fuq metodi ta’ similarità tat-test sabiex tittrasforma l-verżjoni ġeneralizzata ta’ sommarju mbassar f’form a finali, li tinqara mill-bniedem. Proċedura esperimentali estensiva fuq tliet settijiet ta’ dejta popolari tevalwa aspetti ewlenin tal-qafas propost, filwaqt li r-riżultati miksuba juru prestazzjoni promettenti, li tivvalida r-robustezza tal-approċċ propost.</abstract_mt>
      <abstract_pl>W dzisiejszych czasach większość badań prowadzonych w dziedzinie abstrakcyjnej streszczenia tekstu koncentruje się na modelach neuronowych, bez uwzględnienia ich połączenia z podejściami opartymi na wiedzy, które mogłyby jeszcze bardziej zwiększyć ich efektywność. W tym kierunku praca przedstawia nowe ramy łączące podsumowanie tekstu opartego na sekwencji sekwencji neuronowej wraz z metodologią struktury i semantyczną. Proponowane ramy są w stanie poradzić sobie z problemem poza słownictwem lub rzadkimi słowami, poprawiając wydajność modeli głębokiego uczenia się. Ogólna metodologia opiera się na dobrze zdefiniowanym modelu teoretycznym uogólniania treści opartych na wiedzy oraz prognozach głębokiego uczenia w celu generowania abstrakcyjnych streszczeń. Ramy składają się z trzech kluczowych elementów: (i) zadania wstępnego przetwarzania, (ii) metodologii uczenia maszynowego oraz (iii) zadania po przetwarzaniu. Zadaniem przetwarzania wstępnego jest podejście oparte na wiedzy, oparte na ontologicznych zasobach wiedzy, rozpoznawaniu sensu słowa i rozpoznawaniu nazwanych jednostek wraz z uogólnieniem treści, które przekształca zwykły tekst w uogólnioną formę. Model głębokiego uczenia uważnej architektury kodera-dekodera, który został rozbudowany w celu umożliwienia mechanizmu radzenia sobie i pokrycia, a także uczenia się wzmacniającego i architektur opartych na transformatorach, jest trenowany na uogólnionej wersji par tekstowo-podsumowujących, ucząc się przewidywać podsumowania w postaci uogólnionej. Zadanie po przetwarzaniu wykorzystuje wiedzę
Zasoby, osadzenia słów, dyscyplinacja sensu słowa oraz algorytmy heurystyczne oparte na metodach podobieństwa tekstowego w celu przekształcenia uogólnionej wersji przewidywanego podsumowania w ostateczną, czytelną dla człowieka formę. Obszerna procedura eksperymentalna na trzech popularnych zbiorach danych ocenia kluczowe aspekty proponowanego frameworku, natomiast uzyskane wyniki wykazują obiecującą skuteczność, potwierdzając solidność proponowanego podejścia.</abstract_pl>
      <abstract_ro>În zilele noastre, majoritatea cercetărilor efectuate în domeniul rezumatului abstractiv al textului se concentrează numai pe modele bazate pe neural, fără a lua în considerare combinația lor cu abordări bazate pe cunoaștere care ar putea spori și mai mult eficiența lor. În această direcție, această lucrare prezintă un cadru nou care combină rezumarea textului neural secvență-la-secvență împreună cu structura și metodologiile semantice. Cadrul propus este capabil să abordeze problema cuvintelor în afara vocabularului sau a cuvintelor rare, îmbunătățind performanța modelelor de învățare profundă. Metodologia generală se bazează pe un model teoretic bine definit de generalizare a conținutului bazat pe cunoaștere și predicții de învățare profundă pentru generarea rezumatelor abstractive. Cadrul este compus din trei elemente cheie: (i) o sarcină de pre-procesare, (ii) o metodologie de învățare automată și (iii) o sarcină de post-procesare. Sarcina de pre-procesare este o abordare bazată pe cunoaștere, bazată pe resurse de cunoaștere ontologică, dezambiguizarea sensului cuvântului și recunoașterea entităților denumite, împreună cu generalizarea conținutului, care transformă textul obișnuit într-o formă generalizată. Un model de învățare profundă a arhitecturii encoder-decoder atente, care este extins pentru a permite un mecanism de coping și acoperire, precum și învățare de armare și arhitecturi bazate pe transformator, este instruit pe o versiune generalizată a perechilor text-sumar, învățând să prezică rezumatele într-o formă generalizată. Sarcina de post-procesare utilizează cunoștințe
Resurse, încorporări de cuvinte, dezambiguizarea sensului cuvântului și algoritmi euristici bazați pe metode de similitudine a textului pentru a transforma versiunea generalizată a unui rezumat anticipat într-o formă finală, lizibilă de om. O procedură experimentală amplă pe trei seturi de date populare evaluează aspectele cheie ale cadrului propus, în timp ce rezultatele obținute prezintă performanțe promițătoare, validând robustețea abordării propuse.</abstract_ro>
      <abstract_so>Maalmahaas, wax badan oo baaritaanka la sameeyay beerta qoraalka waxyaabaha la’aanta ah ayaa ku focus ah modelalka neurada oo keliya, iyadoon ka fiirsanaynin inay ku xiriiraan qaababka aqoonta ee awoodkooda sii kordhin karo. Xaggan, shuqulkaasu wuxuu soo bandhigaa saxda, kaas oo ku soo ururiya qoraal qoraal ah oo ku qoran xilli-ilaa-xilliga neurada oo ku qoran dhismaha iyo qaababka semantika. Qoraalka la soo jeeday wuxuu awoodaa in uu ka macaamilo karo dhibaatada hadallada aan qoraalka ahayn ama hadallada gaaban, inuu horumariyo tababarka muusikada waxbarashada moolka dheer. Iskuulka dhamaanka waxaa lagu saleeyaa tusaale aad u yaqaan tioretik oo ku qoran qoraalka waxyaabaha aqoonta ku saleysan oo la soo hormariyo horumarinta waxbarashada mool dheer oo la soo saaro xiliga diidmada ah. Qoraalka waxaa lagu sameeyaa saddex element oo muhiim ah: (i) shaqo ka hor baaraandegista, (ii) qaababka waxbarashada machine, iyo (iii) shaqo ka dib baaraandegista. Shaqada horay u baaraandegista waa qaab aqoonta lagu saleeyo asalka aqoonta aqoonta, kala baaraandegista hadalka, aqoonsashada aqoonta, iyo waxyaabaha la magacaabay, kaas oo ku beddelinaya qoraalka caadiga ah oo u beddelaya foom generalis. Tusaale waxbarasho dheer oo ah dhismaha qodeynta, kaas oo loo ballaadhiyay inuu awoodo koordinta iyo daboolidda, sidoo kale in lagu kordhiyo dhismaha barashada iyo beddelinta, waxaa lagu baraa qoraal la qoray labada noocyo oo qoraal ah, taasoo lagu barto in lagu hor dhigo qoraalka lagu qoray. Shaqada ka baaraandegista ayaa isticmaalaya aqoonta
Fursadaha, qeybaha hadalka, kala soocsiga maanka, iyo qoraalka heuristiga oo ku saleysan qoraalka isku mid ah si uu ugu beddelo warqada la soo hormariyey oo ugu horrayay qoraalka ugu dambeeya oo dadka akhrisan. Shahaadada baaritaanka oo ballaadhan oo ku qoran saddexda data oo popular ah ayaa qiimeynaya dhinacyada ugu muhiimsan ee laga soo jeeday frameerka, marka laga soo helayna waxay muujiyaan muuqashada ballan ah, si loo xaqiijiyo dharka qaababka lagu soo jeedo.</abstract_so>
      <abstract_si>අවස්ථාවයි, අවස්ථාවයි, බොහෝම පරීක්ෂණය කරලා තියෙන්නේ අවස්ථාවක් පැත්තක් සුම්පර්ණයේ ප්‍රදේශයේ සුම්පර්ණය ප්‍රදේශයෙන් නිර්ම මේ පැත්තේදී, මේ වැඩ ප්‍රදේශයක් ප්‍රදේශයක් තියෙනවා ක්‍රියාත්මක ප්‍රදේශයක් සම්බන්ධ කරනවා ක්‍රියාත්මක ප්‍රදේශයක් සමග සං ප්‍රශ්නයක් ප්‍රශ්නයක් වෙන්න පුළුවන් විදිහට ප්‍රශ්නයක් නැති වචන වචන වගේ ප්‍රශ්නයක් වෙන්න, ගොඩක් ඉගෙන ගන සම්පූර්ණ විද්‍යාවය හොඳ විශ්වාසිත විද්‍යාත්මක සාමාන්‍ය සාමාන්‍ය විද්‍යාපනය සහ ගොඩක් ඉගෙන ගන්න ප්‍රශ්නයක් නි ප්‍රවේශය තුනක් යතුරු අවශ්‍ය තුනක් නිර්මාණය කරලා තියෙනවා: i) ප්‍රවේශනයක් ප්‍රවේශනයක්, (i) පරීක්ෂණයක් ප්‍රවේශනයක් (machine The pre-processing job is a Known-based approach, based on ontology Known Systems, word sensation disombguation, and Named Unity Known, accompanied with the contingent General lization, that transcends the standard text to a generic form. A depth learning Model of Attensive Encoder-decoder Architectura, that is breed to make a coping and Coveage mekanizer, as well as consolidation learnt and changeover-based Architecturas, is Trained on a genelized Version of text-summy pares, learnt to forecast summits in a genelized form. පස්සේ ප්‍රක්‍රියාස කරණාව දන්නවක් භාවිත කරනවා
සම්බන්ධතාවය, වචන සම්බන්ධතාවය, වචන සම්බන්ධතාවය, හෙයුරිස්ටික ඇල්ගෝරිත්මය, පාළුවන් සම්බන්ධතාවය විදියට ආධාරිත විදියට පරික ප්‍රශ්නයක් පරීක්ෂණයක් තුනක් ප්‍රශ්නයක් තියෙන්නේ ප්‍රශ්නයක් තියෙන්නේ ප්‍රශ්නයක් ප්‍රශ්නයක් ප්‍රශ්නයක් තියෙන්න</abstract_si>
      <abstract_sv>Abstract Nuförtiden fokuserar den mesta forskningen inom området abstraktiv textsammanfattning enbart på neuralbaserade modeller, utan att överväga deras kombination med kunskapsbaserade tillvägagångssätt som ytterligare skulle kunna förbättra deras effektivitet. I den riktningen presenterar detta arbete ett nytt ramverk som kombinerar sekvens-till-sekvens neuralbaserad textsammanfattning tillsammans med struktur och semantiska metoder. Den föreslagna ramen kan hantera problemet med outvokabulära eller sällsynta ord, vilket förbättrar djupinlärningsmodellernas prestanda. Den övergripande metoden bygger på en väl definierad teoretisk modell av kunskapsbaserad innehållsgeneralisering och djupinlärningsförutsägelser för att generera abstrakta sammanfattningar. Ramverket består av tre nyckelelement: i) en förbehandling, ii) en maskininlärningsmetod och iii) en efterbehandling. Förbehandlingsuppgiften är ett kunskapsbaserat tillvägagångssätt, baserat på ontologiska kunskapsresurser, ordsinnesdeklaration och namngiven entitetsigenkänning, tillsammans med innehållsgeneralisering, som omvandlar vanlig text till en generaliserad form. En djupinlärningsmodell av uppmärksam encoder-avkodararkitektur, som utökas för att möjliggöra en coping- och täckningsmekanism, samt förstärkningsinlärning och transformatorbaserade arkitekturer, utbildas på en generaliserad version av text-sammanfattning par, lära sig att förutsäga sammanfattningar i en generaliserad form. Efterbehandlingsuppgiften utnyttjar kunskap
För att omvandla den generella versionen av en förutsagd sammanfattning till en slutlig, mänsklig läsbar form. Ett omfattande experimentförfarande på tre populära datauppsättningar utvärderar centrala aspekter av det föreslagna ramverket, medan de erhållna resultaten uppvisar lovande prestanda, vilket bekräftar robustheten i det föreslagna tillvägagångssättet.</abstract_sv>
      <abstract_mn>Харин одоогийн абстракт, ихэнх судалгаа abstractive text жинхэнэ хэмжээсүүд нь мэдлэг суурилсан арга барилгуудтай холбоотой, тэдний үр дүнг нэмэгдүүлж чадна. Энэ хэсэгт, энэ ажил дарааллаар дарааллаар дарааллаар дарааллаар дарааллаар суурилсан мэдрэлийн хэмжээсүүдийг бүтэц болон семантик суурилсан методологийг нэгтгэдэг шинэ хэлбэрийг харуулдаг. Шинэ санал болгон суралцах загварын үйл ажиллагааг сайжруулах боломжтой. Ихэнх методологи нь мэдлэг дээр суурилсан материалуудын ерөнхийлөгч, гүн гүнзгий суралцах тодорхойлолтуудын теоретик загвар дээр суурилсан. Фреймер нь гурван түлхүүр элементүүдийн бүтэц: i) урд үйлдвэрлэлтийн ажил, ii) машин суралцах методологи, iii) дараа үйлдвэрлэлтийн ажил. Өмнөх үйл ажиллагаа нь мэдлэг дээр суурилсан арга юм. Онтологийн мэдлэг боловсролын баялаг, үг мэдрэмжтэй байдал, нэрлэгдсэн бүтээлүүдийн хүлээн зөвшөөрөл, бүтээлүүдийн ерөнхийлөгч байдалтай хамт энгийн текст ерөнхийлөгч хэлбэр Харин сонирхолтой коддогч архитектурын гүн гүнзгий суралцах загвар, хуваалцах механизм болон суралцах, өөрчлөгч суралцах, өөрчлөгч суралцах архитектуруудын ерөнхийлөгчийн хувилбар дээр суралцагдаж байна. Дараагийн үйл ажиллагаа мэдлэг ашиглан
Байгаль, үг нэвтрүүлэх, үг мэдрэмжгүй байдал, хэлбэрийн алгоритм, мөн хэлбэрийн тэнцүү арга дээр суурилсан хэлбэрүүдийг төгсгөл, хүний унших боломжтой хэлбэртэй хувилбарыг өөрчлөхийн тулд. Гурван хүн төрөлхтний мэдээллийн багц дээрх шинэ туршилтын процедур санал өгсөн хэлбэрийн чухал асуудлыг үнэлдэг. Гэхдээ олсон үр дүн нь амлалтай үйл ажиллагааг харуулж, санал өгсөн арга барилгын чадварыг ба</abstract_mn>
      <abstract_ta>இந்த நேரத்தில் செயல்படுத்தப்பட்ட புலத்தில் பெரும்பாலான ஆராய்ச்சி சுருக்கம் செய்யப்பட்டது, புதிய மாதிரிகளை மட்டுமே கவனம் செலுத்துகிறது, அறிவு அடிப்பட In this direction, this work presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies.  பரிந்துரைக்கப்பட்ட சட்டத்தில் சொல்லத்திலிருந்து அல்லது சிறிய வார்த்தைகளின் பிரச்சினையைக் கொண்டு பாதிக்க முடியும்,  மொத்த முறைமையில் அறிவிப்பு அடிப்படையில் உள்ளடக்கங்களை உருவாக்குதல் மற்றும் ஆழமான கற்றுக்கொள்ள முன்னோட்டங்களை உருவாக்குவதற்கான சட்டத்தின் மூன்று முக்கிய உறுப்புகளில் உருவாக்கப்பட்டுள்ளது: (i) முன் செயல்படுத்தும் செயல் முன் செயல்படுத்தல் செயல் ஒரு அறிவு அடிப்படையான செயல்பாடு, அடிப்படையிலான நொடியல் அறிவு மூலம், வார்த்தை உணர்வு பிரிவு, பெயரிடப்பட்ட பொருள் குறிப்பிடு, ப A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form.  பின்செயல்படுத்தல் செயல் அறிவை பயன்படுத்துகிறது
மூலங்கள், வார்த்தை பொருத்துதல், வார்த்தை உணர்வு பிரிவுகள் மற்றும் உரை ஒத்த முறைகளை அடிப்படையில் மாற்றுவதற்கு, முன்னோக்கப்பட்ட சுருக்கம், மனித படிக்க ம மூன்று பெரிய தகவல் அமைப்புகளில் ஒரு விரிவான சோதனை செயல்பாடு முன்நிர்ணயிக்கப்பட்ட சட்டத்தின் முக்கிய விளைவுகளை மதிப்பிடுகிறது, பெற்றுள்</abstract_ta>
      <abstract_ur>اکثر تحقیقات جو آب تراکیٹی ٹیکسٹ کے مکان میں کیا گیا ہے صرف نئورل بنیادی موڈل پر تمرکز کرتی ہے، بغیر علم بنیادی طریقوں کے ساتھ ان کی ترکیب کی توقع کرتی ہے جو ان کے کامیابی میں اضافہ کرسکتی ہے. اس طریقے میں، یہ کام ایک نئی فرم پیش کرتا ہے جو سطح سے اورال بنیاد رکھے ہوئے پیغام کی تعریف کے ساتھ اور سیمانٹی بنیاد رکھے ہوئے مڈولوژوں کے ساتھ جمع کرتا ہے. پیشنهاد کی فرمود بات یا نادر کلمات کے مسئلہ سے بحث کرنے کے قابل ہے، اور عمیق سیکھنے کی مدل کی عمدت کو بہتر کر سکتا ہے. یہ سب طریقے معلوم ہوتے ہیں کہ علم کی بنیاد رکھی ہوئی منصوبات کی عمومی تعلیم اور عمیق تعلیم کی پیش بینی کی وجہ سے بہتر تعریف کی نظریات کی مدل پر ہے۔ چوکاٹ تین کلی عناصر سے پیدا کیا گیا ہے: i) ایک پیش پردازی کا کام، ii) ایک ماشین سیکھنے کا مطالعہ، اور iii) ایک پوسٹ پردازی کا کام۔ پیش پردازی کا کام ایک علم کی بنیادی طریقہ ہے، اس طریقہ پر متولوژیکی علم کے منبع پر بنیاد ہے، کلمات کا احساس غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر ایک عمدہ سیکھنے کی موڈل ہے جو متوجہ Encoder-Decoder معماری ہے، جو ایک کاپینگ اور کاوٹ مکانیزم کو فعال کرنے کے لئے پھیلائی جاتی ہے، اور اس کے ساتھ زیادہ سیکھنے اور تبدیل کرنے کی معماری ہے، ایک متوجہ جڑوں کی جرائم کی جرائم پر آموزش کی جاتی ہے، جرائم فرم میں سراسر کی پیش بینی کرنے کی تعلیم کی جاتی پوسٹ پرسس کی تابع علم کا استعمال کرتا ہے
سراسر، لفظ انڈینگ، لفظ سمجھ غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر تین محبوب ڈاٹ سٹ پر ایک بڑی آزمائش پردازی پیشنهاد فرمود کی کلی اثرات کا ارزش کرتا ہے، حالانکہ پالیا گیا نتیجے وعدہ کے کامیابی کو دکھاتے ہیں، اور پیشنهاد کی طریقے کی طاقت کا ارزش کرتا ہے.</abstract_ur>
      <abstract_sr>U današnje vrijeme, većina istraživanja provedena u oblasti sažetanja abstraktivnog teksta fokusira se na neuralne modele sami, bez obzira na njihovu kombinaciju sa pristupima na znanju koje bi mogle da povećaju njihovu efikasnost. U ovom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno sa strukturom i semantičkim metodama. Predloženi okvir je sposoban da riješi problem izvan rečenika ili rijetkih reči, poboljšava učenje dubokih modela učenja. Обща методологија је базирана на добро определеном теоретичном моделу генерализације sadržaja базираног на знањима и прогнозирања глубоких учења за производство абстрактивних резюме. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja mašine, i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na znanju, baziran na ontološkim resursima znanja, disambiguaciji riječi i priznanju entiteta, zajedno sa generalizacijom sadržaja, koji transformiše obični tekst u generalizovani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji sažetnih parova teksta, učenje da predvidi sažetke u generalizovanom obliku. Poslije obrade zadatak koristi znanje
resursi, uključenje riječi, disambiguacija riječi, i heuristički algoritmi bazirani na metodi sličnosti teksta kako bi transformisali generaliziranu verziju predviđenog sažetka u konačni, ljudski čitljivi oblik. Ogromna eksperimentalna procedura na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobijeni rezultati pokazuju obećavajuću funkciju, potvrđujući robotu predloženog pristupa.</abstract_sr>
      <abstract_no>Abstrakte dagar, dei fleste forskningar gjennomførte i feltet abstraktive tekstsamansering fokuserer på enkelte neuralbaserte modeller utan å tenke på sine kombinasjon med kunnskapsbaserte tilnærmingar som kan forbetra effektiviteten. I denne retninga viser dette arbeidet eit nytt rammeverk som kombinerer sammendraging av tekst med sekvens-til-sekvens saman med strukturbaserte og semantiske metodar. Det foreslåde rammeverket er i stand til å handtera problemet med utrykke ordet eller sjeldre ord, forbetra utviklinga av dei dype læringsmodelane. Den generelle metodologien er basert på ein godt definert teoretisk modell for generellisering av kunnskapsbasert innhald og dype læringsforensingar for å laga abstraktive samandrag. Rammeverket er lagt av tre nøkkelelementa: i) ei førehandsamingsoppgåve, ii) ein maskinelæringsmetodologi, og iii) ei post- handsamingsoppgåve. Forhandteringsoppgåva er ein kunnskapsbasert tilnærming, basert på ontologiske kunnskapsressursar, disambiguasjon av ordfølelse, og gjenkjenning av namnet entitet, saman med innhaldet generellisering, som transformerer vanleg tekst til eit generelt form. Ein dyp læringsmodell av attentive kodingsdekoderarkitektur, som er utvida for å slå på ein koplingsmekanismekanismen og dekningsmekanismen, og styrkering av læring og transformeringsbasert arkitektur, er trent på ein generelt versjon av tekstsamandringspar, læring for å forventa samandringar i eit generelt form. Oppgåva etter prosessering brukar kunnskap
ressursar, ordinnbygging, ord-sens-disambiguasjon, og heuristiske algoritme basert på tekstliknande metodar for å transformera den generelle versjonen av eit forventa sammendrag til ein sist, menneskelig lesbar form. Eit utvida eksperimentelt prosedyr på tre populære datasett evaluerer nøkkelaspektar av den foreslåde rammeverket, mens dei oppnådd resultatene viser promiserende utviklingar, og kan validera kraftigheten av den foreslåde tilnærminga.</abstract_no>
      <abstract_vi>Bản tóm tắt hiện nay, hầu hết các nghiên cứu thực hiện trong lĩnh vực tổng kết văn bản trừu tượng tập trung vào các mô hình dựa trên thần kinh, mà không cân nhắc sự kết hợp của chúng với các phương pháp dựa trên kiến thức có thể tăng hiệu quả hơn. Trong hướng này, dự án này mang đến một bộ khung mới kết hợp các bản tóm tắt dựa trên chuỗi-tới-số dựa trên-thần kinh cùng với cấu trúc và các phương pháp theo ngữ pháp. Cơ chế được đề xuất có khả năng giải quyết vấn đề về ngôn ngữ ngoài giới hạn, hay những từ hiếm, cải thiện khả năng của các mô hình học sâu. Phương pháp tổng hợp dựa trên một mô hình lý thuyết xác định rõ ràng về tổng hợp nội dung dựa trên kiến thức và dự đoán về học sâu để tạo ra các bản tóm tắt trừu tượng. The frame is composed of three main elements: i) a pre-treatment task, ii) a máy leaving methods, and III a posttreatment task. The pre-treatment task là một phương pháp dựa trên kiến thức, based on ontological knowledge Resources, Từ sensiting dismbiation, and named Enteprise, cùng với phần nội dung rộng, that transforms common text into the general form. Một mô hình học sâu về kiến trúc có mã hóa dữ dội có chú ý, được mở rộng để mở rộng khả năng giải mã, cũng như tăng cường học tập và kiến trúc dựa vào máy biến hình, được rèn luyện trên một phiên bản tổng hợp văn bản, học dự đoán các bản tổng quát. Nhiệm vụ nối tiếp lợi dụng kiến thức
nguồn lực, sự tác ghép nối từ, phân dạng cảm nhận từ, và thuật to án thần kinh dựa trên phương pháp tương tự văn bản, để biến phiên bản phổ biến của một bản tổng hợp được dự đoán thành hình thức đọc cuối cùng. Một thủ tục thử nghiệm rộng rãi trên ba bộ dữ liệu phổ biến đánh giá các khía cạnh chủ chốt của bộ khung đã đề nghị, trong khi kết quả có triển vọng tốt, xác nhận độ bền vững của phương pháp được đề nghị.</abstract_vi>
      <abstract_uz>Bugun hozirda ko'pchilik o'rganish matn muhim sohalarida ishga tushirilgan o'rganishlar faqat neyron asosida modellarni o'rganish mumkin. Ularning ilmiy asosiy usullar bilan birlashtirish mumkin, ularning effektligini oshirish mumkin. Ushbu oynada, bu ishni qoʻllash va semantik asosida qoʻllanilgan matn muhitizasini bir nechta- to- seksirlik darajasi bilan birlashtirish mumkin. Aniqlanadigan freym soʻzlar yoki chegara so'zlarning muammolarini boshqarish mumkin, eng yuqori o'rganish modellarini bajarish mumkin. Umumiy metodologi, ilmiy tarkibi yaratish va eng o'rganish muvaffaqiyatlarini yaratish uchun yaxshi aniqlangan teoretikal modeliga asoslangan. Freym uchta kalit elementlaridan yaratiladi: (i) pre-processing vazifa, (ii) mashinani o'rganish usuli va (iii) keyingi vazifa. Birinchi harakat vazifa, ontologik илм манзилларi asosida, so'z ma'lumotni qismlashtirish va ma'lumotni tasdiqlash va mavzu yaratish bilan ishlatish mumkin, bu oddiy matnni umumiy shaklni o'zgartiradi. Name Keyingi vazifa
@ info: whatsthis Name</abstract_uz>
      <abstract_bg>В днешно време повечето изследвания, проведени в областта на абстрактното обобщаване на текста, се фокусират само върху невронно-базираните модели, без да се има предвид тяхната комбинация с базирани на знание подходи, които биха могли допълнително да повишат тяхната ефективност. В тази посока тази работа представя нова рамка, която съчетава последователност към последователност невронно базирана текстова обобщаване заедно със структурно и семантично базирани методологии. Предложената рамка е в състояние да се справи с проблема с нелексиката или редките думи, подобрявайки ефективността на моделите за дълбоко обучение. Цялостната методология се основава на добре дефиниран теоретичен модел на обобщаване на съдържанието, основано на знанието, и прогнози за дълбоко обучение за генериране на абстрактни резюмета. Рамката се състои от три ключови елемента: i) задача за предварителна обработка, ii) методология за машинно обучение и iii) задача за следобработка. Задачата за предварителна обработка е базиран на знанието подход, базиран на онтологични ресурси на знанието, разграничаване на смисъла на думата и разпознаване на наименовани обекти, заедно с обобщаване на съдържанието, което превръща обикновения текст в обобщена форма. Модел на дълбоко обучение на внимателна архитектура на кодер-декодер, който е разширен, за да позволи механизъм за справяне и покриване, както и укрепване на обучението и трансформаторната архитектура, се обучава на обобщена версия на двойки текст-резюме, научавайки се да предвижда резюмета в обобщена форма. Задачата за последваща обработка използва знания
ресурси, вграждане на думи, разграничаване на смисъла на думата и евристични алгоритми, базирани на методи за сходство на текста, за да се трансформира обобщената версия на предсказаното резюме в окончателна, четлива за човека форма. Обширна експериментална процедура върху три популярни набора от данни оценява ключовите аспекти на предложената рамка, докато получените резултати показват обещаващи резултати, валидиращи здравината на предложения подход.</abstract_bg>
      <abstract_hr>U današnje vrijeme, većina istraživanja provedena u području sažetanja abstraktivnog teksta fokusirala se na samo neurološke modele, bez obzira na njihovu kombinaciju s pristupima na temelju znanja koje bi mogle povećati njihovu učinkovitost. U tom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno s strukturom i semantičkim metodama. Predloženi okvir je sposoban rješavati problem izvan riječi ili rijetkih riječi, poboljšati učinkovitost dubokih modela učenja. Općenita metodika temeljena je na dobro definiranom teorijskom modelu generalizacije sadržaja na znanju i predviđanja dubokog učenja za stvaranje abstraktivnih sažetaka. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja strojeva i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na temelju znanja, temeljen na ontološkim resursima znanja, disambiguaciji riječi osjećaja i priznanju imena entiteta, zajedno s generalizacijom sadržaja, koji transformira obični tekst u generalizirani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji sažetnih parova teksta, učenje predvidjeti sažetke u generaliziranom obliku. Poslije obrade zadatak koristi znanje
resursi, uključuvanje riječi, disambiguacija riječi, i heuristički algoritmi na temelju metoda sličnosti tekstu kako bi se transformirala generalizirana verzija predviđenog sažetka u konačni, ljudski čitljivi oblik. Veliki eksperimentalni postupak na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobiveni rezultati pokazuju obećavajuću učinkovitost, potvrđujući robotu predloženog pristupa.</abstract_hr>
      <abstract_da>I dag fokuserer de fleste forskning inden for abstraktiv tekst resuméering alene på neurale-baserede modeller, uden at overveje deres kombination med videnbaserede tilgange, der yderligere kan forbedre deres effektivitet. I denne retning præsenterer dette arbejde en ny ramme, der kombinerer sekvens-til-sekvens neural-baseret tekst sammenfatning sammen med struktur og semantisk baserede metoder. Den foreslåede ramme er i stand til at håndtere problemet med uden for ordforråd eller sjældne ord og forbedre effektiviteten af deep learning-modellerne. Den overordnede metode er baseret på en veldefineret teoretisk model for videnbaseret indhold generalisering og dyb læring forudsigelser til generering af abstrakte resuméer. Rammen består af tre nøgleelementer: i) en forberedelsesopgave, ii) en maskinlæringsmetode og iii) en efterbehandlingsopgave. Forbearbejdningsopgaven er en videnbaseret tilgang, baseret på ontologiske videnressourcer, ordsanseforståelse og navngivet entitetsgenkendelse, sammen med indholdsgeneralisering, der omdanner almindelig tekst til en generaliseret form. En dyb læringsmodel af opmærksom encoder-dekoder arkitektur, som er udvidet til at muliggøre en coping- og dækningsmekanisme, samt forstærkning læring og transformer-baserede arkitekturer, er trænet på en generaliseret version af tekst-resumé par, der lærer at forudsige resuméer i en generaliseret form. Efterbehandlingsopgaven udnytter viden
Ressourcer, ordindlejringer, ordforståelse og heuristiske algoritmer baseret på tekstligningsmetoder for at omdanne den generaliserede version af et forudsiget resumé til en endelig, menneskelæsbar form. En omfattende eksperimentel procedure på tre populære datasæt evaluerer centrale aspekter af den foreslåede ramme, mens de opnåede resultater viser lovende resultater, hvilket validerer robustheden af den foreslåede tilgang.</abstract_da>
      <abstract_nl>Abstract Tegenwoordig concentreert het meeste onderzoek op het gebied van abstracte tekstsamenvatting zich alleen op neurale modellen, zonder rekening te houden met hun combinatie met kennisgebaseerde benaderingen die hun efficiëntie verder zouden kunnen verbeteren. In deze richting presenteert dit werk een nieuw raamwerk dat sequentie-to-sequence neural-based tekst samenvatting combineert samen met structuur en semantisch gebaseerde methodologieën. Het voorgestelde kader is in staat om het probleem van niet-woordenschat of zeldzame woorden aan te pakken, waardoor de prestaties van de deep learning modellen worden verbeterd. De algemene methodologie is gebaseerd op een goed gedefinieerd theoretisch model van kennisgebaseerde contentgeneralisatie en deep learning voorspellingen voor het genereren van abstracte samenvattingen. Het raamwerk bestaat uit drie kernelementen: (i) een pre-processing taak, (ii) een machine learning methodologie en (iii) een post-processing taak. De pre-processing taak is een op kennis gebaseerde benadering, gebaseerd op ontologische kennisbronnen, woordzinnendiambiguatie en naamsbekendheid, samen met contentgeneralisatie, die gewone tekst transformeert in een algemene vorm. Een deep learning model van attente encoder-decoder architectuur, dat is uitgebreid om een coping- en dekkingsmechanisme mogelijk te maken, evenals versterking learning en transformator-gebaseerde architecturen, wordt getraind op een algemene versie van tekst-samenvattingsparen, waarbij wordt geleerd samenvattingen in een algemene vorm te voorspellen. De post-processing taak maakt gebruik van kennis
De algemene versie van een voorspelde samenvatting wordt omgezet in een definitieve, menselijke leesbare vorm. Een uitgebreide experimentele procedure op drie populaire datasets evalueert belangrijke aspecten van het voorgestelde framework, terwijl de verkregen resultaten veelbelovende prestaties vertonen en de robuustheid van de voorgestelde aanpak valideren.</abstract_nl>
      <abstract_de>Abstract Heutzutage konzentriert sich die meiste Forschung im Bereich der abstraktiven Textzusammenfassung auf neuronale Modelle allein, ohne deren Kombination mit wissensbasierten Ansätzen zu berücksichtigen, die ihre Effizienz weiter steigern könnten. In dieser Richtung präsentiert diese Arbeit ein neuartiges Framework, das sequenzbasierte neuronale Textzusammenfassungen mit Struktur- und semantisch-basierten Methoden kombiniert. Der vorgeschlagene Rahmen ist in der Lage, das Problem von Fremdwörtern oder seltenen Wörtern zu lösen und die Leistung der Deep Learning Modelle zu verbessern. Die Methodik basiert auf einem klar definierten theoretischen Modell der wissensbasierten Inhaltsverallgemeinerung und Deep Learning Vorhersagen zur Generierung abstrakter Zusammenfassungen. Das Framework besteht aus drei Schlüsselelementen: (i) einer Vorverarbeitungsaufgabe, (ii) einer Methodik des maschinellen Lernens und (iii) einer Nachverarbeitungsaufgabe. Die Vorbearbeitungsaufgabe ist ein wissensbasierter Ansatz, der auf ontologischen Wissensressourcen, Wortsinn-Begriffsklärung und Namenserkennung sowie Inhaltsverallgemeinerung basiert, der gewöhnlichen Text in eine verallgemeinerte Form verwandelt. Ein Deep-Learning-Modell der aufmerksamen Encoder-Decoder-Architektur, das erweitert wurde, um einen Coping- und Coverage-Mechanismus sowie Verstärkungslernen und transformatorbasierte Architekturen zu ermöglichen, wird auf einer verallgemeinerten Version von Text-Summary-Paaren trainiert und lernt Zusammenfassungen in verallgemeinerter Form vorherzusagen. Die Nachbearbeitungsaufgabe nutzt Wissen
Um die verallgemeinerte Version einer vorhergesagten Zusammenfassung in eine endgültige, menschenlesbare Form zu verwandeln, werden Ressourcen, Worteinbettungen, Wortsinn-Disambiguation und heuristische Algorithmen basierend auf Textähnlichkeitsmethoden verwendet. Ein umfangreiches experimentelles Verfahren an drei populären Datensätzen evaluiert Schlüsselaspekte des vorgeschlagenen Frameworks, während die erhaltenen Ergebnisse vielversprechende Leistung aufweisen und die Robustheit des vorgeschlagenen Ansatzes bestätigen.</abstract_de>
      <abstract_id>Abstrakt Saat ini, kebanyakan penelitian yang dilakukan dalam bidang penelitian teks abstraktif fokus pada model berbasis saraf sendirian, tanpa mempertimbangkan kombinasi mereka dengan pendekatan berbasis pengetahuan yang dapat meningkatkan lebih lanjut efisiensi mereka. Dalam arah ini, pekerjaan ini mempersembahkan cadangan baru yang menggabungkan persendirian-ke-persendirian teks berasaskan saraf bersama struktur dan metodologi berasaskan semantis. Cadangan yang diusulkan mampu menghadapi masalah dari luar vokbulari atau kata langka, meningkatkan prestasi model belajar dalam. Metodologi umum berdasarkan model teori yang terdefinisikan dengan baik dari generalisasi konten berdasarkan pengetahuan dan prediksi belajar dalam untuk menghasilkan ringkasan abstraktif. Rambutnya terdiri dari tiga elemen kunci: (i) tugas pra-proses, (ii) metodologi belajar mesin, dan (iii) tugas pos-proses. Tugas pra-proyeksi adalah pendekatan berdasarkan pengetahuan, berdasarkan sumber pengetahuan ontologi, penyelesaian perasaan kata, dan pengakuan entitas bernama, bersama dengan generalisasi isi, yang mengubah teks biasa menjadi bentuk generalisasi. Model belajar mendalam arsitektur pengekode-dekoder perhatian, yang diperbesar untuk memungkinkan mekanisme penghadapan dan penyamaran, serta pemerintahan belajar dan arsitektur berdasarkan transformer, dilatih pada versi umum pasangan teks-ringkasan, belajar untuk memprediksi ringkasan dalam bentuk umum. Tugas pos-proses menggunakan pengetahuan
sumber daya, pembangunan kata, penyelesaian perasaan kata, dan algoritma heuristik berdasarkan metode persamaan teks untuk mengubah versi generalisasi dari ringkasan yang diprediksi menjadi bentuk akhir yang dapat dibaca oleh manusia. Sebuah prosedur eksperimen ekstensif pada tiga set data populer mengevaluasi aspek kunci dari cadangan yang diusulkan, sementara hasil yang diperoleh menunjukkan prestasi yang berjanji, mengevalifikasi kepekatan pendekatan yang diusulkan.</abstract_id>
      <abstract_fa>امروز، اکثر تحقیقات انجام شده در زمینه تعداد متن abstractive تنها روی مدل‌های عصبی تمرکز می‌کند، بدون توجه به ترکیب آنها با روش‌های علمی که می‌توانند عملکرد آنها را بیشتر افزایش دهند. در این مسیر، این کار یک چهارچوب نویسی را نشان می دهد که جمع کردن متن بنیاد عصبی را با ساختار و روش‌های بنیاد semantic را ترکیب می‌کند. این چهارچوب پیشنهاد قادر است که با مشکل بیرون کلمات یا کلمات نادر حل کند، و عملکرد مدل یادگیری عمیق را بهتر کند. این روش‌شناسی عمومی بر روی یک مدل نظریه‌ای خوب تعریف شده از محتوای ژنرال‌سازی بر اساس علم و پیش‌بینی‌های یادگیری عمیق برای تولید جمعیت‌های abstractive است. چهارچوب از سه عنصر کلیدی ساخته شده است: i) یک کار پیش‌پردازی، ii) روش یادگیری ماشین، و iii) یک کار بعد از پردازی. وظیفه پیش‌پردازی یک روش بر اساس علم است که بر اساس منابع علم‌شناسی‌شناسی‌شناسی‌های کلمه‌شناسی و شناختن عنوان‌شناسی‌های عنوان‌شناسی است که متن معمولی را تبدیل می‌کند به یک فرم ژنرال‌شناسی. یک مدل یادگیری عمیق از معماری آهنگ‌بندی‌کننده‌ی رمزبندی‌کننده‌ای که برای فعال کردن یک مکانیسم پوشش و پوشش، و یادگیری و معماری‌های بنیاد تغییر‌دهنده، روی نسخه‌ی جفت‌های جمع‌آوری متن آموزش می‌شود، یاد گرفتن برای پیش‌بینی جمع‌آوری در یک شکل عمومی. کار بعد از پرداخت از دانش استفاده می‌کند
منابع، جمع کردن کلمات، غیرقابل تغییر حس کلمات و الگوریتم های حوریستی بر روش شبیه‌سازی متن برای تغییر نسخه‌ی عمومی یک جمع پیش‌بینی به یک فرم نهایی، قابل خواندن بشر. یک روش آزمایشی بسیار گسترده در سه مجموعه داده‌های محبوب ارزش می‌دهد نقطه‌های کلیدی از چهارچوب پیشنهاد، در حالی که نتیجه‌های پیدا شده‌اند اجرای قول‌دهنده را نشان می‌دهند، و ثابت کردن قوی‌ای از روش</abstract_fa>
      <abstract_sw>Kwa siku hizi, utafiti mkubwa uliofanywa katika uwanja wa muhtasari wa maandishi yasiyo na maandishi ya ubora unajikita kwenye mifano yenye msingi wa neura peke yake, bila kuzingatia muunganiko wao na mbinu za kisayansi ambazo zinaweza kuongeza ufanisi wao. Kwa mwelekeo huu, kazi hii inaonyesha mfumo wa riwaya unaoanganisha muhtasari wa maandishi yanayotumika kwa mfululizo wa mfululizo na mbinu za kisasa. Mfumo huu unapendekezwa una uwezo wa kushughulikia tatizo la maneno yasiyo ya lugha au maneno nadra, na kuimarisha utendaji wa mifano ya kujifunza kwa kina. Utawala wa jumla unajikita na mifano ya nadharia yenye ufafanuzi wa maudhui yenye msingi wa maarifa na utabiri wa kujifunza kwa ajili ya kutengeneza muhtasari wa kutosha. Mfumo huu umetengenezwa na vipengele vitatu vya muhimu: (i) kazi ya kabla ya kufanya kazi, (ii) mbinu za kujifunza mashine, na (iii) kazi ya baada ya kuchukua hatua. Kazi ya upasuaji wa awali ni mbinu yenye ufahamu, kwa kutumia rasilimali za maarifa za kiutaalamu, uvumbuzi wa maneno, na utambulisho wa entity, pamoja na uzalishaji wa maudhui, ambayo hubadilisha ujumla kuwa namna ya ujumla. Mfano wa kujifunza kwa kina wa ujenzi wa ubunifu wa kodi unaoaminika, ambao unaongezeka ili kuwezesha ubunifu na taarifa za habari, pamoja na kuboresha majengo ya kujifunza na mabadiliko yenye msingi wa muhtasari, unafundishwa kwa toleo la jumla la la ndoa za muhtasari, kujifunza kutabiri muhtasari katika mfumo wa jumla. Kazi ya baada ya upasuaji inatumia maarifa
rasilimali, maeneo ya maneno, uvunjifu wa maana, na vipimo vya heuristi vilivyo kwa njia sawa na maandishi ili kubadilisha toleo la jumla la la muhtasari lililotabiliwa hadi a in a ya mwisho, inayosomeka kwa binadamu. Utaratibu mkubwa wa majaribio kwenye seti ya data maarufu tatu unatathmini vipengele muhimu vya mfumo wa pendekezo, wakati matokeo yaliyopata yanaonyesha ufanisi wa kuahidini, ukithibitisha ubora wa mbinu hiyo ya pendekezo.</abstract_sw>
      <abstract_sq>Abstrakt Today, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. Në këtë drejtim, ky punë paraqet një kuadër të ri që kombinon përmbledhjen e tekstit nga sekuenca në sekuencë me bazë nervore së bashku me strukturën dhe metodologjitë me bazë semantike. Korniza e propozuar është e aftë të trajtojë problemin e fjalëve jashtë fjalorit apo të rralla, duke përmirësuar performancën e modeleve të mësimit të thellë. Metodologjia e përgjithshme bazohet në një model teorik të përcaktuar mirë të gjeneralizimit të përmbajtjes bazuar në njohuri dhe parashikimeve të mësimit të thellë për gjenerimin e përmbledhjeve abstraktive. Korniza përbëhet nga tre elementë kyçe: (i) një detyrë paraprocesuese, (ii) një metodologji mësimi i makinave dhe (iii) një detyrë pas procesimit. Detyra paraprocesuese është një qasje bazuar në njohuri, bazuar në burimet ontologjike të njohurive, çambiguacionin e kuptimit të fjalës dhe njohjen e emëruar të njësisë së bashku me gjeneralizimin e përmbajtjeve, që transformon tekstin e zakonshëm në një form ë të gjeneralizuar. Një model mësimi i thellë i arkitekturës së koduesit-dekoderit të vëmendshëm, i cili zgjerohet për të mundësuar një mekanizëm përballimi dhe mbulimi, si dhe forcimi i mësimit dhe arkitekturës bazuar në transformues, është trajnuar në një version të gjeneralizuar të çifteve tekst-përmbledhje, duke mësuar të parashikojë përmbledhjet në një form ë të gjeneralizuar. The post-processing task utilizes knowledge
burimet, përfshirjet e fjalëve, çambiguacioni i kuptimit të fjalëve dhe algoritmet heuristikë bazuar në metodat e ngjashmërisë së tekstit me qëllim që të transformojë version in e gjeneralizuar të një përmbledhjeje të parashikuar në një form ë përfundimtare të lexueshme nga njerëzit. Një procedurë eksperimentale të gjerë mbi tre grupe të dhënash popullore vlerëson aspektet kyçe të kuadrit të propozuar ndërsa rezultatet e fituara ekspozojnë performancë premtuese, duke validuar fuqinë e qasjes së propozuar.</abstract_sq>
      <abstract_tr>Abstrakt Köp sany abstraktiw metin toplamynyň sahypasynda işlenýän araştyrmalar neural tabanly modellere ýeke özüne üns berilýär, bilim tabanly hereketleriyle birleşişmäge özleriniň etkinliýetini artdyryp biler üýtgetmeýän şeklinde üns berilýär. Bu görnöşinde, bu işe tertibe-tä-dizirli näyral tabanly metin hulatyny struktur we semantik tabanly metinleri bilen birleştirilýär. Mazmunlar sistemasy sözleriň daşyndaky ýa-da nadir sözleriň meselesini çözmek, derin öwrenmek nusgalarynyň täzeliklerini gowylaşdyryp biler. Hemme methodologiýa bilgi tabanly maglumat döredilmesiniň we çukur öwrenmek üçin gowy tanyş teoriýalygyna daýanýar. Bu çerçew üç a çyk elementlerden oluşulýar: i) öňünden i şleýän zady, (ii) maşynyň öwrenmesi methodologiýasy we (iii) öňünden soňra işleýän zady. Öňki işleýän zady bilim tabanly bir ýazşydyr, ontolojik bilim çeşmelerine daýanýar, söz duýguny çykarmak we adly zatlary tanamak bilen daýanýar, bu da adatça metin döredilmiş bir şekilde üýtgedir. Dykgat ködleme-dekoder arhitekteginiň derin öwrenmek nusgasy, kop we örgüt mekanizmasyny mümkin etmek üçin genişletilýär we öwrenmek we üýtgetmek üçin gurultatyny daýatmak üçin, metin-sumy çiftleriň umumy tarapynda öwrenmeli, toparyny döredilen nusgasynda öwrenmek üçin öwrenmeli. Edilmek üçin işlemden soňra bilgi ullanýar
Resuller, söz gaýşartmaky, söz duýguny çykarmak we heuristik algoritmalar metin benzeri yöntemlerine dayanan metin ýagdaýynda önlenen toparyň döredilmiş sürümini iň soňky, adam okalabilir bir şekilde üýtgetmek üçin üýtgetmek üçin. Üç meýdança maglumat düzümlerinde örän bir deneysel prosedür teklip eden frameýäniň aç aspektlerini deňleýär, we netijeler netijeleri söz berýän zady görkeýär, teklip eden golaýyň güýçligini taýýarlaýar.</abstract_tr>
      <abstract_af>Abstrakte Vandag, die meeste ondersoek wat in die veld van abstraktiewe teks opsomming gedoen is, fokus alleen op neuralgebaseerde modele, sonder om hulle kombinasie met kennis-gebaseerde toegange te onderwerp wat hulle effektiviteit verder kan verbeter. In hierdie rigting, hierdie werk voorsien 'n nuwe raamwerk wat sekwensie-na-sekwensie neurale-gebaseerde teks opsomming kombinieer saam met struktuur en semantiese-gebaseerde metodes. Die voorgestelde raamwerk is in staat om met die probleem van uit-woordeboek of selfde woorde te behandel, die prestasie van die diep leer modele te verbeter. Die algemene metodologie is gebaseer op 'n goed gedefinieerde teorieese model van kennis-gebaseerde inhoud generalisering en diep leer voorskou vir die genereer van abstraktiewe opsommings. Die raamwerk is gemaak van drie sleutel elemente: i) ân voorafverwerking taak, (ii) ân masjien leer metodologie en (iii) ân post-verwerking taak. Die voorafverwerking opdrag is 'n kennis-gebaseerde toegang, gebaseer op ontologiese kennis hulpbronne, woord sens ontsamminging en genoem entiteiterkenning, saam met inhoud generellisering, wat gewone teks verander in 'n genereliseerde vorm. 'n Deep leer model van aandaglike enkoder-dekoder-arkitektuur, wat uitgevou word om 'n kopering en dekkeningsmekanisme te aktiveer, en ook versterking leer en transformeer-gebaseerde arkitektuure, is opgelei op 'n generelse weergawe van teks-opsommingspaar, leer om opsommings in 'n generelliseerde vorm te voorskou. Die post-verwerking taak gebruik kennis
hulpbronne, woord inbettings, woord sens ontsammings en heuristiese algoritme gebaseer op teks gelykenis metodes om die generaliseerde weergawe van 'n voorskoude opsomming te transformeer na 'n finale, menslike-leesbaarde vorm. 'n Uitbreidige eksperimentale prosedure op drie populêre data stelle evalueer sleutel aspekte van die voorgestelde raamwerk, terwyl die ontvangde resultate die beloftende effektiviteit vertoon, die kragtigheid van die voorgestelde toegang bekend.</abstract_af>
      <abstract_ko>현재 추상적인 텍스트 요약 분야에서 진행된 대부분의 연구는 신경 네트워크를 바탕으로 하는 모델에만 주목하고 지식을 바탕으로 하는 방법과 결합하는 것을 고려하지 않아 효율을 한층 높였다.이 방향에서 이 작업은 서열을 바탕으로 서열 신경 네트워크에 이르는 텍스트 요약과 구조와 의미를 바탕으로 하는 방법을 결합한 새로운 구조를 제시했다.이 프레임워크는 어휘량이 부족하거나 희귀어를 해결할 수 있어 딥러닝 모델의 성능을 높일 수 있다.전체적인 방법은 정의가 좋은 이론 모델, 즉 지식을 바탕으로 하는 내용 개괄과 추상적 요약을 생성하는 깊이 있는 학습 예측을 바탕으로 한다.이 프레임워크는 세 가지 관건적인 요소로 구성되어 있는데 그것이 바로 (i)예처리 임무, (ii)기계 학습 방법, 그리고 (iii)후처리 임무이다.예처리 임무는 지식을 바탕으로 하는 방법으로 본체의 지식 자원, 단어의 의미 소멸, 명명 실체 식별과 내용 범화를 바탕으로 일반 텍스트를 광의적인 형식으로 전환한다.인코더-디코더 체계 구조에 전념하는 깊이 있는 학습 모델은 텍스트 요약에 대한 광의적인 버전에서 훈련을 하고 광의적인 형식으로 요약을 예측하는 학습을 한다. 이 모델은 대응과 커버 메커니즘을 실현하고 학습과 변환기를 바탕으로 하는 체계 구조를 강화한다.후처리 임무 활용 지식
자원, 단어 삽입, 의미 변조, 텍스트 유사성 방법을 바탕으로 하는 계발식 알고리즘으로 요약을 예측하는 광의적인 버전을 최종 인류가 읽을 수 있는 형식으로 전환시킨다.세 개의 유행 데이터 집합에서 광범위한 실험을 실시하여 이 프레임워크의 관건적인 부분을 평가했고 얻은 결과는 좋은 성능을 보여 이 방법의 노봉성을 검증했다.</abstract_ko>
      <abstract_am>ዛሬ፣ ብዙዎቹ የጽሑፍ ቁጥጥር በሚደረጉት እርሻ ላይ ተማርከዋል፣ ብቻውን በናውራዊ አካባቢ ምሳሌዎች ላይ ብቻ ነው፡፡ ወደዚህ ቦታ፣ ይህ ሥራ የነጥብ ፍሬም በሥርዓት እና በsemantic-based ሥርዓት የተደረገውን የነጥብ የጽሑፍ ቁጥጥር የሚያሳስብ ነው፡፡ በተዘጋጀው ፍሬም የጠልቅ ትምህርት ምሳሌዎችን ማሳየት የሚችል የቋንቋ ወይም የግልፅ ቃላትን መቆጣጠር ይችላል፡፡ የጠቅላላ ሞዴology እውቀት-based የውይይት ማቀናቀል እና የጥልቅ ትምህርት ማቀናኘት ጥልቅ ትምህርት ላይ የተመሳሳይ ተቃውሞ ነው፡፡ የፍሬም ቁልፎች በሦስት ቁልፎች ውስጥ ነው:(i) የፕሮግራም ስራ:(ii) የመኪን ትምህርት methodology እና (iii) የፖለቲካ ስራ ነው፡፡ የቀድሞው የሥርዓት ሥራ የኦቶሎጂ እውቀት ሀብት፣ የቃላት ማስተዋል ውቀት፣ የተባለው አካባቢ ማውቀት፣ በተባለው ማቀናቀል እና የጽሑፉን ማቀናቀል በመጠቀም የተጠቃሚ ጽሑፍ አቀማመጥ እንዲለውጥ ነው፡፡ የጽሑፍ አቀማመጥ እና የድጋፍ አካባቢ መሠረት ማድረግ የጥልቅ ትምህርት ሞዴል፣ ማስተማርና ማተማር እና የመለወጥ መሠረት፣ የጽሑፍ አነስተኛ ሁለትን በመጠቀም የተማረ ነው፡፡ የፖስታ ስራ እውቀትን ይጠቅማል
ሀብት፣ ቃላት ግንኙነት፣ የቃላት አስተያየት እና የኦርቲክ አሌጎርቲም በጽሑፍ መሰላቸውን ሥርዓት ለመለወጥ የተቀረበ የውጤት ክፍል ወደ መጨረሻ የሰው ተቃውሞ የሚነበበውን መልዕክት ለመለወጥ ነው፡፡ በተፈተናው የሦስት የድምፅ ፈተና ሥርዓት በተፈተናው የፍሬም ቁልፎችን ያስተካክላል፡፡ ፍሬዎቹም በተገኘው ጊዜ የተስፋ የሥርዓት ውጤት ያሳያል፡፡</abstract_am>
      <abstract_az>Abstrakt Günlərdə, abstraktiv mətn toplaması sahəsində təkcə nöral tabanlı modellərə tərəfindən təklif edilmiş araştırmalar, elm tabanlı təklifələrlə birləşdirilməsini daha da artıra bilər. Bu tərəfdə, bu işin bir yeni framework ü göstərir ki, sequence-to-sequence-based mətn quruluşu və semantik metodları ilə birləşdirir. Bu tədbir qurğusu sözlərin və ya nadir sözlərin problemlərini çəkməyə qadir deyildir, böyük öyrənmə modellərinin performansını yaxşılaşdırmağa qadir deyildir. Bu bütün metodoloji elm-tabanlı məlumatların generalizasyonu və abstraktiv toplantıları yaratmaq üçün çox müəyyən edilmiş teoriki modellərə dayanılır. Çerçive üç anahtar elementindən oluşur: i) əvvəlcə i şləmə işləri, ii) makina öyrənmə metodolojisi və iii) post işləmə işləri. Əvvəlcə işləmə işləri bilgi-tabanlı tərzidir, ontolojik elm kaynaqlarına dayanan, sözlərin sağlamlığı dəyişməsi və adı ilə ünvanlıq tanıması ilə birlikdə sıradan metinləri generalizasyona çevirir. Dinli koder-dekoder arhitektarının derin öyrənmə modeli, kopyalama və örtük mehanizmisini fəallaşdırmaq üçün genişlənir, həmçin in öyrənməyi və transformer-tabanlı arhitektarları daha qüvvətli təhsil edirlər, ünvanlı bir şəkildə təhsil etməyi öyrənir. Sonra işləmə işləri bilgi istifadə edir
Mətn similaritə metodlarına dayandırılmaq üçün tədbir edilmiş təsbit verzijünü son, insan oxuyabilən formaya çevirmək üçün mənbəni, sözlər içərisində yazılmış yazılı hisslər, və heuristik algoritmi. Üç popüler veri qurularında böyük bir təcrübə prosedüsü təklif edilmiş quruluşun açarlı aspektlərini değerləşdirir. Yaxılmış sonuçlar təklif edilən təcrübəsinin güclülüyünü təsdiqləyir.</abstract_az>
      <abstract_bn>বর্তমানে বিচ্ছিন্ন করুন, বেশীরভাগ গবেষণা আত্মসংক্ষেপের ক্ষেত্রে নিউরুল ভিত্তিক মডেলের উপর মনোযোগ প্রদান করেছে, তাদের জ্ঞান-ভিত্তিক উপায়ের সাথে  এই দিকে এই কাজ একটি নভেল ফ্রেম্যাক্টর উপস্থাপন করে যা সেকেন্স-থেকে সেকেন্স-ভিত্তিক নিউরাল-ভিত্তিক টেক্সট সংক্রান্ত সংক্ষেপের প্রস্তাবিত ফ্রেমের কাঠামোটি শব্দভাণ্ডার বা দুর্লভ শব্দের সমস্যার সাথে মিলিয়ে নিতে সক্ষম, গভীর শিক্ষা মডেলের প্রদর্শনের সাধারণত পদ্ধতির ভিত্তিক ততিত্তিগত মডেলের উপর ভিত্তিক রয়েছে জ্ঞান-ভিত্তিক বিষয়বস্তু জেনারেলেশন এবং গভীর শিক্ষার ভবিষ্যৎবাণ ফ্রেমের কাঠামো তিনটি গুরুত্বপূর্ণ উপাদানের মধ্যে তৈরি করা হয়েছে: (i) পূর্ব প্রক্রিয়ার কাজ, (ii) একটি মেশিন শিক্ষা পদ্ধতি এবং (আই) একট পূর্ব প্রক্রিয়ার কাজ হচ্ছে একটি জ্ঞান-ভিত্তিক পদ্ধতি, শব্দের মানসিক বিভ্রান্তির ভিত্তিতে, এবং নামে বস্তুর স্বীকৃতি এবং বিষয়বস্তু সংস্কারের স কোডার-ডেকোডার কাঠামোর গভীর শিক্ষার মডেল, যা কপিং এবং কাভারেজ ব্যবস্থা করার জন্য বিস্তৃত হয়েছে এবং সাথে শিক্ষা এবং পরিবর্তনের ভিত্তিক ক কাঠামোগুলোর সাধারণ সংক্রান্ত জোড়ার সংস্করণে শিক্ পরিচালনা করার কাজ জ্ঞান ব্যবহার করে
সম্পদ, শব্দ প্রবাহিত, শব্দের মানসিক বিভ্রান্তি এবং হারিস্টিক অ্যালগরিদম, টেক্সটের সমতুল্য পদ্ধতি ভিত্তিতে ভিত্তি করেছে যাতে ভবিষ্যতের সার্সা প্রস্তাবিত ফ্রেমের কাঠামোর একটি বিস্তারিত পরীক্ষার প্রক্রিয়া তিনটি জনপ্রিয় তথ্য সেটে প্রস্তাবিত পরীক্ষার প্রক্রিয়া মূল্যায়ন করে, আর ফলাফল প্রত</abstract_bn>
      <abstract_bs>U današnje vrijeme, većina istraživanja provedena u oblasti sažetanja abstraktivnog teksta fokusirala se na samo neurološke modele, bez obzira na njihovu kombinaciju sa pristupima na temelju znanja koje bi mogle povećati njihovu učinkovitost. U ovom smjeru, ovaj rad predstavlja nov okvir koji kombinira sažetak teksta na sekvenciji na neuralnoj osnovi zajedno sa strukturom i semantičkim metodama. Predloženi okvir je sposoban rješavati problem izvan rečenika ili rijetkih riječi, poboljšavajući učenje dubokih modela učenja. Općenita metodika se temelji na dobro definiranom teorijskom modelu generalizacije sadržaja na znanju i predviđanja dubokog učenja za stvaranje abstraktivnih sažetaka. Okvir se sastoji od tri ključna elementa: i) zadatak predobrazovanja, ii) metodologija učenja mašine i iii) zadatak postobrazovanja. Preobrađujući zadatak je pristup na znanju, baziran na ontološkim resursima znanja, disambiguaciji riječi, i priznanje entiteta po imenu, zajedno s generalizacijom sadržaja, koji pretvara obični tekst u generalizirani oblik. Duboko učenje model a pozorne arhitekture kodera-dekodera, koja se proširi kako bi omogućila mehanizam kopanja i pokrivanja, kao i pojačanje učenja i arhitektura na osnovu transformera, obučena je na generaliziranoj verziji rezumnih parova teksta, učenje predvidjeti sažetke u generaliziranom obliku. Poslije obrade zadatak koristi znanje
resursi, uključenje riječi, disambiguacija riječi, i heuristički algoritmi bazirani na metodi sličnosti teksta kako bi transformirali generaliziranu verziju predviđenog sažetka u konačni, ljudski čitljivi oblik. Ogromna eksperimentalna procedura na tri popularna seta podataka procjenjuje ključne aspekte predloženog okvira, dok dobijeni rezultati pokazuju obećavajuću učinkovitost, potvrđujući robotu predloženog pristupa.</abstract_bs>
      <abstract_ca>Avui en dia, la majoria de les investigacions fetes en el camp de la resumització abstracta del text es centren només en models basats en neurones, sense considerar la seva combinació amb enfocaments basats en el coneixement que podrien millorar més la seva eficiència. En aquesta direcció, aquesta feina presenta un nou marc que combina una resumida de text basada en seqüència a seqüència neuronal juntament amb estructura i metodologies basades en semàntica. El marc proposat és capaç de tractar el problema de paraules fora de vocabulari o rares, millorant el rendiment dels models d'aprenentatge profund. La metodologia global es basa en un model teòric ben definit de generalització del contingut basat en el coneixement i prediccions profundes d'aprenentatge per generar resumes abstracts. El marc està compost de tres elements clau: i) una tasca de pré-processament, ii) una metodologia d'aprenentatge de màquines i iii) una tasca de post-processament. La tasca de pré-processament és un enfocament basat en el coneixement, basat en recursos ontològics de coneixement, desambiguació del sentit de paraula i reconeixement de l'entitat anomenat, juntament amb la generalització del contingut, que transforma el text normal en una form a generalitzada. Un model d'aprenentatge profund d'arquitectura atenta de codificadors-decoders, que s'expandeix per permetre un mecanisme de copia i cobertura, com també l'aprenentatge de reforç i arquitectures basades en transformadors, està entrenat en una versió generalitzada de parelles de resum de text, aprenent a predir resums en una forma generalitzada. La tasca de postprocessament utilitza el coneixement
recursos, incorporacions de paraules, desambiguació del sentit de paraules i algoritmes heurístics basats en mètodes de similitud de text per transformar la versió generalitzada d'un resum predit en una form a final llegible per a l'humà. An extensive experimental procedure on three popular data sets evaluates key aspects of the proposed framework, while the obtained results exhibit promising performance, validating the robustness of the proposed approach.</abstract_ca>
      <abstract_hy>Այսօր վերացական, վերացական տեքստի համառոտագրման ոլորտում կատարված հետազոտությունների մեծ մասը կենտրոնանում է միայն նեյրոնային հիմնված մոդելների վրա, առանց հաշվի առնելու նրանց համադրումը գիտելիքի հիմնված մոտեցումների հետ, որոնք կարող են ավելի բարելավել իրենց արդ Այս ուղղությամբ, այս աշխատանքը ներկայացնում է նոր շրջանակ, որը համադրում է նյարդային հաջորդականությամբ հիմնված տեքստի համառոտագրությունը, ինչպես նաև կառուցվածքը և սեմանտիկ հիմնված մեթոդոլոգիաները: Առաջարկված շրջանակը կարողանում է լուծել ոչ բառարանի կամ հազվադեպ բառերի խնդիրը, բարելավելով խորը սովորելու մոդելների արդյունքը: Ընդհանուր մեթոդոլոգիան հիմնված է գիտելիքի հիմնված պարունակության ընդհանուր ընդհանուր ընդհանուր տեսական մոդելի վրա և խորը ուսումնասիրության կանխատեսումների վրա վերացրական համառոտագրություններ ստեղծելու համար: Համակարգը կազմված է երեք կարևոր տարրերից: i) նախավերամշակման առաջադրանք, i) մեքենային ուսումնասիրության մեթոդոլոգիա և i) նախավերամշակման առաջադրանք: Նախավերամշակման գործընթացը գիտելիքների հիմնված մոտեցում է, որը հիմնված է օնտոլոգիական գիտելիքների ռեսուրսների վրա, բառերի զգացմունքի անբացատրություն և անվանված էության ճանաչելու վրա, միասին պարունակության ընդհանուր ընդհանուր ընթացքում, որը վերածում է Ուշադիր կոդեր-կոդեր ճարտարապետության խորը ուսումնասիրության մոդելը, որը ընդլայնվում է, որպեսզի հնարավորություն տա հաղթահարելու և ծածկության մեխանիզմներին, ինչպես նաև ուժեղացման ուսումնասիրության և վերափոխման հիմնված ճարտարապետություններին, ուսուցվում է տեքստի համառոտագրական զույգերի ընդհանուր տար Հաջորդ գործընթացը օգտագործում է գիտելիքը
resources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form.  Երեք հայտնի տվյալների համակարգերի ընդլայնված փորձարկման գործընթացը գնահատում է առաջարկած շրջանակի հիմնական ասպեկտները, մինչդեռ ստացված արդյունքները ցույց են տալիս խոստացնող արդյունքներ, ստուգելով առաջարկած մոտեցության կայուն</abstract_hy>
      <abstract_fi>Nykyään suurin osa abstraktiivisen tekstiyhteenvedon alalla tehdyistä tutkimuksista keskittyy pelkästään neuropohjaisiin malleihin ottamatta huomioon niiden yhdistämistä tietoon perustuviin lähestymistapoihin, jotka voisivat parantaa niiden tehokkuutta entisestään. Tähän suuntaan tässä työssä esitellään uusi viitekehys, joka yhdistää sekvenssi-sekvenssiin neuropohjaisen tekstin yhteenvedon rakenne- ja semanttisiin menetelmiin. Ehdotetulla kehyksellä pystytään käsittelemään sanaston ulkopuolisia tai harvinaisia sanoja koskevaa ongelmaa ja parantamaan syväoppimisen mallien suorituskykyä. Kokonaismenetelmä perustuu hyvin määriteltyyn teoreettiseen malliin tietopohjaisesta sisällönyleistämisestä ja syväoppimisen ennusteista abstraktien yhteenvetojen tuottamiseksi. Kehys koostuu kolmesta avaintekijästä: i) esikäsittelytehtävästä, ii) koneoppimismenetelmästä ja iii) jälkikäsittelytehtävästä. Esiprosessointitehtävä on tietopohjainen lähestymistapa, joka perustuu ontologisiin tietoresursseihin, sanaaistin erotteluun ja nimettyjen entiteettien tunnistamiseen sekä sisällön yleistämiseen, joka muuttaa tavallisen tekstin yleiseksi muotoksi. Tarkkaan koodaaja-dekooderiarkkitehtuurin syväoppimismalli, jota laajennetaan mahdollistamaan selviytymis- ja peittomekanismi sekä vahvistus- ja muuntajapohjaiset arkkitehtuurit, on koulutettu teksti-yhteenvetoparien yleiseen versioon, joka oppii ennustamaan tiivistelmiä yleistetyssä muodossa. Jälkikäsittelytehtävässä hyödynnetään tietoa
Tekstin samankaltaisuusmenetelmiin perustuvat heuristiset algoritmit, joilla ennustetun yhteenvedon yleistetty versio muunnetaan lopulliseksi, ihmisluettavaksi muotoon. Laaja kokeellinen menettely kolmella suositulla aineistolla arvioi ehdotetun viitekehyksen keskeisiä näkökohtia, kun taas saadut tulokset osoittavat lupaavaa suorituskykyä vahvistaen ehdotetun lähestymistavan kestävyyden.</abstract_fi>
      <abstract_et>Tänapäeval keskendub enamik abstraktse teksti kokkuvõtte valdkonnas tehtud uuringutest üksnes neuraalsetele mudelitele, kaalumata nende kombinatsiooni teadmistepõhiste lähenemisviisidega, mis võiksid nende tõhusust veelgi suurendada. Selles suunas esitatakse käesolev töö uudset raamistikku, mis ühendab järjestusest järjestuseni neuropõhise teksti kokkuvõtliku koostamise struktuuri ja semantika meetoditega. Kavandatud raamistik on võimeline tegelema sõnavara või haruldaste sõnade probleemiga, parandades sügavõppe mudelite tulemuslikkust. Üldine metoodika põhineb hästi määratletud teoreetilisel mudelil teadmistepõhise sisu üldistamise ja sügavõppe prognooside kohta abstraktsete kokkuvõtete koostamiseks. Raamistik koosneb kolmest põhielementist: i) eeltöötlusülesanne, ii) masinõppe metoodika ja iii) järeltöötlusülesanne. Eeltöötlusülesanne on teadmistepõhine lähenemisviis, mis põhineb ontoloogilistel teadmiste ressurssidel, sõnatähenduse eristamisel ja nimetatud olemi tuvastamisel koos sisu üldistamisega, mis muudab tavalise teksti üldistatud vormiks. Tähelepanu kodeerija-dekooderi arhitektuuri sügavõppemudel, mida laiendatakse, et võimaldada toimetuleku- ja katvusmehhanismi, samuti tugevdusõppe ja transformaatoripõhiseid arhitektuure, on koolitatud teksti-kokkuvõtte paaride üldistatud versioonil, õppides prognoosima kokkuvõtteid üldises vormis. Järeltöötlusülesanne kasutab teadmisi
Teksti sarnasuse meetoditel põhinevad heuristilised algoritmid, et muuta prognoositud kokkuvõtte üldine versioon lõplikuks inimloetavaks vormiks. Laiaulatuslik eksperimentaalne protseduur kolmel populaarsel andmekogumil hindab kavandatud raamistiku põhiaspekte, samas kui saadud tulemused näitavad paljulubavat tulemust, kinnitades kavandatud lähenemisviisi tugevust.</abstract_et>
      <abstract_cs>Abstrakt V současné době se většina výzkumů prováděných v oblasti abstraktivního textového shrnutí zaměřuje pouze na neuronové modely, aniž bychom zvážili jejich kombinaci s přístupy založenými na znalostech, které by mohly dále zvýšit jejich efektivitu. V tomto směru práce představuje nový rámec, který kombinuje sekvenci-to-sekvence neuronově založené textové shrnutí spolu se strukturou a sémanticky založenými metodikami. Navržený rámec je schopen řešit problém mimo slovní zásobu nebo vzácných slov a zlepšit výkon modelů hlubokého učení. Celková metodika je založena na dobře definovaném teoretickém modelu zobecnění obsahu založeném na znalostech a predikcích hlubokého učení pro generování abstraktivních souhrnů. Rámec se skládá ze tří klíčových prvků: (i) úkolu předzpracování, (ii) metodiky strojového učení a (iii) úkolu po zpracování. Úkolem předzpracování je přístup založený na znalostech, založený na ontologických znalostních zdrojích, rozšiřování slovních smyslů a rozpoznávání pojmenovaných entit spolu s zobecněním obsahu, který transformuje běžný text do zobecněné formy. Model hlubokého učení s pozornou architekturou kodéru-dekodéru, který je rozšířen tak, aby umožnil zvládnutí a pokrytí mechanismu, stejně jako posílení učení a transformátorové architektury, je trénován na zobecněné verzi text-souhrnných párů, které se učí předpovídat souhrnné souhrny v obecné podobě. Úkol po zpracování využívá znalostí
Zdroje, vkládání slov, rozšíření slovních smyslů a heuristické algoritmy založené na metodách podobnosti textu s cílem transformovat zobecněnou verzi předpokládaného souhrnu do konečné, člověkem čitelné podoby. Rozsáhlý experimentální postup na třech populárních datových sadách hodnotí klíčové aspekty navrhovaného rámce, zatímco získané výsledky vykazují slibný výkon, což ověřuje robustnost navrhovaného přístupu.</abstract_cs>
      <abstract_jv>absolute Noudays, dibutuhé perusahaan sing dumadhi nèng kapan karo resampungan teks absolute Nang direction wiir, lan uwis menehi un barêng dumaten sing isin secanse-to-sekanse sener resumen ning sampeyan karo structural lan semanti-basa method. Laptop" and "Desktop Laptop" and "Desktop structural navigation Awak-procasa saiki wis diangkat-diangkat sing basa awak-dhuwi, sing basa supoyo ontrologke awak dhéwé, nglanggar kuwi tindakan untarané awak dhéwé, lan nganggo kesempatan sampeyan, lan nganggo perusahaan kuwi nggawe nguasakno deep Laptop
gambar Punika sing perusahaan anyar tentang kanggo telu populer dadi sing rumangsa Aspek Where's the larang pangan</abstract_jv>
      <abstract_ha>Ga baya a yanzu, mafi yawansu da aka aiko a cikin field masu ƙararin matsayin na kanrakati, yana fokus kan misãlai masu baka neura kawai, kuma bã da kula da komowarsu da hanyoyin da zane-ba'a, wanda zai iya ƙara fikancinsu. Daga wannan gefen, wannan aikin yana gaya wani firam na nowaya wanda ke haɗa masu saka-dubi'a-sequence na rubutun neural sami da metodi na rubutu da bakin semantic. An karɓi firam da aka faɗa yana iya iya iya shawara wa matsalar masu yin magana ba'a-magana ko da sauri, kuma yana ƙaranci aikin misalin da aka sanar da masu ƙari. Sura'a ɗabi'a ne a kan wata misãlin da aka ƙayyade mai kyau-defined theoretiske na ƙididdige cikin tsarin da aka danne shi a kan ilmi da kuma babu wani abu mai ƙaranci da za'a sami ƙararin da ba'a sani ba. An samo firam daga ƙanshi uku masu maɓalli:(i) wani aikin aiki mai gabatar da shirin aiki, (ii) wani metode mai amfani da mashine, da (i) wani aikin aiki mai bayan-aiki. Kayan aiki na gabatar da shirin aiki yana da wata hanyoyi a kan saniya, a kan asansa da maɓallin ilmi, yin rarrabẽwa ga magana, da kuma an ambaci sunan ganin shaidar abun, da kuma da mai ƙiƙiro maɓalli, yana musanya matsayin na ɗabi'a zuwa wani tsari mai gabatar da shi. An sanar da wani motsi na matsayin kode-kode-na'urar, wanda za'a faɗa ɗa shi dõmin ya iya amfani da kofi da tsari, da kuma a ƙarfafa wasu matsayin da aka sanar da shi da aka shige shi, an sanar da shi a wani version na jumla'ar nau'in rubutu-nau'in rubutu, kuma an sanar da ɗabi'a cikin tsarin mai jumla. Suna amfani da ilmi
QXml Rukacin jarrabi mai shimfiɗawa a kan data ta sami uku, yana ƙaddara masu key aspects of firam ɗin da aka buƙata, kuma a lokacin da matsala suka nuna performance mai yiwuwa da ake yi wa'adi, yana gaskata tufãfin na hanyarwa da ake faɗi.</abstract_ha>
      <abstract_sk>Danes se večina raziskav na področju abstraktivnega povzetka besedila osredotoča samo na živčno osnovane modele, ne da bi upoštevali njihovo kombinacijo s pristopi na znanju, ki bi lahko še bolj izboljšali njihovo učinkovitost. V tej smeri je v tem delu predstavljen nov okvir, ki združuje povzetek besedila iz zaporedja do zaporedja, ki temelji na nevralni osnovi, skupaj s strukturo in semantično osnovanimi metodologijami. Predlagani okvir je sposoben obravnavati problem izven besedišča ali redkih besed in izboljšati učinkovitost modelov globokega učenja. Celotna metodologija temelji na dobro opredeljenem teoretičnem modelu generalizacije vsebin na znanju in napovedih globokega učenja za ustvarjanje abstraktivnih povzetkov. Okvir je sestavljen iz treh ključnih elementov: (i) naloge predobdelave, (ii) metodologije strojnega učenja in (iii) naloge po obdelavi. Predobdelava je na znanju temelječi pristop, ki temelji na ontoloških virih znanja, razjasnitvi besednega pomena in prepoznavanju imenovanih entitet, skupaj s posploševanjem vsebine, ki navadno besedilo pretvori v posplošeno obliko. Model globokega učenja pozorne arhitekture kodirnika-dekodirnika, ki je razširjen tako, da omogoča mehanizem obvladovanja in pokritosti, kot tudi ojačitveno učenje in arhitekture na podlagi transformatorjev, je usposobljen na splošni različici parov besedilo-povzetek, ki se uči napovedovati povzetke v splošni obliki. Naloga po obdelavi uporablja znanje
Vključevanje besed, razjasnitev besednega pomena in heuristični algoritmi, ki temeljijo na metodah podobnosti besedila, da bi posplošeno različico predvidenega povzetka pretvorili v končno, človeško berljivo obliko. Obsežen eksperimentalni postopek na treh priljubljenih podatkovnih nizih ocenjuje ključne vidike predlaganega okvira, pridobljeni rezultati pa kažejo obetavno delovanje, kar potrjuje robustnost predlaganega pristopa.</abstract_sk>
      <abstract_he>בימים אלה, רוב המחקרים שנערכו בשטח הסיכוי טקסט אסטרקטיבי מתמקדים בדוגמנים מבוססים על עצבים בלבד, מבלי לשקול את שילוב שלהם עם גישות מבוססים על ידע שיכולות לשפר עוד את היעילות שלהם. בכיוון הזה, העבודה הזו מציגה מסגרת חדשה שמשולבת מסגרת טקסט מבוססת ברצף לרצף לרצף המסגרת המוצעת מסוגלת להתמודד עם הבעיה של מילים מחוץ למילים או מילים נדירות, לשפר את ההופעה של דוגמני הלימוד העמוקים. המטדולוגיה הכללית מבוססת על מודל תיאורטי מוגדר היטב של הגנרליזציה של תוכן מבוסס על ידע וחזויות למידה עמוקה לייצור סדרות אסטרקטיביות. The framework is composed of three key elements: (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task.  המשימה הקדמית לעבודה היא גישה מבוססת על ידע, מבוססת על משאבי ידע אונטולוגיים, חוסר ביטוי מילים, והזיהוי של ישות בשם, יחד עם הגנרליזציה של תוכן, שמהפך טקסט רגיל לצורה כללית. מודל למידה עמוק של ארכיטקטורת קודד-פיקוד תשומת לב, שמרוחב כדי לאפשר מנגנון התמודדות וכיסוי כיסוי, כמו גם למידה תגבורת וארכיטקטורות מבוססת מעבר, מאומנת על גרסה כללית של זוגות קודם-טקסט, ללמוד לצפות בקיצורים בצורה כללית. המשימה לאחר העבודה משתמשת בידע
משאבים, תוספות מילים, ניתוח חוש מילים, ואלגוריטמים היוריסטיים מבוססים על שיטות דומות טקסט כדי לשנות את הגרסה המפורסמת של סכם צפוי לצורה סופית, אפשרית לקרוא אנושית. תהליך ניסוי רחב על שלושה קבוצות נתונים פופולריים מעריך היבטים המרכזים של המסגר המוצע, בעוד התוצאות המקבלות מראות ביצועים מבטיחים, מאשרים את החזקה של הגישה המוצעת.</abstract_he>
      <abstract_bo>abstract Nowadays, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. འདིའི་གནས་སྟངས་འདིའི་ནང་དུ་ལས་ཀ་འདི་ལྟ་བུའི་གསར་བ་གྲངས་ཀ་ཞིག་སྟོན་པ་ཡིན་པས། The proposed framework is capable of dealing with the problem of out-of-vocabulary or rare words, improving the performance of the deep learning models. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries. ཝེབ་གཞུང་དེ་གཙོ་ཆེ་རྣམ་གྲངས་གསུམ་ལས་སྔོན་ལས་སྦྱོར་བྱ་རིམ་ཞིག་ཆགས་འདུག: (i)མ་ལག སྔོན་གྱིས་ལས་སྦྱོར་བྱས་པའི་བྱ A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form. Post-processing task utilizes knowledge
resources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form. སྐད་ཆེན་གྱི་ཆ་འཕྲིན་ཡིག་ཆ་གསུམ་གྱི་ལག་ལེན་གྱི་སྒྲིག</abstract_bo>
      </paper>
    <paper id="28">
      <title>The (Un)Suitability of Automatic Evaluation Metrics for Text Simplification</title>
      <author><first>Fernando</first><last>Alva-Manchego</last></author>
      <author><first>Carolina</first><last>Scarton</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <doi>10.1162/coli_a_00418</doi>
      <abstract>Abstract In order to simplify sentences, several rewriting operations can be performed, such as replacing complex words per simpler synonyms, deleting unnecessary information, and splitting long sentences. Despite this multi-operation nature, evaluation of automatic simplification systems relies on <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> that moderately correlate with human judgments on the <a href="https://en.wikipedia.org/wiki/Simplicity">simplicity</a> achieved by executing specific <a href="https://en.wikipedia.org/wiki/Operation_(mathematics)">operations</a> (e.g., <a href="https://en.wikipedia.org/wiki/Simplicity">simplicity gain</a> based on lexical replacements). In this article, we investigate how well existing <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> can assess sentence-level simplifications where multiple <a href="https://en.wikipedia.org/wiki/Operation_(mathematics)">operations</a> may have been applied and which, therefore, require more general simplicity judgments. For that, we first collect a new and more reliable <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> for evaluating the correlation of <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> and human judgments of overall simplicity. Second, we conduct the first meta-evaluation of automatic metrics in Text Simplification, using our new data set (and other existing data) to analyze the variation of the correlation between metrics’ scores and human judgments across three dimensions : the perceived simplicity level, the system type, and the set of references used for computation. We show that these three aspects affect the correlations and, in particular, highlight the limitations of commonly used operation-specific metrics. Finally, based on our findings, we propose a set of recommendations for automatic evaluation of multi-operation simplifications, suggesting which metrics to compute and how to interpret their scores.</abstract>
      <pages>861–889</pages>
      <url hash="64db7533">2021.cl-4.28</url>
      <bibkey>alva-manchego-etal-2021-un</bibkey>
      <pwccode url="https://github.com/feralvam/metaeval-simplification" additional="false">feralvam/metaeval-simplification</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/turkcorpus">TurkCorpus</pwcdataset>
    </paper>
    <paper id="30">
      <title>Are Ellipses Important for <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>?</title>
      <author><first>Payal</first><last>Khullar</last></author>
      <doi>10.1162/coli_a_00414</doi>
      <abstract>Abstract This article describes an experiment to evaluate the impact of different types of ellipses discussed in <a href="https://en.wikipedia.org/wiki/Theoretical_linguistics">theoretical linguistics</a> on Neural Machine Translation (NMT), using English to Hindi / Telugu as source and target languages. Evaluation with manual methods shows that most of the errors made by Google NMT are located in the clause containing the <a href="https://en.wikipedia.org/wiki/Ellipsis">ellipsis</a>, the frequency of such errors is slightly more in <a href="https://en.wikipedia.org/wiki/Telugu_language">Telugu</a> than <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, and the translation adequacy shows improvement when ellipses are reconstructed with their antecedents. These findings not only confirm the importance of <a href="https://en.wikipedia.org/wiki/Ellipsis">ellipses</a> and their resolution for MT, but also hint toward a possible correlation between the translation of discourse devices like <a href="https://en.wikipedia.org/wiki/Ellipsis">ellipses</a> with the morphological incongruity of the source and target. We also observe that not all <a href="https://en.wikipedia.org/wiki/Ellipse">ellipses</a> are translated poorly and benefit from reconstruction, advocating for a disparate treatment of different <a href="https://en.wikipedia.org/wiki/Ellipse">ellipses</a> in MT research.</abstract>
      <pages>927–937</pages>
      <url hash="770090b8">2021.cl-4.30</url>
      <bibkey>khullar-2021-ellipses</bibkey>
    </paper>
    <paper id="31">
      <title>LFG Generation from Acyclic F-Structures is NP-Hard<fixed-case>LFG</fixed-case> Generation from Acyclic <fixed-case>F</fixed-case>-Structures is <fixed-case>NP</fixed-case>-Hard</title>
      <author><first>Jürgen</first><last>Wedekind</last></author>
      <author><first>Ronald M.</first><last>Kaplan</last></author>
      <doi>10.1162/coli_a_00419</doi>
      <abstract>Abstract The universal generation problem for LFG grammars is the problem of determining whether a given <a href="https://en.wikipedia.org/wiki/Formal_grammar">grammar</a> derives any terminal string with a given f-structure. It is known that this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> is decidable for acyclic f-structures. In this brief note, we show that for those f-structures the <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> is nonetheless intractable. This holds even for <a href="https://en.wikipedia.org/wiki/Formal_grammar">grammars</a> that are off-line parsable.</abstract>
      <pages>939–946</pages>
      <url hash="3f8a673f">2021.cl-4.31</url>
      <bibkey>wedekind-kaplan-2021-lfg</bibkey>
    </paper>
  </volume>
</collection>