<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.maiworkshop">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Multimodal Artificial Intelligence</booktitle>
      <editor><first>Amir</first><last>Zadeh</last></editor>
      <editor><first>Louis-Philippe</first><last>Morency</last></editor>
      <editor><first>Paul Pu</first><last>Liang</last></editor>
      <editor><first>Candace</first><last>Ross</last></editor>
      <editor><first>Ruslan</first><last>Salakhutdinov</last></editor>
      <editor><first>Soujanya</first><last>Poria</last></editor>
      <editor><first>Erik</first><last>Cambria</last></editor>
      <editor><first>Kelly</first><last>Shi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Mexico City, Mexico</address>
      <month>June</month>
      <year>2021</year>
      <url hash="f2f0aab4">2021.maiworkshop-1</url>
    </meta>
    <frontmatter>
      <url hash="46cec279">2021.maiworkshop-1.0</url>
      <bibkey>maiworkshop-2021-multimodal</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Multi Task Learning based Framework for Multimodal Classification</title>
      <author><first>Danting</first><last>Zeng</last></author>
      <pages>30–35</pages>
      <abstract>Large-scale multi-modal classification aim to distinguish between different multi-modal data, and it has drawn dramatically attentions since last decade. In this paper, we propose a multi-task learning-based framework for the multimodal classification task, which consists of two branches : multi-modal autoencoder branch and attention-based multi-modal modeling branch. Multi-modal autoencoder can receive multi-modal features and obtain the interactive information which called multi-modal encoder feature, and use this feature to reconstitute all the input data. Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task). As for attention-based multimodal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multi-modal encoder feature to enrich the input information, achieve a better performance. We conduct extensive experiments on different dataset, the results demonstrate the effectiveness of proposed <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>.</abstract>
      <url hash="e12103f7">2021.maiworkshop-1.5</url>
      <doi>10.18653/v1/2021.maiworkshop-1.5</doi>
      <bibkey>zeng-2021-multi</bibkey>
    </paper>
    <paper id="10">
      <title>A Package for Learning on Tabular and Text Data with Transformers</title>
      <author><first>Ken</first><last>Gu</last></author>
      <author><first>Akshay</first><last>Budhkar</last></author>
      <pages>69–73</pages>
      <abstract>Recent progress in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> has led to Transformer architectures becoming the predominant model used for natural language tasks. However, in many real- world datasets, additional modalities are included which the <a href="https://en.wikipedia.org/wiki/Transformer">Transformer</a> does not directly leverage. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face’s existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract>
      <url hash="2665785e">2021.maiworkshop-1.10</url>
      <doi>10.18653/v1/2021.maiworkshop-1.10</doi>
      <bibkey>gu-budhkar-2021-package</bibkey>
    <title_pt>Um pacote para aprendizado em dados tabulares e de texto com transformadores</title_pt>
      <title_ar>حزمة للتعلم على البيانات الجدولية والنصية باستخدام المحولات</title_ar>
      <title_fr>Un package pour l'apprentissage des données tabulaires et textuelles avec Transformers</title_fr>
      <title_es>Un paquete para aprender datos tabulares y de texto con Transformers</title_es>
      <title_ja>変圧器を使用した表形式およびテキストデータの学習パッケージ</title_ja>
      <title_zh>用转换器学表格及文本数软件包</title_zh>
      <title_hi>ट्रांसफॉर्मर के साथ सारणीबद्ध और पाठ डेटा पर सीखने के लिए एक पैकेज</title_hi>
      <title_ru>Пакет для обучения табличным и текстовым данным с трансформаторами</title_ru>
      <title_ga>Pacáiste le haghaidh Foghlama ar Shonraí Tábla agus Téacs le Claochladáin</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>Táblázatos és szöveges adatok tanulására szolgáló csomag transzformátorokkal</title_hu>
      <title_it>Un pacchetto per imparare sui dati tabulari e di testo con i trasformatori</title_it>
      <title_el>Ένα πακέτο για τη μάθηση σε δεδομένα πίνακα και κειμένου με μετασχηματιστές</title_el>
      <title_kk>Қойындық мен мәтін деректерінің оқыту дестесіName</title_kk>
      <title_lt>A Package for Learning on Tabular and Text Data with Transformers</title_lt>
      <title_ms>A Package for Learning on Tabular and Text Data with Transformers</title_ms>
      <title_ml>Name</title_ml>
      <title_mk>Пакет за учење на таблички и текстови податоци со трансформирачиName</title_mk>
      <title_mn>Хүснэгт болон Текст өгөгдлийн тухай сурах багц</title_mn>
      <title_no>Name</title_no>
      <title_ro>Un pachet pentru învățarea datelor tabulare și text cu transformatoare</title_ro>
      <title_mt>Pakkett għat-Tagħlim fuq Dejta Tabulari u tat-Test bi Trasformaturi</title_mt>
      <title_sr>Paket za učenje na tabularnim i tekstskim podacima sa transformatorima</title_sr>
      <title_si>Name</title_si>
      <title_sv>Ett paket för att lära sig om tabeller och textdata med transformatorer</title_sv>
      <title_so>A package for Learning on Table and Text Data with Transformers</title_so>
      <title_ta>Name</title_ta>
      <title_ur>Name</title_ur>
      <title_pl>Pakiet do nauki o danych tabelarnych i tekstowych z transformatorami</title_pl>
      <title_uz>Name</title_uz>
      <title_vi>Một gói tin để học trên các hình ảnh và các dữ liệu văn bản có biến hình</title_vi>
      <title_bg>Пакет за обучение на таблици и текстови данни с трансформатори</title_bg>
      <title_nl>Een pakket voor leren over tabelvormige en tekstgegevens met transformers</title_nl>
      <title_da>En pakke til læring om tabel- og tekstdata med transformatorer</title_da>
      <title_hr>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</title_hr>
      <title_de>Ein Paket zum Lernen von Tabellen- und Textdaten mit Transformatoren</title_de>
      <title_id>Pakej untuk Belajar di Data Tabular dan Teks dengan Transformer</title_id>
      <title_ko>Transformers 학습 표 및 텍스트 데이터를 사용하는 패키지</title_ko>
      <title_fa>Name</title_fa>
      <title_sw>Mpaka wa kujifunza kwenye Taarifa za Tabili na Matandao yenye Wasafiri</title_sw>
      <title_tr>Täbler we Metin Maglumaty Üýtgetmek üçin bir Paket</title_tr>
      <title_hy>Comment</title_hy>
      <title_af>Name</title_af>
      <title_am>Table and Text Data with Transformers</title_am>
      <title_sq>Një paketë për mësim në të dhënat tabelore dhe tekstore me transformues</title_sq>
      <title_bn>Name</title_bn>
      <title_bs>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</title_bs>
      <title_az>T톛rc칲m톛 v톛 Metin Veril톛ri il톛 칐yr톛nm톛k 칲칞칲n Paket</title_az>
      <title_ca>Un paquet d'aprenentatge a les dades tabulars i textuals amb transformadors</title_ca>
      <title_et>Pakett tabel- ja tekstiandmete õppimiseks transformaatoritega</title_et>
      <title_fi>Paketti taulukkotietojen ja tekstitietojen oppimiseen muuntajien avulla</title_fi>
      <title_cs>Balíček pro výuku tabulkových a textových dat s transformátory</title_cs>
      <title_jv>Name</title_jv>
      <title_ha>A Package for Learning on Tabular and Text Data with Transformers</title_ha>
      <title_he>חבילה ללמוד על מידע טקסט ולשולחן עם מעצבים</title_he>
      <title_sk>Paket za učenje tabelarnih in besedilnih podatkov s transformatorji</title_sk>
      <title_bo>ཤོག་བྱང་དང་ཡི་གེའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་བསུབ་པའི་སྒྲིག་སྟངས</title_bo>
      <abstract_fr>Les récents progrès dans le traitement du langage naturel ont conduit les architectures Transformer à devenir le modèle prédominant utilisé pour les tâches en langage naturel. Cependant, dans de nombreux ensembles de données du monde réel, des modalités supplémentaires sont incluses que le Transformer n'exploite pas directement. Nous présentons Multimodal-Toolkit, un package Python open source permettant d'intégrer du texte et des données tabulaires (catégoriques et numériques) avec Transformers pour les applications en aval. Notre boîte à outils s'intègre parfaitement à l'API existante de Hugging Face, telle que la tokenisation et le hub de modèles, qui permet de télécharger facilement différents modèles pré-entraînés.</abstract_fr>
      <abstract_ar>أدى التقدم الأخير في معالجة اللغة الطبيعية إلى أن تصبح معماريات Transformer هي النموذج السائد المستخدم في مهام اللغة الطبيعية. ومع ذلك ، في العديد من مجموعات البيانات في العالم الحقيقي ، يتم تضمين طرائق إضافية لا يستفيد منها المحول بشكل مباشر. نقدم مجموعة الأدوات متعددة الوسائط ، وهي حزمة Python مفتوحة المصدر لدمج البيانات النصية والجداول (الفئوية والرقمية) مع المحولات للتطبيقات النهائية. تتكامل مجموعة الأدوات الخاصة بنا بشكل جيد مع واجهة برمجة التطبيقات الحالية لـ Hugging Face مثل الرمز المميز ومحور النموذج الذي يسمح بتنزيل نماذج مختلفة مُدربة مسبقًا بسهولة.</abstract_ar>
      <abstract_es>El progreso reciente en el procesamiento del lenguaje natural ha llevado a que las arquitecturas Transformer se conviertan en el modelo predominante utilizado para las tareas del lenguaje natural. Sin embargo, en muchos conjuntos de datos del mundo real, se incluyen modalidades adicionales que el Transformer no aprovecha directamente. Presentamos Multimodal- Toolkit, un paquete Python de código abierto para incorporar texto y datos tabulares (categóricos y numéricos) con Transformers para aplicaciones posteriores. Nuestro kit de herramientas se integra bien con la API existente de Hugging Face, como la tokenización y el centro de modelos, que permite descargar fácilmente diferentes modelos previamente entrenados.</abstract_es>
      <abstract_pt>O progresso recente no processamento de linguagem natural fez com que as arquiteturas Transformer se tornassem o modelo predominante usado para tarefas de linguagem natural. No entanto, em muitos conjuntos de dados do mundo real, são incluídas modalidades adicionais que o Transformer não aproveita diretamente. Apresentamos o Multimodal- Toolkit, um pacote Python de código aberto para incorporar texto e dados tabulares (categóricos e numéricos) com Transformers para aplicativos downstream. Nosso kit de ferramentas se integra bem com a API existente do Hugging Face, como tokenização e o hub de modelos, que permite o download fácil de diferentes modelos pré-treinados.</abstract_pt>
      <abstract_ja>自然言語処理の最近の進歩により、Transformerアーキテクチャは自然言語タスクに使用される主なモデルになりました。しかし、多くの現実世界のデータセットでは、トランスフォーマーが直接レバレッジしない追加のモダリティが含まれています。マルチモーダルツールキットは、オープンソースのPythonパッケージで、下流アプリケーションのためのTransformersとのテキストおよび表形式（カテゴリおよび数値）データを組み込むことができます。当社のツールキットは、トークン化やモデルハブなど、Hugging Faceの既存のAPIとうまく統合されており、さまざまな事前にトレーニングを受けたモデルを簡単にダウンロードできます。</abstract_ja>
      <abstract_hi>प्राकृतिक भाषा प्रसंस्करण में हाल की प्रगति ने ट्रांसफॉर्मर आर्किटेक्चर को प्राकृतिक भाषा कार्यों के लिए उपयोग किया जाने वाला प्रमुख मॉडल बनने के लिए प्रेरित किया है। हालांकि, कई वास्तविक दुनिया के डेटासेट में, अतिरिक्त तौर-तरीकों को शामिल किया गया है जो ट्रांसफॉर्मर सीधे लाभ नहीं उठाता है। हम मल्टीमॉडल-टूलकिट, डाउनस्ट्रीम अनुप्रयोगों के लिए ट्रांसफॉर्मर के साथ पाठ और सारणीबद्ध (स्पष्ट और संख्यात्मक) डेटा को शामिल करने के लिए एक ओपन-सोर्स पायथन पैकेज प्रस्तुत करते हैं। हमारा टूलकिट फेस के मौजूदा एपीआई जैसे टोकनाइजेशन और मॉडल हब को गले लगाने के साथ अच्छी तरह से एकीकृत करता है जो विभिन्न पूर्व-प्रशिक्षित मॉडलों के आसान डाउनलोड की अनुमति देता है।</abstract_hi>
      <abstract_zh>自然语言理之最新进展Transformer架构为自然语言务大体。 然世界数集,变形金刚无径用者模态。 余言Multimodal-Toolkit,此一开源Python包也,以合文本与表格(数)数与Transformers并为下流应用程序。 吾工具包与Hugging Face之见API善相聚,若标化与中心,可以轻下载异者。</abstract_zh>
      <abstract_ru>Недавний прогресс в обработке естественного языка привел к тому, что архитектуры трансформаторов стали преобладающей моделью, используемой для задач естественного языка. Тем не менее, во многих наборах данных реального мира включены дополнительные модальности, которые Трансформер напрямую не использует. Мы представляем Multimodal- Toolkit, пакет Python с открытым исходным кодом для интеграции текстовых и табличных (категориальных и числовых) данных с Трансформаторами для последующего применения. Наш инструментарий хорошо интегрируется с существующим API Hugging Face, таким как токенизация и концентратор моделей, который позволяет легко загружать различные предварительно обученные модели.</abstract_ru>
      <abstract_ga>Mar gheall ar an dul chun cinn a rinneadh le déanaí i bpróiseáil teanga nádúrtha is í ailtireacht Claochladáin an príomh-mhúnla a úsáidtear do thascanna nádúrtha teanga. Mar sin féin, i go leor tacar sonraí den fhíorshaol, cuirtear módúlachtaí breise san áireamh nach ndéanann an Trasfhoirmeoir giaráil díreach orthu. Cuirimid i láthair Multimodal- Toolkit, pacáiste foinse oscailte Python chun téacs agus sonraí tábla (catagóireacha agus uimhriúla) a ionchorprú le Transformers le haghaidh feidhmchláir iartheachtacha. Comhtháthaíonn ár bhfoireann uirlisí go maith leis an API atá ann cheana féin Hugging Face ar nós tokenization agus an mol múnla a cheadaíonn samhlacha réamhoilte éagsúla a íoslódáil go héasca.</abstract_ga>
      <abstract_ka>მიმდინარე პროგრესი თავისუფალური ენის პროცესის შესახებ ტრანფორმეტრის აქტიქტიქტურების შესახებ, რომელიც თავისუფალური ენის დავალებებისთვის გამ მაგრამ, ბევრი რეალური მსოფლიოს მონაცემების კონფიგურაციაში, დამატებული მოდილიტები ჩვენებულია, რომლებიც ტრანფიგურაციატორი არ ექსტურ ჩვენ მრავალმედიალური ხელსაწყობილობის კონფიგურაცია, გახსნილი Python ფოკეტის პაკეტი, რომელიც ტექსტის და ტაბულური (კატეგორიალური და ციფრიური) მონაცემების შეყვარე ჩვენი ხელსაწყოთა კიტი ძალიან ინტერგურაცია, როგორც ტოკენიზაცია და მოდელური ჰუბი, რომელიც განსხვავებული პრე-განსწავლებული მოდელების განმავლობაში ადვილი გადატანა.</abstract_ka>
      <abstract_el>Η πρόσφατη πρόοδος στην επεξεργασία φυσικής γλώσσας έχει οδηγήσει στις αρχιτεκτονικές μετασχηματιστών να γίνουν το κυρίαρχο μοντέλο που χρησιμοποιείται για εργασίες φυσικής γλώσσας. Ωστόσο, σε πολλά σύνολα δεδομένων πραγματικού κόσμου, περιλαμβάνονται πρόσθετες λεπτομέρειες τις οποίες ο μετασχηματιστής δεν αξιοποιεί άμεσα. Παρουσιάζουμε ένα πακέτο ανοιχτού κώδικα για την ενσωμάτωση κειμένου και πινάκων (κατηγορηματικών και αριθμητικών) δεδομένων με μετασχηματιστές για μεταγενέστερες εφαρμογές. Η εργαλειοθήκη μας ενσωματώνεται καλά με το υπάρχον όπως η επισήμανση και ο κόμβος μοντέλου που επιτρέπει την εύκολη λήψη διαφορετικών προ-εκπαιδευμένων μοντέλων.</abstract_el>
      <abstract_hu>A természetes nyelv feldolgozásának közelmúltbeli fejlődése miatt a Transformer architektúrák a természetes nyelvi feladatok meghatározó modelljévé váltak. Számos valós adatkészletben azonban további módszereket is tartalmaznak, amelyeket a Transzformátor nem használ közvetlenül. Bemutatjuk a Multimodális- Toolkit-et, egy nyílt forráskódú Python csomagot, amely szöveget és táblázatos (kategorikus és numerikus) adatokat foglal magába a transzformátorokkal downstream alkalmazásokhoz. Eszközkészletünk jól integrálódik a Hugging Face meglévő API-jával, mint például a tokenizáció és a modell hub, amely lehetővé teszi a különböző előre képzett modellek egyszerű letöltését.</abstract_hu>
      <abstract_kk>Табиғи тіл процессінің жаңа жағдайда архитектураларды түрлендіру үшін табиғи тіл тапсырмалар үшін қолданылатын үлгі болады. Бірақ көптеген шын әлемдегі деректер қорларында Трансформациясы тікелей тәртіпке жеткізбейтін қосымша әдістер қосылады. Мәтін мен кестелер (сандар мен сандар) деректерін төменгі қолданбалар үшін Трансформациялау құралдарының көшірмесі Python бағдарламасының көшірмесі. Біздің құралдар панеліміз Hugging Face- дің барлық API мен бірге біріктіреді, мысалы, токенизациялау мен өзгертілген алдындағы моделдерді оңай жүктеуге мүмкіндік беретін моделдерді.</abstract_kk>
      <abstract_lt>Pastaruoju metu gamtinės kalbos apdorojimo pažanga lėmė, kad transformuotojų architektūros tapo vyraujančiu gamtinės kalbos užduotims naudojamu modeliu. However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage.  Mes pristatome Multimodal- Toolkit, atviro kodo Python paketą, kuriame bus įtraukti teksto ir lentelių (kategorijinių ir skaitmeninių) duomenys su Transformers tolesnėms programoms. Mūs ų įrankių rinkinys gerai integruojamas su esama Hugging Face API, pvz., tokenizacija ir modelio centras, kuris leidžia lengvai parsisiųsti įvairius iš anksto parengtus modelius.</abstract_lt>
      <abstract_mk>Неодамнешниот напредок во природното обработување на јазиците доведе до трансформарните архитектури да станат претежниот модел кој се користи за природните јазични задачи. Сепак, во многу податоци од реалниот свет се вклучени дополнителни модијали кои Трансформерот не ги влијае директно. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_mk>
      <abstract_it>I recenti progressi nell'elaborazione del linguaggio naturale hanno portato le architetture Transformer a diventare il modello predominante utilizzato per le attività di linguaggio naturale. Tuttavia, in molti dataset del mondo reale, sono incluse modalità aggiuntive che il Transformer non sfrutta direttamente. Vi presentiamo Multimodal- Toolkit, un pacchetto Python open source per incorporare testo e dati tabulari (categorici e numerici) con Transformers per applicazioni downstream. Il nostro toolkit si integra bene con l'API esistente di Hugging Face come la tokenizzazione e l'hub del modello che consente di scaricare facilmente diversi modelli pre-addestrati.</abstract_it>
      <abstract_ms>Kemajuan baru-baru ini dalam pemprosesan bahasa alami telah menyebabkan arkitektur Transformer menjadi model utama yang digunakan untuk tugas bahasa alami. Bagaimanapun, dalam banyak set data dunia nyata, modaliti tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami perkenalkan Multimodal- Toolkit, pakej Python sumber terbuka untuk menggabungkan teks dan data tabular (kategori dan nombor) dengan Transformers untuk aplikasi turun. Kit alat kami menyertai dengan baik dengan API yang wujud Hugging Face seperti tokenization dan hub model yang membolehkan muat turun mudah bagi model yang berlainan yang dilatih.</abstract_ms>
      <abstract_mn>Байгалийн хэл үйлдвэрлэлийн саяхан хөгжлийн үр дүнд байгалийн хэл үйлдвэрлэлд хэрэглэгддэг архитектурууд Трансфер архитектурууд болж ирсэн. Гэхдээ маш олон бодит ертөнцийн өгөгдлийн санд Трансформатор шууд хэрэглэхгүй нэмэлт арга замыг нэмэгдүүлдэг. Бид олон моделийн хэрэгсэл бөгөөд, нээлттэй эх үүсвэртэй Python багцлагыг өгөгдлийг доорх хэрэглэмжүүдийн Трансформ болон таблицын (категорийн болон тоон) өгөгдлийг нэгтгэх болно. Бидний хэрэгслийн суурь нь Hugging Face-ийн суурилсан API-тэй сайн нэгтгэдэг. Яг л тодорхойлолт, загварын холбоотой. Энэ нь өөр олон сургалтын өмнө сургалтын загваруудыг хялбар авах боломжтой бол</abstract_mn>
      <abstract_ml>സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷയുടെ അടുത്തുള്ള പുരോഗതി സ്വാഭാവിക ഭാഷയുടെ ജോലികള്‍ക്കായി ഉപയോഗിക്കുന്ന പ്രകൃ എന്നാലും, പലതും യഥാര്‍ത്ഥ ലോക ഡാറ്റാസറ്റുകളില്‍, കൂടുതല്‍ മാറ്റങ്ങള്‍ നേരിട്ട് ട്രാന്‍സ്ഫോര്‍മാര്‍ നേരിട്ട്  ടെക്സ്റ്റും ടാബുളും (categorical and numerical) ഡേറ്ററുകളുമായി ട്രാന്‍സ്ട്രീമില്‍ പ്രയോഗങ്ങള്‍ക്ക് വേണ്ടി ട്രാന്‍സ്ഫോര്‍മാരുമായി ഒരു തുറന്ന സോ ഞങ്ങളുടെ ഉപകരണക്കിടം ഹുഗിംഗ് മുഖം നിലവിലുള്ള ഏപിഐ പോലെ ഒരുമിച്ചിരിക്കുന്നു. ടോണിക്ഷനേഷനും മോഡല്‍ ഹുബും പോലെ വ്യത്യസ്ത പരിശീ</abstract_ml>
      <abstract_pl>Ostatnie postępy w przetwarzaniu języka naturalnego doprowadziły do tego, że architektury Transformera stały się dominującym modelem stosowanym do zadań języka naturalnego. Jednak w wielu zbiorach danych świata rzeczywistego zawiera się dodatkowe modalności, których Transformer nie wykorzystuje bezpośrednio. Przedstawiamy Multimodal- Toolkit, open-source pakiet Pythona, który umożliwia włączenie danych tekstowych i tabelarnych (kategorycznych i numerycznych) z Transformerami do dalszych aplikacji. Nasz zestaw narzędzi dobrze integruje się z istniejącym interfejsem API Hugging Face, takim jak tokenizacja i centrum modelu, który umożliwia łatwe pobieranie różnych wstępnie przeszkolonych modeli.</abstract_pl>
      <abstract_sr>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu predominantni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim stvarnim svijetskim podacima, uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket otvorenog izvora Python za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformacijama za programe koji se nalaze niz stranu. Naš toolkit se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</abstract_sr>
      <abstract_ro>Progresele recente în procesarea limbajului natural au condus la arhitecturile Transformer devenind modelul predominant utilizat pentru sarcinile de limbaj natural. Cu toate acestea, în multe seturi de date din lumea reală, sunt incluse modalități suplimentare pe care Transformerul nu le utilizează direct. Vă prezentăm Multimodal- Toolkit, un pachet Python open-source pentru a încorpora text și date tabulare (categorice și numerice) cu Transformers pentru aplicații din aval. Setul nostru de instrumente se integrează bine cu API-ul existent al Hugging Face, cum ar fi tokenizarea și hub-ul modelului, care permite descărcarea ușoară a diferitelor modele pre-instruite.</abstract_ro>
      <abstract_no>Nyleg framgang i naturspråkshandtering har ført til å transformera arkitektur bli den viktigste modellen brukt for naturspråksoppgåver. I mange verdsetata er imidlertid tilleggsmodular som Transformeren ikkje direkte leverer. Vi presenterer multimodal verktøykassett, eit opna kjeldepakke for Python som inkluderer tekst og tabulatordata (kategorisk og numerisk) med Transformerer for nedstrekkprogram. Vårt verktøykassett integrerer godt med den eksisterande API til Hugging Face som tokenisering og modellhuben som tillater enkelt nedlasting av ulike føretrengde modeller.</abstract_no>
      <abstract_so>Horumarinta ugu dambeysa ee baaraandegista luqada dabiicadda ah wuxuu u keenay dhismaha wareejinta oo ay noqdaan modelkii ugu horeeya ee loo isticmaalay shaqooyinka afka dabiicadda ah. Si kastaba ha ahaatee, waxaa ku jira habab dheeraad ah oo uu turjubaanku si toos ah u isticmaalayo. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Qorigayada qalabka ayaa si wanaagsan u qabsada afka Hugging ee uu heysto API, tusaale ahaan calaamad iyo muusikada, kaas oo sahlan soo dejin kara modello kala duduwan oo horay loo tababaray.</abstract_so>
      <abstract_ta>சமீபத்தில் இயல்பான மொழி செயல்படுத்தலின் முன்னேற்றம் இயல்பான மொழி பணிகளுக்கு பயன்படுத்தப்பட்ட முக்கிய மாதிரியான ம ஆனால், பல உண்மையான- உலக தரவுத்தளங்களில், மாற்றி நேரடியாக ஒப்புக்கொள்ளாத கூடுதல் வகைகள் உள்ளன. நாங்கள் பல மூலக் கருவிப்புக்கூட்டு, ஒரு திறந்த மூலத்தின் பைதான் தொகுப்பு, உரையை மற்றும் அட்டவணை (வகையான மற்றும் எண்ணிக்கை) தகவல்களை கூட்டு எங்கள் கருவிப்பெட்டி ஹங்கிங் முகத்தில் இருக்கும் API போன்ற ஒருங்கிணைக்கும், அது வேறு முன் பயிற்சிக்கப்பட்ட மாதிரிகளின் எளிதாக</abstract_ta>
      <abstract_sv>De senaste framstegen inom bearbetningen av naturligt språk har lett till att Transformer-arkitekturer blivit den dominerande modellen som används för naturliga språkuppgifter. Men i många verkliga datauppsättningar ingår ytterligare metoder som Transformern inte direkt utnyttjar. Vi presenterar Multimodal- Toolkit, ett Python-paket med öppen källkod för att införliva text och tabelldata (kategoriska och numeriska) med Transformers för nedströms applikationer. Vår verktygslåda integreras väl med Hugging Faces befintliga API såsom tokenisering och modellhubben som gör det enkelt att ladda ner olika förintränade modeller.</abstract_sv>
      <abstract_ur>طبیعی زبان پردازی میں اچھی پیشرفت کی وجہ سے تغییر معماری بنانے کے لئے طبیعی زبان کے کاموں کے لئے استعمال کیا جاتا ہے۔ However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage. ہم ملٹی موڈال- تولکیٹ کو پیش کریں گے، ایک کھولی- سورس پیٹون پاکس کے لئے پاکستان اور ٹاکلور (کاٹی اور شماری) ڈائٹ ڈونسٹریم کاربریوں کے ساتھ تغییرات کرنے والوں کے ساتھ شامل کریں گے۔ ہماری تولیک کیٹ ہیونگ فیس کے موجود API کے ساتھ اچھی طرح تفسیر کرتی ہے جیسے ٹوکنیزی اور موڈل ہب جو مختلف پیش آموزش کی موڈلیوں کے آسان ڈونلوڈ کی اجازت دیتا ہے.</abstract_ur>
      <abstract_mt>Recent progress in natural language processing has led to Transformer architectures becoming the predominant model used for natural language tasks.  However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage.  We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_mt>
      <abstract_si>ස්වාභාවික භාෂාව ප්‍රක්‍රියාපනයේ අන්තිම ප්‍රභාවිත විද්‍යාපනය විද්‍යාපනය කරනවා ස්වාභික භාෂා නමුත්, ඇත්ත- ලෝකයේ දත්ත සෙට් වලින්, තවත් මොඩියුල් සම්බන්ධ වෙලා තියෙන්නේ මොඩියුල් තියෙන්නේ ම Name අපේ උපකරණ කිට් හොඳටම හුගින් ෆේස්ගේ තියෙන ඉන්න API වලින් ටොකෙනිස් සහ මොඩේල් හුබ් වලින් සමහර විවිධ ප්‍රධානය කරපු</abstract_si>
      <abstract_uz>@ info: whatsthis Ammo, ko'pchilik dunyo maʼlumotlar tarkibida, Transfer toʻgʻri ishlatilmagan qoʻshimcha usullar bor. @ info: whatsthis Bizning asboblar kitoblarimiz Hugging Faceb mavjud API bilan birga birlashtiriladi. Bu model hub boshqa taʼminlovchi modellarni yozib olish imkoniyatini yordam beradi.</abstract_uz>
      <abstract_vi>Sự tiến bộ gần đây trong việc xử lý ngôn ngữ tự nhiên đã khiến các kiến trúc biến hình thành mô hình nổi bật sử dụng cho các nhiệm vụ ngôn ngữ tự nhiên. Tuy nhiên, trong nhiều bộ dữ liệu thế giới thực, có thêm phương thức mà Transformer không trực tiếp hoạt động. Chúng tôi giới thiệu các tập cụ đa phương, một gói Python mở nguồn để cung cấp các dữ liệu cấu hình (và số) dứt điểm với các biến hình cho các ứng dụng xuôi dòng. Bộ hỗ trợ của chúng ta hòa hợp tốt với API hiện có của Huging Face như tokenition và mô hình trung tâm cho phép tải tải xuống dễ dàng các mẫu đã được huấn luyện.</abstract_vi>
      <abstract_bg>Последният напредък в обработката на естествения език доведе до превръщането на архитектурите на трансформаторите в преобладаващия модел, използван за задачи с естествен език. Въпреки това, в много реални набори от данни са включени допълнителни модификации, които трансформаторът не използва пряко. Представяме Мултимодален инструментариум, пакет с отворен код за включване на текстови и таблични (категорични и цифрови) данни с трансформатори за приложения надолу по веригата. Нашият инструментариум се интегрира добре със съществуващия API като токенизация и моделния хъб, който позволява лесно изтегляне на различни предварително обучени модели.</abstract_bg>
      <abstract_hr>Nedavno napredak prirodnog obrazovanja jezika doveo je do arhitekture transformera postajući predsjednik koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne primjenjuje direktno. Predstavljamo Multimodalni Toolkit, otvoreni Python paket za uključivanje teksta i tabularnih (kategorijskih i brojnih) podataka s transformacijama za prijave za dolje. Naš alat se dobro uključuje s postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako preuzimanje različitih predobučenih modela.</abstract_hr>
      <abstract_nl>Recente vooruitgang in de verwerking van natuurlijke taal heeft ertoe geleid dat Transformer architecturen het dominante model zijn geworden voor natuurlijke taaltaken. In veel real-world datasets zijn echter aanvullende modaliteiten opgenomen die de Transformer niet direct benut. We presenteren Multimodal-Toolkit, een open-source Python pakket om tekst en tabulaire (categorische en numerieke) gegevens te integreren met Transformers voor downstream toepassingen. Onze toolkit integreert goed met Hugging Face's bestaande API, zoals tokenization en de model hub, waardoor verschillende voorgetrainde modellen eenvoudig kunnen worden gedownload.</abstract_nl>
      <abstract_da>Nylige fremskridt inden for behandling af naturligt sprog har ført til, at Transformer-arkitekturer er blevet den dominerende model, der anvendes til opgaver med naturligt sprog. Men i mange datasæt i den virkelige verden, er yderligere modaliteter inkluderet, som Transformeren ikke direkte udnytter. Vi præsenterer Multimodal-Toolkit, en open source Python pakke til at indarbejde tekst og tabel (kategoriske og numeriske) data med Transformers til downstream applikationer. Vores værktøjssæt integrerer godt med Hugging Face's eksisterende API såsom tokenisering og model hub, som gør det nemt at downloade forskellige præ-trænede modeller.</abstract_da>
      <abstract_id>Kemajuan baru-baru ini dalam proses bahasa alam telah menyebabkan arsitektur Transformer menjadi model dominan yang digunakan untuk tugas bahasa alam. Namun, dalam banyak set data dunia nyata, modalitas tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami mempersembahkan Multimodal- Toolkit, sebuah paket Python sumber terbuka untuk memasukkan teks dan data tabular (kategori dan numerik) dengan Transformers untuk aplikasi turun. Paket alat kita terintegrasi dengan API yang ada Hugging Face seperti tokenization dan model hub yang memungkinkan muat turun mudah dari model yang berlatih.</abstract_id>
      <abstract_de>Die jüngsten Fortschritte in der Verarbeitung natürlicher Sprache haben dazu geführt, dass Transformer-Architekturen das vorherrschende Modell für Aufgaben natürlicher Sprache geworden sind. In vielen realen Datensätzen sind jedoch zusätzliche Modalitäten enthalten, die der Transformer nicht direkt nutzt. Wir präsentieren Multimodal-Toolkit, ein Open-Source Python-Paket, das Text und tabellarische (kategorische und numerische) Daten mit Transformern für nachgelagerte Anwendungen integriert. Unser Toolkit lässt sich gut mit Hugging Face's bestehender API wie Tokenisierung und dem Model Hub integrieren, der einen einfachen Download verschiedener vortrainierter Modelle ermöglicht.</abstract_de>
      <abstract_sw>Maendeleo ya hivi karibuni katika upasuaji wa lugha za asili yamesababisha majengo ya Kupitisha kuwa modeli muhimu inayotumiwa kwa ajili ya kazi za lugha za asili. Hata hivyo, katika seti nyingi za taarifa za dunia halisi, mbinu za ziada zinajumuisha ambazo WaTransfer hawatumii moja kwa moja. Tunaweza kuweka kituo cha Kifaa cha Multimodal-Tool, kitengele cha Python kilicho wazi kwa ajili ya kuingiza taarifa za maandishi na tabia (makundi na tarakimu) kwa ajili ya matumizi ya mitandao ya chini. Vifaa vyetu vinaunganisha vizuri na API iliyopo Hugging Face kama vile uthibitisho na kituo cha modeli ambacho kinaruhusu kupandisha mifano tofauti ya mafunzo ya awali.</abstract_sw>
      <abstract_tr>Doýal diller işlemeginiň öňki täzelikleri tebigy diller üçin ullanýan arhitekturlary üýtgedir. Ýöne, birnäçe sanat dünýäde maglumat setirlerinde, esasy modlerde terjime etmeýän modlerde dahil edildi. Biz Multimodal-Esbap zolaky, Açyk-çeşme Python paketi metin we täblikler (kategoriýal we sayyk) maglumaty aşaky uygulamalar üçin terjime etmek üçin bir paketi görkeýäris Biziň alet çykyşlarymyz Hugging Face'iň bar API bilen gowy birleştirilýär. Öňünden öňünden bilinmiş modelleriň ýeňil ýüklemegine mümkin edýän nusgalary.</abstract_tr>
      <abstract_ko>자연 언어 처리의 최신 진전은 변환기 구조를 자연 언어 임무의 주요 모델로 만들었다.그러나 많은 실제 세계의 데이터가 집중되어 변압기가 직접적으로 이용하지 않는 다른 모델을 포함하고 있다.우리는 텍스트와 표 (분류, 디지털) 데이터를 변환기와 결합시켜 하위 응용 프로그램에 사용하는Multimodal-Toolkit을 보여 줍니다.Google 패키지는 Hugging Face의 기존 API(예를 들어 표기화)와 모델 센터(model hub)와 잘 통합되어 서로 다른 예비 트레이닝 모델을 쉽게 다운로드할 수 있습니다.</abstract_ko>
      <abstract_fa>پیشرفت اخیرا در پردازش زبان طبیعی به معماری تغییر دهنده به عنوان مدل پیشوایی که برای کار زبان طبیعی استفاده می‌شود تبدیل می‌شود. با این حال، در بسیاری از مجموعه‌های داده‌های واقعی دنیا، modalities additional include which the Transformer does not directly leverage. ما کیت multimodal- Toolkit را نشان می‌دهیم، یک بسته Python منبع باز برای شامل کردن متن و اطلاعات تبلیک (kategorical and numerical) با تغییردهندگان برای کاربردهای پایین سیستم. وسیله‌های ما با API موجود Hugging Face مثل توکین کردن و مدل‌هایی که اجازه می‌دهد آسان دانلود از مدل‌های پیش آموزش متفاوت را فراهم کند.</abstract_fa>
      <abstract_sq>Përparimi i fundit në procesimin natyror të gjuhës ka shpjerë në arkitekturat Transformer të bëhen modeli mbizotërues i përdorur për detyrat natyrore të gjuhës. Megjithatë, në shumë grupe të dhënash të botës reale, janë përfshirë modalitete shtesë që Transformuesi nuk përfshin drejtpërdrejt. Ne paraqesim Multimodal- Toolkit, një paketë Python me burim të hapur për të përfshirë tekst dhe të dhëna tabulare (kategorike dhe numerike) me Transformers për aplikimet e poshtme. Paketa jonë mjete integrohet mirë me API ekzistuese të Hugging Face si tokenization dhe model hub që lejon shkarkimin e lehtë të modeleve të ndryshme të paratrajnuara.</abstract_sq>
      <abstract_am>አዲስ የፍጥረት ቋንቋ ማቀናጃ ውስጥ የሚደረግ ግንኙነትን ለፍጥረት ቋንቋ ስራ የሚጠቀሙት መሠረት መሆኑን አቀረበ፡፡ ምንም እንኳን፣ በብዙ እውነተኛ- ዓለም ዳታዎች ውስጥ፣ በተጨማሪው ድርጅቶች በተጨማሪው ድርጅቶች ውስጥ የተገቡ ናቸው፡፡ Multimodal-Toolkit, open-source Python ጥቅል እና tabular (categorical and numerical) data with Transformers for downstream applications ለማግባት ነው፡፡ የመልኮታችን መሣሪያዎች የHugging ፊታችንን እንደምሳሌ ማስታወቂያ እና የሞዴል ክፍል በተለየ የፊደል ሞዴላዎችን ማውረድ የሚያስቀላል ነው፡፡</abstract_am>
      <abstract_af>Onlangse vordering in natuurlike taal-prosessering het gelei na Transformer-arkitekturke wat die voordekende model gebruik word vir natuurlike taal-taak. Alhoewel, in baie reël- wêreld datastelle, is addisionele modaliteite ingesluit wat die Transformer nie direk verwyder nie. Ons voorsien Multimodal- Nutsbalk, 'n oop- bron Python pakket om teks en tabulêer (kategoriese en numeriese) data te inkorpreer met Transformers vir onderstreem toepassings. Ons nutsbalkit integreer goed met Hugging Face se bestaande API soos tokenisasie en die model hub wat maklik laat af van verskillende voorafoerende modele toe.</abstract_af>
      <abstract_az>Təbiətli dil işləməsində son tədbir tədbir edilməsi təbiətli dil işləri üçün istifadə edilən təbiətli modellərə çevrildi. Ancaq bir çox real dünya verilən qurğularında, Transformer'in düzgün istifadə etmədiyi papildu modüllər daxil edilir. Biz çoxlu-modal-araç çubuğunu, aşağı-aşağı proqramlar üçün Transformers üçün metin və tabular (kategorik və numerik) məlumatları birləşdirmək üçün açıq-kaynak Python paketini göstəririk. Bizim vasitələrimiz Hugging Face'in mövcuddur API ilə yaxşı birləşdirir, çünki tokenizasyon və modeli hub kimi, farklı əvvəlcə təhsil edilmiş modellərin asanlıqlarını indirməyə imkan verir.</abstract_az>
      <abstract_hy>Վերջերս բնական լեզուների վերաբերյալ զարգացումը հանգեցրեց, որ տրանսֆերմերի ճարտարապետությունները դառնան բնական լեզուների խնդիրների համար օգտագործվող գլխավոր մոդելը: Այնուամենայնիվ, շատ իրական աշխարհի տվյալների համակարգերում ներառված են ավելացյալ մեթոդներ, որոնք Transforme-ը անմիջապես չի ազդում: Մենք ներկայացնում ենք Բազմամոդալ-Գործիքների համակարգ, բաց աղբյուր Պիթոն փաթեթ, որը ներառում է տեքստի և տախտային (կատեգորիկական և թվային) տվյալներ Transforme-ների հետ հետագա ծրագրերի համար: Մեր գործիքների շարքը լավ ինտեգրվում է Հուգինգ Ֆեյսի գոյություն ունեցող API-ի հետ, ինչպիսիք են թոկենիզացիան և մոդելի կենտրոնը, որը հնարավորություն է տալիս հեշտ ներբեռնել տարբեր նախապատրաստված մոդելներ:</abstract_hy>
      <abstract_bn>প্রাকৃতিক ভাষা প্রক্রিয়ায় সাম্প্রতিক অগ্রগতি প্রাকৃতিক ভাষার কাজের জন্য ব্যবহৃত প্রাকৃতিক ভাষার কাজের জন্য তবে অনেক বাস্তব-বিশ্বের তথ্য সেটে, যার মধ্যে অন্তর্ভুক্ত বৈষম্য রয়েছে যার মধ্যে ট্রান্সফার্নার নির্দেশ দেয় টেক্সট এবং ট্যাবুল (ক্যাটারেক্টারিক্যাল এবং সংখ্যা) ডাটার অন্তর্ভুক্ত করার জন্য আমরা মাল্টিমোডাল- টুলিকিট, একটি খোলা সোর্স পাইথন আমাদের টুলিকিট হুগিং মুখের বিদ্যমান এপিআই-এর সাথে ভালোভাবে একত্রিত করেছে, যেমন চিহ্নিত বিভিন্ন প্রশিক্ষিত মডেলের সহজে ডাউনলোড</abstract_bn>
      <abstract_bs>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu glavni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket Python otvorenog izvora za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformatorima za programe za snimke. Naš alat se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</abstract_bs>
      <abstract_ca>El progrés recent en el processament natural de llenguatges ha portat a que les arquitectures Transformer es converteixin en el model predominant utilitzat per a tasques de llenguatges naturals. No obstant això, en molts conjunts de dades del món real, s'inclouen modalitats adicionals que el Transformer no utilitza directament. Presentam Multimodal-Toolkit, un paquet de Python de codi obert per incorporar text i dades tabulars (categóriques i numèriques) amb Transformers per aplicacions avall. El nostre conjunt d'eines s'integra bé amb l'API existent d'Hugging Face, com la tocenització i el centre model que permet descarregar fàcilment diferents models pré-entrenats.</abstract_ca>
      <abstract_cs>Nedávný pokrok ve zpracování přirozeného jazyka vedl k tomu, že architektury Transformer se staly dominantním modelem používaným pro úlohy přirozeného jazyka. Nicméně v mnoha skutečných datových sadách jsou zahrnuty další modality, které Transformer přímo nevyužívá. Představujeme Multimodal- Toolkit, open-source Python balíček pro začlenění textových a tabulkových (kategorických a číselných) dat s transformátory pro následné aplikace. Náš nástroj se dobře integruje s existujícím API Hugging Face, jako je tokenizace a modelový hub, který umožňuje snadné stahování různých předškolených modelů.</abstract_cs>
      <abstract_et>Hiljutised edusammud looduskeele töötlemisel on viinud Transformeri arhitektuuride muutumiseni peamiseks mudeliks, mida kasutatakse looduskeele ülesannetes. Paljudes reaalmaailma andmekogumites on siiski lisatud täiendavad meetodid, mida Transformer otseselt ei kasuta. Esitleme Multimodal- Toolkit, avatud lähtekoodiga Pythoni paketti, mis sisaldab teksti- ja tabeliandmeid (kategoorialised ja numbrilised) Transformeritega alljärgnevate rakenduste jaoks. Meie tööriistakomplekt integreerub hästi Hugging Face olemasoleva API-ga, nagu tokeniseerimine ja mudeli hub, mis võimaldab lihtsalt alla laadida erinevaid eeltreenitud mudeleid.</abstract_et>
      <abstract_fi>Luonnonkielen käsittelyn viimeaikainen kehitys on johtanut siihen, että Transformer-arkkitehtuurista on tullut luonnollisissa kielitehtävissä vallitseva malli. Moniin reaalimaailman datakokonaisuuksiin sisältyy kuitenkin muita menetelmiä, joita muuntaja ei suoraan hyödynnä. Esittelemme Multimodal- Toolkit, avoimen lähdekoodin Python-paketin, joka sisältää teksti- ja taulukkotietoja (kategorinen ja numeerinen) Transformers-ohjelmistojen kanssa jatko-sovelluksiin. Työkalupakkimme integroituu hyvin Hugging Facen olemassa olevaan API-rajapintaan, kuten tokenisointiin ja mallikeskukseen, joka mahdollistaa erilaisten esikoulutettujen mallien helpon lataamisen.</abstract_fi>
      <abstract_sk>Nedavni napredek pri obdelavi naravnega jezika je pripeljal do tega, da so arhitekture transformatorjev postale prevladujoči model, ki se uporablja za naloge naravnega jezika. Vendar pa so v številnih resničnih zbirkah podatkov vključene dodatne načine, ki jih transformator ne uporablja neposredno. Predstavljamo Multimodal- Toolkit, odprtokodni paket Python, ki vključuje besedilo in tabularne (kategorične in numerične) podatke s transformatorji za nadaljnje aplikacije. Naš komplet orodij se dobro integrira z obstoječim API-jem Hugging Face, kot sta žetonizacija in vozlišče modela, ki omogoča enostaven prenos različnih predhodno usposobljenih modelov.</abstract_sk>
      <abstract_jv>FindOK politenessoffpolite"), and when there is a change ("assertivepoliteness We present Multimodal- Tool lkit, an open-source Arkit-tool sing ditambah gambaran karo Api yang saben nggawe, lagi tokenizer karo model</abstract_jv>
      <abstract_ha>@ info: whatsthis Amma, cikin masu yawa na danna-duniya masu gaske, akwai wasu shiryoyin dabam da Transformer bã ya gaurar da hanya. Tuna halatar da Shirin Ayuka na Kwamfyuta Tsarin kayan aiki na sami da shirin Hugging Face na da ke gaba kamar shirin ayuka da kwamfyutan ayuka da ke yarda da download masu motsi na daban-danne.</abstract_ha>
      <abstract_bo>རང་བཞིན་གྱི་སྐད་རིགས་ལས་སྦྱོར་བའི་འཕེལ་རིམ་དེ་ནི་བཟོ་བཅོས་ཁང་གཟུགས་རིས་ལ་མཐུན་ནུས་མེད་པའི་རྣམ་གྲངས་སྤ ཡིན་ནའང་། ངོ་མ་འཛམ་གླིང་ཡོད་པའི་གནས་ཚུལ་སྒྲིག་འགོད་མང་པོ་ཞིག་ལ་བཟོ་བཅོས་བྱེད་སྣང་བའི་ཐབས་ལམ་ཁྱབ་སྤྱོད་ We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_bo>
      <abstract_he>התקדמות האחרונה בעבודת שפת טבעית הובילה לארכיטקטורות טרנספורטר להפוך למודל הכי גדול שמשתמש למשימות שפת טבעיות. בכל אופן, במערכות נתונים רבות בעולם האמיתי, מודליות נוספות כוללות שהטרנספורטר לא משתמש באופן ישיר. אנחנו מציגים ערכת כלים מורכבת, חבילה Python מקור פתוח כדי לכלול טקסט ומידע טבלה (קטגורית ומספרית) עם Transformers לתוכניות מתחתיות. חבילת הכלים שלנו משתלבת היטב עם API הקיום של Hugging Face כמו tokenization והמרכז המודל שמאפשר להוריד בקלות של דוגמנים מאומנים מראש.</abstract_he>
      </paper>
    <paper id="13">
      <title>Learning to Select Question-Relevant Relations for Visual Question Answering</title>
      <author><first>Jaewoong</first><last>Lee</last></author>
      <author><first>Heejoon</first><last>Lee</last></author>
      <author><first>Hwanhee</first><last>Lee</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>87–96</pages>
      <abstract>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations. However, studies that use GNNs typically ignore the importance of each relation and simply concatenate outputs from multiple relation encoders. In this paper, we propose a novel layer architecture that fuses multiple visual relations through an attention mechanism to address this issue. Specifically, we develop a model that uses question embedding and joint embedding of the encoders to obtain dynamic attention weights with regard to the type of questions. Using the learnable attention weights, the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can efficiently use the necessary visual relation features for a given question. Experimental results on the VQA 2.0 dataset demonstrate that the proposed model outperforms existing graph attention network-based architectures. Additionally, we visualize the attention weight and show that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> assigns a higher weight to relations that are more relevant to the question.</abstract>
      <url hash="e2e33677">2021.maiworkshop-1.13</url>
      <doi>10.18653/v1/2021.maiworkshop-1.13</doi>
      <bibkey>lee-etal-2021-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering-v2-0">Visual Question Answering v2.0</pwcdataset>
    </paper>
  </volume>
</collection>