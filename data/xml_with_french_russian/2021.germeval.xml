<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.germeval">
  <volume id="1" ingest-date="2021-10-22">
    <meta>
      <booktitle>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</booktitle>
      <editor><first>Julian</first><last>Risch</last></editor>
      <editor><first>Anke</first><last>Stoll</last></editor>
      <editor><first>Lena</first><last>Wilms</last></editor>
      <editor><first>Michael</first><last>Wiegand</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Duesseldorf, Germany</address>
      <month>September</month>
      <year>2021</year>
      <url hash="a6114ee1">2021.germeval-1</url>
    </meta>
    <frontmatter>
      <url hash="d35277ad">2021.germeval-1.0</url>
      <bibkey>germeval-2021-germeval</bibkey>
    </frontmatter>
    <paper id="4">
      <title>DFKI SLT at GermEval 2021 : Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments<fixed-case>DFKI</fixed-case> <fixed-case>SLT</fixed-case> at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments</title>
      <author><first>Remi</first><last>Calizzano</last></author>
      <author><first>Malte</first><last>Ostendorff</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>25–31</pages>
      <abstract>We present our submission to the first subtask of GermEval 2021 (classification of German Facebook comments as toxic or not). Binary sequence classification is a standard NLP task with known state-of-the-art methods. Therefore, we focus on <a href="https://en.wikipedia.org/wiki/Data_preparation">data preparation</a> by using two different techniques : task-specific pre-training and <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>. First, we pre-train multilingual transformers (XLM-RoBERTa and MT5) on 12 hatespeech detection datasets in nine different languages. In terms of F1, we notice an improvement of 10 % on average, using task-specific pre-training. Second, we perform <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> by labelling unlabelled comments, taken from <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>, to increase the size of the training dataset by 79 %. Models trained on the augmented training dataset obtain on average +0.0282 (+5 %) <a href="https://en.wikipedia.org/wiki/F-number">F1 score</a> compared to <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on the original training dataset. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5. The code of the project is available at : https://github.com/airKlizz/germeval2021toxic.</abstract>
      <url hash="ba6470d5">2021.germeval-1.4</url>
      <bibkey>calizzano-etal-2021-dfki</bibkey>
      <pwccode url="https://github.com/airklizz/germeval2021toxic" additional="false">airklizz/germeval2021toxic</pwccode>
    </paper>
    <paper id="5">
      <title>WLV-RIT at GermEval 2021 : Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments<fixed-case>WLV</fixed-case>-<fixed-case>RIT</fixed-case> at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments</title>
      <author><first>Skye</first><last>Morgan</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>32–38</pages>
      <abstract>This paper addresses the identification of toxic, engaging, and fact-claiming comments on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in <a href="https://en.wikipedia.org/wiki/German_language">German</a>. Considering the relatedness of the three tasks, we approached the <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> using large pre-trained transformer models and <a href="https://en.wikipedia.org/wiki/Multitask_learning">multitask learning</a>. Our results indicate that <a href="https://en.wikipedia.org/wiki/Multitask_learning">multitask learning</a> achieves performance superior to the more common single task learning approach in all three tasks. We submit our best systems to GermEval-2021 under the team name WLV-RIT.</abstract>
      <url hash="b8a3edc3">2021.germeval-1.5</url>
      <bibkey>morgan-etal-2021-wlv</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="10">
      <title>TUW-Inf at GermEval2021 : Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments<fixed-case>TUW</fixed-case>-<fixed-case>I</fixed-case>nf at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments</title>
      <author><first>Kinga</first><last>Gémes</last></author>
      <author><first>Gábor</first><last>Recski</last></author>
      <pages>69–75</pages>
      <abstract>This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.</abstract>
      <url hash="9143b01d">2021.germeval-1.10</url>
      <bibkey>gemes-recski-2021-tuw</bibkey>
    </paper>
    <paper id="13">
      <title>Data Science Kitchen at GermEval 2021 : A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven<fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven</title>
      <author><first>Niclas</first><last>Hildebrandt</last></author>
      <author><first>Benedikt</first><last>Boenninghoff</last></author>
      <author><first>Dennis</first><last>Orth</last></author>
      <author><first>Christopher</first><last>Schymura</last></author>
      <pages>88–94</pages>
      <abstract>This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for <a href="https://en.wikipedia.org/wiki/Fact-checking">fact-checking</a> by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8 %, 69.9 % and 72.5 % for the identification of toxic, engaging, and fact-claiming comments.</abstract>
      <url hash="275a546f">2021.germeval-1.13</url>
      <bibkey>hildebrandt-etal-2021-data</bibkey>
    </paper>
    <paper id="15">
      <title>HunterSpeechLab at GermEval 2021 : Does Your Comment Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification<fixed-case>H</fixed-case>unter<fixed-case>S</fixed-case>peech<fixed-case>L</fixed-case>ab at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for <fixed-case>G</fixed-case>erman Fact-Claiming Comment Classification</title>
      <author><first>Subhadarshi</first><last>Panda</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <pages>100–104</pages>
      <abstract>In this paper we investigate the efficacy of using contextual embeddings from multilingual BERT and <a href="https://en.wikipedia.org/wiki/German_language">German BERT</a> in identifying fact-claiming comments in <a href="https://en.wikipedia.org/wiki/German_language">German</a> on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.</abstract>
      <url hash="a9c73794">2021.germeval-1.15</url>
      <bibkey>panda-levitan-2021-hunterspeechlab</bibkey>
    <title_ar>HunterSpeechLab في GermEval 2021: هل يدعي تعليقك حقيقة؟ الضمانات السياقية لتصنيف تعليقات ادعاء الحقائق الألماني</title_ar>
      <title_pt>HunterSpeechLab no GermEval 2021: seu comentário afirma um fato? Incorporações contextualizadas para classificação alemã de comentários de reivindicação de fatos</title_pt>
      <title_fr>HunterSpeechLab au GermEval 2021 : Votre commentaire revendique-t-il un fait ? Embeddings contextualisés pour la classification des commentaires de revendication de faits allemands</title_fr>
      <title_es>HunterSpeechLab en GermEval 2021: ¿Su comentario afirma ser un hecho? Incrustaciones contextualizadas para la clasificación alemana de comentarios sobre afirmaciones de hechos</title_es>
      <title_ja>HunterSpeechLab at GermEval 2021:あなたのコメントは事実を主張しますか？ドイツ語の事実を主張するコメント分類のための文脈化された埋め込み</title_ja>
      <title_zh>HunterSpeechLab在GermEval 2021上,君论称实否? 用德语事实声明注类上下文嵌之</title_zh>
      <title_ru>HunterSpeechLab на конференции GermEval 2021: Заявляет ли ваш комментарий о факте? Контекстуализированные вложения для немецкой фактологической классификации комментариев</title_ru>
      <title_hi>GermEval 2021 में हंटरस्पीचलैब: क्या आपकी टिप्पणी एक तथ्य का दावा करती है? जर्मन तथ्य-दावा टिप्पणी वर्गीकरण के लिए संदर्भित एम्बेडिंग</title_hi>
      <title_ga>HunterSpeechLab ag GermEval 2021: An Éilíonn Do Trácht Fíricí? Leabaithe Comhthéacsúla d'Aicmiú Tráchtanna Gearmánacha Éilimh ar Fhíricí</title_ga>
      <title_el>Το σχόλιό σας ισχυρίζεται ένα γεγονός; Ενσωματώσεις πλαισίων για γερμανικά σχόλια για ισχυρισμούς γεγονότων Ταξινόμηση σχολίων</title_el>
      <title_hu>HunterSpeechLab a GermEval 2021-ben: A hozzászólása tényt állít? Kontextualizált beágyazások a német tényállításhoz Comment Osztályozás</title_hu>
      <title_ka>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</title_ka>
      <title_it>HunterSpeechLab a GermEval 2021: il tuo commento rivendica un fatto? Integrazioni contestualizzate per la rivendicazione tedesca dei fatti</title_it>
      <title_kk>2021 Гермевальдегі HunterSpeechLab: Түсініктемеңіздің шындығын қалайсыз ба? Неміс факт- классификациялау үшін контекстуалды ендірулерComment</title_kk>
      <title_mk>HunterSpeechLab на GermEval 2021: Дали вашиот коментар тврди факт? Name</title_mk>
      <title_ms>HunterSpeechLab di GermEval 2021: Adakah Komen anda menuntut fakta? Name</title_ms>
      <title_lt>HunterSpeechLab at GermEval 2021: Ar Jūsų komentaras reikalauja fakto? Konkstualizuotos įrangos, skirtos Vokietijos faktų pareiškimo komentarų klasifikacijai</title_lt>
      <title_ml>ഗെര്‍മെവാല്‍ 2021: നിങ്ങളുടെ ക്ലായം A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</title_ml>
      <title_mt>HunterSpeechLab f’GermEval 2021: Il-Kumment tiegħek jitlob fatt? Embeddings Contextualized for German Fact-Claiming Comment Classification</title_mt>
      <title_mn>2021 оны Гермевалд ХантерСпехЛаб: Түүнийг хэлэх үнэн гэж үү? Германы Фактик-Классификацийн контекстүүд</title_mn>
      <title_no>HunterSpeechLab på GermEval 2021: Er kommentaren din løp ein faktus? Comment</title_no>
      <title_pl>HunterSpeechLab w GermEval 2021: Czy Twój komentarz twierdzi, że jest faktem? Kontekstualizowane osadzenia dla niemieckiej klasyfikacji komentarza faktowego</title_pl>
      <title_si>හැන්ටර් ස්පෙච්ලේබ් ජර්ම් එවෙල් 2021 වල: ඔයාගේ ප්‍රතිචාරයක් ඇත්තද? Comment</title_si>
      <title_ro>HunterSpeechLab la GermEval 2021: Comentariul tău pretinde un fapt? Încorporări contextualizate pentru afirmarea faptelor germane Comentariu Clasificare</title_ro>
      <title_sr>HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemaèke klasifikacije èinjenica</title_sr>
      <title_so>HunterSpeechLab at GermEval 2021: Je Comment Claim A Fact? Soo wareegayaasha Jarmalka</title_so>
      <title_ur>GermEval 2021 میں HunterSpeechLab: Does your Comment Claim A Fact? Comment</title_ur>
      <title_sv>HunterSpeechLab på GermEval 2021: Påstår din kommentar ett faktum? Kontextualiserade inbäddningar för tyska faktagranspråk Kommentar Klassificering</title_sv>
      <title_ta>ஜெர்ம்Eval 2021: உங்கள் குறிப்பு A Face? Comment</title_ta>
      <title_uz>Lab at GermEval 2021: Your Comment Claim A Fact? Comment</title_uz>
      <title_vi>Hunter SpeechLab ở GermEvl 2021: Bài phát biểu của anh có thực tế không? Ảnh chiếu tương ứng cho khai thác dữ liệu Đức</title_vi>
      <title_bg>Лаборатория на ДжермЕвал 2021: Коментарът ви твърди ли факт? Контекстualiзирани вграждания за класификация на коментари с твърдения за факти в Германия</title_bg>
      <title_hr>HunterSpeechLab na GermEval 2021: Comment</title_hr>
      <title_nl>HunterSpeechLab bij GermEval 2021: Claimt uw commentaar een feit? Gecontextualiseerde embeddings voor Duitse fact-claiming Comment Classificatie</title_nl>
      <title_de>HunterSpeechLab bei GermEval 2021: Behauptet Ihr Kommentar eine Tatsache? Kontextualisierte Einbettungen für die Klassifizierung der deutschen Faktenklausel</title_de>
      <title_id>HunterSpeechLab di GermEval 2021: Apakah Komentar Anda Claim A Fact? Contextualized Embeddings for German Fact-Claiming Comment Classification</title_id>
      <title_ko>Germ Eval 2021:당신의 댓글은 이것이 사실이라고 주장합니까?독일 사실 진술 평론 분류의 어경화 삽입</title_ko>
      <title_sw>Lab ya HunterSpeechLab kwenye GermEval 2021: Je Comment Claim A Fact? Comment</title_sw>
      <title_tr>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</title_tr>
      <title_af>HunterSpeechLab by GermEval 2021: Het u Kommentaar Claim 'n Faak? Comment</title_af>
      <title_sq>HunterSpeechLab në GermEval 2021: A pretendon komenti juaj një fakt? Embeddings Contextualized for German Fact-Claiming Comment Classification</title_sq>
      <title_am>Lab at GermEval 2021: Is Your Comment Claim A Fact? Comment</title_am>
      <title_da>HunterSpeechLab på GermEval 2021: Hævder din kommentar et faktum? Kontekstualiserede indlejringer til tysk fact-claying Kommentar Klassificering</title_da>
      <title_hy>Hunter SpeechLab-ը, ԳերմԷվալ 2021 թվականին. արդյո՞ք ձեր մեկնաբանությունը փաստ է պահանջում: Comment</title_hy>
      <title_az>GermEval 2021-də HunterSpeechLab: Sizin Komutanınız bir həqiqəti iddia edir? Almanca Fakat-Klasifikası üçün Kontekst Yazılımlar</title_az>
      <title_fa>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? Comment</title_fa>
      <title_ca>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact?  Embeddings Contextualized for German Fact-Claiming Comment Classification</title_ca>
      <title_et>HunterSpeechLab GermEval 2021: kas teie kommentaar väidab fakti? Saksa faktide väidetavate kommentaaride klassifitseerimise kontekstualiseeritud manustamised</title_et>
      <title_fi>HunterSpeechLab GermEvalissa 2021: väittääkö kommenttisi faktaa? Konteksturoidut upotukset saksankielisille faktojen väittämistä koskeville kommenteille</title_fi>
      <title_cs>HunterSpeechLab na GermEval 2021: Tvrdí váš komentář fakt? Kontextualizované vložení pro klasifikaci německých faktů</title_cs>
      <title_bn>গের্মেভাল ২০২১-এ হান্টার স্পেকল্যাব: তোমার গ্লায়াম কি এক ফ্যাক্ট? Comment</title_bn>
      <title_bs>HunterSpeechLab u GermEval 2021: Kontekstualizirani integraciji za njemačku klasifikaciju činjenica</title_bs>
      <title_jv>John Doe ? Name</title_jv>
      <title_he>HunterSpeechLab ב GermEval 2021: האם הערה שלך טוענת עובדה? קישורים קונטקסטוליזציונים לסיפור העובדות הגרמניות</title_he>
      <title_sk>HunterSpeechLab na GermEvalu 2021: Ali vaš komentar trdi dejstvo? Konteksturirane vdelave za nemško razvrstitev komentarjev za trditev dejstev</title_sk>
      <title_ha>Lab at GermEal 2021: Shin The Claim A Fact? KCharselect unicode block name</title_ha>
      <title_bo>HunterSpeechLab at GermEval 2021: Does Your Comment Claim A Fact? རང་ཉིད་ཀྱི་དོན་དག་ཕྱོགས་སྒྲིག་འགོད་ཀྱི་སྣང་ཚུལ་ལྡན་རྣམ་པ</title_bo>
      <abstract_ar>في هذه الورقة ، نحقق في فعالية استخدام الزخارف السياقية من BERT متعدد اللغات والألمانية BERT في تحديد التعليقات التي تدعي الحقائق باللغة الألمانية على وسائل التواصل الاجتماعي. بالإضافة إلى ذلك ، ندرس تأثير صياغة مشكلة التصنيف كمشكلة تعلم متعددة المهام ، حيث يحدد النموذج السمية والتفاعل مع التعليق بالإضافة إلى تحديد ما إذا كان يدعي الحقائق. نحن نقدم مقارنة شاملة بين النموذجين المعتمدين على BERT مقارنة بخط أساس الانحدار اللوجستي ونبين أن ميزات BERT الألمانية المدربة باستخدام هدف متعدد المهام تحقق أفضل درجة F1 في مجموعة الاختبار. تم تنفيذ هذا العمل كجزء من إرسال إلى مهمة GermEval 2021 المشتركة بشأن تحديد تعليقات ادعاء الحقائق.</abstract_ar>
      <abstract_pt>Neste artigo, investigamos a eficácia do uso de embeddings contextuais de BERT multilíngue e BERT alemão na identificação de comentários de alegação de fatos em alemão nas mídias sociais. Além disso, examinamos o impacto de formular o problema de classificação como um problema de aprendizado multitarefa, onde o modelo identifica a toxicidade e o engajamento do comentário, além de identificar se é uma afirmação de fato. Fornecemos uma comparação completa dos dois modelos baseados em BERT em comparação com uma linha de base de regressão logística e mostramos que os recursos de BERT alemães treinados usando um objetivo multitarefa atingem a melhor pontuação F1 no conjunto de teste. Este trabalho foi feito como parte de uma submissão à tarefa compartilhada GermEval 2021 sobre a identificação de comentários de alegação de fatos.</abstract_pt>
      <abstract_es>En este artículo investigamos la eficacia del uso de incrustaciones contextuales de BERT multilingües y BERT alemán para identificar comentarios que afirman hechos en alemán en las redes sociales. Además, examinamos el impacto de formular el problema de clasificación como un problema de aprendizaje multitarea, en el que el modelo identifica la toxicidad y el compromiso del comentario, además de identificar si se trata de una afirmación de hechos. Proporcionamos una comparación exhaustiva de los dos modelos basados en BERT en comparación con una línea de base de regresión logística y mostramos que las entidades BERT alemanas entrenadas con un objetivo multitarea logran la mejor puntuación de F1 en el conjunto de pruebas. Este trabajo se realizó como parte de una presentación a la tarea compartida de GermEval 2021 sobre la identificación de comentarios de denuncia de hechos.</abstract_es>
      <abstract_fr>Dans cet article, nous étudions l'efficacité de l'utilisation d'intégrations contextuelles du BERT multilingue et du BERT allemand pour identifier les commentaires factuels en allemand sur les réseaux sociaux. En outre, nous examinons l'impact de la formulation du problème de classification en tant que problème d'apprentissage multitâche, où le modèle identifie la toxicité et l'engagement du commentaire en plus de déterminer s'il s'agit d'allégations factuelles. Nous fournissons une comparaison approfondie des deux modèles basés sur BERT par rapport à une base de régression logistique et montrons que les entités BERT allemandes entraînées à l'aide d'un objectif multi-tâches obtiennent le meilleur score F1 sur l'ensemble de tests. Ce travail a été effectué dans le cadre d'une soumission à la tâche partagée GermEval 2021 sur l'identification des commentaires factuels.</abstract_fr>
      <abstract_ja>この論文では、ソーシャルメディア上のドイツ語での事実を主張するコメントを特定する際に、多言語のBERTとドイツ語のBERTからの文脈埋め込みを使用することの有効性を調査します。さらに、分類問題をマルチタスク学習問題として定式化することの影響を検討する。そこでは、モデルは毒性とコメントのエンゲージメントを特定し、それが事実主張であるかどうかを特定する。ロジスティック回帰ベースラインと比較した2つのBERTベースモデルの徹底的な比較を提供し、マルチタスク目標を使用して訓練されたドイツのBERT特徴が試験セット上で最高のF 1スコアを達成することを示します。この作業は、事実を主張するコメントの特定に関するGermEval 2021への提出の一部として行われました。</abstract_ja>
      <abstract_zh>于本文中,研用多言BERT与德语BERT上下文嵌社交媒体识德语事实声明论有效性。 又考分类为多任务学,其形定是非声明之外,定注毒参与度。 二基于BERT,与逻辑归基线周比,明用多任务之所习德国BERT试集上至F1之分也。 此其所以GermEval 2021知事实声明论议之一体也。</abstract_zh>
      <abstract_ru>В этой статье мы исследуем эффективность использования контекстных вложений из многоязычных BERT и German BERT в выявлении фактологических комментариев на немецком языке в социальных сетях. Кроме того, мы изучаем влияние формулирования проблемы классификации как многозадачной проблемы обучения, где модель идентифицирует токсичность и вовлеченность комментария в дополнение к определению того, является ли он фактологическим. Мы предоставляем тщательное сравнение двух моделей, основанных на BERT, по сравнению с базовой линией логистической регрессии и показываем, что немецкие функции BERT, обученные с использованием многозадачной цели, достигают лучшего балла F1 на тестовом наборе. Эта работа была выполнена в рамках представления на рассмотрение GermEval 2021 общей задачи по выявлению комментариев с изложением фактов.</abstract_ru>
      <abstract_hi>इस पेपर में हम सोशल मीडिया पर जर्मन में तथ्य-दावा टिप्पणियों की पहचान करने में बहुभाषी BERT और जर्मन BERT से प्रासंगिक एम्बेडिंग का उपयोग करने की प्रभावकारिता की जांच करते हैं। इसके अतिरिक्त, हम वर्गीकरण समस्या को बहु-कार्य सीखने की समस्या के रूप में तैयार करने के प्रभाव की जांच करते हैं, जहां मॉडल यह पहचानने के अलावा विषाक्तता और टिप्पणी की सगाई की पहचान करता है कि क्या यह तथ्य-दावा है। हम एक रसद प्रतिगमन आधार रेखा की तुलना में दो BERT आधारित मॉडल की पूरी तरह से तुलना प्रदान करते हैं और दिखाते हैं कि एक बहु-कार्य उद्देश्य का उपयोग करके प्रशिक्षित जर्मन BERT विशेषताएं परीक्षण सेट पर सबसे अच्छा F1 स्कोर प्राप्त करती हैं। यह काम GermEval 2021 साझा कार्य के लिए एक सबमिशन के हिस्से के रूप में किया गया था तथ्य-दावा टिप्पणियों की पहचान पर।</abstract_hi>
      <abstract_ga>Sa pháipéar seo déanaimid imscrúdú ar a éifeachtaí atá sé úsáid a bhaint as leabaithe comhthéacsúla ó BERT ilteangach agus ó BERT Gearmáinise chun tráchtanna a éilíonn fíricí i nGearmáinis ar na meáin shóisialta a aithint. Ina theannta sin, scrúdaíonn muid an tionchar a bheadh ag fadhb an aicmithe a fhoirmliú mar fhadhb foghlama il-tasc, áit a n-aithnítear sa tsamhail tocsaineacht agus rannpháirtíocht na tráchtaireachta chomh maith le sainaithint an bhfuil fíoras á éileamh. Cuirimid comparáid críochnúil ar fáil idir an dá mhúnla atá bunaithe ar CRET i gcomparáid le bonnlíne aischéimnithí loighistice agus léirímid go mbaineann gnéithe BERT Gearmánacha oilte ag baint úsáide as cuspóir il-tasc an scór F1 is fearr ar an tacar tástála. Rinneadh an obair seo mar chuid d’aighneacht chuig GermEval 2021 comhthasc maidir le tuairimí a éilíonn fíricí a aithint.</abstract_ga>
      <abstract_hu>Ebben a tanulmányban a BERT és a német BERT kontextuális beágyazásainak hatékonyságát vizsgáljuk a közösségi médiában megjelenő, német nyelvű megjegyzések azonosításában. Ezenkívül megvizsgáljuk a besorolási probléma többfeladatos tanulási problémaként való megfogalmazásának hatását, ahol a modell azonosítja a megjegyzés toxicitását és elkötelezettségét, valamint azonosítja, hogy tényállításról van szó. Alapos összehasonlítást nyújtunk a két BERT alapú modell logisztikai regressziós alapjával összehasonlítva, és megmutatjuk, hogy a többfeladatos célkitűzéssel kiképzett német BERT funkciók elérik a legjobb F1 pontszámot a tesztkészleten. Ezt a munkát a GermEval 2021 közös feladatának benyújtása részeként végeztük a tényállító észrevételek azonosításával kapcsolatban.</abstract_hu>
      <abstract_el>Σε αυτή την εργασία διερευνούμε την αποτελεσματικότητα της χρήσης περιεχομένων ενσωμάτωσης από πολυγλωσσικό BERT και γερμανικό BERT στον εντοπισμό ισχυριζόμενων γεγονότων σχολίων στα γερμανικά στα μέσα κοινωνικής δικτύωσης. Επιπλέον, εξετάζουμε τον αντίκτυπο της διατύπωσης του προβλήματος ταξινόμησης ως μαθησιακό πρόβλημα πολλαπλών εργασιών, όπου το μοντέλο προσδιορίζει την τοξικότητα και την εμπλοκή του σχολίου, εκτός από τον προσδιορισμό του αν είναι ισχυρισμός γεγονότων. Παρέχουμε μια εμπεριστατωμένη σύγκριση των δύο μοντέλων που βασίζονται στο BERT σε σύγκριση με μια βάση λογιστικής παλινδρόμησης και δείχνουν ότι τα γερμανικά χαρακτηριστικά του BERT που εκπαιδεύονται χρησιμοποιώντας έναν στόχο πολλαπλών εργασιών επιτυγχάνουν την καλύτερη βαθμολογία F1 στο σύνολο δοκιμών. Το έργο αυτό πραγματοποιήθηκε στο πλαίσιο μιας υποβολής στο κοινό έργο της GermEval 2021 σχετικά με τον προσδιορισμό των παρατηρήσεων που ισχυρίζονται γεγονότα.</abstract_el>
      <abstract_ka>ამ დოგომაში ჩვენ შევხედავთ კონტექსტური ინბედინგიების გამოყენება მრავალენგური BERT და გერმანეთის BERT-ის განსაზღვრებით ფაქტის კონტაქტის კონტაქტის გამოყენება საზოგად დამატებით, ჩვენ კლასიფიკაციის პრობლემას ფორმულაციის შესახებ გავაკეთებთ, რომელსაც მოდელემა ტექსტიურობა და კომენტურის შესახებ განვიცნობა თუ არა ეს ფაქტის შესახებ. ჩვენ გვეყენებთ ბერტის ორი მოდელთან დამატებული მოდელების დამატებით ლოგისტიკური რეგრესის ბაზი ხაზი და ჩვენ ჩვენებთ, რომ გერმანეთი BERT ფუნქციები, რომლებიც მრავალ დავალების მიყენებული მიზეზით, გავაკ ეს სამუშაო გავაკეთებულია როგორც ჯერმEval 2021-ში გაყოფილი სამუშაო სამუშაო სამუშაო შესახებ ფაქტის კომენტრების განსაზღვრებაზე.</abstract_ka>
      <abstract_kk>Бұл қағазда біз бірнеше тілді BERT және неміс BERT тілдерінің неміс мәліметтерінің жазбаларын анықтау үшін неміс мәліметтерінің жазбаларын қолдануға мүмкіндігін зерттеп отырмыз. Қосымша, біз классификациялау мәселесін бірнеше тапсырма оқыту мәселесі ретінде формуляциялау нәтижесін тексереміз. Бұл үлгі тек қандай тапсырманы анықтау үшін, мәселелердің тәсіліктерінің тоғызд Біз, логистикалық регрессия негізгі жолымен салыстырылған екі BERT негізгі үлгілерді тұрақты салыстырып, неміс BERT қасиеттері бірнеше тапсырма мақсатын қолдану арқылы бірнеше тапсырма мақсатын қолдану үшін те Бұл жұмыс 2021 жылы GermEval-ге ортақ тапсырманы таңдау үшін факты жайлы түсініктемелерді анықтау үшін ортақ тапсырманың бөлігі болды.</abstract_kk>
      <abstract_it>In questo articolo esaminiamo l'efficacia dell'utilizzo di incorporazioni contestuali di BERT multilingue e BERT tedesco nell'identificare commenti di fatto in tedesco sui social media. Inoltre, esaminiamo l'impatto della formulazione del problema di classificazione come un problema di apprendimento multi-task, dove il modello identifica la tossicità e l'engagement del commento oltre a identificare se è fact-claim. Forniamo un confronto approfondito dei due modelli basati su BERT confrontati con una base di regressione logistica e mostriamo che le caratteristiche BERT tedesche addestrate utilizzando un obiettivo multi-task raggiungono il miglior punteggio F1 sul set di test. Questo lavoro è stato svolto nell'ambito di una presentazione al compito condiviso GermEval 2021 sull'identificazione dei commenti di fatto.</abstract_it>
      <abstract_mk>Во овој весник ја истражуваме ефикасноста на употребата на контекстни вложувања од мултијазичните БЕРТ и Германските БЕРТ во идентификацијата на коментари кои тврдат факти на германски за социјалните медиуми. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  Ние обезбедуваме темелна споредба на двата модели базирани на БЕРТ во споредба со логистичката регресна основа и покажуваме дека германските БЕРТ карактеристики тренирани користејќи мултизадачна цел го постигнуваат најдобриот резултат F1 на тестот. Оваа работа беше направена како дел од поднесувањето на GermEval 2021 заедничка задача за идентификација на коментарите кои тврдат факти.</abstract_mk>
      <abstract_ms>Dalam kertas ini kami menyelidiki kegagalan menggunakan penyembedding kontekstual dari BERT berbilang bahasa dan BERT Jerman dalam mengenalpasti komentar-mengklaim fakta dalam Jerman pada media sosial. Selain itu, kami memeriksa kesan daripada membentuk masalah klasifikasi sebagai masalah pembelajaran berbilang-tugas, di mana model mengenalpasti toksiciti dan keterlibatan komentar selain mengenalpasti sama ada ia adalah fakta-claiming. Kami menyediakan perbandingan teliti dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahawa ciri-ciri BERT Jerman dilatih menggunakan objektif berbilang-tugas mencapai skor F1 terbaik pada set ujian. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ നമ്മള്‍ സാമൂഹ്യ മാധ്യമങ്ങളില്‍ നിന്നും പല ഭാഷകങ്ങളില്‍ നിന്നും ജര്‍മ്മന്‍ ബെര്‍ട്ടിയില്‍ നിന്നും അഭിപ്രായം ഉപയോഗിക്കുന് കൂടാതെ, ക്ലാസ്ഫിക്ഷന്‍ പ്രശ്നത്തിന്റെ പ്രഭാവം നമ്മള്‍ പരിശോധിക്കുന്നത് പല ജോലി പഠിക്കുന്ന പ്രശ്നങ്ങളായിട്ടാണ്. അതിന്റെ മോഡല്‍ വിഷയത്തിലും  ഒരു ലോഗിസ്റ്റിക്ക് റിക്രഷന്‍ ബെസ്റ്റ് ബെര്‍ട്ടിന്റെ അടിസ്ഥാനത്തുള്ള രണ്ട് മോഡലുകളുടെ തുല്യമായ ഒരു തുല്യമായ തുല്യമാണ് ഞങ്ങള്‍ നല്‍കുന്നത്. പരീക്ഷണസെറ്റി ഗെര്‍മെവാല്‍ 2021-ലേക്ക് കൊടുക്കുന്നതിന്‍റെ ഒരു ഭാഗമായി ഈ ജോലി ചെയ്തതാണ് സത്യത്തിന്‍റെ അഭിപ്രായത്തിന്‍റെ തി</abstract_ml>
      <abstract_mt>F’dan id-dokument ninvestigaw l-effikaċja tal-użu ta’ inkorporazzjonijiet kuntestwali minn BERT multilingwi u BERT Ġermaniż fl-identifikazzjoni ta’ kummenti li jsostnu l-fatti fil-Ġermaniż dwar il-midja soċjali. Barra minn hekk, jeżaminaw l-impatt tal-formulazzjoni tal-problem a ta’ klassifikazzjoni bħala problema ta’ tagħlim b’ħafna kompiti, fejn il-mudell jidentifika t-tossiċit à u l-involviment tal-kumment flimkien mal-identifikazzjoni ta’ jekk huwiex dikjarazzjoni ta’ fatti. Aħna nipprovdu tqabbil bir-reqqa taż-żewġ mudelli bbażati fuq BERT meta mqabbel ma’ linja bażi ta’ rigressjoni loġistika u nuru li l-karatteristiċi Ġermaniżi BERT imħarrġa bl-użu ta’ objettiv multikompitu jilħqu l-a ħjar punteġġ F1 fis-sett tat-test. Dan ix-xogħol sar bħala parti minn sottomissjoni lill-GermEval 2021 kompitu komuni dwar l-identifikazzjoni ta’ kummenti li jsostnu l-fatti.</abstract_mt>
      <abstract_mn>Энэ цаасан дээр бид олон хэлний BERT болон Герман BERT-ын орчин үеийн төвлөрүүлэлтийг Германы нийгмийн мэдээллийн тухай мэдээллийг тодорхойлж чадахын тулд нөлөөтэй байдлыг судалж байна. Мөн бид хэлбэрийн асуудлыг олон ажлын суралцах асуудлыг тодорхойлох нөлөөг судалж байна. Загварын загвар нь тодорхойлолтой байдлыг тодорхойлдог. Үнэндээ тодорхойлдог эсэхийг тодорхойлдог. Бид Логистикийн регрессийн суурь шулуунтай харьцуулсан хоёр BERT суурь загварын жишээлбэл харьцуулж, Герман BERT нь олон ажлын зорилго ашиглан сургалтын чадварыг харуулж байна. Энэ ажил 2021 оны GermEval-д үнэндээ илэрхийлж буй комментарын тодорхойлолтын тухай хуваалцах ажлын нэг хэсэг болсон.</abstract_mn>
      <abstract_no>I denne papiret undersøker vi effektiviteten for å bruka kontekstiske innbygging frå fleirspråk BERT og tysk BERT i å identifisera faktiske kommentarar i tysk på sosiale media. I tillegg undersøker vi effekten til å formera klassifikasjonsprobleten som eit problem med å lære fleire oppgåver, der modellen identifiserer toksikitet og involvering av kommentaren i tillegg til å identifisera om det er faktisk opplæring. Vi tilbyr ein røyd samanlikning av dei to BERT-baserte modelane samanlikna med ein logistisk regresjonsbaselinje og viser at tysk BERT-funksjonar trengte med eit multioppgåvemål gjer det beste F1-poeng på testsettet. Dette arbeidet vart gjort som del av ein tillegg til GermEval 2021 delt oppgåve om identifiseringa av faktisk kommentarar.</abstract_no>
      <abstract_lt>Šiame dokumente mes tiriame, kaip veiksminga naudoti daugiakalbį BERT ir Vokietijos BERT turinčius kontekstinius įterpimus nustatant faktus teigiančias komentaras vokiečių kalba apie social in ę žiniasklaidą. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  Mes išsamiai palyginame du BERT pagrįstus modelius, palyginti su logistinės regresijos pradiniu lygiu, ir parodome, kad Vokietijos BERT savybės, parengtos naudojant daugiafunkcinį tikslą, pasiekia geriausią bandymų rinkinio F1 rezultatą. Šis darbas buvo atliktas pateikus „GermEval 2021“ bendrą užduotį nustatyti faktus pareiškančias pastabas.</abstract_lt>
      <abstract_ro>În această lucrare investigăm eficacitatea utilizării încorporărilor contextuale de la BERT multilingv și BERT german în identificarea comentariilor în limba germană pe rețelele de socializare. În plus, examinăm impactul formulării problemei de clasificare ca o problemă de învățare multi-task, în cazul în care modelul identifică toxicitatea și implicarea comentariului în plus față de identificarea dacă este o afirmație de fapt. Oferim o comparație aprofundată a celor două modele bazate pe BERT în comparație cu o bază de regresie logistică și arătăm că caracteristicile BERT germane instruite utilizând un obiectiv multi-task obțin cel mai bun scor F1 pe setul de test. Această lucrare a fost realizată în cadrul unei transmiteri către GermEval 2021 a sarcinii comune privind identificarea comentariilor care susțin fapte.</abstract_ro>
      <abstract_sr>U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo uticaj formiranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gde je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokažemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen kao deo podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</abstract_sr>
      <abstract_si>මේ පත්තරේ අපි පරීක්ෂණය කරනවා සාමාජික මිඩියාවේ ජර්මන් වල සාමාජිකයෙන් ජර්මන් වල සාමාජික ක්‍රියාත්මක ප්‍රයෝජනය කරන්න ස තවත්, අපි පරීක්ෂා කරන්නේ විශේෂණ ප්‍රශ්නයක් වගේ විශේෂණ ප්‍රශ්නයක් ගොඩක් වැඩි වැඩක් ඉගෙන ගන්න ප්‍රශ්නයක් වගේ, මොඩේල් එකේ විශ අපි BERT පරීක්ෂණයේ හොඳම F1 ස්කෝර් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් සම්පූර්ණයෙන් පරීක් මේ වැඩේ ජෙර්ම් එව්ල් 2021 වලට පිළිගන්න පුළුවන් කොටසක් විදිහට කරලා තියෙන්නේ ඇත්තටම පිළිගන්න ප්‍රශ</abstract_si>
      <abstract_so>Qoraalkan ayaannu ka baaraynaa faa’iidada isticmaalka warqadaha joogtada ah ee BERT iyo Jarmalka BERT si aan ugu ogaano commentarada warqada bulshada ee Jarmalka ah. Sidoo kale waxaynu fiirinaynaa saamaynta u sameynta dhibaatada fasaxda sida dhibaato waxbarasho badan oo kale, kaas oo modelku ku qoran yahay dhibaatada waxbarashada, taas oo ku qoran tijaabada iyo wadashada commentarka iyo sidoo kale ayan aqoonsanaynaa in ay tahay mid ku habboon. Waxaannu sameynaa tusaalaha labada BERT ee asalka ah oo la barbarbaro qoraalka regression baseline, waxaana muujinaynaa in Jarmalka BERT ay ku tababartay isticmaalka shaqo badan, waxay gaadhaa kooxda ugu wanaagsan ee F1 ee imtixaanka. Shaqodaas waxaa loo sameeyay qeyb ka mid ah warqada GermEval 2021 oo lagu sharciyey aqoonsiga commentarada xaqiiqa ah.</abstract_so>
      <abstract_sv>I denna uppsats undersöker vi effekten av att använda kontextuella inbäddningar från flerspråkiga BERT och tyska BERT för att identifiera fakta-hävdande kommentarer på tyska på sociala medier. Dessutom undersöker vi effekten av att formulera klassificeringsproblemet som ett inlärningsproblem med flera uppgifter, där modellen identifierar toxicitet och engagemang av kommentaren samt identifierar om det är faktagranspråk. Vi ger en grundlig jämförelse av de två BERT-baserade modellerna jämfört med en logistisk regressionsvärde och visar att tyska BERT-funktioner som tränats med ett multi-task-mål uppnår bästa F1-poäng i testuppsättningen. Detta arbete gjordes som en del av en inlämning till GermEval 2021 delad uppgift om identifiering av faktabaserade kommentarer.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் நாம் பல மொழி BERT மற்றும் ஜெர்மன் பிரெட்டில் இருந்து தற்போதைய முழுமையான குறிப்புகளை பயன்படுத்தும் விளைவுகளை தேடுக Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming.  பிரெட் அடிப்படையில் உள்ள இரண்டு பிரெட்டின் மாதிரிகளை ஒப்பிட்டுக் கொண்டு ஜெர்மன் பிரெட்டின் குணங்களை பயன்படுத்தி பல பணிக்காட்டியை பயிற்சி செய்துள் இந்த வேலை ஜெர்ம்வெல் 2021 க்கு ஒரு ஒப்பிட்ட பகிர்ந்த பணியாக செய்யப்பட்டுள்ளது உண்மையான குறிப்பிட்ட குறிப்ப</abstract_ta>
      <abstract_ur>ہم اس کاغذ میں متوسط زبان BERT اور جرمن BERT سے متوسط انبودینگ کے استعمال کرنے کے اقتدار کی تحقیق کرتے ہیں جرمن میں سوسیل میڈیا کے ذریعے جرمن کی مثالیں معلوم کرنے کے لئے۔ اور اضافہ، ہم نے کلاسپیٹ مسئلہ کی تعلیم کے مطابق مشکل کی تأثیر کی تحقیق کی ہے، جہاں مدل سمجھ رہا ہے اور مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق مطابق م ہم نے دو BERT بنیادی موڈل کے مطابق مطابق مطابق مطابق مقایسہ کی اور دکھا دیتے ہیں کہ جرمن BERT کے مطابق multi-task موضوع کے مطابق تعلیم کی جاتی ہے ایک امتحان سٹ کے سب سے بہترین F1 اسکور کو پہنچ سکتا ہے. یہ کام جرمEval 2021 کے لئے ایک حصہ کے طور پر کیا گیا تھا جو حقیقت کی تصدیق کرنے والی کمانٹروں کے معاملہ میں شریک کام کیا گیا تھا.</abstract_ur>
      <abstract_pl>W niniejszym artykule badamy skuteczność wykorzystania kontekstowych osadzeń z wielojęzycznych BERT i niemieckich BERT w identyfikacji komentarzy twierdzących fakty w języku niemieckim w mediach społecznościowych. Dodatkowo badamy wpływ sformułowania problemu klasyfikacji jako wielozadaniowego problemu uczenia się, w którym model identyfikuje toksyczność i zaangażowanie komentarza, a także identyfikuje, czy jest on twierdzący fakty. Przeprowadzamy dokładne porównanie dwóch modeli opartych na BERT w porównaniu z regresją logistyczną i pokazujemy, że niemieckie cechy BERT trenowane przy użyciu obiektu wielozadaniowego osiągają najlepszy wynik F1 w zestawie testowym. Prace te zostały wykonane w ramach zgłoszenia do GermEval 2021 wspólnego zadania dotyczącego identyfikacji uwag twierdzących fakty.</abstract_pl>
      <abstract_uz>Bu hujjatda biz bir necha tildan BERT va Olmoncha BERT kabi xil tildan foydalanishning effektini o'rganamiz. Olmoniyadagi haqiqiqiy qo'llangan izohlarni ko'paytirish uchun o'rganamiz. Ko'pchilik, biz bir necha vazifa o'rganish muammolari sifatida darajalashtirish muammolarini ko'rib chiqaramiz. Bu yerda model to ʻgʻri va izohni aniqlaydi, bu haqiqiqiy talab qilishini anglatadi. Biz ikkita BERT asosida o'xshash modellarni o'xshash qilamiz va bir necha vazifa obʼektidan foydalanishga o'rganish imkoniyatlarni bir necha qavsga o'rganish imkoniyatlarini sinov sohasida eng eng yaxshi F1 scori bajaradi. Bu ishni GermEval 2021 ga bogʻliq vazifani aniqlash uchun ishga bajarildi.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi nghiên cứu hiệu quả của việc sử dụng tác nhân ngữ chung từ BERT đa dạng và BERT Đức để xác định các bình luận về xã hội trên Đức. Thêm vào đó, chúng tôi nghiên cứu tác động của việc phát triển vấn đề phân loại thành vấn đề học tập nhiều nhiệm vụ, nơi mô hình xác định độc tính và cam kết của lời bình luận, thêm vào việc xác định xem nó có được thực tế không. Chúng tôi cung cấp một so sánh hoàn hảo với hai mô hình nền phục hồi hàng hoá được so sánh với một cơ sở hồi quy mô hàng hoá Đức và cho thấy các đặc điểm thiếu sót được huấn luyện bằng nhiều nhiệm vụ đạt được điểm F1 tốt nhất trong bộ thử nghiệm. Việc này được thực hiện như một phần của việc đệ trình cho GermEvl 2021 sẽ có nhiệm vụ chia sẻ về nhận dạng những nhận xét thực tế.</abstract_vi>
      <abstract_da>I denne artikel undersøger vi effektiviteten af at bruge kontekstuelle indlejringer fra flersprogede BERT og tyske BERT til at identificere fakta-hævdende kommentarer på tysk på sociale medier. Derudover undersøger vi effekten af at formulere klassificeringsproblemet som et multi-task learning problem, hvor modellen identificerer toksicitet og engagement af kommentaren samt identificerer, om det er faktahævdende. Vi leverer en grundig sammenligning af de to BERT-baserede modeller sammenlignet med en logistisk regression baseline og viser, at tyske BERT-funktioner trænet ved hjælp af et multi-task mål opnår den bedste F1 score på testsættet. Dette arbejde blev udført som en del af en indsendelse til GermEval 2021 delt opgave om identifikation af faktahævdende kommentarer.</abstract_da>
      <abstract_hr>U ovom papiru istražujemo djelotvornost korištenja kontekstualnih integracija iz multijezičkih BERT-a i njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formuliranja klasifikacijskog problem a kao problem sa učenjem multizadataka, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi s početnom linijom logističke regresije i pokazujemo da njemačke BERT karakteristike obučene s višezadatačnim ciljem postignu najbolji rezultat F1 na testu. Ovaj rad je učinio kao dio podataka GermEvalu 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</abstract_hr>
      <abstract_nl>In dit artikel onderzoeken we de effectiviteit van het gebruik van contextuele embeddings van meertalige BERT en Duitse BERT bij het identificeren van feiten claimende opmerkingen in het Duits op sociale media. Daarnaast onderzoeken we de impact van het formuleren van het classificatieprobleem als een multi-task leerprobleem, waarbij het model de toxiciteit en betrokkenheid van de opmerking identificeert naast het identificeren van de fact claiming. We bieden een grondige vergelijking van de twee BERT gebaseerde modellen vergeleken met een logistieke regressie baseline en laten zien dat Duitse BERT-functies getraind met behulp van een multi-task objectief de beste F1 score op de testset behalen. Dit werk werd gedaan als onderdeel van een inzending aan GermEval 2021 gedeelde taak over het identificeren van feiten claimende opmerkingen.</abstract_nl>
      <abstract_de>In diesem Beitrag untersuchen wir die Wirksamkeit kontextueller Einbettungen von mehrsprachigen BERT und deutschen BERT bei der Identifizierung faktenbezogener Kommentare in Deutsch in sozialen Medien. Darüber hinaus untersuchen wir die Auswirkungen der Formulierung des Klassifizierungsproblems als Mehraufgaben-Lernproblem, wobei das Modell Toxizität und Engagement des Kommentars identifiziert sowie identifiziert, ob es sich um Fakten-Claiming handelt. Wir führen einen gründlichen Vergleich der beiden BERT-basierten Modelle mit einer logistischen Regressionsbasis durch und zeigen, dass deutsche BERT-Features, die mit einem Multi-Task-Ziel trainiert wurden, die beste F1-Punktzahl im Testset erzielen. Diese Arbeit wurde im Rahmen einer gemeinsamen Aufgabe an GermEval 2021 zur Identifizierung faktenbezogener Kommentare durchgeführt.</abstract_de>
      <abstract_bg>В настоящата статия изследваме ефикасността на използването на контекстуални вграждания от многоезични BERT и немски BERT за идентифициране на фактически коментари на немски език в социалните медии. Освен това изследваме въздействието на формулирането на проблема за класификация като проблем с многозадачи за учене, където моделът идентифицира токсичността и ангажираността на коментара в допълнение към идентифициране дали той е фактически претендиращ. Предлагаме задълбочено сравнение на двата модела базирани на базата на логистична регресия в сравнение с базовата линия и показваме, че германските функции, обучени с помощта на многозадача, постигат най-добрия резултат от теста. Тази работа беше направена като част от подаване на споделена задача за идентифициране на фактически коментари.</abstract_bg>
      <abstract_id>Dalam kertas ini kami menyelidiki efektivitas menggunakan embedding kontekstual dari BERT berbagai bahasa dan BERT Jerman dalam mengidentifikasi komentar fakta-klaim dalam Jerman pada media sosial. Selain itu, kami memeriksa dampak dari formulasi masalah klasifikasi sebagai masalah belajar multi-tugas, di mana model mengidentifikasi toksicitas dan keterlibatan komentar selain mengidentifikasi apakah itu fakta-klaim. Kami menyediakan perbandingan teliti dari dua model berdasarkan BERT dibandingkan dengan dasar regresi logistik dan menunjukkan bahwa fitur BERT Jerman dilatih menggunakan tujuan multi-tugas mencapai skor F1 terbaik pada set tes. Kerja ini dilakukan sebagai bagian dari pengiriman kepada GermEval 2021 tugas berbagi mengenai identifikasi komentar fakta-claiming.</abstract_id>
      <abstract_ko>본고에서 우리는 다어버트와 독일어버트의 언어 환경을 이용하여 소셜 미디어에 독일어 사실 진술 평론을 식별하는 유효성을 연구했다.그 밖에 우리는 분류 문제를 다중 임무 학습 문제로 표현하는 영향도 연구했다. 이 모델은 평론이 사실 성명인지 아닌지를 확인하는 것 외에 평론의 독성과 참여도를 확정했다.우리는 두 개의 버트 기반 모델과 논리 회귀 기선을 철저하게 비교하고 다중 임무 목표 훈련을 사용하는 독일의 버트 특징이 시험집에서 최상의 F1 점수를 얻었다는 것을 나타냈다.이 작업은 GermEval 2021 공유 임무에 제출한 일부분으로 이루어졌으며, 이 임무는 사실을 식별하고 의견을 진술하는 데 관련된다.</abstract_ko>
      <abstract_sw>Katika karatasi hii tunachunguza ufanisi wa kutumia vifaa vya kimataifa kutoka kwa lugha mbalimbali vya BERT na Ujerumani BERT katika kutambua maoni yanayodai ukweli nchini Ujerumani kwenye mitandao ya kijamii. Kwa nyongeza, tunachunguza athari ya kutengeneza tatizo la kutangaza darasa kama tatizo la kujifunza kazi nyingi, ambapo model inaonyesha kuchochea na ushirikiano wa maoni hiyo pamoja na kutambua kama ni madai ya ukweli. Tunatoa ulinganisho mkubwa wa mifano miwili yenye msingi wa BERT ukilinganishwa na msingi wa ukandamizaji wa kisiasa na kuonyesha kwamba Ujerumani BERT hususani zilizofundishwa kwa kutumia lengo la kazi nyingi hufanikiwa vipimo bora vya F1 kwenye seti ya mtihani. Kazi hii ilifanyika kama sehemu ya kuutumia ujumbe wa GermEval 2021 ulishirikiana na kazi ya kutambua maoni yanayodai ukweli.</abstract_sw>
      <abstract_tr>Bu kagyzda biz multi dilli BERT we Almança BERT-nyň multi dilinden duşuşyklary barlamak üçin nemesçe medýädäki suratlaryny tanyşdyrylýarys. Mundan hem, biz klasifikasiýa meseläni bir näçe-täbli öwrenme meseläsi hökmünde soraglaşýarys. Modeli çykyş etmek üçin toksyzlyk we komerniň işbirligini tanap-etmek üçin tanap berer. Biz BERT'yň iki nusgalarynyň logistik regressiýa baseline bilen karşılaşyk çykyşyny we Alman BERT'yň multi-täblik maksadyny ulanyp öwrenmegi mümkin edýän nusgalarynyň üstüne ýetip barýandygyny görkez. Bu işi 2021-nji GermEval'a gönderilýän täzeliklerini barlamak üçin paýlandy.</abstract_tr>
      <abstract_fa>در این کاغذ ما از استفاده از وسیله‌های متوسط از BERT و BERT متوسط آلمانی تحقیق می‌کنیم تا توضیح‌های حقیقت را در رسانه‌های اجتماعی در آلمان شناسایی کنیم. اضافه‌ای از این، ما تاثیر فرمول مشکل فرمول‌سازی را به عنوان مشکل یادگیری چندین کار تحقیق می‌کنیم، جایی که مدل سمی و مشترک توضیح را علاوه بر شناسایی که آیا آن حقیقت‌شناسی است، شناسایی می‌کند. ما یک مقایسه کامل از دو مدل بنیادی BERT را در مقایسه با یک خط بنیادی بازگشت لوژیک پیشنهاد می‌کنیم و نشان می‌دهیم که ویژه‌های BERT آلمانی با استفاده از هدف چندین کار آموزش داده شده با بهترین امتیاز F1 در مجموعه آزمایش می‌رسد. این کار به عنوان بخشی از تسلیم به جرمEval 2021 کار مشترک در مورد شناسایی توضیح‌های حقیقت‌جویی انجام شد.</abstract_fa>
      <abstract_am>በዚህ ገጾች ውስጥ የሁለተኛውን የብሬት ቋንቋ እና የጀርመን ብERT ውይይት በጀርመን በማኅበራዊ ሚዲያ ላይ የውሸት ጥያቄዎችን ለማረጋገጥ ጥያቄን እናሳውቃለን፡፡ በተጨማሪም፣ የግንኙነቱን መግለጫ እንደ ብዙ ትምህርት ትምህርት መሆኑን በመፍጠር ላይ እናሳያልን፤ ሞዴል የጥካት እና የመስመር ግንኙነት ማረጋገጥ እውነተኛ ጥያቄ እንደ ሆነ ማረጋገጥ ነው፡፡ በሁለቱ BERT-based ምሳሌዎች በተለየ logistic regression baseline እናሳያቸዋለን፡፡ የጀርመን BERT የብዙዎች አካሄድ በተጠቃሚ ትክክል የተማረ የF1 score በመፈተናው ደረጃ እንዲደርስ እናሳያቸዋለን፡፡ ይህ ሥራ ለጌርEval 2021 የውሸት አካባቢ ትርጉም በማግኘት ላይ የተካፈለ ስራ እንዲሆን ተደረገ፡፡</abstract_am>
      <abstract_sq>Në këtë letër ne hetojmë efektshmërinë e përdorimit të përfshirjeve kontekstuale nga BERT shumëgjuhëse dhe BERT gjermane në identifikimin e komenteve që pretendojnë fakte në gjermanë mbi mediat sociale. Përveç kësaj, ne shqyrtojmë ndikimin e formulimit të problem it të klasifikimit si një problem mësimi me shumë detyra, ku modeli identifikon toksicitetin dhe përfshirjen e komentit përveç identifikimit nëse është fakt-deklarim. Ne ofrojmë një krahasim të plotë të dy modeleve të bazuar në BERT krahasuar me një bazë logjistike të regresionit dhe tregojmë se funksionet gjermane të BERT të trajnuara duke përdorur një objektiv shumëdetyror arrijnë rezultatin më të mirë të F1 në grupin e testimeve. Ky punë u bë si pjesë e një paraqitjeje ndaj GermEval 2021 detyrë të përbashkët mbi identifikimin e komenteve që pretendojnë fakte.</abstract_sq>
      <abstract_af>In hierdie papier ondersoek ons die effektiviteit van die gebruik van contextual inbêdings van multilinglike BERT en Duitse BERT in die identifiseer van feit-aanklaarde kommentaar in Duitse op sosiale media. In addition, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. Ons verskaf 'n groot vergelyking van die twee BERT gebaseerde modele vergelyk met 'n logistike regresie basislien en wys dat Duitse BERT funksies onderwerp deur 'n multi-taak doel bereik die beste F1 telling op die toets stel. Hierdie werk is gedoen as deel van 'n ondersoek aan GermEval 2021 gedeel taak op die identifiseer van faktuur-aansoek kommentaar.</abstract_af>
      <abstract_az>Bu kağıtda, çoxlu dil BERT və Alman BERT'dan müxtəlif məlumatları istifadə etmək üçün Alman dilində çoxlu məlumatları təsdiqləmək üçün istifadə edirik. Daha çox iş öyrənməsi problemi olaraq klasifikasiya problemini, modeli istifadə etmək üçün zehirliyi və şəkillərin istifadəsini təsdiq edir. Biz iki BERT tabanlı modellərin loģistiki regresiya baseline ilə qarşılaşdığı müddətli bir qarşılaşdırmağını təmin edirik və Almanca BERT özelliklərinin çoxlu işlər məqsədilə təhsil edildiyini göstəririk ki, testdə ən yaxşı F1 nöqtəsini nəsib edir. Bu işin 2021 GermEval'a paylaşdığı şəhadətlərin təsdiqlənməsi haqqında paylaşdığı işin bir parças ı olaraq etdi.</abstract_az>
      <abstract_bn>এই পত্রিকায় আমরা সামাজিক মিডিয়ায় জার্মানের বাস্তবতা দাবী করার জন্য বিভিন্ন ভাষায় বিবের্ট এবং জার্মান বার্টি থেকে বিভিন্ন ভাষায় ব তাছাড়াও, আমরা এই ক্লাসাফিকেশনের সমস্যা গঠনের প্রভাব পরীক্ষা করি বহুক্ষেত্র-কাজের শিক্ষা সমস্যা হিসেবে, যেখানে মডেল ব্যস্ত এবং মন্তব্যের অংশগ্রহণের পর We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set.  এই কাজটি গের্মেভাল ২০২১-এর প্রতি প্রদানের একটি অংশ হিসেবে করা হয়েছে বাস্তবতা দাবী করা মন্তব্যের পরিচিতি নিয়ে।</abstract_bn>
      <abstract_bs>U ovom papiru istražujemo učinkovitost korištenja kontekstualnih integracija iz multijezičkih BERT i Njemačkih BERT-a u identifikaciji komentara koji tvrde činjenice na njemačkim na društvenim medijima. Osim toga, istražujemo učinak formiranja klasifikacijskog problem a kao problem sa multizadatačnim učenjem, gdje je model identificirao toksičnost i uključenje komentara, dodatno identificirao je li to činjenica. Mi pružamo temeljno usporedbu dva modela baziranog na BERT u usporedbi sa početnom linijom logističke regresije i pokazujemo da njemačka BERT karakteristika obučena koristeći cilj višezadataka postiže najbolji rezultat F1 na testu. Ovaj rad je urađen u sklopu podataka GermEval 2021. godine zajedničkom zadatku o identifikaciji komentara koji tvrde činjenice.</abstract_bs>
      <abstract_ca>En aquest paper investigam l'eficacia d'utilitzar integracions contextuals de BERT multilingüe i BERT alemanya per identificar comentaris que afirmaven fets en alemany en els mitjans socials. A més, examinem l'impacte de la formulació del problem a de classificació com un problema d'aprenentatge multitascat, on el model identifica la toxicitat i l'involucració del comentari a més d'identificar si està afirmant els fets. Ens proporcionem una comparació detallada dels dos models basats en BERT comparat amb una base de regressió logística i demostrem que les característiques alemanes de BERT entrenats fent servir un objectiu multitasc aconsegueixen el millor puntuatge F1 en el conjunt de tests. Aquesta feina va ser feta com part d'una presentació a GermEval 2021 de tasca compartida sobre la identificació de comentaris que afirmaven fets.</abstract_ca>
      <abstract_hy>Այս թղթի մեջ մենք ուսումնասիրում ենք, թե արդյունավետությունը օգտագործելով բազլեզու BER-ի և գերմանացի BER-ի կոնտեքստոնալ ներդրումներ' հասարակական լրատվամիջոցների մասին գերմանացի լեզվով փաստեր հայտնելու համար: Ավելին, մենք ուսումնասիրում ենք դասակարգման խնդիրը որպես բազմախնդիր ուսուցման խնդիր ձևավորելու ազդեցությունը, որտեղ մոդելը որոշում է մոտեցումների թունավորությունը և ներգրավումը, բացի նրանից, թե արդյոք այն փաստեր է պնդում: Մենք տրամադրում ենք երկու BER-ի հիմնված մոդելների հիմնական համեմատությունը, համեմատելով լոգոստիկ ռեգրեսիայի հիմնական հիմքի հետ, և ցույց ենք տալիս, որ գերմանական BER-ի առանձնահատկությունները, որոնք վարժեցվել են օգտագործելով բազմախնդիր օբ Այս աշխատանքը կատարվել է որպես մի մաս, որը ներկայացվել է Գերմ Էվալ 2021 թվականին ընդհանուր խնդիրը փաստեր պահանջող մեկնաբանությունների հայտնաբերման մասին:</abstract_hy>
      <abstract_cs>V tomto článku zkoumáme efektivitu využití kontextových vložení z vícejazyčného BERT a německého BERT při identifikaci faktových komentářů v němčině na sociálních médiích. Dále zkoumáme dopad formulace klasifikačního problému jako multi-tasking learning problému, kde model identifikuje toxicitu a angažovanost komentáře a zároveň identifikuje, zda se jedná o faktické tvrzení. Poskytujeme důkladné srovnání dvou modelů založených na BERT ve srovnání s logistickou regresí základní linií a ukážeme, že německé vlastnosti BERT trénované pomocí multi-tasking objektivu dosahují nejlepšího F1 skóre v testovací sadě. Tato práce byla provedena v rámci předložení společného úkolu GermEval 2021 na identifikaci skutečnostních komentářů.</abstract_cs>
      <abstract_et>Käesolevas töös uurime mitmekeelsete BERTi ja saksa BERTi kontekstipõhiste manustamiste tõhusust sotsiaalmeedias faktidele väidetavate kommentaaride tuvastamisel saksa keeles. Lisaks uurime klassifitseerimisprobleemi kui mitmeülesandelise õppeprobleemi sõnastamise mõju, kus mudel tuvastab kommentaari toksilisuse ja kaasatuse lisaks tuvastab, kas see on faktidele väidetav. Pakume põhjalikku võrdlust kahe BERT-põhise mudeli võrreldes logistilise regressiooni algväärtusega ja näitame, et Saksa BERT-funktsioonid, mis on treenitud mitme ülesandega, saavutavad testikomplekti parima F1 skoori. See töö tehti osana GermEval 2021 jagatud ülesandest tuvastada fakte väidetavad kommentaarid.</abstract_et>
      <abstract_fi>Tässä artikkelissa selvitämme monikielisten BERT- ja saksankielisten BERT-upotusten käytön tehokkuutta faktoja väittävien kommenttien tunnistamisessa saksaksi sosiaalisessa mediassa. Lisäksi tarkastelemme luokitteluongelman muotoilun vaikutusta monitehtäväoppimisongelmana, jossa malli tunnistaa kommentin myrkyllisyyden ja sitoutumisen sekä selvittää, onko se faktaesitys. Vertaamme perusteellisesti molempia BERT-pohjaisia malleja logistiseen regressioon ja osoitamme, että monitehtävätavoitteella koulutetut saksalaiset BERT-ominaisuudet saavuttavat parhaan F1-pisteen testisarjassa. Tämä työ tehtiin osana GermEval 2021:n jaettua tehtävää faktoja esittävien kommenttien tunnistamisesta.</abstract_fi>
      <abstract_jv>Nang pepulan iki, awak dhéwé nyokot nggunakake effek nggambar embedding contextual karo multilanggar BERT karo BERT nggambar barang kelangan kuwi nggawe Komentar sapa-kedahané ning aleman nganggo media sotiane. Label Awak dhéwé ngewehke perusahaan karo model sing sampek duwé BERT sampek karo perusahaan langgambar barang nggawe barang resmi Wuhané iki wis rampun ning pating nggawe gerapakan dhe germinval 2020 ora bisa ngejaraké perusahaan anyong komentar nggawe barang-barang.</abstract_jv>
      <abstract_sk>V tem prispevku raziskujemo učinkovitost uporabe kontekstualnih vdelav večjezičnih BERT in nemških BERT pri prepoznavanju komentarjev v nemščini na družbenih omrežjih. Poleg tega preučujemo vpliv oblikovanja klasifikacijskega problema kot večopravilnega učenja, kjer model identificira toksičnost in vključenost komentarja poleg ugotavljanja, ali gre za trditev dejstev. Zagotovili smo temeljito primerjavo obeh modelov BERT v primerjavi z izhodiščem logistične regresije in pokazali, da nemške funkcije BERT, usposobljene z večopravilnim ciljem, dosegajo najboljšo rezultato F1 v testnem naboru. To delo je bilo opravljeno v okviru predložitve skupne naloge GermEval 2021 za identifikacijo pripomb, ki trdijo dejstva.</abstract_sk>
      <abstract_ha>A cikin wannan takarda, Munã yin ƙidãya a kan amfani da matsayin mataimaki daga multi-lingui BERT da Jajeruman BERT dõmin a gane iznin da ke faɗa gaskiya a cikin jeruman a kan mitandan jamii. Ina ƙaranci, Munã jarraba matsalar kunnuwa masu fasalin kamar wata fitina na mai amfani da aiki masu yawa, a inda motel yana gane aikin mai tozarci da kuma ana sami izni da kuma a bayan ka gane shi ko yana madaidaita. Tuna samar da misãlai biyu masu basa BERT sami da kuma a danne logistic regression Baselin kuma Muke nuna cewa karatun BERT na da amfani da abun multi-aikin ya sami mafi kyaun F1 score kan jarraba. Wannan aikin aka samar da shi kamar wani juyi zuwa Germeval 2021 mai shirin aikin da aka samu shi a kan gane na-dai-rayon.</abstract_ha>
      <abstract_he>בעיתון הזה אנו חוקרים את היעילות של השימוש בתכניות קונטקסטיות מ-BERT רבשפותית וגרמנית BERT בזיהוי תגובות בעובדות בגרמנית על תקשורת חברתית. בנוסף, אנו בודקים את ההשפעה של התייצבות של בעיית ההקלטה כבעיה ללמוד במשימות רבות, שבו המודל מזהה רעילות ומתערבות של התערבות בנוסף לזהות אם זו טענת עובדות. אנו מספקים שיוואי יסודי של שני הדוגמנים המבוססים על BERT בהשוואה לבסיס גירוס לוגיסטי ומראים שהתכונות גרמניות BERT מאומנות באמצעות מטרה רבה משימות משיגות את הציון F1 הטוב ביותר בסט הבדיקות. העבודה הזו נעשתה כחלק מההועברה לגרמEval 2021 משימה משותפת על זיהוי העובדות טוענות עובדות.</abstract_he>
      <abstract_bo>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་སྤྱི་ཚོགས་སྐད་ཡིག་གི་BERT དང་སྐད་ཡིག་BERT་ལས་ཕན་ཚུན་ཐུག་གཏོང་ཁང་ལ་གཏོང་མཁན་གྱི་ལྟ་བ་རྟོགས་བ འོན་ཀྱང་། ང་ཚོས་དབྱེ་རིག་གི་དཀའ་ངལ་སྤྲོད་ཀྱི་ཆ་རྐྱེན་གྱི་དཀའ་ངལ་ཞིབ་དཔྱད་བྱས་ན། We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. ལས་ཀ་འདི་ནི་(GermEval)སྤྱི་ཚོལ་༢༠༡༢་ལོའི་ནང་དུ་འཇུག་སྣོད་འཛིན་གྱི་ལས་ཀ་གསལ་བཤད་པ་ཞིག་ངོས་འཛིན་བྱེད་སོང་།</abstract_bo>
      </paper>
    </volume>
</collection>