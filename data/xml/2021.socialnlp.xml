<collection id="2021.socialnlp">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media</booktitle>
      <editor><first>Lun-Wei</first><last>Ku</last></editor>
      <editor><first>Cheng-Te</first><last>Li</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.socialnlp-1</url>
    </meta>
    <frontmatter>
      <url hash="d0f89066">2021.socialnlp-1.0</url>
      <bibkey>socialnlp-2021-international</bibkey>
    </frontmatter>
    <paper id="3">
      <title>A Case Study of In-House Competition for Ranking Constructive Comments in a News Service</title>
      <author><first>Hayato</first><last>Kobayashi</last></author>
      <author><first>Hiroaki</first><last>Taguchi</last></author>
      <author><first>Yoshimune</first><last>Tabuchi</last></author>
      <author><first>Chahine</first><last>Koleejan</last></author>
      <author><first>Ken</first><last>Kobayashi</last></author>
      <author><first>Soichiro</first><last>Fujita</last></author>
      <author><first>Kazuma</first><last>Murao</last></author>
      <author><first>Takeshi</first><last>Masuyama</last></author>
      <author><first>Taichi</first><last>Yatsuka</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <author><first>Satoshi</first><last>Sekine</last></author>
      <pages>24&#8211;35</pages>
      <abstract>Ranking the user comments posted on a news article is important for online news services because comment visibility directly affects the user experience. Research on ranking comments with different metrics to measure the comment quality has shown &#8220;constructiveness&#8221; used in argument analysis is promising from a practical standpoint. In this paper, we report a case study in which this constructiveness is examined in the real world. Specifically, we examine an in-house competition to improve the performance of ranking constructive comments and demonstrate the effectiveness of the best obtained model for a commercial service.</abstract>
      <url hash="973a90ae">2021.socialnlp-1.3</url>
      <doi>10.18653/v1/2021.socialnlp-1.3</doi>
      <bibkey>kobayashi-etal-2021-case</bibkey>
    </paper>
    <paper id="4">
      <title>Quantifying the Effects of <fixed-case>COVID</fixed-case>-19 on Restaurant Reviews</title>
      <author><first>Ivy</first><last>Cao</last></author>
      <author><first>Zizhou</first><last>Liu</last></author>
      <author><first>Giannis</first><last>Karamanolakis</last></author>
      <author><first>Daniel</first><last>Hsu</last></author>
      <author><first>Luis</first><last>Gravano</last></author>
      <pages>36&#8211;60</pages>
      <abstract>The COVID-19 pandemic has implications beyond physical health, affecting society and economies. Government efforts to slow down the spread of the virus have had a severe impact on many businesses, including restaurants. Mandatory policies such as restaurant closures, bans on social gatherings, and social distancing restrictions have affected restaurant operations as well as customer preferences (e.g., prompting a demand of stricter hygiene standards). As of now, however, it is not clear how and to what extent the pandemic has affected restaurant reviews, an analysis of which could potentially inform policies for addressing this ongoing situation. In this work, we present our efforts to understand the effects of COVID-19 on restaurant reviews, with a focus on Yelp reviews produced during the pandemic for New York City and Los Angeles County restaurants. Overall, we make the following contributions. First, we assemble a dataset of 600 reviews with manual annotations of fine-grained COVID-19 aspects related to restaurants (e.g., hygiene practices, service changes, sympathy and support for local businesses). Second, we address COVID-19 aspect detection using supervised classifiers, weakly-supervised approaches based on keywords, and unsupervised topic modeling approaches, and experimentally show that classifiers based on pre-trained BERT representations achieve the best performance (F1=0.79). Third, we analyze the number and evolution of COVID-related aspects over time and show that the resulting time series have substantial correlation (Spearman&#8217;s <tex-math>\rho</tex-math>=0.84) with critical statistics related to the COVID-19 pandemic, including the number of new COVID-19 cases. To our knowledge, this is the first work analyzing the effects of COVID-19 on Yelp restaurant reviews and could potentially inform policies by public health departments, for example, to cover resource utilization.</abstract>
      <url hash="71f3d389">2021.socialnlp-1.4</url>
      <doi>10.18653/v1/2021.socialnlp-1.4</doi>
      <bibkey>cao-etal-2021-quantifying</bibkey>
    </paper>
    <paper id="5">
      <title>Assessing Cognitive Linguistic Influences in the Assignment of Blame</title>
      <author><first>Karen</first><last>Zhou</last></author>
      <author><first>Ana</first><last>Smith</last></author>
      <author><first>Lillian</first><last>Lee</last></author>
      <pages>61&#8211;69</pages>
      <abstract>Lab studies in cognition and the psychology of morality have proposed some thematic and linguistic factors that influence moral reasoning. This paper assesses how well the findings of these studies generalize to a large corpus of over 22,000 descriptions of fraught situations posted to a dedicated forum. At this social-media site, users judge whether or not an author is in the wrong with respect to the event that the author described. We find that, consistent with lab studies, there are statistically significant differences in uses of first-person passive voice, as well as first-person agents and patients, between descriptions of situations that receive different blame judgments. These features also aid performance in the task of predicting the eventual collective verdicts.</abstract>
      <url hash="1364306e">2021.socialnlp-1.5</url>
      <doi>10.18653/v1/2021.socialnlp-1.5</doi>
      <bibkey>zhou-etal-2021-assessing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/scruples">Scruples</pwcdataset>
    </paper>
    <paper id="6">
      <title>Evaluating Deception Detection Model Robustness To Linguistic Variation</title>
      <author><first>Maria</first><last>Glenski</last></author>
      <author><first>Ellyn</first><last>Ayton</last></author>
      <author><first>Robin</first><last>Cosbey</last></author>
      <author><first>Dustin</first><last>Arendt</last></author>
      <author><first>Svitlana</first><last>Volkova</last></author>
      <pages>70&#8211;80</pages>
      <abstract>With the increasing use of machine-learning driven algorithmic judgements, it is critical to develop models that are robust to evolving or manipulated inputs. We propose an extensive analysis of model robustness against linguistic variation in the setting of deceptive news detection, an important task in the context of misinformation spread online. We consider two prediction tasks and compare three state-of-the-art embeddings to highlight consistent trends in model performance, high confidence misclassifications, and high impact failures. By measuring the effectiveness of adversarial defense strategies and evaluating model susceptibility to adversarial attacks using character- and word-perturbed text, we find that character or mixed ensemble models are the most effective defenses and that character perturbation-based attack tactics are more successful.</abstract>
      <url hash="725f36c6">2021.socialnlp-1.6</url>
      <doi>10.18653/v1/2021.socialnlp-1.6</doi>
      <bibkey>glenski-etal-2021-evaluating</bibkey>
    </paper>
    <paper id="11">
      <title>Using Noisy Self-Reports to Predict <fixed-case>T</fixed-case>witter User Demographics</title>
      <author><first>Zach</first><last>Wood-Doughty</last></author>
      <author><first>Paiheng</first><last>Xu</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <pages>123&#8211;137</pages>
      <abstract>Computational social science studies often contextualize content analysis within standard demographics. Since demographics are unavailable on many social media platforms (e.g. Twitter), numerous studies have inferred demographics automatically. Despite many studies presenting proof-of-concept inference of race and ethnicity, training of practical systems remains elusive since there are few annotated datasets. Existing datasets are small, inaccurate, or fail to cover the four most common racial and ethnic groups in the United States. We present a method to identify self-reports of race and ethnicity from Twitter profile descriptions. Despite the noise of automated supervision, our self-report datasets enable improvements in classification performance on gold standard self-report survey data. The result is a reproducible method for creating large-scale training resources for race and ethnicity.</abstract>
      <url hash="c7fca580">2021.socialnlp-1.11</url>
      <doi>10.18653/v1/2021.socialnlp-1.11</doi>
      <bibkey>wood-doughty-etal-2021-using</bibkey>
      <pwccode url="https://bitbucket.org/mdredze/demographer" additional="false">mdredze/demographer</pwccode>
    </paper>
    <paper id="12">
      <title><fixed-case>PANDORA</fixed-case> Talks: Personality and Demographics on <fixed-case>R</fixed-case>eddit</title>
      <author><first>Matej</first><last>Gjurkovi&#263;</last></author>
      <author><first>Mladen</first><last>Karan</last></author>
      <author><first>Iva</first><last>Vukojevi&#263;</last></author>
      <author><first>Mihaela</first><last>Bo&#353;njak</last></author>
      <author><first>Jan</first><last>Snajder</last></author>
      <pages>138&#8211;152</pages>
      <abstract>Personality and demographics are important variables in social sciences and computational sociolinguistics. However, datasets with both personality and demographic labels are scarce. To address this, we present PANDORA, the first dataset of Reddit comments of 10k users partially labeled with three personality models and demographics (age, gender, and location), including 1.6k users labeled with the well-established Big 5 personality model. We showcase the usefulness of this dataset on three experiments, where we leverage the more readily available data from other personality models to predict the Big 5 traits, analyze gender classification biases arising from psycho-demographic variables, and carry out a confirmatory and exploratory analysis based on psychological theories. Finally, we present benchmark prediction models for all personality and demographic variables.</abstract>
      <url hash="05dfea1b">2021.socialnlp-1.12</url>
      <doi>10.18653/v1/2021.socialnlp-1.12</doi>
      <bibkey>gjurkovic-etal-2021-pandora</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/pandora">PANDORA</pwcdataset>
    </paper>
    <paper id="13">
      <title>Room to Grow: Understanding Personal Characteristics Behind Self Improvement Using Social Media</title>
      <author><first>MeiXing</first><last>Dong</last></author>
      <author><first>Xueming</first><last>Xu</last></author>
      <author><first>Yiwei</first><last>Zhang</last></author>
      <author><first>Ian</first><last>Stewart</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>153&#8211;162</pages>
      <abstract>Many people aim for change, but not everyone succeeds. While there are a number of social psychology theories that propose motivation-related characteristics of those who persist with change, few computational studies have explored the motivational stage of personal change. In this paper, we investigate a new dataset consisting of the writings of people who manifest intention to change, some of whom persist while others do not. Using a variety of linguistic analysis techniques, we first examine the writing patterns that distinguish the two groups of people. Persistent people tend to reference more topics related to long-term self-improvement and use a more complicated writing style. Drawing on these consistent differences, we build a classifier that can reliably identify the people more likely to persist, based on their language. Our experiments provide new insights into the motivation-related behavior of people who persist with their intention to change.</abstract>
      <url hash="b1cfcb24">2021.socialnlp-1.13</url>
      <doi>10.18653/v1/2021.socialnlp-1.13</doi>
      <bibkey>dong-etal-2021-room</bibkey>
    </paper>
    <paper id="15">
      <title>Jujeop: <fixed-case>K</fixed-case>orean Puns for K-pop Stars on Social Media</title>
      <author><first>Soyoung</first><last>Oh</last></author>
      <author><first>Jisu</first><last>Kim</last></author>
      <author><first>Seungpeel</first><last>Lee</last></author>
      <author><first>Eunil</first><last>Park</last></author>
      <pages>170&#8211;177</pages>
      <abstract>Jujeop is a type of pun and a unique way for fans to express their love for the K-pop stars they follow using Korean. One of the unique characteristics of Jujeop is its use of exaggerated expressions to compliment K-pop stars, which contain or lead to humor. Based on this characteristic, Jujeop can be separated into four distinct types, with their own lexical collocations: (1) Fragmenting words to create a twist, (2) Homophones and homographs, (3) Repetition, and (4) Nonsense. Thus, the current study first defines the concept of Jujeop in Korean, manually labels 8.6K comments and annotates the comments to one of the four Jujeop types. With the given annotated corpus, this study presents distinctive characteristics of Jujeop comments compared to the other comments by classification task. Moreover, with the clustering approach, we proposed a structural dependency within each Jujeop type. We have made our dataset publicly available for future research of Jujeop expressions.</abstract>
      <url hash="2bd866e7">2021.socialnlp-1.15</url>
      <doi>10.18653/v1/2021.socialnlp-1.15</doi>
      <bibkey>oh-etal-2021-jujeop</bibkey>
      <pwccode url="https://github.com/merry555/jujeop" additional="false">merry555/jujeop</pwccode>
    </paper>
    </volume>
</collection>