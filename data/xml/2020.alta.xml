<collection id="2020.alta">
  <volume id="1" ingest-date="2021-02-07">
    <meta>
      <booktitle>Proceedings of the The 18th Annual Workshop of the Australasian Language Technology Association</booktitle>
      <editor><first>Maria</first><last>Kim</last></editor>
      <editor><first>Daniel</first><last>Beck</last></editor>
      <editor><first>Meladel</first><last>Mistica</last></editor>
      <publisher>Australasian Language Technology Association</publisher>
      <address>Virtual Workshop</address>
      <month>December</month>
      <year>2020</year>
      <url hash="5ebe2288">2020.alta-1</url>
    </meta>
    <frontmatter>
      <url hash="c94ee8a9">2020.alta-1.0</url>
      <bibkey>alta-2020-australasian</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Feature-Based Forensic Text Comparison Using a <fixed-case>P</fixed-case>oisson Model for Likelihood Ratio Estimation</title>
      <author><first>Michael</first><last>Carne</last></author>
      <author><first>Shunichi</first><last>Ishihara</last></author>
      <pages>32&#8211;42</pages>
      <abstract>Score- and feature-based methods are the two main ones for estimating a forensic likelihood ratio (LR) quantifying the strength of evidence. In this forensic text comparison (FTC) study, a score-based method using the Cosine distance is compared with a feature-based method built on a Poisson model with texts collected from 2,157 authors. Distance measures (e.g. Burrows&#8217;s Delta, Cosine distance) are a standard tool in authorship attribution studies. Thus, the implementation of a score-based method using a distance measure is naturally the first step for estimating LRs for textual evidence. However, textual data often violates the statistical assumptions underlying distance-based models. Furthermore, such models only assess the similarity, not the typicality, of the objects (i.e. documents) under comparison. A Poisson model is theoretically more appropriate than distance-based measures for authorship attribution, but it has never been tested with linguistic text evidence within the LR framework. The log-LR cost (Cllr) was used to assess the performance of the two methods. This study demonstrates that: (1) the feature-based method outperforms the score-based method by a Cllr value of ca. 0.09 under the best-performing settings and; (2) the performance of the feature-based method can be further improved by feature selection.</abstract>
      <url hash="beca8450">2020.alta-1.4</url>
      <bibkey>carne-ishihara-2020-feature</bibkey>
    </paper>
    <paper id="5">
      <title>Modelling Verbal Morphology in <fixed-case>N</fixed-case>en</title>
      <author><first>Saliha</first><last>Muradoglu</last></author>
      <author><first>Nicholas</first><last>Evans</last></author>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <pages>43&#8211;53</pages>
      <abstract>Nen verbal morphology is particularly complex; a transitive verb can take up to 1,740 unique forms. The combined effect of having a large combinatoric space and a low-resource setting amplifies the need for NLP tools. Nen morphology utilises distributed exponence - a non-trivial means of mapping form to meaning. In this paper, we attempt to model Nen verbal morphology using state-of-the-art machine learning models for morphological reinflection. We explore and categorise the types of errors these systems generate. Our results show sensitivity to training data composition; different distributions of verb type yield different accuracies (patterning with E-complexity). We also demonstrate the types of patterns that can be inferred from the training data, through the case study of sycretism.</abstract>
      <url hash="ff3d2866">2020.alta-1.5</url>
      <bibkey>muradoglu-etal-2020-modelling</bibkey>
    </paper>
    <paper id="11">
      <title>Pandemic Literature Search: Finding Information on <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Vincent</first><last>Nguyen</last></author>
      <author><first>Maciek</first><last>Rybinski</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Zhenchang</first><last>Xing</last></author>
      <pages>92&#8211;97</pages>
      <abstract>Finding information related to a pandemic of a novel disease raises new challenges for information seeking and retrieval, as the new information becomes available gradually. We investigate how to better rank information for pandemic information retrieval. We experiment with different ranking algorithms and propose a novel end-to-end method for neural retrieval, and demonstrate its effectiveness on the TREC COVID search. This work could lead to a search system that aids scientists, clinicians, policymakers and others in finding reliable answers from the scientific literature.</abstract>
      <url hash="2ca9a550">2020.alta-1.11</url>
      <bibkey>nguyen-etal-2020-pandemic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
    </paper>
    <paper id="12">
      <title>Information Extraction from Legal Documents: A Study in the Context of Common Law Court Judgements</title>
      <author><first>Meladel</first><last>Mistica</last></author>
      <author><first>Geordie Z.</first><last>Zhang</last></author>
      <author><first>Hui</first><last>Chia</last></author>
      <author><first>Kabir Manandhar</first><last>Shrestha</last></author>
      <author><first>Rohit Kumar</first><last>Gupta</last></author>
      <author><first>Saket</first><last>Khandelwal</last></author>
      <author><first>Jeannie</first><last>Paterson</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Daniel</first><last>Beck</last></author>
      <pages>98&#8211;103</pages>
      <abstract>&#8216;Common Law&#8217; judicial systems follow the doctrine of precedent, which means the legal principles articulated in court judgements are binding in subsequent cases in lower courts. For this reason, lawyers must search prior judgements for the legal principles that are relevant to their case. The difficulty for those within the legal profession is that the information that they are looking for may be contained within a few paragraphs or sentences, but those few paragraphs may be buried within a hundred-page document. In this study, we create a schema based on the relevant information that legal professionals seek within judgements and perform text classification based on it, with the aim of not only assisting lawyers in researching cases, but eventually enabling large-scale analysis of legal judgements to find trends in court outcomes over time.</abstract>
      <url hash="e1d80d6f">2020.alta-1.12</url>
      <bibkey>mistica-etal-2020-information</bibkey>
    </paper>
    <paper id="17">
      <title>Overview of the 2020 <fixed-case>ALTA</fixed-case> Shared Task: Assess Human Behaviour</title>
      <author><first>Diego</first><last>Moll&#225;</last></author>
      <pages>127&#8211;130</pages>
      <abstract>The 2020 ALTA shared task is the 11th in stance of a series of shared tasks organised by ALTA since 2010. The task is to classify texts posted in social media according to human judgements expressed in them. The data used for this task is a subset of SemEval 2018 AIT DISC, which has been annotated by domain experts for this task. In this paper we introduce the task, describe the data and present the results of participating systems.</abstract>
      <url hash="5ea36a9e">2020.alta-1.17</url>
      <bibkey>molla-2020-overview</bibkey>
    </paper>
    </volume>
</collection>