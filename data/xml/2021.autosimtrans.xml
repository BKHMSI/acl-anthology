<collection id="2021.autosimtrans">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Automatic Simultaneous Translation</booktitle>
      <editor><first>Hua</first><last>Wu</last></editor>
      <editor><first>Colin</first><last>Cherry</last></editor>
      <editor><first>Liang</first><last>Huang</last></editor>
      <editor><first>Zhongjun</first><last>He</last></editor>
      <editor><first>Qun</first><last>Liu</last></editor>
      <editor><first>Maha</first><last>Elbayad</last></editor>
      <editor><first>Mark</first><last>Liberman</last></editor>
      <editor><first>Haifeng</first><last>Wang</last></editor>
      <editor><first>Mingbo</first><last>Ma</last></editor>
      <editor><first>Ruiqing</first><last>Zhang</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.autosimtrans-1</url>
    </meta>
    <frontmatter>
      <url hash="a887cca4">2021.autosimtrans-1.0</url>
      <bibkey>autosimtrans-2021-automatic</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>ICT</fixed-case>&#8217;s System for <fixed-case>A</fixed-case>uto<fixed-case>S</fixed-case>im<fixed-case>T</fixed-case>rans 2021: Robust Char-Level Simultaneous Translation</title>
      <author><first>Shaolei</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>1&#8211;11</pages>
      <abstract>Simultaneous translation (ST) outputs the translation simultaneously while reading the input sentence, which is an important component of simultaneous interpretation. In this paper, we describe our submitted ST system, which won the first place in the streaming transcription input track of the Chinese-English translation task of AutoSimTrans 2021. Aiming at the robustness of ST, we first propose char-level simultaneous translation and applied wait-k policy on it. Meanwhile, we apply two data processing methods and combine two training methods for domain adaptation. Our method enhance the ST model with stronger robustness and domain adaptability. Experiments on streaming transcription show that our method outperforms the baseline at all latency, especially at low latency, the proposed method improves about 6 BLEU. Besides, ablation studies we conduct verify the effectiveness of each module in the proposed method.</abstract>
      <url hash="2ee04c3d">2021.autosimtrans-1.1</url>
      <doi>10.18653/v1/2021.autosimtrans-1.1</doi>
      <bibkey>zhang-feng-2021-icts</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>XMU</fixed-case>&#8217;s Simultaneous Translation System at <fixed-case>NAACL</fixed-case> 2021</title>
      <author><first>Shuangtao</first><last>Li</last></author>
      <author><first>Jinming</first><last>Hu</last></author>
      <author><first>Boli</first><last>Wang</last></author>
      <author><first>Xiaodong</first><last>Shi</last></author>
      <author><first>Yidong</first><last>Chen</last></author>
      <pages>19&#8211;23</pages>
      <abstract>This paper describes our two systems submitted to the simultaneous translation evaluation at the 2nd automatic simultaneous translation workshop.</abstract>
      <url hash="b22c6f61">2021.autosimtrans-1.3</url>
      <doi>10.18653/v1/2021.autosimtrans-1.3</doi>
      <bibkey>li-etal-2021-xmus</bibkey>
    </paper>
    </volume>
</collection>