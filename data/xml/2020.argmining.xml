<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.argmining">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Argument Mining</booktitle>
      <editor><first>Elena</first><last>Cabrio</last></editor>
      <editor><first>Serena</first><last>Villata</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="9d500249">2020.argmining-1.0</url>
      <bibkey>argmining-2020-argument</bibkey>
    </frontmatter>
    <paper id="1">
      <title>DebateSum : A large-scale argument mining and summarization dataset<fixed-case>D</fixed-case>ebate<fixed-case>S</fixed-case>um: A large-scale argument mining and summarization dataset</title>
      <author><first>Allen</first><last>Roush</last></author>
      <author><first>Arvind</first><last>Balaji</last></author>
      <pages>1–7</pages>
      <abstract>Prior work in <a href="https://en.wikipedia.org/wiki/Argument_mining">Argument Mining</a> frequently alludes to its potential applications in automatic debating systems. Despite this focus, almost no <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> or <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> exist which apply <a href="https://en.wikipedia.org/wiki/Natural-language_processing">natural language processing techniques</a> to problems found within competitive formal debate. To remedy this, we present the DebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with corresponding <a href="https://en.wikipedia.org/wiki/Argument">argument</a> and extractive summaries. DebateSum was made using <a href="https://en.wikipedia.org/wiki/Data">data</a> compiled by competitors within the <a href="https://en.wikipedia.org/wiki/National_Speech_and_Debate_Association">National Speech and Debate Association</a> over a 7year period. We train several transformer summarization models to benchmark <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a> performance on DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Finally, we present a <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engine</a> for this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> which is utilized extensively by members of the <a href="https://en.wikipedia.org/wiki/National_Speech_and_Debate_Association">National Speech and Debate Association</a> today. The DebateSum search engine is available to the public here : http://www.debate.cards</abstract>
      <url hash="3352bff5">2020.argmining-1.1</url>
      <bibkey>roush-balaji-2020-debatesum</bibkey>
      <pwccode url="https://github.com/arvind-balaji/debate-cards" additional="true">arvind-balaji/debate-cards</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/debatesum">DebateSum</pwcdataset>
    <title_ar>DebateSum: مجموعة بيانات التعدين والتلخيص على نطاق واسع</title_ar>
      <title_fr>DebateSum : un ensemble de données d'exploration et de synthèse d'arguments à grande échelle</title_fr>
      <title_es>DebateSum: un conjunto de datos de resumen y minería de argumentos a gran escala</title_es>
      <title_pt>DebateSum: Um conjunto de dados de mineração e sumarização de argumentos em larga escala</title_pt>
      <title_ja>DebateSum:大規模な引数マイニングと要約データセット</title_ja>
      <title_zh>论总结:大论掘、总结数据集</title_zh>
      <title_ru>DebateSum: Масштабный набор данных для интеллектуального анализа и обобщения аргументов</title_ru>
      <title_hi>DebateSum: एक बड़े पैमाने पर तर्क खनन और सारांश डेटासेट</title_hi>
      <title_ga>DebateSum: Tacar sonraí mianadóireachta agus achoimrithe argóinte ar mhórscála</title_ga>
      <title_ka>DebateSum</title_ka>
      <title_el>Ένα σύνολο δεδομένων εξόρυξης και σύνοψης επιχειρημάτων μεγάλης κλίμακας</title_el>
      <title_hu>DebateSum: Egy nagyszabású argumentumbányászat és összefoglaló adatkészlet</title_hu>
      <title_it>DebateSum: un set di dati di estrazione e sintesi di argomenti su larga scala</title_it>
      <title_lt>DebataSum: A large-scale argument mining and summarization data set</title_lt>
      <title_mk>Дебата</title_mk>
      <title_kk>Жөндеу</title_kk>
      <title_ms>DebateSum: A large-scale argument mining and summarization dataset</title_ms>
      <title_mt>Somma tad-dibattitu: Sett ta’ dejta dwar it-tħaffir fil-minjieri u s-sommarju ta’ argumenti fuq skala kbira</title_mt>
      <title_ml>വ്യത്യാസSum: A large- scale argument mining and summarization data set</title_ml>
      <title_mn>DebateSum: Маш том хэмжээний аргументын багасгаж, хуваалтын өгөгдлийн санг</title_mn>
      <title_no>DebateSum: A large-scale argument mining and summarization dataset</title_no>
      <title_pl>DebateSum: Zestaw danych eksploracji argumentów na dużą skalę i podsumowania</title_pl>
      <title_ro>DebateSum: Un set de date de mining și rezumare a argumentelor la scară largă</title_ro>
      <title_sr>DebateSum: Velika skala argumenta za rudarstvo i sažetanje podataka</title_sr>
      <title_si>@ label: textbox</title_si>
      <title_so>Sum: A large-scale argument mining and summarisation dataset</title_so>
      <title_sv>DebateSum: En datauppsättning för utvinning och sammanfattning av argument i stor skala</title_sv>
      <title_ta>விவாதம்Sum: A large- scale argument mining and summarization data set</title_ta>
      <title_ur>DebateSum: ایک بزرگ- اسکیل ارومین مینی اور سراسر ڈاٹ سٹ</title_ur>
      <title_uz>DebateSum: A large-scale argument mining and summarization dataset</title_uz>
      <title_vi>Name=giải thích Comment=Game bàn Comment</title_vi>
      <title_bg>DebateSum: масивен набор от данни за извличане и обобщаване на аргументи</title_bg>
      <title_hr>DebateSum: Velika skala argumenta za rudarstvo i sažetak podataka</title_hr>
      <title_da>DebateSum: Et stort datasæt til argumentmining og opsummering</title_da>
      <title_nl>DebateSum: Een grootschalige dataset voor argumentmining en samenvatting</title_nl>
      <title_de>DebateSumm: Ein umfangreicher Datensatz für Argument Mining und Zusammenfassung</title_de>
      <title_id>DebateSum: Sebuah argumen skala besar penambangan dan dataset ringkasan</title_id>
      <title_ko>DebateSum: 대규모 논점 발굴 및 정리 데이터 세트</title_ko>
      <title_fa>DebateSum: یک مجموعه داده‌های ذخیره‌سازی و جمع‌سازی اردوмент مقیاس بزرگ</title_fa>
      <title_sw>Summary: Mjadala mkubwa wa uchimbaji madini na taarifa za muhtasari</title_sw>
      <title_tr>Sum: A large-scale argument mining and summarization dataset</title_tr>
      <title_af>DebateSum: ' n groot- scale argument mining en opsomming dataset</title_af>
      <title_sq>DebateSum: Një argument në shkallë të madhe mining dhe përmbledhje të dhënash</title_sq>
      <title_am>Sum: A large-scale argument mining and summary data set</title_am>
      <title_hy>Դեբատես</title_hy>
      <title_az>DebateSum: A large-scale argument mining and summarization data set</title_az>
      <title_bn>বিতর্ক: A large- scale argument mining and summarization data set</title_bn>
      <title_bs>DebateSum: Velika skala argumenta za rudarstvo i sažetak podataka</title_bs>
      <title_ca>DebateSum: Un conjunt de dades d'extracció i resum d'arguments a gran escala</title_ca>
      <title_et>DebateSum: ulatuslik argumentide kaevandamise ja kokkuvõtliku andmekogum</title_et>
      <title_cs>DebateSumm: Rozsáhlá datová sada těžby argumentů a shrnutí</title_cs>
      <title_fi>DebateSum: Laajamittainen argumenttien louhinta- ja yhteenvetoaineisto</title_fi>
      <title_jv>Sum: A big-scale argument mineing and suming dataset</title_jv>
      <title_sk>DebateSum: obsežen nabor podatkov o rudarjenju argumentov in povzetku</title_sk>
      <title_he>DebateSum: מסגרת מידע מינוי ומסגרת</title_he>
      <title_ha>Sum: A size- scale argument minining and sumarization data set</title_ha>
      <title_bo>DebateSum: A large-scale argument mining and summarization dataset</title_bo>
      <abstract_ar>كثيرًا ما يلمح العمل السابق في Argument Mining إلى تطبيقاته المحتملة في أنظمة المناقشة التلقائية. على الرغم من هذا التركيز ، لا توجد مجموعات بيانات أو نماذج تقريبًا تطبق تقنيات معالجة اللغة الطبيعية على المشكلات الموجودة في النقاش الرسمي التنافسي. لتصحيح ذلك ، نقدم مجموعة بيانات DebateSum. يتكون DebateSum من 187386 قطعة فريدة من الأدلة مع الحجة المقابلة والملخصات المستخرجة. تم إجراء DebateSum باستخدام البيانات التي جمعها المنافسون داخل الرابطة الوطنية للخطاب والمناظرة على مدار 7 سنوات. نقوم بتدريب العديد من نماذج تلخيص المحولات لقياس أداء التلخيص في DebateSum. نقدم أيضًا مجموعة من متجهات الكلمات ذات النص السريع التي تم تدريبها على DebateSum تسمى المناقشة 2vec. أخيرًا ، نقدم محرك بحث لمجموعة البيانات هذه والذي يتم استخدامه على نطاق واسع من قبل أعضاء الجمعية الوطنية للخطاب والمناظرة اليوم. محرك بحث DebateSum متاح للجمهور هنا: http://www.debate.cards</abstract_ar>
      <abstract_pt>O trabalho anterior em Argument Mining frequentemente alude às suas aplicações potenciais em sistemas de debate automático. Apesar desse foco, quase não existem conjuntos de dados ou modelos que apliquem técnicas de processamento de linguagem natural a problemas encontrados no debate formal competitivo. Para remediar isso, apresentamos o conjunto de dados DebateSum. O DebateSum consiste em 187.386 peças únicas de evidência com argumentos e resumos extrativos correspondentes. O DebateSum foi feito usando dados compilados por concorrentes da National Speech and Debate Association durante um período de 7 anos. Treinamos vários modelos de sumarização de transformadores para comparar o desempenho da sumarização no DebateSum. Também apresentamos um conjunto de vetores de palavras de texto rápido treinados no DebateSum chamado debate2vec. Finalmente, apresentamos um mecanismo de busca para este conjunto de dados que é amplamente utilizado pelos membros da National Speech and Debate Association hoje. O motor de busca DebateSum está disponível ao público aqui: http://www.debate.cards</abstract_pt>
      <abstract_es>El trabajo anterior en Argument Mining con frecuencia alude a sus posibles aplicaciones en los sistemas de debate automático. A pesar de este enfoque, casi no existen conjuntos de datos o modelos que apliquen técnicas de procesamiento del lenguaje natural a los problemas que se encuentran en el debate formal competitivo. Para remediar esto, presentamos el conjunto de datos DebateSum. DebateSum consta de 187 386 piezas de evidencia únicas con el argumento correspondiente y los resúmenes extractivos. DebateSum se realizó utilizando datos recopilados por competidores dentro de la Asociación Nacional de Discurso y Debate durante un período de 7 años. Entrenamos varios modelos de resumen de transformadores para comparar el rendimiento de resumen en DebateSum. También presentamos un conjunto de vectores de palabras de texto rápido entrenados en DebateSum llamado debate2vec. Finalmente, presentamos un motor de búsqueda para este conjunto de datos que actualmente utilizan ampliamente los miembros de la Asociación Nacional de Discurso y Debate. El motor de búsqueda DebateSum está disponible para el público aquí: http://www.debate.cards</abstract_es>
      <abstract_fr>Les travaux antérieurs dans Argument Mining font souvent allusion à ses applications potentielles dans les systèmes de débat automatique. Malgré cette focalisation, il n'existe pratiquement aucun ensemble de données ou modèle qui applique des techniques de traitement du langage naturel à des problèmes rencontrés dans le cadre d'un débat formel compétitif. Pour y remédier, nous présentons l'ensemble de données DebateSum. DebateSum se compose de 187 386 éléments de preuve uniques avec des arguments correspondants et des résumés extractifs. DebateSum a été créé à partir de données compilées par des concurrents au sein de la National Speech and Debate Association sur une période de 7 ans. Nous entraînons plusieurs modèles de synthèse de transformateurs pour évaluer les performances de synthèse sur DebateSum. Nous introduisons également un ensemble de vecteurs de mots rapides formés sur DebateSum appelés debate2vec. Enfin, nous présentons un moteur de recherche pour cet ensemble de données qui est largement utilisé par les membres de la National Speech and Debate Association aujourd'hui. Le moteur de recherche DebateSum est accessible au public ici : http://www.debate.cards</abstract_fr>
      <abstract_ja>Argument Miningの以前の仕事では、自動ディベートシステムへの潜在的な応用について頻繁に言及しています。この焦点にもかかわらず、競争的な正式な議論の中で見つかった問題に自然言語処理技術を適用するデータセットやモデルはほとんど存在しない。これを修正するために、DebateSumデータセットを提示します。DebateSumは、187,386個のユニークな証拠と、対応する議論と抽出サマリーで構成されています。DebateSumは、National Speech and Debate Association内の競合他社が7年間にわたってまとめたデータを使用して作成されました。DebateSumでは、いくつかの変圧器の要約モデルをトレーニングして、ベンチマークの要約パフォーマンスを実現しています。また、DebateSumで訓練された、debate 2 vecと呼ばれるファストテキストのワードベクターのセットも紹介します。最後に、このデータセットの検索エンジンを提示します。この検索エンジンは、今日のNational Speech and Debate Associationのメンバーによって幅広く利用されています。DebateSum検索エンジンはhttp://www.debate.cardsで一般公開されています。</abstract_ja>
      <abstract_hi>तर्क खनन में पूर्व कार्य अक्सर स्वचालित वाद-विवाद प्रणालियों में अपने संभावित अनुप्रयोगों को इंगित करता है। इस फोकस के बावजूद, लगभग कोई डेटासेट या मॉडल मौजूद नहीं हैं जो प्रतिस्पर्धी औपचारिक बहस के भीतर पाई जाने वाली समस्याओं के लिए प्राकृतिक भाषा प्रसंस्करण तकनीकों को लागू करते हैं। इसका समाधान करने के लिए, हम DebateSum डेटासेट प्रस्तुत करते हैं। वाद-विवादसम में इसी तर्क और निष्कर्षण सारांश के साथ सबूत के 187,386 अद्वितीय टुकड़े शामिल हैं। वाद-विवाद 7 साल की अवधि में राष्ट्रीय भाषण और वाद-विवाद संघ के भीतर प्रतियोगियों द्वारा संकलित डेटा का उपयोग करके किया गया था। हम कई ट्रांसफॉर्मर summarization मॉडल को प्रशिक्षित करने के लिए बेंचमार्क debateSum पर summarization प्रदर्शन. हम भी fasttext शब्द-वैक्टर का एक सेट बहस पर प्रशिक्षित वेक्टर परिचयUm debate2vec बुलाया. अंत में, हम इस डेटासेट के लिए एक खोज इंजन प्रस्तुत करते हैं जो आज राष्ट्रीय भाषण और बहस संघ के सदस्यों द्वारा बड़े पैमाने पर उपयोग किया जाता है। DebateSum खोज इंजन यहाँ जनता के लिए उपलब्ध है: http://www.debate.cards</abstract_hi>
      <abstract_zh>先于参数发掘,常讽其自辩系统之用。 虽有此注,殆无数集自然语言术用于竞争性文。 为此数集 DebateSum 。 DebateSum由187,386独证及所论摘要成。 DebateSum者,用国讲辩协会内竞争对手于7年编数为之。 练转换器摘要模样,以 DebateSum 准摘要。 引入 DebateSum 上训练之快文本词向量,谓之 debate2vec。 最后,建此数集之搜索引擎,今天下讲论协会博用此搜索引擎。 DebateSum搜索引擎可于此开公众:http://www.debate.cards</abstract_zh>
      <abstract_ru>Предыдущая работа в Argument Mining часто намекает на ее потенциальные применения в автоматических дискуссионных системах. Несмотря на эту направленность, практически не существует наборов данных или моделей, которые применяли бы методы обработки естественного языка к проблемам, обнаруженным в рамках формальных дебатов по вопросам конкуренции. Чтобы исправить это, мы представляем набор данных DebateSum. DebateSum состоит из 187 386 уникальных доказательств с соответствующими аргументами и резюме. DebateSum был сделан с использованием данных, собранных конкурентами в рамках Национальной ассоциации речи и дебатов за 7-летний период. Мы обучаем несколько моделей суммирования трансформаторов для сравнения эффективности суммирования на DebateSum. Мы также представляем набор векторов быстрых текстов, обученных на DebateSum под названием debate2vec. Наконец, мы представляем поисковую систему для этого набора данных, которая широко используется сегодня членами Национальной ассоциации речи и дебатов. Поисковая система DebateSum доступна для общественности здесь: http://www.debate.cards</abstract_ru>
      <abstract_ga>Is minic a luann réamhobair i Mianadóireacht Argóine a fheidhmchláir ionchasacha i gcórais dhíospóireachta uathoibríocha. In ainneoin an fhócas seo, níl mórán tacair sonraí nó samhlacha ann a chuireann teicnící próiseála teanga nádúrtha i bhfeidhm ar fhadhbanna a fhaightear i ndíospóireacht fhoirmiúil iomaíoch. Chun é seo a leigheas, cuirimid an tacar sonraí DebateSum i láthair. Is éard atá i nDíospóireachtSum ná 187,386 píosa uathúil fianaise le hargóintí comhfhreagracha agus achoimrí eastóscacha. Baineadh leas as sonraí a thiomsaigh iomaitheoirí laistigh den Chumann Náisiúnta Urlabhra agus Díospóireachta thar thréimhse 7 mbliana. Cuirimid oiliúint ar roinnt samhlacha achoimrithe claochladán chun feidhmíocht achoimre a thagarmharcáil ar DebateSum. Tugaimid isteach freisin sraith de veicteoirí focal-téacs tapa oilte ar DebateSum ar a dtugtar debate2vec. Ar deireadh, cuirimid inneall cuardaigh i láthair don tacar sonraí seo a úsáideann baill an Chumainn Náisiúnta Urlabhra agus Díospóireachta go forleathan inniu. Tá inneall cuardaigh DebateSum ar fáil don phobal anseo: http://www.debate.cards</abstract_ga>
      <abstract_hu>Az Argument Mining korábbi munkái gyakran utalnak a potenciális alkalmazásaira az automatikus vitarendszerekben. Ennek ellenére szinte nem létezik olyan adatkészlet vagy modell, amely természetes nyelvfeldolgozási technikákat alkalmaz a versenyképes formális vita során felmerülő problémákra. Ennek orvoslása érdekében bemutatjuk a DebateSum adatkészletet. A DebateSum 187 386 egyedi bizonyítékot tartalmaz a megfelelő érveléssel és kivonatos összefoglalókkal. A DebateSum az Országos Beszéd- és Vitaszövetség versenyzői által összeállított adatok felhasználásával készült hétéves időszak alatt. Több transzformátor összefoglaló modellt képzünk a DebateSum összefoglaló teljesítményének összehasonlítására. Bemutatjuk továbbá a DebateSum nevű fasttext szóvektorokat, amelyeket debate2vec-nek neveznek. Végül bemutatunk egy keresőmotort erre az adatkészletre, amelyet ma az Országos Beszéd- és Vitaszövetség tagjai széles körben használnak. A DebateSum keresőmotor itt érhető el a nyilvánosság számára: http://www.debate.cards</abstract_hu>
      <abstract_el>Οι προηγούμενες εργασίες στην εξόρυξη επιχειρημάτων συχνά αναφέρονται στις πιθανές εφαρμογές της σε συστήματα αυτόματης συζήτησης. Παρά την εστίαση αυτή, σχεδόν δεν υπάρχουν σύνολα δεδομένων ή μοντέλα που να εφαρμόζουν τεχνικές επεξεργασίας φυσικής γλώσσας σε προβλήματα που εντοπίζονται στο πλαίσιο της ανταγωνιστικής επίσημης συζήτησης. Για να διορθωθεί αυτό, παρουσιάζουμε το σύνολο δεδομένων DebateSum. Το DebateSum αποτελείται από 187,386 μοναδικά αποδεικτικά στοιχεία με αντίστοιχα επιχειρήματα και αποσπαστικές περιλήψεις. Το DebateSumm έγινε χρησιμοποιώντας δεδομένα που συγκεντρώθηκαν από ανταγωνιστές στο πλαίσιο της Εθνικής Ένωσης Ομιλίας και Συζήτηση για 7ετή περίοδο. Εκπαιδεύουμε διάφορα μοντέλα σύνοψης μετασχηματιστών για να αξιολογήσουμε την απόδοση σύνοψης στο DebateSum. Παρουσιάζουμε επίσης ένα σύνολο λέξεων που εκπαιδεύονται στο DebiteSum που ονομάζεται debate2vec. Τέλος, παρουσιάζουμε μια μηχανή αναζήτησης για αυτό το σύνολο δεδομένων που χρησιμοποιείται εκτενώς από τα μέλη του Εθνικού Συλλόγου Ομιλίας και Συζήτηση σήμερα. Η μηχανή αναζήτησης είναι διαθέσιμη στο κοινό εδώ: http://www.debate.cards</abstract_el>
      <abstract_ka>პირველი სამუშაო აპგუმენტის მინუსაციაში მხოლოდ მისი პოცენტალური პროგრამებში ავტომატური debatური სისტემებში იყენებს. ამ ფოკუნტის განმავლობაში, პირდაპირად არ არსებობს მონაცემები ან მოდელები, რომლებიც ნაირადი ენის პროცესირების ტექნოგიების გამოყენება კონკუნტებული ფ ჱა ეა დჲ ნაოპაგთმვ რჲა, ოპვეჟრაგთმვ ევბარჟსმ ეატარა ჟვრკა. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum იქნება 7 წლის პერიოდის ნაციონალური საუბრის და განსაზღვრების აციოციაციაციაციაციაციაციაციაციაციაციაციაში კომპიკენტირებით გამოყ ჩვენ განვიყავით რამდენიმე ტრანფორმეტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრის ჩვენ ასევე შევცვალოთ სწრაფად ტექსტის სიტყვების გვექტორის სტრიქცია, რომელიც DebateSum სახელი debate2vec. საბოლოოდ, ჩვენ ამ მონაცემების ძიება მონაცემების ძიება, რომელიც დღეს ნაციონალური საუბრის და განსაკუთრების აციოციაციაციაციაციაციაციაციაციაციაცი DebateSum ძებნა მოწყობილობა აქ ადამიანებისთვის ხელსახურება: http://www.debate.cards</abstract_ka>
      <abstract_it>Il lavoro precedente in Argument Mining spesso allude alle sue potenziali applicazioni nei sistemi di dibattito automatico. Nonostante questa attenzione, non esistono quasi set di dati o modelli che applichino tecniche di elaborazione del linguaggio naturale ai problemi riscontrati nel dibattito formale competitivo. Per rimediare, presentiamo il dataset DebateSum. DebateSum consiste di 187.386 pezzi unici di prova con argomenti corrispondenti e riassunti estrattivi. DebateSum è stato realizzato utilizzando dati compilati dai concorrenti all'interno dell'Associazione Nazionale Discorso e Dibattito per un periodo di 7 anni. Formiamo diversi modelli di riepilogo dei trasformatori per confrontare le prestazioni di riepilogo su DebateSum. Presentiamo anche un insieme di vettori di parole fasttext formati su DebateSum chiamati debate2vec. Infine, presentiamo un motore di ricerca per questo set di dati che viene utilizzato ampiamente dai membri della National Speech and Debate Association oggi. Il motore di ricerca DebateSum è disponibile al pubblico qui: http://www.debate.cards</abstract_it>
      <abstract_lt>Ankstesnis darbas Argument Mining dažnai rodo, kad jis gali būti naudojamas automatinėse diskusijų sistemose. Nepaisant to, beveik nėra duomenų rinkinių ar modelių, kurie taikytų natūralių kalbų apdorojimo metodus konkurencinėse oficialiose diskusijose nustatytoms problemoms spręsti. Norėdami tai ištaisyti, pristatysime DebateSum duomenų rinkinį. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries.  DebateSum was made using data compiled by competitors within the National Speech and Debate Association over a 7year period.  Mes rengiame keletą transformatorių santraukų modelių, kad lygintume santraukų rezultatus DebateSum. Taip pat pristatome spartaus teksto žodžių vektorių rinkinį, apmokytą DebateSum, vadinamą debate2vec. Galiausiai pristatome paieškos variklį šiam duomenų rinkiniui, kurį šiandien plačiai naudoja Nacionalinės kalbos ir diskusijų asociacijos nariai. DebateSum paieškos variklis yra prieinamas visuomenei čia: http://www.debate.cards</abstract_lt>
      <abstract_kk>Аргумент балауындағы алдыңғы жұмыс автоматты дебаттау жүйелерінде мүмкін қолданбаларына көптеген. Бұл көздеген қарамастан, тәуелсіздік тәуелсіздік дискуссияларында табылған мәселелерге негізінде деректер қорлары не үлгілер жоқ. Бұны түзету үшін DebateSum деректер жиынын көрсетуіміз керек. DebateSum бағдарламасының 187 386 бірнеше бөлшектері бар. Сәйкес аргументті және шығыс тұжырымдары бар. DebateSum 7 жыл бөлігінде ұлттық сөйлеу және Debate ассоциациясындағы конкурсорлар компиляцияланған деректерді қолданады. Біз DebateSum дегенде бірнеше түрлендіруші тұжырымдамасының үлгілерін бақылау үлгілерін үйренеміз. Сонымен қатар, DebateSum деген debate2vec деп аталатын тез мәтін векторлар тізімін келтіреміз. Соңында, біз бұл деректер жиынын іздеу тетігін таңдаймыз. Бүгін Ұлттық сөйлеу мен жөндеу ассоциясының мүшелері қолданылады. DebateSum іздеу тетігі мұнда көпшілік үшін бар: http://www.debate.cards</abstract_kk>
      <abstract_mk>Претходната работа во Аргументно минирање честопати наведува на нејзините потенцијални апликации во автоматски дебатирачки системи. И покрај овој фокус, речиси нема датотеки или модели кои аплицираат природни техники за обработување јазик на проблемите откриени во конкурентната формална дебата. За да го поправиме ова, ја претставуваме датотеката DebateSum. DebateSum се состои од 187.386 уникатни докази со соодветни аргументи и екстрактивни резултати. ДебататSum беше направен со користење на податоците собрани од конкурентите во рамките на Националната здруженост за говор и дебат во текот на седумгодишен период. Тренираме неколку модели за резултат на трансформаторите за да ги споредиме резултатите на резултатот на резултатот на DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec.  Конечно, претставуваме пребарувачки мотор за овој податок кој е искористен екстремно од членовите на Националната Здружба за говор и дебат денес. Побарачкиот мотор DebateSum е достапен за јавноста тука: http://www.debate.cards</abstract_mk>
      <abstract_ms>Kerja terdahulu dalam Penyembang Argumen sering menyebutkan aplikasi potensi dalam sistem debat automatik. Walaupun fokus ini, hampir tiada set data atau model yang wujud yang melaksanakan teknik pemprosesan bahasa semulajadi kepada masalah yang ditemui dalam perdebatan rasmi kompetitif. Untuk memperbaiki ini, kami memperkenalkan set data DebateSum. DebateSum terdiri dari 187,386 bukti unik dengan argumen yang sepadan dan ringkasan ekstraktif. DebateSum dibuat menggunakan data dikumpil oleh kompetitor dalam Persatuan Perbualan dan Debat Nasional selama 7 tahun. Kami melatih beberapa model pengringkasan pengubah untuk benchmark prestasi pengringkasan pada DebateSum. Kami juga memperkenalkan set vektor perkataan teks pantas dilatih pada DebateSum yang dipanggil debate2vec. Akhirnya, kami memperkenalkan enjin gelintar untuk set data ini yang digunakan secara luas oleh ahli Persatuan Perkataan Nasional dan Debate hari ini. Enjin gelintar DebateSum tersedia untuk masyarakat di sini: http://www.debate.cards</abstract_ms>
      <abstract_ml>ആര്‍ഗമെന്റ് മൈനിംഗില്‍ മുമ്പ് ജോലി എപ്പോഴും അതിന്റെ സാധ്യതകളുടെ പ്രയോഗങ്ങള്‍ക്ക് ഉപയോഗിക്കുന്നു ഈ ഫോക്സോക്സ് ചെയ്യുന്നതിന് ശേഷം, സ്വാഭാവികമായ ഭാഷ പ്രവര്‍ത്തിപ്പിക്കുന്ന സാങ്കേതികങ്ങള്‍ പ്രയോഗിക്കുന്നില്ല,  ഇത് ശരിയാക്കാന്‍ വേണ്ടി, നമ്മള്‍ ഡെവറ്റ് ഡാറ്റാസെറ്റിനെ കാണിക്കുന്നു. വ്യത്യാസസംഖ്യ 187,386 പ്രത്യേക തെളിവുകളുടെ കൂട്ടത്തില്‍ ഉള്ളതാണ് വ്യക്തമായ തെളിവുകള്‍, വ്യത്യസ്തമായ വിവരങ്ങള്‍ ഉ നാഷണല്‍ സംസാരിക്കുന്നതിനും വിവരങ്ങള്‍ സംഘടിപ്പിക്കുന്നതിനുള്ള വിവരങ്ങള്‍ കൂട്ടിചേര്‍ക്കുന്നതിനുള്ള വിവരങ് നമ്മള്‍ കുറച്ച് മാറ്റങ്ങളുടെ സംസാരിക്കുന്ന മോഡലുകളെ പരിശീലിപ്പിക്കുന്നു We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec.  അവസാനം, നമ്മള്‍ ഈ ഡാറ്റാസേറ്റിന്റെ തെരച്ചില്‍ എഞ്ചിന്‍ കാണിച്ചുകൊണ്ടിരിക്കുന്നു. ഇന്ന് നാഷണല്‍ സംസാരിക്കുന്നതും  സൂമ് തെരച്ചില്‍ എഞ്ചിന്‍ ഇവിടെ ജനങ്ങള്‍ക്ക് ലഭ്യമാണ്: http://www.debate.cards</abstract_ml>
      <abstract_mt>Xogħol preċedenti fil-Minjieri tal-Argumenti ta’ spiss isemmi l-applikazzjonijiet potenzjali tiegħu f’sistemi ta’ dibattitu awtomatiku. Minkejja dan il-fokus, kważi ma jeżistu l-ebda settijiet ta’ dejta jew mudelli li japplikaw tekniki ta’ pproċessar tal-lingwi naturali għal problemi li jinsabu fi ħdan dibattitu formali kompetittiv. Biex nirremedjaw dan, nippreżentaw is-sett tad-dejta DebateSum. Is-somma tad-dibattitu tikkonsisti f’187,386 biċċa evidenza unika b’argumenti korrispondenti u sommarji estrattivi. Is-somma tad-dibattitu saret bl-użu ta’ dejta miġbura mill-kompetituri fl-Assoċjazzjoni Nazzjonali tad-Diskussjoni u d-Diskussjoni fuq perjodu ta’ seba’ snin. Aħna nħarrġu bosta mudelli ta’ sommarju tat-trasformaturi biex nagħmlu referenza għall-prestazzjoni tas-sommarju dwar id-DebateSum. Aħna nintroduċu wkoll sett ta’ vetturi tal-kliem b’test mgħa ġġel imħarrġa fuq DebateSum imsejħa debate2vec. Fl-a ħħar nett, qed nippreżentaw magna ta' tiftix għal dan is-sett ta' dejta li llum hija utilizzata b'mod estensiv mill-membri tal-Assoċjazzjoni Nazzjonali tad-Diskussjoni u d-Diskussjoni. Il-magna tat-tiftix DebateSum hija disponibbli għall-pubbliku hawnhekk: http://www.debate.cards</abstract_mt>
      <abstract_mn>Аргумент салбарын өмнөх ажил нь автоматжуулах системд автоматжуулах боломжийг ашигладаг. Энэ төвлөрөмжтэй ч, байгалийн хэл үйлдвэрлэлийн технологийг өрсөлдөөний официальны өрсөлдөөнд олсон асуудлуудад бараг ямар ч өгөгдлийн санг эсвэл загварууд байхгүй. Үүнийг сайжруулахын тулд бид DebateSum өгөгдлийн санг тайлбарлаж байна. DebateSum нь 187,386 онцгой баталгааны баримт, харьцангуй аргумент болон нэмэлт жишээлүүд байдаг. DebateSum нь 7 жилийн турш National Speech and Debate Association-ын өрсөлдөгчид зохион байгуулсан өгөгдлийг ашиглаж байв. Бид DebateSum дээр хэдэн шилжүүлэгчийн жинхэнэ загваруудыг банкмаркингийн жинхэнэ үйл ажиллагаанд сургаж байна. Мөн бид DebateSum дээр сургалтын хурдан хэмжээний үг векторуудыг "debate2vec" гэж нэрлэдэг. Эцэст нь бид өнөөдөр үндэсний яриа, Debate Association-ын гишүүн дээр маш их ашиглаж байгаа өгөгдлийн сангийн хайлтын машин бий болгож байна. DebateSum хайлтын машин энд олон нийтэд ашиглагддаг: http://www.debate.cards</abstract_mn>
      <abstract_ro>Lucrările anterioare în Argument Mining fac frecvent aluzie la potențialele sale aplicații în sistemele automate de dezbatere. În ciuda acestui accent, aproape nu există seturi de date sau modele care să aplice tehnici de prelucrare a limbajului natural problemelor găsite în cadrul dezbaterii formale competitive. Pentru a remedia acest lucru, vă prezentăm setul de date DebateSum. DebateSum constă din 187.386 elemente unice de probă cu argumente corespunzătoare și rezumate extractive. DebateSum a fost realizată folosind datele colectate de concurenții din cadrul Asociației Naționale de Discurs și Dezbateri pe o perioadă de 7 ani. Instruim mai multe modele de sintetizare a transformatoarelor pentru a compara performanțele de sintetizare pe DebateSum. De asemenea, introducem un set de vectori de cuvinte fasttext instruiți pe DebateSum numit debate2vec. În cele din urmă, prezentăm un motor de căutare pentru acest set de date, care este utilizat pe scară largă de membrii Asociației Naționale de Discurs și Dezbateri astăzi. Motorul de căutare DebateSum este disponibil pentru public aici: http://www.debate.cards</abstract_ro>
      <abstract_no>Førre arbeid i argumentminering viser ofte dei potensielle programmene i dei automatiske debattsystema. Til tross på denne fokusen finst nesten ingen datasett eller modeller som brukar naturspråk-handsamingsteknikk til problemar som finst i konkurrentleg formelt debatt. For å retta dette, presenterer vi DebateSum-datasettet. DebateSum inneheld av 187,386 unike deler av beviser med tilsvarande argument og ekstraktiv samandrag. @ info Vi treng fleire sammendragsmodular for transformeringa til å lage sammendrag på DebateSum. Vi introduserer også eit sett med raskt tekst ord-vektorar trengt på DebateSum kalla debate2vec. I slutt presenterer vi eit søkjemotor for denne dataset som vert brukt utvida av medlemmer i den nasjonale tale og debattassosisjonen i dag. Søkjemotoren DebateSum er tilgjengeleg for offentlege her: http://www.debate.cards</abstract_no>
      <abstract_pl>Wcześniejsze prace w Argument Mining często nawiązują do jego potencjalnych zastosowań w automatycznych systemach debaty. Pomimo tego skupienia prawie nie istnieją zbiory danych ani modele, które stosują techniki przetwarzania języka naturalnego do problemów znajdujących się w ramach konkurencyjnej debaty formalnej. Aby temu zaradzić, przedstawiamy zbiór danych DebateSum. DebateSum składa się z 187,386 unikalnych materiałów dowodowych z odpowiednim argumentem i ekstrakcyjnymi streszczeniami. DebateSum został dokonany z wykorzystaniem danych zebranych przez konkurentów w ramach Krajowego Stowarzyszenia Mowy i Debaty w ciągu 7letniego okresu. Szkolimy kilka modeli podsumowania transformatorów, aby porównać wydajność podsumowania na DebiteSum. Wprowadzamy również zestaw wektorów słów fasttext trenowanych na DebateSum zwanych debate2vec. Na koniec przedstawiamy wyszukiwarkę tego zbioru danych, która jest dziś szeroko wykorzystywana przez członków Narodowego Stowarzyszenia Mowy i Debaty. Wyszukiwarka DebateSum jest dostępna publicznie tutaj: http://www.debate.cards</abstract_pl>
      <abstract_sr>Prije posla u rudarstvu Argumenta često povezuje svoje potencijalne aplikacije u sistemima automatskih debata. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnom formalnom debatu. Da bismo ovo sredili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187.386 jedinstvenih dokaza sa odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka koje su kompilovali konkurenti unutar Nacionalne asocijacije govora i debata tokom sedmogodišnjeg period a. Trenirali smo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Takoðe predstavljamo niz brzog teksta reèi-vektora obuèenih na DebateSumu koji se zove debate2vec. Na kraju, predstavljamo potragu za ovom setu podataka koja se danas široko koristi članovi Nacionalne udruženje govora i debata. Pretraživač DebateSum je dostupan javnosti ovdje: http://www.debate.cards</abstract_sr>
      <abstract_si>ප්‍රධානය මනින්ගේ ප්‍රධාන වැඩේ ස්වයංක්‍රීය විදිහට ස්වයංක්‍රීය විදිහට ප්‍රයෝජනය කරනවා. මේ අවධානය නමුත්, ස්වභාවික භාෂාව ප්‍රශ්නයක් ප්‍රශ්නයක් සම්බන්ධ විශ්නයක් තියෙන ප්‍රශ්නයක් සාම මේක හොයාගන්න, අපි දෙබට්සුම් දත්ත සෙට්ටුව පෙන්වන්න. ඩෙබට්සුම් එක්ක 187,386 විශේෂ සාක්ෂියක් තියෙන්නේ සම්බන්ධ සාක්ෂියක් සහ ප්‍රශ්නයක් සඳහා. @ info: tooltip අපි වෙනස් වෙනුවෙන් වෙනස් වෙනුවෙන් සංවේදනය විදිහට සංවේදනය විදිහට සංවේදනය කරනවා. අපි ඒවගේම වේගවේක්ටර් වචන වචන වෙක්ටර්ස් වලට දැනගන්න පුළුවන් විදියට debatSum කියලා දැනගන්න. අන්තිමේදී, අපි මේ දත්ත සෙට් වෙනුවෙන් හොයාගෙන ඉංජින් එකක් ප්‍රවේශ කරනවා අද රාජ්‍ය භාවිත සහ ඩිබේට් එක් @ info: tooltip http://www.debate.cards</abstract_si>
      <abstract_so>Shaqo horay ah ee ka shaqeynta sharciga Mining inta badan wuxuu ku qoran karaa codsigiisa suurtagalka ah nidaamka debaashka oo automatic ah. Inta kastoo ay fiirsantan noqoto, ma jirto mid dhowaad ah sawirada ama tusaalooyin ah oo u codsada qalabka baaritaanka afka dabiicadda ah si ay dhibaatooyin looga helo debaar rasmi ah. Si aan u bogsado waxan, waxaan keenaynaa sawirada macluumaadka qaramaanka. DebateSum waxaa ka mid ah 187,386 qeybood oo gaar ah oo ay ku jiraan cadaawayaasha islamarkaasna ay ku qoran yihiin xaajooyin islamarkaasna ay soo saaraan. Summada waxaa lagu sameyn jiray macluumaad ku saabsan ururka afka caalamiga ah iyo dooda muddo 7 sano ah. Waxaannu ku tababarinnaa tusaalooyin badan oo isbedelka ah si aan u benchmarkno bandhigyada dhamaanka ee DebateSum. Sidoo kale waxaynu soo bandhignaa koox safar ah oo lagu baray debate 2vec. Ugu dambaysta waxaan keenaynaa mashiinka raadinta ee sawiradan lagu isticmaalayo xubnaha ururka luqada iyo dooda ee maanta. Masruufka raadinta ee dooda Sum waxaad ka heli kartaa dadka halkan: http://www.debate.cards</abstract_so>
      <abstract_sv>Tidigare arbete inom Argument Mining hänvisar ofta till dess potentiella tillämpningar i automatiska debattsystem. Trots detta fokus finns det nästan inga datauppsättningar eller modeller som tillämpar naturliga språkbehandlingstekniker på problem som finns inom konkurrensutsatt formell debatt. För att åtgärda detta presenterar vi datauppsättningen DebateSum. DebateSum består av 187 386 unika bevis med motsvarande argument och extraherande sammanfattningar. DebateSum gjordes med hjälp av data som sammanställts av konkurrenter inom Nationella tal- och debattförbundet under en sjuårsperiod. Vi tränar flera transformatorsammanfattningsmodeller för att jämföra sammanfattningsprocessen på DebateSum. Vi introducerar också en uppsättning snabbtext ordvektorer utbildade på DebateSum som kallas debate2vec. Slutligen presenterar vi en sökmotor för denna datamängd som används flitigt av medlemmar i Nationella tal- och debattförbundet idag. Sökmotorn DebateSum är tillgänglig för allmänheten här: http://www.debate.cards</abstract_sv>
      <abstract_ta>தானியங்கி விவாதம் அமைப்புகளில் சாத்தியமான பயன்பாடுகளுக்கு முன் வேலை செய்யும். இந்த முன்னிறுத்தினாலும், கிட்டத்தட்ட தகவல் அமைப்புகள் அல்லது மாதிரிகள் இல்லை அது இயல்பான மொழி செயல்படுத்தும் தொழில்நுட் இதை சரிபார்க்க, நாம் விவாதத்தை காண்பிக்கிறோம். விவாதம் 187,386 தனிப்பட்ட துண்டுகள் இருக்கும் தெரியும் வார்த்தைகள் மற்றும் வெளியேறும் சுருக்கம். தேசிய பேச்சு மற்றும் விவாதிக்கு சமூகத்திற்குள் திரட்டியாளர்களால் தரவு சேகரிக்கப்பட்டுள்ளது ஒரு 7 ஆண்டுக்கு ம நாங்கள் பல மாற்றங்கள் சுருக்க மாதிரிகளை பயிற்சி செய்து விவாதத்தின் சுருக்கும் செயல்பாட்டை பென்ச்மார நாம் விவாதத்தில் பயிற்சி செய்யப்பட்ட ஒரு சில வார்த்தை - வெக்டர்களை அறிவிக்கிறோம். இறுதியில், நாம் இந்த தகவல் அமைப்புக்கான தேடுப் பொறியை கொண்டு வருகிறோம். அது நாட்டு பேச்சு மற்றும் வாதாட்டு சமூகத்தின The debate Sum search engine is available to the public here: http://www.debate.cards</abstract_ta>
      <abstract_ur>آرمونٹ مینینگ میں پہلے کام اگلے سے اس کے امکانات کاروباروں کو اٹوٹ دیویٹ سیسٹم میں سمجھتا ہے۔ اس فوकस کے باوجود، تقریباً کوئی ڈاٹ سٹ یا نمڈل نہیں ہے جو طبیعی زبان پردازی ٹیکنیک کو مسائل میں پائی جاتی ہے جو مسائل میں پائی جاتی ہیں۔ اس کے لئے ہم DebateSum ڈیٹ سٹ کو پیش کرتے ہیں۔ DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum کو 7 سال کے طول میں ملی سخنچی اور ڈیبٹ اتحادیہ کے اندر رقابت کرنے والوں کے ذریعے کامپیل کیا گیا ہے. ہم نے بہت سی تغییر دینے والی نمڈلوں کو ڈبٹ سوم پر بنچم مارک سپورٹ کرانے کے لئے آموزش دیتے ہیں. ہم نے DebateSum (DebateSum) پر آموزش کی ایک سریع لکھی ویکتروں کا مجموعہ پیش کیا ہے۔ آخر میں، ہم اس ڈیٹ سٹ کے لئے ایک تلاش انجینٹ پیش کرتے ہیں جو آج ملی سخنچی اور ڈیبٹ انجینٹ کے اعضا سے مزید استعمال کیا جاتا ہے. DebateSum تلاش انجین یہاں سب لوگوں کے لئے موجود ہے: http://www.debate.cards</abstract_ur>
      <abstract_uz>Argument davomida birinchi ishni ko'p doim avtomatik debating tizimlarida qo'llash mumkin. Bu fokus aytib boʻlsa, qachon doim maʼlumot setlari yoki modellar mavjud emas, bu asl tilni boshqarish tugmalarini qoʻllash uchun kompetitiv formal debatda topilmadi. Buni tizimga tayyorlash uchun debatSum maʼlumot setini koʻrsatimiz. Name Name Biz bir necha shifokorlar tahrirlash modellarini o'rganamiz Debate Sum'da qisqarish muvaffaqiyatlarini bajaramiz. Biz DebateSum (debate 2vec) deb nomlangan bir ko'plab tez-matn so'z-vektorlarini o'rganamiz. Endi biz Bu maʼlumot sahifasi uchun qidirish mashinani hosil qilamiz. Bugun bugun Taifa Speech va Debat Associations xususiyatlaridan foydalanadi. Sum search engine is available to the public here: http://www.debate.cards</abstract_uz>
      <abstract_vi>Việc làm trước ở Argument Mining thường nhấn mạnh về khả năng ứng dụng của nó trong các hệ thống thảo luận tự động. Mặc dù tiêu điểm này, hầu như không có bộ dữ liệu hay mô hình nào có thể áp dụng kỹ thuật xử lý ngôn ngữ tự nhiên vào những vấn đề được tìm thấy trong cuộc tranh luận sắc thường. Để sửa chữa điều này, chúng tôi giới thiệu bộ dữ liệu DebateSum. Cuộc tranh luận gồm những chứng cứ duy nhất 187,386 với các lời lẽ và bản tóm tắt khai thác tương ứng. Cuộc tranh luận được thực hiện dựa trên dữ liệu được biên tập bởi các đối thủ tại Hiệp hội Phát biểu quốc gia và Debate trong vòng bảy năm. Chúng tôi đào tạo một số mô- đun mô phỏng biến đổi để tiêu điểm kinh nghiệm tóm tắt trên DebateSum. Chúng tôi cũng giới thiệu một nhóm các nhà dịch ngữ nhanh được đào tạo trên DebiateSum được gọi là Debte2vec. Cuối cùng, chúng tôi giới thiệu một động cơ tìm kiếm cho bộ dữ liệu này được sử dụng rộng rãi bởi các thành viên của hiệp hội Phát biểu quốc gia và đàm phán hôm nay. Bộ tìm kiếm DebateSum được công bố ở đây: http://www.debate.cards</abstract_vi>
      <abstract_bg>Предишната работа в Аргумент Мининг често говори за потенциалните му приложения в автоматичните системи за дебати. Въпреки този фокус, почти не съществуват набори от данни или модели, които да прилагат техники за обработка на естествения език към проблеми, открити в рамките на официалните състезателни дебати. За да поправим това, представяме набора от данни. ДебатеСум се състои от 187 386 уникални доказателства със съответните аргументи и извлекателни резюмета. ДебатеСум е направен с помощта на данни, събрани от конкуренти в рамките на Националната асоциация по реч и дебат за период от 7 години. Обучаваме няколко модела за обобщаване на трансформаторите, за да сравним ефективността на обобщаване на ДебатеСум. Представяме и набор от бързи текстови вектори, обучени на ДебатеСум, наречени Дебате2vec. На последно място, представяме търсачка за този набор от данни, която се използва широко от членовете на Националната асоциация по реч и дебат днес. Търсачката е достъпна за обществеността тук: http://www.debate.cards</abstract_bg>
      <abstract_hr>Prije posla u rudarstvu Argumenta često povezuje potencijalne primjene u automatskim raspravnim sustavima. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnom formalnom raspravu. Da bi to riješili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187 386 jedinstvenih dokaza s odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka koje su skupili konkurenti u okviru udruženja nacionalnog govora i debata tijekom sedmogodišnjeg razdoblja. Vježbamo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Također predstavljamo niz brzog teksta riječi-vektori obučenih na DebateSum koji se zove debate2vec. Na kraju, predstavljamo pretraživač za ovaj set podataka koji se danas široko koristi članovi Nacionalne udruženje govora i rasprave. Pretraživač DebateSum ovdje je dostupan javnosti: http://www.debate.cards</abstract_hr>
      <abstract_da>Tidligere arbejde i Argument Mining hentyder ofte til dens potentielle anvendelser i automatiske debatsystemer. På trods af dette fokus findes der næsten ingen datasæt eller modeller, der anvender naturlige sprogbehandlingsteknikker på problemer, der findes inden for konkurrencedygtig formel debat. For at afhjælpe dette præsenterer vi DebateSum datasættet. DebateSum består af 187.386 unikke bevismaterialer med tilsvarende argument og ekstraktive resuméer. DebateSum blev lavet ved hjælp af data indsamlet af konkurrenter inden for National Tale and Debate Association over en 7 års periode. Vi træner flere transformatoropsummeringsmodeller til at benchmark opsummeringsydelse på Debatesum. Vi introducerer også et sæt fasttext ord-vektorer trænet på DebateSum kaldet debate2vec. Endelig præsenterer vi en søgemaskine til dette datasæt, som bruges i vid udstrækning af medlemmer af National Tale and Debate Association i dag. DebateSum søgemaskinen er tilgængelig for offentligheden her: http://www.debate.cards</abstract_da>
      <abstract_nl>Eerder werk in Argument Mining verwijst vaak naar de mogelijke toepassingen ervan in automatische debat systemen. Ondanks deze focus bestaan er bijna geen datasets of modellen die natuurlijke taalverwerkingstechnieken toepassen op problemen die in competitief formeel debat worden aangetroffen. Om dit te verhelpen presenteren we de DebateSum dataset. DebateSum bestaat uit 187.386 unieke bewijsstukken met bijbehorende argumenten en extractieve samenvattingen. DebateSum is gemaakt met behulp van gegevens verzameld door concurrenten binnen de National Speech and Debate Association over een periode van zeven jaar. We trainen verschillende transformatorsamenvattingsmodellen om de samenvattingsprestaties op DebateSum te benchmarken. We introduceren ook een set fasttext woord-vectoren getraind op DebateSum genaamd debate2vec. Tot slot presenteren we een zoekmachine voor deze dataset die vandaag uitgebreid wordt gebruikt door leden van de National Speech and Debate Association. De DebateSum zoekmachine is beschikbaar voor het publiek hier: http://www.debate.cards</abstract_nl>
      <abstract_de>Frühere Arbeiten in Argument Mining verweisen häufig auf seine möglichen Anwendungen in automatischen Debattiersystemen. Trotz dieser Fokussierung gibt es kaum Datensätze oder Modelle, die natürliche Sprachverarbeitungstechniken auf Probleme anwenden, die in der kompetitiven formalen Debatte gefunden werden. Um dies zu beheben, stellen wir Ihnen den Datensatz DebateSum vor. DebateSumm besteht aus 187.386 eindeutigen Beweisstücken mit entsprechenden Argumenten und extraktiven Zusammenfassungen. DebateSum wurde anhand von Daten erstellt, die von Wettbewerbern innerhalb der National Speech and Debate Association über einen Zeitraum von sieben Jahren gesammelt wurden. Wir trainieren mehrere Transformatorzusammenfassungsmodelle, um die Zusammenfassungsleistung auf DebateSum zu benchmarken. Wir stellen auch eine Reihe von Fasttext-Wort-Vektoren vor, die auf DebateSum trainiert wurden, genannt debate2vec. Abschließend stellen wir eine Suchmaschine für diesen Datensatz vor, die heute von Mitgliedern der National Speech and Debate Association ausgiebig genutzt wird. Die DebateSum Suchmaschine steht der Öffentlichkeit hier zur Verfügung: http://www.debate.cards</abstract_de>
      <abstract_id>Pekerjaan sebelumnya di Argument Mining sering menyebutkan aplikasi potensialnya dalam sistem debat otomatis. Meskipun fokus ini, hampir tidak ada set data atau model yang menerapkan teknik proses bahasa alam pada masalah yang ditemukan dalam debat formal kompetitif. Untuk memperbaiki ini, kita mempersembahkan dataset DebateSum. DebateSum terdiri dari 187.386 bukti unik dengan argumen yang cocok dan ringkasan ekstraktif. DebateSum dibuat menggunakan data yang dikompilasi oleh kompetitor di dalam National Speech and Debate Association selama 7 tahun. Kami melatih beberapa model pengringkasan transformator untuk benchmark prestasi pengringkasan di DebateSum. Kami juga memperkenalkan set vektor-kata teks cepat dilatih di DebateSum disebut debate2vec. Akhirnya, kami mempersembahkan mesin pencarian untuk set data ini yang digunakan secara ekstensif oleh anggota Asosiasi Nasional Speech and Debate hari ini. Mesin pencarian DebateSum tersedia untuk masyarakat di sini: http://www.debate.cards</abstract_id>
      <abstract_fa>کارهای پیشینه در آرژومینگ ذخیره اغلب به کاربردهای پتانسیل خود در سیستم مذاکره‌های خودکار ارائه می‌کند. با وجود این تمرکز، تقریباً هیچ مجموعه داده یا مدل وجود ندارد که تکنیک پردازش زبان طبیعی را برای مشکلات در بحث رسمی رقابت یافته است. برای اصلاح این، مجموعه داده‌های DebateSum را پیشنهاد می‌کنیم. DebateSum consists of 187.386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum با استفاده از داده‌ها که توسط رقابتان در مجموعه‌ی سخنرانی ملی و مجادله در طول ۷ سال مجموعه شده‌اند ساخته شده است. ما چندتا مدل جمع کردن تغییر دهنده را آموزش می‌دهیم تا عملکرد جمع کردن ابزار در DebateSum. ما همچنین مجموعه‌ای از ویکتورهای کلمه‌های سریع متن را معرفی می‌کنیم که در DebateSum به نام debate2vec آموزش داده شده است. بالاخره، ما یک موتور جستجو برای این مجموعه داده را پیشنهاد می‌کنیم که امروز توسط اعضای انجمن صحبت و توطئه ملی استفاده می‌شود. موتور جستجو DebateSum برای عمومی در اینجا موجود است: http://www.debate.cards</abstract_fa>
      <abstract_ko>이전에 변론 발굴 분야에서 자동 변론 시스템에서의 잠재적인 응용에 대해 자주 언급했다.그럼에도 불구하고 경쟁적 공식 변론에 자연 언어 처리 기술을 적용해 발견한 문제의 데이터 집합이나 모델은 거의 없다.이 문제를 해결하기 위해 DebateSum 데이터 세트를 제공합니다.DebateSum에는 187386개의 독특한 증거와 그에 상응하는 논거와 발췌문 요약이 포함되어 있다.토론은 미국 강연변론협회(National Speech and Discussion Association)의 경쟁사들이 7년 동안 수집한 데이터를 활용해 이뤄졌다.우리는 DebateSum에서 요약 성능을 테스트하기 위해 몇 개의 변압기 요약 모형을 훈련했다.DebateSum에서 훈련된fasttext 단어 벡터도 소개했는데, 이를 debate2vec라고 부른다.마지막으로 우리는 이 데이터 집합을 위해 검색 엔진을 제공했고 오늘 전국 강연과 변론 협회의 회원들이 이 검색 엔진을 광범위하게 사용했다.DebateSum 검색엔진은 다음 위치에서 일반인이 사용할 수 있습니다.http://www.debate.cards</abstract_ko>
      <abstract_sw>Kazi ya awali katika mazingira ya Mining mara nyingi huwa inatumia matumizi yake ya uwezekano katika mifumo ya mijadala binafsi. Pamoja na lengo hili, takriban hakuna seti za data au mifano inayotumia mbinu za upasuaji wa lugha asili kwa matatizo yanayopatikana ndani ya mjadala rasmi wa ushindani. Ili kurekebisha hili, tunaweka taarifa za Mjadala. Mjadala unajumuisha vipande kipekee cha ushahidi 187,386 vya kutosha hoja na muhtasari wa kutosha. Mjadala ulifanywa kwa kutumia taarifa zilizokusanyika na washindi ndani ya Chama cha Taifa cha Hotuba na Mjadala kwa zaidi ya kipindi cha miaka 7. Tunafundisha mifano kadhaa ya muhtasari wa mabadiliko ya kiangazi ili kusambaza utendaji wa muhtasari wa mijadala ya Mjadala. Pia tunaonyesha kundi la mfululizo wa maneno yanayofundishwa kwenye Mjadala unaoitwa debate 2vec. Mwisho, tunaweka moto wa kutafuta kwa ajili ya seti hii inayotumiwa kwa kiasi kikubwa na wanachama wa Chama cha Taifa cha Hotuba na Mjadala leo. Mjadala wa utafutaji Sum unapatikana kwa umma hapa: http://www.debate.cards</abstract_sw>
      <abstract_tr>Argumentiň öňki işi Köçürmek üçin köplenç otomatik deblemek sistemlerinde öz potansiyeli uygulamalaryny aňsatýar. Bu fokusa rağmen, täze formal debatlarda bolan meselelere tebigy dil işlemek teknikleri ýagdaýa hiç hili maglumatlar ýok. Bunu onarmak üçin DebateSum veri setisini gösteriyoruz. DebateSum 187,386 täze bir kanıt bar we ýene-täk holasasy bilen mejbur. DebateSum Milli Speech we Debate Association'da 7 ýyl içinde rakipler tarapyndan birleştirilen maglumatlar ullanyldy. Biz DebateSum'da bir näçe täsirli terjime nusgalaryny benchmark taýýarlamak üçin öwredýäris. Ayrıca DebateSum üzerinde eğitilmiş, hızlı gelen kelime vektörleri, debate2vec olarak tanıştırıyoruz. Soňunda biz bu veri setirine gözlemek motoryny görkezýäris. Bu gün Milli Speech we Debat Association'yň üyeleri tarapyndan ullanýar DebateSum arama maşyny şu ýerde halkara ýerleşýär: http://www.debate.cards</abstract_tr>
      <abstract_sq>Prior work in Argument Mining frequently alludes to its potential applications in automatic debating systems.  Megjithë këtë fokus, pothuajse nuk ekzistojnë grupe të dhënash apo modele që aplikojnë teknika natyrore të përdorimit të gjuhës ndaj problemeve të gjetura brenda debatit zyrtar konkurrues. To remedy this, we present the DebateSum dataset.  DebateSum përbëhet nga 187,386 prova unike me argumente korrespondente dhe përmbledhje ekstraktive. DebateSum u bë duke përdorur të dhënat e mbledhura nga konkurentët brenda Shoqatës Kombëtare të Fjalëzimit dhe Debatit gjatë një periudhe shtatë vjeçare. Ne trajnojmë disa modele të përmbledhjes së transformuesve për të përcaktuar performancën e përmbledhjes në DebateSum. Ne prezantojmë gjithashtu një sërë vektorësh fjalësh me tekst të shpejtë të trajnuar në DebateSum të quajtur debate2vec. Më në fund, ne paraqesim një motor kërkimi për këtë set të dhënash që përdoret në mënyrë të gjerë nga anëtarët e Shoqatës Kombëtare të Fjalëzimit dhe Debatit sot. Motori i kërkimit DebateSum është në dispozicion për publikun këtu: http://www.debate.cards</abstract_sq>
      <abstract_af>Vorige werk in Argument Mining afgelyk aan sy potensiele toepassings in outomatiese debating stelsels. Terwyl hierdie fokus is, bestaan amper geen datastel of modele wat natuurlike taal verwerking tekniks toewend aan probleme wat binne gemeenskap formele debat gevind is nie. Om dit te herstel, laat ons die DebateSum datastel voorsien. DebateSum bestaan van 187,386 unieke stukke getuienis met ooreenstemmende argument en ekstraktiewe opsommings. DebateSum is gemaak met gebruik van data gemaak deur mededingers binne die Nasionale Spraak en Debate Associasie oor 'n 7jaar periode. Ons tref verskeie transformeerder opsomming modele na benchmark opsomming effektuur op DebateSum. Ons introduiseer ook 'n stel van vinnige teks woord- vektore wat op DebateSum geonderwerp is, wat debate2vec genoem word. Eindelik, ons stel 'n soektog masjien voor hierdie datastel wat uitbreidig gebruik word deur lede van die Nasionale Spraak en Debate Associasie vandag. Die DebateSum soektog masjien is beskikbaar vir die publiek hier: http://www.debate.cards</abstract_af>
      <abstract_am>አስቀድሞ የአርጉም ማነሻ ሥራ በጊዜው የቻይሎችን ፕሮግራሞች በራሱ ውይይት በተጨማሪው ሲስተካከል ያቆማል፡፡ ምንም እንኳን የዚህ ምሳሌ ቢሆንም፣ በአካባቢው የቋንቋ ፕሮጀክት ቴክኖክቶችን ለመጠቀም የሚችሉ ዳታተሮች ወይም ሞዴሎች ምንም አይገኙም፡፡ To remedy this, we present the DebateSum dataset.  የውይይት ጉዳይ 187,386 የተለየ ማስረጃዎችን በተቃዋሚ አዋጅ እና ውጤት አዳራሽ ነው፡፡ የውይይት ጉዳይ ከ7 ዓመት ጀምሮ በብሔራዊ ንግግር እና ክርክር ማኅበረሰብ ውስጥ የተሰበሰቡ ድረቶች የተደረገ ነው፡፡ በጥያቄ ጉዳይ ላይ አቀማመጥ ማሳየትን እናስተምረዋለን፡፡ ጥያቄ 2vec የሚባለውን የጽሑፍ ቃላት-vector እናሳውቃለን፡፡ በመጨረሻውም የብሔራዊ ንግግር እና የጥያቄ ማኅበረሰብ አባላት በሚጠቀምበት ለዚህ ዳታተር ሳንተርሚሽን እናቀርባለን፡፡ Sum search engine is available to the public here: http://www.debate.cards</abstract_am>
      <abstract_hy>Առաջին աշխատանքը Արգենտիվ հանքագործության ոլորտում հաճախ նշանակում է իր պոտենցիալ ծրագրերը ավտոմատիկ քննարկումների համակարգերում: Չնայած այս կենտրոնացումին, գրեթե ոչ մի տվյալների կամ մոդելներ չկան, որոնք օգտագործում են բնական լեզվի վերամշակման տեխնոլոգիաները մրցակցության պաշտոնական քննարկումների ընթացքում գտնվո Այս ամենը լուծելու համար մենք ներկայացնում ենք Դեբատեսում տվյալների համակարգը: ԴեբատեսSum-ը կազմում է 187,386 յուրահատուկ ապացույցներ, որոնք ունեն համապատասխան փաստարկման և արտադրողական համառոտագրություններ: ԴեբատեսSum-ը կատարվել է օգտագործելով տվյալներ, որոնք հավաքվել են ազգային խոսքի և քննարկումների ասոցիայի մրցակիցների կողմից 7 տարվա ընթացքում: Մենք վարժեցնում ենք որոշ վերափոխողների համառոտագրման մոդելներ, որպեսզի համեմատենք քննարկման համառոտագրման արդյունքները Մենք նաև ներկայացնում ենք մի շարք արագ տեքստի բառերի վեկտորներ, որոնք ուսուցանվել են Դեբատեսում, որը կոչվում է Դեբատեսում 2վեկտ: Վերջապես, մենք ներկայացնում ենք այս տվյալների համակարգի որոնման շարժիչը, որը այսօր էքսպենսիվ օգտագործվում է ազգային խոսքի և քննարկումների կազմակերպության անդամների կողմից: ԴեբատեսSum որոնման շարժիչը հասանելի է հանրության համար այստեղ: http://www.debate.cards</abstract_hy>
      <abstract_bn>আর্গামেন্ট মাইনিং-এর পূর্ববর্তী কাজ স্বয়ংক্রিয়ভাবে বিতর্কের সিস্টেমে তার সম্ভাব্য অ্যাপলিকেশনগুলোর প এই মনোযোগ সত্ত্বেও প্রায় কোনো ডাটাসেট বা মডেল নেই যা প্রাকৃতিক ভাষা প্রক্রিয়ার কৌশল প্রয়োগ করে প্রতিযোগিতায় আনুষ্ঠান এটা সুস্থ করার জন্য, আমরা বিতর্কের তথ্য সেট উপস্থাপন করি। বিতর্কের সামের মধ্যে ১৮৭,৩৮৬ অনন্য প্রমাণের অংশ রয়েছে যার সাথে সংশ্লিষ্ট যুক্তি এবং বিদেশী সংক্ষেপ। জাতীয় ভাষা এবং বিতর্ক সংস্থার মধ্যে প্রতিযোগীদের তথ্য সংগ্রহ করা হয়েছে বিতর্ক সাম ৭ বছর ধরে। আমরা বেশ কয়েকটি পরিবর্তনের সারসংক্ষিপ্ত মডেল প্রশিক্ষণ দিচ্ছি বিতর্কের সারসংক্ষিপ্ত কার্যক্রমের জন্য। আমরা বিতর্ক সামে প্রশিক্ষণ প্রদান করেছি যার নাম বিতর্ক ২ভেক। Finally, we present a search engine for this dataset which is utilized extensively by members of the National Speech and Debate Association today.  এখানে জনগণের জন্য বিতর্ক:Sum search ইঞ্জিন পাওয়া যাচ্ছে: http://www.debate.cards</abstract_bn>
      <abstract_az>Argument Mining'də əvvəlki iş çox çox olaraq özünün müzakirə sistemlərində mümkün proqramlarına bənzəyir. Bu fərqli tərzdə, təbiətli dil işləmə tekniklərini müqayisədə formal müzakirədə bulunan problemlərə istifadə edən məlumatlar və modellər yoxdur. Bunu dəyişdirmək üçün DebateSum veri qurğunu göstəririk. DebateSum 187,386 müəyyən dəlil parçaları ilə müqayisədi argument və ekstraktif toplamlar barəsindədir. DebateSum 7 il müddətində Ulusal Sözlük və Debat İşkiləri ilə birləşdirilən məlumatlardan istifadə edildi. Biz DebateSum'da bir çox transformer toplama modellərini benchmark toplama performansına təhsil edirik. Biz də DebateSum adında təhsil edilmiş, təhsil edilmiş, təhsil edilmiş, təhsil edilmiş, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil edilən, təhsil etdik. Sonunda, bu gün Ulusal Sözlük və Debat Asociasyonunun üyesi tarafından çox istifadə edilən verilən qurğu üçün arama maşını göstəririk. DebateSum arama motoru burada insanlara faydalanır: http://www.debate.cards</abstract_az>
      <abstract_ca>La feina anterior a Argument Mining sovint allueix a les seves aplicacions potencials en sistemes de debat automàtic. Malgrat aquest enfocament, gairebé no existeixen conjunts de dades o models que apliquen tècniques naturals de processament de llenguatges a problemes trobat en un debat formal competitiu. Per a arreglar-ho, presentem el conjunt de dades DebateSum. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries.  DebateSum va ser fet utilitzant dades compiladas pels competidors de la National Speech and Debate Association durant un període de 7 anys. Ensenyem varis models de resum de transformadors per comparar el rendiment de resum en DebateSum. També introduim un conjunt de vectors de paraules de text ràpid entrenats en DebateSum anomenat debate2vec. Finalment, presentem un motor de cerca per aquest conjunt de dades que és utilitzat ampliament pels membres de l'Associació Nacional de Discursos i Debats avui dia. El motor de recerca DebateSum està disponible al públic aquí: http://www.debate.cards</abstract_ca>
      <abstract_cs>Předchozí práce v Argument Mining často naráží na jeho potenciální aplikace v automatických debatních systémech. Navzdory tomuto zaměření neexistují téměř žádné datové sady nebo modely, které by aplikovaly techniky zpracování přirozeného jazyka na problémy nalezené v rámci konkurenční formální debaty. Abychom to napravili, představujeme datovou sadu DebateSum. DebateSum se skládá z 187,386 unikátních důkazů s odpovídajícím argumentem a extraktivními shrnutími. DebateSum byl proveden na základě údajů sestavených soutěžícími v rámci Národního sdružení projevů a debat během sedmiletého období. Trénujeme několik modelů shrnutí transformátorů pro srovnání výkonu shrnutí na DebateSumu. Představujeme také sadu fasttext slovních vektorů trénovaných na DebateSumu s názvem debate2vec. Na závěr představujeme vyhledávač pro tento datový soubor, který dnes široce využívají členové Národní asociace projevů a debat. Vyhledávač DebateSum je k dispozici veřejnosti zde: http://www.debate.cards</abstract_cs>
      <abstract_et>Varasem töö Argument Mining viitab sageli selle võimalikele rakendustele automaatsetes arutelusüsteemides. Vaatamata sellele keskendumisele ei ole olemas peaaegu ühtegi andmekogumit ega mudelit, mis rakendaksid looduskeele töötlemise meetodeid konkurentsivõimelise ametliku arutelu käigus leitud probleemidele. Selle parandamiseks esitame DebateSumi andmekogumi. DebateSum koosneb 187 386 unikaalsest tõendist koos vastavate argumentide ja väljavõtetega. DebateSum koostati Riikliku Kõne- ja Debate Assotsiatsiooni konkurentide poolt 7 aasta jooksul koostatud andmetega. Koolitame mitmeid trafode kokkuvõtlusmudeleid, et võrdleda kokkuvõtlusmudeleid DebateSumis. Lisaks tutvustame DebateSum'is koolitatud kiirete tekstivektorite komplekti, mida nimetatakse debate2vec. Lõpuks tutvustame selle andmekogumi otsingumootorit, mida täna laialdaselt kasutavad Riikliku Kõne- ja Debate Assotsiatsiooni liikmed. Otsingumootor DebateSum on avalikkusele kättesaadav siit: http://www.debate.cards</abstract_et>
      <abstract_bs>Prije posla u rudarstvu Argumenta često se ukazuje na njegove potencijalne aplikacije u sistemima automatskih debata. Uprkos ovom fokusu, skoro nema podataka ni modela koji primjenjuju prirodne tehnike obrade jezika na probleme koje su pronađene u konkurentnim formalnim debatima. Da bi to riješili, predstavljamo sastanak podataka DebateSuma. DebateSum se sastoji od 187.386 jedinstvenih dokaza s odgovarajućim argumentima i ekstraktivnim sažetkama. DebateSum je napravljen korištenjem podataka kompileraniranih konkurentima u okviru udruženja nacionalnog govora i debata tokom sedmogodišnjeg razdoblja. Vježbamo nekoliko modela sažetanja transformera za rezimetiranje rezimetara na DebateSum. Također predstavljamo niz brzog teksta rečnih vektora obučenih na DebateSum koji se zove debate2vec. Na kraju, predstavljamo pretraživač za ovaj set podataka koji se danas široko koristi članovi Nacionalne udruženje govora i debata. Pretraživač DebateSum ovdje je dostupan javnosti: http://www.debate.cards</abstract_bs>
      <abstract_fi>Aiempi Argument Miningin ty繹 viittaa usein sen mahdollisiin sovelluksiin automaattisissa keskusteluj瓣rjestelmiss瓣. T瓣st瓣 huolimatta l瓣hes ei ole olemassa aineistoja tai malleja, joissa luonnollisen kielen k瓣sittelytekniikoita sovellettaisiin kilpailullisessa virallisessa keskustelussa havaittuihin ongelmiin. T瓣m瓣n korjaamiseksi esittelemme DebateSum-aineiston. DebateSum koostuu 187 386 ainutlaatuisesta todistekappaleesta, joissa on vastaavat perustelut ja tiivistelm瓣t. DebateSum toteutettiin kansallisen puhe- ja keskusteluyhdistyksen kilpailijoiden ker瓣瓣mill瓣 tiedoilla 7 vuoden ajalta. Koulutamme useita muuntajien yhteenvedon malleja vertailemaan yhteenvedon suorituskyky瓣 DebateSumissa. Esittelemme my繹s joukon DebateSumissa koulutettuja pikatekstivektoreita nimelt瓣 debate2vec. Lopuksi esittelemme t瓣m瓣n aineiston hakukoneen, jota kansallisen puhe- ja keskusteluyhdistyksen j瓣senet hy繹dynt瓣v瓣t laajasti. DebateSum-hakukone on yleis繹n saatavilla t瓣瓣lt瓣: http://www.debate.cards</abstract_fi>
      <abstract_jv>argument Ngawe tho nggawe persok iki, amèh ora ono dataset opo model sing bisa nguasai tékno sing apik perusahaan idiomatan kanggo nggawe perusahaan seneng pisan kang diputasane resmi sakjane kanggo ngilangno iki, kita sampeyan dataset Debate Sum Debate Sum wis mungkin karo 486 unik bukun dadi nggawe karo akeh argument karo resmi extract Debate Sum wis ngawe data kompleh barêng-barêng ngenggo akèh wong sing dibenakno Perancis Nalikar kanggo Debate We've been tracking a number of transformer sumification modeles to bench sumification success on Debate Sum. Awak dhéwé nglebokake pernik nganggo masa gambar-vector seng sedhaya Debate Sum akhar deb2vec. Soale, awak dhéwé ngewehi engin kanggo nggawe dataset iki iki dipunangé luwih panelusuran kanggo wong liyo nggo Resolusi Kasal karo Debate Gosoko Debates Sum sing dibutuhke nang publik iki: http://www.debate.cards</abstract_jv>
      <abstract_ha>Kayyar aiki na Argument Mining, yana da amfani da shiryoyin ayuka masu yiwuwa a cikin tsarin mutane farat ɗaya. Babu dai da wannan fokus, don haka ba za'a iya sãmu kowa tsaro ko misãlai da ke amfani da kunnukan zartar da harshen kwanan zuwa masu zartar da su a cikin jayayi mai tsawo. QNetworkAccessFileBackend DebateSum consists of 187,386 unique pieces of evidence with the same argument and External sums. Summary was made by data composed by competitors in the National Spelling and Debate association over a 7 year. Tuna kõre wasu masu motsi na tsarin samori zuwa bonkimar ƙararin da aka yi wa DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec.  Gani, munã gabatar da wata mashin search wa wannan set of data which is used widely by member of the National Speaker and Debate Sockety a yau. Sum search Engine na da ake iya amfani da zuwa umauman nan: http://www.debate.cards</abstract_ha>
      <abstract_sk>Predhodno delo v Argument Mining pogosto namiguje na njegove potencialne aplikacije v avtomatskih sistemih razprave. Kljub temu poudarku skoraj ni nobenih zbirk podatkov ali modelov, ki bi uporabljali tehnike obdelave naravnega jezika pri težavah, ugotovljenih v okviru konkurenčne formalne razprave. Da bi to odpravili, predstavljamo nabor podatkov DebateSum. DebateSum je sestavljen iz 187.386 edinstvenih dokazov z ustreznimi argumenti in ekstraktivnimi povzetki. DebateSum je bil izveden na podlagi podatkov, ki so jih zbrali tekmovalci znotraj Nacionalnega združenja za govor in debato v obdobju 7 let. Usposabljamo več modelov povzetka transformatorjev za primerjavo zmogljivosti povzetka na DebateSumu. Predstavljamo tudi nabor hitrih besednih vektorjev, usposobljenih na DebateSum, imenovanih debate2vec. Na koncu predstavljamo iskalnik za ta nabor podatkov, ki ga danes obsežno uporabljajo člani Nacionalnega združenja za govor in debato. Iskalnik DebateSum je javnosti na voljo tukaj: http://www.debate.cards</abstract_sk>
      <abstract_bo>སྒྲུབ་རྟགས་ཀྱི་སྔོན་ལྗོངས་ཀྱི་ལག་ལེན་པ་སྤྱིར་ནུས་ཡོད་པའི་ཉེར་སྤྱོད གནད་དོན་འདི་ལྟ་བུའི་ནང་དུ་བློ་གཏོང་ན་ཡིག་སྣོད་དང་མིག་དཔྱད་ཀྱང་མ་ཡོད་པ་རྐྱེན་གྱིས་སྤྲོད་ཀྱི་སྐད་ཡིག་ལས་ འདི་ཡར་དུ་གཏོང་དགོས་ན། ང་ཚོས་DebateSum ཡིག་ཆ་སྒྲིག་ཆ་འཕྲིན་དེ་སྔོན་སྒྲིག་བྱེད་དགོས། DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum རྒྱལ་ཁབ་སྐྱོར་དང་ཕྱོགས་སྐྱོང་ཆེན་དག་གི་སྤྱི་ཚོགས་ཁང་གི་མཉམ་སྤྱོད་མཁན་གྱི་གནས་སྡུད་ཞིག་བེད་སྤྱད་ We train several transformer summarization models to benchmark summarization performance on DebateSum. ང་ཚོས་DebateSum(debate2vec)ནང་གི་མགྱོག་རིང་གི་ཐབས་ལམ་ལུགས་པའི་ཚིག་རྒྱུད་ཀྱི་སྒྲིག་སྟངས་བཤད་པ་ཡིན། མཐའ་མར་འཁོར་སུ། ང་ཚོས་དེ་རིང་རྒྱལ་ཁབ་ཀྱི་སྐད་ཆ་བློ་གཏོང་དང་ཆ་བློ་གཏོང་ཆེན་ཁང་གི་ཆ་འཕྲིན་འདི་ལ་འཚོལ་ འདིར་མི་མང་གིས་DebateSum འཚོལ་བཤེར་སྣུམ་འཁོར་སྐྱོད་རུང་བྱེད་པ： http://www.debate.cards</abstract_bo>
      <abstract_he>העבודה הקודמת במכרות התווכחות הזכירה לעתים קרובות לתוכניות הפוטנציאליות שלה במערכות דיון אוטומטיות. Despite this focus, almost no datasets or models exist which apply natural language processing techniques to problems found within competitive formal debate.  כדי לתקן את זה, אנחנו מציגים את קבוצת נתונים DebateSum. סכום דיבוטה מורכב מ-187,386 חתיכות ראיות יוצאות דופן עם טיעון מתאים וסרטוסים חיצוניים. DebateSum נעשה באמצעות נתונים שנאספו על ידי מתחרים בתוך ארגון הדיבורים הלאומי במשך תקופה של 7 שנים. אנחנו מאמן מספר דוגמנים של סוריזציה משתנה כדי לנקוט ביצועים של סוריזציה על DebateSum. אנחנו גם מציגים קבוצה של ווקטורי מילים טקסט מהירים מאומנים על DebateSum שנקראים debate2vec. סוף סוף, אנו מציגים מנוע חיפוש עבור קבוצת נתונים זו שמשתמשת באופן רחב על ידי חברי האיגוד הלאומי של דיבורים ודיבויים היום. מנוע חיפוש DebateSum זמין לציבור כאן: http://www.debate.cards</abstract_he>
      </paper>
    <paper id="2">
      <title>Annotating Topics, Stance, Argumentativeness and Claims in Dutch Social Media Comments : A Pilot Study<fixed-case>D</fixed-case>utch Social Media Comments: A Pilot Study</title>
      <author><first>Nina</first><last>Bauwelinck</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>8–18</pages>
      <abstract>One of the major challenges currently facing the field of argumentation mining is the lack of consensus on how to analyse argumentative user-generated texts such as online comments. The theoretical motivations underlying the annotation guidelines used to generate labelled corpora rarely include motivation for the use of a particular theoretical basis. This pilot study reports on the <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> of a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of 100 Dutch user comments made in response to politically-themed news articles on <a href="https://en.wikipedia.org/wiki/Facebook">Facebook</a>. The annotation covers topic and aspect labelling, stance labelling, argumentativeness detection and claim identification. Our IAA study reports substantial agreement scores for argumentativeness detection (0.76 Fleiss’ kappa) and moderate agreement for claim labelling (0.45 Fleiss’ kappa). We provide a clear justification of the theories and definitions underlying the design of our <a href="https://en.wikipedia.org/wiki/Guideline">guidelines</a>. Our analysis of the annotations signal the importance of adjusting our guidelines to include allowances for missing context information and defining the concept of argumentativeness in connection with <a href="https://en.wikipedia.org/wiki/List_of_human_positions">stance</a>. Our annotated corpus and associated guidelines are made publicly available.</abstract>
      <url hash="bb2eccd1">2020.argmining-1.2</url>
      <bibkey>bauwelinck-lefever-2020-annotating</bibkey>
    </paper>
    <paper id="5">
      <title>Aspect-Based Argument Mining</title>
      <author><first>Dietrich</first><last>Trautmann</last></author>
      <pages>41–52</pages>
      <abstract>Computational Argumentation in general and <a href="https://en.wikipedia.org/wiki/Argument_mining">Argument Mining</a> in particular are important research fields. In previous works, many of the challenges to automatically extract and to some degree reason over natural language arguments were addressed. The tools to extract <a href="https://en.wikipedia.org/wiki/Argument_of_a_function">argument units</a> are increasingly available and further open problems can be addressed. In this work, we are presenting the task of Aspect-Based Argument Mining (ABAM), with the essential subtasks of Aspect Term Extraction (ATE) and Nested Segmentation (NS). At the first instance, we create and release an annotated corpus with aspect information on the token-level. We consider <a href="https://en.wikipedia.org/wiki/Element_(mathematics)">aspects</a> as the main point(s) argument units are addressing. This information is important for further downstream tasks such as argument ranking, argument summarization and generation, as well as the search for counter-arguments on the aspect-level. We present several experiments using state-of-the-art supervised architectures and demonstrate their performance for both of the subtasks. The annotated benchmark is available at https://github.com/trtm/ABAM.</abstract>
      <url hash="12cdc26e">2020.argmining-1.5</url>
      <bibkey>trautmann-2020-aspect</bibkey>
      <pwccode url="https://github.com/trtm/ABAM" additional="false">trtm/ABAM</pwccode>
    </paper>
    <paper id="6">
      <title>Annotation and Detection of Arguments in Tweets</title>
      <author><first>Robin</first><last>Schaefer</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>53–58</pages>
      <abstract>Notwithstanding the increasing role <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> plays in modern political and social discourse, resources built for conducting <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a> on <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> remain limited. In this paper, we present a new <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of <a href="https://en.wikipedia.org/wiki/Twitter">German tweets</a> annotated for <a href="https://en.wikipedia.org/wiki/Argument_(linguistics)">argument components</a>. To the best of our knowledge, this is the first <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> containing not only annotated full tweets but also argumentative spans within tweets. We further report first promising results using <a href="https://en.wikipedia.org/wiki/Supervised_classification">supervised classification</a> (F1 : 0.82) and sequence labeling (F1 : 0.72) approaches.</abstract>
      <url hash="e177aeab">2020.argmining-1.6</url>
      <bibkey>schaefer-stede-2020-annotation</bibkey>
      <pwccode url="https://github.com/robinschaefer/climate-tweet-corpus" additional="false">robinschaefer/climate-tweet-corpus</pwccode>
    </paper>
    <paper id="8">
      <title>ECHR : <a href="https://en.wikipedia.org/wiki/Corpus_Juris_Civilis">Legal Corpus</a> for Argument Mining<fixed-case>ECHR</fixed-case>: Legal Corpus for Argument Mining</title>
      <author><first>Prakash</first><last>Poudyal</last></author>
      <author><first>Jaromir</first><last>Savelka</last></author>
      <author><first>Aagje</first><last>Ieven</last></author>
      <author><first>Marie Francine</first><last>Moens</last></author>
      <author><first>Teresa</first><last>Goncalves</last></author>
      <author><first>Paulo</first><last>Quaresma</last></author>
      <pages>67–75</pages>
      <abstract>In this paper, we publicly release an annotated corpus of 42 decisions of the <a href="https://en.wikipedia.org/wiki/European_Court_of_Human_Rights">European Court of Human Rights (ECHR)</a>. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> is annotated in terms of three types of <a href="https://en.wikipedia.org/wiki/Clause_(logic)">clauses</a> useful in <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a> : premise, conclusion, and non-argument parts of the text. Furthermore, relationships among the premises and conclusions are mapped. We present baselines for three <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> that lead from <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured texts</a> to structured arguments. The tasks are argument clause recognition, clause relation prediction, and premise / conclusion recognition. Despite a straightforward application of the bidirectional encoders from Transformers (BERT), we obtained very promising results F1 0.765 on argument recognition, 0.511 on relation prediction, and 0.859/0.628 on premise / conclusion recognition). The results suggest the usefulness of pre-trained language models based on <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural network architectures</a> in <a href="https://en.wikipedia.org/wiki/Argument_mining">argument mining</a>. Because of the simplicity of the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>, there is ample space for improvement in future work based on the released corpus.</abstract>
      <url hash="efde1688">2020.argmining-1.8</url>
      <bibkey>poudyal-etal-2020-echr</bibkey>
    </paper>
    <paper id="11">
      <title>Annotating argumentation in Swedish social media<fixed-case>S</fixed-case>wedish social media</title>
      <author><first>Anna</first><last>Lindahl</last></author>
      <pages>100–105</pages>
      <abstract>This paper presents a small study of annotating <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation</a> in Swedish social media. Annotators were asked to annotate spans of <a href="https://en.wikipedia.org/wiki/Argumentation_theory">argumentation</a> in 9 threads from two <a href="https://en.wikipedia.org/wiki/Internet_forum">discussion forums</a>. At the post level, Cohen’s k and Krippendorff’s alpha 0.48 was achieved. When manually inspecting the <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> the annotators seemed to agree when conditions in the guidelines were explicitly met, but implicit argumentation and opinions, resulting in annotators having to interpret what’s missing in the text, caused disagreements.</abstract>
      <url hash="587b0cf2">2020.argmining-1.11</url>
      <bibkey>lindahl-2020-annotating</bibkey>
    </paper>
    </volume>
</collection>