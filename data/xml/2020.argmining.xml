<collection id="2020.argmining">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Argument Mining</booktitle>
      <editor><first>Elena</first><last>Cabrio</last></editor>
      <editor><first>Serena</first><last>Villata</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="9d500249">2020.argmining-1.0</url>
      <bibkey>argmining-2020-argument</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>D</fixed-case>ebate<fixed-case>S</fixed-case>um: A large-scale argument mining and summarization dataset</title>
      <author><first>Allen</first><last>Roush</last></author>
      <author><first>Arvind</first><last>Balaji</last></author>
      <pages>1&#8211;7</pages>
      <abstract>Prior work in Argument Mining frequently alludes to its potential applications in automatic debating systems. Despite this focus, almost no datasets or models exist which apply natural language processing techniques to problems found within competitive formal debate. To remedy this, we present the DebateSum dataset. DebateSum consists of 187,386 unique pieces of evidence with corresponding argument and extractive summaries. DebateSum was made using data compiled by competitors within the National Speech and Debate Association over a 7year period. We train several transformer summarization models to benchmark summarization performance on DebateSum. We also introduce a set of fasttext word-vectors trained on DebateSum called debate2vec. Finally, we present a search engine for this dataset which is utilized extensively by members of the National Speech and Debate Association today. The DebateSum search engine is available to the public here: http://www.debate.cards</abstract>
      <url hash="3352bff5">2020.argmining-1.1</url>
      <bibkey>roush-balaji-2020-debatesum</bibkey>
      <pwccode url="https://github.com/arvind-balaji/debate-cards" additional="true">arvind-balaji/debate-cards</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/debatesum">DebateSum</pwcdataset>
    </paper>
    <paper id="2">
      <title>Annotating Topics, Stance, Argumentativeness and Claims in <fixed-case>D</fixed-case>utch Social Media Comments: A Pilot Study</title>
      <author><first>Nina</first><last>Bauwelinck</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>8&#8211;18</pages>
      <abstract>One of the major challenges currently facing the field of argumentation mining is the lack of consensus on how to analyse argumentative user-generated texts such as online comments. The theoretical motivations underlying the annotation guidelines used to generate labelled corpora rarely include motivation for the use of a particular theoretical basis. This pilot study reports on the annotation of a corpus of 100 Dutch user comments made in response to politically-themed news articles on Facebook. The annotation covers topic and aspect labelling, stance labelling, argumentativeness detection and claim identification. Our IAA study reports substantial agreement scores for argumentativeness detection (0.76 Fleiss&#8217; kappa) and moderate agreement for claim labelling (0.45 Fleiss&#8217; kappa). We provide a clear justification of the theories and definitions underlying the design of our guidelines. Our analysis of the annotations signal the importance of adjusting our guidelines to include allowances for missing context information and defining the concept of argumentativeness in connection with stance. Our annotated corpus and associated guidelines are made publicly available.</abstract>
      <url hash="bb2eccd1">2020.argmining-1.2</url>
      <bibkey>bauwelinck-lefever-2020-annotating</bibkey>
    </paper>
    <paper id="5">
      <title>Aspect-Based Argument Mining</title>
      <author><first>Dietrich</first><last>Trautmann</last></author>
      <pages>41&#8211;52</pages>
      <abstract>Computational Argumentation in general and Argument Mining in particular are important research fields. In previous works, many of the challenges to automatically extract and to some degree reason over natural language arguments were addressed. The tools to extract argument units are increasingly available and further open problems can be addressed. In this work, we are presenting the task of Aspect-Based Argument Mining (ABAM), with the essential subtasks of Aspect Term Extraction (ATE) and Nested Segmentation (NS). At the first instance, we create and release an annotated corpus with aspect information on the token-level. We consider aspects as the main point(s) argument units are addressing. This information is important for further downstream tasks such as argument ranking, argument summarization and generation, as well as the search for counter-arguments on the aspect-level. We present several experiments using state-of-the-art supervised architectures and demonstrate their performance for both of the subtasks. The annotated benchmark is available at https://github.com/trtm/ABAM.</abstract>
      <url hash="12cdc26e">2020.argmining-1.5</url>
      <bibkey>trautmann-2020-aspect</bibkey>
      <pwccode url="https://github.com/trtm/ABAM" additional="false">trtm/ABAM</pwccode>
    </paper>
    <paper id="6">
      <title>Annotation and Detection of Arguments in Tweets</title>
      <author><first>Robin</first><last>Schaefer</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>53&#8211;58</pages>
      <abstract>Notwithstanding the increasing role Twitter plays in modern political and social discourse, resources built for conducting argument mining on tweets remain limited. In this paper, we present a new corpus of German tweets annotated for argument components. To the best of our knowledge, this is the first corpus containing not only annotated full tweets but also argumentative spans within tweets. We further report first promising results using supervised classification (F1: 0.82) and sequence labeling (F1: 0.72) approaches.</abstract>
      <url hash="e177aeab">2020.argmining-1.6</url>
      <bibkey>schaefer-stede-2020-annotation</bibkey>
      <pwccode url="https://github.com/robinschaefer/climate-tweet-corpus" additional="false">robinschaefer/climate-tweet-corpus</pwccode>
    </paper>
    <paper id="8">
      <title><fixed-case>ECHR</fixed-case>: Legal Corpus for Argument Mining</title>
      <author><first>Prakash</first><last>Poudyal</last></author>
      <author><first>Jaromir</first><last>Savelka</last></author>
      <author><first>Aagje</first><last>Ieven</last></author>
      <author><first>Marie Francine</first><last>Moens</last></author>
      <author><first>Teresa</first><last>Goncalves</last></author>
      <author><first>Paulo</first><last>Quaresma</last></author>
      <pages>67&#8211;75</pages>
      <abstract>In this paper, we publicly release an annotated corpus of 42 decisions of the European Court of Human Rights (ECHR). The corpus is annotated in terms of three types of clauses useful in argument mining: premise, conclusion, and non-argument parts of the text. Furthermore, relationships among the premises and conclusions are mapped. We present baselines for three tasks that lead from unstructured texts to structured arguments. The tasks are argument clause recognition, clause relation prediction, and premise/conclusion recognition. Despite a straightforward application of the bidirectional encoders from Transformers (BERT), we obtained very promising results F1 0.765 on argument recognition, 0.511 on relation prediction, and 0.859/0.628 on premise/conclusion recognition). The results suggest the usefulness of pre-trained language models based on deep neural network architectures in argument mining. Because of the simplicity of the baselines, there is ample space for improvement in future work based on the released corpus.</abstract>
      <url hash="efde1688">2020.argmining-1.8</url>
      <bibkey>poudyal-etal-2020-echr</bibkey>
    </paper>
    <paper id="11">
      <title>Annotating argumentation in <fixed-case>S</fixed-case>wedish social media</title>
      <author><first>Anna</first><last>Lindahl</last></author>
      <pages>100&#8211;105</pages>
      <abstract>This paper presents a small study of annotating argumentation in Swedish social media. Annotators were asked to annotate spans of argumentation in 9 threads from two discussion forums. At the post level, Cohen&#8217;s k and Krippendorff&#8217;s alpha 0.48 was achieved. When manually inspecting the annotations the annotators seemed to agree when conditions in the guidelines were explicitly met, but implicit argumentation and opinions, resulting in annotators having to interpret what&#8217;s missing in the text, caused disagreements.</abstract>
      <url hash="587b0cf2">2020.argmining-1.11</url>
      <bibkey>lindahl-2020-annotating</bibkey>
    </paper>
    </volume>
</collection>