<collection id="2020.mwe">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons</booktitle>
      <editor><first>Stella</first><last>Markantonatou</last></editor>
      <editor><first>John</first><last>McCrae</last></editor>
      <editor><first>Jelena</first><last>Mitrovi&#263;</last></editor>
      <editor><first>Carole</first><last>Tiberius</last></editor>
      <editor><first>Carlos</first><last>Ramisch</last></editor>
      <editor><first>Ashwini</first><last>Vaidya</last></editor>
      <editor><first>Petya</first><last>Osenova</last></editor>
      <editor><first>Agata</first><last>Savary</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="fa57eb6a">2020.mwe-1.0</url>
      <bibkey>mwe-2020-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>C</fixed-case>oll<fixed-case>F</fixed-case>r<fixed-case>E</fixed-case>n: Rich Bilingual <fixed-case>E</fixed-case>nglish&#8211;<fixed-case>F</fixed-case>rench Collocation Resource</title>
      <author><first>Beatriz</first><last>Fisas</last></author>
      <author><first>Luis</first><last>Espinosa Anke</last></author>
      <author><first>Joan</first><last>Codina-Filb&#225;</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>1&#8211;12</pages>
      <abstract>Collocations in the sense of idiosyncratic lexical co-occurrences of two syntactically bound words traditionally pose a challenge to language learners and many Natural Language Processing (NLP) applications alike. Reliable ground truth (i.e., ideally manually compiled) resources are thus of high value. We present a manually compiled bilingual English&#8211;French collocation resource with 7,480 collocations in English and 6,733 in French. Each collocation is enriched with information that facilitates its downstream exploitation in NLP tasks such as machine translation, word sense disambiguation, natural language generation, relation classification, and so forth. Our proposed enrichment covers: the semantic category of the collocation (its lexical function), its vector space representation (for each individual word as well as their joint collocation embedding), a subcategorization pattern of both its elements, as well as their corresponding BabelNet id, and finally, indices of their occurrences in large scale reference corpora.</abstract>
      <url hash="e9869b4e">2020.mwe-1.1</url>
      <bibkey>fisas-etal-2020-collfren</bibkey>
      <pwccode url="https://github.com/talnupf/collfren" additional="false">talnupf/collfren</pwccode>
    </paper>
    <paper id="3">
      <title>Hierarchy-aware Learning of Sequential Tool Usage via Semi-automatically Constructed Taxonomies</title>
      <author><first>Nima</first><last>Nabizadeh</last></author>
      <author><first>Martin</first><last>Heckmann</last></author>
      <author><first>Dorothea</first><last>Kolossa</last></author>
      <pages>22&#8211;26</pages>
      <abstract>When repairing a device, humans employ a series of tools that corresponds to the arrangement of the device components. Such sequences of tool usage can be learned from repair manuals, so that at each step, having observed the previously applied tools, a sequential model can predict the next required tool. In this paper, we improve the tool prediction performance of such methods by additionally taking the hierarchical relationships among the tools into account. To this aim, we build a taxonomy of tools with hyponymy and hypernymy relations from the data by decomposing all multi-word expressions of tool names. We then develop a sequential model that performs a binary prediction for each node in the taxonomy. The evaluation of the method on a dataset of repair manuals shows that encoding the tools with the constructed taxonomy and using a top-down beam search for decoding increases the prediction accuracy and yields an interpretable taxonomy as a potentially valuable byproduct.</abstract>
      <url hash="a47f13b7">2020.mwe-1.3</url>
      <bibkey>nabizadeh-etal-2020-hierarchy</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>A</fixed-case>lpha<fixed-case>MWE</fixed-case>: Construction of Multilingual Parallel Corpora with <fixed-case>MWE</fixed-case> Annotations</title>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Gareth</first><last>Jones</last></author>
      <author><first>Alan</first><last>Smeaton</last></author>
      <pages>44&#8211;57</pages>
      <abstract>In this work, we present the construction of multilingual parallel corpora with annotation of multiword expressions (MWEs). MWEs include verbal MWEs (vMWEs) defined in the PARSEME shared task that have a verb as the head of the studied terms. The annotated vMWEs are also bilingually and multilingually aligned manually. The languages covered include English, Chinese, Polish, and German. Our original English corpus is taken from the PARSEME shared task in 2018. We performed machine translation of this source corpus followed by human post editing and annotation of target MWEs. Strict quality control was applied for error limitation, i.e., each MT output sentence received first manual post editing and annotation plus second manual quality rechecking. One of our findings during corpora preparation is that accurate translation of MWEs presents challenges to MT systems. To facilitate further MT research, we present a categorisation of the error types encountered by MT systems in performing MWE related translation. To acquire a broader view of MT issues, we selected four popular state-of-the-art MT models for comparisons namely: Microsoft Bing Translator, GoogleMT, Baidu Fanyi and DeepL MT. Because of the noise removal, translation post editing and MWE annotation by human professionals, we believe our AlphaMWE dataset will be an asset for cross-lingual and multilingual research, such as MT and information extraction. Our multilingual corpora are available as open access at github.com/poethan/AlphaMWE.</abstract>
      <url hash="16e295b9">2020.mwe-1.6</url>
      <bibkey>han-etal-2020-alphamwe</bibkey>
      <pwccode url="https://github.com/poethan/AlphaMWE" additional="false">poethan/AlphaMWE</pwccode>
    </paper>
    <paper id="7">
      <title>Annotating Verbal <fixed-case>MWE</fixed-case>s in <fixed-case>I</fixed-case>rish for the <fixed-case>PARSEME</fixed-case> Shared Task 1.2</title>
      <author><first>Abigail</first><last>Walsh</last></author>
      <author><first>Teresa</first><last>Lynn</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <pages>58&#8211;65</pages>
      <abstract>This paper describes the creation of two Irish corpora (labelled and unlabelled) for verbal MWEs for inclusion in the PARSEME Shared Task 1.2 on automatic identification of verbal MWEs, and the process of developing verbal MWE categories for Irish. A qualitative analysis on the two corpora is presented, along with discussion of Irish verbal MWEs.</abstract>
      <url hash="c78d9a40">2020.mwe-1.7</url>
      <bibkey>walsh-etal-2020-annotating</bibkey>
    </paper>
    <paper id="10">
      <title>Multi-word Expressions for Abusive Speech Detection in <fixed-case>S</fixed-case>erbian</title>
      <author><first>Ranka</first><last>Stankovi&#263;</last></author>
      <author><first>Jelena</first><last>Mitrovi&#263;</last></author>
      <author><first>Danka</first><last>Joki&#263;</last></author>
      <author><first>Cvetana</first><last>Krstev</last></author>
      <pages>74&#8211;84</pages>
      <abstract>This paper presents our work on the refinement and improvement of the Serbian language part of Hurtlex, a multilingual lexicon of words to hurt. We pay special attention to adding Multi-word expressions that can be seen as abusive, as such lexical entries are very important in obtaining good results in a plethora of abusive language detection tasks. We use Serbian morphological dictionaries as a basis for data cleaning and MWE dictionary creation. A connection to other lexical and semantic resources in Serbian is outlined and building of abusive language detection systems based on that connection is foreseen.</abstract>
      <url hash="1a680f61">2020.mwe-1.10</url>
      <bibkey>stankovic-etal-2020-multi</bibkey>
    </paper>
    <paper id="12">
      <title>Comparing word2vec and <fixed-case>G</fixed-case>lo<fixed-case>V</fixed-case>e for Automatic Measurement of <fixed-case>MWE</fixed-case> Compositionality</title>
      <author><first>Thomas</first><last>Pickard</last></author>
      <pages>95&#8211;100</pages>
      <abstract>This paper explores the use of word2vec and GloVe embeddings for unsupervised measurement of the semantic compositionality of MWE candidates. Through comparison with several human-annotated reference sets, we find word2vec to be substantively superior to GloVe for this task. We also find Simple English Wikipedia to be a poor-quality resource for compositionality assessment, but demonstrate that a sample of 10% of sentences in the English Wikipedia can provide a conveniently tractable corpus with only moderate reduction in the quality of outputs.</abstract>
      <url hash="a1809f27">2020.mwe-1.12</url>
      <bibkey>pickard-2020-comparing</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>V</fixed-case>itamin<fixed-case>B</fixed-case>ooster at <fixed-case>PARSEME</fixed-case> Shared Task 2020: Combining Window- and Dependency-Based Features with Multilingual Contextualised Word Embeddings for <fixed-case>VMWE</fixed-case> Detection</title>
      <author><first>Sebastian</first><last>Gombert</last></author>
      <author><first>Sabine</first><last>Bartsch</last></author>
      <pages>149&#8211;155</pages>
      <abstract>In this paper, we present MultiVitaminBooster, a system implemented for the PARSEME shared task on semi-supervised identification of verbal multiword expressions - edition 1.2. For our approach, we interpret detecting verbal multiword expressions as a token classification task aiming to decide whether a token is part of a verbal multiword expression or not. For this purpose, we train gradient boosting-based models. We encode tokens as feature vectors combining multilingual contextualized word embeddings provided by the XLM-RoBERTa language model with a more traditional linguistic feature set relying on context windows and dependency relations. Our system was ranked 7th in the official open track ranking of the shared task evaluations with an encoding-related bug distorting the results. For this reason we carry out further unofficial evaluations. Unofficial versions of our systems would have achieved higher ranks.</abstract>
      <url hash="40e930c0">2020.mwe-1.20</url>
      <bibkey>gombert-bartsch-2020-multivitaminbooster</bibkey>
    </paper>
  </volume>
</collection>