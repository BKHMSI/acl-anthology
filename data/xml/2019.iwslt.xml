<?xml version='1.0' encoding='utf-8'?>
<collection id="2019.iwslt">
  <volume id="1" ingest-date="2022-02-17">
    <meta>
      <booktitle>Proceedings of the 16th International Conference on Spoken Language Translation</booktitle>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Hong Kong</address>
      <month>November 2-3</month>
      <year>2019</year>
      <editor><first>Jan</first><last>Niehues</last></editor>
      <editor><first>Rolando</first><last>Cattoni</last></editor>
      <editor><first>Sebastian</first><last>Stüker</last></editor>
      <editor><first>Matteo</first><last>Negri</last></editor>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <editor><first>Thanh-Le</first><last>Ha</last></editor>
      <editor><first>Elizabeth</first><last>Salesky</last></editor>
      <editor><first>Ramon</first><last>Sanabria</last></editor>
      <editor><first>Loic</first><last>Barrault</last></editor>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <editor><first>Marcello</first><last>Federico</last></editor>
    </meta>
    <paper id="1">
      <title>The IWSLT 2019 Evaluation Campaign<fixed-case>IWSLT</fixed-case> 2019 Evaluation Campaign</title>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Rolando</first><last>Cattoni</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Elizabeth</first><last>Salesky</last></author>
      <author><first>Ramon</first><last>Sanabria</last></author>
      <author><first>Loic</first><last>Barrault</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <abstract>The IWSLT 2019 evaluation campaign featured three tasks : speech translation of (i) <a href="https://en.wikipedia.org/wiki/TED_(conference)">TED talks</a> and (ii) How2 instructional videos from <a href="https://en.wikipedia.org/wiki/English_language">English</a> into <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, and (iii) text translation of <a href="https://en.wikipedia.org/wiki/TED_(conference)">TED talks</a> from <a href="https://en.wikipedia.org/wiki/English_language">English</a> into <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>. For the first two tasks we encouraged submissions of end- to-end speech-to-text systems, and for the second task participants could also use the video as additional input. We received submissions by 12 research teams. This overview provides detailed descriptions of the data and evaluation conditions of each task and reports results of the participating systems.</abstract>
      <url hash="96ae3b28">2019.iwslt-1.1</url>
      <bibkey>niehues-etal-2019-iwslt</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    <paper id="4">
      <title>ESPnet How2 Speech Translation System for IWSLT 2019 : Pre-training, Knowledge Distillation, and Going Deeper<fixed-case>ESP</fixed-case>net How2 Speech Translation System for <fixed-case>IWSLT</fixed-case> 2019: Pre-training, Knowledge Distillation, and Going Deeper</title>
      <author><first>Hirofumi</first><last>Inaguma</last></author>
      <author><first>Shun</first><last>Kiyono</last></author>
      <author><first>Nelson Enrique Yalta</first><last>Soplin</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <author><first>Shinji</first><last>Watanabe</last></author>
      <abstract>This paper describes the ESPnet submissions to the How2 Speech Translation task at IWSLT2019. In this year, we mainly build our systems based on Transformer architectures in all tasks and focus on the end-to-end speech translation (E2E-ST). We first compare RNN-based models and Transformer, and then confirm Transformer models significantly and consistently outperform RNN models in all tasks and corpora. Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks. On top of the pre-training, we further explore knowledge distillation from the NMT model and the deeper speech encoder, and confirm drastic improvements over the baseline model. All of our codes are publicly available in ESPnet.</abstract>
      <url hash="be527f4e">2019.iwslt-1.4</url>
      <bibkey>inaguma-etal-2019-espnet</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/librispeech">LibriSpeech</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    <paper id="5">
      <title>ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task<fixed-case>ON</fixed-case>-<fixed-case>TRAC</fixed-case> Consortium End-to-End Speech Translation Systems for the <fixed-case>IWSLT</fixed-case> 2019 Shared Task</title>
      <author><first>Ha</first><last>Nguyen</last></author>
      <abstract>This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English Portuguese language pair. ON-TRAC Consortium is composed of researchers from three French academic laboratories : LIA (Avignon Universit), LIG (Universit Grenoble Alpes), and LIUM (Le Mans Universit). A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets : (1) TED (MuST-C) and (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of <a href="https://en.wikipedia.org/wiki/Speech_segmentation">speech input segmentation</a> and we also compare our best <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end model</a> (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.</abstract>
      <url hash="4b4966fb">2019.iwslt-1.5</url>
      <bibkey>nguyen-2019-trac</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ted-lium-3">TED-LIUM 3</pwcdataset>
    </paper>
    <paper id="6">
      <title>Transformer-based Cascaded Multimodal Speech Translation</title>
      <author><first>Zixiu</first><last>Wu</last></author>
      <author><first>Ozan</first><last>Caglayan</last></author>
      <author><first>Julia</first><last>Ive</last></author>
      <author><first>Josiah</first><last>Wang</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <abstract>This paper describes the cascaded multimodal speech translation systems developed by Imperial College London for the IWSLT 2019 evaluation campaign. The architecture consists of an automatic speech recognition (ASR) system followed by a Transformer-based multimodal machine translation (MMT) system. While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">visual context</a> (simple conditioning vs. attention), the type of <a href="https://en.wikipedia.org/wiki/Visual_system">visual features</a> exploited (pooled, convolutional, action categories) and the underlying architecture. For the latter, we explore both the canonical transformer and its deliberation version with additive and cascade variants which differ in how they integrate the textual attention. Upon conducting extensive experiments, we found that (i) the explored visual integration schemes often harm the translation performance for the transformer and additive deliberation, but considerably improve the cascade deliberation ; (ii) the transformer and cascade deliberation integrate the visual modality better than the additive deliberation, as shown by the incongruence analysis.</abstract>
      <url hash="3a1fe36d">2019.iwslt-1.6</url>
      <bibkey>wu-etal-2019-transformer</bibkey>
    </paper>
    <paper id="11">
      <title>The LIG system for the English-Czech Text Translation Task of IWSLT 2019<fixed-case>LIG</fixed-case> system for the <fixed-case>E</fixed-case>nglish-<fixed-case>C</fixed-case>zech Text Translation Task of <fixed-case>IWSLT</fixed-case> 2019</title>
      <author><first>Loïc</first><last>Vial</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Hang</first><last>Le</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <abstract>In this paper, we present our submission for the English to Czech Text Translation Task of IWSLT 2019. Our system aims to study how pre-trained language models, used as input embeddings, can improve a specialized machine translation system trained on few data. Therefore, we implemented a Transformer-based encoder-decoder neural system which is able to use the output of a pre-trained language model as input embeddings, and we compared its performance under three configurations : 1) without any pre-trained language model (constrained), 2) using a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> trained on the monolingual parts of the allowed English-Czech data (constrained), and 3) using a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> trained on a large quantity of external monolingual data (unconstrained). We used BERT as external pre-trained language model (configuration 3), and BERT architecture for training our own <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> (configuration 2). Regarding the training data, we trained our MT system on a small quantity of parallel text : one set only consists of the provided MuST-C corpus, and the other set consists of the MuST-C corpus and the News Commentary corpus from WMT. We observed that using the external pre-trained BERT improves the scores of our <a href="https://en.wikipedia.org/wiki/System">system</a> by +0.8 to +1.5 of BLEU on our development set, and +0.97 to +1.94 of BLEU on the test set. However, using our own <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> trained only on the allowed parallel data seems to improve the <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> performances only when the system is trained on the smallest dataset.</abstract>
      <url hash="61d6c2fb">2019.iwslt-1.11</url>
      <bibkey>vial-etal-2019-lig</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    <paper id="13">
      <title>KIT’s Submission to the IWSLT 2019 Shared Task on Text Translation<fixed-case>KIT</fixed-case>’s Submission to the <fixed-case>IWSLT</fixed-case> 2019 Shared Task on Text Translation</title>
      <author><first>Felix</first><last>Schneider</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <abstract>In this paper, we describe KIT’s submission for the IWSLT 2019 shared task on text translation. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is based on the transformer model [ 1 ] using our in-house implementation. We augment the available training data using <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> and employ <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> for the final <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>. For our best results, we used a 12-layer transformer-big config- uration, achieving state-of-the-art results on the WMT2018 test set. We also experiment with student-teacher models to improve performance of smaller <a href="https://en.wikipedia.org/wiki/Computer_simulation">models</a>.</abstract>
      <url hash="a61bab92">2019.iwslt-1.13</url>
      <bibkey>schneider-waibel-2019-kits</bibkey>
    </paper>
    <paper id="16">
      <title>Adapting Multilingual Neural Machine Translation to Unseen Languages</title>
      <author><first>Surafel M.</first><last>Lakew</last></author>
      <author><first>Alina</first><last>Karakanta</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <abstract>Multilingual Neural Machine Translation (MNMT) for low- resource languages (LRL) can be enhanced by the presence of related high-resource languages (HRL), but the relatedness of HRL usually relies on predefined linguistic assumptions about language similarity. Recently, adapting MNMT to a <a href="https://en.wikipedia.org/wiki/Linear_regression">LRL</a> has shown to greatly improve performance. In this work, we explore the problem of adapting an MNMT model to an unseen <a href="https://en.wikipedia.org/wiki/Linear_regression">LRL</a> using data selection and model adapta- tion. In order to improve NMT for <a href="https://en.wikipedia.org/wiki/Linguistic_description">LRL</a>, we employ perplexity to select HRL data that are most similar to the <a href="https://en.wikipedia.org/wiki/Linguistic_description">LRL</a> on the basis of <a href="https://en.wikipedia.org/wiki/Language_distance">language distance</a>. We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRLen). We further show that dynamic adaptation of the model’s vocabulary results in a more favourable segmentation for the LRL in comparison with direct adaptation. Experiments show re- ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection. Our method outperforms current approaches, such as massively multilingual models and <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, on four <a href="https://en.wikipedia.org/wiki/Linear_regression">LRL</a>.</abstract>
      <url hash="1b241b83">2019.iwslt-1.16</url>
      <bibkey>lakew-etal-2019-adapting</bibkey>
      <pwccode url="https://github.com/surafelml/adapt-mnmt" additional="false">surafelml/adapt-mnmt</pwccode>
    </paper>
    <paper id="17">
      <title>Transformers without Tears : Improving the Normalization of Self-Attention</title>
      <author><first>Toan Q.</first><last>Nguyen</last></author>
      <author><first>Julian</first><last>Salazar</last></author>
      <abstract>We evaluate three simple, normalization-centric changes to improve Transformer training. First, we show that pre-norm residual connections (PRENORM) and smaller initializations enable warmup-free, validation-based training with large learning rates. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM). On five low-resource translation pairs from <a href="https://en.wikipedia.org/wiki/TED_(conference)">TED Talks-based corpora</a>, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT’ 15 English-Vietnamese. We ob- serve sharper performance curves, more consistent gradient norms, and a linear relationship between activation scaling and decoder depth. Surprisingly, in the high-resource setting (WMT’ 14 English-German), SCALENORM and FIXNORM remain competitive but PRENORM degrades performance.</abstract>
      <url hash="7cc09ad6">2019.iwslt-1.17</url>
      <bibkey>nguyen-salazar-2019-transformers</bibkey>
      <pwccode url="https://github.com/tnq177/transformers_without_tears" additional="true">tnq177/transformers_without_tears</pwccode>
    </paper>
    <paper id="18">
      <title>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</title>
      <author><first>Juan</first><last>Pino</last></author>
      <author><first>Liezl</first><last>Puzon</last></author>
      <author><first>Jiatao</first><last>Gu</last></author>
      <author><first>Xutai</first><last>Ma</last></author>
      <author><first>Arya D.</first><last>McCarthy</last></author>
      <author><first>Deepak</first><last>Gopinath</last></author>
      <abstract>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. In this work, we evaluate several data augmentation and pretraining approaches for <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">AST</a>, by comparing all on the same <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. Simple <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> by translating ASR transcripts proves most effective on the EnglishFrench augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end approach</a> plus <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> closes the gap on the EnglishRomanian MuST-C dataset from 6.7 to 3.7 <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>. In addition to these results, we present practical rec- ommendations for augmentation and pretraining approaches. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</abstract>
      <url hash="2c55855c">2019.iwslt-1.18</url>
      <bibkey>pino-etal-2019-harnessing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/librispeech">LibriSpeech</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    <title_es>Aprovechamiento de datos de entrenamiento indirectos para la traducción automática de voz de principio a fin: trucos del oficio</title_es>
      <title_ar>تسخير بيانات التدريب غير المباشر للترجمة التلقائية للكلام: حيل التجارة</title_ar>
      <title_pt>Aproveitando dados de treinamento indireto para tradução automática de fala de ponta a ponta: truques do comércio</title_pt>
      <title_ja>エンドツーエンドの自動音声翻訳のための間接トレーニングデータの活用：取引のコツ</title_ja>
      <title_zh>因间接练数端到端自音译:交易技巧</title_zh>
      <title_hi>एंड-टू-एंड स्वचालित भाषण अनुवाद के लिए अप्रत्यक्ष प्रशिक्षण डेटा का दोहन: व्यापार की ट्रिक्स</title_hi>
      <title_ga>Leas a Bhaint as Sonraí Oiliúna Indíreacha le haghaidh Aistriúchán Urlabhra Uathoibríoch ó cheann go ceann: Seifteanna na Trádála</title_ga>
      <title_el>Αξιοποίηση έμμεσων δεδομένων κατάρτισης για την αυτόματη μετάφραση ομιλίας εξ ολοκλήρου: κόλπα του εμπορίου</title_el>
      <title_hu>Közvetett képzési adatok hasznosítása végpontos automatikus beszédfordításhoz: a kereskedelem trükkjei</title_hu>
      <title_ka>ბოლოდან ბოლოდან ბოლოდან დასრულებული სიტყვების თავისწორება: სამუშაო თავისწორება</title_ka>
      <title_it>Sfruttare i dati di formazione indiretta per una traduzione vocale automatica end-to-end: trucchi del mestiere</title_it>
      <title_kk>Аяқтау- аяқтау автоматты сөйлеу аудармасының жетілдік оқыту деректерін қолдануға болады: Салымды тәртіптері</title_kk>
      <title_lt>Netiesioginio mokymo duomenų, skirtų automatiniam kalbos vertimui nuo pabaigos, panaudojimas: prekybos triukšmai</title_lt>
      <title_mk>Употреба на индиректни податоци за обука за автоматски превед на говор од крај до крај: Трикови од трговијата</title_mk>
      <title_mt>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation: Tricks of the Trade</title_mt>
      <title_ml>അവസാന- മുതല്‍ അവസാനിക്കുന്ന സ്വയമായി സംസാര പരിശീലന വിവരങ്ങള്‍</title_ml>
      <title_mn>Бүтээгдэхүүний төгсгөл-төгсгөлд автоматически ярианы хөрөнгө оруулалт: Худалдааны шинжлэх ухаан</title_mn>
      <title_ro>Utilizarea datelor indirecte de formare pentru traducerea automată a vorbirii end-to-end: trucurile comerțului</title_ro>
      <title_ms>Menggunakan Data Latihan Tidak Terlangsung untuk Terjemahan Ucapan Automatik Akhir-Akhir: Tricks of the Trade</title_ms>
      <title_pl>Wykorzystanie pośrednich danych szkoleniowych do kompleksowego automatycznego tłumaczenia mowy: sztuczki handlowe</title_pl>
      <title_no>Hentar indirekte treningsdata for automatisk taleomsetjing til slutt til slutt: Tricks of the Trade</title_no>
      <title_si>අවසානයෙන් අවසානයෙන් ස්වයංක්‍රීය වාර්තාව සඳහා අනිත් ප්‍රධාන දත්ත සම්බන්ධ කරනවා: ව්‍යාපාරයේ ස</title_si>
      <title_so>Turjumidda dhammaadka-to-End Automatic Speech: Tricks of the Trade</title_so>
      <title_sv>Utnyttja indirekta träningsdata för automatisk talöversättning från början till slut: tricks of the trade</title_sv>
      <title_sr>Koristenje indirektnih podataka obuke za automatski prevod govora do kraja: Trikovi trgovine</title_sr>
      <title_ur>پایان سے پایان کے لئے نازل ترینیننگ ڈاٹے کے مطابق اپنا انویٹ ژنرال کیا جا رہا ہے: تجارت کی تریکس</title_ur>
      <title_ta>முடிவில் இருந்து முடிவில் இருந்து தானியங்கி பேச்சு மொழிபெயர்ப்பிற்கான குறிப்பிட்ட பயிற்சி தகவல்</title_ta>
      <title_uz>Tricks of the Trade</title_uz>
      <title_vi>Đang sử dụng dữ liệu giáo dục trực tiếp cho giai đoạn nói tự động cuối:</title_vi>
      <title_hr>Koristenje podataka o indirektnom obuku za automatski prevod govora do kraja: Trikovi trgovine</title_hr>
      <title_nl>Indirecte trainingsgegevens gebruiken voor end-to-end automatische spraakvertaling: trucs van de handel</title_nl>
      <title_bg>Използване на индиректни данни за обучение за автоматичен речен превод от край до край: трикове на търговията</title_bg>
      <title_da>Udnyttelse af indirekte træningsdata til automatisk taleoversættelse end-to-end: Tricks of te Trade</title_da>
      <title_de>Indirekte Trainingsdaten für die End-to-End automatische Sprachübersetzung nutzen: Tricks of the Trade</title_de>
      <title_id>Menggunakan Data Pelatihan Indirekt untuk Perjemahan Ucapan Otomatis Akhir-Akhir: Tricks of the Trade</title_id>
      <title_ko>간접 트레이닝 데이터를 이용하여 끝에서 끝까지 자동 음성 번역: 기교</title_ko>
      <title_fa>استفاده از داده‌های آموزش غیرمستقیم برای ترجمه‌های گفتگوی خودکار پایان به پایان: ترکیب‌های تجارت</title_fa>
      <title_sw>Takwimu za mafunzo ya Kihindi kwa ajili ya Tafsiri ya kujieleza binafsi ya Kuishia hadi mwishoni: Tricks of the Trade</title_sw>
      <title_tr>Soňra-soňra Awtomatik Sözler terjime etmek üçin Taýratyn Ewezam Maglumaty Hareketlenýän: Täkiýet Trikleri</title_tr>
      <title_hy>Օգտագործելով անուղղակի ուսուցման տվյալները վերջ-վերջ ավտոմատիկ խոսքի թարգմանման համար.</title_hy>
      <title_am>Tricks of the Trade</title_am>
      <title_af>Onderhou Indirekte Oefening Data vir Einde- na- Einde Automaties Spraak Vertaling: Tricks of the Trade</title_af>
      <title_sq>Përdorimi i të dhënave të trajnimit të pavarur për përkthimin automatik të fjalës nga fundi në fund: Tricks of the Trade</title_sq>
      <title_bn>স্বয়ংক্রিয়ভাবে স্বাক্ষরিক ভাষণ অনুবাদের জন্য স্থানীয় প্রশিক্ষণের তথ্য হার্নাসিং করছে: ট্রাইডের ট্রিক</title_bn>
      <title_az>Son-to-end avtomatik s칬z 칞evirilm톛si 칲칞칲n indir톛t t톛hsil m톛lumat캼 istifad톛 edilir: ticar톛t s캼ralar캼</title_az>
      <title_cs>Využití nepřímých tréninkových dat pro komplexní automatický překlad řeči: triky obchodu</title_cs>
      <title_bs>Koristenje podataka o indirektnom obuci za automatski prevod govora do kraja: Trikovi trgovine</title_bs>
      <title_et>Kaudse koolituse andmete kasutamine otsast otsani automaatse kõnetõlke jaoks: kaubanduse trikid</title_et>
      <title_fi>Välillisten koulutustietojen hyödyntäminen päästä päähän automaattiseen puheen kääntämiseen: kaupan temput</title_fi>
      <title_ca>Utilitzar les dades d'entrenament indirect per a traduir la llengua automàtica de final a final: trucs del comerç</title_ca>
      <title_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness</title_jv>
      <title_he>שימוש מידע אימון אינדריט לתרגום אוטומטי של נאום סוף-סוף: טריקים של הסחר</title_he>
      <title_ha>@ action</title_ha>
      <title_sk>Izkoriščanje podatkov o posrednem usposabljanju za avtomatsko prevajanje govora od konca do konca: triki trgovine</title_sk>
      <title_bo>མཇུག་ལ་མཇུག་གི་སྐད་ཡིག་ཆ་ལ་རང་འགུལ་གྱི་སྐད་བསྒྱུར་བཅོས་ཐབས་མེད་པའི་ཐད་ཚོགས་གཙོ་རིམ།</title_bo>
      <abstract_ar>بالنسبة للترجمة الآلية للكلام (AST) ، يتفوق أداء الأساليب الشاملة على النماذج المتتالية التي يتم نسخها باستخدام التعرف التلقائي على الكلام (ASR) ، ثم الترجمة الآلية (MT). أحد الأسباب الرئيسية لفجوة الأداء هو أنه في حين أن مجموعات AST الحالية صغيرة ، توجد مجموعات بيانات ضخمة لكل من النظامين الفرعيين لـ ASR و MT. في هذا العمل ، نقوم بتقييم العديد من أساليب زيادة البيانات والتدريب المسبق لـ AST ، من خلال مقارنة الكل في نفس مجموعات البيانات. أثبتت زيادة البيانات البسيطة عن طريق ترجمة نصوص ASR أنها أكثر فاعلية على مجموعة بيانات LibriSpeech المعززة باللغتين الإنجليزية والفرنسية ، مما أدى إلى سد فجوة الأداء من 8.2 إلى 1.4 BLEU ، مقارنة بسلسلة قوية جدًا يمكن أن تستخدم بشكل مباشر بيانات ASR و MT الوفيرة. نفس النهج الشامل بالإضافة إلى الضبط الدقيق يغلق الفجوة في مجموعة البيانات الإنجليزية-الرومانية MuST-C من 6.7 إلى 3.7 BLEU. بالإضافة إلى هذه النتائج ، نقدم توصيات عملية لزيادة وطرق التدريب. أخيرًا ، قمنا بتقليل فجوة الأداء إلى 0.01 BLEU باستخدام بنية قائمة على المحولات.</abstract_ar>
      <abstract_pt>Para tradução automática de fala (AST), as abordagens de ponta a ponta são superadas por modelos em cascata que transcrevem com reconhecimento automático de fala (ASR) e depois traduzem com tradução automática (MT). Uma das principais causas da lacuna de desempenho é que, embora os corpora AST existentes sejam pequenos, existem grandes conjuntos de dados para os subsistemas ASR e MT. Neste trabalho, avaliamos várias abordagens de aumento de dados e pré-treinamento para AST, comparando todas nos mesmos conjuntos de dados. O aumento simples de dados traduzindo transcrições de ASR se mostra mais eficaz no conjunto de dados LibriSpeech aumentado em inglês-francês, fechando a lacuna de desempenho de 8,2 para 1,4 BLEU, em comparação com uma cascata muito forte que poderia utilizar diretamente dados copiosos de ASR e MT. A mesma abordagem de ponta a ponta mais o ajuste fino fecha a lacuna no conjunto de dados MuST-C inglês-romeno de 6,7 para 3,7 BLEU. Além desses resultados, apresentamos recomendações práticas para abordagens de aumento e pré-treinamento. Finalmente, reduzimos a diferença de desempenho para 0,01 BLEU usando uma arquitetura baseada em Transformer.</abstract_pt>
      <abstract_es>Para la traducción automática de voz (AST), los enfoques de extremo a extremo se ven superados por los modelos en cascada que transcriben con reconocimiento automático de voz (ASR) y luego se traducen con traducción automática (MT). Una de las principales causas de la brecha de rendimiento es que, si bien los cuerpos AST existentes son pequeños, existen conjuntos de datos masivos para los subsistemas ASR y MT. En este trabajo, evaluamos varios enfoques de aumento de datos y preentrenamiento para AST, comparando todos en los mismos conjuntos de datos. El simple aumento de datos mediante la traducción de transcripciones de ASR resulta más eficaz en el conjunto de datos de LibriSpeech ampliado en inglés y francés, ya que cierra la brecha de rendimiento de 8,2 a 1,4 BLEU, en comparación con una cascada muy sólida que podría utilizar directamente una gran cantidad de datos de ASR y MT. El mismo enfoque de extremo a extremo más el ajuste fino cierra la brecha en el conjunto de datos Must-C de inglés a rumano de 6,7 a 3,7 BLEU. Además de estos resultados, presentamos recomendaciones prácticas para enfoques de aumento y preentrenamiento. Finalmente, disminuimos la brecha de rendimiento a 0,01 BLEU mediante una arquitectura basada en Transformer.</abstract_es>
      <abstract_ja>自動音声翻訳（ ＡＳＴ ）の場合、エンドツーエンドのアプローチは、自動音声認識（ ＡＳＲ ）で転写し、次に機械翻訳（ Ｍ Ｔ ）で遅れて転写するカスケードモデルによって凌駕される。 パフォーマンスギャップの主な原因は、既存のASTコーラが小さい一方で、ASRサブシステムとMTサブシステムの両方に大規模なデータセットが存在することです。 この研究では、同じデータセット上のすべてを比較することによって、ASTのいくつかのデータ拡張および事前トレーニングアプローチを評価します。 ASRトランスクリプトを翻訳することによる単純なデータ拡張は、英仏の拡張LibriSpeechデータセットで最も効果的であることが証明されており、膨大なASRおよびMTデータを直接利用できる非常に強力なカスケードと比較して、8.2から1.4 BLEUまでのパフォーマンスギャップを埋めます。 同じエンドツーエンドのアプローチと微調整は、英語-ルーマニア語のMuST - Cデータセットの6.7から3.7 BLEUのギャップを埋めます。 これらの結果に加えて、拡張および事前トレーニングアプローチのための実用的な推奨事項を提示します。 最後に、トランスフォーマーベースのアーキテクチャでは、パフォーマンスギャップを0.01 BLEUに減らします。</abstract_ja>
      <abstract_zh>其自语音译 (AST),端到端优于级联,用自语音 (ASR) 转录之,然后用机器翻译 (MT) 后期译。 性所以去者,虽见AST语料库小,而ASRMT子系统皆大集。 于此等事,比较同集数以增预训练方法,评AST数以增预训练方法。 译 ASR 转录本简数增于英语-法语增强型 LibriSpeech 数集上验为最效,与可径用多 ASR 与 MT 数之极强者比,将性相去自 8.2 BLEU缩小至 1.4%。 同端到端加微调英语 - 罗马尼亚MuST-C数集差从6.7缩小至3.7 BLEU。 自此之外,增预训练方法之实用建议。 最后,相去缩小0.01 BLEU基于Transformer架构。</abstract_zh>
      <abstract_hi>स्वचालित भाषण अनुवाद (एएसटी) के लिए, एंड-टू-एंड दृष्टिकोण कैस्केड मॉडल द्वारा बेहतर प्रदर्शन किया जाता है जो स्वचालित भाषण मान्यता (एएसआर) के साथ प्रतिलेखन करते हैं, फिर मशीन अनुवाद (एमटी) के साथ ट्रांस-लेट होते हैं। प्रदर्शन अंतर का एक प्रमुख कारण यह है कि, जबकि मौजूदा एएसटी कॉर्पोरेट छोटे हैं, एएसआर और एमटी सबसिस्टम दोनों के लिए बड़े पैमाने पर डेटासेट मौजूद हैं। इस काम में, हम एक ही डेटासेट पर सभी की तुलना करके एएसटी के लिए कई डेटा वृद्धि और प्रीट्रेनिंग दृष्टिकोणों का मूल्यांकन करते हैं। एएसआर टेपों का अनुवाद करके सरल डेटा वृद्धि अंग्रेजी-फ्रांसीसी संवर्धित LibriSpeech डेटासेट पर सबसे प्रभावी साबित होती है, 8.2 से 1.4 BLEU तक प्रदर्शन अंतर को बंद कर देती है, एक बहुत ही मजबूत कैस्केड की तुलना में जो सीधे प्रचुर मात्रा में एएसआर और एमटी डेटा का उपयोग कर सकती है। एक ही एंड-टू-एंड दृष्टिकोण प्लस फाइन-ट्यूनिंग अंग्रेजी-रोमानियाई MuST-C डेटासेट पर 6.7 से 3.7 BLEU तक के अंतर को बंद कर देता है। इन परिणामों के अलावा, हम वृद्धि और pretraining दृष्टिकोण के लिए व्यावहारिक rec-ommendations प्रस्तुत करते हैं। अंत में, हम प्रदर्शन अंतर को 0.01 BLEU तक कम करते हैं, जो हमें एक ट्रांसफॉर्मर-आधारित आर्किटेक्चर को कम करता है।</abstract_hi>
      <abstract_ga>Maidir le haistriúchán cainte uathoibríoch (AST), tá cur chuige ceann-go-deireadh níos fearr ag samhlacha cascáideacha a thras-scríobhtar le haitheantas cainte uathoibríoch (ASR), a thrasnaíonn le haistriúchán meaisín (MT) ansin. Príomhchúis leis an mbearna feidhmíochta is ea, cé go bhfuil corparáidí AST reatha beag, go bhfuil tacair shonraí ollmhóra ann do na fochórais ASR agus MT araon. San obair seo, déanaimid meastóireacht ar roinnt cineálacha cur chuige um mhéadú sonraí agus réamhoiliúint do AST, trí chomparáid a dhéanamh idir iad uile ar na tacair sonraí céanna. Is éifeachtaí méadú sonraí simplí trí thrascríbhinní ASR a aistriú ar thacar sonraí méadaithe LibriSpeech Béarla-Fraincis, ag dúnadh na bearna feidhmíochta ó 8.2 go 1.4 BLEU, i gcomparáid le easghluaiseachta an-láidir a d’fhéadfadh úsáid dhíreach a bhaint as sonraí ollmhóra ASR agus MT. Dúnann an cur chuige ceann go ceann céanna chomh maith le mionchoigeartú an bhearna ar an tacar sonraí Béarla-Rómhánach MST-C ó 6.7 go 3.7 BLEU. Chomh maith leis na torthaí seo, cuirimid i láthair moltaí praiticiúla maidir le cur chuige méadaithe agus réamhoiliúint. Ar deireadh, laghdóimid an bhearna feidhmíochta go 0.01 BLEU ag baint úsáide as ailtireacht Claochladán-bhunaithe.</abstract_ga>
      <abstract_el>Για την αυτόματη μετάφραση ομιλίας (AST), οι ολοκληρωμένες προσεγγίσεις ξεπερνούν από διαδοχικά μοντέλα που μεταγραφούν με αυτόματη αναγνώριση ομιλίας (ASR) και στη συνέχεια μεταγραφούν με μηχανική μετάφραση (MT). Μια κύρια αιτία του χάσματος επιδόσεων είναι ότι, ενώ τα υπάρχοντα σώματα AST είναι μικρά, υπάρχουν τεράστια σύνολα δεδομένων τόσο για το υποσύστημα ASR όσο και για το MT. Στην εργασία αυτή, αξιολογούμε διάφορες προσεγγίσεις αύξησης και προεπιλογής δεδομένων για την AST, συγκρίνοντας όλα τα ίδια σύνολα δεδομένων. Η απλή αύξηση δεδομένων με τη μετάφραση μεταγραφών αποδεικνύεται πιο αποτελεσματική στο αγγλο-γαλλικό εμπλουτισμένο σύνολο δεδομένων κλείνοντας το χάσμα απόδοσης από 8.2 έως 1.4 σε σύγκριση με έναν πολύ ισχυρό καταρράκτη που θα μπορούσε άμεσα να χρησιμοποιήσει άφθονα δεδομένα ASR και MT. Η ίδια ολοκληρωμένη προσέγγιση και η τελειοποίηση κλείνουν το κενό στο αγγλο-ρουμανικό σύνολο δεδομένων MuST-C από 6.7 έως 3.7 BLEU. Εκτός από αυτά τα αποτελέσματα, παρουσιάζουμε πρακτικές συστάσεις για προσεγγίσεις αύξησης και προεπιλογής. Τέλος, μειώνουμε το χάσμα απόδοσης σε 0.01 δημιουργώντας μια αρχιτεκτονική βασισμένη στον μετασχηματιστή.</abstract_el>
      <abstract_hu>Az automatikus beszédfordítás (AST) esetében a end-to-end megközelítéseket olyan kaszkádos modellek végzik, amelyek automatikus beszédfelismeréssel (ASR), majd gépi fordítással (MT) transzformálják. A teljesítmény hiányának egyik fő oka, hogy míg a meglévő AST testek kicsi, nagy adatkészletek léteznek mind az ASR, mind az MT alrendszerek esetében. Ebben a munkában több adatbővítési és előkészítési megközelítést értékelünk az AST esetében, ugyanazon adatkészletek összehasonlításával. Az ASR átiratok fordításával történő egyszerű adatbővítés a leghatékonyabbnak bizonyul az angol-francia kiterjesztett LibriSpeech adatkészleten, csökkentve a teljesítmény hiányát 8.2 és 1.4 BLEU között, összehasonlítva egy nagyon erős kaszkáddal, amely közvetlenül felhasználható bőséges ASR és MT adatokat. Ugyanez a teljes körű megközelítés és finomhangolás csökkenti az angol-román MuST-C adatkészlet 6.7-től 3.7-ig terjedő rését. Ezen eredmények mellett gyakorlati ajánlásokat is bemutatunk a kiterjesztési és előkészítési megközelítésekre vonatkozóan. Végezetül, a teljesítmény hiányát 0,01 BLEU-ra csökkentjük egy Transformer alapú architektúrával.</abstract_hu>
      <abstract_ka>ავტომატიკური სიტყვის განსაგულისხმებისთვის (AST) დასასრულისხმებისთვის დასასრულისხმებისთვის მოდელები, რომლებიც ავტომატიკური სიტყვის განსაგულისხმებით (ASR), შემდეგ მაქინის განსაგულისხმე მნიშვნელოვანი მიზეზი იყო, რომ არსებობს AST კოპორაა პატარა, მასტივი მონაცემები არსებობს ორივე ASR და MT სუფსისტემებისთვის. ამ სამუშაოში, რამდენიმე მონაცემების აგგენტაცია და AST-ის წინასწორება გავაკეთებთ, ყველაფერი იგივე მონაცემების შესაბამისად. მარტივი მონაცემების აზექტირება, რომელიც ASR ტრანსკრიპტის ტრანსკრიპტის გადატანა უფრო ეფექტიური ინგლისურ- ფრანგური აზექტირებული LibriSpeech მონაცემების შესახებ, რომელიც 8.2-დან 1.4 BLEU-დან გამოსახულებული გან იგივე დასრულებული დასრულებული დასრულებული დასრულებული დასრულება ინგლისური-პომინური მონაცემების მონაცემების დასრულება 6,7-3,7 BLEU-დან. ამ შედეგების დამატებით, ჩვენ გვეყვანეთ პრაქტიკური რეკომენდეციების შესახებ აზემონტიკაციის და წარმოდგენის შესახებ. საბოლოოდ, ჩვენ გავაკეთებთ სამუშაო განსხვავებას 0,01 BLEU-ში, რომელიც განსხვავებულია ტრანფორმეტრის მიერ აქტიქტურაცია.</abstract_ka>
      <abstract_lt>Automatiniam kalbos vertimui (AST) taikomi kaskadiniai modeliai, kurie transkribuojami automatiniu kalbos atpažinimu (ASR), o vėliau transkribuojami mašininiu vertimu (MT). Pagrindinė veikimo spragos priežastis yra ta, kad nors esami AST korporai yra maži, esami masiniai ASR ir MT posistemių duomenų rinkiniai. Šiame darbe vertiname keletą AST duomenų didinimo ir išankstinio mokymo metodų, palygindami visus tuos pačius duomenų rinkinius. Paprastas duomenų didinimas vertant ASR transkriptas įrodo, kad labiausiai veiksmingas anglų ir prancūzų tarpusavyje padidinto LibriSpeech duomenų rinkinio atžvilgiu, panaikinant veiklos spragą nuo 8,2 iki 1,4 BLEU, palyginti su labai stipria kaskada, kuri galėtų tiesiogiai panaudoti kopijuotus ASR ir MT duomenis. Taikant tą patį metodą nuo pabaigos prie pabaigos ir tiksliai koreguojant, anglų ir Rumunijos MUST-C duomenų rinkinio spraga užbaigiama nuo 6,7 iki 3,7 BLEU. Be šių rezultatų, pateikiame praktines rekomendacijas dėl didinimo ir išankstinio mokymo metodų. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</abstract_lt>
      <abstract_ms>Untuk terjemahan ucapan automatik (AST), pendekatan akhir-akhir dilakukan oleh model kaskad yang ditranskrip dengan pengenalan ucapan automatik (ASR), kemudian ditranslasi dengan terjemahan mesin (MT). Sebab utama bagi ruang prestasi ialah, walaupun korpra AST yang wujud adalah kecil, set data besar wujud untuk kedua-dua subsistem ASR dan MT. Dalam kerja ini, kita menilai beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR membuktikan yang paling berkesan pada set data LibriSpeech bertambah bahasa Inggeris-Perancis, menutup ruang prestasi dari 8.2 hingga 1.4 BLEU, dibandingkan dengan kaskad yang sangat kuat yang boleh menggunakan data ASR dan MT yang berkumpul secara langsung. Pendekatan hujung-hujung yang sama ditambah penyesuaian menutup ruang pada set data MuST-C Inggeris-Romania dari 6.7 ke 3.7 BLEU. Selain daripada hasil ini, kami memperkenalkan rekomansi praktik untuk peningkatan dan pendekatan pretraining. Akhirnya, kita menurunkan jarak prestasi kepada 0.01 BLEU kita- menjadi arkitektur berasaskan Transformer.</abstract_ms>
      <abstract_mk>За автоматски превод на говор (AST), пристапите од крај до крај се надминуваат од каскадирани модели кои се препишуваат со автоматско препознавање на говорот (ASR), потоа транс- доцна со машински превод (MT). Големата причина за разликата во резултатите е дека, иако постојните АСТ корпора се мали, постојат масовни податоци за подсистемите АСР и МТ. Во оваа работа, проценуваме неколку податоци за зголемување и претренирање на пристапите за АСТ, споредувајќи ги сите на истите податоци. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  Истиот пристап од крај до крај плус фино прилагодување ја затвора празнината на англиско-романското множество податоци МУСТ-Ц од 6,7 на 3,7 БЛЕУ. Покрај овие резултати, претставуваме практични препораки за зголемување и претренирање пристапи. Конечно, ја намалуваме празнината во резултатите на 0,01 БЛЕУ со трансформска архитектура.</abstract_mk>
      <abstract_ml>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  പ്രകടനത്തിന്റെ പ്രധാന കാരണം, നിലവിലുള്ള ആസ്റ്റ് കോര്‍പ്പോര കൊണ്ട് ചെറുതായിരിക്കുമ്പോള്‍, ആസാരിന്റെയും എംടി ഉപസിസ് ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ പല ഡേറ്റാ കൂട്ടുന്നതിനെയും ആസ്റ്റിന്റെ അടുത്തുനിന്നും പ്രതീക്ഷിക്കുന്നതിനെയും പരിഗ ASR ട്രാന്‍സ്ക്രിപ്റ്റുകള്‍ പരിശോധിപ്പിക്കുന്നതിനാല്‍ എളുപ്പമുള്ള ഡേറ്റാ കൂട്ടിച്ചേര്‍ക്കുന്നതിനാല്‍ ഇംഗ്ലീഷ്- ഫ്രെഞ്ച് കൂട്ടിച്ചേര്‍ത്ത ലിബ്രിസ്പെച്ച് ഡാറ അതേ അവസാനത്തിന്റെ അടുത്തേക്കുള്ള വഴിക്കുറിച്ചും സുന്ദരിക്കുന്നതും ഇംഗ്ലീഷ്-റോമാനിയന്‍ മുസ്റ്റ്-സി ഡാറ്റാസറ്റെറ്റിന ഈ ഫലങ്ങളെക്കൂടാതെ, നമ്മള്‍ കൂടുതല്‍ പ്രാകൃതിക വീണ്ടും മാറ്റുന്നതിനും വേണ്ടിയാണ്. അവസാനം, നമ്മള്‍ പ്രകടന വ്യത്യാസം 0.01 ബില്യൂ വരെ കുറവ് വരുത്തുന്നു. ട്രാന്‍സ്ഫോര്‍മാര്‍ അടിസ്ഥാനമായ ഒരു ആര്‍ക്കിട്</abstract_ml>
      <abstract_mt>Għal traduzzjoni awtomatika tad-diskors (AST), l-approċċi minn tarf sa tarf jitwettqu minn mudelli kaskati li jittraskrivu b’rikonoxximent awtomatiku tad-diskors (ASR), imbagħad jittraskrivu b’traduzzjoni bil-magna (MT). Kawża ewlenija tad-diskrepanza fil-prestazzjoni hija li, filwaqt li l-korpi AST eżistenti huma żgħar, jeżistu settijiet ta’ dejta massivi kemm għas-sottosistemi ASR kif ukoll MT. F’dan ix-xogħol, aħna jevalwaw diversi approċċi ta’ żieda fid-dejta u ta’ taħriġ minn qabel għall-AST, billi nqabblu kollha fuq l-istess settijiet ta’ dejta. Żieda sempliċi fid-dejta bit-traduzzjoni tat-traskrizzjonijiet ASR hija l-aktar effettiva fuq is-sett tad-dejta LibriSpeech miżjud bl-Ingliż-Franċiż, li jagħlaq id-distakk fil-prestazzjoni minn 8.2 għal 1.4 BLEU, meta mqabbel ma’ kaskata qawwija ħafna li tista’ tuża direttament dejta kopja ASR u MT. L-istess approċċ minn tarf għal tarf flimkien ma’ aġġustament fin jagħlaq id-distakk fis-sett tad-dejta MuST-C Ingliż-Rumen minn 6.7 sa 3.7 BLEU. Minbarra dawn ir-riżultati, qed nippreżentaw rakkomandazzjonijiet prattiċi għal approċċi ta’ żieda u taħriġ minn qabel. Fl-a ħħar nett, naqsu d-distakk fil-prestazzjoni għal 0.01 BLEU billi nibnu arkitettura bbażata fuq it-Transformer.</abstract_mt>
      <abstract_kk>Автоматты сөздерді аудару (AST) үшін аяқтау- аяқтау керектері автоматты сөздерді анықтау (ASR) мен аудару үлгілерімен аудару үлгілері (MT) жазылады. АҚШ корпорасы кішкентай болғанда, ASR және MT субжүйелер үшін үлкен деректер қорлары бар. Бұл жұмыс ішінде бірнеше деректер көптегендіруді және AST үшін келесі жағдайларды салыстырып, барлығын бір деректер жиындарына салыстырып бағалаймыз. ASR транскрипттерді аударып қарапайым деректерді көбейту үшін ағылшын- французша ағылшын- французша көбейтілген LibriSpeech деректер жиынында ең ең эффективні көрсетеді, 8. 2- 1. 4 BLEU- ден жұмыс аралығын жабу үшін, көп ASR мен MT дер Бірақ соңындағы жағдайды бірнеше баптау жағдайды ағылшын-руман МАСТ-С деректер жиынының 6,7-3,7 BLEU бойынша жабылады. Бұл нәтижелердің қосымша, көптегендіру және өзгерту арқылы практикалық қайта командаларды таңдаймыз. Соңғы сәтте, біз жылдамдығын 0,01 BLEU-ге қысқартамыз. Трансферлердің архитектурасы.</abstract_kk>
      <abstract_it>Per la traduzione vocale automatica (AST), gli approcci end-to-end sono superati da modelli a cascata che trascrivono con riconoscimento vocale automatico (ASR), quindi trans-late con traduzione automatica (MT). Una delle principali cause del gap di performance è che, mentre i corpi AST esistenti sono piccoli, esistono enormi set di dati sia per i sottosistemi ASR che MT. In questo lavoro, valutiamo diversi approcci di aumento dei dati e pre-formazione per AST, confrontando tutti sugli stessi set di dati. Il semplice aumento dei dati attraverso la traduzione di trascrizioni ASR si rivela più efficace sul set di dati LibriSpeech aumentato inglese-francese, chiudendo il gap di prestazioni da 8.2 a 1.4 BLEU, rispetto a una cascata molto forte che potrebbe utilizzare direttamente abbondanti dati ASR e MT. Lo stesso approccio end-to-end e la messa a punto di fine-tuning colmano il gap sul set di dati MuST-C inglese-rumeno da 6.7 a 3.7 BLEU. Oltre a questi risultati, presentiamo raccomandazioni pratiche per gli approcci di aumento e pre-formazione. Infine, riduciamo il gap di performance a 0,01 BLEU con un'architettura basata su Transformer.</abstract_it>
      <abstract_mn>Автоматик ярианы хөрөнгө оруулалт (AST), төгсгөл-төгсгөл арга барилгууд автоматжуулан ярианы хүлээн зөвшөөрөх (ASR) загвараар автоматжуулан хэлэлцдэг загварууд, дараа нь машин хөрөнгө оруулалт ( АСТ корпора нь жижиг, АСР болон MT субсистем хоёулаа маш том өгөгдлийн сангууд байдаг. Энэ ажил дээр бид олон өгөгдлийн нэмэгдүүлэлт болон АСТ-ийн арга баримтуудыг ижил өгөгдлийн санд харьцуулахад үнэлдэг. ASR транскриптүүдийг орчуулахад энгийн өгөгдлийн нэмэгдүүлэлт нь Англи-Францын нэмэгдсэн LibriSpeech өгөгдлийн санд хамгийн үр дүнтэй харагдаж байна. 8.2-аас 1.4 BLEU-ээс үр дүнтэй ялгааг хадгалж байна. Яг ижил төгсгөл, төгсгөл ойлголт нэмэх нь сайхан зохицуулах нь Англи-Румын МАСТ-С өгөгдлийн сангийн ялгааг 6.7-ээс 3.7 БЛЮС руу холбоотой. Эдгээр үр дүнд нэмэхэд бид дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахи Эцэст нь бид үйл ажиллагааны ялгааг 0.01 БЛУС-д багасгаж байна. Трансформатор суурилсан архитектур.</abstract_mn>
      <abstract_no>For automatisk taleomsetjing (AST) blir tilnærmingar til slutten utført av kaskaderte modeller som transkriver med automatisk tale- gjenkjenning (ASR), og så trans late med maskinsomsetjing (MT). Eit viktig grunn av utgangspunktet er at, mens eksisterande AST-korpora er lite, finst massiv datasett for både ASR og MT-undersystema. I dette arbeidet evaluerer vi fleire data-augmentasjon og trekking av tilnærmingar for AST ved å sammenligne alle på samme datasett. Ein enkel data-økning ved å oversette ASR-transkript viser det mest effektivt på den anglesk-fransk augmenterte LibriSpeech-dataset, og lukkar utgangspunktet frå 8,2 til 1,4 BLEU, sammenlignet med ein veldig sterk kaskade som kunne direkte bruka kopøre ASR-og MT-data. Dette same ende-til-slutt tilnærming pluss fin-tuning lukkar mellomrommet på datasettet engelsk-rumensk MuST-C frå 6,7 til 3,7 BLEU. I tillegg til desse resultatene presenterer vi praktiske rekommendringar for augmentasjon og trekking av tilnærmingar. I slutten reduserer vi utgangspunktet til 0,01 BLEU som gjer ein transformeringsarkitektur.</abstract_no>
      <abstract_pl>W przypadku automatycznego tłumaczenia mowy (AST) podejścia końcowe są przewyższane przez modele kaskadowe, które transkrybują z automatycznym rozpoznawaniem mowy (ASR), a następnie transkrybują z tłumaczeniem maszynowym (MT). Główną przyczyną luki w wydajności jest to, że podczas gdy istniejące korpusy AST są małe, masowe zbiory danych istnieją zarówno dla podsystemów ASR, jak i MT. W niniejszej pracy oceniamy kilka metod zwiększania i wstępnego treningu danych dla AST, porównując wszystkie na tych samych zbiorach danych. Proste powiększanie danych poprzez tłumaczenie transkrypcji ASR okazuje się najbardziej skuteczne na angielsko-francuskim rozszerzonym zbiorze danych LibriSpeech, zmniejszając lukę wydajności od 8.2 do 1.4 BLEU, w porównaniu z bardzo silną kaskadą, która może bezpośrednio wykorzystać obfite dane ASR i MT. To samo kompleksowe podejście oraz precyzyjne dostosowanie zamyka lukę w angielsko-rumuńskim zbiorze danych MuST-C od 6.7 do 3.7 BLEU. Oprócz tych wyników przedstawiamy praktyczne zalecenia dotyczące podejść do rozszerzenia i wstępnego treningu. Wreszcie zmniejszamy lukę wydajnościową do 0.01 BLEU z architekturą opartą na Transformerze.</abstract_pl>
      <abstract_so>Tilmaamaha hadalka oo automatic ah (AST), waxaa lagu sameeyaa qaabab dhammaadka ugu dambaysta ah oo lagu qorayo qoraalka ku qoran aqoonsashada hadalka (ASR), dabadeedna trans-late with translation of machine (MT). Sababta ugu weyn ee burburka sameynta waa in marka shirkadda AST ay jiraan ay yaryihiin, waxaa jira sawirada macluumaadka badan ee ASR iyo MT hoosdhigyada. Markaas waxan, waxaynu qiimeynaynaa kordhiska macluumaadka iyo ka hor-soocidda AST, si aan u barbardhigno dhammaan sawirada isku mid ah. Soo saaridda macluumaadka fudud ee turjumidda qoraalka ASR waxay cadaynaysaa kuwa ugu shaqeeya ee ku saabsan macluumaadka afriiska-Faraansiinta oo afgeysay LibriSpeech, wuxuuna dabooli karaa gafafka performance ka baxay 8.2-1.4 BLEU, compared to a cascade aad u adag oo toos u isticmaali kara macluumaadka ASR iyo MT. Dhaqdooyinka ugu dambeeya isla dhamaadka iyo qurxinta qurxinta ayaa daboolaya burburka warqada ingiriisiga-Romanian MuST-C ee laga soo bilaabo 6.7-3.7 BLEU. Arrimahaan ka sokow, waxan soo bandhignaynaa dib-u-beddelasho ah oo la kordhiyo iyo soo-beddelasho. Ugu dambaysta, waxaynu hoos u dhignaa booska sameynta ilaa 0.01 BLEU - dhismaha baabuurta.</abstract_so>
      <abstract_ro>Pentru traducerea automată a vorbirii (AST), abordările end-to-end sunt depășite de modele în cascadă care transcriu cu recunoașterea automată a vorbirii (ASR), apoi cu traducerea automată (MT). O cauză majoră a decalajului de performanță este că, în timp ce corpurile AST existente sunt mici, există seturi de date masive atât pentru subsistemele ASR, cât și MT. În această lucrare, evaluăm mai multe abordări de mărire a datelor și pre-formare pentru AST, prin compararea tuturor pe aceleași seturi de date. Amplificarea simplă a datelor prin traducerea transcrierilor ASR se dovedește cea mai eficientă pe setul de date LibriSpeech augmentat englez-francez, reducând decalajul de performanță de la 8.2 la 1.4 BLEU, comparativ cu o cascadă foarte puternică care ar putea utiliza direct numeroase date ASR și MT. Aceeași abordare end-to-end plus ajustarea fină elimină decalajul în setul de date MuST-C englez-român de la 6.7 la 3.7 BLEU. Pe lângă aceste rezultate, prezentăm recomandări practice pentru abordările de augmentare și pre-formare. În cele din urmă, reducem decalajul de performanță până la 0,01 BLEU pentru o arhitectură bazată pe Transformer.</abstract_ro>
      <abstract_si>ස්වයංක්‍රිය කතාවක් අවවාදය (AST) සඳහා, end-to-end අවවාදය නිසා ස්වයංක්‍රිය කතාවක් අවවාදය (ASR) සඳහා ස්වයංක්‍රිය කතාවක් අවවාදය (MT) ස ප්‍රශ්නයක් ප්‍රධානයක් තියෙන්නේ AST කොර්පෝරා පුංචි වෙලාවක්, ASR සහ MT සබස්සිස්ටම් දෙන්නම් ගොඩක් දත්ත සැට්  මේ වැඩේ අපි දත්ත විශාලනය සහ AST වෙනුවෙන් ප්‍රතික්‍රීයාවක් විශාලනය කරනවා, එකම දත්ත සේට් වල හැම දේවල්ම සමානු Name එකම අවසානයෙන් අවසානයෙන් අවසානයෙන් හොඳ අවසානය වෙනුවෙන් ඉංග්‍රීසිය-රෝමානියාන් මුස්ට් සී දත්ත සැටුම 6.7 ඉඳල මේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ර අන්තිමේදි, අපි ප්‍රාර්ථනාවක් අවස්ථාවක් 0.01 බ්ලූස් වලට අඩු කරනවා. අපිට ප්‍රාර්ථනාවක් අධාරිත වින</abstract_si>
      <abstract_sr>Za automatski prevod govora (AST), pristupi na kraj do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine izvedbe je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najefikasniji na kompetu podataka o povećanju biblioteke na engleskom francuskom i francuskom jeziku, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa veoma jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup do kraja plus fino podešavanje zatvara prazninu na podacima engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Pored ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koja nas je osnovala na transformeri arhitektura.</abstract_sr>
      <abstract_ta>@ info செயல்பாட்டு வேறுபாட்டின் மிகப்பெரிய காரணம் என்னவென்றால், இருக்கும் AST நிறுவனத்தில் இருக்கும் போது ASR மற்றும் MT உப அமைப்ப இந்த வேலையில், நாம் பல தரவு அதிகரிப்பு மற்றும் AST க்கான முன்னேற்றம் செய்ய வேண்டும் மற்றும் அதே தரவு அமைப்புகளை ஒப்பி ASR எழுத்துருக்களை மொழிமாற்றி சுலபமான தகவல் மேலும் ஆங்கிலம்- பிரெஞ்சு மேம்படுத்தப்பட்ட லிப்ரிஸ்பேச் தகவல் அமைப்பில் மிகவும் விளைவாக தெரியும், செயல்பாட்டு வெளியேற்றம் 8.  அதே முடிவில் இருந்து முடிவு நெருக்கம் கூட்டல் நன்றாக மூடுகிறது ஆங்கிலத்தில் இருந்து ரோமானியன் முஸ்ட்- C தரவுத்தளத்தில் இருந இந்த முடிவுகளுக்கும் தவிர, நாம் மேம்படுத்தல் மற்றும் முன்னோக்கம் செய்ய முடிவுகளை கூட்டுதல் மற்றும் பெரும இறுதியில், நாம் செயல்பாட்டு இடைவெளியை 0.01 பிலியு எங்களுக்கு குறைக்கிறோம் - மாற்று அடிப்படையில் உள்ள ஒரு கட்டு</abstract_ta>
      <abstract_ur>اپنی بات کی ترجمہ (AST) کے لئے آخر-to-end approaches are performed by cascaded models that transcribe with automatic speech recognition (ASR) and then trans late with machine translation (MT). عملکرد فاصلہ کی ایک بڑی دلیل یہ ہے کہ، حالانکہ موجود AST کورپورا چھوٹے ہیں، ASR اور MT سوسٹیموں کے لئے بڑی ڈاٹ سٹ موجود ہیں. اس کام میں ہم نے بہت سی ڈیٹا اضافہ اور آسٹی کے لئے پرٹرینٹ کی طریقے کا ارزش کیا ہے، سب ایک ڈیٹ سٹ پر مقایسہ کرکے۔ ASR ٹرنسکرپٹوں کو ترجمہ کرنے کے ذریعہ ساده ڈاٹ اضافہ کرتا ہے انگلیسی-فرانسوی اضافہ کی لیبری اسپیچ ڈاٹ سٹ پر بہت اثر دیتا ہے، جو 8.2 سے 1.4 بلیوس سے کامپیوتر فاصلہ بند کرتا ہے، ایک بہت مضبوط کاسڈ کے مقابلے میں جو سیدھی آس آر اور ٹی ڈا اسی طرح انگلیسی-رومین ماسٹ-سی ڈاٹ سٹ کے اندر 6.7 سے 3.7 بلیوس کے لئے فاصلہ بند کرتا ہے۔ ان نتائج کے علاوہ، ہم اضافہ اور زیادتی کی طریقوں کے لئے قابل تدبیر کماندر پیش کرتے ہیں. آخر میں، ہم ایک تغییر پھیلانے والی معماری کو 0.01 BLEU تک کم کر رہے ہیں۔</abstract_ur>
      <abstract_sv>För automatisk talöversättning (AST) överträffas end-to-end-tillvägagångssätt av kaskadmodeller som transkriberar med automatisk taligenkänning (ASR) och sedan transkriberar med maskinöversättning (MT). En viktig orsak till prestandakravet är att även om befintliga AST-kroppar är små, finns det massiva datauppsättningar för både ASR- och MT-delsystemet. I detta arbete utvärderar vi flera dataförstärknings- och pretrainingmetoder för AST, genom att jämföra alla på samma datauppsättningar. Enkel dataökning genom att översätta ASR-transkript visar sig vara mest effektiv på den engelsk-franska förstärkta LibriSpeech-datauppsättningen, vilket minskar prestandakravet från 8,2 till 1,4 BLEU, jämfört med en mycket stark kaskad som direkt kunde utnyttja rikliga ASR- och MT-data. Samma heltäckande tillvägagångssätt plus finjustering minskar gapet i den engelsk-rumänska MuST-C-datauppsättningen från 6,7 till 3,7 BLEU. Utöver dessa resultat presenterar vi praktiska rekommendationer för förstärkning och pre-training metoder. Slutligen minskar vi prestandabalansen till 0,01 BLEU genom att använda en Transformer-baserad arkitektur.</abstract_sv>
      <abstract_uz>@ info: whatsthis Va bajarish gapirishining asosiy sababi, mavjud ASAT kompaniya juda kichkina maʼlumot tizimi ASR va MT tizimlari uchun juda katta maʼlumot tizimi mavjud. Bu ishda biz bir necha maʼlumot qoʻshishni qiymatmiz va ASAT uchun yozish usullarini qiymatimiz, hamma bir necha maʼlumot sahifalarni bir necha ko'paytuvchimiz. Name Bu bir oxiriga qo'yish usuli va yaxshi suhbat usuli ingliz-Rumincha MuST-C maʼlumotlar tarkibini 6.7 dan 3.7 BLEU bilan o'zgartiradi. Bu natijalardan boshqa esa, biz tashkilotni oshirish va taqdim qilish usullarini bajaramiz. Endi biz tashkilotni 0.01 BLEU'ga kamaytamiz - Transformer asosiy arxituvchi.</abstract_uz>
      <abstract_vi>Đối với dịch ngôn ngữ tự động (AST), các phương pháp cuối-tới-cuối được thực hiện bởi các mô-đun ngẫu nhiên chuyển qua bằng nhận dạng ngôn ngữ tự động (ASR), sau đó chuyển mới bằng dịch cỗ máy (MTV). Một nguyên nhân quan trọng của việc đó là một trong số hệ thống ASR và MTV. Trong công việc này, chúng tôi đánh giá nhiều phương pháp gia tăng dữ liệu và nâng cấp cho AST bằng cách so sánh tất cả các bộ dữ liệu giống nhau. Đơn giản gia tăng dữ liệu bằng cách dịch chuyển các ghi chép ASR cho thấy hiệu quả nhất với hệ thống dữ liệu LyriSpeech cường Anh-Pháp, thu hồi khoảng cách hiệu suất từ 8.2 đến 1.4 bleU, so với một thác rất mạnh có thể trực tiếp sử dụng dữ liệu ASR và MTV. C ùng một phương pháp cuối cùng cộng với độ chỉnh sửa sửa sửa sửa sửa chữa lỗ hổng trong bộ nhớ dữ liệu giọng Tây Ban Nha MuST-C từ 6.7 tới 3.7 BleU. Ngoài những kết quả này, chúng tôi còn đưa ra các dự án thực tế cho việc tăng trưởng và nâng cấp phương pháp. Cuối cùng, chúng ta giảm khoảng trống hiệu suất đến 0.13 LEU- đang tạo ra một kiến trúc biến hình.</abstract_vi>
      <abstract_da>For automatisk taleoversættelse (AST) udføres end-to-end-tilgange af kaskademodeller, der transkriber med automatisk talegenkendelse (ASR) og derefter transskriber med maskinoversættelse (MT). En væsentlig årsag til performance gap er, at mens eksisterende AST corpora er små, eksisterer massive datasæt for både ASR og MT delsystemer. I dette arbejde evaluerer vi flere data augmentation og pre-training metoder for AST ved at sammenligne alle på de samme datasæt. Enkel dataudvidelse ved oversættelse af ASR-transskriptioner viser sig at være mest effektiv på det engelsk-franske augmented LibriSpeech datasæt, hvilket lukker præstationshullet fra 8,2 til 1,4 BLEU sammenlignet med en meget stærk kaskade, der direkte kunne udnytte rigelige ASR- og MT-data. Den samme end-to-end-tilgang plus finjustering lukker hullet i det engelsk-rumænske MuST-C datasæt fra 6,7 til 3,7 BLEU. Ud over disse resultater præsenterer vi praktiske anbefalinger til forstærkning og forudtræning tilgange. Endelig mindsker vi præstationskløften til 0,01 BLEU ved at bruge en Transformer-baseret arkitektur.</abstract_da>
      <abstract_bg>При автоматичен речен превод (АСТ) подходите от край до край се превъзхождат от каскадни модели, които транскрибират с автоматично разпознаване на речта (АСР), след което транслатират с машинен превод (МТ). Основна причина за разликата в ефективността е, че докато съществуващите корпуси на AST са малки, съществуват масивни набори от данни както за подсистемите ASR, така и MT. В тази работа ние оценяваме няколко подхода за увеличаване и предтрениране на данни за АСТ, като сравняваме всички на едни и същи набори от данни. Опростеното увеличаване на данните чрез превод на транскрипции се оказва най-ефективно върху английско-френския разширен набор от данни, затваряйки разликата в ефективността от 8.2 до 1.4 в сравнение с много силна каскада, която може директно да използва изобилни данни. Същият подход от край до край плюс фина настройка затваря разликата в английско-румънския набор от данни от 6.7 до 3.7 Блеу. В допълнение към тези резултати представяме практически препоръки за подходи за разширение и предобучение. И накрая, намаляваме разликата в производителността до 0.01 чрез изграждане на базирана на трансформатор архитектура.</abstract_bg>
      <abstract_id>Untuk terjemahan pidato otomatis (AST), pendekatan akhir-akhir dilakukan oleh model kaskade yang transkrip dengan pengenal pidato otomatis (ASR), kemudian trans-terlambat dengan terjemahan mesin (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems.  Dalam pekerjaan ini, kami mengevaluasi beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR terbukti paling efektif pada set data LibriSpeech bertambah Inggris-Perancis, menutup ruang prestasi dari 8.2 ke 1.4 BLEU, dibandingkan dengan kaskade yang sangat kuat yang dapat langsung menggunakan data ASR dan MT yang saling berkuasa. Pendekatan akhir-akhir yang sama ditambah penyesuaian menutup ruang di dataset MuST-C Inggris-Romania dari 6.7 ke 3.7 BLEU. Selain hasil-hasil ini, kami mempersembahkan rekomandasi praktis untuk peningkatan dan pendekatan pretraining. Akhirnya, kita mengurangi ruang prestasi ke 0,01 BLEU kita- menjadi arsitektur berasaskan Transformer.</abstract_id>
      <abstract_de>Bei der automatischen Sprachübersetzung (AST) werden End-to-End-Ansätze durch kaskadierte Modelle übertroffen, die mit automatischer Spracherkennung (ASR) transkribieren und dann mit maschineller Übersetzung (MT) übersetzen. Eine Hauptursache für die Leistungslücke ist, dass bestehende AST-Korpora zwar klein sind, aber massive Datensätze sowohl für das ASR- als auch für das MT-Subsystem existieren. In dieser Arbeit evaluieren wir verschiedene Ansätze zur Datenaugmentation und -pretraining für AST, indem wir alle auf denselben Datensätzen vergleichen. Die einfache Datenauswertung durch die Übersetzung von ASR-Transkripten erweist sich am effektivsten auf dem englisch-französischen erweiterten LibriSpeech-Datensatz und schließt die Leistungslücke von 8.2 bis 1.4 BLEU im Vergleich zu einer sehr starken Kaskade, die umfangreiche ASR- und MT-Daten direkt nutzen könnte. Der gleiche End-to-End-Ansatz und die Feinabstimmung schließen die Lücke im englisch-rumänischen MuST-C-Datensatz von 6.7 bis 3.7 BLEU. Zusätzlich zu diesen Ergebnissen präsentieren wir praktische Empfehlungen für Augmentations- und Vortrainingsansätze. Schließlich verringern wir die Leistungslücke auf 0.01 BLEU mit einer Transformer-basierten Architektur.</abstract_de>
      <abstract_hr>Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadirani modeli koji prepisuju s automatskim priznanjem govora (ASR), a zatim transkasnim s prevodom stroja (MT). Veliki uzrok praznine učinkovitosti je da, iako postojeća AST korpora su mala, masivna podaci postoje za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkripte ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi s vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske podatke ASR i MT-a. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu podataka engleskog-rumunskog MuST-C iz 6,7 do 3,7 BLEU-a. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformeri arhitektura.</abstract_hr>
      <abstract_fa>برای ترجمه سخنرانی خودکار (AST) روش‌های پایان به پایان از مدل‌های کاسکیدی که با شناسایی سخنرانی خودکار (ASR) ترجمه می‌کنند، سپس با ترجمه‌های ماشین (MT) ترجمه می‌کنند. یک دلیل بزرگی از فاصله عملکرد این است که در حالی که شرکت AST موجود کوچک هستند، مجموعه‌های داده‌های بزرگ برای سیستم‌های ASR و MT وجود دارد. در این کار، ما چندین افزایش داده ها را ارزیابی می کنیم و به طریق مقایسه کردن همه روی مجموعه‌های داده‌ها و روش‌های پیش‌گیری برای AST، با مقایسه کردن همه روی مجموعه‌های یکسان داده‌ها. افزایش داده‌های ساده با ترجمه ترجمه‌های ASR بر مجموعه داده‌های LibriSpeech افزایش داده‌های انگلیسی-فرانسوی ثابت می‌کند، و فاصله‌های عملکرد از 8.2 تا 1.4 BLEU را بسته می‌کند، در مقایسه با یک کاسکید بسیار قوی که می‌تواند مستقیماً از داده‌های ASR و MT استفاده کن همان دستور پایان و پایان و تنظیم نیکویی در مجموعه داده های انگلیسی-رومانی MuST-C از 6.7 تا 3.7 BLEU بسته است. در addition to these results, we present practical rec-commands for increased and pretraining approaches. بالاخره، ما فاصله عملکرد را به 0.01 BLEU کاهش می‌دهیم که یک معماری بنیاد تغییر دهنده است.</abstract_fa>
      <abstract_sw>Kwa kutafsiri hotuba ya kujitegemea (AST), mbinu za mwisho za mwisho zinaendeshwa na miundo mbinu yenye mabadiliko yanayoandikwa kwa kutambua hotuba ya kujitegemea (ASR), kisha kwa muda mrefu kwa kutafsiri mashine (MT). Sababu kubwa ya mchanganyiko wa utendaji ni kwamba, wakati kampuni ya AST iko ndogo, kuna seti kubwa za data kwa ajili ya mifumo ya ASR na MT. Katika kazi hii, tunatathmini kuongeza takwimu kadhaa na kutengeneza matukio ya AST, kwa kulinganisha vyote katika seti hizo za data. Kuongezeka kwa takwimu rahisi kwa kutafsiri maandishi ya ASR yanaonyesha kuwa na ufanisi zaidi kwenye seti ya data za LibriSpeech zilizoongezewa kwa Kiingereza-Kifaransa, kufunga gaidi ya utendaji kutoka 8.2 hadi 1.4 BLEU, ukilinganisha na kaskadi yenye nguvu sana inayoweza kutumia takwimu za ASR na MT. Mtakatifu huo mwishoni wa mwisho pamoja na ujumbe mzuri unafungua gaidi kuhusu takwimu za Kiingereza-Romanian MuST-C kutoka 6.7 hadi 3.7 BLEU. Zaidi ya matokeo haya, tunatoa mabadiliko ya hali halisi kwa ajili ya kuongeza na kutengeneza mbinu za kutengeneza. Mwisho, tunapunguza kiwango cha utendaji cha BLEU hadi 0.01 BLEU – kutufanya ujenzi wa asili ya Transformer.</abstract_sw>
      <abstract_af>Vir outomatiese woorde vertaling (AST), die einde- na- einde toegang word uitgevoer deur kaskadeerde modele wat met outomatiese woorde herken (ASR), dan trans- laat met masjien vertaling (MT). 'n Hoogte oorsaak van die prestasie gap is dat, terwyl bestaande AST korpora klein is, massiewe datastelle bestaan vir beide die ASR en MT subsystemes. In hierdie werk, ons evalueer veelvuldige data vergroot en voorskyning toegang vir AST deur almal op dieselfde datastelle te vergelyk. Eenvoudige data vergroot deur die vertaling van ASR-transkripte te bevestig mees effektief op die Engelse-Franse vergroot LibriSpeech-datastel, toe die prestasie afstand van 8.2 tot 1.4 BLEU toesluit, vergelyk met 'n baie sterk kaskade wat direk kan gebruik kopiese ASR en MT-data. Die selfde einde-tot-einde toegang plus fin-tuning sluit die afstand op die Engelse-Romaniese MuST-C datastel van 6.7 tot 3.7 BLEU. In addition to these results, we present practical rec- commands for augmentation and pretraining approaches. Eindelik, ons verklein die prestasie afstand tot 0,01 BLES ons - om 'n Transformer-gebaseerde arkitektuur te verminder.</abstract_af>
      <abstract_tr>Otomatik çykyş terjime üçin Görniş gapysynyň esasy sebäbi bolsa, bar AST korporasy kiçi bolsa hem ASR we MT subsystemleriň üçin gaty maglumat setirleri bar. Bu işde, biz birnäçe maglumat üýtgetmesini we AST üçin golaýlaryny deňlendirip, hemmesini birnäçe veri setlerde karşılaştyrarak deňlendirip duruyoruz. ASR terjime edip basit maglumatlar ýetişdirilýär, iňlisçe-fransuzça gelişmiş LibriSpeech veri setinde iň täsirli ýagdaýda, performansyň gapysyny 8.2 we 1.4 BLEU-dan ýapýarylýar, kopy ASR we MT maglumatyny ullanabilen örän güýçli bir kaskada we deňleýär. Şol ýagdaý soňunda ýakynlaşdyrmak üçin iňlisçe-rumynça MuST-C veri sahypalarynyň 6.7 we 3.7 BLEU-dan çykarýar. Bu sonuçlar da arttırmak ve önlenme metodları için pratik bir tekrarlama komutanları sunuyoruz. Sonunda, performans boşluklarını 0.01 BLEU'a düşürüp, Transformer tabanlı bir arhitektura çevirdik.</abstract_tr>
      <abstract_nl>Voor automatische spraakvertaling (AST) worden end-to-end benaderingen overtroffen door cascademodellen die transcriberen met automatische spraakherkenning (ASR) en vervolgens translate met machine translation (MT). Een belangrijke oorzaak van de prestatiekloof is dat, hoewel bestaande AST-corpora's klein zijn, enorme datasets bestaan voor zowel het ASR- als MT-subsysteem. In dit werk evalueren we verschillende data augmentatie en pretraining benaderingen voor AST, door ze allemaal op dezelfde datasets te vergelijken. Eenvoudige gegevensvergroting door ASR-transcripten te vertalen blijkt het meest effectief op de Engels-Franse augmented LibriSpeech dataset, waardoor de prestatiekloof van 8.2 tot 1.4 BLEU wordt dichten, vergeleken met een zeer sterke cascade die direct gebruik kan maken van overvloedige ASR- en MT-gegevens. Dezelfde end-to-end aanpak plus fine-tuning sluit de kloof op de Engels-Roemeense MuST-C dataset van 6.7 tot 3.7 BLEU. Naast deze resultaten presenteren we praktische aanbevelingen voor augmentatie en pretraining benaderingen. Tot slot verkleinen we de prestatiekloof tot 0.01 BLEU met een Transformer-gebaseerde architectuur.</abstract_nl>
      <abstract_bn>স্বয়ংক্রিয় ভাষণ অনুবাদের জন্য (AST) শেষ পর্যন্ত ক্যাস্কেডের মোডেল দ্বারা শেষ পর্যন্ত প্রদর্শন করা হয় যা স্বয়ংক্রিয় ভাষণ স্বীকৃতির সাথে লেখা লেখ প্রদর্শনের প্রধান কারণ হচ্ছে যে এসটি কোর্পোরা বিদ্যমান ছোট, এসআর আর এমটি সাবসিস্টেমের জন্য বিশাল ডাটাসেট রয়েছে। এই কাজে আমরা বেশ কয়েকটি তথ্য যোগাযোগ এবং আস্টের জন্য বৃষ্টিপাতের ক্ষেত্রেও মূল্যায়ন করি, একই তথ্যের সাথে তুলনা করে। Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  একই শেষ পর্যন্ত প্রতিক্রিয়া এবং সুন্দর টুনিং এর সাথে ইংরেজি-রোমানিয়ান মুস্টি-সি ডাটাসেট থেকে ৬. ৭ থেকে ৩. এই ফলাফল ছাড়াও আমরা বাড়তে পারি এবং বৃষ্টির প্রাকৃতিক পুনরাবৃত্তি উপস্থাপন করি। Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</abstract_bn>
      <abstract_ko>자동음성번역(AST)의 경우 종단 연결 모델보다 종단 연결 방법이 우수하며, 종단 연결 모델은 자동음성인식(ASR)으로 전송한 뒤 기계번역(MT)으로 번역한다.성능 차이의 주요 원인은 기존의AST 어료 라이브러리는 매우 작지만 ASR과 MT 서브시스템에 대량의 데이터 집합이 존재하기 때문이다.이 작업에서 우리는 같은 데이터 집합을 비교하여AST의 몇 가지 데이터 확장과 예비 훈련 방법을 평가했다.ASR 전사본 번역을 통한 간단한 데이터 확충은 영어-프랑스어 증강형 Libri Speech 데이터 세트에서 가장 효과적이며, ASR과 MT 데이터의 막대한 종속 연결을 직접 활용하기보다는 8.2BLEU에서 1.4BLEU로 성능 격차를 좁히는 것으로 나타났다.같은 끝에서 끝까지의 방법에 미세한 조정을 더해 영국-루마니아 MuST-C 데이터 세트의 6.7 BLEU에서 3.7 BLEU까지의 격차를 좁혔다.이러한 결과 외에 우리는 증강과 예훈련 방법의 실용적인 건의도 제기했다.마지막으로 우리는 변압기 기반 아키텍처를 사용하여 성능 격차를 0.01 BLEUus로 줄였습니다.</abstract_ko>
      <abstract_sq>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  Një shkak kryesor i daljes së performancës është se, ndërsa korprat ekzistuese AST janë të vogla, të dhënat masive ekzistojnë si për nënsistemet ASR ashtu edhe MT. Në këtë punë, ne vlerësojmë disa rritje të të dhënave dhe metoda përpara stërvitjes për AST, duke krahasuar të gjitha në të njëjtat grupe të të dhënave. Rritja e thjeshtë e të dhënave duke përkthyer transkriptet ASR tregohet më e efektshme në grupin e të dhënave LibriSpeech të rritur anglisht-francez, duke mbyllur dallimin e performancës nga 8.2 në 1.4 BLEU, krahasuar me një kaskade shumë të fortë që mund të përdorte drejtpërdrejt të dhënat kopjoze ASR dhe MT. E njëjta qasje nga fundi në fund plus rregullimi e hollësisë mbyll boshllëkun në grupin e të dhënave anglo-rumune MuST-C nga 6.7 në 3.7 BLEU. Përveç këtyre rezultateve, ne paraqesim rekomandime praktike për rritje dhe metoda paratrajnimi. Më në fund, ne e zvogëlojmë dallimin e performancës në 0.01 BLEU - duke bërë një arkitekturë me bazë në Transformer.</abstract_sq>
      <abstract_bs>Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine predstave je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu na dataset engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformatorskoj arhitekturi.</abstract_bs>
      <abstract_az>Avtomatik sözlər tercüməsi (AST) üçün, maşına tercüməsi (MT) ilə yazılan kaskadlı modellər tərəfindən istifadə edilir. Perfekt boşluğunun ən böyük səbəbi is ə, mevcut AST korporası kiçik olduğu halda, ASR və MT subsystemləri üçün çox böyük veri qurğuları var. Bu işdə, bir neçə məlumat artırmağı və AST üçün təklif metodlarını değerləşdiririk, bütün məlumat qurmaqlarını bir-birinə qarşılaşdırırıq. ASR transkriptlərini tercümə edərək basit məlumat artırması İngiliz-Fransızca yüksələn LibriSpeech veri qutusunda ən etkili göstərir, performans boşluğunu 8.2 ilə 1.4 BLEU ilə bağlayar, köpüsü ASR və MT veriləri istifadə edə bilən çox qüvvətli kascada ilə qarşılaşdırır. Aynı son-to-end approach artıq fin tuning İngiliz-Rumun MuST-C veri qutusu 6,7-3,7 BLEU-dən istifadə edir. Bu sonuçları da artırmaq və təmizləmək üçün praktik yenidən təkrar-təkrarları göstəririk. Sonunda, performans boşluğunu 0,01 BLEU-ə düşürürük - Transformer-based arhitektura.</abstract_az>
      <abstract_ca>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT).  A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems.  En aquest treball, evaluem diversos enfocaments d'augment de dades i de pré-capacitació per a AST, comparant-los tots en els mateixos conjunts de dades. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data.  El mateix enfocament de punta a punta, més ajustes, tanca la diferència en el conjunt de dades MuST-C anglo-rumun de 6,7 a 3,7 BLEU. A més d'aquests resultats, presentem recomanacions pràctiques per a l'augmentació i l'anticraining. Finalment, reduïm la diferència de rendiment a 0,01 BLEU, una arquitectura basada en Transformer.</abstract_ca>
      <abstract_cs>V případě automatického překladu řeči (AST) jsou koncové přístupy překonány kaskádovými modely, které přepisují s automatickým rozpoznáváním řeči (ASR) a poté překládají strojovým překladem (MT). Hlavní příčinou výkonnostní mezery je, že zatímco existující AST korpusy jsou malé, existují masivní datové sady jak pro subsystémy ASR, tak MT. V této práci vyhodnocujeme několik přístupů rozšíření a předškolení dat pro AST, porovnáním všech na stejných datových sadách. Jednoduchá rozšíření dat překladem ASR transkriptů se ukázalo jako nejúčinnější na anglicko-francouzském rozšířeném datovém souboru LibriSpeech, čímž uzavírá mezeru výkonu od 8.2 do 1.4 BLEU, ve srovnání s velmi silnou kaskádou, která by mohla přímo využít hojná ASR a MT data. Stejný end-to-end přístup a jemné ladění překlenují mezeru v anglicko-rumunské datové sadě MuST-C od 6.7 do 3.7 BLEU. Kromě těchto výsledků představujeme praktické doporučení pro augmentační a předškolení přístupů. Konečně snižujeme výkonnostní mezeru na 0.01 BLEU s architekturou založenou na Transformeru.</abstract_cs>
      <abstract_fi>Automaattisessa puheen kääntämisessä (AST) end-to-end-lähestymiset suoritetaan kaskadimalleilla, jotka transkriбираvat automaattisella puheentunnistuksella (ASR) ja sitten konekäännöksellä (MT). Suuri syy suorituskykyvajeeseen on se, että vaikka olemassa olevat AST-korpuset ovat pieniä, sekä ASR- että MT-osajärjestelmissä on massiivisia tietokokonaisuuksia. Tässä työssä arvioimme useita AST:n tiedonlisäys- ja esikoulutusmenetelmiä vertaamalla kaikkia samoja aineistoja. Yksinkertainen datan lisääminen kääntämällä ASR-transkriptit osoittautuu tehokkaimmaksi englannin-ranskan laajennetussa LibriSpeech-aineistossa, sulkemalla suorituskykykuilun 8.2:sta 1.4 BLEU:hun verrattuna erittäin vahvaan kaskadiin, joka voisi suoraan hyödyntää runsaasti ASR- ja MT-dataa. Sama kokonaisvaltainen lähestymistapa ja hienosäätö sulkevat englannin ja romanian MuST-C-aineiston kuilun 6,7–3,7 BLEU. Näiden tulosten lisäksi esittelemme käytännön suosituksia lisä- ja esikoulutukseen. Lopuksi vähennämme suorituskykykuilua 0,01 BLEU:hun Transformer-pohjaisen arkkitehtuurin avulla.</abstract_fi>
      <abstract_hy>Ավտոմատիկ խոսքի թարգմանման (AST) համար վերջ-վերջ մոտեցումները դուրս են գալիս կասկադված մոդելների միջոցով, որոնք թարգմանվում են ավտոմատիկ խոսքի ճանաչման (ASR) միջոցով, հետո թարգմանվում են մեքենայի թարգմանման (MT) միջո Արդյունավետության բացառության հիմնական պատճառը այն է, որ մինչդեռ գոյություն ունի AST-ի կառուցվածքներ փոքր են, ASR-ի և MT-ի ենթահամակարգերի համար գոյություն ունի հսկայական տվյալներ: Այս աշխատանքի ընթացքում մենք գնահատում ենք որոշ տվյալների աճը և AST-ի նախադասական մոտեցումները' համեմատելով բոլորը նույն տվյալների համակարգերի վրա: ASR-ի թարգմանման միջոցով պարզ տվյալների աճը ամենաարդյունավետ է ապացուցում անգլերեն-ֆրանսերեն աճեցված գրադարձ տվյալների համակարգի վրա, փակելով արդյունավետության տարբերությունը 8.2-ից 1.4-ին, համեմատած շատ ուժեղ կասկադի հետ, որը կարող է անմիջապես օգտագործել ASR-ի և MT The same end-to-end approach plus fine-tuning closes the gap on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU.  Ավելին այս արդյունքներին, մենք ներկայացնում ենք ավելացման և նախադասական մոտեցումների պրակտիկ խորհուրդներ: Վերջապես, մենք նվազեցնում ենք արտադրողականության բացառությունը մինչև 0.01 ԲԼԵՎ-ը, որը մեզ հիմնված է Թանֆերմերների ճարտարապետության միջոցով:</abstract_hy>
      <abstract_et>Automaatse kõnetõlke (AST) puhul ületatakse otsast otsa lähenemisviise kaskaadimudelitega, mis transkribeeritakse automaatse kõnetuvastusega (ASR), seejärel transkribeeritakse masintõlkega (MT). Tulemuslikkuse lõhe peamine põhjus on see, et kuigi olemasolevad AST korpused on väikesed, on nii ASR kui ka MT allsüsteemide jaoks olemas massiivsed andmekogumid. Käesolevas töös hindame mitmeid AST-i andmete suurendamise ja eeltreeningu meetodeid, võrreldes kõiki samadel andmekogumitel. Lihtne andmete suurendamine ASR transkriptsioonide tõlkimisega osutub inglise-prantsuse täiendatud LibriSpeech andmekogumi puhul kõige tõhusamaks, sulgedes jõudluse lõhe 8,2 kuni 1,4 BLEU-ni, võrreldes väga tugeva kaskaadiga, mis võiks otseselt kasutada palju ASR- ja MT-andmeid. Sama lõplik lähenemisviis koos peenhäälestusega kaotab lõhe inglise-rumeenia MuST-C andmekogumis vahemikus 6,7 kuni 3,7 BLEU. Lisaks nendele tulemustele esitame praktilisi soovitusi laiendamise ja eelõpetamise lähenemisviiside kohta. Lõpuks vähendame jõudluse lõhet 0,01 BLEU-ni, luues Transformer-põhise arhitektuuri.</abstract_et>
      <abstract_am>For automatic speech translation (AST), the final approach is made by cascaded models that write with automatic speech recognition (ASR), then trans-late with machine translation (MT). የድምፅ ውጤት ግንኙነት በጣም ትልቅ ምክንያት ነው፣ የአስቲ ኮርፖርት ግን ትንሽ ነው፣ የASR እና MT ደብዳቤዎች ደግሞ የብዙ ዳታተር ሰርቨሮች አሉ፡፡ በዚህ ስራ፣ የዳታ አካባቢ እና የAST ደረጃዎችን ለመፍጠር እናሳውቃለን፡፡ ASR transcripts በመግለጫ ቀላል ዳታ ማድረግ በአፍሪካዊ-ፈረንሳይኛ የተጨማሪው የልቤሪንግ ቋንቋ ማድረጊያውን በመግለጫው ይታያል፡፡ ከ8.2 እስከ 1.4 BLEU በመግለጫው ነው፡፡ ይህም የመጨረሻ ቀውስ እና ጥሩ ቀለሞች እንግሊዝኛ-ሮማኒያን MuST-C ዳታተር ከ6.7 ጀምሮ 3.7 BLEU ላይ የሚደረገውን ክፍተት ይጠብቃሉ፡፡ ከዚህም ፍጥረቶች በቀር፣ ለመደጋገፍ እና ለመዘጋጀት የሚደረገውን የስህተት አካባቢ አዳራሽ እናደርጋለን፡፡ በመጨረሻውም የድምፅ ውጤት ወደ 0.01 BLEU እናጎድልናለን - የTransformer-based መሠረት መሠረት እናሳድጋለን፡፡</abstract_am>
      <abstract_ha>@ action: button Maɓalli wa gaura na aikin aiki ni'anar cẽwa, a lokacin da ke iya ƙaranci na shirin ATATAT, ana ƙunsa da data masu ƙaranci wa biyu masu ƙaranci na ATR da MT. Daga wannan aikin, muna ƙaddara ƙaramako da akan data da za'a ƙayyade hanyõyi wa ATATA, da sami-sami duk kan daidaita data. @ item license (short name) Tsarin duk ƙari zuwa ta ƙari kodi da tuning mai kyau yana rufe gap kan maɓallin Ingiriya-Romian Mustan-C na daga 6.7 zuwa 3.7 BLEU. Babu wannan matsayi, Munã halatar da mazaɓa na mazauni-mazaɓa wa ƙãri da kuma misãlai. Gani, Munã ƙarantar gaura da za'a kai 0.01 BLEU - ke samun makarantar da aka Transformer.</abstract_ha>
      <abstract_he>עבור התרגום אוטומטי של דיבור (AST), גישות סוף-סוף מתקדמות על ידי דוגמנים קאסקודים שטרנסקודים עם זיהוי דיבור אוטומטי (ASR), ואז טרנס- מאוחר עם התרגום מכונת (MT). סיבה גדולה של הפער ביצועי היא שבעוד גופות AST קיימות הן קטנות, קבוצות מידע מסיביות קיימות גם עבור מערכות ASR וגם MT. בעבודה הזו, אנו מעריכים מספר שיעורים של נתונים ולגישות מחדש של AST, על ידי השוואה של כולם על אותם קבוצות נתונים. שיעור נתונים פשוט על ידי תרגום תורגם ASR מוכיח הכי יעיל על קבוצת נתונים של LibriSpeech הגדלה אנגלית-צרפתית, לסגור את הפער ביצועים מ-8.2 ל-1.4 BLEU, בהשוואה לקסקד חזק מאוד שיכול להשתמש ישירות בנתונים ASR ומטה. באותו גישה מסוף-לסוף ועוד התרגיל עצום את הפער על קבוצת מידע MuST-C אנגלי-רומנית מ-6.7 ל-3.7 BLEU. בנוסף לתוצאות אלה, אנו מציגים המלצות מעשיות לגבילה ולגישות מחדש. סוף סוף, אנחנו מפחידים את הפער ביצועים ל-0.01 BLEU אנחנו - הארכיטקטורה מבוססת Transformer.</abstract_he>
      <abstract_bo>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans-late with machine translation (MT). performance gaps་ལ་གལ་ཆེ་བའི་རྒྱུ་མཚན་ནི་གནས་ཡུལ་ཡོད་པའི་ AST སྒེར་གྱི་མཐུད་སྒྲིག་ཆ་ཆུང In this work, we evaluate several data augmentation and pretraining approaches for AST, by comparing all on the same data sets. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same end-to-end approach plus fine-tuning closes the gaps on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU. BLEU. གསལ་འབྲས་འདི་དག་ལས་བརྟེན། ང་ཚོས་རྒྱ་བསྐྱེད་སྐབས་སུ་གཏོང་བའི་ཐབས་ལམ་ལ་ཡང་བསྡད་པའི་བརྗོད་བཀོད་པ་ཞིག་ཡོད། མཐའ་མཇུག་དུ། འུ་ཅག་གིས་སྔར་ནས་དབྱིབས་བཟོས་པའི་བཟོ་བརྩིས་གཞི་བརྩིས་གཞི་བཟོ་བྱེད་ཀྱི་ཡོད་ཚད་0.01</abstract_bo>
      <abstract_sk>Pri avtomatskem govornem prevajanju (AST) se pristopi od konca do konca izvajajo s kaskadnimi modeli, ki prepišejo s samodejnim prepoznavanjem govora (ASR), nato pa s strojnim prevajanjem (MT). Glavni vzrok za vrzel v uspešnosti je, da so obstoječe korpuse AST majhne, vendar obstajajo ogromni podatkovni nizi za podsistema ASR in MT. V tem delu smo ocenili več pristopov povečanja in predtreninga podatkov za AST s primerjavo vseh na istih naborih podatkov. Enostavno povečanje podatkov s prevajanjem ASR transkripcij se izkaže za najučinkovitejše na angleško-francoskem naboru podatkov LibriSpeech, saj zmanjšuje vrzel v zmogljivosti od 8,2 do 1,4 BLEU v primerjavi z zelo močno kaskado, ki bi lahko neposredno uporabila obilne ASR in MT podatke. Isti pristop od konca do konca in natančno uravnavanje zapolnjuje vrzel v angleško-romunskem naboru podatkov MuST-C od 6,7 do 3,7 BLEU. Poleg teh rezultatov predstavljamo tudi praktične priporočila za pristope povečanja in predurjenja. Nazadnje pa zmanjšamo vrzel v zmogljivosti na 0,01 BLEU, kar pomeni arhitekturo, ki temelji na transformatorju.</abstract_sk>
      <abstract_jv>Wurungu perusahaan langgambar (AST), dadi kapan-kowe lan mbuh dumateng manut karo model kascade kang karo perusahaan karo perusahaan sesik (ASR), iso terusahaan karo terjamahan (MT). Mbak perusahaan langkung wigatahan kanggo ngerasai, terus akeh AST dumadhi kuwi mungkin, dadi akeh dumadhi kanggo sistem ASR karo MT Nyong-ngobro iki, awak dhéwé ngeremus akeh data nyang diuntingi podho karo AST ngono nggawe dataset sing berarti. Go Sampeyan nganggo cah-sampeyan nganggo cah-sampeyan ngupakan kelas telas nang ingkang-rumani MuRT-C dataset dadi 6.7 sampeyan 3.7 B Nambah gambarang iki, kita ngomong wektu nggawe rerakke praksi- ommendasi kanggo ngilangno karo hal-hal maneh. Lha wiwit, kita ngulinakake perusahaan kanggo 0.1</abstract_jv>
      </paper>
    <paper id="22">
      <title>On Using SpecAugment for End-to-End Speech Translation<fixed-case>S</fixed-case>pec<fixed-case>A</fixed-case>ugment for End-to-End Speech Translation</title>
      <author><first>Parnia</first><last>Bahar</last></author>
      <author><first>Albert</first><last>Zeyer</last></author>
      <author><first>Ralf</first><last>Schlüter</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <abstract>This work investigates a simple data augmentation technique, SpecAugment, for end-to-end speech translation. SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps. We apply SpecAugment on end-to-end speech translation tasks and achieve up to +2.2 % BLEU on LibriSpeech Audiobooks EnFr and +1.2 % on IWSLT TED-talks EnDe by alleviating <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> to some extent. We also examine the effectiveness of the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> in a variety of data scenarios and show that the <a href="https://en.wikipedia.org/wiki/Methodology">method</a> also leads to significant improvements in various data conditions irrespective of the amount of training data.</abstract>
      <url hash="e3ecaec4">2019.iwslt-1.22</url>
      <bibkey>bahar-etal-2019-using</bibkey>
    </paper>
    <paper id="23">
      <title>Estimating post-editing effort : a study on human judgements, task-based and reference-based metrics of MT quality<fixed-case>MT</fixed-case> quality</title>
      <author><first>Scarton</first><last>Scarton</last></author>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <abstract>Devising <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> to assess translation quality has always been at the core of machine translation (MT) research. Traditional automatic reference-based metrics, such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, have shown correlations with human judgements of adequacy and fluency and have been paramount for the advancement of MT system development. Crowd-sourcing has popularised and enabled the scalability of <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> based on human judgments, such as subjective direct assessments (DA) of adequacy, that are believed to be more reliable than reference-based automatic metrics. Finally, task-based measurements, such as post-editing time, are expected to provide a more de- tailed evaluation of the usefulness of translations for a specific task. Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task. In this paper we argue that, although expensive, task-based measurements are the most reliable when estimating MT quality in a specific task ; in our case, this task is <a href="https://en.wikipedia.org/wiki/Post-editing">post-editing</a>. To that end, we report experiments on a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with newly-collected post-editing indicators and show their usefulness when estimating post-editing effort. Our results show that task-based metrics comparing machine-translated and post-edited versions are the best at tracking post-editing effort, as expected.</abstract>
      <url hash="8a61b1b6">2019.iwslt-1.23</url>
      <bibkey>scarton-etal-2019-estimating</bibkey>
      <pwccode url="https://github.com/carolscarton/iwslt2019" additional="false">carolscarton/iwslt2019</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/iwslt-2019">IWSLT 2019</pwcdataset>
    </paper>
    <paper id="24">
      <title>Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification</title>
      <author><first>Yingbo</first><last>Gao</last></author>
      <author><first>Christian</first><last>Herold</last></author>
      <author><first>Weiyue</first><last>Wang</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <abstract>Prominently used in support vector machines and <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic re-gressions</a>, kernel functions (kernels) can implicitly map data points into high dimensional spaces and make it easier to learn complex decision boundaries. In this work, by replacing the inner product function in the softmax layer, we explore the use of <a href="https://en.wikipedia.org/wiki/Kernel_method">kernels</a> for contextual word classification. In order to compare the individual kernels, experiments are conducted on standard language modeling and machine translation tasks. We observe a wide range of performances across different <a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)">kernel settings</a>. Extending the results, we look at the gradient properties, investigate various mixture strategies and examine the disambiguation abilities.</abstract>
      <url hash="f68150f6">2019.iwslt-1.24</url>
      <bibkey>gao-etal-2019-exploring</bibkey>
    </paper>
    <paper id="26">
      <title>Generic and Specialized Word Embeddings for Multi-Domain Machine Translation</title>
      <author><first>MinhQuang</first><last>Pham</last></author>
      <author><first>Josep</first><last>Crego</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <author><first>Jean</first><last>Senellart</last></author>
      <abstract>Supervised machine translation works well when the train and test data are sampled from the same distribution. When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences. We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources. Our proposal transposes to <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> the feature expansion technique of (Daum III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains. Our experiments use two architectures and two language pairs : they show that our approach, while simple and computationally inexpensive, outperforms several strong baselines and delivers a multi-domain system that successfully translates texts from diverse sources.</abstract>
      <url hash="c5a76260">2019.iwslt-1.26</url>
      <bibkey>pham-etal-2019-generic</bibkey>
    </paper>
    <paper id="27">
      <title>Lexical Micro-adaptation for Neural Machine Translation</title>
      <author><first>Jitao</first><last>Xu</last></author>
      <author><first>Josep</first><last>Crego</last></author>
      <author><first>Jean</first><last>Senellart</last></author>
      <abstract>This work is inspired by a typical machine translation industry scenario in which translators make use of in-domain data for facilitating translation of similar or repeating sentences. We introduce a generic framework applied at <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a> in which a subset of segment pairs are first extracted from training data according to their similarity to the input sentences. These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation. Our approach demonstrates strong adaptation performance to new and existing <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> including pseudo in-domain data. We evaluate our approach on a heterogeneous English-French training dataset showing accuracy gains on all evaluated domains when compared to strong adaptation baselines.</abstract>
      <url hash="74fc87c1">2019.iwslt-1.27</url>
      <bibkey>xu-etal-2019-lexical</bibkey>
    </paper>
    <paper id="28">
      <title>Efficient Bilingual Generalization from Neural Transduction Grammar Induction</title>
      <author><first>Yuchen</first><last>Yan</last></author>
      <author><first>Dekai</first><last>Wu</last></author>
      <author><first>Serkan</first><last>Kumyol</last></author>
      <abstract>We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, which we hypothesize that can efficiently learn complex biparse tree patterns. Our work distinguishes from sequential attention-based models, which are more traditionally found in neural machine translation (NMT) in three aspects. First, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> enforces compositional constraints. Second, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has a smaller search space in terms of discovering bilingual relationships from bilingual sentence pairs. Third, our model produces explicit biparse trees, which enable transparent error analysis during evaluation and external tree constraints during training.</abstract>
      <url hash="2cfa24d9">2019.iwslt-1.28</url>
      <bibkey>yan-etal-2019-efficient</bibkey>
    </paper>
    <paper id="29">
      <title>Breaking the Data Barrier : Towards Robust Speech Translation via Adversarial Stability Training</title>
      <author><first>Qiao</first><last>Cheng</last></author>
      <author><first>Meiyuan</first><last>Fan</last></author>
      <author><first>Yaqian</first><last>Han</last></author>
      <author><first>Jin</first><last>Huang</last></author>
      <author><first>Yitao</first><last>Duan</last></author>
      <abstract>In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system. A standard <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation system</a> is usually trained on <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpus</a> composed of clean text and will perform poorly on text with recognition noise, a gap well known in speech translation community. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training architecture</a> which aims at making a neural machine translation model more robust against speech recognition errors. Our approach addresses the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> and the <a href="https://en.wikipedia.org/wiki/Code">decoder</a> simultaneously using <a href="https://en.wikipedia.org/wiki/Adversarial_learning">adversarial learning</a> and <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, respectively. Experimental results on IWSLT2018 speech translation task show that our approach can bridge the gap between the ASR output and the MT input, outperforms the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> by up to 2.83 BLEU on noisy ASR output, while maintaining close performance on clean text.</abstract>
      <url hash="c688bc26">2019.iwslt-1.29</url>
      <bibkey>cheng-etal-2019-breaking</bibkey>
    </paper>
    <paper id="31">
      <title>Controlling the Output Length of Neural Machine Translation</title>
      <author><first>Surafel Melaku</first><last>Lakew</last></author>
      <author><first>Mattia</first><last>Di Gangi</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <abstract>The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, as well as reshaping the quality level to be targeted. In particular, if translations have to fit some given layout, <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> should not only be measured in terms of adequacy and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>, but also length. Exemplary cases are the translation of document files, <a href="https://en.wikipedia.org/wiki/Subtitle_(titling)">subtitles</a>, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT. We investigate two methods for biasing the output length with a transformer architecture : i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information. Our experiments show that both methods can induce the <a href="https://en.wikipedia.org/wiki/Social_network">network</a> to generate shorter translations, as well as acquiring inter- pretable linguistic skills.</abstract>
      <url hash="e032ec61">2019.iwslt-1.31</url>
      <bibkey>lakew-etal-2019-controlling</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/must-c">MuST-C</pwcdataset>
    </paper>
    </volume>
</collection>