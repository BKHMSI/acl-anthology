<collection id="2020.wosp">
  <volume id="1" ingest-date="2020-10-23">
    <meta>
      <booktitle>Proceedings of the 8th International Workshop on Mining Scientific Publications</booktitle>
      <editor><first>Petr</first><last>Knoth</last></editor>
      <editor><first>Christopher</first><last>Stahl</last></editor>
      <editor><first>Bikash</first><last>Gyawali</last></editor>
      <editor><first>David</first><last>Pride</last></editor>
      <editor><first>Suchetha N.</first><last>Kunnath</last></editor>
      <editor><first>Drahomira</first><last>Herrmannova</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Wuhan, China</address>
      <month>05 August</month>
      <year>2020</year>
      <url hash="dc00149a">2020.wosp-1</url>
    </meta>
    <frontmatter>
      <url hash="337783c9">2020.wosp-1.0</url>
      <bibkey>wosp-2020-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Virtual Citation Proximity (<fixed-case>VCP</fixed-case>): Empowering Document Recommender Systems by Learning a Hypothetical In-Text Citation-Proximity Metric for Uncited Documents</title>
      <author><first>Paul</first><last>Molloy</last></author>
      <author><first>Joeran</first><last>Beel</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>1&#8211;8</pages>
      <abstract>The relatedness of research articles, patents, court rulings, web pages, and other document types is often calculated with citation or hyperlink-based approaches like co-citation (proximity) analysis. The main limitation of citation-based approaches is that they cannot be used for documents that receive little or no citations. We propose Virtual Citation Proximity (VCP), a Siamese Neural Network architecture, which combines the advantages of co-citation proximity analysis (diverse notions of relatedness / high recommendation performance), with the advantage of content-based filtering (high coverage). VCP is trained on a corpus of documents with textual features, and with real citation proximity as ground truth. VCP then predicts for any two documents, based on their title and abstract, in what proximity the two documents would be co-cited, if they were indeed co-cited. The prediction can be used in the same way as real citation proximity to calculate document relatedness, even for uncited documents. In our evaluation with 2 million co-citations from Wikipedia articles, VCP achieves an MAE of 0.0055, i.e. an improvement of 20% over the baseline, though the learning curve suggests that more work is needed.</abstract>
      <url hash="2f9def55">2020.wosp-1.1</url>
      <bibkey>molloy-etal-2020-virtual</bibkey>
    </paper>
    <paper id="6">
      <title>The Normalized Impact Index for Keywords in Scholarly Papers to Detect Subtle Research Topics</title>
      <author><first>Daisuke</first><last>Ikeda</last></author>
      <author><first>Yuta</first><last>Taniguchi</last></author>
      <author><first>Kazunori</first><last>Koga</last></author>
      <pages>42&#8211;47</pages>
      <abstract>Mainly due to the open access movement, the number of scholarly papers we can freely access is drastically increasing. A huge amount of papers is a promising resource for text mining and machine learning. Given a set of papers, for example, we can grasp past or current trends in a research community. Compared to the trend detection, it is more difficult to forecast trends in the near future, since the number of occurrences of some features, which are major cues for automatic detection, such as the word frequency, is quite small before such a trend will emerge. As a first step toward trend forecasting, this paper is devoted to finding subtle trends. To do this, the authors propose an index for keywords, called normalized impact index, and visualize keywords and their indices as a heat map. The authors have conducted case studies using some keywords already known as popular, and we found some keywords whose frequencies are not so large but whose indices are large.</abstract>
      <url hash="01f43ada">2020.wosp-1.6</url>
      <bibkey>ikeda-etal-2020-normalized</bibkey>
    </paper>
    <paper id="9">
      <title>Scubed at 3<fixed-case>C</fixed-case> task A - A simple baseline for citation context purpose classification</title>
      <author><first>Shubhanshu</first><last>Mishra</last></author>
      <author><first>Sudhanshu</first><last>Mishra</last></author>
      <pages>59&#8211;64</pages>
      <abstract>We present our team Scubed&#8217;s approach in the &#8216;3C&#8217; Citation Context Classification Task, Subtask A, citation context purpose classification. Our approach relies on text based features transformed via tf-idf features followed by training a variety of models which are capable of capturing non-linear features. Our best model on the leaderboard is a multi-layer perceptron which also performs best during our rerun. Our submission code for replicating experiments is at: https://github.com/napsternxg/Citation_Context_Classification.</abstract>
      <url hash="17a8f207">2020.wosp-1.9</url>
      <bibkey>mishra-mishra-2020-scubed</bibkey>
      <pwccode url="https://github.com/napsternxg/citation_context_classification" additional="false">napsternxg/citation_context_classification</pwccode>
    </paper>
    </volume>
</collection>