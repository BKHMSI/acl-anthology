<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.case">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)</booktitle>
      <editor><first>Ali</first><last>Hürriyetoğlu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="2fadeb05">2021.case-1</url>
    </meta>
    <frontmatter>
      <url hash="4bc787bc">2021.case-1.0</url>
      <bibkey>case-2021-challenges</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021): Workshop and Shared Task Report<fixed-case>CASE</fixed-case> 2021): Workshop and Shared Task Report</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Hristo</first><last>Tanev</last></author>
      <author><first>Vanni</first><last>Zavarella</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Reyyan</first><last>Yeniterzi</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Deniz</first><last>Yuret</last></author>
      <author><first>Aline</first><last>Villavicencio</last></author>
      <pages>1–9</pages>
      <abstract>This workshop is the fourth issue of a series of workshops on automatic extraction of socio-political events from news, organized by the Emerging Market Welfare Project, with the support of the Joint Research Centre of the European Commission and with contributions from many other prominent scholars in this field. The purpose of this series of workshops is to foster research and development of reliable, valid, robust, and practical solutions for automatically detecting descriptions of socio-political events, such as <a href="https://en.wikipedia.org/wiki/Protest">protests</a>, <a href="https://en.wikipedia.org/wiki/Riot">riots</a>, <a href="https://en.wikipedia.org/wiki/War">wars</a> and <a href="https://en.wikipedia.org/wiki/War">armed conflicts</a>, in text streams. This year workshop contributors make use of the state-of-the-art NLP technologies, such as <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a>, Word Embeddings and Transformers and cover a wide range of topics from text classification to news bias detection. Around 40 teams have registered and 15 teams contributed to three tasks that are i) multilingual protest news detection detection, ii) fine-grained classification of socio-political events, and iii) discovering Black Lives Matter protest events. The workshop also highlights two keynote and four invited talks about various aspects of creating event data sets and multi- and cross-lingual machine learning in few- and zero-shot settings.</abstract>
      <url hash="730ae684">2021.case-1.1</url>
      <doi>10.18653/v1/2021.case-1.1</doi>
      <bibkey>hurriyetoglu-etal-2021-challenges</bibkey>
    </paper>
    <paper id="2">
      <title>Keynote Abstract : Events on a Global Scale : Towards Language-Agnostic Event Extraction</title>
      <author><first>Elizabeth</first><last>Boschee</last></author>
      <pages>10</pages>
      <abstract>Event extraction is a challenging and exciting task in the world of <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> &amp; <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. The breadth of events of possible interest, the speed at which surrounding socio-political event contexts evolve, and the complexities involved in generating representative annotated data all contribute to this challenge. One particular dimension of difficulty is the intrinsically global nature of events : many downstream use cases for <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> involve reporting not just in a few major languages but in a much broader context. The languages of interest for even a fixed <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> may still shift from day to day, e.g. when a disease emerges in an unexpected location. Early <a href="https://en.wikipedia.org/wiki/Methodology">approaches</a> to multi-lingual event extraction (e.g. ACE) relied wholly on supervised data provided in each language of interest. Later approaches leveraged the success of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> to side-step the issue, simply translating foreign-language content to <a href="https://en.wikipedia.org/wiki/English_language">English</a> and deploying <a href="https://en.wikipedia.org/wiki/English_language">English models</a> on the result (often leaving some significant portion of the original content behind). Most recently, however, the community has begun to shown significant progress applying zero-shot transfer techniques to the problem, developing models using supervised English data but decoding in a foreign language without translation, typically using embedding spaces specifically designed to capture multi-lingual semantic content. In this talk I will discuss multiple dimensions of these promising new approaches and the linguistic representations that underlie them. I will compare them with approaches based on <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> (as well as with models trained using in-language training data, where available), and discuss their strengths and weaknesses in different contexts, including the amount of English / foreign bitext available and the nature of the target event ontology. I will also discuss possible future directions with an eye to improving the quality of <a href="https://en.wikipedia.org/wiki/Event_extraction">event extraction</a> no matter its source around the globe.</abstract>
      <url hash="7e5e8eb6">2021.case-1.2</url>
      <doi>10.18653/v1/2021.case-1.2</doi>
      <bibkey>boschee-2021-keynote</bibkey>
    </paper>
    <paper id="3">
      <title>Keynote Abstract : <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning</a> in Conflict Studies : Reflections on Ethics, Collaboration, and Ongoing Challenges</title>
      <author><first>Kristine</first><last>Eck</last></author>
      <pages>11</pages>
      <abstract>Advances in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> are nothing short of revolutionary in their potential to analyze massive amounts of data and in doing so, create new <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a>. But there is a responsibility in wielding the power to analyze these <a href="https://en.wikipedia.org/wiki/Data">data</a> since the public attributes a high degree of confidence to results which are based on <a href="https://en.wikipedia.org/wiki/Big_data">big datasets</a>. In this keynote, I will first address our ethical imperative as scholars to get it right. This imperative relates not only to model precision but also to the quality of the underlying data, and to whether the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> inadvertently reproduce or obscure political biases in the source material. In considering the ethical imperative to get it right, it is also important to define what is right : what is considered an acceptable threshold for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> success needs to be understood in light of the project’s objectives. I then reflect on the different topics and data which are sourced in this field. Much of the existing research has focused on identifying <a href="https://en.wikipedia.org/wiki/Conflict_(process)">conflict events</a> (e.g. battles), but scholars are also increasingly turning to ML approaches to address other facets of the conflict environment. Conflict event extraction has long been a challenge for the natural language processing (NLP) community because it requires sophisticated methods for defining <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">event ontologies</a>, creating language resources, and developing algorithmic approaches. NLP machine-learning tools are ill-adapted to the complex, often messy, and diverse data generated during conflicts. Relative to other types of NLP text corpora, conflicts tend to generate less textual data, and texts are generated non-systematically. Conflict-related texts are often lexically idiosyncratic and tend to be written differently across actors, periods, and conflicts. Event definition and <a href="https://en.wikipedia.org/wiki/Adjudication">adjudication</a> present tough challenges in the context of conflict corpora. Topics which rely on other types of <a href="https://en.wikipedia.org/wiki/Data">data</a> may be better-suited to NLP and machine learning methods. For example, <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> and other social media data lend themselves well to studying <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a>, <a href="https://en.wikipedia.org/wiki/Public_opinion">public opinion</a>, <a href="https://en.wikipedia.org/wiki/Social_polarization">social polarization</a>, or discursive aspects of conflictual environments. Likewise, government-produced policy documents have typically been analyzed with historical, qualitative methods but their standardized formats and quantity suggest that ML methods can provide new traction. ML approaches may also allow scholars to exploit <a href="https://en.wikipedia.org/wiki/Primary_source">local sources</a> and <a href="https://en.wikipedia.org/wiki/Multilingualism">multi-language sources</a> to a greater degree than has been possible. Many challenges remain, and these are best addressed in collaborative projects which build on interdisciplinary expertise. Classification projects need to be anchored in the theoretical interests of scholars of <a href="https://en.wikipedia.org/wiki/Political_violence">political violence</a> if the data they produce are to be put to analytical use. There are few <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontologies</a> for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> that adequately reflect conflict researchers’ interests, which highlights the need for conceptual as well as technical development.</abstract>
      <url hash="25e1115b">2021.case-1.3</url>
      <doi>10.18653/v1/2021.case-1.3</doi>
      <bibkey>eck-2021-keynote</bibkey>
    </paper>
    <paper id="9">
      <title>Extracting Events from Industrial Incident Reports</title>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Sangameshwar</first><last>Patil</last></author>
      <author><first>Alok</first><last>Kumar</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>58–67</pages>
      <abstract>Incidents in industries have huge social and political impact and minimizing the consequent damage has been a high priority. However, automated analysis of repositories of incident reports has remained a challenge. In this paper, we focus on automatically extracting <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">events</a> from <a href="https://en.wikipedia.org/wiki/Incident_report">incident reports</a>. Due to absence of event annotated datasets for industrial incidents we employ a transfer learning based approach which is shown to outperform several baselines. We further provide detailed analysis regarding effect of increase in pre-training data and provide explainability of why pre-training improves the performance.</abstract>
      <url hash="1ce6ac61">2021.case-1.9</url>
      <doi>10.18653/v1/2021.case-1.9</doi>
      <bibkey>ramrakhiyani-etal-2021-extracting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nombank">NomBank</pwcdataset>
    </paper>
    <paper id="11">
      <title>Multilingual Protest News Detection-Shared Task 1, CASE 2021<fixed-case>CASE</fixed-case> 2021</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Erdem</first><last>Yörük</last></author>
      <author><first>Farhana Ferdousi</first><last>Liza</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Shyam</first><last>Ratan</last></author>
      <pages>79–91</pages>
      <abstract>Benchmarking state-of-the-art text classification and information extraction systems in multilingual, cross-lingual, few-shot, and zero-shot settings for socio-political event information collection is achieved in the scope of the shared task Socio-political and Crisis Events Detection at the workshop CASE @ ACL-IJCNLP 2021. Socio-political event data is utilized for national and international policy- and decision-making. Therefore, the reliability and validity of these <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> are of the utmost importance. We split the shared task into three parts to address the three aspects of <a href="https://en.wikipedia.org/wiki/Data_collection">data collection</a> (Task 1), fine-grained semantic classification (Task 2), and <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> (Task 3). Task 1, which is the focus of this report, is on multilingual protest news detection and comprises four subtasks that are document classification (subtask 1), sentence classification (subtask 2), event sentence coreference identification (subtask 3), and event extraction (subtask 4). All subtasks had <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> for both training and evaluation data. Data in <a href="https://en.wikipedia.org/wiki/Hindi">Hindi language</a> was available only for the evaluation of subtask 1. The majority of the submissions, which are 238 in total, are created using multi- and cross-lingual approaches. Best scores are above 77.27 F1-macro for subtask 1, above 85.32 F1-macro for subtask 2, above 84.23 CoNLL 2012 average score for subtask 3, and above 66.20 F1-macro for subtask 4 in all evaluation settings.</abstract>
      <url hash="1dfe2342">2021.case-1.11</url>
      <doi>10.18653/v1/2021.case-1.11</doi>
      <bibkey>hurriyetoglu-etal-2021-multilingual</bibkey>
    </paper>
    <paper id="13">
      <title>IIITT at CASE 2021 Task 1 : Leveraging Pretrained Language Models for Multilingual Protest Detection<fixed-case>IIITT</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Leveraging Pretrained Language Models for Multilingual Protest Detection</title>
      <author><first>Pawan</first><last>Kalyan</last></author>
      <author><first>Duddukunta</first><last>Reddy</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Ratnasingam</first><last>Sakuntharaj</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>98–104</pages>
      <abstract>In a world abounding in constant protests resulting from events like a global pandemic, <a href="https://en.wikipedia.org/wiki/Climate_change">climate change</a>, religious or political conflicts, there has always been a need to detect events / protests before getting amplified by <a href="https://en.wikipedia.org/wiki/News_media">news media</a> or <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This paper demonstrates our work on the sentence classification subtask of multilingual protest detection in CASE@ACL-IJCNLP 2021. We approached this task by employing various multilingual pre-trained transformer models to classify if any sentence contains information about an event that has transpired or not. We performed soft voting over the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, achieving the best results among the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>, accomplishing a macro F1-Score of 0.8291, 0.7578, and 0.7951 in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, Spanish, and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, respectively.</abstract>
      <url hash="548f4fea">2021.case-1.13</url>
      <doi>10.18653/v1/2021.case-1.13</doi>
      <bibkey>kalyan-etal-2021-iiitt</bibkey>
      <pwccode url="https://github.com/adeeph/case-2021-task-1" additional="false">adeeph/case-2021-task-1</pwccode>
    </paper>
    <paper id="14">
      <title>NUS-IDS at CASE 2021 Task 1 : Improving Multilingual Event Sentence Coreference Identification With Linguistic Information<fixed-case>NUS</fixed-case>-<fixed-case>IDS</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Improving Multilingual Event Sentence Coreference Identification With Linguistic Information</title>
      <author><first>Fiona Anting</first><last>Tan</last></author>
      <author><first>Sujatha Das</first><last>Gollapalli</last></author>
      <author><first>See-Kiong</first><last>Ng</last></author>
      <pages>105–112</pages>
      <abstract>Event Sentence Coreference Identification (ESCI) aims to cluster event sentences that refer to the same event together for <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>. We describe our ESCI solution developed for the ACL-CASE 2021 shared tasks on the detection and classification of socio-political and crisis event information in a multilingual setting. For a given article, our proposed pipeline comprises of an accurate sentence pair classifier that identifies coreferent sentence pairs and subsequently uses these predicted probabilities to cluster sentences into groups. Sentence pair representations are constructed from fine-tuned BERT embeddings plus POS embeddings fed through a BiLSTM model, and combined with linguistic-based lexical and semantic similarities between sentences. Our best <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> ranked 2nd, 1st and 2nd and obtained CoNLL F1 scores of 81.20 %, 93.03 %, 83.15 % for the English, Portuguese and Spanish test sets respectively in the <a href="https://en.wikipedia.org/wiki/American_Lacrosse_League">ACL-CASE 2021 competition</a>.</abstract>
      <url hash="39a44101">2021.case-1.14</url>
      <doi>10.18653/v1/2021.case-1.14</doi>
      <bibkey>tan-etal-2021-nus</bibkey>
      <pwccode url="https://github.com/nus-ids/eventsentencecoref" additional="false">nus-ids/eventsentencecoref</pwccode>
    </paper>
    <paper id="18">
      <title>IBM MNLP IE at CASE 2021 Task 1 : Multigranular and Multilingual Event Detection on Protest News<fixed-case>IBM</fixed-case> <fixed-case>MNLP</fixed-case> <fixed-case>IE</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Multigranular and Multilingual Event Detection on Protest News</title>
      <author><first>Parul</first><last>Awasthy</last></author>
      <author><first>Jian</first><last>Ni</last></author>
      <author><first>Ken</first><last>Barker</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <pages>138–146</pages>
      <abstract>In this paper, we present the event detection models and systems we have developed for Multilingual Protest News Detection-Shared Task 1 at CASE 2021. The shared task has 4 subtasks which cover event detection at different granularity levels (from document level to token level) and across multiple languages (English, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a> and Spanish). To handle data from multiple languages, we use a multilingual transformer-based language model (XLM-R) as the input text encoder. We apply a variety of techniques and build several transformer-based models that perform consistently well across all the subtasks and languages. Our <a href="https://en.wikipedia.org/wiki/System">systems</a> achieve an average <a href="https://en.wikipedia.org/wiki/F1_(classification)">F_1 score</a> of 81.2. Out of thirteen subtask-language tracks, our submissions rank 1st in nine and 2nd in four tracks.</abstract>
      <url hash="bf723387">2021.case-1.18</url>
      <doi>10.18653/v1/2021.case-1.18</doi>
      <bibkey>awasthy-etal-2021-ibm</bibkey>
    </paper>
    <paper id="19">
      <title>ALEM at CASE 2021 Task 1 : Multilingual Text Classification on News Articles<fixed-case>ALEM</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Multilingual Text Classification on News Articles</title>
      <author><first>Alaeddin</first><last>Gürel</last></author>
      <author><first>Emre</first><last>Emin</last></author>
      <pages>147–151</pages>
      <abstract>We participated CASE shared task in ACL-IJCNLP 2021. This paper is a summary of our experiments and ideas about this shared task. For each subtask we shared our <a href="https://en.wikipedia.org/wiki/Methodology">approach</a>, successful and failed methods and our thoughts about them. We submit our results once for every subtask, except for subtask3, in task submission system and present scores based on our validation set formed from given training samples in this paper. Techniques and models we mentioned includes BERT, Multilingual BERT, <a href="https://en.wikipedia.org/wiki/Oversampling">oversampling</a>, <a href="https://en.wikipedia.org/wiki/Undersampling">undersampling</a>, <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> and their implications with each other. Most of the experiments we came up with were not completed, as time did not permit, but we share them here as we plan to do them as suggested in the future work part of document.</abstract>
      <url hash="99afb34c">2021.case-1.19</url>
      <doi>10.18653/v1/2021.case-1.19</doi>
      <bibkey>gurel-emin-2021-alem</bibkey>
    </paper>
    <paper id="21">
      <title>AMU-EURANOVA at CASE 2021 Task 1 : Assessing the stability of multilingual BERT<fixed-case>AMU</fixed-case>-<fixed-case>EURANOVA</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Assessing the stability of multilingual <fixed-case>BERT</fixed-case></title>
      <author><first>Léo</first><last>Bouscarrat</last></author>
      <author><first>Antoine</first><last>Bonnefoy</last></author>
      <author><first>Cécile</first><last>Capponi</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>161–170</pages>
      <abstract>This paper explains our participation in task 1 of the CASE 2021 shared task. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is about multilingual event extraction from <a href="https://en.wikipedia.org/wiki/News">news</a>. We focused on sub-task 4, event information extraction. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this <a href="https://en.wikipedia.org/wiki/Task_(computing)">sub-task</a>. We studied the instability problem on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and tried to mitigate it.</abstract>
      <url hash="54d722de">2021.case-1.21</url>
      <doi>10.18653/v1/2021.case-1.21</doi>
      <bibkey>bouscarrat-etal-2021-amu</bibkey>
      <pwccode url="https://github.com/euranova/AMU-EURANOVA-CASE-2021" additional="false">euranova/AMU-EURANOVA-CASE-2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    <title_es>AMU-EURANOVA en la Tarea 1 de CASE 2021: Evaluación de la estabilidad del BERT multilingüe</title_es>
      <title_pt>AMU-EURANOVA no CASE 2021 Tarefa 1: Avaliando a estabilidade do BERT multilíngue</title_pt>
      <title_ar>AMU-EURANOVA في CASE 2021 المهمة 1: تقييم استقرار BERT متعدد اللغات</title_ar>
      <title_ja>ケース2021のAMU - EURANOVAタスク1 ：多言語BERTの安定性の評価</title_ja>
      <title_hi>एएमयू-यूरेनोोवा केस 2021 टास्क 1 पर: बहुभाषी बर्ट की स्थिरता का आकलन करना</title_hi>
      <title_zh>AMU-EURANOVA在CASE 2021务1:评估多言BERT之稳定性</title_zh>
      <title_ga>AMU-EURANOVA ag CÁS 2021 Tasc 1: Cobhsaíocht BERT ilteangach a mheas</title_ga>
      <title_ka>AMU-EURANOVA CASE 2021 დავალება 1: მრავალური ბერტის სტაბლიტურობის შესაბამისა</title_ka>
      <title_hu>AMU-EURANOVA a 2021-es ügyben 1. feladat: A BERT többnyelvű stabilitásának értékelése</title_hu>
      <title_el>AMU-EURANOVA στην CASE 2021 Εργασία 1: Αξιολόγηση της σταθερότητας του πολυγλωσσικού BERT</title_el>
      <title_it>AMU-EURANOVA al CASE 2021 Task 1: Valutare la stabilità del BERT multilingue</title_it>
      <title_lt>AMU-EURANOVA 2021 M. BYLA 1 užduotis: daugiakalbių BERT stabilumo vertinimas</title_lt>
      <title_kk>CASE 2021 1 тапсырмасында AMU- EURANOVA: бірнеше тілді BERT- тың стабилдығын оқу</title_kk>
      <title_mk>АМУ-ЕУРАНОВА во КАЈС 2021 задача 1: Проценка на стабилноста на мултијазичниот БЕРТ</title_mk>
      <title_ms>AMU-EURANOVA di CASE 2021 Tugas 1: Mengesan kestabilan BERT berbilang bahasa</title_ms>
      <title_ml>CASE 2021 ടാസ്ക് 1: പല ഭാഷ ബെര്‍ട്ടിന്റെ സ്ഥിരമാണെന്ന് വിചാരിക്കുന്നു</title_ml>
      <title_mt>AMU-EURANOVA fil-KAŻ 2021 Kompitu 1: Valutazzjoni tal-istabbiltà tal-BERT multilingwi</title_mt>
      <title_mn>CASE 2021 Task 1: Олон хэл БЕРТ-ын тогтвортой байдал</title_mn>
      <title_no>AMU-EURANOVA på CASE 2021 Oppgåve 1: Assesser stabiliteten av fleirspråk BERT</title_no>
      <title_pl>AMU-EURANOVA na CASE 2021 Zadanie 1: Ocena stabilności wielojęzycznego BERT</title_pl>
      <title_ro>AMU-EURANOVA la CAUZA 2021 Sarcina 1: Evaluarea stabilității BERT multilingv</title_ro>
      <title_sr>AMU-EURANOVA na CASE 2021 Task 1: procena stabilnosti multijezičkog BERT-a</title_sr>
      <title_si>CASE 2021 වැඩක් 1 වල AMU-EURANOVA: ගොඩක් භාෂාවක් BERT ගැන ස්ථිර විශ්වාස කරන්න</title_si>
      <title_so>AMU-EURANOVA at CASE 2021 Task 1: Assessing stability of BERT luuqado badan</title_so>
      <title_sv>AMU-EURANOVA vid MÅL 2021 Uppgift 1: Bedömning av stabiliteten hos flerspråkig BERT</title_sv>
      <title_ta>CASE 2021 பணியில் AMU- EURANOVA: பல மொழி பெர்ட் நிலையையும் பரிசோதிக்கிறது</title_ta>
      <title_ur>CASE 2021 Task 1 میں AMU-EURANOVA</title_ur>
      <title_uz>AMU-EURANOVA at CASE 2021 Task 1: Assessing the stability of multilingual BERT</title_uz>
      <title_vi>Giao dịch AMU-thiện cảm tại CASE 2021, nhiệm vụ 1: đánh giá ổn định của giao đậu đa dạng.</title_vi>
      <title_bg>Задача 1: Оценка на стабилността на многоезичния BERT</title_bg>
      <title_da>AMU-EURANOVA ved SAG 2021 Opgave 1: Vurdering af stabiliteten i flersproget BERT</title_da>
      <title_de>AMU-EURANOVA bei CASE 2021 Aufgabe 1: Bewertung der Stabilität mehrsprachiger BERT</title_de>
      <title_id>AMU-EURANOVA di CASE 2021 Tugas 1: penilaian stabilitas BERT berbilang bahasa</title_id>
      <title_ko>AMU-EURANOVA 사례 2021 임무 1: 다국어 학습의 안정성 평가</title_ko>
      <title_nl>AMU-EURANOVA op CASE 2021 Taak 1: Beoordeling van de stabiliteit van meertalige BERT</title_nl>
      <title_hr>AMU-EURANOVA na CASE 2021. zadatak 1: procjena stabilnosti multijezičkog BERT-a</title_hr>
      <title_sw>AMU-EURANOVA katika kazi ya CASE 2021 1: Kuthibitisha ustawi wa lugha nyingine</title_sw>
      <title_fa>AMU-EURANOVA در CASE 2021 Task 1: Assessment the stability of multilingual BERT</title_fa>
      <title_af>AMU-EURANOVA by CASE 2021 Taak 1: Assessing die stabiliteit van multilingual BERT</title_af>
      <title_sq>AMU-EURANOVA në CASE 2021 Detyra 1: Vlerësimi i stabilitetit të BERT shumëgjuhës</title_sq>
      <title_tr>AMU-EURANOVA CASE 2021 Görevi 1: Çoklu dil BERT'un stabilityny çözmek</title_tr>
      <title_az>AMU-EURANOVA CASE 2021 G칬z톛l 1: 칞oxlu dil BERT istiqam톛tini t톛min edir</title_az>
      <title_am>በCASE 2021 ስራ AMU-EURANOVA</title_am>
      <title_hy>ԱՄU-Եվրանովան 2021 թվականի դեպքում առաջին հանձնարարությունը՝ բազլեզու BERT-ի կայունության գնահատումը</title_hy>
      <title_bn>১: বহুভাষী ভাষায় বার্টের স্থিতির বিশেষ ধারণা করা হচ্ছে</title_bn>
      <title_ca>AMU-EURANOVA al CAS 2021 Task 1: Evaluation of the stability of multilingual BERT</title_ca>
      <title_cs>AMU-EURANOVA na CASE 2021 Úkol 1: Posouzení stability vícejazyčného BERT</title_cs>
      <title_et>AMU-EURANOVA CASE 2021 Ülesanne 1: mitmekeelse BERTi stabiilsuse hindamine</title_et>
      <title_fi>AMU-EURANOVA CASE 2021 Tehtävä 1: Monikielisen BERT-verkoston vakauden arviointi</title_fi>
      <title_bs>AMU-EURANOVA na CASE 2021 Task 1: procjena stabilnosti multijezičkog BERT-a</title_bs>
      <title_sk>AMU-EURANOVA na CASE 2021 Naloga 1: Ocena stabilnosti večjezičnega BERT</title_sk>
      <title_he>AMU-EURANOVA at CASE 2021 Task 1: Assessing the stability of multilingual BERT</title_he>
      <title_ha>QFontDatabase</title_ha>
      <title_bo>AMU-EURANOVA at CASE 2021 Task 1: Assessing the stability of multilingual BERT</title_bo>
      <title_jv>AU-E URL ANOV nang CYSE 2020 1 task 1: assess the stabilety of multilanguage BERT</title_jv>
      <abstract_ar>تشرح هذه الورقة مشاركتنا في المهمة 1 من مهمة CASE 2021 المشتركة. هذه المهمة تدور حول استخراج حدث متعدد اللغات من الأخبار. ركزنا على المهمة الفرعية 4 ، استخراج معلومات الحدث. تحتوي هذه المهمة الفرعية على مجموعة بيانات تدريب صغيرة وقمنا بضبط BERT متعدد اللغات لحل هذه المهمة الفرعية. درسنا مشكلة عدم الاستقرار في مجموعة البيانات وحاولنا التخفيف من حدتها.</abstract_ar>
      <abstract_pt>Este artigo explica nossa participação na tarefa 1 da tarefa compartilhada CASE 2021. Esta tarefa é sobre extração de eventos multilíngues de notícias. Nós nos concentramos na subtarefa 4, extração de informações de eventos. Essa subtarefa tem um pequeno conjunto de dados de treinamento e ajustamos um BERT multilíngue para resolver essa subtarefa. Estudamos o problema de instabilidade no conjunto de dados e tentamos mitigá-lo.</abstract_pt>
      <abstract_es>Este documento explica nuestra participación en la tarea 1 de la tarea compartida de CASE 2021. Esta tarea trata sobre la extracción de eventos multilingües de las noticias. Nos centramos en la subtarea 4, extracción de información de eventos. Esta subtarea tiene un pequeño conjunto de datos de entrenamiento y hemos ajustado un BERT multilingüe para resolver esta subtarea. Estudiamos el problema de inestabilidad en el conjunto de datos y tratamos de mitigarlo.</abstract_es>
      <abstract_hi>यह पेपर CASE 2021 साझा कार्य के कार्य 1 में हमारी भागीदारी की व्याख्या करता है। यह कार्य समाचार से बहुभाषी ईवेंट निष्कर्षण के बारे में है। हमने उप-कार्य 4, घटना जानकारी निष्कर्षण पर ध्यान केंद्रित किया। इस उप-कार्य में एक छोटा प्रशिक्षण डेटासेट है और हमने इस उप-कार्य को हल करने के लिए एक बहुभाषी BERT को ठीक किया है। हमने डेटासेट पर अस्थिरता की समस्या का अध्ययन किया और इसे कम करने की कोशिश की।</abstract_hi>
      <abstract_ja>本稿では、2021年分担タスクのタスク1への参加について解説する。このタスクは、ニュースからの多言語イベント抽出に関するものです。サブタスク4、イベント情報抽出に焦点を当てました。このサブタスクには小さなトレーニングデータセットがあり、このサブタスクを解決するために多言語のBERTを微調整しました。データセット上の不安定性の問題を研究し、それを軽減しようとしました。</abstract_ja>
      <abstract_zh>本文解吾等CASE 2021共事1者与焉。 事涉新闻中多言事。 专于子职4,事信取之。 此子有小练数集,微调多言 BERT 以决此子务。 考其数集上之不稳定性,以图缓之。</abstract_zh>
      <abstract_ga>Mínítear sa pháipéar seo ár rannpháirtíocht i dtasc 1 de thasc comhroinnte CÁS 2021. Baineann an tasc seo le baint imeachtaí ilteangacha as nuacht. Dhíríomar ar fhothasc 4, asbhaint faisnéise imeachtaí. Tá tacar sonraí oiliúna beag ag an bhfothasc seo agus rinneamar BERT ilteangach a mhionchoigeartú chun an fothasc seo a réiteach. Rinneamar staidéar ar an bhfadhb éagobhsaíochta ar an tacar sonraí agus rinneamar iarracht í a mhaolú.</abstract_ga>
      <abstract_ka>ეს დოკუნტი განახსნა ჩვენი დაწყვეტილება CASE 2021-ის გაყოფილი დავალების 1-ში. ეს დავალება მრავალენგური მოვლენების გამოყენებაზე. ჩვენ სამუშაო სამუშაო სამუშაო სამუშაო 4-ზე, მოვლენების ინფორმაციის ექსტრაქციაზე დავყენეთ. ეს სამუშაო სამუშაო სამუშაო სამუშაო მონაცემები აქვს და ჩვენ მრავალენგური BERT-ს გავაკეთებთ ამ სამუშაო სამუშაო სამუშაო ჩვენ მონაცემების პრობლემა შევსწავლოთ და დავცდილოთ მისი შემცირება.</abstract_ka>
      <abstract_hu>Ez a tanulmány bemutatja a CASE 2021 közös feladatának 1. feladatában való részvételünket. Ez a feladat a hírekből való többnyelvű eseménykivonásról szól. A négyes alfeladatra összpontosítottunk, az eseményinformációk kinyerésére. Ez az alfeladat egy kis képzési adatkészlettel rendelkezik, és finomhangoltunk egy többnyelvű BERT-t, hogy megoldjuk ezt az alfeladatot. Tanulmányoztuk az adatkészlet instabilitási problémáját és megpróbáltuk enyhíteni.</abstract_hu>
      <abstract_el>Η παρούσα εργασία εξηγεί τη συμμετοχή μας στο έργο 1 της κοινής εργασίας CASE 2021. Αυτή η εργασία αφορά την εξαγωγή πολύγλωσσων γεγονότων από τις ειδήσεις. Επικεντρωθήκαμε στην υπο-εργασία 4, εξαγωγή πληροφοριών συμβάντων. Αυτή η δευτερεύουσα εργασία έχει ένα μικρό σύνολο δεδομένων κατάρτισης και τελειοποιήσαμε ένα πολύγλωσσο BERT για την επίλυση αυτής της δευτερεύουσας εργασίας. Μελετήσαμε το πρόβλημα αστάθειας στο σύνολο δεδομένων και προσπαθήσαμε να το μετριάσουμε.</abstract_el>
      <abstract_it>Questo articolo spiega la nostra partecipazione al compito 1 del compito condiviso CASE 2021. Questo compito riguarda l'estrazione di eventi multilingue dalle notizie. Ci siamo concentrati sul sub-task 4, estrazione di informazioni sugli eventi. Questo compito secondario ha un piccolo set di dati di formazione e abbiamo perfezionato un BERT multilingue per risolvere questo compito secondario. Abbiamo studiato il problema di instabilità sul set di dati e cercato di mitigarlo.</abstract_it>
      <abstract_kk>Бұл қағаз біздің CASE 2021 жылы ортақ тапсырманың 1- тапсырмаға қатысуымызды түсіндіреді. Бұл тапсырма жаңалықтан бірнеше тілді оқиғаларды тарқату туралы. Біз 4- тапсырманың астындағы мәліметті тарқатуға көздейдік. Бұл ішкі тапсырманың кішкентай оқыту деректер жиыны бар. Біз бұл ішкі тапсырманы шешу үшін көп тілді BERT дегенді баптық. Біз деректер қойындысының дұрыс емес мәселесін зерттеп, оны азайту дегенді көрдік.</abstract_kk>
      <abstract_lt>Šiame dokumente paaiškinamas mūsų dalyvavimas bendros CASE 2021 užduoties 1 užduotyje. This task is about multilingual event extraction from news.  Mes sutelkėme dėmesį į 4-ąją užduotį, renginių informacijos gavimą. Ši subužduotis turi nedidelį mokymo duomenų rinkinį ir mes patobulinome daugiakalbį BERT, kad išspręstume šią subužduotį. Mes ištyrėme nestabilumo problem ą duomenų rinkinyje ir bandėme ją sušvelninti.</abstract_lt>
      <abstract_ms>This paper explains our participation in task 1 of the CASE 2021 shared task.  Tugas ini adalah tentang pengekstrakan peristiwa berbilang bahasa dari berita. Kami fokus pada sub-tugas 4, pengekstrakan maklumat peristiwa. Subtugas ini mempunyai set data latihan kecil dan kami menyesuaikan BERT berbilang bahasa untuk menyelesaikan subtugas ini. Kami mempelajari masalah ketidakstabilan pada set data dan cuba untuk menguranginya.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങളുടെ പങ്കെടുക്കുന്നത് CASE 2021 പങ്കുചേര്‍ത്ത ജോലിയിലെ 1 ജോലി വിശദീകരിക്കുന്ന വാര്‍ത്തകളില്‍ നിന്നും പല ഭാഷകങ്ങളുടെ സംഭവം പുറത്തെടുക്കുന്നതിനെപ്പറ്റിയാണ് ഈ ജോലി. നമ്മള്‍ സബ് ജോലി 4, സംഭവിക്കുന്ന വിവരങ്ങള്‍ എടുക്കാന്‍ ശ്രദ്ധിച്ചു. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this sub-task.  നമ്മള്‍ ഡാറ്റാസറ്റിലെ സ്ഥിരതയുടെ പ്രശ്നം പഠിച്ചു അത് മുളക്കാന്‍ ശ്രമിച്ചു.</abstract_ml>
      <abstract_mt>Dan id-dokument jispjega l-parteċipazzjoni tagħna fil-kompitu 1 tal-kompitu kondiviż CASE 2021. Dan il-kompitu huwa dwar l-estrazzjoni ta’ avvenimenti multilingwi mill-aħbarijiet. Aħna ffukajna fuq is-sottokompitu 4, l-estrazzjoni tal-informazzjoni dwar l-avvenimenti. Dan is-sottokompitu għandu sett żgħir ta’ dejta dwar it-taħriġ u a ħna aġġustajna BERT multilingwi biex issolvi dan is-sottokompitu. Studjajna l-problema tal-instabbiltà fis-sett tad-dejta u ppruvajna nimmitigawha.</abstract_mt>
      <abstract_mn>Энэ цаас CASE 2021 оны хуваалцааны ажлын 1 даалгаврын оролцоог тайлбарладаг. Энэ даалгавар бол мэдээллээс олон хэлний үйл явдал гаргах талаар. Бид 4 дахь ажил дээр анхаарлаа төвлөрсөн. Энэ суб-задалгаанд жижиг сургалтын өгөгдлийн сан байна. Бид энэ суб-задалтыг шийдэхэд олон хэлний BERT-г тодорхойлдог. Бид өгөгдлийн сангийн тогтворгүй асуудлыг судалж, үүнийг багасгах гэж оролдсон.</abstract_mn>
      <abstract_pl>Niniejszy artykuł wyjaśnia nasz udział w zadaniu 1 wspólnym CASE 2021. To zadanie dotyczy wielojęzycznej ekstrakcji zdarzeń z wiadomości. Skupiliśmy się na podzadaniu 4, ekstrakcji informacji o zdarzeniach. To podzadanie ma mały zestaw danych szkoleniowych i dostosowaliśmy wielojęzyczny BERT, aby rozwiązać to podzadanie. Badaliśmy problem niestabilności na zbiorze danych i staraliśmy się go złagodzić.</abstract_pl>
      <abstract_ro>Această lucrare explică participarea noastră la sarcina 1 a sarcinii comune CASE 2021. Această sarcină este despre extragerea evenimentelor multilingve din știri. Ne-am concentrat pe subsarcina 4, extragerea informaţiilor despre evenimente. Această subsarcină are un set mic de date de instruire și am ajustat fin un BERT multilingv pentru a rezolva această subsarcină. Am studiat problema instabilităţii setului de date şi am încercat să o atenuăm.</abstract_ro>
      <abstract_no>Denne papiret forklarer at deltaket vår i oppgåva 1 av delt oppgåva CASE 2021. Denne oppgåva er om fleirspråk hendingar ut frå nyhetar. Vi fokuserte på underoppgåve 4, hendingsinformasjon. Denne underoppgåva har ein liten opplæringsdataset, og vi finn ein fleirspråk BERT for å løysa denne underoppgåva. Vi studerte problem med instabiliteten på datasettet og prøvde å minne det.</abstract_no>
      <abstract_sr>Ovaj papir objašnjava naše sudjelovanje u zadatku 1 zajedničkog zadatka CASE 2021. Ovaj zadatak je o izvlačenju multijezičkih događaja iz vesti. Fokusirali smo se na podzadatak 4, izvlačenje informacija o događajima. Ovaj podzadatak ima mali podatak za obuku i sredili smo multijezički BERT da riješimo ovaj podzadatak. Proučili smo problem nestabilnosti na setu podataka i pokušali ga smanjiti.</abstract_sr>
      <abstract_mk>Овој документ го објаснува нашето учество во задачата 1 на заедничката задача на CASE 2021. Оваа задача е за мнографски извлекување на настани од вестите. We focused on sub-task 4, event information extraction.  Оваа подзадача има мал набор на податоци за тренирање и ние финизиравме мултијазичен BERT за решавање на оваа подзадача. Го проучувавме проблемот со нестабилноста на податоците и се обидовме да го намалиме.</abstract_mk>
      <abstract_so>Qoraalkan wuxuu u caddaynayaa qayb ka qabsashada shaqada 1 ee CASE 2021. Shaqadan waxaa ku saabsan dhacdooyinka luuqadaha kala duduwan ee warbixinta. Waxaynu ku kalsoonaannay shaqo 4, soo saarista macluumaadka dhacdooyinka. Shaqoonkan waxaa ku jira danbiyo yar oo waxbarasho ah, waxaana si wanaagsan u qabannay BERT oo luuqad kala duduwan si aan u xallino shabakadan. Waxaannu wax ka baranay dhibaatada aan adkayn ee shabakadda, waxaana isku daynay in aan hoos u dhigno.</abstract_so>
      <abstract_sv>Denna uppsats förklarar vårt deltagande i uppgift 1 i den delade uppgiften CASE 2021. Den här uppgiften handlar om flerspråkig händelseutvinning från nyheter. Vi fokuserade på underuppgift 4, händelseinformation utvinning. Denna underuppgift har ett litet utbildningsdataset och vi finjusterade en flerspråkig BERT för att lösa denna underuppgift. Vi studerade instabilitetsproblemet på datauppsättningen och försökte mildra det.</abstract_sv>
      <abstract_si>මේ පත්තුව පැහැදිලි කරනවා CASE 2021 වැදගත් වැඩේ 1 වැඩේ අපේ සම්බන්ධතාව පැහැදිලි කරනවා. මේ වැඩේ විශාල භාෂාවක් අවස්ථාවක් නිර්මාණය ගැන. අපි ප්‍රධානය 4 වැඩක් විතරයි, සැකසුම් තොරතුරු නිර්මාණය කරන්න. මේ සබ් කාර්යයේ පොඩි ප්‍රශ්නයක් තියෙනවා පොඩි ප්‍රශ්නයක් තියෙනවා, අපි මේ සබ් කාර්යය විසඳන්න බොහොම භාෂ අපි තොරතුරු සෙට් එකේ ස්ථිර ප්‍රශ්න ප්‍රශ්නයක් පරීක්ෂා කළා, ඒක අඩු කරන්න උත්සාහ කළා.</abstract_si>
      <abstract_ta>இந்த காகிதத்தில் CASE 2021 பகிர்ந்த பணியில் எங்கள் பங்கீடு 1 ஐ விளக்குகிறது. இந்த செய்தியிலிருந்து பல மொழி நிகழ்வு வெளியேறுதல் பற்றியுள்ளது. நாம் துணை செயல் 4, நிகழ்வு தகவல் பெறுதல் மீது கவனம் செலுத்தினோம். இந்த துணை பணியில் ஒரு சிறிய பயிற்சி தகவல் அமைப்பு உள்ளது மற்றும் நாம் இந்த துணை பணியை தீர்க்க ஒரு பல மொழி பெர்ட் நன்றாக ம நாங்கள் தரவுத்தளத்தில் நிலையான பிரச்சனையை படித்து அதை குறைக்க முயற்சித்தோம்.</abstract_ta>
      <abstract_ur>This paper explains our participation in task 1 of the CASE 2021 shared task. یہ کام اخباروں سے بہت سی زبان کی حادثہ اٹھانے کے بارے میں ہے۔ ہم نے سوب-ٹاکس ۴ پر تمرکز کیا، ایڈیون معلومات اخراج. اس سوب-ٹاکس کے پاس ایک چھوٹی ٹرینگ ڈیٹ سٹ ہے اور ہم نے اس سوب-ٹاکس کو حل کرنے کے لئے ایک بہت سی زبان BERT کو درست کر دیا۔ ہم نے ڈیٹ سٹ پر ناکامی مسئلہ کی تلاش کی اور اسے ذلیل کرنے کی کوشش کی۔</abstract_ur>
      <abstract_uz>Бу саҳифа 2021 параметрланган вазифасининг 1 вазифасига шерик бўлишимизни баён қилади. Bu vazifa yangiliklardan bir necha tildagi hodisa chiqarish haqida. We focused on sub-task 4, event information extraction.  Ushbu vazifanda bir kichkina taʼminlovchi maʼlumotlar satri bor va biz bu tub vazifani olish uchun bir nechta tilni BERT'ni yaxshi ko'proq tilga tayyorlamiz. Biz maʼlumotlar sohasida ishlatuvchi muammolarni o'rgandiк va uni o'chirib chiqarishni istadik.</abstract_uz>
      <abstract_vi>Tờ giấy này giải thích sự tham gia của chúng ta trong vụ án 1 của CASE 2021. Nhiệm vụ này là giải cứu các sự kiện đa dạng từ tin tức. Chúng tôi tập trung vào phần phụ nhiệm 4, giải cứu thông tin. Nhiệm vụ phụ này có một bộ dữ liệu đào tạo nhỏ và chúng tôi đã chỉnh sửa lại một cây BERT đa dạng để giải quyết phân công này. Chúng tôi đã nghiên cứu vấn đề không ổn định trên bộ dữ liệu và cố gắng giảm thiểu nó.</abstract_vi>
      <abstract_da>Denne artikel forklarer vores deltagelse i opgave 1 i CASE 2021 delte opgave. Denne opgave handler om flersproget udtrækning af begivenheder fra nyheder. Vi fokuserede på underopgave 4, udvinding af oplysninger. Denne underopgave har et lille træningsdatasæt, og vi finjusterede en flersproget BERT for at løse denne underopgave. Vi studerede ustabilitetsproblemet på datasættet og forsøgte at afbøde det.</abstract_da>
      <abstract_bg>Настоящата статия обяснява участието ни в задача 1 на споделената задача КАСЕ 2021. Тази задача е за извличане на многоезични събития от новини. Фокусирахме се върху подзадача 4, извличане на информация за събитията. Тази подзадача има малък набор от данни за обучение и ние финализирахме многоезичен BERT, за да решим тази подзадача. Проучихме проблема с нестабилността в набора от данни и се опитахме да го смекчим.</abstract_bg>
      <abstract_nl>Dit artikel legt onze deelname aan taak 1 van de gedeelde taak CASE 2021 uit. Deze taak gaat over meertalige event extractie uit nieuws. We concentreerden ons op subtaak 4, event informatie extractie. Deze deeltaak heeft een kleine trainingsdataset en we hebben een meertalige BERT verfijnd om deze deeltaak op te lossen. We bestudeerden het instabiliteitsprobleem op de dataset en probeerden het te beperken.</abstract_nl>
      <abstract_de>Dieses Papier erläutert unsere Teilnahme an Aufgabe 1 der gemeinsamen Aufgabe CASE 2021. Bei dieser Aufgabe geht es um die mehrsprachige Ereignisextraktion aus Nachrichten. Wir konzentrierten uns auf Teilaufgabe 4, Event Information Extraction. Diese Teilaufgabe hat einen kleinen Trainingsdatensatz und wir haben ein mehrsprachiges BERT zur Lösung dieser Teilaufgabe optimiert. Wir haben das Instabilitätsproblem auf dem Datensatz untersucht und versucht, es zu mildern.</abstract_de>
      <abstract_id>Kertas ini menjelaskan kita berpartisipasi dalam tugas 1 dari tugas bersama CASE 2021. Tugas ini adalah tentang ekstraksi peristiwa berbagai bahasa dari berita. Kami fokus pada sub-tugas 4, ekstraksi informasi peristiwa. Subtugas ini memiliki set data pelatihan kecil dan kami memperbaiki BERT berbilang bahasa untuk memecahkan sub tugas ini. We studied the instability problem on the dataset and tried to mitigate it.</abstract_id>
      <abstract_ko>본고는 사례 2021 공유 임무에 참여하는 우리의 임무 1을 설명한다.이 작업은 뉴스에서 다국어 이벤트를 추출하는 것입니다.우리는 하위 작업 4, 이벤트 정보 추출에 전념합니다.이 하위 임무는 작은 훈련 데이터 집합이 있는데, 우리는 여러 언어의 BERT를 조정하여 이 하위 임무를 해결했다.우리는 데이터 집합의 불안정성을 연구하고 그것을 완화시키려고 했다.</abstract_ko>
      <abstract_hr>Ovaj papir objašnjava naše učešće u zadatku 1 zajedničkog zadatka CASE 2021. Ovaj zadatak je o izvlačenju multijezičkih događaja iz vijesti. Fokusirali smo se na podzadatak 4, izvlačenje informacija o događajima. Ovaj podzadatak ima mali podatak za obuku, a mi smo ispravili višejezičku BERT kako bi riješili ovaj podzadatak. Proučili smo problem nestabilnosti na setu podataka i pokušali ga smanjiti.</abstract_hr>
      <abstract_fa>این کاغذ مشارکت ما در وظیفه ۱ از وظیفه مشترک CASE 2021 را توضیح می دهد. این وظیفه درباره اخراج رویداد های زیادی از اخبار است. ما روی زیر کار چهار تمرکز کردیم، اخراج اطلاعات رویداد. این زیر کار یک مجموعه اطلاعات آموزش کوچک دارد و ما یک BERT multilingual را برای حل این زیر کار درست کردیم. ما مشکل غیرقابل استفاده در مجموعه داده ها را مطالعه کردیم و سعی کردیم آن را کاهش دهیم.</abstract_fa>
      <abstract_tr>Bu kagyz biziň CASE 2021 täbliginiň 1-nji görevidiň bölegimizi düşündirir. Bu zady täzelikden köp dilli bolup çykarmak barada. Biz 4-nji buýrukda üns berdik, bolup maglumatlary açmak üçin üns berdik. Bu alt zadyň kiçijik bir okuwçysy bardyr we bu alt zady çözmek üçin bir multi dilli BERT'i düzenledik. Biz veri setindeki ýok meseläni öwrendik we ony azaltmaya synanyşdyk.</abstract_tr>
      <abstract_af>Hierdie papier verduidelik ons deelheid in taak 1 van die Kas 2021 gedeelde taak. Hierdie taak is oor veelvuldige gebeurtenis uitvoer van nuus. Ons fokus op subtaak 4, gebeurtenis inligting uittrek. Hierdie sub-taak het 'n klein onderwerp datastel en ons het 'n multilinguele BERT gewys om hierdie sub-taak te los. Ons het die instabiliteit probleem op die datastel ondersoek en probeer om dit te verminder.</abstract_af>
      <abstract_hy>Այս հոդվածը բացատրում է մեր մասնակցությունը 2021 թվականին ընդհանուր խնդրի 1-ին: Այս խնդիրը նորություններից բազլեզու իրադարձությունների վերացման մասին է: Մենք կենտրոնացանք 4-րդ ենթախնդրի վրա, իրադարձությունների ինֆորմացիայի վերացման վրա: Այս ենթախնդիրը ունի փոքրիկ ուսումնասիրության տվյալներ և մենք բարելավեցինք բազլեզու BER-ը այս ենթախնդիրը լուծելու համար: Մենք ուսումնասիրեցինք տվյալների համակարգի անկայունության խնդիրը և փորձեցինք նվազեցնել այն:</abstract_hy>
      <abstract_sw>Makala hii inaeleza ushiriki wetu katika kazi 1 ya kazi ya CASE 2021 iliyoshirikiana. This task is about multilingual event extraction from news.  Tulijikita kwenye jukumu la 4, utekelezaji wa taarifa za tukio. Mpango huu una takwimu ndogo ya mafunzo na tumetengeneza vizuri BERT kwa lugha mbalimbali ili kutatua jukumu hili. Tumesoma tatizo la kutokuwepo kwa usawa katika seti ya taarifa na tukajaribu kupunguza.</abstract_sw>
      <abstract_az>Bu kağıt CASE 2021 paylaşılmış işin 1. işində bizim işimizi açıqlayır. Bu iş xəbərlərdən çox dilli olaraq çıxarılması haqqında. Biz 4-ci iş, vaxt məlumatlarını çıxartmaq üçün odaqlandıq. Bu sub-task üçün kiçik təhsil veri qurması var və biz bu sub-task çəkmək üçün çoxlu dilli BERT-i düzəltdik. Biz verilənlər qutusunda sərbəstlik problemini təhsil etdik və onu azaltmağa çalışdıq.</abstract_az>
      <abstract_bn>This paper explains our participation in task 1 of the CASE 2021 shared task.  এই কাজ হচ্ছে সংবাদ থেকে বহুভাষায় অনুষ্ঠানের বের করা সম্পর্কে। আমরা সাব-কাজ ৪, অনুষ্ঠানের তথ্য বের করে মনোযোগ দিয়েছি। এই সাব-কাজে একটি ছোট ট্রেনিং ডাটাসেট আছে এবং আমরা এই সাব-কাজ সমাধানের জন্য একটি বহুভাষী বেরেট সুন্দর করেছি। আমরা ডাটাসেটে অস্থিরতা সমস্যা গবেষণা করেছিলাম এবং এটা কমানোর চেষ্টা করেছিলাম।</abstract_bn>
      <abstract_am>ይህ ገጽ በ2021 ካዜ 2021 የተካፈለ ስራ 1 ተግባራችንን ይናገራል፡፡ ይህ ስራ የቋንቋ ቋንቋ ጉዳይ ከዜና ውጭ ነው፡፡ አካባቢ ስራ 4፣ የጉዳዩ መረጃ ምርጫ ለዚህ አካባቢ ስራ ትንሽ ትምህርት ማህበረሰብ ዳታ አለበት እናም ይህንን ደብዳቤ ለመፍታት በብዙ ቋንቋዎች BERT አቀረብን፡፡ የደህነትን መከራ በዳታተር አስተማርነው ሞክረናል፡፡</abstract_am>
      <abstract_sq>Ky dokument shpjegon pjesëmarrjen tonë në detyrën 1 të detyrës së përbashkët të CASE 2021. Kjo detyrë është për nxjerrjen e ngjarjeve shumëgjuhësore nga lajmet. Ne u përqëndruam në nëndetyrën 4, nxjerrjen e informacionit të ngjarjeve. Ky nëndetyrë ka një set të dhënash të vogël trainimit dhe ne rregulluam një BERT shumëgjuhës për të zgjidhur këtë nëndetyrë. Ne studiuam problemin e paqëndrueshmërisë në sistemin e të dhënave dhe u përpoqëm ta lehtësojmë atë.</abstract_sq>
      <abstract_cs>Tento článek vysvětluje naši účast na úkolu 1 sdíleného úkolu CASE 2021. Tento úkol je o vícejazyčné extrakci událostí ze zpráv. Zaměřili jsme se na podúkol 4, extrakci informací o událostech. Tento dílčí úkol má malý výcvikový datový soubor a pro vyřešení tohoto dílčího úkolu jsme doladili vícejazyčný BERT. Studovali jsme problém nestability na datové sadě a snažili se ho zmírnit.</abstract_cs>
      <abstract_bs>Ovaj papir objašnjava našu sudjelovanje u zadatku 1 zajedničkog zadatka CASE 2021. Ovaj zadatak je o izvlačenju multijezičkih događaja iz vijesti. Fokusirali smo se na podzadatak 4, izvlačenje informacija o događajima. Ovaj podzadatak ima mali set podataka za obuku i sredili smo multijezički BERT da riješimo ovaj podzadatak. Proučili smo problem nestabilnosti na setu podataka i pokušali ga smanjiti.</abstract_bs>
      <abstract_fi>Tässä artikkelissa kerrotaan osallistumisestamme CASE 2021 -yhteisen tehtävän tehtävään 1. Tämä tehtävä on monikielinen tapahtuma poimia uutisista. Keskityimme alitehtävään 4, tapahtumatietojen poimimiseen. Tässä osatehtävässä on pieni koulutustietosarja, ja hioimme monikielisen BERT-järjestelmän tämän osatehtävän ratkaisemiseksi. Tutkimme aineiston epävakausongelmaa ja yritimme lieventää sitä.</abstract_fi>
      <abstract_et>Käesolevas dokumendis selgitatakse meie osalemist CASE 2021 jagatud ülesande 1. ülesandes. See ülesanne on mitmekeelne sündmuste väljavõtmine uudistest. Me keskendusime neljandale allülesandele, sündmuste info väljavõtmisele. Sellel alamülesandel on väike koolitusandmete kogum ja me häälestasime selle alamülesande lahendamiseks mitmekeelse BERT-i. Uurisime ebastabiilsuse probleemi andmekogumis ja püüdsime seda leevendada.</abstract_et>
      <abstract_ca>Aquest paper explica la nostra participació en la tasca 1 de la tasca compartida CASE 2021. Aquesta tasca té a veure amb l'extracció multilingüe d'events de les notícies. Ens vam centrar en la subtasca 4, l'extracció d'informació d'eventos. Aquesta subtasca té un petit conjunt de dades d'entrenament i vam ajustar un BERT multilingüe per resoldre aquesta subtasca. We studied the instability problem on the dataset and tried to mitigate it.</abstract_ca>
      <abstract_jv>Perintah sing paling nggawé nggawé ning acara tanggal 1 ning acara DESE 2020 1 Pernak-pernik kuwi karo akeh akeh langkung wigataké ora seneng barang. Awake Sub-task iki nduwe akeh sistem sithik maneh nggawe dataset dan kita ngawe barang multi-lengkang BERT nggawe barang nggawe Sub-task iki. Awak dhéwé ngejaraké perkoro sing beraksi kanggo dataset</abstract_jv>
      <abstract_sk>Ta prispevek pojasnjuje naše sodelovanje pri nalogi 1 skupne naloge CASE 2021. Ta naloga je večjezično pridobivanje dogodkov iz novic. Osredotočili smo se na podnalogo 4, pridobivanje informacij o dogodkih. Ta podnaloga ima majhen nabor podatkov o usposabljanju in za rešitev te podnaloge smo natančno prilagodili večjezični BERT. Proučili smo problem nestabilnosti na naboru podatkov in ga poskušali ublažiti.</abstract_sk>
      <abstract_he>העיתון הזה מסביר את השתתפותנו במשימה 1 של משימה משותפת CASE 2021. This task is about multilingual event extraction from news.  התמקדנו בתפקיד 4, חיפוש מידע לאירוע. This sub-task has a small training dataset and we fine-tuned a multilingual BERT to solve this sub-task.  למדנו את בעיית אי יציבות במערכת המידע וניסינו להקל עליה.</abstract_he>
      <abstract_ha>This paper explains our participation in task 1 of the CASE 2021 shared task.  Wannan aikin yana da shirin ayuka masu yawa daga lãbãri. Mun yi zura cikin ƙanni na aikin 4, samun masu zartar da information. Wannan sub-aikin yana da wani danne mai ƙaranci na tsari, kuma mun gyara wani na'ura na BERT da mulki-harshe dõmin ya raba wannan bincike. Mun karanta matabbata na'ura a kan database, kuma muka yi jarraba cire shi.</abstract_ha>
      <abstract_bo>ཤོག་བྱང་འདིས་ང་ཚོའི་རྒྱལ་ཁབ་དེ་འདིས་CASE 2021 རིང་གི་བྱ་འགུལ་ཐོག་ལས་༡་དེ་འགྲེལ་བཤད་ཐུབ། བྱ་འགུལ་འདི་ནི་བརྡ་ཞིག་ནས་སྐད་ཡིག་ཆ་འཕྲིན་ནས་ཕྱིར་འདོན་བྱེད་པའི་སྐོར་ཡིན། ང་ཚོས་བྱ་འགུལ་འདི་བཞིན་པ་དང་བྱ་འགུལ་ཆ་ཕྱིར་འདོན་པའི་ལྟ་བུ་གནང་བ་ཡོད། Sub-task འདིས་ལྟ་བུའི་ནང་དུ་གཞུང་སྒྲིག་ཆ་ཆུང་ཀུ་ཞིག་ཡོད་པ་ལས་ངེད་ཚོས་སྒྲུང་མང་ཆེ་ཤོས་ཀྱི་BERT་ལ་གཞུང་གི་ཐབས་ ང་ཚོས་གཞུང་ཚབ་ནང་གི་ཐད་ཆོས་ཀྱི་དཀའ་ངལ་ལྷག་བྱས་ནས་དེ་ཆུང་དུ་གཏོང་བ་རེད།</abstract_bo>
      </paper>
    <paper id="22">
      <title>Team DaDeFrNi at CASE 2021 Task 1 : Document and Sentence Classification for Protest Event Detection<fixed-case>D</fixed-case>a<fixed-case>D</fixed-case>e<fixed-case>F</fixed-case>r<fixed-case>N</fixed-case>i” at <fixed-case>CASE</fixed-case> 2021 Task 1: Document and Sentence Classification for Protest Event Detection</title>
      <author><first>Francesco</first><last>Re</last></author>
      <author><first>Daniel</first><last>Vegh</last></author>
      <author><first>Dennis</first><last>Atzenhofer</last></author>
      <author><first>Niklas</first><last>Stoehr</last></author>
      <pages>171–178</pages>
      <abstract>This paper accompanies our top-performing submission to the CASE 2021 shared task, which is hosted at the workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text. Subtasks 1 and 2 of Task 1 concern the classification of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">newspaper articles</a> and sentences into conflict versus not conflict-related in four different languages. Our model performs competitively in both subtasks (up to 0.8662 macro F1), obtaining the highest score of all contributions for subtask 1 on Hindi articles (0.7877 macro F1). We describe all experiments conducted with the XLM-RoBERTa (XLM-R) model and report results obtained in each binary classification task. We propose supplementing the original training data with additional data on political conflict events. In addition, we provide an analysis of <a href="https://en.wikipedia.org/wiki/Grammatical_number">unigram probability estimates</a> and <a href="https://en.wikipedia.org/wiki/Geographic_data_and_information">geospatial references</a> contained within the original training corpus.</abstract>
      <url hash="b2261046">2021.case-1.22</url>
      <doi>10.18653/v1/2021.case-1.22</doi>
      <bibkey>re-etal-2021-team</bibkey>
    </paper>
    <paper id="23">
      <title>Fine-grained Event Classification in News-like Text Snippets-Shared Task 2, CASE 2021<fixed-case>CASE</fixed-case> 2021</title>
      <author><first>Jacek</first><last>Haneczok</last></author>
      <author><first>Guillaume</first><last>Jacquet</last></author>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Nicolas</first><last>Stefanovitch</last></author>
      <pages>179–192</pages>
      <abstract>This paper describes the Shared Task on Fine-grained Event Classification in News-like Text Snippets. The Shared Task is divided into three sub-tasks : (a) classification of text snippets reporting socio-political events (25 classes) for which vast amount of training data exists, although exhibiting different structure and style vis-a-vis test data, (b) enhancement to a generalized zero-shot learning problem, where 3 additional event types were introduced in advance, but without any training data (‘unseen’ classes), and (c) further extension, which introduced 2 additional event types, announced shortly prior to the evaluation phase. The reported Shared Task focuses on classification of events in English texts and is organized as part of the Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021), co-located with the ACL-IJCNLP 2021 Conference. Four teams participated in the task. Best performing systems for the three aforementioned sub-tasks achieved 83.9 %, 79.7 % and 77.1 % weighted F1 scores respectively.</abstract>
      <url hash="70dd2284">2021.case-1.23</url>
      <doi>10.18653/v1/2021.case-1.23</doi>
      <bibkey>haneczok-etal-2021-fine</bibkey>
    </paper>
    <paper id="25">
      <title>CASE 2021 Task 2 : Zero-Shot Classification of Fine-Grained Sociopolitical Events with Transformer Models<fixed-case>CASE</fixed-case> 2021 Task 2: Zero-Shot Classification of Fine-Grained Sociopolitical Events with Transformer Models</title>
      <author><first>Benjamin J.</first><last>Radford</last></author>
      <pages>203–207</pages>
      <abstract>We introduce a <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for the classification of texts into fine-grained categories of sociopolitical events. This particular method is responsive to all three Subtasks of Task 2, Fine-Grained Classification of Socio-Political Events, introduced at the CASE workshop of ACL-IJCNLP 2021. We frame Task 2 as textual entailment : given an input text and a candidate event class (query), the model predicts whether the text describes an event of the given type. The <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is able to correctly classify in-sample event types with an average <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a> of 0.74 but struggles with some out-of-sample event types. Despite this, the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> shows promise for the zero-shot identification of certain sociopolitical events by achieving an F1-score of 0.52 on one wholly out-of-sample event class.</abstract>
      <url hash="4bf88429">2021.case-1.25</url>
      <doi>10.18653/v1/2021.case-1.25</doi>
      <bibkey>radford-2021-case</bibkey>
      <revision id="1" href="2021.case-1.25v1" hash="089355ad" />
      <revision id="2" href="2021.case-1.25v2" hash="4bf88429" date="2021-08-12">Corrected a typo in Table 2</revision>
    </paper>
    </volume>
</collection>