<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.woah">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 5th Workshop on Online Abuse and Harms (WOAH 2021)</booktitle>
      <editor><first>Aida</first><last>Mostafazadeh Davani</last></editor>
      <editor><first>Douwe</first><last>Kiela</last></editor>
      <editor><first>Mathias</first><last>Lambert</last></editor>
      <editor><first>Bertie</first><last>Vidgen</last></editor>
      <editor><first>Vinodkumar</first><last>Prabhakaran</last></editor>
      <editor><first>Zeerak</first><last>Waseem</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="747477a4">2021.woah-1</url>
    </meta>
    <frontmatter>
      <url hash="7df1a565">2021.woah-1.0</url>
      <bibkey>woah-2021-online</bibkey>
    </frontmatter>
    <paper id="10">
      <title>Improving Counterfactual Generation for Fair Hate Speech Detection</title>
      <author><first>Aida</first><last>Mostafazadeh Davani</last></author>
      <author><first>Ali</first><last>Omrani</last></author>
      <author><first>Brendan</first><last>Kennedy</last></author>
      <author><first>Mohammad</first><last>Atari</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Morteza</first><last>Dehghani</last></author>
      <pages>92–101</pages>
      <abstract>Bias mitigation approaches reduce models’ dependence on sensitive features of data, such as social group tokens (SGTs), resulting in equal predictions across the sensitive features. In <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech detection</a>, however, equalizing model predictions may ignore important differences among targeted social groups, as <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> can contain stereotypical language specific to each SGT. Here, to take the specific language about each SGT into account, we rely on counterfactual fairness and equalize predictions among counterfactuals, generated by changing the SGTs. Our method evaluates the similarity in sentence likelihoods (via pre-trained language models) among <a href="https://en.wikipedia.org/wiki/Counterfactual_conditional">counterfactuals</a>, to treat SGTs equally only within interchangeable contexts. By applying logit pairing to equalize outcomes on the restricted set of counterfactuals for each instance, we improve fairness metrics while preserving model performance on hate speech detection.</abstract>
      <url hash="288ee55e">2021.woah-1.10</url>
      <doi>10.18653/v1/2021.woah-1.10</doi>
      <bibkey>mostafazadeh-davani-etal-2021-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="15">
      <title>Context Sensitivity Estimation in Toxicity Detection</title>
      <author><first>Alexandros</first><last>Xenos</last></author>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>140–145</pages>
      <abstract>User posts whose perceived toxicity depends on the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">conversational context</a> are rare in current toxicity detection datasets. Hence, toxicity detectors trained on current datasets will also disregard <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>, making the detection of context-sensitive toxicity a lot harder when it occurs. We constructed and publicly release a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of 10k posts with two kinds of toxicity labels per post, obtained from annotators who considered (i) both the current post and the previous one as context, or (ii) only the current post. We introduce a new task, context-sensitivity estimation, which aims to identify posts whose perceived toxicity changes if the context (previous post) is also considered. Using the new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, we show that <a href="https://en.wikipedia.org/wiki/System">systems</a> can be developed for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Such systems could be used to enhance toxicity detection datasets with more context-dependent posts or to suggest when moderators should consider the parent posts, which may not always be necessary and may introduce additional costs.</abstract>
      <url hash="c94e092b">2021.woah-1.15</url>
      <doi>10.18653/v1/2021.woah-1.15</doi>
      <bibkey>xenos-etal-2021-context</bibkey>
    </paper>
    <paper id="18">
      <title>When the Echo Chamber Shatters : Examining the Use of Community-Specific Language Post-Subreddit Ban</title>
      <author><first>Milo</first><last>Trujillo</last></author>
      <author><first>Sam</first><last>Rosenblatt</last></author>
      <author><first>Guillermo</first><last>de Anda Jáuregui</last></author>
      <author><first>Emily</first><last>Moog</last></author>
      <author><first>Briane Paul V.</first><last>Samson</last></author>
      <author><first>Laurent</first><last>Hébert-Dufresne</last></author>
      <author><first>Allison M.</first><last>Roth</last></author>
      <pages>164–178</pages>
      <abstract>Community-level bans are a common tool against groups that enable <a href="https://en.wikipedia.org/wiki/Cyberbullying">online harassment</a> and <a href="https://en.wikipedia.org/wiki/Cyberbullying">harmful speech</a>. Unfortunately, the efficacy of community bans has only been partially studied and with mixed results. Here, we provide a flexible <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised methodology</a> to identify in-group language and track user activity on <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a> both before and after the ban of a community (subreddit). We use a simple word frequency divergence to identify uncommon words overrepresented in a given <a href="https://en.wikipedia.org/wiki/Community">community</a>, not as a proxy for harmful speech but as a linguistic signature of the community. We apply our method to 15 banned subreddits, and find that community response is heterogeneous between <a href="https://en.wikipedia.org/wiki/Reddit">subreddits</a> and between users of a <a href="https://en.wikipedia.org/wiki/Reddit">subreddit</a>. Top users were more likely to become less active overall, while random users often reduced use of in-group language without decreasing activity. Finally, we find some evidence that the effectiveness of <a href="https://en.wikipedia.org/wiki/Ban_(law)">bans</a> aligns with the content of a community. Users of dark humor communities were largely unaffected by bans while users of communities organized around <a href="https://en.wikipedia.org/wiki/White_supremacy">white supremacy</a> and <a href="https://en.wikipedia.org/wiki/Fascism">fascism</a> were the most affected. Altogether, our results show that <a href="https://en.wikipedia.org/wiki/Ban_(law)">bans</a> do not affect all groups or users equally, and pave the way to understanding the effect of <a href="https://en.wikipedia.org/wiki/Ban_(law)">bans</a> across communities.</abstract>
      <url hash="018d8659">2021.woah-1.18</url>
      <attachment type="OptionalSupplementaryMaterial" hash="96cf3135">2021.woah-1.18.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.woah-1.18</doi>
      <bibkey>trujillo-etal-2021-echo</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="19">
      <title>Targets and Aspects in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> Hate Speech</title>
      <author><first>Alexander</first><last>Shvets</last></author>
      <author><first>Paula</first><last>Fortuna</last></author>
      <author><first>Juan</first><last>Soler</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>179–190</pages>
      <abstract>Mainstream research on <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories. This may be sufficient if the goal is to detect and delete abusive language posts. However, removal is not always possible due to the legislation of a country. Also, there is evidence that <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> can not be successfully combated by merely removing <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech posts</a> ; they should be countered by <a href="https://en.wikipedia.org/wiki/Education">education</a> and counter-narratives. For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain. The outcome of the experiments is promising and can serve as inspiration for further work on the task</abstract>
      <url hash="ff060c2c">2021.woah-1.19</url>
      <doi>10.18653/v1/2021.woah-1.19</doi>
      <bibkey>shvets-etal-2021-targets</bibkey>
      <pwccode url="https://github.com/talnupf/hatespeechtargetsaspects" additional="false">talnupf/hatespeechtargetsaspects</pwccode>
    <title_ar>أهداف وجوانب في خطاب الكراهية على مواقع التواصل الاجتماعي</title_ar>
      <title_pt>Alvos e Aspectos do Discurso de Ódio nas Mídias Sociais</title_pt>
      <title_fr>Cibles et aspects du discours de haine sur les réseaux sociaux</title_fr>
      <title_es>Objetivos y aspectos en el discurso de odio en las redes sociales</title_es>
      <title_ja>ソーシャルメディアのヘイトスピーチのターゲットと側面</title_ja>
      <title_zh>社交媒体怨言之所在</title_zh>
      <title_hi>लक्ष्य और सामाजिक मीडिया हेट स्पीच में पहलू</title_hi>
      <title_ru>Цели и аспекты ненавистнических высказываний в социальных сетях</title_ru>
      <title_ga>Spriocanna agus Gnéithe sna Meáin Shóisialta Is fuath liom Caint</title_ga>
      <title_ka>სოციალური მედიაში მიზეზები და აზეკტები</title_ka>
      <title_hu>Célok és aspektusok a közösségi média gyűlölet beszédében</title_hu>
      <title_el>Στόχοι και πτυχές στην ομιλία μίσους στα μέσα κοινωνικής δικτύωσης</title_el>
      <title_it>Obiettivi e aspetti nel discorso di odio sui social media</title_it>
      <title_lt>Social in ės žiniasklaidos neapykantos kalbos tikslai ir aspektai</title_lt>
      <title_kk>Социалдық медиаға қарсы сөздерінің мақсаттары мен аспектері</title_kk>
      <title_ms>Sasaran dan Aspekt dalam Ucapan Kebencian Media Sosial</title_ms>
      <title_mt>Targets and Aspects in Social Media Hate Speech</title_mt>
      <title_mk>Targets and Aspects in Social Media Hate Speech</title_mk>
      <title_pl>Cele i aspekty w mowie nienawiści mediów społecznościowych</title_pl>
      <title_ro>Obiective și aspecte în discursul de ură al rețelelor sociale</title_ro>
      <title_ml>സോഷ്യല്‍ മീഡിയ വെറുപ്പ് സംസാരിക്കുന്ന ലക്ഷ്യങ്ങളും ഭാഷകളും</title_ml>
      <title_sr>Meta i aspekti u govoru o mržnji društvenim medijima</title_sr>
      <title_si>සාමාජික මධ්‍යමාධ්‍යම විරෝධ කතාවයේ ලක්ෂණය සහ අනතුරුවන්</title_si>
      <title_no>Comment</title_no>
      <title_so>Goobaha iyo aragtida ee ku qoran hadalka nebcaada sooshalka</title_so>
      <title_sv>Mål och aspekter i sociala medier hattal</title_sv>
      <title_ur>سوسیل میڈیا ناپسند بات میں موجود اور آسپٹ</title_ur>
      <title_ta>சமூக ஊடகத்தில் இலக்குகள் மற்றும் பார்வைகள் வெறுப்பு பேச்சு</title_ta>
      <title_mn>Нийгмийн мэдээллийн дуртай ярианд зориулалт болон хариу үзүүлэлт</title_mn>
      <title_uz>Name</title_uz>
      <title_vi>Mục tiêu và khía cạnh trong tiếng nói ghét truyền thông xã hội</title_vi>
      <title_bg>Цели и аспекти в речта на омразата в социалните медии</title_bg>
      <title_hr>Ciljevi i aspekti u govoru o mržnji društvenim medijima</title_hr>
      <title_da>Mål og aspekter i sociale medier Had Tale</title_da>
      <title_nl>Doelstellingen en aspecten in Hate Speech op sociale media</title_nl>
      <title_fa>هدف و اشکال در سخنرانی متنفر رسانه اجتماعی</title_fa>
      <title_ko>소셜 미디어가 언론을 증오하는 목표와 방면</title_ko>
      <title_de>Ziele und Aspekte in Social Media Hate Speech</title_de>
      <title_id>Targets and Aspects in Social Media Hate Speech</title_id>
      <title_af>Name</title_af>
      <title_sw>Tarehe na mtazamo katika Hotuba ya Kuchukia Mitandao ya Kijamii</title_sw>
      <title_tr>Sosyal Maglumaty nyň sözlerinde maksadlar we aspektler</title_tr>
      <title_hy>Սոցիալական լրատվամիջոցների ատելության խոսքի նպատակները և հարցերը</title_hy>
      <title_az>Sosyal Media Nefr톛ti S칬zl톛rind톛 He칞 v톛 Aspektl톛r</title_az>
      <title_am>ማኅበራዊ ሚዲያ ውስጥ የሚጠሉ ቃላት እና ጉዳዮች</title_am>
      <title_sq>Objektivi dhe aspektet në fjalimin e urrejtjes së medias sociale</title_sq>
      <title_bn>সামাজিক প্রচার মাধ্যমের লক্ষ্য এবং দৃষ্টিভঙ্গি ঘৃণা ভাষণ</title_bn>
      <title_cs>Cíle a aspekty v projevu nenávisti sociálních médií</title_cs>
      <title_bs>Ciljevi i aspekti u govoru o mržnji društvenim medijima</title_bs>
      <title_et>Sotsiaalmeedia vihkamise kõne eesmärgid ja aspektid</title_et>
      <title_fi>Sosiaalisen median vihapuheen tavoitteet ja näkökulmat</title_fi>
      <title_ca>Els objectius i aspectes del discurs d'odi dels mitjans socials</title_ca>
      <title_jv>TarGet lan Aspect nang Panjenengan Media Normal</title_jv>
      <title_sk>Cilji in vidiki sovražnega govora na družbenih medijih</title_sk>
      <title_he>מטרות ואפקטים במדיה החברתית</title_he>
      <title_ha>Target and Aspects in Jamii Media Hate Spelling</title_ha>
      <title_bo>སྤྱི་ཚོགས་འབྲེལ་མཐུད་འབྲེལ་མཐུད་བརྗོད་ལ་འགྲོ་སྟངས་དང་Aspects</title_bo>
      <abstract_ar>ركزت الأبحاث السائدة حول خطاب الكراهية بشكل رئيسي حتى الآن على مهمة تصنيف منشورات وسائل التواصل الاجتماعي بشكل أساسي فيما يتعلق بالأنماط المحددة مسبقًا لفئات خطاب الكراهية الرديئة إلى حد ما. قد يكون هذا كافيًا إذا كان الهدف هو اكتشاف وحذف مشاركات اللغة المسيئة. ومع ذلك ، فإن الإزالة ليست ممكنة دائمًا بسبب تشريعات الدولة. كما أن هناك أدلة على أن خطاب الكراهية لا يمكن مكافحته بنجاح بمجرد إزالة منشورات الكلام الذي يحض على الكراهية ؛ يجب مواجهتهم بالتثقيف والروايات المضادة. لهذا الغرض ، نحتاج إلى تحديد (1) من هو الهدف في منشور خطاب كراهية معين ، و (2) ما هي جوانب (أو خصائص) الهدف المنسوبة إلى الهدف في المنشور. كأول تقدير تقريبي ، نقترح تكييف نموذج استخراج مفهوم عام حديث مع مجال خطاب الكراهية. نتائج التجارب واعدة ويمكن أن تكون مصدر إلهام لمزيد من العمل في المهمة</abstract_ar>
      <abstract_es>La investigación general sobre la incitación al odio se centró hasta ahora predominantemente en la tarea de clasificar principalmente las publicaciones en las redes sociales con respecto a tipologías predefinidas de categorías de discurso de odio bastante groseras. Esto puede ser suficiente si el objetivo es detectar y eliminar publicaciones en idiomas abusivos. Sin embargo, la expulsión no siempre es posible debido a la legislación de un país. Además, hay pruebas de que la incitación al odio no se puede combatir con éxito simplemente eliminando los mensajes de incitación al odio; deben contrarrestarse con educación y contra-narrativas. Para ello, necesitamos identificar (i) quién es el objetivo en una publicación de discurso de odio determinada, y (ii) qué aspectos (o características) del objetivo se atribuyen al objetivo en la publicación. Como primera aproximación, proponemos adaptar un modelo genérico de extracción de conceptos de última generación al dominio de la incitación al odio. El resultado de los experimentos es prometedor y puede servir de inspiración para seguir trabajando en la tarea.</abstract_es>
      <abstract_fr>La recherche courante sur le discours de haine s'est concentrée jusqu'à présent principalement sur la tâche de classer principalement les publications sur les réseaux sociaux en fonction de typologies prédéfinies de catégories de discours de haine plutôt grossières. Cela peut être suffisant si l'objectif est de détecter et de supprimer les publications linguistiques abusives. Toutefois, le renvoi n'est pas toujours possible en raison de la législation d'un pays. En outre, il est prouvé que les discours de haine ne peuvent pas être combattus avec succès en supprimant simplement les messages de haine ; ils devraient être contrés par l'éducation et les contre-discours. À cette fin, nous devons identifier (i) qui est la cible dans un message de discours haineux donné, et (ii) quels aspects (ou caractéristiques) de la cible sont attribués à la cible dans la publication. En première approximation, nous proposons d'adapter un modèle générique d'extraction de concepts de pointe au domaine des discours haineux. Les résultats des expériences sont prometteurs et peuvent servir d'inspiration pour la poursuite des travaux sur cette tâche.</abstract_fr>
      <abstract_pt>A principal pesquisa sobre discurso de ódio se concentrou até agora predominantemente na tarefa de classificar principalmente postagens de mídia social em relação a tipologias predefinidas de categorias de discurso de ódio bastante grosseiras. Isso pode ser suficiente se o objetivo for detectar e excluir postagens de linguagem abusiva. No entanto, a remoção nem sempre é possível devido à legislação de um país. Além disso, há evidências de que o discurso de ódio não pode ser combatido com sucesso simplesmente removendo postagens de discurso de ódio; eles devem ser combatidos pela educação e contra-narrativas. Para isso, precisamos identificar (i) quem é o alvo em um determinado post de discurso de ódio e (ii) quais aspectos (ou características) do alvo são atribuídos ao alvo no post. Como primeira aproximação, propomos adaptar um modelo genérico de extração de conceitos de última geração para o domínio do discurso de ódio. O resultado dos experimentos é promissor e pode servir de inspiração para futuros trabalhos na tarefa</abstract_pt>
      <abstract_ja>これまでのヘイトスピーチに関する主流の研究は、主にソーシャルメディアの投稿を、かなり粗い粒度のヘイトスピーチカテゴリの事前定義された類型に関連して分類する作業に焦点を当てていた。これは、罵倒的な言葉の投稿を検出して削除することを目的としている場合には十分な場合があります。ただし、国の法律により、必ずしも除外が可能ではありません。また、ヘイトスピーチの投稿を削除するだけでは、ヘイトスピーチに対抗できないという証拠があります。それらは教育や反論で対抗すべきです。この目的のためには、(i)特定のヘイトスピーチ投稿のターゲットは誰か、(ii)ターゲットのどの側面（または特徴）が投稿のターゲットに帰属するかを特定する必要があります。最初の近似として、一般的な最先端の概念抽出モデルをヘイトスピーチ領域に適応させることを提案します。実験の結果は有望であり、タスクに関するさらなる作業のインスピレーションとなる可能性がある</abstract_ja>
      <abstract_zh>及目前为止,仇言之主,归于社交媒体帖粗恶之预定义分类也。 若检删骂性语言帖子,庶几足矣。 然国家立法,删之不可常得也。 此外,有证明,但以删仇言帖,无以成功击怨之言。 教反难之。 须定(i)谁是给定恨言帖中的,及(ii)的哪些方面(或特征)归因于帖子中的。 为首近似值,议取通用最先进之概于仇言之域。 实验果有望,可以为事。</abstract_zh>
      <abstract_ru>Основное исследование ненавистнических высказываний до сих пор было сосредоточено преимущественно на задаче классификации в основном постов в социальных сетях в отношении предопределенных типологий довольно грубо выраженных категорий ненавистнических высказываний. Этого может быть достаточно, если цель заключается в выявлении и удалении оскорбительных лингвистических постов. Однако выдворение не всегда возможно из-за законодательства страны. Кроме того, есть свидетельства того, что с ненавистническими высказываниями нельзя успешно бороться, просто удалив сообщения о ненавистнических высказываниях; им следует противостоять с помощью образования и контрнаративов. Для этого нам нужно определить (i), кто является целью в данной публикации с высказываниями на почве ненависти, и (ii) какие аспекты (или характеристики) цели приписываются цели в записи. В качестве первого приближения мы предлагаем адаптировать универсальную современную модель извлечения понятий к области ненавистнических высказываний. Результаты экспериментов являются многообещающими и могут послужить вдохновением для дальнейшей работы над задачей</abstract_ru>
      <abstract_hi>हेट स्पीच पर मुख्यधारा के शोध ने अब तक मुख्य रूप से मुख्य रूप से सोशल मीडिया पोस्ट को वर्गीकृत करने के कार्य पर ध्यान केंद्रित किया है, बल्कि मोटे-दाने वाले घृणा भाषण श्रेणियों के पूर्वनिर्धारित टाइपोलॉजी के संबंध में। यह पर्याप्त हो सकता है यदि लक्ष्य अपमानजनक भाषा पोस्ट का पता लगाने और हटाने के लिए है। हालांकि, किसी देश के कानून के कारण निष्कासन हमेशा संभव नहीं होता है। इसके अलावा, इस बात के सबूत हैं कि हेट स्पीच को केवल हेट स्पीच पोस्ट को हटाकर सफलतापूर्वक मुकाबला नहीं किया जा सकता है; उन्हें शिक्षा और प्रति-कथाओं द्वारा मुकाबला किया जाना चाहिए। इस उद्देश्य के लिए, हमें यह पहचानने की आवश्यकता है (i) किसी दिए गए हेट स्पीच पोस्ट में लक्ष्य कौन है, और (ii) लक्ष्य के किन पहलुओं (या विशेषताओं) को पोस्ट में लक्ष्य के लिए जिम्मेदार ठहराया जाता है। पहले सन्निकटन के रूप में, हम नफरत भाषण डोमेन के लिए एक सामान्य राज्य के कला अवधारणा निष्कर्षण मॉडल को अनुकूलित करने का प्रस्ताव करते हैं। प्रयोगों का परिणाम आशाजनक है और कार्य पर आगे के काम के लिए प्रेरणा के रूप में काम कर सकता है</abstract_hi>
      <abstract_ga>Dhírigh taighde príomhshrutha ar chaint fuath go dtí seo go príomha ar an tasc a bhaineann le postálacha meán sóisialta a rangú go príomha maidir le tíopeolaíochtaí réamhshainithe de chatagóirí gráin chainte atá sách garbh. B’fhéidir gur leor é seo más é an sprioc postálacha teanga maslacha a bhrath agus a scriosadh. Mar sin féin, ní féidir é a bhaint i gcónaí mar gheall ar reachtaíocht tíre. Chomh maith leis sin, tá fianaise ann nach féidir fuathchaint a chomhrac go rathúil trí phoist fuathchaint a bhaint; ba chóir go gcuirfeadh oideachas agus frith-inscne ina gcoinne. Chun na críche sin, ní mór dúinn a aithint (i) cé hé/hí an sprioc i bpost cainte gráin tugtha, agus (ii) cad iad na gnéithe (nó tréithe) den sprioc a chuirtear i leith na sprice sa phost. Mar an chéad mheastachán, tá sé beartaithe againn samhail eastósctha coincheap úrscothach cineálach a oiriúnú don fhearann fuathchaint. Tá toradh na dturgnaimh dóchasach agus féadann sé bheith mar inspioráid le haghaidh tuilleadh oibre ar an tasc</abstract_ga>
      <abstract_hu>A gyűlöletbeszéd általános kutatásai eddig elsősorban a közösségi média posztok osztályozásának feladatára összpontosították a meglehetősen durva szemű gyűlöletbeszéd kategóriák előre meghatározott tipológiáinak tekintetében. Ez elegendő lehet, ha a cél a visszaélő nyelvi bejegyzések észlelése és törlése. Az eltávolítás azonban nem mindig lehetséges egy ország jogszabályai miatt. Továbbá bizonyíték van arra, hogy a gyűlöletbeszéd nem küzdhető sikeresen a gyűlöletbeszéd bejegyzéseinek pusztán eltávolításával; oktatásnak és ellennarratíváknak kell ellensúlyozniuk őket. Ebből a célból azonosítani kell (i) ki a célpont egy adott gyűlöletbeszéd posztban, és (ii) a célpont milyen aspektusait (vagy jellemzőit) tulajdonítják a célpontnak a posztban. Első közelítésként azt javasoljuk, hogy egy általános, korszerű koncepciókivonási modellt adaptáljunk a gyűlölet beszéd területéhez. A kísérletek eredménye ígéretes és inspirációként szolgálhat a feladat további munkájához</abstract_hu>
      <abstract_el>Η κύρια έρευνα για την ρητορική μίσους επικεντρώθηκε μέχρι στιγμής κυρίως στην ταξινόμηση των δημοσιεύσεων στα μέσα κοινωνικής δικτύωσης σε σχέση με προκαθορισμένες τυπολογίες μάλλον χονδροειδείς κατηγορίες ρητορικής μίσους. Αυτό μπορεί να είναι αρκετό εάν ο στόχος είναι ο εντοπισμός και η διαγραφή καταχρηστικών γλωσσικών δημοσιεύσεων. Ωστόσο, η απομάκρυνση δεν είναι πάντα δυνατή λόγω της νομοθεσίας μιας χώρας. Επίσης, υπάρχουν αποδείξεις ότι η ρητορική μίσους δεν μπορεί να καταπολεμηθεί επιτυχώς καταργώντας απλώς δημοσιεύσεις ρητορικής μίσους. Θα πρέπει να αντιμετωπιστούν με εκπαίδευση και αντιπαράθεση. Για το σκοπό αυτό, πρέπει να προσδιορίσουμε (i) ποιος είναι ο στόχος σε μια συγκεκριμένη δημοσίευση ομιλίας μίσους και (ii) ποιες πτυχές (ή χαρακτηριστικά) του στόχου αποδίδονται στον στόχο στη δημοσίευση. Ως πρώτη προσέγγιση, προτείνουμε την προσαρμογή ενός γενικού μοντέλου εξαγωγής εννοιών τελευταίας τεχνολογίας στον τομέα της ομιλίας μίσους. Το αποτέλεσμα των πειραμάτων είναι ελπιδοφόρο και μπορεί να χρησιμεύσει ως έμπνευση για περαιτέρω εργασία στο έργο.</abstract_el>
      <abstract_lt>Pagrindiniai neapykantos kalbos moksliniai tyrimai iki šiol daugiausia buvo susiję su užduotimi klasifikuoti daugiausia socialinės žiniasklaidos pareigas iš anksto apibrėžtų neapykantos kalbos kategorijų tipologijų atžvilgiu. Tai gali pakakti, jei tikslas – nustatyti ir ištrinti piktnaudžiaujančius kalbinius postus. Tačiau dėl šalies teisės aktų pašalinimas ne visada įmanomas. Be to, yra įrodymų, kad neapykantos kalbos negalima sėkmingai kovoti tik pašalinant neapykantos kalbos pareigas; jiems turėtų būti taikomos švietimo ir priešpriešinės narracijos. Šiuo tikslu turime nustatyti i) kas yra tikslinis tam tikroje neapykantos kalbos vietoje ir ii) kokie tikslinio rodiklio aspektai (arba savybės) priskiriami tiksliniam pareigūnui. Kaip pirmasis suderinimas siūlome pritaikyti generinį naujausios koncepcijos ekstrahavimo model į prie neapykantos kalbos srities. The outcome of the experiments is promising and can serve as inspiration for further work on the task</abstract_lt>
      <abstract_it>La ricerca principale sul discorso d'odio si è finora concentrata prevalentemente sul compito di classificare principalmente i post sui social media rispetto a tipologie predefinite di categorie di discorsi d'odio piuttosto grossolani. Questo può essere sufficiente se l'obiettivo è rilevare ed eliminare messaggi in lingua abusiva. Tuttavia, la rimozione non è sempre possibile a causa della legislazione di un paese. Inoltre, ci sono prove che i discorsi di odio non possono essere combattuti con successo semplicemente rimuovendo i messaggi di incitamento all'odio; dovrebbero essere contrastate dall'educazione e dalle contronarrazioni. A tal fine, dobbiamo identificare (i) chi è il bersaglio in un determinato post di incitamento all'odio, e (ii) quali aspetti (o caratteristiche) del bersaglio sono attribuiti al bersaglio nel post. Come prima approssimazione, proponiamo di adattare un modello generico di estrazione di concetti all'avanguardia al dominio dell'incitamento all'odio. Il risultato degli esperimenti è promettente e può servire da ispirazione per ulteriori lavori sul compito</abstract_it>
      <abstract_mk>Главните истражувања за говорот на омраза се фокусираа досега претежно на задачата да се класификуваат главно позиции на социјалните медиуми во однос на преддефинираните типологии на прилично груби категории на говор на омраза. Ова може да биде доволно ако целта е да се откријат и избришат злоупотребни јазички постови. Сепак, отстранувањето не е секогаш можно поради легислативата на една земја. Исто така, постојат докази дека говорот за омраза не може да биде успешно борен само со отстранување на местата за говор за омраза; тие треба да се спротивстават од образование и контра-приказни. За оваа цел, мораме да идентификуваме (i) кој е метата во одредена позиција за говор на омраза, и (ii) кои аспекти (или карактеристики) на метата се припишани на метата во позицијата. Како прва приближување, предлагаме да се адаптира генерален модел на екстракција на најнов концепт на доменот на говорот за омраза. Резултатот на експериментите е ветувачки и може да служи како инспирација за понатамошна работа на задачата</abstract_mk>
      <abstract_ms>Penyelidikan utama tentang ucapan kebencian fokus sejauh ini terutama pada tugas untuk mengklasifikasikan terutamanya pos media sosial mengenai tipologi terdefinisi bagi kategori ucapan kebencian yang agak besar. Ini mungkin cukup jika tujuan adalah untuk mengesan dan menghapuskan pos bahasa yang mengganggu. However, removal is not always possible due to the legislation of a country.  Juga ada bukti bahawa ucapan kebencian tidak dapat berjaya melawan dengan hanya menghapuskan pos ucapan kebencian; seharusnya dihadapi oleh pendidikan dan kontranarrativ. Untuk tujuan in i, kita perlu mengenalpasti (i) siapa sasaran dalam pos ucapan kebencian tertentu, dan (ii) apa aspek (atau ciri-ciri) sasaran ditakrif kepada sasaran dalam pos. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain.  Hasil eksperimen adalah berjanji dan boleh bertindak sebagai inspirasi untuk kerja lanjut dalam tugas</abstract_ms>
      <abstract_kk>Жарамсыз сөйлесу туралы негізгі зерттеулері көбірек әлемдегі социалдық медиа жіберіліктерін алдын- ала анықталған тифологияларға көмектеседі. Бұл мақсат жеткілікті тіл поштасын табу және өшіру мүмкін. Бірақ елдің саясатының себебі өшіру әрқашан мүмкін емес. Сонымен қатар, жек сөйлейтін сөйлейтіні тек жек сөйлейтіні өшіруге болмайды. Олар білім беру және қарсы оқиғалар бойынша қарсы болу керек. Бұл мақсат үшін біз (i) келтірілген сөйлеу поштасының мақсатын анықтау керек, ii) мақсатының (немесе қасиеттері) мақсатына таңдау керек. Бірінші жақсарту үшін, біз өзгерту доменіне жалпы күй- жағдайының түрлендіру үлгісін өзгертуге ұсынамыз. Тәжірибелердің нәтижесі - мұғатты жұмыс істеу және тапсырмасының жаңа істеу үшін</abstract_kk>
      <abstract_ml>വെറുപ്പ് സംസാരിക്കുന്നതിനെ പ്രധാനപ്പെടുത്തുന്ന പദ്ധതികള്‍ പ്രധാനപ്പെട്ട സാമൂഹ്യ മാധ്യമങ്ങളുടെ പോസ്റ്റുകള്‍ വിശദീകരിക്കുന് അപകടത്തിലുള്ള ഭാഷ പോസ്റ്റുകള്‍ കണ്ടുപിടിക്കുകയും നീക്കം ചെയ്യുന്നതിനുള്ള ലക്ഷ്യം ഇത് മതി. എന്നാലും ഒരു രാജ്യത്തെ നിയമം കാരണം നീക്കം എപ്പോഴും സാധ്യമല്ല. വെറുപ്പ് സംസാരം മാത്രമേ വെറുപ്പ് സംസാരിക്കുകയുള്ളൂ എന്ന് തെളിവുകളുണ്ട്; വിദ്യാഭ്യാസത്തിന്റെയും വിരോധകഥകളിലെയും അവരെ എതിര്‍ത്തണം. അതിനുവേണ്ടി നമുക്ക് ലക്ഷ്യം തിരിച്ചറിയേണ്ടതുണ്ട് (i) കൊടുത്ത വെറുപ്പ് സംസാര പോസ്റ്റില്‍ ആരാണെന്നും, എന്നിട്ട് (ii) ലക്ഷ്യത്തിന്‍റെ ലക് ആദ്യത്തെ ആദ്യത്തെ അടുത്തുചേര്‍ന്നപ്പോള്‍, നമ്മള്‍ ഒരു സാധാരണ സ്ഥാനത്തിന്റെ സാമാന്യത്തിലേക്ക് പ്രാപ്തി ചെയ്യുന്നു.  പരീക്ഷണങ്ങളുടെ ഫലം വാഗ്ദാനം ചെയ്യുന്നതും ജോലിയില്‍ കൂടുതല്‍ ജോലി ചെയ്യുന്നതിനായി പ്രബോധനം ചെയ്</abstract_ml>
      <abstract_mt>Mainstream research on hate speech focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories.  This may be sufficient if the goal is to detect and delete abusive language posts.  Madankollu, it-tneħħija mhux dejjem possibbli minħabba l-leġiżlazzjoni ta’ pajjiż. Barra minn hekk, hemm evidenza li d-diskors ta’ mibegħda ma jistax jiġi miġġieled b’suċċess billi jitneħħew biss il-karigi ta’ diskors ta’ mibegħda; għandhom jiġu miġġielda minn edukazzjoni u kontro-narrattivi. For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post.  Bħala l-ewwel approssimazzjoni, nipproponu li jiġi adattat mudell ġeneriku ta’ estrazzjoni ta’ kunċett avvanzat għad-dominju tad-diskors ta’ mibegħda. The outcome of the experiments is promising and can serve as inspiration for further work on the task</abstract_mt>
      <abstract_no>Første forskning om hatespråk fokuserte så langt hovudsakelig på oppgåva om å klassifisera hovudsakelig sosiale mediepost med hensyn til føredefinerte typologiar av ganske kryssa hatespråk- kategoriar. Dette kan vera nok dersom målet er å oppdaga og sletta abusive språkpost. Men fjerning er ikkje alltid mogleg på grunn av lovgivnaden til eit land. Det finst også bevis at hatespråk kan ikkje kommunerast med suksess ved å fjerna berre hatespråkpost. dei bør teljast med utdanning og mottaler. For dette målet må vi identifisera i) kva som er målet i ei gitt hatespråkpost, og ii) kva aspektar (eller karakteristikk) av målet er attributta til målet i posten. Som den første nærminga, foreslår vi å tilpassa eit generiske tilstand av kunstkonseptutpakkingsmodul til hatt-taledomenet. Utgåva av eksperimentene er sverdig og kan kalla som inspirasjon for meir arbeid på oppgåva</abstract_no>
      <abstract_mn>Харамсалтай ярианы үндсэн судалгаагаар ихэвчлэн нийгмийн мэдээллийн захирал дээр ихэвчлэн хэлэлцдэг хэлбэрүүдийн илэрхийлэл дээр анхаарлаа хандуулсан. Хэрэв зорилго нь хүчирхийллэг хэлний захирагдалуудыг олох, устгах юм бол энэ хангалттай байж болох юм. Гэхдээ улс орны хуулийн шалтгаан үргэлж устгах боломжгүй. Мөн үзэн ядах илтгэлийг зөвхөн үзэн ядах илтгэлийг устгаж амжилттай зохицуулж чадахгүй гэдгийг баталгаатай байдаг. боловсрол, эсрэг түүхийн тулд тэднийг тодорхойлж чадна. Ийм зорилго дээр бид (i) хэн зөрчилдөөн ярианы захиралд зорилготой бөгөөд (ii) зорилготнуудын хэн асуудлыг тайлбарлах хэрэгтэй. Эхний хамгийн ойртох үед бид үзэн ядах ярианы сүлжээнд ерөнхий хувьд урлагийн загвар гаргах загварыг зохицуулахыг санал болно. Эдгээр туршилтын үр дүнг нь амлалтай, ажлын дасгал ажиллах урам зориг болгож,</abstract_mn>
      <abstract_pl>Główne badania nad mową nienawiści skupiały się dotychczas głównie na zadaniu klasyfikowania głównie postów w mediach społecznościowych w odniesieniu do predefiniowanych typologii raczej gruboziarnistych kategorii mowy nienawiści. Może to być wystarczające, jeśli celem jest wykrycie i usuwanie nieprawidłowych postów językowych. Jednak wyprowadzka nie zawsze jest możliwa ze względu na ustawodawstwo danego kraju. Istnieją również dowody na to, że mowa nienawiści nie może być skutecznie zwalczana poprzez jedyne usunięcie postów o mowie nienawiści; Należy im przeciwdziałać edukacja i kontrnarracje. W tym celu musimy zidentyfikować (i) kto jest celem w danym wpisie do mowy nienawiści oraz (ii) jakie aspekty (lub cechy) celu są przypisywane celowi w poście. Jako pierwsze przybliżenie proponujemy dostosowanie ogólnego najnowocześniejszego modelu ekstrakcji koncepcji do domeny mowy nienawiści. Wynik eksperymentów jest obiecujący i może służyć jako inspiracja do dalszych prac nad zadaniem</abstract_pl>
      <abstract_ro>Cercetările principale privind discursul la ură s-au concentrat până în prezent în principal pe sarcina de a clasifica postările în principal pe rețelele de socializare în raport cu tipologiile predefinite ale categoriilor de discursuri la ură destul de grosiere. Acest lucru poate fi suficient dacă scopul este detectarea și ștergerea mesajelor în limba abuzivă. Cu toate acestea, eliminarea nu este întotdeauna posibilă datorită legislației unei țări. De asemenea, există dovezi că discursul de ură nu poate fi combătut cu succes prin simpla eliminare a mesajelor de discurs de ură; ar trebui să fie contracarate de educaţie şi contranaraţiuni. În acest scop, trebuie să identificăm (i) cine este ținta într-un anumit post de discurs de ură și (ii) ce aspecte (sau caracteristici) ale țintei sunt atribuite țintei în post. Ca prima aproximare, propunem adaptarea unui model generic de extracție a conceptului de ultimă generație la domeniul discursului de ură. Rezultatul experimentelor este promițător și poate servi drept inspirație pentru lucrările ulterioare la sarcină</abstract_ro>
      <abstract_sr>Obično istraživanje o govoru mržnje usredotočilo se do sada predstavno na zadatak klasifikacije uglavnom postova društvenih medija u pogledu predodređenih tipologa kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvek moguće zbog zakonodavstva zemlje. Takođe, postoje dokazi da govor mržnje ne može biti uspešno borjen samo uklanjanjem govornih postova mržnje; Trebalo bi da se raèunaju obrazovanjem i protivnim prièama. Za ovu svrhu moramo da identifikujemo i) koji je meta u određenom postu govora mržnje, i ii) koji aspekti (ili karakteristike) mete pripisuju meti na postu. Kao prvi približavanje, predlažemo da se prilagodimo generički model izvlačenja koncepta umjetnosti na domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija za daljnji posao na zadatku.</abstract_sr>
      <abstract_so>Mainstream research on hate speech focused so far predominantly on the task of classifying mainly social media posts with respect to predefined typologies of rather coarse-grained hate speech categories.  Waxaa ku filan kara haddii goalku yahay in la ogaado oo la deleto boostada afka caafimaadka ah. Si kastaba ha ahaatee guurista ma suurtogal karo sharciga wadanka darteed. Sidoo kale waxaa jira markhaati aan hadalka nebcaan liibaansan karin in la dagaallamo fursado hadalka nacayb oo keliya; waxaa waajib ah in ay iskuul iyo sheekooyin ka gees ah looga jeedo. Sababtaas darteed waa inaannu aqoonsanno (i) kaalmo ku leennahay warqada hadalka nebcaada iyo (ii) qaybaha ay ku leeyihiin waxyaabaha ay ku leeyihiin hagitaanka. Sida ugu horeysa, waxaynu soo jeedaynaa in aan u beddelno qaabab caadi ah oo ah qorshaha la soo saaro farshaxanka, si aan ugu beddelno xafiiska hadalka nebcaada. Imtixaanka dhamaadkeedu waa wax ballan ah, wuxuuna u shaqeyn karaa waxyaabaha la siiyo shaqada dheeraad ah ee shaqada</abstract_so>
      <abstract_si>ප්‍රධාන පරීක්ෂණය විරුද්ධ කතාවට ප්‍රධාන පරීක්ෂණය විශ්වාස කරලා තියෙන්නේ ඉතින් විශේෂයේ සාමාජික මාධ්‍යමාධ්‍යම පොස්ට මේක පුළුවන් වෙන්න පුළුවන් ඉලක්කය හොයාගන්න සහ මතක කරන්න. නමුත්, හැමවෙලේම දේශයක් නියෝජනය නිසා අතිරික්ෂණය කරන්න පුළුවන් නෑ. ඒවගේම, ප්‍රශ්න සාක්ෂියක් තියෙනවා කියලා වෛර කතාව සමහරවිට සටන් කරන්න බෑ කියලා, වෛර කතාව පොස් ඔවුන්ට ශික්ෂණය සහ කතාවක් විරුද්ධ වෙන්න ඕනි. මේ අදහසට, අපිට අවශ්‍යයි (i) කවුද කියලා දැනගත්ත වෛර කතා පොස්ට් වල ඉලක්කයක් තියෙන්න ඕනේ, ඒ වගේම (i) ඉලක්කයේ පොස්ට් වල ඉලක්ක මුලින්ම සම්බන්ධ වෙනුවෙන්, අපි සාමාන්‍ය ස්ථානයක් සම්බන්ධ කරන්න ප්‍රයෝජනය කරනවා කියලා පරීක්ෂණයේ ප්‍රතිචාරයක් ප්‍රශ්නයක් වෙන්න පුළුවන් ඒ වගේම තවත් වැඩේ වැඩ කරන්න පුළුවන්</abstract_si>
      <abstract_sv>Den huvudsakliga forskningen om hatpropaganda fokuserade hittills främst på uppgiften att klassificera främst sociala medier inlägg med avseende på fördefinierade typologier av ganska grovkorniga hattalskategorier. Detta kan vara tillräckligt om målet är att upptäcka och ta bort kränkande språkinlägg. Men avlägsnande är inte alltid möjligt på grund av lagstiftningen i ett land. Det finns också bevis för att hatpropaganda inte kan bekämpas framgångsrikt genom att bara ta bort hatinlägg. De bör motverkas av utbildning och motberättelser. För detta ändamål behöver vi identifiera (i) vem som är målet i ett visst hattal inlägg, och (ii) vilka aspekter (eller egenskaper) av målet som tillskrivs målet i inlägget. Som den första approximationen föreslår vi att en generisk state-of-the-art modell för konceptutvinning anpassas till hattalsdomänen. Resultatet av experimenten är lovande och kan tjäna som inspiration för vidare arbete med uppgiften</abstract_sv>
      <abstract_ta>வெறுப்பு பேச்சின் முக்கியமாக முக்கியமாக பொருட்களை வகைப்படுத்துவதற்கு முன்னால் வெறுப்பு பேச்சு வகைப்படுத்தும் வேலையில் முக்கியமா இலக்கு தேவையான மொழியை கண்டுபிடிக்க மற்றும் நீக்குவதற்கு இது போதுமானதாக இருக்கலாம். ஆனால், நாட்டின் சட்டத்தினால் எப்போதும் நீக்க முடியாது. மற்றும், வெறுப்பு பேச்சு வெறுப்பு பேச்சு வெற்றிகரமாக போராட முடியாது என்று தெளிவான அத்தாட்சிகள்  கல்வி மற்றும் எதிர்மறை கதைகளை எதிர்பார்க்க வேண்டும். For this purpose, we need to identify (i) who is the target in a given hate speech post, and (ii) what aspects (or characteristics) of the target are attributed to the target in the post.  முதல் சுருக்கம் என்றால், நாம் ஒரு பொதுவான நிலையை மாற்ற வேண்டும் என்று பரிந்துரைக்கிறோம் வெறுப்பு பேச்சு தளத்திற் பரிசோதனைகளின் முடிவு</abstract_ta>
      <abstract_ur>ناپسندیدہ بات کے متعلق اصلی تحقیقات کا ذریعہ یہاں تک پہلی بار سوسیل میڈیا پوسٹ کا کلاس کرنا ہے جو بہت زیادہ ناپسندیدہ بات کا کلاس کرنا ہے۔ یہ کافی ہو سکتا ہے اگر موقع یہ ہے کہ زبان پوسٹوں کو پہچان اور ٹال دینا چاہے۔ لیکن ہمیشہ ملک کی قوانین کے باعث ہمیشہ ہٹنا ممکن نہیں ہے۔ اور کچھ نشانیاں بھی ہیں کہ ناپسند بات کو صرف ناپسند بات کی باتوں کو دور کرنے کے ذریعہ نہیں پہنچا سکتی۔ انہیں تعلیم اور مخالف داستان کے ذریعہ شمار کرنا چاہیے۔ اس لئے ہمیں معلوم ہونا چاہیے کہ (i) کس کا مقصد مقرر کیا گیا ہے؟ اور (ii) مقصد کا مقصد کس کا مقصد مقرر کیا گیا ہے؟ پہلی نزدیک کی حالت میں، ہم ایک عمومی موقعیت کے مطابق مخالف بات ڈمین کے لئے اضافہ کرنے کے لئے پیشنهاد کرتے ہیں. آزمائش کا نتیجہ وعدہ کرتا ہے اور اس کام پر اضافہ کرتا ہے</abstract_ur>
      <abstract_ka>სამყარო სიტყვების ძირითადი შესწავლობა, რომელიც სამყარო სიტყვების კლასიფიკაციას უფრო მეტად სოციალური მედია პოსტის კლასიფიკაციას, რომელიც უფრო განსაზღვრებული ტიპოლოგიების ეს შეიძლება იყოს, თუ მიზეზი იგივეა, რომ ძალიან ძალიან ძალიან სიტყვის პოსტის განახსნა და წაშლა. მაგრამ არ ყოველთვის შესაძლებელია გადასვლა ქვეყანის законодательства. ასევე, არსებობს წარმოდგენები, რომ მპატის სიტყვა არ შეიძლება წარმოდგენა მხოლოდ მპატიური სიტყვას წარმოდგენით; ისინი უნდა განახლება და კონტრატიურებით შეცვლა. ამ მიზეზისთვის, ჩვენ უნდა განვიცნოთ, რომელიც არის მიზეზი მიზეზი მიზეზის პოსტში, და i i) რომელიც მიზეზი (ან მიზეზები) მიზეზით მიზეზის მიზეზით პოსტში. როგორც პირველი დაბრუნება, ჩვენ მინდომებით გავაკეთოთ სულისხმების კონცექტის ექსტრექციის მოდელის განმავლობა. ექსპერიმენტების შედეგება იქნება საკუთარი მუშაობა და შესაძლებელია იქნება ინგრექცია დამატებული მუშაობაზე</abstract_ka>
      <abstract_vi>Nghiên cứu chủ yếu về ngôn ngữ ghét đến nay chủ yếu tập trung vào nhiệm vụ phân loại các bài phát biểu căm ghét chủ yếu xã hội với những hạng mục đã xác định trước. Điều này có thể là đủ nếu mục tiêu là phát hiện và xóa các bài viết ngôn ngữ lạm dụng. Tuy nhiên, không phải lúc nào cũng có thể loại trừ vì luật pháp của một quốc gia. Ngoài ra, có bằng chứng rằng bài phát biểu căm ghét không thể thành công bằng việc đơn thuần là xóa bỏ các bài phát biểu căm ghét; họ nên bị ngăn lại bởi giáo dục và phản thuật. Để đạt được mục đích, chúng ta cần xác định: i) ai là mục tiêu trong một bài phát biểu căm ghét, và (II) các khía cạnh (hay đặc đi ểm) của mục tiêu được gán cho mục tiêu trong bài báo. Là một khả năng gần nhất, chúng tôi đề nghị thích ứng một mô hình khái niệm kiểu mẫu cũ kĩ theo kiểu trích xuất ghét ngôn ngữ. Kết quả của thí nghiệm là đầy hứa hẹn và có thể là nguồn cảm hứng cho công việc tiếp theo</abstract_vi>
      <abstract_uz>Hat so'zlari haqida o'zgarishni o'zgartirish, aslida asosiy jamiyat medya postlarini o'rganish vazifasi o'zgartiradi, o'sha paytda qo'llangan yolg'onlarning turlarini o'zgartiradi. Agar qanday maqsad aniqlanish va oʻchirish mumkin boʻlishi mumkin. Lekin, davlatning қонунлиги сабабидан доимо кўчириш имкон эмас. Шунингдек, ҳужжатлар мавжуд, ҳужжатлар мавжуд, қизиқ сўзларни ўчириш учун муваффақиятсиз муваффақиятга олиб кела олмайди. ularni ta'lim va ko'paytlarni boshqarish kerak. Bu sababda, biz quyidagi xavfsiz pochta qoidadagi maqolani aniqlash kerak va (i) jadvalning ma'lumotlari (yoki qoidalar) qoidadagi maqolaga qanday belgilangan. Birinchi taxminan bo'lsangiz, biz yolg'on soʻzning umumiy holatini o'zgartirib chiqarish modeli yolg'on gapirish domenasiga o'zgartirishni talab qilamiz. Tajribalarning natijasi ishni bajarishi mumkin va vazifani davom etishga iloji mumkin.</abstract_uz>
      <abstract_nl>Mainstream onderzoek naar haatspraak richtte zich tot nu toe voornamelijk op de taak om voornamelijk social media posts te classificeren met betrekking tot vooraf gedefinieerde typologieën van vrij grove haatspraakcategorieën. Dit kan voldoende zijn als het doel is om beledigende taalberichten op te sporen en te verwijderen. Echter, verhuizing is niet altijd mogelijk vanwege de wetgeving van een land. Er is ook bewijs dat haatspraak niet succesvol kan worden bestreden door alleen maar haatspraakberichten te verwijderen; Ze moeten worden tegengegaan door onderwijs en tegenverhalen. Hiervoor moeten we identificeren (i) wie het doelwit is in een bepaald hate speech post, en (ii) welke aspecten (of kenmerken) van het doelwit worden toegeschreven aan het doelwit in de post. Als eerste benadering stellen we voor om een generiek state-of-the-art concept extraction model aan te passen aan het haatspraakdomein. Het resultaat van de experimenten is veelbelovend en kan als inspiratie dienen voor verder werk aan de taak</abstract_nl>
      <abstract_da>Hovedforskningen om hadefuldtale har hidtil hovedsageligt fokuseret på opgaven at klassificere hovedsageligt sociale medier indlæg i forhold til foruddefinerede typologier af temmelig grove hadefulde talekategorier. Dette kan være tilstrækkeligt, hvis målet er at opdage og slette krænkende sprogindlæg. Men fjernelse er ikke altid mulig på grund af lovgivningen i et land. Der er også beviser for, at hadefulde tale ikke kan bekæmpes med succes ved blot at fjerne hadefulde tale indlæg; De bør modvirkes af uddannelse og modfortællinger. Til dette formål er vi nødt til at identificere (i) hvem der er målet i et givet hadefuldtale indlæg, og (ii) hvilke aspekter (eller karakteristika) af målet, der tilskrives målet i indlægget. Som den første tilnærmelse foreslår vi at tilpasse en generisk state-of-the-art konceptudvindingsmodel til hadefulde tale domæne. Resultatet af eksperimenterne er lovende og kan tjene som inspiration til videre arbejde med opgaven</abstract_da>
      <abstract_bg>Основните изследвания на речта на омразата засега се фокусираха предимно върху задачата да класифицират главно публикациите в социалните медии по отношение на предварително определени типологии на доста грубозърнести категории речи на омразата. Това може да е достатъчно, ако целта е откриване и изтриване на злоупотребяващи езикови публикации. Премахването обаче не винаги е възможно поради законодателството на дадена държава. Също така има доказателства, че речта на омразата не може да бъде успешно преодоляна чрез просто премахване на публикациите в речта на омразата; те трябва да бъдат противопоставени чрез образование и контраразкази. За тази цел трябва да идентифицираме (и) коя е целта в дадена публикация за реч на омразата и (ii) какви аспекти (или характеристики) на целта се приписват на целта в публикацията. Като първо сближаване предлагаме да се адаптира генеричен модел за извличане на концепции в областта на речта на омразата. Резултатът от експериментите е обещаващ и може да послужи като вдъхновение за по-нататъшна работа по задачата</abstract_bg>
      <abstract_ko>지금까지 증오 언론에 대한 주류 연구는 주로 미리 정의된 굵은 입도 증오 언론 유형에 따라 소셜미디어 게시물을 분류하는 임무에 집중됐다.욕설성 언어 게시물을 탐지하고 삭제하는 것이 목표라면 충분할 것 같다.그러나 한 나라의 입법 때문에 항상 그것을 제거할 수 있는 것은 아니다.또한 헤이트 스피치 게시물만 삭제하면 헤이트 스피치를 성공적으로 단속할 수 없다는 증거가 있다.그들은 교육과 반사사를 통해 반격해야 한다.이를 위해 (i)특정한 원한 언론 게시물의 목표가 누구인지, (ii)해당 게시물의 목표가 어떤 부분(또는 특징)이 있는지 확인해야 한다.첫 번째 근사로서, 우리는 통용되는 가장 선진적인 개념 추출 모델을 증오 음성 분야에 응용할 것을 건의합니다.실험의 결과는 희망적이어서 진일보한 작업의 영감으로 삼을 수 있다</abstract_ko>
      <abstract_de>Die Mainstream-Forschung zur Hassrede konzentrierte sich bisher vor allem auf die Aufgabe, hauptsächlich Social Media Posts hinsichtlich vordefinierter Typologien eher grobkörniger Hassredekategorien zu klassifizieren. Dies kann ausreichen, wenn es darum geht, missbräuchliche Sprachbeiträge zu erkennen und zu löschen. Allerdings ist ein Umzug aufgrund der Gesetzgebung eines Landes nicht immer möglich. Es gibt auch Beweise dafür, dass Hassrede nicht erfolgreich bekämpft werden kann, indem lediglich Hassrede-Beiträge entfernt werden; Sie sollten durch Bildung und Gegennarrative bekämpft werden. Zu diesem Zweck müssen wir (i) identifizieren, wer das Ziel in einem bestimmten Hassrede-Beitrag ist und (ii) welche Aspekte (oder Merkmale) des Ziels dem Ziel in dem Beitrag zugeschrieben werden. Als erste Annäherung schlagen wir vor, ein generisches State-of-the-Art Konzept Extraktion Modell an die Hassrede Domäne anzupassen. Das Ergebnis der Experimente ist vielversprechend und kann als Inspiration für die weitere Arbeit an der Aufgabe dienen.</abstract_de>
      <abstract_hr>Obično istraživanje o govoru mržnje usredotočilo se do sada predstavno na zadatak klasifikacije uglavnom postignuća društvenih medija u pogledu predodređenih tipologa raznih kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvijek moguće zbog zakonodavstva zemlje. Također, postoje dokazi da govor mržnje ne može uspješno boriti samo uklanjanjem govornih mjesta mržnje; trebali bi se računati obrazovanjem i protivnim pričama. Za ovu svrhu moramo identificirati i) koji je cilj u određenom postu govora mržnje i ii) koji aspekti (ili karakteristike) mete pripisuju cilju na postu. Kao prvi približavanje, predlažemo prilagoditi generični model izvlačenja koncepta umjetnosti u domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija daljnjeg rada na zadatku.</abstract_hr>
      <abstract_fa>تحقیقات اصلی در مورد سخنرانی از نفرت به این مدت بیشتر روی کار کلاس کردن نقطه‌های رسانه‌های اجتماعی در مورد تایپولوژی‌های پیش‌فرض از گروه‌های سخنرانی از ناخوشایند غیرقابل تعریف شده است. این ممکن است به اندازه کافی باشد اگر هدف برای شناسایی و حذف کردن پست زبان زبان زبان زبان زبان زبان استفاده است. ولی حذف کردن همیشه ممکن نیست به دلیل قوانین یک کشور. همچنین، نشانه‌هایی هستند که از سخنرانی که نفرت دارند، نمی‌توانند با موفقیت مبارزه کنند، فقط با حذف کردن نقطه‌های سخنرانی که نفرت دارند. آنها باید توسط تحصیل و داستان مخالف تحصیل کنند. برای این هدف، ما باید تشخیص بدیم که کیست هدف در یک پست سخنرانی متنفر و (i i) چه نقطه (یا ویژگی) هدف به هدف در پست تعریف می‌شود. به عنوان اولین نزدیک شدن، ما پیشنهاد می کنیم که یک مدل استخراج نظریه عمومی در حالت هنری به دامنه سخنرانی متنفر adapt کنیم. نتیجه آزمایشات قول می دهد و می تواند به عنوان الهام برای کار بیشتری در این کار باشد</abstract_fa>
      <abstract_id>Penelitian utama tentang pidato kebencian fokus sejauh ini terutama pada tugas untuk mengklasifikasi terutama pos media sosial mengenai tipologi terdefinisi dari kategori pidato kebencian yang agak kasar. This may be sufficient if the goal is to detect and delete abusive language posts.  Namun, penghapusan tidak selalu mungkin karena undang-undang negara. Juga, ada bukti bahwa pidato kebencian tidak dapat berhasil melawan hanya dengan menghapus pos pidato kebencian; seharusnya diharapkan oleh pendidikan dan kontranarratif. Untuk tujuan in i, kita perlu mengidentifikasi (i) siapa sasaran dalam pos pembicaraan kebencian tertentu, dan (ii) aspek apa (atau karakteristik) sasaran yang disebut kepada sasaran di pos. Sebagai pendekatan pertama, kami mengusulkan untuk mengadaptasi model ekstraksi konsep state-of-the-art generik ke domain pidato kebencian. Hasil eksperimen itu berjanji dan dapat menjadi inspirasi untuk kerja lanjut dalam tugas</abstract_id>
      <abstract_sw>Utafiti mkubwa wa hotuba ya chuki ulilenga muhimu sana katika kazi ya kutangaza makala za mitandao ya kijamii hasa kwa kuheshimu aina zilizotanguliwa na makundi ya hotuba ya chuki yanayojiunga mkono. Hii inaweza tosha ikiwa lengo la kutambua na kufuta makala za lugha zinazotumiwa. Hata hivyo, kuondolewa kwa nchi haiwezekani kwa sababu ya sheria ya nchi hiyo. Pia, kuna ushahidi kuwa hotuba ya chuki haiwezi kupambana na mafanikio tu kwa kuondoa makala za hotuba za chuki; wanatakiwa kukabiliana na elimu na hadithi za kupinga. Kwa sababu hii, tunahitaji kutambua (i) ni nani hasira katika makala yenye hotuba ya chuki, na (ii) mambo (au tabia) ya malengo yanayohusishwa na lengo la makala hiyo. Kama ilivyokaribia mara ya kwanza, tunapendekeza kubadilisha hali ya kawaida ya dhana ya utekelezaji wa sanaa kwenye eneo la hotuba ya chuki. Matokeo ya majaribio ni kuahidini na yanaweza kutumika kama hamasa ya kufanya kazi zaidi kwenye kazi hiyo</abstract_sw>
      <abstract_tr>Iň ýigrenýän çykyşyň adaty barlamagy üçin esasy ýagdaýda sosyal medýdançalaryň ýerlerinde taýýarlanmagy üçin üns berdi. Eger maksadyň gaýd edilen diller tapmak we pozmak üçin bu ýeterlik bolup biler. Ýöne ýurtyň kanunlygyna sebäpli ýitirmek hemişe mümkin däl. Munuň üçin ýigrenýän sözlerin ýöne ýigrenýän sözlerini ýitirmek üçin mümkin edip bilmeýän kanlag bar. Olar bilim we aýdymlar bilen garşy edilmeli. Bu maksadyň üçin biziň (i) berilen ýigrenç çykyş post-da maksady kimdir, we (ii) maksadyň (ýa-da özellikleri) post-de maksadyň nähili aspektlerini takyklamaly. Ilkinji yaklaşyk bolsa, ýigrenç sözleşme domunyna umumy bir şekilde çykarmak nusgasyny üýtgetmegi teklif ediyoruz. Deneylerin netijesi söz berýän we işiň üstünde ýeterlik iş üçin ilham alyp biler.</abstract_tr>
      <abstract_sq>Kërkimet kryesore mbi fjalimin e urrejtjes u përqëndruan deri tani kryesisht në detyrën e klasifikimit kryesisht të posteve të medias sociale lidhur me tipologjitë e paracaktuara të kategorive të fjalimit të urrejtjes me kokërra të mëdha. Kjo mund të jetë e mjaftueshme në qoftë se qëllimi është të zbulojë dhe fshijë postimet e gjuhës abusive. Megjithatë, heqja nuk është gjithmonë e mundur për shkak të legjislacionit të një vendi. Gjithashtu, ka prova se fjalimi i urrejtjes nuk mund të luftohet me sukses vetëm duke hequr postin e fjalimit të urrejtjes; ata duhet të kundërvihen nga arsimi dhe kontranarrativat. Për këtë qëllim, ne duhet të identifikojmë (i) se kush është objektivi në një post të caktuar të fjalimit të urrejtjes dhe (ii) se cilat aspekte (apo karakteristika) të objektivit janë atribuar objektivit në post. Si përafërsimi i parë, ne propozojmë të përshtatemi një model gjeneral të nxjerrjes së konceptit më të lartë në domenin e fjalimit të urrejtjes. Rezultati i eksperimenteve është premtues dhe mund të shërbejë si frymëzim për punë të mëtejshme në detyrë</abstract_sq>
      <abstract_hy>Հիմնական հետազոտությունները ատելության խոսքի մասին, որոնք մինչ այժմ հիմնականում կենտրոնացել են հատկապես սոցիալական լրատվամիջոցների դիրքերի դասակարգման խնդրի վրա, հատկապես դասակարգված ատելության խմբերի նախասահմանված տիպոլոգիաների հետ Սա կարող է բավարար լինել, եթե նպատակն է հայտնաբերել և ջնջել չարաշահույթ լեզվի տեղադրությունները: Այնուամենայնիվ, հեռացումը միշտ հնարավոր չէ երկրի օրենսդրության պատճառով: Կան նաև ապացույցներ, որ ատելության խոսքերը չեն կարող հաջողությամբ պայքարել, պարզապես վերացնելով ատելության խոսքերը: նրանք պետք է հակառակվեն կրթությամբ և հակապատմություններով: Այս նպատակի համար մենք պետք է հայտնաբերենք i) ով է նպատակը ատելության խոսքի պաշտոնում, և i) նպատակի ի՞նչ ասպեկտներ (կամ առանձնահատկություններ) են պատասխանում նպատակին պաշտոնում: Ինչպես առաջին մոտեցումը, մենք առաջարկում ենք հարմարեցնել ընդհանուր տեխնոլոգիական գաղափարի վերացման մոդելը ատելության խոսքի ոլորտում: Փորձերի արդյունքը խոստացնող է և կարող է օգտագործել որպես ոգեշնչում աշխատանքի շարունակման համար,</abstract_hy>
      <abstract_az>Nöqsanlıq sözləri haqqındakı ilk dəyişiklik təhsil edilən təhsil sözləri daha çox dəyişiklik nifrət sözləri kategoriyalarının əvvəlcə müəyyən edilmiş typoloqlarına görə dəyişiklik göstərməsi işinə baxıldı. Əgər məqsəd zəif dil postalarını keçmək və silmək üçün kifayət ola bilər. Ancaq bir ülkenin qaydalarına görə həmişə silinmək mümkün deyil. Həmçinin nifrət sözlərini yalnız nifrət sözlərini silməklə mübahisə edə bilməyəcəyi dəlillər də var. təhsil və müxtəlif hekayələrlə sayılmalıdır. Bu məqsədilə, bizə verilən nifrət sözlərinin məqsədilə nifrət nifrətində olan məqsədili tanımlamaq lazımdır, və i i) məqsədilərin məqsədilə nələr məqsədilə qoyulmuşdur. İlk yaxınlaşdığımız kimi, nifrət sözləri domenasına generiki bir məlumatın qovuşdurulmasını təklif edirik. Həyatların sonuçları vəd edir və daha çox iş üçün ilham edə bilər.</abstract_az>
      <abstract_bs>Uglavnom istraživanju o govoru mržnje usredotočeno je do sada uglavnom na zadatak klasifikacije uglavnom položaja društvenih medija u pogledu predodređenih tipologa kategorija razgovora mržnje. To bi moglo biti dovoljno ako je cilj otkrivanje i izbrisanje nasilnih jezičkih postova. Međutim, uklanjanje nije uvek moguće zbog zakonodavstva zemlje. Također, postoje dokazi da govor mržnje ne može biti uspješno borjen samo uklanjanjem postova govora mržnje. Trebalo bi se suočavati obrazovanjem i protivnim pričama. Za ovu svrhu moramo identificirati i) koji je cilj u određenom postu govora mržnje, i ii) koje aspekte (ili karakteristike) mete pripisuju cilju na postu. Kao prvi približavanje, predlažemo prilagoditi generični model izvlačenja koncepta umjetnosti na domenu govora mržnje. Rezultat eksperimenata obećava i može biti inspiracija za daljnji posao na zadatku.</abstract_bs>
      <abstract_af>Onderstremde ondersoek op haat spraak het so ver voordeel gefokus op die taak van klassifiseer hoofsaaklik sosiale media-pos met betrekking na vooraf-definieerde tipologies van eerder uitgevoerde haat spraak kategories. Hierdie dalk mag genoeg wees as die doel is om abusive taalposte te ontdek en uitvee. Maar verwydering is nie altyd moontlik vanweë die wetgewing van 'n land nie. Ook, daar is getuienis dat haat spreek nie suksesvol gemeenskap word deur net die verwyder van haat spraakposte nie; hulle moet deur opvoeding en teenstoratiewe tel word. Vir hierdie doel, moet ons identifiseer (i) wie die doel is in 'n gegewe haat spraakpost, en (ii) wat aspekte (of karakters) van die doel aan die doel in die pos aangewys word. As die eerste toekoms, voorstel ons om 'n generieke staat-van-die-kuns-konsepte uittrekking model aan die haat-sprekkdomein te pas. Die resultaat van die eksperimente is beloftende en kan as inspirasie dien vir verdere werk op die taak</abstract_af>
      <abstract_am>በጥል ንግግር ላይ የመጠቀም ትምህርት ትምህርት ላይ አስቀድሞ በማኅበራዊ አውታር ሚዲያ ፖርቶች ላይ ለመለፍ ነው፡፡ ይህ ይበቃል፡፡ ነገር ግን ማስወገድ ሁልጊዜ በአገሪቱ ሕግ ምክንያት አይቻልም፡፡ Also, there is evidence that hate speech cannot be successfully combated by merely removing hate speech posts;  ትምህርት እና ተቃዋሚዎች ተቃውሞ ይቃወሙ:: ለዚህ ምክንያት (i) በተሰጠው የጥል ንግግር ጽሑፍ የሚሆነውን መግለጫ (i) እና (ii) የዕቅድን ጉዳይ (ወይም የአካባቢው) ምን ጉዳይ እንዲሆን ያስፈልጋል፡፡ የመጀመሪያው አካባቢ መጠን፣ የ-የ-አርእስት አካባቢ አካሄድ ምሳሌ ለጥል ንግግር ድሆችን ለመቀበል እናስባለን፡፡ የሞከሩ ፍጻሜ ተስፋ የሚያደርገው እና ለስራ ላይ ለሌላ ሥራ ማግኘት የሚችል ነው፡፡</abstract_am>
      <abstract_cs>Hlavní výzkum nenávistné řeči se zatím zaměřil především na úlohu klasifikace příspěvků na sociálních médiích s ohledem na předem definované typologie spíše hrubozrnných kategorií nenávistné řeči. To může být dostačující, pokud je cílem odhalit a odstranit zneužívající jazykové příspěvky. Stěhování však není vždy možné vzhledem k právním předpisům dané země. Také existují důkazy, že nenávistná řeč nelze úspěšně bojovat pouhým odstraněním příspěvků na nenávistné řeči; Měly by být čelit vzděláváním a protipříběhy. Za tímto účelem musíme identifikovat (i) kdo je cílem v daném příspěvku o nenávistné řeči a (ii) jaké aspekty (nebo charakteristiky) cíle jsou přiřazeny cíli v příspěvku. Jako první aproximaci navrhujeme adaptaci obecného stavu-of-the-art konceptního extrakčního modelu do domény nenávistné řeči. Výsledek experimentů je slibný a může sloužit jako inspirace pro další práci na úkolu</abstract_cs>
      <abstract_et>Vihakõne põhitegevus keskendus seni peamiselt ülesandele klassifitseerida peamiselt sotsiaalmeedia postitusi üsna jämedate vihakõne kategooriate eelnevalt määratletud tüpoloogiate järgi. See võib olla piisav, kui eesmärk on tuvastada ja kustutada kuritarvitavad keelepostid. Kuid riigi õigusaktide tõttu ei ole väljasaatmine alati võimalik. Samuti on tõendeid, et vihakõne vastu ei saa edukalt võidelda vaid vihakõne postituste eemaldamisega; nende vastu tuleks võidelda hariduse ja vastupidiste jutustustega. Sel eesmärgil tuleb tuvastada i) kes on sihtmärk antud vihakõne postituses ja ii) millised sihtmärki aspektid (või omadused) omistatakse sihtmärkile postituses. Esimese lähenemisena teeme ettepaneku kohandada üldist kaasaegset kontseptsioonide ekstraheerimise mudelit vihakõne valdkonnale. Katsete tulemus on paljulubav ja võib olla inspiratsiooniks edasiseks tööks ülesandega</abstract_et>
      <abstract_fi>Vihanpuheen valtavirtatutkimus keskittyi tähän mennessä pääasiassa sosiaalisen median viestien luokitteluun melko karkeiden vihapuheluokkien ennalta määriteltyjen typologioiden perusteella. Tämä voi riittää, jos tavoitteena on tunnistaa ja poistaa loukkaavat kieliviestit. Maan lainsäädännön vuoksi maastapoistaminen ei kuitenkaan aina ole mahdollista. On myös näyttöä siitä, että vihapuhetta ei voida torjua menestyksekkäästi pelkästään poistamalla vihapuheviestejä. Niitä olisi torjuttava koulutuksen ja vastakertomusten avulla. Tätä tarkoitusta varten meidän on tunnistettava (i) kuka on kohde tietyssä vihapuheviestissä, ja (ii) mitä kohtia (tai ominaisuuksia) kohdeviestissä kohdellaan. Ensimmäisenä lähestymistapana ehdotamme geneerisen, viimeisintä tekniikkaa edustavan käsitteen uuttamismallin mukauttamista vihapuheen domeeniin. Kokeiden tulos on lupaava ja voi toimia inspiraationa tehtävän jatkotyöhön</abstract_fi>
      <abstract_bn>ঘৃণা ভাষণের প্রধান গবেষণা প্রধান গবেষণা প্রধান সামাজিক যোগাযোগ মাধ্যমের পোস্টগুলোকে বিশ্লেষণ করার কাজের উপর মনোযোগ প্রদান করেছে যারা বেশ This may be sufficient if the goal is to detect and delete abusive language posts.  তবে দেশের আইনের কারণে সবসময় অপসারণ সম্ভব নয়। এছাড়াও প্রমাণ রয়েছে যে ঘৃণা ভাষণ কেবল ঘৃণা বাক্য পোস্ট সরিয়ে দিয়ে সাফল্যের সাথে যুদ্ধ করতে পারে না; তাদের শিক্ষা এবং বিরোধী গল্পের মুখোমুখি হওয়া উচিত। এই উদ্দেশ্যের জন্য আমাদের চিহ্নিত করা দরকার (I) কে একটি ঘৃণা ভাষণ পোস্টে লক্ষ্য করা দরকার এবং (i i) লক্ষ্যবস্তুতে (অথবা চরিত্র) লক্ষ্যবস্তুর জন্যে কি বিষয় প্রথম প্রাথমিক যুক্তি হিসেবে আমরা প্রস্তাব করছি ঘৃণা ভাষণের ডোমেইনে একটি সাধারণ রাষ্ট্রের জেনারিক-শিল্পের ধারণা বের করা পরীক্ষার ফলাফল প্রতিশ্রুতিশীল এবং কাজের উপর আরো কাজের জন্য অনুপ্রেরণা হিসেবে সাহায্য করতে পারে।</abstract_bn>
      <abstract_ca>La recerca principal sobre el discurs d'odi s'ha centrat fins ara principalment en la tasca de classificar principalment els posts dels mitjans socials en relació a tipologies predefinides de categories de discurs d'odi bastant grossos. Això pot ser suficient si l'objectiu és detectar i eliminar posts de llenguatge abusivs. However, removal is not always possible due to the legislation of a country.  També hi ha evidències de que el discurs d'odi no es pot combatre amb èxit només eliminant posts d'odi; haurien de ser contradits per educació i contranarratives. Per aquest objectiu, hem d'identificar (i) qui és l'objectiu d'un discurs d'odi determinat, i (ii) quins aspectes (o característiques) del objectiu s'atribueixen al objectiu del post. Com a primera aproximació, proposem adaptar un model genèric d'extracció de concepte d'última generació al domini del discurs d'odi. El resultat dels experiments és prometedor i pot servir de inspiració per a seguir treballant en la tasca</abstract_ca>
      <abstract_jv>Tolangga Punika sapa kana nggawe goal punika dipakingno karo akeh-akeh oleh basa. Nanging, nggolo-nggolo saiki ora bisa diandelak ning hukum sing paling dhéwé. Mangka, ono bukane pancene ora ngerasakno ora ono nggawe ngubah apakno ora ono nggawe ngubah dilanjuré; ndeloke Kayané iso ngulinakake karo edukasi lan kontribusi. Saiki iki, awake dhéwé kudu nambah (i) sing ngendadi iki bakal terus kesempatan langgar, lan (i i) langgar sampek (obang cara-cara) kebutuhake tarjamahan kanggo langgar sampek winih. When the first confirmation, we proposal to align a generic state-of-the-Art contest extract model to the anti-language domain. Balika nang ujaran ning alih lan gampang lan iso alih luwih dumadhi kanggo nggawe alih dumadhi kanggo nggawe lan kenal</abstract_jv>
      <abstract_ha>Tayyar da muhimmi a kan magana na ƙi ana fokus a kan aikin su rarrabe maimainli mainli maimainli maimaimainlin mitandan jamii da kuma da tsarin wasu typogi na daban-coacoacoast-graffed-categories of hatsi. Wannan yana da amfani da idan aimakin ya zama na gane kuma ka goge takardar harshen mai zartar da shi. A lokacin da za'a iya tafiyar da shi, bã zai iya so ba daidai ne da sharci na kasancẽwa. Kuma akwai shaidar cẽwa, maganar ƙyãma bã za su ci nasara ba fãce da su tunkuɗe maganar ƙyãma. Ina kamata a kamata da abincin da baka-faɗi. Ga wannan, Munã bukãta mu gane (ni) wãne ne ke da goani a cikin wani hotan na ƙi, kuma (ii) yanda ake ƙayyade gafaka (ko da takwara) cikin bango. Kayya da taki na farkon, za'a goyi musammali na halin-na-zaɓen-kunna zuwa hotin da aka ƙi. Faramar jarrabai yana yi wa'adi da kuma yana iya amfani da aikin da ke iya ƙara a kan aikin wannan</abstract_ha>
      <abstract_sk>Glavne raziskave sovražnega govora so se doslej osredotočale predvsem na nalogo razvrščanja predvsem objav v družbenih medijih glede na vnaprej določene tipologije precej grobozrnatih kategorij sovražnega govora. To lahko zadostuje, če je cilj odkrivanja in brisanja zlorabljajočih jezikovnih objav. Vendar odstranitev ni vedno mogoča zaradi zakonodaje države. Obstajajo tudi dokazi, da se sovražnega govora ni mogoče uspešno boriti z zgolj odstranitvijo objav sovražnega govora; se jim je treba zoperstaviti z izobraževanjem in protipogodbami. V ta namen moramo ugotoviti (i) kdo je tarča v določeni objavi sovražnega govora in (ii) kateri vidiki (ali značilnosti) tarče se pripišejo cilju v objavi. Kot prvi približek predlagamo prilagoditev generalnega najsodobnejšega modela ekstrakcije koncepta domeni sovražnega govora. Rezultat poskusov je obetaven in lahko služi kot navdih za nadaljnje delo na nalogi</abstract_sk>
      <abstract_he>המחקר המרכזי בנאום שנאה התמקד עד כה בעיקר במשימה להקליף בעיקר עמדות תקשורת חברתית בנוגע לטיפולוגיות מוגדרות מראש של קטגוריות נאום שנאה עצומות למדי. זה עשוי להיות מספיק אם המטרה היא לזהות ולמחק משימות שפה מתעללות. עם זאת, הסירה לא תמיד אפשרית בגלל החוק של מדינה. בנוסף, יש ראיות שאי אפשר להילחם בהצלחה בנאום שנאה על ידי רק להסיר את עמדות הנאום לשנאה; הם צריכים להילחם על ידי חינוך וסיפורים נגד. למטרה זו, אנחנו צריכים לזהות (i) מי המטרה בתור נאום שנאה מסוים, ו (ii) איזה היבטים (או אופיינים) של המטרה מונחים למטרה בתור התור. As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain.  התוצאה של הניסויים מבטיחה ויכולה לשרת בתור השראה לעבודה נוספת על המשימה</abstract_he>
      <abstract_bo>hate speech. གལ་སྲིད་དམིགས་ཡུལ་ནི་བསམ་བཤེར་དང་བསུབ་པ་ཡིན་ཚེ། ཡིན་ནའང་། རྒྱལ་ཁབ་ཀྱི་ཁྲིད་པ་ཞིག་ཀྱང་རྩ་བསྐྲད་གཏོང་ནི་མི་སྲིད། ད་ལྟ་བུའི་རྗེས་སུ་འབྲེལ་བའི་འཇིག་བརྗོད་འདི་རྒྱལ་ཐག་གཅིག་ལས་གཏོང་མི་ཐུབ་པ་ལྟར། ཁོང་ཚོས་ཤེས་ཡོན་དང་གནད་དོན་རྩོལ་བ་དགོས་མིན་འདོད། དམིགས་ཡུལ་འདི་ལ་ང་ཚོར་དམིགས་ཡུལ་གྱི་ཤོག་བྱས་པར་ཕྱི་ཁག་ཅིག་རེད། As the first approximation, we propose to adapt a generic state-of-the-art concept extraction model to the hate speech domain. བརྟག་ཞིབ་ཀྱི་གྲུབ་འབྲས་བ་དེ་གསལ་བཤད་པ་ཞིག་ཡིན། དེ་ལས་ཀྱི་ལས་ཀ་གཞན་ལས་ཀྱི་སྒེར་སྟོན་རྒྱས་ལས།</abstract_bo>
      </paper>
    <paper id="23">
      <title>Racist or Sexist Meme? Classifying Memes beyond Hateful</title>
      <author><first>Haris Bin</first><last>Zia</last></author>
      <author><first>Ignacio</first><last>Castro</last></author>
      <author><first>Gareth</first><last>Tyson</last></author>
      <pages>215–219</pages>
      <abstract>Memes are the combinations of text and images that are often humorous in nature. But, that may not always be the case, and certain combinations of <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">texts</a> and <a href="https://en.wikipedia.org/wiki/Image">images</a> may depict <a href="https://en.wikipedia.org/wiki/Hatred">hate</a>, referred to as hateful memes. This work presents a multimodal pipeline that takes both visual and textual features from <a href="https://en.wikipedia.org/wiki/Meme">memes</a> into account to (1) identify the protected category (e.g. race, sex etc.) that has been attacked ; and (2) detect the type of attack (e.g. contempt, <a href="https://en.wikipedia.org/wiki/Pejorative">slurs</a> etc.). Our <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> uses state-of-the-art pre-trained visual and textual representations, followed by a simple <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression classifier</a>. We employ our <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> on the Hateful Memes Challenge dataset with additional newly created fine-grained labels for protected category and type of attack. Our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves an AUROC of 0.96 for identifying the protected category, and 0.97 for detecting the type of attack. We release our code at https://github.com/harisbinzia/HatefulMemes</abstract>
      <url hash="24ecb5e6">2021.woah-1.23</url>
      <doi>10.18653/v1/2021.woah-1.23</doi>
      <bibkey>zia-etal-2021-racist</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hateful-memes">Hateful Memes</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/hateful-memes-challenge">Hateful Memes Challenge</pwcdataset>
    </paper>
    </volume>
</collection>