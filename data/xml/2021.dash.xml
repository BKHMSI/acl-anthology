<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.dash">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</booktitle>
      <editor><first>Eduard</first><last>Dragut</last></editor>
      <editor><first>Yunyao</first><last>Li</last></editor>
      <editor><first>Lucian</first><last>Popa</last></editor>
      <editor><first>Slobodan</first><last>Vucetic</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.dash-1</url>
    </meta>
    <frontmatter>
      <url hash="0f20b02d">2021.dash-1.0</url>
      <bibkey>dash-2021-data</bibkey>
    </frontmatter>
    <paper id="3">
      <title>ViziTex : Interactive Visual Sense-Making of Text Corpora<fixed-case>V</fixed-case>izi<fixed-case>T</fixed-case>ex: Interactive Visual Sense-Making of Text Corpora</title>
      <author><first>Natraj</first><last>Raman</last></author>
      <author><first>Sameena</first><last>Shah</last></author>
      <author><first>Tucker</first><last>Balch</last></author>
      <author><first>Manuela</first><last>Veloso</last></author>
      <pages>16–23</pages>
      <abstract>Information visualization is critical to <a href="https://en.wikipedia.org/wiki/Analytical_reasoning">analytical reasoning</a> and <a href="https://en.wikipedia.org/wiki/Epistemology">knowledge discovery</a>. We present an interactive studio that integrates perceptive visualization techniques with powerful text analytics algorithms to assist humans in sense-making of large complex text corpora. The novel visual representations introduced here encode the features delivered by modern text mining models using advanced metaphors such as <a href="https://en.wikipedia.org/wiki/Hypergraph">hypergraphs</a>, nested topologies and <a href="https://en.wikipedia.org/wiki/Tessellation">tessellated planes</a>. They enhance human-computer interaction experience for various tasks such as summarization, exploration, organization and labeling of documents. We demonstrate the ability of the visuals to surface the structure, relations and concepts from documents across different domains.</abstract>
      <url hash="0f1aede9">2021.dash-1.3</url>
      <doi>10.18653/v1/2021.dash-1.3</doi>
      <bibkey>raman-etal-2021-vizitex</bibkey>
    </paper>
    <paper id="7">
      <title>Bridging Multi-disciplinary Collaboration Challenges in ML Development via Domain Knowledge Elicitation<fixed-case>ML</fixed-case> Development via Domain Knowledge Elicitation</title>
      <author><first>Soya</first><last>Park</last></author>
      <pages>44–46</pages>
      <abstract>Building a <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning model</a> in a sophisticated domain is a time-consuming process, partially due to the steep learning curve of <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> for <a href="https://en.wikipedia.org/wiki/Data_science">data scientists</a>. We introduce Ziva, an interface for supporting <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a> from domain experts to data scientists in two ways : (1) a concept creation interface where domain experts extract important concept of the domain and (2) five kinds of justification elicitation interfaces that solicit elicitation how the domain concept are expressed in data instances.</abstract>
      <url hash="e64d6360">2021.dash-1.7</url>
      <doi>10.18653/v1/2021.dash-1.7</doi>
      <bibkey>park-2021-bridging</bibkey>
    </paper>
    <paper id="9">
      <title>Towards integrated, interactive, and extensible text data analytics with Leam</title>
      <author><first>Peter</first><last>Griggs</last></author>
      <author><first>Cagatay</first><last>Demiralp</last></author>
      <author><first>Sajjadur</first><last>Rahman</last></author>
      <pages>52–58</pages>
      <abstract>From <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> to <a href="https://en.wikipedia.org/wiki/Review">product reviews</a>, <a href="https://en.wikipedia.org/wiki/Plain_text">text</a> is ubiquitous on the web and often contains valuable information for both enterprises and consumers. However, the online text is generally noisy and incomplete, requiring users to process and analyze the data to extract insights. While there are systems effective for different stages of <a href="https://en.wikipedia.org/wiki/Text_mining">text analysis</a>, users lack extensible platforms to support interactive text analysis workflows end-to-end. To facilitate integrated text analytics, we introduce LEAM, which aims at combining the strengths of <a href="https://en.wikipedia.org/wiki/Spreadsheet">spreadsheets</a>, <a href="https://en.wikipedia.org/wiki/Computational_notebook">computational notebooks</a>, and interactive visualizations. LEAM supports interactive analysis via GUI-based interactions and provides a declarative specification language, implemented based on a visual text algebra, to enable user-guided analysis. We evaluate LEAM through two <a href="https://en.wikipedia.org/wiki/Case_study">case studies</a> using two popular Kaggle text analytics workflows to understand the strengths and weaknesses of the <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <url hash="17014bf7">2021.dash-1.9</url>
      <doi>10.18653/v1/2021.dash-1.9</doi>
      <bibkey>griggs-etal-2021-towards</bibkey>
    </paper>
    <paper id="10">
      <title>Data Cleaning Tools for Token Classification Tasks</title>
      <author><first>Karthik</first><last>Muthuraman</last></author>
      <author><first>Frederick</first><last>Reiss</last></author>
      <author><first>Hong</first><last>Xu</last></author>
      <author><first>Bryan</first><last>Cutler</last></author>
      <author><first>Zachary</first><last>Eichenberger</last></author>
      <pages>59–61</pages>
      <abstract>Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels for manual review. We have developed a novel technique for flagging potentially-incorrect labels with high sensitivity in named entity recognition corpora. We incorporated our <a href="https://en.wikipedia.org/wiki/Sieve_theory">sieve</a> into an end-to-end system for cleaning NLP corpora, implemented as a modular collection of Jupyter notebooks built on extensions to the Pandas DataFrame library. We used this system to identify incorrect labels in the CoNLL-2003 corpus for English-language named entity recognition (NER), one of the most influential corpora for NER model research. Unlike previous work that only looked at a subset of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>’s validation fold, our automated sieve enabled us to examine the entire corpus in depth. Across the entire CoNLL-2003 corpus, we identified over 1300 incorrect labels (out of 35089 in the corpus). We have published our corrections, along with the code we used in our experiments. We are developing a repeatable version of the process we used on the CoNLL-2003 corpus as an open-source library.</abstract>
      <url hash="3b9c164d">2021.dash-1.10</url>
      <doi>10.18653/v1/2021.dash-1.10</doi>
      <bibkey>muthuraman-etal-2021-data</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="11">
      <title>Building Low-Resource NER Models Using Non-Speaker Annotations<fixed-case>NER</fixed-case> Models Using Non-Speaker Annotations</title>
      <author><first>Tatiana</first><last>Tsygankova</last></author>
      <author><first>Francesca</first><last>Marini</last></author>
      <author><first>Stephen</first><last>Mayhew</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>62–69</pages>
      <abstract>In low-resource natural language processing (NLP), the key problems are a lack of target language training data, and a lack of native speakers to create it. Cross-lingual methods have had notable success in addressing these concerns, but in certain common circumstances, such as insufficient pre-training corpora or languages far from the source language, their performance suffers. In this work we propose a complementary approach to building low-resource Named Entity Recognition (NER) models using non-speaker (NS) annotations, provided by annotators with no prior experience in the target language. We recruit 30 participants in a carefully controlled annotation experiment with <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a>, <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, and <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>. We show that use of NS annotators produces results that are consistently on par or better than cross-lingual methods built on modern contextual representations, and have the potential to outperform with additional effort. We conclude with observations of common annotation patterns and recommended implementation practices, and motivate how NS annotations can be used in addition to prior methods for improved performance.</abstract>
      <url hash="b6fee22a">2021.dash-1.11</url>
      <doi>10.18653/v1/2021.dash-1.11</doi>
      <bibkey>tsygankova-etal-2021-building</bibkey>
    </paper>
    <paper id="13">
      <title>CrossCheck : Rapid, Reproducible, and Interpretable Model Evaluation<fixed-case>C</fixed-case>ross<fixed-case>C</fixed-case>heck: Rapid, Reproducible, and Interpretable Model Evaluation</title>
      <author><first>Dustin</first><last>Arendt</last></author>
      <author><first>Zhuanyi</first><last>Shaw</last></author>
      <author><first>Prasha</first><last>Shrestha</last></author>
      <author><first>Ellyn</first><last>Ayton</last></author>
      <author><first>Maria</first><last>Glenski</last></author>
      <author><first>Svitlana</first><last>Volkova</last></author>
      <pages>79–85</pages>
      <abstract>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> and identify avenues for future <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> improvements. In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis. We describe the tool, discuss design and implementation details, and present three NLP use cases   named entity recognition, <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>, and clickbait detection that show the benefits of using the tool for model evaluation. CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models’ generalizability and highlight models’ limitations, strengths and weaknesses. Furthermore, CrossCheck is implemented as a <a href="https://en.wikipedia.org/wiki/Jupyter">Jupyter widget</a>, which allows for rapid and convenient integration into existing model development workflows.</abstract>
      <url hash="b2a2930a">2021.dash-1.13</url>
      <doi>10.18653/v1/2021.dash-1.13</doi>
      <bibkey>arendt-etal-2021-crosscheck</bibkey>
      <pwccode url="https://github.com/pnnl/crosscheck" additional="false">pnnl/crosscheck</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    <title_es>CrossCheck: evaluación de modelos rápida, reproducible e interpretable</title_es>
      <title_pt>CrossCheck: Avaliação de Modelo Rápida, Reprodutível e Interpretável</title_pt>
      <title_fr>CrossCheck : évaluation de modèle rapide, reproductible et interprétable</title_fr>
      <title_ar>CrossCheck: تقييم نموذج سريع وقابل للتكرار وقابل للتفسير</title_ar>
      <title_hi>CrossCheck: रैपिड, प्रतिलिपि प्रस्तुत करने योग्य, और Interpretable मॉडल मूल्यांकन</title_hi>
      <title_ja>クロスチェック：迅速、再現性、および解釈可能なモデル評価</title_ja>
      <title_ru>Перекрестная проверка: быстрая, воспроизводимая и интерпретируемая оценка модели</title_ru>
      <title_zh>交叉检:速、可重见且可解者</title_zh>
      <title_ga>CrossCheck: Meastóireacht Mhear, In-atáirgthe agus Inléirithe</title_ga>
      <title_ka>CrossCheck: სიჩქარე, გარემოდისური და ინტერპლექციური მოდელის განსაზღვრება</title_ka>
      <title_el>Γρήγορη, αναπαραγώγιμη και ερμηνευτή αξιολόγηση μοντέλων</title_el>
      <title_hu>CrossCheck: Gyors, reprodukálható és értelmezhető modellértékelés</title_hu>
      <title_it>CrossCheck: valutazione rapida, riproducibile e interpretabile del modello</title_it>
      <title_lt>Kryžminis patikrinimas: greitas, reprodukcinis ir aiškinamasis modelio vertinimas</title_lt>
      <title_kk>Қосымша тексеру: жылдамдық, қайталануы және аударылатын үлгілер оқиғасы</title_kk>
      <title_mk>CrossCheck: Rapid, Reproducible, and Interpretable Model Evaluation</title_mk>
      <title_ms>CrossCheck: Rapid, Reproducible, and Interpretable Model Evaluation</title_ms>
      <title_mt>Cross Check: Evalwazzjoni tal-Mudell Rapida, Riproduċibbli u Interpretabbli</title_mt>
      <title_ml>ക്രോസ്സ് പരിശോധിക്കുക: റാപ്പിഡ്, റിപ്പോര്‍ട്ട് ചെയ്യുവാനും പരിഭാഷപ്പെടുത്തുവാനുള്ള മോഡി</title_ml>
      <title_mn>CrossCheck: Хурдан, Хүйцэтгэлтэй, Интернеттэй загварын үнэлгээ</title_mn>
      <title_no>Kryss- sjekk: Rapid, Reproducible og Interpretable Modell Evaluering</title_no>
      <title_pl>CrossCheck: Szybka, reprodukowalna i interpretowalna ocena modelu</title_pl>
      <title_ro>CrossCheck: Evaluare rapidă, reproductibilă și interpretabilă a modelului</title_ro>
      <title_si>Name</title_si>
      <title_sr>Krstoprovjera: brza, preobrazljiva i preobrazljiva ocjena modela</title_sr>
      <title_so>Check: Rapid, Reprodible, and Interpretable Model evaluation</title_so>
      <title_sv>CrossCheck: Snabb, reproducerbar och tolkningsbar modellutvärdering</title_sv>
      <title_ta>கிராஸ்ச் சரிபார்ப்பு: Rapid, Reprodible, and Interpretable Model Evaluation</title_ta>
      <title_ur>کروس چک: سرعت، دوبارہ پیدا کرنے والا، اور مفصل قابل موڈل Evaluation</title_ur>
      <title_vi>Kiểm tra chéo: Đánh giá Mô hình nhanh, Reprodable và giải thích</title_vi>
      <title_uz>Check: Rapid, Reprodible, and Interpretable Model Evaluation</title_uz>
      <title_bg>Кръстосана проверка: бърза, възпроизводима и тълкуваема оценка на модела</title_bg>
      <title_nl>CrossCheck: Snelle, reproduceerbare en interpreteerbare modelbeoordeling</title_nl>
      <title_da>CrossCheck: Hurtig, reproducerbar og fortolkbar modelvurdering</title_da>
      <title_id>CrossCheck: Rapid, Reproducible, and Interpretable Model Evaluation</title_id>
      <title_hr>Krstoprovjera: brza, reproduktivna i preobražljiva ocjena modela</title_hr>
      <title_ko>교차 검사: 신속하고 중복 가능하며 해석 가능한 모델 평가</title_ko>
      <title_de>CrossCheck: Schnelle, reproduzierbare und interpretierbare Modellbewertung</title_de>
      <title_sw>Check: Rapid, Reprodible, and Interpretable Model Evaluation</title_sw>
      <title_af>Kruistoets: Rapid, Reproducible, en Interpretable Model Evaluering</title_af>
      <title_tr>CrossCheck</title_tr>
      <title_sq>CrossCheck: vlerësim i shpejtë, i riprodhueshëm dhe i interpretueshëm i modelit</title_sq>
      <title_fa>کروس چک: ارزیابی قابل تغییر سریع، تغییر‌پذیر و قابل تغییر‌پذیر مدل</title_fa>
      <title_am>Check: Rapid, Reprodible, and Interpretable Model Evaluation</title_am>
      <title_bs>Krstoprovjera: brza, reproduktivna i preobrazna ocjena modela</title_bs>
      <title_bn>CrossCheck: Rapid, Reproducible, and Interpretable Model Evaluation</title_bn>
      <title_hy>Comment</title_hy>
      <title_az>CrossCheck: Hızlı, Yenidən Dönüşdürülə bilər və Əlaqətlə Model Qıymeti</title_az>
      <title_ca>CrossCheck: Evaluació ràpida, reproducible i interpretable del model</title_ca>
      <title_et>CrossCheck: kiire, reprodutseeritav ja tõlgendatav mudeli hindamine</title_et>
      <title_fi>CrossCheck: Nopea, toistettavissa ja tulkittavissa oleva mallien arviointi</title_fi>
      <title_cs>CrossCheck: Rychlé, reprodukovatelné a interpretovatelné hodnocení modelu</title_cs>
      <title_jv>ProgressBarUpdates</title_jv>
      <title_ha>Check: Rapid, Repositable, and Translate Model</title_ha>
      <title_sk>CrossCheck: hitro, reproduktivno in tolmačljivo ocenjevanje modela</title_sk>
      <title_he>CrossCheck: Rapid, Reproducible, and Interpretable Model Evaluation</title_he>
      <title_bo>CrossCheck ៖ མགྱོག་དང་བསྐྱར་འདྲེན་བྱེད་རུང་བའི་མ་དབྱིབས་དཔྱད་བཟོ་རུང་བ</title_bo>
      <abstract_ar>تقييم يتجاوز مقاييس الأداء الإجمالية ، على سبيل المثال تعتبر درجة F1 أمرًا ضروريًا لإنشاء مستوى مناسب من الثقة في نماذج التعلم الآلي وتحديد السبل لتحسين النماذج في المستقبل. في هذه الورقة ، نوضح CrossCheck ، وهي قدرة تفاعلية للمقارنة السريعة عبر النماذج وتحليل الخطأ القابل للتكرار. نحن نصف الأداة ، ونناقش تفاصيل التصميم والتنفيذ ، ونقدم ثلاث حالات لاستخدام البرمجة اللغوية العصبية - التعرف على الكيانات المسماة ، وفهم القراءة ، واكتشاف طعم النقرات التي تُظهر فوائد استخدام الأداة لتقييم النموذج. يتيح CrossCheck للمستخدمين اتخاذ قرارات مستنيرة عند الاختيار بين نماذج متعددة ، وتحديد متى تكون النماذج صحيحة وأي أمثلة لها ، والتحقق مما إذا كانت النماذج ترتكب نفس الأخطاء التي يرتكبها البشر ، وتقييم إمكانية تعميم النماذج وإبراز قيود النماذج ونقاط القوة والضعف فيها. علاوة على ذلك ، يتم تنفيذ CrossCheck باعتباره عنصر واجهة مستخدم Jupyter ، والذي يسمح بالتكامل السريع والمريح في تدفقات عمل تطوير النماذج الحالية.</abstract_ar>
      <abstract_pt>Avaliação além das métricas de desempenho agregadas, por exemplo O F1-score é crucial para estabelecer um nível apropriado de confiança nos modelos de aprendizado de máquina e identificar caminhos para futuras melhorias do modelo. Neste artigo, demonstramos o CrossCheck, um recurso interativo para comparação rápida entre modelos e análise de erros reproduzível. Descrevemos a ferramenta, discutimos detalhes de design e implementação e apresentamos três casos de uso de PNL – reconhecimento de entidade nomeada, compreensão de leitura e detecção de clickbait que mostram os benefícios de usar a ferramenta para avaliação de modelos. O CrossCheck permite que os usuários tomem decisões informadas ao escolher entre vários modelos, identifiquem quando os modelos estão corretos e para quais exemplos, investiguem se os modelos estão cometendo os mesmos erros que os humanos, avaliem a generalização dos modelos e destaquem as limitações, pontos fortes e fracos dos modelos. Além disso, o CrossCheck é implementado como um widget Jupyter, que permite uma integração rápida e conveniente em fluxos de trabalho de desenvolvimento de modelos existentes.</abstract_pt>
      <abstract_es>La evaluación más allá de las métricas de rendimiento agregadas, por ejemplo, la puntuación F1, es crucial tanto para establecer un nivel adecuado de confianza en los modelos de aprendizaje automático como para identificar vías para futuras mejoras de los modelos. En este artículo demostramos CrossCheck, una capacidad interactiva para la comparación rápida entre modelos y el análisis de errores reproducible. Describimos la herramienta, analizamos los detalles de diseño e implementación y presentamos tres casos de uso de PNL: reconocimiento de entidades denominadas, comprensión lectora y detección de clickbait que muestran los beneficios de usar la herramienta para la evaluación de modelos. CrossCheck permite a los usuarios tomar decisiones informadas al elegir entre varios modelos, identificar cuándo los modelos son correctos y para qué ejemplos, investigar si los modelos están cometiendo los mismos errores que los humanos, evaluar la generalización de los modelos y destacar las limitaciones, fortalezas y debilidades. Además, CrossCheck se implementa como un widget de Jupyter, que permite una integración rápida y cómoda en los flujos de trabajo de desarrollo de modelos existentes.</abstract_es>
      <abstract_fr>L'évaluation au-delà des mesures de performance agrégées, par exemple le score F1, est cruciale pour établir un niveau de confiance approprié dans les modèles d'apprentissage automatique et identifier des pistes d'amélioration future des modèles. Dans cet article, nous présentons CrossCheck, une fonctionnalité interactive de comparaison rapide entre modèles et d'analyse d'erreur reproductible. Nous décrivons l'outil, discutons des détails de conception et de mise en œuvre, et présentons trois cas d'utilisation de la NLP : la reconnaissance d'entités nommées, la compréhension en lecture et la détection de clickbait qui montrent les avantages de l'utilisation de l'outil pour l'évaluation de modèles. CrossCheck permet aux utilisateurs de prendre des décisions éclairées lorsqu'ils choisissent entre plusieurs modèles, d'identifier quand les modèles sont corrects et pour quels exemples, d'étudier si les modèles commettent les mêmes erreurs que les humains, d'évaluer la généralisabilité des modèles et de mettre en évidence les limites, les forces et faiblesses. De plus, CrossCheck est implémenté en tant que widget Jupyter, ce qui permet une intégration rapide et pratique dans les flux de travail de développement de modèles existants.</abstract_fr>
      <abstract_ja>F 1スコアなどの総合的なパフォーマンス指標を超えた評価は、機械学習モデルにおける適切なレベルの信頼性を確立し、将来のモデル改善のための手段を特定するために重要です。 本稿では、迅速なクロスモデル比較と再現可能なエラー解析のための対話型機能であるCrossCheckを実証する。 ツールについて説明し、設計と実装の詳細を説明し、モデル評価にツールを使用する利点を示す、名前付きエンティティ認識、読み取り理解、クリックベイト検出の3つのNLPユースケースを提示します。 CrossCheckを使用すると、ユーザーは、複数のモデルを選択する際に情報に基づいた意思決定を行い、モデルが正しいタイミングと例を特定し、モデルが人間と同じ間違いを犯しているかどうかを調査し、モデルの一般化性を評価し、モデルの限界、長所、短所を強調することができます。 さらに、CrossCheckはJupyterウィジェットとして実装されており、既存のモデル開発ワークフローに迅速かつ便利に統合できます。</abstract_ja>
      <abstract_hi>समग्र प्रदर्शन मैट्रिक्स से परे मूल्यांकन, उदाहरण के लिए F1-स्कोर, मशीन लर्निंग मॉडल में विश्वास का एक उपयुक्त स्तर स्थापित करने और भविष्य के मॉडल सुधारों के लिए मार्गों की पहचान करने के लिए महत्वपूर्ण है। इस पेपर में हम CrossCheck, तेजी से क्रॉस-मॉडल तुलना और पुन: प्रस्तुत करने योग्य त्रुटि विश्लेषण के लिए एक इंटरैक्टिव क्षमता प्रदर्शित करते हैं। हम उपकरण का वर्णन करते हैं, डिजाइन और कार्यान्वयन विवरणों पर चर्चा करते हैं, और तीन एनएलपी उपयोग मामलों को प्रस्तुत करते हैं - नामित इकाई मान्यता, पढ़ने की समझ, और क्लिकबेट डिटेक्शन जो मॉडल मूल्यांकन के लिए उपकरण का उपयोग करने के लाभ दिखाते हैं। क्रॉसचेक उपयोगकर्ताओं को कई मॉडलों के बीच चयन करते समय सूचित निर्णय लेने में सक्षम बनाता है, यह पहचानता है कि मॉडल कब सही हैं और किन उदाहरणों के लिए, जांच करें कि क्या मॉडल मनुष्यों के समान गलतियां कर रहे हैं, मॉडल की सामान्यता का मूल्यांकन करते हैं और मॉडल की सीमाओं, ताकत और कमजोरियों को उजागर करते हैं। इसके अलावा, CrossCheck को एक Jupyter विजेट के रूप में लागू किया जाता है, जो मौजूदा मॉडल विकास वर्कफ़्लो में तेजी से और सुविधाजनक एकीकरण की अनुमति देता है।</abstract_hi>
      <abstract_ru>Оценка, выходящая за рамки совокупных показателей эффективности, например, оценка по шкале F1, имеет решающее значение как для установления соответствующего уровня доверия к моделям машинного обучения, так и для определения путей улучшения будущих моделей. В этой статье мы демонстрируем CrossCheck, интерактивную возможность быстрого сравнения кросс-моделей и воспроизводимого анализа ошибок. Мы описываем инструмент, обсуждаем детали проектирования и реализации и представляем три варианта использования NLP – распознавание именованных сущностей, понимание чтения и обнаружение кликбейтов, которые показывают преимущества использования инструмента для оценки модели. CrossCheck позволяет пользователям принимать обоснованные решения при выборе между несколькими моделями, определять, когда модели правильны и для каких примеров, исследовать, допускают ли модели те же ошибки, что и люди, оценивать обобщаемость моделей и выделять ограничения, сильные и слабые стороны моделей. Кроме того, CrossCheck реализован в виде виджета Jupyter, который позволяет быстро и удобно интегрироваться в существующие рабочие процессы разработки моделей.</abstract_ru>
      <abstract_zh>除总体性能指标(如 F1 分数)外之评估,于机器学模中立信级而定未来改进之途至重。 本文之中,演示CrossCheck,此所以速跨形势,较之交互式功也。 述其器用,论其巧致,而见三NLP用例 - 名实识,观点击饵检,展其利。 CrossCheck使用户得择智于数间,定其示例,察其犯与人同非,论其可广而显其局限性,美恶。 CrossCheck为Jupyter小部,可速成就。</abstract_zh>
      <abstract_ga>Meastóireacht thar méadracht feidhmíochta comhiomlán, e.g. Tá scór F1 ríthábhachtach chun leibhéal cuí muiníne a bhunú i múnlaí meaisínfhoghlama agus chun bealaí a aithint le haghaidh feabhsuithe ar mhúnlaí amach anseo. Sa pháipéar seo léirímid CrossCheck, cumas idirghníomhach chun comparáid tapa tras-mhúnla agus anailís earráide in-atáirgthe a dhéanamh. Déanaimid cur síos ar an uirlis, pléimid sonraí dearaidh agus cur chun feidhme, agus cuirimid i láthair trí chás úsáide NLP - aithint aonáin ainmnithe, léamhthuiscint, agus braite clic-bhait a thaispeánann na buntáistí a bhaineann leis an uirlis a úsáid le haghaidh meastóireachta samhlacha. Cuireann CrossCheck ar chumas úsáideoirí cinntí eolasacha a dhéanamh agus iad ag roghnú idir samhlacha iolracha, a aithint cathain atá na samhlacha i gceart agus cad iad na samplaí ina leith, imscrúdú a dhéanamh an bhfuil na botúin chéanna á ndéanamh ag samhlacha agus a dhéanann daoine, measúnú a dhéanamh ar ghinearáltacht na samhlacha agus béim a chur ar shrianta, láidreachtaí agus laigí samhlacha. Ina theannta sin, cuirtear CrossCheck i bhfeidhm mar ghiuirléid Jupyter, a cheadaíonn comhtháthú tapa agus áisiúil isteach sna sreafaí oibre forbartha samhlacha atá ann cheana féin.</abstract_ga>
      <abstract_ka>ადგრაფიური პროცენტის მეტრიკის გარეშე განსაზღვრება, მაგალითად F1- სოფლიო, უფრო მნიშვნელოვანია, რომ ორივე განსაზღვრება სწორესი მნიშვნელოვანი მაქსინური სწავლების მოდელში და მო ამ დომენტში ჩვენ CrossCheck-ს გამოჩვენებთ, ინტერაქტიური შესაძლებლობა სიჩქარე კრისმოდელის შესაბამისათვის და გამოცდილებელი შეცდომის ანალიზაციისთვის. ჩვენ განახსენებთ ხელსაწყოფილი, განახსენება და განახსენება დეტალები, და გამოყენება სამი NLP გამოყენება - სახელსაწყოფილი განახსენება, სახელსაწყოფილი განახსენება, კითხვა განახსენება, და კლე CrossCheck-ის მომხმარებელი შესაძლებელია მომხმარებელი გავაკეთოთ ინფორმაციული განსაზღვრება, როდესაც მოდელები სწორია და რომელსაც მაგალითად მოდელები გავაკეთოთ თუ არა მოდელები იგივე შეცდომები როგორც ადამიანები, მოდელების გენერალიზაცი დამატებით, CrossCheck იყენებულია როგორც Jupyter საქაღალდე, რომელიც შესაძლებელია სწრაფად და საჭირო ინტერგურაციას მსოფლიო მოდელური განვითარებაში.</abstract_ka>
      <abstract_hu>Az összesített teljesítménymutatókon (például F1-pontszámon) túli értékelés kulcsfontosságú mind a gépi tanulási modellekbe vetett megfelelő bizalom kialakításához, mind pedig a jövőbeli modelljavítások lehetőségeinek meghatározásához. Ebben a tanulmányban bemutatjuk a CrossCheck interaktív képességét a gyors cross-model összehasonlításra és reprodukálható hibaelemzésre. Leírjuk az eszközt, megvitatjuk a tervezési és megvalósítási részleteket, és bemutatjuk három NLP felhasználási esetet - entitás felismerés, olvasási megértés és kattintásérzékelés, amelyek bemutatják az eszköz modellek értékeléséhez való használatának előnyeit. A CrossCheck lehetővé teszi a felhasználók számára, hogy megalapozott döntéseket hozzanak, amikor több modell közül választanak, azonosítsák, mikor a modellek helyesek, és mely példákra vonatkozóan, megvizsgálják, hogy a modellek ugyanazokat a hibákat követik-e el, mint az emberek, értékeljék a modellek általánosíthatóságát és kiemeljék a modellek korlátait, erősségeit és gyengeségeit. Ezenkívül a CrossCheck Jupyter widgetként kerül bevezetésre, amely lehetővé teszi a gyors és kényelmes integrációt a meglévő modellfejlesztési munkafolyamatokba.</abstract_hu>
      <abstract_el>Η αξιολόγηση πέρα από τις συνολικές μετρήσεις απόδοσης, π.χ. βαθμολογία F1, είναι ζωτικής σημασίας τόσο για την καθιέρωση κατάλληλου επιπέδου εμπιστοσύνης στα μοντέλα μηχανικής μάθησης όσο και για τον προσδιορισμό οδών για μελλοντικές βελτιώσεις μοντέλων. Σε αυτή την εργασία καταδεικνύουμε μια διαδραστική ικανότητα για γρήγορη σύγκριση μεταξύ μοντέλων και αναπαραγώγιμη ανάλυση σφαλμάτων. Περιγράφουμε το εργαλείο, συζητάμε λεπτομέρειες σχεδιασμού και εφαρμογής και παρουσιάζουμε τρεις περιπτώσεις χρήσης για αναγνώριση ονομαστικής οντότητας, κατανόηση ανάγνωσης και ανίχνευση που δείχνουν τα οφέλη της χρήσης του εργαλείου για αξιολόγηση μοντέλων. Το επιτρέπει στους χρήστες να λαμβάνουν τεκμηριωμένες αποφάσεις όταν επιλέγουν ανάμεσα σε πολλαπλά μοντέλα, να εντοπίζουν πότε τα μοντέλα είναι σωστά και για ποια παραδείγματα, να διερευνούν αν τα μοντέλα κάνουν τα ίδια λάθη με τους ανθρώπους, να αξιολογούν τη γενίκευση των μοντέλων και να αναδεικνύουν τους περιορισμούς, τις δυνάμεις και τις αδυναμίες των μοντέλων. Επιπλέον, εφαρμόζεται ως ένα γραφικό στοιχείο το οποίο επιτρέπει την ταχεία και άνετη ενσωμάτωση στις υπάρχουσες ροές εργασίας ανάπτυξης μοντέλων.</abstract_el>
      <abstract_it>La valutazione al di là delle metriche di prestazione aggregate, ad esempio il punteggio F1, è fondamentale sia per stabilire un livello adeguato di fiducia nei modelli di machine learning sia per identificare le strade per futuri miglioramenti dei modelli. In questo articolo mostriamo CrossCheck, una capacità interattiva per un rapido confronto tra modelli incrociati e analisi degli errori riproducibili. Descriviamo lo strumento, discutiamo i dettagli di progettazione e implementazione e presentiamo tre casi d'uso NLP - riconoscimento entità, comprensione della lettura e rilevamento clickbait che mostrano i vantaggi dell'utilizzo dello strumento per la valutazione del modello. CrossCheck consente agli utenti di prendere decisioni informate quando scelgono tra più modelli, identificare quando i modelli sono corretti e per quali esempi, indagare se i modelli stanno commettendo gli stessi errori degli esseri umani, valutare la generalizzabilità dei modelli e evidenziare i limiti, i punti di forza e le debolezze dei modelli. Inoltre, CrossCheck è implementato come widget Jupyter, che consente una rapida e conveniente integrazione nei flussi di lavoro di sviluppo dei modelli esistenti.</abstract_it>
      <abstract_kk>Мысалы, F1- нұсқасы, машинаны оқыту үлгілеріне қасиетті сенім деңгейін орнату және келесі үлгілерді жақсартуға арналған жолдарды анықтау үшін көмектесу үшін маңызды. Бұл қағазда CrossCheck дегенді көрсету үшін тез қалқан үлгі салыстыру және қайталану мүмкіндігін интерактивті көрсету мүмкіндігін көрсетеді. Біз құрылғыны таңдап, дизайнды және істеу егжей- тегжейлерін талқылап, үш NLP қолдану үшін - аталған нысандарды анықтау, түсініктерді оқу және үлгі бағалау құралының пайдалануын көрсетеді. CrossCheck пайдаланушыларды бірнеше үлгі арасында таңдағанда мәліметті шешімдеу мүмкіндігін береді, үлгілер дұрыс екенін анықтайды, мысалдар үлгілер адамдардың бір қатесін жасап жатқан, үлгілердің жалпы шектерін, қуаттарын және ақшалығын анықтайды Қосымша, CrossCheck Jupyter бөлшегі ретінде орындалады. Бұл үлгі жасау жұмысының істемелеріне тез және оңай интеграциялауға мүмкіндік береді.</abstract_kk>
      <abstract_mk>Оценката надвор од агрегетните метрики на перформанса, на пример оценката F1, е клучна за воспоставување на соодветно ниво на доверба во моделите на машинско учење и идентификување на патиштата за идни подобрувања на моделот. Во овој документ ние демонстрираме CrossCheck, интерактивна способност за брза крстомоделна споредба и репродуктибилна анализа на грешки. Ја опишуваме алатката, разговараме за деталите за дизајнот и спроведувањето, и претставуваме три случаи на употреба на НЛП - именувано препознавање на ентитетите, читање разбирање, и детекција на клик- бајт кои покажуваат бенефиции од употребата на ала CrossCheck им овозможува на корисниците да донесат информирани одлуки кога избираат помеѓу повеќе модели, да идентификуваат кога моделите се точни и за кои примери, да истражуваат дали моделите прават исти грешки како луѓето, да ја проценат генерализацијата на моделите и да ги истакнат ограничувањата, силностите и сл Покрај тоа, CrossCheck се имплементира како веџет на Jupyter, кој овозможува брза и удобна интеграција во постоечките процеси на развој на моделот.</abstract_mk>
      <abstract_lt>Vertinimas, viršijantis bendruosius veiklos rodiklius, pvz., F1 rezultatus, yra labai svarbus siekiant nustatyti tinkamą pasitikėjimo mašin ų mokymosi modeliais lygį ir nustatyti galimybes ateityje tobulinti model į. Šiame dokumente parodomi CrossCheck, interaktyvus gebėjimas greitai palyginti įvairius modelius ir atkurti klaidų analizę. We describe the tool, discuss design and implementation details, and present three NLP use cases - named entity recognition, reading comprehension, and clickbait detection that show the benefits of using the tool for model evaluation.  CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models' generalizability and highlight models' limitations, strengths and weaknesses.  Be to, CrossCheck įgyvendinamas kaip Jupyter elementas, kuris leidžia greitai ir patogiai integruoti į esamus modelio kūrimo darbo srautus.</abstract_lt>
      <abstract_ms>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements.  In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis.  Kami menggambarkan alat ini, membincangkan rincian desain dan pelaksanaan, dan mempersembahkan tiga kes penggunaan NLP - pengenalan entiti bernama, pemahaman membaca, dan pengesan bar klik yang menunjukkan keuntungan menggunakan alat untuk penilaian model. CrossCheck membenarkan pengguna untuk membuat keputusan yang diberitahu bila memilih diantara model berbilang, mengenalpasti bila model betul dan untuk contoh-contoh mana, menyelidiki sama ada model membuat kesilapan yang sama dengan manusia, menilai keseluruhan model dan menyatakan keterangan, kekuatan dan kelemahan model. Furthermore, CrossCheck is implemented as a Jupyter widget, which allows for rapid and convenient integration into existing model development workflows.</abstract_ms>
      <abstract_ml>എഫ്‌1- സ്കോര്‍ക്കിനു ശേഷം പ്രകടന മെട്രിക്കുകള്‍ക്ക് മുന്‍പിലുള്ള വിശ്വാസം സ്ഥാപിക്കാനും ഭാവിയായ മോഡലിനുള്ള മാതൃകങ്ങള്‍ക്ക് വിശ്വ ഈ പത്രത്തില്‍ ഞങ്ങള്‍ ക്രോസ്ചെക്ക് കാണിച്ചുകൊടുക്കുന്നു, വേഗം ക്രോസ് മോഡലിനോട് തുല്യമാക്കുന്നതിനും പിന്നീട്  നമ്മള്‍ ഉപകരണത്തെ വിശദീകരിക്കുന്നു, ഡിസൈന്‍ ചെയ്യുന്നതും പ്രവര്‍ത്തിപ്പിക്കുന്നതിന്റെ വിശദീകരണങ്ങളും സംസാരിക്കുന്നു, മോഡല്‍ evaluation ഉപകരണത്തിനുള ക്രോസ്ചെക്ക് ഉപയോക്താക്കള്‍ പല മോഡലുകള്‍ക്കിടയില്‍ വിവരമറിയിക്കുമ്പോള്‍ തീരുമാനങ്ങള്‍ തെരഞ്ഞെടുക്കാന്‍ സാധ്യമല്ല, മോഡലുകള്‍ ശരിയാണെങ്കില്‍ നിരീക്ഷിക്കുക, ഉദാഹരണങ് അതിനുശേഷം, ക്രോസ്ചെക്ക് ജുപ്പൈറ്റര്‍ വിഡ്ജറ്റായി പ്രവര്‍ത്തിപ്പിക്കപ്പെടുന്നു. അത് വേഗം നിലവിലുള്ള മോഡല്‍ വികസിപ്</abstract_ml>
      <abstract_mt>L-evalwazzjoni lil hinn mill-metriċi aggregati tal-prestazzjoni, pereżempju l-punteġġ F1, hija kruċjali biex it-tnejn jistabbilixxu livell xieraq ta’ fiduċja fil-mudelli tat-tagħlim tal-magni u jidentifikaw modi g ħal titjib fil-mudell futur. F’dan id-dokument qed nippruvaw CrossCheck, kapaċità interattiva għal paragun rapidu bejn mudelli u analiżi ta’ żbalji riproduċibbli. We describe the tool, discuss design and implementation details, and present three NLP use cases - named entity recognition, reading comprehension, and clickbait detection that show the benefits of using the tool for model evaluation.  CrossCheck jippermetti lill-utenti jieħdu deċiżjonijiet infurmati meta jagħżlu bejn mudelli multipli, jidentifikaw meta l-mudelli jkunu korretti u għal liema eżempji, jinvestigaw jekk il-mudelli humiex qed jagħmlu l-istess żbalji bħall-bnedmin, jevalwaw il-ġeneralizzazzjoni tal-mudelli u jenfasizzaw il-limitazzjonijiet, il-qawwiet u d-dgħufijiet tal-mudelli Barra minn hekk, CrossCheck huwa implimentat bħala widget ta’ Jupyter, li jippermetti integrazzjoni rapid a u konvenjenti fil-flussi tax-xogħol eżistenti ta’ żvilupp mudell.</abstract_mt>
      <abstract_no>Evaluering utanfor aggregate utviklingsmeterikk, f.eks. F1- poeng, er viktig for å både oppretta eit passende tillit i maskinelæringsmodeller og identifisera avener for framtidige forbedringar av modeller. I denne papiret viser vi CrossCheck eit interaktiv kapasitet for rask samanlikning av krysmodel og reproduktiv feilanalyse. Vi beskriver verktøyet, diskuterer design og implementeringsdetaljar, og presenterer tre NLP-tilfelle - namnet entitetskjenning, lesing forståelse og klikk-oppdaging som viser fordelene til å bruka verktøyet for å evaluera modellen. Kryss- kontroll gjer brukarar å gjera informarte avgjøringar når du veljer mellom fleire modeller, identifiserer når modelane er rett og for kva eksempel, undersøk om modelane gjer same feil som mennesker, evaluer generelliseringsbehandlingar for modelane og markeringsbehandlingar, styrker og tyrke. I tillegg er CrossCheck implementert som eit Jupyter-element, som tillater rask og nødvendig integrering i eksisterande utviklingsfleksar for utviklingsfleksar.</abstract_no>
      <abstract_pl>Ocena wykraczająca poza zagregowane wskaźniki wydajności, np. wynik F1, ma kluczowe znaczenie zarówno dla ustalenia odpowiedniego poziomu zaufania do modeli uczenia maszynowego, jak i dla określenia możliwości poprawy w przyszłości modeli. W niniejszym artykule przedstawiamy CrossCheck, interaktywną możliwość szybkiego porównywania między modelami i powtarzalnej analizy błędów. Opisujemy narzędzie, omówimy szczegóły projektu i wdrożenia oraz przedstawiamy trzy przypadki zastosowania NLP w zakresie rozpoznawania nazwanych jednostek, zrozumienia czytania i wykrywania klikających, które pokazują korzyści płynące z użycia narzędzia do oceny modelu. CrossCheck umożliwia użytkownikom podejmowanie świadomych decyzji przy wyborze pomiędzy wieloma modelami, identyfikację, kiedy modele są poprawne i dla których przykładów, zbadanie, czy modele popełniają te same błędy co ludzie, ocenę uogólnialności modeli oraz podkreślenie ograniczeń, mocnych i słabych stron modeli. Ponadto CrossCheck jest implementowany jako widget Jupyter, co pozwala na szybką i wygodną integrację z istniejącymi przepływami pracy tworzenia modeli.</abstract_pl>
      <abstract_ro>Evaluarea dincolo de valorile de performanță agregate, de exemplu punctajul F1, este esențială atât pentru stabilirea unui nivel adecvat de încredere în modelele de învățare automată, cât și pentru identificarea căilor de îmbunătățire a modelelor viitoare. În această lucrare demonstrăm CrossCheck, o capacitate interactivă de comparare rapidă încrucișată și de analiză reproductibilă a erorilor. Descriem instrumentul, discutăm detaliile de proiectare și implementare și prezentăm trei cazuri de utilizare a PNL - recunoașterea entității, înțelegerea citirii și detectarea clickbait care arată beneficiile utilizării instrumentului pentru evaluarea modelului. CrossCheck permite utilizatorilor să ia decizii informate atunci când aleg între mai multe modele, să identifice când modelele sunt corecte și pentru ce exemple, să investigheze dacă modelele fac aceleași greșeli ca și oamenii, să evalueze generalizarea modelelor și să evidențieze limitările, punctele forte și punctele slabe ale modelelor. În plus, CrossCheck este implementat ca un widget Jupyter, care permite integrarea rapidă și convenabilă în fluxurile de lucru existente de dezvoltare a modelelor.</abstract_ro>
      <abstract_sr>Evaluacija izvan aggregatne metrike izvršnosti, na primer F1-rezultat, je ključna za uspostavljanje odgovarajuće g nivoa povjerenja u model e učenja mašina i identifikaciju avenata za buduće poboljšanje modela. U ovom papiru pokazujemo CrossCheck interaktivnu sposobnost za brzu usporedbu preko modela i reproduktivnu analizu greške. Opišemo alat, raspravljamo o detaljima dizajna i provedbe, i predstavljamo tri slučaja upotrebe NLP-a - priznanja entiteta, čitanje razumijevanja i otkrivanje mamaca koji pokazuju koristi korištenja alata za procjenu modela. CrossCheck omogućava korisnicima da donesu informativne odluke kada biraju između višestrukih modela, da identifikuju kada su modeli ispravni i za koje primjere, da istražuju da li modeli čine iste greške kao i ljudi, da procjenjuju generalizaciju modela i osvjetljavaju ograničenja modela, snage i slabosti. Osim toga, CrossCheck se provede kao Jupyter widget, koji omogućava brzu i prikladnu integraciju u postojeće protoke rada u modelu razvoja.</abstract_sr>
      <abstract_si>සම්පූර්ණ ක්‍රියාත්මක මෙට්‍රික්ස් වලින් විශ්වාස කරන්න, උදාහරණය F1-ස්කෝර්, දෙන්නම විශ්වාස කරන්න සලකුණු ස්ථානයක් තිය මේ පැත්තේ අපි Crosscheckව පෙන්වන්නම්, ඉක්මනින් ප්‍රවේශනය සහ ප්‍රවේශනය විශ්ලේෂණය සඳහා ඉක්මනින් ප්‍රවේශනය ස අපි උපකරණය විස්තර කරනවා, විද්‍යාපනය සහ විස්තර පරීක්ෂණය කතා කරනවා, සහ NLP භාවිතා විස්තර තුනක් තියෙනවා - නම් පරීක්ෂණය පරීක්ෂණය, කියනවා  Crosscheck සක්‍රිය කරන්න ප්‍රයෝජකයෝ විශ්වාස කරන්න ප්‍රයෝජකයෝ විශ්වාස කරන්න ප්‍රයෝජකයෝ විශ්වාස කරන්න, විශ්වාස කරන්න ප්‍රයෝජකයෝ විශ්වාස කරන්න, විශ්වාස කරන්න ප්‍ර ඊට පස්සේ, Crosscheck විදිහට Jupyter විජෙට් විදිහට පරීක්ෂා කරනවා, ඒකෙන් ඉක්මනින් සහ සාමාන්‍ය සම්බන්ධ විදිහට විදිහට</abstract_si>
      <abstract_so>Qiimeynta ku saabsan qaababka horumarinta, tusaale F1-scorka, waa muhiim in labadoodaba la sameyno heer ku haboon oo ku aamin karo qaababka barashada machineeya iyo sidoo kale loo caddeeyo qalabka horumarinta qaababka mustaqbalka ah. Qoraalkan waxaynu ku muujinnaa CrossCheck, awoodo interactive ah oo u sameynaya sameynta qalabka dhaqsaha ah iyo baaritaanka khaladda la soo celinayo. Waxaynu sawirannaa qalabka, baaraandegaa sawirada iyo waxyaabaha lagu soo bandhigi karo, waxaynu soo bandhignaynaa saddex xaaladood oo isticmaalaya isticmaalka NLP- magaca aqoonsashada entity, akhriska hoos-dhigista, iyo baaritaanka bandhigga, kaas oo muuqata faa'iidada isticmaalka qalabka qiimeynta Isticmaalayaasha CrossCheck waxay suurtogal u yeelan karaan go'aano ogeysiin marka ay dooranayaan tusaalayaal kala duduwan, caddeyso marka ay saxdaan, tusaale ahaan tusaalayaashooyinku ay sameynayaan qallooyinka sida dadka, qiimeeya qaababka dhalashada modelalka iyo xuduudaha modelalka, xoogga iyo itaalka. Furthermore, CrossCheck waxaa loo sameeyaa widget Jupyter, kaas oo u ogolaa in dhaqso iyo si sax ah la qabsado ubaxyo horumarinta model ah oo jira.</abstract_so>
      <abstract_sv>Utvärdering utöver aggregerade prestandamått, t.ex. F1-poäng, är avgörande för att både etablera en lämplig nivå av förtroende för maskininlärningsmodeller och identifiera vägar för framtida modellförbättringar. I denna uppsats demonstrerar vi CrossCheck, en interaktiv förmåga för snabb korsmodell jämförelse och reproducerbar felanalys. Vi beskriver verktyget, diskuterar design- och implementeringsdetaljer och presenterar tre användningsfall för NLP - namngiven entitetsigenkänning, läsförståelse och klickait detektering som visar fördelarna med att använda verktyget för modellutvärdering. CrossCheck gör det möjligt för användare att fatta välgrundade beslut när de väljer mellan flera modeller, identifiera när modellerna är korrekta och för vilka exempel, undersöka om modellerna gör samma misstag som människor, utvärdera modellernas generalisering och belysa modellernas begränsningar, styrkor och svagheter. Dessutom implementeras CrossCheck som en Jupyter widget, vilket möjliggör snabb och bekväm integration i befintliga modellutvecklingsarbetsflöden.</abstract_sv>
      <abstract_ur>ایک جمع عملکرد میٹریک کے بعد، جیسے F1-اسکور، ان دونوں کے لئے ایک مناسب سطح اعتماد کا مقرر کرنے کے لئے اہم ہے اور آیندہ موڈل کی اصلاح کے لئے منزلوں کو پہچان سکتے ہیں. اس کاغذ میں ہم کرس چک کو دکھاتے ہیں، سریع کرس موڈل مقایسہ اور دوبارہ تغییر قابلیت کے لئے ایک پیچیدگی قابلیت. ہم نے ابزار کو توصیح دیتے ہیں، طراحی اور عملومات کے معاملات کی بحث کرتی ہیں، اور تین NLP کے مطابق استعمال کے مطابق مطابق کرتی ہیں، نام داری پہچان لیتے ہیں، سمجھ پڑھتے ہیں، اور کلیکبی ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈ کرس چک کارساز کو بہت سی موڈلوں کے درمیان انتخاب کرنے کے موقع خبردار فیصلہ کرنے کے لئے اجازت دیتا ہے، موڈلوں کو پہچان دیتا ہے کہ کب سیدھے ہیں اور کس مثال کے لئے، تحقیق کرتا ہے کہ موڈلوں انسانوں کے ساتھ بھی سیدھی خطائیں کر رہے ہیں، موڈلوں کی عمومی اختیار اور موڈلوں کی حدود، قوت اور اس کے علاوہ، کروس چک ایک جوپیٹر ویڈیٹ کے طور پر عملکرد کی جاتی ہے، جسے سریع اور مناسب ترکیب دیتی ہے کہ موجود موجود ڈولیٹ ورک فول میں موجود ہے.</abstract_ur>
      <abstract_ta>குறிப்பிடுதல் செயல் முறைமைகளை விட மதிப்பீடு, எ. கா. F1- புள்ளிகள், இயந்திரம் கற்றல் மாதிரிகளில் ஒரு சரியான நம்பிக்கை மட்டத்தை உருவாக்குவதற்கும் ம இந்த காகிதத்தில் நாம் க்ராஸ்செக் காட்டுகிறோம், விரைவான மாதிரி ஒப்பிடுதல் மற்றும் பிழை அறிவிப்பதற்கான ஒரு நடிப் நாம் கருவியை விவரிக்க, வடிவமைப்பு மற்றும் செயல்பாட்டின் விவரங்களை விளக்க, மற்றும் தற்போது மூன்று NLP பயன்பாட்டு விவரங்கள் - பெயரிடப்பட்ட பொருள் அட க்ராஸ்செக் பல மாதிரிகளுக்கு இடையே தேர்ந்தெடுக்கும்போது பயனர் அறிவிப்பு முடிவுகளை எடுத்துக் கொள்ள இயலும், மாதிரிகள் சரியாக இருக்கும் போது கண்டுபிடிக்கவும், உதாரணங்கள Furthermore, CrossCheck is implemented as a Jupyter widget, which allows for rapid and convenient integration into existing model development workflows.</abstract_ta>
      <abstract_mn>Нэгдсэн үйл ажиллагааны метрик, жишээ нь F1-тоо, машины суралцах загварын тухай итгэл найдварын загварын сайжруулах арга замыг тодорхойлох нь чухал. Энэ цаасан дээр бид CrossCheck-г харуулж байна. Хурдан давхар загварын харьцуулах боломжтой алдаа шинжилгээний интерактив чадварыг харуулж байна. Бид хэрэгслийг тайлбарлаж, дизайн болон үйлдвэрлэлийн тухай ярилцаж, 3 NLP хэрэглээний хэрэглээний тухай ярилцаж, нэрлэгдсэн бүтээгдэхүүний хүлээн зөвшөөрөл, ойлголт уншиж, загвар дүгнэх хэрэгслийг ашиглах хэрэгцээг хар CrossCheck хэрэглэгчид олон загварын хоорондоо сонгох үед мэдээлэл шийдвэр гаргаж, загварууд яг зөв вэ гэдгийг тодорхойлох боломжтой болгодог бөгөөд хэн жишээ нь, загварууд хүмүүстэй ижил алдаа хийж байгааг судалж, загварын ерөнхийлөгч чадварыг үнэлж, загварын хязгаа Дараа нь CrossCheck нь Jupyter-ын виджетүүд болгон хөгжүүлэх загварын хөгжүүлэх үйл ажиллагааны урсгалыг хурдан болон удирдлагатай нэгтгэх боломжтой болгодог.</abstract_mn>
      <abstract_vi>Đánh giá vượt qua mức đo hoá suất tổng thể, ví dụ. F1-điểm, là điều quan trọng nhất để thiết lập một mức độ tin tưởng phù hợp trong các mô hình học máy và xác định các phương pháp cải tiến mô hình tương lai. Trong tờ giấy này chúng tôi chứng minh CrossCheck, một khả năng tương tác cho việc so sánh nhanh trên mẫu và phân tích lỗi có thể tái tạo. Chúng tôi mô tả công cụ, thảo luận chi tiết thiết kế và tiến hành, và giới thiệu ba trường hợp dùng kiểu N.P. tên là nhận diện thực thể, đọc thấu hiểu, và phát hiện kiểu điển cho thấy lợi ích của việc sử dụng công cụ để đánh giá mô hình. CrossCheck cho người dùng khả năng đưa ra quyết định dựa trên khi chọn giữa nhiều mẫu, xác định khi nào các mô-đun đã đúng và ví dụ cho đó, kiểm tra xem các mô-đun đang phạm phải sai lầm như con người, đánh giá tính rộng của mô-đun và khả năng hiển thị giới hạn, điểm mạnh và nhược điểm của mô-tượng. Hơn nữa, CrossCheck được thực hiện như một ô điều khiển Jupyger, hỗ trợ cho việc hòa nhập nhanh và tiện lợi vào các dòng dõi phát triển mô hình đã có.</abstract_vi>
      <abstract_uz>Name Bu hujjatda CrossCheck'ni ko'rsatishimiz mumkin, juda tez o'xshash modelga o'xshash va taʼminlovchi xato analyzeri uchun interaktiv qobiliyatni koʻrsatiladi. Biz asboblarni anglatamiz, dizayn va bajarishni taʼrifi qilamiz, va uchta NLP foydalanuvchilarni hozir qilamiz - ma'lumotni aniqlash, kompyuterni oʻqish va tuzuvni aniqlash va model qiymati uchun foydalanish asboblarini koʻrsatish mumkin. CrossCheck bir nechta modellar orasidan tanlanganda, modellar to ʻgʻri boʻlganda aniqlash imkoniyatini beradi. Masalan, modellar odamlarga bir xatolarni qo'llashadi, modellarning umumiy yetarligini qidirish va modellarning chegaralarini koʻrsatish, қувватлар ва заифликларини ko'rsatish mumkin. Koʻrsatgich, CrossCheck mavjud model taʼminlovchi ishlayotlariga tez va juda muhim birlashtirishga ruxsat beradi.</abstract_uz>
      <abstract_bg>Оценката отвъд агрегираните показатели за ефективността, например оценка е от решаващо значение както за установяване на подходящо ниво на доверие в моделите на машинно обучение, така и за определяне на пътищата за бъдещи подобрения на моделите. В тази статия демонстрираме интерактивна способност за бързо сравняване на кръстосани модели и възпроизводим анализ на грешките. Описваме инструмента, обсъждаме подробности за проектирането и внедряването и представяме три случая на използване на НЛП - разпознаване на обекти, разбиране за четене и откриване на щракване, които показват ползите от използването на инструмента за оценка на модела. Кросчек позволява на потребителите да вземат информирани решения при избора между множество модели, да идентифицират кога моделите са правилни и за кои примери, да изследват дали моделите правят същите грешки като хората, да оценяват обобщаваемостта на моделите и да подчертават ограниченията, силните и слабите страни на моделите. Освен това се реализира като джаджа, която позволява бърза и удобна интеграция в съществуващите работни потоци за разработване на модели.</abstract_bg>
      <abstract_nl>Evaluatie die verder gaat dan geaggregeerde prestatiestatistieken, bijvoorbeeld F1-score, is cruciaal om zowel een passend niveau van vertrouwen in machine learning modellen te creëren als manieren te identificeren voor toekomstige modelverbeteringen. In dit artikel demonstreren we CrossCheck, een interactieve mogelijkheid voor snelle cross-model vergelijking en reproduceerbare foutanalyse. We beschrijven de tool, bespreken ontwerp- en implementatiedetails en presenteren drie NLP-gebruikscases voor naamsbekendheid, leesbegrip en clickbait-detectie die de voordelen van het gebruik van de tool voor modelbeoordeling tonen. CrossCheck stelt gebruikers in staat om weloverwogen beslissingen te nemen bij de keuze tussen meerdere modellen, te identificeren wanneer de modellen correct zijn en voor welke voorbeelden, te onderzoeken of de modellen dezelfde fouten maken als mensen, de generaliseerbaarheid van modellen te evalueren en de beperkingen, sterke en zwakke punten van modellen te belichten. Bovendien is CrossCheck geïmplementeerd als Jupyter widget, wat een snelle en gemakkelijke integratie in bestaande modelontwikkelingsworkflows mogelijk maakt.</abstract_nl>
      <abstract_hr>Procjenjivanje izvan aggregatne mjere učinka, na primjer F1-rezultat, ključno je za utvrđivanje odgovarajuće nivoa povjerenja u modele učenja strojeva i identifikaciju avenata za buduće poboljšanje modela. U ovom papiru pokazujemo CrossCheck interaktivnu sposobnost za brzu usporedbu preko modela i reproduktivnu analizu greške. Opišemo alat, raspravljamo o detaljima dizajna i provedbe, i predstavljamo tri slučaja upotrebe NLP-a - priznanja entiteta, čitanje razumijevanja i otkrivanje mamaca koji pokazuju koristi korištenja alata za procjenu modela. CrossCheck omogućava korisnicima donijeti informativne odluke kada biraju između višestrukih modela, identificirati kada su modeli ispravni i za koje primjere, istražiti da li modeli čine iste greške kao i ljudi, procijeniti generalizaciju modela i osvjetljavati ograničenja modela, snage i slabosti. Osim toga, CrossCheck se provede kao Jupyter widget, koji omogućava brzu i prikladnu integraciju u postojeće protoke rada u modelu razvoja.</abstract_hr>
      <abstract_da>Evaluering ud over aggregerede præstationsmålinger, f.eks. F1-score, er afgørende for både at etablere et passende niveau af tillid til maskinlæringsmodeller og identificere muligheder for fremtidige modelforbedringer. I denne artikel demonstrerer vi CrossCheck, en interaktiv evne til hurtig cross-model sammenligning og reproducerbar fejlanalyse. Vi beskriver værktøjet, diskuterer design- og implementeringsdetaljer og præsenterer tre NLP-brugscases - navngivet entitetsgenkendelse, læseforståelse og klikbait detektion, der viser fordelene ved at bruge værktøjet til modelvurdering. CrossCheck giver brugerne mulighed for at træffe informerede beslutninger, når de vælger mellem flere modeller, identificere, hvornår modellerne er korrekte og for hvilke eksempler, undersøge, om modellerne begår de samme fejl som mennesker, evaluere modellernes generalisering og fremhæve modellernes begrænsninger, styrker og svagheder. Desuden er CrossCheck implementeret som en Jupyter widget, som muliggør hurtig og bekvem integration i eksisterende modeludviklingsarbejdsgange.</abstract_da>
      <abstract_id>Evaluasi melebihi metrik prestasi agregat, misalnya skor F1, adalah penting untuk kedua-dua menetapkan tingkat kepercayaan yang sesuai dalam model belajar mesin dan mengidentifikasi jalan untuk perkembangan model masa depan. Dalam kertas ini kami menunjukkan CrossCheck, kemampuan interaktif untuk perbandingan cross-model cepat dan analisis kesalahan yang dapat diproduksi. We describe the tool, discuss design and implementation details, and present three NLP use cases - named entity recognition, reading comprehension, and clickbait detection that show the benefits of using the tool for model evaluation.  CrossCheck memungkinkan pengguna untuk membuat keputusan yang diberitahu ketika memilih antara banyak model, mengidentifikasi kapan model benar dan untuk contoh-contoh mana, menyelidiki apakah model membuat kesalahan yang sama dengan manusia, mengevaluasi generalisasi model dan mempertimbangkan batasan model, kekuatan dan kelemahan. Selain itu, CrossCheck dieksploitasi sebagai widget Jupyter, yang memungkinkan integrasi cepat dan nyaman ke aliran kerja perkembangan model yang ada.</abstract_id>
      <abstract_ko>성능 지표 이외의 평가, 예를 들어 F1 점수는 기계 학습 모델에 대한 적당한 신뢰 수준을 구축하고 미래 모델의 개선 경로를 확정하는 데 매우 중요하다.본고에서 우리는 교차 검사를 보여 주었는데 이것은 신속한 교차 모델 비교와 오차 분석을 재현할 수 있는 상호작용 기능이다.우리는 이 도구를 묘사하고 디자인과 실현의 세부 사항을 토론했으며 세 가지 NLP 용례인 명명 실체 식별, 읽기 이해와 미끼 검측을 보여줌으로써 모델 평가를 하는 장점을 보여 주었다.교차 검사는 사용자가 여러 모델 사이에서 선택할 때 현명한 결정을 내리고 모델이 언제 정확한지, 그리고 어떤 예시를 대상으로 모델이 인류와 같은 오류를 범했는지 조사하고 모델의 보급성을 평가하며 모델의 한계성, 장단점을 강조한다.또한 CrossCheck은 Jupyter 소부품으로 구현되어 기존의 모델 개발 작업 흐름에 신속하고 편리하게 집적할 수 있습니다.</abstract_ko>
      <abstract_fa>ارزیابی فراتر از متریک عملکرد جمع، مثال نمونه F1، برای ایجاد سطح مناسب اعتماد به مدل یادگیری ماشین و شناسایی راه‌ها برای بهترین مدل آینده مهم است. در این کاغذ نشان می‌دهیم که کروس چک، یک توانایی متصل برای مقایسه سریع مدل متصل و تحلیل خطای بازآفریننده است. ما ابزار را توصیف می کنیم، در مورد طراحی و جزئیات عملکرد صحبت می کنیم، و سه پرونده استفاده از NLP را پیشنهاد می کنیم، به نام شناسایی entity، خواندن درک و شناسایی طعمه کلیک که سودهای استفاده از ابزار برای ارزیابی مدل نشان می دهد. کروس چک به کاربران اجازه می‌دهد که وقتی میان مدل‌های متعدد انتخاب کنند تصمیم‌های اطلاعات را انجام دهند، وقتی مدل‌ها درست باشند و برای کدام مثال، تحقیق کنند که آیا مدل‌ها اشتباه‌های مشابه با انسان می‌کنند، ارزیابی قابلیت عمومی مدل‌ها و محدودیت مدل‌ها، قوت‌ها و ضعی علاوه بر این، کروس چک به عنوان یک وضعیت جوپیتر اجازه می‌دهد که برای تنظیم سریع و مناسب در جریان کارهای توسعه مدل موجود باشد.</abstract_fa>
      <abstract_de>Eine Bewertung jenseits aggregierter Leistungskennzahlen, z.B. F1-Score, ist entscheidend, um ein angemessenes Maß an Vertrauen in Machine Learning-Modelle zu schaffen und Wege für zukünftige Modellverbesserungen zu identifizieren. In diesem Beitrag zeigen wir CrossCheck, eine interaktive Fähigkeit für schnellen modellübergreifenden Vergleich und reproduzierbare Fehleranalyse. Wir beschreiben das Tool, diskutieren Design- und Implementierungsdetails und stellen drei NLP-Anwendungsfälle für die Erkennung benannter Entitäten, das Leseverständnis und die Clickbait-Erkennung vor, die die Vorteile der Verwendung des Tools für die Modellbewertung aufzeigen. CrossCheck ermöglicht es Anwendern, fundierte Entscheidungen bei der Auswahl zwischen mehreren Modellen zu treffen, zu erkennen, wann und für welche Beispiele die Modelle korrekt sind, zu untersuchen, ob die Modelle dieselben Fehler wie Menschen machen, die Verallgemeinerbarkeit der Modelle zu bewerten und die Grenzen, Stärken und Schwächen der Modelle aufzuzeigen. Darüber hinaus ist CrossCheck als Jupyter Widget implementiert, das eine schnelle und bequeme Integration in bestehende Modellentwicklungs-Workflows ermöglicht.</abstract_de>
      <abstract_sw>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements.  Katika gazeti hili tunaonyesha Cross Check, uwezo wa kati wa kulinganisha kwa haraka na uchambuzi wa makosa yanayotokea. Tunaelezea zana hiyo, kujadili ubunifu na utekelezaji wa kina, na kuweka madai tatu ya matumizi ya NLP - inayoitwa kutambua entity, kusoma kompyuta, na kugundua maudhui yanayoonyesha manufaa ya kutumia zana kwa ajili ya uchunguzi wa mifano. CrossCheck inawawezesha watumiaji kufanya maamuzi yanayoelezwa wakati wakichagua kati ya mifano mbalimbali, kutambua vipi mifano ni sahihi na kwa mfano huo, uchunguza kama mifano inafanya makosa sawa kama binadamu, kutathmini uhalisia wa mifano na kuonyesha vizuizi vya mifano, nguvu na udhaifu. Zaidi ya hayo, CrossCheck inatekelezwa kama kifaa cha Jupyter, ambacho kinaruhusu kuunganisha haraka na rahisi katika maendeleo ya modeli.</abstract_sw>
      <abstract_af>Evalueer buite agtergrote prestasie metries, bv. F1-telling, is daardie betaling om beide 'n geskikte vlak van vertrou in masjien leer model e te stel en avenue te identifiseer vir toekomstige model verbeteringe. In hierdie papier vertoon ons CrossCheck, 'n interaktiewe kapasiteit vir vinnige kruismodel vergelyking en reproduseerbare fout analiseer. Ons beskrywe die hulpmiddel, bespreek ontwerp en implementering details, en voorsien drie NLP gebruik gevalle - genaamde entiteiterkenning, lees verstanding, en kliek bait-beskrywing wat vertoon die voordele van gebruik van die hulpmiddel vir model evaluering. Kruiskontrole laat gebruikers toe om inligte besluite te maak wanneer hulle kies tussen veelvuldige modele, identifiseer wanneer die modele korrek is en waarvoor voorbeelde, ondersoek of die modele dieselfde foute maak as mense, evalueer die modele se generelliserbaardigheid en verlig modele se beperkings, kragtes en swakhedes. Verder is CrossCheck geïmplementeer as 'n Jupyter-widget, wat toelaat vir vinnige en goeie integrasie in bestaande model ontwikkelingswerksvloei.</abstract_af>
      <abstract_tr>Toparjyk etkinlik metriklerinden öňki çykyş, mysal F1 अ-score, maşynyň öwrenmek nusgalarynda ýeterli ynamyny düzedilemek üçin we gelejek nusgalaryň gelişmeleri üçin ýüzeleşmek üçin örän möhüm. Bu kagyzda biz CrossCheck'i, tiz mod karşılaştyrylmagy we täze bir hata analizi üçin etkileşimli bir ukyp görkezip otyrýarys. Biz bu aralygy tashylaýarys, dizayn we implementleme detaylaryny we üç NLP ulanylary bar we bu barada adlanan bir zady tanyýarys,düşünüp okamak we nusga çykmak üçin nusgasyny görkezýäris. CrossCheck Ullançylaryň aňry modeller arasynda soraglany çözgütlerni mümkin etmegi mümkin edýär, nusgalaryň nähili dogry bolup we nähili myslleriň üçin, modelleriň adamlaryň ýalňyşyny edendigini barlaň, nusgalaryň umumy döredijiligini we ýagtylygynyň mugatlaryny çykarýan, güýçleri we zayıklaryn Ümäpli, CrossCheck bir Jupyter widget häzirki we ýeterlik integrasy bolan nusga öwrülişim aklaryna mümkin edýär.</abstract_tr>
      <abstract_sq>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements.  Në këtë letër ne demonstrojmë CrossCheck, një aftësi interaktive për krahasimin e shpejtë të modelit të kryqëzuar dhe analizën e gabimeve të riprodhueshme. Ne e përshkruajmë mjetin, diskutojmë detajet e dizajnit dhe zbatimit dhe paraqesim tre raste përdorimi të NLP-së - njohje e emëruar e njësisë, leximi i kuptimit dhe zbulimi i klikut që tregojnë përfitimet e përdorimit të mjetit për vlerësimin e modelit. CrossCheck lejon përdoruesit të marrin vendime të informuar kur zgjedhin midis modeleve të shumta, të identifikojnë kur modelet janë të sakta dhe për cilat shembuj, të hetojnë nëse modelet po bëjnë të njëjtat gabime me njerëzit, të vlerësojnë gjeneralizimin e modeleve dhe të theksojnë kufizimet, forcat dhe dobësitë e modeleve. Përveç kësaj, CrossCheck zbatohet si një widget Jupyter, i cili lejon integrimin e shpejtë dhe të përshtatshëm në rrjedhjet e punës ekzistuese të zhvillimit të modelit.</abstract_sq>
      <abstract_am>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements.  በዚህ ፕሮግራም የቆስ መስኮትን እናሳየዋለን፡፡ መሣሪያውን እናሳውቃለን፣ design እና ማስተካከል እና ሦስት የNLP ተጠቃሚ ጉዳዮች - አካባቢ ማስታወቂያ፣ ማነብ እና መዝገበኛ እና የመጠቀም ጥቅሞችን ለmodel ማስታወቂያ የሚጠቀም ጥቅሞችን እናሳየዋለን፡፡ CrossCheck የሚጠይቁትን በሁለት ዓይነቶች መካከል በመምረጡ ጊዜ ማስታወቂያውን እንዲያደርጉ ይችላል፤ ምሳሌዎቹም እውነተኞች መሆኑን እና ለምሳሌዎች እንደ ሰው በአንድ ስህተት እንዲያደርጉ፣ የሞዴል አቀማመጥ እና የሞዴል ግንኙነቶች፣ ኃይልና ድካሞች እንዲያስታውሱ ይችላል፡፡ Furthermore, CrossCheck is implemented as a Jupyter widget, which allows rapid and suitable integration to existing model development flows.</abstract_am>
      <abstract_hy>Արժեքը համընդհանուր արդյունավետության չափումներից դուրս, օրինակ F1-գնահատականը, կարևոր է մեքենային ուսումնասիրության մոդելների հետ վստահության համապատասխան մակարդակի հաստատելու համար և ապագա մոդելի բարելավման ուղիների հայ Այս թղթի մեջ մենք ցույց ենք տալիս "ԿրոսՍթեքը", ինտերակտիվ հնարավորություն արագ համեմատության և վերարտադրվող սխալների վերլուծության համար: We describe the tool, discuss design and implementation details, and present three NLP use cases - named entity recognition, reading comprehension, and clickbait detection that show the benefits of using the tool for model evaluation.  Օգտագործողներին հնարավորություն է տալիս բազմաթիվ մոդելների միջև ընտրելու ժամանակ տեղեկացված որոշումներ կայացնել, պարզել, թե երբ են մոդելները ճիշտ և ինչպիսի օրինակներ, ուսումնասիրել, արդյոք մոդելները մարդկանց հետ նույն սխալներ են անում, գնահատել մոդելների ընդհանուր ընդհանուրությունը և ն Ավելին, ԿրոսՍթեքը կիրառվում է որպես JuPiter տարիք, որը հնարավորություն է տալիս արագ և հարմարավետ ինտեգրացիան գոյություն ունեցող մոդելների զարգացման աշխատահոսքերի մեջ:</abstract_hy>
      <abstract_az>Müxtəlif performans metriklərindən ötrü müəyyən edilmə, məsələn F1-score, maşın öyrənməsi modellərinə uyğun bir təvəkkül seviyyəsini və g ələcək modellərin düzəltməsi üçün yolları tanımmaq üçün çox vacibdir. Bu kağızda CrossCheck'i göstərdik, tez çox modellü karşılaşdırma və yenidən fərqli xəta analizi üçün interaktif bir qabiliyyət. Biz bu vasitəsi təsdiqləyirik, dizayn və implementasyon detaylarını müzakirə edirik, və üç NLP istifadə etdiyimiz məsələləri təsdiqləyirik - adı olan entitə tanıması, anlama oxuması və modellərin değerlənməsi üçün istifadə etmək faydalarını göstərir. CrossCheck istifadəçilərin çoxlu modellər arasında müjdəli kararlar verməsini, modellərin doğruluğunu və hansı məsəllər üçün təsdiqlənməsini, modellərin insanlar ilə eyni hataları etdiklərini təsdiqləməsini, modellərin generalizasizlik və modellərin sınırlarını, qüvvətləri və zəiflikləri təsdiqlənməsini mümkün edir. Daha sonra, CrossCheck mövcuddur modellərin gelişmiş işlər akışlarına hızlı və uyğun bir integrasiya yaratmaq üçün bir Jupyter widget kimi işlədilir.</abstract_az>
      <abstract_bn>মেশিন শিক্ষা মডেল শিক্ষা এবং ভবিষ্যত মডেল উন্নতির জন্য প্রতিশ্রুতি নির্ধারণ করার জন্য প্রয়োজনীয়। In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis.  আমরা টুলটি বর্ণনা করি, ডিজাইন এবং বিস্তারিত বিস্তারিত বিবরণ নিয়ে আলোচনা করি, এবং তিনটি এনএলপি ব্যবহারকারী কেস উপস্থাপন করি- নামের বস্তুর স্বীকার, সম্পূর্ণ ক্রোস চেক ব্যবহারকারীদের জানানো সিদ্ধান্ত নিতে সক্ষম করে যখন বেশ কয়েকটি মডেলের মধ্যে বেছে নেয়, মডেলটি সঠিক হলে চিহ্নিত করুন এবং কোন উদাহরণ হিসেবে মডেল মানুষের মত একই ভুল করছে কিনা, ম এছাড়াও, ক্রোস চেক একটি জাপাইটার উইজেট হিসেবে ব্যবহার করা হয়েছে, যা দ্রুত এবং সুবিধাজনক মডেল উন্নয়নের কার্যক্রমে যোগাযোগ করতে পার</abstract_bn>
      <abstract_ca>L'evaluació més enllà de les mètriques de rendiment agregades, per exemple la puntuació F1, és crucial tant per establir un nivell apropiat de confiança en els models d'aprenentatge màquinari com per identificar camins per millorar futurs models. En aquest paper demostram CrossCheck, una capacitat interactiva per a una ràpida comparació de models cruzados i l'an àlisi d'errors reproducibles. Descrivem l'eina, discutem els detalls de disseny i implementació, i presentem tres casos d'ús de NLP - el reconeixement d'entitats, la comprensió lectora i la detecció de barres de clic que mostran els beneficis d'utilitzar l'eina per a l'evaluació del model. CrossCheck permet als usuaris prendre decisions informades quan escollen entre múltiples models, identificar quan els models són correctes i per quins exemples, investigar si els models cometen els mateixos errors que els humans, evaluar la generalització dels models i destacar les limitacions, fortituds i debilitats dels models. Furthermore, CrossCheck is implemented as a Jupyter widget, which allows for rapid and convenient integration into existing model development workflows.</abstract_ca>
      <abstract_et>Hindamine peale koondtulemuslikkuse mõõdikute (nt F1-skoori) on väga oluline nii masinõppe mudelite asjakohase usalduse loomiseks kui ka mudelite edasiseks täiustamiseks. Käesolevas töös demonstreerime CrossCheck, interaktiivset võimet kiireks mudelitevaheliseks võrdlemiseks ja reprodutseeritavaks veaanalüüsiks. Kirjeldame tööriista, arutame projekteerimis- ja rakendusüksikasju ning esitame kolme NLP-i kasutusjuhtumit - nimega olemi tuvastamine, lugemise mõistmine ja klõpsateave, mis näitavad tööriista kasutamise eeliseid mudeli hindamisel. CrossCheck võimaldab kasutajatel teha teadlikke otsuseid mitme mudeli vahel valides, tuvastada, millal mudelid on õiged ja milliste näidete puhul, uurida, kas mudelid teevad samu vigu nagu inimesed, hinnata mudelite üldistatavust ning tuua esile mudelite piirangud, tugevused ja nõrkused. Lisaks rakendatakse CrossCheck Jupyteri vidina, mis võimaldab kiiret ja mugavat integreerimist olemasolevatesse mudelite arendamise töövoogudesse.</abstract_et>
      <abstract_bs>Procjenjivanje izvan aggregatne metrike učinka, na primjer F1-rezultat, ključno je za uspostavljanje odgovarajuće g nivoa povjerenja u model e učenja mašina i identifikaciju avenata za buduće poboljšanje modela. U ovom papiru pokazujemo CrossCheck interaktivnu sposobnost za brzu usporedbu preko modela i reproduktivnu analizu greške. Opišemo alat, raspravljamo o detaljima dizajna i provedbe, i predstavljamo tri slučaja upotrebe NLP-a - priznanja entiteta, čitanje razumijevanja i otkrivanje mamaca koji pokazuju koristi korištenja alata za procjenu modela. CrossCheck omogućava korisnicima donositi informativne odluke kada biraju između višestrukih modela, identificirati kada su modeli ispravni i za koje primjere, istražiti da li modeli čine iste greške kao i ljudi, procijeniti generalizaciju modela i osvjetljavati ograničenja modela, snage i slabosti. Osim toga, CrossCheck se provede kao Jupyter widget, koji omogućava brzu i prikladnu integraciju u postojeće protoke rada u modelu razvoja.</abstract_bs>
      <abstract_fi>Kokonaissuoritusmittareiden (esim. F1-pisteen) lisäksi arviointi on ratkaisevan tärkeää sekä riittävän luottamuksen luomiseksi koneoppimismalleihin että tulevien malliparannusten löytämiseksi. Tässä työssä esitellään CrossCheck, interaktiivinen kyky nopeaan mallivertailuun ja toistettavissa olevaan virheanalyysiin. Kuvaamme työkalua, keskustelemme suunnittelu- ja toteutusyksityiskohdista ja esittelemme kolme NLP:n käyttötapausta – nimetty entiteetintunnistus, lukemisen ymmärtäminen ja napsautussaitin tunnistus, jotka osoittavat työkalun käytön hyödyt mallin arvioinnissa. CrossCheck antaa käyttäjille mahdollisuuden tehdä tietoon perustuvia päätöksiä valitessaan useita malleja, tunnistaa, milloin mallit ovat oikeita ja mitkä esimerkit, tutkia, ovatko mallit tehneet samoja virheitä kuin ihmiset, arvioida mallien yleistettävyyttä ja korostaa mallien rajoituksia, vahvuuksia ja heikkouksia. Lisäksi CrossCheck toteutetaan Jupyter-widgetinä, joka mahdollistaa nopean ja kätevän integroinnin olemassa oleviin mallikehitystyönkulkuihin.</abstract_fi>
      <abstract_cs>Hodnocení nad rámec agregátních metrik výkonu, např. skóre F1, je klíčové jak pro vytvoření odpovídající úrovně důvěry v modely strojového učení, tak pro identifikaci cest k budoucímu zlepšení modelů. V tomto článku demonstrujeme CrossCheck, interaktivní schopnost rychlého srovnávání mezi modely a reprodukovatelnou analýzu chyb. Popisujeme nástroj, diskutujeme detaily návrhu a implementace a prezentujeme tři případy použití NLP pro rozpoznávání pojmenovaných entit, porozumění čtení a detekci kliknutí, které ukazují výhody použití nástroje pro hodnocení modelu. CrossCheck umožňuje uživatelům činit informovaná rozhodnutí při výběru mezi více modely, identifikovat, kdy jsou modely správné a pro které příklady, zkoumat, zda modely dělají stejné chyby jako lidé, zhodnotit zobecnitelnost modelů a upozornit na omezení, silné a slabé stránky modelů. Kromě toho je CrossCheck implementován jako Jupyter widget, který umožňuje rychlou a pohodlnou integraci do stávajících pracovních postupů vývoje modelů.</abstract_cs>
      <abstract_jv>Wanda Nang pepulan iki kita nambah KrosCheck, kapasitasi interactive kanggo kelas-model kang dianggap karo perusahaan karo perusahaan eror We describe the tool, Debug design and progress details, and present 3 NLP use Case - name Enty knowtion, reading comprehension, and clickbytes detection that show the benets of use the tool for model assertion. politenessoffpolite"), and when there is a change ("assertivepolite"), and when there is a change ("assertivepoliteness Ytambah, krus Check wehku ngewehku nganggo Jupi widget, sing supoyo perusahaan kanggo bantuan lan akeh lanjut sampek kanggo awak dhéwé modèl kanggo dianglangno nggawe operasi sistem sing dumadhi.</abstract_jv>
      <abstract_sk>Ocenjevanje, ki presega skupne meritve zmogljivosti, npr. rezultat F1, je ključnega pomena tako za vzpostavitev ustrezne ravni zaupanja v modele strojnega učenja kot za določitev možnosti za prihodnje izboljšave modela. V prispevku predstavljamo CrossCheck, interaktivno zmogljivost za hitro primerjavo med modeli in ponovljivo analizo napak. Opisujemo orodje, razpravljamo o podrobnostih oblikovanja in implementacije ter predstavljamo tri primere uporabe NLP – imenovano prepoznavanje entitet, razumevanje branja in zaznavanje klikovne naprave, ki kažejo prednosti uporabe orodja za ocenjevanje modela. CrossCheck uporabnikom omogoča sprejemanje informiranih odločitev pri izbiri med več modeli, ugotavljanje, kdaj so modeli pravilni in za katere primere, raziskovanje, ali modeli delajo enake napake kot ljudje, ocenjevanje splošnosti modelov ter poudarjanje omejitev, prednosti in slabosti modelov. Poleg tega je CrossCheck uveden kot Jupyter widget, ki omogoča hitro in priročno integracijo v obstoječe poteke dela za razvoj modelov.</abstract_sk>
      <abstract_he>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements.  בעיתון הזה אנחנו מראים CrossCheck, יכולת אינטראקטיבית לשוואה מהירה צלב מודל וניתוח שגיאות ניתן לשחזור. אנו מתארים את הכל, מדברים על פרטי עיצוב ומבצע, ומציגים שלושה מקרים שימוש בשימוש של NLP - זיהוי ישויות בשם, הבנה קריאה, וגילוי בית קליקים שמראים את היתרונות של השימוש בכלי הערכה דוגמנית. CrossCheck מאפשר למשתמשים לקבל החלטות מודיעות כשבוחרים בין דוגמנים רבים, לזהות מתי הדוגמנים נכונים ולאילו דוגמאות, לחקור אם הדוגמנים עושים את אותן טעויות כמו בני אדם, להעריך את הגנרליזציה של דוגמנים ולדגיש את הגבלות, החזקות וחלשות של דוגמנים. בנוסף, CrossCheck מתפקד כגורל Jupyter, אשר מאפשר לאינטגרציה מהירה ונוחה לזרמי עבודה פיתוח מודל קיימים.</abstract_he>
      <abstract_ha>Ana muhimu a canza tsarin metrics da za'a kiyaye, misali F1-score, don ka daidaita wata daraja mai inganci a cikin misalin ayuka da za'a sani, kuma ka g an e masu tsari wa misãlai masu ƙara. Ga wannan takardan nan, Munã nuna korssCheck, wani abinci mai interactive wa masu sami-misalin tsohon-sami da kuma analyza ɓata da za'a iya duba. Tuna bayyana shirin ayuka, za'a shawara kayan yi shirin ayuka, kuma mu yanzu masu amfani da shiryoyin ayuka uku na NLP - sunan sunan ganin shaidar abun - sunan karandin abun da aka karanta, kuma za'a danna fanin bait wanda ya nuna amfani da amfani da ya yi amfani da zanen canza wa canza-ƙaddara. KCharselect unicode block name Furan haka, an cika KorssCheck kamar wata widget na Jupyter, wanda yana yarda da haɗi da haraka kuma masu sauya zuwa masu motsi da ke samar da shi.</abstract_ha>
      <abstract_bo>Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in machine learning models and identify avenues for future model improvements. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་CrossCheck་ལྟ་བུའི་ནང་དུ་མགྱོག་མྱུར་ཚད་མཐུན་སྒྲིག་དང་བསྐྱར་གསོ་ནུས་པའི་ནོར་འཁྲུལ་ཞིབ་བ We describe the tool, discuss design and implementation details, and present three NLP use cases - named entity recognition, reading comprehension, and clickbait detection that show the benefits of using the tool for model evaluation. CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models' generalizability and highlight models' limitations, strengths and weaknesses. དེ་ལས་ཀྱང་། CrossCheck འདི་ལྟ་བུའི་རྩོམ་པ་ཞིག་གིས་ལག་སྟར་བྱེད་ཡོད་པ། དེ་ནི་མགྱོགས་འཕྱུར་མྱུང་བའི་དཔེ་དབྱིབས་གསར་སྤྲོད་ཀྱི་འགྱུར</abstract_bo>
      </paper>
    <paper id="14">
      <title>TopGuNN : Fast NLP Training Data Augmentation using Large Corpora<fixed-case>T</fixed-case>op<fixed-case>G</fixed-case>u<fixed-case>NN</fixed-case>: Fast <fixed-case>NLP</fixed-case> Training Data Augmentation using Large Corpora</title>
      <author><first>Rebecca</first><last>Iglesias-Flores</last></author>
      <author><first>Megha</first><last>Mishra</last></author>
      <author><first>Ajay</first><last>Patel</last></author>
      <author><first>Akanksha</first><last>Malhotra</last></author>
      <author><first>Reno</first><last>Kriz</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>86–101</pages>
      <abstract>Acquiring training data for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing systems</a> can be expensive and time-consuming. Given a few training examples crafted by experts, large corpora can be mined for thousands of semantically similar examples that provide useful variability to improve model generalization. We present TopGuNN, a fast contextualized k-NN retrieval system that can efficiently index and search over contextual embeddings generated from large corpora. TopGuNN is demonstrated for a training data augmentation use case over the Gigaword corpus. Using approximate k-NN and an efficient <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a>, TopGuNN performs queries over an <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms">embedding space</a> of 4.63 TB (approximately 1.5B embeddings) in less than a day.</abstract>
      <url hash="5da64775">2021.dash-1.14</url>
      <doi>10.18653/v1/2021.dash-1.14</doi>
      <bibkey>iglesias-flores-etal-2021-topgunn</bibkey>
      <pwccode url="https://github.com/penn-topgunn/topgunn" additional="false">penn-topgunn/topgunn</pwccode>
    </paper>
    <paper id="16">
      <title>A <a href="https://en.wikipedia.org/wiki/Computational_model">Computational Model</a> for Interactive Transcription</title>
      <author><first>William</first><last>Lane</last></author>
      <author><first>Mat</first><last>Bettinson</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <pages>105–111</pages>
      <abstract>Transcribing low resource languages can be challenging in the absence of a good lexicon and trained transcribers. Accordingly, we seek a way to enable interactive transcription whereby the machine amplifies human efforts. This paper presents a <a href="https://en.wikipedia.org/wiki/Data_model">data model</a> and a <a href="https://en.wikipedia.org/wiki/Systems_architecture">system architecture</a> for interactive transcription, supporting multiple modes of <a href="https://en.wikipedia.org/wiki/Interactivity">interactivity</a>, increasing the likelihood of finding tasks that engage local participation in language work. The approach also supports other <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> which are useful in our context, including spoken document retrieval and <a href="https://en.wikipedia.org/wiki/Language_acquisition">language learning</a>.</abstract>
      <url hash="f740e892">2021.dash-1.16</url>
      <doi>10.18653/v1/2021.dash-1.16</doi>
      <bibkey>lane-etal-2021-computational</bibkey>
    </paper>
  </volume>
</collection>