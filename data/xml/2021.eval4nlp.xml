<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.eval4nlp">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems</booktitle>
      <editor><first>Yang</first><last>Gao</last></editor>
      <editor><first>Steffen</first><last>Eger</last></editor>
      <editor><first>Wei</first><last>Zhao</last></editor>
      <editor><first>Piyawat</first><last>Lertvittayakumjorn</last></editor>
      <editor><first>Marina</first><last>Fomicheva</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="22b5a124">2021.eval4nlp-1.0</url>
      <bibkey>eval4nlp-2021-evaluation</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Differential Evaluation : a Qualitative Analysis of Natural Language Processing System Behavior Based Upon Data Resistance to Processing</title>
      <author><first>Lucie</first><last>Gianola</last></author>
      <author><first>Hicham</first><last>El Boukkouri</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <author><first>Patrick</first><last>Paroubek</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>1–10</pages>
      <abstract>Most of the time, when dealing with a particular Natural Language Processing task, systems are compared on the basis of global statistics such as <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>, F1-score, etc. While such scores provide a general idea of the behavior of these <a href="https://en.wikipedia.org/wiki/System">systems</a>, they ignore a key piece of information that can be useful for assessing progress and discerning remaining challenges : the relative difficulty of test instances. To address this shortcoming, we introduce the notion of differential evaluation which effectively defines a pragmatic partition of instances into gradually more difficult bins by leveraging the predictions made by a set of systems. Comparing systems along these difficulty bins enables us to produce a finer-grained analysis of their relative merits, which we illustrate on two use-cases : a comparison of systems participating in a multi-label text classification task (CLEF eHealth 2018 ICD-10 coding), and a comparison of neural models trained for biomedical entity detection (BioCreative V chemical-disease relations dataset).</abstract>
      <url hash="8ac4f987">2021.eval4nlp-1.1</url>
      <bibkey>gianola-etal-2021-differential</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.1</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="2">
      <title>Validating Label Consistency in NER Data Annotation<fixed-case>NER</fixed-case> Data Annotation</title>
      <author><first>Qingkai</first><last>Zeng</last></author>
      <author><first>Mengxia</first><last>Yu</last></author>
      <author><first>Wenhao</first><last>Yu</last></author>
      <author><first>Tianwen</first><last>Jiang</last></author>
      <author><first>Meng</first><last>Jiang</last></author>
      <pages>11–15</pages>
      <abstract>Data annotation plays a crucial role in ensuring your named entity recognition (NER) projects are trained with the right information to learn from. Producing the most accurate labels is a challenge due to the complexity involved with <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>. Label inconsistency between multiple subsets of data annotation (e.g., training set and test set, or multiple training subsets) is an indicator of label mistakes. In this work, we present an <a href="https://en.wikipedia.org/wiki/Empirical_research">empirical method</a> to explore the relationship between label (in-)consistency and <a href="https://en.wikipedia.org/wiki/NER_model">NER model</a> performance. It can be used to validate the label consistency (or catches the inconsistency) in multiple sets of NER data annotation. In experiments, our method identified the label inconsistency of test data in SCIERC and CoNLL03 datasets (with 26.7 % and 5.4 % label mistakes). It validated the consistency in the corrected version of both <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>.</abstract>
      <url hash="96ac663c">2021.eval4nlp-1.2</url>
      <bibkey>zeng-etal-2021-validating</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.2</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/conll">CoNLL++</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/scierc">SciERC</pwcdataset>
    </paper>
    <paper id="4">
      <title>StoryDB : Broad Multi-language Narrative Dataset<fixed-case>S</fixed-case>tory<fixed-case>DB</fixed-case>: Broad Multi-language Narrative Dataset</title>
      <author><first>Alexey</first><last>Tikhonov</last></author>
      <author><first>Igor</first><last>Samenko</last></author>
      <author><first>Ivan</first><last>Yamshchikov</last></author>
      <pages>32–39</pages>
      <abstract>This paper presents StoryDB   a broad multi-language dataset of <a href="https://en.wikipedia.org/wiki/Narrative">narratives</a>. StoryDB is a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of texts</a> that includes stories in 42 different languages. Every language includes 500 + stories. Some of the languages include more than 20 000 stories. Every story is indexed across languages and labeled with tags such as a genre or a topic. The <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> shows rich topical and language variation and can serve as a resource for the study of the role of <a href="https://en.wikipedia.org/wiki/Narrative">narrative</a> in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> across various languages including low resource ones. We also demonstrate how the dataset could be used to benchmark three modern multilanguage models, namely, mDistillBERT, mBERT, and XLM-RoBERTa.</abstract>
      <url hash="bec0c91e">2021.eval4nlp-1.4</url>
      <bibkey>tikhonov-etal-2021-storydb</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.4</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/storydb">StoryDB</pwcdataset>
    </paper>
    <paper id="5">
      <title>SeqScore : Addressing Barriers to Reproducible Named Entity Recognition Evaluation<fixed-case>S</fixed-case>eq<fixed-case>S</fixed-case>core: Addressing Barriers to Reproducible Named Entity Recognition Evaluation</title>
      <author><first>Chester</first><last>Palen-Michel</last></author>
      <author><first>Nolan</first><last>Holley</last></author>
      <author><first>Constantine</first><last>Lignos</last></author>
      <pages>40–50</pages>
      <abstract>To address a looming crisis of unreproducible evaluation for <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, we propose guidelines and introduce SeqScore, a software package to improve <a href="https://en.wikipedia.org/wiki/Reproducibility">reproducibility</a>. The guidelines we propose are extremely simple and center around transparency regarding how chunks are encoded and scored. We demonstrate that despite the apparent simplicity of NER evaluation, unreported differences in the scoring procedure can result in changes to scores that are both of noticeable magnitude and statistically significant. We describe SeqScore, which addresses many of the issues that cause <a href="https://en.wikipedia.org/wiki/Replication_(computing)">replication failures</a>.</abstract>
      <url hash="fb7d9669">2021.eval4nlp-1.5</url>
      <bibkey>palen-michel-etal-2021-seqscore</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.5</doi>
      <pwccode url="https://github.com/bltlab/seqscore" additional="false">bltlab/seqscore</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/masakhaner">MasakhaNER</pwcdataset>
    </paper>
    <paper id="6">
      <title>Trainable Ranking Models to Evaluate the Semantic Accuracy of Data-to-Text Neural Generator</title>
      <author><first>Nicolas</first><last>Garneau</last></author>
      <author><first>Luc</first><last>Lamontagne</last></author>
      <pages>51–61</pages>
      <abstract>In this paper, we introduce a new embedding-based metric relying on trainable ranking models to evaluate the semantic accuracy of neural data-to-text generators. This <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> is especially well suited to semantically and factually assess the performance of a <a href="https://en.wikipedia.org/wiki/Text_generator">text generator</a> when tables can be associated with multiple references and table values contain textual utterances. We first present how one can implement and further specialize the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> by training the underlying ranking models on a legal Data-to-Text dataset. We show how it may provide a more robust evaluation than other evaluation schemes in challenging settings using a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> comprising <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> between the table values and their respective references. Finally, we evaluate its generalization capabilities on a well-known dataset, WebNLG, by comparing it with human evaluation and a recently introduced <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> based on natural language inference. We then illustrate how it naturally characterizes, both quantitatively and qualitatively, omissions and <a href="https://en.wikipedia.org/wiki/Hallucination">hallucinations</a>.</abstract>
      <url hash="2a257ef6">2021.eval4nlp-1.6</url>
      <bibkey>garneau-lamontagne-2021-trainable</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.6</doi>
    </paper>
    <paper id="7">
      <title>Evaluation of Unsupervised Automatic Readability Assessors Using Rank Correlations</title>
      <author><first>Yo</first><last>Ehara</last></author>
      <pages>62–72</pages>
      <abstract>Automatic readability assessment (ARA) is the task of automatically assessing readability with little or no <a href="https://en.wikipedia.org/wiki/Supervisor">human supervision</a>. ARA is essential for many second language acquisition applications to reduce the workload of annotators, who are usually language teachers. Previous <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised approaches</a> manually searched textual features that correlated well with <a href="https://en.wikipedia.org/wiki/Readability">readability labels</a>, such as perplexity scores of large language models. This paper argues that, to evaluate an assessors’ performance, rank-correlation coefficients should be used instead of Pearson’s correlation coefficient (). In the experiments, we show that its performance can be easily underestimated using Pearson’s, which is significantly affected by the <a href="https://en.wikipedia.org/wiki/Linearity">linearity</a> of the output readability scores. We also propose a lightweight unsupervised readability assessor that achieved the best performance in both the rank correlations and Pearson’s   among all unsupervised assessors compared.<tex-math>\rho</tex-math>). In the experiments, we show that its performance can be easily underestimated using Pearson’s <tex-math>\rho</tex-math>, which is significantly affected by the linearity of the output readability scores. We also propose a lightweight unsupervised readability assessor that achieved the best performance in both the rank correlations and Pearson’s <tex-math>\rho</tex-math> among all unsupervised assessors compared.</abstract>
      <url hash="7df408a9">2021.eval4nlp-1.7</url>
      <bibkey>ehara-2021-evaluation</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.7</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
    </paper>
    <paper id="8">
      <title>Testing Cross-Database Semantic Parsers With Canonical Utterances</title>
      <author><first>Heather</first><last>Lent</last></author>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Tao</first><last>Yu</last></author>
      <author><first>Tong</first><last>Niu</last></author>
      <author><first>Yingbo</first><last>Zhou</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <author><first>Xi Victoria</first><last>Lin</last></author>
      <pages>73–83</pages>
      <abstract>The benchmark performance of cross-database semantic parsing has climbed steadily in recent years, catalyzed by the wide adoption of pre-trained language models. Yet existing work have shown that state-of-the-art cross-database semantic parsers struggle to generalize to novel user utterances, databases and query structures. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs. Inspired by the CheckList, we characterize a set of essential capabilities for cross-database semantic parsing models, and detailed the method for synthesizing the corresponding test data. We evaluated a variety of high performing <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> using the proposed approach, and identified several non-obvious weaknesses across <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> (e.g. unable to correctly select many columns). Our dataset and code are released as a test suite at http://github.com/hclent/BehaviorCheckingSemPar.</abstract>
      <url hash="2bf0331d">2021.eval4nlp-1.8</url>
      <bibkey>lent-etal-2021-testing</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.8</doi>
      <pwccode url="https://github.com/hclent/behaviorcheckingsempar" additional="false">hclent/behaviorcheckingsempar</pwccode>
    <title_ar>اختبار المحللين الدلاليين عبر قواعد البيانات باستخدام الألفاظ الكنسي</title_ar>
      <title_pt>Testando analisadores semânticos entre bancos de dados com enunciados canônicos</title_pt>
      <title_es>Prueba de analizadores semánticos entre bases de datos con enunciados canónicos</title_es>
      <title_ja>正規表現を使用したクロスデータベースセマンティックパーサーのテスト</title_ja>
      <title_zh>以规语试跨数据库语义解析器</title_zh>
      <title_hi>कैनोनिकल कथन के साथ क्रॉस-डेटाबेस सिमेंटिक पार्सर्स का परीक्षण</title_hi>
      <title_ga>Parsairí Séimeantacha Tras-Bunachar Sonraí a Thástáil le Slite Canónacha</title_ga>
      <title_hu>Adatbázisok közötti szemantikus parserek vizsgálata kanonikus kifejezésekkel</title_hu>
      <title_el>Δοκιμή σημασιολογικών αναλύσεων μεταξύ βάσεων δεδομένων με Κανονικές δηλώσεις</title_el>
      <title_ka>Name</title_ka>
      <title_it>Test di analisi semantiche cross-database con esiti canonici</title_it>
      <title_lt>Testuojant įvairių duomenų bazių Semantinius analizatorius su kanoninėmis reikmėmis</title_lt>
      <title_kk>Canonical UtteransName</title_kk>
      <title_mk>Тестирање на семантични анализатори на крстобазата на податоци со канонички употреби</title_mk>
      <title_ms>Menuji Penjana Semantik Salib-Pangkalan Data Dengan Peralatan Canonical</title_ms>
      <title_mt>L-Ittestjar ta’ Parsers Semantiċi b’Utteranzi Kanoniċi tal-Bażi ta’ Dati Cross</title_mt>
      <title_mn>Хөгжим өгөгдлийн сан Semantic Parsers With Canonical Utterances</title_mn>
      <title_ro>Testarea analizelor semantice cross-baze de date cu experiențe canonice</title_ro>
      <title_ml>ക്രോസ്- ഡാറ്റാബേസ് സെമാന്റിക് പാര്‍സറുകള്‍ കാനോണിക്കല്‍ ഉപയോഗിച്ചു് പരീക്ഷിക്കുന്നു</title_ml>
      <title_no>Name</title_no>
      <title_pl>Testowanie paraserów semantycznych między bazami danych z wypowiedziami kanonicznymi</title_pl>
      <title_sr>Testing Cross-Database Semantic Parsers with Canonical Utterances</title_sr>
      <title_sv>Testning av semantiska tolkare över databaser med kanoniska yttringar</title_sv>
      <title_ur>Name</title_ur>
      <title_ta>Name</title_ta>
      <title_si>Name</title_si>
      <title_so>Imtixaanka baaritaanka baaritaanka baaritaanka basaaska ee iskuulka</title_so>
      <title_uz>Name</title_uz>
      <title_vi>Kiểm tra chéo dữ liệu bố già bố già truyền thống</title_vi>
      <title_bg>Тестване на кръстосани бази данни за семантични анализи с канонични изказвания</title_bg>
      <title_nl>Databaseoverschrijdende semantische parsers testen met canonische uitspraken</title_nl>
      <title_hr>Testiranje semantičnih razmatrača preko baze podataka s kanoničkim upotrebom</title_hr>
      <title_da>Test af semantiske parsere på tværs af databaser med kanoniske udtalelser</title_da>
      <title_fa>آزمایش پزشک‌های متوسط داده‌های عبور با استفاده‌های کانونیک</title_fa>
      <title_de>Testen datenbankübergreifender semantischer Parser mit kanonischen Äußerungen</title_de>
      <title_ko>규범화된 언어로 크로스 데이터베이스 의미 분석기 테스트</title_ko>
      <title_id>Menguji Parser Semantic Cross-Database Dengan Utterances Canonical</title_id>
      <title_sw>Kujaribu mabango ya Kimataifa ya Kusini</title_sw>
      <title_tr>Canonik Ullançy</title_tr>
      <title_am>ምርጫዎች</title_am>
      <title_af>Name</title_af>
      <title_sq>Testimi i analizuesve Semantikë të bazës së të dhënave me përdorime kanonike</title_sq>
      <title_hy>Քանանիկ օգտագործումներով թեստավորելով խաչը բազայի տվյալներ</title_hy>
      <title_az>Canonical Utteransları ilə Cross-Database Semantic Parserləri Testing</title_az>
      <title_bn>ক্রোস-ডাটাবেস সেম্যান্টিক প্যারাসার পরীক্ষা করা হচ্ছে</title_bn>
      <title_ca>Probar els analitzadors Semàtics de bases de dades cruzades amb utilitats canòniques</title_ca>
      <title_cs>Testování sémantických parserů mezi databázemi s kanonickými vyjádřeními</title_cs>
      <title_bs>Testiranje semantičnih razmatrača preko baze podataka sa kanoničkim upotrebom</title_bs>
      <title_et>Andmebaasidevaheliste semantiliste parserite testimine kanooniliste väljenditega</title_et>
      <title_fi>Tietokantojen välisten semanttisten parsereiden testaus kanonisilla ilmaisuilla</title_fi>
      <title_sk>Preizkušanje medbaznih semantičnih razpravljalnikov s kanoničnimi izjavami</title_sk>
      <title_he>מבחן מערכות סמנטיות של בסיס נתונים צלב עם שימוש קנוני</title_he>
      <title_jv>Test</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>Testing Cross-Database Semantic Parsers With Canonical Utterances</title_bo>
      <abstract_ar>ارتفع الأداء المعياري للتحليل الدلالي عبر قواعد البيانات بشكل مطرد في السنوات الأخيرة ، محفزًا من خلال التبني الواسع لنماذج اللغة المدربة مسبقًا. ومع ذلك ، فقد أظهر العمل الحالي أن المحللين الدلاليين المتعددين لقواعد البيانات يكافحون من أجل التعميم على أقوال المستخدم الجديدة وقواعد البيانات وهياكل الاستعلام. للحصول على تفاصيل شفافة حول نقاط القوة والقيود الخاصة بهذه النماذج ، نقترح نهج اختبار تشخيصي يعتمد على توليف متحكم فيه للغة الطبيعية المتعارف عليها وأزواج SQL. مستوحاة من CheckList ، قمنا بتمييز مجموعة من الإمكانات الأساسية لنماذج التحليل الدلالي عبر قواعد البيانات ، وقمنا بتفصيل طريقة تجميع بيانات الاختبار المقابلة. قمنا بتقييم مجموعة متنوعة من النماذج عالية الأداء باستخدام النهج المقترح ، وحددنا العديد من نقاط الضعف غير الواضحة عبر النماذج (على سبيل المثال ، عدم القدرة على تحديد العديد من الأعمدة بشكل صحيح). تم إصدار مجموعة البيانات والرمز الخاص بنا كمجموعة اختبار على http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ar>
      <abstract_es>El rendimiento de referencia del análisis semántico entre bases de datos ha aumentado de manera constante en los últimos años, catalizado por la amplia adopción de modelos de lenguaje previamente entrenados. Sin embargo, el trabajo existente ha demostrado que los analizadores semánticos entre bases de datos de última generación luchan por generalizar a expresiones de usuario novedosas, bases de datos y estructuras de consulta. Para obtener detalles transparentes sobre las fortalezas y limitaciones de estos modelos, proponemos un enfoque de pruebas de diagnóstico basado en la síntesis controlada de pares de lenguaje natural canónico y SQL. Inspirados en CheckList, caracterizamos un conjunto de capacidades esenciales para los modelos de análisis semántico entre bases de datos y detallamos el método para sintetizar los datos de prueba correspondientes. Evaluamos una variedad de modelos de alto rendimiento utilizando el enfoque propuesto e identificamos varias debilidades no obvias en todos los modelos (por ejemplo, la incapacidad de seleccionar correctamente muchas columnas). Nuestro conjunto de datos y código se publican como un conjunto de pruebas en http://github.com/hclent/BehaviorCheckingSemPar.</abstract_es>
      <abstract_pt>O desempenho de referência da análise semântica entre bancos de dados aumentou constantemente nos últimos anos, catalisada pela ampla adoção de modelos de linguagem pré-treinados. No entanto, o trabalho existente mostrou que os analisadores semânticos entre bancos de dados de última geração lutam para generalizar para novos enunciados de usuários, bancos de dados e estruturas de consulta. Para obter detalhes transparentes sobre os pontos fortes e limitações desses modelos, propomos uma abordagem de teste de diagnóstico baseada na síntese controlada de linguagem natural canônica e pares SQL. Inspirados no CheckList, caracterizamos um conjunto de recursos essenciais para modelos de análise semântica entre bancos de dados e detalhamos o método para sintetizar os dados de teste correspondentes. Avaliamos uma variedade de modelos de alto desempenho usando a abordagem proposta e identificamos vários pontos fracos não óbvios entre os modelos (por exemplo, incapaz de selecionar corretamente muitas colunas). Nosso conjunto de dados e código são lançados como um conjunto de testes em http://github.com/hclent/BehaviorCheckingSemPar.</abstract_pt>
      <abstract_ja>クロスデータベースセマンティック構文解析のベンチマークパフォーマンスは、事前にトレーニングされた言語モデルが広く採用されたことによって、近年着実に上昇しています。しかし、既存の研究では、最先端のクロスデータベースセマンティック構文解析器は、新規のユーザー発話、データベース、およびクエリ構造に一般化するのに苦労していることが示されている。これらのモデルの強みと制限に関する透明な詳細を得るために、正準自然言語とSQLペアの制御された合成に基づいた診断テストアプローチを提案します。チェックリストからインスピレーションを得て、データベース間のセマンティック解析モデルのための一連の必須機能を特徴付け、対応するテストデータを合成する方法を詳しく説明します。提案されたアプローチを使用して、さまざまな高性能モデルを評価し、モデル間で明らかでないいくつかの弱点を特定した（例えば、多くの列を正しく選択できなかった）。当社のデータセットとコードは、http://github.com/hclent/BehaviorCheckingSemParでテストスイートとしてリリースされています。</abstract_ja>
      <abstract_zh>近年以来,博采预训语形之催化,跨数据库语义解析之基准性稳步攀升。 然今之研明,最先进跨数据库语义解析器难推新用户语数据库询结。 得其势与局限性之明微,举其自然语言SQL之受控而合其测试方法。 启 CheckList 之启,述跨数据库语义解析之基本功能,备言其测试数据。 臣等以所出之法质诸高性能模形,并见模形之不明者(如,无以正多列)。 臣等集代码于 http://github.com/hclent/BehaviorCheckingSemPar 为试套件发。</abstract_zh>
      <abstract_hi>क्रॉस-डेटाबेस सिमेंटिक पार्सिंग का बेंचमार्क प्रदर्शन हाल के वर्षों में तेजी से चढ़ गया है, जो पूर्व-प्रशिक्षित भाषा मॉडल के व्यापक गोद लेने से उत्प्रेरित हुआ है। फिर भी मौजूदा काम से पता चला है कि अत्याधुनिक क्रॉस-डेटाबेस सिमेंटिक पार्सर उपन्यास उपयोगकर्ता कथन, डेटाबेस और क्वेरी संरचनाओं को सामान्यीकृत करने के लिए संघर्ष करते हैं। इन मॉडलों की ताकत और सीमा पर पारदर्शी विवरण प्राप्त करने के लिए, हम विहित प्राकृतिक भाषा और एसक्यूएल जोड़े के नियंत्रित संश्लेषण के आधार पर एक नैदानिक परीक्षण दृष्टिकोण का प्रस्ताव करते हैं। चेकलिस्ट से प्रेरित होकर, हम क्रॉस-डेटाबेस सिमेंटिक पार्सिंग मॉडल के लिए आवश्यक क्षमताओं के एक सेट को चिह्नित करते हैं, और संबंधित परीक्षण डेटा को संश्लेषित करने के लिए विधि को विस्तृत करते हैं। हमने प्रस्तावित दृष्टिकोण का उपयोग करके विभिन्न प्रकार के उच्च प्रदर्शन वाले मॉडलों का मूल्यांकन किया, और मॉडलों में कई गैर-स्पष्ट कमजोरियों की पहचान की (उदाहरण के लिए कई कॉलम का सही ढंग से चयन करने में असमर्थ)। हमारे डेटासेट और कोड को http://github.com/hclent/BehaviorCheckingSemPar पर एक परीक्षण सूट के रूप में जारी किया जाता है।</abstract_hi>
      <abstract_ga>Tá ardú seasta tagtha ar fheidhmíocht tagarmharcála na parsála séimeantaigh tras-bhunachair shonraí le blianta beaga anuas, rud a spreag glacadh forleathan le samhlacha teanga réamhoilte. Ach léirigh obair atá ann cheana féin go mbíonn sé ag streachailt le parsálaithe séimeantach tras-bhunachar sonraí úrscothacha chun ginearálú go dtí nathanna úsáideora, bunachair shonraí agus struchtúir fiosrúchán nua. Chun sonraí trédhearcacha a fháil ar láidreachtaí agus ar theorannú na múnlaí seo, molaimid cur chuige tástála diagnóiseach bunaithe ar shintéis rialaithe de theanga nádúrtha chanónach agus péirí SQL. Arna spreagadh ag an Seicliosta, sainaithnímid tacar de chumais riachtanacha do mhúnlaí parsála shéimeantacha trasbhunachar sonraí, agus sonraímid an modh chun na sonraí tástála comhfhreagracha a shintéisiú. Rinneamar measúnú ar éagsúlacht de shamhlacha ardfheidhmíochta ag baint úsáide as an gcur chuige molta, agus shainaithnímid roinnt laigí neamhshoiléire trasna na samhlacha (m.sh. gan a bheith in ann go leor colún a roghnú i gceart). Eisítear ár dtacar sonraí agus ár gcód mar shraith tástála ag http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ga>
      <abstract_ka>მრავალური ბაზის სმენტიკური პარასტის ბენქმარიკური მუშაობა შემდეგ წლის შემდეგ, კატალიზებულია წინასწარმოადგენით წინასწარმოადგენით მრავალური ენის მოდელების გადავიწ მაგრამ მსგავსი სამუშაო მუშაობა ჩვენება, რომ სამუშაო სამუშაო სამუშაო დაბაზების სენმანტიკური პარასერები ძალიან ძალიან გავაკეთებენ, როგორც ახალი მომხ ამ მოდელების ძალიან ძალიან და ზომარების განსაზღვრებისთვის, ჩვენ განაზღვრებთ დიაგონტიკური ტესტის პროგრამის კონტროლური კანონიკური ენერგიის და SQL ზომების კონტროლური სინტეზ შემოწმება სია, ჩვენ გავაკეთებთ ძალიან მნიშვნელოვანი შესაძლებლობების ნახვა მოდელებისთვის, და შემდეგი ტესტის მონაცემების სინტესტიზაციის მეტი. ჩვენ განსაზღვრებულია მნიშვნელოვანი მოდელების განსაზღვრება, რომლებიც გამოყენებულია პროგრამის გამოყენება, და მოდელების განსაზღვრებულია რამდენიმე მნიშვნელოვანი დამატებულები (მაგა ჩვენი მონაცემები და კოდის კოდის გახსნა როგორც ტესტის სუტი http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ka>
      <abstract_hu>Az adatbázisok közötti szemantikai elemzés benchmark teljesítménye folyamatosan emelkedett az elmúlt években, amit az előre képzett nyelvi modellek széles körű alkalmazása katalizált. A meglévő munkák azonban azt mutatták, hogy a korszerű adatbázisok közötti szemantikai elemzők küzdenek az új felhasználói kijelentésekre, adatbázisokra és lekérdezési struktúrákra általánosítani. Annak érdekében, hogy átlátható részleteket kapjunk e modellek erősségeiről és korlátairól, javasoljuk a kanonikus természetes nyelv és SQL párok ellenőrzött szintézisén alapuló diagnosztikai tesztelési megközelítést. Az ellenőrzőlista ihletésére jellemzünk egy sor alapvető képességet az adatbázisok közötti szemantikai elemzési modellekhez, és részleteztük a megfelelő tesztadatok szintetizálásának módszerét. Számos nagy teljesítményű modellt értékeltünk a javasolt megközelítés alkalmazásával, és számos nem nyilvánvaló hiányosságot azonosítottunk a modellek között (pl. sok oszlopot nem tudtunk helyesen kiválasztani). Adatkészletünk és kódunk tesztcsomagként kerül kiadásra a http://github.com/hclent/BehaviorCheckingSemPar.</abstract_hu>
      <abstract_kk>Қосымша деректер қорының семантикалық талдау бақылау әрекеті соңғы жылдарда тұрақты көтерілген, алдын- оқылған тіл үлгілерін қабылдау үшін катализацияланған. Бірақ барлық жұмыс істеген күй- жай деректер қорының бірнеше деректер қорының семантикалық талдаушылары, пайдаланушылардың сөздерін, деректер қорын және сұраныс құрылымдарына жалпы түрлендіру Бұл үлгілердің күш және шектеулері туралы мөлдірлі егжей- тегжейлерді алу үшін, каноникалық тәуелді тіл және SQL қорларының басқару синтезесіне негізделген диагностикалық сынақтау тәсілі Тексеру тізімінің сигнализациясы, біз деректер қорының бірнеше семантикалық талдау үлгілеріне негізгі мүмкіндіктерді таңдап, сәйкесті сынақтар деректерін синтезализациялау әдісін егжей- тегжейлі Біз келтірілген тәсілді қолдану арқылы бірнеше жоғары істеу үлгілерін бағаладық және үлгілердің бірнеше түсінбеген қауіпсіздігін анықтадық (мысалы, көп бағандарды дұрыс таңдай Деректер және кодымыз тексеру сәтті ретінде шығарылды http://github.com/hclent/BehaviorCheckingSemPar.</abstract_kk>
      <abstract_el>Η απόδοση αναφοράς της σημασιολογικής ανάλυσης μεταξύ βάσεων δεδομένων έχει αυξηθεί σταθερά τα τελευταία χρόνια, καταλύτης από την ευρεία υιοθέτηση προ-εκπαιδευμένων γλωσσικών μοντέλων. Ωστόσο, η υπάρχουσα εργασία έχει δείξει ότι οι υπερσύγχρονοι σημασιολογικοί αναλυτές διασταυρούμενων βάσεων δεδομένων αγωνίζονται να γενικεύσουν σε νέες εκφράσεις χρηστών, βάσεις δεδομένων και δομές ερωτήματος. Για να αποκτήσουμε διαφανείς λεπτομέρειες σχετικά με τις δυνάμεις και τους περιορισμούς αυτών των μοντέλων, προτείνουμε μια διαγνωστική προσέγγιση δοκιμών βασισμένη στην ελεγχόμενη σύνθεση κανονικών φυσικών γλωσσών και ζευγαριών. Εμπνευσμένοι από τον κατάλογο ελέγχου, χαρακτηρίζουμε ένα σύνολο βασικών δυνατοτήτων για σημασιολογικά μοντέλα ανάλυσης μεταξύ βάσεων δεδομένων και λεπτομερώς τη μέθοδο σύνθεσης των αντίστοιχων δεδομένων δοκιμής. Αξιολογήσαμε μια ποικιλία μοντέλων υψηλής απόδοσης χρησιμοποιώντας την προτεινόμενη προσέγγιση και εντοπίσαμε αρκετές μη προφανείς αδυναμίες μεταξύ μοντέλων (π.χ. αδυναμία σωστής επιλογής πολλών στηλών). Το σύνολο δεδομένων και ο κώδικας μας κυκλοφορούν ως δοκιμαστική σουίτα στο http://github.com/hclent/BehaviorCheckingSemPar.</abstract_el>
      <abstract_mk>Референтната перформанса на семантичното анализирање на крстобазата на податоци постојано се зголеми во последниве години, катализирана од широкото усвојување на предобучени јазички модели. Сепак, постојната работа покажа дека најсовремените семантични анализатори на базата на податоци се борат да се генерализираат на нови изрази на корисниците, бази на податоци и структури за прашања. За да добиеме транспарентни детали за силностите и ограничувањата на овие модели, предложуваме дијагностички тестирачки пристап базиран на контролираната синтеза на каноничкиот природен јазик и парови SQL. Инспирирано од CheckList, ние карактеризираме сентиментални способности за семантички анализирачки модели на крстобазата на податоци, и го деталираме методот за синтезирање на соодветните тестови податоци. Ги проценивме различните модели со високи резултати користејќи го предложениот пристап и идентификувавме неколку неочигледни слабости меѓу моделите (на пример, не можеме правилно да избереме многу колони). Нашиот компјутер на податоци и кодот се објавени како тестиран апартман на http://github.com/hclent/BehaviorCheckingSemPar.</abstract_mk>
      <abstract_it>Le prestazioni di riferimento del parsing semantico cross-database sono aumentate costantemente negli ultimi anni, catalizzate dall'ampia adozione di modelli linguistici pre-formati. Eppure il lavoro esistente ha dimostrato che i parser semantici cross-database all'avanguardia faticano a generalizzare a nuove espressioni degli utenti, database e strutture di query. Per ottenere dettagli trasparenti sui punti di forza e limitazione di questi modelli, proponiamo un approccio diagnostico basato sulla sintesi controllata di linguaggi naturali canonici e coppie SQL. Ispirati dalla CheckList, abbiamo caratterizzato un insieme di funzionalità essenziali per i modelli di analisi semantica cross-database e dettagliato il metodo per sintetizzare i dati di test corrispondenti. Abbiamo valutato una varietà di modelli ad alte prestazioni utilizzando l'approccio proposto e identificato diversi punti deboli non evidenti tra i modelli (ad esempio, non è possibile selezionare correttamente molte colonne). Il nostro dataset e il nostro codice sono rilasciati come suite di test a http://github.com/hclent/BehaviorCheckingSemPar.</abstract_it>
      <abstract_ml>ക്രിസ്റ്റാബേസിന്റെ സെമാന്റിക് പാര്‍സിങ്ങിന്റെ ബെന്‍ച്മാര്‍ക്ക് പ്രകടനം അടുത്ത വര്‍ഷങ്ങളില്‍ സ്ഥിരമായി കയറിയിരിക്കുന്ന എന്നിട്ടും നിലവിലുള്ള ജോലി കാണിച്ചിരിക്കുന്നുവെങ്കിലും ക്രിസ്റ്റ് ഡാറ്റാബേസിന്റെ സെമാന്റിക് പാര്‍സറുകള്‍ നോവല്‍ ഉപയോക് ഈ മോഡലുകളുടെ ശക്തികളെയും പരിധികളെയും സ്വകാര്യമായ വിശദീകരണങ്ങള്‍ ലഭ്യമാക്കാന്‍, നിയന്ത്രിക്കപ്പെട്ട കാനോണിക്കല്‍ സ്വാഭാവ ഭാഷയെയും SQL ജോ ചെക്ക്‌ലിസ്റ്റില്‍ നിന്ന് അംഗീകരിക്കപ്പെട്ടിരിക്കുന്നു, ക്രിസ്റ്റഡാറ്റാബേസിലെ സെമാന്റിക് പാര്‍സിങ്ക് മോഡലുകള്‍ക്കുള്ള ഒര നിര്‍ദ്ദേശിക്കപ്പെട്ട മാതൃകങ്ങള്‍ ഉപയോഗിച്ച് കൂടുതല്‍ ഉയര്‍ന്ന പ്രവര്‍ത്തിപ്പിക്കുന്ന മാതൃകങ്ങള്‍ ഞങ്ങള്‍ വിലയിച്ചു കൊടുത്തു. പ്ര നമ്മുടെ ഡാറ്റാസെറ്റും കോഡും ടെസ്റ്റ് സ്യൂട്ട് ആയി വിട്ടുപോകുന്നു http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ml>
      <abstract_lt>Pastaraisiais metais semantinio analizavimo kryžminių duomenų bazių lyginamasis veiksmingumas nuolat išaugo, o tai paskatino platų iš anksto parengtų kalbų modelių priėmimą. Vis dėlto dabartinis darbas parodė, kad naujausios įvairių duomenų bazių semantiniai analizatoriai stengiasi bendradarbiauti su naujais naudotojų išraiškais, duomenų bazėmis ir užklausų struktūromis. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs.  Įkvėptas kontroliniu sąrašu, mes apibūdiname esminius įvairių duomenų bazių semantinio analizavimo modelių pajėgumus ir išsamiai apibūdiname atitinkamų bandymų duomenų sintezės metodą. Įvertinome įvairius aukšto lygio modelius taikant siūlomą metodą ir nustatėme keletą neaiškų modelių trūkumų (pvz., negalėjome teisingai pasirinkti daugelio stulpelių). Mūsų duomenų rinkinys ir kodas išleidžiami kaip bandymų rinkinys http://github.com/hclent/BehaviorCheckingSemPar.</abstract_lt>
      <abstract_mn>Сүүлийн жилүүд олон өгөгдлийн сангийн шинжлэх ухааны үйл ажиллагаа дамжуулсан хэл загваруудын шинжлэх ухааныг дэлгэрүүлсэн. Гэвч оршин байгаа ажил нь урлагийн төвшин өгөгдлийн сангийн шинжлэх ухааныг шинэ хэрэглэгчийн яриа, өгөгдлийн санг, квадрат бүтээгдэхүүнд нийтлэг зохион байгуулахыг хичээдэг. Эдгээр загваруудын чадвар, хязгаарлалтын тухай тодорхой нарийвчлалуудын тухай олохын тулд бид нарийвчлалтай байгалийн хэл болон SQL хоёрын хяналттай шинжлэх ухааны арга замыг санал болгодог. CheckList-ээс гайхалтай, бид өгөгдлийн сангийн semantic хуваалцах загварын үндсэн чадваруудыг харуулж, харьцангуй шалгалтын өгөгдлийг шинжлэх арга загварыг нарийвчлан тайлбарлаж байна. Бид санал өгсөн аргыг ашиглан олон өндөр үйлдвэрлэлийн загварыг үнэлж, загвар дээр олон тодорхойгүй хүчтэй байдлыг тодорхойлдог (жишээ нь олон багана зөв сонгож чадахгүй). Бидний өгөгдлийн суурь, код нь шалгалтын шийдвэр болж http://github.com/hclent/BehaviorCheckingSemPar.</abstract_mn>
      <abstract_ms>Performasi benchmark penghuraian semantik melintasi pangkalan data telah mendaki secara terus-menerus dalam tahun-tahun terakhir, dikatalizi oleh pengadopsi luas model bahasa terlatih. Yet existing work have shown that state-of-the-art cross-database semantic parsers struggle to generalize to novel user utterances, databases and query structures.  Untuk mendapatkan perincian yang jelas tentang kekuatan dan keterangan model ini, kami cadangkan pendekatan ujian diagnostik berdasarkan sintesis kawal bahasa alam canonical dan pasangan SQL. DiInspirasikan oleh Senarai Semak, kami menguntungkan set kemampuan penting untuk model penghuraian semantik melintas pangkalan data, dan perincian kaedah untuk sintesis data ujian yang sepadan. We evaluated a variety of high performing models using the proposed approach, and identified several non-obvious weaknesses across models (e.g. unable to correctly select many columns).  Set data dan kod kami dibebaskan sebagai suite ujian di http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ms>
      <abstract_mt>Il-prestazzjoni ta’ parametru referenzjarju tal-analiżi semantika bejn id-database żdiedet b’mod stabbli f’dawn l-aħħar snin, ikkatalizzata mill-adozzjoni wiesgħa ta’ mudelli lingwistiċi mħarrġa minn qabel. Madankollu, ix-xogħol eżistenti wera li l-analizzaturi semantiċi transbażiċi l-aktar avvanzati għandhom diffikultà biex jiġġeneralizzaw għal espressjonijiet ġodda tal-utenti, bażijiet tad-dejta u strutturi ta’ mistoqsijiet. Biex jinkisbu dettalji trasparenti dwar il-qawwiet u l-limitazzjoni ta’ dawn il-mudelli, nipproponu approċċ ta’ ttestjar dijanjostiku bbażat fuq sinteżi kkontrollata ta’ lingwa naturali kanonika u pari SQL. Inspired by the CheckList, we characterize a set of essential capabilities for cross-database semantic parsing models, and detailed the method for synthesizing the corresponding test data.  We evaluated a variety of high performing models using the proposed approach, and identified several non-obvious weaknesses across models (e.g. unable to correctly select many columns).  Is-sett tad-dejta u l-kodiċi tagħna huma rilaxxati bħala sett tat-testijiet fuq http://github.com/hclent/BehaviorCheckingSemPar.</abstract_mt>
      <abstract_ro>Performanța de referință a analizării semantice cross-baze de date a crescut constant în ultimii ani, catalizată de adoptarea largă a modelelor lingvistice pre-instruite. Cu toate acestea, lucrările existente au arătat că analizoarele semantice cross-baze de date de ultimă generație se luptă să generalizeze la declarații noi ale utilizatorilor, baze de date și structuri de interogare. Pentru a obține detalii transparente privind punctele forte și limitarea acestor modele, propunem o abordare de testare diagnostică bazată pe sinteza controlată a limbajului natural canonic și a perechilor SQL. Inspirat de CheckList, caracterizăm un set de capacități esențiale pentru modelele de analizare semantică cross-baze de date și detaliam metoda de sintetizare a datelor de testare corespunzătoare. Am evaluat o varietate de modele de înaltă performanță folosind abordarea propusă și am identificat mai multe puncte slabe non-evidente în cadrul modelelor (de exemplu, imposibilitatea de a selecta corect mai multe coloane). Setul nostru de date și codul sunt lansate ca o suită de test la http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ro>
      <abstract_si>බෙන්ච්මාර්ක් සැමැන්ටික් පරීක්ෂණයේ බෙන්ච්මාර්ක් ක්‍රියාත්මක වැඩසටහන් පරීක්ෂණය අවුරුද්ධ අවුරුද්ධ වල ස්ථ ඒත් තියෙන්නේ වැඩක් පෙන්වන්නේ කියලා ස්ථානය-of-the-art cross-data semantic පරීක්ෂකයෝ සාමාන්‍ය භාවිතාකරුවෝ වචන, දත්ත බේස් සහ ප්‍ මේ මොඩේලන්ගේ ශක්තිය සහ සීමාව සඳහා පාරදේශ විස්තර ගන්න, අපි පරීක්ෂණ පරීක්ෂණ අවස්ථාවක් පාලනය කරන්න පුළුවන් කැනෝනික්  පරීක්ෂණ ලැයිස්තුවෙන් ප්‍රශ්නය කරලා, අපි ප්‍රශ්නය කරන්නේ ප්‍රශ්නය සඳහා ප්‍රශ්නය සඳහා ප්‍රශ්නයක් සඳහා ප්‍රශ්නයක් සඳහා ප අපි ප්‍රශ්නයක් විදිහට ප්‍රශ්නයක් විදිහට ප්‍රශ්නයක් කරලා ප්‍රශ්නයක් තියෙනවා, ඒ වගේම ප්‍රශ්නයක් විදිහට ප්‍රශ්නයක් න අපේ දත්ත සැට් සහ කෝඩ් පරීක්ෂණ සූට් වලින් නිදහස් කරලා තියෙනවා http://github.com/hclent/BehaviorCheckingSemPar.</abstract_si>
      <abstract_no>Den vanlege utviklinga av semantiske tolking av kryss- databasen har klikka stabil i løpet av siste år, katalisert av den brede innføring av føretrainerte språk- modeller. Men det eksisterande arbeidet har vist at semantiske analyserar av kunsten kjem til å generellisere til nyttige brukarstaler, databaser og spørjingsstrukturar. For å få gjennomsiktige detaljar om styrkene og begrensningar av desse modelane, foreslår vi ein diagnostisk testmetode basert på kontrollerte syntese av kanoniske naturspråk og SQL-par. Dette er oppretta av CheckList, og vi karakteriserer eit sett av viktige kapasiteter for semantiske tolking av kryss- database og detaljert metoden for å syntisera dei tilsvarande test data. Vi evaluerte ein del høg utføringsmodular med den foreslåtte tilnærminga, og identifiserte fleire ikkje-åpenbarde tyrke over modeller (for eksempel kan ikkje velja mange kolonner riktig). Datasett og kode våre vert sletta som test suite på http://github.com/hclent/BehaviorCheckingSemPar.</abstract_no>
      <abstract_pl>Wydajność analizy semantycznej między bazami danych stale wzrosła w ostatnich latach, katalizowana przez szerokie przyjęcie wstępnie przeszkolonych modeli językowych. Jednak istniejące prace pokazały, że najnowocześniejsze parsery semantyczne między bazami danych trudno uogólnić do nowych wypowiedzi użytkowników, baz danych i struktur zapytań. Aby uzyskać przejrzyste szczegóły dotyczące mocnych i ograniczeń tych modeli, proponujemy podejście testowe diagnostyczne oparte na kontrolowanej syntezie kanonicznego języka naturalnego i par SQL. Zainspirowani Listą kontrolną charakteryzujemy zestaw niezbędnych możliwości dla modeli parsowania semantycznego między bazami danych oraz szczegółowo sposób syntezy odpowiednich danych testowych. Oceniliśmy różne modele o wysokiej wydajności przy użyciu proponowanego podejścia i zidentyfikowaliśmy kilka nieoczywistych słabości w poszczególnych modelach (np. niemożliwość prawidłowego wyboru wielu kolumn). Nasz zestaw danych i kod są udostępniane jako pakiet testowy pod adresem: http://github.com/hclent/BehaviorCheckingSemPar.</abstract_pl>
      <abstract_so>Bangmooyinka lagu sameeyo jardiinada baarlamaanka ee gaarka ah ee qaramaanka ayaa si joogto ah u soo baxay sanadkii ugu dambeeyey, oo waxaa lagu baaraandegay korsashada modellada afka hore oo la tababaray. Weliba shaqada joogta ayaa muujiyey in xaalad-xaalad-farshaxan-sanad-baarlamayaashu ay u dagaalamayaan inay generaliso hadallada isticmaalayaasha, databases iyo dhismaha wax weydiinta. Si aan u helno macluumaad muuqasho ah oo ku saabsan xoogga iyo xadida noocyadan, waxaynu soo jeedaynaa qalabka imtixaanka, taasoo lagu saleyn karo qalabka la ilaaliyo afka asalka ah iyo labaha SQL. Wax lagu soo dhiibo Listiga, waxaynu qornaa koox awoodood muhiim ah oo u qoran samooyinka baaritaanka ee baaritaanka ee basaaska kala duduwan, waxaana qoraynaa qaabka lagu soo ururiyo macluumaadka imtixaanka oo isku mid ah. Waxaannu qiimeynay noocyo faro badan oo sameynta qaababka la soo jeeday, waxaana qiimeynay cudurooyin aan muuqanayn samooyinka oo dhan (tusaale ahaan awoodin inay si hagaagsan u doortaan safooyin badan). Hagaagteena macluumaadka iyo codsigeena waxaa loo furay in loo tijaabiyo http://github.com/hclent/BehaviorCheckingSemPar.</abstract_so>
      <abstract_sv>Jämförelseprestandan för semantisk tolkning över databaser har stigit stadigt under de senaste åren, katalyserat av det breda antagandet av pre-utbildade språkmodeller. Ändå har befintligt arbete visat att state-of-the-art semantiska tolkare över databaser kämpar för att generalisera till nya användaruttryck, databaser och frågestrukturer. För att få transparenta detaljer om styrkorna och begränsningen av dessa modeller föreslår vi en diagnostisk testmetod baserad på kontrollerad syntes av kanoniskt naturligt språk och SQL-par. Inspirerade av CheckList karaktäriserar vi en uppsättning viktiga funktioner för semantisk tolkningsmodeller över databaser och beskriver metoden för att syntetisera motsvarande testdata. Vi utvärderade en mängd högpresterande modeller med hjälp av det föreslagna tillvägagångssättet och identifierade flera icke-uppenbara svagheter mellan modeller (t.ex. oförmåga att välja många kolumner korrekt). Vårt dataset och vår kod släpps som en testsvit på http://github.com/hclent/BehaviorCheckingSemPar.</abstract_sv>
      <abstract_sr>U poslednjih godina se uspješno penjala kriterija semantičkog analiza preko baze podataka, katalizirana širom usvajanjem predobučenih jezičkih modela. Međutim, postojeći rad pokazali su da se semantički parseri među umjetničkim bazama bore za generalizaciju novih govora korisnika, baza podataka i struktura pitanja. Da bi dobili transparentne detalje o snazi i ograničenju ovih modela, predlažemo dijagnostički pristup testiranja baziran na kontroliranoj sintezi kanoničkog prirodnog jezika i SQL pare. Inspirirali smo na kontrolnoj listi, karakteriziramo set ključnih sposobnosti za semantične analize preko baze podataka i detaljirali metodu za sinteziranje odgovarajućih testnih podataka. Procjenjivali smo razne visokih modela provedbe koristeći predloženi pristup i identifikovali nekoliko neoèiglednih slabosti u modelima (na primer, ne mogu ispravno odabrati mnoge kolone). Naši podaci i kodovi su otpušteni kao test apartman u http://github.com/hclent/BehaviorCheckingSemPar.</abstract_sr>
      <abstract_ur>کرسٹ ڈیٹابیس سمانتیک پارسینگ کی بنچم مارک کی عملکرد اگلوں سالوں میں ثابت قدم چڑھی گئی ہے، جو پہلے آموزش کی زبان نمڈلوں کی وسیع قبول کرتی ہے۔ حالانکہ موجود کام نے دکھایا ہے کہ کرس ڈیٹابیس کی حالت سیمانٹیک پارس نے نو کارساز کلمات، ڈیٹابیس اور کیوری ساخترات کے لئے جرائل کی کوشش کی ہے. یہ موڈلوں کی طاقت اور محدودیت کے بارے میں روشن تفصیل حاصل کرنے کے لئے، ہم ایک تفصیل تفصیل کا طریقہ پیش کریں جو کانونیک طبیعی زبان اور SQL جوڑوں کی کنٹرول کی سینٹیس پر بنیاد ہے. چک لیسٹ کے ذریعے ہم نے کرس-ڈیٹابیس سیمنٹی پارسینگ موڈل کے لئے ضروری قابلیت کے ساتھ ایک مجموعہ کو روشن کرلیا ہے اور مطابق آزمائش ڈیٹ کے ساتھ مطابق طریقہ کا تفصیل کرلیا ہے. ہم نے پیش فرض کی طریقہ کے مطابق بہت سی عملہ نمونڈلوں کی آزمائش کی اور نمونڈلوں میں بہت سی ظاہری کمزوری پہچان دی (جیسے بہت سی ستونوں کو درست انتخاب نہیں کر سکتے)۔ ہمارے ڈاٹ سٹ اور کوڈ ایک امتحان سوئٹ کے طور پر آزاد ہوئے ہیں http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ur>
      <abstract_ta>இந்த பென்க்மார்க் செயல்பாடு முன் பயிற்சி மொழி மாதிரி பாடலின் பென்மார்க் செயல்படுத்தப்பட்டது. ஆனாலும் இருக்கும் வேலை காண்பிக்கப்பட்டிருக்கிறது அந்த நிலைமை- கலை கிடைக்கும் குறிப்பு தகவல் தளத்தின் பெம்மான்டிக் பார்சர்கள்  இந்த மாதிரிகளின் சக்திகள் மற்றும் எல்லைகள் பற்றிய தெரிவான விவரங்களை பெற, நாம் கட்டுப்படுத்தப்பட்ட கானோனிக் இயல்பான மொழி மற்றும் SQL ஜோடி தேர்ந்தெடு நாம் பரிந்துரைக்கப்பட்ட முறைமையை பயன்படுத்தி பல உயர் செயல்படுத்தும் மாதிரிகளை மதிப்பிட்டோம், மற்றும் மாதிரிகள் முழுவதும் தெளிவாக எங்கள் தகவல் அமைப்புகள் மற்றும் குறியீடுகள் ஒரு சோதனை தூண்டியாக வெளியேற்றப்பட்டது http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ta>
      <abstract_uz>Name Hech qachon mavjud vazifa maʼlumotlar bazasi haqida semantik parserlarining holatini koʻrsatilgan so'zlar, maʼlumot bazalari va soʻrov tuzuvlarini yaratish uchun harakat qiladi. Bu modellarning tashkilotlari va chegarasini aniqlash uchun, biz kanonik tabiiy tillar va SQL parchalarining boshqaruv tizimini boshqarish uchun diagnostic imtiyozni qoidamiz. Name Biz talab qilingan usulni yordamida ko'p ko'plab bajarish modellarini qiymatdik, va hamma modellardagi ko'plab ko'plab narsalarni aniqlash mumkin (masalan, ko'plab ustunlarni to ʻg ʻri tanlab boʻlmadi). Maʼlumotlar sahifasi va kodlash imkoniyatlarimiz http://github.com/hclent/BehaviorCheckingSemPar.</abstract_uz>
      <abstract_vi>Sự tiến bộ tiêu chuẩn của phân tích mẫu chữ thập dữ liệu đã được tăng liên tục trong những năm gần đây, xúc tác bởi sự phát tán rộng rãi các mô hình ngôn ngữ được đào tạo. Tuy nhiên, công việc đã có đã cho thấy các phân tích ngữ pháp xã hội thời trang đang tìm cách tổng hợp lại thành kiến mới của người dùng, cơ sở dữ liệu và cấu trúc truy vấn. Để có được chi tiết trong suốt về sức mạnh và giới hạn của các mô hình này, chúng tôi đề xuất một phương pháp kiểm tra chẩn đoán dựa trên sự kết hợp tự nhiên và các cặp mã SQL. Dựa theo the CheckList, chúng tôi mô tả một số khả năng thiết yếu cho các mô hình phân tích theo ngữ pháp giao thông, và mô tả phương pháp tổng hợp dữ liệu kiểm tra tương ứng. Chúng tôi đánh giá một loạt các mô hình có trình độ cao bằng phương pháp đề xuất, và xác định vài nhược điểm chưa rõ ràng trên các mô hình (v.d. không thể chọn đúng nhiều cột). Hệ thống dữ liệu và mật mã của chúng tôi được phát hành tại phòng thí nghiệm http://github.com/hclent/BehaviorCheckingSemPar.</abstract_vi>
      <abstract_bg>Сравнителното представяне на семантичното анализиране на кръстосани бази данни се покачва стабилно през последните години, катализирано от широкото приемане на предварително обучени езикови модели. Съществуващите изследвания обаче показват, че съвременните семантични анализатори на кръстосани бази данни се борят да обобщят към нови потребителски изказвания, бази данни и структури на заявки. За да се получат прозрачни подробности за силните страни и ограниченията на тези модели, предлагаме диагностичен подход за тестване въз основа на контролиран синтез на канонични естествени езици и двойки. Вдъхновени от Контролния списък, ние характеризираме набор от основни възможности за семантичен анализ на междубази данни и подробно описваме метода за синтезиране на съответните тестови данни. Ние оценихме различни модели с висока производителност, използвайки предложения подход, и идентифицирахме няколко неочевидни слабости в моделите (напр. неспособност да изберем правилно много колони). Нашият набор от данни и код се публикуват като тест комплект на http://github.com/hclent/BehaviorCheckingSemPar.</abstract_bg>
      <abstract_da>Benchmarkydelsen af semantisk parsing på tværs af databaser er steget støt i de seneste år, katalyseret af den brede anvendelse af prætrænede sprogmodeller. Alligevel har eksisterende arbejde vist, at state-of-the-art semantiske parsere på tværs af databaser kæmper for at generalisere til nye brugerudtalelser, databaser og forespørgselsstrukturer. For at opnå gennemsigtige detaljer om styrker og begrænsninger af disse modeller, foreslår vi en diagnostisk testtilgang baseret på kontrolleret syntese af kanoniske natursprog og SQL par. Inspireret af tjeklisten karakteriserer vi et sæt væsentlige muligheder for semantiske analysemodeller på tværs af databaser og detaljerede metoden til syntetisering af de tilsvarende testdata. Vi evaluerede en række højtydende modeller ved hjælp af den foreslåede fremgangsmåde, og identificerede flere ikke-indlysende svagheder på tværs af modeller (f.eks. ude af stand til korrekt at vælge mange kolonner). Vores datasæt og kode udgives som en test suite på http://github.com/hclent/BehaviorCheckingSemPar.</abstract_da>
      <abstract_nl>De benchmark prestaties van cross-database semantische parsing zijn de afgelopen jaren gestaag gestegen, gekatalyseerd door de brede adoptie van vooraf getrainde taalmodellen. Toch hebben bestaand werk aangetoond dat state-of-the-art cross-database semantische parsers moeite hebben om te generaliseren naar nieuwe gebruikersuitingen, databases en query structuren. Om transparante details te verkrijgen over de sterktes en beperkingen van deze modellen, stellen we een diagnostische testbenadering voor gebaseerd op gecontroleerde synthese van canonieke natuurlijke taal en SQL paren. Geïnspireerd op de CheckList, karakteriseren we een reeks essentiële mogelijkheden voor cross-database semantische parsing modellen en gedetailleerde de methode voor het synthetiseren van de overeenkomstige testgegevens. We evalueerden een verscheidenheid aan high performance modellen met behulp van de voorgestelde aanpak, en identificeerden verschillende niet-voor de hand liggende zwakke punten tussen modellen (bijvoorbeeld niet in staat om veel kolommen correct te selecteren). Onze dataset en code worden uitgebracht als testsuite op http://github.com/hclent/BehaviorCheckingSemPar.</abstract_nl>
      <abstract_hr>U posljednjih godina se uspješno popeo kritična rezultat semantičke analize preko baze podataka, katalizirana širom usvajanjem predobučenih jezičkih modela. Međutim, postojeći rad pokazali su da se semantički analitičari u stanju umjetnosti bore za generalizaciju novih izraza korisnika, baza podataka i struktura pitanja. Da bi dobili transparentne detalje o snazi i ograničenju ovih modela, predlažemo pristup dijagnostičkom testiranju na temelju kontrolirane sinteze kaničkog prirodnog jezika i SQL pare. Uhvaćeni provjerenim listom, karakteriziramo skup ključnih sposobnosti za semantičke analize preko baze podataka i detaljiranje metode za sinteziranje odgovarajućih ispitivanja. Procjenjivali smo razne visoke izvršne modele koristeći predloženi pristup i identificirali nekoliko nedočitih slabosti u svim modelima (npr. ne mogu ispravno odabrati mnoge kolone). Naši podaci i kodovi su otpušteni kao test apartman u http://github.com/hclent/BehaviorCheckingSemPar.</abstract_hr>
      <abstract_de>Die Benchmark-Performance des datenbankübergreifenden semantischen Parsing ist in den letzten Jahren stetig gestiegen, was durch die breite Akzeptanz vortrainierter Sprachmodelle katalysiert wird. Bisherige Arbeiten haben jedoch gezeigt, dass moderne datenbankübergreifende semantische Parser Schwierigkeiten haben, auf neue Benutzer Äußerungen, Datenbanken und Abfragestrukturen zu verallgemeinern. Um transparente Details über die Stärken und Grenzen dieser Modelle zu erhalten, schlagen wir einen diagnostischen Testansatz vor, der auf einer kontrollierten Synthese von kanonischen natürlichen Sprach- und SQL-Paaren basiert. Inspiriert von der CheckList charakterisieren wir eine Reihe wesentlicher Funktionen für datenbankübergreifende semantische Parsing-Modelle und erläutern die Methode zur Synthese der entsprechenden Testdaten. Wir evaluierten eine Vielzahl von Hochleistungsmodellen mit dem vorgeschlagenen Ansatz und identifizierten mehrere nicht offensichtliche Schwächen zwischen Modellen (z.B. nicht in der Lage, viele Spalten korrekt auszuwählen). Unser Datensatz und Code werden als Testsuite unter http://github.com/hclent/BehaviorCheckingSemPar.</abstract_de>
      <abstract_id>Pertunjukan benchmark dari pemeriksaan semantis cross-database telah mendaki secara konstan dalam tahun-tahun terakhir, dikatalisasi oleh adopsi lebar dari model bahasa yang terlatih. Namun pekerjaan yang ada telah menunjukkan bahwa pembicara semantis cross-database state-of-the-art berjuang untuk menyebarkan kepada pengguna baru utterances, databases dan struktur pertanyaan. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs.  Terinspirasi oleh Daftar Periksa, kami mengkaraterisasikan set kemampuan penting untuk model penganalis semantis cross-database, dan mendetail metode untuk sintesis data ujian yang sesuai. Kami mengevaluasi berbagai jenis model berpengaruh tinggi menggunakan pendekatan yang diusulkan, dan mengidentifikasi beberapa kelemahan yang tidak jelas di antara model (misalnya tidak dapat memilih banyak kolom dengan benar). Data set dan kode kami dibebaskan sebagai suite tes di http://github.com/hclent/BehaviorCheckingSemPar.</abstract_id>
      <abstract_ko>최근 몇 년 동안 예비 훈련 언어 모델의 광범위한 사용에 따라 크로스 데이터베이스 의미 분석의 기준 성능이 안정적으로 상승했다.그러나 기존의 작업은 가장 선진적인 크로스 데이터베이스 의미 해석기가 새로운 사용자의 언어, 데이터베이스와 조회 구조에 보급되기 어렵다는 것을 보여준다.이러한 모델의 장점과 한계를 얻기 위해 우리는 자연 언어와 SQL의 통제 합성을 규범화하는 진단 테스트 방법을 제시했다.검사표의 계발을 받아 우리는 크로스 데이터베이스 의미 해석 모델의 기본 기능을 묘사하고 해당하는 테스트 데이터를 합성하는 방법을 상세하게 소개했다.우리는 제안한 방법을 사용하여 각종 고성능 모델을 평가하고 모델 중의 몇 가지 뚜렷하지 않은 약점을 확정했다. 예를 들어 많은 열을 정확하게 선택할 수 없다.우리의 데이터 집합과 코드는 테스트 세트로 발표되었다http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ko>
      <abstract_fa>عملکرد بررسی زیادی از بررسی سامانتیک پایگاه‌های زیادی در سال‌های اخیر به طور کامل بالا رفته است، که توسط پذیرفتن وسیع مدل‌های زبان پیش آموزش شده است. هنوز کارهای موجود نشان داده اند که شرکت‌کننده‌های متوسط داده‌های هنری جهاد می‌کنند تا کلمات‌های نو، بنیاد داده‌ها و ساختارهای پرسیدن به کلمات‌های استفاده‌کننده‌ها، جهاد کنند. برای گرفتن جزئیات شفافیق در مورد قوت و محدودیت این مدل، ما یک روش آزمایش تشخیص را پیشنهاد می‌کنیم که بر اساس مجموعه کنترل از زبان طبیعی کانونیک و جفت SQL کنترل شده است. توسط فهرست چک تحریک شده، ما یک مجموعه از توانایی های ضروری برای مدل‌های تجزیه‌کننده‌ی semantic متصل داده‌های زیادی را characterize می‌کنیم، و روش‌ها را برای تنظیم داده‌های آزمایش متصل می‌کنیم. ما با استفاده از دستور پیشنهاد مختلف مدل عملکرد بالا ارزیابی کردیم و چند ضعیف غیر مشاهده را در مدل شناسایی کردیم (مثال قادر به انتخاب ستون‌های زیادی نیستند). مجموعه داده‌های ما و کد ما به عنوان یک سوئت آزمایش در http://github.com/hclent/BehaviorCheckingSemPar.</abstract_fa>
      <abstract_sw>Uwezeshaji wa bendera wa kubeba mfumo wa sekunde wa mfumo wa taarifa umekuwa ukiendelea katika miaka ya hivi karibuni, umekatwa na utekelezaji wa mifano ya lugha zilizofunzwa kabla. Hata hivyo, kazi iliyopo imeonyesha kuwa hali ya mabunge wa takwimu za aina ya sanaa wanajitahidi kuzalisha hotuba za watumiaji wa kitaifa, databases na miundombinu ya kutafuta. Ili kupata taarifa za uwazi kuhusu nguvu na vizuizi vya mifano hizi, tunapendekeza mbinu ya uchunguzi kwa msingi wa utaratibu wa lugha ya asili na wawili wa SQL. Tulihamishwa na Orodha ya CheckList, tunahusisha uwezo wa muhimu wa mifano ya mabungano ya mifano ya kupitia database, na tunaelezea namna ya kuunganisha data zinazofanana. Tulipima mifano mbalimbali ya maonyesho ya juu kwa kutumia mbinu zilizopendekezwa, na tukakutambua udhaifu kadhaa isiyo wazi katika mifano mbalimbali (kwa mfano hakuna uwezo wa kuchagua safu nyingi). Taarifa zetu na sheria zetu zimetolewa kama suti la jaribio http://github.com/hclent/BehaviorCheckingSemPar.</abstract_sw>
      <abstract_sq>Ekzekutimi i paraqitjes së analizimit semantik të bazës së dhënave kryqësore është rritur në mënyrë të qëndrueshme në vitet e fundit, katalizuar nga miratimi i gjerë i modeleve të gjuhës së paratrajnuar. Megjithatë, puna ekzistuese ka treguar se analizuesit semantikë të bazës së dhënave më të larta luftojnë për të gjeneralizuar në shprehje të reja të përdoruesve, baza të dhënash dhe struktura pyetjeje. Për të marrë detaje transparente mbi forcat dhe kufizimet e këtyre modeleve, propozojmë një metodë diagnostike testimi bazuar në sintezën e kontrolluar të gjuhës kanonike natyrore dhe çifteve SQL. Inspiruar nga Lista e Kontrollit, ne karakterizojmë një sërë aftësive thelbësore për modelet e analizimit semantik të bazës së dhënave kryqësore, dhe detalizojmë metodën për sintezimin e të dhënave korrespondente të testit. Ne vlerësuam një shumicë modelesh me rezultate të larta duke përdorur qasjen e propozuar dhe identifikuam disa dobësi jo të qarta nëpërmjet modeleve (për shembull, të pamundur të zgjedhim korrekt shumë kolona). Të dhënat dhe kodet tona janë lëshuar si një suite testimi në http://github.com/hclent/BehaviorCheckingSemPar.</abstract_sq>
      <abstract_af>Die benchmark-prestasie van kruis-databasis semantiese verwerking het in onlangse jaar stadig geklim, gekatiseer deur die wyde aangeneem van vooraf-opgelei taal modele. Maar bestaande werk het vertoon dat staat-of-the-art kruis-databasis semantiese verwerkers struikel om te genereliseer na nuwe gebruiker uitspraak, databasis en navraag strukture. Om deursigtig besonderhede te kry oor die sterkte en beperking van hierdie modele, voorstel ons 'n dijagnostike toets toegang gebaseer op kontroleerde sinteze van kanoniese natuurlike taal en SQL pare. Inspirasieer deur die CheckList, ons karakteriseer 'n stel van nuwe moontlikhede vir kruisdatabase semantiese verwerking modele, en gedetaileer die metode vir sintetisering van die ooreenstemmende toets data. Ons het 'n verskilligheid van hoë uitvoerde modele met gebruik van die voorgestelde toegang, en verskeie nie-oorskynlike swakhede deur modele g e ïdentifiseer (bv. nie moontlik na korrek kies baie kolomme). Ons datastel en kode word as 'n toets suite verlos op http://github.com/hclent/BehaviorCheckingSemPar.</abstract_af>
      <abstract_tr>Ýakyndaky ýyllar içinde çoklu datum bazynyň semantik analysiýasynyň etkinleşmesi, öňünden öňünden bilim sistemleriniň nusgasyna görä catalyzed edildi. Ýöne meýdança işleýän işiň durumynda, sanat bazalary we soraglary düzenlemek üçin ullançy sözlerini, veritabanlary we soraglar düzenlemek üçin mücadele edýändigini görkezildi. Bu nusgalaryň güýçleri we mugatlaryny barlamak üçin biz kanonik dili we SQL çiftleriň kontrol edilen sintezi üstine diagnostik testi metodyny teklip edip otyrýarys. CheckList tarapyndan üpjümlenen, cross-database semantik analyz modelleri üçin esasy ukyplaryň bir takmyny karakterize edýäris we saýlayan testi maglumaty sintezleýän yöntemi detaylaşdyryldyr. Biz g örkezilen ýagdaýda näçe ýokary ukyply nusgalary çykardyk we nusgalaryň içinde näçe görnüş zawplygy tapandyk (meselâ, köp sütun saýlamagy mümkin edip bilmedik). Biziň veri setmimiz we kodymyz teste takmynasynda çykylýar http://github.com/hclent/BehaviorCheckingSemPar.</abstract_tr>
      <abstract_am>The benchmark performance of cross-database semantic parsing has climbed steadily in recent years, catalyzed by the wide adoption of pre-trained language models.  ነገር ግን የአሁኑ ሥራ የክፍለ የዳታ-አርእስት-የዳታ-አርእስት የስሜናክኛ ፓርራር ቃላትን፣ ዳታ መቀመጫዎች እና የመጠየቂያውን መሠረት ለማቀናቀል ይጋልማሉ፡፡ የእነዚህን ዓይነቶች በኃይል እና ግንኙነትን ለማግኘት፣ የካኖኒካዊ ፍጥረት ቋንቋ እና SQL ዓይነቶች በተጨማሪው የፍጥረት ቋንቋ እና የፍጥረት ጉዳይ ላይ የተመሳሳይ የዳgnostic ፈተና ሥርዓት እና መፍጠርን እናስጀምራለን፡፡ በሥርዓት ዝርዝር የተገኘውን የዳታ መቀመጫውን semantic ማኅበረሰብ እናስቀምጣለን፡፡ በተዘጋጀው ሥርዓት በመጠቀም ብዙ ከፍተኛ የሥርዓት ዓይነቶች አስተዋልነው፤ በዓይነቶች መካከል ያልታወቀ ደካሞችን አረጋገጥን (ምሳሌ ብዙዎችን ስርዓት በመምረጥ አይችልም) ዳታቤያችን እና ኮዱን እንደ ፈተና ጉዳይ ሲፈቱ http://github.com/hclent/BehaviorCheckingSemPar.</abstract_am>
      <abstract_hy>Վերջին տարիների ընթացքում սեմանտիկ վերլուծության համեմատային արտադրողականությունը կանգ բարձրացավ, կատալիզացված նախապատրաստված լեզվի մոդելների լայն ընդունման շնորհիվ: Սակայն գոյություն ունեցող աշխատանքները ցույց են տալիս, որ ամենահետաքրքիր խաչված բազայի սեմանտիկ վերլուծումները պայքարում են ընդհանուր օգտագործողների նոր արտահայտությունների, տվյալների և հարցերի կառուցվածքների համար: Այս մոդելների ուժեղությունների և սահմանափակումների թափանցիկ մանրամասներ ստանալու համար մենք առաջարկում ենք ախտորոշման թեստերի մոտեցում, որը հիմնված է կանոնիկ բնական լեզուների և SQL զույգերի կառավարվող սինթեզի վրա: Հոգեշնչված Կենտրոնային ցանցի կողմից, մենք բնորոշվում ենք մի շարք կարևոր հնարավորություններ, որոնք օգտագործվում են միջաբազայի սեմանտիկ վերլուծության մոդելների համար, և մանրամասն ներկայացնում ենք համապատասխան թեստերի տվյալների սինթեզի Մենք գնահատեցինք բազմաթիվ բարձրահատուկ մոդելներ օգտագործելով առաջարկված մոտեցումը և բացահայտեցինք մի քանի ոչ ակնհայտ թույլ մոդելների միջև (օրինակ, չենք կարողանում ճիշտ ընտրել շատ սյուններ): Մեր տվյալների համակարգը և կոդը արտադրվում են http://github.com/hclent/BehaviorCheckingSemPar.</abstract_hy>
      <abstract_bn>সাম্প্রতিক বছরগুলোতে ক্রস-ডাটাবেস সেমেন্টিক পার্জিং এর বেঞ্চম্যার্ক প্রদর্শন করা হয়েছে, পূর্ব প্রশিক্ষিত ভাষার মডেলের প্রয তবুও বিদ্যমান কাজ দেখিয়েছে যে শিল্প-শিল্পের রাষ্ট্রের সেম্পেন্টিক পার্সারের সংগ্রামের সংগ্রাম, বর্তমান ব্যবহারকারীর ভাষা,  এই মডেলের শক্তি এবং সীমাবদ্ধতা নিয়ে স্বচ্ছতা বিস্তারিত বিস্তারিত বিবরণ পাওয়ার জন্য, আমরা ক্যানোনিক্যাল প্রাকৃতিক ভাষা এবং এসকিউএল জো চেক- লিস্ট দ্বারা অনুপ্রাণিত, আমরা ক্রাস-ডাটাবেসের সেম্যান্টিক পার্সিং মডেলের জন্য একটি গুরুত্বপূর্ণ ক্ষমতা চিহ্নিত করি এবং সংশ্লিষ আমরা প্রস্তাবিত পদ্ধতি ব্যবহার করে বিভিন্ন বিভিন্ন প্রদর্শনীর মডেলের মূল্য মূল্যায়ন করেছি এবং সারা মডেলের বিভিন্ন স্পষ্ট দুর্বলতা পরিচ আমাদের ডাটাসেট এবং কোড একটি পরীক্ষা স্যুট হিসেবে মুক্ত করা হয়েছে http://github.com/hclent/BehaviorCheckingSemPar.</abstract_bn>
      <abstract_bs>U posljednjih godina se uspješno penjala kritična rezultat semantičkog analiza preko baze podataka, katalizirana širom usvajanjem predobučenih jezičkih modela. Međutim, postojeći rad pokazali su da se semantički analitičari među umjetničkim bazama bore za generalizaciju novih izraza korisnika, baza podataka i struktura pitanja. Da bi dobili transparentne detalje o snazi i ograničenju ovih modela, predlažemo pristup dijagnostičkom testiranju na temelju kontrolirane sinteze kaničkog prirodnog jezika i SQL pare. Inspirirali smo na kontrolnoj listi, karakteriziramo set ključnih sposobnosti za semantične analize preko baze podataka, i detaljirali metodu za sinteziranje odgovarajućih testnih podataka. Procjenjivali smo razne visokih modela provedbe koristeći predloženi pristup i identificirali nekoliko neočiglednih slabosti u svim modelima (npr. ne mogu ispravno odabrati mnoge kolone). Naši podaci i kodovi su otpušteni kao test apartman u http://github.com/hclent/BehaviorCheckingSemPar.</abstract_bs>
      <abstract_az>Son illərdə çoxlu dağlar verilənlərin semantik ayırmasının benchmark performansı, əvvəlcə təhsil edilmiş dil modellərinin çoxlu çoxluğu ilə katalizləndirildi. Halbuki mövcuddur işlər yeni istifadəçilərin sözləri, veri tabanları və query strukturlarına generalizasyon üçün mücadele edirlər. Bu modellərin gücü və sınırlığı haqqında a çıq detaylı almaq üçün, kanonik doğal dillərin və SQL çiftlərinin kontrol edilmiş sintezi üzərində diagnostik testi metodlarını təklif edirik. CheckList vasitəsilə təşkil edildi, biz çox-database semantik ayırma modellərinin əsas qabiliyyətlərini təşkil edirik və müəyyən edilən sınama məlumatlarını sintezləşdirmək üçün metodunu detaylaşdırdıq. Biz təklif olunan tərzimlə müxtəlif yüksək performans modellərini değerləşdirdik və modellərdə bir neçə a çıq-aydın zəiflik tanıdıq (məsələn, çoxlu sütunları doğru seçə bilmədik). Məlumatlarımız və kodlarımız sınamaq üçün http://github.com/hclent/BehaviorCheckingSemPar.</abstract_az>
      <abstract_et>Andmebaasidevahelise semantilise parsimise võrdlusjõudlus on viimastel aastatel pidevalt kasvanud, mida katalüseerib eelkoolitud keelemudelite laialdane kasutuselevõtt. Olemasolevad tööd on siiski näidanud, et tipptasemel andmebaasidevahelistel semantilistel parseritel on raskusi üldistada uudseid kasutajate väljendeid, andmebaase ja päringustruktuure. Selleks et saada läbipaistvaid üksikasju nende mudelite tugevuste ja piirangute kohta, pakume välja diagnostilise testimise lähenemisviisi, mis põhineb kanoonilise looduskeele ja SQL paaride kontrollitud sünteesil. Kontrollnimekirjast inspireerituna kirjeldame andmebaasidevaheliste semantiliste parsimismudelite olulisi võimalusi ja täpsustasime vastavate testiandmete sünteesimise meetodit. Hindasime väljapakutud lähenemisviisi abil mitmesuguseid kõrge jõudlusega mudeleid ning tuvastasime mudelites mitmeid ilmselgeid nõrkusi (nt mitmeid veerge ei ole võimalik õigesti valida). Meie andmekogum ja kood avaldatakse testikomplektina aadressil http://github.com/hclent/BehaviorCheckingSemPar.</abstract_et>
      <abstract_cs>Benchmarkový výkon sémantického parsování mezi databázemi v posledních letech neustále stoupal, katalyzovaný širokým přijetím předškolených jazykových modelů. Stávající práce však ukázaly, že nejmodernější sémantické parsery mezi databázemi se snaží zobecnit na nové uživatelské výroky, databáze a dotazové struktury. Pro získání transparentních detailů o silných a omezeních těchto modelů navrhujeme diagnostický testovací přístup založený na řízené syntéze kanonického přirozeného jazyka a SQL párů. Inspirováni kontrolním seznamem charakterizujeme sadu základních schopností pro cross-databázové sémantické parsovací modely a podrobně popisujeme metodu syntetizace odpovídajících testovacích dat. Pomocí navrženého přístupu jsme hodnotili řadu vysoce výkonných modelů a identifikovali jsme několik nezřejmých nedostatků napříč modely (např. neschopnost správně vybrat mnoho sloupců). Naše datová sada a kód jsou vydány jako testovací sada na http://github.com/hclent/BehaviorCheckingSemPar.</abstract_cs>
      <abstract_fi>Tietokantaenvälisen semanttisen jäsentämisen vertailuarvo on noussut tasaisesti viime vuosina, mikä on johtanut ennalta koulutettujen kielimallien laajaan käyttöönottoon. Nykyiset tutkimukset ovat kuitenkin osoittaneet, että uusimmat tietokannan väliset semanttiset parserit pyrkivät yleistymään uusiin käyttäjälauseisiin, tietokantoihin ja kyselyrakenteisiin. Saadaksemme läpinäkyviä yksityiskohtia näiden mallien vahvuuksista ja rajoituksista ehdotamme diagnostista testausmenetelmää, joka perustuu kanonisen luonnollisen kielen ja SQL-parin kontrolloituun synteesiin. Checklistan innoittamana luonnehdimme joukon keskeisiä ominaisuuksia tietokannan välisten semanttisten jäsennysmallien kannalta ja yksityiskohtaisesti menetelmän vastaavien testitietojen syntetisoimiseksi. Arvioimme useita tehokkaita malleja ehdotetun lähestymistavan avulla ja havaitsimme useita epäselviä heikkouksia eri malleissa (esim. se, ettei useita sarakkeita voitu valita oikein). Aineistomme ja koodimme julkaistaan testikokonaisuutena osoitteessa http://github.com/hclent/BehaviorCheckingSemPar.</abstract_fi>
      <abstract_ca>El rendiment de referència de l'analització semàntica transversal de bases de dades ha pujat constantment en els últims anys, catalitzat per l'ampla adopció de models de llenguatge pré-entrenats. Yet existing work have shown that state-of-the-art cross-database semantic parsers struggle to generalize to novel user utterances, databases and query structures.  To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs.  Inspirat per la Llista de Verificació, caracteritzem un conjunt de capacitats essencials per a models d'analització semàntica de la base de dades cruzada, i detallem el mètode de sintetització de les dades de prova correspondents. Vam avaluar una varietat de models d'alta performance utilitzant l'enfocament proposat, i vam identificar diverses debilitats no òbvias a través dels models (per exemple, incapacitat de seleccionar correctament moltes columnes). El nostre conjunt de dades i codis són publicats com una suite de provas http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ca>
      <abstract_jv>Kernel bench Erlangno, akeh barêng saiki wis rampun kanggo state-of-the-arts To Get bright details on the strength and limitation of this model, we proposal a diagram testing method supported on control concheses of canonsal normal language and sql paragraphs. yes Awak dhéwé éntuk sistem akeh pisan neng sampek dadi nggawe model sing bisa nyebuté nggawe akses, dadi nêmên langgar sampek duluran gambar model (bisa nguasai iso diaksebah akeh dumateng). Opo dataset karo kode sing nyimpek dadi nganggo kesempan http://github.com/hclent/BehaviorCheckingSemPar.</abstract_jv>
      <abstract_ha>An buɗe bangon tsarin da aka yi wa salon-database semantic parse ta buƙata daidai cikin shekara na farko, aka katalyẽ shi da shirin faɗaɗawa na zaɓen misãlai masu yin zaman-tsari. Babu da wani aikin da ke jira sun nuna cewa-state-of-the-art-base-semantic parser ɗin na yi kwaɗayi zuwa a ƙiƙiro magana na mai amfani da yanzu, database da tsari na tambayi. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs.  An Inspire shi da Jerin Kifyuta, za'a ƙayyade wasu abinci na muhimu wa misãlai masu yin parse na-database na semantic, kuma ana rarraba shiryoyin da za'a sami da data masu inganci. Mun ƙaddara wasu misãlai masu aikin aiki da aka yi amfani da hanyarwa wanda aka buƙata, kuma Muka gane masu rauni masu bayyani a cikin misãlai (misali, an kasa zãɓi wasu salummai). An sakar da koden da aka samu http://github.com/hclent/BehaviorCheckingSemPar.</abstract_ha>
      <abstract_sk>Referenčna uspešnost semantičnega razčlenjanja med bazami podatkov se je v zadnjih letih stalno povečevala, kar je spodbudilo široko sprejetje vnaprej usposobljenih jezikovnih modelov. Obstoječa dela pa so pokazala, da se najsodobnejši semantični razčlenjevalci medbaz težko posplošujejo na nove uporabniške izjave, baze podatkov in strukture poizvedb. Za pridobitev preglednih podrobnosti o prednostih in omejitvah teh modelov predlagamo diagnostični preskusni pristop, ki temelji na nadzorovani sintezi kanoničnega naravnega jezika in SQL parov. Na podlagi kontrolnega seznama smo opredelili nabor bistvenih zmogljivosti za semantične modele razčlenitve med bazami podatkov in podrobno opisali metodo sintetizacije ustreznih testnih podatkov. Z uporabo predlaganega pristopa smo ocenili različne visoko uspešne modele in ugotovili več neobičajnih slabosti med modeli (npr. nesposobnosti pravilnega izbora številnih stolpcev). Naš nabor podatkov in koda so objavljeni kot testni paket na spletni strani http://github.com/hclent/BehaviorCheckingSemPar.</abstract_sk>
      <abstract_bo>The benchmark performance of cross-database semantic parsing has climbed steadily in recent years, catalyzed by the wide adoption of pre-trained language models. Yet existing work have shown that state-of-the-art cross-database semantic parsers struggle to generalize to novel user utterances, databases and query structures. To obtain transparent details on the strengths and limitation of these models, we propose a diagnostic testing approach based on controlled synthesis of canonical natural language and SQL pairs. Inspired by the CheckList, we characterize a set of essential capabilities for cross-database semantic parsing models, and detailed the method for synthesizing the corresponding test data. ང་ཚོས་བྱ་རིམ་པ་གཞན་དང་མི་འདྲ་བ་གཉིས་ཀྱི་གནད་སྤྱད་ནས་འཆར་ཡོད་པའི་མཐུན་སྣེ་མང་པོ་ཞིག་དཔྱད་བྱས་ནས་མི་འདྲ་བའི་རྣམ ང་ཚོའི་གནད་སྡུད་སྒྲིག་ཆ་འཕྲིན་དང་ཨང་རྟགས་ལ་བརྟག་ཞིབ་བྱེད་པ http://github.com/hclent/BehaviorCheckingSemPar.</abstract_bo>
      <abstract_he>The benchmark performance of cross-database semantic parsing has climbed steadily in recent years, catalyzed by the wide adoption of pre-trained language models.  אך העבודה הקיומית הראה כי מעבדות סמנטיות במאגר נתונים מצוין ביותר נאבקות כדי להתפשט למוצאות משתמשים חדשות, בסיסי נתונים ומבני שאלות. כדי להשיג פרטים שקופים על החזקים והגבולות של הדוגמנים האלה, אנו מציעים גישה אבחנה מבוססת על סינטזה שולטת של שפה טבעית קנונית וזוגים SQL. השראה על ידי רשימת הבדיקה, אנו מאפיינים קבוצה של יכולות חיוניות לדוגמאות מערכת הנתונים סמנטית לחצות, ופרט את השיטה לסינטזיה של נתוני הבדיקה המתאימים. הערכנו מגוון של דוגמנים מופעים גבוהים באמצעות הגישה המוצעת, וזהונו כמה חולשות לא ברורות ברחבי דוגמנים (למשל לא מסוגלים לבחור עמודים רבים בצורה נכונה). Our dataset and code are released as a test suite at  http://github.com/hclent/BehaviorCheckingSemPar.</abstract_he>
      </paper>
    <paper id="9">
      <title>Writing Style Author Embedding Evaluation</title>
      <author><first>Enzo</first><last>Terreau</last></author>
      <author><first>Antoine</first><last>Gourru</last></author>
      <author><first>Julien</first><last>Velcin</last></author>
      <pages>84–93</pages>
      <abstract>Learning authors representations from their textual productions is now widely used to solve multiple downstream tasks, such as <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>, link prediction or <a href="https://en.wikipedia.org/wiki/Recommender_system">user recommendation</a>. Author embedding methods are often built on top of either Doc2Vec (Mikolov et al. 2014) or the Transformer architecture (Devlin et al. Evaluating the quality of these <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> and what they capture is a difficult task. Most articles use either <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification accuracy</a> or <a href="https://en.wikipedia.org/wiki/Attribution_(copyright)">authorship attribution</a>, which does not clearly measure the quality of the <a href="https://en.wikipedia.org/wiki/Representation_space">representation space</a>, if it really captures what it has been built for. In this paper, we propose a novel evaluation framework of author embedding methods based on the <a href="https://en.wikipedia.org/wiki/Writing_style">writing style</a>. It allows to quantify if the embedding space effectively captures a set of <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">stylistic features</a>, chosen to be the best proxy of an author writing style. This approach gives less importance to the topics conveyed by the documents. It turns out that recent <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are mostly driven by the inner semantic of authors’ production. They are outperformed by simple baselines, based on state-of-the-art pretrained sentence embedding models, on several linguistic axes. These baselines can grasp complex linguistic phenomena and <a href="https://en.wikipedia.org/wiki/Writing_style">writing style</a> more efficiently, paving the way for designing new style-driven author embedding models.</abstract>
      <url hash="388c35e5">2021.eval4nlp-1.9</url>
      <attachment type="Software" hash="393e384a">2021.eval4nlp-1.9.Software.zip</attachment>
      <bibkey>terreau-etal-2021-writing</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.9</doi>
      <pwccode url="https://github.com/enzofleur/style_embedding_evaluation" additional="false">enzofleur/style_embedding_evaluation</pwccode>
    </paper>
    <paper id="11">
      <title>Statistically Significant Detection of Semantic Shifts using Contextual Word Embeddings</title>
      <author id="yang-liu-Helsinki"><first>Yang</first><last>Liu</last></author>
      <author><first>Alan</first><last>Medlar</last></author>
      <author><first>Dorota</first><last>Glowacka</last></author>
      <pages>104–113</pages>
      <abstract>Detecting lexical semantic change in smaller data sets, e.g. in <a href="https://en.wikipedia.org/wiki/Historical_linguistics">historical linguistics</a> and <a href="https://en.wikipedia.org/wiki/Digital_humanities">digital humanities</a>, is challenging due to a lack of <a href="https://en.wikipedia.org/wiki/Statistical_power">statistical power</a>. This issue is exacerbated by non-contextual embedding models that produce one embedding per word and, therefore, mask the variability present in the data. In this article, we propose an approach to estimate <a href="https://en.wikipedia.org/wiki/Semantic_shift">semantic shift</a> by combining contextual word embeddings with permutation-based statistical tests. We use the false discovery rate procedure to address the large number of <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">hypothesis tests</a> being conducted simultaneously. We demonstrate the performance of this approach in simulation where it achieves consistently high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> by suppressing false positives. We additionally analyze real-world data from SemEval-2020 Task 1 and the Liverpool FC subreddit corpus. We show that by taking sample variation into account, we can improve the robustness of individual semantic shift estimates without degrading overall performance.</abstract>
      <url hash="02b42c3a">2021.eval4nlp-1.11</url>
      <bibkey>liu-etal-2021-statistically</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.11</doi>
    </paper>
    <paper id="12">
      <title>Referenceless Parsing-Based Evaluation of AMR-to-English Generation<fixed-case>AMR</fixed-case>-to-<fixed-case>E</fixed-case>nglish Generation</title>
      <author><first>Emma</first><last>Manning</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>114–122</pages>
      <abstract>Reference-based automatic evaluation metrics are notoriously limited for NLG due to their inability to fully capture the range of possible outputs. We examine a referenceless alternative : evaluating the adequacy of English sentences generated from Abstract Meaning Representation (AMR) graphs by parsing into AMR and comparing the parse directly to the input. We find that the errors introduced by automatic AMR parsing substantially limit the effectiveness of this approach, but a manual editing study indicates that as <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> improves, parsing-based evaluation has the potential to outperform most reference-based metrics.</abstract>
      <url hash="ea62188a">2021.eval4nlp-1.12</url>
      <bibkey>manning-schneider-2021-referenceless</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.12</doi>
    </paper>
    <paper id="14">
      <title>IST-Unbabel 2021 Submission for the Explainable Quality Estimation Shared Task<fixed-case>IST</fixed-case>-Unbabel 2021 Submission for the Explainable Quality Estimation Shared Task</title>
      <author><first>Marcos</first><last>Treviso</last></author>
      <author><first>Nuno M.</first><last>Guerreiro</last></author>
      <author><first>Ricardo</first><last>Rei</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <pages>133–145</pages>
      <abstract>We present the joint contribution of Instituto Superior Tcnico (IST) and Unbabel to the Explainable Quality Estimation (QE) shared task, where systems were submitted to two tracks : constrained (without word-level supervision) and unconstrained (with word-level supervision). For the constrained track, we experimented with several explainability methods to extract the relevance of input tokens from sentence-level QE models built on top of multilingual pre-trained transformers. Among the different tested methods, composing explanations in the form of attention weights scaled by the <a href="https://en.wikipedia.org/wiki/Norm_(mathematics)">norm of value vectors</a> yielded the best results. When word-level labels are used during training, our best results were obtained by using word-level predicted probabilities. We further improve the performance of our methods on the two tracks by ensembling explanation scores extracted from models trained with different pre-trained transformers, achieving strong results for in-domain and zero-shot language pairs.</abstract>
      <url hash="3e99e093">2021.eval4nlp-1.14</url>
      <bibkey>treviso-etal-2021-ist</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.14</doi>
      <pwccode url="https://github.com/deep-spin/explainable-qe-shared-task" additional="false">deep-spin/explainable-qe-shared-task</pwccode>
    </paper>
    <paper id="21">
      <title>What is SemEval evaluating? A Systematic Analysis of Evaluation Campaigns in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val evaluating? A Systematic Analysis of Evaluation Campaigns in <fixed-case>NLP</fixed-case></title>
      <author><first>Oskar</first><last>Wysocki</last></author>
      <author><first>Malina</first><last>Florea</last></author>
      <author><first>Dónal</first><last>Landers</last></author>
      <author><first>André</first><last>Freitas</last></author>
      <pages>209–229</pages>
      <abstract>SemEval is the primary venue in the NLP community for the proposal of new challenges and for the systematic empirical evaluation of NLP systems. This paper provides a systematic quantitative analysis of <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a> aiming to evidence the patterns of the contributions behind <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a>. By understanding the distribution of task types, <a href="https://en.wikipedia.org/wiki/Performance_metric">metrics</a>, <a href="https://en.wikipedia.org/wiki/Software_architecture">architectures</a>, participation and <a href="https://en.wikipedia.org/wiki/Citation">citations</a> over time we aim to answer the question on what is being evaluated by <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a>.</abstract>
      <url hash="ac0e2951">2021.eval4nlp-1.21</url>
      <bibkey>wysocki-etal-2021-semeval</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.21</doi>
    </paper>
    <paper id="22">
      <title>The UMD Submission to the Explainable MT Quality Estimation Shared Task : Combining Explanation Models with Sequence Labeling<fixed-case>UMD</fixed-case> Submission to the Explainable <fixed-case>MT</fixed-case> Quality Estimation Shared Task: Combining Explanation Models with Sequence Labeling</title>
      <author><first>Tasnim</first><last>Kabir</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <pages>230–237</pages>
      <abstract>This paper describes the UMD submission to the Explainable Quality Estimation Shared Task at the EMNLP 2021 Workshop on Evaluation &amp; Comparison of NLP Systems. We participated in the word-level and sentence-level MT Quality Estimation (QE) constrained tasks for all language pairs : Estonian-English, Romanian-English, German-Chinese, and Russian-German. Our approach combines the predictions of a word-level explainer model on top of a sentence-level QE model and a sequence labeler trained on synthetic data. These <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> are based on pre-trained multilingual language models and do not require any word-level annotations for training, making them well suited to zero-shot settings. Our best-performing system improves over the best baseline across all metrics and language pairs, with an average gain of 0.1 in AUC, <a href="https://en.wikipedia.org/wiki/Average_precision">Average Precision</a>, and <a href="https://en.wikipedia.org/wiki/Recall_(memory)">Recall</a> at Top-K score.</abstract>
      <url hash="db90a85e">2021.eval4nlp-1.22</url>
      <bibkey>kabir-carpuat-2021-umd</bibkey>
      <doi>10.18653/v1/2021.eval4nlp-1.22</doi>
    </paper>
    </volume>
</collection>