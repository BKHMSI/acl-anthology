<collection id="P19">
  <volume id="1" ingest-date="2019-07-28">
    <meta>
      <booktitle>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</booktitle>
      <url hash="8d8cdc49">P19-1</url>
      <editor><first>Anna</first><last>Korhonen</last></editor>
      <editor><first>David</first><last>Traum</last></editor>
      <editor><first>Llu&#237;s</first><last>M&#224;rquez</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Florence, Italy</address>
      <month>July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="5c925b1d">P19-1000</url>
      <bibkey>acl-2019-association</bibkey>
    </frontmatter>
    <paper id="1">
      <title>One Time of Interaction May Not Be Enough: Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues</title>
      <author><first>Chongyang</first><last>Tao</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Can</first><last>Xu</last></author>
      <author><first>Wenpeng</first><last>Hu</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>1&#8211;11</pages>
      <abstract>Currently, researchers have paid great attention to retrieval-based dialogues in open-domain. In particular, people study the problem by investigating context-response matching for multi-turn response selection based on publicly recognized benchmark data sets. State-of-the-art methods require a response to interact with each utterance in a context from the beginning, but the interaction is performed in a shallow way. In this work, we let utterance-response interaction go deep by proposing an interaction-over-interaction network (IoI). The model performs matching by stacking multiple interaction blocks in which residual information from one time of interaction initiates the interaction process again. Thus, matching information within an utterance-response pair is extracted from the interaction of the pair in an iterative fashion, and the information flows along the chain of the blocks via representations. Evaluation results on three benchmark data sets indicate that IoI can significantly outperform state-of-the-art methods in terms of various matching metrics. Through further analysis, we also unveil how the depth of interaction affects the performance of IoI.</abstract>
      <url hash="e6f6a98f">P19-1001</url>
      <video href="https://vimeo.com/385493447" permission="false" />
      <doi>10.18653/v1/P19-1001</doi>
      <bibkey>tao-etal-2019-one</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/douban">Douban</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/douban-conversation-corpus">Douban Conversation Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/e-commerce-1">E-commerce</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ubuntu-dialogue-corpus">UDC</pwcdataset>
    </paper>
    <paper id="2">
      <title>Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</title>
      <author><first>Zekang</first><last>Li</last></author>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Fandong</first><last>Meng</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Qian</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>12&#8211;21</pages>
      <abstract>Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformer-based architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance.</abstract>
      <url hash="7789293c">P19-1002</url>
      <video href="https://vimeo.com/383950369" />
      <doi>10.18653/v1/P19-1002</doi>
      <bibkey>li-etal-2019-incremental</bibkey>
      <pwccode url="https://github.com/lizekang/ITDD" additional="false">lizekang/ITDD</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cmu-dog">CMU DoG</pwcdataset>
    </paper>
    <paper id="3">
      <title>Improving Multi-turn Dialogue Modelling with Utterance <fixed-case>R</fixed-case>e<fixed-case>W</fixed-case>riter</title>
      <author><first>Hui</first><last>Su</last></author>
      <author><first>Xiaoyu</first><last>Shen</last></author>
      <author><first>Rongzhi</first><last>Zhang</last></author>
      <author><first>Fei</first><last>Sun</last></author>
      <author><first>Pengwei</first><last>Hu</last></author>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>22&#8211;31</pages>
      <abstract>Recent research has achieved impressive results in single-turn dialogue modelling. In the multi-turn setting, however, current models are still far from satisfactory. One major challenge is the frequently occurred coreference and information omission in our daily conversation, making it hard for machines to understand the real intention. In this paper, we propose rewriting the human utterance as a pre-process to help multi-turn dialgoue modelling. Each utterance is first rewritten to recover all coreferred and omitted information. The next processing steps are then performed based on the rewritten utterance. To properly train the utterance rewriter, we collect a new dataset with human annotations and introduce a Transformer-based utterance rewriting architecture using the pointer network. We show the proposed architecture achieves remarkably good performance on the utterance rewriting task. The trained utterance rewriter can be easily integrated into online chatbots and brings general improvement over different domains.</abstract>
      <url hash="9fc5d1cd">P19-1003</url>
      <video href="https://vimeo.com/383951307" />
      <doi>10.18653/v1/P19-1003</doi>
      <bibkey>su-etal-2019-improving</bibkey>
    </paper>
    <paper id="4">
      <title>Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study</title>
      <author><first>Chinnadhurai</first><last>Sankar</last></author>
      <author><first>Sandeep</first><last>Subramanian</last></author>
      <author><first>Chris</first><last>Pal</last></author>
      <author><first>Sarath</first><last>Chandar</last></author>
      <author><first>Yoshua</first><last>Bengio</last></author>
      <pages>32&#8211;37</pages>
      <abstract>Neural generative models have been become increasingly popular when building conversational agents. They offer flexibility, can be easily adapted to new domains, and require minimal domain engineering. A common criticism of these systems is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these models use the available dialog history by studying the sensitivity of the models to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our code, we believe that it will serve as a useful diagnostic tool for evaluating dialog systems in the future.</abstract>
      <url hash="164144c6">P19-1004</url>
      <video href="https://vimeo.com/383952222" />
      <doi>10.18653/v1/P19-1004</doi>
      <bibkey>sankar-etal-2019-neural</bibkey>
      <pwccode url="https://github.com/chinnadhurai/ParlAI" additional="false">chinnadhurai/ParlAI</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mutualfriends">MutualFriends</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/persona-chat-1">PERSONA-CHAT</pwcdataset>
    </paper>
    <paper id="5">
      <title>Boosting Dialog Response Generation</title>
      <author><first>Wenchao</first><last>Du</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>38&#8211;43</pages>
      <abstract>Neural models have become one of the most important approaches to dialog response generation. However, they still tend to generate the most common and generic responses in the corpus all the time. To address this problem, we designed an iterative training process and ensemble method based on boosting. We combined our method with different training and decoding paradigms as the base model, including mutual-information-based decoding and reward-augmented maximum likelihood learning. Empirical results show that our approach can significantly improve the diversity and relevance of the responses generated by all base models, backed by objective measurements and human evaluation.</abstract>
      <url hash="d672a301">P19-1005</url>
      <video href="https://vimeo.com/383953490" />
      <doi>10.18653/v1/P19-1005</doi>
      <bibkey>du-black-2019-boosting</bibkey>
    </paper>
    <paper id="7">
      <title>Semantic Parsing with Dual Learning</title>
      <author><first>Ruisheng</first><last>Cao</last></author>
      <author><first>Su</first><last>Zhu</last></author>
      <author><first>Chen</first><last>Liu</last></author>
      <author><first>Jieyu</first><last>Li</last></author>
      <author><first>Kai</first><last>Yu</last></author>
      <pages>51&#8211;64</pages>
      <abstract>Semantic parsing converts natural language queries into structured logical forms. The lack of training data is still one of the most serious problems in this area. In this work, we develop a semantic parsing framework with the dual learning algorithm, which enables a semantic parser to make full use of data (labeled and even unlabeled) through a dual-learning game. This game between a primal model (semantic parsing) and a dual model (logical form to query) forces them to regularize each other, and can achieve feedback signals from some prior-knowledge. By utilizing the prior-knowledge of logical form structures, we propose a novel reward signal at the surface and semantic levels which tends to generate complete and reasonable logical forms. Experimental results show that our approach achieves new state-of-the-art performance on ATIS dataset and gets competitive performance on OVERNIGHT dataset.</abstract>
      <url hash="8f19cd7e">P19-1007</url>
      <video href="https://vimeo.com/383955994" />
      <doi>10.18653/v1/P19-1007</doi>
      <bibkey>cao-etal-2019-semantic</bibkey>
      <pwccode url="https://github.com/rhythmcao/semantic-parsing-dual" additional="false">rhythmcao/semantic-parsing-dual</pwccode>
    </paper>
    <paper id="9">
      <title><fixed-case>AMR</fixed-case> Parsing as Sequence-to-Graph Transduction</title>
      <author><first>Sheng</first><last>Zhang</last></author>
      <author><first>Xutai</first><last>Ma</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>80&#8211;94</pages>
      <abstract>We propose an attention-based model that treats AMR parsing as sequence-to-graph transduction. Unlike most AMR parsers that rely on pre-trained aligners, external semantic resources, or data augmentation, our proposed parser is aligner-free, and it can be effectively trained with limited amounts of labeled AMR data. Our experimental results outperform all previously reported SMATCH scores, on both AMR 2.0 (76.3% on LDC2017T10) and AMR 1.0 (70.2% on LDC2014T12).</abstract>
      <url hash="4006f92a">P19-1009</url>
      <video href="https://vimeo.com/383957151" />
      <doi>10.18653/v1/P19-1009</doi>
      <bibkey>zhang-etal-2019-amr</bibkey>
      <pwccode url="https://github.com/sheng-z/stog" additional="false">sheng-z/stog</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ldc2017t10">LDC2017T10</pwcdataset>
    </paper>
    <paper id="10">
      <title>Generating Logical Forms from Graph Representations of Text and Entities</title>
      <author><first>Peter</first><last>Shaw</last></author>
      <author><first>Philip</first><last>Massey</last></author>
      <author><first>Angelica</first><last>Chen</last></author>
      <author><first>Francesco</first><last>Piccinno</last></author>
      <author><first>Yasemin</first><last>Altun</last></author>
      <pages>95&#8211;106</pages>
      <abstract>Structured information about entities is critical for many semantic parsing tasks. We present an approach that uses a Graph Neural Network (GNN) architecture to incorporate information about relevant entities and their relations during parsing. Combined with a decoder copy mechanism, this approach provides a conceptually simple mechanism to generate logical forms with entities. We demonstrate that this approach is competitive with the state-of-the-art across several tasks without pre-training, and outperforms existing approaches when combined with BERT pre-training.</abstract>
      <url hash="ed852d90">P19-1010</url>
      <video href="https://vimeo.com/383957851" />
      <doi>10.18653/v1/P19-1010</doi>
      <bibkey>shaw-etal-2019-generating</bibkey>
    </paper>
    <paper id="11">
      <title>Learning Compressed Sentence Representations for On-Device Text Processing</title>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Pengyu</first><last>Cheng</last></author>
      <author><first>Dhanasekar</first><last>Sundararaman</last></author>
      <author><first>Xinyuan</first><last>Zhang</last></author>
      <author><first>Qian</first><last>Yang</last></author>
      <author><first>Meng</first><last>Tang</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>107&#8211;116</pages>
      <abstract>Vector representations of sentences, trained on massive text corpora, are widely used as generic sentence embeddings across a variety of NLP problems. The learned representations are generally assumed to be continuous and real-valued, giving rise to a large memory footprint and slow retrieval speed, which hinders their applicability to low-resource (memory and computation) platforms, such as mobile devices. In this paper, we propose four different strategies to transform continuous and generic sentence embeddings into a binarized form, while preserving their rich semantic information. The introduced methods are evaluated across a wide range of downstream tasks, where the binarized sentence embeddings are demonstrated to degrade performance by only about 2% relative to their continuous counterparts, while reducing the storage requirement by over 98%. Moreover, with the learned binary representations, the semantic relatedness of two sentences can be evaluated by simply calculating their Hamming distance, which is more computational efficient compared with the inner product operation between continuous embeddings. Detailed analysis and case study further validate the effectiveness of proposed methods.</abstract>
      <url hash="02a68727">P19-1011</url>
      <video href="https://vimeo.com/383958512" />
      <doi>10.18653/v1/P19-1011</doi>
      <bibkey>shen-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/senteval">SentEval</pwcdataset>
    </paper>
    <paper id="12">
      <title>The (Non-)Utility of Structural Features in <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-based Dependency Parsers</title>
      <author><first>Agnieszka</first><last>Falenska</last></author>
      <author><first>Jonas</first><last>Kuhn</last></author>
      <pages>117&#8211;128</pages>
      <abstract>Classical non-neural dependency parsers put considerable effort on the design of feature functions. Especially, they benefit from information coming from structural features, such as features drawn from neighboring tokens in the dependency tree. In contrast, their BiLSTM-based successors achieve state-of-the-art performance without explicit information about the structural context. In this paper we aim to answer the question: How much structural context are the BiLSTM representations able to capture implicitly? We show that features drawn from partial subtrees become redundant when the BiLSTMs are used. We provide a deep insight into information flow in transition- and graph-based neural architectures to demonstrate where the implicit information comes from when the parsers make their decisions. Finally, with model ablations we demonstrate that the structural context is not only present in the models, but it significantly influences their performance.</abstract>
      <url hash="073aa8d0">P19-1012</url>
      <video href="https://vimeo.com/383962400" />
      <doi>10.18653/v1/P19-1012</doi>
      <bibkey>falenska-kuhn-2019-non</bibkey>
    </paper>
    <paper id="19">
      <title>An Effective Approach to Unsupervised Machine Translation</title>
      <author><first>Mikel</first><last>Artetxe</last></author>
      <author><first>Gorka</first><last>Labaka</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <pages>194&#8211;203</pages>
      <abstract>While machine translation has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fine-tuned through on-the-fly back-translation. Together, we obtain large improvements over the previous state-of-the-art in unsupervised machine translation. For instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014.</abstract>
      <url hash="d450f4bc">P19-1019</url>
      <video href="https://vimeo.com/383966926" />
      <doi>10.18653/v1/P19-1019</doi>
      <bibkey>artetxe-etal-2019-effective</bibkey>
      <pwccode url="https://github.com/artetxem/monoses" additional="false">artetxem/monoses</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="20">
      <title>Effective Adversarial Regularization for Neural Machine Translation</title>
      <author><first>Motoki</first><last>Sato</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Shun</first><last>Kiyono</last></author>
      <pages>204&#8211;210</pages>
      <abstract>A regularization technique based on adversarial perturbation, which was initially developed in the field of image processing, has been successfully applied to text classification tasks and has yielded attractive improvements. We aim to further leverage this promising methodology into more sophisticated and critical neural models in the natural language processing field, i.e., neural machine translation (NMT) models. However, it is not trivial to apply this methodology to such models. Thus, this paper investigates the effectiveness of several possible configurations of applying the adversarial perturbation and reveals that the adversarial regularization technique can significantly and consistently improve the performance of widely used NMT models, such as LSTM-based and Transformer-based models.</abstract>
      <url hash="2901f136">P19-1020</url>
      <attachment type="supplementary" hash="29b84b1b">P19-1020.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/383968561" />
      <doi>10.18653/v1/P19-1020</doi>
      <bibkey>sato-etal-2019-effective</bibkey>
    </paper>
    <paper id="24">
      <title>Attention Guided Graph Convolutional Networks for Relation Extraction</title>
      <author><first>Zhijiang</first><last>Guo</last></author>
      <author><first>Yan</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <pages>241&#8211;251</pages>
      <abstract>Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.</abstract>
      <url hash="55490755">P19-1024</url>
      <video href="https://vimeo.com/383992004" />
      <doi>10.18653/v1/P19-1024</doi>
      <bibkey>guo-etal-2019-attention</bibkey>
      <pwccode url="https://github.com/Cartus/AGGCN_TACRED" additional="true">Cartus/AGGCN_TACRED</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/tacred">TACRED</pwcdataset>
    </paper>
    <paper id="26">
      <title>Relation Embedding with Dihedral Group in Knowledge Graph</title>
      <author><first>Canran</first><last>Xu</last></author>
      <author><first>Ruijiang</first><last>Li</last></author>
      <pages>263&#8211;272</pages>
      <abstract>Link prediction is critical for the application of incomplete knowledge graph (KG) in the downstream tasks. As a family of effective approaches for link predictions, embedding methods try to learn low-rank representations for both entities and relations such that the bilinear form defined therein is a well-behaved scoring function. Despite of their successful performances, existing bilinear forms overlook the modeling of relation compositions, resulting in lacks of interpretability for reasoning on KG. To fulfill this gap, we propose a new model called DihEdral, named after dihedral symmetry group. This new model learns knowledge graph embeddings that can capture relation compositions by nature. Furthermore, our approach models the relation embeddings parametrized by discrete values, thereby decrease the solution space drastically. Our experiments show that DihEdral is able to capture all desired properties such as (skew-) symmetry, inversion and (non-) Abelian composition, and outperforms existing bilinear form based approach and is comparable to or better than deep learning models such as ConvE.</abstract>
      <url hash="4cf5cc05">P19-1026</url>
      <video href="https://vimeo.com/383993749" />
      <doi>10.18653/v1/P19-1026</doi>
      <bibkey>xu-li-2019-relation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18rr">WN18RR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago3-10">YAGO3-10</pwcdataset>
    </paper>
    <paper id="28">
      <title>Augmenting Neural Networks with First-order Logic</title>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <pages>292&#8211;302</pages>
      <abstract>Today, the dominant paradigm for training neural networks involves minimizing task loss on a large dataset. Using world knowledge to inform a model, and yet retain the ability to perform end-to-end training remains an open question. In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide training and prediction. Our framework systematically compiles logical statements into computation graphs that augment a neural network without extra learnable parameters or manual redesign. We evaluate our modeling strategy on three tasks: machine comprehension, natural language inference, and text chunking. Our experiments show that knowledge-augmented networks can strongly improve over baselines, especially in low-data regimes.</abstract>
      <url hash="320b1585">P19-1028</url>
      <video href="https://vimeo.com/383997156" />
      <doi>10.18653/v1/P19-1028</doi>
      <revision id="1" href="P19-1028v1" hash="c3c70c54" />
      <revision id="2" href="P19-1028v2" hash="320b1585" date="2020-09-01">This revision corrects a typo in Constraint N3 (disjunction -&gt; conjunction) and a typo in its explanation (Y -&gt; Y^\prime). It also includes an additional citation we have added to Arxiv version on Aug 12 2019.</revision>
      <bibkey>li-srikumar-2019-augmenting</bibkey>
      <pwccode url="https://github.com/utahnlp/layer_augmentation" additional="false">utahnlp/layer_augmentation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="29">
      <title>Self-Regulated Interactive Sequence-to-Sequence Learning</title>
      <author><first>Julia</first><last>Kreutzer</last></author>
      <author><first>Stefan</first><last>Riezler</last></author>
      <pages>303&#8211;315</pages>
      <abstract>Not all types of supervision signals are created equal: Different types of feedback have different costs and effects on learning. We show how self-regulation strategies that decide when to ask for which kind of feedback from a teacher (or from oneself) can be cast as a learning-to-learn problem leading to improved cost-aware sequence-to-sequence learning. In experiments on interactive neural machine translation, we find that the self-regulator discovers an <tex-math>\epsilon</tex-math>-greedy strategy for the optimal cost-quality trade-off by mixing different feedback types including corrections, error markups, and self-supervision. Furthermore, we demonstrate its robustness under domain shift and identify it as a promising alternative to active learning.</abstract>
      <url hash="df02bb94">P19-1029</url>
      <video href="https://vimeo.com/383997816" />
      <doi>10.18653/v1/P19-1029</doi>
      <bibkey>kreutzer-riezler-2019-self</bibkey>
      <pwccode url="https://github.com/joeynmt/joeynmt" additional="true">joeynmt/joeynmt</pwccode>
    </paper>
    <paper id="30">
      <title>You Only Need Attention to Traverse Trees</title>
      <author><first>Mahtab</first><last>Ahmed</last></author>
      <author><first>Muhammad Rifayat</first><last>Samee</last></author>
      <author><first>Robert E.</first><last>Mercer</last></author>
      <pages>316&#8211;322</pages>
      <abstract>In recent NLP research, a topic of interest is universal sentence encoding, sentence representations that can be used in any supervised task. At the word sequence level, fully attention-based models suffer from two problems: a quadratic increase in memory consumption with respect to the sentence length and an inability to capture and use syntactic information. Recursive neural nets can extract very good syntactic information by traversing a tree structure. To this end, we propose Tree Transformer, a model that captures phrase level syntax for constituency trees as well as word-level dependencies for dependency trees by doing recursive traversal only with attention. Evaluation of this model on four tasks gets noteworthy results compared to the standard transformer and LSTM-based models as well as tree-structured LSTMs. Ablation studies to find whether positional information is inherently encoded in the trees and which type of attention is suitable for doing the recursive traversal are provided.</abstract>
      <url hash="7d82b714">P19-1030</url>
      <video href="https://vimeo.com/384000960" />
      <doi>10.18653/v1/P19-1030</doi>
      <bibkey>ahmed-etal-2019-need</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="31">
      <title>Cross-Domain Generalization of Neural Constituency Parsers</title>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Nikita</first><last>Kitaev</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>323&#8211;330</pages>
      <abstract>Neural parsers obtain state-of-the-art results on benchmark treebanks for constituency parsing&#8212;but to what degree do they generalize to other domains? We present three results about the generalization of neural parsers in a zero-shot setting: training on trees from one corpus and evaluating on out-of-domain corpora. First, neural and non-neural parsers generalize comparably to new domains. Second, incorporating pre-trained encoder representations into neural parsers substantially improves their performance across all domains, but does not give a larger relative improvement for out-of-domain treebanks. Finally, despite the rich input representations they learn, neural parsers still benefit from structured output prediction of output trees, yielding higher exact match accuracy and stronger generalization both to larger text spans and to out-of-domain corpora. We analyze generalization on English and Chinese corpora, and in the process obtain state-of-the-art parsing results for the Brown, Genia, and English Web treebanks.</abstract>
      <url hash="4f613174">P19-1031</url>
      <video href="https://vimeo.com/385244938" />
      <doi>10.18653/v1/P19-1031</doi>
      <bibkey>fried-etal-2019-cross</bibkey>
      <pwccode url="https://github.com/dpfried/rnng-bert" additional="false">dpfried/rnng-bert</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="32">
      <title>Adaptive Attention Span in Transformers</title>
      <author><first>Sainbayar</first><last>Sukhbaatar</last></author>
      <author><first>Edouard</first><last>Grave</last></author>
      <author><first>Piotr</first><last>Bojanowski</last></author>
      <author><first>Armand</first><last>Joulin</last></author>
      <pages>331&#8211;335</pages>
      <abstract>We propose a novel self-attention mechanism that can learn its optimal attention span. This allows us to extend significantly the maximum context size used in Transformer, while maintaining control over their memory footprint and computational time. We show the effectiveness of our approach on the task of character level language modeling, where we achieve state-of-the-art performances on text8 and enwiki8 by using a maximum context of 8k characters.</abstract>
      <url hash="9856a0e7">P19-1032</url>
      <video href="https://vimeo.com/384007585" />
      <doi>10.18653/v1/P19-1032</doi>
      <bibkey>sukhbaatar-etal-2019-adaptive</bibkey>
      <pwccode url="https://github.com/facebookresearch/adaptive-span" additional="true">facebookresearch/adaptive-span</pwccode>
    </paper>
    <paper id="33">
      <title>Neural News Recommendation with Long- and Short-term User Representations</title>
      <author><first>Mingxiao</first><last>An</last></author>
      <author><first>Fangzhao</first><last>Wu</last></author>
      <author><first>Chuhan</first><last>Wu</last></author>
      <author><first>Kun</first><last>Zhang</last></author>
      <author><first>Zheng</first><last>Liu</last></author>
      <author><first>Xing</first><last>Xie</last></author>
      <pages>336&#8211;345</pages>
      <abstract>Personalized news recommendation is important to help users find their interested news and improve reading experience. A key problem in news recommendation is learning accurate user representations to capture their interests. Users usually have both long-term preferences and short-term interests. However, existing news recommendation methods usually learn single representations of users, which may be insufficient. In this paper, we propose a neural news recommendation approach which can learn both long- and short-term user representations. The core of our approach is a news encoder and a user encoder. In the news encoder, we learn representations of news from their titles and topic categories, and use attention network to select important words. In the user encoder, we propose to learn long-term user representations from the embeddings of their IDs.In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both long- and short-term user representations as a unified user vector. Extensive experiments on a real-world dataset show our approach can effectively improve the performance of neural news recommendation.</abstract>
      <url hash="01dee795">P19-1033</url>
      <doi>10.18653/v1/P19-1033</doi>
      <bibkey>an-etal-2019-neural</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mind">MIND</pwcdataset>
    </paper>
    <paper id="35">
      <title>Manipulating the Difficulty of <fixed-case>C</fixed-case>-Tests</title>
      <author><first>Ji-Ung</first><last>Lee</last></author>
      <author><first>Erik</first><last>Schwan</last></author>
      <author><first>Christian M.</first><last>Meyer</last></author>
      <pages>360&#8211;370</pages>
      <abstract>We propose two novel manipulation strategies for increasing and decreasing the difficulty of C-tests automatically. This is a crucial step towards generating learner-adaptive exercises for self-directed language learning and preparing language assessment tests. To reach the desired difficulty level, we manipulate the size and the distribution of gaps based on absolute and relative gap difficulty predictions. We evaluate our approach in corpus-based experiments and in a user study with 60 participants. We find that both strategies are able to generate C-tests with the desired difficulty level.</abstract>
      <url hash="5c307d90">P19-1035</url>
      <attachment type="supplementary" hash="a86cdf8c">P19-1035.Supplementary.pdf</attachment>
      <attachment type="software" hash="e483b4a1">P19-1035.Software.zip</attachment>
      <doi>10.18653/v1/P19-1035</doi>
      <bibkey>lee-etal-2019-manipulating</bibkey>
      <pwccode url="https://github.com/UKPLab/acl2019-ctest-difficulty-manipulation" additional="false">UKPLab/acl2019-ctest-difficulty-manipulation</pwccode>
    </paper>
    <paper id="41">
      <title>Disentangled Representation Learning for Non-Parallel Text Style Transfer</title>
      <author><first>Vineet</first><last>John</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Hareesh</first><last>Bahuleyan</last></author>
      <author><first>Olga</first><last>Vechtomova</last></author>
      <pages>424&#8211;434</pages>
      <abstract>This paper tackles the problem of disentangling the latent representations of style and content in language models. We propose a simple yet effective approach, which incorporates auxiliary multi-task and adversarial objectives, for style prediction and bag-of-words prediction, respectively. We show, both qualitatively and quantitatively, that the style and content are indeed disentangled in the latent space. This disentangled latent representation learning can be applied to style transfer on non-parallel corpora. We achieve high performance in terms of transfer accuracy, content preservation, and language fluency, in comparison to various previous approaches.</abstract>
      <url hash="806163e4">P19-1041</url>
      <doi>10.18653/v1/P19-1041</doi>
      <bibkey>john-etal-2019-disentangled</bibkey>
      <pwccode url="https://github.com/vineetjohn/linguistic-style-transfer" additional="true">vineetjohn/linguistic-style-transfer</pwccode>
    </paper>
    <paper id="43">
      <title>This Email Could Save Your Life: Introducing the Task of Email Subject Line Generation</title>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <pages>446&#8211;456</pages>
      <abstract>Given the overwhelming number of emails, an effective subject line becomes essential to better inform the recipient of the email&#8217;s content. In this paper, we propose and study the task of <i>email subject line generation</i>: automatically generating an email subject line from the email body. We create the first dataset for this task and find that email subject line generation favor extremely abstractive summary which differentiates it from news headline generation or news single document summarization. We then develop a novel deep learning method and compare it to several baselines as well as recent state-of-the-art text summarization systems. We also investigate the efficacy of several automatic metrics based on correlations with human judgments and propose a new automatic evaluation metric. Our system outperforms competitive baselines given both automatic and human evaluations. To our knowledge, this is the first work to tackle the problem of effective email subject line generation.</abstract>
      <url hash="577c59dd">P19-1043</url>
      <attachment type="supplementary" hash="ef0085a5">P19-1043.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1043</doi>
      <bibkey>zhang-tetreault-2019-email</bibkey>
      <pwccode url="https://github.com/ryanzhumich/AESLC" additional="false">ryanzhumich/AESLC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aeslc">AESLC</pwcdataset>
    </paper>
    <paper id="44">
      <title>Time-Out: Temporal Referencing for Robust Modeling of Lexical Semantic Change</title>
      <author><first>Haim</first><last>Dubossarsky</last></author>
      <author><first>Simon</first><last>Hengchen</last></author>
      <author><first>Nina</first><last>Tahmasebi</last></author>
      <author><first>Dominik</first><last>Schlechtweg</last></author>
      <pages>457&#8211;470</pages>
      <abstract>State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.</abstract>
      <url hash="622af851">P19-1044</url>
      <doi>10.18653/v1/P19-1044</doi>
      <bibkey>dubossarsky-etal-2019-time</bibkey>
      <pwccode url="https://github.com/Garrafao/TemporalReferencing" additional="false">Garrafao/TemporalReferencing</pwccode>
    </paper>
    <paper id="46">
      <title>Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</title>
      <author><first>Sijie</first><last>Mai</last></author>
      <author><first>Haifeng</first><last>Hu</last></author>
      <author><first>Songlong</first><last>Xing</last></author>
      <pages>481&#8211;492</pages>
      <abstract>We propose a general strategy named &#8216;divide, conquer and combine&#8217; for multimodal fusion. Instead of directly fusing features at holistic level, we conduct fusion hierarchically so that both local and global interactions are considered for a comprehensive interpretation of multimodal embeddings. In the &#8216;divide&#8217; and &#8216;conquer&#8217; stages, we conduct local fusion by exploring the interaction of a portion of the aligned feature vectors across various modalities lying within a sliding window, which ensures that each part of multimodal embeddings are explored sufficiently. On its basis, global fusion is conducted in the &#8216;combine&#8217; stage to explore the interconnection across local interactions, via an Attentive Bi-directional Skip-connected LSTM that directly connects distant local interactions and integrates two levels of attention mechanism. In this way, local interactions can exchange information sufficiently and thus obtain an overall view of multimodal information. Our method achieves state-of-the-art performance on multimodal affective computing with higher efficiency.</abstract>
      <url hash="b5cbe6a1">P19-1046</url>
      <doi>10.18653/v1/P19-1046</doi>
      <bibkey>mai-etal-2019-divide</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cmu-mosei">CMU-MOSEI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
    </paper>
    <paper id="50">
      <title><fixed-case>MELD</fixed-case>: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations</title>
      <author><first>Soujanya</first><last>Poria</last></author>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Navonil</first><last>Majumder</last></author>
      <author><first>Gautam</first><last>Naik</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>527&#8211;536</pages>
      <abstract>Emotion recognition in conversations is a challenging task that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at http://affective-meld.github.io.</abstract>
      <url hash="93893a69">P19-1050</url>
      <doi>10.18653/v1/P19-1050</doi>
      <bibkey>poria-etal-2019-meld</bibkey>
      <pwccode url="https://github.com/declare-lab/MELD" additional="true">declare-lab/MELD</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/meld">MELD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/emotionlines">EmotionLines</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/semaine">SEMAINE</pwcdataset>
    </paper>
    <paper id="51">
      <title>Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification</title>
      <author><first>Minghao</first><last>Hu</last></author>
      <author><first>Yuxing</first><last>Peng</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <author><first>Dongsheng</first><last>Li</last></author>
      <author><first>Yiwei</first><last>Lv</last></author>
      <pages>537&#8211;546</pages>
      <abstract>Open-domain targeted sentiment analysis aims to detect opinion targets along with their sentiment polarities from a sentence. Prior work typically formulates this task as a sequence tagging problem. However, such formulation suffers from problems such as huge search space and sentiment inconsistency. To address these problems, we propose a span-based extract-then-classify framework, where multiple opinion targets are directly extracted from the sentence under the supervision of target span boundaries, and corresponding polarities are then classified using their span representations. We further investigate three approaches under this framework, namely the pipeline, joint, and collapsed models. Experiments on three benchmark datasets show that our approach consistently outperforms the sequence tagging baseline. Moreover, we find that the pipeline model achieves the best performance compared with the other two models.</abstract>
      <url hash="1e333a7d">P19-1051</url>
      <doi>10.18653/v1/P19-1051</doi>
      <bibkey>hu-etal-2019-open</bibkey>
      <pwccode url="https://github.com/huminghao16/SpanABSA" additional="false">huminghao16/SpanABSA</pwccode>
    </paper>
    <paper id="53">
      <title>Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis</title>
      <author><first>Jialong</first><last>Tang</last></author>
      <author><first>Ziyao</first><last>Lu</last></author>
      <author><first>Jinsong</first><last>Su</last></author>
      <author><first>Yubin</first><last>Ge</last></author>
      <author><first>Linfeng</first><last>Song</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <author><first>Jiebo</first><last>Luo</last></author>
      <pages>557&#8211;566</pages>
      <abstract>In aspect-level sentiment classification (ASC), it is prevalent to equip dominant neural models with attention mechanisms, for the sake of acquiring the importance of each context word on the given aspect. However, such a mechanism tends to excessively focus on a few frequent words with sentiment polarities, while ignoring infrequent ones. In this paper, we propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training corpus to refine attention mechanisms. Specifically, we iteratively conduct sentiment predictions on all training instances. Particularly, at each iteration, the context word with the maximum attention weight is extracted as the one with active/misleading influence on the correct/incorrect prediction of every instance, and then the word itself is masked for subsequent iterations. Finally, we augment the conventional training objective with a regularization term, which enables ASC models to continue equally focusing on the extracted active context words while decreasing weights of those misleading ones. Experimental results on multiple datasets show that our proposed approach yields better attention mechanisms, leading to substantial improvements over the two state-of-the-art neural ASC models. Source code and trained models are available at https://github.com/DeepLearnXMU/PSSAttention.</abstract>
      <url hash="ff9db42f">P19-1053</url>
      <doi>10.18653/v1/P19-1053</doi>
      <bibkey>tang-etal-2019-progressive</bibkey>
      <pwccode url="https://github.com/DeepLearnXMU/PSSAttention" additional="false">DeepLearnXMU/PSSAttention</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2014-task-4-sub-task-2">SemEval 2014 Task 4 Sub Task 2</pwcdataset>
    </paper>
    <paper id="55">
      <title>Sentiment Tagging with Partial Labels using Modular Architectures</title>
      <author><first>Xiao</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>579&#8211;590</pages>
      <abstract>Many NLP learning tasks can be decomposed into several distinct sub-tasks, each associated with a partial label. In this paper we focus on a popular class of learning problems, sequence prediction applied to several sentiment analysis tasks, and suggest a modular learning approach in which different sub-tasks are learned using separate functional modules, combined to perform the final task while sharing information. Our experiments show this approach helps constrain the learning process and can alleviate some of the supervision efforts.</abstract>
      <url hash="1cd0f3d3">P19-1055</url>
      <attachment type="supplementary" hash="0d45ac66">P19-1055.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1055</doi>
      <bibkey>zhang-goldwasser-2019-sentiment</bibkey>
      <pwccode url="https://github.com/cosmozhang/Modular_Neural_CRF" additional="false">cosmozhang/Modular_Neural_CRF</pwccode>
    </paper>
    <paper id="57">
      <title>A Corpus for Modeling User and Language Effects in Argumentation on Online Debating</title>
      <author><first>Esin</first><last>Durmus</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>602&#8211;607</pages>
      <abstract>Existing argumentation datasets have succeeded in allowing researchers to develop computational methods for analyzing the content, structure and linguistic features of argumentative text. They have been much less successful in fostering studies of the effect of &#8220;user&#8221; traits &#8212; characteristics and beliefs of the participants &#8212; on the debate/argument outcome as this type of user information is generally not available. This paper presents a dataset of 78,376 debates generated over a 10-year period along with surprisingly comprehensive participant profiles. We also complete an example study using the dataset to analyze the effect of selected user traits on the debate outcome in comparison to the linguistic features typically employed in studies of this kind.</abstract>
      <url hash="b04a3bb0">P19-1057</url>
      <doi>10.18653/v1/P19-1057</doi>
      <bibkey>durmus-cardie-2019-corpus</bibkey>
    </paper>
    <paper id="61">
      <title>Data Programming for Learning Discourse Structure</title>
      <author><first>Sonia</first><last>Badene</last></author>
      <author><first>Kate</first><last>Thompson</last></author>
      <author><first>Jean-Pierre</first><last>Lorr&#233;</last></author>
      <author><first>Nicholas</first><last>Asher</last></author>
      <pages>640&#8211;645</pages>
      <abstract>This paper investigates the advantages and limits of data programming for the task of learning discourse structure. The data programming paradigm implemented in the Snorkel framework allows a user to label training data using expert-composed heuristics, which are then transformed via the &#8220;generative step&#8221; into probability distributions of the class labels given the training candidates. These results are later generalized using a discriminative model. Snorkel&#8217;s attractive promise to create a large amount of annotated data from a smaller set of training data by unifying the output of a set of heuristics has yet to be used for computationally difficult tasks, such as that of discourse attachment, in which one must decide where a given discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using Snorkel requires significant modifications to the structure of the heuristics, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem.</abstract>
      <url hash="d972e4b7">P19-1061</url>
      <doi>10.18653/v1/P19-1061</doi>
      <bibkey>badene-etal-2019-data</bibkey>
    </paper>
    <paper id="62">
      <title>Evaluating Discourse in Structured Text Representations</title>
      <author><first>Elisa</first><last>Ferracane</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <author><first>Katrin</first><last>Erk</last></author>
      <pages>646&#8211;653</pages>
      <abstract>Discourse structure is integral to understanding a text and is helpful in many NLP tasks. Learning latent representations of discourse is an attractive alternative to acquiring expensive labeled discourse data. Liu and Lapata (2018) propose a structured attention mechanism for text classification that derives a tree over a text, akin to an RST discourse tree. We examine this model in detail, and evaluate on additional discourse-relevant tasks and datasets, in order to assess whether the structured attention improves performance on the end task and whether it captures a text&#8217;s discourse structure. We find the learned latent trees have little to no structure and instead focus on lexical cues; even after obtaining more structured trees with proposed model modifications, the trees are still far from capturing discourse structure when compared to discourse dependency trees from an existing discourse parser. Finally, ablation studies show the structured attention provides little benefit, sometimes even hurting performance.</abstract>
      <url hash="6f5a237d">P19-1062</url>
      <attachment type="poster" hash="40489732">P19-1062.Poster.pdf</attachment>
      <doi>10.18653/v1/P19-1062</doi>
      <bibkey>ferracane-etal-2019-evaluating</bibkey>
      <pwccode url="https://github.com/elisaF/structured" additional="false">elisaF/structured</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="68">
      <title><fixed-case>MOROCO</fixed-case>: The <fixed-case>M</fixed-case>oldavian and <fixed-case>R</fixed-case>omanian Dialectal Corpus</title>
      <author><first>Andrei</first><last>Butnaru</last></author>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <pages>688&#8211;698</pages>
      <abstract>In this work, we introduce the MOldavian and ROmanian Dialectal COrpus (MOROCO), which is freely available for download at https://github.com/butnaruandrei/MOROCO. The corpus contains 33564 samples of text (with over 10 million tokens) collected from the news domain. The samples belong to one of the following six topics: culture, finance, politics, science, sports and tech. The data set is divided into 21719 samples for training, 5921 samples for validation and another 5924 samples for testing. For each sample, we provide corresponding dialectal and category labels. This allows us to perform empirical studies on several classification tasks such as (i) binary discrimination of Moldavian versus Romanian text samples, (ii) intra-dialect multi-class categorization by topic and (iii) cross-dialect multi-class categorization by topic. We perform experiments using a shallow approach based on string kernels, as well as a novel deep approach based on character-level convolutional neural networks containing Squeeze-and-Excitation blocks. We also present and analyze the most discriminative features of our best performing model, before and after named entity removal.</abstract>
      <url hash="465316ed">P19-1068</url>
      <doi>10.18653/v1/P19-1068</doi>
      <bibkey>butnaru-ionescu-2019-moroco</bibkey>
      <pwccode url="https://github.com/butnaruandrei/MOROCO" additional="false">butnaruandrei/MOROCO</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/moroco">MOROCO</pwcdataset>
    </paper>
    <paper id="69">
      <title>Just &#8220;<fixed-case>O</fixed-case>ne<fixed-case>S</fixed-case>e<fixed-case>C</fixed-case>&#8221; for Producing Multilingual Sense-Annotated Data</title>
      <author><first>Bianca</first><last>Scarlini</last></author>
      <author><first>Tommaso</first><last>Pasini</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>699&#8211;709</pages>
      <abstract>The well-known problem of knowledge acquisition is one of the biggest issues in Word Sense Disambiguation (WSD), where annotated data are still scarce in English and almost absent in other languages. In this paper we formulate the assumption of One Sense per Wikipedia Category and present OneSeC, a language-independent method for the automatic extraction of hundreds of thousands of sentences in which a target word is tagged with its meaning. Our automatically-generated data consistently lead a supervised WSD model to state-of-the-art performance when compared with other automatic and semi-automatic methods. Moreover, our approach outperforms its competitors on multilingual and domain-specific settings, where it beats the existing state of the art on all languages and most domains. All the training data are available for research purposes at http://trainomatic.org/onesec.</abstract>
      <url hash="f2a2d03e">P19-1069</url>
      <doi>10.18653/v1/P19-1069</doi>
      <bibkey>scarlini-etal-2019-just</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/senseval-2-1">Senseval-2</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    <paper id="70">
      <title>How to (Properly) Evaluate Cross-Lingual Word Embeddings: On Strong Baselines, Comparative Analyses, and Some Misconceptions</title>
      <author><first>Goran</first><last>Glava&#353;</last></author>
      <author><first>Robert</first><last>Litschko</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Ivan</first><last>Vuli&#263;</last></author>
      <pages>710&#8211;721</pages>
      <abstract>Cross-lingual word embeddings (CLEs) facilitate cross-lingual transfer of NLP models. Despite their ubiquitous downstream usage, increasingly popular projection-based CLE models are almost exclusively evaluated on bilingual lexicon induction (BLI). Even the BLI evaluations vary greatly, hindering our ability to correctly interpret performance and properties of different CLE models. In this work, we take the first step towards a comprehensive evaluation of CLE models: we thoroughly evaluate both supervised and unsupervised CLE models, for a large number of language pairs, on BLI and three downstream tasks, providing new insights concerning the ability of cutting-edge CLE models to support cross-lingual NLP. We empirically demonstrate that the performance of CLE models largely depends on the task at hand and that optimizing CLE models for BLI may hurt downstream performance. We indicate the most robust supervised and unsupervised CLE models and emphasize the need to reassess simple baselines, which still display competitive performance across the board. We hope our work catalyzes further research on CLE evaluation and model analysis.</abstract>
      <url hash="2f065fe1">P19-1070</url>
      <attachment type="supplementary" hash="e6e1aa5a">P19-1070.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1070</doi>
      <bibkey>glavas-etal-2019-properly</bibkey>
      <pwccode url="https://github.com/codogogo/xling-eval" additional="false">codogogo/xling-eval</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/xnli">XNLI</pwcdataset>
    </paper>
    <paper id="76">
      <title>Automatic Evaluation of Local Topic Quality</title>
      <author><first>Jeffrey</first><last>Lund</last></author>
      <author><first>Piper</first><last>Armstrong</last></author>
      <author><first>Wilson</first><last>Fearn</last></author>
      <author><first>Stephen</first><last>Cowley</last></author>
      <author><first>Courtni</first><last>Byun</last></author>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <author><first>Kevin</first><last>Seppi</last></author>
      <pages>788&#8211;796</pages>
      <abstract>Topic models are typically evaluated with respect to the global topic distributions that they generate, using metrics such as coherence, but without regard to local (token-level) topic assignments. Token-level assignments are important for downstream tasks such as classification. Even recent models, which aim to improve the quality of these token-level topic assignments, have been evaluated only with respect to global metrics. We propose a task designed to elicit human judgments of token-level topic assignments. We use a variety of topic model types and parameters and discover that global metrics agree poorly with human assignments. Since human evaluation is expensive we propose a variety of automated metrics to evaluate topic models at a local level. Finally, we correlate our proposed metrics with human judgments from the task on several datasets. We show that an evaluation based on the percent of topic switches correlates most strongly with human judgment of local topic quality. We suggest that this new metric, which we call consistency, be adopted alongside global metrics such as topic coherence when evaluating new topic models.</abstract>
      <url hash="088cb249">P19-1076</url>
      <doi>10.18653/v1/P19-1076</doi>
      <bibkey>lund-etal-2019-automatic</bibkey>
    </paper>
    <paper id="78">
      <title>Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</title>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Andrea</first><last>Madotto</last></author>
      <author><first>Ehsan</first><last>Hosseini-Asl</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>808&#8211;819</pages>
      <abstract>Over-dependence on domain ontology and lack of sharing knowledge across domains are two practical and yet less studied problems of dialogue state tracking. Existing approaches generally fall short when tracking unknown slot values during inference and often have difficulties in adapting to new domains. In this paper, we propose a Transferable Dialogue State Generator (TRADE) that generates dialogue states from utterances using copy mechanism, facilitating transfer when predicting (domain, slot, value) triplets not encountered during training. Our model is composed of an utterance encoder, a slot gate, and a state generator, which are shared across domains. Empirical results demonstrate that TRADE achieves state-of-the-art 48.62% joint goal accuracy for the five domains of MultiWOZ, a human-human dialogue dataset. In addition, we show the transferring ability by simulating zero-shot and few-shot dialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal accuracy in one of the zero-shot domains, and is able to adapt to few-shot cases without forgetting already trained domains.</abstract>
      <url hash="2afa5639">P19-1078</url>
      <video href="https://vimeo.com/384011409" />
      <award>Outstanding Paper</award>
      <doi>10.18653/v1/P19-1078</doi>
      <bibkey>wu-etal-2019-transferable</bibkey>
      <pwccode url="https://github.com/jasonwu0731/trade-dst" additional="true">jasonwu0731/trade-dst</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multiwoz">MultiWOZ</pwcdataset>
    </paper>
    <paper id="79">
      <title>Multi-Task Networks with Universe, Group, and Task Feature Learning</title>
      <author><first>Shiva</first><last>Pentyala</last></author>
      <author><first>Mengwen</first><last>Liu</last></author>
      <author><first>Markus</first><last>Dreyer</last></author>
      <pages>820&#8211;830</pages>
      <abstract>We present methods for multi-task learning that take advantage of natural groupings of related tasks. Task groups may be defined along known properties of the tasks, such as task domain or language. Such task groups represent supervised information at the inter-task level and can be encoded into the model. We investigate two variants of neural network architectures that accomplish this, learning different feature spaces at the levels of individual tasks, task groups, as well as the universe of all tasks: (1) parallel architectures encode each input simultaneously into feature spaces at different levels; (2) serial architectures encode each input successively into feature spaces at different levels in the task hierarchy. We demonstrate the methods on natural language understanding (NLU) tasks, where a grouping of tasks into different task domains leads to improved performance on ATIS, Snips, and a large in-house dataset.</abstract>
      <url hash="1fa3f7e4">P19-1079</url>
      <video href="https://vimeo.com/384538335" />
      <doi>10.18653/v1/P19-1079</doi>
      <bibkey>pentyala-etal-2019-multi</bibkey>
    </paper>
    <paper id="84">
      <title>Don&#8217;t Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference</title>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <author><first>Adam</first><last>Poliak</last></author>
      <author><first>Stuart</first><last>Shieber</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>877&#8211;891</pages>
      <abstract>Natural Language Inference (NLI) datasets often contain hypothesis-only biases&#8212;artifacts that allow models to achieve non-trivial performance without learning whether a premise entails a hypothesis. We propose two probabilistic methods to build models that are more robust to such biases and better transfer across datasets. In contrast to standard approaches to NLI, our methods predict the probability of a premise given a hypothesis and NLI label, discouraging models from ignoring the premise. We evaluate our methods on synthetic and existing NLI datasets by training on datasets containing biases and testing on datasets containing no (or different) hypothesis-only biases. Our results indicate that these methods can make NLI models more robust to dataset-specific artifacts, transferring better than a baseline architecture in 9 out of 12 NLI datasets. Additionally, we provide an extensive analysis of the interplay of our methods with known biases in NLI datasets, as well as the effects of encouraging models to ignore biases and fine-tuning on target datasets.</abstract>
      <url hash="c793a21f">P19-1084</url>
      <attachment type="presentation" hash="fdceea00">P19-1084.Presentation.pdf</attachment>
      <video href="https://vimeo.com/384034160" />
      <doi>10.18653/v1/P19-1084</doi>
      <bibkey>belinkov-etal-2019-dont</bibkey>
      <pwccode url="https://github.com/azpoliak/robust-nli" additional="false">azpoliak/robust-nli</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="88">
      <title>What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations</title>
      <author><first>Ver&#243;nica</first><last>P&#233;rez-Rosas</last></author>
      <author><first>Xinyi</first><last>Wu</last></author>
      <author><first>Kenneth</first><last>Resnicow</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>926&#8211;935</pages>
      <abstract>The quality of a counseling intervention relies highly on the active collaboration between clients and counselors. In this paper, we explore several linguistic aspects of the collaboration process occurring during counseling conversations. Specifically, we address the differences between high-quality and low-quality counseling. Our approach examines participants&#8217; turn-by-turn interaction, their linguistic alignment, the sentiment expressed by speakers during the conversation, as well as the different topics being discussed. Our results suggest important language differences in low- and high-quality counseling, which we further use to derive linguistic features able to capture the differences between the two groups. These features are then used to build automatic classifiers that can predict counseling quality with accuracies of up to 88%.</abstract>
      <url hash="74a2fb41">P19-1088</url>
      <video href="https://vimeo.com/384465038" />
      <doi>10.18653/v1/P19-1088</doi>
      <bibkey>perez-rosas-etal-2019-makes</bibkey>
    </paper>
    <paper id="89">
      <title>Finding Your Voice: The Linguistic Development of Mental Health Counselors</title>
      <author><first>Justine</first><last>Zhang</last></author>
      <author><first>Robert</first><last>Filbin</last></author>
      <author><first>Christine</first><last>Morrison</last></author>
      <author><first>Jaclyn</first><last>Weiser</last></author>
      <author><first>Cristian</first><last>Danescu-Niculescu-Mizil</last></author>
      <pages>936&#8211;947</pages>
      <abstract>Mental health counseling is an enterprise with profound societal importance where conversations play a primary role. In order to acquire the conversational skills needed to face a challenging range of situations, mental health counselors must rely on training and on continued experience with actual clients. However, in the absence of large scale longitudinal studies, the nature and significance of this developmental process remain unclear. For example, prior literature suggests that experience might not translate into consequential changes in counselor behavior. This has led some to even argue that counseling is a profession without expertise. In this work, we develop a computational framework to quantify the extent to which individuals change their linguistic behavior with experience and to study the nature of this evolution. We use our framework to conduct a large longitudinal study of mental health counseling conversations, tracking over 3,400 counselors across their tenure. We reveal that overall, counselors do indeed change their conversational behavior to become more diverse across interactions, developing an individual voice that distinguishes them from other counselors. Furthermore, a finer-grained investigation shows that the rate and nature of this diversification vary across functionally different conversational components.</abstract>
      <url hash="8bd90cea">P19-1089</url>
      <video href="https://vimeo.com/384467269" />
      <doi>10.18653/v1/P19-1089</doi>
      <bibkey>zhang-etal-2019-finding</bibkey>
    </paper>
    <paper id="93">
      <title>Are You Convinced? Choosing the More Convincing Evidence with a <fixed-case>S</fixed-case>iamese Network</title>
      <author><first>Martin</first><last>Gleize</last></author>
      <author><first>Eyal</first><last>Shnarch</last></author>
      <author><first>Leshem</first><last>Choshen</last></author>
      <author><first>Lena</first><last>Dankin</last></author>
      <author><first>Guy</first><last>Moshkowich</last></author>
      <author><first>Ranit</first><last>Aharonov</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>967&#8211;976</pages>
      <abstract>With the advancement in argument detection, we suggest to pay more attention to the challenging task of identifying the more convincing arguments. Machines capable of responding and interacting with humans in helpful ways have become ubiquitous. We now expect them to discuss with us the more delicate questions in our world, and they should do so armed with effective arguments. But what makes an argument more persuasive? What will convince you? In this paper, we present a new data set, IBM-EviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives. We also propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own. Finally, we provide insights into our experimental results and the various kinds of argumentative value our method is capable of detecting.</abstract>
      <url hash="9c94ae1e">P19-1093</url>
      <video href="https://vimeo.com/384469154" />
      <doi>10.18653/v1/P19-1093</doi>
      <bibkey>gleize-etal-2019-convinced</bibkey>
    </paper>
    <paper id="94">
      <title>From Surrogacy to Adoption; From Bitcoin to Cryptocurrency: Debate Topic Expansion</title>
      <author><first>Roy</first><last>Bar-Haim</last></author>
      <author><first>Dalia</first><last>Krieger</last></author>
      <author><first>Orith</first><last>Toledo-Ronen</last></author>
      <author><first>Lilach</first><last>Edelstein</last></author>
      <author><first>Yonatan</first><last>Bilu</last></author>
      <author><first>Alon</first><last>Halfon</last></author>
      <author><first>Yoav</first><last>Katz</last></author>
      <author><first>Amir</first><last>Menczel</last></author>
      <author><first>Ranit</first><last>Aharonov</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>977&#8211;990</pages>
      <abstract>When debating a controversial topic, it is often desirable to expand the boundaries of discussion. For example, we may consider the pros and cons of possible alternatives to the debate topic, make generalizations, or give specific examples. We introduce the task of Debate Topic Expansion - finding such related topics for a given debate topic, along with a novel annotated dataset for the task. We focus on relations between Wikipedia concepts, and show that they differ from well-studied lexical-semantic relations such as hypernyms, hyponyms and antonyms. We present algorithms for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically. We suggest that debate topic expansion may have various use cases in argumentation mining.</abstract>
      <url hash="83f6a24e">P19-1094</url>
      <video href="https://vimeo.com/384469239" />
      <doi>10.18653/v1/P19-1094</doi>
      <bibkey>bar-haim-etal-2019-surrogacy</bibkey>
    </paper>
    <paper id="96">
      <title>Emotion-Cause Pair Extraction: A New Task to Emotion Analysis in Texts</title>
      <author><first>Rui</first><last>Xia</last></author>
      <author><first>Zixiang</first><last>Ding</last></author>
      <pages>1003&#8211;1012</pages>
      <abstract>Emotion cause extraction (ECE), the task aimed at extracting the potential causes behind certain emotions in text, has gained much attention in recent years due to its wide applications. However, it suffers from two shortcomings: 1) the emotion must be annotated before cause extraction in ECE, which greatly limits its applications in real-world scenarios; 2) the way to first annotate emotion and then extract the cause ignores the fact that they are mutually indicative. In this work, we propose a new task: emotion-cause pair extraction (ECPE), which aims to extract the potential pairs of emotions and corresponding causes in a document. We propose a 2-step approach to address this new ECPE task, which first performs individual emotion extraction and cause extraction via multi-task learning, and then conduct emotion-cause pairing and filtering. The experimental results on a benchmark emotion cause corpus prove the feasibility of the ECPE task as well as the effectiveness of our approach.</abstract>
      <url hash="85e96057">P19-1096</url>
      <video href="https://vimeo.com/385493617" permission="false" />
      <award>Outstanding Paper</award>
      <doi>10.18653/v1/P19-1096</doi>
      <bibkey>xia-ding-2019-emotion</bibkey>
      <pwccode url="https://github.com/NUSTM/ECPE" additional="true">NUSTM/ECPE</pwccode>
    </paper>
    <paper id="99">
      <title>Global Optimization under Length Constraint for Neural Text Summarization</title>
      <author><first>Takuya</first><last>Makino</last></author>
      <author><first>Tomoya</first><last>Iwakura</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>1039&#8211;1048</pages>
      <abstract>We propose a global optimization method under length constraint (GOLC) for neural text summarization models. GOLC increases the probabilities of generating summaries that have high evaluation scores, ROUGE in this paper, within a desired length. We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers. The experimental results show that a state-of-the-art neural summarization model optimized with GOLC generates fewer overlength summaries while maintaining the fastest processing speed; only 6.70% overlength summaries on CNN/Daily and 7.8% on long summary of Mainichi, compared to the approximately 20% to 50% on CNN/Daily Mail and 10% to 30% on Mainichi with the other optimization methods. We also demonstrate the importance of the generation of in-length summaries for post-editing with the dataset Mainich that is created with strict length constraints. The ex- perimental results show approximately 30% to 40% improved post-editing time by use of in-length summaries.</abstract>
      <url hash="a3f5df62">P19-1099</url>
      <video href="https://vimeo.com/384475549" />
      <doi>10.18653/v1/P19-1099</doi>
      <bibkey>makino-etal-2019-global</bibkey>
    </paper>
    <paper id="102">
      <title>Multi-News: A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model</title>
      <author><first>Alexander</first><last>Fabbri</last></author>
      <author><first>Irene</first><last>Li</last></author>
      <author><first>Tianwei</first><last>She</last></author>
      <author><first>Suyi</first><last>Li</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>1074&#8211;1084</pages>
      <abstract>Automatic generation of summaries from multiple news articles is a valuable tool as the number of online publications grows rapidly. Single document summarization (SDS) systems have benefited from advances in neural encoder-decoder model thanks to the availability of large datasets. However, multi-document summarization (MDS) of news articles has been limited to datasets of a couple of hundred examples. In this paper, we introduce Multi-News, the first large-scale MDS news dataset. Additionally, we propose an end-to-end model which incorporates a traditional extractive summarization model with a standard SDS model and achieves competitive results on MDS datasets. We benchmark several methods on Multi-News and hope that this work will promote advances in summarization in the multi-document setting.</abstract>
      <url hash="84c79d84">P19-1102</url>
      <video href="https://vimeo.com/384478403" />
      <doi>10.18653/v1/P19-1102</doi>
      <attachment type="presentation" hash="46320095">P19-1102.Presentation.pdf</attachment>
      <bibkey>fabbri-etal-2019-multi</bibkey>
      <pwccode url="https://github.com/Alex-Fabbri/Multi-News" additional="true">Alex-Fabbri/Multi-News</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multi-news">Multi-News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsroom">NEWSROOM</pwcdataset>
    </paper>
    <paper id="103">
      <title>Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency</title>
      <author><first>Shuhuai</first><last>Ren</last></author>
      <author><first>Yihe</first><last>Deng</last></author>
      <author><first>Kun</first><last>He</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <pages>1085&#8211;1097</pages>
      <abstract>We address the problem of adversarial attacks on text classification, which is rarely studied comparing to attacks on image classification. The challenge of this task is to generate adversarial examples that maintain lexical correctness, grammatical correctness and semantic similarity. Based on the synonyms substitution strategy, we introduce a new word replacement order determined by both the word saliency and the classification probability, and propose a greedy algorithm called probability weighted word saliency (PWWS) for text adversarial attack. Experiments on three popular datasets using convolutional as well as LSTM models show that PWWS reduces the classification accuracy to the most extent, and keeps a very low word substitution rate. A human evaluation study shows that our generated adversarial examples maintain the semantic similarity well and are hard for humans to perceive. Performing adversarial training using our perturbed datasets improves the robustness of the models. At last, our method also exhibits a good transferability on the generated adversarial examples.</abstract>
      <url hash="4dfce917">P19-1103</url>
      <video href="https://vimeo.com/384478489" />
      <doi>10.18653/v1/P19-1103</doi>
      <bibkey>ren-etal-2019-generating</bibkey>
      <pwccode url="https://github.com/JHL-HUST/PWWS" additional="false">JHL-HUST/PWWS</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="104">
      <title>Heuristic Authorship Obfuscation</title>
      <author><first>Janek</first><last>Bevendorff</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <author><first>Matthias</first><last>Hagen</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>1098&#8211;1108</pages>
      <abstract>Authorship verification is the task of determining whether two texts were written by the same author. We deal with the adversary task, called authorship obfuscation: preventing verification by altering a to-be-obfuscated text. Our new obfuscation approach (1) models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts, and (2) manipulates an author&#8217;s subconsciously encoded writing style in a sophisticated manner using heuristic search. To obfuscate, we analyze the huge space of textual variants for a paraphrased version of the to-be-obfuscated text that has a sufficient Jensen-Shannon distance at minimal costs in terms of text quality. We analyze, quantify, and illustrate the rationale of this approach, define paraphrasing operators, derive obfuscation thresholds, and develop an effective obfuscation framework. Our authorship obfuscation approach defeats state-of-the-art verification approaches, including unmasking and compression models, while keeping text changes at a minimum.</abstract>
      <url hash="1b7eb74d">P19-1104</url>
      <video href="https://vimeo.com/384478577" />
      <doi>10.18653/v1/P19-1104</doi>
      <bibkey>bevendorff-etal-2019-heuristic</bibkey>
      <pwccode url="https://github.com/webis-de/acl-19" additional="false">webis-de/acl-19</pwccode>
    </paper>
    <paper id="108">
      <title>Figurative Usage Detection of Symptom Words to Improve Personal Health Mention Detection</title>
      <author><first>Adith</first><last>Iyer</last></author>
      <author><first>Aditya</first><last>Joshi</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Ross</first><last>Sparks</last></author>
      <author><first>Cecile</first><last>Paris</last></author>
      <pages>1142&#8211;1147</pages>
      <abstract>Personal health mention detection deals with predicting whether or not a given sentence is a report of a health condition. Past work mentions errors in this prediction when symptom words, i.e., names of symptoms of interest, are used in a figurative sense. Therefore, we combine a state-of-the-art figurative usage detection with CNN-based personal health mention detection. To do so, we present two methods: a pipeline-based approach and a feature augmentation-based approach. The introduction of figurative usage detection results in an average improvement of 2.21% F-score of personal health mention detection, in the case of the feature augmentation-based approach. This paper demonstrates the promise of using figurative usage detection to improve personal health mention detection.</abstract>
      <url hash="cccd70e9">P19-1108</url>
      <doi>10.18653/v1/P19-1108</doi>
      <bibkey>iyer-etal-2019-figurative</bibkey>
    </paper>
    <paper id="110">
      <title>Neural News Recommendation with Topic-Aware News Representation</title>
      <author><first>Chuhan</first><last>Wu</last></author>
      <author><first>Fangzhao</first><last>Wu</last></author>
      <author><first>Mingxiao</first><last>An</last></author>
      <author><first>Yongfeng</first><last>Huang</last></author>
      <author><first>Xing</first><last>Xie</last></author>
      <pages>1154&#8211;1159</pages>
      <abstract>News recommendation can help users find interested news and alleviate information overload. The topic information of news is critical for learning accurate news and user representations for news recommendation. However, it is not considered in many existing news recommendation methods. In this paper, we propose a neural news recommendation approach with topic-aware news representations. The core of our approach is a topic-aware news encoder and a user encoder. In the news encoder we learn representations of news from their titles via CNN networks and apply attention networks to select important words. In addition, we propose to learn topic-aware news representations by jointly training the news encoder with an auxiliary topic classification task. In the user encoder we learn the representations of users from their browsed news and use attention networks to select informative news for user representation learning. Extensive experiments on a real-world dataset validate the effectiveness of our approach.</abstract>
      <url hash="45212a85">P19-1110</url>
      <doi>10.18653/v1/P19-1110</doi>
      <bibkey>wu-etal-2019-neural-news-recommendation</bibkey>
    </paper>
    <paper id="115">
      <title>Self-Attentional Models for Lattice Inputs</title>
      <author><first>Matthias</first><last>Sperber</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Ngoc-Quan</first><last>Pham</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <pages>1185&#8211;1197</pages>
      <abstract>Lattices are an efficient and effective method to encode ambiguity of upstream systems in natural language processing tasks, for example to compactly capture multiple speech recognition hypotheses, or to represent multiple linguistic analyses. Previous work has extended recurrent neural networks to model lattice inputs and achieved improvements in various tasks, but these models suffer from very slow computation speeds. This paper extends the recently proposed paradigm of self-attention to handle lattice inputs. Self-attention is a sequence modeling technique that relates inputs to one another by computing pairwise similarities and has gained popularity for both its strong results and its computational efficiency. To extend such models to handle lattices, we introduce probabilistic reachability masks that incorporate lattice structure into the model and support lattice scores if available. We also propose a method for adapting positional embeddings to lattice structures. We apply the proposed model to a speech translation task and find that it outperforms all examined baselines while being much faster to compute than previous neural lattice models during both training and inference.</abstract>
      <url hash="bbe7ede5">P19-1115</url>
      <doi>10.18653/v1/P19-1115</doi>
      <bibkey>sperber-etal-2019-self</bibkey>
    </paper>
    <paper id="117">
      <title>A Compact and Language-Sensitive Multilingual Translation Method</title>
      <author><first>Yining</first><last>Wang</last></author>
      <author><first>Long</first><last>Zhou</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Feifei</first><last>Zhai</last></author>
      <author><first>Jingfang</first><last>Xu</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>1213&#8211;1223</pages>
      <abstract>Multilingual neural machine translation (Multi-NMT) with one encoder-decoder model has made remarkable progress due to its simple deployment. However, this multilingual translation paradigm does not make full use of language commonality and parameter sharing between encoder and decoder. Furthermore, this kind of paradigm cannot outperform the individual models trained on bilingual corpus in most cases. In this paper, we propose a compact and language-sensitive method for multilingual translation. To maximize parameter sharing, we first present a universal representor to replace both encoder and decoder models. To make the representor sensitive for specific languages, we further introduce language-sensitive embedding, attention, and discriminator with the ability to enhance model performance. We verify our methods on various translation scenarios, including one-to-many, many-to-many and zero-shot. Extensive experiments demonstrate that our proposed methods remarkably outperform strong standard multilingual translation systems on WMT and IWSLT datasets. Moreover, we find that our model is especially helpful in low-resource and zero-shot translation scenarios.</abstract>
      <url hash="925ed253">P19-1117</url>
      <doi>10.18653/v1/P19-1117</doi>
      <bibkey>wang-etal-2019-compact</bibkey>
    </paper>
    <paper id="119">
      <title>Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation</title>
      <author><first>Haipeng</first><last>Sun</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>1235&#8211;1245</pages>
      <abstract>Unsupervised bilingual word embedding (UBWE), together with other technologies such as back-translation and denoising, has helped unsupervised neural machine translation (UNMT) achieve remarkable results in several language pairs. In previous methods, UBWE is first trained using non-parallel monolingual corpora and then this pre-trained UBWE is used to initialize the word embedding in the encoder and decoder of UNMT. That is, the training of UBWE and UNMT are separate. In this paper, we first empirically investigate the relationship between UBWE and UNMT. The empirical findings show that the performance of UNMT is significantly affected by the performance of UBWE. Thus, we propose two methods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT.</abstract>
      <url hash="987381b0">P19-1119</url>
      <doi>10.18653/v1/P19-1119</doi>
      <bibkey>sun-etal-2019-unsupervised</bibkey>
    </paper>
    <paper id="120">
      <title>Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies</title>
      <author><first>Yunsu</first><last>Kim</last></author>
      <author><first>Yingbo</first><last>Gao</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <pages>1246&#8211;1257</pages>
      <abstract>Transfer learning or multilingual model is essential for low-resource neural machine translation (NMT), but the applicability is limited to cognate languages by sharing their vocabularies. This paper shows effective techniques to transfer a pretrained NMT model to a new, unrelated language without shared vocabularies. We relieve the vocabulary mismatch by using cross-lingual word embedding, train a more language-agnostic encoder by injecting artificial noises, and generate synthetic data easily from the pretraining data without back-translation. Our methods do not require restructuring the vocabulary or retraining the model. We improve plain NMT transfer by up to +5.1% BLEU in five low-resource translation tasks, outperforming multilingual joint training by a large margin. We also provide extensive ablation studies on pretrained embedding, synthetic data, vocabulary size, and parameter freezing for a better understanding of NMT transfer.</abstract>
      <url hash="b25ea728">P19-1120</url>
      <doi>10.18653/v1/P19-1120</doi>
      <bibkey>kim-etal-2019-effective</bibkey>
      <pwccode url="https://github.com/yunsukim86/sockeye-transfer" additional="false">yunsukim86/sockeye-transfer</pwccode>
    </paper>
    <paper id="121">
      <title>Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations</title>
      <author><first>Jiatao</first><last>Gu</last></author>
      <author><first>Yong</first><last>Wang</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Victor O.K.</first><last>Li</last></author>
      <pages>1258&#8211;1268</pages>
      <abstract>Zero-shot translation, translating between language pairs on which a Neural Machine Translation (NMT) system has never been trained, is an emergent property when training the system in multilingual settings. However, naive training for zero-shot NMT easily fails, and is sensitive to hyper-parameter setting. The performance typically lags far behind the more conventional pivot-based approach which translates twice using a third language as a pivot. In this work, we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the mutual information between language IDs of the source and decoded sentences. Inspired by this analysis, we propose to use two simple but effective approaches: (1) decoder pre-training; (2) back-translation. These methods show significant improvement (4 22 BLEU points) over the vanilla zero-shot translation on three challenging multilingual datasets, and achieve similar or better results than the pivot-based approach.</abstract>
      <url hash="4adbf392">P19-1121</url>
      <doi>10.18653/v1/P19-1121</doi>
      <bibkey>gu-etal-2019-improved</bibkey>
    </paper>
    <paper id="122">
      <title>Syntactically Supervised Transformers for Faster Neural Machine Translation</title>
      <author><first>Nader</first><last>Akoury</last></author>
      <author><first>Kalpesh</first><last>Krishna</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>1269&#8211;1281</pages>
      <abstract>Standard decoders for neural machine translation autoregressively generate a single target token per timestep, which slows inference especially for long outputs. While architectural advances such as the Transformer fully parallelize the decoder computations at training time, inference still proceeds sequentially. Recent developments in non- and semi-autoregressive decoding produce multiple tokens per timestep independently of the others, which improves inference speed but deteriorates translation quality. In this work, we propose the syntactically supervised Transformer (SynST), which first autoregressively predicts a chunked parse tree before generating all of the target tokens in one shot conditioned on the predicted parse. A series of controlled experiments demonstrates that SynST decodes sentences ~5x faster than the baseline autoregressive Transformer while achieving higher BLEU scores than most competing methods on En-De and En-Fr datasets.</abstract>
      <url hash="cbd6ea34">P19-1122</url>
      <attachment type="poster" hash="8221d008">P19-1122.Poster.pdf</attachment>
      <doi>10.18653/v1/P19-1122</doi>
      <bibkey>akoury-etal-2019-syntactically</bibkey>
      <pwccode url="https://github.com/dojoteef/synst" additional="false">dojoteef/synst</pwccode>
    </paper>
    <paper id="123">
      <title>Dynamically Composing Domain-Data Selection with Clean-Data Selection by &#8220;Co-Curricular Learning&#8221; for Neural Machine Translation</title>
      <author><first>Wei</first><last>Wang</last></author>
      <author><first>Isaac</first><last>Caswell</last></author>
      <author><first>Ciprian</first><last>Chelba</last></author>
      <pages>1282&#8211;1292</pages>
      <abstract>Noise and domain are important aspects of data quality for neural machine translation. Existing research focus separately on domain-data selection, clean-data selection, or their static combination, leaving the dynamic interaction across them not explicitly examined. This paper introduces a &#8220;co-curricular learning&#8221; method to compose dynamic domain-data selection with dynamic clean-data selection, for transfer learning across both capabilities. We apply an EM-style optimization procedure to further refine the &#8220;co-curriculum&#8221;. Experiment results and analysis with two domains demonstrate the effectiveness of the method and the properties of data scheduled by the co-curriculum.</abstract>
      <url hash="1c4b28eb">P19-1123</url>
      <doi>10.18653/v1/P19-1123</doi>
      <bibkey>wang-etal-2019-dynamically</bibkey>
    </paper>
    <paper id="125">
      <title>Imitation Learning for Non-Autoregressive Neural Machine Translation</title>
      <author><first>Bingzhen</first><last>Wei</last></author>
      <author><first>Mingxuan</first><last>Wang</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Junyang</first><last>Lin</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>1304&#8211;1312</pages>
      <abstract>Non-autoregressive translation models (NAT) have achieved impressive inference speedup. A potential issue of the existing NAT algorithms, however, is that the decoding is conducted in parallel, without directly considering previous context. In this paper, we propose an imitation learning framework for non-autoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart. We conduct experiments on the IWSLT16, WMT14 and WMT16 datasets. Our proposed model achieves a significant speedup over the autoregressive models, while keeping the translation quality comparable to the autoregressive models. By sampling sentence length in parallel at inference time, we achieve the performance of 31.85 BLEU on WMT16 Ro<tex-math>\rightarrow</tex-math>En and 30.68 BLEU on IWSLT16 En<tex-math>\rightarrow</tex-math>De.</abstract>
      <url hash="048e454f">P19-1125</url>
      <doi>10.18653/v1/P19-1125</doi>
      <bibkey>wei-etal-2019-imitation</bibkey>
    </paper>
    <paper id="126">
      <title>Monotonic Infinite Lookback Attention for Simultaneous Machine Translation</title>
      <author><first>Naveen</first><last>Arivazhagan</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>Wolfgang</first><last>Macherey</last></author>
      <author><first>Chung-Cheng</first><last>Chiu</last></author>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Ruoming</first><last>Pang</last></author>
      <author><first>Wei</first><last>Li</last></author>
      <author><first>Colin</first><last>Raffel</last></author>
      <pages>1313&#8211;1323</pages>
      <abstract>Simultaneous machine translation begins to translate each source sentence before the source speaker is finished speaking, with applications to live and streaming scenarios. Simultaneous systems must carefully schedule their reading of the source sentence to balance quality against latency. We present the first simultaneous translation system to learn an adaptive schedule jointly with a neural machine translation (NMT) model that attends over all source tokens read thus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention, which maintains both a hard, monotonic attention head to schedule the reading of the source sentence, and a soft attention head that extends from the monotonic head back to the beginning of the source. We show that MILk&#8217;s adaptive schedule allows it to arrive at latency-quality trade-offs that are favorable to those of a recently proposed wait-k strategy for many latency values.</abstract>
      <url hash="7ad7a0ec">P19-1126</url>
      <attachment type="supplementary" hash="75895a49">P19-1126.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1126</doi>
      <bibkey>arivazhagan-etal-2019-monotonic</bibkey>
    </paper>
    <paper id="130">
      <title>Exploiting Entity <fixed-case>BIO</fixed-case> Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data</title>
      <author><first>Wei</first><last>Ye</last></author>
      <author id="bo-li"><first>Bo</first><last>Li</last></author>
      <author><first>Rui</first><last>Xie</last></author>
      <author><first>Zhonghao</first><last>Sheng</last></author>
      <author><first>Long</first><last>Chen</last></author>
      <author><first>Shikun</first><last>Zhang</last></author>
      <pages>1351&#8211;1360</pages>
      <abstract>In practical scenario, relation extraction needs to first identify entity pairs that have relation and then assign a correct relation class. However, the number of non-relation entity pairs in context (negative instances) usually far exceeds the others (positive instances), which negatively affects a model&#8217;s performance. To mitigate this problem, we propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification with ranking loss. Meanwhile, we observe that a sentence may have multiple entities and relation mentions, and the patterns in which the entities appear in a sentence may contain useful semantic information that can be utilized to distinguish between positive and negative instances. Thus we further incorporate the embeddings of character-wise/word-wise BIO tag from the named entity recognition task into character/word embeddings to enrich the input representation. Experiment results show that our proposed approach can significantly improve the performance of a baseline model with more than 10% absolute increase in F1-score, and outperform the state-of-the-art models on ACE 2005 Chinese and English corpus. Moreover, BIO tag embeddings are particularly effective and can be used to improve other models as well.</abstract>
      <url hash="26d2f5ba">P19-1130</url>
      <doi>10.18653/v1/P19-1130</doi>
      <bibkey>ye-etal-2019-exploiting</bibkey>
    </paper>
    <paper id="132">
      <title>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</title>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Ming</first><last>Tan</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Dakuo</first><last>Wang</last></author>
      <author><first>Kun</first><last>Xu</last></author>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>Saloni</first><last>Potdar</last></author>
      <pages>1371&#8211;1377</pages>
      <abstract>Many approaches to extract multiple relations from a paragraph require multiple passes over the paragraph. In practice, multiple passes are computationally expensive and this makes difficult to scale to longer paragraphs and larger text corpora. In this work, we focus on the task of multiple relation extractions by encoding the paragraph only once. We build our solution upon the pre-trained self-attentive models (Transformer), where we first add a structured prediction layer to handle extraction between multiple entity pairs, then enhance the paragraph embedding to capture multiple relational information associated with each entity with entity-aware attention. We show that our approach is not only scalable but can also perform state-of-the-art on the standard benchmark ACE 2005.</abstract>
      <url hash="3558fb9c">P19-1132</url>
      <doi>10.18653/v1/P19-1132</doi>
      <bibkey>wang-etal-2019-extracting</bibkey>
      <pwccode url="https://github.com/helloeve/mre-in-one-pass" additional="false">helloeve/mre-in-one-pass</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="134">
      <title>Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction</title>
      <author><first>Christoph</first><last>Alt</last></author>
      <author><first>Marc</first><last>H&#252;bner</last></author>
      <author><first>Leonhard</first><last>Hennig</last></author>
      <pages>1388&#8211;1398</pages>
      <abstract>Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these models to be biased towards recognizing a limited set of relations with high precision, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) (Radford et al., 2018). The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of &#8220;common-sense&#8221; knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our model shows that it achieves a state-of-the-art AUC score of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels.</abstract>
      <url hash="7a63dbbe">P19-1134</url>
      <doi>10.18653/v1/P19-1134</doi>
      <bibkey>alt-etal-2019-fine</bibkey>
      <pwccode url="https://github.com/DFKI-NLP/DISTRE" additional="false">DFKI-NLP/DISTRE</pwccode>
    </paper>
    <paper id="135">
      <title><fixed-case>ARNOR</fixed-case>: Attention Regularization based Noise Reduction for Distant Supervision Relation Classification</title>
      <author><first>Wei</first><last>Jia</last></author>
      <author><first>Dai</first><last>Dai</last></author>
      <author><first>Xinyan</first><last>Xiao</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <pages>1399&#8211;1408</pages>
      <abstract>Distant supervision is widely used in relation classification in order to create large-scale training data by aligning a knowledge base with an unlabeled corpus. However, it also introduces amounts of noisy labels where a contextual sentence actually does not express the labeled relation. In this paper, we propose ARNOR, a novel Attention Regularization based NOise Reduction framework for distant supervision relation classification. ARNOR assumes that a trustable relation label should be explained by the neural attention model. Specifically, our ARNOR framework iteratively learns an interpretable model and utilizes it to select trustable instances. We first introduce attention regularization to force the model to pay attention to the patterns which explain the relation labels, so as to make the model more interpretable. Then, if the learned model can clearly locate the relation patterns of a candidate instance in the training set, we will select it as a trustable instance for further training step. According to the experiments on NYT data, our ARNOR framework achieves significant improvements over state-of-the-art methods in both relation classification performance and noise reduction effect.</abstract>
      <url hash="8937d844">P19-1135</url>
      <doi>10.18653/v1/P19-1135</doi>
      <bibkey>jia-etal-2019-arnor</bibkey>
    </paper>
    <paper id="136">
      <title><fixed-case>G</fixed-case>raph<fixed-case>R</fixed-case>el: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction</title>
      <author><first>Tsu-Jui</first><last>Fu</last></author>
      <author><first>Peng-Hsuan</first><last>Li</last></author>
      <author><first>Wei-Yun</first><last>Ma</last></author>
      <pages>1409&#8211;1418</pages>
      <abstract>In this paper, we present GraphRel, an end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations. In contrast to previous baselines, we consider the interaction between named entities and relations via a 2nd-phase relation-weighted GCN to better extract relations. Linear and dependency structures are both used to extract both sequential and regional features of the text, and a complete word graph is further utilized to extract implicit features among all word pairs of the text. With the graph-based approach, the prediction for overlapping relations is substantially improved over previous sequential approaches. We evaluate GraphRel on two public datasets: NYT and WebNLG. Results show that GraphRel maintains high precision while increasing recall substantially. Also, GraphRel outperforms previous work by 3.2% and 5.8% (F1 score), achieving a new state-of-the-art for relation extraction.</abstract>
      <url hash="beabe36d">P19-1136</url>
      <doi>10.18653/v1/P19-1136</doi>
      <bibkey>fu-etal-2019-graphrel</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/webnlg">WebNLG</pwcdataset>
    </paper>
    <paper id="137">
      <title><fixed-case>DIAG</fixed-case>-<fixed-case>NRE</fixed-case>: A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction</title>
      <author><first>Shun</first><last>Zheng</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Peilin</first><last>Yu</last></author>
      <author><first>Lu</first><last>Chen</last></author>
      <author><first>Ling</first><last>Huang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Wei</first><last>Xu</last></author>
      <pages>1419&#8211;1429</pages>
      <abstract>Pattern-based labeling methods have achieved promising results in alleviating the inevitable labeling noises of distantly supervised neural relation extraction. However, these methods require significant expert labor to write relation-specific patterns, which makes them too sophisticated to generalize quickly. To ease the labor-intensive workload of pattern writing and enable the quick generalization to new relation types, we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine high-quality relational patterns from noise data with human experts in the loop. To demonstrate the effectiveness of DIAG-NRE, we apply it to two real-world datasets and present both significant and interpretable improvements over state-of-the-art methods.</abstract>
      <url hash="f3c03929">P19-1137</url>
      <doi>10.18653/v1/P19-1137</doi>
      <bibkey>zheng-etal-2019-diag</bibkey>
      <pwccode url="https://github.com/thunlp/DIAG-NRE" additional="false">thunlp/DIAG-NRE</pwccode>
    </paper>
    <paper id="139">
      <title><fixed-case>ERNIE</fixed-case>: Enhanced Language Representation with Informative Entities</title>
      <author><first>Zhengyan</first><last>Zhang</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>1441&#8211;1451</pages>
      <abstract>Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.</abstract>
      <url hash="234e9f33">P19-1139</url>
      <doi>10.18653/v1/P19-1139</doi>
      <bibkey>zhang-etal-2019-ernie</bibkey>
      <pwccode url="https://github.com/thunlp/ERNIE" additional="false">thunlp/ERNIE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cola">CoLA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fewrel">FewRel</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/open-entity-1">Open Entity</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/qnli">QNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quora-question-pairs">Quora Question Pairs</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rte">RTE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sts-benchmark">STS Benchmark</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/superglue">SuperGLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tacred">TACRED</pwcdataset>
    </paper>
    <paper id="140">
      <title>Multi-Channel Graph Neural Network for Entity Alignment</title>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Chengjiang</first><last>Li</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>1452&#8211;1461</pages>
      <abstract>Entity alignment typically suffers from the issues of structural heterogeneity and limited seed alignments. In this paper, we propose a novel Multi-channel Graph Neural Network model (MuGNN) to learn alignment-oriented knowledge graph (KG) embeddings by robustly encoding two KGs via multiple channels. Each channel encodes KGs via different relation weighting schemes with respect to self-attention towards KG completion and cross-KG attention for pruning exclusive entities respectively, which are further combined via pooling techniques. Moreover, we also infer and transfer rule knowledge for completing two KGs consistently. MuGNN is expected to reconcile the structural differences of two KGs, and thus make better use of seed alignments. Extensive experiments on five publicly available datasets demonstrate our superior performance (5% Hits@1 up on average). Source code and data used in the experiments can be accessed at https://github.com/thunlp/MuGNN .</abstract>
      <url hash="43d79483">P19-1140</url>
      <doi>10.18653/v1/P19-1140</doi>
      <bibkey>cao-etal-2019-multi</bibkey>
      <pwccode url="https://github.com/thunlp/MuGNN" additional="false">thunlp/MuGNN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dbp15k">DBP15K</pwcdataset>
    </paper>
    <paper id="141">
      <title>A Neural Multi-digraph Model for <fixed-case>C</fixed-case>hinese <fixed-case>NER</fixed-case> with Gazetteers</title>
      <author><first>Ruixue</first><last>Ding</last></author>
      <author><first>Pengjun</first><last>Xie</last></author>
      <author><first>Xiaoyan</first><last>Zhang</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Linlin</first><last>Li</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>1462&#8211;1467</pages>
      <abstract>Gazetteers were shown to be useful resources for named entity recognition (NER). Many existing approaches to incorporating gazetteers into machine learning based NER systems rely on manually defined selection strategies or handcrafted templates, which may not always lead to optimal effectiveness, especially when multiple gazetteers are involved. This is especially the case for the task of Chinese NER, where the words are not naturally tokenized, leading to additional ambiguities. To automatically learn how to incorporate multiple gazetteers into an NER system, we propose a novel approach based on graph neural networks with a multi-digraph structure that captures the information that the gazetteers offer. Experiments on various datasets show that our model is effective in incorporating rich gazetteer information while resolving ambiguities, outperforming previous approaches.</abstract>
      <url hash="bf2f4923">P19-1141</url>
      <attachment type="supplementary" hash="e7830c05">P19-1141.Supplementary.pdf</attachment>
      <attachment type="software" hash="7a79855f">P19-1141.Software.zip</attachment>
      <doi>10.18653/v1/P19-1141</doi>
      <bibkey>ding-etal-2019-neural</bibkey>
      <pwccode url="https://github.com/PhantomGrapes/MultiDigraphNER" additional="false">PhantomGrapes/MultiDigraphNER</pwccode>
    </paper>
    <paper id="153">
      <title>Towards Lossless Encoding of Sentences</title>
      <author><first>Gabriele</first><last>Prato</last></author>
      <author><first>Mathieu</first><last>Duchesneau</last></author>
      <author><first>Sarath</first><last>Chandar</last></author>
      <author><first>Alain</first><last>Tapp</last></author>
      <pages>1577&#8211;1583</pages>
      <abstract>A lot of work has been done in the field of image compression via machine learning, but not much attention has been given to the compression of natural language. Compressing text into lossless representations while making features easily retrievable is not a trivial task, yet has huge benefits. Most methods designed to produce feature rich sentence embeddings focus solely on performing well on downstream tasks and are unable to properly reconstruct the original sequence from the learned embedding. In this work, we propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations. We test our method on sentiment analysis and show good performance across all sub-sentence and sentence embeddings.</abstract>
      <url hash="7beab5df">P19-1153</url>
      <doi>10.18653/v1/P19-1153</doi>
      <bibkey>prato-etal-2019-towards</bibkey>
      <pwccode url="https://github.com/pratogab/rae" additional="false">pratogab/rae</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="157">
      <title>Historical Text Normalization with Delayed Rewards</title>
      <author><first>Simon</first><last>Flachs</last></author>
      <author><first>Marcel</first><last>Bollmann</last></author>
      <author><first>Anders</first><last>S&#248;gaard</last></author>
      <pages>1614&#8211;1619</pages>
      <abstract>Training neural sequence-to-sequence models with simple token-level log-likelihood is now a standard approach to historical text normalization, albeit often outperformed by phrase-based models. Policy gradient training enables direct optimization for exact matches, and while the small datasets in historical text normalization are prohibitive of from-scratch reinforcement learning, we show that policy gradient fine-tuning leads to significant improvements across the board. Policy gradient training, in particular, leads to more accurate normalizations for long or unseen words.</abstract>
      <url hash="9b7aeac6">P19-1157</url>
      <doi>10.18653/v1/P19-1157</doi>
      <bibkey>flachs-etal-2019-historical</bibkey>
    </paper>
    <paper id="160">
      <title>Gender-preserving Debiasing for Pre-trained Word Embeddings</title>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Danushka</first><last>Bollegala</last></author>
      <pages>1641&#8211;1650</pages>
      <abstract>Word embeddings learnt from massive text collections have demonstrated significant levels of discriminative biases such as gender, racial or ethnic biases, which in turn bias the down-stream NLP applications that use those word embeddings. Taking gender-bias as a working example, we propose a debiasing method that preserves non-discriminative gender-related information, while removing stereotypical discriminative gender biases from pre-trained word embeddings. Specifically, we consider four types of information: <i>feminine</i>, <i>masculine</i>, <i>gender-neutral</i> and <i>stereotypical</i>, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.</abstract>
      <url hash="63fa606a">P19-1160</url>
      <video href="https://vimeo.com/384482232" />
      <doi>10.18653/v1/P19-1160</doi>
      <bibkey>kaneko-bollegala-2019-gender</bibkey>
      <pwccode url="https://github.com/kanekomasahiro/gp_debias" additional="false">kanekomasahiro/gp_debias</pwccode>
    </paper>
    <paper id="165">
      <title><fixed-case>LSTME</fixed-case>mbed: Learning Word and Sense Representations from a Large Semantically Annotated Corpus with Long Short-Term Memories</title>
      <author><first>Ignacio</first><last>Iacobacci</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>1685&#8211;1695</pages>
      <abstract>While word embeddings are now a de facto standard representation of words in most NLP tasks, recently the attention has been shifting towards vector representations which capture the different meanings, i.e., senses, of words. In this paper we explore the capabilities of a bidirectional LSTM model to learn representations of word senses from semantically annotated corpora. We show that the utilization of an architecture that is aware of word order, like an LSTM, enables us to create better representations. We assess our proposed model on various standard benchmarks for evaluating semantic representations, reaching state-of-the-art performance on the SemEval-2014 word-to-sense similarity task. We release the code and the resulting word and sense embeddings at http://lcl.uniroma1.it/LSTMEmbed.</abstract>
      <url hash="32b6b190">P19-1165</url>
      <video href="https://vimeo.com/384489801" />
      <doi>10.18653/v1/P19-1165</doi>
      <bibkey>iacobacci-navigli-2019-lstmembed</bibkey>
    </paper>
    <paper id="166">
      <title>Understanding Undesirable Word Embedding Associations</title>
      <author><first>Kawin</first><last>Ethayarajh</last></author>
      <author><first>David</first><last>Duvenaud</last></author>
      <author><first>Graeme</first><last>Hirst</last></author>
      <pages>1696&#8211;1705</pages>
      <abstract>Word embeddings are often criticized for capturing undesirable word associations such as gender stereotypes. However, methods for measuring and removing such biases remain poorly understood. We show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection (Bolukbasi et al., 2016) is, under certain conditions, equivalent to training on an unbiased corpus. We also prove that WEAT, the most common association test for word embeddings, systematically overestimates bias. Given that the subspace projection method is provably effective, we use it to derive a new measure of association called the relational inner product association (RIPA). Experiments with RIPA reveal that, on average, skipgram with negative sampling (SGNS) does not make most words any more gendered than they are in the training corpus. However, for gender-stereotyped words, SGNS actually amplifies the gender association in the corpus.</abstract>
      <url hash="3ae2a4ed">P19-1166</url>
      <video href="https://vimeo.com/384490216" />
      <doi>10.18653/v1/P19-1166</doi>
      <bibkey>ethayarajh-etal-2019-understanding</bibkey>
    </paper>
    <paper id="167">
      <title>Unsupervised Discovery of Gendered Language through Latent-Variable Modeling</title>
      <author><first>Alexander Miserlis</first><last>Hoyle</last></author>
      <author><first>Lawrence</first><last>Wolf-Sonkin</last></author>
      <author><first>Hanna</first><last>Wallach</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>1706&#8211;1716</pages>
      <abstract>Studying the ways in which language is gendered has long been an area of interest in sociolinguistics. Studies have explored, for example, the speech of male and female characters in film and the language used to describe male and female politicians. In this paper, we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way. To that end, we introduce a generative latent-variable model that jointly represents adjective (or verb) choice, with its sentiment, given the natural gender of a head (or dependent) noun. We find that there are significant differences between descriptions of male and female nouns and that these differences align with common gender stereotypes: Positive adjectives used to describe women are more often related to their bodies than adjectives used to describe men.</abstract>
      <url hash="9482ff7f">P19-1167</url>
      <attachment type="software" hash="fa75ec92">P19-1167.Software.zip</attachment>
      <video href="https://vimeo.com/385493733" permission="false" />
      <doi>10.18653/v1/P19-1167</doi>
      <bibkey>hoyle-etal-2019-unsupervised</bibkey>
    </paper>
    <paper id="169">
      <title><fixed-case>S</fixed-case>phere<fixed-case>RE</fixed-case>: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings</title>
      <author><first>Chengyu</first><last>Wang</last></author>
      <author><first>Xiaofeng</first><last>He</last></author>
      <author><first>Aoying</first><last>Zhou</last></author>
      <pages>1727&#8211;1737</pages>
      <abstract>Lexical relations describe how meanings of terms relate to each other. Typical examples include hypernymy, synonymy, meronymy, etc. Automatic distinction of lexical relations is vital for NLP applications, and also challenging due to the lack of contextual signals to discriminate between such relations. In this work, we present a neural representation learning model to distinguish lexical relations among term pairs based on Hyperspherical Relation Embeddings (SphereRE). Rather than learning embeddings for individual terms, the model learns representations of relation triples by mapping them to the hyperspherical embedding space, where relation triples of different lexical relations are well separated. Experiments over several benchmarks confirm SphereRE outperforms state-of-the-arts.</abstract>
      <url hash="5705f0a8">P19-1169</url>
      <doi>10.18653/v1/P19-1169</doi>
      <video href="https://vimeo.com/384491244" />
      <revision id="1" href="P19-1169v1" hash="9e2c1491" />
      <revision id="2" href="P19-1169v2" hash="5705f0a8">The name of the first author has changed.</revision>
      <bibkey>wang-etal-2019-spherere</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
    </paper>
    <paper id="170">
      <title>Multilingual Factor Analysis</title>
      <author><first>Francisco</first><last>Vargas</last></author>
      <author><first>Kamen</first><last>Brestnichki</last></author>
      <author><first>Alex</first><last>Papadopoulos Korfiatis</last></author>
      <author><first>Nils</first><last>Hammerla</last></author>
      <pages>1738&#8211;1750</pages>
      <abstract>In this work we approach the task of learning multilingual word representations in an offline manner by fitting a generative latent variable model to a multilingual dictionary. We model equivalent words in different languages as different views of the same word generated by a common latent variable representing their latent lexical meaning. We explore the task of alignment by querying the fitted model for multilingual embeddings achieving competitive results across a variety of tasks. The proposed model is robust to noise in the embedding space making it a suitable method for distributed representations learned from noisy corpora.</abstract>
      <url hash="91329ee9">P19-1170</url>
      <attachment type="supplementary" hash="65216531">P19-1170.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/384494210" />
      <doi>10.18653/v1/P19-1170</doi>
      <bibkey>vargas-etal-2019-multilingual</bibkey>
      <pwccode url="https://github.com/Babylonpartners/MultilingualFactorAnalysis" additional="false">Babylonpartners/MultilingualFactorAnalysis</pwccode>
    </paper>
    <paper id="173">
      <title>Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect Morphological Modeling</title>
      <author><first>Nasser</first><last>Zalmout</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>1775&#8211;1786</pages>
      <abstract>Morphological tagging is challenging for morphologically rich languages due to the large target space and the need for more training data to minimize model sparsity. Dialectal variants of morphologically rich languages suffer more as they tend to be more noisy and have less resources. In this paper we explore the use of multitask learning and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging. We use multitask learning for joint morphological modeling for the features within two dialects, and as a knowledge-transfer scheme for cross-dialectal modeling. We use adversarial training to learn dialect invariant features that can help the knowledge-transfer scheme from the high to low-resource variants. We work with two dialectal variants: Modern Standard Arabic (high-resource &#8220;dialect&#8217;&#8221;) and Egyptian Arabic (low-resource dialect) as a case study. Our models achieve state-of-the-art results for both. Furthermore, adversarial training provides more significant improvement when using smaller training datasets in particular.</abstract>
      <url hash="d87f33d3">P19-1173</url>
      <video href="https://vimeo.com/384512599" />
      <doi>10.18653/v1/P19-1173</doi>
      <bibkey>zalmout-habash-2019-adversarial</bibkey>
    </paper>
    <paper id="174">
      <title>Neural Machine Translation with Reordering Embeddings</title>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>1787&#8211;1799</pages>
      <abstract>The reordering model plays an important role in phrase-based statistical machine translation. However, there are few works that exploit the reordering information in neural machine translation. In this paper, we propose a reordering mechanism to learn the reordering embedding of a word based on its contextual information. These learned reordering embeddings are stacked together with self-attention networks to learn sentence representation for machine translation. The reordering mechanism can be easily integrated into both the encoder and the decoder in the Transformer translation system. Experimental results on WMT&#8217;14 English-to-German, NIST Chinese-to-English, and WAT Japanese-to-English translation tasks demonstrate that the proposed methods can significantly improve the performance of the Transformer.</abstract>
      <url hash="3ddfdc57">P19-1174</url>
      <video href="https://vimeo.com/384527233" />
      <doi>10.18653/v1/P19-1174</doi>
      <bibkey>chen-etal-2019-neural</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="175">
      <title>Neural Fuzzy Repair: Integrating Fuzzy Matches into Neural Machine Translation</title>
      <author><first>Bram</first><last>Bulte</last></author>
      <author><first>Arda</first><last>Tezcan</last></author>
      <pages>1800&#8211;1809</pages>
      <abstract>We present a simple yet powerful data augmentation method for boosting Neural Machine Translation (NMT) performance by leveraging information retrieved from a Translation Memory (TM). We propose and test two methods for augmenting NMT training data with fuzzy TM matches. Tests on the DGT-TM data set for two language pairs show consistent and substantial improvements over a range of baseline systems. The results suggest that this method is promising for any translation environment in which a sizeable TM is available and a certain amount of repetition across translations is to be expected, especially considering its ease of implementation.</abstract>
      <url hash="8488cec0">P19-1175</url>
      <video href="https://vimeo.com/384527378" />
      <doi>10.18653/v1/P19-1175</doi>
      <bibkey>bulte-tezcan-2019-neural</bibkey>
    </paper>
    <paper id="178">
      <title>Self-Supervised Neural Machine Translation</title>
      <author><first>Dana</first><last>Ruiter</last></author>
      <author><first>Cristina</first><last>Espa&#241;a-Bonet</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>1828&#8211;1834</pages>
      <abstract>We present a simple new method where an emergent NMT system is used for simultaneously selecting training data and learning internal NMT representations. This is done in a self-supervised way without parallel data, in such a way that both tasks enhance each other during training. The method is language independent, introduces no additional hyper-parameters, and achieves BLEU scores of 29.21 (en2fr) and 27.36 (fr2en) on newstest2014 using English and French Wikipedia data for training.</abstract>
      <url hash="aca8a68c">P19-1178</url>
      <video href="https://vimeo.com/384515284" />
      <doi>10.18653/v1/P19-1178</doi>
      <bibkey>ruiter-etal-2019-self</bibkey>
      <pwccode url="https://github.com/ruitedk6/comparableNMT" additional="false">ruitedk6/comparableNMT</pwccode>
    </paper>
    <paper id="179">
      <title>Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation</title>
      <author><first>Elizabeth</first><last>Salesky</last></author>
      <author><first>Matthias</first><last>Sperber</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>1835&#8211;1841</pages>
      <abstract>Previous work on end-to-end translation from speech has primarily used frame-level features as speech representations, which creates longer, sparser sequences than text. We show that a naive method to create compressed phoneme-like speech representations is far more effective and efficient for translation than traditional frame-level speech features. Specifically, we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation. We see improvements of up to 5 BLEU on both our high and low resource language pairs, with a reduction in training time of 60%. Our improvements hold across multiple data sizes and two language pairs.</abstract>
      <url hash="db586366">P19-1179</url>
      <video href="https://vimeo.com/384515395" />
      <doi>10.18653/v1/P19-1179</doi>
      <bibkey>salesky-etal-2019-exploring</bibkey>
    </paper>
    <paper id="181">
      <title>Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation</title>
      <author><first>Vihan</first><last>Jain</last></author>
      <author><first>Gabriel</first><last>Magalhaes</last></author>
      <author><first>Alexander</first><last>Ku</last></author>
      <author><first>Ashish</first><last>Vaswani</last></author>
      <author><first>Eugene</first><last>Ie</last></author>
      <author><first>Jason</first><last>Baldridge</last></author>
      <pages>1862&#8211;1872</pages>
      <abstract>Advances in learning and representations have reinvigorated work that connects language to other modalities. A particularly exciting direction is Vision-and-Language Navigation(VLN), in which agents interpret natural language instructions and visual scenes to move through environments and reach goals. Despite recent progress, current research leaves unclear how much of a role language under-standing plays in this task, especially because dominant evaluation metrics have focused on goal completion rather than the sequence of actions corresponding to the instructions. Here, we highlight shortcomings of current metrics for the Room-to-Room dataset (Anderson et al.,2018b) and propose a new metric, Coverage weighted by Length Score (CLS). We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set, Room-for-Room (R4R). Using R4R and CLS, we show that agents that receive rewards for instruction fidelity outperform agents that focus on goal completion.</abstract>
      <url hash="b7f0d6dd">P19-1181</url>
      <video href="https://vimeo.com/384518803" />
      <doi>10.18653/v1/P19-1181</doi>
      <bibkey>jain-etal-2019-stay</bibkey>
    </paper>
    <paper id="182">
      <title>Expressing Visual Relationships via Language</title>
      <author><first>Hao</first><last>Tan</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Zhe</first><last>Lin</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>1873&#8211;1883</pages>
      <abstract>Describing images with text is a fundamental problem in vision-language research. Current studies in this domain mostly focus on single image captioning. However, in various real applications (e.g., image editing, difference interpretation, and retrieval), generating relational captions for two images, can also be very useful. This important problem has not been explored mostly due to lack of datasets and effective models. To push forward the research in this direction, we first introduce a new language-guided image editing dataset that contains a large number of real image pairs with corresponding editing instructions. We then propose a new relational speaker model based on an encoder-decoder architecture with static relational attention and sequential multi-head attention. We also extend the model with dynamic relational attention, which calculates visual alignment while decoding. Our models are evaluated on our newly collected and two public datasets consisting of image pairs annotated with relationship sentences. Experimental results, based on both automatic and human evaluation, demonstrate that our model outperforms all baselines and existing methods on all the datasets.</abstract>
      <url hash="249d6d98">P19-1182</url>
      <video href="https://vimeo.com/384520109" />
      <doi>10.18653/v1/P19-1182</doi>
      <bibkey>tan-etal-2019-expressing</bibkey>
      <pwccode url="https://github.com/airsplay/VisualRelationships" additional="false">airsplay/VisualRelationships</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/image-editing-request-dataset">Image Editing Request Dataset</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/spot-the-diff">Spot-the-diff</pwcdataset>
    </paper>
    <paper id="189">
      <title>Reinforced Training Data Selection for Domain Adaptation</title>
      <author><first>Miaofeng</first><last>Liu</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Hongbin</first><last>Zou</last></author>
      <author><first>Tong</first><last>Zhang</last></author>
      <pages>1957&#8211;1968</pages>
      <abstract>Supervised models suffer from the problem of domain shifting where distribution mismatch in the data across domains greatly affect model performance. To solve the problem, training data selection (TDS) has been proven to be a prospective solution for domain adaptation in leveraging appropriate data. However, conventional TDS methods normally requires a predefined threshold which is neither easy to set nor can be applied across tasks, and models are trained separately with the TDS process. To make TDS self-adapted to data and task, and to combine it with model training, in this paper, we propose a reinforcement learning (RL) framework that synchronously searches for training instances relevant to the target domain and learns better representations for them. A selection distribution generator (SDG) is designed to perform the selection and is updated according to the rewards computed from the selected data, where a predictor is included in the framework to ensure a task-specific model can be trained on the selected data and provides feedback to rewards. Experimental results from part-of-speech tagging, dependency parsing, and sentiment analysis, as well as ablation studies, illustrate that the proposed framework is not only effective in data selection and representation, but also generalized to accommodate different NLP tasks.</abstract>
      <url hash="3a51ee05">P19-1189</url>
      <doi>10.18653/v1/P19-1189</doi>
      <bibkey>liu-etal-2019-reinforced</bibkey>
      <pwccode url="https://github.com/timerstime/SDG4DA" additional="false">timerstime/SDG4DA</pwccode>
    </paper>
    <paper id="192">
      <title>Rhetorically Controlled Encoder-Decoder for <fixed-case>M</fixed-case>odern <fixed-case>C</fixed-case>hinese Poetry Generation</title>
      <author><first>Zhiqiang</first><last>Liu</last></author>
      <author><first>Zuohui</first><last>Fu</last></author>
      <author><first>Jie</first><last>Cao</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <author><first>Yik-Cheung</first><last>Tam</last></author>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>1992&#8211;2001</pages>
      <abstract>Rhetoric is a vital element in modern poetry, and plays an essential role in improving its aesthetics. However, to date, it has not been considered in research on automatic poetry generation. In this paper, we propose a rhetorically controlled encoder-decoder for modern Chinese poetry generation. Our model relies on a continuous latent variable as a rhetoric controller to capture various rhetorical patterns in an encoder, and then incorporates rhetoric-based mixtures while generating modern Chinese poetry. For metaphor and personification, an automated evaluation shows that our model outperforms state-of-the-art baselines by a substantial margin, while human evaluation shows that our model generates better poems than baseline methods in terms of fluency, coherence, meaningfulness, and rhetorical aesthetics.</abstract>
      <url hash="559d7232">P19-1192</url>
      <doi>10.18653/v1/P19-1192</doi>
      <bibkey>liu-etal-2019-rhetorically</bibkey>
      <pwccode url="https://github.com/Lucien-qiang/Rhetoric-Generator" additional="false">Lucien-qiang/Rhetoric-Generator</pwccode>
    </paper>
    <paper id="196">
      <title>Ensuring Readability and Data-fidelity using Head-modifier Templates in Deep Type Description Generation</title>
      <author><first>Jiangjie</first><last>Chen</last></author>
      <author><first>Ao</first><last>Wang</last></author>
      <author><first>Haiyun</first><last>Jiang</last></author>
      <author><first>Suo</first><last>Feng</last></author>
      <author><first>Chenguang</first><last>Li</last></author>
      <author><first>Yanghua</first><last>Xiao</last></author>
      <pages>2036&#8211;2046</pages>
      <abstract>A type description is a succinct noun compound which helps human and machines to quickly grasp the informative and distinctive information of an entity. Entities in most knowledge graphs (KGs) still lack such descriptions, thus calling for automatic methods to supplement such information. However, existing generative methods either overlook the grammatical structure or make factual mistakes in generated texts. To solve these problems, we propose a head-modifier template based method to ensure the readability and data fidelity of generated type descriptions. We also propose a new dataset and two metrics for this task. Experiments show that our method improves substantially compared with baselines and achieves state-of-the-art performance on both datasets.</abstract>
      <url hash="453d43ab">P19-1196</url>
      <doi>10.18653/v1/P19-1196</doi>
      <bibkey>chen-etal-2019-ensuring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="197">
      <title>Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</title>
      <author><first>Shuming</first><last>Ma</last></author>
      <author><first>Pengcheng</first><last>Yang</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Peng</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>2047&#8211;2057</pages>
      <abstract>Table-to-text generation aims to translate the structured data into the unstructured text. Most existing methods adopt the encoder-decoder framework to learn the transformation, which requires large-scale training samples. However, the lack of large parallel data is a major practical problem for many domains. In this work, we consider the scenario of low resource table-to-text generation, where only limited parallel data is available. We propose a novel model to separate the generation into two stages: key fact prediction and surface realization. It first predicts the key facts from the tables, and then generates the text with the key facts. The training of key fact prediction needs much fewer annotated data, while surface realization can be trained with pseudo parallel corpus. We evaluate our model on a biography generation dataset. Our model can achieve 27.34 BLEU score with only 1,000 parallel data, while the baseline model only obtain the performance of 9.71 BLEU score.</abstract>
      <url hash="6ebceadb">P19-1197</url>
      <doi>10.18653/v1/P19-1197</doi>
      <revision id="1" href="P19-1197v1" hash="aefa47e8" />
      <revision id="2" href="P19-1197v2" hash="6ebceadb">We have corrected Equation 8,9,10 in Page 5, or it may cause misunderstanding about the method in the paper. The rest of the paper remains unchanged.</revision>
      <bibkey>ma-etal-2019-key</bibkey>
      <pwccode url="https://github.com/lancopku/Pivot" additional="false">lancopku/Pivot</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikibio">WikiBio</pwcdataset>
    </paper>
    <paper id="200">
      <title>Towards Generating Long and Coherent Text with Multi-Level Latent Variable Models</title>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Liqun</first><last>Chen</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>2079&#8211;2089</pages>
      <abstract>Variational autoencoders (VAEs) have received much attention recently as an end-to-end architecture for text generation with latent variables. However, previous works typically focus on synthesizing relatively short sentences (up to 20 words), and the posterior collapse issue has been widely identified in text-VAEs. In this paper, we propose to leverage several multi-level structures to learn a VAE model for generating long, and coherent text. In particular, a hierarchy of stochastic layers between the encoder and decoder networks is employed to abstract more informative and semantic-rich latent codes. Besides, we utilize a multi-level decoder structure to capture the coherent long-term structure inherent in long-form texts, by generating intermediate sentence representations as high-level plan vectors. Extensive experimental results demonstrate that the proposed multi-level VAE model produces more coherent and less repetitive long text compared to baselines as well as can mitigate the posterior-collapse issue.</abstract>
      <url hash="0fa811de">P19-1200</url>
      <attachment type="supplementary" hash="fd568a49">P19-1200.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1200</doi>
      <bibkey>shen-etal-2019-towards</bibkey>
    </paper>
    <paper id="205">
      <title>Improving Abstractive Document Summarization with Salient Information Modeling</title>
      <author><first>Yongjian</first><last>You</last></author>
      <author><first>Weijia</first><last>Jia</last></author>
      <author><first>Tianyi</first><last>Liu</last></author>
      <author><first>Wenmian</first><last>Yang</last></author>
      <pages>2132&#8211;2141</pages>
      <abstract>Comprehensive document encoding and salient information selection are two major difficulties for generating summaries with adequate salient information. To tackle the above difficulties, we propose a Transformer-based encoder-decoder framework with two novel extensions for abstractive document summarization. Specifically, (1) to encode the documents comprehensively, we design a focus-attention mechanism and incorporate it into the encoder. This mechanism models a Gaussian focal bias on attention scores to enhance the perception of local context, which contributes to producing salient and informative summaries. (2) To distinguish salient information precisely, we design an independent saliency-selection network which manages the information flow from encoder to decoder. This network effectively reduces the influences of secondary information on the generated summaries. Experimental results on the popular CNN/Daily Mail benchmark demonstrate that our model outperforms other state-of-the-art baselines on the ROUGE metrics.</abstract>
      <url hash="6fb05201">P19-1205</url>
      <doi>10.18653/v1/P19-1205</doi>
      <bibkey>you-etal-2019-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="206">
      <title>Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</title>
      <author><first>Masaru</first><last>Isonuma</last></author>
      <author><first>Junichiro</first><last>Mori</last></author>
      <author><first>Ichiro</first><last>Sakata</last></author>
      <pages>2142&#8211;2152</pages>
      <abstract>This paper focuses on the end-to-end abstractive summarization of a single product review without supervision. We assume that a review can be described as a discourse tree, in which the summary is the root, and the child sentences explain their parent in detail. By recursively estimating a parent from its children, our model learns the latent discourse tree without an external parser and generates a concise summary. We also introduce an architecture that ranks the importance of each sentence on the tree to support summary generation focusing on the main review point. The experimental results demonstrate that our model is competitive with or outperforms other unsupervised approaches. In particular, for relatively long reviews, it achieves a competitive or better performance than supervised models. The induced tree shows that the child sentences provide additional information about their parent, and the generated summary abstracts the entire review.</abstract>
      <url hash="64f5f0a7">P19-1206</url>
      <attachment type="supplementary" hash="e410cc98">P19-1206.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1206</doi>
      <bibkey>isonuma-etal-2019-unsupervised</bibkey>
      <pwccode url="https://github.com/misonuma/strsum" additional="false">misonuma/strsum</pwccode>
    </paper>
    <paper id="211">
      <title>Adversarial Domain Adaptation Using Artificial Titles for Abstractive Title Generation</title>
      <author><first>Francine</first><last>Chen</last></author>
      <author><first>Yan-Ying</first><last>Chen</last></author>
      <pages>2197&#8211;2203</pages>
      <abstract>A common issue in training a deep learning, abstractive summarization model is lack of a large set of training summaries. This paper examines techniques for adapting from a labeled source domain to an unlabeled target domain in the context of an encoder-decoder model for text generation. In addition to adversarial domain adaptation (ADA), we introduce the use of artificial titles and sequential training to capture the grammatical style of the unlabeled target domain. Evaluation on adapting to/from news articles and Stack Exchange posts indicates that the use of these techniques can boost performance for both unsupervised adaptation as well as fine-tuning with limited target data.</abstract>
      <url hash="5d98af08">P19-1211</url>
      <doi>10.18653/v1/P19-1211</doi>
      <bibkey>chen-chen-2019-adversarial</bibkey>
    </paper>
    <paper id="212">
      <title><fixed-case>BIGPATENT</fixed-case>: A Large-Scale Dataset for Abstractive and Coherent Summarization</title>
      <author><first>Eva</first><last>Sharma</last></author>
      <author><first>Chen</first><last>Li</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>2204&#8211;2213</pages>
      <abstract>Most existing text summarization datasets are compiled from the news domain, where summaries have a flattened discourse structure. In such datasets, summary-worthy content often appears in the beginning of input articles. Moreover, large segments from input articles are present verbatim in their respective summaries. These issues impede the learning and evaluation of systems that can understand an article&#8217;s global content structure as well as produce abstractive summaries with high compression ratio. In this work, we present a novel dataset, BIGPATENT, consisting of 1.3 million records of U.S. patent documents along with human written abstractive summaries. Compared to existing summarization datasets, BIGPATENT has the following properties: i) summaries contain a richer discourse structure with more recurring entities, ii) salient content is evenly distributed in the input, and iii) lesser and shorter extractive fragments are present in the summaries. Finally, we train and evaluate baselines and popular learning models on BIGPATENT to shed light on new challenges and motivate future directions for summarization research.</abstract>
      <url hash="baf090f8">P19-1212</url>
      <doi>10.18653/v1/P19-1212</doi>
      <bibkey>sharma-etal-2019-bigpatent</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bigpatent">BigPatent</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsroom">NEWSROOM</pwcdataset>
    </paper>
    <paper id="213">
      <title>Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference</title>
      <author><first>Tobias</first><last>Falke</last></author>
      <author><first>Leonardo F. R.</first><last>Ribeiro</last></author>
      <author><first>Prasetya Ajie</first><last>Utama</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>2214&#8211;2220</pages>
      <abstract>While recent progress on abstractive summarization has led to remarkably fluent summaries, factual errors in generated summaries still severely limit their use in practice. In this paper, we evaluate summaries produced by state-of-the-art models via crowdsourcing and show that such errors occur frequently, in particular with more abstractive models. We study whether textual entailment predictions can be used to detect such errors and if they can be reduced by reranking alternative predicted summaries. That leads to an interesting downstream application for entailment models. In our experiments, we find that out-of-the-box entailment models trained on NLI datasets do not yet offer the desired performance for the downstream task and we therefore release our annotations as additional test data for future extrinsic evaluations of NLI.</abstract>
      <url hash="ffe26bac">P19-1213</url>
      <doi>10.18653/v1/P19-1213</doi>
      <bibkey>falke-etal-2019-ranking</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="214">
      <title>Self-Supervised Learning for Contextualized Extractive Summarization</title>
      <author><first>Hong</first><last>Wang</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>2221&#8211;2227</pages>
      <abstract>Existing models for extractive summarization are usually trained from scratch with a cross-entropy loss, which does not explicitly capture the global context at the document level. In this paper, we aim to improve this task by introducing three auxiliary pre-training tasks that learn to capture the document-level context in a self-supervised fashion. Experiments on the widely-used CNN/DM dataset validate the effectiveness of the proposed auxiliary tasks. Furthermore, we show that after pre-training, a clean model with simple building blocks is able to outperform previous state-of-the-art that are carefully designed.</abstract>
      <url hash="53577a61">P19-1214</url>
      <doi>10.18653/v1/P19-1214</doi>
      <bibkey>wang-etal-2019-self-supervised</bibkey>
      <pwccode url="https://github.com/hongwang600/Summarization" additional="false">hongwang600/Summarization</pwccode>
    </paper>
    <paper id="215">
      <title>On the Summarization of Consumer Health Questions</title>
      <author><first>Asma</first><last>Ben Abacha</last></author>
      <author><first>Dina</first><last>Demner-Fushman</last></author>
      <pages>2228&#8211;2234</pages>
      <abstract>Question understanding is one of the main challenges in question answering. In real world applications, users often submit natural language questions that are longer than needed and include peripheral information that increases the complexity of the question, leading to substantially more false positives in answer retrieval. In this paper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000 summarized consumer health questions. We explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this new task. In particular, we show that semantic augmentation from question datasets improves the overall performance, and that pointer-generator networks outperform sequence-to-sequence attentional models on this task, with a ROUGE-1 score of 44.16%. We also present a detailed error analysis and discuss directions for improvement that are specific to question summarization.</abstract>
      <url hash="b05f1a54">P19-1215</url>
      <doi>10.18653/v1/P19-1215</doi>
      <bibkey>ben-abacha-demner-fushman-2019-summarization</bibkey>
      <pwccode url="https://github.com/abachaa/MeQSum" additional="false">abachaa/MeQSum</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/meqsum">MeQSum</pwcdataset>
    </paper>
    <paper id="216">
      <title>Unsupervised Rewriter for Multi-Sentence Compression</title>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Xiaoyu</first><last>Shen</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>2235&#8211;2240</pages>
      <abstract>Multi-sentence compression (MSC) aims to generate a grammatical but reduced compression from multiple input sentences while retaining their key information. Previous dominating approach for MSC is the extraction-based word graph approach. A few variants further leveraged lexical substitution to yield more abstractive compression. However, two limitations exist. First, the word graph approach that simply concatenates fragments from multiple sentences may yield non-fluent or ungrammatical compression. Second, lexical substitution is often inappropriate without the consideration of context information. To tackle the above-mentioned issues, we present a neural rewriter for multi-sentence compression that does not need any parallel corpus. Empirical studies have shown that our approach achieves comparable results upon automatic evaluation and improves the grammaticality of compression based on human evaluation. A parallel corpus with more than 140,000 (sentence group, compression) pairs is also constructed as a by-product for future research.</abstract>
      <url hash="2bbebcbb">P19-1216</url>
      <attachment type="supplementary" hash="f0963d68">P19-1216.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1216</doi>
      <bibkey>zhao-etal-2019-unsupervised</bibkey>
    </paper>
    <paper id="219">
      <title>Explicit Utilization of General Knowledge in Machine Reading Comprehension</title>
      <author><first>Chao</first><last>Wang</last></author>
      <author><first>Hui</first><last>Jiang</last></author>
      <pages>2263&#8211;2272</pages>
      <abstract>To bridge the gap between Machine Reading Comprehension (MRC) models and human beings, which is mainly reflected in the hunger for data and the robustness to noise, in this paper, we explore how to integrate the neural networks of MRC models with the general knowledge of human beings. On the one hand, we propose a data enrichment method, which uses WordNet to extract inter-word semantic connections as general knowledge from each given passage-question pair. On the other hand, we propose an end-to-end MRC model named as Knowledge Aided Reader (KAR), which explicitly uses the above extracted general knowledge to assist its attention mechanisms. Based on the data enrichment method, KAR is comparable in performance with the state-of-the-art MRC models, and significantly more robust to noise than them. When only a subset (20%-80%) of the training examples are available, KAR outperforms the state-of-the-art MRC models by a large margin, and is still reasonably robust to noise.</abstract>
      <url hash="f069eaaa">P19-1219</url>
      <doi>10.18653/v1/P19-1219</doi>
      <bibkey>wang-jiang-2019-explicit</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="220">
      <title>Multi-style Generative Reading Comprehension</title>
      <author><first>Kyosuke</first><last>Nishida</last></author>
      <author><first>Itsumi</first><last>Saito</last></author>
      <author><first>Kosuke</first><last>Nishida</last></author>
      <author><first>Kazutoshi</first><last>Shinoda</last></author>
      <author><first>Atsushi</first><last>Otsuka</last></author>
      <author><first>Hisako</first><last>Asano</last></author>
      <author><first>Junji</first><last>Tomita</last></author>
      <pages>2273&#8211;2284</pages>
      <abstract>This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We propose a multi-style abstractive summarization model for question answering, called Masque. The proposed model has two key characteristics. First, unlike most studies on RC that have focused on extracting an answer span from the provided passages, our model instead focuses on generating a summary from the question and multiple passages. This serves to cover various answer styles required for real-world applications. Second, whereas previous studies built a specific model for each answer style because of the difficulty of acquiring one general model, our approach learns multi-style answers within a model to improve the NLG capability for all styles involved. This also enables our model to give an answer in the target style. Experiments show that our model achieves state-of-the-art performance on the Q&amp;A task and the Q&amp;A + NLG task of MS MARCO 2.1 and the summary task of NarrativeQA. We observe that the transfer of the style-independent NLG capability to the target style is the key to its success.</abstract>
      <url hash="292461f5">P19-1220</url>
      <attachment type="supplementary" hash="7b946c5c">P19-1220.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1220</doi>
      <bibkey>nishida-etal-2019-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/duorc">DuoRC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/narrativeqa">NarrativeQA</pwcdataset>
    </paper>
    <paper id="223">
      <title><fixed-case>E</fixed-case>3: Entailment-driven Extracting and Editing for Conversational Machine Reading</title>
      <author><first>Victor</first><last>Zhong</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>2310&#8211;2320</pages>
      <abstract>Conversational machine reading systems help users answer high-level questions (e.g. determine if they qualify for particular government benefits) when they do not know the exact rules by which the determination is made (e.g. whether they need certain income levels or veteran status). The key challenge is that these rules are only provided in the form of a procedural text (e.g. guidelines from government website) which the system must read to figure out what to ask the user. We present a new conversational machine reading model that jointly extracts a set of decision rules from the procedural text while reasoning about which are entailed by the conversational history and which still need to be edited to create questions for the user. On the recently introduced ShARC conversational machine reading dataset, our Entailment-driven Extract and Edit network (E3) achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In addition, by explicitly highlighting which information still needs to be gathered, E3 provides a more explainable alternative to prior work. We release source code for our models and experiments at https://github.com/vzhong/e3.</abstract>
      <url hash="30337cbb">P19-1223</url>
      <attachment type="supplementary" hash="4dab762e">P19-1223.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1223</doi>
      <bibkey>zhong-zettlemoyer-2019-e3</bibkey>
      <pwccode url="https://github.com/vzhong/e3" additional="false">vzhong/e3</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sharc">ShARC</pwcdataset>
    </paper>
    <paper id="224">
      <title>Generating Question-Answer Hierarchies</title>
      <author><first>Kalpesh</first><last>Krishna</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>2321&#8211;2334</pages>
      <abstract>The process of knowledge acquisition can be viewed as a question-answer game between a student and a teacher in which the student typically starts by asking broad, open-ended questions before drilling down into specifics (Hintikka, 1981; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a new way of representing documents. In this paper, we present SQUASH (Specificity-controlled Question-Answer Hierarchies), a novel and challenging text generation task that converts an input document into a hierarchy of question-answer pairs. Users can click on high-level questions (e.g., &#8220;Why did Frodo leave the Fellowship?&#8221;) to reveal related but more specific questions (e.g., &#8220;Who did Frodo leave with?&#8221;). Using a question taxonomy loosely based on Lehnert (1978), we classify questions in existing reading comprehension datasets as either GENERAL or SPECIFIC . We then use these labels as input to a pipelined system centered around a conditional neural language model. We extensively evaluate the quality of the generated QA hierarchies through crowdsourced experiments and report strong empirical results.</abstract>
      <url hash="fce7c74c">P19-1224</url>
      <attachment type="poster" hash="c171a591">P19-1224.Poster.pdf</attachment>
      <attachment type="note" hash="75b4bf70">P19-1224.Note.pdf</attachment>
      <doi>10.18653/v1/P19-1224</doi>
      <bibkey>krishna-iyyer-2019-generating</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/coqa">CoQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quac">QuAC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="226">
      <title>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension</title>
      <author><first>An</first><last>Yang</last></author>
      <author><first>Quan</first><last>Wang</last></author>
      <author><first>Jing</first><last>Liu</last></author>
      <author><first>Kai</first><last>Liu</last></author>
      <author><first>Yajuan</first><last>Lyu</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Qiaoqiao</first><last>She</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <pages>2346&#8211;2357</pages>
      <abstract>Machine reading comprehension (MRC) is a crucial and challenging task in NLP. Recently, pre-trained language models (LMs), especially BERT, have achieved remarkable success, presenting new state-of-the-art results in MRC. In this work, we investigate the potential of leveraging external knowledge bases (KBs) to further improve BERT for MRC. We introduce KT-NET, which employs an attention mechanism to adaptively select desired knowledge from KBs, and then fuses selected knowledge with BERT to enable context- and knowledge-aware predictions. We believe this would combine the merits of both deep LMs and curated KBs towards better MRC. Experimental results indicate that KT-NET offers significant and consistent improvements over BERT, outperforming competitive baselines on ReCoRD and SQuAD1.1 benchmarks. Notably, it ranks the 1st place on the ReCoRD leaderboard, and is also the best single model on the SQuAD1.1 leaderboard at the time of submission (March 4th, 2019).</abstract>
      <url hash="fc01bc47">P19-1226</url>
      <doi>10.18653/v1/P19-1226</doi>
      <bibkey>yang-etal-2019-enhancing-pre</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nell">NELL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/record">ReCoRD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
    </paper>
    <paper id="229">
      <title>Semi-supervised Domain Adaptation for Dependency Parsing</title>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Xue</first><last>Peng</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Luo</first><last>Si</last></author>
      <pages>2386&#8211;2395</pages>
      <abstract>During the past decades, due to the lack of sufficient labeled data, most studies on cross-domain parsing focus on unsupervised domain adaptation, assuming there is no target-domain training data. However, unsupervised approaches make limited progress so far due to the intrinsic difficulty of both domain adaptation and parsing. This paper tackles the semi-supervised domain adaptation problem for Chinese dependency parsing, based on two newly-annotated large-scale domain-aware datasets. We propose a simple domain embedding approach to merge the source- and target-domain training data, which is shown to be more effective than both direct corpus concatenation and multi-task learning. In order to utilize unlabeled target-domain data, we employ the recent contextualized word representations and show that a simple fine-tuning procedure can further boost cross-domain parsing accuracy by large margin.</abstract>
      <url hash="e9515dbb">P19-1229</url>
      <doi>10.18653/v1/P19-1229</doi>
      <bibkey>li-etal-2019-semi-supervised-domain</bibkey>
      <pwccode url="https://github.com/SUDA-LA/ACL2019-dp-cross-domain" additional="false">SUDA-LA/ACL2019-dp-cross-domain</pwccode>
    </paper>
    <paper id="230">
      <title><fixed-case>H</fixed-case>ead-<fixed-case>D</fixed-case>riven <fixed-case>P</fixed-case>hrase <fixed-case>S</fixed-case>tructure <fixed-case>G</fixed-case>rammar Parsing on <fixed-case>P</fixed-case>enn <fixed-case>T</fixed-case>reebank</title>
      <author><first>Junru</first><last>Zhou</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>2396&#8211;2408</pages>
      <abstract>Head-driven phrase structure grammar (HPSG) enjoys a uniform formalism representing rich contextual syntactic and even semantic meanings. This paper makes the first attempt to formulate a simplified HPSG by integrating constituent and dependency formal representations into head-driven phrase structure. Then two parsing algorithms are respectively proposed for two converted tree representations, division span and joint span. As HPSG encodes both constituent and dependency structure information, the proposed HPSG parsers may be regarded as a sort of joint decoder for both types of structures and thus are evaluated in terms of extracted or converted constituent and dependency parsing trees. Our parser achieves new state-of-the-art performance for both parsing tasks on Penn Treebank (PTB) and Chinese Penn Treebank, verifying the effectiveness of joint learning constituent and dependency structures. In details, we report 95.84 F1 of constituent parsing and 97.00% UAS of dependency parsing on PTB.</abstract>
      <url hash="92a04554">P19-1230</url>
      <attachment type="software" hash="8df33df2">P19-1230.Software.zip</attachment>
      <doi>10.18653/v1/P19-1230</doi>
      <bibkey>zhou-zhao-2019-head</bibkey>
      <pwccode url="https://github.com/DoodleJZ/HPSG-Neural-Parser" additional="false">DoodleJZ/HPSG-Neural-Parser</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="237">
      <title>Graph-based Dependency Parsing with Graph Neural Networks</title>
      <author><first>Tao</first><last>Ji</last></author>
      <author><first>Yuanbin</first><last>Wu</last></author>
      <author><first>Man</first><last>Lan</last></author>
      <pages>2475&#8211;2485</pages>
      <abstract>We investigate the problem of efficiently incorporating high-order features into neural graph-based dependency parsing. Instead of explicitly extracting high-order features from intermediate parse trees, we develop a more powerful dependency tree node representation which captures high-order information concisely and efficiently. We use graph neural networks (GNNs) to learn the representations and discuss several new configurations of GNN&#8217;s updating and aggregation functions. Experiments on PTB show that our parser achieves the best UAS and LAS on PTB (96.0%, 94.3%) among systems without using any external resources.</abstract>
      <url hash="1e5b1b5f">P19-1237</url>
      <doi>10.18653/v1/P19-1237</doi>
      <bibkey>ji-etal-2019-graph</bibkey>
      <pwccode url="https://github.com/AntNLP/gnn-dep-parsing" additional="false">AntNLP/gnn-dep-parsing</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="240">
      <title>Topic-Aware Neural Keyphrase Generation for Social Media Language</title>
      <author><first>Yue</first><last>Wang</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Hou Pong</first><last>Chan</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <author><first>Michael R.</first><last>Lyu</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <pages>2516&#8211;2526</pages>
      <abstract>A huge volume of user-generated content is daily produced on social media. To facilitate automatic language understanding, we study keyphrase prediction, distilling salient information from massive posts. While most existing methods extract words from source posts to form keyphrases, we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created. Moreover, our model, being topic-aware, allows joint modeling of corpus-level latent topic representations, which helps alleviate data sparsity widely exhibited in social media language. Experiments on three datasets collected from English and Chinese social media platforms show that our model significantly outperforms both extraction and generation models without exploiting latent topics. Further discussions show that our model learns meaningful topics, which interprets its superiority in social media keyphrase generation.</abstract>
      <url hash="644eec27">P19-1240</url>
      <doi>10.18653/v1/P19-1240</doi>
      <bibkey>wang-etal-2019-topic-aware</bibkey>
      <pwccode url="https://github.com/yuewang-cuhk/TAKG" additional="true">yuewang-cuhk/TAKG</pwccode>
    </paper>
    <paper id="241">
      <title>#<fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>oo? Detection of Personal Recollections of Sexual Harassment on Social Media</title>
      <author><first>Arijit</first><last>Ghosh Chowdhury</last></author>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <author><first>Debanjan</first><last>Mahata</last></author>
      <pages>2527&#8211;2537</pages>
      <abstract>The availability of large-scale online social data, coupled with computational methods can help us answer fundamental questions relat- ing to our social lives, particularly our health and well-being. The #MeToo trend has led to people talking about personal experiences of harassment more openly. This work at- tempts to aggregate such experiences of sex- ual abuse to facilitate a better understanding of social media constructs and to bring about social change. It has been found that disclo- sure of abuse has positive psychological im- pacts. Hence, we contend that such informa- tion can leveraged to create better campaigns for social change by analyzing how users react to these stories and to obtain a better insight into the consequences of sexual abuse. We use a three part Twitter-Specific Social Media Lan- guage Model to segregate personal recollec- tions of sexual harassment from Twitter posts. An extensive comparison with state-of-the-art generic and specific models along with a de- tailed error analysis explores the merit of our proposed model.</abstract>
      <url hash="a0c9888a">P19-1241</url>
      <doi>10.18653/v1/P19-1241</doi>
      <bibkey>ghosh-chowdhury-etal-2019-youtoo</bibkey>
      <pwccode url="https://github.com/arijit1410/ACL2019-YouToo" additional="false">arijit1410/ACL2019-YouToo</pwccode>
    </paper>
    <paper id="244">
      <title>Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks</title>
      <author><first>Jing</first><last>Ma</last></author>
      <author><first>Wei</first><last>Gao</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>2561&#8211;2571</pages>
      <abstract>Claim verification is generally a task of verifying the veracity of a given claim, which is critical to many downstream applications. It is cumbersome and inefficient for human fact-checkers to find consistent pieces of evidence, from which solid verdict could be inferred against the claim. In this paper, we propose a novel end-to-end hierarchical attention network focusing on learning to represent coherent evidence as well as their semantic relatedness with the claim. Our model consists of three main components: 1) A coherence-based attention layer embeds coherent evidence considering the claim and sentences from relevant articles; 2) An entailment-based attention layer attends on sentences that can semantically infer the claim on top of the first attention; and 3) An output layer predicts the verdict based on the embedded evidence. Experimental results on three public benchmark datasets show that our proposed model outperforms a set of state-of-the-art baselines.</abstract>
      <url hash="2a3f25b3">P19-1244</url>
      <doi>10.18653/v1/P19-1244</doi>
      <bibkey>ma-etal-2019-sentence</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="246">
      <title>You Write like You Eat: Stylistic Variation as a Predictor of Social Stratification</title>
      <author><first>Angelo</first><last>Basile</last></author>
      <author><first>Albert</first><last>Gatt</last></author>
      <author><first>Malvina</first><last>Nissim</last></author>
      <pages>2583&#8211;2593</pages>
      <abstract>Inspired by Labov&#8217;s seminal work on stylisticvariation as a function of social stratification,we develop and compare neural models thatpredict a person&#8217;s presumed socio-economicstatus, obtained through distant supervision,from their writing style on social media. Thefocus of our work is on identifying the mostimportant stylistic parameters to predict socio-economic group. In particular, we show theeffectiveness of morpho-syntactic features aspredictors of style, in contrast to lexical fea-tures, which are good predictors of topic</abstract>
      <url hash="65eb679d">P19-1246</url>
      <doi>10.18653/v1/P19-1246</doi>
      <bibkey>basile-etal-2019-write</bibkey>
    </paper>
    <paper id="249">
      <title>Celebrity Profiling</title>
      <author><first>Matti</first><last>Wiegmann</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <pages>2611&#8211;2618</pages>
      <abstract>Celebrities are among the most prolific users of social media, promoting their personas and rallying followers. This activity is closely tied to genuine writing samples, which makes them worthy research subjects in many respects, not least profiling. With this paper we introduce the Webis Celebrity Corpus 2019. For its construction the Twitter feeds of 71,706 verified accounts have been carefully linked with their respective Wikidata items, crawling both. After cleansing, the resulting profiles contain an average of 29,968 words per profile and up to 239 pieces of personal information. A cross-evaluation that checked the correct association of Twitter account and Wikidata item revealed an error rate of only 0.6%, rendering the profiles highly reliable. Our corpus comprises a wide cross-section of local and global celebrities, forming a unique combination of scale, profile comprehensiveness, and label reliability. We further establish the state of the art&#8217;s profiling performance by evaluating the winning approaches submitted to the PAN gender prediction tasks in a transfer learning experiment. They are only outperformed by our own deep learning approach, which we also use to exemplify celebrity occupation prediction for the first time.</abstract>
      <url hash="9cb3acb3">P19-1249</url>
      <doi>10.18653/v1/P19-1249</doi>
      <bibkey>wiegmann-etal-2019-celebrity</bibkey>
      <pwccode url="https://github.com/webis-de/acl-19" additional="false">webis-de/acl-19</pwccode>
    </paper>
    <paper id="252">
      <title><fixed-case>T</fixed-case>witter Homophily: Network Based Prediction of User&#8217;s Occupation</title>
      <author><first>Jiaqi</first><last>Pan</last></author>
      <author><first>Rishabh</first><last>Bhardwaj</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <author><first>Hai Leong</first><last>Chieu</last></author>
      <author><first>Xinghao</first><last>Pan</last></author>
      <author><first>Ni Yi</first><last>Puay</last></author>
      <pages>2633&#8211;2638</pages>
      <abstract>In this paper, we investigate the importance of social network information compared to content information in the prediction of a Twitter user&#8217;s occupational class. We show that the content information of a user&#8217;s tweets, the profile descriptions of a user&#8217;s follower/following community, and the user&#8217;s social network provide useful information for classifying a user&#8217;s occupational group. In our study, we extend an existing data set for this problem, and we achieve significantly better performance by using social network homophily that has not been fully exploited in previous work. In our analysis, we found that by using the graph convolutional network to exploit social homophily, we can achieve competitive performance on this data set with just a small fraction of the training data.</abstract>
      <url hash="4427b1ea">P19-1252</url>
      <attachment type="software" hash="cabd2d81">P19-1252.Software.zip</attachment>
      <doi>10.18653/v1/P19-1252</doi>
      <bibkey>pan-etal-2019-twitter</bibkey>
      <pwccode url="https://github.com/jqnap/Twitter-Occupation-Prediction" additional="false">jqnap/Twitter-Occupation-Prediction</pwccode>
    </paper>
    <paper id="254">
      <title>Strategies for Structuring Story Generation</title>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <author><first>Yann</first><last>Dauphin</last></author>
      <pages>2650&#8211;2660</pages>
      <abstract>Writers often rely on plans or sketches to write long stories, but most current language models generate word by word from left to right. We explore coarse-to-fine models for creating narrative texts of several hundred words, and introduce new models which decompose stories by abstracting over actions and entities. The model first generates the predicate-argument structure of the text, where different mentions of the same entity are marked with placeholder tokens. It then generates a surface realization of the predicate-argument structure, and finally replaces the entity placeholders with context-sensitive names and references. Human judges prefer the stories from our models to a wide range of previous approaches to hierarchical text generation. Extensive analysis shows that our methods can help improve the diversity and coherence of events and entities in generated stories.</abstract>
      <url hash="6971b732">P19-1254</url>
      <video href="https://vimeo.com/384728593" />
      <doi>10.18653/v1/P19-1254</doi>
      <bibkey>fan-etal-2019-strategies</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sentence-compression">Sentence Compression</pwcdataset>
    </paper>
    <paper id="255">
      <title>Argument Generation with Retrieval, Planning, and Realization</title>
      <author><first>Xinyu</first><last>Hua</last></author>
      <author><first>Zhe</first><last>Hu</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>2661&#8211;2672</pages>
      <abstract>Automatic argument generation is an appealing but challenging task. In this paper, we study the specific problem of counter-argument generation, and present a novel framework, CANDELA. It consists of a powerful retrieval system and a novel two-step generation model, where a text planning decoder first decides on the main talking points and a proper language style for each sentence, then a content realization decoder reflects the decisions and constructs an informative paragraph-level argument. Furthermore, our generation model is empowered by a retrieval system indexed with 12 million articles collected from Wikipedia and popular English news media, which provides access to high-quality content with diversity. Automatic evaluation on a large-scale dataset collected from Reddit shows that our model yields significantly higher BLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial comparisons. Human evaluation further indicates that our system arguments are more appropriate for refutation and richer in content.</abstract>
      <url hash="4732298e">P19-1255</url>
      <video href="https://vimeo.com/384728654" />
      <doi>10.18653/v1/P19-1255</doi>
      <bibkey>hua-etal-2019-argument-generation</bibkey>
    </paper>
    <paper id="256">
      <title>A Simple Recipe towards Reducing Hallucination in Neural Surface Realisation</title>
      <author><first>Feng</first><last>Nie</last></author>
      <author><first>Jin-Ge</first><last>Yao</last></author>
      <author><first>Jinpeng</first><last>Wang</last></author>
      <author><first>Rong</first><last>Pan</last></author>
      <author><first>Chin-Yew</first><last>Lin</last></author>
      <pages>2673&#8211;2679</pages>
      <abstract>Recent neural language generation systems often <i>hallucinate</i> contents (i.e., producing irrelevant or contradicted facts), especially when trained on loosely corresponding pairs of the input structure and text. To mitigate this issue, we propose to integrate a language understanding module for data refinement with self-training iterations to effectively induce strong equivalence between the input data and the paired text. Experiments on the E2E challenge dataset show that our proposed framework can reduce more than 50% relative unaligned noise from the original data-text pairs. A vanilla sequence-to-sequence neural NLG model trained on the refined data has improved on content correctness compared with the current state-of-the-art ensemble generator.</abstract>
      <url hash="b96018f5">P19-1256</url>
      <video href="https://vimeo.com/384728744" />
      <doi>10.18653/v1/P19-1256</doi>
      <bibkey>nie-etal-2019-simple</bibkey>
    </paper>
    <paper id="257">
      <title>Cross-Modal Commentator: Automatic Machine Commenting Based on Cross-Modal Information</title>
      <author><first>Pengcheng</first><last>Yang</last></author>
      <author><first>Zhihan</first><last>Zhang</last></author>
      <author><first>Fuli</first><last>Luo</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <author><first>Chengyang</first><last>Huang</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>2680&#8211;2686</pages>
      <abstract>Automatic commenting of online articles can provide additional opinions and facts to the reader, which improves user experience and engagement on social media platforms. Previous work focuses on automatic commenting based solely on textual content. However, in real-scenarios, online articles usually contain multiple modal contents. For instance, graphic news contains plenty of images in addition to text. Contents other than text are also vital because they are not only more attractive to the reader but also may provide critical information. To remedy this, we propose a new task: cross-model automatic commenting (CMAC), which aims to make comments by integrating multiple modal contents. We construct a large-scale dataset for this task and explore several representative methods. Going a step further, an effective co-attention model is presented to capture the dependency between textual and visual information. Evaluation results show that our proposed model can achieve better performance than competitive baselines.</abstract>
      <url hash="8d659a88">P19-1257</url>
      <video href="https://vimeo.com/384731731" />
      <doi>10.18653/v1/P19-1257</doi>
      <bibkey>yang-etal-2019-cross</bibkey>
      <pwccode url="https://github.com/lancopku/CMAC" additional="false">lancopku/CMAC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cross-modal-comments-dataset">Cross-Modal Comments Dataset</pwcdataset>
    </paper>
    <paper id="259">
      <title>Cognitive Graph for Multi-Hop Reading Comprehension at Scale</title>
      <author><first>Ming</first><last>Ding</last></author>
      <author><first>Chang</first><last>Zhou</last></author>
      <author><first>Qibin</first><last>Chen</last></author>
      <author><first>Hongxia</first><last>Yang</last></author>
      <author><first>Jie</first><last>Tang</last></author>
      <pages>2694&#8211;2703</pages>
      <abstract>We propose a new CogQA framework for multi-hop reading comprehension question answering in web-scale documents. Founded on the dual process theory in cognitive science, the framework gradually builds a <i>cognitive graph</i> in an iterative process by coordinating an implicit extraction module (System 1) and an explicit reasoning module (System 2). While giving accurate answers, our framework further provides explainable reasoning paths. Specifically, our implementation based on BERT and graph neural network efficiently handles millions of documents for multi-hop reasoning questions in the HotpotQA fullwiki dataset, achieving a winning joint <tex-math>F_1</tex-math> score of 34.9 on the leaderboard, compared to 23.1 of the best competitor.</abstract>
      <url hash="27f32f3e">P19-1259</url>
      <video href="https://vimeo.com/384732092" />
      <doi>10.18653/v1/P19-1259</doi>
      <bibkey>ding-etal-2019-cognitive</bibkey>
      <pwccode url="https://github.com/THUDM/CogQA" additional="true">THUDM/CogQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hotpotqa">HotpotQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="262">
      <title>Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and Model Development for Multi-Hop <fixed-case>QA</fixed-case></title>
      <author><first>Yichen</first><last>Jiang</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>2726&#8211;2736</pages>
      <abstract>Multi-hop question answering requires a model to connect multiple pieces of evidence scattered in a long context to answer the question. In this paper, we show that in the multi-hop HotpotQA (Yang et al., 2018) dataset, the examples often contain reasoning shortcuts through which models can directly locate the answer by word-matching the question with a sentence in the context. We demonstrate this issue by constructing adversarial documents that create contradicting answers to the shortcut but do not affect the validity of the original answer. The performance of strong baseline models drops significantly on our adversarial test, indicating that they are indeed exploiting the shortcuts rather than performing multi-hop reasoning. After adversarial training, the baseline&#8217;s performance improves but is still limited on the adversarial test. Hence, we use a control unit that dynamically attends to the question at different reasoning hops to guide the model&#8217;s multi-hop reasoning. We show that our 2-hop model trained on the regular data is more robust to the adversaries than the baseline. After adversarial training, it not only achieves significant improvements over its counterpart trained on regular data, but also outperforms the adversarially-trained baseline significantly. Finally, we sanity-check that these improvements are not obtained by exploiting potential new shortcuts in the adversarial data, but indeed due to robust multi-hop reasoning skills of the models.</abstract>
      <url hash="7c756d3d">P19-1262</url>
      <video href="https://vimeo.com/384736016" />
      <doi>10.18653/v1/P19-1262</doi>
      <bibkey>jiang-bansal-2019-avoiding</bibkey>
      <pwccode url="https://github.com/jiangycTarheel/Adversarial-MultiHopQA" additional="false">jiangycTarheel/Adversarial-MultiHopQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hotpotqa">HotpotQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="263">
      <title>Exploiting Explicit Paths for Multi-hop Reading Comprehension</title>
      <author><first>Souvik</first><last>Kundu</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <pages>2737&#8211;2747</pages>
      <abstract>We propose a novel, path-based reasoning approach for the multi-hop reading comprehension task where a system needs to combine facts from multiple passages to answer a question. Although inspired by multi-hop reasoning over knowledge graphs, our proposed approach operates directly over unstructured text. It generates potential paths through passages and scores them without any direct path supervision. The proposed model, named PathNet, attempts to extract implicit relations from text through entity pair representations, and compose them to encode each path. To capture additional context, PathNet also composes the passage representations along each path to compute a passage-based representation. Unlike previous approaches, our model is then able to explain its reasoning via these explicit paths through the passages. We show that our approach outperforms prior models on the multi-hop Wikihop dataset, and also can be generalized to apply to the OpenBookQA dataset, matching state-of-the-art performance.</abstract>
      <url hash="823c3697">P19-1263</url>
      <video href="https://vimeo.com/384736068" />
      <doi>10.18653/v1/P19-1263</doi>
      <bibkey>kundu-etal-2019-exploiting</bibkey>
      <pwccode url="https://github.com/allenai/PathNet" additional="false">allenai/PathNet</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/openbookqa">OpenBookQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikihop">WikiHop</pwcdataset>
    </paper>
    <paper id="267">
      <title>We Need to Talk about Standard Splits</title>
      <author><first>Kyle</first><last>Gorman</last></author>
      <author><first>Steven</first><last>Bedrick</last></author>
      <pages>2786&#8211;2791</pages>
      <abstract>It is standard practice in speech &amp; language technology to rank systems according to their performance on a test set held out for evaluation. However, few researchers apply statistical tests to determine whether differences in performance are likely to arise by chance, and few examine the stability of system ranking across multiple training-testing splits. We conduct replication and reproduction experiments with nine part-of-speech taggers published between 2000 and 2018, each of which claimed state-of-the-art performance on a widely-used &#8220;standard split&#8221;. While we replicate results on the standard split, we fail to reliably reproduce some rankings when we repeat this analysis with randomly generated training-testing splits. We argue that randomly generated splits should be used in system evaluation.</abstract>
      <url hash="d076ee26">P19-1267</url>
      <video href="https://vimeo.com/384738334" />
      <award>Outstanding Paper</award>
      <doi>10.18653/v1/P19-1267</doi>
      <bibkey>gorman-bedrick-2019-need</bibkey>
      <pwccode url="https://github.com/kylebgorman/SOTA-taggers" additional="false">kylebgorman/SOTA-taggers</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="270">
      <title>Joint Effects of Context and User History for Predicting Online Conversation Re-entries</title>
      <author><first>Xingshan</first><last>Zeng</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>2809&#8211;2818</pages>
      <abstract>As the online world continues its exponential growth, interpersonal communication has come to play an increasingly central role in opinion formation and change. In order to help users better engage with each other online, we study a challenging problem of re-entry prediction foreseeing whether a user will come back to a conversation they once participated in. We hypothesize that both the context of the ongoing conversations and the users&#8217; previous chatting history will affect their continued interests in future engagement. Specifically, we propose a neural framework with three main layers, each modeling context, user history, and interactions between them, to explore how the conversation context and user chatting history jointly result in their re-entry behavior. We experiment with two large-scale datasets collected from Twitter and Reddit. Results show that our proposed framework with bi-attention achieves an F1 score of 61.1 on Twitter conversations, outperforming the state-of-the-art methods from previous work.</abstract>
      <url hash="8b5685e1">P19-1270</url>
      <video href="https://vimeo.com/384738763" />
      <doi>10.18653/v1/P19-1270</doi>
      <bibkey>zeng-etal-2019-joint</bibkey>
      <pwccode url="https://github.com/zxshamson/re-entry-prediction" additional="false">zxshamson/re-entry-prediction</pwccode>
    </paper>
    <paper id="271">
      <title><fixed-case>CONAN</fixed-case> - <fixed-case>CO</fixed-case>unter <fixed-case>NA</fixed-case>rratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech</title>
      <author><first>Yi-Ling</first><last>Chung</last></author>
      <author><first>Elizaveta</first><last>Kuzmenko</last></author>
      <author><first>Serra Sinem</first><last>Tekiroglu</last></author>
      <author><first>Marco</first><last>Guerini</last></author>
      <pages>2819&#8211;2829</pages>
      <abstract>Although there is an unprecedented effort to provide adequate responses in terms of laws and policies to hate content on social media platforms, dealing with hatred online is still a tough problem. Tackling hate speech in the standard way of content deletion or user suspension may be charged with censorship and overblocking. One alternate strategy, that has received little attention so far by the research community, is to actually oppose hate content with counter-narratives (i.e. informed textual responses). In this paper, we describe the creation of the first large-scale, multilingual, expert-based dataset of hate-speech/counter-narrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task. Together with the collected data we also provide additional annotations about expert demographics, hate and response type, and data augmentation through translation and paraphrasing. Finally, we provide initial experiments to assess the quality of our data.</abstract>
      <url hash="e0810e2a">P19-1271</url>
      <video href="https://vimeo.com/384740828" />
      <doi>10.18653/v1/P19-1271</doi>
      <bibkey>chung-etal-2019-conan</bibkey>
      <pwccode url="https://github.com/marcoguerini/CONAN" additional="false">marcoguerini/CONAN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conan">CONAN</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="275">
      <title>Exploring Author Context for Detecting Intended vs Perceived Sarcasm</title>
      <author><first>Silviu</first><last>Oprea</last></author>
      <author><first>Walid</first><last>Magdy</last></author>
      <pages>2854&#8211;2859</pages>
      <abstract>We investigate the impact of using author context on textual sarcasm detection. We define author context as the embedded representation of their historical posts on Twitter and suggest neural models that extract these representations. We experiment with two tweet datasets, one labelled manually for sarcasm, and the other via tag-based distant supervision. We achieve state-of-the-art performance on the second dataset, but not on the one labelled manually, indicating a difference between intended sarcasm, captured by distant supervision, and perceived sarcasm, captured by manual labelling.</abstract>
      <url hash="52a13218">P19-1275</url>
      <video href="https://vimeo.com/384744638" />
      <doi>10.18653/v1/P19-1275</doi>
      <bibkey>oprea-magdy-2019-exploring</bibkey>
    </paper>
    <paper id="276">
      <title>Open Domain Event Extraction Using Neural Latent Variable Models</title>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Heyan</first><last>Huang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>2860&#8211;2871</pages>
      <abstract>We consider open domain event extraction, the task of extracting unconstraint types of events from news clusters. A novel latent variable neural model is constructed, which is scalable to very large corpus. A dataset is collected and manually annotated, with task-specific evaluation metrics being designed. Results show that the proposed unsupervised model gives better performance compared to the state-of-the-art method for event schema induction.</abstract>
      <url hash="d02a88dd">P19-1276</url>
      <video href="https://vimeo.com/384744763" />
      <doi>10.18653/v1/P19-1276</doi>
      <bibkey>liu-etal-2019-open</bibkey>
      <pwccode url="https://github.com/lx865712528/ACL2019-ODEE" additional="false">lx865712528/ACL2019-ODEE</pwccode>
    </paper>
    <paper id="277">
      <title>Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification</title>
      <author><first>Zhi-Xiu</first><last>Ye</last></author>
      <author><first>Zhen-Hua</first><last>Ling</last></author>
      <pages>2872&#8211;2881</pages>
      <abstract>This paper presents a multi-level matching and aggregation network (MLMAN) for few-shot relation classification. Previous studies on this topic adopt prototypical networks, which calculate the embedding vector of a query instance and the prototype vector of the support set for each relation candidate independently. On the contrary, our proposed MLMAN model encodes the query instance and each support set in an interactive way by considering their matching information at both local and instance levels. The final class prototype for each support set is obtained by attentive aggregation over the representations of support instances, where the weights are calculated using the query instance. Experimental results demonstrate the effectiveness of our proposed methods, which achieve a new state-of-the-art performance on the FewRel dataset.</abstract>
      <url hash="9c09b69b">P19-1277</url>
      <video href="https://vimeo.com/384744882" />
      <doi>10.18653/v1/P19-1277</doi>
      <bibkey>ye-ling-2019-multi</bibkey>
      <pwccode url="https://github.com/ZhixiuYe/MLMAN" additional="false">ZhixiuYe/MLMAN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fewrel">FewRel</pwcdataset>
    </paper>
    <paper id="281">
      <title><fixed-case>FIESTA</fixed-case>: Fast <fixed-case>I</fixed-case>d<fixed-case>E</fixed-case>ntification of State-of-The-Art models using adaptive bandit algorithms</title>
      <author><first>Henry</first><last>Moss</last></author>
      <author><first>Andrew</first><last>Moore</last></author>
      <author><first>David</first><last>Leslie</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <pages>2920&#8211;2930</pages>
      <abstract>We present FIESTA, a model selection approach that significantly reduces the computational resources required to reliably identify state-of-the-art performance from large collections of candidate models. Despite being known to produce unreliable comparisons, it is still common practice to compare model evaluations based on single choices of random seeds. We show that reliable model selection also requires evaluations based on multiple train-test splits (contrary to common practice in many shared tasks). Using bandit theory from the statistics literature, we are able to adaptively determine appropriate numbers of data splits and random seeds used to evaluate each model, focusing computational resources on the evaluation of promising models whilst avoiding wasting evaluations on models with lower performance. Furthermore, our user-friendly Python implementation produces confidence guarantees of correctly selecting the optimal model. We evaluate our algorithms by selecting between 8 target-dependent sentiment analysis methods using dramatically fewer model evaluations than current model selection approaches.</abstract>
      <url hash="bf2bf733">P19-1281</url>
      <video href="https://vimeo.com/384794970" />
      <doi>10.18653/v1/P19-1281</doi>
      <bibkey>moss-etal-2019-fiesta</bibkey>
      <pwccode url="https://github.com/apmoore1/fiesta" additional="false">apmoore1/fiesta</pwccode>
    </paper>
    <paper id="286">
      <title>Domain Adaptation of Neural Machine Translation by Lexicon Induction</title>
      <author><first>Junjie</first><last>Hu</last></author>
      <author><first>Mengzhou</first><last>Xia</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Jaime</first><last>Carbonell</last></author>
      <pages>2989&#8211;3001</pages>
      <abstract>It has been previously noted that neural machine translation (NMT) is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of NMT, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words. To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines.</abstract>
      <url hash="670f6605">P19-1286</url>
      <attachment type="supplementary" hash="05c2a04e">P19-1286.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1286</doi>
      <bibkey>hu-etal-2019-domain-adaptation</bibkey>
    </paper>
    <paper id="287">
      <title>Reference Network for Neural Machine Translation</title>
      <author><first>Han</first><last>Fu</last></author>
      <author><first>Chenghao</first><last>Liu</last></author>
      <author><first>Jianling</first><last>Sun</last></author>
      <pages>3002&#8211;3012</pages>
      <abstract>Neural Machine Translation (NMT) has achieved notable success in recent years. Such a framework usually generates translations in isolation. In contrast, human translators often refer to reference data, either rephrasing the intricate sentence fragments with common terms in source language, or just accessing to the golden translation directly. In this paper, we propose a Reference Network to incorporate referring process into translation decoding of NMT. To construct a reference book, an intuitive way is to store the detailed translation history with extra memory, which is computationally expensive. Instead, we employ Local Coordinates Coding (LCC) to obtain global context vectors containing monolingual and bilingual contextual information for NMT decoding. Experimental results on Chinese-English and English-German tasks demonstrate that our proposed model is effective in improving the translation quality with lightweight computation cost.</abstract>
      <url hash="a374f9e4">P19-1287</url>
      <doi>10.18653/v1/P19-1287</doi>
      <bibkey>fu-etal-2019-reference</bibkey>
    </paper>
    <paper id="290">
      <title>Look Harder: A Neural Machine Translation Model with Hard Attention</title>
      <author><first>Sathish Reddy</first><last>Indurthi</last></author>
      <author><first>Insoo</first><last>Chung</last></author>
      <author><first>Sangha</first><last>Kim</last></author>
      <pages>3037&#8211;3043</pages>
      <abstract>Soft-attention based Neural Machine Translation (NMT) models have achieved promising results on several translation tasks. These models attend all the words in the source sequence for each target token, which makes them ineffective for long sequence translation. In this work, we propose a hard-attention based NMT model which selects a subset of source tokens for each target token to effectively handle long sequence translation. Due to the discrete nature of the hard-attention mechanism, we design a reinforcement learning algorithm coupled with reward shaping strategy to efficiently train it. Experimental results show that the proposed model performs better on long sequences and thereby achieves significant BLEU score improvement on English-German (EN-DE) and English-French (ENFR) translation tasks compared to the soft attention based NMT.</abstract>
      <url hash="ed83e30e">P19-1290</url>
      <doi>10.18653/v1/P19-1290</doi>
      <bibkey>indurthi-etal-2019-look</bibkey>
    </paper>
    <paper id="292">
      <title>A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning</title>
      <author><first>Gon&#231;alo M.</first><last>Correia</last></author>
      <author><first>Andr&#233; F. T.</first><last>Martins</last></author>
      <pages>3050&#8211;3056</pages>
      <abstract>Automatic post-editing (APE) seeks to automatically refine the output of a black-box machine translation (MT) system through human post-edits. APE systems are usually trained by complementing human post-edited data with large, artificial data generated through back-translations, a time-consuming process often no easier than training a MT system from scratch. in this paper, we propose an alternative where we fine-tune pre-trained BERT models on both the encoder and decoder of an APE system, exploring several parameter sharing strategies. By only training on a dataset of 23K sentences for 3 hours on a single GPU we obtain results that are competitive with systems that were trained on 5M artificial sentences. When we add this artificial data our method obtains state-of-the-art results.</abstract>
      <url hash="5d7ad86d">P19-1292</url>
      <doi>10.18653/v1/P19-1292</doi>
      <bibkey>correia-martins-2019-simple</bibkey>
      <pwccode url="https://github.com/deep-spin/OpenNMT-APE" additional="false">deep-spin/OpenNMT-APE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/escape">eSCAPE</pwcdataset>
    </paper>
    <paper id="294">
      <title>Training Neural Machine Translation to Apply Terminology Constraints</title>
      <author><first>Georgiana</first><last>Dinu</last></author>
      <author><first>Prashant</first><last>Mathur</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <author><first>Yaser</first><last>Al-Onaizan</last></author>
      <pages>3063&#8211;3068</pages>
      <abstract>This paper proposes a novel method to inject custom terminology into neural machine translation at run time. Previous works have mainly proposed modifications to the decoding algorithm in order to constrain the output to include run-time-provided target terms. While being effective, these constrained decoding methods add, however, significant computational overhead to the inference step, and, as we show in this paper, can be brittle when tested in realistic conditions. In this paper we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. Comparative experiments show that our method is not only more effective than a state-of-the-art implementation of constrained decoding, but is also as fast as constraint-free decoding.</abstract>
      <url hash="fd968e31">P19-1294</url>
      <doi>10.18653/v1/P19-1294</doi>
      <bibkey>dinu-etal-2019-training</bibkey>
      <pwccode url="https://github.com/mtresearcher/terminology_dataset" additional="false">mtresearcher/terminology_dataset</pwccode>
    </paper>
    <paper id="295">
      <title>Leveraging Local and Global Patterns for Self-Attention Networks</title>
      <author><first>Mingzhou</first><last>Xu</last></author>
      <author><first>Derek F.</first><last>Wong</last></author>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Lidia S.</first><last>Chao</last></author>
      <pages>3069&#8211;3075</pages>
      <abstract>Self-attention networks have received increasing research attention. By default, the hidden states of each word are hierarchically calculated by attending to all words in the sentence, which assembles global information. However, several studies pointed out that taking all signals into account may lead to overlooking neighboring information (e.g. phrase pattern). To address this argument, we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions. Experiments on various neural machine translation tasks demonstrate the effectiveness of the proposed method. The extensive analyses verify that the two types of contexts are complementary to each other, and our method gives highly effective improvements in their integration.</abstract>
      <url hash="558347cd">P19-1295</url>
      <doi>10.18653/v1/P19-1295</doi>
      <bibkey>xu-etal-2019-leveraging</bibkey>
      <pwccode url="https://github.com/scewiner/Leveraging" additional="false">scewiner/Leveraging</pwccode>
    </paper>
    <paper id="296">
      <title>Sentence-Level Agreement for Neural Machine Translation</title>
      <author><first>Mingming</first><last>Yang</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>3076&#8211;3082</pages>
      <abstract>The training objective of neural machine translation (NMT) is to minimize the loss between the words in the translated sentences and those in the references. In NMT, there is a natural correspondence between the source sentence and the target sentence. However, this relationship has only been represented using the entire neural network and the training objective is computed in word-level. In this paper, we propose a sentence-level agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance.</abstract>
      <url hash="5ef14026">P19-1296</url>
      <doi>10.18653/v1/P19-1296</doi>
      <bibkey>yang-etal-2019-sentence</bibkey>
    </paper>
    <paper id="297">
      <title>Multilingual Unsupervised <fixed-case>NMT</fixed-case> using Shared Encoder and Language-Specific Decoders</title>
      <author><first>Sukanta</first><last>Sen</last></author>
      <author><first>Kamal Kumar</first><last>Gupta</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>3083&#8211;3089</pages>
      <abstract>In this paper, we propose a multilingual unsupervised NMT scheme which jointly trains multiple languages with a shared encoder and multiple decoders. Our approach is based on denoising autoencoding of each language and back-translating between English and multiple non-English languages. This results in a universal encoder which can encode any language participating in training into an inter-lingual representation, and language-specific decoders. Our experiments using only monolingual corpora show that multilingual unsupervised model performs better than the separately trained bilingual models achieving improvement of up to 1.48 BLEU points on WMT test sets. We also observe that even if we do not train the network for all possible translation directions, the network is still able to translate in a many-to-many fashion leveraging encoder&#8217;s ability to generate interlingual representation.</abstract>
      <url hash="b59684db">P19-1297</url>
      <doi>10.18653/v1/P19-1297</doi>
      <bibkey>sen-etal-2019-multilingual</bibkey>
    </paper>
    <paper id="301">
      <title>Choosing Transfer Languages for Cross-Lingual Learning</title>
      <author><first>Yu-Hsiang</first><last>Lin</last></author>
      <author><first>Chian-Yu</first><last>Chen</last></author>
      <author><first>Jean</first><last>Lee</last></author>
      <author><first>Zirui</first><last>Li</last></author>
      <author><first>Yuyan</first><last>Zhang</last></author>
      <author><first>Mengzhou</first><last>Xia</last></author>
      <author><first>Shruti</first><last>Rijhwani</last></author>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Xuezhe</first><last>Ma</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Patrick</first><last>Littell</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>3125&#8211;3135</pages>
      <abstract>Cross-lingual transfer, where a high-resource transfer language is used to improve the accuracy of a low-resource task language, is now an invaluable tool for improving performance of natural language processing (NLP) on low-resource languages. However, given a particular task language, it is not clear which language to transfer from, and the standard strategy is to select languages based on ad hoc criteria, usually the intuition of the experimenter. Since a large number of features contribute to the success of cross-lingual transfer (including phylogenetic similarity, typological properties, lexical overlap, or size of available data), even the most enlightened experimenter rarely considers all these factors for the particular task at hand. In this paper, we consider this task of automatically selecting optimal transfer languages as a ranking problem, and build models that consider the aforementioned features to perform this prediction. In experiments on representative NLP tasks, we demonstrate that our model predicts good transfer languages much better than ad hoc baselines considering single features in isolation, and glean insights on what features are most informative for each different NLP tasks, which may inform future ad hoc selection even without use of our method.</abstract>
      <url hash="7abdad4b">P19-1301</url>
      <doi>10.18653/v1/P19-1301</doi>
      <bibkey>lin-etal-2019-choosing</bibkey>
      <pwccode url="https://github.com/neulab/langrank" additional="false">neulab/langrank</pwccode>
    </paper>
    <paper id="302">
      <title><fixed-case>C</fixed-case>og<fixed-case>N</fixed-case>et: A Large-Scale Cognate Database</title>
      <author><first>Khuyagbaatar</first><last>Batsuren</last></author>
      <author><first>Gabor</first><last>Bella</last></author>
      <author><first>Fausto</first><last>Giunchiglia</last></author>
      <pages>3136&#8211;3145</pages>
      <abstract>This paper introduces CogNet, a new, large-scale lexical database that provides cognates -words of common origin and meaning- across languages. The database currently contains 3.1 million cognate pairs across 338 languages using 35 writing systems. The paper also describes the automated method by which cognates were computed from publicly available wordnets, with an accuracy evaluated to 94%. Finally, it presents statistics about the cognate data and some initial insights into it, hinting at a possible future exploitation of the resource by various fields of lingustics.</abstract>
      <url hash="d0f85065">P19-1302</url>
      <attachment type="software" hash="14d8b5de">P19-1302.Software.zip</attachment>
      <doi>10.18653/v1/P19-1302</doi>
      <bibkey>batsuren-etal-2019-cognet</bibkey>
      <pwccode url="https://github.com/kbatsuren/cognet" additional="false">kbatsuren/cognet</pwccode>
    </paper>
    <paper id="303">
      <title>Neural Decipherment via Minimum-Cost Flow: From <fixed-case>U</fixed-case>garitic to <fixed-case>L</fixed-case>inear <fixed-case>B</fixed-case></title>
      <author><first>Jiaming</first><last>Luo</last></author>
      <author><first>Yuan</first><last>Cao</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <pages>3146&#8211;3155</pages>
      <abstract>In this paper we propose a novel neural approach for automatic decipherment of lost languages. To compensate for the lack of strong supervision signal, our model design is informed by patterns in language change documented in historical linguistics. The model utilizes an expressive sequence-to-sequence model to capture character-level correspondences between cognates. To effectively train the model in unsupervised manner, we innovate the training procedure by formalizing it as a minimum-cost flow problem. When applied to decipherment of Ugaritic, we achieve 5% absolute improvement over state-of-the-art results. We also report first automatic results in deciphering Linear B, a syllabic language related to ancient Greek, where our model correctly translates 67.3% of cognates.</abstract>
      <url hash="a734131e">P19-1303</url>
      <doi>10.18653/v1/P19-1303</doi>
      <bibkey>luo-etal-2019-neural</bibkey>
      <pwccode url="https://github.com/j-luo93/NeuroDecipher" additional="false">j-luo93/NeuroDecipher</pwccode>
    </paper>
    <paper id="306">
      <title>Improving Low-Resource Cross-lingual Document Retrieval by Reranking with Deep Bilingual Representations</title>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Caitlin</first><last>Westerfield</last></author>
      <author><first>Sungrok</first><last>Shim</last></author>
      <author><first>Garrett</first><last>Bingham</last></author>
      <author><first>Alexander</first><last>Fabbri</last></author>
      <author><first>William</first><last>Hu</last></author>
      <author><first>Neha</first><last>Verma</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>3173&#8211;3179</pages>
      <abstract>In this paper, we propose to boost low-resource cross-lingual document retrieval performance with deep bilingual query-document representations. We match queries and documents in both source and target languages with four components, each of which is implemented as a term interaction-based deep neural network with cross-lingual word embeddings as input. By including query likelihood scores as extra features, our model effectively learns to rerank the retrieved documents by using a small number of relevance labels for low-resource language pairs. Due to the shared cross-lingual word embedding space, the model can also be directly applied to another language pair without any training label. Experimental results on the Material dataset show that our model outperforms the competitive translation-based baselines on English-Swahili, English-Tagalog, and English-Somali cross-lingual information retrieval tasks.</abstract>
      <url hash="09cc1749">P19-1306</url>
      <doi>10.18653/v1/P19-1306</doi>
      <bibkey>zhang-etal-2019-improving-low</bibkey>
    </paper>
    <paper id="307">
      <title>Are Girls Neko or Sh&#333;jo? Cross-Lingual Alignment of Non-Isomorphic Embeddings with Iterative Normalization</title>
      <author><first>Mozhi</first><last>Zhang</last></author>
      <author><first>Keyulu</first><last>Xu</last></author>
      <author><first>Ken-ichi</first><last>Kawarabayashi</last></author>
      <author><first>Stefanie</first><last>Jegelka</last></author>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <pages>3180&#8211;3189</pages>
      <abstract>Cross-lingual word embeddings (CLWE) underlie many multilingual natural language processing systems, often through orthogonal transformations of pre-trained monolingual embeddings. However, orthogonal mapping only works on language pairs whose embeddings are naturally isomorphic. For non-isomorphic pairs, our method (Iterative Normalization) transforms monolingual embeddings to make orthogonal alignment easier by simultaneously enforcing that (1) individual word vectors are unit length, and (2) each language&#8217;s average vector is zero. Iterative Normalization consistently improves word translation accuracy of three CLWE methods, with the largest improvement observed on English-Japanese (from 2% to 44% test accuracy).</abstract>
      <url hash="e28409d1">P19-1307</url>
      <doi>10.18653/v1/P19-1307</doi>
      <bibkey>zhang-etal-2019-girls</bibkey>
    </paper>
    <paper id="311">
      <title>Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections</title>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>3211&#8211;3223</pages>
      <abstract>Cross-lingual transfer is an effective way to build syntactic analysis tools in low-resource languages. However, transfer is difficult when transferring to typologically distant languages, especially when neither annotated target data nor parallel corpora are available. In this paper, we focus on methods for cross-lingual transfer to distant languages and propose to learn a generative model with a structured prior that utilizes labeled source data and unlabeled target data jointly. The parameters of source model and target model are softly shared through a regularized log likelihood objective. An invertible projection is employed to learn a new interlingual latent embedding space that compensates for imperfect cross-lingual word embedding input. We evaluate our method on two syntactic tasks: part-of-speech (POS) tagging and dependency parsing. On the Universal Dependency Treebanks, we use English as the only source corpus and transfer to a wide range of target languages. On the 10 languages in this dataset that are distant from English, our method yields an average of 5.2% absolute improvement on POS tagging and 8.3% absolute improvement on dependency parsing over a direct transfer method using state-of-the-art discriminative models.</abstract>
      <url hash="97e94a8f">P19-1311</url>
      <doi>10.18653/v1/P19-1311</doi>
      <bibkey>he-etal-2019-cross</bibkey>
      <pwccode url="https://github.com/jxhe/cross-lingual-struct-flow" additional="false">jxhe/cross-lingual-struct-flow</pwccode>
    </paper>
    <paper id="312">
      <title>Unsupervised Joint Training of Bilingual Word Embeddings</title>
      <author><first>Benjamin</first><last>Marie</last></author>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>3224&#8211;3230</pages>
      <abstract>State-of-the-art methods for unsupervised bilingual word embeddings (BWE) train a mapping function that maps pre-trained monolingual word embeddings into a bilingual space. Despite its remarkable results, unsupervised mapping is also well-known to be limited by the original dissimilarity between the word embedding spaces to be mapped. In this work, we propose a new approach that trains unsupervised BWE jointly on synthetic parallel data generated through unsupervised machine translation. We demonstrate that existing algorithms that jointly train BWE are very robust to noisy training data and show that unsupervised BWE jointly trained significantly outperform unsupervised mapped BWE in several cross-lingual NLP tasks.</abstract>
      <url hash="2835c165">P19-1312</url>
      <doi>10.18653/v1/P19-1312</doi>
      <bibkey>marie-fujita-2019-unsupervised-joint</bibkey>
    </paper>
    <paper id="314">
      <title>Is Word Segmentation Necessary for Deep Learning of <fixed-case>C</fixed-case>hinese Representations?</title>
      <author><first>Xiaoya</first><last>Li</last></author>
      <author><first>Yuxian</first><last>Meng</last></author>
      <author><first>Xiaofei</first><last>Sun</last></author>
      <author><first>Qinghong</first><last>Han</last></author>
      <author><first>Arianna</first><last>Yuan</last></author>
      <author><first>Jiwei</first><last>Li</last></author>
      <pages>3242&#8211;3252</pages>
      <abstract>Segmenting a chunk of text into words is usually the first step of processing Chinese text, but its necessity has rarely been explored. In this paper, we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing. We benchmark neural word-based models which rely on word segmentation against neural char-based models which do not involve word segmentation in four end-to-end NLP benchmark tasks: language modeling, machine translation, sentence matching/paraphrase and text classification. Through direct comparisons between these two types of models, we find that char-based models consistently outperform word-based models. Based on these observations, we conduct comprehensive experiments to study why word-based models underperform char-based models in these deep learning-based NLP tasks. We show that it is because word-based models are more vulnerable to data sparsity and the presence of out-of-vocabulary (OOV) words, and thus more prone to overfitting. We hope this paper could encourage researchers in the community to rethink the necessity of word segmentation in deep learning-based Chinese Natural Language Processing.</abstract>
      <url hash="1bfc2648">P19-1314</url>
      <doi>10.18653/v1/P19-1314</doi>
      <bibkey>li-etal-2019-word-segmentation</bibkey>
    </paper>
    <paper id="316">
      <title>On the Compositionality Prediction of Noun Phrases using Poincar&#233; Embeddings</title>
      <author><first>Abhik</first><last>Jana</last></author>
      <author><first>Dima</first><last>Puzyrev</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <pages>3263&#8211;3274</pages>
      <abstract>The compositionality degree of multiword expressions indicates to what extent the meaning of a phrase can be derived from the meaning of its constituents and their grammatical relations. Prediction of (non)-compositionality is a task that has been frequently addressed with distributional semantic models. We introduce a novel technique to blend hierarchical information with distributional information for predicting compositionality. In particular, we use hypernymy information of the multiword and its constituents encoded in the form of the recently introduced Poincar&#233; embeddings in addition to the distributional information to detect compositionality for noun phrases. Using a weighted average of the distributional similarity and a Poincar&#233; similarity function, we obtain consistent and substantial, statistically significant improvement across three gold standard datasets over state-of-the-art models based on distributional information only. Unlike traditional approaches that solely use an unsupervised setting, we have also framed the problem as a supervised task, obtaining comparable improvements. Further, we publicly release our Poincar&#233; embeddings, which are trained on the output of handcrafted lexical-syntactic patterns on a large corpus.</abstract>
      <url hash="a2f25618">P19-1316</url>
      <doi>10.18653/v1/P19-1316</doi>
      <bibkey>jana-etal-2019-compositionality</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="317">
      <title>Robust Representation Learning of Biomedical Names</title>
      <author><first>Minh C.</first><last>Phan</last></author>
      <author><first>Aixin</first><last>Sun</last></author>
      <author><first>Yi</first><last>Tay</last></author>
      <pages>3275&#8211;3285</pages>
      <abstract>Biomedical concepts are often mentioned in medical documents under different name variations (synonyms). This mismatch between surface forms is problematic, resulting in difficulties pertaining to learning effective representations. Consequently, this has tremendous implications such as rendering downstream applications inefficacious and/or potentially unreliable. This paper proposes a new framework for learning robust representations of biomedical names and terms. The idea behind our approach is to consider and encode contextual meaning, conceptual meaning, and the similarity between synonyms during the representation learning process. Via extensive experiments, we show that our proposed method outperforms other baselines on a battery of retrieval, similarity and relatedness benchmarks. Moreover, our proposed method is also able to compute meaningful representations for unseen names, resulting in high practical utility in real-world applications.</abstract>
      <url hash="5e4fe3d6">P19-1317</url>
      <doi>10.18653/v1/P19-1317</doi>
      <bibkey>phan-etal-2019-robust</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bc5cdr">BC5CDR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ncbi-disease-1">NCBI Disease</pwcdataset>
    </paper>
    <paper id="320">
      <title>Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks</title>
      <author><first>Shikhar</first><last>Vashishth</last></author>
      <author><first>Manik</first><last>Bhandari</last></author>
      <author><first>Prateek</first><last>Yadav</last></author>
      <author><first>Piyush</first><last>Rai</last></author>
      <author><first>Chiranjib</first><last>Bhattacharyya</last></author>
      <author><first>Partha</first><last>Talukdar</last></author>
      <pages>3308&#8211;3318</pages>
      <abstract>Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.</abstract>
      <url hash="26edfa15">P19-1320</url>
      <attachment type="supplementary" hash="3d445ede">P19-1320.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1320</doi>
      <bibkey>vashishth-etal-2019-incorporating</bibkey>
      <pwccode url="https://github.com/malllabiisc/WordGCN" additional="false">malllabiisc/WordGCN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="325">
      <title>Making Fast Graph-based Algorithms with Graph Metric Embeddings</title>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <author><first>Mohammad</first><last>Dorgham</last></author>
      <author><first>Oleksiy</first><last>Oliynyk</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>3349&#8211;3355</pages>
      <abstract>Graph measures, such as node distances, are inefficient to compute. We explore dense vector representations as an effective way to approximate the same information. We introduce a simple yet efficient and effective approach for learning graph embeddings. Instead of directly operating on the graph structure, our method takes structural measures of pairwise node similarities into account and learns dense node representations reflecting user-defined graph distance measures, such as e.g. the shortest path distance or distance measures that take information beyond the graph structure into account. We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings on semantic similarity and word sense disambiguation tasks.</abstract>
      <url hash="b9cffbf6">P19-1325</url>
      <doi>10.18653/v1/P19-1325</doi>
      <bibkey>kutuzov-etal-2019-making</bibkey>
      <pwccode url="https://github.com/uhh-lt/path2vec" additional="false">uhh-lt/path2vec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
    </paper>
    <paper id="328">
      <title><fixed-case>BERT</fixed-case>-based Lexical Substitution</title>
      <author><first>Wangchunshu</first><last>Zhou</last></author>
      <author><first>Tao</first><last>Ge</last></author>
      <author><first>Ke</first><last>Xu</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>3368&#8211;3373</pages>
      <abstract>Previous studies on lexical substitution tend to obtain substitute candidates by finding the target word&#8217;s synonyms from lexical resources (e.g., WordNet) and then rank the candidates based on its contexts. These approaches have two limitations: (1) They are likely to overlook good substitute candidates that are not the synonyms of the target words in the lexical resources; (2) They fail to take into account the substitution&#8217;s influence on the global context of the sentence. To address these issues, we propose an end-to-end BERT-based lexical substitution approach which can propose and validate substitute candidates without using any annotated data or manually curated resources. Our approach first applies dropout to the target word&#8217;s embedding for partially masking the word, allowing BERT to take balanced consideration of the target word&#8217;s semantics and contexts for proposing substitute candidates, and then validates the candidates based on their substitution&#8217;s influence on the global contextualized representation of the sentence. Experiments show our approach performs well in both proposing and ranking substitute candidates, achieving the state-of-the-art results in both LS07 and LS14 benchmarks.</abstract>
      <url hash="a93ac869">P19-1328</url>
      <attachment type="supplementary" hash="a48bd5c4">P19-1328.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1328</doi>
      <bibkey>zhou-etal-2019-bert</bibkey>
    </paper>
    <paper id="330">
      <title><fixed-case>H</fixed-case>igh<fixed-case>RES</fixed-case>: Highlight-based Reference-less Evaluation of Summarization</title>
      <author><first>Hardy</first><last>Hardy</last></author>
      <author><first>Shashi</first><last>Narayan</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>3381&#8211;3392</pages>
      <abstract>There has been substantial progress in summarization research enabled by the availability of novel, often large-scale, datasets and recent advances on neural network-based approaches. However, manual evaluation of the system generated summaries is inconsistent due to the difficulty the task poses to human non-expert readers. To address this issue, we propose a novel approach for manual evaluation, Highlight-based Reference-less Evaluation of Summarization (HighRES), in which summaries are assessed by multiple annotators against the source document via manually highlighted salient content in the latter. Thus summary assessment on the source document by human judges is facilitated, while the highlights can be used for evaluating multiple systems. To validate our approach we employ crowd-workers to augment with highlights a recently proposed dataset and compare two state-of-the-art systems. We demonstrate that HighRES improves inter-annotator agreement in comparison to using the source document directly, while they help emphasize differences among systems that would be ignored under other evaluation approaches.</abstract>
      <url hash="a905a1cd">P19-1330</url>
      <attachment type="supplementary" hash="fe39d2a8">P19-1330.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/384768559" />
      <doi>10.18653/v1/P19-1330</doi>
      <bibkey>hardy-etal-2019-highres</bibkey>
      <pwccode url="https://github.com/sheffieldnlp/highres" additional="false">sheffieldnlp/highres</pwccode>
    </paper>
    <paper id="331">
      <title><fixed-case>E</fixed-case>dit<fixed-case>NTS</fixed-case>: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing</title>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Zichao</first><last>Li</last></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>3393&#8211;3402</pages>
      <abstract>We present the first sentence simplification model that learns explicit edit operations (ADD, DELETE, and KEEP) via a neural programmer-interpreter approach. Most current neural sentence simplification systems are variants of sequence-to-sequence models adopted from machine translation. These methods learn to simplify sentences as a byproduct of the fact that they are trained on complex-simple sentence pairs. By contrast, our neural programmer-interpreter is directly trained to predict explicit edit operations on targeted parts of the input sentence, resembling the way that humans perform simplification and revision. Our model outperforms previous state-of-the-art neural sentence simplification models (without external knowledge) by large margins on three benchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89 WikiSmall, +1.41 Newsela), and is judged by humans to produce overall better and simpler output sentences.</abstract>
      <url hash="fe115747">P19-1331</url>
      <video href="https://vimeo.com/384771870" />
      <doi>10.18653/v1/P19-1331</doi>
      <bibkey>dong-etal-2019-editnts</bibkey>
      <pwccode url="https://github.com/yuedongP/EditNTS" additional="false">yuedongP/EditNTS</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/turkcorpus">TurkCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikilarge">WikiLarge</pwcdataset>
    </paper>
    <paper id="332">
      <title>Decomposable Neural Paraphrase Generation</title>
      <author><first>Zichao</first><last>Li</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Lifeng</first><last>Shang</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>3403&#8211;3414</pages>
      <abstract>Paraphrasing exists at different granularity levels, such as lexical level, phrasal level and sentential level. This paper presents Decomposable Neural Paraphrase Generator (DNPG), a Transformer-based model that can learn and generate paraphrases of a sentence at different levels of granularity in a disentangled way. Specifically, the model is composed of multiple encoders and decoders with different structures, each of which corresponds to a specific granularity. The empirical study shows that the decomposition mechanism of DNPG makes paraphrase generation more interpretable and controllable. Based on DNPG, we further develop an unsupervised domain adaptation method for paraphrase generation. Experimental results show that the proposed model achieves competitive in-domain performance compared to state-of-the-art neural models, and significantly better performance when adapting to a new domain.</abstract>
      <url hash="50945a83">P19-1332</url>
      <video href="https://vimeo.com/384795570" />
      <doi>10.18653/v1/P19-1332</doi>
      <bibkey>li-etal-2019-decomposable</bibkey>
    </paper>
    <paper id="334">
      <title>Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference</title>
      <author><first>Tom</first><last>McCoy</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>3428&#8211;3448</pages>
      <abstract>A machine learning system can score well on a given test set by relying on heuristics that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics: the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these heuristics, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the heuristics fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on HANS, suggesting that they have indeed adopted these heuristics. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.</abstract>
      <url hash="5fe475e9">P19-1334</url>
      <video href="https://vimeo.com/384776891" />
      <doi>10.18653/v1/P19-1334</doi>
      <bibkey>mccoy-etal-2019-right</bibkey>
      <pwccode url="https://github.com/tommccoy1/hans" additional="true">tommccoy1/hans</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="336">
      <title>Dual Adversarial Neural Transfer for Low-Resource Named Entity Recognition</title>
      <author><first>Joey Tianyi</first><last>Zhou</last></author>
      <author><first>Hao</first><last>Zhang</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Hongyuan</first><last>Zhu</last></author>
      <author><first>Meng</first><last>Fang</last></author>
      <author><first>Rick Siow Mong</first><last>Goh</last></author>
      <author><first>Kenneth</first><last>Kwok</last></author>
      <pages>3461&#8211;3471</pages>
      <abstract>We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER). Specifically, two variants of DATNet, i.e., DATNet-F and DATNet-P, are investigated to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD). Additionally, adversarial training is adopted to boost model generalization. In experiments, we examine the effects of different components in DATNet across domains and languages and show that significant improvement can be obtained especially for low-resource data, without augmenting any additional hand-crafted features and pre-trained language model.</abstract>
      <url hash="d585aac2">P19-1336</url>
      <video href="https://vimeo.com/384782139" />
      <doi>10.18653/v1/P19-1336</doi>
      <bibkey>zhou-etal-2019-dual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="338">
      <title>An Imitation Learning Approach to Unsupervised Parsing</title>
      <author><first>Bowen</first><last>Li</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Frank</first><last>Keller</last></author>
      <pages>3485&#8211;3492</pages>
      <abstract>Recently, there has been an increasing interest in unsupervised parsers that optimize semantically oriented objectives, typically using reinforcement learning. Unfortunately, the learned trees often do not match actual syntax trees well. Shen et al. (2018) propose a structured attention mechanism for language modeling (PRPN), which induces better syntactic structures but relies on ad hoc heuristics. Also, their model lacks interpretability as it is not grounded in parsing actions. In our work, we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by PRPN to a Tree-LSTM model with discrete parsing actions. Its policy is then refined by Gumbel-Softmax training towards a semantically oriented objective. We evaluate our approach on the All Natural Language Inference dataset and show that it achieves a new state of the art in terms of parsing F-score, outperforming our base models, including PRPN.</abstract>
      <url hash="6ebb1768">P19-1338</url>
      <video href="https://vimeo.com/384800134" />
      <doi>10.18653/v1/P19-1338</doi>
      <bibkey>li-etal-2019-imitation</bibkey>
      <pwccode url="https://github.com/libowen2121/Imitation-Learning-for-Unsup-Parsing" additional="false">libowen2121/Imitation-Learning-for-Unsup-Parsing</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
    </paper>
    <paper id="339">
      <title>Women&#8217;s Syntactic Resilience and Men&#8217;s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing</title>
      <author><first>Aparna</first><last>Garimella</last></author>
      <author><first>Carmen</first><last>Banea</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>3493&#8211;3498</pages>
      <abstract>Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for part-of-speech tagging and dependency parsing have still not adapted to account for these differences. To address this, we annotate the Wall Street Journal part of the Penn Treebank with the gender information of the articles&#8217; authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous part-of-speech tags and syntactic relations whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community.</abstract>
      <url hash="e25b82c0">P19-1339</url>
      <video href="https://vimeo.com/384801759" />
      <doi>10.18653/v1/P19-1339</doi>
      <bibkey>garimella-etal-2019-womens</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="340">
      <title>Multilingual Constituency Parsing with Self-Attention and Pre-Training</title>
      <author><first>Nikita</first><last>Kitaev</last></author>
      <author><first>Steven</first><last>Cao</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <pages>3499&#8211;3505</pages>
      <abstract>We show that constituency parsing benefits from unsupervised pre-training across a variety of languages and a range of pre-training conditions. We first compare the benefits of no pre-training, fastText, ELMo, and BERT for English and find that BERT outperforms ELMo, in large part due to increased model capacity, whereas ELMo in turn outperforms the non-contextual fastText embeddings. We also find that pre-training is beneficial across all 11 languages tested; however, large model sizes (more than 100 million parameters) make it computationally expensive to train separate models for each language. To address this shortcoming, we show that joint multilingual pre-training and fine-tuning allows sharing all but a small number of parameters between ten languages in the final model. The 10x reduction in model size compared to fine-tuning one model per language causes only a 3.2% relative error increase in aggregate. We further explore the idea of joint fine-tuning and show that it gives low-resource languages a way to benefit from the larger datasets of other languages. Finally, we demonstrate new state-of-the-art results for 11 languages, including English (95.8 F1) and Chinese (91.8 F1).</abstract>
      <url hash="3f471e3f">P19-1340</url>
      <video href="https://vimeo.com/384782901" />
      <doi>10.18653/v1/P19-1340</doi>
      <bibkey>kitaev-etal-2019-multilingual</bibkey>
      <pwccode url="https://github.com/nikitakit/self-attentive-parser" additional="true">nikitakit/self-attentive-parser</pwccode>
    </paper>
    <paper id="341">
      <title>A Multilingual <fixed-case>BPE</fixed-case> Embedding Space for Universal Sentiment Lexicon Induction</title>
      <author><first>Mengjie</first><last>Zhao</last></author>
      <author><first>Hinrich</first><last>Sch&#252;tze</last></author>
      <pages>3506&#8211;3517</pages>
      <abstract>We present a new method for sentiment lexicon induction that is designed to be applicable to the entire range of typological diversity of the world&#8217;s languages. We evaluate our method on Parallel Bible Corpus+ (PBC+), a parallel corpus of 1593 languages. The key idea is to use Byte Pair Encodings (BPEs) as basic units for multilingual embeddings. Through zero-shot transfer from English sentiment, we learn a seed lexicon for each language in the domain of PBC+. Through domain adaptation, we then generalize the domain-specific lexicon to a general one. We show &#8211; across typologically diverse languages in PBC+ &#8211; good quality of seed and general-domain sentiment lexicons by intrinsic and extrinsic and by automatic and human evaluation. We make freely available our code, seed sentiment lexicons for all 1593 languages and induced general-domain sentiment lexicons for 200 languages.</abstract>
      <url hash="5af8e7a9">P19-1341</url>
      <video href="https://vimeo.com/384801834" />
      <doi>10.18653/v1/P19-1341</doi>
      <bibkey>zhao-schutze-2019-multilingual</bibkey>
    </paper>
    <paper id="343">
      <title>Improved Sentiment Detection via Label Transfer from Monolingual to Synthetic Code-Switched Text</title>
      <author><first>Bidisha</first><last>Samanta</last></author>
      <author><first>Niloy</first><last>Ganguly</last></author>
      <author><first>Soumen</first><last>Chakrabarti</last></author>
      <pages>3528&#8211;3537</pages>
      <abstract>Multilingual writers and speakers often alternate between two languages in a single discourse. This practice is called &#8220;code-switching&#8221;. Existing sentiment detection methods are usually trained on sentiment-labeled monolingual text. Manually labeled code-switched text, especially involving minority languages, is extremely rare. Consequently, the best monolingual methods perform relatively poorly on code-switched text. We present an effective technique for synthesizing labeled code-switched text from labeled monolingual text, which is relatively readily available. The idea is to replace carefully selected subtrees of constituency parses of sentences in the resource-rich language with suitable token spans selected from automatic translations to the resource-poor language. By augmenting the scarce labeled code-switched text with plentiful synthetic labeled code-switched text, we achieve significant improvements in sentiment labeling accuracy (1.5%, 5.11% 7.20%) for three different language pairs (English-Hindi, English-Spanish and English-Bengali). The improvement is even significant in hatespeech detection whereby we achieve a 4% improvement using only synthetic code-switched data (6% with data augmentation).</abstract>
      <url hash="8d6f1312">P19-1343</url>
      <video href="https://vimeo.com/384803075" />
      <doi>10.18653/v1/P19-1343</doi>
      <bibkey>samanta-etal-2019-improved</bibkey>
      <pwccode url="https://github.com/bidishasamantakgp/2019_CSGen_ACL" additional="false">bidishasamantakgp/2019_CSGen_ACL</pwccode>
    </paper>
    <paper id="346">
      <title><fixed-case>ELI</fixed-case>5: Long Form Question Answering</title>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Yacine</first><last>Jernite</last></author>
      <author><first>Ethan</first><last>Perez</last></author>
      <author><first>David</first><last>Grangier</last></author>
      <author><first>Jason</first><last>Weston</last></author>
      <author><first>Michael</first><last>Auli</last></author>
      <pages>3558&#8211;3567</pages>
      <abstract>We introduce the first large-scale corpus for long form question answering, a task requiring elaborate and in-depth answers to open-ended questions. The dataset comprises 270K threads from the Reddit forum &#8220;Explain Like I&#8217;m Five&#8221; (ELI5) where an online community provides answers to questions which are comprehensible by five year olds. Compared to existing datasets, ELI5 comprises diverse questions requiring multi-sentence answers. We provide a large set of web documents to help answer the question. Automatic and human evaluations show that an abstractive model trained with a multi-task objective outperforms conventional Seq2Seq, language modeling, as well as a strong extractive baseline.However, our best model is still far from human performance since raters prefer gold responses in over 86% of cases, leaving ample opportunity for future improvement.</abstract>
      <url hash="087127be">P19-1346</url>
      <attachment type="supplementary" hash="95e67ec1">P19-1346.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/384783066" />
      <doi>10.18653/v1/P19-1346</doi>
      <bibkey>fan-etal-2019-eli5</bibkey>
      <pwccode url="https://github.com/facebookresearch/ELI5" additional="true">facebookresearch/ELI5</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/eli5">ELI5</pwcdataset>
    </paper>
    <paper id="347">
      <title>Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension</title>
      <author><first>Daesik</first><last>Kim</last></author>
      <author><first>Seonhoon</first><last>Kim</last></author>
      <author><first>Nojun</first><last>Kwak</last></author>
      <pages>3568&#8211;3584</pages>
      <abstract>In this work, we introduce a novel algorithm for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of the TQA dataset. First, solving the TQA problems requires to comprehend multi-modal contexts in complicated input data. To tackle this issue of extracting knowledge features from long text lessons and merging them with visual features, we establish a context graph from texts and images, and propose a new module f-GCN based on graph convolutional networks (GCN). Second, scientific terms are not spread over the chapters and subjects are split in the TQA dataset. To overcome this so called &#8216;out-of-domain&#8217; issue, before learning QA problems, we introduce a novel self-supervised open-set learning process without any annotations. The experimental results show that our model significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating f-GCN for extracting knowledge from multi-modal contexts and our newly proposed self-supervised learning process are effective for TQA problems.</abstract>
      <url hash="d522e341">P19-1347</url>
      <video href="https://vimeo.com/385504540" permission="false" />
      <doi>10.18653/v1/P19-1347</doi>
      <bibkey>kim-etal-2019-textbook</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tqa">TQA</pwcdataset>
    </paper>
    <paper id="350">
      <title>Psycholinguistics Meets Continual Learning: Measuring Catastrophic Forgetting in Visual Question Answering</title>
      <author><first>Claudio</first><last>Greco</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Raquel</first><last>Fern&#225;ndez</last></author>
      <author><first>Raffaella</first><last>Bernardi</last></author>
      <pages>3601&#8211;3605</pages>
      <abstract>We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA). Motivated by evidence from psycholinguistics, we devise a set of linguistically-informed VQA tasks, which differ by the types of questions involved (Wh-questions and polar questions). We test what impact task difficulty has on continual learning, and whether the order in which a child acquires question types facilitates computational models. Our results show that dramatic forgetting is at play and that task difficulty and order matter. Two well-known current continual learning methods mitigate the problem only to a limiting degree.</abstract>
      <url hash="cbef0d73">P19-1350</url>
      <attachment type="supplementary" hash="ebdcc766">P19-1350.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/384787273" />
      <doi>10.18653/v1/P19-1350</doi>
      <bibkey>greco-etal-2019-psycholinguistics</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="354">
      <title>Assessing the Ability of Self-Attention Networks to Learn Word Order</title>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Longyue</first><last>Wang</last></author>
      <author><first>Derek F.</first><last>Wong</last></author>
      <author><first>Lidia S.</first><last>Chao</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>3635&#8211;3644</pages>
      <abstract>Self-attention networks (SAN) have attracted a lot of interests due to their high parallelization and strong performance on a variety of NLP tasks, e.g. machine translation. Due to the lack of recurrence structure such as recurrent neural networks (RNN), SAN is ascribed to be weak at learning positional information of words for sequence modeling. However, neither this speculation has been empirically confirmed, nor explanations for their strong performances on machine translation tasks when &#8220;lacking positional information&#8221; have been explored. To this end, we propose a novel word reordering detection task to quantify how well the word order information learned by SAN and RNN. Specifically, we randomly move one word to another position, and examine whether a trained model can detect both the original and inserted positions. Experimental results reveal that: 1) SAN trained on word reordering detection indeed has difficulty learning the positional information even with the position embedding; and 2) SAN trained on machine translation learns better positional information than its RNN counterpart, in which position embedding plays a critical role. Although recurrence structure make the model more universally-effective on learning word order, learning objectives matter more in the downstream tasks such as machine translation.</abstract>
      <url hash="fddc5e1f">P19-1354</url>
      <video href="https://vimeo.com/384961600" />
      <doi>10.18653/v1/P19-1354</doi>
      <bibkey>yang-etal-2019-assessing</bibkey>
      <pwccode url="https://github.com/baosongyang/WRD" additional="false">baosongyang/WRD</pwccode>
    </paper>
    <paper id="355">
      <title>Energy and Policy Considerations for Deep Learning in <fixed-case>NLP</fixed-case></title>
      <author><first>Emma</first><last>Strubell</last></author>
      <author><first>Ananya</first><last>Ganesh</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>3645&#8211;3650</pages>
      <abstract>Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.</abstract>
      <url hash="a7d39254">P19-1355</url>
      <video href="https://vimeo.com/384787604" />
      <doi>10.18653/v1/P19-1355</doi>
      <bibkey>strubell-etal-2019-energy</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="359">
      <title>Generating Responses with a Specific Emotion in Dialog</title>
      <author><first>Zhenqiao</first><last>Song</last></author>
      <author><first>Xiaoqing</first><last>Zheng</last></author>
      <author><first>Lu</first><last>Liu</last></author>
      <author><first>Mu</first><last>Xu</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>3685&#8211;3695</pages>
      <abstract>It is desirable for dialog systems to have capability to express specific emotions during a conversation, which has a direct, quantifiable impact on improvement of their usability and user satisfaction. After a careful investigation of real-life conversation data, we found that there are at least two ways to express emotions with language. One is to describe emotional states by explicitly using strong emotional words; another is to increase the intensity of the emotional experiences by implicitly combining neutral words in distinct ways. We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework. Experimental results showed EmoDS performed better than the baselines in BLEU, diversity and the quality of emotional expression.</abstract>
      <url hash="4a6dff4b">P19-1359</url>
      <doi>10.18653/v1/P19-1359</doi>
      <bibkey>song-etal-2019-generating</bibkey>
    </paper>
    <paper id="360">
      <title>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</title>
      <author><first>Wenhu</first><last>Chen</last></author>
      <author><first>Jianshu</first><last>Chen</last></author>
      <author><first>Pengda</first><last>Qin</last></author>
      <author><first>Xifeng</first><last>Yan</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>3696&#8211;3709</pages>
      <abstract>Semantically controlled neural response generation on limited-domain has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the graph. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</abstract>
      <url hash="d8536665">P19-1360</url>
      <doi>10.18653/v1/P19-1360</doi>
      <bibkey>chen-etal-2019-semantically</bibkey>
      <pwccode url="https://github.com/budzianowski/multiwoz" additional="true">budzianowski/multiwoz</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multiwoz">MultiWOZ</pwcdataset>
    </paper>
    <paper id="365">
      <title>Comparison of Diverse Decoding Methods from Conditional Language Models</title>
      <author><first>Daphne</first><last>Ippolito</last></author>
      <author><first>Reno</first><last>Kriz</last></author>
      <author><first>Jo&#227;o</first><last>Sedoc</last></author>
      <author><first>Maria</first><last>Kustikova</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>3752&#8211;3762</pages>
      <abstract>While conditional language models have greatly improved in their ability to output high quality natural language, many NLP applications benefit from being able to generate a diverse set of candidate sequences. Diverse decoding strategies aim to, within a given-sized candidate list, cover as much of the space of high-quality outputs as possible, leading to improvements for tasks that rerank and combine candidate outputs. Standard decoding methods, such as beam search, optimize for generating high likelihood sequences rather than diverse ones, though recent work has focused on increasing diversity in these methods. In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from a conditional language model. In addition, we present a novel method where we over-sample candidates, then use clustering to remove similar sequences, thus achieving high diversity without sacrificing quality.</abstract>
      <url hash="38a2aa76">P19-1365</url>
      <doi>10.18653/v1/P19-1365</doi>
      <bibkey>ippolito-etal-2019-comparison</bibkey>
      <pwccode url="https://github.com/rekriz11/DeDiv" additional="false">rekriz11/DeDiv</pwccode>
    </paper>
    <paper id="366">
      <title>Retrieval-Enhanced Adversarial Training for Neural Response Generation</title>
      <author><first>Qingfu</first><last>Zhu</last></author>
      <author><first>Lei</first><last>Cui</last></author>
      <author><first>Wei-Nan</first><last>Zhang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>3763&#8211;3773</pages>
      <abstract>Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.</abstract>
      <url hash="32e6c1e1">P19-1366</url>
      <doi>10.18653/v1/P19-1366</doi>
      <bibkey>zhu-etal-2019-retrieval</bibkey>
    </paper>
    <paper id="367">
      <title>Vocabulary Pyramid Network: Multi-Pass Encoding and Decoding with Multi-Level Vocabularies for Response Generation</title>
      <author><first>Cao</first><last>Liu</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>3774&#8211;3783</pages>
      <abstract>We study the task of response generation. Conventional methods employ a fixed vocabulary and one-pass decoding, which not only make them prone to safe and general responses but also lack further refining to the first generated raw sequence. To tackle the above two problems, we present a Vocabulary Pyramid Network (VPN) which is able to incorporate multi-pass encoding and decoding with multi-level vocabularies into response generation. Specifically, the dialogue input and output are represented by multi-level vocabularies which are obtained from hierarchical clustering of raw words. Then, multi-pass encoding and decoding are conducted on the multi-level vocabularies. Since VPN is able to leverage rich encoding and decoding information with multi-level vocabularies, it has the potential to generate better responses. Experiments on English Twitter and Chinese Weibo datasets demonstrate that VPN remarkably outperforms strong baselines.</abstract>
      <url hash="d23c9763">P19-1367</url>
      <doi>10.18653/v1/P19-1367</doi>
      <bibkey>liu-etal-2019-vocabulary</bibkey>
    </paper>
    <paper id="368">
      <title>On-device Structured and Context Partitioned Projection Networks</title>
      <author><first>Sujith</first><last>Ravi</last></author>
      <author><first>Zornitsa</first><last>Kozareva</last></author>
      <pages>3784&#8211;3793</pages>
      <abstract>A challenging problem in on-device text classification is to build highly accurate neural models that can fit in small memory footprint and have low latency. To address this challenge, we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections. We show that this results in accelerated inference and performance improvements. We conduct extensive evaluation on multiple conversational tasks and languages such as English, Japanese, Spanish and French. Our SGNN++ model significantly outperforms all baselines, improves upon existing on-device neural models and even surpasses RNN, CNN and BiLSTM models on dialog act and intent prediction. Through a series of ablation studies we show the impact of the partitioned projections and structured information leading to 10% improvement. We study the impact of the model size on accuracy and introduce quatization-aware training for SGNN++ to further reduce the model size while preserving the same quality. Finally, we show fast inference on mobile phones.</abstract>
      <url hash="2b4ef219">P19-1368</url>
      <doi>10.18653/v1/P19-1368</doi>
      <bibkey>ravi-kozareva-2019-device</bibkey>
    </paper>
    <paper id="369">
      <title>Proactive Human-Machine Conversation with Explicit Conversation Goal</title>
      <author><first>Wenquan</first><last>Wu</last></author>
      <author><first>Zhen</first><last>Guo</last></author>
      <author><first>Xiangyang</first><last>Zhou</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <author><first>Xiyuan</first><last>Zhang</last></author>
      <author><first>Rongzhong</first><last>Lian</last></author>
      <author><first>Haifeng</first><last>Wang</last></author>
      <pages>3794&#8211;3804</pages>
      <abstract>Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy: it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent: endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new dataset named Konv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a knowledge graph and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. Konv enables a very challenging task as the model needs to both understand dialogue and plan over the given knowledge graph. We establish baseline results on this dataset (about 270K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The baseline systems along with the dataset are publicly available.</abstract>
      <url hash="10012d41">P19-1369</url>
      <doi>10.18653/v1/P19-1369</doi>
      <bibkey>wu-etal-2019-proactive</bibkey>
    </paper>
    <paper id="371">
      <title>Learning to Abstract for Memory-augmented Conversational Response Generation</title>
      <author><first>Zhiliang</first><last>Tian</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Xiaopeng</first><last>Li</last></author>
      <author><first>Nevin L.</first><last>Zhang</last></author>
      <pages>3816&#8211;3825</pages>
      <abstract>Neural generative models for open-domain chit-chat conversations have become an active area of research in recent years. A critical issue with most existing generative models is that the generated responses lack informativeness and diversity. A few researchers attempt to leverage the results of retrieval models to strengthen the generative models, but these models are limited by the quality of the retrieval results. In this work, we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the memory to assist the response generation. Our model clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation. Experimental results show that our model outperforms other competitive baselines.</abstract>
      <url hash="5cf9203e">P19-1371</url>
      <doi>10.18653/v1/P19-1371</doi>
      <bibkey>tian-etal-2019-learning</bibkey>
      <pwccode url="https://github.com/tianzhiliang/MemoryAugDialog" additional="false">tianzhiliang/MemoryAugDialog</pwccode>
    </paper>
    <paper id="374">
      <title>A Large-Scale Corpus for Conversation Disentanglement</title>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <author><first>Sai R.</first><last>Gouravajhala</last></author>
      <author><first>Joseph J.</first><last>Peper</last></author>
      <author><first>Vignesh</first><last>Athreya</last></author>
      <author><first>Chulaka</first><last>Gunasekara</last></author>
      <author><first>Jatin</first><last>Ganhotra</last></author>
      <author><first>Siva Sankalp</first><last>Patel</last></author>
      <author><first>Lazaros C</first><last>Polymenakos</last></author>
      <author><first>Walter</first><last>Lasecki</last></author>
      <pages>3846&#8211;3856</pages>
      <abstract>Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our data is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include context. We use our data to re-examine prior work, in particular, finding that 89% of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.</abstract>
      <url hash="a1256dea">P19-1374</url>
      <attachment type="supplementary" hash="f64b2186">P19-1374.Supplementary.pdf</attachment>
      <attachment type="software" hash="e7686716">P19-1374.Software.tgz</attachment>
      <doi>10.18653/v1/P19-1374</doi>
      <bibkey>kummerfeld-etal-2019-large</bibkey>
      <pwccode url="https://github.com/jkkummerfeld/irc-disentanglement" additional="true">jkkummerfeld/irc-disentanglement</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/irc-disentanglement">irc-disentanglement</pwcdataset>
    </paper>
    <paper id="375">
      <title>Self-Supervised Dialogue Learning</title>
      <author><first>Jiawei</first><last>Wu</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>3857&#8211;3867</pages>
      <abstract>The sequential order of utterances is often meaningful in coherent dialogues, and the order changes of utterances could lead to low-quality and incoherent conversations. We consider the order information as a crucial supervised signal for dialogue learning, which, however, has been neglected by many previous dialogue systems. Therefore, in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues. Given a sampled utterance pair triple, the task is to predict whether it is ordered or misordered. Then we propose a sampling-based self-supervised network SSN to perform the prediction with sampled triple references from previous dialogue history. Furthermore, we design a joint learning framework where SSN can guide the dialogue systems towards more coherent and relevant dialogue learning through adversarial training. We demonstrate that the proposed methods can be applied to both open-domain and task-oriented dialogue scenarios, and achieve the new state-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking datasets.</abstract>
      <url hash="d271b832">P19-1375</url>
      <doi>10.18653/v1/P19-1375</doi>
      <bibkey>wu-etal-2019-self</bibkey>
    </paper>
    <paper id="376">
      <title>Are we there yet? Encoder-decoder neural networks as cognitive models of <fixed-case>E</fixed-case>nglish past tense inflection</title>
      <author><first>Maria</first><last>Corkery</last></author>
      <author><first>Yevgen</first><last>Matusevych</last></author>
      <author><first>Sharon</first><last>Goldwater</last></author>
      <pages>3868&#8211;3877</pages>
      <abstract>The cognitive mechanisms needed to account for the English past tense have long been a subject of debate in linguistics and cognitive science. Neural network models were proposed early on, but were shown to have clear flaws. Recently, however, Kirov and Cotterell (2018) showed that modern encoder-decoder (ED) models overcome many of these flaws. They also presented evidence that ED models demonstrate humanlike performance in a nonce-word task. Here, we look more closely at the behaviour of their model in this task. We find that (1) the model exhibits instability across multiple simulations in terms of its correlation with human data, and (2) even when results are aggregated across simulations (treating each simulation as an individual human participant), the fit to the human data is not strong&#8212;worse than an older rule-based model. These findings hold up through several alternative training regimes and evaluation measures. Although other neural architectures might do better, we conclude that there is still insufficient evidence to claim that neural nets are a good cognitive model for this task.</abstract>
      <url hash="e3420d7f">P19-1376</url>
      <doi>10.18653/v1/P19-1376</doi>
      <bibkey>corkery-etal-2019-yet</bibkey>
    </paper>
    <paper id="377">
      <title>A Spreading Activation Framework for Tracking Conceptual Complexity of Texts</title>
      <author><first>Ioana</first><last>Hulpu&#537;</last></author>
      <author><first>Sanja</first><last>&#352;tajner</last></author>
      <author><first>Heiner</first><last>Stuckenschmidt</last></author>
      <pages>3878&#8211;3887</pages>
      <abstract>We propose an unsupervised approach for assessing conceptual complexity of texts, based on spreading activation. Using DBpedia knowledge graph as a proxy to long-term memory, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as semantic priming, sentence wrap-up, and forgetting. We show that our models capture various aspects of conceptual text complexity and significantly outperform current state of the art.</abstract>
      <url hash="64f2dc26">P19-1377</url>
      <doi>10.18653/v1/P19-1377</doi>
      <bibkey>hulpus-etal-2019-spreading</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
    </paper>
    <paper id="379">
      <title>Diachronic Sense Modeling with Deep Contextualized Word Embeddings: An Ecological View</title>
      <author><first>Renfen</first><last>Hu</last></author>
      <author><first>Shen</first><last>Li</last></author>
      <author><first>Shichen</first><last>Liang</last></author>
      <pages>3899&#8211;3908</pages>
      <abstract>Diachronic word embeddings have been widely used in detecting temporal changes. However, existing methods face the meaning conflation deficiency by representing a word as a single vector at each time period. To address this issue, this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes. The experiments show that our framework is effective in representing fine-grained word senses, and it brings a significant improvement in word change detection task. Furthermore, we model the word change from an ecological viewpoint, and sketch two interesting sense behaviors in the process of language evolution, i.e. sense competition and sense cooperation.</abstract>
      <url hash="432abfed">P19-1379</url>
      <doi>10.18653/v1/P19-1379</doi>
      <bibkey>hu-etal-2019-diachronic</bibkey>
    </paper>
    <paper id="380">
      <title>Miss Tools and Mr Fruit: Emergent Communication in Agents Learning about Object Affordances</title>
      <author><first>Diane</first><last>Bouchacourt</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>3909&#8211;3918</pages>
      <abstract>Recent research studies communication emergence in communities of deep network agents assigned a joint task, hoping to gain insights on human language evolution. We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants. By conducting a thorough pragmatic and semantic analysis of the emergent protocol, we show that the agents solve the shared task through genuine bilateral, referential communication. However, the agents develop multiple idiolects, which makes us conclude that full symmetry is not a sufficient condition for a common language to emerge.</abstract>
      <url hash="a5fd3bf7">P19-1380</url>
      <attachment type="supplementary" hash="3c888cde">P19-1380.Supplementary.zip</attachment>
      <doi>10.18653/v1/P19-1380</doi>
      <bibkey>bouchacourt-baroni-2019-miss</bibkey>
    </paper>
    <paper id="381">
      <title><fixed-case>CNN</fixed-case>s found to jump around more skillfully than <fixed-case>RNN</fixed-case>s: Compositional Generalization in Seq2seq Convolutional Networks</title>
      <author><first>Roberto</first><last>Dess&#236;</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>3919&#8211;3923</pages>
      <abstract>Lake and Baroni (2018) introduced the SCAN dataset probing the ability of seq2seq models to capture compositional generalizations, such as inferring the meaning of &#8220;jump around&#8221; 0-shot from the component words. Recurrent networks (RNNs) were found to completely fail the most challenging generalization cases. We test here a convolutional network (CNN) on these tasks, reporting hugely improved performance with respect to RNNs. Despite the big improvement, the CNN has however not induced systematic rules, suggesting that the difference between compositional and non-compositional behaviour is not clear-cut.</abstract>
      <url hash="70e0bc70">P19-1381</url>
      <doi>10.18653/v1/P19-1381</doi>
      <bibkey>dessi-baroni-2019-cnns</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/scan">SCAN</pwcdataset>
    </paper>
    <paper id="385">
      <title>Attention-based Conditioning Methods for External Knowledge Integration</title>
      <author><first>Katerina</first><last>Margatina</last></author>
      <author><first>Christos</first><last>Baziotis</last></author>
      <author><first>Alexandros</first><last>Potamianos</last></author>
      <pages>3944&#8211;3951</pages>
      <abstract>In this paper, we present a novel approach for incorporating external knowledge in Recurrent Neural Networks (RNNs). We propose the integration of lexicon features into the self-attention mechanism of RNN-based architectures. This form of conditioning on the attention distribution, enforces the contribution of the most salient words for the task at hand. We introduce three methods, namely attentional concatenation, feature-based gating and affine transformation. Experiments on six benchmark datasets show the effectiveness of our methods. Attentional feature-based gating yields consistent performance improvement across tasks. Our approach is implemented as a simple add-on module for RNN-based models with minimal computational overhead and can be adapted to any deep neural architecture.</abstract>
      <url hash="96f0553e">P19-1385</url>
      <doi>10.18653/v1/P19-1385</doi>
      <bibkey>margatina-etal-2019-attention</bibkey>
      <pwccode url="https://github.com/mourga/affective-attention" additional="false">mourga/affective-attention</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="391">
      <title>Crowdsourcing and Validating Event-focused Emotion Corpora for <fixed-case>G</fixed-case>erman and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Enrica</first><last>Troiano</last></author>
      <author><first>Sebastian</first><last>Pad&#243;</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>4005&#8211;4011</pages>
      <abstract>Sentiment analysis has a range of corpora available across multiple languages. For emotion analysis, the situation is more limited, which hinders potential research on crosslingual modeling and the development of predictive models for other languages. In this paper, we fill this gap for German by constructing deISEAR, a corpus designed in analogy to the well-established English ISEAR emotion dataset. Motivated by Scherer&#8217;s appraisal theory, we implement a crowdsourcing experiment which consists of two steps. In step 1, participants create descriptions of emotional events for a given emotion. In step 2, five annotators assess the emotion expressed by the texts. We show that transferring an emotion classification model from the original English ISEAR to the German crowdsourced deISEAR via machine translation does not, on average, cause a performance drop.</abstract>
      <url hash="d861e01d">P19-1391</url>
      <attachment type="supplementary" hash="f4ab35b9">P19-1391.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1391</doi>
      <bibkey>troiano-etal-2019-crowdsourcing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/event-focused-emotion-corpora-for-german-and">Event-focused Emotion Corpora for German and English</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/isear">ISEAR</pwcdataset>
    </paper>
    <paper id="393">
      <title>Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation</title>
      <author><first>Cunxiang</first><last>Wang</last></author>
      <author><first>Shuailong</first><last>Liang</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Xiaonan</first><last>Li</last></author>
      <author><first>Tian</first><last>Gao</last></author>
      <pages>4020&#8211;4026</pages>
      <abstract>Introducing common sense to natural language understanding systems has received increasing research attention. It remains a fundamental question on how to evaluate whether a system has the sense-making capability. Existing benchmarks measure common sense knowledge indirectly or without reasoning. In this paper, we release a benchmark to directly test whether a system can differentiate natural language statements that make sense from those that do not make sense. In addition, a system is asked to identify the most crucial reason why a statement does not make sense. We evaluate models trained over large-scale language modeling tasks as well as human performance, showing that there are different challenges for system sense-making.</abstract>
      <url hash="f0ca64e3">P19-1393</url>
      <doi>10.18653/v1/P19-1393</doi>
      <bibkey>wang-etal-2019-make</bibkey>
      <pwccode url="https://github.com/wangcunxiang/Sen-Making-and-Explanation" additional="true">wangcunxiang/Sen-Making-and-Explanation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/copa">COPA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wsc">WSC</pwcdataset>
    </paper>
    <paper id="397">
      <title>Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning</title>
      <author><first>Shuai</first><last>Tang</last></author>
      <author><first>Virginia R.</first><last>de Sa</last></author>
      <pages>4050&#8211;4060</pages>
      <abstract>Encoder-decoder models for unsupervised sentence representation learning using the distributional hypothesis effectively constrain the learnt representation of a sentence to only that needed to reproduce the next sentence. While the decoder is important to constrain the representation, these models tend to discard the decoder after training since only the encoder is needed to map the input sentence into a vector representation. However, parameters learnt in the decoder also contain useful information about the language. In order to utilise the decoder after learning, we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation. Therefore, the inverse of the decoding function serves as another encoder that produces sentence representations. We show that, with careful design of the decoding functions, the model learns good sentence representations, and the ensemble of the representations produced from the encoder and the inverse of the decoder demonstrate even better generalisation ability and solid transferability.</abstract>
      <url hash="c921b5b6">P19-1397</url>
      <doi>10.18653/v1/P19-1397</doi>
      <bibkey>tang-de-sa-2019-exploiting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mpqa-opinion-corpus">MPQA Opinion Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="402">
      <title>Few-Shot Representation Learning for Out-Of-Vocabulary Words</title>
      <author><first>Ziniu</first><last>Hu</last></author>
      <author><first>Ting</first><last>Chen</last></author>
      <author><first>Kai-Wei</first><last>Chang</last></author>
      <author><first>Yizhou</first><last>Sun</last></author>
      <pages>4102&#8211;4112</pages>
      <abstract>Existing approaches for learning word embedding often assume there are sufficient occurrences for each word in the corpus, such that the representation of words can be accurately estimated from their contexts. However, in real-world scenarios, out-of-vocabulary (a.k.a. OOV) words that do not appear in training corpus emerge frequently. How to learn accurate representations of these words to augment a pre-trained embedding by only a few observations is a challenging research problem. In this paper, we formulate the learning of OOV embedding as a few-shot regression problem by fitting a representation function to predict an oracle embedding vector (defined as embedding trained with abundant observations) based on limited contexts. Specifically, we propose a novel hierarchical attention network-based embedding framework to serve as the neural regression function, in which the context information of a word is encoded and aggregated from K observations. Furthermore, we propose to use Model-Agnostic Meta-Learning (MAML) for adapting the learned model to the new corpus fast and robustly. Experiments show that the proposed approach significantly outperforms existing methods in constructing an accurate embedding for OOV words and improves downstream tasks when the embedding is utilized.</abstract>
      <url hash="dd21d877">P19-1402</url>
      <doi>10.18653/v1/P19-1402</doi>
      <bibkey>hu-etal-2019-shot</bibkey>
      <pwccode url="https://github.com/acbull/HiCE" additional="false">acbull/HiCE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-103">WikiText-103</pwcdataset>
    </paper>
    <paper id="407">
      <title>Keeping Notes: Conditional Natural Language Generation with a Scratchpad Encoder</title>
      <author><first>Ryan</first><last>Benmalek</last></author>
      <author><first>Madian</first><last>Khabsa</last></author>
      <author><first>Suma</first><last>Desu</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <author><first>Michele</first><last>Banko</last></author>
      <pages>4157&#8211;4167</pages>
      <abstract>We introduce the Scratchpad Mechanism, a novel addition to the sequence-to-sequence (seq2seq) neural network architecture and demonstrate its effectiveness in improving the overall fluency of seq2seq models for natural language generation tasks. By enabling the decoder at each time step to write to all of the encoder output layers, Scratchpad can employ the encoder as a &#8220;scratchpad&#8221; memory to keep track of what has been generated so far and thereby guide future generation. We evaluate Scratchpad in the context of three well-studied natural language generation tasks &#8212; Machine Translation, Question Generation, and Text Summarization &#8212; and obtain state-of-the-art or comparable performance on standard datasets for each task. Qualitative assessments in the form of human judgements (question generation), attention visualization (MT), and sample output (summarization) provide further evidence of the ability of Scratchpad to generate fluent and expressive output.</abstract>
      <url hash="1f986871">P19-1407</url>
      <doi>10.18653/v1/P19-1407</doi>
      <bibkey>benmalek-etal-2019-keeping</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="408">
      <title>Using Automatically Extracted Minimum Spans to Disentangle Coreference Evaluation from Boundary Detection</title>
      <author><first>Nafise Sadat</first><last>Moosavi</last></author>
      <author><first>Leo</first><last>Born</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>4168&#8211;4178</pages>
      <abstract>The common practice in coreference resolution is to identify and evaluate the maximum span of mentions. The use of maximum spans tangles coreference evaluation with the challenges of mention boundary detection like prepositional phrase attachment. To address this problem, minimum spans are manually annotated in smaller corpora. However, this additional annotation is costly and therefore, this solution does not scale to large corpora. In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora. We show that the extracted minimum spans by MINA are consistent with those that are manually annotated by experts. Our experiments show that using minimum spans is in particular important in cross-dataset coreference evaluation, in which detected mention boundaries are noisier due to domain shift. We have integrated MINA into https://github.com/ns-moosavi/coval for reporting standard coreference scores based on both maximum and automatically detected minimum spans.</abstract>
      <url hash="931ea332">P19-1408</url>
      <video href="https://vimeo.com/385196786" />
      <doi>10.18653/v1/P19-1408</doi>
      <bibkey>moosavi-etal-2019-using</bibkey>
      <pwccode url="https://github.com/ns-moosavi/coval" additional="false">ns-moosavi/coval</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikicoref">WikiCoref</pwcdataset>
    </paper>
    <paper id="410">
      <title>A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</title>
      <author><first>Xiang</first><last>Lin</last></author>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Prathyusha</first><last>Jwalapuram</last></author>
      <author><first>M Saiful</first><last>Bari</last></author>
      <pages>4190&#8211;4200</pages>
      <abstract>We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST). Our framework comprises a discourse segmenter to identify the elementary discourse units (EDU) in a text, and a discourse parser that constructs a discourse tree in a top-down fashion. Both the segmenter and the parser are based on Pointer Networks and operate in linear time. Our segmenter yields an F1 score of 95.4%, and our parser achieves an F1 score of 81.7% on the aggregated labeled (relation) metric, surpassing previous approaches by a good margin and approaching human agreement on both tasks (98.3 and 83.0 F1).</abstract>
      <url hash="829c23e2">P19-1410</url>
      <attachment type="supplementary" hash="4973f219">P19-1410.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/385254497" />
      <doi>10.18653/v1/P19-1410</doi>
      <bibkey>lin-etal-2019-unified</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="411">
      <title>Employing the Correspondence of Relations and Connectives to Identify Implicit Discourse Relations via Label Embeddings</title>
      <author><first>Linh The</first><last>Nguyen</last></author>
      <author><first>Linh</first><last>Van Ngo</last></author>
      <author><first>Khoat</first><last>Than</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>4201&#8211;4207</pages>
      <abstract>It has been shown that implicit connectives can be exploited to improve the performance of the models for implicit discourse relation recognition (IDRR). An important property of the implicit connectives is that they can be accurately mapped into the discourse relations conveying their functions. In this work, we explore this property in a multi-task learning framework for IDRR in which the relations and the connectives are simultaneously predicted, and the mapping is leveraged to transfer knowledge between the two prediction tasks via the embeddings of relations and connectives. We propose several techniques to enable such knowledge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset).</abstract>
      <url hash="8daf553c">P19-1411</url>
      <video href="https://vimeo.com/385254810" />
      <doi>10.18653/v1/P19-1411</doi>
      <bibkey>nguyen-etal-2019-employing</bibkey>
    </paper>
    <paper id="417">
      <title>Improving Question Answering over Incomplete <fixed-case>KB</fixed-case>s with Knowledge-Aware Reader</title>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>4258&#8211;4264</pages>
      <abstract>We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets.Under the assumptions that structured data is easier to query and the acquired knowledge can help the understanding of unstructured text, our model first accumulates knowledge ofKB entities from a question-related KB sub-graph; then reformulates the question in the latent space and reads the text with the accumulated entity knowledge at hand. The evidence from KB and text are finally aggregated to predict answers. On the widely-used KBQA benchmark WebQSP, our model achieves consistent improvements across settings with different extents of KB incompleteness.</abstract>
      <url hash="7d7895de">P19-1417</url>
      <video href="https://vimeo.com/385198664" />
      <doi>10.18653/v1/P19-1417</doi>
      <bibkey>xiong-etal-2019-improving</bibkey>
      <pwccode url="https://github.com/xwhan/Knowledge-Aware-Reader" additional="true">xwhan/Knowledge-Aware-Reader</pwccode>
    </paper>
    <paper id="418">
      <title><fixed-case>A</fixed-case>da<fixed-case>NSP</fixed-case>: Uncertainty-driven Adaptive Decoding in Neural Semantic Parsing</title>
      <author><first>Xiang</first><last>Zhang</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>4265&#8211;4270</pages>
      <abstract>Neural semantic parsers utilize the encoder-decoder framework to learn an end-to-end model for semantic parsing that transduces a natural language sentence to the formal semantic representation. To keep the model aware of the underlying grammar in target sequences, many constrained decoders were devised in a multi-stage paradigm, which decode to the sketches or abstract syntax trees first, and then decode to target semantic tokens. We instead to propose an adaptive decoding method to avoid such intermediate representations. The decoder is guided by model uncertainty and automatically uses deeper computations when necessary. Thus it can predict tokens adaptively. Our model outperforms the state-of-the-art neural models and does not need any expertise like predefined grammar or sketches in the meantime.</abstract>
      <url hash="b3db04e8">P19-1418</url>
      <attachment type="software" hash="cb34cfcb">P19-1418.Software.zip</attachment>
      <video href="https://vimeo.com/385933481" permission="false" />
      <doi>10.18653/v1/P19-1418</doi>
      <bibkey>zhang-etal-2019-adansp</bibkey>
    </paper>
    <paper id="419">
      <title>The Language of Legal and Illegal Activity on the <fixed-case>D</fixed-case>arknet</title>
      <author><first>Leshem</first><last>Choshen</last></author>
      <author><first>Dan</first><last>Eldad</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <pages>4271&#8211;4279</pages>
      <abstract>The non-indexed parts of the Internet (the Darknet) have become a haven for both legal and illegal anonymous activity. Given the magnitude of these networks, scalably monitoring their activity necessarily relies on automated tools, and notably on NLP tools. However, little is known about what characteristics texts communicated through the Darknet have, and how well do off-the-shelf NLP tools do on this domain. This paper tackles this gap and performs an in-depth investigation of the characteristics of legal and illegal text in the Darknet, comparing it to a clear net website with similar content as a control condition. Taking drugs-related websites as a test case, we find that texts for selling legal and illegal drugs have several linguistic characteristics that distinguish them from one another, as well as from the control condition, among them the distribution of POS tags, and the coverage of their named entities in Wikipedia.</abstract>
      <url hash="d33854ff">P19-1419</url>
      <attachment type="supplementary" hash="2e1bfe89">P19-1419.Supplementary.zip</attachment>
      <attachment type="presentation" hash="546e0ba1">P19-1419.Presentation.pdf</attachment>
      <video href="https://vimeo.com/385198774" />
      <doi>10.18653/v1/P19-1419</doi>
      <bibkey>choshen-etal-2019-language</bibkey>
      <pwccode url="https://github.com/huji-nlp/cyber" additional="false">huji-nlp/cyber</pwccode>
    </paper>
    <paper id="425">
      <title>Robust Neural Machine Translation with Doubly Adversarial Inputs</title>
      <author><first>Yong</first><last>Cheng</last></author>
      <author><first>Lu</first><last>Jiang</last></author>
      <author><first>Wolfgang</first><last>Macherey</last></author>
      <pages>4324&#8211;4333</pages>
      <abstract>Neural machine translation (NMT) often suffers from the vulnerability to noisy perturbations in the input. We propose an approach to improving the robustness of NMT models, which consists of two parts: (1) attack the translation model with adversarial source examples; (2) defend the translation model with adversarial target inputs to improve its robustness against the adversarial source inputs. For the generation of adversarial inputs, we propose a gradient-based method to craft adversarial examples informed by the translation loss over the clean inputs. Experimental results on Chinese-English and English-German translation tasks demonstrate that our approach achieves significant improvements (2.8 and 1.6 BLEU points) over Transformer on standard clean benchmarks as well as exhibiting higher robustness on noisy data.</abstract>
      <url hash="db0b42b8">P19-1425</url>
      <video href="https://vimeo.com/385933600" permission="false" />
      <doi>10.18653/v1/P19-1425</doi>
      <bibkey>cheng-etal-2019-robust</bibkey>
    </paper>
    <paper id="431">
      <title><fixed-case>A</fixed-case>2<fixed-case>N</fixed-case>: Attending to Neighbors for Knowledge Graph Inference</title>
      <author><first>Trapit</first><last>Bansal</last></author>
      <author><first>Da-Cheng</first><last>Juan</last></author>
      <author><first>Sujith</first><last>Ravi</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>4387&#8211;4392</pages>
      <abstract>State-of-the-art models for knowledge graph completion aim at learning a fixed embedding representation of entities in a multi-relational graph which can generalize to infer unseen entity relationships at test time. This can be sub-optimal as it requires memorizing and generalizing to all possible entity relationships using these fixed representations. We thus propose a novel attention-based method to learn query-dependent representation of entities which adaptively combines the relevant graph neighborhood of an entity leading to more accurate KG completion. The proposed method is evaluated on two benchmark datasets for knowledge graph completion, and experimental results show that the proposed model performs competitively or better than existing state-of-the-art, including recent methods for explicit multi-hop reasoning. Qualitative probing offers insight into how the model can reason about facts involving multiple hops in the knowledge graph, through the use of neighborhood attention.</abstract>
      <url hash="2370aa4d">P19-1431</url>
      <video href="https://vimeo.com/385264668" />
      <doi>10.18653/v1/P19-1431</doi>
      <bibkey>bansal-etal-2019-a2n</bibkey>
    </paper>
    <paper id="432">
      <title>Graph based Neural Networks for Event Factuality Prediction using Syntactic and Semantic Structures</title>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <author><first>Dejing</first><last>Dou</last></author>
      <pages>4393&#8211;4399</pages>
      <abstract>Event factuality prediction (EFP) is the task of assessing the degree to which an event mentioned in a sentence has happened. For this task, both syntactic and semantic information are crucial to identify the important context words. The previous work for EFP has only combined these information in a simple way that cannot fully exploit their coordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed model for EFP.</abstract>
      <url hash="b7158175">P19-1432</url>
      <video href="https://vimeo.com/385264738" />
      <doi>10.18653/v1/P19-1432</doi>
      <bibkey>pouran-ben-veyseh-etal-2019-graph</bibkey>
    </paper>
    <paper id="433">
      <title>Embedding Time Expressions for Deep Temporal Ordering Models</title>
      <author><first>Tanya</first><last>Goyal</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>4400&#8211;4406</pages>
      <abstract>Data-driven models have demonstrated state-of-the-art performance in inferring the temporal ordering of events in text. However, these models often overlook explicit temporal signals, such as dates and time windows. Rule-based methods can be used to identify the temporal links between these time expressions (timexes), but they fail to capture timexes&#8217; interactions with events and are hard to integrate with the distributed representations of neural net models. In this paper, we introduce a framework to infuse temporal awareness into such models by learning a pre-trained model to embed timexes. We generate synthetic data consisting of pairs of timexes, then train a character LSTM to learn embeddings and classify the timexes&#8217; temporal relation. We evaluate the utility of these embeddings in the context of a strong neural model for event temporal ordering, and show a small increase in performance on the MATRES dataset and more substantial gains on an automatically collected dataset with more frequent event-timex interactions.</abstract>
      <url hash="92e38d36">P19-1433</url>
      <video href="https://vimeo.com/385203861" />
      <doi>10.18653/v1/P19-1433</doi>
      <bibkey>goyal-durrett-2019-embedding</bibkey>
      <pwccode url="https://github.com/tagoyal/Temporal-event-ordering" additional="true">tagoyal/Temporal-event-ordering</pwccode>
    </paper>
    <paper id="440">
      <title>Complex Question Decomposition for Semantic Parsing</title>
      <author><first>Haoyu</first><last>Zhang</last></author>
      <author><first>Jingjing</first><last>Cai</last></author>
      <author><first>Jianjun</first><last>Xu</last></author>
      <author><first>Ji</first><last>Wang</last></author>
      <pages>4477&#8211;4486</pages>
      <abstract>In this work, we focus on complex question semantic parsing and propose a novel Hierarchical Semantic Parsing (HSP) method, which utilizes the decompositionality of complex questions for semantic parsing. Our model is designed within a three-stage parsing architecture based on the idea of decomposition-integration. In the first stage, we propose a question decomposer which decomposes a complex question into a sequence of sub-questions. In the second stage, we design an information extractor to derive the type and predicate information of these questions. In the last stage, we integrate the generated information from previous stages and generate a logical form for the complex question. We conduct experiments on COMPLEXWEBQUESTIONS which is a large scale complex question semantic parsing dataset, results show that our model achieves significant improvement compared to state-of-the-art methods.</abstract>
      <url hash="61ecaa4e">P19-1440</url>
      <doi>10.18653/v1/P19-1440</doi>
      <bibkey>zhang-etal-2019-complex</bibkey>
      <pwccode url="https://github.com/cairohy/hsp" additional="false">cairohy/hsp</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/complexwebquestions">ComplexWebQuestions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="444">
      <title>Towards Complex Text-to-<fixed-case>SQL</fixed-case> in Cross-Domain Database with Intermediate Representation</title>
      <author><first>Jiaqi</first><last>Guo</last></author>
      <author><first>Zecheng</first><last>Zhan</last></author>
      <author><first>Yan</first><last>Gao</last></author>
      <author><first>Yan</first><last>Xiao</last></author>
      <author><first>Jian-Guang</first><last>Lou</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Dongmei</first><last>Zhang</last></author>
      <pages>4524&#8211;4535</pages>
      <abstract>We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges: 1) the mismatch between intents expressed in natural language (NL) and the implementation details in SQL; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a SQL query, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a database schema. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge NL and SQL. Finally, IRNet deterministically infers a SQL query from the synthesized SemQL query with domain knowledge. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7% accuracy, obtaining 19.5% absolute improvement over previous state-of-the-art approaches. At the time of writing, IRNet achieves the first position on the Spider leaderboard.</abstract>
      <url hash="e70a7796">P19-1444</url>
      <attachment type="supplementary" hash="fd534d3b">P19-1444.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1444</doi>
      <bibkey>guo-etal-2019-towards</bibkey>
      <pwccode url="https://github.com/zhanzecheng/IRNet" additional="true">zhanzecheng/IRNet</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="447">
      <title>Reranking for Neural Semantic Parsing</title>
      <author><first>Pengcheng</first><last>Yin</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>4553&#8211;4559</pages>
      <abstract>Semantic parsing considers the task of transducing natural language (NL) utterances into machine executable meaning representations (MRs). While neural network-based semantic parsers have achieved impressive improvements over previous methods, results are still far from perfect, and cursory manual inspection can easily identify obvious problems such as lack of adequacy or coherence of the generated MRs. This paper presents a simple approach to quickly iterate and improve the performance of an existing neural semantic parser by reranking an n-best list of predicted MRs, using features that are designed to fix observed problems with baseline models. We implement our reranker in a competitive neural semantic parser and test on four semantic parsing (GEO, ATIS) and Python code generation (Django, CoNaLa) tasks, improving the strong baseline parser by up to 5.7% absolute in BLEU (CoNaLa) and 2.9% in accuracy (Django), outperforming the best published neural parser results on all four datasets.</abstract>
      <url hash="605e1219">P19-1447</url>
      <doi>10.18653/v1/P19-1447</doi>
      <bibkey>yin-neubig-2019-reranking</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conala">CoNaLa</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conala-ext">CoNaLa-Ext</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/django">Django</pwcdataset>
    </paper>
    <paper id="448">
      <title>Representing Schema Structure with Graph Neural Networks for Text-to-<fixed-case>SQL</fixed-case> Parsing</title>
      <author><first>Ben</first><last>Bogin</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <author><first>Matt</first><last>Gardner</last></author>
      <pages>4560&#8211;4565</pages>
      <abstract>Research on parsing language to SQL has largely ignored the structure of the database (DB) schema, either because the DB was very simple, or because it was observed at both training and test time. In spider, a recently-released text-to-SQL dataset, new and complex DBs are given at test time, and so the structure of the DB schema can inform the predicted SQL query. In this paper, we present an encoder-decoder semantic parser, where the structure of the DB schema is encoded with a graph neural network, and this representation is later used at both encoding and decoding time. Evaluation shows that encoding the schema structure improves our parser accuracy from 33.8% to 39.4%, dramatically above the current state of the art, which is at 19.7%.</abstract>
      <url hash="455e9d05">P19-1448</url>
      <attachment type="supplementary" hash="eac37a18">P19-1448.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1448</doi>
      <bibkey>bogin-etal-2019-representing</bibkey>
      <pwccode url="https://github.com/benbogin/spider-schema-gnn" additional="false">benbogin/spider-schema-gnn</pwccode>
    </paper>
    <paper id="449">
      <title>Human vs. Muppet: A Conservative Estimate of Human Performance on the <fixed-case>GLUE</fixed-case> Benchmark</title>
      <author><first>Nikita</first><last>Nangia</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>4566&#8211;4575</pages>
      <abstract>The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding tasks which has seen dramatic progress in the past year, with average performance moving from 70.0 at launch to 83.9, state of the art at the time of writing (May 24, 2019). Here, we measure human performance on the benchmark, in order to learn whether significant headroom remains for further progress. We provide a conservative estimate of human performance on the benchmark through crowdsourcing: Our annotators are non-experts who must learn each task from a brief set of instructions and 20 examples. In spite of limited training, these annotators robustly outperform the state of the art on six of the nine GLUE tasks and achieve an average score of 87.1. Given the fast pace of progress however, the headroom we observe is quite limited. To reproduce the data-poor setting that our annotators must learn in, we also train the BERT model (Devlin et al., 2019) in limited-data regimes, and conclude that low-resource sentence classification remains a challenge for modern neural network approaches to text understanding.</abstract>
      <url hash="202237b5">P19-1449</url>
      <doi>10.18653/v1/P19-1449</doi>
      <bibkey>nangia-bowman-2019-human</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cola">CoLA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/qnli">QNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wsc">WSC</pwcdataset>
    </paper>
    <paper id="450">
      <title>Compositional Semantic Parsing across Graphbanks</title>
      <author><first>Matthias</first><last>Lindemann</last></author>
      <author><first>Jonas</first><last>Groschwitz</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>4576&#8211;4585</pages>
      <abstract>Most semantic parsers that map sentences to graph-based meaning representations are hand-designed for specific graphbanks. We present a compositional neural semantic parser which achieves, for the first time, competitive accuracies across a diverse range of graphbanks. Incorporating BERT embeddings and multi-task learning improves the accuracy further, setting new states of the art on DM, PAS, PSD, AMR 2015 and EDS.</abstract>
      <url hash="521871b6">P19-1450</url>
      <doi>10.18653/v1/P19-1450</doi>
      <attachment type="poster" hash="8305d1eb">P19-1450.Poster.pdf</attachment>
      <bibkey>lindemann-etal-2019-compositional</bibkey>
      <pwccode url="https://github.com/coli-saar/am-parser" additional="false">coli-saar/am-parser</pwccode>
    </paper>
    <paper id="452">
      <title><fixed-case>BERT</fixed-case> Rediscovers the Classical <fixed-case>NLP</fixed-case> Pipeline</title>
      <author><first>Ian</first><last>Tenney</last></author>
      <author><first>Dipanjan</first><last>Das</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <pages>4593&#8211;4601</pages>
      <abstract>Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</abstract>
      <url hash="a7f535a1">P19-1452</url>
      <doi>10.18653/v1/P19-1452</doi>
      <bibkey>tenney-etal-2019-bert</bibkey>
    </paper>
    <paper id="454">
      <title>Second-Order Semantic Dependency Parsing with End-to-End Neural Networks</title>
      <author><first>Xinyu</first><last>Wang</last></author>
      <author><first>Jingxian</first><last>Huang</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>4609&#8211;4618</pages>
      <abstract>Semantic dependency parsing aims to identify semantic relationships between words in a sentence that form a graph. In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of edges. We show that second-order parsing can be approximated using mean field (MF) variational inference or loopy belief propagation (LBP). We can unfold both algorithms as recurrent layers of a neural network and therefore can train the parser in an end-to-end manner. Our experiments show that our approach achieves state-of-the-art performance.</abstract>
      <url hash="bb48f563">P19-1454</url>
      <doi>10.18653/v1/P19-1454</doi>
      <bibkey>wang-etal-2019-second</bibkey>
      <pwccode url="https://github.com/wangxinyu0922/Second_Order_SDP" additional="true">wangxinyu0922/Second_Order_SDP</pwccode>
    </paper>
    <paper id="455">
      <title>Towards Multimodal Sarcasm Detection (An _<fixed-case>O</fixed-case>bviously_ Perfect Paper)</title>
      <author><first>Santiago</first><last>Castro</last></author>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Ver&#243;nica</first><last>P&#233;rez-Rosas</last></author>
      <author><first>Roger</first><last>Zimmermann</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>4619&#8211;4629</pages>
      <abstract>Sarcasm is often expressed through several verbal and non-verbal cues, e.g., a change of tone, overemphasis in a word, a drawn-out syllable, or a straight looking face. Most of the recent work in sarcasm detection has been carried out on textual data. In this paper, we argue that incorporating multimodal cues can improve the automatic classification of sarcasm. As a first step towards enabling the development of multimodal approaches for sarcasm detection, we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD), compiled from popular TV shows. MUStARD consists of audiovisual utterances annotated with sarcasm labels. Each utterance is accompanied by its context of historical utterances in the dialogue, which provides additional information on the scenario where the utterance occurs. Our initial results show that the use of multimodal information can reduce the relative error rate of sarcasm detection by up to 12.9% in F-score when compared to the use of individual modalities. The full dataset is publicly available for use at https://github.com/soujanyaporia/MUStARD.</abstract>
      <url hash="2cc6230f">P19-1455</url>
      <doi>10.18653/v1/P19-1455</doi>
      <attachment type="poster" hash="fe866480">P19-1455.Poster.pdf</attachment>
      <bibkey>castro-etal-2019-towards</bibkey>
      <pwccode url="https://github.com/soujanyaporia/MUStARD" additional="false">soujanyaporia/MUStARD</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mustard">MUStARD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/meld">MELD</pwcdataset>
    </paper>
    <paper id="458">
      <title>An Investigation of Transfer Learning-Based Sentiment Analysis in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Enkhbold</first><last>Bataa</last></author>
      <author><first>Joshua</first><last>Wu</last></author>
      <pages>4652&#8211;4657</pages>
      <abstract>Text classification approaches have usually required task-specific model architectures and huge labeled datasets. Recently, thanks to the rise of text-based transfer learning techniques, it is possible to pre-train a language model in an unsupervised manner and leverage them to perform effective on downstream tasks. In this work we focus on Japanese and show the potential use of transfer learning techniques in text classification. Specifically, we perform binary and multi-class sentiment classification on the Rakuten product review and Yahoo movie review datasets. We show that transfer learning-based approaches perform better than task-specific models trained on 3 times as much data. Furthermore, these approaches perform just as well for language modeling pre-trained on only 1/30 of the data. We release our pre-trained models and code as open source.</abstract>
      <url hash="5ef4af0f">P19-1458</url>
      <doi>10.18653/v1/P19-1458</doi>
      <bibkey>bataa-wu-2019-investigation</bibkey>
    </paper>
    <paper id="459">
      <title>Probing Neural Network Comprehension of Natural Language Arguments</title>
      <author><first>Timothy</first><last>Niven</last></author>
      <author><first>Hung-Yu</first><last>Kao</last></author>
      <pages>4658&#8211;4664</pages>
      <abstract>We are surprised to find that BERT&#8217;s peak performance of 77% on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the dataset. We analyze the nature of these cues and demonstrate that a range of models all exploit them. This analysis informs the construction of an adversarial dataset on which all models achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.</abstract>
      <url hash="88f3f9a4">P19-1459</url>
      <doi>10.18653/v1/P19-1459</doi>
      <bibkey>niven-kao-2019-probing</bibkey>
      <pwccode url="https://github.com/IKMLab/arct2" additional="false">IKMLab/arct2</pwccode>
    </paper>
    <paper id="461">
      <title>Toward Comprehensive Understanding of a Sentiment Based on Human Motives</title>
      <author><first>Naoki</first><last>Otani</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>4672&#8211;4677</pages>
      <abstract>In sentiment detection, the natural language processing community has focused on determining holders, facets, and valences, but has paid little attention to the reasons for sentiment decisions. Our work considers human motives as the driver for human sentiments and addresses the problem of motive detection as the first step. Following a study in psychology, we define six basic motives that cover a wide range of topics appearing in review texts, annotate 1,600 texts in restaurant and laptop domains with the motives, and report the performance of baseline methods on this new dataset. We also show that cross-domain transfer learning boosts detection performance, which indicates that these universal motives exist across different domains.</abstract>
      <url hash="f3bb301c">P19-1461</url>
      <attachment type="supplementary" hash="5d403c50">P19-1461.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1461</doi>
      <bibkey>otani-hovy-2019-toward</bibkey>
      <pwccode url="https://github.com/notani/acl2019-human-motive-identification" additional="false">notani/acl2019-human-motive-identification</pwccode>
    </paper>
    <paper id="462">
      <title>Context-aware Embedding for Targeted Aspect-based Sentiment Analysis</title>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Jiachen</first><last>Du</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <author><first>Binyang</first><last>Li</last></author>
      <author><first>Hejiao</first><last>Huang</last></author>
      <pages>4678&#8211;4683</pages>
      <abstract>Attention-based neural models were employed to detect the different aspects and sentiment polarities of the same target in targeted aspect-based sentiment analysis (TABSA). However, existing methods do not specifically pre-train reasonable embeddings for targets and aspects in TABSA. This may result in targets or aspects having the same vector representations in different contexts and losing the context-dependent information. To address this problem, we propose a novel method to refine the embeddings of targets and aspects. Such pivotal embedding refinement utilizes a sparse coefficient vector to adjust the embeddings of target and aspect from the context. Hence the embeddings of targets and aspects can be refined from the highly correlative words instead of using context-independent or randomly initialized vectors. Experiment results on two benchmark datasets show that our approach yields the state-of-the-art performance in TABSA task.</abstract>
      <url hash="4a985f8e">P19-1462</url>
      <doi>10.18653/v1/P19-1462</doi>
      <bibkey>liang-etal-2019-context</bibkey>
    </paper>
    <paper id="466">
      <title>Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</title>
      <author><first>Deepak</first><last>Nathani</last></author>
      <author><first>Jatin</first><last>Chauhan</last></author>
      <author><first>Charu</first><last>Sharma</last></author>
      <author><first>Manohar</first><last>Kaul</last></author>
      <pages>4710&#8211;4723</pages>
      <abstract>The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity&#8217;s neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.</abstract>
      <url hash="dea514be">P19-1466</url>
      <doi>10.18653/v1/P19-1466</doi>
      <bibkey>nathani-etal-2019-learning</bibkey>
      <pwccode url="https://github.com/deepakn97/relationPrediction" additional="true">deepakn97/relationPrediction</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nell-995">NELL-995</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/umls">UMLS</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18rr">WN18RR</pwcdataset>
    </paper>
    <paper id="467">
      <title>Neural Network Alignment for Sentential Paraphrases</title>
      <author><first>Jessica</first><last>Ouyang</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>4724&#8211;4735</pages>
      <abstract>We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are ill-suited for these longer alignments. Our system is capable of aligning semantically similar spans of arbitrary length. We achieve significantly higher recall on aligning phrases of four or more words and outperform state-of-the- art aligners on the long alignments in the MSR RTE corpus.</abstract>
      <url hash="7b3a2d80">P19-1467</url>
      <doi>10.18653/v1/P19-1467</doi>
      <bibkey>ouyang-mckeown-2019-neural</bibkey>
    </paper>
    <paper id="468">
      <title>Duality of Link Prediction and Entailment Graph Induction</title>
      <author><first>Mohammad Javad</first><last>Hosseini</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>4736&#8211;4746</pages>
      <abstract>Link prediction and entailment graph induction are often treated as different problems. In this paper, we show that these two problems are actually complementary. We train a link prediction model on a knowledge graph of assertions extracted from raw text. We propose an entailment score that exploits the new facts discovered by the link prediction model, and then form entailment graphs between relations. We further use the learned entailments to predict improved link prediction scores. Our results show that the two tasks can benefit from each other. The new entailment score outperforms prior state-of-the-art results on a standard entialment dataset and the new link prediction scores show improvements over the raw link prediction scores.</abstract>
      <url hash="ef54d3b8">P19-1468</url>
      <doi>10.18653/v1/P19-1468</doi>
      <bibkey>hosseini-etal-2019-duality</bibkey>
      <pwccode url="https://github.com/mjhosseini/linkpred_entgraph" additional="false">mjhosseini/linkpred_entgraph</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="470">
      <title><fixed-case>COMET</fixed-case>: Commonsense Transformers for Automatic Knowledge Graph Construction</title>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <author><first>Hannah</first><last>Rashkin</last></author>
      <author><first>Maarten</first><last>Sap</last></author>
      <author><first>Chaitanya</first><last>Malaviya</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>4762&#8211;4779</pages>
      <abstract>We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and ConceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.</abstract>
      <url hash="7ad942b4">P19-1470</url>
      <doi>10.18653/v1/P19-1470</doi>
      <bibkey>bosselut-etal-2019-comet</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="476">
      <title>Generalized Tuning of Distributional Word Vectors for Monolingual and Cross-Lingual Lexical Entailment</title>
      <author><first>Goran</first><last>Glava&#353;</last></author>
      <author><first>Ivan</first><last>Vuli&#263;</last></author>
      <pages>4824&#8211;4830</pages>
      <abstract>Lexical entailment (LE; also known as hyponymy-hypernymy or is-a relation) is a core asymmetric lexical relation that supports tasks like taxonomy induction and text generation. In this work, we propose a simple and effective method for fine-tuning distributional word vectors for LE. Our Generalized Lexical ENtailment model (GLEN) is decoupled from the word embedding model and applicable to any distributional vector space. Yet &#8211; unlike existing retrofitting models &#8211; it captures a general specialization function allowing for LE-tuning of the entire distributional space and not only the vectors of words seen in lexical constraints. Coupled with a multilingual embedding space, GLEN seamlessly enables cross-lingual LE detection. We demonstrate the effectiveness of GLEN in graded LE and report large improvements (over 20% in accuracy) over state-of-the-art in cross-lingual LE detection.</abstract>
      <url hash="85b6284b">P19-1476</url>
      <doi>10.18653/v1/P19-1476</doi>
      <bibkey>glavas-vulic-2019-generalized</bibkey>
      <pwccode url="https://github.com/codogogo/glen" additional="false">codogogo/glen</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hyperlex">HyperLex</pwcdataset>
    </paper>
    <paper id="478">
      <title>A Surprisingly Robust Trick for the <fixed-case>W</fixed-case>inograd Schema Challenge</title>
      <author><first>Vid</first><last>Kocijan</last></author>
      <author><first>Ana-Maria</first><last>Cretu</last></author>
      <author><first>Oana-Maria</first><last>Camburu</last></author>
      <author><first>Yordan</first><last>Yordanov</last></author>
      <author><first>Thomas</first><last>Lukasiewicz</last></author>
      <pages>4837&#8211;4842</pages>
      <abstract>The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for natural language understanding and commonsense reasoning. In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.5% and 74.7% on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.8% and 9.6%, respectively. Furthermore, our fine-tuned models are also consistently more accurate on the &#8220;complex&#8221; subsets of WSC273, introduced by Trichelair et al. (2018).</abstract>
      <url hash="d897dd6e">P19-1478</url>
      <doi>10.18653/v1/P19-1478</doi>
      <bibkey>kocijan-etal-2019-surprisingly</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/definite-pronoun-resolution-dataset">Definite Pronoun Resolution Dataset</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wsc">WSC</pwcdataset>
    </paper>
    <paper id="482">
      <title>A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer</title>
      <author><first>Chen</first><last>Wu</last></author>
      <author><first>Xuancheng</first><last>Ren</last></author>
      <author><first>Fuli</first><last>Luo</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>4873&#8211;4883</pages>
      <abstract>Unsupervised text style transfer aims to alter text styles while preserving the content, without aligned data for supervision. Existing seq2seq methods face three challenges: 1) the transfer is weakly interpretable, 2) generated outputs struggle in content preservation, and 3) the trade-off between content and style is intractable. To address these challenges, we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a low-level agent that alters the sentence. We provide comprehensive training objectives to control the fluency, style, and content of the outputs and a mask-based inference algorithm that allows for multi-step revision based on the single-step trained agents. Experimental results on two text style transfer datasets show that our method significantly outperforms recent methods and effectively addresses the aforementioned challenges.</abstract>
      <url hash="64d276b0">P19-1482</url>
      <video href="https://vimeo.com/385265051" />
      <doi>10.18653/v1/P19-1482</doi>
      <bibkey>wu-etal-2019-hierarchical-reinforced</bibkey>
    </paper>
    <paper id="487">
      <title>Explain Yourself! Leveraging Language Models for Commonsense Reasoning</title>
      <author><first>Nazneen Fatema</first><last>Rajani</last></author>
      <author><first>Bryan</first><last>McCann</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>4932&#8211;4942</pages>
      <abstract>Deep learning models perform poorly on tasks that require commonsense reasoning, which often necessitates some form of world-knowledge or reasoning over information not immediately present in the input. We collect human explanations for commonsense reasoning in the form of natural language sequences and highlighted annotations in a new dataset called Common Sense Explanations (CoS-E). We use CoS-E to train language models to automatically generate explanations that can be used during training and inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the state-of-the-art by 10% on the challenging CommonsenseQA task. We further study commonsense reasoning in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks. Empirical results indicate that we can effectively leverage language models for commonsense reasoning.</abstract>
      <url hash="4afb8171">P19-1487</url>
      <video href="https://vimeo.com/385213801" />
      <doi>10.18653/v1/P19-1487</doi>
      <bibkey>rajani-etal-2019-explain</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cos-e">CoS-E</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/swag">SWAG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/e-snli">e-SNLI</pwcdataset>
    </paper>
    <paper id="488">
      <title>Interpretable Question Answering on Knowledge Bases and Text</title>
      <author><first>Alona</first><last>Sydorova</last></author>
      <author><first>Nina</first><last>Poerner</last></author>
      <author><first>Benjamin</first><last>Roth</last></author>
      <pages>4943&#8211;4951</pages>
      <abstract>Interpretability of machine learning (ML) models becomes more relevant with their increasing adoption. In this work, we address the interpretability of ML based question answering (QA) models on a combination of knowledge bases (KB) and text documents. We adapt post hoc explanation methods such as LIME and input perturbation (IP) and compare them with the self-explanatory attention mechanism of the model. For this purpose, we propose an automatic evaluation paradigm for explanation methods in the context of QA. We also conduct a study with human annotators to evaluate whether explanations help them identify better QA models. Our results suggest that IP provides better explanations than LIME or attention, according to both automatic and human evaluation. We obtain the same ranking of methods in both experiments, which supports the validity of our automatic evaluation paradigm.</abstract>
      <url hash="25dd47cf">P19-1488</url>
      <video href="https://vimeo.com/385215761" />
      <doi>10.18653/v1/P19-1488</doi>
      <bibkey>sydorova-etal-2019-interpretable</bibkey>
    </paper>
    <paper id="490">
      <title>Multilingual and Cross-Lingual Graded Lexical Entailment</title>
      <author><first>Ivan</first><last>Vuli&#263;</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <author><first>Goran</first><last>Glava&#353;</last></author>
      <pages>4963&#8211;4974</pages>
      <abstract>Grounded in cognitive linguistics, graded lexical entailment (GR-LE) is concerned with fine-grained assertions regarding the directional hierarchical relationships between concepts on a continuous scale. In this paper, we present the first work on cross-lingual generalisation of GR-LE relation. Starting from HyperLex, the only available GR-LE dataset in English, we construct new monolingual GR-LE datasets for three other languages, and combine those to create a set of six cross-lingual GR-LE datasets termed CL-HYPERLEX. We next present a novel method dubbed CLEAR (Cross-Lingual Lexical Entailment Attract-Repel) for effectively capturing graded (and binary) LE, both monolingually in different languages as well as across languages (i.e., on CL-HYPERLEX). Coupled with a bilingual dictionary, CLEAR leverages taxonomic LE knowledge in a resource-rich language (e.g., English) and propagates it to other languages. Supported by cross-lingual LE transfer, CLEAR sets competitive baseline performance on three new monolingual GR-LE datasets and six cross-lingual GR-LE datasets. In addition, we show that CLEAR outperforms current state-of-the-art on binary cross-lingual LE detection by a wide margin for diverse language pairs.</abstract>
      <url hash="23ca4f80">P19-1490</url>
      <attachment type="supplementary" hash="1f6d78cd">P19-1490.Supplementary.zip</attachment>
      <video href="https://vimeo.com/385216016" />
      <doi>10.18653/v1/P19-1490</doi>
      <bibkey>vulic-etal-2019-multilingual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/hyperlex">HyperLex</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/panlex">Panlex</pwcdataset>
    </paper>
    <paper id="492">
      <title>Analyzing the Limitations of Cross-lingual Word Embedding Mappings</title>
      <author><first>Aitor</first><last>Ormazabal</last></author>
      <author><first>Mikel</first><last>Artetxe</last></author>
      <author><first>Gorka</first><last>Labaka</last></author>
      <author><first>Aitor</first><last>Soroa</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <pages>4990&#8211;4995</pages>
      <abstract>Recent research in cross-lingual word embeddings has almost exclusively focused on offline methods, which independently train word embeddings in different languages and map them to a shared space through linear transformations. While several authors have questioned the underlying isomorphism assumption, which states that word embeddings in different languages have approximately the same structure, it is not clear whether this is an inherent limitation of mapping approaches or a more general issue when learning cross-lingual embeddings. So as to answer this question, we experiment with parallel corpora, which allows us to compare offline mapping to an extension of skip-gram that jointly learns both embedding spaces. We observe that, under these ideal conditions, joint learning yields to more isomorphic embeddings, is less sensitive to hubness, and obtains stronger results in bilingual lexicon induction. We thus conclude that current mapping methods do have strong limitations, calling for further research to jointly learn cross-lingual embeddings with a weaker cross-lingual signal.</abstract>
      <url hash="7383c2a9">P19-1492</url>
      <video href="https://vimeo.com/385218856" />
      <doi>10.18653/v1/P19-1492</doi>
      <bibkey>ormazabal-etal-2019-analyzing</bibkey>
    </paper>
    <paper id="494">
      <title>Bilingual Lexicon Induction through Unsupervised Machine Translation</title>
      <author><first>Mikel</first><last>Artetxe</last></author>
      <author><first>Gorka</first><last>Labaka</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <pages>5002&#8211;5007</pages>
      <abstract>A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a bilingual lexicon from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the bilingual lexicon using statistical word alignment techniques. As such, our method can work with any word embedding and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over nearest neighbor and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset.</abstract>
      <url hash="69b54ef0">P19-1494</url>
      <video href="https://vimeo.com/385219132" />
      <doi>10.18653/v1/P19-1494</doi>
      <bibkey>artetxe-etal-2019-bilingual</bibkey>
      <pwccode url="https://github.com/artetxem/monoses" additional="false">artetxem/monoses</pwccode>
    </paper>
    <paper id="496">
      <title><fixed-case>TWEETQA</fixed-case>: A Social Media Focused Question Answering Dataset</title>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Jiawei</first><last>Wu</last></author>
      <author><first>Hong</first><last>Wang</last></author>
      <author><first>Vivek</first><last>Kulkarni</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>5020&#8211;5031</pages>
      <abstract>With social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effective-ness of many applications that rely on real-time knowledge. While previous datasets have concentrated on question answering (QA) for formal text like news and Wikipedia, we present the first large-scale dataset for QA over social media data. To ensure that the tweets we collected are useful, we only gather tweets used by journalists to write news articles. We then ask human annotators to write questions and answers upon these tweets. Unlike otherQA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. We show that two recently proposed neural models that perform well on formal texts are limited in their performance when applied to our dataset. In addition, even the fine-tuned BERT model is still lagging behind human performance with a large margin. Our results thus point to the need of improved QA systems targeting social media text.</abstract>
      <url hash="4050c847">P19-1496</url>
      <video href="https://vimeo.com/385272712" />
      <doi>10.18653/v1/P19-1496</doi>
      <bibkey>xiong-etal-2019-tweetqa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/tweetqa">TweetQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="498">
      <title>Tree <fixed-case>LSTM</fixed-case>s with Convolution Units to Predict Stance and Rumor Veracity in Social Media Conversations</title>
      <author><first>Sumeet</first><last>Kumar</last></author>
      <author><first>Kathleen</first><last>Carley</last></author>
      <pages>5047&#8211;5058</pages>
      <abstract>Learning from social-media conversations has gained significant attention recently because of its applications in areas like rumor detection. In this research, we propose a new way to represent social-media conversations as binarized constituency trees that allows comparing features in source-posts and their replies effectively. Moreover, we propose to use convolution units in Tree LSTMs that are better at learning patterns in features obtained from the source and reply posts. Our Tree LSTM models employ multi-task (stance + rumor) learning and propagate the useful stance signal up in the tree for rumor classification at the root node. The proposed models achieve state-of-the-art performance, outperforming the current best model by 12% and 15% on F1-macro for rumor-veracity classification and stance classification tasks respectively.</abstract>
      <url hash="3dbf2f48">P19-1498</url>
      <video href="https://vimeo.com/385272871" />
      <doi>10.18653/v1/P19-1498</doi>
      <bibkey>kumar-carley-2019-tree</bibkey>
    </paper>
    <paper id="503">
      <title>Simple Unsupervised Summarization by Contextual Matching</title>
      <author><first>Jiawei</first><last>Zhou</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <pages>5101&#8211;5106</pages>
      <abstract>We propose an unsupervised method for sentence summarization using only language modeling. The approach employs two language models, one that is generic (i.e. pretrained), and the other that is specific to the target domain. We show that by using a product-of-experts criteria these are enough for maintaining continuous contextual matching while maintaining output fluency. Experiments on both abstractive and extractive sentence summarization data sets show promising results of our method without being exposed to any paired data.</abstract>
      <url hash="bcecdc13">P19-1503</url>
      <video href="https://vimeo.com/385219323" />
      <doi>10.18653/v1/P19-1503</doi>
      <bibkey>zhou-rush-2019-simple</bibkey>
      <pwccode url="https://github.com/jzhou316/Unsupervised-Sentence-Summarization" additional="false">jzhou316/Unsupervised-Sentence-Summarization</pwccode>
    </paper>
    <paper id="507">
      <title>Relating Simple Sentence Representations in Deep Neural Networks and the Brain</title>
      <author><first>Sharmistha</first><last>Jat</last></author>
      <author><first>Hao</first><last>Tang</last></author>
      <author><first>Partha</first><last>Talukdar</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>5137&#8211;5154</pages>
      <abstract>What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain? Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.). We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences. Overall, we find that BERT&#8217;s activations correlate the best with MEG brain data. We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data. To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.</abstract>
      <url hash="ce43a409">P19-1507</url>
      <attachment type="software" hash="0a0ff737">P19-1507.Software.zip</attachment>
      <video href="https://vimeo.com/385446129" />
      <doi>10.18653/v1/P19-1507</doi>
      <bibkey>jat-etal-2019-relating</bibkey>
      <pwccode url="https://github.com/SharmisthaJat/ACL2019-SimpleSentenceRepr-DNN-Brain" additional="false">SharmisthaJat/ACL2019-SimpleSentenceRepr-DNN-Brain</pwccode>
    </paper>
    <paper id="510">
      <title><fixed-case>NNE</fixed-case>: A Dataset for Nested Named Entity Recognition in <fixed-case>E</fixed-case>nglish Newswire</title>
      <author><first>Nicky</first><last>Ringland</last></author>
      <author><first>Xiang</first><last>Dai</last></author>
      <author><first>Ben</first><last>Hachey</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Cecile</first><last>Paris</last></author>
      <author><first>James R.</first><last>Curran</last></author>
      <pages>5176&#8211;5181</pages>
      <abstract>Named entity recognition (NER) is widely used in natural language processing applications and downstream tasks. However, most NER tools target flat annotation from popular datasets, eschewing the semantic information available in nested entity mentions. We describe NNE&#8212;a fine-grained, nested named entity dataset over the full Wall Street Journal portion of the Penn Treebank (PTB). Our annotation comprises 279,795 mentions of 114 entity types with up to 6 layers of nesting. We hope the public release of this large dataset for English newswire will encourage development of new techniques for nested NER.</abstract>
      <url hash="7a3a1720">P19-1510</url>
      <doi>10.18653/v1/P19-1510</doi>
      <bibkey>ringland-etal-2019-nne</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nne">NNE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="511">
      <title>Sequence-to-Nuggets: Nested Entity Mention Detection via Anchor-Region Networks</title>
      <author><first>Hongyu</first><last>Lin</last></author>
      <author><first>Yaojie</first><last>Lu</last></author>
      <author><first>Xianpei</first><last>Han</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <pages>5182&#8211;5192</pages>
      <abstract>Sequential labeling-based NER approaches restrict each word belonging to at most one entity mention, which will face a serious problem when recognizing nested entity mentions. In this paper, we propose to resolve this problem by modeling and leveraging the head-driven phrase structures of entity mentions, i.e., although a mention can nest other mentions, they will not share the same head word. Specifically, we propose Anchor-Region Networks (ARNs), a sequence-to-nuggets architecture for nested mention detection. ARNs first identify anchor words (i.e., possible head words) of all mentions, and then recognize the mention boundaries for each anchor word by exploiting regular phrase structures. Furthermore, we also design Bag Loss, an objective function which can train ARNs in an end-to-end manner without using any anchor word annotation. Experiments show that ARNs achieve the state-of-the-art performance on three standard nested entity mention detection benchmarks.</abstract>
      <url hash="e163669c">P19-1511</url>
      <doi>10.18653/v1/P19-1511</doi>
      <bibkey>lin-etal-2019-sequence</bibkey>
      <pwccode url="https://github.com/sanmusunrise/ARNs" additional="false">sanmusunrise/ARNs</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ace-2005">ACE 2005</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
    </paper>
    <paper id="515">
      <title>Incorporating Linguistic Constraints into Keyphrase Generation</title>
      <author><first>Jing</first><last>Zhao</last></author>
      <author><first>Yuxiang</first><last>Zhang</last></author>
      <pages>5224&#8211;5233</pages>
      <abstract>Keyphrases, that concisely describe the high-level topics discussed in a document, are very useful for a wide range of natural language processing tasks. Though existing keyphrase generation methods have achieved remarkable performance on this task, they generate many overlapping phrases (including sub-phrases or super-phrases) of keyphrases. In this paper, we propose the parallel Seq2Seq network with the coverage attention to alleviate the overlapping phrase problem. Specifically, we integrate the linguistic constraints of keyphrase into the basic Seq2Seq network on the source side, and employ the multi-task learning framework on the target side. In addition, in order to prevent from generating overlapping phrases of keyphrases with correct syntax, we introduce the coverage vector to keep track of the attention history and to decide whether the parts of source text have been covered by existing generated keyphrases. Experimental results show that our method can outperform the state-of-the-art CopyRNN on scientific datasets, and is also more effective in news domain.</abstract>
      <url hash="8540a395">P19-1515</url>
      <doi>10.18653/v1/P19-1515</doi>
      <bibkey>zhao-zhang-2019-incorporating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/kp20k">KP20k</pwcdataset>
    </paper>
    <paper id="518">
      <title>A Deep Reinforced Sequence-to-Set Model for Multi-Label Classification</title>
      <author><first>Pengcheng</first><last>Yang</last></author>
      <author><first>Fuli</first><last>Luo</last></author>
      <author><first>Shuming</first><last>Ma</last></author>
      <author><first>Junyang</first><last>Lin</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>5252&#8211;5258</pages>
      <abstract>Multi-label classification (MLC) aims to predict a set of labels for a given instance. Based on a pre-defined label order, the sequence-to-sequence (Seq2Seq) model trained via maximum likelihood estimation method has been successfully applied to the MLC task and shows powerful ability to capture high-order correlations between labels. However, the output labels are essentially an unordered set rather than an ordered sequence. This inconsistency tends to result in some intractable problems, e.g., sensitivity to the label order. To remedy this, we propose a simple but effective sequence-to-set model. The proposed model is trained via reinforcement learning, where reward feedback is designed to be independent of the label order. In this way, we can reduce the dependence of the model on the label order, as well as capture high-order correlations between labels. Extensive experiments show that our approach can substantially outperform competitive baselines, as well as effectively reduce the sensitivity to the label order.</abstract>
      <url hash="743c2ba3">P19-1518</url>
      <doi>10.18653/v1/P19-1518</doi>
      <bibkey>yang-etal-2019-deep</bibkey>
      <pwccode url="https://github.com/lancopku/Seq2Set" additional="false">lancopku/Seq2Set</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rcv1">RCV1</pwcdataset>
    </paper>
    <paper id="521">
      <title>Cost-sensitive Regularization for Label Confusion-aware Event Detection</title>
      <author><first>Hongyu</first><last>Lin</last></author>
      <author><first>Yaojie</first><last>Lu</last></author>
      <author><first>Xianpei</first><last>Han</last></author>
      <author><first>Le</first><last>Sun</last></author>
      <pages>5278&#8211;5283</pages>
      <abstract>In supervised event detection, most of the mislabeling occurs between a small number of confusing type pairs, including trigger-NIL pairs and sibling sub-types of the same coarse type. To address this label confusion problem, this paper proposes cost-sensitive regularization, which can force the training procedure to concentrate more on optimizing confusing type pairs. Specifically, we introduce a cost-weighted term into the training loss, which penalizes more on mislabeling between confusing label pairs. Furthermore, we also propose two estimators which can effectively measure such label confusion based on instance-level or population-level statistics. Experiments on TAC-KBP 2017 datasets demonstrate that the proposed method can significantly improve the performances of different models in both English and Chinese event detection.</abstract>
      <url hash="a8e6cde5">P19-1521</url>
      <doi>10.18653/v1/P19-1521</doi>
      <bibkey>lin-etal-2019-cost</bibkey>
      <pwccode url="https://github.com/sanmusunrise/CSR" additional="false">sanmusunrise/CSR</pwccode>
    </paper>
    <paper id="523">
      <title>Improving Open Information Extraction via Iterative Rank-Aware Learning</title>
      <author><first>Zhengbao</first><last>Jiang</last></author>
      <author><first>Pengcheng</first><last>Yin</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5295&#8211;5300</pages>
      <abstract>Open information extraction (IE) is the task of extracting open-domain assertions from natural language sentences. A key step in open IE is confidence modeling, ranking the extractions based on their estimated quality to adjust precision and recall of extracted assertions. We found that the extraction likelihood, a confidence measure used by current supervised open IE systems, is not well calibrated when comparing the quality of assertions extracted from different sentences. We propose an additional binary classification loss to calibrate the likelihood to make it more globally comparable, and an iterative learning process, where extractions generated by the open IE model are incrementally included as training samples to help the model learn from trial and error. Experiments on OIE2016 demonstrate the effectiveness of our method. Code and data are available at https://github.com/jzbjyb/oie_rank.</abstract>
      <url hash="297ef022">P19-1523</url>
      <doi>10.18653/v1/P19-1523</doi>
      <bibkey>jiang-etal-2019-improving</bibkey>
      <pwccode url="https://github.com/jzbjyb/oie_rank" additional="false">jzbjyb/oie_rank</pwccode>
    </paper>
    <paper id="524">
      <title>Towards Improving Neural Named Entity Recognition with Gazetteers</title>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Jin-Ge</first><last>Yao</last></author>
      <author><first>Chin-Yew</first><last>Lin</last></author>
      <pages>5301&#8211;5307</pages>
      <abstract>Most of the recently proposed neural models for named entity recognition have been purely data-driven, with a strong emphasis on getting rid of the efforts for collecting external resources or designing hand-crafted features. This could increase the chance of overfitting since the models cannot access any supervision signal beyond the small amount of annotated data, limiting their power to generalize beyond the annotated entities. In this work, we show that properly utilizing external gazetteers could benefit segmental neural NER models. We add a simple module on the recently proposed hybrid semi-Markov CRF architecture and observe some promising results.</abstract>
      <url hash="b423f4b6">P19-1524</url>
      <attachment type="supplementary" hash="484daa38">P19-1524.Supplementary.zip</attachment>
      <doi>10.18653/v1/P19-1524</doi>
      <bibkey>liu-etal-2019-towards</bibkey>
      <pwccode url="https://github.com/lyutyuh/acl19_subtagger" additional="false">lyutyuh/acl19_subtagger</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ontonotes-5-0">OntoNotes 5.0</pwcdataset>
    </paper>
    <paper id="529">
      <title>How to Best Use Syntax in Semantic Role Labelling</title>
      <author><first>Yufei</first><last>Wang</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <author><first>Stephen</first><last>Wan</last></author>
      <author><first>Yifang</first><last>Sun</last></author>
      <author><first>Wei</first><last>Wang</last></author>
      <pages>5338&#8211;5343</pages>
      <abstract>There are many different ways in which external information might be used in a NLP task. This paper investigates how external syntactic information can be used most effectively in the Semantic Role Labeling (SRL) task. We evaluate three different ways of encoding syntactic parses and three different ways of injecting them into a state-of-the-art neural ELMo-based SRL sequence labelling model. We show that using a constituency representation as input features improves performance the most, achieving a new state-of-the-art for non-ensemble SRL models on the in-domain CoNLL&#8217;05 and CoNLL&#8217;12 benchmarks.</abstract>
      <url hash="22002c29">P19-1529</url>
      <doi>10.18653/v1/P19-1529</doi>
      <bibkey>wang-etal-2019-best</bibkey>
      <pwccode url="https://github.com/GaryYufei/bestParseSRL" additional="false">GaryYufei/bestParseSRL</pwccode>
    </paper>
    <paper id="530">
      <title><fixed-case>PTB</fixed-case> Graph Parsing with Tree Approximation</title>
      <author><first>Yoshihide</first><last>Kato</last></author>
      <author><first>Shigeki</first><last>Matsubara</last></author>
      <pages>5344&#8211;5349</pages>
      <abstract>The Penn Treebank (PTB) represents syntactic structures as graphs due to nonlocal dependencies. This paper proposes a method that approximates PTB graph-structured representations by trees. By our approximation method, we can reduce nonlocal dependency identification and constituency parsing into single tree-based parsing. An experimental result demonstrates that our approximation method with an off-the-shelf tree-based constituency parser significantly outperforms the previous methods in nonlocal dependency identification.</abstract>
      <url hash="c3360c0c">P19-1530</url>
      <doi>10.18653/v1/P19-1530</doi>
      <bibkey>kato-matsubara-2019-ptb</bibkey>
      <pwccode url="https://github.com/yosihide/ptb2cf" additional="false">yosihide/ptb2cf</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="532">
      <title>A Prism Module for Semantic Disentanglement in Name Entity Recognition</title>
      <author><first>Kun</first><last>Liu</last></author>
      <author><first>Shen</first><last>Li</last></author>
      <author><first>Daqi</first><last>Zheng</last></author>
      <author><first>Zhengdong</first><last>Lu</last></author>
      <author><first>Sheng</first><last>Gao</last></author>
      <author><first>Si</first><last>Li</last></author>
      <pages>5358&#8211;5362</pages>
      <abstract>Natural Language Processing has been perplexed for many years by the problem that multiple semantics are mixed inside a word, even with the help of context. To solve this problem, we propose a prism module to disentangle the semantic aspects of words and reduce noise at the input layer of a model. In the prism module, some words are selectively replaced with task-related semantic aspects, then these denoised word representations can be fed into downstream tasks to make them easier. Besides, we also introduce a structure to train this module jointly with the downstream model without additional data. This module can be easily integrated into the downstream model and significantly improve the performance of baselines on named entity recognition (NER) task. The ablation analysis demonstrates the rationality of the method. As a side effect, the proposed method also provides a way to visualize the contribution of each word.</abstract>
      <url hash="76c69e20">P19-1532</url>
      <doi>10.18653/v1/P19-1532</doi>
      <bibkey>liu-etal-2019-prism</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="534">
      <title>Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset</title>
      <author><first>Hannah</first><last>Rashkin</last></author>
      <author><first>Eric Michael</first><last>Smith</last></author>
      <author><first>Margaret</first><last>Li</last></author>
      <author><first>Y-Lan</first><last>Boureau</last></author>
      <pages>5370&#8211;5381</pages>
      <abstract>One challenge for dialogue agents is recognizing feelings in the conversation partner and replying accordingly, a key communicative skill. While it is straightforward for humans to recognize and acknowledge others&#8217; feelings in a conversation, this is a significant challenge for AI systems due to the paucity of suitable publicly-available datasets for training and evaluation. This work proposes a new benchmark for empathetic dialogue generation and EmpatheticDialogues, a novel dataset of 25k conversations grounded in emotional situations. Our experiments indicate that dialogue models that use our dataset are perceived to be more empathetic by human evaluators, compared to models merely trained on large-scale Internet conversation data. We also present empirical comparisons of dialogue model adaptations for empathetic responding, leveraging existing models or datasets without requiring lengthy re-training of the full model.</abstract>
      <url hash="c1ad2ebd">P19-1534</url>
      <attachment type="supplementary" hash="ad86ea7a">P19-1534.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1534</doi>
      <bibkey>rashkin-etal-2019-towards</bibkey>
      <pwccode url="https://github.com/facebookresearch/EmpatheticDialogues" additional="true">facebookresearch/EmpatheticDialogues</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/empatheticdialogues">EmpatheticDialogues</pwcdataset>
    </paper>
    <paper id="536">
      <title>Training Neural Response Selection for Task-Oriented Dialogue Systems</title>
      <author><first>Matthew</first><last>Henderson</last></author>
      <author><first>Ivan</first><last>Vuli&#263;</last></author>
      <author><first>Daniela</first><last>Gerz</last></author>
      <author><first>I&#241;igo</first><last>Casanueva</last></author>
      <author><first>Pawe&#322;</first><last>Budzianowski</last></author>
      <author><first>Sam</first><last>Coope</last></author>
      <author><first>Georgios</first><last>Spithourakis</last></author>
      <author><first>Tsung-Hsien</first><last>Wen</last></author>
      <author><first>Nikola</first><last>Mrk&#353;i&#263;</last></author>
      <author><first>Pei-Hao</first><last>Su</last></author>
      <pages>5392&#8211;5404</pages>
      <abstract>Despite their popularity in the chatbot literature, retrieval-based models have had modest impact on task-oriented dialogue systems, with the main obstacle to their application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying response selection in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which: 1) pretrains the response selection model on large general-domain conversational corpora; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on five diverse application domains, ranging from e-commerce to banking, demonstrates the effectiveness of the proposed training method.</abstract>
      <url hash="83c9f8e1">P19-1536</url>
      <doi>10.18653/v1/P19-1536</doi>
      <bibkey>henderson-etal-2019-training</bibkey>
    </paper>
    <paper id="537">
      <title>Collaborative Dialogue in <fixed-case>M</fixed-case>inecraft</title>
      <author><first>Anjali</first><last>Narayan-Chen</last></author>
      <author><first>Prashant</first><last>Jayannavar</last></author>
      <author><first>Julia</first><last>Hockenmaier</last></author>
      <pages>5405&#8211;5415</pages>
      <abstract>We wish to develop interactive agents that can communicate with humans to collaboratively solve tasks in grounded scenarios. Since computer games allow us to simulate such tasks without the need for physical robots, we define a Minecraft-based collaborative building task in which one player (A, the Architect) is shown a target structure and needs to instruct the other player (B, the Builder) to build this structure. Both players interact via a chat interface. A can observe B but cannot place blocks. We present the Minecraft Dialogue Corpus, a collection of 509 conversations and game logs. As a first step towards our goal of developing fully interactive agents for this task, we consider the subtask of Architect utterance generation, and show how challenging it is.</abstract>
      <url hash="f9ba62d2">P19-1537</url>
      <attachment type="supplementary" hash="3e90363b">P19-1537.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1537</doi>
      <bibkey>narayan-chen-etal-2019-collaborative</bibkey>
    </paper>
    <paper id="538">
      <title>Neural Response Generation with Meta-words</title>
      <author><first>Can</first><last>Xu</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Chongyang</first><last>Tao</last></author>
      <author><first>Huang</first><last>Hu</last></author>
      <author><first>Matt</first><last>Schuerman</last></author>
      <author><first>Ying</first><last>Wang</last></author>
      <pages>5416&#8211;5426</pages>
      <abstract>We present open domain dialogue generation with meta-words. A meta-word is a structured record that describes attributes of a response, and thus allows us to explicitly model the one-to-many relationship within open domain dialogues and perform response generation in an explainable and controllable manner. To incorporate meta-words into generation, we propose a novel goal-tracking memory network that formalizes meta-word expression as a goal in response generation and manages the generation process to achieve the goal with a state memory panel and a state controller. Experimental results from both automatic evaluation and human judgment on two large-scale data sets indicate that our model can significantly outperform state-of-the-art generation models in terms of response relevance, response diversity, and accuracy of meta-word expression.</abstract>
      <url hash="b1a45601">P19-1538</url>
      <doi>10.18653/v1/P19-1538</doi>
      <bibkey>xu-etal-2019-neural</bibkey>
    </paper>
    <paper id="540">
      <title>Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System</title>
      <author><first>Hardik</first><last>Chauhan</last></author>
      <author><first>Mauajama</first><last>Firdaus</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>5437&#8211;5447</pages>
      <abstract>Multimodal dialogue systems have opened new frontiers in the traditional goal-oriented dialogue systems. The state-of-the-art dialogue systems are primarily based on unimodal sources, predominantly the text, and hence cannot capture the information present in the other sources such as videos, audios, images etc. With the availability of large scale multimodal dialogue dataset (MMD) (Saha et al., 2018) on the fashion domain, the visual appearance of the products is essential for understanding the intention of the user. Without capturing the information from both the text and image, the system will be incapable of generating correct and desirable responses. In this paper, we propose a novel position and attribute aware attention mechanism to learn enhanced image representation conditioned on the user utterance. Our evaluation shows that the proposed model can generate appropriate responses while preserving the position and attribute information. Experimental results also prove that our proposed approach attains superior performance compared to the baseline models, and outperforms the state-of-the-art approaches on text similarity based evaluation metrics.</abstract>
      <url hash="6e1c9b59">P19-1540</url>
      <doi>10.18653/v1/P19-1540</doi>
      <bibkey>chauhan-etal-2019-ordinal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mmd">MMD</pwcdataset>
    </paper>
    <paper id="543">
      <title>Reading Turn by Turn: Hierarchical Attention Architecture for Spoken Dialogue Comprehension</title>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>5460&#8211;5466</pages>
      <abstract>Comprehending multi-turn spoken conversations is an emerging research area, presenting challenges different from reading comprehension of passages due to the interactive nature of information exchange from at least two speakers. Unlike passages, where sentences are often the default semantic modeling unit, in multi-turn conversations, a turn is a topically coherent unit embodied with immediately relevant context, making it a linguistically intuitive segment for computationally modeling verbal interactions. Therefore, in this work, we propose a hierarchical attention neural network architecture, combining turn-level and word-level attention mechanisms, to improve spoken dialogue comprehension performance. Experiments are conducted on a multi-turn conversation dataset, where nurses inquire and discuss symptom information with patients. We empirically show that the proposed approach outperforms standard attention baselines, achieves more efficient learning outcomes, and is more robust to lengthy and out-of-distribution test samples.</abstract>
      <url hash="2cff57eb">P19-1543</url>
      <doi>10.18653/v1/P19-1543</doi>
      <bibkey>liu-chen-2019-reading</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="544">
      <title>A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling</title>
      <author><first>Haihong</first><last>E</last></author>
      <author><first>Peiqing</first><last>Niu</last></author>
      <author><first>Zhongfu</first><last>Chen</last></author>
      <author><first>Meina</first><last>Song</last></author>
      <pages>5467&#8211;5471</pages>
      <abstract>A spoken language understanding (SLU) system includes two main tasks, slot filling (SF) and intent detection (ID). The joint model for the two tasks is becoming a tendency in SLU. But the bi-directional interrelated connections between the intent and slots are not established in the existing joint models. In this paper, we propose a novel bi-directional interrelated model for joint intent detection and slot filling. We introduce an SF-ID network to establish direct connections for the two tasks to help them promote each other mutually. Besides, we design an entirely new iteration mechanism inside the SF-ID network to enhance the bi-directional interrelated connections. The experimental results show that the relative improvement in the sentence-level semantic frame accuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets, respectively, compared to the state-of-the-art model.</abstract>
      <url hash="ebf8b39a">P19-1544</url>
      <attachment type="supplementary" hash="e00e5a85">P19-1544.Supplementary.zip</attachment>
      <doi>10.18653/v1/P19-1544</doi>
      <bibkey>e-etal-2019-novel</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/atis">ATIS</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snips">SNIPS</pwcdataset>
    </paper>
    <paper id="545">
      <title>Dual Supervised Learning for Natural Language Understanding and Generation</title>
      <author><first>Shang-Yu</first><last>Su</last></author>
      <author><first>Chao-Wei</first><last>Huang</last></author>
      <author><first>Yun-Nung</first><last>Chen</last></author>
      <pages>5472&#8211;5477</pages>
      <abstract>Natural language understanding (NLU) and natural language generation (NLG) are both critical research topics in the NLP and dialogue fields. Natural language understanding is to extract the core semantic meaning from the given utterances, while natural language generation is opposite, of which the goal is to construct corresponding sentences based on the given semantics. However, such dual relationship has not been investigated in literature. This paper proposes a novel learning framework for natural language understanding and generation on top of dual supervised learning, providing a way to exploit the duality. The preliminary experiments show that the proposed approach boosts the performance for both tasks, demonstrating the effectiveness of the dual relationship.</abstract>
      <url hash="297a547f">P19-1545</url>
      <doi>10.18653/v1/P19-1545</doi>
      <bibkey>su-etal-2019-dual</bibkey>
      <pwccode url="https://github.com/MiuLab/DuaLUG" additional="true">MiuLab/DuaLUG</pwccode>
    </paper>
    <paper id="549">
      <title>Modeling Semantic Relationship in Multi-turn Conversations with Hierarchical Latent Variables</title>
      <author><first>Lei</first><last>Shen</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Haolan</first><last>Zhan</last></author>
      <pages>5497&#8211;5502</pages>
      <abstract>Multi-turn conversations consist of complex semantic structures, and it is still a challenge to generate coherent and diverse responses given previous utterances. It&#8217;s practical that a conversation takes place under a background, meanwhile, the query and response are usually most related and they are consistent in topic but also different in content. However, little work focuses on such hierarchical relationship among utterances. To address this problem, we propose a Conversational Semantic Relationship RNN (CSRR) model to construct the dependency explicitly. The model contains latent variables in three hierarchies. The discourse-level one captures the global background, the pair-level one stands for the common topic information between query and response, and the utterance-level ones try to represent differences in content. Experimental results show that our model significantly improves the quality of responses in terms of fluency, coherence, and diversity compared to baseline methods.</abstract>
      <url hash="520238b0">P19-1549</url>
      <doi>10.18653/v1/P19-1549</doi>
      <bibkey>shen-etal-2019-modeling</bibkey>
    </paper>
    <paper id="550">
      <title>Rationally Reappraising <fixed-case>ATIS</fixed-case>-based Dialogue Systems</title>
      <author><first>Jingcheng</first><last>Niu</last></author>
      <author><first>Gerald</first><last>Penn</last></author>
      <pages>5503&#8211;5507</pages>
      <abstract>The Air Travel Information Service (ATIS) corpus has been the most common benchmark for evaluating Spoken Language Understanding (SLU) tasks for more than three decades since it was released. Recent state-of-the-art neural models have obtained F1-scores near 98% on the task of slot filling. We developed a rule-based grammar for the ATIS domain that achieves a 95.82% F1-score on our evaluation set. In the process, we furthermore discovered numerous shortcomings in the ATIS corpus annotation, which we have fixed. This paper presents a detailed account of these shortcomings, our proposed repairs, our rule-based grammar and the neural slot-filling architectures associated with ATIS. We also rationally reappraise the motivations for choosing a neural architecture in view of this account. Fixing the annotation errors results in a relative error reduction of between 19.4 and 52% across all architectures. We nevertheless argue that neural models must play a different role in ATIS dialogues because of the latter&#8217;s lack of variety.</abstract>
      <url hash="1cb35d29">P19-1550</url>
      <doi>10.18653/v1/P19-1550</doi>
      <bibkey>niu-penn-2019-rationally</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/atis">ATIS</pwcdataset>
    </paper>
    <paper id="551">
      <title>Learning Latent Trees with Stochastic Perturbations and Differentiable Dynamic Programming</title>
      <author><first>Caio</first><last>Corro</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <pages>5508&#8211;5521</pages>
      <abstract>We treat projective dependency trees as latent variables in our probabilistic model and induce them in such a way as to be beneficial for a downstream task, without relying on any direct tree supervision. Our approach relies on Gumbel perturbations and differentiable dynamic programming. Unlike previous approaches to latent tree learning, we stochastically sample global structures and our parser is fully differentiable. We illustrate its effectiveness on sentiment analysis and natural language inference tasks. We also study its properties on a synthetic structure induction task. Ablation studies emphasize the importance of both stochasticity and constraining latent structures to be projective trees.</abstract>
      <url hash="d671c266">P19-1551</url>
      <doi>10.18653/v1/P19-1551</doi>
      <bibkey>corro-titov-2019-learning</bibkey>
      <pwccode url="https://github.com/FilippoC/diffdp" additional="false">FilippoC/diffdp</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/listops">ListOps</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="555">
      <title>Soft Contextual Data Augmentation for Neural Machine Translation</title>
      <author><first>Fei</first><last>Gao</last></author>
      <author><first>Jinhua</first><last>Zhu</last></author>
      <author><first>Lijun</first><last>Wu</last></author>
      <author><first>Yingce</first><last>Xia</last></author>
      <author><first>Tao</first><last>Qin</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <author><first>Wengang</first><last>Zhou</last></author>
      <author><first>Tie-Yan</first><last>Liu</last></author>
      <pages>5539&#8211;5544</pages>
      <abstract>While data augmentation is an important trick to boost the accuracy of deep learning methods in computer vision tasks, its study in natural language tasks is still very limited. In this paper, we present a novel data augmentation method for neural machine translation.Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a distribution (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced,the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation data sets demonstrate the superiority of our method over strong baselines.</abstract>
      <url hash="4f32fae0">P19-1555</url>
      <doi>10.18653/v1/P19-1555</doi>
      <bibkey>gao-etal-2019-soft</bibkey>
      <pwccode url="https://github.com/teslacool/SCA" additional="false">teslacool/SCA</pwccode>
    </paper>
    <paper id="556">
      <title>Reversing Gradients in Adversarial Domain Adaptation for Question Deduplication and Textual Entailment Tasks</title>
      <author><first>Anush</first><last>Kamath</last></author>
      <author><first>Sparsh</first><last>Gupta</last></author>
      <author><first>Vitor</first><last>Carvalho</last></author>
      <pages>5545&#8211;5550</pages>
      <abstract>Adversarial domain adaptation has been recently proposed as an effective technique for textual matching tasks, such as question deduplication. Here we investigate the use of gradient reversal on adversarial domain adaptation to explicitly learn both shared and unshared (domain specific) representations between two textual domains. In doing so, gradient reversal learns features that explicitly compensate for domain mismatch, while still distilling domain specific knowledge that can improve target domain accuracy. We evaluate reversing gradients for adversarial adaptation on multiple domains, and demonstrate that it significantly outperforms other methods on question deduplication as well as on recognizing textual entailment (RTE) tasks, achieving up to 7% absolute boost in base model accuracy on some datasets.</abstract>
      <url hash="d4673a9c">P19-1556</url>
      <doi>10.18653/v1/P19-1556</doi>
      <bibkey>kamath-etal-2019-reversing</bibkey>
    </paper>
    <paper id="559">
      <title>Generating Fluent Adversarial Examples for Natural Languages</title>
      <author><first>Huangzhao</first><last>Zhang</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Ning</first><last>Miao</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>5564&#8211;5569</pages>
      <abstract>Efficiently building an adversarial attacker for natural language processing (NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it is difficult to make small perturbations along the direction of gradients. Secondly, the fluency of the generated examples cannot be guaranteed. In this paper, we propose MHA, which addresses both problems by performing Metropolis-Hastings sampling, whose proposal is designed with the guidance of gradients. Experiments on IMDB and SNLI show that our proposed MHAoutperforms the baseline model on attacking capability. Adversarial training with MHA also leads to better robustness and performance.</abstract>
      <url hash="ccbfd155">P19-1559</url>
      <attachment type="supplementary" hash="29b13efa">P19-1559.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1559</doi>
      <bibkey>zhang-etal-2019-generating-fluent</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="560">
      <title>Towards Explainable <fixed-case>NLP</fixed-case>: A Generative Explanation Framework for Text Classification</title>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Qingyu</first><last>Yin</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>5570&#8211;5581</pages>
      <abstract>Building explainable systems is a critical problem in the field of Natural Language Processing (NLP), since most machine learning models provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information (e.g. textual explanations for the labels) is often ignored, and the systems do not explicitly generate the human-readable explanations. To solve this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new datasets that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both datasets, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both datasets, and is able to generate concise explanations at the same time.</abstract>
      <url hash="7e21e563">P19-1560</url>
      <doi>10.18653/v1/P19-1560</doi>
      <bibkey>liu-etal-2019-towards-explainable</bibkey>
    </paper>
    <paper id="561">
      <title>Combating Adversarial Misspellings with Robust Word Recognition</title>
      <author><first>Danish</first><last>Pruthi</last></author>
      <author><first>Bhuwan</first><last>Dhingra</last></author>
      <author><first>Zachary C.</first><last>Lipton</last></author>
      <pages>5582&#8211;5591</pages>
      <abstract>To combat adversarial spelling mistakes, we propose placing a word recognition model in front of the downstream classifier. Our word recognition models build upon the RNN semi-character architecture, introducing several new backoff strategies for handling rare and unseen words. Trained to recognize words corrupted by random adds, drops, swaps, and keyboard mistakes, our method achieves 32% relative (and 3.3% absolute) error reduction over the vanilla semi-character model. Notably, our pipeline confers robustness on the downstream classifier, outperforming both adversarial training and off-the-shelf spell checkers. Against a BERT model fine-tuned for sentiment analysis, a single adversarially-chosen character attack lowers accuracy from 90.3% to 45.8%. Our defense restores accuracy to 75%. Surprisingly, better word recognition does not always entail greater robustness. Our analysis reveals that robustness also depends upon a quantity that we denote the sensitivity.</abstract>
      <url hash="d0c241a9">P19-1561</url>
      <doi>10.18653/v1/P19-1561</doi>
      <bibkey>pruthi-etal-2019-combating</bibkey>
      <pwccode url="https://github.com/danishpruthi/Adversarial-Misspellings" additional="true">danishpruthi/Adversarial-Misspellings</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mrpc">MRPC</pwcdataset>
    </paper>
    <paper id="562">
      <title>An Empirical Investigation of Structured Output Modeling for Graph-based Neural Dependency Parsing</title>
      <author><first>Zhisong</first><last>Zhang</last></author>
      <author><first>Xuezhe</first><last>Ma</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>5592&#8211;5598</pages>
      <abstract>In this paper, we investigate the aspect of structured output modeling for the state-of-the-art graph-based neural dependency parser (Dozat and Manning, 2017). With evaluations on 14 treebanks, we empirically show that global output-structured models can generally obtain better performance, especially on the metric of sentence-level Complete Match. However, probably because neural models already learn good global views of the inputs, the improvement brought by structured output modeling is modest.</abstract>
      <url hash="438bda11">P19-1562</url>
      <attachment type="supplementary" hash="c74c11ca">P19-1562.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1562</doi>
      <bibkey>zhang-etal-2019-empirical</bibkey>
      <pwccode url="https://github.com/zzsfornlp/zmsp" additional="false">zzsfornlp/zmsp</pwccode>
    </paper>
    <paper id="563">
      <title>Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral Codes</title>
      <author><first>Jie</first><last>Cao</last></author>
      <author><first>Michael</first><last>Tanana</last></author>
      <author><first>Zac</first><last>Imel</last></author>
      <author><first>Eric</first><last>Poitras</last></author>
      <author><first>David</first><last>Atkins</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <pages>5599&#8211;5611</pages>
      <abstract>Automatically analyzing dialogue can help understand and guide behavior in domains such as counseling, where interactions are largely mediated by conversation. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define neural network models that build upon recent successes in dialogue modeling. Our experiments demonstrate that our models can outperform several baselines for both tasks. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.</abstract>
      <url hash="7443bcba">P19-1563</url>
      <attachment type="supplementary" hash="93a85eaf">P19-1563.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/385223469" />
      <doi>10.18653/v1/P19-1563</doi>
      <bibkey>cao-etal-2019-observing</bibkey>
      <pwccode url="https://github.com/utahnlp/therapist-observer" additional="false">utahnlp/therapist-observer</pwccode>
    </paper>
    <paper id="565">
      <title>Target-Guided Open-Domain Conversation</title>
      <author><first>Jianheng</first><last>Tang</last></author>
      <author><first>Tiancheng</first><last>Zhao</last></author>
      <author><first>Chenyan</first><last>Xiong</last></author>
      <author><first>Xiaodan</first><last>Liang</last></author>
      <author><first>Eric</first><last>Xing</last></author>
      <author><first>Zhiting</first><last>Hu</last></author>
      <pages>5624&#8211;5634</pages>
      <abstract>Many real-world open-domain conversation applications have specific goals to achieve during open-ended chats, such as recommendation, psychotherapy, education, etc. We study the problem of imposing conversational goals on open-domain chat agents. In particular, we want a conversational system to chat naturally with human and proactively guide the conversation to a designated target subject. The problem is challenging as no public data is available for learning such a target-guided strategy. We propose a structured approach that introduces coarse-grained keywords to control the intended content of system responses. We then attain smooth conversation transition through turn-level supervised learning, and drive the conversation towards the target with discourse-level constraints. We further derive a keyword-augmented conversation dataset for the study. Quantitative and human evaluations show our system can produce meaningful and effective conversations, significantly improving over other approaches</abstract>
      <url hash="b6d3ead8">P19-1565</url>
      <attachment type="supplementary" hash="d5866644">P19-1565.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/385223824" />
      <doi>10.18653/v1/P19-1565</doi>
      <bibkey>tang-etal-2019-target</bibkey>
      <pwccode url="https://github.com/squareRoot3/Target-Guided-Conversation" additional="true">squareRoot3/Target-Guided-Conversation</pwccode>
    </paper>
    <paper id="566">
      <title>Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good</title>
      <author><first>Xuewei</first><last>Wang</last></author>
      <author><first>Weiyan</first><last>Shi</last></author>
      <author><first>Richard</first><last>Kim</last></author>
      <author><first>Yoojung</first><last>Oh</last></author>
      <author><first>Sijia</first><last>Yang</last></author>
      <author><first>Jingwen</first><last>Zhang</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>5635&#8211;5649</pages>
      <abstract>Developing intelligent persuasive conversational agents to change people&#8217;s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals&#8217; demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals&#8217; personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.</abstract>
      <url hash="9bc397c9">P19-1566</url>
      <video href="https://vimeo.com/385225678" />
      <doi>10.18653/v1/P19-1566</doi>
      <bibkey>wang-etal-2019-persuasion</bibkey>
      <pwccode url="https://gitlab.com/ucdavisnlp/persuasionforgood" additional="true">ucdavisnlp/persuasionforgood</pwccode>
    </paper>
    <paper id="569">
      <title>Language Modelling Makes Sense: Propagating Representations through <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for Full-Coverage Word Sense Disambiguation</title>
      <author><first>Daniel</first><last>Loureiro</last></author>
      <author><first>Al&#237;pio</first><last>Jorge</last></author>
      <pages>5682&#8211;5691</pages>
      <abstract>Contextual embeddings represent a new generation of semantic representations learned from Neural Language Modelling (NLM) that addresses the issue of meaning conflation hampering traditional word embeddings. In this work, we show that contextual embeddings can be used to achieve unprecedented gains in Word Sense Disambiguation (WSD) tasks. Our approach focuses on creating sense-level embeddings with full-coverage of WordNet, and without recourse to explicit knowledge of sense distributions or task-specific modelling. As a result, a simple Nearest Neighbors (k-NN) method using our representations is able to consistently surpass the performance of previous systems using powerful neural sequencing models. We also analyse the robustness of our approach when ignoring part-of-speech and lemma features, requiring disambiguation against the full sense inventory, and revealing shortcomings to be improved. Finally, we explore applications of our sense embeddings for concept-level analyses of contextual embeddings and their respective NLMs.</abstract>
      <url hash="89fc428e">P19-1569</url>
      <video href="https://vimeo.com/385428418" />
      <doi>10.18653/v1/P19-1569</doi>
      <bibkey>loureiro-jorge-2019-language</bibkey>
      <pwccode url="https://github.com/danlou/LMMS" additional="false">danlou/LMMS</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    <paper id="570">
      <title><fixed-case>W</fixed-case>ord2<fixed-case>S</fixed-case>ense: Sparse Interpretable Word Embeddings</title>
      <author><first>Abhishek</first><last>Panigrahi</last></author>
      <author><first>Harsha Vardhan</first><last>Simhadri</last></author>
      <author><first>Chiranjib</first><last>Bhattacharyya</last></author>
      <pages>5692&#8211;5705</pages>
      <abstract>We present an unsupervised method to generate Word2Sense word embeddings that are interpretable &#8212; each dimension of the embedding space corresponds to a fine-grained sense, and the non-negative value of the embedding along the j-th dimension represents the relevance of the j-th sense to the word. The underlying LDA-based generative model can be extended to refine the representation of a polysemous word in a short context, allowing us to use the embedings in contextual tasks. On computational NLP tasks, Word2Sense embeddings compare well with other word embeddings generated by unsupervised methods. Across tasks such as word similarity, entailment, sense induction, and contextual interpretation, Word2Sense is competitive with the state-of-the-art method for that task. Word2Sense embeddings are at least as sparse and fast to compute as prior art.</abstract>
      <url hash="040da2a5">P19-1570</url>
      <video href="https://vimeo.com/385428467" />
      <doi>10.18653/v1/P19-1570</doi>
      <bibkey>panigrahi-etal-2019-word2sense</bibkey>
    </paper>
    <paper id="571">
      <title>Modeling Semantic Compositionality with Sememe Knowledge</title>
      <author><first>Fanchao</first><last>Qi</last></author>
      <author><first>Junjie</first><last>Huang</last></author>
      <author><first>Chenghao</first><last>Yang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Xiao</first><last>Chen</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>5706&#8211;5715</pages>
      <abstract>Semantic compositionality (SC) refers to the phenomenon that the meaning of a complex linguistic unit can be composed of the meanings of its constituents. Most related works focus on using complicated compositionality functions to model SC while few works consider external knowledge in models. In this paper, we verify the effectiveness of sememes, the minimum semantic units of human languages, in modeling SC by a confirmatory experiment. Furthermore, we make the first attempt to incorporate sememe knowledge into SC models, and employ the sememe-incorporated models in learning representations of multiword expressions, a typical task of SC. In experiments, we implement our models by incorporating knowledge from a famous sememe knowledge base HowNet and perform both intrinsic and extrinsic evaluations. Experimental results show that our models achieve significant performance boost as compared to the baseline methods without considering sememe knowledge. We further conduct quantitative analysis and case studies to demonstrate the effectiveness of applying sememe knowledge in modeling SC.All the code and data of this paper can be obtained on https://github.com/thunlp/Sememe-SC.</abstract>
      <url hash="10f7c3de">P19-1571</url>
      <video href="https://vimeo.com/385428643" />
      <doi>10.18653/v1/P19-1571</doi>
      <bibkey>qi-etal-2019-modeling</bibkey>
      <pwccode url="https://github.com/thunlp/Sememe-SC" additional="false">thunlp/Sememe-SC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cos960">COS960</pwcdataset>
    </paper>
    <paper id="573">
      <title>Empirical Linguistic Study of Sentence Embeddings</title>
      <author><first>Katarzyna</first><last>Krasnowska-Kiera&#347;</last></author>
      <author><first>Alina</first><last>Wr&#243;blewska</last></author>
      <pages>5729&#8211;5739</pages>
      <abstract>The purpose of the research is to answer the question whether linguistic information is retained in vector representations of sentences. We introduce a method of analysing the content of sentence embeddings based on universal probing tasks, along with the classification datasets for two contrasting languages. We perform a series of probing and downstream experiments with different types of sentence embeddings, followed by a thorough analysis of the experimental results. Aside from dependency parser-based embeddings, linguistic information is retained best in the recently proposed LASER sentence embeddings.</abstract>
      <url hash="920cb787">P19-1573</url>
      <video href="https://vimeo.com/385428708" />
      <doi>10.18653/v1/P19-1573</doi>
      <bibkey>krasnowska-kieras-wroblewska-2019-empirical</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/senteval">SentEval</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="574">
      <title>Probing for Semantic Classes: Diagnosing the Meaning Content of Word Embeddings</title>
      <author><first>Yadollah</first><last>Yaghoobzadeh</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>T. J.</first><last>Hazen</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <author><first>Hinrich</first><last>Sch&#252;tze</last></author>
      <pages>5740&#8211;5753</pages>
      <abstract>Word embeddings typically represent different meanings of a word in a single conflated vector. Empirical analysis of embeddings of ambiguous words is currently limited by the small size of manually annotated resources and by the fact that word senses are treated as unrelated individual concepts. We present a large dataset based on manual Wikipedia annotations and word senses, where word senses from different words are related by semantic classes. This is the basis for novel diagnostic tests for an embedding&#8217;s content: we probe word embeddings for semantic classes and analyze the embedding space by classifying embeddings into semantic classes. Our main findings are: (i) Information about a sense is generally represented well in a single-vector embedding &#8211; if the sense is frequent. (ii) A classifier can accurately predict whether a word is single-sense or multi-sense, based only on its embedding. (iii) Although rare senses are not well represented in single-vector embeddings, this does not have negative impact on an NLP application whose performance depends on frequent senses.</abstract>
      <url hash="8d3ef09c">P19-1574</url>
      <video href="https://vimeo.com/385429181" />
      <doi>10.18653/v1/P19-1574</doi>
      <bibkey>yaghoobzadeh-etal-2019-probing</bibkey>
      <pwccode url="https://github.com/yyaghoobzadeh/WIKI-PSE" additional="false">yyaghoobzadeh/WIKI-PSE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/senteval">SentEval</pwcdataset>
    </paper>
    <paper id="575">
      <title>Deep Neural Model Inspection and Comparison via Functional Neuron Pathways</title>
      <author><first>James</first><last>Fiacco</last></author>
      <author><first>Samridhi</first><last>Choudhary</last></author>
      <author><first>Carolyn</first><last>Rose</last></author>
      <pages>5754&#8211;5764</pages>
      <abstract>We introduce a general method for the interpretation and comparison of neural models. The method is used to factor a complex neural model into its functional components, which are comprised of sets of co-firing neurons that cut across layers of the network architecture, and which we call neural pathways. The function of these pathways can be understood by identifying correlated task level and linguistic heuristics in such a way that this knowledge acts as a lens for approximating what the network has learned to apply to its intended task. As a case study for investigating the utility of these pathways, we present an examination of pathways identified in models trained for two standard tasks, namely Named Entity Recognition and Recognizing Textual Entailment.</abstract>
      <url hash="533a1237">P19-1575</url>
      <video href="https://vimeo.com/385434363" />
      <doi>10.18653/v1/P19-1575</doi>
      <bibkey>fiacco-etal-2019-deep</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
    </paper>
    <paper id="579">
      <title>Generalized Data Augmentation for Low-Resource Translation</title>
      <author><first>Mengzhou</first><last>Xia</last></author>
      <author><first>Xiang</first><last>Kong</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5786&#8211;5796</pages>
      <abstract>Low-resource language pairs with a paucity of parallel data pose challenges for machine translation in terms of both adequacy and fluency. Data augmentation utilizing a large amount of monolingual data is regarded as an effective way to alleviate the problem. In this paper, we propose a general framework of data augmentation for low-resource machine translation not only using target-side monolingual data, but also by pivoting through a related high-resource language. Specifically, we experiment with a two-step pivoting method to convert high-resource data to the low-resource language, making best use of available resources to better approximate the true distribution of the low-resource language. First, we inject low-resource words into high-resource sentences through an induced bilingual dictionary. Second, we further edit the high-resource data injected with low-resource words using a modified unsupervised machine translation framework. Extensive experiments on four low-resource datasets show that under extreme low-resource settings, our data augmentation techniques improve translation quality by up to 1.5 to 8 BLEU points compared to supervised back-translation baselines.</abstract>
      <url hash="10d26d60">P19-1579</url>
      <video href="https://vimeo.com/385226257" />
      <doi>10.18653/v1/P19-1579</doi>
      <bibkey>xia-etal-2019-generalized</bibkey>
    </paper>
    <paper id="581">
      <title>Better <fixed-case>OOV</fixed-case> Translation with Bilingual Terminology Mining</title>
      <author><first>Matthias</first><last>Huck</last></author>
      <author><first>Viktor</first><last>Hangya</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>5809&#8211;5815</pages>
      <abstract>Unseen words, also called out-of-vocabulary words (OOVs), are difficult for machine translation. In neural machine translation, byte-pair encoding can be used to represent OOVs, but they are still often incorrectly translated. We improve the translation of OOVs in NMT using easy-to-obtain monolingual data. We look for OOVs in the text to be translated and translate them using simple-to-construct bilingual word embeddings (BWEs). In our MT experiments we take the 5-best candidates, which is motivated by intrinsic mining experiments. Using all five of the proposed target language words as queries we mine target-language sentences. We then back-translate, forcing the back-translation of each of the five proposed target-language OOV-translation-candidates to be the original source-language OOV. We show that by using this synthetic data to fine-tune our system the translation of OOVs can be dramatically improved. In our experiments we use a system trained on Europarl and mine sentences containing medical terms from monolingual data.</abstract>
      <url hash="50c1135e">P19-1581</url>
      <video href="https://vimeo.com/385434714" />
      <doi>10.18653/v1/P19-1581</doi>
      <bibkey>huck-etal-2019-better</bibkey>
    </paper>
    <paper id="583">
      <title>Target Conditioned Sampling: Optimizing Data Selection for Multilingual Neural Machine Translation</title>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>5823&#8211;5828</pages>
      <abstract>To improve low-resource Neural Machine Translation (NMT) with multilingual corpus, training on the most related high-resource language only is generally more effective than us- ing all data available (Neubig and Hu, 2018). However, it remains a question whether a smart data selection strategy can further improve low-resource NMT with data from other auxiliary languages. In this paper, we seek to construct a sampling distribution over all multilingual data, so that it minimizes the training loss of the low-resource language. Based on this formulation, we propose and efficient algorithm, (TCS), which first samples a target sentence, and then conditionally samples its source sentence. Experiments show TCS brings significant gains of up to 2 BLEU improvements on three of four languages we test, with minimal training overhead.</abstract>
      <url hash="fca3f4aa">P19-1583</url>
      <video href="https://vimeo.com/385434805" />
      <doi>10.18653/v1/P19-1583</doi>
      <bibkey>wang-neubig-2019-target</bibkey>
    </paper>
    <paper id="585">
      <title>Merge and Label: A Novel Neural Network Architecture for Nested <fixed-case>NER</fixed-case></title>
      <author><first>Joseph</first><last>Fisher</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>5840&#8211;5850</pages>
      <abstract>Named entity recognition (NER) is one of the best studied tasks in natural language processing. However, most approaches are not capable of handling nested structures which are common in many applications. In this paper we introduce a novel neural network architecture that first merges tokens and/or entities into entities forming nested structures, and then labels each of them independently. Unlike previous work, our merge and label approach predicts real-valued instead of discrete segmentation structures, which allow it to combine word and nested entity embeddings while maintaining differentiability. We evaluate our approach using the ACE 2005 Corpus, where it achieves state-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT) to 82.4, an overall improvement of close to 8 F1 points over previous approaches trained on the same data. Additionally we compare it against BiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that its ability to predict nested structures does not impact performance in simpler cases.</abstract>
      <url hash="e89dc31a">P19-1585</url>
      <video href="https://vimeo.com/385226453" />
      <doi>10.18653/v1/P19-1585</doi>
      <bibkey>fisher-vlachos-2019-merge</bibkey>
      <pwccode url="https://github.com/fishjh2/merge_label" additional="false">fishjh2/merge_label</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ace-2005">ACE 2005</pwcdataset>
    </paper>
    <paper id="586">
      <title>Low-resource Deep Entity Resolution with Transfer and Active Learning</title>
      <author><first>Jungo</first><last>Kasai</last></author>
      <author><first>Kun</first><last>Qian</last></author>
      <author><first>Sairam</first><last>Gurajada</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Lucian</first><last>Popa</last></author>
      <pages>5851&#8211;5861</pages>
      <abstract>Entity resolution (ER) is the task of identifying different representations of the same real-world entities across databases. It is a key step for knowledge base creation and text mining. Recent adaptation of deep learning methods for ER mitigates the need for dataset-specific feature engineering by constructing distributed representations of entity records. While these methods achieve state-of-the-art performance over benchmark data, they require large amounts of labeled data, which are typically unavailable in realistic ER applications. In this paper, we develop a deep learning-based method that targets low-resource settings for ER through a novel combination of transfer learning and active learning. We design an architecture that allows us to learn a transferable model from a high-resource setting to a low-resource one. To further adapt to the target dataset, we incorporate active learning that carefully selects a few informative examples to fine-tune the transferred model. Empirical evaluation demonstrates that our method achieves comparable, if not better, performance compared to state-of-the-art learning-based methods while using an order of magnitude fewer labels.</abstract>
      <url hash="acdda0e6">P19-1586</url>
      <video href="https://vimeo.com/385226574" />
      <doi>10.18653/v1/P19-1586</doi>
      <bibkey>kasai-etal-2019-low</bibkey>
    </paper>
    <paper id="587">
      <title>A Semi-<fixed-case>M</fixed-case>arkov Structured Support Vector Machine Model for High-Precision Named Entity Recognition</title>
      <author><first>Ravneet</first><last>Arora</last></author>
      <author><first>Chen-Tse</first><last>Tsai</last></author>
      <author><first>Ketevan</first><last>Tsereteli</last></author>
      <author><first>Prabhanjan</first><last>Kambadur</last></author>
      <author><first>Yi</first><last>Yang</last></author>
      <pages>5862&#8211;5866</pages>
      <abstract>Named entity recognition (NER) is the backbone of many NLP solutions. F1 score, the harmonic mean of precision and recall, is often used to select/evaluate the best models. However, when precision needs to be prioritized over recall, a state-of-the-art model might not be the best choice. There is little in literature that directly addresses training-time modifications to achieve higher precision information extraction. In this paper, we propose a neural semi-Markov structured support vector machine model that controls the precision-recall trade-off by assigning weights to different types of errors in the loss-augmented inference during training. The semi-Markov property provides more accurate phrase-level predictions, thereby improving performance. We empirically demonstrate the advantage of our model when high precision is required by comparing against strong baselines based on CRF. In our experiments with the CoNLL 2003 dataset, our model achieves a better precision-recall trade-off at various precision levels.</abstract>
      <url hash="aebe889c">P19-1587</url>
      <attachment type="supplementary" hash="57766d63">P19-1587.Supplementary.pdf</attachment>
      <video href="https://vimeo.com/385242676" />
      <doi>10.18653/v1/P19-1587</doi>
      <bibkey>arora-etal-2019-semi</bibkey>
    </paper>
    <paper id="589">
      <title>Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision</title>
      <author><first>Abiola</first><last>Obamuyide</last></author>
      <author><first>Andreas</first><last>Vlachos</last></author>
      <pages>5873&#8211;5879</pages>
      <abstract>In this paper we frame the task of supervised relation classification as an instance of meta-learning. We propose a model-agnostic meta-learning protocol for training relation classifiers to achieve enhanced predictive performance in limited supervision settings. During training, we aim to not only learn good parameters for classifying relations with sufficient supervision, but also learn model parameters that can be fine-tuned to enhance predictive performance for relations with limited supervision. In experiments conducted on two relation classification datasets, we demonstrate that the proposed meta-learning approach improves the predictive performance of two state-of-the-art supervised relation classification models.</abstract>
      <url hash="557f6db3">P19-1589</url>
      <video href="https://vimeo.com/385243188" />
      <doi>10.18653/v1/P19-1589</doi>
      <bibkey>obamuyide-vlachos-2019-model</bibkey>
    </paper>
    <paper id="601">
      <title>Style Transformer: Unpaired Text Style Transfer without Disentangled Latent Representation</title>
      <author><first>Ning</first><last>Dai</last></author>
      <author><first>Jianze</first><last>Liang</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>5997&#8211;6007</pages>
      <abstract>Disentangling the content and style in the latent space is prevalent in unpaired text style transfer. However, two major issues exist in most of the current neural models. 1) It is difficult to completely strip the style information from the semantics for a sentence. 2) The recurrent neural network (RNN) based encoder and decoder, mediated by the latent representation, cannot well deal with the issue of the long-term dependency, resulting in poor preservation of non-stylistic semantic content. In this paper, we propose the Style Transformer, which makes no assumption about the latent representation of source sentence and equips the power of attention mechanism in Transformer to achieve better style transfer and better content preservation.</abstract>
      <url hash="0ca2c53d">P19-1601</url>
      <doi>10.18653/v1/P19-1601</doi>
      <bibkey>dai-etal-2019-style</bibkey>
      <pwccode url="https://github.com/fastnlp/style-transformer" additional="true">fastnlp/style-transformer</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="603">
      <title>Learning to Control the Fine-grained Sentiment for Story Ending Generation</title>
      <author><first>Fuli</first><last>Luo</last></author>
      <author><first>Damai</first><last>Dai</last></author>
      <author><first>Pengcheng</first><last>Yang</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>6020&#8211;6026</pages>
      <abstract>Automatic story ending generation is an interesting and challenging task in natural language generation. Previous studies are mainly limited to generate coherent, reasonable and diversified story endings, and few works focus on controlling the sentiment of story endings. This paper focuses on generating a story ending which meets the given fine-grained sentiment intensity. There are two major challenges to this task. First is the lack of story corpus which has fine-grained sentiment labels. Second is the difficulty of explicitly controlling sentiment intensity when generating endings. Therefore, we propose a generic and novel framework which consists of a sentiment analyzer and a sentimental generator, respectively addressing the two challenges. The sentiment analyzer adopts a series of methods to acquire sentiment intensities of the story dataset. The sentimental generator introduces the sentiment intensity into decoder via a Gaussian Kernel Layer to control the sentiment of the output. To the best of our knowledge, this is the first endeavor to control the fine-grained sentiment for story ending generation without manually annotating sentiment labels. Experiments show that our proposed framework can generate story endings which are not only more coherent and fluent but also able to meet the given sentiment intensity better.</abstract>
      <url hash="9ba30680">P19-1603</url>
      <doi>10.18653/v1/P19-1603</doi>
      <bibkey>luo-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="606">
      <title>Storyboarding of Recipes: Grounded Contextual Generation</title>
      <author><first>Khyathi</first><last>Chandu</last></author>
      <author><first>Eric</first><last>Nyberg</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>6040&#8211;6046</pages>
      <abstract>Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a dataset for sequential procedural (how-to) text generation from images in cooking domain. The dataset consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by: (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing model (SSiL) achieves a METEOR score of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61% found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.</abstract>
      <url hash="ac1523e3">P19-1606</url>
      <doi>10.18653/v1/P19-1606</doi>
      <bibkey>chandu-etal-2019-storyboarding</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/vist">VIST</pwcdataset>
    </paper>
    <paper id="607">
      <title>Negative Lexically Constrained Decoding for Paraphrase Generation</title>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <pages>6047&#8211;6052</pages>
      <abstract>Paraphrase generation can be regarded as monolingual translation. Unlike bilingual machine translation, paraphrase generation rewrites only a limited portion of an input sentence. Hence, previous methods based on machine translation often perform conservatively to fail to make necessary rewrites. To solve this problem, we propose a neural model for paraphrase generation that first identifies words in the source sentence that should be paraphrased. Then, these words are paraphrased by the negative lexically constrained decoding that avoids outputting these words as they are. Experiments on text simplification and formality transfer show that our model improves the quality of paraphrasing by making necessary rewrites to an input sentence.</abstract>
      <url hash="0542d1ba">P19-1607</url>
      <doi>10.18653/v1/P19-1607</doi>
      <bibkey>kajiwara-2019-negative</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/gyafc">GYAFC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
    </paper>
    <paper id="610">
      <title>Improving the Robustness of Question Answering Systems to Question Paraphrasing</title>
      <author><first>Wee Chung</first><last>Gan</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <pages>6065&#8211;6075</pages>
      <abstract>Despite the advancement of question answering (QA) systems and rapid improvements on held-out test sets, their generalizability is a topic of concern. We explore the robustness of QA models to question paraphrasing by creating two test sets consisting of paraphrased SQuAD questions. Paraphrased questions from the first test set are very similar to the original questions designed to test QA models&#8217; over-sensitivity, while questions from the second test set are paraphrased using context words near an incorrect answer candidate in an attempt to confuse QA models. We show that both paraphrased test sets lead to significant decrease in performance on multiple state-of-the-art QA models. Using a neural paraphrasing model trained to generate multiple paraphrased questions for a given source question and a set of paraphrase suggestions, we propose a data augmentation approach that requires no human intervention to re-train the models for improved robustness to question paraphrasing.</abstract>
      <url hash="3b4820de">P19-1610</url>
      <doi>10.18653/v1/P19-1610</doi>
      <bibkey>gan-ng-2019-improving</bibkey>
      <pwccode url="https://github.com/nusnlp/paraphrasing-squad" additional="false">nusnlp/paraphrasing-squad</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="611">
      <title><fixed-case>R</fixed-case>ank<fixed-case>QA</fixed-case>: Neural Question Answering with Answer Re-Ranking</title>
      <author><first>Bernhard</first><last>Kratzwald</last></author>
      <author><first>Anna</first><last>Eigenmann</last></author>
      <author><first>Stefan</first><last>Feuerriegel</last></author>
      <pages>6076&#8211;6085</pages>
      <abstract>The conventional paradigm in neural question answering (QA) for narrative content is limited to a two-stage process: first, relevant text passages are retrieved and, subsequently, a neural network for machine comprehension extracts the likeliest answer. However, both stages are largely isolated in the status quo and, hence, information from the two phases is never properly fused. In contrast, this work proposes RankQA: RankQA extends the conventional two-stage process in neural QA with a third stage that performs an additional answer re-ranking. The re-ranking leverages different features that are directly extracted from the QA pipeline, i.e., a combination of retrieval and comprehension features. While our intentionally simple design allows for an efficient, data-sparse estimation, it nevertheless outperforms more complex QA systems by a significant margin: in fact, RankQA achieves state-of-the-art performance on 3 out of 4 benchmark datasets. Furthermore, its performance is especially superior in settings where the size of the corpus is dynamic. Here the answer re-ranking provides an effective remedy against the underlying noise-information trade-off due to a variable corpus size. As a consequence, RankQA represents a novel, powerful, and thus challenging baseline for future research in content-based QA.</abstract>
      <url hash="c4e50faf">P19-1611</url>
      <doi>10.18653/v1/P19-1611</doi>
      <bibkey>kratzwald-etal-2019-rankqa</bibkey>
      <pwccode url="https://github.com/bernhard2202/rankqa" additional="false">bernhard2202/rankqa</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimovies">WikiMovies</pwcdataset>
    </paper>
    <paper id="613">
      <title>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</title>
      <author><first>Sewon</first><last>Min</last></author>
      <author><first>Victor</first><last>Zhong</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <pages>6097&#8211;6109</pages>
      <abstract>Multi-hop Reading Comprehension (RC) requires reasoning and aggregation across several paragraphs. We propose a system for multi-hop RC that decomposes a compositional question into simpler sub-questions that can be answered by off-the-shelf single-hop RC models. Since annotations for such decomposition are expensive, we recast subquestion generation as a span prediction problem and show that our method, trained using only 400 labeled examples, generates sub-questions that are as effective as human-authored sub-questions. We also introduce a new global rescoring approach that considers each decomposition (i.e. the sub-questions and their answers) to select the best final answer, greatly improving overall performance. Our experiments on HotpotQA show that this approach achieves the state-of-the-art results, while providing explainable evidence for its decision making in the form of sub-questions.</abstract>
      <url hash="d24cabf7">P19-1613</url>
      <doi>10.18653/v1/P19-1613</doi>
      <bibkey>min-etal-2019-multi</bibkey>
      <pwccode url="https://github.com/shmsw25/DecompRC" additional="true">shmsw25/DecompRC</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hotpotqa">HotpotQA</pwcdataset>
    </paper>
    <paper id="614">
      <title>Combining Knowledge Hunting and Neural Language Models to Solve the <fixed-case>W</fixed-case>inograd Schema Challenge</title>
      <author><first>Ashok</first><last>Prakash</last></author>
      <author><first>Arpit</first><last>Sharma</last></author>
      <author><first>Arindam</first><last>Mitra</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <pages>6110&#8211;6119</pages>
      <abstract>Winograd Schema Challenge (WSC) is a pronoun resolution task which seems to require reasoning with commonsense knowledge. The needed knowledge is not present in the given text. Automatic extraction of the needed knowledge is a bottleneck in solving the challenge. The existing state-of-the-art approach uses the knowledge embedded in their pre-trained language model. However, the language models only embed part of the knowledge, the ones related to frequently co-existing concepts. This limits the performance of such models on the WSC problems. In this work, we build-up on the language model based methods and augment them with a commonsense knowledge hunting (using automatic extraction from text) module and an explicit reasoning module. Our end-to-end system built in such a manner improves on the accuracy of two of the available language model based approaches by 5.53% and 7.7% respectively. Overall our system achieves the state-of-the-art accuracy of 71.06% on the WSC dataset, an improvement of 7.36% over the previous best.</abstract>
      <url hash="14fdd018">P19-1614</url>
      <doi>10.18653/v1/P19-1614</doi>
      <bibkey>prakash-etal-2019-combining</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wsc">WSC</pwcdataset>
    </paper>
    <paper id="615">
      <title>Careful Selection of Knowledge to Solve Open Book Question Answering</title>
      <author><first>Pratyay</first><last>Banerjee</last></author>
      <author><first>Kuntal Kumar</first><last>Pal</last></author>
      <author><first>Arindam</first><last>Mitra</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <pages>6120&#8211;6129</pages>
      <abstract>Open book question answering is a type of natural language based QA (NLQA) where questions are expected to be answered with respect to a given set of open book facts, and common knowledge about a topic. Recently a challenge involving such QA, OpenBookQA, has been proposed. Unlike most other NLQA that focus on linguistic understanding, OpenBookQA requires deeper reasoning involving linguistic understanding as well as reasoning with common knowledge. In this paper we address QA with respect to the OpenBookQA dataset and combine state of the art language models with abductive information retrieval (IR), information gain based re-ranking, passage selection and weighted scoring to achieve 72.0% accuracy, an 11.6% improvement over the current state of the art.</abstract>
      <url hash="4562abfd">P19-1615</url>
      <doi>10.18653/v1/P19-1615</doi>
      <bibkey>banerjee-etal-2019-careful</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/openbookqa">OpenBookQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="616">
      <title>Learning Representation Mapping for Relation Detection in Knowledge Base Question Answering</title>
      <author><first>Peng</first><last>Wu</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Rongxiang</first><last>Weng</last></author>
      <author><first>Zaixiang</first><last>Zheng</last></author>
      <author><first>Jianbing</first><last>Zhang</last></author>
      <author><first>Xiaohui</first><last>Yan</last></author>
      <author><first>Jiajun</first><last>Chen</last></author>
      <pages>6130&#8211;6139</pages>
      <abstract>Relation detection is a core step in many natural language process applications including knowledge base question answering. Previous efforts show that single-fact questions could be answered with high accuracy. However, one critical problem is that current approaches only get high accuracy for questions whose relations have been seen in the training data. But for unseen relations, the performance will drop rapidly. The main reason for this problem is that the representations for unseen relations are missing. In this paper, we propose a simple mapping method, named representation adapter, to learn the representation mapping for both seen and unseen relations based on previously learned relation embedding. We employ the adversarial objective and the reconstruction objective to improve the mapping performance. We re-organize the popular SimpleQuestion dataset to reveal and evaluate the problem of detecting unseen relations. Experiments show that our method can greatly improve the performance of unseen relations while the performance for those seen part is kept comparable to the state-of-the-art.</abstract>
      <url hash="af975275">P19-1616</url>
      <doi>10.18653/v1/P19-1616</doi>
      <bibkey>wu-etal-2019-learning-representation</bibkey>
      <pwccode url="https://github.com/wudapeng268/KBQA-Adapter" additional="false">wudapeng268/KBQA-Adapter</pwccode>
    </paper>
    <paper id="621">
      <title>Are Red Roses Red? Evaluating Consistency of Question-Answering Models</title>
      <author><first>Marco Tulio</first><last>Ribeiro</last></author>
      <author><first>Carlos</first><last>Guestrin</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <pages>6174&#8211;6184</pages>
      <abstract>Although current evaluation of question-answering systems treats predictions in isolation, we need to consider the relationship between predictions to measure true understanding. A model should be penalized for answering &#8220;no&#8221; to &#8220;Is the rose red?&#8221; if it answers &#8220;red&#8221; to &#8220;What color is the rose?&#8221;. We propose a method to automatically extract such implications for instances from two QA datasets, VQA and SQuAD, which we then use to evaluate the consistency of models. Human evaluation shows these generated implications are well formed and valid. Consistency evaluation provides crucial insights into gaps in existing models, while retraining with implication-augmented data improves consistency on both synthetic and human-generated implications.</abstract>
      <url hash="b5beb179">P19-1621</url>
      <doi>10.18653/v1/P19-1621</doi>
      <bibkey>ribeiro-etal-2019-red</bibkey>
      <pwccode url="https://github.com/marcotcr/qa_consistency" additional="false">marcotcr/qa_consistency</pwccode>
    </paper>
    <paper id="623">
      <title>Reducing Word Omission Errors in Neural Machine Translation: A Contrastive Learning Approach</title>
      <author><first>Zonghan</first><last>Yang</last></author>
      <author><first>Yong</first><last>Cheng</last></author>
      <author id="yang-liu-ict"><first>Yang</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>6191&#8211;6196</pages>
      <abstract>While neural machine translation (NMT) has achieved remarkable success, NMT systems are prone to make word omission errors. In this work, we propose a contrastive learning approach to reducing word omission errors in NMT. The basic idea is to enable the NMT model to assign a higher probability to a ground-truth translation and a lower probability to an erroneous translation, which is automatically constructed from the ground-truth translation by omitting words. We design different types of negative examples depending on the number of omitted words, word frequency, and part of speech. Experiments on Chinese-to-English, German-to-English, and Russian-to-English translation tasks show that our approach is effective in reducing word omission errors and achieves better translation performance than three baseline methods.</abstract>
      <url hash="c5d2dc0d">P19-1623</url>
      <doi>10.18653/v1/P19-1623</doi>
      <bibkey>yang-etal-2019-reducing</bibkey>
    </paper>
    <paper id="627">
      <title>An Automated Framework for Fast Cognate Detection and <fixed-case>B</fixed-case>ayesian Phylogenetic Inference in Computational Historical Linguistics</title>
      <author><first>Taraka</first><last>Rama</last></author>
      <author><first>Johann-Mattis</first><last>List</last></author>
      <pages>6225&#8211;6235</pages>
      <abstract>We present a fully automated workflow for phylogenetic reconstruction on large datasets, consisting of two novel methods, one for fast detection of cognates and one for fast Bayesian phylogenetic inference. Our results show that the methods take less than a few minutes to process language families that have so far required large amounts of time and computational power. Moreover, the cognates and the trees inferred from the method are quite close, both to gold standard cognate judgments and to expert language family trees. Given its speed and ease of application, our framework is specifically useful for the exploration of very large datasets in historical linguistics.</abstract>
      <url hash="6fcb28e0">P19-1627</url>
      <doi>10.18653/v1/P19-1627</doi>
      <bibkey>rama-list-2019-automated</bibkey>
      <pwccode url="https://github.com/lingpy/bipskip" additional="false">lingpy/bipskip</pwccode>
    </paper>
    <paper id="628">
      <title>Sentence Centrality Revisited for Unsupervised Summarization</title>
      <author><first>Hao</first><last>Zheng</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>6236&#8211;6247</pages>
      <abstract>Single document summarization has enjoyed renewed interest in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. In this paper we develop an unsupervised approach arguing that it is unrealistic to expect large-scale and high-quality training data to be available or created for different types of summaries, domains, or languages. We revisit a popular graph-based ranking algorithm and modify how node (aka sentence) centrality is computed in two ways: (a) we employ BERT, a state-of-the-art neural representation learning model to better capture sentential meaning and (b) we build graphs with directed edges arguing that the contribution of any two nodes to their respective centrality is influenced by their relative position in a document. Experimental results on three news summarization datasets representative of different languages and writing styles show that our approach outperforms strong baselines by a wide margin.</abstract>
      <url hash="25b9d107">P19-1628</url>
      <doi>10.18653/v1/P19-1628</doi>
      <bibkey>zheng-lapata-2019-sentence</bibkey>
      <pwccode url="https://github.com/mswellhao/PacSum" additional="false">mswellhao/PacSum</pwccode>
    </paper>
    <paper id="629">
      <title>Discourse Representation Parsing for Sentences and Documents</title>
      <author><first>Jiangming</first><last>Liu</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>6248&#8211;6262</pages>
      <abstract>We introduce a novel semantic parsing task based on Discourse Representation Theory (DRT; Kamp and Reyle 1993). Our model operates over Discourse Representation Tree Structures which we formally define for sentences and documents. We present a general framework for parsing discourse structures of arbitrary length and granularity. We achieve this with a neural model equipped with a supervised hierarchical attention mechanism and a linguistically-motivated copy strategy. Experimental results on sentence- and document-level benchmarks show that our model outperforms competitive baselines by a wide margin.</abstract>
      <url hash="cf1bca17">P19-1629</url>
      <attachment type="software" hash="798e7fe6">P19-1629.Software.zip</attachment>
      <doi>10.18653/v1/P19-1629</doi>
      <bibkey>liu-etal-2019-discourse</bibkey>
    </paper>
    <paper id="631">
      <title>Incorporating Priors with Feature Attribution on Text Classification</title>
      <author><first>Frederick</first><last>Liu</last></author>
      <author><first>Besim</first><last>Avci</last></author>
      <pages>6274&#8211;6283</pages>
      <abstract>Feature attribution methods, proposed recently, help users interpret the predictions of complex models. Our approach integrates feature attributions into the objective function to allow machine learning practitioners to incorporate priors in model building. To demonstrate the effectiveness our technique, we apply it to two tasks: (1) mitigating unintended bias in text classifiers by neutralizing identity terms; (2) improving classifier performance in scarce data setting by forcing model to focus on toxic terms. Our approach adds an L2 distance loss between feature attributions and task-specific prior values to the objective. Our experiments show that i) a classifier trained with our technique reduces undesired model biases without a tradeoff on the original task; ii) incorporating prior helps model performance in scarce data settings.</abstract>
      <url hash="ccbc52bb">P19-1631</url>
      <attachment type="supplementary" hash="22bd2434">P19-1631.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1631</doi>
      <bibkey>liu-avci-2019-incorporating</bibkey>
    </paper>
    <paper id="632">
      <title>Matching Article Pairs with Graphical Decomposition and Convolutions</title>
      <author><first>Bang</first><last>Liu</last></author>
      <author><first>Di</first><last>Niu</last></author>
      <author><first>Haojie</first><last>Wei</last></author>
      <author><first>Jinghong</first><last>Lin</last></author>
      <author><first>Yancheng</first><last>He</last></author>
      <author><first>Kunfeng</first><last>Lai</last></author>
      <author><first>Yu</first><last>Xu</last></author>
      <pages>6284&#8211;6294</pages>
      <abstract>Identifying the relationship between two articles, e.g., whether two articles published from different sources describe the same breaking news, is critical to many document understanding tasks. Existing approaches for modeling and matching sentence pairs do not perform well in matching longer documents, which embody more complex interactions between the enclosed entities than a sentence does. To model article pairs, we propose the Concept Interaction Graph to represent an article as a graph of concepts. We then match a pair of articles by comparing the sentences that enclose the same concept vertex through a series of encoding techniques, and aggregate the matching signals through a graph convolutional network. To facilitate the evaluation of long article matching, we have created two datasets, each consisting of about 30K pairs of breaking news articles covering diverse topics in the open domain. Extensive evaluations of the proposed methods on the two datasets demonstrate significant improvements over a wide range of state-of-the-art methods for natural language matching.</abstract>
      <url hash="a05415a0">P19-1632</url>
      <doi>10.18653/v1/P19-1632</doi>
      <bibkey>liu-etal-2019-matching</bibkey>
      <pwccode url="https://github.com/BangLiu/ArticlePairMatching" additional="false">BangLiu/ArticlePairMatching</pwccode>
    </paper>
    <paper id="636">
      <title>Large-Scale Multi-Label Text Classification on <fixed-case>EU</fixed-case> Legislation</title>
      <author><first>Ilias</first><last>Chalkidis</last></author>
      <author><first>Emmanouil</first><last>Fergadiotis</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>6314&#8211;6322</pages>
      <abstract>We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with &#8764;4.3k EUROVOC labels, which is suitable for LMTC, few- and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings further improve performance. We also find that considering only particular zones of the documents is sufficient. This allows us to bypass BERT&#8217;s maximum text length limit and fine-tune BERT, obtaining the best results in all but zero-shot learning cases.</abstract>
      <url hash="3840271f">P19-1636</url>
      <doi>10.18653/v1/P19-1636</doi>
      <bibkey>chalkidis-etal-2019-large</bibkey>
      <pwccode url="https://github.com/iliaschalkidis/lmtc-eurlex57k" additional="false">iliaschalkidis/lmtc-eurlex57k</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/eurlex57k">EURLEX57K</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rcv1">RCV1</pwcdataset>
    </paper>
    <paper id="641">
      <title>Dense Procedure Captioning in Narrated Instructional Videos</title>
      <author><first>Botian</first><last>Shi</last></author>
      <author><first>Lei</first><last>Ji</last></author>
      <author><first>Yaobo</first><last>Liang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Peng</first><last>Chen</last></author>
      <author><first>Zhendong</first><last>Niu</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>6382&#8211;6391</pages>
      <abstract>Understanding narrated instructional videos is important for both research and real-world web applications. Motivated by video dense captioning, we propose a model to generate procedure captions from narrated instructional videos which are a sequence of step-wise clips with description. Previous works on video dense captioning learn video segments and generate captions without considering transcripts. We argue that transcripts in narrated instructional videos can enhance video representation by providing fine-grained complimentary and semantic textual information. In this paper, we introduce a framework to (1) extract procedures by a cross-modality module, which fuses video content with the entire transcript; and (2) generate captions by encoding video frames as well as a snippet of transcripts within each extracted procedure. Experiments show that our model can achieve state-of-the-art performance in procedure extraction and captioning, and the ablation studies demonstrate that both the video frames and the transcripts are important for the task.</abstract>
      <url hash="666d207d">P19-1641</url>
      <doi>10.18653/v1/P19-1641</doi>
      <bibkey>shi-etal-2019-dense</bibkey>
    </paper>
    <paper id="642">
      <title>Latent Variable Model for Multi-modal Translation</title>
      <author><first>Iacer</first><last>Calixto</last></author>
      <author><first>Miguel</first><last>Rios</last></author>
      <author><first>Wilker</first><last>Aziz</last></author>
      <pages>6392&#8211;6405</pages>
      <abstract>In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a latent variable model. This latent variable can be seen as a multi-modal stochastic embedding of an image and its description in a foreign language. It is used in a target-language decoder and also to predict image features. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and Kadar, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a constraint on the KL term to promote models with non-negligible mutual information between inputs and latent variable, and (iii) by training on additional target-language image descriptions (i.e. synthetic data).</abstract>
      <url hash="f7d9670a">P19-1642</url>
      <doi>10.18653/v1/P19-1642</doi>
      <bibkey>calixto-etal-2019-latent</bibkey>
      <pwccode url="https://github.com/iacercalixto/variational_mmt" additional="false">iacercalixto/variational_mmt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="643">
      <title>Identifying Visible Actions in Lifestyle Vlogs</title>
      <author><first>Oana</first><last>Ignat</last></author>
      <author><first>Laura</first><last>Burdick</last></author>
      <author><first>Jia</first><last>Deng</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>6406&#8211;6417</pages>
      <abstract>We consider the task of identifying human actions visible in online videos. We focus on the widely spread genre of lifestyle vlogs, which consist of videos of people performing actions while verbally describing them. Our goal is to identify if actions mentioned in the speech description of a video are visually present. We construct a dataset with crowdsourced manual annotations of visible actions, and introduce a multimodal algorithm that leverages information derived from visual and linguistic clues to automatically infer which actions are visible in a video.</abstract>
      <url hash="fb315e0e">P19-1643</url>
      <doi>10.18653/v1/P19-1643</doi>
      <bibkey>ignat-etal-2019-identifying</bibkey>
      <pwccode url="https://github.com/MichiganNLP/vlog_action_recognition" additional="false">MichiganNLP/vlog_action_recognition</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/vlogs">Vlogs</pwcdataset>
    </paper>
    <paper id="644">
      <title>A Corpus for Reasoning about Natural Language Grounded in Photographs</title>
      <author><first>Alane</first><last>Suhr</last></author>
      <author><first>Stephanie</first><last>Zhou</last></author>
      <author><first>Ally</first><last>Zhang</last></author>
      <author><first>Iris</first><last>Zhang</last></author>
      <author><first>Huajun</first><last>Bai</last></author>
      <author><first>Yoav</first><last>Artzi</last></author>
      <pages>6418&#8211;6428</pages>
      <abstract>We introduce a new dataset for joint reasoning about natural language and images, with a focus on semantic diversity, compositionality, and visual reasoning challenges. The data contains 107,292 examples of English sentences paired with web photographs. The task is to determine whether a natural language caption is true about a pair of photographs. We crowdsource the data using sets of visually rich images and a compare-and-contrast task to elicit linguistically diverse language. Qualitative analysis shows the data requires compositional joint reasoning, including about quantities, comparisons, and relations. Evaluation using state-of-the-art visual reasoning methods shows the data presents a strong challenge.</abstract>
      <url hash="9e13eba7">P19-1644</url>
      <attachment type="supplementary" hash="2accb595">P19-1644.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1644</doi>
      <revision id="1" href="P19-1644v1" hash="590f6420" />
      <revision id="2" href="P19-1644v2" hash="9e13eba7">In the main paper (attached), in Table 3, the row for "Cardinality (soft)" has incorrect values under the NLVR and NLVR2 columns. The respective values should be 16 and 23.6. The value of 16 was reported in Suhr et al. 2017 (P17-2034; the error occurred when I accidentally overwrote the NLVR cell value).</revision>
      <bibkey>suhr-etal-2019-corpus</bibkey>
      <pwccode url="https://github.com/lil-lab/nlvr" additional="true">lil-lab/nlvr</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr-humans">CLEVR-Humans</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nlvr">NLVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="645">
      <title>Learning to Discover, Ground and Use Words with Segmental Neural Language Models</title>
      <author><first>Kazuya</first><last>Kawakami</last></author>
      <author><first>Chris</first><last>Dyer</last></author>
      <author><first>Phil</first><last>Blunsom</last></author>
      <pages>6429&#8211;6441</pages>
      <abstract>We propose a segmental neural language model that combines the generalization power of neural networks with the ability to discover word-like units that are latent in unsegmented character sequences. In contrast to previous segmentation models that treat word segmentation as an isolated task, our model unifies word discovery, learning how words fit together to form sentences, and, by conditioning the model on visual context, how words&#8217; meanings ground in representations of nonlinguistic modalities. Experiments show that the unconditional model learns predictive distributions better than character LSTM models, discovers words competitively with nonparametric Bayesian word segmentation models, and that modeling language conditional on visual context improves performance on both.</abstract>
      <url hash="5b0638a5">P19-1645</url>
      <doi>10.18653/v1/P19-1645</doi>
      <bibkey>kawakami-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="647">
      <title>Symbolic Inductive Bias for Visually Grounded Learning of Spoken Language</title>
      <author><first>Grzegorz</first><last>Chrupa&#322;a</last></author>
      <pages>6452&#8211;6462</pages>
      <abstract>A widespread approach to processing spoken language is to first automatically transcribe it into text. An alternative is to use an end-to-end approach: recent works have proposed to learn semantic embeddings of spoken language from images with spoken captions, without an intermediate transcription step. We propose to use multitask learning to exploit existing transcribed speech within the end-to-end setting. We describe a three-task architecture which combines the objectives of matching spoken captions with corresponding images, speech with text, and text with images. We show that the addition of the speech/text task leads to substantial performance improvements on image retrieval when compared to training the speech/image task in isolation. We conjecture that this is due to a strong inductive bias transcribed speech provides to the model, and offer supporting evidence for this.</abstract>
      <url hash="a0ac629c">P19-1647</url>
      <doi>10.18653/v1/P19-1647</doi>
      <bibkey>chrupala-2019-symbolic</bibkey>
      <pwccode url="https://github.com/gchrupala/symbolic-bias" additional="false">gchrupala/symbolic-bias</pwccode>
    </paper>
    <paper id="648">
      <title>Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog</title>
      <author><first>Zhe</first><last>Gan</last></author>
      <author><first>Yu</first><last>Cheng</last></author>
      <author><first>Ahmed</first><last>Kholy</last></author>
      <author><first>Linjie</first><last>Li</last></author>
      <author><first>Jingjing</first><last>Liu</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>6463&#8211;6474</pages>
      <abstract>This paper presents a new model for visual dialog, Recurrent Dual Attention Network (ReDAN), using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step. On the VisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art of 64.47% NDCG score. Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step.</abstract>
      <url hash="c7deb9ca">P19-1648</url>
      <doi>10.18653/v1/P19-1648</doi>
      <bibkey>gan-etal-2019-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/guesswhat">GuessWhat?!</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visdial">VisDial</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="650">
      <title>Informative Image Captioning with External Sources of Information</title>
      <author><first>Sanqiang</first><last>Zhao</last></author>
      <author><first>Piyush</first><last>Sharma</last></author>
      <author><first>Tomer</first><last>Levinboim</last></author>
      <author><first>Radu</first><last>Soricut</last></author>
      <pages>6485&#8211;6494</pages>
      <abstract>An image caption should fluently present the essential information in a given image, including informative, fine-grained entity mentions and the manner in which these entities interact. However, current captioning models are usually trained to generate captions that only contain common object names, thus falling short on an important &#8220;informativeness&#8221; dimension. We present a mechanism for integrating image information together with fine-grained labels (assumed to be generated by some upstream models) into a caption that describes the image in a fluent and informative manner. We introduce a multimodal, multi-encoder model based on Transformer that ingests both image features and multiple sources of entity labels. We demonstrate that we can learn to control the appearance of these entity labels in the output, resulting in captions that are both fluent and informative.</abstract>
      <url hash="d503b762">P19-1650</url>
      <doi>10.18653/v1/P19-1650</doi>
      <bibkey>zhao-etal-2019-informative</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptual-captions">Conceptual Captions</pwcdataset>
    </paper>
    <paper id="653">
      <title>Distilling Translations with Visual Awareness</title>
      <author><first>Julia</first><last>Ive</last></author>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>6525&#8211;6538</pages>
      <abstract>Previous work on multimodal machine translation has shown that visual information is only needed in very specific cases, for example in the presence of ambiguous words where the textual context is not sufficient. As a consequence, models tend to learn to ignore this information. We propose a translate-and-refine approach to this problem where images are only used by a second stage decoder. This approach is trained jointly to generate a good first draft translation and to improve over this draft by (i) making better use of the target language textual context (both left and right-side contexts) and (ii) making use of visual context. This approach leads to the state of the art results. Additionally, we show that it has the ability to recover from erroneous or missing words in the source language.</abstract>
      <url hash="ee6ba889">P19-1653</url>
      <doi>10.18653/v1/P19-1653</doi>
      <bibkey>ive-etal-2019-distilling</bibkey>
      <pwccode url="https://github.com/ImperialNLP/MMT-Delib" additional="false">ImperialNLP/MMT-Delib</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="654">
      <title><fixed-case>VIFIDEL</fixed-case>: Evaluating the Visual Fidelity of Image Descriptions</title>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Josiah</first><last>Wang</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>6539&#8211;6550</pages>
      <abstract>We address the task of evaluating image description generation systems. We propose a novel image-aware metric for this task: VIFIDEL. It estimates the faithfulness of a generated caption with respect to the content of the actual image, based on the semantic similarity between labels of objects depicted in images and words in the description. The metric is also able to take into account the relative importance of objects mentioned in human reference descriptions during evaluation. Even if these human reference descriptions are not available, VIFIDEL can still reliably evaluate system descriptions. The metric achieves high correlation with human judgments on two well-known datasets and is competitive with metrics that depend on and rely exclusively on human references.</abstract>
      <url hash="a14ecfae">P19-1654</url>
      <doi>10.18653/v1/P19-1654</doi>
      <bibkey>madhyastha-etal-2019-vifidel</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="655">
      <title>Are You Looking? Grounding to Multiple Modalities in Vision-and-Language Navigation</title>
      <author><first>Ronghang</first><last>Hu</last></author>
      <author><first>Daniel</first><last>Fried</last></author>
      <author><first>Anna</first><last>Rohrbach</last></author>
      <author><first>Dan</first><last>Klein</last></author>
      <author><first>Trevor</first><last>Darrell</last></author>
      <author><first>Kate</first><last>Saenko</last></author>
      <pages>6551&#8211;6557</pages>
      <abstract>Vision-and-Language Navigation (VLN) requires grounding instructions, such as &#8220;turn right and stop at the door&#8221;, to routes in a visual environment. The actual grounding can connect language to the environment through multiple modalities, e.g. &#8220;stop at the door&#8221; might ground into visual objects, while &#8220;turn right&#8221; might rely only on the geometric structure of a route. We investigate where the natural language empirically grounds under two recent state-of-the-art VLN models. Surprisingly, we discover that visual features may actually hurt these models: models which only use route structure, ablating visual features, outperform their visual counterparts in unseen new environments on the benchmark Room-to-Room dataset. To better use all the available modalities, we propose to decompose the grounding procedure into a set of expert models with access to different modalities (including object detections) and ensemble them at prediction time, improving the performance of state-of-the-art models on the VLN task.</abstract>
      <url hash="2a370633">P19-1655</url>
      <attachment type="supplementary" hash="e8468dc5">P19-1655.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1655</doi>
      <bibkey>hu-etal-2019-looking</bibkey>
    </paper>
    <paper id="656">
      <title>Multimodal Transformer for Unaligned Multimodal Language Sequences</title>
      <author><first>Yao-Hung Hubert</first><last>Tsai</last></author>
      <author><first>Shaojie</first><last>Bai</last></author>
      <author><first>Paul Pu</first><last>Liang</last></author>
      <author><first>J. Zico</first><last>Kolter</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <author><first>Ruslan</first><last>Salakhutdinov</last></author>
      <pages>6558&#8211;6569</pages>
      <abstract>Human language is often multimodal, which comprehends a mixture of natural language, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist: 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise crossmodal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art methods by a large margin. In addition, empirical analysis suggests that correlated crossmodal signals are able to be captured by the proposed crossmodal attention mechanism in MulT.</abstract>
      <url hash="df5c8de3">P19-1656</url>
      <doi>10.18653/v1/P19-1656</doi>
      <bibkey>tsai-etal-2019-multimodal</bibkey>
      <pwccode url="https://github.com/yaohungt/Multimodal-Transformer" additional="true">yaohungt/Multimodal-Transformer</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cmu-mosei">CMU-MOSEI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multimodal-opinionlevel-sentiment-intensity">Multimodal Opinionlevel Sentiment Intensity</pwcdataset>
    </paper>
    <paper id="657">
      <title>Show, Describe and Conclude: On Exploiting the Structure Information of Chest <fixed-case>X</fixed-case>-ray Reports</title>
      <author><first>Baoyu</first><last>Jing</last></author>
      <author><first>Zeya</first><last>Wang</last></author>
      <author><first>Eric</first><last>Xing</last></author>
      <pages>6570&#8211;6580</pages>
      <abstract>Chest X-Ray (CXR) images are commonly used for clinical screening and diagnosis. Automatically writing reports for these images can considerably lighten the workload of radiologists for summarizing descriptive findings and conclusive impressions. The complex structures between and within sections of the reports pose a great challenge to the automatic report generation. Specifically, the section Impression is a diagnostic summarization over the section Findings; and the appearance of normality dominates each section over that of abnormality. Existing studies rarely explore and consider this fundamental structure information. In this work, we propose a novel framework which exploits the structure information between and within report sections for generating CXR imaging reports. First, we propose a two-stage strategy that explicitly models the relationship between Findings and Impression. Second, we design a novel co-operative multi-agent system that implicitly captures the imbalanced distribution between abnormality and normality. Experiments on two CXR report datasets show that our method achieves state-of-the-art performance in terms of various evaluation metrics. Our results expose that the proposed approach is able to generate high-quality medical reports through integrating the structure information.</abstract>
      <url hash="1f863b4e">P19-1657</url>
      <doi>10.18653/v1/P19-1657</doi>
      <bibkey>jing-etal-2019-show</bibkey>
    </paper>
    <paper id="658">
      <title>Visual Story Post-Editing</title>
      <author><first>Ting-Yao</first><last>Hsu</last></author>
      <author><first>Chieh-Yang</first><last>Huang</last></author>
      <author><first>Yen-Chia</first><last>Hsu</last></author>
      <author><first>Ting-Hao</first><last>Huang</last></author>
      <pages>6581&#8211;6586</pages>
      <abstract>We introduce the first dataset for human edits of machine-generated visual stories and explore how these collected edits may be used for the visual story post-editing task. The dataset ,VIST-Edit, includes 14,905 human-edited versions of 2,981 machine-generated visual stories. The stories were generated by two state-of-the-art visual storytelling models, each aligned to 5 human-edited versions. We establish baselines for the task, showing how a relatively small set of human edits can be leveraged to boost the performance of large visual storytelling models. We also discuss the weak correlation between automatic evaluation scores and human ratings, motivating the need for new automatic metrics.</abstract>
      <url hash="2308f3fc">P19-1658</url>
      <doi>10.18653/v1/P19-1658</doi>
      <bibkey>hsu-etal-2019-visual</bibkey>
      <pwccode url="https://github.com/tingyaohsu/VIST-Edit" additional="false">tingyaohsu/VIST-Edit</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/vist-edit">VIST-Edit</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/vist">VIST</pwcdataset>
    </paper>
    <paper id="660">
      <title>Learning to Relate from Captions and Bounding Boxes</title>
      <author><first>Sarthak</first><last>Garg</last></author>
      <author><first>Joel Ruben Antony</first><last>Moniz</last></author>
      <author><first>Anshu</first><last>Aviral</last></author>
      <author><first>Priyatham</first><last>Bollimpalli</last></author>
      <pages>6597&#8211;6603</pages>
      <abstract>In this work, we propose a novel approach that predicts the relationships between various entities in an image in a weakly supervised manner by relying on image captions and object bounding box annotations as the sole source of supervision. Our proposed approach uses a top-down attention mechanism to align entities in captions to objects in the image, and then leverage the syntactic structure of the captions to align the relations. We use these alignments to train a relation classification network, thereby obtaining both grounded captions and dense relationships. We demonstrate the effectiveness of our model on the Visual Genome dataset by achieving a recall@50 of 15% and recall@100 of 25% on the relationships present in the image. We also show that the model successfully predicts relations that are not present in the corresponding captions.</abstract>
      <url hash="46ca5cb9">P19-1660</url>
      <attachment type="supplementary" hash="02546483">P19-1660.Supplementary.pdf</attachment>
      <doi>10.18653/v1/P19-1660</doi>
      <bibkey>garg-etal-2019-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
  </volume>
  <volume id="2" ingest-date="2019-07-28">
    <meta>
      <booktitle>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</booktitle>
      <url hash="95cc83d6">P19-2</url>
      <editor><first>Fernando</first><last>Alva-Manchego</last></editor>
      <editor><first>Eunsol</first><last>Choi</last></editor>
      <editor><first>Daniel</first><last>Khashabi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Florence, Italy</address>
      <month>July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="8e3fc4eb">P19-2000</url>
      <bibkey>acl-2019-association-linguistics</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Robust to Noise Models in Natural Language Processing Tasks</title>
      <author><first>Valentin</first><last>Malykh</last></author>
      <pages>10&#8211;16</pages>
      <abstract>There are a lot of noise texts surrounding a person in modern life. The traditional approach is to use spelling correction, yet the existing solutions are far from perfect. We propose robust to noise word embeddings model, which outperforms existing commonly used models, like fasttext and word2vec in different tasks. In addition, we investigate the noise robustness of current models in different natural language processing tasks. We propose extensions for modern models in three downstream tasks, i.e. text classification, named entity recognition and aspect extraction, which shows improvement in noise robustness over existing solutions.</abstract>
      <url hash="698a1cd5">P19-2002</url>
      <doi>10.18653/v1/P19-2002</doi>
      <bibkey>malykh-2019-robust</bibkey>
      <pwccode url="https://gitlab.com/madrugado/robust-w2v" additional="true">madrugado/robust-w2v</pwccode>
    </paper>
    <paper id="4">
      <title>Measuring the Value of Linguistics: A Case Study from <fixed-case>S</fixed-case>t. <fixed-case>L</fixed-case>awrence <fixed-case>I</fixed-case>sland <fixed-case>Y</fixed-case>upik</title>
      <author><first>Emily</first><last>Chen</last></author>
      <pages>27&#8211;33</pages>
      <abstract>The adaptation of neural approaches to NLP is a landmark achievement that has called into question the utility of linguistics in the development of computational systems. This research proposal consequently explores this question in the context of a neural morphological analyzer for a polysynthetic language, St. Lawrence Island Yupik. It asks whether incorporating elements of Yupik linguistics into the implementation of the analyzer can improve performance, both in low-resource settings and in high-resource settings, where rich quantities of data are readily available.</abstract>
      <url hash="bd5cb0b4">P19-2004</url>
      <doi>10.18653/v1/P19-2004</doi>
      <bibkey>chen-2019-measuring</bibkey>
    </paper>
    <paper id="5">
      <title>Not All Reviews Are Equal: Towards Addressing Reviewer Biases for Opinion Summarization</title>
      <author><first>Wenyi</first><last>Tay</last></author>
      <pages>34&#8211;42</pages>
      <abstract>Consumers read online reviews for insights which help them to make decisions. Given the large volumes of reviews, succinct review summaries are important for many applications. Existing research has focused on mining for opinions from only review texts and largely ignores the reviewers. However, reviewers have biases and may write lenient or harsh reviews; they may also have preferences towards some topics over others. Therefore, not all reviews are equal. Ignoring the biases in reviews can generate misleading summaries. We aim for summarization of reviews to include balanced opinions from reviewers of different biases and preferences. We propose to model reviewer biases from their review texts and rating distributions, and learn a bias-aware opinion representation. We further devise an approach for balanced opinion summarization of reviews using our bias-aware opinion representation.</abstract>
      <url hash="d9235336">P19-2005</url>
      <doi>10.18653/v1/P19-2005</doi>
      <bibkey>tay-2019-reviews</bibkey>
    </paper>
    <paper id="6">
      <title>Towards <fixed-case>T</fixed-case>urkish <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation</title>
      <author><first>Zahra</first><last>Azin</last></author>
      <author><first>G&#252;l&#351;en</first><last>Eryi&#287;it</last></author>
      <pages>43&#8211;47</pages>
      <abstract>Using rooted, directed and labeled graphs, Abstract Meaning Representation (AMR) abstracts away from syntactic features such as word order and does not annotate every constituent in a sentence. AMR has been specified for English and was not supposed to be an Interlingua. However, several studies strived to overcome divergences in the annotations between English AMRs and those of their target languages by refining the annotation specification. Following this line of research, we have started to build the first Turkish AMR corpus by hand-annotating 100 sentences of the Turkish translation of the novel &#8220;The Little Prince&#8221; and comparing the results with the English AMRs available for the same corpus. The next step is to prepare the Turkish AMR annotation specification for training future annotators.</abstract>
      <url hash="bdaa78be">P19-2006</url>
      <doi>10.18653/v1/P19-2006</doi>
      <bibkey>azin-eryigit-2019-towards</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/amr-bank">AMR Bank</pwcdataset>
    </paper>
    <paper id="9">
      <title>Knowledge Discovery and Hypothesis Generation from Online Patient Forums: A Research Proposal</title>
      <author><first>Anne</first><last>Dirkson</last></author>
      <pages>64&#8211;73</pages>
      <abstract>The unprompted patient experiences shared on patient forums contain a wealth of unexploited knowledge. Mining this knowledge and cross-linking it with biomedical literature, could expose novel insights, which could subsequently provide hypotheses for further clinical research. As of yet, automated methods for open knowledge discovery on patient forum text are lacking. Thus, in this research proposal, we outline future research into methods for mining, aggregating and cross-linking patient knowledge from online forums. Additionally, we aim to address how one could measure the credibility of this extracted knowledge.</abstract>
      <url hash="dccf21e4">P19-2009</url>
      <doi>10.18653/v1/P19-2009</doi>
      <bibkey>dirkson-2019-knowledge</bibkey>
    </paper>
    <paper id="11">
      <title>Natural Language Generation: Recently Learned Lessons, Directions for Semantic Representation-based Approaches, and the Case of <fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese Language</title>
      <author><first>Marco Antonio</first><last>Sobrevilla Cabezudo</last></author>
      <author><first>Thiago</first><last>Pardo</last></author>
      <pages>81&#8211;88</pages>
      <abstract>This paper presents a more recent literature review on Natural Language Generation. In particular, we highlight the efforts for Brazilian Portuguese in order to show the available resources and the existent approaches for this language. We also focus on the approaches for generation from semantic representations (emphasizing the Abstract Meaning Representation formalism) as well as their advantages and limitations, including possible future directions.</abstract>
      <url hash="9cd2254b">P19-2011</url>
      <doi>10.18653/v1/P19-2011</doi>
      <bibkey>sobrevilla-cabezudo-pardo-2019-natural</bibkey>
    </paper>
    <paper id="14">
      <title>Active Reading Comprehension: A Dataset for Learning the Question-Answer Relationship Strategy</title>
      <author><first>Diana</first><last>Galv&#225;n-Sosa</last></author>
      <pages>106&#8211;112</pages>
      <abstract>Reading comprehension (RC) through question answering is a useful method for evaluating if a reader understands a text. Standard accuracy metrics are used for evaluation, where high accuracy is taken as indicative of a good understanding. However, literature in quality learning suggests that task performance should also be evaluated on the undergone process to answer. The Question-Answer Relationship (QAR) is one of the strategies for evaluating a reader&#8217;s understanding based on their ability to select different sources of information depending on the question type. We propose the creation of a dataset to learn the QAR strategy with weak supervision. We expect to complement current work on reading comprehension by introducing a new setup for evaluation.</abstract>
      <url hash="21550ec2">P19-2014</url>
      <doi>10.18653/v1/P19-2014</doi>
      <bibkey>galvan-sosa-2019-active</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="15">
      <title>Paraphrases as Foreign Languages in Multilingual Neural Machine Translation</title>
      <author><first>Zhong</first><last>Zhou</last></author>
      <author><first>Matthias</first><last>Sperber</last></author>
      <author><first>Alexander</first><last>Waibel</last></author>
      <pages>113&#8211;122</pages>
      <abstract>Paraphrases, rewordings of the same semantic meaning, are useful for improving generalization and translation. Unlike previous works that only explore paraphrases at the word or phrase level, we use different translations of the whole training data that are consistent in structure as paraphrases at the corpus level. We treat paraphrases as foreign languages, tag source sentences with paraphrase labels, and train on parallel paraphrases in the style of multilingual Neural Machine Translation (NMT). Our multi-paraphrase NMT that trains only on two languages outperforms the multilingual baselines. Adding paraphrases improves the rare word translation and increases entropy and diversity in lexical choice. Adding the source paraphrases boosts performance better than adding the target ones, while adding both lifts performance further. We achieve a BLEU score of 57.2 for French-to-English translation using 24 corpus-level paraphrases of the Bible, which outperforms the multilingual baselines and is +34.7 above the single-source single-target NMT baseline.</abstract>
      <url hash="5ac03988">P19-2015</url>
      <doi>10.18653/v1/P19-2015</doi>
      <bibkey>zhou-etal-2019-paraphrases</bibkey>
    </paper>
    <paper id="17">
      <title>Unsupervised Pretraining for Neural Machine Translation Using Elastic Weight Consolidation</title>
      <author><first>Du&#353;an</first><last>Vari&#353;</last></author>
      <author><first>Ond&#345;ej</first><last>Bojar</last></author>
      <pages>130&#8211;135</pages>
      <abstract>This work presents our ongoing research of unsupervised pretraining in neural machine translation (NMT). In our method, we initialize the weights of the encoder and decoder with two language models that are trained with monolingual data and then fine-tune the model on parallel data using Elastic Weight Consolidation (EWC) to avoid forgetting of the original language modeling task. We compare the regularization by EWC with the previous work that focuses on regularization by language modeling objectives. The positive result is that using EWC with the decoder achieves BLEU scores similar to the previous work. However, the model converges 2-3 times faster and does not require the original unlabeled training data during the fine-tuning stage. In contrast, the regularization using EWC is less effective if the original and new tasks are not closely related. We show that initializing the bidirectional NMT encoder with a left-to-right language model and forcing the model to remember the original left-to-right language modeling task limits the learning capacity of the encoder for the whole bidirectional context.</abstract>
      <url hash="38fa1224">P19-2017</url>
      <doi>10.18653/v1/P19-2017</doi>
      <bibkey>varis-bojar-2019-unsupervised</bibkey>
    </paper>
    <paper id="19">
      <title>Ranking of Potential Questions</title>
      <author><first>Luise</first><last>Schricker</last></author>
      <author><first>Tatjana</first><last>Scheffler</last></author>
      <pages>143&#8211;148</pages>
      <abstract>Questions are an integral part of discourse. They provide structure and support the exchange of information. One linguistic theory, the Questions Under Discussion model, takes question structures as integral to the functioning of a coherent discourse. This theory has not been tested on the count of its validity for predicting observations in real dialogue data, however. In this submission, a system for ranking explicit and implicit questions by their appropriateness in a dialogue is presented. This system implements constraints and principles put forward in the linguistic literature.</abstract>
      <url hash="51644c4d">P19-2019</url>
      <doi>10.18653/v1/P19-2019</doi>
      <bibkey>schricker-scheffler-2019-ranking</bibkey>
      <pwccode url="https://github.com/QUD-comp/ranking-potential-questions" additional="false">QUD-comp/ranking-potential-questions</pwccode>
    </paper>
    <paper id="20">
      <title>Controlling Grammatical Error Correction Using Word Edit Rate</title>
      <author><first>Kengo</first><last>Hotate</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Satoru</first><last>Katsumata</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>149&#8211;154</pages>
      <abstract>When professional English teachers correct grammatically erroneous sentences written by English learners, they use various methods. The correction method depends on how much corrections a learner requires. In this paper, we propose a method for neural grammar error correction (GEC) that can control the degree of correction. We show that it is possible to actually control the degree of GEC by using new training data annotated with word edit rate. Thereby, diverse corrected sentences is obtained from a single erroneous sentence. Moreover, compared to a GEC model that does not use information on the degree of correction, the proposed method improves correction accuracy.</abstract>
      <url hash="98a8a019">P19-2020</url>
      <doi>10.18653/v1/P19-2020</doi>
      <bibkey>hotate-etal-2019-controlling</bibkey>
    </paper>
    <paper id="21">
      <title>From Brain Space to Distributional Space: The Perilous Journeys of f<fixed-case>MRI</fixed-case> Decoding</title>
      <author><first>Gosse</first><last>Minnema</last></author>
      <author><first>Aur&#233;lie</first><last>Herbelot</last></author>
      <pages>155&#8211;161</pages>
      <abstract>Recent work in cognitive neuroscience has introduced models for predicting distributional word meaning representations from brain imaging data. Such models have great potential, but the quality of their predictions has not yet been thoroughly evaluated from a computational linguistics point of view. Due to the limited size of available brain imaging datasets, standard quality metrics (e.g. similarity judgments and analogies) cannot be used. Instead, we investigate the use of several alternative measures for evaluating the predicted distributional space against a corpus-derived distributional space. We show that a state-of-the-art decoder, while performing impressively on metrics that are commonly used in cognitive neuroscience, performs unexpectedly poorly on our metrics. To address this, we propose strategies for improving the model&#8217;s performance. Despite returning promising results, our experiments also demonstrate that much work remains to be done before distributional representations can reliably be predicted from brain data.</abstract>
      <url hash="15cdf899">P19-2021</url>
      <doi>10.18653/v1/P19-2021</doi>
      <bibkey>minnema-herbelot-2019-brain</bibkey>
      <pwccode url="https://gitlab.com/gosseminnema/ds-brain-decoding" additional="false">gosseminnema/ds-brain-decoding</pwccode>
    </paper>
    <paper id="23">
      <title>A Strong and Robust Baseline for Text-Image Matching</title>
      <author><first>Fangyu</first><last>Liu</last></author>
      <author><first>Rongtian</first><last>Ye</last></author>
      <pages>169&#8211;176</pages>
      <abstract>We review the current schemes of text-image matching models and propose improvements for both training and inference. First, we empirically show limitations of two popular loss (sum and max-margin loss) widely used in training text-image embeddings and propose a trade-off: a kNN-margin loss which 1) utilizes information from hard negatives and 2) is robust to noise as all K-most hardest samples are taken into account, tolerating pseudo negatives and outliers. Second, we advocate the use of Inverted Softmax (IS) and Cross-modal Local Scaling (CSLS) during inference to mitigate the so-called hubness problem in high-dimensional embedding space, enhancing scores of all metrics by a large margin.</abstract>
      <url hash="0343d74c">P19-2023</url>
      <doi>10.18653/v1/P19-2023</doi>
      <bibkey>liu-ye-2019-strong</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
    </paper>
    <paper id="25">
      <title>Corpus Creation and Analysis for Named Entity Recognition in <fixed-case>T</fixed-case>elugu-<fixed-case>E</fixed-case>nglish Code-Mixed Social Media Data</title>
      <author><first>Vamshi Krishna</first><last>Srirangam</last></author>
      <author><first>Appidi Abhinav</first><last>Reddy</last></author>
      <author><first>Vinay</first><last>Singh</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>183&#8211;189</pages>
      <abstract>Named Entity Recognition(NER) is one of the important tasks in Natural Language Processing(NLP) and also is a subtask of Information Extraction. In this paper we present our work on NER in Telugu-English code-mixed social media data. Code-Mixing, a progeny of multilingualism is a way in which multilingual people express themselves on social media by using linguistics units from different languages within a sentence or speech context. Entity Extraction from social media data such as tweets(twitter) is in general difficult due to its informal nature, code-mixed data further complicates the problem due to its informal, unstructured and incomplete information. We present a Telugu-English code-mixed corpus with the corresponding named entity tags. The named entities used to tag data are Person(&#8216;Per&#8217;), Organization(&#8216;Org&#8217;) and Location(&#8216;Loc&#8217;). We experimented with the machine learning models Conditional Random Fields(CRFs), Decision Trees and BiLSTMs on our corpus which resulted in a F1-score of 0.96, 0.94 and 0.95 respectively.</abstract>
      <url hash="b62dbad3">P19-2025</url>
      <doi>10.18653/v1/P19-2025</doi>
      <bibkey>srirangam-etal-2019-corpus</bibkey>
    </paper>
    <paper id="26">
      <title>Joint Learning of Named Entity Recognition and Entity Linking</title>
      <author><first>Pedro Henrique</first><last>Martins</last></author>
      <author><first>Zita</first><last>Marinho</last></author>
      <author><first>Andr&#233; F. T.</first><last>Martins</last></author>
      <pages>190&#8211;196</pages>
      <abstract>Named entity recognition (NER) and entity linking (EL) are two fundamentally related tasks, since in order to perform EL, first the mentions to entities have to be detected. However, most entity linking approaches disregard the mention detection part, assuming that the correct mentions have been previously detected. In this paper, we perform joint learning of NER and EL to leverage their relatedness and obtain a more robust and generalisable system. For that, we introduce a model inspired by the Stack-LSTM approach. We observe that, in fact, doing multi-task learning of NER and EL improves the performance in both tasks when comparing with models trained with individual objectives. Furthermore, we achieve results competitive with the state-of-the-art in both NER and EL.</abstract>
      <url hash="a27d410d">P19-2026</url>
      <doi>10.18653/v1/P19-2026</doi>
      <bibkey>martins-etal-2019-joint</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/aida-conll-yago">AIDA CoNLL-YAGO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="27">
      <title>Dialogue-Act Prediction of Future Responses Based on Conversation History</title>
      <author><first>Koji</first><last>Tanaka</last></author>
      <author><first>Junya</first><last>Takayama</last></author>
      <author><first>Yuki</first><last>Arase</last></author>
      <pages>197&#8211;202</pages>
      <abstract>Sequence-to-sequence models are a common approach to develop a chatbot. They can train a conversational model in an end-to-end manner. One significant drawback of such a neural network based approach is that the response generation process is a black-box, and how a specific response is generated is unclear. To tackle this problem, an interpretable response generation mechanism is desired. As a step toward this direction, we focus on dialogue-acts (DAs) that may provide insight to understand the response generation process. In particular, we propose a method to predict a DA of the next response based on the history of previous utterances and their DAs. Experiments using a Switch Board Dialogue Act corpus show that compared to the baseline considering only a single utterance, our model achieves 10.8% higher F1-score and 3.0% higher accuracy on DA prediction.</abstract>
      <url hash="91370793">P19-2027</url>
      <doi>10.18653/v1/P19-2027</doi>
      <bibkey>tanaka-etal-2019-dialogue</bibkey>
    </paper>
    <paper id="29">
      <title>Multiple Character Embeddings for <fixed-case>C</fixed-case>hinese Word Segmentation</title>
      <author><first>Jianing</first><last>Zhou</last></author>
      <author><first>Jingkang</first><last>Wang</last></author>
      <author><first>Gongshen</first><last>Liu</last></author>
      <pages>210&#8211;216</pages>
      <abstract>Chinese word segmentation (CWS) is often regarded as a character-based sequence labeling task in most current works which have achieved great success with the help of powerful neural networks. However, these works neglect an important clue: Chinese characters incorporate both semantic and phonetic meanings. In this paper, we introduce multiple character embeddings including Pinyin Romanization and Wubi Input, both of which are easily accessible and effective in depicting semantics of characters. We propose a novel shared Bi-LSTM-CRF model to fuse linguistic features efficiently by sharing the LSTM network during the training procedure. Extensive experiments on five corpora show that extra embeddings help obtain a significant improvement in labeling accuracy. Specifically, we achieve the state-of-the-art performance in AS and CityU corpora with F1 scores of 96.9 and 97.3, respectively without leveraging any external lexical resources.</abstract>
      <url hash="97583e70">P19-2029</url>
      <doi>10.18653/v1/P19-2029</doi>
      <bibkey>zhou-etal-2019-multiple</bibkey>
    </paper>
    <paper id="33">
      <title>From Bilingual to Multilingual Neural Machine Translation by Incremental Training</title>
      <author><first>Carlos</first><last>Escolano</last></author>
      <author><first>Marta R.</first><last>Costa-juss&#224;</last></author>
      <author><first>Jos&#233; A. R.</first><last>Fonollosa</last></author>
      <pages>236&#8211;242</pages>
      <abstract>Multilingual Neural Machine Translation approaches are based on the use of task specific models and the addition of one more language can only be done by retraining the whole system. In this work, we propose a new training schedule that allows the system to scale to more languages without modification of the previous components based on joint training and language-independent encoder/decoder modules allowing for zero-shot translation. This work in progress shows close results to state-of-the-art in the WMT task.</abstract>
      <url hash="64755f04">P19-2033</url>
      <doi>10.18653/v1/P19-2033</doi>
      <bibkey>escolano-etal-2019-bilingual</bibkey>
    </paper>
    <paper id="34">
      <title><fixed-case>STRASS</fixed-case>: A Light and Effective Method for Extractive Summarization Based on Sentence Embeddings</title>
      <author><first>L&#233;o</first><last>Bouscarrat</last></author>
      <author><first>Antoine</first><last>Bonnefoy</last></author>
      <author><first>Thomas</first><last>Peel</last></author>
      <author><first>C&#233;cile</first><last>Pereira</last></author>
      <pages>243&#8211;252</pages>
      <abstract>This paper introduces STRASS: Summarization by TRAnsformation Selection and Scoring. It is an extractive text summarization method which leverages the semantic information in existing sentence embedding spaces. Our method creates an extractive summary by selecting the sentences with the closest embeddings to the document embedding. The model earns a transformation of the document embedding to minimize the similarity between the extractive summary and the ground truth summary. As the transformation is only composed of a dense layer, the training can be done on CPU, therefore, inexpensive. Moreover, inference time is short and linear according to the number of sentences. As a second contribution, we introduce the French CASS dataset, composed of judgments from the French Court of cassation and their corresponding summaries. On this dataset, our results show that our method performs similarly to the state of the art extractive methods with effective training and inferring time.</abstract>
      <url hash="dbb51a4e">P19-2034</url>
      <doi>10.18653/v1/P19-2034</doi>
      <bibkey>bouscarrat-etal-2019-strass</bibkey>
      <pwccode url="https://github.com/euranova/CASS-dataset" additional="false">euranova/CASS-dataset</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/french-cass-dataset">French CASS dataset</pwcdataset>
    </paper>
    <paper id="35">
      <title>Attention and Lexicon Regularized <fixed-case>LSTM</fixed-case> for Aspect-based Sentiment Analysis</title>
      <author><first>Lingxian</first><last>Bao</last></author>
      <author><first>Patrik</first><last>Lambert</last></author>
      <author><first>Toni</first><last>Badia</last></author>
      <pages>253&#8211;259</pages>
      <abstract>Abstract Attention based deep learning systems have been demonstrated to be the state of the art approach for aspect-level sentiment analysis, however, end-to-end deep neural networks lack flexibility as one can not easily adjust the network to fix an obvious problem, especially when more training data is not available: e.g. when it always predicts <i>positive</i> when seeing the word <i>disappointed</i>. Meanwhile, it is less stressed that attention mechanism is likely to &#8220;over-focus&#8221; on particular parts of a sentence, while ignoring positions which provide key information for judging the polarity. In this paper, we describe a simple yet effective approach to leverage lexicon information so that the model becomes more flexible and robust. We also explore the effect of regularizing attention vectors to allow the network to have a broader &#8220;focus&#8221; on different parts of the sentence. The experimental results demonstrate the effectiveness of our approach.</abstract>
      <url hash="1641bcd3">P19-2035</url>
      <doi>10.18653/v1/P19-2035</doi>
      <bibkey>bao-etal-2019-attention</bibkey>
    </paper>
    <paper id="37">
      <title>Normalizing Non-canonical <fixed-case>T</fixed-case>urkish Texts Using Machine Translation Approaches</title>
      <author><first>Talha</first><last>&#199;olako&#287;lu</last></author>
      <author><first>Umut</first><last>Sulubacak</last></author>
      <author><first>Ahmet C&#252;neyd</first><last>Tantu&#287;</last></author>
      <pages>267&#8211;272</pages>
      <abstract>With the growth of the social web, user-generated text data has reached unprecedented sizes. Non-canonical text normalization provides a way to exploit this as a practical source of training data for language processing systems. The state of the art in Turkish text normalization is composed of a token level pipeline of modules, heavily dependent on external linguistic resources and manually defined rules. Instead, we propose a fully automated, context-aware machine translation approach with fewer stages of processing. Experiments with various implementations of our approach show that we are able to surpass the current best-performing system by a large margin.</abstract>
      <url hash="2ee11481">P19-2037</url>
      <doi>10.18653/v1/P19-2037</doi>
      <bibkey>colakoglu-etal-2019-normalizing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    </paper>
    <paper id="39">
      <title>Investigating Political Herd Mentality: A Community Sentiment Based Approach</title>
      <author><first>Anjali</first><last>Bhavan</last></author>
      <author><first>Rohan</first><last>Mishra</last></author>
      <author><first>Pradyumna Prakhar</first><last>Sinha</last></author>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>281&#8211;287</pages>
      <abstract>Analyzing polarities and sentiments inherent in political speeches and debates poses an important problem today. This experiment aims to address this issue by analyzing publicly-available Hansard transcripts of the debates conducted in the UK Parliament. Our proposed approach, which uses community-based graph information to augment hand-crafted features based on topic modeling and emotion detection on debate transcripts, currently surpasses the benchmark results on the same dataset. Such sentiment classification systems could prove to be of great use in today&#8217;s politically turbulent times, for public knowledge of politicians&#8217; stands on various relevant issues proves vital for good governance and citizenship. The experiments also demonstrate that continuous feature representations learned from graphs can improve performance on sentiment classification tasks significantly.</abstract>
      <url hash="b8ca077f">P19-2039</url>
      <doi>10.18653/v1/P19-2039</doi>
      <bibkey>bhavan-etal-2019-investigating</bibkey>
    </paper>
    <paper id="41">
      <title>Embedding Strategies for Specialized Domains: Application to Clinical Entity Recognition</title>
      <author><first>Hicham</first><last>El Boukkouri</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>295&#8211;301</pages>
      <abstract>Using pre-trained word embeddings in conjunction with Deep Learning models has become the &#8220;de facto&#8221; approach in Natural Language Processing (NLP). While this usually yields satisfactory results, off-the-shelf word embeddings tend to perform poorly on texts from specialized domains such as clinical reports. Moreover, training specialized word representations from scratch is often either impossible or ineffective due to the lack of large enough in-domain data. In this work, we focus on the clinical domain for which we study embedding strategies that rely on general-domain resources only. We show that by combining off-the-shelf contextual embeddings (ELMo) with static word2vec embeddings trained on a small in-domain corpus built from the task data, we manage to reach and sometimes outperform representations learned from a large corpus in the medical domain.</abstract>
      <url hash="51426742">P19-2041</url>
      <doi>10.18653/v1/P19-2041</doi>
      <bibkey>el-boukkouri-etal-2019-embedding</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/2010-i2b2-va">2010 i2b2/VA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="44">
      <title>Improving Neural Entity Disambiguation with Graph Embeddings</title>
      <author><first>&#214;zge</first><last>Sevgili</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>315&#8211;322</pages>
      <abstract>Entity Disambiguation (ED) is the task of linking an ambiguous entity mention to a corresponding entry in a knowledge base. Current methods have mostly focused on unstructured text data to learn representations of entities, however, there is structured information in the knowledge base itself that should be useful to disambiguate entities. In this work, we propose a method that uses graph embeddings for integrating structured information from the knowledge base with unstructured information from text-based representations. Our experiments confirm that graph embeddings trained on a graph of hyperlinks between Wikipedia articles improve the performances of simple feed-forward neural ED model and a state-of-the-art neural ED system.</abstract>
      <url hash="eb34789d">P19-2044</url>
      <doi>10.18653/v1/P19-2044</doi>
      <bibkey>sevgili-etal-2019-improving</bibkey>
    </paper>
    <paper id="46">
      <title>Convolutional Neural Networks for Financial Text Regression</title>
      <author><first>Ne&#351;at</first><last>Dereli</last></author>
      <author><first>Murat</first><last>Saraclar</last></author>
      <pages>331&#8211;337</pages>
      <abstract>Forecasting financial volatility of a publicly-traded company from its annual reports has been previously defined as a text regression problem. Recent studies use a manually labeled lexicon to filter the annual reports by keeping sentiment words only. In order to remove the lexicon dependency without decreasing the performance, we replace bag-of-words model word features by word embedding vectors. Using word vectors increases the number of parameters. Considering the increase in number of parameters and excessive lengths of annual reports, a convolutional neural network model is proposed and transfer learning is applied. Experimental results show that the convolutional neural network model provides more accurate volatility predictions than lexicon based models.</abstract>
      <url hash="77e56af3">P19-2046</url>
      <doi>10.18653/v1/P19-2046</doi>
      <bibkey>dereli-saraclar-2019-convolutional</bibkey>
    </paper>
    <paper id="49">
      <title>Scheduled Sampling for Transformers</title>
      <author><first>Tsvetomila</first><last>Mihaylova</last></author>
      <author><first>Andr&#233; F. T.</first><last>Martins</last></author>
      <pages>351&#8211;356</pages>
      <abstract>Scheduled sampling is a technique for avoiding one of the known problems in sequence-to-sequence generation: exposure bias. It consists of feeding the model a mix of the teacher forced embeddings and the model predictions from the previous step in training time. The technique has been used for improving model performance with recurrent neural networks (RNN). In the Transformer model, unlike the RNN, the generation of a new word attends to the full sentence generated so far, not only to the last word, and it is not straightforward to apply the scheduled sampling technique. We propose some structural changes to allow scheduled sampling to be applied to Transformer architectures, via a two-pass decoding strategy. Experiments on two language pairs achieve performance close to a teacher-forcing baseline and show that this technique is promising for further exploration.</abstract>
      <url hash="7d6e900e">P19-2049</url>
      <doi>10.18653/v1/P19-2049</doi>
      <bibkey>mihaylova-martins-2019-scheduled</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="51">
      <title>Cross-domain and Cross-lingual Abusive Language Detection: A Hybrid Approach with Deep Learning and a Multilingual Lexicon</title>
      <author><first>Endang Wahyu</first><last>Pamungkas</last></author>
      <author><first>Viviana</first><last>Patti</last></author>
      <pages>363&#8211;370</pages>
      <abstract>The development of computational methods to detect abusive language in social media within variable and multilingual contexts has recently gained significant traction. The growing interest is confirmed by the large number of benchmark corpora for different languages developed in the latest years. However, abusive language behaviour is multifaceted and available datasets are featured by different topical focuses. This makes abusive language detection a domain-dependent task, and building a robust system to detect general abusive content a first challenge. Moreover, most resources are available for English, which makes detecting abusive language in low-resource languages a further challenge. We address both challenges by considering ten publicly available datasets across different domains and languages. A hybrid approach with deep learning and a multilingual lexicon to cross-domain and cross-lingual detection of abusive content is proposed and compared with other simpler models. We show that training a system on general abusive language datasets will produce a cross-domain robust system, which can be used to detect other more specific types of abusive content. We also found that using the domain-independent lexicon HurtLex is useful to transfer knowledge between domains and languages. In the cross-lingual experiment, we demonstrate the effectiveness of our jointlearning model also in out-domain scenarios.</abstract>
      <url hash="f36f6d9b">P19-2051</url>
      <doi>10.18653/v1/P19-2051</doi>
      <bibkey>pamungkas-patti-2019-cross</bibkey>
    </paper>
    <paper id="52">
      <title>De-Mixing Sentiment from Code-Mixed Text</title>
      <author><first>Yash Kumar</first><last>Lal</last></author>
      <author><first>Vaibhav</first><last>Kumar</last></author>
      <author><first>Mrinal</first><last>Dhar</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>371&#8211;377</pages>
      <abstract>Code-mixing is the phenomenon of mixing the vocabulary and syntax of multiple languages in the same sentence. It is an increasingly common occurrence in today&#8217;s multilingual society and poses a big challenge when encountered in different downstream tasks. In this paper, we present a hybrid architecture for the task of Sentiment Analysis of English-Hindi code-mixed data. Our method consists of three components, each seeking to alleviate different issues. We first generate subword level representations for the sentences using a CNN architecture. The generated representations are used as inputs to a Dual Encoder Network which consists of two different BiLSTMs - the Collective and Specific Encoder. The Collective Encoder captures the overall sentiment of the sentence, while the Specific Encoder utilizes an attention mechanism in order to focus on individual sentiment-bearing sub-words. This, combined with a Feature Network consisting of orthographic features and specially trained word embeddings, achieves state-of-the-art results - 83.54% accuracy and 0.827 F1 score - on a benchmark dataset.</abstract>
      <url hash="ea259c52">P19-2052</url>
      <doi>10.18653/v1/P19-2052</doi>
      <bibkey>lal-etal-2019-de</bibkey>
    </paper>
    <paper id="55">
      <title>Deep Neural Models for Medical Concept Normalization in User-Generated Texts</title>
      <author><first>Zulfat</first><last>Miftahutdinov</last></author>
      <author><first>Elena</first><last>Tutubalina</last></author>
      <pages>393&#8211;399</pages>
      <abstract>In this work, we consider the medical concept normalization problem, i.e., the problem of mapping a health-related entity mention in a free-form text to a concept in a controlled vocabulary, usually to the standard thesaurus in the Unified Medical Language System (UMLS). This is a challenging task since medical terminology is very different when coming from health care professionals or from the general public in the form of social media texts. We approach it as a sequence learning problem with powerful neural networks such as recurrent neural networks and contextualized word representation models trained to obtain semantic representations of social media expressions. Our experimental evaluation over three different benchmarks shows that neural architectures leverage the semantic meaning of the entity mention and significantly outperform existing state of the art models.</abstract>
      <url hash="2e4a6205">P19-2055</url>
      <doi>10.18653/v1/P19-2055</doi>
      <bibkey>miftahutdinov-tutubalina-2019-deep</bibkey>
    </paper>
    <paper id="56">
      <title>Using Semantic Similarity as Reward for Reinforcement Learning in Sentence Generation</title>
      <author><first>Go</first><last>Yasui</last></author>
      <author><first>Yoshimasa</first><last>Tsuruoka</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>400&#8211;406</pages>
      <abstract>Traditional model training for sentence generation employs cross-entropy loss as the loss function. While cross-entropy loss has convenient properties for supervised learning, it is unable to evaluate sentences as a whole, and lacks flexibility. We present the approach of training the generation model using the estimated semantic similarity between the output and reference sentences to alleviate the problems faced by the training with cross-entropy loss. We use the BERT-based scorer fine-tuned to the Semantic Textual Similarity (STS) task for semantic similarity estimation, and train the model with the estimated scores through reinforcement learning (RL). Our experiments show that reinforcement learning with semantic similarity reward improves the BLEU scores from the baseline LSTM NMT model.</abstract>
      <url hash="8b693d84">P19-2056</url>
      <doi>10.18653/v1/P19-2056</doi>
      <bibkey>yasui-etal-2019-using</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
    </paper>
    <paper id="58">
      <title>Detecting Adverse Drug Reactions from Biomedical Texts with Neural Networks</title>
      <author><first>Ilseyar</first><last>Alimova</last></author>
      <author><first>Elena</first><last>Tutubalina</last></author>
      <pages>415&#8211;421</pages>
      <abstract>Detection of adverse drug reactions in postapproval periods is a crucial challenge for pharmacology. Social media and electronic clinical reports are becoming increasingly popular as a source for obtaining health related information. In this work, we focus on extraction information of adverse drug reactions from various sources of biomedical textbased information, including biomedical literature and social media. We formulate the problem as a binary classification task and compare the performance of four state-of-the-art attention-based neural networks in terms of the F-measure. We show the effectiveness of these methods on four different benchmarks.</abstract>
      <url hash="6b256d52">P19-2058</url>
      <doi>10.18653/v1/P19-2058</doi>
      <bibkey>alimova-tutubalina-2019-detecting</bibkey>
    </paper>
    <paper id="59">
      <title>Annotating and Analyzing Semantic Role of Elementary Units and Relations in Online Persuasive Arguments</title>
      <author><first>Ryo</first><last>Egawa</last></author>
      <author><first>Gaku</first><last>Morio</last></author>
      <author><first>Katsuhide</first><last>Fujita</last></author>
      <pages>422&#8211;428</pages>
      <abstract>For analyzing online persuasions, one of the important goals is to semantically understand how people construct comments to persuade others. However, analyzing the semantic role of arguments for online persuasion has been less emphasized. Therefore, in this study, we propose a novel annotation scheme that captures the semantic role of arguments in a popular online persuasion forum, so-called ChangeMyView. Through this study, we have made the following contributions: (i) proposing a scheme that includes five types of elementary units (EUs) and two types of relations. (ii) annotating ChangeMyView which results in 4612 EUs and 2713 relations in 345 posts. (iii) analyzing the semantic role of persuasive arguments. Our analyses captured certain characteristic phenomena for online persuasion.</abstract>
      <url hash="7e7811ca">P19-2059</url>
      <doi>10.18653/v1/P19-2059</doi>
      <bibkey>egawa-etal-2019-annotating</bibkey>
    </paper>
    <paper id="60">
      <title>A <fixed-case>J</fixed-case>apanese Word Segmentation Proposal</title>
      <author><first>Stalin</first><last>Aguirre</last></author>
      <author><first>Josaf&#225;</first><last>Aguiar</last></author>
      <pages>429&#8211;435</pages>
      <abstract>Current Japanese word segmentation methods, that use a morpheme-based approach, may produce different segmentations for the same strings. This occurs when these strings appear in different sentences. The cause is the influence of different contexts around these strings affecting the probabilistic models used in segmentation algorithms. This paper presents an alternative to the current morpheme-based scheme for Japanese word segmentation. The proposed scheme focuses on segmenting inflections as single words instead of separating the auxiliary verbs and other morphemes from the stems. Some morphological segmentation rules are presented for each type of word and these rules are implemented in a program which is properly described. The program is used to generate a segmentation of a sentence corpus, whose consistency is calculated and compared with the current morpheme-based segmentation of the same corpus. The experiments show that this method produces a much more consistent segmentation than the morpheme-based one.</abstract>
      <url hash="d3d8d18a">P19-2060</url>
      <doi>10.18653/v1/P19-2060</doi>
      <bibkey>aguirre-aguiar-2019-japanese</bibkey>
    </paper>
  </volume>
  <volume id="3" ingest-date="2019-07-28">
    <meta>
      <booktitle>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</booktitle>
      <url hash="a4023c8e">P19-3</url>
      <editor><first>Marta R.</first><last>Costa-juss&#224;</last></editor>
      <editor><first>Enrique</first><last>Alfonseca</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Florence, Italy</address>
      <month>July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="c76860a8">P19-3000</url>
      <bibkey>acl-2019-association-linguistics-system</bibkey>
    </frontmatter>
    <paper id="2">
      <title><fixed-case>SLATE</fixed-case>: A Super-Lightweight Annotation Tool for Experts</title>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <pages>7&#8211;12</pages>
      <abstract>Many annotation tools have been developed, covering a wide variety of tasks and providing features like user management, pre-processing, and automatic labeling. However, all of these tools use Graphical User Interfaces, and often require substantial effort to install and configure. This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow. SLATE supports annotation at different scales (spans of characters, tokens, and lines, or a document) and of different types (free text, labels, and links), with easily customisable keybindings, and unicode support. In a user study comparing with other tools it was consistently the easiest to install and use. SLATE fills a need not met by existing systems, and has already been used to annotate two corpora, one of which involved over 250 hours of annotation effort.</abstract>
      <url hash="922e0760">P19-3002</url>
      <attachment type="note" hash="c5753d1d">P19-3002.Note.pdf</attachment>
      <doi>10.18653/v1/P19-3002</doi>
      <bibkey>kummerfeld-2019-slate</bibkey>
      <pwccode url="https://github.com/jkkummerfeld/slate" additional="false">jkkummerfeld/slate</pwccode>
    </paper>
    <paper id="3">
      <title>lingvis.io - A Linguistic Visual Analytics Framework</title>
      <author><first>Mennatallah</first><last>El-Assady</last></author>
      <author><first>Wolfgang</first><last>Jentner</last></author>
      <author><first>Fabian</first><last>Sperrle</last></author>
      <author><first>Rita</first><last>Sevastjanova</last></author>
      <author><first>Annette</first><last>Hautli-Janisz</last></author>
      <author><first>Miriam</first><last>Butt</last></author>
      <author><first>Daniel</first><last>Keim</last></author>
      <pages>13&#8211;18</pages>
      <abstract>We present a modular framework for the rapid-prototyping of linguistic, web-based, visual analytics applications. Our framework gives developers access to a rich set of machine learning and natural language processing steps, through encapsulating them into micro-services and combining them into a computational pipeline. This processing pipeline is auto-configured based on the requirements of the visualization front-end, making the linguistic processing and visualization design, detached independent development tasks. This paper describes the constellation and modality of our framework, which continues to support the efficient development of various human-in-the-loop, linguistic visual analytics research techniques and applications.</abstract>
      <url hash="d022bde8">P19-3003</url>
      <doi>10.18653/v1/P19-3003</doi>
      <bibkey>el-assady-etal-2019-lingvis</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>SARAL</fixed-case>: A Low-Resource Cross-Lingual Domain-Focused Information Retrieval System for Effective Rapid Document Triage</title>
      <author><first>Elizabeth</first><last>Boschee</last></author>
      <author><first>Joel</first><last>Barry</last></author>
      <author><first>Jayadev</first><last>Billa</last></author>
      <author><first>Marjorie</first><last>Freedman</last></author>
      <author><first>Thamme</first><last>Gowda</last></author>
      <author><first>Constantine</first><last>Lignos</last></author>
      <author><first>Chester</first><last>Palen-Michel</last></author>
      <author><first>Michael</first><last>Pust</last></author>
      <author><first>Banriskhem Kayang</first><last>Khonglah</last></author>
      <author><first>Srikanth</first><last>Madikeri</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <author><first>Scott</first><last>Miller</last></author>
      <pages>19&#8211;24</pages>
      <abstract>With the increasing democratization of electronic media, vast information resources are available in less-frequently-taught languages such as Swahili or Somali. That information, which may be crucially important and not available elsewhere, can be difficult for monolingual English speakers to effectively access. In this paper we present an end-to-end cross-lingual information retrieval (CLIR) and summarization system for low-resource languages that 1) enables English speakers to search foreign language repositories of text and audio using English queries, 2) summarizes the retrieved documents in English with respect to a particular information need, and 3) provides complete transcriptions and translations as needed. The SARAL system achieved the top end-to-end performance in the most recent IARPA MATERIAL CLIR+summarization evaluations. Our demonstration system provides end-to-end open query retrieval and summarization capability, and presents the original source text or audio, speech transcription, and machine translation, for two low resource languages.</abstract>
      <url hash="0f3b2e4c">P19-3004</url>
      <doi>10.18653/v1/P19-3004</doi>
      <bibkey>boschee-etal-2019-saral</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>J</fixed-case>iuge: A Human-Machine Collaborative <fixed-case>C</fixed-case>hinese Classical Poetry Generation System</title>
      <author><first>Guo</first><last>Zhipeng</last></author>
      <author><first>Xiaoyuan</first><last>Yi</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Wenhao</first><last>Li</last></author>
      <author><first>Cheng</first><last>Yang</last></author>
      <author><first>Jiannan</first><last>Liang</last></author>
      <author><first>Huimin</first><last>Chen</last></author>
      <author><first>Yuhui</first><last>Zhang</last></author>
      <author><first>Ruoyu</first><last>Li</last></author>
      <pages>25&#8211;30</pages>
      <abstract>Research on the automatic generation of poetry, the treasure of human culture, has lasted for decades. Most existing systems, however, are merely model-oriented, which input some user-specified keywords and directly complete the generation process in one pass, with little user participation. We believe that the machine, being a collaborator or an assistant, should not replace human beings in poetic creation. Therefore, we proposed Jiuge, a human-machine collaborative Chinese classical poetry generation system. Unlike previous systems, Jiuge allows users to revise the unsatisfied parts of a generated poem draft repeatedly. According to the revision, the poem will be dynamically updated and regenerated. After the revision and modification procedure, the user can write a satisfying poem together with Jiuge system collaboratively. Besides, Jiuge can accept multi-modal inputs, such as keywords, plain text or images. By exposing the options of poetry genres, styles and revision modes, Jiuge, acting as a professional assistant, allows constant and active participation of users in poetic creation.</abstract>
      <url hash="40fb9cc1">P19-3005</url>
      <doi>10.18653/v1/P19-3005</doi>
      <bibkey>zhipeng-etal-2019-jiuge</bibkey>
    </paper>
    <paper id="7">
      <title>A Multiscale Visualization of Attention in the Transformer Model</title>
      <author><first>Jesse</first><last>Vig</last></author>
      <pages>37&#8211;42</pages>
      <abstract>The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.</abstract>
      <url hash="e47fd3d3">P19-3007</url>
      <attachment type="poster" hash="069c963f">P19-3007.Poster.pdf</attachment>
      <doi>10.18653/v1/P19-3007</doi>
      <bibkey>vig-2019-multiscale</bibkey>
      <pwccode url="https://github.com/jessevig/bertviz" additional="true">jessevig/bertviz</pwccode>
    </paper>
    <paper id="8">
      <title><fixed-case>P</fixed-case>ost<fixed-case>A</fixed-case>c : A Visual Interactive Search, Exploration, and Analysis Platform for <fixed-case>P</fixed-case>h<fixed-case>D</fixed-case> Intensive Job Postings</title>
      <author><first>Chenchen</first><last>Xu</last></author>
      <author><first>Inger</first><last>Mewburn</last></author>
      <author><first>Will J</first><last>Grant</last></author>
      <author><first>Hanna</first><last>Suominen</last></author>
      <pages>43&#8211;48</pages>
      <abstract>Over 60% of Australian PhD graduates land their first job after graduation outside academia, but this job market remains largely hidden to these job seekers. Employers&#8217; low awareness and interest in attracting PhD graduates means that the term &#8220;PhD&#8221; is rarely used as a keyword in job advertisements; 80% of companies looking to employ similar researchers do not specifically ask for a PhD qualification. As a result, typing in &#8220;PhD&#8221; to a job search engine tends to return mostly academic jobs. We set out to make the market for advanced research skills more visible to job seekers. In this paper, we present PostAc, an online platform of authentic job postings that helps PhD graduates sharpen their career thinking. The platform is underpinned by research on the key factors that identify what an employer is looking for when they want to hire a highly skilled researcher. Its ranking model leverages the free-form text embedded in the job description to quantify the most sought-after PhD skills and educate information seekers about the Australian job-market appetite for PhD skills. The platform makes visible the geographic location, industry sector, job title, working hours, continuity, and wage of the research intensive jobs. This is the first data-driven exploration in this field. Both empirical results and online platform will be presented in this paper.</abstract>
      <url hash="25321a60">P19-3008</url>
      <doi>10.18653/v1/P19-3008</doi>
      <bibkey>xu-etal-2019-postac</bibkey>
    </paper>
    <paper id="9">
      <title>An adaptable task-oriented dialog system for stand-alone embedded devices</title>
      <author><first>Long</first><last>Duong</last></author>
      <author><first>Vu Cong Duy</first><last>Hoang</last></author>
      <author><first>Tuyen Quang</first><last>Pham</last></author>
      <author><first>Yu-Heng</first><last>Hong</last></author>
      <author><first>Vladislavs</first><last>Dovgalecs</last></author>
      <author><first>Guy</first><last>Bashkansky</last></author>
      <author><first>Jason</first><last>Black</last></author>
      <author><first>Andrew</first><last>Bleeker</last></author>
      <author><first>Serge Le</first><last>Huitouze</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <pages>49&#8211;57</pages>
      <abstract>This paper describes a spoken-language end-to-end task-oriented dialogue system for small embedded devices such as home appliances. While the current system implements a smart alarm clock with advanced calendar scheduling functionality, the system is designed to make it easy to port to other application domains (e.g., the dialogue component factors out domain-specific execution from domain-general actions such as requesting and updating slot values). The system does not require internet connectivity because all components, including speech recognition, natural language understanding, dialogue management, execution and text-to-speech, run locally on the embedded device (our demo uses a Raspberry Pi). This simplifies deployment, minimizes server costs and most importantly, eliminates user privacy risks. The demo video in alarm domain is here youtu.be/N3IBMGocvHU</abstract>
      <url hash="8ef6cf1e">P19-3009</url>
      <doi>10.18653/v1/P19-3009</doi>
      <bibkey>duong-etal-2019-adaptable</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>FASTD</fixed-case>ial: Abstracting Dialogue Policies for Fast Development of Task Oriented Agents</title>
      <author><first>Serra Sinem</first><last>Tekiroglu</last></author>
      <author><first>Bernardo</first><last>Magnini</last></author>
      <author><first>Marco</first><last>Guerini</last></author>
      <pages>75&#8211;80</pages>
      <abstract>We present a novel abstraction framework called FASTDial for designing task oriented dialogue agents, built on top of the OpenDial toolkit. This framework is meant to facilitate prototyping and development of dialogue systems from scratch also by non tech savvy especially when limited training data is available. To this end, we use a generic and simple frame-slots data-structure with pre-defined dialogue policies that allows for fast design and implementation at the price of some flexibility reduction. Moreover, it allows for minimizing programming effort and domain expert training time, by hiding away many implementation details. We provide a system demonstration screencast video in the following link: https://vimeo.com/329840716</abstract>
      <url hash="48c568cd">P19-3013</url>
      <doi>10.18653/v1/P19-3013</doi>
      <bibkey>tekiroglu-etal-2019-fastdial</bibkey>
      <pwccode url="https://github.com/serrasinem/FASTDial" additional="false">serrasinem/FASTDial</pwccode>
    </paper>
    <paper id="14">
      <title>A Neural, Interactive-predictive System for Multimodal Sequence to Sequence Tasks</title>
      <author><first>&#193;lvaro</first><last>Peris</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <pages>81&#8211;86</pages>
      <abstract>We present a demonstration of a neural interactive-predictive system for tackling multimodal sequence to sequence tasks. The system generates text predictions to different sequence to sequence tasks: machine translation, image and video captioning. These predictions are revised by a human agent, who introduces corrections in the form of characters. The system reacts to each correction, providing alternative hypotheses, compelling with the feedback provided by the user. The final objective is to reduce the human effort required during this correction process. This system is implemented following a client-server architecture. For accessing the system, we developed a website, which communicates with the neural model, hosted in a local server. From this website, the different tasks can be tackled following the interactive&#8211;predictive framework. We open-source all the code developed for building this system. The demonstration in hosted in http://casmacat.prhlt.upv.es/interactive-seq2seq.</abstract>
      <url hash="9fe6153d">P19-3014</url>
      <doi>10.18653/v1/P19-3014</doi>
      <bibkey>peris-casacuberta-2019-neural</bibkey>
      <pwccode url="https://github.com/lvapeab/interactive-keras-captioning" additional="false">lvapeab/interactive-keras-captioning</pwccode>
    </paper>
    <paper id="17">
      <title><fixed-case>KCAT</fixed-case>: A Knowledge-Constraint Typing Annotation Tool</title>
      <author><first>Sheng</first><last>Lin</last></author>
      <author><first>Luye</first><last>Zheng</last></author>
      <author><first>Bo</first><last>Chen</last></author>
      <author><first>Siliang</first><last>Tang</last></author>
      <author><first>Zhigang</first><last>Chen</last></author>
      <author><first>Guoping</first><last>Hu</last></author>
      <author><first>Yueting</first><last>Zhuang</last></author>
      <author><first>Fei</first><last>Wu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <pages>99&#8211;104</pages>
      <abstract>In this paper, we propose an efficient Knowledge Constraint Fine-grained Entity Typing Annotation Tool, which further improves the entity typing process through entity linking together with some practical functions.</abstract>
      <url hash="9fa2129a">P19-3017</url>
      <doi>10.18653/v1/P19-3017</doi>
      <bibkey>lin-etal-2019-kcat</bibkey>
      <pwccode url="https://github.com/donnyslin/KCAT" additional="false">donnyslin/KCAT</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
    </paper>
    <paper id="20">
      <title><fixed-case>O</fixed-case>pen<fixed-case>K</fixed-case>iwi: An Open Source Framework for Quality Estimation</title>
      <author><first>Fabio</first><last>Kepler</last></author>
      <author><first>Jonay</first><last>Tr&#233;nous</last></author>
      <author><first>Marcos</first><last>Treviso</last></author>
      <author><first>Miguel</first><last>Vera</last></author>
      <author><first>Andr&#233; F. T.</first><last>Martins</last></author>
      <pages>117&#8211;122</pages>
      <abstract>We introduce OpenKiwi, a Pytorch-based open source framework for translation quality estimation. OpenKiwi supports training and testing of word-level and sentence-level quality estimation systems, implementing the winning systems of the WMT 2015&#8211;18 quality estimation campaigns. We benchmark OpenKiwi on two datasets from WMT 2018 (English-German SMT and NMT), yielding state-of-the-art performance on the word-level tasks and near state-of-the-art in the sentence-level tasks.</abstract>
      <url hash="cd2b919f">P19-3020</url>
      <award>Best Demo Paper</award>
      <doi>10.18653/v1/P19-3020</doi>
      <bibkey>kepler-etal-2019-openkiwi</bibkey>
      <pwccode url="https://github.com/Unbabel/OpenKiwi" additional="false">Unbabel/OpenKiwi</pwccode>
    </paper>
    <paper id="22">
      <title><fixed-case>P</fixed-case>erspectro<fixed-case>S</fixed-case>cope: A Window to the World of Diverse Perspectives</title>
      <author><first>Sihao</first><last>Chen</last></author>
      <author><first>Daniel</first><last>Khashabi</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>129&#8211;134</pages>
      <abstract>This work presents PerspectroScope, a web-based system which lets users query a discussion-worthy natural language claim, and extract and visualize various perspectives in support or against the claim, along with evidence supporting each perspective. The system thus lets users explore various perspectives that could touch upon aspects of the issue at hand.The system is built as a combination of retrieval engines and learned textual-entailment-like classifiers built using a few recent developments in natural language understanding. To make the system more adaptive, expand its coverage, and improve its decisions over time, our platform employs various mechanisms to get corrections from the users. PerspectroScope is available at github.com/CogComp/perspectroscope Web demo link: http://orwell.seas.upenn.edu:4002/ Link to demo video: https://www.youtube.com/watch?v=MXBTR1Sp3Bs</abstract>
      <url hash="e2da3c78">P19-3022</url>
      <doi>10.18653/v1/P19-3022</doi>
      <bibkey>chen-etal-2019-perspectroscope</bibkey>
      <pwccode url="https://github.com/CogComp/perspectroscope" additional="false">CogComp/perspectroscope</pwccode>
    </paper>
    <paper id="23">
      <title><fixed-case>HEIDL</fixed-case>: Learning Linguistic Expressions with Deep Learning and Human-in-the-Loop</title>
      <author><first>Prithviraj</first><last>Sen</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Eser</first><last>Kandogan</last></author>
      <author><first>Yiwei</first><last>Yang</last></author>
      <author><first>Walter</first><last>Lasecki</last></author>
      <pages>135&#8211;140</pages>
      <abstract>While the role of humans is increasingly recognized in machine learning community, representation of and interaction with models in current human-in-the-loop machine learning (HITL-ML) approaches are too low-level and far-removed from human&#8217;s conceptual models. We demonstrate HEIDL, a prototype HITL-ML system that exposes the machine-learned model through high-level, explainable linguistic expressions formed of predicates representing semantic structure of text. In HEIDL, human&#8217;s role is elevated from simply evaluating model predictions to interpreting and even updating the model logic directly by enabling interaction with rule predicates themselves. Raising the currency of interaction to such semantic levels calls for new interaction paradigms between humans and machines that result in improved productivity for text analytics model development process. Moreover, by involving humans in the process, the human-machine co-created models generalize better to unseen data as domain experts are able to instill their expertise by extrapolating from what has been learned by automated algorithms from few labelled data.</abstract>
      <url hash="a3343b77">P19-3023</url>
      <doi>10.18653/v1/P19-3023</doi>
      <bibkey>sen-etal-2019-heidl</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>C</fixed-case>laim<fixed-case>P</fixed-case>ortal: Integrated Monitoring, Searching, Checking, and Analytics of Factual Claims on <fixed-case>T</fixed-case>witter</title>
      <author><first>Sarthak</first><last>Majithia</last></author>
      <author><first>Fatma</first><last>Arslan</last></author>
      <author><first>Sumeet</first><last>Lubal</last></author>
      <author><first>Damian</first><last>Jimenez</last></author>
      <author><first>Priyank</first><last>Arora</last></author>
      <author><first>Josue</first><last>Caraballo</last></author>
      <author><first>Chengkai</first><last>Li</last></author>
      <pages>153&#8211;158</pages>
      <abstract>We present ClaimPortal, a web-based platform for monitoring, searching, checking, and analyzing English factual claims on Twitter from the American political domain. We explain the architecture of ClaimPortal, its components and functions, and the user interface. While the last several years have witnessed a substantial growth in interests and efforts in the area of computational fact-checking, ClaimPortal is a novel infrastructure in that fact-checkers have largely skipped factual claims in tweets. It can be a highly powerful tool to both general web users and fact-checkers. It will also be an educational resource in helping cultivate a society that is less susceptible to falsehoods.</abstract>
      <url hash="137255d3">P19-3026</url>
      <doi>10.18653/v1/P19-3026</doi>
      <bibkey>majithia-etal-2019-claimportal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="28">
      <title><fixed-case>P</fixed-case>arallax: Visualizing and Understanding the Semantics of Embedding Spaces via Algebraic Formulae</title>
      <author><first>Piero</first><last>Molino</last></author>
      <author><first>Yang</first><last>Wang</last></author>
      <author><first>Jiawei</first><last>Zhang</last></author>
      <pages>165&#8211;180</pages>
      <abstract>Embeddings are a fundamental component of many modern machine learning and natural language processing models. Understanding them and visualizing them is essential for gathering insights about the information they capture and the behavior of the models. In this paper, we introduce Parallax, a tool explicitly designed for this task. Parallax allows the user to use both state-of-the-art embedding analysis methods (PCA and t-SNE) and a simple yet effective task-oriented approach where users can explicitly define the axes of the projection through algebraic formulae. %consists in projecting them in two-dimensional planes without any interpretable semantics associated to the axes of the projection, which makes detailed analyses and comparison among multiple sets of embeddings challenging. In this approach, embeddings are projected into a semantically meaningful subspace, which enhances interpretability and allows for more fine-grained analysis. We demonstrate the power of the tool and the proposed methodology through a series of case studies and a user study.</abstract>
      <url hash="daf60dac">P19-3028</url>
      <doi>10.18653/v1/P19-3028</doi>
      <bibkey>molino-etal-2019-parallax</bibkey>
      <pwccode url="https://github.com/uber-research/parallax" additional="true">uber-research/parallax</pwccode>
    </paper>
    <paper id="31">
      <title><fixed-case>TARGER</fixed-case>: Neural Argument Mining at Your Fingertips</title>
      <author><first>Artem</first><last>Chernodub</last></author>
      <author><first>Oleksiy</first><last>Oliynyk</last></author>
      <author><first>Philipp</first><last>Heidenreich</last></author>
      <author><first>Alexander</first><last>Bondarenko</last></author>
      <author><first>Matthias</first><last>Hagen</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>195&#8211;200</pages>
      <abstract>We present TARGER, an open source neural argument mining framework for tagging arguments in free input texts and for keyword-based retrieval of arguments from an argument-tagged web-scale corpus. The currently available models are pre-trained on three recent argument mining datasets and enable the use of neural argument mining without any reproducibility effort on the user&#8217;s side. The open source code ensures portability to other domains and use cases.</abstract>
      <url hash="51f933af">P19-3031</url>
      <doi>10.18653/v1/P19-3031</doi>
      <revision id="1" href="P19-3031v1" hash="1f846543" />
      <revision id="2" href="P19-3031v2" hash="51f933af">Added a missing reference (footnote 3) and an acknowledgment to a library author.</revision>
      <bibkey>chernodub-etal-2019-targer</bibkey>
      <pwccode url="https://github.com/achernodub/targer" additional="false">achernodub/targer</pwccode>
    </paper>
    <paper id="32">
      <title><fixed-case>M</fixed-case>o<fixed-case>N</fixed-case>oise: A Multi-lingual and Easy-to-use Lexical Normalization Tool</title>
      <author><first>Rob</first><last>van der Goot</last></author>
      <pages>201&#8211;206</pages>
      <abstract>In this paper, we introduce and demonstrate the online demo as well as the command line interface of a lexical normalization system (MoNoise) for a variety of languages. We further improve this model by using features from the original word for every normalization candidate. For comparison with future work, we propose the bundling of seven datasets in six languages to form a new benchmark, together with a novel evaluation metric which is particularly suitable for cross-dataset comparisons. MoNoise reaches a new state-of-art performance for six out of seven of these datasets. Furthermore, we allow the user to tune the &#8216;aggressiveness&#8217; of the normalization, and show how the model can be made more efficient with only a small loss in performance. The online demo can be found on: http://www.robvandergoot.com/monoise and the corresponding code on: https://bitbucket.org/robvanderg/monoise/</abstract>
      <url hash="e7d75a1c">P19-3032</url>
      <doi>10.18653/v1/P19-3032</doi>
      <bibkey>van-der-goot-2019-monoise</bibkey>
      <pwccode url="https://bitbucket.org/robvanderg/cacheembeds" additional="false">robvanderg/cacheembeds</pwccode>
    </paper>
    <paper id="33">
      <title>Level-Up: Learning to Improve Proficiency Level of Essays</title>
      <author><first>Wen-Bin</first><last>Han</last></author>
      <author><first>Jhih-Jie</first><last>Chen</last></author>
      <author><first>Chingyu</first><last>Yang</last></author>
      <author><first>Jason</first><last>Chang</last></author>
      <pages>207&#8211;212</pages>
      <abstract>We introduce a method for generating suggestions on a given sentence for improving the proficiency level. In our approach, the sentence is transformed into a sequence of grammatical elements aimed at providing suggestions of more advanced grammar elements based on originals. The method involves parsing the sentence, identifying grammatical elements, and ranking related elements to recommend a higher level of grammatical element. We present a prototype tutoring system, Level-Up, that applies the method to English learners&#8217; essays in order to assist them in writing and reading. Evaluation on a set of essays shows that our method does assist user in writing.</abstract>
      <url hash="cb9e295c">P19-3033</url>
      <doi>10.18653/v1/P19-3033</doi>
      <bibkey>han-etal-2019-level</bibkey>
    </paper>
    </volume>
  <volume id="4" ingest-date="2019-07-28">
    <meta>
      <booktitle>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</booktitle>
      <url hash="8caff722">P19-4</url>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Alexis</first><last>Palmer</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Florence, Italy</address>
      <month>July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url hash="28964f4c">P19-4000</url>
      <bibkey>acl-2019-association-linguistics-tutorial</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Graph-Based Meaning Representations: Design and Processing</title>
      <author><first>Alexander</first><last>Koller</last></author>
      <author><first>Stephan</first><last>Oepen</last></author>
      <author><first>Weiwei</first><last>Sun</last></author>
      <pages>6&#8211;11</pages>
      <abstract>This tutorial is on representing and processing sentence meaning in the form of labeled directed graphs. The tutorial will (a) briefly review relevant background in formal and linguistic semantics; (b) semi-formally define a unified abstract view on different flavors of semantic graphs and associated terminology; (c) survey common frameworks for graph-based meaning representation and available graph banks; and (d) offer a technical overview of a representative selection of different parsing approaches.</abstract>
      <url hash="db6fb488">P19-4002</url>
      <doi>10.18653/v1/P19-4002</doi>
      <bibkey>koller-etal-2019-graph</bibkey>
      <pwccode url="https://github.com/cfmrp/tutorial" additional="false">cfmrp/tutorial</pwccode>
    </paper>
    <paper id="4">
      <title>Computational Analysis of Political Texts: Bridging Research Efforts Across Communities</title>
      <author><first>Goran</first><last>Glava&#353;</last></author>
      <author><first>Federico</first><last>Nanni</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <pages>18&#8211;23</pages>
      <abstract>In the last twenty years, political scientists started adopting and developing natural language processing (NLP) methods more actively in order to exploit text as an additional source of data in their analyses. Over the last decade the usage of computational methods for analysis of political texts has drastically expanded in scope, allowing for a sustained growth of the text-as-data community in political science. In political science, NLP methods have been extensively used for a number of analyses types and tasks, including inferring policy position of actors from textual evidence, detecting topics in political texts, and analyzing stylistic aspects of political texts (e.g., assessing the role of language ambiguity in framing the political agenda). Just like in numerous other domains, much of the work on computational analysis of political texts has been enabled and facilitated by the development of resources such as, the topically coded electoral programmes (e.g., the Manifesto Corpus) or topically coded legislative texts (e.g., the Comparative Agenda Project). Political scientists created resources and used available NLP methods to process textual data largely in isolation from the NLP community. At the same time, NLP researchers addressed closely related tasks such as election prediction, ideology classification, and stance detection. In other words, these two communities have been largely agnostic of one another, with NLP researchers mostly unaware of interesting applications in political science and political scientists not applying cutting-edge NLP methodology to their problems. The main goal of this tutorial is to systematize and analyze the body of research work on political texts from both communities. We aim to provide a gentle, all-round introduction to methods and tasks related to computational analysis of political texts. Our vision is to bring the two research communities closer to each other and contribute to faster and more significant developments in this interdisciplinary research area.</abstract>
      <url hash="fc3c89ff">P19-4004</url>
      <doi>10.18653/v1/P19-4004</doi>
      <bibkey>glavas-etal-2019-computational</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>W</fixed-case>ikipedia as a Resource for Text Analysis and Retrieval</title>
      <author><first>Marius</first><last>Pasca</last></author>
      <pages>24</pages>
      <abstract>This tutorial examines the role of Wikipedia in tasks related to text analysis and retrieval. Text analysis tasks, which take advantage of Wikipedia, include coreference resolution, word sense and entity disambiguation and information extraction. In information retrieval, a better understanding of the structure and meaning of queries helps in matching queries against documents, clustering search results, answer and entity retrieval and retrieving knowledge panels for queries asking about popular entities.</abstract>
      <url hash="3fbb1180">P19-4005</url>
      <doi>10.18653/v1/P19-4005</doi>
      <bibkey>pasca-2019-wikipedia</bibkey>
    </paper>
    <paper id="6">
      <title>Deep <fixed-case>B</fixed-case>ayesian Natural Language Processing</title>
      <author><first>Jen-Tzung</first><last>Chien</last></author>
      <pages>25&#8211;30</pages>
      <abstract>This introductory tutorial addresses the advances in deep Bayesian learning for natural language with ubiquitous applications ranging from speech recognition to document summarization, text classification, text segmentation, information extraction, image caption generation, sentence generation, dialogue control, sentiment classification, recommendation system, question answering and machine translation, to name a few. Traditionally, &#8220;deep learning&#8221; is taken to be a learning process where the inference or optimization is based on the real-valued deterministic model. The &#8220;semantic structure&#8221; in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in mathematical logic or computer programs. The &#8220;distribution function&#8221; in discrete or continuous latent variable model for natural language may not be properly decomposed or estimated. This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including hierarchical Dirichlet process, Chinese restaurant process, hierarchical Pitman-Yor process, Indian buffet process, recurrent neural network, long short-term memory, sequence-to-sequence model, variational auto-encoder, generative adversarial network, attention mechanism, memory-augmented neural network, skip neural network, stochastic neural network, predictive state neural network and policy neural network. We present how these models are connected and why they work for a variety of applications on symbolic and complex patterns in natural language. The variational inference and sampling method are formulated to tackle the optimization for complicated models. The word and sentence embeddings, clustering and co-clustering are merged with linguistic and semantic constraints. A series of case studies and domain applications are presented to tackle different issues in deep Bayesian processing, learning and understanding. At last, we will point out a number of directions and outlooks for future studies.</abstract>
      <url hash="5c4f9604">P19-4006</url>
      <doi>10.18653/v1/P19-4006</doi>
      <bibkey>chien-2019-deep</bibkey>
    </paper>
    <paper id="7">
      <title>Unsupervised Cross-Lingual Representation Learning</title>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Anders</first><last>S&#248;gaard</last></author>
      <author><first>Ivan</first><last>Vuli&#263;</last></author>
      <pages>31&#8211;38</pages>
      <abstract>In this tutorial, we provide a comprehensive survey of the exciting recent work on cutting-edge weakly-supervised and unsupervised cross-lingual word representations. After providing a brief history of supervised cross-lingual word representations, we focus on: 1) how to induce weakly-supervised and unsupervised cross-lingual word representations in truly resource-poor settings where bilingual supervision cannot be guaranteed; 2) critical examinations of different training conditions and requirements under which unsupervised algorithms can and cannot work effectively; 3) more robust methods for distant language pairs that can mitigate instability issues and low performance for distant language pairs; 4) how to comprehensively evaluate such representations; and 5) diverse applications that benefit from cross-lingual word representations (e.g., MT, dialogue, cross-lingual sequence labeling and structured prediction applications, cross-lingual IR).</abstract>
      <url hash="fd8da2de">P19-4007</url>
      <doi>10.18653/v1/P19-4007</doi>
      <bibkey>ruder-etal-2019-unsupervised</bibkey>
    </paper>
    </volume>
</collection>