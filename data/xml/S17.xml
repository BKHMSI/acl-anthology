<?xml version='1.0' encoding='utf-8'?>
<collection id="S17">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*<fixed-case>SEM</fixed-case> 2017)</booktitle>
      <url hash="ab2df2f7">S17-1</url>
      <editor><first>Nancy</first><last>Ide</last></editor>
      <editor><first>Aurélie</first><last>Herbelot</last></editor>
      <editor><first>Lluís</first><last>Màrquez</last></editor>
      <doi>10.18653/v1/S17-1</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="072af725">S17-1000</url>
      <bibkey>semeval-2017-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>What Analogies Reveal about Word Vectors and their Compositionality</title>
      <author><first>Gregory</first> <last>Finley</last></author>
      <author><first>Stephanie</first> <last>Farmer</last></author>
      <author><first>Serguei</first> <last>Pakhomov</last></author>
      <pages>1–11</pages>
      <url hash="8007b00b">S17-1001</url>
      <doi>10.18653/v1/S17-1001</doi>
      <abstract>Analogy completion via <a href="https://en.wikipedia.org/wiki/Vector_arithmetic">vector arithmetic</a> has become a common means of demonstrating the compositionality of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. Previous work have shown that this <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a> works more reliably for certain types of analogical word relationships than for others, but these studies have not offered a convincing account for why this is the case. We arrive at such an account through an experiment that targets a wide variety of analogy questions and defines a baseline condition to more accurately measure the efficacy of our <a href="https://en.wikipedia.org/wiki/System">system</a>. We find that the most reliably solvable analogy categories involve either 1) the application of a <a href="https://en.wikipedia.org/wiki/Morpheme">morpheme</a> with clear syntactic effects, 2) malefemale alternations, or 3) <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a>. These broader types do not pattern cleanly along a syntacticsemantic divide. We suggest instead that their commonality is distributional, in that the difference between the distributions of two words in any given pair encompasses a relatively small number of word types. Our study offers a needed explanation for why analogy tests succeed and fail where they do and provides nuanced insight into the relationship between word distributions and the <a href="https://en.wikipedia.org/wiki/Semantics">theoretical linguistic domains of syntax and semantics</a>.</abstract>
      <bibkey>finley-etal-2017-analogies</bibkey>
    </paper>
    <paper id="3">
      <title>Decoding Sentiment from Distributed Representations of Sentences</title>
      <author><first>Edoardo Maria</first> <last>Ponti</last></author>
      <author><first>Ivan</first> <last>Vulić</last></author>
      <author><first>Anna</first> <last>Korhonen</last></author>
      <pages>22–32</pages>
      <url hash="ad76958d">S17-1003</url>
      <doi>10.18653/v1/S17-1003</doi>
      <abstract>Distributed representations of sentences have been developed recently to represent their meaning as real-valued vectors. However, it is not clear how much information such <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representations</a> retain about the polarity of sentences. To study this question, we decode sentiment from <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised sentence representations</a> learned with different architectures (sensitive to the order of words, the order of sentences, or none) in 9 typologically diverse languages. Sentiment results from the (recursive) composition of lexical items and grammatical strategies such as <a href="https://en.wikipedia.org/wiki/Affirmation_and_negation">negation</a> and concession. The results are manifold : we show that there is no ‘one-size-fits-all’ representation architecture outperforming the others across the board. Rather, the top-ranking architectures depend on the language at hand. Moreover, we find that in several cases the additive composition model based on skip-gram word vectors may surpass supervised state-of-art architectures such as bi-directional LSTMs. Finally, we provide a possible explanation of the observed variation based on the type of negative constructions in each language.</abstract>
      <bibkey>ponti-etal-2017-decoding</bibkey>
    </paper>
    <paper id="4">
      <title>Detecting Asymmetric Semantic Relations in Context : A Case-Study on Hypernymy Detection</title>
      <author><first>Yogarshi</first> <last>Vyas</last></author>
      <author><first>Marine</first> <last>Carpuat</last></author>
      <pages>33–43</pages>
      <url hash="3287d135">S17-1004</url>
      <doi>10.18653/v1/S17-1004</doi>
      <abstract>We introduce WHiC, a challenging testbed for detecting hypernymy, an asymmetric relation between words. While previous work has focused on detecting hypernymy between word types, we ground the meaning of words in specific contexts drawn from WordNet examples, and require predictions to be sensitive to changes in contexts. WHiC lets us analyze complementary properties of two approaches of inducing vector representations of word meaning in context. We show that such contextualized word representations also improve detection of a wider range of semantic relations in context.</abstract>
      <bibkey>vyas-carpuat-2017-detecting</bibkey>
    </paper>
    <paper id="5">
      <title>Domain-Specific New Words Detection in Chinese<fixed-case>C</fixed-case>hinese</title>
      <author><first>Ao</first> <last>Chen</last></author>
      <author><first>Maosong</first> <last>Sun</last></author>
      <pages>44–53</pages>
      <url hash="ce22b078">S17-1005</url>
      <doi>10.18653/v1/S17-1005</doi>
      <abstract>With the explosive growth of <a href="https://en.wikipedia.org/wiki/Internet">Internet</a>, more and more domain-specific environments appear, such as <a href="https://en.wikipedia.org/wiki/Internet_forum">forums</a>, <a href="https://en.wikipedia.org/wiki/Blog">blogs</a>, <a href="https://en.wikipedia.org/wiki/Massive_open_online_course">MOOCs</a> and etc. Domain-specific words appear in these areas and always play a critical role in the domain-specific NLP tasks. This paper aims at extracting Chinese domain-specific new words automatically. The extraction of domain-specific new words has two parts including both new words in this domain and the especially important words. In this work, we propose a joint statistical model to perform these two works simultaneously. Compared to traditional new words detection models, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> does n’t need handcraft features which are labor intensive. Experimental results demonstrate that our joint model achieves a better performance compared with the <a href="https://en.wikipedia.org/wiki/State-of-the-art">state-of-the-art methods</a>.</abstract>
      <bibkey>chen-sun-2017-domain</bibkey>
      <pwccode url="https://github.com/dreamszl/dtopwords" additional="false">dreamszl/dtopwords</pwccode>
    </paper>
    <paper id="6">
      <title>Deep Learning Models For Multiword Expression Identification</title>
      <author><first>Waseem</first> <last>Gharbieh</last></author>
      <author><first>Virendrakumar</first> <last>Bhavsar</last></author>
      <author><first>Paul</first> <last>Cook</last></author>
      <pages>54–64</pages>
      <url hash="676391ca">S17-1006</url>
      <doi>10.18653/v1/S17-1006</doi>
      <abstract>Multiword expressions (MWEs) are lexical items that can be decomposed into multiple component words, but have properties that are unpredictable with respect to their component words. In this paper we propose the first <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> for token-level identification of MWEs. Specifically, we consider a layered feedforward network, a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a>, and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a>. In experimental results we show that <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> are able to outperform the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> for MWE identification, with a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> with three hidden layers giving the best performance.</abstract>
      <bibkey>gharbieh-etal-2017-deep</bibkey>
    </paper>
    <paper id="7">
      <title>Emotion Intensities in Tweets</title>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Felipe</first> <last>Bravo-Marquez</last></author>
      <pages>65–77</pages>
      <url hash="2b4c4649">S17-1007</url>
      <doi>10.18653/v1/S17-1007</doi>
      <abstract>This paper examines the task of detecting intensity of emotion from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>. We create the first datasets of <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> annotated for <a href="https://en.wikipedia.org/wiki/Anger">anger</a>, <a href="https://en.wikipedia.org/wiki/Fear">fear</a>, <a href="https://en.wikipedia.org/wiki/Joy">joy</a>, and sadness intensities. We use a technique called bestworst scaling (BWS) that improves annotation consistency and obtains reliable fine-grained scores. We show that emotion-word hashtags often impact emotion intensity, usually conveying a more intense emotion. Finally, we create a benchmark regression system and conduct experiments to determine : which <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> are useful for detecting emotion intensity ; and, the extent to which two emotions are similar in terms of how they manifest in language.</abstract>
      <bibkey>mohammad-bravo-marquez-2017-emotion</bibkey>
      <pwccode url="https://github.com/felipebravom/AffectiveTweets" additional="false">felipebravom/AffectiveTweets</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/11k-hands">11k Hands</pwcdataset>
    </paper>
    <paper id="8">
      <title>Deep Active Learning for Dialogue Generation</title>
      <author><first>Nabiha</first> <last>Asghar</last></author>
      <author><first>Pascal</first> <last>Poupart</last></author>
      <author><first>Xin</first> <last>Jiang</last></author>
      <author><first>Hang</first> <last>Li</last></author>
      <pages>78–83</pages>
      <url hash="6239638e">S17-1008</url>
      <doi>10.18653/v1/S17-1008</doi>
      <abstract>We propose an online, end-to-end, neural generative conversational model for open-domain dialogue. It is trained using a unique combination of offline two-phase supervised learning and online human-in-the-loop active learning. While most existing research proposes offline supervision or hand-crafted reward functions for online reinforcement, we devise a novel interactive learning mechanism based on hamming-diverse beam search for response generation and one-character user-feedback at each step. Experiments show that our model inherently promotes the generation of semantically relevant and interesting responses, and can be used to train <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> with customized personas, <a href="https://en.wikipedia.org/wiki/Mood_(psychology)">moods</a> and conversational styles.</abstract>
      <bibkey>asghar-etal-2017-deep</bibkey>
    </paper>
    <paper id="9">
      <title>Mapping the Paraphrase Database to <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Anne</first> <last>Cocos</last></author>
      <author><first>Marianna</first> <last>Apidianaki</last></author>
      <author><first>Chris</first> <last>Callison-Burch</last></author>
      <pages>84–90</pages>
      <url hash="b06e0349">S17-1009</url>
      <doi>10.18653/v1/S17-1009</doi>
      <abstract>WordNet has facilitated important research in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> but its usefulness is somewhat limited by its relatively small lexical coverage. The Paraphrase Database (PPDB) covers 650 times more words, but lacks the semantic structure of <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> that would make it more directly useful for downstream tasks. We present a method for mapping words from PPDB to WordNet synsets with 89 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. The mapping also lays important groundwork for incorporating WordNet’s relations into PPDB so as to increase its utility for semantic reasoning in applications.</abstract>
      <bibkey>cocos-etal-2017-mapping</bibkey>
    </paper>
    <paper id="10">
      <title>Semantic Frame Labeling with Target-based Neural Model</title>
      <author><first>Yukun</first> <last>Feng</last></author>
      <author><first>Dong</first> <last>Yu</last></author>
      <author><first>Jian</first> <last>Xu</last></author>
      <author><first>Chunhua</first> <last>Liu</last></author>
      <pages>91–96</pages>
      <url hash="c6e175d3">S17-1010</url>
      <doi>10.18653/v1/S17-1010</doi>
      <abstract>This paper explores the automatic learning of <a href="https://en.wikipedia.org/wiki/Distributed_representation">distributed representations</a> of the target’s context for semantic frame labeling with target-based neural model. We constrain the whole sentence as the <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>’s input without <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction</a> from the sentence. This is different from many previous works in which local feature extraction of the targets is widely used. This constraint makes the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> harder, especially with long sentences, but also makes our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> easily applicable to a range of resources and other similar tasks. We evaluate our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on several resources and get the state-of-the-art result on subtask 2 of SemEval 2015 task 15. Finally, we extend the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> to word-sense disambiguation task and we also achieve a strong result in comparison to state-of-the-art work.</abstract>
      <bibkey>feng-etal-2017-semantic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="11">
      <title>Frame-Based Continuous Lexical Semantics through Exponential Family Tensor Factorization and Semantic Proto-Roles</title>
      <author><first>Francis</first> <last>Ferraro</last></author>
      <author><first>Adam</first> <last>Poliak</last></author>
      <author><first>Ryan</first> <last>Cotterell</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>97–103</pages>
      <url hash="38d313ae">S17-1011</url>
      <doi>10.18653/v1/S17-1011</doi>
      <abstract>We study how different frame annotations complement one another when learning continuous lexical semantics. We learn the representations from a tensorized skip-gram model that consistently encodes syntactic-semantic content better, with multiple 10 % gains over baselines.</abstract>
      <bibkey>ferraro-etal-2017-frame</bibkey>
      <pwccode url="https://github.com/fmof/tensor-factorization" additional="false">fmof/tensor-factorization</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="13">
      <title>Comparing Approaches for Automatic Question Identification</title>
      <author><first>Angel</first> <last>Maredia</last></author>
      <author><first>Kara</first> <last>Schechtman</last></author>
      <author><first>Sarah Ita</first> <last>Levitan</last></author>
      <author><first>Julia</first> <last>Hirschberg</last></author>
      <pages>110–114</pages>
      <url hash="69cccfb3">S17-1013</url>
      <doi>10.18653/v1/S17-1013</doi>
      <abstract>Collecting spontaneous speech corpora that are open-ended, yet topically constrained, is increasingly popular for research in spoken dialogue systems and speaker state, inter alia. Typically, these <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> are labeled by human annotators, either in the lab or through <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourcing</a> ; however, this is cumbersome and time-consuming for large corpora. We present four different approaches to automatically tagging a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> when general topics of the conversations are known. We develop these approaches on the Columbia X-Cultural Deception corpus and find <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> that significantly exceeds the <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a>. Finally, we conduct a cross-corpus evaluation by testing the best performing approach on the Columbia / SRI / Colorado corpus.</abstract>
      <bibkey>maredia-etal-2017-comparing</bibkey>
    </paper>
    <paper id="14">
      <title>Does Free Word Order Hurt? Assessing the Practical Lexical Function Model for Croatian<fixed-case>C</fixed-case>roatian</title>
      <author><first>Zoran</first> <last>Medić</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <author><first>Sebastian</first> <last>Padó</last></author>
      <pages>115–120</pages>
      <url hash="3e24b3e2">S17-1014</url>
      <attachment type="poster" hash="b783686a">S17-1014.Poster.pdf</attachment>
      <doi>10.18653/v1/S17-1014</doi>
      <abstract>The Practical Lexical Function (PLF) model is a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> of computational distributional semantics that attempts to strike a balance between expressivity and learnability in predicting phrase meaning and shows competitive results. We investigate how well the PLF carries over to free word order languages, given that it builds on observations of predicate-argument combinations that are harder to recover in free word order languages. We evaluate variants of the PLF for <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian</a>, using a new lexical substitution dataset. We find that the PLF works about as well for <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian</a> as for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, but demonstrate that its strength lies in modeling verbs, and that the free word order affects the less robust PLF variant.</abstract>
      <bibkey>medic-etal-2017-free</bibkey>
    </paper>
    <paper id="15">
      <title>A <a href="https://en.wikipedia.org/wiki/Mixture_model">Mixture Model</a> for Learning Multi-Sense Word Embeddings</title>
      <author><first>Dai Quoc</first> <last>Nguyen</last></author>
      <author><first>Dat Quoc</first> <last>Nguyen</last></author>
      <author><first>Ashutosh</first> <last>Modi</last></author>
      <author><first>Stefan</first> <last>Thater</last></author>
      <author><first>Manfred</first> <last>Pinkal</last></author>
      <pages>121–127</pages>
      <url hash="d1d01cc5">S17-1015</url>
      <doi>10.18653/v1/S17-1015</doi>
      <abstract>Word embeddings are now a standard technique for inducing <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">meaning representations</a> for words. For getting good <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representations</a>, it is important to take into account different senses of a word. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Mixture_model">mixture model</a> for learning multi-sense word embeddings. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> generalizes the previous works in that it allows to induce different weights of different senses of a word. The experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms previous <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on standard evaluation tasks.</abstract>
      <bibkey>nguyen-etal-2017-mixture</bibkey>
    </paper>
    <paper id="18">
      <title>Semantic Frames and Visual Scenes : Learning Semantic Role Inventories from Image and Video Descriptions</title>
      <author><first>Ekaterina</first> <last>Shutova</last></author>
      <author><first>Andreas</first> <last>Wundsam</last></author>
      <author><first>Helen</first> <last>Yannakoudakis</last></author>
      <pages>149–154</pages>
      <url hash="bba9a09e">S17-1018</url>
      <doi>10.18653/v1/S17-1018</doi>
      <abstract>Frame-semantic parsing and semantic role labelling, that aim to automatically assign semantic roles to arguments of verbs in a sentence, have become an active strand of research in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. However, to date these methods have relied on a predefined inventory of semantic roles. In this paper, we present a method to automatically learn argument role inventories for verbs from large corpora of text, images and videos. We evaluate the method against manually constructed role inventories in <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a> and show that the <a href="https://en.wikipedia.org/wiki/Visual_model">visual model</a> outperforms the language-only model and operates with a high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>.</abstract>
      <bibkey>shutova-etal-2017-semantic</bibkey>
    </paper>
    <paper id="19">
      <title>Acquiring Predicate Paraphrases from News Tweets</title>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <author><first>Gabriel</first> <last>Stanovsky</last></author>
      <author><first>Ido</first> <last>Dagan</last></author>
      <pages>155–160</pages>
      <url hash="9bbfa26b">S17-1019</url>
      <doi>10.18653/v1/S17-1019</doi>
      <abstract>We present a simple method for ever-growing extraction of predicate paraphrases from <a href="https://en.wikipedia.org/wiki/Headline">news headlines</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. Analysis of the output of ten weeks of collection shows that the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> with different support levels is estimated between 60-86 %. We also demonstrate that our <a href="https://en.wikipedia.org/wiki/Resource">resource</a> is to a large extent complementary to existing resources, providing many novel <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a>. Our <a href="https://en.wikipedia.org/wiki/Resource">resource</a> is publicly available, continuously expanding based on <a href="https://en.wikipedia.org/wiki/News">daily news</a>.</abstract>
      <bibkey>shwartz-etal-2017-acquiring</bibkey>
    </paper>
    <paper id="20">
      <title>Evaluating <a href="https://en.wikipedia.org/wiki/Semantic_parsing">Semantic Parsing</a> against a Simple Web-based Question Answering Model</title>
      <author><first>Alon</first> <last>Talmor</last></author>
      <author><first>Mor</first> <last>Geva</last></author>
      <author><first>Jonathan</first> <last>Berant</last></author>
      <pages>161–167</pages>
      <url hash="68f0bc9f">S17-1020</url>
      <doi>10.18653/v1/S17-1020</doi>
      <abstract>Semantic parsing shines at analyzing complex natural language that involves <a href="https://en.wikipedia.org/wiki/Composition_(language)">composition</a> and computation over multiple pieces of evidence. However, <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> contain many factoid questions that can be answered from a single <a href="https://en.wikipedia.org/wiki/Web_page">web document</a>. In this paper, we propose to evaluate semantic parsing-based question answering models by comparing them to a question answering baseline that queries the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a> and extracts the answer only from <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web snippets</a>, without access to the target knowledge-base. We investigate this approach on COMPLEXQUESTIONS, a dataset designed to focus on compositional language, and find that our model obtains reasonable performance (35 F1 compared to 41 F1 of state-of-the-art). We find in our analysis that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs well on complex questions involving <a href="https://en.wikipedia.org/wiki/Logical_conjunction">conjunctions</a>, but struggles on questions that involve relation composition and <a href="https://en.wikipedia.org/wiki/Superlative">superlatives</a>.</abstract>
      <bibkey>talmor-etal-2017-evaluating</bibkey>
      <pwccode url="https://worksheets.codalab.org/worksheets/0x91d77db37e0a4bbbaeb37b8972f4784f" additional="false">worksheets/0x91d77db3</pwccode>
    </paper>
    <paper id="21">
      <title>Logical Metonymy in a Distributional Model of Sentence Comprehension</title>
      <author><first>Emmanuele</first> <last>Chersoni</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <author><first>Philippe</first> <last>Blache</last></author>
      <pages>168–177</pages>
      <url hash="51648445">S17-1021</url>
      <doi>10.18653/v1/S17-1021</doi>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Theoretical_linguistics">theoretical linguistics</a>, logical metonymy is defined as the combination of an event-subcategorizing verb with an <a href="https://en.wikipedia.org/wiki/Object_(grammar)">entity-denoting direct object</a> (e.g., The author began the book), so that the interpretation of the VP requires the retrieval of a covert event (e.g., writing). Psycholinguistic studies have revealed extra processing costs for logical metonymy, a phenomenon generally explained with the introduction of new semantic structure. In this paper, we present a general <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional model</a> for <a href="https://en.wikipedia.org/wiki/Sentence_processing">sentence comprehension</a> inspired by the Memory, Unification and Control model by Hagoort (2013,2016). We show that our distributional framework can account for the extra processing costs of logical metonymy and can identify the covert event in a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification task</a>.</abstract>
      <bibkey>chersoni-etal-2017-logical</bibkey>
    </paper>
    <paper id="22">
      <title>Double Trouble : The Problem of Construal in Semantic Annotation of Adpositions</title>
      <author><first>Jena D.</first> <last>Hwang</last></author>
      <author><first>Archna</first> <last>Bhatia</last></author>
      <author><first>Na-Rae</first> <last>Han</last></author>
      <author><first>Tim</first> <last>O’Gorman</last></author>
      <author><first>Vivek</first> <last>Srikumar</last></author>
      <author><first>Nathan</first> <last>Schneider</last></author>
      <pages>178–188</pages>
      <url hash="0a323287">S17-1022</url>
      <attachment type="presentation" hash="1c9c87d0">S17-1022.Presentation.pdf</attachment>
      <doi>10.18653/v1/S17-1022</doi>
      <abstract>We consider the semantics of prepositions, revisiting a broad-coverage <a href="https://en.wikipedia.org/wiki/Annotation">annotation scheme</a> used for annotating all 4,250 <a href="https://en.wikipedia.org/wiki/Preposition_and_postposition">preposition tokens</a> in a 55,000 word corpus of English. Attempts to apply the scheme to adpositions and <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">case markers</a> in other languages, as well as some problematic cases in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, have led us to reconsider the assumption that an adposition’s lexical contribution is equivalent to the role / relation that it mediates. Our proposal is to embrace the potential for construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation. We suggest a framework to represent both the scene role and the adposition’s lexical function so they can be annotated at scalesupporting automatic, statistical processing of domain-general languageand discuss how this representation would allow for a simpler inventory of labels.</abstract>
      <bibkey>hwang-etal-2017-double</bibkey>
    </paper>
    <paper id="23">
      <title>Issues of Mass and Count : Dealing with ‘Dual-Life’ Nouns</title>
      <author><first>Tibor</first> <last>Kiss</last></author>
      <author><first>Francis Jeffry</first> <last>Pelletier</last></author>
      <author><first>Halima</first> <last>Husić</last></author>
      <author><first>Johanna</first> <last>Poppek</last></author>
      <pages>189–198</pages>
      <url hash="ef9f354b">S17-1023</url>
      <doi>10.18653/v1/S17-1023</doi>
      <abstract>The topics of mass and count have been studied for many decades in <a href="https://en.wikipedia.org/wiki/Philosophy">philosophy</a> (e.g., Quine, 1960 ; Pelletier, 1975), <a href="https://en.wikipedia.org/wiki/Linguistics">linguistics</a> (e.g., McCawley, 1975 ; Allen, 1980 ; Krifka, 1991) and <a href="https://en.wikipedia.org/wiki/Psychology">psychology</a> (e.g., Middleton et al, 2004 ; Barner et al, 2009). More recently, interest from within <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> has studied the issues involved (e.g., Pustejovsky, 1991 ; Bond, 2005 ; Schmidtke &amp; Kuperman, 2016), to name just a few. As is pointed out in these works, there are many difficult conceptual issues involved in the study of this contrast. In this article we study one of these issues   the Dual-Life of being simultaneously + mass and + count   by means of an unusual combination of human annotation, online lexical resources, and online corpora.</abstract>
      <bibkey>kiss-etal-2017-issues</bibkey>
    </paper>
    <paper id="24">
      <title>Parsing Graphs with Regular Graph Grammars</title>
      <author><first>Sorcha</first> <last>Gilroy</last></author>
      <author><first>Adam</first> <last>Lopez</last></author>
      <author><first>Sebastian</first> <last>Maneth</last></author>
      <pages>199–208</pages>
      <url hash="ed1afd48">S17-1024</url>
      <doi>10.18653/v1/S17-1024</doi>
      <abstract>Recently, several <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> have become available which represent <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language phenomena</a> as <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a>. Hyperedge Replacement Languages (HRL) have been the focus of much attention as a formalism to represent the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> in these datasets. Chiang et al. (2013) prove that HRL graphs can be parsed in <a href="https://en.wikipedia.org/wiki/Time_complexity">polynomial time</a> with respect to the size of the input graph. We believe that HRL are more expressive than is necessary to represent semantic graphs and we propose the use of Regular Graph Languages (RGL ; Courcelle 1991), which is a subfamily of HRL, as a possible alternative. We provide a top-down parsing algorithm for RGL that runs in time linear in the size of the input graph.</abstract>
      <bibkey>gilroy-etal-2017-parsing</bibkey>
    </paper>
    <paper id="25">
      <title>Embedded Semantic Lexicon Induction with Joint Global and Local Optimization</title>
      <author><first>Sujay Kumar</first> <last>Jauhar</last></author>
      <author><first>Eduard</first> <last>Hovy</last></author>
      <pages>209–219</pages>
      <url hash="b4cf09bc">S17-1025</url>
      <doi>10.18653/v1/S17-1025</doi>
      <abstract>Creating annotated frame lexicons such as <a href="https://en.wikipedia.org/wiki/PropBank">PropBank</a> and <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a> is expensive and labor intensive. We present a method to induce an embedded frame lexicon in an minimally supervised fashion using nothing more than unlabeled predicate-argument word pairs. We hypothesize that aggregating such pair selectional preferences across training leads us to a global understanding that captures predicate-argument frame structure. Our approach revolves around a novel integration between a predictive embedding model and an Indian Buffet Process posterior regularizer. We show, through our experimental evaluation, that we outperform baselines on two tasks and can learn an embedded frame lexicon that is able to capture some interesting generalities in relation to hand-crafted semantic frames.</abstract>
      <bibkey>jauhar-hovy-2017-embedded</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="26">
      <title>Generating Pattern-Based Entailment Graphs for Relation Extraction</title>
      <author><first>Kathrin</first> <last>Eichler</last></author>
      <author><first>Feiyu</first> <last>Xu</last></author>
      <author><first>Hans</first> <last>Uszkoreit</last></author>
      <author><first>Sebastian</first> <last>Krause</last></author>
      <pages>220–229</pages>
      <url hash="8ac3b938">S17-1026</url>
      <doi>10.18653/v1/S17-1026</doi>
      <abstract>Relation extraction is the task of recognizing and extracting relations between entities or concepts in texts. A common approach is to exploit existing knowledge to learn linguistic patterns expressing the target relation and use these <a href="https://en.wikipedia.org/wiki/Pattern">patterns</a> for extracting new relation mentions. Deriving relation patterns automatically usually results in large numbers of candidates, which need to be filtered to derive a subset of <a href="https://en.wikipedia.org/wiki/Pattern_matching">patterns</a> that reliably extract correct relation mentions. We address the pattern selection task by exploiting the knowledge represented by entailment graphs, which capture semantic relationships holding among the learned pattern candidates. This is motivated by the fact that a <a href="https://en.wikipedia.org/wiki/Pattern_matching">pattern</a> may not express the target relation explicitly, but still be useful for extracting instances for which the relation holds, because its meaning entails the meaning of the target relation. We evaluate the usage of both automatically generated and gold-standard entailment graphs in a relation extraction scenario and present favorable experimental results, exhibiting the benefits of structuring and selecting patterns based on entailment graphs.</abstract>
      <bibkey>eichler-etal-2017-generating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
    </paper>
    <paper id="27">
      <title>Classifying Semantic Clause Types : Modeling Context and Genre Characteristics with Recurrent Neural Networks and Attention</title>
      <author><first>Maria</first> <last>Becker</last></author>
      <author><first>Michael</first> <last>Staniek</last></author>
      <author><first>Vivi</first> <last>Nastase</last></author>
      <author><first>Alexis</first> <last>Palmer</last></author>
      <author><first>Anette</first> <last>Frank</last></author>
      <pages>230–240</pages>
      <url hash="80b2ee00">S17-1027</url>
      <doi>10.18653/v1/S17-1027</doi>
      <abstract>Detecting aspectual properties of clauses in the form of situation entity types has been shown to depend on a combination of syntactic-semantic and contextual features. We explore this task in a deep-learning framework, where tuned word representations capture lexical, syntactic and semantic features. We introduce an attention mechanism that pinpoints relevant context not only for the current instance, but also for the larger context. Apart from implicitly capturing task relevant features, the advantage of our neural model is that it avoids the need to reproduce linguistic features for other languages and is thus more easily transferable. We present experiments for <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/German_language">German</a> that achieve competitive performance. We present a novel take on modeling and exploiting genre information and showcase the adaptation of our <a href="https://en.wikipedia.org/wiki/System">system</a> from one language to another.</abstract>
      <bibkey>becker-etal-2017-classifying</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="30">
      <title>Ways of Asking and Replying in Duplicate Question Detection</title>
      <author><first>João</first> <last>António Rodrigues</last></author>
      <author><first>Chakaveh</first> <last>Saedi</last></author>
      <author><first>Vladislav</first> <last>Maraev</last></author>
      <author><first>João</first> <last>Silva</last></author>
      <author><first>António</first> <last>Branco</last></author>
      <pages>262–270</pages>
      <url hash="ff31f4dd">S17-1030</url>
      <doi>10.18653/v1/S17-1030</doi>
      <abstract>This paper presents the results of systematic experimentation on the impact in duplicate question detection of different types of questions across both a number of established approaches and a novel, superior one used to address this language processing task. This study permits to gain a novel insight on the different levels of <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> of the diverse detection methods with respect to different conditions of their application, including the ones that approximate real usage scenarios.</abstract>
      <bibkey>antonio-rodrigues-etal-2017-ways</bibkey>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 11th International Workshop on Semantic Evaluation (<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017)</booktitle>
      <url hash="d37f2cbc">S17-2</url>
      <editor><first>Steven</first><last>Bethard</last></editor>
      <editor><first>Marine</first><last>Carpuat</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Saif M.</first><last>Mohammad</last></editor>
      <editor><first>Daniel</first><last>Cer</last></editor>
      <editor><first>David</first><last>Jurgens</last></editor>
      <doi>10.18653/v1/S17-2</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vancouver, Canada</address>
      <month>August</month>
      <year>2017</year>
    </meta>
    <frontmatter>
      <url hash="d7122f80">S17-2000</url>
      <bibkey>semeval-2017-international</bibkey>
    </frontmatter>
    <paper id="2">
      <title>SemEval-2017 Task 2 : Multilingual and Cross-lingual Semantic Word Similarity<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Multilingual and Cross-lingual Semantic Word Similarity</title>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Mohammad Taher</first> <last>Pilehvar</last></author>
      <author><first>Nigel</first> <last>Collier</last></author>
      <author><first>Roberto</first> <last>Navigli</last></author>
      <pages>15–26</pages>
      <url hash="ae94a5fa">S17-2002</url>
      <doi>10.18653/v1/S17-2002</doi>
      <abstract>This paper introduces a new task on Multilingual and Cross-lingual SemanticThis paper introduces a new task on Multilingual and Cross-lingual Semantic Word Similarity which measures the semantic similarity of word pairs within and across five languages : <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Persian_language">Farsi</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a> and <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>. High quality datasets were manually curated for the five languages with high <a href="https://en.wikipedia.org/wiki/Inter-annotator_agreement">inter-annotator agreements</a> (consistently in the 0.9 ballpark). These were used for semi-automatic construction of ten cross-lingual datasets. 17 teams participated in the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, submitting 24 systems in subtask 1 and 14 systems in subtask 2. Results show that systems that combine statistical knowledge from <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpora</a>, in the form of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, and external knowledge from lexical resources are best performers in both subtasks. More information can be found on the task website :<url>http://alt.qcri.org/semeval2017/task2/</url>
      </abstract>
      <bibkey>camacho-collados-etal-2017-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="3">
      <title>SemEval-2017 Task 3 : Community Question Answering<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Community Question Answering</title>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <author><first>Doris</first> <last>Hoogeveen</last></author>
      <author><first>Lluís</first> <last>Màrquez</last></author>
      <author><first>Alessandro</first> <last>Moschitti</last></author>
      <author><first>Hamdy</first> <last>Mubarak</last></author>
      <author><first>Timothy</first> <last>Baldwin</last></author>
      <author><first>Karin</first> <last>Verspoor</last></author>
      <pages>27–48</pages>
      <url hash="e72e2e5e">S17-2003</url>
      <doi>10.18653/v1/S17-2003</doi>
      <abstract>We describe SemEval2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016 : (A) QuestionComment Similarity, (B) QuestionQuestion Similarity, (C) QuestionExternal Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added a new subtask E in order to enable experimentation with Multi-domain Question Duplicate Detection in a larger-scale scenario, using StackExchange subforums. A total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks AD. Unfortunately, no teams participated in subtask E. A variety of <a href="https://en.wikipedia.org/wiki/Software_development_process">approaches</a> and <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> were used by the participating <a href="https://en.wikipedia.org/wiki/System">systems</a> to address the different subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively. These scores are better than the <a href="https://en.wikipedia.org/wiki/Baseline_(surveying)">baselines</a>, especially for subtasks AC.</abstract>
      <bibkey>nakov-etal-2017-semeval</bibkey>
      <pwccode url="https://github.com/tbmihailov/semeval2016-task3-CQA" additional="false">tbmihailov/semeval2016-task3-CQA</pwccode>
    </paper>
    <paper id="4">
      <title>SemEval-2017 Task 6 : # HashtagWars : Learning a Sense of Humor<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: #<fixed-case>H</fixed-case>ashtag<fixed-case>W</fixed-case>ars: Learning a Sense of Humor</title>
      <author><first>Peter</first> <last>Potash</last></author>
      <author><first>Alexey</first> <last>Romanov</last></author>
      <author><first>Anna</first> <last>Rumshisky</last></author>
      <pages>49–57</pages>
      <url hash="b6a83323">S17-2004</url>
      <doi>10.18653/v1/S17-2004</doi>
      <abstract>This paper describes a new shared task for humor understanding that attempts to eschew the ubiquitous binary approach to humor detection and focus on comparative humor ranking instead. The task is based on a new dataset of funny tweets posted in response to shared hashtags, collected from the ‘Hashtag Wars’ segment of the TV show @midnight. The results are evaluated in two subtasks that require the participants to generate either the correct pairwise comparisons of tweets (subtask A), or the correct ranking of the tweets (subtask B) in terms of how funny they are. 7 teams participated in subtask A, and 5 teams participated in subtask B. The best <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> in subtask A was 0.675. The best (lowest) rank edit distance for subtask B was 0.872.</abstract>
      <bibkey>potash-etal-2017-semeval</bibkey>
    </paper>
    <paper id="5">
      <title>SemEval-2017 Task 7 : Detection and Interpretation of English Puns<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Detection and Interpretation of <fixed-case>E</fixed-case>nglish Puns</title>
      <author><first>Tristan</first> <last>Miller</last></author>
      <author><first>Christian</first> <last>Hempelmann</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>58–68</pages>
      <url hash="0f60999a">S17-2005</url>
      <doi>10.18653/v1/S17-2005</doi>
      <abstract>A pun is a form of <a href="https://en.wikipedia.org/wiki/Word_play">wordplay</a> in which a word suggests two or more meanings by exploiting <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a>, <a href="https://en.wikipedia.org/wiki/Homonym">homonymy</a>, or phonological similarity to another word, for an intended humorous or rhetorical effect. Though a recurrent and expected feature in many discourse types, puns stymie traditional approaches to computational lexical semantics because they violate their one-sense-per-context assumption. This paper describes the first competitive evaluation for the automatic detection, location, and interpretation of puns. We describe the motivation for these <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, the evaluation methods, and the manually annotated data set. Finally, we present an overview and discussion of the participating <a href="https://en.wikipedia.org/wiki/System">systems</a>’ methodologies, resources, and results.</abstract>
      <bibkey>miller-etal-2017-semeval</bibkey>
    </paper>
    <paper id="6">
      <title>SemEval-2017 Task 8 : RumourEval : Determining rumour veracity and support for rumours<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: <fixed-case>R</fixed-case>umour<fixed-case>E</fixed-case>val: Determining rumour veracity and support for rumours</title>
      <author><first>Leon</first> <last>Derczynski</last></author>
      <author><first>Kalina</first> <last>Bontcheva</last></author>
      <author><first>Maria</first> <last>Liakata</last></author>
      <author><first>Rob</first> <last>Procter</last></author>
      <author><first>Geraldine</first> <last>Wong Sak Hoi</last></author>
      <author><first>Arkaitz</first> <last>Zubiaga</last></author>
      <pages>69–76</pages>
      <url hash="594c0236">S17-2006</url>
      <doi>10.18653/v1/S17-2006</doi>
      <abstract>Media is full of false claims. Even <a href="https://en.wikipedia.org/wiki/Oxford_Dictionaries">Oxford Dictionaries</a> named <a href="https://en.wikipedia.org/wiki/Post-truth">post-truth</a> as the word of 2016. This makes it more important than ever to build systems that can identify the veracity of a story, and the nature of the discourse around it. RumourEval is a SemEval shared task that aims to identify and handle <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a> and reactions to them, in text. We present an annotation scheme, a large dataset covering multiple topics   each having their own families of claims and replies   and use these to pose two concrete challenges as well as the results achieved by participants on these challenges.</abstract>
      <bibkey>derczynski-etal-2017-semeval</bibkey>
    </paper>
    <paper id="7">
      <title>BIT at SemEval-2017 Task 1 : Using Semantic Information Space to Evaluate Semantic Textual Similarity<fixed-case>BIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Using Semantic Information Space to Evaluate Semantic Textual Similarity</title>
      <author><first>Hao</first> <last>Wu</last></author>
      <author><first>Heyan</first> <last>Huang</last></author>
      <author><first>Ping</first> <last>Jian</last></author>
      <author><first>Yuhang</first> <last>Guo</last></author>
      <author><first>Chao</first> <last>Su</last></author>
      <pages>77–84</pages>
      <url hash="7e86d41a">S17-2007</url>
      <doi>10.18653/v1/S17-2007</doi>
      <abstract>This paper presents three systems for semantic textual similarity (STS) evaluation at SemEval-2017 STS task. One is an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised system</a> and the other two are <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised systems</a> which simply employ the unsupervised one. All our systems mainly depend on the (SIS), which is constructed based on the semantic hierarchical taxonomy in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>, to compute non-overlapping information content (IC) of sentences. Our team ranked 2nd among 31 participating teams by the primary score of Pearson correlation coefficient (PCC) mean of 7 tracks and achieved the best performance on Track 1 (AR-AR) dataset.</abstract>
      <bibkey>wu-etal-2017-bit</bibkey>
    </paper>
    <paper id="8">
      <title>ConceptNet at SemEval-2017 Task 2 : Extending Word Embeddings with Multilingual Relational Knowledge<fixed-case>C</fixed-case>oncept<fixed-case>N</fixed-case>et at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Extending Word Embeddings with Multilingual Relational Knowledge</title>
      <author><first>Robyn</first> <last>Speer</last></author>
      <author><first>Joanna</first> <last>Lowry-Duda</last></author>
      <pages>85–89</pages>
      <url hash="e22cb6c7">S17-2008</url>
      <doi>10.18653/v1/S17-2008</doi>
      <revision id="1" href="S17-2008v1" hash="cded96af" />
      <revision id="2" href="S17-2008v2" hash="e22cb6c7">No description of the changes were recorded.</revision>
      <abstract>This paper describes Luminoso’s participation in SemEval 2017 Task 2, Multilingual and Cross-lingual Semantic Word Similarity, with a system based on <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>. ConceptNet is an open, multilingual knowledge graph that focuses on general knowledge that relates the meanings of words and phrases. Our submission to <a href="https://en.wikipedia.org/wiki/SemEval">SemEval</a> was an update of previous work that builds high-quality, multilingual word embeddings from a combination of <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a> and <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> took first place in both subtasks. It ranked first in 4 out of 5 of the separate languages, and also ranked first in all 10 of the cross-lingual language pairs.</abstract>
      <bibkey>speer-lowry-duda-2017-conceptnet</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    </paper>
    <paper id="9">
      <title>IIT-UHH at SemEval-2017 Task 3 : Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification<fixed-case>IIT</fixed-case>-<fixed-case>UHH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Exploring Multiple Features for Community Question Answering and Implicit Dialogue Identification</title>
      <author><first>Titas</first> <last>Nandi</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <author><first>Seid Muhie</first> <last>Yimam</last></author>
      <author><first>Deepak</first> <last>Gupta</last></author>
      <author><first>Sarah</first> <last>Kohail</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>90–97</pages>
      <url hash="e5637e75">S17-2009</url>
      <doi>10.18653/v1/S17-2009</doi>
      <abstract>In this paper we present the system for Answer Selection and Ranking in Community Question Answering, which we build as part of our participation in SemEval-2017 Task 3. We develop a Support Vector Machine (SVM) based system that makes use of textual, domain-specific, word-embedding and topic-modeling features. In addition, we propose a novel <a href="https://en.wikipedia.org/wiki/Methodology">method</a> for dialogue chain identification in <a href="https://en.wikipedia.org/wiki/Internet_forum">comment threads</a>. Our primary submission won subtask C, outperforming other systems in all the primary evaluation metrics. We performed well in other English subtasks, ranking third in subtask A and eighth in subtask B. We also developed open source toolkits for all the three English subtasks by the name cQARank [ ].<url>https://github.com/TitasNandi/cQARank</url>].
    </abstract>
      <bibkey>nandi-etal-2017-iit</bibkey>
      <pwccode url="https://github.com/TitasNandi/cQARank" additional="false">TitasNandi/cQARank</pwccode>
    </paper>
    <paper id="10">
      <title>HumorHawk at SemEval-2017 Task 6 : Mixing Meaning and Sound for Humor Recognition<fixed-case>H</fixed-case>umor<fixed-case>H</fixed-case>awk at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: Mixing Meaning and Sound for Humor Recognition</title>
      <author><first>David</first> <last>Donahue</last></author>
      <author><first>Alexey</first> <last>Romanov</last></author>
      <author><first>Anna</first> <last>Rumshisky</last></author>
      <pages>98–102</pages>
      <url hash="361d0c3f">S17-2010</url>
      <doi>10.18653/v1/S17-2010</doi>
      <abstract>This paper describes the winning system for SemEval-2017 Task 6 : # HashtagWars : Learning a Sense of Humor. Humor detection has up until now been predominantly addressed using feature-based approaches. Our system utilizes recurrent deep learning methods with dense embeddings to predict humorous tweets from the @midnight show # HashtagWars. In order to include both meaning and sound in the analysis, GloVe embeddings are combined with a novel <a href="https://en.wikipedia.org/wiki/Phonetic_transcription">phonetic representation</a> to serve as input to an LSTM component. The output is combined with a character-based CNN model, and an XGBoost component in an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble model</a> which achieves 0.675 <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on the evaluation data.</abstract>
      <bibkey>donahue-etal-2017-humorhawk</bibkey>
    </paper>
    <paper id="11">
      <title>Idiom Savant at Semeval-2017 Task 7 : Detection and Interpretation of English Puns<fixed-case>S</fixed-case>emeval-2017 Task 7: Detection and Interpretation of <fixed-case>E</fixed-case>nglish Puns</title>
      <author><first>Samuel</first> <last>Doogan</last></author>
      <author><first>Aniruddha</first> <last>Ghosh</last></author>
      <author><first>Hanyang</first> <last>Chen</last></author>
      <author><first>Tony</first> <last>Veale</last></author>
      <pages>103–108</pages>
      <url hash="c9c96f67">S17-2011</url>
      <doi>10.18653/v1/S17-2011</doi>
      <abstract>This paper describes our system, entitled Idiom Savant, for the 7th Task of the Semeval 2017 workshop, Detection and interpretation of English Puns. Our system consists of two <a href="https://en.wikipedia.org/wiki/Statistical_model">probabilistic models</a> for each type of puns using Google n-gram and Word2Vec. Our system achieved <a href="https://en.wikipedia.org/wiki/F-number">f-score</a> of calculating, 0.663, and 0.07 in homographic puns and 0.8439, 0.6631, and 0.0806 in heterographic puns in task 1, task 2, and task 3 respectively.</abstract>
      <bibkey>doogan-etal-2017-idiom</bibkey>
    </paper>
    <paper id="12">
      <title>CompiLIG at SemEval-2017 Task 1 : Cross-Language Plagiarism Detection Methods for <a href="https://en.wikipedia.org/wiki/Semantic_similarity">Semantic Textual Similarity</a><fixed-case>C</fixed-case>ompi<fixed-case>LIG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Cross-Language Plagiarism Detection Methods for Semantic Textual Similarity</title>
      <author><first>Jérémy</first> <last>Ferrero</last></author>
      <author><first>Laurent</first> <last>Besacier</last></author>
      <author><first>Didier</first> <last>Schwab</last></author>
      <author><first>Frédéric</first> <last>Agnès</last></author>
      <pages>109–114</pages>
      <url hash="daf686f9">S17-2012</url>
      <attachment type="poster" hash="cc63aa82">S17-2012.Poster.pdf</attachment>
      <doi>10.18653/v1/S17-2012</doi>
      <abstract>We present our submitted <a href="https://en.wikipedia.org/wiki/System">systems</a> for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each <a href="https://en.wikipedia.org/wiki/System">system</a> must estimate their <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02 % with human annotations.</abstract>
      <bibkey>ferrero-etal-2017-compilig</bibkey>
    </paper>
    <paper id="16">
      <title>HCTI at SemEval-2017 Task 1 : Use <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> to evaluate Semantic Textual Similarity<fixed-case>HCTI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Use convolutional neural network to evaluate Semantic Textual Similarity</title>
      <author><first>Yang</first> <last>Shao</last></author>
      <pages>130–133</pages>
      <url hash="4be91351">S17-2016</url>
      <doi>10.18653/v1/S17-2016</doi>
      <abstract>This paper describes our convolutional neural network (CNN) system for Semantic Textual Similarity (STS) task. We calculated semantic similarity score between two sentences by comparing their semantic vectors. We generated semantic vector of every sentence by max pooling every dimension of their word vectors. There are mainly two trick points in our <a href="https://en.wikipedia.org/wiki/System">system</a>. One is that we trained a CNN to transfer GloVe word vectors to a more proper form for STS task before pooling. Another is that we trained a fully-connected neural network (FCNN) to transfer difference of two semantic vectors to probability of every similarity score. We decided all hyper parameters empirically. In spite of the simplicity of our neural network system, we achieved a good <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and ranked 3rd in primary track of SemEval 2017.</abstract>
      <bibkey>shao-2017-hcti</bibkey>
    </paper>
    <paper id="17">
      <title>LIM-LIG at SemEval-2017 Task1 : Enhancing the Semantic Similarity for Arabic Sentences with Vectors Weighting<fixed-case>LIM</fixed-case>-<fixed-case>LIG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task1: Enhancing the Semantic Similarity for <fixed-case>A</fixed-case>rabic Sentences with Vectors Weighting</title>
      <author><first>El Moatez Billah</first> <last>Nagoudi</last></author>
      <author><first>Jérémy</first> <last>Ferrero</last></author>
      <author><first>Didier</first> <last>Schwab</last></author>
      <pages>134–138</pages>
      <url hash="1fa0cdae">S17-2017</url>
      <doi>10.18653/v1/S17-2017</doi>
      <abstract>This article describes our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> named LIM-LIG. This system is designed for SemEval 2017 Task1 : Semantic Textual Similarity (Track1). LIM-LIG proposes an innovative enhancement to word embedding-based model devoted to measure the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> in Arabic sentences. The main idea is to exploit the word representations as vectors in a <a href="https://en.wikipedia.org/wiki/Dimension_(vector_space)">multidimensional space</a> to capture the semantic and syntactic properties of words. IDF weighting and Part-of-Speech tagging are applied on the examined sentences to support the identification of words that are highly descriptive in each sentence. LIM-LIG system achieves a <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson’s correlation</a> of 0.74633, ranking 2nd among all participants in the Arabic monolingual pairs STS task organized within the SemEval 2017 evaluation campaign</abstract>
      <bibkey>nagoudi-etal-2017-lim</bibkey>
    </paper>
    <paper id="18">
      <title>OPI-JSA at SemEval-2017 Task 1 : Application of <a href="https://en.wikipedia.org/wiki/Ensemble_learning">Ensemble learning</a> for computing semantic textual similarity<fixed-case>OPI</fixed-case>-<fixed-case>JSA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Application of Ensemble learning for computing semantic textual similarity</title>
      <author><first>Martyna</first> <last>Śpiewak</last></author>
      <author><first>Piotr</first> <last>Sobecki</last></author>
      <author><first>Daniel</first> <last>Karaś</last></author>
      <pages>139–143</pages>
      <url hash="b54bba03">S17-2018</url>
      <doi>10.18653/v1/S17-2018</doi>
      <abstract>Semantic Textual Similarity (STS) evaluation assesses the degree to which two parts of texts are similar, based on their semantic evaluation. In this paper, we describe three <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> submitted to STS SemEval 2017. Given two English parts of a text, each of proposed <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> outputs the assessment of their <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>. We propose an approach for computing monolingual semantic textual similarity based on an ensemble of three distinct methods. Our model consists of recursive neural network (RNN) text auto-encoders ensemble with supervised a model of vectorized sentences using reduced part of speech (PoS) weighted word embeddings as well as unsupervised a method based on word coverage (TakeLab). Additionally, we enrich our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with additional <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> that allow disambiguation of <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble methods</a> based on their efficiency. We have used Multi-Layer Perceptron as an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble classifier</a> basing on estimations of trained Gradient Boosting Regressors. Results of our research proves that using such <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> leads to a higher <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> due to a fact that each <a href="https://en.wikipedia.org/wiki/Algorithm">member-algorithm</a> tends to specialize in particular type of sentences. Simple model based on PoS weighted Word2Vec word embeddings seem to improve performance of more complex RNN based auto-encoders in the ensemble. In the monolingual English-English STS subtask our Ensemble based model achieved mean Pearson correlation of.785 compared with human annotators.</abstract>
      <bibkey>spiewak-etal-2017-opi</bibkey>
    </paper>
    <paper id="19">
      <title>Lump at SemEval-2017 Task 1 : Towards an Interlingua Semantic Similarity<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Towards an Interlingua Semantic Similarity</title>
      <author><first>Cristina</first> <last>España-Bonet</last></author>
      <author><first>Alberto</first> <last>Barrón-Cedeño</last></author>
      <pages>144–149</pages>
      <url hash="7658234e">S17-2019</url>
      <doi>10.18653/v1/S17-2019</doi>
      <abstract>This is the Lump team participation at SemEval 2017 Task 1 on <a href="https://en.wikipedia.org/wiki/Semantic_similarity">Semantic Textual Similarity</a>. Our <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised model</a> relies on <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> which are multilingual or interlingual in nature. We include <a href="https://en.wikipedia.org/wiki/Lexical_similarity">lexical similarities</a>, cross-language explicit semantic analysis, internal representations of multilingual neural networks and interlingual word embeddings. Our representations allow to use large datasets in language pairs with many instances to better classify instances in smaller language pairs avoiding the necessity of translating into a single language. Hence we can deal with all the languages in the task : <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish</a>.</abstract>
      <bibkey>espana-bonet-barron-cedeno-2017-lump</bibkey>
    </paper>
    <paper id="20">
      <title>QLUT at SemEval-2017 Task 1 : Semantic Textual Similarity Based on Word Embeddings<fixed-case>QLUT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Semantic Textual Similarity Based on Word Embeddings</title>
      <author><first>Fanqing</first> <last>Meng</last></author>
      <author><first>Wenpeng</first> <last>Lu</last></author>
      <author><first>Yuteng</first> <last>Zhang</last></author>
      <author><first>Jinyong</first> <last>Cheng</last></author>
      <author><first>Yuehan</first> <last>Du</last></author>
      <author><first>Shuwang</first> <last>Han</last></author>
      <pages>150–153</pages>
      <url hash="8474fef1">S17-2020</url>
      <doi>10.18653/v1/S17-2020</doi>
      <abstract>This paper reports the details of our submissions in the task 1 of SemEval 2017. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> aims at assessing the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic textual similarity</a> of two sentences or texts. We submit three <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised systems</a> based on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. The differences between these runs are the various preprocessing on evaluation data. The best performance of these <a href="https://en.wikipedia.org/wiki/System">systems</a> on the evaluation of <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson correlation</a> is 0.6887. Unsurprisingly, results of our runs demonstrate that data preprocessing, such as <a href="https://en.wikipedia.org/wiki/Lexical_analysis">tokenization</a>, <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a>, extraction of content words and removing stop words, is helpful and plays a significant role in improving the performance of models.</abstract>
      <bibkey>meng-etal-2017-qlut</bibkey>
    </paper>
    <paper id="21">
      <title>ResSim at SemEval-2017 Task 1 : Multilingual Word Representations for Semantic Textual Similarity<fixed-case>R</fixed-case>es<fixed-case>S</fixed-case>im at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Multilingual Word Representations for Semantic Textual Similarity</title>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <author><first>Robert</first> <last>Östling</last></author>
      <pages>154–158</pages>
      <url hash="b0fd75f2">S17-2021</url>
      <doi>10.18653/v1/S17-2021</doi>
      <abstract>Shared Task 1 at SemEval-2017 deals with assessing the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> between sentences, either in the same or in different languages. In our system submission, we employ multilingual word representations, in which similar words in different languages are close to one another. Using such representations is advantageous, since the increasing amount of available parallel data allows for the application of such <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> to many of the languages in the world. Hence, <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> can be inferred even for languages for which no <a href="https://en.wikipedia.org/wiki/Annotation">annotated data</a> exists. Our system is trained and evaluated on all language pairs included in the shared task (English, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, and Turkish). Although development results are promising, our <a href="https://en.wikipedia.org/wiki/System">system</a> does not yield high performance on the shared task test sets.</abstract>
      <bibkey>bjerva-ostling-2017-ressim</bibkey>
    </paper>
    <paper id="22">
      <title>ITNLP-AiKF at SemEval-2017 Task 1 : Rich Features Based SVR for Semantic Textual Similarity Computing<fixed-case>ITNLP</fixed-case>-<fixed-case>A</fixed-case>i<fixed-case>KF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Rich Features Based <fixed-case>SVR</fixed-case> for Semantic Textual Similarity Computing</title>
      <author><first>Wenjie</first> <last>Liu</last></author>
      <author><first>Chengjie</first> <last>Sun</last></author>
      <author><first>Lei</first> <last>Lin</last></author>
      <author><first>Bingquan</first> <last>Liu</last></author>
      <pages>159–163</pages>
      <url hash="e6b1561b">S17-2022</url>
      <doi>10.18653/v1/S17-2022</doi>
      <abstract>Semantic Textual Similarity (STS) devotes to measuring the degree of equivalence in the underlying semantic of the sentence pair. We proposed a new system, ITNLP-AiKF, which applies in the SemEval 2017 Task1 Semantic Textual Similarity track 5 English monolingual pairs. In our system, rich features are involved, including Ontology based, word embedding based, Corpus based, Alignment based and Literal based feature. We leveraged the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to predict sentence pair similarity by a Support Vector Regression (SVR) model. In the result, a <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation</a> of 0.8231 is achieved by our system, which is a competitive result in the contest of this track.</abstract>
      <bibkey>liu-etal-2017-itnlp</bibkey>
    </paper>
    <paper id="23">
      <title>Neobility at SemEval-2017 Task 1 : An Attention-based Sentence Similarity Model<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: An Attention-based Sentence Similarity Model</title>
      <author><first>WenLi</first> <last>Zhuang</last></author>
      <author><first>Ernie</first> <last>Chang</last></author>
      <pages>164–169</pages>
      <url hash="b407e6bc">S17-2023</url>
      <doi>10.18653/v1/S17-2023</doi>
      <abstract>This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>.</abstract>
      <bibkey>zhuang-chang-2017-neobility</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
    </paper>
    <paper id="24">
      <title>SEF@UHH at SemEval-2017 Task 1 : Unsupervised Knowledge-Free Semantic Textual Similarity via Paragraph Vector<fixed-case>SEF</fixed-case>@<fixed-case>UHH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Unsupervised Knowledge-Free Semantic Textual Similarity via Paragraph Vector</title>
      <author><first>Mirela-Stefania</first> <last>Duma</last></author>
      <author><first>Wolfgang</first> <last>Menzel</last></author>
      <pages>170–174</pages>
      <url hash="94f6b012">S17-2024</url>
      <doi>10.18653/v1/S17-2024</doi>
      <abstract>This paper describes our unsupervised knowledge-free approach to the SemEval-2017 Task 1 Competition. The proposed method makes use of Paragraph Vector for assessing the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> between pairs of sentences. We experimented with various dimensions of the <a href="https://en.wikipedia.org/wiki/Euclidean_vector">vector</a> and three state-of-the-art <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity metrics</a>. Given a cross-lingual task, we trained <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> corresponding to its two languages and combined the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> by averaging the <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity scores</a>. The results of our submitted runs are above the median scores for five out of seven <a href="https://en.wikipedia.org/wiki/Set_(mathematics)">test sets</a> by means of <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation</a>. Moreover, one of our system runs performed best on the Spanish-English-WMT test set ranking first out of 53 runs submitted in total by all participants.</abstract>
      <bibkey>duma-menzel-2017-sef</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="25">
      <title>STS-UHH at SemEval-2017 Task 1 : Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble<fixed-case>STS</fixed-case>-<fixed-case>UHH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Scoring Semantic Textual Similarity Using Supervised and Unsupervised Ensemble</title>
      <author><first>Sarah</first> <last>Kohail</last></author>
      <author><first>Amr Rekaby</first> <last>Salama</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>175–179</pages>
      <url hash="a69fa5ee">S17-2025</url>
      <doi>10.18653/v1/S17-2025</doi>
      <abstract>This paper reports the STS-UHH participation in the SemEval 2017 shared Task 1 of Semantic Textual Similarity (STS). Overall, we submitted 3 runs covering monolingual and cross-lingual STS tracks. Our participation involves two approaches : unsupervised approach, which estimates a word alignment-based similarity score, and supervised approach, which combines dependency graph similarity and coverage features with lexical similarity measures using regression methods. We also present a way on ensembling both <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Out of 84 submitted runs, our team best multi-lingual run has been ranked 12th in overall performance with correlation of 0.61, 7th among 31 participating teams.</abstract>
      <bibkey>kohail-etal-2017-sts</bibkey>
    </paper>
    <paper id="26">
      <title>UMDeep at SemEval-2017 Task 1 : End-to-End Shared Weight LSTM Model for Semantic Textual Similarity<fixed-case>UMD</fixed-case>eep at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: End-to-End Shared Weight <fixed-case>LSTM</fixed-case> Model for Semantic Textual Similarity</title>
      <author><first>Joe</first> <last>Barrow</last></author>
      <author><first>Denis</first> <last>Peskov</last></author>
      <pages>180–184</pages>
      <url hash="3a385a7c">S17-2026</url>
      <doi>10.18653/v1/S17-2026</doi>
      <abstract>We describe a modified shared-LSTM network for the Semantic Textual Similarity (STS) task at SemEval-2017. The <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> builds on previously explored Siamese network architectures. We treat max sentence length as an additional <a href="https://en.wikipedia.org/wiki/Hyperparameter">hyperparameter</a> to be tuned (beyond learning rate, <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a>, and dropout). Our results demonstrate that hand-tuning max sentence training length significantly improves final <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. After optimizing <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a>, we train the <a href="https://en.wikipedia.org/wiki/Computer_network">network</a> on the multilingual semantic similarity task using pre-translated sentences. We achieved a <a href="https://en.wikipedia.org/wiki/Correlation_and_dependence">correlation</a> of 0.4792 for all the subtasks. We achieved the fourth highest team correlation for Task 4b, which was our best relative placement.</abstract>
      <bibkey>barrow-peskov-2017-umdeep</bibkey>
    </paper>
    <paper id="27">
      <title>MITRE at SemEval-2017 Task 1 : Simple Semantic Similarity<fixed-case>MITRE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Simple Semantic Similarity</title>
      <author><first>John</first> <last>Henderson</last></author>
      <author><first>Elizabeth</first> <last>Merkhofer</last></author>
      <author><first>Laura</first> <last>Strickhart</last></author>
      <author><first>Guido</first> <last>Zarrella</last></author>
      <pages>185–190</pages>
      <url hash="04ef69ac">S17-2027</url>
      <doi>10.18653/v1/S17-2027</doi>
      <abstract>This paper describes MITRE’s participation in the Semantic Textual Similarity task (SemEval-2017 Task 1), which evaluated machine learning approaches to the identification of similar meaning among text snippets in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish</a>. We detail the techniques we explored ranging from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Linear regression is used to tie the <a href="https://en.wikipedia.org/wiki/System">systems</a> together into an <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> submitted for evaluation. The resulting <a href="https://en.wikipedia.org/wiki/System">system</a> is capable of matching human similarity ratings of image captions with correlations of 0.73 to 0.83 in monolingual settings and 0.68 to 0.78 in cross-lingual conditions, demonstrating the power of relatively simple approaches.</abstract>
      <bibkey>henderson-etal-2017-mitre</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="28">
      <title>ECNU at SemEval-2017 Task 1 : Leverage Kernel-based Traditional NLP features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Leverage Kernel-based Traditional <fixed-case>NLP</fixed-case> features and Neural Networks to Build a Universal Model for Multilingual and Cross-lingual Semantic Textual Similarity</title>
      <author><first>Junfeng</first> <last>Tian</last></author>
      <author><first>Zhiheng</first> <last>Zhou</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>191–197</pages>
      <url hash="3f2d4dc5">S17-2028</url>
      <doi>10.18653/v1/S17-2028</doi>
      <abstract>To address semantic similarity on multilingual and cross-lingual sentences, we firstly translate other foreign languages into English, and then feed our monolingual English system with various interactive features. Our system is further supported by combining with deep learning semantic similarity and our best run achieves the mean Pearson correlation 73.16 % in primary track.</abstract>
      <bibkey>tian-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="29">
      <title>PurdueNLP at SemEval-2017 Task 1 : Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings<fixed-case>P</fixed-case>urdue<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Predicting Semantic Textual Similarity with Paraphrase and Event Embeddings</title>
      <author><first>I-Ta</first> <last>Lee</last></author>
      <author><first>Mahak</first> <last>Goindani</last></author>
      <author><first>Chang</first> <last>Li</last></author>
      <author><first>Di</first> <last>Jin</last></author>
      <author><first>Kristen Marie</first> <last>Johnson</last></author>
      <author><first>Xiao</first> <last>Zhang</last></author>
      <author><first>Maria Leonor</first> <last>Pacheco</last></author>
      <author><first>Dan</first> <last>Goldwasser</last></author>
      <pages>198–202</pages>
      <url hash="5238c1f0">S17-2029</url>
      <doi>10.18653/v1/S17-2029</doi>
      <abstract>This paper describes our proposed solution for SemEval 2017 Task 1 : <a href="https://en.wikipedia.org/wiki/Semantic_similarity">Semantic Textual Similarity</a> (Daniel Cer and Specia, 2017). The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> aims at measuring the degree of equivalence between sentences given in English. Performance is evaluated by computing <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation scores</a> between the predicted scores and <a href="https://en.wikipedia.org/wiki/Judgement">human judgements</a>. Our proposed <a href="https://en.wikipedia.org/wiki/System">system</a> consists of two <a href="https://en.wikipedia.org/wiki/System">subsystems</a> and one <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression model</a> for predicting STS scores. The two subsystems are designed to learn Paraphrase and Event Embeddings that can take the consideration of paraphrasing characteristics and <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence structures</a> into our <a href="https://en.wikipedia.org/wiki/System">system</a>. The <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression model</a> associates these <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> to make the final predictions. The experimental result shows that our <a href="https://en.wikipedia.org/wiki/Tensor_(intrinsic_definition)">system</a> acquires 0.8 of <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson Correlation Scores</a> in this task.</abstract>
      <bibkey>lee-etal-2017-purduenlp</bibkey>
    </paper>
    <paper id="30">
      <title>RTM at SemEval-2017 Task 1 : Referential Translation Machines for Predicting Semantic Similarity<fixed-case>RTM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Referential Translation Machines for Predicting Semantic Similarity</title>
      <author><first>Ergun</first> <last>Biçici</last></author>
      <pages>203–207</pages>
      <url hash="0d9940d5">S17-2030</url>
      <doi>10.18653/v1/S17-2030</doi>
      <abstract>We use referential translation machines for predicting the semantic similarity of text in all STS tasks which contain <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, and <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish</a> this year. RTMs pioneer a language independent approach to semantic similarity and remove the need to access any task or domain specific information or resource. RTMs become 6th out of 52 submissions in <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a> to English STS. We average prediction scores using weights based on the training performance to improve the overall performance.</abstract>
      <bibkey>bicici-2017-rtm</bibkey>
    </paper>
    <paper id="31">
      <title>LIPN-IIMAS at SemEval-2017 Task 1 : Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity<fixed-case>LIPN</fixed-case>-<fixed-case>IIMAS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 1: Subword Embeddings, Attention Recurrent Neural Networks and Cross Word Alignment for Semantic Textual Similarity</title>
      <author><first>Ignacio</first> <last>Arroyo-Fernández</last></author>
      <author><first>Ivan Vladimir</first> <last>Meza Ruiz</last></author>
      <pages>208–212</pages>
      <url hash="311b7a5f">S17-2031</url>
      <doi>10.18653/v1/S17-2031</doi>
      <abstract>In this paper we report our attempt to use, on the one hand, state-of-the-art neural approaches that are proposed to measure Semantic Textual Similarity (STS). On the other hand, we propose an unsupervised cross-word alignment approach, which is linguistically motivated. The neural approaches proposed herein are divided into two main stages. The first stage deals with constructing neural word embeddings, the components of sentence embeddings. The second stage deals with constructing a semantic similarity function relating pairs of <a href="https://en.wikipedia.org/wiki/Sentence_embedding">sentence embeddings</a>. Unfortunately our competition results were poor in all tracks, therefore we concentrated our research to improve them for Track 5 (EN-EN).</abstract>
      <bibkey>arroyo-fernandez-meza-ruiz-2017-lipn</bibkey>
    </paper>
    <paper id="33">
      <title>HCCL at SemEval-2017 Task 2 : Combining Multilingual Word Embeddings and Transliteration Model for Semantic Similarity<fixed-case>HCCL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Combining Multilingual Word Embeddings and Transliteration Model for Semantic Similarity</title>
      <author><first>Junqing</first> <last>He</last></author>
      <author><first>Long</first> <last>Wu</last></author>
      <author><first>Xuemin</first> <last>Zhao</last></author>
      <author><first>Yonghong</first> <last>Yan</last></author>
      <pages>220–225</pages>
      <url hash="be394bf6">S17-2033</url>
      <doi>10.18653/v1/S17-2033</doi>
      <abstract>In this paper, we introduce an approach to combining <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> for multilingual semantic word similarity, the task2 of SemEval-2017. Thanks to the unsupervised transliteration model, our cross-lingual word embeddings encounter decreased sums of OOVs. Our results are produced using only monolingual Wikipedia corpora and a limited amount of sentence-aligned data. Although relatively little resources are utilized, our system ranked 3rd in the monolingual subtask and can be the 6th in the cross-lingual subtask.</abstract>
      <bibkey>he-etal-2017-hccl</bibkey>
    </paper>
    <paper id="34">
      <title>Citius at SemEval-2017 Task 2 : Cross-Lingual Similarity from Comparable Corpora and Dependency-Based Contexts<fixed-case>C</fixed-case>itius at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Cross-Lingual Similarity from Comparable Corpora and Dependency-Based Contexts</title>
      <author><first>Pablo</first> <last>Gamallo</last></author>
      <pages>226–229</pages>
      <url hash="ed909af4">S17-2034</url>
      <doi>10.18653/v1/S17-2034</doi>
      <abstract>This article describes the <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional strategy</a> submitted by the Citius team to the SemEval 2017 Task 2. Even though the team participated in two subtasks, namely monolingual and cross-lingual word similarity, the article is mainly focused on the cross-lingual subtask. Our method uses comparable corpora and syntactic dependencies to extract count-based and transparent bilingual distributional contexts. The evaluation of the results show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is competitive with other cross-lingual strategies, even those using aligned and parallel texts.</abstract>
      <bibkey>gamallo-2017-citius</bibkey>
    </paper>
    <paper id="36">
      <title>QLUT at SemEval-2017 Task 2 : Word Similarity Based on Word Embedding and Knowledge Base<fixed-case>QLUT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Word Similarity Based on Word Embedding and Knowledge Base</title>
      <author><first>Fanqing</first> <last>Meng</last></author>
      <author><first>Wenpeng</first> <last>Lu</last></author>
      <author><first>Yuteng</first> <last>Zhang</last></author>
      <author><first>Ping</first> <last>Jian</last></author>
      <author><first>Shumin</first> <last>Shi</last></author>
      <author><first>Heyan</first> <last>Huang</last></author>
      <pages>235–238</pages>
      <url hash="a2b36efd">S17-2036</url>
      <doi>10.18653/v1/S17-2036</doi>
      <abstract>This paper shows the details of our system submissions in the task 2 of SemEval 2017. We take part in the subtask 1 of this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, which is an English monolingual subtask. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is designed to evaluate the <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic word similarity</a> of two linguistic items. The results of runs are assessed by standard <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson and Spearman correlation</a>, contrast with official gold standard set. The best performance of our <a href="https://en.wikipedia.org/wiki/Run_(cricket)">runs</a> is 0.781 (Final). The techniques of our runs mainly make use of the <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and the knowledge-based method. The results demonstrate that the combined method is effective for the computation of word similarity, while the word embeddings and the knowledge-based technique, respectively, needs more deeply improvement in details.</abstract>
      <bibkey>meng-etal-2017-qlut-semeval</bibkey>
    </paper>
    <paper id="37">
      <title>RUFINO at SemEval-2017 Task 2 : Cross-lingual lexical similarity by extending PMI and word embeddings systems with a Swadesh’s-like list<fixed-case>RUFINO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Cross-lingual lexical similarity by extending <fixed-case>PMI</fixed-case> and word embeddings systems with a <fixed-case>S</fixed-case>wadesh’s-like list</title>
      <author><first>Sergio</first> <last>Jimenez</last></author>
      <author><first>George</first> <last>Dueñas</last></author>
      <author><first>Lorena</first> <last>Gaitan</last></author>
      <author><first>Jorge</first> <last>Segura</last></author>
      <pages>239–244</pages>
      <url hash="fcc3503e">S17-2037</url>
      <doi>10.18653/v1/S17-2037</doi>
      <abstract>The RUFINO team proposed a non-supervised, conceptually-simple and low-cost approach for addressing the Multilingual and Cross-lingual Semantic Word Similarity challenge at SemEval 2017. The proposed systems were cross-lingual extensions of popular monolingual lexical similarity approaches such as PMI and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a>. The extensions were possible by means of a small parallel list of concepts similar to the Swadesh’s list, which we obtained in a semi-automatic way. In spite of its simplicity, our approach showed to be effective obtaining statistically-significant and consistent results in all datasets proposed for the task. Besides, we provide some research directions for improving this novel and affordable approach.</abstract>
      <bibkey>jimenez-etal-2017-rufino</bibkey>
    </paper>
    <paper id="38">
      <title>MERALI at SemEval-2017 Task 2 Subtask 1 : a Cognitively Inspired approach<fixed-case>MERALI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2 Subtask 1: a Cognitively Inspired approach</title>
      <author><first>Enrico</first> <last>Mensa</last></author>
      <author><first>Daniele P.</first> <last>Radicioni</last></author>
      <author><first>Antonio</first> <last>Lieto</last></author>
      <pages>245–249</pages>
      <url hash="6ffb5c73">S17-2038</url>
      <doi>10.18653/v1/S17-2038</doi>
      <abstract>In this paper we report on the participation of the MERALI system to the SemEval Task 2 Subtask 1. The MERALI system approaches conceptual similarity through a simple, cognitively inspired, <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> ; it builds on a linguistic resource, the TTCS-e, that relies on <a href="https://en.wikipedia.org/wiki/BabelNet">BabelNet</a>, NASARI and <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a>. The linguistic resource in fact contains a novel mixture of common-sense and encyclopedic knowledge. The obtained results point out that there is ample room for improvement, so that they are used to elaborate on present limitations and on future steps.</abstract>
      <bibkey>mensa-etal-2017-merali</bibkey>
    </paper>
    <paper id="39">
      <title>HHU at SemEval-2017 Task 2 : Fast Hash-Based Embeddings for Semantic Word Similarity Assessment<fixed-case>HHU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Fast Hash-Based Embeddings for Semantic Word Similarity Assessment</title>
      <author><first>Behrang</first> <last>QasemiZadeh</last></author>
      <author><first>Laura</first> <last>Kallmeyer</last></author>
      <pages>250–255</pages>
      <url hash="e970d8ba">S17-2039</url>
      <doi>10.18653/v1/S17-2039</doi>
      <abstract>This paper describes the HHU system that participated in Task 2 of SemEval 2017, Multilingual and Cross-lingual Semantic Word Similarity. We introduce our unsupervised embedding learning technique and describe how it was employed and configured to address the problems of monolingual and multilingual word similarity measurement. This paper reports from empirical evaluations on the <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmark</a> provided by the task’s organizers.</abstract>
      <bibkey>qasemizadeh-kallmeyer-2017-hhu</bibkey>
    </paper>
    <paper id="40">
      <title>Mahtab at SemEval-2017 Task 2 : Combination of Corpus-based and Knowledge-based Methods to Measure Semantic Word Similarity<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Combination of Corpus-based and Knowledge-based Methods to Measure Semantic Word Similarity</title>
      <author><first>Niloofar</first> <last>Ranjbar</last></author>
      <author><first>Fatemeh</first> <last>Mashhadirajab</last></author>
      <author><first>Mehrnoush</first> <last>Shamsfard</last></author>
      <author><first>Rayeheh</first> <last>Hosseini pour</last></author>
      <author><first>Aryan</first> <last>Vahid pour</last></author>
      <pages>256–260</pages>
      <url hash="ab2e6014">S17-2040</url>
      <doi>10.18653/v1/S17-2040</doi>
      <abstract>In this paper, we describe our proposed method for measuring <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> for a given pair of words at SemEval-2017 monolingual semantic word similarity task. We use a combination of knowledge-based and corpus-based techniques. We use FarsNet, the Persian Word Net, besides deep learning techniques to extract the similarity of words. We evaluated our proposed approach on Persian (Farsi) test data at SemEval-2017. It outperformed the other participants and ranked the first in the challenge.</abstract>
      <bibkey>ranjbar-etal-2017-mahtab</bibkey>
    </paper>
    <paper id="41">
      <title>Sew-Embed at SemEval-2017 Task 2 : Language-Independent Concept Representations from a Semantically Enriched Wikipedia<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Language-Independent Concept Representations from a Semantically Enriched <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Claudio</first> <last>Delli Bovi</last></author>
      <author><first>Alessandro</first> <last>Raganato</last></author>
      <pages>261–266</pages>
      <url hash="9915904e">S17-2041</url>
      <doi>10.18653/v1/S17-2041</doi>
      <abstract>This paper describes Sew-Embed, our language-independent approach to multilingual and cross-lingual semantic word similarity as part of the SemEval-2017 Task 2. We leverage the Wikipedia-based concept representations developed by Raganato et al. (2016), and propose an embedded augmentation of their explicit high-dimensional vectors, which we obtain by plugging in an arbitrary word (or sense) embedding representation, and computing a <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted average</a> in the continuous vector space. We evaluate Sew-Embed with two different off-the-shelf embedding representations, and report their performances across all monolingual and cross-lingual benchmarks available for the task. Despite its simplicity, especially compared with supervised or overly tuned approaches, Sew-Embed achieves competitive results in the cross-lingual setting (3rd best result in the global ranking of subtask 2, score 0.56).</abstract>
      <bibkey>delli-bovi-raganato-2017-sew</bibkey>
    </paper>
    <paper id="42">
      <title>Wild Devs’ at SemEval-2017 Task 2 : Using Neural Networks to Discover Word Similarity<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 2: Using Neural Networks to Discover Word Similarity</title>
      <author><first>Răzvan-Gabriel</first> <last>Rotari</last></author>
      <author><first>Ionuț</first> <last>Hulub</last></author>
      <author><first>Ștefan</first> <last>Oprea</last></author>
      <author><first>Mihaela</first> <last>Plămadă-Onofrei</last></author>
      <author><first>Alina Beatrice</first> <last>Lorenţ</last></author>
      <author><first>Raluca</first> <last>Preisler</last></author>
      <author><first>Adrian</first> <last>Iftene</last></author>
      <author><first>Diana</first> <last>Trandabăț</last></author>
      <pages>267–270</pages>
      <url hash="626ba4c6">S17-2042</url>
      <doi>10.18653/v1/S17-2042</doi>
      <abstract>This paper presents Wild Devs’ participation in the SemEval-2017 Task 2 Multi-lingual and Cross-lingual Semantic Word Similarity, which tries to automatically measure the semantic similarity between two words. The system was build using <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>, having as input a collection of word pairs, whereas the output consists of a list of scores, from 0 to 4, corresponding to the degree of similarity between the word pairs.</abstract>
      <bibkey>rotari-etal-2017-wild</bibkey>
    </paper>
    <paper id="43">
      <title>TrentoTeam at SemEval-2017 Task 3 : An application of Grice Maxims in Ranking Community Question Answers<fixed-case>T</fixed-case>rento<fixed-case>T</fixed-case>eam at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: An application of <fixed-case>G</fixed-case>rice Maxims in Ranking Community Question Answers</title>
      <author><first>Mohammed R. H.</first> <last>Qwaider</last></author>
      <author><first>Abed Alhakim</first> <last>Freihat</last></author>
      <author><first>Fausto</first> <last>Giunchiglia</last></author>
      <pages>271–274</pages>
      <url hash="526f5506">S17-2043</url>
      <doi>10.18653/v1/S17-2043</doi>
      <abstract>In this paper we present the Tren-toTeam system which participated to thetask 3 at SemEval-2017 (Nakov et al.,2017).We concentrated our work onapplying Grice Maxims(used in manystate-of-the-art Machine learning applica-tions(Vogel et al., 2013 ; Kheirabadiand Aghagolzadeh, 2012 ; Dale and Re-iter, 1995 ; Franke, 2011)) to ranking an-swers of a question by answers relevancy. Particularly, we created a ranker systembased on relevancy scores, assigned by 3main components : Named entity recogni-tion, similarity score, sentiment analysis. Our system obtained a comparable resultsto Machine learning systems.</abstract>
      <bibkey>qwaider-etal-2017-trentoteam</bibkey>
    </paper>
    <paper id="44">
      <title>UPC-USMBA at SemEval-2017 Task 3 : Combining multiple approaches for CQA for Arabic<fixed-case>UPC</fixed-case>-<fixed-case>USMBA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Combining multiple approaches for <fixed-case>CQA</fixed-case> for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Yassine</first> <last>El Adlouni</last></author>
      <author><first>Imane</first> <last>Lahbari</last></author>
      <author><first>Horacio</first> <last>Rodríguez</last></author>
      <author><first>Mohammed</first> <last>Meknassi</last></author>
      <author><first>Said Ouatik</first> <last>El Alaoui</last></author>
      <author><first>Noureddine</first> <last>Ennahnahi</last></author>
      <pages>275–279</pages>
      <url hash="495163a8">S17-2044</url>
      <doi>10.18653/v1/S17-2044</doi>
      <abstract>This paper presents a description of the participation of the UPC-USMBA team in the SemEval 2017 Task 3, subtask D, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>. Our approach for facing the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is based on a combination of a set of atomic classifiers. The atomic classifiers include lexical string based, based on vectorial representations and rulebased. Several combination approaches have been tried.</abstract>
      <bibkey>el-adlouni-etal-2017-upc</bibkey>
    </paper>
    <paper id="45">
      <title>Beihang-MSRA at SemEval-2017 Task 3 : A Ranking System with Neural Matching Features for Community Question Answering<fixed-case>MSRA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering</title>
      <author><first>Wenzheng</first> <last>Feng</last></author>
      <author><first>Yu</first> <last>Wu</last></author>
      <author><first>Wei</first> <last>Wu</last></author>
      <author><first>Zhoujun</first> <last>Li</last></author>
      <author><first>Ming</first> <last>Zhou</last></author>
      <pages>280–286</pages>
      <url hash="ea9b1b96">S17-2045</url>
      <doi>10.18653/v1/S17-2045</doi>
      <abstract>This paper presents the <a href="https://en.wikipedia.org/wiki/System">system</a> in SemEval-2017 Task 3, Community Question Answering (CQA). We develop a <a href="https://en.wikipedia.org/wiki/Ranking">ranking system</a> that is capable of capturing <a href="https://en.wikipedia.org/wiki/Semantics">semantic relations</a> between text pairs with little word overlap. In addition to traditional NLP features, we introduce several neural network based matching features which enable our system to measure text similarity beyond <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>. Our system significantly outperforms baseline methods and holds the second place in Subtask A and the fifth place in Subtask B, which demonstrates its efficacy on answer selection and question retrieval.</abstract>
      <bibkey>feng-etal-2017-beihang</bibkey>
    <title_ar>Beihang-MSRA في SemEval-2017 المهمة 3: نظام تصنيف مع ميزات المطابقة العصبية للإجابة على أسئلة المجتمع</title_ar>
      <title_es>Beihang-MSRA en la Tarea 3 de SemEval-2017: Un sistema de clasificación con funciones de emparejamiento neuronal para la respuesta a preguntas de la comunidad</title_es>
      <title_fr>Beihang-MSRA à SemEval-2017 Tâche 3 : Un système de classement avec des fonctionnalités de correspondance neuronale pour la réponse aux questions de la communauté</title_fr>
      <title_pt>Beihang-MSRA no SemEval-2017 Tarefa 3: Um Sistema de Classificação com Recursos de Correspondência Neural para Resposta a Perguntas da Comunidade</title_pt>
      <title_zh>北京-MSRA在SemEval-2017务3:有神经匹配功能之统,以社区问答</title_zh>
      <title_ja>SemEval -2017のBeihang - MSRAタスク3 ：コミュニティの質問への回答のためのニューラルマッチング機能を備えたランキングシステム</title_ja>
      <title_hi>Beihang-MSRA पर SemEval-2017 कार्य 3: समुदाय प्रश्न उत्तर देने के लिए तंत्रिका मिलान सुविधाओं के साथ एक रैंकिंग प्रणाली</title_hi>
      <title_ru>Beihang-MSRA на SemEval-2017 Задача 3: Система ранжирования с нейросопоставительными функциями для ответов на вопросы сообщества</title_ru>
      <title_ga>Beihang-MSRA ag SemEval-2017 Tasc 3: Córas Rangaithe le Gnéithe Comhoiriúnacha Néaracha le haghaidh Freagra Ceisteanna Pobail</title_ga>
      <title_ka>Beihang-MSRA semiEval-2017 პარამეტრი 3: სისტემა, რომელიც ნეიროლური თანამდვილეობის ფუნქციები საზოგადოებო კითხვების გარეშე</title_ka>
      <title_hu>Beihang-MSRA a SemEval-2017 3. feladat: A rangsorolási rendszer idegi egyezési funkciókkal a közösségi kérdések megválaszolásához</title_hu>
      <title_el>Εργασία 3: Ένα σύστημα κατάταξης με νευρωνικά χαρακτηριστικά αντιστοίχισης για την απάντηση σε κοινοτικές ερωτήσεις</title_el>
      <title_it>Beihang-MSRA a SemEval-2017 Task 3: Un sistema di classificazione con caratteristiche di corrispondenza neurale per la risposta alle domande della comunità</title_it>
      <title_kk>Beihang</title_kk>
      <title_mk>Беханг-МСРА на SemEval-2017 задача 3: Рејтинг систем со нервни способности за одговори на прашања во заедницата</title_mk>
      <title_lt>„Beihang-MSRA“ programos „SemEval-2017“ 3 uždavinys. Klasifikavimo sistema su neurologiniais derinimo požymiais, skirta atsakymui į Bendrijos klausimus</title_lt>
      <title_ms>Beihang-MSRA di SemEval-2017 Tugas 3: Sistem Ranking dengan Features Neural Matching untuk Jawapan soalan Komuniti</title_ms>
      <title_ml>സെമ്എവാല്‍- 2017 ടാസ്ക് 3-ല്‍ ബെയിഹാങ്ങ്- എസ്ര: സമൂഹത്തിന്റെ ചോദ്യങ്ങള്‍</title_ml>
      <title_mn>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Response</title_mn>
      <title_mt>Beihang-MSRA f’SemEval-2017 Kompitu 3: Sistema ta’ Klassifikazzjoni b’Karatteristiċi ta’ Tqabbil Newrali għat-tweġibiet għall-mistoqsijiet tal-Komunità</title_mt>
      <title_no>Beihang-MSRA på semiEval-2017 oppgåve 3: Eit Ranking System med Neural Match Features for Community Question Answering</title_no>
      <title_pl>Beihang-MSRA w SemEval-2017 Zadanie 3: System rankingowy z funkcjami dopasowywania neuronów do odpowiedzi na pytania społeczności</title_pl>
      <title_sr>Beihang-MSRA na pola Evala-2017 zadatak 3: sistem probanja sa neurološkim funkcijama odgovora na pitanje zajednice</title_sr>
      <title_ro>Beihang-MSRA la SemEval-2017 Sarcina 3: Un sistem de clasare cu caracteristici de potrivire neurală pentru răspunsul la întrebări comunitare</title_ro>
      <title_si>Beihang-MSRA at semeval-2017 Job 3: A Raning System with neural Matching Featuries for Comunity Query Answer</title_si>
      <title_so>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering</title_so>
      <title_sv>Beihang-MSRA på SemEval-2017 Uppgift 3: Ett rankningssystem med neurala matchningsfunktioner för svar på gemenskapsfrågor</title_sv>
      <title_ta>செம்Eval- 2017 பணியில் பெய்ஹாங்- எம்ஸ்ரா: சமுதாயத்தின் கேள்விக்கு பதில் செய்தி</title_ta>
      <title_ur>SemEval-2017 Task 3 میں Beihang-MSRA بن جاتا ہے: ایک Ranking System with Neural Matching Features for Community Question Answering</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Bị treo-MSA tại Nhiệm vụ Semkhai-137: Hệ thống phân phối khí thần kết nối với bộ phận Trả lời câu hỏi ở Cộng đồng.</title_vi>
      <title_bg>Задача 3: Система за класиране с функции за съвпадение на невроните за отговор на въпроси на общността</title_bg>
      <title_da>Beihang-MSRA på SemEval-2017 Opgave 3: Et rangeringssystem med neurale matchende funktioner til besvarelse af fællesskabsspørgsmål</title_da>
      <title_nl>Bijhang-MSRA op SemEval-2017 Taak 3: Een rangschikkingssysteem met neurale matching functies voor het beantwoorden van vragen in de gemeenschap</title_nl>
      <title_ko>북항 MSRA가SemEval-2017에서의 임무 3: 신경 일치 기능을 갖춘 지역사회 퀴즈 랭킹 시스템</title_ko>
      <title_de>Aufgabe 3: Ein Rankingsystem mit neuronalen Matching-Funktionen für die Beantwortung von Community-Fragen</title_de>
      <title_id>Beihang-MSRA di SemEval-2017 Tugas 3: Sistem Ranking dengan Features Neural Matching untuk Jawaban Pertanyaan Komunitas</title_id>
      <title_hr>Beihang-MSRA na zadatku 3. iz poluvremenog ispitivanja 2017: sustav za probijanje sa neurološkim funkcijama odgovora na pitanje zajednice</title_hr>
      <title_fa>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Response</title_fa>
      <title_sw>Beihang-MSRA kwenye SemEval-2017 Tamko 3: Mfumo wa Kusini wenye Tamko za Matukio ya Kiasili kwa ajili ya swali la Jamii</title_sw>
      <title_tr>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering</title_tr>
      <title_sq>Beihang-MSRA në SemEval-2017 Task 3: A Ranging System with Neural Matching Features for Community Question Answering</title_sq>
      <title_am>Beihang-MSRA በSemEval-2017 ስራ 3: A Ranking System with Neural Matching Features for Community Question Answers</title_am>
      <title_af>Beihang-MSRA by SemEval-2017 Opdrag 3: 'n Ranking Stelsel met Neurale ooreenstemmende eienskappe vir gemeenskap vraag antwoord</title_af>
      <title_hy>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering</title_hy>
      <title_bn>সেমইভাল-২০১৭ কাজ ৩-এ বেইহাং-এমএসরা: কমিউনিটির প্রশ্নের উত্তর দিয়ে একটি রেঙ্কিং সিস্টেমের সাথে নিউরাল মিথ্যা বৈশিষ্</title_bn>
      <title_ca>Beihang-MSRA a SemEval-2017 tasca 3: Un sistema de classificació amb característiques neurològiques per respondre a preguntes comunitaries</title_ca>
      <title_cs>Beihang-MSRA na SemEval-2017 Úkol 3: Žebříčkový systém s neuronovými funkcemi pro odpověď na otázky komunity</title_cs>
      <title_et>Beihang-MSRA SemEval-2017 Ülesanne 3: Neuraalsete sobitamisfunktsioonidega järjestussüsteem kogukonna küsimustele vastamiseks</title_et>
      <title_bs>Beihang-MSRA na semiEval-2017 zadatku 3: sustav za probanje sa neurološkim funkcijama odgovora na pitanje zajednice</title_bs>
      <title_az>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Response</title_az>
      <title_fi>Beihang-MSRA SemEval-2017 Tehtävä 3: Ranking järjestelmä, jossa on hermojen täsmäytysominaisuudet yhteisön kysymyksiin vastaamiseen</title_fi>
      <title_jv>Pekhang</title_jv>
      <title_sk>Beihang-MSRA na SemEval-2017 Naloga 3: Sistem razvrščanja z nevralnimi funkcijami ujemanja za odgovarjanje na vprašanja skupnosti</title_sk>
      <title_ha>QSystemSemaphore</title_ha>
      <title_he>Beihang-MSRA ב SemEval-2017 משימה 3: מערכת כיוון עם תכונות התאמה נוירולית לענות על שאלות קהילתית</title_he>
      <title_bo>Beihang-MSRA at SemEval-2017 Task 3: A Ranking System with Neural Matching Features for Community Question Answering</title_bo>
      <abstract_pt>Este artigo apresenta o sistema na Tarefa 3 do SemEval-2017, Community Question Answering (CQA). Desenvolvemos um sistema de classificação capaz de capturar relações semânticas entre pares de texto com pouca sobreposição de palavras. Além dos recursos tradicionais de PNL, apresentamos vários recursos de correspondência baseados em redes neurais que permitem que nosso sistema meça a similaridade de texto além dos léxicos. Nosso sistema supera significativamente os métodos de linha de base e ocupa o segundo lugar na Subtarefa A e o quinto lugar na Subtarefa B, o que demonstra sua eficácia na seleção de respostas e recuperação de perguntas.</abstract_pt>
      <abstract_ar>تقدم هذه الورقة النظام في SemEval-2017 Task 3 ، Community Question Answer (CQA). نقوم بتطوير نظام تصنيف قادر على التقاط العلاقات الدلالية بين أزواج النص مع تداخل بسيط بين الكلمات. بالإضافة إلى ميزات البرمجة اللغوية العصبية التقليدية ، نقدم العديد من ميزات المطابقة القائمة على الشبكة العصبية والتي تمكن نظامنا من قياس تشابه النص خارج المعاجم. يتفوق نظامنا بشكل كبير على الأساليب الأساسية ويحتل المركز الثاني في Subtask A والمركز الخامس في Subtask B ، مما يوضح فعاليته في اختيار الإجابة واسترجاع الأسئلة.</abstract_ar>
      <abstract_fr>Cet article présente le système de SEMEval-2017 Task 3, Community Question Answering (CQA). Nous développons un système de classement capable de saisir les relations sémantiques entre des paires de textes avec peu de chevauchement de mots. En plus des fonctionnalités traditionnelles de PNL, nous introduisons plusieurs fonctionnalités de correspondance basées sur les réseaux neuronaux qui permettent à notre système de mesurer la similitude de texte au-delà des lexiques. Notre système surpasse largement les méthodes de base et occupe la deuxième place dans la sous-tâche A et la cinquième place dans la sous-tâche B, ce qui démontre son efficacité sur la sélection des réponses et la récupération des questions.</abstract_fr>
      <abstract_es>Este documento presenta el sistema en la Tarea 3 de SemEval-2017, Respuesta a preguntas de la comunidad (CQA). Desarrollamos un sistema de clasificación que es capaz de capturar las relaciones semánticas entre pares de texto con poca superposición de palabras. Además de las funciones tradicionales de PNL, introducimos varias funciones de correspondencia basadas en redes neuronales que permiten a nuestro sistema medir la similitud del texto más allá de los léxicos. Nuestro sistema supera significativamente los métodos de referencia y ocupa el segundo lugar en la subtarea A y el quinto lugar en la subtarea B, lo que demuestra su eficacia en la selección de respuestas y la recuperación de preguntas.</abstract_es>
      <abstract_hi>यह पेपर SemEval-2017 टास्क 3, सामुदायिक प्रश्न उत्तर (CQA) में सिस्टम प्रस्तुत करता है। हम एक रैंकिंग प्रणाली विकसित करते हैं जो छोटे शब्द ओवरलैप के साथ पाठ जोड़े के बीच शब्दार्थ संबंधों को कैप्चर करने में सक्षम है। पारंपरिक एनएलपी सुविधाओं के अलावा, हम कई तंत्रिका नेटवर्क आधारित मिलान सुविधाओं को पेश करते हैं जो हमारे सिस्टम को शब्दकोशों से परे पाठ समानता को मापने में सक्षम बनाते हैं। हमारी प्रणाली बेसलाइन विधियों को काफी बेहतर बनाती है और सबटास्क ए में दूसरा स्थान रखती है और सबटास्क बी में पांचवें स्थान पर है, जो उत्तर चयन और प्रश्न पुनर्प्राप्ति पर अपनी प्रभावकारिता को दर्शाती है।</abstract_hi>
      <abstract_ru>В настоящем документе система представлена в Задаче 3 SemEval-2017, Ответы на вопросы сообщества (CQA). Мы разрабатываем систему ранжирования, которая способна фиксировать семантические отношения между текстовыми парами с небольшим перекрытием слов. В дополнение к традиционным функциям NLP, мы вводим несколько функций сопоставления на основе нейронной сети, которые позволяют нашей системе измерять сходство текста за пределами лексиконов. Наша система значительно превосходит базовые методы и занимает второе место в подзадаче А и пятое место в подзадаче Б, что демонстрирует ее эффективность в подборе ответов и поиске вопросов.</abstract_ru>
      <abstract_ja>本稿では， SemEval -2017 Task 3, Community Question Answering (CQA)でシステムを紹介する．単語の重複が少ないテキストペア間の意味関係を捉えることができるランキングシステムを開発しました。従来のNLP機能に加えて、当社のシステムが辞書を超えてテキストの類似性を測定できるようにする、いくつかのニューラルネットワークベースのマッチング機能を導入しています。当社のシステムは、ベースラインの方法を大幅に上回り、サブタスクAの2位とサブタスクBの5位を保持しています。これは、回答の選択と質問の取得における有効性を示しています。</abstract_ja>
      <abstract_zh>本文言SemEval-2017务3,社区问(CQA)中之统。 我们开了一个排名系统,该系统能获文本对语义,并且几乎没有单词重叠。 自旧NLP之外,引入数神经网络,使吾统测词典外文本相似性。 臣等统明优于基线法,于子职A中第二,于子务B中第五,明其对案检索之有效性也。</abstract_zh>
      <abstract_ga>Cuireann an páipéar seo an córas i láthair i dTasc 3 SemEval-2017, Freagairt Cheisteanna Pobail (CQA). Forbraímid córas rangú atá in ann caidreamh séimeantach a ghabháil idir péirí téacs ar bheagán forluí focal. Chomh maith le gnéithe traidisiúnta NLP, tugaimid isteach roinnt gnéithe meaitseála líonra néar-bhunaithe a chuireann ar chumas ár gcóras cosúlacht téacs a thomhas thar na foclóirí. Sáraíonn ár gcóras modhanna bunlíne go suntasach agus tá an dara háit i bhFothasc A agus an cúigiú háit i bhFothasc B, rud a léiríonn a éifeachtúlacht maidir le freagraí a roghnú agus ceisteanna a aisghabháil.</abstract_ga>
      <abstract_el>Η παρούσα εργασία παρουσιάζει το σύστημα στο έργο 3, Κοινοτική Απάντηση Ερωτήσεων (CQA). Αναπτύσσουμε ένα σύστημα κατάταξης που είναι ικανό να συλλάβει σημασιολογικές σχέσεις μεταξύ ζευγαριών κειμένου με μικρή επικάλυψη λέξεων. Εκτός από τα παραδοσιακά χαρακτηριστικά εισάγουμε διάφορα χαρακτηριστικά αντιστοίχισης νευρωνικών δικτύων που επιτρέπουν στο σύστημά μας να μετρήσει την ομοιότητα κειμένου πέρα από τα λεξικά. Το σύστημά μας ξεπερνά σημαντικά τις μεθόδους βάσης και κατέχει τη δεύτερη θέση στην Υποεργασία Α και την πέμπτη θέση στην Υποεργασία Β, γεγονός που αποδεικνύει την αποτελεσματικότητά του στην επιλογή απαντήσεων και την ανάκτηση ερωτήσεων.</abstract_el>
      <abstract_hu>Ez a tanulmány bemutatja a rendszert a SemEval-2017 feladat 3, Közösségi kérdések megválaszolása (CQA). Olyan rangsorolási rendszert fejlesztünk ki, amely képes rögzíteni a szövegpárok szemantikai kapcsolatait kis szóátfedéssel. A hagyományos NLP funkciók mellett számos neurális hálózat alapú megfelelő funkciót vezetünk be, amelyek lehetővé teszik rendszerünk számára, hogy mérje a szöveghasonlóságot a lexikonokon túl. Rendszerünk jelentősen felülmúlja a kiindulási módszereket, és az A alfeladatban a második helyet, a B alfeladatban pedig az ötödik helyet foglalja el, ami bizonyítja hatékonyságát a válaszok kiválasztására és a kérdések lekérdezésére.</abstract_hu>
      <abstract_ka>ამ დოკუმენტის სისტემა semiEval-2017 სამუშაო სამუშაო სამუშაო კითხვების გარეშე (CQA). ჩვენ განვითარებთ სერვინტიკური სისტემი, რომელიც შეუძლია სერვინტიკური შესახებ ტექსტის ზოგების შორის შესახებ, რომელიც ცოტა სიტყვას გადარჩ ტრადიციონალური NLP ფუნქციების დამატებით, ჩვენ ვიყენებთ რამდენიმე ნეიროლური ქსელის შესაბამისი ფუნქციები, რომელიც ჩვენი სისტემის შესაძლებლობა ტექსტი ჩვენი სისტემა მნიშვნელოვანია გავაკეთებს ფესტლინის მეტოვები და მეორე ადგილის A და მეხუთე ადგილის სამუშაო B ადგილში, რომელიც გამოჩვენება სამუშაო ეფექტიურობას განახლებისთვი</abstract_ka>
      <abstract_it>Questo articolo presenta il sistema in SemEval-2017 Task 3, Community Question Answering (CQA). Sviluppiamo un sistema di ranking in grado di catturare relazioni semantiche tra coppie di testo con poca sovrapposizione di parole. Oltre alle tradizionali funzionalità NLP, introduciamo diverse funzionalità di corrispondenza basate su reti neurali che consentono al nostro sistema di misurare la somiglianza del testo oltre i lessici. Il nostro sistema supera significativamente i metodi di base e detiene il secondo posto nella sottomissione A e il quinto posto nella sottomissione B, che dimostra la sua efficacia nella selezione delle risposte e nel recupero delle domande.</abstract_it>
      <abstract_mk>Овој документ го претставува системот во "SemEval-2017 Task 3", Одговор на прашањата на заедницата (CQA). Развиваме систем за рангирање кој е способен да заземе семантични односи помеѓу текстовите парови со мало преплавување на зборовите. Покрај традиционалните карактеристики на НЛП, воведуваме неколку нервни мрежни карактеристики кои овозможуваат нашиот систем да ја мери сличноста на текстот надвор од лексиконите. Нашиот систем значително ги надминува основните методи и го држи второто место во Субзадачата А и петто место во Субзадачата Б, што ја покажува својата ефикасност во изборот на одговори и преземањето прашања.</abstract_mk>
      <abstract_lt>Šiame dokumente pristatoma sistema 3 užduotyje „Bendrijos atsakymai į klausimus“ (angl. SemEval-2017 Task 3 – CQA). Mes sukuriame klasifikavimo sistemą, kuri sugeba užfiksuoti semantinius santykius tarp teksto poros su mažu žodžių dubliavimu. Be tradicinių NLP savybių, įdiegiame keletą nervų tinklu pagrįstų atitikties savybių, kurios leidžia mūsų sistemai išmatuoti teksto panašumą už leksikonų ribų. Mūsų sistema gerokai viršija pradinius metodus ir užima antrąją vietą A pakopos užduotyje ir penktąją vietą B pakopos užduotyje, kuri rodo, kad ji veiksmingai atrenka atsakymus ir gauna klausimus.</abstract_lt>
      <abstract_kk>Бұл қағаз жүйені біртінші уақыт 2017 жылы 3- тапсырмасында көрсетеді, Жалпы сұрақтар жауап беру (CQA). Біз мәтін екеуі арасындағы симантикалық қатынастарды түсінеміз мүмкіндік жүйесін жасаймыз. Тәдімгі NLP мүмкіндіктеріне қосымша, біз бірнеше невралдық желімізге сәйкес келетін мүмкіндіктерді келтіреміз. Бұл жүйеңіздің лексикандықтан артық мә Біздің жүйеміз негізгі жол әдістерін өзгертіп, A- тапсырмасындағы екінші жағдайда және B- тапсырмасындағы бесінші жағдайда болады. Бұл жауапты таңдау мен сұрақтарды алу үші</abstract_kk>
      <abstract_ml>ഈ പത്രത്തില്‍ സെമ്എവാല്‍- 2017 ടാസ്ക് 3-ല്‍ സിസ്റ്റം കാണിക്കുന്നു. കമ്മിറ്റി ചോദ്യം ഉത്തരം (സിക്യൂഎ). ഞങ്ങള്‍ ഒരു റാങ്ങിംഗ് സിസ്റ്റം നിര്‍മ്മിക്കുന്നു. വാക്ക് മേല്‍പ്പിച്ചുകൊണ്ട് ടെക്സ്റ്റ് ജോടികള്‍ക്ക പാരമ്പര്യമായ NLP വിശേഷതകള്‍ കൂടാതെ, നമ്മള്‍ കുറച്ചു പ്രധാനപ്പെട്ട നെയൂറല്‍ നെറ്റല്‍ നെറ്റോവര്‍ക്ക് അടിസ്ഥാനമായി പരിചയപ്പെടുത നമ്മുടെ സിസ്റ്റത്തിന്റെ പ്രധാനപ്പെടുത്തിയിരിക്കുന്നു നമ്മുടെ ബെസ്ലൈന്‍ രീതികള്‍ പ്രവര്‍ത്തിപ്പിക്കുന്നത്. രണ്ടാമത്തെ സ്ഥലം</abstract_ml>
      <abstract_ms>Kertas ini memperkenalkan sistem dalam SemEval-2017 Task 3, Community Question Answering (CQA). Kami mengembangkan sistem peringkat yang mampu menangkap hubungan semantik antara pasangan teks dengan perkataan yang sedikit meliputi. Selain ciri-ciri NLP tradisional, kami memperkenalkan beberapa ciri-ciri persamaan berasaskan rangkaian saraf yang membolehkan sistem kami mengukur kesamaan teks di luar leksikon. Sistem kita jauh melebihi kaedah asas dan memegang tempat kedua di Subtugas A dan tempat kelima di Subtugas B, yang menunjukkan kegunaannya pada pemilihan jawapan dan pemulihan soalan.</abstract_ms>
      <abstract_mt>This paper presents the system in SemEval-2017 Task 3, Community Question Answering (CQA).  Aħna niżviluppaw sistema ta' klassifikazzjoni li tkun kapaċi taqbad relazzjonijiet semantiċi bejn pari ta' testi bi ftit kliem li jaqblu. Minbarra l-karatteristiċi tradizzjonali tal-NLP, aħna nintroduċu diversi karatteristiċi ta’ tqabbil ibbażati fuq in-netwerk newrali li jippermettu lis-sistema tagħna tkejjel is-similarità tat-test lil hinn mill-lexicons. Is-sistema tagħna taqbeż b’mod sinifikanti l-metodi ta’ bażi u żżomm it-tieni post fis-Subkompitu A u l-ħames post fis-Subkompitu B, li juri l-effikaċja tagħha fl-għażla tat-tweġibiet u l-ġbir tal-mistoqsijiet.</abstract_mt>
      <abstract_mn>Энэ цаас нь системийг SemEval-2017 Task 3, Нийгмийн асуулт хариулт (CQA) дээр харуулдаг. Бид жижиг хэлбэртэй үг хоорондын зэрэгцээний харилцаа авах боломжтой тогтмол системийг бүтээж байна. Олон уламжлалт NLP боломжуудыг нэмбэл бид хэдэн мэдрэлийн сүлжээний төвөгтэй холбоотой чадварыг танилцуулдаг. Энэ нь бидний системийг Лексиконуудын илүү төвөгтэй дүрслэлийг хэмжих боломж Бидний систем суурь шугамын арга замыг илүүтэй хийдэг. Subtask A-д хоёр дахь орон, Subtask B-д 5 дахь орон байдаг. Энэ нь хариулт сонголт, асуулт авахын тулд нөлөөтэй байдлыг харуулдаг.</abstract_mn>
      <abstract_no>Denne papiret viser systemet i halvEval-2017 oppgåve 3, svar på spørsmål i fellesskapet (CQA). Vi utviklar eit rekningssystem som kan henta semantiske forhold mellom tekstpar med lite ordoverlapping. I tillegg til tradisjonelle NLP-funksjonar introduserer vi fleire neuralnettverksbaserte tilsvarande funksjonar som aktiverer systemet vårt for å måle tekstsimilaritet utenfor leksikon. Systemet vårt utfører vanleg baseline metodar og inneheld den andre plassen i Subtask A og femte plassen i Subtask B, som viser effektiviteten på utvalet av svar og oppgåve av spørsmål.</abstract_no>
      <abstract_pl>W artykule przedstawiono system w SemEval-2017 Task 3, Community Question Respwering (CQA). Opracowujemy system rankingu, który jest w stanie uchwycić relacje semantyczne pomiędzy parami tekstowymi z małym nakładaniem się słów. Oprócz tradycyjnych funkcji NLP wprowadzamy kilka funkcji dopasowania opartych na sieci neuronowej, które umożliwiają naszemu systemowi mierzenie podobieństwa tekstu poza leksykonami. Nasz system znacznie przewyższa metody bazowe i zajmuje drugie miejsce w Podzadaniu A i piąte miejsce w Podzadaniu B, co pokazuje swoją skuteczność w wyborze odpowiedzi i pobieraniu pytań.</abstract_pl>
      <abstract_ro>Această lucrare prezintă sistemul în Sarcina 3 SemEval-2017, Răspunsul la întrebări comunitare (CQA). Dezvoltăm un sistem de clasificare capabil să capteze relațiile semantice dintre perechile de text cu suprapunere mică de cuvinte. În plus față de caracteristicile tradiționale NLP, introducem mai multe caracteristici de potrivire bazate pe rețele neurale care permit sistemului nostru să măsoare similaritatea textului dincolo de lexicoane. Sistemul nostru depășește semnificativ metodele de bază și deține locul doi în Subsarcina A și locul cinci în Subsarcina B, ceea ce demonstrează eficacitatea sa în selectarea răspunsurilor și recuperarea întrebărilor.</abstract_ro>
      <abstract_sr>Ovaj papir predstavlja sistem u zadatku 3. za pola Evala-2017, odgovor na pitanja zajednice (CQA). Razvijamo sistem za ranking koji je sposoban da uhvati semantičke odnose između parova teksta sa malim riječima preklapanjem. Uz tradicionalne NLP karakteristike, predstavljamo nekoliko neuralnih mreža baziranih odgovarajućih karakteristika koje omogućavaju naš sistem da mjeri sličnost teksta izvan leksiona. Naš sistem značajno iznosi početne metode i drži drugo mesto u subtask A i petom mestu u subtask B, što pokazuje svoju efikasnost na odabiru odgovora i povratku pitanja.</abstract_sr>
      <abstract_si>මේ පැත්තේ පද්ධතිය සෙම්වෙල්-2017 වැඩක් 3, සමාජ ප්‍රශ්න ප්‍රශ්න ප්‍රතිච්චාරය (CQA). අපි ප්‍රමාණ පද්ධතියක් හොයාගන්න පුළුවන් විදිහට පැත්තක් සම්බන්ධතාවක් අල්ලගන්න. පාරමාන්‍ය NLP අවශ්‍යතාවය සමග, අපි ප්‍රමාණය සම්බන්ධ විශේෂතාවක් විතරයි, අපේ පද්ධතිය ලෙක්සිකන්ස් වලින් පැත අපේ පද්ධතිය විශේෂයෙන් අධ්‍යාත්මක විධානය කරන්න පුළුවන් විදියට වැඩ කරනවා ඒ වගේම අධ්‍යාත්මක A වල දෙවෙනි ස්ථානයේ තියෙනවා</abstract_si>
      <abstract_sv>Denna uppsats presenterar systemet i SemEval-2017 Task 3, Community Question Answering (CQA). Vi utvecklar ett rankningssystem som kan fånga semantiska relationer mellan textpar med liten ordöverlappning. Förutom traditionella NLP-funktioner introducerar vi flera neurala nätverksbaserade matchningsfunktioner som gör det möjligt för vårt system att mäta textlikhet bortom lexikon. Vårt system överträffar signifikant baslinjemetoder och innehar andraplatsen i deluppgift A och femte plats i deluppgift B, vilket visar sin effektivitet på svarsval och frågesökning.</abstract_sv>
      <abstract_ta>இந்த தாள் செம்Eval- 2017 பணியில் அமைப்பை வழங்குகிறது, சமுதாயத்தின் கேள்வி பதில் (CQA). நாம் சிறிய வார்த்தை மேற்கொண்டு உரை ஜோடிகளுக்கிடையில் இருந்து பாதிப்பு தொடர்புகளை பிடித்துக் கொள்ள மரபார்ந்த NLP குணங்களை கூட, நாம் பல புதிய வலைப்பின்னலை பொருத்தும் குணங்களை குறிப்பிடுகிறோம். இது எங்கள் கணினியை லெக்சிக்ஸ எங்கள் அமைப்பு அடிப்படையில் முறையில் செயல்படுத்துகிறது மற்றும் துப்பணி B ல் இரண்டாவது இடத்தில் இருக்கிறது, அது பதில் தேர்வு தேர்வு மற்றும்</abstract_ta>
      <abstract_ur>This paper presents the system in SemEval-2017 Task 3, Community Question Answering (CQA). ہم ایک رقم سیسٹم ایجاد کر رہے ہیں جو ٹیکسٹ جوڑوں کے درمیان سیمانٹی رابطہ حاصل کرسکتی ہے اور تھوڑی کلمات پر مزید مزید مزید ہے۔ اس کے علاوہ ہم بہت سی نئورل نیٹ ورک کے متعلق مطابق مطابق فیصلہ کریں جو ہمارے سیستم کو لکسیون کے بعد متن مطابق مطابق اندازے کے لئے اجازت دیتے ہیں. ہمارا سیستم بنسٹ لین طریقے سے زیادہ زیادہ کامل ہوتا ہے اور دوسری جگہ Subtask A میں ہے اور پانچویں جگہ Subtask B میں ہے، جو جواب کے انتخاب اور سوال کے اٹھانے پر اثرات دکھاتا ہے۔</abstract_ur>
      <abstract_so>This paper presents the system in SemEval-2017 Task 3, Community Question Answering (CQA).  Waxaynu korinaynaa nidaam aad leedahay, taasoo awoodi kara inuu qabsado xiriir siman oo u dhaxaysa labada labood ee qoraal ah oo ku qoran hadal yar. Xiriikhda asalka ah ee NLP waxaa dheer oo aan soo bandhignaa shabakado neuro ah oo ku saleysan tayooyin la eg, taasoo awoodi kara nidaamka aan ku qiyaasto qoraal isku mid ah oo aan leksikanka ka badnayn. nidaamkayaga ayaa si weyn u sameeya qaabab hoose-dhig ah, wuxuuna xajiyaa meeshii labaad ee Subtask A iyo meeshii shanaad ee Subtask B, taasoo muujiya saamaynta ku saabsan doorashada iyo soo celinta su'aalaha.</abstract_so>
      <abstract_uz>This paper presents the system in SemEval-2017 Task 3, Community Question Answering (CQA).  Biz chegara tizimni yaratib, bir so'zlar bir kichik so'zlar bilan bir semantik aloqalarni olib tashlash mumkin. Biz bir necha neyrol tarmoqni o'rganamiz. Bu tizimmizni leksikondan keyin bir xil tilni o'zgartirish imkoniyatlariga foydalanadi. Bizning tizimimiz asosiy usullarini bajaradi va Subtask B'da ikkinchi joyni boshlaydi. Bu javob tanlash va savol olish uchun javob beradi.</abstract_uz>
      <abstract_vi>Tờ giấy này giới thiệu hệ thống trong Nhiệm vụ Semkhai-thẩm 7, Trả lời câu hỏi của Cộng đồng (CQA). Chúng tôi phát triển một hệ thống xếp hạng có khả năng nắm bắt quan hệ theo ngữ nghĩa giữa hai chữ với một sự gấp bội nhỏ. Ngoài những tính năng ngLP, chúng tôi còn thiết nhiều tính năng liên kết dựa trên mạng thần kinh, nhờ đó hệ thống có khả năng đo mức độ tương đồng văn bản vượt qua ngôn ngữ. Hệ thống của chúng ta hoàn thiện các phương pháp cơ bản và nắm giữ vị trí thứ hai trong Subhỏi A và vị trí thứ năm của giấu B, chứng minh hiệu quả khi chọn câu trả lời và lấy câu hỏi.</abstract_vi>
      <abstract_da>Denne artikel præsenterer systemet i SemEval-2017 Task 3, Community Question Answering (CQA). Vi udvikler et rangeringssystem, der er i stand til at fange semantiske relationer mellem tekstpar med lidt ordoverlapning. Ud over traditionelle NLP funktioner introducerer vi flere neurale netværksbaserede matchningsfunktioner, som gør det muligt for vores system at måle tekst lighed ud over leksikoner. Vores system overgår grundlæggende metoder betydeligt og holder andenpladsen i underopgave A og femtepladsen i underopgave B, hvilket demonstrerer dets effektivitet på besvarelse og spørgsmålshentning.</abstract_da>
      <abstract_bg>Настоящата статия представя системата в задача 3, Отговаряне на въпроси на Общността. Разработваме система за класиране, която е способна да улавя семантични връзки между текстови двойки с малко припокриване на думи. В допълнение към традиционните функции на НЛП, ние въвеждаме няколко базирани на невронна мрежа съвпадение функции, които позволяват на нашата система да измерва сходството на текста извън лексиконите. Системата ни значително надминава базовите методи и заема второ място в подзадача А и пето място в подзадача Б, което демонстрира ефективността си при избора на отговори и извличането на въпроси.</abstract_bg>
      <abstract_hr>Ovaj papir predstavlja sustav u zadatku 3. za pola Evala-2017, odgovor na pitanja zajednice (CQA). Razvijemo redovni sustav koji je sposoban da uhvati semantičke odnose između tekstskih parova sa malim riječima. Uz tradicionalne funkcije NLP-a, predstavljamo nekoliko podudarajućih funkcija neuralne mreže koje omogućavaju naš sustav mjeriti sličnost teksta izvan leksiona. Naš sustav značajno iznosi početne metode i drži drugo mjesto u podzadatku A i petom mjestu u podzadatku B, što pokazuje svoju djelotvornost na izboru odgovora i povlačenju pitanja.</abstract_hr>
      <abstract_id>Kertas ini memperkenalkan sistem dalam SemEval-2017 Task 3, Community Question Answering (CQA). Kami mengembangkan sistem peringkat yang mampu menangkap hubungan semantis antara pasangan teks dengan sedikit saling bertindak kata. Selain ciri-ciri tradisional NLP, kami memperkenalkan beberapa ciri-ciri persamaan jaringan saraf yang berdasarkan yang memungkinkan sistem kami untuk mengukur kesamaan teks di luar lexikon. Sistem kita jauh melebihi metode dasar dan memegang tempat kedua di Subtask A dan tempat kelima di Subtask B, yang menunjukkan efektivitasnya pada seleksi jawaban dan penulisan pertanyaan.</abstract_id>
      <abstract_de>Dieser Beitrag stellt das System in SemEval-2017 Task 3, Community Question Answering (CQA) vor. Wir entwickeln ein Rankingsystem, das in der Lage ist, semantische Beziehungen zwischen Textpaaren mit geringer Wortüberlappung zu erfassen. Zusätzlich zu den traditionellen NLP-Funktionen führen wir mehrere neuronale Netzwerk-basierte Matching-Funktionen ein, mit denen unser System Textähnlichkeit jenseits von Lexikonen messen kann. Unser System übertrifft die Basismethoden deutlich und belegt den zweiten Platz in Teilaufgabe A und den fünften Platz in Teilaufgabe B, was seine Wirksamkeit bei der Antwortauswahl und dem Abfragen von Fragen demonstriert.</abstract_de>
      <abstract_nl>Dit document presenteert het systeem in SemEval-2017 Taak 3, Community Question Respwering (CQA). We ontwikkelen een ranking systeem dat in staat is semantische relaties tussen tekstparen met kleine woordoverlapping vast te leggen. Naast traditionele NLP-functies introduceren we verschillende op neuraal netwerk gebaseerde matching-functies waarmee ons systeem tekstgelijkenis kan meten buiten lexicons. Ons systeem presteert aanzienlijk beter dan baseline methodes en houdt de tweede plaats in Subtaak A en de vijfde plaats in Subtaak B, wat aantoont dat het effectief is bij het selecteren van antwoorden en het ophalen van vragen.</abstract_nl>
      <abstract_sw>Makala hii inaonyesha mfumo wa SemEval-2017 kazi 3, Swali la Jamii (CQA). Tunaendeleza mfumo wa rangi ambao una uwezo wa kupata mahusiano ya kimapenzi kati ya wanandoa wa maandishi wenye maneno madogo. Zaidi ya vipengele vya kitamaduni vya NLP, tunaonyesha mitandao kadhaa ya neurali inayohusiana na vipengele vinavyowezesha mfumo wetu kupima ujumbe wa simu zaidi ya lexico. Mfumo wetu unafanya mbinu za msingi na inashikilia nafasi ya pili katika Ujumbe A na nafasi ya tano katika Subtask B, ambayo inaonyesha ufanisi wake wa kujibu uchaguzi na kurejesha swali.</abstract_sw>
      <abstract_fa>این کاغذ سیستم را در نیمه سال ۲۰۱۷، پاسخ سؤال اجتماعی (CQA) نشان می‌دهد. ما یک سیستم صفحه‌ای را توسعه می‌کنیم که قادر است رابطه‌های طبیعی بین جفت‌های متن با کلمه‌های کوچک بالا برد. علاوه بر ویژگی‌های NLP سنتی، چند ویژگی‌های متفاوت بر پایه شبکه‌های عصبی را معرفی می‌کنیم که سیستم ما را برای اندازه‌گیری شبیه‌های متن فراتر از لکسیون اجازه می‌دهد. سیستم ما خیلی زیادی از روش‌های پایه‌خط انجام می‌دهد و دومین مکان در پایه‌کار A و پنجمین مکان در پایه‌کار B را دارد که عملکرد خود را بر انتخاب پاسخ و بازیابی سوال نشان می‌دهد.</abstract_fa>
      <abstract_ko>본고는SemEval-2017 퀘스트 3 커뮤니티 퀴즈(CQA)의 시스템을 소개한다.우리는 단어가 거의 겹치지 않는 상황에서 텍스트의 의미 관계를 포착할 수 있는 랭킹 시스템을 개발했다.전통적인 NLP 특징 외에 우리는 몇 가지 신경 네트워크를 바탕으로 하는 일치 특징을 소개했는데 이런 특징들은 우리 시스템이 어휘 이외의 텍스트의 유사성을 측정할 수 있게 한다.우리의 시스템은 기본 방법보다 현저히 우수하다. 하위 임무 A에서 2위, 하위 임무 B에서 5위를 차지한다. 이것은 답안 선택과 문제 검색에 있어 유효성을 나타낸다.</abstract_ko>
      <abstract_am>ይህ ገጽ ስርዓቱን በSemEval-2017 ስርዓት 3፣ Community Question Answer (CQA) ያቀርባል፡፡ We develop a ranking system that is capable of capturing semantic relations between text pairs with little word overlap.  ከባሕላዊ NLP ምርጫዎች በቀር፣ ከሌክሲኮን በላይ የጽሑፉን ብጤት እንዲያሰናክል እናስፈልጋለን፡፡ ስርዓታችን የጥያቄ ሥርዓት እና ሁለተኛውን ቦታ በSubtask B እና አምስተኛው ስፍራ ይኖራል፡፡</abstract_am>
      <abstract_sq>Ky dokument paraqet sistemin në SemEval-2017 Task 3, Community Question Answering (CQA). Ne zhvillojmë një sistem renditjeje që është në gjendje të kapë marrëdhënie semantike midis çifteve teksti me fjalë të vogla mbishtypje. Përveç karakteristikave tradicionale të NLP, ne futim disa karakteristika të barazimit me rrjetin nervor që lejojnë sistemin tonë të matë ngjashmërinë e tekstit përtej lexikonëve. Sistemi ynë mbikalon ndjeshëm metodat bazë dhe mban vendin e dytë në Subtask A dhe vendin e pestë në Subtask B, që tregon efektshmërinë e tij në zgjedhjen e përgjigjeve dhe marrjen e pyetjeve.</abstract_sq>
      <abstract_tr>Bu kagyz sistemi SemEval-2017 Görevi 3, jemgyýet soragy jogaplamagy (CQA) içinde belleýär. Biz küçük söz doly metin çiftleri arasynda semantik ilişkileri almak üçin bir derejli sistemi gelişýäris. Däpli NLP karakterleriň üstine, biz näral şebekeleriň beýleki eşleşmelerini tapdyryp, sistemimiziň leksiýalardan öňki metin meňzeşliklerini ölçürmegini mümkin edip bilýäris. Bizim sistemamyz basit yöntemleri çykar we ikinji ýerini Subtask A we Subtask B'de beşinji ýerini tutar. Bu ýerde jogap saýlamak we soraglary almak üçin etkinligini görkez.</abstract_tr>
      <abstract_bn>এই পত্রিকাটি সেমইভাল-২০১৭ কার্যক্রম ৩, কমিউনিটি প্রশ্নের উত্তর (সিকিয়াএ) সিস্টেম উপস্থাপন করেছে। We develop a ranking system that is capable of capturing semantic relations between text pairs with little word overlap.  ঐতিহ্যবাহী এনএলপি বৈশিষ্ট্য ছাড়াও আমরা বেশ কয়েকটি নিউরেল নেটওয়ার্কের সাথে মিলিয়ে যাচ্ছি বৈশিষ্ট্য যা লেক্সিকোন বাইরে লে আমাদের সিস্টেম গুরুত্বপূর্ণ ভিত্তিক পদ্ধতি প্রদর্শন করে এবং সাবাবাজ বিতে দ্বিতীয় স্থান রাখে, যা উত্তর নির্বাচন এবং প্রশ্ন পুনরুদ্ধারে</abstract_bn>
      <abstract_hy>Այս փաստաթղթին ներկայացնում է համակարգը «ՍեմԵվալ 2017» 3. հանրային հարցերի պատասխանը (CQA). Մենք զարգանում ենք դասակարգման համակարգ, որը կարողանում է զբաղվել սեմանտիկ հարաբերություններով տեքստի զույգերի միջև փոքր բառերի կողմից: Բացի ավանդական ՆԼՊ հատկանիշներից, մենք ներկայացնում ենք մի քանի նյարդային ցանցի հիմնված հատկանիշներ, որոնք հնարավորություն են տալիս մեր համակարգին չափել տեքստի նմանությունը լեքսիկոններից դուրս: Մեր համակարգը նշանակալիորեն գերազանցում է հիմնական մեթոդները և պահպանում է երկրորդ տեղը Սիբ-հանձնարարության A-ում և հինգերորդ տեղը Սիբ-հանձնարարության B-ում, ինչը ցույց է տալիս իր արդյունավետությունը պատասխան</abstract_hy>
      <abstract_az>Bu kağıt sistemi SemEval-2017 Task 3, CQA soruşu cavab verir. Biz mətn çiftləri arasındakı semantik ilişkileri küçük sözlərin üstünü alan səf sistemini təhsil edirik. Əlavə NLP özelliklərinə bənzər nöral ağ tərəfindən istifadə edirik ki, sistemimizin leksiklərdən ötrü metin similaritəsini ölçüyə qadir olur. Sistemimiz əsas çətinliklərdən çox üstün gəlir və A Subtask'də ikinci yeri və B Subtask'də beşinci yeri tutar. Bu, cevap seçməsində və sual almaqda etkinlik göstərir.</abstract_az>
      <abstract_af>Hierdie papier stel die stelsel in SemEval-2017 Opdrag 3, gemeenskapsvraag antwoord (CQA). Ons ontwikkel 'n ranking stelsel wat is in staat om semantiese relasies tussen teks paar te vang met klein woord oorvloei. In addition to traditional NLP features, we introduce several neural network based matching features which enable our system to measure text similarity beyond lexicons. Ons stelsel buitengewoon uitvoer basisline metodes en hou die tweede plek in Subtask A en die vyfde plek in Subtask B, wat sy effektiviteit vertoon op antwoord-keuse en vraag ontvang.</abstract_af>
      <abstract_et>Käesolevas töös tutvustatakse süsteemi SemEval-2017 ülesandes 3, ühenduse küsimustele vastamine (CQA). Töötame välja järjestussüsteemi, mis suudab jäädvustada semantilisi seoseid tekstipaaride vahel vähese kattumisega. Lisaks traditsioonilistele NLP funktsioonidele tutvustame mitmeid närvivõrgupõhiseid sobitamisfunktsioone, mis võimaldavad meie süsteemil mõõta teksti sarnasust väljaspool leksikone. Meie süsteem ületab oluliselt baasmeetodeid ja on teisel kohal alaülesandes A ja viiendal kohal alaülesandes B, mis näitab oma efektiivsust vastuste valimisel ja küsimuste leidmisel.</abstract_et>
      <abstract_bs>Ovaj papir predstavlja sistem u zadatku 3. za pola Evala-2017, odgovor na pitanja zajednice (CQA). Mi razvijamo sistem reda koji je sposoban da uhvati semantičke odnose između parova teksta sa malim riječima. Uz tradicionalne NLP karakteristike, predstavljamo nekoliko neuralnih mreža baziranih odgovarajućih karakteristika koje omogućavaju naš sistem da mjeri sličnost teksta izvan leksiona. Naš sistem značajno iznosi početne metode i drži drugo mjesto u podzadatku A i petom mjestu u podzadatku B, što pokazuje svoju učinkovitost na izboru odgovora i povlačenju pitanja.</abstract_bs>
      <abstract_ca>Aquest paper presenta el sistema en SemEval-2017 Task 3, Community Question Answering (CQA). Desenvolvem un sistema de classificació capaç de capturar relacions semàntiques entre parelles de textos amb poca sobreposió de paraules. A més de les característiques tradicionals del NLP, introduïm diverses característiques de comparació basades en la xarxa neural que permeten al nostre sistema mesurar la similitud del text més enllà dels lexicòns. El nostre sistema supera significativament els mètodes de base i manté el segon lloc a la Subtasca A i el quint lloc a la Subtasca B, que demostra la seva eficacia en la selecció de respostes i la recuperació de preguntes.</abstract_ca>
      <abstract_cs>Tento článek prezentuje systém v SemEval-2017 Task 3, Community Question Answering (CQA). Vyvíjíme systém hodnocení, který je schopen zachytit sémantické vztahy mezi textovými páry s malým překrytím slov. Kromě tradičních funkcí NLP představujeme několik funkcí porovnávání založených na neuronové síti, které umožňují našemu systému měřit podobnost textu mimo lexikon. Náš systém výrazně překonává základní metody a drží druhé místo v podúkolu A a páté místo v podúkolu B, což dokazuje svou účinnost při výběru odpovědi a vyhledávání otázek.</abstract_cs>
      <abstract_fi>Tämä artikkeli esittelee järjestelmän SemEval-2017 Task 3, Community Question Answering (CQA). Kehitämme ranking-järjestelmän, joka kykenee kuvaamaan semanttisia suhteita tekstiparejen välillä, joilla on vähän päällekkäisyyksiä. Perinteisten NLP-ominaisuuksien lisäksi esittelemme useita neuroverkkoihin perustuvia yhteensopivuusominaisuuksia, joiden avulla järjestelmämme pystyy mittaamaan tekstin samankaltaisuutta sanaston ulkopuolella. Järjestelmämme suoriutuu merkittävästi lähtötason menetelmistä ja on toisella sijalla osatehtävässä A ja viidennellä sijalla osatehtävässä B, mikä osoittaa sen tehokkuuden vastausten valinnassa ja kysymysten hakemisessa.</abstract_fi>
      <abstract_jv>Ngawe Perintah-ne saiki sistem kanggo seminval-2011 task 3, Ngusungkamu Gales Kumpulan (CqA). Awak dhéwé nggawe sistem sing paling-urip kuwi iso nggawe semanti karo pawaran gambaran seneng pisan kelas kuwi duluran. Nambah tanggal NLP perusahaan, kita sampeyan akeh operasi sing dibutuhke alam sing dibutuhke butar sampeyan nggawe sistem kanggo meh sampeyan teks seneng luwih apik leyekon. Sistem awak dhéwé ngerasakno sistem sing beraksi perusahaan bakal sing dumateng liyane karo Subtask A lan basa sing lima nang Subtask B, sing bisa nguasakno efekasi kanggo langgar-awak dhéwé lan pangan werong.</abstract_jv>
      <abstract_sk>Ta prispevek predstavlja sistem v nalogi 3 SemEval-2017, Odgovarjanje na vprašanja Skupnosti (CQA). Razvijamo sistem razvrščanja, ki je sposoben zajemati semantične relacije med besedilnimi pari z majhnim prekrivanjem besed. Poleg tradicionalnih funkcij NLP uvajamo več funkcij ujemanja na podlagi nevronskih omrežij, ki omogočajo našemu sistemu merjenje podobnosti besedila preko leksikonov. Naš sistem bistveno presega osnovne metode in ima drugo mesto v podnalogi A in peto mesto v podnalogi B, kar dokazuje njegovo učinkovitost pri izbiri odgovorov in iskanju vprašanj.</abstract_sk>
      <abstract_he>העבודה הזו מציגה את המערכת במשימה 3 SemEval-2017, תשובת שאלות קהילתית (CQA). אנחנו מפתחים מערכת מעמד שיכולה לתפוס מערכות יחסים סמנטיות בין זוגות טקסט עם מילים מעט מתקפלות. בנוסף לתחומים מסורתיים של NLP, אנחנו מכירים מספר תכונות התאמה מבוססים ברשת עצבית שמאפשרים למערכת שלנו למדוד דומות טקסט מעבר ללקסיקונים. המערכת שלנו מעליפה את שיטות הבסיס באופן משמעותי ומחזיקה את המקום השני בתפקיד א' והמקום החמישי בתפקיד ב', מה שמוכיח את יעילותו בבחירת תשובות ובחיפוש שאלות.</abstract_he>
      <abstract_ha>Bu takardan na gaya na'ura cikin aikin SemEV-2017, Jabu na Jami'in Jamii (CQA). Tuna buɗe wani matsayi mai rangi wanda zai iya iya samo danganiya na semanti a tsakanin nau'i-nau'in matsayi da nauyi. Babu bayan tayari na NLP, za'a ƙunsa da wasu na'urar tarayya na neural wanda ke daidaita wasu tayari da ke daidai, wanda ya iya amfani da system don ya daidaita matsayin. Ana nuna muhimmin shirin ayukanmu na samar hanyõyin bazata kuma yana riƙe na saurin na biyu a cikin Subaikin A da na shan wurin a Subaikin B, wanda ya nuna fassararsa a kan zãɓen su da tambayar.</abstract_ha>
      <abstract_bo>ཤོག་བྱང་འདིས་དེ་ལྟ་བུའི་ནང་དུ་རིམ་ལྟ་བུའི་ལས་འགུལ་གྱི་གནད་སྡུད་སའི་དོན་ལ་ ཚོགས་སྡེའི་གནས་ཚུལ་ལོགས་ལ ང་ཚོས་ཡིག་གི་མཐོ་རིམ་དང་ཐིག་ཁྲམ་མེད་པའི་ལྟར་གྱི་རིམ་པ་ཞིག་གིས་ཕན་ཚུན་འབྲེལ་འདུག སྔོན་སྲོལ་གྱི་NLP་ཆ་ཁྱད་པར་བསྡུར་ན། ང་ཚོས་རང་ཉིད་ཀྱི་དྲ་རྒྱ་སྟངས་ལ་མཐུན་པའི་ཆ་ཁྱད་ཆོས་ཉེན ང་ཚོའི་མ་ལག</abstract_bo>
      </paper>
    <paper id="46">
      <title>MoRS at SemEval-2017 Task 3 : Easy to use SVM in Ranking Tasks<fixed-case>M</fixed-case>o<fixed-case>RS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Easy to use <fixed-case>SVM</fixed-case> in Ranking Tasks</title>
      <author><first>Miguel J.</first> <last>Rodrigues</last></author>
      <author><first>Francisco M.</first> <last>Couto</last></author>
      <pages>287–291</pages>
      <url hash="f41a1fd8">S17-2046</url>
      <doi>10.18653/v1/S17-2046</doi>
      <abstract>This paper describes our system, dubbed MoRS (Modular Ranking System), pronounced ‘Morse’, which participated in Task 3 of SemEval-2017. We used MoRS to perform the Community Question Answering Task 3, which consisted on reordering a set of comments according to their usefulness in answering the question in the thread. This was made for a large collection of questions created by a user community. As for this challenge we wanted to go back to simple, easy-to-use, and somewhat forgotten technologies that we think, in the hands of non-expert people, could be reused in their own data sets. Some of our techniques included the annotation of text, the retrieval of meta-data for each comment, <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">POS tagging</a> and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">Named Entity Recognition</a>, among others. These gave place to <a href="https://en.wikipedia.org/wiki/Syntax">syntactical analysis</a> and semantic measurements. Finally we show and discuss our results and the context of our approach, which is part of a more comprehensive <a href="https://en.wikipedia.org/wiki/System">system</a> in development, named MoQA.</abstract>
      <bibkey>rodrigues-couto-2017-mors</bibkey>
    </paper>
    <paper id="47">
      <title>EICA Team at SemEval-2017 Task 3 : Semantic and Metadata-based Features for Community Question Answering<fixed-case>EICA</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Semantic and Metadata-based Features for Community Question Answering</title>
      <author><first>Yufei</first> <last>Xie</last></author>
      <author><first>Maoquan</first> <last>Wang</last></author>
      <author><first>Jing</first> <last>Ma</last></author>
      <author><first>Jian</first> <last>Jiang</last></author>
      <author><first>Zhao</first> <last>Lu</last></author>
      <pages>292–298</pages>
      <url hash="b95f0d69">S17-2047</url>
      <doi>10.18653/v1/S17-2047</doi>
      <abstract>We describe our <a href="https://en.wikipedia.org/wiki/System">system</a> for participating in SemEval-2017 Task 3 on Community Question Answering. Our approach relies on combining a rich set of various types of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> : <a href="https://en.wikipedia.org/wiki/Semantic_Web">semantic</a> and <a href="https://en.wikipedia.org/wiki/Metadata">metadata</a>. The most important group turned out to be the metadata feature and the semantic vectors trained on QatarLiving data. In the main Subtask C, our primary submission was ranked fourth, with a <a href="https://en.wikipedia.org/wiki/Markup_language">MAP</a> of 13.48 and <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 97.08. In Subtask A, our primary submission get into the top 50 %.</abstract>
      <bibkey>xie-etal-2017-eica</bibkey>
    </paper>
    <paper id="48">
      <title>FA3L at SemEval-2017 Task 3 : A ThRee Embeddings Recurrent Neural Network for Question Answering<fixed-case>FA</fixed-case>3<fixed-case>L</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: A <fixed-case>T</fixed-case>h<fixed-case>R</fixed-case>ee Embeddings Recurrent Neural Network for Question Answering</title>
      <author><first>Giuseppe</first> <last>Attardi</last></author>
      <author><first>Antonio</first> <last>Carta</last></author>
      <author><first>Federico</first> <last>Errica</last></author>
      <author><first>Andrea</first> <last>Madotto</last></author>
      <author><first>Ludovica</first> <last>Pannitto</last></author>
      <pages>299–304</pages>
      <url hash="c4a4cd18">S17-2048</url>
      <doi>10.18653/v1/S17-2048</doi>
      <abstract>In this paper we present ThReeNN, a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for Community Question Answering, Task 3, of SemEval-2017. The proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> exploits both syntactic and semantic information to build a single and meaningful <a href="https://en.wikipedia.org/wiki/Embedding">embedding space</a>. Using a <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parser</a> in combination with <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, the model creates sequences of inputs for a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Network</a>, which are then used for the ranking purposes of the Task. The score obtained on the <a href="https://en.wikipedia.org/wiki/Test_(assessment)">official test data</a> shows promising results.</abstract>
      <bibkey>attardi-etal-2017-fa3l</bibkey>
    </paper>
    <paper id="49">
      <title>SCIR-QA at SemEval-2017 Task 3 : CNN Model Based on Similar and Dissimilar Information between Keywords for Question Similarity<fixed-case>SCIR</fixed-case>-<fixed-case>QA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: <fixed-case>CNN</fixed-case> Model Based on Similar and Dissimilar Information between Keywords for Question Similarity</title>
      <author><first>Le</first> <last>Qi</last></author>
      <author><first>Yu</first> <last>Zhang</last></author>
      <author><first>Ting</first> <last>Liu</last></author>
      <pages>305–309</pages>
      <url hash="b79fd6e2">S17-2049</url>
      <doi>10.18653/v1/S17-2049</doi>
      <abstract>We describe a method of calculating the similarity of questions in community QA. Question in <a href="https://en.wikipedia.org/wiki/CQA">cQA</a> are usually very long and there are a lot of useless information about calculating the similarity of questions. Therefore, we implement a CNN model based on <a href="https://en.wikipedia.org/wiki/Similarity_measure">similar and dissimilar information</a> between question’s keywords. We extract the keywords of questions, and then model the similar and dissimilar information between the <a href="https://en.wikipedia.org/wiki/Index_term">keywords</a>, and use the CNN model to calculate the similarity.</abstract>
      <bibkey>qi-etal-2017-scir</bibkey>
    </paper>
    <paper id="50">
      <title>LearningToQuestion at SemEval 2017 Task 3 : Ranking Similar Questions by Learning to Rank Using Rich Features<fixed-case>L</fixed-case>earning<fixed-case>T</fixed-case>o<fixed-case>Q</fixed-case>uestion at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2017 Task 3: Ranking Similar Questions by Learning to Rank Using Rich Features</title>
      <author><first>Naman</first> <last>Goyal</last></author>
      <pages>310–314</pages>
      <url hash="ddbdf000">S17-2050</url>
      <doi>10.18653/v1/S17-2050</doi>
      <abstract>This paper describes our official entry LearningToQuestion for SemEval 2017 task 3 community question answer, subtask B. The objective is to rerank questions obtained in <a href="https://en.wikipedia.org/wiki/Internet_forum">web forum</a> as per their similarity to original question. Our system uses pairwise learning to rank methods on rich set of hand designed and representation learning features. We use various semantic features that help our <a href="https://en.wikipedia.org/wiki/System">system</a> to achieve promising results on the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. The <a href="https://en.wikipedia.org/wiki/System">system</a> achieved second highest results on official metrics MAP and good results on other <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">search metrics</a>.</abstract>
      <bibkey>goyal-2017-learningtoquestion</bibkey>
    </paper>
    <paper id="51">
      <title>SimBow at SemEval-2017 Task 3 : Soft-Cosine Semantic Similarity between Questions for Community Question Answering<fixed-case>S</fixed-case>im<fixed-case>B</fixed-case>ow at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Soft-Cosine Semantic Similarity between Questions for Community Question Answering</title>
      <author><first>Delphine</first> <last>Charlet</last></author>
      <author><first>Géraldine</first> <last>Damnati</last></author>
      <pages>315–319</pages>
      <url hash="1243c0bd">S17-2051</url>
      <doi>10.18653/v1/S17-2051</doi>
      <abstract>This paper describes the SimBow system submitted at SemEval2017-Task3, for the question-question similarity subtask B. The proposed approach is a supervised combination of different unsupervised textual similarities. These textual similarities rely on the introduction of a relation matrix in the classical <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> between bag-of-words, so as to get a soft-cosine that takes into account relations between words. According to the type of relation matrix embedded in the soft-cosine, semantic or lexical relations can be considered. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked first among the official submissions of subtask B.</abstract>
      <bibkey>charlet-damnati-2017-simbow-semeval</bibkey>
    </paper>
    <paper id="52">
      <title>FuRongWang at SemEval-2017 Task 3 : Deep Neural Networks for Selecting Relevant Answers in Community Question Answering<fixed-case>F</fixed-case>u<fixed-case>R</fixed-case>ong<fixed-case>W</fixed-case>ang at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Deep Neural Networks for Selecting Relevant Answers in Community Question Answering</title>
      <author><first>Sheng</first> <last>Zhang</last></author>
      <author><first>Jiajun</first> <last>Cheng</last></author>
      <author><first>Hui</first> <last>Wang</last></author>
      <author><first>Xin</first> <last>Zhang</last></author>
      <author><first>Pei</first> <last>Li</last></author>
      <author><first>Zhaoyun</first> <last>Ding</last></author>
      <pages>320–325</pages>
      <url hash="561993e3">S17-2052</url>
      <doi>10.18653/v1/S17-2052</doi>
      <abstract>We describes deep neural networks frameworks in this paper to address the community question answering (cQA) ranking task (SemEval-2017 task 3). Convolutional neural networks and bi-directional long-short term memory networks are applied in our methods to extract semantic information from questions and answers (comments). In addition, in order to take the full advantage of question-comment semantic relevance, we deploy interaction layer and augmented features before calculating the <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a>. The results show that our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> have the great effectiveness for both subtask A and subtask C.</abstract>
      <bibkey>zhang-etal-2017-furongwang</bibkey>
    </paper>
    <paper id="53">
      <title>KeLP at SemEval-2017 Task 3 : Learning Pairwise Patterns in Community Question Answering<fixed-case>K</fixed-case>e<fixed-case>LP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Learning Pairwise Patterns in Community Question Answering</title>
      <author><first>Simone</first> <last>Filice</last></author>
      <author><first>Giovanni</first> <last>Da San Martino</last></author>
      <author><first>Alessandro</first> <last>Moschitti</last></author>
      <pages>326–333</pages>
      <url hash="2934b7d1">S17-2053</url>
      <doi>10.18653/v1/S17-2053</doi>
      <abstract>This paper describes the KeLP system participating in the SemEval-2017 community Question Answering (cQA) task. The system is a refinement of the kernel-based sentence pair modeling we proposed for the previous year challenge. It is implemented within the Kernel-based Learning Platform called KeLP, from which we inherit the team’s name. Our primary submission ranked first in subtask A, and third in subtasks B and C, being the only systems appearing in the top-3 ranking for all the English subtasks. This shows that the proposed <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>, which has minor variations among the three subtasks, is extremely flexible and effective in tackling learning tasks defined on sentence pairs.</abstract>
      <bibkey>filice-etal-2017-kelp</bibkey>
    </paper>
    <paper id="54">
      <title>SwissAlps at SemEval-2017 Task 3 : Attention-based Convolutional Neural Network for Community Question Answering<fixed-case>S</fixed-case>wiss<fixed-case>A</fixed-case>lps at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Attention-based Convolutional Neural Network for Community Question Answering</title>
      <author><first>Jan Milan</first> <last>Deriu</last></author>
      <author><first>Mark</first> <last>Cieliebak</last></author>
      <pages>334–338</pages>
      <url hash="f96125b2">S17-2054</url>
      <doi>10.18653/v1/S17-2054</doi>
      <abstract>In this paper we propose a <a href="https://en.wikipedia.org/wiki/System">system</a> for reranking answers for a given question. Our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> builds on a siamese CNN architecture which is extended by two attention mechanisms. The approach was evaluated on the datasets of the SemEval-2017 competition for Community Question Answering (cQA), where it achieved 7th place obtaining a MAP score of 86:24 points on the Question-Comment Similarity subtask.</abstract>
      <bibkey>deriu-cieliebak-2017-swissalps</bibkey>
      <pwccode url="https://github.com/jderiu/community_qa" additional="false">jderiu/community_qa</pwccode>
    </paper>
    <paper id="55">
      <title>TakeLab-QA at SemEval-2017 Task 3 : Classification Experiments for Answer Retrieval in Community QA<fixed-case>T</fixed-case>ake<fixed-case>L</fixed-case>ab-<fixed-case>QA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Classification Experiments for Answer Retrieval in Community <fixed-case>QA</fixed-case></title>
      <author><first>Filip</first> <last>Šaina</last></author>
      <author><first>Toni</first> <last>Kukurin</last></author>
      <author><first>Lukrecija</first> <last>Puljić</last></author>
      <author><first>Mladen</first> <last>Karan</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <pages>339–343</pages>
      <url hash="47030f0e">S17-2055</url>
      <doi>10.18653/v1/S17-2055</doi>
      <abstract>In this paper we present the TakeLab-QA entry to SemEval 2017 task 3, which is a question-comment re-ranking problem. We present a classification based approach, including two supervised learning models   Support Vector Machines (SVM) and Convolutional Neural Networks (CNN). We use <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on different semantic similarity models (e.g., Latent Dirichlet Allocation), as well as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on several types of pre-trained word embeddings. Moreover, we also use some hand-crafted task-specific features. For <a href="https://en.wikipedia.org/wiki/Training">training</a>, our <a href="https://en.wikipedia.org/wiki/System">system</a> uses no external labeled data apart from that provided by the organizers. Our primary submission achieves a MAP-score of 81.14 and F1-score of 66.99   ranking us 10th on the SemEval 2017 task 3, subtask A.</abstract>
      <bibkey>saina-etal-2017-takelab</bibkey>
    </paper>
    <paper id="56">
      <title>GW_QA at SemEval-2017 Task 3 : Question Answer Re-ranking on Arabic Fora<fixed-case>GW</fixed-case>_<fixed-case>QA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Question Answer Re-ranking on <fixed-case>A</fixed-case>rabic Fora</title>
      <author><first>Nada</first> <last>Almarwani</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>344–348</pages>
      <url hash="1fada65a">S17-2056</url>
      <doi>10.18653/v1/S17-2056</doi>
      <abstract>This paper describes our submission to SemEval-2017 Task 3 Subtask D, Question Answer Ranking in Arabic Community Question Answering. In this work, we applied a supervised machine learning approach to automatically re-rank a set of QA pairs according to their relevance to a given question. We employ <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> based on latent semantic models, namely WTMF, as well as a set of lexical features based on string lengths and surface level matching. The proposed <a href="https://en.wikipedia.org/wiki/System">system</a> ranked first out of 3 submissions, with a <a href="https://en.wikipedia.org/wiki/Score_(statistics)">MAP score</a> of 61.16 %.</abstract>
      <bibkey>almarwani-diab-2017-gw</bibkey>
    </paper>
    <paper id="57">
      <title>NLM_NIH at SemEval-2017 Task 3 : from Question Entailment to Question Similarity for Community Question Answering<fixed-case>NLM</fixed-case>_<fixed-case>NIH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: from Question Entailment to Question Similarity for Community Question Answering</title>
      <author><first>Asma</first> <last>Ben Abacha</last></author>
      <author><first>Dina</first> <last>Demner-Fushman</last></author>
      <pages>349–352</pages>
      <url hash="389dd280">S17-2057</url>
      <doi>10.18653/v1/S17-2057</doi>
      <abstract>This paper describes our participation in SemEval-2017 Task 3 on Community Question Answering (cQA). The Question Similarity subtask (B) aims to rank a set of related questions retrieved by a <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engine</a> according to their similarity to the original question. We adapted our feature-based system for Recognizing Question Entailment (RQE) to the question similarity task. Tested on cQA-B-2016 test data, our RQE system outperformed the best system of the 2016 challenge in all measures with 77.47 MAP and 80.57 Accuracy. On cQA-B-2017 test data, performances of all <a href="https://en.wikipedia.org/wiki/System">systems</a> dropped by around 30 points. Our primary system obtained 44.62 <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">MAP</a>, 67.27 <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Accuracy</a> and 47.25 <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">F1 score</a>. The cQA-B-2017 best <a href="https://en.wikipedia.org/wiki/System">system</a> achieved 47.22 MAP and 42.37 <a href="https://en.wikipedia.org/wiki/F1_score">F1 score</a>. Our system is ranked sixth in terms of MAP and third in terms of <a href="https://en.wikipedia.org/wiki/Formula_One">F1</a> out of 13 participating teams.</abstract>
      <bibkey>ben-abacha-demner-fushman-2017-nlm</bibkey>
    </paper>
    <paper id="58">
      <title>bunji at SemEval-2017 Task 3 : Combination of Neural Similarity Features and Comment Plausibility Features<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Combination of Neural Similarity Features and Comment Plausibility Features</title>
      <author><first>Yuta</first> <last>Koreeda</last></author>
      <author><first>Takuya</first> <last>Hashito</last></author>
      <author><first>Yoshiki</first> <last>Niwa</last></author>
      <author><first>Misa</first> <last>Sato</last></author>
      <author><first>Toshihiko</first> <last>Yanase</last></author>
      <author><first>Kenzo</first> <last>Kurotsuchi</last></author>
      <author><first>Kohsuke</first> <last>Yanai</last></author>
      <pages>353–359</pages>
      <url hash="aed13d6c">S17-2058</url>
      <doi>10.18653/v1/S17-2058</doi>
      <abstract>This paper describes a text-ranking system developed by bunji team in SemEval-2017 Task 3 : Community Question Answering, Subtask A and C. The goal of the task is to re-rank the comments in a question-and-answer forum such that useful comments for answering the question are ranked high. We proposed a method that combines neural similarity features and hand-crafted comment plausibility features, and we modeled inter-comments relationship using conditional random field. Our approach obtained the fifth place in the Subtask A and the second place in the Subtask C.</abstract>
      <bibkey>koreeda-etal-2017-bunji</bibkey>
    </paper>
    <paper id="59">
      <title>QU-BIGIR at SemEval 2017 Task 3 : Using Similarity Features for Arabic Community Question Answering Forums<fixed-case>QU</fixed-case>-<fixed-case>BIGIR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2017 Task 3: Using Similarity Features for <fixed-case>A</fixed-case>rabic Community Question Answering Forums</title>
      <author><first>Marwan</first> <last>Torki</last></author>
      <author><first>Maram</first> <last>Hasanain</last></author>
      <author><first>Tamer</first> <last>Elsayed</last></author>
      <pages>360–364</pages>
      <url hash="b1735c28">S17-2059</url>
      <doi>10.18653/v1/S17-2059</doi>
      <abstract>In this paper we describe our QU-BIGIR system for the Arabic subtask D of the SemEval 2017 Task 3. Our approach builds on our participation in the past version of the same subtask. This year, our system uses different <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity measures</a> that encodes lexical and semantic pairwise similarity of text pairs. In addition to well known <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity measures</a> such as <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a>, we use other measures based on the summary statistics of word embedding representation for a given text. To rank a list of candidate question answer pairs for a given question, we learn a linear SVM classifier over our similarity features. Our best resulting run came second in subtask D with a very competitive performance to the first-ranking system.</abstract>
      <bibkey>torki-etal-2017-qu</bibkey>
    </paper>
    <paper id="60">
      <title>ECNU at SemEval-2017 Task 3 : Using Traditional and Deep Learning Methods to Address Community Question Answering Task<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Using Traditional and Deep Learning Methods to Address Community Question Answering Task</title>
      <author><first>Guoshun</first> <last>Wu</last></author>
      <author><first>Yixuan</first> <last>Sheng</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>365–369</pages>
      <url hash="3d02fa97">S17-2060</url>
      <doi>10.18653/v1/S17-2060</doi>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">systems</a> we submitted to the task 3 (Community Question Answering) in SemEval 2017 which contains three subtasks on English corpora, i.e., subtask A : Question-Comment Similarity, subtask B : Question-Question Similarity, and subtask C : Question-External Comment Similarity. For subtask A, we combined two different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> to represent question-comment pair, i.e., <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised model</a> using traditional <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a>. For subtask B, we utilized the information of snippets returned from <a href="https://en.wikipedia.org/wiki/Web_search_engine">Search Engine</a> with question subject as query. For subtask C, we ranked the comments by multiplying the probability of the pair related question comment being Good by the reciprocal rank of the related question.</abstract>
      <bibkey>wu-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="61">
      <title>UINSUSKA-TiTech at SemEval-2017 Task 3 : Exploiting Word Importance Levels for Similarity Features for CQA<fixed-case>UINSUSKA</fixed-case>-<fixed-case>T</fixed-case>i<fixed-case>T</fixed-case>ech at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Exploiting Word Importance Levels for Similarity Features for <fixed-case>CQA</fixed-case></title>
      <author><first>Surya</first> <last>Agustian</last></author>
      <author><first>Hiroya</first> <last>Takamura</last></author>
      <pages>370–374</pages>
      <url hash="2c241890">S17-2061</url>
      <doi>10.18653/v1/S17-2061</doi>
      <abstract>The majority of core techniques to solve many problems in Community Question Answering (CQA) task rely on similarity computation. This work focuses on <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a> between two sentences (or questions in subtask B) based on <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. We exploit words importance levels in sentences or questions for similarity features, for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and <a href="https://en.wikipedia.org/wiki/Ranking">ranking</a> with <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>. Using only 2 types of similarity metric, our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> has shown comparable results with other <a href="https://en.wikipedia.org/wiki/Complex_system">complex systems</a>. This <a href="https://en.wikipedia.org/wiki/Methodology">method</a> on subtask B 2017 dataset is ranked on position 7 out of 13 participants. Evaluation on 2016 dataset is on position 8 of 12, outperforms some <a href="https://en.wikipedia.org/wiki/Complex_system">complex systems</a>. Further, this finding is explorable and potential to be used as baseline and extensible for many tasks in CQA and other textual similarity based system.</abstract>
      <bibkey>agustian-takamura-2017-uinsuska</bibkey>
    </paper>
    <paper id="62">
      <title>Talla at SemEval-2017 Task 3 : Identifying Similar Questions Through Paraphrase Detection<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 3: Identifying Similar Questions Through Paraphrase Detection</title>
      <author><first>Byron</first> <last>Galbraith</last></author>
      <author><first>Bhanu</first> <last>Pratap</last></author>
      <author><first>Daniel</first> <last>Shank</last></author>
      <pages>375–379</pages>
      <url hash="03f0a89e">S17-2062</url>
      <doi>10.18653/v1/S17-2062</doi>
      <abstract>This paper describes our approach to the SemEval-2017 shared task of determining question-question similarity in a community question-answering setting (Task 3B). We extracted both syntactic and semantic similarity features between candidate questions, performed pairwise-preference learning to optimize for ranking order, and then trained a random forest classifier to predict whether the candidate questions are paraphrases of each other. This approach achieved a <a href="https://en.wikipedia.org/wiki/Score_(statistics)">MAP</a> of 45.7 % out of max achievable 67.0 % on the test set.</abstract>
      <bibkey>galbraith-etal-2017-talla</bibkey>
    </paper>
    <paper id="63">
      <title>QUB at SemEval-2017 Task 6 : Cascaded Imbalanced Classification for Humor Analysis in Twitter<fixed-case>QUB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: Cascaded Imbalanced Classification for Humor Analysis in <fixed-case>T</fixed-case>witter</title>
      <author><first>Xiwu</first> <last>Han</last></author>
      <author><first>Gregory</first> <last>Toner</last></author>
      <pages>380–384</pages>
      <url hash="ee933d15">S17-2063</url>
      <doi>10.18653/v1/S17-2063</doi>
      <abstract>This paper presents our submission to SemEval-2017 Task 6 : # HashtagWars : Learning a Sense of Humor. There are two subtasks : A. <a href="https://en.wikipedia.org/wiki/Pairwise_comparison">Pairwise Comparison</a>, and B. <a href="https://en.wikipedia.org/wiki/Ranking">Semi-Ranking</a>. Our assumption is that the distribution of humorous and non-humorous texts in real life language is naturally imbalanced. Using Nave Bayes Multinomial with standard text-representation features, we approached Subtask B as a sequence of imbalanced classification problems, and optimized our system per the macro-average recall. Subtask A was then solved via the Semi-Ranking results. On the final test, our <a href="https://en.wikipedia.org/wiki/System">system</a> was ranked 10th for Subtask A, and 3rd for Subtask B.</abstract>
      <bibkey>han-toner-2017-qub</bibkey>
    </paper>
    <paper id="64">
      <title>Duluth at SemEval-2017 Task 6 : Language Models in Humor Detection<fixed-case>D</fixed-case>uluth at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: Language Models in Humor Detection</title>
      <author><first>Xinru</first> <last>Yan</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>385–389</pages>
      <url hash="f4c0bd40">S17-2064</url>
      <doi>10.18653/v1/S17-2064</doi>
      <abstract>This paper describes the Duluth system that participated in SemEval-2017 Task 6 # HashtagWars : Learning a Sense of Humor. The <a href="https://en.wikipedia.org/wiki/System">system</a> participated in Subtasks A and B using N-gram language models, ranking highly in the task evaluation. This paper discusses the results of our <a href="https://en.wikipedia.org/wiki/System">system</a> in the development and evaluation stages and from two post-evaluation runs.</abstract>
      <bibkey>yan-pedersen-2017-duluth</bibkey>
    </paper>
    <paper id="65">
      <title>DataStories at SemEval-2017 Task 6 : Siamese LSTM with Attention for Humorous Text Comparison<fixed-case>D</fixed-case>ata<fixed-case>S</fixed-case>tories at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: <fixed-case>S</fixed-case>iamese <fixed-case>LSTM</fixed-case> with Attention for Humorous Text Comparison</title>
      <author><first>Christos</first> <last>Baziotis</last></author>
      <author><first>Nikos</first> <last>Pelekis</last></author>
      <author><first>Christos</first> <last>Doulkeridis</last></author>
      <pages>390–395</pages>
      <url hash="17fa6ad7">S17-2065</url>
      <doi>10.18653/v1/S17-2065</doi>
      <abstract>In this paper we present a deep-learning system that competed at SemEval-2017 Task 6 # HashtagWars : Learning a Sense of Humor. We participated in Subtask A, in which the goal was, given two Twitter messages, to identify which one is funnier. We propose a Siamese architecture with bidirectional Long Short-Term Memory (LSTM) networks, augmented with an attention mechanism. Our system works on the token-level, leveraging <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> trained on a big collection of unlabeled Twitter messages. We ranked 2nd in 7 teams. A post-completion improvement of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, achieves state-of-the-art results on # HashtagWars dataset.</abstract>
      <bibkey>baziotis-etal-2017-datastories</bibkey>
    </paper>
    <paper id="66">
      <title>TakeLab at SemEval-2017 Task 6 : # RankingHumorIn4Pages<fixed-case>T</fixed-case>ake<fixed-case>L</fixed-case>ab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: #<fixed-case>R</fixed-case>anking<fixed-case>H</fixed-case>umor<fixed-case>I</fixed-case>n4<fixed-case>P</fixed-case>ages</title>
      <author><first>Marin</first> <last>Kukovačec</last></author>
      <author><first>Juraj</first> <last>Malenica</last></author>
      <author><first>Ivan</first> <last>Mršić</last></author>
      <author><first>Antonio</first> <last>Šajatović</last></author>
      <author><first>Domagoj</first> <last>Alagić</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <pages>396–400</pages>
      <url hash="2f649ca3">S17-2066</url>
      <doi>10.18653/v1/S17-2066</doi>
      <abstract>This paper describes our system for humor ranking in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> within the SemEval 2017 Task 6 : # HashtagWars (6A and 6B). For both subtasks, we use an off-the-shelf gradient boosting model built on a rich set of features, handcrafted to provide the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with the external knowledge needed to better predict the <a href="https://en.wikipedia.org/wiki/Humour">humor</a> in the text. The <a href="https://en.wikipedia.org/wiki/Feature_film">features</a> capture various cultural references and specific <a href="https://en.wikipedia.org/wiki/Culture_of_the_United_States">humor patterns</a>. Our system ranked 2nd (officially 7th) among 10 submissions on the Subtask A and 2nd among 9 submissions on the Subtask B.</abstract>
      <bibkey>kukovacec-etal-2017-takelab</bibkey>
    </paper>
    <paper id="67">
      <title>SRHR at SemEval-2017 Task 6 : Word Associations for Humour Recognition<fixed-case>SRHR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: Word Associations for Humour Recognition</title>
      <author><first>Andrew</first> <last>Cattle</last></author>
      <author><first>Xiaojuan</first> <last>Ma</last></author>
      <pages>401–406</pages>
      <url hash="e1f9893a">S17-2067</url>
      <doi>10.18653/v1/S17-2067</doi>
      <abstract>This paper explores the role of <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic relatedness features</a>, such as <a href="https://en.wikipedia.org/wiki/Word_association">word associations</a>, in humour recognition. Specifically, we examine the task of inferring pairwise humour judgments in Twitter hashtag wars. We examine a variety of word association features derived from University of Southern Florida Free Association Norms (USF) and the Edinburgh Associative Thesaurus (EAT) and find that word association-based features outperform Word2Vec similarity, a popular semantic relatedness measure. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 56.42 % using a combination of unigram perplexity, bigram perplexity, EAT difference (tweet-avg), USF forward (max), EAT difference (word-avg), USF difference (word-avg), EAT forward (min), USF difference (tweet-max), and EAT backward (min).</abstract>
      <bibkey>cattle-ma-2017-srhr</bibkey>
    </paper>
    <paper id="68">
      <title># WarTeam at SemEval-2017 Task 6 : Using Neural Networks for Discovering Humorous Tweets<fixed-case>W</fixed-case>ar<fixed-case>T</fixed-case>eam at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 6: Using Neural Networks for Discovering Humorous Tweets</title>
      <author><first>Iuliana Alexandra</first> <last>Fleșcan-Lovin-Arseni</last></author>
      <author><first>Ramona Andreea</first> <last>Turcu</last></author>
      <author><first>Cristina</first> <last>Sîrbu</last></author>
      <author><first>Larisa</first> <last>Alexa</last></author>
      <author><first>Sandra Maria</first> <last>Amarandei</last></author>
      <author><first>Nichita</first> <last>Herciu</last></author>
      <author><first>Constantin</first> <last>Scutaru</last></author>
      <author><first>Diana</first> <last>Trandabăț</last></author>
      <author><first>Adrian</first> <last>Iftene</last></author>
      <pages>407–410</pages>
      <url hash="f7e9e878">S17-2068</url>
      <doi>10.18653/v1/S17-2068</doi>
      <abstract>This paper presents the participation of # WarTeam in Task 6 of SemEval2017 with a system classifying humor by comparing and ranking tweets. The training data consists of annotated tweets from the @midnight TV show. # WarTeam’s system uses a neural network (TensorFlow) having inputs from a Nave Bayes humor classifier and a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analyzer</a>.</abstract>
      <bibkey>flescan-lovin-arseni-etal-2017-warteam</bibkey>
    </paper>
    <paper id="71">
      <title>UWaterloo at SemEval-2017 Task 7 : Locating the Pun Using Syntactic Characteristics and Corpus-based Metrics<fixed-case>UW</fixed-case>aterloo at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Locating the Pun Using Syntactic Characteristics and Corpus-based Metrics</title>
      <author><first>Olga</first> <last>Vechtomova</last></author>
      <pages>421–425</pages>
      <url hash="cdebc4ac">S17-2071</url>
      <doi>10.18653/v1/S17-2071</doi>
      <abstract>The paper presents a <a href="https://en.wikipedia.org/wiki/System">system</a> for locating a pun word. The developed method calculates a score for each word in a <a href="https://en.wikipedia.org/wiki/Pun">pun</a>, using a number of components, including its Inverse Document Frequency (IDF), Normalized Pointwise Mutual Information (NPMI) with other words in the pun text, its position in the text, <a href="https://en.wikipedia.org/wiki/Part_of_speech">part-of-speech</a> and some syntactic features. The <a href="https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations">method</a> achieved the best performance in the Heterographic category and the second best in the Homographic. Further analysis showed that IDF is the most useful characteristic, whereas the count of words with which the given word has high NPMI has a negative effect on performance.</abstract>
      <bibkey>vechtomova-2017-uwaterloo</bibkey>
    </paper>
    <paper id="72">
      <title>PunFields at SemEval-2017 Task 7 : Employing Roget’s Thesaurus in Automatic Pun Recognition and Interpretation<fixed-case>P</fixed-case>un<fixed-case>F</fixed-case>ields at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Employing <fixed-case>R</fixed-case>oget’s Thesaurus in Automatic Pun Recognition and Interpretation</title>
      <author><first>Elena</first> <last>Mikhalkova</last></author>
      <author><first>Yuri</first> <last>Karyakin</last></author>
      <pages>426–431</pages>
      <url hash="1fbedc04">S17-2072</url>
      <doi>10.18653/v1/S17-2072</doi>
      <abstract>The article describes a model of automatic interpretation of English puns, based on <a href="https://en.wikipedia.org/wiki/Roget’s_Thesaurus">Roget’s Thesaurus</a>, and its implementation, PunFields. In a <a href="https://en.wikipedia.org/wiki/Pun">pun</a>, the <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> discovers two groups of words that belong to two main <a href="https://en.wikipedia.org/wiki/Semantic_field">semantic fields</a>. The fields become a semantic vector based on which an SVM classifier learns to recognize puns. A rule-based model is then applied for recognition of intentionally ambiguous (target) words and their definitions. In SemEval Task 7 PunFields shows a considerably good result in pun classification, but requires improvement in searching for the target word and its definition.</abstract>
      <bibkey>mikhalkova-karyakin-2017-punfields</bibkey>
      <pwccode url="https://github.com/evrog/PunFields" additional="false">evrog/PunFields</pwccode>
    </paper>
    <paper id="74">
      <title>N-Hance at SemEval-2017 Task 7 : A Computational Approach using Word Association for Puns<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: A Computational Approach using Word Association for Puns</title>
      <author><first>Özge</first> <last>Sevgili</last></author>
      <author><first>Nima</first> <last>Ghotbi</last></author>
      <author><first>Selma</first> <last>Tekir</last></author>
      <pages>436–439</pages>
      <url hash="8c074ef1">S17-2074</url>
      <doi>10.18653/v1/S17-2074</doi>
      <abstract>This paper presents a system developed for SemEval-2017 Task 7, Detection and Interpretation of English Puns consisting of three subtasks ; pun detection, pun location, and pun interpretation, respectively. The system stands on recognizing a distinctive word which has a high association with the <a href="https://en.wikipedia.org/wiki/Pun">pun</a> in the given sentence. The intended humorous meaning of pun is identified through the use of this word. Our official results confirm the potential of this <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a>.</abstract>
      <bibkey>sevgili-etal-2017-n</bibkey>
    </paper>
    <paper id="75">
      <title>ELiRF-UPV at SemEval-2017 Task 7 : Pun Detection and Interpretation<fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Pun Detection and Interpretation</title>
      <author><first>Lluís-F.</first> <last>Hurtado</last></author>
      <author><first>Encarna</first> <last>Segarra</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <author><first>Pascual</first> <last>Carrasco</last></author>
      <author><first>José-Ángel</first> <last>González</last></author>
      <pages>440–443</pages>
      <url hash="4ccef11f">S17-2075</url>
      <doi>10.18653/v1/S17-2075</doi>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 7 (subtask 2 : homographic pun detection and subtask 3 : homographic pun interpretation) of SemEval2017. Our approach is based on the use of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> to find related words in a sentence and a version of the <a href="https://en.wikipedia.org/wiki/Lesk_algorithm">Lesk algorithm</a> to establish relationships between synsets. The results obtained are in line with those obtained by the other participants and they encourage us to continue working on this problem.</abstract>
      <bibkey>hurtado-etal-2017-elirf</bibkey>
    </paper>
    <paper id="76">
      <title>BuzzSaw at SemEval-2017 Task 7 : Global vs. Local Context for Interpreting and Locating Homographic English Puns with Sense Embeddings<fixed-case>B</fixed-case>uzz<fixed-case>S</fixed-case>aw at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Global vs. Local Context for Interpreting and Locating Homographic <fixed-case>E</fixed-case>nglish Puns with Sense Embeddings</title>
      <author><first>Dieke</first> <last>Oele</last></author>
      <author><first>Kilian</first> <last>Evang</last></author>
      <pages>444–448</pages>
      <url hash="6b71a2f6">S17-2076</url>
      <doi>10.18653/v1/S17-2076</doi>
      <abstract>This paper describes our system participating in the SemEval-2017 Task 7, for the subtasks of homographic pun location and homographic pun interpretation. For pun interpretation, we use a knowledge-based Word Sense Disambiguation (WSD) method based on sense embeddings. Pun-based jokes can be divided into two parts, each containing information about the two distinct senses of the pun. To exploit this structure we split the context that is input to the WSD system into two local contexts and find the best sense for each of them. We use the output of pun interpretation for pun location. As we expect the two meanings of a pun to be very dissimilar, we compute sense embedding cosine distances for each sense-pair and select the word that has the highest distance. We describe experiments on different <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> of splitting the context and compare our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> to several baselines. We find evidence supporting our hypotheses and obtain competitive results for pun interpretation.</abstract>
      <bibkey>oele-evang-2017-buzzsaw</bibkey>
    </paper>
    <paper id="77">
      <title>UWAV at SemEval-2017 Task 7 : Automated feature-based system for locating puns<fixed-case>UWAV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Automated feature-based system for locating puns</title>
      <author><first>Ankit</first> <last>Vadehra</last></author>
      <pages>449–452</pages>
      <url hash="735d1ea6">S17-2077</url>
      <doi>10.18653/v1/S17-2077</doi>
      <abstract>In this paper we describe our <a href="https://en.wikipedia.org/wiki/System">system</a> created for SemEval-2017 Task 7 : Detection and Interpretation of English Puns. We tackle subtask 1, pun detection, by leveraging features selected from sentences to design a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> that can disambiguate between the presence or absence of a pun. We address subtask 2, pun location, by utilizing a decision flow structure that uses presence or absence of certain features to decide the next action. The results obtained by our <a href="https://en.wikipedia.org/wiki/System">system</a> are encouraging, considering the simplicity of the <a href="https://en.wikipedia.org/wiki/System">system</a>. We consider this <a href="https://en.wikipedia.org/wiki/System">system</a> as a precursor for deeper exploration on efficient <a href="https://en.wikipedia.org/wiki/Feature_selection">feature selection</a> for pun detection.</abstract>
      <bibkey>vadehra-2017-uwav</bibkey>
    </paper>
    <paper id="78">
      <title>ECNU at SemEval-2017 Task 7 : Using Supervised and Unsupervised Methods to Detect and Locate English Puns<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Using Supervised and Unsupervised Methods to Detect and Locate <fixed-case>E</fixed-case>nglish Puns</title>
      <author><first>Yuhuan</first> <last>Xiu</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>453–456</pages>
      <url hash="96a48049">S17-2078</url>
      <doi>10.18653/v1/S17-2078</doi>
      <abstract>This paper describes our submissions to task 7 in SemEval 2017, i.e., <a href="https://en.wikipedia.org/wiki/Detection_theory">Detection</a> and <a href="https://en.wikipedia.org/wiki/Interpretation_(linguistics)">Interpretation of English Puns</a>. We participated in the first two subtasks, which are to detect and locate English puns respectively. For subtask 1, we presented a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised system</a> to determine whether or not a sentence contains a <a href="https://en.wikipedia.org/wiki/Pun">pun</a> using similarity features calculated on sense vectors or cluster center vectors. For subtask 2, we established an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised system</a> to locate the <a href="https://en.wikipedia.org/wiki/Pun">pun</a> by scoring each word in the sentence and we assumed that the word with the smallest score is the <a href="https://en.wikipedia.org/wiki/Pun">pun</a>.</abstract>
      <bibkey>xiu-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="79">
      <title>Fermi at SemEval-2017 Task 7 : Detection and Interpretation of Homographic puns in <a href="https://en.wikipedia.org/wiki/English_language">English Language</a><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 7: Detection and Interpretation of Homographic puns in <fixed-case>E</fixed-case>nglish Language</title>
      <author><first>Vijayasaradhi</first> <last>Indurthi</last></author>
      <author><first>Subba Reddy</first> <last>Oota</last></author>
      <pages>457–460</pages>
      <url hash="1c103890">S17-2079</url>
      <doi>10.18653/v1/S17-2079</doi>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> for detection and interpretation of English puns. We participated in 2 subtasks related to homographic puns achieve comparable results for these tasks. Through the paper we provide detailed description of the <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a>, as well as the results obtained in the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> achieved a F1-score of 77.65 % for Subtask 1 and 52.15 % for Subtask 2.</abstract>
      <bibkey>indurthi-oota-2017-fermi</bibkey>
    </paper>
    <paper id="80">
      <title>UWaterloo at SemEval-2017 Task 8 : Detecting Stance towards Rumours with Topic Independent Features<fixed-case>UW</fixed-case>aterloo at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Detecting Stance towards Rumours with Topic Independent Features</title>
      <author><first>Hareesh</first> <last>Bahuleyan</last></author>
      <author><first>Olga</first> <last>Vechtomova</last></author>
      <pages>461–464</pages>
      <url hash="445ce7ab">S17-2080</url>
      <doi>10.18653/v1/S17-2080</doi>
      <abstract>This paper describes our system for subtask-A : SDQC for RumourEval, task-8 of SemEval 2017. Identifying <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>, especially for <a href="https://en.wikipedia.org/wiki/Breaking_news">breaking news events</a> as they unfold, is a challenging task due to the absence of sufficient information about the exact <a href="https://en.wikipedia.org/wiki/Rumor">rumour stories</a> circulating on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. Determining the stance of Twitter users towards rumourous messages could provide an indirect way of identifying potential <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>. The proposed approach makes use of topic independent features from two categories, namely cue features and message specific features to fit a <a href="https://en.wikipedia.org/wiki/Gradient_boosting">gradient boosting classifier</a>. With an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.78, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved the second best performance on subtask-A of RumourEval.</abstract>
      <bibkey>bahuleyan-vechtomova-2017-uwaterloo</bibkey>
    </paper>
    <paper id="81">
      <title>IKM at SemEval-2017 Task 8 : <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> for stance detection and rumor verification<fixed-case>IKM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Convolutional Neural Networks for stance detection and rumor verification</title>
      <author><first>Yi-Chin</first> <last>Chen</last></author>
      <author><first>Zhao-Yang</first> <last>Liu</last></author>
      <author><first>Hung-Yu</first> <last>Kao</last></author>
      <pages>465–469</pages>
      <url hash="5d8f7c39">S17-2081</url>
      <doi>10.18653/v1/S17-2081</doi>
      <abstract>This paper describes our approach for SemEval-2017 Task 8. We aim at detecting the stance of tweets and determining the veracity of the given rumor. We utilize a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> for short text categorization using multiple <a href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">filter sizes</a>. Our approach beats the baseline classifiers on different <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">event data</a> with good <a href="https://en.wikipedia.org/wiki/F1_score">F1 scores</a>. The best of our submitted runs achieves rank 1st among all scores on subtask B.</abstract>
      <bibkey>chen-etal-2017-ikm</bibkey>
    </paper>
    <paper id="82">
      <title>NileTMRG at SemEval-2017 Task 8 : Determining Rumour and Veracity Support for Rumours on Twitter.<fixed-case>N</fixed-case>ile<fixed-case>TMRG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Determining Rumour and Veracity Support for Rumours on <fixed-case>T</fixed-case>witter.</title>
      <author><first>Omar</first> <last>Enayet</last></author>
      <author><first>Samhaa R.</first> <last>El-Beltagy</last></author>
      <pages>470–474</pages>
      <url hash="dade7f3a">S17-2082</url>
      <doi>10.18653/v1/S17-2082</doi>
      <abstract>Final submission for NileTMRG on RumourEval 2017.</abstract>
      <bibkey>enayet-el-beltagy-2017-niletmrg</bibkey>
    </paper>
    <paper id="83">
      <title>Turing at SemEval-2017 Task 8 : Sequential Approach to Rumour Stance Classification with Branch-LSTM<fixed-case>T</fixed-case>uring at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Sequential Approach to Rumour Stance Classification with Branch-<fixed-case>LSTM</fixed-case></title>
      <author><first>Elena</first> <last>Kochkina</last></author>
      <author><first>Maria</first> <last>Liakata</last></author>
      <author><first>Isabelle</first> <last>Augenstein</last></author>
      <pages>475–480</pages>
      <url hash="b9e7b2cb">S17-2083</url>
      <doi>10.18653/v1/S17-2083</doi>
      <abstract>This paper describes team Turing’s submission to SemEval 2017 RumourEval : Determining rumour veracity and support for rumours (SemEval 2017 Task 8, Subtask A). Subtask A addresses the challenge of rumour stance classification, which involves identifying the attitude of Twitter users towards the truthfulness of the rumour they are discussing. Stance classification is considered to be an important step towards rumour verification, therefore performing well in this task is expected to be useful in debunking false rumours. In this work we classify a set of Twitter posts discussing rumours into either supporting, denying, questioning or commenting on the underlying <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>. We propose a LSTM-based sequential model that, through modelling the conversational structure of tweets, which achieves an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.784 on the RumourEval test set outperforming all other <a href="https://en.wikipedia.org/wiki/System">systems</a> in Subtask A.</abstract>
      <bibkey>kochkina-etal-2017-turing</bibkey>
    </paper>
    <paper id="84">
      <title>Mama Edha at SemEval-2017 Task 8 : Stance Classification with CNN and Rules<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Stance Classification with <fixed-case>CNN</fixed-case> and Rules</title>
      <author><first>Marianela</first> <last>García Lozano</last></author>
      <author><first>Hanna</first> <last>Lilja</last></author>
      <author><first>Edward</first> <last>Tjörnhammar</last></author>
      <author><first>Maja</first> <last>Karasalo</last></author>
      <pages>481–485</pages>
      <url hash="3033e64d">S17-2084</url>
      <doi>10.18653/v1/S17-2084</doi>
      <abstract>For the competition SemEval-2017 we investigated the possibility of performing stance classification (support, deny, query or comment) for messages in Twitter conversation threads related to rumours. Stance classification is interesting since <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> can provide a basis for rumour veracity assessment. Our ensemble classification approach of combining <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> with both automatic rule mining and manually written rules achieved a final <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 74.9 % on the competition’s test data set for Task 8A. To improve <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> we also experimented with data relabeling and using the <a href="https://en.wikipedia.org/wiki/Grammar">grammatical structure</a> of the tweet contents for <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>.</abstract>
      <bibkey>garcia-lozano-etal-2017-mama</bibkey>
    </paper>
    <paper id="85">
      <title>DFKI-DKT at SemEval-2017 Task 8 : Rumour Detection and Classification using Cascading Heuristics<fixed-case>DFKI</fixed-case>-<fixed-case>DKT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Rumour Detection and Classification using Cascading Heuristics</title>
      <author><first>Ankit</first> <last>Srivastava</last></author>
      <author><first>Georg</first> <last>Rehm</last></author>
      <author><first>Julian</first> <last>Moreno Schneider</last></author>
      <pages>486–490</pages>
      <url hash="1cfe9c40">S17-2085</url>
      <doi>10.18653/v1/S17-2085</doi>
      <abstract>We describe our submissions for SemEval-2017 Task 8, Determining Rumour Veracity and Support for Rumours. The Digital Curation Technologies (DKT) team at the German Research Center for Artificial Intelligence (DFKI) participated in two subtasks : Subtask A (determining the stance of a message) and Subtask B (determining veracity of a message, closed variant). In both cases, our implementation consisted of a Multivariate Logistic Regression (Maximum Entropy) classifier coupled with hand-written patterns and rules (heuristics) applied in a post-process cascading fashion. We provide a detailed analysis of the <a href="https://en.wikipedia.org/wiki/System">system</a> performance and report on variants of our <a href="https://en.wikipedia.org/wiki/System">systems</a> that were not part of the official submission.</abstract>
      <bibkey>srivastava-etal-2017-dfki</bibkey>
    </paper>
    <paper id="86">
      <title>ECNU at SemEval-2017 Task 8 : Rumour Evaluation Using Effective Features and Supervised Ensemble Models<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8: Rumour Evaluation Using Effective Features and Supervised Ensemble Models</title>
      <author><first>Feixiang</first> <last>Wang</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>491–496</pages>
      <url hash="8d3d67ed">S17-2086</url>
      <doi>10.18653/v1/S17-2086</doi>
      <abstract>This paper describes our submissions to task 8 in SemEval 2017, i.e., Determining rumour veracity and support for <a href="https://en.wikipedia.org/wiki/Rumor">rumours</a>. Given a rumoured tweet and a lot of reply tweets, the subtask A is to label whether these tweets are support, deny, query or comment, and the subtask B aims to predict the veracity (i.e., true, false, and unverified) with a confidence (in range of 0-1) of the given rumoured tweet. For both subtasks, we adopted supervised machine learning methods, incorporating <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">rich features</a>. Since training data is imbalanced, we specifically designed a two-step classifier to address subtask A.</abstract>
      <bibkey>wang-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="87">
      <title>IITP at SemEval-2017 Task 8 : A Supervised Approach for Rumour Evaluation<fixed-case>IITP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 8 : A Supervised Approach for Rumour Evaluation</title>
      <author><first>Vikram</first> <last>Singh</last></author>
      <author><first>Sunny</first> <last>Narayan</last></author>
      <author><first>Md Shad</first> <last>Akhtar</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>497–501</pages>
      <url hash="5948af08">S17-2087</url>
      <doi>10.18653/v1/S17-2087</doi>
      <abstract>This paper describes our <a href="https://en.wikipedia.org/wiki/System">system</a> participation in the SemEval-2017 Task 8 ‘RumourEval : Determining rumour veracity and support for rumours’. The objective of this task was to predict the stance and veracity of the underlying <a href="https://en.wikipedia.org/wiki/Rumor">rumour</a>. We propose a supervised classification approach employing several lexical, content and twitter specific features for learning. Evaluation shows promising results for both the <a href="https://en.wikipedia.org/wiki/Problem_solving">problems</a>.</abstract>
      <bibkey>singh-etal-2017-iitp</bibkey>
    </paper>
    <paper id="88">
      <title>SemEval-2017 Task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in Twitter<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Analysis in <fixed-case>T</fixed-case>witter</title>
      <author><first>Sara</first> <last>Rosenthal</last></author>
      <author><first>Noura</first> <last>Farra</last></author>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <pages>502–518</pages>
      <url hash="8bb3710d">S17-2088</url>
      <doi>10.18653/v1/S17-2088</doi>
      <abstract>This paper describes the fifth year of the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in Twitter task. SemEval-2017 Task 4 continues with a rerun of the subtasks of SemEval-2016 Task 4, which include identifying the overall sentiment of the tweet, sentiment towards a topic with classification on a two-point and on a five-point ordinal scale, and quantification of the distribution of sentiment towards a topic across a number of tweets : again on a two-point and on a five-point ordinal scale. Compared to 2016, we made two changes : (i) we introduced a new language, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, for all subtasks, and (ii) we made available information from the profiles of the Twitter users who posted the target tweets. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> continues to be very popular, with a total of 48 teams participating this year.</abstract>
      <bibkey>rosenthal-etal-2017-semeval</bibkey>
    </paper>
    <paper id="89">
      <title>SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis on Financial Microblogs and News<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News</title>
      <author><first>Keith</first> <last>Cortis</last></author>
      <author><first>André</first> <last>Freitas</last></author>
      <author><first>Tobias</first> <last>Daudert</last></author>
      <author><first>Manuela</first> <last>Huerlimann</last></author>
      <author><first>Manel</first> <last>Zarrouk</last></author>
      <author><first>Siegfried</first> <last>Handschuh</last></author>
      <author><first>Brian</first> <last>Davis</last></author>
      <pages>519–535</pages>
      <url hash="7f510d82">S17-2089</url>
      <doi>10.18653/v1/S17-2089</doi>
      <abstract>This paper discusses the Fine-Grained Sentiment Analysis on Financial Microblogs and News task as part of SemEval-2017, specifically under the Detecting sentiment, humour, and truth theme. This task contains two tracks, where the first one concerns <a href="https://en.wikipedia.org/wiki/Microblogging">Microblog messages</a> and the second one covers <a href="https://en.wikipedia.org/wiki/News">News Statements</a> and <a href="https://en.wikipedia.org/wiki/Headline">Headlines</a>. The main goal behind both tracks was to predict the sentiment score for each of the mentioned companies / stocks. The sentiment scores for each text instance adopted floating point values in the range of -1 (very negative / bearish) to 1 (very positive / bullish), with 0 designating neutral sentiment. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> attracted a total of 32 participants, with 25 participating in Track 1 and 29 in Track 2.</abstract>
      <bibkey>cortis-etal-2017-semeval</bibkey>
    </paper>
    <paper id="90">
      <title>SemEval-2017 Task 9 : Abstract Meaning Representation Parsing and Generation<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation Parsing and Generation</title>
      <author><first>Jonathan</first> <last>May</last></author>
      <author><first>Jay</first> <last>Priyadarshi</last></author>
      <pages>536–545</pages>
      <url hash="963ef0fc">S17-2090</url>
      <doi>10.18653/v1/S17-2090</doi>
      <abstract>In this report we summarize the results of the 2017 AMR SemEval shared task. The <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> consisted of two separate yet related <a href="https://en.wikipedia.org/wiki/Task_(project_management)">subtasks</a>. In the parsing subtask, participants were asked to produce Abstract Meaning Representation (AMR) (Banarescu et al., 2013) graphs for a set of English sentences in the biomedical domain. In the generation subtask, participants were asked to generate <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">English sentences</a> given AMR graphs in the <a href="https://en.wikipedia.org/wiki/Internet_forum">news / forum domain</a>. A total of five sites participated in the parsing subtask, and four participated in the generation subtask. Along with a description of the task and the participants’ systems, we show various score ablations and some sample outputs.</abstract>
      <bibkey>may-priyadarshi-2017-semeval</bibkey>
    </paper>
    <paper id="91">
      <title>SemEval 2017 Task 10 : ScienceIE-Extracting Keyphrases and Relations from Scientific Publications<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2017 Task 10: <fixed-case>S</fixed-case>cience<fixed-case>IE</fixed-case> - Extracting Keyphrases and Relations from Scientific Publications</title>
      <author><first>Isabelle</first> <last>Augenstein</last></author>
      <author><first>Mrinal</first> <last>Das</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <author><first>Lakshmi</first> <last>Vikraman</last></author>
      <author><first>Andrew</first> <last>McCallum</last></author>
      <pages>546–555</pages>
      <url hash="cc657c1d">S17-2091</url>
      <doi>10.18653/v1/S17-2091</doi>
      <abstract>We describe the SemEval task of extracting keyphrases and relations between them from scientific documents, which is crucial for understanding which publications describe which processes, tasks and materials. Although this was a new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we had a total of 26 submissions across 3 evaluation scenarios. We expect the task and the findings reported in this paper to be relevant for researchers working on understanding scientific content, as well as the broader knowledge base population and information extraction communities.</abstract>
      <bibkey>augenstein-etal-2017-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval2017">SemEval2017</pwcdataset>
    </paper>
    <paper id="92">
      <title>SemEval-2017 Task 11 : End-User Development using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language</a><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 11: End-User Development using Natural Language</title>
      <author><first>Juliano</first> <last>Sales</last></author>
      <author><first>Siegfried</first> <last>Handschuh</last></author>
      <author><first>André</first> <last>Freitas</last></author>
      <pages>556–564</pages>
      <url hash="9faed52d">S17-2092</url>
      <doi>10.18653/v1/S17-2092</doi>
      <abstract>This task proposes a challenge to support the interaction between users and applications, <a href="https://en.wikipedia.org/wiki/Microservices">micro-services</a> and software APIs using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>. The task aims for supporting the evaluation and evolution of the discussions surrounding the natural language processing approaches within the context of end-user natural language programming, under scenarios of high semantic heterogeneity / gap.</abstract>
      <bibkey>sales-etal-2017-semeval</bibkey>
    </paper>
    <paper id="95">
      <title>Lancaster A at SemEval-2017 Task 5 : Evaluation metrics matter : predicting sentiment from financial news headlines<fixed-case>L</fixed-case>ancaster A at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Evaluation metrics matter: predicting sentiment from financial news headlines</title>
      <author><first>Andrew</first> <last>Moore</last></author>
      <author><first>Paul</first> <last>Rayson</last></author>
      <pages>581–585</pages>
      <url hash="dc8632a3">S17-2095</url>
      <doi>10.18653/v1/S17-2095</doi>
      <abstract>This paper describes our participation in Task 5 track 2 of SemEval 2017 to predict the sentiment of financial news headlines for a specific company on a continuous scale between -1 and 1. We tackled the problem using a number of approaches, utilising a Support Vector Regression (SVR) and a Bidirectional Long Short-Term Memory (BLSTM). We found an improvement of 4-6 % using the LSTM model over the <a href="https://en.wikipedia.org/wiki/Stéphane_Ratel_Organisation">SVR</a> and came fourth in the track. We report a number of different evaluations using a finance specific word embedding model and reflect on the effects of using different evaluation metrics.</abstract>
      <attachment type="poster" hash="7120a76d">S17-2095.Poster.pdf</attachment>
      <attachment type="presentation" hash="bd5a6b49">S17-2095.Presentation.pdf</attachment>
      <bibkey>moore-rayson-2017-lancaster</bibkey>
      <pwccode url="https://github.com/apmoore1/semeval" additional="false">apmoore1/semeval</pwccode>
    </paper>
    <paper id="96">
      <title>Sheffield at SemEval-2017 Task 9 : Transition-based language generation from AMR.<fixed-case>S</fixed-case>heffield at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: Transition-based language generation from <fixed-case>AMR</fixed-case>.</title>
      <author><first>Gerasimos</first> <last>Lampouras</last></author>
      <author><first>Andreas</first> <last>Vlachos</last></author>
      <pages>586–591</pages>
      <url hash="7061435e">S17-2096</url>
      <doi>10.18653/v1/S17-2096</doi>
      <abstract>This paper describes the submission by the University of Sheffield to the SemEval 2017 Abstract Meaning Representation Parsing and Generation task (SemEval 2017 Task 9, Subtask 2). We cast language generation from AMR as a sequence of <a href="https://en.wikipedia.org/wiki/Action_(philosophy)">actions</a> (e.g., insert / remove / rename edges and nodes) that progressively transform the AMR graph into a dependency parse tree. This transition-based approach relies on the fact that an AMR graph can be considered structurally similar to a dependency tree, with a focus on content rather than <a href="https://en.wikipedia.org/wiki/Function_word">function words</a>. An added benefit to this approach is the greater amount of data we can take advantage of to train the parse-to-text linearizer. Our submitted run on the <a href="https://en.wikipedia.org/wiki/Test_(assessment)">test data</a> achieved a <a href="https://en.wikipedia.org/wiki/BLEU">BLEU score</a> of 3.32 and a Trueskill score of -22.04 on <a href="https://en.wikipedia.org/wiki/Human_factors_and_ergonomics">automatic and human evaluation</a> respectively.</abstract>
      <bibkey>lampouras-vlachos-2017-sheffield</bibkey>
    </paper>
    <paper id="98">
      <title>LIMSI-COT at SemEval-2017 Task 12 : Neural Architecture for Temporal Information Extraction from Clinical Narratives<fixed-case>LIMSI</fixed-case>-<fixed-case>COT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 12: Neural Architecture for Temporal Information Extraction from Clinical Narratives</title>
      <author><first>Julien</first> <last>Tourille</last></author>
      <author><first>Olivier</first> <last>Ferret</last></author>
      <author><first>Xavier</first> <last>Tannier</last></author>
      <author><first>Aurélie</first> <last>Névéol</last></author>
      <pages>597–602</pages>
      <url hash="eb2ff9c5">S17-2098</url>
      <doi>10.18653/v1/S17-2098</doi>
      <abstract>In this paper we present our participation to SemEval 2017 Task 12. We used a neural network based approach for entity and temporal relation extraction, and experimented with two domain adaptation strategies. We achieved competitive performance for both <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>.</abstract>
      <bibkey>tourille-etal-2017-limsi</bibkey>
    </paper>
    <paper id="99">
      <title>OMAM at SemEval-2017 Task 4 : Evaluation of English State-of-the-Art Sentiment Analysis Models for Arabic and a New Topic-based Model<fixed-case>OMAM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Evaluation of <fixed-case>E</fixed-case>nglish State-of-the-Art Sentiment Analysis Models for <fixed-case>A</fixed-case>rabic and a New Topic-based Model</title>
      <author><first>Ramy</first> <last>Baly</last></author>
      <author><first>Gilbert</first> <last>Badaro</last></author>
      <author><first>Ali</first> <last>Hamdi</last></author>
      <author><first>Rawan</first> <last>Moukalled</last></author>
      <author><first>Rita</first> <last>Aoun</last></author>
      <author><first>Georges</first> <last>El-Khoury</last></author>
      <author><first>Ahmad</first> <last>Al Sallab</last></author>
      <author><first>Hazem</first> <last>Hajj</last></author>
      <author><first>Nizar</first> <last>Habash</last></author>
      <author><first>Khaled</first> <last>Shaban</last></author>
      <author><first>Wassim</first> <last>El-Hajj</last></author>
      <pages>603–610</pages>
      <url hash="53516a59">S17-2099</url>
      <doi>10.18653/v1/S17-2099</doi>
      <abstract>While <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in <a href="https://en.wikipedia.org/wiki/English_language">English</a> has achieved significant progress, it remains a challenging task in <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> given the rich morphology of the language. It becomes more challenging when applied to Twitter data that comes with additional sources of noise including <a href="https://en.wikipedia.org/wiki/Dialect">dialects</a>, misspellings, grammatical mistakes, <a href="https://en.wikipedia.org/wiki/Code-switching">code switching</a> and the use of non-textual objects to express sentiments. This paper describes the OMAM systems that we developed as part of SemEval-2017 task 4. We evaluate English state-of-the-art methods on <a href="https://en.wikipedia.org/wiki/Twitter">Arabic tweets</a> for subtask A. As for the remaining subtasks, we introduce a topic-based approach that accounts for topic specificities by predicting topics or domains of upcoming tweets, and then using this <a href="https://en.wikipedia.org/wiki/Information">information</a> to predict their <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment</a>. Results indicate that applying the English state-of-the-art method to <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a> has achieved solid results without significant enhancements. Furthermore, the topic-based method ranked 1st in subtasks C and E, and 2nd in subtask D.</abstract>
      <bibkey>baly-etal-2017-omam</bibkey>
    </paper>
    <paper id="100">
      <title>NILC-USP at SemEval-2017 Task 4 : A Multi-view Ensemble for Twitter Sentiment Analysis<fixed-case>NILC</fixed-case>-<fixed-case>USP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: A Multi-view Ensemble for <fixed-case>T</fixed-case>witter Sentiment Analysis</title>
      <author><first>Edilson Anselmo</first> <last>Corrêa Júnior</last></author>
      <author><first>Vanessa Queiroz</first> <last>Marinho</last></author>
      <author><first>Leandro Borges</first> <last>dos Santos</last></author>
      <pages>611–615</pages>
      <url hash="473174c9">S17-2100</url>
      <doi>10.18653/v1/S17-2100</doi>
      <abstract>This paper describes our multi-view ensemble approach to SemEval-2017 Task 4 on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, specifically, the Message Polarity Classification subtask for English (subtask A). Our system is a voting ensemble, where each base classifier is trained in a different <a href="https://en.wikipedia.org/wiki/Feature_space">feature space</a>. The first space is a <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words model</a> and has a Linear SVM as base classifier. The second and third spaces are two different strategies of combining <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> to represent sentences and use a Linear SVM and a <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regressor</a> as base classifiers. The proposed <a href="https://en.wikipedia.org/wiki/System">system</a> was ranked 18th out of 38 systems considering F1 score and 20th considering recall.</abstract>
      <bibkey>correa-junior-etal-2017-nilc</bibkey>
      <pwccode url="https://github.com/edilsonacjr/semeval2017" additional="false">edilsonacjr/semeval2017</pwccode>
    </paper>
    <paper id="101">
      <title>deepSA at SemEval-2017 Task 4 : Interpolated Deep Neural Networks for Sentiment Analysis in Twitter<fixed-case>SA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Interpolated Deep Neural Networks for Sentiment Analysis in <fixed-case>T</fixed-case>witter</title>
      <author><first>Tzu-Hsuan</first> <last>Yang</last></author>
      <author><first>Tzu-Hsuan</first> <last>Tseng</last></author>
      <author><first>Chia-Ping</first> <last>Chen</last></author>
      <pages>616–620</pages>
      <url hash="732519d1">S17-2101</url>
      <doi>10.18653/v1/S17-2101</doi>
      <abstract>In this paper, we describe our system implementation for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. This system combines two models based on deep neural networks, namely a convolutional neural network (CNN) and a long short-term memory (LSTM) recurrent neural network, through interpolation. Distributed representation of words as vectors are input to the <a href="https://en.wikipedia.org/wiki/System">system</a>, and the output is a sentiment class. The neural network models are trained exclusively with the data sets provided by the organizers of SemEval-2017 Task 4 Subtask A. Overall, this <a href="https://en.wikipedia.org/wiki/System">system</a> has achieved 0.618 for the average recall rate, 0.587 for the average F1 score, and 0.618 for <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <bibkey>yang-etal-2017-deepsa</bibkey>
    </paper>
    <paper id="102">
      <title>NNEMBs at SemEval-2017 Task 4 : Neural Twitter Sentiment Classification : a Simple Ensemble Method with Different Embeddings<fixed-case>NNEMB</fixed-case>s at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Neural <fixed-case>T</fixed-case>witter Sentiment Classification: a Simple Ensemble Method with Different Embeddings</title>
      <author><first>Yichun</first> <last>Yin</last></author>
      <author><first>Yangqiu</first> <last>Song</last></author>
      <author><first>Ming</first> <last>Zhang</last></author>
      <pages>621–625</pages>
      <url hash="83cc1c1d">S17-2102</url>
      <doi>10.18653/v1/S17-2102</doi>
      <abstract>Recently, neural twitter sentiment classification has become one of state-of-thearts, which relies less feature engineering work compared with traditional methods. In this paper, we propose a simple and effective <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble method</a> to further boost the performances of neural models. We collect several word embedding sets which are publicly released (often are learned on different corpus) or constructed by running <a href="https://en.wikipedia.org/wiki/Skip-gram">Skip-gram</a> on released large-scale corpus. We make an assumption that different <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> cover different words and encode different semantic knowledge, thus using them together can improve the generalizations and performances of neural models. In the SemEval 2017, our method ranks 1st in <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Accuracy</a>, 5th in AverageR. Meanwhile, the additional comparisons demonstrate the superiority of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> over these ones based on only one word embedding set. We release our code for the method duplicability.</abstract>
      <bibkey>yin-etal-2017-nnembs</bibkey>
    </paper>
    <paper id="103">
      <title>CrystalNest at SemEval-2017 Task 4 : Using Sarcasm Detection for Enhancing Sentiment Classification and Quantification<fixed-case>C</fixed-case>rystal<fixed-case>N</fixed-case>est at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Using Sarcasm Detection for Enhancing Sentiment Classification and Quantification</title>
      <author><first>Raj Kumar</first> <last>Gupta</last></author>
      <author><first>Yinping</first> <last>Yang</last></author>
      <pages>626–633</pages>
      <url hash="c7b48b40">S17-2103</url>
      <doi>10.18653/v1/S17-2103</doi>
      <abstract>This paper describes a system developed for a shared sentiment analysis task and its subtasks organized by SemEval-2017. A key feature of our <a href="https://en.wikipedia.org/wiki/System">system</a> is the embedded ability to detect <a href="https://en.wikipedia.org/wiki/Sarcasm">sarcasm</a> in order to enhance the performance of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment classification</a>. We first constructed an affect-cognition-sociolinguistics sarcasm features model and trained a SVM-based classifier for detecting sarcastic expressions from general tweets. For sentiment prediction, we developed CrystalNest a two-level cascade classification system using features combining sarcasm score derived from our sarcasm classifier, sentiment scores from Alchemy, NRC lexicon, n-grams, word embedding vectors, and part-of-speech features. We found that the sarcasm detection derived features consistently benefited key sentiment analysis evaluation metrics, in different degrees, across four subtasks A-D.</abstract>
      <bibkey>gupta-yang-2017-crystalnest</bibkey>
    </paper>
    <paper id="104">
      <title>SINAI at SemEval-2017 Task 4 : User based classification<fixed-case>SINAI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: User based classification</title>
      <author><first>Salud María</first> <last>Jiménez-Zafra</last></author>
      <author><first>Arturo</first> <last>Montejo-Ráez</last></author>
      <author><first>Maite</first> <last>Martin</last></author>
      <author><first>L. Alfonso</first> <last>Ureña-López</last></author>
      <pages>634–639</pages>
      <url hash="7338f5c4">S17-2104</url>
      <doi>10.18653/v1/S17-2104</doi>
      <abstract>This document describes our participation in SemEval-2017 Task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. We have only reported results for subtask B-English, determining the polarity towards a topic on a two point scale (positive or negative sentiment). Our main contribution is the integration of <a href="https://en.wikipedia.org/wiki/User_information">user information</a> in the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification process</a>. A SVM model is trained with Word2Vec vectors from user’s tweets extracted from his timeline. The obtained results show that user-specific classifiers trained on tweets from user timeline can introduce <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> as they are error prone because they are classified by an imperfect system. This encourages us to explore further integration of <a href="https://en.wikipedia.org/wiki/User_information">user information</a> for author-based Sentiment Analysis.</abstract>
      <bibkey>jimenez-zafra-etal-2017-sinai</bibkey>
    </paper>
    <paper id="105">
      <title>HLP@UPenn at SemEval-2017 Task 4A : A simple, self-optimizing text classification system combining dense and sparse vectors<fixed-case>HLP</fixed-case>@<fixed-case>UP</fixed-case>enn at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4<fixed-case>A</fixed-case>: A simple, self-optimizing text classification system combining dense and sparse vectors</title>
      <author><first>Abeed</first> <last>Sarker</last></author>
      <author><first>Graciela</first> <last>Gonzalez</last></author>
      <pages>640–643</pages>
      <url hash="31a2d64c">S17-2105</url>
      <doi>10.18653/v1/S17-2105</doi>
      <abstract>We present a simple supervised text classification system that combines sparse and dense vector representations of words, and generalized representations of words via clusters. The <a href="https://en.wikipedia.org/wiki/Sparse_matrix">sparse vectors</a> are generated from word n-gram sequences (1-3). The dense vector representations of words (embeddings) are learned by training a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> to predict neighboring words in a large unlabeled dataset. To classify a text segment, the different representations of it are concatenated, and the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> is performed using Support Vector Machines (SVM). Our <a href="https://en.wikipedia.org/wiki/System">system</a> is particularly intended for use by non-experts of natural language processing and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a>, and, therefore, the <a href="https://en.wikipedia.org/wiki/System">system</a> does not require any manual tuning of parameters or weights. Given a training set, the system automatically generates the training vectors, optimizes the relevant <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyper-parameters</a> for the SVM classifier, and trains the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification model</a>. We evaluated this <a href="https://en.wikipedia.org/wiki/System">system</a> on the SemEval-2017 English sentiment analysis task. In terms of average F1-score, our <a href="https://en.wikipedia.org/wiki/System">system</a> obtained 8th position out of 39 submissions (F1-score : 0.632, <a href="https://en.wikipedia.org/wiki/Precision_and_recall">average recall</a> : 0.637, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> : 0.646).</abstract>
      <bibkey>sarker-gonzalez-2017-hlp</bibkey>
    </paper>
    <paper id="106">
      <title>ej-sa-2017 at SemEval-2017 Task 4 : Experiments for Target oriented Sentiment Analysis in Twitter<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Experiments for Target oriented Sentiment Analysis in <fixed-case>T</fixed-case>witter</title>
      <author><first>Enkhzol</first> <last>Dovdon</last></author>
      <author><first>José</first> <last>Saias</last></author>
      <pages>644–647</pages>
      <url hash="b8de344f">S17-2106</url>
      <doi>10.18653/v1/S17-2106</doi>
      <abstract>This paper describes the system we have used for participating in Subtasks A (Message Polarity Classification) and B (Topic-Based Message Polarity Classification according to a two-point scale) of SemEval-2017 Task 4 Sentiment Analysis in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. We used several features with a sentiment lexicon and <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP techniques</a>, <a href="https://en.wikipedia.org/wiki/Maximum_entropy">Maximum Entropy</a> as a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> for our system.</abstract>
      <bibkey>dovdon-saias-2017-ej</bibkey>
    </paper>
    <paper id="107">
      <title>SentiME++ at SemEval-2017 Task 4 : Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification<fixed-case>S</fixed-case>enti<fixed-case>ME</fixed-case>++ at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Stacking State-of-the-Art Classifiers to Enhance Sentiment Classification</title>
      <author><first>Raphaël</first> <last>Troncy</last></author>
      <author><first>Enrico</first> <last>Palumbo</last></author>
      <author><first>Efstratios</first> <last>Sygkounas</last></author>
      <author><first>Giuseppe</first> <last>Rizzo</last></author>
      <pages>648–652</pages>
      <url hash="ebfa87be">S17-2107</url>
      <doi>10.18653/v1/S17-2107</doi>
      <abstract>In this paper, we describe the participation of the SentiME++ system to the SemEval 2017 Task 4A Sentiment Analysis in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> that aims to classify whether English tweets are of positive, neutral or negative sentiment. SentiME++ is an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble approach</a> to <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> that leverages stacked generalization to automatically combine the predictions of five state-of-the-art sentiment classifiers. SentiME++ achieved officially 61.30 % F1-score, ranking 12th out of 38 participants.</abstract>
      <bibkey>troncy-etal-2017-sentime</bibkey>
    </paper>
    <paper id="108">
      <title>Amobee at SemEval-2017 Task 4 : Deep Learning System for Sentiment Detection on Twitter<fixed-case>A</fixed-case>mobee at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Deep Learning System for Sentiment Detection on <fixed-case>T</fixed-case>witter</title>
      <author><first>Alon</first> <last>Rozental</last></author>
      <author><first>Daniel</first> <last>Fleischer</last></author>
      <pages>653–658</pages>
      <url hash="19d90653">S17-2108</url>
      <doi>10.18653/v1/S17-2108</doi>
      <abstract>This paper describes the Amobee sentiment analysis system, adapted to compete in SemEval 2017 task 4. The system consists of two parts : a supervised training of RNN models based on a Twitter sentiment treebank, and the use of <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward NN</a>, Naive Bayes and logistic regression classifiers to produce predictions for the different sub-tasks. The <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> reached the 3rd place on the 5-label classification task (sub-task C).</abstract>
      <bibkey>rozental-fleischer-2017-amobee</bibkey>
    </paper>
    <paper id="110">
      <title>Tw-StAR at SemEval-2017 Task 4 : Sentiment Classification of Arabic Tweets<fixed-case>S</fixed-case>t<fixed-case>AR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Classification of <fixed-case>A</fixed-case>rabic Tweets</title>
      <author><first>Hala</first> <last>Mulki</last></author>
      <author><first>Hatem</first> <last>Haddad</last></author>
      <author><first>Mourad</first> <last>Gridach</last></author>
      <author><first>Ismail</first> <last>Babaoglu</last></author>
      <pages>664–669</pages>
      <url hash="653fe424">S17-2110</url>
      <doi>10.18653/v1/S17-2110</doi>
      <abstract>In this paper, we present our contribution in SemEval 2017 international workshop. We have tackled task 4 entitled <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, specifically subtask 4A-Arabic. We propose two Arabic sentiment classification models implemented using <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised and unsupervised learning strategies</a>. In both models, Arabic tweets were preprocessed first then various schemes of bag-of-N-grams were extracted to be used as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. The final submission was selected upon the best performance achieved by the <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning-based model</a>. However, the results obtained by the unsupervised learning-based model are considered promising and evolvable if more rich lexica are adopted in further work.</abstract>
      <bibkey>mulki-etal-2017-tw</bibkey>
    </paper>
    <paper id="111">
      <title>OMAM at SemEval-2017 Task 4 : English Sentiment Analysis with Conditional Random Fields<fixed-case>OMAM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: <fixed-case>E</fixed-case>nglish Sentiment Analysis with Conditional Random Fields</title>
      <author><first>Chukwuyem</first> <last>Onyibe</last></author>
      <author><first>Nizar</first> <last>Habash</last></author>
      <pages>670–674</pages>
      <url hash="97c1b87e">S17-2111</url>
      <doi>10.18653/v1/S17-2111</doi>
      <abstract>We describe a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised system</a> that uses optimized Condition Random Fields and lexical features to predict the sentiment of a tweet. The <a href="https://en.wikipedia.org/wiki/System">system</a> was submitted to the English version of all subtasks in SemEval-2017 Task 4.</abstract>
      <bibkey>onyibe-habash-2017-omam</bibkey>
    </paper>
    <paper id="112">
      <title>Tweester at SemEval-2017 Task 4 : Fusion of Semantic-Affective and pairwise classification models for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Fusion of Semantic-Affective and pairwise classification models for sentiment analysis in <fixed-case>T</fixed-case>witter</title>
      <author><first>Athanasia</first> <last>Kolovou</last></author>
      <author><first>Filippos</first> <last>Kokkinos</last></author>
      <author><first>Aris</first> <last>Fergadis</last></author>
      <author><first>Pinelopi</first> <last>Papalampidi</last></author>
      <author><first>Elias</first> <last>Iosif</last></author>
      <author><first>Nikolaos</first> <last>Malandrakis</last></author>
      <author><first>Elisavet</first> <last>Palogiannidi</last></author>
      <author><first>Haris</first> <last>Papageorgiou</last></author>
      <author><first>Shrikanth</first> <last>Narayanan</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>675–682</pages>
      <url hash="7a8e6837">S17-2112</url>
      <doi>10.18653/v1/S17-2112</doi>
      <abstract>In this paper, we describe our submission to SemEval2017 Task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>. Specifically the proposed system participated both to tweet polarity classification (two-, three- and five class) and tweet quantification (two and five-class) tasks.</abstract>
      <bibkey>kolovou-etal-2017-tweester</bibkey>
    </paper>
    <paper id="113">
      <title>NRU-HSE at SemEval-2017 Task 4 : Tweet Quantification Using Deep Learning Architecture<fixed-case>NRU</fixed-case>-<fixed-case>HSE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Tweet Quantification Using Deep Learning Architecture</title>
      <author><first>Nikolay</first> <last>Karpov</last></author>
      <pages>683–688</pages>
      <url hash="bf45cf68">S17-2113</url>
      <doi>10.18653/v1/S17-2113</doi>
      <abstract>In many areas, such as <a href="https://en.wikipedia.org/wiki/Social_science">social science</a>, politics or market research, people need to deal with dataset shifting over time. Distribution drift phenomenon usually appears in the field of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, when proportions of instances are changing over time. In this case, the task is to correctly estimate proportions of each sentiment expressed in the set of documents (quantification task). Basically, our study was aimed to analyze the effectiveness of a mixture of quantification technique with one of deep learning architecture. All the techniques are evaluated using the SemEval-2017 Task4 dataset and <a href="https://en.wikipedia.org/wiki/Source_code">source code</a>, mentioned in this paper and available online in the <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python programming language</a>. The results of an application of the <a href="https://en.wikipedia.org/wiki/Quantification_(science)">quantification techniques</a> are discussed.</abstract>
      <bibkey>karpov-2017-nru</bibkey>
    </paper>
    <paper id="114">
      <title>MI&amp;T Lab at SemEval-2017 task 4 : An Integrated Training Method of Word Vector for Sentiment Classification<fixed-case>MI</fixed-case>&amp;<fixed-case>T</fixed-case> Lab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 task 4: An Integrated Training Method of Word Vector for Sentiment Classification</title>
      <author><first>Jingjing</first> <last>Zhao</last></author>
      <author><first>Yan</first> <last>Yang</last></author>
      <author><first>Bing</first> <last>Xu</last></author>
      <pages>689–693</pages>
      <url hash="5e6ccf89">S17-2114</url>
      <doi>10.18653/v1/S17-2114</doi>
      <abstract>A CNN method for sentiment classification task in Task 4A of SemEval 2017 is presented. To solve the problem of <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> training word vector slowly, a method of training <a href="https://en.wikipedia.org/wiki/Word_vector">word vector</a> by integrating <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> and Convolutional Neural Network (CNN) is proposed. This training method not only improves the training speed of <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a>, but also makes the <a href="https://en.wikipedia.org/wiki/Word_(computer_architecture)">word vector</a> more effective for the target task. Furthermore, the <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> adopts a full connection between the input layer and the projection layer of the Continuous Bag-of-Words (CBOW) for acquiring the semantic information of the original sentence.</abstract>
      <bibkey>zhao-etal-2017-mi</bibkey>
    </paper>
    <paper id="115">
      <title>SiTAKA at SemEval-2017 Task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> Based on a Rich Set of Features<fixed-case>S</fixed-case>i<fixed-case>TAKA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Analysis in <fixed-case>T</fixed-case>witter Based on a Rich Set of Features</title>
      <author><first>Mohammed</first> <last>Jabreel</last></author>
      <author id="antonio-moreno-ribas"><first>Antonio</first> <last>Moreno</last></author>
      <pages>694–699</pages>
      <url hash="9783816c">S17-2115</url>
      <doi>10.18653/v1/S17-2115</doi>
      <abstract>This paper describes SiTAKA, our system that has been used in task 4A, English and Arabic languages, <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> of SemEval2017. The <a href="https://en.wikipedia.org/wiki/System">system</a> proposes the representation of tweets using a novel set of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, which include a bag of negated words and the information provided by some <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>. The polarity of tweets is determined by a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> based on a <a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machine</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> ranks 2nd among 8 systems in the Arabic language tweets and ranks 8th among 38 systems in the English-language tweets.</abstract>
      <bibkey>jabreel-moreno-2017-sitaka</bibkey>
    </paper>
    <paper id="116">
      <title>Senti17 at SemEval-2017 Task 4 : Ten Convolutional Neural Network Voters for Tweet Polarity Classification<fixed-case>S</fixed-case>enti17 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Ten Convolutional Neural Network Voters for Tweet Polarity Classification</title>
      <author><first>Hussam</first> <last>Hamdan</last></author>
      <pages>700–703</pages>
      <url hash="a6b66fe9">S17-2116</url>
      <doi>10.18653/v1/S17-2116</doi>
      <abstract>This paper presents Senti17 system which uses ten convolutional neural networks (ConvNet) to assign a sentiment label to a tweet. The network consists of a convolutional layer followed by a fully-connected layer and a <a href="https://en.wikipedia.org/wiki/Softmax">Softmax</a> on top. Ten instances of this <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">network</a> are initialized with the same word embeddings as inputs but with different initializations for the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">network weights</a>. We combine the results of all instances by selecting the sentiment label given by the majority of the ten voters. This system is ranked fourth in SemEval-2017 Task4 over 38 systems with 67.4 % average recall.</abstract>
      <bibkey>hamdan-2017-senti17</bibkey>
    </paper>
    <paper id="118">
      <title>SSN_MLRG1 at SemEval-2017 Task 4 : Sentiment Analysis in Twitter Using Multi-Kernel Gaussian Process Classifier<fixed-case>SSN</fixed-case>_<fixed-case>MLRG</fixed-case>1 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Analysis in <fixed-case>T</fixed-case>witter Using Multi-Kernel <fixed-case>G</fixed-case>aussian Process Classifier</title>
      <author><first>Angel Deborah</first> <last>S</last></author>
      <author><first>S Milton</first> <last>Rajendram</last></author>
      <author><first>T T</first> <last>Mirnalinee</last></author>
      <pages>709–712</pages>
      <url hash="d5fe7f2f">S17-2118</url>
      <doi>10.18653/v1/S17-2118</doi>
      <abstract>The SSN MLRG1 team for Semeval-2017 task 4 has applied <a href="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian Process</a>, with bag of words feature vectors and fixed rule multi-kernel learning, for sentiment analysis of tweets. Since tweets on the same topic, made at different times, may exhibit different emotions, their properties such as <a href="https://en.wikipedia.org/wiki/Smoothness">smoothness</a> and <a href="https://en.wikipedia.org/wiki/Frequency">periodicity</a> also vary with time. Our experiments show that, compared to single kernel, multiple kernels are effective in learning the simultaneous presence of multiple properties.</abstract>
      <bibkey>s-etal-2017-ssn</bibkey>
    </paper>
    <paper id="119">
      <title>YNUDLG at SemEval-2017 Task 4 : A GRU-SVM Model for Sentiment Classification and Quantification in Twitter<fixed-case>YNUDLG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: A <fixed-case>GRU</fixed-case>-<fixed-case>SVM</fixed-case> Model for Sentiment Classification and Quantification in <fixed-case>T</fixed-case>witter</title>
      <author><first>Ming</first> <last>Wang</last></author>
      <author><first>Biao</first> <last>Chu</last></author>
      <author><first>Qingxun</first> <last>Liu</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>713–717</pages>
      <url hash="8884a080">S17-2119</url>
      <doi>10.18653/v1/S17-2119</doi>
      <abstract>Sentiment analysis is one of the central issues in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> and has become more and more important in many fields. Typical sentiment analysis classifies the sentiment of sentences into several discrete classes (e.g.,positive or negative). In this paper we describe our deep learning system(combining GRU and SVM) to solve both two-, three- and five-tweet polarity classifications. We first trained a gated recurrent neural network using pre-trained word embeddings, then we extracted <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> from GRU layer and input these <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> into support vector machine to fulfill both the classification and quantification subtasks. The proposed approach achieved 37th, 19th, and 14rd places in subtasks A, B and C, respectively.</abstract>
      <bibkey>wang-etal-2017-ynudlg-semeval</bibkey>
    </paper>
    <paper id="120">
      <title>LSIS at SemEval-2017 Task 4 : Using Adapted Sentiment Similarity Seed Words For English and Arabic Tweet Polarity Classification<fixed-case>LSIS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Using Adapted Sentiment Similarity Seed Words For <fixed-case>E</fixed-case>nglish and <fixed-case>A</fixed-case>rabic Tweet Polarity Classification</title>
      <author><first>Amal</first> <last>Htait</last></author>
      <author><first>Sébastien</first> <last>Fournier</last></author>
      <author><first>Patrice</first> <last>Bellot</last></author>
      <pages>718–722</pages>
      <url hash="75b44678">S17-2120</url>
      <doi>10.18653/v1/S17-2120</doi>
      <abstract>We present, in this paper, our contribution in SemEval2017 task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, subtask A : Message Polarity Classification, for English and Arabic languages. Our system is based on a list of sentiment seed words adapted for <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. The sentiment relations between seed words and other terms are captured by <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> between the word embedding representations (word2vec). These seed words are extracted from datasets of annotated tweets available online. Our tests, using these seed words, show significant improvement in results compared to the use of Turney and Littman’s (2003) seed words, on polarity classification of tweet messages.</abstract>
      <bibkey>htait-etal-2017-lsis</bibkey>
    </paper>
    <paper id="121">
      <title>ELiRF-UPV at SemEval-2017 Task 4 : <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> using <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a><fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Analysis using Deep Learning</title>
      <author><first>José-Ángel</first> <last>González</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <author><first>Lluís-F.</first> <last>Hurtado</last></author>
      <pages>723–727</pages>
      <url hash="b4c38016">S17-2121</url>
      <doi>10.18653/v1/S17-2121</doi>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 4 of SemEval2017. Our approach is based on the use of convolutional and recurrent neural networks and the combination of general and specific word embeddings with polarity lexicons. We participated in all of the proposed subtasks both for English and Arabic languages using the same system with small variations.</abstract>
      <bibkey>gonzalez-etal-2017-elirf</bibkey>
    </paper>
    <paper id="122">
      <title>XJSA at SemEval-2017 Task 4 : A Deep System for Sentiment Classification in Twitter<fixed-case>XJSA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: A Deep System for Sentiment Classification in <fixed-case>T</fixed-case>witter</title>
      <author><first>Yazhou</first> <last>Hao</last></author>
      <author><first>YangYang</first> <last>Lan</last></author>
      <author><first>Yufei</first> <last>Li</last></author>
      <author><first>Chen</first> <last>Li</last></author>
      <pages>728–731</pages>
      <url hash="207ccb67">S17-2122</url>
      <doi>10.18653/v1/S17-2122</doi>
      <abstract>This paper describes the XJSA System submission from XJTU. Our <a href="https://en.wikipedia.org/wiki/System">system</a> was created for SemEval2017 Task 4   subtask A which is very popular and fundamental. The <a href="https://en.wikipedia.org/wiki/System">system</a> is based on <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embedding</a>. We used two pre-trained word vectors and adopt a dynamic strategy for k-max pooling.</abstract>
      <bibkey>hao-etal-2017-xjsa</bibkey>
    </paper>
    <paper id="124">
      <title>EICA at SemEval-2017 Task 4 : A Simple Convolutional Neural Network for Topic-based Sentiment Classification<fixed-case>EICA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: A Simple Convolutional Neural Network for Topic-based Sentiment Classification</title>
      <author><last>Wang</last> <first>Maoquan</first></author>
      <author><last>Chen</last> <first>Shiyun</first></author>
      <author><last>Xie</last> <first>Yufei</first></author>
      <author><last>Zhao</last> <first>Lu</first></author>
      <pages>737–740</pages>
      <url hash="53668ae8">S17-2124</url>
      <doi>10.18653/v1/S17-2124</doi>
      <abstract>This paper describes our approach for SemEval-2017 Task 4-Sentiment Analysis in Twitter (SAT). Its five subtasks are divided into two categories : (1) <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment classification</a>, i.e., predicting topic-based tweet sentiment polarity, and (2) sentiment quantification, that is, estimating the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment distributions</a> of a set of given tweets. We build a convolutional sentence classification system for the task of <a href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem">SAT</a>. Official results show that the experimental results of our <a href="https://en.wikipedia.org/wiki/System">system</a> are comparative.</abstract>
      <bibkey>wang-etal-2017-eica</bibkey>
    </paper>
    <paper id="127">
      <title>TwiSe at SemEval-2017 Task 4 : Five-point Twitter Sentiment Classification and Quantification<fixed-case>T</fixed-case>wi<fixed-case>S</fixed-case>e at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Five-point <fixed-case>T</fixed-case>witter Sentiment Classification and Quantification</title>
      <author><first>Georgios</first> <last>Balikas</last></author>
      <pages>755–759</pages>
      <url hash="2a0a5cca">S17-2127</url>
      <doi>10.18653/v1/S17-2127</doi>
      <abstract>The paper describes the participation of the team TwiSE in the SemEval-2017 challenge. Specifically, I participated at Task 4 entitled Sentiment Analysis in <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> for which I implemented systems for five-point tweet classification (Subtask C) and five-point tweet quantification (Subtask E) for English tweets. In the feature extraction steps the systems rely on the <a href="https://en.wikipedia.org/wiki/Vector_space_model">vector space model</a>, morpho-syntactic analysis of the <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a> and several sentiment lexicons. The classification step of Subtask C uses a <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> trained with the one-versus-rest approach. Another instance of <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic Regression</a> combined with the classify-and-count approach is trained for the quantification task of Subtask E. In the official leaderboard the system is ranked 5/15 in Subtask C and 2/12 in Subtask E.<i>5/15</i> in Subtask C and <i>2/12</i> in Subtask E.
    </abstract>
      <bibkey>balikas-2017-twise</bibkey>
    </paper>
    <paper id="128">
      <title>LIA at SemEval-2017 Task 4 : An Ensemble of Neural Networks for Sentiment Classification<fixed-case>LIA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: An Ensemble of Neural Networks for Sentiment Classification</title>
      <author><first>Mickael</first> <last>Rouvier</last></author>
      <pages>760–765</pages>
      <url hash="9f3c7527">S17-2128</url>
      <doi>10.18653/v1/S17-2128</doi>
      <abstract>This paper describes the <a href="https://en.wikipedia.org/wiki/System">system</a> developed at LIA for the SemEval-2017 evaluation campaign. The goal of Task 4.A was to identify sentiment polarity in <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. The system is an ensemble of Deep Neural Network (DNN) models : Convolutional Neural Network (CNN) and Recurrent Neural Network Long Short-Term Memory (RNN-LSTM). We initialize the input representation of <a href="https://en.wikipedia.org/wiki/Deep_learning">DNN</a> with different sets of <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> trained on large datasets. The ensemble of DNNs are combined using a score-level fusion approach. The <a href="https://en.wikipedia.org/wiki/System">system</a> ranked 2nd at SemEval-2017 and obtained an <a href="https://en.wikipedia.org/wiki/Recall_(memory)">average recall</a> of 67.6 %.</abstract>
      <bibkey>rouvier-2017-lia</bibkey>
    </paper>
    <paper id="129">
      <title>TopicThunder at SemEval-2017 Task 4 : Sentiment Classification Using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a> with Distant Supervision<fixed-case>T</fixed-case>opic<fixed-case>T</fixed-case>hunder at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Sentiment Classification Using a Convolutional Neural Network with Distant Supervision</title>
      <author><first>Simon</first> <last>Müller</last></author>
      <author><first>Tobias</first> <last>Huonder</last></author>
      <author><first>Jan</first> <last>Deriu</last></author>
      <author><first>Mark</first> <last>Cieliebak</last></author>
      <pages>766–770</pages>
      <url hash="f0ccdaf7">S17-2129</url>
      <doi>10.18653/v1/S17-2129</doi>
      <abstract>In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> for predicting topic-specific sentiments of English Twitter messages. Our method is based on a 2-layer CNN.With a distant supervised phase we leverage a large amount of weakly-labelled training data. Our system was evaluated on the <a href="https://en.wikipedia.org/wiki/Data">data</a> provided by the SemEval-2017 competition in the Topic-Based Message Polarity Classification subtask, where it ranked 4th place.</abstract>
      <bibkey>muller-etal-2017-topicthunder</bibkey>
    </paper>
    <paper id="133">
      <title>NileTMRG at SemEval-2017 Task 4 : Arabic Sentiment Analysis<fixed-case>N</fixed-case>ile<fixed-case>TMRG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: <fixed-case>A</fixed-case>rabic Sentiment Analysis</title>
      <author><first>Samhaa R.</first> <last>El-Beltagy</last></author>
      <author><first>Mona</first> <last>El Kalamawy</last></author>
      <author><first>Abu Bakr</first> <last>Soliman</last></author>
      <pages>790–795</pages>
      <url hash="3edd98f3">S17-2133</url>
      <doi>10.18653/v1/S17-2133</doi>
      <abstract>This paper describes two systems that were used by the NileTMRG for addressing Arabic Sentiment Analysis as part of SemEval-2017, task 4. NileTMRG participated in three Arabic related subtasks which are : Subtask A (Message Polarity Classification), Subtask B (Topic-Based Message Polarity classification) and Subtask D (Tweet quantification). For subtask A, we made use of NU’s sentiment analyzer which we augmented with a scored lexicon. For subtasks B and D, we used an ensemble of three different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>. The first <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> was a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> that used trained (word2vec) word embeddings. The second <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> consisted of a MultiLayer Perceptron while the third <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> was a <a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic regression model</a> that takes the same input as the second <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a>. Voting between the three classifiers was used to determine the final outcome. In all three <a href="https://en.wikipedia.org/wiki/Tertiary_sector_of_the_economy">Arabic related tasks</a> in which NileTMRG participated, the team ranked at number one.</abstract>
      <bibkey>el-beltagy-etal-2017-niletmrg</bibkey>
    </paper>
    <paper id="135">
      <title>TSA-INF at SemEval-2017 Task 4 : An Ensemble of Deep Learning Architectures Including Lexicon Features for Twitter Sentiment Analysis<fixed-case>TSA</fixed-case>-<fixed-case>INF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: An Ensemble of Deep Learning Architectures Including Lexicon Features for <fixed-case>T</fixed-case>witter Sentiment Analysis</title>
      <author><first>Amit Ajit</first> <last>Deshmane</last></author>
      <author><first>Jasper</first> <last>Friedrichs</last></author>
      <pages>802–806</pages>
      <url hash="32fd39ee">S17-2135</url>
      <doi>10.18653/v1/S17-2135</doi>
      <abstract>This paper describes the submission of team TSA-INF to SemEval-2017 Task 4 Subtask A. The submitted <a href="https://en.wikipedia.org/wiki/System">system</a> is an ensemble of three varying deep learning architectures for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>. The core of the <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a> is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> that performs well on <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> as is. The second <a href="https://en.wikipedia.org/wiki/System">subsystem</a> is a gated recurrent neural network implementation. Additionally, the third <a href="https://en.wikipedia.org/wiki/System">system</a> integrates <a href="https://en.wikipedia.org/wiki/Lexicon">opinion lexicons</a> directly into a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolution neural network architecture</a>. The resulting ensemble of the three <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> achieved a top ten ranking with a macro-averaged recall of 64.3 %. Additional results comparing variations of the submitted system are not conclusive enough to determine a best <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a>, but serve as a benchmark for further implementations.</abstract>
      <bibkey>deshmane-friedrichs-2017-tsa</bibkey>
    </paper>
    <paper id="137">
      <title>ECNU at SemEval-2017 Task 4 : Evaluating Effective Features on Machine Learning Methods for Twitter Message Polarity Classification<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 4: Evaluating Effective Features on Machine Learning Methods for <fixed-case>T</fixed-case>witter Message Polarity Classification</title>
      <author><first>Yunxiao</first> <last>Zhou</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>812–816</pages>
      <url hash="79dbabf5">S17-2137</url>
      <doi>10.18653/v1/S17-2137</doi>
      <abstract>This paper reports our submission to subtask A of task 4 (Sentiment Analysis in Twitter, SAT) in SemEval 2017, i.e., Message Polarity Classification. We investigated several traditional <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP) features</a>, domain specific features and word embedding features together with <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine learning methods</a> to address this task. Officially released results showed that our <a href="https://en.wikipedia.org/wiki/System">system</a> ranked above average.</abstract>
      <bibkey>zhou-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="139">
      <title>SSN_MLRG1 at SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis Using Multiple Kernel Gaussian Process Regression Model<fixed-case>SSN</fixed-case>_<fixed-case>MLRG</fixed-case>1 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Fine-Grained Sentiment Analysis Using Multiple Kernel <fixed-case>G</fixed-case>aussian Process Regression Model</title>
      <author><first>Angel Deborah</first> <last>S</last></author>
      <author><first>S Milton</first> <last>Rajendram</last></author>
      <author><first>T T</first> <last>Mirnalinee</last></author>
      <pages>823–826</pages>
      <url hash="aeb9940a">S17-2139</url>
      <doi>10.18653/v1/S17-2139</doi>
      <abstract>The system developed by the SSN_MLRG1 team for Semeval-2017 task 5 on fine-grained sentiment analysis uses Multiple Kernel Gaussian Process for identifying the optimistic and pessimistic sentiments associated with companies and stocks. Since the comments made at different times about the same companies and stocks may display different emotions, their properties such as <a href="https://en.wikipedia.org/wiki/Smoothness">smoothness</a> and <a href="https://en.wikipedia.org/wiki/Frequency">periodicity</a> may vary. Our experiments show that while single kernel Gaussian Process can learn certain properties well, Multiple Kernel Gaussian Process are effective in learning the presence of different properties simultaneously.</abstract>
      <bibkey>s-etal-2017-ssn-mlrg1</bibkey>
    </paper>
    <paper id="141">
      <title>HHU at SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis on Financial Data using Machine Learning Methods<fixed-case>HHU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Data using Machine Learning Methods</title>
      <author><first>Tobias</first> <last>Cabanski</last></author>
      <author><first>Julia</first> <last>Romberg</last></author>
      <author><first>Stefan</first> <last>Conrad</last></author>
      <pages>832–836</pages>
      <url hash="f96dda3d">S17-2141</url>
      <doi>10.18653/v1/S17-2141</doi>
      <abstract>In this Paper a <a href="https://en.wikipedia.org/wiki/System">system</a> for solving SemEval-2017 Task 5 is presented. This task is divided into two tracks where the sentiment of microblog messages and <a href="https://en.wikipedia.org/wiki/Headline">news headlines</a> has to be predicted. Since two submissions were allowed, two different <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning methods</a> were developed to solve this task, a <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine approach</a> and a <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network approach</a>. To feed in data for these approaches, different <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extraction methods</a> are used, mainly <a href="https://en.wikipedia.org/wiki/Word_processor_(electronic_device)">word representations</a> and <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexica</a>. The best submissions for both tracks are provided by the <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural network</a> which achieves a F1-score of 0.729 in track 1 and 0.702 in track 2.</abstract>
      <bibkey>cabanski-etal-2017-hhu</bibkey>
    </paper>
    <paper id="142">
      <title>INF-UFRGS at SemEval-2017 Task 5 : A Supervised Identification of Sentiment Score in Tweets and Headlines<fixed-case>INF</fixed-case>-<fixed-case>UFRGS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: A Supervised Identification of Sentiment Score in Tweets and Headlines</title>
      <author><first>Tiago</first> <last>Zini</last></author>
      <author><first>Karin</first> <last>Becker</last></author>
      <author><first>Marcelo</first> <last>Dias</last></author>
      <pages>837–841</pages>
      <url hash="97d07a71">S17-2142</url>
      <doi>10.18653/v1/S17-2142</doi>
      <abstract>This paper describes a supervised solution for detecting the polarity scores of tweets or headline news in the financial domain, submitted to the SemEval 2017 Fine-Grained Sentiment Analysis on Financial Microblogs and News Task. The premise is that it is possible to understand <a href="https://en.wikipedia.org/wiki/Market_sentiment">market reaction</a> over a company stock by measuring the positive / negative sentiment contained in the financial tweets and news headlines, where polarity is measured in a continuous scale ranging from -1.0 (very bearish) to 1.0 (very bullish). Our system receives as input the textual content of tweets or news headlines, together with their <a href="https://en.wikipedia.org/wiki/User_(computing)">ids</a>, stock cashtag or name of target company, and the polarity score gold standard for the training dataset. Our solution retrieves <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> from these text instances using <a href="https://en.wikipedia.org/wiki/N-gram">n-gram</a>, hashtags, sentiment score calculated by a external APIs and others <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to train a regression model capable to detect continuous score of these sentiments with precision.</abstract>
      <bibkey>zini-etal-2017-inf</bibkey>
    </paper>
    <paper id="143">
      <title>HCS at SemEval-2017 Task 5 : Polarity detection in business news using convolutional neural networks<fixed-case>HCS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Polarity detection in business news using convolutional neural networks</title>
      <author><first>Lidia</first> <last>Pivovarova</last></author>
      <author><first>Llorenç</first> <last>Escoter</last></author>
      <author><first>Arto</first> <last>Klami</last></author>
      <author><first>Roman</first> <last>Yangarber</last></author>
      <pages>842–846</pages>
      <url hash="b19c8a6c">S17-2143</url>
      <doi>10.18653/v1/S17-2143</doi>
      <abstract>Task 5 of SemEval-2017 involves fine-grained sentiment analysis on <a href="https://en.wikipedia.org/wiki/Microblogging">financial microblogs</a> and <a href="https://en.wikipedia.org/wiki/News">news</a>. Our solution for determining the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment score</a> extends an earlier <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> in several ways. We explicitly encode a focus on a particular company, we apply a data augmentation scheme, and use a larger data collection to complement the small training data provided by the task organizers. The best results were achieved by training a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> on an external dataset and then tuning it using the provided training dataset.</abstract>
      <bibkey>pivovarova-etal-2017-hcs</bibkey>
    </paper>
    <paper id="144">
      <title>NLG301 at SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis on Financial Microblogs and News<fixed-case>NLG</fixed-case>301 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News</title>
      <author><first>Chung-Chi</first> <last>Chen</last></author>
      <author><first>Hen-Hsen</first> <last>Huang</last></author>
      <author><first>Hsin-Hsi</first> <last>Chen</last></author>
      <pages>847–851</pages>
      <url hash="6c3fd57f">S17-2144</url>
      <doi>10.18653/v1/S17-2144</doi>
      <abstract>Short length, multi-targets, target relation-ship, monetary expressions, and outside reference are characteristics of financial tweets. This paper proposes methods to extract target spans from a tweet and its referencing web page. Total 15 publicly available sentiment dictionaries and one sentiment dictionary constructed from training set, containing <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment scores</a> in binary or real numbers, are used to compute the <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment scores</a> of text spans. Moreover, the correlation coeffi-cients of the price return between any two stocks are learned with the price data from <a href="https://en.wikipedia.org/wiki/Bloomberg_L.P.">Bloomberg</a>. They are used to capture the relationships between the interesting tar-get and other stocks mentioned in a tweet. The best result of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> in both <a href="https://en.wikipedia.org/wiki/Task_(project_management)">sub-task</a> are 56.68 % and 55.43 %, evaluated by evaluation method 2.</abstract>
      <bibkey>chen-etal-2017-nlg301</bibkey>
    </paper>
    <paper id="145">
      <title>funSentiment at SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis on Financial Microblogs Using Word Vectors Built from StockTwits and Twitter<fixed-case>S</fixed-case>entiment at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs Using Word Vectors Built from <fixed-case>S</fixed-case>tock<fixed-case>T</fixed-case>wits and <fixed-case>T</fixed-case>witter</title>
      <author><first>Quanzhi</first> <last>Li</last></author>
      <author><first>Sameena</first> <last>Shah</last></author>
      <author><first>Armineh</first> <last>Nourbakhsh</last></author>
      <author><first>Rui</first> <last>Fang</last></author>
      <author><first>Xiaomo</first> <last>Liu</last></author>
      <pages>852–856</pages>
      <url hash="b26d5553">S17-2145</url>
      <doi>10.18653/v1/S17-2145</doi>
      <abstract>This paper describes the approach we used for SemEval-2017 Task 5 : Fine-Grained Sentiment Analysis on Financial Microblogs. We use three types of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> in our algorithm : <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> learned from 200 million tweets, sentiment-specific word embeddings learned from 10 million tweets using distance supervision, and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> learned from 20 million StockTwits messages. In our approach, we also take the left and right context of the target company into consideration when generating polarity prediction features. All the <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> generated from different word embeddings and contexts are integrated together to train our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a></abstract>
      <bibkey>li-etal-2017-funsentiment-semeval</bibkey>
    </paper>
    <paper id="146">
      <title>SentiHeros at SemEval-2017 Task 5 : An application of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> on Financial Tweets<fixed-case>S</fixed-case>enti<fixed-case>H</fixed-case>eros at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: An application of Sentiment Analysis on Financial Tweets</title>
      <author><first>Narges</first> <last>Tabari</last></author>
      <author><first>Armin</first> <last>Seyeditabari</last></author>
      <author><first>Wlodek</first> <last>Zadrozny</last></author>
      <pages>857–860</pages>
      <url hash="ea6322d7">S17-2146</url>
      <doi>10.18653/v1/S17-2146</doi>
      <abstract>Sentiment analysis is the process of identifying the opinion expressed in text. Recently it has been used to study <a href="https://en.wikipedia.org/wiki/Behavioral_economics">behavioral finance</a>, and in particular the effect of <a href="https://en.wikipedia.org/wiki/Opinion">opinions</a> and emotions on economic or financial decisions. SemEval-2017 task 5 focuses on the <a href="https://en.wikipedia.org/wiki/Financial_market">financial market</a> as the domain for <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis of text</a> ; specifically, task 5, subtask 1 focuses on <a href="https://en.wikipedia.org/wiki/Twitter">financial tweets</a> about stock symbols. In this paper, we describe a machine learning classifier for binary classification of financial tweets. We used natural language processing techniques and the random forest algorithm to train our model, and tuned it for the training dataset of Task 5, subtask 1. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves the 7th rank on the leaderboard of the task.</abstract>
      <bibkey>tabari-etal-2017-sentiheros</bibkey>
    </paper>
    <paper id="147">
      <title>DUTH at SemEval-2017 Task 5 : Sentiment Predictability in Financial Microblogging and News Articles<fixed-case>DUTH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Sentiment Predictability in Financial Microblogging and News Articles</title>
      <author><first>Symeon</first> <last>Symeonidis</last></author>
      <author><first>John</first> <last>Kordonis</last></author>
      <author><first>Dimitrios</first> <last>Effrosynidis</last></author>
      <author><first>Avi</first> <last>Arampatzis</last></author>
      <pages>861–865</pages>
      <url hash="2c5ecee1">S17-2147</url>
      <doi>10.18653/v1/S17-2147</doi>
      <abstract>We present the system developed by the team DUTH for the participation in Semeval-2017 task 5-Fine-Grained Sentiment Analysis on Financial Microblogs and <a href="https://en.wikipedia.org/wiki/News">News</a>, in subtasks A and B. Our approach to determine the sentiment of Microblog Messages and News Statements &amp; Headlines is based on linguistic preprocessing, <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>, and supervised machine learning techniques. To train our model, we used Neural Network Regression, <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear Regression</a>, Boosted Decision Tree Regression and Decision Forrest Regression classifiers to forecast sentiment scores. At the end, we present an <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">error measure</a>, so as to improve the performance about <a href="https://en.wikipedia.org/wiki/Forecasting">forecasting methods</a> of the <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <bibkey>symeonidis-etal-2017-duth-semeval</bibkey>
    </paper>
    <paper id="148">
      <title>TakeLab at SemEval-2017 Task 5 : Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news<fixed-case>T</fixed-case>ake<fixed-case>L</fixed-case>ab at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news</title>
      <author><first>Leon</first> <last>Rotim</last></author>
      <author><first>Martin</first> <last>Tutek</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <pages>866–871</pages>
      <url hash="70776738">S17-2148</url>
      <doi>10.18653/v1/S17-2148</doi>
      <abstract>This paper describes our system for fine-grained sentiment scoring of news headlines submitted to SemEval 2017 task 5subtask 2. Our system uses a feature-light method that consists of a Support Vector Regression (SVR) with various kernels and <a href="https://en.wikipedia.org/wiki/Word_vector">word vectors</a> as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. Our best-performing submission scored 3rd on the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> out of 29 teams and 4th out of 45 submissions with a <a href="https://en.wikipedia.org/wiki/Trigonometric_functions">cosine score</a> of 0.733.</abstract>
      <bibkey>rotim-etal-2017-takelab</bibkey>
    </paper>
    <paper id="149">
      <title>UW-FinSent at SemEval-2017 Task 5 : Sentiment Analysis on Financial News Headlines using Training Dataset Augmentation<fixed-case>UW</fixed-case>-<fixed-case>F</fixed-case>in<fixed-case>S</fixed-case>ent at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Sentiment Analysis on Financial News Headlines using Training Dataset Augmentation</title>
      <author><first>Vineet</first> <last>John</last></author>
      <author><first>Olga</first> <last>Vechtomova</last></author>
      <pages>872–876</pages>
      <url hash="31f0e311">S17-2149</url>
      <doi>10.18653/v1/S17-2149</doi>
      <abstract>This paper discusses the approach taken by the UWaterloo team to arrive at a solution for the Fine-Grained Sentiment Analysis problem posed by Task 5 of SemEval 2017. The paper describes the document vectorization and sentiment score prediction techniques used, as well as the design and implementation decisions taken while building the system for this task. The system uses text vectorization models, such as N-gram, TF-IDF and paragraph embeddings, coupled with regression model variants to predict the sentiment scores. Amongst the methods examined, <a href="https://en.wikipedia.org/wiki/Unigram">unigrams</a> and <a href="https://en.wikipedia.org/wiki/Bigram">bigrams</a> coupled with simple <a href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> obtained the best baseline accuracy. The paper also explores data augmentation methods to supplement the training dataset. This <a href="https://en.wikipedia.org/wiki/System">system</a> was designed for Subtask 2 (News Statements and Headlines).</abstract>
      <bibkey>john-vechtomova-2017-uw</bibkey>
      <pwccode url="https://github.com/v1n337/semeval2017-task5" additional="false">v1n337/semeval2017-task5</pwccode>
    </paper>
    <paper id="150">
      <title>RiTUAL-UH at SemEval-2017 Task 5 : Sentiment Analysis on Financial Data Using Neural Networks<fixed-case>R</fixed-case>i<fixed-case>TUAL</fixed-case>-<fixed-case>UH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Sentiment Analysis on Financial Data Using Neural Networks</title>
      <author><first>Sudipta</first> <last>Kar</last></author>
      <author><first>Suraj</first> <last>Maharjan</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <pages>877–882</pages>
      <url hash="8ab635d0">S17-2150</url>
      <doi>10.18653/v1/S17-2150</doi>
      <abstract>In this paper, we present our systems for the SemEval-2017 Task-5 on Fine-Grained Sentiment Analysis on Financial Microblogs and <a href="https://en.wikipedia.org/wiki/News">News</a>. In our system, we combined hand-engineered lexical, sentiment and metadata features, the representations learned from Convolutional Neural Networks (CNN) and Bidirectional Gated Recurrent Unit (Bi-GRU) with Attention model applied on top. With this architecture we obtained weighted cosine similarity scores of 0.72 and 0.74 for subtask-1 and subtask-2, respectively. Using the official scoring system, our system ranked the second place for subtask-2 and eighth place for the subtask-1. It ranked first for both of the subtasks by the scores achieved by an alternate <a href="https://en.wikipedia.org/wiki/Score_(game)">scoring system</a>.</abstract>
      <bibkey>kar-etal-2017-ritual</bibkey>
    </paper>
    <paper id="151">
      <title>COMMIT at SemEval-2017 Task 5 : Ontology-based Method for Sentiment Analysis of Financial Headlines<fixed-case>COMMIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: Ontology-based Method for Sentiment Analysis of Financial Headlines</title>
      <author><first>Kim</first> <last>Schouten</last></author>
      <author><first>Flavius</first> <last>Frasincar</last></author>
      <author><first>Franciska</first> <last>de Jong</last></author>
      <pages>883–887</pages>
      <url hash="19264abb">S17-2151</url>
      <doi>10.18653/v1/S17-2151</doi>
      <abstract>This paper describes our submission to Task 5 of SemEval 2017, Fine-Grained Sentiment Analysis on Financial Microblogs and News, where we limit ourselves to performing sentiment analysis on news headlines only (track 2). The approach presented in this paper uses a <a href="https://en.wikipedia.org/wiki/Support-vector_machine">Support Vector Machine</a> to do the required <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression</a>, and besides unigrams and a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment tool</a>, we use various <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology-based features</a>. To this end we created a domain ontology that models various concepts from the financial domain. This allows us to model the sentiment of actions depending on which entity they are affecting (e.g., ‘decreasing debt’ is positive, but ‘decreasing profit’ is negative). The presented approach yielded a <a href="https://en.wikipedia.org/wiki/Trigonometric_functions">cosine distance</a> of 0.6810 on the <a href="https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations">official test data</a>, resulting in the 12th position.</abstract>
      <bibkey>schouten-etal-2017-commit</bibkey>
    </paper>
    <paper id="152">
      <title>ECNU at SemEval-2017 Task 5 : An Ensemble of Regression Algorithms with Effective Features for Fine-Grained Sentiment Analysis in Financial Domain<fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: An Ensemble of Regression Algorithms with Effective Features for Fine-Grained Sentiment Analysis in Financial Domain</title>
      <author><first>Mengxiao</first> <last>Jiang</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>888–893</pages>
      <url hash="ea185a8b">S17-2152</url>
      <doi>10.18653/v1/S17-2152</doi>
      <abstract>This paper describes our systems submitted to the Fine-Grained Sentiment Analysis on Financial Microblogs and News task (i.e., Task 5) in SemEval-2017. This <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> includes two subtasks in <a href="https://en.wikipedia.org/wiki/Microblogging">microblogs</a> and news headline domain respectively. To settle this problem, we extract four types of effective <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>, including linguistic features, sentiment lexicon features, domain-specific features and word embedding features. Then we employ these <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to construct <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> by using ensemble regression algorithms. Our submissions rank 1st and rank 5th in subtask 1 and subtask 2 respectively.</abstract>
      <bibkey>jiang-etal-2017-ecnu</bibkey>
    </paper>
    <paper id="154">
      <title>IITP at SemEval-2017 Task 5 : An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis<fixed-case>IITP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 5: An Ensemble of Deep Learning and Feature Based Models for Financial Sentiment Analysis</title>
      <author><first>Deepanway</first> <last>Ghosal</last></author>
      <author><first>Shobhit</first> <last>Bhatnagar</last></author>
      <author><first>Md Shad</first> <last>Akhtar</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>899–903</pages>
      <url hash="fc9e6ea2">S17-2154</url>
      <doi>10.18653/v1/S17-2154</doi>
      <abstract>In this paper we propose an ensemble based model which combines state of the art deep learning sentiment analysis algorithms like Convolution Neural Network (CNN) and Long Short Term Memory (LSTM) along with feature based models to identify optimistic or pessimistic sentiments associated with companies and stocks in financial texts. We build our <a href="https://en.wikipedia.org/wiki/System">system</a> to participate in a competition organized by Semantic Evaluation 2017 International Workshop. We combined predictions from various models using an <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">artificial neural network</a> to determine the opinion towards an entity in (a) Microblog Messages and (b) News Headlines data. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> achieved a cosine similarity score of 0.751 and 0.697 for the above two tracks giving us the rank of 2nd and 7th best team respectively.</abstract>
      <bibkey>ghosal-etal-2017-iitp</bibkey>
    </paper>
    <paper id="156">
      <title>UIT-DANGNT-CLNLP at SemEval-2017 Task 9 : Building Scientific Concept Fixing Patterns for Improving CAMR<fixed-case>UIT</fixed-case>-<fixed-case>DANGNT</fixed-case>-<fixed-case>CLNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: Building Scientific Concept Fixing Patterns for Improving <fixed-case>CAMR</fixed-case></title>
      <author><first>Khoa</first> <last>Nguyen</last></author>
      <author><first>Dang</first> <last>Nguyen</last></author>
      <pages>909–913</pages>
      <url hash="c269f6c8">S17-2156</url>
      <doi>10.18653/v1/S17-2156</doi>
      <abstract>This paper describes the improvements that we have applied on CAMR baseline parser (Wang et al., 2016) at Task 8 of SemEval-2016. Our objective is to increase the performance of CAMR when parsing sentences from scientific articles, especially articles of biology domain more accurately. To achieve this goal, we built two <a href="https://en.wikipedia.org/wiki/Wrapper_function">wrapper layers</a> for <a href="https://en.wikipedia.org/wiki/Command-line_interface">CAMR</a>. The first layer, which covers the input data, will normalize, add necessary information to the input sentences to make the input dependency parser and the aligner better handle reference citations, scientific figures, formulas, etc. The second layer, which covers the output data, will modify and standardize output data based on a list of scientific concept fixing patterns. This will help CAMR better handle biological concepts which are not in the training dataset. Finally, after applying our approach, CAMR has scored 0.65 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> on the test set of Biomedical training data and 0.61 <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> on the official blind test dataset.</abstract>
      <bibkey>nguyen-nguyen-2017-uit</bibkey>
    </paper>
    <paper id="158">
      <title>FORGe at SemEval-2017 Task 9 : Deep sentence generation based on a sequence of graph transducers<fixed-case>FORG</fixed-case>e at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: Deep sentence generation based on a sequence of graph transducers</title>
      <author><first>Simon</first> <last>Mille</last></author>
      <author><first>Roberto</first> <last>Carlini</last></author>
      <author><first>Alicia</first> <last>Burga</last></author>
      <author><first>Leo</first> <last>Wanner</last></author>
      <pages>920–923</pages>
      <url hash="48868d56">S17-2158</url>
      <doi>10.18653/v1/S17-2158</doi>
      <abstract>We present the contribution of Universitat Pompeu Fabra’s NLP group to the SemEval Task 9.2 (AMR-to-English Generation). The proposed generation pipeline comprises : (i) a series of rule-based graph-transducers for the syntacticization of the input graphs and the resolution of morphological agreements, and (ii) an off-the-shelf statistical linearization component.</abstract>
      <bibkey>mille-etal-2017-forge</bibkey>
    </paper>
    <paper id="159">
      <title>RIGOTRIO at SemEval-2017 Task 9 : Combining Machine Learning and Grammar Engineering for AMR Parsing and Generation<fixed-case>RIGOTRIO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: Combining Machine Learning and Grammar Engineering for <fixed-case>AMR</fixed-case> Parsing and Generation</title>
      <author><first>Normunds</first> <last>Gruzitis</last></author>
      <author><first>Didzis</first> <last>Gosko</last></author>
      <author><first>Guntis</first> <last>Barzdins</last></author>
      <pages>924–928</pages>
      <url hash="3112dd59">S17-2159</url>
      <doi>10.18653/v1/S17-2159</doi>
      <abstract>By addressing both text-to-AMR parsing and AMR-to-text generation, SemEval-2017 Task 9 established AMR as a powerful semantic interlingua. We strengthen the interlingual aspect of AMR by applying the multilingual Grammatical Framework (GF) for AMR-to-text generation. Our current rule-based GF approach completely covered only 12.3 % of the test AMRs, therefore we combined it with state-of-the-art JAMR Generator to see if the combination increases or decreases the overall performance. The combined <a href="https://en.wikipedia.org/wiki/System">system</a> achieved the <a href="https://en.wikipedia.org/wiki/BLEU">automatic BLEU score</a> of 18.82 and the human Trueskill score of 107.2, to be compared to the plain JAMR Generator results. As for AMR parsing, we added NER extensions to our SemEval-2016 general-domain AMR parser to handle the biomedical genre, rich in organic compound names, achieving Smatch F1=54.0 %.</abstract>
      <bibkey>gruzitis-etal-2017-rigotrio</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bio">Bio</pwcdataset>
    </paper>
    <paper id="160">
      <title>The Meaning Factory at SemEval-2017 Task 9 : Producing AMRs with Neural Semantic Parsing<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 9: Producing <fixed-case>AMR</fixed-case>s with Neural Semantic Parsing</title>
      <author><first>Rik</first> <last>van Noord</last></author>
      <author><first>Johan</first> <last>Bos</last></author>
      <pages>929–933</pages>
      <url hash="12b0a1db">S17-2160</url>
      <doi>10.18653/v1/S17-2160</doi>
      <abstract>We evaluate a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> based on a character-based sequence-to-sequence model in the context of the SemEval-2017 shared task on semantic parsing for AMRs. With <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a>, super characters, and POS-tagging we gain major improvements in performance compared to a baseline character-level model. Although we improve on previous character-based neural semantic parsing models, the overall accuracy is still lower than a state-of-the-art AMR parser. An ensemble combining our neural semantic parser with an existing, traditional <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>, yields a small gain in performance.</abstract>
      <bibkey>van-noord-bos-2017-meaning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bio">Bio</pwcdataset>
    </paper>
    <paper id="161">
      <title>PKU_ICL at SemEval-2017 Task 10 : Keyphrase Extraction with Model Ensemble and External Knowledge<fixed-case>PKU</fixed-case>_<fixed-case>ICL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Keyphrase Extraction with Model Ensemble and External Knowledge</title>
      <author><first>Liang</first> <last>Wang</last></author>
      <author><first>Sujian</first> <last>Li</last></author>
      <pages>934–937</pages>
      <url hash="123ec515">S17-2161</url>
      <doi>10.18653/v1/S17-2161</doi>
      <abstract>This paper presents a system that participated in SemEval 2017 Task 10 (subtask A and subtask B): Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017). Our proposed approach utilizes external knowledge to enrich feature representation of candidate keyphrase, including <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, IEEE taxonomy and pre-trained word embeddings etc. Ensemble of unsupervised models, <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a> and linear models are used for candidate keyphrase ranking and keyphrase type classification. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves the 3rd place in subtask A and 4th place in subtask B.</abstract>
      <bibkey>wang-li-2017-pku</bibkey>
    </paper>
    <paper id="162">
      <title>NTNU-1@ScienceIE at SemEval-2017 Task 10 : Identifying and Labelling Keyphrases with Conditional Random Fields<fixed-case>NTNU</fixed-case>-1@<fixed-case>S</fixed-case>cience<fixed-case>IE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Identifying and Labelling Keyphrases with Conditional Random Fields</title>
      <author><first>Erwin</first> <last>Marsi</last></author>
      <author><first>Utpal Kumar</first> <last>Sikdar</last></author>
      <author><first>Cristina</first> <last>Marco</last></author>
      <author><first>Biswanath</first> <last>Barik</last></author>
      <author><first>Rune</first> <last>Sætre</last></author>
      <pages>938–941</pages>
      <url hash="d9873bf8">S17-2162</url>
      <doi>10.18653/v1/S17-2162</doi>
      <abstract>We present NTNU’s systems for Task A (prediction of keyphrases) and Task B (labelling as Material, Process or Task) at SemEval 2017 Task 10 : Extracting Keyphrases and Relations from Scientific Publications (Augenstein et al., 2017). Our approach relies on <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised machine learning</a> using <a href="https://en.wikipedia.org/wiki/Conditional_random_field">Conditional Random Fields</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> yields a micro F-score of 0.34 for <a href="https://en.wikipedia.org/wiki/Task_(project_management)">Tasks</a> A and B combined on the test data. For Task C (relation extraction), we relied on an independently developed system described in (Barik and Marsi, 2017). For the full Scenario 1 (including relations), our approach reaches a micro F-score of 0.33 (5th place). Here we describe our <a href="https://en.wikipedia.org/wiki/System">systems</a>, report results and discuss errors.</abstract>
      <bibkey>marsi-etal-2017-ntnu</bibkey>
    </paper>
    <paper id="163">
      <title>EELECTION at SemEval-2017 Task 10 : Ensemble of nEural Learners for kEyphrase ClassificaTION<fixed-case>EELECTION</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Ensemble of n<fixed-case>E</fixed-case>ural Learners for k<fixed-case>E</fixed-case>yphrase <fixed-case>C</fixed-case>lassifica<fixed-case>TION</fixed-case></title>
      <author><first>Steffen</first> <last>Eger</last></author>
      <author><first>Erik-Lân</first> <last>Do Dinh</last></author>
      <author><first>Ilia</first> <last>Kuznetsov</last></author>
      <author><first>Masoud</first> <last>Kiaeeha</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>942–946</pages>
      <url hash="bf768535">S17-2163</url>
      <doi>10.18653/v1/S17-2163</doi>
      <abstract>This paper describes our approach to the SemEval 2017 Task 10 : Extracting Keyphrases and Relations from Scientific Publications, specifically to Subtask (B): Classification of identified keyphrases. We explored three different deep learning approaches : a character-level convolutional neural network (CNN), a stacked learner with an MLP meta-classifier, and an attention based Bi-LSTM. From these approaches, we created an ensemble of differently hyper-parameterized systems, achieving a micro-F_1-score of 0.63 on the test data. Our <a href="https://en.wikipedia.org/wiki/Glossary_of_French_expressions_in_English">approach</a> ranks 2nd (score of 1st placed system : 0.64) out of four according to this official score. However, we erroneously trained 2 out of 3 <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural nets</a> (the stacker and the CNN) on only roughly 15 % of the full data, namely, the original development set. When trained on the full data (training+development), our <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a> has a micro-F_1-score of 0.69. Our code is available from.<tex-math>F_1</tex-math>-score of 0.63 on the test data. Our approach ranks 2nd (score of 1st placed system: 0.64) out of four according to this official score. However, we erroneously trained 2 out of 3 neural nets (the stacker and the CNN) on only roughly 15% of the full data, namely, the original development set. When trained on the full data (training+development), our ensemble has a micro-<tex-math>F_{1}</tex-math>-score of 0.69. Our code is available from <url>https://github.com/UKPLab/semeval2017-scienceie</url>. </abstract>
      <bibkey>eger-etal-2017-eelection</bibkey>
      <pwccode url="https://github.com/UKPLab/semeval2017-scienceie" additional="false">UKPLab/semeval2017-scienceie</pwccode>
    </paper>
    <paper id="164">
      <title>LABDA at SemEval-2017 Task 10 : Extracting Keyphrases from Scientific Publications by combining the BANNER tool and the UMLS Semantic Network<fixed-case>LABDA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Extracting Keyphrases from Scientific Publications by combining the <fixed-case>BANNER</fixed-case> tool and the <fixed-case>UMLS</fixed-case> Semantic Network</title>
      <author><first>Isabel</first> <last>Segura-Bedmar</last></author>
      <author><first>Cristóbal</first> <last>Colón-Ruiz</last></author>
      <author><first>Paloma</first> <last>Martínez</last></author>
      <pages>947–950</pages>
      <url hash="265b9d52">S17-2164</url>
      <doi>10.18653/v1/S17-2164</doi>
      <abstract>This paper describes the system presented by the LABDA group at SemEval 2017 Task 10 ScienceIE, specifically for the subtasks of identification and classification of keyphrases from scientific articles. For the task of identification, we use the BANNER tool, a <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition system</a>, which is based on conditional random fields (CRF) and has obtained successful results in the biomedical domain. To classify keyphrases, we study the UMLS semantic network and propose a possible linking between the keyphrase types and the UMLS semantic groups. Based on this semantic linking, we create a <a href="https://en.wikipedia.org/wiki/Dictionary">dictionary</a> for each keyphrase type. Then, a <a href="https://en.wikipedia.org/wiki/Software_feature">feature</a> indicating if a token is found in one of these <a href="https://en.wikipedia.org/wiki/Dictionary">dictionaries</a> is incorporated to feature set used by the BANNER tool. The final results on the test dataset show that our <a href="https://en.wikipedia.org/wiki/System">system</a> still needs to be improved, but the conditional random fields and, consequently, the BANNER system can be used as a first approximation to identify and classify keyphrases.</abstract>
      <bibkey>segura-bedmar-etal-2017-labda</bibkey>
    </paper>
    <paper id="165">
      <title>The NTNU System at SemEval-2017 Task 10 : Extracting Keyphrases and Relations from Scientific Publications Using Multiple Conditional Random Fields<fixed-case>NTNU</fixed-case> System at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Extracting Keyphrases and Relations from Scientific Publications Using Multiple Conditional Random Fields</title>
      <author><first>Lung-Hao</first> <last>Lee</last></author>
      <author><first>Kuei-Ching</first> <last>Lee</last></author>
      <author><first>Yuen-Hsien</first> <last>Tseng</last></author>
      <pages>951–955</pages>
      <url hash="17363b85">S17-2165</url>
      <doi>10.18653/v1/S17-2165</doi>
      <abstract>This study describes the design of the NTNU system for the ScienceIE task at the SemEval 2017 workshop. We use self-defined feature templates and multiple conditional random fields with extracted features to identify keyphrases along with categorized labels and their relations from scientific publications. A total of 16 teams participated in evaluation scenario 1 (subtasks A, B, and C), with only 7 teams competing in all sub-tasks. Our best micro-averaging F1 across the three subtasks is 0.23, ranking in the middle among all 16 submissions.</abstract>
      <bibkey>lee-etal-2017-ntnu</bibkey>
    </paper>
    <paper id="166">
      <title>MayoNLP at SemEval 2017 Task 10 : Word Embedding Distance Pattern for Keyphrase Classification in Scientific Publications<fixed-case>M</fixed-case>ayo<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2017 Task 10: Word Embedding Distance Pattern for Keyphrase Classification in Scientific Publications</title>
      <author><first>Sijia</first> <last>Liu</last></author>
      <author><first>Feichen</first> <last>Shen</last></author>
      <author><first>Vipin</first> <last>Chaudhary</last></author>
      <author><first>Hongfang</first> <last>Liu</last></author>
      <pages>956–960</pages>
      <url hash="5ce93e38">S17-2166</url>
      <doi>10.18653/v1/S17-2166</doi>
      <abstract>In this paper, we present MayoNLP’s results from the participation in the ScienceIE share task at SemEval 2017. We focused on the keyphrase classification task (Subtask B). We explored semantic similarities and patterns of keyphrases in <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific publications</a> using pre-trained word embedding models. Word Embedding Distance Pattern, which uses the head noun word embedding to generate distance patterns based on labeled keyphrases, is proposed as an incremental feature set to enhance the conventional Named Entity Recognition feature sets. Support vector machine is used as the <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classifier</a> for keyphrase classification. Our system achieved an overall F1 score of 0.67 for keyphrase classification and 0.64 for keyphrase classification and relation detection.</abstract>
      <bibkey>liu-etal-2017-mayonlp</bibkey>
    </paper>
    <paper id="167">
      <title>Know-Center at SemEval-2017 Task 10 : Sequence Classification with the CODE Annotator<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Sequence Classification with the <fixed-case>CODE</fixed-case> Annotator</title>
      <author><first>Roman</first> <last>Kern</last></author>
      <author><first>Stefan</first> <last>Falk</last></author>
      <author><first>Andi</first> <last>Rexha</last></author>
      <pages>961–964</pages>
      <url hash="a684d04d">S17-2167</url>
      <doi>10.18653/v1/S17-2167</doi>
      <abstract>This paper describes our participation in SemEval-2017 Task 10. We competed in Subtask 1 and 2 which consist respectively in identifying all the key phrases in scientific publications and label them with one of the three categories : Task, Process, and Material. These <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific publications</a> are selected from <a href="https://en.wikipedia.org/wiki/Computer_science">Computer Science</a>, <a href="https://en.wikipedia.org/wiki/Materials_science">Material Sciences</a>, and <a href="https://en.wikipedia.org/wiki/Physics">Physics domains</a>. We followed a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised approach</a> for both subtasks by using a sequential classifier (CRF-Conditional Random Fields). For generating our <a href="https://en.wikipedia.org/wiki/Solution">solution</a> we used a <a href="https://en.wikipedia.org/wiki/Web_application">web-based application</a> implemented in the EU-funded research project, named CODE. Our system achieved an F1 score of 0.39 for the Subtask 1 and 0.28 for the Subtask 2.</abstract>
      <bibkey>kern-etal-2017-know</bibkey>
    </paper>
    <paper id="168">
      <title>NTNU-2 at SemEval-2017 Task 10 : Identifying Synonym and Hyponym Relations among Keyphrases in Scientific Documents<fixed-case>NTNU</fixed-case>-2 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Identifying Synonym and Hyponym Relations among Keyphrases in Scientific Documents</title>
      <author><first>Biswanath</first> <last>Barik</last></author>
      <author><first>Erwin</first> <last>Marsi</last></author>
      <pages>965–968</pages>
      <url hash="a31925c2">S17-2168</url>
      <doi>10.18653/v1/S17-2168</doi>
      <abstract>This paper presents our relation extraction system for subtask C of SemEval-2017 Task 10 : ScienceIE. Assuming that the keyphrases are already annotated in the input data, our work explores a wide range of linguistic features, applies various feature selection techniques, optimizes the hyper parameters and class weights and experiments with different problem formulations (single classification model vs individual classifiers for each keyphrase type, single-step classifier vs pipeline classifier for hyponym relations). Performance of five popular <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification algorithms</a> are evaluated for each <a href="https://en.wikipedia.org/wiki/Problem_formulation">problem formulation</a> along with <a href="https://en.wikipedia.org/wiki/Feature_selection">feature selection</a>. The best <a href="https://en.wikipedia.org/wiki/Setting_(narrative)">setting</a> achieved an <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">F1 score</a> of 71.0 % for <a href="https://en.wikipedia.org/wiki/Synonym">synonym</a> and 30.0 % for <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponym relation</a> on the test data.</abstract>
      <bibkey>barik-marsi-2017-ntnu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="169">
      <title>LABDA at SemEval-2017 Task 10 : Relation Classification between keyphrases via <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a><fixed-case>LABDA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Relation Classification between keyphrases via Convolutional Neural Network</title>
      <author><first>Víctor</first> <last>Suárez-Paniagua</last></author>
      <author><first>Isabel</first> <last>Segura-Bedmar</last></author>
      <author><first>Paloma</first> <last>Martínez</last></author>
      <pages>969–972</pages>
      <url hash="22eb314b">S17-2169</url>
      <doi>10.18653/v1/S17-2169</doi>
      <abstract>In this paper, we describe our participation at the subtask of extraction of relationships between two identified keyphrases. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> can be very helpful in improving <a href="https://en.wikipedia.org/wiki/Web_search_engine">search engines</a> for <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific articles</a>. Our approach is based on the use of a convolutional neural network (CNN) trained on the training dataset. This deep learning model has already achieved successful results for the extraction relationships between named entities. Thus, our hypothesis is that this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be also applied to extract relations between keyphrases. The official results of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> show that our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> obtained an F1-score of 0.38 % for Keyphrases Relation Classification. This performance is lower than the expected due to the generic preprocessing phase and the basic configuration of the CNN model, more complex architectures are proposed as future work to increase the classification rate.</abstract>
      <bibkey>suarez-paniagua-etal-2017-labda</bibkey>
    </paper>
    <paper id="170">
      <title>WING-NUS at SemEval-2017 Task 10 : Keyphrase Extraction and Classification as Joint Sequence Labeling<fixed-case>WING</fixed-case>-<fixed-case>NUS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Keyphrase Extraction and Classification as Joint Sequence Labeling</title>
      <author><first>Animesh</first> <last>Prasad</last></author>
      <author><first>Min-Yen</first> <last>Kan</last></author>
      <pages>973–977</pages>
      <url hash="0032030f">S17-2170</url>
      <doi>10.18653/v1/S17-2170</doi>
      <abstract>We describe an end-to-end pipeline processing approach for SemEval 2017’s Task 10 to extract keyphrases and their relations from scientific publications. We jointly identify and classify keyphrases by modeling the subtasks as sequential labeling. Our system utilizes standard, surface-level features along with the adjacent word features, and performs conditional decoding on whole text to extract <a href="https://en.wikipedia.org/wiki/Phrase">keyphrases</a>. We focus only on the identification and typing of keyphrases (Subtasks A and B, together referred as extraction), but provide an end-to-end system inclusive of keyphrase relation identification (Subtask C) for completeness. Our top performing configuration achieves an <a href="https://en.wikipedia.org/wiki/F-number">F_1</a> of 0.27 for the end-to-end keyphrase extraction and relation identification scenario on the final test data, and compares on par to other top ranked systems for <a href="https://en.wikipedia.org/wiki/Keyphrase_extraction">keyphrase extraction</a>. Our system outperforms other techniques that do not employ global decoding and hence do not account for dependencies between keyphrases. We believe this is crucial for keyphrase classification in the given context of scientific document mining.<tex-math>F_1</tex-math> of 0.27 for the end-to-end keyphrase extraction and relation identification scenario on the final test data, and compares on par to other top ranked systems for keyphrase extraction. Our system outperforms other techniques that do not employ global decoding and hence do not account for dependencies between keyphrases. We believe this is crucial for keyphrase classification in the given context of scientific document mining. </abstract>
      <bibkey>prasad-kan-2017-wing</bibkey>
    </paper>
    <paper id="171">
      <title>MIT at SemEval-2017 Task 10 : Relation Extraction with <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a><fixed-case>MIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Relation Extraction with Convolutional Neural Networks</title>
      <author><first>Ji Young</first> <last>Lee</last></author>
      <author><first>Franck</first> <last>Dernoncourt</last></author>
      <author><first>Peter</first> <last>Szolovits</last></author>
      <pages>978–984</pages>
      <url hash="0cf35b5d">S17-2171</url>
      <doi>10.18653/v1/S17-2171</doi>
      <abstract>Over 50 million scholarly articles have been published : they constitute a unique repository of knowledge. In particular, one may infer from them relations between <a href="https://en.wikipedia.org/wiki/Scientific_theory">scientific concepts</a>. Artificial neural networks have recently been explored for <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>. In this work, we continue this line of work and present a <a href="https://en.wikipedia.org/wiki/System">system</a> based on a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> to extract <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a>. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> ranked first in the SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific articles (subtask C).</abstract>
      <bibkey>lee-etal-2017-mit</bibkey>
    </paper>
    <paper id="172">
      <title>TTI-COIN at SemEval-2017 Task 10 : Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers<fixed-case>TTI</fixed-case>-<fixed-case>COIN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Investigating Embeddings for End-to-End Relation Extraction from Scientific Papers</title>
      <author><first>Tomoki</first> <last>Tsujimura</last></author>
      <author><first>Makoto</first> <last>Miwa</last></author>
      <author><first>Yutaka</first> <last>Sasaki</last></author>
      <pages>985–989</pages>
      <url hash="290046cc">S17-2172</url>
      <doi>10.18653/v1/S17-2172</doi>
      <abstract>This paper describes our TTI-COIN system that participated in SemEval-2017 Task 10. We investigated appropriate <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> to adapt a neural end-to-end entity and relation extraction system LSTM-ER to this task. We participated in the full task setting of the <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity segmentation</a>, entity classification and relation classification (scenario 1) and the setting of <a href="https://en.wikipedia.org/wiki/Relation_(database)">relation classification</a> only (scenario 3). The <a href="https://en.wikipedia.org/wiki/System">system</a> was directly applied to the scenario 1 without modifying the codes thanks to its generality and flexibility. Our evaluation results show that the choice of appropriate pre-trained embeddings affected the performance significantly. With the best <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>, our <a href="https://en.wikipedia.org/wiki/System">system</a> was ranked third in the scenario 1 with the micro F1 score of 0.38. We also confirm that our <a href="https://en.wikipedia.org/wiki/System">system</a> can produce the micro F1 score of 0.48 for the scenario 3 on the test data, and this score is close to the score of the 3rd ranked system in the task.</abstract>
      <bibkey>tsujimura-etal-2017-tti</bibkey>
    </paper>
    <paper id="173">
      <title>SZTE-NLP at SemEval-2017 Task 10 : A High Precision Sequence Model for Keyphrase Extraction Utilizing Sparse Coding for Feature Generation<fixed-case>SZTE</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: A High Precision Sequence Model for Keyphrase Extraction Utilizing Sparse Coding for Feature Generation</title>
      <author><first>Gábor</first> <last>Berend</last></author>
      <pages>990–994</pages>
      <url hash="dfd07fa3">S17-2173</url>
      <doi>10.18653/v1/S17-2173</doi>
      <abstract>In this paper we introduce our <a href="https://en.wikipedia.org/wiki/System">system</a> participating at the 2017 SemEval shared task on <a href="https://en.wikipedia.org/wiki/Keyphrase_extraction">keyphrase extraction</a> from <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific documents</a>. We aimed at the creation of a keyphrase extraction approach which relies on as little external resources as possible. Without applying any hand-crafted external resources, and only utilizing a transformed version of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> trained at <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, our proposed system manages to perform among the best participating systems in terms of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>.</abstract>
      <bibkey>berend-2017-szte</bibkey>
    </paper>
    <paper id="174">
      <title>LIPN at SemEval-2017 Task 10 : Filtering Candidate Keyphrases from Scientific Publications with Part-of-Speech Tag Sequences to Train a Sequence Labeling Model<fixed-case>LIPN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 10: Filtering Candidate Keyphrases from Scientific Publications with Part-of-Speech Tag Sequences to Train a Sequence Labeling Model</title>
      <author><first>Simon David</first> <last>Hernandez</last></author>
      <author><first>Davide</first> <last>Buscaldi</last></author>
      <author><first>Thierry</first> <last>Charnois</last></author>
      <pages>995–999</pages>
      <url hash="ad502833">S17-2174</url>
      <doi>10.18653/v1/S17-2174</doi>
      <abstract>This paper describes the system used by the team LIPN in SemEval 2017 Task 10 : Extracting Keyphrases and Relations from Scientific Publications. The team participated in Scenario 1, that includes three subtasks, Identification of keyphrases (Subtask A), Classification of identified keyphrases (Subtask B) and Extraction of relationships between two identified keyphrases (Subtask C). The presented system was mainly focused on the use of part-of-speech tag sequences to filter candidate keyphrases for Subtask A. Subtasks A and B were addressed as a sequence labeling problem using Conditional Random Fields (CRFs) and even though Subtask C was out of the scope of this approach, one rule was included to identify synonyms.</abstract>
      <bibkey>hernandez-etal-2017-lipn</bibkey>
    </paper>
    <paper id="176">
      <title>Hitachi at SemEval-2017 Task 12 : System for temporal information extraction from clinical notes<fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 12: System for temporal information extraction from clinical notes</title>
      <author><first>Sarath</first> <last>P R</last></author>
      <author><first>Manikandan</first> <last>R</last></author>
      <author><first>Yoshiki</first> <last>Niwa</last></author>
      <pages>1005–1009</pages>
      <url hash="0337987a">S17-2176</url>
      <doi>10.18653/v1/S17-2176</doi>
      <abstract>This paper describes the system developed for the task of temporal information extraction from clinical narratives in the context of the 2017 Clinical TempEval challenge. Clinical TempEval 2017 addressed the problem of temporal reasoning in the clinical domain by providing annotated clinical notes, pathology and radiology reports in line with Clinical TempEval challenges 2015/16, across two different evaluation phases focusing on cross domain adaptation. Our team focused on subtasks involving extractions of temporal spans and relations for which the developed systems showed average F-score of 0.45 and 0.47 across the two phases of evaluations.</abstract>
      <bibkey>p-r-etal-2017-hitachi</bibkey>
    </paper>
    <paper id="178">
      <title>XJNLP at SemEval-2017 Task 12 : Clinical temporal information ex-traction with a Hybrid Model<fixed-case>XJNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 12: Clinical temporal information ex-traction with a Hybrid Model</title>
      <author><first>Yu</first> <last>Long</last></author>
      <author><first>Zhijing</first> <last>Li</last></author>
      <author><first>Xuan</first> <last>Wang</last></author>
      <author><first>Chen</first> <last>Li</last></author>
      <pages>1014–1018</pages>
      <url hash="5e54ac13">S17-2178</url>
      <doi>10.18653/v1/S17-2178</doi>
      <revision id="1" href="S17-2178v1" hash="fd45a75d" />
      <revision id="2" href="S17-2178v2" hash="5e54ac13">No description of the changes were recorded.</revision>
      <abstract>Temporality is crucial in understanding the course of clinical events from a patient’s electronic health recordsand temporal processing is becoming more and more important for improving access to content. SemEval 2017 Task 12 (Clinical TempEval) addressed this challenge using the THYME corpus, a corpus of clinical narratives annotated with a schema based on TimeML2 guidelines. We developed and evaluated approaches for : extraction of temporal expressions (TIMEX3) and EVENTs ; EVENT attributes ; document-time relations. Our approach is a hybrid model which is based on rule based methods, <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>, and semantic features with addition of manually crafted rules.</abstract>
      <bibkey>long-etal-2017-xjnlp</bibkey>
    </paper>
    <paper id="179">
      <title>ULISBOA at SemEval-2017 Task 12 : Extraction and classification of temporal expressions and events<fixed-case>ULISBOA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 12: Extraction and classification of temporal expressions and events</title>
      <author><first>Andre</first> <last>Lamurias</last></author>
      <author><first>Diana</first> <last>Sousa</last></author>
      <author><first>Sofia</first> <last>Pereira</last></author>
      <author><first>Luka</first> <last>Clarke</last></author>
      <author><first>Francisco M.</first> <last>Couto</last></author>
      <pages>1019–1023</pages>
      <url hash="fc6eaffe">S17-2179</url>
      <doi>10.18653/v1/S17-2179</doi>
      <abstract>This paper presents our approach to participate in the SemEval 2017 Task 12 : Clinical TempEval challenge, specifically in the event and time expressions span and attribute identification subtasks (ES, EA, TS, TA). Our approach consisted in training Conditional Random Fields (CRF) classifiers using the provided annotations, and in creating manually curated rules to classify the attributes of each event and time expression. We used a set of common <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> for the event and time CRF classifiers, and a set of <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> specific to each type of entity, based on <a href="https://en.wikipedia.org/wiki/Domain_knowledge">domain knowledge</a>. Training only on the source domain data, our best <a href="https://en.wikipedia.org/wiki/F-number">F-scores</a> were 0.683 and 0.485 for event and time span identification subtasks. When adding target domain annotations to the training data, the best F-scores obtained were 0.729 and 0.554, for the same subtasks. We obtained the second highest F-score of the challenge on the event polarity subtask (0.708). The source code of our <a href="https://en.wikipedia.org/wiki/System">system</a>, Clinical Timeline Annotation (CiTA), is available at.<url>https://github.com/lasigeBioTM/CiTA</url>.
    </abstract>
      <bibkey>lamurias-etal-2017-ulisboa</bibkey>
      <pwccode url="https://github.com/lasigeBioTM/CiTA" additional="false">lasigeBioTM/CiTA</pwccode>
    </paper>
    <paper id="180">
      <title>GUIR at SemEval-2017 Task 12 : A Framework for Cross-Domain Clinical Temporal Information Extraction<fixed-case>GUIR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2017 Task 12: A Framework for Cross-Domain Clinical Temporal Information Extraction</title>
      <author><first>Sean</first> <last>MacAvaney</last></author>
      <author><first>Arman</first> <last>Cohan</last></author>
      <author><first>Nazli</first> <last>Goharian</last></author>
      <pages>1024–1029</pages>
      <url hash="fa4afa8f">S17-2180</url>
      <doi>10.18653/v1/S17-2180</doi>
      <abstract>Clinical TempEval 2017 (SemEval 2017 Task 12) addresses the task of cross-domain temporal extraction from clinical text. We present a system for this task that uses <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> for the extraction of temporal expression and event spans with corresponding attributes and narrative container relations. Approaches include conditional random fields and <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision tree ensembles</a>, using lexical, syntactic, semantic, distributional, and rule-based features. Our system received best or second best scores in TIMEX3 span, EVENT span, and CONTAINS relation extraction.</abstract>
      <bibkey>macavaney-etal-2017-guir</bibkey>
    </paper>
    </volume>
</collection>