<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.alta">
  <volume id="1" ingest-date="2022-01-31">
    <meta>
      <booktitle>Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association</booktitle>
      <editor><first>Afshin</first><last>Rahimi</last></editor>
      <editor><first>William</first><last>Lane</last></editor>
      <editor><first>Guido</first><last>Zuccon</last></editor>
      <publisher>Australasian Language Technology Association</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2021</year>
      <url hash="f6f6059a">2021.alta-1</url>
    </meta>
    <frontmatter>
      <url hash="fc00c500">2021.alta-1.0</url>
      <bibkey>alta-2021-australasian</bibkey>
    </frontmatter>
    <paper id="2">
      <title>An Approach to the Frugal Use of Human Annotators to Scale up Auto-coding for Text Classification Tasks</title>
      <author><first>Li’An</first><last>Chen</last></author>
      <author><first>Hanna</first><last>Suominen</last></author>
      <pages>12–21</pages>
      <abstract>Human annotation for establishing the training data is often a very costly process in natural language processing (NLP) tasks, which has led to frugal NLP approaches becoming an important research topic. Many research teams struggle to complete projects with limited funding, labor, and computational resources. Driven by the Move-Step analytic framework theorized in the applied linguistics field, our study offers a rigorous approach to the frugal use of two human annotators to scale up auto-coding for text classification tasks. We applied the Linear Support Vector Machine algorithm to <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> of a job ad corpus. Our Cohens Kappa for inter-rater agreement and Area Under the Curve (AUC) values reached averages of 0.76 and 0.80, respectively. The calculated time consumption for our human training process was 36 days. The results indicated that even the strategic and frugal use of only two human annotators could enable the efficient training of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> with reasonably good performance. This study does not aim to provide generalizability of the results. Rather, we propose that the annotation strategies arising from this study be considered by our readers only if such <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> are fit for one’s specific research purposes.</abstract>
      <url hash="8d7c61b9">2021.alta-1.2</url>
      <bibkey>chen-suominen-2021-approach</bibkey>
    </paper>
    <paper id="5">
      <title>Multi-modal Intent Classification for Assistive Robots with Large-scale Naturalistic Datasets</title>
      <author><first>Karun Varghese</first><last>Mathew</last></author>
      <author><first>Venkata S Aditya</first><last>Tarigoppula</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <pages>47–57</pages>
      <abstract>Recent years have brought a tremendous growth in assistive robots / prosthetics for people with partial or complete loss of upper limb control. These technologies aim to help the users with various reaching and grasping tasks in their daily lives such as picking up an object and transporting it to a desired location ; and their utility critically depends on the ease and effectiveness of communication between the user and robot. One of the natural ways of communicating with <a href="https://en.wikipedia.org/wiki/Assistive_technology">assistive technologies</a> is through <a href="https://en.wikipedia.org/wiki/Linguistic_description">verbal instructions</a>. The meaning of natural language commands depends on the current configuration of the surrounding environment and needs to be interpreted in this multi-modal context, as accurate interpretation of the command is essential for a successful execution of the users intent by an <a href="https://en.wikipedia.org/wiki/Assistive_device">assistive device</a>. The research presented in this paper demonstrates how large-scale situated natural language datasets can support the development of robust assistive technologies. We leveraged a navigational dataset comprising 25k human-provided natural language commands covering diverse situations. We demonstrated a way to extend the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> in a task-informed way and use it to develop multi-modal intent classifiers for pick and place tasks. Our best <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> reached 98 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> in a 16-way multi-modal intent classification task, suggesting high robustness and <a href="https://en.wikipedia.org/wiki/Stiffness">flexibility</a>.</abstract>
      <url hash="9de37c2f">2021.alta-1.5</url>
      <bibkey>mathew-etal-2021-multi</bibkey>
    </paper>
    <paper id="7">
      <title>Combining Shallow and Deep Representations for Text-Pair Classification</title>
      <author><first>Vincent</first><last>Nguyen</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Zhenchang</first><last>Xing</last></author>
      <pages>68–78</pages>
      <abstract>Text-pair classification is the task of determining the class relationship between two sentences. It is embedded in several tasks such as paraphrase identification and duplicate question detection. Contemporary methods use fine-tuned transformer encoder semantic representations of the classification token in the text-pair sequence from the transformer’s final layer for <a href="https://en.wikipedia.org/wiki/Statistical_classification">class prediction</a>. However, research has shown that earlier parts of the network learn shallow features, such as <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> and <a href="https://en.wikipedia.org/wiki/Structure">structure</a>, which existing methods do not directly exploit. We propose a novel convolution-based decoder for transformer-based architecture that maximizes the use of encoder hidden features for text-pair classification. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> exploits hidden representations within transformer-based architecture. It outperforms a transformer encoder baseline on average by 50 % (relative F1-score) on six datasets from the <a href="https://en.wikipedia.org/wiki/Medicine">medical</a>, software engineering, and open-domains. Our work shows that transformer-based models can improve text-pair classification by modifying the fine-tuning step to exploit shallow features while improving model generalization, with only a slight reduction in efficiency.</abstract>
      <url hash="f9d74bfc">2021.alta-1.7</url>
      <bibkey>nguyen-etal-2021-combining</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/blue">BLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="9">
      <title>Evaluation of Review Summaries via <a href="https://en.wikipedia.org/wiki/Question_answering">Question-Answering</a></title>
      <author><first>Nannan</first><last>Huang</last></author>
      <author><first>Xiuzhen</first><last>Zhang</last></author>
      <pages>87–96</pages>
      <abstract>Summarisation of reviews aims at compressing opinions expressed in multiple review documents into a concise form while still covering the key opinions. Despite the advancement in summarisation models, evaluation metrics for opinionated text summaries lag behind and still rely on lexical-matching metrics such as ROUGE. In this paper, we propose to use the question-answering(QA) approach to evaluate summaries of opinions in reviews. We propose to identify opinion-bearing text spans in the reference summary to generate QA pairs so as to capture salient opinions. A QA model is then employed to probe the candidate summary to evaluate information overlap between candidate and reference summaries. We show that our metric RunQA, Review Summary Evaluation via Question Answering, correlates well with human judgments in terms of coverage and focus of information. Finally, we design an adversarial task and demonstrate that the proposed approach is more robust than <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> in the literature for ranking summaries.</abstract>
      <url hash="c646845e">2021.alta-1.9</url>
      <bibkey>huang-zhang-2021-evaluation</bibkey>
    </paper>
    <paper id="13">
      <title>Document Level Hierarchical Transformer</title>
      <author><first>Najam</first><last>Zaidi</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>128–137</pages>
      <abstract>Generating long and coherent text is an important and challenging task encompassing many application areas such as <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, document level machine translation and <a href="https://en.wikipedia.org/wiki/Storytelling">story generation</a>. Despite the success in modeling intra-sentence coherence, existing long text generation models (e.g., BART and GPT-3) still struggle to maintain a coherent event sequence throughout the generated text. We conjecture that this is because of the difficulty for the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to revise, replace, revoke or delete any part that has been generated by the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. In this paper, we present a novel semi-autoregressive document generation model capable of revising and editing the generated text. Building on recent models by (Gu et al., 2019 ; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each <a href="https://en.wikipedia.org/wiki/Policy">policy</a> learns on the output of applying the previous action. Experiments applying the proposed approach sheds various insights on the problems of long text generation using our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using <a href="https://en.wikipedia.org/wiki/Autoregressive_model">autoregressive models</a> as a <a href="https://en.wikipedia.org/wiki/Low-level_programming_language">low level program</a>.</abstract>
      <url hash="7949b16f">2021.alta-1.13</url>
      <bibkey>zaidi-etal-2021-document</bibkey>
    <title_ar>المحولات الهرمية على مستوى الوثيقة</title_ar>
      <title_es>Transformador jerárquico de documentos</title_es>
      <title_pt>Transformador Hierárquico de Nível de Documento</title_pt>
      <title_hi>दस्तावेज़ स्तर पदानुक्रमित ट्रांसफॉर्मर</title_hi>
      <title_ja>ドキュメントレベルの階層トランスフォーマー</title_ja>
      <title_zh>文档级分转换器</title_zh>
      <title_ga>Trasfhoirmeoir Ordlathach Leibhéal an Doiciméid</title_ga>
      <title_ka>Comment</title_ka>
      <title_el>Ιεραρχικός μετασχηματιστής επιπέδου εγγράφου</title_el>
      <title_hu>Dokumentumszint hierarchikus transzformátor</title_hu>
      <title_it>Trasformatore gerarchico a livello di documento</title_it>
      <title_kk>Құжат деңгейі гиерархикалық түрлендіргіші</title_kk>
      <title_mk>Херархиски трансформирач на ниво на документ</title_mk>
      <title_ml>രേഖയുടെ നില ഉയര്‍ച്ചയുള്ള വിവരങ്ങള്‍</title_ml>
      <title_mn>Документын түвшин гиерархик шилжүүлэгч</title_mn>
      <title_no>Hierarisk transformering for dokumentnivå</title_no>
      <title_lt>Dokumento lygis Hierarchinis transformatorius</title_lt>
      <title_pl>Transformator hierarchiczny na poziomie dokumentu</title_pl>
      <title_ms>Penukar Hierarkikal Aras Dokumen</title_ms>
      <title_ro>Transformator ierarhic la nivel de document</title_ro>
      <title_sr>Hierarhički transformator nivoa dokumenta</title_sr>
      <title_si>විස්තාරය ස්තූතිය හියාර්චිකාල ප්‍රවර්තකය</title_si>
      <title_so>Tilmaamaha dukumentiga heerka sare</title_so>
      <title_ta>ஆவண நிலை உயர்நிலை மாற்றுதல்</title_ta>
      <title_sv>Hierarkisk transformator på dokumentnivå</title_sv>
      <title_ur>Document Level Hierarchical Transformer</title_ur>
      <title_mt>Trasformatur Ġerarkiku tal-Livell tad-Dokument</title_mt>
      <title_uz>Hujjatning darajasi</title_uz>
      <title_vi>Dịch biến hình cấp ảnhName</title_vi>
      <title_nl>Hierarchische transformatie op documentniveau</title_nl>
      <title_hr>Hierarični transformator razine dokumenta</title_hr>
      <title_bg>Йерархичен трансформатор на ниво документ</title_bg>
      <title_da>Hierarkisk transformator på dokumentniveau</title_da>
      <title_id>Transformer Hierarkis Tingkat Dokumen</title_id>
      <title_fa>تغییر سطح سطح سند</title_fa>
      <title_de>Hierarchischer Transformator auf Dokumentebene</title_de>
      <title_tr>_Senedler</title_tr>
      <title_af>Dokumentvlak Hierariese Transformeerder</title_af>
      <title_sq>Transformues Hierarkik i Nivelit të Dokumentit</title_sq>
      <title_ko>문서 수준 계층 변환기</title_ko>
      <title_sw>Transfers</title_sw>
      <title_am>ሰነድ ደረጃዎች</title_am>
      <title_hy>Comment</title_hy>
      <title_az>D칬k칲m톛t s톛viyy톛si Hierarhikal Transformat칬r칲</title_az>
      <title_bs>Hierarični transformator nivoa dokumenta</title_bs>
      <title_ca>Transformador Hierarquic del Nivel del Document</title_ca>
      <title_cs>Hierarchický transformátor úrovně dokumentu</title_cs>
      <title_bn>ডকুমেন্টের স্তর অতিরিক্ত অনুবাদক</title_bn>
      <title_et>Dokumenditaseme hierarhiline muundur</title_et>
      <title_fi>Asiakirjatason hierarkinen muuntaja</title_fi>
      <title_ha>Document Level Hierarchical Transformer</title_ha>
      <title_sk>Hierarhični pretvornik na ravni dokumenta</title_sk>
      <title_he>מעברת רמת המסמך הייררכית</title_he>
      <title_bo>ཡིག་གེའི་སྒྲིག་ཡིག་གི་དཔེ་དབྱིབས་སྒྱུར་བ</title_bo>
      <title_jv>undo-type</title_jv>
      <abstract_es>Generar texto largo y coherente es una tarea importante y desafiante que abarca muchas áreas de aplicación, como el resumen, la traducción automática a nivel de documentos y la generación de historias. A pesar del éxito en el modelado de la coherencia entre oraciones, los modelos existentes de generación de texto largo (por ejemplo, BART y GPT-3) siguen teniendo dificultades para mantener una secuencia de eventos coherente en todo el texto generado. Suponemos que esto se debe a la dificultad para que el modelo revise, reemplace, revoque o elimine cualquier parte que haya sido generada por el modelo. En este artículo, presentamos un novedoso modelo de generación de documentos semiautorregresivos capaz de revisar y editar el texto generado. Sobre la base de modelos recientes de (Gu et al., 2019; Xu y Carpuat, 2020) proponemos la generación de documentos como un proceso de decisión jerárquico de Markov con una jerarquía de dos niveles, donde los programas de edición de alto y bajo nivel. Entrenamos nuestro modelo mediante el aprendizaje de imitación (Hussein et al., 2017) e introducimos una política acumulada de manera que cada política aprenda del resultado de la aplicación de la acción anterior. Los experimentos que aplican el enfoque propuesto arrojan varios puntos de vista sobre los problemas de la generación de textos largos utilizando nuestro modelo. Sugerimos varias soluciones, como el uso de datos destilados, el diseño de mejores mecanismos de atención y el uso de modelos autorregresivos como un programa de bajo nivel.</abstract_es>
      <abstract_pt>A geração de texto longo e coerente é uma tarefa importante e desafiadora que abrange muitas áreas de aplicação, como sumarização, tradução automática em nível de documento e geração de histórias. Apesar do sucesso na modelagem da coerência intra-frase, os modelos de geração de texto longo existentes (por exemplo, BART e GPT-3) ainda lutam para manter uma sequência de eventos coerente em todo o texto gerado. Conjecturamos que isso se deve à dificuldade do modelo em revisar, substituir, revogar ou excluir qualquer parte que tenha sido gerada pelo modelo. Neste artigo, apresentamos um novo modelo de geração de documentos semiautoregressivo capaz de revisar e editar o texto gerado. Com base em modelos recentes de (Gu et al., 2019; Xu e Carpuat, 2020) propomos a geração de documentos como um processo de decisão Markov hierárquico com uma hierarquia de dois níveis, onde os programas de edição de alto e baixo nível. Treinamos nosso modelo usando aprendizado por imitação (Hussein et al., 2017) e introduzimos a política de roll-in de modo que cada política aprenda com o resultado da aplicação da ação anterior. Experimentos que aplicam a abordagem proposta lançam vários insights sobre os problemas de geração de texto longo usando nosso modelo. Sugerimos vários remédios, como usar conjuntos de dados destilados, projetar melhores mecanismos de atenção e usar modelos autorregressivos como um programa de baixo nível.</abstract_pt>
      <abstract_ar>يعد إنشاء نص طويل ومتماسك مهمة مهمة وصعبة تشمل العديد من مجالات التطبيق مثل التلخيص والترجمة الآلية على مستوى المستند وإنشاء القصة. على الرغم من النجاح في نمذجة التماسك داخل الجملة ، لا تزال نماذج إنشاء النص الطويل الحالية (على سبيل المثال ، BART و GPT-3) تكافح للحفاظ على تسلسل حدث متماسك في جميع أنحاء النص الذي تم إنشاؤه. نعتقد أن هذا بسبب صعوبة قيام النموذج بمراجعة أو استبدال أو إبطال أو حذف أي جزء تم إنشاؤه بواسطة النموذج. في هذه الورقة ، نقدم نموذجًا جديدًا لإنشاء المستندات شبه الانحدار الذاتي قادر على مراجعة النص الناتج وتحريره. بناءً على النماذج الحديثة من (Gu et al. ، 2019 ؛ Xu and Carpuat ، 2020) نقترح إنشاء المستندات كعملية قرار ماركوف الهرمية مع تسلسل هرمي من مستويين ، حيث برامج التحرير عالية ومنخفضة المستوى. نحن ندرب نموذجنا باستخدام التعلم بالمحاكاة (حسين وآخرون ، 2017) ونقدم سياسة التدرج بحيث تتعلم كل سياسة على مخرجات تطبيق الإجراء السابق. تلقي التجارب التي تطبق النهج المقترح رؤى مختلفة حول مشاكل إنشاء النص الطويل باستخدام نموذجنا. نقترح علاجات مختلفة مثل استخدام مجموعة البيانات المقطرة ، وتصميم آليات انتباه أفضل واستخدام نماذج الانحدار الذاتي كبرنامج منخفض المستوى.</abstract_ar>
      <abstract_ja>長く一貫したテキストを生成することは、要約、文書レベルの機械翻訳、ストーリー生成などの多くのアプリケーション領域を含む、重要で困難なタスクです。 文章内の一貫性をモデリングすることに成功したにもかかわらず、既存の長いテキスト生成モデル（例えば、ＢＡＲＴ及びＧＰＴ － ３ ）は、生成されたテキスト全体にわたって一貫性のあるイベントシーケンスを維持するために依然として苦労する。 これは、モデルがモデルによって生成された部品を改訂、交換、取り消し、または削除することが困難であるためであると推測します。 本稿では、生成されたテキストの改訂・編集が可能な新規の半自己回帰文書生成モデルを提示する。 (Gu et al., 2019; Xu and Carpuat, 2020)による最近のモデルに基づいて、高レベルと低レベルの編集プログラムを含む2レベルの階層構造を持つ階層的なマルコフ決定プロセスとしてドキュメント生成を提案します。 模倣学習を使用してモデルをトレーニングし（ Hussein et al., 2017 ）、各ポリシーが前のアクションを適用することでアウトプットを学習するように、ロールインポリシーを導入します。 提案されたアプローチを適用する実験は、私たちのモデルを使用した長いテキスト生成の問題に関するさまざまな洞察を提供します。 蒸留データセットの使用、より良い注意メカニズムの設計、低レベルプログラムとしての自己回帰モデルの使用など、さまざまな救済策を提案します。</abstract_ja>
      <abstract_zh>生长连贯,本一重挑战性,涵盖众应用领域,摘要、文档机器翻译、故事成。 虽一致性建模成功于句,而长文本生模(如 BART 与 GPT-3),难以贯序。 臣测其模形难改,代易,省削模样。 于本文中,新过半自归文档生成模样,当模能改辑成文本。 近模(Gu等,2019。 Xu、Carpuat,2020)文档生成两等层次结构分马尔可夫决策之际,高下辑序。 吾以法学习吾形(Hussein et al., 2017),引入滚策,以学先输。 宜用所法实验示用吾模样生长文本诸见。 臣等条上诸补救措施,如用精炼数据集,设意机制及用自归模形为下程。</abstract_zh>
      <abstract_hi>लंबे और सुसंगत पाठ उत्पन्न करना एक महत्वपूर्ण और चुनौतीपूर्ण कार्य है जिसमें कई अनुप्रयोग क्षेत्रों जैसे सारांश, दस्तावेज़ स्तर की मशीन अनुवाद और कहानी पीढ़ी शामिल हैं। मॉडलिंग इंट्रा-वाक्य सुसंगतता में सफलता के बावजूद, मौजूदा लंबे पाठ पीढ़ी के मॉडल (जैसे, BART और GPT-3) अभी भी उत्पन्न पाठ में एक सुसंगत घटना अनुक्रम बनाए रखने के लिए संघर्ष करते हैं। हम अनुमान लगाते हैं कि यह मॉडल द्वारा उत्पन्न किए गए किसी भी हिस्से को संशोधित करने, बदलने, रद्द करने या हटाने के लिए मॉडल के लिए कठिनाई के कारण है। इस पेपर में, हम एक उपन्यास अर्ध-autoregressive दस्तावेज़ पीढ़ी मॉडल प्रस्तुत करते हैं जो उत्पन्न पाठ को संशोधित और संपादित करने में सक्षम है। द्वारा हाल के मॉडल पर निर्माण (Gu et al., 2019; Xu और Carpuat, 2020) हम दो स्तर पदानुक्रम के साथ एक पदानुक्रमित मार्कोव निर्णय प्रक्रिया के रूप में दस्तावेज़ पीढ़ी का प्रस्ताव करते हैं, जहां उच्च और निम्न स्तर के संपादन कार्यक्रम हैं। हम नकल सीखने (हुसैन एट अल. 2017) का उपयोग करके अपने मॉडल को प्रशिक्षित करते हैं और रोल-इन नीति पेश करते हैं जैसे कि प्रत्येक नीति पिछली कार्रवाई को लागू करने के आउटपुट पर सीखती है। प्रस्तावित दृष्टिकोण को लागू करने वाले प्रयोग हमारे मॉडल का उपयोग करके लंबी पाठ पीढ़ी की समस्याओं पर विभिन्न अंतर्दृष्टि डालते हैं। हम विभिन्न उपचारों का सुझाव देते हैं जैसे कि आसुत डेटासेट का उपयोग करना, बेहतर ध्यान तंत्र डिजाइन करना और निम्न स्तर के कार्यक्रम के रूप में ऑटोरिग्रेसिव मॉडल का उपयोग करना।</abstract_hi>
      <abstract_ga>Is tasc tábhachtach dúshlánach é téacs fada comhleanúnach a ghiniúint a chuimsíonn go leor réimsí feidhmchláir mar achoimre, aistriúchán meaisín ar leibhéal doiciméad agus giniúint scéalta. In ainneoin gur éirigh chomh maith sin le comhleanúnachas in abairt a shamhaltú, tá deacrachtaí fós ag samhlacha giniúna téacs fada atá ann cheana féin (m.sh., BART agus GPT-3) seicheamh comhleanúnach teagmhas a choinneáil ar fud an téacs ginte. Is dóigh linn gurb é seo an chúis leis an deacracht atá ag an múnla aon chuid atá ginte ag an múnla a athbhreithniú, a athsholáthar, a chúlghairm nó a scriosadh. Sa pháipéar seo, cuirimid i láthair samhail giniúna doiciméad leath-uathchéimnitheach úrscéal atá in ann athbhreithniú agus eagarthóireacht a dhéanamh ar an téacs ginte. Ag tógáil ar mhúnlaí le déanaí le (Gu et al., 2019; Xu agus Carpuat, 2020) molaimid giniúint doiciméad mar phróiseas cinnidh ordlathach Markov le hordlathas dhá leibhéal, ina ndéantar na cláir eagarthóireachta ardleibhéil agus ísealleibhéil. Déanaimid ár múnla a thraenáil trí úsáid a bhaint as foghlaim aithrise (Hussein et al., 2017) agus tugtar isteach beartas rollaithe isteach ionas go bhfoghlaimíonn gach beartas ar an aschur ó chur i bhfeidhm an ghnímh roimhe seo. Trí na turgnaimh a bhaineann leis an gcur chuige molta a chur i bhfeidhm, faightear léargais éagsúla ar na fadhbanna a bhaineann le cruthú téacs fada ag baint úsáide as ár múnla. Molaimid réitigh éagsúla ar nós tacar sonraí driogtha a úsáid, meicníochtaí airde níos fearr a dhearadh agus samhlacha uath-aischéimnitheacha a úsáid mar chlár ísealleibhéil.</abstract_ga>
      <abstract_el>Η δημιουργία μεγάλου και συνεκτικού κειμένου είναι μια σημαντική και προκλητική εργασία που περιλαμβάνει πολλούς τομείς εφαρμογής, όπως η σύνοψη, η μηχανική μετάφραση σε επίπεδο εγγράφων και η δημιουργία ιστοριών. Παρά την επιτυχία στη μοντελοποίηση της συνοχής εντός των προτάσεων, τα υπάρχοντα μοντέλα δημιουργίας μεγάλου μήκους κειμένου (π.χ. και GPT-3) εξακολουθούν να αγωνίζονται να διατηρήσουν μια συνεκτική ακολουθία γεγονότων σε όλο το παραγόμενο κείμενο. Υποθέτουμε ότι αυτό οφείλεται στη δυσκολία για το μοντέλο να αναθεωρήσει, να αντικαταστήσει, να ανακαλέσει ή να διαγράψει οποιοδήποτε μέρος έχει δημιουργηθεί από το μοντέλο. Στην παρούσα εργασία, παρουσιάζουμε ένα νέο μοντέλο ημι-αυτοανακριτικής δημιουργίας εγγράφων ικανό να αναθεωρήσει και να επεξεργαστεί το παραγόμενο κείμενο. Βασιζόμενοι σε πρόσφατα μοντέλα (κ.λ., 2019, και Καρπουάτ, 2020) προτείνουμε τη δημιουργία εγγράφων ως ιεραρχική διαδικασία λήψης αποφάσεων με ιεραρχία δύο επιπέδων, όπου το υψηλό και το χαμηλό επίπεδο προγραμμάτων επεξεργασίας. Εκπαιδεύουμε το μοντέλο μας χρησιμοποιώντας τη μάθηση απομίμησης (κ.α., 2017) και εισάγουμε πολιτική με τέτοιο τρόπο ώστε κάθε πολιτική να μαθαίνει σχετικά με το αποτέλεσμα της εφαρμογής της προηγούμενης δράσης. Τα πειράματα που εφαρμόζουν την προτεινόμενη προσέγγιση ρίχνουν διάφορες απόψεις για τα προβλήματα της μακροχρόνιας δημιουργίας κειμένου χρησιμοποιώντας το μοντέλο μας. Προτείνουμε διάφορες λύσεις όπως η χρήση αποσταγμένων δεδομένων, ο σχεδιασμός καλύτερων μηχανισμών προσοχής και η χρήση αυτοανακριτικών μοντέλων ως χαμηλού επιπέδου πρόγραμμα.</abstract_el>
      <abstract_ka>სიგრძელი და შესაძლებელი ტექსტის შექმნა არის მნიშვნელოვანი და შესაძლებელი რაოდენობა, როგორც გამოსახულება, დოკუმენტის დოკუმენტის მაქსინის გადატყვება და ისტორიის მაგრამ მოდელის შემდგომარების შემდგომარეობაში, სხვა დრო ტექსტის შემდგომარების მოდელები (მაგალითად, BART და GPT-3) მუშაობის შემდგომარების შემდგომარების შემდგომარებისთვის მუშ ჩვენ ვფიქრობთ, რომ ეს არის მოდელის რედაქტირება, შეცვლა, გამოცვლა ან წაშლა ყველა ნაწილი, რომელიც მოდელის შექმნა. ამ დოკუმენტში ჩვენ აჩვენებთ პრომენტის ნახევატორეგრესიური დოკუმენტის შექმნა მოდელის რედაქტირება და რედაქტირება. (Gu et al., 2019; Xu და Carpuat, 2020) ჩვენ მივიღეთ დოკუმენტის შექმნა როგორც იერაქტიკური მარковის გადაწყვეტილების პროცესი, რომელიც ორი დონის იერაქტია, სადაც მაღალი და მაღალი დონის რედაქტირების პ ჩვენ ჩვენი მოდელს იმიტაციის სწავლების გამოყენებით (Hussein et al., 2017) და შევცვალოთ პოლიტიკაში, როგორც ყოველ პოლიტიკაში ისწავლის წინა მომხმარების გამოყენება. პრობლემენტების გამოყენება პრობლემენტების განსაზღვრებით განსხვავებული მონაცემების შესახებ ჩვენი მოდელის გამოყენება. ჩვენ შეგიძლიათ განსხვავებული სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა მონაცემების გამოყენება, სხვადასხვა სხვადასხვა მონაცე</abstract_ka>
      <abstract_hu>Hosszú és koherens szöveg létrehozása fontos és kihívást jelentő feladat, amely számos alkalmazási területet magában foglal, mint például az összefoglalás, a dokumentum szintű gépi fordítás és a történetek generálása. A mondatokon belüli koherencia modellezésének sikere ellenére a meglévő hosszú szöveggenerációs modellek (például BART és GPT-3) még mindig küzdenek egy koherens eseménysorozat fenntartásával a generált szövegben. Feltételezzük, hogy ez azért van, mert a modell nehézséget okoz a modell által létrehozott bármely alkatrész felülvizsgálatának, kicserélésének, visszavonásának vagy törlésének. Ebben a tanulmányban egy új, félig-autoregresszív dokumentumgenerációs modellt mutatunk be, amely képes a generált szöveg felülvizsgálatára és szerkesztésére. A legutóbbi modellekre építve (Gu et al., 2019; Xu és Carpuat, 2020) javasoljuk a dokumentum generálását hierarchikus Markov döntési folyamatként, kétszintes hierarchiával, ahol a magas és alacsony szintű szerkesztési programok. Modellünket imitációs tanulással (Hussein et al., 2017) képezzük, és bevezetjük a roll-in politikát úgy, hogy minden politika megismerje az előző intézkedés alkalmazásának eredményeit. A javasolt megközelítést alkalmazó kísérletek különböző betekintéseket nyújtanak a modellünk segítségével a hosszú szöveggenerálás problémáira. Különböző megoldásokat javasolunk, mint például desztillált adatkészlet használata, jobb figyelemmechanizmusok kialakítása és az autoregresszív modellek használata alacsony szintű programként.</abstract_hu>
      <abstract_kk>Уақыт және тәуелсіз мәтін құру - маңызды және бұл көп қолданбалар аумақтарын, құжаттың деңгейіндегі машинаның аударуы және оқиғаны құру үшін бірнеше қолданба Интернет сөздердің теңдеу моделінің сәттілігіне қарамастан, барлық ұзын мәтін құру үлгілері (мысалы, BART және GPT- 3) жасалған мәтін бойынша теңдеу үшін әлі көмектеседі. Біз үлгісін қайта қарау, алмастыру, қайта алып тастау немесе өшіру үшін бұл үлгісінің қиындығының себебі деп ойлаймыз. Бұл қағазда, жарты авторегрессивні құжатты құру үлгісін көрсетедік, құрылған мәтінді қайта қарау және өзгерту мүмкіндігі болатын. Жуырдағы моделдерге (Gu et al., 2019; Xu және Carpuat, 2020) құжатты құру процесі ретінде екі деңгейіндегі иерархиясы бар, онда жоғары және төмен деңгейіндегі өңдеу бағдарламалары болып, құжатты құру процесі ретін Біз моделімізді түрлендіру үйренімізді (Hussein et al., 2017) қолданып, әрбір ережелер алдыңғы әрекетті қолдану үшін үйренетін саясаттарды келтіреміз. Келтірілген тәжірибені қолдану тәжірибелері үлгі мәтінді құру мәселелерін өзгертеді. Біз бөлек деректер жиынын қолдану, артықшылық механизмтерді құру және авторегрессиялық үлгілерді төмен деңгейіндегі бағдарлама ретінде авторегрессиялық моделдерді қолдану үші</abstract_kk>
      <abstract_ms>Generating long and coherent text is an important and challenging task encompassing many application areas such as summarization, document level machine translation and story generation.  Walaupun berjaya dalam memmodelkan kesehatan dalam kalimat, model generasi teks panjang yang ada (cth., BART dan GPT-3) masih berjuang untuk menjaga urutan peristiwa yang konsisten sepanjang teks yang dijana. Kami menduga bahawa ini adalah kerana kesulitan bagi model untuk mengubah, menggantikan, membatalkan atau padam sebarang bahagian yang telah dijana oleh model. Dalam kertas ini, kami memperkenalkan model generasi dokumen setengah-autoregresif yang mampu mengubah dan edit teks yang dijana. Membangun pada model baru-baru ini oleh (Gu et al., 2019; Xu dan Carpuat, 2020) kami cadangkan generasi dokumen sebagai proses keputusan Markov hierarkik dengan hierarki dua tahap, di mana program penyuntingan tahap tinggi dan rendah. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action.  Eksperimen yang melaksanakan pendekatan yang diusulkan membuang berbagai pandangan mengenai masalah generasi teks panjang menggunakan model kami. Kami cadangkan berbagai ubat-ubatan seperti menggunakan set data berwarna, merancang mekanisme perhatian yang lebih baik dan menggunakan model autoregresif sebagai program tahap rendah.</abstract_ms>
      <abstract_it>Generare testo lungo e coerente è un compito importante e impegnativo che comprende molte aree applicative come la sintesi, la traduzione automatica a livello di documento e la generazione di storie. Nonostante il successo nella modellazione della coerenza intra-frase, i modelli esistenti di generazione di testo lungo (ad esempio BART e GPT-3) faticano ancora a mantenere una sequenza di eventi coerente in tutto il testo generato. Supponiamo che ciò sia dovuto alla difficoltà per il modello di rivedere, sostituire, revocare o eliminare qualsiasi parte generata dal modello. In questo articolo, presentiamo un nuovo modello di generazione di documenti semi-autoregressivo in grado di rivedere e modificare il testo generato. Basandoci su modelli recenti di (Gu et al., 2019; Xu e Carpuat, 2020) proponiamo la generazione di documenti come processo decisionale gerarchico Markov con una gerarchia a due livelli, dove i programmi di editing di alto e basso livello. Formiamo il nostro modello utilizzando l'apprendimento imitativo (Hussein et al., 2017) e introduciamo una politica di rollin in modo che ogni politica impari sui risultati dell'applicazione dell'azione precedente. Esperimenti che applicano l'approccio proposto forniscono varie intuizioni sui problemi della generazione di testi lunghi utilizzando il nostro modello. Suggeriamo vari rimedi come l'utilizzo di set di dati distillati, la progettazione di meccanismi di attenzione migliori e l'utilizzo di modelli autoregressivi come programma di basso livello.</abstract_it>
      <abstract_lt>Ilgo ir nuoseklaus teksto kūrimas yra svarbi ir sunki užduotis, apimanti daugelį taikymo sričių, pavyzdžiui, santrauką, dokumentų lygio vertimą mašinomis ir istorijų kūrimą. Nepaisant sėkmės modeliuojant nuoseklumą tarp sakinių, esami ilgų tekstų kūrimo modeliai (pvz., BART ir GPT-3) vis dar stengiasi išlaikyti nuoseklią renginių seką viso parengto teksto metu. Mes darome prielaidą, kad tai yra dėl sunkumų modeliui peržiūrėti, pakeisti, atšaukti ar išbraukti bet kurią modelio sukurtą dalį. Šiame dokumente pristatome naują pusiau autoregresinį dokumentų kūrimo model į, galintį peržiūrėti ir redaguoti sukauptą tekstą. Remdamiesi naujausiais modeliais (Gu et al., 2019; Xu ir Carpuat, 2020 m.), siūlome dokumentų kūrimą kaip hierarchinį Markovo sprendimų priėmimo procesą su dviejų lygių hierarchija, kurioje rengiamos aukšto ir žemo lygio redakcijos programos. Mokome savo model į imituojant mokymąsi (Hussein et al., 2017 m.) ir įgyvendiname įtraukimo politiką, kad kiekviena politika pasimokytų iš ankstesnių veiksmų taikymo rezultatų. Siūlomo požiūrio taikymo eksperimentai rodo įvairias žinias apie ilgos tekstų kūrimo problemas naudojant mūsų model į. Siūlome įvairias taisomąsias priemones, pavyzdžiui, naudoti distiliuotus duomenų rinkinius, kurti geresnius dėmesio mechanizmus ir kaip mažo lygio program ą naudoti autoregresinius modelius.</abstract_lt>
      <abstract_mk>Генерирањето долг и коеорентен текст е важна и предизвикувачка задача која вклучува многу области на апликациите како што се резултатите, машинскиот превод на ниво на документи и генерацијата на приказни. И покрај успехот во моделирањето на внатрешната кохеренција на речениците, постојните модели на долга генерација на текст (на пример, BART и GPT-3) сé уште се борат за одржување на кохерентна секвенца на настани низ целиот генериран текст. Претпоставуваме дека ова е поради тешкотијата на моделот да го ревидира, замени, повлече или избрише било кој дел кој е генериран од моделот. Во овој весник, претставуваме нов полуавторегресивен модел за генерација на документи способен да го ревидира и уредува генерираниот текст. Поради неодамнешните модели од (Гу и други, 2019; Ху и Карпуат, 2020) предложуваме генерација на документи како хиерархичен процес на одлука на Марков со хиерархија на две нивоа, каде што програмите за уредување на високо и ниско ниво. Ние го обучуваме нашиот модел користејќи имитациско учење (Хусеин и други, 2017) и воведуваме политика за вложување, така што секоја политика ќе научи за резултатот на апликацијата на претходната акција. Експериментите кои го применуваат предложениот пристап даваат различни информации за проблемите на долгата генерација на текст користејќи го нашиот модел. Предлагаме различни лекови, како што е употребата на дестилирани податоци, дизајнирањето подобри механизми на внимание и употребата на авторегресивни модели како програма на ниско ниво.</abstract_mk>
      <abstract_ml>ഒരുപാട് പ്രയോഗത്തിന്റെ പ്രദേശങ്ങളെ ചുരുക്കം ചെയ്യുന്ന ഒരു പ്രധാനപ്പെട്ട പ്രയോഗത്തിന്റെ പ്രദേശങ്ങള്‍ക്കുള്ള പ്രധാ നിലവിലുള്ള ടെക്സ്റ്റ് തലമുറന്ന മോഡലുകള്‍ (ഉദാ. BART, GPT-3) നിലവിലുള്ള ഒരു സഹജമായ സംഭവത്തിന്റെ സംവിധാനത്തില്‍ സൂക്ഷിക്കുന്നതിനായി പ്രശ മോഡല്‍ ഉണ്ടാക്കിയ ഏതെങ്കിലും ഭാഗം മാറ്റുവാന്‍, പകര്‍ത്തുവാന്‍, വീണ്ടും മാറ്റുക അല്ലെങ്കില്‍ നീക്കം ചെയ്യാന്‍ മാതൃകയുടെ  ഈ പത്രത്തില്‍, നമ്മള്‍ ഒരു നോവല്‍ സ്വയമായി രേഖയില്‍ നിര്‍മ്മിക്കുന്ന രേഖയുടെ നിര്‍മ്മാണം മോഡല്‍ നിര്‍മ്മിക്കുന്ന അടുത്തിടെ മോഡലുകളില്‍ നിര്‍മ്മിക്കുന്നത് (Gu et al., 2019; Xu and Carpuat, 2020) ഞങ്ങള്‍ രേഖയുടെ തലമുറയില്‍ നിന്നും രണ്ടു നില മാര്‍ക്കോവിന്റെ തീരുമാന പ്രക്രിയയായി പ ഞങ്ങള്‍ നമ്മുടെ മോഡല്‍ പരിശീലിപ്പിക്കുന്നു. മുമ്പ് പ്രവര്‍ത്തിപ്പിക്കുന്നതിന്‍റെ ഫലം പ്രയോഗിക്കുന്നതിനെപ്പറ്റി എല്ലാ പോളിസി നീണ്ട ട ടെക്സ്റ്റ് തലമുറതലമുറയുടെ പ്രശ്നങ്ങളെക്കുറിച്ച് പ്രായശ്ചിത്തമായ പരീക്ഷണങ്ങള്‍ നമ്മുടെ മോ We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</abstract_ml>
      <abstract_no>Oppretting av lange og koherent tekst er ein viktig og vanskeleg oppgåve som omsluttar mange program-område som samansering, omsetjing av maskinen til dokumentnivå og storleik. Til tross suksess i modellen av samsvar med innsetningar, står det lange tekstgenereringsmodeller (f.eks. BART og GPT-3) fortsatt i bruk til å halda e in samsvarande hendingskombinasjon gjennom den genererte teksten. Vi gjer at dette er på grunn av vanskeligheta for modellen å gjenoppretta, erstatta, tilbakekalla eller sletta alle deler som er laga av modellen. I denne papiret viser vi eit roman semi- autoregressiv dokumentlagmodell som kan gjere om og redigere den genererte teksten. Byggjer vi på nyleg modeller av (Gu et al., 2019; Xu og Carpuat, 2020) vi fører til å laga dokument som eit hierarkisk Markov beslutningsprosess med to nivåhierarki, der høg og låg nivåredigeringsprogram. Vi treng modellen vårt ved å lære imitasjonar (Hussein et al., 2017) og introdusere rolleringspolitikk slik at kvar politikk lærer på utdata av å bruka førre handlinga. Eksperimentar som brukar den foreslåde tilnærminga gjer ulike innsyningar om problema med lang tekstgenerering med modellen vår. Vi foreslår forskjellige rettingar som å bruka destilerte datasett, utforma betre oppmerksmekanisme og bruka autoregressive modeller som eit låg nivåprogram.</abstract_no>
      <abstract_pl>Generowanie długiego i spójnego tekstu jest ważnym i wymagającym zadaniem obejmującym wiele obszarów zastosowań, takich jak podsumowanie, tłumaczenie maszynowe na poziomie dokumentów i generowanie historii. Pomimo sukcesu w modelowaniu spójności wewnątrz zdań istniejące długie modele generowania tekstu (np. BART i GPT-3) nadal trudno utrzymać spójną sekwencję zdarzeń w całym wygenerowanym tekście. Domyślamy się, że jest to z powodu trudności dla modelu w zmianie, zastąpieniu, cofnięciu lub usunięciu dowolnej części, która została wygenerowana przez model. W niniejszym artykule przedstawiamy nowatorski model generowania półautoresywnego dokumentu zdolny do rewizji i edycji wygenerowanego tekstu. Opierając się na najnowszych modelach (Gu et al., 2019; Xu i Carpuat, 2020) proponujemy generowanie dokumentów jako hierarchiczny proces decyzji Markova z dwupoziomową hierarchią, gdzie programy edycji wysokiego i niskiego poziomu. Szkolimy nasz model przy użyciu imitacji uczenia się (Hussein et al., 2017) i wprowadzamy politykę roll-in tak, aby każda polityka uczyła się na wynikach zastosowania poprzedniego działania. Eksperymenty stosujące proponowane podejście dają różne spostrzeżenia na problemy generowania długiego tekstu przy użyciu naszego modelu. Proponujemy różne środki zaradcze, takie jak wykorzystanie destylowanego zbioru danych, projektowanie lepszych mechanizmów uwagi i wykorzystanie modeli autoregresywnych jako programu niskiego poziomu.</abstract_pl>
      <abstract_mt>Il-ġenerazzjoni ta’ test twil u koerenti hija kompitu importanti u ta’ sfida li jinkludi ħafna oqsma ta’ applikazzjoni bħas-sommarju, it-traduzzjoni tal-magni fil-livell tad-dokumenti u l-ġenerazzjoni tal-istoriji. Minkejja s-suċċess fl-immudellar tal-koerenza bejn is-sentenzi, il-mudelli e żistenti tal-ġenerazzjoni tat-testi twal (pereżempju, il-BART u l-GPT-3) g ħadhom qed jaħdmu biex iżommu sekwenza koerenti ta’ avvenimenti fit-test ġenerat kollu. Aħna nżuru li dan huwa minħabba d-diffikultà għall-mudell biex jirrevedi, jissostitwixxi, jirrevoka jew iħassar kwalunkwe parti li ġiet iġġenerata mill-mudell. In this paper, we present a novel semi-autoregressive document generation model capable of revising and editing the generated text.  Filwaqt li nibnu fuq mudelli reċenti minn (Gu et al., 2019; Xu u Carpuat, 2020) nipproponu l-ġenerazzjoni tad-dokumenti bħal a proċess ta’ deċiżjoni ġerarkiku Markov b’ġerarkija ta’ żewġ livelli, fejn il-programmi ta’ edizzjoni ta’ livell għoli u baxx. Aħna nħarrġu l-mudell tagħna bl-użu tat-tagħlim tal-imitazzjoni (Hussein et al., 2017) u nintroduċu politika ta’ introduzzjoni b’tali mod li kull politika titgħallem dwar ir-riżultati tal-applikazzjoni tal-azzjoni preċedenti. L-esperimenti li japplikaw l-approċċ propost jagħtu diversi fehmiet dwar il-problemi tal-ġenerazzjoni ta’ testi twal bl-użu tal-mudell tagħna. Aħna ssuġġerixxu diversi rimedji bħall-użu ta’ sett ta’ dejta distillat, it-tfassil ta’ mekkaniżmi ta’ attenzjoni a ħjar u l-użu ta’ mudelli awtoregressivi bħala programm ta’ livell baxx.</abstract_mt>
      <abstract_mn>Урт, нийгмийн текст бий болгох нь чухал, шаардлагатай ажиллагаа, олон програм хэсгийг тодруулах, баримтын түвшинд машин орчуулах, түүх бий болгох мэт олон хэсгийг тодруулдаг. Интро-өгүүлбэр хоорондоо холбогдолтой модель хийх амжилтыг хүртэл, урт текст үеийн загвар (жишээ нь BART болон GPT-3) үүсгэсэн текст дээр холбогдолтой үйл явдлын дарааллыг хадгалахын тулд тэмцдэг. Бид үүнийг загварын шинэчлэх, орлуулах, сэргээх, эсвэл устгах хэцүү хэсгийг загвараар бүтээсэн хэцүү хэсгийг шинэчлэхэд хэцүү гэж боддог. Энэ цаасан дээр бид бүтээгдэхүүнийг шинэчлэх, өөрчлөх боломжтой, шинэчлэх зохиолын загварыг шинэчлэх, өөрчлөх боломжтой шинэ санааг автоматжуулж байна. Сүүлийн үеийн загварууд дээр (Gu et al., 2019; Xu, Carpuat, 2020) бид баримт бичлэг бүтээхийг 2 түвшинд шийдвэр гаргах процесс болгож, хамгийн өндөр, бага түвшинд зохион бүтээх програм гэж санал болгож байна. Бид загварын загварыг хуурамжлах сургалтыг ашиглан (Хуссейн et al., 2017) суралцаж, өмнөх үйл явдлыг хэрэгжүүлэх үйл явдлыг суралцаж байгаа төлөвлөгөө хийдэг. Өмнөх арга барилгыг ашиглах туршилтууд бидний загварыг ашиглан урт текст үеийн асуудлуудын тухай олон ойлголт өгдөг. Бид өөр өөр төрлийн шинэчлэлүүдийг санал болгож, сайн анхаарал төвлөрүүлэх механизм, авторегрессийн загваруудыг бага түвшин програм болгон ашиглана.</abstract_mn>
      <abstract_ro>Generarea de text lung și coerent este o sarcină importantă și provocatoare care cuprinde multe domenii de aplicare, cum ar fi rezumarea, traducerea automată la nivel de documente și generarea de povești. În ciuda succesului în modelarea coerenței intra-frază, modelele existente de generare a textului lung (de exemplu, BART și GPT-3) încă se luptă pentru a menține o secvență de evenimente coerente pe tot parcursul textului generat. Presupunem că acest lucru se datorează dificultății modelului de a revizui, înlocui, revoca sau șterge orice parte generată de model. În această lucrare, prezentăm un nou model semi-autoregresiv de generare a documentelor capabil să revizuiască și să editeze textul generat. Bazându-ne pe modele recente până la (Gu et al., 2019; Xu și Carpuat, 2020) propunem generarea documentelor ca proces decizional ierarhic Markov cu o ierarhie de două niveluri, unde programele de editare de nivel înalt și jos. Ne pregătim modelul folosind învățarea imitației (Hussein et al., 2017) și introducem politici roll-in astfel încât fiecare politică să învețe rezultatele aplicării acțiunii anterioare. Experimentele care aplică abordarea propusă oferă diverse perspective asupra problemelor generarii de text lung folosind modelul nostru. Vă sugerăm diverse remedii, cum ar fi utilizarea setului de date distilate, proiectarea unor mecanisme mai bune de atenție și utilizarea modelelor autoregresive ca un program de nivel scăzut.</abstract_ro>
      <abstract_sr>Napravljanje dugog i saslušnog teksta je važan i izazovni zadatak koji uključuje mnoge oblasti aplikacije poput sažetanja, prevoda stroja na nivou dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli dugog teksta generacije (npr. BART i GPT-3) i dalje se bore za održavanje koherentne sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela da pregleda, zameni, ukloni ili izbriše bilo koji deo koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i editaciju proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao hijerarhički proces odluke Markov a sa hijerarhijom dva nivoa, gde su programi za editiranje visokog i niskog nivoa. Mi treniramo svoj model koristeći učenje imitacije (Hussein et al., 2017) i predstavljamo politiku koja se uključuje kako svaka politika uči o izlazu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup imaju različite uvjete o problemima duge generacije teksta koristeći naš model. Predlažemo raznim sredstvima za opremu poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</abstract_sr>
      <abstract_si>ලොකු සහ සම්බන්ධ පාළුව නිර්මාණය වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැඩසටහන් වලින් ව සාමාන්‍ය වාක්ය සංවිධානයක් නිර්මාණය කරලා තියෙන්නේ සාමාන්‍ය විශ්වාස කරලා තියෙන්නේ ලොකු පාළ ප්‍රමාණය (උදාහරණය, BART සහ GPT-3) තාම අපි හිතන්නේ මේක නිර්මාණය වෙනස් කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථ මේ පැත්තට, අපි නිර්මාණය කරපු පාළුවට පරික්ෂා සහ ස්වයංක්‍රියාත්මක විස්තර කරන්න පුළුවන් නිර්මාණය සහ ස (Gu et al., 2019; Xu and Carpuat, 2020යි) අපි ලිපිණිපත් විශාල විශාල විශාල විශාලයක් විදියට පරීක්ෂණය කරනවා මාර්කොව් තීර්ණාපත්ති පරීක්ෂණයක් දෙ අපි අපේ මොඩල් එක ප්‍රයෝජනය කරනවා ප්‍රයෝජනය ඉගෙන ගන්න පුළුවන් විදිහට (හුසේන් ට් ල්., 2017) සහ ප්‍රයෝජනය ප්‍රයෝජනය කරනවා වග පරීක්ෂණය සඳහා ප්‍රවේශනය කරන්න පුළුවන් ප්‍රශ්නයක් අපේ මොඩල් භාවිතා කරන්න පුළුවන් ලොකු පාළුවේ  අපි ප්‍රශ්නයක් කරනවා විවිධ ප්‍රශ්නයක් වගේම විශේෂ දත්ත සෙට් වියුතුයි, හොඳ අවධානය සැකසුම් සැකසුම් වි</abstract_si>
      <abstract_so>Muujinta qoraal dhaadheer iyo isku xiran waa shaqa muhiim ah oo dhibaato leh oo ku wareegsan meelo badan oo codsiga, sida summarinta, turjumidda qoraalka heerka ee muusikada iyo farshaha sheekooyinka. Inkastoo liibaanshaha sameynta halqabsiga interna-sentence, waxaa jira modello dhaadheer oo dhaadheer qoraal ah (tusaale. BART iyo GPT-3) weli waxay u dagaalamayaan inay ilaaliyaan muuqashada isku xiran dhacdooyinka dhashay oo dhan. Waxaynu malaynaynaa in taasi sababtoo ah dhibaatada tusaaleyda ay ku adag tahay in ay ku cusboonayso, beddelo, beddelo ama deleto qeyb kasta oo sameynta sameeyay. Qoraalkan waxaynu ku soo qoraynaa qoraal saxda ah oo u eg qoraal dhaqan ah oo u awoodi kara inuu ka baaraandegiso iyo tahriri karo qoraalka la sameeyay. Dhisidno modello ugu dambeysan (Gu et al., 2019; Xu iyo Carpuat, 2020) waxaynu u soo jeedaynaa sameynta dukumentiga sida go'aanka hierarchical Markov oo leh laba heer hierarchy, halkaas oo ah barnaamijyada hagitaanka heerka sare iyo hoose. Tusaale ahaan waxaynu ku tababarinnaa waxbarashada takhasuska (Hussein et al., 2017) waxaana soo bandhijinaynaa siyaasada qoraalka qoraalka, kaas oo ah in siyaasad kastaa uu ka baranayo dhamaanka codsashada falimaha hore. Imtixaanka lagu sameeyo qaababka la soo jeeday wuxuu muujiyaa aragtida kala duduwan dhibaatooyinka qarniga qoraalka dheer ee isticmaalka modellkayaga. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</abstract_so>
      <abstract_sv>Att generera lång och sammanhängande text är en viktig och utmanande uppgift som omfattar många tillämpningsområden såsom sammanfattning, maskinöversättning på dokumentnivå och historiegenerering. Trots framgångarna med modellering av samstämmighet mellan meningar kämpar befintliga modeller för lång textgenerering (t.ex. BART och GPT-3) fortfarande för att upprätthålla en sammanhängande händelsesekvens i hela den genererade texten. Vi antar att detta beror på att modellen har svårt att revidera, ersätta, återkalla eller ta bort någon del som genererats av modellen. I denna uppsats presenterar vi en ny semi-autoregressiv dokumentgenerationsmodell som kan revidera och redigera den genererade texten. Baserat på de senaste modellerna från (Gu et al., 2019; Xu och Carpuat, 2020) föreslår vi dokumentgenerering som en hierarkisk Markov beslutsprocess med två nivåer hierarki, där hög och låg nivå redigeringsprogram. Vi tränar vår modell med hjälp av imitationsinlärning (Hussein m.fl., 2017) och introducerar roll-in-policy så att varje policy lär sig resultatet av att tillämpa den tidigare åtgärden. Experiment med tillämpning av det föreslagna tillvägagångssättet ger olika insikter om problemen med lång textgenerering med hjälp av vår modell. Vi föreslår olika botemedel såsom att använda destillerad dataset, utforma bättre uppmärksamhetsmekanismer och använda autoregressiva modeller som ett lågnivåprogram.</abstract_sv>
      <abstract_ta>நீண்ட மற்றும் இணைந்த உரையை உருவாக்குதல் ஒரு முக்கியமான மற்றும் சவாலிக்கும் பணியாகும் சுருக்கம், ஆவண நிலை மொழிமாற்றி மற் வெற்றிகரமாக உள்வாக்கி இணைப்பை மாதிரியும் போது, நீண்ட உரை உரை உருவாக்கும் மாதிரிகள் (உதாரணமாக, BART மற்றும் GPT- 3) முழுவதும் உருவாக்கப்பட்ட உரையில மாதிரி உருவாக்கப்பட்ட எந்த பகுதியையும் மாதிரியாக மாற்ற, மாற்ற, மீண்டும், அல்லது நீக்குவதற்கான கடினமாக இது நினைக்கிறது. இந்த காகிதத்தில், நாம் ஒரு புதிய பாதை- தானியங்கி கட்டுப்பாட்டு ஆவணத்தை உருவாக்க முறைமையை கொண்டு வருகிறோம், உருவ சமீபத்தில் உள்ள மாதிரிகளில் (Gu et al., 2019; Xu மற்றும் கார்புவாட், 2020) நாம் ஆவணத்தை உருவாக்குவது ஒரு மேற்பட்ட மார்க்கோவ் தீர்ப்பு செயல்பாட்டில் இரு மட்டத்தின்  நாங்கள் எங்கள் மாதிரியை பார்ப்பு கற்றுக்கொள்ள பயிற்சி செய்து முந்தைய செயல்களை பயன்படுத்தும் வெளியீட்டில் ஒவ்வொரு கொள்கைய நீண்ட உரை தலைமுறையின் பிரச்சனைகளை நம் மாதிரியை பயன்படுத்தி முன்னோட்டத்தைக் கொண்டு நீண்ட உரை உருவாக்கு We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</abstract_ta>
      <abstract_ur>لہروں اور مہربانی پیغام پیدا کرنے کا ایک اہم اور مشکل کام ہے جو بہت سی کاربریوں کے منطقه میں شامل ہوتا ہے جیسے سامنے پیدا کرنا، دفتر لئوی مہینی ترجمہ اور کہانی پیدا کرنا۔ مہربانی کے ساتھ مہربانی کے ساتھ مہربانی کے ساتھ موجود ہونے کے باعث، موجود لگ ٹیکسٹ نسل موڈل (جیسا کہ BART اور GPT-3) یہاں تک بھی پیدا کیا گیا ہے کہ پیدا کیا گیا متن کے درمیان ایک مشکل حادثہ کے سطح حفاظت کرنے کے لئے کوشش کریں ہم خیال کرتے ہیں کہ یہ مدل کی تغییر، بدل، روک یا حذف کرنے کے لئے مشکل ہے جو مدل سے پیدا کیا گیا ہے۔ اس کاغذ میں، ہم نے ایک نئی نصف-autoregressive سند کی نسل مدل پیش کیے جو پیدا کیا گیا ہے اور سمجھنے کے قابل ہے. ہم نے اچھی مدلکوں پر (Gu et al., 2019; Xu اور Carpuat, 2020) دوسری سطح سطح کے ساتھ دو سطح سطح سطح کے مطابق فیصلہ کا پروسس بنایا ہے جہاں اوپر اور نیچے سطح سمجھنے کے پروگراموں کو پیشنهاد کرتے ہیں. ہم نے اپنے مدل کو مثال سیکھنے کے مطابق (Hussein et al., 2017) کی استعمال سے تطالب کرتے ہیں اور اس طرح رول-in پولیس کو معلوم کرتے ہیں جس طرح ہر پولیس پہلے کے کام کے مطابق استعمال کرتا ہے۔ آزمائش کے مطابق پیشنهاد کی تقریبا کے مطابق ہمارے مدل کے مطابق طویل ٹکسٹ نسل کے مشکلوں کے بارے میں مختلف نظر آتا ہے۔ ہم طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح کرتے ہیں جیسے ڈیٹ سٹ استعمال کرتے ہیں، اچھی توجه کے مکانیسم طراحی کرتے ہیں اور اتروگریسٹ موڈل کو کم سطح پروگرام کے طور پر استعمال کرتے ہیں.</abstract_ur>
      <abstract_uz>@ info: whatsthis @ info: whatsthis Biz o'ylaymiz, bu model yaratilgan bir qismini o'zgartirish, almashtirish, bekor qilish yoki olib tashlash uchun qiyin sababi. Bu hujjatda, biz yaratilgan matnni oʻzgartirish va tahrirlash imkoniyatini yaratib boʻladigan novel avtomatik raqamli hujjat yaratish modelini koʻrsatimiz. Yaqinda ochilgan modellarda (Gu et al., 2019; Xu va Karpuat, 2020) yaratish uchun, biz hujjat yaratishni ikkita darajadagi hamma darajadagi xabarlarni oʻzgartirish dasturi bilan boshqarishni talab qilamiz. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action.  Taʼminlovchi usulni qoʻllash uchun imtiyozlar modelmizni yordamida uzun matn generalining muammolari haqida ko'plab keladi. Biz bir necha muammolar bilan bir xil maʼlumotlar tizimini ishlatish, yaxshi paytlarni yaratish va avto-regressiv modellarni kamaytirish dasturi sifatida foydalanishimizni talab qilamiz.</abstract_uz>
      <abstract_vi>Phát ra một văn bản dài và đồng bộ là một nhiệm vụ quan trọng và đầy thử thách bao gồm nhiều lĩnh vực ứng dụng như là tóm tắt, dịch thuyết trình bằng văn bản và sản xuất câu chuyện. Mặc dù sự thành công trong việc tạo ra sự đồng bộ hạn tù, các mô hình nền văn bản tồn tại (v.d., BART và GPT-3) vẫn đang đấu tranh để duy trì một chuỗi sự kiện liên quan trong suốt đoạn được tạo ra. Chúng tôi cho rằng đây là vì khó khăn cho mô hình để sửa đổi, thay thế, thu hồi hay xóa bất cứ phần nào tạo ra từ mô hình. Trong tờ giấy này, chúng tôi giới thiệu một mẫu tài liệu bán tự động mới có khả năng sửa và sửa đổi văn bản đã tạo ra. Dựa trên các mô hình gần đây của Cố vấn và địa chỉ bây giờ Chúng tôi đề nghị tạo tài liệu như một tiến trình quyết định kiểu Markov cấp hai, nơi các chương trình soạn thảo cấp cao và cấp thấp. Chúng tôi huấn luyện mô hình bằng việc bắt chước học (Hussein et al., tê 7) và đưa ra một chính sách nào đó để cho mỗi chính sách học về kết quả của việc áp dụng hành động trước. Các thử nghiệm áp dụng phương pháp đã đề xuất đưa ra những nghiên cứu khác nhau về vấn đề sản xuất văn bản lâu dài dựa trên phương pháp. Chúng tôi đề nghị phương pháp trị liệu khác nhau như sử dụng bộ dữ liệu chưng cất, thiết kế các cơ chế chăm sóc tốt hơn và sử dụng các mô hình tự vệ như chương trình cấp thấp.</abstract_vi>
      <abstract_nl>Het genereren van lange en samenhangende tekst is een belangrijke en uitdagende taak die veel toepassingsgebieden omvat, zoals samenvatting, machinevertaling op documentniveau en verhaaltgeneratie. Ondanks het succes in het modelleren van coherentie binnen de zin, hebben bestaande lange tekstgeneratiemodellen (bijv. BART en GPT-3) nog steeds moeite om een coherente gebeurtenissequentie in de gegenereerde tekst te behouden. We veronderstellen dat dit te wijten is aan de moeilijkheid voor het model om elk onderdeel dat door het model is gegenereerd te herzien, vervangen, intrekken of verwijderen. In dit artikel presenteren we een nieuw semi-autoregressief documentgeneratiemodel dat de gegenereerde tekst kan reviseren en bewerken. Voortbouwend op recente modellen van (Gu et al., 2019; Xu en Carpuat, 2020) stellen we documentgeneratie voor als een hiërarchisch Markov beslissingsproces met een twee niveaus hiërarchie, waarbij het hoge en lage niveau bewerkingsprogramma's programmeert. We trainen ons model met imitatie learning (Hussein et al., 2017) en introduceren roll-in beleid zodanig dat elk beleid leert over de output van de toepassing van de vorige actie. Experimenten die de voorgestelde aanpak toepassen, geven verschillende inzichten over de problemen van lange tekstgeneratie met behulp van ons model. We stellen verschillende remedies voor, zoals het gebruik van gedestilleerde dataset, het ontwerpen van betere aandachtsmechanismen en het gebruik van autoregressieve modellen als een laag niveau programma.</abstract_nl>
      <abstract_bg>Генерирането на дълъг и съгласуван текст е важна и предизвикателна задача, обхващаща много области на приложение като обобщаване, машинен превод на ниво документи и генериране на истории. Въпреки успеха при моделирането на съгласуваността между изреченията, съществуващите модели за генериране на дълги текстове (напр. BART и GPT-3) все още се борят да поддържат последователност на събитията в целия генериран текст. Предполагаме, че това се дължи на трудността моделът да преразгледа, замени, отмени или изтрие всяка част, която е генерирана от модела. В настоящата статия представяме нов полу-авторегресивен модел за генериране на документи, способен да преразгледа и редактира генерирания текст. Въз основа на последните модели на (Гу и др., 2019; Ксу и Карпуат, 2020) предлагаме генериране на документи като йерархичен процес на вземане на решения на Марков с йерархична йерархия на две нива, където са програмите за редактиране на високо и ниско ниво. Ние обучаваме нашия модел, използвайки имитация на обучение (Хюсеин и др., 2017) и въвеждаме политика на рол-ин, така че всяка политика да се научи за резултатите от прилагането на предишното действие. Експериментите, прилагащи предложения подход, хвърлят различни прозрения за проблемите на дългото генериране на текст, използвайки нашия модел. Предлагаме различни средства за защита, като например използване на дестилиран набор от данни, проектиране на по-добри механизми за внимание и използване на авторегресивни модели като програма на ниско ниво.</abstract_bg>
      <abstract_de>Lange und kohärente Texte zu generieren ist eine wichtige und herausfordernde Aufgabe, die viele Anwendungsbereiche wie Zusammenfassung, maschinelle Übersetzung auf Dokumentenebene und Story-Generierung umfasst. Trotz des Erfolgs bei der Modellierung der Kohärenz innerhalb des Satzes kämpfen bestehende Modelle zur Generierung langer Texte (z.B. BART und GPT-3) immer noch darum, eine kohärente Ereignissequenz im gesamten generierten Text aufrechtzuerhalten. Wir vermuten, dass dies auf die Schwierigkeit des Modells zurückzuführen ist, Teile zu überarbeiten, zu ersetzen, zu widerrufen oder zu löschen, die vom Modell generiert wurden. In diesem Beitrag stellen wir ein neuartiges semi-autoregressives Dokumentengenerationsmodell vor, das in der Lage ist, den generierten Text zu revidieren und zu bearbeiten. Aufbauend auf aktuellen Modellen von (Gu et al., 2019; Xu und Carpuat, 2020) schlagen wir die Dokumentenerzeugung als hierarchischen Markov-Entscheidungsprozess mit einer zweistufigen Hierarchie vor, bei der die Bearbeitung auf hoher und niedriger Ebene erfolgt. Wir trainieren unser Modell anhand von Imitation Learning (Hussein et al., 2017) und führen Roll-in-Politik ein, so dass jede Politik von den Ergebnissen der Anwendung der vorherigen Aktion lernt. Experimente, die den vorgeschlagenen Ansatz anwenden, geben verschiedene Einblicke in die Probleme der langen Textgenerierung mit unserem Modell. Wir schlagen verschiedene Abhilfemaßnahmen vor, wie die Verwendung destillierter Datensätze, die Entwicklung besserer Aufmerksamkeitsmechanismen und die Verwendung autoregressiver Modelle als Low-Level-Programm.</abstract_de>
      <abstract_id>Menjana teks panjang dan konsisten adalah tugas yang penting dan menantang yang meliputi banyak bidang aplikasi seperti ringkasan, penerjemah mesin tingkat dokumen dan generasi cerita. Meskipun sukses dalam modeling koerensi intra-kalimat, model generasi teks panjang yang ada (contohnya, BART dan GPT-3) masih berjuang untuk mempertahankan urutan peristiwa koerenen sepanjang teks yang dibuat. Kami menduga bahwa ini karena kesulitan bagi model untuk mengubah, mengganti, membatalkan atau menghapus setiap bagian yang telah dihasilkan oleh model. Dalam kertas ini, kami mempersembahkan model generasi dokumen semi-autoregresif yang mampu mengubah dan edit teks yang dihasilkan. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs.  Kami melatih model kami menggunakan belajar imitasi (Hussein et al., 2017) dan memperkenalkan kebijakan roll-in sehingga setiap kebijakan belajar tentang hasil dari menerapkan tindakan sebelumnya. Experiments applying the proposed approach sheds various insights on the problems of long text generation using our model.  Kami menyarankan berbagai obat seperti menggunakan set data distil, merancang mekanisme perhatian yang lebih baik dan menggunakan model autoregresif sebagai program tingkat rendah.</abstract_id>
      <abstract_da>Generering af lang og sammenhængende tekst er en vigtig og udfordrende opgave, der omfatter mange anvendelsesområder såsom opsummering, maskinoversættelse på dokumentniveau og historiegenerering. På trods af succesen med at modellere intra-sætning kohærens, eksisterende lange tekstgenereringsmodeller (f.eks. BART og GPT-3) stadig kæmper for at opretholde en sammenhængende begivenhedssekvens i hele den genererede tekst. Vi formoder, at dette skyldes, at modellen har svært ved at revidere, erstatte, tilbagekalde eller slette enhver del, der er genereret af modellen. I denne artikel præsenterer vi en ny semi-autoregressiv dokumentgenerationsmodel, der er i stand til at revidere og redigere den genererede tekst. Med udgangspunkt i de seneste modeller fra (Gu et al., 2019; Xu og Carpuat, 2020) foreslår vi dokumentgenerering som en hierarkisk Markov beslutningsproces med to niveauer hierarki, hvor højt og lavt niveau redigeringsprogrammer. Vi træner vores model ved hjælp af imiteret læring (Hussein et al., 2017) og indfører roll-in politik, således at hver politik lærer om resultatet af anvendelsen af den tidligere handling. Eksperimenter med anvendelse af den foreslåede tilgang giver forskellige indsigter i problemerne med lang tekst generering ved hjælp af vores model. Vi foreslår forskellige løsninger såsom at bruge destilleret datasæt, designe bedre opmærksomhedsmekanismer og bruge autoregressive modeller som et lavt niveau program.</abstract_da>
      <abstract_ko>성장하고 일관된 텍스트는 중요하고 도전적인 임무로 요약, 문서급 기계 번역과 이야기 생성 등 많은 응용 분야와 관련된다.문장 내 연관 모델링에 성공했지만 기존의 긴 텍스트 생성 모델(예를 들어 BART와 GPT-3)은 생성된 텍스트에서 일관된 이벤트 서열을 유지하기 어렵다.우리는 이것이 모델이 생성한 모든 부분을 수정, 교체, 취소하거나 삭제하기 어려웠기 때문이라고 추측한다.본고에서 우리는 새로운 반자귀환 문서 생성 모델을 제시하여 생성된 텍스트를 수정하고 편집할 수 있다.최근의 모델(Gu 등, 2019년, Xu와 Carpuat, 2020년)을 바탕으로 우리는 문서 생성은 두 가지 차원 구조를 가진 차원 마르코프 결정 과정으로 그 중에서 고급과 저급 편집 프로그램이라고 주장했다.우리는 모방 학습(Hussein et al., 2017)을 사용하여 우리의 모델을 훈련시키고 모든 전략이 이전 동작의 출력을 학습할 수 있도록 스크롤 전략을 도입한다.본고가 제시한 방법을 응용하여 진행한 실험은 우리의 모델을 이용하여 성장하는 텍스트 문제에 대한 여러 가지 견해를 제시했다.우리는 추출한 데이터 집합을 사용하고 더 좋은 주의 메커니즘을 설계하며 자귀환 모델을 저급 프로그램으로 사용하는 등 각종 보완 조치를 제시했다.</abstract_ko>
      <abstract_hr>Proizvodnja dugog i usklađenog teksta je važan i izazovan zadatak koji uključuje mnoge područje aplikacije poput sažetka, prevoda strojeva na razini dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli dugog teksta generacije (npr. BART i GPT-3) i dalje se bore za održavanje sklonjene sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela pregledati, zamijeniti, ukloniti ili izbrisati bilo koji dio koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i uredbu proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao proces odluke o hijerarhičkom Markovu s hijerarhijom dvije razine, gdje su programi uredbe visoke i niske razine. Vježbamo naš model s učenjem imitacije (Hussein et al., 2017) i uvodimo politiku koja se uključuje kako svaka politika uči o ishodu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup proizvode različite uvide o problemima duge proizvodnje teksta koristeći naš model. Predlažemo različite lijekove poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</abstract_hr>
      <abstract_sw>Kutengeneza maandishi ya muda mrefu na yenye umuhimu ni jukumu la muhimu na changamoto linalohusu maeneo mengi ya matumizi kama vile muhtasari, tafsiri ya mashine ya nyaraka na kizazi cha habari. Pamoja na mafanikio ya kutengeneza mshikamano wa sentenca, mifano ndefu ya kizazi cha maandishi (kwa mfano, BART na GPT-3) bado wanajitahidi kuendelea kwa mujibu wa tukio la pamoja katika maeneo yote ya maandishi yaliyozaliwa. Tunafikiri kuwa hii ni kwa sababu ya vigumu kwa mtindo wa kurekebisha, kubadilisha, kurudisha au kufuta sehemu yoyote iliyotengenezwa na mtindo. Katika gazeti hili, tunaweka mtandao wa riwaya wa kutengeneza muundo wa nyaraka yenye kudhibiti kujitegemea na uwezo wa kufuatilia na kuhariri ujumbe uliotengenezwa. Kujenga kwenye mifano ya hivi karibuni na (Gu et al., 2019; Xu na Carpuat, 2020) tunapendekeza kizazi cha dokumu kama mchakato wa uamuzi wa Markov wa ngazi mbili, ambapo programu za kuhariri kiwango cha juu na chini za kiwango. Tunamfundisha muundo wetu kwa kutumia kujifunza kwa uchimbaji (Hussein et al., 2017) na kutengeneza sera za ibada kama vile kila sera inajifunza kuhusu matokeo ya kutekeleza hatua zilizopita. Majaribio yanayotumia mbinu zilizopendekezwa yanaonyesha mitazamo mbalimbali kuhusu matatizo ya kizazi chenye maandishi ya ndege kwa kutumia mifano yetu. Tunazipendekeza njia mbalimbali kama vile kutumia seti ya taarifa tofauti, kutengeneza mfumo bora wa kutoa hisia na kutumia mifano ya kujikandamiza kama programu ya chini ya ngazi.</abstract_sw>
      <abstract_tr>Uzun we ýerleşikli metin döretmek wajyp we çykyş täblisaň, bellenen uygulamalar meýdançasyny, desktap düzümleri makine terjime we hekaýa döretmäge mejbur edýär. Çözümler birleşmelerini modellendirmek üçin üstünlik gazanyp hem bolan uzun metin döredilmeleri (meselâ, BART we GPT-3) bar we ýene-de üretilen metin içinde kohereket terjimesini saglamak üçin çöpýärler. Biziň pikirimçe nusga görkezilen, üýtgetmek, tertiblemek ýa çykarmak üçin bu nusga üçin kyndygyny çaklaýarys. Bu kagyzda, biz ýarym-otoregressiv sened bejermek üçin janlaşdyrylýan we düzenleyebilir bir romany görkeýäris. Soňky modellere guruldyk (Gu et al., 2019; Xu we Carpuat, 2020) biz sened döredigini iki düýp iýerarhiýasy bilen iki düýp iýerarhiýa bilen, iýokary we düşük düýpüň editleme programleri bilen teklip edip barýarys. Biz nusganymyzy imitaýýa öwrenmegi ulanyp (Hussein et al., 2017) we her politika öňki hereket etmäge öwrenmegi üçin guruldyrys. Öň teklipden gelen ýagdaýyň tapanyşy örän köp metin döredilişiniň kynçylyklaryny nusgasymyzda çykýar. Biz daşary çykan düzümleri ulanmak ýaly düzümleri taýýarlamak, gowy üns meýdançalaryny tassyklamak we awtomatik regressiv nusgalaryny düşük dereje programy ýaly ulanmak teklip edýäris.</abstract_tr>
      <abstract_af>Skep lank en koerende teks is 'n belangrike en uitgelykbare taak wat versamel baie aansoek gebiede soos opsomming, dokumentvlak masjien vertaling en storie generasie. Terwyl die sukses in die modellering van intra- sentence koherens, bestaande lang teks generasie modele (bv. BART en GPT-3) stoor nog steeds struikel om 'n koherente gebeurtenisvolgorde te hou deur die genereerde teks. Ons verwerp dat dit is vanweë die moeilikheid vir die model om enige deel te hersien, vervang, herhaal of uitvee wat deur die model genereer is. In hierdie papier, voorsien ons 'n roman semi- autoregressiewe dokumentgenerasie model wat moontlik kan hersien en redigeer die genereerde teks. By gebou op onlangse modele deur (Gu et al., 2019; Xu en Carpuat, 2020) voorstel ons dokumentgenerasie as 'n hierarkies Markov besluit proses met 'n twee vlak hierarkie waar die hoë en lae vlak redigeringsprogrammes voorstel. Ons tref ons model deur imitasie leer te gebruik (Hussein et al., 2017) en introduseer rol-in beleid sodat elke beleid leer op die uitvoer van die vorige aksie toepassing. Eksperimente wat die voorgestelde toegang toepassing doen, skep verskeie insigte op die probleme van lang teksgenerasie wat ons model gebruik. Ons stel verskillende herstellings soos die gebruik van verskillende datastel, die ontwerp van beter aandag mekanisme en die gebruik van autoregressiewe modele as 'n lae vlak program.</abstract_af>
      <abstract_sq>Gjenerimi i tekstit të gjatë dhe koherent është një detyrë e rëndësishme dhe sfiduese që përfshin shumë fusha aplikimi të tilla si përmbledhje, përkthimi i makinave në nivel të dokumentit dhe gjenerimi i historive. Pavarësisht nga suksesi në modelimin e koherencës brenda fjalëve, modelet ekzistuese të gjata të gjenerimit të tekstit (për shembull, BART dhe GPT-3) ende luftojnë për të mbajtur një sekuencë koherente ngjarjesh gjatë gjithë tekstit të gjeneruar. Ne supozojmë se kjo është për shkak të vështirësisë për modelin për të revizuar, zëvendësuar, revokuar apo eleminuar çdo pjesë që është gjeneruar nga modeli. Në këtë letër, ne paraqesim një model të ri gjysmë-autoregresiv të gjenerimit të dokumenteve të aftë për të revizuar dhe edituar tekstin e gjeneruar. Duke u ndërtuar në modelet e fundit nga (Gu et al., 2019; Xu dhe Carpuat, 2020) ne propozojmë gjenerimin e dokumenteve si një proces vendimi hierarkik Markov me një hierarki dy niveli, ku programet e ndryshimit të nivelit të lartë dhe të ulët. Ne trajnojmë model in tonë duke përdorur imitimin e mësimit (Hussein et al., 2017) dhe futim politikë të vendosur në mënyrë që çdo politikë të mësojë mbi rezultatin e zbatimit të veprimit të mëparshëm. Eksperimentet që zbatojnë qasjen e propozuar hedhin kuptime të ndryshme mbi problemet e gjenerimit të gjatë të tekstit duke përdorur modelin tonë. Ne sugjerojmë mjete të ndryshme të tilla si përdorimi i grupit të dhënash distilluar, dizajnimi i mekanizmave më të mirë të vëmendjes dhe përdorimi i modeleve autoregressive si një program të nivelit të ulët.</abstract_sq>
      <abstract_am>የረጅም እና የአካባቢ ጽሑፍ መፍጠር ብዙዎችን ፕሮግራሞች ክፍሎች እንደአቀማመጥ፣ የሰነድ ደረጃዎች መተርጓሜ እና ታሪክ ትውልድ የሚያስጨንቅ እና የሚያስቃወም ስራ ነው፡፡ ምንም እንኳን የድል ግንኙነት ማቀናቀል ቢሆንም፣ ረጅም የጽሑፍ ትውልድ አካባቢዎች (ምሳሌ BART እና GPT-3) በተገኘው ጽሑፍ በሙሉ የተደረገ የግንኙነቱን ድርጊት ለመጠበቅ ይታገላሉ፡፡ We conjecture that this is because of the difficulty for the model to revise, replace, revoke or delete any part that has been generated by the model.  በዚህ ገጽ ውስጥ የተፈጠረውን ጽሑፍ ማቀናቀል እና ማስተካክል የሚችል የሰነድ ትውልድ ምሳሌ እናቀርባለን፡፡ አዲስ ዓይነቶች (Gu et al., 2019; Xu እና ካርፉት, 2020) በመሠረት ላይ የሰነድ ትውልድ በሁለት ደረጃዎች ማርኮov ፍርድ ክፍል እና ከፍተኛ እና ታናሹ ፕሮግራሙቶችን ማቀናጃ ፕሮግራም እና ዋናው፡፡ ሞዴሌዎቻችንን በመግለጽ ትምህርት በማድረግ እናስተምረዋለን (Hussein et 2017) እና ሁሉም ፖሊሲ በተቀድሞው ሥራ ለመጠቀም የሚችሉትን የፖሊሲ ውጤት እንዲያስተምረናል፡፡ በተዘጋጀው የጽሑፍ ትውልድ በመጠቀም የረጅም የጽሑፍ ትውልድ ጉዳዮች ላይ የልዩ አሳብ ያሳያል፡፡ የተለየ የዳታ ሰርቨሮች፣ የበለጠ ማስታወቂያውን እና የራሳቸውን ሥልጣን ምሳሌዎችን እንደ ዝቅተኛ ደረጃ ፕሮግራም በመጠቀም እናስባለን፡፡</abstract_am>
      <abstract_hy>Երկար և համապատասխան տեքստի ստեղծելը կարևոր և դժվար խնդիր է, որը ներառում է շատ ծրագրերի ոլորտներ, ինչպիսիք են համառոտագրությունը, փաստաթղթի մակարդակի մեքենային թարգմանությունը և պատմությունների ստեղծ Չնայած ներս նախադասությունների կոնցենսիայի մոդելավորման հաջողությանը, գոյություն ունի երկար տեքստի ստեղծման մոդելներ (օրինակ, BAR և GPT-3), որոնք դեռևս պահպանում են կոնցենսիվ իրադարձությունների հաջորդականությունը ստեղծված Մենք ենթադրում ենք, որ սա այն պատճառով է, որ մոդելը բարդ է վերանայել, փոխարինել, վերանայել կամ ջնջել մոդելի կողմից ստեղծված ցանկացած մասը: Այս թղթի մեջ մենք ներկայացնում ենք մի նոր կիսա-ավտոգրեսիվ փաստաթղթի ստեղծման մոդել, որը կարողանում է վերանայել և խմբագրել ստեղծված տեքստը: Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs.  Մենք ուսուցանում ենք մեր մոդելը՝ օգտագործելով կրկնօրինակման ուսումնասիրությունը (Հուսեյնը և այլն., 2017 թ․-ը) և ներկայացնում ենք այնպիսի քաղաքականություն, որ յուրաքանչյուր քաղաքականություն սովորի նախորդ գործողության կիրառման Փորձերը, որոնք օգտագործում են նախագծված մոտեցումը, տարբեր տեսանկյուններ են տալիս երկար տեքստի սերունդների խնդիրների մասին, օգտագործելով մեր մոդելը: Մենք առաջարկում ենք տարբեր բուժման միջոցներ, ինչպիսիք են՝ օգտագործելը դիսլիլացված տվյալների համակարգը, ավելի լավ ուշադրության մեխանիզմներ ստեղծելը և օգտագործելը ինքնագրեսիվ մոդելներ որպես ցածր մա</abstract_hy>
      <abstract_fa>پیدا کردن متن طولانی و هماهنگی یک کار مهم و سخت‌گیری است که شامل بسیاری از منطقه‌های کاربرد مانند جمع کردن، ترجمه‌های دستگاه سطح سند و نسل داستان است. با وجود موفقیت در مدل‌سازی هماهنگی داخل جمله، مدل‌های نسل متن طولانی وجود دارد (مثال BART و GPT-3) هنوز برای نگه داشتن یک رده‌ی اتفاق هماهنگی در تمام متن تولید می‌کنند. ما تصور می‌کنیم که این به دلیل مشکلی برای مدل است که هر بخشی که توسط مدل تولید شده است تغییر دهد، جایگزین، باز کند یا پاک کند. در این کاغذ، ما یک مدل نسل سند semi-autoregressive را نشان می دهیم که قادر به تغییر و ویرایش متن تولید شده است. بر روی مدل های اخیر توسط (Gu et al., 2019; Xu and Carpuat, 2020) ما نسل سند را به عنوان یک فرایند تصمیم گرفتن قانونی مارکوف با یک قانونی دو سطح پیشنهاد می‌کنیم که برنامه‌های ویرایش سطح بالا و پایین است. ما مدل خود را با استفاده از یادگیری تصویر (Hussein et al., 2017) آموزش می‌دهیم و سیاست‌های داخلی را معرفی می‌کنیم که هر سیاست در نتیجه کارهای قبلی یاد می‌گیرد. تجربه‌هایی که با استفاده از دستور پیشنهاد می‌گیرند، مشاهده‌های مختلف در مورد مشکلات نسل متن طولانی با استفاده از مدل ما می‌کند. ما پیشنهاد می‌کنیم داروهای متفاوتی مثل استفاده از مجموعه داده‌های متفاوت، طراحی مکانیسم توجه بهتر و استفاده از مدل‌های خودگریزی به عنوان برنامه‌ی سطح پایین استفاده کنیم.</abstract_fa>
      <abstract_az>Uzun və müvafiq metinləri yaratmaq möhüm və çətin bir görevdir ki, çoxlu uyğulama bölgeleri, məlumat seviyyəti maşına çevirilməsi və hekayə nəzəriyyəti kimi məlumatdır. İçin cümlələrin birləşməsi modellərində başarılı olmasına rağmen, mövcud uzun mətn nəsli modelləri (bəzisi, BART və GPT-3) yaratdığı mətn boyunca birləşmiş bir vaxt sequencesini qorumaq üçün mübahisə edirlər. Bu modeli yenidən dəyişdirmək, əvəz etmək, təkrar etmək və ya silmək üçün çətindir. Bu kağızda, biz yaratdığı mətn yenidən dəyişdirmək və düzəltmək mümkün olaraq yeni yarı-autoregressiv döküm nəsili modelini göstəririk. Son modellərə inşa edirik (Gu et al., 2019; Xu və Carpuat, 2020; tərəfindən, hörarşik Markov hökmü prosesi olaraq, yüksək və düşük səviyyə düzəltmə proqramları olan iki səviyyə hierarhiyəsi ilə, hörarşik bir Markov hökmü prosesi olaraq). Biz modellərimizi imitasyon öyrənməyi (Hussein et al., 2017) ilə təhsil edirik və hər siyasət əvvəlki eylemlərin istifadə etməsini öyrənir. Önülləşdirilmiş təcrübələrin uygulaması modelimizi istifadə edərək uzun mətn nəsillərinin problemlərinə müxtəlif fikirləri çəkir. Biz destilmiş veri qutusu istifadə etmək, daha yaxşı dikkati mehānismi tasarlamaq və düşük seviyyət program ı olaraq autoregressiv modelləri istifadə etmək kimi müxtəlif dəyişiklikləri təbliğ edirik.</abstract_az>
      <abstract_bs>Proizvodnja dugog i saslušnog teksta je važan i izazovni zadatak koji uključuje mnoge oblasti aplikacije poput sažetke, prevode strojeva na nivou dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli generacije dugog teksta (npr. BART i GPT-3) i dalje se bore za održavanje sklonjene sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela pregledati, zamijeniti, ukloniti ili izbrisati bilo koji dio koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i editiranje proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao proces odluke o hijerarhičkom Markovu sa hijerarhijom dva nivoa, gdje su programi za editiranje visokog i niskog nivoa. Vježbamo svoj model koristeći učenje imitacije (Hussein et al., 2017) i predstavljamo politiku koja se uključuje kako svaka politika uči o izlazu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup proizvode različite uvide o problemima duge generacije teksta koristeći naš model. Predlažemo raznim sredstvima za opremu poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</abstract_bs>
      <abstract_et>Pika ja sidusa teksti loomine on oluline ja keeruline ülesanne, mis hõlmab paljusid rakendusvaldkondi, nagu kokkuvõte, dokumenditasemel masintõlge ja lugude loomine. Vaatamata lausesisese sidususe modelleerimise edule on olemasolevatel pika teksti genereerimise mudelitel (nt BART ja GPT-3) endiselt raske säilitada ühtne sündmuste jada kogu genereeritud teksti ulatuses. Eeldame, et see on tingitud mudeli raskustest muuta, asendada, tühistada või kustutada mis tahes mudeli loodud osa. Käesolevas töös tutvustame uudset poolaurregressiivset dokumentide genereerimise mudelit, mis suudab genereeritud teksti muuta ja redigeerida. Tuginedes hiljutistele mudelitele (Gu et al., 2019; Xu ja Carpuat, 2020) pakume välja dokumentide genereerimise kui hierarhilise Markovi otsustamisprotsessi kahetasandilise hierarhiaga, kus kõrge ja madala taseme redigeerimisprogrammid. Koolitame oma mudelit imitatsiooniõppe abil (Hussein jt., 2017) ja võtame kasutusele roll-in poliitika nii, et iga poliitika õpib eelmise meetme rakendamise tulemusi. Kavandatud lähenemisviisi rakendamise katsed annavad erinevaid ülevaateid pika teksti genereerimise probleemidest meie mudeli abil. Soovitame erinevaid abinõusid, nagu destilleeritud andmekogumi kasutamine, paremate tähelepanumehhanismide kujundamine ja autoregressiivsete mudelite kasutamine madala taseme programmina.</abstract_et>
      <abstract_fi>Pitkän ja johdonmukaisen tekstin luominen on tärkeä ja haastava tehtävä, joka kattaa monia sovellusalueita, kuten tiivistelmän, dokumenttitason konekäännöksen ja tarinan tuottamisen. Vaikka lauseidensisäisten koherenssien mallintaminen onnistui, olemassa olevat pitkän tekstintuotannon mallit (esim. BART ja GPT-3) kamppailevat edelleen johdonmukaisen tapahtumajärjestyksen ylläpitämiseksi koko luodussa tekstissä. Arvelemme, että tämä johtuu siitä, että mallin on vaikea tarkistaa, korvata, peruuttaa tai poistaa mitään mallin luomaa osaa. Tässä työssä esitellään uusi puoliautoregressiivinen dokumenttien generointimalli, joka pystyy tarkistamaan ja muokkaamaan luotua tekstiä. Uusien mallien pohjalta (Gu et al., 2019; Xu ja Carpuat, 2020) ehdotamme dokumenttien luomista hierarkkisena Markovin päätöksentekoprosessina kaksitasoisella hierarkialla, jossa korkean ja matalan tason editointiohjelmat. Koulutamme mallimme jäljitelmäoppimisen avulla (Hussein et al., 2017) ja otamme käyttöön roll-in-politiikan siten, että jokainen politiikka oppii aiemman toimen soveltamisen tuotokset. Ehdotettua lähestymistapaa soveltavat kokeilut tuovat erilaisia näkemyksiä pitkän tekstin tuottamisen ongelmista mallimme avulla. Ehdotamme erilaisia korjaustoimenpiteitä, kuten tislatun datajoukon käyttöä, parempien huomiomekanismien suunnittelua ja autoregressiivisten mallien käyttöä matalatasoisena ohjelmana.</abstract_fi>
      <abstract_bn>Generating long and coherent text is an important and challenging task encompassing many application areas such as summarization, document level machine translation and story generation.  প্রজাতির প্রজন্ম মডেল করার সাফল্য সত্ত্বেও বিদীর্ঘ টেক্সট প্রজন্ম মডেল (উদাহরণস্বরূপ বার্টি এবং জিপিটি-৩) সারা জুড়ে তৈরি করা টেক্সটের সাথে  আমরা ধারণা করছি যে মডেলের কারণে মডেলের কোন অংশ পরিবর্তন, প্রতিস্থাপন, বাতিল করা অথবা মুছে ফেলার জন্য কঠিন। এই কাগজটিতে আমরা একটি নোভেল স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে নথিপত্রের প্রজন্ম মডেল উপস্থাপন করি যা তৈরি করা লেখা পরি সাম্প্রতিক মডেলে (গু et al., 2019; জু এবং ক্যার্পুয়াট, ২০২০) নির্মাণ করে আমরা নথিপত্রের প্রজন্ম হিয়ারেরাক্কিল মার্কোভ সিদ্ধান্ত নির্মাণের প্রস্তাব করছি যেখ আমরা আমাদের মডেল শিক্ষা প্রশিক্ষণ করি (হুসেন এন্ট ২০১৭) ব্যবহার করে এবং রোল-ইন নীতি পরিচালনা করি যেমন প্রত্যেক নীতি পূর্ববর্তী কাজের আউটপ প্রস্তাবিত পদ্ধতি প্রয়োগ করার পরীক্ষা আমাদের মডেল ব্যবহার করে দীর্ঘ লেখা প্রজন্মের সমস্যার বিভিন্ন দৃষ্টিভ আমরা বিভিন্ন প্রতিক্রিয়া পরামর্শ দিচ্ছি যেমন বিচ্ছিন্ন তথ্য সেট ব্যবহার করে, ভালো মনোযোগ মেকানিস্টেম এবং স্বয়ংক্রিয় স্</abstract_bn>
      <abstract_ca>generar un text llarg i coherent és una tasca important i desafiadora que inclou moltes àrees d'aplicació com la somària, la traducció màquina a nivell de documentos i la generació de històries. Malgrat l'èxit en la modelació de la coherencia intrafrases, els models existents de generació de text llarg (per exemple, BART i GPT-3) encara lluiten per mantenir una seqüència coherent d'eventos a través del text generat. Suposem que això és degut a la dificultat del model de revisar, substituir, revocar o eliminar qualsevol part que ha estat generada pel model. En aquest article presentem un nou model de generació semi-autoregressiu capaç de revisar i editar el text generat. Construïnt en models recents de (Gu et al., 2019; Xu i Carpuat, 2020) proposem la generació de documents com un procés de decisió jeràrquic Markov amb una jerarquia de dos nivells, on els programes d'edició de alt i baix nivell. Ensenyem el nostre model fent servir l'aprenentatge de imitació (Hussein et al., 2017) i introduïm una política d'introducció de tal manera que cada política aprengui sobre el resultat d'aplicar l'acció anterior. Els experiments que aplican l'enfocament proposat revelen diversos aspectes sobre els problemes de la llarga generació de text utilitzant el nostre model. Sugirem diversos recursos, com l'ús de conjunt de dades destilats, el disseny de mecanismes d'atenció millors i l'ús de models autoregressius com un program a de baix nivell.</abstract_ca>
      <abstract_cs>Generování dlouhého a soudržného textu je důležitým a náročným úkolem zahrnujícím mnoho oblastí aplikace, jako je shrnutí, strojový překlad dokumentů a generování příběhů. Navzdory úspěchu v modelování koherence uvnitř věty stále probíhají existující modely generace dlouhého textu (např. BART a GPT-3) s udržením koherentní sekvence událostí v generovaném textu. Domníváme se, že je to kvůli obtížnosti modelu revidovat, nahradit, zrušit nebo smazat jakoukoliv část, která byla vygenerována modelem. V tomto článku představujeme nový model semi-autoregresivní generace dokumentů schopný revidovat a editovat generovaný text. Na základě nejnovějších modelů (Gu et al., 2019; Xu a Carpuat, 2020) navrhujeme generování dokumentů jako hierarchický Markovský rozhodovací proces se dvouúrovňovou hierarchií, kde editační programy vysoké a nízké úrovně programují. Náš model trénujeme pomocí imitačního učení (Hussein et al., 2017) a zavádíme roll-in politiku tak, aby se každá politika učila o výstupu uplatnění předchozí akce. Experimenty aplikující navržený přístup přinášejí různé pohledy na problémy generování dlouhého textu pomocí našeho modelu. Navrhujeme různé prostředky jako například použití destilované datové sady, navrhování lepších mechanismů pozornosti a použití autoregresivních modelů jako programu nízké úrovně.</abstract_cs>
      <abstract_jv>Jejaring Ngawe ngupakane seneng nglanggar sampeyan ingkang sampeyan-seneng kawelan, model sing langgar teks oleh dumateng (adil. Balt karo Gpta-3) kang isih nguasai nglanggar sampeyan operasi sing berarti secanse sampeyan nggo ndelok teks oluyo. Awak dhéwé ngerasai iki ngono hal-hal susahe kanggo model nggunakake Nang pemilih iki, kita sembaran model sing sembaran autoRegresno dokumen sing bisa ngubah banjure ngubah lan ngubah teks Generation Gu et al, 2011; Xu lan carpuat, 2020) awak dhéwé nggawe dokumen nganggep sistem anu sakjane perbudhakan karo siji-perbudhakan bakal kelas iki sakjane sampek deweke sampek, ndéwé kuwi wis ana sakjane perusahaan mat ambalo sakjane program. Awakdhéwé éntuk model nambah imitasi nggawe sistem imitasi (Herseyen et al, 1997) lan nganggep nggawe dolanan politik sing berarti segala kejahatan winih sing lembane nggawe barang sistem sing lembane nggawe aksi sing berarti. Gebudhakan langkung nggunakaé diangkat nggawe barang sampeyan urip kuwi nggawe pertualangan tentang kanggo nggawe modèl. Awak dhéwé suggerén akeh barêng-barêng lagi koyo gampang dataset wis disenyongno, nggawe mekanimat sing luwih nggawe sistem sing luwih nêmên karo sistem autoRegresor sing model nang program sing di ambang.</abstract_jv>
      <abstract_ha>Mai ƙãga matsayin kwanan da aka ƙunsa, yana da wani aikin mai muhimu da mai gaura wanda ke ƙunsa da wasu area na shiryoyin ayuka kamar tsorori, fassarar maɓallin zane da kizafi. Babu da cin nasara a sami-danna-ɗabi'a, yana ƙari motel masu ƙari na matsayi (misali, BArT da GPT-3) don ka sami tsari wani sequence na haɗi cikin matsayin da aka ƙãga. Tuna zaton cewa wannan yana da tsanani wa misali da za'a canza, kuma ka bada, ka sake, ko kuma ka goge wani abu wanda aka gina shi na motel. Ga wannan takardan, muna halatar da wata shekara na takardar da ke iya iya canza kure da taƙaita matsayin da aka ƙãga. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs.  Tuna sanar da misalinmu da za'a yi amfani da in karanta surori (Hussein et al., 2017) kuma mu ƙarfafa lissafar rubutu kamar yadda kowane siyafar za'a sani a kan zartar da aikin da ya gabatar. Tajarakin da ke amfani da mazaɓan da aka buƙata, yana nuna masu basĩri masu cikin masu matsayin kiyãyen matsayi tsawo da misalinmu. Tuna shawarar da wasu mutane kamar misãlai da za'a yi amfani da tsarin danne da aka rarraba, ana ƙayyade masu amfani da shiryoyin muhalli masu amfani da shiryoyin ayuka da farat-regressive kamar wata shirin wuri mai ƙas ƙanci.</abstract_ha>
      <abstract_sk>Ustvarjanje dolgega in koherentnega besedila je pomembna in zahtevna naloga, ki zajema številna področja uporabe, kot so povzetek, strojno prevajanje dokumentov in ustvarjanje zgodb. Kljub uspehu pri modeliranju koherence znotraj stavka obstoječi modeli dolge generacije besedila (npr. BART in GPT-3) še vedno težko ohranjajo skladno zaporedje dogodkov v celotnem ustvarjenem besedilu. Domnevamo, da je to zaradi težav, ki jih model ustvari, spremeni, prekliče ali izbriše. V prispevku predstavljamo nov pol-avtoregresivni model generiranja dokumentov, ki lahko revidira in ureja ustvarjeno besedilo. Na podlagi novejših modelov (Gu et al., 2019; Xu in Carpuat, 2020) predlagamo ustvarjanje dokumentov kot hierarhični Markov proces odločanja z dvostopenjsko hierarhijo, kjer so programi urejanja na visoki in nizki ravni. Naš model usposabljamo z uporabo imitacijskega učenja (Hussein et al., 2017) in uvajamo politiko roll-in, tako da se vsaka politika nauči o rezultatih uporabe prejšnjega ukrepa. Eksperimenti, ki uporabljajo predlagani pristop, dajejo različne vpoglede na probleme dolge oblikovanje besedila z uporabo našega modela. Predlagamo različna sredstva, kot so uporaba destiliranega nabora podatkov, oblikovanje boljših mehanizmov pozornosti in uporaba avtoregresivnih modelov kot nizko raven programa.</abstract_sk>
      <abstract_he>יצירת טקסט ארוך ותקביל היא משימה חשובה ומתאגרת שמכילה אזורי שימוש רבים כמו הסכם, תרגום מכונות רמה מסמכים ודור סיפורים. למרות ההצלחה בהדגמה בתוך המשפט, דוגמנים של דוגמנים של דוגמנים של דוגמנים ארוכים (למשל BART וג'י.פי.טי. אנו מניחים שזה בגלל הקשה למודל לשנות, להחליף, לבטל או למחוק כל חלק שנוצר על ידי המודל. בעיתון הזה, אנחנו מציגים מודל דוגמא של דוגמא של דוגמא חצי-אוטורגרסיבי מסוגל לשנות ולהעורר את הטקסט המיוצר. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs.  We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action.  ניסויים בהשתמשת הגישה המוצעת משפיעים תובנות שונות על הבעיות של דור טקסט ארוך באמצעות הדוגמא שלנו. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</abstract_he>
      <abstract_bo>ཉེར་སྤྱོད་རིང དབྱེ་རིམ་འདིའི་ནང་གི་ཚིག ང་ཚོས་མིག་འཆར་བྱས་ན། མ་དབྱིབས་བཟོ་བཅོས་བྱེད་པར་དཀའ་ངལ་པོ་ཞིག་ཡིན་པ་རྟོགས། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཚོའི་དུས་ཡིག་ཆ་ལུས་རང་འགུལ་གྱི་ཡིག Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. ང་ཚོའི་མ་དབུགས་ལ་imitation learning་སྤྱད་ནས་ང་ཚོའི་ཐབས་ལམ་སྟོན་བྱེད་ཀྱི་ཡོད། ལག་ལེན་བྱེད་པའི་སྔོན་སྒྲིག་གི་ཐབས་ལམ་ལ་ལག་ལེན་འཐབ་པའི་སྣེ་ཚོགས་རྣམས་ལ་མཐོང་ནུས་མེད་པའི་མིག་རྣམས་ ང་ཚོས་རང་ཉིད་ཀྱི་ཆེད་དུ་བཅུག་ཐབས་མེད་པར། དཔེར་ན་གསལ་བཤད་ཀྱི་གནད་སྡུད་ཇུས་གཏོང་བའི་ཐབས་ལམ་ལ་ཇེ་གསལ་བཀལ་བ་དང</abstract_bo>
      </paper>
    <paper id="15">
      <title>Generating and Modifying Natural Language Explanations</title>
      <author><first>Abdus</first><last>Salam</last></author>
      <author><first>Rolf</first><last>Schwitter</last></author>
      <author><first>Mehmet</first><last>Orgun</last></author>
      <pages>149–157</pages>
      <abstract>HESIP is a hybrid explanation system for image predictions that combines sub-symbolic and symbolic machine learning techniques to explain the predictions of image classification tasks. The sub-symbolic component makes a prediction for an image and the symbolic component learns probabilistic symbolic rules in order to explain that prediction. In HESIP, the explanations are generated in <a href="https://en.wikipedia.org/wiki/Controlled_natural_language">controlled natural language</a> from the learned probabilistic rules using a bi-directional logic grammar. In this paper, we present an explanation modification method where a <a href="https://en.wikipedia.org/wiki/Human-in-the-loop">human-in-the-loop</a> can modify an incorrect explanation generated by the <a href="https://en.wikipedia.org/wiki/Human-in-the-loop">HESIP system</a> and afterwards, the modified explanation is used by <a href="https://en.wikipedia.org/wiki/Human-in-the-loop">HESIP</a> to learn a better explanation.</abstract>
      <url hash="7c0f4eb1">2021.alta-1.15</url>
      <bibkey>salam-etal-2021-generating</bibkey>
    </paper>
    <paper id="25">
      <title>An Ensemble Model for Automatic Grading of Evidence</title>
      <author><first>Yuting</first><last>Guo</last></author>
      <author><first>Yao</first><last>Ge</last></author>
      <author><first>Ruqi</first><last>Liao</last></author>
      <author><first>Abeed</first><last>Sarker</last></author>
      <pages>213–217</pages>
      <abstract>This paper describes our approach for the automatic grading of evidence task from the Australasian Language Technology Association (ALTA) Shared Task 2021. We developed two classification models with SVM and RoBERTa and applied an <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble technique</a> to combine the grades from different <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a>. Our results showed that the <a href="https://en.wikipedia.org/wiki/Statistical_model">SVM model</a> achieved comparable results to the RoBERTa model, and the <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble system</a> outperformed the individual models on this task. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved the first place among five teams and obtained 3.3 % higher <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> than the second place.</abstract>
      <url hash="e92e5658">2021.alta-1.25</url>
      <bibkey>guo-etal-2021-ensemble</bibkey>
    </paper>
    </volume>
</collection>