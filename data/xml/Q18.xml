<?xml version='1.0' encoding='utf-8'?>
<collection id="Q18">
  <volume id="1">
    <meta>
      <booktitle>Transactions of the Association for Computational Linguistics, Volume 6</booktitle>
      <editor><last>Lee</last><first>Lillian</first></editor>
      <editor><last>Johnson</last><first>Mark</first></editor>
      <editor><last>Toutanova</last><first>Kristina</first></editor>
      <editor><last>Roark</last><first>Brian</first></editor>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <year>2018</year>
    </meta>
    <frontmatter>
      <bibkey>tacl-2018-transactions</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Whodunnit? Crime Drama as a Case for Natural Language Understanding</title>
      <author><first>Lea</first><last>Frermann</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <doi>10.1162/tacl_a_00001</doi>
      <abstract>In this paper we argue that <a href="https://en.wikipedia.org/wiki/Crime_film">crime drama</a> exemplified in television programs such as CSI : Crime Scene Investigation is an ideal testbed for approximating real-world natural language understanding and the complex inferences associated with it. We propose to treat <a href="https://en.wikipedia.org/wiki/Crime_film">crime drama</a> as a new inference task, capitalizing on the fact that each episode poses the same basic question (i.e., who committed the crime) and naturally provides the answer when the perpetrator is revealed. We develop a new dataset based on CSI episodes, formalize perpetrator identification as a sequence labeling problem, and develop an LSTM-based model which learns from multi-modal data. Experimental results show that an incremental inference strategy is key to making accurate guesses as well as learning from representations fusing textual, visual, and acoustic input.</abstract>
      <pages>1–15</pages>
      <url hash="297b5f86">Q18-1001</url>
      <video href="https://vimeo.com/285805531" />
      <bibkey>frermann-etal-2018-whodunnit</bibkey>
      <pwccode url="https://github.com/EdinburghNLP/csi-corpus" additional="false">EdinburghNLP/csi-corpus</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/movieqa">MovieQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    <title_ar>Whodunnit؟ دراما الجريمة كحالة لفهم اللغة الطبيعية</title_ar>
      <title_pt>Quem foi? Drama de crime como um caso para a compreensão da linguagem natural</title_pt>
      <title_fr>Qui l'a fait ? Le drame policier comme argument pour la compréhension du langage naturel</title_fr>
      <title_es>¿Quién no lo sabe? El drama criminal como caso para la comprensión del lenguaje natural</title_es>
      <title_ja>自然言語を理解するためのケースとしての犯罪ドラマ</title_ja>
      <title_zh>谁? 犯罪剧为自然语言解例</title_zh>
      <title_ru>Криминальная драма как пример понимания естественного языка</title_ru>
      <title_hi>Whodunnit? प्राकृतिक भाषा की समझ के लिए एक मामले के रूप में अपराध नाटक</title_hi>
      <title_ga>Cé leis? Dráma Coireachta mar Chás do Thuiscint Teanga Nádúrtha</title_ga>
      <title_ka>კჲი ეყნნთრ? Crime Drama as a Case for Natural Language Understanding</title_ka>
      <title_hu>Ki tudnit? A bűnügyi dráma mint a természetes nyelv megértésének esete</title_hu>
      <title_kk>Кідіннит? Тәуелді тілді түсініктіру үшін Crime Drama</title_kk>
      <title_lt>Kas? Nusikaltimo drama kaip natūralaus kalbos supratimo atvejis</title_lt>
      <title_ms>Siapa? Drama jenayah sebagai kes untuk Pemahaman Bahasa Alami</title_ms>
      <title_el>Ποιος ξέρει; Το δράμα του εγκλήματος ως υπόθεση για την κατανόηση της φυσικής γλώσσας</title_el>
      <title_ml>വുഡുനിറ്റ്? സാധാരണ ഭാഷയ്ക്കുള്ള വിവരങ്ങള്‍</title_ml>
      <title_it>Chi dunnit? Il dramma del crimine come caso per la comprensione del linguaggio naturale</title_it>
      <title_mk>Кој? Криминалната драма како случај за разбирање на природниот јазик</title_mk>
      <title_pl>Kto nie wie? Drama zbrodni jako przypadek zrozumienia języka naturalnego</title_pl>
      <title_mt>Whodunnit? Crime Drama as a Case for Natural Language Understanding</title_mt>
      <title_ro>Cinedunnit? Drama crimei ca un caz pentru înțelegerea limbajului natural</title_ro>
      <title_mn>Хэн хэн? Байгалийн хэл ойлголтын тухай</title_mn>
      <title_sr>Ko je to? Crime Drama kao slučaj prirodnog razumevanja jezika</title_sr>
      <title_no>Hvor dunnit? Crime Drama som tilfelle for naturspråk forståking</title_no>
      <title_si>කවුද දුන්නිට්? ස්වභාවික භාෂාව තේරුම්ගන්න ප්‍රශ්නයක් වගේ</title_si>
      <title_sv>Vem dunnit? Brottsdrama som ett fall för förståelse av naturligt språk</title_sv>
      <title_so>Whodunnit? Crime Drama sida xaalad loogu talagalay afka asalka ah</title_so>
      <title_ta>Whodunnit? இயல்பான மொழிக்கு புரிந்து கொள்ளும் குற்றம் Drama</title_ta>
      <title_ur>کون دن؟ Crime Drama as a Case for Natural Language Understanding</title_ur>
      <title_uz>Whodunnit? Name</title_uz>
      <title_vi>Không. Tội ác kịch là nguyên nhân hiểu biết ngôn ngữ tự nhiên</title_vi>
      <title_hr>Koji dunnit? Drama zločina kao slučaj prirodnog razumijevanja jezika</title_hr>
      <title_bg>Кой знае? Престъпната драма като случай за разбиране на естествения език</title_bg>
      <title_da>Hvem dunnit? Kriminalitet Drama som en sag for natursprogforståelse</title_da>
      <title_nl>Wie weet het? Criminaliteitsdrama als een zaak voor het begrijpen van natuurlijke taal</title_nl>
      <title_id>Siapa? Drama kejahatan sebagai kasus untuk Pemahaman Bahasa Alami</title_id>
      <title_de>Wer weiß nicht? Kriminaldrama als Fall für das Verständnis natürlicher Sprache</title_de>
      <title_ko>누가 알겠는가?자연 언어 이해 사례로서의 범죄극</title_ko>
      <title_fa>کي دانت؟ دراما جنایت به عنوان پرونده درک زبان طبیعی</title_fa>
      <title_sw>Yudunnit? Makosa ya Drama kama kesi kwa lugha ya asili</title_sw>
      <title_sq>Kush? Drama e krimit si një rast për kuptimin e gjuhës natyrore</title_sq>
      <title_am>ቡዱኒት? የኀጢአት መዝገብ የዘርፍ ቋንቋ ማስተዋል</title_am>
      <title_tr>Kim dunnit? Tebiýal dil düşünmesi üçin bir hasapla</title_tr>
      <title_af>Wie dunnit? Krime Drama as 'n Kas vir Natuurlike Taal Verstaan</title_af>
      <title_hy>Ո՞վ է: Բնական լեզվի հասկանալու դեպքում հանցագործությունը</title_hy>
      <title_bs>Ko je to? Crime Drama kao slučaj prirodnog razumijevanja jezika</title_bs>
      <title_az>Kim dunnit? T…Щbi…Щtli dil anlama olaraq Crime Drama</title_az>
      <title_bn>ওদুনিট? প্রাকৃতিক ভাষার বুঝতে অপরাধ ড্রামা হিসেবে মামলা</title_bn>
      <title_ca>Qui no? El Drama del Crime com un cas de comprensió del llenguatge natural</title_ca>
      <title_et>Kes ei tea? Kuritegevuse draama kui loodusliku keele mõistmise juhtum</title_et>
      <title_cs>Kdo neví? Kriminální drama jako případ pro porozumění přirozenému jazyku</title_cs>
      <title_fi>Kuka tietää? Rikosdraama luonnollisen kielen ymmärtämisen tukena</title_fi>
      <title_he>מי? Crime Drama as a Case for Natural Language Understanding</title_he>
      <title_bo>ཝེ་ཌིན་ནི་ཡིན་ནམ། འཆམ་གཞུང་གི་སྐད་རིགས་ལ་རྟོགས་པའི་སྣང་ཚུལ་ཞིག་དང་།</title_bo>
      <title_jv>Piye dunit ? Drama Pengan Kemerdekaan kanggo Kemerdekaan kanggo ngerasahan</title_jv>
      <title_ha>QUnicodeControlCharacterMenu KCharselect unicode block name</title_ha>
      <title_sk>Kdo ne ve? Drama kriminala kot primer za razumevanje naravnega jezika</title_sk>
      <abstract_ar>في هذه الورقة ، نجادل في أن الدراما الإجرامية المتمثلة في البرامج التلفزيونية مثل CSI: Crime Scene Investigation هي اختبار مثالي لتقريب فهم اللغة الطبيعية في العالم الحقيقي والاستنتاجات المعقدة المرتبطة بها. نقترح التعامل مع الدراما الإجرامية كمهمة استدلال جديدة ، مع الاستفادة من حقيقة أن كل حلقة تطرح نفس السؤال الأساسي (أي ، من ارتكب الجريمة) وتوفر الإجابة بشكل طبيعي عند الكشف عن الجاني. نقوم بتطوير مجموعة بيانات جديدة بناءً على حلقات CSI ، وإضفاء الطابع الرسمي على تحديد الجاني كمشكلة تسمية تسلسل ، وتطوير نموذج قائم على LSTM يتعلم من البيانات متعددة الوسائط. تظهر النتائج التجريبية أن استراتيجية الاستدلال التدريجي هي المفتاح لعمل تخمينات دقيقة بالإضافة إلى التعلم من التمثيلات التي تدمج المدخلات النصية والمرئية والصوتية.</abstract_ar>
      <abstract_pt>Neste artigo, argumentamos que o drama criminal exemplificado em programas de televisão como CSI: Crime Scene Investigation é um teste ideal para aproximar a compreensão da linguagem natural do mundo real e as inferências complexas associadas a ela. Propomos tratar o drama do crime como uma nova tarefa de inferência, aproveitando o fato de que cada episódio coloca a mesma questão básica (ou seja, quem cometeu o crime) e, naturalmente, fornece a resposta quando o agressor é revelado. Desenvolvemos um novo conjunto de dados baseado em episódios CSI, formalizamos a identificação do agressor como um problema de rotulagem de sequência e desenvolvemos um modelo baseado em LSTM que aprende com dados multimodais. Os resultados experimentais mostram que uma estratégia de inferência incremental é a chave para fazer suposições precisas, bem como aprender com representações que fundem entradas textuais, visuais e acústicas.</abstract_pt>
      <abstract_es>En este artículo argumentamos que el drama criminal ejemplificado en programas de televisión como CSI: Crime Scene Investigation es un banco de pruebas ideal para aproximar la comprensión del lenguaje natural del mundo real y las complejas inferencias asociadas con él. Proponemos tratar el drama criminal como una nueva tarea de inferencia, capitalizando el hecho de que cada episodio plantea la misma pregunta básica (es decir, quién cometió el crimen) y, naturalmente, proporciona la respuesta cuando se revela al autor. Desarrollamos un nuevo conjunto de datos basado en episodios de CSI, formalizamos la identificación del agresor como un problema de etiquetado de secuencias y desarrollamos un modelo basado en LSTM que aprende de datos multimodales. Los resultados experimentales muestran que una estrategia de inferencia incremental es clave para hacer conjeturas precisas, así como para aprender de representaciones que fusionan entradas textuales, visuales y acústicas.</abstract_es>
      <abstract_fr>Dans cet article, nous soutenons que les dramatiques criminelles illustrées dans des émissions de télévision telles que CSI : Crime Scene Investigation constituent un banc d'essai idéal pour approcher la compréhension du langage naturel dans le monde réel et les inférences complexes qui y sont associées. Nous proposons de traiter le drame criminel comme une nouvelle tâche d'inférence, en capitalisant sur le fait que chaque épisode pose la même question fondamentale (c'est-à-dire qui a commis le crime) et fournit naturellement la réponse lorsque l'auteur est révélé. Nous développons un nouveau jeu de données basé sur les épisodes de CSI, formalisons l'identification des agresseurs en tant que problème d'étiquetage de séquence et développons un modèle basé sur LSTM qui apprend à partir de données multimodales. Les résultats expérimentaux montrent qu'une stratégie d'inférence incrémentielle est essentielle pour faire des suppositions précises ainsi que pour apprendre à partir de représentations fusionnant des entrées textuelles, visuelles et acoustiques.</abstract_fr>
      <abstract_ja>本稿では、CSI: Crime Scene Investigationなどのテレビ番組で例示される犯罪ドラマは、現実の自然言語理解とそれに関連する複雑な推論を近似するための理想的なテストベースであると主張する。犯罪ドラマを新たな推論課題として扱うことを提案しており、各エピソードが同じ基本的な疑問（つまり、犯人が誰であるか）を提起し、犯人が明らかになったときに当然答えを提供するという事実を利用している。CSIエピソードに基づいた新しいデータセットを開発し、シーケンスラベルの問題として加害者の識別を形式化し、マルチモーダルデータから学習するLSTMベースのモデルを開発します。実験結果は、テキスト、視覚、音響入力を融合した表現から学ぶだけでなく、正確な推測を行うためにも、増分推論戦略が重要であることを示しています。</abstract_ja>
      <abstract_zh>《犯罪现场勘》等电视节目中举例犯罪剧近似世界自然语言解脱相关,理欲试平台。 臣等请以剧为新理,因每集同本(罪)事实,发露自对。 发一CSI之新数,以肇事者识为序,发一基于LSTM,学于多模态之数。 实验结果表明,增量推理之策,准的测度及从融合文本,视声学输入之要。</abstract_zh>
      <abstract_hi>इस पेपर में हम तर्क देते हैं कि सीएसआई जैसे टेलीविजन कार्यक्रमों में अपराध नाटक का उदाहरण दिया गया है: अपराध दृश्य जांच वास्तविक दुनिया की प्राकृतिक भाषा की समझ और इसके साथ जुड़े जटिल अनुमानों को अनुमानित करने के लिए एक आदर्श टेस्टबेड है। हम अपराध नाटक को एक नए अनुमान कार्य के रूप में मानने का प्रस्ताव करते हैं, इस तथ्य को भुनाते हुए कि प्रत्येक एपिसोड एक ही मूल प्रश्न पैदा करता है (यानी, जिसने अपराध किया) और स्वाभाविक रूप से जवाब प्रदान करता है जब अपराधी का पता चलता है। हम सीएसआई एपिसोड के आधार पर एक नया डेटासेट विकसित करते हैं, एक अनुक्रम लेबलिंग समस्या के रूप में अपराधी की पहचान को औपचारिक बनाते हैं, और एक एलएसटीएम-आधारित मॉडल विकसित करते हैं जो बहु-मोडल डेटा से सीखता है। प्रयोगात्मक परिणामों से पता चलता है कि एक वृद्धिशील अनुमान रणनीति सटीक अनुमान लगाने के साथ-साथ पाठ्य, दृश्य और ध्वनिक इनपुट को फ्यूज करने वाले अभ्यावेदनों से सीखने के लिए महत्वपूर्ण है।</abstract_hi>
      <abstract_ru>В этой статье мы утверждаем, что криминальная драма, приведенная в качестве примера в телевизионных программах, таких как CSI: Расследование на месте преступления, является идеальным испытательным стендом для приближения понимания естественного языка в реальном мире и связанных с ним сложных выводов. Мы предлагаем рассматривать криминальную драму как новую задачу вывода, используя тот факт, что каждый эпизод ставит один и тот же основной вопрос (то есть, кто совершил преступление) и, естественно, дает ответ, когда преступник раскрывается. Мы разрабатываем новый набор данных на основе эпизодов CSI, формализуем идентификацию преступников как проблему маркировки последовательностей и разрабатываем модель на основе LSTM, которая извлекает уроки из мультимодальных данных. Экспериментальные результаты показывают, что стратегия постепенного вывода является ключом к точным догадкам, а также извлечению уроков из представлений, объединяющих текстовые, визуальные и акустические входные данные.</abstract_ru>
      <abstract_ga>Sa pháipéar seo áitímid go bhfuil dráma coireachta mar eiseamláire i gcláir theilifíse mar CSI: Crime Scene Investigation ina leaba thástála iontach chun tuiscint ar theanga nádúrtha an fhíorsaoil agus na tátail chasta a bhaineann léi a chomhfhogasú. Tá sé beartaithe againn caitheamh le drámaíocht choireachta mar thasc tátal nua, ag baint leasa as an bhfíric go gcuireann gach eipeasóid an bhuncheist chéanna (i.e. cé a rinne an choir) agus go soláthraíonn sé an freagra go nádúrtha nuair a nochtar an té a rinne an choir. Forbraímid tacar sonraí nua bunaithe ar eipeasóidí CSI, déanaimid sainaithint coireanna a chur ar bhonn foirmiúil mar fhadhb lipéadaithe seichimh, agus forbróimid samhail bunaithe ar LSTM a fhoghlaimíonn ó shonraí ilmhódacha. Léiríonn torthaí turgnamhacha go bhfuil straitéis incriminteach tátail ríthábhachtach chun tomhais chruinne a dhéanamh chomh maith le foghlaim ó léiriúcháin a chomhcheanglaíonn ionchur téacsach, amhairc agus fuaimiúil.</abstract_ga>
      <abstract_ka>ამ დომენტში ჩვენ ვთქვათ, რომ კრისიმენტის დირამა, როგორც CSI-ში გამოიყენებულია: კრისიმენტის სენ ინტერვისტირება იდეალური ტესტირება, რომელიც მსოფლიოდ მსოფლიოდ ნატრალიური ენის გაგრძ ჩვენ გვეუნდა გავაკეთოთ კრისიმენტის დირამას როგორც ახალი ინფრენციის რაოდენობა, რომლებიც ყოველ ეპიციოდის განმავლობაში იგივე მსგავსი კითხვა (მაგალითად, რომელიც გავაკეთე კრისიმენტი) და ნართო ჩვენ განვითარებთ ახალი მონაცემების კონფიგურაცია CSI ეპიზოდის ბაზაზე, პორმალურად მონაცემების ინდენტიფიკაცია როგორც წერტილების პრობლემა, და განვითარებთ LSTM-ის მხარე მონაცემებ ექსპერიმენტიური შედეგები აჩვენებენ, რომ ინფერიმენტიური ინფერიციის სტრატიგია გასაკეთებელი გასაკეთებელი გასაკეთებელი გასაკეთებელი გასაკეთებელი და გასწავლებელი ტექსტულ</abstract_ka>
      <abstract_hu>Ebben a tanulmányban azzal érvelünk, hogy a televíziós műsorokban például a CSI: Crime Scene Investigation egy ideális tesztágyat jelent a valós világ természetes nyelv megértésének és a hozzá kapcsolódó komplex következtetések megközelítéséhez. Javasoljuk, hogy a bűnügyi drámát új következtetési feladatként kezeljük, kihasználva azt a tényt, hogy minden epizód ugyanazt az alapvető kérdést teszi fel (azaz ki követte el a bűncselekményt), és természetesen adja a választ, amikor az elkövetőt felfedik. CSI epizódokon alapuló új adatkészletet dolgozunk ki, formalizáljuk az elkövetők azonosítását sorozatcímkézési problémákként, és kifejlesztünk egy LSTM alapú modellt, amely multimodális adatokból tanul. A kísérleti eredmények azt mutatják, hogy az inkrementális következtetési stratégia kulcsfontosságú a pontos találgatások elvégzéséhez, valamint a szöveges, vizuális és akusztikus bemeneteket ötvöző reprezentációkból való tanuláshoz.</abstract_hu>
      <abstract_el>Στην παρούσα εργασία υποστηρίζουμε ότι το εγκληματικό δράμα που παρουσιάζεται σε τηλεοπτικά προγράμματα όπως το CSI: Crime Scene Investigation είναι ένα ιδανικό δοκιμαστικό πεδίο για την προσέγγιση της πραγματικής κατανόησης της φυσικής γλώσσας και των πολύπλοκων συμπερασμάτων που σχετίζονται με αυτό. Προτείνουμε να αντιμετωπιστεί το εγκληματικό δράμα ως ένα νέο έργο συμπερασμάτων, αξιοποιώντας το γεγονός ότι κάθε επεισόδιο θέτει το ίδιο βασικό ερώτημα (δηλαδή ποιος διέπραξε το έγκλημα) και φυσικά παρέχει την απάντηση όταν αποκαλυφθεί ο δράστης. Αναπτύσσουμε ένα νέο σύνολο δεδομένων βασισμένο σε επεισόδια CSI, επισημοποιούμε τον προσδιορισμό του δράστη ως πρόβλημα σήμανσης ακολουθίας και αναπτύσσουμε ένα μοντέλο βασισμένο στο LSTM που μαθαίνει από πολυμορφικά δεδομένα. Τα πειραματικά αποτελέσματα δείχνουν ότι μια σταδιακή στρατηγική συμπερασμάτων είναι το κλειδί για την πραγματοποίηση ακριβών εικασιών καθώς και για την εκμάθηση από αναπαραστάσεις που συνδυάζουν γραπτή, οπτική και ακουστική εισαγωγή.</abstract_el>
      <abstract_lt>Šiame dokumente teigiame, kad nusikalstama drama, pavyzdžiui, televizijos programose, kaip antai CSI: nusikalstamos scenos tyrimas yra idealus bandomasis pagrindas suderinti tikrojo pasaulio gamtos kalbos supratimą ir su juo susijusias sudėtingas išvadas. Siūlome, kad nusikaltimo drama būtų laikoma nauja i švados užduotimi, pasinaudojant tuo, kad kiekvienas epizodas kelia tokį patį pagrindinią klausimą (t. y. kas padarė nusikaltimą) ir, žinoma, pateikia atsakymą, kai nustatomas nusikaltėlis. Kuriame naują duomenų rinkinį, pagrįstą CSI epizodais, formalizuojame nusikaltėlio identifikavimą kaip sekos ženklinimo problem ą ir kuriame LSTM pagrįstą model į, kuris mokomas iš daugiarūšio pobūdžio duomenų. Eksperimentiniai rezultatai rodo, kad laipsniškos išvados strategija yra labai svarbi siekiant tikslių spėjimų ir mokymosi iš reprezentacijų, jungiančių tekstinį, vizualinį ir akustinį įnašą.</abstract_lt>
      <abstract_it>In questo articolo sosteniamo che il dramma criminoso esemplificato in programmi televisivi come CSI: Crime Scene Investigation è un banco di prova ideale per approssimare la comprensione del linguaggio naturale del mondo reale e le complesse inferenze ad esso associate. Proponiamo di trattare il dramma criminale come un nuovo compito di inferenza, capitalizzando sul fatto che ogni episodio pone la stessa domanda di base (cioè chi ha commesso il crimine) e fornisce naturalmente la risposta quando l'autore viene rivelato. Sviluppiamo un nuovo set di dati basato su episodi CSI, formalizziamo l'identificazione degli autori come problema di etichettatura delle sequenze e sviluppiamo un modello basato su LSTM che apprende dai dati multimodali. I risultati sperimentali mostrano che una strategia di inferenza incrementale è fondamentale per fare congetture accurate e imparare dalle rappresentazioni che fondono input testuali, visivi e acustici.</abstract_it>
      <abstract_mk>In this paper we argue that crime drama exemplified in television programs such as CSI: Crime Scene Investigation is an ideal testbed for approximating real-world natural language understanding and the complex inferences associated with it.  Ние предложуваме да се третира криминалната драма како нова задача за конференција, искористувајќи го фактот дека секоја епизода поставува исто основно прашање (т.е. кој го извршил криминалот) и природно го обезбедува одговорот кога ќе биде откриен извршителот. Развиваме нов податок базиран на CSI епизоди, формализираме идентификација на извршителот како проблем со означувањето на секвенца, и развиваме модел базиран на LSTM кој учи од мултимодилни податоци. Експерименталните резултати покажуваат дека екстременталната стратегија за инференција е клучна за прецизните претпоставувања, како и за учење од претставувањата кои фузираат текстуални, визуелни и акустички влози.</abstract_mk>
      <abstract_kk>Бұл қағазда, CSI секілді телевизиялық бағдарламаларында мысалды қамтамасы драмасы деп айтып тұрмыз: Қайту сценарын зерттеу - шын әлемдегі тәуелді тілді түсініктерді жақындау үшін идеалдық сынақтар. Біз преступтердің драмасын жаңа инференциялық тапсырмасы ретінде әрбір епизод бір негізгі сұрақ (мысалы, қамтамасы істеген) деп жауап беру үшін негізгі сұрақ береді. Біз CSI эпизодтарына негізделген жаңа деректер жиынын құрамыз, әрекетші идентификациясын реттеу мәселесі ретінде оқып, көп модалдық деректерден үйренетін LSTM негізделген моделін құрамыз. Эксперименталдық нәтижелер текстік, визуалды және акустикалық енгізімдерден оқыту үшін көптеген инференциялық стратегиясы дегенді көрсетеді.</abstract_kk>
      <abstract_ms>Dalam kertas ini kami menyangka bahawa drama jenayah yang ditunjukkan sebagai contoh dalam program televisyen seperti CSI: Penyelidikan TKP adalah tempat ujian yang ideal untuk mengharapkan pemahaman bahasa alam dunia nyata dan kesimpulan kompleks yang berkaitan dengannya. Kami mengusulkan untuk memperlakukan drama jenayah sebagai tugas kesimpulan baru, menggunakan fakta bahawa setiap episod mengajukan soalan dasar yang sama (iaitu siapa yang melakukan jenayah) dan secara alami memberikan jawapan apabila pelaku diketahui. Kami mengembangkan set data baru berdasarkan episod CSI, formalisasi pengenalan pelaku sebagai masalah label urutan, dan mengembangkan model berdasarkan LSTM yang belajar dari data multi modal. Hasil percubaan menunjukkan bahawa strategi kesimpulan tambahan adalah kunci untuk membuat tekaan yang tepat serta belajar dari perwakilan yang menggabungkan input teks, visual, dan akustik.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങള്‍ വാദിക്കുന്നത് കുറ്റകൃത്യം ടെലിവിയിലെ പ്രോഗ്രാമുകളില്‍ ഉദാഹരണമാണെന്നാണ്: കുറ്റകൃത്യ സ്കൈന്‍ അന്വേഷണം ശരിക്കും ലോകത്തെ സ്വ കുറ്റകൃത്യത്തിന്റെ ദ്രാമയെ പുതിയ അപകടത്തിന്റെ ജോലിയാക്കാന്‍ ഞങ്ങള്‍ ആലോചിക്കുന്നു. എല്ലാ പ്രദേശങ്ങളും ഒരേ അടിസ്ഥാനത്തില്‍ ചോദ്യം ഉണ്ടാക്കുന്നു ( സിസിഐ എപ്പിസോഡുകളില്‍ അടിസ്ഥാനമായി ഒരു പുതിയ ഡാറ്റാസേറ്റ് നമ്മള്‍ നിര്‍മ്മിക്കുന്നു. പ്രവര്‍ത്തിക്കുന്നവരുടെ തിരിച്ചറിയുന്നത് സെക്കന്‍ പരീക്ഷണത്തിന്റെ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു ഒരു കൂടുതല്‍ അപകടത്തിന്റെ കാര്യം കൃത്യമായി ഊഹിക്കുന്നതിനും പ്രതിനിധികളില്‍ നി</abstract_ml>
      <abstract_mt>F’dan id-dokument aħna jargumentaw li d-dramma tal-kriminalità eżemplifikata fi programmi televiżivi bħas-CSI: L-Investigazzjoni dwar ix-Xena tal-Kriminalità hija test ideali għall-approssimazzjoni tal-fehim tal-lingwa naturali fid-dinja reali u l-inferenzi kumplessi assoċjati miegħu. Aħna nipproponu li d-dramma tal-kriminalità tiġi ttrattata bħala kompitu ġdid ta’ inferenza, billi nikkapitalizzaw fuq il-fatt li kull episodju joħloq l-istess mistoqsija bażika (jiġifieri, min wettaq il-kriminalità) u naturalment jipprovdu t-tweġiba meta jiġi żvelat l-awtur. Aħna niżviluppaw sett ta’ dejta ġdid ibbażat fuq episodji tas-CSI, niformalizzaw l-identifikazzjoni tal-perpetratur bħala problem a tat-tikkettar tas-sekwenza, u niżviluppaw mudell ibbażat fuq l-LSTM li jitgħallem minn dejta multimodali. Riżultati esperimentali juru li strateġija inkrementali ta’ inferenza hija kruċjali biex isiru suppożizzjonijiet preċiżi kif ukoll biex jitgħallmu minn rappreżentazzjonijiet li jiffurmaw input testwali, viżiv u akustiku.</abstract_mt>
      <abstract_pl>W niniejszym artykule argumentujemy, że dramat kryminalny przykładowy w programach telewizyjnych takich jak CSI: Crime Scene Investigation jest idealnym miejscem testowym do zbliżenia rzeczywistego zrozumienia języka naturalnego i skomplikowanych wniosków z nim związanych. Proponujemy traktować dramat kryminalny jako nowe zadanie wnioskowania, wykorzystując fakt, że każdy epizod stawia to samo podstawowe pytanie (tj. kto popełnił przestępstwo) i naturalnie udziela odpowiedzi, gdy sprawca zostanie ujawniony. Opracowujemy nowy zestaw danych oparty na epizodach CSI, formalizujemy identyfikację sprawcy jako problem etykietowania sekwencji oraz opracowujemy model oparty na LSTM, który uczy się na danych multimodalnych. Wyniki eksperymentalne pokazują, że strategia wnioskowania przyrostowego jest kluczem do dokonywania dokładnych zgadywań, a także uczenia się z reprezentacji łączących dane tekstowe, wizualne i akustyczne.</abstract_pl>
      <abstract_no>I denne papiret argumenterer vi at kriminalitet drama som eksemplet i televizjonsprogrammer som CSI: Crime Scene Investigation er ein ideell testen for å nærme tilnærminga av verkelig naturleg språk og den komplekse inferensen som er tilknytta med det. Vi foreslår å behandla kriminaldrama som eit nytt inferensningsoppgåve, med å skrive stort på faktum at kvar episode plasserer det same grunnleggjande spørsmålet (dvs. som utførte kriminaldrama) og naturleg tilbyr svaret når det gjeldande vert opna. Vi utviklar eit nytt dataset basert på CSI-episoder, formaliser identifikasjon av gjeldande som eit problem med merkelappen på sekvens, og utviklar ein LSTM-basert modell som lærer frå fleire modal data. Eksperimentale resultater viser at ein inkremental infeksjonsstrategi er nøkkel for å gjera nøyaktig gjester og lære frå representasjonar som fuserer tekstual, visual og akustisk inndata.</abstract_no>
      <abstract_ro>În această lucrare susținem că drama criminală exemplificată în programe de televiziune precum CSI: Crime Scene Investigation este un test ideal pentru aproximarea înțelegerii limbajului natural din lumea reală și concluziile complexe asociate cu acesta. Propunem să tratăm drama crimei ca pe o nouă sarcină de deducție, valorificând faptul că fiecare episod pune aceeași întrebare de bază (adică cine a comis crima) și oferă în mod natural răspunsul atunci când făptașul este dezvăluit. Dezvoltăm un nou set de date bazat pe episoadele CSI, formalizăm identificarea făptașului ca o problemă de etichetare a secvențelor și dezvoltăm un model bazat pe LSTM care învață din datele multimodale. Rezultatele experimentale arată că o strategie de inferență incrementală este cheia pentru a face presupuneri exacte, precum și pentru a învăța din reprezentări care fuzionează intrarea textuală, vizuală și acustică.</abstract_ro>
      <abstract_mn>Энэ цаасан дээр бид гэмт хэрэг үйл явдал CSI гэх мэт телевизийн програмуудад жишээ болсон гэмт хэрэг үйл явдал гэдэгт хэлж байна: гэмт хэрэг үйл явдал нь бодит ертөнцийн байгалийн хэл ойлголтын тухай ойролцохын тулд үнэхээр шийд Бид гэмт хэрэг үйлдвэрлэлийг шинэ халдвар үйлдвэрлэх ажил болгож, хэсэг бүр ижил үндсэн асуулт (яг хэн гэмт хэрэг үйлдвэрлэж байсан бөгөөд гэмт хэрэг үйлдвэрлэж байгаа) гэдэгт итгэдэг, гэмт хэрэг үйлдвэрлэгч явахад хариу Бид CSI хэвлэлүүдийн үндсэн шинэ өгөгдлийн санг бүтээж, хэрэглэгчийн тодорхойлолтыг дарааллын маркингийн асуудал болгож, олон моделийн өгөгдлийн мэдээллээс суралцах LSTM-ын үндсэн загвар бүтээж байна. Үүний туршилтын үр дүнд нэмэлт халдварын стратеги нь зөв тооцоолох, мөн textual, visual, acoustic оролцооллоос хамтдаа суралцах зүйлс гэдгийг харуулдаг.</abstract_mn>
      <abstract_sr>U ovom dokumentu tvrdimo da je drama kriminala primjerena u televizijskim programima kao što je CSI: istraživanje scene kriminala idealno testovano za približavanje razumevanja prirodnog jezika u stvarnom svijetu i kompleksnih inferencija povezanih s njim. Predlažemo da tretiramo dramu zločina kao novi zadatak infekcije, kapitalizirajući činjenicu da svaka epizoda postavlja is to osnovno pitanje (tj. ko je počinio zločin) i prirodno pruža odgovor kada se pojavi počinitelj. Razvijamo novi set podataka na osnovu epizoda CSI-a, formaliziramo identifikaciju počinitelja kao problem označavanja sekvence, i razvijamo model osnovan na LSTM-u koji uči od multimodalnih podataka. Eksperimentalni rezultati pokazuju da je povećana strategija infekcije ključna za pravljenje tačnih pogađanja, kao i učenje od zastupanja koji spajaju tekstualne, vizuelne i akustične ulaze.</abstract_sr>
      <abstract_si>මේ පත්තරේ අපි ප්‍රශ්නයක් කරනවා අපරාධ විද්‍යාමය CSI වගේ ටීවියෝජින් ව්‍යාපෘතියේදී ප්‍රශ්නයක් නිර්මාණය කරලා තියෙන්නේ අපරාධ වි අපි අපරාධ ක්‍රියාමාව අලුත් අපරාධ ක්‍රියාවක් විදිහට ගන්න පුළුවන් වෙනවා, හැම අපරාධ ප්‍රශ්නයක්ම අවස්ථාවක් වගේ ප්‍රශ්නයක් තියෙනවා ක අපි CSI අවස්ථාවයේ අළුත් දත්ත සූදානයක් විස්තර කරනවා, ක්‍රමයක් ලේබිල් ප්‍රශ්නයක් විස්තර කරනවා, ඒ වගේම LSTM අධාරිත මන්ද්‍රයක්  පරීක්ෂණාත්මක ප්‍රතිචාරයක් පෙන්වන්නේ විශේෂ විනාශ ව්‍යාපාරයක් තමයි හරියට අහන්න අවශ්‍ය කරන්න සහ ප්‍රතිචාර</abstract_si>
      <abstract_so>Warqadan waxaynu ka sheekaynaynaa in dhaqdhaqaaqa dembigu uu tusaale ahaan ku qoray barnaamijyada television, sida CSI: Baaritaanka cilmiga dembiga waa fikrada loo tijaabiyey si loo barto garashada afka asalka ah ee dunida iyo cudurada adag ee la xiriira. Waxaynu soo jeedaynaa in lagu dhaqsado khamiirka dembiga oo cusub shaqo cudur ah, taas oo ku habboon in kastoo dareemo uu yahay su'aal aasaasi ah (tusaale ahaan dembiga) islamarkaasna si dabiicadda ah jawaabta ka bixinaya marka uu dembigu muujiyo. We develop a new dataset based on CSI episodes, formalize perpetrator identification as a sequence labeling problem, and develop an LSTM-based model which learns from multi-modal data.  Imtixaanka waxaa laga muujiyaa in qorshaha cudurka dhimirka ah uu yahay mid si sax ah u sameeya malayo iyo sidoo kale in laga barto macluumaadka dhaqdhaqaaqa, aragga iyo injiga.</abstract_so>
      <abstract_sv>I denna uppsats argumenterar vi för att brottsdrama exemplifierat i tv-program som CSI: Crime Scene Investigation är en idealisk testbädd för att närma sig verklighetens naturspråkförståelse och komplexa slutsatser förknippade med det. Vi föreslår att brottsdrama behandlas som en ny slutuppgift, med utgångspunkt i att varje avsnitt ställer samma grundläggande fråga (dvs vem som begick brottet) och givetvis ger svaret när förövaren avslöjas. Vi utvecklar ett nytt dataset baserat på CSI-episoder, formaliserar förövarens identifiering som ett sekvensmärkningsproblem och utvecklar en LSTM-baserad modell som lär sig av multimodala data. Experimentella resultat visar att en inkrementell inferensstrategi är nyckeln till att göra exakta gissningar samt lära sig från representationer som kombinerar text, visuell och akustisk input.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் நாம் விவாதம் செய்து குற்றம் தொலைக்காட்சி நிரல்களில் உதாரணமாக்கப்பட்டுள்ளது என்று கூறுகிறோம் CSI போன்ற குற்றம்: குற்றம் அறிவி நாம் குற்றவாளி drama ஒரு புதிய பாதிப்பு பணியாக சிகிச்சை செய்ய நினைவூட்டுகிறோம், ஒவ்வொரு நிகழ்வும் அதே அடிப்படை கேள்வி கொண்டிருக்கிறது (அதாவது பாவம்  நாங்கள் CSI முறைமைகளை அடிப்படையில் புதிய தகவல் அமைப்பை உருவாக்குகிறோம், செய்பவர் அடையாளத்தை தொடர்ந்து குறிப்பிடும் பிரச்சனையாக வடிவமைக்கும சோதனையின் முடிவுகள் காண்பிக்கப்படுகிறது அதிகரிக்கும் நோய் திட்டம் சரியான எண்ணங்களை உருவாக்கும் மற்றும் குறிப்பிட்ட உரையாடல், பார்</abstract_ta>
      <abstract_ur>ہم اس کاغذ میں جھگڑتے ہیں کہ جرم ڈراما ٹیلیوی پروگراموں میں مثال لکھا گیا ہے جیسے CSI: جرم سین تحقیقات واقعی دنیا کی طبیعی زبان سمجھنے کے قریب آزمائش کے لئے ایک ایڈال آزمائش ہے اور اس کے ساتھ تعلق کی پیچیدہ آزمائش ہے۔ ہم گناہ ڈراما کو نئی عفونت کا کام بنانے کے لئے پیشنهاد کرتے ہیں، ہر قسم کے لئے ایک ہی بنیادی سوال ہے (یعنی جرم کا کام) اور طبیعی طور پر جبرائیت کا جواب دیتے ہیں جب گناہگار نازل ہوتا ہے۔ ہم CSI اپیسوڈز پر بنیاد ایک نئی ڈیٹ سٹ ایجاد کرتے ہیں، مجرمین کی شناسایی ایک سٹم لابلینگ مسئلہ کے طور پر فرمولی کر دیتے ہیں، اور ایک LSTM بنیاد مدل ایجاد کرتے ہیں جو بہت سی موڈال ڈیٹے سے سکھتا ہے. تجربے کے نتیجے دکھاتے ہیں کہ ایک اضافہ ایفارنس کا استراتژی دقیق گمان بنانے کی کلید ہے اور ایک دقیق معلومات کی تعلیم بھی لکھ رہی ہے جو ٹکسٹیول, بصیرت اور آکسٹیک ایمپ سے ملتی ہے۔</abstract_ur>
      <abstract_uz>Bu hujjatda biz murojaat qilamiz, CSI kabi televizyoning dasturlarida misol qilinamiz: Criminal Scan Investigation haqiqiqiy dunyo asl tili tushunishni va uning bilan bog'liq murakkablik kasalliklarni ko'rganish uchun fikr imkoniyatini tekshirish. Biz kriminal drama yangi vazifa sifatida boshqarish talab qilamiz. Bu haqida, har bir episodda bir asosiy savol (masalan qo'llanma) ega bo'ladi va tabiiy qiluvchi ko'rsatilga javob beradi. @ info Tajriba natijalari ko'rsatadi, ko'proq murakkablik strategiya bir tashkilotlarni aniqlash mumkin, va texnologiya, ko'rinishi va yaxshi narsalarni o'rganish mumkin.</abstract_uz>
      <abstract_vi>Trong tờ giấy này chúng tôi tranh luận rằng bi kịch tội phạm được ví dụ trong các chương trình truyền hình như CSI: Cuộc điều tra của tội phạm là một thử nghiệm lý tưởng để mô phỏng sự hiểu biết ngôn ngữ tự nhiên trên thế giới thực và kết quả phức tạp. Chúng tôi đề nghị coi bi kịch tội phạm như một nhiệm vụ phủ nhận mới, tận dụng sự thật rằng mỗi tập tin đặt câu hỏi cơ bản như nhau (ai đã phạm tội) và hiển nhiên là câu trả lời khi thủ phạm được lộ ra. Chúng tôi phát triển một tập tin mới dựa trên các tập tin CSI, chính thức việc xác nhận kẻ thủ phạm là một vấn đề mô phỏng các chuỗi, và phát triển một mô hình dựa trên LSD, học từ các dữ liệu đa phương. Kết quả thí nghiệm cho thấy một chiến lược nhận biết tăng dần là chìa khóa để dự đoán chính xác và học hỏi từ các biểu hiện kết hợp kết cấu, hình ảnh và âm thanh.</abstract_vi>
      <abstract_nl>In dit artikel stellen we dat criminaliteitsdrama in televisieprogramma's zoals CSI: Crime Scene Investigation een ideaal testbed is voor het benaderen van het begrip van natuurlijke taal in de echte wereld en de complexe conclusies die ermee verbonden zijn. We stellen voor om criminaliteitsdrama te behandelen als een nieuwe conclusietaak, waarbij we profiteren van het feit dat elke aflevering dezelfde basisvraag stelt (d.w.z. wie de misdaad heeft gepleegd) en natuurlijk het antwoord geeft wanneer de dader wordt onthuld. We ontwikkelen een nieuwe dataset op basis van CSI episodes, formaliseren de identificatie van daders als een sequentie labeling probleem en ontwikkelen een LSTM gebaseerd model dat leert van multimodale data. Experimentele resultaten tonen aan dat een incrementele inferentiestrategie essentieel is voor het maken van nauwkeurige gissingen en leren van representaties waarbij tekstuele, visuele en akoestische input wordt samengevoegd.</abstract_nl>
      <abstract_hr>U ovom papiru tvrdimo da je drama kriminala primjerena u televizijskim programima poput CSI: istraživanje scene kriminala idealno testirano za približavanje razumijevanja prirodnog jezika u stvarnom svijetu i kompleksnih inferencija povezanih s njim. Predlažemo liječiti dramu zločina kao novi zadatak infekcije, kapitalizirajući činjenicu da svaka epizoda postavlja is to osnovno pitanje (tj. tko je počinio zločin) i prirodno pruža odgovor kada se pojavi počinitelj. Razvijamo novi set podataka na temelju epizoda CSI-a, formaliziramo identifikaciju počinitelja kao problem označavanja sekvence i razvijamo model osnovan na LSTM-u koji uči iz multimodalnih podataka. Eksperimentalni rezultati pokazuju da je povećana strategija infekcije ključna za pravljenje tačnih pogađanja, kao i učenje od zastupanja koji fusiraju tekstualni, vizualni i akustički ulaz.</abstract_hr>
      <abstract_bg>В тази статия ние твърдим, че криминалната драма, представена в телевизионни програми като Криминална сцена на разследване, е идеална база за доближаване на разбирането на естествения език в реалния свят и сложните заключения, свързани с него. Предлагаме криминалната драма да се разглежда като нова задача за заключение, като се възползва от факта, че всеки епизод поставя един и същ основен въпрос (т.е. кой е извършил престъплението) и естествено дава отговор, когато извършителят бъде разкрит. Разработваме нов набор от данни въз основа на епизоди на CSI, формализираме идентифицирането на извършителя като проблем с етикетирането на последователността и разработваме базиран модел, който се учи от мултимодални данни. Експерименталните резултати показват, че стратегията за постепенно заключение е ключова за правене на точни предположения, както и за учене от репрезентации, обединяващи текстов, визуален и акустичен вход.</abstract_bg>
      <abstract_da>I denne artikel argumenterer vi for, at kriminalitet drama eksemplificeret i tv-programmer som CSI: Crime Scene Investigation er et ideelt testbed for tilnærmelse af den virkelige verdens naturlige sprogforståelse og de komplekse konklusioner, der er forbundet med det. Vi foreslår at behandle kriminalitetsdrama som en ny konklusionsopgave, idet vi drager fordel af, at hver episode stiller det samme grundlæggende spørgsmål (dvs. hvem der har begået forbrydelsen) og naturligvis giver svaret, når gerningsmanden afsløres. Vi udvikler et nyt datasæt baseret på CSI episoder, formaliserer gerningsmændenes identifikation som et sekvensmærkningsproblem og udvikler en LSTM-baseret model, der lærer af multimodale data. Eksperimentelle resultater viser, at en trinvis inferensstrategi er nøglen til at lave nøjagtige gæt samt lære af repræsentationer, der fusionerer tekst, visuel og akustisk input.</abstract_da>
      <abstract_de>In diesem Beitrag argumentieren wir, dass Kriminaldrama, das in Fernsehprogrammen wie CSI: Crime Scene Investigation beispielhaft dargestellt wird, ein ideales Testfeld für die Annäherung an reales Verständnis natürlicher Sprache und die damit verbundenen komplexen Schlussfolgerungen ist. Wir schlagen vor, Kriminaldrama als neue Schlussfolgerungsaufgabe zu behandeln, indem wir die Tatsache nutzen, dass jede Episode die gleiche Grundfrage stellt (d.h. wer das Verbrechen begangen hat) und natürlich die Antwort liefert, wenn der Täter aufgedeckt wird. Wir entwickeln einen neuen Datensatz basierend auf CSI-Episoden, formalisieren die Täter-Identifikation als Sequenz-Kennzeichnungsproblem und entwickeln ein LSTM-basiertes Modell, das aus multimodalen Daten lernt. Experimentelle Ergebnisse zeigen, dass eine inkrementelle Inferenzstrategie der Schlüssel ist, um genaue Schätzungen zu treffen und aus Repräsentationen zu lernen, die textuelle, visuelle und akustische Eingaben verschmelzen.</abstract_de>
      <abstract_ko>본고에서 우리는 등 텔레비전 프로그램을 중심으로 하는 범죄극은 이상적인 테스트 플랫폼으로 실제 세계의 자연 언어 이해와 이와 관련된 복잡한 추리에 가깝다고 생각한다.우리는 범죄극을 새로운 추리 임무로 삼아 매회 같은 기본적인 문제(즉 누가 죄를 지었는가)를 제기하고 범죄자가 폭로될 때 자연히 답을 내놓는 사실을 활용할 것을 제안한다.우리는 CSI 이벤트를 기반으로 한 새로운 데이터 집합을 개발하여 범죄자 식별을 서열 표기 문제로 형식화하고 LSTM 기반의 모델을 개발하여 다중모드 데이터에서 배웠다.실험 결과에 따르면 증량 추리 전략은 정확한 추측을 하고 텍스트, 시각과 소리 입력을 융합시키는 표현에서 학습하는 관건이다.</abstract_ko>
      <abstract_fa>در این کاغذ می‌گوییم که درام جنایت در برنامه‌های تلویزیون مثل CSI مثال شده است: تحقیقات صحنه جنایت یک آزمایش ایده‌ای برای نزدیک کردن درک زبان طبیعی دنیای واقعی و آزمایش پیچیده با آن است. ما پیشنهاد می‌کنیم که درام جنایت را به عنوان یک کار جدید آلودگی درمان کنیم، با استفاده از این حقیقت که هر قسمت یک سوال بنیادی (یعنی کدام جنایت را انجام داده) قرار می‌دهد، و طبیعتاً پاسخ را وقتی مجرم آشکار شود می‌دهد. ما یک مجموعه اطلاعات جدید را بر اساس بخش‌های CSI توسعه می‌کنیم، شناسایی مجرمان را به عنوان یک مشکل نقاشی‌نامه‌نامه‌نامه فرمول می‌کنیم، و یک مدل بنیاد LSTM را توسعه می‌دهیم که از داده‌های چند مدل یاد می‌گیرد نتیجه‌های تجربه نشان می‌دهد که استراتژی افزایش افزایش اضافه‌ای کلید برای ساختن حدس‌های دقیق و یادگیری از نمایش‌های متن، دیده و آکوستیک ترکیب می‌کنند.</abstract_fa>
      <abstract_id>Dalam koran ini kami berdebat bahwa drama kejahatan yang digambarkan dalam program televisi seperti CSI: Penyelidikan TKP adalah tempat ujian ideal untuk mendekati pemahaman bahasa alam dunia nyata dan kesimpulan kompleks yang berhubungan dengannya. Kami mengusulkan untuk memperlakukan drama kejahatan sebagai tugas kesimpulan baru, menggunakan fakta bahwa setiap episode mengajukan pertanyaan dasar yang sama (i.e., siapa yang melakukan kejahatan) dan secara alami memberikan jawaban ketika pelaku terbuka. Kami mengembangkan dataset baru berdasarkan episode CSI, formalisasi identifikasi pelaku sebagai masalah label urutan, dan mengembangkan model berdasarkan LSTM yang belajar dari data multi modal. Hasil eksperimen menunjukkan bahwa strategi kesimpulan incremental adalah kunci untuk membuat tebakan akurat serta belajar dari rappresentasi yang menggabungkan input tekstual, visual, dan akustik.</abstract_id>
      <abstract_sw>Katika karatasi hii tunahoji kwamba drama ya uhalifu ilifanikiwa katika programu za televisheni kama vile CSI: Utafiti wa Sayansi ya Kihalifu ni jaribio la kufikia uelewa wa lugha halisi duniani na maambukizi magumu yanayohusiana nayo. Tunazipendekeza kukabiliana na mauaji ya uhalifu kama jukumu jipya la maambukizi, kwa kuzingatia ukweli kwamba kila episode linaleta swali hilo la msingi (yaani aliyefanya makosa) na kwa uhalisia anatoa jibu pale mwandamizi atapowekwa wazi. Tunaweza kutengeneza seti mpya ya taarifa zinazotumiwa na maeneo ya CSI, kutengeneza utambulisho wa wahalifu kama tatizo la kutambua kwa mfululizo, na kutengeneza muundo wa msingi wa LSTM ambao unajifunza kutoka kwa takwimu za aina mbalimbali. Matokeo ya majaribio yanaonyesha kuwa mkakati wa maambukizi yanayozidi kuongezeka ni ufunguo wa kutengeneza dhana sahihi pamoja na kujifunza kutoka kwa uwakilishi wanaosababisha matokeo ya msingi, kuona na kwa kiasi kikubwa.</abstract_sw>
      <abstract_tr>Bu gazetde CSI ýaly telewizor programlarında örenmiş jenaýat dramasyny çykarýarys: Krim senasyny barlamak, dünýäde tebigy dillerin düşünüşi we onuň bilen gaty karmaşık hasaplançlygy ýakynlamak üçin ideal bir testedir. Biz jenaýatyň dramasyny täze bir täze zalanjyk täze bir täze bolmagy teklip edýäris we her sany bir soragy (meseläm, kimler jenaýatyny edenler) diýip dogry ulykdan soňra jogap berilýäris. Biz CSI epizodlaryna daýan ýar, perpetratoryň tanyşygyny sıralan etiketleme meselesi hökmünde döredik we LSTM-dan daýanýar bir nusgany çykarýarys. Deneysel sonuçları, düzgün tahmin etmek ve tekst, görsel ve akustik girişinden birleştirilen ifadelerden öğrenmek içün azaltma stratejisi açtır.</abstract_tr>
      <abstract_sq>Në këtë gazetë argumentojmë se drama e krimit e shembulluar në programe televizive të tilla si CSI: hetimi i skenës së krimit është një vend i testuar ideal për afrimin e kuptimit të gjuhës natyrore të botës reale dhe përfundimet komplekse të lidhura me të. Ne propozojmë të trajtojmë dramat e krimit si një detyrë të re përfundimi, duke përfituar nga fakti se çdo episod posedon të njëjtin pyetje bazë (pra, kush e ka kryer krimin) dhe natyrisht jep përgjigjen kur zbulohet kryetari. Ne zhvillojmë një grup të ri të dhënash bazuar në episodet CSI, formalizojmë identifikimin e kryetarit si një problem me etiketën e sekuencës dhe zhvillojmë një model bazuar në LSTM që mëson nga të dhënat multimodale. Rezultatet eksperimentale tregojnë se një strategji përfundimi shtesë është kryesore për të bërë supozime të sakta si dhe për të mësuar nga përfaqësimet që bashkojnë input tekstual, vizual dhe akustik.</abstract_sq>
      <abstract_az>Bu kağıtda, CSI kimi televizyon proqramlarında nümunə edilmiş suç draması: Crime Scene Investigation gerçek dünyanın doğal dillərin anlaşılmasını və bununla bağlı kompleks inferensi yaxınlaşması üçün ideal sınaqdır. Biz suç dramatisini yeni bir infeksiya görevi kimi davranmağı təklif edirik, hər epizoda eyni temel sual təklif edir (həmçinin suç i şlədi) və həmçinin günahkarın a çıldığı zaman cavabı təklif edir. Biz CSI epizodlarına dayanan yeni verilən qurma qurmasını təşkil edirik, günahkar kimliğini seçmə etiketi problemi olaraq formalizə təşkil edirik və çoxlu modal verilənlərdən öyrənən LSTM-ə dayanan modeli təşkil edirik. Eksperiment sonuçları göstərir ki, artıqlıq infeksyon stratejisi doğru tahmin etmək üçün, həmçinin textual, visual və akustik girişdən öyrənmək üçün nöqtədir.</abstract_az>
      <abstract_af>In hierdie papier het ons gespreek dat misdaad drama voorbeeld in televisieprogramme soos CSI: Crime Scene Investigation is 'n ideaal toets vir aankomming van reël-wêreld natuurlike taal verstanding en die komplekse inferensies wat met dit geassosieer is. Ons stel voorstel om misdaad drama as 'n nuwe inferensie taak te behandel, kapitaliseer op die feit dat elke episode dieselfde basiese vraag (i.e. wie die misdaad gemaak het) en natuurlik verskaf die antwoord wanneer die misdaad openbaar word. Ons ontwikkel 'n nuwe datastel gebaseer op CSI episodes, formaliseer doen identifikasie as 'n volgorde etiket probleme, en ontwikkel 'n LSTM-gebaseerde model wat leer van multimodale data. Eksperimentale resultate wys dat 'n inkremensiele inferensie strategie sleutel is om regte gaste te maak as ook te leer van voorstellings wat versamel tekstuele, visuele en akustiese invoer.</abstract_af>
      <abstract_hy>Այս թղթի մեջ մենք փաստարկում ենք, որ հանցագործության դրամը, որը ցույց է տալիս հեռուստատեսության ծրագրերում, ինչպիսիք են CSI-ը. հանցագործական Scene-ի հետազոտությունը իդեալական փորձարկումներ է իրական աշխարհի բնական լեզվի հասկացության և դրա հետ կապված բարդ հետ Մենք առաջարկում ենք հանցագործության դրաման վերաբերել որպես նոր եզրակացություն, օգտագործելով այն փաստը, որ յուրաքանչյուր դեպք նույն հիմնական հարց է տալիս (այսինքն, ով է հանցագործել հանցագործությունը) և բնական պատասխան է տալիս, երբ հանցագործը հայտնաբերվում է: Մենք զարգանում ենք նոր տվյալների համակարգ, որը հիմնված է CSI-ի դեպքերի վրա, կազմակերպում ենք գործողի ինքնությունը որպես հաջորդականության պիտակ տալու խնդիր, և զարգանում ենք LSMT-ի հիմնված մոդել, որը սովորում է բազմամոդալ տվյալներից Փորձարկվող արդյունքները ցույց են տալիս, որ աճող հետևանքների ռազմավարությունը կարևոր է ճշգրիտ գուշակումների կատարման համար, ինչպես նաև արտահայտություններից սովորելու համար, որոնք միավորում են տեքստոնալ, տեսողական և ձայնային ներդրումները:</abstract_hy>
      <abstract_bn>এই কাগজটিতে আমরা যুক্তি দিচ্ছি যে টেলিভিশন প্রোগ্রামে অপরাধ নাটক যেমন সিসিআই: অপরাধ স্কেন গুরুত্বপূর্ণ বিশ্বের প্রাকৃতিক ভাষা বুঝতে এবং এর সা আমরা অপরাধের নাটকে নতুন অসুস্থ কাজ হিসেবে চিকিৎসা করার প্রস্তাব দিচ্ছি, যার মাধ্যমে রাজধানী করা হয়েছে যে প্রত্যেক পর্বের মৌলিক প্রশ্ন (যেমন অপরাধ করেছে) এব আমরা একটি নতুন ডাটাসেট তৈরি করি সিসিআই পরিস্থিতির উপর ভিত্তি করে, অপরাধীদের চিহ্ন ব্যবহারকারীদের একটি সেকেন্ড লেবেলিং সমস্যা হিসেবে গঠন করি এবং একটি এলসিএ Experimental results show that an incremental inference strategy is key to making accurate guesses as well as learning from representations fusing textual, visual, and acoustic input.</abstract_bn>
      <abstract_am>በዚህ ገጾች ውስጥ የኃጢአተኛ drama እንደ CSI የቴሌቪዥን ፕሮግራም እንዳደረገ ነው፡፡ የኃጢአተኛ ነጻ ምርመራ እውነተኛ የዓለም ፍጥረት ቋንቋ ማስተዋል እና በተገኘው አካባቢ ድካም ነው፡፡ የኃጢአተኛ ድራም አዲስ ነጻ ስራ እንዲሆን እና ሁሉም ጉዳይ አንድ መሠረት ጥያቄ (አዲስ ወንጀል ያደረገው) እና በተገኘው ጊዜ ጥያቄውን በማስተካከል እናስመክራለን፡፡ በCSI episodes ላይ የተመሳሳይን አዲስ የዳታተር setን እናደርጋለን፣ የአሳባቢውን ግንኙነት መግለጫ እና በብዙ-ሞዴል ዳታዎች የሚተማርበትን የLSTM ምሳሌ እናሳድጋለን፡፡ ፈተና ፍሬዎች፣ የግንኙነት፣ የዓይነት እና የአስቸጋሪ ግንኙነትን ለማድረግ መግለጫ ነው፡፡</abstract_am>
      <abstract_cs>V tomto článku argumentujeme, že kriminální drama příkladem televizních programů jako CSI: Crime Scene Investigation je ideální testovací místo pro přiblížení skutečného porozumění přirozenému jazyku a složitých závěrů s ním spojených. Navrhujeme považovat kriminální drama za nový úkol závěru, využít skutečnosti, že každá epizoda klade stejnou základní otázku (tj. kdo spáchal trestný čin) a přirozeně poskytuje odpověď, když je pachatel odhalen. Vyvíjíme novou datovou sadu založenou na epizodách CSI, formalizujeme identifikaci pachatele jako problém značení sekvence a vyvíjíme model založený na LSTM, který se učí z multimodálních dat. Experimentální výsledky ukazují, že strategie inkrementální inference je klíčová pro přesné odhady a učení se z reprezentací spojujících textové, vizuální a akustické vstupy.</abstract_cs>
      <abstract_ca>En aquest article argumentem que el drama del crim exemplificat en programes de televisió com CSI: L'investigació de la escena del crim és un test ideal per aproximar la comprensió de la llengua natural del món real i les complexes inferències associades a ella. We propose to treat crime drama as a new inference task, capitalizing on the fact that each episode poses the same basic question (i.e., who committed the crime) and naturally provides the answer when the perpetrator is revealed.  Desenvolvem un nou conjunt de dades basat en episodis de CSI, formalitzem l'identificació del autor com un problem a d'etiqueta de seqüència, i desenvolupem un model basat en LSTM que aprenen de dades multimodals. Els resultats experimentals mostren que una estratègia de inferència incremental és clau per fer suposicions exactes i aprendre de representacions que fusionen entrada textual, visual i acústica.</abstract_ca>
      <abstract_bs>U ovom papiru tvrdimo da je drama zločina primjerena u televizijskim programima poput CSI: istraživanje scene zločina idealno testirano za približavanje razumijevanja prirodnog jezika u stvarnom svijetu i kompleksnih inferencija povezanih s njim. Predlažemo da tretiramo dramu zločina kao novi zadatak infekcije, kapitalizirajući činjenicu da svaka epizoda postavlja is to osnovno pitanje (tj. ko je počinio zločin) i prirodno pruža odgovor kada se pojavi počinitelj. Razvijamo novi set podataka na temelju epizoda CSI-a, formaliziramo identifikaciju počinitelja kao problem označavanja sekvence, i razvijamo model osnovan na LSTM-u koji uči iz multimodalnih podataka. Eksperimentalni rezultati pokazuju da je povećana strategija infekcije ključna za pravljenje tačnih pogađanja, kao i učenje od zastupanja koji spajaju tekstualni, vizualni i akustički ulaz.</abstract_bs>
      <abstract_fi>Tässä artikkelissa väitämme, että esimerkiksi CSI: Crime Scene Investigation -televisioohjelmissa esiintyvä rikosdraama on ihanteellinen testipaikka reaalimaailman luonnollisen kielen ymmärtämisen ja siihen liittyvien monimutkaisten johtopäätösten lähentämiselle. Ehdotamme rikosdraamaa uutena johtopäätöksenä hyödyntäen sitä, että jokainen jakso esittää saman peruskysymyksen (eli kuka rikoksen teki) ja antaa luonnollisesti vastauksen, kun tekijä paljastuu. Kehitämme CSI-jaksoihin perustuvan uuden aineiston, virallistamme tekijän tunnistamisen sekvenssimerkintäongelmaksi ja kehitämme LSTM-pohjaisen mallin, joka oppii multimodaalisesta datasta. Kokeelliset tulokset osoittavat, että inkrementaalinen päättelystrategia on avainasemassa tarkkojen arvausten tekemisessä sekä tekstuaalista, visuaalista ja akustista syötettä yhdistävistä representaatioista oppimisessa.</abstract_fi>
      <abstract_et>Käesolevas dokumendis väidame, et kriminaaldraama, mida näidatakse sellistes telesaadetes nagu CSI: Crime Scene Investigation, on ideaalne testimisplats reaalse maailma looduskeele mõistmise ja sellega seotud keerukate järelduste lähendamiseks. Me teeme ettepaneku käsitleda kuriteodraamat kui uut järeldusülesannet, kasutades ära asjaolu, et iga episood esitab sama põhiküsimuse (st kes kuriteo toime pani) ja annab loomulikult vastuse, kui toimepanija paljastatakse. Töötame välja uue CSI episoodidel põhineva andmekogumi, vormistame kurjategija identifitseerimise kui järjestuse märgistamise probleemi ning töötame välja LSTM-põhise mudeli, mis õpib multimodaalsetest andmetest. Eksperimentaalsed tulemused näitavad, et järkjärguline järeldusstrateegia on võti täpsete oletuste tegemiseks ning teksti, visuaalse ja akustilise sisendi ühendavatest representatsioonidest õppimiseks.</abstract_et>
      <abstract_jv>Nang paper iki, awake dhewe sawetara dadi Drama sing apik batir nang aplikasi telewiji koyo CSI: Awak dhéwé ngerasah kudu nggawe Drama sing berarti pertaman anyar, iso nggawe barang kanggo kowé sapa soko pertaman kuwi wis dipulangan ingkang dipulangan (i.e. sing berarti pertaman) lan budhakan sakjane ngomong responsa sak pertaman kang ora bisa mbualah Awak dhéwé nggawe dataset sing isiné saben karo CSI Episots, kartulisé perperator nggawe barang langgar sampek urip lan nggawe model sing isine basa podho akhar multi modal data . Reulti sing paling nggambar kelas kuwi nggawe barang kelas kuwi mau, ngono nggawe nguasai lagi gambar textual, Visual lan akustik input.</abstract_jv>
      <abstract_ha>A cikin wannan takardan, Munã jãyayya da cewa, durma laifi an bayyana shi a cikin programmen television kamar misãlai na SAI: Munã nufi kafin zartar zunubi kamar wani aikin na zartar da kafin aiki na dabam, yana madaidaita a kan duk takarda yana da tambayar misãlai (misali wanda ya yi zunubi) kuma a natura ke bãyar da majibu idan an bayyana mai ganganci. Tuna buɗe wani tsari na danne a kan kwamfyutan tsumarni na SAI, kana dangane shaidar mai zartar da shi kamar wata matsayi mai sauri, kuma Muke buɗe wani misali na LSSM wanda yana sanar da daga data masu yawa. Matarin jarrabai yana nũna cewa, wata kimar kashi na ƙaranci yana da muhimmin ta samar zato masu sahihi da kuma an sani daga mazaɓan-matsayi, da gane da akroniki.</abstract_ha>
      <abstract_sk>V prispevku trdimo, da je kriminalna drama, ki jo ponazarjajo televizijski programi, kot je CSI: Crime Scene Investigation, idealna preizkusna plošča za približevanje razumevanja naravnega jezika v realnem svetu in z njim povezanih kompleksnih sklepov. Predlagamo, da kriminalno dramo obravnavamo kot novo nalogo sklepanja, pri čemer izkoristimo dejstvo, da vsaka epizoda postavlja isto osnovno vprašanje (tj. kdo je storil kaznivo dejanje) in seveda zagotovi odgovor, ko se storilec razkrije. Razvijamo nov nabor podatkov, ki temelji na CSI epizodah, formaliziramo identifikacijo storilca kot problem označevanja zaporedja in razvijamo model, ki temelji na LSTM, ki se uči iz multimodalnih podatkov. Eksperimentalni rezultati kažejo, da je strategija postopnega sklepanja ključnega pomena za natančne ugibanje in učenje iz reprezentacij, ki združujejo besedilni, vizualni in akustični vnos.</abstract_sk>
      <abstract_he>בעיתון הזה אנו טוענים שדרמה פשע מודגמת בתוכניות טלוויזיה כמו CSI: חקירת סצנה פשע היא מקום מבחן אידיאלי להתקרב להבנה טבעית של העולם האמיתי אנו מציעים להתייחס לדרמה פשעית כמשימה חדשה למסקנה, בניסיון לעובדה שכל פרק מעלה את אותה שאלה בסיסית (כלומר, מי ביצע את הפשע) ובטבעי מספק את התשובה כאשר הפושע נחשף. אנחנו מפתחים קבוצת נתונים חדשה מבוססת על פרקים CSI, פורמליזם זיהוי עבריין כבעיה תווית רצף, ופתחים מודל מבוסס LSTM שלמד מידע רב-מודאלי. תוצאות ניסיוניות מראות שסטרטגיה למסקנה נוספת היא מפתחת לבצע ניחושים מדויקים, כמו גם ללמוד ממציגות שממזגות כניסה טקסטולית, ויזואלית וקוסטית.</abstract_he>
      <abstract_bo>འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་བྱ་སྡུད་བྱ་རིམ་ནང་གི་དཀའ་ངལ་ཆེ་བ་དཔེར་ན། འུ་ཅག་གིས་བྱ་ཚུལ་གྱི་གནད་དོན་གསརཔ་ཞིག་མི་ལྟ་བུ་འཇུག་སྤྲོད་རྒྱུ་དང་། We develop a new dataset based on CSI episodes, formalize perpetrator identification as a sequence labeling problem, and develop an LSTM-based model which learns from multi-modal data. ལག་ལས་འཚོལ་བ་སྐྱེས་བ་ཅིག་གི་རྐྱེན་གྱི་ཐབས་ལམ་དེ་གཙོ་བོ་རེད་ཅིག་གཙོ་ཆོག་ཡོད་པས།</abstract_bo>
      </paper>
    <paper id="4">
      <title>Representation Learning for Grounded Spatial Reasoning</title>
      <author><first>Michael</first><last>Janner</last></author>
      <author><first>Karthik</first><last>Narasimhan</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <doi>10.1162/tacl_a_00004</doi>
      <abstract>The interpretation of spatial references is highly contextual, requiring <a href="https://en.wikipedia.org/wiki/Bayesian_inference">joint inference</a> over both language and the environment. We consider the task of <a href="https://en.wikipedia.org/wiki/Spatial–temporal_reasoning">spatial reasoning</a> in a <a href="https://en.wikipedia.org/wiki/Simulation">simulated environment</a>, where an agent can act and receive rewards. The proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> learns a representation of the world steered by instruction text. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. We train our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> using a variant of generalized value iteration. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state-of-the-art approaches on several metrics, yielding a 45 % reduction in goal localization error.</abstract>
      <pages>49–61</pages>
      <url hash="f62e10dd">Q18-1004</url>
      <video href="https://vimeo.com/285802158" />
      <bibkey>janner-etal-2018-representation</bibkey>
      <pwccode url="https://github.com/JannerM/spatial-reasoning" additional="false">JannerM/spatial-reasoning</pwccode>
    <title_ar>تعلم التمثيل من أجل الاستدلال المكاني المتجذر</title_ar>
      <title_es>Aprendizaje de representación para un razonamiento espacial fundamentado</title_es>
      <title_fr>Apprentissage de la représentation pour un raisonnement spatial fondé</title_fr>
      <title_pt>Aprendizagem de Representação para Raciocínio Espacial Fundamentado</title_pt>
      <title_ja>グラウンデッド空間推論のための表象学習</title_ja>
      <title_zh>基于空理表徵学</title_zh>
      <title_hi>ग्राउंडेड स्थानिक तर्क के लिए प्रतिनिधित्व सीखना</title_hi>
      <title_ru>Репрезентативное обучение для обоснованного пространственного мышления</title_ru>
      <title_ga>Foghlaim Ionadaíochta do Réasúnaíocht Spáis Bhunaithe</title_ga>
      <title_hu>Képviseleti tanulás a földi térbeli észleléshez</title_hu>
      <title_el>Εκπροσώπευση Μάθηση για αιτιολογημένη χωρική Λογιστική</title_el>
      <title_ka>სამუშაო სისტემალური მიზეზებისთვის გასწავლება</title_ka>
      <title_it>Apprendimento della rappresentazione per una ragione territoriale a terra</title_it>
      <title_kk>Жергілікті жергілікті себептердің білімі</title_kk>
      <title_lt>Atstovavimas Mokymasis pagrįstu erdviniu pagrindu</title_lt>
      <title_mk>Претставништво учење за основано просторно размислување</title_mk>
      <title_ms>Perwakilan Belajar untuk Perasaan Ruang Terutama</title_ms>
      <title_ml>ഭൂമിയിലുള്ള സ്പെയില്‍ റികോണ്‍ ചെയ്യുന്നതിനുള്ള പ്രതിനിധി പഠിക്കുന്നു</title_ml>
      <title_mt>Rappreżentazzjoni Tagħlim għal Raġunar Spazjali Raġunat</title_mt>
      <title_no>Læring av representasjon for grunnleggjande mellomrom</title_no>
      <title_mn>Зөвхөн орон зайд суралцах суралцах</title_mn>
      <title_pl>Uczenie się reprezentacyjne dla uzasadnienia przestrzennego</title_pl>
      <title_ro>Învățarea reprezentării pentru raționarea spațială împământată</title_ro>
      <title_so>Representation Learning for Grounded Spatial Reading</title_so>
      <title_sr>Predstavno učenje za osnovne svemirske razloge</title_sr>
      <title_si>ප්‍රතිනිධාන ස්පේසියල් හේතුව සඳහා ඉගෙනගන්න</title_si>
      <title_sv>Representation Learning for Grounded Spatial Resonance</title_sv>
      <title_ta>நிரப்பப்பட்ட வெற்றிடங்களை ஏற்றுவதற்கான பிரதிநிகழ்வு கற்றுக்கொடுக்கிறது</title_ta>
      <title_ur>گروڈ ڈی فضائی کیونگ کے لئے نمایشگری سیکھنا</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Truyền thuyết về lý do đất đai</title_vi>
      <title_bg>Учене на представителство за обосновано пространствено разсъждаване</title_bg>
      <title_nl>Vertegenwoordiging Leren voor gegronde ruimtelijke redenering</title_nl>
      <title_da>Repræsentationslæring med henblik på begrundet geografisk begrundelse</title_da>
      <title_hr>Predstavno učenje za osnovne prostorne razloge</title_hr>
      <title_id>Representation Learning for Grounded Spatial Reasoning</title_id>
      <title_ko>뿌리내린 공간 추리에 기초한 표징 학습</title_ko>
      <title_sw>Representation Learning for Grounded Spatial Reasoning</title_sw>
      <title_de>Repräsentationslernen für Grounded Spatial Reasoning</title_de>
      <title_tr>Ýükselen ýerleşdirim sebäpleri üçin temsil öwrenmesi</title_tr>
      <title_af>Voorstelling Leer vir Grounded Spasiele Redigering</title_af>
      <title_fa>نماینده یادگیری برای دلایل فضایی زیادی</title_fa>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Representation Learning for Grounded Spatial Reasoning</title_hy>
      <title_az>Yerli 캻spanyol Reasonlar캼n 칐yr톛nm톛si</title_az>
      <title_ca>Representació Aprendència per raonament espacial fundamentat</title_ca>
      <title_bs>Predstavno učenje za osnovne prostorne razloge</title_bs>
      <title_et>Representation Learning for Grounded Spatial Reasong</title_et>
      <title_sq>Përfaqësuesi Mëson për arsyetimin e themeluar të hapësirës</title_sq>
      <title_bn>ভূমিকা স্পেশিয়াল প্রতিক্রিয়া শিক্ষা শিক্ষা</title_bn>
      <title_cs>Reprezentační učení pro uzemněné prostorové odůvodnění</title_cs>
      <title_fi>Representation Learning for Grounded Spatial Reasoning</title_fi>
      <title_jv>Vaturan</title_jv>
      <title_he>מייצגה לומדת הגיון מרחבי מבוסס</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Učenje predstavništva za ozemljeno prostorsko razumevanje</title_sk>
      <title_bo>རྨང་གཞིའི་སྒེར་གྱི་རྒྱུ་མཚན་ལ་བསྡུས་སྐབས་སུ་ཤེས་དུས་རམ་པ།</title_bo>
      <abstract_ar>يعتبر تفسير المراجع المكانية سياقيًا إلى حد كبير ، ويتطلب استنتاجًا مشتركًا حول كل من اللغة والبيئة. نحن نأخذ في الاعتبار مهمة التفكير المكاني في بيئة محاكاة ، حيث يمكن للوكيل التصرف والحصول على المكافآت. يتعلم النموذج المقترح تمثيل العالم من خلال نص التعليمات. يسمح هذا التصميم بالمحاذاة الدقيقة للأحياء المحلية مع التفسيرات المقابلة ، مع التعامل أيضًا مع المراجع العالمية في التعليمات. نقوم بتدريب نموذجنا بالتعلم المعزز باستخدام متغير لتكرار القيمة المعمم. يتفوق النموذج على أحدث الأساليب في العديد من المقاييس ، مما يؤدي إلى انخفاض بنسبة 45٪ في خطأ توطين الهدف.</abstract_ar>
      <abstract_pt>A interpretação de referências espaciais é altamente contextual, exigindo inferência conjunta sobre a linguagem e o ambiente. Consideramos a tarefa de raciocínio espacial em um ambiente simulado, onde um agente pode atuar e receber recompensas. O modelo proposto aprende uma representação do mundo orientada por texto de instrução. Esse design permite o alinhamento preciso das vizinhanças locais com as verbalizações correspondentes, ao mesmo tempo em que lida com referências globais nas instruções. Treinamos nosso modelo com aprendizado por reforço usando uma variante de iteração de valor generalizado. O modelo supera as abordagens de última geração em várias métricas, gerando uma redução de 45% no erro de localização de metas.</abstract_pt>
      <abstract_fr>L'interprétation des références spatiales est hautement contextuelle, nécessitant une inférence conjointe à la fois sur la langue et sur l'environnement. Nous considérons la tâche du raisonnement spatial dans un environnement simulé, où un agent peut agir et recevoir des récompenses. Le modèle proposé apprend une représentation du monde guidée par un texte d'instructions. Cette conception permet un alignement précis des voisinages locaux avec les verbalisations correspondantes, tout en gérant les références globales dans les instructions. Nous entraînons notre modèle avec l'apprentissage par renforcement en utilisant une variante de l'itération de valeur généralisée. Le modèle surpasse les approches de pointe pour plusieurs mesures, ce qui permet de réduire de 45 % les erreurs de localisation des objectifs.</abstract_fr>
      <abstract_es>La interpretación de las referencias espaciales es altamente contextual y requiere una inferencia conjunta tanto del lenguaje como del entorno. Consideramos la tarea del razonamiento espacial en un entorno simulado, donde un agente puede actuar y recibir recompensas. El modelo propuesto aprende una representación del mundo guiada por el texto de instrucciones. Este diseño permite una alineación precisa de los vecindarios locales con las verbalizaciones correspondientes, al mismo tiempo que maneja las referencias globales en las instrucciones. Entrenamos nuestro modelo con aprendizaje por refuerzo utilizando una variante de iteración de valor generalizado. El modelo supera a los enfoques más avanzados en varias métricas, lo que produce una reducción del 45% en el error de localización de objetivos.</abstract_es>
      <abstract_ja>空間参照の解釈は非常に文脈的であり、言語と環境の両方にわたる共同推論を必要とする。エージェントが行動し、報酬を受け取ることができるシミュレーション環境での空間推論のタスクを考慮します。提案されたモデルは、インストラクションテキストによって舵取りされた世界の表現を学習する。この設計は、対応する言語化とローカルの近隣地域を正確に整列させることを可能にすると同時に、説明書のグローバル参照も扱うことができる。私たちは、一般化された値反復のバリアントを使用して、強化学習でモデルをトレーニングします。このモデルは、いくつかの指標で最先端のアプローチを上回り、目標のローカリゼーションエラーを45%削減します。</abstract_ja>
      <abstract_hi>स्थानिक संदर्भों की व्याख्या अत्यधिक प्रासंगिक है, जिसमें भाषा और पर्यावरण दोनों पर संयुक्त अनुमान की आवश्यकता होती है। हम एक नकली वातावरण में स्थानिक तर्क के कार्य पर विचार करते हैं, जहां एक एजेंट कार्य कर सकता है और पुरस्कार प्राप्त कर सकता है। प्रस्तावित मॉडल निर्देश पाठ द्वारा संचालित दुनिया का एक प्रतिनिधित्व सीखता है। यह डिजाइन इसी मौखिककरण के साथ स्थानीय पड़ोस के सटीक संरेखण की अनुमति देता है, जबकि निर्देशों में वैश्विक संदर्भों को भी संभालता है। हम सामान्यीकृत मूल्य पुनरावृत्ति के एक संस्करण का उपयोग करके सुदृढीकरण सीखने के साथ अपने मॉडल को प्रशिक्षित करते हैं। मॉडल कई मैट्रिक्स पर अत्याधुनिक दृष्टिकोणों को मात देता है, जिससे लक्ष्य स्थानीयकरण त्रुटि में 45% की कमी होती है।</abstract_hi>
      <abstract_ru>Толкование пространственных ссылок носит в высшей степени контекстуальный характер, требуя совместного вывода как по языку, так и по окружающей среде. Мы рассматриваем задачу пространственного мышления в моделируемой среде, где агент может действовать и получать награды. Предлагаемая модель изучает представление мира, управляемое текстом инструкции. Эта конструкция позволяет точно выравнивать местные районы с соответствующими вербализациями, а также обрабатывать глобальные ссылки в инструкциях. Мы обучаем нашу модель с обучением подкреплению с использованием варианта обобщенной итерации значений. Модель превосходит современные подходы по нескольким показателям, что приводит к снижению ошибки локализации целей на 45%.</abstract_ru>
      <abstract_zh>空参之说,高上下文相关,须合言语推理。 臣等思模拟空理,其摄可采而赏之。 所立模样学了由令文本引导的世界。 此计许将局邻域与语精确对齐,兼处分全局引用。 吾用广义值迭代之变体,以强学习之。 其模形于数指标上优于最先进之法,定位差减45%。</abstract_zh>
      <abstract_ga>Tá léirmhíniú na dtagairtí spásúla thar a bheith comhthéacsúil, a éilíonn comhthátal ar theanga agus ar an timpeallacht araon. Breithnímid an tasc a bhaineann le réasúnaíocht spásúil i dtimpeallacht insamhladh, áit ar féidir le gníomhaire gníomhú agus luach saothair a fháil. Foghlaimíonn an tsamhail atá beartaithe léiriú den domhan arna stiúradh ag téacs treorach. Ligeann an dearadh seo comharsanachtaí áitiúla a ailíniú go beacht le briathra comhfhreagracha, agus tagairtí domhanda sna treoracha á láimhseáil ag an am céanna. Cuirimid oiliúint ar ár múnla le foghlaim athneartaithe ag baint úsáide as malairt atriallta luachanna ginearálaithe. Feidhmíonn an tsamhail cur chuige úrscothach ar roinnt méadracht, rud a thugann laghdú 45% ar earráid logánaithe sprice.</abstract_ga>
      <abstract_lt>The interpretation of spatial references is highly contextual, requiring joint inference over both language and the environment.  Mes svarstome erdvinio pagrįstumo užduotį simuliuojamoje aplinkoje, kurioje agentas gali veikti ir gauti atlygį. Siūlomu modeliu pasimokoma atstovauti pasauliui, vadovaujamam mokymo tekstu. Šis projektas leidžia tiksliai suderinti vietos rajonus su atitinkamais žodžiais, taip pat tvarkyti visuotines nuorodas instrukcijose. Mokome savo model į stiprinant mokymąsi naudojant generalizuotos vertės kartojimo variant ą. Modeliu pasiekiami moderniausi metodai pagal keletą metrinių rodiklių, o tikslinės vietos nustatymo klaidos sumažėja 45 %.</abstract_lt>
      <abstract_it>L'interpretazione dei riferimenti spaziali è altamente contestuale e richiede deduzioni congiunte sia sul linguaggio che sull'ambiente. Consideriamo il compito del ragionamento spaziale in un ambiente simulato, dove un agente può agire e ricevere ricompense. Il modello proposto apprende una rappresentazione del mondo guidata dal testo di istruzioni. Questo design consente un allineamento preciso dei quartieri locali con le corrispondenti verbalizzazioni, gestendo anche riferimenti globali nelle istruzioni. Alleniamo il nostro modello con l'apprendimento di rinforzo utilizzando una variante di iterazione generalizzata del valore. Il modello supera gli approcci all'avanguardia su diverse metriche, con una riduzione del 45% degli errori di localizzazione degli obiettivi.</abstract_it>
      <abstract_ka>სოციალური რეფერენციების ინტერპუქცია ძალიან კონტექსტულია, რომელიც საერთო ინტერპუქცია იგივე ენაზე და გარეშე. ჩვენ ვფიქრობთ სიმულაციული გარემოსების რაოდენობა, სადაც ადვნენტი შეუძლია აკეთება და მიიღება სამუშაო. პროგრამეტული მოდელის შესწავლის მსოფლიოს გამოყენება ინსტრუქციის ტექსტით. ამ დიზაინის შესაძლებელია მსოფლიო საზოგადოებლო საზოგადოებების განმავლობაზე, როგორც შესაძლებელია გერბალიზაციების განმავლობაში, როგორც გლობალური რეფერ ჩვენ ჩვენი მოდელის სწავლის სწავლის სწავლის სწავლის გარიანტირებას გამოყენებთ. მოდელის შესაძლებელობა მრავალური მეტრიკის შესაძლებლობად გავაკეთება, რომელიც მიზედომის ლოკალიზაციის შეცდომაში 45%-ს გამოკლება.</abstract_ka>
      <abstract_ms>Interpretasi rujukan ruang adalah sangat kontekstual, memerlukan kesimpulan bersama atas kedua-dua bahasa dan persekitaran. Kami mempertimbangkan tugas penyebab ruang dalam persekitaran simulasi, di mana ejen boleh bertindak dan menerima imbalan. Model yang diusulkan belajar mewakili dunia yang dikendalikan oleh teks arahan. Rancangan ini membolehkan penyesuaian tepat lingkungan setempat dengan perkataan yang sepadan, sementara juga mengendalikan rujukan global dalam arahan. Kita melatih model kita dengan pembelajaran kuasa menggunakan variasi pengulangan nilai yang luas. Model melampaui pendekatan state-of-the-art pada beberapa metrik, menghasilkan pengurangan 45% dalam ralat lokasi sasaran.</abstract_ms>
      <abstract_ml>സ്പെയില്‍ രേഖകളുടെ വ്യാഖ്യാനം വളരെ പരിഗണിതമാണ്, ഭാഷയിലും പരിസ്ഥിതിയിലും യോജിപ്പിക്കേണ്ടത്. സ്പെയില്‍ കാര്യങ്ങളുടെ ജോലി നമ്മള്‍ ചിന്തിക്കുന്നു. ഒരു ഏജന്‍റ് പ്രവര്‍ത്തിക്കുകയും പ്രതിഫലം ലഭിക്കുകയും ചെയ നിര്‍ദ്ദേശിക്കപ്പെട്ട ലോകത്തിന്‍റെ പ്രതിനിധിയില്‍ ലോകത്തിന്‍റെ പ്രതിനിധി പഠിക്കുന്നു. ഈ ഡിസൈനിങ്ങള്‍ക്ക് പ്രാദേശികമായ വാര്‍ബലേഷനുകളുമായി പ്രാദേശിക അയല്‍ക്കാരുടെ സ്ഥാനത്തിലേക്കുള്ള ഒരുമിച്ചുനിര്‍ ഞങ്ങള്‍ നമ്മുടെ മോഡല്‍ പരിശീലിപ്പിക്കുന്നു. പഠിപ്പിക്കുന്നത് പൊതുവായ മൂല്യത്തിന്റെ വ്യത്യാസം ഉപയോ കുറച്ചു മെട്രിക്കങ്ങളില്‍ നിന്നും ആര്‍ട്ട്രിക്കിന്റെ അവസ്ഥ പ്രവര്‍ത്തിപ്പിക്കുന്ന മോഡല്‍ പ്രവര്‍ത്തിപ്പിക്കുന</abstract_ml>
      <abstract_hu>A térbeli hivatkozások értelmezése rendkívül kontextuális, közös következtetést igényel mind a nyelv, mind a környezet felett. A térbeli érvelés feladatát egy szimulált környezetben vesszük figyelembe, ahol egy ügynök tevékenykedhet és jutalmat kap. A javasolt modell megtanulja a világ ábrázolását az utasítási szöveg irányításával. Ez a kialakítás lehetővé teszi a helyi környékek pontos igazítását a megfelelő szóbeli szövegekkel, miközben kezeli a globális hivatkozásokat az utasításokban. Modellünket erősítő tanulással képezzük az általános érték iteráció változatával. A modell több mutatónál is felülmúlja a korszerű megközelítéseket, ami 45%-kal csökkenti a céllokalizációs hibákat.</abstract_hu>
      <abstract_el>Η ερμηνεία των χωρικών αναφορών είναι ιδιαίτερα συναφής και απαιτεί κοινή συμπέρασμα τόσο για τη γλώσσα όσο και για το περιβάλλον. Εξετάζουμε το καθήκον της χωρικής λογικής σε ένα προσομοιωμένο περιβάλλον, όπου ένας πράκτορας μπορεί να ενεργήσει και να λάβει ανταμοιβές. Το προτεινόμενο μοντέλο μαθαίνει μια αναπαράσταση του κόσμου καθοδηγούμενη από κείμενο οδηγιών. Ο σχεδιασμός αυτός επιτρέπει την ακριβή ευθυγράμμιση των τοπικών γειτονιών με αντίστοιχες λεκτικές διατυπώσεις, ενώ παράλληλα χειρίζεται τις παγκόσμιες αναφορές στις οδηγίες. Εκπαιδεύουμε το μοντέλο μας με ενισχυτική μάθηση χρησιμοποιώντας μια παραλλαγή γενικευμένης επανάληψης τιμών. Το μοντέλο ξεπερνά τις σύγχρονες προσεγγίσεις σε αρκετές μετρήσεις, αποδίδοντας 45% μείωση του σφάλματος εντοπισμού στόχων.</abstract_el>
      <abstract_kk>Бос орын сілтемелердің түсінімі көп контекстік, тіл мен орта бойынша біріктіру керек. Біз бір агент жұмыс істей алатын және мәселелерді алуға мүмкін болатын жергілікті түсініктердің тапсырмасын қалаймыз. Келтірілген үлгі мәтінді басқару үшін әлемді көрсетуді үйренеді. Бұл құрылғы келесі вербализациялармен жергілікті ауырмаларды дұрыс түзетуге мүмкіндік береді, сонымен қатар жүйелік сілтемелерді басқаруға мүмкіндік береді. Өзіміздің үлгімізді жалпы мәндердің қайталауын қолдану үшін күшейту үйренімізді оқып береміз. Бұл үлгі бірнеше метрикалық метрикалық күй- жайын жасайды. Мақсатты жергіліктердің қатесін 45% азайтады.</abstract_kk>
      <abstract_mk>Интерпретацијата на просторните референции е високо контекстуална, барајќи заедничка конференција за јазикот и за животната средина. Размислуваме за задачата на просторно размислување во симулирана средина, каде агентот може да дејствува и да добие награда. Предложениот модел научи претставување на светот управуван со инструкциски текст. Овој дизајн овозможува прецизно прилагодување на локалните соседи со соодветните вербализации, истовремено и со глобалните референции во инструкциите. Го тренираме нашиот модел со засилување на учењето користејќи варијант на генерализирана вредност итерација. Моделот ги надминува најсовремените пристапи на неколку метрики, предизвикувајќи 45 отсто намалување на грешките во локализацијата на целите.</abstract_mk>
      <abstract_mt>L-interpretazzjoni tar-referenzi ġeografiċi hija kuntestwali ħafna, li teħtieġ inferenza konġunta kemm fuq il-lingwa kif ukoll fuq l-ambjent. Aħna nqisu l-kompitu tar-raġunament ġeografiku f’ambjent simulat, fejn a ġent jista’ jaġixxi u jirċievi premjijiet. Il-mudell propost jitgħallem rappreżentazzjoni tad-dinja mmexxija mit-test tal-istruzzjoni. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions.  Aħna nħarrġu l-mudell tagħna bit-tagħlim ta’ rinfurzar bl-użu ta’ varjant ta’ iterazzjoni tal-valur ġeneralizzat. Il-mudell iwassal għal approċċi avvanzati fuq diversi metriċi, u dan iwassal għal tnaqqis ta’ 45 % fl-iżball fil-lokalizzazzjoni tal-objettivi.</abstract_mt>
      <abstract_mn>Газрын тодорхойлолтын тодорхойлолт нь маш өндөр нөхцөл байдал, хэл болон орчин тойрноос хоорондоо холбоотой халдвар хэрэгтэй. Бид нэг агент ажиллаж, шагналыг авч чадна гэдгийг тодорхойлогдсон орчинд орон зайн ойлголтын даалгаварыг ойлгож байна. Загвар өгсөн загвар нь дэлхийн загварын текстэй удирдлагатай загварыг суралцдаг. Энэ загвар нь газрын хөршүүдийн тодорхой хэлбэртэй адилхан хэлбэртэй байдлаар тодорхой тодорхойлох боломжтой болгодог. Мөн дэлхийн загваруудын тухай тодорхойлолт нь зө Бид загварын загварыг ерөнхийлөгчийн үнэ цэнэтэй дахин дахин ашиглан суралцах боломжтой болгож суралцах хэрэгтэй. Загвар нь хэдэн метрийн хувьд урлагийн байр суурь байдлыг багасгаж байгаа бөгөөд зориулалтын алдаа 45% багасгаж байна.</abstract_mn>
      <abstract_pl>Interpretacja odniesień przestrzennych jest bardzo kontekstowa, wymagająca wspólnego wnioskowania zarówno w odniesieniu do języka, jak i środowiska. Rozważamy zadanie rozumowania przestrzennego w symulowanym środowisku, w którym agent może działać i otrzymywać nagrody. Proponowany model uczy się reprezentacji świata kierowanego tekstem instrukcji. Konstrukcja ta pozwala na precyzyjne wyrównanie lokalnych dzielnic z odpowiednimi werbalizacjami, przy jednoczesnym obsłudze globalnych odniesień w instrukcjach. Szkolimy nasz model z uczeniem wzmacniającym przy użyciu wariantu uogólnionej iteracji wartości. Model przewyższa najnowocześniejsze podejścia w odniesieniu do kilku metryk, dając 45% zmniejszenia błędu lokalizacji celu.</abstract_pl>
      <abstract_no>Interpretasjonen av mellomromreferanser er svært kontekstalt, som krev joint infeksjon over både språk og miljøet. Vi ser på oppgåva av mellomrom- rasjon i eit simulert miljø, der ein agent kan arbeide og motta tiltak. Foreslått modellen lærer eit representasjon av verden som styrer med instruksjonsteksten. Dette utforminga tillèt nøyaktig justering av lokale nabolar med tilsvarande verbalisering, mens også handterer globale referanser i instruksjonane. Vi treng modellen vårt med å forstørra læring med ein variant av generelliserte gjentakingar av verdiar. Modellen utfører tilstanden til kunsten nærmer på fleire metrikar og gjer ei 45% reduksjon i målfeil for lokalisering.</abstract_no>
      <abstract_ro>Interpretarea referințelor spațiale este extrem de contextuală, necesitând deducție comună atât asupra limbii, cât și asupra mediului. Considerăm sarcina raționamentului spațial într-un mediu simulat, unde un agent poate acționa și primi recompense. Modelul propus învață o reprezentare a lumii condusă de textul instrucțiunilor. Acest design permite alinierea precisă a cartierelor locale cu verbalizările corespunzătoare, gestionând totodată referințele globale din instrucțiuni. Ne antrenăm modelul cu învățarea de armare folosind o variantă de iterație generalizată a valorii. Modelul depășește abordările de ultimă generație pe mai multe măsurători, ducând la o reducere de 45% a erorii de localizare a obiectivelor.</abstract_ro>
      <abstract_sr>Interpretacija prostornih referencija je vrlo kontekstualna, zahteva zajedničku infekciju na jeziku i okolinu. Smatramo zadatak svemirskog razmišljanja u simuliranom okruženju, gde agent može da djeluje i dobije nagradu. Predloženi model nauči zastupanje sveta upravljanog tekstom instrukcije. Ovaj dizajn omogućava precizno usklađivanje lokalnih komšiluka sa odgovarajućim verbalizacijama, dok se takođe obrađuje globalne referencije u instrukcijama. Vježbamo naš model sa učenjem jačanja koristeći variant generalizovane ponavljanja vrijednosti. Model iznosi stanje umjetnosti pristupe na nekoliko metrika, koji dovodi do smanjenja 45% pogreške lokalizacije ciljeva.</abstract_sr>
      <abstract_sv>Tolkningen av rumsliga referenser är mycket kontextuell och kräver gemensam slutsats över både språk och miljö. Vi betraktar uppgiften med rumsligt resonemang i en simulerad miljö, där en agent kan agera och få belöningar. Den föreslagna modellen lär sig en representation av världen styrd av instruktionstext. Denna design möjliggör exakt anpassning av lokala stadsdelar med motsvarande ordalydelser, samtidigt som den hanterar globala referenser i instruktionerna. Vi tränar vår modell med förstärkningsinlärning med hjälp av en variant av generaliserad värdeiteration. Modellen överträffar toppmoderna metoder på flera mätvärden, vilket ger en 45% minskning av mållokaliseringsfel.</abstract_sv>
      <abstract_si>ස්පේසියල් සංවේදනය ගොඩක් සංවේදනය, භාෂාවය සහ වාතාවයේ සම්බන්ධ සංවේදනය අවශ්‍යයි. අපි හිතන්නේ ස්ථානික සලකුණු වැඩක් සිමුලිත් වාතාවක් වලට, නියෝජිතයෙක්ට ප්‍රතිචාරයක් වැඩ කරන ප්‍රයෝජනය කරපු මොඩල් ඉගෙන ගන්නවා ලෝකයේ ප්‍රතිනිධානයක් පිළිගන්න පුළුවන්. මේ විද්‍යාපනය සම්බන්ධ වාර්තාවක් සමග ස්ථානික පාර්ශාවක් සම්බන්ධ විද්‍යාපනය සඳහා ස්ථානික පාර්ශා අපි අපේ මොඩේල් එක ප්‍රධානය කරනවා සාමාන්‍ය විශේෂ වර්ගයක් ප්‍රයෝජනය කරනවා. මොඩේල් විසින් ස්ථානයේ ක්‍රියාත්මක විසින් විසින් පරීක්ෂා කරනවා, මෙට්‍රික් විසින් පරීක්ෂණය 45% විසින් අර</abstract_si>
      <abstract_ta>வெளியீட்டு குறிப்புகளின் விளக்கம் மிகப்பெரிய நிலையானது, இரு மொழி மற்றும் சூழலுக்கும் மேலும் இணைய புரிய நாங்கள் ஒரு போன்ற சூழலில் விண்வெளி காரணங்கள் செய்ய வேண்டும் என்று கருதுகிறோம், அங்கு ஒரு முகவர் செயல்படுத் பரிந்துரைக்கப்பட்ட மாதிரி கட்டளை உரையால் உலகின் ஒரு பிரதிநிதியத்தை கற்றுக் கொள்கிறது. இந்த வடிவமைப்பு சரியான ஒழுங்குபடுத்தலை உள்ளூர்வுகளுக்கு அனுமதிக்கிறது, பொருத்தமான வார்பாலிலங்களுடன், கட்டளைகளில் உலகலாவிய பொதுவான மதிப்பு உருவாக்கத்தை பயன்படுத்தி நாம் எங்கள் மாதிரியை பயிற்சி செய்கிறோம். The model outperforms the state- of- the art approaches on several metrics, resulting in a 45% reduction in goal localization error.</abstract_ta>
      <abstract_ur>فضائی نسبتوں کی تعبیر بہت متوسط ہے، اور دونوں زبانوں اور محیط پر joint inference کی ضرورت ہے. ہم نے ایک سیمولیٹ محیط میں جگہ منطقی بحث کا کام سمجھ لیا ہے جہاں ایک اگنٹ عمل کرسکتا ہے اور اجر مل سکتا ہے۔ پیغمبر کی مدل ایک دنیا کی نمونش سکھائی جاتی ہے جو نصیحت کے متن سے چلتی ہے۔ یہ ڈیزائن مستقل محله کے مطابق مطابق ویرومیزی کے ساتھ مطابق مطابق تضابطہ کرنے کے لئے اجازت دیتا ہے، حالانکہ وصیت کے مطابق وصول کی نسبت بھی مدد کرتی ہے. ہم نے اپنی مدل کی استعمال کی مضبوط تعلیم کے ذریعہ مضبوط تعلیم کے ذریعہ استعمال کرتے ہیں. موڈل کئی میٹریک کے مقابلہ میں مضبوط طریقے سے زیادہ آرام کرتا ہے، جہاں موقع محلی سازی خطا میں 45 فیصد کاٹ دیتا ہے۔</abstract_ur>
      <abstract_so>Turjumaadda macluumaadku waa mid aad u taxadar ah, wuxuuna u baahan yahay mid ka mid ah luqada iyo deegaanka. Waxaynu ka fiirsanaynaa shaqada sababta isbooyinka ee lagu sameynayo deegaanka, kaas oo ay dhaqaale ka shaqeyn karto oo mushaar heli karo. Tusaale la soo jeeday wuxuu baraa mid ka mid ah wakiilka aduunka uu ku hoggaamiyo qoraalka hagitaanka. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions.  Tusaalkayaga waxaynu ku tababarinnaa barashada horumarinta si kala duduwan qiimaha horumarinta. Tusaalada ayaa soo saara habka farshaxanka qaarkood, wuxuuna keenaa 45% ka go'aanka qalabka boolidka.</abstract_so>
      <abstract_uz>Ispaniya parametrlarining tafsiri juda katta davlat, va tillar va muhitda bir necha infeksiyat kerak. Biz tashkilotni o'ylaymiz, bu muammolar amalga oshirishi va ijodkorni qabul qilishi mumkin. Taʼminlovchi model tizim matn orqali dunyodagi tashkilotni o'rganadi. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions.  Biz modelimizni o'rganishni o'rganish uchun o'rganishni o'rganamiz va o'zgarishni o'rganamiz. Name</abstract_uz>
      <abstract_vi>Sự giải thích về địa phương rất là ngữ cảnh, cần phải có kết luận chung về ngôn ngữ và môi trường. Chúng tôi xem xét nhiệm vụ phân tích không gian trong một môi trường mô phỏng, nơi một đặc vụ có thể hành động và nhận phần thưởng. Người mẫu đã đề nghị học một đại diện của thế giới được điều khiển bằng văn bản hướng dẫn. Thiết kế này cho phép sự thẳng hàng các láng giềng địa phương với các lời nói tương ứng, trong khi còn sử dụng các chỉ dẫn toàn cầu trong hướng dẫn. Chúng tôi đào tạo mô hình của mình bằng việc củng cố học sử dụng một biến cách lặp giá trị phổ biến. The model outtay thực hiện các phương pháp hiện đại trên một số đo, dẫn tới một sự giảm lỗi định vị của mục đích.</abstract_vi>
      <abstract_nl>De interpretatie van ruimtelijke verwijzingen is zeer contextueel en vereist gezamenlijke conclusies over zowel taal als omgeving. We beschouwen de taak van ruimtelijk redeneren in een gesimuleerde omgeving, waar een agent kan handelen en beloningen kan ontvangen. Het voorgestelde model leert een weergave van de wereld gestuurd door instructietekst. Dit ontwerp maakt een nauwkeurige uitlijning van lokale wijken mogelijk met overeenkomstige verbalisaties, terwijl ook globale verwijzingen in de instructies worden verwerkt. We trainen ons model met versterking learning met behulp van een variant van generaliseerde waardeiteratie. Het model presteert beter dan state-of-the-art benaderingen op verschillende metrics, wat resulteert in een 45% vermindering van de doellokalisatiefout.</abstract_nl>
      <abstract_da>Tolkningen af rumlige referencer er meget kontekstuel og kræver fælles konklusion over både sprog og miljø. Vi overvejer opgaven med rumlig ræsonnement i et simuleret miljø, hvor en agent kan handle og modtage belønninger. Den foreslåede model lærer en repræsentation af verden styret af instruktionstekst. Dette design giver mulighed for præcis justering af lokale kvarterer med tilsvarende verbaliseringer, samtidig med at de håndterer globale referencer i instruktionerne. Vi træner vores model med forstærkningslæring ved hjælp af en variant af generaliseret værdiiteration. Modellen overgår state-of-the-art tilgange på flere metrics, hvilket giver en 45% reduktion i mållokaliseringsfejl.</abstract_da>
      <abstract_hr>Interpretacija prostornih referencija je vrlo kontekstualna, zahtijevajući zajedničku infekciju na jeziku i okolinu. Smatramo zadatak prostornog razmišljanja u simuliranom okruženju, gdje agent može djelovati i primiti nagradu. Predloženi model nauči zastupanje svijeta upravljanog instrukcijskim tekstom. Ovaj dizajn omogućava precizno usklađivanje lokalnih susjedstva s odgovarajućim verbalizacijama, dok se također obrađuje globalne referencije u uputama. Vježbamo naš model sa učenjem pojačanja koristeći variant generalizirane ponavljanja vrijednosti. Model je nadmašio pristupe stanju umjetnosti na nekoliko metrika, što dovodi do smanjenja 45% pogreške lokalizacije ciljeva.</abstract_hr>
      <abstract_bg>Интерпретацията на пространствените препратки е силно контекстуална, изискваща съвместно заключение както върху езика, така и върху околната среда. Разглеждаме задачата на пространственото разсъждаване в симулирана среда, където агентът може да действа и да получава награди. Предложеният модел научава представяне на света, ръководено от инструкционен текст. Този дизайн позволява прецизно подравняване на местните квартали със съответните вербализации, като същевременно обработва глобални препратки в инструкциите. Обучаваме модела си с усвояване, използвайки вариант на обобщена стойност итерация. Моделът превъзхожда най-съвременните подходи по няколко показателя, което води до 45% намаление на грешката при локализация на целите.</abstract_bg>
      <abstract_ko>공간 참조의 해석은 고도의 언어 환경화로 언어와 환경에 대해 연합 추리를 해야 한다.우리는 시뮬레이션 환경에서 공간 추리를 하는 임무를 고려하고 시뮬레이션 환경에서 한 대리인이 행동을 취하고 보상을 받을 수 있다.이 모델 학습은 지령 텍스트가 제어하는 세계 표시이다.이런 디자인은 상응하는 언어를 사용하여 로컬 커뮤니티를 정확하게 정렬할 수 있고 명령의 전역 인용도 처리할 수 있다.우리는 광의치가 교체되는 변체를 사용하여 학습을 강화함으로써 우리의 모델을 훈련시킨다.이 모델은 몇 가지 지표에서 가장 선진적인 방법보다 우수하고 목표 포지셔닝 오차가 45퍼센트 감소했다.</abstract_ko>
      <abstract_id>Interpretasi referensi ruang sangat kontekstual, membutuhkan kesimpulan bersama tentang bahasa dan lingkungan. Kami mempertimbangkan tugas reasoning ruang dalam lingkungan simulasi, di mana seorang agen dapat bertindak dan menerima imbalan. Model yang diusulkan belajar representation dunia yang dikendalikan oleh teks instruksi. Desain ini memungkinkan penyesuaian tepat lingkungan lokal dengan verbalisasi yang sesuai, sementara juga menangani referensi global dalam instruksi. Kami melatih model kami dengan pembelajaran pemerintahan menggunakan variasi dari iterasi nilai generalisasi. Model ini melebihi pendekatan state-of-the-art pada beberapa metrik, memberikan pengurangan 45% dalam kesalahan lokasi tujuan.</abstract_id>
      <abstract_sw>Tafsiri ya maoni ya angani ni wakati wa muhimu sana, inayohitaji ugonjwa wa pamoja kwa lugha na mazingira. Tunafahamu jukumu la malengo ya anga katika mazingira yanayofanana, ambapo mfanyakazi anaweza kutenda na kupokea malipo. Mfano huu unapendekezwa unajifunza uwakilishi wa dunia ulioongozwa na ujumbe wa maelekezo. Mpango huu unaruhusu kuingia kwa maeneo sahihi kwa maeneo ya maeneo yanayofanana na wimbo huo, na pia kutekeleza maoni ya kimataifa katika maelekezo hayo. Tunamfundisha muundo wetu kwa kuuza kujifunza kwa kutumia tofauti ya vifaa vya ujumla. Mfano huo unatoa mbinu za hali ya sanaa kwa njia kadhaa, na kusababisha kupunguza asilimia 45 katika kosa la kuweka kwa lengo hilo.</abstract_sw>
      <abstract_fa>تعبیر ارتباطات فضایی بسیار محیط است که نیاز به آلودگی مشترک بر هر زبان و محیط محیط است. ما کار منطق فضایی را در یک محیط شبیه‌سازی می‌بینیم، جایی که یک مامور می‌تواند عمل کند و پاداش گیرد. این مدل پیشنهاد نمایش جهان را با متن آموزش هدایت می‌کند. این طراحی اجازه می‌دهد برای تنظیم دقیق محله‌های محلی با ارتباطات متفاوت، در حالی که در ارتباطات جهانی هم مدیریت می‌کند. ما مدل خود را با یادگیری که با استفاده از یک تغییر ارزش ژنرالیز استفاده می کنیم، با استفاده از یک تغییر ارزش عمومی تمرین می کنیم. مدل موقعیت هنر به چند متری نزدیک می‌شود، و در خطای محل‌سازی هدف ۴۵ درصد کاهش می‌دهد.</abstract_fa>
      <abstract_de>Die Interpretation räumlicher Bezüge ist hochkontextbezogen und erfordert gemeinsame Rückschlüsse auf Sprache und Umwelt. Wir betrachten die Aufgabe des räumlichen Denkens in einer simulierten Umgebung, in der ein Agent handeln und Belohnungen erhalten kann. Das vorgeschlagene Modell lernt eine Darstellung der Welt gesteuert durch Instruktionstext. Dieses Design ermöglicht eine präzise Ausrichtung lokaler Nachbarschaften mit entsprechenden Verbalisierungen, während auch globale Referenzen in den Anweisungen behandelt werden. Wir trainieren unser Modell mit Verstärkungslernen unter Verwendung einer Variante der generalisierten Wertiteration. Das Modell übertrifft modernste Ansätze bei mehreren Metriken und führt zu einer 45% Reduzierung des Ziellokalisierungsfehlers.</abstract_de>
      <abstract_af>Die uitlegging van spasielle verwysings is baie konteksual, wat saamgevoerde inferensie nodig oor albei taal en die omgewing. Ons beskou die taak van spasiele redening in 'n simuleerde omgewing, waar 'n agent kan werk en vergelde ontvang. Die voorgestelde model leer 'n voorstelling van die wêreld wat deur instruksieteks gestuur is. Hierdie ontwerp laat toe vir presies oplyn van plaaslike nabygede met ooreenstemmende verbalisasies, terwyl ook globale verwysing in die instruksies hanteer. Ons trein ons model met versterking leer met gebruik van 'n variant van generelliseerde waarde iterasie. Die model uitvoer die state-of-the-art toegang op verskeie metries, wat 'n 45% verduur in die doel lokalisering fout.</abstract_af>
      <abstract_am>ቋንቋ እና አካባቢ ላይ የስፋዊ መልዕክቶች መተርጓሜ እጅግ ባሕላዊ ነው፡፡ በተስተካከለው አካባቢ ውስጥ የስፋዊ ጉዳይ ጉዳይ እናስባለን፡፡ በተዘጋጀው ሞዴል የትምህርት ጽሑፍ የዓለምን መልዕክት ያስተምራል፡፡ ይህ አዲስ ግንኙነት የአገራዊ ጎረቤቶችን በመቀናቀል እና በዓለምአቀፍ ግንኙነቶችን በመጠቀም ይችላል፡፡ ሞዴሌዎቻችንን በማስተማርን በተለየ የዋጋ ትርጉም በማድረግ እናስተምራለን፡፡ The model outperforms state-of-the-art approaches on several metrics, yielding a 45% reduction in goal localization error.</abstract_am>
      <abstract_az>Uzay referansların yorumluğu çox müxtəlif, dillərin və çevrelərin üstündə birləşdirilməsi lazımdır. Biz bir agent əməllərini və mükafatlarını alacaq yerli razılaşma işlərini simulatlı ortamda düşünürük. Önülləşdirilmiş model öyrənir, öyrənmək mətnindən təşkil edilən dünyanın təşkiləri. Bu dizayn yerli məmləkətlərin tamamlanmasına müvəffəqiyyət edər, həmçin in də müəyyən edilənlərdə qlobal referans işləyir. Bizim modelimizi genellik qiymətli iterasyonun dəyişikliyini istifadə edərək öyrənməyi gücləndirməklə təhsil edirik. Model bir neçə metrik məlumatlarına yaxınlaşır, məlumatların yerləşdirilməsi xətasında 45%-ni azaltır.</abstract_az>
      <abstract_tr>Gaýd edilen çykyşlaryň terjimesi örän wajypdyr. Dilleriň we çevreleriň üstünde bir ýaraşlyk gerek. Simülatýan bir ortamda uzay razylygyň täbligini pikir edýäris, bir ajaýyn edip üýgürläp alap bilýär. Mazmunlar nusgasy guruldygy bilen dünýädäki ýerleşdirişligi öwredýär. Bu tasarlam ýerli etraplaryň dogry sözleşmeleri bilen gabdalygy mümkin edýär, we hem dünýäpli derejesi görkezilýän derejesi hem edip görkezilýär. Biz nusgadymyzy döredil deň iterjegiň üýtgeşigini ulanyp güçlendirmek bilen öwrenmegimizi ukyplaýarys. Bu nusga birnäçe metriýada ýakynlaşyk möhümmetlerden çykýar, maksadyň ýerleşmesi hatasynda 45% azaltýar.</abstract_tr>
      <abstract_bn>স্পেশিয়াল রেফারেন্সের ব্যাখ্যা খুব সাধারণ, যাদের উভয় ভাষা এবং পরিবেশের ব্যাপারে যৌথ আক্রান্ত প্রয়োজন। আমরা একটি সমতুল্য পরিবেশে স্পেশিয়াল কারণের কাজ বিবেচনা করি, যেখানে একজন এজেন্ট কাজ করতে পারে এবং পুরস্কার পেতে পারে। প্রস্তাবিত মডেল নির্দেশনার মাধ্যমে পৃথিবীর প্রতিনিধিত্ব শিখেছে। এই ডিজাইন স্থানীয় এলাকার সঠিকভাবে স্থানীয় প্রতিষ্ঠানের সাথে সংশ্লিষ্ট ভার্বালেজেশনের সাথে সংশ্লিষ্ট করার জন্য অনু We train our model with reinforcement learning using a variant of generalized value iteration.  এই মডেল বেশ কয়েকটি মিট্রিকে শিল্পের রাষ্ট্রের প্রতিক্রিয়া প্রদর্শন করে, যার ফলে গোলের স্থানীয় ত্রুটির ৪৫% কমিয়ে দেয়</abstract_bn>
      <abstract_ca>L'interpretació de les referències espacials és molt contextual, requereix una inferència conjunta sobre el llenguatge i sobre l'entorn. Considerem la tasca del raonament espacial en un entorn simulat, on un agent pot actuar i rebre recompensas. The proposed model learns a representation of the world steered by instruction text.  Aquest disseny permet allinjar precisament els barris locals amb les verbalitzacions correspondents, mentre també manipula les referències globals en les instruccions. Ensenyem el nostre model amb aprenentatge de reforç fent servir una variant de repetició de valor generalitzat. El model supera els enfocaments més avançats en diverses mètriques, produint una reducció del 45% en l'error de localització d'objectius.</abstract_ca>
      <abstract_sq>Interpretimi i referencave hapësirore është shumë kontekstual, duke kërkuar përfundim të përbashkët mbi gjuhën dhe mjedisin. Ne konsiderojmë detyrën e arsyetimit hapësiror në një mjedis të simuluar, ku një agjent mund të veprojë dhe të marrë shpërblime. Modeli i propozuar mëson një përfaqësim të botës drejtuar nga teksti i instruksionit. Ky dizajn lejon përshtatjen e saktë të lagjeve lokale me verbalizacionet korrespondente, duke trajtuar gjithashtu referencat globale në instruksionet. Ne trajnojmë modelin tonë me mësimin e forcimit duke përdorur një variant të përsëritjes së vlerave të gjeneralizuara. Modeli kryen qasje më të larta në disa metrika, duke dhënë një reduktim 45% në gabimin e lokalizimit të objektivit.</abstract_sq>
      <abstract_hy>The interpretation of spatial references is highly contextual, requiring joint inference over both language and the environment.  We consider the task of spatial reasoning in a simulated environment, where an agent can act and receive rewards.  Առաջարկված մոդելը սովորում է աշխարհի ներկայացումը, որը ղեկավարվում է դասավանդման տեքստով: Այս դիզայնը հնարավորություն է տալիս տեղական հարևանքների ճշգրիտ համապատասխան վերբերալիզացիաների հետ միասին վերահսկել գլոբալ հղումները ցուցումներում: Մենք վարժեցնում ենք մեր մոդելը ուժեղացված ուսումնասիրությամբ օգտագործելով ընդհանուր արժեքի կրկնման տարբերակը: Մոդելը հաջողվում է տարբեր մետրիկների վրա բարձրագույն մոտեցումները, ինչը նշանակում է 45 տոկոսով նվազեցնել նպատակի գտնվելու սխալ:</abstract_hy>
      <abstract_cs>Interpretace prostorových odkazů je vysoce kontextová a vyžaduje společné odvození jak na jazyk, tak na prostředí. Zvažujeme úkol prostorového uvažování v simulovaném prostředí, kde může agent jednat a získat odměny. Navržený model se naučí reprezentovat svět řízený textem instrukcí. Tento design umožňuje přesné zarovnání místních čtvrtí s odpovídajícími verbalizacemi a zároveň zpracovávání globálních referencí v návodech. Náš model trénujeme s výztužným učením pomocí varianty generalizované iterace hodnot. Model překonává nejmodernější přístupy na několika metrikách, což přináší 45% snížení chyby lokalizace cíle.</abstract_cs>
      <abstract_fi>Paikkatietoviitteiden tulkinta on erittäin kontekstuaalista ja edellyttää yhteistä päättelyä sekä kielestä että ympäristöstä. Mietimme tilaajattelun tehtävää simuloidussa ympäristössä, jossa agentti voi toimia ja saada palkkioita. Ehdotettu malli oppii esityksen maailmasta ohjetekstin ohjaamana. Tämä muotoilu mahdollistaa paikallisten kaupunginosien tarkan linjauksen vastaavilla sanamuodoilla, samalla kun käsitellään ohjeissa olevia globaaleja viittauksia. Harjoittelemme malliamme vahvistamalla oppimista käyttämällä yleistetyn arvoiteraation varianttia. Malli päihittää uusimmat lähestymistavat useissa mittareissa, mikä vähentää tavoitteen lokalisointivirhettä 45%.</abstract_fi>
      <abstract_bs>Interpretacija prostornih referencija je vrlo kontekstualna, zahtijevajući zajedničku infekciju na jeziku i okolinu. Smatramo zadatak prostornog razmišljanja u simuliranom okruženju, gdje agent može djelovati i dobiti nagradu. Predloženi model nauči zastupanje svijeta upravljanog tekstom instrukcije. Ovaj dizajn omogućava precizno usklađivanje lokalnih susjedstva sa odgovarajućim verbalizacijama, dok se također obrađuje globalne referencije u uputama. Vježbamo naš model sa učenjem pojačanja koristeći variant generalizirane ponavljanja vrijednosti. Model je nadmašio pristupe stanju umjetnosti na nekoliko metrika, što dovodi do smanjenja 45% pogreške lokalizacije ciljeva.</abstract_bs>
      <abstract_et>Ruumiliste viidete tõlgendamine on väga kontekstiline, nõuab ühist järeldust nii keele kui ka keskkonna kohta. Me kaalume ruumilise mõtlemise ülesannet simuleeritud keskkonnas, kus agent saab tegutseda ja saada preemiaid. Kavandatud mudel õpib maailma kujutamist juhenditeksti abil. See kujundus võimaldab kohalike naabruskondade täpset joondamist vastavate sõnalisanditega, käsitledes samal ajal juhistes olevaid globaalseid viiteid. Me treenime oma mudelit tugevdamisõppega, kasutades üldistatud väärtuste iteratsiooni varianti. Mudel ületab mitme mõõdiku puhul tipptasemel lähenemisviise, vähendades eesmärgi lokaliseerimise viga 45%.</abstract_et>
      <abstract_ha>Babu fassarar misãlai na spaspaspati yana da muhimmi mai girma, kuma yana nufin samar-ƙunci a kan lugha da muhalli. Tuna ƙaddara aikin spaspati a cikin muhimmada wanda ke kamfata, inda wani mataimaki zai iya aiki kuma ke karɓi ijãra. Ana fahimtar da misalin duniya wanda aka yi shirin a matsayin shiryarwa. Wannan design na yarda da juyi masu cikin masallaci na lokaci da ake daidaita verbalization, da kuma yana yarda da yin amfani da fassarar abubuwan a cikin shiryoyin ayuka. Tuna sanar da misalinmu da ƙari da za'a yi amfani da variant na ƙanshi na kima. Modelen na ƙara halin-sanar da za'a iya kusantar da shi kan wasu metric, mai ƙara %45 cikin ɓata lokalogin goa.</abstract_ha>
      <abstract_sk>Interpretacija prostorskih referenc je zelo kontekstualna in zahteva skupno sklepanje o jeziku in okolju. Obravnavamo nalogo prostorskega razmišljanja v simuliranem okolju, kjer lahko agent deluje in prejema nagrade. Predlagani model uči predstavitev sveta, ki ga vodi besedilo navodil. Ta zasnova omogoča natančno poravnavo lokalnih sosesk z ustreznimi besedami, hkrati pa obravnava globalne reference v navodilih. Model treniramo z ojačitvenim učenjem z uporabo različice generalizirane vrednosti iteracije. Model presega najsodobnejše pristope pri več meritvah, kar pomeni 45-odstotno zmanjšanje napake pri lokalizaciji ciljev.</abstract_sk>
      <abstract_jv>Tenbudhakan langkung dibuturan Awak dhéwé isih luwih nggawe barang-luwih iki dadi, nik nguasah barang penggunaké beraksi lan nganggo barang. Laptop" and "Desktop design Awak dhéwé luwih akeh model sing nggawe ngubah sistem sing gawe ngubah perusahaan butur nggawe barang. Validity</abstract_jv>
      <abstract_he>הפרשנות של התייחסות חלליות היא תקשורת מאוד, דורשת תוצאה משותפת על שפה ובסביבה. אנחנו שוקלים את המשימה של הגיון מרחבי בסביבה סימולרית, שבו סוכן יכול לפעול ולקבל פרסים. המודל המוצע לומד מייצג של העולם מונח על ידי טקסט הוראה. העיצוב הזה מאפשר ליישור מדויק של שכונות מקומיות עם מילים מתאימים, בזמן שגם לטפל בהרשומות גלובליות בהוראות. אנחנו מאמן את המודל שלנו עם לימוד תגבורה בשימוש שונה של שיפוט ערך כללי. הדוגמא מציגה גישות חדשות על מספר מטריות, ומביאה לפחות 45% של טעות במיקום המטרה.</abstract_he>
      <abstract_bo>སྐད་ཡིག་དང་སྒྲུབ་ཐང་གཉིས་ཀྱི་གསལ་བཤད་ནི་རང་ཆས་གནས་སྟངས་མཐུན་རྐྱེན་ཡོད། ང་ཚོས་རྩོམ་པ་ཞིག་གིས་མཐུན་སྒྲིག་ཀྱི་ཕྱོགས་སྟོང་ཤིག་མཁན་གྱི་ལས་འགན་ལ་བསམ་བློ་ཐུབ། གྲོས་འཆར་བྱས་པའི་མ་དབུགས་དེ་ནི་འཇིག་རྟེན་འདིས་སྟོན་པའི་ཡིག་གེ་རྟོགས་པ་ཞིག་ཏུ་ཤེས་ཀྱི་ཡོད། This design allows precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. ང་ཚོས་མ་དབྱིབས་བསྒྱུར་རྩལ་གྱིས་མཐུན་རྐྱེན་བཟོ་བྱེད་ཀྱི་སྣེ་ཚོགས་རྐྱེན་གྱིས་མཐུན་གཏོང་བྱེད། Model outperforms state-of-the-art approaches on several metrics, resulting in a 45% reduction in the goal of localization error.</abstract_bo>
      </paper>
    <paper id="5">
      <title>Learning Structured Text Representations</title>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <doi>10.1162/tacl_a_00005</doi>
      <abstract>In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016 ; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use <a href="https://en.wikipedia.org/wiki/Attentional_control">attention mechanisms</a> to incorporate the structural biases. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.</abstract>
      <pages>63–75</pages>
      <url hash="b4205089">Q18-1005</url>
      <video href="https://vimeo.com/276396538" />
      <bibkey>liu-lapata-2018-learning</bibkey>
      <pwccode url="https://github.com/nlpyang/structured" additional="true">nlpyang/structured</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    <title_ar>تعلم تمثيل النص المنظم</title_ar>
      <title_fr>Apprendre des représentations textuelles structurées</title_fr>
      <title_pt>Aprendendo Representações de Texto Estruturado</title_pt>
      <title_es>Aprendizaje de representaciones de texto estructurado</title_es>
      <title_ja>学習構造化テキスト表現</title_ja>
      <title_zh>学结构化文本</title_zh>
      <title_hi>संरचित पाठ अभ्यावेदन सीखना</title_hi>
      <title_ru>Структурированные текстовые представления обучения</title_ru>
      <title_ga>Ag Foghlaim Léiriúcháin Téacs Struchtúrtha</title_ga>
      <title_ka>სტრუქტურაციული ტექსტის გამოსახულება</title_ka>
      <title_hu>Tanulás strukturált szövegreprezentációk</title_hu>
      <title_el>Μάθηση δομημένων αναπαραστάσεων κειμένου</title_el>
      <title_it>Rappresentazioni testuali strutturate di apprendimento</title_it>
      <title_lt>Mokymasis struktūrizuotais tekstais</title_lt>
      <title_kk>Құрастырылған мәтін таңбаларын үйрену</title_kk>
      <title_ms>Learning Structured Text Representations</title_ms>
      <title_ml>സ്ഥാപിച്ച പദാവലി പ്രതിനിധികള്‍ പഠിക്കുന്നു</title_ml>
      <title_mn>Структур бүтээгдэхүүнийг сурах</title_mn>
      <title_mk>Научи структурни текстови претставувања</title_mk>
      <title_ro>Reprezentarea textului structurat de învățare</title_ro>
      <title_mt>Tagħlim Rappreżentazzjonijiet tat-Test Strutturat</title_mt>
      <title_no>Læring av strukturerte tekstrepresentasjonar</title_no>
      <title_pl>Uczenie się strukturalnych reprezentacji tekstu</title_pl>
      <title_so>Barista quraanka la dhisay</title_so>
      <title_sv>Lärande strukturerade textrepresentationer</title_sv>
      <title_sr>Naučenje strukturnih predstavljanja teksta</title_sr>
      <title_si>සංවිධානය කළ පාළුව ප්‍රතිස්ථාපනය ඉගෙනගන්න</title_si>
      <title_ta>கட்டப்பட்ட உரை மாற்றங்களை கற்றுக்கொள்கிறது</title_ta>
      <title_ur>ساخترائی ٹیکسٹ ریسپانسیٹ سیکھ رہی ہے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Học án Hình sự</title_vi>
      <title_bg>Учене на структурирани текстови представяния</title_bg>
      <title_hr>Učenje strukturnih predstavljanja teksta</title_hr>
      <title_nl>Gestructureerde tekstrepresentaties leren</title_nl>
      <title_da>Læringsstrukturerede tekstrepræsentationer</title_da>
      <title_de>Lernen strukturierter Textdarstellungen</title_de>
      <title_id>Belajar Perwakilan Teks Struktur</title_id>
      <title_sw>Kujifunza Mazungumzo yaliyojengwa</title_sw>
      <title_ko>학습 구조화 텍스트 표시</title_ko>
      <title_fa>یاد گرفتن نمایش متن ساخته</title_fa>
      <title_sq>Mësimi i përfaqësimeve të tekstit të strukturuar</title_sq>
      <title_am>text-tool-action</title_am>
      <title_hy>Սովորեցնել կառուցված տեքստի ներկայացումներ</title_hy>
      <title_tr>Baýlanan Metin Mazmunlaryny öwrenmek</title_tr>
      <title_af>Leer struktureerde teks voorstellings</title_af>
      <title_bs>Naučenje strukturovanih predstavljanja teksta</title_bs>
      <title_cs>Učení strukturovaných textových reprezentací</title_cs>
      <title_bn>নির্মিত টেক্সট প্রতিনিধি</title_bn>
      <title_az>YapńĪlmńĪŇü Metin T…ôŇükilatlarńĪnńĪ √∂yr…ônm…ôk</title_az>
      <title_fi>Oppimisen strukturoidut tekstiesitykset</title_fi>
      <title_et>Õppestruktureeritud teksti esindused</title_et>
      <title_ca>Aprendre representacions de textos estructurats</title_ca>
      <title_jv>Ngerti Gambaran Teks structural navigation</title_jv>
      <title_sk>Učenje strukturiranih predstavitev besedila</title_sk>
      <title_he>לימוד מייצגים טקסטים מבוססים</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>དབྱིབས་བཟོས་ཡོད་པའི་ཡིག་གི་བསྡུས་བརྗོད་པ</title_bo>
      <abstract_ar>في هذه الورقة ، نركز على تعلم تمثيلات المستندات المدركة للهيكل من البيانات دون اللجوء إلى محلل الخطاب أو التعليقات التوضيحية الإضافية. استلهامًا من الجهود الأخيرة لتمكين الشبكات العصبية من خلال التحيز الهيكلي (Cheng et al. ، 2016 ؛ Kim et al. ، 2017) ، نقترح نموذجًا يمكنه ترميز مستند مع إحداث تبعيات هيكلية غنية تلقائيًا. على وجه التحديد ، قمنا بتضمين خوارزمية تحليل غير إسقاطية قابلة للتفاضل في نموذج عصبي واستخدام آليات الانتباه لدمج التحيزات الهيكلية. تُظهر التقييمات التجريبية عبر المهام ومجموعات البيانات المختلفة أن النموذج المقترح يحقق أحدث النتائج في مهام نمذجة المستندات مع استحداث هياكل وسيطة قابلة للتفسير وذات مغزى.</abstract_ar>
      <abstract_es>En este artículo, nos centramos en aprender representaciones de documentos sensibles a la estructura a partir de datos sin recurrir a un analizador del discurso ni a anotaciones adicionales. Inspirándonos en los esfuerzos recientes para potenciar las redes neuronales con un sesgo estructural (Cheng et al., 2016; Kim et al., 2017), proponemos un modelo que puede codificar un documento al tiempo que induce automáticamente dependencias estructurales ricas. Específicamente, incorporamos un algoritmo de análisis no proyectivo diferenciable en un modelo neuronal y utilizamos mecanismos de atención para incorporar los sesgos estructurales. Las evaluaciones experimentales de diferentes tareas y conjuntos de datos muestran que el modelo propuesto logra resultados de vanguardia en las tareas de modelado de documentos, al tiempo que induce estructuras intermedias que son interpretables y significativas.</abstract_es>
      <abstract_pt>Neste artigo, nos concentramos em aprender representações de documentos com reconhecimento de estrutura a partir de dados sem recorrer a um analisador de discurso ou anotações adicionais. Inspirando-se nos esforços recentes para capacitar as redes neurais com um viés estrutural (Cheng et al., 2016; Kim et al., 2017), propomos um modelo que pode codificar um documento enquanto induz automaticamente ricas dependências estruturais. Especificamente, incorporamos um algoritmo de análise não projetiva diferenciável em um modelo neural e usamos mecanismos de atenção para incorporar os vieses estruturais. Avaliações experimentais em diferentes tarefas e conjuntos de dados mostram que o modelo proposto alcança resultados de última geração em tarefas de modelagem de documentos enquanto induz estruturas intermediárias que são interpretáveis e significativas.</abstract_pt>
      <abstract_fr>Dans cet article, nous nous concentrons sur l'apprentissage de représentations de documents sensibles à la structure à partir de données sans recourir à un analyseur de discours ou à des annotations supplémentaires. En nous inspirant des récents efforts visant à renforcer les réseaux de neurones avec un biais structurel (Cheng et al., 2016 ; Kim et al., 2017), nous proposons un modèle qui peut coder un document tout en induisant automatiquement de riches dépendances structurelles. Plus précisément, nous intégrons un algorithme d'analyse non projective différentiable dans un modèle neuronal et utilisons des mécanismes d'attention pour intégrer les biais structuraux. Les évaluations expérimentales de différentes tâches et ensembles de données montrent que le modèle proposé permet d'obtenir des résultats de pointe sur les tâches de modélisation de documents tout en induisant des structures intermédiaires qui sont à la fois interprétables et significatives.</abstract_fr>
      <abstract_ja>本稿では，ディスクロージャーや追加の注釈を用いずに，データから構造を認識した文書表現を学習することに焦点を当てる．構造的バイアスを持つニューラルネットワークを強化するための最近の努力（ Cheng et al., 2016; Kim et al., 2017 ）からヒントを得て、豊富な構造的依存関係を自動的に誘発しながら文書をエンコードできるモデルを提案します。具体的には、差別化可能な非投機的解析アルゴリズムをニューラルモデルに埋め込み、注意メカニズムを使用して構造的バイアスを取り入れます。さまざまなタスクとデータセットにわたる実験的評価は、提案されたモデルが、解釈可能で有意義な中間構造を誘導しながら、文書モデリングタスクで最先端の結果を達成することを示しています。</abstract_ja>
      <abstract_hi>इस पेपर में, हम एक प्रवचन पार्सर या अतिरिक्त एनोटेशन के सहारा के बिना डेटा से संरचना-जागरूक दस्तावेज़ अभ्यावेदन सीखने पर ध्यान केंद्रित करते हैं। एक संरचनात्मक पूर्वाग्रह के साथ तंत्रिका नेटवर्क को सशक्त बनाने के लिए हाल के प्रयासों से प्रेरणा लेना (चेंग एट अल। किम एट अल., 2017), हम एक मॉडल का प्रस्ताव करते हैं जो एक दस्तावेज़ को एन्कोड कर सकता है, जबकि स्वचालित रूप से समृद्ध संरचनात्मक निर्भरताओं को प्रेरित कर सकता है। विशेष रूप से, हम एक तंत्रिका मॉडल में एक विभेद्य गैर-प्रोजेक्टिव पार्सिंग एल्गोरिथ्म एम्बेड करते हैं और संरचनात्मक पूर्वाग्रहों को शामिल करने के लिए ध्यान तंत्र का उपयोग करते हैं। विभिन्न कार्यों और डेटासेट में प्रयोगात्मक मूल्यांकन से पता चलता है कि प्रस्तावित मॉडल मध्यवर्ती संरचनाओं को प्रेरित करते हुए दस्तावेज़ मॉडलिंग कार्यों पर अत्याधुनिक परिणाम प्राप्त करता है जो व्याख्या योग्य और सार्थक दोनों हैं।</abstract_hi>
      <abstract_zh>其在本文,专注于从数据中学习结构感知文档示,而无待诉诸语解析器或他注释。 自近赋予神经网络结构偏差之力,汲灵感(Cheng等,2016。 Kim et al., 2017)也,吾为之编码于文档,而自诱富焉。 具体来说将微分非射影解析算法嵌神经模,用意机整合结构偏差。 异务与数集之实验质,形于文档建模务取最先进,兼诱之又有义结。</abstract_zh>
      <abstract_ru>В этой статье мы сосредоточены на структурах обучения - осознанных представлениях документов из данных без использования анализатора дискурса или дополнительных аннотаций. Вдохновляясь недавними усилиями по расширению возможностей нейронных сетей со структурным смещением (Cheng et al., 2016; Kim et al., 2017), мы предлагаем модель, которая может кодировать документ, автоматически вызывая богатые структурные зависимости. В частности, мы внедряем дифференцируемый непроективный алгоритм синтаксического анализа в нейронную модель и используем механизмы внимания для включения структурных искажений. Экспериментальные оценки по различным задачам и наборам данных показывают, что предлагаемая модель достигает самых современных результатов по задачам моделирования документов, одновременно стимулируя промежуточные структуры, которые являются как интерпретируемыми, так и значимыми.</abstract_ru>
      <abstract_ga>Sa pháipéar seo, dírímid ar léiriú doiciméad atá feasach ar struchtúr a fhoghlaim ó shonraí gan dul i muinín parsálaí dioscúrsa nó nótaí breise. Ag tarraingt inspioráid ó iarrachtaí le déanaí chun líonraí néaracha a chumhachtú a bhfuil claonadh struchtúrach acu (Cheng et al., 2016; Kim et al., 2017), molaimid múnla a fhéadfaidh doiciméad a ionchódú agus spleáchais struchtúracha saibhre á gcothú go huathoibríoch ag an am céanna. Go sonrach, déanaimid algartam parsála neamhtheilgeanach difreálach a neadú isteach i múnla néarúil agus úsáidimid meicníochtaí aird chun na laofachtaí struchtúracha a ionchorprú. Léiríonn meastóireachtaí turgnamhacha thar thascanna agus tacair shonraí éagsúla go mbaineann an tsamhail mholta torthaí den scoth amach ar thascanna samhaltaithe doiciméad agus ag an am céanna struchtúir idirmheánacha atá inléirmhínithe agus brí a chruthú.</abstract_ga>
      <abstract_el>Σε αυτή την εργασία, εστιάζουμε στην εκμάθηση αναπαραστάσεων εγγράφων με επίγνωση δομής από δεδομένα χωρίς να καταφεύγουμε σε έναν αναλυτή λόγου ή πρόσθετες παρατηρήσεις. Με έμπνευση από τις πρόσφατες προσπάθειες ενδυνάμωσης των νευρωνικών δικτύων με δομική προκατάληψη (κ.α., 2016; Κιμ κ.α., 2017), προτείνουμε ένα μοντέλο που μπορεί να κωδικοποιήσει ένα έγγραφο ενώ ταυτόχρονα προκαλεί αυτόματα πλούσιες δομικές εξαρτήσεις. Συγκεκριμένα, ενσωματώνουμε έναν διαφοροποιημένο μη προβολικό αλγόριθμο ανάλυσης σε ένα νευρωνικό μοντέλο και χρησιμοποιούμε μηχανισμούς προσοχής για να ενσωματώσουμε τις δομικές προκαταλήψεις. Πειραματικές αξιολογήσεις σε διαφορετικές εργασίες και σύνολα δεδομένων δείχνουν ότι το προτεινόμενο μοντέλο επιτυγχάνει αποτελέσματα τελευταίας τεχνολογίας σε εργασίες μοντελοποίησης εγγράφων ενώ προκαλεί ενδιάμεσες δομές που είναι ερμηνευτές και ουσιαστικές.</abstract_el>
      <abstract_hu>Ebben a tanulm찼nyban a strukt첬ra-tudatos dokumentumreprezent찼ci처k adatokb처l t철rt챕n흷 tanul찼s찼ra 철sszpontos챠tunk diskurzus elemz흷 vagy kieg챕sz챠t흷 jegyzetek haszn찼lata n챕lk체l. A k철zelm첬ltbeli er흷fesz챠t챕sekb흷l inspir찼lva, hogy struktur찼lis elfogults찼ggal rendelkez흷 neur찼lis h찼l처zatokat er흷s챠ts체nk (Cheng et al., 2016; Kim et al., 2017), olyan modellt javasolunk, amely k챕pes k처dolni egy dokumentumot, mik철zben automatikusan gazdag struktur찼lis f체gg흷s챕geket id챕z el흷. Konkr챕tan be찼gyazunk egy differenci찼lhat처, nem projekt챠v elemz챕si algoritmust egy neur찼lis modellbe, 챕s figyelemmechanizmusokat haszn찼lunk a struktur찼lis el흷챠t챕letek be챕p챠t챕s챕re. A k체l철nb철z흷 feladatok 챕s adatk챕szletek k챠s챕rleti 챕rt챕kel챕sei azt mutatj찼k, hogy a javasolt modell korszer킥 eredm챕nyeket 챕r el a dokumentummodellez챕si feladatokban, mik철zben olyan k철ztes strukt첬r찼kat induk찼l, amelyek egyszerre 챕rtelmezhet흷ek 챕s 챕rtelmes.</abstract_hu>
      <abstract_it>In questo articolo, ci concentriamo sull'apprendimento di rappresentazioni documentali consapevoli della struttura dai dati senza ricorrere a un parser di discorso o annotazioni aggiuntive. Prendendo spunto dai recenti sforzi per potenziare le reti neurali con un bias strutturale (Cheng et al., 2016; Kim et al., 2017), proponiamo un modello in grado di codificare un documento inducendo automaticamente ricche dipendenze strutturali. Nello specifico, integriamo un algoritmo di analisi non proiettiva differenziabile in un modello neurale e utilizziamo meccanismi di attenzione per incorporare i pregiudizi strutturali. Le valutazioni sperimentali su diversi task e set di dati mostrano che il modello proposto raggiunge risultati all'avanguardia sulle attività di modellazione documentale inducendo strutture intermedie interpretabili e significative.</abstract_it>
      <abstract_ka>ამ დოკუმენტში ჩვენ სტუკუმენტის სტრუქტურაციას გავისწავლეთ დოკუმენტის გამოსახულებაზე, მონაცემების გამოსახულებაში დავუბრუნეთ დისკუ შემდეგ შემდეგ მოძლევებიდან ინგრექცია, რომელიც ნეიროლური ქსელები სტრუქტურური განსაზღვრებით (Cheng et al., 2016; Kim et al., 2017), ჩვენ გვეძლევა მოდელს, რომელიც შეუძლია კოდისტურაციის კოდისტურ განსაკუთრებულად, ჩვენ განსხვავებული არ-პროექტიური პარაქტიური ალგორიტიმს ნეიროლური მოდელში ჩვენ დავყენებთ და გამოყენებთ ინტერქტიური პროექტიური განსხვავება. ექსპერიმენტიური განსხვავებული მონაცემების და მონაცემების კონფიგურაციების შესახებ გამოწვება რომ მონაცემები მოდელის შესახებ დოკუმენტის მოდელის მონაცემების შესახებ, რომლებიც უნ</abstract_ka>
      <abstract_kk>Бұл қағазда, біз құрылымызды құжаттың түсініктерін оқытуға көмектесеміз, дискурстарды талдауға не қосымша жазбаларға қайта келтірілмей. Невралды желілерді структуралық қауіпсіздіктермен көмектесу үшін жаңа жұмыс істеу үшін (Cheng et al., 2016; Kim et al., 2017), біз құжатты кодтау үлгісін автоматты түрде бағытты структуралық тәуелдіктерді көмектесет Ескерту үшін, біз проективті емес талдау алгоритмін невралдық моделіне ендіріп, структуралық бөлшектерді қосу үшін назар механизмін қолданамыз. Басқа тапсырмалар мен деректер қорларының эксперименталдық оқу үлгісі құжатты моделдеу тапсырмалардың күй- жай нәтижесін жеткізеді. Бұл құжатты моделдеу тапсырмалардың орташа құрылымдарының</abstract_kk>
      <abstract_mk>Во овој документ, се фокусираме на учењето на претставувања на документите свесни за структурата од податоци без користење на дискурсник анализатор или дополнителни анотации. Нацртајќи инспирација од неодамнешните напори за зајакнување на невровните мрежи со структурни предрасуди (Ченг и други, 2016; Ким и други, 2017), предложуваме модел кој може да кодира документ додека автоматски индуцира богати структурни зависности. Специфично, вградивме различен непроективен алгоритм за анализирање во нервен модел и користиме механизми на внимание за вклучување на структурните предрасуди. Експерименталните проценки во различните задачи и податочни групи покажуваат дека предложениот модел постигнува најсовремени резултати во врска со задачите за моделирање на документите, истовремено индукционирајќи меѓувремени структури кои се толкувачки и значајни.</abstract_mk>
      <abstract_ml>ഈ പത്രത്തില്‍ നമ്മള്‍ സംസാരിക്കുന്ന ഒരു സംസാരത്തിന്റെ പേരിലേക്കോ കൂടുതല്‍ അഭിപ്രായശ്ചിത്രങ്ങളിലേക്കോ വിവരിക്ക അടുത്ത പ്രവര്‍ത്തനങ്ങളില്‍ നിന്നും ന്യൂറല്‍ ശ്രമങ്ങളില്‍ നിന്നും പ്രബോധനം വര്‍ത്തിക്കുന്നത് ഒരു സ്ഥാപിതികമായ കാര്യത്തിലൂടെ (ചെങ്ങ് അല്‍ , 2016; കിം എറ്റ് അല്‍., 2017 പ്രത്യേകിച്ച്, നമ്മള്‍ ഒരു വ്യത്യസ്ത പ്രോജക്റ്റീവ് പാര്‍ഗ്ഗോരിത്മിനെ ന്യൂറല്‍ മോഡലിലേക്ക് അകത്തേക്ക് കയറ്റിയിരിക്കുന്നു.  വ്യത്യസ്ത കാര്യങ്ങളിലും ഡാറ്റാസറ്റുകളിലും പരീക്ഷണവിലാസങ്ങള്‍ കാണിക്കുന്നു പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്‍ രാജ്യത്തിന്റെ മാതൃകങ്ങള്‍ രേഖ</abstract_ml>
      <abstract_lt>Šiame dokumente daugiausia dėmesio skiriame mokymuisi, atsižvelgiant į struktūrą, dokumentų pateikimui iš duomenų, nenaudojant diskurso analizatoriaus ar papildomų pastabų. Remdamiesi pastarojo meto pastangomis stiprinti struktūrinius nervų tinklus (Cheng et al., 2016; Kim et al., 2017), siūlome model į, kuris galėtų koduoti dokumentą ir automatiškai paskatinti didelę struktūrinę priklausomybę. Konkrečiai, į nervinį model į įtraukėme diferencijuotą neprojektyvų analizavimo algoritmą ir naudojame dėmesio mechanizmus, kad būtų įtraukti struktūriniai iškraipymai. Įvairių užduočių ir duomenų rinkinių eksperimentiniai vertinimai rodo, kad siūlomas modelis užtikrina naujausius dokumentų modeliavimo užduočių rezultatus ir skatina tarpines struktūras, kurios yra aiškinamos ir prasmingos.</abstract_lt>
      <abstract_ms>Dalam kertas ini, kita fokus pada belajar persembahan dokumen yang sedar-struktur dari data tanpa menggunakan penghurai diskors atau anotasi tambahan. Melukis inspirasi dari usaha baru-baru ini untuk memberikan kuasa rangkaian saraf dengan bias struktur (Cheng et al., 2016; Kim et al., 2017), kami cadangkan model yang boleh mengekodkan dokumen sementara secara automatik mengakibatkan dependensi struktur yang kaya. Secara khusus, kami memasukkan algoritma penghuraian tidak projektif yang boleh berbeza ke dalam model saraf dan menggunakan mekanisme perhatian untuk memasukkan biases struktur. Evaluasi eksperimental melalui tugas dan set data yang berbeza menunjukkan bahawa model yang diusulkan mencapai keputusan-state-of-the-art pada tugas model dokumen semasa mengandungi struktur sementara yang kedua-dua boleh diterangkan dan bermakna.</abstract_ms>
      <abstract_no>I denne papiret fokuserer vi på å lære struktureære dokumentrepresentasjonar frå data utan å gjenoppretta til ein diskurstolar eller fleire merknader. Teiknar inspirasjon frå nyleg forsøk for å styra neuralnettverk med ein strukturær forsikt (Cheng et al., 2016; Kim et al., 2017), vi foreslår eit modell som kan koda eit dokument medan automatisk induserar rike strukturavhengighet. Spesielt innebygger vi ein ulik ikkje-projektiv tolking-algoritme inn i ein neuralmodell og bruk oppmerksmekanisme for å inkludere strukturelle forvirkningar. Eksperimentale evalueringar gjennom ulike oppgåver og datasett viser at den foreslåde modellen gjer tilstand til kunstende resultat på dokumentmodellering av oppgåver ved å indusera mellombelse strukturar som både er tolkbare og betydelig.</abstract_no>
      <abstract_mt>F’dan id-dokument, niffokaw fuq rappreżentazzjonijiet ta’ dokumenti li huma konxji mill-istruttura tat-tagħlim minn dejta mingħajr rikors għal analizzatur ta’ diskors jew annotazzjonijiet addizzjonali. Bl-ispirazzjoni mill-isforzi reċenti biex in-netwerks newrali jingħataw is-setgħa bi preġudizzju strutturali (Cheng et al., 2016; Kim et al., 2017), qed nipproponu mudell li jista’ jikkodifika dokument filwaqt li awtomatikament jinduċi dipendenzi strutturali rikki. Speċifikament, a ħna inkorporajna algoritmu tal-analiżi differenzjabbli mhux proġettiv f’mudell newrali u nużaw mekkaniżmi ta’ attenzjoni biex inkorporaw il-preġudizzji strutturali. Evalwazzjonijiet sperimentali f’kompiti u settijiet ta’ dejta differenti juru li l-mudell propost jikseb riżultati l-aktar avvanzati dwar kompiti ta’ mudellar tad-dokumenti filwaqt li jinduċu strutturi intermedji li huma kemm interpretabbli kif ukoll sinifikanti.</abstract_mt>
      <abstract_sr>U ovom papiru, fokusiramo se na predstavljanja dokumenta koji znaju strukturu bez preusmjerenja na analizatora diskursa ili dodatne annotacije. Nacrtajući inspiraciju iz nedavnih napora da bi omogućili neuralne mreže strukturnim predrasudama (Cheng et al., 2016; Kim et al., 2017), predlažemo model koji može kodirati dokument dok automatski izaziva bogate strukturne zavisnosti. Posebno, uključujemo različitog neoprojektivnog algoritma za analizu u neuralni model i koristimo mehanizme pažnje da uključimo strukturne predrasude. Eksperimentalne procjene u raznim zadacima i setima podataka pokazuju da predloženi model postigne rezultate stanja umjetnosti na modeliranju zadataka dokumenta dok induciraju prosječne strukture koje su interpretabilne i značajne.</abstract_sr>
      <abstract_ro>În această lucrare, ne concentrăm pe învățarea reprezentărilor documentelor conștiente de structură din date, fără a recurge la un parser de discurs sau adnotări suplimentare. Tragând inspirație din eforturile recente de a împuternici rețelele neuronale cu o părtinire structurală (Cheng et al., 2016; Kim et al., 2017), propunem un model care poate codifica un document, inducând automat dependențe structurale bogate. Mai exact, încorporăm un algoritm de analizare non-proiectivă diferențiabil într-un model neural și folosim mecanisme de atenție pentru a încorpora prejudecățile structurale. Evaluările experimentale ale diferitelor sarcini și seturi de date arată că modelul propus obține rezultate de ultimă oră în ceea ce privește sarcinile de modelare a documentelor, inducând în același timp structuri intermediare care sunt atât interpretabile, cât și semnificative.</abstract_ro>
      <abstract_pl>W artykule skupiamy się na uczeniu się strukturalnych reprezentacji dokumentów z danych bez użycia parsera dyskursu czy dodatkowych adnotacji. Czerpiąc inspirację z ostatnich wysiłków na rzecz wzmocnienia sieci neuronowych o strukturalnym uprzedzeniu (Cheng et al., 2016; Kim et al., 2017), proponujemy model, który może kodować dokument, automatycznie indukując bogate zależności strukturalne. W szczególności osadzamy do modelu neuronowego różnicowalny algorytm analizy nieprojekcyjnej i wykorzystujemy mechanizmy uwagi do uwzględnienia uprzedzeń strukturalnych. Eksperymentalne oceny różnych zadań i zbiorów danych pokazują, że proponowany model osiąga najnowocześniejsze wyniki w zakresie zadań modelowania dokumentów przy jednoczesnym wywoływaniu struktur pośrednich, które są interpretowalne i znaczące.</abstract_pl>
      <abstract_mn>Энэ цаасан дээр бид бүтэц мэдэх баримтуудын үзүүлэлтийг суралцах эсвэл нэмэлт анзаарлаас дахин ярианы хуваалцагч эсвэл нэмэлт анзаарлаа хандуулахгүй мэдээллээс анхаарлаа хандуул Сүүлийн үеийн мэдрэлийн сүлжээний сэтгэл хөдлөлөөс урам зориулан бүтээлч байдлаар хүргэх зориулалт зурах (Ченг, аль., 2016; Ким, аль., 2017) бид баримтыг автоматаар баян бүтээлч хамааралтай байдлаар шинэчлэх боломжтой за Ялангуяа бид өөрчлөгдөж чадахгүй проектив хуваалцах алгоритмыг мэдрэлийн загвар руу оруулж, бүтэц загваруудыг нэгтгэхэд анхаарал төвлөрүүлэх механизмийг ашигладаг. Өөр төрлийн ажил, өгөгдлийн сангийн туршилтын үнэлгээ нь баримт загварын моделийн үр дүнг гаргаж чадна гэдгийг харуулж байна.</abstract_mn>
      <abstract_ta>இந்த காகிதத்தில், நாம் மீண்டும் பேச்சு பகுதி அல்லது கூடுதல் குறிப்புகள் இல்லாமல் தகவலிலிருந்து தெரியும் அட்டவணையை கற சமீபத்தில் இருந்து நெயுரல் வலைப்பின்னல்களை உருவாக்குவதற்கு தெரிவிக்கும் முயற்சிகளிலிருந்து தெரிவிக்கும் பொருட்களை உருவாக்கும் (செங் அல், 2016; கிம் மற குறிப்பிட்டு, நாங்கள் ஒரு வேறுபாடு அல்லாத திட்டங்களை ஒரு புதிய மாதிரியாக பாடல் முறைமையில் உள்ளிட்டோம் மற்றும் அடிப்படையின் பாக வேறு பணிகள் மற்றும் தரவு அமைப்புகளிலும் சோதனையின் மதிப்பீடுகள் காட்டுகிறது பரிந்துரைக்கப்பட்ட மாதிரி மாதிரி முடிவுகள் ஆவண மாதிரியாக்கும</abstract_ta>
      <abstract_so>Qoraalkan waxaynu ku kalsoonaynaa barashada dukumentiyada hoose-aqoonta ah oo aan laguugu soo celin in laguugu hadlo baaritaanka ama wax kale oo ku saabsan. Dhab u soo qaadashada waxyaabaha ugu dambeeyay si aad ugu xoogaysato shabakada neurada ee ku habboon dhismaha dhismaha (Cheng et al., 2016; Kim et al., 2017), waxaynu soo jeedinnaa model ku qori kara dukumenti sameyn karo isla markaasna si automatic ah u sameyn karno suurooyinka dhismaha taajirka ah. Si gaar ah, waxaynu qornay algoritm oo aan kala duwan ahayn oo aan qoraalka baarayno, waxaana isticmaalnay meymisyo dhaqanka ah si aan u koobnayno tababarka dhismaha. Qiimeynta baaritaanka shaqada iyo macluumaadka kala duduwan waxay muuqataa in modellka la soo jeeday uu dhamaado arimaha farshaxanka oo ku saabsan sameynta shaqooyinka sameynta sameynta dukumentiyada marka lagu sameynayo dhismaha dhexe ee lagu turjumayo iyo faa’iido leh.</abstract_so>
      <abstract_sv>I denna uppsats fokuserar vi på att lära oss strukturmedvetna dokumentrepresentationer från data utan att använda diskurstolkare eller ytterligare anteckningar. Med inspiration från de senaste ansträngningarna att stärka neurala nätverk med en strukturell bias (Cheng et al., 2016; Kim et al., 2017), föreslår vi en modell som kan koda ett dokument samtidigt som det automatiskt framkallar rika strukturella beroenden. Specifikt bäddar vi in en differentierbar icke-projektiv tolkningsalgoritm i en neural modell och använder uppmärksamhetsmekanismer för att införliva strukturella fördomar. Experimentella utvärderingar över olika uppgifter och datauppsättningar visar att den föreslagna modellen uppnår toppmoderna resultat på dokumentmodelleringsuppgifter samtidigt som den inducerar mellanliggande strukturer som är både tolkningsbara och meningsfulla.</abstract_sv>
      <abstract_ur>اس کاغذ میں، ہم نے ساختاری جاننے والی دکمیٹ کی تعلیمات کی طرف متمرکز کیا بغیر کسی گفتگو پارچر یا اضافہ اضافہ کرنے کے. نئورل نیٹورک کو ایک ساخترال عام کے ساتھ مضبوط کرنے کے لئے اخری تلاش کی پیدائش کرتا ہے (Cheng et al., 2016; Kim et al., 2017), ہم ایک مدل پیشنهاد کرتے ہیں جو ایک دفتر کو آزاد کرسکتا ہے جبکہ پوری ساخترال اعتباری کے ساتھ آزاد کرتا ہے۔ خاص طور پر، ہم ایک متفاوت غیر پروژیکٹی الگوریتم کو نئورل موڈل میں داخل کریں گے اور ساختاری بحثوں میں شامل کرنے کے لئے توجه کی مکانیسم استعمال کریں گے. مختلف کاموں اور ڈاٹ سٹوں میں تجربہ کی ارزیابی دکھاتی ہے کہ پیشنهاد کی موڈل دکمیٹ موڈلینگ کے کاموں پر موجود ہوتی ہے اور میانڈیٹ ساختاروں کو ایجاد کرتی ہے جو دونوں تعبیر قابل اور معنی ہیں۔</abstract_ur>
      <abstract_si>මේ පැත්තේ, අපි ඉගෙනගන්න ස්ථාපනය සඳහා දැනගන්න දත්ත ප්‍රතිචාරයක් ඉගෙනගන්න හිටියේ කතාවක් විශේෂකයෙක්  අලුත් ප්‍රයෝජනයෙන් ප්‍රයෝජනය කරන්න පුළුවන් නිර්මාණ ජාලයෙන් ස්ථානය ප්‍රයෝජනය කරන්න (චෙන්ග් ට් ල්., 2016; කිම් ට් ල්., 2017), අපි ප්‍රයෝජ විශේෂයෙන්ම, අපි වෙනස් නොප්‍රොජේක්ටිව විශ්වාස කරන්න බැරි අල්ගෝරිතම් එකක් නිර්මාණ මදුල්යෙක් වලට ඇතුළත් කරනවා  පරීක්ෂණාත්මක විවිධ වැඩසටහන් සහ දත්ත සටහන් වලින් පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ප්‍රයෝජන විදිහට ප්‍රයෝජන විදිහට ව</abstract_si>
      <abstract_uz>Bu hujjatda, biz taʼminlovchi hujjatning tahrirlarini o'rganishga qaramaymiz, gapiruvchi parametrlarni yoki qoʻshimcha taʼminlovchiga ega boʻlmaydi. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies.  Ko'rsatilgan, biz o'zgarishni nazar modelga o'zgartirdik va tuzuvchi tizimlarni qo'yish uchun foydalanamiz. Name</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi tập trung vào việc trình bày tài liệu dựa trên kiến trúc học từ dữ liệu mà không cần phải bàn tán hay chú thích thêm. Lấy nguồn cảm hứng từ những nỗ lực gần đây để trao quyền cho các mạng thần kinh có khuynh hướng cấu trúc (Cheng et al., 2006; Kim et al., 2007), chúng tôi đề xuất một mô hình có thể mã hóa một tài liệu trong khi tự động dẫn đến các quan hệ cấu trúc giàu có. Cụ thể, chúng tôi đã nhúng một thuật to án phân tách biệt không có hình ảnh vào một mô hình thần kinh và sử dụng các cơ quan chú ý để nhập các biến dạng cấu trúc. Phân tích thử nghiệm giữa các công việc và bộ dữ liệu khác nhau cho thấy mẫu đề nghị đạt được kết quả hiện đại về các công việc tạo mẫu tài liệu, đồng thời tạo ra các cấu trúc trung ương có thể hiểu được và có ý nghĩa.</abstract_vi>
      <abstract_bg>В тази статия се фокусираме върху изучаването на структурни представяния на документи от данни без прибягване до дискурсен анализатор или допълнителни анотации. Възхищавайки се от последните усилия за овластяване на невронните мрежи със структурно отклонение (Ченг и др., 2016; Ким и др., 2017), предлагаме модел, който може да кодира документ, като същевременно автоматично индуцира богати структурни зависимости. По-конкретно, ние вграждаме диференцируем непроективен алгоритъм за анализ в невронен модел и използваме механизми за внимание, за да включим структурните отклонения. Експерименталните оценки на различни задачи и набори от данни показват, че предложеният модел постига най-съвременни резултати при задачи за моделиране на документи, като същевременно индуцира междинни структури, които са едновременно тълкуваеми и смислени.</abstract_bg>
      <abstract_nl>In dit artikel richten we ons op het leren van structurele documentrepresentaties uit data zonder gebruik te maken van een discoursparser of aanvullende annotaties. Geïnspireerd door recente inspanningen om neuronale netwerken te versterken met een structurele bias (Cheng et al., 2016; Kim et al., 2017), stellen we een model voor dat een document kan coderen en automatisch rijke structurele afhankelijkheden kan induceren. Specifiek, we integreren een differentieerbaar niet-projectief parsing algoritme in een neuraal model en gebruiken aandachtsmechanismen om de structurele biases op te nemen. Experimentele evaluaties over verschillende taken en datasets tonen aan dat het voorgestelde model state-of-the-art resultaten behaalt op documentmodelleringstaken en tussenstructuren induceert die zowel interpreteerbaar als zinvol zijn.</abstract_nl>
      <abstract_hr>U ovom papiru, usredotočili smo se na predstavljanje dokumenta koji znaju strukturu bez obzira na pretraživač diskusija ili dodatne annotacije. Nacrtajući inspiraciju iz nedavnih napora za jačanje neuronskih mreža s strukturnim predrasudama (Cheng et al., 2016; Kim et al., 2017), predlažemo model koji može kodirati dokument dok automatski izaziva bogate strukturne zavisnosti. Posebno, uključujemo različitog neoprojektivnog algoritma za analizu u neuralni model i koristimo mehanizme pažnje da bi uključili strukturne predrasude. Eksperimentalne procjene u raznim zadacima i setima podataka pokazuju da predloženi model postigne rezultate stanja umjetnosti na zadacima modeliranja dokumenta, dok induciraju prosječne strukture koje su interpretabilne i značajne.</abstract_hr>
      <abstract_da>I denne artikel fokuserer vi på at lære strukturbevidste dokumentrepræsentationer fra data uden brug af en diskursfortolker eller yderligere noteringer. Med inspiration fra de seneste bestræbelser på at styrke neurale netværk med en strukturel bias (Cheng et al., 2016; Kim et al., 2017), foreslår vi en model, der kan kode et dokument, samtidig med at der automatisk fremkalder rige strukturelle afhængigheder. Specielt integrerer vi en differentierelig ikke-projektiv parsing algoritme i en neural model og bruger opmærksomhedsmekanismer til at indarbejde de strukturelle fordomme. Eksperimentelle evalueringer på tværs af forskellige opgaver og datasæt viser, at den foreslåede model opnår state-of-the-art resultater på dokumentmodelleringsopgaver, samtidig med at den fremkalder mellemliggende strukturer, som er både fortolkningsfulde og meningsfulde.</abstract_da>
      <abstract_ko>본고에서 우리가 주목하는 것은 데이터에서 구조적 감지의 문서 표시를 배우는 것이지 언어 해석기나 다른 주석에 도움을 청할 필요가 없다.최근 신경 네트워크 구조에 편견을 부여하려는 노력(Cheng 등, 2016년, Kim 등, 2017년)에서 영감을 받아 문서를 인코딩하면서 풍부한 구조적 의존성을 자동으로 만들어낼 수 있는 모델을 제시했다.구체적으로 말하면 우리는 미세한 비투영 해석 알고리즘을 신경 모델에 삽입하고 주의 메커니즘을 사용하여 구조적 편차를 통합시킬 것이다.서로 다른 임무와 데이터 집합에 대한 실험 평가에 따르면 이 모델은 문서 모델링 임무에서 가장 선진적인 결과를 얻었고 해석 가능하고 의미 있는 중간 구조를 형성했다.</abstract_ko>
      <abstract_id>Dalam kertas ini, kita fokus pada mempelajari persembahan dokumen yang sadar struktur dari data tanpa menggunakan parser diskors atau anotasi tambahan. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Secara spesifik, kita memasukkan algoritma penghuraian tidak proyektif yang berbeda ke dalam model saraf dan menggunakan mekanisme perhatian untuk memasukkan biases struktur. Evaluasi eksperimental melalui tugas dan set data yang berbeda menunjukkan bahwa model yang diusulkan mencapai hasil terbaik pada tugas model dokumen sementara mengakibatkan struktur intermedi yang dapat diterjemahkan dan berarti.</abstract_id>
      <abstract_de>In diesem Beitrag konzentrieren wir uns auf das Lernen strukturbewusster Dokumentdarstellungen aus Daten ohne Rückgriff auf einen Diskursparser oder zusätzliche Anmerkungen. Inspiriert von den jüngsten Bemühungen, neuronale Netze mit einem strukturellen Bias zu stärken (Cheng et al., 2016; Kim et al., 2017), schlagen wir ein Modell vor, das ein Dokument kodieren und gleichzeitig umfangreiche strukturelle Abhängigkeiten induzieren kann. Konkret betten wir einen differenzierbaren nicht-projektiven Parsing-Algorithmus in ein neuronales Modell ein und nutzen Aufmerksamkeitsmechanismen, um die strukturellen Verzerrungen zu integrieren. Experimentelle Auswertungen über verschiedene Aufgaben und Datensätze zeigen, dass das vorgeschlagene Modell aktuelle Ergebnisse bei Dokumentenmodellierungsaufgaben erzielt und gleichzeitig interpretierbare und aussagekräftige Zwischenstrukturen induziert.</abstract_de>
      <abstract_fa>در این کاغذ، ما تمرکز می‌کنیم روی نمایش‌های سند آگاه ساختاری از داده‌ها بدون بازگشت به یک بازشنگر سخنرانی یا نمایش‌های اضافه. طراحی الهام از تلاش اخیر برای تأکید شبکه‌های عصبی با تأکید ساختاری (Cheng et al., 2016; Kim et al., 2017) یک مدل پیشنهاد می‌دهیم که می‌تواند یک سند را در حالی که خودکار بستگی‌های ساختاری ثروتمند را تولید کند. مخصوصا، ما الگوریتم تجزیه کردن غیر پروژه‌ای متفاوت را در یک مدل عصبی وارد می‌کنیم و از مکانیسم توجه استفاده می‌کنیم تا جابجایی ساختاری را جمع کنیم. تحقیقات تجربه‌ای در سراسر کارهای مختلف و مجموعه‌های داده‌ها نشان می‌دهند که مدل پیشنهاد نتایج‌های موجود هنری بر مدل‌های مدل‌سازی سند می‌رسد در حالی که تولید ساختارهای بین‌المللی که هر دو قابل تعبیر و معنی هستند.</abstract_fa>
      <abstract_tr>Bu kagyzda, biz struktur bilýän senediň hasaplamalaryny barlamak üçin diskusiýa tanyşçylara çevirilmek üçin üns berýäris. Näyral şebekeleri strukturel bias (Cheng et al., 2016; Kim et al., 2017) bilen güýçlendirmek üçin soňky çabalardan ilham alyp çykýan bir nusga teklip edip görýäris. Adatça, biz faýllary üýtgeşdirmän bir projektibden çykyş algoritmyny neural nusga girdirýäris we strukturlary üýtgetmek üçin üns mehanizmalaryny ulanýarys. Farklı görevler we veri setirleri arasynda örneksel çykyşlar görkezilýän nusgalaryň, teklip eden nusgalaryň hem aňsatly we möhüm bolan ýagdaýlaryň durumyny çekip bolandygyny görkezýär.</abstract_tr>
      <abstract_sw>Katika karatasi hii, tunalenga kujifunza muundo unaofahamika na dokumu za taarifa bila kuruhusu mazungumzo au matangazo mengine. Kuchapisha hamasa kutoka juhudi za hivi karibuni za kuwawezesha mitandao ya neura kwa upendeleo wa miundombinu (Cheng et al, 2016; Kim et al., 2017), tunapendekeza modeli ambayo inaweza kuingiza nyaraka wakati wa kutegemea matajiri ya miundombinu. Kwa ujumla, tuliweka utambulisho usio na mradi wa kubadilika katika mtindo wa ubongo na kutumia mfumo wa ufuatiliaji ili kuunganisha upendeleo wa miundombinu. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.</abstract_sw>
      <abstract_am>በዚህ ፕሮግራም፣ አካባቢ አካባቢ አካባቢ ሰነዱን በማስተማር እናስማራለን፡፡ ከቅርብ ዘመን ጀምሮ የናውሬል መረብ አካባቢ ጥያቄን (Cheng et 2016; Kim et al 2017) በማድረግ ማድረግ እናሳውቃለን፡፡ በተለይም፣ የተለየ የፕሮጀክት ባሕላዊ ማኅበረሰብ ማኅበረሰብ አካባቢ እና የጥያቄ ስልጣናዎችን ለመጠቀም እና የግንኙነትን ጉዳይ ለመጠቀም እናስጠይቃለን፡፡ በተለያዩ ስራዎች እና ዳታ ማዕከላዎች ላይ የሚሞክሩ ምርጫዎች የሞላው ሞዴል የልዩ-አርራሲ ፍሬዎችን በሰነድ ምሳሌ አድራጊዎች ላይ እንዲያገኝ እና በመካከለኛው መካከለኛ ሥርዓቶች የሚተረጉም እና የሚያስፈልጋቸው ነው፡፡</abstract_am>
      <abstract_sq>Në këtë letër, ne përqëndrohemi në mësimin e përfaqësimeve të dokumenteve të ndërgjegjshëm për strukturën nga të dhënat pa përdorur një analizues diskursi apo anotacione shtesë. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies.  Veçanërisht, ne përfshijmë një algoritëm analizimi diferencial jo-projektiv në një model nervor dhe përdorim mekanizma vëmendjeje për të përfshirë paragjykimet strukturore. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.</abstract_sq>
      <abstract_hy>Այս թղթի մեջ մենք կենտրոնանում ենք սովորելու կառուցվածքի գիտակցած փաստաթղթի ներկայացումների վրա տվյալներից առանց օգտագործելու խոսքի վերլուծում կամ ավելին նոտացիաներ: Հոգեշնչում ենք վերջին ջանքերից նյարդային ցանցերի հզորություն տալու համար կառուցվածքային կողմնականությամբ (Չենգ և այլն., 2016 թվականը, Քիմ և այլն., 2017 թվականը), մենք առաջարկում ենք մի մոդել, որը կարող է կոդավորել փաստաթղթի, միաժամանակ Հատկապես, մենք ներառում ենք տարբերակելի ոչ պրոյեկտիվ վերլուծության ալգորիթմ նյարդային մոդելի մեջ և օգտագործում ենք ուշադրության մեխանիզմներ կառուցվածքային կողմնականությունների ներառման համար: Տարբեր առաջադրանքների և տվյալների համակարգերի փորձարկվող գնահատումները ցույց են տալիս, որ առաջարկած մոդելը հասնում է ամենակարևոր արդյունքներ փաստաթղթերի մոդելավորման առաջադրանքների վրա, միաժամանակ առաջացնում է միջին կառուցվածքներ, որոնք կարող են մեկնաբան</abstract_hy>
      <abstract_az>Bu kağızda, biz quruluş bilən dökümənin məlumatlarından məlumatları öyrənməyə başlayırıq, danışma ayırıcısına və əlavə məlumatlarına qayıtmadan. Nəyral a ğlarını strukturlu bias ilə qüvvətləndirmək üçün yeni çabalardan ilham çəkilmək üçün (Cheng et al., 2016; Kim et al., 2017), zəngin strukturlu bağlılıqları təşkil edən bir modeli təklif edirik. Özellikle, biz müxtəlif bir proyektiv olmayan ayırma algoritmini nöral modeli içində yerləşdiririk və strukturlu tərzlərini birləşdirmək üçün gözləmə mehanizmilərini istifadə edirik. Müxtəlif işlər və veri qurduğu təcrübələrin müxtəlif təcrübələrində təcrübə etdiyi modellərin təcrübəsi və anlamlı məqsədilə müxtəlif qurduğu müxtəlif təcrübələrin sonuçlarına nail olacağını göstərir.</abstract_az>
      <abstract_bn>এই কাগজটিতে আমরা তথ্য থেকে প্রতিনিধিত্বের প্রতিনিধিত্ব শিখতে মনোযোগ দিচ্ছি কোন কথোপকথন প্যারার্স বা অতিরিক্ত বিব সাম্প্রতিক প্রচেষ্টা থেকে নিউরুল নেটওয়ার্ক কে ক্ষমতাশীল করার জন্য অনুপ্রাণিত করা হচ্ছে (চেঙ্গ আল, ২০১৬; কিম এন আল, ২০১৭), আমরা একটি মডেল প্রস্তাব করেছি যা একটি নথির বিশেষ করে আমরা একটি প্রজেক্টিভ অনলাইন পার্গোরিদমকে নিউরেল মডেলে বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন প্রজেক্টিভ পার্সিং করেছি এবং কা বিভিন্ন কাজ এবং ডাটাসেটগুলোর বিভিন্ন পরীক্ষার পরীক্ষার মূল্য দেখাচ্ছে যে প্রস্তাবিত মডেলের রাষ্ট্র-শিল্পের ফলাফল পাওয়া যাচ্ছে নথির</abstract_bn>
      <abstract_bs>U ovom papiru, fokusiramo se na predstavljanja dokumenta koji znaju strukturu bez preusmjerenja na pretraživač diskusija ili dodatne annotacije. Nacrtajući inspiraciju iz nedavnih napora na jačanje neuronskih mreža sa strukturnim predrasudama (Cheng et al., 2016; Kim et al., 2017), predlažemo model koji može kodirati dokument dok automatski inducira bogate strukturne zavisnosti. Posebno, ugrađujemo različitog neoprojektivnog algoritma za analizu u neuralni model i koristimo mehanizme pažnje da bi uključili strukturne predrasude. Eksperimentalne procjene u raznim zadacima i setima podataka pokazuju da predloženi model postigne rezultate state-of-the-art na modelirajućim zadacima dokumenta dok induciraju prosječne strukture koje su interpretabilne i smislene.</abstract_bs>
      <abstract_cs>V tomto článku se zaměřujeme na učení se strukturově orientovanými reprezentacemi dokumentů z dat bez použití diskurzního parseru nebo dalších anotací. Čerpáme inspiraci z nedávných snah o posílení neuronových sítí se strukturálním biasem (Cheng et al., 2016; Kim et al., 2017) a navrhujeme model, který dokáže kódovat dokument a automaticky vyvolávat bohaté strukturální závislosti. Konkrétně vkládáme do neuronového modelu diferencovatelný non-projektivní parsovací algoritmus a používáme mechanismy pozornosti k začlenění strukturálních předsudků. Experimentální vyhodnocení napříč různými úlohami a datovými sadami ukazují, že navržený model dosahuje nejmodernějších výsledků u úloh modelování dokumentů a zároveň indukuje meziproduktivní struktury, které jsou interpretovatelné i smysluplné.</abstract_cs>
      <abstract_ca>En aquest article, ens centrem en aprendre representacions documentals conscients de l'estructura a partir de dades sense recurrir a un analitzador de discurs o anotacions adicionals. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Concretament, vam incorporar un algoritme d'analització diferenciable i no projeccionable en un model neural i vam utilitzar mecanismes d'atenció per incorporar els prejudicis estructurals. Evaluacions experimentals a través de diverses tasques i conjunts de dades demostren que el model proposat aconsegueix resultats més avançats en tasques de modelació de documents mentre indueix estructures intermedies que són interpretables i significatives.</abstract_ca>
      <abstract_af>In hierdie papier, ons fokus op die leer van struktuur-bevestig dokument voorstellings van data sonder herrekurs na 'n diskursie ontwerker of addisionele annotasies. Teken inspirasie van onlangse versoekte om neuralnetwerke te versterk met 'n strukturele bias (Cheng et al., 2016; Kim et al., 2017), ons voorstel 'n model wat 'n dokument kan kodeer terwyl automaties ryk strukturele afhanklikhede verkondig kan word. Spesifieke, ons inbêer 'n verskillende non-projektiewe verwerking algoritme in 'n neurale model en gebruik aandag mekanisme om die strukturele biases te inkorporeer. Eksperimentele evaluasies oor verskillende opdragte en datastelle vertoon dat die voorgestelde model bereik staat-van-die-kunstens resultate op dokumentmodellering opdragte terwyl die middelste strukture wat beide uittelbare en betekende is.</abstract_af>
      <abstract_et>Käesolevas töös keskendume struktuuriteadlike dokumentide esitamise õppimisele andmetest ilma diskursuse parserit või täiendavaid märkusi kasutamata. Tuginedes inspiratsiooni hiljutistest jõupingutustest tugevdada struktuurilise kalduvusega neurovõrke (Cheng et al., 2016; Kim et al., 2017), pakume välja mudeli, mis suudab dokumenti kodeerida, tekitades samas automaatselt rikkalikke struktuurilisi sõltuvusi. Täpsemalt lisame neuraalmudelisse diferentseeritava mitteprojektiivse parsimise algoritmi ja kasutame tähelepanumehhanisme struktuuriliste kallakute kaasamiseks. Erinevate ülesannete ja andmekogumite eksperimentaalsed hindamised näitavad, et kavandatud mudel saavutab dokumendi modelleerimise ülesannete puhul kaasaegseid tulemusi, tekitades samal ajal vahelisi struktuure, mis on nii tõlgendatavad kui ka mõttekad.</abstract_et>
      <abstract_fi>Tässä artikkelissa keskitytään oppimaan rakenteeseen perustuvia asiakirjaesityksiä datasta ilman diskurssin jäsentäjää tai lisähuomautuksia. Inspiraation pohjalta viimeaikaisista pyrkimyksistä vahvistaa neuroverkkoja rakenteellisesti (Cheng et al., 2016; Kim et al., 2017) ehdotamme mallia, joka pystyy koodaamaan asiakirjan ja automaattisesti indusoimaan rikkaita rakenteellisia riippuvuuksia. Erityisesti upotamme erilaistuvan ei-projektiivisen jäsennysalgoritmin neuromalliin ja käytämme huomiomekanismeja rakenteellisten vääristymien sisällyttämiseen. Kokeelliset arvioinnit eri tehtävistä ja aineistoista osoittavat, että ehdotetulla mallilla saavutetaan viimeisimpiä tuloksia dokumenttien mallinnustehtävissä samalla kun luodaan sekä ymmärrettäviä että merkityksellisiä välirakenteita.</abstract_fi>
      <abstract_sk>V tem prispevku se osredotočamo na učenje strukturnih predstavitev dokumentov iz podatkov brez uporabe razčlenjevalnika diskurza ali dodatnih opomb. Črpamo navdih iz nedavnih prizadevanj za opolnomočenje nevronskih omrežij s strukturno pristranskostjo (Cheng et al., 2016; Kim et al., 2017), predlagamo model, ki lahko kodira dokument, hkrati pa samodejno inducira bogate strukturne odvisnosti. Natančneje, v nevronski model vključimo diferencialni neprojektivni algoritem razčlenjevanja in uporabljamo mehanizme pozornosti za vključitev strukturnih pristranskosti. Eksperimentalne ocene različnih nalog in podatkovnih nizov kažejo, da predlagani model dosega najsodobnejše rezultate pri opravilih modeliranja dokumentov, hkrati pa inducira vmesne strukture, ki so tako razložljive kot smiselne.</abstract_sk>
      <abstract_jv>deep Awakdhéwé éntuk arnong sing nggawe aturan sing nggawe tambah nyebuturan karo structural bias CURRENTCURRENT Where's the reference</abstract_jv>
      <abstract_he>בעיתון הזה, אנו מתמקדים ללמוד מייצגים מסמכים מודעים למבנה ממידע ללא שימוש במחקר דיבורים או הערות נוספות. ציירת השראה ממאמצים לאחרונה כדי להפעיל רשתות עצביות בעזרת ההתמחות המבנית (Cheng et al., 2016; Kim et al., 2017), אנו מציעים מודל שיכול לקוד מסמך בזמן שגורם באופן אוטומטי תלויות מבנה עשירות. במיוחד, אנחנו מכניסים אלגוריתם בדיקת לא פרויקטיבי שונה למודל עצבי ולהשתמש במנגנוני תשומת לב כדי להכיל את ההתמונות המבנית. הערכות ניסיוניות ברחבי משימות ומערכות נתונים שונות מראות שהמודל המוצע משיג תוצאות מוקדמות על משימות דוגמניות מסמכים בזמן שגורמות מבנים בינויים שיכולים לפרש ולא משמעותיים.</abstract_he>
      <abstract_ha>Ga wannan takardan, Munã fokus a kan karatun karatun takardar da aka sani na rubutu daga data, kuma bã za mu iya samu zuwa wani salon da aka yi mazaɓa ko wata takardar da aka ƙara. Kuwo hamoyi daga aikin kwanan nan zuwa ga ya iya ƙara wa zane tarayya na neurar da wani bashaske (Tsing et, 2016; Kim et al., 2017), za'a goyya da wani motsi wanda ke iya kodi takarda da farat-ƙaranci masu bakarãrar rubutu. A ƙayyade, mun sami algoritm mai rarraba da shi ba-projeko ko zuwa wani motsi na neura kuma muka yi amfani da matsayin muhimmanci dõmin ya shigar da shi a cikin firam. Ana ƙidãya kowace aikin da aka samu'a cikin wasu aikin da aka sani yana nuna cewa, shirin da aka buƙata yana sami matsalar-halin-sanannin a kan aikin yin motsi na dokuman da za'a ƙãga masu fasahawa da masu muhimmi.</abstract_ha>
      <abstract_bo>In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional annotations. དབུས་གཞུང་གི་ལྟ་བུའི་ནང་དུ་ཡོད་པ་ལས་སྐྱེས་ཚུལ་འདྲེན་དགོས་པ་ཞིག་ཡོད། དམིགས་བསལ་ནི། ང་ཚོས་དབྱིབས་དང་ཁྱད་པར་མེད་རྐྱེན་པའི་གྲངས་སྒྲིག་གི་སྐྱེས་སྟངས་ཅིག་སྒྲིག་འཇུག་བྱེད་ཀྱི་མིན་འདུག Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.</abstract_bo>
      </paper>
    <paper id="7">
      <title>Towards Evaluating Narrative Quality In Student Writing</title>
      <author><first>Swapna</first><last>Somasundaran</last></author>
      <author><first>Michael</first><last>Flor</last></author>
      <author><first>Martin</first><last>Chodorow</last></author>
      <author><first>Hillary</first><last>Molloy</last></author>
      <author><first>Binod</first><last>Gyawali</last></author>
      <author><first>Laura</first><last>McCulla</last></author>
      <doi>10.1162/tacl_a_00007</doi>
      <abstract>This work lays the foundation for automated assessments of narrative quality in student writing. We first manually score <a href="https://en.wikipedia.org/wiki/Essay">essays</a> for narrative-relevant traits and sub-traits, and measure inter-annotator agreement. We then explore linguistic features that are indicative of good narrative writing and use them to build an automated scoring system. Experiments show that our <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> are more effective in scoring specific aspects of <a href="https://en.wikipedia.org/wiki/Narrative">narrative quality</a> than a state-of-the-art <a href="https://en.wikipedia.org/wiki/Software_feature">feature set</a>.</abstract>
      <pages>91–106</pages>
      <url hash="99a14735">Q18-1007</url>
      <video href="https://vimeo.com/276372446" />
      <bibkey>somasundaran-etal-2018-towards</bibkey>
    <title_ar>نحو تقييم جودة السرد في كتابة الطالب</title_ar>
      <title_es>Hacia la evaluación de la calidad narrativa en la escritura</title_es>
      <title_pt>Para avaliar a qualidade narrativa na escrita do aluno</title_pt>
      <title_fr>Vers l'évaluation de la qualité narrative des textes des élèves</title_fr>
      <title_ja>生徒の書き込みにおけるナレーションの質の評価に向けて</title_ja>
      <title_zh>评诸生叙事质量</title_zh>
      <title_hi>छात्र लेखन में कथा गुणवत्ता का मूल्यांकन करने की दिशा में</title_hi>
      <title_ru>На пути к оценке качества повествования в письменной форме учащихся</title_ru>
      <title_ga>I dTreo Cáilíochta Inste a Mheas i Scríbhneoireacht na nDaltaí</title_ga>
      <title_hu>A narratív minőség értékelése a diákok írásában</title_hu>
      <title_ka>სტუდენტების წერილის ნარატიგური კაalitეტის განსაზღვრება</title_ka>
      <title_el>Προς την αξιολόγηση της αφηγηματικής ποιότητας στη συγγραφή φοιτητών</title_el>
      <title_it>Verso la valutazione della qualità narrativa nella scrittura degli studenti</title_it>
      <title_kk>Студенттердің жазуындағы нарративті сапатты оқу үшін</title_kk>
      <title_lt>Student ų rašymo kokybės vertinimo link</title_lt>
      <title_ml>വിദ്യാര്‍ത്ഥിയില്‍ എഴുതുന്നതിനുള്ള വിവരങ്ങള്‍ മുകളിലേക്ക് പരിശോധിക്കുന്നു</title_ml>
      <title_mk>Надвор кон проценката на приказната за квалитетот во пишувањето на студентите</title_mk>
      <title_ms>Ke arah Evaluasi Kualiti Narratif Dalam Penulisan Murid</title_ms>
      <title_mt>Towards Evaluating Narrative Quality In Student Writing</title_mt>
      <title_mn>Оюутнуудын бичих чадварыг үнэлэх рүү</title_mn>
      <title_pl>W kierunku oceny jakości narracji w pisaniu studentów</title_pl>
      <title_no>Til evaluering av narrative kvalitet i studentskriving</title_no>
      <title_ro>Către evaluarea calității narative în scrierea studenților</title_ro>
      <title_sr>Prema procjenu narativne kvalitete u pisanju studenata</title_sr>
      <title_sv>Mot utvärdering av berättarkvalitet i studentskrivning</title_sv>
      <title_ta>மாணவன் எழுதுவதில் விளக்கமான தரம் மதிப்பை மதிப்பிடுகிறது</title_ta>
      <title_si>විද්‍යාඥික ලිපිනයේ අවශ්‍යාවක් විශ්වාස කරන්න</title_si>
      <title_so>Towards assessing Narrative quality In Student Writing</title_so>
      <title_ur>استاد لکھنے میں ناراریٹی کیفیت کا ارزش کرنے کی طرف</title_ur>
      <title_uz>Avto- yozish</title_uz>
      <title_vi>Để đánh giá chất lượng đĩa thịt trong văn học</title_vi>
      <title_hr>Prema procjenu narativne kvalitete u pisanju studenata</title_hr>
      <title_bg>Към оценка на качеството на разказите в студентското писане</title_bg>
      <title_nl>Naar het evalueren van narratieve kwaliteit in het schrijven van studenten</title_nl>
      <title_da>På vej mod evaluering af fortællingskvalitet i elevskrivning</title_da>
      <title_id>Menuju Evaluasi Kualitas Narratif Dalam Penulisan Murid</title_id>
      <title_ko>학생 작문에서 서사의 질에 대한 평가</title_ko>
      <title_fa>به ارزیابی کیفیت مصنوعی در نوشتن دانش آموزان</title_fa>
      <title_de>Auf dem Weg zur Bewertung der narrativen Qualität im studentischen Schreiben</title_de>
      <title_sw>Kupitia Utawala wa Kihafidhina Katika Wanafunzi Kuandika</title_sw>
      <title_tr>Okuwçylar ýazmasynda näsazlyk kwaliteti Taýýarlamak üçin</title_tr>
      <title_af>Na die evaluering van Narratiewe Kwaliteit in Studente Skryf</title_af>
      <title_sq>Towards Evaluating Narrative Quality In Student Writing</title_sq>
      <title_hy>Աշակերտների գրության մեջ նմանատիպ որակի գնահատման ուղղությամբ</title_hy>
      <title_az>√Ėńürencil…ôr YazńĪlńĪŇüńĪnda Narrativ Keyfiyy…ôti QńĪdńĪmlama t…ôr…ôfind…ô</title_az>
      <title_am>ተማሪ ጽሑፍ</title_am>
      <title_bs>Prema procjenu narrativne kvalitete u pisanju studenata</title_bs>
      <title_cs>K hodnocení kvality vyprávění ve studentském psaní</title_cs>
      <title_et>Õpilaste kirjutamise narratiivse kvaliteedi hindamise suunas</title_et>
      <title_bn>Towards Evaluating Narrative Quality In Student Writing</title_bn>
      <title_ca>Vers l'Evaluació de la qualitat narrativa en l'escriptura d'estudiants</title_ca>
      <title_fi>Opiskelijoiden kirjoittamisen narratiivisen laadun arviointi</title_fi>
      <title_jv>Tarjamahan Kapalitat Narrate</title_jv>
      <title_he>לכיוון הערכה של איכות תספורת בכתיבה של סטודנטים</title_he>
      <title_ha>@ action</title_ha>
      <title_sk>K vrednotenju kakovosti pripovedi v študentskem pisanju</title_sk>
      <title_bo>ཤེས་རིག་བྲི་པར་ནང་ལྡན་རིམ་དཔྱད་ཚད་ལྟར་མཁན་</title_bo>
      <abstract_ar>يضع هذا العمل الأساس للتقييمات الآلية للجودة السردية في كتابة الطلاب. نقوم أولاً بتسجيل المقالات يدويًا للسمات والسمات الفرعية ذات الصلة بالسرد ، وقياس اتفاقية المعلقين. ثم نستكشف الميزات اللغوية التي تدل على الكتابة السردية الجيدة ونستخدمها لبناء نظام تسجيل آلي. تُظهر التجارب أن ميزاتنا أكثر فاعلية في تسجيل جوانب معينة من جودة السرد من مجموعة الميزات الحديثة.</abstract_ar>
      <abstract_es>Este trabajo sienta las bases para las evaluaciones automatizadas de la calidad narrativa en la escritura de los estudiantes. Primero calificamos manualmente los ensayos para detectar rasgos y sub-rasgos relevantes para la narrativa, y medimos la concordancia entre anotadores. Luego exploramos las características lingüísticas que son indicativas de una buena redacción narrativa y las utilizamos para crear un sistema de puntuación automatizado. Los experimentos demuestran que nuestras funciones son más eficaces a la hora de calificar aspectos específicos de la calidad narrativa que un conjunto de funciones de última generación.</abstract_es>
      <abstract_fr>Ce travail jette les bases des évaluations automatisées de la qualité narrative des textes des élèves. Nous notons d'abord manuellement les dissertations pour les traits et les sous-traits pertinents pour la narration, et nous mesurons l'accord entre les annotateurs. Nous explorons ensuite les caractéristiques linguistiques qui indiquent une bonne rédaction narrative et les utilisons pour créer un système de notation automatisé. Les expériences montrent que nos fonctionnalités sont plus efficaces pour noter des aspects spécifiques de la qualité narrative qu'un ensemble de fonctionnalités de pointe.</abstract_fr>
      <abstract_pt>Este trabalho estabelece as bases para avaliações automatizadas da qualidade narrativa na escrita dos alunos. Primeiro, avaliamos manualmente as redações para traços e subtraços relevantes para a narrativa e medimos a concordância entre os anotadores. Em seguida, exploramos características linguísticas que são indicativas de uma boa escrita narrativa e as usamos para construir um sistema de pontuação automatizado. Experimentos mostram que nossos recursos são mais eficazes na pontuação de aspectos específicos da qualidade narrativa do que um conjunto de recursos de última geração.</abstract_pt>
      <abstract_ja>この研究は、学生の執筆における物語の質の自動評価の基礎を築いている。まず、物語に関連する形質とサブ形質のエッセイを手動で採点し、注釈者間の合意を測定します。次に、優れた物語的書き方を示す言語学的特徴を探求し、それらを使用して自動スコアリングシステムを構築します。実験によると、当社の機能は、最先端の機能セットよりも、物語の質の特定の側面をスコアリングするのに効果的であることが示されています。</abstract_ja>
      <abstract_zh>为诸生叙事者自定其基。 首手动其特征、子特征之文评分之,而量注释者之一致性。 然后探其叙事之言,而用之以自评分统。 实验明先进之功,评分于叙事之特定。</abstract_zh>
      <abstract_hi>यह काम छात्र लेखन में कथा गुणवत्ता के स्वचालित मूल्यांकन के लिए नींव रखता है। हम पहले कथा-प्रासंगिक लक्षणों और उप-लक्षणों के लिए मैन्युअल रूप से निबंध स्कोर करते हैं, और अंतर-एनोटेटर समझौते को मापते हैं। फिर हम भाषाई विशेषताओं का पता लगाते हैं जो अच्छे कथा लेखन का संकेत हैं और उनका उपयोग एक स्वचालित स्कोरिंग सिस्टम बनाने के लिए करते हैं। प्रयोगों से पता चलता है कि हमारी विशेषताएं एक अत्याधुनिक सुविधा सेट की तुलना में कथा गुणवत्ता के विशिष्ट पहलुओं को स्कोर करने में अधिक प्रभावी हैं।</abstract_hi>
      <abstract_ru>Эта работа закладывает основу для автоматизированных оценок качества повествования при написании студентами. Сначала мы вручную оцениваем эссе для характерных черт и подрисовок, относящихся к повествованию, и измеряем согласованность между аннотаторами. Затем мы исследуем лингвистические особенности, которые указывают на хорошее нарративное письмо, и используем их для создания автоматизированной системы подсчета баллов. Эксперименты показывают, что наши функции более эффективны в оценке конкретных аспектов качества повествования, чем набор современных функций.</abstract_ru>
      <abstract_ga>Leagann an obair seo an bonn le haghaidh measúnuithe uathoibrithe ar cháilíocht na hinsinte i scríbhneoireacht na scoláirí. Déanaimid aistí a scóráil de láimh ar dtús maidir le tréithe agus fo-thréithe a bhaineann le hinsint, agus tomhaisimid comhaontú idir-anótairí. Déanaimid iniúchadh ansin ar ghnéithe teangeolaíocha a léiríonn dea-scríbhneoireacht insinte agus úsáidimid iad chun córas scórála uathoibrithe a chruthú. Léiríonn turgnaimh go bhfuil ár ngnéithe níos éifeachtaí maidir le gnéithe sainiúla de cháilíocht na hinsinte a scóráil ná sraith gnéithe den scoth.</abstract_ga>
      <abstract_hu>Ez a munka lefekteti az alapot a narratív minőség automatizált értékelésének a hallgatói írásban. Először manuálisan értékelünk esszéket a narratív-releváns jellemzőkhöz és aljellemzőkhöz, és mérjük az inter-annotator megállapodást. Ezután feltárjuk azokat a nyelvi jellemzőket, amelyek a jó elbeszélésírásra utalnak, és felhasználjuk őket egy automatizált pontszámrendszer kialakítására. A kísérletek azt mutatják, hogy tulajdonságaink hatékonyabbak az elbeszélés minőségének konkrét aspektusainak pontozásában, mint egy korszerű játékkészlet.</abstract_hu>
      <abstract_ka>ეს სამუშაო სტუდენტის წერილებში ავტომატიური განსაზღვრებისთვის ფუნდაცია. ჩვენ პირველი ხელსახურად დავაწერეთ ესეები შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი და შესაბამისი შემდეგ ჩვენ ინდომისტიკური ფუნქციების გამოყენება, რომლებიც კარგი სიტყვების წერილების ინდინტიკურია და გამოყენება ისინი ავტომატიკური სკორინის სის ექსპერიმენტები გამოჩვენება, რომ ჩვენი განსაზღვრებები უფრო ეფექტიურია განსაზღვრებულ განსაზღვრებული განსაზღვრების განსაზღვრებისთვის, ვიდრე შესაძლებელ</abstract_ka>
      <abstract_el>Αυτή η εργασία θέτει τα θεμέλια για αυτοματοποιημένες αξιολογήσεις της αφηγηματικής ποιότητας στη συγγραφή φοιτητών. Πρώτα βαθμολογούμε χειροκίνητα δοκίμια για χαρακτηριστικά και υποχαρακτηριστικά που σχετίζονται με την αφήγηση και μετράμε τη συμφωνία μεταξύ σχολιαστών. Στη συνέχεια εξερευνούμε γλωσσικά χαρακτηριστικά που είναι ενδεικτικά της καλής αφηγηματικής γραφής και τα χρησιμοποιούμε για να χτίσουμε ένα αυτοματοποιημένο σύστημα βαθμολογίας. Τα πειράματα δείχνουν ότι τα χαρακτηριστικά μας είναι πιο αποτελεσματικά στη βαθμολογία συγκεκριμένων πτυχών της αφηγηματικής ποιότητας από ένα σύγχρονο σύνολο χαρακτηριστικών.</abstract_el>
      <abstract_mk>Оваа работа ја поставува основата за автоматизирани проценки на приказната за квалитетот во пишувањето на студентите. We first manually score essays for narrative-relevant traits and sub-traits, and measure inter-annotator agreement.  Потоа истражуваме јазични карактеристики кои покажуваат добра приказна и ги користиме за да изградиме автоматизиран систем на оценка. Експериментите покажуваат дека нашите карактеристики се поефикасни во оценката на специфичните аспекти на раскажувачкиот квалитет отколку на најсовремените карактеристики.</abstract_mk>
      <abstract_kk>Бұл жұмыс студенттердің жазуының автоматты түрде оқиғалардың негізін орнатады. Біз біріншіден сөйлеу қасиеттері мен ішкі қасиеттер үшін есептерді қолмен есептеп, белгілер арасындағы келесінің өлшемін. Содан кейін оларды автоматты сұрау жүйесін құру үшін қолданатын лингвистикалық қасиеттерді зерттеп, жақсы жазуды көрсетеді. Тәжірибелер біздің мүмкіндіктеріміз оқиғалық сапасының арнаулы аспектеріне көмектесетінін көрсетеді.</abstract_kk>
      <abstract_it>Questo lavoro pone le basi per valutazioni automatiche della qualità narrativa nella scrittura degli studenti. Per prima cosa segniamo manualmente i saggi per tratti e sotto-tratti narrativi rilevanti, e misuriamo l'accordo tra gli annotatori. Esploriamo poi le caratteristiche linguistiche che sono indicative di una buona scrittura narrativa e le usiamo per costruire un sistema di punteggio automatizzato. Gli esperimenti dimostrano che le nostre caratteristiche sono più efficaci nel segnare aspetti specifici della qualità narrativa di un set di funzionalità all'avanguardia.</abstract_it>
      <abstract_lt>Šis darbas sudaro pagrindą automatizuotam moksleivių rašymo istorijos kokybės vertinimui. Pirmiausia rankiniu būdu surenkame egzaminus, susijusius su istoriniais požymiais ir požymiais, ir matuojame tarpanotatorių susitarimą. Tada tiriame kalbines savybes, rodančias gerą narracinį rašymą, ir naudojame jas automatizuotai įvertinimo sistemai sukurti. Eksperimentai rodo, kad mūsų savybės yra veiksmingesnės vertinant konkrečius narracinės kokybės aspektus nei naujausias savybes.</abstract_lt>
      <abstract_ml>വിദ്യാര്‍ത്ഥിയുടെ എഴുത്തില്‍ സ്വയം ചരിത്രത്തിന്റെ വിശദീകരണങ്ങള്‍ക്കുള്ള അടിസ്ഥാനമാണിത്. നമ്മള്‍ ആദ്യം വിവരിച്ചിരിക്കുന്ന കഥാര്‍ത്ഥത്തിനും സബ് ട്രേയിറ്റിനും വേണ്ടിയുള്ള വിവരങ്ങള്‍ കൈകാര്യം ചെയ്യ പിന്നീട് നമ്മള്‍ ഭാഷ വിവരങ്ങള്‍ പരിശോധിക്കുന്നു. നല്ല വിവരങ്ങള്‍ എഴുതുന്നതിന്‍റെ അടയാളങ്ങളാണ്. അത് സ്വയം സ്കോര്‍ട്ട്  പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ വിശേഷതകള്‍ വിവരങ്ങളുടെ വിശിഷ്ടമായ സ്ഥാനത്തേക്കാള്‍ പ്രത്യേകിച്ച</abstract_ml>
      <abstract_ms>Kerja ini menetapkan dasar untuk penilaian automatik kualiti cerita dalam tulisan pelajar. Kami pertama secara manual skor essai untuk ciri-ciri dan subciri-ciri yang berkaitan dengan cerita, dan ukur kesepakatan antar-annotator. Kemudian kami mengeksplorasi ciri-ciri bahasa yang menunjukkan penulisan cerita yang baik dan menggunakannya untuk membina sistem skor automatik. Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.</abstract_ms>
      <abstract_mn>Энэ ажил оюутнуудын бичиж бичих түүх чадварын автоматжуулалтын үнэлгээ үүсгэдэг. Эхлээд бид түүхийн тухай харилцааны чанар, суб-чанарын эссийг гараараа тооцоолж, харилцааны зөвлөлтийг хэмжиж байна. Дараа нь бид сайн зохиолын бичиж чаддаг хэлний чадварыг судалж автоматжуулсан сүлжээний системийг бүтээхэд хэрэглэдэг. Эмчилгээний туршилтууд бидний харилцааны чанарын тодорхойлолтой талаар урлагийн төвшин чанараас илүү үр дүнтэй гэдгийг харуулдаг.</abstract_mn>
      <abstract_mt>Dan ix-xogħol jistabbilixxi l-bażi għal valutazzjonijiet awtomatizzati ta’ kwalità narrattiva fl-kitba tal-istudenti. Aħna l-ewwel nagħmlu eżamijiet manwali għal karatteristiċi u sottokaratteristiċi relattivi, u nqisu ftehim bejn l-annotaturi. Imbagħad nesploraw karatteristiċi lingwistiċi li huma indikattivi ta’ kitba narrattiva tajba u nużahom biex nibnu sistema awtomatizzata ta’ punteġġi. L-esperimenti juru li l-karatteristiċi tagħna huma aktar effettivi fil-valutazzjoni ta’ aspetti speċifiċi ta’ kwalità narrattiva minn sett ta’ karatteristiċi l-aktar avvanzati.</abstract_mt>
      <abstract_no>Dette arbeidet legger fundamentet for automatiske evaluering av storatyrkvalitet i studentskriving. Vi prøver først manuelt oppdagingsessar for historiske relevante eigenskapar og undertraitar, og målar inter- annotatorsavtale. Vi så utforskar språkstiske funksjonar som er indikator for godt historisk skriving og brukar dei for å bygge eit automatisk oppløysing. Eksperimentar viser at funksjonane våre er meir effektive i å sjå spesifikke aspektar av narrativ kvalitet enn ein innstilling av kunstfunksjonen.</abstract_no>
      <abstract_pl>Praca ta stanowi podstawę zautomatyzowanej oceny jakości narracji w pisaniu studentów. Najpierw ręcznie oceniamy eseje dla cech istotnych dla narracji i podcech oraz mierzymy zgodność między adnotatorami. Następnie badamy cechy językowe, które wskazują na dobre pisanie narracji i wykorzystujemy je do zbudowania zautomatyzowanego systemu punktowania. Eksperymenty pokazują, że nasze funkcje są bardziej skuteczne w ocenie konkretnych aspektów jakości narracji niż najnowocześniejszy zestaw funkcji.</abstract_pl>
      <abstract_ro>Această lucrare pune bazele evaluărilor automate ale calității narative în scrierea studenților. Mai întâi înscriem manual eseuri pentru trăsături și subtrăsături relevante naraționale și măsurăm acordul inter-adnotator. Apoi explorăm caracteristicile lingvistice care indică o bună scriere narativă și le folosim pentru a construi un sistem automat de scoring. Experimentele arată că caracteristicile noastre sunt mai eficiente în punctarea unor aspecte specifice ale calității narative decât un set de caracteristici de ultimă generație.</abstract_ro>
      <abstract_sr>Ovaj rad stavlja temelj za automatsku procjenu priče kvalitete u pisanju studenata. Prvo ručno rezultiramo eseje za priče relevantne osobine i podosobine i mjerimo sporazum međuannotatora. Onda istražujemo lingvističke karakteristike koje su indikativne dobrog pisanja priče i koristimo ih za izgradnju automatskog sistema izvlačenja. Eksperimenti pokazuju da su naša karakteristika učinkovitija u izveštaju specifičnih aspekta priče kvalitete nego u setu stanja umjetnosti.</abstract_sr>
      <abstract_si>මේ වැඩේ ස්වයංක්‍රීය විද්‍යාපිත විද්‍යාපිත විශේෂයේ ස්වයංක්‍රීය විද්‍යාපයක් ගැන ස්වයං අපි මුලින්ම පළවෙනි ස්කෝර් එක්ක සංවේදනය සහ සබ් විශේෂතාවක් සඳහා ස්කෝර් එක්කම් කරනවා. ඊට පස්සේ අපි භාෂාවික විශේෂතාවක් පරීක්ෂණය කරනවා ඒ වගේම හොඳ කතාවක් ලියනය සහ ඔවුන්ව ස්වයංක්‍රීය ස පරීක්ෂණය පෙන්වන්නේ අපේ විශේෂතාවට විශේෂ ප්‍රතිශේෂතාවට වඩා විශේෂ ප්‍රතිශේෂතාවට ප්‍රතිශේෂ වි</abstract_si>
      <abstract_ur>یہ کام استادی لکھنے میں داستان کی کیفیت کی آٹوٹی ارزیابی کے لئے بنیاد رکھتا ہے. ہم پہلی بار اپنے ہاتھ سے آزمائش کررہے ہیں کہانیاں کے معاملہ دار شخصیتیں اور زیر خاصیات کے لئے، اور بیٹی آزمائش کرنے والے معاملہ کا اندازہ کررہے ہیں. پھر ہم زبان صحیح تعریف کرتے ہیں جو اچھی داستان صحیح لکھنے کی نشانی دیتے ہیں اور ان کو استعمال کرتے ہیں کہ ایک آٹوٹی اسکورینگ سیستم بنائیں۔ تجربے دکھاتے ہیں کہ ہماری ویژگی ایک ایسی موجود آرتی ویژگی سے زیادہ مثبت ہے</abstract_ur>
      <abstract_so>This work lays the foundation for automated assessments of narrative quality in student writing.  Marka ugu horeysa waxaynu qornaa koorasyo ku saabsan ganacsiga iyo hoos-socodka, waxaynu qiyaynaynaa heshiiska kala dhexeeya. Markaas waxaynu baaraynaa tayooyin luuqadeed oo ku qoran qoraalka wanaagsan, waxaadna u isticmaalaynaa si aan u dhisno nidaam jimicsiga oo gaar ah. Imtixaanka waxaa muuqda in tayada ay ka faa’iido badan yihiin in ay kooban yihiin dhinacyo gaar ah oo qiimaha saameyn ah oo ay ka shaqeeyaan xaaladda farshaxanka.</abstract_so>
      <abstract_sv>Detta arbete lägger grunden för automatiserade bedömningar av berättande kvalitet i studentskrivning. Vi gör först manuellt uppsatser för berättande-relevanta drag och underdrag, och mäter inter-annotator överenskommelse. Vi utforskar sedan språkliga egenskaper som tyder på bra berättarskrift och använder dem för att bygga ett automatiserat poängsystem. Experiment visar att våra funktioner är mer effektiva när det gäller att poängtera specifika aspekter av narrativ kvalitet än en state-of-the-art funktionsuppsättning.</abstract_sv>
      <abstract_ta>இந்த வேலை மாணவன் எழுதுவதில் தானியங்கிய செய்தியின் மதிப்புகளுக்கு அடித்தளத்தை அமைக்கிறது. நாம் முதல் கைமுறையாக சொல்லும் வியாபாரத்திற்கும் துணை வழிகளுக்கும் புள்ளிகளை மதிப்பிடுகிறோம், மற்றும் இடையே  பின்னர் நாம் மொழி குணங்களை கண்டுபிடிப்போம் நல்ல கதை எழுதுதல் குறிப்புகள் மற்றும் தானியங்கிய மதிப்பெண் அமைப்பை உர சோதனைகள் காண்பிக்கப்பட்டுள்ளது என்றால் நமது தன்மைகள் செயல்படுத்தப்படுகிறது சொல்லும் தரத்தின் குறிப்பிட்ட பாகங்களை மதிப்</abstract_ta>
      <abstract_uz>Bu ishni o'quvchi o'quvchi o'qituvchi qiymatni avtomatik o'qituvchi asosini yaratadi. Biz birinchi qo'lbola aytganimiz ma'lumotga bog'liq suhbat va tub suhbat sohasini qo'llab qo'llanmalamiz va narsalarning inter-annotator heshimini o'ylaymiz. Keyin biz yaxshi tarixi yozuvga ega bo'lgan tillar xususiyatlarini aniqlamiz va ularni avtomatik qiymatlash tizimini yaratishdan foydalanamiz. Tajribalar shunday ko'rsatadi, bizning xususiyatlarimiz tarixi sifatini qidirishdan foydalanishimiz mumkin.</abstract_uz>
      <abstract_vi>Việc này đặt nền tảng cho việc đánh giá tự động chất lượng lời kể trong viết thư sinh viên. Chúng tôi lần đầu tiên ghi bài luận về các đặc điểm liên quan câu chuyện và tiểu phẩm, và đo thỏa thuận liên tục. Sau đó chúng ta khám phá các tính năng ngôn ngữ chỉ dẫn việc viết truyện tốt và sử dụng chúng để xây dựng một hệ thống ghi điểm tự động. Các thí nghiệm cho thấy chúng tôi có hiệu quả hơn trong việc ghi nhận các khía cạnh cụ thể của cốt truyện nhiều hơn là bộ phim hiện đại.</abstract_vi>
      <abstract_da>Dette arbejde lægger fundamentet for automatiserede vurderinger af fortællingskvalitet i elevskrivning. Vi scorer først manuelt essays for fortællingsrelevante træk og undertræk, og måler inter-annotator aftale. Vi undersøger derefter sproglige træk, der indikerer god fortællingsskrift, og bruger dem til at opbygge et automatiseret scoresystem. Eksperimenter viser, at vores funktioner er mere effektive til at score specifikke aspekter af fortællingskvaliteten end et state-of-the-art feature sæt.</abstract_da>
      <abstract_nl>Dit werk legt de basis voor geautomatiseerde beoordelingen van narratieve kwaliteit in het schrijven van studenten. We scoren eerst handmatig essays op verhalende eigenschappen en subkenmerken en meten de overeenkomst tussen annotatoren. Vervolgens onderzoeken we taalkundige kenmerken die indicatief zijn voor goed verhalend schrijven en gebruiken ze om een geautomatiseerd scoresysteem op te bouwen. Experimenten tonen aan dat onze functies effectiever zijn in het scoren van specifieke aspecten van narratieve kwaliteit dan een state-of-the-art feature set.</abstract_nl>
      <abstract_bg>Тази работа поставя основите за автоматизирани оценки на качеството на разказа в студентското писане. Първо ръчно оценяваме есета за релевантни черти и подчерти и измерваме съгласието между анотаторите. След това изследваме езиковите характеристики, които са показателни за добро писане на разкази и ги използваме за изграждане на автоматизирана система за оценка. Експериментите показват, че нашите функции са по-ефективни при оценяване на специфични аспекти на качеството на разказа, отколкото най-съвременните функции.</abstract_bg>
      <abstract_de>Diese Arbeit legt die Grundlage für automatisierte Bewertungen der narrativen Qualität im studentischen Schreiben. Zunächst bewerten wir Essays manuell nach erzählungsrelevanten Merkmalen und Untermerkmalen und messen Inter-Annotator Übereinstimmung. Anschließend untersuchen wir linguistische Merkmale, die für gutes narratives Schreiben kennzeichnen und verwenden sie, um ein automatisiertes Bewertungssystem aufzubauen. Experimente zeigen, dass unsere Features bei der Bewertung bestimmter Aspekte der erzählerischen Qualität effektiver sind als ein State-of-the-Art Feature Set.</abstract_de>
      <abstract_id>Pekerjaan ini meletakkan dasar untuk penilaian otomatis kualitas cerita dalam penulisan siswa. Kita pertama-tama secara manual mencetak esei untuk ciri-ciri dan subciri-ciri yang relevan cerita, dan mengukur kesepakatan inter annotator. Kemudian kami mengeksplorasi fitur bahasa yang menunjukkan penulisan cerita yang baik dan menggunakannya untuk membangun sistem skor otomatis. Eksperimen menunjukkan bahwa ciri-ciri kita lebih efektif dalam mencetak aspek spesifik kualitas cerita daripada set ciri-ciri terbaik.</abstract_id>
      <abstract_hr>Ovaj rad stavlja temelj za automatsku procjenu priče kvalitete u pisanju učenika. Prvo ručno rezultiramo eseje za priče relevantne osobine i podosobine i mjerimo sporazum međuannotatora. Onda istražujemo jezičke karakteristike koje pokazuju dobru priču pisanje i koristimo ih za izgradnju automatskog sustava izvlačenja. Eksperimenti pokazuju da su naša karakteristika učinkovitija u izvještaju specifičnih aspekta priče kvalitete nego u stanju umjetnosti.</abstract_hr>
      <abstract_ko>이 작업은 학생들의 창작에서 서사의 질을 자동으로 평가하는 데 기초를 다졌다.우리는 먼저 문장의 서사 관련 특징과 하위 특징을 수동으로 평가하고 주석자 간의 일치성을 평가한다.그리고 우리는 양호한 서사 쓰기의 언어 특징을 탐색하고 이를 이용하여 자동 평가 시스템을 구축한다.실험에 의하면 가장 선진적인 기능집에 비해 우리의 기능은 서사의 질을 평가하는 특정한 방면에서 더욱 효과적이다.</abstract_ko>
      <abstract_sw>Kazi hii inaweka msingi kwa ajili ya kutathmini sifa za simulizi za wanafunzi kuandika. We first manually score essays for narrative-relevant traits and sub-traits, and measure inter-annotator agreement.  Kisha tunatafuta vipengele vya lugha ambavyo ni ishara ya kuandika hadithi nzuri na kutumia ili kujenga mfumo wa michezo. Majaribio yanaonyesha kuwa vipengele vyetu vina ufanisi zaidi katika kuchukua vipengele maalum vya ubora wa simulizi kuliko kipengele cha hali ya sanaa.</abstract_sw>
      <abstract_af>Hierdie werk lê die fondasie vir outomatiese evaluering van narratiewe kwaliteit in studente skryf. Ons maak eerste manuele besoeke vir narratiewe-relevante eienskappe en sub-eienskappe en maat inter-annotator ooreenkoms. Ons ondersoek dan lingwisiese funksies wat aanduidelik is van goeie narratiewe skryf en gebruik hulle om 'n outomatiese skoring stelsel te bou. Eksperimente wys dat ons eienskappe meer effektief is in spesifieke aspekte van narratiewe kwaliteit as 'n staat-van-kuns-funksie stel.</abstract_af>
      <abstract_tr>Bu i힊e okuw챌ylar 첵azmasynda a첵dym howplygyny흫 awtomatik ba첵ramlaryny 챌ykar첵ar. Biz ilkinji gezek d체zg체n hasaplar ve 철zellikler i챌in elimizde el 챌철z체mler 챌철z체mler ve 철rnek 챌철z체mler anla힊mas캇n캇 철l챌체r체z. Sonra biz g체zel heka첵at 첵azmasyny g철rke첵채n lingwistiki 철zellikleri ke힊fed첵채ris we olary흫 otomatik bir gol sistemasyny guramak 체챌in ullan첵arys. Experiimentlerimiz 챌yky힊larymyz heka첵at howplygyny흫 d체z체mlerinden has 첵체zerinde t채sirli bolandygyny g철rkez첵채r.</abstract_tr>
      <abstract_fa>این کار بنیادی برای ارزیابی خودکار از کیفیت داستان در نوشتن دانش آموزان قرار می دهد. ما اولین امتحان‌ها برای ویژگی‌های مربوط به داستان و زیر ویژگی‌ها و توافق‌های بین‌نویسنده‌ها را به دست می‌اندازیم. سپس ویژه‌های زبان‌شناسی را تحقیق می‌کنیم که نوشتن داستان‌شناسی خوبی را نشان می‌دهند و از آنها استفاده می‌کنیم تا یک سیستم آزمایش‌شناسی خودکار بسازند. تجربه‌ها نشان می‌دهند که ویژه‌های ما در جستجوی نقطه‌های ویژه‌ای از کیفیت داستان بیشتر از یک مجموعه‌ی ویژه‌های هنر موثر‌تر هستند.</abstract_fa>
      <abstract_sq>This work lays the foundation for automated assessments of narrative quality in student writing.  Ne së pari punojmë në mënyrë manuale esej për trashëgimi dhe nën-trashëgimi të lidhura me tregimet treguese dhe matëm marrëveshjen ndër-anotator. Pastaj eksplorojmë karakteristikat gjuhësore që tregojnë shkrimin e mirë të tregueshëm dhe i përdorim për të ndërtuar një sistem pikërimi automatik. Eksperimentet tregojnë se karakteristikat tona janë më efektive në shënimin e aspekteve specifike të cilësisë treguese sesa një komplet karakteristikë më të larta.</abstract_sq>
      <abstract_az>Bu işin öğrenci yazmağında hekayət kalitetinin otomatik təcrübələrinə qurulması üçün qurular. Biz ilk dəfə hökmləri və ilahi xüsusiyyətləri və ilahi xüsusiyyətləri üçün elə dəstəklə müəyyən edirik və müəyyən edən anlaşmaları ölçürük. Sonra da yaxşı hekayə yazmağı göstərən dillərin özelliklərini keşfetirik və onları automatik bir scoring sistemi inşa etmək üçün istifadə edirik. Həqiqətən, təcrübələrimiz xüsusiyyətlərimizin hekayət kalitetindən daha etkilidir.</abstract_az>
      <abstract_am>ይህ ሥራ ተማሪ ጽሕፈት የተማርነው ጥያቄ ጥያቄዎችን ለመፍጠር መሠረት ነው፡፡ ለመጀመሪያ የንግግር እና የግንኙነት ጉዳይ እና የግንኙነት ጉዳይ እናስቀድማለን እና የግንኙነት አስተያየት ቃል እናስቀምጣለን፡፡ ከዚያም በኋላ መልካም ታሪክ ጽሑፎችን የሚያሳየው የቋንቋዊ ጥያቄዎችን እናሳውቃለን፡፡ ፈተናዎች የ-አርእስት ግንኙነት ከመስመር ይልቅ የተለየ የታሪክ ጥያቄዎችን ለመቆጣጠር የሚያስፈልጋቸው ናቸው፡፡</abstract_am>
      <abstract_bn>এই কাজ শিক্ষার্থীদের লেখায় স্বয়ংক্রিয়ভাবে বর্ণনার মানের মূল্যের জন্য ভিত্তিক স্থাপন করে। আমরা প্রথম কাহিনীতে সংক্রান্ত ব্যবসা এবং সাবট্র্যাটের ব্যবস্থার জন্য কার্যক্রম স্কোর করি এবং বিভিন্ন বিষয়ের মধ্যে ব তারপর আমরা ভাষার বৈশিষ্ট্য অনুসন্ধান করি যা ভালো গল্প লেখার নির্দেশ দেয়া হয় এবং স্বয়ংক্রিয় স্কোরিং সিস্টেম তৈরি করা পরীক্ষাগুলো দেখাচ্ছে যে আমাদের বৈশিষ্ট্যাবলী মানের বিশেষ প্রতিক্রিয়া সংক্রান্ত বর্ণনা করার চেয়ে বেশী কার্যকর।</abstract_bn>
      <abstract_hy>Այս աշխատանքը հիմնադրում է աշակերտների գրության ավտոմատիկ որակի գնահատման հիմքը: Սկզբում մենք ձեռքով գնահատում ենք պատմվածքների և ենթահատկությունների էսսեները և չափում ենք ինտերնտոտորային համաձայնությունը: Այնուհետև մենք ուսումնասիրում ենք լեզվաբանական առանձնահատկություններ, որոնք լավ պատմություններ են տալիս գրելու և օգտագործում ենք դրանք ավտոմատիկ գնահատման համակարգի կառուցելու համար: Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.</abstract_hy>
      <abstract_bs>Ovaj rad stavlja temelj za automatsku procjenu priče kvalitete u pisanju studenata. Prvo ručno rezultiramo eseje za priče relevantne osobine i podosobine i mjerimo sporazum međuannotatora. Onda istražujemo jezičke karakteristike koje ukazuju na dobro pisanje priče i koristimo ih da izgradimo automatski sistem izvlačenja. Eksperimenti pokazuju da su naša karakteristika učinkovitija u izvještaju specifičnih aspekta priče kvalitete nego u setu stanja umjetnosti.</abstract_bs>
      <abstract_ca>Aquesta feina és la base de les evaluacions automatitzats de la qualitat narrativa en l'escriptura dels estudiants. Primer puntuem manualment els assais de trets i subtrets pertinents per a la narració, i mesurem l'acord entre anotators. Després explorem característiques lingüístices que indiquen una bona escriptura narrativa i les utilitzem per construir un sistema de puntuació automatitzat. Els experiments demostren que les nostres característiques són més eficaces en puntuar aspectes específics de la qualitat narrativa que un conjunt de característiques més avançats.</abstract_ca>
      <abstract_cs>Tato práce položí základ pro automatizované hodnocení kvality vyprávění v studentském psaní. Nejprve ručně skórujeme eseje pro vyprávění relevantní rysy a podrysy a měříme shodu mezi anotátory. Následně zkoumáme jazykové vlastnosti, které ukazují na dobré příběhové psaní a využíváme je k vytvoření automatizovaného bodovacího systému. Experimenty ukazují, že naše funkce jsou efektivnější při hodnocení konkrétních aspektů vyprávění než moderní sada funkcí.</abstract_cs>
      <abstract_et>See töö paneb aluse narratiivse kvaliteedi automatiseeritud hindamisele üliõpilaste kirjutamises. Esmalt hindame käsitsi esseesid narratiivselt oluliste tunnuste ja alamjoonte kohta ning mõõdame annotatoritevahelist kokkulepet. Seejärel uurime keelelisi omadusi, mis viitavad heale narratiivsele kirjutamisele ja kasutame neid automatiseeritud punktisüsteemi loomiseks. Eksperimentid näitavad, et meie funktsioonid on tõhusamad narratiivse kvaliteedi konkreetsete aspektide hindamisel kui kaasaegsed funktsioonikomplektid.</abstract_et>
      <abstract_fi>Tämä työ luo perustan opiskelijakirjoittamisen kerronnan laadun automaattiselle arvioinnille. Ensiksi pisteytämme esseet manuaalisesti kerronnallisiin ominaisuuksiin ja alaominaisuuksiin sekä mittaamme huomautusten välistä sopivuutta. Tämän jälkeen tutkimme kielellisiä ominaisuuksia, jotka viittaavat hyvään narratiiviseen kirjoittamiseen ja käytämme niitä automatisoidun pisteytysjärjestelmän rakentamiseen. Kokeet osoittavat, että ominaisuutemme ovat tehokkaampia selostuksen laadun erityispiirteiden pisteyttämisessä kuin uusin ominaisuussarja.</abstract_fi>
      <abstract_jv>Ombudhakan iki bakal nggawe sistem kanggo tukang mrogram sing apik dadi kapan ning acara dadi. Awak dhéwé wis ngubah manut kanggo tukang mrograh kanggo kalagayaan cara-cara ngono hasil cara-cara ngono kuwi nggawe tarjamahan kanggo ngubah ujaran Awak dhéwé éntuk akeh pernik-pernik ingkang liyane sing bisa nguasal kelas rambarang apik lan gambar dhéwé nggawe sistem sing otomatik. Name</abstract_jv>
      <abstract_he>העבודה הזו מסיימת את הבסיס להערכות אוטומטיות של איכות הסיפור בכתיבת סטודנטים. אנחנו קודם מבצעים בידיים עבור תכונות רלוונטיות לסיפורים ותחתונים, ומדוד הסכם בין המכתבים. ואז אנו חוקרים תכונות שפתיות שמראות לכתיבה טובה ונשתמש בהן כדי לבנות מערכת ציונים אוטומטית. ניסויים מראים שהתכונות שלנו יעילות יותר בכיוון חיונים ספציפיים של איכות הסיפור מאשר תכונות חדשות.</abstract_he>
      <abstract_sk>Delo postavlja temelje za avtomatizirano ocenjevanje kakovosti pripovedi v študentskem pisanju. Najprej ročno ocenimo eseje za pripovedne lastnosti in podlastnosti ter merimo soglasje med opombatorji. Nato raziskujemo jezikovne značilnosti, ki kažejo na dobro pripovedno pisanje in jih uporabljamo za izgradnjo avtomatiziranega sistema točkovanja. Eksperimenti kažejo, da so naše funkcije učinkovitejše pri ocenjevanju specifičnih vidikov kakovosti pripovedi kot vrhunski nabor funkcij.</abstract_sk>
      <abstract_ha>Wannan aikin yana dõgara a kan tunkuɗe yana iya ƙayyade sifori farat ɗaya a cikin littafin karatun. Ina sami karatun karatun masu da muhimmi na masu fasahan da masu husũma, kuma masu cika alkawarin da za'a yi taƙaita. Sa'an nan kuma Muke jarraba wasu mistakarda cikin harshen waɗanda ke cikin littãfin mai kyau na rubutu kuma Muke amfani da su dõmin su gina wani tsari na'urar kwamfyuta. Fijaroyi na nuna cewa masu iya amfani ga kofi masu tsari na tsari masu tsari daga halin-state-of-the-art.</abstract_ha>
      <abstract_bo>འདིས་ལས་ཀྱང་གིས་ཤེས་ཡིག་འབྲི་བརྗོད་པར་རང་བཞིན་གྱིས་རྨས་གཞི་བཞག་པ་དེ་རེད། ངེད་ཚོས་དང་པོ་ལ་སྤྱི་ཚོགས་འབྲེལ་བ་དང་ཁྱད་ཆོས་ཚོགས་དང་རྣམ་པ་ཚོགས་ལ་ལག་ཐོག་གི་བརྟག་དཔྱད་ཞིབ་བྱེད། འོན་ཀྱང་། ང་ཚོས་སྐད་ཡིག་ཆ་ལ་དམིགས་གཏོང་བ་ཡིན་པའི་སྐད་ཡིག་ཆ་ལ་ལྟ་ཞིབ Experiments show that our features are more effective in scoring specific aspects of narrative quality than a state-of-the-art feature set.</abstract_bo>
      </paper>
    <paper id="8">
      <title>Evaluating the Stability of Embedding-based Word Similarities</title>
      <author><first>Maria</first><last>Antoniak</last></author>
      <author><first>David</first><last>Mimno</last></author>
      <doi>10.1162/tacl_a_00008</doi>
      <abstract>Word embeddings are increasingly being used as a tool to study <a href="https://en.wikipedia.org/wiki/Word_association">word associations</a> in specific corpora. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents. We find that nearest-neighbor distances are highly sensitive to small changes in the training corpus for a variety of <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a>. For all <a href="https://en.wikipedia.org/wiki/Methodology">methods</a>, including specific documents in the training set can result in substantial variations. We show that these effects are more prominent for smaller training corpora. We recommend that users never rely on single embedding models for distance calculations, but rather average over multiple bootstrap samples, especially for small corpora.</abstract>
      <pages>107–119</pages>
      <url hash="109dc4fd">Q18-1008</url>
      <video href="https://vimeo.com/277670053" />
      <bibkey>antoniak-mimno-2018-evaluating</bibkey>
    <title_ar>تقييم استقرار تشابه الكلمات القائمة على التضمين</title_ar>
      <title_es>Evaluación de la estabilidad de las similitudes de palabras basadas en incrustaciones</title_es>
      <title_fr>Évaluation de la stabilité des similitudes de mots basées sur l'intégration</title_fr>
      <title_pt>Avaliando a estabilidade de semelhanças de palavras baseadas em incorporação</title_pt>
      <title_ja>埋め込みベースの単語の類似性の安定性の評価</title_ja>
      <title_zh>评估基于嵌单词相似性之稳定性</title_zh>
      <title_ru>Оценка стабильности сходства слов на основе встраивания</title_ru>
      <title_hi>एम्बेडिंग-आधारित Word समानताओं की स्थिरता का मूल्यांकन करना</title_hi>
      <title_ga>Ag Measúnú Cobhsaíochta Cosúlachtaí Focal Bunaithe ar Leabú</title_ga>
      <title_hu>A beágyazáson alapuló szavahasonlóságok stabilitásának értékelése</title_hu>
      <title_ka>სიტყვის სიმბოლოების სიმართლურობის სტაბილობას განსაზღვრება</title_ka>
      <title_el>Αξιολόγηση της σταθερότητας των ομοιοτήτων λέξεων που βασίζονται στην ενσωμάτωση</title_el>
      <title_lt>Įterpiamųjų žodžių panašumų stabilumo vertinimas</title_lt>
      <title_it>Valutazione della stabilità delle somiglianze di parole basate sull'integrazione</title_it>
      <title_kk>Ендіру негіздеген сөздердің ұқсастығын оқу</title_kk>
      <title_mk>Оценувањето на стабилноста на сличностите на зборови базирани на вградување</title_mk>
      <title_mt>Evalwazzjoni ta’ l-Istabbiltà ta’ Similaritajiet ta’ kliem ibbażati fuq l-Inkorporazzjoni</title_mt>
      <title_mn>Нэгдсэн үг төстэй байдлыг үнэлэх</title_mn>
      <title_ms>Mengevaluasi Kestabilan Persamaan Perkataan Berasas Pencampuran</title_ms>
      <title_ml>എംബെഡിംഗ് അടിസ്ഥാനമായ വാക്കുകളുടെ സ്ഥിതിയെല്ലാം സമമാക്കുന്നു</title_ml>
      <title_no>Evaluerer Stabiliteten på innbyggingsbaserte ord-likningar</title_no>
      <title_pl>Ocena stabilności podobieństw słów opartych na osadzeniu</title_pl>
      <title_ro>Evaluarea stabilității similitudinilor cuvintelor bazate pe încorporarea</title_ro>
      <title_sr>Procjenjivanje stabilnosti sličnosti riječi na osnovu uključenja</title_sr>
      <title_so>Evaluating the Stability of Embedding-based Word Similarities</title_so>
      <title_sv>Utvärdering av stabiliteten hos inbäddade ordlikheter</title_sv>
      <title_si>සම්බන්ධිත වචන ස්ථාවත්වය අවශ්‍ය කරන්න</title_si>
      <title_ta>உட்பொதியில் உள்ள சார்ந்த வார்த்தையின் நிலைமையை மதிப்பிடுகிறது</title_ta>
      <title_ur>Embedding-based Word Similarities کی استبلیت کا ارزش کیا جاتا ہے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Đánh giá ổn định tỷ lệ ngôn từ nhúng</title_vi>
      <title_nl>Evaluatie van de stabiliteit van op embedding gebaseerde woordgelijkenissen</title_nl>
      <title_hr>Procjenjivanje stabilnosti sličnosti riječi na osnovu uključenih</title_hr>
      <title_bg>Оценка на стабилността на базираните на вграждане сходства на думи</title_bg>
      <title_da>Evaluering af stabiliteten i integrering baserede ordligheder</title_da>
      <title_de>Bewertung der Stabilität von eingebetteten Word-Ähnlichkeiten</title_de>
      <title_fa>ارزیابی ثابت کردن شبیه‌سازی کلمات بر اساس جمع کردن</title_fa>
      <title_id>Mengevaluasi Stabilitas Perasaan Kata Berdasarkan Penambahan</title_id>
      <title_af>Evalueer die Stabiliteit van Inbêer- gebaseerde Woord Similarisies</title_af>
      <title_sw>Kupima msimamo wa neno linalozingatia</title_sw>
      <title_ko>삽입된 단어의 유사도 안정성에 대한 평가</title_ko>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_sq>Vlerësimi i stabilitetit të ngjashmërive të fjalëve të bazuara në përfshirje</title_sq>
      <title_tr>Edilmek tabanly Kelimleriň Stabilityny Taýýarlamak</title_tr>
      <title_az>캻칞eri daxil edil톛n S칬zl톛r Similaritl톛rinin Stabiliyy톛tini Q캼d캼rlama</title_az>
      <title_hy>Խոսքերի նմանությունների կայունության գնահատումը</title_hy>
      <title_bn>এমবেডিং-ভিত্তিক শব্দের অবস্থান মুক্তি করা হচ্ছে</title_bn>
      <title_ca>Evaluar la estabilitat de les similituds de paraules basades en l'incorporació</title_ca>
      <title_cs>Hodnocení stability podobností slov založených na vložení</title_cs>
      <title_et>Põimimispõhiste sõnassarnasuste stabiilsuse hindamine</title_et>
      <title_bs>Procjenjivanje stabilnosti sličnosti riječi na osnovu uključenih</title_bs>
      <title_fi>Upotukseen perustuvien sanasamankaltaisuuksien vakauden arviointi</title_fi>
      <title_jv>Name</title_jv>
      <title_sk>Ocena stabilnosti podobnosti besed, ki temeljijo na vdelavi</title_sk>
      <title_ha>Yana inganci game da Halar Aiki na Ƙara da aka Base da magana Similarity</title_ha>
      <title_he>הערכה של יציבות דומות מילים מבוססות על קידום</title_he>
      <title_bo>ཨ་རུང་ནང་དུ་བཙུགས་པའི་ཡིག་ཆ་མཚོན་རྟགས་ཀྱི་བཅད་རིམ་གྱི་ཚད་ལྟར་ཞིབ་བྱེད་བཞིན་པ</title_bo>
      <abstract_pt>Word embeddings estão sendo cada vez mais usados como uma ferramenta para estudar associações de palavras em corpora específicos. No entanto, não está claro se tais incorporações refletem propriedades duradouras da linguagem ou se são sensíveis a variações inconsequentes nos documentos de origem. Descobrimos que as distâncias do vizinho mais próximo são altamente sensíveis a pequenas mudanças no corpus de treinamento para uma variedade de algoritmos. Para todos os métodos, incluir documentos específicos no conjunto de treinamento pode resultar em variações substanciais. Mostramos que esses efeitos são mais proeminentes para corpos de treinamento menores. Recomendamos que os usuários nunca confiem em modelos de incorporação únicos para cálculos de distância, mas sim na média de várias amostras de bootstrap, especialmente para pequenos corpora.</abstract_pt>
      <abstract_ar>يتزايد استخدام عمليات دمج الكلمات كأداة لدراسة ارتباطات الكلمات في مجموعات محددة. ومع ذلك ، ليس من الواضح ما إذا كانت هذه الزخارف تعكس الخصائص الدائمة للغة أو ما إذا كانت حساسة للتغيرات غير المهمة في المستندات المصدر. وجدنا أن مسافات الجوار الأقرب حساسة للغاية للتغييرات الصغيرة في مجموعة التدريب لمجموعة متنوعة من الخوارزميات. لجميع الأساليب ، بما في ذلك وثائق محددة في مجموعة التدريب يمكن أن يؤدي إلى اختلافات جوهرية. نظهر أن هذه التأثيرات تكون أكثر وضوحًا لمؤسسات التدريب الأصغر. نوصي بألا يعتمد المستخدمون مطلقًا على نماذج التضمين الفردي لحسابات المسافة ، بل يعتمدون على متوسط أكثر من عينات تمهيد التشغيل المتعددة ، خاصةً للمؤسسات الصغيرة.</abstract_ar>
      <abstract_fr>Les intégrations de mots sont de plus en plus utilisées comme outil pour étudier les associations de mots dans des corpus spécifiques. Cependant, il n'est pas clair si ces intégrations reflètent les propriétés durables du langage ou s'ils sont sensibles à des variations sans conséquence dans les documents sources. Nous avons constaté que les distances du plus proche voisin sont très sensibles aux petits changements dans le corpus d'apprentissage pour divers algorithmes. Pour toutes les méthodes, l'inclusion de documents spécifiques dans le kit de formation peut entraîner des variations importantes. Nous montrons que ces effets sont plus importants pour les petits corpus d'entraînement. Nous recommandons aux utilisateurs de ne jamais se fier à des modèles d'intégration uniques pour les calculs de distance, mais plutôt de faire la moyenne sur plusieurs échantillons bootstrap, en particulier pour les petits corpus.</abstract_fr>
      <abstract_es>Las incrustaciones de palabras se utilizan cada vez más como una herramienta para estudiar las asociaciones de palabras en corpus específicos. Sin embargo, no está claro si estas incrustaciones reflejan propiedades duraderas del lenguaje o si son sensibles a variaciones intrascendentes en los documentos fuente. Encontramos que las distancias de los vecinos más cercanos son muy sensibles a pequeños cambios en el corpus de entrenamiento para una variedad de algoritmos. Para todos los métodos, incluir documentos específicos en el conjunto de capacitación puede dar lugar a variaciones sustanciales. Mostramos que estos efectos son más prominentes para los cuerpos de entrenamiento más pequeños. Recomendamos que los usuarios nunca se basen en modelos de incrustación únicos para los cálculos de distancia, sino que hagan un promedio de varias muestras de bootstrap, especialmente para cuerpos pequeños.</abstract_es>
      <abstract_ja>ワード埋め込みは、特定のコーラにおけるワードの関連付けを研究するためのツールとしてますます使用されています。しかし、そのような埋め込みが言語の永続的な特性を反映しているかどうか、またはソースドキュメントの重要でない変動に敏感であるかどうかは不明です。最も近い距離は、さまざまなアルゴリズムのトレーニングコーパスの小さな変化に非常に敏感であることがわかります。トレーニングセットに特定の文書を含むすべての方法では、実質的なバリエーションが生じる可能性があります。これらの効果は、より小さなトレーニング体にとってより顕著であることを示しています。ユーザーは、距離計算に単一の埋め込みモデルに頼らず、複数のブートストラップサンプルの平均値を使用することをお勧めします。</abstract_ja>
      <abstract_zh>词嵌益多,以究特定语料库单词关联之具。 然未详其久语,或对源文之急变也。 见诸算法,近对训练语料库中微变高敏。 凡诸方法,包练集特定文档,皆可致变。 明于小训语料库尤甚。 臣等建议用户永无依单嵌,而于数引样本上取平均值,特于小语料库。</abstract_zh>
      <abstract_ru>Вложения слов все чаще используются в качестве инструмента для изучения ассоциаций слов в конкретных корпусах. Однако неясно, отражают ли такие вложения стойкие свойства языка или они чувствительны к несущественным вариациям в исходных документах. Мы обнаружили, что расстояния до ближайших соседей очень чувствительны к небольшим изменениям в обучающем корпусе для различных алгоритмов. Для всех методов, включая конкретные документы в обучающем наборе, могут быть существенные вариации. Мы показываем, что эти эффекты более заметны для небольших обучающих корпусов. Мы рекомендуем пользователям никогда не полагаться на модели одиночного встраивания для расчетов расстояния, а использовать среднее значение по нескольким выборкам бутстрепов, особенно для небольших корпусов.</abstract_ru>
      <abstract_hi>शब्द एम्बेडिंग का उपयोग तेजी से विशिष्ट कॉर्पोरेट में शब्द संघों का अध्ययन करने के लिए एक उपकरण के रूप में किया जा रहा है। हालांकि, यह स्पष्ट नहीं है कि क्या इस तरह के एम्बेडिंग भाषा के स्थायी गुणों को दर्शाते हैं या यदि वे स्रोत दस्तावेजों में असंगत भिन्नताओं के प्रति संवेदनशील हैं। हम पाते हैं कि निकटतम पड़ोसी दूरी विभिन्न प्रकार के एल्गोरिदम के लिए प्रशिक्षण कॉर्पस में छोटे परिवर्तनों के प्रति अत्यधिक संवेदनशील हैं। प्रशिक्षण सेट में विशिष्ट दस्तावेजों सहित सभी विधियों के लिए, पर्याप्त भिन्नताएं हो सकती हैं। हम दिखाते हैं कि ये प्रभाव छोटे प्रशिक्षण निगम के लिए अधिक प्रमुख हैं। हम अनुशंसा करते हैं कि उपयोगकर्ता कभी भी दूरी की गणना के लिए एकल एम्बेडिंग मॉडल पर भरोसा नहीं करते हैं, बल्कि कई बूटस्ट्रैप नमूनों पर औसत, विशेष रूप से छोटे कॉर्पोरेट के लिए।</abstract_hi>
      <abstract_ga>Tá níos mó úsáide á baint as leabaithe focal mar uirlis chun staidéar a dhéanamh ar chomhcheangail focal i gcorpas sonrach. Níl sé soiléir, áfach, an léiríonn leabú den sórt sin tréithe marthanacha teanga nó an bhfuil siad íogair d’éagsúlachtaí neamhleanúnacha sna buncháipéisí. Faighimid amach go bhfuil faid na gcomharsan is gaire thar a bheith íogair d’athruithe beaga sa chorpas traenála le haghaidh éagsúlacht algartam. I gcás gach modha, féadfaidh éagsúlachtaí suntasacha a bheith mar thoradh ar dhoiciméid shonracha san áireamh sa tacar oiliúna. Léirímid go bhfuil na héifeachtaí seo níos suntasaí do chorpas oiliúna níos lú. Molaimid nach mbeadh úsáideoirí ag brath ar mhúnlaí leabaithe aonair chun achair a ríomh, ach go mbeadh siad ag brath ar an meán thar ilshamplaí strata tosaithe, go háirithe i gcás corpora beaga.</abstract_ga>
      <abstract_el>Οι ενσωματώσεις λέξεων χρησιμοποιούνται όλο και περισσότερο ως εργαλείο για τη μελέτη συσχετισμών λέξεων σε συγκεκριμένα σώματα. Ωστόσο, δεν είναι σαφές αν τέτοιες ενσωματώσεις αντικατοπτρίζουν μόνιμες ιδιότητες της γλώσσας ή αν είναι ευαίσθητες σε ασήμαντες διακυμάνσεις στα έγγραφα προέλευσης. Διαπιστώνουμε ότι οι αποστάσεις κοντινών γειτόνων είναι ιδιαίτερα ευαίσθητες σε μικρές αλλαγές στο σώμα εκπαίδευσης για μια ποικιλία αλγορίθμων. Για όλες τις μεθόδους, συμπεριλαμβανομένων συγκεκριμένων εγγράφων στο σύνολο κατάρτισης μπορεί να οδηγήσει σε σημαντικές διακυμάνσεις. Δείχνουμε ότι αυτά τα αποτελέσματα είναι πιο εμφανή για μικρότερα σώματα εκπαίδευσης. Συνιστούμε στους χρήστες να μην βασίζονται ποτέ σε μεμονωμένα μοντέλα ενσωμάτωσης για υπολογισμούς απόστασης, αλλά μάλλον στο μέσο όρο πάνω από πολλαπλά δείγματα, ειδικά για μικρά σώματα.</abstract_el>
      <abstract_hu>A szóbeágyazásokat egyre inkább eszközként használják arra, hogy tanulmányozzák a szótársításokat bizonyos corporákban. Nem világos azonban, hogy az ilyen beágyazások a nyelv tartós tulajdonságait tükrözik-e, vagy érzékenyek-e a forrásdokumentumok lényegtelen változásaira. Úgy találjuk, hogy a legközelebbi szomszéd távolságok nagyon érzékenyek a különböző algoritmusok képzési korpuszában bekövetkező kis változásokra. Minden módszer esetében, beleértve a képzési készletben található konkrét dokumentumokat is, jelentős eltéréseket eredményezhet. Megmutatjuk, hogy ezek a hatások jelentősebbek a kisebb edzőtestek esetében. Javasoljuk, hogy a felhasználók soha ne támaszkodjanak egyetlen beágyazási modellekre a távolság kiszámításához, hanem inkább átlagosan több bootstrap minta esetében, különösen kisebb corpora esetében.</abstract_hu>
      <abstract_ka>სიტყვების შებრუნება უფრო მეტი გამოიყენება როგორც ხელსაწყო სიტყვების შებრუნებების განსაკუთრებული კოპორაში. მაგრამ არ უცნობია თუ ასეთი ინტებიზიციები განაცნობენ ენის მუშაობას, ან თუ ისინი განაცნობიან შემდეგ განაცნობების შემდეგ დოკუმენტებში. ჩვენ ვიფიქრობთ, რომ უფრო მხოლოდ საზოგადოებო განტოლებები ძალიან სიგრძნობელია მალკი ცვლილებების შემდეგ განტოლებების კორპოსში, რამდენიმე ალგორიტემი ყველა მეტისთვის, რომელიც განსაკუთრებული დოკუმენტები განათლებაში შეიძლება გავამრავლება. ჩვენ ჩვენ აჩვენებთ, რომ ეს ეფექტები უფრო მნიშვნელოვანია კოპორაზე პატარა განაკეთება. ჩვენ მუშაობით, რომ მომხმარებელი არასდროს ერთი მოდელზე დააყენება განსხვავებულებისთვის, მაგრამ განსხვავებულად განსხვავებულად მრავალური მოდელზე, განსაკუთრებით</abstract_ka>
      <abstract_it>Le incorporazioni di parole sono sempre più utilizzate come strumento per studiare le associazioni di parole in corpora specifici. Tuttavia, non è chiaro se tali incorporazioni riflettono proprietà permanenti del linguaggio o se sono sensibili a variazioni irrilevanti nei documenti di origine. Troviamo che le distanze vicino-vicino sono altamente sensibili a piccoli cambiamenti nel corpo di allenamento per una varietà di algoritmi. Per tutti i metodi, inclusi documenti specifici nel set di formazione può comportare variazioni sostanziali. Mostriamo che questi effetti sono più prominenti per i corpi di allenamento più piccoli. Consigliamo agli utenti di non affidarsi mai a singoli modelli di incorporazione per i calcoli della distanza, ma piuttosto a una media su più campioni di bootstrap, specialmente per i piccoli corpora.</abstract_it>
      <abstract_lt>žodžių įterpimas vis dažniau naudojamas kaip įrankis žodžių asociacijoms konkrečioje korporoje studijuoti. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents.  Matome, kad artimiausi kaimyniniai atstumai labai jautrūs nedideliams mokymo korpuso pokyčiams įvairiems algoritmams. Visiems metodams, įskaitant specialius mokymo dokumentus, gali būti daromi esminiai pokyčiai. Mes rodome, kad šis poveikis yra labiau akivaizdus mažesniam mokymo korporams. Rekomenduojame, kad naudotojai niekada nesikliautų vieninteliais įterpimo modeliais atstumui apskaičiuoti, o vidutiniškai daugiau nei keli bootstrap mėginiai, ypač mažoms korporams.</abstract_lt>
      <abstract_mk>Вклучувањето на зборови се користи сé повеќе како алатка за учење на зборни асоцијации во специфични корпорации. Сепак, не е јасно дали ваквите вградувања ги одразуваат трајните сопствености на јазикот или дали се чувствителни на несеквенцијални варијации во изворните документи. Најблиските соседи се многу чувствителни на мали промени во обуката за различни алгоритми. За сите методи, вклучувајќи ги и специфичните документи во наборот на обуки, може да резултира со значителни варијации. Ние покажуваме дека овие ефекти се поистакнати за помалите обуки. Препорачуваме корисниците никогаш да не се потпираат на единствени модели за вградување за пресметки на далечината, туку на просечен примерок во врска со повеќе примероци, особено за малите корпора.</abstract_mk>
      <abstract_kk>Сөздерді ендіру құралы болып, сөздерді қатынау үшін керек корпорадағы құралы ретінде қолданылады. Бірақ бұл ендіру тілдің қасиеттеріне тұрақты қасиеттері көрсетілмейді, немесе олар көзінің құжаттарындағы тұрақты айырмашылықтарына сәтсіз болса, бұл құжаттарды көрсе Біз ең жақын соңғы қашықтарды бірнеше алгоритмдар үшін оқыту корпусының кішкентай өзгерістеріне көп сезімді деп ойлаймыз. Барлық әдістер үшін, оқыту бағдарламасындағы ерекше құжаттарды қоса, көп айырмашылығы болады. Біз бұл эффекттер кішкентай оқыту корпорасы үшін көптеген. Біз пайдаланушыларды қашықтық есептеу үшін бір ендіру үлгілеріне әсер етпейді, бірақ бірнеше жүктеу үлгілерінен орташа, өзіне кішкентай корпора үшін.</abstract_kk>
      <abstract_ms>Penampilan perkataan semakin digunakan sebagai alat untuk mempelajari hubungan perkataan dalam korpra tertentu. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents.  We find that nearest-neighbor distances are highly sensitive to small changes in the training corpus for a variety of algorithms.  Untuk semua kaedah, termasuk dokumen khusus dalam set latihan boleh menghasilkan variasi yang besar. Kami menunjukkan bahawa kesan ini lebih terkenal untuk corpora latihan yang lebih kecil. Kami cadangkan pengguna tidak pernah bergantung pada model penyembedding tunggal untuk pengiraan jarak, tetapi rata-rata lebih banyak sampel tali bot, terutama untuk korpra kecil.</abstract_ms>
      <abstract_mt>L-inkorporazzjoni tal-kliem qed tintuża dejjem aktar bħala għodda biex jiġu studjati l-assoċjazzjonijiet tal-kliem f’korpra speċifika. Madankollu, mhuwiex ċar jekk tali inkorporazzjonijiet jirriflettux il-karatteristiċi dejjiema tal-lingwa jew jekk humiex sensittivi għal varjazzjonijiet inkonsegwenzjali fid-dokumenti tas-sors. Aħna nsibu li d-distanzi l-eqreb ġirien huma sensittivi ħafna għal bidliet żgħar fil-korpus tat-taħriġ għal varjetà ta’ algoritmi. Għall-metodi kollha, inklużi dokumenti speċifiċi fis-sett ta’ taħriġ jistgħu jirriżultaw f’varjazzjonijiet sostanzjali. Aħna nuru li dawn l-effetti huma aktar prominenti għal korpora ta’ taħriġ iżgħar. Aħna nirrakkomandaw li l-utenti qatt ma jiddependu fuq mudelli ta’ inkorporazzjoni waħdanija għall-kalkoli tad-distanza, iżda pjuttost medja fuq kampjuni multipli ta’ bootstrap, speċjalment għal korpora żgħira.</abstract_mt>
      <abstract_mn>Өөр корпора дахь үгийн холбоотой байгууллагуудыг судлах хэрэгсэл болгон ашиглаж байна. Гэвч ийм загварууд хэлний үргэлжлүүлэх чадварыг харуулж чадахгүй, эсвэл эх баримт дээрх үргэлжлүүлэхгүй өөрчлөлтийг харуулж чадахгүй. Бид хамгийн ойрхон хөрш хоорондын зай олон алгоритмын төлөө сургалтын корпусын жижиг өөрчлөлтөнд маш чухал байдаг. Бүх арга баримтуудын тулд, дасгал хөдөлгөөн дээрх тодорхой баримтууд нь маш олон өөрчлөлт гарч чадна. Бид эдгээр үр дүнг бага сургалтын корпоратын тулд илүү чухал гэдгийг харуулж байна. Бид хэрэглэгчид хэзээ ч зайн тооцоололтын нэг загварын загвар дээр итгэдэггүй гэдгийг санал дэвшүүлдэг. Гэхдээ олон загварын жижиг корпора дээр дундаж байдаг.</abstract_mn>
      <abstract_ml>വാക്കുകളുടെ അകത്തേക്ക് കൂടുതല്‍ ഉപയോഗിക്കുന്നത് പ്രത്യേകിച്ച കോര്‍പ്പോരിയില്‍ വാക്കുകളുടെ സങ്കേതി എങ്കിലും ഇതുപോലുള്ള അകത്തുനിന്നുള്ള വ്യത്യാസങ്ങള്‍ ഭാഷയുടെ സ്ഥിതികളെ പ്രത്യേകിക്കുന്നുണ്ടോ അല്ലെങ്കില്‍ ഉറവിട രേഖകള അടുത്ത അയല്‍ക്കാരുടെ ദൂരം വിവിധ ആല്‍ഗോരിത്മുകള്‍ക്ക് പരിശീലനത്തിലെ ചെറിയ മാറ്റങ്ങള്‍ക്ക് വളരെ ശ്രദ്ധയുള്ളതാണെന് എല്ലാ രീതികള്‍ക്കും, ട്രെയിനിങ്ങളുടെ സജ്ജീകരണത്തിലെ പ്രത്യേക രേഖകളും ഉള്ള രേഖകള്‍ക്കും വലിയ വ്യത്യാസ ഈ പ്രഭാവങ്ങള്‍ ചെറിയ പരിശീലനത്തിന്റെ കോര്‍പ്പോറിയില്‍ കൂടുതല്‍ പ്രധാനപ്പെട്ടതാണെന്ന് ഞങ് ഞങ്ങള്‍ ഉപയോക്താക്കള്‍ ഒരിക്കലും അകലെ കണക്കിനു വേണ്ടി ഒരിക്കലും ആശ്രയിക്കുന്നില്ല, പക്ഷെ ഒരുപാട് ബൂട്ട്സ്ട്രാപ്പ് ടാമ്പുകളില</abstract_ml>
      <abstract_no>Ordinnbygging blir større brukt som verktøy for å studera ordsamlingar i spesifikke korpora. Det er imidlertid ukjent om slike innbyggingar reflekterer gjennomgåande eigenskapar for språk eller dersom dei er sensitivne til inklusive variasjonar i kjeldedokumenta. Vi finn at næraste-nabo-avstandane er svært sensitivne til små endringar i øvingskorpusen for mange algoritme. For alle metodar kan, inkludert spesifikke dokument i opplæringssettet, føre til store variasjonar. Vi viser at desse effektene er meir viktigere for mindre opplæringskorpora. Vi anbefaler at brukarar aldri skal bruka på enkelte innbyggingsmodeller for avstandkalkulasjonar, men i staden gjennomsnittlig over fleire oppstartslapp, spesielt for små korpora.</abstract_no>
      <abstract_pl>Osadzania słów są coraz częściej wykorzystywane jako narzędzie do badania skojarzeń słów w określonych korpusach. Nie jest jednak jasne, czy takie osadzenia odzwierciedlają trwałe właściwości języka, czy są wrażliwe na nieistotne zmiany w dokumentach źródłowych. Odkrywamy, że odległości najbliższych sąsiadów są bardzo wrażliwe na małe zmiany w korpusie treningowym dla różnych algorytmów. W przypadku wszystkich metod, w tym konkretnych dokumentów w zestawie szkoleniowym, może spowodować znaczne różnice. Pokazujemy, że efekty te są bardziej widoczne dla mniejszych korpusów treningowych. Zalecamy, aby użytkownicy nigdy nie polegali na pojedynczych modelach osadzania do obliczeń odległości, ale raczej średnio w przypadku wielu próbek bootstrap, zwłaszcza w przypadku małych korpusów.</abstract_pl>
      <abstract_ro>Încorporările de cuvinte sunt folosite din ce în ce mai mult ca un instrument pentru a studia asociațiile de cuvinte în corpore specifice. Cu toate acestea, nu este clar dacă astfel de încorporări reflectă proprietățile durabile ale limbajului sau dacă sunt sensibile la variații inutile ale documentelor sursă. Descoperim că distanțele apropiate de vecini sunt foarte sensibile la mici schimbări în corpul de instruire pentru o varietate de algoritmi. Pentru toate metodele, inclusiv documentele specifice din setul de instruire poate duce la variații substanțiale. Arătăm că aceste efecte sunt mai proeminente pentru corporele de antrenament mai mici. Recomandăm ca utilizatorii să nu se bazeze niciodată pe modele de încorporare unică pentru calculele distanței, ci mai degrabă pe o medie peste mai multe mostre de bootstrap, în special pentru corporele mici.</abstract_ro>
      <abstract_si>වචන සම්බන්ධයක් විශේෂ කොර්පෝරාවේ වචන සම්බන්ධයක් ඉගෙන ගන්න උපකරණයක් විදිහට භාවිත වෙනව ඒත් ඒ වගේම, ඒ වගේ සම්බන්ධ විශේෂතාවක් භාෂාවේ සාමාන්‍ය විශේෂතාවක් පෙන්වන්න පුළුවන් නැත්නම් නැත්නම අපිට හොයාගන්න පුළුවන් අයිතුරු දුරක්ෂණය ගොඩක් සංවේදනය වෙන්න පුළුවන් වෙනස් වෙන්න පුළුවන් කොර්පුස සියළු විදියට, ප්‍රශ්නය සම්පූර්ණයේ විශේෂ විදියට විශේෂ ලිපිණිත් සම්පූර්ණය කරන් අපි පෙන්වන්නේ මේ ප්‍රභාව ප්‍රශ්නයක් පොඩි ප්‍රශ්නයක් වෙනුවෙන් වඩා ප්‍රශ්නයක් වෙනවා  අපි ප්‍රයෝජකයෝ කවදාවත් විශ්වාස කරන්න ප්‍රයෝජකයෝ විශ්වාස කරන්නේ නැහැ කියලා දුරස්ථානයක් ගණනය කරන්න, ඒත් ව</abstract_si>
      <abstract_so>Waxyaabaha ku qoran hadalka waxaa loogu isticmaalaa sida qalabka lagu baranayo ururada hadalka ee shirkadda gaarka ah. Si kastaba ha ahaatee ma ahan in qalabka caynkaas ah ay ka fiiriyaan hantida joogtada ah ee luqada ama in ay ka fekeraan iskala beddelka ee warqada asalka ah. Waxaynu ognahay in safarka deriska u dhow ay aad u taxadar u leeyihiin isbedelka yar ee iskuulka waxbarashada ee algorithm kala duduwan. Dhammaan qaababka, kuwaas oo ku jira dukumentiyada gaar ah oo ku qoran koorasyada waxbarashada waxay ku sababi karaan beddelooyin badan. Waxaynu muujinnaa in saamayntanu ay ugu muhiimsan yihiin shirkadaha waxbarashada yar. We recommend that users never rely on single embedding models for distance calculations, but rather average over multiple bootstrap samples, especially for small corpora.</abstract_so>
      <abstract_sv>Ordinbäddningar används alltmer som ett verktyg för att studera ordassociationer i specifika korpora. Det är dock oklart om sådana inbäddningar återspeglar varaktiga språkegenskaper eller om de är känsliga för obetydliga variationer i källdokumenten. Vi finner att närmaste grannavstånd är mycket känsliga för små förändringar i träningskorpusen för en mängd olika algoritmer. För alla metoder, inklusive specifika dokument i träningsuppsättningen, kan resultera i betydande variationer. Vi visar att dessa effekter är mer framträdande för mindre träningscorpora. Vi rekommenderar att användare aldrig förlitar sig på enstaka inbäddningsmodeller för avståndsberäkningar, utan snarare medelvärden över flera bootstrap-prover, särskilt för små corpora.</abstract_sv>
      <abstract_sr>Povećavaju uključenje riječi kao alat za proučavanje udruženja riječi u određenoj korpori. Međutim, nije jasno da li su takve uključenje odražavale trajne vlasništvo jezika ili da su osjetljive na neposredne varijacije u izvornim dokumentima. Najbliži susedni udaljenosti su veoma osjetljive na male promjene u trening korpusu za različite algoritme. Za sve metode, uključujući specifične dokumente u setu obuke, mogu rezultirati značajne varijacije. Pokazujemo da su ovi efekti važniji za manje obuku. Preporučujemo da korisnici nikad ne oslanjaju na jednog ugrađenog modela za izračune udaljenosti, ali prosječno preko više uzorka šampanjca, posebno za male korporacije.</abstract_sr>
      <abstract_ta>Name However, such embeddings reflect enduring language properties or they are sensitive to inconsistent variations in the source documents. நாங்கள் கண்டுபிடிக்கும் நெருங்கி அண்டை தூரத்தில் உள்ள மிகவும் உணர்வுடைய மாற்றங்கள் மாற்றங்கள் பல ஆல்ஜிரிக்களு For all methods, including specific documents in the training set can result in substantial variations.  சிறிய பயிற்சி நிறுவனத்திற்கு இந்த விளைவு தூரத்தில் கணக்கீடுகளுக்கு ஒரே உள்ளீட்டு மாதிரிகளை பயன்படுத்துபவர்கள் சார்ந்து கொள்ளாது, ஆனால் சிறிய நிறுவனத்திற்கு அதிக சராசரிய</abstract_ta>
      <abstract_ur>Word embedding is increasingly used as a tool to study words associations in specific corpora. However, it is unclear whether such embeddings reflect lasting properties of language or if they are sensitive to inconsistent variations in the source documents. ہم دیکھتے ہیں کہ قریب ترین گھر کی دور بہت سی تغییرات کے لئے بہت سی مختلف الگوریتم کے لئے ہے۔ ہر طریقہ کے لئے، ترینس سٹ میں مخصوص سند شامل ہوتے ہیں، بہت سی تغییرات کا نتیجہ ہے۔ ہم دکھاتے ہیں کہ یہ اثرات چھوٹی ترکینس کورپورا کے لئے زیادہ اثر ہیں۔ ہم یہ سفارش دیتے ہیں کہ کارساز کبھی دور کی محاسبات کے لئے ایک ایمبڈینگ موڈل پر اعتماد نہیں کریں، لیکن بہت سے بوٹ سٹراپ نمونے پر متوسط ہے، مخصوصاً چھوٹے کورپورا کے لئے۔</abstract_ur>
      <abstract_uz>Name Lekin, bunday foydalanuvchilar tilning davomida moslamalarini ko'rinishi mumkin yoki manba hujjatdagi qisqa oʻzgarishlarni qiymati mumkin. Biz o'rganamiz, bu ko'pchilik algoritlarga o'zgarishlarning kichkina o'zgarishlarini o'rganish juda juda juda qiziqarli. For all methods, including specific documents in the training set can result in substantial variations.  Biz shu effektlar kichkina ta'lim kompaniyalar uchun juda muhim. Biz foydalanuvchilar orasidagi masofadagi hisoblash uchun hech qachon bir xil boshqaruv modellarga ishlatmaydi, balki ko'plab boshqaruv samollaridan ko'p narsalardan, hususan kichkina kompaniya uchun.</abstract_uz>
      <abstract_vi>Từ ngữ được sử dụng ngày càng nhiều như một công cụ để nghiên cứu các tổ chức từ ngữ trong cơ thể cụ thể. Tuy nhiên, không rõ liệu sự nhúng tay này có phản ánh tính chất bền vững của ngôn ngữ hay không nếu nó nhạy cảm với những biến đổi không liên quan trong tài liệu nguồn. Chúng tôi thấy khoảng cách hàng xóm gần nhất rất nhạy cảm với những thay đổi nhỏ trong tập thể huấn cho nhiều thuật to án. Tất cả các phương pháp, kể cả các tài liệu cụ thể trong bộ huấn luyện có thể tạo ra sự khác biệt lớn. Chúng tôi cho thấy những hiệu ứng này quan trọng hơn đối với tập đoàn nhỏ hơn. Chúng tôi đề nghị người dùng không bao giờ dựa vào mô hình nhúng đơn để tính toán khoảng cách, nhưng trung bình hơn nhiều mẫu ủng hộ, đặc biệt cho hạ sĩ nhỏ.</abstract_vi>
      <abstract_bg>Вградените думи все повече се използват като инструмент за изучаване на асоциации на думи в конкретни корпуси. Не е ясно обаче дали тези вграждания отразяват трайни свойства на езика или са чувствителни към незначителни вариации в изходните документи. Откриваме, че разстоянието на най-близкия съсед е силно чувствително към малки промени в тренировъчния корпус за различни алгоритми. За всички методи, включително конкретни документи в комплекта от обучения, може да доведе до значителни вариации. Показваме, че тези ефекти са по-видни за по-малки тренировъчни корпорации. Препоръчваме потребителите никога да не разчитат на единични модели за вграждане за изчисляване на разстоянието, а по-скоро средно за няколко проби за зареждане, особено за малки корпуси.</abstract_bg>
      <abstract_da>Ordindlejringer bruges i stigende grad som et værktøj til at studere ordforeninger i bestemte korpora. Det er imidlertid uklart, om sådanne indlejringer afspejler sprogets varige egenskaber, eller om de er følsomme over for ubetydelige variationer i kildedokumenterne. Vi finder ud af, at afstande mellem nærmeste nabo er meget følsomme over for små ændringer i træningskorpus for en række algoritmer. For alle metoder, herunder specifikke dokumenter i træningssættet, kan resultere i betydelige variationer. Vi viser, at disse effekter er mere fremtrædende for mindre træningskorpora. Vi anbefaler, at brugerne aldrig stoler på enkelte indlejringsmodeller til afstandsberegninger, men snarere gennemsnitligt over flere bootstrap-prøver, især for små corpora.</abstract_da>
      <abstract_nl>Word embeddings worden steeds vaker gebruikt als een hulpmiddel om woordassociaties in specifieke corpora te bestuderen. Het is echter onduidelijk of dergelijke insluitingen blijvende eigenschappen van taal weerspiegelen of ze gevoelig zijn voor onbelangrijke variaties in de brondocumenten. We vinden dat de dichtstbijzijnde buurverbindingen zeer gevoelig zijn voor kleine veranderingen in het trainingscorpus voor een verscheidenheid van algoritmen. Voor alle methoden kan het opnemen van specifieke documenten in de trainingsset tot aanzienlijke variaties leiden. We laten zien dat deze effecten prominenter zijn voor kleinere trainingscorpora's. We raden gebruikers aan om nooit te vertrouwen op enkele embedding modellen voor afstandsberekeningen, maar eerder gemiddeld over meerdere bootstrap samples, vooral voor kleine corpora's.</abstract_nl>
      <abstract_de>Worteinbettungen werden zunehmend als Werkzeug verwendet, um Wortverknüpfungen in bestimmten Korpora zu untersuchen. Es ist jedoch unklar, ob solche Einbettungen dauerhafte Eigenschaften der Sprache widerspiegeln oder ob sie empfindlich auf unbedeutende Abweichungen in den Quelldokumenten reagieren. Wir stellen fest, dass Nah-Nachbar-Entfernungen für eine Vielzahl von Algorithmen sehr empfindlich auf kleine Veränderungen im Trainingskorpus reagieren. Für alle Methoden, einschließlich spezifischer Dokumente im Trainingsset, kann es zu erheblichen Abweichungen kommen. Wir zeigen, dass diese Effekte für kleinere Trainingskorpora prominenter sind. Wir empfehlen Benutzern, sich bei Entfernungsberechnungen niemals auf einzelne Einbettungsmodelle zu verlassen, sondern eher durchschnittlich über mehrere Bootstrap-Samples, insbesondere bei kleinen Corpora.</abstract_de>
      <abstract_hr>Povećavaju se uključenje riječi kao alat za proučavanje udruženja riječi u određenoj korpori. Međutim, nije jasno da li se takve ugrađenje odražavaju tržišne vlasništvo jezika ili da su osjetljive na neslužbene varijacije u izvornim dokumentima. Najbliže susjedske udaljenosti su jako osjetljive na male promjene u tržišnom korpusu za razne algoritme. Za sve metode, uključujući specifične dokumente u skupini obuke, mogu rezultirati značajne varijacije. Pokazujemo da su te učinke važnije za manje obuku. Preporučujemo da se korisnici nikada ne oslanjaju na jednog ugrađenog modela za izračune udaljenosti, nego prosječan preko višestrukih uzorka šampanjca, posebno za male korporacije.</abstract_hr>
      <abstract_id>Pencampuran kata semakin digunakan sebagai alat untuk mempelajari asosiasi kata dalam corpora spesifik. Namun, tidak jelas apakah bentuk tersebut mencerminkan properti bahasa yang kekal atau apakah mereka sensitif kepada variasi yang tidak konsekuensi dalam dokumen sumber. Kami menemukan bahwa jarak tetangga terdekat sangat sensitif untuk perubahan kecil dalam korpus latihan untuk berbagai algoritma. Untuk semua metode, termasuk dokumen spesifik dalam set pelatihan dapat menghasilkan variasi yang besar. Kami menunjukkan bahwa efek ini lebih terkenal untuk korpora pelatihan yang lebih kecil. Kami merekomendasikan bahwa pengguna tidak pernah bergantung pada satu model embedding untuk perhitungan jarak, tetapi rata-rata lebih banyak sampel bootstrap, terutama untuk korpora kecil.</abstract_id>
      <abstract_ko>단어 삽입은 특정어 자료 라이브러리에서 단어와 관련된 연구를 위한 도구로 점점 더 많이 사용되고 있다.그러나 이 삽입이 언어의 지속적인 속성을 반영하거나 원본 파일의 중요하지 않은 변화에 민감한지 아직은 알 수 없다.우리는 각종 알고리즘에 대해 최근 인접 거리가 훈련 자료 라이브러리의 미세한 변화에 대해 매우 민감하다는 것을 발견했다.교육 집합의 특정 문서를 포함한 모든 방법은 중대한 변화를 초래할 수 있다.우리는 비교적 작은 훈련 자료 라이브러리에 대한 이러한 영향이 더욱 현저하다는 것을 발견했다.우리는 사용자가 한 개의 삽입 모델에 의존하여 거리를 계산하지 말고 여러 개의 안내 견본에서 평균치를 구하는 것을 권장합니다. 특히 소형 어료 라이브러리에 대해서는.</abstract_ko>
      <abstract_fa>استفاده کردن کلمات بیشتر به عنوان ابزار برای مطالعه اتصال کلمات در شرکت خاص استفاده می‌شود. ولی مشخص نیست که آیا این وسیله‌ها ویژگی‌های پایداری زبان را نشان می‌دهند یا اگر آنها به تغییرات ناپایداری در سند منبع حساس هستند. ما پیدا می‌کنیم که فاصله‌های نزدیک‌ترین همسایه‌ها بسیار حساس به تغییرات کوچک در شرکت آموزش برای مختلف الگوریتم هستند. برای همه روش، شامل مدارک خاص در مجموعه آموزش می تواند به نتیجه تغییرات زیادی برساند. ما نشان می دهیم که این اثرات برای شرکت آموزش کوچکتر مهم تر است. ما پیشنهاد می‌کنیم که کاربران هرگز بر یک مدل وارد کردن برای محاسبات فاصله اعتماد نکنند، ولی بیشتر متوسط بر نمونه‌های زیادی از پرده‌ها، مخصوصا برای شرکت کوچک.</abstract_fa>
      <abstract_tr>Kelime birlikleri h채zirki korporada s철z birliklerini 철wrenmek 체챌in ullan첵ar. 횦agna g철r채, 힊e첵le d체z체mler dili흫 s체rekli h채si첵etlerini 첵ada-da munu흫 챌e힊itli senedi흫 체첵tgewlerine g철r채 g철r채 bilme첵채n d채l. Biz go흫힊ulary흫 i흫 첵akyn meseleleri k철p체de 철r채n g철rn체힊 algoritmalar 체챌in ki챌i 체첵tgewlere hasaplan첵arys. 횉altylyk d체z체mlerinde takyk senedi흫 hemme y철ntemleri 체챌in 철r채n 체첵tge힊ikleri bolup biler. Biz bu t채sirler ki챌ir채k okuw korporasy 체챌in has m철h체m bolandygyny g철rke첵채ris. Qullan캇c캇lary흫 hi챌 ha챌an uzak hesaplamak 체챌in bir integr modellerine ynanma첵andygyny maslahat ediyoruz, 첵철ne ortalama birden 챌oklu sistem 철rneklerinden, 철zellikle ki챌i korpora 체챌in.</abstract_tr>
      <abstract_sw>Matambo yanatumiwa kwa kiasi kikubwa kama zana ya kusoma mashirika ya maneno katika kampuni maalum. Hata hivyo, haijaweka wazi kama vifaa hivyo vinaonyesha utafiti wa kudumu wa lugha au kama vina uelewa wa mabadiliko yasiyoeleweka katika nyaraka za chanzo. Tunapata kwamba umbali wa karibu wa jirani ni wenye uelewa sana wa mabadiliko madogo katika makampuni ya mafunzo kwa ajili ya miolori mbalimbali. Kwa njia zote, ikiwa ni pamoja na nyaraka maalum katika seti ya mafunzo, kunaweza kusababisha mabadiliko makubwa. Tunaonyesha kwamba madhara haya ni makubwa zaidi kwa kampuni ndogo ya mafunzo. Tunawapendekeza kwamba watumiaji hawategemea mifano moja kwa ajili ya hisabu za mbali, bali kwa wastani zaidi ya sampuli mbalimbali za boot, hasa kwa kampuni ndogo.</abstract_sw>
      <abstract_af>Woord inbêding word vermeerder gebruik word as 'n nutsprogram om woord assosiasies in spesifieke korpora te studeer. Maar dit is onbekende of sodanige inbettings reflekteer voortdurende eienskappe van taal of as hulle sensitief is tot onvolgende veranderinge in die bron dokumente. Ons vind dat nabiese-nabiese afstande baie sensitief is na klein veranderinge in die onderwerp korpus vir 'n verskillende algoritme. Vir alle metodes, insluitend spesifieke dokumente in die onderwerp stel kan resultaat in substantiele variasies. Ons wys dat hierdie effekte meer bekend is vir kleiner onderwerp korpora. Ons aanbeveel dat gebruikers nooit op enkele inbêding modele vertrou nie vir afstand berekenings, maar eerder gemiddelde oor veelvuldige bootstrap voorbeelde, veral vir klein korpora.</abstract_af>
      <abstract_sq>Word embeddings are increasingly being used as a tool to study word associations in specific corpora.  Megjithatë, nuk është e qartë nëse përfshirjet e tilla reflektojnë pronësitë e vazhdueshme të gjuhës apo nëse ato janë të ndjeshme ndaj variacioneve jo sekuencuese në dokumentet e burimit. Gjetëm se distancat më të afërta të fqinjëve janë shumë të ndjeshme ndaj ndryshimeve të vogla në trupin e stërvitjes për një varietet algoritmesh. Për të gjitha metodat, duke përfshirë dokumente specifike në grupin e trajnimit mund të rezultojnë në variacione thelbësore. Ne tregojmë se këto efekte janë më të rëndësishme për korporatën më të vogël të trajnimit. Ne rekomandojmë që përdoruesit të mos mbështeten kurrë në modele të vetme të përfshirjes për llogaritje të distancës, por mesatare mbi kampione të shumta bootstrap, veçanërisht për korpra të vogla.</abstract_sq>
      <abstract_am>የቃላት ግንኙነቶች በተለያዩ ኮርፖርት ቃላት ማኅበረሰቦችን ለማስተምር መጠቀሚያ ሆኗል፡፡ ነገር ግን እንደዚህ ያሉ አካባቢዎች የቋንቋን አካላት ማሳየት ወይም በመጀመሪያው ሰነድ ውስጥ ያልተቃውሞ ለውጦችን ማሳየት አይችልም፡፡ የቅርብ ጎረቤቶች ርቀት በተለያዩ የአልጎሪም ክፍል ለትንሽ ለውጦች እንደሚያሳየው ነው ብለን እናገኛለን፡፡ ለሁሉም ሥርዓቶች፣ የተለየ ሰነዱን በሙሉ ማሰናከል ማቀናቀል ይችላል፡፡ ይህች ማስታወቂያው ትንሽ ትምህርት ኮርፖርት ላይ የተለየ ነው ብለን እናሳያቸዋለን፡፡ በተጠቃሚዎች አንዲት የራቀ ቁጥጥር ማድረግ እንዳይታመኑ እናመክራለን፣ ነገር ግን አብዛኛው ብዙዎች የቡቶክራፕሮግራም ምሳሌዎች ይልቁንም ለትንሽ ኮርፖርት ነው፡፡</abstract_am>
      <abstract_bn>বিশেষ কর্পোরায় শব্দ সংস্থা পড়ার একটি টুল হিসেবে ব্যবহার করা হচ্ছে। তবে এটা পরিষ্কার নয় যে এই ধরনের বিভিন্ন ভাষার দৈর্ঘ্যের বৈশিষ্ট্য প্রতিফলিত করে কি না অথবা উৎসের নথিপত্রের বিভিন্ন ভিন্ন ভিন আমরা দেখতে পাচ্ছি যে কাছাকাছি প্রতিবেশী দূরত্ব বিভিন্ন অ্যালগরিদমের জন্য প্রশিক্ষণ কোর্পাসে ছোট পরিবর্তনের জন্য অত্যন্ For all methods, including specific documents in the training set can result in substantial variations.  আমরা দেখাচ্ছি যে এই প্রভাব ছোট প্রশিক্ষণ কোর্পোরার জন্য বেশী গুরুত্বপূর্ণ। আমরা পরামর্শ দিচ্ছি যে ব্যবহারকারীরা দূরত্ব গণনা করার জন্য কখনোই একক এমপেডিং মডেলের উপর নির্ভর করে না, কিন্তু সাধারণ বুটস্ট্র্যাপ টাম</abstract_bn>
      <abstract_hy>Բառերի ներառումները ավելի ու ավելի օգտագործվում են որպես գործիք բառերի կապերի ուսումնասիրելու համար որոշակի մարմնում: Այնուամենայնիվ, անհասկանալի չէ, արդյոք նման ներդրումները արտացոլում են լեզվի կայուն հատկությունները, թե արդյոք դրանք զգայուն են աղբյուրների փաստաթղթերի անհետաքրքիր տարբերությունների նկատմամբ: Մենք հայտնաբերում ենք, որ ամենամոտ հարևանների հեռավորությունը շատ զգայուն է փոքր փոփոխությունների դեպքում ուսուցման մարմնի բազմաթիվ ալգորիթմների համար: Բոլոր մեթոդների համար, ներառյալ մասնավոր փաստաթղթերը կրթության համակարգում, կարող են հանգեցնել նշանակալի տարբերությունների: We show that these effects are more prominent for smaller training corpora.  Մենք խորհուրդ ենք տալիս, որ օգտագործողները երբեք չեն հույս ունենա հեռավորության հաշվարկների համար միակ ներդրման մոդելների վրա, այլ միջինի վրա բազմաթիվ սկզբնական նմուշների վրա, հատկապես փոքր մարմնի համար:</abstract_hy>
      <abstract_az>Sözlük in şalları məxluqatın məxluqatını təhsil etmək üçün daha çox istifadə edilir. Ancaq bu səbəbdən istifadə edilənlər dilin səbəbi özelliklərini göstərməyiniz və ya mənbə belələrində sonsuz dəyişiklikləri üzərində hiss edirlər. Ən yaxın qonşuların uzaqlaşması, müxtəlif algoritmlər üçün təhsil corpusunda küçük dəyişikliklərə çox hassaslıdır. Bütün metodlar üçün, təhsil qurduğu müəyyən dəyişikliklər də dahil edə bilər. Biz bu təsirlərin küçük təhsil korporası üçün daha böyük olduğunu göstəririk. Biz istifadəçilərin uzaq hesablamalar üçün təkcə təkcə sadiq modellərə təvəkkül etməsini tavsiye edirik, lakin çoxlu bootstrap nümunələrindən ortalamaq, özellikle kiçik corpora üçün.</abstract_az>
      <abstract_bs>Povećavaju se uključenje riječi kao alat za proučavanje udruženja riječi u određenoj korpori. Međutim, nije jasno da li su takve ugrađenje odražavale trajne vlasništvo jezika ili da su osjetljive na neposredne varijacije u izvornim dokumentima. Smatramo da su najbliže susjedske udaljenosti jako osjetljive na male promjene u trening korpusu za različite algoritme. Za sve metode, uključujući specifične dokumente u setu obuke, mogu rezultirati značajne varijacije. Pokazujemo da su ovi efekti važniji za manje obuku. Preporučujemo da korisnici nikad ne oslanjaju na jednog ugrađenog modela za izračune udaljenosti, već prosječan preko višestrukih uzorka cipela, posebno za male korpore.</abstract_bs>
      <abstract_ca>Les integracions de paraules s'utilitzen cada cop més com una eina per estudiar associacions de paraules en corpores específics. No obstant això, no és clar si aquestes incorporacions reflecteixen les propietats durables del llenguatge o si són sensibles a variacions inconseqüents dels documents d'origen. Trobem que les distàncies més properes dels veïns són molt sensibles a petits canvis en el cos d'entrenament per a una varietat d'algoritmes. Per a tots els mètodes, incloent documents específics en el conjunt d'entrenaments, poden resultar en variacions substancials. Mostrem que aquests efectes són més prominents per a corpores de formació més petits. Recomendem que els usuaris mai confiin en models d'integració únics per a calcular la distància, sinó en mitjana sobre múltiples mostres de bootstrap, especialment per a petites corpores.</abstract_ca>
      <abstract_cs>Vložení slov se stále více používají jako nástroj ke studiu slovních asociací v konkrétních korpusech. Není však jasné, zda takové vložení odrážejí trvalé vlastnosti jazyka nebo zda jsou citlivé na nepodstatné změny ve zdrojových dokumentech. Zjišťujeme, že vzdálenosti nejbližších sousedů jsou vysoce citlivé na malé změny tréninkového korpusu pro různé algoritmy. U všech metod, včetně konkrétních dokumentů v souboru školení, může vést k podstatným rozdílům. Ukazujeme, že tyto efekty jsou výraznější u menších tréninkových korpusů. Doporučujeme uživatelům nikdy spoléhat na jednotlivé modely pro výpočty vzdálenosti, ale spíše průměrné nad více bootstrap vzorků, zejména u malých korpusů.</abstract_cs>
      <abstract_fi>Sanaupotuksia käytetään yhä enemmän työkaluna sanayhteyksien tutkimiseen tietyissä korpusissa. On kuitenkin epäselvää, heijastavatko tällaiset upotukset kielen pysyviä ominaisuuksia vai ovatko ne herkkiä lähdeasiakirjojen merkittäville vaihteluille. Havaitsemme, että lähimmän naapurin etäisyydet ovat erittäin herkkiä pienille muutoksille harjoituskorpusessa erilaisten algoritmien osalta. Kaikilla menetelmillä, myös erityisillä asiakirjoilla, voi olla huomattavia eroja. Osoitamme, että nämä vaikutukset ovat näkyvämpiä pienemmillä harjoituskorpusilla. Suosittelemme, että käyttäjät eivät koskaan luota yksittäisiin upotusmalleihin etäisyyslaskelmissa, vaan pikemminkin keskimääräisiin useisiin bootstrap-näytteisiin, erityisesti pienille yrityksille.</abstract_fi>
      <abstract_et>Sõnade manustamist kasutatakse üha enam vahendina sõnaseoste uurimiseks konkreetsetes korpustes. Siiski on ebaselge, kas sellised manustamised kajastavad keele püsivaid omadusi või kas need on tundlikud lähtedokumentide oluliste muutuste suhtes. Leiame, et lähima naabri vahemaad on väga tundlikud väikeste muutuste suhtes erinevate algoritmide treeningkorpuses. Kõikide meetodite puhul, sealhulgas koolituskomplekti konkreetsete dokumentide lisamine, võib põhjustada olulisi erinevusi. Me näitame, et need mõjud on silmapaistvamad väiksemate treeningkorpuste puhul. Soovitame, et kasutajad ei toetuks kauguse arvutamiseks kunagi üksikutele manustamismudelitele, vaid pigem keskmisele mitme bootstrap-näidise puhul, eriti väikeste korporatsioonide puhul.</abstract_et>
      <abstract_jv>embedding Nanging Awak dhéwé éntuk akeh langgar-wong liyane gak dhéwé ngerasakno karo ngono perusahaan langgar tarjamahan kanggo kalaayé Algorithm. Genjer-Genjer Awak dhéwé ngomong nik efek iki luwih akeh perusahaan kanggo ngerasakno Awak dhéwé tukong ngomong nik akeh pengguna-pengguna ngono model sing nyelehake karo kalem tukang, njuk kuwi etiket dadi sabanjur sing manut karo sistem sing bisa pasar, supoyo akeh sampur mbut sing apik.</abstract_jv>
      <abstract_he>המילים משתמשות יותר ויותר בתור כלי ללמוד איגודות מילים בקופורה ספציפית. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents.  אנחנו מוצאים שמרחקים השכנים הקרובים ביותר רגישים מאוד לשינויים קטנים בקורפוס האימונים למגוון של אלגוריתמים. לכל השיטות, כולל מסמכים ספציפיים בתוכנית האימונים, יכולים לגרום להחלטות משמעותיות. אנחנו מראים שהתופעות האלה יותר ברוכות עבור גופורה אימונים קטנה יותר. אנו ממליצים שמשתמשים לעולם לא יסמוך על דוגמנים חדים למחשבות מרחק, אלא בממוצע על דוגמנים מרובים של חטיפי טיסה, במיוחד עבור גופרה קטנה.</abstract_he>
      <abstract_sk>Vgradnje besed se vedno bolj uporablja kot orodje za preučevanje besednih asociacij v določenih korpusih. Vendar ni jasno, ali takšne vdelave odražajo trajne lastnosti jezika ali so občutljive na nepomembne spremembe izvornih dokumentov. Ugotavljamo, da so razdalje najbližje sosede zelo občutljive na majhne spremembe v korpusu usposabljanja za različne algoritme. Pri vseh metodah, vključno s posebnimi dokumenti v nabor usposabljanja, lahko pride do bistvenih razlik. Pokazali smo, da so ti učinki bolj vidni za manjše korpuse usposabljanja. Priporočamo, da se uporabniki nikoli ne zanašajo na posamezne modele vdelave za izračun razdalje, temveč na povprečje več vzorcev zagona, zlasti za majhne korpuse.</abstract_sk>
      <abstract_ha>An ƙara amfani da maganar da aka shigar da shi kamar zance wa karanta associations da ke cikin korpo na ƙayyade. Babu gane, ko da waɗannan da ke fitarwa, za'a yi amfani da wasu properties na harshen ko kuma idan an gane su da musamman da ke cikin takardun kwanan. Muna gane cewa tsakanin jiran nan masu kamfata da musanyi masu ƙaranci na musanyi cikin makaron da aka yi wa karatun algorisi dabam-dabam. @ action: button Tuna nũna cewa waɗannan muhimmada ne mafiya girma ga makampuni ƙarami. Munã shawarar da mai amfani da shi, bã zã su dõgara ga misãlai guda ba dõmin hisãbi mai nĩsa, kuma amma, tsammaci ne kan misãlai masu yawa masu ƙaranci, kuma haske dõmin ƙarami ƙarami.</abstract_ha>
      <abstract_bo>སྦུང་མཐུད་པའི་ཡིག་ཆ་སྒྲིག་འཛུགས་ཀྱི་ནང་དུ་ཡི་གེ་འབྲེལ་མཐུད་དང་མཐུད་སྣེ་ཐོག་ཏུ་ལག་ལེན་འཐབ་འདུག ཡིན་ནའང་། འདིའི་ནང་དུ་ཡིག་ཚང་མས་སྐད་ཀྱི་ངོ་བོ་ལ་མཚུངས་ཡོད་མིན་ན། ང་ཚོར་ཉེ་བའི་ཁྱིམ་མཚེས་གཡས་གཡོན་གྱི་བར་སྐབས་སུ་མཐོང་བ་མི་འདུག གྲི་སྒྲིག་འཛུགས་ནང་དུ་ཡིག་ཆ་དམིགས་བསལ་གྱི་ཐབས་ལམ་ཡོངས་རྫོགས་ལ་སྒྲིག་འགོད་ནང་གི་ཡིག ང་ཚོའི་དབུལ་འབྲེལ་འདི་དག་སྒོ་འབྱེད་གྱི་བསྡུས་ལས་ཆེན་པོ་ཤིག་ཏུ་ཆེ་མཐོང་བ་རེད། ང་ཚོས་ལག་ལེན་པ་ཚོའི་རྩིས་ལས་བར་ཐག་རིང་ལ་གྲངས་ཀ་ལས་ཕན་ཚུན་ཁག་ཅིག་གིས་okiག་འཛུགས་མེད་པར་སྟོན་རྒྱུ་བྱེད་དགོས</abstract_bo>
      </paper>
    <paper id="10">
      <title>Learning Representations Specialized in Spatial Knowledge : Leveraging Language and Vision</title>
      <author><first>Guillem</first><last>Collell</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <doi>10.1162/tacl_a_00010</doi>
      <abstract>Spatial understanding is crucial in many real-world problems, yet little progress has been made towards building <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> that capture <a href="https://en.wikipedia.org/wiki/Spatial_memory">spatial knowledge</a>. Here, we move one step forward in this direction and learn such <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> by leveraging a task consisting in predicting continuous 2D spatial arrangements of objects given object-relationship-object instances (e.g., cat under chair) and a simple <a href="https://en.wikipedia.org/wiki/Neural_network">neural network model</a> that learns the task from <a href="https://en.wikipedia.org/wiki/Annotation">annotated images</a>. We show that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> succeeds in this task and, furthermore, that it is capable of predicting correct spatial arrangements for unseen objects if either CNN features or <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> of the objects are provided. The differences between visual and linguistic features are discussed. Next, to evaluate the spatial representations learned in the previous <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we introduce a <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> consisting in a set of crowdsourced human ratings of spatial similarity for object pairs. We find that both CNN (convolutional neural network) features and word embeddings predict human judgments of similarity well and that these vectors can be further specialized in spatial knowledge if we update them when training the model that predicts spatial arrangements of objects. Overall, this paper paves the way towards building distributed spatial representations, contributing to the understanding of spatial expressions in language.</abstract>
      <pages>133–144</pages>
      <url hash="3c9992cb">Q18-1010</url>
      <bibkey>collell-moens-2018-learning</bibkey>
      <pwccode url="https://github.com/gcollell/spatial-representations" additional="false">gcollell/spatial-representations</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    <title_ar>تمثيلات التعلم المتخصصة في المعرفة المكانية: الاستفادة من اللغة والرؤية</title_ar>
      <title_pt>Representações de Aprendizagem Especializadas em Conhecimento Espacial: Alavancando Linguagem e Visão</title_pt>
      <title_fr>Représentations d'apprentissage spécialisées dans la connaissance spatiale : tirer parti du langage et de la vision</title_fr>
      <title_es>Representaciones de aprendizaje especializadas en conocimiento espacial: aprovechamiento del lenguaje y la visión</title_es>
      <title_ja>空間知識に特化した学習表現：言語とビジョンの活用</title_ja>
      <title_zh>学空知专业表徵,利用语言和视觉</title_zh>
      <title_hi>सीखना प्रतिनिधित्व स्थानिक ज्ञान में विशेष: भाषा और दृष्टि का लाभ उठाना</title_hi>
      <title_ru>Учебные представления, специализирующиеся на пространственных знаниях: использование языка и видения</title_ru>
      <title_ga>Léiriúcháin Foghlama Speisialaithe in Eolas Spásúlachta: Ag Giaráil Teanga agus Fís</title_ga>
      <title_ka>სპეციალური მეცნიერებაში სპეციალური გამოსწავლება: სისტემალური მეცნიერებაში</title_ka>
      <title_hu>A térismeretekre specializálódott tanulási reprezentációk: a nyelv és a látás kihasználása</title_hu>
      <title_el>Εξειδικευμένες στη χωρική γνώση: Αξιοποίηση της γλώσσας και του οράματος</title_el>
      <title_it>Rappresentanze di apprendimento specializzate nella conoscenza spaziale: sfruttare il linguaggio e la visione</title_it>
      <title_mk>Учење претставувања специјализирани во просторно знаење: Разголемување на јазикот и визијата</title_mk>
      <title_kk>Бос мәліметінде өзгертілген кескіндерді оқыту: Тіл және көрініс</title_kk>
      <title_lt>Mokymosi atstovybės, specializuotos erdvės žiniomis: kalbos ir vizijos didinimas</title_lt>
      <title_ms>Belajar Perwakilan yang Dikhususkan dalam Pengetahuan Ruang: Menegang Bahasa dan Pandangan</title_ms>
      <title_ml>സ്പെയില്‍ അറിവില്‍ പ്രത്യേകിച്ചുള്ള പ്രതിനിധികള്‍ പഠിക്കുന്നു</title_ml>
      <title_mt>Rappreżentazzjonijiet ta’ Tagħlim Speċjalizzati fl-Għarfien Spazjali: L-Iżvilupp tal-Lingwa u l-Viżjoni</title_mt>
      <title_mn>Сургуулийн мэдлэгт төсөөлж суралцах суралцах: Холбоотой хэл, үзэл</title_mn>
      <title_sr>Naučenje predstavljanja specijalizovanih u svemirskom znanju: proizvodnja jezika i vizije</title_sr>
      <title_no>Læringsrepresentasjonar spesifisert i mellomromkunnskap: Leveraging Language and Vision</title_no>
      <title_si>ස්පේසියල් දන්නවයේ විශේෂ විශේෂ විදියට ඉගෙන ගන්න</title_si>
      <title_pl>Wyspecjalizowane w wiedzy przestrzennej: wykorzystanie języka i wizji</title_pl>
      <title_ro>Reprezentanțe de învățare specializate în cunoștințe spațiale: valorificarea limbajului și viziunii</title_ro>
      <title_so>Barista Representations Specialized in ku qoran aqoonta Spatial: Leveraging Language and Vision</title_so>
      <title_ta>வெற்று அறிவியலில் சிறப்பான பிரதிநிகழ்வுகளை கற்றுக்கொள்வது: எழுத்து மொழி மற்றும் பார்வையும்</title_ta>
      <title_sv>Läranderepresentationer specialiserade på rumslig kunskap: Utnyttja språk och vision</title_sv>
      <title_ur>جگہ علم میں مخصوص معلومات کی تعلیم کی تعلیم: زبان اور نظر</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Phụ trách giáo dục Đặc biệt về địa phương học:</title_vi>
      <title_da>Læringsrepræsentationer Specialiseret i rumlig viden: Udnyttelse af sprog og vision</title_da>
      <title_de>Lernrepräsentationen Spezialisiert auf räumliches Wissen: Sprache und Vision nutzen</title_de>
      <title_hr>Predstavnici za učenje specijalizirani u svemirskom znanju: proizvodnja jezika i vizije</title_hr>
      <title_nl>Leervertegenwoordigingen gespecialiseerd in ruimtelijke kennis: Gebruik maken van taal en visie</title_nl>
      <title_bg>Учебни представителства, специализирани в пространствени знания: усвояване на езика и визията</title_bg>
      <title_id>Belajar Perwakilan yang Spesialisasi dalam Pengetahuan Ruang: Menegang Bahasa dan Visi</title_id>
      <title_ko>공간 지식의 학습 표징: 언어와 시각을 이용하다</title_ko>
      <title_sw>Kujifunza maoni yaliyohusishwa kwa ufahamu wa Hispania: Lugha ya Uandishi na Maoni</title_sw>
      <title_tr>Gaýd bilgi bilen aýratyn öwrenmek: Dili we Görnüş</title_tr>
      <title_sq>Mësimi i përfaqësimeve të specializuara në njohuri hapësirore: zgjerimi i gjuhës dhe vizionit</title_sq>
      <title_am>በተስፓኒያ እውቀት የተለየ ተሟጋቾች ማስተማር: ቋንቋ እና ራእይ</title_am>
      <title_az>Uzay Biliml톛rind톛 칐yr톛n톛n 칐yr톛nm톛k: Dili v톛 G칬z칲</title_az>
      <title_hy>Գիտել տարածական գիտելիքներում մասնավորված ներկայացումներ. լեզու և տեսողության բարձրացման</title_hy>
      <title_bs>Predstavnici za učenje specijalizovane u svemirskom znanju: Usporavanje jezika i vizije</title_bs>
      <title_fa>ЫҢШ§ШҜЪҜЫҢШұЫҢ ЩҶЩ…Ш§ЫҢШҙвҖҢЩҮШ§ЫҢ ЩҲЫҢЪҳЩҮвҖҢШ§ЫҢ ШҜШұ ШҜШ§ЩҶШҙ ЩҒШ¶Ш§ЫҢЫҢ: ШӘШәЫҢЫҢШұ ШҜЩҮЩҶШҜЩҮ ШІШЁШ§ЩҶ ЩҲ ШҜЫҢШҜ</title_fa>
      <title_cs>Výukové zastoupení specializované na prostorové znalosti: využití jazyka a vize</title_cs>
      <title_ca>Aprendre representacions especialitzades en coneixement espacial: ampliar la llengua i la visió</title_ca>
      <title_fi>Paikkatietouteen erikoistuneet oppimisedustustot: kielen ja vision hyödyntäminen</title_fi>
      <title_af>Leer voorstellings gespesifiseer in Spasiele kennis: Leveraging Language and Vision</title_af>
      <title_et>Ruumilistele teadmistele spetsialiseerunud õppeesindused: keele ja visiooni kasutamine</title_et>
      <title_bn>স্পেশিয়াল জ্ঞানে বিশেষ প্রতিনিধি শিক্ষা শিখা: লেভারেজিং ভাষা এবং ভিশন</title_bn>
      <title_sk>Učna predstavništva, specializirana za prostorsko znanje: spodbujanje jezika in vizije</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>לימוד מייצגים מיוחדים במידע חללי: השפה והחזון</title_he>
      <title_jv>Ngerti Rayakno Kemerdekaan Rusak</title_jv>
      <title_bo>ས་གནས་ཤེས་པའི་ནང་དུ་དམིགས་བསལ་ཅན་གྱི་Representations Learning Representations Specialized in Spatial Knowledge: Leveraging Language and Vision</title_bo>
      <abstract_ar>يعد الفهم المكاني أمرًا بالغ الأهمية في العديد من مشكلات العالم الحقيقي ، ومع ذلك تم إحراز تقدم ضئيل نحو بناء التمثيلات التي تلتقط المعرفة المكانية. هنا ، نتحرك خطوة واحدة للأمام في هذا الاتجاه ونتعلم مثل هذه التمثيلات من خلال الاستفادة من مهمة تتكون في التنبؤ بالترتيبات المكانية ثنائية الأبعاد المستمرة للكائنات التي تُعطى مثيلات كائن علاقة الكائن (على سبيل المثال ، "القط تحت الكرسي") ونموذج الشبكة العصبية البسيط الذي يتعلم المهمة من الصور المشروحة. نظهر أن النموذج نجح في هذه المهمة ، علاوة على أنه قادر على التنبؤ بالترتيبات المكانية الصحيحة للأشياء غير المرئية إذا تم توفير ميزات CNN أو تضمين الكلمات للأشياء. تمت مناقشة الاختلافات بين السمات المرئية واللغوية. بعد ذلك ، لتقييم التمثيلات المكانية التي تم تعلمها في المهمة السابقة ، نقدم مهمة ومجموعة بيانات تتكون من مجموعة من التصنيفات البشرية التعهيد الجماعي للتشابه المكاني لأزواج الكائنات. لقد وجدنا أن ميزات كل من CNN (الشبكة العصبية التلافيفية) ودمج الكلمات تتنبأ بالأحكام البشرية للتشابه جيدًا وأن هذه النواقل يمكن أن تكون أكثر تخصصًا في المعرفة المكانية إذا قمنا بتحديثها عند تدريب النموذج الذي يتنبأ بالترتيبات المكانية للأشياء. بشكل عام ، تمهد هذه الورقة الطريق نحو بناء تمثيلات مكانية موزعة ، مما يساهم في فهم التعبيرات المكانية في اللغة.</abstract_ar>
      <abstract_fr>La compréhension spatiale est cruciale dans de nombreux problèmes du monde réel, mais peu de progrès ont été réalisés dans la création de représentations qui capturent la connaissance spatiale. Ici, nous faisons un pas en avant dans cette direction et apprenons de telles représentations en tirant parti d'une tâche consistant à prédire des arrangements spatiaux 2D continus d'objets donnés par des instances objet-relation objet (par exemple, « chat assis sur une chaise ») et un modèle de réseau neuronal simple qui apprend la tâche à partir d'annotations images. Nous montrons que le modèle réussit cette tâche et, en outre, qu'il est capable de prédire des arrangements spatiaux corrects pour des objets invisibles si des caractéristiques CNN ou des incorporations de mots des objets sont fournies. Les différences entre les caractéristiques visuelles et linguistiques sont discutées. Ensuite, pour évaluer les représentations spatiales apprises au cours de la tâche précédente, nous introduisons une tâche et un jeu de données consistant en un ensemble d'évaluations humaines de similitude spatiale pour des paires d'objets. Nous trouvons que les caractéristiques CNN (réseau neuronal convolutionnel) et les intégrations de mots prédisent bien les jugements humains de similitude et que ces vecteurs peuvent être spécialisés davantage dans la connaissance spatiale si nous les actualisons lors de l'entraînement du modèle qui prédit les arrangements spatiaux des objets. Dans l'ensemble, cet article ouvre la voie à la création de représentations spatiales distribuées, contribuant ainsi à la compréhension des expressions spatiales dans le langage.</abstract_fr>
      <abstract_pt>A compreensão espacial é crucial em muitos problemas do mundo real, mas pouco progresso foi feito na construção de representações que capturem o conhecimento espacial. Aqui, avançamos um passo nessa direção e aprendemos tais representações aproveitando uma tarefa que consiste em prever arranjos espaciais 2D contínuos de objetos dadas instâncias objeto-relacionamento-objeto (por exemplo, “gato na cadeira”) e um modelo de rede neural simples que aprende a tarefa a partir de imagens anotadas. Mostramos que o modelo é bem-sucedido nessa tarefa e, além disso, é capaz de prever arranjos espaciais corretos para objetos não vistos se forem fornecidos recursos de CNN ou embeddings de palavras dos objetos. As diferenças entre recursos visuais e linguísticos são discutidas. Em seguida, para avaliar as representações espaciais aprendidas na tarefa anterior, introduzimos uma tarefa e um conjunto de dados que consiste em um conjunto de classificações humanas de semelhança espacial para pares de objetos. Descobrimos que tanto os recursos da CNN (rede neural convolucional) quanto os embeddings de palavras predizem bem os julgamentos humanos de similaridade e que esses vetores podem ser ainda mais especializados em conhecimento espacial se os atualizarmos ao treinar o modelo que prevê arranjos espaciais de objetos. De modo geral, este artigo abre caminho para a construção de representações espaciais distribuídas, contribuindo para a compreensão das expressões espaciais na linguagem.</abstract_pt>
      <abstract_ja>空間的理解は多くの現実世界の問題において重要であるが、空間的知識を取り込む表現を構築する上ではほとんど進展していない。 ここで、我々は、この方向に一歩前進し、所与のオブジェクト関係オブジェクトインスタンス（例えば、「椅子の下の猫」）のオブジェクトの連続２ Ｄ空間配置を予測するタスクと、注釈付き画像からタスクを学習する単純なニューラルネットワークモデルとを活用することによって、そのような表現を学習する。 我々は、モデルがこのタスクに成功し、さらに、オブジェクトのCNNフィーチャーまたはワード埋め込みのいずれかが提供されている場合、見えないオブジェクトの正しい空間配置を予測することができることを示します。 視覚的特徴と言語的特徴の違いについて論じた。 次に、前のタスクで学習した空間表現を評価するために、タスクと、オブジェクトペアの空間類似性のクラウドソーシングされた人間評価のセットからなるデータセットを紹介します。 CNN （畳み込みニューラルネットワーク）の特徴と単語埋め込みの両方が、類似性の人間の判断をうまく予測しており、これらのベクトルは、オブジェクトの空間配置を予測するモデルをトレーニングする際にそれらを更新すると、空間知識にさらに特化することができることがわかっています。 全体として、この論文は分散空間表現の構築への道を開き、言語における空間表現の理解に貢献する。</abstract_ja>
      <abstract_zh>空知世界重,构得空知微。 于是向此而进,因一而学之,其占给定所 - - 连2D空列(如椅下猫),及注象之略神经网络。 吾明其成功以成其事,而供CNN词,可以占不见之正也。 论视觉特征、语言特征之异。 接下来,估计在上一个务中学到的空间,我们引入了一个职务和一个数据集,该数据集由一朋众包的空间相似性人们评级成。 CNN(卷积神经网络)特征与词嵌皆善占相似性,若于训练之间,排列更新,向量可更专于空间。 总体而言,本文构分布式空铺平道路,有助于解语。</abstract_zh>
      <abstract_hi>स्थानिक समझ कई वास्तविक दुनिया की समस्याओं में महत्वपूर्ण है, फिर भी स्थानिक ज्ञान पर कब्जा करने वाले अभ्यावेदनों के निर्माण की दिशा में बहुत कम प्रगति हुई है। यहां, हम इस दिशा में एक कदम आगे बढ़ते हैं और ऑब्जेक्ट-रिलेशनशिप-ऑब्जेक्ट इंस्टेंस (जैसे, "कुर्सी के नीचे बिल्ली") और एक साधारण तंत्रिका नेटवर्क मॉडल जो एनोटेट छवियों से कार्य सीखता है, दिए गए ऑब्जेक्ट्स की निरंतर 2 डी स्थानिक व्यवस्था की भविष्यवाणी करने वाले कार्य का लाभ उठाकर इस तरह के अभ्यावेदन सीखते हैं। हम दिखाते हैं कि मॉडल इस कार्य में सफल होता है और, इसके अलावा, यह अनदेखी वस्तुओं के लिए सही स्थानिक व्यवस्था की भविष्यवाणी करने में सक्षम है यदि या तो सीएनएन विशेषताएं या वस्तुओं के शब्द एम्बेडिंग प्रदान किए जाते हैं। दृश्य और भाषाई विशेषताओं के बीच के अंतर पर चर्चा की जाती है। अगला, पिछले कार्य में सीखे गए स्थानिक प्रतिनिधित्वों का मूल्यांकन करने के लिए, हम एक कार्य और एक डेटासेट पेश करते हैं जिसमें ऑब्जेक्ट जोड़े के लिए स्थानिक समानता के क्राउडसोर्स मानव रेटिंग के एक सेट शामिल होते हैं। हम पाते हैं कि सीएनएन (convolutional तंत्रिका नेटवर्क) सुविधाओं और शब्द एम्बेडिंग दोनों समानता के मानव निर्णय की भविष्यवाणी करते हैं और इन वैक्टरों को स्थानिक ज्ञान में और अधिक विशिष्ट किया जा सकता है यदि हम उन्हें अपडेट करते हैं जब मॉडल को प्रशिक्षित करते हैं जो वस्तुओं की स्थानिक व्यवस्था की भविष्यवाणी करता है। कुल मिलाकर, यह पेपर वितरित स्थानिक प्रतिनिधित्व के निर्माण की दिशा में मार्ग प्रशस्त करता है, जो भाषा में स्थानिक अभिव्यक्तियों की समझ में योगदान देता है।</abstract_hi>
      <abstract_ru>Пространственное понимание имеет решающее значение во многих реальных проблемах, однако в деле построения представлений, отражающих пространственные знания, достигнут незначительный прогресс. Здесь мы продвигаемся на один шаг вперед в этом направлении и изучаем такие представления, используя задачу, заключающуюся в прогнозировании непрерывных 2D пространственных расположений объектов при заданных экземплярах объект-связь-объект (например, «кошка под стулом») и простую нейронную сетевую модель, которая изучает задачу по аннотированным изображениям. Мы показываем, что модель успешно справляется с этой задачей и, кроме того, она способна предсказывать правильные пространственные расположения для невидимых объектов, если предоставляются либо признаки CNN, либо вложения слов объектов. Обсуждаются различия между визуальными и лингвистическими признаками. Далее для оценки пространственных представлений, изученных в предыдущей задаче, вводим задачу и набор данных, состоящий из набора краудсорсинговых человеческих рейтингов пространственного сходства для пар объектов. Мы обнаружили, что как признаки сверточной нейронной сети (CNN), так и вложения слов хорошо предсказывают человеческие суждения о сходстве, и что эти векторы могут быть дополнительно специализированы в пространственных знаниях, если мы обновим их при обучении модели, которая предсказывает пространственное расположение объектов. В целом, этот документ прокладывает путь к построению распределенных пространственных представлений, способствуя пониманию пространственных выражений в языке.</abstract_ru>
      <abstract_ga>Tá tuiscint spásúlachta ríthábhachtach i go leor fadhbanna sa saol fíor, ach is beag dul chun cinn atá déanta i dtreo léiriúcháin a thógáil a ghlacann eolas spásúil. Anseo, bogaimid céim amháin ar aghaidh sa treo seo agus foghlaimímid léirithe den sórt sin trí thasc a ghiaráil arb é atá ann socruithe leanúnacha spáis 2T a thuar maidir le réada nuair a thugtar cásanna oibiachta-gaolmhaireachta (m.sh., “cat under chair”) agus samhail líonra néarúil simplí a foghlaimíonn sé an tasc ó íomhánna anótáilte. Léirímid go n-éiríonn leis an tsamhail sa tasc seo agus, ina theannta sin, go bhfuil sé in ann socruithe ceart spáis a thuar do réada neamhfheicthe má chuirtear gnéithe CNN nó leabaithe focal de na réada ar fáil. Pléitear na difríochtaí idir gnéithe físiúla agus teangeolaíocha. Ansin, chun na huiríll spásúlachta a foghlaimíodh sa tasc roimhe seo a mheas, tugaimid tasc agus tacar sonraí isteach ina bhfuil sraith rátálacha daonna sluafhoinsithe de chosúlachtaí spásúlachta do phéirí réad. Feictear dúinn go ndéanann gnéithe CNN (líonra néarúil comhraonta) agus leabaithe focal a thuar go maith breithiúnais dhaonna cosúlachta agus gur féidir na veicteoirí seo a shainfheidhmiú tuilleadh in eolas spásúlachta má dhéanaimid iad a nuashonrú agus an tsamhail a thuar socruithe spáis réada á oiliúint. Tríd is tríd, réitíonn an páipéar seo an bealach chun léirithe spásúla dáilte a thógáil, ag cur le tuiscint ar nathanna spásúlachta i dteanga.</abstract_ga>
      <abstract_es>La comprensión espacial es crucial en muchos problemas del mundo real, pero se ha avanzado poco en la construcción de representaciones que capturen el conocimiento espacial. Aquí, avanzamos un paso en esta dirección y aprendemos tales representaciones aprovechando una tarea que consiste en predecir disposiciones espaciales 2D continuas de objetos dadas instancias de objeto-relación-objeto (por ejemplo, «gato bajo silla») y un modelo de red neuronal simple que aprende la tarea de imágenes. Mostramos que el modelo tiene éxito en esta tarea y, además, que es capaz de predecir las disposiciones espaciales correctas para objetos invisibles si se proporcionan características CNN o incrustaciones de palabras de los objetos. Se discuten las diferencias entre las características visuales y lingüísticas. A continuación, para evaluar las representaciones espaciales aprendidas en la tarea anterior, introducimos una tarea y un conjunto de datos que consiste en un conjunto de clasificaciones humanas colaborativas de similitud espacial para pares de objetos. Encontramos que tanto las características de la CNN (red neuronal convolucional) como las incrustaciones de palabras predicen bien los juicios humanos de similitud y que estos vectores pueden especializarse aún más en el conocimiento espacial si los actualizamos al entrenar el modelo que predice la disposición espacial de los objetos. En general, este documento allana el camino hacia la construcción de representaciones espaciales distribuidas, lo que contribuye a la comprensión de las expresiones espaciales en el lenguaje.</abstract_es>
      <abstract_ka>მსოფლიო შესახებ ძალიან მნიშვნელოვანი მსოფლიოს პრობლემებში, მაგრამ ცოტა პროგრესი გავაკეთებულია, რომლებიც კონტაქტიური ცოტაციას აქ, ჩვენ ერთი ნაწილის წინ გადავიწყეთ ამ მხარეს და ასეთი გამოსახულებების გავისწავლით, რომლებიც რაოდენობას წარმოიდგინოთ, რაოდენობას, რომლებიც გადავიწყეთ მუშაობელი 2D განსახულებული განსახულებელი განსახულებელი პროგრამების განსახ ჩვენ ჩვენ აჩვენებთ, რომ მოდელი ამ რაოდენობაში წარმოდგენა და, დამატებით, რომ ის შეუძლებელია წარმოდგენოთ მარტივი განსხვავებულ ობიექტების განსხვავება თუ CNN ფუნქციები ან სიტყვების ვიზუალური და ლინგურისტიკური განსხვავებების განსხვავება განსხვავებულია. შემდეგ, სამუშაო რეპეცენტაციების განსაზღვრება, რომელიც წინა დავასწავლეთ რაოდენობა და მონაცემების კონფიგურაცია, რომელიც სამუშაო ადამიანური რეტენტაციების კონფიგურა ჩვენ აღმოჩნეთ, რომ CNN (კონტუალური ნეიროლური ქსელი) ფუნქციები და სიტყვების შემდეგ ადამიანის სწორეობების შესახებ და რომ ეს გვექტორები უფრო სპეციალური ცნობილებში შეიძლება იყოს, თუ ჩვენ მათ აღ ყველაფერად, ეს დოკუმენტი ახალგაზრდება სივრცელი გამოსახულებების გასახულებას, რომლებიც სივრცელი გამოსახულებების გაგრძნობას ენაში.</abstract_ka>
      <abstract_el>Η χωρική κατανόηση είναι ζωτικής σημασίας σε πολλά προβλήματα πραγματικού κόσμου, ωστόσο έχει σημειωθεί μικρή πρόοδος προς την οικοδόμηση αναπαραστάσεων που συλλαμβάνουν τη χωρική γνώση. Εδώ, προχωράμε ένα βήμα προς αυτή την κατεύθυνση και μαθαίνουμε τέτοιες αναπαραστάσεις αξιοποιώντας μια εργασία που συνίσταται στην πρόβλεψη συνεχών 2χωρικών διευθετήσεων αντικειμένων που δίνονται σε περιπτώσεις αντικειμένου-σχέσης-αντικειμένου (π.χ. "γάτα κάτω από καρέκλα") και ένα απλό μοντέλο νευρωνικού δικτύου που μαθαίνει την εργασία από σχολιασμένες εικόνες. Δείχνουμε ότι το μοντέλο πετυχαίνει σε αυτό το έργο και, επιπλέον, ότι είναι σε θέση να προβλέψει σωστές χωρικές διευθετήσεις για αόρατα αντικείμενα εάν παρέχονται είτε χαρακτηριστικά CNN είτε ενσωμάτωση λέξεων των αντικειμένων. Εξετάζονται οι διαφορές μεταξύ οπτικών και γλωσσικών χαρακτηριστικών. Στη συνέχεια, για να αξιολογήσουμε τις χωρικές αναπαραστάσεις που μάθαμε στην προηγούμενη εργασία, εισάγουμε μια εργασία και ένα σύνολο δεδομένων που αποτελείται από ένα σύνολο ανθρώπινων αξιολογήσεων χωρικής ομοιότητας για ζεύγη αντικειμένων. Διαπιστώνουμε ότι τόσο τα χαρακτηριστικά του νευρικού δικτύου όσο και η ενσωμάτωση λέξεων προβλέπουν καλά τις ανθρώπινες κρίσεις ομοιότητας και ότι αυτά τα διανύσματα μπορούν να εξειδικευτούν περαιτέρω στη χωρική γνώση αν τα ενημερώσουμε κατά την εκπαίδευση του μοντέλου που προβλέπει τις χωρικές διευθετήσεις των αντικειμένων. Συνολικά, η παρούσα εργασία ανοίγει το δρόμο για την οικοδόμηση κατανεμημένων χωρικών αναπαραστάσεων, συμβάλλοντας στην κατανόηση των χωρικών εκφράσεων στη γλώσσα.</abstract_el>
      <abstract_it>La comprensione dello spazio è fondamentale in molti problemi del mondo reale, ma sono stati fatti pochi progressi verso la costruzione di rappresentazioni che catturano la conoscenza spaziale. Qui, facciamo un passo avanti in questa direzione e impariamo tali rappresentazioni sfruttando un compito consistente nel predire continue disposizioni spaziali 2D di oggetti dati istanze oggetto-relazione-oggetto (ad esempio, 'gatto sotto sedia') e un semplice modello di rete neurale che impara il compito dalle immagini annotate. Mostriamo che il modello ha successo in questo compito e, inoltre, che è in grado di prevedere la corretta disposizione spaziale per gli oggetti invisibili se sono fornite caratteristiche CNN o incorporazioni di parole degli oggetti. Vengono discusse le differenze tra caratteristiche visive e linguistiche. Successivamente, per valutare le rappresentazioni spaziali apprese nel compito precedente, introduciamo un task e un dataset costituito da un insieme di valutazioni umane crowdsourcing di somiglianza spaziale per coppie di oggetti. Troviamo che sia le caratteristiche della CNN (rete neurale convoluzionale) che le incorporazioni di parole predicono bene i giudizi umani di somiglianza e che questi vettori possono essere ulteriormente specializzati nella conoscenza spaziale se li aggiorniamo durante l'addestramento del modello che predice le disposizioni spaziali degli oggetti. Nel complesso, questo articolo apre la strada alla costruzione di rappresentazioni spaziali distribuite, contribuendo alla comprensione delle espressioni spaziali nel linguaggio.</abstract_it>
      <abstract_hu>A térbeli megértés kulcsfontosságú számos valós problémában, mégis kevés előrelépés történt a térbeli ismereteket megragadó reprezentációk kiépítésében. Itt egy lépéssel előrelépünk ebben az irányban, és megtanuljuk ezeket a reprezentációkat egy olyan feladat kihasználásával, amely az objektumok folyamatos 2D térbeli elrendezésének előrejelzéséből áll, és egy egyszerű neurális hálózati modell, amely a jegyzetelt képekből tanulja meg a feladatot. Megmutatjuk, hogy a modell sikeres ebben a feladatban, továbbá, hogy képes a láthatatlan objektumok helyes térbeli elrendezésének előrejelzésére, ha az objektumok CNN jellemzői vagy szóbeágyazásai vannak megadva. A vizuális és nyelvi jellemzők közötti különbségeket vitatjuk meg. Ezt követően az előző feladatban tanult térbeli reprezentációk értékeléséhez bemutatunk egy feladatot és egy adatkészletet, amely az objektumpárok térbeli hasonlóságának közösségi forrásból álló emberi minősítéseiből áll. Úgy találjuk, hogy mind a CNN (convolucionális neurális hálózat) tulajdonságai, mind a szóbeágyazások jól megjósolják az emberi hasonlóság megítélését, és ezek a vektorok tovább specializálódhatnak a térbeli ismeretekre, ha frissítjük őket az objektumok térbeli elrendezését előrejelző modell kiképzésekor. Összességében ez a tanulmány előkészíti az utat elosztott térbeli reprezentációk építéséhez, hozzájárulva a nyelvi térbeli kifejezések megértéséhez.</abstract_hu>
      <abstract_kk>Аралық түсініктері көптеген әлемдегі мәселелерде маңызды, бірақ жергілікті білімдерді түсіндіру үшін кішкентай жағдай жасалған. Мұнда, біз осы бағытта бір қадам алға жылжытып, бұл тапсырмаларды көрсету үшін тапсырмаларды оқып, келтірілген нысандар- қатынас- нысандардың (мысалы, 'бағыттың астындағы бет') және тапсырманы белгіленген кескіндерден оқып беретін қарапайым не Біз үлгі осы тапсырманың сәттілігін көрсетедік. Сонымен қатар, CNN функциялары не сөз ендіру керек болса, ол көрсетілмеген нысандардың жергілікті тәртібін көрсетеді. Көрініс мен лингвистикалық қасиеттер арасындағы айырмашылықтар талқылады. Келесіден, алдыңғы тапсырмада үйренген бос орындық тапсырмаларды бағалау үшін біз тапсырманы және деректер жиынын көрсету үшін нысандардың бірнеше бос орындық ұқсас рейтингиялығында тұрады. Біз CNN (конверсионалды невралды желі) мүмкіндіктері мен сөздерді ендіру адамдардың ұқсас тәртіптерін дұрыс көрсетеді, және бұл векторлар бос мәліметтерінде көбірек болады, егер біз оларды бос орын мәліметтердің үлгісі Жалпы, бұл қағаз жергілікті көрсеткіштерді құру жолын жасайды, тілде бос орындық өрнектерді түсінуге көмектеседі.</abstract_kk>
      <abstract_lt>Daugelyje realaus pasaulio problemų labai svarbus erdvinis supratimas, tačiau padaryta maža pažanga kuriant erdvių žinias atitinkančias atstovybes. Čia mes žengiame vieną žingsnį į priekį šia kryptimi ir išmokome tokius rodymus, sutelkdami svertą užduotį, kurią sudaro numatyti nuolatinius dvimatžius erdvinius objektų, nurodytų objektų santykio su objektais atvejus (pvz., "katė po kėdėmis") ir paprastą nervinio tinklo model į, kuris išmoko užduotį iš anotuotų vaizdų. We show that the model succeeds in this task and, furthermore, that it is capable of predicting correct spatial arrangements for unseen objects if either CNN features or word embeddings of the objects are provided.  Aptariami vizualinių ir kalbinių savybių skirtumai. Next, to evaluate the spatial representations learned in the previous task, we introduce a task and a dataset consisting in a set of crowdsourced human ratings of spatial similarity for object pairs.  Matome, kad tiek CNN (konvoliucinio nervinio tinklo) savybės, tiek žodžių įterpimas gerai numato žmogaus panašumo sprendimus ir kad šie vektoriai gali būti labiau specializuoti erdvinių žinių srityje, jei juos atnaujinsime rengiant model į, kuris numato objektų erdvinius susitarimus. Apskritai šis dokumentas padeda kurti paskirstytus erdvinius atvaizdus ir prisideda prie erdvinių išraiškų supratimo kalba.</abstract_lt>
      <abstract_mk>Просторното разбирање е клучно во многу проблеми во реалниот свет, но малку напредок е постигнат кон изградбата на претставувања кои заземаат просторно знаење. Овде, одиме еден чекор напред во оваа насока и научиме такви претставувања со влијание на задачата која се состои од предвидување на континуирани дводмерни просторни аранжмани на објекти кои се дадени примероци на објект-врска-објект (на пример, „мачка под столот“) и едноставен модел на неврална мрежа кој ја научи Ние покажуваме дека моделот успева во оваа задача и, понатаму, дека е способен да предвиде точни просторни аранжмани за невидени објекти ако се обезбедуваат или CNN карактеристики или зборови вложување на објектите. Разликите помеѓу визуелните и јазичните карактеристики се разговараат. Следно, за да ги процениме просторските претставувања научени во претходната задача, воведуваме задача и податок кој се состои од множина човечки рејтинзи на просторска сличност за парови објекти. Најдовме дека и карактеристиките на CNN (конволуционална нервна мрежа) и вложувањето на зборови добро предвидуваат човечки пресуди за сличност и дека овие вектори може да бидат понатаму специјализирани во просторно знаење ако ги ажурираме кога ќе го обучуваме моделот кој предвидува просторни аранжмани на објекти Вкупно, овој весник го отвора патот кон изградба на дистрибуирани просторни претставувања, придонесувајќи за разбирање на просторните изрази на јазик.</abstract_mk>
      <abstract_ml>സ്പെയില്‍ മനസ്സിലാക്കുന്നത് വളരെ യഥാര്‍ത്ഥ ലോക പ്രശ്നങ്ങളില്‍ പ്രധാനപ്പെട്ടതാണ്. പക്ഷെ സ്പെയില്‍ അറിവ് പിടിച്ചുക ഇവിടെ നാം ഒരു പടി മുന്നോട്ട് നീങ്ങി പഠിക്കുന്നു. നിലനില്‍ക്കുന്ന ഒരു ജോലിയുടെ പ്രതിനിധികള്‍ മുന്നോട്ട് പഠിക്കുന്നു. നിലനില്‍ക്കുന്ന രണ്ടു ഡി സ്പെയില്‍ സ്പെയില്‍ നിര്‍ണയി ഈ ജോലിയില്‍ മോഡല്‍ വിജയിച്ചിരിക്കുന്നു എന്ന് ഞങ്ങള്‍ കാണിക്കുന്നു. അതിനുശേഷം, അദൃശ്യമായ വസ്തുക്കള്‍ക്കുള്ള ശരിയായ സ്പെയിസ്റ്റിയേല്‍ നിര്‍ണയിക് കാഴ്ചക്കാരും ഭാഷക്കാരുമിടയിലുള്ള വ്യത്യാസങ്ങള്‍ സംസാരിക്കുന്നു. Next, to evaluate the spatial representations learned in the previous task, we introduce a task and a dataset consisting in a set of crowdsourced human ratings of spatial similarity for object pairs.  നമുക്ക് കണ്ടെത്തുന്നത് സിഎന്‍ (ക്രൂപ്യനികമായ ന്യൂറല്‍ നെറ്റര്‍ നെറ്റ്‌വര്‍ക്ക്) രണ്ട് വാക്കുകളും ഒരുപോലുള്ള മനുഷ്യരുടെ വിധികളും പ്രവചിക്കുന്നു. ഈ വെക്റ്റര്‍ക്ക് സ്പാ മൊത്തം, ഈ പേപ്പറില്‍ സ്പെയില്‍ പ്രതിനിധികള്‍ വിതരണം ചെയ്യുന്ന സ്പെയില്‍ പ്രതിനിധികള്‍ നിര്‍മ്മിക്കുന്നതിന് വഴി ക</abstract_ml>
      <abstract_ms>Spatial understanding is crucial in many real-world problems, yet little progress has been made towards building representations that capture spatial knowledge.  Di sini, kita bergerak satu langkah ke hadapan dalam arah ini dan belajar perwakilan seperti ini dengan menggunakan tugas yang terdiri dalam meramalkan pengaturan ruang 2D terus menerus objek yang diberikan contoh objek-hubungan-objek (contohnya, 'kucing di bawah kerusi') dan model rangkaian saraf sederhana yang belajar tugas dari imej yang dicatat. Kami menunjukkan bahawa model berjaya dalam tugas ini dan, selain itu, bahawa ia mampu meramalkan penyesuaian ruang yang betul untuk objek yang tidak terlihat jika sama ada ciri CNN atau penyelesaian perkataan objek disediakan. Perbezaan antara ciri-ciri visual dan bahasa dibahas. Seterusnya, untuk menilai perwakilan ruang yang belajar dalam tugas sebelumnya, kami memperkenalkan tugas dan set data yang terdiri dari set nilai manusia yang berasal ramai untuk persamaan ruang bagi pasangan objek. Kami mendapati bahawa kedua-dua ciri CNN (rangkaian saraf konvolusi) dan penyampaian perkataan meramalkan penghakiman manusia tentang persamaan dengan baik dan bahawa vektor ini boleh lebih khusus dalam pengetahuan ruang jika kita kemaskini mereka apabila melatih model yang meramalkan pengaturan ruang objek. Secara keseluruhan, kertas ini membuka jalan untuk membina perwakilan ruang yang disebarkan, berkontribusi kepada pemahaman ungkapan ruang dalam bahasa.</abstract_ms>
      <abstract_mt>Il-fehim spazjali huwa kruċjali f’ħafna problemi tad-dinja reali, iżda ftit progress sar lejn il-bini ta’ rappreżentazzjonijiet li jaqbdu l-għarfien spazjali. Hawnhekk, nimxu pass ’il quddiem f’din id-direzzjoni u nitgħallmu rappreżentazzjonijiet bħal dawn billi ninfurzaw kompitu li jikkonsisti fit-tbassir ta’ arranġamenti spazjali kontinwi 2D ta’ oġġetti mogħtija e żempji ta’ oġġett-relazzjoni-oġġett (pereżempju, 'qtates taħt siġġu') u mudell sempliċi tan-netwerk newrali li jitgħallmu l-kompitu minn immaġni annotati. Aħna nuru li l-mudell jirnexxi f’dan il-kompitu u, barra minn hekk, li huwa kapaċi jipprevedi arranġamenti spazjali korretti għal oġġetti mhux osservati jekk jiġu pprovduti karatteristiċi CNN jew inkorporazzjonijiet tal-kliem tal-oġġetti. The differences between visual and linguistic features are discussed.  Next, to evaluate the spatial representations learned in the previous task, we introduce a task and a dataset consisting in a set of crowdsourced human ratings of spatial similarity for object pairs.  Aħna nsibu li kemm il-karatteristiċi CNN (netwerk newrali konvoluzzjonali) kif ukoll l-inkorporazzjonijiet tal-kliem jipprevedu sentenzi umani ta’ similarità tajjeb u li dawn il-vetturi jistgħu jkunu aktar speċjalizzati fl-għarfien ġeografiku jekk naġġornawhom meta nħarrġu l-mudell li jipprevedi arranġamenti ġeografiċi tal-oġġetti. B’mod ġenerali, dan id-dokument iwitti t-triq lejn il-bini ta’ rappreżentazzjonijiet ġeografiċi distribwiti, u jikkontribwixxi għall-fehim tal-espressjonijiet ġeografiċi fil-lingwa.</abstract_mt>
      <abstract_mn>Олон бодит ертөнцийн асуудалд орон нутгийн ойлголт чухал. Гэхдээ орон нутгийн мэдлэг барьж буй загваруудыг бүтээхэд бага зэрэг хөгжлийг хийгдсэн. Энд бид нэг алхам урагшлуулж, ийм загваруудыг суралцаж байдаг. Объект-харилцаа-объект жишээ (жишээлбэл, ширээний доорх муур) болон анзаарсан зурагтаас ажлыг суралцаж байгаа энгийн мэдрэлийн сүлжээний загварыг ашиглаж байдаг. Бид энэ ажлын загвар амжилттай гэдгийг харуулж байна. Үүнээс гайхшруулагдсан объектуудын сонирхолтой эсвэл сөрөг нэмж гаргаж өгсөн бол энэ загвар нь тодорхойлж чадах боломжтой гэдгийг харуулж байна. Дүрслэл болон хэл хэлний өөрчлөлтийн ялгаа ярилцдаг. Дараа нь, өмнөх ажил дээр сурсан орон зайн илтгэлийг үнэлэхэд бид ажил болон өгөгдлийн санг объектын хоёр хоёрын орон зайн төстэй хэмжээний хүн төрөлхтний хэмжээнд байдаг. Бид CNN хоёулаа хоёулаа нь хүн төрөлхтний төсөөллийг сайн тодорхойлох боломжтой. Эдгээр векторууд огторгуйн мэдлэгт илүү төсөөлж чадна. Хэрвээ бид эдгээрийг огторгуйн төсөөллийг тайлбарлах загварын загварыг суралцах үед шинэчлэх боло Энэ цаас нь хэлний орон зай илэрхийллийг ойлгохын тулд хуваагдсан орон зай илэрхийллийг бүтээх арга зам болгож байна.</abstract_mn>
      <abstract_no>Spasielle forståelse er viktig i mange verdsproblemer, men det er likevel lite framdrift gjennomført til bygging av representasjonar som får mellombels kunnskap. Her flyttar vi eitt steg framover i denne retninga og lærer slike representasjonar ved å levera eit oppgåve som inneheld i forhåndsvising av kontinuerlege 2D mellomromlige arrangeringar av objektet gjeven objekt-relasjon-objekt-instansar (f.eks. «katt under stol») og eit enkel neuralnettverksmodell som lærer oppgåva frå markerte bilete. Vi viser at modellen vellukkar i denne oppgåva, og likevel at det er i stand til å foregå korrekte mellomromarrangeringar for ukjende objekt dersom anten CNN-funksjonar eller ordinnbygging av objektane er tilgjengeleg. Forskjellene mellom visuelle og lingviske funksjonar vert diskutert. Neste, for å evaluere mellomromrepresentasjonane lærte i den førre oppgåva, introduserer vi ei oppgåve og ei dataset som inneheld i eit sett av fleire menneskelige verdiar med mellomromlighet for objektparer. Vi finn at begge CNN-funksjonar og ord-innbygging foregår menneskelige sprøytebrukar av liknande likningar og at disse vektorane kan vera meir spesialiserte i romlige kunnskap dersom vi oppdaterer dei når vi treng modellen som foregår romlige arrangeringar av objektar. Denne papiret gjer overalt veien til bygging av distribuerte mellomromrepresentasjonar, som bidrar til forståelse av mellomromuttrykk i språk.</abstract_no>
      <abstract_ro>Înțelegerea spațială este crucială în multe probleme din lumea reală, dar s-au făcut puține progrese în direcția construirii de reprezentări care capturează cunoștințele spațiale. Aici, facem un pas înainte în această direcție și învățăm astfel de reprezentări utilizând o sarcină constând în predicerea aranjamentelor spațiale 2D continue ale obiectelor date instanțelor obiect-relație-obiect (de exemplu, "pisica sub scaun") și un model simplu de rețea neurală care învață sarcina din imaginile adnotate. Aratăm că modelul reușește în această sarcină și, în plus, că este capabil să prevină aranjamentele spațiale corecte pentru obiectele nevăzute dacă sunt furnizate caracteristici CNN sau încorporări de cuvinte ale obiectelor. Sunt discutate diferențele dintre caracteristicile vizuale și lingvistice. Apoi, pentru a evalua reprezentările spațiale învățate în sarcina anterioară, introducem o sarcină și un set de date constând într-un set de evaluări umane crowdsourced de similitudine spațială pentru perechile de obiecte. Descoperim că atât caracteristicile CNN (rețeaua neuronală convoluțională), cât și încorporările cuvintelor prezic bine judecățile umane de asemănare și că acești vectori pot fi specializați în cunoașterea spațială dacă îi actualizăm atunci când pregătim modelul care prezice aranjamentele spațiale ale obiectelor. În general, această lucrare deschide calea spre construirea reprezentărilor spațiale distribuite, contribuind la înțelegerea expresiilor spațiale în limbaj.</abstract_ro>
      <abstract_sr>Svemirsko razumijevanje je ključno u mnogim stvarnim problemima u svetu, ali je napredak napredak u cilju izgradnje predstavljanja koje uhvate prostorno znanje. Ovde, kreæemo jedan korak napred u ovom smjeru i nauèimo takve predstave uticajuæi na zadatak koji se sastoji u predviðanju stalnih 2D prostornih aranžmana objekata odreðenih sluèajeva objekata-odnosa-objekata (npr. 'maèka pod stolicom') i jednostavnog model a neuralne mreže koji nauèi zadatak iz annotiranih slika. Pokazujemo da model uspeva u ovom zadatku i da je sposoban predviđati ispravne prostorne aranžmane za nevidljive objekte ako se pružaju ili CNN karakteristike ili rečne integracije objekata. Razlika između vizuelnih i jezičkih karakteristika se raspravlja. Sledeće, za procjenu svemirskih predstavljanja naučenih u prethodnom zadatku, predstavljamo zadatak i setu podataka koji se sastoji u skupu popularnih ljudskih ocjena prostorne sličnosti objektima. Nalazimo da i CNN (konvolucionalna neuralna mreža) karakteristike i ugrađenje riječi predviđaju ljudske osude o sličnosti i da se ovi vektori mogu više specijalizirati u svemirskim znanjima ako ih aktualizujemo kada obučavamo model koji predviđa svemirske aranžmana objekata. U svemu, ovaj papir otvara put ka izgradnji raspodijeljenih prostornih predstavljanja, koji doprinosi razumijevanju prostornih izraza na jeziku.</abstract_sr>
      <abstract_so>waxgarashada Spanishku waa muhiim in ay dhibaatooyin badan oo halis ah ku jirto, laakiin horumar yar ayaa loo sameeyay dhisidda wakiilada aqoonta iswidhista. Halkan, hal qad ayaannu hore ugu soconnaa halkan, waxaynu barnaa noocyo caynkaas ah, waxaana ku qoran shaqada la sii daabacayaa alaabta cimilka ah oo joogtada ah oo 2D ah oo la siiyo alaabta la xiriira alaabta dhamaadka (tusaale ahaan ''cat ka hooseeya carshiga') iyo model neurada ah oo shaqada ka barta sawirada la taxeeyey. Waxaynu tusnaynaa in modellka uu ku liibaanay shaqadan, waxaadna sidoo kale awoodi karto in uu horumariyo qoraalo saxda ah oo ay wax qarsoon yihiin, haddii ay qoraalka CNN ama hadal ku qoran yihiin waxyaabaha. Isku xiriirka muuqashada iyo luuqadaha waxaa loola hadlaa. Inta dambe, si aan u qiimeeyno wakiilada spatial ee lagu baray shaqadii hore, waxaynu soo bandhigaynaa shaqo iyo taarif ah oo ku qoran koox ka mid ah rasmiga dadka oo isku mid ah ee isfaaniyada labada labood. Waxaynu helnaa in labada CNN (shabakadda kooxaha neurada ah) ay leedahay iyo hadal ku qoran yihiin wax u sheegta xukummada biniaadamka oo isku mid ah, iyo in wadooyinkaas lagu sii gaari karo aqoonta iswidhishka, haddii aynu kordhinno sameynta qaababka qaababka isbedela. Dhammaan warqaddan wuxuu ku hagaa dhismaha wakiilada spatiada lagu kala qaybiyey, kaasoo ku caawinaya garashada hadalka spatiada ee luqada.</abstract_so>
      <abstract_pl>Zrozumienie przestrzenne ma kluczowe znaczenie w wielu problemach świata rzeczywistego, jednak poczyniono niewielki postęp w kierunku budowania reprezentacji, które uwzględniają wiedzę przestrzenną. Tutaj idziemy o krok naprzód w tym kierunku i uczymy się takich reprezentacji poprzez wykorzystanie zadania polegającego na przewidywaniu ciągłych układów przestrzennych 2D obiektów podanych instancjami obiektu-relacji-obiektu (np. "kot pod krzesłem") oraz prostego modelu sieci neuronowej, który uczy się zadania z adnotacji obrazów. Pokazujemy, że model odnosi sukces w tym zadaniu, a ponadto, że jest w stanie przewidzieć poprawne układy przestrzenne dla niewidzialnych obiektów, jeśli dostarczone są cechy CNN lub osadzenia słów obiektów. Omówiono różnice między cechami wizualnymi i językowymi. Następnie, aby ocenić przestrzenne reprezentacje nauczone w poprzednim zadaniu, wprowadzamy zadanie i zbiór danych składający się z zestawu crowdsourcingowych ocen podobieństwa przestrzennego dla par obiektów. Odkrywamy, że zarówno cechy CNN (konwolucyjna sieć neuronowa), jak i osadzenia słów dobrze przewidują ludzkie oceny podobieństwa i że wektory te mogą być dalej specjalizowane w wiedzy przestrzennej, jeśli aktualizujemy je podczas treningu modelu przewidującego układy przestrzenne obiektów. Ogólnie rzecz biorąc, artykuł ten toruje drogę do budowy rozproszonych reprezentacji przestrzennych, przyczyniając się do zrozumienia wyrażeń przestrzennych w języku.</abstract_pl>
      <abstract_sv>Territoriell förståelse är avgörande i många verkliga problem, men små framsteg har gjorts mot att bygga representationer som fångar rumslig kunskap. Här rör vi oss ett steg framåt i denna riktning och lär oss sådana representationer genom att utnyttja en uppgift som består i att förutsäga kontinuerliga 2D rumsliga arrangemang av objekt givna objekt-relation-objekt instanser (t.ex. "katt under stol") och en enkel neural nätverksmodell som lär sig uppgiften från kommenterade bilder. Vi visar att modellen lyckas med denna uppgift och dessutom att den kan förutsäga korrekta rumsliga arrangemang för osynliga objekt om antingen CNN-funktioner eller ordinbäddningar av objekten tillhandahålls. Skillnaderna mellan visuella och språkliga drag diskuteras. Därefter, för att utvärdera de rumsliga representationer som lärts sig i föregående uppgift, introducerar vi en uppgift och en datauppsättning bestående av en uppsättning crowdsourcing mänskliga bedömningar av rumslig likhet för objektpar. Vi finner att både CNN (convolutional neural network) funktioner och ordinbäddningar förutspår mänskliga bedömningar av likhet väl och att dessa vektorer kan specialiseras ytterligare på rumslig kunskap om vi uppdaterar dem när vi tränar modellen som förutspår rumsliga arrangemang av objekt. Sammantaget banar denna uppsats väg för att bygga distribuerade rumsliga representationer, vilket bidrar till förståelsen av rumsliga uttryck i språket.</abstract_sv>
      <abstract_si>ස්ථානය තේරුම්ගන්නේ ඇත්ත ලෝකයේ ප්‍රශ්නයක් ගොඩක් විශ්වාසයි, නමුත් පොඩි ප්‍රශ්නයක් වැඩ කරලා තිය මෙන්න, අපි මේ පැත්තේ එක පැත්තක් ඉස්සරහා ඉගෙන ගන්නවා ඒ වගේ ප්‍රතිනිධානයක් ඉගෙන ගන්නවා වගේම වැඩක් සාමාන්‍ය 2D ස්පේසියල් සැකසුම් සැකසුම් දැනුම් දැනුම් දැනුම් ද අපි පෙන්වන්නේ මොඩල් එක මේ වැඩේ සාර්ථක වෙන්න පුළුවන් කියලා, ඒ වගේම, ඒක අනතුරු වැඩක් නැති වැඩක් සඳහා අනතුරු වැඩක් සැකසුම් ස දර්ශනය සහ භාෂාවික සැකසුම් අතර වෙනස් කරනවා. ඊළඟට, පස්සේ වැඩේ ඉගෙන ගත්ත වැඩේ ඉගෙන ඉගෙන ඉගෙන ගත්ත ස්ථානය ප්‍රතිචාරය අවශ්‍ය කරන්න, අපි වැඩක් සහ දත්ත සෙට් එකක් පෙනුම් කරනවා මි අපිට හොයාගන්න පුළුවන් කියලා CNN (සම්පූර්ණ න්යූරාල් ජාලය) අවශ්‍ය සහ වචන සම්පූර්ණ වලින් මිනිස්සුන්ගේ සැකසුම් හොඳයි, ඒ වගේම මේ වෙක් සම්පූර්ණයෙන්ම, මේ පැත්තේ විතරයි විතරයි ස්ථානය ප්‍රතිචාරය, භාෂාවයේ ස්ථානය ප්‍රතිචාරයේ තේරු</abstract_si>
      <abstract_ta>வெளிச்சமான புரிவு பல உண்மையான உலக பிரச்சினைகளில் முக்கியமானது, ஆனாலும் சிறிய முன்னேற்றம் உருவாக்கப்பட்டுள்ளது வெ இங்கே நாம் ஒரு படி முன்னே நகர்த்தி இந்த திசையில் இவ்வாறு குறிப்புகளை கற்றுக் கொள்கிறோம் மூலம் தொடர்ந்து இருந்துள்ள வெளியீட்டு அமைப்புகளை கொடுக்கும் பொருள் தொடர்பு நிகழ்வுகளி நாம் இந்த செயலில் மாதிரி வெற்றியடைந்தது என்பதை காட்டுகிறோம் மறைக்கப்பட்ட பொருட்களுக்கு சரியான வெளியீட்டு அமைப்புகளை காண்பிக்க முடியும் என்பதை  காட்சி மற்றும் மொழிக் குணங்களுக்கிடையே வேறுபாடுகள் விவாதமாக்கப்படுகின்றன. அடுத்து, We find that both CNN (convolutional neural network) features and word embeddings predict human judgments of similarity well and that these vectors can be further specialized in spatial knowledge if we update them when training the model that predicts spatial arrangements of objects.  மொத்தமாக, இந்த காகிதம் விதியாசமான வெளியீட்டு பிரதிநிதிகளை கட்டுவதற்கு வழியை காட்டுகிறது, மொழியில் வெளியீட்டு</abstract_ta>
      <abstract_ur>فضائی سمجھ بہت سی حقیقی دنیا کے مشکلوں میں اہم ہے، لیکن بہت ہی کم پیشرفت کی گئی ہے جو فضائی علم کو پکڑتے ہیں۔ یہاں، ہم اس طرح ایک قدم آگے چلتے ہیں اور اس طرح کی تعلیم یاد کرتے ہیں کہ ایک کام کی پیش آنے کے ذریعہ ایک دودھی فضائی تعلیم کریں جن میں موجود objects-relationship-object instances (جیسے کہ 'chair under cat') اور ایک ساده نیورال نیٹ ورک موڈل ہے جو تابع کو یاد رکھی ہوئی تصاویروں سے سکھاتا ہے۔ ہم دکھاتے ہیں کہ موڈل اس کام میں کامیاب ہوتی ہے اور اس کے علاوہ یہ غیب کی objectوں کے لئے صحیح فضائی تعمیرات کی پیش بینی کرنے کے قابل ہے اگر ان کے سی ان فوئٹوں یا کلمات کے مطابق اشیاء کے مطابق پیدا کئے جائیں۔ visual and linguistic features کے درمیان تفاوت بحث کی جاتی ہیں. آگے، پہلے کے کام میں سکھائے ہوئے فضائی نمونات کا ارزش کرنا، ہم ایک کام اور ایک ڈیٹ سٹ کو معلوم کرتے ہیں جو ایک مجموعہ سے انسان کی نسبت فضائی ریٹینگ کی جڑ کے مطابق ہے۔ ہم دیکھ رہے ہیں کہ سی ان ان کے (کنویروشن نیورل نیورل نیٹ ورک) فرصت اور کلمات انبودینگ دونوں ایسی طرح کے مطابق انسان کے فیصلے کو اچھی طرح پیش بینی کرتے ہیں اور یہ ویکتوروں کو فضائی علم میں زیادہ مخصوص کر سکتے ہیں اگر ہم ان کو آدٹر کر دیں جب موڈل کی تعلیم اور یہ کاغذ سب سے زیادہ مضبوط ہے کہ اسپانیایی مثالیں بنانے کی طرف تقسیم کی جاتی ہیں اور زبان کے مطابق فضائی مثالیں سمجھنے کی مدد کرتی ہیں۔</abstract_ur>
      <abstract_uz>Ispaniya tushunishi dunyodagi muammolar juda muhim, ammo butunlay spatial илмni qabul qiladigan tashkilotlarni yaratish uchun juda qisqa muvaffaqiyatlar yaratildi. Bu yerda biz bir qadam oldingi yuboramiz va bir qadam orqali o'rganamiz va ishni taʼminlovchi rasmlarni o'rganish oddiy narsalar bilan davom etish mumkin. Biz bu vazifaning modeli muvaffaqiyatli ko'rsatumiz va u yerda, agar CNN xossalari yoki obʼektlarning soʻzlari koʻrsatilgan boʻlsa, gapirmagan obʼektlarning toʻgʻri spatial moslamalarini koʻrsatish mumkin. Koʻrinadigan va tillik xossalarining orasidagi o'zgarishlar. Keyingi, oldingi vazifani o'rganilgan spatial representarini qiymatish uchun, biz vazifani ko'rib chiqaramiz va obʼekt qo'llangan bir guruhdagi inson rasmlarning bir guruhida qo'llangan maʼlumotlar tarkibini o'rganamiz. Biz o'ylaymiz, CNN (murakkab neyron tarmoq) xususiyatlari va so'zlar bir xil o'zgarishlarni tasavvur qiladi va bu vectorlar o'zgarishlarni o'rganishda o'zgartirish mumkin, agar biz obʼektlarning spatial tartiblarini o'rganishda yangilashimiz mumkin. Umumiy, bu qogʻoz, spatial tashkilotlarini tashqi qilishga yordam beradi, gapirish tilni tushunishga yordam beradi.</abstract_uz>
      <abstract_vi>Tâm lý học rất quan trọng trong nhiều vấn đề thế giới thực, nhưng đã có rất ít tiến triển về việc xây dựng những diễn biến thu thập kiến thức về vũ trụ. Ở đây, chúng ta di chuyển một bước tiến về hướng này và học được các biểu hiện đó bằng cách thao tác vũ trụ 2D tiếp theo của các đối tượng đã nhận diện đối tượng với đối tượng tương tác với đối tượng (v.v. d., mèo dưới ghế) và một mô hình mạng thần kinh đơn giản học nhiệm vụ từ các hình đã ghi chú. Chúng tôi cho thấy rằng mô hình thành công trong nhiệm vụ này và, thêm nữa, nó có khả năng dự đoán sự sắp đặt không gian đúng cho các vật thể không nhìn thấy, nếu như hiển thị của kênh CNN hoặc là sự nhúng vào từ của các vật thể được cung cấp. Sự khác nhau giữa tính thị và ngôn ngữ được thảo luận. Tiếp theo, để đánh giá các biểu tượng về không gian học được trong nhiệm vụ trước, chúng tôi giới thiệu một nhiệm vụ và một bộ dữ liệu gồm một bộ xếp hạng người đông đúc về khả năng tương tự không gian cho các cặp đối tượng. Chúng tôi thấy cả hai tính năng của CNN (mạng thần kinh kết nối) và sự nhúng vào từ dự đoán những phán đoán của con người về điểm giống nhau tốt và những cỗ máy này có thể chuyên môn về kiến thức về không gian nếu chúng tôi cập nhật nó khi huấn luyện mô hình dự đoán sắp đặt không gian của đối tượng. Nói chung, tờ giấy này mở đường tiến tới việc xây dựng các biểu tượng vũ trụ được phân phối, giúp hiểu các biểu hiện về vũ trụ trong ngôn ngữ.</abstract_vi>
      <abstract_bg>Пространственото разбиране е от решаващо значение за много проблеми от реалния свят, но е постигнат малък напредък към изграждането на изображения, които улавят пространственото знание. Тук ние се придвижваме една стъпка напред в тази посока и научаваме такива изображения, като използваме задача, състояща се в предвиждане на непрекъснати 2D пространствени подреждания на обекти, дадени обект-взаимоотношения (например "котка под стол") и прост модел на невронна мрежа, който научава задачата от анотирани изображения. Показваме, че моделът успява в тази задача и освен това, че е способен да предвиди правилното пространствено подреждане на невидими обекти, ако са предоставени или характеристики на CNN или словни вграждания на обектите. Разгледани са разликите между визуалните и езиковите особености. След това, за да оценим пространствените изображения, научени в предишната задача, въвеждаме задача и набор от данни, състоящи се от набор от човешки рейтинги за пространствено сходство за двойки обекти. Установяваме, че както характеристиките на конволюционната невронна мрежа, така и вграждането на думи предсказват добре човешките преценки за сходство и че тези вектори могат да бъдат допълнително специализирани в пространственото знание, ако ги актуализираме при обучението на модела, който предсказва пространствените подреждания на обекти. Като цяло, тази статия проправя пътя към изграждането на разпределени пространствени изображения, допринасящи за разбирането на пространствените изрази в езика.</abstract_bg>
      <abstract_hr>Svemirsko razumijevanje je ključno u mnogim stvarnim problemima u svijetu, a ipak je napredak napredovao prema izgradnji predstavljanja koje uključuju prostorno znanje. Ovdje ćemo pokrenuti jedan korak naprijed u ovom smjeru i naučiti takve predstave učenjem zadatka koji se sastoji u predviđanju neprestano dvostrukih prostornih aranžmana objekata odanih primjera objekata-odnosa-objekata (npr. „mačka pod stolicom“) i jednostavnog model a neuralne mreže koji uči zadatak iz annotiranih slika. Pokazujemo da je model uspješan u ovom zadatku i, dodatno, sposoban predvidjeti ispravne prostorne aranžmane za nevidljive objekte ako se pružaju ili CNN karakteristike ili riječi uključenje objekata. Razlika između vizuelnih i jezičkih karakteristika raspravljaju se. Sljedeće, kako bi procijenili prostorne predstave koje su naučene u prethodnom zadatku, predstavljamo zadatak i komplet podataka koji se sastoji u skupu popularnih ljudskih ocjena prostorne sličnosti objektima. Nalazimo da i CNN (konvolucionalna neuralna mreža) karakteristike i ugrađenje riječi dobro predviđaju ljudske osude o sličnosti i da se ovi vektori mogu dalje specijalizirati u prostornim znanjima ako ih aktualizujemo kada vježbamo model koji predviđa prostorne aranžmane objekata. U cjelokupnom slučaju, ovaj papir otvara put ka izgradnji raspodjeljenih prostornih predstavljanja, koji doprinosi razumijevanju prostornih izraza na jeziku.</abstract_hr>
      <abstract_de>Raumverständnis ist für viele reale Probleme von entscheidender Bedeutung, dennoch wurden kaum Fortschritte beim Aufbau von Repräsentationen erzielt, die räumliches Wissen erfassen. Hier gehen wir einen Schritt vorwärts in diese Richtung und lernen solche Darstellungen, indem wir eine Aufgabe nutzen, die darin besteht, kontinuierliche 2D räumliche Anordnungen von Objekten in Objekt-Beziehung-Objekt-Instanzen vorherzusagen (z.B. "Katze unter Stuhl") und ein einfaches neuronales Netzwerkmodell, das die Aufgabe aus annotierten Bildern lernt. Wir zeigen, dass das Modell diese Aufgabe erfüllt und darüber hinaus in der Lage ist, korrekte räumliche Anordnungen für unsichtbare Objekte vorherzusagen, wenn entweder CNN-Features oder Worteinbettungen der Objekte bereitgestellt werden. Die Unterschiede zwischen visuellen und sprachlichen Merkmalen werden diskutiert. Um die in der vorherigen Aufgabe erlernten räumlichen Darstellungen zu bewerten, stellen wir eine Aufgabe und einen Datensatz vor, der aus einer Menge von crowdsourcing menschlichen Bewertungen räumlicher Ähnlichkeit für Objektpaare besteht. Wir stellen fest, dass sowohl CNN (convolutional neural network) Merkmale als auch Worteinbettungen menschliche Ähnlichkeitsurteile gut vorhersagen und dass diese Vektoren weiter auf räumliches Wissen spezialisiert werden können, wenn wir sie aktualisieren, wenn wir das Modell trainieren, das räumliche Anordnungen von Objekten vorhersagt. Insgesamt ebnet diese Arbeit den Weg zum Aufbau verteilter räumlicher Repräsentationen, die zum Verständnis räumlicher Ausdrücke in Sprache beitragen.</abstract_de>
      <abstract_da>Rumlig forståelse er afgørende i mange problemer i den virkelige verden, men der er kun sket få fremskridt hen imod at opbygge repræsentationer, der fanger rumlig viden. Her bevæger vi os et skridt fremad i denne retning og lærer sådanne repræsentationer ved at udnytte en opgave, der består i at forudsige kontinuerlige 2D rumlige arrangementer af objekter givet objekt-relation-objekt forekomster (f.eks. "kat under stol") og en simpel neural netværksmodel, der lærer opgaven fra annoterede billeder. Vi viser, at modellen lykkes med denne opgave, og at den desuden er i stand til at forudsige korrekte rumlige arrangementer for usynlige objekter, hvis enten CNN-funktioner eller ordindlejringer af objekterne er angivet. Forskellene mellem visuelle og sproglige træk diskuteres. Dernæst, for at evaluere de rumlige repræsentationer, der er lært i den foregående opgave, introducerer vi en opgave og et datasæt bestående af et sæt crowdsourcerede menneskelige vurderinger af rumlig lighed for objektpar. Vi finder ud af, at både CNN (convolutional neural network) funktioner og ordindlejringer forudsiger menneskelige vurderinger af lighed godt, og at disse vektorer kan specialiseres yderligere i rumlig viden, hvis vi opdaterer dem, når vi træner modellen, der forudsiger rumlige arrangementer af objekter. Samlet set baner denne artikel vejen for at opbygge distribuerede rumlige repræsentationer, der bidrager til forståelsen af rumlige udtryk i sproget.</abstract_da>
      <abstract_nl>Ruimtelijk begrip is cruciaal in veel problemen in de echte wereld, maar er is weinig vooruitgang geboekt bij het bouwen van representaties die ruimtelijke kennis vastleggen. Hier gaan we een stap voorwaarts in deze richting en leren we dergelijke representaties door gebruik te maken van een taak die bestaat uit het voorspellen van continue 2D ruimtelijke ordeningen van objecten met object-relatie-object-instanties (bijvoorbeeld 'kat onder stoel') en een eenvoudig neuraal netwerkmodel dat de taak leert van geannoteerde afbeeldingen. We tonen aan dat het model in deze taak slaagt en dat het bovendien in staat is om correcte ruimtelijke ordeningen voor onzichtbare objecten te voorspellen als ofwel CNN-kenmerken of woordinsluitingen van de objecten worden verstrekt. De verschillen tussen visuele en taalkundige kenmerken worden besproken. Vervolgens, om de ruimtelijke representaties die in de vorige taak zijn geleerd te evalueren, introduceren we een taak en een dataset bestaande uit een verzameling crowdsourcing menselijke beoordelingen van ruimtelijke overeenkomsten voor objectparen. We vinden dat zowel CNN (convolutional neural network) eigenschappen als woord embeddings menselijke beoordelingen van overeenkomsten goed voorspellen en dat deze vectoren verder kunnen worden gespecialiseerd in ruimtelijke kennis als we ze bijwerken bij het trainen van het model dat ruimtelijke ordeningen van objecten voorspelt. Over het algemeen effent deze paper de weg naar het bouwen van gedistribueerde ruimtelijke representaties, die bijdragen aan het begrijpen van ruimtelijke expressies in taal.</abstract_nl>
      <abstract_id>Pemahaman ruang penting dalam banyak masalah dunia nyata, namun sedikit kemajuan telah dilakukan untuk membangun representation yang menangkap pengetahuan ruang. Di sini, kita bergerak satu langkah ke depan dalam arah ini dan belajar represisi seperti ini dengan menggunakan tugas yang terdiri dalam memprediksi persediaan ruang 2D terus menerus objek yang diberikan contoh objek-hubungan-objek (contohnya, 'kucing di bawah kursi') dan model jaringan saraf sederhana yang mempelajari tugas dari gambar yang dicatat. Kami menunjukkan bahwa model berhasil dalam tugas ini dan, selain itu, bahwa ia mampu memprediksi persediaan ruang yang tepat untuk objek yang tidak terlihat jika sama ada fitur CNN atau kata embedding objek diberikan. Perbedaan antara karakteristik visual dan bahasa didiskusikan. Selanjutnya, untuk mengevaluasi representation ruang yang belajar dalam tugas sebelumnya, kami memperkenalkan sebuah tugas dan sebuah set data yang terdiri dari set ratings manusia sumber ramai dari persamaan ruang untuk pasangan objek. Kami menemukan bahwa kedua fitur CNN (jaringan saraf konvolusi) dan pembangunan kata memprediksi penilaian manusia tentang persamaan dengan baik dan bahwa vektor-vektor ini dapat lebih spesialisasi dalam pengetahuan ruang jika kita memperbaharuinya ketika melatih model yang memprediksi persediaan ruang objek. Secara umum, kertas ini membuka jalan untuk membangun representation ruang yang disebarkan, berkontribusi untuk memahami ekspresi ruang dalam bahasa.</abstract_id>
      <abstract_ko>공간 이해는 많은 현실 문제에서 매우 중요하지만 공간 지식을 포착하는 표현을 구축하는 데는 진전이 매우 적다.여기서 우리는 이 방향으로 한 걸음 나아갔다. 하나의 임무를 이용하여 이러한 표현을 배웠다. 이 임무는 주어진 대상 관계 대상의 실례(예를 들어 의자 아래의 고양이)를 예측하는 대상의 연속 2차원 공간 배열과 간단한 신경 네트워크 모델을 포함한다. 이 모델은 주석 이미지에서 임무를 배운다.우리는 이 모델이 성공적으로 이 임무를 완성했고 CNN 특징이나 대상의 단어를 삽입하면 보이지 않는 대상의 정확한 공간 배열을 예측할 수 있다는 것을 증명했다.시각적 특징과 언어적 특징 간의 차이를 토론했다.다음에 이전 임무에서 배운 공간을 평가하기 위해 우리는 하나의 임무와 하나의 데이터 집합을 도입했다. 이 데이터 집합은 한 그룹의 패키지의 인류 대상이 공간의 유사성에 대한 평가를 구성하는 것이다.CNN(권적신경망) 특징과 단어 삽입은 유사성에 대한 인간의 판단을 잘 예측할 수 있으며, 만약 우리가 예측 대상의 공간 배열 모델을 훈련할 때 이러한 벡터를 업데이트한다면 이러한 벡터는 공간 지식을 더욱 전문화할 수 있다는 것을 발견했다.전체적으로 말하자면 본고는 분포식 공간 표시를 구축하기 위해 도로를 평평하게 깔아 언어의 공간 표현을 이해하는데 도움이 된다.</abstract_ko>
      <abstract_sw>Uelelezi wa Hispania ni muhimu katika matatizo mengi ya halisi ya dunia, lakini maendeleo madogo yamekuwa yakifanya kwa ajili ya kujenga uwakilishi wenye maarifa ya hisia. Here, we move one step forward in this direction and learn such representations by leveraging a task consisting in predicting continuous 2D spatial arrangements of objects given object-relationship-object instances (e.g., 'cat under chair') and a simple neural network model that learns the task from annotated images.  Tunaonyesha kuwa mtindo huu umefanikiwa katika kazi hii na zaidi, kwamba inaweza kutabiri mikakati sahihi ya anga kwa vitu visivyofichikana kama ni vipengele vya CNN au maneno ya kuweka vifaa vinavyotolewa. tofauti kati ya vipengele vya kuona na lugha zinajadiliwa. Baadae, ili kutathmini wawakilishi wa anga waliojifunza katika kazi zilizopita, tunaanzisha kazi na seti ya taarifa zinazojumuisha katika mfululizo wa vyanzo vya wanadamu vya usawa wa anga kwa ajili ya wanaume wanaoba vitu. Tunapata kwamba wote CNN (mtandao wa taratibu za kikatili) zinaonyesha na maneno yanayotangaza maamuzi ya binadamu yanayofanana vizuri na kwamba vector hizi zinaweza kuwa maalumu zaidi katika maarifa ya anga kama tutawafundisha mifano inayotabiri mikakati ya anga ya vitu. Kwa ujumla, gazeti hili linaweka njia ya kujenga uwakilishi wa anga, na kusaidia kuelewa maoni ya hisia kwa lugha.</abstract_sw>
      <abstract_fa>درک فضایی در بسیاری از مشکلات دنیای واقعی مهم است، ولی هنوز پیشرفت کمی به ساختن نمایش‌های فضایی که علم فضایی را گیر می‌گیرند انجام شده است. در اینجا، ما یک قدم به پیش روی این مسیر حرکت می کنیم و چنین نمایش‌هایی را یاد می‌گیریم با تأثیر کردن یک کار در پیش بینی کردن دستورالعمل فضایی ۲D از چیزهایی که به عنوان نمایش‌های رابطه‌های objektu-objektu (مثلاً 'گربه زیر صندلی') و یک مدل شبکه عصبی ساده‌ای که این کار را از تصاویر ما نشان می‌دهیم که مدل در این کار موفق می‌شود و در ضمن، قادر است پیش‌بینی برنامه‌های فضایی درست برای اشیاء غیب باشد، اگر یا ویژه‌های سی‌ان یا جمع کلمه‌های اشیاء پیش‌بینی شود. تفاوت بین ویژه‌های دیده و زبان‌شناسی در مورد بحث می‌شوند. بعدش، برای ارزیابی نمایش های فضایی که در وظیفه قبلی یاد گرفته‌اند، ما یک کار و مجموعه داده‌ای را معرفی می‌کنیم که در مجموعه‌ی مقدار‌های انسان‌های جامعه‌ای از شبیه‌های فضایی برای جفت‌های جفت‌ها وجود دارد. ما پیدا می‌کنیم که هر دو ویژگی‌های سی‌ان‌ان (شبکه‌های عصبی) و ابتدایی‌های کلمه‌های ابتدایی از قضاوت انسان را خوب پیش‌بینی می‌کنند و این ویکتورها می‌توانند در دانش فضایی بیشتر ویژه‌گیری کنند اگر آنها را در زمان آموزش مدل‌ای که پیش‌بینی سازی فضای در کل این کاغذ راه به ساختن نمایش های فضایی تقسیم می کند و به درک تعریف های فضایی به زبان کمک می کند.</abstract_fa>
      <abstract_tr>Esasy d체힊체nmek birn채챌e d체n첵채 챌yky힊 meselelerinde m철h체m, 첵철ne uzay bilgileri alyp 첵erle힊첵채n 챌yky힊lara biraz 철s체mli boldy. Bu 첵erde, biz bu y철nde bir ad캇m 철흫체nde g 철챌dik we 힊onu흫 첵aly suratlaryny 챌ykaryp 철wrenip otyrsak zady흫 2-nji derejesi baglany힊yk-zady흫 (mesel창, 'oturgan pi힊ik') we bellenen suratlardan bu첵ruky 철wrenip bilen basit bir nu첵ral 힊ebeke modelini 철wrenip otyr첵arys. Biz bu zady흫 nusgasyny ba힊arap bar첵andygyny g철rke첵채n. Mundan hem, CNN-i흫 체첵tgewleri 첵a-da zady흫 gabdalyklary흫 d체zg체n d체z체mlerni t채ze tahmin edip biljekdigini g철rke첵채n. G철rsel we lingwistiki 철zellikleri흫 arasyndaky tapawutlar 챌ykyl첵ar. So흫ra, 철흫ki g철relde 철wrenen 첵erleri 챌yky힊 etmek 체챌in, biz zady we veri setirini bir topar ki힊i hasaplan첵ar we zady흫 챌ift 체챌in spasi첵al me흫ze힊liklerinde guruldyr첵arys. CNN hem 철zellikleri hem s철zlerimiz be 첵leki 챌철z체mlerini gowy tahmin edip bil첵채ris we bu vekt철rler, eger olary흫 uzay d체zenlemelerini tahmin eden modelini 철흫체nde 철zellikle edip biljeklerimizi tap첵arys. Bu kagyz hemme 체챌in 첵erle힊ikli suratlary d체zenlemek 체챌in 첵olu 챌ykar첵ar.</abstract_tr>
      <abstract_af>Spasiele verstanding is daardie groot in baie regte wêreld probleme, maar nog klein vordering is gemaak tot die bou van voorstellings wat spasiele kennis aanvang. Hier, ons beweeg een stap vorentoe in hierdie rigting en leer sodanige voorstellings deur 'n taak wat bestaan in voorskou van voortdurende 2D spasielle arrangensies van voorwerpe gegee objekte-verhouding-voorwerpe (bv. 'kat onder stoel') en 'n eenvoudige neural e netwerk model wat leer die taak van annotateerde beelde. Ons wys dat die model suksesvol in hierdie taak en, daarom, dat dit kan voorskou korrekte spasielle arrangemente vir ongestelde objekte as of CNN funksies of woord inbettings van die objekte verskaf word. Die verskille tussen visuele en lingvisiese eienskappe word gespreek. Volgende, om die spasiele voorstellings wat in die vorige taak geleer word te evalueer, introduseer ons 'n taak en 'n datastel wat in 'n stel van verskeie menslike waardelings van spasiele gelykenis vir objekte paar bestaan word. Ons vind dat beide CNN (konvolusionele neuralnetwerk) funksies en woord inbêdings menslike oordelings goed voorskou en dat hierdie vektore verder spesialiseer kan word in spasiele kennis as ons dit opdateer wanneer ons die model optrek wat spasielle aanpassings van objekte voorskou. Hierdie papier bedryf die pad na die bou van verspreidige spasielle voorstellings en bydra by die verstanding van spasielle uitdrukkings in taal.</abstract_af>
      <abstract_hy>Տարային հասկացությունը շատ իրական աշխարհի խնդիրների մեջ կարևոր է, սակայն փոքր առաջընթաց է արվել պատկերացումների կառուցման համար, որոնք ընդունում են տարածական գիտելիքները: Այստեղ մենք մի քայլ առաջ ենք քայլում այս ուղղությամբ և սովորում ենք նման ներկայացումներ օգտագործելով մի խնդիր, որը կազմում է նշված առարկաների շարունակական երկչափ տարածական կառուցվածքների կանխատեսումը, որոնք տրվում են առարկաների և հարաբերության առարկաների օրինակներ (օրինակ, "կատուն աթոռի տակ"), և մի պարզ ն Մենք ցույց ենք տալիս, որ մոդելը հաջողվում է այս խնդրի մեջ, և, ավելին, որ այն կարող է կանխատեսել անտեսանելի օբյեկտների ճիշտ տարածական կառուցվածքները, եթե կամ CNN-ի հատկությունները կամ օբյեկտների բառերը ներգրավված են: Վիզուալ և լեզվաբանական հատկությունների տարբերությունները քննարկվում են: Հաջորդ, նախորդ խնդրի ժամանակ սովորված տարածական ներկայացումների գնահատման համար մենք ներկայացնում ենք խնդիր և տվյալներ, որոնք կազմված են մարդկային բազմաթիվ բնակվող տարածական նմանության գնահատականներով օբյեկտների զույգերի համար: We find that both CNN (convolutional neural network) features and word embeddings predict human judgments of similarity well and that these vectors can be further specialized in spatial knowledge if we update them when training the model that predicts spatial arrangements of objects.  Ընդհանուր առմամբ, այս թղթին պատրաստում է ճանապարհ տարածված տարածական ներկայացումներ կառուցելու համար, որոնք օգնում են հասկանալ տարածական արտահայտությունները լեզվով:</abstract_hy>
      <abstract_az>Uzay anlaşılması çox real dünya problemlərində çox mövcuddur, amma uzay bilgiləri almaq üçün az bir tədbir in şa edildi. Burada, biz bu tərəfdə bir adım ileri sürükləyirik və böyük g östəriciləri öyrənirik, bu işləri müəyyən edilən objektlər-ilişkilər-objektlərin müəyyən edilməsi ilə müəyyən edilən 2D uzaq düzenlemelərini təmin edərək öyrənirik (məsələn 'sandığın altındakı keçik') və bu işi bildirilmiş şəkillərdən öyrənən basit nör Biz modellərin bu işdə başarılı olduğunu göstərərik və buna görə də, CNN fəaliyyətləri və ya sözlərin istifadə edilməsi üçün müəyyən edilməmiş şeylərə doğru uzaq düzenlemeləri təmin edə bilər. Görüş və dil özellikləri arasındakı fərqlər mübahisə edilir. Daha sonra, əvvəlki işdə öyrəndiyi yer göstəricilərin değerlendirmək üçün, objek çiftlərinin uzaq similitəsi ilə birlikdə olan bir iş və veri qurğunu təşkil edirik. Biz CNN-nin (konvolucional nöral ağ) özellikləri və sözlərin istifadə edilməsi insanların bənzərinin hökmlərini yaxşı tədbir edir və bu vektörlər uzaq elmdə daha çox xüsusiyyətli olarlar, əgər biz onları məsələlərin uzaq düzenlemesini təhsil edən modeli təhsil edərkən güncellə bilərik. Bütün bunlar, bu kağıt dildə uzay ifadələri anlamağa kömək edir.</abstract_az>
      <abstract_bs>Svemirsko razumijevanje je ključno u mnogim stvarnim problemima u svijetu, a ipak je napredak napredovao prema izgradnji predstavljanja koje uključuju prostorno znanje. Ovdje, krećemo jedan korak naprijed u ovom smjeru i naučimo takve predstave uvećanjem zadatka koji se sastoji u predviđanju neprestano dvostrukih prostornih aranžmana objekata koji su određeni instanci objekata-odnosa-objekata (npr. 'mačka pod stolicom') i jednostavnog model a neuralne mreže koji nauči zadatak iz annotiranih slika. Pokazujemo da je model uspješan u ovom zadatku i, dodatno, sposoban je predvidjeti ispravne prostorne aranžmane za nevidljive objekte ako se pružaju ili CNN karakteristike ili riječi uključenje objekata. Raspravljaju se razlike između vizuelnih i jezičkih karakteristika. Sljedeće, kako bi procijenili svemirske predstave koje su naučene u prethodnom zadatku, predstavljamo zadatak i set podataka koji se sastoji u skupu popularnih ljudskih ocjena prostorne sličnosti objektima. Nalazimo da i CNN (konvolucionalna neuralna mreža) karakteristike i ugrađenje riječi dobro predviđaju ljudske osude o sličnosti i da ovi vektori mogu biti dalje specijalizovani u prostornim znanjima ako ih aktualizujemo kada obučavamo model koji predviđa prostorne aranžmane objekata. U cjelokupnom, ovaj papir otvara put ka izgradnji raspodjeljenih prostornih predstavljanja, koji doprinosi razumijevanju prostornih izraza na jeziku.</abstract_bs>
      <abstract_am>Spatial understanding is crucial in many real-world problems, yet little progress has been made towards building representations that capture spatial knowledge.  ወደዚህ፣ አንድ ደረጃን ወደፊት እንነሳቅሳለን እና እንደዚህ ዓይነት መልዕክቶችን በመስጠት እና ትምህርት እና ስራውን ከታዋቂው ምስሎች የሚተማር ቀላል የሁለት ዲዮ ስፋትዊ ጉዳይ አካባቢዎች (ለምሳሌ፣ 'በክፍል በታች›) እና ቀላል የነጥብ መረብ model ነው፡፡ እናሳያቸዋለን፤ ሞላው በዚህ ስራ እንዲያድነው እናም ደግሞ የCNN ምርጫዎች ወይም የአካባቢዎች ግንኙነት እንዲሰጧቸው የስፍራዊ ደረጃዎችን ለመቀበል ይችላል፡፡ የራእይ እና የቋንቋዊ ምርጫዎች መካከል የተለያየ ነው፡፡ የቀድሞው ስራ ውስጥ ተማርነው የነበረውን የስፋዊ መልዕክቶች ለማስተዋል፣ ስራትን እና አካባቢ አካባቢ አካባቢ አካባቢ አካባቢ እና የሚቆጠሩን ዳታተሮችን እናስጠጋለን፡፡ የCNN (የጠንካራ ኔትዎርክ) ደብዳቤ እና ቃላት የሰው ፍርድ በሚያሳየው እና እነዚህም vectors የስፋዊ እውቀት ባስተማርናቸው ጊዜ የስፋዊ ድርጅቶችን ባስተማርናቸው ጊዜ እናሳውቃቸዋለን፡፡ ይህ ገጽ በቋንቋ ውስጥ የስፋዊ መልዕክቶችን ለመሥራት መንገድ ያሳድጋል፡፡</abstract_am>
      <abstract_sq>Përkuptimi hapësiror është vendimtar në shumë probleme të botës reale, megjithatë është bërë pak përparim drejt ndërtimit të përfaqësimeve që kapin njohurinë hapësirore. Këtu, ne lëvizim një hap përpara në këtë drejtim dhe mësojmë përfaqësime të tilla duke përdorur një detyrë që përbëhet nga parashikimi i rregullimeve të vazhdueshme hapësore 2D të objekteve të dhëna raste objekti-marrëdhënie-objekti (për shembull, 'mace nën karrige') dhe një model i thjeshtë rrjeti nervor që mëson detyrën nga imazhet e anotuara. We show that the model succeeds in this task and, furthermore, that it is capable of predicting correct spatial arrangements for unseen objects if either CNN features or word embeddings of the objects are provided.  Ndryshimet midis karakteristikave vizuale dhe gjuhësore diskutohen. Më pas, për të vlerësuar përfaqësimet hapësirore të mësuara në detyrën e mëparshme, ne paraqesim një detyrë dhe një grup të dhënash që përbëhet nga një sërë vlerësimesh njerëzore të shumëllojshme të ngjashmërisë hapësirore për dy objekte. Ne zbulojmë se si funksionet e CNN (rrjetit nervor konvolutiv) dhe përfshirjet e fjalëve parashikojnë gjykimet njerëzore të ngjashmërisë mirë dhe se këto vektorë mund të specializohen më tej në njohuri hapësirore nëse i përditësojmë ato kur trajnojmë model in që parashikon rregullimet hapësirore të objekteve. Në përgjithësi, kjo letër hap rrugën drejt ndërtimit të përfaqësimeve hapësirore të shpërndara, duke kontribuar në kuptimin e shprehjeve hapësirore në gjuhë.</abstract_sq>
      <abstract_bn>বিশ্বের অনেক বাস্তবতা সমস্যায় স্পেয়াল বুঝতে গুরুত্বপূর্ণ, কিন্তু সামান্য অগ্রগতি তৈরি করা হয়েছে যারা স্পেশি এখানে আমরা এই দিকে একটি পদক্ষেপ এগিয়ে যাই এবং এই ধরনের প্রতিনিধিত্ব শিখতে পারি যেখানে দ্বিতীয় দ্বিতীয় দ্বিতীয় বস্তুর স্পেশিয়াল সংক্রান্ত বিষয়বস্তুর প্রতিষ্ঠানের মাধ্যমে প্রতিনিধ আমরা দেখাচ্ছি যে মডেল এই কাজে সফল হয়েছে এবং তাছাড়াও, এটি অদৃশ্য বস্তুর জন্য সঠিক স্পেশিয়াল সংগঠন ভবিষ্যদ্বাণী করতে সক্ষম, যদি সিএনএন-এর বৈশিষ্ট্য অথবা বস্তুর দৃশ্যমান এবং ভাষাগত বৈশিষ্ট্যের মধ্যে পার্থক্য আলোচনা করা হয়েছে। পরবর্তীতে পূর্ববর্তী কাজে শিক্ষিত স্পেশিয়াল প্রতিনিধিদের মূল্যায়নের জন্য আমরা একটি কাজ পরিচয় করিয়ে দেই এবং একটি ডাটাসেটের পরিচয় করিয়ে দেই যার মধ্যে  We find that both CNN (convolutional neural network) features and word embeddings predict human judgments of similarity well and that these vectors can be further specialized in spatial knowledge if we update them when training the model that predicts spatial arrangements of objects.  সাধারণত এই পত্রিকা স্পেশিয়াল প্রতিনিধিদের বিতরণের দিকে বানানোর পথ প্রকাশ করে, যা ভাষায় স্পেশিয়াল প্রকাশের বুঝা</abstract_bn>
      <abstract_ca>L'enteniment espacial és crucial en molts problemes del món real, però s'ha fet poc progrés cap a la construcció de representacions que capturen el coneixement espacial. Aquí, avancem un pas cap endavant en aquesta direcció i aprenem aquestes representacions aprofitant una tasca consistint en predir arreglaments espacials en 2D continus d'objectes donats instances d'object e-relació-objecte (per exemple, 'gat sota la cadera') i un simple model de xarxa neural que aprenen la tasca a partir d'imatges anotates. We show that the model succeeds in this task and, furthermore, that it is capable of predicting correct spatial arrangements for unseen objects if either CNN features or word embeddings of the objects are provided.  Les diferències entre les característiques visuals i lingüístices es discuten. Next, to evaluate the spatial representations learned in the previous task, we introduce a task and a dataset consisting in a set of crowdsourced human ratings of spatial similarity for object pairs.  Trobem que tant les característiques CNN (xarxa neural convolutiva) com l'incorporació de paraules predeixen bé els judicis humans de similitud i que aquests vectors poden ser més especialitzats en el coneixement espacial si les actualitzem quan entrenem el model que predeix arreglaments espacials d'objectes. En general, aquest paper obre el camí cap a construir representacions espacials distribuïdes, contribuint a la comprensió de les expressions espacials en el llenguatge.</abstract_ca>
      <abstract_cs>Prostorové porozumění je klíčové v mnoha problémech reálného světa, přesto bylo dosaženo malého pokroku směrem k budování reprezentací, které zachycují prostorové znalosti. Zde se pohybujeme o krok vpřed tímto směrem a naučíme se takové reprezentace využitím úkolu spočívajícího v předpovědi kontinuálního 2D prostorového uspořádání objektů v instancích objektu-vztahu-objektu (např. "kočka pod křeslem") a jednoduchého modelu neuronové sítě, který se úkol učí z anotovaných obrázků. Ukazujeme, že model uspěje tento úkol a dále je schopen předpovídat správné prostorové uspořádání neviditelných objektů, pokud jsou poskytnuty buď CNN prvky, nebo slovní vložení objektů. Jsou diskutovány rozdíly mezi vizuálními a jazykovými rysy. Dále pro zhodnocení prostorových reprezentací naučených v předchozím úkolu představujeme úlohu a datovou sadu sestávající ze sady crowdsourcingových lidských hodnocení prostorové podobnosti pro objektové páry. Zjišťujeme, že jak CNN (konvoluční neuronová síť) vlastnosti, tak i slovní vložení dobře předpovídají lidské hodnocení podobnosti a že tyto vektory mohou být dále specializovány na prostorové znalosti, pokud je aktualizujeme při tréninku modelu, který předpovídá prostorové uspořádání objektů. Celkově tento článek připravuje cestu k budování distribuovaných prostorových reprezentací, které přispívají k porozumění prostorovým výrazům v jazyce.</abstract_cs>
      <abstract_et>Ruumiline mõistmine on paljude reaalsete probleemide puhul otsustava tähtsusega, kuid ruumilisi teadmisi hõlmavate representatsioonide loomisel on tehtud vähe edusamme. Siin liigume ühe sammu edasi selles suunas ja õpime selliseid esitusi, kasutades ülesannet, mis seisneb objektide pideva 2D ruumilise paigutuse ennustamises objekti antud suhte-objekti eksemplaride (nt "kass tooli all") ja lihtsat närvivõrgumudelit, mis õpib ülesande annoteeritud piltidest. Näitame, et mudel õnnestub selles ülesandes ja lisaks on võimeline ennustama nähtamatute objektide korrektset ruumilist paigutust, kui on esitatud objektide CNN-funktsioonid või sõnaseadistused. Arutatakse visuaalsete ja keeleliste omaduste erinevusi. Seejärel tutvustame eelmises ülesandes õppitud ruumiliste representatsioonide hindamiseks ülesannet ja andmekogumit, mis koosneb ühisallikatest inimeste ruumilise sarnasuse hinnangutest objektipaaride jaoks. Leiame, et nii CNN-i (konvolutsioonilise neuraalvõrgu) funktsioonid kui ka sõnade manustamine ennustavad hästi inimese sarnasuse hinnanguid ning et need vektorid võivad olla veelgi spetsialiseerunud ruumilistele teadmistele, kui neid uuendame objektide ruumilist paigutust prognoosiva mudeli koolitamisel. Kokkuvõttes sillutatakse käesolev töö teed hajutatud ruumiliste representatsioonide loomisele, aidates kaasa ruumiliste väljendite mõistmisele keeles.</abstract_et>
      <abstract_fi>Tilan ymmärtäminen on ratkaisevan tärkeää monissa reaalimaailman ongelmissa, mutta vain vähän edistystä on saavutettu paikkatietoutta hyödyntävien representaatioiden rakentamisessa. Tässä siirrymme askeleen eteenpäin tähän suuntaan ja opimme tällaisia esityksiä hyödyntämällä tehtävää, joka koostuu objektien jatkuvan 2D-paikkajärjestelyn ennustamisesta tiettyihin objekti-suhde-objektiinstanssiin (esim. "kissa tuolin alla") ja yksinkertaisesta neuroverkkomallista, joka oppii tehtävän annotoiduista kuvista. Osoitamme, että malli onnistuu tässä tehtävässä ja lisäksi, että se pystyy ennustamaan näkymättömien kohteiden oikeat paikkajärjestelyt, jos kohteiden CNN-ominaisuudet tai sanaupotukset ovat saatavilla. Keskustellaan visuaalisten ja kielellisten ominaisuuksien eroista. Seuraavaksi edellisessä tehtävässä opittujen paikkaesitysten arvioimiseksi esittelemme tehtävän ja aineiston, joka koostuu joukkolähteistä kootuista ihmisluokituksista paikkatietopareille. Havaitsemme, että sekä CNN:n (konvolutional neural network) ominaisuudet että sanaupotukset ennustavat hyvin ihmisten samankaltaisuusarvioita ja että nämä vektorit voivat erikoistua edelleen paikkatietoon, jos päivitämme niitä koulutettaessa mallia, joka ennustaa objektien paikkajärjestelyjä. Yleisesti ottaen tämä työ tasoittaa tietä hajautettujen paikkaesitysten rakentamiselle, mikä auttaa ymmärtämään kielen paikkailmaisuja.</abstract_fi>
      <abstract_sk>Prostorsko razumevanje je ključnega pomena pri številnih resničnih problemih, vendar je bil dosežen malo napredka pri gradnji reprezentacij, ki zajemajo prostorsko znanje. Tukaj se premaknemo korak naprej v to smer in se naučimo takšnih predstavitev z izkoriščanjem naloge, ki je sestavljena iz napovedovanja neprekinjenih 2D prostorskih ureditev objektov v danih primerih objekta-odnosa-objekt (npr. "mačka pod stolom") in preprostega modela nevronskega omrežja, ki se nalogo nauči iz označenih slik. Pokažemo, da model uspe pri tej nalogi in da je sposoben napovedati pravilno prostorsko ureditev za nevidne objekte, če so zagotovljene bodisi značilnosti CNN bodisi besedne vdelave objektov. Obravnavane so razlike med vizualnimi in jezikovnimi značilnostmi. Za vrednotenje prostorskih reprezentacij, pridobljenih v prejšnji nalogi, predstavimo nalogo in nabor podatkov, sestavljen iz nabora množičnih človeških ocen prostorske podobnosti za objektne pare. Ugotavljamo, da tako značilnosti CNN (konvolucijsko nevronsko omrežje) kot tudi besedne vdelave dobro napovedujejo človeške presoje podobnosti in da so ti vektorji lahko še bolj specializirani za prostorsko znanje, če jih posodobimo pri usposabljanju modela, ki napoveduje prostorsko ureditev objektov. Prispevek na splošno utrjuje pot k gradnji porazdeljenih prostorskih reprezentacij, ki prispevajo k razumevanju prostorskih izrazov v jeziku.</abstract_sk>
      <abstract_he>הבנה חללית היא קריטית בבעיות רבות בעולם האמיתי, אך התקדמות מעט בניית מייצגים שיתפסו ידע חללית. כאן, אנו ממשיכים צעד אחד קדימה בכיוון הזה וללמד מייצגים כאלה על ידי השימוש במשימה שמתכוונת בחזוי אסורות חלליות שתיים מימדיות ממשיכות של אובייקטים שנתנו מקרים של אובייקטים-יחסים-אובייקטים (למשל, "חתול מתחת לכיסא") ומודל רשת עצבית פשוט שלמד את המשימה מתמונות מוצבות. אנו מראים שהמודל מצליח במשימה הזאת, ובנוסף לכך, שהוא מסוגל לחזות סידורים מקומיים נכונים עבור חפצים בלתי נראים אם ניתן גם תכונות CNN או מילים של החפצים. ההבדלים בין תכונות ויזואליות לשוניות נדון. לאחר מכן, כדי להעריך את היציגות החלל שנלמדו במשימה הקודמת, אנו מכירים משימה ומערכת נתונים שמכילה בסט של ציונים אנושיים ממקורים קהלים של דומות חלליות לזוגי אובייקטים. אנו מוצאים ששני תכונות CNN (רשת עצבית משתנה) וכניסות מילים חושפות את השיפוטים האנושיים של דמיון טוב ושווקטורים אלה יכולים להיות מיוחדים יותר בידע חללי באופן כללי, הנייר הזה מוציא את הדרך לכיוון בניית מייצגים חלליים מרוחקים, תורם להבנה של ביטויים חלליים בשפה.</abstract_he>
      <abstract_ha>Babu fahimtar spati yana da muhimu a cikin masu cikin masu cikin duniya masu gaskiya, kuma amma an sami mafariko kaɗan zuwa kuɓutar da mabuwãyar taskõki waɗanda ke riƙon ilmi na spaspati. Hali, Munã tafiyar da ƙõfõfi guda a gaba gaba ɗaya cikin wannan gefen kuma munã barci masu tsari da shi da za'a gajiya wani aikin da za'a iya ƙara wa muhimmi na biyu na sauri da abubuwa da aka yi wa abun-da-abun (misali, "kata a a ƙarƙasan sararin") da misãlin jeri mai sauƙi da yana sanar da aikin daga zane-zane da aka sanar da shi. Tuna nũna cewa misalin ya ci nasara a cikin wannan aikin kuma, a ƙaranci, yana iya iya ƙayyade juyi masu tsari na gaske wa abun da ba'a ɓõye ba, idan an ba da tsarin CNN ko kuma kalmar da aka shigar da abun. An yi musu sãɓãnin gafaku da lingui. Na ƙarshe, dõmin ka yi evaluation ga wakilishi na spaspati wanda aka sanar da shi a cikin aikin da aka riga, za mu introduce wani aikin na farko, da wani tsarin da ke haɗa a cikin wasu mutane da aka tsohatar mutane da rabon spaspaspati da daidaita wa nau'in abun biyu. Tuna gane cewa dukkan CNN (shirin neural na ɗabi'a) masu amfani da maganar da ke gabatar da hukuncin mutãne masu daidaita da misãli, kuma za'a iya iya ƙayyade wannan masu shiryuwa a cikin ilmi na spaspaspata idan za mu yanyanka su idan an sanar da shi da motel wanda ke gajiya masu cikin tsari na gaskiyar abubuwa. Overall, this paper paves the way towards building distributed spatial representations, contributing to the understanding of spatial expressions in language.</abstract_ha>
      <abstract_jv>Awakdhèké beraksi sing klêrung nêmên wong liya-wong liya, kuwi jenis akeh njaluké durung nggawe ngupakan pawar kuwi nggawe barang awak dhéwé. string" in "context_BAR_stringLink Awak dhéwé ngomong nik model sing sumulai ing nggawe iki dadi, lan tambah, iso disenyong kelas pangan anyar sing dibutuhke tarjamahan kanggo ngilangno object. Versi karo akeh liyane anyar karo akeh ingkang dipepuli Next Awak dhéwé éntukno gawe lan tambah konvolutasyon seneng nggawe geraksi perbudhakan winih sing dumadhi, lan vector nyong bisa dianggawe barang dhéwé urip bantuan ingkang dipunangé awak dhéwé. Tulung bon, kuwi iki dadi nggawe barang kanggo nggawe pawartos resmi surraning, iso nggunakake ngerasahan kelas kuwi tindah.</abstract_jv>
      <abstract_bo>བར་སྟོང་ཤེས་ཀྱི་རྟོགས་འདི་ནི་ངོ་མ་འཛམ་གླིང་གི་དཀའ་ངལ་ཆེ་བའི་ནང་དུ་གལ་ཆེན་པོ་ཡོད་ནའང་མ་ལས་ཕར་རྒྱས་སྐྱོར་ འདིར་ང་ཚོས་རྒྱབ་སྐྱོར་འདིའི་གཤམ་ལ་གཅིག་སྤྱད་ནས་གནད་དོན་མི་སྟོན་པའི་བྱ་རིམ་ཞིག་ལ་སྤྱད་ནས་མཐུན་རྐྱེན་དུ་འཇུག ང་ཚོས་མིག་སྔར་སྟོན་པར་བྱ་འགུལ་འདིའི་ནང་གི་རྣམ་པ་དེ་ལས་ཕར་སྟོན་པར་བྱུང་བ་སྟེ། མ་ཤེས་པའི་དངོས་པོ་ཚོའི་ཁྱད་ཆོས་ཡང་ན་གསལ་གྲངས མཐོང་ནུས་དང་སྐད་རིགས་ཆ་ཁྱད་པར་བཤད་ཡོད། འོན་ཀྱང་། ང་ཚོས་དུས་མཐུན་གྱི་བརྗོད་རྗེས་སྔོན་གྱི་བྱ་འགུལ་ནང་གི་བར་སྟོང་བ་མང་པོ་ཞིག་སྤྲོད་ཡོད་པའི་བྱ་བ་དང་། ང་ཚོས་CNN(ཆ་མཉམ་སྦྲེལ་མཐུད་དྲ་བར་ཆ་དང་)ཆ་མཉམ་དུ་མཐུད་པའི་མི་རྣམས་མཐུན་སྔོན་སྒྲིག་ཡོད་པའི་མཐུན་རྐྱེན་འདི་དག་སྟོང ཡིག</abstract_bo>
      </paper>
    <paper id="11">
      <title>Modeling Past and Future for Neural Machine Translation</title>
      <author><first>Zaixiang</first><last>Zheng</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Xinyu</first><last>Dai</last></author>
      <author><first>Jiajun</first><last>Chen</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <doi>10.1162/tacl_a_00011</doi>
      <abstract>Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase. To address this problem, we propose a novel mechanism that separates the source information into two parts : translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers. The Past and Future contents are fed to both the attention model and the decoder states, which provides Neural Machine Translation (NMT) systems with the knowledge of translated and untranslated contents. Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English, and English-German translation tasks. Specifically, the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the conventional coverage model in terms of both the translation quality and the alignment error rate.</abstract>
      <pages>145–157</pages>
      <url hash="5c301710">Q18-1011</url>
      <bibkey>zheng-etal-2018-modeling</bibkey>
      <pwccode url="https://github.com/zhengzx-nlp/past-and-future-nmt" additional="false">zhengzx-nlp/past-and-future-nmt</pwccode>
    <title_ar>نمذجة الماضي والمستقبل للترجمة الآلية العصبية</title_ar>
      <title_pt>Modelagem do passado e do futuro para a tradução automática neural</title_pt>
      <title_es>Modelando pasado y futuro para la traducción automática neuronal</title_es>
      <title_fr>Modélisation du passé et de l'avenir pour la traduction automatique</title_fr>
      <title_ja>神経機械翻訳のための過去と未来のモデリング</title_ja>
      <title_zh>神经机器翻译往与来建模</title_zh>
      <title_hi>मॉडलिंग अतीत और तंत्रिका मशीन अनुवाद के लिए भविष्य</title_hi>
      <title_ru>Моделирование прошлого и будущего для нейронного машинного перевода</title_ru>
      <title_ga>Samhaltú an Amach agus Amach Anseo le hAghaidh Néar-Aistriúcháin Meaisín</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Μοντελοποίηση του παρελθόντος και του μέλλοντος για τη νευρωνική μηχανική μετάφραση</title_el>
      <title_hu>Múlt és jövő modellezése a neurális gépi fordításhoz</title_hu>
      <title_it>Modellare passato e futuro per la traduzione automatica neurale</title_it>
      <title_kk>Неврал машинаны аудару үшін өткен және келесі үлгілеу</title_kk>
      <title_mk>Моделирање на минатото и иднината за превод на неврални машини</title_mk>
      <title_ms>Modeling Past and Future for Neural Machine Translation</title_ms>
      <title_mt>Mudellar tal-passat u tal-ġejjieni għat-traduzzjoni tal-makkinarju newrali</title_mt>
      <title_lt>Ankstesnio ir būsimo modeliavimas neurologinių mašinų vertimui</title_lt>
      <title_mn>Өмнөх болон ирээдүйн сэтгэл мэдрэлийн машин хөгжлийн модель</title_mn>
      <title_ro>Modelarea trecutului și viitorului pentru traducerea automată neurală</title_ro>
      <title_no>Modelerer tidlegare og framtidig for neirale maskinsomsetjing</title_no>
      <title_ml>നെയുറല്‍ മെഷീന്‍ പരിഭാഷക്കുള്ള മോഡലിങ് പാസ്റ്റും ഭാവിയും</title_ml>
      <title_si>පසුගිය සහ අනාගතය සඳහා න්‍යූරල් මැෂින් පරිවර්තනය</title_si>
      <title_sv>Modellera förflutet och framtiden för neural maskinöversättning</title_sv>
      <title_pl>Modelowanie przeszłości i przyszłości neuronowego tłumaczenia maszynowego</title_pl>
      <title_ta>Modeling Past and Future for Neural Machine Translation</title_ta>
      <title_sr>Modeliranje prošle i budućnosti za neuronski prevod mašine</title_sr>
      <title_so>Modeling Past and Future for Neural Machine Translation</title_so>
      <title_ur>نئورل ماشین ترجمہ کے لئے پچھلے اور آیندہ مدل کیا جاتا ہے</title_ur>
      <title_uz>Modeling Past and Future for Neural Machine Translation</title_uz>
      <title_vi>Chế độ lắp đặt Máy thần kinh</title_vi>
      <title_da>Modellering af fortid og fremtid for neural maskinoversættelse</title_da>
      <title_nl>Modelleren van verleden en toekomst voor neuronale machinevertaling</title_nl>
      <title_bg>Моделиране на миналото и бъдещето за неврален машинен превод</title_bg>
      <title_hr>Modeliranje prošle i budućnosti za neuronski prevod stroja</title_hr>
      <title_de>Modellierung von Vergangenheit und Zukunft für neuronale maschinelle Übersetzung</title_de>
      <title_fa>Modeling Past and Future for Neural Machine Translation</title_fa>
      <title_ko>신경기계 번역의 과거와 미래 모델링</title_ko>
      <title_id>Modeling masa lalu dan masa depan untuk Translation Mesin Neural</title_id>
      <title_sw>Tafsiri ya Mashine ya Kifaransa</title_sw>
      <title_tr>Neural Makina terjime üçin öňki we Gelecek nusgala</title_tr>
      <title_af>Name</title_af>
      <title_sq>Modelimi i së kaluarës dhe të ardhmes për përkthimin e makinave nervore</title_sq>
      <title_am>undo-type</title_am>
      <title_bn>নিউরাল মেশিন অনুবাদের জন্য মডেলিং প্যাস্ট এবং ভবিষ্যত</title_bn>
      <title_hy>Նյարդային մեքենայի թարգմանման անցյալի և ապագայի մոդելավորումը</title_hy>
      <title_az>N칬ral ma코in t톛rc칲m톛si 칲칞칲n 톛vv톛lki v톛 g톛l톛c톛k modell톛ri</title_az>
      <title_bs>Modeliranje prošle i budućnosti za neuronski prevod mašine</title_bs>
      <title_et>Mineviku ja tuleviku modelleerimine neuroaalse masintõlke jaoks</title_et>
      <title_ca>Modelar el passat i el futur per a la traducció de màquines neurals</title_ca>
      <title_cs>Modelování minulosti a budoucnosti pro neuronový strojový překlad</title_cs>
      <title_fi>Menneisyyden ja tulevaisuuden mallintaminen neurokääntämiseen</title_fi>
      <title_sk>Modeliranje preteklosti in prihodnosti za nevralno strojno prevajanje</title_sk>
      <title_ha>@ action</title_ha>
      <title_jv>Ngawe Perintah Pasing karo Perintah kanggo Perintah Njaral</title_jv>
      <title_he>Modeling Past and Future for Neural Machine Translation</title_he>
      <title_bo>དཔེ་དབྱིབས་མིའི་ལག་འཁྱེར་ལ་སྔོན་སྒྲིག་དང་མ་འོངས་པ</title_bo>
      <abstract_fr>Les systèmes de traduction automatique neuronale existants ne modélisent pas explicitement ce qui a été traduit et ce qui ne l'a pas été pendant la phase de décodage. Pour résoudre ce problème, nous proposons un nouveau mécanisme qui sépare les informations sources en deux parties : les contenus passés traduits et les contenus futurs non traduits, qui sont modélisés par deux couches récurrentes supplémentaires. Les contenus passés et futurs sont transmis au modèle d'attention et aux états du décodeur, ce qui fournit aux systèmes de traduction automatique neuronale (NMT) la connaissance des contenus traduits et non traduits. Les résultats expérimentaux montrent que l'approche proposée améliore considérablement les performances dans les tâches de traduction chinois-anglais, allemand-anglais et anglais-allemand. Plus précisément, le modèle proposé surpasse le modèle de couverture classique en termes de qualité de traduction et de taux d'erreur d'alignement.</abstract_fr>
      <abstract_es>Los sistemas de traducción automática neuronal existentes no modelan explícitamente lo que se ha traducido y lo que no durante la fase de decodificación. Para abordar este problema, proponemos un mecanismo novedoso que separa la información fuente en dos partes: Contenidos pasados traducidos y Contenidos futuros no traducidos, que se modelan mediante dos capas recurrentes adicionales. Los contenidos Pasados y Futuros se alimentan tanto al modelo de atención como a los estados del decodificador, lo que proporciona a los sistemas de traducción automática neuronal (NMT) el conocimiento de los contenidos traducidos y no traducidos. Los resultados experimentales muestran que el enfoque propuesto mejora significativamente el rendimiento en las tareas de traducción chino-inglés, alemán-inglés e inglés-alemán. Específicamente, el modelo propuesto supera al modelo de cobertura convencional en términos de calidad de traducción y tasa de errores de alineación.</abstract_es>
      <abstract_ar>لا تقوم أنظمة الترجمة الآلية العصبية الحالية بنمذجة ما تم ترجمته وما لم يتم ترجمته خلال مرحلة فك التشفير. لمعالجة هذه المشكلة ، نقترح آلية جديدة تفصل معلومات المصدر إلى جزأين: المحتويات السابقة المترجمة والمحتويات المستقبلية غير المترجمة ، والتي تم تصميمها بواسطة طبقتين متكررتين إضافيتين. يتم تغذية محتويات الماضي والمستقبل لكل من نموذج الانتباه وحالات وحدة فك التشفير ، والتي تزود أنظمة الترجمة الآلية العصبية (NMT) بمعرفة المحتويات المترجمة وغير المترجمة. تظهر النتائج التجريبية أن النهج المقترح يحسن بشكل كبير الأداء في مهام الترجمة الصينية-الإنجليزية ، والألمانية-الإنجليزية ، والإنجليزية-الألمانية. على وجه التحديد ، يتفوق النموذج المقترح على نموذج التغطية التقليدي من حيث جودة الترجمة ومعدل خطأ المحاذاة.</abstract_ar>
      <abstract_pt>Os sistemas de tradução automática neural existentes não modelam explicitamente o que foi traduzido e o que não foi durante a fase de decodificação. Para resolver este problema, propomos um novo mecanismo que separa a informação fonte em duas partes: conteúdo passado traduzido e conteúdo futuro não traduzido, que são modelados por duas camadas recorrentes adicionais. Os conteúdos Passado e Futuro são alimentados tanto para o modelo de atenção quanto para os estados do decodificador, o que fornece aos sistemas de Tradução Automática Neural (NMT) o conhecimento dos conteúdos traduzidos e não traduzidos. Os resultados experimentais mostram que a abordagem proposta melhora significativamente o desempenho em tarefas de tradução chinês-inglês, alemão-inglês e inglês-alemão. Especificamente, o modelo proposto supera o modelo de cobertura convencional em termos de qualidade de tradução e taxa de erro de alinhamento.</abstract_pt>
      <abstract_zh>今神经机器翻译统不在解码显式已译与未译者建模。 分为二:译与未译,两额外循环层建模。 往者与来者,致意于解码器,这为神经机器翻译(NMT)统于译未译也。 实验结果表明,其法著汉英、德英、英德译之性。 其形在译质与齐错误率优于旧覆之。</abstract_zh>
      <abstract_ja>既存のニューラル機械翻訳システムは、デコード段階で翻訳されたものとされていないものを明示的にモデル化しない。この問題に対処するために、私たちはソース情報を2つの部分に分離する新規のメカニズムを提案します：翻訳された過去のコンテンツと未翻訳の未来のコンテンツは、2つの追加の反復レイヤーによってモデリングされます。過去と未来のコンテンツは、注意モデルとデコーダー状態の両方に供給され、ニューラル・マシン・トランスレーション（ NMT ）システムに翻訳されたコンテンツと未翻訳コンテンツの知識を提供します。実験結果は、提案されたアプローチが、中国語-英語、ドイツ語-英語、および英語-ドイツ語の翻訳タスクのパフォーマンスを大幅に改善することを示しています。具体的には、提案されたモデルは、翻訳品質とアライメントエラーレートの両方で従来のカバレッジモデルよりも優れています。</abstract_ja>
      <abstract_hi>मौजूदा तंत्रिका मशीन अनुवाद प्रणाली स्पष्ट रूप से मॉडल नहीं करती है कि डिकोडिंग चरण के दौरान क्या अनुवाद किया गया है और क्या नहीं किया गया है। इस समस्या को हल करने के लिए, हम एक उपन्यास तंत्र का प्रस्ताव करते हैं जो स्रोत जानकारी को दो भागों में विभाजित करता है: अनुवादित पिछली सामग्री और अअनुवादित भविष्य की सामग्री, जो दो अतिरिक्त आवर्तक परतों द्वारा मॉडलिंग की जाती है। अतीत और भविष्य की सामग्री को ध्यान मॉडल और विकोडक राज्यों दोनों को खिलाया जाता है, जो अनुवादित और अअनुवादित सामग्री के ज्ञान के साथ न्यूरल मशीन ट्रांसलेशन (एनएमटी) सिस्टम प्रदान करता है। प्रयोगात्मक परिणामों से पता चलता है कि प्रस्तावित दृष्टिकोण चीनी-अंग्रेजी, जर्मन-अंग्रेजी और अंग्रेजी-जर्मन अनुवाद कार्यों में प्रदर्शन में काफी सुधार करता है। विशेष रूप से, प्रस्तावित मॉडल अनुवाद गुणवत्ता और संरेखण त्रुटि दर दोनों के संदर्भ में पारंपरिक कवरेज मॉडल को मात देता है।</abstract_hi>
      <abstract_ru>Существующие системы нейронного машинного перевода явно не моделируют то, что было переведено, и то, что не было переведено на этапе декодирования. Для решения этой проблемы мы предлагаем новый механизм, который разделяет исходную информацию на две части: переведенное прошлое содержимое и непереведенное будущее содержимое, которые моделируются двумя дополнительными рекуррентными слоями. Содержимое «Прошлое» и «Будущее» подается как в модель внимания, так и в состояние декодера, что обеспечивает системы нейронного машинного перевода (НМП) знаниями переведенного и нетранслируемого содержимого. Экспериментальные результаты показывают, что предлагаемый подход значительно улучшает производительность в китайско-английских, немецко-английских и английско-немецких переводческих задачах. В частности, предлагаемая модель превосходит традиционную модель охвата как с точки зрения качества перевода, так и с точки зрения частоты ошибок при выравнивании.</abstract_ru>
      <abstract_ga>Ní mhúnlaíonn córais néar-aistritheora meaisín atá ann cheana an méid a aistríodh agus cad nach ndearnadh le linn na céime díchódaithe. Chun aghaidh a thabhairt ar an bhfadhb seo, molaimid meicníocht nua a scarann an fhaisnéis fhoinseach ina dhá chuid: inneachar a aistríodh san am atá caite agus inneachar neamhaistrithe ón Todhchaí, atá múnlaithe ag dhá shraith athfhillteacha breise. Cuirtear an t-ábhar san am atá caite agus sa todhchaí leis an tsamhail aire agus na stáit díchódaithe araon, a sholáthraíonn eolas ar inneachar aistrithe agus neamhaistrithe do chórais Neural Machine Translation (NMT). Léiríonn torthaí turgnamhacha go gcuireann an cur chuige atá beartaithe feabhas suntasach ar fheidhmíocht tascanna aistriúcháin Sínis-Béarla, Gearmáinis-Béarla, agus Béarla-Gearmáinis. Go sonrach, sáraíonn an tsamhail atá beartaithe an tsamhail chlúdaigh thraidisiúnta i dtéarmaí cháilíocht an aistriúcháin agus an ráta earráide ailínithe.</abstract_ga>
      <abstract_el>Τα υπάρχοντα νευρωνικά συστήματα μηχανικής μετάφρασης δεν μοντελοποιούν ρητά τι έχει μεταφραστεί και τι όχι κατά τη φάση αποκωδικοποίησης. Για να αντιμετωπιστεί αυτό το πρόβλημα, προτείνουμε έναν νέο μηχανισμό που διαχωρίζει τις πληροφορίες προέλευσης σε δύο μέρη: μεταφρασμένα παρελθόντα περιεχόμενα και μη μεταφρασμένα μελλοντικά περιεχόμενα, τα οποία μοντελοποιούνται από δύο επιπλέον επαναλαμβανόμενα στρώματα. Τα περιεχόμενα του παρελθόντος και του μέλλοντος τροφοδοτούνται τόσο στο μοντέλο προσοχής όσο και στις καταστάσεις αποκωδικοποιητή, το οποίο παρέχει στα συστήματα Νευρικής Μηχανικής Μετάφραση (NMT) τη γνώση μεταφρασμένων και μη μεταφρασμένων περιεχομένων. Τα πειραματικά αποτελέσματα δείχνουν ότι η προτεινόμενη προσέγγιση βελτιώνει σημαντικά την απόδοση σε κινεζικά-αγγλικά, γερμανικά-αγγλικά και αγγλικά-γερμανικά μεταφραστικά καθήκοντα. Συγκεκριμένα, το προτεινόμενο μοντέλο ξεπερνά το συμβατικό μοντέλο κάλυψης τόσο όσον αφορά την ποιότητα της μετάφρασης όσο και το ποσοστό σφαλμάτων ευθυγράμμισης.</abstract_el>
      <abstract_hu>A meglévő neurális gépi fordító rendszerek nem modellezik kifejezetten, hogy mit lefordítottak és mit nem a dekódolási fázisban. A probléma megoldása érdekében egy új mechanizmust javasolunk, amely a forrásinformációkat két részre osztja: fordított múlt tartalmak és le nem fordított jövő tartalmak, amelyeket két további visszatérő réteg modellez. A múlt és jövő tartalmát mind a figyelemmodell, mind a dekódoló állapotok táplálják, amelyek a Neural Machine Translation (NMT) rendszerek számára biztosítják a lefordított és le nem fordított tartalmak ismeretét. Kísérleti eredmények azt mutatják, hogy a javasolt megközelítés jelentősen javítja a kínai-angol, német-angol és angol-német fordítási feladatok teljesítményét. Konkrétan a javasolt modell mind a fordítási minőség, mind az igazítási hibaarány tekintetében felülmúlja a hagyományos lefedettségi modellt.</abstract_hu>
      <abstract_it>I sistemi di traduzione automatica neurale esistenti non modellano esplicitamente ciò che è stato tradotto e ciò che non è stato durante la fase di decodifica. Per affrontare questo problema, proponiamo un nuovo meccanismo che separa le informazioni di origine in due parti: contenuti passati tradotti e contenuti futuri non tradotti, che sono modellati da due strati ricorrenti aggiuntivi. I contenuti del passato e del futuro sono alimentati sia al modello di attenzione che agli stati del decoder, che fornisce ai sistemi Neural Machine Translation (NMT) la conoscenza dei contenuti tradotti e non tradotti. I risultati sperimentali mostrano che l'approccio proposto migliora significativamente le prestazioni nelle attività di traduzione cinese-inglese, tedesco-inglese e inglese-tedesco. In particolare, il modello proposto supera il modello di copertura convenzionale sia in termini di qualità di traduzione che di tasso di errore di allineamento.</abstract_it>
      <abstract_lt>Esamos nervinių mašinų vertimo sistemos nėra aiškiai modeliuojamos tai, kas buvo vertta ir kas nebuvo dekodiavimo etape. To address this problem, we propose a novel mechanism that separates the source information into two parts: translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers.  The Past and Future contents are fed to both the attention model and the decoder states, which provides Neural Machine Translation (NMT) systems with the knowledge of translated and untranslated contents.  Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English, and English-German translation tasks.  Konkrečiai siūlomas modelis atitinka įprastinį aprėpties model į tiek vertimo kokybės, tiek suderinimo klaidų lygio atžvilgiu.</abstract_lt>
      <abstract_mk>Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase.  За да го решиме овој проблем, предлагаме нов механизам кој ги разделува изворните информации во два дела: преведени содржини од минатото и непроведени содржини од иднината, кои се моделирани од два дополнителни повторни слоја. Содржината на минатото и иднината се храни и на моделот на внимание, и на состојбите на декодерот, кој ги обезбедува системите за преведување на невралните машини (НМТ) со знаење за преведени и непроведени содржини. Експерименталните резултати покажуваат дека предложениот пристап значително ја подобрува изведбата на кинеско-англиски, германски-англиски и англиско-германски преводни задачи. Специфично, предложениот модел го надминува конвенционалниот модел на покривање во поглед на квалитетот на преводот и стапката на грешки во прилагодувањето.</abstract_mk>
      <abstract_ka>არსებობს ნეიროლური მაქინის გადატვირთვა სისტემები არ გამოსახულებელად მოდელურია რაც გადატვირთვალია და რაც არ მოხდა დეკოდირების ფაზაში. ამ პრობლემას გადაწყვეტისთვის, ჩვენ მინდა პრობლემას პრობლემა მექანსი, რომელიც მხოლოდ ინფორმაციას ორი ნაწილში გაყოფილი: გადაწყვეტილი ინფორმაცია და გადაწყვეტილი მომავალე პირველი და მომავალე შემდგომარების შემდგომარების მოდგომარებისთვის და დეკოდერებისთვის შემდგომარებისთვის, რომელიც ნეიროლური მაქსინური განაცვლის (NMT) სისტემების შემ ექსპერიმენტიური წარმოდგენები აჩვენებენ, რომ პროგენტირებული პროგენტი ძალიან უფრო მეტად უფრო მეტადებს ჩინგლისურ, გერმანური-ანგლისური და განსაკუთრებულია, მოდელის შესაძლებელი მოდელის კონტრანციონალური შესახებ მოდელის შესახებ და შეცდომის შეცდომის სიმაღლე.</abstract_ka>
      <abstract_ml>നിലവിലുള്ള ന്യൂറല്‍ മെഷീന്‍ പരിഭാഷ സിസ്റ്റമുകള്‍ വ്യക്തമായി പരിഭാഷപ്പെടുത്തിയിട്ടുള്ളതും ഡെകോഡിങ്ങ് പ്രേസില To address this problem, we propose a novel mechanism that separates the source information into two parts: translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers.  പാസ്റ്റും ഭാവിയുടെയും ഉള്ളടക്കം മോഡലും ഡെകോഡേര്‍ രാജ്യങ്ങള്‍ക്കും ഭക്ഷണം നല്‍കുന്നു. അത് പരിഭാഷപ്പെടുത്തുന്നതും പരിശോധിക്കാത്ത ഉള്ളടക്കം അറി പരീക്ഷണ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു പ്രൊദ്ദേശിച്ച ചൈനീസ്-ഇംഗ്ലീഷ്, ജര്‍മ്മന്‍ ഇംഗ്ലീഷ്, ഇംഗ്ലീഷ്- ജര പ്രത്യേകിച്ച്, പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്‍ പരിഭാഷപൂര്‍ണ്ണമായ പരിഭാഷപൂര്‍ണ്ണമായ പിശകുകളുടെയും വ്യവസ്ഥയ്ക്കുള്</abstract_ml>
      <abstract_kk>Бар невралдық компьютердің аудармалы жүйелері оны аударылған және декодтау кезінде не үлгісін көрсетпейді. Бұл мәселеге шешу үшін көзінің мәліметін екі бөлігіне бөліп бөліп, жаңа механизмін ұсынып тастаймыз: алдыңғы мазмұны мен аударылмаған Болашақ мазмұнын аударып, ол екі қосымша Алдыңғы және Болашақ мазмұның мазмұнын аударылмаған және аударылмаған мазмұның білімі мен аударылмаған Neural Machine Translation (NMT) жүйелерін түсіндіру үлгісіне және декодердің күйіне қолданылады. Эксперименталдық нәтижелер ұсынылған тәсілі қытап-ағылшын, неміс-ағылшын және ағылшын-неміс аудармаларының тапсырмаларын өте жақсартады. Ескерту үлгісі, аудармалардың сапасы мен түзету қатенің жиілігіне қарай үлгісін жасайды.</abstract_kk>
      <abstract_mt>Is-sistemi eżistenti tat-traduzzjoni tal-magni newrali ma jimmudellawx espliċitament dak li ġie tradott u dak li ma kienx matul il-fażi tad-dekodifikazzjoni. Biex nindirizzaw din il-problem a, nipproponu mekkaniżmu ġdid li jissepara l-informazzjoni tas-sors f’żewġ partijiet: kontenut tradott tal-passat u kontenut futur mhux tradott, li huma mmudellati minn żewġ saffi rikorrenti addizzjonali. Il-kontenut tal-passat u tal-ġejjieni jingħata kemm lill-mudell ta’ attenzjoni kif ukoll lill-istati tad-dekoder, li jipprovdi lis-sistemi tat-Traduzzjoni tal-Magni Newrali (NMT) bl-għarfien ta’ kontenut tradott u mhux tradott. Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English, and English-German translation tasks.  B’mod speċifiku, il-mudell propost jaqbeż il-mudell ta’ kopertura konvenzjonali f’termini kemm tal-kwalità tat-traduzzjoni kif ukoll tar-rata ta’ żball ta’ allinjament.</abstract_mt>
      <abstract_pl>Istniejące neuronowe systemy tłumaczeń maszynowych nie modelują wyraźnie tego, co zostało przetłumaczone, a czego nie podczas fazy dekodowania. Aby rozwiązać ten problem, proponujemy nowy mechanizm dzielący informacje źródłowe na dwie części: przetłumaczone treści przeszłości i nieprzetłumaczone treści przyszłości, które są modelowane przez dwie dodatkowe powtarzające się warstwy. Treści przeszłości i przyszłości są dostarczane zarówno do modelu uwagi, jak i stanów dekodera, co zapewnia systemom neuronowego tłumaczenia maszynowego (NMT) wiedzę na temat przetłumaczonych i nieprzetłumaczonych treści. Wyniki eksperymentalne pokazują, że proponowane podejście znacząco poprawia wydajność w zadaniach tłumaczeniowych chińsko-angielsko, niemiecki-angielski oraz angielsko-niemiecki. W szczególności proponowany model przewyższa konwencjonalny model pokrycia zarówno pod względem jakości tłumaczenia, jak i wskaźnika błędów wyrównania.</abstract_pl>
      <abstract_mn>Ингээд оршиж буй мэдрэлийн машин орчуулах системүүд юу орчуулагдсан бөгөөд юу орчуулагдаагүйг тодорхой загварчлахгүй. Энэ асуудлыг олохын тулд бид эх үүсвэрийн мэдээллийг хоёр хэсэгт хуваалцах шинэ механизм санал өгдөг: Өмнөх contentment болон хуулдаагүй ирээдүйн бүтээгдэхүүнд орлогдсон, энэ нь хоёр дахин дахин дахин дахи Өнгөрсөн болон ирээдүйн тодорхойлолтууд нь анхаарлын загвар болон загвар зохион байгуулагч байдаг. Энэ нь сэтгэл зүйн машин хөгжүүлэх (NMT) системийг орчуулагдсан болон орчуулагүй тодорхойлолтуудын мэдлэг боло Үүний туршилтын үр дүнд санал өгсөн арга нь Хятад-Англи, Герман-Англи, Англи-Германы хөрөнгө оруулах үйл ажиллагааг үнэхээр сайжруулдаг. Тодорхой хэлбэл, санал өгсөн загвар нь ерөнхийлөгчийн мэдээллийн загварыг хөгжүүлдэг.</abstract_mn>
      <abstract_no>Det eksisterande neuralmaskineoversettelsystemet er ikkje eksplisisert modeller kva som er oversettet og kva som ikkje er under dekodingsfasen. For å setja opp dette problemet, fører vi eit nytt mekanisme som skiljer kjeldeinformasjonen til to deler: omsetjing av limt innhald og ikkje oversettet framtidig innhald, som er modelert av to tilgjengelege gjentakelige lag. Den tidlegare og framtidige innhaldet blir ført til både oppmerksmodellen og dekodertilstandane, som tilbyr Neuralmaskineomsetjingssystemet (NMT) med kunnskap om omsetjingssystemet og ikkje omsetjingssystemet. Eksperimentale resultat viser at den foreslåde tilnærminga betydelig forbedrar utviklinga i kinesisk-engelsk, tysk-engelsk og engelsk-tysk oversettelsesoppgåver. Det foreslåde modellen utfører den konvensjonale dekkemodellen ved høve til både omsetjingskvaliteten og feilfargen på justeringa.</abstract_no>
      <abstract_ms>Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase.  Untuk mengatasi masalah ini, kami cadangkan mekanisme baru yang memisahkan maklumat sumber ke dua bahagian: terjemahan kandungan masa lalu dan kandungan masa depan tidak terjemahan, yang dipodelkan oleh dua lapisan berkurang tambahan. Kandungan masa lalu dan masa depan diberi makan kepada kedua-dua model perhatian dan keadaan dekoder, yang menyediakan sistem Perjemahan Mesin Neural (NMT) dengan pengetahuan kandungan terjemahan dan tidak terjemahan. Hasil percubaan menunjukkan bahawa pendekatan yang diusulkan meningkatkan prestasi dalam tugas terjemahan bahasa Cina-Inggeris, Jerman-Inggeris, dan bahasa Inggeris-Jerman. Secara khusus, model yang diusulkan melampaui model penyamaran konvensional dalam terma kualiti terjemahan dan kadar ralat penyesuaian.</abstract_ms>
      <abstract_ro>Sistemele de traducere automată neurală existente nu modelează explicit ceea ce a fost tradus și ceea ce nu a fost în faza de decodare. Pentru a rezolva această problemă, propunem un mecanism nou care separă informațiile sursă în două părți: conținutul trecut tradus și conținutul viitor netranslat, care sunt modelate de două straturi recurente suplimentare. Conținutul trecut și viitor este alimentat atât modelului de atenție, cât și stărilor decodorului, care oferă sistemelor Neural Machine Translation (NMT) cunoștințele conținutului tradus și netranspirat. Rezultatele experimentale arată că abordarea propusă îmbunătățește semnificativ performanța în sarcinile de traducere chineză-engleză, germană-engleză și engleză-germană. Mai exact, modelul propus depășește modelul convențional de acoperire în ceea ce privește atât calitatea traducerii, cât și rata erorilor de aliniere.</abstract_ro>
      <abstract_si>තියෙන්නේ න්‍යුරෝල් මැෂින් වාර්ථාව පද්ධතිය ප්‍රශ්නයක් නොමොඩල් කරන්නේ නැහැ මොකක්ද වාර්ථාව කරල මේ ප්‍රශ්නය විසඳන්න, අපි ප්‍රශ්නයක් ප්‍රශ්නයක් ප්‍රශ්නයක් ප්‍රශ්නයක් තියෙන්නේ මුළු තොරතුරු දෙකට පෙරවන්න: පසුගිය ස පසුගිය සහ අනාගතයේ සාමාන්‍යත්වය අවධානය සහ ඩිකොඩර් ස්ථානය දෙන්න පුළුවන් වෙනවා, ඒකෙන් න්‍යුරල් මැෂින් අවවාදය (NMT) ප පරීක්ෂණාත්මක ප්‍රතිචාර ප්‍රතිචාර ප්‍රතිචාර විදිහට චීනි-ඉංග්‍රීසි, ජර්මාන්-ඉංග්‍රීසි සහ ඉ විශේෂයෙන්, ප්‍රතිචාරිත විශේෂය සහ ප්‍රතිචාර විශේෂය ගැන සාමාන්‍ය ආවරණය මදුල්ය ප්‍රතිචාර කරනවා.</abstract_si>
      <abstract_ta>Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase.  இந்த பிரச்சனையை முகவரிக்க, நாம் ஒரு புதிய முறைமையை மூலத்தின் தகவலை இரண்டு பகுதிகளாக பிரிக்கும் பொருட்டு பரிந்துரைக்கிறோம்: மொழிபெயர் மொழிபெயர்ப்பு மற்றும் எதிர்கால உள்ளடக்கங்கள் மாதிரி மற்றும் குறியீட்டு நாடுகளுக்கும் உணவளிக்கப்படுகிறது, அது மொழிபெயர்ப்பு மற்றும் மீறாத உள் பரிந்துரைக்கப்பட்ட முடிவுகள் சீனா- ஆங்கிலம், ஜெர்மன்- ஆங்கிலம், மற்றும் ஆங்கிலம்- ஜெர்மன் மொழிபெயர்ப்பு பணிகளில் செயல்ப குறிப்பிட்ட மாதிரி மொழிபெயர்ப்பு தரம் மற்றும் ஒழுங்குப்படுத்தல் பிழை விகிதத்திற்கும் பொருட்டு வழக்கமான மறைப</abstract_ta>
      <abstract_sv>Befintliga neurala maskin철vers채ttningssystem modellerar inte uttryckligen vad som har 철versatts och vad som inte har under avkodningsfasen. F철r att l철sa detta problem f철resl책r vi en ny mekanism som skiljer k채llinformationen i tv책 delar: 철versatt Tidigare inneh책ll och out철versatt Framtida inneh책ll, som modelleras av ytterligare tv책 책terkommande lager. Inneh책llet i det f철rflutna och framtiden matas till b책de uppm채rksamhetsmodellen och avkodningstillst책nden, vilket ger Neural Machine Translation (NMT) system kunskap om 철versatt och out철versatt inneh책ll. Experimentella resultat visar att det f철reslagna tillv채gag책ngss채ttet avsev채rt f철rb채ttrar prestandan i kinesisk-engelska, tysk-engelska och engelsk-tyska 철vers채ttningsuppgifter. Den f철reslagna modellen 철vertr채ffar den konventionella t채ckningsmodellen n채r det g채ller b책de 철vers채ttningskvalitet och justeringsfelfrekvensen.</abstract_sv>
      <abstract_so>Isticmaalka turjumista maskinada ee gudaha ah ma tijaabiyaan tusaale cad waxa lagu turjumay iyo wixii aan ku jirin fasaxa deynta. To address this problem, we propose a novel mechanism that separates the source information into two parts: translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers.  Waxyaabaha ku jirta dhamaadka iyo mustaqbalka waxaa loo cunaa tusaale-hoosaysiinta iyo wadamada deynta, kaas oo bixiya nidaamka turjumidda maskinada (NMT) oo aqoonta tarjuman iyo waxyaabaha aan la tarayn. Imtixaanka waxaa laga muujiyaa in qaababka la soo jeeday uu si weyn u hagaajiyo bandhigyada lagu sameeyo afka Shiino-Ingiriis, Jarmal-Ingiriis iyo shaqooyinka turjumaadda Ingiriis-Jarmal. Sida gaar ah modellka la soo jeeday wuxuu soo saaraa modelka daboolka caadiga ah oo ku qoran takhasuska turjumaadda iyo fasirka qaladka isbedelka.</abstract_so>
      <abstract_sr>Postojeći sistemi prevođenja neuralnih mašina ne modeluju jasno ono što je prevedeno i ono što nije bilo tokom faze dekodiranja. Za rješavanje ovog problem a predlažemo novi mehanizam koji razdvaja izvornu informaciju u dva dijela: preveden prošli sadržaj i nepromijenjen budući sadržaj, koji su modelirani dva dodatna ponovna sloja. Poslednji i budući sadržaj se hrani i pažnjom modelu i državama dekodera, koja pruža sisteme Neuralne mašine prevode (NMT) sa znanjem prevedenog i nepromijenjenog sadržaja. Eksperimentalni rezultati pokazuju da predloženi pristup značajno poboljšava izvedbu na kineskim-engleskim, nemačkim-engleskim i njemačkim prevodnim zadacima. Posebno, predloženi model iznosi konvencionalni model pokrivanja u smislu kvalitete prevoda i stope greške poravnanja.</abstract_sr>
      <abstract_ur>Existing neural machine translation systems do not explicitly model what has been translated and what has not been decoding phase. اس مسئلہ کے لئے ہم ایک نئی مکانیسم کی پیشنهاد کرتے ہیں جو سورج معلومات کو دو قسمتوں میں تقسیم کرتا ہے: اگلے معلومات اور غیر ترجمہ مسئلہ معلومات کو ترجمہ کرتا ہے، جو دو اضافہ دوبارہ ترجمہ لائر کے ذریعہ مکانیسم پچھلی اور آیندگی موجودات دونوں موجودات اور ڈیکوڈر کی موجودات کے لئے کھلائے جاتے ہیں، جنہوں نے نورال ماشین ترجمہ (NMT) سیستم کو ترجمہ اور غیر ترجمہ موجودات کے علم سے پہنچایا ہے. تجربہ نتائج دکھاتے ہیں کہ پیشنهاد کی تقریبا چین-انگلیسی، جرمن-انگلیسی اور انگلیسی-جرمن ترجمہ کے کاموں میں عملکرد اضافہ کرتی ہے. مخصوص طور پر، پیشنهاد کی موڈل ترجمہ کی کیفیت اور الیمینٹ کی خطا رات کے مطابق معمولی کاوٹ موڈل کو کامل کرتا ہے.</abstract_ur>
      <abstract_uz>Name @ info: whatsthis Name Tajriba natijalarini ko'rsatadi, talab qilingan muvaffaqiyatlar Xitoycha- Inglizcha, Olmon- Ingliz va Inglizcha tarjima vazifalarining vazifalarini muhimiy yaxshi ko'radi. Tafsilotni koʻrsatish</abstract_uz>
      <abstract_vi>Các hệ thống dịch chuyển máy não tồn tại không thể hiển thị mô tả những gì đã được dịch và những gì chưa được dịch trong giai đoạn giải mã. Để giải quyết vấn đề này, chúng tôi đề xuất một cơ chế mới phân cách thông tin nguồn thành hai phần: nội dung quá khứ dịch và nội dung tương lai không được đóng, được mô hình hóa bởi hai lớp khác thường xuyên. Nội dung quá khứ và tương lai được cung cấp cho cả mô hình chú ý và trạng thái giải mã, mà cung cấp cho hệ thống dịch Cỗ Máy thần kinh (NMB) với kiến thức về nội dung dịch và chưa được dịch. Các kết quả thử nghiệm cho thấy phương pháp đã đề nghị cải thiện đáng kể thành quả trong dịch vụ Anh-Anh-Quốc, Anh-Anh-Anh và Anh-Đức. Cụ thể, kiểu mẫu được đề xuất vượt trội theo kiểu bảo hiểm thông thường về chất lượng dịch và tỉ lệ lỗi thẳng hàng.</abstract_vi>
      <abstract_bg>Съществуващите невронни системи за машинен превод не моделират изрично какво е преведено и какво не е по време на фазата на декодиране. За да се справим с този проблем, предлагаме нов механизъм, който разделя източната информация на две части: преведено минало съдържание и непреведено бъдещо съдържание, които са моделирани от два допълнителни повтарящи се слоя. Съдържанието Минало и Бъдеще се подава както към модела на вниманието, така и към декодиращите състояния, които осигуряват на системите за неврален машинен превод (НМТ) познания за преведено и неплатено съдържание. Експерименталните резултати показват, че предложеният подход значително подобрява изпълнението на преводачески задачи по китайско-английски, немски-английски и английски-немски. По-конкретно, предложеният модел превъзхожда конвенционалния модел на покритие както по отношение на качеството на превода, така и по отношение на процента грешки при подравняване.</abstract_bg>
      <abstract_da>Eksisterende neurale maskinoversættelsessystemer modellerer ikke eksplicit, hvad der er oversat, og hvad der ikke har været i afkodningsfasen. For at løse dette problem foreslår vi en ny mekanisme, der adskiller kildeinformationen i to dele: Oversat Tidligere indhold og ikke-oversat Fremtidigt indhold, som er modelleret af yderligere to tilbagevendende lag. Tidligere og fremtidige indhold føres til både opmærksomhedsmodellen og dekodertilstandene, som giver Neural Machine Translation (NMT) systemer viden om oversat og ikke oversat indhold. Eksperimentelle resultater viser, at den foreslåede tilgang betydeligt forbedrer ydeevnen i kinesisk-engelsk, tysk-engelsk og engelsk-tysk oversættelsesopgaver. Specielt overgår den foreslåede model den konventionelle dækningsmodel med hensyn til både oversættelseskvalitet og justeringsfejlfrekvensen.</abstract_da>
      <abstract_hr>Postojeći sustavi prevoda neuroloških strojeva ne modeluju jasno ono što je prevedeno i ono što nije tijekom faze dekodiranja. Za rješavanje ovog problem a predlažemo novi mehanizam koji razdvaja izvornu informaciju u dva dijela: prevedeni prošli sadržaj i nepromijenjeni budući sadržaj, koji su modelirani dva dodatna ponovna slojeva. Posljednji i budući sadržaj se hrani i modelu pažnje i državama dekodera, koje pružaju sustave neurološkog prevoda stroja (NMT) sa znanjem prevedenog i nepromijenjenog sadržaja. Eksperimentalni rezultati pokazuju da predloženi pristup značajno poboljšava učinkovitost kineskog, njemačkog-engleskog i njemačkog prevođenja. Posebno, predloženi model iznosi konvencionalni model pokrivanja u smislu kvalitete prevoda i stope greške poravnanja.</abstract_hr>
      <abstract_nl>Bestaande neurale machinevertaalsystemen modelleren niet expliciet wat wel en niet is vertaald tijdens de decoderingsfase. Om dit probleem aan te pakken, stellen we een nieuw mechanisme voor dat de broninformatie scheidt in twee delen: vertaalde Past content en niet vertaalde Future content, die gemodelleerd worden door twee extra terugkerende lagen. De inhoud van het verleden en de toekomst wordt zowel naar het aandachtsmodel als naar de decoderstaten gevoerd, waardoor Neural Machine Translation (NMT)-systemen kennis krijgen van vertaalde en niet-vertaalde inhoud. Experimentele resultaten tonen aan dat de voorgestelde aanpak de prestaties in Chinees-Engels, Duits-Engels en Engels-Duits vertaaltaken aanzienlijk verbetert. Met name overtreft het voorgestelde model het conventionele dekkingsmodel wat betreft zowel de vertaalkwaliteit als het uitlijningsfoutenpercentage.</abstract_nl>
      <abstract_ko>기존의 신경 디코딩 시스템은 번역 단계에서 명확하게 번역된 것이 없다.이 문제를 해결하기 위해 우리는 새로운 메커니즘을 제시했다. 원본 정보를 두 부분으로 나눈다. 번역된 과거 내용과 번역되지 않은 미래 내용이다. 이 두 부분은 두 개의 추가 중복층으로 모델링된다.과거와 미래의 내용은 주의 모델과 디코더 상태로 피드백되어 신경기계번역(NMT) 시스템에 번역과 미번역 내용에 대한 지식을 제공한다.실험 결과, 이 방법은 한영, 덕영, 영덕 번역 임무의 성능을 현저히 향상시켰다.구체적으로 말하면 이 모델은 번역 품질과 정렬 오류율 면에서 전통적인 커버 모델보다 우수하다.</abstract_ko>
      <abstract_de>Bestehende neuronale maschinelle Übersetzungssysteme modellieren nicht explizit, was während der Dekodierungsphase übersetzt wurde und was nicht. Um dieses Problem anzugehen, schlagen wir einen neuartigen Mechanismus vor, der die Quellinformationen in zwei Teile unterteilt: übersetzte Past-Inhalte und nicht übersetzte Future-Inhalte, die durch zwei zusätzliche wiederkehrende Schichten modelliert werden. Die vergangenen und zukünftigen Inhalte werden sowohl dem Aufmerksamkeitsmodell als auch den Decoderzuständen zugeführt, was Neural Machine Translation (NMT)-Systemen das Wissen über übersetzte und nicht übersetzte Inhalte vermittelt. Experimentelle Ergebnisse zeigen, dass der vorgeschlagene Ansatz die Leistung in Chinesisch-Englisch, Deutsch-Englisch und Englisch-Deutsch Übersetzungsaufgaben signifikant verbessert. Konkret übertrifft das vorgeschlagene Modell das herkömmliche Deckungsmodell sowohl hinsichtlich der Übersetzungsqualität als auch der Ausrichtungsfehlerrate.</abstract_de>
      <abstract_id>Sistem terjemahan mesin saraf yang ada tidak secara eksplicit model apa yang telah terjemahan dan apa yang belum selama fase dekoding. Untuk mengatasi masalah ini, kami mengusulkan mekanisme baru yang memisahkan informasi sumber ke dua bagian: terjemahan isi masa lalu dan tidak terjemahan isi masa depan, yang dipodelkan oleh dua lapisan rekuren tambahan. Sisa masa lalu dan masa depan diberi makan kepada model perhatian dan negara dekoder, yang menyediakan sistem Translation Machine Neural (NMT) dengan pengetahuan tentang isi terjemahan dan tidak terjemahan. Hasil eksperimen menunjukkan bahwa pendekatan yang diusulkan meningkatkan prestasi dalam bahasa Cina-Inggris, Jerman-Inggris, dan tugas terjemahan bahasa Inggris-Jerman. Secara spesifik, model yang diusulkan melebihi model penyamaran konvensional dalam terma kualitas terjemahan dan tingkat kesalahan penyesuaian.</abstract_id>
      <abstract_fa>سیستم‌های ترجمه‌کننده‌ی ماشین عصبی وجود دارد، آنچه را ترجمه می‌شود و آنچه در حالی تغییر‌دهنده نیست، به طور کامل مدل نمی‌دهد. برای حل این مشکل، ما یک مکانیسم نوی پیشنهاد می‌کنیم که اطلاعات منبع را به دو قسمت جدا می‌کند: محتوای گذشته و محتوای آینده غیر قانونی، که توسط دو طبقه بازگشت اضافه می‌شوند. محتویات گذشته و آینده به مدل توجه و وضعیت‌های dekoder، که سیستم‌های ترجمه ماشین عصبی (NMT) را با دانش محتویات ترجمه و غیر ترجمه می‌دهد، تغذیه می‌کنند. نتیجه‌های تجربه نشان می‌دهد که این دستور پیشنهاد عملکرد را با توجه به کار ترجمه‌های چینی-انگلیسی، آلمانی-انگلیسی و انگلیسی-آلمانی بسیار بهتر می‌کند. مخصوصا، مدل پیشنهاد مدل پوشش معمولی را با توجه به کیفیت ترجمه و میزان خطای تنظیم انجام می دهد.</abstract_fa>
      <abstract_af>Bestaande neurale masjien vertaling stelsels doen nie uitduidelik model wat is vertaal en wat het nie gedurende die dekoding fase nie. Om hierdie probleem te adres, voorstel ons 'n nuwe mekanisme wat die bron inligting in twee dele skei: vertaal Plak inhoud en ongevertaalde Toekomstige inhoud, wat word modelleer deur twee addisionele herhaalde laag. Die Vorige en Toekomstige inhoud word verskaf tot beide die aandag model en die dekoder staatste, wat verskaf Neurale Masjien Vertaling (NMT) stelsels met die kennis van vertaling en ongevertaling inhoud. Eksperimentele resultate wys dat die voorgestelde toegang betekeurig verbeter die prestasie in Sinees-Engels, Duitse-Engels en Engels-Duitse vertalingstaak. Spesifieke, die voorgestelde model uitvoer die konvensionale dekking model in terms van beide die vertaling kwaliteit en die belyning fout tempo.</abstract_af>
      <abstract_am>የአሁኑ የነጥብ መሣሪያው ትርጉም ሲስተካከል የተመረጠው ምንድን ነው እና በdecoding ደረጃው ውስጥ ያልሆነ ሞዴል አይደለም። የዚህን ጉዳይ ለመቀበል፣ የኩነቶች መረጃዎችን ወደ ሁለት ክፍሎች ለመለየት የመረጃ መክፈቻን እና በተለየ ጥቅሎች እና የማይታወቀው የመጨረሻው ዕቃዎች እና በሁለት ተጨማሪ ደረጃዎች በመዘጋጀት መክፈት ነው፡፡ የባሕር እና የመጨረሻው ውይይት ተርጓሚዎች እና ያልተረጉም ውይይት በማወቅ የኔural Machine ትርጉም (NMT) ሲስተካከሉ ለጥያቄ ሞዴል እና ለድኮድ ሀገራት ነው፡፡ ፈተና ውጤቶች በቻይና-እንግሊዘኛ፣ የጀርመን-እንግሊዘኛ እና እንግሊዘኛ-ጀርመን ትርጉም የሚደረገውን ስርዓት በክፍል ያሳያል፡፡ በተጠቃሚ፣ በተዘጋጀው ሞዴል በተርጉም ጥሩ እና በመተካከል የስህተት ቁጥር በኩል የተሰናከረውን የክስል ሞዴል ያሳያል፡፡</abstract_am>
      <abstract_tr>Öň bar näyral maşynyň terjime sistemleri, terjime edilen we kodlemeýän sahypalary takykly nusgala etmeýär. Bu meseleyi çözmek üçin, çeşme maglumaty iki bölüne ayıran täze bir mehanizme teklip edip görýäris: terjime edip geçen maslahatlar we terjime etmeýän Geljek Mazmunlar bilen döredildi. Geçen we Geljek maglumaty üns Modeli we dekoder durumlaryna süýtgedýär. Bu Neural Makina Terjime (NMT) sistemleri terjime edilmedik we terjime edilmedik maglumaty bilen üýtgedýär. Araşdyrylyk netijeleri görkezilýän ýagdaýyň hyňlis, iňlisçe, iňlisçe we iňlisçe-nemesçe terjime eden zadlaryň täsirini gowurap biljegini görkeýär. Aýratyn üçin, teklip eden nusga düzgün ajaýyp nusgasyny terjime etmek howpsuzlykyny we çykyş hatasynyň häzirinde çykarýar.</abstract_tr>
      <abstract_sw>Mfumo wa utafsiri wa mashine ya kiserikali hauwezi kuonyesha wazi kile kinachotafsiriwa na kile ambacho hakikuwa wakati wa kiwango cha uchunguzi. Ili kukabiliana na tatizo hili, tunapendekeza mfumo wa riwaya unaofanya taarifa za vyanzo katika sehemu mbili: kutafsiriwa maudhui ya Past na maudhui ya mustakabali yasiyoeleweka, ambayo yanatengenezwa na vipande viwili vya ziada vya kurekebisha. Maudhui yaliyopita na baadae yanaruzukiwa kwa mifano ya kusikiliza na majimbo ya maboresho, ambayo yanatoa mifumo ya Tafsiri ya Mashine ya NMT (NMT) yenye ufahamu wa maudhui yanayotafsiriwa na yasiyoeleweka. Matokeo ya majaribio yanaonyesha kwamba mbinu hiyo ilipendekezwa kuboresha ufanisi wa kazi katika lugha ya Kichina-Kiingereza, Kijerumani-Kiingereza na Tafsiri ya Kiingereza. Kwa hakika, muundo unapendekezwa unaonyesha muundo wa habari wa kawaida kwa mukhtadha wa kiwango cha tafsiri na kiwango cha makosa ya upasuaji.</abstract_sw>
      <abstract_sq>Sistemet ekzistuese të përkthimit të makinave nervore nuk modelojnë shprehësisht atë që është përkthyer dhe atë që nuk ka gjatë fazës së dekodimit. Për të trajtuar këtë problem, ne propozojmë një mekanizëm të ri që ndan informacionin e burimit në dy pjesë: përmbajtjet e kaluara të përkthyera dhe përmbajtjet e ardhshme të paskthyera, të cilat janë modeluar nga dy shtresa shtesë të përsëritura. Përmbajtja e së kaluarës dhe e ardhmes ushqen si modelin e vëmendjes, ashtu edhe shtetet e dekodimit, i cili ofron sistemet e Translacionit të Makinës Neurale (NMT) me njohuri të përmbajtjeve të përkthyera dhe të paskthyera. Rezultatet eksperimentale tregojnë se qasja e propozuar përmirëson ndjeshëm paraqitjen në detyrat e përkthimit kinez-anglez, gjerman-anglez dhe anglez-gjerman. Veçanërisht, modeli i propozuar paraqet model in konvencional të mbulimit në lidhje me cilësinë e përkthimit dhe normën e gabimeve të përshtatjes.</abstract_sq>
      <abstract_bs>Postojeći sistemi prevoda neuronskih strojeva ne modeluju jasno ono što je prevedeno i ono što nije tokom faze dekodiranja. Za rješavanje ovog problem a predlažemo novi mehanizam koji razdvaja izvornu informaciju u dva dijela: preveden prošli sadržaj i nepromijenjen budući sadržaj, koji se modeliraju dva dodatna ponovna sloja. Posljednji i budući sadržaj se hrani i pažnjom modelu i državama dekodera, koja pruža sisteme Neuralne mašine prevode (NMT) sa znanjem prevedenog i nepromijenjenog sadržaja. Eksperimentalni rezultati pokazuju da predloženi pristup značajno poboljšava izvođenje na kineskim-engleskim, njemačkim-engleskim i njemačkim prevodnim zadacima. Posebno, predloženi model iznosi konvencionalni model pokrivanja u smislu kvalitete prevoda i stope greške poravnanja.</abstract_bs>
      <abstract_az>Əvvəlki nöral maşın tərcümə sistemləri tərcümə ediləni və dekoding fəsasında olmayan şeyləri açıq-aydın modellə etməz. Bu problemi çəkmək üçün mənbə məlumatını iki parçaya ayıran yeni mehanizmi təklif edirik: əvvəlki məlumatı və çevirilmədiyimiz Geləcək məlumatı çevirildi, ki bu məlumatı iki əlavə geri dönüşdürülər. Əvvəlki və gələcək məzmunları təkrar edilməmiş və təkrar edilməmiş məzmunların bilgi ilə nöral maşın təkrarlaması (NMT) sistemlərinə nəzarət edir. Həqiqətən, təcrübə etdiyi təcrübə metodlarının Çin-İngilizce, Alman-İngilizce və İngilizce-Alman çeviriş işlərində performansını çox yaxşılaşdırdığını göstərir. Özellikle, təbliğ edilmiş modellər təkrar qiyməti ilə təkrar qiyməti ilə təkrar xətasının hüquqlarına görə standart örtük modelini daha üstün edər.</abstract_az>
      <abstract_hy>Գոյություն ունեցող նյարդային մեքենայի թարգմանման համակարգերը բացատրականորեն չեն մոդելավորում այն, ինչ թարգմանվել է և ինչ դեկոդավորման ժամանակ չունի: Այս խնդիրը լուծելու համար մենք առաջարկում ենք նոր մեխանիզմ, որը բաժանում է աղբյուրների տեղեկատվությունը երկու մասի' թարգմանված Անցյալ պարունակությունը և անթարգմանված Ապագա պարունակությունը, որոնք մոդելավորված են երկու ավելին կրկնվող շերտերով Անցյալ և Ապագա պարունակությունը կերակրում է նաև ուշադրության մոդելը, նաև դեկոդերի վիճակները, որոնք տրամադրում են նյարդային մեքենայի թարգմանման (NMT) համակարգերը թարգմանված և անթարգմանված պարունակության գիտելիքներով: Փորձարկվող արդյունքները ցույց են տալիս, որ առաջարկված մոտեցումը նշանակալի բարելավում է չինական-անգլերեն, գերմաներեն-անգլերեն և անգլերեն-գերմաներեն թարգմանման խնդիրները: Հատկապես, առաջարկված մոդելը արտադրում է ավանդական ծածկումների մոդելը՝ ինչպես թարգմանման որակի, ինչպես նաև հարմարեցման սխալների արագության տեսքով:</abstract_hy>
      <abstract_bn>বিদ্যমান নিউরেল মেশিন অনুবাদ সিস্টেম স্পষ্টভাবে মডেল করে না যা অনুবাদ করা হয়েছে এবং ডিকোডিং মেসের সময় কি নেই। এই সমস্যাকে ঠিকানা করার জন্য আমরা একটি নোভেল মেনিস্টেম প্রস্তাব করি যা উৎসের তথ্য দুই অংশে বিভক্ত করে: অনুবাদ করা হয়েছে পাস্টের বিষয়বস্তু এবং অসমর্থ পাস্ট এবং ভবিষ্যতের বিষয়বস্তু উভয় মনোযোগ মডেল এবং ডেকোডার রাষ্ট্রের প্রতি খাওয়া যাচ্ছে, যা অনুবাদ এবং অসমর্থিত বিষয়বস্তুর জ্ঞানের সাথে নি পরীক্ষার ফলাফল দেখাচ্ছে যে প্রস্তাবিত পদক্ষেপ চীনা-ইংরেজী, জার্মান- ইংরেজি এবং ইংরেজী জার্মান-অনুবাদের কাজের ভাষ Specifically, the proposed model outperforms the conventional coverage model in terms of both the translation quality and the alignment error rate.</abstract_bn>
      <abstract_et>Olemasolevad neuromasintõlke süsteemid ei modelleeri selgesõnaliselt seda, mida on dekodeerimise faasis tõlgitud ja mida mitte. Selle probleemi lahendamiseks pakume välja uue mehhanismi, mis eraldab lähteinfo kaheks osaks: tõlgitud mineviku sisu ja tõlkimata tuleviku sisu, mida modelleerivad veel kaks korduvat kihti. Mineviku ja tuleviku sisu toimetatakse nii tähelepanu mudeli kui ka dekooderi olekusse, mis annab neuroaalse masintõlke (NMT) süsteemidele teadmisi tõlgitud ja tõlkimata sisust. Eksperimentaalsed tulemused näitavad, et kavandatud lähenemisviis parandab oluliselt hiina-inglise, saksa-inglise ja inglise-saksa tõlketööde tulemuslikkust. Täpsemalt ületab kavandatud mudel tavapärast katvusmudelit nii tõlkekvaliteedi kui ka vastavusvigade määra osas.</abstract_et>
      <abstract_cs>Stávající neuronové strojové překladové systémy explicitně nemodelují, co bylo přeloženo a co ne během fáze dekódování. Pro řešení tohoto problému navrhujeme nový mechanismus, který rozděluje zdrojové informace na dvě části: přeložený obsah minulosti a nepřeložený obsah budoucnosti, které jsou modelovány dvěma dalšími opakujícími se vrstvami. Obsah minulosti a budoucnosti je předáván jak do modelu pozornosti, tak do stavu dekodéru, který poskytuje systémům neuronového strojového překladu (NMT) znalosti přeloženého i nepřeloženého obsahu. Experimentální výsledky ukazují, že navržený přístup výrazně zlepšuje výkon v čínsko-anglických, německo-anglických a anglicko-německých překladatelských úlohách. Konkrétně navržený model překonává konvenční model pokrytí, pokud jde o kvalitu překladu a míru chyb zarovnání.</abstract_cs>
      <abstract_ca>Els sistemes de traducció neural existents no modelen explícitament el que s'ha traduit i el que no ha fet durant la fase de decodificació. Per abordar aquest problem a, proposem un mecanisme nou que separa la informació de fonts en dues parts: el contingut passat traduit i el contingut futur no traduit, modelats per dues capes recurrents adicionals. El contingut passat i futur es alimenta tant al model d'atenció com a l'estat de decodificació, que proporciona als sistemes de traducció neuronal de màquines (NMT) el coneixement de continguts traduits i no traduits. Els resultats experimentals mostren que l'enfocament proposat millora significativament el rendiment en tasques de traducció en xinès-anglès, alemany-anglès i anglès-alemany. Concretament, el model proposat supera el model de cobertura convencional en termes tant de qualitat de traducció com de taxa d'error d'allinjament.</abstract_ca>
      <abstract_fi>Nykyiset neurokonek채채nn철sj채rjestelm채t eiv채t nimenomaisesti mallinna sit채, mit채 on k채채nnetty ja mit채 ei ole dekoodausvaiheessa. T채m채n ongelman ratkaisemiseksi ehdotamme uutta mekanismia, joka erottaa l채hdetiedon kahteen osaan: k채채nnetty Mennyt sis채lt철 ja k채채nt채m채t철n Tulevaisuus sis채lt철, jotka mallinnetaan kahdella toistuvalla kerroksella. Menneisyys- ja tulevaisuustiedot sy철tet채채n sek채 huomiomalliin ett채 dekooderitilaan, joka antaa hermokonek채채nn철sj채rjestelm채lle (NMT) tietoa k채채nnetyist채 ja k채채nt채m채tt철mist채 sis채ll철ist채. Kokeelliset tulokset osoittavat, ett채 ehdotettu l채hestymistapa parantaa merkitt채v채sti suorituskyky채 kiina-englanti, saksa-englanti ja englanti-saksa k채채nn철steht채viss채. Ehdotettu malli suoriutuu perinteisest채 kattavuusmallista sek채 k채채nn철slaadun ett채 kohdistusvirheiden suhteen.</abstract_fi>
      <abstract_jv>Sayensi Jejaring Ndukung wektu karo Perintah sing bakal nggawe modèl nang dadi nggawe gerakan karo sistem sing ditambah karo perintah pakan karo ingkang dibutuhke tarjamahan (NMT). Rejelongno sing paling nggambar nganggep kuwi dianggap sing nyengkuyung bantuan kanggo nggambar tarjamahan kanggo anu barang basa Inggris-Inggris, Jamenes-Inggris lan lan tarjamahan Inggris. Laptop" and "Desktop</abstract_jv>
      <abstract_ha>@ info: whatsthis To, dõmin a yi amfani da wannan masu husũma, muna goyyade wani mekanin noveli wanda ke rarraba information daga sourcen zuwa biyu: an fassar kayan Past da wanda bai da ransa ba na Future, wanda za'a yi motsi da zanen sau biyu na sauri. An ba da kayan ƙunsa da wanda aka Past da Future zuwa duk motsi na muhalli da staten koda, wanda ke samar da tarjifani na Mataimakin Naural (NMT) da sancan da aka fassar da kuma ba da ransnawa. Matariyan jarrabai na nũna cewa, hanyarwa da aka buƙata, yana ƙari aikin fassarar aiki na China-Ingiriya, Jarman-Ingiriya, da kuma taƙaitãwa na Ingiriya. A ƙayyade, shirin da aka buɗe shi yana fitar da motel ɗin rufaffiyar da ɗabi'a cikin maɓallin fassarar da tsohon sararin mai daidaita.</abstract_ha>
      <abstract_he>Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase.  כדי להתמודד עם הבעיה הזאת, אנו מציעים מנגנון חדש שמפריד את המידע המקורי לשני חלקים: תוכן עבר תורגם ועתיד עתיד לא תורגם התוכן העבר והעתיד מאכיל גם למודל תשומת לב וגם למדינות המתקן, אשר מספק מערכות התרגום של מכונות נוירוליות (NMT) עם ידע של תוכן מתרגם ולא מתרגם. תוצאות ניסויים מראות שהגישה המוצעת משפר באופן משמעותי את ההופעה במשימות התרגום הסינית-אנגלית, גרמנית-אנגלית, ואנגלית-גרמנית. במיוחד, המודל המוצע מוביל את מודל הכיסוי הקונסיונציאלי בנוגע לאיכות התרגום וגם לקצב שגיאות ההתאמה.</abstract_he>
      <abstract_sk>Obstoječi sistemi nevronskega strojnega prevajanja ne modelirajo izrecno, kaj je bilo prevedeno in kaj ni bilo v fazi dekodiranja. Za reševanje tega problema predlagamo nov mehanizem, ki ločuje izvorne informacije na dva dela: prevedene vsebine preteklosti in neprevedene vsebine prihodnosti, ki sta modelirana z dvema dodatnima ponavljajočima se plastma. Vsebine preteklosti in prihodnosti se podajajo tako modelu pozornosti kot dekodirnim stanjem, ki sistemom nevralnega strojnega prevajanja (NMT) zagotavlja znanje prevedenih in neprevedenih vsebin. Eksperimentalni rezultati kažejo, da predlagani pristop bistveno izboljša učinkovitost prevajanja v kitajsko-angleščini, nemščini-angleščini in angleščini-nemščini. Natančneje, predlagani model presega običajni model pokritosti tako v smislu kakovosti prevajanja kot tudi stopnje napak pri poravnavi.</abstract_sk>
      <abstract_bo>Existing neural machine translation system does not explicitly Model what has been translated and what has not been during the decoding phase. To address this problem, we propose a new mechanism that separates the source information into two parts: translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers. སྔོན་སྒྲིག་དང་མ་འོངས Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English and English-German translation tasks. དམིགས་འཛུགས་ཀྱིས་བྱས་པར་དམིགས་འཛུགས་པའི་མ་དཔེ་གཟུགས་རིས་སྔོན་སྤྲོད་ཀྱི་དཔེ་དབྱིབས</abstract_bo>
      </paper>
    <paper id="12">
      <title>Mapping to Declarative Knowledge for Word Problem Solving</title>
      <author><first>Subhro</first><last>Roy</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <doi>10.1162/tacl_a_00012</doi>
      <abstract>Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding <a href="https://en.wikipedia.org/wiki/Finance">financial news</a>, <a href="https://en.wikipedia.org/wiki/Sports_journalism">sports results</a>, and <a href="https://en.wikipedia.org/wiki/Casualty_(person)">casualties of war</a>. Solving such problems requires the understanding of several mathematical concepts such as <a href="https://en.wikipedia.org/wiki/Dimensional_analysis">dimensional analysis</a>, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these <a href="https://en.wikipedia.org/wiki/Concept">concepts</a> to <a href="https://en.wikipedia.org/wiki/Expression_(mathematics)">math expressions</a>. We then present a <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for incorporating such <a href="https://en.wikipedia.org/wiki/Descriptive_knowledge">declarative knowledge</a> into word problem solving. Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression. This provides a way to handle multiple <a href="https://en.wikipedia.org/wiki/Concept">concepts</a> in the same problem while, at the same time, supporting interpretability of the answer expression. Our method models the mapping to declarative knowledge as a <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a>, thus removing the need for expensive annotations. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.</abstract>
      <pages>159–172</pages>
      <url hash="021b28ce">Q18-1012</url>
      <video href="https://vimeo.com/282338901" />
      <bibkey>roy-roth-2018-mapping</bibkey>
      <pwccode url="https://github.com/CogComp/arithmetic" additional="false">CogComp/arithmetic</pwccode>
    <title_ar>تعيين المعرفة التصريحية لحل مشكلة الكلمات</title_ar>
      <title_fr>Mappage avec la connaissance déclarative pour la résolution de problèmes Word</title_fr>
      <title_es>Mapeo al conocimiento declarativo para la resolución de problemas verbales</title_es>
      <title_pt>Mapeamento para conhecimento declarativo para solução de problemas do Word</title_pt>
      <title_ja>言葉の問題解決のための宣言的知識へのマッピング</title_ja>
      <title_hi>Word समस्या को हल करने के लिए घोषणात्मक ज्ञान के लिए मैपिंग</title_hi>
      <title_zh>映射到所以决单词声明性知</title_zh>
      <title_ru>Сопоставление декларативным знаниям для решения проблем со словом</title_ru>
      <title_ga>Mapáil go hEolas Dearbhaithe le haghaidh Réiteach Fadhbanna Focal</title_ga>
      <title_el>Χαρτογράφηση σε Δηλητική Γνώση για την επίλυση προβλημάτων λέξεων</title_el>
      <title_hu>A Word problémamegoldáshoz való hozzárendelés a deklaratív ismeretekhez</title_hu>
      <title_it>Mappatura alle conoscenze dichiarative per la risoluzione dei problemi di Word</title_it>
      <title_lt>Nurodymas į deklaracines žinias žodžių problemų sprendimui</title_lt>
      <title_ms>Mapping to Declarative Knowledge for Word Problem Solving</title_ms>
      <title_mk>Mapping to Declarative Knowledge for Word Problem Solving</title_mk>
      <title_ml>വാക്ക് പ്രശ്നം പരിഹരിക്കുന്നതിനുള്ള വിവരങ്ങളിലേക്ക് മാപ്പ് ചെയ്യുന്നു</title_ml>
      <title_mt>Ippjanar għal Għarfien Dikjarattiv għas-Soluzzjoni tal-Problemi tal-Kliem</title_mt>
      <title_ka>სიტყვების პრობლემების გადაწყვება</title_ka>
      <title_mn>Үүний асуудал шийдвэрлэхийн тулд тайлбарлалтын мэдлэг руу зураг зураг</title_mn>
      <title_pl>Mapowanie do wiedzy deklaracyjnej dla rozwiązywania problemów słowa</title_pl>
      <title_ro>Maparea la cunoștințe declarative pentru rezolvarea problemelor Word</title_ro>
      <title_no>Mapping til deklarativt kjenning for løysing av ordproblemet</title_no>
      <title_sr>Mapiranje na deklarativnu znanost za rešenje problema riječi</title_sr>
      <title_so>Raadiyada aqoonta caddeynta ee xafiiska dhibaatooyinka hadalka</title_so>
      <title_sv>Mappning till deklarativ kunskap för Word problemlösning</title_sv>
      <title_si>වචන ප්‍රශ්නයක් විසඳන්න ප්‍රශ්නයක් විස්තර කරන්න විස්තර දැනගන්න</title_si>
      <title_ta>வார்த்தை பிரச்சனை தீர்வு செய்வதற்கான விளக்கமான அறிவிப்புக்கு வரைப்படம்</title_ta>
      <title_kk>Сөздің мәселесін шешу үшін мәліметті белгілеу</title_kk>
      <title_ur>کلمات مشکل حل کے لئے مکانٹی علم کی جگہ</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Bản đồ kiến thức Tuyên bố về giải quyết vấn đề từ ngữ</title_vi>
      <title_hr>Mapiranje na deklarativnu znanost za rješavanje problema riječi</title_hr>
      <title_da>Tilknytning til erklærende viden til Word problemløsning</title_da>
      <title_bg>Картиране на декларативно знание за решаване на проблеми с думите</title_bg>
      <title_nl>Mapping naar declaratieve kennis voor het oplossen van woordproblemen</title_nl>
      <title_ko>단어 문제 해결에 사용되는 진술식 지식에 비추다</title_ko>
      <title_de>Mapping to Declarative Knowledge for Word Problem Solving</title_de>
      <title_id>Mempetakan ke Pengetahuan Deklaratif untuk penyelesaian masalah kata</title_id>
      <title_sw>Ramani kwa ufahamu wa Tamko kwa Tatizo la Word</title_sw>
      <title_fa>نقشه‌بندی به دانش اعلام برای حل مشکل کلمات</title_fa>
      <title_af>Kaart na Deklaratiewe kennis vir Woord Problem Oplos</title_af>
      <title_sq>hartimi në njohuri deklaruese për zgjidhjen e problemeve me fjalë</title_sq>
      <title_tr>Sözler çözmek üçin deklarative Bilim</title_tr>
      <title_am>አዲስ ዶሴ ፍጠር</title_am>
      <title_hy>Բառերի խնդիրների լուծման համար հայտարարական գիտելիքների քարտեզագրումը</title_hy>
      <title_az>S칬zl칲k problemini 칞톛km톛k 칲칞칲n Deklaratl캼 Bilm톛y톛 Mapping to Declarative Knowledge</title_az>
      <title_bn>Name</title_bn>
      <title_bs>Mapiranje na deklarativnu znanost za rješavanje problema riječi</title_bs>
      <title_ca>Mapar al coneixement declaratiu per resoldre problemes de paraules</title_ca>
      <title_et>Deklaratsiooniliste teadmiste kaardistamine sõnaprobleemide lahendamiseks</title_et>
      <title_cs>Mapování na deklarativní znalosti pro řešení problémů se slovy</title_cs>
      <title_fi>Kartoitus deklaratiiviseen tietoon sanaongelmien ratkaisemiseksi</title_fi>
      <title_jv>string" in "context_BAR_stringLink</title_jv>
      <title_he>המפה למידע הצהרתי לפתור בעיות מילים</title_he>
      <title_sk>Zemljevanje na deklarativno znanje za reševanje težav z besedami</title_sk>
      <title_ha>Mapping to Declarative Knowledge for Word Problem Solving</title_ha>
      <title_bo>ཡི་གེའི་དཀའ་ངལ་ཆོས་མཐུན་སྒྲིག་གཏོང་གི་ཤེས་ཚོགས་ལ་སྦྱར་བ</title_bo>
      <abstract_es>Los problemas verbales de matemáticas forman una abstracción natural de una serie de problemas de razonamiento cuantitativo, como la comprensión de las noticias financieras, los resultados deportivos y las bajas de la guerra. Resolver estos problemas requiere la comprensión de varios conceptos matemáticos, como el análisis dimensional, las relaciones de subconjuntos, etc. En este artículo, desarrollamos reglas declarativas que rigen la traducción de la descripción en lenguaje natural de estos conceptos a expresiones matemáticas. A continuación, presentamos un marco para incorporar ese conocimiento declarativo en la resolución de problemas verbales. Nuestro método aprende a mapear el texto del problema verbal aritmético con las expresiones matemáticas, aprendiendo a seleccionar el conocimiento declarativo relevante para cada operación de la expresión de la solución. Esto proporciona una forma de manejar varios conceptos en el mismo problema y, al mismo tiempo, apoya la interpretabilidad de la expresión de respuesta. Nuestro método modela la asignación al conocimiento declarativo como una variable latente, eliminando así la necesidad de anotaciones costosas. La evaluación experimental sugiere que nuestro solucionador basado en el conocimiento del dominio supera a todos los demás sistemas y que se generaliza mejor en el caso realista en el que los datos de entrenamiento a los que está expuesto están sesgados de manera diferente a los datos de prueba.</abstract_es>
      <abstract_ar>تشكل مسائل الكلمات الحسابية تجريدًا طبيعيًا لمجموعة من مشاكل التفكير الكمي ، مثل فهم الأخبار المالية ، والنتائج الرياضية ، وضحايا الحرب. يتطلب حل مثل هذه المشكلات فهم العديد من المفاهيم الرياضية مثل تحليل الأبعاد ، والعلاقات بين المجموعات الفرعية ، وما إلى ذلك. في هذه الورقة ، نقوم بتطوير القواعد التصريحية التي تحكم ترجمة وصف اللغة الطبيعية لهذه المفاهيم إلى التعبيرات الرياضية. ثم نقدم إطارًا لدمج هذه المعرفة التصريحية في حل مشكلة الكلمات. تتعلم طريقتنا تعيين نص مشكلة الكلمات الحسابية إلى التعبيرات الرياضية ، من خلال تعلم تحديد المعرفة التصريحية ذات الصلة لكل عملية من عمليات تعبير الحل. يوفر هذا طريقة للتعامل مع مفاهيم متعددة في نفس المشكلة مع دعم إمكانية تفسير تعبير الإجابة في نفس الوقت. تقوم طريقتنا بنمذجة التعيين إلى المعرفة التصريحية كمتغير كامن ، وبالتالي إزالة الحاجة إلى التعليقات التوضيحية باهظة الثمن. يشير التقييم التجريبي إلى أن الحلول القائمة على معرفة المجال لدينا تتفوق على جميع الأنظمة الأخرى ، وأنه يتم تعميمها بشكل أفضل في الحالة الواقعية حيث تكون بيانات التدريب التي تتعرض لها متحيزة بطريقة مختلفة عن بيانات الاختبار.</abstract_ar>
      <abstract_fr>Les problèmes de mots mathématiques constituent une abstraction naturelle d'une gamme de problèmes de raisonnement quantitatifs, tels que la compréhension de l'actualité financière, des résultats sportifs et des victimes de guerre. La résolution de tels problèmes nécessite la compréhension de plusieurs concepts mathématiques tels que l'analyse dimensionnelle, les relations entre sous-ensembles, etc. Dans cet article, nous développons des règles déclaratives qui régissent la traduction de la description en langage naturel de ces concepts en expressions mathématiques. Nous présentons ensuite un cadre pour intégrer ces connaissances déclaratives dans la résolution de problèmes de mots. Notre méthode apprend à mapper un texte de problème de mots arithmétiques avec des expressions mathématiques, en apprenant à sélectionner les connaissances déclaratives pertinentes pour chaque opération de l'expression de solution. Cela permet de gérer plusieurs concepts dans le même problème tout en favorisant l'interprétabilité de l'expression de réponse. Notre méthode modélise le mappage à la connaissance déclarative en tant que variable latente, éliminant ainsi le besoin d'annotations coûteuses. L'évaluation expérimentale suggère que notre solveur basé sur les connaissances du domaine surpasse tous les autres systèmes et qu'il généralise mieux dans le cas réaliste où les données d'entraînement auxquelles il est exposé sont biaisées d'une manière différente des données de test.</abstract_fr>
      <abstract_pt>Problemas de palavras matemáticas formam uma abstração natural para uma série de problemas de raciocínio quantitativo, como entender notícias financeiras, resultados esportivos e baixas de guerra. A resolução de tais problemas requer a compreensão de vários conceitos matemáticos, como análise dimensional, relacionamentos de subconjuntos, etc. Neste artigo, desenvolvemos regras declarativas que governam a tradução da descrição em linguagem natural desses conceitos para expressões matemáticas. Em seguida, apresentamos uma estrutura para incorporar esse conhecimento declarativo na resolução de problemas de palavras. Nosso método aprende a mapear o texto do problema da palavra aritmética para expressões matemáticas, aprendendo a selecionar o conhecimento declarativo relevante para cada operação da expressão da solução. Isso fornece uma maneira de lidar com vários conceitos no mesmo problema e, ao mesmo tempo, oferece suporte à interpretabilidade da expressão de resposta. Nosso método modela o mapeamento para conhecimento declarativo como uma variável latente, eliminando assim a necessidade de anotações caras. A avaliação experimental sugere que nosso solucionador baseado em conhecimento de domínio supera todos os outros sistemas e que generaliza melhor no caso realista em que os dados de treinamento aos quais é exposto são tendenciosos de maneira diferente dos dados de teste.</abstract_pt>
      <abstract_ja>数学の単語の問題は、財務ニュース、スポーツの結果、戦争の犠牲者の理解など、さまざまな定量的推論の問題への自然な抽象化を形成します。 このような問題を解決するには、次元解析、部分集合関係などのいくつかの数学的概念の理解が必要である。 本稿では，これらの概念の自然言語記述の数学的表現への翻訳を支配する宣言的規則を展開する． そして、このような宣言的知識を単語の問題解決に組み込むための枠組みを提示する。 算術の単語問題テキストを数式にマッピングする方法を学習し、解式の各演算に関連する宣言的知識を選択する方法を学習しています。 これは、回答式の解釈可能性をサポートしながら、同じ問題で複数の概念を扱う方法を提供します。 私たちの方法は、宣言的知識へのマッピングを潜在的な変数としてモデル化し、高価な注釈の必要性を排除します。 実験的評価では、当社のドメイン知識ベースのソルバーは他のすべてのシステムよりも優れており、暴露されるトレーニングデータがテストデータとは異なる方法で偏っている現実的なケースでは、より一般化することが示唆されています。</abstract_ja>
      <abstract_zh>数学单词者,列数自然抽象,如解财经新闻,体育比赛卒伤亡。 凡此数者,如维度析子集。 本文开声明性则,以治其概自然语言转为数学表达式。 然后发一框架,以陈性知识整合于单词。 吾道以学为解表达式每操择声明性知,学将算术单词文本映射于数学表达式。 此同一术也,兼赞答表达式之可解释性。 吾法将声明性知识之映建模为潜在变量,以消昂贵注释之需。 实验评估,本乎领域之求解器优于所有之统,而于其实,其所暴练数以异测试数据之偏倚,故其有善泛化。</abstract_zh>
      <abstract_hi>गणित शब्द की समस्याएं मात्रात्मक तर्क समस्याओं की एक श्रृंखला के लिए एक प्राकृतिक अमूर्तता बनाती हैं, जैसे कि वित्तीय समाचार, खेल परिणाम और युद्ध के हताहतों को समझना। ऐसी समस्याओं को हल करने के लिए कई गणितीय अवधारणाओं की समझ की आवश्यकता होती है जैसे कि आयामी विश्लेषण, सबसेट संबंध, आदि। इस पत्र में, हम घोषणात्मक नियम विकसित करते हैं जो गणित अभिव्यक्तियों के लिए इन अवधारणाओं के प्राकृतिक भाषा विवरण के अनुवाद को नियंत्रित करते हैं। फिर हम शब्द समस्या को हल करने में इस तरह के घोषणात्मक ज्ञान को शामिल करने के लिए एक रूपरेखा प्रस्तुत करते हैं। हमारी विधि अंकगणितीय शब्द समस्या पाठ को गणित अभिव्यक्तियों में मैप करना सीखती है, समाधान अभिव्यक्ति के प्रत्येक ऑपरेशन के लिए प्रासंगिक घोषणात्मक ज्ञान का चयन करना सीखकर। यह एक ही समस्या में कई अवधारणाओं को संभालने का एक तरीका प्रदान करता है, जबकि एक ही समय में, उत्तर अभिव्यक्ति की व्याख्या का समर्थन करता है। हमारी विधि एक अव्यक्त चर के रूप में घोषणात्मक ज्ञान के लिए मैपिंग को मॉडल करती है, इस प्रकार महंगे एनोटेशन की आवश्यकता को हटा देती है। प्रयोगात्मक मूल्यांकन से पता चलता है कि हमारा डोमेन ज्ञान आधारित सॉल्वर अन्य सभी प्रणालियों से बेहतर प्रदर्शन करता है, और यह यथार्थवादी मामले में बेहतर सामान्यीकरण करता है जहां प्रशिक्षण डेटा के संपर्क में आता है, परीक्षण डेटा की तुलना में एक अलग तरीके से पक्षपाती है।</abstract_hi>
      <abstract_ru>Проблемы с математическим словом образуют естественную абстракцию к целому ряду проблем количественного мышления, таких как понимание финансовых новостей, спортивных результатов и жертв войны. Решение таких задач требует понимания нескольких математических понятий, таких как размерный анализ, отношения подмножества и т.д. В этой статье мы разрабатываем декларативные правила, которые регулируют перевод описания естественного языка этих понятий на математические выражения. Затем мы представляем структуру для включения таких декларативных знаний в решение проблем слов. Наш метод учится отображать текст задачи арифметического слова в математические выражения, обучаясь выбирать соответствующие декларативные знания для каждой операции выражения решения. Это обеспечивает способ обработки нескольких концепций в одной и той же задаче, в то же время поддерживая интерпретируемость выражения ответа. Наш метод моделирует отображение декларативных знаний как скрытую переменную, тем самым устраняя необходимость дорогостоящих аннотаций. Экспериментальная оценка предполагает, что наш решебник, основанный на знаниях, превосходит все другие системы, и что он лучше обобщает в реалистичном случае, когда обучающие данные, которым он подвергается, смещены иным образом, чем тестовые данные.</abstract_ru>
      <abstract_ga>Is astarraingt nádúrtha iad fadhbanna focal matamaitice do raon fadhbanna réasúnaíochta cainníochtúla, amhail nuacht airgeadais, torthaí spóirt agus taismigh cogaidh a thuiscint. Chun fadhbanna den sórt sin a réiteach tá gá le tuiscint ar roinnt coincheap matamaitice cosúil le hanailís tríthoiseach, caidreamh fo-thacar, etc. Sa pháipéar seo, forbraímid rialacha dearbhaithe a rialaíonn aistriú cur síos teanga nádúrtha ar na coincheapa seo go habairtí matamaitice. Cuirimid creat i láthair ansin chun eolas dearbhaithe den sórt sin a ionchorprú i réiteach fadhbanna focal. Foghlaimíonn ár modh téacs faidhbe focal uimhríochtúil a mhapáil go nathanna matamaitice, trí fhoghlaim an t-eolas dearbhaithe ábhartha a roghnú do gach oibríocht den slonn réitigh. Soláthraíonn sé seo bealach chun ilchoincheapa a láimhseáil san fhadhb chéanna agus, ag an am céanna, tacaíonn sé le léirmhíniú an fhreagra a léiriú. Múnlaíonn ár modh an mhapáil go heolas dearbhaithe mar athróg fholaigh, rud a fhágann nach mbíonn gá le nótaí costasacha. Tugann meastóireacht thurgnamhach le fios go sáraíonn ár n-réiteoir eolasbhunaithe fearainn gach córas eile, agus go ndéanann sé ginearálú níos fearr i gcás réalaíoch ina bhfuil na sonraí oiliúna dá nochtar claonta ar bhealach difriúil ná na sonraí tástála.</abstract_ga>
      <abstract_el>Τα μαθηματικά προβλήματα λέξεων αποτελούν μια φυσική αφαίρεση σε μια σειρά από προβλήματα ποσοτικής συλλογιστικής, όπως η κατανόηση οικονομικών ειδήσεων, αθλητικών αποτελεσμάτων και θυμάτων πολέμου. Η επίλυση τέτοιων προβλημάτων απαιτεί την κατανόηση αρκετών μαθηματικών εννοιών, όπως η διαστατική ανάλυση, οι σχέσεις υποσύνολων κλπ. Σε αυτή την εργασία, αναπτύσσουμε δηλωτικούς κανόνες που διέπουν τη μετάφραση της περιγραφής της φυσικής γλώσσας αυτών των εννοιών σε μαθηματικές εκφράσεις. Στη συνέχεια, παρουσιάζουμε ένα πλαίσιο για την ενσωμάτωση τέτοιων δηλωτικών γνώσεων στην επίλυση προβλημάτων λέξεων. Η μέθοδος μας μαθαίνει να χαρτογραφεί αριθμητικό κείμενο προβλήματος λέξεων σε μαθηματικές εκφράσεις, μαθαίνοντας να επιλέγει τη σχετική δηλωτική γνώση για κάθε λειτουργία της έκφρασης λύσης. Αυτό παρέχει έναν τρόπο χειρισμού πολλαπλών εννοιών στο ίδιο πρόβλημα ενώ, ταυτόχρονα, υποστηρίζει την ερμηνεία της έκφρασης απάντησης. Η μέθοδος μας μοντελοποιεί τη χαρτογράφηση της δηλωτικής γνώσης ως λανθάνουσα μεταβλητή, αφαιρώντας έτσι την ανάγκη για ακριβές σχολιασμούς. Η πειραματική αξιολόγηση δείχνει ότι ο επιλυτής που βασίζεται στη γνώση του τομέα μας ξεπερνά όλα τα άλλα συστήματα, και ότι γενικεύει καλύτερα στην ρεαλιστική περίπτωση όπου τα δεδομένα κατάρτισης στα οποία εκτίθεται είναι προκατειλημμένα με διαφορετικό τρόπο από τα δεδομένα δοκιμής.</abstract_el>
      <abstract_hu>A matematikai szóproblémák természetes absztrakciót alkotnak számos kvantitatív érvelési problémához, mint például a pénzügyi hírek, a sport eredményei és a háborús áldozatok megértése. Az ilyen problémák megoldása számos matematikai fogalom megértését igényli, mint például dimenzióanalízis, részhalmaz kapcsolatok stb. Jelen tanulmányban olyan deklaratív szabályokat dolgozunk ki, amelyek szabályozzák ezen fogalmak természetes nyelvi leírásának matematikai kifejezésekre való fordítását. Ezután bemutatunk egy keretet az ilyen deklaratív ismeretek beépítésére a szóproblémamegoldásba. Módszerünk megtanulja a matematikai szóprobléma szövegét matematikai kifejezésekhez térképezni azáltal, hogy megtanulja kiválasztani a releváns deklaratív ismereteket a megoldási kifejezés minden műveletéhez. Ez lehetővé teszi ugyanabban a problémában több fogalom kezelését, ugyanakkor támogatja a válasz kifejezés értelmezhetőségét. Módszerünk látens változóként modellezi a leképezést deklaratív tudásra, így eltávolítva a drága megjegyzések szükségességét. A kísérleti értékelés azt sugallja, hogy a domain tudásalapú megoldónk minden más rendszert felülmúlja, és általánosítja jobban abban az esetben, amikor a képzési adatok, amelyeknek ki vannak téve, más módon elfogultak, mint a tesztadatok.</abstract_hu>
      <abstract_it>I problemi di parole matematiche formano una naturale astrazione di una serie di problemi di ragionamento quantitativo, come la comprensione di notizie finanziarie, risultati sportivi e perdite di guerra. Risolvere tali problemi richiede la comprensione di diversi concetti matematici come l'analisi dimensionale, le relazioni di sottoinsieme, ecc In questo articolo, sviluppiamo regole dichiarative che governano la traduzione della descrizione del linguaggio naturale di questi concetti in espressioni matematiche. Presentiamo quindi un quadro per incorporare tale conoscenza dichiarativa nella risoluzione dei problemi di parola. Il nostro metodo impara a mappare il testo del problema delle parole aritmetiche alle espressioni matematiche, imparando a selezionare le conoscenze dichiarative pertinenti per ogni operazione dell'espressione della soluzione. Questo fornisce un modo per gestire più concetti nello stesso problema, supportando, allo stesso tempo, l'interpretabilità dell'espressione di risposta. Il nostro metodo modella la mappatura alla conoscenza dichiarativa come variabile latente, eliminando così la necessità di annotazioni costose. La valutazione sperimentale suggerisce che il nostro solutore basato sulla conoscenza del dominio superi tutti gli altri sistemi e che generalizzi meglio nel caso realistico in cui i dati di allenamento a cui è esposto sono parziali in modo diverso dai dati di test.</abstract_it>
      <abstract_lt>Matematikos žodžių problemos yra natūrali daugelio kiekybinių motyvavimo problemų abstrakcija, pavyzdžiui, finansinių naujienų supratimas, sporto rezultatai ir karo aukos. Tokių problemų sprendimas reikalauja suprasti keletą matematinių sąvokų, pavyzdžiui, matmenų analizę, santykius su pogrupiais ir t. t. Šiame dokumente rengiame deklaracines taisykles, reglamentuojančias šių sąvokų natūralaus kalbos aprašymo vertimą į matematines išraiškas. Tada pristatysime tokių deklaracinių žinių įtraukimo į žodžių problem ų sprendimą sistemą. Mūsų metodas išmoko mapuoti aritmetinį žodžio problemos tekstą į matematines išraiškas, mokydamas pasirinkti atitinkamas deklaracines žinias kiekvienai sprendimo išraiškos operacijai. Tai yra būdas spręsti daugelį sąvokų toje pačioje problemoje, tuo pat metu remiant atsakymo išraiškos aiškinamumą. Mūsų metodas modeliuoja deklaracinių žinių žemėlapį kaip latentinį kintamąjį, taip pašalinant brangių anotacijų poreikį. Eksperimentinis vertinimas rodo, kad mūsų srities žiniomis pagrįstas tirpiklis yra veiksmingesnis už visas kitas sistemas ir kad jis geriau apibendrina realiu atveju, kai mokymo duomenys, kuriems jis veikiamas, yra kitokiu būdu nei bandymų duomenys.</abstract_lt>
      <abstract_mk>Проблемите со математичките зборови формираат природна апстракција на голем број квантитивни проблеми со размислување, како што се разбирањето на финансиските вести, спортските резултати и жртвите од војната. Решењето на ваквите проблеми бара разбирање на неколку математички концепти како што се димензионалната анализа, односите со подгрупите итн. Во овој весник, развиваме декларативни правила кои го регулираат преводот на природниот јазик опис на овие концепти на математички изрази. Потоа претставуваме рамка за вклучување на вакво декларативно знаење во решавањето на зборовите проблеми. Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression.  Ова обезбедува начин да се справат со повеќе концепти во истиот проблем, истовремено поддржувајќи ја интерпретабилноста на изразот на одговорот. Нашиот метод го моделира мапирањето на декларативното знаење како лајна променлива, отстранувајќи ја потребата за скапи анотации. Експерименталната проценка покажува дека нашиот резолувач базиран на знаење на доменот ги надминува сите други системи, и дека тој се генерализира подобро во реалниот случај каде податоците за обука на кои се изложени се предрасудени на различен начин од тестовите податоци.</abstract_mk>
      <abstract_ms>Masalah perkataan matematik membentuk abstraksi semulajadi kepada sejumlah masalah pemikiran kuantitatif, seperti memahami berita kewangan, hasil sukan, dan korban perang. Menyelesaikan masalah tersebut memerlukan pemahaman beberapa konsep matematik seperti analisis dimensi, hubungan subset, dll. Dalam kertas ini, kami mengembangkan peraturan pernyataan yang mengatur terjemahan keterangan bahasa alami konsep ini kepada ungkapan matematik. Kemudian kita memperkenalkan kerangka untuk memasukkan pengetahuan deklaratif seperti ini ke dalam penyelesaian masalah perkataan. Kaedah kami belajar untuk memetakan teks masalah perkataan aritmetik kepada ungkapan matematik, dengan belajar untuk memilih pengetahuan deklaratif yang relevan untuk setiap operasi ungkapan penyelesaian. Ini menyediakan cara untuk menangani konsep berbilang dalam masalah yang sama sementara, pada masa yang sama, menyokong interpretabiliti ungkapan jawapan. Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.  Evaluasi eksperimental menunjukkan bahawa penyelesair berdasarkan pengetahuan domain kita melebihi semua sistem lain, dan bahawa ia menyebarkan lebih baik dalam kes realistik di mana data latihan yang dikekspos adalah biased dengan cara yang berbeza daripada data ujian.</abstract_ms>
      <abstract_ml>കണക്ക് വാക്കുകളുടെ പ്രശ്നങ്ങള്‍ സ്വാഭാവികമായ പ്രശ്നങ്ങള്‍ക്ക് ഒരു പ്രധാനപ്പെട്ട പ്രശ്നങ്ങള്‍ ഉണ്ടാക്കുന്നു. സമാധാന വാര്‍ത് ഇതുപോലുള്ള പ്രശ്നങ്ങള്‍ പരിഹരിക്കുന്നതിന് ഒരുപാട് ഗണിത വിശദീകരണത്തിന്റെ ആശയങ്ങള്‍ക്ക് മനസ്സിലാക്കാന്‍ ആവശ്യമുണ്ട്. ഈ പത്രത്തില്‍ കണക്കിന്റെ വിശദീകരണ പിന്നീട് ഈ പ്രഖ്യാപനത്തിന്റെ അറിവ് വാക്കിന്റെ പ്രശ്നത്തിലേക്ക് ചേര്‍ക്കാന്‍ ഒരു ഫ്രെയിമെ നമ്മുടെ രീതി ഇത് ഒരേ പ്രശ്നത്തില്‍ പല ആശയങ്ങളും കൈകാര്യം ചെയ്യാന്‍ ഒരു വഴി തരുന്നു. അതോടൊപ്പം ഉത്തരം പ്രസ്താനത്തിന്റെ വ്യാഖ്യാന നമ്മുടെ രീതിയില്‍ പരിജ്ഞാനം പ്രഖ്യാപിക്കാനുള്ള മാതൃകയാണ് പ്രഖ്യാപിപ്പിക്കുന്നത്. അതുകൊണ്ട് വിലയേറിയ വ പരീക്ഷിക്കുന്ന പരിശീലനത്തില്‍ നമ്മുടെ ഡൊമെയിനിലെ അറിവ് അടിസ്ഥാനമാക്കുന്ന പരിശീലനം എല്ലാ സിസ്റ്റമുകളും പ്രവര്‍ത്തിപ്പിക്കുന്നു എന്ന് പറയുന്ന</abstract_ml>
      <abstract_ka>მათემატიკური სიტყვების პრობლემები იქნება ნაირადი აბსტრაქცია კონტაქტიური პარამენტიური პრობლემებისთვის, როგორც ფინანსური ნუზები, სპორტის შედეგი ასეთი პრობლემების გადაწყვება უნდა განსხვავება რამდენიმე მათემატიკური კონცემების, როგორც განსხვავებული ანალიზია, სესესეტები პრობლემები და განსაზღვრება. ამ დომებში ჩვენ განვითარებთ შემდეგ ჩვენ აჩვენებთ რამდენიმე განახლება სიტყვების პრობლემების გარეშე. ჩვენი მეთოდი მოსწავლის არიტემეტიული სიტყვის პრობლემების ტექსტის მათემატიკური გამოსახულებისთვის მარტიკური გამოსახულებისთვის, მასწავლის შესაძლებელი ევკლარატი ეს იგივე პრობლემაში მრავალ კონცექტის შესახებ, როგორც, ერთადერთი დროში, განსხვავებული გამოსახულების შესახებ. ჩვენი მეტი მოდელები მოდელების კაპრატირების ცნობილებისთვის განახლებელი ცნობილებისთვის, რადგან გამოყენება ძალიან ძალიან წარმოადგენების საჭიროა. ექსპერიმენტიური განსაზღვრება იგივეა, რომ ჩვენი დიომინური მეცნიერების გარეშე ყველა სხვა სისტემის გარეშე, და რომ ის უფრო უფრო მეტია რეალური შემთხვევაში, სადაც განსაზღვრებული მონაცემები, რომელი</abstract_ka>
      <abstract_mt>Il-problemi tal-kliem matematiku jiffurmaw astrazzjoni naturali għal firxa ta’ problemi kwantitattivi ta’ raġunament, bħall-fehim tal-a ħbarijiet finanzjarji, ir-riżultati sportivi, u l-vittmi tal-gwerra. Is-soluzzjoni ta’ problemi bħal dawn teħtieġ il-fehim ta’ diversi kunċetti matematiċi bħall-analiżi dimensjonali, ir-relazzjonijiet tas-sottosett, eċċ. F’dan id-dokument, qed niżviluppaw regoli dikjarattivi li jirregolaw it-traduzzjoni tad-deskrizzjoni tal-lingwa naturali ta’ dawn il-kunċetti għall-espressjonijiet matematiċi. Imbagħad nippreżentaw qafas għall-inkorporazzjoni ta’ tali għarfien dikjarattiv fis-soluzzjoni tal-kliem problemi. Il-metodu tagħna jitgħallem jimmappa t-test tal-problema tal-kelma aritmetika għall-espressjonijiet tal-matematika, billi jitgħallem jagħżel l-għarfien dikjarattiv rilevanti għal kull operazzjoni tal-espressjoni tas-soluzzjoni. Dan jipprovdi mod kif jiġu ttrattati kunċetti multipli fl-istess problem a filwaqt li, fl-istess ħin, tiġi appoġġjata l-interpretabbiltà tal-espressjoni tat-tweġiba. Il-metodu tagħna jimmudella l-immappjar għall-għarfien dikjarattiv bħala varjabbli moħbija, u b’hekk jitneħħa l-ħtieġa għal annotazzjonijiet għaljin. Evalwazzjoni sperimentali tissuġġerixxi li s-solver ibbażat fuq l-għarfien fid-dominju tagħna jaqbeż is-sistemi l-oħra kollha, u li jiġġeneralizza a ħjar fil-każ realistiku fejn id-dejta tat-taħriġ li hija esposta għaliha hija preġudikata b’mod differenti mid-dejta tat-test.</abstract_mt>
      <abstract_kk>Математикалық сөздер мәселелері табиғи абстракциялық көпшілікті сезім мәселелеріне, мысалы, қаржылық жаңалықтарды, спорт нәтижелерін түсіну және соғыс мәселелері Бұл мәселелерді шешу үшін бірнеше математикалық концепцияларды білмеу керек, мысалы өлшемі анализ, субөлік қатынастар, т.д. деп. Бұл қағазда, біз бұл концепцияларды математикалық өрнектерге түсінікт Содан кейін бұл мәліметті сөздердің мәселелерін шешуге ендіру үшін қолданып тастаймыз. Біздің әдіміміз арифметикалық сөздің мәселесін математикалық өрнектеріне картап, шешім өрнектерінің әрбір әрекетінің мәліметін таңдау үшін үйреніп береді. Бұл бір мәселеде бірнеше концепцияларды бірдей түсініктіру үшін бірнеше түсінікті береді, бірде жауап өрнегінің түсініктемесін қолдау үшін. Біздің әдіміміздің мәліметтерімізді келесі айнымалылық ретінде көрсету үшін картасын өзгерту үшін үлкен мәліметтердің қажеттігін өшіру үшін. Эксперименталды оқу үшін доменге негіздеген мәліметтердің шешіміз барлық жүйелерді жақсы жұмыс істейді, және ол тек шындық жағдайда жақсы жұмыс істейді, ол тексеру деректерінен басқа түрде тұрады.</abstract_kk>
      <abstract_mn>Математикийн үг асуудлууд нь байгалийн асуудлыг олон хэмжээний шалтгааны асуудлууд, санхүүгийн мэдээ, спортын үр дүнг ойлгох, дайны хохирогчид гэдэг. Ийм асуудлыг шийдвэрлэхэд хэмжээст шинжилгээ, доорх харилцаа, т.д. олон математикийн ойлголтыг ойлгох шаардлагатай. Дараа нь бид ийм илтгэл мэдлэгийг үг асуудлын шийдвэрлэлт оруулахын тулд нэг хэлбэрийг тайлбарлаж байна. Бидний арифметикийн асуудлын текст математикийн илэрхийлэл дээр газрын зураг зурж суралцаж, шийдвэрлэлийн илэрхийлэл бүрт харилцааны мэдлэг сонгохыг суралцаж байна. Энэ нь ижил асуудлын олон ойлголтыг хариултын илэрхийллийг дэмжих арга юм. Бидний арга загвар нь хамгийн сүүлийн өөрчлөлт гэх мэт мэдлэгийг илэрхийлж чаддаг газрын зураг загварын зураг юм. Иймээс үнэтэй мэдээллийн хэрэгцээ алга болгож байна. Эмчилгээний оюун шалгалт нь бидний мэдлэг дээр суурилсан шийдвэгч бусад системүүдийг илүү үр дүнтэй болгодог гэдгийг сануулдаг. Энэ нь шалгалтын мэдээллээс өөр өөр аргаар харагдаж байгаа дасгал өгөгдлийг бодит тохиолдолд илүү сайн байдаг.</abstract_mn>
      <abstract_pl>Problemy słów matematycznych stanowią naturalną abstrakcję do szeregu problemów rozumowania ilościowego, takich jak zrozumienie wiadomości finansowych, wyników sportowych i ofiar wojny. Rozwiązanie takich problemów wymaga zrozumienia kilku pojęć matematycznych, takich jak analiza wymiarowa, relacje podzbiorowe itp. W niniejszym artykule opracowujemy reguły deklaratywne regulujące tłumaczenie opisu języka naturalnego tych pojęć na wyrażenia matematyczne. Następnie przedstawiamy ramy włączania takiej deklaratywnej wiedzy do rozwiązywania problemów słowowych. Nasza metoda uczy się mapować arytmetyczny tekst problemu słowa do wyrażeń matematycznych, ucząc się dobierać odpowiednią wiedzę deklaratywną dla każdej operacji wyrażenia rozwiązania. Zapewnia to sposób obsługi wielu koncepcji w tym samym problemie, jednocześnie wspierając interpretację wyrażenia odpowiedzi. Nasza metoda modeluje mapowanie do wiedzy deklaratywnej jako zmiennej utajonej, eliminując tym samym konieczność stosowania kosztownych adnotacji. Ocena eksperymentalna sugeruje, że nasz rozwiązacz oparty na wiedzy domenowej przewyższa wszystkie inne systemy i że lepiej uogólnia się w realistycznym przypadku, gdy dane treningowe, na które jest narażone, są stronnicze w inny sposób niż dane testowe.</abstract_pl>
      <abstract_ro>Problemele cuvintelor matematice formează o abstracție naturală la o serie de probleme cantitative de raționament, cum ar fi înțelegerea știrilor financiare, rezultatele sportive și victimele războiului. Rezolvarea unor astfel de probleme necesită înțelegerea mai multor concepte matematice, cum ar fi analiza dimensională, relațiile de subset etc. În această lucrare, dezvoltăm reguli declarative care guvernează traducerea descrierii limbajului natural a acestor concepte în expresii matematice. Apoi prezentăm un cadru pentru încorporarea acestor cunoștințe declarative în rezolvarea problemelor cuvintelor. Metoda noastră învață să mapeze textul problemei cuvintelor aritmetice cu expresiile matematice, învățând să selecteze cunoștințele declarative relevante pentru fiecare operațiune a expresiei soluției. Aceasta oferă o modalitate de a gestiona mai multe concepte în aceeași problemă, susținând în același timp interpretabilitatea expresiei de răspuns. Metoda noastră modelează maparea la cunoștințele declarative ca variabilă latentă, eliminând astfel nevoia de adnotări costisitoare. Evaluarea experimentală sugerează că solutorul nostru bazat pe cunoștințe de domeniu depășește toate celelalte sisteme și că generalizează mai bine în cazul realist în care datele de formare la care este expus sunt părtinitoare într-un mod diferit de datele de testare.</abstract_ro>
      <abstract_si>ගණිත වචන ප්‍රශ්නයක් ප්‍රශ්නයක් ස්වභාවිතයෙන් ප්‍රශ්නයක් වෙන්නේ ප්‍රශ්නයක් ප්‍රශ්නයක් විතරයි ප්‍රශ්න ඒ වගේ ප්‍රශ්නයක් විසඳන්න අවශ්‍ය විශේෂ විශ්ලේෂණය, සම්බන්ධ සම්බන්ධය, ඉතින්. මේ පැත්තේ, අපි ප්‍රශ්නයක් නීතියක් විසින් විසින ඊට පස්සේ අපි වචන ප්‍රශ්නයක් විසඳන්න ප්‍රශ්නයක් වචන දැනගන්න ප්‍රශ්නයක් තියෙනවා. අපේ විධානය සිහින්නේ ගණිත වචන ප්‍රශ්නයක් ප්‍රශ්නයක් පිළිබඳට ගණිත ප්‍රශ්නයක් තියෙන්න, ප්‍රශ්නයක් ප්‍රශ මේක තරම් ප්‍රශ්නයක් තියෙන විදියට ප්‍රශ්නයක් තියෙන්නේ, එකම වෙලාවට, උත්තර ප්‍රශ්නයක් ගැන අභිවේදන අපේ පරීක්ෂණය මොඩේල්ස් කරනවා ප්‍රතිකෘති දන්නවන්න ප්‍රතිකෘති වෙනස් වෙනුවෙන්, ඉතින් ගොඩක් අවශ්‍යය සඳහ පරීක්ෂණාත්මක විශ්වාස කරන්න පුළුවන් අපේ ඩොමේන් දන්නවට අධික විස්තාරකය හැම පද්ධතියක්ම විස්තර කරන්න පුළුවන් කියලා, ඒක සාමාන්‍ය ව</abstract_si>
      <abstract_sv>Matematiska ordproblem utgör en naturlig abstraktion till en rad kvantitativa resonemangsproblem, såsom förståelse av finansiella nyheter, idrottsresultat och krigsoffer. För att lösa sådana problem krävs förståelsen av flera matematiska begrepp såsom dimensionell analys, delmängdsrelationer m.m. I denna uppsats utvecklar vi deklarativa regler som styr översättningen av naturspråksbeskrivningar av dessa begrepp till matematiska uttryck. Vi presenterar sedan en ram för att införliva sådan deklarativ kunskap i ordproblemlösning. Vår metod lär sig att kartlägga aritmetiska ord problemtext till matematiska uttryck, genom att lära sig att välja relevant deklarativ kunskap för varje operation av lösningsuttrycket. Detta ger ett sätt att hantera flera begrepp i samma problem samtidigt som det stöder tolkningen av svarsuttrycket. Vår metod modellerar kartläggningen till deklarativ kunskap som en latent variabel, vilket eliminerar behovet av dyra anteckningar. Experimentell utvärdering tyder på att vår domänkunskapsbaserade lösare presterar bättre än alla andra system, och att den generaliserar bättre i det realistiska fallet där träningsdata den utsätts för är partisk på ett annat sätt än testdata.</abstract_sv>
      <abstract_no>Mathematiske ordproblemer er eit naturleg abstraksjon til eit rekkje kvantitativ rasjonsbruk, slik som forståking av finansielle nyhetar, sportresultat og krig. Å løysa slike problemer krev forståking av fleire matematiske konseptar som dimensjonal analyse, undergrupper relasjon osv. I denne papiret utviklar vi deklarativ reglar som styrer omsetjinga av naturspråksbeskrivelsen av desse konseptane til matematiske uttrykk. Vi presenterer så eit rammeverk for å inkludere slike deklarativ kunnskap i ordproblemløysing. Metoden vårt lærer å kartera aritmetiske ordproblemtekst til matematiske uttrykk ved å lære å velja det relevante deklarativt kunnskap for kvar operasjon av løysingsstrykket. Dette gjev ein måte å handtera fleire konseptar i samme problemet mens, samtidig, støttar tolkingar av svaruttrykket. Metoden vårt modeller kartet til deklarasjon av kunnskap som ein latent variable, slik at du fjernar nødvendigheten for dykka merknader. Eksperimentelt evaluering foreslår at domenekunnskapen vårt basert løysar utfører alle andre systemer, og at det genereliserer bedre i det realistiske tilfellet der opplæringsdata som er eksponert til er forvirra på ein annan måte enn test data.</abstract_no>
      <abstract_ta>கணித பிரச்சினைகள் ஒரு இயற்கையான பிரச்சனைக்கான பிரச்சனைகள் மாறுகிறது, நிதி செய்திகள், விளையாட்டு முடிவுகள் மற்றும் போர் க இத்தகைய பிரச்சனைகளை தீர்வு செய்யும் பல கணித கருத்துக்களை புரிந்து கொள்ள வேண்டும், பரிமாற்றம், துணை உறவுகள் etc. இந்த த தாளில், நாம் அறிவிப்பு விதிகளை உருவா வார்த்தையின் பிரச்சனையை தீர்வு செய்ய ஒரு சட்டத்தில் சேர்க்க ஒரு அறிவிப்பு அறிவை சேர்க்க ஒரு  தீர்வு கூற்றின் ஒவ்வொரு செயல்பாட்டிற்கும் தொடர்பு அறிவிப்பு அறிவிப்பை தேர்ந்தெடுத்து கற்றுக் கொண்டு நமது முறைமை இது ஒரே பிரச்சனையில் பல கருத்துருவுகளை கையாளும் வழியைக் கொடுக்கிறது, ஆனால் அதே நேரத்தில் பதில் கூற்றின் மொழியின Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.  பரிசோதனையின் மதிப்பெண் நம் களம் அறிவு தீர்வு அடிப்படையில் உள்ள அனைத்து அமைப்புகளையும் வெளியேற்றுகிறது மற்றும் அது உண்மையில் சிறப்பாக்குகிறது இது</abstract_ta>
      <abstract_so>Dhibaatooyin ku saabsan hadalka xisaabta ah waxay leedahay dib u go'aanka dabiicadda ah oo dhibaatooyin badan oo sababo ah, tusaale ahaan garashada macluumaadka dhaqaalaha, resultinta jimicsiga iyo waxyeellada dagaalka. Saamaynta dhibaatooyinka caynkaas waxaa u baahan in loo garto fikrada xisaabta, tusaale ahaan baaritaanka kala duduwan, xiriirka hoose iyo sidoo kale. Qoraalkan waxaynu horumarinnaa sharciyada ogeysiiska, kaas oo maamula turjumidda luuqada dabiiciga ah sawirida fikradan ee xisaabta. Markaas waxaynu soo bandhignaynaa hoos u dhigno aqoonta warqada ah si aan u dhigno dhibaatada hadalka Midabkayagu wuxuu ku baranayaa in uu karo qoraal dhibaato ah oo ereyga arithmetic ah oo uu ku qoro xisaabta, marka lagu barto in lagu doorto aqoonta ogeysiiska ku saabsan ee ku saabsan qaab kasta oo uu ku sameeyo qaabixinta. Markaas waxaa laga helaa qaab aad u xambaarto fikrada kala duduwan isla markaasna la kaalmeeyo turjubaanka jawaabta. Midabkayaga ayaa sameynaya sawirada aqoonta lagu ogeysiiyaa sida mid beddelan ee ugu dambeeya, sidaa darteed waxaa dhaqaalaya baahida dhibaatooyin qaali ah. Qiimeynta baaritaanka waxaa loola jeedaa in aqoontayada domain ku saleysan uu ka muujiyo nidaamka kale oo dhan, iyo in ay ka fiican tahay xaalada runta ah, meesha macluumaadka waxbarashada looga soo bandhigayo si ka duwan macluumaadka imtixaanka.</abstract_so>
      <abstract_ur>ریاضی کلمات مشکلات ایک طبیعی غیرقابل غیرقابل غیرقابل مشکلات کی طرح بناتے ہیں، جیسے مالی خبریں سمجھتے ہیں، کھیل نتیجے اور جنگ کی ضرورت سمجھتے ہیں۔ یہ مشکلات حل کرنے کی ضرورت ہے کہ بہت سی ریاضی نظریں کا سمجھنا چاہے جیسے اندازے کی تحلیل، سوسٹ رابطہ، غیر اولاد. اس کاغذ میں ہم دکھانے کے قوانین کی تغییر کریں جو ان نظریں کی طبیعی زبان کی تعریف کی تعریف ریاضیات کی تعری اس کے بعد ہم ایک فرم بناتے ہیں کہ اس طرح کی واضح علم کو کلمات کے حل میں شامل کریں ہمارا طریقہ سیکھ رہا ہے کہ ریاضی کلمات مشکل کے متعلق متعلق متعلق متعلق متعلق متعلق ہو سکتا ہے، ریاضی مثالیں کے لئے، ہر حل کے مطابق معلوم علم کو انتخاب کرنے کے لئے سیکھ رہا ہے. یہ ایک ہی مسئلہ میں بہت سی مشورات کا تحمل کرنے کے لئے ایک طریقہ پیش کرتا ہے حالانکہ، ایک ہی موقع، جواب کی تعبیر کی تعبیر کی مدد کرتا ہے۔ ہماری طریقہ مدل مکالمپینگ کو لاٹینٹ ویرئیٹ کے طور پر دکھانے کے لئے مکالمپینگ بنا رہا ہے، اس طرح بہت اچھے مکالمانوں کی ضرورت کو ہٹا رہا ہے. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the real case where the training data it is exposed to is biased in a different way than the test data.</abstract_ur>
      <abstract_sr>Problemi sa matematičkim riječima formiraju prirodnu apstrakciju do niza kvantitativnih problema razuma, poput razumevanja finansijskih vijesti, sportskih rezultata i žrtava rata. Rešavanje takvih problema zahteva razumevanje nekoliko matematičkih koncepta poput dimenzionalne analize, podzemne odnose itd. U ovom papiru razvijamo deklarativne pravila koje upravljaju prevodom prirodnog jezika opisa tih koncepta na izraze matematike. Onda predstavljamo okvir za uključenje takvih deklarativnih znanja u rešenje rešenja riječi. Naša metoda nauèi da mapiramo tekst problema sa aritmetskim rijeèima na izraze matematike, nauèimo da odaberemo relevantne deklarativne znanje za svaku operaciju rešenja. To pruža način za rješavanje višestrukih koncepta u istom problemu dok, u isto vreme, podržava interpretabilnost izraza odgovora. Naša metoda modeli mapiranje za deklarativno znanje kao latentna varijabla, tako uklanjajući potrebu za skupim annotacijom. Eksperimentalna procjena ukazuje na to da naš rezolver na temelju znanja na domenu nadmašuje sve ostale sisteme, i da generalizuje bolje u reālističkom slučaju u kojem podaci o obuci na koji je izložen izloženom su predrasudeni na drugačiji naèin nego test podaci.</abstract_sr>
      <abstract_uz>Math so'zlar muammolari o'zgarishga ega bo'ladi, huddi financial news, sport natijalarini va dagaal qobiliyatlarini tushunishga ega bo'lgan muammolar. Bu muammolarni qidirish uchun bir necha matematika g'oyalarini o'rganish kerak. Bu takarda biz o'z fikrlarni matematika hisobotiga tarjima qilishini boshqarishimiz mumkin. Keyin biz bu hodisa ma'lumotni so'zlar muammolasiga qo'yish uchun freymni yaratdik. Bizning usuli arifmetik soʻzning muammolari matnni matematik imkoniyatlariga o'rganadi, o'rganish imkoniyatining har bir amalning har bir amalni o'rganish uchun muhim hujjatni tanlashni o'rganadi. Bu bir muammoga bir nechta g'oyalarni boshqarish usuli yordam beradi, shu paytda, javob ifodalarning tafsirini qoʻllash imkoniyatini qoʻllash mumkin. Maʼlumotni yangi oʻzgaruvchi deb hisoblash usuli modellarimiz, shunday qilib qiymati tajribalarni olib tashlash kerakligini olib tashlash. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.</abstract_uz>
      <abstract_vi>Vấn đề về to án học tạo ra sự phân chia tự nhiên với các vấn đề lập luận về số lượng, như hiểu được tin tài chính, kết quả thể thao và thương vong chiến tranh. Giải quyết vấn đề này yêu cầu phải hiểu nhiều khái niệm to án học như phân tích đa chiều, các mối quan hệ ngầm, v.v. trong tờ giấy này, chúng tôi phát triển các quy tắc tuyên bố về việc dịch thuật ngữ tự nhiên mô tả các khái niệm này thành dạng toán. Chúng tôi đưa ra một cơ sở để đưa những kiến thức tuyên bố này vào giải quyết vấn đề từ. Phương pháp của chúng tôi học cách vạch bản đồ các chữ vấn đề theo dạng to án, bằng cách học cách chọn các kiến thức tuyên bố liên quan cho mỗi thao tác biểu thức giải pháp. Đây là cách để xử lý nhiều khái niệm trong cùng một vấn đề, đồng thời hỗ trợ sự hiểu biết của câu trả lời. Theo phương pháp của chúng tôi, việc lập bản đồ cho các kiến thức tuyên bố là một biến số tiềm ẩn, loại bỏ nhu cầu ghi chú đắt tiền. Phân tích thử nghiệm cho thấy khả năng phá hủy tài liệu miền của chúng ta hoàn thiện tất cả các hệ thống khác, và nó phổ biến tốt hơn trong trường hợp thực tế nơi dữ liệu huấn luyện mà nó bị phơi bày theo một cách khác với các dữ liệu thử nghiệm.</abstract_vi>
      <abstract_bg>Проблемите с математическите думи формират естествена абстракция на редица количествени разсъждения, като разбиране на финансови новини, спортни резултати и жертви от войната. Решаването на такива проблеми изисква разбиране на няколко математически понятия като анализ на измеренията, взаимоотношенията на подмножество и др. В настоящата статия разработваме декларативни правила, които управляват превода на описанието на естествения език на тези понятия към математически изрази. След това представяме рамка за включване на такива декларативни знания в решаването на словни проблеми. Нашият метод се научава да картографира аритметичен текст на проблемен текст към математически изрази, като се научи да избира съответните декларативни знания за всяка операция на израза на решението. Това осигурява начин за справяне с множество понятия в един и същ проблем, като същевременно поддържа интерпретацията на израза на отговора. Нашият метод моделира картографирането до декларативно знание като латентна променлива, като по този начин премахва необходимостта от скъпи анотации. Експерименталната оценка предполага, че нашият домейн базиран на знания решаващ е по-добър от всички други системи и че обобщава по-добре в реалистичен случай, когато данните за обучение, на които е изложен, са предубедени по различен начин от данните от тестовете.</abstract_bg>
      <abstract_da>Matematiske ordproblemer danner en naturlig abstraktion til en række kvantitative ræsonnementsproblemer, såsom forståelse af finansielle nyheder, sportsresultater og krigstab. Løsning af sådanne problemer kræver forståelse af flere matematiske begreber såsom dimensionel analyse, delmængdeforhold osv. I denne artikel udvikler vi deklarative regler, der styrer oversættelsen af natursprog beskrivelse af disse begreber til matematiske udtryk. Vi præsenterer derefter en ramme for at indarbejde sådan deklarativ viden i ordproblemløsning. Vores metode lærer at kortlægge aritmetisk ordproblemtekst til matematiske udtryk, ved at lære at vælge den relevante deklarative viden for hver operation af løsningsudtrykket. Dette giver mulighed for at håndtere flere begreber i samme problem, samtidig med at det understøtter fortolkningen af svarudtrykket. Vores metode modellerer kortlægningen til deklarativ viden som en latent variabel, hvilket fjerner behovet for dyre noteringer. Eksperimentel evaluering tyder på, at vores domænevidensbaserede løser overgår alle andre systemer, og at den generaliserer bedre i det realistiske tilfælde, hvor de træningsdata, den udsættes for, er partisk på en anden måde end testdataene.</abstract_da>
      <abstract_hr>Problemi s matematičkim riječima čine prirodnu apstrakciju do niza kvantitativnih problema razuma, poput razumijevanja financijskih vijesti, sportskih rezultata i žrtava rata. Rešavanje takvih problema zahtijeva razumijevanje nekoliko matematičkih koncepta poput dimenzionalne analize, podzemne odnose itd. U ovom papiru razvijamo deklarativne pravila koje upravljaju prevodom prirodnog jezika opisa tih koncepta na izraze matematike. Onda predstavljamo okvir za uključenje takvih deklarativnih znanja u rješavanje riječi. Naš metod nauči mapirati tekst problema s aritmetičkim riječima na izraze matematike, učeći odabrati relevantne deklarativne znanje za svaku operaciju rješenja. To pruža način za rješavanje višestrukih koncepta u istom problemu dok, u isto vrijeme, podržava interpretabilnost izraza odgovora. Naše metode modele mapiranja deklarativnim znanjima kao latentna varijabla, tako uklanjajući potrebu skupih annotacija. Eksperimentalna procjena ukazuje na to da naš rješavač na temelju znanja na domenu nadmašuje sve ostale sustave i da se generalizira bolje u realističkom slučaju gdje su podaci o obuci na koji je izložen izloženom je pristrasno na drugačiji način nego podaci o testiranju.</abstract_hr>
      <abstract_nl>Wiskundige woordproblemen vormen een natuurlijke abstractie van een reeks kwantitatieve redeneringsproblemen, zoals het begrijpen van financieel nieuws, sportresultaten en oorlogsslachtoffers. Het oplossen van dergelijke problemen vereist het begrijpen van verschillende wiskundige concepten zoals dimensionale analyse, subset relaties, enz. In dit artikel ontwikkelen we declaratieve regels die de vertaling van natuurlijke taalbeschrijving van deze concepten naar wiskundige uitdrukkingen regelen. Vervolgens presenteren we een raamwerk voor het integreren van dergelijke declaratieve kennis in het oplossen van woordproblemen. Onze methode leert rekenkundige woordprobleemtekst in kaart te brengen aan wiskundige uitdrukkingen, door te leren de relevante declaratieve kennis voor elke bewerking van de oplossingsuitdrukking te selecteren. Dit biedt een manier om meerdere concepten in hetzelfde probleem aan te pakken en tegelijkertijd de interpreteerbaarheid van de antwoordexpressie te ondersteunen. Onze methode modelleert de toewijzing naar declaratieve kennis als een latente variabele, waardoor dure annotaties overbodig zijn. Experimentele evaluatie suggereert dat onze domeinkennis gebaseerde solver beter presteert dan alle andere systemen, en dat hij beter generaliseert in het realistische geval waarin de trainingsgegevens waaraan hij wordt blootgesteld op een andere manier bevooroordeeld zijn dan de testgegevens.</abstract_nl>
      <abstract_de>Mathe Wortprobleme bilden eine natürliche Abstraktion zu einer Reihe quantitativer Argumentationsprobleme, wie das Verstehen von Finanznachrichten, Sportergebnissen und Kriegsopfern. Die Lösung solcher Probleme erfordert das Verständnis mehrerer mathematischer Konzepte wie Dimensionsanalyse, Teilmengenbeziehungen usw. In diesem Beitrag entwickeln wir deklarative Regeln, die die Übersetzung natürlicher sprachlicher Beschreibung dieser Konzepte in mathematische Ausdrücke regeln. Anschließend stellen wir einen Rahmen für die Einbeziehung dieses deklarativen Wissens in die Wortproblemlösung vor. Unsere Methode lernt, arithmetische Wortproblemtexte mathematischen Ausdrücken zuzuordnen, indem sie lernt, das relevante deklarative Wissen für jede Operation des Lösungsausdrucks auszuwählen. Dies bietet eine Möglichkeit, mehrere Konzepte in einem Problem zu behandeln und gleichzeitig die Interpretierbarkeit des Antwortausdrucks zu unterstützen. Unsere Methode modelliert die Zuordnung zu deklarativem Wissen als latente Variable, wodurch teure Annotationen überflüssig werden. Die experimentelle Auswertung deutet darauf hin, dass unser Domänenwissen-basierter Solver alle anderen Systeme übertrifft und dass er besser generalisiert wird, wenn die Trainingsdaten, denen er ausgesetzt ist, auf eine andere Weise verzerrt sind als die Testdaten.</abstract_de>
      <abstract_id>Masalah kata matematika membentuk abstraksi alami untuk sejumlah masalah alasan kuantitatif, seperti memahami berita keuangan, hasil olahraga, dan korban perang. Menyelesaikan masalah tersebut membutuhkan pemahaman beberapa konsep matematika seperti analisis dimensi, hubungan subset, dll. Dalam kertas ini, kami mengembangkan aturan deklaratif yang mengatur terjemahan dari deskripsi bahasa alami dari konsep ini ke ekspresi matematika. Kemudian kita mempersembahkan rangkaian untuk memasukkan pengetahuan deklaratif seperti ini ke dalam penyelesaian masalah kata. Metode kami belajar untuk memetakan teks masalah kata aritmetik ke ekspresi matematika, dengan belajar untuk memilih pengetahuan deklaratif relevan untuk setiap operasi ekspresi solusi. Ini menyediakan cara untuk menangani beberapa konsep dalam masalah yang sama sementara, pada saat yang sama, mendukung interpretabilitas ekspresi jawaban. Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.  Evaluasi eksperimental menunjukkan bahwa penyelesair berbasis pengetahuan domain kita melebihi semua sistem lain, dan bahwa itu menyebar lebih baik dalam kasus realistis di mana data latihan yang dikekspos adalah bias dengan cara yang berbeda dari data tes.</abstract_id>
      <abstract_fa>مشکلات کلمه ریاضی یک اخراج طبیعی برای مشکلات منطقی، مثل فهمیدن اخبار مالی، نتیجه ورزشی و تلفات جنگ است. حل این مشکلات نیاز به فهمیدن چند نظریه ریاضی مانند تحلیل بعدی، رابطه‌های زیر بعدی و غیر از آن است. در این کاغذ، ما قوانین اعلام‌کننده را توسعه می‌کنیم که توسعه‌ی توسعه زبان طبیعی این نظریه‌ها را به تعریف ریاضی حکو سپس ما یک چهارچوب برای درآوردن این دانش آگاهی به حل مشکل کلمات پیشنهاد می کنیم. روش ما یاد می‌گیرد که متن مشکل کلمه‌های ریاضی را به نمایش ریاضی نقشه‌بندی کنیم، با یاد می‌گیرد که دانش‌های اعلام‌بندی مربوط به هر عملیات توضیح راه حل را انتخاب کنیم. این راهی برای حل تعدادی از نظریه‌های متعدد در یک مشکل پیشنهاد می‌کند، در حالی که در همین زمان، تعبیر قابلیت جواب را پشتیبانی می‌کند. مدل‌های روش ما نقشه‌سازی را برای تعریف دانش به عنوان تغییر اخیر می‌دهد، بنابراین نیازی برای توضیح گران را از دست می‌دهد. تحقیقات تجربه پیشنهاد می‌دهد که حل کننده‌ی دانش‌های دومینی ما بر روی همه سیستم‌های دیگر بیشتر از آن انجام می‌دهد، و این در مورد واقعیت بهتر است که داده‌های آموزش را که به آن نشان داده می‌شود، به صورت متفاوتی از داده‌های آزمایش تحقیق می‌کند.</abstract_fa>
      <abstract_sw>Tatizo la neno la Hesabu linatengeneza kujitokeza asili kwa matatizo mengi ya sababu, kama vile kuelewa habari za kifedha, matokeo ya michezo na majeraha ya vita. Kutafuta matatizo kama hayo yanahitaji kuelewa dhana kadhaa ya hisabati kama vile uchambuzi wa kidini, mahusiano ya kidini, etc. Katika karatasi hii, tunaendelea sheria za tangazo zinazotawala tafsiri ya lugha za asili ya maelezo ya mawazo haya kwa hisabati. Kisha tunaweka mfumo wa kuingiza maarifa kama haya ya tangazo katika tatizo la neno. Utawala wetu unajifunza kuchora ujumbe wa matatizo ya neno la kiarithmetic kwa hisabati, kwa kujifunza kuchagua maarifa muhimu ya tangazo kwa kila operesheni ya ufumbuzi. Hii inatoa njia ya kukabiliana na dhana mbalimbali katika tatizo hilo, wakati huo huo, kuunga mkono ufafanuzi wa kujieleza. Mfano wetu unaonyesha ramani ya kutangaza maarifa kama mabadiliko ya hivi karibuni, kwa hiyo kuondoa haja ya matatizo ya ghali. Utafiti wa majaribio unaonyesha kuwa maarifa yetu ya ndani yanaonyesha mifumo yote mengine, na kwamba inatengeneza vizuri katika kesi halisi ambapo taarifa za mafunzo zinazoonekana zinachukuliwa kwa njia tofauti kuliko taarifa za jaribio.</abstract_sw>
      <abstract_tr>Matematikanyň söz meseleleri tebigaty soňrak wajyplygyna bir görnüş hasaplanýar, mali täzelikleri, spor netijelerini we urşuň hasaplaryna düşürmek ýaly. Şol kynçylyklary çözmek üçin bir näçe matematiksel düşünjelerini, ölçülik analýusiýa, subünt baglaşyklary we bölegi ýaly düşünmesi gerek. Bu kagyzda, biz bu düşünjelerin tebigy dil waspyny matematiksel suratlara çevirilýäris. Sonra bu şekilde ifade eden bilimleri kelime çözmesine dahil etmek üçin bir çerçeve sunuyoruz. Biziň yöntemimiz matematik sözlerine aritmetik sözleriniň metini matematik sözlerine kartlamagy öwrenip, çözüm sözleriniň her işlerini saýlamagyny öwrenip öwrenip otyrýar. Bu birden birden düşünüp aynı meselede çözmek için bir yol sağlar, aynı zamanda cevap ifadesinin yorumluluğunu destekleýär. Biziň yöntemimiz kartasyny geçen bilim şeklinde ifade etmek üçin şekilde, bu şekilde pahalı täzelikler üçin gereklidigini a ýyrýar. Experimental değerlendirmegimiz domeniň bilgilerimize tabanly çözümler hemme başga sistemalary üstün edýär we bu durum çözümlerden başga bir şekilde üýtgedir.</abstract_tr>
      <abstract_sq>Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding financial news, sports results, and casualties of war.  Përzgjidhja e problemeve të tilla kërkon kuptimin e disa koncepteve matematike të tilla si analiza dimensionale, marrëdhëniet e nëngrupeve, etj. Në këtë letër, ne zhvillojmë rregulla deklaruese që rregullojnë përkthimin e përshkrimit të gjuhës natyrore të këtyre koncepteve në shprehjet matematike. Pastaj paraqesim një kuadër për përfshirjen e njohurive të tilla deklaruese në zgjidhjen e fjalëve probleme. Metoda jonë mëson të hartojmë tekstin e problemit të fjalës aritmetike në shprehjet matematike, duke mësuar të zgjedhë njohurinë e duhur deklaruese për çdo operacion të shprehjes së zgjidhjes. Kjo ofron një mënyrë për të trajtuar koncepte të shumta në të njëjtin problem ndërsa, në të njëjtën kohë, mbështet interpretueshmërinë e shprehjes së përgjigjes. Metoda jonë modelon hartimin e njohurive deklaruese si një ndryshues të fshehtë, duke hequr kështu nevojën për anotacione të shtrenjta. Vlerësimi eksperimental sugjeron se zgjidhësi i bazuar në njohuritë tona në domeni ekziston në të gjitha sistemet e tjera dhe se gjeneralizohet më mirë në rastin realist ku të dhënat e trajnimit që ekspozohen janë të paragjykuar në një mënyrë tjetër sesa të dhënat e test it.</abstract_sq>
      <abstract_am>የመስመር ቃላት ጉዳይ የባሕላዊ አካባቢ ጉዳይ፣ የሀብት ወሬ፣ የጨዋታ ውጤቶች እና የሰልፍ ወቅት እንዳስተዋሉ ነው፡፡ እንደዚህ ያሉ መከራዎች መፍታትን ለመፍታት፣ የሥልጣዊ አስተያየት፣ የውይይት ግንኙነት እና አስፈላጊ አስተያየት ያስፈልጋል፡፡ የዚያን ጊዜም እንዲህ ያለውን አዋቂ እውቀትን ለመቀበል ለቃላት መከራ እናስገባለን፡፡ የሥርዓታችን አካባቢ የቃላትን መክፈት ጽሑፍ ለመቆጣጠር እውቀትን ለመምረጥ ትማራለች፡፡ ይህም በአንድ መከራ ላይ ብዙዎችን አሳውሮዎችን ለመቀበል የሚችል መንገድ እና በዚያው ሰዓት የመልሱን ትርጉም ለመረዳት ይችላል፡፡ የእውቀትን አቀራቢ እንዲሆን የሚያሳውቀው ስህተት አካባቢ ነው የሚል ሥርዓታችን አካባቢ ነው፡፡ ፈተና ማረጋገጫ የኖሜን እውቀታችን መፍታት ሌሎችን ስርዓቶች ሁሉ እንዲያሳየው እና ለፈተናው ዳታዎችን ከሌሎች በተለየ ልዩ ዓይነት በሚያሳየው እውነተኛ ጉዳይ ላይ የተሻለ መሆኑን ያሳያል፡፡</abstract_am>
      <abstract_af>Wiskundige woord probleme vorm 'n natuurlike abstraksie tot 'n reek van kvantitatiewe redekende probleme, soos finansiële nuus, sportresultate en gevaarde van oorlog. Die oplossing van sodanige probleme benodig die verstanding van verskeie matematiese konsepte soos dimensjoneel analisie, onderwerpe verhouding, ensfh. In hierdie papier ontwikkel ons deklarative reëls wat die vertaling van natuurlike taal beskrywing van hierdie konsepte na matematiese uitdrukkings bestuur. Ons stel dan 'n raamwerk voor die inkorporeer van sodanige deklarative kennis in woord probleem oplossing. Ons metode leer na kaart aritmetiese woord probleem teks na matematiese uitdrukkings deur te leer na kies die relevante deklarative kennis vir elke operasie van die oplossing uitdrukking. Hierdie verskaf 'n manier om veelvuldige konsepte in dieselfde probleem te hanteer terwyl, op dieselfde tyd, ondersteun uitleggbare van die antwoord uitdrukking. Ons metode modeller die kaart om te deklareer kennis as 'n latente veranderlike, sodat die behoefte vir kosbare notasies verwyder. Eksperimentele evaluasie stel voorstel dat ons domein kennis gebaseerde oplosser uitvoer alle ander stelsels, en dat dit generelliseer beter in die realistiese geval waar die opvoering data wat dit uitgevoer is, is biased in 'n ander manier as die toets data.</abstract_af>
      <abstract_hy>Մաթեմատիկական բառերի խնդիրները բնական վերացացում են մի շարք քանակական մտածողական խնդիրների, ինչպիսիք են ֆինանսական նորությունների հասկանալը, սպորտային արդյունքները և պատերազմի վնասվածքները: Այսպիսի խնդիրների լուծման համար հարկավոր է հասկանալ մի քանի մաթեմատիկական հասկացություններ, ինչպիսիք են՝ չափերի վերլուծությունը, հարաբերությունները, և այլն: Այս աշխատանքում մենք զարգանում ենք հայտարարական կանոններ, որոնք ղեկավարում են այս հասկացությունների բնական լեզվի նկարագրման թարգմանումը Այնուհետև մենք ներկայացնում ենք մի շրջանակ, որը ներառում է այս հայտարարական գիտելիքները խնդիրների բառերի լուծման մեջ: Մեր մեթոդը սովորում է քարտեզագրել լուծության արտահայտության յուրաքանչյուր գործողության համար հարմար բառի տեքստը մաթեմատիկական արտահայտումների հետ, սովորելով ընտրել լուծության արտահայտության հարմար հայտարարական գիտելիքը: Սա նույն խնդրի մեջ բազմաթիվ գաղափարներ լուծելու միջոց է տալիս, միաժամանակ աջակցում է պատասխանի արտահայտության մեկնաբանելիությունը: Our method models the mapping to declarative knowledge as a latent variable, thus removing the need for expensive annotations.  Փորձարկվող գնահատումը ցույց է տալիս, որ մեր գիտելիքներով հիմնված լուծողը արտադրում է բոլոր այլ համակարգերը, և որ այն ավելի լավ է ընդհանրացվում իրական դեպքում, երբ այն արտադրված ուսումնասիրության տվյալները այլ կերպ են, քան թեստերի տվյալները:</abstract_hy>
      <abstract_bs>Problemi sa matematičkim riječima stvaraju prirodnu apstrakciju do niza kvantitativnih problema razuma, poput razumijevanja financijskih vijesti, sportskih rezultata i žrtava rata. Rešavanje takvih problema zahtijeva razumijevanje nekoliko matematičkih koncepta poput dimenzionalne analize, podzemne odnose itd. U ovom papiru razvijamo deklarativne pravila koje upravljaju prevodom prirodnog jezika opisa tih koncepta na izraze matematike. Zatim predstavljamo okvir za uključenje takvih deklarativnih znanja u rješavanje riječi. Naša metoda nauči mapirati tekst problema s aritmetičkim riječima na izraze matematike, učeći odabrati relevantne deklarativne znanje za svaku operaciju rješenja izraza. To pruža način za rješavanje višestrukih koncepta u istom problemu dok, u isto vrijeme, podržava interpretabilnost izraza odgovora. Naša metoda modelira mapiranje deklarativnim znanjima kao latentna varijanta, tako uklanjajući potrebu za skupim annotacijom. Eksperimentalna procjena ukazuje na to da naš rješavač na temelju znanja na domenu nadmašuje sve ostale sisteme, i da generalizuje bolje u reālističkom slučaju gdje su podaci o obuci na koji je izložen izloženom je predrasuden na drugačiji način nego podaci o testiranju.</abstract_bs>
      <abstract_ko>수학 단어 문제는 일련의 정량 추리 문제의 자연 추상을 형성했다. 예를 들어 금융 뉴스, 스포츠 성적과 전쟁 사상을 이해하는 것이다.이러한 문제를 해결하려면 차원 분석, 서브집합 관계 등 몇 가지 수학 개념을 이해해야 한다. 본고에서 우리는 이러한 개념의 자연 언어 묘사를 수학 표현식으로 전환하는 성명적 규칙을 개발했다.그리고 우리는 이러한 진술적 지식을 단어 문제 해결에 통합시키는 틀을 제시했다.우리의 방법은 표현식을 풀기 위한 모든 조작에 대한 성명성 지식을 배우고 산술 단어 문제 텍스트를 수학 표현식에 비추는 것을 배운다.이것은 같은 문제의 여러 개념을 처리하는 방법을 제공하고 답안 표현식의 해석성을 지원한다.우리의 방법은 성명성 지식에 대한 매핑 모델을 잠재적인 변수로 만들어 비싼 주석에 대한 수요를 없앴다.실험 평가에 의하면 우리의 분야 지식을 바탕으로 하는 구해기는 모든 다른 시스템보다 우수하고 실제 상황에서 그 범위화 효과가 더욱 좋다. 왜냐하면 노출된 훈련 데이터는 테스트 데이터와 다른 방식으로 편차가 존재하기 때문이다.</abstract_ko>
      <abstract_az>Matematik sözlərin problemləri təbiətli bir abstraktiya olaraq, malik xəbərləri, sport sonuçlarını və müharibələrin ölümlərini anlamaq məsələlərinə bənzəyir. Bütün problemlərin çəkinməsi ölçülük analizi, apakš ilişkileri və ya da kimi bir neçə matematik fikirlərini anlamaq lazımdır. Bu kağızda, bu fikirlərin təbiətli dil tərzini matematik ifadələrinə dəstəkləyici qaydaları təşkil edirik. Sonra böyük a çıq bilgiləri söz problemlərini çəkmək üçün bir çerçive göstəririk. Bizim metodumuz aritmetik sözlərin məlumatını matematik ifadələrinə mapa etməyi öyrənir, çətin ifadəsinin hər işləri üçün məlumatı seçməyi öyrənir. Bu, bir problem içində çoxlu fikirləri idarə etmək üçün bir yol verir, həmçin in, həmçinin cavab ifadəsinin yorumluluğunu dəstəkləyir. Bizim metodlarımız müəyyən bir dəyişiklik olaraq xəbərdarlıq etmək üçün xəbərdarlıqları modellərini, bu sərvətli xəbərdarlıqların ehtiyacını silib aparır. Eksperiment değerlendirməsi bizim domenə bilgi tabanlı çözücümüz bütün başqa sistemlərdən üstün olduğunu göstərir və bu təhsil məlumatlarını test məlumatlarından daha yaxşı təhsil edir.</abstract_az>
      <abstract_bn>গণিত শব্দের সমস্যা একটি প্রাকৃতিক উপেক্ষা বিভিন্ন কারণের ক্ষেত্রে, যেমন অর্থনৈতিক সংবাদ, খেলার ফলাফল এবং যুদ্ধের ক্ষতিগ্রস্ত। এই সমস্যার সমাধানের জন্য বেশ কয়েকটি গণতানিক ধারণা প্রয়োজন যেমন দৈতিক বিশ্লেষণ, সাবট সম্পর্ক ইত্যাদি। এই কাগজে আমরা ঘোষণা নিয়ম উন্নয়ন করি যা এই ধারণাগুলো গণতান্ত্রি তারপর আমরা এই ধরনের ঘোষণার জ্ঞান সমাধানে শব্দের সমস্যা সমাধান করার জন্য একটি ফ্রেম উপস্থাপন করি। আমাদের পদ্ধতি মানচিত্রের মানচিত্রের মানচিত্র হিসেবে মানচিত্রের জন্য শিখতে পারে, সমাধানের প্রতিটি কার্যকলাপের জন্য প্র এটি একই সমস্যায় বেশ কিছু ধারণা নিয়ে যাওয়ার উপায় আছে এবং একই সময়ে উত্তরের ব্যাখ্যার ব্যাখ্যা সমর্থন করে। আমাদের পদ্ধতি সাম্প্রতিক পরিবর্তন হিসেবে জ্ঞানের মানচিত্রের মানচিত্র মানচিত্রের মাধ্যমে মানচিত্র তৈরি করে,  পরীক্ষার পরীক্ষার বিষয়টি পরামর্শ দেয় যে আমাদের ডোমেইনের জ্ঞান ভিত্তিক সমাধানকারী সকল সিস্টেমের বিষয়গুলো প্রকাশ করে, এবং এটা বাস্তবতার ক্ষেত্রে ভ</abstract_bn>
      <abstract_ca>Els problemes de paraules matemàtiques formen una abstracció natural a una gamma de problemes quantitativs de raonament, com la comprensió de notícies financeres, resultats esportius i víctimes de guerra. Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions.  Llavors presentem un marc per incorporar aquest coneixement declaratiu en la solució de paraules problemes. El nostre mètode aprene a mapejar el text del problema de paraules aritmètiques a les expressions matemàtiques, aprenent a seleccionar el coneixement declaratiu pertinent per cada operació de l'expressió de solució. Això proporciona una manera de gestionar múltiples conceptes en el mateix problem a mentre, al mateix temps, suporta l'interpretabilitat de l'expressió de la resposta. El nostre mètode modela el mapatge al coneixement declaratiu com una variable latent, eliminant així la necessitat d'anotacions cares. L'evaluació experimental suggereix que el nostre solucionador basat en el coneixement de domini supera tots els altres sistemes, i que s'generalitza millor en el cas realiste en què les dades d'entrenament a les que està exposada estàn biasades d'una manera diferent de les dades de prova.</abstract_ca>
      <abstract_fi>Matemaattiset sanaongelmat muodostavat luonnollisen abstraktion useisiin kvantitatiivisiin päättelyongelmiin, kuten taloudellisten uutisten, urheilutulosten ja sodan uhrien ymmärtämiseen. Tällaisten ongelmien ratkaiseminen edellyttää useiden matemaattisten käsitteiden ymmärtämistä, kuten ulottuvuusanalyysin, osajoukkosuhteiden jne. Tässä työssä kehitämme deklaratiivisia sääntöjä, jotka ohjaavat näiden käsitteiden luonnollisen kielen kuvauksen kääntämistä matemaattisiksi ilmaisuiksi. Tämän jälkeen esitämme kehyksen tällaisen deklaratiivisen tiedon sisällyttämiseksi sanaongelmanratkaisuun. Menetelmämme oppii kartoittamaan aritmeettisen sanaongelmatekstin matemaattisiin lausekkeisiin oppimalla valitsemaan asiaankuuluvat deklaratiiviset tiedot ratkaisulausekkeen kullekin toiminnolle. Näin voidaan käsitellä useita käsitteitä samassa ongelmassa ja samalla tukea vastauslausekkeen tulkittavuutta. Menetelmämme mallintaa kartoituksen deklaratiiviseen tietoon piilevänä muuttujana, jolloin kalliiden merkintöjen tarve poistuu. Kokeellinen arviointi viittaa siihen, että verkkotietoon perustuva ratkaisumme suoriutuu paremmin kuin muut järjestelmät ja yleistyy paremmin realistisessa tapauksessa, jossa sille altistuvat harjoitustiedot ovat vääristyneitä eri tavalla kuin testitiedot.</abstract_fi>
      <abstract_et>Matemaatika sõna probleemid moodustavad loomuliku abstraktsiooni mitmesugustele kvantitatiivsetele arutlusprobleemidele, nagu finantsauudiste, sporditulemuste ja sõjaohvrite mõistmine. Selliste probleemide lahendamine nõuab mõistmist mitmetest matemaatilistest kontseptsioonidest nagu dimensioonianalüüs, alamhulga seosed jne Käesolevas töös töötame välja deklaratiivsed reeglid, mis reguleerivad looduskeele kirjelduse tõlkimist nende kontseptsioonide matemaatika väljenditeks. Seejärel esitame raamistiku selliste deklaratiivsete teadmiste kaasamiseks sõnaprobleemide lahendamisse. Meie meetod õpib kaardistama aritmeetilise sõna probleemi teksti matemaatilistele avaldistele, õppides valima vastavad deklaratiivsed teadmised iga lahenduse avaldise toimingu jaoks. See annab võimaluse käsitleda mitut kontseptsiooni sama probleemi, toetades samal ajal vastuse avaldise tõlgendatavust. Meie meetod modelleerib deklaratiivsete teadmiste kaardistamist latentse muutujana, kõrvaldades vajaduse kulukate märkuste järele. Eksperimentaalne hindamine näitab, et meie domeeni teadmistepõhine lahendaja on kõigist teistest süsteemidest parem ning et see üldistab paremini realistlikul juhul, kui koolitusandmed, millega ta kokku puutub, on erapooletud teistsugusel viisil kui testiandmed.</abstract_et>
      <abstract_cs>Matematické slovo problémy tvoří přirozenou abstrakci k řadě kvantitativních úvah problémů, jako je porozumění finančním zprávám, sportovním výsledkům a obětem války. Řešení těchto problémů vyžaduje porozumění několika matematickým pojmům, jako je dimenzionální analýza, vztahy podmnožin apod. V tomto článku vyvíjíme deklarativní pravidla, která řídí překlad popisu těchto pojmů do matematických výrazů. Následně představujeme rámec pro začlenění těchto deklarativních znalostí do řešení slovních problémů. Naše metoda se naučí mapovat aritmetický text slovního problému matematickým výrazům tím, že se naučí vybrat relevantní deklarativní znalosti pro každou operaci řešení výrazu. To poskytuje způsob, jak zvládnout více konceptů ve stejném problému a zároveň podporovat interpretovatelnost výrazu odpovědi. Naše metoda modeluje mapování na deklarativní znalosti jako latentní proměnnou, čímž odstraňuje potřebu drahých anotací. Experimentální vyhodnocení naznačuje, že náš řešitel založený na doménových znalostech předčí všechny ostatní systémy a že lépe zobecňuje v realistickém případě, kdy tréninková data, kterým je vystavena, jsou zaujatá jiným způsobem než testovací data.</abstract_cs>
      <abstract_ha>Mataimakin matsayin yana danganta kansar zuwa masu mataimaki masu yawa kamar fahimta ma'anar dũkiya, fassarar firam da hasãra na yãƙi. Solving such problems requires the understanding of several mathematical concepts such as dimensional analysis, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these concepts to math expressions.  Sa'an nan kuma Muke samun wani firam dõmin Mu shigar da kunyar wannan a cikin masu faɗa zuwa masu solar da matsayi. Tsarinmu ya sanar da karta matsayin matabbaci ga magana na arithmetic zuwa magana na matsayin, da za'a yarda da za'a zãɓi ilmi na da inganci da inganci wa kowace aikin ajin da ake bayyana. Wannan na ƙudura wani hanyor wa ka yi amfani da zato-zato masu yawa cikin masu shagala da shi, a lokacin da, yana ƙarfafa fassarar maganar ajiya. Salon hanyõyinmu na kamata yin kunna da sanarwa kamar wata mai tsohon nan, sai ya tafiyar da amfani ga surori masu nau'i. Taƙaitar jarrabai yana son cewa masu da ilmi a danne gudani, zai nuna duk wasu na'ura, kuma yana ƙara mafi alhẽri a cikin kashfa da gaskiyar, inda data wanda ake samar da shi ya sami shi, za'a sami shi da wata dabam ko da data ta jarraba.</abstract_ha>
      <abstract_jv>Wurung-Wurung ung Where's the first language Awak dhéwé éntuk sistem kanggo nggawe akeh luwih dumadhi iki bakal ngubah perusahaan kelas kuwi. method Iki nyengke sistem sing nggawe ngerti apa sing sampeyan nèng iki, sampeyan ngono sampeyan, nggunaké tolungkampun layang pangan. Laptop" and "Desktop Wang tengahane sing paling nggawe kelas nang awak dhéwé dipunangé awak dhéwé kuwi nggawe sistem sing wis nong, lan digawe kuwi nggawe sistem sing luwih apik dhéwé, dadi triyang dipunangé awak dhéwé.</abstract_jv>
      <abstract_sk>Težave z matematičnimi besedami tvorijo naravno abstrakcijo za vrsto kvantitativnih težav razmišljanja, kot so razumevanje finančnih novic, športnih rezultatov in vojne žrtve. Reševanje takih problemov zahteva razumevanje več matematičnih konceptov, kot so dimenzionalna analiza, razmerja podmnožic itd. V tem prispevku razvijamo deklarativna pravila, ki urejajo prevod opisa naravnega jezika teh konceptov v matematične izraze. Nato predstavimo okvir za vključitev takšnega deklarativnega znanja v reševanje besednih problemov. Naša metoda se nauči kartirati aritmetično besedno problematično besedilo v matematične izraze, tako da se nauči izbrati ustrezno deklarativno znanje za vsako operacijo rešitvenega izraza. To zagotavlja način obravnavanja več konceptov v istem problemu, hkrati pa podpira razlago izraza odgovora. Naša metoda modelira kartiranje na deklarativno znanje kot latentno spremenljivko, s čimer odpravlja potrebo po dragih opombah. Eksperimentalna vrednotenja kaže, da naš reševalec na področju znanja presega vse druge sisteme in da se bolje posploši v realnem primeru, ko so podatki o usposabljanju, ki jim je izpostavljen, pristranski na drugačen način kot podatki o preskusu.</abstract_sk>
      <abstract_he>בעיות מילים מתמטיקות נוצרות אסטראקציה טבעית לטווח של בעיות הגיון כמוניות, כמו להבין חדשות פיננסיות, תוצאות ספורט, ופגיעות מלחמה. לפתור בעיות כאלה דורשת הבנה של מספר מושגים מתמטיים כמו ניתוח מימדי, מערכות יחסים תת-קבוצות וכו"כ. בעיתון הזה, אנחנו מפתחים חוקים מבטחים שמשלטים את התרגום של תיאור שפה טבעי של המושגים האלה לבטאות מתמטיות. ואז אנו מציגים מסגרת להכניס ידע מוכר כזה לפתור בעיות מילים. השיטה שלנו לומדת למפות טקסט בעיות מילים ארתמטית לבטאות מתמטיות, על ידי ללמוד לבחור את הידע ההכרה הרלוונטי לכל פעולה של הביטוי הפתרון. זה מספק דרך להתמודד עם הרעיונות רבות באותה בעיה בזמן, באותו הזמן, לתמוך בפרשנות של הביטוי התשובה. השיטה שלנו דוגמנית את המפה לידע הצהיר כמשתנה מוסתרת, כך להסיר את הצורך להציעות יקרות. הערכה ניסיונית מצביעה כי המפתח המבוסס על ידע המחוזי שלנו עולה על כל מערכות אחרות, והוא מתפשט טוב יותר במקרה המצייאותי שבו נתוני האימונים שהוא נחשף אליהם הם מועמדים בדרך שונה מהנתונים המבחנים.</abstract_he>
      <abstract_bo>གྲངས་རིག་གི་ཐ་སྙད་དཀའ་ངལ་མ་ཞིག་ནི་རང་བཞིན་གྱི་གཟུགས་རྐྱེན་དེ་གྲངས་འབྲེལ་མ་བསམ་བློ་གཏོང་གི་དཀའ དབྱེ་སེལ་ཐབས་འཇུག་བྱེད་དེ་དག་གི་གྲངས་རིག་གི་ལྟ་བ་མང་ཙམ་གྱི་རྟོགས་པར་ལེན་དགོས་པ་མིན་ན། འོན་ཀྱང་། ང་ཚོས་དོན་དག་གི་ཤེས་བ་འདི་ལྟ་བུའི་ནང་དུ་གཏོང་ཁང་ཅིག་བཤད་པ་དེ་ཤེས་ཀྱི་ཡོད། ང་ཚོའི་ལམ་ལུགས་འདི་གྲངས་རྩིས་ཀྱི་གནད་དོན་དག་གི་ཡི་གེ་གྲངས་རིག འདིས་དཀའ་ངལ་གཅིག་མཚུངས་ཀྱི་ལྟ་བ་མང་པོ་ཞིག་གིས་གནད་དོན་གཅིག་མཚུངས་ཀྱིས་མཐུན་སྣུམ་ཚོར་ལ་རྒྱབ་སྐྱོར་བ ང་ཚོའི་ཐབས་ལམ་གཟུགས་རིས་སྔར་བས་ཀྱིས་གསལ་བཤད་ཀྱི་ཤེས་ཚིག་ལ་འགྱུར་ཅན་ཞིག་ཡིན། Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data is exposed to is biased in different ways than the test data.</abstract_bo>
      </paper>
    <paper id="13">
      <title>Video Captioning with Multi-Faceted Attention</title>
      <author><first>Xiang</first><last>Long</last></author>
      <author><first>Chuang</first><last>Gan</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <doi>10.1162/tacl_a_00013</doi>
      <abstract>Video captioning has attracted an increasing amount of interest, due in part to its potential for improved <a href="https://en.wikipedia.org/wiki/Accessibility">accessibility</a> and <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval</a>. While existing methods rely on different kinds of <a href="https://en.wikipedia.org/wiki/Visual_system">visual features</a> and model architectures, they do not make full use of pertinent semantic cues. We present a unified and extensible framework to jointly leverage multiple sorts of <a href="https://en.wikipedia.org/wiki/Feature_(computer_vision)">visual features</a> and <a href="https://en.wikipedia.org/wiki/Semantic_Web">semantic attributes</a>. Our novel <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a> builds on LSTMs with two multi-faceted attention layers. These first learn to automatically select the most salient visual features or semantic attributes, and then yield overall representations for the input and output of the sentence generation component via custom feature scaling operations. Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms previous work and performs robustly even in the presence of added noise to the features and attributes.</abstract>
      <pages>173–184</pages>
      <url hash="e365dc4a">Q18-1013</url>
      <bibkey>long-etal-2018-video</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/msvd">MSVD</pwcdataset>
    <title_ar>شرح مقاطع الفيديو مع الاهتمام متعدد الأوجه</title_ar>
      <title_pt>Legendagem de vídeo com atenção multifacetada</title_pt>
      <title_es>Subtítulos de vídeo con atención multifacética</title_es>
      <title_fr>Sous-titrage vidéo avec une attention multiforme</title_fr>
      <title_ja>多面的な注意を払ったビデオキャプション</title_ja>
      <title_zh>多所关视频字幕</title_zh>
      <title_hi>बहुआयामी ध्यान के साथ वीडियो कैप्शनिंग</title_hi>
      <title_ru>Подписи к видео с многогранным вниманием</title_ru>
      <title_ga>Fortheidealú Físe le hAire Ilghnéitheach</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Λεζάντες βίντεο με προσοχή πολλαπλών όψεων</title_el>
      <title_hu>Videó feliratozás több arcú figyelemmel</title_hu>
      <title_it>Sottotitoli video con attenzione a più facce</title_it>
      <title_lt>Video Captioning with Multifaceted Attention</title_lt>
      <title_mk>Запишување на видео со повеќе лица внимание</title_mk>
      <title_ms>Capsyen Video dengan Perhatian Berberbilang-Fakta</title_ms>
      <title_kk>Көп бетті қарау арқылы видео айдары</title_kk>
      <title_ml>Multi- Faced Attention</title_ml>
      <title_mn>Ихэнх нүүрний анхаарлын бичлэг зураг</title_mn>
      <title_no>Videotittering med fleire trekk merking</title_no>
      <title_mt>Taqsim tal-Vidjo b’Attenzjoni Multi-Faced</title_mt>
      <title_pl>Napisy wideo z uwagą wielowymiarową</title_pl>
      <title_ro>Subtitrare video cu atenție multiplă</title_ro>
      <title_sr>Video snimanje sa višelicnim pažnjom</title_sr>
      <title_si>Name</title_si>
      <title_so>Fiidiyow Captioning with Multi-Faceted Attention</title_so>
      <title_sv>Bildtext med flerfacetterad uppmärksamhet</title_sv>
      <title_ur>ویڈیو کاپیٹینگ چند چہروں کے ساتھ</title_ur>
      <title_ta>Multi- Faced Attention with Video Captioning</title_ta>
      <title_uz>Comment</title_uz>
      <title_vi>Thu nhỏ ảnh bằng đa khuôn</title_vi>
      <title_nl>Videobijschriften met meerzijdige aandacht</title_nl>
      <title_bg>Записване на видео с многостранно внимание</title_bg>
      <title_hr>Video snimanje s višelicnim pažnjom</title_hr>
      <title_da>Videobilledtekster med opmærksomhed i flere facetter</title_da>
      <title_de>Videobeschriftung mit mehrseitiger Aufmerksamkeit</title_de>
      <title_ko>다방면의 관심 영상 자막</title_ko>
      <title_fa>تصویر ویدئو با توجه بسیاری از چهره‌ها</title_fa>
      <title_id>Video Captioning dengan Perhatian Multi-Faced</title_id>
      <title_sw>Video yenye mwangalizi wa Multi-Faced Attention</title_sw>
      <title_af>Name</title_af>
      <title_sq>Video Captioning me vëmendje me shumë faqe</title_sq>
      <title_tr>Birnäçe Görnüş bilen wideo Käpşenler</title_tr>
      <title_am>Video Captioning with Multi-Faced Attention</title_am>
      <title_bn>Multi-Faced Attention সহ ভিডিও ক্যাপ্টেশন</title_bn>
      <title_hy>Տեսագրություն բազմատեսակ ուշադրության հետ</title_hy>
      <title_bs>Video snimanje sa višelicnim pažnjom</title_bs>
      <title_az>Multi-Faced Attention ilə Video Captioning</title_az>
      <title_ca>Capcions de vídeo amb atenció multifacetada</title_ca>
      <title_cs>Video titulky s vícetvářovou pozorností</title_cs>
      <title_et>Video pealdis mitmepoolse tähelepanuga</title_et>
      <title_fi>Videotekstitys monimuotoisella huomiolla</title_fi>
      <title_jv>Video Caption with Multi-Covered Attention</title_jv>
      <title_he>תוכנית וידאו עם תשומת לב מרובה פנים</title_he>
      <title_sk>Video posnetki z večstransko pozornostjo</title_sk>
      <title_ha>Phonon:: MMF:: EffectFactory</title_ha>
      <title_bo>གདོང་རིས་མང་ཙམ་ཅན་གྱི་རྣམ་པ་ལ་བརྙན་ཡིག་པར་བཤད་པ</title_bo>
      <abstract_ar>جذبت التسميات التوضيحية على الفيديو قدرًا متزايدًا من الاهتمام ، ويرجع ذلك جزئيًا إلى قدرتها على تحسين إمكانية الوصول واسترجاع المعلومات. بينما تعتمد الأساليب الحالية على أنواع مختلفة من الميزات المرئية وبنيات النماذج ، فإنها لا تستفيد بشكل كامل من الإشارات الدلالية ذات الصلة. نقدم إطارًا موحدًا وقابل للتوسيع للاستفادة بشكل مشترك من أنواع متعددة من الميزات المرئية والسمات الدلالية. بنيتنا الجديدة مبنية على LSTM مع طبقتين من الانتباه متعدد الأوجه. يتعلم هؤلاء أولاً تحديد السمات المرئية الأكثر بروزًا أو السمات الدلالية تلقائيًا ، ثم تقديم تمثيلات شاملة لمدخلات ومخرجات مكون إنشاء الجملة عبر عمليات تحجيم الميزة المخصصة. تظهر النتائج التجريبية على مجموعات بيانات MSVD و MSR-VTT الصعبة أن إطار عملنا يتفوق على العمل السابق ويعمل بقوة حتى في وجود ضوضاء مضافة إلى الميزات والسمات.</abstract_ar>
      <abstract_pt>A legendagem de vídeo tem atraído cada vez mais interesse, em parte devido ao seu potencial para melhorar a acessibilidade e a recuperação de informações. Embora os métodos existentes dependam de diferentes tipos de recursos visuais e arquiteturas de modelo, eles não fazem pleno uso das dicas semânticas pertinentes. Apresentamos uma estrutura unificada e extensível para alavancar conjuntamente vários tipos de recursos visuais e atributos semânticos. Nossa nova arquitetura se baseia em LSTMs com duas camadas de atenção multifacetadas. Eles primeiro aprendem a selecionar automaticamente os recursos visuais ou atributos semânticos mais salientes e, em seguida, produzem representações gerais para a entrada e saída do componente de geração de frases por meio de operações de dimensionamento de recursos personalizados. Resultados experimentais nos desafiadores conjuntos de dados MSVD e MSR-VTT mostram que nossa estrutura supera o trabalho anterior e funciona de forma robusta, mesmo na presença de ruído adicional aos recursos e atributos.</abstract_pt>
      <abstract_es>Los subtítulos de vídeo han despertado un interés cada vez mayor, debido en parte a su potencial para mejorar la accesibilidad y la recuperación de información. Si bien los métodos existentes se basan en diferentes tipos de características visuales y arquitecturas de modelos, no hacen un uso completo de las señales semánticas pertinentes. Presentamos un marco unificado y extensible para aprovechar conjuntamente múltiples tipos de características visuales y atributos semánticos. Nuestra arquitectura novedosa se basa en LSTM con dos capas de atención multifacéticas. Primero aprenden a seleccionar automáticamente las características visuales o los atributos semánticos más destacados y, a continuación, producen representaciones generales para la entrada y la salida del componente de generación de oraciones mediante operaciones de escalado de entidades personalizadas. Los resultados experimentales de los desafiantes conjuntos de datos MSVD y MSR-VTT muestran que nuestro marco supera el trabajo anterior y funciona con solidez incluso en presencia de ruido adicional en las características y los atributos.</abstract_es>
      <abstract_fr>Le sous-titrage vidéo suscite un intérêt croissant, en partie en raison de son potentiel d'amélioration de l'accessibilité et de la récupération d'informations. Bien que les méthodes existantes reposent sur différents types de caractéristiques visuelles et d'architectures de modèles, elles n'exploitent pas pleinement les indices sémantiques pertinents. Nous présentons un cadre unifié et extensible pour exploiter conjointement plusieurs types de caractéristiques visuelles et d'attributs sémantiques. Notre architecture novatrice repose sur des LSTM avec deux couches d'attention aux multiples facettes. Ceux-ci apprennent d'abord à sélectionner automatiquement les caractéristiques visuelles ou les attributs sémantiques les plus saillants, puis à produire des représentations globales pour l'entrée et la sortie du composant de génération de phrases via des opérations de mise à l'échelle des entités personnalisées. Les résultats expérimentaux sur les ensembles de données MSVD et MSR-VTT difficiles montrent que notre framework surpasse les travaux précédents et fonctionne de manière robuste même en présence de bruit supplémentaire pour les caractéristiques et les attributs.</abstract_fr>
      <abstract_ja>ビデオキャプションは、アクセシビリティと情報検索の向上の可能性があるため、ますます関心を集めています。既存の方法は、さまざまな種類の視覚的特徴とモデルアーキテクチャに依存していますが、それらは適切な意味的手がかりを十分に活用していません。私たちは、複数の種類の視覚的特徴とセマンティック属性を共同で活用するための統一された拡張可能なフレームワークを提示します。当社の新しいアーキテクチャは、2つの多面的な注目レイヤーを備えたLSTMに基づいています。これらはまず、最も顕著な視覚的特徴またはセマンティック属性を自動的に選択し、次にカスタム特徴スケーリング操作を介して文章生成コンポーネントの入出力の全体的な表現を生成することを学びます。難易度の高いMSVDおよびMSR - VTTデータセットの実験結果は、当社のフレームワークが以前の作業を上回り、機能と属性にノイズが追加された場合でも堅牢な性能を発揮することを示しています。</abstract_ja>
      <abstract_hi>वीडियो कैप्शनिंग ने ब्याज की बढ़ती राशि को आकर्षित किया है, जो बेहतर पहुंच और सूचना पुनर्प्राप्ति के लिए इसकी क्षमता के कारण भाग में है। जबकि मौजूदा तरीके विभिन्न प्रकार की दृश्य विशेषताओं और मॉडल आर्किटेक्चर पर भरोसा करते हैं, वे प्रासंगिक शब्दार्थ संकेतों का पूरा उपयोग नहीं करते हैं। हम संयुक्त रूप से दृश्य सुविधाओं और शब्दार्थ विशेषताओं के कई प्रकार का लाभ उठाने के लिए एक एकीकृत और एक्सटेंसिबल फ्रेमवर्क प्रस्तुत करते हैं। हमारा उपन्यास वास्तुकला दो बहुआयामी ध्यान परतों के साथ एलएसटीएम पर बनाता है। ये पहले स्वचालित रूप से सबसे प्रमुख दृश्य विशेषताओं या शब्दार्थ विशेषताओं का चयन करना सीखते हैं, और फिर कस्टम सुविधा स्केलिंग संचालन के माध्यम से वाक्य पीढ़ी घटक के इनपुट और आउटपुट के लिए समग्र प्रतिनिधित्व प्राप्त करते हैं। चुनौतीपूर्ण MSVD और MSR-VTT डेटासेट पर प्रयोगात्मक परिणाम बताते हैं कि हमारा ढांचा पिछले काम से बेहतर प्रदर्शन करता है और सुविधाओं और विशेषताओं के लिए अतिरिक्त शोर की उपस्थिति में भी मजबूती से प्रदर्शन करता है।</abstract_hi>
      <abstract_zh>视频字幕引益众之兴者,盖有改善访性信息检索之力也。 虽有法依于异类者,体系结构而不尽其语义也。 建一统而广框架,以共众目之性语义。 我新架构在两多力LSTM上。 先学自择至视语义性,然后因自定义缩放操为句组件输输成体。 有挑战性之 MSVD , MSR-VTT 数之实验结果表明,吾框架优于前事,虽属性有附噪声者,其性亦甚有色。</abstract_zh>
      <abstract_ru>Подписи к видеоматериалам вызывают все больший интерес, что отчасти объясняется их потенциалом в плане улучшения доступности и поиска информации. Хотя существующие методы основаны на различных видах визуальных особенностей и архитектур моделей, они не используют в полной мере соответствующие семантические сигналы. Мы представляем унифицированный и расширяемый фреймворк для совместного использования множества видов визуальных функций и семантических атрибутов. Наша новая архитектура построена на LSTM с двумя многогранными слоями внимания. Они сначала учатся автоматически выбирать наиболее значимые визуальные признаки или семантические атрибуты, а затем выдают общие представления для ввода и вывода компонента генерации предложений с помощью пользовательских операций масштабирования признаков. Экспериментальные результаты на сложных наборах данных MSVD и MSR-VTT показывают, что наша структура превосходит предыдущую работу и выполняет надежно даже при наличии добавленного шума к признакам и атрибутам.</abstract_ru>
      <abstract_ga>Tá suim mhéadaitheach tarraingthe ag gabháil le fotheidealú físeáin, go páirteach mar gheall ar a acmhainneacht le haghaidh inrochtaineachta feabhsaithe agus aisghabhála faisnéise. Cé go mbraitheann modhanna atá ann cheana ar chineálacha éagsúla gnéithe amhairc agus ailtireachta samhlacha, ní bhaineann siad úsáid iomlán as leideanna shéimeantacha ábhartha. Cuirimid creat aontaithe agus sínte i láthair chun cineálacha iolracha de ghnéithe amhairc agus de thréithe shéimeantacha a ghiaráil i gcomhpháirt. Tógann ár n-ailtireacht úrscéal ar LSTManna le dhá shraith aird ilghnéitheacha. Foghlaimíonn siad seo ar dtús na gnéithe amhairc nó na tréithe séimeantaice is suntasaí a roghnú go huathoibríoch, agus ansin uiríll iomlána a thabhairt d'ionchur agus aschur chomhpháirt giniúna na habairte trí oibríochtaí saincheaptha scálaithe gné. Léiríonn torthaí turgnamhacha ar thacair shonraí dúshlánacha MSVD agus MSR-VTT go n-éiríonn lenár gcreat oibre roimhe seo agus go bhfeidhmíonn sé go láidir fiú i láithreacht torainn bhreise leis na gnéithe agus na tréithe.</abstract_ga>
      <abstract_el>Οι λεζάντες βίντεο έχουν προσελκύσει αυξανόμενο ενδιαφέρον, εν μέρει λόγω της δυνατότητάς τους για βελτιωμένη προσβασιμότητα και ανάκτηση πληροφοριών. Ενώ οι υπάρχουσες μέθοδοι βασίζονται σε διαφορετικά είδη οπτικών χαρακτηριστικών και αρχιτεκτονικών μοντέλων, δεν χρησιμοποιούν πλήρως τις σχετικές σημασιολογικές ενδείξεις. Παρουσιάζουμε ένα ενοποιημένο και επεκτάσιμο πλαίσιο για να αξιοποιήσουμε από κοινού πολλαπλά είδη οπτικών χαρακτηριστικών και σημασιολογικών χαρακτηριστικών. Η νέα αρχιτεκτονική μας βασίζεται σε δύο πολύπλευρα στρώματα προσοχής. Αυτοί μαθαίνουν πρώτα να επιλέγουν αυτόματα τα πιο σημαντικά οπτικά χαρακτηριστικά ή σημασιολογικά χαρακτηριστικά και στη συνέχεια να αποδίδουν συνολικές αναπαραστάσεις για την εισαγωγή και την έξοδο του στοιχείου δημιουργίας προτάσεων μέσω προσαρμοσμένων λειτουργιών κλιμάκωσης χαρακτηριστικών. Τα πειραματικά αποτελέσματα στα απαιτητικά σύνολα δεδομένων δείχνουν ότι το πλαίσιο μας ξεπερνά τις προηγούμενες εργασίες και αποδίδει γερά ακόμη και με την παρουσία προστιθέμενου θορύβου στα χαρακτηριστικά και χαρακτηριστικά.</abstract_el>
      <abstract_hu>A videofeliratozás egyre nagyobb érdeklődést vonzott, részben a jobb hozzáférhetőség és az információk lekérhetősége miatt. Míg a meglévő módszerek különböző vizuális jellemzőkre és modellarchitektúrákra támaszkodnak, nem használják ki teljes mértékben a vonatkozó szemantikai utakat. Egységes és bővíthető keretrendszert mutatunk be, amely többféle vizuális jellemzőt és szemantikai attribútumot használ együtt. Újszerű architektúránk két sokoldalú figyelemrétegű LSTMre épül. Ezek először megtanulják automatikusan kiválasztani a legkiemelkedőbb vizuális jellemzőket vagy szemantikai attribútumokat, majd egyéni funkcióskálázási műveletek segítségével általános reprezentációkat adnak a mondatgyártás összetevőjének bemenetére és kimenetére. A kihívást jelentő MSVD és MSR-VTT adatkészletekkel kapcsolatos kísérleti eredmények azt mutatják, hogy keretrendszerünk felülmúlja a korábbi munkákat és robusztus teljesítményt még a funkciók és attribútumok kiegészítése esetén is.</abstract_hu>
      <abstract_ka>ვიდეო შესახებ უფრო მეტი ინტერესტის განმავლობა, რომელიც იმის პოტენციალური შესაძლებლობა და ინფორმაციის მიღებაზე გაუფრო მეტია. თუმცა არსებობს მეტი განსხვავებული ვიზუალური ფუნქციები და მოდელური აქტიქტიქტურების განსაზღვრებით, ისინი არ გამოყენებენ მსგავსი სემენტიკური სიმპან ჩვენ ერთადერთებული და გაფართლებელი ფრამეტრის გაჩვენებთ, რომ ერთადერთად მრავალური ვიზუალური ფუნქციები და სენმანტიური ატრიბუტებები გამოყენებს. ჩვენი პრომენტური არქტიქტიკური LSTMs-ზე ახლოს ორი მნიშვნელოვანი დაახლოებით. ეს პირველი მოვისწავლეთ ავტომატურად გადანიშნოთ უკეთესი ვიზუალური ფუნქციები ან სიმენტიკური ატრიბუტები, და შემდეგ უკეთესი გამოსახულებების გამოყენება და გამოსახულება მ ექსპერიმენტიური შედეგი MSVD და MSR-VTT მონაცემების შესახებ ჩვენი პარამეტრი უფრო გავაკეთება წინა სამუშაო დავაკეთება და უფრო ძალიან გავაკეთება ჩვენი მონაცემების და ატრიბუტე</abstract_ka>
      <abstract_it>La didascalia video ha attirato un crescente interesse, in parte a causa del suo potenziale per migliorare l'accessibilità e il recupero delle informazioni. Mentre i metodi esistenti si basano su diversi tipi di caratteristiche visive e architetture di modello, non fanno pieno uso di indizi semantici pertinenti. Presentiamo un framework unificato ed estensibile per sfruttare congiuntamente molteplici tipi di caratteristiche visive e attributi semantici. La nostra nuova architettura si basa su LSTMs con due strati di attenzione sfaccettati. Questi imparano a selezionare automaticamente le caratteristiche visive o gli attributi semantici più salienti e quindi a produrre rappresentazioni complessive per l'input e l'output del componente di generazione delle frasi tramite operazioni di ridimensionamento delle funzionalità personalizzate. I risultati sperimentali sugli impegnativi set di dati MSVD e MSR-VTT mostrano che il nostro framework supera i lavori precedenti e funziona in modo robusto anche in presenza di rumore aggiunto alle caratteristiche e agli attributi.</abstract_it>
      <abstract_mk>Запишувањето на видео привлече зголемена сума на интерес, делумно поради нејзиниот потенцијал за подобрен пристап и добивање информации. Иако постојните методи зависат од различни видови визуелни карактеристики и моделни архитектури, тие не користат целосно перспективни семантични знаци. Презентираме унифицирана и проширена рамка за заеднички употреба на повеќе видови визуелни карактеристики и семантични атрибути. Нашата романска архитектура се гради на ЛСТМ со два слоја на внимание. Овие први учат автоматски да ги изберат најзначајните визуелни карактеристики или семантични атрибути, а потоа да дадат целокупни претставувања за внесувањето и излезот на компонентот за генерација на реченици преку сопствени операции за скалирање на карактери Експерименталните резултати на предизвикувачките податоци на MSVD и MSR-VTT покажуваат дека нашата рамка ја надминува претходната работа и функционира силно дури и во присуство на додадена бучава на карактеристиките и атрибутите.</abstract_mk>
      <abstract_kk>Видео айдарылығы өзінің мүмкіндігін жақсарту және мәліметті алу мүмкіндігінің көбінде өзінің артықшылығын өзгертіп жатыр. Бар әдістер әртүрлі көрініс мүмкіндіктер мен архитектуралардың түрлі түрлеріне тәуелді, олар керек семантикалық белгілерді толық қолданбады. Біз біріктірілген және кеңейтілген фреймін бірнеше түрлі көрінетін қасиеттерді және semantic атрибуттарды біріктіру үшін көрсету үшін көрсету. Біздің романдық архитектурамыз LSTMs-ге екі көп қатынасы бар. Бұлар біріншіден көрініс қасиеттерін немесе семантикалық атрибуттарды автоматты түрде таңдауға үйренеді, содан кейін сөздерді құру компонентінің келтірілген және шығысын өзгерту әрекеттері арқылы жа MSVD және MSR- VTT деректер жиындарының эксперименталдық нәтижелері біздің фрейміміз алдыңғы жұмыс істейді және қасиеттер мен атрибуттарға қосылған дыбыс болғанда да дұрыс жұмыс істейді.</abstract_kk>
      <abstract_lt>Vaizdo įrašas pritraukė vis didesnę palūkanų sumą, iš dalies dėl jo galimybės gerinti prieinamumą ir gauti informaciją. Nors esami metodai priklauso nuo skirtingų rūšių vizualinių savybių ir modelių architektūrų, jie visiškai nepasinaudoja atitinkamais semantiniais ženklais. Pateikiame vieningą ir išplėstinę sistemą, kad kartu būtų galima suvienodinti įvairių rūšių vizualinius požymius ir semantinius požymius. Mūsų naujoji architektūra grindžiama LSTM su dviem daugialypiais dėmesio sluoksniais. These first learn to automatically select the most salient visual features or semantic attributes, and then yield overall representations for the input and output of the sentence generation component via custom feature scaling operations.  Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms previous work and performs robustly even in the presence of added noise to the features and attributes.</abstract_lt>
      <abstract_ms>Penulisan video telah menarik jumlah kepentingan yang meningkat, sebahagian disebabkan potensi untuk peningkatan aksesibiliti dan pemulihan maklumat. Walaupun kaedah yang wujud bergantung pada jenis-jenis ciri-ciri visual dan arkitektur model yang berbeza, mereka tidak menggunakan isyarat semantik yang sesuai. Kami memperkenalkan kerangka yang bersatu dan boleh diperluaskan untuk bersama-sama menggunakan berbagai jenis ciri-ciri visual dan atribut semantik. Arkitektur novel kami membina pada LSTM dengan dua lapisan perhatian berbilang-muka. Ini pertama belajar untuk memilih secara automatik ciri-ciri visual yang paling penting atau atribut semantik, dan kemudian menghasilkan perwakilan keseluruhan untuk input dan output komponen generasi kalimat melalui operasi skala ciri-ciri suai. Hasil percubaan pada set data MSVD dan MSR-VTT menantang menunjukkan bahawa kerangka kami melampaui kerja sebelumnya dan melaksanakan dengan kuat walaupun ada bunyi tambahan pada ciri-ciri dan atribut.</abstract_ms>
      <abstract_ml>വീഡിയോ പിടിക്കുന്നത് കൂടുതല്‍ താല്‍പര്യമുള്ളതായി ആകര്‍ഷിച്ചിരിക്കുന്നു. അതിന്റെ സാധ്യതയില്‍ ഭാഗമായി അതിന്റെ വിവരങ നിലവിലുള്ള രീതികളില്‍ വ്യത്യസ്ത തരം കാഴ്ചകളിലും മോഡല്‍ ആര്‍ക്കിട്ടുകളിലും ആശ്രയിക്കുന്ന പ്രകാരം അവയൊന്നും പൂര്‍ണ്ണമായി സ ഒരുമിച്ചും വിശാലമായ ഒരു ഫ്രെയിമെക്ക് ഞങ്ങള്‍ കൊണ്ടുവരുന്നു. ഒരുമിച്ചിരിക്കുന്നു. കാഴ്ചപ്പെടുത്തുന്ന പല തരം  നമ്മുടെ നോവല്‍ ആര്‍ക്ടിക്കറ്റര്‍ എല്‍സ്റ്റിഎസ്സില്‍ നിര്‍മ്മിക്കുന്നു. രണ്ട് മുഖമുള്ള രണ്ട് ശ്രദ്ധ കാ ആദ്യം അവയില്‍ ഏറ്റവും സാധാരണ കാഴ്ചയുള്ള ഗുണഗണങ്ങള്‍ അല്ലെങ്കില്‍ സെമാന്റിക് ഗുണഗണങ്ങള്‍ തെരഞ്ഞെടുക്കാന്‍ പഠിക്കുന്നു. പിന്നീട് അവയ്ക്ക് സ മുമ്പുള്ള ജോലി പ്രവര്‍ത്തിപ്പിക്കുന്നു എന്നിട്ട് നമ്മുടെ ഫ്രെയിമ്പ് പ്രവര്‍ത്തിപ്പിക്കുന്നത് മുമ്പുള്ള വിവരങ്ങള്‍ക്കും കൂടുതല്‍ ശബ്ദം</abstract_ml>
      <abstract_mt>Il-video captioning ġibdet ammont dejjem akbar ta’ interess, parzjalment minħabba l-potenzjal tiegħu għal aċċessibbiltà mtejba u ġbir ta’ informazzjoni. Filwaqt li l-metodi eżistenti jiddependu fuq tipi differenti ta’ karatteristiċi viżivi u arkitetturi mudelli, ma jagħmlux użu sħiħ minn sinjali semantiċi pertinenti. Aħna nippreżentaw qafas unifikat u estensibbli biex inħeġġu flimkien diversi tipi ta’ karatteristiċi viżivi u attributi semantiċi. L-arkitettura l-ġdida tagħna tibni fuq LSTMs b’żewġ saffi ta’ attenzjoni b’diversi aspetti. Dawn l-ewwel jitgħallmu jagħżlu awtomatikament l-aktar karatteristiċi viżivi salienti jew attributi semantiċi, u mbagħad jagħtu rappreżentazzjonijiet ġenerali għall-input u l-output tal-komponent tal-ġenerazzjoni tas-sentenzi permezz ta’ operazzjonijiet ta’ skalar tal-karatteristiċi personali. Riżultati esperimentali dwar is-settijiet ta’ dejta MSVD u MSR-VTT li jisfidaw juru li l-qafas tagħna jwettaq ħidma preċedenti u jwettaq b’mod robust anke fil-preżenza ta’ storbju miżjud mal-karatteristiċi u l-attributi.</abstract_mt>
      <abstract_no>Videotittel har tiltrekket aukande interesse, som delvis er det mogleg for forbetra tilgjengelighet og informasjonshenting. Mens eksisterande metodar er på ulike typar visuelle funksjonar og modellerarkitektur, brukar dei ikkje fullstendig semantiske teikn. Vi presenterer eit unifisert og utvidbare rammeverk for å samanlikna fleire typar visuelle funksjonar og semantiske attributt. Det romanarkitekturen vår bygger på LSTMs med to fleire oppmerkslag. Desse første lærer å automatisk velja dei mest salient visuelle funksjonane eller semantiske attributtane, og så gjer alle representasjonane for inndata og utdata av setningskomponenten via eigendefinerte skaleringsoperasjonar. Eksperimentale resultat på dei vanskelege MSVD- og MSR- VTT- datasetta viser at rammeverket vårt utfører tidlegare arbeid og utfører kraftig sjølv når det er lagt lyd til funksjonane og attributtane.</abstract_no>
      <abstract_pl>Podpisy wideo cieszą się coraz większym zainteresowaniem, częściowo ze względu na jego potencjał zwiększenia dostępności i pozyskiwania informacji. Chociaż istniejące metody opierają się na różnych rodzajach cech wizualnych i architekturach modeli, nie wykorzystują one w pełni odpowiednich wskazówek semantycznych. Prezentujemy ujednolicony i rozszerzalny framework, który wspólnie wykorzystuje wiele rodzajów cech wizualnych i atrybutów semantycznych. Nasza nowatorska architektura opiera się na LSTMach z dwoma wielowymiarowymi warstwami uwagi. Najpierw uczą się automatycznie wybierać najważniejsze cechy wizualne lub atrybuty semantyczne, a następnie generować ogólne reprezentacje dla wejścia i wyjścia komponentu generowania zdań za pomocą niestandardowych operacji skalowania funkcji. Wyniki eksperymentalne na wymagających zestawach danych MSVD i MSR-VTT pokazują, że nasz framework przewyższa poprzednie prace i działa solidnie nawet w obecności dodatkowego szumu do funkcji i atrybutów.</abstract_pl>
      <abstract_mn>Видео тайлбарлалт нь нэмэгдүүлэх боломжтой болон мэдээллийг авах боломжтой боломжтой болохоор илүү их сонирхолтой болсон. Хэдийгээр оршин буй арга баримтууд өөр төрлийн төрлийн үзүүлэлт болон загварын архитектур дээр байдаг ч тэд үр дүнтэй үр дүнг ашиглахгүй. Бид олон төрлийн үзүүлэлт болон semantic харилцааны чадварыг нийлүүлэхэд нэгтгэл болон өргөн хэмжээсүүд бий болгодог. Бидний шинэ архитектур LSTMs дээр олон төрлийн анхаарал давхартай байдаг. Эдгээр нь анх автоматаар хамгийн шингэн харагдаж буй харагдаж буй харагдаж, эсвэл semantic өөрчлөлтийг автоматаар сонгож суралцдаг. Тэгээд дараа нь өгүүлбэрийн үйлдвэрлэлийн компонентийн оролцоо болон гаргах үзүүлэлтийг өөр MSVD болон MSR-VTT өгөгдлийн хэмжээний шаардлагатай туршилтын үр дүнд бидний хэмжээсүүд өмнө ажил дээр ажиллаж, нэмэгдсэн чимээ болон хариултууд дээр хүртэл хүртэл хийдэг.</abstract_mn>
      <abstract_si>වීඩියෝ කැප්ටයින් විශේෂ විශේෂයෙන් වැඩි විශේෂ ප්‍රමාණයක් අල්ලගත්තා තියෙනවා, කොටසක් විශේෂ විශ වෙනස් විදියට තියෙන විදියට ප්‍රතිකෘති වර්ගයක් සහ මන්ද්‍රව්‍යාත්මක වර්ගයක් විශේෂ විදියට විශේෂ විදි අපි එකතු සහ විශේෂ ප්‍රමාණයක් පෙන්වන්නේ විශේෂ විශේෂ වර්ගයක් සහ සැමැන්තික විශේෂ වර්ගයක් සමඟ ප අපේ විද්‍යාපාර විද්‍යාපෘතියේ LSTMs වලට ගොඩක් මුහුණු අවධානය දෙකක් තියෙනවා. මේ මුලින්ම ස්වයංක්‍රමයෙන් ස්වයංක්‍රීය විශේෂ අවශ්‍යය හෝ සෙමැන්ටික් අවශ්‍යය තෝරාගන්න ස්වයංක්‍රීය විශේෂාවක MSVD සහ MSR-VTT දත්ත සූදානයේ පරීක්ෂණ ප්‍රතිචාරණ ප්‍රතිචාර විදිහට පෙන්වන්නේ අපේ පරීක්ෂණය ප්‍රතිචාරය ප්‍රතිචාර කරනවා වගේම අප</abstract_si>
      <abstract_sr>Videokapisanje privlačilo je veću količinu interesa zbog mogućnosti poboljšanja pristupnosti i prikupljanja informacija. Iako postojeće metode oslanjaju se na različite vrste vizuelnih karakteristika i modelnih arhitektura, oni ne koriste potpune semantičke znakove. Predstavljamo jedinstven i prošireni okvir da zajedno utiče na više vrsta vizualnih karakteristika i semantičnih atributa. Naša romanska arhitektura izgradi na LSTMs sa dvije višelične slojeve pažnje. Prvi su naučili da automatski izaberu najsaliènije vizualne karakteristike ili semantične atribute, a onda daju ukupne predstave za ulaz i izlaz komponenta generacije rečenica putem posebnih operacija skaliranja karakteristika. Eksperimentalni rezultati na izazovnim podacima MSVD i MSR-VTT pokazuju da naš okvir iznosi prethodni rad i čini robno čak i u prisustvu dodanog buke karakteristikama i atributima.</abstract_sr>
      <abstract_ro>Subtitrarea video a atras un interes din ce în ce mai mare, datorită în parte potențialului său de a îmbunătăți accesibilitatea și recuperarea informațiilor. Deși metodele existente se bazează pe diferite tipuri de caracteristici vizuale și arhitecturi de model, ele nu utilizează pe deplin indicii semantice pertinente. Prezentăm un cadru unificat și extensibil pentru a valorifica împreună mai multe tipuri de caracteristici vizuale și atribute semantice. Arhitectura noastră nouă se bazează pe LSTMs cu două straturi de atenție multifațete. Acestea învață mai întâi să selecteze automat cele mai importante caracteristici vizuale sau atribute semantice și apoi să producă reprezentări globale pentru intrarea și ieșirea componentei de generare a propozițiilor prin operațiuni personalizate de scalare a caracteristicilor. Rezultatele experimentale asupra seturilor de date MSVD și MSR-VTT provocatoare arată că cadrul nostru depășește lucrările anterioare și funcționează robust chiar și în prezența unui zgomot adăugat caracteristicilor și atributelor.</abstract_ro>
      <abstract_ta>வீடியோ பிடிப்பு அதிகரிக்கப்பட்ட வட்டியை வரையறுக்கிறது, இதில் ஒரு பகுதியில் அதிகப்படுத்தும் அணுகல் மற்றும் தகவல் மீட்டுதலு இருக்கும் முறைகளில் வேறு வகையான காட்சி குணங்கள் மற்றும் மாதிரி அமைப்புகளை சார்ந்திருக்கும் போது, அவர்கள் முழுமையான ப ஒருங்கிணைக்கப்பட்ட மற்றும் விரிவாக்கும் சட்டத்தை காண்பிக்கும் பல வகையான பார்வைகள் மற்றும் அரை குணங்கள். எங்கள் புதிய கட்டமைப்பு LSTMs மீது கட்டுகிறது இரண்டு பல முகத்தில் கவனம் அடுக்குகள் உள்ளது. முதலில் தானாகவே பார்வையின் குணங்களை அல்லது அரை குணங்களை தேர்ந்தெடுக்கவும், பின்னர் மொத்த குணங்களை உள்ளீடு மற்றும் வாக்கு உருவாக்கும் பொருள MSVD மற்றும் MSR- VTT தகவல் அமைப்புகளின் சோதனையின் முடிவுகள் முந்தைய வேலையை செய்து கொண்டிருக்கிறது மற்றும் குணங்கள் மற்றும் குணங்களுக்கு க</abstract_ta>
      <abstract_ur>ویڈیو کاپٹینگ نے اضافہ کی سود کی مقدار کو اضافہ کر دیا ہے، اس کے امکانات کے باعث اس کی زیادہ زیادہ زیادہ زیادہ سود ہے، جو اس کے امکانات کے لئے بہترین دستیابی اور اطلاعات اٹھانے کے لئے حاﻻنکہ موجود طریقے مختلف طریقوں کے ذریعہ نظر آور اور موڈل معماری پر اعتماد رکھتے ہیں، وه تعلق سیمانٹیکوں سے کامل استعمال نہیں کرتے۔ ہم ایک متحدہ اور پھیلا دینے والی فرمود کے لئے مختلف طریقوں کی تصویر اور سیمانٹی اثرات کے ساتھ استعمال کریں۔ ہماری روانی معماری LSTMs پر دو مختلف متوجہ لہروں کے ساتھ بنائی جاتی ہے. یہ پہلی بار اپنے ساتھ سیکھتے ہیں کہ سب سے زیادہ سائل ویزیئل ویزیئل ویزیئل ویزیئل ویزیئل ویزیئل ویزیئل ویزیئل ویزیئل یا سیمانٹی آبریٹوں کو انتخاب کریں، پھر اس کے بعد جمع طریقہ ویزیئل ویزیئل کی عملیات کے ذری MSVD اور MSR-VTT ڈاٹ سٹ کے مشکل میں جہالت کا نتیجہ دکھاتا ہے کہ ہمارا فرمود پہلے کاروبار سے زیادہ کام کرتا ہے اور اضافہ صوت کے حضور بھی زیادہ اضافہ کرتا ہے۔</abstract_ur>
      <abstract_sv>Videotextning har väckt ett ökande intresse, delvis på grund av dess potential för förbättrad tillgänglighet och informationssökning. Även om befintliga metoder bygger på olika typer av visuella funktioner och modellarkitekturer, utnyttjar de inte till fullo relevanta semantiska ledtrådar. Vi presenterar ett enhetligt och utbyggbart ramverk för att gemensamt utnyttja flera typer av visuella funktioner och semantiska attribut. Vår nya arkitektur bygger på LSTMs med två mångfacetterade uppmärksamhetslager. Dessa lär sig först automatiskt välja de mest framträdande visuella funktionerna eller semantiska attributen och ger sedan övergripande representationer för inmatning och utmatning av meningsgenereringskomponenten via anpassade funktionsskalningsåtgärder. Experimentella resultat på de utmanande MSVD- och MSR-VTT-datauppsättningarna visar att vårt ramverk överträffar tidigare arbete och presterar robust även i närvaro av extra buller till funktionerna och attributen.</abstract_sv>
      <abstract_so>Dalbashada fiidiyowgu wuxuu soo kordhay qiimo korodhsan, sababtoo ah fursado horumarinta helitaanka iyo helitaanka macluumaadka. Inta lagu jiro qaababka joogta waxay ku xiran yihiin noocyo kala duduwan oo aragtida iyo dhismaha muuqashada, ma wada isticmaalaan isticmaalka caadiga ah. Waxaynu soo bandhignaynaa shirkad la xiriiray oo aad u bannaan karto si wadajir ah u isticmaala noocyo badan oo muuqashada iyo noocyo badan. Arkitirkayaga hore wuxuu ku dhisaa LSTMs, waxayna lahaayeen laba xarumo oo aad u jeedsan. Intaasu waxay marka hore u bartaan inay iskuul ka doortaan xuquuqda aragtida ama qalabka kala duwan, markaasna waxay soo saaraan noocyada ugu wada nool ee gudaha iyo ka soo baxa qaybaha qarniga sentencegga sida loo isticmaalo qalabka iskuulka. Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms previous work and performs robustly even in the presence of added noise to the features and attributes.</abstract_so>
      <abstract_uz>Name While existing methods rely on different kinds of visual features and model architectures, they do not make full use of pertinent semantic cues.  Biz bir necha ko'plab ko'p ko'plab ko'plab ko'rinish xossalarini va semantik attributlarini bir bir bir yetarli va kengaytma freymni hozir qilamiz. Bizning novel arxituvchimiz LSTMs'da ikki ko'pgina ko'plab-qo'llangan qatlamlar bilan yaratadi. Ushbu birinchi marta foydalanuvchi parametrlar moslamalari yoki semantik xossalarini avtomatik tanlash uchun o'rganadi va keyin maxsus moslamalar qidirish amallari yordamida matn tarkibini kiritish va tugmalar tarkibini chiqarish mumkin. Comment</abstract_uz>
      <abstract_vi>Bản đánh giá ảnh đã thu hút một số lượng thú vị tăng lên, cũng vì khả năng có khả năng giúp nâng cao khả năng truy cập và thu thập thông tin. Trong khi các phương pháp tồn tại dựa trên các hình ảnh khác nhau và các kiến trúc mẫu, chúng không sử dụng đầy đủ các cách thức ngữ pháp thích hợp. Chúng tôi giới thiệu một bộ khung thống nhất và rộng mở để hợp tác tác với nhiều loại các tính năng hình ảnh và các thuộc tính ngữ pháp. Kiến trúc mới của chúng tôi dựa trên LSD với hai lớp tập trung đa mặt. Đầu tiên, chúng học tự động chọn các tính năng quan trọng nhất hay các thuộc tính theo ngữ pháp, rồi cung cấp các biểu hiện tổng thể cho phần nhập và kết của phần tạo câu đó qua các thao tác có tính nóng. Kết quả thử nghiệm của các tập tin mẫu thử thách của MSVD và MSR-VT... cho thấy rằng cơ sở dữ liệu của chúng ta vượt trội hơn những công việc trước và hoạt động mạnh mẽ, ngay cả khi có thêm nhiễu tính năng và đặc tính.</abstract_vi>
      <abstract_bg>Видео надписите привличат все по-голям интерес, отчасти поради потенциала си за подобрена достъпност и извличане на информация. Въпреки че съществуващите методи разчитат на различни видове визуални характеристики и архитектури на моделите, те не използват пълноценно съответните семантични знаци. Представяме единна и разширяема рамка за съвместно използване на множество видове визуални характеристики и семантични атрибути. Нашата нова архитектура се основава на ЛСТМ с два многостранни слоя внимание. Те първо се научават да избират автоматично най-важните визуални функции или семантични атрибути, а след това да дават общи представяния за входа и изхода на компонента за генериране на изречение чрез персонализирани операции за мащабиране на функции. Експерименталните резултати на предизвикателните набори от данни показват, че нашата рамка надминава предишната работа и работи здраво дори при наличие на добавен шум към характеристиките и атрибутите.</abstract_bg>
      <abstract_da>Videobilledtekster har tiltrukket en stigende interesse, bl.a. på grund af dets potentiale for forbedret tilgængelighed og informationssøgning. Mens eksisterende metoder er afhængige af forskellige former for visuelle funktioner og modelarkitekturer, udnytter de ikke fuldt ud relevante semantiske signaler. Vi præsenterer en samlet og udvidelig ramme til i fællesskab at udnytte flere slags visuelle funktioner og semantiske attributter. Vores nye arkitektur bygger på LSTMs med to forskellige opmærksomhedslag. Disse lærer først automatisk at vælge de mest fremtrædende visuelle funktioner eller semantiske attributter og derefter give overordnede repræsentationer for input og output af sætningsgenereringskomponenten via brugerdefinerede funktionsskaleringsoperationer. Eksperimentelle resultater på de udfordrende MSVD- og MSR-VTT-datasæt viser, at vores framework overgår tidligere arbejde og yder robust selv i tilstedeværelse af ekstra støj til funktionerne og attributterne.</abstract_da>
      <abstract_hr>Video snimanje privlačilo je povećanu količinu interesa zbog mogućnosti poboljšanja pristupnosti i prikupljanja informacija. Iako postojeće metode oslanjaju se na različite vrste vizualnih karakteristika i modelnih arhitektura, oni ne koriste punu primjenu odgovarajućih semantičkih znakova. Predstavljamo ujedinjeni i prošireni okvir da zajedno utječe na višestruke vrste vizualnih karakteristika i semantičnih atributa. Naša romanska arhitektura izgradi na LSTMs-ovima sa dvije višelicne slojeve pažnje. Prvi su naučili da automatski odaberete najsalientnije vizualne karakteristike ili semantične atribute, a zatim daju ukupne predstave za ulaz i izlaz komponenta generacije rečenica putem priličnih mjerenja funkcija. Eksperimentalni rezultati na izazovnim podacima MSVD-a i MSR-VTT-a pokazuju da naš okvir iznosi prethodni rad i čini jak čak i u prisustvu dodatne buke karakteristikama i atributima.</abstract_hr>
      <abstract_nl>Videoondertiteling heeft een toenemende belangstelling getrokken, mede vanwege het potentieel voor betere toegankelijkheid en informatieterugwinning. Hoewel bestaande methoden afhankelijk zijn van verschillende soorten visuele kenmerken en modelarchitecturen, maken ze niet volledig gebruik van relevante semantische aanwijzingen. We presenteren een uniform en uitbreidbaar framework om gezamenlijk gebruik te maken van meerdere soorten visuele kenmerken en semantische kenmerken. Onze nieuwe architectuur bouwt voort op LSTMs met twee veelzijdige aandachtslagen. Deze leren eerst om automatisch de meest opvallende visuele kenmerken of semantische attributen te selecteren, en geven vervolgens algemene representaties voor de invoer en uitvoer van de zinsgeneratie component via aangepaste feature scaling operaties. Experimentele resultaten op de uitdagende MSVD en MSR-VTT datasets tonen aan dat ons framework beter presteert dan vorig werk en robuust presteert, zelfs in aanwezigheid van extra ruis aan de functies en attributen.</abstract_nl>
      <abstract_de>Video-Untertitel haben ein wachsendes Interesse erregt, was zum Teil auf das Potenzial für verbesserte Zugänglichkeit und Informationsabruf zurückzuführen ist. Bestehende Methoden basieren zwar auf unterschiedlichen visuellen Merkmalen und Modellarchitekturen, nutzen jedoch nicht alle relevanten semantischen Hinweise. Wir präsentieren ein einheitliches und erweiterbares Framework, um gemeinsam mehrere Arten von visuellen Merkmalen und semantischen Attributen zu nutzen. Unsere neuartige Architektur baut auf LSTMs mit zwei facettenreichen Aufmerksamkeitsschichten auf. Diese lernen zunächst, die wichtigsten visuellen Merkmale oder semantischen Attribute automatisch auszuwählen und liefern dann über benutzerdefinierte Feature Scaling-Operationen Gesamtdarstellungen für die Eingabe und Ausgabe der Satzgenerationskomponente. Experimentelle Ergebnisse an den herausfordernden MSVD- und MSR-VTT-Datensätzen zeigen, dass unser Framework frühere Arbeiten übertrifft und selbst bei zusätzlichem Rauschen der Features und Attribute robust funktioniert.</abstract_de>
      <abstract_id>Video captioning telah menarik jumlah tertarik yang meningkat, sebagian karena potensi untuk memperbaiki aksesibilitas dan retrieval informasi. Meskipun metode yang ada bergantung pada berbagai jenis karakteristik visual dan arsitektur model, mereka tidak membuat penuh penggunaan tanda semantis pertinent. Kami mempersembahkan rangka yang bersatu dan bisa diperluaskan untuk bersama-sama menggunakan berbagai jenis fitur visual dan atribut semantis. Arkitektur novel kami dibangun pada LSTM dengan dua lapisan perhatian multifacet. Pertama belajar untuk memilih secara otomatis karakteristik visual yang paling penting atau atribut semantis, dan kemudian memberikan representation umum untuk masukan dan keluaran komponen generasi kalimat melalui operasi skala karakteristik suai. Hasil percobaan pada set data MSVD dan MSR-VTT menantang menunjukkan bahwa rangka kami melampaui pekerjaan sebelumnya dan bekerja dengan kuat bahkan dalam kehadiran kebisingan tambahan pada fitur dan atribut.</abstract_id>
      <abstract_ko>동영상 자막이 점점 더 많은 흥미를 끌고 있는데, 일부 원인은 접근성과 정보 검색의 잠재력을 높이기 때문이다.기존의 방법은 서로 다른 유형의 시각적 특징과 모델 구조에 의존하지만 관련 의미 단서를 충분히 이용하지 못했다.우리는 다양한 시각적 특징과 의미 속성을 연합하여 활용하기 위해 통일되고 확장 가능한 구조를 제시했다.우리의 새로운 구조는 LSTM 위에 세워져 두 가지 다방면의 주의층을 가지고 있다.그들은 먼저 가장 현저한 시각적 특징이나 의미 속성을 자동으로 선택한 다음에 사용자 정의 특징 축소 조작을 통해 문장을 생성하여 구성 요소의 입력과 출력의 전체적인 표현을 생성한다.도전적인 MSVD와 MSR-VTT 데이터 집합에서의 실험 결과에 의하면 우리의 구조는 이전의 작업보다 우수하고 특징과 속성에 추가 소음이 존재하는 상황에서도 좋은 성능을 가진다.</abstract_ko>
      <abstract_tr>Video gaýşartmak üçin ýeterli elýeterlik we maglumatlary almak üçin köpüsi gyzyklanýar. Öň bar yöntemler farklı görsel hatlary we nusgalary üçin ynanýarlar. Olar semantik hatlaryny doly ulanmaýarlar. Biz birnäçe görsel hatlary we semantik hatlaryny bir arada çykarmak üçin bir birleşik we uzaklyk bir çerçewçiliki görkeýäris. Biziň roman arhitekturymyz LST-larynda birnäçe çenli üns gaty bilen guruldy. Bu ilkinji görsel möhümatlary ýa-da semantik atributleri otomatik saýlamak öwrenip, soňra sözlem döredijili komponentiň girdi we çizmesi üçin häzirki möhüm möhüm eserleri bilen üýtget edip bilýär. MSVD we MSR</abstract_tr>
      <abstract_fa>عنوان ویدئو یک مقدار بیشتری از سود را جذب کرده است که بخشی از پتانسیل آن برای بهتر دسترسی و بازیابی اطلاعات است. در حالی که روش‌های موجود به نوع‌های ویژه‌های دیده‌ای و معماری‌های مدل اعتماد دارند، آنها کامل از نشانه‌های سنتی‌ای استفاده نمی‌کنند. ما یک چهارچوب متحد و قابل تغییر قرار می دهیم تا با همدیگر از نوع ویژه های دیده و ویژه های semantic را تغییر دهیم. معماری رمانی ما روی LSTMs با دو طبقه متفاوت توجه می سازد. اینها اولین بار یاد می گیرند که از طریق عملکرد مقیاس ویژه‌های ویژه‌های ویژه‌ای یا ویژه‌های سیمانتیک‌ترین ویژه‌های خود انتخاب کنند، و سپس تمام نمایش‌های واژه‌های ورودی و نتیجه‌ی ویژه‌های تولید جمله نتیجه‌های تجربه روی مجموعه داده‌های MSVD و MSR-VTT‌ها نشان می‌دهند که چهارچوب ما کار قبلی را انجام می‌دهد و حتی در حضور صدا اضافه می‌شود به ویژه‌های و ویژه‌های مختلف.</abstract_fa>
      <abstract_af>Videotitel het 'n vergroot hoeveelheid belang aantrek, gevolg in deel aan sy potensieel vir verbeterde toegang en inligting ontvang. Alhoewel bestaande metodes op verskillende soorte visuele funksies en model arkitektuure vertrou, maak hulle nie volle gebruik van pertinent semantiese tekens nie. Ons stel 'n eenvoudige en uitbreidige raamwerk om meerdere soorte visuele eienskappe en semantiese eienskappe saamgewys te maak. Ons nuwe arkitektuur bou op LSTMs met twee multi-gesig aandag-laag. Hierdie eerste leer na outomaties kies die mees salient visuele funksies of semantiese eienskappe, en dan gee gewone voorstellings vir die invoer en uitvoer van die setgeslag komponent deur pasmaak funksieskaling operasies. Eksperimentale resultate op die uitgelykende MSVD en MSR-VTT-datastelle vertoon dat ons raamwerk vooraf werk uitvoer en uitvoer kragtig selfs in die teenwoordigheid van bygevoeg ruis aan die funksies en eienskappe.</abstract_af>
      <abstract_sw>Kuelelewa kwa video imevutia ongezeko la maslahi, kwa sababu ya uwezekano wake wa kuboresha upatikanaji na upatikanaji wa taarifa. Wakati mbinu zilizopo zinategemea aina mbalimbali za kuona na majengo ya model, hawatumii vifaa vinavyohusiana. Tunaweza kutengeneza mfumo wa pamoja na uwezekano wa kiwango kikubwa cha kuona pamoja na vipengele vya semantic. Ujengo wetu wa riwaya unajenga kwenye viwanja vya LSTMs ikiwa na vipande viwili vinavyozungumza. Hawa wanajifunza kwa mara ya kwanza kujichagua vipengele vya kuona au vifaa vya sekunde vinavyosalimika zaidi, na kisha kutoa maoni ya jumla kwa ajili ya input na matokeo ya kizazi cha hukumu kwa kutumia shughuli za uchaguzi. Matokeo ya majaribio yanayohusu changamoto za taarifa za MSVD na MSR-VTT zinaonyesha kuwa mfumo wetu unafanya kazi zilizopita na kufanya kazi za kibinafsi hata katika kuwepo kwa sauti zinazoongezeka kwa tabia na vifaa.</abstract_sw>
      <abstract_hy>Տեսագրության վերնագրությունը գրավել է աճող հետաքրքրություն, մասամբ այն պոտենցիալի պատճառով, որ այն կարող է բարելավել հասանելիությունը և տեղեկատվությունը վերցնել: Մինչդեռ գոյություն ունեցող մեթոդները հիմնված են տարբեր տեսողական հատկանիշների և մոդելների ճարտարապետության վրա, դրանք չեն օգտագործում ամբողջությամբ համապատասխան սեմանտիկ նշաններ: Մենք ներկայացնում ենք միավոր և ընդլայնելի շրջանակ, որպեսզի միասին օգտագործենք բազմաթիվ տեսողական առանձնահատկություններ և սեմանտիկ առանձնահատկություններ: Մեր նոր ճարտարապետությունը կառուցվում է LSMT-ների վրա, որոնք ունեն երկու բազմակողմնակի ուշադրության շերտեր: Սկզբում նրանք սովորում են ինքնաբերաբար ընտրել ամենակարևոր տեսողական հատկանիշները կամ սեմանտիկ առանձնահատկանիշները, ապա տալիս են ընդհանուր ներկայացումներ նախադասությունների ստեղծման բաղադրամի ներմուծի և արտադրման համար անհատական հատկանի Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms previous work and performs robustly even in the presence of added noise to the features and attributes.</abstract_hy>
      <abstract_az>Video qismini artırmaq üçün artırmaq üçün artırmaq məlumatı tələb etdi. Halbuki mövcud metodlar müxtəlif şəkildə və modeli arhitektürlərə təvəkkül edirlər, onlar müxtəlif semantik məqsədlərdən tam istifadə etməzlər. Biz birçoxlu cür görsel mövzuları və semantik qüdrətlərini birlikdə istifadə etmək üçün birləşdirilmiş və genişliyi bir framework ü göstəririk. Bizim roman arhitektarımız LSTMs-lərə iki çox üzlü ünsiyyət səviyyəsi ilə inşa edir. Bunlar ilk dəfə ən çətin görünüş xüsusiyyətləri ya da semantik xüsusiyyətləri seçməyi öyrənirlər, sonra da cümlənin yaratdığı komponentin girdi və çıxışını özlük xüsusiyyətlərin ölçü işləri vasitəsilə müəyyən edirlər. MSVD və MSR-VTT verilənlərin çətinlikləri üzərində təcrübə sonuçları əvvəlki işlərimizin üstünə çıxartdığını göstərər və fəaliyyətlərə və qüvvətlərə çox gürültü olaraq hətta güclü səs göstərər.</abstract_az>
      <abstract_sq>Titullimi i videos ka tërhequr një sasi në rritje interesi, pjesërisht për shkak të potencialit të tij për përmirësimin e aksesibilitetit dhe marrjes së informacionit. Ndërsa metodat ekzistuese mbështeten në lloje të ndryshme karakteristike vizuale dhe arkitektura modelesh, ato nuk përdorin plotësisht shenjat semantike të përshtatshme. Ne paraqesim një kuadër të unifikuar dhe të zgjerueshëm për të përdorur së bashku shumë lloje karakteristike vizuale dhe atribute semantike. Arkitektura jonë e re ndërton në LSTM me dy shtresa vëmendjeje shumë-faqe. Këto mësojnë së pari të zgjedhin automatikisht karakteristikat më të rëndësishme vizuale apo atributet semantike dhe pastaj të japin përfaqësime të përgjithshme për hyrjen dhe daljen e komponentit të gjenerimit të fjalëve nëpërmjet operacioneve të caktuara të shkallimit të funksioneve. Rezultatet eksperimentale mbi sërat e vështira të të dhënave MSVD dhe MSR-VTT tregojnë se kuadri ynë kryen punën e mëparshme dhe funksionon me forcë edhe në praninë e zhurmës së shtuar të karakteristikave dhe atributeve.</abstract_sq>
      <abstract_bn>ভিডিও ক্যাপ্টেশন বাড়তে থাকা সুবিধা বৃদ্ধির আকর্ষণ করেছে, কারণ এর সম্ভাবনার কারণে প্রবেশ এবং তথ্য পুনরুদ্ধারের সম্ভাবনা। বিদ্যমান পদ্ধতি বিভিন্ন ধরনের দৃশ্যমান বৈশিষ্ট্য এবং মডেল স্থাপনের উপর নির্ভর করে, কিন্তু তারা সম্পূর্ণ সেমেন্টিক কুয়ের আমরা একত্রিত এবং ব্যাপকভাবে একটি ফ্রেম উপস্থাপন করেছি যাতে সাথে যুক্ত করে বেশ কয়েকটি ধরনের দৃষ্টিভঙ্গি এবং সেম্যান্ট আমাদের উপন্যাস কাঠামো এলস্টিএমসে বানানো হয়েছে দুই মাল্টিমুখোমুখি কাঠামো দিয়ে। এগুলো প্রথমে স্বয়ংক্রিয়ভাবে বেছে নিতে শিখতে পারে সবচেয়ে বেশী বিশেষ দৃশ্য বৈশিষ্ট্য অথবা সেম্যান্টিক বৈশিষ্ট্য বৈশিষ্ট্য বৈশিষ্ট্য এমএসভিডি এবং এমএসআর-ভিটিটি ডাটাসেটের চ্যালেঞ্জের ফলাফল দেখাচ্ছে যে আমাদের ফ্রেমার্কার পূর্ববর্তী কাজের আয়োজন করে এবং বৈশিষ্ট্য ও বৈশিষ</abstract_bn>
      <abstract_am>የቪዲዮ አቀማመጥ የሚጨምረው የውጤት ማቀናቀል ነው፡፡ የሥልጣን ሥርዓቶች በተለያዩ ዓይነቶች እና ሞዴል አካካውንት ላይ ይታመናሉ፡፡ በተለያዩ የዓይነቶች እና የsemantic አካላት እና በተለያዩ የዓይነቶች ፍሬማርዎችን እናስቀራለን፡፡ አረንጓዴያችን የመዝገብ ግንኙነታችንን በሁለት የዓይነት መልዕክቶች ላይ ይሠራል፡፡ እነዚህም አስቀድመው የሚያስተምሩ የዓይነቶች ምርጫዎች ወይም የsemantic ምርጫዎች ለመምረጡ ይማራሉ፤ ከዚያም በኋላ ለጥቅምት እና የመክፈት ትውልድ ክፍተቶችን በመጠቀም የመስመር ማቀናጃ ማቀናጃ ማቀናጃ ነው፡፡ የMSVD እና አሜስR-VTT ዳታዎችን በሚያቃጥሉ ውጤቶች ፍሬማችን የቀድሞውን ሥራ እንዲያሳየው እና የድምፅ ድምፅ እና የፊደሎችን ድምፅ በሚጨምርበት ውጤት ላይ እንኳ በተጨማሪም ድምፅ እንዲያደርጋል ያሳያል፡፡</abstract_am>
      <abstract_ca>La captura del vídeo ha atraït un interès cada vegada més gran, en part degut al seu potencial d'accesibilitat millorada i recuperació d'informació. Mentre que els mètodes existents depenen de diferents tipus de característiques visuals i arquitectures models, no utilitzen plenament les indicacions semàntiques pertinents. We present a unified and extensible framework to jointly leverage multiple sorts of visual features and semantic attributes.  La nostra nova arquitectura es basa en LSTMs amb dues capes d'atenció multifacetades. Aquests primers aprenen a seleccionar automàticament les característiques visuals més salients o atributs semàntics, i després donen representacions globals per a l'entrada i la sortida del component de generació de frases mitjançant operacions d'escala de característiques personalitzades. Els resultats experimentals dels desafiants conjunts de dades MSVD i MSR-VTT mostren que el nostre marc supera la feina anterior i funciona de manera robusta fins i tot en presencia de soroll afegit a les característiques i atributs.</abstract_ca>
      <abstract_cs>Video titulky přitahují stále větší zájem, částečně kvůli jeho potenciálu pro lepší přístupnost a vyhledávání informací. Zatímco existující metody spoléhají na různé druhy vizuálních rysů a modelových architektur, nevyužívají plně relevantní sémantické návody. Představujeme jednotný a rozšiřitelný rámec, který společně využívá více druhů vizuálních prvků a sémantických atributů. Naše nová architektura staví na LSTMs se dvěma mnohostrannými vrstvami pozornosti. Ty se nejprve naučí automaticky vybrat nejvýznamnější vizuální prvky nebo sémantické atributy a pak vytvářejí celkové reprezentace pro vstup a výstup komponenty generování vět prostřednictvím vlastních operací škálování funkcí. Experimentální výsledky na náročných datových sadách MSVD a MSR-VTT ukazují, že náš framework překonává předchozí práci a funguje robustně i v přítomnosti přidaného šumu funkcí a atributů.</abstract_cs>
      <abstract_fi>Videotekstitys on herättänyt yhä enemmän kiinnostusta, mikä johtuu osittain sen mahdollisuuksista parantaa saavutettavuutta ja tiedonhakua. Vaikka nykyiset menetelmät perustuvat erilaisiin visuaalisiin ominaisuuksiin ja malliarkkitehtuuriin, niissä ei hyödynnetä täysin olennaisia semanttisia vihjeitä. Esittelemme yhtenäisen ja laajennettavan kehyksen, jolla voidaan yhdessä hyödyntää erilaisia visuaalisia ominaisuuksia ja semanttisia attribuutteja. Uusi arkkitehtuurimme perustuu LSTMs:iin, joissa on kaksi monitahoista huomiokerrosta. Nämä oppivat ensin valitsemaan automaattisesti tärkeimmät visuaaliset ominaisuudet tai semanttiset attribuutit ja tuottavat sitten lauseen luontikomponentin syötteen ja tuotoksen yleiset esitykset mukautettujen ominaisuuksien skaalaustoimenpiteiden avulla. Kokeelliset tulokset haastavista MSVD- ja MSR-VTT-aineistoista osoittavat, että runkomme suoriutuu edellisistä töistä ja toimii lujasti myös ominaisuuksiin ja attribuutteihin lisätyn kohinan vallitessa.</abstract_fi>
      <abstract_et>Videopealdiste tegemine on suurendanud huvi, osaliselt tänu võimalusele parandada ligipääsetavust ja teabe hankimist. Kuigi olemasolevad meetodid tuginevad erinevatele visuaalsetele omadustele ja mudeliarhitektuuridele, ei kasuta nad täielikult ära asjakohaseid semantilisi vihjeid. Esitame ühtse ja laiendatava raamistiku, et ühiselt kasutada mitmesuguseid visuaalseid funktsioone ja semantilisi atribuute. Meie uudne arhitektuur põhineb kahe mitmekülgse tähelepanukihiga LSTMdel. Kõigepealt õpivad nad automaatselt valima kõige silmapaistvamaid visuaalseid funktsioone või semantilisi atribuute ning seejärel looma kohandatud funktsioonide skaleerimise toimingute kaudu lausegeneratsiooni komponendi sisendi ja väljundi üldised esitused. Eksperimentaalsed tulemused keerukate MSVD ja MSR-VTT andmekogumite kohta näitavad, et meie raamistik ületab varasemaid tööd ja toimib usaldusväärselt isegi funktsioonidele ja atribuutidele lisatud müra olemasolul.</abstract_et>
      <abstract_bs>Video snimanje privlačilo je povećanu količinu interesa koji je dio mogućnosti poboljšavanja pristupnosti i prikupljanja informacija. Iako postojeće metode oslanjaju se na različite vrste vizuelnih karakteristika i modelnih arhitektura, ne koriste potpune semantičke znakove. Predstavljamo jedinstven i prošireni okvir da zajedno utiče na više vrsta vizualnih karakteristika i semantičnih atributa. Naša romanska arhitektura izgradi na LSTMs sa dvije višelične slojeve pažnje. Prvi su naučili da automatski izaberu najsalijentne vizualne karakteristike ili semantične atribute, a onda daju ukupne predstave za ulaz i izlaz komponenta generacije rečenica putem posebnih operacija skaliranja karakteristika. Eksperimentalni rezultati na izazovnim podacima MSVD-a i MSR-VTT-a pokazuju da naš okvir iznosi prethodni rad i provodi jak čak i u prisustvu dodanog buke na karakteristike i atribute.</abstract_bs>
      <abstract_jv>Video caption Along sampeyan sistem sing perusahaan dengané kapan akeh liyane lan akeh-akeh model, kuwi nggawe barang sistem sing perusahaan semantar kuwi. Awak dhéwé éntukno sistem sing beraksi lan tambahan kanggo nggawe akeh liyane karo akeh penting lan atiribute semantar Awak dhéwé nyupir architecture sing nggawe barang kelas iki sampek multi-sampek sing ngawe barang nggawe barang. First letter Laptop" and "Desktop</abstract_jv>
      <abstract_sk>Video napisovanje je pritegnilo vse več zanimanja, deloma zaradi potenciala za boljšo dostopnost in pridobivanje informacij. Medtem ko obstoječe metode temeljijo na različnih vrstah vizualnih značilnostih in arhitekturah modelov, ne uporabljajo v celoti ustreznih semantičnih namigov. Predstavljamo enoten in razširljiv okvir za skupno izkoriščanje več vrst vizualnih značilnosti in semantičnih atributov. Naša nova arhitektura gradi na LSTMs z dvema večplastnima slojema pozornosti. Ti se najprej naučijo samodejno izbrati najpomembnejše vizualne funkcije ali semantične atribute, nato pa zagotovijo splošne predstavitve za vnos in izhod komponente za ustvarjanje stavka prek operacij povečanja funkcij po meri. Eksperimentalni rezultati zahtevnih naborov podatkov MSVD in MSR-VTT kažejo, da naš okvir presega prejšnje delo in deluje zanesljivo tudi ob prisotnosti dodanega hrupa funkcijam in atributom.</abstract_sk>
      <abstract_ha>Sura fanikin video ya nuna kima mai ƙãra riba, owa cikin rabo da ya yi amfani da mataimaki ya fi kyau a sami motsi da masu motsi. While existing methods rely on different kinds of visual features and model architectures, they do not make full use of pertinent semantic cues.  Tuna halatar da firam masu haɗi da wanda ke faɗa wa kodi masu tsari masu gani da halin na semantiki. An samar layin nan da ke samar a kan LSM da zane-zane biyu biyu. Wannan suna da amfani da ɗabi'a don ka zãɓi mafiya sali masu basu'in gani farat ɗaya ko kiyayen halin na semantic, sa'an nan ka ƙara masu motsi da mazaɓa wa shiga da fitarwa na ƙarshen ƙanni da ke amfani da aikin canza masu ƙayyade na amfani da ɗabi'a. Tajararin matsala a kan masu tsõratar da masu motsi na mazaɓa wa masu motsi na mazaɓa na mazaɓa da mazaɓa na zaman aikin da kuma yana aikin ransa, ko kuma don idan ana presence da sau na ƙari zuwa ga tabofati da halin.</abstract_ha>
      <abstract_he>צילום וידאו משך כמות גדולה של עניין, בשל חלק פוטנציאל שלה לשיפור גישה ומידע. בעוד שיטות קיימות תלויות בסוגים שונים של תכונות ויזואליות וארכיטקטורות דוגמניות, הן לא משתמשות במלוא בסימנטיות רלוונטיות. אנו מציגים מסגרת מאוחדת ומתוארת כדי להשתמש ביחד במספר סוגים של תכונות ויזואליות ותכונות סמנטיות. הארכיטקטורה הרומנית שלנו בונה על LSTMs עם שתי שכבות תשומת לב רבות פנים. These first learn to automatically select the most salient visual features or semantic attributes, and then yield overall representations for the input and output of the sentence generation component via custom feature scaling operations.  תוצאות ניסיוניות על קבוצות נתונים MSVD ומתאגרים MSR-VTT מראות שהמסגרת שלנו עובדת יותר בעבודה קודמת ומופקדת בצורה חזקה אפילו בנוכחות הרעש המווסף לתחומים והתכונות.</abstract_he>
      <abstract_bo>བརྙན་གཟུགས་འགྲེལ་བཤད་ཀྱིས་མཐུན་སྤྱོད་རྒྱུ་དང་གནས་ཚུལ་ཉར་རྒྱུ་དང་མཐུན་རྐྱེན་ཡར་རྒྱས་གཏོང་བྱས་ཡོད། གནས་ཡུལ་གྱི་ཐབས་ལམ་དེ་མིན་འདུག ང་ཚོས་ཀྱིས་མཐོང་ཆོས་དང་རྒྱ་བསྐྱེད་པའི་གཞུང་སྒྲིག་གཅིག་གི་མཐོང་སྣང་དང་semantic ཁྱད་ཆོས་མང་པོ་སྤྱད་ནས་བསྡུར་བ་ཡ ང་ཚོའི་གསར་གཏོད་བཟོ་བརྩིས་གཞི་སྒྲིག་ཆ་ཁང་གིས་སྣ་གདོང་ཅན་གྱི་བཟའ་བ་གཉིས་ཡོད་པ་རེད། These first learn to automatically select the most salient visual features or semantic attributes, and then yield overall representations for the input and output of the sentence generation component via custom feature scaling operations. MSVD དང་MSR-VTT གནད་དོན་དགོས་པའི་ལས་འགན་འགྲུལ་གྱི་ཕྱོགས་སྟོན་བྱུང་ན་ང་ཚོའི་གཞི་ཁུང་གིས་གནད་དོན་གྱི་ལས་འགན་སྟངས་ལ་འགྱུར་བ་དང་བརྟན་སྟབས</abstract_bo>
      </paper>
    <paper id="15">
      <title>Knowledge Completion for Generics using Guided Tensor Factorization</title>
      <author><first>Hanie</first><last>Sedghi</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <doi>10.1162/tacl_a_00015</doi>
      <abstract>Given a <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> or <a href="https://en.wikipedia.org/wiki/Knowledge_base">KB</a> containing (noisy) facts about common nouns or generics, such as all trees produce oxygen or some animals live in forests, we consider the problem of inferring additional such facts at a precision similar to that of the starting KB. Such KBs capture general knowledge about the world, and are crucial for various <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> such as <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>. Different from commonly studied named entity KBs such as <a href="https://en.wikipedia.org/wiki/Freebase">Freebase</a>, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA). We show that existing KB completion methods struggle with this new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, and present the first approach that is successful. Our results demonstrate that external information, such as relation schemas and <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity taxonomies</a>, if used appropriately, can be a surprisingly powerful tool in this setting. First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80 % precise) for science, doubling their size at 74%86 % precision. Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract>
      <pages>197–210</pages>
      <url hash="855b68bb">Q18-1015</url>
      <video href="https://vimeo.com/276898240" />
      <bibkey>sedghi-sabharwal-2018-knowledge</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
    <title_ar>إتمام المعرفة في علم الوراثة باستخدام عامل الموتر الموجه</title_ar>
      <title_pt>Conclusão de Conhecimento para Genéricos usando Fatoração Tensor Guiada</title_pt>
      <title_fr>Compléter les connaissances pour les génériques à l'aide de la factorisation tensorielle</title_fr>
      <title_es>Finalización de conocimientos para genéricos mediante factorización guiada de tensores</title_es>
      <title_ja>誘導テンソル因子化を使用したジェネリックのための知識補完</title_ja>
      <title_zh>用导张量分解者泛型知成</title_zh>
      <title_hi>निर्देशित टेंसर फैक्टराइजेशन का उपयोग करके जेनेरिक के लिए ज्ञान पूरा करना</title_hi>
      <title_ru>Завершение знаний о дженериках с использованием коэффициента управляемого тензора</title_ru>
      <title_ga>Críochnú Eolais le haghaidh Cineálach ag baint úsáide as Fachtóiriú Teannas Treoraithe</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Ολοκλήρωση γνώσεων για τα γενόσημα με τη χρήση καθοδηγούμενης παραγόμενης τάσης</title_el>
      <title_lt>Knowledge Completion for Generics using Guided Tensor Factorization</title_lt>
      <title_it>Completamento delle conoscenze per i farmaci generici utilizzando la factorizzazione guidata della tensione</title_it>
      <title_kk>Бағытталған тенсор факторизациясын қолданып жалпы жалпы мәліметтердің толтыруы</title_kk>
      <title_mk>Дополнување на знаење за генерика со управувана тензорска факторизација</title_mk>
      <title_hu>Tudás kiegészítése generikus gyógyszerek számára irányított feszültségfaktorozással</title_hu>
      <title_ml>ഗൈഡ് ടെന്‍സര്‍ ഫാക്റ്റോററിഷന്‍ ഉപയോഗിച്ച് ജെനററികള്‍ക്കുള്ള അറിവ് പൂര്‍ത്തിയാക്കുക</title_ml>
      <title_mt>Tlestija tal-Għarfien għall-Ġenerika bl-użu ta’ Fattorizzazzjoni tat-Tensor Gwida</title_mt>
      <title_ms>Knowledge Completion for Generics using Guided Tensor Factorization</title_ms>
      <title_ro>Completarea cunoștințelor pentru medicamente generice folosind factorizarea de tensiune ghidată</title_ro>
      <title_mn>Цахилгаан Тенсор Фактерикацийг ашиглан Генерикийн мэдлэг дуусгал</title_mn>
      <title_pl>Zakończenie wiedzy dla leków generycznych przy użyciu kierowanej faktoryzacji napinacza</title_pl>
      <title_si>Name</title_si>
      <title_so>Dhameynta aqoonta generic using haged Tensor Factorization</title_so>
      <title_sv>Kunskapskomplettering för generika med hjälp av styrd spänningsfaktorisering</title_sv>
      <title_ta>தேர்ந்தெடுக்கப்பட்ட பத்திரிகையை பயன்படுத்தி அறிவு முடிவு</title_ta>
      <title_sr>Završenje znanja za generike koristeći navedenu tenzorsku fabrikaciju</title_sr>
      <title_ur>Name</title_ur>
      <title_no>Kvitensfullføring for generelle brukar hjelpelinjeringsfakterisering</title_no>
      <title_uz>Name</title_uz>
      <title_vi>Hoàn chỉnh tri thức cho Chung dùng Độ bền dẫn đại số</title_vi>
      <title_bg>Завършване на знанията за генерични лекарства с помощта на ръководена факторизация на напрежението</title_bg>
      <title_de>Wissensergänzung für Generika mittels geführter Tensor Factorization</title_de>
      <title_id>Penyempurnaan Pengetahuan untuk Generik menggunakan Faktorisasi Tensor Dipandang</title_id>
      <title_nl>Kennisvoltooiing voor generica met behulp van geleide tensor factorization</title_nl>
      <title_fa>Completion of Knowledge for Generics using Guided Tensor Factorization</title_fa>
      <title_sw>Kutimiza maarifa kwa ajili ya Umoja kwa kutumia Ukatili wa Kitibu kinachoongozwa</title_sw>
      <title_da>Videnskabsfuldførelse for generiske lægemidler ved hjælp af guidet spændingsfaktor</title_da>
      <title_hr>Završenje znanja za generale koristeći vodeći tenzorski faktorizaciju</title_hr>
      <title_sq>Përfundimi i njohurive për gjenerikën duke përdorur faktorizimin e tensionit të udhëzuar</title_sq>
      <title_tr>Gürjükli Tensor Faýletimi ullanýan Umumy üçin Bilgi Tamamlama</title_tr>
      <title_ko>유도 장량 인자 분해에 기초한 범용 지식 완비</title_ko>
      <title_am>undo-type</title_am>
      <title_az>䝥摩얟汩⁔敮獯爠䙡歴潲楳楹慳쒱滄넠楳瑩晡擉餠敤즙渠䝥湥物歬즙爠쎼쎧쎼渠䉩汩洠瑡浡浬慭愊</title_az>
      <title_af>Name</title_af>
      <title_bn>গাইড টেনসার ফ্যাক্টরিশন ব্যবহার করে জ্ঞান সম্পূর্ণ</title_bn>
      <title_hy>Knowledge Completion for Generics using Guided Tensor Factorization</title_hy>
      <title_bs>Završenje znanja za generike koristeći vodeću tenzorsku fabrikaciju</title_bs>
      <title_fi>Geneeristen lääkkeiden tietämyksen täydennys ohjatulla jännitekerrorisoinnilla</title_fi>
      <title_ca>Completació del coneixement per a la genèrica utilitzant la fabricació de tensors orientats</title_ca>
      <title_cs>Doplňování znalostí pro generická léčiva pomocí řízené faktorizace Tensoru</title_cs>
      <title_et>Teadmiste täiendamine geneeriliste ravimite jaoks, kasutades juhendatud pingutusfaktorisatsiooni</title_et>
      <title_ha>@ action</title_ha>
      <title_jv>Kumpilan Bilih kanggo Generik kang Gambar Tipe Tenor Fakturi</title_jv>
      <title_he>Knowledge Completion for Generics using Guided Tensor Factorization</title_he>
      <title_sk>Dopolnjevanje znanja za generične zdravila z vodeno faktorizacijo napetosti</title_sk>
      <title_bo>Guided Tensor Factorization སྤྱོད་པའི་སྤྱིར་བཏང་གི་ཆ་རྐྱེན་ལ་མཇུག་བསྡུས་པ</title_bo>
      <abstract_ar>نظرًا لقاعدة المعرفة أو قاعدة المعارف التي تحتوي على حقائق (صاخبة) حول الأسماء الشائعة أو الأدوية الجنيسة ، مثل "كل الأشجار تنتج الأكسجين" أو "تعيش بعض الحيوانات في الغابات" ، فإننا نعتبر مشكلة استنتاج مثل هذه الحقائق الإضافية بدقة مماثلة لتلك الخاصة بـ البداية KB. تلتقط قواعد المعارف هذه المعرفة العامة حول العالم ، وهي ضرورية للعديد من التطبيقات مثل الإجابة على الأسئلة. تختلف قواعد KBs للكيانات التي تمت دراستها بشكل شائع مثل Freebase ، حيث تشتمل قواعد KB الخاصة بالأدوية العامة على القياس الكمي ، ولها انتظام أساسي أكثر تعقيدًا ، وتميل إلى أن تكون غير كاملة ، وتنتهك افتراض العالم المغلق محليًا (LCWA). نظهر أن أساليب إكمال قاعدة المعارف الحالية تكافح مع هذه المهمة الجديدة ، ونقدم الطريقة الأولى الناجحة. توضح نتائجنا أن المعلومات الخارجية ، مثل مخططات العلاقات وتصنيفات الكيانات ، إذا تم استخدامها بشكل مناسب ، يمكن أن تكون أداة قوية بشكل مدهش في هذا الإعداد. أولاً ، يحقق نهج عامل التنسور الموجه بالمعرفة البسيطة والفعالة نتائج متطورة على اثنين من وحدات KBs العامة (دقة 80٪) للعلوم ، مما يضاعف حجمهما بدقة 74٪ -86٪. ثانيًا ، تعد طريقة التعلم النشط والموجهة تحت النموذجية الخاصة بنا لجمع التعليقات التوضيحية حول الكيانات النادرة (على سبيل المثال ، oriole ، الطيور) أكثر فاعلية بمقدار 6 أضعاف في استنتاج المزيد من الحقائق الجديدة عنها مقارنة بخطوط الأساس المتعددة للتعلم النشط.</abstract_ar>
      <abstract_fr>Étant donné une base de connaissances ou une base de connaissances contenant des faits (bruyants) sur des noms communs ou des génériques, tels que « tous les arbres produisent de l'oxygène » ou « certains animaux vivent dans les forêts », nous examinons le problème de la déduction de tels faits supplémentaires avec une précision similaire à celle du KB de départ. Ces bases de connaissances recueillent des connaissances générales sur le monde et sont cruciales pour diverses applications telles que la réponse aux questions. Différentes des KB d'entités nommées couramment étudiées telles que Freebase, les KB génériques impliquent une quantification, ont des régularités sous-jacentes plus complexes, ont tendance à être plus incomplètes et violent l'hypothèse de monde fermé localement (LCWA) couramment utilisée. Nous montrons que les méthodes de complétion de la base de connaissances existantes ont du mal à effectuer cette nouvelle tâche et présentons la première approche qui fonctionne. Nos résultats démontrent que les informations externes, telles que les schémas de relations et les taxonomies d'entités, si elles sont utilisées de manière appropriée, peuvent constituer un outil étonnamment puissant dans ce contexte. Tout d'abord, notre approche simple mais efficace de factorisation des tenseurs guidée par les connaissances permet d'obtenir des résultats de pointe sur deux KB génériques (précis à 80 %) pour la science, doublant leur taille à une précision de 74 % à 86 %. Deuxièmement, notre nouvelle méthode d'apprentissage actif sous-modulaire, guidée par la taxonomie, pour collecter des annotations sur des entités rares (par exemple, un oriole, un oiseau) est 6 fois plus efficace pour déduire de nouveaux faits supplémentaires à leur sujet que de multiples bases d'apprentissage actif.</abstract_fr>
      <abstract_es>Dada una base de conocimientos o KB que contiene datos (ruidosos) sobre sustantivos comunes o genéricos, como «todos los árboles producen oxígeno» o «algunos animales viven en bosques», consideramos el problema de inferir hechos adicionales con una precisión similar a la del KB inicial. Estos KB capturan el conocimiento general sobre el mundo y son cruciales para diversas aplicaciones, como la respuesta a preguntas. A diferencia de las KB de entidades nombradas comúnmente estudiadas, como Freebase, las KB genéricas implican cuantificación, tienen regularidades subyacentes más complejas, tienden a ser más incompletas e infringen la suposición de mundo cerrado local (LCWA) comúnmente utilizada. Demostramos que los métodos de finalización de la base de conocimientos existentes tienen problemas con esta nueva tarea y presentamos el primer enfoque que tiene éxito. Nuestros resultados demuestran que la información externa, como los esquemas de relaciones y las taxonomías de entidades, si se usa adecuadamente, puede ser una herramienta sorprendentemente poderosa en este contexto. En primer lugar, nuestro enfoque de factorización de tensores guiado por el conocimiento, simple pero eficaz, logra resultados de vanguardia en dos KB genéricos (80% de precisión) para la ciencia, duplicando su tamaño con una precisión del 74 al 86%. En segundo lugar, nuestro novedoso método de aprendizaje activo, submodular y guiado por taxonomía para recopilar anotaciones sobre entidades raras (por ejemplo, oropéndola, un pájaro) es 6 veces más eficaz a la hora de inferir nuevos datos sobre ellas que múltiples líneas de base de aprendizaje activo.</abstract_es>
      <abstract_pt>Dada uma base de conhecimento ou KB contendo fatos (ruidosos) sobre substantivos comuns ou genéricos, como “todas as árvores produzem oxigênio” ou “alguns animais vivem em florestas”, consideramos o problema de inferir esses fatos adicionais com uma precisão semelhante à de o KB inicial. Esses KBs capturam conhecimento geral sobre o mundo e são cruciais para várias aplicações, como respostas a perguntas. Diferentemente das KBs de entidades nomeadas comumente estudadas, como o Freebase, as KBs genéricas envolvem quantificação, têm regularidades subjacentes mais complexas, tendem a ser mais incompletas e violam a suposição de mundo localmente fechado (LCWA) comumente usada. Mostramos que os métodos de preenchimento de KB existentes enfrentam essa nova tarefa e apresentamos a primeira abordagem bem-sucedida. Nossos resultados demonstram que informações externas, como esquemas de relação e taxonomias de entidades, se usadas adequadamente, podem ser uma ferramenta surpreendentemente poderosa nesse cenário. Primeiro, nossa abordagem de fatoração tensorial guiada por conhecimento simples, mas eficaz, alcança resultados de última geração em dois KBs genéricos (80% de precisão) para ciência, dobrando seu tamanho com precisão de 74% a 86%. Em segundo lugar, nosso novo método de aprendizado ativo, submodular e guiado por taxonomia para coletar anotações sobre entidades raras (por exemplo, oriole, um pássaro) é 6x mais eficaz em inferir novos fatos sobre eles do que várias linhas de base de aprendizado ativo.</abstract_pt>
      <abstract_ja>「すべての木は酸素を生成する」や「一部の動物は森林に住む」など、一般的な名詞やジェネリックに関する（騒々しい）事実を含む知識ベースまたはKBを考慮すると、開始KBと同様の精度で追加の事実を推測する問題を考慮します。 このようなKBは、世界に関する一般的な知識を捉え、質問への回答などのさまざまなアプリケーションにとって重要です。 Freebaseのような一般的に研究されている名前付きエンティティKBとは異なり、ジェネリックKBは定量化を伴い、より複雑な基礎的規則性を有し、より不完全である傾向があり、一般的に使用されているローカルクローズドワールド仮定（ LCWA ）に違反します。 既存のチームドットの完了方法がこの新しいタスクに苦労していることを示し、成功した最初のアプローチを提示します。 私たちの結果は、関係スキーマやエンティティ分類などの外部情報が適切に使用されている場合、この設定で驚くほど強力なツールになる可能性があることを示しています。 まず、当社のシンプルで効果的な知識誘導テンソル因子分解アプローチは、2つのジェネリックKB （ 80 ％正確）で科学の最先端の結果を達成し、そのサイズを74 ％～ 86 ％の精度で倍増させます。 第二に、希少な実体（例えば、オリオレ、鳥）に関する注釈を収集するための私たちの新規の分類ガイド付き、亜モジュール、アクティブな学習方法は、複数のアクティブな学習ベースラインよりも、それらに関するさらなる新しい事実を推測するのに6倍効果的です。</abstract_ja>
      <abstract_zh>给定一知识库或知识库,其中常有名词、泛型(嘈杂)实,如"凡木皆生氧气"、"诸物在林中",思以类知识库之精度推其类。 此知识库获世界常知,而于诸应用(如问答)至重。 与治名实体KB(如Freebase)不同,泛型KB及量化,有更杂之理,往往不完,而违常用之局封闭世界假设(LCWA)。 示现知识库成法难成此新,并供第一成功。 吾之的结果表明,若用之得宜,外之信息(架构与实体分类)于此设中,或可讶强大之具。 先约而效者张量以式分解于科学之二泛型KB(80%)而致其先进,以74%-86%其精翻了一番其大小。 其次,臣等采摭希有实体(如金莺,鸟)注新型分类导引,子模块,自为之法,推其增益新实,倍于数学基线有效6倍。</abstract_zh>
      <abstract_hi>सामान्य संज्ञाओं या जेनेरिक्स के बारे में एक ज्ञान आधार या केबी युक्त (शोर) तथ्यों को देखते हुए, जैसे कि "सभी पेड़ ऑक्सीजन का उत्पादन करते हैं" या "कुछ जानवर जंगलों में रहते हैं", हम शुरुआती केबी के समान परिशुद्धता पर अतिरिक्त ऐसे तथ्यों का अनुमान लगाने की समस्या पर विचार करते हैं। इस तरह के केबी दुनिया के बारे में सामान्य ज्ञान पर कब्जा करते हैं, और विभिन्न अनुप्रयोगों जैसे प्रश्न उत्तर देने के लिए महत्वपूर्ण हैं। आमतौर पर अध्ययन किए जाने वाले नामित इकाई केबी जैसे फ्रीबेस से अलग, जेनेरिक केबी में परिमाणीकरण शामिल होता है, अधिक जटिल अंतर्निहित नियमितताएं होती हैं, अधिक अपूर्ण होती हैं, और आमतौर पर उपयोग की जाने वाली स्थानीय रूप से बंद विश्व धारणा (एलसीडब्ल्यूए) का उल्लंघन करती हैं। हम दिखाते हैं कि मौजूदा KB पूर्णता विधियाँ इस नए कार्य के साथ संघर्ष करती हैं, और सफल होने वाला पहला दृष्टिकोण प्रस्तुत करती हैं. हमारे परिणाम दर्शाते हैं कि बाहरी जानकारी, जैसे संबंध स्कीमा और एंटिटी टैक्सोनॉमी, यदि उचित रूप से उपयोग किया जाता है, तो इस सेटिंग में एक आश्चर्यजनक रूप से शक्तिशाली उपकरण हो सकता है। सबसे पहले, हमारे सरल अभी तक प्रभावी ज्ञान निर्देशित टेंसर फैक्टराइजेशन दृष्टिकोण विज्ञान के लिए दो जेनेरिक केबी (80% सटीक) पर अत्याधुनिक परिणाम प्राप्त करता है, जो 74% -86% परिशुद्धता पर उनके आकार को दोगुना करता है। दूसरा, दुर्लभ संस्थाओं (जैसे, ओरिओल, एक पक्षी) के बारे में एनोटेशन एकत्र करने के लिए हमारी उपन्यास वर्गीकरण निर्देशित, सबमॉड्यूलर, सक्रिय सीखने की विधि कई सक्रिय सीखने के आधार रेखाओं की तुलना में उनके बारे में और नए तथ्यों का अनुमान लगाने में 6x अधिक प्रभावी है।</abstract_hi>
      <abstract_ru>Учитывая базу знаний или КБ, содержащую (шумные) факты об общих существительных или дженериках, такие как «все деревья производят кислород» или «некоторые животные живут в лесах», мы рассматриваем проблему вывода дополнительных таких фактов с точностью, аналогичной начальной КБ. Такие КБ фиксируют общие знания о мире и имеют решающее значение для различных приложений, таких как ответы на вопросы. В отличие от обычно изучаемых именованных KB сущностей, таких как Freebase, генерические KB включают в себя количественное определение, имеют более сложные основные закономерности, имеют тенденцию быть более неполными и нарушают широко используемое предположение локально замкнутого мира (LCWA). Мы показываем, что существующие методы завершения КБ борются с этой новой задачей, и представляем первый успешный подход. Наши результаты показывают, что внешняя информация, такая как схемы отношений и таксономии сущностей, если ее использовать надлежащим образом, может быть удивительно мощным инструментом в этой ситуации. Во-первых, наш простой, но эффективный подход к тензорной факторизации, основанный на знаниях, достигает самых современных результатов на двух универсальных КБ (80% точности) для науки, удваивая их размер на 74%–86% точности. Во-вторых, наш новый метод таксономии, управляемый субмодульным активным обучением, для сбора аннотаций о редких сущностях (например, ориоле, птице) в 6 раз эффективнее для вывода дальнейших новых фактов о них, чем несколько активных базовых линий обучения.</abstract_ru>
      <abstract_ga>Nuair a chuirtear bonn eolais nó KB san áireamh ina bhfuil fíricí (torannacha) faoi ainmfhocail choitianta nó cineálacha, mar “táirgeann gach crann ocsaigine” nó “cónaíonn roinnt ainmhithe i bhforaoisí”, breithnímid an fhadhb a bhaineann le fíricí breise dá leithéid a thabhairt isteach ag beachtas cosúil leis an KB tosaigh. Gabhann KBanna den sórt sin eolas ginearálta ar an domhan, agus tá siad ríthábhachtach le haghaidh feidhmeanna éagsúla mar fhreagairt ceisteanna. Difriúil ó KBanna aonáin ainmnithe a ndéantar staidéar orthu go coitianta ar nós Freebase, bíonn cainníochtú i gceist le KBanna generics, tá bunrialacha níos casta acu, bíonn claonadh acu a bheith níos neamhiomlán, agus sáraíonn siad an toimhde domhanda dúnta go háitiúil (LCWA). Léirímid go bhfuil modhanna críochnaithe KB atá ann cheana féin ag streachailt leis an tasc nua seo, agus cuirtear i láthair an chéad chur chuige a n-éiríonn leis. Léiríonn ár dtorthaí gur féidir le faisnéis sheachtrach, cosúil le scéimre chaidrimh agus tacsanomaíochtaí aonáin, má úsáidtear é go cuí, a bheith ina uirlis iontach chumhachtach sa suíomh seo. Ar an gcéad dul síos, baintear amach torthaí úrscothacha ar dhá KB chineálacha (80% beacht) don eolaíocht lenár gcur chuige fachtóirithe tensor simplí ach éifeachtach atá bunaithe ar eolas, ag dúbailt a méide ag 74%–86% beachtas. Ar an dara dul síos, tá ár modh foghlama gníomhaí faoi threoir tacsanomaíocht, fomhodúil, úrnua chun nótaí a bhailiú faoi eintitis neamhchoitianta (m.sh., oriole, éan) 6x níos éifeachtaí ag baint le tuilleadh fíricí nua fúthu ná mar a bhaineann le bonnlínte foghlama gníomhaí iolracha.</abstract_ga>
      <abstract_ka>მეცნიერების ბაზა ან KB-ს, რომელიც საერთო სახელი ან გენერიკების შესახებ ფაქტის შესახებ, როგორც 'ყველა სახელი წარმოიქმნის კიცექტური' ან 'ზოგიერთი ცხოველი ქალში ცხოვრებს', ჩვენ ვფიქრობთ პრობლემა,  ასეთი KB-ები მსოფლიოს საერთო ცნობიერებას გააკეთებენ და უფრო მნიშვნელოვანია განსხვავებულ პროგრამებისთვის, როგორც კითხვის გასაგები განსხვავებული საერთოდ განსწავლებული ინტერტიკის კიბებიდან, როგორც Freebase, განსხვავებული KBs კონტაქტიფიკაცია, უფრო კომპლექტიკური რეგულაციებიდან, უფრო კომპლექტიკური რეგულაციებიდან, უფრო უფრო დასრულებული იყოს ჩვენ ჩვენ აჩვენებთ, რომ მსგავსი KB დასრულება მეტებები ამ ახალი დავალებით გაბრუნდება და გაჩვენებთ პირველი დასრულება, რომელიც წარმოდგენა. ჩვენი წარმოდგენები გამოიყენებენ, რომ გარეშე ინფორმაცია, როგორც შესახებ სქემები და ინტერტიკონომიები, თუ გამოყენებული სწორად, შეიძლება იყოს საინტერესო ძალიან პირველად, ჩვენი განსაკუთრებული მაგრამ ეფექტიური ცნობილების გადაწყვეტილი ტენსორის ფაქტორიზაციის პროგრამის შესაძლებლობა მიიღება ორი განსაკუთრებული KBs (80% დასაკუთრებული) მეცნიერებისთვის, მათი ზ მეორე, ჩვენი პრომენური რაქონომიის მიზეზი, სუბმოულური, აქტიური სწავლების მეტი, რომელიც წარმოადგენების შესახებ (მაგალითად, ორიოლი, ორიოლი) არის 6x უფრო ეფექტიური ახალი ფაქტების შესახებ, ვიდრე</abstract_ka>
      <abstract_hu>Tekintettel arra a tudásbázisra vagy KB-ra, amely a közönséges főnevekkel vagy generikusokkal kapcsolatos (zajos) tényeket tartalmazza, mint például "minden fa oxigént termel" vagy "néhány állat erdőben él", úgy gondoljuk, hogy további ilyen tények következtetésének problémáját a kiinduló KB-hoz hasonló pontossággal vizsgáljuk. Az ilyen KBs megragadja az általános ismereteket a világról, és kulcsfontosságúak a különböző alkalmazásokhoz, mint például a kérdések megválaszolásához. Az általánosan tanulmányozott, nevezett entitás KBs-től eltérően, mint például a Freebase, a generikus KBs-k számszerűsítést igényelnek, bonyolultabb alapszabályszerűséggel rendelkeznek, általában hiányosabbak, és megsértik a gyakran használt lokálisan zárt világ feltételezést (LCWA). Megmutatjuk, hogy a meglévő KB kiegészítési módszerek küzdenek ezzel az új feladattal, és bemutatjuk az első sikeres megközelítést. Eredményeink azt mutatják, hogy a külső információk, mint például a kapcsolatsémák és entitás-taxonómiák, ha megfelelően használják, meglepően hatékony eszközt jelenthetnek ebben a beállításban. Először is, egyszerű, mégis hatékony tudásvezérelt tenszor faktorizációs megközelítésünk a legkorszerűbb eredményeket ér el két generikus KBen (80%-os pontossággal) a tudomány számára, méretük megduplázása 74%-86%-os pontossággal. Másodszor, új taxonómiai vezérelt, szubmoduláris, aktív tanulási módszerünk ritka entitásokról (pl. oriol, madárról) szóló jegyzetek gyűjtésére hatékonyabb, mint több aktív tanulás alapja.</abstract_hu>
      <abstract_el>Δεδομένης μιας βάσης γνώσεων ή ΚΒ που περιέχει (θορυβώδη) γεγονότα σχετικά με κοινά ουσιαστικά ή γενικά, όπως "όλα τα δέντρα παράγουν οξυγόνο" ή "μερικά ζώα ζουν σε δάση", εξετάζουμε το πρόβλημα της συναγωγής επιπλέον τέτοιων γεγονότων με ακρίβεια παρόμοια με εκείνη της αρχικής ΚΒ. Τέτοια KBs συλλαμβάνουν γενικές γνώσεις για τον κόσμο και είναι ζωτικής σημασίας για διάφορες εφαρμογές, όπως η απάντηση σε ερωτήσεις. Διαφορετικά από τις κοινώς μελετημένες ονομαστικές οντότητες όπως η Freebase, τα γενικά περιλαμβάνουν ποσοτικοποίηση, έχουν πιο πολύπλοκες υποκείμενες κανονικότητες, τείνουν να είναι πιο ελλιπή και παραβιάζουν την κοινώς χρησιμοποιούμενη τοπική υπόθεση κλειστού κόσμου (LCWA). Δείχνουμε ότι οι υπάρχουσες μέθοδοι ολοκλήρωσης της ΚΒ αγωνίζονται με αυτό το νέο έργο και παρουσιάζουμε την πρώτη προσέγγιση που είναι επιτυχής. Τα αποτελέσματά μας δείχνουν ότι εξωτερικές πληροφορίες, όπως σχήματα σχέσεων και ταξινομίες οντοτήτων, αν χρησιμοποιηθούν κατάλληλα, μπορούν να αποτελέσουν ένα εκπληκτικά ισχυρό εργαλείο σε αυτή τη ρύθμιση. Πρώτον, η απλή αλλά αποτελεσματική προσέγγιση παραγωγής τενσορών καθοδηγούμενη από τη γνώση επιτυγχάνει αποτελέσματα τελευταίας τεχνολογίας σε δύο γενόσημα για την επιστήμη, διπλασιάζοντας το μέγεθός τους με ακρίβεια 74%-86% . Δεύτερον, η νέα μας μεθοδολογία υποβοηθούμενης, ενεργού μάθησης για τη συλλογή σχολίων σχετικά με σπάνιες οντότητες (π.χ. οριόλη, πουλί) είναι 6x πιο αποτελεσματική στην εξαγωγή νέων γεγονότων σχετικά με αυτές από τις πολλαπλές γραμμές ενεργού μάθησης.</abstract_el>
      <abstract_it>Data una base di conoscenze o KB contenente fatti (rumorosi) su sostantivi comuni o generici, come "tutti gli alberi producono ossigeno" o "alcuni animali vivono nelle foreste", consideriamo il problema di dedurre ulteriori fatti di questo tipo con una precisione simile a quella della KB iniziale. Tali KB acquisiscono conoscenze generali sul mondo e sono cruciali per varie applicazioni come la risposta alle domande. Diversamente da quelle comunemente studiate con nome di entità KBs come Freebase, le KBs generiche comportano una quantificazione, presentano regolarità sottostanti più complesse, tendono ad essere più incomplete e violano l'ipotesi comunemente usata localmente closed world (LCWA). Mostriamo che i metodi di completamento KB esistenti lottano con questo nuovo compito e presentiamo il primo approccio che ha successo. I nostri risultati dimostrano che le informazioni esterne, come schemi di relazione e tassonomie di entità, se utilizzate in modo appropriato, possono essere uno strumento sorprendentemente potente in questa impostazione. In primo luogo, il nostro semplice ma efficace approccio di fattorizzazione del tensore guidato dalla conoscenza raggiunge risultati all'avanguardia su due KBs generici (80% precisi) per la scienza, raddoppiando le loro dimensioni con una precisione del 74%-86%. In secondo luogo, il nostro nuovo metodo di apprendimento attivo guidato dalla tassonomia per raccogliere annotazioni su entità rare (ad esempio, oriole, un uccello) è 6 volte più efficace nell'inferire ulteriori fatti nuovi su di loro rispetto a molteplici linee di base di apprendimento attivo.</abstract_it>
      <abstract_lt>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.  Skirtingai nuo paprastai tiriamų subjektų KB, pavyzdžiui, Freebase, generiniai KB apima kiekybinį įvertinimą, turi sudėtingesnius pagrindinius reguliarumo rodiklius, dažniausiai yra neišsamesni ir pažeidžia paprastai naudojamą vietiškai uždarytą pasaulio prielaidą (LCWA). Mes rodome, kad esami KB užbaigimo metodai kovoja su šia nauja užduotimi ir pristato pirmąjį sėkmingą metodą. Mūsų rezultatai rodo, kad išorės informacija, pavyzdžiui, santykių schemos ir subjektų taksonomijos, jei jos naudojamos tinkamai, gali būti stebimai galinga priemonė šioje aplinkoje. First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.  Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_lt>
      <abstract_kk>Бірақ білім негізінде немесе КБ-де жалпы атаулар немесе жалпы материалар туралы, мысалы 'барлық ағаштар көкжиекті құрады' немесе 'кейбір амьтандар орманда тұрады' деген мәселелерін көрсету мәселесі болады. Біз КБ-нің Бұл КБ әлемдегі жалпы білімдерді түсінеді және сұрақ жауап беру үшін әртүрлі қолданбалар үшін маңызды. Көпшілікті көпшілікті көпшілікті аталған КБ секілді, көпшілікті көпшілікті көпшілікті көпшілікті көпшілікті, көпшілікті көпшілікті көпшілікті, көпшілікті тәртіпті тәртіпт Біз KB толтыру әдістерін жаңа тапсырманың күресіп, бірінші әдістерін сәтті көрсетуге болады. Біздің нәтижелеріміздің сыртқы мәліметі, мысалы сұлбалар мен нысандар таксономиясы, егер дұрыс қолданылса, бұл параметрде әлі қуатты құрал болуы мүмкін. Біріншіден, біздің қарапайым біліміздің тензер факторизациялау тәсілі біліміздің күйінің нәтижесін білім үшін 2 кб (80% дұрыс) күйінде жеткізеді, олардың өлшемін 74%-86% дұрыс көбейті Екіншіден, біздің романдық таксономия бағытталған, субмодульді, белсенді оқыту әдісіміз (мысалы, ориол, дұш) бағыттарды (мысалы, ориол, дұш) бірнеше белсенді оқыту негізінен артық жаңа факттарды шектеу үшін 6</abstract_kk>
      <abstract_ms>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.  Berbeza dari KB entiti bernama yang biasa dipelajari seperti Freebase, KB generik melibatkan kuantifikasi, mempunyai regularitas dasar yang lebih kompleks, cenderung menjadi lebih tidak lengkap, dan melanggar asumsi dunia yang biasa digunakan secara setempat ditutup (LCWA). Kami menunjukkan bahawa kaedah penyelesaian KB yang ada berjuang dengan tugas baru ini, dan memperkenalkan pendekatan pertama yang berjaya. Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.  Kedua, kaedah pembelajaran aktif yang dipandu oleh taksonomi novel kita untuk mengumpulkan anotasi mengenai entiti langka (contohnya oriol, burung) adalah 6x lebih efektif dalam menyimpulkan fakta baru lebih lanjut mengenai mereka daripada garis dasar pembelajaran aktif berbilang.</abstract_ms>
      <abstract_mk>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  Таквите КБ го заземаат општото знаење за светот и се клучни за различни апликации како што е одговорот на прашањата. Различно од обично испитаните ентитети КБ, како што е Freebase, генеричките КБ вклучуваат квантификација, имаат покомплексни основни регулативности, имаат тенденција да бидат понекомплетни и ја кршат обично употребената локално затворена светска претпоставка (ЛЦВА). Ние покажуваме дека постојните методи на комплетирање на КБ се борат со оваа нова задача и го претставуваат првиот пристап кој е успешен. Нашите резултати покажуваат дека надворешните информации, како што се шемите на односи и таксономиите на ентитетите, ако се користат соодветно, може да бидат изненадувачки моќна алатка во ова поставување. First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.  Второ, нашата нова таксономија управувана, подмодуларна, активна метода на учење за собирање анотации за ретки ентитети (на пример ориол, птица) е 6 пати поефикасна во инференцијата на понатамошни нови факти за нив отколку на повеќето бази на активно учење.</abstract_mk>
      <abstract_ml>എല്ലാ വൃക്ഷങ്ങളും ഓക്സിജെന്‍ ഉല്‍പാദിക്കുന്നു. അല്ലെങ്കില്‍ 'കാട്ടില്‍ ജീവിക്കുന്ന ചില മൃഗങ്ങള്‍ കൂടുതല്‍ കെബിയെ പ്രേരിപ്പിക്കുന്നതിനെപ്പോലെ ഇങ്ങനെയുള്ള കെബികള്‍ ലോകത്തെക്കുറിച്ച് പൊതുവിന്റെ അറിവ് പിടിച്ചുകൊണ്ടിരിക്കുന്നു. ചോദ്യം ഉത്തര സാധാരണ പഠിക്കപ്പെട്ട സാധാരണ കെബിസ് പേരില്‍ നിന്നും വ്യത്യസ്തമാണ്, സാധാരണ കെബികള്‍ പരിശീലനത്തില്‍ ചേര്‍ക്കുന്നത്, കൂടുതല്‍ കൂടുതല്‍ സങ്കീര്‍ണ്ണമായ നിയമങ്ങളുണ്ട്, കൂട നിലവിലുള്ള കെബി പൂര്‍ത്തിയാക്കുന്ന രീതികള്‍ ഈ പുതിയ ജോലിയോടൊപ്പം പൊരുതുന്നു എന്ന് നമ്മള്‍ കാണിച് നമ്മുടെ ഫലങ്ങള്‍ വെളിപ്പെടുത്തിയിരിക്കുന്നു, ബന്ധപ്പെടുത്തിയ സ്കീമാസിന്റെയും ശരീരത്തിന്റെയും ടാക്സോണിയുടെയും പുറത്തുള ആദ്യം, നമ്മുടെ എളുപ്പമുള്ള വിജ്ഞാനം പ്രാപ്തികമായിട്ടുമുണ്ടെങ്കിലും ടെന്‍സോര്‍ ഫാക്ടറിഷന്‍ നടപടികള്‍ നേര്‍വഴിയിലാക്കിയിരിക്കുന്നു. സാന്ത്രീയ Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_ml>
      <abstract_mt>Minħabba bażi ta’ għarfien jew KB li fiha fatti (storbjużi) dwar ismijiet komuni jew ġeneriċi, bħal 'is-siġar kollha jipproduċu ossiġnu' jew 'xi annimali jgħixu fil-foresti', a ħna nqisu l-problem a li jiġu konklużi fatti addizzjonali bħal dawn bi preċiżjoni simili għal dik tal-KB tal-bidu. Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.  Differenti minn entitajiet KBs magħrufa b’mod komuni bħal Freebase, KBs ġeneriċi jinvolvu kwantifikazzjoni, għandhom regolaritajiet sottostanti aktar kumplessi, għandhom it-tendenza li jkunu aktar inkompleti, u jiksru s-suppożizzjoni dinjija magħluqa b’mod komuni (LCWA). Aħna nuru li l-metodi ta’ tlestija tal-KB eżistenti qed iħabbtu wiċċhom ma’ dan il-kompitu l-ġdid, u nippreżentaw l-ewwel approċċ li jkun ta’ suċċess. Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  L-ewwel nett, l-approċċ sempliċi iżda effettiv tagħna ta’ fatturizzazzjoni tat-tensuri ggwidat mill-għarfien jikseb riżultati l-aktar avvanzati fuq żewġ KBs ġeneriċi (80% preċiżi) għax-xjenza, li jirdoppjaw id-daqs tagħhom bi preċiżjoni ta’ 74%-86%. Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_mt>
      <abstract_no>Given ein kunnskapsbasen eller KB som inneheld (støy) faktar om vanlege namn eller generikk, slik som « alle trær produserer oksygen » eller « noen dyr lever i skog », ser vi på problemet for å få tillegg slike faktar på eit nøyaktig liknande som den starta KB- en. Slike KBs får generell kunnskap om verden, og er viktig for ulike program som svarar på spørsmål. Forskjellig frå vanleg studiert entitet KBs som Freebase, generiske KBs involverer kvantifikasjon, har meir kompliserte underliggande reguleringar, vanlegvis er meir inkomplete, og violerer den vanleg brukte lokalt lukka verdensassumpsjonen (LCWA). Vi viser at eksisterande KB- fullføringsmetodar strømmer med denne nye oppgåva og viser den første tilnærminga som er vellukka. Resultatet våre viser at eksterne informasjon, slik som relasjonsskjemar og entitetstaxonomi, viss det er nøyaktig brukt, kan vera eit overraska kraftig verktøy i denne innstillinga. Først, vårt enkle enn effektiv kunnskap, hjelpet av tenorefaktoriseringstilnærming, oppnår resultatet til tilstanden av kunsten på to generiske KBs (80% presis) for vitenskap, dobbelt storleiken på 74% - 86% presis. Andre, vår roman taxonomi er hjelpet, submodular, aktiv læringsmetode for å samla merknader om sjeldre einingar (f.eks. oriol, fugl) er 6x mer effektiv for å få fram nye faktar om dei enn fleire aktive læringsbaselinjer.</abstract_no>
      <abstract_pl>Biorąc pod uwagę bazę wiedzy lub KB zawierającą (hałaśliwe) fakty dotyczące rzeczowników wspólnych lub generyków, takie jak "wszystkie drzewa produkują tlen" lub "niektóre zwierzęta żyją w lasach", rozważamy problem wnioskowania dodatkowych takich faktów z precyzją podobną do początkowej KB. Takie KBs zdobywają ogólną wiedzę o świecie i mają kluczowe znaczenie dla różnych zastosowań, takich jak odpowiedzi na pytania. W odróżnieniu od powszechnie badanych nazywanych jednostek KBs, takich jak Freebase, generyczne KBs obejmują kwantyfikację, mają bardziej złożone podstawowe prawidłowości, są zwykle bardziej niekompletne i naruszają powszechnie stosowane lokalnie założenie zamkniętego świata (LCWA). Pokazujemy, że istniejące metody kompletacji KB borykają się z tym nowym zadaniem i przedstawiamy pierwsze podejście, które się uda. Nasze wyniki pokazują, że informacje zewnętrzne, takie jak schematy relacji i taksonomie jednostek, jeśli są stosowane odpowiednio, mogą być zaskakująco potężnym narzędziem w tym ustawieniu. Po pierwsze, nasze proste, ale skuteczne podejście do faktoryzacji tensorów kierujące się wiedzą osiąga najnowocześniejsze wyniki na dwóch generycznych KBs (80% precyzyjnych) dla nauki, podwojając ich wielkość przy precyzji 74%-86% . Po drugie, nasza nowa, submodułowa, aktywna metoda uczenia się, kierowana taksonomią, służąca zbieraniu adnotacji o rzadkich istotach (np. oriole, ptak) jest 6-krotnie skuteczniejsza w wnioskowaniu dalszych nowych faktów o nich niż wiele aktywnych linii bazowych uczenia się.</abstract_pl>
      <abstract_ro>Având în vedere o bază de cunoștințe sau KB care conține fapte (zgomotoase) despre substantive comune sau generice, cum ar fi "toți copacii produc oxigen" sau "unele animale trăiesc în păduri", considerăm problema deducerii unor astfel de fapte suplimentare la o precizie similară cu cea a KB-ului de pornire. Astfel de KBs captează cunoștințe generale despre lume și sunt esențiale pentru diverse aplicații, cum ar fi răspunsul la întrebări. Spre deosebire de KBs-urile cu denumire obișnuită, cum ar fi Freebase, KBs-urile generice implică cuantificarea, au regularități subiacente mai complexe, tind să fie mai incomplete și să încalce ipoteza locală închisă (LCWA). Noi arătăm că metodele existente de completare KB se luptă cu această nouă sarcină și prezentăm prima abordare care are succes. Rezultatele noastre demonstrează că informațiile externe, cum ar fi schemele de relații și taxonomiile entităților, dacă sunt utilizate corespunzător, pot fi un instrument surprinzător de puternic în această setare. În primul rând, abordarea noastră simplă, dar eficientă, ghidată prin factorizarea tensorilor, obține rezultate de ultimă generație pe două KBs generice (80% precise) pentru știință, dublându-le dimensiunea la o precizie de 74%-86%. În al doilea rând, noua noastră metodă de învățare axonomică ghidată, submodulară și activă pentru colectarea adnotărilor despre entități rare (de exemplu, oriol, o pasăre) este de 6 ori mai eficientă în deducerea altor fapte noi despre ele decât mai multe linii de bază de învățare activă.</abstract_ro>
      <abstract_so>Sida lagu helo aasaaska aqoonta ama KB oo ku jira waxyaabo ku saabsan cuntada caadiga ah ama dabiicadda, tusaale ahaan 'dhirta oo dhan waxey dhashaan oksygeneen' ama 'xoolaha qaarkood kaynta ku nool yihiin', waxaynu ka fiirsanaynaa dhibaatada ku saabsan dhibaatada kaloo kale ee ku saabsan waxyaabaha la mid ah ee ka bilowga KB. Kuwaas oo kale KBs waxay qabsadaan aqoonta guud ee dunida, waxayna muhiim u yihiin codsiyada kala duduwan sida jawaabta su'aalaha. Qof ka duwan karo qofka caadiga ah ee la magacaabay KBs, sida Freebase, geneeral KBs ayaa ku saabsan qiimeynta, waxay leeyihiin sharciyada hoose ka hooseeya oo adag, inta badan waa mid aan dhamaan, waxayna jebiyaan malaabooyinka caadiga ah ee degmada ku xidhan (LCWA). We show that existing KB completion methods struggle with this new task, and present the first approach that is successful.  Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  Marka ugu horeysa, aqoontayada fudud ee weli faa’iido leh ayaa hagay qaababka sameeyaha tensor, wuxuu gaadhaa xaaladda-farshaxanta labada generic KBs (80% saxda) si cilmiga loo yaqaan, waxayna labanlaabin yihiin tirada 74%-86 boqolkiiba. Second, takhasuskayagu wuxuu hagaa, qaababka waxbarashada e e la shaqeeyo oo la soo ururiyo wax ka saabsan waxyaabaha qaaliga ah (tusaale ahaan oriole, shimbir) waa 6x ka faa’iido badan si ay ugu dhacdo waxyaabo cusub oo ku saabsan aasaaska waxbarashada oo shaqo badan.</abstract_so>
      <abstract_sv>Med tanke på en kunskapsbas eller KB som innehåller (bullriga) fakta om vanliga substantiv eller generika, såsom "alla träd producerar syre" eller "vissa djur lever i skogar", överväger vi problemet med att härleda ytterligare sådana fakta med en noggrannhet som liknar den ursprungliga KB. Sådana KBs fångar allmän kunskap om världen och är avgörande för olika tillämpningar som frågesvar. Till skillnad från de allmänt studerade namngivna entitetsKBs som Freebase innebär generiska KBs kvantifiering, har mer komplexa underliggande regelbundenhet, tenderar att vara mer ofullständiga och bryter mot det allmänt använda lokalt slutna världsantagandet (LCWA). Vi visar att befintliga KB-kompletteringsmetoder kämpar med denna nya uppgift, och presenterar den första metoden som är framgångsrik. Våra resultat visar att extern information, såsom relationsscheman och entitetstaxonomier, om den används på lämpligt sätt, kan vara ett förvånansvärt kraftfullt verktyg i den här inställningen. För det första uppnår vår enkla men effektiva kunskapsstyrda tensorfaktoriseringsmetod toppmoderna resultat på två generiska KBs (80% exakta) för vetenskap och fördubblar deras storlek med 74% -86% precision. För det andra är vår nya taxonomi guidade, submodulära, aktiva inlärningsmetod för att samla in anteckningar om sällsynta enheter (t.ex. oriol, en fågel) sex gånger effektivare på att härleda ytterligare nya fakta om dem än flera aktiva inlärningsgränser.</abstract_sv>
      <abstract_ta>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.  பொதுவான ஆராய்ந்த பொருள் கேபிஸ் போன்ற பொருள்களிலிருந்து வேறுபாடு, பொதுவான கேபிகள் அளவு சேர்க்கிறது, மேலும் சிக்கலான அடிப்படையான விதிமுறைகள் உள்ளன, பொதுவாக உள நாம் காண்பிக்கிறோம் இருக்கும் KB முடிப்பு முறைமைகள் இந்த புதிய பணியுடன் போராடுகிறார்கள் என்பதை மற்று எங்கள் முடிவுகள் வெளி தகவல்கள், தொடர்பு திட்டங்கள் மற்றும் பொருள் வரிசைப்படுத்தப்பட்டுள்ளது போன்று, சரியாக பயன்படுத்தப்பட்டால், இந்த அமைப முதலில், எங்கள் எளிய அறிவு இன்னும் வெளிப்படையான முறையில் பத்து காரணிகளை நேர்வழியில் செலுத்தியுள்ளது, இரண்டு பொதுவான கேபிகளின் முடிவுகள் நிலையை பெறுக இரண்டாவது, எங்கள் புதிய வரிசைப்படுத்தல், துணை மாற்று, சிறிய பொருள்கள் பற்றிய அறிவிப்புகளை சேகரிக்கும் முறைமையான கற்றுக்கொள்ளும் முறையில் (உதாரணமாக ஓய்லோ, ஒரு பறவை)</abstract_ta>
      <abstract_ur>ہم نے ایک علم بنسس یا KB کے بارے میں (غروب) حقیقت کا ذریعہ رکھا ہے، جیسے 'تمام درخت اکسیژن پیدا کرتی ہیں' یا 'کچھ جانور جنگل میں زندگی کرتی ہیں، ہم نے اس طرح اضافہ کرنے کی مشکل سمجھ لیا ہے جس طرح یہ حقیقت آغاز کی KB کی مثال ہے۔ اس طرح کی ک ب اس دنیا کے بارے میں معمولی علم کو پکڑتے ہیں اور مختلف کاربریوں کے لئے ضروری ہے جیسے سوال جواب دینے کے لئے۔ بہت سی مطالعہ کے نام کی ایٹنی کیب سے متفاوت ہیں جیسے Freebase، جینیریک کیب کی تعداد کے ساتھ ہے، زیادہ پیچیدہ معلومات ہیں، زیادہ غلطی ہوتی ہیں، اور زیادہ مطالعہ ہوتی ہیں، اور عمومی طور پر استعمال کیا جاتا ہے جہان سے بند ہوا دنیاوی فرض (LCWA) کو بہکاتے ہیں ہم دکھاتے ہیں کہ موجود KB کامل طریقے اس نوی کام کے ساتھ جہاد کرتے ہیں اور پہلی طریقہ کو پیش کریں جو کامل ہے۔ ہمارے نتیجے دکھاتے ہیں کہ بیرونی معلومات، جیسے ارتباط طریقے اور اتنی تاکسنوم، اگر مناسب طور پر استعمال کیا جاتا ہے، اس تنظیم میں ایک عجیب طاقتور ابزار ہو سکتا ہے۔ پہلے، ہماری ساده اور اثبات علم کی ہدایت کی تنسور فکتوریزی کی تقریبا دو جینیریک کیب (80% دقیق) کے ذریعہ پہنچ جاتی ہے، ان کی اندازہ 74%-86% دقیق سے دوگنا ہوتا ہے۔ دوسرا، ہماری روزنامہ تاکسونومی کی راہ دکھائی، سوب موڈولر، فعال سیکھنے کا طریقہ ہے کہ ان کے بارے میں بہت سی فعالیت یادہانی بنسٹلین کے بارے میں اضافہ جمع کرنے کے لئے (جیسے اوریول، پرندہ) 6x اضافہ ہے۔</abstract_ur>
      <abstract_si>සාමාන්‍ය ප්‍රමාණයක් නැත්නම් සාමාන්‍ය ප්‍රමාණයක් නැත්නම් 'සියළු ගස් ඔක්සිජන් කරන්න' නැත්නම් 'සතුන් ජීවත් වලට ජීවත් වෙන්න' නැත්නම්, අපි හිතන්නේ අ ඒ වගේම KBs ලෝකය ගැන සාමාන්‍ය දන්නවක් අල්ලගන්නවා, ඒවගේම ප්‍රශ්න ප්‍රතිච්චාරයක් වගේම විවිධි ප්‍රමාණයෙන් අධ්‍යානය කරලා තියෙන අධ්‍යානය KBs වගේ, freebase, generics KBs අධ්‍යානය කරනවා ක්වාන්ටිෆික් එක්ක, විශේෂයෙන් අධ්‍යානය සම්පූර්ණය කරනවා, සාමාන්‍ය ව අපි පෙන්වන්නේ මේ අලුත් වැඩ සමඟ ඉතිරියට KB සම්පූර්ණ විධානය සම්පූර්ණ විධානය, සහ පළමු වැඩේ  අපේ ප්‍රතිචාරයක් පෙන්වන්නේ පුළුවන් පුළුවන් විදිහට ප්‍රතිචාරයක්, සම්බන්ධතාවක් සහ ප්‍රතිචාරයක් සඳහා ප්‍රති මුලින්ම, අපේ සාමාන්‍ය දැනගන්න තියෙන්නේ විද්‍යානය සඳහා ප්‍රතිකාර විද්‍යාපකය විද්‍යාපකය විද්‍යාපකය ප්‍රතිකාරයෙන් විද්‍යාපකයෙන් ස්ථ දෙවෙනි විදියටම, අපේ කොතුරු ටැක්සිනෝමික් ප්‍රධානය, සබ්මෝඩ්යුලර්, සක්‍රිය ප්‍රධානය සම්බන්ධ විධානය සම්බන්ධ විදියට සම්බන්ධ විදිය</abstract_si>
      <abstract_sr>S obzirom na bazu znanja ili KB koja sadrži (bučne) činjenice o zajedničkim imenima ili generikama, kao što su 'sve drveće proizvode kiseonik' ili 'neke životinje žive u šumama', smatramo problemom uvođenja dodatnih takvih činjenica na tačnost sličnu prema početnoj KB-u. Takvi KB uhvate opće znanje o svetu i ključne su za različite aplikacije kao što su odgovori na pitanje. Drugačije od češće proučavanih entitetskih KB-a poput Freebase, generičnih KB-a uključuju kvantifikaciju, imaju kompleksnije ispod redovitosti, navodno su nepotpunije i kršiju uobičajeno korištenu lokalno zatvorenu svjetsku pretpostavku (LCWA). Pokazujemo da postojeće metode završetka KB bore se sa ovom novom zadatkom i predstavljamo prvi pristup koji je uspješan. Naši rezultati pokazuju da vanjska informacija, poput rešema odnosa i taksonomija entitata, ako se prikladno koristi, može biti iznenađujuće moćna alata u ovom stanju. Prvo, naš jednostavan, ali efikasni pristup faktorizacije tenzora vodi do znanja postiže rezultate stanja umjetnosti na dva generična KB (80% precizno) za nauku, povećavajući njihovu veličinu sa 74%-86% preciznosti. Drugo, naša nova taksonomija vodi, podmodularni, aktivni metod učenja za skupljanje annotacija o retkim entitetima (npr. oriola, ptica) je 6x efikasniji u prijavljivanju novih činjenica o njima od višestruke aktivne osnovne linije učenja.</abstract_sr>
      <abstract_mn>Бүх мод хүчилтөрөгч болон зарим амьтдыг ой дотор амьдардаг гэсэн мэдлэгтэй суурь эсвэл КБ-ийн тухай (чимээгүй) нэр хэмжээний тухай бодит байдлаар бид үүнийг КБ-ийн эхлэлтэй төстэй тодорхойлох асуудал гэж боддог. Ийм километр дэлхийн тухай ерөнхий мэдлэгийг барьж, асуулт хариулт гаргах мэт олон програмуудын тулд чухал. Ихэнх судалгааны нэрлэгдсэн КБ-ээс өөр өөр өөр өөр хэлбэрүүд нь Freebase, генерал КБ-д хэмжээний тооцоололт, илүү төвөгтэй байдал байдаг, илүү төвөгтэй байдаг, илүү төвөгтэй байдаг, ихэнхдээ орчин нутгийн хаалгдсан дэлхийн тооцоололтыг буруутгадаг Бид суурилсан КБ-ын төгсгөлийн аргыг шинэ ажил дээр тулалдаг, амжилттай анхны арга замыг харуулж байна. Бидний үр дүнд гадаад мэдээллийг харуулж байна. Хэрвээ хэрвээ зөв хэрэглэгддэг бол энэхүү тохиолдолд гайхалтай хүчтэй хэрэгсэл болж чадна. Эхлээд, бидний энгийн ч үр дүнтэй мэдлэг нь tensor factorization арга зам нь шинжлэх ухааны хоёр ерөнхий хэмжээний КБ (80% тодорхой) шинжлэх ухааны төлөвлөгөөний үр дүнд 74%-86% тодорхойлогдсон. Хоёр дахь, бидний шинэ татекономикийн удирдагч, субмодуль, идэвхитэй суралцах арга нь ховор зүйлсийн (жишээ нь ориол, шувууд) тухай анхаарлаа цуглуулахын тулд бидний шинэ зүйлийг олон актив суралцах суралцах сургалтын сургал</abstract_mn>
      <abstract_uz>Biz KB boshlanishga qarab ko'proq narsalarni ko'proq narsalar haqida ko'p narsa bilan ko'rsatish haqida ko'p narsalarni ko'rsatish mumkin. Bu kabi KBs dunyo haqida umumiy maʼlumotni qabul qiladi va savol kabi dasturlar uchun muhim. Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).  Biz mavjud KB tuzilishi usullarini ushbu yangi vazifa bilan harakat qilamiz va muvaffaqiyatli birinchi usulni hozir qilamiz. Bizning natijalarimiz bilan tashqi maʼlumot, huddi murojaat qoliplari va ma'lumot taxonomlari, agar muhimi ishlatilgan бўлса, bu moslamada juda ajoyib қувватли vosita bo'lishi mumkin. Birinchisi, bizning oddiy ishlaydigan aqlliyasiz tensor fabrikalarning qismlarini ko'rsatadigan darajaga ega bo'ladi, ilmiy fani ikkita genetika KBs (80% darajada) darajaga ega bo'ladi, ularning oʻlchamini 74% - 86% darajada ko'paytirish mumkin. Ikkinchi so'zda, bizning novel taxonomi boshqaruvchi, tub modulyat, aktiv o'rganish usuli ko'plab o'rganish qismlari (m. g. oriole, bir қуш) haqida qanchalik ko'p aktiv o'rganish asboblarning bir necha qanchalik asboblarini o'zgartirish uchun 66 ta'siri ishlaydi.</abstract_uz>
      <abstract_vi>Dựa vào một căn cứ kiến thức hoặc KB có (ồn ào) dữ liệu về các danh từ thường hay đại loại như "mọi cây tạo ra oxy" hay "một số động vật sống trong rừng", chúng tôi cho rằng vấn đề này có thể ngụ ý thêm vào sự thật chính xác tương tự như của KB đầu. Những KBs nắm giữ kiến thức thông thường về thế giới, và rất quan trọng cho các ứng dụng khác nhau như câu hỏi trả lời. Khác với các tập đoàn tên thường được nghiên cứu, như Freebase, generic KBs bao gồm lượng tử, có các quy tắc cơ bản phức tạp hơn, có xu hướng trở nên phức tạp hơn, và xâm phạm giả định thế giới gần gũi cục bộ thường dùng (LCWA). Chúng tôi cho thấy các phương pháp hoàn thành KB đang đương đầu với nhiệm vụ mới này, và trình bày phương pháp đầu tiên thành công. Những kết quả của chúng tôi chứng minh rằng thông tin bên ngoài, như các quy trình liên quan và các phân loại thực thể, nếu sử dụng thích hợp, có thể là một công cụ mạnh đến ngạc nhiên trong môi trường này. Thứ nhất, phương pháp hướng dẫn học và hiệu quả đơn giản nhất đạt được kết quả tối tân về hai gen KBs (80=. chính xác) cho khoa học, tăng gấp đôi kích thước của họ với sự chính xác 74=-86. Thứ hai, loại taxonomy của chúng ta đã được điều khiển, submodular, active leaving methods for collecting annotations about rare caterpies (ví dụ, orile, a bird, a bird) is 6x more effectively to inferrering new facts about them before multiple active leaving Baseline.</abstract_vi>
      <abstract_bg>Предвид базата от знания или КБ, съдържащи (шумни) факти за общи съществителни или генерични знаци, като например "всички дървета произвеждат кислород" или "някои животни живеят в горите", разглеждаме проблема с извеждането на допълнителни такива факти с точност, подобна на тази на началната КБ. Такива КБ улавят общи познания за света и са от решаващо значение за различни приложения като отговор на въпроси. За разлика от често изучаваните КБ субекти като Freebase, генеричните КБ включват количествено определяне, имат по-сложни базови редовности, са склонни да бъдат по-непълни и нарушават често използваното предположение за местен затворен свят (LCWA). Показваме, че съществуващите методи за завършване на КБ се борят с тази нова задача и представяме първия успешен подход. Нашите резултати показват, че външна информация, като релационни схеми и таксономии на единици, ако се използва правилно, може да бъде изненадващо мощен инструмент в тази настройка. Първо, нашият прост, но ефективен подход на тензорна факторизация, ръководен от знанието, постига най-съвременни резултати върху две генерични КБ (80% прецизни) за науката, удвоявайки размера им с точност 74%-86%. Второ, нашият нов таксономичен, подмодулен, активен метод за събиране на анотации за редки същества (например ориол, птица) е 6 пъти по-ефективен при извеждането на нови факти за тях, отколкото множество базови линии за активно учене.</abstract_bg>
      <abstract_nl>Gezien een kennisbank of KB met (luidruchtige) feiten over gewone zelfstandige naamwoorden of generieke naamwoorden, zoals 'alle bomen produceren zuurstof' of 'sommige dieren leven in bossen', overwegen we het probleem van het afleiden van extra dergelijke feiten met een nauwkeurigheid vergelijkbaar met die van de beginnende KB. Dergelijke KBs leggen algemene kennis over de wereld vast en zijn cruciaal voor diverse toepassingen zoals het beantwoorden van vragen. Anders dan veelal bestudeerde entiteitkb's zoals Freebase, omvatten generieke KBs kwantificering, hebben complexere onderliggende regulariteiten, zijn vaak onvollediger en schenden ze de veelgebruikte local closed world veronderstelling (LCWA). We laten zien dat bestaande KB completion methodes worstelen met deze nieuwe taak en presenteren de eerste aanpak die succesvol is. Onze resultaten tonen aan dat externe informatie, zoals relatieschema's en entiteitentaxonomieën, indien correct gebruikt, een verrassend krachtig hulpmiddel kan zijn in deze instelling. Ten eerste bereikt onze eenvoudige maar effectieve kennisgestuurde tensor factorization benadering state-of-the-art resultaten op twee generieke KBs (80% nauwkeurig) voor de wetenschap, waarbij hun grootte met 74%-86% precisie wordt verdubbeld. Ten tweede is onze nieuwe taxonomie geleide, submodulaire, actieve leermethode voor het verzamelen van annotaties over zeldzame entiteiten (bijvoorbeeld oriole, een vogel) 6x effectiever in het afleiden van verdere nieuwe feiten over hen dan meerdere actieve leerbaselines.</abstract_nl>
      <abstract_hr>S obzirom na bazu znanja ili KB koja sadrži (bučne) činjenice o zajedničkim imenima ili generikama, poput 'svih drveća proizvode kisik' ili 'neke životinje žive u šumama', smatramo problem uvođenja dodatnih takvih činjenica na preciznost sličnu onome što je početnom KB-u. Takve KBs uhvate opće znanje o svijetu i ključne su za različite aplikacije poput odgovora na pitanje. Drugačije od često proučavanih entitetskih KB-a poput Freebase, generičnih KB-a uključuju kvantifikaciju, imaju kompleksnije temeljne redovitosti, navodno su nepotpunije i kršiju uobičajeno korištenu lokalno zatvorenu svjetsku pretpostavku (LCWA). Pokazujemo da postojeće metode završetka KB bore se s tim novim zadatkom i predstavljamo prvi pristup koji je uspješan. Naši rezultati pokazuju da vanjske informacije, poput režima veze i taksonomija entitata, ako se prikladno koristi, mogu biti iznenađujuće moćni alat u ovom stanju. Prvo, naš jednostavan, ali učinkovit pristup faktorizaciji tenzora usmjeren na znanje postiže rezultate stanja umjetnosti na dvije generične KBs (80% precizne) za znanost, povećavajući njihovu veličinu sa 74%-86% preciznosti. Drugo, naš novi taksonomija vodi, podmodularni, aktivni metod učenja za skupljanje annotacija o rijetkim entitetima (npr. oriola, ptica) je 6x učinkovitiji u uvođenju daljnjih novih činjenica o njima nego više aktivnih osnovnih linija učenja.</abstract_hr>
      <abstract_da>I betragtning af en vidensbase eller KB, der indeholder (støjende) fakta om almindelige navneord eller generiske betegnelser, såsom "alle træer producerer ilt" eller "nogle dyr lever i skove", betragter vi problemet med at udlede yderligere sådanne fakta med en nøjagtighed svarende til den oprindelige KB. Sådanne KBs indsamler generel viden om verden og er afgørende for forskellige applikationer såsom spørgsmål besvarelse. Forskellige fra almindeligt undersøgte navngivne entitet KBs såsom Freebase, generiske KBs involverer kvantificering, har mere komplekse underliggende regelmæssigheder, har tendens til at være mere ufuldstændige og overtræder den almindeligt anvendte lokalt lukkede verden antagelse (LCWA). Vi viser, at eksisterende KB fuldførelsesmetoder kæmper med denne nye opgave, og præsenterer den første tilgang, der er vellykket. Vores resultater viser, at eksterne oplysninger, såsom relationsskemaer og entitetstaksonomier, hvis de bruges korrekt, kan være et overraskende kraftfuldt værktøj i denne indstilling. For det første opnår vores enkle, men effektive vidensstyrede tensor factorization tilgang state-of-the-art resultater på to generiske KBs (80% præcise) til videnskab, fordoblet deres størrelse med 74% -86% præcision. For det andet er vores nye taxonomi guidede, submodulære, aktive læringsmetode til indsamling af noter om sjældne enheder (f.eks. oriole, en fugl) 6 gange mere effektiv til at udlede yderligere nye fakta om dem end flere aktive læringsgrundlinjer.</abstract_da>
      <abstract_de>Angesichts einer Wissensbasis oder KB, die (laute) Fakten über gewöhnliche Substantive oder Generika enthält, wie z.B. "alle Bäume produzieren Sauerstoff" oder "einige Tiere leben in Wäldern", betrachten wir das Problem, zusätzliche solche Fakten mit einer Genauigkeit zu schließen, ähnlich der der beginnenden KB. Solche KBs erfassen Allgemeinwissen über die Welt und sind entscheidend für verschiedene Anwendungen wie die Beantwortung von Fragen. Anders als allgemein untersuchte Entitäten-KBs wie Freebase beinhalten Generika-KBs Quantifizierung, haben komplexere zugrunde liegende Regelmäßigkeiten, sind tendenziell unvollständiger und verletzen die allgemein verwendete Local Closed World Annahme (LCWA). Wir zeigen, dass bestehende KB-Vervollständigungsmethoden mit dieser neuen Aufgabe zu kämpfen haben und stellen den ersten erfolgreichen Ansatz vor. Unsere Ergebnisse zeigen, dass externe Informationen, wie Beziehungsschemas und Entitätstaxonomien, bei entsprechender Verwendung ein überraschend leistungsfähiges Werkzeug in dieser Einstellung sein können. Erstens erzielt unser einfacher, aber effektiver wissensgesteuerter Tensorfaktorisierungsansatz modernste Ergebnisse auf zwei generischen KBs (80% präzise) für die Wissenschaft und verdoppelt ihre Größe mit 74%-86% Präzision. Zweitens ist unsere neuartige taxonomie geführte, submoduläre, aktive Lernmethode zum Sammeln von Anmerkungen über seltene Entitäten (z.B. Oriol, ein Vogel) 6x effektiver, um weitere neue Fakten über sie abzuleiten als mehrere aktive Lernbaselines.</abstract_de>
      <abstract_ko>흔히 볼 수 있는 명사나 범형(시끄러운) 사실, 예를 들어'모든 나무에서 산소가 발생한다'거나'일부 동물이 숲에서 생활한다'는 것을 포함하는 지식 라이브러리나 지식 라이브러리의 정밀도로 다른 사실을 추정하는 문제를 고려합니다.이러한 지식 라이브러리는 세계에 대한 일반적인 지식을 포획하여 각종 응용 프로그램(예를 들어 문답)에 매우 중요하다.일반적인 연구의 명명된 실체 지식 라이브러리(예를 들어 Freebase)와 달리 범형 지식 라이브러리는 양적화와 관련되어 더욱 복잡한 기본 규칙을 가지고 왕왕 더욱 완전하지 못하며 자주 사용하는 국부 폐쇄 세계 가설(LCWA)을 위반한다.우리는 기존의 지식 라이브러리 완성 방법이 이 새로운 임무를 완성하기 어렵다는 것을 보여 주었고 첫 번째 성공적인 방법을 제시했다.우리의 결과에 따르면 외부 정보, 예를 들어 관계 모델과 실체 분류법이 적절하게 사용되면 이런 상황에서 매우 강력한 도구가 될 수 있다.우선, 우리의 간단하고 효과적인 지식 유도 장량 인자 분해 방법은 과학에 사용되는 두 개의 범주형 KBS(80% 정밀도)에서 가장 선진적인 결과를 실현했고 74%-86%의 정밀도에서 그들의 크기가 두 배로 커졌다.그 다음으로 우리의 새로운 분류지도, 서브모듈, 능동적인 학습 방법은 희귀한 실체(예를 들어 꾀꼬리, 새)의 주석을 수집하는 데 사용되며 그것들과 관련된 더 많은 새로운 사실을 추정하는 데 여러 능동적인 학습 기선보다 6배 효과적이다.</abstract_ko>
      <abstract_tr>Bilim sistemasyna görä 'hemme agaç oksijen döreýär' ýa 'kimi haýwanlar tokaýda ýa şaýar' hasaplanýar, biz bu ýaly zatlary KB-iň başlangyçynda birnäçe deňil bir şekilde üýtgetmek üçin hasaplanýarys. Bütin KBler dünýä barada umumy bilgileri taýýarlar we sorag jogapy ýaly dürli uygulamalar üçin örän möhüm. Adatça okanan KB-lerden üýtgeşim bolsa Freebase ýaly, jeneral KB-leriň küýtgeşmeleri ylalaşyk bolýar, iň soňky düzgün düzgünleriň döwletleri ýok bolýar we olaryň ýakyn ýerli ýapylan dünýä üýtgeşmelerini bozmaýar. Biz bar kB tamamlama metodlarynyň bu täze zady bilen çykyp barýandygyny görkezip, we ilkinji ýagdaýy üstünlik gazandyrýarys. Biziň netijelerimiz daşarydaky maglumatyň, şemalar we gural taslaşmalary ýaly daşarydaky maglumatyň bu düzümlerde gaty güýçli bir araç bolup biler diýip görkezilýär. Ilkinji gezek, biziň basit hem etkinji bilgimiz ýüzünji şeklinde näsazlyk taýýarlanmasy ýagdaýynda bilim üçin 2 jeneral kB netijede ýetip barýar. Olaryň ölçüsini 74%-86% dyggaty artdyrylýar. Ikinji gezek, romanlarymyzyň taksonomiýasyny guruldy, submodular, aktiw öwrenmek yöntemi nadir bir zat hakynda ýazyklamak üçin (meseläm, oriol, kuş) 6x täze zatlary ýagdaý öwrenmek üçin birnäçe aktiw öwrenmek çyzgytlardan has efektdyr.</abstract_tr>
      <abstract_id>Berdasarkan dasar pengetahuan atau KB yang mengandung fakta (bising) tentang nama umum atau generik, seperti 'semua pohon menghasilkan oksigen' atau 'beberapa hewan hidup di hutan', kita mempertimbangkan masalah untuk menyimpulkan fakta-fakta tersebut tambahan dengan presisi yang sama dengan yang pada KB awal. KB seperti ini menangkap pengetahuan umum tentang dunia, dan penting untuk berbagai aplikasi seperti menjawab pertanyaan. Berbeda dari yang biasanya dipelajari entitas bernama KB seperti Freebase, generik KB melibatkan kuantifikasi, memiliki regularitas dasar yang lebih kompleks, cenderung menjadi lebih tidak lengkap, dan melanggar asumsi dunia tertutup lokal yang biasanya digunakan (LCWA). Kami menunjukkan bahwa metode penyelesaian KB yang ada berjuang dengan tugas baru ini, dan menunjukkan pendekatan pertama yang berhasil. Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  Pertama, pengetahuan sederhana namun efektif kita didorong pendekatan faktorisasi tensor mencapai hasil state-of-the-art pada dua KB generik (80% tepat) untuk ilmu pengetahuan, menggandakan ukuran mereka pada 74%-86% presisi. Kedua, metode pembelajaran aktif yang dipandu oleh taksonomi novel kita untuk mengumpulkan anotasi tentang entitas langka (contohnya oriol, burung) adalah 6x lebih efektif dalam menyimpulkan fakta baru lebih lanjut tentang mereka daripada berbagai garis dasar pembelajaran aktif.</abstract_id>
      <abstract_fa>با توجه به پایگاه دانش یا KB که شامل (صدا) حقیقت‌هایی در مورد نام‌های معمولی یا ژنتریک معمولی است، مانند «همه درختان اکسیژن را تولید می‌کنند» یا «بعضی حیوانات در جنگل زندگی می‌کنند»، مشکل اضافه کردن چنین حقیقت‌ها را به دقیق شبیه به آن‌ها از کل‌بی این کیب‌ها علم عمومی در مورد دنیا را گرفته می‌کنند و برای کاربردهای مختلف مثل جواب سوال مهم است. متفاوت از سابقه‌های معمولاً مطالعه شده‌ای که کیب‌های نامیده می‌شود، مثل «Freebase»، کیب‌های ژنتریک شامل تعداد تعداد، سابقه‌های معمولی پیچیده‌تری دارند، طبقه‌های غیر کامل‌تری می‌باشند، و تغییر فرضیه‌های جهانی که معمولاً در محلی بس ما نشان می دهیم که روش کامل کردن KB موجود با این کار جدید مبارزه می کنند و اولین روش موفقیت را نشان می دهیم. نتیجه‌های ما نشان می‌دهند که اطلاعات خارجی، مثل نقشه‌های ارتباطی و تاکسونوم‌های ارتباطی، اگر به طور مناسب استفاده می‌شود، می‌تواند یک ابزار فوق‌العاده قدرتمند در این تنظیم باشد. اول، دستور فناوریزی تنسور راهنمای دانش ساده‌ای ما به نتیجه‌های موجود هنر دو کیلومتر (۸۰ درصد دقیق) برای علم رسیده است، و اندازه‌شان را با دقیق 74 درصد-86 درصد دو برابر می‌کند. دوم، روش یادگیری تاکسونومی روزنامه‌ی نویسنی ما، زیر مودولر، فعال برای جمع آوری‌های درباره چیزهای نادر (مثال اوریول، پرنده) 6x موثرتر است که در آوری حقیقت جدید بیشتری در موردشان نسبت به خط‌های زیرزمین یادگیری فعال بیشتری در موردشان آوری</abstract_fa>
      <abstract_sw>Kutokana na msingi wa maarifa au KB yenye kelele (kelele) kuhusu matunda ya kawaida au asili ya jeni, kama vile 'miti yote hutengeneza oksygen' au 'wanyama wengine wanaishi misituni', tunafikiria tatizo la kuathiri ukweli wa ziada kama hizo kwa kiasi kikubwa kama ilivyofanana na kuanzia KB. Kama hizo KBs wanachukua maarifa ya jumla kuhusu dunia, na ni muhimu kwa matumizi mbalimbali kama vile majibu ya maswali. Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).  Tunaonyesha kuwa mbinu za kutimiza KB zilizopo zikipambana na kazi hii mpya, na kuweka mbinu za kwanza za za mafanikio. Matokeo yetu yanaonyesha kuwa taarifa za nje, kama vile mipango ya mahusiano na kodi za entity, kama inatumiwa kwa haki, inaweza kuwa zana yenye nguvu ya kushangaza katika mazingira haya. Kwanza, maarifa yetu rahisi lakini yenye ufanisi unaongoza mbinu za kutengeneza viwanda kwa kiwango fulani hufanikiwa matokeo ya sanaa kwa viwanda viwili vya KBs (asilimia 80 ya sayansi) kwa ajili ya sayansi, kwa kiasi kikubwa cha kuongezeka kwa asilimia 74-86. Pili, utamaduni wetu wa kitaifa uliongozwa, utaratibu wa kujifunza kwa haraka wa kukusanya matangazo yanayohusu vitu nadra (kama vile oriole, ndege) ni yenye ufanisi zaidi wa 66 katika kuathiri ukweli mpya zaidi kuhusu hizo kuliko misingi mbalimbali ya kujifunza.</abstract_sw>
      <abstract_am>እንደ ‘ዛፎች ሁሉ oksygen’ ወይም ‘አንዳንድ እንስሶች በዱር ውስጥ የሚኖሩ’ የሚል የውይይት መሠረት ቢሆን (ድምፅ) ወይም የKB ውይይት የሚኖር እውነተኞች ቢሆን፣ የKB መጀመሪያ እንደጀመሩ እንደምትመስል መከራ እናስባለን፡፡ እንደነዚህ ያሉት KBs በዓለም ላይ የዓለም አዋቂ እውቀትን ያዛሉ፣ እንደጠያየቁም መልስ እንዲመስል ለልዩ ፕሮግራሞች ያስፈልጋሉ፡፡ Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).  ይህ አዲስ ስራ ሲታገል እናሳየዋለን፡፡ ፍሬዎቻችን የውጭ መረጃዎች፣ የግንኙነት ፕሮግራም እና የአካባቢ ስኮኖሚ፣ በተግባር ቢጠቀም፣ በዚህ ማስተካከል የሚያስደንቅ ኃይለኛ መሣሪያ ይችላል፡፡ አስቀድሞ፣ ቀላል እውቀታችን ግን አሥር እውቀት ማቀናቀል አካባቢ የ-የ-የ-የ-አርእስት ፍሬታዎችን በሁለት የውይይት የKBs (80 በመቶ እርግጠኛ) ለሳይንቀሳዊ መጠን 74 በመቶ 86 በመቶ እጥፍ ይጨመርበታል፡፡ በሁለተኛው፣ የረኀብ ትክክለኛ፣ ደብዳቤ፣ የአካባቢ አካባቢዎች (ምሳሌ ኦሮዮ፣ ወፍ) የሚያሳስብ ስርዓት (ምሳሌ አዲስ ትምህርት መሠረት) ከእነዚህ አብዛኛዎቹ ከተማሩ መሠረት መሠረት ይልቅ 66 የበለጠ ነው፡፡</abstract_am>
      <abstract_hy>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  Այսպիսի ԿԲ-ները հավաքում են աշխարհի մասին ընդհանուր գիտելիքներ և կարևոր են տարբեր ծրագրերի համար, ինչպիսիք են հարցերի պատասխանը: Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).  Մենք ցույց ենք տալիս, որ գոյություն ունեցող ԿԲ-ի ավարտական մեթոդները պայքարում են այս նոր խնդրի հետ և ներկայացնում են առաջին հաջողակ մոտեցումը: Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  Առաջինը, մեր պարզ, սակայն արդյունավետ գիտելիքների ուղղությամբ տենսորի գործոնացման մոտեցումը հասնում է լավագույն արդյունքներին երկու գեներական ԿԲ-ի (80 տոկոս ճշգրիտ) վրա գիտության համար, կրկնապատկելով նրանց չափը 74-86 տոկոսի ճշգրիտության վրա Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_hy>
      <abstract_af>Gien 'n kennis basie of Kb wat (geluid) fakte bevat oor gemeenskare noume of generieke, soos 'alle bome produseer oksygenis' of 'sommige diere lewe in boste', ons dink die probleem van die verwyder van ekstra sodanige fakte by 'n presisie gelyk aan wat van die begin Kb. sodanige Kbs het algemene kennis oor die wêreld opgeneem, en is crucial vir verskeie toepassings soos vraag antwoord. Verskillende van gemeenskaplik ondersoekte entiteite Kb soos Freebase, generieke Kb insluit kvantifikasie, het meer komplekse ondersoekte regulariseite, tendig om meer onvolledige te wees en die gewoonlik gebruikte lokaal gesluit wêreld-assumpsie (LCWA) te violeer. Ons wys dat bestaande Kb voltooiing metodes struikel met hierdie nuwe taak, en voorsien die eerste toegang wat suksesvol is. Ons resultate wys dat eksterne inligting, soos verwanting skemas en entiteittaksonomies, indien toepaslik gebruik word, kan 'n verwonderbaar kragtige hulpmiddel wees in hierdie opstelling. Eerste, ons eenvoudige, nog effektief kennis gevoerde tensor faktoriseering toegang bereik staat-van-die-kuns resultate op twee generieke KBs (80% presies) vir wetenskap, dubbel hulle grootte by 74%-86% presies. Tweede, ons roman taksonomie gids, submodular, aktiewe leer metode vir die versamel van notasies oor rare entiteite (bv. oriël,  'n voël) is 6x meer effektief om verdere nuwe fakties oor hulle te bring as veelvuldige aktiewe leer basisline.</abstract_af>
      <abstract_bs>S obzirom na bazu znanja ili KB koja sadrži (bučne) činjenice o zajedničkim imenima ili generikama, poput 'sve drveće proizvode kisik' ili 'neke životinje žive u šumama', smatramo problem uvođenja dodatnih takvih činjenica na tačnost sličnu onome što je početnom KB-u. Takve KBs uhvate opće znanje o svijetu i ključne su za različite aplikacije poput odgovora na pitanje. Drugačije od češće proučavanih entitetskih KB-a poput Freebase, generičnih KB-a uključuju kvantifikaciju, imaju kompleksne ispod redovitosti, često su nepotpunije i kršiju uobičajeno korištenu lokalno zatvorenu svjetsku pretpostavku (LCWA). Pokazujemo da postojeće metode završetka KB bore se s ovim novim zadatkom i predstavljamo prvi pristup koji je uspješan. Naši rezultati pokazuju da vanjska informacija, poput rešema odnosa i taksonomija entitata, ako se prikladno koristi, može biti iznenađujuće moćna alata u ovom stanju. Prvo, naš jednostavan, ali efikasni pristup faktorizacije tenzora vodi do znanja ostvario je rezultate stanja umjetnosti na dva generična KB (80% precizno) za nauku, povećavajući njihovu veličinu sa 74%-86% preciznosti. Drugo, naša nova taksonomija vodi, podmodularni, aktivni metod učenja za skupljanje annotacija o rijetkim entitetima (npr. oriola, ptica) je 6x efikasniji u prijavi novih činjenica o njima od višestruke aktivne osnovne linije učenja.</abstract_bs>
      <abstract_az>Bütün a ğaclar oksijen ürəkləyir və ya 'bəzi heyvanlar ormanlarda yaşadıqları' kimi, bu həqiqətləri başlangıç KB-in bənzərinə bənzər bir qismində daxil etmək problemini düşünürük. Bütün KB dünya haqqında genel bilgi alır və sual cavab vermək kimi müxtəlif uyğulamalar üçün çox vacib olur. Freebase kimi çoxlu təhsil edilənlər KB kimi, qüdrət KB kimi, qüdrət KB kimi, daha kompleks düzgünlüklər vardır, daha çox kompleks olarlar və çoxlu yerli qapılmış dünya təsəvvürlərini boşarlar (LCWA). Biz həmin KB tamamlama metodlarının bu yeni iş ilə mübahisə edir və başarılı olan ilk tərzini göstəririk. Sonuçlarımız belə göstərir ki, əgər bu şəkildə yaxşı işlənirsə, həmçin in bağlantı schemları və entity taxonomiyaları kimi, daxili daxili məlumat bu şəkildə çox qüvvətli bir vasitə olar. İlk dəfə, bizim basit hətta effektiv elmimiz, tensor fabrikasiya yolu göstərilən təhsil olaraq bilim üçün iki generiki KB (80%-accuracy) sonuçlarını art ırar, onların böyüklüyünü 74%-86% dəqiqliyində artırar. İkincisi, yeni taksonomiyyətimiz, submodular, aktif öyrənmə metodumuz, nadir məxluqat haqqındakı məlumatları toplamaq üçün (məsələn, oriol, quş) 6x daha etkilidir ki, onların haqqında çoxlu aktif öyrənmə səhifələrindən daha çox yeni faktirlər çəkir.</abstract_az>
      <abstract_cs>Vzhledem k znalostní bázi nebo KB obsahující (hlučné) fakta o běžných podstatných nebo generických jménech, jako například "všechny stromy produkují kyslík" nebo "některá zvířata žijí v lesích", zvažujeme problém odvození dalších takových faktů s přesností podobnou jako u počáteční KB. Takové KBs zachycují obecné znalosti o světě a jsou klíčové pro různé aplikace, jako je odpověď na otázky. Na rozdíl od běžně studovaných pojmenovaných entit KBs, jako je Freebase, generické KBs zahrnují kvantifikaci, mají složitější základní pravidelnosti, mají tendenci být neúplnější a porušují běžně používaný lokálně uzavřený svět předpoklad (LCWA). Ukazujeme, že stávající metody dokončování KB s tímto novým úkolem bojují a představujeme první přístup, který je úspěšný. Naše výsledky ukazují, že externí informace, jako jsou schémata vztahů a taxonomie entit, pokud jsou použity vhodně, mohou být v tomto nastavení překvapivě výkonným nástrojem. Za prvé, náš jednoduchý, ale efektivní znalostně řízený tenzorový faktorizační přístup dosahuje nejmodernějších výsledků u dvou generických KBs (80% přesných) pro vědu a zdvojnásobuje jejich velikost při 74%-86% přesnosti. Za druhé, naše nová taxonomie řízená submodulární, aktivní učební metoda pro sběr anotací o vzácných entitách (např. oriol, pták) je 6x efektivnější při odvozování dalších nových faktů o nich než několik aktivních učebních linek.</abstract_cs>
      <abstract_sq>Duke pasur parasysh një bazë njohurie apo KB që përmban (zhurmë) fakte rreth emrave të përbashkëta apo gjenerike, të tilla si "të gjitha pemët prodhojnë oksigjen" apo "disa kafshë jetojnë në pyje", ne konsiderojmë problem in e përfundimit të fakteve shtesë të tilla në një saktësi të ngjashme me at ë të KB-së filluese. KB të tilla kapin njohuri të përgjithshme rreth botës dhe janë vendimtare për aplikacione të ndryshme të tilla si përgjigjet pyetjeve. Ndryshe nga njësia me emër të studiuar në mënyrë të zakonshme KB të tilla si Freebase, generics KB përfshijnë kuantifikim, kanë rregullalitet më komplekse bazë, kanë tendencë të jenë më të pakompletë dhe shkelin supozimin e botës së mbyllur në mënyrë të zakonshme (LCWA). Ne tregojmë se metodat ekzistuese të përfundimit të KB-së luftojnë me këtë detyrë të re dhe paraqesin qasjen e parë që është e suksesshme. Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  Së pari, metoda jonë e thjeshtë por efektive e drejtuar nga njohuria e faktorizimit të tensorit arrin rezultate më të larta në dy KB gjenerike (80% saktë) për shkencën, duke dyfishuar madhësinë e tyre me 74%-86% saktësi. Së dyti, metoda jonë e drejtuar nga taksonomia, nënmodulare dhe aktive e mësimit për mbledhjen e anotacioneve rreth njësive të rralla (për shembull oriol, një zog) është 6x më e efektshme në përfundimin e fakteve të mëtejshme të reja rreth tyre sesa linjat bazë të mësimit të shumëfishtë aktiv.</abstract_sq>
      <abstract_et>Arvestades teadmistebaasi või KB-d, mis sisaldavad (mürakaid) fakte tavaliste nimisõnade või geneeriliste sõnade kohta, nagu näiteks "kõik puud toodavad hapnikku" või "mõned loomad elavad metsas", käsitleme probleemi selliste täiendavate faktide järeldamisega sarnaselt algse KB-ga. Sellised KBd koguvad üldist teadmisi maailmast ja on olulised erinevate rakenduste jaoks, näiteks küsimustele vastamiseks. Erinevalt tavaliselt uuritud nimetatud üksuste KBdest, nagu Freebase, hõlmavad geneerilised KBd kvantifitseerimist, nende aluseks on keerulisemad regulaarsused, kipuvad olema ebatäielikumad ja rikuvad tavaliselt kasutatavat kohalikult suletud maailma eeldust (LCWA). Näitame, et olemasolevad KB lõpetamise meetodid võitlevad selle uue ülesandega ning esitame esimese eduka lähenemisviisi. Meie tulemused näitavad, et välised andmed, näiteks seosskeemid ja üksuste taksonoomiad, kui neid kasutatakse asjakohaselt, võivad olla selles seadmes üllatavalt võimas tööriist. Esiteks saavutab meie lihtne, kuid tõhus teadmistepõhine tensoorfaktorisatsiooni lähenemine kahe geneerilise KB-ga (80% täpne) tipptasemel tulemused, kahekordistades nende suuruse 74%-86% täpsusega. Teiseks on meie uus taksonoomia juhendatud, submodulaarne aktiivne õppemeetod haruldaste üksuste kohta märkuste kogumiseks (nt oriool, lind) 6 korda efektiivsem nende kohta uute faktide järeldamisel kui mitmed aktiivse õppe lähtejooned.</abstract_et>
      <abstract_fi>Kun otetaan huomioon tietopohja tai tietopohja, joka sisältää (meluisia) faktoja yleisistä substantiiveistä tai geneerisistä aineista, kuten "kaikki puut tuottavat happea" tai "jotkut eläimet elävät metsissä", otamme huomioon ongelman päätellä lisää tällaisia faktoja vastaavalla tarkkuudella kuin aloitustietopohja. Tällaiset KB:t keräävät yleistä tietoa maailmasta, ja ne ovat ratkaisevan tärkeitä eri sovelluksissa, kuten kysymyksissä vastaamisessa. Toisin kuin yleisesti tutkittu nimetty kokonaisuus KB, kuten Freebase, geneeriset KB:t sisältävät kvantifiointia, niillä on monimutkaisempia perussääntöjenvastaisuuksia, ne ovat yleensä epätäydellisiä ja rikkovat yleisesti käytettyä paikallisesti suljettua maailmaa koskevaa oletusta (LCWA). Osoitamme, että nykyiset KB-täydennysmenetelmät kamppailevat tämän uuden tehtävän kanssa, ja esittelemme ensimmäisen onnistuneen lähestymistavan. Tuloksemme osoittavat, että ulkoiset tiedot, kuten suhdekaaviot ja entiteettitaksonomiat, voivat asianmukaisesti käytettynä olla yllättävän tehokas työkalu tässä asetuksessa. Ensinnäkin yksinkertainen, mutta tehokas tietoohjattu tensorifaktorisointi-lähestymistapamme saavuttaa huipputason tulokset kahdella geneerisellä KB:llä (80% tarkka) tieteeseen, kaksinkertaistaen niiden koon 74–86% tarkkuudella. Toiseksi, uusi taksonomiaohjattu, submodulaarinen, aktiivinen oppimismenetelmä harvinaisten entiteettien (esim. orioli, lintu) huomautusten keräämiseen on kuusi kertaa tehokkaampi päätellä niistä uusia faktoja kuin useita aktiivisia oppimislähtökohtia.</abstract_fi>
      <abstract_bn>একটি জ্ঞানের বেস বা কেবির মধ্যে সাধারণ নিষেধাজ্ঞা বা জেনেজিজেনের ব্যাপারে (শব্দ) বাস্তবতা দিয়ে যেমন 'সকল গাছ উৎপাদন করে অক্সিজেন' অথবা 'কিছু প্রাণী বনে বাস করে, আমরা  এই ধরনের কেবিএস বিশ্ব সম্পর্কে সাধারণ জ্ঞান ধরে নিয়েছে এবং প্রশ্নের উত্তরের মতো বিভিন্ন অ্যাপলিকেশনের জন্য গুর সাধারণত গবেষণার নাম কেবিএস, যেমন ফ্রিবাস, জেনেরিকেবিস সংখ্যার সাথে যুক্ত, আরো কঠিন নিয়ম রয়েছে, যেমন বেশী অসম্পূর্ণ, এবং স্থানীয় বন্ধ বিশ্ব ধারণা লঙ্ঘন করে। আমরা দেখাচ্ছি যে বিদ্যমান কেবি সম্পূর্ণ পদ্ধতি এই নতুন কাজের সাথে সংগ্রাম করছে এবং প্রথম পদক্ষেপ যা সফল হয়েছে ত Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  প্রথমত, আমাদের সাধারণ জ্ঞান এখনো কার্যকর পরিচালিত হয়েছে টেনসার ফ্যাক্টরিশন কার্যক্রমের ক্ষেত্রে দুটি জেনেরিক কেবিএসের রাষ্ট্রের ফলাফল অর্জন করেছে (৮০% ব দ্বিতীয়, আমাদের উপন্যাসের ট্যাক্সোনামি নির্দেশিত, সাবমোডিয়াল, সক্রিয় শিক্ষার পদ্ধতি সংগ্রহ করার (যেমন দুর্লম্ব বিদ্যালয়, পাখি) বিষয়বস্তুর বিষয়গুলোর ব</abstract_bn>
      <abstract_ca>Dant una base de coneixements o KB que conté fets (sorollosos) sobre noms comuns o genèrics, com "tots els arbres produeixen oxigen" o "alguns animals viuen en boscos", considerem el problem a de deduir altres fets així a una precisió similar a la de la KB inicial. Such KBs capture general knowledge about the world, and are crucial for various applications such as question answering.  Different from commonly studied named entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA).  Mostrem que els mètodes de completament de KB existents lluiten amb aquesta nova tasca i presenten el primer enfocament que té èxit. Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting.  First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80% precise) for science, doubling their size at 74%-86% precision.  Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_ca>
      <abstract_sk>Glede na bazo znanja ali KB, ki vsebuje (hrupna) dejstva o običajnih samostalnikih ali generičnih besedilih, kot je "vsa drevesa proizvajajo kisik" ali "nekatere živali živijo v gozdovih", obravnavamo problem sklepanja dodatnih takih dejstev z natančnostjo, podobno tisti v začetni KB. Takšne KB zajemajo splošno znanje o svetu in so ključnega pomena za različne aplikacije, kot je odgovor na vprašanja. Drugače od običajno preučevanih imenovanih subjektov KB, kot je Freebase, generične KB vključujejo kvantifikacijo, imajo bolj kompleksne osnovne pravilnosti, so običajno bolj nepopolne in kršijo pogosto uporabljeno lokalno zaprto domnevo sveta (LCWA). Pokazujemo, da obstoječe metode dokončanja KB težijo s to novo nalogo in predstavljamo prvi pristop, ki je uspešen. Naši rezultati kažejo, da so lahko zunanje informacije, kot so relacijske sheme in taksonomije entitet, če se uporabljajo ustrezno, presenetljivo močno orodje v tej nastavitvi. Najprej, naš preprost, vendar učinkovit pristop k faktorizaciji tenzorjev, voden na znanju, doseže najsodobnejše rezultate na dveh generičnih KB (80% natančna) za znanost in podvoji njihovo velikost pri 74%-86% natančnosti. Drugič, naša nova taksonomijsko vodena, submodularna, aktivna metoda učenja za zbiranje opomb o redkih entitetah (npr. oriolu, ptici) je šestkrat učinkovitejša pri sklepanju novih dejstev o njih kot več aktivnih izhodišč učenja.</abstract_sk>
      <abstract_ha>Gida wani sali na sano ko KB wanda ke ƙunsa da gaskiya masu hususan da sune ko jeni, kamar 'duk itãce ke tsirar oksygen' ko 'na'yan dabbõbi sunã cikin wurãre', ko kuma tuna mataimako da za'a sami masu ƙaranci masu kama da shi na fara KB. Kamar waɗancan KBs sun kãma wani ilmi na jumla a kan duniya, kuma yana da muhimu ga shiryoyin ayuka masu kama masu tambayar. Farawa daga kowancin da aka karanta a bayani da aka ambaci sunan KBs kamar Freebase, misãlin KBs na haɗi tsarin, sun da wasu shiryoyin masu adadi masu ƙarƙashin ƙaddara, sunã da kamfata mafi cikakken, kuma sunã warware da misãlai da aka yi amfani da shi a lokal rufe duniya (LCWA). Tuna nũna cewa metoden cikakken KB masu yin jihãdi da wannan aikin na yanzu, kuma mu yanyanke na farkon hanyor wanda ya kasance na cin nasara. MatamayinMu sun nuna cewa, ma'anar bayani, kamar kwamfyutan mazaɓa da matsayin abubuwa, idan an yi amfani da shi daidai, za'a iya zama zane mai ƙarfi a cikin wannan settings. Kayyan, ma'ananmu masu sauƙi da fassarar kunyar ta shirya hanyor kungiyar fassarar-kungiyar ta kai halin-fassarar-kungiyar KBs (80% fassara) wa sanar, yana ƙara girma a shekara 74%-86% na ƙayyade. Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</abstract_ha>
      <abstract_jv>Nyong-ngodekake sistem sing paling dhuwur kesempatan karo pernik (ingang) ingkang angka sing nyimpen, koyo 'gak pernik' lan 'kewat karo bek' supoyo 'sak enem sing bisa nêmên kanggo ngerayakno, kita isih pernik nggawe nguasah seneng nggawe barang langgar-uwur kesempatan sing dumadhi koyo ngono nggawe Mb. Kibro-Kibro kuwi nggawe ngerasara awak kenal ning dunya, lan wong liyane kanggo ngerasara aplikasi sing kalang-wong liyane Dijejer-jejer kaloroh sing dipunangé karo akeh liyane K-blot lagi lagi "freebaz", kayata "kB-blot" sing beraksi kuwi nggunakake kuwi nyang sumelang, ditawakdhé awak dhéwé kuwi dulasakno, tentang ngono nggawe ketemu podho awak dhéwé beraksi barêng-barêng (LCWA). Awak dhéwé ngerasakno sistem sing gawe Ketoken pertaman karo nggawe task sing dibutuhke lan nganggo pertaman sing susahke batasan. Rejalaké awak dhéwé menehi ngomong nik akeh informasi luwih-luwih, koyo ngono akeh-luwih dumadhi kanggo nik kabèh dumadhi, iso dianggawe barang-sistem sing gak adhil kanggo nambah iki. Awak dhéwé, ngénaké kesempil sampeyan luwih akeh nggawe gerarané perusahaan karo hal-hal kuwi mau-kalem sekondirno sakjane dhéwé (8% diperaksi) sing sampeyan sabanjuré, iso nggawe wigatiningaké karo perusahaan 75%-draw % Pak-Pak, nganggo tanggal manut sing dadi, sembol-modul, iso nggawe sistem sing dibutuhke tarjamahan kanggo kowe perintah sing dibutuhke sithik (isih. Oriol, manut) sing 6 x luwih apik sing luwih apik dhéwé, lak dhéwé kuwi susahé supoyo awak dhéwé kuwi tambah kuwi tambah sing perusahaan</abstract_jv>
      <abstract_bo>དབྱིབས་ཤེས་ཀྱི་གཞི་རྟེན་དང་། ཚིག་རྩ་བ་སྤྱི་ཚོགས་དང་གྲངས་འབོར་བའི་ཆ་རྐྱེན་ཅིག་ལ་བཞག་ཡོད། ཡིག་ཆ་འདི་དག་ལ་འཛམ་གླིང་སྐོར་གྱི་སྤྱི་ཚོགས་ཤེས་ཀྱི་རྣམས་པར་འཛིན་ཡོད་པ། དེ་ལས་ཉེར་སྤྱོད་འདི་ལ་ལན་གསལ Different from commonly studied entity KBs such as Freebase, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA). ང་ཚོས་དུས་ཡོད་པའི་KB་ཡོངས་རྫོགས་ཐབས་ལམ་ལ་བྱ་འགུལ་གསར་བ་འདི་ལ་འཐབ་རྩོད་བྱེད་ཀྱི་ཡོད་པ་དང་གནད་སྤ Our results demonstrate that external information, such as relation schemas and entity taxonomies, if used appropriately, can be a surprisingly powerful tool in this setting. དང་པོ་ནས་ང་ཚོའི་སྔོན་ལྟར་རང་ཉིད་ཀྱིས་དམིགས་འཛུགས་ཀྱི་ཐབས་ལམ་དུ་གཏོང་བ་ཡིན་པའི་གནས་སྟངས་དང་འབྲེལ་བ་གཉིས་ཀྱིས་མཐུན་རྒྱུ་དང་། གཉིས་པ། ང་ཚོའི་གསར་གཏོད་ཁང་གི་དྲ་རྒྱ་སྟངས་ཀྱི་ལག་ལེན་འཐབ་ལམ་ལུགས་སྡུད་མེད་དུ་གླེང་སྒྲུབ་ཀྱི་ཐབས་ལམ་ལུགས་སྐྱེས་པ་ཞིག་ཡོད།</abstract_bo>
      <abstract_he>Given a knowledge base or KB containing (noisy) facts about common nouns or generics, such as 'all trees produce oxygen' or 'some animals live in forests', we consider the problem of inferring additional such facts at a precision similar to that of the starting KB.  KBs כאלה תופסים ידע כללי על העולם, והם קריטיים עבור שימושים שונים כמו לענות על שאלות. בניגוד ליחידות KB שנלמדות באופן רגיל כמו Freebase, generics KB מכילים כיוון, יש קבועות בסיסית מורכבות יותר, נוטים להיות לא מושלמות יותר, ולהפר את ההנחה העולמית סגורה מקומית (LCWA). אנחנו מראים ששיטות סיום KB קיימות נאבקות עם המשימה החדשה הזו, ומציג את הגישה הראשונה שמצליחה. התוצאות שלנו מראות כי מידע חיצוני, כמו skemas מערכות יחסים ומוניות היחידות, אם משתמשים בהתאם, יכול להיות כלי חזק באופן מפתיע במצב הזה. ראשית, גישת הידע הפשוטה, אך יעילה, המדריכת למפעל מתנגד משיגה תוצאות מוקדמות על שני קי.בי.איי גנריקים (80% מדויקים) למדע, כפילה את הגודל שלהם ב-74%-86% מדויק. שנית, שיטת הלימודים הפעילה, המדריכה למקסינומיה הרומנית שלנו לאסוף ציונים על ישויות נדירות (למשל אוריול, ציפור) היא 6x יותר יעילה בהוצאה עובדות חדשות נוספות עליהן מאשר קווי הבסיס של הלימודים הפעילים רבים.</abstract_he>
      </paper>
    <paper id="16">
      <title>Unsupervised Grammar Induction with Depth-bounded PCFG<fixed-case>PCFG</fixed-case></title>
      <author><first>Lifeng</first><last>Jin</last></author>
      <author><first>Finale</first><last>Doshi-Velez</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <doi>10.1162/tacl_a_00016</doi>
      <abstract>There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011 ; Noji and Johnson, 2016 ; Shain et al., 2016). This work extends this depth-bounding approach to probabilistic context-free grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depth-bounding. Results for this model on <a href="https://en.wikipedia.org/wiki/Grammar">grammar acquisition</a> from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy. Moreover, <a href="https://en.wikipedia.org/wiki/Grammar">grammars</a> acquired from this <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.</abstract>
      <pages>211–224</pages>
      <url hash="9fe0a145">Q18-1016</url>
      <video href="https://vimeo.com/277673890" />
      <bibkey>jin-etal-2018-unsupervised</bibkey>
      <pwccode url="https://github.com/lifengjin/db-pcfg" additional="false">lifengjin/db-pcfg</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    <title_ar>الاستقراء النحوي غير الخاضع للإشراف مع PCFG محدود العمق</title_ar>
      <title_es>Inducción gramatical no supervisada con PCFG de profundidad limitada</title_es>
      <title_pt>Indução gramatical não supervisionada com PCFG limitado por profundidade</title_pt>
      <title_fr>Induction grammaticale non supervisée avec PCFG limité en profondeur</title_fr>
      <title_ja>深さ制限付きPCFGを使用した文法誘導の監督なし</title_ja>
      <title_hi>गहराई से घिरा PCFG के साथ असुरक्षित व्याकरण प्रेरण</title_hi>
      <title_zh>用深度有界 PCFG 者无监语法归</title_zh>
      <title_ru>Неконтролируемая грамматическая индукция с глубинным PCFG</title_ru>
      <title_ga>Ionduchtú Gramadaí Gan Maoirseacht le PCFG le teorainn dhomhain</title_ga>
      <title_el>Μη εποπτευόμενη γραμματική επαγωγή με οριοθετημένο σε βάθος PCFG</title_el>
      <title_hu>Felügyelet nélküli nyelvtani indukció mélységkorlátozott PCFG-vel</title_hu>
      <title_ka>განსხვავებული გრამატური ინდექცია მანძილის განსაზღვრებული PCFG</title_ka>
      <title_it>Induzione grammaticale non controllata con PCFG delimitato dalla profondità</title_it>
      <title_kk>Жергілікті шектелген PCFG грамма индукциясы</title_kk>
      <title_lt>Neprižiūrima gramos indukcija su gilumo ribomis PCFG</title_lt>
      <title_mk>Ненадгледувана граматска индукција со PCFG со длабока граница</title_mk>
      <title_ms>Induksi Gram Tidak Dikawal dengan PCFG Terbatas Kedalaman</title_ms>
      <title_mt>Induzzjoni Grammarja Mhux Sorveljata b’PCFG limitat għall-fond</title_mt>
      <title_ml>ആഴത്തില്‍ നില്‍ക്കുന്ന പിസിഎഫിജിയോടൊപ്പം നിരീക്ഷിക്കപ്പെടാത്ത ഗ്രാമ്മറ്‍ ഇന്‍ഡിക്ഷന്‍</title_ml>
      <title_mn>Гүнд хязгаарлагдсан PCFG</title_mn>
      <title_no>Ikkje oppretta Grammar- Induksjon med Djupngrensa PCFG</title_no>
      <title_pl>Niekontrolowana indukcja gramatyki z PCFG o ograniczonej głębokości</title_pl>
      <title_ro>Inducţie gramaticală nesupravegheată cu PCFG limitată la adâncime</title_ro>
      <title_sr>Neodređena granična indukcija sa PCFG ograničenim dubinom</title_sr>
      <title_si>ගොඩක් සම්පූර්ණ PCFG සඳහා ග්‍රාමාර්මාර් ඉන්දීමක් නැති</title_si>
      <title_sv>Icke övervakad grammatisk induktion med djupbunden PCFG</title_sv>
      <title_so>Induction aan la ilaalinayn Grammar with Depth-bounded PCFG</title_so>
      <title_ta>Unsupervised Grammar Induction with Depth-bounded PCFG</title_ta>
      <title_ur>عمیق محدود PCFG کے ساتھ غیر محفوظت کی گرامر انڈاکٹ</title_ur>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_uz>Comment</title_uz>
      <title_da>Ikke-overvåget grammatisk induktion med dybdegrænset PCFG</title_da>
      <title_nl>Niet-begeleide grammatica inductie met dieptebepende PCFG</title_nl>
      <title_de>Unaufsichtigte Grammatik Induktion mit Tiefenbegrenzung PCFG</title_de>
      <title_bg>Неконтролирана граматична индукция с ограничена дълбочина PCFG</title_bg>
      <title_hr>Neodređena granična indukcija s PCFG ograničenim dubinom</title_hr>
      <title_ko>깊이 유계 PCFG의 무감독 문법 귀납</title_ko>
      <title_id>Induksi Gram Tidak Disupervisi dengan PCFG Berbatas Kedalaman</title_id>
      <title_fa>تأثیر گرم غیرقابل حفاظت با PCFG محدود عمیق</title_fa>
      <title_sw>Uoneshaji wa Grammar usiotangazwa na PCFG</title_sw>
      <title_tr>Gaýd edilmedik PCFG bilen Mazmunlar Girişi</title_tr>
      <title_hy>Առանց վերահսկված գրամամային ինդուկցիան խորության սահմանափակ պոֆԳ-ով</title_hy>
      <title_af>Onondersteunde Grammar Induksie met Djipte- gebrende PCFG</title_af>
      <title_bn>গভীর-সীমাবদ্ধ পিসিএফজির সাথে অনলাইন করা গ্রামার নির্দেশনা</title_bn>
      <title_sq>Induktimi i Gramave i Pambikqyrur me PCFG të kufizuar me thellësi</title_sq>
      <title_am>undo-type</title_am>
      <title_az>D…ôrzind…ô qurulmu≈ü PCFG olan Grammar Induksyonu</title_az>
      <title_bs>Neodređena granična indukcija s PCFG ograničenim dubinom</title_bs>
      <title_ca>Inducció gram sense supervisió amb PCFG llimitat a profunditat</title_ca>
      <title_cs>Nehlídaná gramatická indukce s hloubkově omezeným PCFG</title_cs>
      <title_fi>Tarkkailematon kieliopin induktio, jossa on syvyysrajoitus PCFG</title_fi>
      <title_et>Järelevalveta grammatika induktsioon sügavusega PCFG</title_et>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>תוכנית גרמה ללא השגחה עם PCFG מוגבל עמוק</title_he>
      <title_sk>Nenadzorovana slovnična indukcija z globinsko omejenim PCFG</title_sk>
      <title_jv>Learn Mode</title_jv>
      <title_bo>རྩིས་བ་སྲུང་མེད་པའི་སྒུལ་རྒྱས་ཁབ་ཀྱི་Induction with depth-bounded PCFG</title_bo>
      <abstract_pt>Tem havido interesse recente em aplicar limites motivados cognitivamente ou empiricamente na profundidade de recursão para limitar o espaço de busca de modelos de indução gramatical (Ponvert et al., 2011; Noji e Johnson, 2016; Shain et al., 2016). Este trabalho estende essa abordagem de limitação de profundidade para a indução de gramática livre de contexto probabilística (DB-PCFG), que possui um espaço de parâmetros menor do que os modelos de sequência hierárquica e, portanto, explora mais completamente as reduções de espaço da limitação de profundidade. Os resultados para este modelo de aquisição gramatical de fala dirigida a crianças e textos de notícias transcritos excedem ou são competitivos com os de outros modelos quando avaliados na precisão da análise. Além disso, gramáticas adquiridas a partir deste modelo demonstram um uso consistente de rótulos de categoria, algo que não foi demonstrado por outros modelos de aquisição.</abstract_pt>
      <abstract_fr>Il y a eu récemment un intérêt pour l'application de limites motivées par des considérations cognitives ou empiriques à la profondeur de récursion afin de limiter l'espace de recherche des modèles d'induction grammaticale (Ponvert et al., 2011 ; Noji et Johnson, 2016 ; Shain et al., 2016). Ce travail étend cette approche de limitation de profondeur à l'induction grammaticale probabiliste sans contexte (DB-PCFG), qui possède un espace de paramètres plus petit que les modèles de séquence hiérarchique, et exploite donc plus pleinement les réductions d'espace de la limite de profondeur. Les résultats de ce modèle sur l'acquisition grammaticale à partir de la parole transcrite à l'intention de l'enfant et du texte de fil d'actualité dépassent ou sont compétitifs par rapport à ceux des autres modèles lorsqu'ils sont évalués sur la précision de l'analyse. De plus, les grammaires acquises à partir de ce modèle démontrent une utilisation cohérente des étiquettes de catégories, ce qui n'a pas été démontré par d'autres modèles d'acquisition.</abstract_fr>
      <abstract_ar>كان هناك اهتمام حديثًا بتطبيق الحدود المعرفية أو ذات الدوافع التجريبية على عمق التكرار للحد من مساحة البحث الخاصة بنماذج الاستقراء النحوي (Ponvert et al. ، 2011 ؛ Noji and Johnson ، 2016 ؛ Shain et al. ، 2016). يوسع هذا العمل هذا النهج المحيط بالعمق إلى الاستقراء النحوي الخالي من السياق الاحتمالي (DB-PCFG) ، والذي يحتوي على مساحة معلمة أصغر من نماذج التسلسل الهرمي ، وبالتالي يستغل بشكل كامل التخفيضات في مساحة إحاطة العمق. نتائج هذا النموذج على اكتساب القواعد النحوية من الكلام الموجه للأطفال والنص الإخباري تتجاوز أو تتنافس مع تلك الخاصة بالنماذج الأخرى عند تقييمها على دقة التحليل. علاوة على ذلك ، توضح القواعد النحوية المكتسبة من هذا النموذج الاستخدام المتسق لعلامات الفئات ، وهو أمر لم يتم إثباته بواسطة نماذج الاستحواذ الأخرى.</abstract_ar>
      <abstract_es>Recientemente ha habido interés en aplicar límites motivados cognitiva o empíricamente en la profundidad de recursión para limitar el espacio de búsqueda de los modelos de inducción gramatical (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Este trabajo amplía este enfoque de delimitación de profundidad a la inducción probabilística de gramática libre de contexto (DB-PCFG), que tiene un espacio de parámetros más pequeño que los modelos de secuencia jerárquica y, por lo tanto, aprovecha más plenamente las reducciones de espacio de la delimitación de profundidad. Los resultados de este modelo sobre la adquisición de gramática a partir del discurso transcrito dirigido a niños y el texto de la cadena de noticias superan o son competitivos con los de otros modelos cuando se evalúan en la precisión del análisis. Además, las gramáticas adquiridas a partir de este modelo demuestran un uso coherente de las etiquetas de categoría, algo que no han demostrado otros modelos de adquisición.</abstract_es>
      <abstract_zh>近人有兴于递归深度上应用识验动机界限语法归模索空(Ponvert等,2011。 Noji and Johnson， 2016; Shain等,2016)。 其深边之法至于概率上下文无关文法归(DB-PCFG),其参数空比分序小,故益用深界之间。 当评估解析准确性时,转录童子导语音新闻线文本者语法取之过与争。 取诸其语法,此其他未得其验也。</abstract_zh>
      <abstract_ja>最近、再帰深度に認知的または経験的に動機づけられた境界を適用して、文法帰納モデルの検索空間を制限することに関心がある（ Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016 ）。この研究は、この深さ境界アプローチを確率的文脈自由文法帰納法（ DB - PCFG ）に拡張し、階層的シーケンスモデルよりもパラメータ空間が小さく、したがって、深さ境界の空間縮小をより完全に利用する。文字起こしされた子ども向けスピーチとニュースワイヤのテキストからの文法取得に関するこのモデルの結果は、解析精度で評価された場合、他のモデルの結果を上回るか、または他のモデルの結果と競合する。さらに、このモデルから取得された文法は、他の取得モデルでは実証されていないカテゴリラベルの一貫した使用を示しています。</abstract_ja>
      <abstract_hi>व्याकरण प्रेरण मॉडल के खोज स्थान को सीमित करने के लिए पुनरावृत्ति गहराई पर संज्ञानात्मक रूप से- या अनुभवजन्य रूप से प्रेरित सीमाओं को लागू करने में हाल ही में रुचि रही है (पोनवर्ट एट अल। नोजी और जॉनसन, 2016; Shain et al., 2016)। यह काम इस गहराई-बाउंडिंग दृष्टिकोण को संभाव्य संदर्भ-मुक्त व्याकरण प्रेरण (डीबी-पीसीएफजी) तक बढ़ाता है, जिसमें पदानुक्रमित अनुक्रम मॉडल की तुलना में एक छोटा पैरामीटर स्थान है, और इसलिए गहराई-बाउंडिंग के स्थान में कटौती का अधिक पूरी तरह से शोषण करता है। ट्रांसक्रिप्टेड चाइल्ड-निर्देशित भाषण और न्यूज़वायर पाठ से व्याकरण अधिग्रहण पर इस मॉडल के लिए परिणाम पार्स सटीकता पर मूल्यांकन किए जाने पर अन्य मॉडलों के साथ अधिक या प्रतिस्पर्धी होते हैं। इसके अलावा, इस मॉडल से प्राप्त व्याकरण श्रेणी लेबल के लगातार उपयोग का प्रदर्शन करते हैं, कुछ ऐसा जो अन्य अधिग्रहण मॉडलों द्वारा प्रदर्शित नहीं किया गया है।</abstract_hi>
      <abstract_ru>В последнее время наблюдается интерес к применению когнитивно или эмпирически мотивированных границ глубины рекурсии для ограничения пространства поиска моделей грамматической индукции (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Эта работа расширяет этот подход, ограничивающий глубину, к вероятностной бесконтекстной грамматической индукции (DB-PCFG), которая имеет меньшее пространство параметров, чем иерархические модели последовательностей, и, следовательно, более полно использует сокращения пространства, ограничивающие глубину. Результаты для этой модели по получению грамматики из транскрибированной речи под руководством ребенка и текста новостной ленты превосходят или конкурируют с результатами других моделей при оценке точности синтаксического анализа. Более того, грамматики, полученные из этой модели, демонстрируют последовательное использование меток категорий, что не было продемонстрировано другими моделями сбора данных.</abstract_ru>
      <abstract_ga>Is díol spéise le déanaí teorainneacha cognaíocha nó eimpíreacha a chur i bhfeidhm ar dhoimhneacht athfhillteach chun spás cuardaigh na samhlacha ionduchtaithe gramadaí a theorannú (Ponvert et al., 2011; Noji agus Johnson, 2016; Shain et al., 2016). Síneann an obair seo an cur chuige doimhne seo chuig ionduchtú gramadaí saor ó chomhthéacs dóchúlacht (DB-PCFG), a bhfuil spás paraiméadair níos lú aige ná samhlacha seichimh ordlathacha, agus mar sin baintear leas níos iomláine as laghduithe spáis a bhaineann le doimhneacht teorann. Sáraíonn torthaí na samhla seo ar shealbhú gramadaí ó théacs cainte tras-scríofa páiste-dhírithe agus nuachtshreang nó bíonn siad iomaíoch le samhlacha eile nuair a dhéantar measúnú orthu ar chruinneas parsála. Ina theannta sin, léiríonn gramadach a fuarthas ón múnla seo úsáid chomhsheasmhach as lipéid chatagóirí, rud nach bhfuil léirithe ag samhlacha sealbhaithe eile.</abstract_ga>
      <abstract_ka>შემდეგ ინტერესტი იყო კონციგურად- ან ემპერიკურად მოტიგურად მოტიგურად განახლებული დრამმარიური ინდიქციის მოდელების სივრცე (Ponvert et al., 2011; Noji და Johnson, 2016; Shain et al., 2016). ეს სამუშაო, ამ სამუშაო განმავლობაში განმავლობაში მცირე პარამეტრის სივრცე იერაქტიკური მოდელებისგან, და ამიტომ უფრო მცირე გამოყენებს სივრცე სივრცე სივრცე სივრცე სივრცე სივრცე სივრცე სივ ამ მოდელის შედეგები, რომლებიც დატანსკრებული ბავშვების სიტყვის და ახალი სიტყვის ტექსტის მიღებაზე დარჩენა ან უფრო კონპექტიურია სხვა მოდელის შესახებ, როდესაც განსაზღვრული მარ დამატებით, ამ მოდელიდან მიღებული გრამეტრები გამოყენება კატეგორია ნიშანების კონსტენსტური გამოყენება, რაც სხვა მოდელიდან არ მოდენსტურებულია.</abstract_ka>
      <abstract_hu>A közelmúltban felmerült érdeklődés a rekurziós mélységre vonatkozó kognitív vagy empirikus motivációs korlátozások alkalmazása a nyelvtani indukciós modellek keresési terének korlátozása érdekében (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Ez a munka kiterjeszti ezt a mélységkorlátozó megközelítést a valószínűsíthető kontextusmentes nyelvtani indukcióra (DB-PCFG), amely kisebb paramétertérrel rendelkezik, mint a hierarchikus szekvencia modellek, és így jobban kihasználja a mélységkorlátozás tércsökkentését. Az átírt gyermek-irányított beszéd és hírszöveg nyelvtani elsajátításáról szóló modell eredményei meghaladják vagy versenyképesek más modellekével az elemzési pontosság alapján értékelve. Ezenkívül az ebből a modellből beszerzett nyelvtanfolyamok bizonyítják a kategóriacímkék következetes használatát, amit más beszerzési modellek nem bizonyítanak.</abstract_hu>
      <abstract_el>Πρόσφατα υπήρξε ενδιαφέρον για την εφαρμογή γνωστικών ή εμπειρικών ορίων στο βάθος αναδρομής για τον περιορισμό του χώρου αναζήτησης των μοντέλων επαγωγής γραμματικής (κ.α., 2011; Νότζι και Τζόνσον, 2016; Σαιν κ.α., 2016). Η παρούσα εργασία επεκτείνει αυτή την προσέγγιση οριοθέτησης βάθους στην πιθανολογική επαγωγή γραμματικής χωρίς πλαίσιο (η οποία έχει μικρότερο χώρο παραμέτρων από τα ιεραρχικά μοντέλα ακολουθίας, και ως εκ τούτου αξιοποιεί πλήρως τις μειώσεις χώρου του οριοθέτησης βάθους. Τα αποτελέσματα για αυτό το μοντέλο για την απόκτηση γραμματικής από μεταγραφημένη ομιλία και κείμενο ειδήσεων υπερβαίνουν ή είναι ανταγωνιστικά με εκείνα άλλων μοντέλων όταν αξιολογούνται με βάση την ακρίβεια ανάλυσης. Επιπλέον, οι γραμματικές που αποκτήθηκαν από αυτό το μοντέλο καταδεικνύουν συνεπή χρήση ετικετών κατηγοριών, κάτι που δεν έχει αποδειχθεί από άλλα μοντέλα απόκτησης.</abstract_el>
      <abstract_it>C'è stato recentemente interesse ad applicare limiti cognitivamente o empiricamente motivati sulla profondità ricorsiva per limitare lo spazio di ricerca dei modelli di induzione grammaticale (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Questo lavoro estende questo approccio di profondità all'induzione grammaticale senza contesto probabilistico (DB-PCFG), che ha uno spazio di parametro più piccolo rispetto ai modelli di sequenza gerarchica, e quindi sfrutta più pienamente le riduzioni di spazio della profondità-bounding. I risultati di questo modello sull'acquisizione grammaticale dal testo trascritto diretto da bambini superano o sono competitivi con quelli di altri modelli se valutati sulla precisione di analisi. Inoltre, le grammatiche acquisite da questo modello dimostrano un uso coerente delle etichette di categoria, cosa che non è stata dimostrata da altri modelli di acquisizione.</abstract_it>
      <abstract_lt>Pastaruoju metu buvo suinteresuota taikyti kognityviai arba empiriniu būdu motyvuotas ribas atkrypimo gilumui siekiant apriboti gramatinių indukcijos modelių paieškos erdvę (Ponvert et al., 2011; Noji ir Johnson, 2016; Shain et al., 2016). Šis darbas išplečia šį gilumo ribojimo metodą ir apima tikėtiną gramatinę indukciją be konteksto (DB-PCFG), kuri turi mažesnę parametrų erdvę nei hierarchinės sekos modeliai, todėl labiau naudojamas gilumo ribojimo mažinimas. Šio modelio, skirto gramatiniam įgijimui iš transkriptos vaikų orientuotos kalbos ir žiniasklaidos teksto, rezultatai viršija arba yra konkurencingi su kitų modelių rezultatais, vertinant pagal analizės tikslumą. Be to, pagal šį model į įgytos gramatikos rodo nuoseklų kategorijų etikečių naudojimą, o to neįrodė kiti įsigijimo modeliai.</abstract_lt>
      <abstract_mk>Неодамна имаше интерес да се применат когнитивно или емпирички мотивирани граници на длабочината на рекусијата за ограничување на просторот за пребарување на граматичките индукциони модели (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Оваа работа го проширува овој пристап на ограничување на длабочината до веројатната граматска индукција без контекст (DB-PCFG), која има помал параметрален простор од хиерархичните модели на секвенца, и затоа поцелосно ги искористува просторските намалувања на ограничувањето на длабочината. Резултатите на овој модел за набавка на граматика од транскриптираниот говор директиран од децата и текстот на новинската жица надминуваат или се конкурентни со оние на другите модели кога се оценуваат на прецизноста на анализирањето. Покрај тоа, граматичките добиени од овој модел демонстрираат константна употреба на етикетите на категоријата, нешто што не е демонстрирано од други модели на купување.</abstract_mk>
      <abstract_kk>Грамматикалық индукциялық үлгілердің іздеу орындарын шектеу үшін, қайталану тереңілігінде конифициялық не импирикалық түрде мотивациялық шектерді қолдану жаңа қызықты (Ponvert et al., 2011; Noji және Johnson, 2016; Shain et al., 2016). Бұл жұмыс иерархиялық реттеу үлгілерінен кішкентай параметрлердің шектеу тәртібін ықтималдық контексті бос грамматикалық индукциясына (DB- PCFG) кеңейтуге арналады. Сондықтан, орын шектеудің шектеуді толық қолданады. Бұл үлгінің грамматикалық түрлендірілген балалардың сөздері мен жаңалық тізбектерінің мәтіндерінің нәтижелері, талдау дұрыстығында басқа үлгілердің нәтижелерінен артық немесе жаңалық тізбектері Сонымен қатар, бұл үлгіден алған граммалар санаттар жарлықтарының қолдануын көрсетеді. Басқа алу үлгілері көрсетілмеген.</abstract_kk>
      <abstract_ms>Terdapat kepentingan baru-baru ini untuk melaksanakan batas-batas yang disebabkan secara kognitif atau empirik pada kedalaman rekursi untuk hadapi ruang carian model induksi grammar (Ponvert et al., 2011; Noji dan Johnson, 2016; Shain et al., 2016). Kerja ini memperluas pendekatan pembatasan kedalaman ini kepada induksi grammar bebas konteks (DB-PCFG), yang mempunyai ruang parameter yang lebih kecil daripada model urutan hierarkis, dan oleh itu lebih sepenuhnya mengeksploitasi penurunan ruang pembatasan kedalaman. Results for this model on grammar acquisition from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy.  Lagipun, grammar yang diberikan dari model ini menunjukkan penggunaan konsisten label kategori, sesuatu yang belum dipaparkan oleh model penerimaan lain.</abstract_ms>
      <abstract_ml>ആഴത്തില്‍ തിരിച്ചറിയുന്നതിന്റെ ആഴത്തില്‍ പ്രയോഗിക്കുന്നതില്‍ അടുത്തിടെ താല്‍പര്യമുണ്ട്- അല്ലെങ്കില്‍ ശാസ്ത്രികമായിട്ടുള്ള അതിരുകള്‍ പ്രയോഗിക്കുന്നതില ഈ പ്രവര്‍ത്തിയില്‍ സാധ്യതയുള്ള കോണ്‍ട്ടെക്സ്റ്റ് സ്വതന്ത്രമായ ഗ്രാമാര്‍ ഇന്‍ഷന്‍ഷനിലേക്ക് ആഴത്തിലുള്ള അടിസ്ഥാനത്തിലേക്കുള്ള ആഴത്തിലുള്ള സ്ഥലമുണ്ട്. അതിനാ ഈ മോഡലിന്റെ ഫലങ്ങള്‍ അതുകൊണ്ടും, ഈ മാതൃകയില്‍ നിന്ന് കിട്ടിയ ഗ്രാമാറ്റര്‍ കാണിക്കുന്നത് വ്യത്യസ്തമായ വിഭാഗത്തിന്‍റെ ലേബിളുകള്‍ ഉപയോഗിക്കുന്നതാ</abstract_ml>
      <abstract_mt>Kien hemm interess reċenti fl-applikazzjoni ta’ limiti motivati b’mod konjittiv jew empiriku fuq il-fond tar-rikorrezzjoni biex jiġi limitat l-ispazju tat-tiftix ta’ mudelli ta’ induzzjoni grammarja (Ponvert et al., 2011; Noji u Johnson, 2016; Shain et al., 2016). Dan ix-xogħol jestendi dan l-approċċ ta’ limitu tal-fond għall-induzzjoni grammarja probabilistika ħielsa mill-kuntest (DB-PCFG), li għandha spazju parametriku iżgħar mill-mudelli ta’ sekwenza ġerarkika, u għalhekk tisfrutta b’mod aktar sħiħ it-tnaqqis spazjali tal-limitu tal-fond. Ir-riżultati għal dan il-mudell dwar l-akkwist tal-grammar minn diskors u test bil-wajer tal-aħbarijiet transkritti diretti mit-tfal jaqbżu jew huma kompetittivi ma’ dawk ta’ mudelli oħra meta evalwati fuq il-preċiżjoni tal-analiżi. Barra minn hekk, il-grammi miksuba minn dan il-mudell juru użu konsistenti tat-tikketti tal-kategorija, xi ħa ġa li ma ġietx murija minn mudelli oħra ta’ akkwist.</abstract_mt>
      <abstract_pl>Ostatnio pojawiło się zainteresowanie zastosowaniem poznawczo- lub empirycznie motywowanych granic głębokości rekursji w celu ograniczenia przestrzeni wyszukiwania modeli indukcji gramatycznej (Ponvert et al., 2011; Noji i Johnson, 2016; Shain et al., 2016). W niniejszej pracy rozszerzono to podejście głębokograniczne o prawdopodobieństwo kontekstowej indukcji gramatyki (DB-PCFG), która ma mniejszą przestrzeń parametrów niż hierarchiczne modele sekwencji, a zatem w pełni wykorzystuje redukcje przestrzeni głębokogranicznej. Wyniki tego modelu dotyczącego nabywania gramatyki z transkrypcji mowy kierowanej przez dzieci i tekstu wiadomości przekraczają lub są konkurencyjne z innymi modelami, gdy oceniane są pod kątem dokładności parsowania. Ponadto gramatyki nabyte na podstawie tego modelu wykazują spójne stosowanie etykiet kategorii, czego nie udowodniły inne modele akwizycji.</abstract_pl>
      <abstract_ro>A existat interes recent în aplicarea unor limite motivate cognitiv sau empiric privind adâncimea recursiei pentru a limita spațiul de căutare al modelelor de inducție gramaticală (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Această lucrare extinde această abordare de limitare a adâncimii la inducția gramaticală fără context probabilistic (DB-PCFG), care are un spațiu parametric mai mic decât modelele de secvență ierarhică și, prin urmare, exploatează mai pe deplin reducerea spațiului de limitare a adâncimii. Rezultatele pentru acest model privind achiziția gramaticală din vorbire transcrisă de copii și text de știri depășesc sau sunt competitive cu cele ale altor modele atunci când sunt evaluate pe acuratețea analizării. Mai mult decât atât, gramaticile obținute din acest model demonstrează o utilizare consistentă a etichetelor categoriilor, ceea ce nu a fost demonstrat de alte modele de achiziție.</abstract_ro>
      <abstract_mn>Грамматикийн үйлдвэрлэлийн загварын хайх орон зайг хязгаарлахын тулд ойлголттой, эсвэл эзэмшигтэй сэргээгдсэн хил хязгаарыг ашиглах нь саяхан сонирхолтой болсон. Энэ ажил магадгүй гүн гүнзгий хязгааргүй грамматикийн үйлдвэрлэлд (DB-PCFG) хүртэл бага параметр зай байдаг. Энэ нь ихэвчлэн гүн гүнзгий хязгааргүй загвараас бага хэмжээний зай байдаг. Энэ загварын үр дүнг нь хүүхдүүдийн яриа, мэдээллийн хэлбэрээс илүү, эсвэл бусад загваруудын зөв хэлбэрээр үнэлэхэд илүү өрсөлдөг эсвэл өрсөлдөг. Дараа нь энэ загвараас авсан грамматууд нь бусад худалдааны загвараас харуулагдаагүй зүйлсийг харуулдаг.</abstract_mn>
      <abstract_no>Det har gått nyleg interesse på å bruka kognitivt- eller empirisk motivert grenser på rekursjonsdjupn for å avgrensa søkjemodellen av grammatiske induksjonsmodular (Ponvert et al., 2011; Noji og Johnson, 2016; Shain et al., 2016). Denne arbeidet utvidar denne dybgrensa tilnærminga til sannsynligvis kontekstfri grammatiske induksjon (DB-PCFG), som har ein mindre parameterplass enn hierarkiske sekvensmodeller, og derfor brukar meir fullstendig romreduksjonen av dybgrenser. Resultatet for denne modellen på gramatisk henting frå transkripterte barnsdirekte tale og tekst over eller er konkurrente med dei av andre modeller når det er evaluert ved tolkinga av nøyaktighet. I tillegg kan grammar som er henta frå denne modellen vise ein konsistent bruk av kategorietikettar, noe som ikkje er demonstrert av andre inntekningsmodular.</abstract_no>
      <abstract_sr>Nedavno je bilo interesovano da se primjenjuje kognitivno- ili empirički motivisane granice na dubinu rekonstrukcije kako bi ograničilo prostor pretraživanja modela indukcije gramatike (Ponvert et al., 2011; Noji i Johnson, 2016; Shain et al., 2016). Ovaj rad proširi ovaj pristup ograničenjem dubine na verovatnoj indukciji gramatike bez konteksta (DB-PCFG), koji ima manji prostor parametara od modela hijerarhijske sekvence, i stoga je u potpunosti iskoristio smanjenje prostora dubine ograničenja. Rezultati ovog modela o prikupljivanju gramatike iz prepisanog govora i teksta novinarskih žica iznosi ili su konkurentni s onim drugim modelima kada su procenili preciznost analize. Osim toga, gramari koji su dobili iz ovog model a pokazuju konsekventnu upotrebu etiketa kategorije, nešto što nisu pokazali drugi modeli prikupljanja.</abstract_sr>
      <abstract_si>තියෙන්නේ අලුත් විශ්වාසයෙන් ප්‍රයෝජනය- නැත්තම් ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජ මේ වැඩේ මේ ගුහුණු සීමාව සම්බන්ධ සංවේදනය නිදහස් ග්‍රාමාර්ක්‍රීය (DB-PCFG) විසින් විසින් විසින් විසින් විසින් විසින් පරාමාර්ක්‍රීය සීමාව ග්‍රාමාර්ටික් අල්ලගන්න පුළුවන්ගේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රති ඒ වගේම, මේ මොඩල් එකෙන් ගත්ත ගර්මාර්ස් වලින් ප්‍රකාශ කරනවා වර්ගය ලේබල් වලින් සාමාන්‍ය භාවිතාවක් පෙන්වන්න,</abstract_si>
      <abstract_sv>Det har nyligen funnits intresse för att tillämpa kognitivt- eller empiriskt motiverade gränser för rekursionsdjup för att begränsa sökutrymmet för grammatiska induktionsmodeller (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Detta arbete utökar denna djupbegränsande ansats till sannolik kontextfri grammatik induktion (DB-PCFG), som har ett mindre parameterutrymme än hierarkiska sekvensmodeller, och därmed mer fullt utnyttjar rymdreduktionerna av djupbegränsning. Resultat för denna modell på grammatikförvärv från transkriberat barnriktat tal och nyhetstext överstiger eller är konkurrenskraftiga med andra modeller när de utvärderas på tolkningsnoggrannhet. Dessutom visar grammater som erhållits från denna modell en konsekvent användning av kategorietiketter, något som inte har påvisats av andra inköpsmodeller.</abstract_sv>
      <abstract_so>There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016).  Shaqodanku wuxuu ku fidiyaa qaababkan hoose-u-duubinta ee laga yaabayo inuu sameeyo xarunta xor-xor ah (DB-PCFG), kaas oo ay leedahay meel ka yar oo ay leedahay tusaalaha hierarchical sequence, sidaas darteed si buuxda ah ayaa u isticmaalaya hoos-hoos-u-socodka. Midabkan sameynta ku saabsan helashada qofka laga soo qoray hadalka la hagayo ee cunugga iyo qoraalka cusub ee lagu qoray ay ay badnaan yihiin ama waxay ku tartami karaan tusaalooyin kale marka lagu qiimeeyo si saxda ah. Sidoo kale grammadahan tusaalahan laga soo helay waxay muujiyaan isticmaalka alaabta ku siman, taas oo aan lagu muujin tusaale kale oo laga helay.</abstract_so>
      <abstract_ta>திரும்பச் செல்லும் ஆழத்தில் அண்மையில் உள்ள வட்டி செயல்படுத்தப்பட்டது - அல்லது நோஜி மற்றும் ஜான்சன், 2016; ஷைத்தான் மற்றும் அல்., 2016). இந்த வேலை ஆழத்திலிருந்து சுழற்றும் முறையான சூழ்நிலையிலிருந்து இலவசமான கிராமார் செயல்பாட்டிற்கு (DB- PCFG) விரிவாக்குகிறது, அது hierarchical வரிசை மாதிரிகளை விட இந்த மாதிரியின் முடிவுகள் எழுதப்பட்ட குழந்தைத் தேர்ந்தெடுக்கப்பட்ட பேச்சிலிருந்து மற்றும் புதிய உரையிலிருந்து பெறுதல் மற்ற மாதி மேலும், இந்த மாதிரியிலிருந்து கிடைக்கப்பட்ட சிட்டைகள் ஒரு மாறாக பயன்படுத்தும் வகை சிட்டைகளை காட்டுகிறது, அது மற்ற பெறும் மாதி</abstract_ta>
      <abstract_ur>اس سے اچھی علاقہ ہے کہ دوبارہ دوبارہ گھبراہٹ کی گھبراہٹ کی جگہ کی محدود کرنے کے لئے (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016) کی جگہ محدود کرنے کے لئے پہچان رہے ہیں۔ یہ کام اسے گھبراہٹ کی حد سے زیادہ گھبراہٹ کرتا ہے شائستہ کنٹنسیٹ-بے فائدہ گراماری انڈاکس (DB-PCFG) کی طرف، جس کے پاس ایک چھوٹا پارامتر فضا ہے ہیراریک سیٹ نمڈل سے، اور اس لئے اس سے زیادہ گھبراہٹ کی جگہ کم کرتا ہے۔ اس مدل کے نتیجے جو لکھی ہوئی بیٹے کی طرف سے لکھی ہوئی سخنرانی اور نیوزویر کی متن سے زیادہ ہیں یا دوسرے موڈل کے ساتھ مطابق ہیں جب پارس دقیق پر مطابق کیا جاتا ہے۔ اور اس مدل سے حاصل کئے گئے گرامرے کاٹی لیبل کے مطابق کامل استعمال کررہے ہیں، جو دوسری حاصل کی مدل سے دکھائی نہیں کی گئی ہے.</abstract_ur>
      <abstract_vi>Đã có quan tâm gần đây tới việc áp dụng các giới hạn do nhận thức hay do tồn tại của ý thức về độ sâu đệ quy để hạn chế khoảng tìm kiếm của các mô hình cảm ứng từ ngữ pháp (Ponvert et al., 2011; Noji, Johnson, 206; Shain et al., 206). Việc này mở rộng phương pháp giới hạn sâu này sang quy từ ngữ pháp không ràng buộc theo dự đoán (DB-PCFG), có khoảng tham số nhỏ hơn các mô hình dãy thứ cấp, và do đó khai thác hoàn thiện sự giảm giới hạn không gian của giới hạn sâu hơn. Kết quả của mô hình này về việc lấy lỗi từ văn bản đọc được viết trên văn bản con và dòng tin tức vượt qua hoặc đang cạnh tranh với các mẫu khác khi được đánh giá dựa trên độ chính xác. Hơn nữa, các tạp chí được lấy từ mẫu này chứng minh một cách dùng nhãn hạng liên tục, điều mà chưa được chứng minh bởi các mẫu vật khác.</abstract_vi>
      <abstract_uz>Yaqinda qiziqaruvchining grammatika induktsiya modellarning qismini chegaralashtirish qo'llashga ega bo'ldi (Povert et, 2011; Noji va Johnson, 2016; Шайтон et al., 2016). Bu ishni eng yuqori chegara qoʻyish usulini ajratish mumkinligi, balbalar bilan bog'liq grammatika induktoriga (DB-PCFG) qoʻyish mumkin, va hierarchik cheksiz modellaridan kichkina parametr boʻsh joyini ko'paytirish mumkin, va shunday qilib qo'shimcha soʻzni kamaytirish mumkin. Name Ko'rsatilgan grammatika bu modeldan olingan grammatika kategori tugmalar bilan bir doim ishlatish imkoniyatini koʻrsatiladi. Bu bir narsa boshqa ta'lim modellari tomonidan ko'rsatilmagan.</abstract_uz>
      <abstract_bg>Наскоро се проявява интерес към прилагането на когнитивно или емпирично мотивирани граници на дълбочината на рекурсия, за да се ограничи пространството за търсене на модели на граматическа индукция (Понверт и др., 2011; Ноджи и Джонсън, 2016; Шайн и др., 2016). Тази работа разширява този подход за дълбочина към вероятностна граматична индукция без контекст (DB-PCFG), която има по-малко параметрично пространство от йерархичните последователни модели и следователно по-пълно експлоатира намаляването на пространството при дълбочината. Резултатите за този модел за придобиване на граматика от преведена реч, насочена от деца, и текст от новини надвишават или се конкурират с тези на други модели, когато се оценява точността на анализирането. Освен това граматиките, придобити от този модел, демонстрират последователно използване на категории етикети, нещо, което не е доказано от други модели на придобиване.</abstract_bg>
      <abstract_da>Der har for nylig været interesse i at anvende kognitivt- eller empirisk motiverede grænser for rekursionsdybde for at begrænse søgerummet i grammatiske induktionsmodeller (Ponvert et al., 2011; Noji og Johnson, 2016; Shain et al., 2016). Dette arbejde udvider denne dybdegrænsende tilgang til probabilistisk kontekstfri grammatik induktion (DB-PCFG), som har et mindre parameterrum end hierarkiske sekvensmodeller, og derfor udnytter mere fuldt ud rumreduktionerne af dybdegrænsning. Resultaterne for denne model om grammatikerhvervelse fra transkriberat børneorienteret tale og nyhedstekst overstiger eller er konkurrencedygtige med andre modeller, når de vurderes på parse nøjagtighed. Desuden viser grammatier, der er erhvervet ved denne model, en konsekvent anvendelse af kategorimærker, hvilket ikke er blevet påvist af andre erhvervsmodeller.</abstract_da>
      <abstract_nl>Recent is er interesse geweest om cognitief of empirisch gemotiveerde grenzen op recursiediepte toe te passen om de zoekruimte van grammatica inductiemodellen te beperken (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Dit werk breidt deze deep-bounding benadering uit naar probabilistische context-free grammatica induction (DB-PCFG), die een kleinere parameterruimte heeft dan hiërarchische sequentiemodellen, en daarom meer gebruik maakt van de ruimtereducties van deep-bounding. De resultaten voor dit model op grammatica verwerving van transcribere kindergerichte spraak en newswire tekst overtreffen of concurreren met die van andere modellen wanneer geëvalueerd op parse nauwkeurigheid. Bovendien tonen grammatica's verkregen uit dit model een consistent gebruik van categorielabels aan, iets wat niet is aangetoond door andere acquisitiemodellen.</abstract_nl>
      <abstract_id>Terdapat minat baru-baru ini untuk menerapkan batas-batas kognitif-atau empiris-motivasi pada kedalaman rekursi untuk membatasi ruang pencarian model induksi gramatika (Ponvert et al., 2011; Noji dan Johnson, 2016; Shain et al., 2016). Pekerjaan ini memperluas pendekatan batas kedalaman ini ke induksi gramatika tanpa konteks probabilis (DB-PCFG), yang memiliki ruang parameter yang lebih kecil dari model urutan hierarkis, dan oleh itu lebih sepenuhnya mengeksploitasi reduksi ruang batas kedalaman. Hasil untuk model ini pada akuisisi gramatika dari pidato yang direksi kanak-kanak transkrip dan teks kabel berita melebihi atau kompetitif dengan model lain ketika diteliti pada akurasi analisis. Selain itu, gramatika yang diperoleh dari model ini menunjukkan penggunaan konsisten label kategori, sesuatu yang belum diperoleh oleh model akvizi lain.</abstract_id>
      <abstract_ko>최근에는 문법적 귀납 모델을 제한할 수 있는 검색 공간을 재귀적 깊이의 인지나 경험계를 적용해 활용하는 데 관심이 생겼다(Ponvert 등, 2011년, 노지와 존슨, 2016년, 샤인 등, 2016년).본고는 이러한 깊이 정계 방법을 확률 상하문은 문법귀납(DB-PCFG)과 무관하게 확장하고 차원 서열 모델보다 더 작은 매개 변수 공간을 가지기 때문에 깊이 정계의 공간 축소를 충분히 이용했다.분석의 정확도에 있어 이 모델은 기록된 어린이의 정향 음성과 뉴스 전선 텍스트에 대한 문법 습득 결과가 다른 모델을 초과하거나 경쟁한다.그 밖에 이 모델에서 얻은 문법은 분류 라벨의 일치된 사용을 증명했고 이것은 다른 습득 모델에서 증명되지 않은 것이다.</abstract_ko>
      <abstract_sw>Kumekuwa na maslahi ya hivi karibuni ya kutumia mipaka yenye msimamo mkali juu ya kurudi kwa kina cha kutafuta nafasi ya mifano ya viwanda vya grammani (Poverty et al., 2011; Noji na Johnson, 2016; Shetani et al., 2016). Kazi hii inaongezea mbinu hii ya kina inayozunguka kwa kiwango cha uwezekano wa bure cha gramma (DB-PCFG), ambacho ina nafasi ndogo ya parameter kuliko mifano ya msingi, na kwa hiyo inatumia kiwango kikubwa cha kupungua kwa kiwango cha ndani. Matokeo ya mtindo huu kuhusu kupatikana kwa grammani kutoka kwa hotuba iliyoandikwa kwa mtoto na ujumbe mpya wa maandishi ya kijana yanazidi kuongezeka au wanajitahidi na mifano mingine wakati unapopitiwa kwa usahihi. Zaidi ya hayo, maombi yaliyopata kutoka kwenye mtindo huu yanaonyesha matumizi ya maabara yanayoendelea, ambayo hayajaonyesha na mifano mingine ya upatikanaji.</abstract_sw>
      <abstract_hr>Nedavno se zanima primjena kognitivno- ili empirički motiviranih granica na dubinu rekonstrukcije kako bi ograničila prostor pretraživanja modela indukcije gramatike (Ponvert et al., 2011; Noji i Johnson, 2016; Shain et al., 2016). Ovaj rad proširi ovaj pristup ograničenjem dubine na verovatnoj indukciji gramatike bez konteksta (DB-PCFG), koji ima manji prostor parametara od modela hierarhijske sekvence, i stoga je u potpunosti iskoristio smanjenje prostora dubine ograničenja. Rezultati ovog modela o prikupljivanju gramatike iz prepisanog govora i teksta novinske žice iznosi ili su konkurentni s drugim modelima kada su procjene preciznosti analize. Osim toga, gramari koji su dobili iz ovog model a pokazuju konsekventu upotrebu etiketa kategorije, nešto što nisu pokazali drugi modeli prikupljanja.</abstract_hr>
      <abstract_de>In jüngster Zeit gab es Interesse, kognitiv- oder empirisch motivierte Grenzen auf Rekursionstiefe anzuwenden, um den Suchraum von Grammatik-Induktionsmodellen zu begrenzen (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Diese Arbeit erweitert diesen Tiefenbegrenzungsansatz auf probabilistische kontextfreie Grammatikinduktion (DB-PCFG), die einen kleineren Parameterraum als hierarchische Sequenzmodelle hat und daher die räumlichen Reduktionen der Tiefenbegrenzung besser ausnutzt. Die Ergebnisse dieses Modells zur Grammatikwerbung aus transkribierter kindgesteuerter Sprache und Nachrichtentext übertreffen oder sind wettbewerbsfähig mit denen anderer Modelle, wenn sie auf Parse-Genauigkeit ausgewertet werden. Darüber hinaus zeigen Grammatiken, die aus diesem Modell gewonnen wurden, eine konsistente Verwendung von Kategoriebezeichnungen, was von anderen Erwerbsmodellen nicht nachgewiesen wurde.</abstract_de>
      <abstract_af>Daar is onlangse belang in toepassing van kognitiewe- of empiriese-motiveerde grense op herhaalde diepte om die soektog ruimte van grammatiese induksie modele te beperk (Ponvert et al., 2011; Noji en Johnson, 2016; Shain et al., 2016). Hierdie werk uitbrei hierdie diepte-grense toegang na waarskynlik konteks-vry grammatiese induksie (DB-PCFG), wat het 'n kleiner parameter spasie as hierarkies volgorde modele, en dus meer volledig uitbrei die spasiereduksies van diepte-grense. Resultate vir hierdie model op grammatiese aanvang van transkripteerde kinderdoerwerp spraak en nuuswire teks oorskry of is medelykbaar met die van ander modele wanneer geevalueer word op verwerking presies. Ook, gramme wat van hierdie model aangeneem is, wys 'n konsistente gebruik van kategorie etikette, iets wat nie deur ander aangeneem modele verskyn is nie.</abstract_af>
      <abstract_fa>علاقه اخیراً در کاربرد مرزهای شناخته یا انگیزه به عمیق تکرار برای محدودیت فضای جستجوی مدل فعالیت گرامی (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). این کار این روش محدودیت عمیق را به عنوان محدودیت گرامی بی احتمال (DB-PCFG) گسترش می‌دهد که فضا پارامتر کوچکتر از مدل‌های مدل‌های سطح آفرینی دارد، و به همین دلیل بیشتر از کاهش فضا محدودیت عمیق را استفاده می‌کند. نتیجه‌های این مدل دریافت کردن گرامی از سخنرانی و متن‌های ویژه‌های نوشته‌شده از نوشته‌های نوشته‌ای بیشتر از یا با آن‌ها از مدل‌های دیگر رقابت‌کننده می‌شوند، زمانی که با دقیق تحلیل داده می‌شود. علاوه بر این، گرامارها که از این مدل دریافت شده‌اند، استفاده از برچسب‌های مختلف را نشان می‌دهند، چیزی که توسط مدل‌های دیگر دریافت نشده است.</abstract_fa>
      <abstract_am>በአሁኑ ወቅት በአውቀት፣ ወይም በአምባቢ መንቀሳቅስ ላይ የተመሳሳይ ደረጃዎችን ለመቀበል ጥልቅ ጥልቅ ለመፈለግ ወቅት ነበር፡፡ This work extends this depth-bounding approach to probabilistic context-free grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depth-bounding.  የዚህ ምሳሌ ውጤቶች በጽሑፍ የተገኘ ሕፃን እና አዲስ የጽሑፍ ማግኘት ላይ በgrammar ማግኘት ወይም በፓርስቲ እርግጠኛ ላይ በተመሳሳይ ጊዜ ከሌሎቹ ምሳሌዎች ጋር ተቃዋሚ ናቸው፡፡ ከዚህም ምሳሌ የተገኘው grammar በተጨማሪው የክፍለ መለያ ምልክቶች እና በሌላ አካባቢ ዓይነቶች ያልታየው ነው፡፡</abstract_am>
      <abstract_hy>Վերջերս հետաքրքրված է կիրառել ճանաչողական կամ էմպիրիկապես մոտիվացված սահմանները կրկնօրինակ խորության վրա, որպեսզի Այս աշխատանքը ընդլայնում է այս խորության սահմանափակ մոտեցումը հավանական կոնտեքստից ազատ գրամական ինդուկցիայի (DB-PFG), որը ունի ավելի փոքր պարամետրի տարածք, քան հիերարխիկ հաջորդականության մոդելները, և հետևաբար ավելի ամբողջովին օգտագործում է խորության սահմանափակումն Այս մոդելի արդյունքները, որոնք վերցնում են գրաֆիկական ձեռք բերումը երեխաների ուղղությամբ գրված խոսքի և նորությունների լար տեքստի միջոցով, գերազանցում են կամ մրցակցում են այլ մոդելների հետ, երբ վերլուծում են ճշգրտությունը: Ավելին, այս մոդելից ստացված գրամանները ցույց են տալիս կատեգորիայի պիտակների համապատասխան օգտագործումը, մի բան, որ չցույց է տալիս այլ գնումների մոդելների կողմից:</abstract_hy>
      <abstract_tr>Ilkinji- ýa empiriýa-görnüş çukulygyna gollanmakda ýakyn gyzyklanýar (Ponvert et al., 2011; Noji we Johnson, 2016; Shain et al., 2016). Bu işe bu derinliklerin çyzygyny gramatik boşadyrmak üçin (DB-PCFG), iýerarhiýa hatlaryň modellerinden kiçi bir parameterler bolar we şonuň üçin mekanyň çyzygynyň azalyşyny doly ulanýar. Bu nusgada gramatik gazanýan çaga sözlerinden we saz sözlerinden çykyp almanyň netijesi bardyr ýa-da paýlaşyp dogrylygynda deňleýän başga modelleriň üstünde ýa-da paýlaşyp barýarlar. Mundan soňra, bu nusgadan alan grammalar kategoriýa etiketleriniň sürekli ulanmagyny görkezýär. Başga harp modellerinden görkezilmedik zatlar.</abstract_tr>
      <abstract_sq>Ka pasur interes të fundit në zbatimin e kufijve të motivuara në mënyrë kognitive apo empirike në thellësinë e rekursionit për të kufizuar hapësirën e kërkimit të modeleve të induksionit gramatik (Ponvert et al., 2011; Noji dhe Johnson, 2016; Shain et al., 2016). Ky punë zgjeron këtë qasje kufizuese të thellësisë në induksionin gramatik probabilist pa kontekst (DB-PCFG), i cili ka një hapësirë më të vogël parametri se modelet e sekuencës hierarkike dhe prandaj shfrytëzon plotësisht reduksionet e hapësirës së kufizimit të thellësisë. Rezultatet për këtë model mbi blerjen gramatike nga fjalimi i transkriptuar drejtuar nga fëmijët dhe teksti i rrjetit të lajmeve kapërcejnë apo janë konkurruese me ato të modeleve të tjerë kur vlerësohen në saktësinë e analizimit. Përveç kësaj, gramatikat e fituara nga ky model demonstrojnë një përdorim konsistent të etiketave të kategorisë, diçka që nuk është demonstruar nga modele të tjera blerjesh.</abstract_sq>
      <abstract_az>Yenidən gəlib çatmaq üçün biliklik və empirik-motivasyon sınırlarını (Ponvert et al., 2011; Noji və Johnson, 2016; Shain et al., 2016). Bu işlər bu derinlik sınırlığını ehtimallı kontekst boş gramatik induksiya (DB-PCFG) ilə uzaqlaşdırır. Bu, hiyerarşik sıralama modellerindən daha kiçik bir parametr uzağı var, buna görə də uzaq sınırın azaltmasını daha çox istifadə edir. Bu modellərin qəbul edilməsi üçün yazılmış çocuk dilindən və xəbər tərəfindən yazılmış mətnlərdən daha çox və ya daha çox modellərlə müqayisədir. Daha sonra, bu modelden alınan qrammalar kategoriya etiketlərinin istifadəsini göstərir, digər alış modellərinin göstərilmədiyi bir şey.</abstract_az>
      <abstract_ca>Hi ha hagut un interess recent en aplicar límits motivats cognitivament o empíricament en la profunditat de recursió per limitar l'espai de cerca de models d'inducció gramàtica (Ponvert et al., 2011; Noji i Johnson, 2016; Shain et al., 2016). Aquesta feina extreu aquest enfocament de limitació de profunditat a l'inducció gramàtica probabilista sense contest (DB-PCFG), que té un espai de paràmetres més petit que els models de seqüència jeràrquica, i, per tant, aprofita més plenament les reduccions espacials de limitació de profunditat. Els resultats d'aquest model sobre l'adquisició gramàtica a partir de discurs transcrits dirigits per nens i text de fils de notícies superen o són competitius amb els d'altres models quan es valora a la precisió de l'analització. A més, les gramàtiques adquiridas d'aquest model demostren un ús consistent de les etiquetes de categoria, cosa que no ha estat demostrata per altres models d'adquisició.</abstract_ca>
      <abstract_bn>গ্রামার শিল্প মডেলের অনুসন্ধান সীমা সীমাবদ্ধ করার জন্য সম্প্রতি সাম্প্রতিক সংবাদ প্রয়োগ করা হয়েছে- অথবা সাম্প্রতিক উদ্দেশ্যের সীমাবদ্ধতা প্রয়োগ করা হয়েছে (পার্চ এই কাজ সম্ভবত কন্টেক্সটেক্স-ফ্রি গ্রামার শিল্পের (ডিবি-পিসিএফজি) প্রতি গভীর-বিধানের এই গভীর-বিধানের প্রযুক্তি বৃদ্ধি প্রদান করে, যার মধ্যে হিয়ারেরাক্কিল এই মডেলের ফলাফল প্রকাশিত শিশুদের নির্দেশিত বক্তৃতা এবং নতুন টেক্সটের বাড়িয়ে দেয়া হয়েছে অথবা অন্যান্য মডেলের সাথে প্রতিদ্বন্দ্বিতা করছে যে  এছাড়াও, এই মডেল থেকে গ্রাম পেয়েছে তারা বিভিন্ন ধরনের লেবেল ব্যবহার করেছে, যা অন্যান্য গ্রহণ মডেল দ্বারা প্রদর্শন করেনি।</abstract_bn>
      <abstract_bs>Nedavno se zanima primjena kognitivno- ili empirički motiviranih granica na dubinu rekonstrukcije kako bi ograničila prostor pretraživanja modela indukcije gramatike (Ponvert et al., 2011; Noji i Johnson, 2016; Shain et al., 2016). Ovaj rad proširi ovaj pristup ograničenjem dubine na verovatnoj indukciji gramatike bez konteksta (DB-PCFG), koji ima manji prostor parametara od modela hijerarhijske sekvence, i stoga je u potpunosti iskoristio smanjenje prostora dubine ograničenja. Rezultati ovog modela o preuzimanju gramatike iz prepisanog govora i teksta novine žice preko ili su konkurentni s onim drugim modelima kada se procjenjuje preciznost analize. Osim toga, gramari koji su dobili iz ovog model a pokazuju konsekventu upotrebu etiketa kategorije, nešto što nisu pokazali drugi modeli prikupljanja.</abstract_bs>
      <abstract_fi>Viime aikoina on ollut kiinnostusta soveltaa kognitiivisesti tai empiirisesti motivoituneita rekursiosyvyyden rajoja kieliopin induktiomallien hakutilan rajoittamiseksi (Ponvert et al., 2011; Noji ja Johnson, 2016; Shain et al., 2016). Tämä työ laajentaa tätä syvyyttä rajoittavaa lähestymistapaa todennäköiseen kontekstivapaan kieliopin induktioon (DB-PCFG), jossa on pienempi parametritila kuin hierarkkiset sekvenssimallit, ja siten hyödynnetään syvyysrajauksen avaruuden vähennyksiä. Tämän kieliopin hankkimista koskevan mallin tulokset kopioidusta lapsiohjatusta puheesta ja uutiskirjetekstistä ylittävät tai kilpailevat muiden mallien kanssa jäsennystarkkuuden perusteella. Lisäksi tästä mallista saadut kieliopit osoittavat luokkamerkintöjen johdonmukaisen käytön, mitä muut hankintamallit eivät ole osoittaneet.</abstract_fi>
      <abstract_cs>V poslední době existuje zájem o aplikaci kognitivně nebo empiricky motivovaných hranic na hloubku rekurze k omezení prostoru hledání gramatických indukčních modelů (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). Tato práce rozšiřuje tento hloubkový přístup o pravděpodobnostní kontextovou gramatickou indukci (DB-PCFG), která má menší parametrový prostor než hierarchické sekvenční modely, a proto plněji využívá snížení prostoru hloubkového ohraničení. Výsledky tohoto modelu na získávání gramatiky z přepisované dětské řeči a textu novinek překračují nebo jsou konkurenční s ostatními modely, pokud jsou hodnoceny na přesnost parse. Grammatiky získané z tohoto modelu navíc ukazují konzistentní používání kategorií, což jiné akviziční modely neprokázaly.</abstract_cs>
      <abstract_et>Hiljuti on olnud huvi kohaldada kognitiivselt või empiiriliselt motiveeritud rekursioonisügavuse piire grammatika induktsiooni mudelite otsinguruumi piiramiseks (Ponvert jt., 2011; Noji ja Johnson, 2016; Shain jt., 2016). Käesolev töö laiendab seda sügavuspiirilist lähenemisviisi tõenäolisele kontekstivabale grammatika induktsioonile (DB-PCFG), millel on väiksem parameetriruum kui hierarhilistel järjestusmudelitel, ja seega kasutab täielikult ära sügavuspiiride ruumi vähendamist. Selle mudeli grammatika omandamise tulemused transkribeeritud lapsesuunatud kõnest ja uudistest ületavad või konkureerivad teiste mudelitega parsimise täpsuse hindamisel. Lisaks näitavad sellest mudelist saadud grammatikad kategooriamärgiste järjepidevat kasutamist, mida muud omandamismudelid ei ole näidanud.</abstract_et>
      <abstract_jv>Awak dhéwé éntuk ngéwé éntuk ing nggawé kowéngkapungot- karo empirekalno-éntuk gawe barang nggawe barang nggawe barang nggawe gerakan perusahaan sistem sing nggawe parang ingrak (ponvertical et al, 2011; Noji lan Jonathan, 2011; shadin et al, 2013). This job expans this deep-limiting method to likely context-free gram ndution Validity Nambah, gambar nggambar luwih dumaten ning model iki dadi bisa diutag oleh sing kategori Label, sing durung ono sing durungke durung bisa model sing wis ana.</abstract_jv>
      <abstract_he>יש עניין לאחרונה בהשתמשות גבולות מוטיבציה קוגניטיבית או אמפירית על עמוק התחזור כדי להגביל את מרחב החיפוש של דוגמני induction גרמטיקה (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). העבודה הזאת מגבירה את הגישה העמוקה הזו לתחילת גרמטיקה ללא קשר סיפורי (DB-PCFG), שיש לה מרחב פרמטיקה קטן יותר מאשר דוגמני רצף היירארכיים, ולכן ניצל במלוא את הפחות החלל של הגבולות העמוקים. התוצאות של המודל הזה על רכישת גרמטיקה מנאום מוסר על ידי ילדים וטקסט חוט חדשות מעלים או מתחרים עם אלה של דוגמנים אחרים כאשר הוערכו על מדויקת התחקור. חוץ מזה, גרמטיקות שנרכשו מהמודל הזה מראות שימוש קבוע של תוויות הקטגוריה, משהו שלא הוכח על ידי דוגמנים אחרים של רכישה.</abstract_he>
      <abstract_sk>Nedavno je bilo zanimanje za uporabo kognitivno ali empirično motiviranih omejitev rekurzijske globine za omejitev iskalnega prostora modelov indukcije slovnice (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016). To delo razširja ta globinski pristop na verjetnostno indukcijo slovnice brez konteksta (DB-PCFG), ki ima manjši parametrski prostor kot hierarhični modeli zaporedja in zato bolj izkorišča zmanjšanje prostora pri globinskem omejevanju. Rezultati tega modela pridobivanja slovnice iz prepisanega otroškega govora in besedila novic presegajo ali so konkurenčni z rezultati drugih modelov pri ocenjevanju natančnosti razčlenjanja. Poleg tega slovnice, pridobljene s tem modelom, kažejo dosledno uporabo oznak kategorij, kar drugi modeli pridobivanja niso dokazali.</abstract_sk>
      <abstract_ha>There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al., 2016).  Wannan aikin yana shimfiɗa hanyarta mai inuwanta zuwa wani mai yiwuwa na aikin kwamfyuta-bure grammar (DB-PCFG), wanda yana da wani fili kaɗan da kwamfyuta mafi ƙaranci daga misãlai masu sequence na hierorchical, kuma don haka sai ya cika amfani da kwamfyutan sauri na ƙarami. Mataimakin wannan motel na samun motsi da aka samu karatun daga magana na rubutun-da aka rubutu da kuma aka ƙara matsayin tsohon yanzu ko su yi gauraya da waɗancan misãlai idan an ƙaddara a kan tsarin parse. Da haka, grammati da aka samu daga wannan misalin ya nuna wani mai amfani da alama mai daidai, da wani abu wanda ba a nuna da wasu misãlai na sami ba.</abstract_ha>
      <abstract_bo>འཕྲད་དུ་མ་ཤེས་པའི་དགའ་ཚོགས་ཀྱི་ཉེན་རིས་སྤྲོད་ཀྱི་ཐབས་ལམ་གྱིས་རྒྱས་ཁབ་ཀྱི་དཔེ་བས། This work extends this depth-bounding approach to probabilistic context-free grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depth-bounding. Results for this model on grammar acquisition from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy. Moreover, grammars acquired from this model demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.</abstract_bo>
      </paper>
    <paper id="17">
      <title>Scheduled Multi-Task Learning : From Syntax to Translation</title>
      <author><first>Eliyahu</first><last>Kiperwasser</last></author>
      <author><first>Miguel</first><last>Ballesteros</last></author>
      <doi>10.1162/tacl_a_00017</doi>
      <abstract>Neural encoder-decoder models of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> have achieved impressive results, while learning linguistic knowledge of both the source and target languages in an implicit end-to-end manner. We propose a framework in which our model begins learning <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> and translation interleaved, gradually putting more focus on <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. Using this approach, we achieve considerable improvements in terms of BLEU score on relatively large parallel corpus (WMT14 English to German) and a low-resource (WIT German to English) setup.</abstract>
      <pages>225–240</pages>
      <url hash="b10c863b">Q18-1017</url>
      <bibkey>kiperwasser-ballesteros-2018-scheduled</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    <title_es>Aprendizaje multitarea programado: de la sintaxis a la traducción</title_es>
      <title_ar>التعلم المجدول متعدد المهام: من بناء الجملة إلى الترجمة</title_ar>
      <title_fr>Apprentissage multitâche planifié : de la syntaxe à la traduction</title_fr>
      <title_pt>Aprendizado multitarefa programado: da sintaxe à tradução</title_pt>
      <title_ja>予定されたマルチタスク学習：構文から翻訳へ</title_ja>
      <title_hi>शेड्यूल किए गए बहु-कार्य सीखना: सिंटैक्स से अनुवाद तक</title_hi>
      <title_zh>预定多任务学,自语法至译</title_zh>
      <title_ru>Запланированное многозадачное обучение: от синтаксиса к переводу</title_ru>
      <title_ga>Foghlaim Sceidealta Ilthasc: Ó Chomhréir go Aistriú</title_ga>
      <title_ka>სინტექსტიდან გადატყვება</title_ka>
      <title_hu>Ütemezett többfeladatos tanulás: a szintaxistól a fordításig</title_hu>
      <title_el>Προγραμματισμένη εκμάθηση πολλαπλών εργασιών: Από τη σύνταξη στη μετάφραση</title_el>
      <title_it>Apprendimento multi-task programmato: dalla sintassi alla traduzione</title_it>
      <title_kk>Жоспарланған көп тапсырмаларды оқыту: Синтаксиснен аудармаға</title_kk>
      <title_ms>Pelajaran Berbagai Tugas Terjadual: Dari Sintaks ke Terjemahan</title_ms>
      <title_lt>Numatytas daugiafunkcinis mokymasis: nuo sintakso iki vertimo raštu</title_lt>
      <title_ml>ക്രമീകരിച്ചിരിക്കുന്ന കൂടുതല്‍ ജോലി പഠിപ്പിക്കുന്നു: സിന്റാക്സില്‍ നിന്നും പരിഭാഷക്</title_ml>
      <title_mt>Tagħlim Multikompiti skedat: Mis-Sintassa sat-Traduzzjoni</title_mt>
      <title_mn>Многоон ажлын суралцах төлөвлөгөө: Синтаксисээс хөгжүүлэх хүртэл</title_mn>
      <title_mk>Запланирано мултизадачно учење: Од синтаксис до превод</title_mk>
      <title_no>Planlagt fleire oppgåver- læring: Fra syntaks til omsetjing</title_no>
      <title_ro>Învățare programată Multi-Task: de la sintaxă la traducere</title_ro>
      <title_sr>Planirano učenje mnogih zadataka: Od sintaksa do prevoda</title_sr>
      <title_so>Waxbarashada shaqo badan ee la qorsheeyey: Ka imaanshaha kaalmada iyo turjumista</title_so>
      <title_sv>Schemalagd Multi-Task Learning: Från syntax till översättning</title_sv>
      <title_pl>Zaplanowane wielozadaniowe uczenie się: od składni do tłumaczenia</title_pl>
      <title_si>ගොඩක් කාර්ය ඉගෙනගන්න</title_si>
      <title_ur>Scheduled Multi-Task Learning: From Syntax to Translation</title_ur>
      <title_ta>வரையறுக்கப்பட்ட பல பணிகள் கற்றுக்கொடுக்கப்பட்டது: ஒத்திசைவிலிருந்து மொழிபெயர்ப்புக்கு</title_ta>
      <title_uz>Bir nechta vazifa oĘ»rganish</title_uz>
      <title_vi>Chương trình đa công việc đương thời: Từ cú pháp sang dịch</title_vi>
      <title_bg>Планирано обучение с множество задачи: от синтаксис до превод</title_bg>
      <title_nl>Geplande multi-task leren: van syntaxis naar vertaling</title_nl>
      <title_hr>Planirano učenje mnogih zadataka: Od sintakse do prevoda</title_hr>
      <title_da>Planlagt Multi-Task Learning: Fra syntaks til oversættelse</title_da>
      <title_de>Geplantes Multi-Task-Lernen: Von der Syntax bis zur Übersetzung</title_de>
      <title_ko>계획 다중 임무 학습: 문법부터 번역까지</title_ko>
      <title_fa>یادگیری بسیاری از کار برنامه‌بندی: از سنتاکس تا ترجمه</title_fa>
      <title_id>Scheduled Multi-Task Learning: From Syntax to Translation</title_id>
      <title_sw>Kutoka Syntax hadi Tafsiri</title_sw>
      <title_af>Skeduleerde Multi- Task Leer: Van Sintaks na Vertaling</title_af>
      <title_sq>Mësimi i planifikuar me shumë detyra: Nga sintaksi në përkthim</title_sq>
      <title_tr>Çoklu-Taýry öwrenmek: Sentaksydan terjime etmek üçin</title_tr>
      <title_hy>Comment</title_hy>
      <title_am>ßè¿Syntax to ßëÁßê¡ßîëßêØ</title_am>
      <title_bn>Scheduled Multi-Task Learning: From Syntax to Translation</title_bn>
      <title_az>칂oxlu-Task 칐yr톛nm톛si: Sintaksid톛n T톛rc칲m톛</title_az>
      <title_bs>Planirano učenje mnogih zadataka: Od sintaksa do prevoda</title_bs>
      <title_ca>Aprendiment multitascat programat: des de la sintaxi a la traducció</title_ca>
      <title_cs>Plánované víceúlohové učení: od syntaxe k překladu</title_cs>
      <title_et>Ajastatud mitme ülesandega õppimine: süntaksist tõlkeni</title_et>
      <title_fi>Ajoitettu Multi-Task Learning: Syntaksista kääntämiseen</title_fi>
      <title_jv>Multi-tasks Learn Mode</title_jv>
      <title_ha>@ action</title_ha>
      <title_he>לומדת משימות רבות מתוכננת: מסינטקס לתרגום</title_he>
      <title_sk>Načrtovano večopravilno učenje: od sintakse do prevajanja</title_sk>
      <title_bo>དུས་བཀོད་ཡོད་པའི་སྣ་མང་བོའི་བྱ་འགུལ་ཤེས་ཀྱི་སྤྲོ་སྟངས：ཚིག་རྟགས་ལ་སྐད་བསྒྱུར་བཅོས་བྱེད</title_bo>
      <abstract_ar>حققت نماذج وحدة فك التشفير والتشفير العصبية للترجمة الآلية نتائج رائعة ، بينما تتعلم المعرفة اللغوية لكل من اللغات المصدر والهدف بطريقة ضمنية شاملة. نقترح إطارًا يبدأ فيه نموذجنا في تعلم بناء الجملة وترجمة متداخلة ، مع التركيز بشكل تدريجي على الترجمة. باستخدام هذا النهج ، نحقق تحسينات كبيرة من حيث درجة BLEU على مجموعة كبيرة متوازية نسبيًا (WMT14 من الإنجليزية إلى الألمانية) وإعداد منخفض الموارد (WIT من الألمانية إلى الإنجليزية).</abstract_ar>
      <abstract_fr>Les modèles encodeur-décodeur neuronal de traduction automatique ont obtenu des résultats impressionnants, tout en apprenant les connaissances linguistiques des langues source et cible de manière implicite de bout en bout. Nous proposons un cadre dans lequel notre modèle commence à apprendre la syntaxe et la traduction entrelacées, en mettant progressivement l'accent sur la traduction. Grâce à cette approche, nous obtenons des améliorations considérables en termes de score BLEU sur un corpus parallèle relativement important (WMT14 anglais-allemand) et une configuration à faibles ressources (WIT allemand vers anglais).</abstract_fr>
      <abstract_es>Los modelos de codificador-decodificador neuronal de traducción automática han logrado resultados impresionantes, al tiempo que aprenden el conocimiento lingüístico de los idiomas de origen y de destino de forma implícita de principio a fin. Proponemos un marco en el que nuestro modelo comienza a aprender la sintaxis y la traducción intercalada, centrándose poco a poco en la traducción. Con este enfoque, logramos mejoras considerables en términos de puntuación BLEU en un corpus paralelo relativamente grande (WMT14 de inglés a alemán) y una configuración de recursos bajos (WIT de alemán a inglés).</abstract_es>
      <abstract_pt>Os modelos de codificador-decodificador neural de tradução automática alcançaram resultados impressionantes, enquanto aprendiam o conhecimento linguístico dos idiomas de origem e de destino de maneira implícita de ponta a ponta. Propomos um framework no qual nosso modelo começa a aprender sintaxe e tradução intercalada, gradualmente colocando mais foco na tradução. Usando essa abordagem, alcançamos melhorias consideráveis em termos de pontuação BLEU em um corpus paralelo relativamente grande (WMT14 inglês para alemão) e uma configuração de poucos recursos (WIT alemão para inglês).</abstract_pt>
      <abstract_zh>机器翻译之神经编码器-解码器,取深果,以隐式端到端学语言。 发一框架,于此框架中,模样初学语法与译相错,渐加意于译上。 用此法,相对较大者并行语料库(WMT14 英语至德语)低资源(WIT 德语至英语)所置BLEU分数大改。</abstract_zh>
      <abstract_ja>機械翻訳のニューラルエンコーダーデコーダーモデルは、ソース言語とターゲット言語の両方の言語学的知識を暗黙のエンドツーエンドで学習しながら、印象的な結果を達成しました。私たちは、モデルが構文と翻訳の相互作用を学び始め、徐々に翻訳に重点を置くフレームワークを提案します。このアプローチを使用して、私たちは、比較的大きな並列コーパス（ WMT 14英語からドイツ語）および低リソース（ WITドイツ語から英語）セットアップでBLEUスコアの点でかなりの改善を達成します。</abstract_ja>
      <abstract_hi>मशीन अनुवाद के तंत्रिका एन्कोडर-डिकोडर मॉडल ने प्रभावशाली परिणाम प्राप्त किए हैं, जबकि एक अंतर्निहित अंत-से-अंत तरीके से स्रोत और लक्ष्य दोनों भाषाओं के भाषाई ज्ञान को सीखना है। हम एक ऐसे ढांचे का प्रस्ताव करते हैं जिसमें हमारा मॉडल वाक्यविन्यास और अनुवाद सीखना शुरू कर देता है, धीरे-धीरे अनुवाद पर अधिक ध्यान केंद्रित करता है। इस दृष्टिकोण का उपयोग करते हुए, हम अपेक्षाकृत बड़े समानांतर कॉर्पस (WMT14 अंग्रेजी से जर्मन) और एक कम संसाधन (अंग्रेजी के लिए WIT जर्मन) सेटअप पर BLEU स्कोर के संदर्भ में काफी सुधार प्राप्त करते हैं।</abstract_hi>
      <abstract_ru>Нейронные модели шифратор-декодер машинного перевода достигли впечатляющих результатов, при этом изучая языковые знания как исходного, так и целевого языков неявным сквозным образом. Мы предлагаем фреймворк, в котором наша модель начинает изучать синтаксис и чередование перевода, постепенно уделяя больше внимания переводу. Используя этот подход, мы добиваемся значительных улучшений с точки зрения оценки BLEU на относительно большом параллельном корпусе (WMT14 с английского на немецкий) и низкоресурсной (WIT С немецкого на английский) установке.</abstract_ru>
      <abstract_ga>Tá torthaí iontacha bainte amach ag samhlacha néarchódóra-dhíchódóra meaisín-aistriúcháin, agus eolas teangeolaíoch á foghlaim ar na teangacha foinse agus ar na sprioctheangacha araon ar bhealach intuigthe ó cheann ceann. Molaimid creat ina gcuirtear tús lenár múnla ag foghlaim comhréire agus an t-aistriúchán idirdhuilleogach, ag díriú níos mó ar an aistriúchán de réir a chéile. Trí úsáid a bhaint as an gcur chuige seo, bainimid amach feabhsuithe suntasacha i dtéarmaí scór BLEU ar chorpas comhthreomhar measartha mór (WMT14 Béarla go Gearmáinis) agus socrú acmhainní ísle (WIT Gearmáinis go Béarla).</abstract_ga>
      <abstract_hu>A gépi fordítás idegi kódoló-dekódoló modelljei lenyűgöző eredményeket értek el, miközben implicit, end-to-end módon tanulják a forrás- és célnyelvek nyelvtudását. Olyan keretrendszert javasolunk, amelyben modellünk elkezdi megtanulni a szintaxist és a fordítást, fokozatosan nagyobb hangsúlyt fektetve a fordításra. Ezzel a megközelítéssel jelentős javulást érünk el a BLEU pontszám tekintetében viszonylag nagy párhuzamos korpuszon (WMT14 angol-német) és alacsony erőforrású (WIT német-angol) beállításon.</abstract_hu>
      <abstract_el>Τα μοντέλα νευρωνικών κωδικοποιητών-αποκωδικοποιητών της μηχανικής μετάφρασης έχουν επιτύχει εντυπωσιακά αποτελέσματα, ενώ μαθαίνουν γλωσσικές γνώσεις τόσο της γλώσσας προέλευσης όσο και της γλώσσας-στόχου με έμμεσο τρόπο. Προτείνουμε ένα πλαίσιο στο οποίο το μοντέλο μας αρχίζει να μαθαίνει σύνταξη και μετάφραση διασυνδεδεμένη, δίνοντας σταδιακά μεγαλύτερη έμφαση στη μετάφραση. Χρησιμοποιώντας αυτή την προσέγγιση, επιτυγχάνουμε σημαντικές βελτιώσεις όσον αφορά την βαθμολογία σε σχετικά μεγάλο παράλληλο σώμα (Αγγλικά στα Γερμανικά) και μια ρύθμιση χαμηλής περιεκτικότητας (Γερμανικά στα Αγγλικά).</abstract_el>
      <abstract_kk>Машин аудармасының нейрондық кодер- декодер үлгілері көзі мен мақсатты тілдердің білімін оқу үшін әсер ететін нәтижелерін жеткізді. Біз үлгіміздің синтаксисін және аудармасының арасындағы түрлендіруді бастап, аудармасына көңіл түрлендіру үшін қолданатын қоршауымызды ұсынамыз. Бұл тәсілді қолдану үшін біз BLEU нәтижесін салыстыру үлкен параллель корпус (WMT14 ағылшын тілінен неміс) және төмен ресурс (неміс тілінен ағылшын тіліне қарай) баптауларына көп жақсы</abstract_kk>
      <abstract_lt>Mašininio vertimo neurologinio kodavimo kodavimo modeliai sukaupė įspūdingų rezultatų, o kalbinių žinių apie šaltinį ir tikslines kalbas mokymasis netiesioginiu būdu nuo pabaigos iki pabaigos. Siūlome sistemą, pagal kurią mūsų modelis pradeda mokytis sintaksijos ir vertimo tarpusavyje laipsniškai daugiau dėmesio skiriant vertimui. Taikant šį metodą pasiekiame gerokai pagerinti BLEU rezultatus palyginti didelio lygiagretaus korpuso (WMT14 anglų ir vokiečių) ir mažo išteklių (WIT anglų ir vokiečių) sukūrimo atžvilgiu.</abstract_lt>
      <abstract_mk>Моделите на невралниот кодер-декодер на машински превод постигнаа импресивни резултати, додека учењето на јазичното знаење на изворот и на јазиците на цел на имплицитен начин од крај до крај. Предложуваме рамка во која нашиот модел почнува да учи синтаксика и превод меѓу себе, постепено ставајќи поголем фокус на преводот. Користејќи го овој пристап, постигнуваме значителни подобрувања во поглед на оценката БЛЕУ на релативно големиот паралелен корпус (ВМТ14 англиски до германски) и поставување на ниски ресурси (ВИТ германски до англиски).</abstract_mk>
      <abstract_ms>Model pengekod-dekoder saraf terjemahan mesin telah mencapai keputusan yang mengesankan, sementara belajar pengetahuan bahasa dari sumber dan bahasa sasaran dalam cara yang tidak jelas akhir-akhir. Kami mengusulkan kerangka di mana model kami mula belajar sintaks dan terjemahan saling-saling, secara perlahan-lahan meletakkan lebih fokus pada terjemahan. Dengan pendekatan ini, kami mencapai peningkatan yang besar dalam terma skor BLEU pada corpus selari relatif besar (WMT14 Inggeris ke Jerman) dan seting sumber rendah (WIT Jerman ke Inggeris).</abstract_ms>
      <abstract_ml>മെഷിന്‍ പരിഭാഷത്തിന്റെ ന്യൂറല്‍ കോഡെര്‍ ഡെകോഡെര്‍ മോഡലുകള്‍ വളരെ നല്ല ഫലങ്ങള്‍ നേടിയിരിക്കുന്നു. സ്രോതസ്സിന്റെ വിവരങ്ങളും ലക്ഷ്യഭാഷങ്ങളും  ഞങ്ങള്‍ ഒരു ഫ്രെയിമെയിക്ക് പ്രൊദ്ദേശിപ്പിക്കുന്നു. അതില്‍ നമ്മുടെ മോഡല്‍ സിന്‍ട്രാക്സും പരിഭാഷപ്രഭാഷണവും ശിഷ ഈ നടപടി ഉപയോഗിക്കുന്നതിനാല്‍ നമുക്ക് വളരെ വലിയ പാരാളല്‍ കോര്‍പ്പുസിന്‍റെ (WMT14 ഇംഗ്ലീഷിലേക്ക് ജര്‍മ്മനിലേക്ക് ഇംഗ്ലീഷിലേക്ക്) സ്കോര്‍ട്ട് ക</abstract_ml>
      <abstract_mt>Neural encoder-decoder models of machine translation have achieved impressive results, while learning linguistic knowledge of both the source and target languages in an implicit end-to-end manner.  Aħna qed nipproponu qafas li fih il-mudell tagħna jibda jitgħallem is-sintaks u t-traduzzjoni interleaved, bil-mod il-mod b’aktar enfasi fuq it-traduzzjoni. Bl-użu ta’ dan l-approċċ, inkisbu titjib konsiderevoli f’termini tal-punteġġ BLEU fuq korpus parallelu relattivament kbir (WMT14 Ingliż għal Ġermaniż) u twaqqif ta’ riżorsi baxxi (WIT Ġermaniż għal Ingliż).</abstract_mt>
      <abstract_mn>Машины орчуулалтын мэдрэлийн коддогч загвар нь гайхалтай үр дүн гарч ирсэн. Хэдийгээр хэлний эх үүсвэр болон зорилготой хэлний мэдлэгийг суралцаж байдаг. Бид загвар нь синтаксис болон хөрөнгө оруулалтыг илүү анхаарлаа хөрөнгө оруулж эхэлдэг. Энэ арга хэмжээ ашиглан бид БЛЕС оноо харьцангуй том параллел корпус (WMT14 Англи хэл Герман хэлэх зэрэг) болон бага ресурс (WIT Герман хэлэх Англи хэлэх зэрэг) төлөвлөгөөнд маш их сайжруулсан.</abstract_mn>
      <abstract_no>Nøyrale koderingsmodeller for maskineoversettelse har oppnådd uttrykkelige resultat, mens læring av lingviske kunnskap om både kjeldespråket og målspråket på ein implisitt slutttil sluttmodus. Vi foreslår eit rammeverk som modellen vårt startar å lære syntaks og omsetjingar, og gradvis setter meir fokus på omsetjinga. Når vi bruker denne tilnærminga, oppnår vi betydelig forbedringar ved hjelp av BLEU-poeng på relativt stor parallell korpus (WMT14 engelsk til tysk) og eit låg ressurs (WIT tysk til engelsk).</abstract_no>
      <abstract_pl>Neuronowe modele koderów-dekoderów tłumaczenia maszynowego osiągnęły imponujące rezultaty, jednocześnie ucząc się językowej wiedzy zarówno języka źródłowego, jak i docelowego w sposób ukryty end-to-end. Proponujemy ramy, w których nasz model zaczyna uczyć się składni i tłumaczeń przeplatanych, stopniowo kładąc większy nacisk na tłumaczenie. Za pomocą tego podejścia osiągamy znaczną poprawę wyniku BLEU na stosunkowo dużym korpusie równoległym (WMT14 z angielskiego na niemiecki) oraz niskim zasobem (WIT z niemieckiego na angielski).</abstract_pl>
      <abstract_ro>Modelele encoder-decoder neurale de traducere automată au obținut rezultate impresionante, în timp ce învățăm cunoștințele lingvistice atât ale limbilor sursă, cât și ale limbilor țintă într-un mod implicit end-to-end. Propunem un cadru în care modelul nostru începe să învețe sintaxa și traducerea interleavată, punând treptat mai mult accent pe traducere. Folosind această abordare, obținem îmbunătățiri considerabile în ceea ce privește scorul BLEU pe corpuri paralele relativ mari (WMT14 din engleză la germană) și o configurație cu resurse reduse (WIT din germană la engleză).</abstract_ro>
      <abstract_sr>Neuralni modeli prevoda uređaja postigli su impresivni rezultati, dok su naučili jezičko znanje i izvora i ciljnih jezika na implicitni način kraja do kraja. Predlažemo okvir u kojem naš model počinje naučiti sintaks i prevod, postupno stavljajući više fokus na prevod. Koristeći ovaj pristup, postigli smo značajne poboljšanje u smislu rezultata BLEU-a o relativno velikom paralelnom korpusu (WMT14 engleski na njemački) i uspostavljanju niskog resursa (WIT njemački na engleski jezik).</abstract_sr>
      <abstract_si>පද්ධතිය අවවාදයේ න්‍යූරාලික කෝඩාර්-ඩිකෝඩර් මොඩේල්ස් එක්ක ප්‍රශ්ණ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ර අපි ප්‍රයෝජනයක් ප්‍රයෝජනය කරනවා අපේ මෝඩල් එකේ සංකේතය සහ වාර්තාව අනුවෙන් ඉගෙන ගන්න පටන් ගන්නවා, වාර් මේ විදියට පාවිච්චි කරන්න, අපි ලොකු ප්‍රමාණයක් ලොකු සමාන්‍ය කොර්පුස් වලින් ගොඩක් ප්‍රමාණයක් ලැබෙනවා (WMT14 ඉංග්‍රීසි ජර්මන් වලි</abstract_si>
      <abstract_so>Tilmaamaha kookoordirada ee turjumidda machine waxay gaadheen resulto aad u wanaagsan, marka aad barato aqoonta afka luuqada iyo luqadaha aad u baahan tahay waa mid ugu dambeysa dhammaadka. Waxaynu soo jeedaynaa framework, kaasoo modellkayagu ka bilaabaa barashada canshuuraha iyo turjumidda, si hoos ah ugu kalsoonaan turjumista. Isku isticmaaliddan qaababkan, horumarinta aad u fiican ayaannu u sameynaa habka BLEU-scorta ku saabsan korpus aad u weyn (WMT14 Ingiriis-Jarmal-Ingiriis) iyo asal hoos u ah (WIT Jarmal-Ingiriis-Ingiriis).</abstract_so>
      <abstract_sv>Neurala encoder-avkodarmodeller av maskinöversättning har uppnått imponerande resultat, samtidigt som de lär sig språkliga kunskaper om både käll- och målspråk på ett implicit end-to-end sätt. Vi föreslår ett ramverk där vår modell börjar lära sig syntax och översättning interleaved, gradvis lägga mer fokus på översättning. Med detta tillvägagångssätt uppnår vi avsevärda förbättringar vad gäller BLEU-poäng på relativt stor parallell korpus (WMT14 engelska till tyska) och en lågresurs (WIT tyska till engelska).</abstract_sv>
      <abstract_ta>கணினி மொழிமாற்றியின் புதிய குறியீட்டாளர் மாதிரி மாதிரிகள் செய்துவிட்டது, மூலத்தின் மூலம் மற்றும் இலக்கு மொழிகளின் அறிவு பொருள் முட நாம் ஒரு சட்டத்தை பரிந்துரைக்கிறோம் அதில் எங்கள் மாதிரி ஒத்திசைநிரல் மற்றும் மொழிபெயர்ப்பு இடைவெளியில் கற் இந்த செயல்பாட்டை பயன்படுத்தி, நாம் சார்ந்த பெரிய இணைப்பு கார்புஸ் (WMT14 ஆங்கிலத்தில் இருந்து ஜெர்மனில் இருந்து) பிலியு மதிப்பு முன்னேற்றம் பெறுக</abstract_ta>
      <abstract_ur>ماشین ترجمہ کی نیورال کوڈر-ڈیکوڈر نمونڈل کے لئے اثر انگیز نتیجے پہنچ گئے ہیں، حالانکہ سورج اور موقع زبانوں کی زبان علم کو ایک اثر انگیز طریقے سے سیکھ رہی ہے. ہم ایک فرمود پیش کریں گے جس میں ہماری مدل سینٹکس اور ترجمہ کی تعلیم شروع کرتا ہے، تدریجاً ترجمہ پر زیادہ تمرکز کرتا ہے۔ اس طریقے کے مطابق، ہم BLEU اسکور کے مطابق بہت بڑے مشابہ کورپوس (WMT14 انگلیسی سے جرمن سے) اور کم منبع (WIT جرمن سے انگلیسی سے) سٹاپ کے مطابق بہت زیادہ اضافہ کر رہے ہیں.</abstract_ur>
      <abstract_ka>მანქანის გარგულისხმების ნეიროლური კოდირების მოდელები მიიღეთ ინტერფექციური შედეგები, როცა ენდომისტიკური მეცნიერება და მისაღების მსოფლიო ენგების შესაძლებლობად ინტერფ ჩვენ მინდომარებთ ფრამეტრი, რომელიც ჩვენი მოდელის სინტაქსი და გადაწყვეტილება დავიწყება, რომელიც უფრო კონუქტირებაზე დავიწყება. ამ პროგრამის გამოყენებაში, ჩვენ მივიღეთ მნიშვნელოვანი წარმოდგენება BLEU წარმოდგენების შესახებ პარალელური კორპუსზე (WMT14 ინგლისური გერმანეთის შესახებ) და ცოტა რესურსის (WIT გერმა</abstract_ka>
      <abstract_it>I modelli di encoder-decoder neurali della traduzione automatica hanno ottenuto risultati impressionanti, imparando la conoscenza linguistica sia delle lingue di origine che di destinazione in modo implicito end-to-end. Proponiamo un framework in cui il nostro modello inizia ad apprendere sintassi e traduzioni interleave, ponendo gradualmente maggiore attenzione alla traduzione. Utilizzando questo approccio, otteniamo notevoli miglioramenti in termini di punteggio BLEU su un corpus parallelo relativamente grande (WMT14 dall'inglese al tedesco) e un setup a basso contenuto di risorse (WIT dal tedesco all'inglese).</abstract_it>
      <abstract_uz>Name Biz murojaat qilamiz, bu yerda modelmiz syntax va tarjima bir tarjima bilan o'rganishni boshlaydi, taʼminlov tarjima qiladigan foydalanishni tahlil qilamiz. Bu usulni ishlatish uchun biz juda katta parallel kopus (WMT14 Inglizcha Ingliz tiliga Ingliz tilidan Olmonchaga (WIT Olmonchaga Ingliz tilidan Inglizchaga) oʻrnatilgan BLEU scorida juda ko'p yaxshi o'zgarishni bajaramiz.</abstract_uz>
      <abstract_vi>Mô hình mã hóa thần kinh của dịch chuyển máy đã đạt được kết quả ấn tượng, trong khi học kiến thức ngôn ngữ cả nguồn lẫn ngôn ngữ đích theo một cách riêng riêng. Chúng tôi đề xuất một khung cảnh mà mô hình của chúng tôi bắt đầu học syntax và dịch thuật kết nối nhau, dần tập trung vào dịch thuật. Sử dụng cách tiếp cận này, chúng ta đạt được những cải tiến đáng kể về lượng đứng bắn của đại bàng trên tập đoàn tương đối lớn (WM T14 Anh-Đức) và một thiết lập ít nguồn (lT.Đức-Anh).</abstract_vi>
      <abstract_da>Neurale encoder-dekoder modeller af maskinoversættelse har opnået imponerende resultater, samtidig med at man lærer sproglig viden om både kilde- og målsprog på en implicit end-to-end måde. Vi foreslår en ramme, hvor vores model begynder at lære syntaks og oversættelse indbyrdes og gradvist sætter fokus på oversættelse. Ved hjælp af denne tilgang opnår vi betydelige forbedringer i forhold til BLEU score på relativt stort parallelkorpus (WMT14 engelsk til tysk) og en lav ressource (WIT tysk til engelsk) setup.</abstract_da>
      <abstract_hr>Neuralni modeli prevoda uređaja postigli su impresivni rezultati, dok su učili jezičko znanje i izvora i ciljnih jezika na implicitni način kraja do kraja. Predlažemo okvir u kojem naš model počinje učiti sintaks i prevod, postupno stavljajući više fokus na prevod. Koristeći ovaj pristup, postigli smo značajne poboljšanje u smislu rezultata BLEU-a o relativno velikom paralelnom korpusu (WMT14 engleski na njemački) i uspostavljanju niskog resursa (WIT njemački na engleski jezik).</abstract_hr>
      <abstract_bg>Моделите на машинния превод с неврален кодер-декодер постигат впечатляващи резултати, докато изучават езиковото познание както на изходния, така и на целевия език по имплицитуален начин от край до край. Предлагаме рамка, в която нашият модел започва да изучава синтаксиса и превод, като постепенно поставя повече фокус върху превода. Използвайки този подход, постигаме значителни подобрения по отношение на оценката на сравнително голям паралелен корпус (от английски на немски) и нискоресурсна настройка (от немски на английски).</abstract_bg>
      <abstract_nl>Neuronale encoder-decodermodellen van machinevertaling hebben indrukwekkende resultaten behaald, terwijl linguïstische kennis van zowel de bron- als doeltalen impliciet end-to-end wordt geleerd. We stellen een framework voor waarin ons model begint syntaxis en vertaling onderling te leren, waarbij geleidelijk meer nadruk wordt gelegd op vertaling. Met deze aanpak bereiken we aanzienlijke verbeteringen in termen van BLEU score op relatief groot parallel corpus (WMT14 Engels naar Duits) en een low-resource (WIT Duits naar Engels) setup.</abstract_nl>
      <abstract_de>Neuronale Encoder-Decoder-Modelle der maschinellen Übersetzung haben beeindruckende Ergebnisse erzielt, während linguistische Kenntnisse sowohl der Quell- als auch der Zielsprache implizit durchgehend erlernt werden. Wir schlagen ein Framework vor, in dem unser Modell beginnt, Syntax und Übersetzung ineinander zu lernen und allmählich mehr Fokus auf die Übersetzung legt. Mit diesem Ansatz erzielen wir erhebliche Verbesserungen hinsichtlich des BLEU-Scores auf relativ großem Parallelkorpus (WMT14 Englisch in Deutsch) und eines ressourcenarmen (WIT Deutsch in Englisch) Setups.</abstract_de>
      <abstract_id>Model pengekoder-dekoder saraf dari terjemahan mesin telah mencapai hasil yang mengesankan, sementara mempelajari pengetahuan bahasa dari sumber dan bahasa sasaran dengan cara implicit akhir-akhir. Kami mengusulkan cadangan di mana model kita mulai belajar sintaks dan terjemahan saling melewati, secara perlahan-lahan menempatkan fokus lebih pada terjemahan. Menggunakan pendekatan ini, kami mencapai peningkatan yang konsiderel dalam terma skor BLEU pada corpus yang relatif besar paralel (WMT14 Inggris ke Jerman) dan sumber daya rendah (WIT Jerman ke Inggris).</abstract_id>
      <abstract_ko>기계 번역의 신경 코딩 모델은 은밀하게 원어와 목표 언어의 언어 지식을 학습하는 동시에 인상적인 성과를 거두었다.우리는 하나의 틀을 제시했다. 이 틀에서 우리의 모델은 문법과 교체 번역을 배우기 시작했고 점점 더 많은 주의력을 번역에 두었다.이런 방법으로 우리는 비교적 큰 평행 어료 라이브러리(WMT14 영어에서 독일어)와 비교적 낮은 자원(WIT 독일어에서 영어) 설정에서 상당히 큰 BLEU 점수 개선을 실현했다.</abstract_ko>
      <abstract_sw>Mfano wa kutangaza mfumo wa kutafsiri mashine umefanikiwa matokeo mazuri, wakati wanajifunza maarifa ya lugha ya kilele cha vyanzo na lugha zinazolenga kwa njia isiyo na maana ya mwisho. Tunazipendekeza mfumo ambao mwelekeo wetu unaanza kujifunza kodi na tafsiri zinazoingizwa, na kwa taratibu kuangalia tafsiri zaidi. Kwa kutumia mbinu hii, tunapata maendeleo makubwa kwa mujibu wa vipimo vya BLEU kuhusu makampuni makubwa yanayofanana (WMT14 hadi Ujerumani) na rasilimali duni (WIT Ujerumani hadi Kiingereza).</abstract_sw>
      <abstract_tr>Maşynyň terjimesiniň näbiri ködleme-kodeýji modelleri täsirli netijelere ýetdi, hem çeşmeleriň we maksady dilleriniň bilimi hem bilimi hem netijeli bir soňra çenli bilen öwrenýär. Biz nusgamyzyň sintaksy we terjime öwrenmesini terjime edip başlayan bir çerçew teklip edip görýäris. Bu ýalaýyşy ulanarak, BLEU अंश (WMT14 iňlisçe Almança) we iň az resurslar (iňlisçe bilen iňlisçe) düzümlendirmegi üçin esasy gowurak tapdyk.</abstract_tr>
      <abstract_fa>مدل‌های رمزبندی‌کننده‌های عصبی از ترجمه‌های ماشین به نتیجه‌های تاثیر‌پذیر رسیده‌اند، در حالی که دانش زبان‌شناسی از زبان‌های منبع و هدف به طریق پایان و پایان‌دهنده‌ای یاد گرفته‌اند. ما یک چهارچوب پیشنهاد می‌کنیم که مدل ما شروع به یادگیری از سنتاکس و ترجمه‌های متصل می‌شود، با تخفیف تمرکز بیشتری بر ترجمه می‌کند. با استفاده از این روش، ما با توجه به توجه به عنوان امتیاز BLEU در مورد شرکت نسبتا بزرگ مشترک (WMT14 انگلیسی به آلمان) و یک سازمان منابع کم (WIT آلمان به انگلیسی) رسیدیم.</abstract_fa>
      <abstract_sq>Modelet nervore të kodifikuesit dhe dekodimit të përkthimit të makinave kanë arritur rezultate mbresëlënëse, ndërsa mësimi i njohurive gjuhësore të burimit dhe të gjuhëve objektive në një mënyrë implicite nga fundi në fund. We propose a framework in which our model begins learning syntax and translation interleaved, gradually putting more focus on translation.  Duke përdorur këtë qasje, ne arrijmë përmirësime të konsiderueshme në lidhje me rezultatin BLEU në një korpus relativisht të madh paralel (WMT14 anglisht në gjerman) dhe një ngritje me burime të ulëta (WIT gjerman në anglisht).</abstract_sq>
      <abstract_af>Neurale enkoder-dekoder modele van masjien vertaling het inpresief resultate bereik, terwyl lingwisiese kennis van beide die bron en doel tale geleer het in 'n inplisite end- to- end manier. Ons voorstel 'n raamwerk waarin ons model begin om sintaks en vertaling te leer, met graduul meer fokus op vertaling te stel. Deur hierdie toegang te gebruik, het ons betekende verbeteringe aangevolg van BLEU aantal op relativies groot parallele korpus (WMT14 Engels tot Duits) en 'n lae hulpbron (WIT Duits tot Engels) opstelling bereik.</abstract_af>
      <abstract_am>የኔural encoder-decoder models of machine translation may be impressive results, while the language knowledge of both ቋንቋ and target ቋንቋዎች is under an impressive end to end. We propose a framework in which our model begins learning syntax and translation interleaved, gradually putting more focus on translation.  ይህንን ሥርዓት በመጠቀም፣ በቢሌU የኮርፓስ ትልቅ ትልቅ የኮርፓስ (WMT14 የጀርመን እንግሊዘኛ ወደ ጀርመን) እና ትንሽ የዕቃ ክፍል (WIT ጀርመን ወደ እንግሊዘኛ) የተደረገውን እና ትልቅ ክፍሎች እናደርጋለን፡፡</abstract_am>
      <abstract_hy>Մեքենայի թարգմանման նյարդային կոդավորման մոդելները տպավորիչ արդյունքներ են ստացել, մինչդեռ լեզվաբանական գիտելիքները սովորել են նաև աղբյուրի և նպատակային լեզուների մասին աննշանակալի վերջ-վերջ ձևով: We propose a framework in which our model begins learning syntax and translation interleaved, gradually putting more focus on translation.  Օգտագործելով այս մոտեցումը, մենք հասնում ենք նշանակալի բարելավումների ԲԼԵՎ գնահատականի առումով համեմատաբար մեծ զուգահեռ կորպոսի (ՀՄԹ14 անգլերեն գերմաներեն) և ցածր ռեսուրսների (ՀՄԹ գերմաներեն անգլե</abstract_hy>
      <abstract_az>Makina çevirilməsinin nöral kodlayıcı-dekoder modelləri təsirli sonuçlarını öyrənərək dillərin mənbəsini və məqsəd dillərini imkansız end-to-end yolu ilə öyrənərək təsirli sonuçları başa düşdü. Biz modellərimizin sintaksi və tercümə öyrənməsini başlayan bir çerçivi təklif edirik, təkrar çeviriməyə daha çox odaqlanır. Bu approach vasitəsilə, BLEU nöqtəsi haqqında çox böyük parallel korpus (WMT14 İngilizə Almanca) və düşük ressurs (WIT Almanca İngilizə qədər İngilizə qədər) düzəltdik.</abstract_az>
      <abstract_bn>মেশিন অনুবাদের নিউরেল এনকোডার-ডেকোডার মডেল চমৎকারের ফলাফল অর্জন করেছে, যেখানে উৎস এবং লক্ষ্য ভাষাগুলো উভয় সম্পর্কে ভাষার জ্ঞান শিখেছে ব আমরা একটি ফ্রেম কাঠামো প্রস্তাব করি যেখানে আমাদের মডেল সিন্ক্যাক্স এবং অনুবাদের মধ্যে শিখতে শুরু করে, ধীরে অনুবাদের উপর এই পদ্ধতি ব্যবহার করে আমরা বিলু স্কোরের মাধ্যমে বিশাল উন্নতি পেয়েছি (উইএমটি১৪ ইংরেজী জার্মান থেকে জার্মান) এবং একটি কম সম্পদ (উইটি জার্মান থেকে ইংরেজী থ</abstract_bn>
      <abstract_bs>Neuralni modeli prevoda uređaja postigli su impresivni rezultati, dok su učili jezičko znanje i izvora i ciljnih jezika na implicitni način kraja do kraja. Mi predlažemo okvir u kojem naš model počinje učiti sintaks i prevod, postupno stavljajući više fokus na prevod. Koristeći ovaj pristup, postigli smo značajne poboljšanje u smislu rezultata BLEU-a o relativno velikom paralelnom korpusu (WMT14 engleski na njemački) i uspostavi niskog resursa (WIT njemački na engleski jezik).</abstract_bs>
      <abstract_ca>Models neurocodificadors de traducció màquina han aconseguit resultats impressionants, mentre aprenent coneixements lingüístics de les llengües fonts i alvos d'una manera implícita de final a final. Proposem un marc en el qual el nostre model comença a aprendre sintaxi i traducció intercalades, posant gradualment més atenció a la traducció. Utilitzant aquest enfocament, aconsegueixem millores consideràries en termes de puntuació BLEU en un corpus relativament gran paral·lel (WMT14 anglès a alemany) i una configuració de baix recursos (WIT alemany a anglès).</abstract_ca>
      <abstract_cs>Modely strojového překladu s neurálním kodérem a dekodérem dosáhly působivých výsledků, přičemž se učí jazykové znalosti zdrojového i cílového jazyka implicitním end-to-end způsobem. Navrhujeme rámec, ve kterém se náš model začíná učit syntaxi a překlad prolínající, postupně se více zaměřuje na překlad. Pomocí tohoto přístupu dosahujeme výrazných zlepšení z hlediska BLEU skóre na relativně velkém paralelním korpusu (WMT14 z angličtiny do němčiny) a nastavení s nízkými zdroji (WIT z němčiny do angličtiny).</abstract_cs>
      <abstract_et>Masintõlke neurokodeerija-dekooderi mudelid on saavutanud muljetavaldavaid tulemusi, õppides nii lähte- kui ka sihtkeelte keeleoskust kaudselt lõpuni. Pakume välja raamistiku, kus meie mudel hakkab õppima süntaksit ja tõlke vahele, pöörates järk-järgult rohkem tähelepanu tõlkele. Selle lähenemisviisi abil saavutame märkimisväärseid parandusi BLEU skoori suhteliselt suure paralleelse korpuse (WMT14 inglise kuni saksa) ja madala ressursiga (WIT saksa kuni inglise) seadistuse osas.</abstract_et>
      <abstract_fi>Konekäännöksen neurokooderi-dekooderimallit ovat saaneet aikaan vaikuttavia tuloksia, samalla kun he oppivat kielellistä tietoa sekä lähde- että kohdekielistä implisiittisesti päästä päähän. Ehdotamme viitekehystä, jossa mallimme alkaa oppia syntaksia ja kääntämistä vuorotellen, kiinnittäen vähitellen enemmän huomiota kääntämiseen. Tämän lähestymistavan avulla saavutamme merkittäviä parannuksia BLEU-pisteissä suhteellisen suuressa rinnakkaiskorpusessa (WMT14 englanniksi saksaksi) ja vähävaraisessa (WIT saksaksi englanniksi) kokoonpanossa.</abstract_fi>
      <abstract_sk>Modeli strojnega prevajanja so dosegli impresivne rezultate, medtem ko so se implicitno učili jezikovnega znanja izvornih in ciljnih jezikov. Predlagamo okvir, v katerem se naš model začne učiti sintakse in prevajanje prepleteno, s čimer se postopoma bolj osredotoča na prevajanje. S tem pristopom dosežemo precejšnje izboljšave v smislu rezultatov BLEU na relativno velikem vzporednem korpusu (WMT14 angleščina v nemščini) in nizkih virov (WIT nemščina v angleščini).</abstract_sk>
      <abstract_ha>@ info: whatsthis Tuna goyyar da wani firam wanda misalinmu ke fara karanta taɓa da fassarar da aka haɗa shi, kuma za'a saka muhimmin fassarar da fassarar. Yana amfani da wannan hanyarwa, za'a sami mafiya kyau a cikin fassarar BLEU ko ko kuma ma'abũcin rubutu mai tsawo (WMT14 na Ingiriya zuwa Jarmaya) da wani marufu mai ƙasƙanci (WAT Jaman zuwa Ingiriya).</abstract_ha>
      <abstract_bo>Neural encoder-decoder models of machine translation have achieved impressive results, while learning linguistic knowledge of both the source and target languages in an implicit end-to-end manner. ང་ཚོས་རང་གི་མིག་ཆས་འདིའི་ནང་གི་མ་དབྱིབས་ཤེས་པའི་དབྱེ་རིགས་དང་སྐད་རིགས་ཀྱི་ནང་དུ་འགོ་བཙུགས་ཏེ། འོན་ཀྱང་། ང་ཚོས་རང་ཉིད་ཀྱི་གནད་སྡུད་འདི་སྤྱོད་མཁན་ལས་ཉུང་བའི་མཐུན་རྐྱེན་ཚད་ལྡན་པ་ཞིག་ཡིན།</abstract_bo>
      <abstract_jv>Kernel Awak dhéwé ngerasah sistem sing sampeyan mrogram kuwi, iso nggambar njaluk sistem sing tarjamahan karo terjamah. Awak dhéwé nggunakake iki, awak dhéwé iso nglanggar bantuan liyane karo perusahaan-perusahaan banget kanggo kalagayut ngregani anu barang blok (WW14 Inggris kanggo German) lan nganggo alaman sing paling dhéwé (WIT German nganggo Inggris).</abstract_jv>
      <abstract_he>דוגמני קודד-קידור עצביים של התרגום מכונת השיגו תוצאות מרשים, בעוד ללמוד ידע שפתי של גם המקור וגם שפות המטרה בדרך מפורסמת סוף-סוף. אנו מציעים מסגרת שבה המודל שלנו מתחיל ללמוד סינטקס ותרגום בין השעות, בהדרגה לשים יותר מרכז על התרגום. Using this approach, we achieve considerable improvements in terms of BLEU score on relatively large parallel corpus (WMT14 English to German) and a low-resource (WIT German to English) setup.</abstract_he>
      </paper>
    <paper id="19">
      <title>Do latent tree learning models identify meaningful structure in sentences?</title>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Andrew</first><last>Drozdov</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <doi>10.1162/tacl_a_00019</doi>
      <abstract>Recent work on the problem of latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting <a href="https://en.wikipedia.org/wiki/Parsing">parse</a> to interpret the sentence, all without exposure to ground-truth parse trees at training time. Surprisingly, these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> often perform better at sentence understanding tasks than <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that use parse trees from conventional <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. This paper aims to investigate what these latent tree learning models learn. We replicate two such models in a shared codebase and find that (i) only one of these models outperforms conventional tree-structured models on sentence classification, (ii) its parsing strategies are not especially consistent across random restarts, (iii) the parses it produces tend to be shallower than standard Penn Treebank (PTB) parses, and (iv) they do not resemble those of PTB or any other semantic or syntactic formalism that the authors are aware of.</abstract>
      <pages>253–267</pages>
      <url hash="06cb8e8f">Q18-1019</url>
      <video href="https://vimeo.com/277673973" />
      <bibkey>williams-etal-2018-latent</bibkey>
      <pwccode url="https://github.com/NYU-MLL/spinn" additional="false">NYU-MLL/spinn</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    <title_ar>هل تحدد نماذج تعلم الشجرة الكامنة بنية ذات معنى في الجمل؟</title_ar>
      <title_fr>Les modèles d'apprentissage par arbre latent identifient-ils une structure significative dans les phrases ?</title_fr>
      <title_es>¿Los modelos de aprendizaje de árboles latentes identifican la estructura significativa en las oraciones?</title_es>
      <title_pt>Os modelos de aprendizagem de árvores latentes identificam estruturas significativas nas frases?</title_pt>
      <title_zh>潜树学模形识句有义否?</title_zh>
      <title_ja>潜在的な木の学習モデルは、文章の意味のある構造を特定しますか？</title_ja>
      <title_ru>Определяют ли модели обучения латентному дереву значимую структуру в предложениях?</title_ru>
      <title_hi>क्या अव्यक्त पेड़ सीखने के मॉडल वाक्यों में सार्थक संरचना की पहचान करते हैं?</title_hi>
      <title_ga>An sainaithníonn samhlacha folaithe crannfhoghlama struchtúr brí in abairtí?</title_ga>
      <title_ka>ლეტენტის სწავლების მოდელები იდენტიფიკაციენ სანიშვნელოვანი სტრუქტურა სიტყვებში?</title_ka>
      <title_el>Τα λανθάνοντα μοντέλα εκμάθησης δέντρων αναγνωρίζουν ουσιαστική δομή στις προτάσεις;</title_el>
      <title_hu>A látens fatanulási modellek azonosítják-e a mondatok értelmes struktúráját?</title_hu>
      <title_it>I modelli di apprendimento ad albero latente identificano una struttura significativa nelle frasi?</title_it>
      <title_kk>Кейтілген ағаш үйрену үлгілері сөздерде маңызды құрылымды анықтайды ба?</title_kk>
      <title_mk>Дали latent tree learning models identify meaningful structure in sentences?</title_mk>
      <title_lt>Ar latentiniai medžių mokymosi modeliai nustato prasmingą sakinių struktūrą?</title_lt>
      <title_ms>Adakah model pembelajaran pokok tersembunyi mengenalpasti struktur bermakna dalam kalimat?</title_ms>
      <title_ml>അടുത്ത വൃക്ഷത്തില്‍ പഠിക്കുന്ന മോഡലുകള്‍ വാക്കുകളില്‍ അര്‍ത്ഥതയുള്ള ഘടനയെ തിരിച്ചറിയുന്</title_ml>
      <title_mt>Il-mudelli latenti tat-tagħlim tas-siġar jidentifikaw struttura sinifikanti fis-sentenzi?</title_mt>
      <title_mn>Сүүлийн мод суралцах загварууд өгүүлбэрт утгатай бүтэц тодорхойлж байна уу?</title_mn>
      <title_no>Er det lette trelæringsmodeller identifisert meaningfulle struktur i setningar?</title_no>
      <title_pl>Czy ukryte modele uczenia się drzew identyfikują znaczącą strukturę w zdaniach?</title_pl>
      <title_sr>Da li se latentni modeli učenja drveta identifikuju značajnu strukturu rečenica?</title_sr>
      <title_ro>Modelele latente de învățare în arbori identifică structura semnificativă a propozițiilor?</title_ro>
      <title_si>අන්තිම වස්තුවක් ඉගෙන ඉගෙන ගස් මොඩේල් එක්ක අදහස් කරනවද?</title_si>
      <title_so>Tusaalada waxbarashada ee geedka ugu dambeeyay ma aqoonsadaa dhismo waxyaabo leh oo ku saabsan hadallada?</title_so>
      <title_sv>Identifierar latenta trädinlärningsmodeller meningsfull struktur i meningar?</title_sv>
      <title_ta>சமீபத்தில் மரம் கற்றுக்கொள்ளும் மாதிரி</title_ta>
      <title_ur>کیا لٹینٹ درخت کی تعلیم مدل کلمات میں معنی ساختار کی تعریف کرتے ہیں؟</title_ur>
      <title_uz>Yaqinda ochilgan daraxt o'rganish modellari soʻzlarda muhim tizimni aniqlashni istaysizmi?</title_uz>
      <title_vi>Mẫu học gốc ẩn có nhận diện cấu trúc có ý nghĩa trong câu không?</title_vi>
      <title_bg>Дали латентните модели за учене на дървета идентифицират смислена структура в изреченията?</title_bg>
      <title_nl>Identificeren latente boomleermodellen betekenisvolle structuur in zinnen?</title_nl>
      <title_hr>Da li latentni modeli učenja drveta identificiraju značajnu strukturu u rečenicama?</title_hr>
      <title_da>Identificerer latente trælæringsmodeller meningsfuld struktur i sætninger?</title_da>
      <title_de>Erkennen latente Baumlernmodelle sinnvolle Strukturen in Sätzen?</title_de>
      <title_id>Apakah model belajar pohon latent mengidentifikasi struktur berarti dalam kalimat?</title_id>
      <title_ko>잠재적 트리 학습 모델은 문장의 의미 있는 구조를 식별할 수 있습니까?</title_ko>
      <title_fa>آیا مدل یادگیری درخت لاتین ساختار معنی را در جمله شناسایی می کنند؟</title_fa>
      <title_tr>Soňky agaç öwrenmek nusgalary sözleriň aňsat strukturyny tanyşdyrýarmy?</title_tr>
      <title_sw>Je, mitindo ya kujifunza hivi karibuni yanatambua muundo wa maana katika hukumu?</title_sw>
      <title_af>Doen latente boom leer modele betekenlike struktuur in setnings identifiseer?</title_af>
      <title_sq>A identifikojnë modelet e mësimit të drurit të fshehtë strukturën e kuptueshme në fraza?</title_sq>
      <title_am>የአሁኑ ዛፍ ተማሪ ሞዴላዎችን በክፍሎች የሚያስፈልገውን ሥርዓት ማግኘት ይችላልን?</title_am>
      <title_hy>Արդյո՞ք թաքնված ծառերի ուսումնասիրության մոդելները բացահայտում են նախադասությունների իմաստալից կառուցվածք:</title_hy>
      <title_az>Lakin ağac öyrənmə modelləri cümlələrdə anlamlı quruluş tanıdırmı?</title_az>
      <title_bn>সাম্প্রতিক গাছ শিক্ষা মডেল কি বাক্যের মানে অর্থহীন কাঠামো চিহ্নিত করে?</title_bn>
      <title_ca>Els models latents d'aprenentatge d'arbres identificen una estructura significativa en les frases?</title_ca>
      <title_bs>Da li latentni modeli učenja drveta identifikuju značajnu strukturu u rečenicama?</title_bs>
      <title_cs>Identifikují modely latentního učení stromů smysluplnou strukturu ve větách?</title_cs>
      <title_fi>Tunnistavatko piilevät puuoppimismallit lauseiden merkityksellisen rakenteen?</title_fi>
      <title_et>Kas latentsed puuõppemudelid tuvastavad lausetes tähendusliku struktuuri?</title_et>
      <title_jv>Opo sampeyan Jared sing paling nggambar model kuwi nggawe structural yang menehi mu ngerasah?</title_jv>
      <title_sk>Ali latentni modeli učenja dreves prepoznajo pomembno strukturo stavkov?</title_sk>
      <title_he>האם דוגמני לימוד עצים מוסתרים מזהה מבנה משמעותי במשפטים?</title_he>
      <title_ha>Do latent tree learning models identify meaningful structure in sentences?</title_ha>
      <title_bo>མཇུག་གི་དབྱིབས་ཤོག་གི་མིག་སྔར་མ་དཔེ་ཚོགས་ཚིག་གི་དབྱིབས་ཕལ་ཆེན་དུ་དམ་འཛུགས་བྱེད་སམ།</title_bo>
      <abstract_ar>أتاح العمل الأخير على مشكلة تعلم الشجرة الكامن إمكانية تدريب الشبكات العصبية التي تتعلم تحليل جملة ما واستخدام التحليل الناتج لتفسير الجملة ، كل ذلك دون التعرض لأشجار تحليل الحقيقة الأرضية في وقت التدريب. والمثير للدهشة أن هذه النماذج غالبًا ما تؤدي أداءً أفضل في مهام فهم الجمل من النماذج التي تستخدم أشجار التحليل من المحللين التقليديين. تهدف هذه الورقة إلى استكشاف ما تتعلمه نماذج التعلم الشجري الكامنة. قمنا بتكرار نموذجين من هذا القبيل في قاعدة بيانات مشتركة ووجدنا أن (1) واحدًا فقط من هذه النماذج يتفوق في الأداء على النماذج التقليدية المهيكلة بالأشجار في تصنيف الجملة ، (2) استراتيجيات التحليل الخاصة به ليست متسقة بشكل خاص عبر عمليات إعادة التشغيل العشوائية ، (3) يوزعها تميل المنتجات إلى أن تكون ضحلة من تحليلات Penn Treebank (PTB) القياسية ، و (4) أنها لا تشبه تلك الخاصة بـ PTB أو أي شكليات دلالية أو نحوية أخرى يعرفها المؤلفون.</abstract_ar>
      <abstract_es>El trabajo reciente sobre el problema del aprendizaje de árboles latentes ha hecho posible entrenar redes neuronales que aprenden tanto a analizar una oración como a usar el análisis sintáctico resultante para interpretarla, todo sin exposición a árboles de análisis de verdad fundamental en el momento del entrenamiento. Sorprendentemente, estos modelos a menudo funcionan mejor en las tareas de comprensión de oraciones que los modelos que utilizan árboles de análisis de analizadores convencionales. Este artículo tiene como objetivo investigar lo que aprenden estos modelos de aprendizaje de árboles latentes. Replicamos dos de estos modelos en una base de código compartido y encontramos que (i) solo uno de estos modelos supera a los modelos convencionales estructurados en árbol en la clasificación de oraciones, (ii) sus estrategias de análisis no son especialmente consistentes en reinicios aleatorios, (iii) los análisis que produce tienden a ser más superficiales que el estándar Penn Treebank (PTB) analiza, y (iv) no se parecen a los de PTB ni a ningún otro formalismo semántico o sintáctico que los autores conozcan.</abstract_es>
      <abstract_pt>Trabalhos recentes sobre o problema de aprendizado de árvore latente tornaram possível treinar redes neurais que aprendem a analisar uma sentença e usar a análise resultante para interpretar a sentença, tudo sem exposição a árvores de análise de verdade no tempo de treinamento. Surpreendentemente, esses modelos geralmente têm um desempenho melhor em tarefas de compreensão de sentenças do que os modelos que usam árvores de análise sintática de analisadores convencionais. Este artigo tem como objetivo investigar o que esses modelos de aprendizagem em árvore latente aprendem. Replicamos dois desses modelos em uma base de código compartilhada e descobrimos que (i) apenas um desses modelos supera os modelos convencionais estruturados em árvore na classificação de sentenças, (ii) suas estratégias de análise não são especialmente consistentes em reinicializações aleatórias, (iii) a análise produz tendem a ser mais superficiais do que as análises padrão do Penn Treebank (PTB) e (iv) não se assemelham às do PTB ou de qualquer outro formalismo semântico ou sintático de que os autores estejam cientes.</abstract_pt>
      <abstract_fr>Des travaux récents sur le problème de l'apprentissage par arbre latent ont permis de former des réseaux de neurones qui apprennent à la fois à analyser une phrase et à utiliser l'analyse résultante pour interpréter la phrase, le tout sans exposition aux arbres d'analyse de la vérité de terrain au moment de l'apprentissage. Étonnamment, ces modèles sont souvent plus performants dans les tâches de compréhension des phrases que les modèles qui utilisent des arbres d'analyse provenant d'analyseurs conventionnels. Cet article vise à étudier ce que ces modèles d'apprentissage d'arbres latents apprennent. Nous reproduisons deux modèles de ce type dans une base de code partagée et constatons que (i) un seul de ces modèles surpasse les modèles structurés en arborescence conventionnels sur la classification des phrases, (ii) ses stratégies d'analyse ne sont pas particulièrement cohérentes entre les redémarrages aléatoires, (iii) les analyses qu'il produit ont tendance à être moins profondes que la norme Penn Treebank (PTB) analyse, et (iv) ils ne ressemblent pas à ceux de PTB ou à tout autre formalisme sémantique ou syntaxique dont les auteurs ont connaissance.</abstract_fr>
      <abstract_ja>潜伏木学習の問題に関する最近の研究により、文を構文解析する方法と、結果として得られる構文解析を使用して文を解釈する方法の両方を学習するニューラルネットワークを訓練することが可能になり、すべての場合、訓練時に真の構文解析木に露出することはありません。驚くべきことに、これらのモデルは、従来の構文解析器からの構文解析ツリーを使用するモデルよりも、文章理解タスクで優れた性能を発揮することが多い。本論文は、これらの潜在的な木の学習モデルが学ぶことを調査することを目的としている。私たちは、共有コードベースで2つのそのようなモデルを複製し、(i)これらのモデルのうちの1つだけが、文章分類に関する従来の木構造化モデルよりも優れていること、(ii)その構文解析戦略がランダムな再起動にわたって特に一貫していないこと、(iii)それが生成する構文解析は、標準的なペンツリーバンク（ PTB ）構文解析よりも浅い傾向があること、および(iv)それらが、PTBまたは著者が認識している他のいかなる意味論的または構文論的形式主義のものとも似ていないことを発見した。</abstract_ja>
      <abstract_hi>अव्यक्त पेड़ सीखने की समस्या पर हाल के काम ने तंत्रिका नेटवर्क को प्रशिक्षित करना संभव बना दिया है जो एक वाक्य को पार्स करना सीखते हैं और वाक्य की व्याख्या करने के लिए परिणामी पार्स का उपयोग करते हैं, सभी प्रशिक्षण के समय जमीन-सत्य पार्स पेड़ों के संपर्क में आने के बिना। हैरानी की बात है, ये मॉडल अक्सर पारंपरिक पार्सर से पार्स पेड़ों का उपयोग करने वाले मॉडल की तुलना में वाक्य समझने वाले कार्यों में बेहतर प्रदर्शन करते हैं। इस पेपर का उद्देश्य यह जांचना है कि ये अव्यक्त पेड़ सीखने के मॉडल क्या सीखते हैं। हम एक साझा कोडबेस में ऐसे दो मॉडलों को दोहराते हैं और पाते हैं कि (i) इनमें से केवल एक मॉडल वाक्य वर्गीकरण पर पारंपरिक पेड़-संरचित मॉडल को मात देता है, (ii) इसकी पार्सिंग रणनीतियां यादृच्छिक पुनरारंभ में विशेष रूप से सुसंगत नहीं हैं, (iii) इसके द्वारा उत्पादित पार्स मानक पेन ट्रीबैंक (पीटीबी) पार्स की तुलना में उथले होते हैं, और (iv) वे पीटीबी या किसी अन्य शब्दार्थ या वाक्यात्मक औपचारिकता के समान नहीं होते हैं जिनके बारे में लेखकों को पता है।</abstract_hi>
      <abstract_zh>近者能使练神经网络为可也,神经网络能学解析句,能成解析解句,不待练而触地真值解析树也。 令人讶之,比解析器解析树,句解之常善也。 本文旨在研究这些潜伏树学习模样。 共享代码库复制二模,(i)一句优于旧树,(ii)其解析策随机重启时不特一,(iii)其所生解析往往比Penn Treebank(PTB)解析浅,(iv)与PTB所知语义或主义异文。</abstract_zh>
      <abstract_ru>Недавняя работа над проблемой обучения латентному дереву позволила обучить нейронные сети, которые учатся как анализировать предложение, так и использовать полученный анализ для интерпретации предложения, все без воздействия деревьев анализа истины на земле во время обучения. Удивительно, но эти модели часто лучше справляются с задачами по пониманию предложений, чем модели, которые используют деревья синтаксического анализа из обычных синтаксических анализаторов. Целью данной работы является исследование того, чему учатся эти модели обучения латентным деревьям. Мы воспроизводим две такие модели в общей кодовой базе и обнаруживаем, что (i) только одна из этих моделей превосходит обычные древовидные модели классификации предложений, (ii) ее стратегии синтаксического анализа не особенно последовательны при случайных перезапусках, (iii) синтаксический анализ, который она производит, как правило, неглубоко, чем стандартные синтаксические анализы Penn Treebank (PTB), и (iv) они не похожи на синтаксический или синтаксический формализм PTB или любой другой семантический или синтаксический формализм, о котором знают авторы.</abstract_ru>
      <abstract_ga>Mar gheall ar obair a rinneadh le déanaí ar fhadhb na foghlama folaigh crann is féidir líonraí néaracha a oiliúint a fhoghlaimíonn conas abairt a pharsáil agus a úsáideann an pharsáil mar thoradh air chun an abairt a léirmhíniú, ar fad gan nochtadh do chrainn pharsála fhírinneachta ag am oiliúna. Is ionadh é, is minic a éiríonn leis na samhlacha seo tascanna tuiscint pianbhreithe níos fearr ná samhlacha a úsáideann crainn pharsála as gnáthpharsálaithe. Tá sé mar aidhm ag an bpáipéar seo imscrúdú a dhéanamh ar cad a fhoghlaimíonn na samhlacha foluaite crannfhoghlama seo. Déanaimid dhá mhúnla dá leithéid a mhacasamhlú i gcódbhonn comhroinnte agus feicimid (i) nach sáraíonn ach múnla amháin de na múnlaí traidisiúnta samhlacha struchtúrtha crann maidir le haicmiú abairtí, (ii) nach bhfuil a straitéisí parsála comhsheasmhach go háirithe thar atosú randamach, (iii) parsanna é is gnách go mbíonn táirgí níos éadomhain ná parsaí caighdeánacha Penn Treebank (PTB), agus (iv) níl siad cosúil le táirgí PTB ná le haon fhoirmiúlacht shéimeantach nó chomhréire eile a bhfuil na húdair ar an eolas faoi.</abstract_ga>
      <abstract_el>Πρόσφατες εργασίες σχετικά με το πρόβλημα της λανθάνουσας μάθησης δέντρων έχουν καταστήσει δυνατή την εκπαίδευση νευρωνικών δικτύων που μαθαίνουν τόσο να αναλύουν μια πρόταση όσο και να χρησιμοποιούν την προκύπτουσα ανάλυση για να ερμηνεύσουν την πρόταση, όλα αυτά χωρίς έκθεση σε δέντρα ανάλυσης επίγειας αλήθειας κατά τη διάρκεια της εκπαίδευσης. Παραδόξως, αυτά τα μοντέλα συχνά αποδίδουν καλύτερα σε εργασίες κατανόησης προτάσεων από μοντέλα που χρησιμοποιούν δέντρα ανάλυσης από συμβατικούς αναλυτές. Η παρούσα εργασία έχει ως στόχο να διερευνήσει τι μαθαίνουν αυτά τα λανθάνοντα μοντέλα μάθησης δέντρων. Αντιγραφούμε δύο τέτοια μοντέλα σε μια κοινή βάση κώδικα και διαπιστώνουμε ότι (i) μόνο ένα από αυτά τα μοντέλα ξεπερνά τα συμβατικά μοντέλα δομής δέντρων στην ταξινόμηση προτάσεων, (ii) οι στρατηγικές ανάλυσης του δεν είναι ιδιαίτερα συνεπείς σε τυχαίες επανεκκινήσεις, (iii) οι αναλύσεις που παράγει τείνουν να είναι πιο ρηχές από τις τυπικές αναλύσεις Penn Tree Bank (PTB) και iv) δεν μοιάζουν με εκείνα της PTB ή με οποιονδήποτε άλλο σημασιολογικό ή συντακτικό φορμαλισμό που γνωρίζουν οι συγγραφείς.</abstract_el>
      <abstract_hu>A látens fatanulás problémájával kapcsolatos közelmúltbeli munkák lehetővé tették a neurális hálózatok kiképzését, amelyek megtanulják egy mondat elemzését és az ebből eredő elemzést használni a mondat értelmezésére, mindezt anélkül, hogy a képzés időpontjában a talaj-igazság elemzési fáknak kitettsék volna. Meglepő módon ezek a modellek gyakran jobban teljesítenek mondatértési feladatokat, mint a hagyományos elemzők elemzési fáit használó modellek. A tanulmány célja, hogy megvizsgálja, mit tanulnak ezek a látens fa tanulási modellek. Két ilyen modellt replikálunk egy megosztott kódbázisban, és megállapítjuk, hogy (i) e modellek közül csak az egyik túllép a hagyományos fastrukturált modelleknél a mondatok osztályozásában, (ii) elemzési stratégiái nem különösen következetesek a véletlenszerű újraindításoknál, (iii) az általa előállított elemzések általában keskenyebbek, mint a hagyományos Penn Treebank (PTB) elemzések, és (iv) nem hasonlítanak a PTB-hez vagy bármely más szemantikai vagy szintaktikus formalizmushoz, amelyről a szerzők tisztában vannak.</abstract_hu>
      <abstract_ka>ბოლოდან მუშაობის პრობლემაზე, რომელიც შეუძლებელია გასწავლა ნეიროლური ქსელი, რომელიც გასწავლა სიტყვას და გამოყენება გასწავლა შემდეგი პარასტის გამოყენება, რომ გარგება სიტყვას, ყველა სხვადასხვა, ეს მოდელები ხშირად უფრო უკეთესია, როგორც მოდელები, რომლებიც კონტაქციონალური პარასერებიდან გამოყენებენ პარასუზაციას. ეს დოკუნტის მიზეზი იყო, რომ პასუხოთ რას მოდელები სწავლებენ ამ ლეტენტური ხე სწავლების. ჩვენ ორი ასეთი მოდელეები ერთი კოდენციალური კოდენციალური კოდენტიკური მოდელეების კლასიფიკაციაში დავიწყებთ. i i) მისი პანსტიკური სტრატიკური სტრატიკური მოდელეები არიან განსაკუთრებულია შემდეგ შემდეგ დავიწყება, iii) პანსტიკური მოდელეები, რომლები და iv) ისინი PTB-ის ან სხვა სიმენტიკური ან სინტაქტიკური ფორმატიზმის არსებობს, რომელიც ავტორები იცნობენ.</abstract_ka>
      <abstract_lt>Neseniai atliktas darbas sprendžiant latentinio medžio mokymosi problem ą sudarė galimybę treniruoti nervinius tinklus, kurie mokosi išanalizuoti sakinį ir naudoja gautą analizę išaiškinti sakinį, bet nenustatyta žeminės tiesos išanalizavimo medžių mokymo metu. Įspūdinga, kad šie modeliai dažnai geriau supranta sakinius nei modeliai, kuriuose naudojami paprastųjų analizatorių mediniai apdorojimai. Šiame dokumente siekiama ištirti, ką mokosi šie latentiniai medžių mokymosi modeliai. Kartojame du tokius modelius bendroje kodų bazėje ir nustatome, kad i) tik vienas i š šių modelių atitinka tradicinius medžio struktūrizuotus modelius pagal sakinių klasifikaciją, ii) jo analizavimo strategijos nėra ypač nuoseklios atsitiktinio atnaujinimo metu, iii) jo gaminami analizavimai paprastai yra žemesni nei standartiniai Penn Treebank (PTB) analizavimai, ir iv) jie neatitinka PTB arba bet kokio kito semantinio ar sintaktinio formalumo, apie kurį autoriai žino.</abstract_lt>
      <abstract_it>Recenti lavori sul problema dell'apprendimento degli alberi latenti hanno permesso di formare reti neurali che imparano sia ad analizzare una frase che ad usare il parse risultante per interpretare la frase, il tutto senza esposizione ad alberi di parse della verità del suolo al momento dell'allenamento. Sorprendentemente, questi modelli spesso funzionano meglio nelle attività di comprensione delle frasi rispetto ai modelli che utilizzano alberi di parsing da parser convenzionali. Questo articolo mira a indagare cosa imparano questi modelli di apprendimento degli alberi latenti. Replicamo due di questi modelli in una codebase condivisa e scopriamo che (i) solo uno di questi modelli supera i modelli tradizionali strutturati ad albero sulla classificazione delle frasi, (ii) le sue strategie di analisi non sono particolarmente coerenti durante i riavvi casuali, (iii) le analisi che produce tendono ad essere più basse rispetto alle analisi standard Penn Treebank (PTB), e (iv) non assomigliano a quelli del PTB o di qualsiasi altro formalismo semantico o sintattico di cui gli autori siano a conoscenza.</abstract_it>
      <abstract_mn>Сүүлийн үеийн мод суралцах асуудлын тухай ажиллах нь мэдрэлийн сүлжээг суралцах боломжтой болгож өгүүлбэрийг хуваалцах боломжтой, үр дүн нь өгүүлбэрийг илэрхийлэх боломжтой болгож, бүх зүйлсийг суралцах цаг хугацаанд газар Гайхалтай нь эдгээр загварууд даалгаваруудыг илүү ойлгох арга загвараас илүү сайн хийдэг. Энэ цаасан нь эдгээр сүүлийн модны суралцах загварууд юу суралцахыг судалдаг. Бид хоёр иймэрхүү загварыг хуваалцах кодлогийн суурь дээр хуваалцаж, i) зөвхөн энэ загварын нэг нь өгүүлбэр хэлэлцүүлэхэд энгийн мод бүтээгдэхүүн загвар, ii) түүний хуваалцах стратеги нь ялангуяа санамсаргүй дахин дахин тогтмол биш, iii) үүний үйлдвэрлэх талаар нь стандарт Пэнн Трибанк (PT Мөн (iv) тэд ПТБ эсвэл зохиолчдын мэдэх ямар ч semantic, синтактик официализм шиг харагдахгүй.</abstract_mn>
      <abstract_kk>Соңғы жұмыс істеген ағаш оқытуының мәселесі, сөзді талдау және мәселесін толықтау үшін үйренетін невралдық желілерді оқыту мүмкіндігін жасады. Бүкіл ағаштарды оқыту уақытында талдау үшін, мәсе Бұл үлгілер әдеттегі талдаушылардан ағаштарды талдау үлгілерінен артық тапсырмаларды түсінуге көп жақсы жұмыс істейді. Бұл қағаз бұл ағаш оқыту үлгілерін зерттеу үшін мақсатты. Біз бұл екі үлгі ортақтастырылған кодтамасында қайталап, i) тек бұл үлгілердің бірі сөздерді шектеу үлгілерінде әдеттегі ағаш құрылған моделдерді, ii) оның талдау стратегиясы кездейсоқ қайталау үшін әдеттегі емес, (iii) оның талдау үлгілері стандартты Penn Treebank (PTB) талдауынан және iv) олар PTB немесе авторлардың білетін синтактикалық не синтактикалық формализміне ұқсас емес.</abstract_kk>
      <abstract_pl>Ostatnie prace nad problemem ukrytego uczenia się drzewa pozwoliły na trening sieci neuronowych, które uczą się zarówno analizować zdanie, jak i używać wynikającej analizy do interpretacji zdania, wszystko bez narażenia na drzewa analizy ziemi-prawdy w czasie treningu. Co zaskakujące, modele te często sprawdzają się lepiej w rozumieniu zdań niż modele wykorzystujące drzewa parsowania z konwencjonalnych parserów. Celem niniejszego artykułu jest zbadanie, czego uczą się te ukryte modele uczenia się drzew. Replikujemy dwa takie modele we wspólnej bazie kodu i stwierdzimy, że (i) tylko jeden z tych modeli przewyższa konwencjonalne modele struktury drzewa w klasyfikacji zdań, (ii) jego strategie parsowania nie są szczególnie spójne w przypadku losowych restartów, (iii) parsy, które wytwarza, są bardziej płytkie niż standardowe parsy Penn Treebank (PTB), i iv) nie przypominają one formalizmów PTB ani żadnego innego formalizmu semantycznego lub składniowego, którego autorzy są świadomi.</abstract_pl>
      <abstract_ro>Lucrările recente privind problema învățării arborilor latenți au făcut posibilă instruirea rețelelor neuronale care învață atât să analizeze o propoziție, cât și să folosească analiza rezultată pentru a interpreta propoziția, toate fără expunerea la arborii de analizare a adevărului pământului în timpul antrenamentului. În mod surprinzător, aceste modele deseori funcționează mai bine la sarcinile de înțelegere a propozițiilor decât modelele care utilizează arbori de parsing din parsere convenționale. Această lucrare își propune să investigheze ce învață aceste modele latente de învățare a arborilor. Reproducem două astfel de modele într-o bază de coduri partajată și constatăm că (i) doar unul dintre aceste modele depășește modelele convenționale structurate în arbori în clasificarea propozițiilor, (ii) strategiile sale de analizare nu sunt deosebit de consistente în timpul repornirilor aleatorii, (iii) analizele pe care le produce tind să fie mai subțiri decât analizele standard Penn Treebank (PTB), și (iv) nu seamănă cu cele ale PTB sau orice alt formalism semantic sau sintactic de care autorii sunt conștienți.</abstract_ro>
      <abstract_si>ප්‍රශ්නයක් ලේටින් ගස් ඉගෙනගන්න ප්‍රශ්නයක් ගැන අතින් වැඩ කරන්න පුළුවන් විදිහට ප්‍රශ්නයක් කරලා තියෙන්නේ න්‍යූරාල ජාලයක් දෙන්නම පුදුම විශ්වාසයෙන්, මේ මොඩල් සාමාන්‍ය විශ්වාසකයෙන් වැඩක් තේරුම් ගන්න පුළුවන් මොඩල් වඩා විශ්ව මේ පැත්තේ අදහස් කරනවා මේ ලේටින් ගස් ඉගෙන ගන්න මොකක්ද ඉගෙන ගන්නේ. අපි ඒ වගේ මොඩල් දෙකක් සමාගන්නේ කෝඩ් බේස් එකේ හොයාගන්න හැකි විදියට (i) මේ මොඩල් එකෙක් විතරයි ප්‍රමාණය විදියට සාමාන්‍ය ගස් සංවිධානය විදියට විශේෂයෙන් විශේෂයෙන් ප්‍රමාණ ඒ වගේම (iv) ඔවුන් PTB වලින් සම්බන්ධ නැහැ නැහැ නැහැ නැහැ නැහැ නැහැ නැත්නම් ලේඛකයන් දැනගෙන ඉන්න තියෙන ස</abstract_si>
      <abstract_mt>Ħidma reċenti dwar il-problem a tat-tagħlim latenti tas-siġar ippermettiet it-taħriġ tan-netwerks newrali li jitgħallmu kemm janalizzaw sentenza kif ukoll jużaw l-analiżijiet li jirriżultaw biex jinterpretaw is-sentenza, kollha mingħajr espożizzjoni għas-siġar tal-analiżijiet tal-verità tal-art waqt it-taħriġ. Bħala sorpriża, dawn il-mudelli ta’ spiss iwettqu kompiti ta’ fehim aħjar fis-sentenzi minn mudelli li jużaw siġar tal-ipproċessar minn analizzaturi konvenzjonali. Dan id-dokument għandu l-għan li jinvestiga x’jitgħallmu dawn il-mudelli latenti ta’ tagħlim tas-siġar. Aħna nirreplikaw żewġ mudelli bħal dawn f’bażi ta’ kodiċi kondiviża u nsibu li (i) wieħed biss minn dawn il-mudelli jaqbeż il-mudelli konvenzjonali strutturati fuq is-siġar dwar il-klassifikazzjoni tas-sentenzi, (ii) l-istrateġiji tal-analiżi tiegħu mhumiex konsistenti b’mod speċjali fil-bidu mill-ġdid każwali, (iii) l-analiżijiet li jipproduċi għandhom it-tendenza li jkunu aktar baxxi mill-analiżijiet standard Penn Treebank ( ) u (iv) ma jixbħux lil dawk ta’ PTB jew kwalunkwe formaliżmu semantiku jew sintetiku ieħor li l-awturi jkunu konxji minnu.</abstract_mt>
      <abstract_mk>Неодамнешната работа на проблемот со тајното учење на дрвјата овозможи обука на невровните мрежи кои учат да анализираат реченица и да ја користат резултатната анализира за да ја интерпретираат реченицата, сите без изложеност на дрвјата на анализирање на земјата во време на обуката. Изненадувачки, овие модели честопати изведуваат подобри задачи за разбирање на речениците отколку модели кои користат анализирање дрвја од конвенционални анализатори. Оваа хартија има за цел да истражи што научуваат овие тајни модели за учење дрва. Ние репликираме два вакви модели во заедничка кодова база и откриваме дека (i) само еден од овие модели ги надминува конвенционалните дрвја-структурирани модели на класификацијата на речениците, (ii) нејзините стратегии за анализирање не се особено константни во случајните рестартирања, (iii) анализите кои ги произведува се пониски од стандардните анализи И (iv) тие не се слични на оние на ПТБ или на било кој друг семантичен или синтактички формализам за кој авторите се свесни.</abstract_mk>
      <abstract_so>Shaqo ku saabsan arimaha la xiriira barashada geedka ee ugu dambeeyay waxaa suurtagal ah in lagu baro shabakado neuro ee barta labada dhinac iyo in lagu isticmaalo baaritaanka sababtiisa si uu u turjumo qoraalka, dhammaantood iyadoon cadeyn geedaha baarlamaanka ee dhulka ee runta ah xilliga waxbarashada. Si la yaab leh, tusaalahan inta badan waxey si ka fiican u sameeyaan shaqada waxyaabaha lagu garto garsooridda, sida tusaale ahaan geedaha baarlamaanka laga isticmaalo jardiinada caadiga ah. Warqaddan waxey ku qoran tahay baaritaanka qaababka barashada geedkan ugu dambeeya. Waxaan labada noocyo oo kale ku bedelaynaa qoraal qeyb ah, waxaana ka helaynaa (i) mid ka mid ah tusaalooyinkaas oo ku saabsan fasaxa qoraalka, ii) qorshaha baarlamayaasha baaritaanku ma ahan si gaar ah oo ay u leedahay dib u bilaabashada cayiman, (iii) kaniisada ay soo bixiso waa mid ka yar yihiin jardiinada caadiga ah ee Penn Treebank (PTB),  and (iv) they do not resemble those of PTB or any other semantic or syntactic formalism that the authors are aware of.</abstract_so>
      <abstract_ml>Recent work on the problem of latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time.  അത്ഭുതപ്പെടുന്നു, ഈ മോഡലുകള്‍ പലപ്പോഴും വാക്കുകളില്‍ ചെയ്യുന്നതിനെക്കാള്‍ നല്ല ജോലികള്‍ പ്രവര്‍ത്തിക്കുന്നു. പാ ഈ പേപ്പറിന്റെ ലക്ഷ്യമാണ് ഈ അവസാന വൃക്ഷത്തില്‍ പഠിക്കുന്നത് എന്താണെന്ന് അന്വേഷിക്കാന്‍. നമ്മള്‍ രണ്ടു ഇങ്ങനെയുള്ള മോഡലുകള്‍ പങ്കുചേര്‍ക്കുന്ന കോഡെബാസില്‍ പകര്‍ത്തുന്നു. ഈ മോഡലുകളില്‍ ഒന്ന് മാത്രം (I) വാക്ക് ക്ലാസ്ഫിക്ഷനില്‍ സാധാരണ വൃക്ഷത്തിലുള്ള മോഡലുകള്‍ പ്രവര്‍ത്തിക്കുന്നു; (i i) അത എഴുത്തുകാര്‍ക്ക് അറിയാവുന്ന പിടിബിയിലെയോ മറ്റൊരു സെമാന്റിക്കോ സിന്റാക്റ്റിക്കോ ഫോര്‍മാലിസ്റ്റിക്ക് സംവി</abstract_ml>
      <abstract_sv>Nyligen arbetat med problemet med latent trädinlärning har gjort det möjligt att träna neurala nätverk som lär sig att både tolka en mening och använda den resulterande tolkningen för att tolka meningen, allt utan exponering för marksanning parse träd vid träningstid. Överraskande nog presterar dessa modeller ofta bättre på meningsförståelseuppgifter än modeller som använder parseträd från konventionella parsrar. Denna uppsats syftar till att undersöka vad dessa latenta trädinlärningsmodeller lär sig. Vi replikerar två sådana modeller i en delad kodbas och finner att (i) bara en av dessa modeller överträffar konventionella trädstrukturerade modeller när det gäller meningsklassificering, (ii) dess tolkningsstrategier är inte särskilt konsekventa över slumpmässiga omstart, (iii) tolkningarna som den producerar tenderar att vara lägre än vanliga Penn Treebank (PTB)-tolkningar, och (iv) de liknar inte PTB eller någon annan semantisk eller syntaktisk formalism som författarna är medvetna om.</abstract_sv>
      <abstract_ms>Kerja baru-baru ini mengenai masalah pembelajaran pepohonan tersembunyi telah memungkinkan untuk melatih rangkaian saraf yang belajar untuk hurai kalimat dan menggunakan hurai hasil untuk menerangkan kalimat, semua tanpa terdedah kepada pepohonan hurai kebenaran tanah pada masa latihan. Kejutan sekali, model ini sering melakukan tugas pemahaman kalimat yang lebih baik daripada model yang menggunakan hurai pepohonan dari hurai konvensional. Kertas ini bermaksud untuk menyelidiki apa yang model belajar pokok tersembunyi ini belajar. Kami mereplikasikan dua model tersebut dalam pangkalan kod terkongsi dan mencari bahawa (i) hanya salah satu model ini melampaui model konvensional struktur pokok pada klasifikasi kalimat, (ii) strategi penghuraiannya tidak terutama konsisten dalam permulaan semula rawak, (iii) penghuraian yang i a hasilkan cenderung untuk lebih rendah daripada penghuraian piawai Penn Treebank (PTB), Dan (iv) mereka tidak mirip dengan PTB atau mana-mana formalisme semantik atau sintaktik lain yang diketahui oleh penulis.</abstract_ms>
      <abstract_no>Nyleg arbeidet på problemet med latent trelæring har gjort det mogleg å trenja neuralnettverk som lærer både å tolka eit setning og bruka den resultatet tolkinga for å tolka setninga, alle utan eksponering til grunnsannheten tolka tre ved treningstid. Desse modelane gjer ofte bedre ved setninga å forstå oppgåver enn modeller som brukar tolking av tre frå konvensjonale tolkar. Denne papiret må undersøkja kva desse latente trelæringsmodelane lærer. Vi kopierer to slike modeller i ein delt kodebase og finn at i) berre ein av desse modelane utfører konvensjonelle tre-strukturerte modeller på setningsklassifikasjon, ii) analyserstrategiane er ikkje spesielt konsistent i tilfeldige omstartar, iii) tolkingane han produserer vanlegvis er sålare enn standardtranslar av Penn Treebank (PTB), og iv) dei er ikkje liknande med PTB eller andre semantiske eller syntaktiske formalisme som utviklarane er kjent på.</abstract_no>
      <abstract_sr>Nedavno je rad na problemu latentnog učenja drveta omogućio da obučava neuralne mreže koje nauče da analiziraju rečenicu i koriste rezultatnu analizu da interpretiraju rečenicu, sve bez izloženosti zemaljskoj istini da analiziraju drveće na treningu. Iznenađujuće, ovi modeli često čine bolje u razumijevanju rečenica nego modeli koji koriste analizu drveta od konvencionalnih parsera. Ovaj papir ima cilj da istraži šta ovi latentni modeli učenja drveta nauče. Duplikujemo dva takva modela u zajedničkoj kodnoj bazi i otkrijemo da i) samo jedan od ovih modela iznosi konvencionalne modele na klasifikaciji rečenica, ii) njene strategije za analizu nisu posebno konsekventne na slučajnim ponovnim početkama, iii) analizu koje proizvodi su tendencije da su plići od standardnih analize Penn Treebank (PTB), i iv) ne sliči na PTB-ove ili bilo kakve druge semantičke ili sintaktičke formalizme koje autori znaju.</abstract_sr>
      <abstract_ur>لیٹینٹ درخت کی تعلیم کے مسئلہ پر اچھا کام کیا گیا ہے کہ نئورل نیٹورک کی تعلیم کرنا امکان رکھتا ہے جو ایک جماعت کو پارس کرنا سکتے ہیں اور نتیجہ پارس کا استعمال کرتا ہے کہ کلمہ تعلیم کرنا چاہے، سب کو بغیر زمین-حقیقت کے درختوں کو تربیت تعجب ہوتا ہے کہ یہ موڈل اغلب کلمز کے بارے میں بہتر کام کرتے ہیں جو موڈل سے کام سمجھنے سے بہتر کام کرتے ہیں جو معمولی پارس سے درختوں کا پارس استعمال کرتے ہیں۔ یہ کاغذ کا مطابق ہے کہ ان لٹینٹ درخت کی تعلیم مدل کیا سیکھیں۔ ہم ایک مشترک کوڈ بنسس میں دو ایسے موڈل کو دوبارہ دفع کرتے ہیں اور یہ دیکھتے ہیں کہ یہ موڈل میں سے صرف ایک ایسی موڈل جو مجلس کلاسیفوں پر منطقی درخت ساختہ موڈل کرتی ہے، i i) اس کا پارسینگ استراتژی مخصوصاً تصادفی آغاز کے بارے میں مشترک نہیں ہے، iii) پارسینز جو اس کے پیدا کرتا ہے اس سے زیادہ کم ہوتا ہے۔ اور (iv) وہ PTB کے افراد کے برابر نہیں ہیں اور نہ کسی دوسری سیمانتیک یا سینٹکتیک فرمولیسم کے برابر ہیں جو لکھنے والے جانتے ہیں۔</abstract_ur>
      <abstract_ta>சமீபத்தில் மரத்தில் கற்றுக் கொள்ளும் பிரச்சனையில் தற்போதைய வேலை செய்திருக்கிறது பயிற்சிக்கும் புதிய வலைப்பின்னல்களை பயிற்சி செய்து வாக்க ஆச்சரியமாக, இந்த மாதிரிகள் வழக்கமான பார்ச்சர்களில் இருந்து பார்ச் மரங்களை பயன்படுத்தும் மாதிரிகளை விட சிறந்த வாக இந்த காகிதம் இந்த சமீபத்தில் மரத்தை கற்றுக் கொள்ளும் மாதிரிகளை ஆய்வு செய்யும். நாம் இரண்டு போன்ற மாதிரிகளை பகிர்ந்த குறியீட்டில் மாற்றுகிறோம் மற்றும் இந்த மாதிரிகளில் ஒருவன் மட்டும் வாக்கு வகைப்பில் வழக்கமான மரம் அமைப்பு மாதிரிகளை செயல்படுத்துகிறது என்பதை கண்டுபிடி எழுத்தாளர்கள் தெரிந்து கொண்டிருக்கும் பிடிபி அல்லது மற்ற எந்த ஒத்திசைவு அல்லது ஒத்திசைவு வடிவமைப்பு போன்றவில்லை.</abstract_ta>
      <abstract_uz>Yaqinda ochiq daraxt o'rganish muammolari yordamida yangi tarmoqni o'rganish mumkin va bir so'zni o'rganish va natijada so'zni o'rganish uchun ishlatish mumkin, hamma narsalarni o'rganish vaqtda o'rganish vaqtda hech qanday o'rganish mumkin. Bu modellar odatda o'sha paydo bo'lgan holatda o'rganish vazifalarini o'xshash ko'proq o'xshash bajaradi. Bu modellarni konstant parserdan foydalanish mumkin. Bu qogʻoz esa bu yangi daraxt o'rganish modellarini o'rganishni o'rganish mumkin. Biz bir necha modellarni birinchi o'zgartirib kelamiz va bu modellarning biri oddiy darajadagi darajadagi modellarni bajaradi, (i i) uning tashkilotlari takrorlanish strategiyasi oddiy raqamlarni boshlash imkoniyati emas, (iii) buning tashkilotlari andoza Penn Treebank (PTB) parchalaridan bir qismi bo'ladi, va bu mualliflar haqida o'rganilgan PTB yoki boshqa semantik yoki syntactic formatlariga mos kelmaydi.</abstract_uz>
      <abstract_vi>Việc nghiên cứu gần đây về vấn đề học tập trên các cây thần kinh đã làm cho phép huấn luyện các mạng lưới thần kinh học cách phân tích một câu và sử dụng phân tích kết quả để giải mã câu đó, tất cả đều không bị phơi nhiễm với thực tế mặt đất phân tích cây vào thời điểm huấn luyện. Ngạc nhiên là, những mẫu này thường làm tốt việc hiểu câu ở các công việc hơn những mẫu sử dụng căn cây của cha xứ thông thường. Mục tiêu của bài báo này là nghiên cứu những gì các mô hình ngầm này học. Chúng tôi tái tạo hai mẫu như vậy trong một mật mã chia sẻ và thấy rằng: i) chỉ một trong số những mẫu này vượt trội các mô hình cấu trúc cây thông thường về mức độ phân loại án, và (IV) chúng không giống với thứ của PTB hay bất cứ khái niệm hay dạng chính thức cú pháp mà các tác giả biết.</abstract_vi>
      <abstract_da>Nyligt arbejde med problemet med latent trælæring har gjort det muligt at træne neurale netværk, der både lærer at fortolke en sætning og bruge den resulterende fortolkning til at fortolke sætningen, alt sammen uden eksponering for jord-sandhed parse træer på træningstid. Overraskende nok fungerer disse modeller ofte bedre til sætningsforklaring opgaver end modeller, der bruger parsetræer fra konventionelle fortolkere. Denne artikel har til formål at undersøge, hvad disse latente trælæringsmodeller lærer. Vi replikerer to sådanne modeller i en fælles kodebase og finder ud af, at (i) kun en af disse modeller overgår konventionelle træstrukturerede modeller på sætningsklassificering, (ii) dens parsningsstrategier er ikke særligt konsekvente på tværs af tilfældige genstarter, (iii) de parses, den producerer, har tendens til at være lavere end standard Penn Treebank (PTB) parses, og (iv) de ligner ikke PTB's eller nogen anden semantisk eller syntaktisk formalisme, som forfatterne er opmærksomme på.</abstract_da>
      <abstract_nl>Recent werk over het probleem van latent tree learning heeft het mogelijk gemaakt om neurale netwerken te trainen die leren om zowel een zin te parsen als de resulterende parse te gebruiken om de zin te interpreteren, allemaal zonder blootstelling aan grond-truth parse bomen tijdens de training tijd. Verrassend genoeg presteren deze modellen vaak beter bij het begrijpen van zinnen dan modellen die parsen bomen van conventionele parsers gebruiken. Dit artikel wil onderzoeken wat deze latente boomleermodellen leren. We repliceren twee dergelijke modellen in een gedeelde codebase en vinden dat (i) slechts één van deze modellen overtreft conventionele boomgestructureerde modellen op zinsclassificatie, (ii) zijn parsing strategieën niet bijzonder consistent zijn bij willekeurige herstarts, (iii) de parses die het produceert zijn meestal ondieper dan standaard Penn Treebank (PTB) parses, en iv) zij lijken niet op die van PTB of enig ander semantisch of syntactisch formalisme waarvan de auteurs zich bewust zijn.</abstract_nl>
      <abstract_bg>Последната работа по проблема с латентното учене на дървета даде възможност да се обучават невронни мрежи, които се научават да анализират изречение и да използват получения анализ за интерпретиране на изречението, всичко това без излагане на основен анализ на дървета по време на тренировка. Изненадващо, тези модели често изпълняват по-добре задачи за разбиране на изречения, отколкото модели, които използват дървета за анализ от конвенционални анализатори. Настоящата статия има за цел да проучи какво научават тези латентни модели за учене на дървета. Репликираме два такива модела в споделена кодова база и откриваме, че (i) само един от тези модели превъзхожда конвенционалните дървесни структурирани модели при класификацията на изреченията, (ii) стратегиите му за анализ не са особено последователни при случайни рестартирания, (iii) анализите, които произвежда са склонни да бъдат по-плитки от стандартните анализи на Penn Treebank (PTB), и (iv) те не приличат на тези на ПТБ или друг семантичен или синтактичен формализъм, с който авторите са запознати.</abstract_bg>
      <abstract_hr>Posljednji rad o problemu latentnog učenja drveta omogućio je obučavati neuralne mreže koje nauče analizirati rečenicu i koristiti rezultatnu analizu da interpretiraju rečenicu, sve bez izlaganja zemaljskoj istini analizirati drveće na vrijeme obuke. Iznenađujuće, ovi modeli često čine bolje u razumijevanju rečenica nego modeli koji koriste analizu drveća od konvencionalnih parsera. Ovaj papir je cilj istražiti što ovi latentni modeli učenja drveta uče. Kopiramo dva takva modela u zajedničkoj kodnoj bazi i otkrijemo da i) samo jedan od ovih modela iznosi konvencionalne modele strukturirane drveće na klasifikaciji kazne, ii) njene strategije za analizu nisu posebno konsekventne u slučajnim ponovnim početkama, iii) analizu koje proizvodi tendencije biti plići od standardnih analize Penn Treebank (PTB), i iv) ne sliči na PTB-ove ili bilo kakve druge semantičke ili sintaktičke formalizme koje autori znaju.</abstract_hr>
      <abstract_id>Pekerjaan baru-baru ini mengenai masalah pembelajaran pohon latent telah memungkinkan untuk melatih jaringan saraf yang belajar untuk mengurai kalimat dan menggunakan penghuraian hasilnya untuk menerjemahkan kalimat, semua tanpa eksposisi ke pohon mengurai kebenaran tanah pada waktu latihan. Surprisingly, these models often perform better at sentence understanding tasks than models that use parse trees from conventional parsers.  Kertas ini bermaksud untuk menyelidiki apa yang model belajar pohon tersembunyi ini belajar. Kami mereplikasikan dua model tersebut dalam sebuah kodebas berbagi dan menemukan bahwa (i) hanya salah satu model ini melampaui model konvensional strukturasi pohon pada klasifikasi kalimat, (ii) strategi penghuraiannya tidak spesial konsisten di permulaan ulang acak, (iii) analisis yang diproduksi cenderung menjadi lebih rendah dari analisis standar Penn Treebank (PTB), Dan (iv) mereka tidak mirip dengan PTB atau formalisme semantis atau sintaks lainnya yang diketahui penulis.</abstract_id>
      <abstract_de>Jüngste Arbeiten zum Problem des latenten Baumlernens haben es ermöglicht, neuronale Netze zu trainieren, die lernen, sowohl einen Satz zu parsen als auch die resultierende Parse zur Interpretation des Satzes zu verwenden, und das alles ohne Kontakt mit Ground-Truth Parse Bäumen während des Trainings. Überraschenderweise sind diese Modelle oft besser beim Verstehen von Sätzen als Modelle, die Parse-Bäume aus herkömmlichen Parsern verwenden. In diesem Beitrag soll untersucht werden, was diese latenten Baumlernmodelle lernen. Wir replizieren zwei solcher Modelle in einer gemeinsamen Codebasis und stellen fest, dass (i) nur eines dieser Modelle herkömmliche baumstrukturierte Modelle bei der Satzklassifizierung übertrifft, (ii) seine Parsing-Strategien bei zufälligen Neustarts nicht besonders konsistent sind, (iii) die Parses, die es erzeugt, tendenziell flacher sind als Standard Penn Treebank (PTB) Parses, und iv) sie ähneln nicht denen der PTB oder einem anderen semantischen oder syntaktischen Formalismus, den die Autoren kennen.</abstract_de>
      <abstract_sw>Kazi za hivi karibuni kuhusu tatizo la kujifunza mti wa hivi karibuni imefanya uwezekano wa kufundisha mitandao ya kijamii ambazo hujifunza kujenga hukumu hiyo na kutumia bunge la matokeo la kutafsiri hukumu hiyo, yote bila ya kuonyesha mti wa magenge ya chini ya ardhi wakati wa mafunzo. Kwa kushangaza, mifano hii mara nyingi hufanya kazi nzuri zaidi ya kuelewa hukumu kuliko mifano inayotumia mti wa parge kutoka kwenye bunge la kawaida. Gazeti hili linakusudia kuchunguza mifano ya kujifunza kwa mti huu wa hivi karibuni. Tunaweza kubadilisha mifano miwili kama hizi katika kurasa ya ushirikiano na kuona kuwa (I) moja tu ya mifano hii inaonyesha mifano ya miti ya kawaida ya kutengenezwa kwa mti wa a in a hiyo katika kutangaza hukumu, (i i) mikakati yake ya ubaguzi hayajafananisha zaidi ya viungo vya Penn Treebank (PTB), na (iv) hawafananiwi na wale wa PTB au utaratibu wowote wa kisiasa au ushirikiano ambao waandishi wanafahamu.</abstract_sw>
      <abstract_ko>최근 잠재적 트리 학습 문제에 대한 연구로 훈련 신경 네트워크가 가능해졌다. 이런 신경 네트워크는 해석 문장을 배울 수도 있고 해석 결과를 사용하여 문장을 해석할 수도 있다. 이 모든 것은 훈련할 때 지면 진가 해석 트리에 접촉할 필요가 없다.놀랍게도 이 모델들은 통상적으로 문장 이해 임무에서 전통 해석기의 해석 트리를 사용하는 모델보다 더 잘 표현된다.본고는 이러한 잠재적 나무 학습 모델의 학습 내용을 연구하는 데 목적을 두고 있다.우리는 공유된 코드 라이브러리에서 두 개의 이런 모델을 복제했는데 (i) 이 모델 중 하나만 문장 분류에 있어서 전통적인 트리 구조 모델보다 우수하다는 것을 발견했다. (ii) 그 해석 전략은 무작위로 다시 시작할 때 특별히 일치하지 않는다. (iii) 이 발생하는 해석은 표준 Penn Treebank(PTB)보다 얕다.(iv) PTB 또는 작성자가 아는 다른 의미나 구문 형식주의와 비슷하지 않습니다.</abstract_ko>
      <abstract_fa>کارهای اخیرا روی مشکل یادگیری درخت تاریخی ممکن است شبکه‌های عصبی را آموزش دهد که در زمان آموزش یاد می‌گیرند که هر دو یک جمله را پاره‌سازی کنند و از پاره‌سازی نتیجه‌ای برای تعبیر کردن جمله استفاده کنند، همه بدون توضیح به حقیقت زمین درخت تعجب کننده است، این مدلها اغلب در مجازات بهتر عمل می کنند تا از مدلها که از درخت‌های پراکنده‌های سنتی استفاده می‌کنند. این کاغذ هدف دارد تا تحقیق کنید که این مدل یادگیری درخت لاتین چی یاد می گیرند. ما دو مدل چنین را در یک پایگاه کد مشترک تکرار می‌کنیم و می‌بینیم که تنها یکی از این مدل‌ها از مدل‌های ساخته شده‌ی درخت‌های سنتی در کلیسازی جمله‌ها انجام می‌دهد، (i i) استراتژی‌های تجزیه‌کننده‌اش مخصوصا در دوباره‌ی بازگشت تصادفی مشترک نیستند، (iii) تجزیه‌هایی که تولید می‌کند، معمولاً از و (iv) آنها شبیه افرادی از PTB یا دیگر فرمولیسم سیمانتیک یا سینتیکی که نویسندگان می‌دانند نیستند.</abstract_fa>
      <abstract_sq>Recent work on the problem of latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time.  Për mrekulli, këto modele shpesh kryejnë më mirë në kuptimin e gjykimeve se modelet që përdorin pemë analizuese nga analizuesit konvencionalë. Kjo letër synon të hetojë se çfarë mësojnë këto modele të fshehta të mësimit të pemëve. We replicate two such models in a shared codebase and find that (i) only one of these models outperforms conventional tree-structured models on sentence classification, (ii) its parsing strategies are not especially consistent across random restarts, (iii) the parses it produces tend to be shallower than standard Penn Treebank (PTB) parses, dhe (iv) nuk ngjajnë me ato të PTB apo ndonjë formalizmi tjetër semantik apo sintaktik për të cilin autorët janë në dijeni.</abstract_sq>
      <abstract_af>Onlangse werk op die probleem van latent boom leer het dit moontlik gemaak om neurale netwerke te tren wat leer om beide 'n seting te ontleer en die resultaat verwerking te gebruik om die seting te interpreteer, almal sonder uitwerking tot grond-waarheid te verwerk bome by onderwerp tyd. Onverwonderbaar, hierdie modele doen dikwels beter by setnings verstaan opdragte as modele wat verwerking bome gebruik van konvensionele verwerkers. Hierdie papier bepaal om te ondersoek wat hierdie latente boom leer modele leer. Ons kopieer twee sodanige modele in 'n gedeelde kodebasse en vind dat (i) slegs een van hierdie modele uitvoer konvensionele boom-struktureerde modele op sentence klasifikasie, (ii) sy verwerking strategies is nie veral bestaan onder willekeurige herbegin nie, (iii) die verwerking wat dit produseer het, tendig om te wees swaar as standaard Penn Treebank (PTB) verwerking, en (iv) hulle vergelyk nie soos die van PTB of enige ander semantiese of sintaktiese formalisme wat die outeurs bevestig is nie.</abstract_af>
      <abstract_tr>Soňky agaç öwrenmesiniň meselesinde ýakyn işleýän işiň hem sözlemi parslamak üçin öwrenip, netijeli sözlemi terjime etmek üçin paýlaşmagy mümkin etdi. Gurhal hasaplançylar üçin bu nusgalar sözlemlerde işlerini düşünýän nusgalardan köplenç gowy edip bilýärler. Bu kagyz şu soňky agaç öwrenmek nusgalarynyň öwrenmesini barlamak maksady. Biz bu iki nusgasyny paylaşyk kodeýasynda kopyaladyrys we şuny tapdyrys: i) diňe bu nusgalaryň biri sözleriň klasifikasynda adalat agaç strukturlydyr nusgasynda däl, (ii) parsleme strategiýasy çapda täsirli başlangıçda däldir, (iii) onuň üretýän analysiýasy Penn Treebank (PTB) analysiýasyndan has däldir. we (iv) awtorlaryň bilýän PTB ýa-da bir semantik ýa-da syntaktik formalismi meňzeýärler.</abstract_tr>
      <abstract_hy>Վերջերս ծառերի թաքնված ուսումնասիրության խնդիրը հնարավորություն է տալիս ուսուցանել նյարդային ցանցեր, որոնք սովորում են նախադասություն վերլուծել և օգտագործում են արդյունքում ստացված վերլուծությունը նախադասությունը մեկնաբանելու համար, բոլորը առանց արտահայտության հողի ճշմարտության վերլու Զարմանալի է, որ այս մոդելները հաճախ ավելի լավ են աշխատում նախադասությունների ընկալում, քան մոդելները, որոնք օգտագործում են սովորական վերլուծումների ծառերը: Այս աշխատանքը նպատակն է ուսումնասիրել, թե ինչ են սովորում այս թաքնված ծառերի ուսումնասիրության մոդելները: We replicate two such models in a shared codebase and find that (i) only one of these models outperforms conventional tree-structured models on sentence classification, (ii) its parsing strategies are not especially consistent across random restarts, (iii) the parses it produces tend to be shallower than standard Penn Treebank (PTB) parses, Նրանք չեն նման ՀՏԲ-ի կամ այլ սեմանտիկ կամ սինտակտիկ ֆորմալիզմի, որի մասին հեղինակները գիտակցում են:</abstract_hy>
      <abstract_az>Sonrakı a ğac öyrənməsinin problemlərində son işi hər ikisinin cümləni ayırmaq öyrənməsini öyrənən nöral ağaclarını təhsil etmək və sonuçlarını təhsil etmək üçün təhsil etmək üçün istifadə etdi, hamısı təhsil vaxtında təhsil olunan ağacları təhsil etmədən. Bu modellər çox təəccüblü cümlələrdə işləri anlamaqdan daha yaxşı işlər edirlər. Bu kağıt bu son ağac öyrənmə modellərinin nəyi öyrəndiyini incitmək istəyir. Biz bu iki modeli paylaşılmış kodu basesində replikləyirik və bu modellərdən yalnız i) cümlələr klasifikasyonu üzərində standart a ğac strukturlı modellərdən daha çox yapışır, ii) analiz stratejiləri təsirli yenidən başlamaq üçün müəyyən edilməz, iii) analizi ürəklərinin standart Penn Treebank (PTB) analizindən daha çox çətin olar. Və onlar PTB və yazıcıların bildiyi bir semantik və sintaktik formalism ə bənzəymirlər.</abstract_az>
      <abstract_ca>Recent work on the problem of latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time.  Sorprenentment, aquests models sovint desempenyen millors tasques de comprensió de frases que models que utilitzen arbres d'analitzadors convencionals. Aquest paper té l'objectiu d'investigar el que aprenen aquests models latents d'aprenentatge d'arbres. Reproduim dos models d'aquest tipus en una base de codi compartida i descobrim que (i) només un d'aquests models supera els models convencionals estructurats en arbres en la classificació de frases, (ii) les seves estratègies d'analització no són especialment consistents a través de reaniciacions aleatòries, (iii) les analitzacions que produeix tendeixen a ser més baixes que les normalitzacions de Penn Treebank (PTB), i iv) no s'assemblen a aquells de PTB ni a qualsevol altre formalisme semàntic o sinàctic que els autors coneixen.</abstract_ca>
      <abstract_am>በቅርብ ጊዜ የዛፍ ትምህርት መግለጫ ላይ የሚደረገውን ሥራ የነዌብ መረቦችን ክፍል ማግኘት እና የውይይት ፓርቲውን ለመተርጓም የሚችሉትን የሥርዓቱን ማግኘት ማግኘት ማግኘት እንዲችል አግኝቷል፡፡ በተደናቂው፣ እነዚህ ምሳሌዎች ብዙ ጊዜ ከሕግ ፓርላማ ዛፎች ከመጠቀም በሚጠቀም ምሳሌዎች የሚሻሉትን በማስተዋል ስራዎችን በማስተዋል ይሠራሉ፡፡ ይህች ገጽ የቀድሞው ዛፍ የትምህርት ምሳሌዎች ምን እንደተማሩ ሊመርምር ነው፡፡ ሁለት ዓይነቶች በተለያዩ ኮድባብ ውስጥ እናስገዛለን (I) ከእነዚህ ዓይነቶች አንዱ ብቻ የሥርዓት ዛፍ-አካባቢ ዓይነቶችን በተለየ ክፍል ማሳየት ነው፣ (i i) የፓርቲው ዘለላዎች በተለየ ፍጥረት ማሳየት አይደሉም፣ (iii) የፓርላማ ፓርላማ ከዓላማ ፓርላማ ፕቴን ቲብክ (PTB) ፓርላማ ላይ ጥሩ ነው፡፡ እናም (iv) ጸሐፊዎቹ የሚያውቁትን PTB ወይም ሌሎችን የsemantic ወይም Syntactic formalism አይመስሉም፡፡</abstract_am>
      <abstract_bn>সম্প্রতি সাম্প্রতিক গাছ শিক্ষার সমস্যার কাজ সম্ভাবনা করেছে যে নিউরুল নেটওয়ার্ক প্রশিক্ষণ করতে পারে যারা দুজনের কারাদণ্ড পার্স শিক্ষা প্রদান করতে শিখেছে এবং  Surprisingly, these models often perform better at sentence understanding tasks than models that use parse trees from conventional parsers.  এই কাগজের লক্ষ্য হচ্ছে এই সাম্প্রতিক গাছ শিক্ষা মডেল কি শিখেছে। আমরা শেয়ার করা কোডেবাসে দুটি মডেল প্রতিস্থাপন করি এবং পাই যে এই মডেলের মধ্যে কেবল একটি সাধারণ গাছের কাঠামো মডেল ব্যবহার করে, (২) এর পার্জিং কৌশল বিশেষ করে বিভিন্ন রিসার্ট শুরু করা যায় না, (আই) পার্সের প্যারেসে এবং (আই) তারা পিটিবি বা অন্যান্য সেম্যান্টিক বা সিন্ট্যাক্টিক্যালিজমের মত নয় যারা লেখকদের সম্পর্কে জানে।</abstract_bn>
      <abstract_cs>Nedávná práce na problému latentního učení stromů umožnila trénovat neuronové sítě, které se naučí jak analyzovat větu, tak používat výslednou parsu k interpretaci věty, a to vše bez vystavení pozemním parsovacím stromům v době tréninku. Překvapivě tyto modely často fungují lépe při porozumění větám než modely, které používají parsování stromů z konvenčních parserů. Tento článek si klade za cíl zkoumat, co se tyto modely učení latentních stromů naučí. Replikujeme dva takové modely ve sdílené kódové bázi a zjišťujeme, že (i) pouze jeden z těchto modelů překoná konvenční stromově strukturované modely na klasifikaci vět, (ii) jeho analýzy nejsou zvláště konzistentní při náhodných restartech, (iii) parsy, které produkuje, mají tendenci být mělké než standardní parsy Penn Treebank (PTB), a iv) nepodobují PTB ani žádnému jinému sémantickému či syntaktickému formalismu, kterého si autoři uvědomují.</abstract_cs>
      <abstract_bs>Nedavno je rad na problemu latentnog učenja drveta omogućio da obučava neuralne mreže koje nauče da analiziraju rečenicu i koriste rezultatnu analizu da interpretiraju rečenicu, sve bez izloženosti zemaljskoj istini analiziraju drveće na treningu. Iznenađujuće, ovi modeli često čine bolje u razumijevanju rečenica nego modeli koji koriste analizu drveta od konvencionalnih parsera. Ovaj papir ima cilj da istraži šta ovi latentni modeli učenja drveta uče. Kopiramo dva takva modela u zajedničkoj kodnoj bazi i otkrivamo da i) samo jedan od ovih modela iznosi konvencionalne modele strukturirane drveće na klasifikaciji rečenica, ii) njene strategije za analizu nisu posebno konsekventne u slučajnim ponovnim početkama, iii) analizu koje proizvodi su tendencije da su plići od standardnih analize Penn Treebank (PTB), i iv) ne sliči na PTB-ove ili bilo kakve druge semantičke ili sintaktičke formalizme koje autori znaju.</abstract_bs>
      <abstract_et>Hiljutine töö latentse puuõppe probleemiga on võimaldanud treenida närvivõrke, mis õpivad nii lause parsimist kui ka tulemuslikku parsimist lause tõlgendamiseks, kõik ilma kokkupuuteta maapinna tõde parsimise puudega treeningu ajal. Üllataval kombel toimivad need mudelid sageli lause mõistmise ülesannetes paremini kui mudelid, mis kasutavad tavapäraste parserite parsimispuid. Käesoleva töö eesmärk on uurida, mida need latentsed puuõppemudelid õpivad. Me kopeerime kaks sellist mudelit jagatud koodibaasis ja leiame, et i) ainult üks neist mudelitest on lauseklassifitseerimisel üle tavapäraste puustruktuuriliste mudelite, (ii) selle parsimisstrateegiad ei ole juhuslike taaskäivitamiste puhul eriti järjepidevad, (iii) selle parsimised kipuvad olema madalamad kui standardsed Penn Treebanki (PTB) parsimised, ja (iv) need ei sarnane PTB või muu semantilise või süntaktilise formalismi omadega, millest autorid on teadlikud.</abstract_et>
      <abstract_fi>Hiljattain tehty työ piilevän puun oppimisen ongelmasta on mahdollistanut neuroverkkojen kouluttamisen, jotka oppivat sekä jäsentämään lauseen että tulkitsemaan lausetta, kaikki ilman altistumista ground-truth parse puille harjoittelun aikana. Yllättävää kyllä nämä mallit suoriutuvat usein paremmin lauseiden ymmärtämisessä kuin mallit, jotka käyttävät perinteisen parsin parsauspuita. Tämän artikkelin tavoitteena on selvittää, mitä nämä piilevät puuoppimismallit oppivat. Replikoimme kaksi tällaista mallia yhteisessä kooditietokannassa ja havaitsimme, että (i) vain yksi näistä malleista suoriutuu lauseiden luokittelussa perinteisiä puurakenteisia malleja paremmin, (ii) sen jäsennysstrategiat eivät ole erityisen johdonmukaisia satunnaisissa uudelleenkäynnistyksissä, (iii) sen tuottamat jäsennykset ovat yleensä matalampia kuin standardit Penn Treebank (PTB) -jäsennykset, ja (iv) ne eivät muistuta PTB:n tai minkään muun semanttisen tai syntaktisen formalismin, jonka kirjoittajat ovat tietoisia.</abstract_fi>
      <abstract_jv>Tool Options, Layersdock Awak dhéwé, model iki dadi sing ngomong nik akeh luwih apik batasan gagal karo model sing bisa ngelarane perusahaan karo perusahaan karo perusahaan Awak dhéwé iki lak ngerasakno sing model kuwi nggawe. We duplicate 2 like modeles in a shared kodbaz and find that (i) only one of this modes out of the prattribution of the Traditional jelly-structural modeles on a word CLASCIPATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATIKATI INCOMPATIKATIKATIKATIKATIKATIKATIKATIKATIKATI INCOMPATIKATIKATIKA lan</abstract_jv>
      <abstract_ha>Taimar aiki na ƙarami a kan matsalar da aka karanta na it ãcen kwanan nan, ya kamata ta iya ƙidãya wa zantarakin neural waɗanda za su iya yin cũtar da su duk birane kuma su yi amfani da parse ta fassarar da fassarar, dukansu bã da bayani ga parse-gaske a lokacin da za'a yi amfani da shi. Ina yi mãmãki, waɗannan misãlai ko da yawa su aikata mafiya alhẽri a cikin aikin kunnuwa na gareshi ko misãlai da ke amfani da itãcen parse daga mazaɓa mai kawaici. Wannan takardan na aimar ya yi tambayi abin da waɗannan misãlai na karanta na itãce na ƙarshen. Mu musanya misalin biyu kamar wannan a cikin kode da ke haɗa, kuma munã sãmu (i) kawai ɗayan waɗannan misãlai na samar da misãlai masu tsari na it ãce a dangantar da shi a kan fassarar azãba, (ii) ma'anar musammakinsa ba su zama daidai a kowace ta fara ranar da rana, (i) parse da ke samu da shi ya yi ƙaranci ko bada parse na Penn Treebank (PTB), kuma ba su daidaita da wasu mutane na PTB ko wani abu wanda marubuci na sani ba.</abstract_ha>
      <abstract_sk>Nedavno delo na problemu latentnega učenja dreves je omogočilo usposabljanje nevronskih omrežij, ki se naučijo razčlenjevati stavek in uporabljati nastalo razčlenjevanje stavka za interpretiranje stavka, vse brez izpostavljenosti zemeljskemu razčlenjevanju dreves v času treninga. Presenetljivo je, da so ti modeli pogosto boljši pri razumevanju stavkov kot modeli, ki uporabljajo razčlenjevanje dreves iz običajnih razčlenjevalnikov. Namen prispevka je raziskati, kaj se ti latentni modeli učenja dreves naučijo. Ponovimo dva takšna modela v skupni kodni bazi in ugotovimo, da (i) le eden od teh modelov presega običajne drevesne strukturirane modele pri klasifikaciji stavkov, (ii) njegove strategije razčlenitve niso posebej skladne pri naključnih ponovnih zagonih, (iii) razčlenitve, ki jih proizvaja, so običajno plitvejše od standardnih razčlenitve Penn Treebank (PTB), in (iv) ne spominjajo na PTB ali katerega koli drugega semantičnega ali sintaktičnega formalizma, ki ga avtorji poznajo.</abstract_sk>
      <abstract_he>העבודה האחרונה על הבעיה של לימוד עצים מוסתרים אפשרה לאמן רשתות עצביות שלמדות לאבד משפט ולהשתמש באבדוק הנוצא כדי לפרש את המשפט באופן מפתיע, דוגמנים אלה לעתים קרובות פועלים טוב יותר במשימות הבנה משפטים מאשר דוגמנים שמשתמשים בעצים מפרסמים קונבנציונאליים. העיתון הזה מכוון לחקור מה דוגמנים ללמוד עצים מוסתרים אלה לומדים. אנחנו משכפלים שני דוגמנים כאלה בבסיס קוד משותף ומוצאים כי (i) רק אחד מהדוגמנים האלה מופעים מודלים מובנים עצים קונבנציונציוניים על מסגרת משפטים, (ii) אסטרטגיות המחקר שלה אינן במיוחד תואמות בין התחלות אקראיות מחדש, (iii) המחקרים שהוא מייצר נוטים להיות גבוהים יותר מאשר הפרסים הסטנדרטיים Penn Treebank (iv) הם לא דומים לאלה של PTB או כל פורמליזם סמנטי או סינטקטי אחר שהסופרים מודעים אליו.</abstract_he>
      <abstract_bo>ཉེ་ཆར་མ་དེ་ལྟ་བུའི་རིང་ཚང་གི་དཀའ་ངལ་སྤེལ མཁའ་མ་བསམ་བར། མིག་ལམ་འདི་དག་གིས་ཚིག་ལས་སྤྱོད་པའི་རྣམ་པ་ལས་ཚོར་བ་ཐད་ཚོར་བ་ཟབ་པ་ལས། ཤོག་བྱང་འདིས་མཐའ་མའ་གི་དབྱིབས་སློབ་པའི་རྣམ་པ་ཚོས་ག་རེ་བསམ་བློ་གཏོང་དང་། ང་ཚོས་དབྱེ་བ་གཅིག་མཐུན་པའི་རྣམ་གྲངས་འདིའི་མིག་ལམ་གཉིས་མཉམ་དུ་བསྡུར་བ་ཞིག་ཏེ། ཡིན་ན།</abstract_bo>
      </paper>
    <paper id="20">
      <title>Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora</title>
      <author><first>Andrius</first><last>Mudinas</last></author>
      <author><first>Dell</first><last>Zhang</last></author>
      <author><first>Mark</first><last>Levene</last></author>
      <doi>10.1162/tacl_a_00020</doi>
      <abstract>There is often the need to perform sentiment classification in a particular domain where no labeled document is available. Although we could make use of a general-purpose off-the-shelf sentiment classifier or a pre-built one for a different domain, the effectiveness would be inferior. In this paper, we explore the possibility of building domain-specific sentiment classifiers with unlabeled documents only. Our investigation indicates that in the word embeddings learned from the unlabeled corpus of a given domain, the distributed word representations (vectors) for opposite sentiments form distinct clusters, though those clusters are not transferable across domains. Exploiting such a clustering structure, we are able to utilize <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> to induce a quality domain-specific sentiment lexicon from just a few typical sentiment words (seeds). An important finding is that simple linear model based supervised learning algorithms (such as linear SVM) can actually work better than more sophisticated semi-supervised / transductive learning algorithms which represent the state-of-the-art technique for sentiment lexicon induction. The induced lexicon could be applied directly in a lexicon-based method for sentiment classification, but a higher performance could be achieved through a two-phase bootstrapping method which uses the induced lexicon to assign positive / negative sentiment scores to unlabeled documents first, a nd t hen u ses those documents found to have clear sentiment signals as pseudo-labeled examples to train a document sentiment classifier v ia supervised learning algorithms (such as LSTM).</abstract>
      <pages>269–285</pages>
      <url hash="ef8bb85c">Q18-1020</url>
      <bibkey>mudinas-etal-2018-bootstrap</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    <title_ar>مصنّفات المشاعر الخاصة بنطاق Bootstrap من Corpora غير المسماة</title_ar>
      <title_es>Clasificadores de opinión específicos de dominio Bootstrap de Corpora sin etiqueta</title_es>
      <title_pt>Classificadores de sentimento específicos de domínio do Bootstrap de Corpora não rotulados</title_pt>
      <title_fr>Classificateurs de sentiment spécifiques au domaine Bootstrap à partir de corpus non étiquetés</title_fr>
      <title_ja>ラベル付けされていないCorporaからのBootstrapドメイン固有のセンチメント分類子</title_ja>
      <title_zh>未识语料库导域特定情类器</title_zh>
      <title_ru>Классификаторы настроений, специфичные для домена Bootstrap, из немаркированных тел</title_ru>
      <title_hi>बूटस्ट्रैप डोमेन-विशिष्ट भावना क्लासिफायर्स अनलेबल कॉर्पोरेट से</title_hi>
      <title_ga>Aicmitheoirí Mothúcháin a Bhaineann go Sonrach le Fearainn Bootstrap ó Corpora Gan Lipéad</title_ga>
      <title_ka>კლასიფიერები საქაღალდე- სპეციფიკალური სენტიმენტის კლასიფიერები უცნობილი კოპორადან</title_ka>
      <title_el>Κατηγοριοποιητές συναισθημάτων ειδικά για τομέα από το Χωρίς ετικέτα Corpora</title_el>
      <title_hu>Bootstrap Domain-Specifikus Sentiment Classifiers from Unlabel Corpora</title_hu>
      <title_it>Bootstrap Domain-Specific Sentiment Classifiers from Unlabel Corpora</title_it>
      <title_kk>Құрылмаған корпорасының доменге белгіленген Sentiment классификаторлары</title_kk>
      <title_lt>Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora</title_lt>
      <title_mk>Класификатори на чувства специфични за домен од Необележана корпора</title_mk>
      <title_ml>ബുട്ട്സ്ട്രാപ്പ് ഡൊമെയിന്‍ - പ്രത്യേക സെന്റിമെന്‍റ് ക്ലാസിക്കല്‍സ്</title_ml>
      <title_mt>Klassifikaturi tas-Sentiment Speċifiċi għad-Domain Bootstrap minn Korpora Mhux Tikkettata</title_mt>
      <title_ms>Klasifikasi Sentimen Khusus Domain Bootstrap dari Corpora Tanpa Tanda Tanda</title_ms>
      <title_mn>Буутсtrap Domain-Specific Sentiment Classifiers from Unsabeled Corpora</title_mn>
      <title_no>Bootstrap- domenespesifiserte sentiseringsklassifikatorar frå ubeabelte korpora</title_no>
      <title_pl>Bootstrap Domain-Specific Sentiment Classifiers from Unlabel Corpora</title_pl>
      <title_ro>Bootstrap Domain-Specific Sentiment Classificatori de la Unlabel Corpora</title_ro>
      <title_sr>Sklapanje domena-specijalne sentimentne klasifikatore iz nezabelirane korpore</title_sr>
      <title_si>බුට්ස්ට්‍රැප් ඩොමේන්- විශේෂ සංවේදන ක්‍ලාසිෆාර්ස්</title_si>
      <title_sv>Bootstrap Domain-Specific Sentiment Classifiers från Unlabel Corpora</title_sv>
      <title_so>Bootbag-bookstrap Domain-Specific Senssifiers from Unlabeled Corpora</title_so>
      <title_ta>புத்தகக்குறிப்பிட்ட களம்- குறிப்பிட்ட அமர்வு வகைப்பாட்டாளர்கள்</title_ta>
      <title_ur>بٹٹسٹراپ ڈومین-مخصوص سنٹیمینٹ کلاسیفور غیرقابل کارپور سے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Ủng Da miền đặc biệt Bước phân tích từ Corpus</title_vi>
      <title_da>Bootstrap Domain-Specific Sentiment Classifiers fra Unlabel Corpora</title_da>
      <title_hr>Klasifikatori iz neopisivane korpore</title_hr>
      <title_nl>Bootstrap Domain-Specific Sentiment Classifiers van Unlabel Corpora</title_nl>
      <title_bg>Сентимент класификатори, специфични за домейна от Немаркирана Корпора</title_bg>
      <title_ko>표기되지 않은 자료 라이브러리 기반의Bootstrap 영역 특정 감정 분류기</title_ko>
      <title_de>Bootstrap Domain-Specific Sentiment Classifiers von Unlabeled Corpora</title_de>
      <title_id>Klasifikasi Sentimen Spesifik Domain Bootstrap dari Korpora Tidak Berlebar</title_id>
      <title_fa>گروه‌های مجموعه‌کننده‌ی مجموعه‌ی مجموعه‌ای از کوپرا غیرقابل نوشته‌شده</title_fa>
      <title_sw>Makala ya Makala maalumu ya Domain kutoka Corpora isiyo na mafanikio</title_sw>
      <title_af>Bootstrap Domein- Spesifieke Sentiment Classifiers van Onabelde Korpora</title_af>
      <title_sq>Klasifikuesit e ndjenjave specifike për domenin Bootstrap nga Korpora e Pashënuar</title_sq>
      <title_hy>Comment</title_hy>
      <title_am>የአሁኑን ፋይል አስቀምጥ</title_am>
      <title_tr>Açmak Açmak Taýdaly Sentiment Köpüründen Açmak</title_tr>
      <title_az>S…ôf…ôrl…ônmiŇü C…ôrporadan S…ôf…ôrl…ônmiŇü Domain-Specific Sentiment Classifiers</title_az>
      <title_bn>বুটট্র্যাপ ডোমেইন- বিশেষ সেন্টাইমেন্ট ক্লাসিকার্সার অলাবেল কর্পোরা থেকে</title_bn>
      <title_cs>Bootstrap Doménově specifické klasifikátory sentimentů z Unlabeled Corpora</title_cs>
      <title_ca>Classificadors de sentiments específics per domini Bootstrap de la Corpora sense marca</title_ca>
      <title_bs>Sklopac domena specijalnih poslovnih klasifikatora iz nezabelirane korpore</title_bs>
      <title_fi>Bootstrap Domain-spesifiset tunteet vuokrattavaksi in Unlabeled Corpora</title_fi>
      <title_et>Bootstrap Domeeni spetsiifilised Sentiment Classifiers alates Unlabeled Corpora</title_et>
      <title_jv>Language</title_jv>
      <title_sk>Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora</title_sk>
      <title_he>סימני רגשות ספציפיים למשפחה של Bootstrap מחברת ללא סימנים</title_he>
      <title_ha>QShortcut</title_ha>
      <title_bo>Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora</title_bo>
      <abstract_ar>غالبًا ما تكون هناك حاجة لإجراء تصنيف للمشاعر في مجال معين حيث لا يتوفر مستند معنون. على الرغم من أنه يمكننا الاستفادة من مصنف المشاعر الجاهز للأغراض العامة أو المصنف مسبقًا لمجال مختلف ، فإن الفعالية ستكون أقل جودة. في هذه الورقة ، نستكشف إمكانية بناء مصنفات المشاعر الخاصة بالمجال باستخدام المستندات غير المصنفة فقط. يشير تحقيقنا إلى أنه في كلمة التضمينات التي تم تعلمها من المجموعة غير المسماة لمجال معين ، فإن تمثيلات الكلمات الموزعة (المتجهات) للمشاعر المعاكسة تشكل مجموعات متميزة ، على الرغم من أن هذه المجموعات غير قابلة للتحويل عبر المجالات. من خلال استغلال مثل هذا الهيكل التجميعي ، نحن قادرون على استخدام خوارزميات التعلم الآلي للحث على معجم مشاعر عالي الجودة خاص بمجال معين من مجرد عدد قليل من كلمات المشاعر النموذجية ("البذور"). من النتائج المهمة أن خوارزميات التعلم الخاضعة للإشراف القائمة على النموذج الخطي البسيط (مثل SVM الخطي) يمكن أن تعمل في الواقع بشكل أفضل من خوارزميات التعلم شبه الخاضعة للإشراف / التحويلية الأكثر تطوراً والتي تمثل أحدث التقنيات لتحريض معجم المشاعر. يمكن تطبيق المعجم المستحث مباشرةً بطريقة قائمة على المعجم لتصنيف المشاعر ، ولكن يمكن تحقيق أداء أعلى من خلال طريقة تمهيد التشغيل على مرحلتين والتي تستخدم المعجم المستحث لتعيين درجات المشاعر الإيجابية / السلبية للمستندات غير المصنفة أولاً ، و عند العثور على تلك المستندات واضحة
إشارات المشاعر كأمثلة مزيفة لتدريب مصنف المشاعر للوثيقة من خلال خوارزميات التعلم الخاضعة للإشراف (مثل LSTM). في العديد من مجموعات البيانات المعيارية لتصنيف مشاعر المستندات ، يتفوق نهجنا الشامل غير الخاضع للإشراف (باستثناء مجموعة صغيرة من الكلمات الأولية) على الأساليب الحالية غير الخاضعة للإشراف ويحقق دقة مماثلة لتلك الخاصة بالنهج الخاضعة للإشراف الكامل.</abstract_ar>
      <abstract_ja>多くの場合、ラベル付けされた文書が利用できない特定のドメインでセンチメント分類を実行する必要があります。 汎用の既製センチメント分類子または別のドメインのために事前に構築されたセンチメント分類子を使用することはできますが、有効性は劣ります。 本稿では、ラベル付けされていない文書のみでドメイン固有のセンチメント分類子を構築する可能性を探る。 私たちの調査では、所与のドメインの未標識コーパスから学んだ単語埋め込みでは、反対の感情の分散された単語表現（ベクター）が異なるクラスタを形成することが示されていますが、これらのクラスタはドメイン間で移転可能ではありません。 このようなクラスタリング構造を利用することで、機械学習アルゴリズムを利用して、典型的な感情語（「シード」）のいくつかから質の高いドメイン固有の感情語彙を誘導することができる。 重要な発見は、単純な線形モデルに基づく監督学習アルゴリズム（線形SVMなど）が、センチメント辞書誘導のための最先端の技術を表す、より洗練された半監督/変換学習アルゴリズムよりも実際に優れている可能性があることです。 誘導された辞書は、感情分類のための辞書ベースの方法に直接適用することができましたが、誘導された辞書を使用して正/負の感情スコアを最初にラベル付けされていない文書に割り当てる二相ブートストラップ法を通じて、より高いパフォーマンスを達成することができます。
文書センチメント分類器v ia監修学習アルゴリズム（ LSTMなど）を訓練するための擬似ラベル付けされた例としてセンチメントシグナル。文書センチメント分類のためのいくつかのベンチマークデータセットでは、全体的に監督されていないエンドツーエンドのパイプラインアプローチ（シードワードの小さなセットを除く）は、既存の監督されていないアプローチを上回り、完全に監督されたアプローチに匹敵する精度を実現します。</abstract_ja>
      <abstract_pt>Muitas vezes, há a necessidade de realizar a classificação de sentimentos em um domínio específico onde nenhum documento rotulado está disponível. Embora pudéssemos usar um classificador de sentimento pronto para uso geral ou um pré-construído para um domínio diferente, a eficácia seria inferior. Neste artigo, exploramos a possibilidade de construir classificadores de sentimento específicos de domínio apenas com documentos não rotulados. Nossa investigação indica que nas incorporações de palavras aprendidas do corpus não rotulado de um determinado domínio, as representações de palavras distribuídas (vetores) para sentimentos opostos formam clusters distintos, embora esses clusters não sejam transferíveis entre domínios. Explorando essa estrutura de agrupamento, podemos utilizar algoritmos de aprendizado de máquina para induzir um léxico de sentimento específico de domínio de qualidade a partir de apenas algumas palavras de sentimento típicas (“sementes”). Uma descoberta importante é que algoritmos de aprendizado supervisionado baseados em modelo linear simples (como SVM linear) podem realmente funcionar melhor do que algoritmos de aprendizado semi-supervisionado/transdutivo mais sofisticados que representam a técnica de última geração para indução de léxico de sentimento. O léxico induzido pode ser aplicado diretamente em um método baseado em léxico para classificação de sentimentos, mas um desempenho mais alto pode ser alcançado por meio de um método de bootstrapping de duas fases que usa o léxico induzido para atribuir pontuações de sentimentos positivos/negativos a documentos não rotulados primeiro, e então usa os documentos que têm
sinais de sentimento como exemplos pseudo-rotulados para treinar um classificador de sentimento de documento por meio de algoritmos de aprendizado supervisionado (como LSTM). Em vários conjuntos de dados de referência para classificação de sentimentos de documentos, nossa abordagem em pipeline de ponta a ponta, que geralmente não é supervisionada (exceto por um pequeno conjunto de palavras-chave), supera as abordagens não supervisionadas existentes e atinge uma precisão comparável à das abordagens totalmente supervisionadas.</abstract_pt>
      <abstract_es>A menudo es necesario realizar una clasificación de opiniones en un dominio particular donde no hay ningún documento etiquetado disponible. Aunque podríamos utilizar un clasificador de sentimientos estándar de uso general o uno prediseñado para un dominio diferente, la eficacia sería inferior. En este artículo, exploramos la posibilidad de crear clasificadores de opinión específicos de dominio solo con documentos sin etiqueta. Nuestra investigación indica que en las incrustaciones de palabras aprendidas del corpus no etiquetado de un dominio dado, las representaciones de palabras distribuidas (vectores) para sentimientos opuestos forman grupos distintos, aunque esos grupos no son transferibles entre dominios. Aprovechando esta estructura de agrupamiento, podemos utilizar algoritmos de aprendizaje automático para inducir un léxico de opinión específico de dominio de calidad a partir de unas pocas palabras de opinión típicas («semillas»). Un hallazgo importante es que los algoritmos de aprendizaje supervisado basados en modelos lineales simples (como la SVM lineal) pueden funcionar mejor que los algoritmos de aprendizaje semisupervisados/transductivos más sofisticados que representan la técnica más avanzada para la inducción de léxico de sentimientos. El léxico inducido podría aplicarse directamente en un método basado en léxico para la clasificación de opiniones, pero se podría lograr un mayor rendimiento a través de un método de arranque de dos fases que utilice el léxico inducido para asignar puntuaciones de opinión positivas/negativas a documentos sin etiqueta primero, y luego usarlos documentos que se encuentren claros
señales de opinión como ejemplos pseudoetiquetados para entrenar un clasificador de opinión de documentos mediante algoritmos de aprendizaje supervisado (como LSTM). En varios conjuntos de datos de referencia para la clasificación de opiniones de documentos, nuestro enfoque canalizado de extremo a extremo, que en general no está supervisado (excepto por un pequeño conjunto de palabras semilla) supera a los enfoques no supervisados existentes y logra una precisión comparable a la de los enfoques totalmente supervisados.</abstract_es>
      <abstract_fr>Il est souvent nécessaire d'effectuer une classification des sentiments dans un domaine particulier où aucun document étiqueté n'est disponible. Bien que nous puissions utiliser un classificateur de sentiments standard à usage général ou un classificateur prédéfini pour un domaine différent, l'efficacité serait moindre. Dans cet article, nous explorons la possibilité de créer des classificateurs de sentiments spécifiques à un domaine avec des documents non étiquetés uniquement. Notre enquête indique que dans les intégrations de mots apprises à partir du corpus non étiqueté d'un domaine donné, les représentations de mots distribuées (vecteurs) pour des sentiments opposés forment des groupes distincts, bien que ces groupes ne soient pas transférables entre les domaines. En exploitant une telle structure de regroupement, nous sommes en mesure d'utiliser des algorithmes d'apprentissage automatique pour induire un lexique de sentiment spécifique à un domaine de qualité à partir de quelques mots de sentiment typiques (« graines »). Une constatation importante est que les algorithmes d'apprentissage supervisé basés sur un modèle linéaire simple (tels que la SVM linéaire) peuvent en fait fonctionner mieux que des algorithmes d'apprentissage semi-supervisé/transductif plus sophistiqués qui représentent la technique de pointe pour l'induction du lexique des sentiments. Le lexique induit peut être appliqué directement dans une méthode basée sur un lexique pour la classification des sentiments, mais une meilleure performance peut être obtenue grâce à une méthode d'amorçage en deux phases qui utilise le lexique induit pour attribuer des scores d'opinion positifs/négatifs à des documents non étiquetés en premier, puis utilise ces documents identifiés comme étant clairs
des signaux de sentiment en tant qu'exemples pseudo-étiquetés pour entraîner un classificateur de sentiment de document via des algorithmes d'apprentissage supervisé (tels que LSTM). Sur plusieurs ensembles de données de référence pour la classification des sentiments des documents, notre approche en pipeline de bout en bout qui est globalement non supervisée (à l'exception d'un petit ensemble de mots semence) surpasse les approches non supervisées existantes et atteint une précision comparable à celle des approches entièrement supervisées.</abstract_fr>
      <abstract_zh>常须无标记文档特定域中行情类。 虽可以通用见成情类器,或针对异域预构分类器,其有效性更差。 本文讨论未标文档特定于域情类器可能。 臣等考明,于给定域未标语料库中学词嵌入,反情者分布式示(向量)成聚类,虽聚类不可跨域移。 因此聚类构,能用机器学算法,只从数典("种子")诱出特定特定域高质量情词典。 要在简线性督学算法(如线性SVM)实监督/转导,情词汇归最新。 诱词典直施于词典之情类,而可以两阶致高,其法用诱词典先分/极之情于未标之文档,非有清文档也。
情信号为伪标示例,以训练文档情类器 v ia 督习算法(如 LSTM)。 于文档情类数准集上,吾端到端流水线法总体无监督(除一组种词)优于见无监督之法,与全监相当者准确性。</abstract_zh>
      <abstract_hi>अक्सर किसी विशेष डोमेन में भावना वर्गीकरण करने की आवश्यकता होती है जहां कोई लेबल दस्तावेज़ उपलब्ध नहीं होता है। यद्यपि हम एक सामान्य-उद्देश्य ऑफ-द-शेल्फ भावना क्लासिफायर या एक अलग डोमेन के लिए पूर्व-निर्मित का उपयोग कर सकते हैं, प्रभावशीलता हीन होगी। इस पेपर में, हम केवल अनलेबल किए गए दस्तावेजों के साथ डोमेन-विशिष्ट भावना क्लासिफायर बनाने की संभावना का पता लगाते हैं। हमारी जांच इंगित करती है कि किसी दिए गए डोमेन के अनलेबल कॉर्पस से सीखे गए शब्द एम्बेडिंग में, विपरीत भावनाओं के लिए वितरित शब्द प्रतिनिधित्व (वैक्टर) अलग-अलग क्लस्टर बनाते हैं, हालांकि वे क्लस्टर डोमेन में हस्तांतरणीय नहीं हैं। इस तरह के एक क्लस्टरिंग संरचना का शोषण करते हुए, हम कुछ विशिष्ट भावना शब्दों ("बीज") से एक गुणवत्ता डोमेन-विशिष्ट भावना शब्दकोश को प्रेरित करने के लिए मशीन लर्निंग एल्गोरिदम का उपयोग करने में सक्षम हैं। एक महत्वपूर्ण खोज यह है कि सरल रैखिक मॉडल आधारित पर्यवेक्षित सीखने के एल्गोरिदम (जैसे रैखिक एसवीएम) वास्तव में अधिक परिष्कृत अर्ध-पर्यवेक्षित / ट्रांसडक्टिव लर्निंग एल्गोरिदम की तुलना में बेहतर काम कर सकते हैं जो भावना शब्दकोश प्रेरण के लिए अत्याधुनिक तकनीक का प्रतिनिधित्व करते हैं। प्रेरित शब्दकोश को भावना वर्गीकरण के लिए एक शब्दकोश-आधारित विधि में सीधे लागू किया जा सकता है, लेकिन एक उच्च प्रदर्शन दो-चरण बूटस्ट्रैपिंग विधि के माध्यम से प्राप्त किया जा सकता है जो प्रेरित शब्दकोश का उपयोग करता है ताकि पहले लेबल रहित दस्तावेजों को सकारात्मक / नकारात्मक भावना स्कोर असाइन किया जा सके, एक एनडी टी मुर्गी यू सेस उन दस्तावेजों को स्पष्ट पाया गया
एक दस्तावेज़ भावना क्लासिफायर वी आईए पर्यवेक्षित सीखने एल्गोरिदम (जैसे एलएसटीएम) को प्रशिक्षित करने के लिए छद्म-लेबल उदाहरणों के रूप में भावना संकेत। दस्तावेज़ भावना वर्गीकरण के लिए कई बेंचमार्क डेटासेट पर, हमारे एंड-टू-एंड पाइपलाइनेड दृष्टिकोण जो समग्र रूप से असुरक्षित है (बीज शब्दों के एक छोटे से सेट को छोड़कर) मौजूदा असुरक्षित दृष्टिकोणों को मात देता है और पूरी तरह से पर्यवेक्षित दृष्टिकोणों की तुलना में सटीकता प्राप्त करता है।</abstract_hi>
      <abstract_ga>Is minic go mbíonn gá le haicmiú meon a dhéanamh i bhfearann ar leith nach bhfuil aon doiciméad lipéadaithe ar fáil ann. Cé go bhféadfaimis úsáid a bhaint as aicmitheoir ginearálta um dhearcadh lasmuigh den tseilf nó as aicmitheoir réamhthógtha d’fhearann eile, bheadh an éifeachtacht níos lú. Sa pháipéar seo, déanaimid iniúchadh ar an bhféidearthacht atá ann aicmitheoirí meon atá sainiúil don fhearann a thógáil le doiciméid neamhlipéadaithe amháin. Léiríonn ár n-imscrúdú go bhfuil na léirithe focal dáilte (veicteora) do dhearcthaí codarsnacha i gcnuasaigh ar leith, cé nach féidir na cnuasaigh sin a aistriú thar fearainn. Agus leas á bhaint againn as struchtúr cnuasaithe den sórt sin, táimid in ann úsáid a bhaint as halgartaim meaisínfhoghlama chun foclóir meon sainiúil don fhearann a chothaítear ó chúpla focal meon tipiciúil (“síolta”). Toradh tábhachtach is ea gur féidir le halgartaim foghlama maoirsithe shimplí líneacha atá bunaithe ar mhúnla (cosúil le SVM líneach) oibriú níos fearr ná algartaim foghlama leath-mhaoirsithe/tarchurtha níos sofaisticiúla a léiríonn an teicníocht úrscothach le haghaidh ionduchtaithe foclóir meon. D’fhéadfaí an foclóir ionduchtaithe a chur i bhfeidhm go díreach i modh foclóireachta-bhunaithe chun meon a rangú, ach d’fhéadfaí feidhmíocht níos airde a bhaint amach trí mhodh tosaithe dhá chéim a úsáideann an foclóir ionduchtaithe chun scóir meon dearfach/diúltach a shannadh do dhoiciméid neamhlipéadaithe ar dtús, a nd úsáideann tú na doiciméid sin a bhfuarthas amach go bhfuil siad soiléir
comharthaí meon mar shamplaí bréag-lipéadaithe chun aicmitheoir meon doiciméad a oiliúint trí algartaim foghlama maoirsithe (amhail LSTM). Ar roinnt tacar sonraí tagarmharcála le haghaidh aicmiú meon doiciméad, sáraíonn ár gcur chuige píblíne ó cheann go ceann atá gan mhaoirseacht ar an iomlán (seachas tacair bídeach de shíolfhocail) cur chuige neamh-mhaoirsithe atá ann cheana féin agus a bhaineann cruinneas amach atá inchomparáide leis an gcur chuige atá faoi mhaoirseacht iomlán.</abstract_ga>
      <abstract_ru>Часто возникает необходимость в классификации настроений в определенной области, где нет маркированного документа. Хотя мы могли бы использовать общепринятый классификатор настроений или готовый классификатор для другой области, эффективность была бы ниже. В этой статье мы исследуем возможность построения классификаторов настроений для конкретных доменов только с немаркированными документами. Наше исследование показывает, что в словах, изученных из немеченного тела данного домена, распределенные представления слов (векторы) для противоположных настроений образуют отдельные кластеры, хотя эти кластеры не могут передаваться между доменами. Используя такую кластерную структуру, мы можем использовать алгоритмы машинного обучения, чтобы вызвать качественный лексикон настроений, специфичный для конкретной области, всего из нескольких типичных слов настроений («семян»). Важным выводом является то, что простые алгоритмы обучения под наблюдением на основе линейной модели (такие как линейная виртуальная машина защиты) могут на самом деле работать лучше, чем более сложные алгоритмы обучения под наблюдением/трансдуктивного обучения, которые представляют собой современную технику для индукции лексикона чувств. Индуцированный лексикон может быть применен непосредственно в методе классификации настроений на основе лексиконов, но более высокая производительность может быть достигнута с помощью двухфазного метода бутстреппинга, который использует индуцированный лексикон для присвоения баллов положительных/отрицательных настроений немеченным документам сначала, а затем эти документы имеют четкие
сигналы настроений в виде псевдомеченных примеров для обучения классификатора настроений документа через алгоритмы контролируемого обучения (такие как LSTM). На нескольких эталонных наборах данных для классификации настроений документов наш сквозной конвейерный подход, который в целом не контролируется (за исключением небольшого набора начальных слов), превосходит существующие неконтролируемые подходы и достигает точности, сопоставимой с точностью полностью контролируемых подходов.</abstract_ru>
      <abstract_ka>სენტიმენტის სიგნალები, როგორც პესეუდო-მაგალითი მაგალითები, რომლებიც დოკუმენტის სენტიმენტის კლასიფიკაცია v ia-ს შემდეგებული სწავლების ალგორიტემი (როგორც კოკუმენტის სენტიმენტის კლასიფიკაციისთვის რამდენიმე ბენტიმენტის მონაცემების კონფიკაციაში ჩვენი ბენტიმენტის კონფიკაციაში, ჩვენი ბენტიმენტის კონფიგურაციას, რომელიც უფრო მუშაობელია (მაგრამ ცოტა სიტყვების ნაწილი</abstract_ka>
      <abstract_it>Segnali sentiment come esempi pseudo-etichettati per formare un classificatore di sentiment di documenti v ia algoritmi di apprendimento supervisionati (come LSTM). Su diversi set di dati di benchmark per la classificazione dei sentimenti dei documenti, il nostro approccio pipelined end-to-end, che è generalmente non supervisionato (ad eccezione di un piccolo set di parole iniziali) supera gli approcci non supervisionati esistenti e raggiunge un'accuratezza paragonabile a quella degli approcci pienamente supervisionati.</abstract_it>
      <abstract_hu>Az érzelmező jelek pszeudo jelölésű példákként taníthatók egy dokumentum érzelmező osztályozó v ia felügyelt tanulási algoritmusok (például LSTM). A dokumentumok hangulatosztályozásához szükséges referenciaadatkészletek esetében a teljes körűen felügyelet nélküli, végpontos megközelítésünk, amely általánosságban felügyelet nélküli (kivéve egy kis vetőszót) felülmúlja a meglévő, felügyelet nélküli megközelítéseket, és a teljes körűen felügyelt megközelítésekhez hasonló pontosságot ér el.</abstract_hu>
      <abstract_el>σήματα συναισθημάτων ως ψευτοσημασμένα παραδείγματα για την εκπαίδευση ενός ταξινομητή συναισθημάτων εγγράφων σε αλγόριθμους επιτήρησης μάθησης (όπως LSTM). Σε διάφορα σύνολα δεδομένων αναφοράς για την ταξινόμηση συναισθημάτων εγγράφων, η ολοκληρωμένη προσέγγιση μας που είναι συνολικά χωρίς επίβλεψη (εκτός από ένα μικρό σύνολο λέξεων εκκίνησης) ξεπερνά τις υπάρχουσες προσεγγίσεις χωρίς επίβλεψη και επιτυγχάνει μια ακρίβεια συγκρίσιμη με εκείνη των πλήρως εποπτευόμενων προσεγγίσεων.</abstract_el>
      <abstract_kk>Құжаттың сезімдік классификациясын оқыту алгоритмдері (LSTM секілді) үшін псевдо белгіленген сезімдік сигналдары. Құжаттардың сезімдерін шектеу үшін бірнеше кеңістік деректер жиындарында, біздің соңғы жолдарымыздың жалпы жолдарымыз (бірнеше кеңістік сөздерінен басқа), барлық кеңістіктерді шектеп, толық бақылау кеңістіктерімен салыстыратын дұрыстығын</abstract_kk>
      <abstract_ml>ഒരു രേഖയുടെ അനുഭവങ്ങള്‍ ക്ലാസ്ഫിഫയര്‍ v ia പഠിക്കുന്നതിന്റെ ആല്‍ഗോരിത്മുകള്‍ പരിശീലിപ്പിക്കാന്‍ പെസുഡോ- ലേബിള്‍ ചെയ്ത ഉദാഹ രേഖപ്രകാരം ക്ലാസ്ഫിക്കാനുള്ള പല ബെന്‍മാര്‍ക്ക് ഡേറ്റാസറ്റുകളില്‍ നമ്മുടെ അവസാനത്തെ അവസാനത്തേക്ക് മുഴുവന്‍ സൂക്ഷിച്ചിട്ടില്ലാത്ത ചെറിയ വാക്കുകള്‍ ഒഴിച്ച് നിലവ</abstract_ml>
      <abstract_mt>sinjali ta’ sensazzjoni bħala eżempji psewdotikkettati biex jitħarreġ klassifikatur ta’ sensazzjoni ta’ dokument v ia algoritmi ta’ tagħlim supervizzati (bħal LSTM). F’diversi settijiet ta’ dejta referenzjarji għall-klassifikazzjoni tas-sentimenti tad-dokument, l-approċċ imfassal minn tarf sa tarf tagħna li huwa ġeneralment mhux sorveljat (ħlief għal sett żgħir ta’ kliem taż-żerriegħa) jaqbeż l-approċċi eżistenti mhux sorveljati u jikseb preċiżjoni komparabbli ma’ dik ta’ approċċi sorveljati bis-sħiħ.</abstract_mt>
      <abstract_mn>мэдрэмжийн сигналууд нь баримт мэдрэмжийн хувьд суралцах алгоритмыг суралцахын тулд суралцах шиг жишээ болсон. Документын мэдрэмжтэй хуваалцах хэд хэдэн тооны өгөгдлийн сангууд дээр бидний төгсгөл хоолойн шугамын арга зам нь ихэвчлэн дүгнэгдэхгүй (жижиг хэсэг үгнээс гадна) үргэлж суурилсан тусламжгүй арга зам гаргаж, бүрэн удирдагдсан арга зам дээр харьцуулах зөв байдалтай тэнц</abstract_mn>
      <abstract_ms>isyarat perasaan sebagai contoh pseudo-labeled untuk melatih pengklasifikasi perasaan dokumen v ia algoritma pembelajaran yang diawasi (seperti LSTM). Pada beberapa set data benchmark untuk klasifikasi sentimen dokumen, pendekatan paip akhir-akhir kami yang secara keseluruhan tidak diawasi (kecuali set kecil kata benih) melampaui pendekatan tidak diawasi yang wujud dan mencapai ketepatan yang boleh dibandingkan dengan pendekatan yang diawasi sepenuhnya.</abstract_ms>
      <abstract_pl>Sygnały sentymentów jako pseudoznakowane przykłady do trenowania klasyfikatora sentymentów dokumentów przez nadzorowane algorytmy uczenia się (takie jak LSTM). W przypadku kilku zbiorów danych referencyjnych dla klasyfikacji sentymentów dokumentów nasze kompleksowe podejście, które jest ogólnie bez nadzoru (z wyjątkiem małego zestawu słów podstawowych), przewyższa istniejące podejścia bez nadzoru i osiąga dokładność porównywalną z podejściami w pełni nadzorowanymi.</abstract_pl>
      <abstract_no>sentimentsignaler som pseudomerket eksemplar for å trenja eit dokumentsentimentklassifiserer v ia supervisert læringsalgoritme (som LSTM). På fleire benchmarkdatasett for dokumentsentimentklassifikasjon utfører det eksisterande tilnærmingar og når det er sammenlignbar med det fullstendig oversiktte tilnærmingane, er det vanskeleg at det er ikkje oppretta (unntatt ein liten set av frøord).</abstract_no>
      <abstract_ro>Semnale sentimentale ca exemple pseudo-etichetate pentru a instrui un clasificator de sentimente de documente v ia algoritmi de învățare supravegheat (cum ar fi LSTM). Pe mai multe seturi de date de referință pentru clasificarea sentimentului documentelor, abordarea noastră end-to-end pipelined, care este în general nesupravegheată (cu excepția unui set mic de cuvinte inițiale) depășește abordările nesupravegheate existente și atinge o precizie comparabilă cu cea a abordărilor complet supravegheate.</abstract_ro>
      <abstract_lt>jausmų signalai kaip pseudo žymėti pavyzdžiai, skirti dokumentų jausmų klasifikatoriui v ia apmokyti prižiūrimus mokymosi algoritmus (pvz., LSTM). Keliuose dokumentų jautrumo klasifikavimo lyginamuosiuose duomenų rinkiniuose mūsų iš vienos iki kitos nesustebimas metodas (išskyrus nedidelį sėklos žodžių rinkinį) viršija esamus nesustebimus metodus ir užtikrina tikslumą, palyginamą su visiškai prižiūrimomis metodais.</abstract_lt>
      <abstract_mk>сигналите на чувства како примери со псевдо-означени означувања за обука на класификатор на чувства на документот во вија надгледувани алгоритми за учење (како што е ЛСТМ). На неколку бази на податоци за класификација на чувствата на документите, нашиот контролен пристап кој е целосно ненадгледуван (освен мал набор зборови за семе) ги надминува постојните ненадгледувани пристапи и постигнува прецизност споредлива со онаа на целосно надгледувани пристапи.</abstract_mk>
      <abstract_sr>signale sentiment a kao primjeri pseudo-označene za obuku klasifikatora sentimenta u dokumentu v ia nadgledani algoritmi učenja (kao što je LSTM). Na nekoliko standardnih set a podataka za klasifikaciju osjećanja dokumenta, naš pristup na konačnoj do kraja, koji je općenito neodređen (osim malih seta riječi semena) iznosi postojeće neodređene pristupe i postiže to čnost usporednost s tim potpuno nadziranim pristupima.</abstract_sr>
      <abstract_si>සංවේදන සංඥාවක් pseudo-label උදාහරණයක් විදිහට ලේබුම් කිරීමට ලේබුම් සංවේදනය විදිහට පරීක්ෂා කරනවා විදිහට පරීක්ෂ විශේෂය සඳහා බෙන්ච්මාර්ක් දත්ත සේට් වලින්, අපේ අවසානයෙන් අවසානය කරන්න පායිපලින් විධානය සඳහා අපේ අවසානයෙන් පායිපලින් විධානය සඳහා සාමාන්‍ය විධානය නැති ව</abstract_si>
      <abstract_so>Calaamadaha xisaabta sida tusaale ahaan la magacaabay pseudo-labo in loo tababariyo tababar xuquuqda qofka ka mid ah kalgorityada waxbarashada (sida LSTM). Kuwii ku qoran sawirada qoraalka loo kala soocayn karo, qaababkayaga dhammaadka ugu dambaysta ah ee a an dhammaan la ilaalinayn (marka laga bilaabo koob ka mid ah erayada farcanka) wuxuu sameeyaa qaabab aan la ilaalinayn iyo wuxuu gaadhaa si saxda ah oo u eg qaababka aad u ilaalisan.</abstract_so>
      <abstract_sv>sentimentsignaler som pseudomärkta exempel för att träna en dokumentsentimentklassificerare v ia övervakade inlärningsalgoritmer (t.ex. LSTM). På flera referensdatauppsättningar för klassificering av dokumentsentiment presterar vår pipelined-metod som generellt inte är övervakad (med undantag för en liten uppsättning utsädesord) bättre än befintliga icke-övervakade metoder och uppnår en noggrannhet som är jämförbar med den för fullt övervakade tillvägagångssättet.</abstract_sv>
      <abstract_ta>ஒரு ஆவண உணர்வு வகைப்படுத்தும் வகைப்பாளர் v ia யா கற்றுக்கொள்ளும் படிக்கைகளை பயிற்சி செய்ய உணர்வு குறிப்புகள் (LSTM போன்ற). ஆவணத்தின் உணர்வு வகைப்படுத்தலுக்கான பல பென்மேக் தகவல் அமைப்புகளில், எங்கள் முடிவில் இருந்து முடிவில் உள்ள முடிவு புள்ளியிடப்பட்ட செயல்பாடு மொத்தமாக காப்பாற்றப்படாத (சிறி</abstract_ta>
      <abstract_ur>سنگت سیگنالوں کو مثالیں بناتے ہیں جو ایک سنگت سیگنالیٹ کلاسیٹر کی تطارین کرنے کے لئے لکھی جاتی ہیں۔ چند بینچم مارک ڈیٹ سٹ کے لئے سنگت احساس کلاسیفوں کے لئے، ہماری آخری پائپ لین کی تقریبا جو عموماً غیر حفاظت کی ہے (صرف تھوڑی سیٹ لکھ کے لکھ کے) موجود غیر حفاظت کی تقریبا سے زیادہ اضافہ کرتی ہے اور پوری حفاظت کی تقریبا کے مطابق دقیق حاصل کرتی ہے۔</abstract_ur>
      <abstract_uz>sentiment signals as pseudo-labeled examples to train a document sentiment classifier v ia supervised learning algorithms (such as LSTM).  Ҳужжат sentiment darajasini bir nechta benchmark maʼlumot etishda, bizning oxirimiz oxirigi qoʻyilgan usul hamma saqlanmagan (kichkina soʻzlar soʻzlari bilan bir nechta saqlanmagan soʻzlarni bajaradi) mavjud saqlash muvaffaqiyatlarini bajaradi va butun taʼminlovchi soʻzlarni bajaradi.</abstract_uz>
      <abstract_vi>ảo giác như v í dụ giả được đánh dấu để đào tạo một người phân loại cảm xúc tài liệu v.a giám sát thuật to án học (v. v. d. HTTM). Trên nhiều bộ dữ liệu tiêu chuẩn cho việc phân loại cảm xúc tài liệu, phương pháp kết thúc của đường ống mà hoàn to àn không giám sát được (ngoại trừ một bộ chữ hạt nhỏ) vượt trội các phương pháp chưa được giám sát hiện tại và đạt độ chính xác tương đương với các phương pháp được giám sát đầy đủ.</abstract_vi>
      <abstract_hr>signali osjećanja kao primjeri pseudo-označene za obuku klasifikatora osjećanja dokumenta v ia nadzirani algoritmi učenja (poput LSTM). Na nekoliko standardnih podataka za klasifikaciju osjećanja dokumenta, naš pristup na konačnoj do kraja cjevi koji je ukupno neodržen (osim malih set a riječi sjemena) iznosi postojeće neodržavane pristupe i postiže to čnost usporednost s onim potpuno nadziranim pristupima.</abstract_hr>
      <abstract_bg>сентиментални сигнали като псевдо-маркирани примери за обучение на класификатор на сентиментални документи в контролирани учебни алгоритми (като LSTM). На няколко базови набора от данни за класификация на сентимента на документите нашият подход от край до край, който като цяло е без надзор (с изключение на малък набор от начални думи), превъзхожда съществуващите ненадзорни подходи и постига точност, сравнима с тази на напълно надзорните подходи.</abstract_bg>
      <abstract_nl>sentimentsignalen als pseudo-gelabelde voorbeelden om een documentsentimentclassificator te trainen in begeleide leeralgoritmen (zoals LSTM). Op verschillende benchmark datasets voor documentsentiment classificatie presteert onze end-to-end pipeline aanpak, die over het algemeen onbeheerd is (met uitzondering van een kleine set startwoorden), beter dan bestaande onbeheerde benaderingen en bereikt een nauwkeurigheid vergelijkbaar met die van volledig begeleide benaderingen.</abstract_nl>
      <abstract_ko>감정 신호는 위조 표기 샘플로 감독 학습 알고리즘(예를 들어 LSTM)을 통해 문서의 감정 분류기를 훈련시킨다.문서의 감정 분류에 사용되는 몇 가지 기준 데이터 집합에서 우리의 끝에서 끝까지 흐르는 수선 방법(작은 부분의 씨앗을 제외하고)은 기존의 무감독 방법보다 우수하고 완전한 감독 방법과 비슷한 정밀도를 달성했다.</abstract_ko>
      <abstract_fa>سیگنال احساسات به عنوان مثال‌هایی که با نام pseudo-labeled برای آموزش کردن یک مجموعه احساسات نسبت به الگوریتم یادگیری (مثل LSTM) تحت نظر گرفته است. روی چندین مجموعه‌های اطلاعات صندوق برای مجموعه‌ی احساسات سند، دستور لوله‌های پایان به پایان ما که عموماً غیر مجموعه‌ی کلمه دانه‌های کوچک (به جز مجموعه کلمه دانه) از دستورات غیرقابل قابل قابل قابل قابل مقایسه با دستورات کامل تحت نظر قرار می‌گیرد</abstract_fa>
      <abstract_da>sentiment signals som pseudo-mærkede eksempler til at træne en dokumentsentiment klassificerer v ia overvågede læringsalgoritmer (såsom LSTM). På flere benchmark-datasæt til klassificering af dokumentstemninger overgår vores end-to-end pipelined-tilgang, som generelt ikke er overvåget (bortset fra et lille sæt seed words), eksisterende ikke-overvågede tilgange og opnår en nøjagtighed, der kan sammenlignes med tilgangene med fuldt overvågede.</abstract_da>
      <abstract_de>Sentimentsignale als pseudo-markierte Beispiele, um einen Klassifikator für Dokumentesentimente in überwachten Lernalgorithmen (wie LSTM) zu trainieren. Auf mehreren Benchmark-Datensätzen für die Klassifizierung der Dokumentesentiments übertrifft unser durchgängiger Pipeline-Ansatz, der insgesamt unbeaufsichtigt ist (mit Ausnahme eines winzigen Satzes von Startwörtern), bestehende unbeaufsichtigte Ansätze und erreicht eine Genauigkeit, die mit der von vollständig überwachten Ansätzen vergleichbar ist.</abstract_de>
      <abstract_id>sinyal sentimen sebagai contoh pseudo-labeled untuk melatih klassifikasi sentimen dokumen v ia algoritma belajar yang diawasi (seperti LSTM). Dalam beberapa set data benchmark untuk klasifikasi sentimen dokumen, pendekatan dari akhir ke akhir kami yang secara umum tidak diawasi (kecuali untuk set kecil kata-kata benih) melampaui pendekatan yang tidak diawasi dan mencapai akurasi yang dapat dibandingkan dengan pendekatan yang diawasi sepenuhnya.</abstract_id>
      <abstract_af>sentimente signale as pseudo- etiketeerde voorbeelde om 'n dokument sentiment klassifiseerder v ia superviseer leer algoritme (soos LSTM). Op verskeie benchmarkdatastelle vir dokumentsentiment klasifikasie, ons einde-tot-einde-pipelineerde toegang wat totaal onverondersteun is (behalwe vir 'n klein stel van saad woorde) uitvoer bestaande onverondersteunde toegange en bereik 'n presies vergelykbaar met wat van volledig ondersoekte toegange is.</abstract_af>
      <abstract_sw>ishara za hisia kama mifano yenye jina la pseudo ili kufundisha hisia mbalimbali za nyaraka v ia walifuatilia algorithi za kujifunza (kama vile LSTM). Kwenye taarifa kadhaa za benchma za kutangazwa kwa hisia za dokumenta, mbinu yetu ya mwisho hadi mwishoni ambayo kwa ujumla haijawekwa (isipokuwa kwa seti ndogo ya maneno ya uzazi) hufanya mbinu zisizo sahihi na kupata uhakika unaofanana na namna ambazo zinazofuatiliwa kabisa.</abstract_sw>
      <abstract_sq>sinjalet e ndjenjave si shembuj pseudo-etiketuar për të trajnuar një klasifikues të ndjenjave të dokumentit v ia algoritme mësimi të mbikqyrur (të tillë si LSTM). Në disa baza të dhënash për klasifikimin e ndjenjave të dokumenteve, qasja jonë nga fundi në fund e tubacionit që është përgjithësisht e pazgjidhur (me përjashtim të një grupi të vogël fjalësh të frymës) kalon qasjet ekzistuese të pazgjidhura dhe arrin një saktësi të krahasueshme me atë të qasjeve plotësisht të mbikqyrura.</abstract_sq>
      <abstract_hy>զգացմունքների ազդանշաններ, ինչպիսիք են կեղծ նշանները, որպեսզի ուսուցանենք փաստաթղթի զգացմունքների դասակարգիչը v իա վերահսկված ուսումնական ալգորիթմները (ինչպիսիք են LSMT-ները): On several benchmark datasets for document sentiment classification, our end-to-end pipelined approach which is overall unsupervised (except for a tiny set of seed words) outperforms existing unsupervised approaches and achieves an accuracy comparable to that of fully supervised approaches.</abstract_hy>
      <abstract_az>sentiment sinyalləri təhsil etmək üçün pseudo-etiketli məsəllər kimi məsəllər təhsil edir. Dökümət hissləri seçmək üçün bir neçə benchmark veri qurularında, bütün müəyyən edilməmiş (küçük bir növ söz istisna olmaqla) məlumatların müəyyən edilməsi və tamamilə gözlənmiş yaxınlıqların müqayisədə müəyyən edilməsi ilə müəyyən edilməyən bir dəqiqliyimizi başa düşür.</abstract_az>
      <abstract_tr>duýgular şeklinde elimde duýgular ýaly mysal görkezilýär. Sened duýgulary klasifikatçy v ia gözetleýän öwrenme algoritmalary (LSTM ýaly). Sened howlamagyny üçin birnäçe benchmark sanatynda, iň soňky we soňky gabdaly golaýatymyz (kiçi süz sözlerinden başga) meýilleşdirilmeýän golaýatlaryň üstüne çykar we doly gözleýän golaýatlaryň ýagdaýyny çykar.</abstract_tr>
      <abstract_bs>signale osjećanja kao primjeri pseudo-označene za obuku klasifikatora osjećanja dokumenta v ia nadzornog algoritma učenja (kao što je LSTM). Na nekoliko standardnih set a podataka za klasifikaciju osjećanja dokumenta, naš pristup na konačnoj do kraja cijevi koji je ukupno neodređen (osim malih seta riječi sjemena) iznosi postojeće neodređene pristupe i postiže to čnost usporedbenu s tim potpuno nadziranim pristupima.</abstract_bs>
      <abstract_am>የሰነድ እውቀት መግለጫ እና አዲስ ትምህርት ትምህርት ትምህርት ትምህርት ትምህርት ማድረግ (እንደ LSTM) በሚያስተምሩ ምሳሌዎች የሰነድ እውቀት መግለጫ ላይ በብዙ benchmark ዳታዎች ላይ፣ የፍጻሜያችን ወደ መጨረሻ ያልጠበቀውን መግለጫ (ከዘር ቃላት በቀር ትንሽ ክፍል ያልጠበቀውን) የተገኘውን ያልጠበቀውን ደረጃዎች አግኝቷል፡፡</abstract_am>
      <abstract_cs>sentimentové signály jako pseudoznačené příklady pro trénink klasifikátoru sentimentu dokumentů v algoritmech supervisovaného učení (například LSTM). Na několika referenčních datových sadách pro klasifikaci sentimentu dokumentů je náš komplexní přístup, který je celkově bez dohledu (s výjimkou malé sady základních slov), překonává stávající přístupy bez dohledu a dosahuje přesnosti srovnatelné s přístupem plně dohledu.</abstract_cs>
      <abstract_ca>senyals de sentiment com exemples pseudoetiquetats per formar un classificador de sentiment documental v ia algoritmes d'aprenentatge supervisats (com LSTM). En diversos conjunts de dades de referència per a la classificació del sentiment documental, el nostre enfocament de punta a punta que no és supervisat en general (excepte un petit conjunt de paraules de semilla) supera els enfocaments no supervisats existents i aconsegueix una precisió comparable a la d'enfocaments plenament supervisats.</abstract_ca>
      <abstract_bn>একটি নথিপত্রের অনুভূতি শিক্ষা শিক্ষা অ্যালগোরিদম (যেমন এলস্টিএম) প্রশিক্ষণ করার জন্য অনুভূতির সিগন্যাল হিসেবে পুসুডো-লেব ডকুমেন্টের অনুভূতি শ্রেণীকরণের জন্য বেনম্যার্ক ডাটাসেটে আমাদের শেষ থেকে শেষ পর্যন্ত পাইপেলের প্রতিক্রিয়া যা সম্পূর্ণরূপে সংরক্ষণ করা হয়েছে (সামান্য একটি সংখ্যা বিজ্ঞ</abstract_bn>
      <abstract_et>sentimentaalsed signaalid kui pseudomärgistatud näited dokumendi sentimentaalse klassifitseerija koolitamiseks v ia järelevalve algoritmid (nt LSTM). Mitmete dokumentide sentimentaalse klassifitseerimise võrdlusandmekogumite puhul ületab meie täielikult järelevalveta lähenemisviis (välja arvatud väikesed seemnesõnad) olemasolevaid järelevalveta lähenemisviise ja saavutab täpsuse, mis on võrreldav täielikult järelevalvega lähenemisviisidega.</abstract_et>
      <abstract_fi>Tunteisignaalit pseudomerkittyinä esimerkkeinä dokumenttien tunteiden luokittelijan kouluttamiseksi v ia ohjattuja oppimisalgoritmeja (kuten LSTM). Useissa dokumenttien tuntemusluokituksen vertailuaineistoissa kokonaisvaltainen pipelined-lähestymistapamme, joka on yleisesti valvomaton (lukuun ottamatta pieniä siemensanoja), ylittää nykyiset valvomattomat lähestymistapamme ja saavuttaa täysin valvottujen lähestymistapojen tarkkuuden.</abstract_fi>
      <abstract_ha>Simboli na kiyaye kamar misãlai da aka rubuta na cewa wa wa're wa're wa're wa're wa're wa'anar fanin takardar (kamar LStM). On several bangon data set for classified hisãbi na dokuman, hanyokanmu ta ƙarami zuwa ƙarami wanda aka tsare (fãce ƙarami wani abu kaɗan daga maganar zura) na samar da wanda ba'a tsare shi ba na da kuma ya isa wani tsari daidai da cikakken hanyoyin wanda aka tsare.</abstract_ha>
      <abstract_sk>sentimentalni signali kot psevdoznačeni primeri za usposabljanje razvrščevalca sentimentalnih elementov v a nadzorovani učni algoritmi (kot je LSTM). Na več referenčnih naborih podatkov za klasifikacijo občutkov dokumentov naš načrtovan pristop od konca do konca, ki je na splošno nenadzorovan (razen majhnega nabora besed), presega obstoječe nenadzorovane pristope in dosega natančnost, primerljivo z natančnostjo popolnoma nadzorovanih pristopov.</abstract_sk>
      <abstract_jv>Validity section</abstract_jv>
      <abstract_he>אותות רגשות כדוגמאות עם תווית פסאודו כדי לאמן מסמך מסווג רגשות v ia אלגוריתמים למידה שולטים (כמו LSTM). על מספר קבוצות נתונים של רמזים לסיפור ההרגשה של מסמכים, הגישה שלנו מסוף-לסוף צנרת אשר באופן כללי לא מושגת (מלבד קבוצת קטנה של מילים זרע) עוברת גישות לא מושגת קיימות ושיגה מדויקה שווה לאותה של גישות מושגת לחלוטין.</abstract_he>
      <abstract_bo>sentiment signals as pseudo-labeled examples to train a document sentiment classifier v ia supervised learning algorithms (such as LSTM). On several benchmark datasets for document sentiment classification, our end-to-end pipelined approach which is overall unsupervised (except for a tiny set of words) outperforms existing unsupervised approaches and achieves an accuracy comparable to that of fully supervised approaches.</abstract_bo>
      </paper>
    <paper id="22">
      <title>Leveraging Orthographic Similarity for Multilingual Neural Transliteration</title>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <author><first>Mitesh</first><last>Khapra</last></author>
      <author><first>Gurneet</first><last>Singh</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <doi>10.1162/tacl_a_00022</doi>
      <abstract>We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of <a href="https://en.wikipedia.org/wiki/Multitask_learning">multitask learning</a>, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a> involving related <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> i.e., <a href="https://en.wikipedia.org/wiki/Language_family">languages sharing writing systems</a> and <a href="https://en.wikipedia.org/wiki/Phoneme">phonetic properties</a> (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58 % across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages / language pairs not encountered during training and hence perform well on the zeroshot transliteration task. We show that further improvements can be achieved by using phonetic feature input.</abstract>
      <pages>303–316</pages>
      <url hash="09cbdbd7">Q18-1022</url>
      <bibkey>kunchukuttan-etal-2018-leveraging</bibkey>
    <title_ar>الاستفادة من التشابه الهجائي للترجمة العصبية متعددة اللغات</title_ar>
      <title_fr>Exploiter la similitude orthographique pour la translittération neuronale multilingue</title_fr>
      <title_es>Aprovechamiento de la similitud ortográfica para la transliteración neuronal multilingüe</title_es>
      <title_pt>Aproveitando a semelhança ortográfica para transliteração neural multilíngue</title_pt>
      <title_ja>多言語ニューラル・トランリテレーションのための正書法の類似性の活用</title_ja>
      <title_zh>因正字法相似性多语言神经音译</title_zh>
      <title_hi>बहुभाषी तंत्रिका लिप्यंतरण के लिए ऑर्थोग्राफिक समानता का लाभ उठाना</title_hi>
      <title_ru>Использование орфографического сходства для многоязычной нейронной транслитерации</title_ru>
      <title_ga>Cosúlacht Ortagrafach a Ghiaráil don Traslitriú Néarthach Ilteangach</title_ga>
      <title_hu>Az ortográfiai hasonlóság kihasználása a többnyelvű idegátvitelhez</title_hu>
      <title_ka>Multilingual Neural Transliteration</title_ka>
      <title_el>Αξιοποίηση της ορθογραφικής ομοιότητας για την πολύγλωσση νευρωνική μεταγραφή</title_el>
      <title_kk>Көптілік невралды транслитерациялық ортографикалық ұқсас</title_kk>
      <title_lt>Ortografinio panašumo didinimas daugiakalbei neurologinei transliteracijai</title_lt>
      <title_it>Sfruttare la somiglianza ortografica per la traslitterazione neurale multilingue</title_it>
      <title_mk>Разголемување на православната сличност за мултијазична неурална транслитерација</title_mk>
      <title_ms>Menegang Simulasi Ortografik untuk Transliterasi Neural Berbahasa</title_ms>
      <title_no>Tilhøyrande ortografisk likning for fleirspråk neuraltransliterasjon</title_no>
      <title_pl>Wykorzystanie podobieństwa ortograficznego do wielojęzycznej transliteracji neuronowej</title_pl>
      <title_ml>പല ഭാഷകളുടെ നെയുറല്‍ ട്രാന്‍സ്ട്രാന്‍സ്റ്റരേഷനിനുള്ള ലെവര്‍വരേജിങ് ഓര്‍ട്ടോഗ്രാഫിക് സമമാണ്</title_ml>
      <title_mt>Inżidu s-Similarità Ortografika għat-Trasliterazzjoni Newrali Multilingwi</title_mt>
      <title_mn>Олон хэл мэдрэлийн дамжуулалтын ортографик төстэй</title_mn>
      <title_sr>Uzbudljiva pravoslavna sličnost za višejezičku neuralnu transliteraciju</title_sr>
      <title_si>ගොඩක් භාෂාවක් නිර්මාණය සඳහා ප්‍රතික්‍රියාත්මක සිද්ධතාවය</title_si>
      <title_ta>பல மொழிகளின் நெருக்கல் மாற்றியமைப்புக்கு எழுதிசைப்பொருள் ஒத்தம்</title_ta>
      <title_ro>Valorificarea similitudinii ortografice pentru transliterarea neurală multilingvă</title_ro>
      <title_so>Isu eg qoraalka qoyska ee afka luuqadaha badan</title_so>
      <title_sv>Utnyttja ortografisk likhet för flerspråkig neural translitering</title_sv>
      <title_ur>Multilingual Neural Transliteration for Leveraging Orthographic Similarity</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Đánh giá hiệu lực tương đồng đa ngôn ngữ thần kinh</title_vi>
      <title_bg>Използване на ортографска прилика за многоезична неврална транслитерация</title_bg>
      <title_nl>Gebruik maken van orthografische gelijkenis voor meertalige neurale transliteratie</title_nl>
      <title_da>Udnyttelse af ortografisk lighed til flersproget neural translitering</title_da>
      <title_hr>Uzbudljiva pravoslavna sličnost za višejezičku nervnu transliteraciju</title_hr>
      <title_id>Meningkatkan Simulasi Ortografis untuk Transliterasi Neural Berbahasa</title_id>
      <title_de>Nutzung orthographischer Ähnlichkeit für mehrsprachige neuronale Transliteration</title_de>
      <title_ko>정교 유사성을 이용하여 다언어 신경 음역을 진행하다</title_ko>
      <title_tr>Çoklu dilli näyral terjime etmek üçin süsleme Ortografiýasy</title_tr>
      <title_sw>Ukumbuzi wa Orthographi wa Utafsiri wa lugha nyingi</title_sw>
      <title_fa>شبیه‌سازی Orthographic برای ترجمه عصبی‌های زیادی زبان</title_fa>
      <title_af>Versterking Ortografiese Ligging vir Multilingual Neurale Transliterasie</title_af>
      <title_am>ትርጉም</title_am>
      <title_az>Çoxlu dil nöral Transliterasyonun Ortografiki Simiları</title_az>
      <title_hy>Բազլեզու նյարդային տրանսգրաֆիա նմանությունը բարձրացնելը</title_hy>
      <title_sq>Duke rritur ngjashmërinë ortografike për transliteracionin neuronal shumëgjuhës</title_sq>
      <title_bn>বহুভাষী নিউরেল অনুবাদের জন্য লেভারেজিং এর অর্থোগ্রাফিক সামান্য</title_bn>
      <title_bs>Uzbudljiva pravoslavna sličnost za multijezičku neuralnu transliteraciju</title_bs>
      <title_ca>Ampliar la Similaritat Ortogràfica de Transliteració Neural Multilingüe</title_ca>
      <title_cs>Využití ortografické podobnosti pro vícejazyčnou neuronovou transliteraci</title_cs>
      <title_et>Ortograafilise sarnasuse kasutamine mitmekeelse neurotransliteratsiooni puhul</title_et>
      <title_fi>Ortografisen samankaltaisuuden hyödyntäminen monikielisessä hermotransliteraatiossa</title_fi>
      <title_jv>Rayakno Simularity Peringgambar kanggo Kemerdekaan Neral</title_jv>
      <title_sk>Izkoriščanje ortografske podobnosti za večjezično nevralno transliteracijo</title_sk>
      <title_he>מעלה דמיון אורתוגרפי לטרנסליטרציה נוירולית רבות</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>སྤྲོ་སྣང་ཉམས་ཅན་གྱི་སྣ་ཚོགས་ཀྱི་དཔེ་རིགས་གནས་སྟངས་ལ་མཉམ་དུ་མཉམ་དུ་གཏོང</title_bo>
      <abstract_ar>نتناول مهمة التدريب المشترك لنماذج التحويل الصوتي لأزواج لغوية متعددة (الترجمة الصوتية متعددة اللغات). هذا مثال على التعلم متعدد المهام ، حيث تستفيد المهام الفردية (الأزواج اللغوية) من مشاركة المعرفة مع المهام ذات الصلة. نحن نركز على الترجمة الصوتية التي تتضمن المهام ذات الصلة ، مثل مشاركة اللغات في أنظمة الكتابة والخصائص الصوتية (اللغات المتشابهة إملائيًا). نقترح نموذجًا معدلًا لفك التشفير والتشفير العصبي يزيد من مشاركة المعلمات عبر أزواج اللغات من أجل زيادة التشابه الإملائي بشكل فعال. نوضح أن التحويل الصوتي متعدد اللغات يتفوق بشكل كبير على الترجمة الصوتية ثنائية اللغة في سيناريوهات مختلفة (متوسط زيادة بنسبة 58٪ عبر مجموعة متنوعة من اللغات التي جربناها). نوضح أيضًا أن نماذج التحويل الصوتي متعددة اللغات يمكن أن تعمم جيدًا على أزواج اللغات / اللغات التي لم تتم مواجهتها أثناء التدريب ، وبالتالي تؤدي أداءً جيدًا في مهمة التحويل الصوتي الصفري. نظهر أنه يمكن تحقيق المزيد من التحسينات باستخدام إدخال الميزات الصوتية.</abstract_ar>
      <abstract_es>Abordamos la tarea de la formación conjunta de modelos de transliteración para múltiples pares de idiomas (transliteración multilingüe). Este es un ejemplo de aprendizaje multitarea, en el que las tareas individuales (combinaciones de idiomas) se benefician de compartir conocimientos con tareas relacionadas. Nos centramos en la transliteración que implica tareas relacionadas, es decir, idiomas que comparten sistemas de escritura y propiedades fonéticas (idiomas ortográficamente similares). Proponemos un modelo de codificador-decodificador neuronal modificado que maximiza el intercambio de parámetros entre pares de idiomas para aprovechar eficazmente la similitud ortográfica. Demostramos que la transliteración multilingüe supera significativamente a la transliteración bilingüe en diferentes escenarios (aumento promedio del 58% en una variedad de idiomas con los que experimentamos). También mostramos que los modelos de transliteración multilingüe pueden generalizarse bien a lenguas/pares de idiomas que no se encuentran durante el entrenamiento y, por lo tanto, funcionan bien en la tarea de transliteración zeroshot. Demostramos que se pueden lograr mejoras adicionales mediante el uso de la entrada de funciones fonéticas.</abstract_es>
      <abstract_fr>Nous abordons la tâche de formation conjointe de modèles de translittération pour plusieurs paires de langues (translittération multilingue). Il s'agit d'un exemple d'apprentissage multitâche, dans lequel les tâches individuelles (paires de langues) bénéficient du partage de connaissances avec des tâches connexes. Nous nous concentrons sur la translittération impliquant des tâches connexes, c'est-à-dire le partage de systèmes d'écriture et de propriétés phonétiques (langues orthographiquement similaires). Nous proposons un modèle encodeur-décodeur neuronal modifié qui maximise le partage des paramètres entre les paires de langues afin de tirer parti efficacement de la similitude orthographique. Nous montrons que la translittération multilingue surpasse largement la translittération bilingue dans différents scénarios (augmentation moyenne de 58 % dans les différentes langues que nous avons expérimentées). Nous montrons également que les modèles de translittération multilingue peuvent bien se généraliser aux couples langues/langues non rencontrés pendant la formation et qu'ils fonctionnent donc bien sur la tâche de translittération zeroshot. Nous montrons que d'autres améliorations peuvent être apportées en utilisant la saisie de caractéristiques phonétiques.</abstract_fr>
      <abstract_pt>Abordamos a tarefa de treinamento conjunto de modelos de transliteração para múltiplos pares de idiomas (transliteração multilíngue). Esta é uma instância de aprendizagem multitarefa, onde tarefas individuais (pares de idiomas) se beneficiam do compartilhamento de conhecimento com tarefas relacionadas. Nós nos concentramos na transliteração envolvendo tarefas relacionadas, ou seja, línguas que compartilham sistemas de escrita e propriedades fonéticas (línguas ortograficamente semelhantes). Propomos um modelo de codificador-decodificador neural modificado que maximiza o compartilhamento de parâmetros entre pares de idiomas para alavancar efetivamente a similaridade ortográfica. Mostramos que a transliteração multilíngue supera significativamente a transliteração bilíngue em diferentes cenários (aumento médio de 58% em vários idiomas que experimentamos). Também mostramos que os modelos de transliteração multilíngue podem generalizar bem para idiomas/pares de idiomas não encontrados durante o treinamento e, portanto, têm um bom desempenho na tarefa de transliteração zeroshot. Mostramos que outras melhorias podem ser alcançadas usando a entrada de recurso fonético.</abstract_pt>
      <abstract_ru>Мы решаем задачу совместного обучения моделей транслитерации для нескольких языковых пар (многоязычная транслитерация). Это пример многозадачного обучения, когда отдельные задачи (языковые пары) извлекают выгоду из обмена знаниями со связанными задачами. Мы фокусируемся на транслитерации, включающей в себя связанные задачи, то есть языки, совместно использующие системы письма и фонетические свойства (орфографически похожие языки). Мы предлагаем модифицированную модель нейронный кодер-декодер, которая максимизирует обмен параметрами между языковыми парами, чтобы эффективно использовать ортографическое сходство. Мы показываем, что многоязычная транслитерация значительно превосходит двуязычную транслитерацию в различных сценариях (среднее увеличение на 58% для различных языков, с которыми мы экспериментировали). Мы также показываем, что многоязычные модели транслитерации могут хорошо обобщать языки/языковые пары, не встречающиеся во время обучения, и, следовательно, хорошо выполнять задачу нулевой транслитерации. Мы показываем, что дальнейшие улучшения могут быть достигнуты с помощью ввода фонетических признаков.</abstract_ru>
      <abstract_zh>解联训练数语音译(多言音译)之任。 此多任务学之一实也,其一务也(言)益与事共之。 注相关之音译,共书系统语音属性之言(正字法相似之语)。 吾建一神经编码器-解码器,可以大言参数共之,而利用正交相似性。 多言音译显优于双语音译(诸语均增58%)。 又明言语音译模形可善推及未遇语言/对,故于零速音译务为善。 我们明白,因为用语音特征输入可以成就改进。</abstract_zh>
      <abstract_ja>私たちは、複数の言語ペアのための音訳モデルの共同トレーニング（多言語音訳）の課題に取り組んでいます。 これはマルチタスク学習の例であり、個々のタスク（言語ペア）が関連するタスクと知識を共有することで利益を得ます。 関連するタスク、すなわち、ライティングシステムと音声特性を共有する言語（正書法的に類似した言語）に関わる翻訳に焦点を当てています。 我々は、オルソグラフィの類似性を効果的に活用するために、言語ペア間のパラメータ共有を最大化する修正されたニューラルエンコーダデコーダモデルを提案する。 多言語音訳は、さまざまなシナリオでバイリンガル音訳よりも著しく優れていることが示されています（私たちが実験したさまざまな言語で平均58 ％の増加）。 また、多言語音訳モデルは、トレーニング中に遭遇しなかった言語/言語ペアにうまく一般化することができ、したがって、ゼロショット音訳タスクでうまく機能することも示されている。 音声特徴入力を使用することで、さらなる改善が可能であることを示しています。</abstract_ja>
      <abstract_hi>हम एकाधिक भाषा जोड़े (बहुभाषी लिप्यंतरण) के लिए लिप्यंतरण मॉडल के संयुक्त प्रशिक्षण के कार्य को संबोधित करते हैं। यह मल्टीटास्क सीखने का एक उदाहरण है, जहां व्यक्तिगत कार्य (भाषा जोड़े) संबंधित कार्यों के साथ ज्ञान साझा करने से लाभान्वित होते हैं। हम संबंधित कार्यों को शामिल करने वाले लिप्यंतरण पर ध्यान केंद्रित करते हैं, यानी लेखन प्रणालियों और ध्वन्यात्मक गुणों को साझा करने वाली भाषाएं (ऑर्थोग्राफिक रूप से समान भाषाएं)। हम एक संशोधित तंत्रिका एन्कोडर-डिकोडर मॉडल का प्रस्ताव करते हैं जो ऑर्थोग्राफिक समानता का प्रभावी ढंग से लाभ उठाने के लिए भाषा जोड़े में पैरामीटर साझाकरण को अधिकतम करता है। हम दिखाते हैं कि बहुभाषी लिप्यंतरण विभिन्न परिदृश्यों में द्विभाषी लिप्यंतरण को काफी हद तक बेहतर बनाता है (विभिन्न भाषाओं में 58% की औसत वृद्धि जिसके साथ हमने प्रयोग किया था)। हम यह भी दिखाते हैं कि बहुभाषी लिप्यंतरण मॉडल प्रशिक्षण के दौरान सामना नहीं की जाने वाली भाषाओं / भाषा जोड़े के लिए अच्छी तरह से सामान्यीकृत कर सकते हैं और इसलिए शून्य शॉट लिप्यंतरण कार्य पर अच्छा प्रदर्शन करते हैं। हम दिखाते हैं कि ध्वन्यात्मक सुविधा इनपुट का उपयोग करके आगे सुधार प्राप्त किए जा सकते हैं।</abstract_hi>
      <abstract_ga>Tugaimid aghaidh ar an tasc a bhaineann le comhoiliúint a dhéanamh ar mhúnlaí traslitrithe do phéirí iltheangacha (traslitriú ilteangach). Is sampla é seo d’fhoghlaim ilthasc, ina mbaineann tascanna aonair (beirteanna teanga) leas as eolas a roinnt le tascanna gaolmhara. Dírímid ar thraslitriú a bhaineann le tascanna gaolmhara .i., teangacha ag roinnt córais scríbhneoireachta agus airíonna foghraíochta (teangacha atá cosúil le hordagrafaíocht). Molaimid múnla néarchódóra-díchódóra modhnaithe a uasmhéadaíonn comhroinnt paraiméadar trasna péirí teangacha chun cosúlacht ortagrafach a ghiaráil go héifeachtach. Léirímid go sáraíonn traslitriú ilteangach traslitriú dátheangach i gcásanna éagsúla (meánmhéadú 58% thar na teangacha éagsúla a ndearnamar triail astu). Léirímid freisin gur féidir le samhlacha traslitrithe ilteangacha ginearálú maith a dhéanamh ar theangacha/beirteanna teangacha nár aimsíodh le linn na hoiliúna agus go n-éiríonn leo go maith mar sin ar an tasc traslitrithe náid. Léirímid gur féidir tuilleadh feabhsuithe a bhaint amach trí úsáid a bhaint as ionchur gné foghraíochta.</abstract_ga>
      <abstract_el>Αντιμετωπίζουμε το έργο της κοινής κατάρτισης μοντέλων μεταγραφής για πολλαπλά γλωσσικά ζεύγη (πολύγλωσση μεταγραφή). Πρόκειται για μια περίπτωση εκμάθησης πολλαπλών εργασιών, όπου μεμονωμένες εργασίες (γλωσσικά ζεύγη) επωφελούνται από την ανταλλαγή γνώσεων με συναφείς εργασίες. Εστιάζουμε στην μεταγραφή που περιλαμβάνει συναφείς εργασίες, δηλαδή γλώσσες που μοιράζονται συστήματα γραφής και φωνητικές ιδιότητες (ορθογραφικά παρόμοιες γλώσσες). Προτείνουμε ένα τροποποιημένο μοντέλο νευρικού κωδικοποιητή-αποκωδικοποιητή που μεγιστοποιεί την κατανομή παραμέτρων μεταξύ γλωσσικών ζευγαριών προκειμένου να αξιοποιήσει αποτελεσματικά την ορθογραφική ομοιότητα. Δείχνουμε ότι η πολύγλωσση μεταγραφή ξεπερνά σημαντικά τη δίγλωσση μεταγραφή σε διαφορετικά σενάρια (μέση αύξηση 58% σε μια ποικιλία γλωσσών με τις οποίες πειραματιζόμασταν). Δείχνουμε επίσης ότι τα πολύγλωσσα μοντέλα μεταγραφής μπορούν να γενικεύσουν καλά σε ζεύγη γλωσσών/γλωσσών που δεν συναντήθηκαν κατά τη διάρκεια της εκπαίδευσης και ως εκ τούτου να επιτελέσουν καλά στην εργασία μεταγραφής zeroshot. Δείχνουμε ότι περαιτέρω βελτιώσεις μπορούν να επιτευχθούν με τη χρήση φωνητικών χαρακτηριστικών εισόδου.</abstract_el>
      <abstract_kk>Біз бірнеше тіл екеуі (көп тілді транслитерация) үлгілерінің біріктірілген оқыту үлгілерінің тапсырмасын жасаймыз. Бұл көптеген тапсырмаларды оқыту мысалы. Бұл жеке тапсырмалар (тіл екеуі) білімдерді қатынасыз тапсырмаларды ортақтастыруға мүмкіндік береді. Мысалы, жазу жүйелерін және фонетикалық қасиеттерді ортақтастыру тілдері (ортографикалық ұқсас тілдері) қатынау үшін көздейтік. Біз өзгертілген невралдық кодер- декодер үлгісін таңдаймыз. Ортографиялық ұқсастығын көтеру үшін параметрлерді тілдерді ортақтастыру үшін көтерілген невралдық кодер- декодер Біз көптеген тілдердің транслитерациясы әртүрлі сценарияларда екі тілдердің транслитерациясының көптеген жолын көрсетедік (біз тәжірибедік тілдердің орташа 58% көтеріп жатыр). Мұндай-ақ біз бірнеше тілді транслитерация үлгілері оқыту кезінде тілдер/тілдер екісіне жақсы жасай алады. Сондай-ақ Zeroshot транслитерация тапсырмасында жақсы жұмыс істейді. Біз фонетикалық мүмкіндіктерді қолдану арқылы жақсы жақсартуларды жеткізе аламыз.</abstract_kk>
      <abstract_hu>Több nyelvpárra vonatkozó transzliterációs modellek közös képzésével foglalkozunk (többnyelvű transzliteráció). Ez a többfeladatú tanulás példája, ahol az egyes feladatok (nyelvpárok) előnyös az ismeretek megosztása a kapcsolódó feladatokkal. A kapcsolódó feladatokat magában foglaló transzliterációra összpontosítunk, írási rendszereket és fonetikai tulajdonságokat megosztó nyelvekre (ortográfiailag hasonló nyelvek). Javasolunk egy módosított neurális kódoló-dekódoló modellt, amely maximalizálja a paraméterek megosztását a nyelvpárok között annak érdekében, hogy hatékonyan kihasználja az ortográfiai hasonlóságot. Megmutatjuk, hogy a többnyelvű transzliteráció jelentősen felülmúlja a kétnyelvű transzliterációt különböző forgatókönyvekben (átlagosan 58%-os növekedés számos nyelven, amikkel kísérleteztünk). Azt is megmutatjuk, hogy a többnyelvű transzliterációs modellek jól általánosíthatók a képzés során nem tapasztalható nyelvek/nyelvpárokra, így jól teljesítenek a nulloshot transzliterációs feladaton. Megmutatjuk, hogy további fejlesztések érhetők el a fonetikai funkciók bevitelével.</abstract_hu>
      <abstract_ka>ჩვენ განვითარებთ ტრანსლიტაციის მოდელების ერთადერთი განაკლების დავალება მრავალენგური ტრანსლიტაციაზე (მრავალენგური ტრანსლიტაციაში). ეს არის მრავალ დავალების სწავლების თენსტაცია, სადაც ინდიველური დავალებები (ენერგიის ზოგები) გამოიყენებენ ცოდნიერების გაყოფილი დავალებებით. ჩვენ ტრანსლიტაციის ფონსკურება, რომელიც შესახებ დაკავშირებული დავალებებით, მაგალითად, ენების გაყოფილი სისტემი და ფონეტიკური განსაზღვრებები (ორტოგრაფიურად ჩვენ მოვეხსენებთ შეცვლელი ნეიროლური კოდერის რეკოდერის მოდელს, რომელიც მაქსიმიზებს პარამეტრების გაყოფილი ენის ზოგების გარეშე, რომელიც ეფექტიურად ორტოგრაფიკური განს ჩვენ ჩვენ გამოჩვენებთ, რომ მრავალენგური ტრანსლიტრაცია ძალიან უფრო მნიშვნელოვანია ორიენგური ტრანსლიტრაცია განსხვავებული სინარიოში (სინამდვილეში 58% უფრო მეტი წარმო ჩვენ ასევე ჩვენ აჩვენებთ, რომ მრავალენგური ტრანსლიტაციის მოდელები შეუძლიათ წარმოიდგინოთ ენები/ენგური ზოგები, რომლებიც არ შეიძლია განაკეთებული განაკეთებაში და ამიტომ ჩვენ ჩვენ აჩვენებთ, რომ უფრო მეტი უფრო მეტადება შეიძლება გავაკეთოთ ფონეტიკური ფუნეტიკური მონაცემებით.</abstract_ka>
      <abstract_lt>Mes sprendžiame užduotį, susijusią su bendru transliteracijos modelių mokymu daugiakalbėms poroms (daugiakalbei transliteracijai). Tai yra daugiafunkcinio mokymosi atvejis, kai atskiroms užduotims (kalbų poroms) naudinga dalintis žiniomis su susijusiomis užduotimis. Mes daugiausia dėmesio skiriame transliteracijai, susijusiai su susijusiomis užduotimis, t. y. kalbomis, kuriose dalijamasi rašymo sistemomis ir fonetinėmis savybėmis (ortografiškai panašiomis kalbomis). Siūlome pakeistą neurologinio kodavimo kodavimo model į, kuris maksimaliai padidina parametrų pasidalijimą kalbų poromis, kad būtų veiksmingai naudojamas ortografinis panašumas. Mes rodome, kad daugiakalbė transliteracija žymiai viršija dvikalbę transliteraciją įvairiais scenarijais (vidutiniškai 58 proc. padidėjo įvairiose kalbose, su kuriomis eksperimentavome). Taip pat rodome, kad daugiakalbiai transliteracijos modeliai gali gerai paplitti kalboms ir (arba) kalbų poroms, su kuriomis mokymo metu nenustatyta, ir taip gerai atlikti nulinės transliteracijos užduotį. Mes parodome, kad tolesnius patobulinimus galima pasiekti naudojant fonetines savybes.</abstract_lt>
      <abstract_mk>Ние ја решаваме задачата на заедничка обука на транслитературни модели за повеќе јазички парови (мултијазичка транслитература). Ова е пример на мултизадачно учење, каде индивидуалните задачи (парови на јазици) имаат корист од споделувањето на знаење со поврзаните задачи. Ние се фокусираме на транслитерацијата која вклучува поврзани задачи, т.е. јазици кои споделуваат пишувачки системи и фонетски сопствености (ортографски слични јазици). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity.  We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58% across a variety of languages we experimented with).  Исто така покажуваме дека мултијазичните транслитерациски модели можат да се генерализираат добро на јазици/јазични парови кои не се соочуваат за време на обуката и со тоа добро се вршат со задачата за транслитерација на нула. Покажуваме дека понатамошни подобрувања може да се постигнат со користење на внесување на фонетички карактеристики.</abstract_mk>
      <abstract_it>Ci occupiamo della formazione congiunta di modelli di traslitterazione per coppie linguistiche multiple (traslitterazione multilingue). Si tratta di un esempio di apprendimento multitasking, in cui i singoli compiti (coppie linguistiche) traggono vantaggio dalla condivisione delle conoscenze con compiti correlati. Ci concentriamo sulla traslitterazione che coinvolge attività correlate, ad esempio lingue che condividono sistemi di scrittura e proprietà fonetiche (lingue ortograficamente simili). Proponiamo un modello codificatore neurale modificato che massimizza la condivisione dei parametri tra le coppie linguistiche al fine di sfruttare efficacemente la somiglianza ortografica. Mostriamo che la traslitterazione multilingue supera significativamente la traslitterazione bilingue in diversi scenari (aumento medio del 58% in una varietà di lingue con cui abbiamo sperimentato). Mostriamo anche che i modelli di traslitterazione multilingue possono generalizzare bene alle coppie lingue/lingue non incontrate durante la formazione e quindi eseguire bene il compito di traslitterazione zeroshot. Mostriamo che è possibile ottenere ulteriori miglioramenti utilizzando l'input fonetico delle funzionalità.</abstract_it>
      <abstract_mt>Aħna nindirizzaw il-kompitu ta’ taħriġ konġunt ta’ mudelli ta’ traslitterazzjoni għal par ta’ lingwi multipli (traslitterazzjoni multilingwi). Dan huwa eżempju ta’ tagħlim multikompiti, fejn kompiti individwali (pari lingwistiċi) jibbenefikaw mill-kondiviżjoni tal-għarfien ma’ kompiti relatati. Aħna niffokaw fuq it-traslitterazzjoni li tinvolvi kompiti relatati, jiġifieri l-lingwi li jaqsmu s-sistemi tal-kitba u l-proprjetajiet fonetiċi (lingwi ortografikament simili). Aħna nipproponu mudell modifikat ta’ kodifikatur newrali li jimmassimizza l-qsim tal-parametri bejn il-pari lingwistiċi sabiex b’mod effettiv tiġi sfruttata s-similarità ortografika. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58% across a variety of languages we experimented with).  Aħna nuru wkoll li mudelli ta’ traslitterazzjoni multilingwi jistgħu jiġġeneralizzaw tajjeb għal lingwi/pari ta’ lingwi li ma nstabux waqt it-taħriġ u għalhekk iwettqu tajjeb il-kompitu ta’ traslitterazzjoni żero. Aħna nuru li jista’ jinkiseb aktar titjib bl-użu ta’ input ta’ karatteristiċi fonetiċi.</abstract_mt>
      <abstract_mn>Бид олон хэл хоёр (олон хэл хэлний орчуулах) загварын нэгдсэн сургалтын дасгал загварыг удирдаж байна. Энэ бол олон ажлын сургалтын жишээ. Хувь ажил (хэл хоёр) нь мэдлэгийг холбоотой ажилтай хуваалцах хэрэгтэй. Бид харилцааны үйл ажиллагааг хуваалцах хэл, фонетик чанар (ортографик төстэй хэл) дээр анхаарлаа хандуулдаг. Бид өөрчлөгдсөн мэдрэлийн коддогч загварын загварыг санал дэвшүүлнэ. Энэ нь хэл хоорондоо параметр хуваалцахын тулд ортографик тэнцүү байдлыг эффективно ашиглах боломжтой. Бид олон хэлний орчуулалт олон хэлний орчуулалт өөр хувилбарт хоёр хэлний орчуулалт илүү чухал байдаг гэдгийг харуулж байна. Бид мөн олон хэл хэлний орчуулах загварууд суралцах үед харилцаагүй хэл/хэл хооронд сайн нийтлэгддэг болохоор zeroshot орчуулах үйл ажилд сайн ажиллаж чадна. Бид илүү сайжруулалт гаргаж чадна гэдгийг харуулж байна.</abstract_mn>
      <abstract_ml>പല ഭാഷകളുടെ ജോടികള്‍ക്ക് വേണ്ടി ട്രാന്‍സ്ലിറ്റരേഷന്‍ മോഡലുകള്‍ക്കുള്ള യൂട്ടിലേറ്റ് ട്രാന്‍സ്റ്റെ വ്യക്തിപരമായ ജോലികളുടെ ജോലി (ഭാഷ ജോട്ടി) അറിവ് പങ്കുവെക്കുന്നതില്‍ നിന്നും വ്യക്തിപ്പെട്ട ജോലികള്‍ ഉപകരിക് നമ്മള്‍ ബന്ധപ്പെട്ട ജോലികളുടെ കൂട്ടത്തിലുള്ള ട്രാന്‍സ്ട്രാന്‍സ്റ്റലേഷന്‍ ചെയ്യുന്നതിനെപ്പറ്റി ശ്രദ്ധിക്കുന്ന നിര്‍മ്മിക്കപ്പെട്ട നെയൂറല്‍ കോഡെര്‍ ഡെകോഡെര്‍ മോഡല്‍ ഞങ്ങള്‍ പ്രൊദാനം ചെയ്യുന്നു. അത് ഭാഷ ജോട്ടുകാരില്‍ പങ്കുചേര്‍ക്കുന്ന നമ്മള്‍ കാണിക്കുന്നു പല ഭാഷകങ്ങളുടെ ട്രാന്‍സ്ലൈറ്റരേഷന്‍ വ്യത്യസ്ത ഭാഷകളില്‍ രണ്ടു ഭാഷകങ്ങളുടെ ട്രാന്‍സ്ലിറ്റരേഷന്‍ പ്രധാന We also show that multilingual transliteration models can generalize well to languages/language pairs not encountered during training and hence perform well on the zeroshot transliteration task.  ഫോണെറ്റിക് വിശേഷതകളുടെ ഇന്‍പുട്ട് ഉപയോഗിച്ച് കൂടുതല്‍ മെച്ചപ്പെടുത്താന്‍ സാധിക്കുന്നു</abstract_ml>
      <abstract_pl>Zajmujemy się zadaniem wspólnego szkolenia modeli transliteracyjnych dla par językowych (transliteracja wielojęzyczna). Jest to przykład wielozadaniowego uczenia się, gdzie indywidualne zadania (pary językowe) korzystają z dzielenia się wiedzą z powiązanymi zadaniami. Koncentrujemy się na transliteracji z powiązanymi zadaniami tj. językami współdzielącymi systemy pisania i właściwościami fonetycznymi (ortograficznie podobnymi językami). Proponujemy zmodyfikowany model kodera-dekodera neuronowego, który maksymalizuje współdzielenie parametrów między parami językowymi w celu skutecznego wykorzystania podobieństwa ortograficznego. Pokazujemy, że transliteracja wielojęzyczna znacznie przewyższa transliterację dwujęzyczną w różnych scenariuszach (średni wzrost 58% w różnych językach, z którymi eksperymentowaliśmy). Pokazujemy również, że wielojęzyczne modele transliteracji mogą dobrze uogólniać języki/pary językowe niespotykane podczas treningu i dzięki temu sprawdzać się dobrze w zadaniu transliteracji zeroshot. Pokazujemy, że dalsze ulepszenia można osiągnąć dzięki wykorzystaniu wejścia funkcji fonetycznych.</abstract_pl>
      <abstract_ro>Ne adresăm sarcinii de formare comună a modelelor de transliterare pentru mai multe perechi de limbi (transliterare multilingvă). Acesta este un exemplu de învățare cu mai multe sarcini, în care sarcinile individuale (perechile de limbi străine) beneficiază de schimbul de cunoștințe cu sarcini conexe. Ne concentrăm pe transliterație care implică sarcini conexe și anume limbile care partajează sisteme de scriere și proprietăți fonetice (limbi ortografice similare). Propunem un model modificat de encoder-decoder neural care maximizează partajarea parametrilor între perechile de limbi pentru a valorifica eficient similitudinea ortografică. Aratăm că transliterația multilingvă depășește semnificativ transliterația bilingvă în diferite scenarii (creștere medie de 58% într-o varietate de limbi cu care am experimentat). De asemenea, arătăm că modelele de transliterare multilingvă pot generaliza bine la perechile de limbi/limbi care nu se întâlnesc în timpul antrenamentului și, prin urmare, performează bine în sarcina de transliterare zeroshot. Noi arătăm că îmbunătățiri suplimentare pot fi realizate prin utilizarea funcțiilor fonetice introduse.</abstract_ro>
      <abstract_ms>Kami menjalankan tugas latihan bersama model transliterasi untuk pasangan bahasa berbilang (transliterasi berbilang bahasa). Ini adalah contoh pembelajaran tugas berbilang, di mana tugas individu (pasangan bahasa) berguna daripada berkongsi pengetahuan dengan tugas berkaitan. Kami fokus pada transliterasi yang melibatkan tugas berkaitan iaitu, bahasa berkongsi sistem tulisan dan ciri-ciri fonetik (bahasa yang sama secara ortografik). Kami cadangkan model pengekod saraf yang diubah suai yang maksimumkan berkongsi parameter di sepanjang pasangan bahasa untuk menggunakan kesamaan ortografik secara efektif. Kami menunjukkan bahawa transliterasi berbilang bahasa secara signifikan melebihi transliterasi dua bahasa dalam skenario yang berbeza (meningkat rata-rata 58% dalam berbagai bahasa yang kami eksperimen dengan). Kami juga menunjukkan bahawa model transliterasi berbilang bahasa boleh menyebarkan dengan baik kepada bahasa/pasangan bahasa yang tidak ditemui semasa latihan dan oleh itu berjalan dengan baik pada tugas transliterasi sifar. Kami menunjukkan bahawa perbaikan lanjut boleh dicapai dengan menggunakan input ciri fonetik.</abstract_ms>
      <abstract_si>අපි බොහොම භාෂාවක් ජෝඩියාව (බොහොම භාෂාවක් වාර්තාවක්) ගැන සම්පූර්ණ ප්‍රශ්නයක් ගැන සම්ප මේක ගොඩක් වැඩක් වැඩක් ඉගෙන ගන්න පුළුවන් උදාහයක්, කොහේද ප්‍රතිකාර වැඩක් (භාෂාවක් ජොඩක්) සම්බ අපි සම්බන්ධ වැඩක් සම්බන්ධ විදියට අනුවිධාන ක්‍රියාව සම්බන්ධ කරනවා කියලා, භාෂාවල් ලියන පද්ධතිය සහ ෆ අපි වෙනස් කරලා තියෙන්නේ න්‍යූරාල් කෝඩාර් කෝඩාර් මොඩේල් එකක් ප්‍රතිචාර කරනවා ඒ වගේම භාෂා ජාතියෙන් ප්‍රතිචාර අපි පෙන්වන්නේ විශේෂ භාෂාව පාරක්‍රියාත්මක විශේෂයෙන් දෙවල් භාෂාව පාරක්‍රියාත්මක විශේෂයෙන් ප්‍රතික්‍රියාත අපි වගේම පෙන්වන්නේ විශේෂ භාෂාවක් වාර්ථාපනය මදුල් හොඳට භාෂාවක්/භාෂාවක් ජාතිකයෙන් හොඳට සාමාන්‍ය විදිහට ස අපි පෙන්වන්නේ වැඩි වැඩි වැඩි ප්‍රවෘත්තියක් ප්‍රවෘත්තිය කරන්න පුළුවන් කියලා.</abstract_si>
      <abstract_no>Vi adresserer oppgåva til kopla trening av transliterasjonsmodeller for fleire språkopar (fleirspråk transliterasjon). Dette er ein instans av å læra fleire oppgåver, der individuelle oppgåver (språkopar) nyttar frå å dele kunnskap med relaterte oppgåver. Vi fokuserer på transliterasjon med tilhøyrande oppgåver, t.d. språk som deler skrivesystemet og fonetiske eigenskapar (ortografisk liknande språk). Vi foreslår eit endra neuralkoderingsmodell som maksimerer deling av parametrar over språkparar for å levera ortografisk likning effektivt. Vi viser at fleirspråkstransliterasjonen utfører bilingbokstavering i ulike scenarior (gjennomsnittlig økning av 58% på ulike språk vi eksperimenterte med). Vi viser også at fleirspråk-transliterasjonsmodeller kan generellisere bra til språk/språk-par som ikkje oppstod under opplæring og derfor utføra bra på nuloshot-transliterasjonsoppgåva. Vi viser at meir forbedringar kan oppnå ved å bruka inndata frå fonetiske funksjonar.</abstract_no>
      <abstract_sv>Vi behandlar uppgiften att gemensamt utbilda transliterationsmodeller för flera språkpar (flerspråkig transliteration). Detta är ett exempel på multitasking lärande, där enskilda uppgifter (språkpar) drar nytta av att dela kunskap med relaterade uppgifter. Vi fokuserar på transliteration med relaterade uppgifter, dvs språk som delar skrivsystem och fonetiska egenskaper (ortografiskt liknande språk). Vi föreslår en modifierad neural encoder-dekoder modell som maximerar parameterdelning mellan språkpar för att effektivt utnyttja ortografisk likhet. Vi visar att flerspråkig transliteration avsevärt överträffar tvåspråkig transliteration i olika scenarier (genomsnittlig ökning på 58% över en mängd olika språk vi experimenterade med). Vi visar också att flerspråkiga translitterationsmodeller kan generalisera väl till språk/språkpar som inte påträffas under träning och därmed presterar bra på zeroshot translitterationsuppgiften. Vi visar att ytterligare förbättringar kan uppnås genom att använda fonetiska funktioner inmatning.</abstract_sv>
      <abstract_ta>நாம் பல மொழி ஜோடிகளுக்கு இணைய பயிற்சி மாதிரிகளின் செயலை முகவரிக்கிறோம் (பல மொழி மொழி மாற்றியமை). இது பல விருப்பங்களின் உதாரணத்தாகும், அங்கு தனிப்பட்ட பணிகள் (மொழி ஜோடி) தொடர்பு பணிகளுடன் அறிவை பகிர்ந்து கொள்ளும்  தொடர்புடைய பணிகளைச் சேர்த்து மாற்றுதலை நாம் கவனம் செலுத்துகிறோம், அதாவது, மொழிகள் எழுதும் முறைமைகளையும் போன்டெடிக் க நாம் மாற்றப்பட்ட புதிய குறியீட்டாளர் மாதிரியை பரிந்துரைக்கிறோம். அது மொழி ஜோடிகளுக்கு மேல் பகிர்ந்த அளவுருவை பெரிதாக்குக பல மொழி மொழிபெயர்ப்பு மாற்றுதல் முக்கியமாக வெவ்வேறு காட்சிகளில் இரு மொழியை மாற்றுகிறது (நாம் பரிசோதித்துக் கொண்ட பல மொழிகளில்  We also show that multilingual transliteration models can generalize well to languages/language pairs not encountered during training and hence perform well on the zeroshot transliteration task.  நாம் காண்பிக்கிறோம் அதிக முன்னேற்றங்கள் போன்டிக் குணங்கள் உள்ளீட்டை பயன்படுத்தி முடியும்.</abstract_ta>
      <abstract_sr>Mi obraćamo zadatak zajedničkog treninga modela transliteracije za višestruke jezičke parove (multilingual transliteration). Ovo je primjer učenja multitaska, gdje individualni zadatak (parovi jezika) koristi od dijeljenja znanja sa povezanim zadatacima. Fokusiramo se na transliteraciju uključujući povezane zadatke, tj. jezike koji dijele pismene sisteme i fonetičke vlasništvo (ortografski slične jezike). Predlažemo modificirani model neuralnog kodera koji maksimalizuje podeljenje parametara preko parova jezika kako bi učinkovito uticalo na ortografsku sličnost. Pokazujemo da multijezička transliteracija značajno iznosi dvojezičku transliteraciju u različitim scenarijama (prosjeèno povećanje od 58% na raznim jezicima s kojima smo eksperimentirali). Također pokazujemo da multijezički modeli transliteracije mogu dobro generalizirati na jezike/jezičke pare koje se ne susreću tokom treninga i stoga dobro izvršavaju na zadatku za transliteraciju zerošota. Pokazujemo da se dodatno poboljšanje može ostvariti koristeći fonetički ulaz.</abstract_sr>
      <abstract_ur>ہم بہت سی زبان جوڑوں کے لئے (بہت سی زبان ترنسلیٹر کے) ترنسلیٹ موڈل کے جوڑے کی تعلیم کے ساتھ مشترک تعلیم کی کوشش کرتے ہیں۔ یہ ایک مثال ملتی تاسک کی تعلیم ہے جہاں تک تک تک تک تک تک تک تک علم کے ساتھ ملنے سے فائدہ اٹھائے جاتے ہیں۔ ہم اس طرح تغییر لکھنے پر تمرکز کریں گے جس طرح ارتباط کے کام ہیں، یعنی لکھنے کی سیسٹم اور فونیٹی ویژگی (اورٹوگرافیک طرح طرح کی زبانیں)۔ ہم ایک modified neural encoder-decoder Model پیشنهاد کرتے ہیں جو پارامیٹر کو زبان جوڑوں میں تقسیم کرنے کے لئے عمدہ طور پر آراٹوگرافیکی برابری کے ذریعہ مکمل کرتا ہے۔ ہم دکھاتے ہیں کہ بہت سی زبان کی ٹرنسلیٹریٹریٹریٹریٹریٹریٹ دو زبان کی ٹرنسلیٹریٹ مختلف سناریوں میں زیادہ اضافہ کرتی ہے ہم بھی دکھاتے ہیں کہ بہت سی زبان ترنسلیٹ موڈل زبان/زبان جوڑوں کو اچھی طرح آسان کر سکتے ہیں جبکہ تدریس کے وقت نہیں ملتے اور اس کے بعد صفر ترنسلیٹ کے کام پر اچھی طرح عمل کرتے ہیں. ہم دکھاتے ہیں کہ اضافہ تغییرات فانی اپنا انپیٹ استعمال کرکے پہنچ سکتے ہیں.</abstract_ur>
      <abstract_so>Shaqada wadajirka ah ayaannu ku sheekeynaynaa tusaale ahaan turjumista noocyada kala duduwan (turjumista luuqadaha kala duduwan). Waa tusaale ahaan waxbarashada waxbarashada kala duduwan, kaas oo shaqooyinka shakhsi ah (labo luqad) faa’iido ka leh sharciga aqoonta shaqada la xiriira. Waxaynu ku kalsoonaynaa qoraalka shaqaalaha la xiriira, tusaale ahaan luuqadaha lagu sharrajiyo nidaamka qoraalka iyo xuquuqda telefonetka (habaarka u eg luuqadaha). Waxaan soo jeedaynaa tusaale qodeynta neurada oo beddelan, kaas oo si faa’iido ah u kala qaybsada parameter oo ku saabsan labada labood oo luqada ah, si ay u faa’iido u bixiso ortografikada. Waxaynu muujinnaa in turjumista luuqadaha kala duduwan ay si weyn u sameeyaan kala duwan oo kala duduwan kala duduwan (ugu badnaan kordha 58% oo ku qoran luqado kala duduwan oo aan ku tijaabiyey). Sidoo kale waxaynu tusnaynaa in qaababka kala faa'iidada luuqadaha kala duduwan ay si wanaagsan u sameyn karaan labo luqad/luuqad oo aan la kulmin xilliga waxbarashada islamarkaasna ay si wanaagsan u sameyn karaan shaqada tarjumista zero. Waxaynu muujinnaa in horumarinta dheeraadka ah lagu sameyn karo isticmaalka internetka.</abstract_so>
      <abstract_uz>Biz bir necha tillar ikkita xil (ko'plab tillar tarjima qilish) uchun bir necha xil tilning bir xil o'lchamini bajaramiz. Bu bir misol, bir xil vazifalar (tillar parchalari) bilan bog'liq vazifalar bilan ta'limni qaytadan foydalanadi. Biz bog'liq vazifalar bilan tarjima qilishga foydalanamiz, balki tillar yozish tizimlarini va fonetik xossalarini (orthografikda o'xshash tillar) bilan bog'liq o'zgarishga qaramaymiz. Biz o'zgartirilgan neyron kodkodlash modelini tahrirlash mumkin. Oddiy ortografik likligini ishlab chiqarish uchun parametrlarni ko'paytirish mumkin. Biz ko'pchilik tili tarjima qilishni ko'rsatamiz, har xil tilda ikkita tarjima tarjima qilishni ko'rsatadi (biz o'rganilgan har xil tillarda 58% dan foydalanadi). Biz ko'pchilik tillar tarjima modellarini tajriba qilayotganda ko'p tillar/tillar parchaga yaxshi narsa yaratish mumkin va shunday qilib zeroshot tarjima qilish vazifasida yaxshi bajarishi mumkin. Ko'rsatishimiz mumkin, fonetik foydalanuvchi foydalanishi mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi đề cập đến nhiệm vụ huấn luyện chung các mô hình chuyển dạng cho các cặp ngôn ngữ đa dạng. Đây là một trường hợp nghiên cứu đa nhiệm vụ, nơi các công việc cá nhân (cặp ngôn ngữ) được hưởng từ việc chia sẻ kiến thức với các công việc liên quan. Chúng tôi tập trung vào chuyển dạng liên quan đến các công việc liên quan, ví dụ, các ngôn ngữ chia sẻ các hệ thống chữ và di sản. Chúng tôi đề xuất một mô hình mã hóa thần kinh đã được sửa đổi để tối ưu hóa các tham số chia sẻ qua các cặp ngôn ngữ để có hiệu lực giống nhau. Chúng tôi cho thấy khả năng chuyển dạng ngôn ngữ rộng lớn vượt trội khả năng chuyển dạng hai thứ trong các tình huống khác nhau (tăng số trung bình 58=) trong các ngôn ngữ khác nhau chúng tôi thí nghiệm). Chúng tôi cũng cho thấy các mô hình chuyển dạng đa dạng có thể tổng hợp tốt với các cặp ngôn ngữ không thể gặp trong khi tập luyện và làm việc tốt trong nhiệm vụ chuyển chữ không phù hợp. Chúng tôi cho thấy có thể cải tiến thêm bằng cách dùng nội dung điện thoại.</abstract_vi>
      <abstract_nl>We behandelen de taak van gezamenlijke training van transliteratiemodellen voor meerdere taalparen (meertalige transliteratie). Dit is een voorbeeld van multitask leren, waarbij individuele taken (taalparen) profiteren van het delen van kennis met gerelateerde taken. We richten ons op transliteratie met gerelateerde taken, d.w.z. talen die schrijfsystemen en fonetische eigenschappen delen (orthografisch vergelijkbare talen). We stellen een aangepast neuraal encoder-decoder model voor dat het delen van parameters tussen taalparen maximaliseert om orthografische gelijkenis effectief te benutten. We laten zien dat meertalige transliteratie aanzienlijk beter presteert dan tweetalige transliteratie in verschillende scenario's (gemiddelde toename van 58% in een verscheidenheid van talen waarmee we experimenteerden). We laten ook zien dat meertalige transliteratiemodellen goed kunnen generaliseren naar talen/taalparen die niet tijdens de training zijn tegengekomen en dus goed presteren bij de zeroshot transliteratie taak. We laten zien dat verdere verbeteringen kunnen worden bereikt door gebruik te maken van fonetische feature input.</abstract_nl>
      <abstract_da>Vi tager os af opgaven med fælles træning af transliterationsmodeller for flere sprogpar (flersproget transliteration). Dette er et eksempel på multitasking learning, hvor individuelle opgaver (sprogpar) har gavn af at dele viden med relaterede opgaver. Vi fokuserer på translitteration, der involverer relaterede opgaver, dvs. sprog, der deler skrivesystemer og fonetiske egenskaber (ortografisk lignende sprog). Vi foreslår en modificeret neural encoder-dekoder model, der maksimerer parameterdeling på tværs af sprogpar for effektivt at udnytte ortografisk lighed. Vi viser, at flersproget transliteration betydeligt overgår tosproget transliteration i forskellige scenarier (gennemsnitlig stigning på 58% på tværs af en række sprog, vi eksperimenterede med). Vi viser også, at flersprogede translitterationsmodeller kan generalisere godt til sprog/sprogpar, der ikke er stødt på under træning og dermed fungere godt på Zeroshot translitterationsopgaven. Vi viser, at yderligere forbedringer kan opnås ved at bruge fonetiske funktioner input.</abstract_da>
      <abstract_bg>Ние разглеждаме задачата за съвместно обучение на транслитерационни модели за множество езикови двойки (многоезична транслитерация). Това е пример за многозадачно обучение, при което индивидуалните задачи (езикови двойки) се възползват от споделянето на знания със свързани задачи. Фокусираме се върху транслитерацията, включваща свързани задачи, т.е. езици, споделящи системи за писане и фонетични свойства (ортографски подобни езици). Предлагаме модифициран невронен кодер-декодер модел, който максимизира споделянето на параметри между езиковите двойки, за да се възползва ефективно от ортографското сходство. Показваме, че многоезичната транслитерация значително превъзхожда двуезичната транслитерация в различни сценарии (средно увеличение от 58% при различни езици, с които експериментирахме). Показваме също, че многоезичните транслитерационни модели могат да обобщят добре езици/езикови двойки, които не са срещани по време на тренировка и следователно се представят добре при задачата за транслитерация на нулишот. Показваме, че по-нататъшни подобрения могат да бъдат постигнати чрез въвеждане на фонетични функции.</abstract_bg>
      <abstract_hr>Mi obraćamo zadatak zajedničke obuke modela transliteracije za višestruke jezičke pare (multijezička transliteracija). To je primjer učenja multizadataka, gdje pojedinačni zadatak (parovi jezika) koristi od dijeljenja znanja s povezanim zadatacima. Fokusiramo se na transliteraciju uključujući povezane zadatke, tj. jezike dijeljenja pismenih sustava i fonetičkih vlasništva (ortografski sličnih jezika). Predlažemo modificirani model neuralnog kodera koji maksimalizira dijeljenje parametara preko parova jezika kako bi učinkovito utjecalo na ortografsku sličnost. Pokazujemo da multijezička transliteracija značajno iznosi dvojezičku transliteraciju u različitim scenarijama (prosječni povećanje od 58% u raznim jezicima s kojima smo eksperimentirali). Također pokazujemo da se multijezički modeli transliteracije dobro mogu generalizirati na jezičke/jezičke pare koje nisu susreli tijekom treninga i stoga dobro održavaju na zadatku transliteracije zerošota. Pokazujemo da se dodatno poboljšavanje može postići koristeći fonetički ulaz.</abstract_hr>
      <abstract_de>Wir beschäftigen uns mit der Aufgabe des gemeinsamen Trainings von Transliterationsmodellen für mehrere Sprachpaare (mehrsprachige Transliteration). Dies ist eine Instanz des Multitask-Lernens, bei der einzelne Aufgaben (Sprachpaare) davon profitieren, Wissen mit verwandten Aufgaben zu teilen. Wir konzentrieren uns auf Transliteration mit verwandten Aufgaben, d.h. Sprachen, die Schreibsysteme und phonetische Eigenschaften teilen (orthographisch ähnliche Sprachen). Wir schlagen ein modifiziertes neuronales Encoder-Decoder-Modell vor, das das Teilen von Parametern zwischen Sprachpaaren maximiert, um orthographische Ähnlichkeiten effektiv zu nutzen. Wir zeigen, dass die mehrsprachige Transliteration die zweisprachige Transliteration in verschiedenen Szenarien deutlich übertrifft (durchschnittliche Zunahme von 58% in einer Vielzahl von Sprachen, mit denen wir experimentiert haben). Wir zeigen auch, dass mehrsprachige Transliterationsmodelle gut auf Sprachen/Sprachpaare verallgemeinern können, die während des Trainings nicht angetroffen werden und daher eine gute Leistung bei der Zeroshot Transliterationsaufgabe erbringen. Wir zeigen, dass weitere Verbesserungen durch die Verwendung von phonetischen Features erreicht werden können.</abstract_de>
      <abstract_id>Kami mengatasi tugas pelatihan kongsi dari model transliterasi untuk pasangan berbagai bahasa (transliterasi berbagai bahasa). Ini adalah contoh belajar multitask, di mana tugas individu (pasangan bahasa) berguna dari berbagi pengetahuan dengan tugas terkait. We focus on transliteration involving related tasks i.e., languages sharing writing systems and phonetic properties (orthographically similar languages).  Kami mengusulkan model pengkode saraf yang diubah yang memaksimalkan pembagian parameter di sepanjang pasangan bahasa agar secara efektif menggunakan persamaan ortografik. Kami menunjukkan bahwa transliterasi berbagai bahasa secara signifikan melebihi transliterasi dua bahasa dalam skenario yang berbeda (meningkat rata-rata 58% di berbagai bahasa yang kami eksperimen dengan). Kami juga menunjukkan bahwa model transliterasi berbagai bahasa dapat menyebarkan dengan baik untuk bahasa/pasangan bahasa yang tidak ditemui selama latihan dan oleh itu bekerja dengan baik pada tugas transliterasi nol. Kami menunjukkan bahwa perkembangan lanjut dapat dicapai dengan menggunakan input fitur fonetik.</abstract_id>
      <abstract_ko>우리는 다국어 음역 모델에 대한 연합 훈련 임무를 해결했다.이것은 다중 임무 학습의 한 예로 그 중에서 단일 임무(언어대)는 관련 임무와 지식을 공유하는 데 도움이 된다.우리는 쓰기 시스템과 음성 특성을 공유하는 언어 (정자법과 비슷한 언어) 와 관련된 음역에 전념한다.우리는 정교 유사성을 효과적으로 이용하기 위해 개선된 신경 코딩 모델을 제시했다. 이 모델은 언어 간의 매개 변수 공유를 최대화했다.우리는 서로 다른 상황에서 다국어 음역의 표현이 쌍음성역보다 현저히 우수하다는 것을 발견했다(우리가 실험한 각종 언어에서 평균 58% 증가했다).우리는 또한 다국어 음역 모델은 훈련 중에 만나지 못한 언어/언어 쌍에 잘 보급될 수 있기 때문에 제로 음역 임무에서 좋은 모습을 보일 수 있다고 밝혔다.우리는 음성 특징 입력을 사용하면 진일보한 개선을 실현할 수 있음을 나타낸다.</abstract_ko>
      <abstract_sw>Tunajadili jukumu la mafunzo ya pamoja ya mifano ya usafiri kwa ajili ya wawili wa lugha mbalimbali (tafsiri ya lugha nyingi). Huu ni mfano wa kujifunza zaidi, ambapo kazi binafsi (wanandoa wa lugha) zinafaa kwa kushirikisha maarifa na kazi zinazohusiana. Tunakatiza kutafsiri kazi zinazohusisha, yaani lugha zinazoshirikisha mfumo wa kuandika na mali za simu (lugha zinazofanana na lugha hizo). Tunazipendekeza modeli ya kodi ya neura inayoongezeka kwa kiwango kikubwa cha kushirikiana kwa wanandoa wa lugha ili kuweka kwa ufanisi wa usambazaji wa orthografi. Tunaonyesha kwamba utafsiri wa lugha mbalimbali unafanya tafsiri ya lugha mbili katika hali mbalimbali (ongezeko la wastani wa asilimia 58 katika lugha mbalimbali tulizozijaribu). Tunaonyesha pia kuwa mifano ya kutafsiri lugha mbalimbali inaweza kutengeneza vizuri kwa lugha/lugha ambazo hazikutana wakati wa mafunzo na hivyo kufanya vizuri katika kazi za kutafsiri sifuri. Tunaonyesha kwamba maendeleo zaidi yanaweza kufanikiwa kwa kutumia vifaa vya mtandaoni.</abstract_sw>
      <abstract_tr>Biz birnäçe dil çiftleri üçin terjime etmek nusgynyň birleşik okuwçysyny çykarýarys. Bu multi-täblik öwrenmeniň örneksi. Şol ýerde birnäçe zadlar (dil çiftleri) bilgi bilen baglanyşyk zadlary bilen paýlaşmakdan faydalandyrýarlar. Biz ýazma sistemalary we fonetik häsiýetleri (ortografiýa meňzeş diller) i çinden meňzeş işleri barada terjime edip görýäris. Biz özüniň üýtgeden neiral ködleme modini teklip edip, ortografiýa meňzeşliklerini etkinleştirmek üçin bu sahypalary dil çiftlerde bejermek üçin azaltýar. Birnäçe dil terjime edilmesi farklı senarylarda iki dil terjime edilmesinden has baglanýandygyny görkeýäris (ortalama 58% we experimentediğimiz dillerde). Biz hem köp dilli terjime edip bilmeýän nusgalary okuw wagty bilen gowy döredip bilmeýän dillere/dillere gelip bilmeýän nusgalary görkeýäris we şonuň üçin zeroshot terjime edip bilýäris. Biz fonetik wajyplary girişinden ullanarak köpräk gelişmeler başaryp biljekdigini görkez.</abstract_tr>
      <abstract_fa>ما وظیفه آموزش مشترک مدل ترجمه برای جفت‌های زبان‌های متعدد (ترجمه‌نامه‌های متعدد زبان) را دریافت می‌کنیم. این مثال یادگیری چندین تکلیف است، جایی که تکلیف (جفت زبان) از شریک علم با وظیفه‌های ارتباط سود می‌دهد. ما روی تغییر نوشتن تمرکز می‌کنیم که شامل وظیفه‌های مربوط به زبان‌ها سیستم نوشتن و ویژگی‌های تلفنی (زبان‌های متفاوتی) است. ما پیشنهاد می‌کنیم یک مدل رمزبندی‌کننده‌ی عصبی تغییر داده شده که پارامتر را در جفت‌های زبان تقسیم می‌کند تا به طور تاثیر شبیه‌ای orthographic را تغییر دهد. ما نشان می‌دهیم که ترجمه‌نامه‌های زیادی زبان‌ها در سناریو‌های مختلف بیشتر از ۲ زبان‌ها (متوسط افزایش ۵۸ درصد در مختلف زبان‌هایی که با آن آزمایش کرده‌ایم) انجام می‌دهد. ما همچنین نشان می دهیم که مدلهای ترجمه زبان‌های زیادی می‌توانند به زبان/زبان جفت‌های زیادی که در طول آموزش با هم ملاقات نشده باشند و به این نتیجه در کار ترجمه‌سازی Zeroshot خوب انجام می‌دهند. ما نشان می دهیم که بهترین پیشرفت بیشتری با استفاده از ورودهای ویژه‌های فونیک می‌تواند به دست یافت.</abstract_fa>
      <abstract_sq>Ne trajtojmë detyrën e trajnimit të përbashkët të modeleve transliteracioni për çifte të shumta gjuhësh (transliteracion shumëgjuhës). Ky është një shembull mësimi i shumë detyrave, ku detyrat individuale (çiftet gjuhësh) përfitojnë nga ndarja e njohurive me detyrat e lidhura. Ne përqëndrohemi në transliteracionin që përfshin detyra të lidhura, pra, gjuhët që ndajnë sistemet e shkrimit dhe pronësitë fonetike (gjuhë ortografikisht të ngjashme). Ne propozojmë një model të modifikuar të kodifikuesit nervor që maksimumon ndarjen e parametrave nëpër çiftet gjuhësh me qëllim që të nxjerrë efektivisht ngjashmërinë ortografike. Ne tregojmë se transliteracioni shumëgjuhës është më i mirë se transliteracioni dygjuhës në skenarë të ndryshme (rritje mesatare prej 58% në një varietet gjuhësh me të cilat eksperimentuam). Ne gjithashtu tregojmë se modelet e transliteracionit shumëgjuhës mund të gjeneralizohen mirë për gjuhët/çiftet gjuhësh që nuk janë takuar gjatë trajnimit dhe kështu të kryejnë mirë në detyrën e transliteracionit zero. Ne tregojmë se përmirësime të mëtejshme mund të arrihen duke përdorur input fonetik.</abstract_sq>
      <abstract_af>Ons adres die taak van joint training van transliterasie modele vir veelvuldige taal paar (multilingual transliterasie). Hierdie is 'n voorbeeld van multitaak leer, waar individuele taak (taal paar) voordeel van die deel van kennis met verwante taak. Ons fokus op transliterasie met verwante taak, t.d. tale wat skryfstelsels deel en fonetiese eienskappe (orthografies gelykbaar tale). Ons voorstel 'n veranderde neurale enkoder- dekoder model wat maksimaliseer parameter deel oor taal paar om effektief orthografiese gelykenis te verwyder. Ons wys dat multilinglike transliterasie betekenlik twee tale transliterasie in verskillende scenarios uitvoer (gemiddelde vergroot van 58% oor 'n verskillende tale waarmee ons eksperimenteer het). Ons wys ook dat multilinglike transliterasie-modele goed kan genereer na tale/taal paar wat nie teenoor onderwerp het nie, en daarom doen goed op die zeroshot transliterasie-taak. Ons wys dat verdere verbeteringe kan bereik word deur die gebruik van fonetiese funksie invoer.</abstract_af>
      <abstract_am>ለብዙ ቋንቋዎች ዓይነቶች (በብዙ ቋንቋዎች ትርጓሜ) የተጠቃሚ ትርጉም ማድረጉን እናስገራለን፡፡ ይህ የብዙ ትምህርት ምሳሌ ነው፤ የሁሉም ስራዎች (ቋንቋ ዓይነቶች) እውቀትን ከሚያስተካክሉ ስራዎችን ማጋራት ይጠቅማል፡፡ We focus on transliteration involving related tasks i.e., languages sharing writing systems and phonetic properties (orthographically similar languages).  በቋንቋ ሁለንተና በተለየ የነጥብ አካባቢ አካባቢ-ዴክዶዶር ሞዴል እናሳውቃለን፡፡ ብዙ ቋንቋዎች በተለየ ቋንቋዎች ላይ ትርጓሜን በብዛት ያሳየናል (በተፈተናነው በተለያዩ ቋንቋዎች ላይ 58 በመቶ ያበዛል፡፡ እናሳያቸዋለን በቋንቋ-ቋንቋ ትርጉም ሞዴላዎች በተማሪዎች ጊዜ ያልተገናኙትን ለቋንቋ/ቋንቋ ዓይነቶች መልካም እንዲያሳየፉ እና በዛፎት ትርጉም ላይ መልካም እንዲያደርጉ ይችላል፡፡ የፎንnetic ጥያቄ በመጠቀም የሚጨማሪውን ትክክል ማድረግ እናሳየዋለን፡፡</abstract_am>
      <abstract_hy>Մենք խոսում ենք վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ հազմալեզվի երկու զույգերի (բազլեզվի վերաբերյալ վերաբերյալ վերաբերյալ վերաբերյալ) միջոցառումն Սա բազմախնդիրների ուսումնասիրության օրինակ է, որտեղ անհատական խնդիրները (լեզվի զույգերը) շահում են գիտելիքների կիսվելուց կապված խնդիրների հետ: Մենք կենտրոնանում ենք տրանսգրականության վրա, որը ներառում է կապված խնդիրներ, այսինքն, լեզուներ, որոնք կիսում են գրական համակարգեր և ֆոնետիկ հատկություններ (օրտոգրաֆիկապես նման լեզուներ): Մենք առաջարկում ենք փոփոխված նյարդային կոդավորման մոդել, որը մեծացնում է պարամետրերի կիսվելը լեզվի զույգերի միջև, որպեսզի արդյունավետ օգտագործենք օրտոգրաֆիկ նմանությունը: Մենք ցույց ենք տալիս, որ բազմալեզու տրանսգրականությունը կարևորաբար գերազանցում է երկլեզու տրանսգրականությունը տարբեր սցենարներում (միջին աճը 58 տոկոսով տարբեր լեզուներում, որոնց հետ մենք փորձեցինք): Մենք նաև ցույց ենք տալիս, որ բազմալեզու տրանսգրականության մոդելները կարող են լավ ընդհանուր լինել լեզուների և լեզվի զույգերի համար, որոնք չեն հանդիպել ուսուցման ընթացքում, և այսպես լավ են աշխատում զրոշոտ տրանսգրականության խնդրի վրա Մենք ցույց ենք տալիս, որ ավելի շատ բարելավումներ կարելի է հասնել օգտագործելով ֆոնետիկ հատկանիշներ:</abstract_hy>
      <abstract_az>Biz çoxlu dil çiftlərinin (çoxlu dil transliterasyonu üçün) transliterasyon modellərinin birlikdə təhsil etməsini çəkirik. Bu çoxlu işin öyrənməsinin məsəli, indi işlər (dil çiftlər) elmi ilə müxtəlif işlərlə paylaşmaqdan faydalanır. Biz yazmaq sistemlərini və fonetik özellikləri (ortografiki kimi dilləri) ilə bağlı i şlər haqqında olan transliterasyona odaqlanırıq. Biz dəyişdirilmiş nöral kodlayıcı modeli təklif edirik ki, bu parametrləri dil çiftləri arasında paylaşdırmaq üçün ortografiki bənzərini etkinlik edər. Biz çoxlu dil transliterasyonun müxtəlif senaryolarda iki dil transliterasyonun üstünlüyünü göstəririk (ortalama 58% ilə müxtəlif dillərdə təcrübə edirik). Biz də göstəririk ki, çoxlu dil transliterasyon modelləri təhsil sırasında qarşılaşmayan dillər/dil çiftlərə çox yaxşı təhsil edə bilər və buna görə də zeroshot transliterasyon işində yaxşı təhsil edə bilər. Biz fonetik xüsusiyyətlər istifadə edərək daha yaxşılıqların başarılı olaraq göstəririk.</abstract_az>
      <abstract_bn>আমরা বেশ কয়েকটি ভাষার জোড়ার জন্য যৌথ প্রশিক্ষণ প্রশিক্ষণের কাজের কথা বলছি (বহুভাষার ট্রান্সলিকেশন)। এটি মাল্টিউটিক্রিক শিক্ষার উদাহরণ, যেখানে ব্যক্তিগত কাজ (ভাষার জোড়া) সম্পর্কিত কাজের সাথে জ্ঞান শেয়ার করার আমরা সংশ্লিষ্ট কাজের মধ্যে ট্রান্সলিটেশনের উপর মনোযোগ প্রদান করি, যেমন ভাষা লেখা ব্যবস্থা এবং ফোনেটিক বৈশিষ্ট্য শেয়ার করে ( আমরা একটি পরিবর্তিত নিউরেল এনকোডার-ডেকোডার মডেল প্রস্তাব করছি যা ভাষার জোড়া জোড়ার সারা ভাষায় প্যারামিটার শেয়ার করার জন্য কার্যকর ভ আমরা দেখাচ্ছি যে মাল্টিভাষার বিভিন্ন দৃশ্যে দুই ভাষার বিভিন্ন ভাষায় ট্রান্সলিকেশনের বাড়িয়ে দিয়েছে (বিভিন্ন ভাষায় আমরা পরীক আমরা একই সাথে দেখাচ্ছি যে বহুভাষাভাষী ট্রান্সলিটারেশন মডেল ভাষা/ভাষার জোড়ার সাথে প্রশিক্ষণের সময় সাক্ষাৎ করা না থাকার সময়  আমরা দেখাচ্ছি যে ফোনেটিক বৈশিষ্ট্যাবলী ইনপুট ব্যবহার করে আরো উন্নতি পাওয়া যাবে।</abstract_bn>
      <abstract_bs>Mi se obraćamo zadatku zajedničke obuke modela transliteracije za višestruke jezičke pare (multilingual transliteration). Ovo je primjer multitask učenja, gdje individualni zadaci (parovi jezika) koriste od dijeljenja znanja sa povezanim zadacima. Fokusiramo se na transliteraciju uključujući povezane zadatke, tj. jezike dijeljenja pismenih sustava i fonetičkih vlasništva (ortografski sličnih jezika). Predlažemo modificirani model neuralnog kodera koji maksimalizira dijeljenje parametara preko parova jezika kako bi učinkovito utjecalo na ortografsku sličnost. Pokazujemo da multijezička transliteracija značajno iznosi dvojezičku transliteraciju u različitim scenarijama (prosječno povećanje od 58% na raznim jezicima s kojima smo eksperimentirali). Također pokazujemo da multijezički modeli transliteracije mogu dobro generalizirati jezicima/jezičkim parovima koji se ne susreću tijekom treninga i stoga dobro izvršavaju na zadatku za transliteraciju zerošota. Pokazujemo da se dodatno poboljšavanje može postići koristeći fonetički ulaz.</abstract_bs>
      <abstract_ca>Ens ocupem de la tasca de formació conjunta de models de transliteració per parelles de llenguatges múltiples (transliteració multillengua). Això és un exemple d'aprenentatge multitasca, on tasques individuals (parells de llenguatges) beneficien de compartir coneixements amb tasques relacionades. Ens centrem en la transliteració que implica tasques relacionades, és a dir, llengües que comparteixen sistemes d'escriptura i propietats fonètiques (llengües ortogràficament similars). Proposem un model modificat de codificador neuronal que maximitza el compartiment de paràmetres entre parelles de llengües per aprofitar eficaçment la similitud ortogràfica. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58% across a variety of languages we experimented with).  També demostram que els models de transliteració multillengües poden generalitzar-se bé a les llengües/parelles de llengües que no es troben durant l'entrenament i, per tant, actuen bé en la tasca de transliteració zero. Ens mostren que es poden aconseguir millors fent servir les entrades fonètiques.</abstract_ca>
      <abstract_cs>Řešíme úkol společného tréninku transliteračních modelů pro více jazykových párů (multilingvální transliterace). Jedná se o příklad víceúlohového učení, kdy jednotlivé úkoly (jazykové páry) mají prospěch ze sdílení znalostí s souvisejícími úkoly. Zaměřujeme se na transliteraci zahrnující související úlohy, tj. jazyky sdílející psací systémy a fonetické vlastnosti (ortograficky podobné jazyky). Navrhujeme modifikovaný neuronový kodér-dekodér model, který maximalizuje sdílení parametrů napříč jazykovými páry s cílem efektivně využít ortografické podobnosti. Ukazujeme, že vícejazyčná transliterace výrazně překonává dvojjazyčnou transliteraci v různých scénářích (průměrný nárůst 58% v různých jazycích, se kterými jsme experimentovali). Dále ukazujeme, že vícejazyčné transliterační modely se mohou dobře zobecnit na jazyky/jazykové páry, které se během tréninku nevyskytují, a proto fungují dobře při transliteračním úkolu zeroshot. Ukazujeme, že dalších zlepšení lze dosáhnout pomocí fonetického vstupu.</abstract_cs>
      <abstract_et>Tegeleme mitme keelepaari transliteratsioonimudelite ühise koolituse ülesandega (mitmekeelne transliteratsioon). See on mitme ülesandega õppimise näide, kus individuaalsed ülesanded (keelepaarid) saavad kasu teadmiste jagamisest seotud ülesannetega. Keskendume transliteratsioonile, mis hõlmab seotud ülesandeid, st kirjutamissüsteeme jagavaid keeli ja foneetilisi omadusi (ortograafiliselt sarnased keeled). Pakume välja modifitseeritud neurokodeeri-dekooderi mudeli, mis maksimeerib parameetrite jagamist keelepaaride vahel, et efektiivselt kasutada ortograafilist sarnasust. Me näitame, et mitmekeelne transliteratsioon ületab oluliselt kakskeelset transliteratsiooni erinevates stsenaariumides (keskmine kasv 58% erinevates keeltes, millega me eksperimenteerisime). Samuti näitame, et mitmekeelsed transliteratsioonimudelid võivad hästi üldistada keelte/keelepaaride jaoks, mida treeningu käigus ei esine, ning seega toimivad hästi zeroshot transliteratsiooni ülesandes. Näitame, et foneetiliste funktsioonide sisestamisega on võimalik saavutada täiendavaid parandusi.</abstract_et>
      <abstract_fi>Käsittelemme transliteraatiomallien yhteiskoulutusta useille kielipareille (monikielinen transliterointi). Tämä on monitehtäväoppimisen tapaus, jossa yksittäiset tehtävät (kieliparit) hyötyvät tiedon jakamisesta niihin liittyvien tehtävien kanssa. Keskitymme transliteraatioon, joka sisältää siihen liittyviä tehtäviä eli kirjoitusjärjestelmiä jakavia kieliä ja foneettisia ominaisuuksia (ortografisesti samankaltaisia kieliä). Ehdotamme modifioitua neurokooderi-dekooderimallia, joka maksimoi parametrien jakamisen kielipareissa, jotta ortografista samankaltaisuutta voitaisiin hyödyntää tehokkaasti. Osoitamme, että monikielinen transliteraatio ylittää merkittävästi kaksikielisen transliteraation eri skenaarioissa (keskimääräinen kasvu on 58% useilla kokeiltavilla kielillä). Osoitamme myös, että monikieliset transliteraatiomallit voivat yleistyä hyvin kielipareihin, joita ei ole havaittu koulutuksen aikana ja siten suoriutua hyvin zeroshot transliteraatiotehtävässä. Osoitamme, että lisää parannuksia voidaan saavuttaa foneettisten ominaisuuksien syötön avulla.</abstract_fi>
      <abstract_jv>Awak dhéwé nggawe gerangkamu nggawe sistem sing luwih nggawe Ing sampeyan karo akeh multitask nang sampeyan, sapa task singgu Awak dhéwé éntuk nggambar tarjamahan ing nggawe operasi sing nggambar, t.e. langgar pisan sistem lan nganggo gambar kaplan saiki (langgar banter) Awakdhéwé nggawe model sing dadi nggo koder-nggawe gerangkat oleh dumaten Awak dhéwé ngerasakno karo akeh bantulangan luwih-luwih bantuan ing sak bantulangan ingkang sampeyan gak bener (amèh, njaluk luwih akeh 58%  ning sak sampeyan liyane sing sampeyan ingkang sampeyan kawit dhéwé ujaran). Awak dhéwé éntuk akeh, model bantulatan sampeyan luwih iso nggambar tarjamahan kanggo limun/limun sing ora nggolaké, lan kaya nggawe barang kelas terakhir suarané. Awak dhéwé éntuk luwih-luwih kanggo ngerasakno ngono nggawe perusahaan resmi.</abstract_jv>
      <abstract_sk>Obravnavamo nalogo skupnega usposabljanja transliteracijskih modelov za več jezikovnih parov (večjezična transliteracija). To je primer večopravilnega učenja, kjer imajo posamezne naloge (jezikovni pari) koristi od izmenjave znanja s sorodnimi nalogami. Osredotočamo se na transliteracijo, ki vključuje sorodne naloge, tj. jezikovne skupne pisalne sisteme in fonetične lastnosti (ortografsko podobni jeziki). Predlagamo modificiran model nevronskih kodirnikov-dekodirnikov, ki maksimira delitev parametrov med jezikovnimi pari, da bi učinkovito izkoristili ortografsko podobnost. Pokazali smo, da večjezična transliteracija znatno presega dvojezično transliteracijo v različnih scenarijih (povprečno povečanje za 58% v različnih jezikih, s katerimi smo eksperimentirali). Pokazali smo tudi, da se lahko večjezični transliteracijski modeli dobro posplošijo na jezike/jezikovne pare, ki jih med treningom ni bilo mogoče srečati in zato dobro uspešno opravijo transliteracijo zeroshot. Pokazali smo, da je mogoče nadaljnje izboljšave doseči z uporabo fonetičnega vnosa funkcij.</abstract_sk>
      <abstract_he>אנו מתייחסים למשימה של אימון משותף של דוגמנים טרנסליטציה לזוגות שפות רבות (טרנסליטציה רבות שפות). זהו דוגמא של לימוד משימות רבות, שבו משימות בודדות (זוגות שפות) מרוויחות משתף ידע עם משימות קשורות. אנחנו מתמקדים בטרנסליטציה שמעניינת משימות קשורות, כלומר שפות שחולקות מערכות כתיבה ותכונות פונטיות (שפות דומות באורטוגרפית). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity.  אנו מראים שטרנסליטציה רבת-שפותית משפיעה משמעותית על טרנסליטציה שתיים-שפותית בתרחישים שונים (הגידול הממוצע של 58% בכל מגוון שפות שניסינו איתן). אנחנו גם מראים שדוגמנים לטרנסליטציה רבות שפות יכולים להתפשט היטב לשפות/זוגות שפות שלא נפגשו בזמן האימון ולכן להפעיל היטב במשימת הטרנסליטציה של אפס. We show that further improvements can be achieved by using phonetic feature input.</abstract_he>
      <abstract_ha>Munã jãyayya aikin da ke haɗa wa masu tsari da misalin transliteratori wa misalin misalin misalin wasu harshe (transliteratori masu multilala). Wannan misali ne da za'a sanar da multiaski, a cikinsa akwai amfani ga sharing ilmi da aiki masu husũma. Tuna fokus a kan transliteratori da ke cikin wasu aikin da aka yi wa husũma, misali, harshen su yi sharka da tsarin rubutu da properties na fomat (orthografi da misãlai). Munã goyyade wani motali na-kode-neural wanda ya yi gyarawa, yana faɗi shari da parameter a tsakanin nau'i biyu cikin harshen dõmin ya yi amfani da shirin ortografi masu daidaita. Tuna nũna cewa transliteratori mulki na'ura yana ƙara fasalin lugha biyu mai girma a cikin filayen dabam-dabam (an ƙara sauri ga sauri 58% a cikin wasu harsunan dabam-dabam da muka jarraba shi). Tuna nũna misalin transliteratori masu mulki-lingui, za'a iya ƙiƙira sauri ga lugha/harshe wanda ba su haɗi shi ba a lokacin da za'a yi aikin mai kyau a kan aikin transliteratori na sifro. We show that further improvements can be achieved by using phonetic feature input.</abstract_ha>
      <abstract_bo>ང་ཚོས་སྐད་ཡིག་ཆ་གཉིས་ཀྱི་དབྱིབས་ཡིག་གཟུགས་རིས་ཀྱི་བསྒྱུར་བཅོས་ཀྱི་ལས་འགུལ་འདོན་བྱེད་ཀྱི་ཡོད། འདི་ནི་ལྟ་བུའི་དཔེ་བརྗོད་བཏང་བ་དང་སྐད་རིགས་ཀྱི་ལས་འགུལ་གྱི་རྣམ་པ(སྐད་ཆ་གཉིས་)ཆ་རྐྱེན་ཏེ། ང་ཚོས་འབྲེལ་བ་འདི་དང་འབྲེལ་བའི་བྱ་འགུལ་དང་མཉམ་དུ་བསླབས་སྤྱད་ནུས་པ་དཔེར་ན། སྐད་ཡིག་འབྲི་ན་རིམ་མིང་དང་སྤྱོད་ར We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. ང་ཚོས་སྐད་ཡིག ང་ཚོས་ཀྱང་སྐད་ཡིག་འབྲི་ཀྱི་དཔེ་གཞི་ཚོགས་ཀྱི་རྣམ་པ་ནི་སྐད་ཡིག་ཆ་དང་གཅིག་མཐུན་མི་རྣམས་ལས་ གཞུང་ཕྱོགས་ཀྱི་ལས་འགན་སྤྲོད་ཀྱི་ལས་འགན འུ་ཅག་གིས་སྐོར་གྱི་ཁྱད་ཆོས་ཉིད་ཀྱི་འགྱུར་རིམ་གཞན་ལས་ཕར་རྒྱས་གཏོང་བ་ཐུབ་པར་བྱུང་།</abstract_bo>
      </paper>
    <paper id="23">
      <title>The NarrativeQA Reading Comprehension Challenge<fixed-case>N</fixed-case>arrative<fixed-case>QA</fixed-case> Reading Comprehension Challenge</title>
      <author><first>Tomáš</first><last>Kočiský</last></author>
      <author><first>Jonathan</first><last>Schwarz</last></author>
      <author><first>Phil</first><last>Blunsom</last></author>
      <author><first>Chris</first><last>Dyer</last></author>
      <author><first>Karl Moritz</first><last>Hermann</last></author>
      <author><first>Gábor</first><last>Melis</last></author>
      <author><first>Edward</first><last>Grefenstette</last></author>
      <doi>10.1162/tacl_a_00023</doi>
      <abstract>Reading comprehension (RC)in contrast to information retrievalrequires integrating information and reasoning about events, <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entities</a>, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial agents</a> and children learning to read. However, existing RC datasets and <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency) ; they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and set of <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> in which the reader must answer questions about stories by reading entire books or <a href="https://en.wikipedia.org/wiki/Screenplay">movie scripts</a>. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">salience</a>. We show that although humans solve the <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> easily, standard RC models struggle on the <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> presented here. We provide an analysis of the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and the challenges it presents.</abstract>
      <pages>317–328</pages>
      <url hash="62868a98">Q18-1023</url>
      <video href="https://vimeo.com/285804931" />
      <bibkey>kocisky-etal-2018-narrativeqa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/narrativeqa">NarrativeQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/booktest">BookTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/searchqa">SearchQA</pwcdataset>
    <title_ar>تحدي القراءة والفهم السردي</title_ar>
      <title_fr>Le défi de la compréhension en lecture NarrativeQA</title_fr>
      <title_pt>O desafio de compreensão de leitura NarrativeQA</title_pt>
      <title_es>El desafío de comprensión lectora de NarrativeQA</title_es>
      <title_ja>ナラティブQA読解力の課題</title_ja>
      <title_hi>NarrativeQA पठन समझ चुनौती</title_hi>
      <title_zh>叙事问答读解</title_zh>
      <title_ru>Проблема понимания нарративного QA чтения</title_ru>
      <title_ga>Dúshlán na Léitheoireachta NarrativeQA</title_ga>
      <title_ka>ნაპრატიური QA კითხვის კომპრეცენციის გარეშე</title_ka>
      <title_hu>A NarrativeQA olvasási megértési kihívás</title_hu>
      <title_el>Η πρόκληση κατανόησης της αφήγησηQA</title_el>
      <title_it>La sfida narrativaQA Reading Comprehension Challenge</title_it>
      <title_kk>QA Reading Comprehension Challenge</title_kk>
      <title_lt>QA Reading Comprehension Challenge</title_lt>
      <title_mk>QA Reading Comprehension Challenge</title_mk>
      <title_ms>QA Reading Comprehension Challenge</title_ms>
      <title_ml>QA വായിക്കുന്നത് Comprehension Challenge</title_ml>
      <title_mt>L-Isfida ta’ Komprensjoni Narrattiva tal-QA fil-Qara</title_mt>
      <title_mn>QA унших шаардлагатай шаардлага</title_mn>
      <title_no>NarrativQA Reading Comprehension Challenge</title_no>
      <title_pl>NarrativeQA Reading Comprehension Challenge</title_pl>
      <title_sr>Narrative QA Comprehension Challenge</title_sr>
      <title_ro>The NarrativeQA Reading Comprehension Challenge</title_ro>
      <title_si>QA Reading Compren challenge</title_si>
      <title_so>QA Reading Completion Challenge</title_so>
      <title_sv>BerättelseQA Reading Comprehension Challenge</title_sv>
      <title_ta>QA படித்தல் முடிவு சவால்</title_ta>
      <title_ur>The NarrativeQA Reading Comprehension Challenge</title_ur>
      <title_uz>QA oĘ»quvchi kompyuterName</title_uz>
      <title_vi>Câu hỏi hoàn toàn của giới hạn.</title_vi>
      <title_nl>De NarrativeQA Reading Comprehension Challenge</title_nl>
      <title_bg>Предизвикателството за разбиране на четенето на QA</title_bg>
      <title_da>The NarrativeQA Reading Comprehension Challenge</title_da>
      <title_ko>서사적 독해 도전</title_ko>
      <title_de>Die Herausforderung zum Verständnis von NarrativeQA beim Lesen</title_de>
      <title_hr>Izazov za pročitanje NarrativeQA</title_hr>
      <title_id>The NarrativeQA Reading Comprehension Challenge</title_id>
      <title_fa>تأثیر تأثیر خواندن QA</title_fa>
      <title_sw>Mgogoro wa Msomaji wa Kufungua</title_sw>
      <title_sq>QA Reading Comprehension Challenge</title_sq>
      <title_am>QA Reading Comprehension Challenge</title_am>
      <title_hy>The NarrativeQA Reading Comprehension Challenge</title_hy>
      <title_af>QA Reading Comprehension Challenge</title_af>
      <title_bs>Narrative QA Comprehension Challenge</title_bs>
      <title_bn>QA পাঠক সম্পূর্ণ চ্যালেঞ্জ</title_bn>
      <title_ca>El desafiament de la comprensió narrativaQA Reading</title_ca>
      <title_et>JutustusQA Reading Comprehension Challenge</title_et>
      <title_cs>VyprávěníQA Reading Comprehension Challenge</title_cs>
      <title_fi>KertomuksetQA Reading Comprehension Challenge</title_fi>
      <title_az>NarrativeQA Reading Comprehension Challenge</title_az>
      <title_tr>QA Reading Comprehension Challenge</title_tr>
      <title_jv>Validity</title_jv>
      <title_he>אתגר ההבנה בקריאה QA</title_he>
      <title_ha>QA reading Comprehension Challenge</title_ha>
      <title_sk>Izziv razumevanja branja zgodbeQA</title_sk>
      <title_bo>NarrativeQA Reading Comprehension Challenge</title_bo>
      <abstract_ar>يتطلب فهم القراءة (RC) - على عكس استرجاع المعلومات - تكامل المعلومات والتفكير حول الأحداث والكيانات وعلاقاتهم عبر مستند كامل. تُستخدم الإجابة على الأسئلة بشكل تقليدي لتقييم قدرة RC ، في كل من العوامل الاصطناعية وتعلم الأطفال القراءة. ومع ذلك ، فإن مجموعات بيانات ومهام المنسقين المقيمين تهيمن عليها الأسئلة التي يمكن حلها عن طريق اختيار الإجابات باستخدام المعلومات السطحية (على سبيل المثال ، تشابه السياق المحلي أو تكرار المصطلح العالمي) ؛ وبالتالي فشلوا في اختبار الجانب التكاملي الأساسي لـ RC. لتشجيع التقدم في فهم أعمق للغة ، نقدم مجموعة بيانات جديدة ومجموعة من المهام التي يجب على القارئ من خلالها الإجابة عن أسئلة حول القصص من خلال قراءة كتب كاملة أو نصوص أفلام. تم تصميم هذه المهام بحيث تتطلب الإجابة الناجحة على أسئلتهم فهم السرد الأساسي بدلاً من الاعتماد على مطابقة النمط الضحل أو البروز. نوضح أنه على الرغم من أن البشر يحلون المهام بسهولة ، إلا أن نماذج RC القياسية تكافح في المهام المعروضة هنا. نقدم تحليلاً لمجموعة البيانات والتحديات التي تطرحها.</abstract_ar>
      <abstract_es>La comprensión lectora (RC), a diferencia de la recuperación de información, requiere integrar la información y el razonamiento sobre eventos, entidades y sus relaciones en un documento completo. La respuesta a preguntas se usa convencionalmente para evaluar la capacidad de RC, tanto en agentes artificiales como en niños que aprenden a leer. Sin embargo, los conjuntos de datos y tareas de RC existentes están dominados por cuestiones que pueden resolverse mediante la selección de respuestas utilizando información superficial (por ejemplo, similitud de contexto local o frecuencia de término global); por lo tanto, no prueban el aspecto integrador esencial de RC. Para fomentar el progreso en una comprensión más profunda del lenguaje, presentamos un nuevo conjunto de datos y un conjunto de tareas en las que el lector debe responder preguntas sobre historias leyendo libros completos o guiones de películas. Estas tareas están diseñadas para que responder con éxito a sus preguntas requiera comprender la narrativa subyacente en lugar de confiar en la coincidencia de patrones superficiales o la prominencia. Demostramos que, aunque los humanos resuelven las tareas fácilmente, los modelos RC estándar tienen dificultades en las tareas que se presentan aquí. Proporcionamos un análisis del conjunto de datos y los desafíos que presenta.</abstract_es>
      <abstract_pt>A compreensão de leitura (RC) – em contraste com a recuperação de informações – requer a integração de informações e raciocínio sobre eventos, entidades e suas relações em um documento completo. A resposta a perguntas é convencionalmente usada para avaliar a habilidade de CR, tanto em agentes artificiais quanto em crianças que estão aprendendo a ler. No entanto, conjuntos de dados e tarefas de RC existentes são dominados por questões que podem ser resolvidas selecionando respostas usando informações superficiais (por exemplo, semelhança de contexto local ou frequência global de termos); eles, portanto, falham em testar o aspecto integrador essencial da CR. Para incentivar o progresso na compreensão mais profunda da linguagem, apresentamos um novo conjunto de dados e um conjunto de tarefas em que o leitor deve responder a perguntas sobre histórias lendo livros inteiros ou roteiros de filmes. Essas tarefas são projetadas para que responder com sucesso às suas perguntas exija a compreensão da narrativa subjacente, em vez de confiar na correspondência de padrões superficiais ou na saliência. Mostramos que, embora os humanos resolvam as tarefas com facilidade, os modelos RC padrão lutam nas tarefas apresentadas aqui. Fornecemos uma análise do conjunto de dados e os desafios que ele apresenta.</abstract_pt>
      <abstract_fr>La compréhension écrite (RC), contrairement à la récupération d'informations, nécessite d'intégrer des informations et un raisonnement sur les événements, les entités et leurs relations dans un document complet. La réponse aux questions est classiquement utilisée pour évaluer la capacité de RC, à la fois chez les agents artificiels et chez les enfants qui apprennent à lire. Toutefois, les ensembles de données et les tâches de CR existants sont dominés par des questions qui peuvent être résolues en sélectionnant des réponses à l'aide d'informations superficielles (par exemple, similarité de contexte local ou fréquence globale des termes) ; ils ne permettent donc pas de tester l'aspect intégratif essentiel de la CR. Pour favoriser une meilleure compréhension de la langue, nous présentons un nouveau jeu de données et un ensemble de tâches dans lesquelles le lecteur doit répondre à des questions sur des histoires en lisant des livres entiers ou des scénarios de films. Ces tâches sont conçues de telle sorte que pour répondre à leurs questions avec succès, il faut comprendre le récit sous-jacent plutôt que de s'appuyer sur une correspondance superficielle ou une mise en évidence des motifs. Nous montrons que même si les humains résolvent les tâches facilement, les modèles RC standard ont du mal à réaliser les tâches présentées ici. Nous fournissons une analyse de l'ensemble de données et des défis qu'il présente.</abstract_fr>
      <abstract_ja>理解（ RC ）の読み取り-完全な文書全体にわたってイベント、エンティティ、およびそれらの関係に関する情報と推論を統合する情報検索要件とは対照的です。 質問への回答は、人工的な薬剤と子供の読書学習の両方で、RC能力を評価するために慣習的に使用されています。 しかし、既存のRCデータセットとタスクは、表面的な情報（例えば、ローカルコンテキストの類似性やグローバルな用語の頻度）を使用して回答を選択することによって解決できる質問に支配されているため、RCの本質的な統合的側面をテストすることはできません。 言語のより深い理解を促進するために、読者は本や映画の脚本全体を読んでストーリーに関する質問に答えなければならない新しいデータセットとタスクのセットを提示します。 これらのタスクは、質問にうまく答えるために、浅いパターンマッチングや顕著さに頼るのではなく、基礎となる物語を理解する必要があるように設計されています。 人間は簡単にタスクを解決できるが、標準的なRCモデルはここで提示されたタスクに苦労することを示している。 データセットとそれが提示する課題の分析を提供します。</abstract_ja>
      <abstract_zh>与信息检索相反,读解(RC)须将事件,实体与信息推理集成一文档中。 问答常以估人工摄童子所习RC能。 然见RC数集,要在用外(如局上下文相似性全局术语频率)择对案以决之。 故其未试RC大略综之。 劝深解言语,发一新集,读者必读整本书电影剧本答故事。 设使成功答问,须解潜述,非依浅层式配显著性。 吾言人可以轻事,而RC形于此者甚矣。 我供数据集及挑战之说。</abstract_zh>
      <abstract_ru>Чтение понимания (RC)- в отличие от извлечения информации - требует объединения информации и рассуждений о событиях, сущностях и их отношениях в полном документе. Ответы на вопросы обычно используются для оценки способностей RC, как у искусственных агентов, так и у детей, которые учатся читать. Однако в существующих наборах данных и задачах RC преобладают вопросы, которые могут быть решены путем отбора ответов с использованием поверхностной информации (например, сходство локального контекста или частота глобальных терминов); таким образом, они не могут проверить существенный интегративный аспект RC. Чтобы стимулировать прогресс в более глубоком понимании языка, мы представляем новый набор данных и набор задач, в которых читатель должен отвечать на вопросы об историях, читая целые книги или сценарии фильмов. Эти задачи разработаны таким образом, что успешный ответ на их вопросы требует понимания лежащего в их основе повествования, а не опоры на неглубокое сопоставление шаблонов или выраженность. Мы показываем, что хотя люди легко решают задачи, стандартные модели RC борются с задачами, представленными здесь. Мы проводим анализ набора данных и связанных с ним проблем.</abstract_ru>
      <abstract_hi>रीडिंग कॉम्प्रिहेंशन (आरसी) - सूचना पुनर्प्राप्ति के विपरीत - एक पूर्ण दस्तावेज़ में घटनाओं, संस्थाओं और उनके संबंधों के बारे में जानकारी और तर्क को एकीकृत करने की आवश्यकता होती है। प्रश्न उत्तर का उपयोग पारंपरिक रूप से आरसी क्षमता का आकलन करने के लिए किया जाता है, दोनों कृत्रिम एजेंटों और बच्चों को पढ़ने के लिए सीखने में। हालांकि, मौजूदा आरसी डेटासेट और कार्यों में उन प्रश्नों का प्रभुत्व है जिन्हें सतही जानकारी (जैसे, स्थानीय संदर्भ समानता या वैश्विक शब्द आवृत्ति) का उपयोग करके उत्तरों का चयन करके हल किया जा सकता है; वे इस प्रकार आर सी के आवश्यक एकीकृत पहलू के लिए परीक्षण करने में विफल रहते हैं। भाषा की गहरी समझ पर प्रगति को प्रोत्साहित करने के लिए, हम एक नया डेटासेट और कार्यों का सेट प्रस्तुत करते हैं जिसमें पाठक को पूरी किताबें या फिल्म स्क्रिप्ट पढ़कर कहानियों के बारे में सवालों के जवाब देने चाहिए। इन कार्यों को डिज़ाइन किया गया है ताकि उनके सवालों का सफलतापूर्वक जवाब देने के लिए उथले पैटर्न मिलान या लचीलेपन पर भरोसा करने के बजाय अंतर्निहित कथा को समझने की आवश्यकता हो। हम दिखाते हैं कि यद्यपि मनुष्य कार्यों को आसानी से हल करते हैं, मानक आरसी मॉडल यहां प्रस्तुत कार्यों पर संघर्ष करते हैं। हम डेटासेट और इसके द्वारा प्रस्तुत चुनौतियों का विश्लेषण प्रदान करते हैं।</abstract_hi>
      <abstract_ga>Éilíonn Léamhthuiscint (RC) - i gcodarsnacht le haisghabháil faisnéise - faisnéis agus réasúnaíocht faoi imeachtaí, aonáin, agus a gcaidreamh a chomhtháthú trasna doiciméad iomlán. Go hiondúil úsáidtear freagra ceisteanna chun cumas RC a mheas, i ngníomhairí saorga agus i leanaí atá ag foghlaim na léitheoireachta. Mar sin féin, tá na tacair sonraí agus na dtascanna RC atá ann cheana féin faoi cheannas na gceisteanna is féidir a réiteach trí fhreagraí a roghnú ag úsáid faisnéis fhorleathan (m.sh. cosúlacht sa chomhthéacs áitiúil nó minicíocht téarma domhanda); dá bhrí sin ní dhéanann siad tástáil le haghaidh gné riachtanach lánpháirtithe RC. Chun dul chun cinn ar thuiscint níos doimhne ar theanga a spreagadh, cuirimid tacar sonraí nua agus sraith tascanna i láthair ina gcaithfidh an léitheoir ceisteanna faoi scéalta a fhreagairt trí leabhair iomlána nó scripteanna scannáin a léamh. Tá na tascanna seo deartha sa chaoi is go n-éilíonn freagairt rathúil a gcuid ceisteanna tuiscint a fháil ar an scéal bunúsach seachas a bheith ag brath ar mheaitseáil nó ar shuntas patrún éadomhain. Léiríonn muid, cé go réitíonn daoine na tascanna go héasca, go mbíonn samhlacha caighdeánacha RC ag streachailt ar na tascanna a chuirtear i láthair anseo. Cuirimid anailís ar fáil ar an tacar sonraí agus ar na dúshláin a chuireann sé i láthair.</abstract_ga>
      <abstract_el>Η κατανόηση ανάγνωσης (σε αντίθεση με την ανάκτηση πληροφοριών) απαιτεί την ενσωμάτωση πληροφοριών και συλλογισμού σχετικά με γεγονότα, οντότητες και τις σχέσεις τους σε ένα πλήρες έγγραφο. Η απάντηση στις ερωτήσεις χρησιμοποιείται συμβατικά για να αξιολογήσει την ικανότητα RC, τόσο σε τεχνητούς παράγοντες όσο και σε παιδιά που μαθαίνουν να διαβάζουν. Ωστόσο, τα υπάρχοντα σύνολα δεδομένων και τα καθήκοντα RC κυριαρχούν από ερωτήματα που μπορούν να επιλυθούν επιλέγοντας απαντήσεις χρησιμοποιώντας επιφανειακές πληροφορίες (π.χ. ομοιότητα τοπικού πλαισίου ή συχνότητα παγκόσμιων όρων). Συνεπώς, δεν μπορούν να ελέγξουν την ουσιαστική ενοποιητική πτυχή της RC. Για να ενθαρρύνουμε την πρόοδο στην βαθύτερη κατανόηση της γλώσσας, παρουσιάζουμε ένα νέο σύνολο δεδομένων και ένα σύνολο εργασιών στα οποία ο αναγνώστης πρέπει να απαντήσει σε ερωτήσεις σχετικά με ιστορίες διαβάζοντας ολόκληρα βιβλία ή σενάρια ταινιών. Αυτές οι εργασίες είναι σχεδιασμένες έτσι ώστε η επιτυχής απάντηση στις ερωτήσεις τους απαιτεί κατανόηση της υποκείμενης αφήγησης αντί να βασίζεται σε ρηχή αντιστοίχιση μοτίβων ή ευδιάκριτη εμφάνιση. Δείχνουμε ότι αν και οι άνθρωποι λύνουν εύκολα τα καθήκοντα, τα τυποποιημένα μοντέλα δυσκολεύονται στις εργασίες που παρουσιάζονται εδώ. Παρέχουμε μια ανάλυση του συνόλου δεδομένων και των προκλήσεων που παρουσιάζει.</abstract_el>
      <abstract_hu>Az olvasási megértés (RC) – ellentétben az információvisszakereséssel – szükségessé teszi az eseményekkel, entitásokkal és azok kapcsolataival kapcsolatos információk és érvelések integrálását egy teljes dokumentumban. A kérdések megválaszolását hagyományosan használják az RC képességek felmérésére, mind a mesterséges anyagok, mind az olvasást tanuló gyermekek esetében. A meglévő RC-adatkészleteket és feladatokat azonban olyan kérdések uralják, amelyeket felületes információk (pl. helyi kontextushasonlóság vagy globális kifejezések gyakorisága) segítségével lehet megoldani; így nem tesztelik az RC alapvető integrációs aspektusát. A nyelv mélyebb megértésének előmozdítása érdekében új adatkészletet és feladatokat mutatunk be, amelyekben az olvasónak teljes könyvek vagy filmforgatókönyvek olvasásával kell megválaszolnia a történetekkel kapcsolatos kérdéseket. Ezeket a feladatokat úgy tervezték meg, hogy a kérdéseik sikeres megválaszolása inkább a mögöttes elbeszélés megértéséhez szükséges, mintsem a sekély mintaegyezésre vagy kiemelésre támaszkodni. Megmutatjuk, hogy bár az emberek könnyen megoldják a feladatokat, a standard RC modellek küzdenek az itt bemutatott feladatokkal. Elemzést nyújtunk az adatkészletről és az általa jelentett kihívásokról.</abstract_hu>
      <abstract_ka>ინფორმაციის მიღებაზე კონტრასტურად ინფორმაციის ინტერგურაცია და პარამენტის შესახებ მოვლენები, ინტერციები და მათი შესახებ სამყარო დოკუმენტის შესახებ უნდა ინტერგ პროგრამის შესაძლებლობად კითხვის პასუხი კითხვის შესაძლებლობაში გამოყენება RC შესაძლებლობაში, ორივე მსგავსი ადვნენტებში და ბავშვებში, რომლებიც კითხვის მაგრამ არსებობს RC მონაცემები და დავალებები დომინტრებულია კითხვებით, რომლებიც შეუძლიათ გადაწყენოთ პასუხების გამოყენებით გამოიყენებით საფუძველი ინფორმაციის გამოყენებით (მა ისინი არ შეუძლებელია RC-ის მნიშვნელოვანი ინტერგრაციური ადექტის ტესტის შესახებ. რომ უფრო დიდი სიტყვის გაგრძნობის პროგრესის შესაძლებლობად, ჩვენ ახალი მონაცემების კონფიგურაციას და რაოდენობის რაოდენობების შესაძლებლობა, რომელსაც კითხველი უნდა გაუკეთოთ ეს დავალებები განაზღვრებულია, რადგან წარმატებით მისი კითხვების შესაძლებლობა უნდა გავიგოთ ქვეყნებული ისტორია, მაგრამ უფრო დარწმუნდეთ საშუალოდ სტრუქტ ჩვენ ჩვენ აჩვენებთ, რომ თუმცა ადამიანები ადამიანის დავალების ადამიანი გაუკეთება, სტანდარტური RC მოდელები აქ ჩვენებული დავალების შემდეგ ბრძნობა. ჩვენ მონაცემების ანალიზაციას და გამოცემების გამოყენება.</abstract_ka>
      <abstract_it>La comprensione della lettura (RC) – a differenza del recupero delle informazioni – richiede l'integrazione di informazioni e ragionamenti su eventi, entità e loro relazioni attraverso un documento completo. La risposta alle domande è convenzionalmente utilizzata per valutare la capacità RC, sia negli agenti artificiali che nei bambini che imparano a leggere. Tuttavia, i set di dati e le attività RC esistenti sono dominati da domande che possono essere risolte selezionando le risposte utilizzando informazioni superficiali (ad esempio, somiglianza del contesto locale o frequenza globale dei termini); non riescono quindi a testare l'aspetto integrativo essenziale della RC. Per incoraggiare i progressi nella comprensione più profonda del linguaggio, presentiamo un nuovo set di dati e una serie di compiti in cui il lettore deve rispondere alle domande sulle storie leggendo interi libri o sceneggiature cinematografiche. Questi compiti sono progettati in modo che rispondere con successo alle loro domande richiede la comprensione della narrativa sottostante piuttosto che affidarsi ad un pattern matching superficiale o salience. Mostriamo che sebbene gli esseri umani risolvano facilmente i compiti, i modelli RC standard lottano sui compiti presentati qui. Forniamo un'analisi del set di dati e delle sfide che esso presenta.</abstract_it>
      <abstract_kk>Мәліметті алу арқылы (RC) түсініктерді оқу үшін - мәліметті алу арқылы - оқиғалар, нысандар және олардың қатынастарын толық құжатта біріктіру және түсініктерін бірікт Сұрақ жауап беру әдетте RC мүмкіндігін оқу үшін, әртүрлі агенттер мен балалар оқу үшін қолданылады. Бірақ, бар RC деректер қорлары мен тапсырмалар жауаптарды таңдап, жауаптарды таңдай алатын сұрақтар (мысалы, жергілікті контекстің ұқсастығы не жалпы терминнің жиілігі); Олар РК-нің негізгі интеграциялық аспектін тексеруге болмайды. Тілдердің түсініктерін жаңа деректер жинағын және оқушы оқиғаларды оқуға не фильм скрипттерді оқу үшін оқиғалар туралы сұрақтарды жауап беру керек. Бұл тапсырмалар құрылған, сондықтан олардың сұрақтарына сәтті жауап беру керек, олардың түсініктерін түсінуге қажет болады. Бұл үлгі сәйкестіктеріне сәйкес немесе Біз адамдар тапсырмаларды оңай шешуге қарағанда, мұнда көрсетілген тапсырмалардың стандартты RC үлгілері күреседі. Біз деректер қорларының анализациясын және оның көрсетілетін мәселелерін береміз.</abstract_kk>
      <abstract_lt>Skaitymo supratimas (RC), priešingai nei informacijos gavimas, reikalauja, kad informacija ir argumentai apie įvykius, subjektus ir jų santykius būtų įtraukti į visą dokumentą. Klausimų atsakymas paprastai naudojamas vertinant RC gebėjimą tiek dirbtiniams veiksniams, tiek skaityti mokantiems vaikams. Tačiau esamiems RK duomenų rinkiniams ir užduotims dominuoja klausimai, kuriuos galima išspręsti pasirinkus atsakymus naudojant paviršinę informaciją (pvz., vietos konteksto panašumą arba pasaulinį terminų dažnį); taigi jie neišbando esminio integracinio RC aspekto. Siekiant skatinti pažangą giliau suprantant kalbą, pristatome naują duomenų rinkinį ir užduočių rinkinį, kuriame skaitytojas turi atsakyti į klausimus apie istorijas skaitydamas visas knygas ar filmų scenarijus. Šios užduotys suprojektuotos taip, kad sėkmingai atsakant į jų klausimus būtų būtina suprasti pagrindinę narraciją, o ne pasikliauti plokščiu modelio sutampamumu ar protingumu. Mes rodome, kad nors žmonės lengvai išspręsia užduotis, standartiniai RC modeliai kovoja su šioje srityje pateiktomis užduotimis. Pateikiame duomenų rinkinio ir jos keliamų iššūkių analizę.</abstract_lt>
      <abstract_mk>Читањето на разбирањето (РЦ) – во спротивност на добивањето информации – бара интеграција на информациите и размислувањето за настаните, ентитетите и нивните односи низ целиот документ. Одговорите на прашањата се конвенционално користат за проценка на способноста на РЦ, и во вештачките агенти, и во децата кои учат да читаат. Сепак, постоечките групи податоци и задачи на РЦ се доминирани од прашања кои може да се решат со избор на одговори користејќи површни информации (на пример, локална сличност на контекст или глобална фреквенција на терминот); тие не успеваат да го тестираат основниот интегративен аспект на РЦ. За да го охрабриме напредокот во подлабоко разбирање на јазикот, претставуваме нов набор на податоци и набор на задачи во кои читателот мора да одговори на прашања за приказните со читање на цели книги или филмски скрипти. Овие задачи се дизајнирани за успешно одговорување на нивните прашања да бара разбирање на основната приказна наместо да се потпираат на ниско споредување на шеми или ослободување. Ние покажуваме дека иако луѓето лесно ги решаваат задачите, стандардните RC модели се борат со задачите претставени овде. Ние обезбедуваме анализа на податоците и предизвиците кои ги претставува.</abstract_mk>
      <abstract_ms>Pembacaan pemahaman (RC)—berbeza dengan pemulihan maklumat—memerlukan penyelesaian maklumat dan alasan mengenai peristiwa, entiti, dan hubungan mereka di seluruh dokumen penuh. Jawapan soalan digunakan secara konvensional untuk menilai kemampuan RC, dalam agen buatan dan kanak-kanak belajar membaca. Namun, set data dan tugas RC yang wujud didominasi oleh soalan yang boleh diselesaikan dengan memilih jawapan menggunakan maklumat permukaan (cth., persamaan konteks setempat atau frekuensi terma global); mereka gagal menguji aspek integratif penting RC. Untuk mendorong kemajuan dalam pemahaman bahasa yang lebih dalam, kami memperkenalkan set data baru dan set tugas di mana pembaca mesti menjawab soalan tentang cerita dengan membaca seluruh buku atau skrip filem. Tugas-tugas ini dirancang supaya menjawab soalan mereka dengan berjaya memerlukan pemahaman cerita yang didasarkan daripada bergantung pada persamaan corak rendah atau kelebihan. Kami menunjukkan bahawa walaupun manusia menyelesaikan tugas dengan mudah, model RC piawai berjuang pada tugas yang dihadapkan di sini. Kami memberikan analisis set data dan cabaran yang ia perkenalkan.</abstract_ms>
      <abstract_ml>Reading comprehension (RC)—in contrast to information retrieval—requires integrating information and reasoning about events, entities, and their relations across a full document.  ചോദ്യത്തിന്റെ ഉത്തരമെടുക്കുന്നത് RC ശക്തിയെയും വായിക്കാന്‍ പഠിക്കുന്ന ഏജന്റുകളെയും കുട്ടികളെയും പരിഗണ എന്നാലും നിലവിലുള്ള RC ഡാറ്റാസറ്റുകളും ജോലികളും പരിഹരിക്കുന്ന ചോദ്യങ്ങളാല്‍ ഉത്തരം തെരഞ്ഞെടുക്കാന്‍ സാധിക്കുന്നു അതുകൊണ്ട് ആര്‍സിയുടെ പ്രധാനപ്പെട്ട ഒരുമിച്ച ഭാഗങ്ങള്‍ക്ക് പരീക്ഷിക്കാന്‍ അവര്‍ക്ക് പരാജയപ്പെ ഭാഷയുടെ ആഴത്തിലുള്ള പ്രവർത്തനങ്ങളെക്കുറിച്ച് പ്രേരിപ്പിക്കാനാണ് ഞങ്ങൾ ഒരു പുതിയ ഡാറ്റാസേറ്റ് കൊണ്ടുവരുന്നത്. ഒരു ജോലികളെ ഈ ജോലികള്‍ നിര്‍മ്മിക്കപ്പെട്ടിരിക്കുന്നു. അതുകൊണ്ട് അവരുടെ ചോദ്യങ്ങള്‍ക്ക് വിജയകരമായി ഉത്തരം നല്‍കുന്നതിനാല്‍ അടിസ്ഥാ മനുഷ്യര്‍ ജോലികള്‍ എളുപ്പമായി പരിഹരിക്കുന്നുവെങ്കിലും, ഇവിടെ കൊണ്ടുവരുന്ന ജോലികളില്‍ സാധാരണ RC മോഡലുകള്‍ പോ നമ്മള്‍ ഡാറ്റാസറ്റിന്റെ അന്വേഷണം കൊടുക്കുന്നു. അതിന്റെ സങ്കേതികളും.</abstract_ml>
      <abstract_mt>Il-fehim tal-qari (RC)—b’kuntrast mal-ġbir tal-informazzjoni—jeħtieġ l-integrazzjoni tal-informazzjoni u r-raġunament dwar avvenimenti, entitajiet, u r-relazzjonijiet tagħhom f’dokument sħiħ. It-tweġiba għall-mistoqsijiet tintuża konvenzjonalment biex tiġi vvalutata l-ħila tal-RC, kemm fl-aġenti artifiċjali kif ukoll fit-tfal li jitgħallmu jaqraw. Madankollu, settijiet ta’ dejta u kompiti e żistenti tal-RC huma ddominati minn mistoqsijiet li jistgħu jiġu solvuti billi jintgħażlu tweġibiet bl-użu ta’ informazzjoni superfiċjali (eż., similarità tal-kuntest lokali jew frekwenza globali tat-terminu); b’hekk jonqsu milli jittestjaw għall-aspett integrattiv essenzjali tal-RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts.  Dawn il-kompiti huma mfassla sabiex iwieġbu b’suċċess il-mistoqsijiet tagħhom jirrikjedu fehim tan-narrattiva sottostanti minflok jiddependu fuq tqabbil ta’ mudelli baxxi jew salienza. Aħna nuru li għalkemm il-bnedmin isolvu l-kompiti faċilment, il-mudelli standard tar-RC iħabbtu wiċċhom mal-kompiti ppreżentati hawnhekk. Aħna nipprovdu analiżi tas-sett tad-dejta u l-isfidi li jippreżenta.</abstract_mt>
      <abstract_mn>Бүгдээрээ ойлголт унших нь мэдээлэл авах эсрэг мэдээлэл, үйл явдал, байгууллагууд, харилцаа нь бүрэн баримт бүрдүүлэхэд хэрэгтэй. Хариулт асуулт хариулт нь RC чадварыг үнэлэхэд хэрэглэгддэг. Гэхдээ орших RC өгөгдлийн сангууд болон үйл ажиллагаанууд гадаргуу мэдээллийг ашиглан шийдвэрлэж болох асуултуудад давамгайлагддаг. РК-ын үндсэн бүрдүүлэх талаар шалгаж чадахгүй. Холны гүн гүнзгий ойлголтын тухай хөгжлийг дэмжихийн тулд, бид уншигч ном, кино скриптүүдийг уншиж, түүхийн тухай асуудлыг хариулна. Эдгээр үйл ажиллагаа бүтээгдэхүүний асуултуудад амжилттай хариулт өгөх нь гүехэн хэлбэрээр холбогдох эсвэл сайхан байдлыг ойлгохын оронд суурь ойлголт хэрэгтэй. Бид хүмүүс үүнийг амархан шийдвэрлэхэд хэдий ч энд тайлбарласан үйлдлийн талаар стандарт РК загварууд тулалдаг. Бид өгөгдлийн сангийн шинжлэх ухаан болон үүнийг тайлбарладаг сорилтуудыг гаргадаг.</abstract_mn>
      <abstract_pl>Rozumienie czytania (RC) – w przeciwieństwie do pozyskiwania informacji – wymaga integracji informacji i rozumowania o zdarzeniach, podmiotach i ich relacjach w całym dokumencie. Odpowiedzi na pytania są konwencjonalnie używane do oceny zdolności RC, zarówno u sztucznych środków, jak i u dzieci uczących się czytać. Jednak istniejące zbiory danych i zadania RC są zdominowane przez pytania, które można rozwiązać poprzez wybór odpowiedzi za pomocą informacji powierzchownych (np. podobieństwo kontekstu lokalnego lub częstotliwość terminów globalnych); Nie potrafią zatem sprawdzić podstawowego aspektu integracyjnego RC. Aby zachęcić do głębszego zrozumienia języka, przedstawiamy nowy zestaw danych i zestaw zadań, w których czytelnik musi odpowiadać na pytania dotyczące opowieści czytając całe książki lub scenariusze filmowe. Zadania te są zaprojektowane tak, aby skuteczne odpowiedzi na ich pytania wymagały zrozumienia podstawowej narracji zamiast polegać na płytkim dopasowaniu wzorców lub wyraźności. Pokazujemy, że chociaż ludzie łatwo rozwiązują zadania, standardowe modele RC zmagają się z przedstawionymi tutaj zadaniami. Zapewniamy analizę zbioru danych i wyzwań, jakie przedstawia.</abstract_pl>
      <abstract_no>Lesing av forståelse (RC) – i contrast til informasjonshenting – krev å integrera informasjon og rasjon om hendingar, einingar og forholdene sine over eit fullstendig dokument. Svar på spørsmål er konvensjonelt brukt for å vurdere RC-kapasitet, både kunstiske agentar og barn som lærer å lesa. Men eksisterande RC-datasett og oppgåver er dominarte av spørsmål som kan løyst ved å velja svar ved hjelp av superinformasjon (f.eks. lokale kontekstsimilaritet eller global term frekvense); dei kan derfor ikkje testa for den viktigste integrerte aspekten av RC. For å oppretta framgang på dypere forståelse av språk, presenterer vi ei ny dataset og set oppgåver som lesaren må svara på spørsmål om historiar ved å lesa heile bokar eller filmskript. Desse oppgåvene er designerte slik at så fullførleg svar på spørsmålene sine krev å forstå den underliggende narrativen i staden for å forstå sålte mønsterelementsamsvar eller saliensjon. Vi viser at selv om mennesker løyser oppgåva enkelt, støtter standard RC-modeller på oppgåva som er presentert her. Vi gjev ein analyse av datasettet og utfordringane det gjev.</abstract_no>
      <abstract_ro>Înțelegerea citirii (RC) – spre deosebire de recuperarea informațiilor – necesită integrarea informațiilor și raționamentului despre evenimente, entități și relațiile acestora într-un document complet. Răspunsul la întrebări este utilizat convențional pentru a evalua capacitatea RC, atât în agenții artificiali, cât și în copiii care învață să citească. Cu toate acestea, seturile de date și sarcinile RC existente sunt dominate de întrebări care pot fi rezolvate prin selectarea răspunsurilor utilizând informații superficiale (de exemplu, similitudinea contextului local sau frecvența termenilor globali); Astfel, nu reușesc să testeze aspectul integrativ esențial al RC. Pentru a încuraja progresul în înțelegerea mai profundă a limbii, vă prezentăm un nou set de date și un set de sarcini în care cititorul trebuie să răspundă la întrebări despre povești prin citirea unor cărți întregi sau scenarii de film. Aceste sarcini sunt concepute astfel încât răspunsul cu succes la întrebările lor necesită înțelegerea narațiunii subiacente, mai degrabă decât bazarea pe potrivirea superficială a modelelor sau saliența. Noi arătăm că, deși oamenii rezolvă sarcinile cu ușurință, modelele RC standard se luptă cu sarcinile prezentate aici. Oferim o analiză a setului de date și a provocărilor pe care le prezintă.</abstract_ro>
      <abstract_sr>Čitanje razumijevanja (RC)—u suprotnosti s prikupljanjem informacija—zahteva integraciju informacija i razgovora o događajima, entitetima i njihovim odnosima u potpunom dokumentu. Odgovor na pitanja se konvencionalno koristi za procjenu sposobnosti RC-a, u umetničkim agentima i djeci koji uče čitati. Međutim, postojeće RC podaci i zadatke dominiraju pitanjima koje mogu rešiti odabereći odgovore koristeći površne informacije (npr. lokalnu kontekstsku sličnost ili globalnu terminsku frekvenciju); Zato nisu testirali ključni integrativni aspekt RC-a. Da bi ohrabrili napredak na dublje razumijevanje jezika, predstavljamo novi set podataka i set zadataka u kojima čitač mora odgovoriti na pitanja o prièama čitajući cijele knjige ili filmske scenarije. Ovi zadaci su dizajnirani tako da uspešno odgovaraju na njihova pitanja zahteva razumeti temeljnu priču umjesto da se oslanjaju na plitke uzorke odgovarajuće ili salijencije. Pokazujemo da, iako ljudi lako rešavaju zadatke, standardni RC modeli bore se za predstavljene zadatke. Mi pružamo analizu seta podataka i izazova koje predstavlja.</abstract_sr>
      <abstract_so>Waxbarashada aasaasiga ah (RC)- si ka duwan helitaanka macluumaadka waxaa looga baahan yahay mid la qabsashada macluumaad iyo ka fikir ku saabsan dhacdooyinka, entities iyo xiriirkooda oo dhan warqad buuxa. Jawaalka su'aalaha waxaa inta badan lagu isticmaalaa qiimeynta awoodda RC, marka labada dhallinyarada la barto karo. Si kastaba ha ahaatee sawirada RC iyo shaqaalaha waxaa lagu maamulaa su'aalo ay ku xalli karaan jawaabaha lagu doorto isticmaalo macluumaad dheeraad ah (tusaale, isku mid ah xiliga deegaanka ama frequency waqtiga caalamiga ah). sidaa darteed waxay ku baaqan waayeen in ay tijaabiyaan dhinaca hoose ee RC Si aan u dhiirrigelino horumarinta hoos u dhigista luuqada, waxaynu keennaa sawir cusub iyo shuqullo badan oo uu akhriyuhu ugu jawaabo su'aalo su'aalo ku saabsan warqadaha la akhriyo buugaagta ama buugaagta filimada oo dhan. Shaqooyinkaasi waxaa loo qoray si ay u jawaabaan su'aalahooda liibaansan ugu baahan yihiin inay fahamaan sheekada hoose taasoo aan ku kalsoonaanin qaab xunxun oo ku habboon ama isbedelka. Waxaynu tusnaynaa in kastoo dadku uu si fudud u xalliyo shuqullada, asalka caadiga ah ee RC waxay ku dagaalamayaan shaqada halkan lagu soo saaray. Analys baaritaanka macluumaadka iyo dhibaatooyinka ay soo saaraan.</abstract_so>
      <abstract_sv>Läsförståelse (RC) – i motsats till informationshämtning – kräver att information och resonemang om händelser, entiteter och deras relationer integreras i ett fullständigt dokument. Frågeställning används konventionellt för att bedöma RC förmåga, både i konstgjorda agens och barn som lär sig läsa. Befintliga datauppsättningar och uppgifter domineras dock av frågor som kan lösas genom att välja svar med hjälp av ytlig information (t.ex. likhet i lokal kontext eller global termfrekvens). De misslyckas därmed med att testa den väsentliga integrativa aspekten av RC. För att uppmuntra till framsteg med djupare språkförståelse presenterar vi en ny datauppsättning och en uppsättning uppgifter där läsaren måste svara på frågor om berättelser genom att läsa hela böcker eller filmmanus. Dessa uppgifter är utformade så att framgångsrikt besvara deras frågor kräver att förstå den underliggande berättelsen snarare än att förlita sig på ytlig mönstermatchning eller saliens. Vi visar att även om människor löser uppgifterna enkelt, kämpar vanliga RC-modeller med de uppgifter som presenteras här. Vi ger en analys av datauppsättningen och de utmaningar den innebär.</abstract_sv>
      <abstract_ta>தகவல் மீட்டுதலுக்கு எதிராக தொகுப்பு (RC)- படிக்க - நிகழ்வு, உண்மைகள் மற்றும் அவங்கள் முழு ஆவணத்திற்கும் முழு தொடர்புகளை ஒன்றிணைக் கேள்வியின் பதில் வழக்கமாக RC இயல்பை மதிப்பதற்கு பயன்படுத்தப்படுகிறது, கலைஞர் மற்றும் குழந்தைகளும் படிக்க கற்று ஆயினும், இருக்கும் RC தரவுத்தளங்கள் மற்றும் பணிகள் தேர்ந்தெடுக்கப்பட்டுள்ள கேள்விகளால் தீர்மானிக்கப்படும் அது மேல்மையான தகவலை தேர அதனால் ஆர்சியின் முக்கியமான ஒருங்கிணைப்பு பகுதிக்கு அவர்கள் சோதிக்க முடியவில்லை. மொழியின் ஆழமான முன்னேற்றத்தை ஆராய்ப்பதற்கு, நாம் ஒரு புதிய தகவல் அமைப்பை கொடுக்கிறோம் மற்றும் ஒரு செயல்களை கொண்டுள்ளோம். அதில் பட இந்த செயல்கள் வடிவமைக்கப்பட்டுள்ளது அதனால் வெற்றிகரமாக அவர்களின் கேள்விகளுக்கு பதில் விற்பனை சார்ந்து அல்லது விற்பனையின் மீ மனிதர்கள் பணிகளை எளிதாக தீர்க்கும் போதும், நிலையான RC மாதிரிகள் இங்கு கொண்ட பணிகளில் போராடுகிறார்கள். நாம் தரவுத்தளத்தின் ஒரு ஆய்வு மற்றும் அது தற்போதிக்கும் சவால்களை வழங்குகிறோம்.</abstract_ta>
      <abstract_si>කියවන්න පුළුවන් (RC)—තොරතුරු ගන්න පුළුවන් වෙනුවෙන් ප්‍රතිචාරයෙන්—සංවිධානයක්, සංවිධානයක්, සහ ඔවුන් ප්‍රශ්න උත්තර දෙන්න ප්‍රශ්න පුළුවන් කියලා කියවන්න පුළුවන් RC ක්‍රියාත්මක විශ්වාස කරන්න ප්‍රයෝජ නමුත්, තියෙන්නේ RC දත්ත සැටුම් සහ වැඩක් ප්‍රශ්න වලින් ප්‍රශ්න වලින් විශ්වාස කරන්න පුළුවන් උත්තර තොරතුරු තෝරගන්න (උදා ඒ වගේම ඔවුන් RC ගේ අවශ්‍යය සම්බන්ධතාවක් වෙනුවෙන් පරීක්ෂා කරන්න බැරි වුනා. භාෂාව ගොඩක් ගොඩක් තේරුම් ගන්න, අපි අළුත් දත්ත සූදානයක් හා වැඩක් සූදානයක් පෙන්වන්න, කියවන්නේ කියවන්නේ කතාවට වග මේ වැඩේ සිද්ධිය කරලා තියෙන්නේ, ඉතින් ඔවුන්ගේ ප්‍රශ්නේ සමහරවිට උත්තර දෙන්න අවශ්‍ය වෙන්න පුළුවන් විදිහ අපි පෙන්වන්නේ මිනිස්සුන් මේ වැඩක් ලේසියෙන් විස්තර කරනවා නමුත්, මෙතන පෙන්වන්න ප්‍රමාණය RC මොඩේල් වලට අපි දත්ත සූදානයේ විශ්ලේෂණයක් සහ අභ්‍යාසයක් දෙන්නේ.</abstract_si>
      <abstract_ur>(RC) سمجھ پڑھنے کی ضرورت ہے - معلومات حاصل کرنے کے بغیر - سؤال جواب سنگتا ہے کہ RC قابلیت کی آزمائش کے لئے استعمال کیا جاتا ہے، دونوں کارساز اگنٹوں اور بچوں میں پڑھنے کی تعلیم لیتے ہیں. However, existing RC data sets and tasks are dominated by questions that can be solved by selecting answers by superficial information (e.g., local context similarity or global term frequency); اس طرح وہ RC کی ضروری تفریق کے لئے امتحان نہیں کرسکتے۔ زبان کی عمیق سمجھنے کے لئے پیشرفت کی سفارش دینے کے لئے، ہم نے ایک نوی ڈیٹ سٹ اور دنیا کے مجموعے پیش کیے ہیں جن میں پڑھنے والے کو تمام کتابوں یا فیلم اسکریٹوں کی پڑھنے کے ذریعے کہانیاں کے بارے میں سوال جواب دینے کے لئے ضر یہ کام طراحی کئے گئے ہیں تاکہ ان کے سوال کو موفق طور پر جواب دینے کی ضرورت ہے کہ دھوپ پٹرنے کے مطابق یا سائل پر بھروسہ کریں ہم دکھاتے ہیں کہ اگرچہ انسان کے کاموں کو آسانی طرح حل کرتا ہے، استاندارڈ رک موڈل یہاں پیش کیے ہوئے کاموں پر جہاد کرتا ہے. ہم نے ڈیٹسٹ کی تحلیل اور چالیوں کی تحلیل دی ہے۔</abstract_ur>
      <abstract_uz>Name Soʻrov odatda o'qishni o'rganish uchun RC qobiliyatini qidirish uchun ishlatiladi. Lekin mavjud RC maʼlumotlar va vazifalar juda muloqat maʼlumot yordamida javoblarni tanlash mumkin (m. g. lokal context- moslamasi yoki global tugma frequency) bilan boshqarish mumkin. they thus fail to test for the essential integrative aspect of RC.  Tilni eng yaxshi o'zgartirish uchun yangi maʼlumot set va shu vazifalarni qo'shish uchun o'qituvchi hamma kitoblar yoki filamu skriptlarini o'qish uchun maslahatlarni javob berishimiz kerak. Bu vazifalar yaratiladi. Ularning savollariga muvaffaqiyatli javob berish kerak, balki kichkina shaklni o'xshash modelga ishlashni yoki saliqlik bilan ishlash kerak. Biz shunday ko'ramiz, oddiy oddiy narsalarni ko'rsatuvchi bo'lsa, bu yerda koʻrilgan vazifalar uchun standard RC modellari harakat qiladi. Biz maʼlumotlar sahifasini taʼlumot qilamiz va hosil qilayotgan challenglarni bajaramiz.</abstract_uz>
      <abstract_vi>Đọc to àn bộ các thông tin (RC) 812; trái với việc thu thập thông tin 812; yêu cầu ghép thông tin và lý trí về các sự kiện, thực thể, và quan hệ của chúng qua một tài liệu đầy đủ. Câu trả lời câu hỏi được dùng thường xuyên để đánh giá khả năng của RC, trong cả nhân viên nhân tạo và trẻ em học đọc. Tuy nhiên, các tập tin và các công việc trên cộng đồng đều bị ảnh hưởng bởi những câu hỏi có thể giải quyết bằng cách chọn các câu trả lời bằng thông tin hời (ví dụ, khả năng tương đồng địa phương hay tần số toàn cầu). họ không kiểm tra được yếu tố bổ sung quan trọng của RC. Để khuyến khích tiến bộ hiểu biết sâu hơn ngôn ngữ, chúng tôi giới thiệu một tập tin mới và một tập hợp các công việc mà người đọc phải trả lời câu hỏi về câu chuyện bằng cách đọc toàn bộ sách hay tập kịch điện ảnh. Những nhiệm vụ này được thiết kế để trả lời các câu hỏi thành công đòi hỏi phải hiểu được cốt truyện cơ bản chứ không phải dựa vào sự khớp mô hình nông nổi. Chúng tôi cho thấy mặc dù con người giải quyết các nhiệm vụ dễ dàng, nhưng các mẫu nâng cao chống đối các nhiệm vụ được đưa ra. Chúng tôi cung cấp một bản phân tích dữ liệu và những thử thách nó đưa ra.</abstract_vi>
      <abstract_bg>Разбирането за четене (РК) - за разлика от извличането на информация - изисква интегриране на информация и разсъждения за събития, образувания и техните взаимоотношения в пълен документ. Отговарянето на въпроси обикновено се използва за оценка на способността както при изкуствени агенти, така и при децата, които се учат да четат. Съществуващите набори от данни и задачи обаче са доминирани от въпроси, които могат да бъдат решени чрез избор на отговори с помощта на повърхностна информация (напр. прилика в локалния контекст или глобална честота на термините); По този начин те не успяват да тестват съществения интегративен аспект на РК. За да насърчим напредъка в по-дълбокото разбиране на езика, представяме нов набор от данни и набор от задачи, в които читателят трябва да отговаря на въпроси за истории чрез четене на цели книги или филмови сценарии. Тези задачи са проектирани така, че успешното отговаряне на въпросите им изисква разбиране на основния разказ, а не разчитане на плитко съвпадение на модели или подчертаване. Показваме, че въпреки че хората решават задачите лесно, стандартните модели се борят със задачите, представени тук. Ние предоставяме анализ на набора от данни и предизвикателствата, които той представя.</abstract_bg>
      <abstract_hr>Pročitanje razumijevanja (RC)-u suprotno s prikupljanjem informacija zahtijeva integraciju informacija i razgovora o događajima, subjektima i njihovim odnosima u cijelom dokumentu. Odgovor na pitanja se konvencionalno koristi za procjenu sposobnosti RC-a, u umjetničkim agentima i djeci koji uče čitati. Međutim, postojeće RC podaci i zadatke dominiraju pitanjima koje se mogu riješiti izrazom odgovora koristeći površne informacije (npr. lokalnu sličnost konteksta ili globalnu frekvenciju termina); Zato nisu testirali temeljni integrativni aspekt RC-a. Da bi potaknuli napredak na dublje razumijevanje jezika, predstavljamo novi set podataka i set zadataka u kojima čitač mora odgovoriti na pitanja o pričama čitajući cijele knjige ili filmske skriptove. Ovi zadaci su dizajnirani tako da uspješno odgovaraju na njihova pitanja zahtijeva razumjeti temeljnu priču umjesto da se oslanjaju na plitke uzorke odgovarajuće ili salijencije. Mi pokazujemo da iako ljudi lako riješe zadatke, standardni RC modeli bore se protiv zadataka predstavljenih ovdje. Mi pružamo analizu seta podataka i izazova koje predstavlja.</abstract_hr>
      <abstract_nl>Reading understanding (RC) – in tegenstelling tot information retrieval – vereist het integreren van informatie en redeneren over gebeurtenissen, entiteiten en hun relaties in een volledig document. Vragen beantwoorden wordt conventioneel gebruikt om RC vermogen te beoordelen, zowel bij kunstmatige agenten als bij kinderen die leren lezen. Bestaande RC datasets en taken worden echter gedomineerd door vragen die kunnen worden opgelost door antwoorden te selecteren met behulp van oppervlakkige informatie (bijvoorbeeld lokale context gelijkenis of globale termfrequentie); Ze slagen er dus niet in om te testen op het essentiële integratieve aspect van RC. Om vooruitgang te bevorderen op het dieper begrijpen van taal, presenteren we een nieuwe dataset en een reeks taken waarin de lezer vragen over verhalen moet beantwoorden door volledige boeken of filmscripts te lezen. Deze taken zijn zo ontworpen dat het succesvol beantwoorden van hun vragen vereist het begrijpen van het onderliggende verhaal in plaats van te vertrouwen op oppervlakkige patroonmatching of salience. We laten zien dat hoewel mensen de taken gemakkelijk oplossen, standaard RC-modellen worstelen met de hier voorgestelde taken. We bieden een analyse van de dataset en de uitdagingen die deze met zich meebrengt.</abstract_nl>
      <abstract_de>Leseverstehen (RC) – im Gegensatz zum Informationsabruf – erfordert die Integration von Informationen und Argumentationen über Ereignisse, Entitäten und ihre Beziehungen in einem vollständigen Dokument. Die Beantwortung von Fragen wird üblicherweise verwendet, um RC-Fähigkeiten zu beurteilen, sowohl bei künstlichen Agenten als auch bei Kindern, die lesen lernen. Bestehende RC-Datensätze und Aufgaben werden jedoch von Fragen dominiert, die durch Auswahl von Antworten anhand oberflächlicher Informationen gelöst werden können (z.B. lokale Kontextähnlichkeit oder globale Termfrequenz); Damit scheitern sie daran, den wesentlichen integrativen Aspekt von RC zu testen. Um Fortschritte beim tieferen Sprachverständnis zu fördern, stellen wir einen neuen Datensatz und eine Reihe von Aufgaben vor, bei denen der Leser Fragen zu Geschichten beantworten muss, indem er ganze Bücher oder Filmskripte liest. Diese Aufgaben sind so konzipiert, dass die erfolgreiche Beantwortung ihrer Fragen das Verständnis der zugrunde liegenden Erzählung erfordert, anstatt sich auf flache Musterabgleichung oder Salienz zu verlassen. Wir zeigen, dass der Mensch zwar die Aufgaben leicht löst, aber Standard-RC-Modelle mit den hier vorgestellten Aufgaben kämpfen. Wir analysieren den Datensatz und die damit verbundenen Herausforderungen.</abstract_de>
      <abstract_da>Læseforståelse (RC) – i modsætning til informationshentning – kræver integrering af information og ræsonnement om begivenheder, enheder og deres relationer på tværs af et fuldt dokument. Spørgsmål besvarelse bruges konventionelt til at vurdere RC evne, både i kunstige agenser og børn, der lærer at læse. Eksisterende datasæt og opgaver domineres dog af spørgsmål, der kan løses ved at vælge svar ved hjælp af overfladiske oplysninger (f.eks. lokal sammenhæng lighed eller global termhyppighed). de undlader således at teste for det væsentlige integrative aspekt af RC. For at fremme fremskridt med dybere sprogforståelse præsenterer vi et nyt datasæt og et sæt opgaver, hvor læseren skal besvare spørgsmål om historier ved at læse hele bøger eller filmmanuskripter. Disse opgaver er designet således, at en vellykket besvarelse af deres spørgsmål kræver forståelse af den underliggende fortælling snarere end at stole på overfladisk mønstermatchning eller fremhævelse. Vi viser, at selvom mennesker nemt løser opgaverne, kæmper standard RC modeller med de opgaver, der præsenteres her. Vi leverer en analyse af datasættet og de udfordringer, det indebærer.</abstract_da>
      <abstract_sw>Kusoma msingi (RC) tofauti na kupata taarifa zinahitaji kuunganisha taarifa na kujadili kuhusu matukio, taasisi na mahusiano yao katika nyaraka kamili. Swali la kujibu linatumiwa kwa kawaida kutathmini uwezo wa RC, katika mashirika ya viwanda na watoto wanaojifunza kusoma. Hata hivyo, seti za data na kazi zinazopo RC zinatawala na maswali yanayoweza kutatua kwa kuchagua majibu kwa kutumia taarifa za juu (kwa mfano, mazingira yanayofanana na kiwango cha muhula wa kimataifa); Kwa hiyo hushindwa kujaribu upande wa uhalisia wa RC. Ili kuhamasisha maendeleo ya kina zaidi ya lugha, tunaweka seti mpya ya taarifa na shughuli ambazo wasomaji lazima ajibu maswali kuhusu maswali yanayohusu vitabu vyote vya filamu. Kazi hizi zimetengenezwa ili kwa mafanikio kujibu maswali yao yanahitaji kuelewa hadithi za msingi badala ya kutegemea kwa mtindo mbaya unaoingana na mauzo. Tunaonyesha kwamba ingawa binadamu wanaweza kutatua kazi hizi kwa urahisi, mitindo ya msingi wa RC hupambana na kazi zilizotolewa hapa. Tunatoa uchambuzi wa kituo cha taarifa na changamoto ambazo huwasilisha.</abstract_sw>
      <abstract_tr>Laýlamak (RC) bilen maglumat almak üçin faýly okamak üçin maglumat we taryşlamak gerek. Gerçekleri, işleri we olaryň ilişkileri doly sened bilen birleştirilýär. Sorag jogapy RC ukyplary barlamak üçin, hem sanal ajamlar hem çagalar okamak üçin ullanýar. Ýöne, bar RC maglumat setirleri we zadalary üst edip çözebilecek soraglar tarapyndan domine edildi (meselâ, ýerli kontekst meňzeşliki we dünýäb terjime frekwensi) saýlarak çözülebilir; Şonuň üçin RK'yň esasy integraty bölegi üçin barlamady. Diliň derinliklerini düşünmegi üçin ilerlemegi täzeden, okuwçynyň hemme kitaplar ýa-da film skriptlerini okap hekaýa barada soraglary jogap bermeli zadlary tapdyk. Bu zadlar bolup özleriniň soraglarynyň üstüne jogap bermek üçin peýdaly düşürmek ýa süýdalyga ynanmak yerine, düşürmeli hekaýaty düşünmek gerek bolar. Biz insanlar bu görevleri kolayca çözmesine rağmen standart RC modelleri burada sunulan görevlerden mücadele ediyoruz. Biz veri setiriniň analyzasyny we munyň sowgatlarynyň kynçylygyny berýäris.</abstract_tr>
      <abstract_af>Lees verstanding (RC)-in kontras tot inligting ontvang-benodig integreer inligting en redening oor gebeurtenis, einhede en hul verwantings oor 'n vollede dokument. Fraag antwoord is konvensionale gebruik om RC-moontlikheid te asseer, in beide kunstenaarlike agente en kinders wat leer om te lees. Alhoewel, bestaande RC datastelle en opdragte word domineer deur vrae wat kan opgelos word deur te kies antwoordes deur te gebruik superficiele inligting (bv. plaaslike konteks gelykenis of globaal term frekwensie); sodat hulle misluk om te toets vir die behoorlike integratiewe aspekte van RC. Om vordering te bevestig oor dieper verstanding van taal, laat ons 'n nuwe datastel en stel van taak voorsien waarin die leser vrae oor stories moet antwoord deur die hele boeke of filmskripte te lees. Hierdie opdragte is ontwerp sodat suksesvol hulle vrae antwoord, benodig verstaan die onderstelde narratiewe eerder as vertrou op slagte patroon ooreenstemmende of salienskap. Ons wys dat alhoewel mense die opdragte maklik oplos, standaard RC-modelle struikel op die opdragte wat hier voorgestel is. Ons verskaf 'n analiseer van die datastel en die uitdagings wat dit voorsien.</abstract_af>
      <abstract_id>Membaca pemahaman (RC)-dalam perbedaan dengan penemuan informasi-membutuhkan integrasi informasi dan alasan tentang peristiwa, entitas, dan hubungan mereka di seluruh dokumen penuh. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read.  Namun, dataset dan tugas RC yang ada didominasi oleh pertanyaan yang dapat diselesaikan dengan memilih jawaban dengan menggunakan informasi superficial (conteks similaritas konteks lokal atau frekuensi terma global); sehingga mereka gagal menguji aspek integratif penting dari RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts.  Tugas-tugas ini dirancang sehingga menjawab dengan sukses pertanyaan mereka membutuhkan pemahaman narratif yang didasarkan daripada bergantung pada persamaan pola rendah atau salinsi. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here.  Kami menyediakan analisis dataset dan tantangan-tantangannya.</abstract_id>
      <abstract_sq>Reading comprehension (RC)-in contrast to information retrieval-requires integrating information and reasoning about events, entities, and their relations across a full document.  Përgjigja e pyetjeve përdoret tradicionalisht për të vlerësuar aftësinë e RC-së, si në agjentët artificial ë ashtu edhe fëmijët që mësojnë të lexojnë. Megjithatë, të dhënat dhe detyrat ekzistuese të RC dominohen nga pyetje që mund të zgjidhen duke zgjedhur përgjigjet duke përdorur informacion sipërfaqësor (për shembull ngjashmëria e kontekstit lokal apo frekuenca globale e termit); ata kështu dështojnë të testojnë për aspektin thelbësor të integrimit të RC. Për të inkurajuar përparimin në kuptimin më të thellë të gjuhës, ne paraqesim një sërë të dhënash të reja dhe një sërë detyrash në të cilat lexuesi duhet të përgjigjet pyetjeve rreth historive duke lexuar libra të tëra apo skripte filmi. Këto detyra janë projektuar në mënyrë që përgjigja me sukses e pyetjeve të tyre të kërkojë kuptimin e rrëfimit themelor në vend që të mbështetet në përputhjen e modelit të thellë apo rëndësinë. Ne tregojmë se megjithëse njerëzit zgjidhin detyrat lehtë, modelet standarde RC luftojnë mbi detyrat e paraqitura këtu. Ne japim një analizë të të dhënave dhe sfidave që paraqet.</abstract_sq>
      <abstract_am>Reading comprehension (RC)-in contrast to information retrieval-requires integrating information and reasoning about events, entities, and their relations across a full document.  ጥያቄ መልስ በመጠቀም RC ኃይልን በማስተካከል፣ በሥልጣናት እና ልጆችም ለማንበብ የሚያስተምሩ ነው፡፡ ምንም እንኳን፣ የአሁኑ RC ዳታተሮች እና ስራዎችን በመምረጥ ጥያቄዎች በመምረጥ ላይ መረጃ በመምረጥ ይጠቅማል፡፡ ስለዚህም RC በሚያስፈልገው ጠቅላላ ጉዳይ ይሞክራሉ፡፡ ቋንቋን ለማጠናቀቅ አዲስ ዳታተር እና ስራዎችን እና አቆማለን፤ አንባቢው የዝርዝሮች ወይም የፊልም ጽሑፎችን በማንበብ ጉዳይ ላይ ጥያቄዎችን ለመመልስ ያስፈልጋል፡፡ እነዚህም ስራዎች የተዘጋጁ ጥያቄዎቻቸውን በመቀበል የደረጃ ታሪክ እንዲያስተውሉ፣ በመጠቀም ወይም በጭንቅ ምሳሌ ላይ ከመታሰል ይልቅ በመጠቀም የሚችሉትን ታሪክ እንዲያስተውሉ ይፈልጋሉ፡፡ ሰውነቱ ስራዎቹን በቀላል ቢፈጸም እናሳያቸዋለን፡፡ የዳታ ሳጥን እና የሚያሳየው ጥያቄዎችን እናሳውቃለን፡፡</abstract_am>
      <abstract_hy>Ինֆորմացիայի վերաբերյալ ընկալումների կարդալը պահանջում է ինտեգրել տեղեկատվությունը և մտածել իրադարձությունների, կազմակերպությունների և նրանց հարաբերությունների մասին ամբողջ փաստաթղթի մեջ: Հարցերի պատասխանը սովորաբար օգտագործվում է ՀԿ-ի կարողության գնահատման համար, և արհեստական գործակալների, և երեխաների համար, ովքեր սովորում են կարդալ: Այնուամենայնիվ, գոյություն ունեցող ՌԿ տվյալների համակարգերը և առաջադրանքները գերիշխում են հարցերով, որոնք կարող են լուծվել ընտրելով պատասխաններ՝ օգտագործելով մակերեսային տեղեկատվություն (օրինակ, տեղական կոնտեքստի նմանությունը կամ գլոբալ նրանք չեն ստուգում ՀԿ-ի հիմնական ինտեգրացիվ ասպեկտը: Որպեսզի խրախուսենք լեզվի ավելի խորը հասկանալու առաջընթացը, մենք ներկայացնում ենք նոր տվյալների համակարգ և առաջադրանքներ, որտեղ կարդացողը պետք է պատասխանի պատմությունների մասին հարցերին՝ կարդալով ամբողջ գրքերը կամ ֆիլմի գրքերը These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience.  Մենք ցույց ենք տալիս, որ չնայած որ մարդիկ հեշտությամբ լուծում են խնդիրները, ստանդարտ ՌԿ մոդելները պայքարում են այստեղ ներկայացված խնդիրների վրա: Մենք տրամադրում ենք տվյալների համակարգի վերլուծություն և այն առաջացնող մարտահրավերներ:</abstract_hy>
      <abstract_az>Qəbər alınması ilə (RC) anlaşılığı oxuyarkən məlumat alması haqqında məlumatları, olaraq, məlumatları və əlaqələrini bütün bir dökümə ilə birləşdirmək lazımdır. Söylə cavab vermək RC qabiliyyətini təsdiqləmək üçün, həmçin in sanatlı ajanlar və uşaqlar oxumaq öyrənmək üçün işlədilər. Ancaq, mövcud RC veri qurğuları və işləri üstünlük məlumatları istifadə edərək çəkilən cavabları seçərək dəstəklənir. buna görə də RC'nin əsas integratlı hissəsini imtahana çəkməyə başarısız oldular. Dillərin daha derin anlaşılmasını təşkil etmək üçün, oxuyucunun bütün kitablar və film skriptlərini oxuyaraq hekayələri haqqında soruşmalarına cavab verməsi lazım olan yeni verilən qurğuları və işləri təşkil edirik. Bu işlər müəyyən edilmişdir ki, suallarına müvəffəqiyyətlə cavab vermək üçün çətinliklə uyğunlaşdırma və çətinliklərə güvən etmək yerinə düzgün hekayəti anlaması lazımdır. Biz göstəririk ki, insanlar bu işləri asanlıqla çəksələr də, burada göstərilən işlərdə standart RC modelləri mübahisə edirlər. Biz verilən qurğuların analizi və göstərilən çətinləri təmin edirik.</abstract_az>
      <abstract_fa>خواندن درک (RC) در مقابل گرفتن اطلاعات نیاز دارد که اطلاعات و دلیل‌گیری در مورد اتفاقات، واحد‌ها و رابطه‌هایشان در یک سند کامل جمع شود. پاسخ سوال به طور معمولی برای ارزیابی توانایی RC استفاده می‌شود، در هر دو ماموران هنری و بچه‌ها یاد می‌گیرند که بخوانند. با این حال، مجموعه‌های داده‌های RC موجود و وظیفه‌ها توسط سوال‌هایی که می‌توانند با انتخاب جواب‌ها با استفاده از اطلاعات superficial (مثال شبیه‌سازی محلی محلی یا فرکانس اصلی جهانی) تسلیم شوند. به همین دلیل شکست نمی‌گیرند که برای نقطه‌های تفریحی اصلی RC آزمایش کنند. برای تشویق پیشرفت در درک عمیق زبان، ما یک مجموعه داده‌های جدید و مجموعه کارها را پیشنهاد می‌کنیم که در آن خواننده باید سوالات درباره داستان‌ها را با خواندن کل کتاب یا نوشته‌های فیلم جواب دهد. این وظیفه‌ها طراحی می‌شوند تا به موفقیت جواب سوال‌هایشان نیاز به فهمیدن داستان‌های بنیادی به جای استفاده کردن روی نمونه‌های گسترده یا ساده‌ای است. ما نشان می دهیم که هر چند انسان کار را به آسانی حل می کنند، مدل های استاندارد RC در مورد کارهای پیشنهاد اینجا مبارزه می کنند. ما تحلیل مجموعه داده‌ها و چالش‌هایی را که پیشنهاد می‌دهند را پیشنهاد می‌کنیم.</abstract_fa>
      <abstract_ko>읽기 이해(RC) - 정보 검색과 달리 읽기 이해는 이벤트, 실체와 그 관계에 대한 정보와 추리를 완전한 문서에 통합시켜야 한다.인공지능과 어린이의 읽기 학습에서 문답은 보통 읽기 능력을 평가하는 데 쓰인다.그러나 기존의 RC 데이터 집합과 임무는 주로 문제로 구성되어 있는데 이런 문제들은 표면 정보(예를 들어 국부 상하문 유사성이나 전역 용어 주파수)를 사용하여 답을 선택하여 해결할 수 있다.따라서 RC의 기본적인 종합적인 측면을 테스트할 수 없다.언어에 대한 깊은 이해를 촉진하기 위해 우리는 새로운 데이터 집합과 하나의 임무를 제공했다. 이런 임무에서 독자는 반드시 책 전체나 영화 각본을 읽으며 이야기와 관련된 문제를 대답해야 한다.이러한 임무의 디자인은 그들의 질문에 성공적으로 대답하기 위해 잠재적인 서사를 이해해야 하며, 얕은 패턴의 일치나 현저성에 의존하는 것이 아니라 잠재적인 서사를 이해해야 한다.인간은 이런 임무들을 쉽게 해결하지만, 표준적인 RC모델은 여기에 소개된 임무에 있어 어렵다는 점을 발견했다.우리는 데이터 집합과 그에 따른 도전에 대해 분석을 진행했다.</abstract_ko>
      <abstract_bs>Pročitanje razumijevanja (RC)-u suprotnost s prikupljanjem informacija zahtijeva integraciju informacija i razgovora o događajima, entitetima i njihovim odnosima u potpunom dokumentu. Odgovor na pitanja se konvencionalno koristi za procjenu sposobnosti RC-a, u umjetničkim agentima i djeci koji uče čitati. Međutim, postojeće RC podaci i zadatke dominiraju pitanjima koje mogu riješiti odabereći odgovore koristeći površne informacije (npr. lokalnu kontekstsku sličnost ili globalnu terminsku frekvenciju); Zato nisu testirali ključni integrativni aspekt RC-a. Da bi potaknuli napredak na dublje razumijevanje jezika, predstavljamo novi set podataka i set zadataka u kojima čitač mora odgovoriti na pitanja o pričama čitajući cijele knjige ili filmske skriptove. Ovi zadaci su dizajnirani tako da uspješno odgovaraju na njihova pitanja zahtijeva razumjeti temeljnu priču umjesto da se oslanjaju na plitke uzorke odgovarajuće ili salijencije. Mi pokazujemo da, iako ljudi lako riješe zadatke, standardni RC modeli bore se za predstavljene zadatke. Mi pružamo analizu seta podataka i izazova koje predstavlja.</abstract_bs>
      <abstract_bn>তথ্য পুনরুদ্ধারের বিরুদ্ধে সম্পূর্ণ তথ্য সম্পূর্ণ তথ্য, বস্তু এবং তাদের সম্পর্ক একত্রিত করার প্রয়োজন। প্রশ্নের উত্তর সাধারণত RC-এর ক্ষমতা মূল্যের জন্য ব্যবহার করা হয়, যা কৌতূহলিক এজেন্ট এবং শিশুদের পড়তে শিখতে পারে। তবে বিদ্যমান RC ডাটাসেট এবং কাজের মাধ্যমে প্রশ্নের মাধ্যমে নিয়ন্ত্রণ করা হচ্ছে যা অতিরিক্ত তথ্য ব্যবহার করে উত্তর নির্বাচন করে সমাধান করা যাবে (উদ তাই তারা RC এর প্রধান একত্রিত প্রান্তের জন্য পরীক্ষা করতে ব্যর্থ। ভাষার গভীর ভাষায় অগ্রগতিকে উৎসাহিত করার জন্য আমরা একটি নতুন ডাটাসেট এবং একটি কাজ উপস্থাপন করি যেখানে পাঠকের পুরো বই অথবা চলচ্চিত্রের স্ক্ এই কাজগুলো ডিজাইন করা হয়েছে যাতে সফলভাবে তাদের প্রশ্নের উত্তর প্রদান করা প্রয়োজন যে তাদের কাহিনী বুঝতে পারে তাদের কাহিনীর আমরা দেখাচ্ছি যে যদিও মানুষ সহজে কাজ সমাধান করে, তবে এখানে প্রকাশিত কাজের উপর স্থান্ডার্ডার রিসি মডেল সংগ্রাম করছ আমরা ডাটাসেটের বিশ্লেষণ এবং এটা উপস্থাপন করা চ্যালেঞ্জের ব্যাপারে বিশ্লেষণ করি।</abstract_bn>
      <abstract_ca>Reading comprehension (RC)-in contrast to information retrieval-requires integrating information and reasoning about events, entities, and their relations across a full document.  Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read.  No obstant això, els conjunts de dades i tasques de RC existents són dominats per preguntes que es poden resoldre seleccionant respostes utilitzant informació superficial (per exemple, similitud del context local o freqüència global de termes); així que no poden provar l'aspecte integrador essencial de la RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts.  These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience.  We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here.  Fem una an àlisi del conjunt de dades i dels reptes que presenta.</abstract_ca>
      <abstract_et>Lugemise arusaamine (RC) – vastupidiselt teabe hankimisele – nõuab sündmuste, üksuste ja nende suhete teabe ja arutluse integreerimist tervikdokumendis. Küsimustele vastamist kasutatakse tavaliselt RC võime hindamiseks nii kunstlike ainete kui ka lugemist õppivate laste puhul. Olemasolevates RC andmekogumites ja ülesannetes domineerivad aga küsimused, mida saab lahendada vastuste valimisega pealiskaudse teabe abil (nt kohaliku konteksti sarnasus või ülemaailmne terminite sagedus); Seega ei suuda nad riskikapitali olulist integratiivset aspekti testida. Keele sügavama mõistmise soodustamiseks esitame uue andmekogumi ja ülesannete komplekti, milles lugeja peab vastama lugude küsimustele tervete raamatute või filmide skriptide abil. Need ülesanded on kavandatud nii, et nende küsimustele edukalt vastamine nõuab pigem alusnarratiivi mõistmist, kui tugineda madalale mustrite sobitamisele või silmapaistvusele. Näitame, et kuigi inimesed lahendavad ülesandeid kergesti, on standardsed RC mudelid siin esitatud ülesannete täitmisel raske. Analüüsime andmekogumit ja selle väljakutseid.</abstract_et>
      <abstract_fi>Lukuymmärrys (RC) – toisin kuin tiedonhaku – vaatii tiedon ja päättelyn yhdistämistä tapahtumista, entiteeteistä ja niiden suhteista koko asiakirjaan. Kysymyksiin vastaamista käytetään perinteisesti RC-kyvyn arviointiin sekä keinotekoisissa tekijöissä että lukemista oppivissa lapsissa. Nykyisiä RC-aineistoja ja tehtäviä hallitsevat kuitenkin kysymykset, jotka voidaan ratkaista valitsemalla vastaukset pinnallisilla tiedoilla (esim. paikallisen kontekstin samankaltaisuus tai termien yleisyys). ne eivät siis testaa RC:n olennaista integratiivista näkökohtaa. Edistääksemme kielen syvempää ymmärtämistä esittelemme uuden aineiston ja joukon tehtäviä, joissa lukijan on vastattava tarinoihin liittyviin kysymyksiin lukemalla kokonaisia kirjoja tai elokuvakäsikirjoituksia. Nämä tehtävät on suunniteltu siten, että heidän kysymyksiinsä vastaaminen edellyttää taustalla olevan kerronnan ymmärtämistä sen sijaan, että luottaisit matalaan kuvion vastaamiseen tai korostumiseen. Osoitamme, että vaikka ihmiset ratkovat tehtävät helposti, standardit RC-mallit kamppailevat tässä esitetyissä tehtävissä. Analysoimme aineistoa ja sen tuomia haasteita.</abstract_fi>
      <abstract_cs>Porozumění čtení (RC) – na rozdíl od vyhledávání informací – vyžaduje integraci informací a uvažování o událostech, entitách a jejich vztazích napříč celým dokumentem. Odpověď na otázky se běžně používá k posouzení RC schopnosti, jak u umělých agentů, tak u dětí učících se číst. Stávajícím datovým souborům a úkolům RC ovšem dominují otázky, které lze řešit výběrem odpovědí pomocí povrchových informací (např. podobnost lokálního kontextu nebo frekvence globálních termínů); Proto nedokážou testovat základní integrační aspekt RC. Abychom podpořili pokrok v hlubším porozumění jazyku, představujeme nový datový soubor a soubor úkolů, ve kterých čtenář musí zodpovědět otázky týkající se příběhů čtením celých knih nebo filmových scénářů. Tyto úkoly jsou navrženy tak, aby úspěšné odpovědi na jejich otázky vyžadovaly porozumění základnímu příběhu spíše než spoléhat na mělké shody vzorů nebo významnost. Ukazujeme, že i když lidé řeší úkoly snadno, standardní RC modely bojují s úkoly zde prezentovanými. Poskytujeme analýzu datového souboru a výzev, které představuje.</abstract_cs>
      <abstract_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness Sugeng responseng diputungan ijol-ijolan diputêrangke nggawe kapan PN, ning kelas artikse lan kelas sing oleh basa. politenessoffpolite"), and when there is a change ("assertivepoliteness yo nganggo cara-cara sing paling maneh kanggo akeh dikenalke aspek awak dhéwé Ombudhakan langkung ngerasakno akeh luwih akeh luwih apik, awak dhéwé iso nggawe dataset anyar lan nganggo perusahaan sing kudu nggawe barang langkung dhéwé ngerasakno sing nyimpen basa sing paling dhéwé karo akeh stir sing paling dhéwé uga nyong, or a basa Awak dhéwé iki dibenakno dadi, winih kanggo ngomong nik nggabungi layang-layang sing nyatakakno Awak dhéwé éntuk wong hal-hal wong liyane luwih nggawe barang-alam iki banget, nik sampek model sing bakal nggawe barang nggawe barang iki dadi. Awak dhéwé ngewehke beraksi kanggo nggawe dataset lan kanggo dianggawe kuwi nggawe</abstract_jv>
      <abstract_sk>Razumevanje branja (RC) – v nasprotju s pridobivanjem informacij – zahteva vključitev informacij in razmišljanja o dogodkih, entitetah in njihovih odnosih v celoten dokument. Odgovarjanje na vprašanja se običajno uporablja za oceno sposobnosti RC, tako pri umetnih agentih kot pri otrocih, ki se učijo brati. Vendar v obstoječih naborih podatkov in nalogah RC prevladujejo vprašanja, ki jih je mogoče rešiti z izbiro odgovorov s površinskimi informacijami (npr. podobnost lokalnega konteksta ali globalna frekvenca izrazov); Zato ne preskusijo bistvenega integrativnega vidika RC. Da bi spodbudili napredek pri globljem razumevanju jezika, predstavljamo nov nabor podatkov in nabor nalog, v katerih mora bralec odgovarjati na vprašanja o zgodbah z branjem celih knjig ali filmskih scenarijev. Te naloge so zasnovane tako, da uspešno odgovarjanje na njihova vprašanja zahteva razumevanje osnovne pripovedi, namesto da se zanašajo na plitko ujemanje vzorcev ali izpostavljenost. Pokazali smo, da čeprav ljudje enostavno rešujejo naloge, se standardni RC modeli borijo pri nalogah, predstavljenih tukaj. Zagotavljamo analizo nabora podatkov in izzivov, ki jih predstavlja.</abstract_sk>
      <abstract_he>קריאת הבנה (RC) בניגוד לשיגור מידע דורשת אינטגרציה מידע והסיבה על אירועים, יחסים, ומערכת יחסיהם בכל מסמך מלא. תשובות לשאלות משתמשות באופן קונציונלי כדי להעריך את היכולת של RC, גם בסוכנים מלאכותיים וגם ילדים ללמודים לקרוא. בכל אופן, קבוצות נתונים ומשימות RC קיימות שולטות על ידי שאלות שאפשר לפתור על ידי בחירת תשובות באמצעות מידע שטחי (למשל דמיון קונטקסט מקומי או תדירות מונח גלובלי); כך הם לא מסוגלים לבדוק את היבט האינטגרטיבי החיובי של RC. כדי לעודד התקדמות בהבנה עמוקה יותר של השפה, אנו מציגים קבוצת נתונים חדשה ומערכת משימות שבהן הקורא חייב לענות על שאלות על סיפורים על ידי קריאת ספרים שלמים או סרטים שלמים. המשימות האלה מתוכננות כדי לענות בהצלחה לשאלותיהם דורשת להבין את הסיפור הנוכחי במקום לסמוך על התאמת דפוס שטחי או מראה. אנחנו מראים שלמרות שאנשים פותרים את המשימות בקלות, דוגמנים סטנדרטיים RC נאבקים על המשימות המוציאות כאן. We provide an analysis of the dataset and the challenges it presents.</abstract_he>
      <abstract_ha>QUnicodeControlCharacterMenu Sunan tambayar ta ana amfani da shi a ɗabi'a don a iya ƙaddara abincin RC, kuma a cikin duk mataimaki da yãyen su karanta karatun. A lokacin da, ana domin tsari da masu jira na RC da aikin su na tambayi wanda za'a iya solve su da kuma za'a zãɓe su da amfani da masu tsari masu rufe (misali, misali, mazaɓa da mazaɓa mai daidaita ko kuma misali da duran muhimman duniya). Kayya, ba su yi jarraba ne masu kami na RC. Dõmin Mu ƙara gaba ga rufi da harshen, muna halatar da wani matsayi na danne da shiryoyin aikin wanda mai karantawa ya kamata ya karɓa wa maswali masu tambayar lãbãran da za'a karatun takardun littattafai ko manuscriptun filamu. Wannan aikin aka designa don a sami marubuci wajen karɓa wa maswalinsu, ana kamata su fahimta lãbãrin masu ƙaranci, kuma bã ya dõgara a kan missalin da ya yi ƙunci ko sali. Tuna nũna cewa, kuma kõ da mutum ke raba aikin su da sauƙi, misãlai na RC na tsakani a kan aikin da aka halatar da su a nan. Munã samar da anarrai ga tsari da muramman da ke gabatar da shi.</abstract_ha>
      <abstract_bo>Reading comprehension (RC)-in contrast to information retrieval-requires integrating information and reasoning about events, entities, and their relations across a full document. ཡིག་གཟུགས་ལན་གསལ་འདོན་ནི་རྩོམ་པ་ལ་ཆོས་ཉིད་དུ་གཏོང་གི་ཐབས་ཤེས་ཡོད་པ་ལས། ཡིན་ནའང་། existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g. local context similarity or global term frequency); ཆོག་ཡིན་ནའང་། དེར་བརྟེན། ཁོང་ཚོས་RC འི་ཆེད་དུ་གླེང་སྒྲིག་གི་ཆེད་དུ་བརྟག་ཞིབ་བྱེད་མི་ཐུབ། སྐད་ཡིག་གི་འདྲ་རྒྱའི་ལྟ་སྟངས་དཀའ་བར་གྱི་འཕེལ་རིམ་གྱི་འཕེལ་རིམ་ལ་གཏོང་དགོས་པའི་ནང་དུ་ཡིག་ཆ་སྒྲིག་ཡིག་ཆ་གསར་པ་ཞིག་དང་ལས་འགུལ་ བྱ་འགུལ་འདི་དག་གི་དོན་ལ་རྒྱས་ཐལ་ཐོག་ཏུ་མཐུན་པ་ལས་ཁོང་ཚོའི་དྲི་ཚིག་ལ་དང་མཉམ་དུ་མཐུན་པའི་གཟུགས་རིས་མཐུན་སྒྲིག་ ང་ཚོས་མི་རིགས་ཀྱིས་ལས་ཀ་འདི་ལས་སླ་མོལ་ལས་ཀར་ཆེན་བྱེད་པ་ཡིན་ནའང་མི་མང་གིས་ ང་ཚོས་གནས་ཚུལ་སྒྲིག་ཆ་འཕྲིན་དང་གདོང་ལེན་གྱི་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡོད།</abstract_bo>
      </paper>
    <paper id="24">
      <title>Native Language Cognate Effects on Second Language Lexical Choice</title>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <author><first>Shuly</first><last>Wintner</last></author>
      <doi>10.1162/tacl_a_00024</doi>
      <abstract>We present a computational analysis of cognate effects on the spontaneous linguistic productions of advanced non-native speakers. Introducing a large corpus of highly competent non-native English speakers, and using a set of carefully selected lexical items, we show that the lexical choices of non-natives are affected by cognates in their native language. This effect is so powerful that we are able to reconstruct the <a href="https://en.wikipedia.org/wiki/Phylogenetic_tree">phylogenetic language tree</a> of the <a href="https://en.wikipedia.org/wiki/Indo-European_languages">Indo-European language family</a> solely from the frequencies of specific lexical items in the English of authors with various native languages. We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers.</abstract>
      <pages>329–342</pages>
      <url hash="230e2b0c">Q18-1024</url>
      <video href="https://vimeo.com/285802410" />
      <bibkey>rabinovich-etal-2018-native</bibkey>
      <pwccode url="https://github.com/ellarabi/reddit-l2" additional="false">ellarabi/reddit-l2</pwccode>
    <title_ar>تأثيرات اللغة الأصلية المعرفية على الاختيار المعجمي للغة الثانية</title_ar>
      <title_fr>Effets liés à la langue maternelle sur le choix lexical de la langue seconde</title_fr>
      <title_es>Efectos afines del idioma nativo en la elección léxica de un segundo idioma</title_es>
      <title_pt>Efeitos cognatos da língua nativa na escolha léxica da segunda língua</title_pt>
      <title_ja>第二言語の言語選択へのネイティブ言語のコグネイト効果</title_ja>
      <title_ru>Влияние родного языка на лексический выбор второго языка</title_ru>
      <title_hi>दूसरी भाषा लेक्सिकल पसंद पर मूल भाषा संज्ञेय प्रभाव</title_hi>
      <title_zh>母语同源第二语言词汇所择也</title_zh>
      <title_ga>Éifeachtaí Gaolmhara Teanga Dúchais ar Rogha Foclaíochta an Dara Teanga</title_ga>
      <title_el>Γνωσιακές επιδράσεις στη Λεξική Επιλογή Δεύτερης Γλώσσας</title_el>
      <title_hu>Anyanyelv Cognate hatások a második nyelv lexikai választására</title_hu>
      <title_ka>Name</title_ka>
      <title_kk>Екінші тіл лексикалық таңдау үшін жергілікті тілдің когнат эффекттері</title_kk>
      <title_it>Effetti cognitivi della lingua nativa sulla scelta lessicale della seconda lingua</title_it>
      <title_mk>Домашниот јазик Когни ефекти на вториот јазик Лексикален избор</title_mk>
      <title_ml>രണ്ടാമത്തെ ഭാഷ ലെക്സിക്കല്‍ തെരഞ്ഞെടുക്കുന്നതില്‍ നാത്ര ഭാഷ കോഗ്നേറ്റ് പ്രഭാവങ്ങള്‍</title_ml>
      <title_lt>gimtinės kalbos pažįstamas poveikis antrosios kalbos leksiniam pasirinkimui</title_lt>
      <title_ms>Kesan Cognate Bahasa asli pada Pilihan Leksikal Bahasa Kedua</title_ms>
      <title_mt>Effetti tal-Kuntatt tal-Lingwa Nativa fuq l-Għażla Lessika tat-Tieni Lingwa</title_mt>
      <title_pl>Język ojczysty Efekty poznawcze na wybór leksykalny drugiego języka</title_pl>
      <title_mn>Хоёрдугаар хэл болон лексикийн сонголтын тулд төрөлхтний хэл</title_mn>
      <title_no>Name</title_no>
      <title_ro>Efecte cognitive de limbă nativă asupra alegerii limbii a doua</title_ro>
      <title_si>දෙවෙනි භාෂාව ලෙක්සිකාල් තෝරණයේ ස්ථානික භාෂාව සම්බන්ධතාව</title_si>
      <title_so>Effectfects of native language Cognate on the Second Luqad Leksikal</title_so>
      <title_sv>Native Language Cognate Effects on Second Language Lexical Choice</title_sv>
      <title_sr>Efekti kognate jezika na drugi leksički izbor jezika</title_sr>
      <title_ta>மொழி குறியீட்டு விளைவுகள் இரண்டாவது மொழி லெக்சிகல் தேர்வில் உள்ளது</title_ta>
      <title_ur>دوسری زبان لکسیکل انتخاب پر نائب زبان کی کنٹی اثرات</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Hậu quả phát ngôn ngữ bản địa về ngôn ngữ học thứ hai</title_vi>
      <title_nl>Native Language Cognate Effecten op Second Language Lexical Choice</title_nl>
      <title_hr>Učinci kognate jezika na drugi leksički izbor jezika</title_hr>
      <title_bg>Когнитни ефекти на родния език върху лексикалния избор на втори език</title_bg>
      <title_de>Native Language Cognate Effects on Second Language Lexical Choice</title_de>
      <title_id>Native Language Cognate Effects on Second Language Lexical Choice</title_id>
      <title_da>Native Language Cognate Effekter på andetsprog Lexical Choice</title_da>
      <title_fa>اثرات تغییرات زبان طبیعی روی انتخاب تغییرات زبان دوم</title_fa>
      <title_tr>Ýabşyrky Diller Beýiksel Saýlawda Etkiler</title_tr>
      <title_af>Name</title_af>
      <title_sq>Gjuha e lindur ka efekte në zgjedhjen e gjuhës së dytë</title_sq>
      <title_am>ቋንቋ</title_am>
      <title_ko>모국어 동원어가 제2언어 어휘 선택에 미친 영향</title_ko>
      <title_sw>Matokeo ya Ushirika wa Lugha ya Kiasili kwenye Uchaguzi wa pili wa Lugha ya Kilexico</title_sw>
      <title_hy>Ծննդյան լեզուն ճանաչող ազդեցություններ երկրորդ լեզվի լեքսիկական ընտրության վրա</title_hy>
      <title_az>İkinci Dil Leksikal Seçimi</title_az>
      <title_bs>Efekti kognate jezika na drugi leksički izbor jezika</title_bs>
      <title_cs>Rodný jazyk Kognitivní efekty na výběr Lexikálního jazyka druhého jazyka</title_cs>
      <title_et>Native Language Cognate Effects on Second Language Lexical Choice</title_et>
      <title_ca>Els efectes coneguts de la llengua nativa en la elecció lèxica de la segona llengua</title_ca>
      <title_fi>Native Language Cognate Effects on Second Language Lexical Choice</title_fi>
      <title_bn>দ্বিতীয় ভাষার লেক্সিক্যাল নির্বাচনে স্থানীয় ভাষার কোগনেট প্রভাব</title_bn>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_jv>lahir</title_jv>
      <title_he>Native Language Cognate Effects on Second Language Lexical Choice</title_he>
      <title_sk>Učinki maternega jezika na leksično izbiro drugega jezika</title_sk>
      <title_bo>སྐད་ཡིག་གཟུགས་ཐག་གདམ་ཀ་གཉིས་པ་ནི་སྐད་ཡིག་ཆ་Cognate Effects on Second Language Lexical Choice</title_bo>
      <abstract_fr>Nous présentons une analyse informatique des effets apparentés sur les productions linguistiques spontanées de locuteurs non natifs avancés. En présentant un vaste corpus d'anglophones non natifs hautement compétents et en utilisant un ensemble d'éléments lexicaux soigneusement sélectionnés, nous montrons que les choix lexicaux des non-natifs sont influencés par des apparentés dans leur langue maternelle. Cet effet est si puissant que nous sommes en mesure de reconstruire l'arbre linguistique phylogénétique de la famille des langues indo-européennes uniquement à partir des fréquences d'éléments lexicaux spécifiques en anglais d'auteurs de différentes langues maternelles. Nous analysons quantitativement le choix lexical non natif, en soulignant que la facilitation apparentée est l'un des phénomènes importants qui façonnent la langue des locuteurs non natifs.</abstract_fr>
      <abstract_ar>نقدم تحليلًا حسابيًا للتأثيرات المماثلة على الإنتاج اللغوي العفوي للمتحدثين المتقدمين من غير الناطقين بها. من خلال تقديم مجموعة كبيرة من الناطقين باللغة الإنجليزية من غير الناطقين باللغة الإنجليزية على درجة عالية من الكفاءة ، وباستخدام مجموعة من العناصر المعجمية المختارة بعناية ، نظهر أن الاختيارات المعجمية لغير الناطقين بها تتأثر بالآخرين في لغتهم الأم. هذا التأثير قوي للغاية لدرجة أننا قادرون على إعادة بناء شجرة لغة النشوء والتطور لعائلة اللغات الهندو أوروبية فقط من ترددات عناصر معجمية محددة في اللغة الإنجليزية لمؤلفين ذوي لغات أصلية مختلفة. نحن نحلل كميًا الاختيار المعجمي غير الأصلي ، مع إبراز التيسير المعرفي كواحدة من الظواهر المهمة التي تشكل لغة المتحدثين غير الأصليين.</abstract_ar>
      <abstract_es>Presentamos un análisis computacional de los efectos afines en las producciones lingüísticas espontáneas de hablantes no nativos avanzados. Presentando un amplio corpus de hablantes no nativos de inglés altamente competentes y utilizando un conjunto de elementos léxicos cuidadosamente seleccionados, demostramos que las elecciones léxicas de los no nativos se ven afectadas por los cognados en su idioma nativo. Este efecto es tan poderoso que podemos reconstruir el árbol lingüístico filogenético de la familia lingüística indoeuropea únicamente a partir de las frecuencias de elementos léxicos específicos en el inglés de autores con varias lenguas nativas. Analizamos cuantitativamente la elección léxica no nativa, destacando la facilitación afín como uno de los fenómenos importantes que dan forma al idioma de los hablantes no nativos.</abstract_es>
      <abstract_pt>Apresentamos uma análise computacional dos efeitos cognatos nas produções linguísticas espontâneas de falantes não nativos avançados. Apresentando um grande corpus de falantes não nativos de inglês altamente competentes e usando um conjunto de itens lexicais cuidadosamente selecionados, mostramos que as escolhas lexicais de não nativos são afetadas por cognatos em sua língua nativa. Esse efeito é tão poderoso que podemos reconstruir a árvore filogenética das línguas da família das línguas indo-europeias apenas a partir das frequências de itens lexicais específicos no inglês de autores com várias línguas nativas. Analisamos quantitativamente a escolha lexical não nativa, destacando a facilitação cognata como um dos fenômenos importantes que moldam a linguagem de falantes não nativos.</abstract_pt>
      <abstract_ja>私たちは、高度な非ネイティブスピーカーの自発的な言語生産への同種の影響の計算分析を提示します。非常に有能な非ネイティブ英語話者の大規模なコーパスを紹介し、慎重に選択された一連の語彙項目を使用して、非ネイティブの語彙選択が彼らのネイティブ言語のコグネイトの影響を受けることを示します。この効果は非常に強力であるため、インド・ヨーロッパ語族の系統樹を、さまざまな母語を持つ著者の英語の特定の語彙項目の頻度からのみ再構築することができます。私たちは、非ネイティブの語彙的選択を定量的に分析し、非ネイティブスピーカーの言語を形作る重要な現象の1つとして同種のファシリテーションを強調しています。</abstract_ja>
      <abstract_zh>同源效高第母语自发言生计。 引入大任非英语母语人士语料库,并用精选词汇目,明非母语者词汇择受其母语同源词也。 其强大如此,至于百母语之英语特定词汇项目频建印欧语系系统育言语树。 定量分析非母语词汇择,同源非母语人语。</abstract_zh>
      <abstract_hi>हम उन्नत गैर-देशी वक्ताओं की सहज भाषाई प्रस्तुतियों पर संज्ञानात्मक प्रभावों का एक कम्प्यूटेशनल विश्लेषण प्रस्तुत करते हैं। अत्यधिक सक्षम गैर-देशी अंग्रेजी बोलने वालों के एक बड़े कॉर्पस का परिचय देते हुए, और सावधानीपूर्वक चयनित लेक्सिकल आइटम के एक सेट का उपयोग करके, हम दिखाते हैं कि गैर-मूल निवासियों के लेक्सिकल विकल्प उनकी मूल भाषा में कॉग्नेट्स से प्रभावित होते हैं। यह प्रभाव इतना शक्तिशाली है कि हम विभिन्न मूल भाषाओं के साथ लेखकों की अंग्रेजी में विशिष्ट लेक्सिकल वस्तुओं की आवृत्तियों से पूरी तरह से इंडो-यूरोपीय भाषा परिवार के फाइलोजेनेटिक भाषा पेड़ का पुनर्निर्माण करने में सक्षम हैं। हम मात्रात्मक रूप से गैर-देशी लेक्सिकल पसंद का विश्लेषण करते हैं, गैर-देशी वक्ताओं की भाषा को आकार देने वाली महत्वपूर्ण घटनाओं में से एक के रूप में संज्ञानात्मक सुविधा को उजागर करते हैं।</abstract_hi>
      <abstract_ru>Представляем вычислительный анализ сопутствующих эффектов на спонтанные лингвистические произведения продвинутых неродных носителей языка. Представляя большой корпус высококомпетентных неродных носителей английского языка и используя набор тщательно отобранных лексических элементов, мы показываем, что на лексический выбор неродных влияют родные на их родном языке. Этот эффект настолько силен, что мы можем реконструировать филогенетическое языковое дерево индоевропейской языковой семьи исключительно по частотам конкретных лексических элементов в английском языке авторов с различными родными языками. Мы количественно анализируем неродной лексический выбор, выделяя родственное облегчение как одно из важных явлений, формирующих язык неродных носителей.</abstract_ru>
      <abstract_ga>Cuirimid i láthair anailís ríomhaireachtúil ar éifeachtaí gaolmhara ar léiriúcháin spontáineacha teanga ardchainteoirí neamhdhúchasacha. Agus corpas mór de chainteoirí Béarla neamhdhúchasacha sár-inniúla á thabhairt isteach againn, agus ag baint úsáide as tacar de mhíreanna foclóireachta a roghnaíodh go cúramach, léirímid go mbíonn tionchar ag roghanna foclóireachta daoine neamhdhúchasacha ar ghaolmhara ina dteanga dhúchais. Tá an éifeacht seo chomh cumhachtach sin gur féidir linn crann teanga fhileigineach an teaghlaigh teanga Ind-Eorpach a athchruthú ó mhinicíocht míreanna sainiúla foclóireachta i mBéarla na n-údar a bhfuil teangacha dúchais éagsúla acu amháin. Déanaimid anailís chainníochtúil ar rogha foclóireachta neamhdhúchais, ag cur béime ar éascú gaolmhar mar cheann de na feiniméin thábhachtacha a mhúnlaíonn teanga na gcainteoirí neamhdhúchasacha.</abstract_ga>
      <abstract_ka>ჩვენ კონფიგურაციული ეფექტის კონფიგურაციის კონფიგურაციის ანალიზაციას ჩვენ აჩვენებთ სპონტანური ენგურაციური პროექტირების წარმოდგენება რომელიც ძალიან კომპეტენტური ანგლისური მუშაობების დიდი კორპუსს ჩატვირთვა, და გამოყენება კომპეტენტური ელექსიკური ელექსიკური ელექსიკური ელექსიკური არჩეულებების ლექსიკური მო ეს ეფექტი ძალიან ძალიან ძალიან, რომ ჩვენ შეგვიძლია ინდო-ევროპოული ენის ოჯახის ფილოგენეტიკური ენის ხელის შექმნა მხოლოდ სპექტიკური ლექსიკური ელექტიკური ელექტიკური ფერიკ ჩვენ კონტაქტიურად ანალიზაცით არ არის ნაირადი ლექსიკალური გამოყენება, როგორც კონტაქტის სწორედ ერთი მნიშვნელოვანი ფექომენი, რომელიც არ არის ნაირადი მუშაობელ</abstract_ka>
      <abstract_hu>Bemutatjuk a fejlett nem anyanyelvűek spontán nyelvi produkcióira gyakorolt kognált hatások számítástechnikai elemzését. Nagy kompetenciával rendelkező, nem anyanyelvű angol nyelvű anyanyelvűek széles körét mutatjuk be, és gondosan kiválasztott lexikai elemeket használunk fel arra, hogy a nem anyanyelvűek lexikai választásait befolyásolják az anyanyelvükön lévő kognátok. Ez a hatás olyan erőteljes, hogy az indoeurópai nyelvcsalád filogenetikai nyelvfáját kizárólag a különböző anyanyelvű szerzők angol nyelvű specifikus lexikai elemeinek gyakoriságából tudjuk rekonstruálni. Mennyiségileg elemezzük a nem anyanyelvű lexikai választást, kiemelve a kognált facilitációt, mint a nem anyanyelvűek nyelvének egyik fontos jelenségét.</abstract_hu>
      <abstract_el>Παρουσιάζουμε μια υπολογιστική ανάλυση των γνωστών επιδράσεων στις αυθόρμητες γλωσσικές παραγωγές προηγμένων μη μητρικών ομιλητών. Παρουσιάζοντας ένα μεγάλο σώμα από εξαιρετικά ικανούς μη φυσικούς ομιλητές της αγγλικής γλώσσας, και χρησιμοποιώντας ένα σύνολο προσεκτικά επιλεγμένων λεξικών στοιχείων, δείχνουμε ότι οι λεξικές επιλογές των μη ιθαγενών επηρεάζονται από γνωστές στη μητρική τους γλώσσα. Αυτό το αποτέλεσμα είναι τόσο ισχυρό που μπορούμε να αναδείξουμε το φυλλογενικό γλωσσικό δέντρο της ινδοευρωπαϊκής γλωσσικής οικογένειας μόνο από τις συχνότητες συγκεκριμένων λεξικών στα αγγλικά συγγραφέων με διάφορες μητρικές γλώσσες. Αναλύουμε ποσοτικά την μη μητρική λεξική επιλογή, αναδεικνύοντας τη γνωστική διευκόλυνση ως ένα από τα σημαντικά φαινόμενα που διαμορφώνουν τη γλώσσα των μη μητρικών ομιλητών.</abstract_el>
      <abstract_it>Presentiamo un'analisi computazionale degli effetti cognitivi sulle produzioni linguistiche spontanee di parlanti non nativi avanzati. Introducendo un ampio corpus di persone non madrelingua altamente competenti e utilizzando una serie di elementi lessicali accuratamente selezionati, mostriamo che le scelte lessicali dei non nativi sono influenzate dai cognati nella loro lingua madre. Questo effetto è così potente che siamo in grado di ricostruire l'albero filogenetico della famiglia linguistica indoeuropea esclusivamente dalle frequenze di specifici elementi lessicali in inglese di autori con varie lingue native. Analizziamo quantitativamente la scelta lessicale non nativa, evidenziando la facilitazione cognitiva come uno dei fenomeni importanti che modellano la lingua dei non madrelingua.</abstract_it>
      <abstract_lt>Pateikiame kompiuterinę pažintinio poveikio pažangiųjų ne gimtinių kalbėtojų spontaninėms kalbinėms produkcijoms analizę. Pateikdami didelį aukštos kvalifikacijos negyvenančių anglų kalbėtojų korpusą ir naudojant kruopščiai pasirinktus leksinius straipsnius, parodome, kad nekyvenančių asmenų leksinius pasirinkimus paveikia jų gimtąja kalba pažįstamieji asmenys. Šis poveikis yra toks galingas, kad galime atkurti indoeuropietiškos kalbos šeimos filogenetinį medį tik iš konkrečių tekstinių straipsnių dažnių anglų kalba, kuriuose rašomi įvairios gimtosios kalbos. Mes kiekybiškai analizuojame ne gimtąjį leksinį pasirinkimą, pabrėždami pažinties palengvinimą kaip vieną iš svarbių reiškinių, formuojančių ne gimtųjų kalbėtojų kalbą.</abstract_lt>
      <abstract_mk>Презентираме компјутативна анализа на когнатите ефекти на спонтаните јазични производи на напредните не-родни говорници. Внесувајќи голем корпус високо компетентни англиски не-родни говорници, и користејќи сет внимателно избрани лексични предмети, покажуваме дека лексичките избори на не-родните се влијаени од когнатите на нивниот роден јазик. Овој ефект е толку моќен што можеме да го реконструираме дрвото на филогенетскиот јазик на семејството на индо-европски јазици само од фреквенциите на специфичните лексикални предмети на англискиот јазик на авторите со различни родни јазици. Ние квантитивно анализираме нероден лексикален избор, истакнувајќи го олеснувањето на когнатите како еден од важните феномени кои го формираат јазикот на неродните говорници.</abstract_mk>
      <abstract_kk>Біз тілді емес сөйлейткердің автоматты лингвистикалық жасауларының белгілі эффекттерін есептеп анализ береміз. Енді ағылшын тілінде белгілі сөйлейтіншілердің үлкен корпусын таңдау және тілінде белгілі сөйлейтіншілердің лексикалық таңдауын көрсетуге болады. Бұл эффект толық күшті, біз Индо-Еуропалық тіл үйлерінің филогенетикалық тілдер ағылшын тілдерінің ағылшын тілдерінің ағылшын тілдерінің әртүрлі тілдерінің қайта жасауға болады. Біз тілді емес лексикалық таңдауын санатты түрде анализ, белгілі көмектесу үшін негізгі пайдаланушылардың тілін құру үшін белгілі болады.</abstract_kk>
      <abstract_ms>Kami memperkenalkan analisis perhitungan kesan pengetahuan pada produksi bahasa spontan dari pembicara bukan asli yang maju. Memperkenalkan korpus besar pembicara bahasa Inggeris bukan asli yang berkuasa tinggi, dan menggunakan set item leksik terpilih dengan hati-hati, kami menunjukkan bahasa pilihan leksik bukan asli dipengaruhi oleh kognat dalam bahasa asli mereka. Kesan ini sangat kuat sehingga kita boleh membina semula pokok bahasa filogenetik keluarga bahasa Indo-Eropah hanya dari frekuensi item leksikal khusus dalam bahasa Inggeris penulis dengan berbagai bahasa asli. Kami menganalisis secara kuantitatif pilihan leksik bukan asli, menyatakan kemudahan konnat sebagai salah satu fenomena penting membentuk bahasa pembicara bukan asli.</abstract_ms>
      <abstract_mn>Бид тооцооллын шинжилгээ үзүүлнэ. Хөгжиж буй орнуудын хөгжиж буй хэлний үйлдвэрлэлүүдийн сэтгэл хөдлөл боловсруулагдсан. Ихэнх Англи хэлний сурагчдын маш их компетент корпус бий болгож, анхаарлын хэл дээр анхаарлын сонгогдсон хэсэг хэрэглэхэд бид үндэстэй бус орнуудын лексикийн сонголтыг эх хэл дээр мэдлэгтэй нөлөөлдөг гэдгийг харуулж байна. Энэ нөлөө маш хүчирхэг бөгөөд бид Индо-Европын хэл гэр бүлийн филогенетик хэл модыг зөвхөн англи хэлний зохиолчдын хэлбэрээр англи хэлний хэлний тодорхой хэлбэрээс дахин бүтээж чадна. Бид үндэсний бус хэлний сонголтыг тоо хэмжээнд шинжилгээ хийж, хүлээн зөвшөөрч бус орчуудын хэл боловсруулдаг чухал явдалуудын нэг гэдгийг тодорхойлдог.</abstract_mn>
      <abstract_mt>Aħna nippreżentaw analiżi komputattiva tal-effetti konjitti fuq il-produzzjoni lingwistika spontanja ta’ kelliema avvanzati mhux nattivi. L-introduzzjoni ta’ korpus kbir ta’ kelliema Ingliżi mhux nattivi kompetenti ħafna, u bl-użu ta’ sett ta’ oġġetti lexiċi magħżula bir-reqqa, nuru li l-għa żliet lexiċi ta’ dawk mhux nattivi huma affettwati mill-kononati fil-lingwa nattiva tagħhom. Dan l-effett huwa tant qawwi li nistgħu nibnu s-siġar filoġenetiku tal-lingwa tal-familja tal-lingwi Indo-Ewropej biss mill-frekwenzi ta’ oġġetti lexiċi speċifiċi fl-Ingliż ta’ awturi b’diversi lingwi nattivi. Aħna tanalizzaw kwantitattivament l-għażla lexika mhux nattiva, filwaqt li tenfasizza l-faċilitazzjoni tal-konoxximent bħala wieħed mill-fenomeni importanti li jiffurmaw il-lingwa tal-kelliema mhux nattivi.</abstract_mt>
      <abstract_ml>നമ്മള്‍ കോഗ്നേറ്റ് പ്രഭാവങ്ങളുടെ കൂട്ടിക്കണക്ക് അന്വേഷണം കൊടുക്കുന്നു. മുന്നോട്ടുള്ള ഭാഷക്കാരുടെ സ്പാന സ്ഥാനമില്ലാത്ത ഇംഗ്ലീഷ് സംസാരിക്കുന്നവരുടെ ഒരു വലിയ കോര്‍പ്പുസിനെ പരിചയപ്പെടുത്തുന്നതും, സൂക്ഷ്മമായി തെരഞ്ഞെടുത്ത ലെക്സിക്കല്‍ വസ്തുക്കള്‍ ഉപയോഗ This effect is so powerful that we are able to reconstruct the phylogenetic language tree of the Indo-European language family solely from the frequencies of specific lexical items in the English of authors with various native languages.  സ്ഥാനമില്ലാത്ത ലെക്സിക്കല്‍ തെരഞ്ഞെടുക്കാത്തത് നമ്മള്‍ വിശ്വാസിക്കുന്നു. കോഗ്നേറ്റ് സ്വീകരിക്കുന്നതിനെ പ്രധാനപ്പെട്</abstract_ml>
      <abstract_no>Vi presenterer ein dataanalyse av kjennende effektar på den spontane språkstiske produksjonen av avanserte ikkje-native taler. Ved å introdusera ein stor korpus av svært kompetentne ikkje-lokale engelske taler, og med eit sett av forsiktig valde leksiske elementer, viser vi at dei leksiske vala av ikkje-nativ er påvirka av kjenner i dei følgjande språket sine. Dette effekten er så kraftig at vi kan gjenoppretta filogenetiske språkttre i Indo-europeiske språktfamilien berre frå frekvensene av spesifikke leksiske elementer i engelsk av utviklarane med ulike native språk. Vi analyserer kvantitativt ikkje-native leksisk val, og markerer kjente tilgjengelighet som ein av dei viktige fenomenane som skaper språket av ikkje-native taler.</abstract_no>
      <abstract_pl>Przedstawiamy obliczeniową analizę poznanych efektów na spontaniczną produkcję językową zaawansowanych osób nienative speakerów. Przedstawiając duży korpus wysoce kompetentnych nienative speakerów języka angielskiego i wykorzystując zestaw starannie dobranych elementów leksykalnych, pokazujemy, że na wybory leksykalne osób nie-native mają wpływ poznania w ich ojczystym języku. Efekt ten jest tak silny, że jesteśmy w stanie zrekonstruować filogenetyczne drzewo języków indoeuropejskich wyłącznie z częstotliwości określonych elementów leksykalnych w języku angielskim autorów z różnymi językami ojczystymi. Analizujemy ilościowo wybór leksykaliczny nienative, podkreślając ułatwienie poznania jako jedno z ważnych zjawisk kształtujących język nienative speakerów.</abstract_pl>
      <abstract_ro>Prezentăm o analiză computațională a efectelor cognitive asupra producțiilor lingvistice spontane ale vorbitorilor avansați non-nativi. Introducerea unui corpus larg de vorbitori de limba engleză non-nativă foarte competenți și folosind un set de elemente lexicale atent selectate, arătăm că opțiunile lexicale ale non-nativilor sunt afectate de cunoștințe în limba lor maternă. Acest efect este atât de puternic încât suntem capabili să reconstruim arborele limbajului filogenetic al familiei de limbi indo-europene numai din frecvențele elementelor lexicale specifice în limba engleză ale autorilor cu diferite limbi materne. Analizăm cantitativ alegerea lexicală non-nativă, evidențiind facilitarea cognitivă ca fiind unul dintre fenomenele importante care modelează limba vorbitorilor non-nativi.</abstract_ro>
      <abstract_sr>Predstavljamo računalnu analizu kognitivnih efekata na spontanske jezičke proizvode naprednih ne-rodnih govornika. Predstavljajući veliki korpus veoma kompetentnih nerijednih engleskih govornika, i koristeći skup pažljivo izabranih leksičkih predmeta, pokazujemo da leksički izbori neproditelja utječu na kognite na njihov rodni jezik. Ovaj efekat je tako moćan da možemo rekonstruisati filogenetičko jezičko drvo porodice Indo-evropske jezike samo iz frekvencije specifičnih leksičkih predmeta na engleskom jeziku autora sa različitim jezicima. Mi kvantitativno analiziramo neprodični leksički izbor, naglašavamo kognitivno olakšanje kao jedan od važnih fenomena koji formiraju jezik neprodičnih govornika.</abstract_sr>
      <abstract_si>අපි පරීක්ෂණය විශ්ලේෂණයක් පෙන්වන්නේ ප්‍රශ්ණ භාෂාවික විශ්ලේෂණයක් ඉදිරිපත් නොමැත්තික ස්පීකර ප්‍රශ්නයක් විශාලයෙන් ඉංග්‍රීසි ස්පීකර්ටර් නැති ප්‍රශ්නයක් ගැන ලොකු කොර්පුස් එකක් ප්‍රශ්නයක් කරනවා, ඒ වගේම ප්‍රශ්නයක් විශ් මේ පරීක්ෂණය ගොඩක් ශක්තිමත් වෙන්නේ අපිට පුළුවන් ඉන්දෝරෝපිය භාෂාව පවුලේ ෆිලෝජෙනෙටික් භාෂාව ආපහු නිර්මාණය කරන්න පු අපි ප්‍රමාණයක් විශ්ලේෂණය කරන්නේ නැති ලෙක්සික් විකල්පයක් නැති විකල්පයක් නැති විකල්පයක් නිර්මාණය කරන්න, ප්‍රමාණි</abstract_si>
      <abstract_so>Anagaa keennaa baaritaanka xisaabta ah oo saameyn ku saabsan waxyaabaha ku saabsan dhaqaalaha afka hooyo ee dadka aan hooyo ahayn. Markii aan baranayno qof badan oo ku hadla afkooda Ingiriiska oo aan aheyn dad aad u awood leh, islamarkaasna aan isticmaalno noocyo aad u taxadar ah oo la doortay alaabta lexicada, waxaynu muujinnaa in doorashooyinka aan nationada aheyn ay saameyn ku yeelan yihiin jinsiyada afkooda hooyo. Saamayntan waa xoog badan tahay in aynu mar kale dhisi karno geedka afka Finnishka ee qoyska Indo-Yurub oo kaliya laga soo celiyo alaabta khaaska ah oo ku qoran afka Ingiriiska oo qoraalka ku qoran luuqado kala duduwan. Waxaynu si qiyaas ah u baaraynaa doorasho aan aheyn kuwa aan hooyo u dhashay, waxaynu u bandhigaynaa xarunta hooyada sida mid ka mid ah arimaha muhiimka ah oo burburiya luqada dadka aan hooyo ahayn.</abstract_so>
      <abstract_sv>Vi presenterar en beräkningsanalys av kognitiva effekter på spontana språkliga produktioner av avancerade icke-infödda talare. Genom att introducera en stor samling mycket kompetenta icke-infödda engelska talare, och med hjälp av en uppsättning noggrant utvalda lexikala objekt, visar vi att lexikala val för icke-infödda påverkas av kognitioner på deras modersmål. Denna effekt är så kraftfull att vi kan rekonstruera det fylogenetiska språkträdet i den indoeuropeiska språkfamiljen enbart utifrån frekvensen av specifika lexikala objekt på engelska av författare med olika modersmål. Vi analyserar kvantitativt icke-infödda lexikala val och lyfter fram kognitiv facilitering som ett av de viktiga fenomen som formar språket för icke-infödda talare.</abstract_sv>
      <abstract_ta>நாம் முன்னேற்றப்பட்ட பேச்சாளர்கள் இல்லாத பேச்சாளர்களின் தானாகவே மொழிமை உற்பத்திற்கு ஒரு கணக்கிட்ட விளைவுகளை கொண்டு  ஒரு பெரிய தேவையான ஆங்கிலத்திலிருந்து இல்லாத பேச்சாளர்களை அறிவிக்கும் மற்றும் கவனமாக தேர்ந்தெடுக்கப்பட்ட சில தேர்வுகளை பயன்படுத்தி காட்டுகிறோம், நாம இந்த விளைவு மிகவும் சக்தியுடையது நாம் சிந்தோ-ஐரோப்பிய மொழி குடும்பத்தின் விசைப்பலமான மொழி மரத்தை மீண்டும் உருவாக்க முடியும் என்று முடி நாம் குறிப்பிட்டு தேர்வு இல்லாத நெதர்லாத விருப்பங்களை ஆய்வு செய்கிறோம், கோகான்ட் வசதியை முன்னிலைப்படுத்துகிறது, தேவையா</abstract_ta>
      <abstract_ur>ہم ایک کمپیوٹریسی تحقیقات کے ذریعہ پیش کئے گئے غیر ملی صحبت کرنے والوں کے سامنے زبان شناسی کے اثرات کے ذریعہ۔ ایک بڑی کورپوس کی پیدا کرتی ہے جو بہت زیادہ مستحکم غیر مستحکم انگلیسی صحبت کرنے والے ہیں، اور ایک مجموعہ مضطرب سے انتخاب کیا گیا لکسیکی اثرات کا استعمال کرتی ہے، ہم نشان دیتے ہیں کہ غیر مستحکموں کی لکسیکی انتخاب کو ان کی ماں زبان میں پہچا یہ اثر بہت طاقتور ہے کہ ہم انڈو-اروپای زبان خاندان کے فیلوگنیٹیک زبان درخت کو صرف مختلف ملک زبانوں کے لکھنے والوں کے انگلیسی میں مختلف لکھنے والوں کی فرکانس سے دوبارہ بنا سکتے ہیں. ہم غیر منطقی لکھنے والی انتخاب کے مطابق مطابق تحلیل کرتے ہیں، پہچان کرنے والی آسانی کو مطابق مطابق مطابق مطابق مطابق مطابق غیر منطقی لکھنے والی زبان کی شکل کرنے والی ہے.</abstract_ur>
      <abstract_uz>Biz bir kompyuterni o'rganamiz, o'zida o'xshagan o'xshash tillar tilining tashkilotlarini o'zgartiradik. Bu katta tashkilotli ingliz tili tilidagi gapiruvchilar bilan o'rganish va taqdim tanlangan leksikal narsalarni ishlatish mumkin, balki natijalar uchun leksikal tanlovchilari natijadagi tillardan foydalanadi. Bu effekti juda katta, biz Indo-European tili oilasining phylogenetik daraxtini qayta yuklash mumkin, faqat nativiy tillari bilan ingliz tillari tilidagi mahsus leksikal narsalarning frekvenlaridan foydalanishimiz mumkin. We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers.</abstract_uz>
      <abstract_vi>Chúng tôi trình bày một phân tích tính hiệu ứng răng nanh với các sản phẩm ngôn ngữ tự phát của những người không gốc tiên tiến. Giới thiệu một tập lớn những người nói tiếng Anh không thổ dân giỏi nhất, và sử dụng một bộ các thứ ngôn ngữ văn học được chọn cẩn thận, chúng tôi cho thấy các ngôn ngữ ngôn ngữ ngôn ngữ ngôn ngữ ngôn ngữ ngôn ngữ ngôn ngữ không thổ dân bị ảnh hưởng. This effect is so strong that we are able to Reconstruction the phylogeetic language tree of the Indo-European language family only from the tần số of particular lexical items in the English of authors with various native language. Chúng tôi phân tích từ ngôn ngữ không thổ dân về cách thức, nhấn mạnh sự giúp đỡ ngôn ngữ là một trong những hiện tượng quan trọng định dạng ngôn ngữ của người không thổ dân.</abstract_vi>
      <abstract_bg>Представяме изчислителен анализ на познатите ефекти върху спонтанните лингвистични продукции на напреднали чуждоезикови. Представяйки голям корпус от висококомпетентни чуждоезикови английски език и използвайки набор от внимателно подбрани лексикални елементи, ние показваме, че лексикалният избор на чуждоезици се влияе от конгатите на техния роден език. Този ефект е толкова мощен, че можем да реконструираме филогенетичното езиково дърво на индоевропейското езиково семейство единствено от честотите на специфични лексикални елементи в английския език на автори с различни родни езици. Анализираме количествено неродния лексикален избор, като подчертаваме когнатното улесняване като един от важните явления, оформящи езика на чуждоезиковите.</abstract_bg>
      <abstract_hr>Predstavljamo računalnu analizu kognitivnih učinka na spontanne jezičke proizvode naprednih neprodnih govornika. Uključujući veliki korpus veoma kompetentnih nerijednih engleskih govornika i koristeći skup pažljivo izabranih leksičkih predmeta, pokazujemo da leksički izbori neproditelja utječu na kognite na njihov rodni jezik. Ovaj učinak je tako moćan da možemo rekonstruirati filogenetičko jezičko drvo porodice Indo-europskog jezika samo iz frekvencije specifičnih leksičkih predmeta na engleskom jeziku autora s različitim jezicima. Mi kvantitativno analiziramo neprodični leksički izbor, naglašavamo pojačanje kogniranja kao jedan od važnih fenomena koji formiraju jezik neprodičnih govornika.</abstract_hr>
      <abstract_nl>We presenteren een computationele analyse van cognitieve effecten op de spontane linguïstische producties van gevorderde niet-native speakers. We introduceren een groot corpus van zeer competente niet-native Engels sprekers, en met behulp van een reeks zorgvuldig geselecteerde lexicale items, laten we zien dat de lexicale keuzes van niet-native mensen worden beïnvloed door cognaten in hun moedertaal. Dit effect is zo krachtig dat we de fylogenetische taalboom van de Indo-Europese taalfamilie alleen kunnen reconstrueren uit de frequenties van specifieke lexicale items in het Engels van auteurs met verschillende moedertalen. We analyseren kwantitatief niet-native lexicale keuze en benadrukken cognitieve facilitatie als een van de belangrijke fenomenen die de taal van niet-native speakers vormgeven.</abstract_nl>
      <abstract_da>Vi præsenterer en beregningsmæssig analyse af kognitive effekter på de spontane sproglige produktioner af avancerede ikke-indfødte talere. Ved at introducere et stort korpus af meget kompetente ikke-indfødte engelsktalende, og ved hjælp af et sæt nøje udvalgte leksikalske elementer, viser vi, at de leksikalske valg af ikke-indfødte påvirkes af kognitioner på deres modersmål. Denne effekt er så kraftig, at vi er i stand til at rekonstruere det fylogenetiske sprogtræ i den indoeuropæiske sprogfamilie udelukkende ud fra hyppigheden af specifikke leksikalske elementer på engelsk af forfattere med forskellige modersmål. Vi analyserer kvantitativt ikke-indfødte leksikalske valg og fremhæver kognitiv facilitering som et af de vigtige fænomener, der former sproget for ikke-indfødte talere.</abstract_da>
      <abstract_de>Wir präsentieren eine computergestützte Analyse von kognitiven Effekten auf die spontanen linguistischen Produktionen fortgeschrittener Nicht-Muttersprachler. Durch die Einführung eines großen Korpus hochkompetenter Nicht-Muttersprachler und die Verwendung einer Reihe sorgfältig ausgewählter lexikalischer Elemente zeigen wir, dass die lexikalischen Entscheidungen von Nicht-Muttersprachlern durch Kognitionen in ihrer Muttersprache beeinflusst werden. Dieser Effekt ist so stark, dass wir in der Lage sind, den phylogenetischen Sprachbaum der indoeuropäischen Sprachfamilie ausschließlich aus den Frequenzen spezifischer lexikalischer Elemente im Englisch von Autoren mit verschiedenen Muttersprachen zu rekonstruieren. Wir analysieren quantitativ die lexikalische Auswahl von Nicht-Muttersprachlern und heben kognitive Facilitation als eines der wichtigsten Phänomene hervor, die die Sprache von Nicht-Muttersprachlern prägen.</abstract_de>
      <abstract_id>Kami mempersembahkan analisis komputasi efek kognat pada produksi bahasa spontan dari pembicara non-asli maju. Memperkenalkan tubuh besar pembicara bahasa Inggris yang tidak asli yang sangat kompeten, dan menggunakan set benda leksik yang dipilih dengan hati-hati, kami menunjukkan bahwa pilihan leksik yang tidak asli dipengaruhi oleh kognat dalam bahasa asli mereka. Efek ini sangat kuat sehingga kita dapat membangun kembali pohon bahasa filogenetik dari keluarga bahasa Indo-Eropa hanya dari frekuensi dari item leksik spesifik dalam bahasa Inggris penulis dengan berbagai bahasa asli. Kami menganalisis secara kuantitatif pilihan leksik bukan asli, menandai fasilitasi kognat sebagai salah satu fenomena penting membentuk bahasa pembicara bukan asli.</abstract_id>
      <abstract_tr>Biz esasy çykyşlaryň ýetginjek ýokary çykyşlaryň spontane dil täsirlerini bilýän hasaplamagyny görkeýäris. Iňlisçe gürlemän adamlaryň uly köpüsini daşyrýan we adatça saýlanan iňlisçe gürlemäniň köpüsini daşyrýan we ene dilinde tanyşlaryň etkilendiklerini görkez. Bu täsiri Indo-Evropa dilleriniň filogenetik agajyny diňe birnäçe ene diller bilen iňlisleriň spesifik dillerinden beýleki dillerden döredip bileris. Biz ýerlik faýllaryň ýerlik ýok saýlamasyny ýagdaýda çykýarys, tanyş ýerlerini ýerlik ýok bolmadyklaryň dili döredilen möhüm döwürilerinden birini ýagtylaşdyrýarys.</abstract_tr>
      <abstract_ko>우리는 고급 비모국어인들이 자발적으로 언어에서 나오는 동원 효과에 대해 계산 분석을 진행했다.우리는 대량의 능력이 매우 강한 비영어 모국어인을 도입하고 정성스럽게 선택한 어휘 항목을 사용하여 비영어 모국어인의 어휘 선택이 그 모국어 동원어의 영향을 받았다는 것을 나타낸다.이런 영향은 이처럼 커서 우리는 각종 모국어를 사용하는 작가의 영어에서 특정한 어휘의 빈도만으로 인구어계의 체계적인 발육 언어 트리를 재건할 수 있다.우리는 비모국어자의 어휘 선택을 정량적으로 분석했고 동원 촉진을 강조하는 것은 비모국어자의 언어에 영향을 주는 중요한 현상 중의 하나이다.</abstract_ko>
      <abstract_fa>ما یک تحلیل کامپیوتری از اثرات شناخته‌ای روی تولید زبان‌شناخته‌ای از صحبت‌کننده‌های غیر طبیعی پیشرفته را نشان می‌دهیم. با توجه به یک مجموعه بزرگ از زبان انگلیسی غیر از طبیعی استفاده می‌کنیم، و با استفاده از مجموعهٔ مجموعهٔ برگزیده شده‌ای از زبان‌های زبان‌شناسی، نشان می‌دهیم که انتخاب‌های زبان‌شناسی غیر از طبیعی‌نشینان این تاثیر خیلی قوی است که ما می توانیم درخت زبان فیلوژنتیک خانواده زبان Indo-European را تنها از فرکانس کلمه‌های زبان ویژه‌ای در انگلیسی نویسندگان با زبان‌های متفاوتی بازسازی کنیم. ما به اندازه اندازه‌ای انتخاب زبان‌های غیر طبیعی را تحلیل می‌کنیم، آسایش شناختن را به عنوان یکی از پدیده‌های مهم که زبان‌های زبان‌های غیر طبیعی می‌سازند.</abstract_fa>
      <abstract_af>Ons stel 'n rekenaarsie analiseer van kogniteit effekte op die spontanee lingwisiese produksies van gevorderde non-native sprekkers. By die gebruik van 'n groot korpus van baie kompetente nie-natuurlike Engelske sprekkers en gebruik van 'n stel van versigtig gekose leksiese items, wys ons dat die leksieke keuses van nie-natuurlike onderwerp word deur konnekteers in hul natuurlike taal. Hierdie effek is so kragtig dat ons die phylogenetiske taal boom van die Indo-Europeese taal familie kan herkonstrukteer sole van die frekwensies van spesifieke leksiese items in die Engels van outeurs met verskillende taal. Ons het kvantitatiewe nie-natuurlike leksieke keuse analiseer, verlig kogniteit fasilitasie as een van die belangrike fenomene wat die taal van nie-natuurlike sprekkers skep.</abstract_af>
      <abstract_sw>Tunatoa uchambuzi wa kompyuta wa madhara ya ushirikiano juu ya uzalishaji wa lugha za watu wasio wazawa. Kutambua viungo vikubwa vya wazungumzaji wasio na asili wa Kiingereza, na kwa kutumia kundi la vitu vilivyochaguliwa kwa makini, tunaonyesha kuwa chaguo za kisaikolojia za asili zinaathirika na makampuni yanayotokana na lugha yao ya asili. Matokeo haya ni yenye nguvu sana kwamba tunaweza kujenga tena mti wa lugha ya kiutamaduni wa familia ya lugha ya Kihindi-Ulaya pekee kutoka kwa kiwango maalum cha vitu vya lexico katika Kiingereza kwa waandishi wenye lugha mbalimbali za wenyeji. Tunafanya uchaguzi wa asili wa lexico kwa kiasi kikubwa, tunaonyesha vifaa vya ushirikiano kama moja ya jambo muhimu linalovunja lugha ya wazungumzaji wasio wenyeji.</abstract_sw>
      <abstract_sq>Ne paraqesim një analizë kompjuterike të efekteve të njohura në prodhimet spontane gjuhësore të folësve të përparuar jo-vendas. Duke prezantuar një korpus të madh të anglezëve jo-natyrorë shumë kompetentë, dhe duke përdorur një sërë elementesh lexike të zgjedhur me kujdes, ne tregojmë se zgjedhjet lexike të jo-natyrorëve janë të prekura nga njohësit në gjuhën e tyre natyrore. This effect is so powerful that we are able to reconstruct the phylogenetic language tree of the Indo-European language family solely from the frequencies of specific lexical items in the English of authors with various native languages.  Ne analizojmë kuantitativisht zgjedhjen lexike jo-natyrore, duke theksuar lehtësimin e njohur si një nga fenomenet e rëndësishme që formojnë gjuhën e folësve jo-natyrorë.</abstract_sq>
      <abstract_am>የቋንቋ ቋንቋዎች አካባቢዎች ላይ በተለይ እናሳየዋለን፡፡ በአገራጆች ያልሆነው እንግሊዘኛ ቋንቋዎችን በመጠቀም እና በጥንቃቄ የተመረጡትን የሌክሲካዊ ምርጫዎች በአገራቸው ቋንቋ እንዲያካክሉ እናሳያቸዋለን፡፡ ይህ ፍቺው የኢንዶና-አውሮፓውያን የቋንቋ ቋንቋ ዛፍ በቋንቋ ቋንቋ መሠረት ኃይለኛ ነው፡፡ የአገሪቱ ያልሆነውን የሊክሲ ምርጫ በብዛት እናስተዋልታለን፣ የኮንኖት ማሰናከል እናደርጋለን፡፡</abstract_am>
      <abstract_az>Biz bilən təsirlərin spontanlı dil ürəklərinə bilən təsirlərin hesablama analizi göstəririk. İngilizə dilində çox qüvvətli danışanların böyük bir korpusu təşkil etmək və dikkatli seçilmiş leksik məsələlərini istifadə etmək göstəririk. Bu təsiri çox güclüdür ki, biz Indo-Avropa dilin ailəsinin filogenetik dil ağacı yenidən in şa edə bilərik, yalnız müxtəlif yerli dillərlə İngilis dilində yazanların məxluqatının məxluqatından istifadə edə bilərik. Biz yerli olmayan leksi seçimlərini kvantitatlı analiz edirik, tanıdıqlarını yerli danışanların dilini yaratdığı möhüm fenomenlərdən biri kimi işıqlandırırıq.</abstract_az>
      <abstract_hy>Մենք ներկայացնում ենք ճանաչողական էֆեկտների հաշվարկման վերլուծությունը զարգացած ոչ բնիկ խոսնակների ինքնաբուխ լեզվաբանական արտադրության վրա: Մենք ներկայացնում ենք մի մեծ մարմին բարձր կոմպտենցիոնալ անգլերեն ոչ բնիկ խոսացողների և օգտագործելով մի շարք ուշադիր ընտրված լեքսիկական առարկաներ, մենք ցույց ենք տալիս, որ ոչ բնիկ բնիկների լեքսիկական ընտրությունները ազդում են իրենց բնիկ լեզվով ճանաչո Այս էֆեկտը այնքան ուժեղ է, որ մենք կարողանում ենք վերակառուցել Հնդեվրոպական լեզվի ընտանիքի ֆիլոգենետիկ ծառը միայն տարբեր լեզվի հեղինակների անգլերենում հաճախականություններից: Մենք քանակությամբ վերլուծում ենք ոչ բնիկ լեքսիկական ընտրությունը, ներկայացնելով ճանաչողական միջոցը որպես ոչ բնիկ խոսացողների լեզուն ձևավորող կարևոր երևույթներից մեկը:</abstract_hy>
      <abstract_bn>আমরা স্বয়ংক্রিয়ভাষার ভাষার উৎপাদনের উপর কক্নেট প্রভাব সম্পর্কে গণনামূলক বিশ্লেষণ উপস্থাপন করছি। বিশাল কোর্পাস ব্যবহার করে অত্যন্ত ক্ষমতাশীল অইংরেজী ভাষাকে চিহ্নিত করে এবং সাবধানে বেছে নিয়েছে লেক্সিক্যাল জিনিস ব্যবহার করে, আমরা দেখাচ্ছি যে নাগরিকদের বে এই প্রভাব অত্যন্ত শক্তিশালী যে আমরা ভারত-ইউরোপীয় ভাষার পরিবারের ফ্যালিজেনেটিক ভাষা গাছ পুনরায় তৈরি করতে পারি শুধুমাত্র ভাষায় লেক্সিক্যাল জিনি আমরা স্থানীয় নেতৃত্ব বা লেক্সিক্যাল নির্বাচন বিশ্লেষণ করি, কোক্নেট সুবিধা হিসেবে উল্লেখ করি যেহেতু সেই গুরুত্বপূর্ণ ঘটনা যা স্</abstract_bn>
      <abstract_cs>Představujeme výpočetní analýzu kognitivních vlivů na spontánní jazykovou produkci pokročilých nerodilých mluvčích. Představujeme velký korpus vysoce kompetentních nerodilých mluvčích angličtiny a pomocí sady pečlivě vybraných lexikálních položek ukazujeme, že lexikální volby nerodilých mluvčích jsou ovlivněny konáty v jejich rodném jazyce. Tento efekt je natolik silný, že jsme schopni rekonstruovat fylogenetický jazykový strom indoevropské jazykové rodiny pouze z frekvencí specifických lexikálních položek v angličtině autorů s různými rodnými jazyky. Kvantitativně analyzujeme non-native lexikální volbu a zdůrazňujeme kognitivní facilitaci jako jeden z důležitých jevů formujících jazyk nerodilých mluvčích.</abstract_cs>
      <abstract_bs>Predstavljamo računalnu analizu kognitivnih efekata na spontanske jezičke proizvode naprednih neprodnih govornika. Uključujući veliki korpus veoma kompetentnih nerijednih engleskih govornika, i koristeći skup pažljivo izabranih leksičkih predmeta, pokazujemo da leksički izbori neproditelja utječu na kognite na njihov rodni jezik. Ovaj učinak je tako moćan da možemo rekonstruirati filogenetičko jezičko drvo porodice Indo-evropske jezike samo iz frekvencije specifičnih leksičkih predmeta na engleskom jeziku autora sa različitim jezicima. Mi kvantitativno analiziramo neprodični leksički izbor, naglašavamo kognitivno olakšanje kao jedan od važnih fenomena koji formiraju jezik neprodičnih govornika.</abstract_bs>
      <abstract_et>Esitleme arvutusliku analüüsi kogniatide mõjudest arenenud keelelistele produktsioonidele. Tutvustades suurt korpust kõrgelt pädevaid mitte-emakeelseid inglise keelt kõnelevaid ja kasutades hoolikalt valitud leksikaalseid elemente, näitame, et mitte-emakeelsete leksikaalseid valikuid mõjutavad nende emakeeles konnaadid. See efekt on nii võimas, et suudame Indo-Euroopa keelteperekonna fülogeneetilise keelepuu rekonstrueerida ainult erinevate emakeeltega autorite ingliskeelsete konkreetsete leksikaalsete elementide sagedustest. Analüüsime kvantitatiivselt mitte-emakeelset leksikaalset valikut, rõhutades kognitiivset hõlbustamist kui ühte olulist nähtust, mis kujundab mitte-emakeelsete kõnelejate keelt.</abstract_et>
      <abstract_fi>Esitämme laskennallisen analyysin kogniattisista vaikutuksista edistyneiden ei-syntyperäisten puhujien spontaaneihin kielellisiin tuotantoihin. Esittelemme laajan kokoelman erittäin päteviä ei-äidinkielenään puhuvia englanninkielisiä henkilöitä ja käyttämällä huolellisesti valittuja sanastokohteita, osoitamme, että ei-äidinkielen konnaatit vaikuttavat muiden kuin äidinkielen kielivalintoihin. Tämä vaikutus on niin voimakas, että pystymme rekonstruoimaan indoeurooppalaisen kieliperheen fylogeenisen kielipuun yksinomaan eri äidinkielejä käyttävien kirjailijoiden englanninkielisten tiettyjen sanamuotojen taajuuksista. Analysoimme kvantitatiivisesti vieraskielisen sanaston valintaa korostaen kognitiivisen fasilitoinnin yhtenä tärkeänä ilmiönä vieraskielisten kielten muokkaajana.</abstract_fi>
      <abstract_ca>Presentam una anàlisi computacional dels efectes cognats en les produccions lingüístices espontàniques dels parlants no natius avançats. Introducint un gran cos de parlants anglès no natius altament competents, i utilitzant un conjunt d'articles lèxics seleccionats amb cura, demostram que les eleccions lèxices dels no natius són afectades pels coneguts en la seva llengua materna. Aquest efecte és tan poderós que podem reconstruir l'arbre filogenètic de llenguatges de la família de llenguatges indoeuropeus només a partir de les freqüències d'objectes lèxics específics en anglès d'autors amb diverses llenguatges natives. Analitzem quantitativament l'elecció lèxica no nativa, destacant la facilitació del cognat com un dels fenomens importants que formen la llengua dels parlants no natius.</abstract_ca>
      <abstract_he>We present a computational analysis of cognate effects on the spontaneous linguistic productions of advanced non-native speakers.  להציג גוף גדול של מדברים אנגליים לא מקומיים, ומשתמשים בסדרה של פריטים לקסיים שנבחרו בזהירות, אנו מראים שהבחירות הלקסיות של לא מקומיים משפיעות על ידי קוגנייטים בשפה הלידית שלהם. השפעה הזאת כל כך חזקה שאנחנו מסוגלים לבנות מחדש את עץ השפה הפילוגנטית של משפחת השפה האינדו-אירופאית רק מהתדירות של פריטים לקסיים ספציפיים באנגלית של סופרים עם שפות מקומיות שונות. אנו מנתחים באופן כמוני בחירה לקסית לא מקומית, ומדגישים את ההקלה הקונאטית כאחד התופעות החשובות שיוצרו את שפת הדיבורים לא מקומיים.</abstract_he>
      <abstract_jv>Awak dhéwé éntuk karo alèhku komputer sing nggawe efek karo akeh juter alèhku nggawe barang pengguna kuwi mau. Gjenenganih akeh bantuan karo akeh sing nguasakno sing wis ana luwih basa Inggris, lan ijol-ijolan winih dhéwé kuwi nggawe kudu nggawe lineksi, awak dhéwé ngerasakno bakal terus akeh langgar sing gawe nguasakno. Efek iki dadi kêrlo ngono kéné iso nggawe ngubah barêng-barêng langa filetik kanggo ngubah barêng-barêng manut neng wong liyane wong liyane manut kanggo ingkang dipatenno karo akeh basa sing paling. Awak dhéwé éntuk akeh pisan langgar, iso nglanggar nggawe gerakan luwih cara-saka sing gak bênêr, ngregani kapan pawaran kuwi jenis akeh perusahaan kanggo nggawe langgar sing ora ono langgar kibo awak dhéwé.</abstract_jv>
      <abstract_sk>Predstavljamo računalniško analizo spoznanih učinkov na spontane jezikovne produkcije naprednih tujih govorcev. S predstavitvijo velikega korpusa visoko kompetentnih tujih angleških govorcev in skrbno izbranih leksikalnih elementov pokažemo, da na leksikalne izbire tujcev vplivajo kongniti v njihovem maternem jeziku. Ta učinek je tako močan, da lahko filogenetsko jezikovno drevo indoevropske jezikovne družine rekonstruiramo izključno iz frekvenc specifičnih leksikalnih elementov v angleščini avtorjev z različnimi maternimi jeziki. Kvantitativno analiziramo tuje leksikalne izbire in poudarjamo kognitno facilitacijo kot enega pomembnih pojavov, ki oblikujejo jezik tujih govorcev.</abstract_sk>
      <abstract_ha>Tuna halatar da rabo ƙidãyayyuta masu fassarar kokode a kan manunufi na'ura da bakin-harshen masu saurãre da ba'a taƙaita ba. Ina iya gane da jama'a mai girma na saurãre masu tawada'a na Ingiriya ba masu nati'a ba, kuma da amfani da matsayin abubuwa masu taƙaitacce, za mu nuna cewa zaɓallin zaɓen kashi na mutane sun yi musamman da kokafiya a cikin harshen uwarsu. Ga wannan aikin zai iya ƙarfi ko kuma za mu iya iya rekodi wata itãciya na lugha na Indo-Eura kawai daga ruwan abubuwa masu ƙayyade leksisi cikin Ingiriya na marubũta da lugha daban'a. Tuna yin anayya akan zaɓen lissafi wanda ba'a nati'a ba, kuma Muke sarrafa fassarar kwamfyuta kamar ɗayan abu na muhimu da za'a shafe harshen masu baka-mataifa.</abstract_ha>
      <abstract_bo>ང་ཚོས་རྩིས་འཁོར་གྱི་དབྱེ་ཞིབ་དཔྱད་ནི་གྲངས་སུ་རྒྱལ་ཁབ་མིན་པའི་སྐད་རིགས་གསར་གཏོང་ཐུབ་པའི་ནང་ལྟ་བུ་ སྐད་ཡིག་གི་མིང་ཚུལ་ཆེན་པོ་ཞིག་དང་སྤྱད་ནས་ཐད་ཀར་བདམས་ཟིན་པའི་སྐད་རིགས་ཤིག་སྟེ། དབྱངས་འགྲོས་འདིས་ངེད་ཚོའི་ནང་དུ་ཨིན་ཌོ་ཡུ་རིའི་སྐད་ཀྱི་ནང་ཁག་གི་སྐྱེས་ཚུལ་གྱི་རྣམ་པ་ཚོ་དང་གཅིག་མཐུན་སྒྲིག་འབད་བཏུབ་མིན་འདུག ང་ཚོས་རྣམས་མེད་སྐད་ཡིག་ཆ་གདམ་ཀ་མིན་པ་ལས་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཆ་རྐྱེན་ཅིག་ལ་དམིགས་གཏོང་།</abstract_bo>
      </paper>
    <paper id="27">
      <title>Polite Dialogue Generation Without Parallel Data</title>
      <author><first>Tong</first><last>Niu</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <doi>10.1162/tacl_a_00027</doi>
      <abstract>Stylistic dialogue response generation, with valuable applications in personality-based conversational agents, is a challenging task because the response needs to be fluent, contextually-relevant, as well as paralinguistically accurate. Moreover, <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallel datasets</a> for regular-to-stylistic pairs are usually unavailable. We present three weakly-supervised models that can generate diverse, polite (or rude) dialogue responses without parallel data. Our late fusion model (Fusion) merges the decoder of an encoder-attention-decoder dialogue model with a language model trained on stand-alone polite utterances. Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score. Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response. We also present two retrievalbased, polite dialogue model baselines. Human evaluation validates that while the Fusion and the retrieval-based models achieve <a href="https://en.wikipedia.org/wiki/Politeness">politeness</a> with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialogue quality.</abstract>
      <pages>373–389</pages>
      <url hash="0ed1c30e">Q18-1027</url>
      <bibkey>niu-bansal-2018-polite</bibkey>
    <title_ar>إنشاء حوار مهذب بدون بيانات موازية</title_ar>
      <title_pt>Geração de diálogo educado sem dados paralelos</title_pt>
      <title_es>Generación de diálogos educados sin datos paralelos</title_es>
      <title_fr>Génération de dialogues polis sans données parallèles</title_fr>
      <title_ja>並列データなしの丁寧なダイアログ生成</title_ja>
      <title_ru>Вежливое создание диалога без параллельных данных</title_ru>
      <title_zh>无并行数礼貌</title_zh>
      <title_hi>समानांतर डेटा के बिना विनम्र संवाद पीढ़ी</title_hi>
      <title_ga>Dea-Agallamh Giniúint Gan Sonraí Comhuaineach</title_ga>
      <title_el>Ευγενική δημιουργία διαλόγου χωρίς παράλληλα δεδομένα</title_el>
      <title_hu>Udvarias párbeszéd generálása párhuzamos adatok nélkül</title_hu>
      <title_ka>პარალვლური მონაცემები გარეშე დიალოგის შექმნა</title_ka>
      <title_kk>Параллелі деректері жоқ диалогты құру</title_kk>
      <title_it>Generazione di dialoghi gentili senza dati paralleli</title_it>
      <title_lt>Politinio dialogo generavimas be lygiagrečių duomenų</title_lt>
      <title_mk>Генерација на политички дијалог без паралелни податоци</title_mk>
      <title_ms>Polite Dialogue Generation Without Parallel Data</title_ms>
      <title_ml>പാരാളല്‍ ഡേറ്റ ഇല്ലാതെ പോളിറ്റ് ഡയലോഗ് സൃഷ്ടിക്കുക</title_ml>
      <title_mn>Гэвч параллель өгөгдлийн бэрхшээлтэй диалог үүсгэл</title_mn>
      <title_no>Generering av polite dialogvindauge utan parallelle data</title_no>
      <title_pl>Uprzejme generowanie dialogów bez równoległych danych</title_pl>
      <title_ro>Generarea dialogului politicos fără date paralele</title_ro>
      <title_sr>Generacija pristojnog dijaloga bez paralelnih podataka</title_sr>
      <title_si>සාමාන්‍ය දත්ත නැති සංවාදය නිර්මාණය සංවාදය</title_si>
      <title_so>Generation dialogue Without Parallel Data</title_so>
      <title_mt>Ġenerazzjoni ta’ Djalogu Politiku Mingħajr Dejta Paralela</title_mt>
      <title_sv>Generation av artig dialog utan parallella data</title_sv>
      <title_ta>இணைப்பு தரவு இல்லாமல் வரையறை உரையாடல் உருவாக்கம்</title_ta>
      <title_ur>بغیر پارالئل ڈاٹا بغیر سیدھا ڈالیلوگ پیدا کرنا</title_ur>
      <title_uz>Parallel maò¥lumot yoò£q muloqat yaratish</title_uz>
      <title_vi>Tái tạo thoại không có dữ liệu song</title_vi>
      <title_nl>Beleefde dialooggeneratie zonder parallelle gegevens</title_nl>
      <title_da>Generering af høflig dialog uden parallelle data</title_da>
      <title_bg>Създаване на учтив диалог без паралелни данни</title_bg>
      <title_hr>Generacija lijepog dijaloga bez paralelnih podataka</title_hr>
      <title_de>Höfliche Dialoggenerierung ohne parallele Daten</title_de>
      <title_ko>병렬 데이터 없는 예의 대화 생성</title_ko>
      <title_id>Generasi Dialog Polit Tanpa Data Paralel</title_id>
      <title_sw>Uzalishaji wa Dialogu ya Uchaguzi bila Takwimu</title_sw>
      <title_fa>تولید محاورۀ مناسب بدون داده‌های پارالی</title_fa>
      <title_af>Polite Dialoog Genereer sonder Parallele Data</title_af>
      <title_sq>Gjenerimi i dialogut polit pa të dhëna paralele</title_sq>
      <title_am>አዲስ ዶሴ ፍጠር</title_am>
      <title_hy>Խաղաղ պատուհանի ստեղծման առանց զուգահեռ տվյալների</title_hy>
      <title_tr>Parallel Maglumaty Olmadan Ýüklemek Dialogy</title_tr>
      <title_bn>প্যারালেল ডাটা ছাড়া পলিট ডায়ালগ উৎপাদন</title_bn>
      <title_bs>Generacija pristojnog dijaloga bez paralelnih podataka</title_bs>
      <title_ca>Generació de diàleg polític sense dades paralleles</title_ca>
      <title_cs>Generování zdvořilého dialogu bez paralelních dat</title_cs>
      <title_az>Parallel M…ôlumatlarƒ± olmadan S…ônin Dialoog M…ôxluqatƒ±</title_az>
      <title_fi>Kohtelias dialogin luominen ilman rinnakkaisia tietoja</title_fi>
      <title_et>Viisakas dialoogi loomine ilma paralleelsete andmeteta</title_et>
      <title_jv>Generation Dialog Generation Unlimited Parall data</title_jv>
      <title_ha>@ action</title_ha>
      <title_sk>Ustvarjanje vljudnega dialoga brez vzporednih podatkov</title_sk>
      <title_bo>བྱེད་རྒྱུན་ལྡུང་མེད་པའི་སྒེར་གྱི་ཌའི་ལོག་བློ་གཏོང་བ</title_bo>
      <title_he>Polite Dialogue Generation Without Parallel Data</title_he>
      <abstract_fr>La génération de réponses au dialogue stylistique, avec des applications utiles dans les agents conversationnels basés sur la personnalité, est une tâche difficile car la réponse doit être fluide, pertinente au contexte et précise du point de vue paralinguistique. De plus, les ensembles de données parallèles pour les paires régulières à stylistiques ne sont généralement pas disponibles. Nous présentons trois modèles faiblement supervisés qui peuvent générer des réponses de dialogue diverses, polies (ou grossières) sans données parallèles. Notre modèle de fusion tardive (Fusion) fusionne le décodeur d'un modèle de dialogue encodeur-attention-décodeur avec un modèle de langage formé sur des énoncés polis autonomes. Notre modèle de réglage fin d'étiquette (LFT) ajoute à chaque séquence source une étiquette graduée de score de politesse (prédite par notre classificateur de politesse de pointe) pendant la formation et, au moment du test, est capable de générer des réponses polies, neutres et grossières en mettant simplement à l'échelle l'intégration de l'étiquette par le score correspondant. Notre modèle d'apprentissage par renforcement (Polite-RL) encourage la génération de politesse en attribuant des récompenses proportionnelles au score du classificateur de politesse de la réponse échantillonnée. Nous présentons également deux modèles de base de dialogue poli basés sur la récupération. L'évaluation humaine confirme que si les modèles Fusion et basés sur la récupération permettent d'obtenir une politesse avec une moindre pertinence contextuelle, les modèles LFT et Polite-RL peuvent produire des réponses beaucoup plus polies sans sacrifier la qualité du dialogue.</abstract_fr>
      <abstract_ar>يعد إنشاء استجابة الحوار الأسلوبي ، مع تطبيقات قيّمة في وكلاء المحادثة المستندة إلى الشخصية ، مهمة صعبة لأن الاستجابة يجب أن تكون بطلاقة ، وذات صلة بالسياق ، وكذلك دقيقة من الناحية اللغوية. علاوة على ذلك ، عادةً ما تكون مجموعات البيانات المتوازية للأزواج العادية إلى الأسلوبية غير متوفرة. نقدم ثلاثة نماذج خاضعة للإشراف الضعيف يمكنها توليد استجابات حوار متنوعة ومهذبة (أو وقحة) بدون بيانات موازية. يدمج نموذج الاندماج المتأخر الخاص بنا (Fusion) وحدة فك التشفير لنموذج حوار وحدة فك ترميز الانتباه وفك الشفرة مع نموذج لغة تم تدريبه على أقوال مهذبة قائمة بذاتها. يُعد نموذج ضبط الملصق (LFT) الخاص بنا مُسبقًا لكل تسلسل مصدر ، ملصق مقياس درجة التأدب (تم توقعه بواسطة مُصنف الأدب الحديث الخاص بنا) أثناء التدريب ، وفي وقت الاختبار يكون قادرًا على توليد مهذبة ومحايدة ووقاحة الردود ببساطة عن طريق تحجيم تسمية التضمين بالنتيجة المقابلة. يشجع نموذج التعلم المعزز (Polite-RL) الخاص بنا على تكوين الأدب من خلال تخصيص مكافآت تتناسب مع درجة مصنف الأدب للاستجابة التي تم أخذ عينات منها. نقدم أيضًا خطين أساسيين لنموذج حوار مهذب قائم على الاسترجاع. يتحقق التقييم البشري من أنه بينما يحقق الاندماج والنماذج القائمة على الاسترجاع مهذبًا بملاءمة أقل للسياق ، يمكن أن ينتج نموذجا LFT و Polite-RL استجابات أكثر مهذبة بشكل ملحوظ دون التضحية بجودة الحوار.</abstract_ar>
      <abstract_es>La generación de respuestas de diálogo estilístico, con aplicaciones valiosas en agentes conversacionales basados en la personalidad, es una tarea desafiante porque la respuesta debe ser fluida, relevante para el contexto y paralingüísticamente precisa. Además, los conjuntos de datos paralelos para pares regulares a estilísticos no suelen estar disponibles. Presentamos tres modelos débilmente supervisados que pueden generar respuestas de diálogo diversas, educadas (o groseras) sin datos paralelos. Nuestro modelo de fusión tardía (Fusion) fusiona el decodificador de un modelo de diálogo codificador-atención-decodificador con un modelo de lenguaje entrenado en expresiones educadas independientes. Nuestro modelo de ajuste fino de etiquetas (LFT) antepone a cada secuencia fuente una etiqueta con escala de puntuación de cortesía (predicha por nuestro clasificador de cortesía de última generación) durante el entrenamiento, y en el momento del examen es capaz de generar respuestas educadas, neutrales y groseras simplemente escalando la incrustación de la etiqueta por la puntuación correspondiente. Nuestro modelo de aprendizaje por refuerzo (Polite-RL) fomenta la generación de cortesía al asignar recompensas proporcionales a la puntuación del clasificador de cortesía de la respuesta de muestra. También presentamos dos líneas de base del modelo de diálogo educado y basado en la recuperación. La evaluación humana valida que, si bien los modelos de Fusión y basados en la recuperación logran la cortesía con una menor relevancia del contexto, los modelos LFT y Polite-RL pueden producir respuestas significativamente más educadas sin sacrificar la calidad del diálogo.</abstract_es>
      <abstract_pt>A geração estilística de respostas de diálogo, com aplicações valiosas em agentes conversacionais baseados em personalidade, é uma tarefa desafiadora porque a resposta precisa ser fluente, contextualmente relevante e paralinguísticamente precisa. Além disso, conjuntos de dados paralelos para pares regulares para estilísticos geralmente não estão disponíveis. Apresentamos três modelos fracamente supervisionados que podem gerar respostas de diálogo diversas, educadas (ou rudes) sem dados paralelos. Nosso modelo de fusão tardia (Fusion) mescla o decodificador de um modelo de diálogo codificador-atenção-decodificador com um modelo de linguagem treinado em enunciados educados autônomos. Nosso modelo de ajuste fino de rótulo (LFT) anexa a cada sequência de origem um rótulo escalonado de pontuação de polidez (previsto por nosso classificador de polidez de última geração) durante o treinamento e, no momento do teste, é capaz de gerar respostas simplesmente dimensionando a incorporação do rótulo pela pontuação correspondente. Nosso modelo de aprendizado por reforço (Polite-RL) incentiva a geração de polidez atribuindo recompensas proporcionais à pontuação do classificador de polidez da resposta amostrada. Também apresentamos duas linhas de base do modelo de diálogo educado e baseado em recuperação. A avaliação humana valida que, enquanto os modelos Fusion e baseados em recuperação alcançam polidez com menor relevância ao contexto, os modelos LFT e Polite-RL podem produzir respostas significativamente mais educadas sem sacrificar a qualidade do diálogo.</abstract_pt>
      <abstract_zh>风格应生,于人格摄中有价用,一项有挑战性之任,盖应须流畅,上下文关副语言确也。 此外,常到样式对的并行数据集常不可用。 吾陈三弱以督之,可以生多样化于无数,礼(粗)以应之。 我后期合模(Fusion)将编码器-注意-解码器对话的解码器与在独立礼貌的话上训练的言语模形并合。 凡我标 (LFT) 每源序预置一礼貌评分缩放标(最先进礼貌分类器占),并试以分数缩放嵌之以成礼貌、中立、粗鲁之应。 吾之化学模样(Polite-RL)以分抽样应之器分数为比例之赏以劝礼貌。 供二基于检索、礼貌之基线。 人工质实,虽Fusion与检上下文相关性差相参,LFT与Polite-RL形可以不杀对质而生明应。</abstract_zh>
      <abstract_hi>व्यक्तित्व-आधारित संवादात्मक एजेंटों में मूल्यवान अनुप्रयोगों के साथ शैलीगत संवाद प्रतिक्रिया पीढ़ी, एक चुनौतीपूर्ण कार्य है क्योंकि प्रतिक्रिया को धाराप्रवाह, प्रासंगिक रूप से प्रासंगिक, साथ ही साथ पराभाषिक रूप से सटीक होने की आवश्यकता है। इसके अलावा, नियमित रूप से शैलीगत जोड़े के लिए समानांतर डेटासेट आमतौर पर अनुपलब्ध होते हैं। हम तीन कमजोर-पर्यवेक्षित मॉडल प्रस्तुत करते हैं जो समानांतर डेटा के बिना विविध, विनम्र (या असभ्य) संवाद प्रतिक्रियाएं उत्पन्न कर सकते हैं। हमारा देर से संलयन मॉडल (फ्यूजन) स्टैंड-अलोन विनम्र उच्चारण पर प्रशिक्षित भाषा मॉडल के साथ एक एनकोडर-अटेंशन-डिकोडर संवाद मॉडल के डिकोडर को मर्ज करता है। हमारे लेबल-फाइनट्यूनिंग (एलएफटी) मॉडल प्रशिक्षण के दौरान प्रत्येक स्रोत अनुक्रम को एक विनम्रता-स्कोर स्केल किए गए लेबल (हमारे अत्याधुनिक शिष्टता क्लासिफायरद्वारा भविष्यवाणी की गई) को पूर्वनिर्धारित करता है, और परीक्षण के समय में विनम्र, तटस्थ और असभ्य प्रतिक्रियाओं को उत्पन्न करने में सक्षम है बस संबंधित स्कोर द्वारा एम्बेडिंग लेबल को स्केल करके। हमारे सुदृढीकरण सीखने के मॉडल (Polite-RL) नमूना प्रतिक्रिया की विनम्रता क्लासिफायर स्कोर के आनुपातिक पुरस्कार असाइन करके विनम्रता पीढ़ी को प्रोत्साहित करता है। हम दो पुनर्प्राप्ति आधारित, विनम्र संवाद मॉडल बेसलाइन भी प्रस्तुत करते हैं। मानव मूल्यांकन सत्यापित करता है कि जबकि फ्यूजन और पुनर्प्राप्ति-आधारित मॉडल गरीब संदर्भ-प्रासंगिकता के साथ विनम्रता प्राप्त करते हैं, एलएफटी और विनम्र-आरएल मॉडल संवाद गुणवत्ता का त्याग किए बिना काफी अधिक विनम्र प्रतिक्रियाओं का उत्पादन कर सकते हैं।</abstract_hi>
      <abstract_ru>Генерация отклика на стилистический диалог с ценными приложениями в личностных разговорных агентах является сложной задачей, потому что отклик должен быть бегло выраженным, контекстуально релевантным, а также паралингвистически точным. Кроме того, параллельные наборы данных для регулярных стилистических пар обычно недоступны. Мы представляем три слабо контролируемые модели, которые могут генерировать разнообразные, вежливые (или грубые) диалоговые ответы без параллельных данных. Наша модель позднего слияния (Fusion) объединяет декодер диалоговой модели кодер-внимание-декодер с языковой моделью, обученной автономным вежливым высказываниям. Наша модель label-finetuning (LFT) добавляет к каждой исходной последовательности метку с оценкой вежливости (предсказанную нашим современным классификатором вежливости) во время обучения, и во время тестирования способна генерировать вежливые, нейтральные и грубые ответы, просто масштабируя встраивание метки соответствующей оценкой. Наша модель обучения подкреплению (Polite-RL) поощряет создание вежливости, назначая награды, пропорциональные баллу классификатора вежливости выбранного ответа. Мы также представляем две базовые модели основанного на поиске вежливого диалога. Оценка человека подтверждает, что в то время как модели, основанные на слиянии и извлечении, достигают вежливости с более низкой контекстно-релевантностью, модели FFT и Polite-RL могут давать значительно более вежливые ответы, не жертвуя качеством диалога.</abstract_ru>
      <abstract_ja>パーソナリティベースの会話エージェントにおける貴重なアプリケーションを備えたスタイル的な対話応答生成は、応答が流暢で、文脈に関連性があり、パラリンガル的に正確である必要があるため、困難な課題です。 さらに、通常、通常のスタイルペアの並列データセットは利用できません。 私たちは、並列データなしで多様で丁寧な（または失礼な）対話応答を生成できる3つの弱い監督モデルを提示します。 当社の後期融合モデル（ Fusion ）は、エンコーダ-アテンション-デコーダ対話モデルのデコーダを、スタンドアロンの丁寧な発話で訓練された言語モデルと融合させます。 当社のラベル同調（ ＬＦＴ ）モデルは、トレーニング中に各ソースシーケンスに（当社の最先端の丁寧さ分類器によって予測される）丁寧さスコアスケールされたラベルを事前に割り当て、テスト時間に、対応するスコアによってラベル埋め込みをスケーリングするだけで、丁寧、中立、および失礼な応答を生成することができる。 当社の強化学習モデル（ Polite - RL ）は、サンプリングされた応答の丁寧さ分類子スコアに比例した報酬を割り当てることにより、丁寧さの生成を促進します。 また、2つの検索ベースの丁寧な対話モデルのベースラインを提示します。 人間の評価は、Fusionモデルと検索ベースのモデルが文脈関連性の低い丁寧さを達成する一方で、LFTモデルとPolite - RLモデルは、対話の質を犠牲にすることなく、大幅に丁寧な応答を生み出すことができることを検証します。</abstract_ja>
      <abstract_ga>Is tasc dúshlánach é freagairt stíliúil idirphlé a ghiniúint, le feidhmchláir luachmhara i ngníomhairí comhrá bunaithe ar phearsantacht, mar ní mór don fhreagra a bheith líofa, comhthéacs-ábhartha, chomh maith le bheith cruinn ó thaobh na parateanga de. Ina theannta sin, is gnách nach mbíonn tacair shonraí comhthreomhara do phéirí rialta go stíle ar fáil. Cuirimid i láthair trí mhúnla faoi mhaoirseacht lag ar féidir leo freagairtí comhphlé ilghnéitheacha, dea-bhéasacha (nó drochbhéasacha) a ghiniúint gan sonraí comhthreomhara. Cumascann ár samhail chomhleá déanach (Fusion) díchódóir samhail idirphlé ionchódóra-aire-decoder le múnla teanga atá oilte ar chainteanna múinte neamhspleácha. Réamh-mheastar ár múnla mionchoigeartaithe lipéad (LFT) do gach seicheamh foinse lipéad scálaithe dea-scála (arna thuar ag ár n-aicmitheoir dea-cháilíochta den scoth) le linn na hoiliúna, agus ag am tástála tá sé in ann dea-bhéasach, neodrach agus drochbhéasach a ghiniúint. freagraí tríd an lipéad a leabú ag an scór comhfhreagrach. Spreagann ár múnla foghlama treisithe (Polite-RL) béasacht a ghiniúint trí luaíochtaí a shannadh i gcomhréir le scór aicmitheora dea-bhéasa na freagartha sampláilte. Cuirimid i láthair freisin dhá bhonnlíne mhúnla dea-agallaimh atá bunaithe ar aisghabháil. Deimhníonn meastóireacht dhaonna, cé go mbaineann an Comhleá agus na samhlacha atá bunaithe ar aisghabháil béasach le hábharthacht comhthéacs níos measa, gur féidir leis na samhlacha LFT agus Polite-RL freagraí i bhfad níos dea-bhéanta a tháirgeadh gan cáilíocht an chomhphlé a íobairt.</abstract_ga>
      <abstract_el>Η δημιουργία στυλιστικής ανταπόκρισης διαλόγου, με πολύτιμες εφαρμογές σε παράγοντες συνομιλίας βασισμένους στην προσωπικότητα, είναι ένα δύσκολο έργο επειδή η ανταπόκριση πρέπει να είναι άπταιστη, συναφής με το περιβάλλον, καθώς και παραγλωσσολογικά ακριβής. Επιπλέον, τα παράλληλα σύνολα δεδομένων για κανονικά-στυλιστικά ζεύγη είναι συνήθως μη διαθέσιμα. Παρουσιάζουμε τρία αδύναμα εποπτευόμενα μοντέλα που μπορούν να δημιουργήσουν ποικίλες, ευγενικές (ή αγενείς) απαντήσεις διαλόγου χωρίς παράλληλα δεδομένα. Το μοντέλο μεταγενέστερης σύντηξης (Fusion) συνδυάζει τον αποκωδικοποιητή ενός μοντέλου διαλόγου κωδικοποιητή-προσοχής-αποκωδικοποιητή με ένα μοντέλο γλώσσας εκπαιδευμένο σε αυτόνομες ευγενικές εκφράσεις. Το μοντέλο μας προηγείται σε κάθε ακολουθία πηγής μιας ετικέτας με κλίμακα βαθμού ευγένειας (που προβλέπεται από τον υπερσύγχρονο ταξινομητή ευγένειας) κατά τη διάρκεια της εκπαίδευσης και κατά τη διάρκεια της δοκιμής είναι σε θέση να δημιουργήσει ευγενικές, ουδέτερες και αγενείς απαντήσεις απλά κλιμακώνοντας την ενσωμάτωση της ετικέτας με την αντίστοιχη βαθμολογία. Το μοντέλο εκμάθησης ενίσχυσης ενθαρρύνει τη δημιουργία ευγένειας με την εκχώρηση ανταμοιβών ανάλογων με την βαθμολογία του ταξινομητή ευγένειας της δειγματοληψίας απάντησης. Παρουσιάζουμε επίσης δύο βασικές γραμμές του ευγενικού διαλόγου. Η ανθρώπινη αξιολόγηση επιβεβαιώνει ότι ενώ τα μοντέλα σύντηξης και ανάκτησης επιτυγχάνουν ευγένεια με μικρότερη συνάφεια με το περιβάλλον, τα μοντέλα LFT και Polite-RL μπορούν να παράγουν σημαντικά πιο ευγενικές απαντήσεις χωρίς να θυσιάζουν την ποιότητα του διαλόγου.</abstract_el>
      <abstract_hu>A stílusos párbeszéd-válasz generálása, értékes alkalmazásokkal a személyiség-alapú beszélgetési ügynökökben, kihívást jelent, mert a válasznak folyékonynak, kontextusszempontból relevánsnak és paralingvisztikailag pontosnak kell lennie. Ezenkívül általában nem állnak rendelkezésre párhuzamos adatkészletek a hagyományos és stilisztikai párokhoz. Három gyengén felügyelt modellt mutatunk be, amelyek párhuzamos adatok nélkül sokszínű, udvarias (vagy durva) párbeszédválaszokat generálhatnak. Késői fúziós modellünk (Fusion) egyesíti egy kódoló-figyelem-dekóder párbeszédmodell dekódolóját egy önálló udvarias kifejezésekre képzett nyelvi modellel. A címke-finomhangoló (LFT) modellünk minden forrásszekvenciára egy udvariasság-pontszám skálázott címkét (a legkorszerűbb udvariasság osztályozónk által előrejelzett) előír az edzés során, és tesztidőben képes udvarias, semleges és durva válaszokat generálni azáltal, hogy egyszerűen skálázza a címke beágyazását a megfelelő pontszámmal. Erősítő tanulási modellünk (Polite-RL) ösztönzi az udvariasság generálását azáltal, hogy a mintázott válasz udvariasság osztályozó pontszámával arányos jutalmakat oszt ki. Két visszakeresési alapú, udvarias párbeszédmodell alapját is bemutatjuk. Az emberi értékelés igazolja, hogy miközben a Fusion és a visszakeresés alapú modellek rosszabb kontextusjelentőségű udvariasságot érnek el, az LFT és a Polite-RL modellek jelentősen udvariasabb válaszokat tudnak adni anélkül, hogy feláldoznák a párbeszéd minőségét.</abstract_hu>
      <abstract_ka>სტილისტიკური დიალოგის რეაქტების შესახებ, რომელიც პირადნობიურად დაკავშირებული კონტაქციო ადვნენტებში მნიშვნელოვანი პროგრამეტური პროგრამეტური პროგრამეტური პროგრამეტური პროგრამეტური ადვნ დამატებით, რედალური სტილისტიკური ზოგებისთვის პარალელური მონაცემები უფრო არ შეიძლება. ჩვენ სამი ცოტა მოდელის შესახებ, რომელიც შეგვიძლია განსხვავებული, სწორედ (ან უცოტა) დიალოგის პარალელური მონაცემების გარეგების შექმნა. ჩვენი ბოლო ფუზონის მოდელი (Fusion) კოდირების დიალოგის მოდელის დეკოდირების გამოყენება ენის მოდელით, რომელიც მუშაობით მუშაობით მუშაობით. ჩვენი მარტილის კონფინტუნირება (LFT) მოდელი ყოველ წიგნის კონფინტურაციას წარმოიდგინდება მარტივი სონტურაციის კონფინტურაციას (ჩვენი წიგნის კონფინტურაციის კლასიფინტურაციას) სტრინტურაციის შემდეგ და ტესტის დროში შეუძლია წარმოდ ჩვენი სწავლობის მოდელი (Polite-RL) უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად უფრო მეტად მოწყობ ჩვენ ასევე ჩვენ მხოლოდ ორი მიღებული, სწორედ დიალოგის მოდელის ბაზის ხაზები. ადამიანის განსაზღვრება გავაკეთებს, რომ, როცა ფუზიანი და მიღებული მოდელები უფრო ცოტა კონტექსტური მნიშვნელობით მიიღებენ, LFT და Polite-RL მოდელები შეუძლიათ მნიშვნელოვანად უფრო სწორესი განსახულებ</abstract_ka>
      <abstract_it>La generazione di risposte stilistiche al dialogo, con applicazioni preziose in agenti conversazionali basati sulla personalità, è un compito impegnativo perché la risposta deve essere fluente, contestualmente rilevante e paralinguisticamente accurata. Inoltre, i set di dati paralleli per coppie regolari-stilistiche non sono solitamente disponibili. Presentiamo tre modelli poco supervisionati che possono generare risposte di dialogo diverse, educate (o maleducate) senza dati paralleli. Il nostro modello di fusione tardiva (Fusion) fonde il decoder di un modello di dialogo encoder-attenzione-decoder con un modello di linguaggio addestrato sulle espressioni educate stand-alone. Il nostro modello di label-finetuning (LFT) è in grado di generare risposte educate, neutre e maleducate semplicemente ridimensionando l'etichetta in base al punteggio corrispondente. Il nostro modello di apprendimento di rinforzo (Polite-RL) incoraggia la generazione di educazione assegnando ricompense proporzionali al punteggio del classificatore di educazione della risposta campionata. Presentiamo anche due linee di base del modello di dialogo educato e retrievalase. La valutazione umana conferma che mentre i modelli Fusion e quelli basati sul recupero raggiungono l'educazione con una minore rilevanza del contesto, i modelli LFT e Polite-RL possono produrre risposte significativamente più educate senza sacrificare la qualità del dialogo.</abstract_it>
      <abstract_lt>Stilistinio dialogo reakcijų generavimas su vertingomis pritaikymais asmeniškumu grindžiamuose pokalbių agentuose yra sudėtinga užduotis, nes atsakas turi būti lankstus, kontekstu aktualus ir lygiagrečiai tikslus. Be to, paprastai nėra lygiagrečių duomenų rinkinių, skirtų įprastoms ar stilistinėms poroms. Mes pristatome tris silpnai prižiūrimus modelius, kurie gali sukurti įvairius, sąžiningus (arba nerūpestingus) dialogo atsakymus be lygiagrečių duomenų. Mūsų vėlesnio branduolių sintezės modelis (Fusion) jungia koduotojo-dėmesio-dekoderio dialogo modelio dekoderį su kalbos modeliu, mokomu savarankiškai mandagiais žodžiais. Mūsų etiketės tobulinimo (LFT) model is rengia kiekvienai šaltinio sekai poliškumo-balų skalės etiketę (prognozuojamą mūsų pažangiausio poliškumo klasifikatoriaus) mokymo metu, ir bandymo metu gali sukurti poliškus, neutralius ir nepagrįstus atsakus paprasčiausiai skaluojant etiketę, įdėtą atitinkamu balu. Mūsų stiprinimo mokymosi modelis (Polite-RL) skatina kurtumą, suteikiant atlyginimus proporcingus atrinkto atsako į kurtumą klasifikavimo rezultatams. Mes taip pat pristatome dvi pagrįstas, mandagus dialogo modelio bazes. Žmogaus vertinimas patvirtina, kad nors branduolių sintezės ir atgavimo modeliai pasiekia mandagesnį požiūrį į blogesnį kontekstą, LFT ir Polite-RL modeliai gali duoti daug mandagesnius atsakymus nepažeidžiant dialogo kokybės.</abstract_lt>
      <abstract_ms>Jenerasi balas dialog stilistik, dengan aplikasi berharga dalam ejen perbualan berdasarkan personaliti, adalah tugas yang mencabar kerana balasan perlu lengkap, relevan-konteks, serta tepat secara paralinguistik. Lagipun, set data selari untuk pasangan biasa-ke-stilistik biasanya tidak tersedia. Kami mempersembahkan tiga model yang mengawasi lemah yang boleh menghasilkan balasan dialog yang berbeza, sopan (atau kasar) tanpa data selari. Model fusi lewat kami (Fusion) gabungkan penyahkod model dialog pengekod-perhatian-penyahkod dengan model bahasa dilatih dalam ungkapan sopan sendirian. Model label-finetuning (LFT) kami mempersiapkan untuk setiap urutan sumber label skala kebudahan-skor (dijangka oleh klasifikasi kebudahan state-of-the-art) semasa latihan, dan pada masa ujian mampu menghasilkan balasan sopan, neutral, dan kasar dengan hanya skala label yang memasukkan dengan skor yang sepadan. Model pembelajaran kuasa kami (Polite-RL) mendorong generasi kebaikan dengan memberikan hadiah yang proporsional dengan skor pengklasifikasi kebaikan balasan yang ditempatkan. Kami juga memperkenalkan dua garis dasar model dialog yang berdasarkan asas, sopan. Evaluasi manusia sahkan bahawa walaupun Fusion dan model berdasarkan pemulihan mencapai kebaikan dengan relevan konteks yang lebih buruk, model LFT dan Polite-RL boleh menghasilkan respon yang jauh lebih sopan tanpa mengorbankan kualiti dialog.</abstract_ms>
      <abstract_kk>Стилистикалық диалог жауап беру үшін, әрқашандағы конвертациялық агенттердің бағаламалы қолданбалары жасау үшін, жауап жауап тұру қажетті, қазіргі уақытта қатынасыз және параллингвистикалық дұрыс болу керек. Қосымша, кәдімгі стильстикалық екептердің параллелі деректер жиындары қол жеткізбейді. Біз үш бақылау үлгілерін келтіреміз, бұл түрлі, тұрақты (немесе бұлды) диалог жауаптарын параллель деректері жоқ жауап бере алады. Біздің соңғы жинақтау үлгіміз (Fusion) кодтамасын декодтамасын декодтамасын диалог үлгісін біріктіреді. Тіл үлгісімен бірге жалғыз мұндай сөздерді біріктіреді. Біздің белгілеріміздің (LFT) үлгісіміз әрбір көзінің түрінде масштабын масштабтау жарлығына (өзіміздің күй- жайындағы кеңістік классификациясы бойынша көрсетілген) сәйкестік кезінде ұқсас, нейтралды және қарапайым жауаптарды құру мүмкіндігінде Біздің жақсы оқыту үлгісіміз (Polite-RL) бақылау үлгісіміз үлгілікті жауап беру үшін бақылау үлгісін құру үшін ұнайымдылық құрылады. Сонымен қатар екі қалпына келтіріп тұрмыз. Адам оқиғасы Фузион және қалпына негізделген үлгілер бақылау үлгілері керек контексті маңызды болғанда, LFT және Polite-RL үлгілері диалогтың сапасы жеткізілмеген артық жауап бере алады.</abstract_kk>
      <abstract_mk>Генерацијата на реакции на стилистичкиот дијалог, со вредни апликации во персоналните разговарачки агенти, е предизвикувачка задача бидејќи одговорот мора да биде тесен, контекстно релевантен, како и паралингуски точен. Покрај тоа, паралелните датотеки за редовни до стилистички парови обично не се достапни. Презентираме три слабо надгледувани модели кои можат да генерираат различни, учтиви (или груби) дијалози без паралелни податоци. Нашиот модел на доцна фузија (Фузија) го спојува декодерот на дијалогот за декодер-внимание-декодер со јазички модел трениран на самостојни учтиви изрази. Нашиот модел за финетизирање на етикетата (LFT) подготвува за секоја изворна секвенца етикета со скалирана точка на љубезност (предвидена од нашиот најсовремен класификатор на љубезност) за време на тренингот, и во времето на тестот е во можност да генерира љубезни, неутрални и груби одговори со едноставно скалирање на етикетата вклучена со соодветната точка Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response.  Исто така, претставуваме две бази на моделот на обработување на базите на политичниот дијалог. Човечката оценка потврдува дека додека Фузијата и моделите засновани на враќање постигнуваат учтивост со полоша контекстна релеванција, моделите ЛФТ и Полит-РЛ можат да произведат значително поучтиви одговори без да го жртвуваат квалитетот на дијалогот.</abstract_mk>
      <abstract_ml>സ്റ്റൈലിസ്റ്റിക്ക് ഡയലോഗ് പ്രതികരണം തലമുറയാണ്, വ്യക്തിപരമായ സംസാരിക്കുന്ന സംസാരിക്കുന്ന പ്രയോഗങ്ങളുടെ വിലപ്പെട്ട പ്രയോഗങ്ങളുടെ കൂട അതുകൊണ്ട്, സാധാരണയില്‍ നിന്നും സ്റ്റൈലിസ്റ്റിക് ജോടികള്‍ക്കുള്ള പാരാളില്‍ ഡാറ്റാസറ്റുകള്‍ സാധാ നമ്മള്‍ മൂന്നു ദുര്‍ബലനിരീക്ഷിക്കപ്പെട്ട മോഡലുകള്‍ കാണിക്കുന്നു. അത് വ്യത്യസ്ത വിഭാഗങ്ങള്‍ ഉണ്ടാക്കുവാന്‍ സാധിക നമ്മുടെ അവസാന ഫ്യൂഷന്‍ മോഡല്‍ (ഫ്യൂഷന്‍) ഒരു എക്ഡോര്‍ ശ്രദ്ധ-ഡെക്കോഡേര്‍ ഡയലോഗ് മോഡലിന്റെ ഡെകോഡിറ്റര്‍ ചേര്‍ക്കുന്നു. ഒരു ഭാഷ മോഡ Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score.  നമ്മുടെ പഠിക്കാനുള്ള മോഡല്‍ (പോലീസ്-RL) പ്രധാനപ്പെടുത്തുന്നത് പോലീസ് തലമുറകള്‍ക്ക് പ്രേരിപ്പിക്കുന്നു. മാതൃകയായ പ്രത നമ്മള്‍ രണ്ടു പിന്തിരിക്കുന്നതിന്‍റെ അടിസ്ഥാനത്തുള്ള സംസാര മോഡല്‍ ബെസ്റ്റ് ലൈനുകളും കാണിക് മനുഷ്യരുടെ വിലാസങ്ങള്‍ തെളിയിക്കുന്നുണ്ടെങ്കില്‍ ഫ്യൂഷനും വീണ്ടെടുക്കുന്നതിന്റെ അടിസ്ഥാനമായ മോഡലുകളും ദരിദ്രരീതിയുള്ള സംവിധാനത്തോടൊപ്പം സൌമ്യ</abstract_ml>
      <abstract_mt>Il-ġenerazzjoni ta’ rispons għad-djalogu stilistiku, b’applikazzjonijiet ta’ valur f’a ġenti ta’ konverżjoni bbażati fuq il-personalità, hija kompitu ta’ sfida minħabba li r-rispons jeħtieġ li jkun fluwidu, rilevanti mil-lat kuntestwali, kif ukoll preċiż b’mod paralinġistiku. Barra minn hekk, settijiet ta’ dejta paralleli għal par regolari sa stilistiċi normalment mhumiex disponibbli. Aħna nippreżentaw tliet mudelli b’superviżjoni dgħajfa li jistgħu jiġġeneraw reazzjonijiet ta’ djalogu diversifikati, politi (jew inġusti) mingħajr dejta parallela. Il-mudell ta’ fużjoni tardiva tagħna (Fużjoni) jgħaqqad id-dekoder ta’ mudell ta’ djalogu ta’ dikoder-attenzjoni-dekoder mal-mudell lingwistiku mħarreġ fuq espressjonijiet awtonomi u politi. Il-mudell tagħna tal-irfinar tat-tikketta (LFT) jipprepara għal kull sekwenza tas-sors tikketta skalata tal-punteġġ tal-politeness (imbassra mill-klassifikatur tal-politeness l-aktar avvanzat tagħna) waqt it-taħriġ, u fil-ħin tat-test huwa kapaċi jiġġenera risponsi politi, newtrali, u rudi billi sempliċement timskala t-tikketta inkorporata bil-punteġġ korrispondenti. Il-mudell tagħna ta’ tagħlim ta’ rinfurzar (Polite-RL) jinkoraġġixxi l-ġenerazzjoni ta’ politeness billi jassenja premjijiet proporzjonali għall-punteġġ tal-klassifikatur tal-politeness tar-rispons fil-kampjun. Aħna nippreżentaw ukoll żewġ linji bażi ta’ mudell ta’ djalogu edukat u bbażati fuq l-irkupru. L-evalwazzjoni tal-bniedem tivvalida li filwaqt li l-Fużjoni u l-mudelli bbażati fuq l-irkupru jiksbu politezza b’rilevanza inqas fil-kuntest, il-mudelli LFT u Polite-RL jistgħu jipproduċu reazzjonijiet ferm aktar politi mingħajr ma jiġu sacrifikati l-kwalità tad-djalogu.</abstract_mt>
      <abstract_no>Generering av stillistisk dialog-svar, med verdilege program i personleg samtaleagentar, er eit vanskeleg oppgåve fordi svaret må vera svøgt, kontekst-relevant, og paralingisk nøyaktig. I tillegg er det vanlegvis ikkje tilgjengelege parallelle datasett for regulære til stylistiske par. Vi presenterer tre viktige oversikte modeller som kan laga diverse, polite (eller rude) dialogsvar utan parallelle data. Det siste fusjonmodellen vår (Fusion) flettar dekoderen av eit dialogmodell for koderingsdekoder med eit språk- modell trent på enkelte polite uttrykk. Etikettefinetuning (LFT) modellen vårt forventar kvar kjeldesekvens eit merkelapp skalert med politenesspoeng (foregått av vårt klassifisering av politenessklassifisering av kunsten) under opplæring, og på testtid kan laga polite, nøytrale og rude svar ved enkelt skalering av merkelappen innebygd av tilsvarande poeng. Størringsmodulet vårt (Polite-RL) forstørrar politenesslag ved å tilgje tiltak proporsjonell til den politenessklassifiseringskolaren av utvalte svaret. Vi viser også to baselinjer for henting av albaserte, polite dialogmodell. Evalueringa av menneske er gyldig at mens Fusion og tilbakebaserte modelane gjer pålitelighet med dårlegare kontekstrelevante, kan LFT- og Polite- RL- modelane lage mykje meir pålitege svar utan å oftast dialogkvalitet.</abstract_no>
      <abstract_ro>Generarea de răspunsuri stilistice în dialog, cu aplicații valoroase în agenții conversaționali bazați pe personalitate, este o sarcină provocatoare, deoarece răspunsul trebuie să fie fluent, relevant din punct de vedere contextual, precum și precis din punct de vedere paralingvistic. În plus, seturile de date paralele pentru perechile regulate-stilistice sunt de obicei indisponibile. Prezentăm trei modele slab supravegheate care pot genera răspunsuri de dialog diverse, politicoase (sau nepoliticoase) fără date paralele. Modelul nostru de fuziune târziu (Fusion) combină decodorul unui model de dialog encoder-atenție-decoder cu un model de limbaj instruit pe cuvinte politicoase independente. Modelul nostru de finisare a etichetelor (LFT) prezintă pentru fiecare secvență sursă o etichetă scalată de politețe-scor (prezisă de clasificatorul nostru de politețe de ultimă generație) în timpul antrenamentului, și la timpul testului este capabil să genereze răspunsuri politicoase, neutre și nepoliticoase prin simpla scalare a etichetei încorporate de scorul corespunzător. Modelul nostru de învățare de consolidare (Polite-RL) încurajează generarea de politețe prin atribuirea recompenselor proporționale cu scorul clasificatorului de politețe al răspunsului eșantionat. De asemenea, vă prezentăm două modele de referință de dialog politicos, bazate pe retrageri. Evaluarea umană validează faptul că, în timp ce modelele Fusion și cele bazate pe recuperare obțin politețe cu relevanță mai slabă în context, modelele LFT și Polite-RL pot produce răspunsuri semnificativ mai politicoase fără a sacrifica calitatea dialogului.</abstract_ro>
      <abstract_mn>Стилистикийн ярианы хариу үйлдэл гаргах үед, хувь хүн төрөлхтний ярианы агентуудын үнэ цэнэтэй хэрэглээ гэдэг нь хэцүү ажил. Учир нь хариу үйлдэл нь шингэн, орчин үед хамааралтай, мөн параллингистикийн зөв байх хэрэгтэй Үүнээс гадна хэдий ч стилист хооронд параллел өгөгдлийн сангууд ихэвчлэн ашиггүй. Бид төвөгтэй мэдээлэл байхгүй олон, зөв (эсвэл буруу) диалогын хариултыг бүтээж чадна гэдгийг гурван бага зэрэг удирдлагатай загваруудыг тайлбарлаж байна. Бидний сүүлийн цуглуулах загвар (Fusion) нь кодер-анхаарал-удирдах диалог загварын кодлогч загварыг нэгтгэдэг. Холбоо загвар нь ганцаараа зөв хэлбэрээр сургалтын загвартай. Бидний загварын сайхан зохиолын загвар нь эх үүсвэрийн дарааллаар бага зэрэг бага зэрэг хэмжээтэй тэмдэглэгддэг (бидний урлагийн сайхан хэмжээний хэлбэрээр таамаглагдсан) загварын тулд бага зэрэг, цэвэр, бус хариулт үүсгэх боломжтой. Бидний суралцах загвар (Polite-RL) нь шалгалтын хариултын хувьд зөвхөн шагналыг зөвхөн зөвхөн үнэ цэнэтэй хэмжээнд хангалттай байдаг. Мөн бид хоёр сэргээгдсэн, сайн диалог загварын суурь шугам бий болгож байна. Хүн төрөлхтөн дүгнэлт нь Фузион болон аврах суурь загварууд илүү ядуу нөхцөл байдлын хамааралтай сайхан байдлыг хүртэх үед, LFT болон Polite-RL загварууд диалог чадварыг нийлэхгүй илүү сайхан хариулт гаргаж чадна.</abstract_mn>
      <abstract_sr>Generacija odgovora na stilistički dijalog, sa vrijednom aplikacijom u razgovornim agentima na osnovu ličnosti, je izazovan zadatak jer odgovor mora biti tečna, kontekstualno relevantna, kao i paralinguistički tačna. Osim toga, paralelne podatke za redovne do stilističke pare obično nisu dostupne. Predstavljamo tri slabe nadzorne modele koji mogu stvoriti različite, pristojne (ili nepristojne) dijalogske odgovore bez paralelnih podataka. Naš kasni model fuzije spoji dekoder dijaloga kodera-pažnje-dekodera sa jezičkim modelom obučenim na samim pristojnim rečenicama. Naš model oznake finetuniranja (LFT) predstavlja svakom izvornom sekvenciji skaliranu etiketu (predviđenu od našeg države-umjetničkog klasifikatora pristojnosti) tokom treninga, a na vrijeme testa može stvoriti pristojne, neutralne i nepristojne odgovore jednostavno skaliranjem etikete ugrađene odgovarajućim rezultatima. Naš model učenja pojačanja (Polite-RL) poticava generaciju pristojnosti dodajući nagradu proporcionalnu prema ocjenu klasifikatora pristojnosti uzorke odgovora. Takoðe predstavljamo dva izveštajna, pristojna dijalogska modela osnovnih linija. Ljudska procjena potvrđuje da dok Fuzija i modeli na osnovu povratka ostvaruju pristojnost sa siromašnijim kontekstima, modeli LFT i Polite-RL mogu da proizvode značajno pristojnije odgovore bez žrtvovanja kvalitete dijaloga.</abstract_sr>
      <abstract_si>ස්ටායිලිස්ට් සංවාද ප්‍රතික්‍රියාත්මක ප්‍රතික්‍රියාත්මක ප්‍රතික්‍රියාත්මක ප්‍රතික්‍රියාත්මක ප්‍රතික්‍රියාත්මක විදිහට, ප්‍රතික්‍ර තවත්, සාමාන්‍ය වෙනුවෙන් ස්ටිලිස්ටික් ජෝඩු සඳහා සමාන්‍ය දත්ත සේට් විසින් පුළුවන් නෑ. අපි දුර්වලින් බලාපොරොත්තු මොඩේල් තුනක් පෙන්වන්න පුළුවන් විවිදියට, සාමාන්‍ය දත්ත නැති සංවාදය සංවාදය අපේ පරක්කු සම්පූර්ණ මොඩේල් (Fution) කෝඩාර්-අවධානය-සංවාදකයේ සංවාදකය සංවාදකය සමග භාෂා මොඩේල් එක්ක ස්ථාන අපේ ලේබල්-ෆින්ටුනික් (LFT) මොඩේල් ප්‍රීප්ඩ් කරනවා හැම ප්‍රභාව පරීක්ෂණයකට politeness-score ස්කේල් ලේබල් (ප්‍රශ්නයක් අපේ state-of-the-art politeness classifier) ප්‍රීක්ෂණය වෙලාවට, සහ පරීක්ෂණ වෙලාවට ප්‍රීත අපේ විශ්වාසයේ ඉගෙන ගන්න ප්‍රමාණය (polite-RL) සාම්පල් ප්‍රතික්‍රියාවේ ප්‍රතික්‍රියාව සම්පූර්ණය සඳහා ප්‍රතික්‍රියාත්මක අපි ආරක්ෂා කරලා තියෙන්නේ පුළුවන් දෙකක් පෙන්වන්න. මිනිස්සු විශ්ලේෂණය විශ්වාස කරනවා කියලා ෆුසියෝන් සහ ආරක්ෂාත්මක විශ්වාසයෙන් පුළුවන් විදිහට පුළුවන් විදිහට පුළුවන් විදිහට පුළ</abstract_si>
      <abstract_so>Stylistic dialogue response generation, with valuable applications in personality-based conversational agents, is a challenging task because the response needs to be fluent, contextually-relevant, as well as paralinguistically accurate.  Sidoo kale sida caadiga ah lama heli karo kooxaha macluumaadka lambarka ah ee lama isticmaalayo sida caadiga ah. Waxaynu soo jeednaa saddex noocyo oo taag yar oo la ilaaliyo oo sameyn karo jawaabo dialogue oo kala duduwan, qabow (ama si qalloocan) oo aan u sameyn macluumaad siman. Tusaalka ugu dambeeya fusion (Fusion) wuxuu ku ururiyaa koodeynta dialogue-cododer oo ku qoran model af ah oo lagu baray hadal caadi ah oo kaliya. Tusaale-finetu (LFT) ayaa u horumarinaya mid kasta oo sourceed ah inuu sameeyo calaamad xariifsan oo la mid ah (oo lagu sii sheegay state-of-the-art politeness) xilliga waxbarashada, oo wakhtiga la imtixaamo wuxuu sameyn karaa jawaabo qalloocan, neutral iyo ruqsi si si ah, si fudud u qiyaasa calaamada ku qoran scorka isku mid ah. Tilmaanka waxbarashada (Police-RL) ayaa ku dhiirrigeliya qarniga istareexsan, waxayna ku fidiyaan abaalmarinta si u eg kooxda fasaxa ee sameynta. Sidoo kale waxaan keenaynaa labada samooyin oo ku saleysan labada qaab oo ku qoran sameynta dialogue-ka. Qiimeynta dadku wuxuu xaqiijiyaa in marka muuqashada fuushan iyo modelalka ku saleysan ay si fiican u helaan, qaababka LFT iyo booliska-RL waxay keeni karaan jawaabo aad u fiican iyadoon bixinayn qiimaha dialogka.</abstract_so>
      <abstract_sv>Stilistisk dialogresponsgenerering, med värdefulla tillämpningar i personlighetsbaserade samtalsagenter, är en utmanande uppgift eftersom svaret måste vara flytande, kontextuellt relevant och paralingvistiskt korrekt. Dessutom är parallella datauppsättningar för regelbundna till stilistiska par vanligtvis otillgängliga. Vi presenterar tre svagt övervakade modeller som kan generera olika, artiga (eller oförskämda) dialogsvar utan parallella data. Vår sena fusionsmodell (Fusion) kombinerar avkodaren av en encoder-uppmärksamhet-avkodare dialogmodell med en språkmodell utbildad på fristående artiga uttalanden. Vår etikett-finjusteringsmodell (LFT) ger varje källsekvens en artighetspoäng skalad etikett (förutspådd av vår state-of-the-art artighetsklassificerare) under träning, och vid testtiden kan generera artiga, neutrala och oförskämda svar genom att helt enkelt skala etikettinbäddningen med motsvarande poäng. Vår modell för förstärkning av inlärning (Polite-RL) uppmuntrar artighet genom att tilldela belöningar som är proportionella till artighetsklassificeringspoäng för det utvalda svaret. Vi presenterar också två retrievbaserade, artiga dialogmodeller baselines. Mänsklig utvärdering bekräftar att medan Fusion och de återvinningsbaserade modellerna uppnår artighet med sämre kontextrelevans, kan LFT och Polite-RL modellerna producera betydligt mer artiga svar utan att offra dialogens kvalitet.</abstract_sv>
      <abstract_ta>பாணியல் உரையாடல் பதில் உருவாக்கு, தனிப்பட்ட பேச்சு முகவரிகளில் மதிப்புள்ள பயன்பாடுகளுடன், இது சவாலிக்கும் பணி மேலும், வழக்கமான- to- stylist ஜோடிகளுக்கான இணைய தரவுத்தள அமைப்புகள் வழக்கமாக கிடைக்கவில்லை. நாம் மூன்று பலவீனமான கண்காணிக்கப்பட்ட மாதிரிகளை காண்பிக்கிறோம். இது ஒப்பீட்டு தரவு இல்லாமல் பல்வேறு பாதுகாப்பு, அல் எங்கள் தாமதமான குளியீட்டு மாதிரி (Fusion) குறியீட்டு கவனம்- குறியீட்டாளர் உரையாடல் மாதிரியை ஒரு மொழி மாதிரியில் பயிற்சிக்கப்பட்ட ம எங்கள் விளக்கச்சீட்டு மாதிரி ஒவ்வொரு மூலத்தின் வரிசையிலும் முன்னிருக்கும் முன்னிருக்கிறது பயிற்சியில் உள்ள விளக்கச்சீட்டை மாற்றுகிறது (எங்கள் நிலையில்- கலை பரிசுத்தமான வகுப்பாளரால்) பய நம்முடைய கல்வி மாதிரி( போலிட்- RL) முறைமையில் முழுமையான தலைமுறையின் மூலம் முன்னோட்டிருக்கும் பதிலின் முழுமையான பிரிவி நாம் இரண்டு மீண்டும் மீண்டும் பெற்றுக்கொண்டிருக்கிறோம், மிகவும் சுத்தமான உரையாடல் மாதிர மனித மதிப்பு சரிபார்க்கிறது என்றால் முடிவும் மற்றும் மீட்டெடுக்கப்பட்ட மாதிரிகளும் ஏழைய சூழல் தொடர்புடன் கொள்ள முடியும் போது, LFT மற்றும் கோள்காட்டி</abstract_ta>
      <abstract_ur>استیلیسٹ ڈیلوگر کی جواب کی نسل، شخصیت-based conversational agents میں مقدار کاربرد کے ساتھ، ایک مشکل کام ہے کیونکہ جواب پالنے کی ضرورت ہے، کنٹیکسٹ-مرتبہ اور مشکل دقیق ہونے کی ضرورت ہے. اور اس کے علاوہ، سائل ڈاٹ سٹ ریڈیل سے استیلیستیک جوڑوں کے لئے معمولاً غیر موجود ہیں. ہم تین کمزور نظارت والی موڈل پیش کرتے ہیں جو مختلف، مطمئن (یا ناپاک) دائٹ کے بغیر مختلف جواب دیں گے۔ ہماری آخری فوزین موڈل (Fusion) ایک کوڈر-توجه-ڈیکوڈر دیالوگ موڈل کے ڈیکوڈر کو ایک زبان موڈل کے ساتھ آموزش کی جاتی ہے جو ایک ہی اچھی باتوں پر آموزش کی جاتی ہے۔ ہمارے لیبل فین ٹونگ (LFT) موڈل ہر سورس کی سطح کے لئے ایک پاکیزگی-اسکائٹ اسکائل لیبل (ہماری حالت-of-the-art-politeness classifier کی پیش بینی کی گئی) کی تدریجی میں، اور آزمائش کے وقت پر نرمی، نرمی اور بے حیائی کا جواب پیدا کرنا قادر ہے، صرف مطابق سطح سطح سطح سطح سطح سطح کے لبل میں ہماری مضبوط تعلیم مدل (Polite-RL) اچھی نسل کو اچھی طرح سفارش دیتا ہے کہ نمونڈ کی جواب کے مطابق اچھی طرح کے ثواب کے مطابق مقرر کر دیتے ہیں۔ ہم نے دو پھیر لینے والی، پسندیدہ ڈالیلوگر موڈل بنسلین بھی پیش کیے۔ انسان کا ارزیابی کرتا ہے کہ جہاں تک فسین اور پھیر لینے پر بنیاد رکھے ہوئے موڈل کمزور کنٹنس کے معاملہ سے پاکیزگی حاصل کرتی ہیں، LFT اور Polite-RL موڈل بہت اچھے جواب حاصل کرسکتے ہیں بغیر جہاد کی کیفیت کے۔</abstract_ur>
      <abstract_pl>Generowanie odpowiedzi na dialog stylistyczny, z cennymi zastosowaniami dla agentów rozmowy opartych na osobowości, jest wyzwaniem, ponieważ odpowiedź musi być płynna, kontekstowo istotna, a także paralingwistycznie dokładna. Ponadto równoległe zbiory danych dla par regularnych do stylistycznych są zwykle niedostępne. Przedstawiamy trzy słabo nadzorowane modele, które mogą generować różnorodne, uprzejme (lub niegrzeczne) odpowiedzi dialogowe bez równoległych danych. Nasz późny model fuzji (Fusion) łączy dekoder modelu dialogu koder-uwaga-dekoder z modelem językowym przeszkolonym na samodzielnych uprzejmych wypowiedziach. Nasz model precyzyjnego dostrajania etykiet (LFT) wstępuje do każdej sekwencji źródłowej etykietę skalowaną w skali wyniku grzeczności (przewidywaną przez nasz najnowocześniejszy klasyfikator grzeczności) podczas treningu, a w czasie testu jest w stanie generować grzeczne, neutralne i niegrzeczne odpowiedzi poprzez po prostu skalowanie etykiety osadzonej przez odpowiedni wynik. Nasz model uczenia się wzmacniającego (Polite-RL) zachęca do generowania grzeczności poprzez przypisanie nagród proporcjonalnych do wyniku klasyfikacji grzeczności w próbkowanej odpowiedzi. Przedstawiamy również dwie opisane, uprzejme modele dialogu. Ocena ludzka potwierdza, że podczas gdy model Fusion i modele oparte na odzyskiwaniu osiągają uprzejmość o mniejszym kontekście, modele LFT i Polite-RL mogą wytwarzać znacznie bardziej uprzejme odpowiedzi bez poświęcania jakości dialogu.</abstract_pl>
      <abstract_uz>Name Koʻrsatilgan, oddiy qoʻllanmalar uchun parallel maʼlumot setlari oddiy mavjud emas. We present three weakly-supervised models that can generate diverse, polite (or rude) dialogue responses without parallel data.  Bizning oxirgi fusion modeli (Fusion) kodlash usulining kodlash usulini birlashtirish mumkin va bir tilning o'xshash qo'llangan gaplarga o'rganish modeli bilan o'rganish mumkin. Bizning yorliq soni (LFT) modelimiz har bir manbani qo'yish qoidaga qo'yish chegarasining chegarasi yordamida o'zgartirib chiqaradi. Va sinov vaqtda qo'l, katta va ruxsat javoblarni yaratish mumkin. Bizning o'rganish modelimizni yordam berishimiz mumkin, samol javoblarning eng yaxshi darajadagi soʻzlarni qo'shishga yordam beradi. Biz ikkita xabarlar asosiy, oq muloqat modeli asosiy yozuvlarini hozir qilamiz. Inson qiymatlari haqiqiqiyligini toʻgʻri qiladi. Bir xil va qayta olish asosida modellar juda ko'proq darajada qo'shishni amalga oshirishda, LFT va Polisi- RL modellari muloqat sifatini qo'shish mumkin.</abstract_uz>
      <abstract_vi>Thế hệ phản ứng cuộc đối thoại kiểu dáng, với những ứng dụng có giá trị trong các đặc vụ đối thoại dựa trên cá nhân, là một nhiệm vụ khó khăn bởi vì phản ứng cần phải thông thạo, liên quan ngữ cảnh, cũng như tương đối chính xác. Thêm nữa, các tập tin song song cho các cặp kiểu đều không sẵn sàng. Chúng tôi giới thiệu ba mẫu được giám sát thiếu sót có thể tạo ra các phản ứng đối thoại rộng rãi, lịch sự hoặc thô lỗ. Mẫu tan chảy (Fusion) của chúng ta hợp nhất bộ giải mã của một mô hình giữa mã hóa và mã hóa bằng một mô hình ngôn ngữ được rèn luyện bằng những từ bình thường. Mẫu dán nhãn tuyệt độ (LFT) tính trước mỗi chuỗi nguồn một nhãn hiệu chỉnh biên số tráng lệ (dự đoán bởi người phân loại lịch sự nghệ thuật thời đại) trong thời gian huấn luyện, và trong thời gian thử nghiệm là có khả năng tạo ra các phản ứng lịch sự, trung lập và thô lỗ bằng cách đơn giản xếp nhãn ngang bằng số lượng tương ứng. Cách học củng cố (Polite-RL) của chúng tôi khuyến khích việc sản xuất các phẩm lịch sự bằng cách tặng những phần thưởng tỉ lệ cho số người phân phối lịch sự trong phản ứng thử. Chúng tôi cũng giới thiệu hai căn cứ mẫu thoại mẫu mực. Phân tích con người xác nhận rằng mặc dù thử nghiệm Fusion và các mẫu dựa trên việc lấy lại đạt độ lịch sự với giá trị ngữ cảnh kém hơn, các mô hình LFT và Polite-RL có thể tạo phản ứng tốt hơn đáng kể mà không cần phải hy sinh chất lượng đối thoại.</abstract_vi>
      <abstract_nl>Stijlvolle dialoogresponsgeneratie, met waardevolle toepassingen in persoonlijkheidsgebaseerde gespreksagenten, is een uitdagende taak omdat de respons vloeiend, contextueel relevant en paralinguïstisch nauwkeurig moet zijn. Bovendien zijn parallelle datasets voor regular-to-stylistische paren meestal niet beschikbaar. We presenteren drie zwak begeleide modellen die verschillende, beleefde (of onbeschofte) dialoogreacties kunnen genereren zonder parallelle gegevens. Ons late fusiemodel (Fusion) combineert de decoder van een encoder-aandacht-decoder dialoogmodel met een taalmodel dat is getraind op stand-alone beleefde uitspraken. Ons label-finetuning (LFT) model prepareert aan elke bronsequentie een beleefdheidsscore geschaald label (voorspeld door onze state-of-the-art beleefdheidsclassificator) tijdens de training en is in staat beleefde, neutrale en onbeschofte reacties te genereren door simpelweg de label embedded met de overeenkomstige score te schalen. Ons versterkingsmodel (Polite-RL) stimuleert het genereren van beleefdheid door beloningen toe te kennen die evenredig zijn met de score van de beleefdheidsclassificator van de sampled respons. We presenteren ook twee retrievalbased, beleefde dialoogmodel baselines. Menselijke evaluatie bevestigt dat terwijl de Fusion en de op retrieval gebaseerde modellen beleefdheid bereiken met een slechtere context-relevantie, de LFT en Polite-RL modellen aanzienlijk beleefdere reacties kunnen produceren zonder afbreuk te doen aan de kwaliteit van de dialoog.</abstract_nl>
      <abstract_da>Stilistisk dialog respons generation, med værdifulde anvendelser i personlighedsbaserede samtaleagenter, er en udfordrende opgave, fordi responsen skal være flydende, kontekstuelt relevant, såvel som paralingvistisk nøjagtig. Desuden er parallelle datasæt for almindelige til stilistiske par normalt utilgængelige. Vi præsenterer tre svagt overvågede modeller, der kan generere forskellige, høflige (eller uhøflige) dialogsvar uden parallelle data. Vores sene fusionsmodel (Fusion) fusionerer dekoder af en encoder-opmærksomhed-dekoder dialog model med en sprogmodel trænet i stand-alone høflige udtalelser. Vores label-finjusteringsmodel (LFT) model præsenterer for hver kildesekvens en høflighedsscore skaleret etiket (forudsagt af vores state-of-the-art høflighedsklassificering) under træning, og på testtidspunktet er i stand til at generere høflige, neutrale og uhøflige svar ved blot at skalere etiket indlejring med den tilsvarende score. Vores forstærkningslæringsmodel (Polite-RL) opfordrer til generering af høflighed ved at tildele belønninger, der står i forhold til høflighedsklassificeringsscoren for den prøvede respons. Vi præsenterer også to henvisningsbaserede, høflige dialog model baselines. Menneskelig evaluering bekræfter, at mens Fusion og de hentningsbaserede modeller opnår høflighed med dårligere kontekst-relevans, kan LFT og Polite-RL modellerne producere betydeligt mere høflige svar uden at gå på kompromis med dialogens kvalitet.</abstract_da>
      <abstract_hr>Generacija odgovora na stilistički dijalog, s vrijednim primjenama u razgovornim agentima na osnovu osobnosti, je izazovan zadatak jer odgovor mora biti tečna, kontekstualno relevantna, kao i paralinguistički tačna. Osim toga, paralelne podatke za obične do stilističke pare obično nisu dostupne. Predstavljamo tri slabe nadzorne modele koji mogu stvoriti različite, pristojne (ili nepristojne) dijalogske odgovore bez paralelnih podataka. Naš kasni fuzijski model (Fusion) spoji dekoder dijaloga kodera-pažnje-dekodera s jezičkim modelom obučenim na samim pristojnim izrazima. Naš model označavanja finetuniranja (LFT) predstavlja svakom izvornom sekvenciji skaliranu etiketu skaliranog rezultata pristojnosti (predviđenu od našeg klasifikatora stanja umjetnosti pristojnosti) tijekom treninga, a na vrijeme ispitivanja može stvoriti pristojne, neutralne i nepristojne odgovore jednostavno skaliranjem etikete uključene odgovarajućim rezultatima. Naš model učenja pojačanja (Polite-RL) poticava generaciju pristojnosti dodajući nagrade proporcionalne prema ocjenu klasifikatora pristojnosti uzorke odgovora. Također predstavljamo dvije osnovne linije prikupljene, pristojne dijalogske modele. Ljudska procjena potvrđuje da dok Fusion i modeli na osnovu povratka postignu pristojnost s siromašnijim kontekstskim relevancijom, modeli LFT i Polite-RL mogu proizvesti značajno pristojnije odgovore bez žrtvovanja kvalitete dijaloga.</abstract_hr>
      <abstract_bg>Генерирането на стилистичен диалог с ценни приложения в личностно базирани разговорни агенти е предизвикателна задача, тъй като отговорът трябва да бъде плавен, контекстуално уместен, както и паралингвистически точен. Освен това паралелните набори от данни за редовни към стилистични двойки обикновено не са налични. Представяме три слабо контролирани модела, които могат да генерират разнообразни, учтиви (или груби) диалогови отговори без паралелни данни. Нашият модел за късен синтез слива декодера на диалогов модел кодер-внимание-декодер с езиков модел, обучен върху самостоятелни учтиви изказвания. Нашият модел за фино настройване на етикети (LFT) предхожда към всяка последователност източник етикет с мащабиран рейтинг за учтивост (прогнозиран от нашия най-модерен класификатор за учтивост) по време на обучение и по време на теста може да генерира учтиви, неутрални и груби отговори, като просто мащабира вграждането на етикета със съответния резултат. Нашият модел на обучение за подсилване насърчава генерирането на учтивост чрез присъждане на награди, пропорционални на оценката на класификатора за учтивост на избрания отговор. Представяме и две базови линии на модела на възпитан диалог. Оценката на човека потвърждава, че докато моделите, базирани на синтез и извличане, постигат учтивост с по-слабо значение за контекста, моделите LFT и Polite-RL могат да дадат значително по-учтиви отговори, без да жертват качеството на диалога.</abstract_bg>
      <abstract_de>Stilistische Dialogantwort-Generierung mit wertvollen Anwendungen in persГ¶nlichkeitsbasierten GesprГӨchspartnern ist eine herausfordernde Aufgabe, da die Antwort flieГҹend, kontextbezogen und paralinguistisch genau sein muss. DarГјber hinaus sind parallele DatensГӨtze fГјr regulГӨr-stilistische Paare in der Regel nicht verfГјgbar. Wir prГӨsentieren drei schwach Гјberwachte Modelle, die vielfГӨltige, hГ¶fliche (oder unhГ¶fliche) Dialogantworten ohne parallele Daten generieren kГ¶nnen. Unser spГӨtes Fusionsmodell (Fusion) verbindet den Decoder eines Encoder-Aufmerksamkeits-Decoder Dialogmodells mit einem Sprachmodell, das auf eigenstГӨndige hГ¶fliche Г„uГҹerungen trainiert ist. Unser Label-Finetuning (LFT)-Modell bereitet jeder Quellsequenz wГӨhrend des Trainings ein HГ¶flichkeits-Score skaliertes Label vor (das von unserem hochmodernen HГ¶flichkeitsklassifikator vorhergesagt wird) und ist zum Testzeitpunkt in der Lage hГ¶fliche, neutrale und unhГ¶fliche Antworten zu generieren, indem die Label-Einbettung einfach um die entsprechende Punktzahl skaliert wird. Unser VerstГӨrkungs-Lernmodell (Polite-RL) fГ¶rdert die Generierung von HГ¶flichkeit, indem Belohnungen proportional zum HГ¶flichkeitsklassifikator-Score der gesampelten Antwort zugewiesen werden. Wir stellen auch zwei Retrievalbasierte, hГ¶fliche Dialogmodelle vor. Die menschliche Bewertung bestГӨtigt, dass die Fusion- und die Retrieval-basierten Modelle zwar HГ¶flichkeit mit geringerer Kontextrelevanz erzielen, die LFT- und Polite-RL-Modelle jedoch deutlich hГ¶flichere Antworten liefern kГ¶nnen, ohne dabei die DialogqualitГӨt zu beeintrГӨchtigen.</abstract_de>
      <abstract_id>Generasi respons dialog stilistik, dengan aplikasi berharga dalam agen konversasi berdasarkan pribadi, adalah tugas yang menantang karena respons perlu fluent, kontekstual-relevan, serta akurat secara paralinguis. Selain itu, dataset paralel untuk pasangan rutin-ke-stilistik biasanya tidak tersedia. Kami mempersembahkan tiga model yang diawasi lemah yang dapat menghasilkan respons dialog yang berbeda, sopan (atau kasar) tanpa data paralel. Model fusi terlambat kami (Fusion) menggabungkan dekoder dari model dialog pengekoder-perhatian-dekoder dengan model bahasa yang dilatih pada ucapan sopan sendiri. Model label-finetuning (LFT) kami mempersiapkan untuk setiap urutan sumber label skala kebaikan-skor (diprediksi oleh klasifikasi kebaikan state-of-the-art kami) selama latihan, dan pada waktu tes mampu menghasilkan respon sopan, netral, dan kasar dengan hanya skala label memasukkan dengan skor yang sesuai. Model belajar pemerintahan kami (Polite-RL) mendorong generasi kebaikan dengan memberikan hadiah proporsional dengan skor klasifikasi kebaikan dari respon yang ditempatkan. Kami juga mempersembahkan dua garis dasar model dialog yang sopan dan dibasis kembali. Evaluasi manusia mengkvalifikasi bahwa sementara Fusion dan model berdasarkan retrieval mencapai kebaikan dengan konteks-relevansi yang lebih buruk, model LFT dan Polite-RL dapat menghasilkan respon yang jauh lebih sopan tanpa mengorbankan kualitas dialog.</abstract_id>
      <abstract_ko>문체 대화 반응 생성은 개성을 바탕으로 하는 대화 주체에서 중요한 응용을 하는데 이것은 도전적인 임무이다. 왜냐하면 반응은 유창하고 상하문이 관련되며 부언어가 정확해야 하기 때문이다.그 밖에 일반적인 스타일에 맞는 병렬 데이터 집합을 얻을 수 없습니다.우리는 세 가지 약한 감독 모델을 제시했는데 그것이 평행 데이터가 없는 상황에서 서로 다른, 예의바른(또는 거칠은) 대화 반응을 생성할 수 있다.우리의 후기 융합 모델(fusion)은 인코더-주의-인코더 대화 모델의 인코더와 독립된 예의 언어 훈련을 바탕으로 하는 언어 모델을 융합시켰다.우리의 라벨 마이크로스피커(LFT) 모델은 훈련 기간에 모든 원본 서열에 예의 점수 표시 라벨(우리가 가장 선진적인 예의 분류기로 예측)을 미리 설정하여 테스트할 때 상응하는 점수 표시 라벨에 간단하게 삽입함으로써 예의, 중립, 거친 대답을 생성할 수 있다.우리의 강화된 학습모델(Politive RL)은 표본 응답의 예의 분류 점수와 비례하는 보상을 분배함으로써 예의 생성을 장려한다.우리는 또한 검색을 바탕으로 하는 두 가지 예의 대화 모델의 기선을 제시했다.인간 평가는 검색에 기반한 모델을 융합시켜 언어 환경 관련성이 떨어지는 예의를 실현했지만 LFT와 예의 RL모델은 대화의 질을 희생하지 않고 더욱 예의 바르게 대응할 수 있음을 증명했다.</abstract_ko>
      <abstract_sw>Kizazi cha mwitikio wa mazungumzo ya usolusi, kwa matumizi ya thamani katika mashirika ya mazungumzo yenye kibinafsi, ni jukumu la changamoto kwa sababu jibu lazima iwe sahihi, yenye umuhimu, pamoja na uhakika wa lugha. Zaidi ya hayo, seti za takwimu zinazofanana kwa wanaume wa kawaida hadi aina moja kwa moja huwa hazipatikani. Tunaweza kuwaweka mifano mitatu inayofuatiliwa na udhaifu ambao unaweza kutengeneza majadiliano mbalimbali, mweupe (au yasiyo ya kawaida) bila taarifa za usambazaji. Mradi wetu wa mwishoni wa fujo (Fusion) unaunganisha kodi ya modeli ya mazungumzo yenye uchunguzi mkali na mtindo wa lugha uliojifundishwa kwa maneno yasiyo sahihi pekee ya kusimama. Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score.  Mfano wetu wa kujifunza (Polisi-RL) unahamasisha kizazi cha uraia kwa kutoa malipo yanayofanana na kipimo cha usawa wa majibu ya sampuli. Pia tunaweka mistari miwili ya mazungumzo mazuri ya mazungumzo. Utafiti wa binadamu unathibitisha kwamba wakati Uhamiaji na mifano yenye msingi wa kurejesha hupata urahisi na hali mbaya zaidi ya mazingira, mifano ya LFT na Polisi-RL inaweza kuleta miitikio bora zaidi bila kutoa sifa za mazungumzo.</abstract_sw>
      <abstract_tr>Şahsy görkezilişi ajamlardan mykdarlar bilen stilistik dialog jogabaty döredilmesi çykyş bir täsirdir, sebäbi jogabat howply, günlerde möhüm bolmaly we paralizik derejesi bar. Ayrıca, adatça-stil çiftleriň parallel sanlary adatça ulaşan däl. Biz üç iň zayıf-gözleýän modelleri parallel maglumaty bolmasa çeşitli, polit (ýa kaba) dialogyň jogaplary döredip biljek üçin örän nusgasyny görkeýäris Fusion etiket-finetimiz (LFT) nusgasymyz öňünde her çeşme sanlarynda politenes-अ-golaýy derejesini golaýlaýar Biziň güçlendirmeli öwrenmek nusgasymyz (Polite-RL) örnekleriň gönülden jogabatyň proporsiýalygy bilen üýtgetmegi üçin mykdarlygy jemgyýetlendirir. Biz hem iki arkalanyş hasaplanýarys, polit dialog nusgasyny çykarýarys Adamlar deňlemesi Fusiýa we almak tabanly nusgalary ýakyn kontekst wajyplygyna golaýlaýan wagtynda, LFT we Polite-RL nusgalary dijalogyň keyfiýasyny boýunça has gowy jogaplary üretebilir.</abstract_tr>
      <abstract_fa>نسل پاسخ گفتگوی استیلیست، با کاربردهای ارزشمند در ماموران گفتگوی بر اساس شخصیت، یک کار سخت‌کننده است چون پاسخ باید آب باشد، در موقعیت مربوط به موقعیت و همچنین دقیق پارالینگ باشد. علاوه بر این، مجموعه‌های داده‌های متفاوتی برای جفت‌های معمولی به استیلیستیک معمولاً در دسترسی نیستند. ما سه مدل تحت نظر ضعیف را پیشنهاد می‌کنیم که می‌توانند پاسخ‌های گفتگوی مختلف، مودبانه (یا بی‌اثر) را بدون داده‌های متفاوت تولید کنند. مدل فسیون (Fusion) آخرین ما دکوردر یک مدل محاورۀ دیکورد توجه‌دهنده با مدل زبانی آموزش داده شده در کلمات پاکیزه تنها می‌کند. مدل آرامش نقاشی (LFT) ما در طول تمرین برای هر رده منبع یک نقاشی مقایسه‌ای از نمره‌های آرامش (پیش‌بینی توسط برنامه‌های آرامش هنرمان) پیش‌بینی می‌کند، و در زمان آزمایش می‌تواند پاسخ‌های پاکیزه، بی‌نیاز و بی‌نیاز را توسط ساده‌سازی نقاشی که توسط نقاشی متصل می‌شود توس مدل یادگیری نیرومندگی ما (Polite-RL) نسل نیرومندگی را با توجه به پاداش دادن پاداش‌های نسبت به نمونه‌های نمونه‌بندی به نمونه‌بندی‌کننده‌ی کلانترین نیرومندگی تشویق می‌کند. ما همچنین دو مدل پایین صفحه‌های استفاده از بازیابی‌شده‌ای را پیشنهاد می‌کنیم. ارزیابی انسان تصدیق می‌کند که در حالی که مدل‌های فسیون و بازیابی بر اساس بازیابی با ارزش محیط ضعیف‌تری می‌رسد، مدل‌های LFT و Polite-RL می‌توانند جواب‌های مهربان‌تری را بدون قربانی کیفیت گفتگوی بسیار مهربان‌تر تولید کنند.</abstract_fa>
      <abstract_sq>Gjenerimi i përgjigjeve të dialogut stilistik, me aplikime të vlefshme në agjentët bisedimorë bazuar në personalitet, është një detyrë e vështirë sepse përgjigja duhet të jetë fluente, kontekstualisht e rëndësishme, si dhe paralinguistikisht e saktë. Përveç kësaj, të dhënat paralele për çiftet e rregullta në stilistike zakonisht nuk janë të disponueshme. Ne prezantojmë tre modele të mbikqyrur dobësisht që mund të gjenerojnë përgjigje të ndryshme, të sjellshme (apo të paduruara) të dialogut pa të dhëna paralele. Modeli ynë i fundit i fuzionit (Fusion) bashkon dekoderin e një modeli të dialogut të koduesit-vëmendjes-dekoderit me një model gjuhësh të stërvitur në shprehje të vetme të sjellshme. Modeli ynë i përmirësimit të etiketës (LFT) përgatitet për secuencën e burimeve një etiketë të shkallëzuar me pikë të sjellshme (parashikuar nga klasifikuesi ynë i lartë i sjellshëm) gjatë trajnimit, dhe në kohën e testit është në gjendje të gjenerojë përgjigje të sjellshme, neutrale dhe të padurueshme duke thjesht shkallëzuar etiketën e përfshirë nga pika korrespondente. Modeli ynë i mësimit të forcimit (Polite-RL) inkurajon gjeneratën e sjellshmërisë duke caktuar shpërblime proporcionale me rezultatin klasifikues të sjellshmërisë të përgjigjes së marrë në muzikë. Ne prezantojmë gjithashtu dy linja bazë të modelit të dialogut të sjellshëm dhe të sjellshëm. Vlerësimi njerëzor vlerëson se ndërsa Fusion dhe modelet bazuar në marrje arrijnë sjellje me rëndësi më të dobët konteksti, modelet LFT dhe Polite-RL mund të prodhojnë përgjigje më të sjellshme pa sakrifikuar cilësinë e dialogut.</abstract_sq>
      <abstract_am>የስታሌስክ መልዕክት ትውልድ፣ በአዳራዊ በተቃዋሚ ፕሮግራሞች ውስጥ በሚያዋርዱ አካባቢዎች፣ መልዕክቱ ፍላጎት፣ በተጨማሪው እና በተለየ ቋንቋዊ ግንኙነት ሊሆን ያስፈልጋል፡፡ በተጨማሪም፣ ለዘጠኝ-ወደ-stylistic ዓይነቶች የተለየ የዳታተር ዕይታ አይገኙም፡፡ ሦስት የደካማ ተሟጋቾች ምሳሌዎችን እናቀርባታለን፣ መልዕክት ልዩ፣ ንጹሕ (ወይም ቀይ) በማስተካከል ጥያቄዎችን እናደርጋለን፡፡ የኋለኛይቱ ፍጹም ሞዴል (Fusion) የድምፅ-አዳራሽ-የድምፅ-አቀማመጥ-አቋራጭ የሚናገሩትን የቋንቋ ምሳሌ ለብቻው ንጹሕ ንግግር የተጠቃመ ቋንቋ አካባቢ እና አቀማቅሎታል፡፡ የኢንተርኔት-ፍላጎታችን (LFT) ሞዴል ለሁሉም ምንጮች የደረጃ ደረጃዎችን ለዋጭቷል፡፡ Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response.  ሁለትን አቀማመጥ እናቀርባታለን፣ ጥሩ እናስማማታለን፡፡ የሰው ውይይት ግንኙነት፣ የውጤት እና የመስጠት ዓይነቶች ከድህነት ግንኙነት ጋር ማድረግ ሲደረጉ፣ የLFT እና ፖሊሲ-RL ሞዴሎች በማስተካከል ጥሩ ጥሩ ጥያቄን ሳይሰጥ ጥሩ ጥያቄዎችን ሊያደርጉ ይችላል፡፡</abstract_am>
      <abstract_af>Stylistiese dialoog antwoord generasie, met waardelike toepassings in persoonlike gebaseerde konversasionale agente, is 'n pragtige taak omdat die antwoord fluent moet wees, contextually-relevante, en paralingiese presies. Ook, parallele datastelle vir gewone na- stylistiese paar is gewoonlik onbeskikbaar. Ons stel drie swak-ondersoekte modele wat verskeie, polite (of rude) dialoog antwoordes kan genereer sonder parallele data. Ons laat fusie model (Fusion) maak die dekoder van 'n enkoder-aandag-dekoder dialoog model saam met 'n taal model opgelei op stand-alone polite uitdrukkings. Ons etiket- finetuning (LFT) model voorstel na elke bron sekvensie 'n belangrikheid- score skaleerde etiket (voorskou deur ons state- of- the- art- belangrikheid klassifiseerder) tydens onderwerp, en op toets tyd is in staat om belangrike, neutrale en rude reaksies te genereer deur eenvoudig die etiket inbeter deur die ooreenstemmende telling te skaleer. Ons versterking onderwerp model (Polite-RL) bevestig belangrikheid generasie deur vergelde proporsioneel aan die belangrikheid klassifiseerder aantal van die verstelde antwoord te wys. Ons stel ook twee herhaal, belangrike dialoog model basilyne. Die menslike evaluering bevestig dat terwyl die Fusion en die herhaal-gebaseerde modele belangrikheid met armer konteks-relevansie bereik, kan die LFT en Polite-RL-modele betekenlik meer belangrike reaksies produseer sonder om dialoog-kwaliteit te offer.</abstract_af>
      <abstract_hy>Ստիլիստիկ երկխոսության արձագանքների ստեղծման արդյունք, որն ունի արժեքավոր ծրագրեր անհատականության հիմնված հաղորդակցման գործոններում, դժվար խնդիր է, որովհետև արձագանքը պետք է լինի հեշտ, կոնտեքստորեն կարևոր, ինչպես նաև զուգահեռական ճշգրի Ավելին, սովորաբար կանոնական-ոճելիստ զույգերի զույգերի զուգահեռ տվյալներ չկան: Մենք ներկայացնում ենք երեք թույլ վերահսկվող մոդել, որոնք կարող են ստեղծել բազմազան, քաղաքավար (կամ անդամ) պատասխաններ առանց զուգահեռ տվյալների: Մեր ուշ ֆուզիոնային մոդելը միավորում է կոդավոր-ուշադրություն-կոդավոր-կոդավոր երկրորդ մոդելի կոդավորը լեզվի մոդելի հետ, որը սովորեցվում է առանձին քաղաքավարական արտահայտություններով: Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score.  Մեր ուժեղացման ուսուցման մոդելը խրախուսում է քաղաքավարության սերունդը, տրելով պարգևեր, որոնք համապատասխանատու են քաղաքավարության դասակարգման գնահատականներին: Մենք նաև ներկայացնում ենք երկու բարձրացված, քաղաքավար հաղորդակցման մոդելի հիմնական գծեր: Human evaluation validates that while the Fusion and the retrieval-based models achieve politeness with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialogue quality.</abstract_hy>
      <abstract_bn>স্টাইলিস্টিক ডায়ালগের প্রতিক্রিয়া প্রজন্ম, ব্যক্তিগত ভিত্তিক কথোপকথন এজেন্টের মূল্যবান অ্যাপলিকেশন, এটা একটি চ্যালেঞ্জ কাজ, কারণ প্রতিক্রিয় এছাড়াও, নিয়মিত-থেকে স্টাইলিস্ট জোড়ার জন্য প্যারালেল ডাটাসেট সাধারণত উপলব্ধ নয়। আমরা তিনটি দুর্বল পর্যবেক্ষণের মডেল উপস্থাপন করছি যা প্যারালেল ডাটা ছাড়া বৈচিত্র্যময়, নৈতিক (অথবা নিষ্ঠুর) ডায়ালগের প্রত আমাদের শেষ ফ্যাশন মডেল (ফিউশন) একটি এনকোডার-মনোযোগ-ডেকোডার ডায়ালগ মডেলের ডেকোডারের সাথে যুক্ত করেছে যার মাধ্যমে একটি ভাষার মডেলের আমাদের লেবেল-ফিনিটিং (এলএফটি) মডেল প্রশিক্ষণের সময়ে প্রত্যেক উৎসের স্কোরের স্কোরের স্কোরের একটি নীতিশীল লেবেল (আমাদের রাষ্ট্র-শিল্প-শ্রেণীর নীতিশীলতা বিশ্লেষকের প্রতি ভবিষ্যৎবাণী)  আমাদের শিক্ষা শিক্ষা মডেল (পুলিশ-আরএল) সামান্য প্রতিক্রিয়ার সুন্দর স্কোরের মাধ্যমে নীতির প্রজন্ম উৎসাহ প্রদান করে। আমরা দুটি পুনরুদ্ধারের ভিত্তিক, সুন্দর ডায়ালগ মডেলাইনের বেসাইন উপস্থাপন করি। মানুষের মানুষের মূল্য যোগাযোগ করে যে যখন ফিউশন এবং পুনরুদ্ধারের ভিত্তিক মডেলগুলো দরিদ্র পরিসংক্রান্ত পরিসংক্রান্ত পরিসংক্রান্ত পরিসংখ্যানের সাথে সুশ</abstract_bn>
      <abstract_bs>Generacija odgovora na stilistički dijalog, s vrijednim aplikacijom u razgovornim agentima na osnovu ličnosti, je izazovan zadatak jer odgovor mora biti tečna, kontekstualno relevantna, kao i paralinguistički tačna. Osim toga, paralelne podatke za redovne do stilističke pare obično nisu dostupne. Predstavljamo tri slabe nadzorne modela koji mogu stvoriti različite, pristojne (ili nepristojne) dijalogske odgovore bez paralelnih podataka. Naš kasni model fuzije spoji dekoder dijaloga kodera-pažnje-dekodera sa jezičkim modelom obučenim na samim pristojnim rečenicama. Naš model finetuniranja etiketa (LFT) predstavlja svakoj sekvenciji izvora skaliranu etiketu (predviđenu od našeg države-umjetničkog klasifikatora pristojnosti) tijekom treninga, a na vrijeme testa može stvoriti pristojne, neutralne i nepristojne odgovore jednostavno skaliranjem etikete ugrađene odgovarajućim rezultatima. Naš model učenja pojačanja (Polite-RL) poticava generaciju pristojnosti dodajući nagradu proporcionalnu prema ocjenu klasifikatora pristojnosti uzorke odgovora. Također predstavljamo dva izvedena, pristojna dijalogska modela osnovnih linija. Ljudska procjena potvrđuje da dok Fuzija i modeli na osnovu povratka ostvaruju pristojnost sa siromašnijim kontekstskim relevancijama, modeli LFT i Polite-RL mogu proizvesti značajno pristojnije odgovore bez žrtvovanja kvalitete dijaloga.</abstract_bs>
      <abstract_az>Stylistik danışma cavabı nəzəriyyəti, kişilik tabanlı danışma a ģentlərində qiymətli uyğulamalar ilə, çətin bir işdir, çünki cavabı sıxıntılı, contextual-relevant və paralinguisticki doğru olmalıdır. Daha sonra, normal-to-stylistik çiftlər üçün paralel veri qurğuları genellikle faydalanılmaz. Biz müxtəlif, müqəddəs, mərhəmətli (ya da çətin) dijalog cavablarını paralel məlumatları olmadan yarada bilən üç zəif gözləyirli modelləri göstəririk. Bizim sonuncu fusion modellərimiz kodlayıcı-dikkat-dekoder dialogu modellərini yalnız təmiz sözlərdə təhsil edilən dil modelləri ilə birləşdirir. Bizim etiket-finetuning modelimiz hər mənbə seçməsinə təcrübə sırasında təcrübə sırasında təcrübə sırasında kiçik, nötrlü və çətin cavab verə bilər, sadəcə müəyyən nöqtəsi ilə etiket inşa edilən etiketi ölçüdə təcrübə edir. Bizim yenilənmək öyrənmə modeli (Polite-RL) nümunə çəkilmiş cavabının mükafatlarına proporcional mükafatları verməklə kiçik nəsilləri təşkil edir. Biz həmçinin iki alınmış, kibarlı dialoglı modelləri təsdiqləyirik. İnsan değerlendirməsi təsdiqləyir ki, Fusion və alış-veriş modelləri daha zəif kontekst-bağlılığıyla yaxşılıq edərkən, LFT və Polite-RL modelləri dialog keyfiyyətini qurbanlıq etmədən çox kiçik cavab verə bilərlər.</abstract_az>
      <abstract_fi>Tyylistinen dialogivasteen luominen arvokkailla sovelluksilla persoonallisuusperusteisiin keskusteluagentteihin on haastava tehtävä, koska vastauksen on oltava sujuva, kontekstuaalisesti relevantti ja paralingvistisesti tarkka. Lisäksi rinnakkaisia tietokokonaisuuksia säännöllisistä tyylipareista ei yleensä ole saatavilla. Esitämme kolme heikosti valvottua mallia, jotka voivat tuottaa erilaisia, kohteliaita (tai töykeitä) dialogivastauksia ilman rinnakkaista dataa. Myöhäisen fuusion mallimme (Fusion) yhdistää koodaaja-huomio-dekooderin dialogimallin dekooderin itsenäiseen kohteliaisuuteen koulutettuun kielimalliin. Label-fine tuning (LFT) -mallimme edeltää kuhunkin lähdesarjaan kohteliaisuuspisteiden skaalautuvan etiketin (jonka ennustaa huipputekninen kohteliaisuusluokitus) harjoittelun aikana, ja testin aikana pystyy luomaan kohteliaita, neutraaleja ja töykeitä vastauksia yksinkertaisesti skaalaamalla etiketin upottamista vastaavan pistemäärän mukaan. Vahvistusoppimismallimme (Polite-RL) kannustaa kohteliaisuuden syntymiseen antamalla palkinnot, jotka ovat verrannollisia näytteenotetun vasteen kohteliaisuusluokituksen pistemäärään. Esittelemme myös kaksi palautettua, kohteliasta dialogimallia. Ihmisten arviointi vahvistaa, että vaikka fuusio- ja hakupohjaiset mallit saavuttavat kohteliaisuutta, jolla on huonompi asiayhteys, LFT- ja Polite-RL-mallit voivat tuottaa huomattavasti kohteliampia vastauksia uhraamatta vuoropuhelun laatua.</abstract_fi>
      <abstract_ca>La generació de respostes al diàleg estilistic, amb aplicacions valioses en agents de conversació basats en la personalitat, és una tasca desafiadora perquè la resposta ha de ser fluida, contextualment rellevant i paralinguísticament exacta. A més, els conjunts de dades parallels per parelles regulars a estilistiques normalment no són disponibles. Presentam tres models de supervisió dèbil que poden generar respostes de diàleg diverses, educades (o rudes) sense dades paralleles. El nostre model de fusió tardia (Fusion) fusion a el decodificador d'un model de diàleg codificador-atenció-decodificador amb un model lingüístic entrenat en expressions soles i polites. El nostre model de finetzació de l'etiqueta (LFT) prepara a cada seqüència de font una etiqueta escalada de puntuació de politesa (predida pel nostre classificador de politesa d'última generació) durant l'entrenament, i al moment de la prova és capaç de generar respostes educades, neutrals i rudes simplement escalant l'etiqueta incorporada amb la puntuació correspondent. Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response.  També presentem dues línies de base basades en un model de diàleg educat. L'evaluació humana valida que, mentre que la fusió i els models basats en la recuperació aconsegueixen politesa amb menys relevància contextual, els models LFT i Polite-RL poden produir respostes molt més polites sense sacrificar la qualitat del diàleg.</abstract_ca>
      <abstract_cs>Generování stylových dialogových reakcí s cennými aplikacemi v komunikačních agentech založených na osobnosti je náročným úkolem, protože odpověď musí být plynulá, kontextově relevantní a paralingvisticky přesná. Navíc paralelní datové sady pro pravidelné až stylistické páry nejsou obvykle k dispozici. Představujeme tři slabě dohlížené modely, které mohou generovat různorodé, zdvořilé (nebo hrubé) dialogové reakce bez paralelních dat. Náš model pozdní fúze (Fusion) spojuje dekód dialogového modelu kodér-pozornost-dekód s jazykovým modelem trénovaným na samostatných zdvořilých výrokech. Náš model pro jemné ladění etiket (LFT) předchází každé zdrojové sekvenci škálovaný štítek (předpověděný naším nejmodernějším klasifikátorem zdvořilosti) během tréninku a v době testu je schopen generovat zdvořilé, neutrální a hrubé odpovědi jednoduchým škálováním vložení etiket o odpovídající skóre. Náš model posílení učení (Polite-RL) podporuje generování zdvořilosti tím, že přiřazuje odměny úměrné skóre klasifikátoru zdvořilosti vzorkované odpovědi. Dále představujeme dvě základní základní linie založené na retrievalování, zdvořilého dialogu. Lidské hodnocení potvrzuje, že zatímco modely Fusion a modely založené na retrievalu dosahují zdvořilosti s nižší kontextovou relevancí, modely LFT a Polite-RL mohou vytvářet výrazně zdvořilější reakce bez oběti kvality dialogu.</abstract_cs>
      <abstract_et>Stiilne dialoogi reageerimine koos väärtuslike rakendustega isikupõhistes vestlusagentides on keeruline ülesanne, sest reageerimine peab olema sujuv, kontekstipõhiselt asjakohane ja paralingvistiliselt täpne. Lisaks on tavaliselt kättesaadavad paralleelsed andmekogumid tavaliselt tavaliselt tavaliselt saadaval. Esitleme kolm nõrgalt kontrollitud mudelit, mis võivad luua mitmekesiseid, viisakaid (või ebaviisakaid) dialoogivastuseid ilma paralleelsete andmeteta. Meie hilise fusiooni mudel (Fusion) ühendab kodeerija-tähelepanu-dekooderi dialoogimudeli dekooderi keelemudeliga, mis on koolitatud iseseisvatele viisakatele väljendustele. Meie label-fine tuning (LFT) mudel eelistab igale lähtejärjestusele viisakuse-skoori skaleeritud sildi (ennustab meie kaasaegse viisakuse klassifikaator) treeningu ajal ja testimise ajal suudab luua viisakaid, neutraalseid ja ebaviisakaid vastuseid lihtsalt skaleerides sildi manustamist vastava skoori järgi. Meie tugevdamise õppemudel (Polite-RL) julgustab viisakuse tekitamist, määrates tasusid proportsionaalselt valimisse võetud vastuse viisakuse klassifitseerija skooriga. Samuti tutvustame kahte tagasivõetud viisaka dialoogi mudelit. Inimhinnang kinnitab, et kuigi Fusion ja tagasivõtmisel põhinevad mudelid saavutavad viisakuse, millel on vähem konteksti asjakohane tähtsus, võivad LFT ja Polite-RL mudelid anda oluliselt viisakamaid vastuseid ilma dialoogi kvaliteeti ohverdamata.</abstract_et>
      <abstract_jv>Generasi dialog jalakno stylistik, nganggo aplikasi sing wis nggawe nang artisane conversatif sing basa gambar n'uwong, kuwi nggunakake sing kudu nggawe balesan tambah akèh, tambah-akèh lan tambah-akèh lanjut. Label Awak dhéwé éntuk telu model sing gawe nguasai-perbudhakan sing bisa ngelarang langgar sampek, polite (atawa gawan karo paké) dialog alamat sane data yang dipolel. Kita pernik-pernik model (F) Kita label-Finetuning Clear politenessoffpolite"), and when there is a change ("assertive Ndheke kuwi nggunakake sing paling-urip kuwi masalah iki banjur kelangan kelangan iki bakal sing nyimpen politeness karo perusahaan kontèks-kowarno sing luwih apik, model Lft karo polite-RL sing iso dianggawe barang langkung polite iso dianggawe barang langkung wigatining ketahanan ora bisa dianggap perusahaan dialoog.</abstract_jv>
      <abstract_sk>Ustvarjanje odzivov na stilski dialog z dragocenimi aplikacijami v osebnostnih pogovornih agentih je zahtevna naloga, saj mora biti odziv tekoč, kontekstualno ustrezen in paralingvistično natančen. Poleg tega vzporedni nabori podatkov za redne do stilske pare običajno niso na voljo. Predstavljamo tri šibko nadzorovane modele, ki lahko brez vzporednih podatkov ustvarijo raznolike, vljudne (ali nevljudne) dialogske odzive. Naš model pozne fuzije (Fusion) združuje dekodirni model dialoga kodirnik-pozornost-dekodirnik z jezikovnim modelom, usposobljenim za samostojne vljudne izgovore. Naš model za fine tuning oznak (LFT) predstavlja vsakemu zaporedju vira nalepko z lestvico vljudnosti-ocene (ki jo napoveduje naš najsodobnejši klasifikator vljudnosti) med treningom, v času testiranja pa lahko ustvari vljudne, nevtralne in nevljudne odzive s preprosto lestvijo nalepke z ustrezno oceno. Naš model učenja za ojačanje (Polite-RL) spodbuja ustvarjanje vljudnosti z dodeljevanjem nagrad sorazmernih z oceno klasifikatorja vljudnosti vzorčenega odziva. Predstavljamo tudi dve osnovni liniji vljudnega dialoga. Človeška ocena potrjuje, da medtem ko modeli, ki temeljijo na fuziji in pridobivanju, dosegajo vljudnost z manjšo kontekstno relevantnostjo, lahko modeli LFT in Polite-RL ustvarijo bistveno bolj vljudne odzive, ne da bi žrtvovali kakovost dialoga.</abstract_sk>
      <abstract_ha>Kijan mai karɓar zauren akwatin bayani na Stylisti, da shiryoyin ayuka masu inganci cikin masu shiryuwa masu basara a kanana, yana da wani aiki mai walau, kwani ana ƙayyade a matsayin su zama masu buƙata, da masu da muhimmi, kuma da ƙayyade fasalin linguistic. Da haka, tsarin data masu daidaita wa nau'i-nau'in-rubutu ko daidai ba za'a iya ba. Tuna halatar da misãlai uku wanda aka tsare masu rauni, waɗanda ke iya iya ƙiƙiro majibu dabam-dabam, masu nau'i (ko rude) cikin zauren akwatin bayani masu basu'a da tsari. @ info: whatsthis @ label Ana ƙarfafa misali da karantawa (Police-RL) yana ƙaramar wa kizafi masu tsari da kuma ya raba sakamakon da ke sami'a mai kyau. Tuna halatar da misalin zauren zauren akwatin bayani biyu da aka samu. Tilurin mutum na gaskata cewa, a lokacin da Fusion da misãlai masu motsi da ake samu'a, sai misãlai na LFT da Police-RL za'a sami marubuci mai girma kuma ba da tsarin zauren zauren akwatin bayani.</abstract_ha>
      <abstract_bo>རྣམ་པ་གླེང་སྒྲོམ་གྱི་དཔེ་དབུས་མཐུན་སླབ་དང་མིན་འདུག ཡིན་ཡང་། རྒྱུན་ལྡན་དང་བཟོ་རྣམ་གྲངས་ཀྱི་གནད་སྡུད་གཞི་སྒྲིག་ཚུ་སྤྱིར་བཏང་མི་བྱེད་པ ང་ཚོས་རང་ཉིད་ཀྱི་རྣམ་པ་ལྟ་བུའི་མིག་དབུགས་གསུམ་ཀྱི་དཔེ་དབུགས་སྐྱེས་བ་ཡིན་པ་དེ་གིས་སྣུམ་དང་གནད་མེད་པའི་དབུ Our late fusion model (Fusion) merges the decoder of an encoder-attention-decoder dialog model with a language model trained on stand-alone polite utterances. Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score. Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response. ང་ཚོས་ཀློག་འཇུག་བྱེད་པའི་རྣམ་གྲངས་གཉིས་ཀྱང་སྔོན་སྒྲིག Human evaluation validates that while the Fusion and the retrieval-based models achieve politeness with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialog quality.</abstract_bo>
      <abstract_he>Stylistic dialogue response generation, with valuable applications in personality-based conversational agents, is a challenging task because the response needs to be fluent, contextually-relevant, as well as paralinguistically accurate.  חוץ מזה, קבוצות נתונים מקבילות לזוגים רגילים לסטיליסטיים בדרך כלל לא זמינות. אנחנו מציגים שלושה דוגמנים מפקחים חלשים שיכולים ליצור תגובות דיאלוג מגוונות, מנומסות (או גס רוח) ללא נתונים מקבילים. מודל התמזגות המאוחר שלנו (Fusion) מארגן את המתקן של מודל דיאלוג קודר-תשומת לב-קודר עם מודל שפה מאומן על מילים מנומסים לבד. מודל התיקון התווית שלנו (LFT) מכין לכל רצף מקור תווית מנומסת-נקודת מסודרת (צפוי על ידי מסגר הנומסת המדינה שלנו) במהלך האימונים, ובזמן הבדיקה הוא מסוגל ליצור תגובות מנומסות, נוטרליות וגוסות על ידי פשוט לסקול את התווית המתוקפת על ידי נקודת המתאימה. מודל הלימודים של התגבורה שלנו (Polite-RL) מעודד את דור הנדיבות על ידי להעניק פרס פרופורציונלי לקליסס הנדיבות של התגובה הנבחרת. אנחנו גם מציגים שני קווי בסיס דוגמני דיאלוג מנומסים ומבוססים. Human evaluation validates that while the Fusion and the retrieval-based models achieve politeness with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialogue quality.</abstract_he>
      </paper>
    <paper id="29">
      <title>Learning to Remember Translation History with a Continuous Cache</title>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <author id="yang-liu-ict"><first>Yang</first><last>Liu</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <author><first>Tong</first><last>Zhang</last></author>
      <doi>10.1162/tacl_a_00029</doi>
      <abstract>Existing neural machine translation (NMT) models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history. The <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> over generated words is updated online depending on the translation history retrieved from the <a href="https://en.wikipedia.org/wiki/Computer_memory">memory</a>, endowing NMT models with the capability to dynamically adapt over time. Experiments on multiple domains with different topics and styles show the effectiveness of the proposed approach with negligible impact on the <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a>.</abstract>
      <pages>407–420</pages>
      <url hash="ed1d96f4">Q18-1029</url>
      <bibkey>tu-etal-2018-learning</bibkey>
      <pwccode url="https://github.com/longyuewangdcu/tvsub" additional="false">longyuewangdcu/tvsub</pwccode>
    <title_ar>تعلم تذكر تاريخ الترجمة باستخدام ذاكرة تخزين مؤقت مستمرة</title_ar>
      <title_fr>Apprendre à se souvenir de l'historique des traductions avec un cache continu</title_fr>
      <title_pt>Aprendendo a lembrar a história da tradução com um cache contínuo</title_pt>
      <title_es>Aprender a recordar el historial de traducciones con un caché continuo</title_es>
      <title_ja>継続的なキャッシュで翻訳履歴を記憶することを学ぶ</title_ja>
      <title_hi>एक निरंतर कैश के साथ अनुवाद इतिहास याद करने के लिए सीखना</title_hi>
      <title_zh>学连缓存记译历史记录</title_zh>
      <title_ru>Учимся запоминать историю перевода с помощью непрерывного кэша</title_ru>
      <title_ga>Foghlaim conas Stair an Aistriúcháin a Chuimhniú le Taisce Leanúnach</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>A fordítási előzmények megjegyzése folyamatos gyorsítótárral</title_hu>
      <title_el>Μάθετε να θυμάστε το ιστορικό μετάφρασης με μια συνεχή μνήμη μνήμης</title_el>
      <title_it>Imparare a ricordare la cronologia delle traduzioni con una cache continua</title_it>
      <title_lt>Mokymasis prisiminti vertimo istoriją su nuolatine cache</title_lt>
      <title_kk>Жалғастыру кэшімен аудармалардың журналын еске салу</title_kk>
      <title_mk>Научи да се сеќаваш на историјата на преводот со континуиран кеш</title_mk>
      <title_ms>Belajar untuk Ingat Sejarah Terjemahan dengan Cache Terus</title_ms>
      <title_ml>നിലനില്‍ക്കുന്ന കാഷുമായി പരിഭാഷകങ്ങളുടെ ചരിത്രം ഓര്‍മ്മിക്കാന്‍ പഠിക്കുന്നു</title_ml>
      <title_mt>Tagħlim biex tiftakar l-Istorja tat-Traduzzjoni b’Cache Kontinwu</title_mt>
      <title_mn>Түүхийг үргэлжлүүлэх кэштэй түүхийг санаж сурах нь</title_mn>
      <title_no>Læring å huska omsetjingsgistorien med ein kontinuerleg mellomlager</title_no>
      <title_pl>Nauka się pamiętać historię tłumaczeń za pomocą ciągłej pamięci podręcznej</title_pl>
      <title_sr>Naučenje da se seća š istorije prevoda sa kontinualnim kavezom</title_sr>
      <title_ro>Învățarea de a reține istoricul traducerilor cu un cache continuu</title_ro>
      <title_si>Name</title_si>
      <title_so>Waxbarashada inaad xusuusatid taariikhda turjumista</title_so>
      <title_sv>Lär dig att komma ihåg översättningshistorik med en kontinuerlig cache</title_sv>
      <title_ta>மொழிபெயர்ப்பு வரலாற்றை நினைவு கொள்ள கற்றுக் கொண்டு</title_ta>
      <title_ur>ترجمہ تاریخ کو یاد رکھنے کی سیکھ رہی ہے ایک قائم کیچ کے ساتھ</title_ur>
      <title_uz>Tarjima tarixini davom etishni istaysizmi?</title_uz>
      <title_vi>Học cách nhớ lại lịch sử dịch với một bộ nhớ liên tục</title_vi>
      <title_bg>Научете се да запомняте историята на преводите с непрекъснато кеш</title_bg>
      <title_da>Lære at huske oversættelseshistorik med en kontinuerlig cache</title_da>
      <title_nl>Vertalingsgeschiedenis leren onthouden met een continue cache</title_nl>
      <title_hr>Naučenje zapamtiti povijest prevoda sa kontinualnim kavetom</title_hr>
      <title_id>Belajar mengingat Sejarah Terjemahan dengan Cache Terus</title_id>
      <title_ko>연속 캐시로 번역 역사를 기억하는 것을 배우다</title_ko>
      <title_de>Lernen, sich mit einem kontinuierlichen Cache an den Übersetzungsverlauf zu erinnern</title_de>
      <title_fa>یاد گرفتن تاریخ ترجمه را به یاد داشتن با یک ذخیره دائمی</title_fa>
      <title_sw>Learning to Remember Translation History with a Continuous Cache</title_sw>
      <title_af>Name</title_af>
      <title_sq>Mësoni të mbani mend historinë e përkthimit me një cache të vazhdueshme</title_sq>
      <title_tr>Terjime geçmişi daýatmak üçin öwrenmek üçin öwrenmek</title_tr>
      <title_am>Learning to Remember Translation History with a Continuous Cache</title_am>
      <title_hy>Հիշել թարգմանման պատմությունը անընդհատ աղյուսակի միջոցով</title_hy>
      <title_bn>Learning to Remember Translation History with a Continuous Cache</title_bn>
      <title_az>Tərcümə keçmişini yada salmaq öyrənmək</title_az>
      <title_bs>Naučenje zapamtiti povijest prevoda sa kontinualnim kavezom</title_bs>
      <title_ca>Aprendre a recordar la història de la traduccióamb una caché continua</title_ca>
      <title_et>Tõlkeajaloo mälestamise õppimine pideva vahemäluga</title_et>
      <title_fi>Oppiminen muistamaan käännöshistoriaa jatkuvalla välimuistilla</title_fi>
      <title_cs>Naučit se zapamatovat si historii překladů s nepřetržitou mezipamětí</title_cs>
      <title_jv>Jejaring</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Naučite se zapomniti zgodovino prevodov z neprekinjenim predpomnilnikom</title_sk>
      <title_he>ללמוד לזכור היסטוריה של התרגום עם עוגה ממשיכה</title_he>
      <title_bo>རྒྱུན་ཆད་མེད་པའི་ཡིག་རྒྱུན་ལོ་རྒྱུས་ལ་དམིགས་འཇུག་བྱེད་དགོས་པ</title_bo>
      <abstract_ar>تعمل نماذج الترجمة الآلية العصبية الحالية (NMT) بشكل عام على ترجمة الجمل بمعزل عن غيرها ، مما يفقد فرصة الاستفادة من المعلومات على مستوى المستند. في هذا العمل ، نقترح زيادة نماذج NMT بشبكة ذاكرة خفيفة الوزن جدًا تشبه ذاكرة التخزين المؤقت ، والتي تخزن التمثيلات المخفية الحديثة كتاريخ ترجمة. يتم تحديث توزيع الاحتمالية على الكلمات التي تم إنشاؤها عبر الإنترنت اعتمادًا على سجل الترجمة المسترجع من الذاكرة ، مما يمنح نماذج NMT القدرة على التكيف ديناميكيًا بمرور الوقت. التجارب على مجالات متعددة مع مواضيع وأنماط مختلفة تظهر فعالية النهج المقترح مع تأثير ضئيل على التكلفة الحسابية.</abstract_ar>
      <abstract_pt>Os modelos de tradução automática neural (NMT) existentes geralmente traduzem frases isoladamente, perdendo a oportunidade de aproveitar as informações no nível do documento. Neste trabalho, propomos aumentar os modelos NMT com uma rede de memória tipo cache muito leve, que armazena representações ocultas recentes como histórico de tradução. A distribuição de probabilidade sobre as palavras geradas é atualizada online dependendo do histórico de tradução recuperado da memória, dotando os modelos NMT com a capacidade de se adaptar dinamicamente ao longo do tempo. Experimentos em vários domínios com diferentes tópicos e estilos mostram a eficácia da abordagem proposta com impacto insignificante no custo computacional.</abstract_pt>
      <abstract_es>Los modelos de traducción automática neuronal (NMT) existentes generalmente traducen oraciones de forma aislada y pierden la oportunidad de aprovechar la información a nivel de documento. En este trabajo, proponemos aumentar los modelos NMT con una red de memoria similar a la caché muy liviana, que almacena representaciones ocultas recientes como historial de traducción. La distribución de probabilidad entre las palabras generadas se actualiza en línea en función del historial de traducción recuperado de la memoria, lo que dota a los modelos NMT de la capacidad de adaptarse dinámicamente a lo largo del tiempo. Los experimentos en múltiples dominios con diferentes temas y estilos muestran la eficacia del enfoque propuesto con un impacto insignificante en el costo computacional.</abstract_es>
      <abstract_fr>Les modèles de traduction automatique neuronale (NMT) existants traduisent généralement les phrases de manière isolée, ce qui laisse passer l'occasion de tirer parti des informations au niveau du document. Dans ce travail, nous proposons d'augmenter les modèles NMT avec un réseau de mémoire cache très léger, qui stocke les représentations cachées récentes sous forme d'historique de traduction. La distribution de probabilité sur les mots générés est mise à jour en ligne en fonction de l'historique de traduction extrait de la mémoire, ce qui permet aux modèles NMT de s'adapter dynamiquement au fil du temps. Des expériences sur de multiples domaines avec des sujets et des styles différents montrent l'efficacité de l'approche proposée avec un impact négligeable sur le coût de calcul.</abstract_fr>
      <abstract_ja>既存のニューラル機械翻訳（ NMT ）モデルは、一般に、文書レベルの情報を利用する機会を逃して、文章を分離的に翻訳する。この作業では、NMTモデルを非常に軽量なキャッシュのようなメモリネットワークで拡張することを提案します。これは、最近の隠された表現を翻訳履歴として格納します。生成された単語に対する確率分布は、メモリから取得された翻訳履歴に応じてオンラインで更新され、時間の経過とともに動的に適応する能力をNMTモデルに付与する。異なるトピックとスタイルを持つ複数のドメインでの実験は、計算コストに軽微な影響を与える提案されたアプローチの有効性を示しています。</abstract_ja>
      <abstract_hi>मौजूदा तंत्रिका मशीन अनुवाद (एनएमटी) मॉडल आम तौर पर अलगाव में वाक्यों का अनुवाद करते हैं, जो दस्तावेज़-स्तर की जानकारी का लाभ उठाने का अवसर खो देते हैं। इस काम में, हम एक बहुत ही हल्के वजन कैश-जैसे मेमोरी नेटवर्क के साथ एनएमटी मॉडल को बढ़ाने का प्रस्ताव करते हैं, जो हाल ही में छिपे हुए प्रतिनिधित्व को अनुवाद इतिहास के रूप में संग्रहीत करता है। उत्पन्न शब्दों पर संभावना वितरण को स्मृति से पुनर्प्राप्त अनुवाद इतिहास के आधार पर ऑनलाइन अपडेट किया जाता है, जो समय के साथ गतिशील रूप से अनुकूलित करने की क्षमता के साथ एनएमटी मॉडल को समाप्त करता है। विभिन्न विषयों और शैलियों के साथ कई डोमेन पर प्रयोग कम्प्यूटेशनल लागत पर नगण्य प्रभाव के साथ प्रस्तावित दृष्टिकोण की प्रभावशीलता दिखाते हैं।</abstract_hi>
      <abstract_ru>Существующие модели нейронного машинного перевода (НМП) обычно переводят предложения изолированно, упуская возможность воспользоваться информацией на уровне документа. В этой работе мы предлагаем дополнить модели NMT очень легкой кэш-подобной сетью памяти, которая хранит недавние скрытые представления как историю перевода. Распределение вероятности по сгенерированным словам обновляется онлайн в зависимости от истории перевода, извлеченной из памяти, наделяя модели NMT способностью динамически адаптироваться с течением времени. Эксперименты по нескольким областям с различными темами и стилями показывают эффективность предлагаемого подхода с незначительным влиянием на вычислительную стоимость.</abstract_ru>
      <abstract_zh>今神经机器翻译(NMT)模常孤立译句,误乘文档级信息。 于是建议用非常轻量级类缓存之内存网络以强NMT形,宜网络以近藏为译历史记录。 检内存之译历史记录,成单词之概率分布在线新,使 NMT 随时而调。 多方实验明,有效性计算成本可忽略不计。</abstract_zh>
      <abstract_ga>Is gnách go n-aistríonn samhlacha néar-aistriúcháin meaisín (NMT) atá ann cheana abairtí ina n-aonar, rud a chailleann an deis leas a bhaint as faisnéis ar leibhéal doiciméad. Sa obair seo, tá sé beartaithe againn samhlacha NMT a mhéadú le líonra cuimhne an-éadrom cosúil le taisce, a stórálann léirithe ceilte le déanaí mar stair aistriúcháin. Déantar dáileadh na dóchúlachta thar fhocail ghinte a nuashonrú ar líne ag brath ar stair an aistriúcháin a fuarthas ón gcuimhne, rud a thugann an cumas do mhúnlaí NMT oiriúnú go dinimiciúil le himeacht ama. Léiríonn turgnaimh ar réimsí iolracha a bhfuil topaicí agus stíleanna éagsúla acu éifeachtacht an chur chuige atá beartaithe agus is beag an tionchar atá acu ar an gcostas ríomhaireachtúil.</abstract_ga>
      <abstract_el>Τα υπάρχοντα μοντέλα νευρολογικής μηχανικής μετάφρασης (NMT) γενικά μεταφράζουν προτάσεις μεμονωμένα, χάνοντας την ευκαιρία να επωφεληθούν από πληροφορίες σε επίπεδο εγγράφου. Στην εργασία αυτή, προτείνουμε να ενισχυθούν τα μοντέλα με ένα πολύ ελαφρύ δίκτυο μνήμης, το οποίο αποθηκεύει πρόσφατες κρυφές αναπαραστάσεις ως ιστορικό μετάφρασης. Η κατανομή πιθανοτήτων επί των παραγόμενων λέξεων ενημερώνεται σε απευθείας σύνδεση ανάλογα με το ιστορικό μετάφρασης που ανακτάται από τη μνήμη, παρέχοντας στα μοντέλα τη δυνατότητα δυναμικής προσαρμογής με την πάροδο του χρόνου. Τα πειράματα σε πολλαπλούς τομείς με διαφορετικά θέματα και στυλ δείχνουν την αποτελεσματικότητα της προτεινόμενης προσέγγισης με αμελητέα επίπτωση στο υπολογιστικό κόστος.</abstract_el>
      <abstract_it>I modelli esistenti di traduzione automatica neurale (NMT) generalmente traducono frasi in modo isolato, perdendo l'opportunità di sfruttare le informazioni a livello di documento. In questo lavoro, proponiamo di aumentare i modelli NMT con una rete di memoria cache molto leggera, che memorizza le recenti rappresentazioni nascoste come cronologia delle traduzioni. La distribuzione delle probabilità sulle parole generate viene aggiornata online a seconda della cronologia delle traduzioni recuperata dalla memoria, dotando i modelli NMT della capacità di adattarsi dinamicamente nel tempo. Esperimenti su più domini con argomenti e stili diversi mostrano l'efficacia dell'approccio proposto con un impatto trascurabile sul costo computazionale.</abstract_it>
      <abstract_ka>არსებობს ნეიროლური მანქანის გაგრძელება (NMT) მოდელები საერთოდ იზოლაციაში გაგრძელება, რომლებიც დოკუმენტის დოკუმენტის ინფორმაციის გამოსახულება არ ამ სამუშაოში, ჩვენ მინდა NMT მოდელების გაზრდილობა, რომლებიც ძალიან მარტივი ფექსის სიმბოლოებით, რომლებიც ახლა შემდეგ დახმარებული გამოსახულებების ისტორია. შესაძლებლობა გაყოფილი სიტყვების შესაძლებლობა იქნება ინტერნეტის ახალგაზრულება, რომელიც შესაძლებელია ჩატვირთვა ისტორიაზე, რომელიც ჩატვირთვადან მიღებულია, რომელიც N ექსპერიმენტები განსხვავებული ტემებით და სტილისთვის განსხვავებული პროგრამის ეფექტიურობა, რომელიც კომპიუტაციალური ღირებულების შესაძლებლობად გააჩვენება.</abstract_ka>
      <abstract_kk>Бар невралдық компьютердің аударуы (NMT) үлгілері кәдімгі сөздерді өзгертіп, құжат деңгейіндегі мәліметті ашу мүмкіндігін жоқ. Бұл жұмыс ішінде, NMT үлгілерін өте жатты кэш сияқты жады желімен көбейту үшін қолданамыз. Бұл жаңа жасырын көрсеткілерді аудару тарыхы ретінде сақтайды. Жасалған сөздер үшін маңыздылық үлестірімі онлайн арқылы жаңарту журналы жадынан алынған аудармалардың журналына тәуелді, NMT үлгілерін уақытта динамикалық адаптациялау мүмкіндігімен Бірнеше доменге әртүрлі тақырыптар мен стильдер туралы тәжірибелер санаттық бағаттарына тәжірибесін көрсетеді.</abstract_kk>
      <abstract_lt>Esami nervinių mašin ų vertimo (NMT) modeliai paprastai verta sakinius atskirai, todėl trūksta galimybės pasinaudoti dokumentų lygmens informacija. Šiame darbe siūlome papildyti NMT modelius labai lengvu, į cache panašiu atminties tinklu, kuriame kaip vertimo istoriją saugomi neseniai paslėpti paveikslai. Galimybės pasiskirstymas per sukurtus žodžius atnaujinamas internete, atsižvelgiant į vertimo istoriją, gautą iš atminties, suteikiant NMT modeliams galimybę laikui bėgant dinamiškai prisitaikyti. Eksperimentai įvairiose srityse su skirtingomis temomis ir stiliais rodo siūlomo metodo veiksmingumą, turintį nedidelį poveikį skaičiavimo sąnaudoms.</abstract_lt>
      <abstract_ml>നിലവിലുള്ള ന്യൂറല്‍ മെഷീന്‍ പരിഭാഷ (NMT) മോഡലുകള്‍ പൊതുവായി വാക്കുകള്‍ ഒറ്റയ്ക്കില്‍ ഉപയോഗിക്കുന്നു. രേഖയുടെ നില വി ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ NMT മോഡലുകള്‍ കൂട്ടിച്ചേര്‍ക്കുവാന്‍ പ്രൊദ്ദേശിക്കുന്നു. വളരെ വെളുത്ത ഭാരം ക്യാഷ് പോലുള്ള മെമ സൃഷ്ടിക്കപ്പെട്ട വാക്കുകള്‍ക്ക് മേല്‍ വിതരണം ലഭ്യമാക്കുന്നതിനുള്ള സാധ്യതയാണ് ഓണ്‍ലൈനില്‍ നിന്നും പരിഭാഷകങ്ങളുടെ ചരിത്രം പുതുക്കം  വ്യത്യസ്ത പ്രമേയങ്ങളും ശൈലികളുമുള്ള പല ഡൊമെയിനുകളിലുള്ള പരീക്ഷണങ്ങള്‍ കാണിക്കുന്നു പ്രൊദ്ദേശിക്കപ്പെട്ട പ്രായോഗ്</abstract_ml>
      <abstract_mk>Постојаните модели за превод на невровни машини (НМТ) генерално преводат реченици во изолација, пропуштајќи ја можноста да се искористат информациите на ниво на документ. Во оваа работа предлагаме да ги зголемиме моделите на НМТ со многу лесна мемориска мрежа слична на кеш, која ги чува неодамнешните скриени претставувања како историја на превод. Веројатноста на дистрибуцијата над генерираните зборови се онлајн се онлајн во зависност од историјата на преводот што се добива од меморијата, давајќи им на моделите НМТ способност да се адаптираат динамично со текот на времето. Експериментите на повеќе домени со различни теми и стили ја покажуваат ефикасноста на предложениот пристап со незначително влијание врз пресметките трошоци.</abstract_mk>
      <abstract_ms>Model terjemahan mesin saraf (NMT) yang wujud secara umum terjemahan kalimat dalam pengasingan, hilang peluang untuk mengambil keuntungan maklumat aras dokumen. Dalam kerja ini, kami cadangkan untuk menambah model NMT dengan rangkaian memori yang sangat ringan seperti cache, yang menyimpan perwakilan tersembunyi baru-baru ini sebagai sejarah terjemahan. Penghapusan kemungkinan atas perkataan yang dijana dikemaskini secara online bergantung pada sejarah terjemahan yang dicapai dari memori, memberikan model NMT dengan kemampuan untuk menyesuaikan secara dinamik pada masa. Eksperimen pada domain berbilang dengan topik dan gaya yang berbeza menunjukkan keefektivitas pendekatan yang diusulkan dengan kesan yang tidak terkira pada kos pengiraan.</abstract_ms>
      <abstract_mn>Ингээд оршиж байгаа мэдрэлийн машины хөгжлийн загварууд баримт түвшинд мэдээллийг ашиглах боломжгүй болдог. Энэ ажлын хувьд бид NMT загваруудыг маш хялбар хэмжээтэй дурсамж шиг хэлбэрээр нэмэгдүүлэхийг сануулж байна. Энэ нь саяхан нуугдсан үзүүлэлтийг орчуулах түүхийн хувьд хадгалдаг. Бүтээгдсэн үгнүүдийн магадлал хуваарилалт нь онлайн хуваариллага нь санамжтаас авсан орнуудын түүхийн хамааралтай, NMT загварыг цаг хугацааны хугацаанд өөрчлөх боломжтой болгож өгдөг. Бидний олон сүлжээний туршилт олон сэдэв болон стиль дээр тооцоололтын үнэтэй тэнцүү нөлөөтэй байдаг.</abstract_mn>
      <abstract_no>Eksiste modeller for omsetjing av neuralmaskin (NMT) gjennomfører setningar i isolation, manglar det muligheten til å bruka nyttighet av informasjon om dokumentnivået. I denne arbeida foreslår vi å auka NMT- modeller med eit veldig lys mellomlageret som lys mellomlageret, som lagrar nyleg gøymde representasjonar som oversettelsistorie. Sannsynlighetsferdelingen over genererte ord er oppdatert på nettverk avhengig av omsetjingssistorien henta frå minnet, og tilbyr NMT-modeller med kapasiteten for å dynamisk tilpassa over tid. Eksperimentar på fleire domene med ulike emne og stil viser effektiviteten av den foreslåde tilnærminga med alvorleg effekt på datakostnaden.</abstract_no>
      <abstract_ro>Modelele existente de traducere automată neurală (NMT) traduc în general propozițiile în mod izolat, lipsind posibilitatea de a profita de informațiile la nivel de document. În această lucrare, propunem extinderea modelelor NMT cu o rețea de memorie cache foarte ușoară, care stochează reprezentările ascunse recente ca istoric de traduceri. Distribuția probabilității peste cuvintele generate este actualizată online în funcție de istoricul traducerilor recuperat din memorie, dotând modelele NMT cu capacitatea de a se adapta dinamic în timp. Experimentele pe mai multe domenii cu subiecte și stiluri diferite arată eficacitatea abordării propuse cu impact neglijabil asupra costului de calcul.</abstract_ro>
      <abstract_pl>Istniejące modele neuronowego tłumaczenia maszynowego (NMT) zwykle tłumaczą zdania w izolacji, brakując możliwości wykorzystania informacji na poziomie dokumentu. W niniejszej pracy proponujemy rozszerzenie modeli NMT o bardzo lekką sieć pamięci podobną do pamięci cache, która przechowuje ostatnie ukryte reprezentacje jako historię tłumaczeń. Rozkład prawdopodobieństwa na generowane słowa jest aktualizowany online w zależności od historii tłumaczeń pobieranej z pamięci, co daje modelom NMT możliwość dynamicznego dostosowywania się w czasie. Eksperymenty na wielu dziedzinach o różnych tematach i stylach pokazują skuteczność proponowanego podejścia przy nieistotnym wpływie na koszty obliczeniowe.</abstract_pl>
      <abstract_hu>A meglévő neurális gépi fordítási (NMT) modellek általában elszigetelten fordítják le a mondatokat, kihagyva a lehetőséget a dokumentum szintű információk kihasználására. Ebben a munkában azt javasoljuk, hogy az NMT modelleket nagyon könnyű gyorsítótárszerű memóriahálózattal bővítsük, amely a legutóbbi rejtett reprezentációkat fordítási előzményként tárolja. A generált szavak közötti valószínűségi eloszlás a memóriából visszanyert fordítási előzményektől függően frissül online, így az NMT modellek képesek dinamikusan alkalmazkodni idővel. Több területen végzett kísérletek különböző témákkal és stílusokkal mutatják be a javasolt megközelítés hatékonyságát, elhanyagolható hatással a számítási költségekre.</abstract_hu>
      <abstract_mt>Il-mudelli eżistenti tat-traduzzjoni tal-magni newrali (NMT) ġeneralment jittraduċu sentenzi iżolati, u jitilfu l-opportunità li jittieħed vantaġġ mill-informazzjoni fil-livell tad-dokument. F’dan ix-xogħol, qed nipproponu li jiżdiedu l-mudelli NMT b’netwerk ta’ memorja li jixbah lill-cache ħafif ħafna, li jaħżen rappreżentazzjonijiet moħbija reċenti bħala storja ta’ traduzzjoni. Id-distribuzzjoni tal-probabbiltà fuq kliem iġġenerat hija aġġornata onlajn skont l-istorja tat-traduzzjoni miksuba mill-memorja, u tagħti mudelli NMT il-kapaċità li jadattaw b’mod dinamiku maż-żmien. L-esperimenti fuq diversi oqsma b’suġġetti u stili differenti juru l-effettività tal-approċċ propost b’impatt negliġibbli fuq l-ispiża tal-komputazzjoni.</abstract_mt>
      <abstract_sv>Befintliga neurala maskin철vers채ttningsmodeller (NMT) 철vers채tter vanligtvis meningar isolerat och missar m철jligheten att dra nytta av information p책 dokumentniv책. I detta arbete f철resl책r vi att NMT-modeller ut철kas med ett mycket l채tt cachelaknande minnesn채tverk, som lagrar senaste dolda representationer som 철vers채ttningshistorik. Sannolikhetsf철rdelningen 철ver genererade ord uppdateras online beroende p책 철vers채ttningshistoriken h채mtad fr책n minnet, vilket ger NMT-modeller m철jlighet att dynamiskt anpassa sig 철ver tid. Experiment p책 flera dom채ner med olika 채mnen och stilar visar hur effektiv den f철reslagna metoden 채r med f철rsumbar inverkan p책 ber채kningskostnaderna.</abstract_sv>
      <abstract_si>ඉතින් න්‍යූරාල් යන්ත්‍ර පරිවර්තනය (NMT) මොඩල් සාමාන්‍ය විතරයෙන් වාක්ය භාවිත කරන්න, ලිපින්ත- තත්වය තොරතුරු  මේ වැඩේදී, අපි NMT මොඩේල් එක්ක ගොඩක් ලොකු බලාපොරොත්තු කැෂ් වගේ මතක ජාලයෙක් එක්ක වැඩ කරන්න පුළුවන් වෙනවා, ඒක අතින නිර්මාණය කරපු වචන වලින් වලින් විතරය අවසානය කරනවා, මතකයෙන් ලැබෙන අවසානය ඉතිහාසයෙන් අවශ්‍ය විතරයි, NMT මොඩේල් එක්ක වෙනස් විදියට සහ විදියට ප්‍රශ්නයක් තියෙන විදියට ප්‍රශ්නයක් පෙන්වන්න පුළුවන් විදියට ප්‍රශ්නයක් පෙන්ව</abstract_si>
      <abstract_sr>Postojeći modeli prevoda neuralnih mašina (NMT) obično prevode rečenice u izolaciji, nedostaju prilika da iskoriste informacije na nivou dokumenta. U ovom poslu predlažemo da povećamo NMT modele sa veoma laganom mrežom pamćenja poput kovčega, koja čuva nedavno skrivene predstave kao istorija prevoda. Verovatnoća distribucija nad proizvedenim riječima se aktualizuje na internetu u ovisnosti o povijesti prevođenja iz sećanja, koji podržava NMT modele sa mogućnostima da se dinamički prilagodi tijekom vremena. Eksperimenti o višestrukim domenama sa različitim temama i stilima pokazuju učinkovitost predloženog pristupa sa nezgodnim uticajem na računalne troškove.</abstract_sr>
      <abstract_so>Tusaalada qoraalka neural ee ku jira (NMT) waxay sida caadiga ah u turjumaan fursado si ay u isticmaalaan macluumaadka qoraalka. Markaas waxan shaqada, waxaynu soo jeedaynaa in aan ku kordhiyo noocyada NMT oo ay leedahay shabakadda xusuusta oo u eg shabakad aad u fudud, kaas oo ku wareegsan muuqashada qarsoon sida taariikhda turjumista. Sharciga suurtagalka ah oo ku qoran hadallada la soo dhashay waxaa lagu xiran yahay taariikhda turjumista ee xasuusta laga soo bandhigay, kaas oo sameynaya modellada NMT oo awoodda u bedelmi karo waqtiga dheer. Imtixaanka ku saabsan meelo kala duduwan oo ay ku jiraan maadooyinka iyo qaababka kala duduwan waxay tustaa saameyn ku saameyn la’aan kharashka xisaabinta.</abstract_so>
      <abstract_ur>Existing neural machine translation (NMT) models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. اس کام میں ہم NMT موڈل کو زیادہ ہلکا بوجھ کے مطابق ذکر نیٹورک کے ساتھ بڑھنے کے لئے پیشنهاد کرتے ہیں، جو اچھے چھپائے نمونے تاریخ کے طور پر چھپائے جاتے ہیں۔ پیدا کئے ہوئے کلمات پر احتمالات تقسیم آنلاین میں آدھیری جاتی ہے جو مترجم تاریخ سے حاصل کئے گئے ہیں، NMT موڈل کو زمانہ کے بارے میں دائمی طور پر اضافہ کرنے کے قابلیت کے ساتھ دیا جاتا ہے. مختلف موضوع اور استیلوں کے ساتھ بہت سی ڈومین کے تجربے کے ذریعے پیشنهاد کی طریقہ کے مثبت کو دکھاتے ہیں اور کمپیوٹریشن کے قیمت پر غیر اثر کے ساتھ۔</abstract_ur>
      <abstract_ta>இருக்கும் புதிய கணினி மொழிபெயர்ப்பு (NMT) மாதிரிகள் பொதுவாக மொழிகளை தனியாக மொழிபெயர்க்கவும், ஆவண- மட்டத்தின் தகவல் பயன்பாட் In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history.  @ info: whatsthis பல்வேறு தலைப்புகள் மற்றும் பாணிகள் உள்ள பல தளங்களில் சோதனைகள் கணிப்பொறி விலையில் எதிர்பாராத விளைவுகளுடன் பரிந்துரையுள்ள</abstract_ta>
      <abstract_uz>Name Bu ishda, biz NMT modellarini o'zgartirishni tahrirlash tarixi sifatida juda light-weight xotira tarmoq bilan qoʻshish talab qilamiz. Name Har xil mavzular va uslublar bilan bir nechta domen'ning imtiyozlari kompyuterning qiymatiga hech qanday effekti koʻrsatiladi.</abstract_uz>
      <abstract_vi>Các mô hình dịch máy thần kinh tồn tại (NMB) thông thường phiên bản cách biệt, mất cơ hội để lợi dụng thông tin cấp tài liệu. Trong công việc này, chúng tôi đề nghị nâng cao các mô hình NMT với một mạng lưới bộ nhớ tạm ít, mà lưu trữ các biểu tượng ẩn gần đây như là lịch sử dịch. Xác suất phân phối các từ đã tạo ra được cập nhật trực tuyến dựa vào lịch sử dịch được lấy ra từ bộ nhớ, cung cấp cho các mô hình NMT khả năng thích nghi theo thời gian. Thí nghiệm trên nhiều miền với các chủ đề và kiểu dáng khác nhau cho thấy hiệu quả của phương pháp được đề xuất với tác động ít ỏi lên về giá trị tính toán.</abstract_vi>
      <abstract_bg>Съществуващите модели на невронен машинен превод обикновено превеждат изречения изолирано, пропускайки възможността да се възползват от информацията на ниво документ. В тази работа предлагаме да се разширят моделите с много лека кеш-подобна паметна мрежа, която съхранява скорошни скрити изображения като история на преводите. Вероятното разпределение върху генерираните думи се актуализира онлайн в зависимост от историята на преводите, извлечена от паметта, като се дава възможност на моделите да се адаптират динамично с течение на времето. Експерименти в множество области с различни теми и стилове показват ефективността на предложения подход с незначително въздействие върху изчислителните разходи.</abstract_bg>
      <abstract_nl>Bestaande neurale machine translation (NMT) modellen vertalen zinnen over het algemeen geïsoleerd, waardoor de mogelijkheid wordt gemist om gebruik te maken van informatie op documentniveau. In dit werk stellen we voor om NMT modellen uit te breiden met een zeer lichtgewicht cache-achtig geheugennetwerk, dat recente verborgen representaties opslaat als vertaalgeschiedenis. De waarschijnlijkheidsverdeling over gegenereerde woorden wordt online bijgewerkt afhankelijk van de vertaalgeschiedenis die uit het geheugen wordt opgehaald, waardoor NMT-modellen in staat zijn zich dynamisch aan te passen in de tijd. Experimenten op meerdere domeinen met verschillende onderwerpen en stijlen tonen de effectiviteit van de voorgestelde aanpak aan met een verwaarloosbare impact op de rekenkosten.</abstract_nl>
      <abstract_hr>Postojeći modeli prevoda neuralnih strojeva (NMT) obično prevode rečenice u izolaciji, nedostaju prilika iskoristiti informacije o nivou dokumenta. U ovom poslu predlažemo povećati NMT modele sa veoma laganom mrežom pamćenja poput cache, koja čuva nedavno skrivene predstave kao povijest prevoda. Vjerojatnost distribucije nad proizvođenim riječima se aktualizira na internetu ovisno o povijesti prevođenja iz sjećanja, podržavajući modele NMT-a sposobnosti dinamički prilagoditi tijekom vremena. Eksperimenti o višestrukim domenama s različitim temama i stilima pokazuju učinkovitost predloženog pristupa s nezgodnim utjecajem na računalne troškove.</abstract_hr>
      <abstract_da>Eksisterende neurale maskinoversættelsesmodeller (NMT) oversætter generelt sætninger isoleret og går glip af muligheden for at udnytte oplysninger på dokumentniveau. I dette arbejde foreslår vi at udvide NMT-modeller med et meget let cache-lignende hukommelsesnetværk, som gemmer nylige skjulte repræsentationer som oversættelseshistorik. Sandsynlighedsfordelingen over genererede ord opdateres online afhængigt af oversættelseshistorikken hentet fra hukommelsen, hvilket giver NMT-modeller mulighed for dynamisk tilpasning over tid. Eksperimenter på flere domæner med forskellige emner og stilarter viser effektiviteten af den foreslåede tilgang med ubetydelig indvirkning på de beregningsmæssige omkostninger.</abstract_da>
      <abstract_id>Model terjemahan mesin saraf (NMT) yang ada secara umum menerjemahkan kalimat dalam isolasi, kehilangan kesempatan untuk mengambil keuntungan dari informasi tingkat dokumen. Dalam pekerjaan ini, kami mengusulkan untuk meningkatkan model NMT dengan jaringan memori yang sangat ringan seperti cache, yang menyimpan representation tersembunyi baru-baru ini sebagai sejarah terjemahan. Distribusi kemungkinan atas kata-kata yang dihasilkan diperbarui online bergantung pada sejarah terjemahan yang dicapai dari memori, memberikan model NMT dengan kemampuan untuk dinamik beradaptasi dengan waktu. Eksperimen di berbagai domain dengan topik dan gaya yang berbeda menunjukkan efektivitas pendekatan yang diusulkan dengan dampak yang tidak terlihat pada biaya perhitungan.</abstract_id>
      <abstract_de>Bestehende NMT-Modelle übersetzen Sätze in der Regel isoliert und verpassen die Möglichkeit, Informationen auf Dokumentenebene zu nutzen. In dieser Arbeit schlagen wir vor, NMT-Modelle um ein sehr leichtes cache-ähnliches Speichernetzwerk zu erweitern, das aktuelle versteckte Darstellungen als Übersetzungsgeschichte speichert. Die Wahrscheinlichkeitsverteilung über generierte Wörter wird online aktualisiert, abhängig von der Übersetzungshistorie, die aus dem Speicher abgerufen wird, wodurch NMT-Modelle in der Lage sind, sich im Laufe der Zeit dynamisch anzupassen. Experimente an mehreren Domänen mit unterschiedlichen Themen und Stilen zeigen die Wirksamkeit des vorgeschlagenen Ansatzes mit vernachlässigbaren Auswirkungen auf die Rechenkosten.</abstract_de>
      <abstract_fa>مدلهای ترجمه ماشین عصبی وجود دارد (NMT) معمولاً جمله‌ها را در تنهایی ترجمه می‌کند، فرصت برای استفاده از اطلاعات سطح سند را از دست داده است. در این کار، ما پیشنهاد می‌کنیم که مدل NMT را با شبکه حافظه‌ای شبیه به ذهن بسیار سنگین بالا ببریم، که نمایش‌های مخفی تاریخ ترجمه اخیر را به عنوان تاریخ ذخیره می‌کند. تقسیم احتمالات بر روی کلمات تولید شده بستگی به تاریخ ترجمه‌ها از حافظه گرفته شده است، که مدل‌های NMT را با توانایی که در طول زمان به داینامی اضافه کند، به آنلاین تبدیل می‌شود. تجربه‌هایی روی مجموعه‌ها با موضوع و طرح‌های مختلف نشان می‌دهند که موثرت روش پیشنهاد با تاثیر بی‌اثر بر هزینه‌های محاسبات است.</abstract_fa>
      <abstract_ko>기존 신경기계번역(NMT) 모델은 통상 문장을 고립적으로 번역해 문서급 정보를 활용할 기회를 놓친다.최근의 메모리 모델과 같은 숨겨진 네트워크로 NMT를 저장하는 것을 권장합니다.메모리에서 검색된 번역 역사에 따라 온라인 업데이트로 단어를 생성할 확률의 분포를 통해 NMT 모델은 시간에 따라 동태적으로 조정할 수 있는 능력을 가진다.서로 다른 주제와 풍격의 여러 분야에서의 실험은 이 방법의 유효성을 나타냈기 때문에 계산 원가에 대한 영향은 무시할 수 없다.</abstract_ko>
      <abstract_sw>Tafsiri ya mashine ya kijinsia (NMT) kwa ujumla hutafsiri maneno katika kutengana, bila fursa ya kutumia taarifa za kiwango cha nyaraka. Katika kazi hii, tunapendekeza kuongeza mifano ya NMT yenye mtandao wa kumbukumbu yenye uzito mkubwa, ambazo hubeba maoni yaliyofichikana hivi karibuni kama historia ya kutafsiri. Utambazaji wa uwezekano wa kusambaza maneno yaliyozaliwa unategemea historia ya tafsiri iliyochapishwa kutoka kumbukumbu, kwa kutumia mifano ya NMT yenye uwezo wa kubadilisha kwa muda mrefu. Majaribio kwenye maeneo mbalimbali yenye mada na nyenzo tofauti yanaonyesha ufanisi wa mbinu zilizopendekezwa na athari zisizo na maana juu ya gharama za kompyuta.</abstract_sw>
      <abstract_af>Bestaande neurale masjien vertaling (NMT) modele vertaal gewoonlik teikens in isolation, mis die geleentheid om voordeel van dokumentvlak inligting te neem. In hierdie werk, voorstel ons om NMT-modele te vergroot met 'n baie lig gewig cache-soos geheue netwerk te vergroot, wat onlangse verborge voorstellings as vertaling geskiedenis stoor. Die waarskynlik verspreiding oor genereerde woorde is opgedateer online afhanklik van die vertalingsgeskiedenis wat van die geheue ontvang is, wat NMT-modelles ondersteun met die kapasiteit om dinamies oor tyd te pas. Eksperimente op veelvuldige domeine met verskillende onderwerpe en style vertoon die effektiviteit van die voorgestelde toegang met negligbare invloek op die rekenaar koste.</abstract_af>
      <abstract_am>የኩነቶች መረጃ በዚህ ስራ፣ የNMT ሞዴላዎችን ለመጨመር እናስጀጋለን፡፡ The probability distribution over generated words is updated online depending on the translation history retrieved from the memory, endowing NMT models with the capability to dynamically adapt over time.  በተለየ አካባቢዎች እና ዓይነቶች ላይ በብዙ አዳራሽ ፈተናዎች በቁጥጥር ውስጥም በጥያቄ ላይ ጥቃት የሚያሳየው፡፡</abstract_am>
      <abstract_sq>Modelet ekzistuese të përkthimit të makinave nervore (NMT) përkthyen zakonisht fjalët në izolim, duke humbur mundësinë për të përfituar nga informacioni në nivel të dokumentit. Në këtë punë, propozojmë të shtojmë modelet NMT me një rrjet kujtese shumë të lehtë si cache, i cili ruan përfaqësime të fshehta të fundit si histori e përkthimit. The probability distribution over generated words is updated online depending on the translation history retrieved from the memory, endowing NMT models with the capability to dynamically adapt over time.  Eksperimentet në fusha të shumta me temë dhe stile të ndryshme tregojnë efektshmërinë e qasjes së propozuar me ndikim të pakujdesshëm në koston llogaritës.</abstract_sq>
      <abstract_tr>Öň bar näyral maşynyň terjimesini Bu çalışmada, NMT modellerini örän hafıza benzeri bir şekilde yükseltmek teklif ediyoruz. Bu son zamanlarda gizli ifadeleri taryha olarak saklayan. Ýüklendirilen sözler üçin muhtemelen döwletlerniň esasy ýagdaýdan alınan terjime geçmişinden görä, NMT modellerini dinamik zamanda gollaşdyrmak üçin mümkin edip biler. Birnäçe sahypalarda farklı temalar we stiller bilen örän deneyler bilgisayar maliýetiniň täsirini görkezýär.</abstract_tr>
      <abstract_az>Əvvəlki nöral maşın çevirimi (NMT) modelləri genellikle sözləri təkrarlaşdırır, belə səviyyədə məlumatlarından faydalanmaq üçün fırsatı yoxdur. Bu işdə NMT modellərini çox a ğırlı cache kimi hafıza ağlası ilə artırmağı təklif edirik. Bu, son günlərdə gizli nümunələri təhrif tarihi kimi saxlayar. Yapılmış sözlərin ehtimal dağıtımı online tərzində yenilənir, yaddaşlardan alınan çevirim tarihinə bağlı olaraq, NMT modellərini dinamik olaraq vaxt boyunca adapt edə bilər. Müxtəlif məsələlər və stillər ilə çoxlu domena təcrübələri hesablama maliyyətlərinin ucuz təsiri ilə təcrübə edilmiş təcrübəsinin etkinliğini göstərir.</abstract_az>
      <abstract_hy>Գոյություն ունի նյարդային մեքենայի թարգմանման (NMT) մոդելներ, որոնք ընդհանուր առմամբ թարգմանում են նախադասությունները մեկուսացման մեջ, բացակայելով հնարավորությունը օգտագործել փաստաթղթի մակար Այս աշխատանքի ընթացքում մենք առաջարկում ենք բարձրացնել NMT մոդելները շատ թեթև կեղտով նման հիշողության ցանցով, որը պահպանում է վերջերս թաքնված ներկայացումները, որպես թարգմանման պատմություն: Հավանականության տարածումը ստեղծված բառերի վերաբերյալ տեղափոխվում է առցանց, կախված թարգմանման պատմությունից, որը ստացվել է հիշողությունից, և տալիս է NMT մոդելներին դինամիկ հարմարվելու հնարավորություն ժամանակի ընթացքում: Տարբեր թեմաներ և ոճեր ունեցող բազմաթիվ ոլորտների փորձարկումները ցույց են տալիս առաջարկած մոտեցումների արդյունավետությունը, որն աննշան ազդեցություն ունի հաշվարկների արժեքների վրա:</abstract_hy>
      <abstract_bn>বিদ্যমান নিউরেল মেশিন অনুবাদ (NMT) মডেল সাধারণত একাক্তিতে শব্দ অনুবাদ করে, নথি- স্তর তথ্যের সুবিধা নেই। এই কাজে আমরা এনএমটি মডেল যোগ করার প্রস্তাব করছি একটি খুব হাল্কা ক্যাশের মতো মেমোরি নেটওয়ার্ক, যা সম্প্রতি লুকিয়ে রাখা প্রতিনিধিত্ব The probability distribution over generated words is updated online depending on the translation history retrieved from the memory, endowing NMT models with the capability to dynamically adapt over time.  বিভিন্ন বিষয় এবং স্টাইলের সাথে বেশ কয়েকটি ডোমেনের উপর পরীক্ষা দেখাচ্ছে যে প্রস্তাবিত পদ্ধতির কার্যক্রম এই গণনাত্রিক খরচের উপর</abstract_bn>
      <abstract_ca>Els models existents de traducció neural de màquines (NMT) tradueixen les frases en aïllament, perdent l'oportunitat d'aprofitar-se de la informació a nivell de documents. En aquesta feina, proposem augmentar els models NMT amb una xarxa de memòria molt lleugera com la de cache, que emmagatzema representacions ocultes recents com a història de traducció. La distribució de probabilitat sobre paraules generades es actualitza en línia segons la història de traducció obtenida de la memòria, donant a models NMT la capacitat d'adaptar-se dinàmicament al llarg del temps. Els experiments en múltiples dominis amb diferents temes i estils demostren l'eficacia de l'enfocament proposat amb un impacte negligent en el cost computacional.</abstract_ca>
      <abstract_fi>Nykyiset neurokonekäännösmallit (NMT) kääntävät lauseita yleensä erillään, jolloin ei ole mahdollista hyödyntää dokumenttitason tietoa. Tässä työssä ehdotamme NMT-mallien lisäämistä erittäin kevyellä välimuistin kaltaisella muistiverkolla, joka tallentaa viimeaikaiset piilotetut esitykset käännöshistoriaaksi. Todennäköisyysjakauma generoiduille sanoille päivitetään verkossa muistista haetun käännöshistorian mukaan, jolloin NMT-mallit pystyvät mukautumaan dynaamisesti ajan mittaan. Kokeet useilla toimialoilla eri aiheilla ja tyyleillä osoittavat ehdotetun lähestymistavan tehokkuuden ja vähäisen vaikutuksen laskennallisiin kustannuksiin.</abstract_fi>
      <abstract_bs>Postojeći modeli prevoda neuralnih strojeva (NMT) obično prevode rečenice u izolaciji, nedostaju prilika da iskoriste informacije na nivou dokumenta. U ovom poslu predlažemo povećati NMT modele sa veoma laganom mrežom pamćenja poput cache, koja čuva nedavno skrivene predstave kao povijest prevoda. Vjerojatnost distribucije nad proizvedenim riječima se aktualizuje na internetu ovisno o povijesti prevođenja iz sjećanja, podržavajući modele NMT-a sposobnosti dinamički prilagoditi tijekom vremena. Eksperimenti o višestrukim domenama s različitim temama i stilima pokazuju učinkovitost predloženog pristupa sa nezgodnim utjecajem na računalne troškove.</abstract_bs>
      <abstract_et>Olemasolevad närvilise masintõlke mudelid tõlgivad lauseid tavaliselt eraldi, jättes ilma võimaluse kasutada ära dokumenditasemel teavet. Selles töös teeme ettepaneku täiendada NMT mudeleid väga kerge vahemälu-sarnase mäluvõrguga, mis salvestab hiljutised peidetud representatsioonid tõlkeajaloolina. Tõenäosusjaotust genereeritud sõnade üle uuendatakse veebis sõltuvalt mälust saadud tõlkeajaloost, andes NMT mudelitele võime aja jooksul dünaamiliselt kohaneda. Erinevate teemade ja stiilidega mitme valdkonna eksperimendid näitavad kavandatud lähenemisviisi tõhusust, millel on väike mõju arvutuskuludele.</abstract_et>
      <abstract_cs>Stávající modely neuronového strojového překladu (NMT) obvykle překládají věty izolovaně a ztrácejí příležitost využít informací na úrovni dokumentu. V této práci navrhujeme rozšířit NMT modely o velmi lehkou paměťovou síť, která ukládá nedávné skryté reprezentace jako historii překladu. Rozložení pravděpodobnosti na generovaná slova je aktualizováno online v závislosti na historii překladu získané z paměti, což dává NMT modelům schopnost dynamicky se přizpůsobit v průběhu času. Experimenty na více oblastech s různými tématy a styly ukazují efektivitu navrhovaného přístupu s zanedbatelným dopadem na výpočetní náklady.</abstract_cs>
      <abstract_jv>buddy Nang barêng-barêng iki, kita unêmên mrêter nggawe model NMT karo netwisan sing paling apik ketahan Mangkin Gebudhakan langkung sampeyan luwih dumadhi sing gagal gak nggawe tema sing sampeyan karo styl sing gak bener effek nggawe gerakan kanggo nguasai perusahaan</abstract_jv>
      <abstract_he>דוגמנים הנוכחים לתרגום מכונות עצביות (NMT) בדרך כלל מתרגמים משפטים בבידוד, מפספסים את ההזדמנות לנצל מידע ברמה מסמכים. בעבודה הזו, אנו מציעים להגדיל דוגמנים NMT עם רשת זיכרון קלה מאוד דומה למשקל, אשר מאחסן מייצגים נסתרים לאחרונה כהיסטוריה של התרגום. ההפצה של הסבירות על מילים יוצרות מתעדכנת באינטרנט תלוי בהיסטוריה של התרגום שנמצאה מהזיכרון, מאשר מודלים NMT עם היכולת להתאים דינמית במהלך הזמן. ניסויים על תרומות רבות עם נושאים וסגנונים שונים מראים את היעילות של הגישה המוצעת עם השפעה בלתי משמעותית על העלות החישובית.</abstract_he>
      <abstract_ha>@ action: button Daga wannan aikin, Munã kwaɗayin Mu ƙara misãlai na NMT da wani jerin memory mai sauƙi-nau'in haske, wanda ke adana shaidar da aka ɓõye a yanzu kamar historin fassarar. Ana son rabon maganar da aka ƙãga shi ana ƙara cikin shirin ayuka da aka raba shi a lokacin, yana inganci da historin fassarar da aka canza daga kumbar, kuma yana da motdalun NMT da awon ya yi adadin a lokaci. Tajararin a kan sauri masu yawa da wasu madaidaita da misali daban, suna nuna sharrin aikin da aka yi niyyar da shi, yana da haifuta mai shagala kan aikin lissafi.</abstract_ha>
      <abstract_sk>Obstoječi modeli nevronskega strojnega prevajanja (NMT) na splošno prevajajo stavke ločeno in zamudijo priložnost za izkoriščanje informacij na ravni dokumenta. V tem delu predlagamo dopolnitev modelov NMT z zelo lahkim pomnilniškim omrežjem, podobnim predpomnilniku, ki shranjuje nedavne skrite predstavitve kot zgodovino prevodov. Razporeditev verjetnosti prek generiranih besed se posodablja na spletu glede na zgodovino prevodov, pridobljeno iz pomnilnika, kar omogoča modelom NMT dinamično prilagajanje skozi čas. Eksperimenti na več področjih z različnimi temami in slogi kažejo učinkovitost predlaganega pristopa z zanemarljivim vplivom na računalniške stroške.</abstract_sk>
      <abstract_bo>Existing neural machine translation (NMT) models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history. The probability distribution over generated words is updated online depending on the translation history retrieved from the memory, endowing NMT models with the capability to dynamically adapt over time. གླེང་སྒྲོམ་མང་པོ་ཞིག་གི་བརྟག་དཔྱད་འགོད་པ་དང་བཟོ་རྣམ་པ་སྦྲེལ་མཐུད་ནི་གྲོས་ཟེར་བ་གྱི་ནུས་པ་ཐད་ཀར་མེད</abstract_bo>
      </paper>
    <paper id="31">
      <title>Generating Sentences by Editing Prototypes</title>
      <author><first>Kelvin</first><last>Guu</last></author>
      <author><first>Tatsunori B.</first><last>Hashimoto</last></author>
      <author><first>Yonatan</first><last>Oren</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <doi>10.1162/tacl_a_00030</doi>
      <abstract>We propose a new generative language model for sentences that first samples a prototype sentence from the training corpus and then edits it into a new sentence. Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.</abstract>
      <pages>437–450</pages>
      <url hash="0a891ec9">Q18-1031</url>
      <video href="https://vimeo.com/285801187" />
      <bibkey>guu-etal-2018-generating</bibkey>
      <pwccode url="https://github.com/kelvinguu/neural-editor" additional="true">kelvinguu/neural-editor</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
    <title_ar>توليد الجمل عن طريق تحرير النماذج</title_ar>
      <title_es>Generar oraciones mediante la edición de prototipos</title_es>
      <title_pt>Gerando sentenças editando protótipos</title_pt>
      <title_fr>Génération de phrases par modification de prototypes</title_fr>
      <title_ja>プロトタイプの編集による文章の生成</title_ja>
      <title_hi>प्रोटोटाइप संपादित करके वाक्य जनरेट करना</title_hi>
      <title_zh>辑原型成句</title_zh>
      <title_ru>Создание предложений путем редактирования прототипов</title_ru>
      <title_ga>Pianbhreitheanna a Ghiniúint trí Fhréamhshamhlacha a Chur in Eagar</title_ga>
      <title_hu>Mondások generálása prototípusok szerkesztésével</title_hu>
      <title_el>Δημιουργία προτάσεων με επεξεργασία πρωτοτύπων</title_el>
      <title_ka>პროტოტიპების რედაქტირება</title_ka>
      <title_it>Generare frasi modificando prototipi</title_it>
      <title_kk>Прототиптерді өңдеу арқылы сөздерді құру</title_kk>
      <title_lt>Generuojamas sakinys redaguojant prototipus</title_lt>
      <title_ms>Menjana perkataan dengan Menyunting Prototip</title_ms>
      <title_mk>Генерирам реченици со уредување прототипи</title_mk>
      <title_mt>Il-Ġenerazzjoni tas-Sentenzi permezz tal-Editar tal-Prototipi</title_mt>
      <title_mn>Прототипүүдийг засварлах үг бий болгодог</title_mn>
      <title_no>Lagar setningar ved redigering av prototypar</title_no>
      <title_ml>പ്രോട്ടോട്ടൈപ്പുകള്‍ ചിട്ടപ്പെടുത്തുന്നതിനാല്‍ ശിക്ഷകള്‍ ഉണ്ടാക്കുന്നു</title_ml>
      <title_pl>Generowanie zdań poprzez edycję prototypów</title_pl>
      <title_ro>Generarea sentințelor prin editarea prototipurilor</title_ro>
      <title_si>ප්‍රොටොක්ටය සංපාදනය කරන්න ප්‍රතිචාරයක් නිර්මාණය කරනවා</title_si>
      <title_sr>Generiranje rečenica između uredbe prototipa</title_sr>
      <title_so>Generating daryeelka ku saabsan heshiiska arimaha</title_so>
      <title_ur>پروٹروٹیپیپ ایڈیٹ کرنے کے ذریعہ سنتز جوڑ رہے ہیں</title_ur>
      <title_sv>Skapa meningar genom att redigera prototyper</title_sv>
      <title_ta>திருத்தும் நெறிமுறைகளால் வாக்குறிகளை உருவாக்குகிறது</title_ta>
      <title_uz>Comment</title_uz>
      <title_vi>Phát ra câu đó bằng cách sửa đổi Prototype</title_vi>
      <title_bg>Генериране на изречения чрез редактиране на прототипи</title_bg>
      <title_hr>Generiranje rečenica između uredbe prototipa</title_hr>
      <title_da>Generere sætninger ved redigering af prototyper</title_da>
      <title_de>Erzeugen von Sätzen durch Bearbeiten von Prototypen</title_de>
      <title_nl>Zinnen genereren door prototypes te bewerken</title_nl>
      <title_ko>원형을 편집하여 문장을 생성하다</title_ko>
      <title_id>Menjana Hukuman dengan Menyunting Prototipe</title_id>
      <title_fa>تولید کردن کلمات با ویرایش پروتکیپ‌ها</title_fa>
      <title_tr>Sözleri Editleýän Protohiller</title_tr>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_sw>Generating Sentences by Editing Prototypes</title_sw>
      <title_af>Genereer Uitdrukkings deur Redigeer Prototipes</title_af>
      <title_sq>Generating Sentences by Editing Prototypes</title_sq>
      <title_bn>প্রোটোটোটাইপ সম্পাদনার মাধ্যমে শাস্তি তৈরি করা হচ্ছে</title_bn>
      <title_bs>Generiranje rečenica između uredbe prototipa</title_bs>
      <title_hy>Խմբագրելով նախադասություններ</title_hy>
      <title_az>Prototipl톛ri Editl톛ndirir</title_az>
      <title_et>Launete genereerimine prototüüpide redigeerimise teel</title_et>
      <title_fi>Luodaan lauseita muokkaamalla prototyyppejä</title_fi>
      <title_ca>Generant Sentences Editant Prototips</title_ca>
      <title_cs>Generování vět úpravou prototypů</title_cs>
      <title_jv>Gworongi Kemerdekaan Ubah Prototype</title_jv>
      <title_ha>Mai ƙiƙiro Shaki da Ƙaradin Nautilus</title_ha>
      <title_he>מייצר גזרות על ידי העורך פרוטוטיפים</title_he>
      <title_sk>Ustvarjanje stavkov z urejanjem prototipov</title_sk>
      <title_bo>སྦྲེལ་མཐུད་རིགས་བསྒྱུར་བཅོས་བྱེད་བཞིན་པའི་ཚིག་གྲངས་གསར་བཟོ་བ</title_bo>
      <abstract_ar>نقترح نموذجًا جديدًا للغة التوليدية للجمل الذي يقوم أولاً بتجربة نموذج أولي للجملة من مجموعة التدريب ثم تحريرها في جملة جديدة. مقارنةً بنماذج اللغة التقليدية التي تولد من الصفر إما من اليسار إلى اليمين أو عن طريق أخذ عينات أولاً من متجه الجملة الكامنة ، فإن نموذجنا الأولي - ثم التحرير - يحسن الارتباك في نمذجة اللغة ويولد مخرجات عالية الجودة وفقًا للتقييم البشري. علاوة على ذلك ، فإن النموذج يؤدي إلى ناقل تحرير كامن يلتقط دلالات قابلة للتفسير مثل تشابه الجملة والتشابهات على مستوى الجملة.</abstract_ar>
      <abstract_es>Proponemos un nuevo modelo de lenguaje generativo para oraciones que primero muestrea una oración prototipo del corpus de entrenamiento y luego la edita en una nueva oración. En comparación con los modelos lingüísticos tradicionales que generan desde cero, ya sea de izquierda a derecha o muestreando primero un vector de oración latente, nuestro modelo de prototipos y luego editar mejora la perplejidad en el modelado del lenguaje y genera resultados de mayor calidad de acuerdo con la evaluación humana. Además, el modelo da lugar a un vector de edición latente que captura la semántica interpretable, como la similitud de oraciones y las analogías a nivel de oración.</abstract_es>
      <abstract_fr>Nous proposons un nouveau modèle de langage génératif pour les phrases qui prélève d'abord un prototype de phrase à partir du corpus de formation, puis l'édite dans une nouvelle phrase. Comparé aux modèles de langage traditionnels qui génèrent de toutes pièces soit de gauche à droite, soit en échantillonnant d'abord un vecteur de phrase latent, notre modèle prototype puis édition améliore la perplexité sur la modélisation du langage et génère des résultats de meilleure qualité en fonction de l'évaluation humaine. De plus, le modèle donne naissance à un vecteur d'édition latent qui capture des sémantiques interprétables telles que la similarité de phrases et les analogies au niveau de la phrase.</abstract_fr>
      <abstract_pt>Propomos um novo modelo de linguagem generativa para sentenças que primeiro amostra uma sentença protótipo do corpus de treinamento e depois a edita em uma nova sentença. Comparado aos modelos de linguagem tradicionais que geram do zero da esquerda para a direita ou pela primeira amostragem de um vetor de sentença latente, nosso modelo de protótipo e edição melhora a perplexidade na modelagem de linguagem e gera resultados de maior qualidade de acordo com a avaliação humana. Além disso, o modelo dá origem a um vetor de edição latente que captura semântica interpretável, como similaridade de sentença e analogias em nível de sentença.</abstract_pt>
      <abstract_ja>まずトレーニングコーパスからプロトタイプの文章をサンプリングし、それを新しい文章に編集する文章のための新しい生成言語モデルを提案します。従来の言語モデルは、左から右へ、または潜在的な文章ベクトルを最初にサンプリングすることによって生成されるのと比較して、当社のプロトタイプ-その後-編集モデルは、言語モデリングの複雑さを改善し、人間の評価に従ってより高い品質の出力を生成します。さらに、モデルは、文の類似性や文レベルの類似性などの解釈可能な意味論を取り込む潜在的な編集ベクトルを生み出す。</abstract_ja>
      <abstract_zh>为句生言模,先从训练语料库中采样原型句,然后编为新句。 始于从头从左到右或先采样于句向量,吾原型辑改言建模之惑,因人伦而高质量之。 又有潜编向量,向量获可解之语义,如句相似性类。</abstract_zh>
      <abstract_hi>हम वाक्यों के लिए एक नया उत्पादक भाषा मॉडल प्रस्तावित करते हैं जो पहले प्रशिक्षण कॉर्पस से एक प्रोटोटाइप वाक्य का नमूना लेता है और फिर इसे एक नए वाक्य में संपादित करता है। पारंपरिक भाषा मॉडल की तुलना में जो खरोंच से या तो बाएं-से-दाएं या पहले एक अव्यक्त वाक्य वेक्टर का नमूना लेकर उत्पन्न करते हैं, हमारा प्रोटोटाइप-तो-संपादन मॉडल भाषा मॉडलिंग पर उलझन में सुधार करता है और मानव मूल्यांकन के अनुसार उच्च गुणवत्ता वाले आउटपुट उत्पन्न करता है। इसके अलावा, मॉडल एक अव्यक्त संपादन वेक्टर को जन्म देता है जो वाक्य समानता और वाक्य-स्तर की उपमाओं जैसे व्याख्यायोग्य शब्दार्थ को कैप्चर करता है।</abstract_hi>
      <abstract_ru>Мы предлагаем новую генеративную языковую модель для предложений, которая сначала отображает прототип предложения из обучающего корпуса, а затем редактирует его в новое предложение. По сравнению с традиционными языковыми моделями, которые генерируют с нуля либо слева направо, либо путем первой выборки вектора скрытых предложений, наша модель прототип-потом-редактирование улучшает недоумение в языковом моделировании и генерирует более качественные результаты в соответствии с оценкой человека. Кроме того, модель порождает скрытый вектор редактирования, который захватывает интерпретируемую семантику, такую как сходство предложений и аналогии на уровне предложений.</abstract_ru>
      <abstract_ga>Molaimid múnla teanga giniúna nua d’abairtí a shamplaíonn abairt fhréamhshamhail ar dtús ón gcorpas oiliúna agus a athróidh ina habairt nua ansin. I gcomparáid le samhlacha teanga traidisiúnta a ghineann ón tús ó chlé go deas nó trí veicteora abairte folaigh a shampláil ar dtús, feabhsaíonn ár múnla fréamhshamhlacha-eagarthóireachta ansin an t-imní ar shamhaltú teanga agus gineann sé aschuir chaighdeán níos airde de réir meastóireachta daonna. Ina theannta sin, eascraíonn veicteoir folaigh eagarthóireachta as an tsamhail a ghlacann séimeantaic inmhínithe ar nós cosúlacht na habairte agus analaí ar leibhéal na habairte.</abstract_ga>
      <abstract_ka>ჩვენ შეგიძლიათ ახალი გენერაციური ენერაციის მოდელის მოდელის, რომელიც პირველად პროტოტიპის სიტყვების გამოყენება კორპუსდან და შემდეგ ახალი სიტყვებში რედაქტირება. ჩვენი პროტოტიპი შემდეგ რედაქტირებული მოდელისთვის, რომელიც მარჯვნიდან მარჯვნიდან შექმნა, ან პირველი მარჯვნიდან მარჯვნიდან ან პირველი მარჯვნიდან გამოიყენება, ჩვენი პროტოტიპი შემდეგ რედაქტირებული მოდელისთვი დამატებით, მოდელეში მოიქნება ლატენტური რედაქტირებული გვექტორის შესახებ, რომელიც შეიძლება განსხვავებელი სიმენტიკების შესახებ, როგორც წესების სხვადასხვა და წეს</abstract_ka>
      <abstract_hu>Új generációs nyelvi modellt javasolunk olyan mondatokhoz, amelyek először mintáznak egy prototípust a tréningkorpuszból, majd új mondatba szerkesztik. A hagyományos nyelvi modellekkel összehasonlítva, amelyek balról jobbra vagy látens mondatvektort generálnak, a prototípus-majd-szerkesztés modellünk javítja a nyelvmodellezés zavaróságát és jobb minőségű kimeneteket generál az emberi értékelés szerint. Ezenkívül a modell egy látens szerkesztési vektort eredményez, amely értelmezhető szemantikát rögzít, mint például mondatszintű analógiák és mondatszintű analógiák.</abstract_hu>
      <abstract_el>Προτείνουμε ένα νέο μοντέλο γενετήσιας γλώσσας για προτάσεις που πρώτα δειγματολαμβάνει μια πρωτότυπη πρόταση από το εκπαιδευτικό σώμα και στη συνέχεια την επεξεργάζεται σε μια νέα πρόταση. Σε σύγκριση με τα παραδοσιακά γλωσσικά μοντέλα που παράγουν από το μηδέν είτε από αριστερά προς τα δεξιά είτε με την πρώτη δειγματοληψία ενός λανθάνοντος διανύσματος προτάσεων, το πρότυπο-μετά-επεξεργασία μοντέλο μας βελτιώνει την σύγχυση στη γλωσσική μοντελοποίηση και παράγει υψηλότερης ποιότητας αποτελέσματα σύμφωνα με την ανθρώπινη αξιολόγηση. Επιπλέον, το μοντέλο δημιουργεί ένα λανθάνον διάνυσμα επεξεργασίας που συλλαμβάνει ερμηνευτές σημασιολογικές όπως ομοιότητα προτάσεων και αναλογίες σε επίπεδο προτάσεων.</abstract_el>
      <abstract_lt>Siūlome naują kartos kalbos model į, skirtą sakiniams, kurie pirmiausia atrinktų prototipą sakinį iš mokymo korpuso ir tada jį pakeistų į naują sakinį. Palyginti su tradiciniais kalbų modeliais, kurie atsiranda iš nulio arba kairėje į dešinę, arba pirmą kartą paimant latentinį sakinio vektorių mėginius, mūsų prototipas-tada-redakcijos modelis pagerina kalbų modeliavimo perpleksiją ir pagal žmogaus vertinimą sukuria aukštesnės kokybės rezultatus. Be to, modelis sukuria latentinį redakcijos vektorių, kuris apima aiškinamąją semantiką, pvz., sakinių panašumą ir sakinių lygio analogiją.</abstract_lt>
      <abstract_it>Proponiamo un nuovo modello di linguaggio generativo per le frasi che prima campiona una frase prototipo dal corpus formativo e poi la modifica in una nuova frase. Rispetto ai modelli linguistici tradizionali che generano da zero da sinistra a destra o campionando prima un vettore di frase latente, il nostro modello prototipale-then-edit migliora la perplessità sulla modellazione del linguaggio e genera output di qualità superiore secondo la valutazione umana. Inoltre, il modello dà origine a un vettore di modifica latente che cattura semantica interpretabile come somiglianza di frase e analogie a livello di frase.</abstract_it>
      <abstract_mk>Ние предложуваме нов генерациски јазик модел за реченици кои прво примеруваат прототип реченица од обуката корпус и потоа го уредуваат во нова реченица. Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation.  Покрај тоа, моделот предизвикува latent уредувачки вектор кој captures interpretable semantics such as sentence similarity and sentence-level analogies.</abstract_mk>
      <abstract_kk>Біз тіл үлгісін біріншіден бақылау корпустағы прототипті сөйлеменің үлгісін өзгертіп, оны жаңа сөйлемеге өзгертетін жаңа тіл үлгісін таңдаймыз. Сол жақтан оң жақтан құрылған әдетті тіл үлгілеріне салыстырылып, немесе алғашқы сөз векторын алдыңғы ретінде алдыңғы үлгілеріне салыстырып, прототипті өңдеу үлгілеріміз тіл моделінде қарапайымдылығын жақсартып, адамның о Қосымша, үлгі сөйлеменің ұқсас пен сөйлеменің деңгейінің аналогиялығын түсіндіретін соңғы өңдеу векторына көтереді.</abstract_kk>
      <abstract_ms>Kami cadangkan model bahasa generasi baru untuk kalimat yang pertama mencampur kalimat prototip dari korpus latihan dan kemudian menyuntingnya ke kalimat baru. Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Lagipun, model memberikan bangunan kepada vektor edit tersembunyi yang menangkap semantik yang boleh diterjemahkan seperti persamaan kalimat dan analogi aras kalimat.</abstract_ms>
      <abstract_ml>വാക്കുകള്‍ സ്ക്രാച്ചില്‍ നിന്നും ഇടത്തോട്ടോ വലത്തോട്ടോ സൃഷ്ടിക്കുന്ന പാഠമായ ഭാഷ മോഡലുകള്‍ക്ക് താല്‍പ്പര്യമായി മാറ്റുന്നതിനായി നമ്മുടെ പ്രോട്ടോട്ടൈപ്പ് മോഡല്‍ മാതൃകയ അതിനുശേഷം, മോഡല്‍ ഒരു സാധാരണ എഡിറ്റ് വെക്റ്റരിലേക്ക് ഉയര്‍ന്നുവരുന്നു. വാക്കിന്റെ സമമാകുന്ന വാക്കുകളും വാക്കുന്ന നിലയി</abstract_ml>
      <abstract_mt>Aħna nipproponu mudell ġdid ta’ lingwa ġenerattiva għas-sentenzi li l-ewwel jittieħed kampjun ta’ sentenza prototipika mill-korpus tat-taħriġ u mbagħad jemendah f’sentenza ġdida. Meta mqabbel ma’ mudelli lingwistiċi tradizzjonali li jiġġeneraw minn żero jew mix-xellug għal-lemin jew bl-ewwel teħid ta’ kampjuni ta’ vettur ta’ sentenza moħbija, il-mudell prototip-then-edit tagħna jtejjeb il-perplessità fuq l-immudellar tal-lingwi u jiġġenera riżultati ta’ kwalità ogħla skont l-evalwazzjoni umana. Barra minn hekk, il-mudell jagħti lok għal vettur tal-edit latenti li jaqbad semantiċi interpretabbli bħas-similarità tas-sentenza u l-analogiji fil-livell tas-sentenza.</abstract_mt>
      <abstract_mn>Бид эхлээд сургалтын корпусын прототип өгүүлбэр шинэ хэл загварын загварыг санал болгож, дараа нь шинэ өгүүлбэр шинэчлэх болно. Энэ нь уламжлалт хэл загвартай харьцуулсан нь зүүн, баруун, эсвэл хамгийн сүүлийн үгийн векторын хувьд анхны жишээнээс гарч ирдэг. Бидний прототип-загварын загвар хэл загварын төлөвлөлт дээр хувьцааны төлөвлөлт болон хүн төрөлхтний үнэлгээ Үүнээс гадна загвар нь хэлбэрийн төстэй, өгүүлбэрийн төстэй аналогийг дүгнэж байгаа сүүлийн загварын загварын вектор үүсгэдэг.</abstract_mn>
      <abstract_ro>Propunem un nou model de limbaj generativ pentru propoziții care probează mai întâi un prototip de propoziție din corpul de instruire și apoi o editează într-o nouă propoziție. Comparativ cu modelele lingvistice tradiționale care generează de la zero fie de la stânga la dreapta, fie prin eșantionarea unui vector latent de propoziție, modelul nostru prototip-apoi-editare îmbunătățește perplexitatea asupra modelării limbajului și generează ieșiri de calitate superioară conform evaluării umane. În plus, modelul dă naștere unui vector de editare latent care surprinde semantica interpretabilă, cum ar fi similitudinea frazelor și analogiile la nivel de propoziție.</abstract_ro>
      <abstract_pl>Proponujemy nowy generatywny model językowy dla zdań, który najpierw próbuje prototypowe zdanie z korpusu treningowego, a następnie edytuje je na nowe zdanie. W porównaniu z tradycyjnymi modelami językowymi, które generują od podstaw od lewej do prawej lub poprzez pierwsze próbkowanie utajonego wektora zdań, nasz prototyp-a-następnie edytuj model poprawia zakłopotanie w modelowaniu językowym i generuje wyższą jakość wyników według oceny ludzkiej. Ponadto model daje powstawanie utajonego wektora edycji, który przechwytuje interpretowalną semantykę, taką jak podobieństwo zdań i analogię na poziomie zdań.</abstract_pl>
      <abstract_sr>Predlažemo novu generičnu jezičku modelu rečenica koja prvo uzorava prototipnu rečenicu iz treninga korpusa i onda ga rediguje u novu rečenicu. U usporedbi sa tradicionalnim jezičkim modelima koji proizvode od ogrebotine ili lijeve do desne ili prve uzorke latentnog vektora rečenice, naš prototip-onda-editni model poboljšava kompleksnost na modeliranju jezika i proizvodi veće kvalitetne ishode prema ljudskoj procjeni. Osim toga, model daje rezultat latentnog redaktornog vektora koji uključuje interpretabilne semantike poput sličnosti rečenica i analogije nivoa rečenica.</abstract_sr>
      <abstract_no>Vi foreslår eit nytt generert språk-modell for setningar som først prøver eit prototype-setning frå øvingskorpusen og deretter redigerer den til eit nytt setning. Sammenlignet med tradisjonelle språk-modeller som lagar frå rulla anten venstre til høgre eller ved å første samla eit latent setningsvektor, vil vår prototype-deretter-redigeringsmodellen forbetra kompleksitet på språk-modellering og laga høgare kvalitetsvektor etter menneske evaluering. I tillegg går modellen opp til ein latent redigeringsvektor som hentar tolkbare semantikk som setningslinjer og setningslinjer.</abstract_no>
      <abstract_si>අපි අළුත් ජීවිත භාෂාවක් නිර්මාණය කරන්න ප්‍රධාන කොර්පුස් වලින් ප්‍රධාන වචනයක් පටන් ගන්න පුළුවන් වචනයක පාරමාන්‍ය භාෂා මොඩේල්ස් එක්ක සම්පූර්ණයෙන් වෙන්න පුළුවන් වෙන්න පුළුවන් වචන වෙක්ටර් එක්ක, අපේ ප්‍රමෝටිප් පස්සේ-පස්සේ-සම්පූර්ණය මදුල ඉතින්, මොඩේල් එක්ක ලේටින් සංපාදනය වෙක්ටර් වලට ප්‍රමාණය කරනවා, ඒ වගේම වාක්ය සහ වාක්ය සාමාන්තික වගේම වාක්ය සම</abstract_si>
      <abstract_so>Waxaan soo jeedaynaa tusaale-qaab luuqad cusub oo ku qoran hadalka ugu horreeya tusaale ahaan oo ka mid ah qaababka waxbarashada kadibna u bedeli karno hadal cusub. Isbarbardhig noocyada asalka ah oo ka soo saara qoraalka luqada xagga bidixda ama xagga midigta ama marka hore tusaale ahaan vectorka ugu dambeeya, tusaale-qaabeenkeenna sawirida ayaa bedela murug ku saabsan tusaalaha luuqada, wuxuuna sameeyaa dibadda u sareeya sida qiimeynta dadka. Markaas waxaa kaloo dheer in tusaale ahaan u soo bixinaya vector sawir u dhow, kaasoo qabsada semantiga lagu turjumi karo tusaale ahaan isku mid ah iyo kalajarida heerka ereyga.</abstract_so>
      <abstract_sv>Vi föreslår en ny generativ språkmodell för meningar som först samplar en prototypmening från träningskorpusen och sedan redigerar den till en ny mening. Jämfört med traditionella språkmodeller som genererar från grunden antingen från vänster till höger eller genom att först provspela en latent meningsvektor, förbättrar vår prototyp-sedan-edit-modell förvirringen kring språkmodellering och genererar högre kvalitet enligt mänsklig utvärdering. Dessutom ger modellen upphov till en latent redigeringsvektor som fångar tolkningsbar semantik såsom meningsskillnader och meningsnivåanalogier.</abstract_sv>
      <abstract_ta>வாக்கியங்களுக்கு புதிய பொதுவான மொழி மாதிரியை நாம் பரிந்துரைக்கிறோம். முதலில் பயிற்சி குறியீட்டிலிருந்து ஒரு முன் மொழி மாதிரி மாதிரிகளில் இருந்து உருவாக்கும் பொதுவான மொழி மாதிரிகளை ஒப்பிட்டு ஒப்பிடும் முதலில் இடப்புறத்திலிருந்து வலப்புறத்திலிருந்து அல்லது புதிய வாக்க அதற்கும், மாதிரி ஒரு சமீபத்தில் திருத்தி நெறிக்கு அதிகரிக்கும் வாக்கின் ஒத்தம் மற்றும் வாக்கு- மட்டத்தின் பொருத்தம் போன்ற</abstract_ta>
      <abstract_ur>ہم ایک نئی ژنرانیٹ زبان مدل کی پیشنهاد کرتے ہیں جو پہلی بار تدریس کورپوس سے ایک پروٹیٹیپ جماعت کا نمونہ بناتا ہے اور پھر اسے نئی جماعت میں سمجھتا ہے. سنتی زبان مدلکوں کے مقابلہ میں جو بائیں سے دائیں سے یا پہلی بار ایک لٹینٹ ویکتور سے پیدا ہوتے ہیں، ہمارے پروٹینٹیپ-پھر-ایڈیٹ موڈل زبان موڈلینگ کے معاملہ میں نہایت اضافہ کرتا ہے اور انسان کی ارزش کے مطابق اضافہ اضافہ کرتا ہے. اور اس کے علاوہ، موڈل ایک لاٹینٹ ایڈیٹ ویکتور کو اضافہ کرتا ہے جس کی تعبیر قابل سیمانٹیکوں کو پکڑتا ہے جیسے جماعت کی برابری اور جماعت سطح آنلوژی۔</abstract_ur>
      <abstract_uz>Biz birinchi so'zlar uchun yangi generativ tilning modeli rivojlanamiz va birinchi misol taʼminlovchi kompyuterdagi prototyp so'zlarini o'zgartiradi. Name Koʻrsatgich, model yangi tahrirlash vektoriga ega bo'ladi. Bu soʻzning bir xil va sentence darajasi analog kabi tarjima qilinadigan semantika qabul qiladi.</abstract_uz>
      <abstract_vi>Chúng tôi đề xuất một mô hình ngôn ngữ tạo hóa mới cho câu thứ nhất thử một bản mẫu từ tập thể huấn và sau đó soạn thành một bản mới. So với các mô hình ngôn ngữ truyền thống tạo ra từ vết thương hoặc từ trái sang phải hoặc bằng cách thử nghiệm trước một véc- tơ từ câu thần thoại, mô hình mẫu mẫu mẫu mẫu mẫu mẫu mẫu nguyên mẫu sẽ cải thiện sự bối rối về cách tạo ngôn ngữ và phát xuất chất lượng cao hơn dựa theo đánh giá con người. Hơn nữa, mô hình này tạo ra một véc- tơ sửa đổi tiềm năng nắm bắt ngữ pháp thể dịch như kiểu giống câu và tương tự mức án.</abstract_vi>
      <abstract_bg>Предлагаме нов генеративен езиков модел за изречения, който първо изважда прототипно изречение от тренировъчния корпус и след това го редактира в ново изречение. В сравнение с традиционните езикови модели, които генерират от нулата или отляво надясно, или чрез първо вземане на проби от латентен вектор на изречение, нашият модел прототип-след-редактиране подобрява объркването на езиковото моделиране и генерира по-качествени изходи според човешката оценка. Освен това моделът поражда латентен вектор за редактиране, който улавя тълкуваема семантика като сходство на изречения и аналогии на ниво изречение.</abstract_bg>
      <abstract_nl>We stellen een nieuw generatief taalmodel voor zinnen voor dat eerst een prototype zin uit het trainingscorpus steekt en vervolgens bewerkt in een nieuwe zin. Vergeleken met traditionele taalmodellen die vanaf nul van links naar rechts genereren of door eerst een latente zinnenvector te bemonsteren, verbetert ons prototype-en-bewerken model de verwarring over taalmodellering en genereert outputs van hogere kwaliteit volgens menselijke evaluatie. Bovendien geeft het model aanleiding tot een latente bewerkingsvector die interpreteerbare semantiek zoals zinsgelijkenis en zins-niveau analogieën vastlegt.</abstract_nl>
      <abstract_hr>Predlažemo novi generični jezički model za rečenice koje prvo uzoravaju prototipnu rečenicu iz tržišnog korpusa, a zatim ga uredimo u novu rečenicu. U usporedbi s tradicionalnim jezičkim modelima koji proizvode od ogrebotine ili lijeve do desne ili prve uzorke latentnog vektora rečenice, naš model prototipa zatim-editiranja poboljšava kompleksnost na modeliranju jezika i proizvodi visoke kvalitetne ishode u skladu s ljudskim procjenama. Osim toga, model daje povećanje latentnog redaktornog vektora koji uključuje interpretabilne semantike poput sličnosti rečenica i analogija razine rečenica.</abstract_hr>
      <abstract_da>Vi foreslår en ny generativ sprogmodel for sætninger, der først samler en prototypesætning fra træningskorpus og derefter redigerer den til en ny sætning. Sammenlignet med traditionelle sprogmodeller, der genererer fra bunden enten venstre mod højre eller ved første prøveudtagning af en latent sætningsvektor, forbedrer vores prototype-derefter-rediger model forvirring om sprogmodellering og genererer output af højere kvalitet ifølge menneskelig evaluering. Desuden giver modellen anledning til en latent redigeringsvektor, der fanger fortolkningsbar semantik såsom sætningens lighed og sætningsniveau analogier.</abstract_da>
      <abstract_de>Wir schlagen ein neues generatives Sprachmodell für Sätze vor, das zunächst einen Prototypsatz aus dem Trainingskorpus entnimmt und ihn dann in einen neuen Satz bearbeitet. Im Vergleich zu herkömmlichen Sprachmodellen, die entweder von links nach rechts oder durch das erste Abtasten eines latenten Satzvektors von Grund auf neu generieren, verbessert unser Prototyp-dann-Editier-Modell die Verwirrung bei der Sprachmodellierung und generiert qualitativ hochwertigere Outputs gemäß menschlicher Bewertung. Darüber hinaus ergibt das Modell einen latenten Editvektor, der interpretierbare Semantik wie Satzähnlichkeit und Satzanalogien erfasst.</abstract_de>
      <abstract_ko>우리는 새로운 문장 생성 언어 모델을 제시했다. 이 모델은 먼저 훈련 자료 라이브러리에서 원형 문장을 추출한 다음에 이를 새로운 문장으로 편집한다.전통적으로 0에서 왼쪽에서 오른쪽으로 또는 잠재적인 문장 벡터를 먼저 샘플링하는 언어 모델에 비해 우리의 원형 재편집 모델은 언어 모델링의 복잡성을 개선하고 인류의 평가에 따라 더욱 높은 품질의 출력을 생성했다.그 밖에 이 모델은 문장의 유사성과 문장급의 유비 등 해석 가능한 의미를 포획하는 잠재적인 편집 벡터를 만들어 냈다.</abstract_ko>
      <abstract_tr>Biz sözler üçin täze jeneral dil nusgasyny teklip edip, ilkinji gezek okuw korpusyndan prototip sözlerini örän eserleýän we soňra ony täze sözlere düzenleyän. Çaltdan saňa-sagdan döreden däpli dil nusgalaryna karşılaşdyryldy, ýöne iň soňky sözler vektörüne görkezilip, biziň prototipimiz soňra-düzenlemek nusgalarymyz dil modelleşdirilýän işligini bejerýär we adam baýramyna görä ýokary kaliwatly netijeleri çykar. Üstelik, model sözler benzeri ve sözler seviyesinde analogileri çözebilir bir laten düzenleyici vektöre yükselir.</abstract_tr>
      <abstract_id>Kami mengusulkan model bahasa generasi baru untuk kalimat yang pertama sampel kalimat prototip dari korpus latihan dan kemudian mengubahnya menjadi kalimat baru. Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation.  Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.</abstract_id>
      <abstract_sq>Ne propozojmë një model të ri gjenerativ gjuhësh për fraza që së pari shembullon një frazë prototipi nga korpusi i stërvitjes dhe pastaj e ndryshon në një frazë të re. Në krahasim me modelet tradicionale gjuhësh që gjenerojnë nga zero ose nga majta në djathtë ose duke marrë kampionatin e parë të një vektori të fjalës së fshehtë, modeli ynë prototip-pastaj-edit përmirëson perpleksinë në modelimin gjuhësor dhe gjeneron dalje më të larta cilësi sipas vlerësimit njerëzor. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.</abstract_sq>
      <abstract_af>Ons voorstel 'n nuwe genereerbare taal model vir setnings wat eerste voorbeeld 'n prototipe setning van die oefening korpus en dan redigeer dit in 'n nuwe seting. Vergelyk met tradisionele taal modele wat genereer van skrap of links-na-regs of deur eerste versameling van 'n latente setvektor, ons prototipe-dan-redigeer model verbeter die verpligtigheid op taal modellering en genereer hoëre kwaliteit uitvoerdes volgens menslike evaluering. Verder, die model gee opstanding tot 'n latente redigeerbare vektor wat ontvangbare semantieke, soos sentence-vlak analogies, opneem.</abstract_af>
      <abstract_fa>ما یک مدل ژنترافی جدید برای جمله‌ها پیشنهاد می‌کنیم که اول یک جمله پیش‌بینی از کورپوس آموزش می‌کند و سپس آن را به یک جمله جدید ویرایش می‌کند. در مقایسه با مدل زبان سنتی که از گسترش چپ به سمت راست یا اولین نمونه‌ای از یک ویکتور جمله‌های latent تولید می‌کند، مدل پیش‌نویس‌های ما در مورد مدل‌سازی زبان تغییر می‌دهد و نتیجه‌های کیفیت بالاتر را بر اساس ارزیابی انسان تولید می‌کند. علاوه بر این، مدل به یک ویکتور ویکتور تاریخی تغییر می‌دهد که سیماناتیک قابل تعبیر مانند جمله‌ای شبیه‌سازی و اتلالوژی سطح جمله‌ها را می‌گیرد.</abstract_fa>
      <abstract_az>Biz bu cümlələrdən ilk dəfə prototip cümləsini təhsil edir və sonra onu yeni cümləyə düzəltər. Həmçinin soldan sağdan oluşan və ya ilk cümlənin vektörünün örneçəsi ilə, prototipimiz-sonra-düzenleyən modellərimiz dil modellərində çoxluğunu yaxşılaşdırır və insan değerlendirməsinə görə daha yüksək kaliteli çıxışları yaradır. Daha sonra, modeli, sözlərin simantiklərini və sözlərin səviyyəsi analogiləri kimi yorumlayıcı semantikləri yakalayan latent edit ör vektoru yüksəlir.</abstract_az>
      <abstract_bn>আমরা একটি নতুন জেনারেটিভ ভাষার মডেল প্রস্তাব করছি যা প্রথমে প্রশিক্ষণের কোর্পাস থেকে একটি প্রোটোটোপটাইপের বাক্য প্রদান করে এবং তা ঐতিহ্যবাহী ভাষার মডেলের তুলনায় যা বাম থেকে বা ডান দিক থেকে তৈরি করে অথবা প্রথমে একটি সাম্প্রতিক বাক্য ভেক্টরের উদাহরণ করে, আমাদের প্রোটোপটাইপ- তারপর-সম্পাদনা মডেলের মাধ্ এছাড়াও, মডেল একটি সাম্প্রতিক সম্পাদক ভেক্টরের দিকে বাড়িয়ে দেয় যেটি ব্যাখ্যাত সেমেন্টিকের মতো বাক্যের সমতা এবং শাস্তি স্</abstract_bn>
      <abstract_sw>Tunapendekeza mtindo mpya wa lugha ya kizalendo kwa hukumu ambazo mara ya kwanza inasambaza hukumu ya mfano kutoka kwenye makampuni ya mafunzo na kisha kuihariri katika hukumu mpya. Kulinganishwa na mifano ya lugha za kitamaduni yanayotengeneza kutoka kwenye viwanja vya kushoto hadi kulia au kwa mara ya kwanza kwa sampuli vector ya hivi karibuni ya hukumu, mtindo wetu wa kuhariri tena unabadilisha utata kuhusu mifano ya lugha na kutengeneza matokeo ya kiwango kikubwa kwa mujibu wa tathmini za binadamu. Zaidi ya hayo, mifano inaongezeka kwa vector ya kuhariri ya hivi karibuni ambayo inachukua mifano yanayotafsiriwa kama vile hukumu inayofanana na anachambua kiwango cha hukumu.</abstract_sw>
      <abstract_bs>Predlažemo novi generični jezički model za rečenice koje prvo uzoravaju prototipnu rečenicu iz treninga korpusa, a zatim ga uredimo u novu rečenicu. U usporedbi sa tradicionalnim jezičkim modelima koji proizvode od ogrebotine ili lijeve do desne ili prve uzorke latentnog vektora rečenice, naš prototip-onda-editirani model poboljšava kompleksnost na modeliranju jezika i proizvodi viši kvalitetni ishod prema ljudskoj procjeni. Osim toga, model daje rezultat latentnog redaktornog vektora koji uključuje interpretabilne semantike poput sličnosti rečenica i analogije razine rečenica.</abstract_bs>
      <abstract_ca>Proposem un nou model de llenguatge generador per a les frases que primer mostren un prototip de frases del cos d'entrenament i després l'edita en una nova frase. Comparat amb els models tradicionals de llenguatge que generen de zero, d'esquerra a dreta o per primera mostra d'un vector de frases latents, el nostre prototip-llavors-edit millora la perplexitat en la modelació de llenguatge i genera productes de qualitat més alta segons l'evaluació humana. A més, el model dóna lloc a un vector d'edició latent que captura semàntica interpretable com la similitud de frases i analogies de nivell de frases.</abstract_ca>
      <abstract_cs>Navrhujeme nový generativní jazykový model pro věty, který nejprve vzorkuje prototypovou větu z tréninkového korpusu a poté ji upravuje do nové věty. Ve srovnání s tradičními jazykovými modely, které generují od začátku buď zleva doprava nebo prvním vzorkováním latentního vektoru věty, náš prototyp-pak-edit model zlepšuje zmatenost při modelování jazyka a generuje kvalitnější výstupy podle lidského hodnocení. Dále vzniká latentní editační vektor, který zachycuje interpretovatelnou sémantiku, jako je podobnost vět a analogie na úrovni věty.</abstract_cs>
      <abstract_am>አዲስ የውይይት ቋንቋ ምሳሌ ለመጀመሪያ ምሳሌ ከአስተማሪው ኮርፓስ እና አዲስ ክፍል እንዲያስተካክለው እናስባለን፡፡ ከግራ-ወደ ቀኝ ወይም በመጀመሪያ አዲስ የፊደል ቃላት vector በሚያስተካክሉ ባሕላዊ ቋንቋ ምሳሌዎች ይተካክሉ፤ የፕሮሮግራም-በኋላ-አስተካክል ሞዴል በቋንቋ ምሳሌ ማሳየት እና በሰው ማስታወቂያ ላይ ከፍተኛ ጥሩ ውጤቶችን ይሠራል፡፡ ከዚህም በላይ ምሳሌው አዲስ ማረፊያ vector እንዲያነካው የሚተረጉትን ምናሴዎችን እንደ ቃላት ብጤትና የፍርድ-ደረጃ analog እንዲያሳስብ ነው፡፡</abstract_am>
      <abstract_hy>Մենք առաջարկում ենք նոր սերունդային լեզվի մոդել նախադասությունների համար, որոնք նախ փորձում են մարզի մարզից նախատիպի նախադասությունը և հետո խմբագրում են այն նոր նախադասություն: Համեմատելով ավանդական լեզվի մոդելների հետ, որոնք ստեղծում են զրոյից ձախ դեպի աջ կամ առաջին նմուշ վերցնելով թաքնված նախադասությունների վեկտոր, մեր նախատիպ-ապա-խմբագրման մոդելը բարելավում է լեզվի մոդելների խառնաշփոթը և ստեղծում է մարդկային գնահատման Ավելին, մոդելը ստեղծում է թաքնված խմբագրման վեկտոր, որը ներառում է մեկնաբանելի սեմանտիկա, ինչպիսիք են նախադասությունների նմանությունը և նախադասության մակարդակի նմանությունները:</abstract_hy>
      <abstract_et>Pakume välja uue generatiivse keelemudeli lausetele, mis esmalt proovib prototüüpi lause koolituskorpusest ja seejärel redigeerib selle uueks lauseks. Võrreldes traditsiooniliste keelemudelitega, mis genereerivad nullist kas vasakult paremale või esimese latentse lausevektori proovivõtmise teel, parandab meie prototüüp-seejärel-redigeerimine mudel keele modelleerimise segadust ja loob kvaliteetsemaid väljundeid vastavalt inimhinnangule. Lisaks tekitab mudel latentse redigeerimisvektori, mis tabab tõlgendatavat semantikat, nagu lausete sarnasus ja lausetaseme analoogiad.</abstract_et>
      <abstract_fi>Ehdotamme lauseille uutta generatiivista kielimallia, joka ensin näyttelee harjoituskorpusesta prototyypin lauseen ja sitten muokkaa sen uudeksi lauseeksi. Verrattuna perinteisiin kielimalleihin, jotka tuottavat tyhjästä joko vasemmalta oikealle tai ottamalla ensin näytteitä piilevästä lausevektorista, prototyyppi-sitten-edit-mallimme parantaa kielimallinnuksen hämmennystä ja tuottaa parempia tuloksia ihmisen arvioinnin mukaan. Lisäksi malli synnyttää piilevän muokkausvektorin, joka tallentaa tulkittavissa olevaa semantiikkaa, kuten lauseidensamankaltaisuutta ja lausetason analogiaa.</abstract_fi>
      <abstract_jv>Awak dhéwé ngerasah model sing luwih akeh kanggo sabanjuré nggawe sapur prototype kuwi nggawe cara-cara kuwi nggawe ngubah dhéwé, njuk ngubah dhéwé ngerasah winih dhéwé. Sampling to Traditional language modes that Generate from right-to-right politenessoffpolite"), and when there is a change ("assertive</abstract_jv>
      <abstract_ha>Kana goyyar da wani misali na ƙiro wata cikin harshen mai zartar da shi ga kalmõmi, da kuma za'a sami wani misali na farko daga shirin kwamfyutan ya yi amfani da shi, sa'an nan kuma za'a haƙiya shi cikin wata kalma na dabam. @ label: listbox Furan haka, shirin ya ƙara zuwa wani shiryori na taƙaita na yanzu, mai riƙon wasu masu fassara kamar daidai da maganar da aka yi fassara.</abstract_ha>
      <abstract_he>אנו מציעים דוגמא לשפה דורית חדשה למשפטים שדגימות ראשונה משפט אבטוטיפוס ממחלקת האימון ואז עורכים אותו למשפט חדש. בהשוואה לדוגמאות שפות מסורתיות שמיוצרות מאפס שמאלה ימינה או על ידי דגימה ראשונה נוקטור משפט מוסתר, הדוגמא הארוטוטיפ-ואז-עורך שלנו משפר את התבלבות בנוגע לדוגמאות שפות ויוצר תוצאות איכות גבוהה על פי הערכה האנושית. חוץ מזה, הדוגמא נותנת מקום לוקטור עורך חבוי שמתפס סמנטיקה אפשרית לפרש כמו דומות משפטים ואנלוגיות רמת משפטים.</abstract_he>
      <abstract_sk>Predlagamo nov generativni jezikovni model za stavke, ki najprej vzorči prototipni stavek iz korpusa usposabljanja in ga nato uredi v nov stavek. V primerjavi s tradicionalnimi jezikovnimi modeli, ki ustvarjajo iz nič bodisi od leve proti desni ali s prvim vzorčenjem latentnega vektorja stavka, naš prototip-nato-uredi model izboljšuje zmedenost pri modeliranju jezika in ustvarja višjo kakovost izhodov glede na človeško oceno. Poleg tega model povzroča latentni vektor urejanja, ki zajema razložljivo semantiko, kot sta podobnost stavkov in analogije na ravni stavka.</abstract_sk>
      <abstract_bo>ང་ཚོས་ཚིག Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves the perplexity on language modeling and generates higher quality outputs according to human evaluation. ད་དུང་། མ་དབྱིབས་འདིས་ཕན་ཚུན་ལྡན་པའི་སྔར་སྒྲིག་ཀྱིས་ཕན་ཚུན་རྙེད་ཐུབ་པའི་བརྒྱུད་རིས།</abstract_bo>
      </paper>
    <paper id="32">
      <title>Language Modeling for Morphologically Rich Languages : Character-Aware Modeling for Word-Level Prediction</title>
      <author><first>Daniela</first><last>Gerz</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Edoardo</first><last>Ponti</last></author>
      <author><first>Jason</first><last>Naradowsky</last></author>
      <author><first>Roi</first><last>Reichart</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <doi>10.1162/tacl_a_00032</doi>
      <abstract>Neural architectures are prominent in the construction of language models (LMs). However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set. Indeed, while subword-aware models boost performance across a variety of NLP tasks, previous work did not evaluate the ability of these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to assist next-word prediction in language modeling tasks. Such subword-level informed models should be particularly effective for morphologically-rich languages (MRLs) that exhibit high type-to-token ratios. In this work, we present a large-scale LM study on 50 typologically diverse languages covering a wide variety of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological systems</a>, and offer new LM benchmarks to the community, while considering subword-level information. The main technical contribution of our work is a novel method for injecting subword-level information into semantic word vectors, integrated into the neural language modeling training, to facilitate word-level prediction. We conduct experiments in the LM setting where the number of infrequent words is large, and demonstrate strong perplexity gains across our 50 languages, especially for morphologically-rich languages. Our code and data sets are publicly available.</abstract>
      <pages>451–465</pages>
      <url hash="8c554ad3">Q18-1032</url>
      <bibkey>gerz-etal-2018-language</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    <title_ar>نمذجة اللغة للغات الغنية شكليًا: النمذجة المدركة للشخصية للتنبؤ على مستوى الكلمات</title_ar>
      <title_fr>Modélisation linguistique pour les langues morphologiquement riches : modélisation sensible aux caractères pour la prédiction au niveau des mots</title_fr>
      <title_es>Modelado del lenguaje para lenguajes morfológicamente ricos: modelado con reconocimiento de caracteres para la predicción a nivel de palabras</title_es>
      <title_pt>Modelagem de linguagem para linguagens morfologicamente ricas: modelagem com reconhecimento de caracteres para previsão em nível de palavra</title_pt>
      <title_ja>形態論的に豊かな言語のための言語モデリング：単語レベルの予測のための文字意識モデリング</title_ja>
      <title_zh>语言建模:字级符感建模</title_zh>
      <title_hi>रूपात्मक रूप से समृद्ध भाषाओं के लिए भाषा मॉडलिंग: वर्ड-स्तर की भविष्यवाणी के लिए चरित्र-जागरूक मॉडलिंग</title_hi>
      <title_ru>Языковое моделирование для морфологически насыщенных языков: персонажевое моделирование для прогнозирования на уровне слов</title_ru>
      <title_ga>Samhaltú Teanga do Theangacha atá Saibhir Moirfeolaíoch: Samhaltú atá Feasach ar Charachtar le haghaidh Réamhinsint ar Leibhéal na bhFocal</title_ga>
      <title_el>Μοντελοποίηση γλωσσών για Μορφολογικά πλούσιες γλώσσες: Μοντελοποίηση χαρακτήρων για πρόβλεψη επιπέδου λέξης</title_el>
      <title_ka>Language Modeling for Morphologically Rich Languages: Character- Aware Modeling for Word- Level Prediction</title_ka>
      <title_hu>Nyelvmodellezés morfológiailag gazdag nyelvekhez: Karaktertudatos modellezés szószintű előrejelzéshez</title_hu>
      <title_it>Modellazione linguistica per lingue morfologicamente ricche: Modellazione consapevole dei caratteri per predizione a livello di parola</title_it>
      <title_lt>Kalbos modeliavimas morfologiškai turtingoms kalboms: charakteristikų sąmoningas modeliavimas žodžių lygio prognozėms</title_lt>
      <title_mk>Моделирање на јазик за морфолошки богати јазици: Моделирање на знаци за предвидување на ниво на зборови</title_mk>
      <title_kk>Марфологикалық байланысты тілдер үлгісі: Character- Aware Modeling for Word- Level Prediction</title_kk>
      <title_mt>Mudellar tal-lingwi għal-lingwi morfoloġikament rikki: Mudellar konxju tal-Karatteri għat-Tbassir tal-Livell tal-Kliem</title_mt>
      <title_ms>Modeling Bahasa untuk Bahasa Berkaya Morfologik: Modeling Sedia Aksara untuk Prediksi Aras-Kata</title_ms>
      <title_ml>മോര്‍ഫോളോഗിക്കല്‍ സമ്പന്നതയുള്ള ഭാഷകള്‍ക്കുള്ള ഭാഷകളുടെ മോഡോളിങ്ങ്: വാക്ക്- നില മോഡില്‍ വാക്കുകള്‍</title_ml>
      <title_no>Språk- modellering for morfologisk rikte språk: Teikn- vekk- modellering for ordnivåforhåndsvising</title_no>
      <title_mn>Марфологик баян хэлний хэл загвар: Character-Aware Modeling for Word-Level Prediction</title_mn>
      <title_pl>Modelowanie języków dla języków bogatych morfologicznie: Modelowanie znaków dla prognozowania poziomu słowa</title_pl>
      <title_sr>Modeliranje jezika za morfološki bogate jezike: Modeliranje znakova za predviđanje na nivou reči</title_sr>
      <title_ro>Modelare lingvistică pentru limbi bogate morfologic: Modelare conștientă de caractere pentru predicția la nivel de cuvânt</title_ro>
      <title_so>Modeling for Morphologically Rich language: Character-aware Modeling for Word-Level Prediction</title_so>
      <title_si>Name</title_si>
      <title_sv>Språkmodellering för morfologiskt rika språk: Teckenmedveten modellering för förutsägelse på ordnivå</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>Name</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Chế độ ngôn ngữ cho ngôn ngữ Morpholo Rich Ngôn ngữ: Ký tự-Nhận Dạng cho dự đoán từ cấp</title_vi>
      <title_bg>Езиково моделиране за морфологично богати езици: моделиране с знаци за прогнозиране на ниво дума</title_bg>
      <title_da>Sprogmodellering for morfologisk rige sprog: Tegnbevidst modellering for forudsigelse af ordniveau</title_da>
      <title_hr>Modeliranje jezika za morfološki bogate jezike: Modeliranje znakova za predviđanje riječi na nivou</title_hr>
      <title_nl>Taalmodellering voor morfologisch rijke talen: karakterbewuste modellering voor voorspellingen op woordniveau</title_nl>
      <title_de>Sprachmodellierung für morphologisch reiche Sprachen: Charakterbasierte Modellierung für Vorhersagen auf Word-Ebene</title_de>
      <title_ko>형태가 풍부한 언어의 언어 모델링: 단어급 예측의 문자 감지 모델링</title_ko>
      <title_fa>Modeling Language for Morphologically Rich Languages: Character-Aware Modeling for Word-Level Prediction</title_fa>
      <title_id>Modeling Bahasa untuk Bahasa Morfologis Kaya: Modeling Awas-Karakter untuk Prediksi Tingkat Kata</title_id>
      <title_sw>Utawala wa lugha kwa lugha za Kimorphologically Rich Lugha: Character-aware Modeling for Word-Level Prediction</title_sw>
      <title_sq>Modelimi i gjuhës për gjuhët morfologjikisht të pasura: Modelimi i njohur me karakter për parashikimin e nivelit të fjalëve</title_sq>
      <title_tr>_Diller</title_tr>
      <title_af>Taal Modelering vir Morphologically Rich Languages: Character- Aware Modeling for Word- Level Prediction</title_af>
      <title_am>Character-aware Modeling for Word-Level Prediction</title_am>
      <title_bn>Name</title_bn>
      <title_hy>Լեզու մոդելավորումը բարեբավարար լեզուների համար. բառերի մակարդակի կանխատեսման մոդելավորումը</title_hy>
      <title_bs>Modeliranje jezika za morfološki bogate jezike: Modeliranje znakova za predviđanje na nivou riječi</title_bs>
      <title_ca>Modell de llengües per llengües morfològicament rics: Modell conscient del caràcter per predicció de nivell de paraules</title_ca>
      <title_cs>Jazykové modelování pro morfologicky bohaté jazyky: znakové modelování pro predikci na úrovni slova</title_cs>
      <title_az>Morphologically Rich Dillər üçün Dil Modeling: Character-Aware Modeling for Word-Level Prediction</title_az>
      <title_et>Keele modelleerimine morfoloogiliselt rikkatele keeltele: märgiteadlik modelleerimine sõnataseme prognoosimiseks</title_et>
      <title_fi>Kielimallinnus morfologisesti rikkaille kielille: Merkkitietoinen mallinnus sanatason ennustamiseen</title_fi>
      <title_jv>Language</title_jv>
      <title_he>מודל שפות לשפות עשירות מורפולוגית: מודל מודע לכמויות לטיפול רמה מילים</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Jezikovno modeliranje za morfološko bogate jezike: modeliranje znakov za napovedovanje besedne ravni</title_sk>
      <title_bo>ཆེ་མཐོང་ནུས་པའི་སྐད་རིགས་Modeling for Morphologically Rich Languages: Character-Aware Modeling for Word-Level Prediction</title_bo>
      <abstract_fr>Les architectures neuronales jouent un rôle prépondérant dans la construction de modèles de langage (LM). Cependant, la prédiction au niveau des mots est généralement indépendante des informations au niveau des sous-mots (caractères et séquences de caractères) et fonctionne sur un vocabulaire fermé, constitué d'un ensemble de mots limité. En effet, alors que les modèles prenant en charge les sous-mots améliorent les performances pour une variété de tâches de PNL, les travaux précédents n'évaluaient pas la capacité de ces modèles à aider à la prédiction du mot suivant dans les tâches de modélisation linguistique. Ces modèles éclairés au niveau des sous-mots devraient être particulièrement efficaces pour les langues morphologiquement riches (LMR) qui présentent des rapports type/jeton élevés. Dans ce travail, nous présentons une étude LM à grande échelle sur 50 langues typologiquement diverses couvrant une grande variété de systèmes morphologiques, et proposons de nouveaux points de référence LM à la communauté, tout en tenant compte des informations au niveau des sous-mots. La principale contribution technique de nos travaux est une nouvelle méthode d'injection d'informations au niveau des sous-mots dans des vecteurs de mots sémantiques, intégrée dans la formation à la modélisation du langage neuronal, afin de faciliter la prédiction au niveau des mots. Nous menons des expériences dans le contexte de LM où le nombre de mots peu fréquents est important, et nous démontrons de forts gains de perplexité dans nos 50 langues, en particulier pour les langues riches en morphologie. Notre code et nos ensembles de données sont accessibles au public.</abstract_fr>
      <abstract_ar>تعتبر البنى العصبية بارزة في بناء النماذج اللغوية (LMs). ومع ذلك ، فإن التنبؤ على مستوى الكلمة عادة ما يكون محايدًا للمعلومات على مستوى الكلمات الفرعية (الأحرف وتسلسل الأحرف) ويعمل على مفردات مغلقة ، تتكون من مجموعة كلمات محدودة. في الواقع ، بينما تعمل النماذج المدركة للكلمات الفرعية على تعزيز الأداء عبر مجموعة متنوعة من مهام البرمجة اللغوية العصبية ، لم يقم العمل السابق بتقييم قدرة هذه النماذج على مساعدة التنبؤ بالكلمة التالية في مهام نمذجة اللغة. يجب أن تكون هذه النماذج المستنيرة على مستوى الكلمات الفرعية فعالة بشكل خاص للغات الغنية شكليًا (MRLs) التي تعرض نسبًا عالية من النوع إلى الرمز المميز. في هذا العمل ، نقدم دراسة LM واسعة النطاق على 50 لغة متنوعة نسبيًا تغطي مجموعة واسعة من الأنظمة الصرفية ، ونقدم معايير LM جديدة للمجتمع ، مع مراعاة المعلومات على مستوى الكلمات الفرعية. المساهمة التقنية الرئيسية لعملنا هي طريقة جديدة لحقن معلومات على مستوى الكلمات الفرعية في ناقلات الكلمات الدلالية ، المدمجة في تدريب نمذجة اللغة العصبية ، لتسهيل التنبؤ على مستوى الكلمات. نجري تجارب في إعداد LM حيث يكون عدد الكلمات النادرة كبيرًا ، ونظهر مكاسب قوية من الارتباك عبر 50 لغة لدينا ، خاصة للغات الغنية شكليًا. كودنا ومجموعات البيانات متاحة للجمهور.</abstract_ar>
      <abstract_es>Las arquitecturas neuronales ocupan un lugar destacado en la construcción de modelos de lenguaje (LM). Sin embargo, la predicción a nivel de palabra es típicamente independiente de la información a nivel de subpalabra (caracteres y secuencias de caracteres) y opera sobre un vocabulario cerrado, que consiste en un conjunto de palabras limitado. De hecho, si bien los modelos con conciencia de subpalabras aumentan el rendimiento en una variedad de tareas de PNL, el trabajo anterior no evaluó la capacidad de estos modelos para ayudar a la predicción de la siguiente palabra en las tareas de modelado del lenguaje. Estos modelos informados a nivel de subpalabras deberían ser particularmente eficaces para los lenguajes ricos en morfología (LMR) que exhiben altas proporciones de tipo a token. En este trabajo, presentamos un estudio de ML a gran escala sobre 50 idiomas tipológicamente diversos que cubren una amplia variedad de sistemas morfológicos, y ofrecemos nuevos puntos de referencia de ML a la comunidad, al tiempo que consideramos la información a nivel de subpalabras. La principal contribución técnica de nuestro trabajo es un método novedoso para inyectar información a nivel de subpalabra en vectores de palabras semánticas, integrado en el entrenamiento de modelado del lenguaje neuronal, para facilitar la predicción a nivel de palabras. Llevamos a cabo experimentos en el entorno de LM donde el número de palabras poco frecuentes es grande y demostramos grandes ganancias de perplejidad en nuestros 50 idiomas, especialmente en el caso de los idiomas ricos en morfología. Nuestros conjuntos de códigos y datos están disponibles públicamente.</abstract_es>
      <abstract_pt>As arquiteturas neurais são proeminentes na construção de modelos de linguagem (LMs). No entanto, a previsão em nível de palavra é tipicamente agnóstica de informações em nível de subpalavra (caracteres e sequências de caracteres) e opera em um vocabulário fechado, consistindo em um conjunto limitado de palavras. De fato, enquanto os modelos com reconhecimento de subpalavras aumentam o desempenho em uma variedade de tarefas de PNL, trabalhos anteriores não avaliaram a capacidade desses modelos de auxiliar a previsão da próxima palavra em tarefas de modelagem de linguagem. Esses modelos informados em nível de subpalavra devem ser particularmente eficazes para linguagens morfologicamente ricas (MRLs) que exibem altas proporções de tipo para token. Neste trabalho, apresentamos um estudo de LM em larga escala em 50 linguagens tipologicamente diversas cobrindo uma ampla variedade de sistemas morfológicos e oferecemos novos benchmarks de LM para a comunidade, considerando informações em nível de subpalavras. A principal contribuição técnica de nosso trabalho é um novo método para injetar informações em nível de subpalavra em vetores semânticos de palavras, integrado ao treinamento de modelagem de linguagem neural, para facilitar a previsão em nível de palavra. Conduzimos experimentos no cenário LM, onde o número de palavras infrequentes é grande e demonstramos fortes ganhos de perplexidade em nossos 50 idiomas, especialmente para idiomas morfologicamente ricos. Nosso código e conjuntos de dados estão disponíveis publicamente.</abstract_pt>
      <abstract_ja>言語モデル（ LM ）の構築においては、ニューラルアーキテクチャが顕著である。 しかしながら、単語レベルの予測は、典型的には、サブワードレベルの情報（文字および文字シーケンス）の不可知論的なものであり、限定された単語セットからなる閉じた語彙上で動作する。 実際、サブワード認識モデルは、さまざまなNLPタスク全体のパフォーマンスを向上させるが、以前の研究では、言語モデリングタスクにおける次の単語予測を支援するこれらのモデルの能力を評価しなかった。 このようなサブワードレベルの情報モデルは、高いタイプ対トークン比を示す形態豊富な言語（ MRL ）に特に効果的であるべきである。 本研究では、多種多様な形態学的システムをカバーする50のタイプ多様な言語に関する大規模なLM研究を提示し、サブワードレベルの情報を考慮しながら、コミュニティに新しいLMベンチマークを提供する。 私たちの仕事の主な技術的貢献は、神経言語モデリングトレーニングに統合された、意味論的な単語ベクトルにサブワードレベルの情報を注入して、単語レベルの予測を容易にするための新規の方法です。 私たちは、頻度の低い単語の数が多いLM環境で実験を行い、特に形態的に豊富な言語では、50の言語にわたって強い困惑の利得を示します。 当社のコードとデータセットは一般に公開されています。</abstract_ja>
      <abstract_hi>तंत्रिका आर्किटेक्चर भाषा मॉडल (एलएम) के निर्माण में प्रमुख हैं। हालांकि, शब्द-स्तर की भविष्यवाणी आमतौर पर सबवर्ड-स्तर की जानकारी (वर्ण और चरित्र अनुक्रम) का अज्ञेयवादी है और एक बंद शब्दावली पर संचालित होती है, जिसमें एक सीमित शब्द सेट होता है। दरअसल, जबकि सबवर्ड-जागरूक मॉडल विभिन्न प्रकार के एनएलपी कार्यों में प्रदर्शन को बढ़ावा देते हैं, पिछले काम ने भाषा मॉडलिंग कार्यों में अगले शब्द की भविष्यवाणी की सहायता करने के लिए इन मॉडलों की क्षमता का मूल्यांकन नहीं किया था। इस तरह के सबवर्ड-स्तरीय सूचित मॉडल रूपात्मक रूप से समृद्ध भाषाओं (एमआरएल) के लिए विशेष रूप से प्रभावी होने चाहिए जो उच्च प्रकार-से-टोकन अनुपात प्रदर्शित करते हैं। इस काम में, हम 50 टाइपोलॉजिकल रूप से विविध भाषाओं पर एक बड़े पैमाने पर एलएम अध्ययन प्रस्तुत करते हैं जो विभिन्न प्रकार की रूपात्मक प्रणालियों को कवर करते हैं, और उप-शब्द-स्तर की जानकारी पर विचार करते हुए समुदाय को नए एलएम बेंचमार्क प्रदान करते हैं। हमारे काम का मुख्य तकनीकी योगदान शब्द-स्तर की भविष्यवाणी को सुविधाजनक बनाने के लिए, तंत्रिका भाषा मॉडलिंग प्रशिक्षण में एकीकृत, शब्दार्थ शब्द वैक्टर में सबवर्ड-स्तर की जानकारी को इंजेक्ट करने के लिए एक उपन्यास विधि है। हम एलएम सेटिंग में प्रयोग करते हैं जहां अक्सर शब्दों की संख्या बड़ी होती है, और हमारी 50 भाषाओं में मजबूत उलझन लाभ प्रदर्शित करते हैं, विशेष रूप से रूपात्मक रूप से समृद्ध भाषाओं के लिए। हमारे कोड और डेटा सेट सार्वजनिक रूप से उपलब्ध हैं।</abstract_hi>
      <abstract_ru>Нейронные архитектуры занимают видное место в построении языковых моделей (ЛМ). Тем не менее, прогнозирование на уровне слов, как правило, является агностическим по отношению к информации на уровне подслова (символы и последовательности символов) и работает над закрытым словарным запасом, состоящим из ограниченного набора слов. Действительно, в то время как модели, основанные на подсловах, повышают производительность для различных задач NLP, предыдущая работа не оценивала способность этих моделей помогать прогнозированию следующего слова в задачах языкового моделирования. Такие модели, основанные на подсловах, должны быть особенно эффективными для морфологически богатых языков (MRL), которые демонстрируют высокие отношения типа к токену. В этой работе мы представляем масштабное исследование LM на 50 типологически разнообразных языках, охватывающих широкий спектр морфологических систем, и предлагаем новые эталоны LM сообществу, рассматривая информацию на уровне подслова. Основным техническим вкладом нашей работы является новый метод впрыскивания информации на уровне подслова в семантические векторы слов, интегрированные в обучение моделированию нейронного языка, для облегчения прогнозирования на уровне слова. Мы проводим эксперименты в среде LM, где количество редких слов велико, и демонстрируем сильный рост недоумения среди наших 50 языков, особенно для морфологически богатых языков. Наш код и наборы данных являются общедоступными.</abstract_ru>
      <abstract_zh>神经架构于语言模样(LM)构中甚异。 然单词级测常与子词级信息(字符与字符序)无关,且于有限单词集之封闭词汇表上行。 虽子词知范之可以益NLP,而前事未尝质其言建模助一单词之能也。 此词级知情形之见于高者(MRL)宜特效。 于是条上50种类型学上语言之大LM,涵盖其形势,资其新社区LM,兼虑子词级息。 要术者,将子词级信注语义词向量新法,集神经言建模训练,以促词级占。 吾实验于LM,其不常见单词之数甚大,而困益于吾50之强言,尤多于形容之语。 吾代码数集是明矣。</abstract_zh>
      <abstract_ga>Tá ailtireachtaí néaracha chun tosaigh i dtógáil na samhlacha teanga (LMs). Mar sin féin, is gnách go mbíonn tuar ar leibhéal na bhfocal agnostic ar fhaisnéis leibhéal fofhocail (carachtair agus seichimh charachtair) agus feidhmíonn sé thar stór focal dúnta, comhdhéanta de thacar teoranta focal. Go deimhin, cé go gcuireann samhlacha atá feasach ar fhofhocail le feidhmíocht thar raon de thascanna NLP, ní dhearna obair roimhe seo measúnú ar chumas na múnlaí seo cabhrú le réamhfhocail an chéad fhocail eile i dtascanna samhaltaithe teanga. Ba cheart go mbeadh múnlaí eolasacha ar leibhéal na bhfocal den sórt sin éifeachtach go háirithe do theangacha atá saibhir ó thaobh moirfeolaíochta (MRLanna) a léiríonn cóimheasa arda cineál-go-deimhniú. San obair seo, cuirimid i láthair staidéar LM ar mhórscála ar 50 teanga atá éagsúil ó thaobh na tíopeolaíochta de a chlúdaíonn raon leathan de chórais mhoirfeolaíocha, agus tairgimid tagarmharcanna LM nua don phobal, agus faisnéis ag leibhéal na bhfofhocail á meas againn. Is é príomh-ranníocaíocht theicniúil ár gcuid oibre ná modh nua chun faisnéis ag leibhéal fofhocail a instealladh isteach i veicteoirí shéimeantacha focal, arna lánpháirtiú san oiliúint samhaltaithe teanga néarach, chun tuar ar leibhéal na bhfocal a éascú. Déanaimid turgnaimh i suíomh LM áit a bhfuil líon na bhfocal neamhchoitianta mór, agus léirímid gnóthachain tréana imphléacsachta ar fud ár 50 teanga, go háirithe do theangacha atá saibhir ó thaobh moirfeolaíochta de. Tá ár gcód agus tacair sonraí ar fáil go poiblí.</abstract_ga>
      <abstract_el>Οι νευρωνικές αρχιτεκτονικές είναι εμφανείς στην κατασκευή γλωσσικών μοντέλων (LM). Ωστόσο, η πρόβλεψη σε επίπεδο λέξεων είναι τυπικά αγνωστική των πληροφοριών σε επίπεδο υπολέξεων (χαρακτήρες και ακολουθίες χαρακτήρων) και λειτουργεί πάνω από ένα κλειστό λεξιλόγιο, που αποτελείται από ένα περιορισμένο σύνολο λέξεων. Πράγματι, ενώ τα μοντέλα επίγνωσης των υπολέξεων ενισχύουν την απόδοση σε μια ποικιλία εργασιών Η προηγούμενη εργασία δεν αξιολόγησε την ικανότητα αυτών των μοντέλων να βοηθούν την πρόβλεψη της επόμενης λέξης σε εργασίες μοντελοποίησης γλωσσών. Τέτοια ενημερωμένα μοντέλα σε επίπεδο υπολέξεων θα πρέπει να είναι ιδιαίτερα αποτελεσματικά για μορφολογικά πλούσιες γλώσσες (ΑΟΚ) που παρουσιάζουν υψηλές αναλογίες τύπου προς σήματος. Στην παρούσα εργασία, παρουσιάζουμε μια μεγάλης κλίμακας μελέτη για 50 τυπολογικά διαφορετικές γλώσσες που καλύπτει μια μεγάλη ποικιλία μορφολογικών συστημάτων, και προσφέρουμε νέα σημεία αναφοράς στην κοινότητα, λαμβάνοντας υπόψη πληροφορίες σε επίπεδο υπολέξεων. Η κύρια τεχνική συνεισφορά της εργασίας μας είναι μια νέα μέθοδος για την έγχυση πληροφοριών σε επίπεδο υπολέξεων σε σημασιολογικά διανύσματα λέξεων, ενσωματωμένη στην εκπαίδευση μοντελοποίησης νευρωνικής γλώσσας, για τη διευκόλυνση της πρόβλεψης σε επίπεδο λέξης. Διεξάγουμε πειράματα στο περιβάλλον όπου ο αριθμός των σπάνιων λέξεων είναι μεγάλος και καταδεικνύουμε ισχυρά κέρδη σύγχυσης στις 50-γλώσσες μας, ειδικά στις μορφολογικά πλούσιες γλώσσες. Ο κώδικας και τα σύνολα δεδομένων μας είναι δημόσια διαθέσιμα.</abstract_el>
      <abstract_hu>A neurális architektúrák kiemelkedőek a nyelvi modellek (LM) építésében. A szószintű előrejelzés azonban jellemzően agnosztikus az alszószintű információkhoz (karakterekhez és karaktersorozatokhoz) és zárt szókincsen működik, amely korlátozott szóhalmazból áll. Valójában, míg az alszó-tudatos modellek növelik a teljesítményt a különböző NLP-feladatokban, a korábbi munkák nem értékelték, hogy ezek a modellek képesek-e segíteni a következő szó előrejelzését a nyelvmodellezési feladatokban. Az ilyen alszó-szintű tájékoztatott modelleknek különösen hatékonynak kell lenniük a morfológiailag gazdag nyelvek (MRL) esetében, amelyek magas típus-token arányt mutatnak. Ebben a munkában egy nagyszabású LM tanulmányt mutatunk be 50 tipológiailag különböző nyelven, amely lefedi a morfológiai rendszerek széles választékát, és új LM referenciaértékeket kínálunk a közösségnek, miközben figyelembe vesszük az alszó szintű információkat. Munkánk fő technikai hozzájárulása egy új módszer az alszó-szintű információk szemantikus szóvektorokba történő injektálására, amely integrált az idegi nyelvmodellezési képzésbe, hogy megkönnyítse a szó-szintű előrejelzést. Kísérleteket végzünk LM környezetben, ahol a ritka szavak száma nagy, és erős zavarban mutatunk 50 nyelvünkön, különösen morfológiailag gazdag nyelvek esetében. Kódunk és adatkészleteink nyilvánosan hozzáférhetők.</abstract_hu>
      <abstract_ka>ნეირალური არქტიქტურები მნიშვნელოვანია ენის მოდელების შექმნა (LMs). მაგრამ, სიტყვის დონეზე წარმოდგენა ტიპოლურად აგნოსტიურია საბუტატური დონეზე ინფორმაციის (სიტყვის და სიტყვის წარმოდგენების) და მუშაობა დახურებული სიტყვის, რო ნამდვილად, როცა სუბსიტყვანის მოდელები NLP მოქმედების განსხვავებულობაში უფრო მეტად მოქმედება, წინა სამუშაო მოდელების შესაძლებლობა შემდეგ სიტყვანის წინასწარმოდგენება ენის მოდელ ასეთი სუბსიტყვანის სუბსიტყვანის ინფორმაციული მოდელები უნდა იყოს განსაკუთრებით ეფექტიური მოპოროლოგიურად ღარიბული ენებისთვის (MRLs) რომელიც გამოჩვენებენ მაღალი ამ სამუშაოში, ჩვენ 50 ტიპოლოგიურად განსხვავებული ენების შესახებ დიდი სწავლა LM სწავლა, რომელიც უფრო განსხვავებული მორპოლოგიური სისტემების განსხვავებულია, და საზოგადოებაში ახალი LM ბენქმარი ჩვენი სამუშაო მუშაო ტექნიკური დამატება არის პრომენტი მეტი, რომელიც სამუშაო სიტყვების ინფორმაციას სემონტიკური სიტყვების გვექტორებში ინტერგურაცია, რომელიც ნეიროლურ ჩვენ ვაკეთებთ ექსპერიმენტები LM-ში, რომელიც შემდეგ სიტყვების რაოდენობა დიდია, და გამოჩვენება ძალიან პროპლექტიური მიღება ჩვენი 50 ენაში, განსაკუთრებით მორპოლოგიურად ღარ ჩვენი კოდი და მონაცემების კოდეები ადგილურად ხელსახულია.</abstract_ka>
      <abstract_it>Le architetture neurali sono prominenti nella costruzione di modelli linguistici (LM). Tuttavia, la previsione a livello di parola è tipicamente agnostica delle informazioni a livello di subparola (caratteri e sequenze di caratteri) e opera su un vocabolario chiuso, costituito da un insieme limitato di parole. Infatti, mentre i modelli subword-aware migliorano le prestazioni in una varietà di attività NLP, i lavori precedenti non hanno valutato la capacità di questi modelli di aiutare la previsione delle parole successive nelle attività di modellazione linguistica. Tali modelli informati a livello di subparola dovrebbero essere particolarmente efficaci per i linguaggi morfologicamente ricchi (LMR) che presentano elevati rapporti tipo-token. In questo lavoro, presentiamo uno studio LM su larga scala su 50 lingue tipologicamente diverse che coprono un'ampia varietà di sistemi morfologici, e offriamo nuovi benchmark LM alla comunità, considerando le informazioni a livello di sottoparola. Il principale contributo tecnico del nostro lavoro è un nuovo metodo per iniettare informazioni a livello di subparola nei vettori semantici di parole, integrato nella formazione di modellazione del linguaggio neurale, per facilitare la previsione a livello di parola. Conduciamo esperimenti nell'ambiente LM dove il numero di parole rare è grande, e dimostriamo forti guadagni di perplessità nelle nostre 50 lingue, specialmente per le lingue ricche di morfologia. Il nostro codice e i nostri set di dati sono disponibili pubblicamente.</abstract_it>
      <abstract_mk>Неуралните архитектури се истакнати во изградбата на јазичките модели. Сепак, предвидувањето на ниво на зборови е обично агностично на информации на ниво на подзборови (знаци и секвенци на знаци) и функционира преку затворен речник, кој се состои од ограничен набор зборови. Всушност, иако моделите свесни за подзборови ја зајакнуваат перформансата во различни задачи на НЛП, претходната работа не ја процени способноста на овие модели да помогнат со предвидувањето на следните зборови во задачите за моделирање на јазиците. Таквите информирани модели на ниво на подзборови треба да бидат особено ефикасни за морфолошки богатите јазици (МРЛ) кои покажуваат високи односи од тип до token. Во оваа работа, претставуваме голема студија на ЛМ на 50 типологички различни јазици кои покриваат широка различност на морфолошки системи, и понудуваме нови референтни значки за ЛМ на заедницата, при што разгледуваме информации на ниво на подзборови. Главниот технички придонес на нашата работа е нов метод за инјектирање информации на ниво на подзборови во семантични вектори на зборови, интегрирани во тренингот за моделирање на нервниот јазик, за олеснување на предвидувањето на ниво на зборови. Ние спроведуваме експерименти во рамките на ЛМ каде бројот на ретки зборови е голем, и демонстрираме силни збркувања во нашите 50 јазици, особено за морфолошки богати јазици. Нашите кодови и податоци се јавно достапни.</abstract_mk>
      <abstract_kk>Невралдық архитектуралар тіл үлгілерін құру үшін (LMs) маңызды. Бірақ сөздердің деңгейінің бақылауы әдетте сөздер деңгейінің (таңбалар мен таңбалар ретінде) мәліметін агностикалық болып, сөздердің шектелген сөздердің үстінде жұмыс істейді. Алдыңғы жұмыс NLP тапсырмаларының түрлі ішкі сөздер үлгілерін көтергенде, бұл үлгілердің келесі сөздер үлгілеу тапсырмаларында келесі үлгілерді бағалау мүмкіндігін бағаламады. Бұл ішкі сөздер деңгейіндегі мәліметті үлгілер морфологиялық баяны тілдер (MRL) үшін әсер ететін болуы керек. Бұл үлгілер үлгілері көп түрлі мен токен қатынасын көрсе Бұл жұмыста, 50 типтологиялық түрлі тілдер туралы көптеген морфологиялық жүйелер туралы үлкен LM зерттеулерін таңдап, жаңа LM белгілерін қоғамдастырып, субсөздің деңгейінің мәліметін қарастыруға болады Жұмысының негізгі техникалық қатынасы - сөздер деңгейіндегі мәліметті семантикалық сөздер векторына инжекциялау әдісі, невралдық тілдерді моделеу оқыту үшін, сөздер деңгейіндегі мәліметті Біз LM баптауындағы тәжірибелерді орындаймыз, олардың саны үлкен болып, 50 тілдерімізде күшті тәжірибелерді көрсетеді, осылай-ақ морфологиялық баяны тілдер үшін. Код мен деректер жинақтарымыз көпшілікті қол жеткізеді.</abstract_kk>
      <abstract_ms>Arkitektur saraf adalah terkenal dalam pembangunan model bahasa (LMs). Namun, ramalan aras perkataan biasanya agnostik maklumat aras subperkataan (aksara dan urutan aksara) dan berfungsi melalui vokbulari tertutup, yang terdiri dari set perkataan yang terbatas. Sebenarnya, walaupun model sedar-subword meningkatkan prestasi melalui pelbagai tugas NLP, kerja sebelumnya tidak menilai kemampuan model ini untuk membantu ramalan perkataan seterusnya dalam tugas pemodelan bahasa. Model yang diberitahu aras-subkata tersebut seharusnya sangat berkesan untuk bahasa yang kaya secara morfologik (MRL) yang menunjukkan nisbah jenis-ke-token yang tinggi. Dalam kerja ini, kami memperkenalkan kajian LM skala besar pada 50 bahasa yang berbeza secara tipologi yang meliputi berbagai sistem morfologi, dan menawarkan tanda referensi LM baru kepada komuniti, sementara mempertimbangkan maklumat aras subkata. Kontribusi teknikal utama kerja kita adalah kaedah baru untuk menyuntik maklumat aras-subkata ke dalam vektor perkataan semantik, terpisah ke dalam latihan model bahasa saraf, untuk memudahkan ramalan aras-perkataan. Kami melakukan eksperimen dalam tetapan LM di mana bilangan perkataan yang tidak sering besar, dan menunjukkan kekuatan kekacauan yang kuat di seluruh 50 bahasa kami, terutama untuk bahasa yang kaya secara morfologik. Our code and data sets are publicly available.</abstract_ms>
      <abstract_ml>ഭാഷ മോഡലുകളുടെ നിര്‍മ്മാണിയ്ക്കുന്നതില്‍ നെയുറല്‍ ആര്‍ക്കിട്ടുകള്‍ പ്രധാനപ്പെട്ടിരിക്കുന്നു. എന്നാലും വാക്ക്- നില പ്രവചനം സാധാരണ വാക്ക് നില വിവരങ്ങളുടെ (അക്ഷരങ്ങളും അക്ഷരത്തിന്റെ സെക്കന്റുകളും) അടച്ച വാക്കുകളില്‍ പ്രവര്‍ത്തിക്കുകയും, ഒര യഥാര്‍ത്ഥത്തില്‍, വ്യത്യസ്ത വാക്കുകളുടെ മോഡലുകള്‍ NLP ജോലികളിലൂടെ പ്രവര്‍ത്തിപ്പിക്കുമ്പോള്‍, മുമ്പ് ജോലി മോഡലുകളുടെ അടുത്ത വാക്ക് പ് ഇത്തരം സബ്വോര്‍ഡ് നില വിവരമറിയിക്കപ്പെട്ട മോഡലുകള്‍ മോര്‍ഫോളജിക്കല്‍ സമ്പന്നതയുള്ള ഭാഷകള്‍ക്ക് പ്രത്യേക പ്രാവര്‍ത്തമായിരിക്കണം.  ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ 50 സാധാരണ വ്യത്യസ്ത ഭാഷകളില്‍ ഒരു വലിയ എല്‍എംഎം പഠിപ്പിക്കുന്നു. ഒരു വിവിധ വ്യത്യസ്ത ഭാഷകള്‍ വെളിപ്പെടുത്തുന്നു. ഒരു വ നമ്മുടെ ജോലിയുടെ പ്രധാന സാങ്കേതിക വാക്ക് വെക്ടറുകളിലേക്ക് വിവരങ്ങള്‍ ഉള്‍പ്പെടുത്തുന്നതിനുള്ള പ്രധാന പദാര്‍ത്ഥത്തിന്റെ പ്രധാനപ് നമ്മുടെ 50 ഭാഷകളിലൂടെ ശക്തിയുള്ള വാക്കുകളുടെ എണ്ണം വലുതാണെന്നും, പ്രത്യേകിച്ചും മോര്‍ഫോളജിക്കല്‍ സമ്പന്നതയുള്ള ഭാഷകള്‍ക്കും നമ്മുടെ  നമ്മുടെ കോഡും ഡേറ്റാ സജ്ജീകരണങ്ങളും പ്രസിദ്ധമാണ്.</abstract_ml>
      <abstract_lt>Neural in ės architektūros yra svarbios kuriant kalbų modelius. Vis dėlto žodžių lygio prognozė paprastai yra agnostinė informacija apie požymių lygį (simboliai ir simbolių sekos) ir veikia uždarame žodyne, kurį sudaro ribotas žodžių rinkinys. Indeed, while subword-aware models boost performance across a variety of NLP tasks, previous work did not evaluate the ability of these models to assist next-word prediction in language modeling tasks.  Tokie subžodžių lygiu pagrįsti modeliai turėtų būti ypač veiksmingi morfologiškai turtingoms kalboms (DLK), kurioms būdingas didelis tipo ir ženklo santykis. Šiame darbe pristatome plataus masto LM tyrimą apie 50 tipologiškai įvairaus pobūdžio kalbų, apimančių įvairias morfologines sistemas, ir siūlome bendruomenei naujus LM lyginamuosius rodiklius, kartu svarstant informaciją žodžių lygmeniu. Pagrindinis mūsų darbo techninis įnašas yra naujas metodas, kaip į semantinius žodžių vektorius sušvirkšti informaciją apie subžodžių lygį, integruotą į mokymą modeliuoti nervines kalbas, siekiant palengvinti žodžių lygį prognozavimą. Atliekame eksperimentus LM aplinkoje, kur nedažnų žodžių skaičius yra didelis, ir parodome, kad mūsų 50 kalbų, ypač morfologiškai turtingų kalbų, labai susipainioja. Our code and data sets are publicly available.</abstract_lt>
      <abstract_mt>L-arkitetturi newrali huma prominenti fil-kostruzzjoni ta’ mudelli lingwistiċi (LMs). Madankollu, it-tbassir fil-livell tal-kliem huwa tipikament agnostiku ta’ informazzjoni fil-livell tas-subkliem (karattri u sekwenzi ta’ karattri) u jopera fuq vokabulari magħluq, li jikkonsisti f’sett limitat ta’ kliem. Indeed, while subword-aware models boost performance across a variety of NLP tasks, previous work did not evaluate the ability of these models to assist next-word prediction in language modeling tasks.  Dawn il-mudelli infurmati fil-livell ta’ subkliem għandhom ikunu partikolarment effettivi għal-lingwi morfoloġikament rikki (MRLs) li juru proporzjonijiet għoljin bejn it-tip u t-token. F’dan ix-xogħol, qed nippreżentaw studju fuq skala kbira ta’ LM dwar 50 lingwa tipoloġikament diversifikati li jkopru varjetà wiesgħa ta’ sistemi morfoloġiċi, u noffru punti ta’ riferiment ġodda ta’ LM lill-komunità, filwaqt li nikkunsidraw informazzjoni fil-livell ta’ sottokliem. Il-kontribuzzjoni teknika ewlenija tax-xogħol tagħna hija metodu ġdid għall-injezzjoni ta’ informazzjoni fil-livell ta’ subkliem f’vetturi semantiċi tal-kliem, integrati fit-taħriġ tal-mudellar tal-lingwi newrali, biex tiġi ffaċilitata t-tbassir fil-livell tal-kliem. Aħna nagħmlu esperimenti fl-ambjent tal-LM fejn in-numru ta’ kliem mhux frekwenti huwa kbir, u nuru kisbiet qawwija ta’ perplessità fil-50 lingwa tagħna, speċjalment għal lingwi rikki morfoloġikament. Il-kodiċi u s-settijiet tad-dejta tagħna huma disponibbli għall-pubbliku.</abstract_mt>
      <abstract_no>Neuralarkitekturar er viktige i bygging av språk- modeller (LMs). Ordnivåforhåndsvising er likevel agnostisk av underordnivåinformasjon (teikn og teiknkombinasjonar) og fungerer over eit lukka ordliste som inneheld eit begrenset ordsett. Mens underordvare-modeller styrer utviklinga over ulike NLP-oppgåver, så tidlegare arbeid evaluerte ikkje kapasiteten på desse modelane for å hjelpa neste ordforhåndsvising i språk-modellering. Desse underordnivået informarte modeller bør vera spesielt effektiv for morfologisk rikke språk (MRL) som viser høg type-til-token-forholdet. I denne arbeiden presenterer vi eit stor LM-studie på 50 typologisk ulike språk som dekkar ein stor variasjon av morfologiske systemer, og tilbyr nye LM-benchmarker til fellesskapet medan du ser på underordnivåinformasjon. Den viktigste tekniske bidraga av arbeidet vårt er eit nytt metode for å injesera underordnivåinformasjon i semantiske ordvektorar, integrert i uttrykket av neuralspråk for å få framsyning av ordnivået. Vi gjer eksperimenter i LM-innstillinga der antallet frekvenste ord er stor, og demonstrerer sterke forskjellighet på 50 språk våre, spesielt for morfologisk rikke språk. Kode og datasett våre er tilgjengelege offentlig.</abstract_no>
      <abstract_pl>Architektury neuronowe są ważne w konstrukcji modeli językowych (LMs). Jednak przewidywanie poziomu słowa jest zazwyczaj agnostyczne informacji na poziomie podsłów (znaków i sekwencji znaków) i działa na zamkniętym słownictwie, składającym się z ograniczonego zbioru słów. Rzeczywiście, podczas gdy modele świadome podsłów zwiększają wydajność w różnych zadaniach NLP, poprzednie prace nie oceniały zdolności tych modeli do wspomagania przewidywania następnego słowa w zadaniach modelowania językowego. Takie modele informowane na poziomie podsłów powinny być szczególnie skuteczne w przypadku języków bogatych morfologicznie (NDP), które wykazują wysoki stosunek typu do tokenu. W niniejszej pracy przedstawiamy wielkoskalowe badanie LM na temat 50-ciu typologicznie zróżnicowanych języków obejmujące szeroką gamę systemów morfologicznych oraz oferujemy nowe wskaźniki LM dla społeczności, biorąc pod uwagę informacje na poziomie podsłów. Głównym wkładem technicznym naszej pracy jest nowatorska metoda wstrzykiwania informacji na poziomie podsłów do semantycznych wektorów słów, zintegrowana z treningiem modelowania języka neuronowego, w celu ułatwienia przewidywania poziomu słowa. Przeprowadzamy eksperymenty w warunkach LM, w których liczba rzadkich słów jest duża, i wykazujemy silny wzrost zdezorientowania w naszych 50-tych językach, zwłaszcza w przypadku języków bogatych morfologicznie. Nasze kody i zestawy danych są publicznie dostępne.</abstract_pl>
      <abstract_mn>Цөмийн архитектурууд хэл загварын бүтээлд чухал. Гэвч үгний түвшин таамаглал нь ихэвчлэн суб-үгний түвшин мэдээллийн агностик юм. Хязгаарлагдсан үгний хэлбэрээр ажилладаг. НЛП-ын олон ажлын даалгаврын даалгаврыг нэмэгдүүлэх үед өмнөх ажил эдгээр загваруудын дараагийн үгийг хэл загварын даалгаврын таамаглалд туслах чадварыг үнэлэхгүй байлаа. Ийм суб-үгийн түвшинд мэдээллэг загварууд нь морфологийн баян хэл (MRL) дээр өндөр төрлийн холбоотой холбоотой байх ёстой. Энэ ажлын хувьд бид 50 хэлбэрийн өөр өөр хэл дээр том хэмжээний LM судалгааг үзүүлж, олон янз бүрийн морфологик системийн тухай харуулж, нийгэмд шинэ LM баталгаа өгдөг. Бидний ажлын гол техник түлхүүр нь суб-үг хэмжээний мэдээллийг semantic үг векторууд руу инжекцийн шинэ арга юм. Энэ нь сэтгэл зүйн хэл загварын сургалтын сургалтын тусламжтай, үг хэмжээний таамаглалтыг амжил Бид LM-ийн туршилтын туршилтыг хийдэг. Ялангуяа морфологийн баян хэл дээр маш их хэмжээний тоо байдаг. Бидний код болон өгөгдлийн сангууд олон нийтэд хангалттай.</abstract_mn>
      <abstract_ro>Arhitecturile neurale sunt proeminente în construirea modelelor lingvistice (LM). Cu toate acestea, predicția la nivel de cuvânt este de obicei agnostică de informații la nivel de subcuvânt (caractere și secvențe de caractere) și operează pe un vocabular închis, constând dintr-un set limitat de cuvinte. Într-adevăr, în timp ce modelele conștiente de subcuvinte sporesc performanța într-o varietate de activități PNL, lucrările anterioare nu au evaluat capacitatea acestor modele de a asista predicția cuvântului următor în activitățile de modelare lingvistică. Astfel de modele informate la nivel de subcuvinte ar trebui să fie deosebit de eficiente pentru limbile bogate din punct de vedere morfologic (LMR) care prezintă raporturi ridicate tip-token. În această lucrare, prezentăm un studiu LM la scară largă pe 50 de limbi diverse tipologic care acoperă o mare varietate de sisteme morfologice și oferim noi criterii LM comunității, luând în considerare informațiile la nivel de subcuvânt. Principala contribuție tehnică a lucrării noastre este o metodă nouă de injectare a informațiilor la nivel de subcuvânt în vectorii de cuvinte semantici, integrată în instruirea de modelare a limbajului neural, pentru a facilita predicția la nivel de cuvânt. Realizăm experimente în cadrul LM unde numărul de cuvinte rare este mare și demonstrăm câștiguri puternice de perplexitate în cele 50 de limbi ale noastre, în special pentru limbile bogate din punct de vedere morfologic. Codul și seturile noastre de date sunt disponibile public.</abstract_ro>
      <abstract_sr>Neuralne arhitekture su značajne u izgradnji jezičkih modela (LMs). Međutim, predviđanje na nivou riječi obično je agnostično informacija na nivou podriječi (znakovi i sekvence karaktera) i funkcioniše preko zatvorenih rečnika, sastavljajući od ograničenih reči. Zapravo, dok su modeli podrečenih svesnih podrečenica povećali performancu u raznim zadacima NLP-a, prethodni rad nije procenio sposobnost ovih modela da pomognu predviđanju sljedećih reči u zadacima za modeliranje jezika. Takvi podrečeni modeli moraju biti posebno efikasni za morfološki bogate jezike (MRL) koji pokazuju visoke procjene tipa do tokena. U ovom poslu predstavljamo veliku studiju LM-a o 50 tipološki različitim jezicima koji pokrivaju široke razne morfološke sisteme, i nudimo nove kritike LM-a zajednici, dok razmatramo informacije o podriječju nivou. Glavni tehnički doprinos našeg rada je nova metoda za ubrizgavanje podrečnih informacija u semantičke rečne vektore, integrisane u obuku modeliranja neuralnih jezika, kako bi olakšali predviđanje na nivou riječi. Mi vodimo eksperimente u postavljanju LM-a gde je broj neobičnih reči velikih, i pokazujemo snažne dobitke kompleksnosti na našim 50 jezika, posebno za morfološki bogate jezike. Naši kodovi i podaci su javno dostupni.</abstract_sr>
      <abstract_si>භාෂාව නිර්මාණය (LMs) නිර්මාණයේ නිර්මාණයේ ප්‍රධානයි. නමුත්, වචන- මට්ටම සාමාන්‍ය වචන- මට්ටම් තොරතුරු (අක්ෂර සහ අක්ෂර ක්‍රමයක්) සබ් වචන- මට්ටම් තොරතුරු (අක්ෂර සහ අක්ෂර ක්‍රම ඇත්තටම, සබ්වර්ඩ් දැනගන්න ප්‍රමාණය NLP විවිධ වැඩක් වලින් ප්‍රමාණයක් විශේෂ කරනවා නම්, මුලින් වැඩක් මේ මෝඩේල්ස් වලින් පස්ස මෙච්චර සබ්වර්ඩ් ලේවල් තොරතුරු ප්‍රමාණය විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් ප්‍රශ්නය වෙන්න ඕනේ මොර්ෆෝලෝගික මේ වැඩේ අපි ලොකු ස්කේල් LM පරීක්ෂණයක් පිළිගන්නවා වර්ගවිද්‍ය භාෂාවන් 50 වලින් විවිද්‍ය භාෂාවන් වලින් විවිද්‍ය විද්‍යාපාර පද්ධතියක අපේ වැඩේ ප්‍රධාන තාක්ෂණික ප්‍රයෝජනය තමයි සබ්වර්ඩ් ලේවල් තොරතුරු ප්‍රයෝජනයක් වෙක්ටර්ස් වචන වචන වෙක්ටර්ස් වලට ඇතුළත් වෙන අපි LM සැකසුමේදී පරීක්ෂණය කරනවා කියලා ප්‍රශ්නයක් විශාල වචන සංඛ්යා ලොකු වෙනවා, අපේ භාෂාවල් 50 වලින් ශක්තිමත් විශේෂ අපේ කෝඩ් සහ දත්ත සැට් සාමාන්‍යයෙන් ප්‍රවේශ වෙනවා.</abstract_si>
      <abstract_so>Qabuuraha naadiga ah waxaa lagu baran karaa dhismaha noocyada luuqada (LMs). Si kastaba ha ahaatee wax u sii sheegi karo hadal-heer waa sida caadiga ah macluumaad heerka hoose (xaraf iyo imtixaanka) wuxuuna ka shaqeeyaa qoraal xiran oo ku qoran qoraal xad ah. Indeed, while subword-aware models boost performance across a variety of NLP tasks, previous work did not evaluate the ability of these models to assist next-word prediction in language modeling tasks.  Tilmaamahan qoraalka hoose ee loo qoray waa inay si gaar ah u faa’iido u leedahay luuqadaha morphologically-rich (MRLs) oo muujiya qaybaha aad u sareeya-to-token. Markaas waxan shaqada ku qornaa waxbarasho LM oo aad u weyn oo ku qoran 50 luuqado kala duduwan oo ku qoran nidaamka morphologiga oo kala duduwan, oo waxaan jamiimka u soo bandhignaynaa qoraal cusub oo LM ah, iyadoo aan ka fikirayno macluumaad hoose-word. Kharashka teknolojiga ah ee shaqadeenna waa qaab saxda ah oo lagu soo wado macluumaadka heerka hoose-hadalka si uu u noqdo vectorooyinka hadalka semantika ah, oo lagu qabto waxbarashada qaabilaadda afka neurada ah, si uu u sahliyo wax sii sheegidda heerka. Waxaynu sameynaa imtixaamo ku saabsan qoraalka LM, meesha ay tirada hadalka caadiga ah ku weyn tahay, waxaana muujinnaa dhibaatooyin aad u adag oo ku saabsan 50 luqadeena, khusuusan ugu qoran luqadaha hodanka ah. Qoidayada iyo kooxda macluumaadyadu waxay si bayaan ah u helaan.</abstract_so>
      <abstract_sv>Neurala arkitekturer är framträdande vid byggandet av språkmodeller (LM). Förutsägelse på ordnivå är dock vanligtvis agnostisk av information på underordsnivå (tecken och teckensekvenser) och fungerar över ett slutet ordförråd, bestående av en begränsad orduppsättning. Även om underordmedvetna modeller ökar prestandan för en mängd olika NLP-uppgifter utvärderades inte tidigare modeller för att underlätta förutsägelse av nästa ord i språkmodelleringsuppgifter. Sådana underordsmodeller bör vara särskilt effektiva för morfologiskt rika språk (MRL) som uppvisar höga typ-tokenförhållanden. I detta arbete presenterar vi en storskalig LM-studie på 50 typologiskt olika språk som täcker en mängd olika morfologiska system, och erbjuder nya LM-riktmärken till samhället, samtidigt som vi överväger information på underordsnivå. Det huvudsakliga tekniska bidraget i vårt arbete är en ny metod för att injicera underordsnivå information i semantiska ordvektorer, integrerad i den neurala språkmodelleringsträningen, för att underlätta prediktion på ordnivå. Vi genomför experiment i LM-inställningen där antalet ovanliga ord är stort, och uppvisar starka förvirringsvinster över våra 50 språk, särskilt för morfologiskt rika språk. Våra koder och datauppsättningar är tillgängliga för allmänheten.</abstract_sv>
      <abstract_ta>மொழி மாதிரிகளின் உருவாக்கத்தில் நெருக்கருவிகள் பெரியதாக உள்ளன (LMs). However, word- level prediction is usually agnostic of subword- level information (characters and character sequences) and operates over a closed vocabulary, consistent with a limited word set. உண்மையில், துணை வார்த்தையான மாதிரிகள் பல்வேறு NLP பணிகளுக்கும் மேம்படுத்தும் போது, முந்தைய வேலை இந்த மாதிரிகளின் இயல்பினை மதிப்பிடாத இத்தகைய உச்சொல்- நிலையில் அறிவிக்கப்பட்ட மாதிரிகள் மாதிரியும் செல்லுபடியாக இருக்க வேண்டும். அது உயர் வகையில் இருந்து குறியீ இந்த வேலையில், நாம் 50 வழக்கமான மொழிகளில் ஒரு பெரிய அளவு LM படிப்பாட்டை கொண்டு வருகிறோம் மொழிகளை வெவ்வேறு வித்தியாசமான மொழிகள் மூலம் மற்றும் புதி எங்கள் வேலையின் முதன்மையான தொழில்நுட்பம் ஒரு புதிய முறைமையாகும் துணை சொல்- மட்டத்திற்கு தகவல் பென்மான்டிக் வார்த்தை வெக்டார்களுக்கு உள We conduct experiments in the LM setting where the number of infrequent words is large, and demonstrate strong perplexity gains across our 50 languages, especially for morphologically-rich languages.  எங்கள் குறியீடு மற்றும் தரவு அமைப்புகள் பொதுவாக கிடைக்கும்.</abstract_ta>
      <abstract_ur>زبان نمڈلوں (LMs) کے ساخت میں نئورل معمار ہیں۔ However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set. حقیقت یہ ہے، حالانکہ سوبرویڈ جاننے والی موڈلیاں NLP کے مختلف کاموں میں فعالیت اضافہ کرتی ہیں، اگلے کام نے ان موڈلیاں کی قدرت نہیں دیکھی کہ زبان موڈلینگ کے کاموں میں اگلے کلمات کی پیش بینی کی مدد کریں۔ ایسی سوبرویڈ سطح کی معلوم کی موڈل مخصوصاً مورفولوژیکی ثروت زبانوں (MRLs) کے لئے مفید ہونا چاہیے جو اچھی طرح سے ٹوکین کے نسبت دکھاتے ہیں۔ ہم نے اس کام میں 50 ٹائیپولوژیکی مختلف زبانوں پر ایک بڑی مطالعہ لم کی تحقیق پیش کیا ہے جو بہت سی مختلف مورفولوژیکی سیستموں پر پورے ہوتے ہیں اور کمونٹی کے لئے نئی LM بانچمارک پیش کرتے ہیں، اور اس کے بعد سوبر لفظ معلومات کی فکر کرتے ہیں. ہمارے کام کی اصلی تکنیکی حصہ یہ ہے کہ اسب ورڈ لائل کی معلومات کو سیمنٹی لفظ ویکتروں میں تزریق کرنے کے لئے ایک نئورل زبان کی مدل کی تعلیم میں تخلیق کیا گیا ہے، لفظ لائل کی پیش بینی کے لئے آسان کرنے کے لئے۔ ہم LM سٹینٹ میں آزمائش کرتے ہیں جہاں کلمات کی تعداد بڑی ہے اور ہماری 50 زبانوں میں مضبوط غلطی کا فائدہ دکھاتے ہیں، مخصوصاً morphology-rich languages کے لئے۔ ہمارے کڈ اور ڈیٹ سٹ ظاہر طور پر موجود ہیں.</abstract_ur>
      <abstract_uz>Name Ikkinchi so'z- darajada taʼminlovchi soʻzni moslash oddiy soʻzning tarkibi maʼlumot (belgi va belgilar tarkibi) va cheksiz soʻzni oʻchirish mumkin. Hullas, tub soʻzning taʼminlovchi modellari NLP vazifalarining turli vazifalarini bajarayotganda, oldingi ishni o'ylamaydi, bu modellarning keyingi so'zni oldingi tashkilotga qoʻllash imkoniyatini o'ylamaydi. Name Bu vazifanda, biz 50 oddiy turli tillarda ko'plab fofofologik tizimlari bilan bir necha LM ta'lim o'qituvchini hozir qilamiz, va yangi LM moslamalarini jamiyatga qarasamiz, va subword darajada maʼlumotni tasavvur qilayotganda. Bizning ishimizning asosiy teknologiya qandaydir - soʻzning tub darajada maʼlumotni semantik so'zlar vektoriga kiritish usuli, yangilik tilning modelini o'rnatish mumkin, so'z darajadagi oldini ishlatish uchun foydalanish. We conduct experiments in the LM setting where the number of infrequent words is large, and demonstrate strong perplexity gains across our 50 languages, especially for morphologically-rich languages.  Kodlash va maʼlumot moslamalarimiz publicly mavjud.</abstract_uz>
      <abstract_vi>Cấu trúc thần kinh rất quan trọng trong cấu trúc các mô hình ngôn ngữ. Tuy nhiên, khả năng tiên đoán mức từ là âm tính của thông tin cấp dưới (các ký tự và các chuỗi ký tự) và hoạt động qua một từ khóa, gồm một tập hợp từ giới hạn. Mặc dù các mô hình nhận thức dưới từ gia tăng khả năng ứng biến trong nhiều công việc lập trình ngôn ngữ, nhưng công việc trước đây không đánh giá khả năng của các mô hình này để dự đoán từ tiếp theo trong các công việc tạo mẫu ngôn ngữ. Những mô hình được thông báo dưới từ phải đặc biệt hiệu quả cho ngôn ngữ có độ phong phú (MRX) có tỷ lệ cao giữa các loại và biểu tượng. Trong công việc này, chúng tôi giới thiệu một nghiên cứu mô phỏng lớn LM về 50, các ngôn ngữ khác nhau theo tiêu chuẩn, bao gồm một loạt các hệ thống morphology, và cung cấp cho cộng đồng những tiêu chuẩn LM mới, trong khi xem xét thông tin dạng chữ phụ. Tác phẩm kỹ thuật chính của chúng ta là một phương pháp mới cho việc cung cấp thông tin cấp chữ ngầm vào các cỗ máy theo từ ngữ văn học, được hợp nhất với huấn luyện tạo mẫu ngôn ngữ thần kinh, để dễ dàng tiên đoán cấp từ. Chúng tôi tiến hành thí nghiệm trong môi trường LM, nơi có số lượng từ hiếm gặp lớn, và chứng minh sự biến mất nhiệt độ tăng vọt trong các ngôn ngữ 50, đặc biệt là những ngôn ngữ có độ bền. Mật mã và các bộ dữ liệu của chúng tôi công khai.</abstract_vi>
      <abstract_hr>Neuralne arhitekture su značajne u izgradnji jezičkih modela (LMs). Međutim, predviđanje na razini riječi obično je agnostično informacija na razini podriječi (znakovi i sekvence karaktera) i funkcioniše preko zatvorenog rečnika, sastavljajući od ograničenog set a riječi. Zapravo, dok modeli podriječju svjesni povećavaju učinkovitost u raznim zadacima NLP-a, prethodni rad nije procijenio sposobnost tih modela da pomognu predviđanju sljedećih riječi u zadacima za modeliranje jezika. Takvi podriječni modeli bi trebali biti posebno učinkoviti za morfološki bogate jezike (MRL) koji pokazuju visoke procjene tipa do tokena. U ovom poslu predstavljamo veliku proučavanje LM-a o 50 tipološki različitim jezicima koje pokrivaju široke razne morfološke sustave i nudimo nove kritike LM-a zajednici, dok razmatramo podriječje podriječje informacije. Glavni tehnički doprinos našeg rada je nova metoda za ubrizgavanje podriječnih informacija u semantičke riječne vektore, integrirane u obuku modeliranja neuralnih jezika, kako bi olakšali predviđanje na razini riječi. Mi provodimo eksperimente u postavljanju LM-a gdje je broj riječi velikih i pokazujemo snažne dobitke kompleksnosti na našim 50 jezicima, posebno za morfološki bogate jezike. Naši kodovi i podaci su javno dostupni.</abstract_hr>
      <abstract_nl>Neurale architecturen zijn prominent in de constructie van taalmodellen (LMs). De voorspelling op woordniveau is echter typisch agnostisch van informatie op subwoordniveau (tekens en tekenreeksen) en werkt over een gesloten woordenschat, bestaande uit een beperkte woordenset. Hoewel subwoordbewuste modellen de prestaties verhogen bij een verscheidenheid aan NLP-taken, werd in eerdere werkzaamheden niet geëvalueerd of deze modellen in staat zijn om volgende woorden te voorspellen bij taalmodelleringstaken. Dergelijke modellen op subwoordniveau moeten bijzonder effectief zijn voor morfologisch rijke talen (MRL's) die hoge type-to-token ratio's vertonen. In dit werk presenteren we een grootschalige LM studie over 50 typologisch diverse talen die een grote verscheidenheid aan morfologische systemen bestrijkt, en bieden we nieuwe LM benchmarks aan de gemeenschap, terwijl we informatie op subwoordniveau overwegen. De belangrijkste technische bijdrage van ons werk is een nieuwe methode voor het injecteren van informatie op subwoordniveau in semantische woordvectoren, geïntegreerd in de neurale taalmodelleringstraining, om voorspelling op woordniveau te vergemakkelijken. We voeren experimenten uit in de LM-omgeving waar het aantal zeldzame woorden groot is, en tonen sterke verwarringswinsten aan in onze 50-talen, vooral voor morfologisch rijke talen. Onze code en datasets zijn openbaar beschikbaar.</abstract_nl>
      <abstract_da>Neurale arkitekturer er fremtrædende i opbygningen af sprogmodeller. Forudsigelse på ordniveau er dog typisk agnostisk af oplysninger på underordniveau (tegn og tegnsekvenser) og fungerer over et lukket ordforråd, der består af et begrænset ordsæt. Mens underordbevidste modeller øger ydeevnen på tværs af en række NLP-opgaver, evaluerede tidligere arbejde ikke disse modellers evne til at hjælpe med næste ord forudsigelse i sprogmodelleringsopgaver. Sådanne underordsprogede modeller bør være særligt effektive for morfologisk rige sprog (MRL), der udviser høje type-til-tokenforhold. I dette arbejde præsenterer vi en omfattende LM undersøgelse af 50 typologisk forskelligartede sprog, der dækker en bred vifte af morfologiske systemer, og tilbyder nye LM benchmarks til fællesskabet, samtidig med at vi overvejer information på underordsniveau. Det vigtigste tekniske bidrag fra vores arbejde er en ny metode til indsprøjtning af underordniveau information i semantiske ordvektorer, integreret i neural sprogmodellering træning, for at lette ordniveau forudsigelse. Vi udfører eksperimenter i LM-indstillingen, hvor antallet af sjældne ord er stort, og demonstrerer stærke forvirringsgevinster på tværs af vores 50 sprog, især for morfologisk rige sprog. Vores kode og datasæt er offentligt tilgængelige.</abstract_da>
      <abstract_bg>Неврологичните архитектури са видни в изграждането на езикови модели (ЛМ). Въпреки това, предсказването на ниво дума обикновено е агностично на информация на ниво поддума (знаци и последователности от знаци) и работи върху затворен речник, състоящ се от ограничен набор от думи. Всъщност, докато моделите с подсъзнание подобряват ефективността при различни задачи за НЛП, предишна работа не оценява способността на тези модели да подпомагат предсказването на следващата дума в задачите за езиково моделиране. Такива информирани модели на ниво поддума следва да бъдат особено ефективни за морфологично богати езици (МДГОВ), които показват високи съотношения тип-символ. В тази работа ние представяме мащабно изследване на ЛМ на 50 типологично разнообразни езика, обхващащо голямо разнообразие от морфологични системи, и предлагаме нови референтни показатели за ЛМ на общността, като същевременно разглеждаме информацията на ниво поддума. Основният технически принос на нашата работа е нов метод за инжектиране на информация на ниво субдума в семантични речни вектори, интегриран в обучението за моделиране на невронни езици, за да се улесни предсказването на ниво дума. Ние провеждаме експерименти в среда, където броят на редките думи е голям, и демонстрираме силни печалби от объркване на нашите 50 езика, особено за морфологично богати езици. Нашите кодове и набори от данни са публично достъпни.</abstract_bg>
      <abstract_de>Neuronale Architekturen sind prominent in der Konstruktion von Sprachmodellen (LMs). Allerdings ist die Vorhersage auf Wortebene typischerweise agnostisch gegenüber Informationen auf Unterwortebene (Zeichen und Zeichenfolgen) und arbeitet über ein geschlossenes Vokabular, bestehend aus einer begrenzten Wortmenge. Während Subword-bewusste Modelle die Leistung bei einer Vielzahl von NLP-Aufgaben steigern, wurde in früheren Arbeiten die Fähigkeit dieser Modelle, die Vorhersage des nächsten Wortes bei Sprachmodellierungsaufgaben zu unterstützen, nicht evaluiert. Solche auf Subword-Ebene informierten Modelle sollten besonders effektiv für morphologisch-reiche Sprachen (MRLs) sein, die hohe Typ-Token-Verhältnisse aufweisen. In dieser Arbeit präsentieren wir eine großangelegte LM-Studie zu 50 typologisch unterschiedlichen Sprachen, die eine Vielzahl von morphologischen Systemen abdeckt, und bieten der Gemeinschaft neue LM-Benchmarks an, unter Berücksichtigung von Informationen auf Subwortebene. Der wesentliche technische Beitrag unserer Arbeit ist eine neuartige Methode zur Injektion von Informationen auf Unterwortebene in semantische Wortvektoren, die in das neuronale Sprachmodellierungstraining integriert ist, um Vorhersagen auf Wortebene zu erleichtern. Wir führen Experimente im LM-Setting durch, in dem die Anzahl seltener Wörter groß ist, und zeigen starke Verwirrung in unseren 50-Sprachen, insbesondere für morphologisch reiche Sprachen. Unsere Codes und Datensätze sind öffentlich zugänglich.</abstract_de>
      <abstract_id>Arkitektur saraf terkenal dalam pembangunan model bahasa (LMs). Namun, prediksi tingkat kata biasanya agnostik dari informasi tingkat subword (karakter dan urutan karakter) dan beroperasi melalui sebuah vokabular tertutup, yang terdiri dari set kata yang terbatas. Sebenarnya, sementara model yang menyadari subword meningkatkan prestasi melalui berbagai tugas NLP, pekerjaan sebelumnya tidak mengevaluasi kemampuan model ini untuk membantu prediksi kata berikutnya dalam tugas model bahasa. Model informasi tingkat subword tersebut seharusnya sangat efektif untuk bahasa yang kaya secara morfologis (MRL) yang menunjukkan nisbah tipe-token yang tinggi. In this work, we present a large-scale LM study on 50 typologically diverse languages covering a wide variety of morphological systems, and offer new LM benchmarks to the community, while considering subword-level information.  Kontribusi teknik utama dari pekerjaan kita adalah metode baru untuk menyuntik informasi tingkat subword ke vektor kata semantis, terintegrasi ke pelatihan model bahasa saraf, untuk memudahkan prediksi tingkat kata. Kami melakukan eksperimen di lingkungan LM di mana jumlah kata yang tidak sering besar, dan menunjukkan kekuatan kekacauan di seluruh 50 bahasa kita, terutama untuk bahasa yang kaya secara morfologis. Kode dan set data kita tersedia publik.</abstract_id>
      <abstract_ko>신경 체계 구조는 언어모델(LMs) 구축에서 중요한 위치를 차지한다.그러나 어급 예측은 보통 하위 어급 정보(문자와 문자 서열)와 무관하고 유한한 어집으로 구성된 폐쇄된 어휘표에서 실행된다.사실 하위 단어 감지 모델은 각종 NLP 작업의 성능을 향상시킬 수 있지만 이전 작업에서는 이러한 모델이 언어 모델링 작업에서 다음 단어의 예측을 보조하는 능력을 평가하지 않았다.이런 하위 단어급 정보 모델은 높은 유형-표기 비율을 나타내는 형태가 풍부한 언어(MRL)에 특히 효과적일 것이다.이 작업에서 우리는 50가지 유형의 다양한 언어에 대해 대규모의 LM 연구를 실시했고 각종 형태 시스템을 포괄했으며 자어급 정보를 고려하는 동시에 지역사회에 새로운 LM 기준을 제공했다.우리가 일하는 주요 기술 공헌은 자사급 정보를 어의어향량에 주입하는 새로운 방법으로 신경언어 모델링 훈련에 집적하여 어급 예측을 추진하는 것이다.우리는 LM 환경에서 실험을 진행했는데 LM 환경에서 자주 나타나지 않는 단어의 수가 매우 많고 우리의 50가지 언어 중, 특히 형태가 풍부한 언어에서 우리는 강한 곤혹을 나타냈다.우리의 코드와 데이터 집합은 공개된 것이다.</abstract_ko>
      <abstract_fa>معماری عصبی در ساختن مدل زبان (LMs) مهم است. ولی پیش‌بینی سطح کلمه معمولاً از اطلاعات سطح زیر کلمه (karakters and character sequences) agnostic است و بر روی یک کلمه بسته کار می‌کند که از جمله کلمه محدود است. در حقیقت، در حالی که مدلهای زیر کلمه آگاهی بر روی کارهای مختلف NLP افزایش می دهند، کار قبلی توانایی این مدلها را برای پیش بینی کردن کلمه بعدی در کارهای مدلک زبان ارزیابی نکرد. چنین مدل‌های اطلاع شده از سطح زیر کلمه باید مخصوصا برای زبان‌های مورفولوژیکی ثروتمند (MRLs) موثر باشد که نسبت‌های نوع بالا به توکین را نمایش می‌دهند. در این کار، ما یک مطالعه LM بسیار بزرگ روی ۵۰ زبان نوع شناسایی متفاوت را پیشنهاد می‌کنیم که به طریق مختلف سیستم‌های مورفولوژیک متفاوت است، و نشانه‌های LM جدید را به جامعه پیشنهاد می‌کنیم، در حالی که در نظر گرفتن اطلاعات سطح زیر ارتباط اصلی تکنیکی کار ما یک روش تازه برای تزریق اطلاعات سطح زیر کلمه به ویکتورهای کلمه semantic است که در آموزش مدل کردن زبان عصبی تزریق شده است، برای آسانی پیش بینی سطح کلمه‌ها. ما آزمایش‌ها را در تنظیم LM انجام می‌دهیم که تعداد کلمات غیر عادی بزرگ است، و نشان می‌دهیم که پیروزی قوی در پنجاه زبان‌های ما، مخصوصا برای زبان‌های ثروتمندی مورفولوژیک است. کد و مجموعه اطلاعات ما به طور عمومی در دسترس هستند.</abstract_fa>
      <abstract_sw>majengo ya msingi ni maarufu katika ujenzi wa miundo ya lugha (LMs). Hata hivyo, utabiri wa kiwango cha maneno kwa kawaida unaonyesha taarifa za ngazi za chini ya maneno (tabia na mfululizo wa tabia) na hutumia zaidi ya lugha iliyofungwa, ikiwa ni pamoja na seti ya neno lenye mipaka. Kwa hakika, wakati mifano yenye ufahamu wa maneno ya upinzani huongezea utendaji katika kazi mbalimbali za NLP, kazi iliyopita haikutathmini uwezo wa mifano hii ili kusaidia utabiri wa maneno ijayo katika kazi za mifano ya lugha. Mifano ya aina hii ya ujumbe wa maneno yanapaswa kuwa na ufanisi hasa kwa lugha zenye utajiri wa kifolojia (MRLs) ambayo inaonyesha kiwango kikubwa cha aina ya aina moja kwa moja. Katika kazi hii, tunaweka utafiti mkubwa wa LM kuhusu lugha 50 kwa kawaida tofauti mbalimbali zinazohusu mfumo mbalimbali wa kifolojia, na kutoa misingi mpya ya LM kwa jamii, wakati tunafikiria taarifa za kiwango cha chini ya maneno. Mchango mkuu wa kiteknolojia wa kazi yetu ni njia ya riwaya ya kuingiza taarifa za ngazi za chini za maneno katika vectors za semantic word, inayojumuisha katika mafunzo ya mtindo wa lugha ya asili, ili kusaidia utabiri wa ngazi ya neno. Tunafanya majaribio katika mazingira ya LM ambapo idadi ya maneno yasiyo na msingi ni kubwa, na kuonyesha wasiwasi mkubwa katika lugha zetu 50, hususani kwa lugha zenye utajiri wa kimaadilojia. Kodi zetu na seti za taarifa zinapatikana wazi.</abstract_sw>
      <abstract_tr>Tyl nusgalary (LMs) düzenlemekde örän möhüm. Ýöne söz derejesi önlemek adatça subsöz derejesi maglumatyň agnostik we ýapylan sözleriň üstünde işleýär. Bu söz düzünden boşadylýar. Adatça, alt sözleri bilýän nusgalar NLP zadynyň birnäçe zadynda ukyplary artýardy, öňki işi bu nusgalaryň indiki sözleri modelleýän täzeliklerinde kömekleýän ukyplaryny çykarmady. Häzirki subsöz derejesi bilgili nusgalar morfolojik bilen baý diller üçin täsirli bolmaly. Bu işde 50 tipolojik dürli diller barada Ullakan LM araştyrmasyny görkezip edýäris we jemgyýetä täze LM etiket salgynlary görkezip, sübde-dürli maglumatlary düşünýäris. Çalışmalarymyzyň esasy tekniki täsiri semantik söz vektörlerine süýtgetmek üçin, söz derejesini bejermek üçin, söz derejesini azaltmak üçin bir täze täsiridir. Biz LM düzümlerinde ýagdaý sözlerin sany uly döredip barýarys we 50 dillerimizde ýigrenç çykyşlygyny görkez.Özellikle morfologik baý diller üçin ýigrenç çykyşlygyny görkez. Biziň ködlerimiz we maglumat setirlerimiz publika mejbur.</abstract_tr>
      <abstract_af>Nurale arkitektuure is prominente in die konstruksie van taal modele (LMs). Maar, woord-vlak voorskou is tipies agnostik van subwoord-vlak inligting (karakters en karaktersekwensies) en werk oor 'n gesluit woordeboek, bestaan van 'n beperkte woord stel. Waarlik, terwyl subwoord-bewyse modele voorspoediging oor 'n verskillende NLP-taak verhoog het, het die vorige werk nie die moontlikheid van hierdie modele evalueer om volgende woord voorspoediging te help in taal modeling taak nie. Soos subwoord-vlak inligte modele moet veral effektief wees vir morfologiese-ryk tale (MRL) wat hoë tipe-to-token-ratioes vertoon. In hierdie werk voorsien ons 'n groot skaal LM studie op 50 tipologies verskillende tale wat 'n wyde verskeie morfologiese stelsels oordek en nuwe LM-benchmarke aan die gemeenskap aanbied, terwyl ons onderwerp subwoord-vlak inligting. Die hooftegniese bydrang van ons werk is 'n nuwe metode vir subwoord-vlak inligting in semantiese woord vektore, integreer in die neurale taal modellering onderwerp, om woord-vlak voorskou te maak. Ons bestuur eksperimente in die LM-instelling waar die nommer van onvolgende woorde groot is, en wys sterk perpleksiteit verskaf oor ons 50 tale, veral vir morfologiese ryk tale. Ons kode en data stel is openlik beskikbaar.</abstract_af>
      <abstract_sq>Arkitekturat neuronale janë të shquara në ndërtimin e modeleve gjuhësore (LMs). Megjithatë, parashikimi i nivelit të fjalëve është tipikisht agnostik i informacionit të nivelit të nënfjalëve (karaktere dhe sekuenca karakteresh) dhe funksionon mbi një fjalor të mbyllur, që përbëhet nga një set fjalësh të kufizuar. Në fakt, ndërsa modelet e ndërgjegjshëm për fjalë rritin performancën nëpër një varietet detyrash NLP, puna e mëparshme nuk vlerësoi aftësinë e këtyre modeleve për të ndihmuar parashikimin e fjalës tjetër në detyrat e modelimit gjuhësor. Modele të tilla të informuara në nivelin e nënfjalëve duhet të jenë veçanërisht efektive për gjuhët e pasura morfologikisht (MRL) që ekspozojnë raporte të larta lloj-token. Në këtë punë, ne paraqesim një studim në shkallë të madhe LM mbi 50 gjuhë tipologjikisht të ndryshme që mbulojnë një varietet të gjerë të sistemeve morfologjike dhe ofrojmë pika të reja LM për komunitetin, duke konsideruar informacionin e nivelit të nënfjalëve. Kontributi kryesor teknik i punës sonë është një metodë e re për injektimin e informacionit të nivelit të nënfjalëve në vektorët semantik të fjalëve, të integruar në trajnimin e modelimit të gjuhës nervore, për të lehtësuar parashikimin e nivelit të fjalëve. Ne kryejmë eksperimente në vendosjen e LM ku numri i fjalëve të papritura është i madh dhe demonstrojmë fitime të forta të hutimit nëpër 50 gjuhët tona, veçanërisht për gjuhët e pasura morfologikisht. Our code and data sets are publicly available.</abstract_sq>
      <abstract_hy>Նյարդային ճարտարապետությունները նշանակալի են լեզվի մոդելների կառուցվածքում: However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set.  Իրականում, մինչ ենթաբառերով գիտակցած մոդելները բարձրացնում են ՆԼՊ-ի բազմաթիվ առաջադրանքների արդյունքները, նախորդ աշխատանքը չգնահատեց այս մոդելների կարողությունը օգնել հաջորդ բառի կանխատեսումը լեզվի մոդելների առաջադրանքներում Այս ենթաբառերի մակարդակի տեղեկացված մոդելները պետք է հատկապես արդյունավետ լինեն մորֆոլոգիապես հարուստ լեզուների (ՄՌԼ) համար, որոնք ցույց են տալիս բարձր տեսակի և նշանի հարաբերություններ: Այս աշխատանքի ընթացքում մենք ներկայացնում ենք 50 տիպոլոգիապես բազմազան լեզուների ուսումնասիրություն, որը ներառում է բազմազան մորֆոլոգիական համակարգեր, և ներկայացնում ենք նոր համեմատական նպատակներ համայնքի համար, հաշվի առնելով ենթաբառերի մակարդակի տեղեկատվություն The main technical contribution of our work is a novel method for injecting subword-level information into semantic word vectors, integrated into the neural language modeling training, to facilitate word-level prediction.  Մենք կատարում ենք փորձարկումներ LM-ում, որտեղ հազվադեպ բառերի թիվը մեծ է, և ցույց ենք տալիս, որ մեր 50 լեզուների ընթացքում մեծ խառնաշփոթ է զարգանում, հատկապես մորֆոլոգիապես հարուստ լեզուների համար: Մեր կոդը և տվյալների համակարգերը հանրային հասանելի են:</abstract_hy>
      <abstract_am>የነጥብ መሠረት መሠረት የቋንቋ ዓይነቶች (LMs) However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set.  አነስተኛነት፣ ደብረ ቃላት የሚያውቀው ዓይነቶች የNLP አድራጊዎችን የሚያበዛ ሥርዓት ሲሆን፣ የቀድሞው ሥራ በቋንቋ ምሳሌ ማሳየት የሚችለውን የእነዚህን ሞዴላዎች ማስታወቂያውን አያስተምርም፡፡ እንደነዚህ አዲስ ቃላት የደረጃ ደረጃ ማውጣት ሞሮፎሎጂ-ባለ ሀብታሞች ቋንቋዎች (MRLs) ከፍ-type-to-token ክፍተቶችን የሚያሳየው መጠቀሚያ እንዲሆን ያስፈልጋል። በዚህ ሥራ፣ 50 በተለያዩ ቋንቋዎች የሞፎሎጂ ስርዓቶች የሚሸከሙትን በብዙ ልዩ ልዩ ቋንቋዎች ላይ ትልቁ LM ትምህርት እናቀርባታለን፡፡ የሥራችን መጀመሪያ የቴክክክሎጂ አዋጅ የደብዳቤ ቋንቋ ምሳሌ መግለጫ እና የቃላት-ደረጃ ምርጫን ለመግለጥ የደብዳቤ ቋንቋ ምሳሌ ማቀናቀል ነው፡፡ የግንኙነት ቃላት ቁጥር ታላቅ በሚሆነበት የLM ፈተና እናደርጋለን፤ በ50 ቋንቋዎቻችንም ይልቁንም ለሞፎሎጂ ባለ ጠጎች ቋንቋዎች የበረታውን ጥረት እናሳያልን፡፡ የኮድ እና የዳታ መስመር ግልፅ ነው፡፡</abstract_am>
      <abstract_bn>ভাষার মডেল (এলএমএস) নির্মাণের মধ্যে নিউরেলিয়াল কাঠামো বিশ্ববিদ্যালয়। তবে শব্দ-স্তরের ভবিষ্যৎবাণী সাধারণত সাবওয়ার্ড-স্তর তথ্য (অক্ষর এবং অক্ষর সেকেন্স) এবং একটি বন্ধ শব্দভাণ্ডারের উপর পরিচালনা করে, যা একটি সীমিত সত্যিই, যখন সাবওয়ার্ড-পরিচিত মডেল বিভিন্ন ধরনের এনএলপি কাজের মাধ্যমে বৃদ্ধি প্রদান করে, তখন পূর্ববর্তী কাজ ভাষার মডেলের মডেলের ক্ষমতার পরের শ এই ধরনের সাবওয়ার্ড-স্তরের তথ্য প্রদান করা মডেল বিশেষ করে মোরফোল্যালিক-সমৃদ্ধ ভাষার (এমআরএল) জন্য কার্যকর হবে যা উচ্চ ধরনের-থেকে প্ এই কাজে আমরা ৫০ টি সাধারণ ভাষায় বিভিন্ন ভাষার উপর একটি বিশাল স্কেল এলএম গবেষণা উপস্থাপন করি, যা বিভিন্ন ধরনের মরোফোলিক্যাল সিস্টেম সম্পর্কে সম্প্রদায়ের কা আমাদের কাজের প্রধান প্রযুক্তিগত অবদান হচ্ছে সাবওয়ার্ড-স্তরের তথ্য সেম্পেন্টিক শব্দ ভেক্টরে প্রবেশ করার জন্য সাবওয়ার্ড-স্তরের তথ্য, যা নিউ আমরা এলএম সেটিং এ পরীক্ষার পরীক্ষা করি যেখানে প্রাকৃতিক শব্দ বিশাল এবং আমাদের ৫০ ভাষায় শক্তিশালী বিভ্রান্তির অর্জন প্রদর্শন করি, বিশেষ করে  আমাদের কোড এবং ডাটা সেট প্রকাশ্যে পাওয়া যাচ্ছে।</abstract_bn>
      <abstract_az>Nöral arhitektarlar dil modellərinin in şallarında möhtərəmdir. Lakin söz səviyyəsi təhlükəsizləri əsas-səviyyəsi məlumatların (karakterlər və karakter sequences) arasında agnostik və qapılmış sözlərin üstündə işləyir. Bu sözlər müəyyən edilmişdir. Əslində, alt-sözlər bilən modellər NLP işlərinin müxtəlif işlərində performans artırmaq üçün, əvvəlki işlər bu modellərin sonrakı sözlərin modellik işlərinə kömək etmək üçün qabiliyyətini değerlətmədi. Bütün bu sübsöz səviyyəsi bilən modellər çox yüksək tür-to-token qiymətlərini göstərən morpholojik zengin dillər (MRLs) üçün istifadə edilməli olmalıdır. Bu işdə, 50 tipolojik müxtəlif dillər barəsində böyük ölçülü LM təhsil edirik ki, çoxlu çoxlu morfolojik sistemlərini örtür və ümmətlərə yeni LM benchmarkləri təklif edirik, altı sözlər səviyyəsi məlumatlarını düşünürək. Bizim işimizin ən böyük tekniki səbəbi məlumatları semantik söz vektörlərinə inşa etmək üçün yeni bir yoldur, nöral dillərin modellərinin təhsil edilməsi üçün, söz səviyyəsini təhsil etmək üçün. Biz LM ayarlarında müxtəlif sözlərin sayı böyükdüyünü və 50 dillərimizdə qüvvətli müxtəlif əlaqələri göstəririk, özlərinə də morfolojik zengin dillər üçün. Kodumuz və veri qurularımız açıq-aşkar mövcuddur.</abstract_az>
      <abstract_ca>Neural architectures are prominent in the construction of language models (LMs).  Però la predicció del nivell de paraules és típicament agnòstica d'informació del nivell de subparaules (caràcters i seqüències de caràcters) i funciona sobre un vocabulari tancat, compost d'un conjunt limitat de paraules. De fet, mentre que els models conscients de subparaules impulsen el rendiment a través d'una varietat de tasques de NLP, la feina anterior no va evaluar l'habilitat d'aquests models per ajudar a predir les pròpies paraules en tasques de modelació de llenguatges. Aquests models informats a nivell de subparaules haurien de ser particularment efectius per a les llengües rics morfològicament (LMR) que mostran elevades proporcions entre tipus i fitxes. En aquest treball, presentem un estudi de gran escala sobre 50 llengües tipològicament diverses que cobreixen una gran varietat de sistemes morfològics, i oferim nous punts de referència sobre el LM a la comunitat, mentre considerem informació a nivell de subparaules. La principal contribució tècnica de la nostra feina és un mètode nou per injectar informació de nivell subparaula en vectors semàntics de paraules, integrats en l'entrenament de modelació neuronal de llenguatges, per facilitar la predicció de nivell de paraules. Conduem experiments en un entorn de LM on el nombre de paraules poc freqüents és gran, i demostrem forts guanys de perplexitat a través de les nostres 50 llengües, especialment en llengües rics morfològicament. Els nostres codis i conjunts de dades estan disponibles al públic.</abstract_ca>
      <abstract_cs>Neurální architektury jsou významné při konstrukci jazykových modelů (LM). Avšak predikce na úrovni slova je obvykle agnostická informací na úrovni podslov (znaků a znakových sekvencí) a funguje přes uzavřenou slovní zásobu, skládající se z omezené množiny slov. Zatímco modely s podslovem zvyšují výkon v různých úlohách NLP, předchozí práce nehodnotily schopnost těchto modelů pomoci predikci dalších slov v jazykových modelováních. Tyto informované modely na úrovni podslov by měly být obzvláště účinné pro morfologicky bohaté jazyky (MLR), které vykazují vysoký poměr typu k tokenu. V této práci představujeme rozsáhlou LM studii o 50 typologicky rozmanitých jazycích pokrývajících širokou škálu morfologických systémů a nabízíme komunitě nové LM referenční hodnoty s ohledem na informace na úrovni podslov. Hlavním technickým přínosem naší práce je nová metoda vkládání informací na úrovni podslov do sémantických slovních vektorů integrovaná do tréninku modelování neuronového jazyka za účelem usnadnění predikce na úrovni slova. Provádíme experimenty v LM nastavení, kde je počet vzácných slov velký, a demonstrujeme silné zmatenosti v našich padesáti jazycích, zejména u morfologicky bohatých jazyků. Náš kód a datové sady jsou veřejně dostupné.</abstract_cs>
      <abstract_bs>Neuralne arhitekture su značajne u izgradnji jezičkih modela (LMs). Međutim, predviđanje na nivou riječi obično je agnostično informacija na nivou podriječi (karakteri i sekvence karaktera) i funkcioniše preko zatvorenog rečnika, sastavljajući se od ograničenog set a riječi. Zapravo, iako modeli podriječju svjesni povećavaju učinkovitost u raznim zadacima NLP-a, prethodni rad nije procenio sposobnost tih modela da pomognu predviđanju sljedećih riječi u zadacima za modeliranje jezika. Takvi podrečeni modeli moraju biti posebno efikasni za morfološki bogate jezike (MRL) koji pokazuju visoke procjene tipa do tokena. U ovom poslu predstavljamo veliku proučavanje LM-a o 50 tipološki različitim jezicima koji pokrivaju široke razne morfološke sustave, i nudimo nove kritike LM-a zajednici, s obzirom na informacije o podriječju nivou. Glavni tehnički doprinos našeg rada je nova metoda za ubrizgavanje podriječnih informacija u semantične riječne vektore, integrirane u obuku modeliranja neuralnih jezika, kako bi olakšalo predviđanje na nivou riječi. Mi provodimo eksperimente u postavljanju LM-a gdje je broj riječi velikih i pokazujemo snažne dobitke kompleksnosti na našim 50 jezicima, posebno za morfološki bogate jezike. Naši kodovi i podaci su javno dostupni.</abstract_bs>
      <abstract_fi>Neuroarkkitektuurit ovat merkittäviä kielimallien rakentamisessa. Sanatason ennustus on kuitenkin tyypillisesti agnostinen alasanatason tiedoista (merkeistä ja merkkisekvensseistä) ja toimii suljetussa sanastossa, joka koostuu rajallisesta sanastosta. Vaikka alasanatietoiset mallit parantavat suorituskykyä useissa NLP-tehtävissä, aiemmissa tutkimuksissa ei arvioitu näiden mallien kykyä avustaa seuraavan sanan ennustamista kielimallinnustehtävissä. Tällaisten alasanatason tietoon perustuvien mallien olisi oltava erityisen tehokkaita morfologisesti rikkaille kielille (MRL), joilla on suuri tyyppi-tunniste-suhde. Tässä työssä esitellään laaja-alainen LM-tutkimus 50 typologisesti erilaisesta kielestä, joka kattaa laajan valikoiman morfologisia järjestelmiä, ja tarjotaan uusia LM-vertailuarvoja yhteisölle ottaen huomioon alasanatason tiedot. Työn pääasiallinen tekninen panos on uusi menetelmä subsanatason tiedon syöttämiseksi semanttisiin sanavektoreihin, joka on integroitu neurokielen mallinnuskoulutukseen sanatason ennustamisen helpottamiseksi. Teemme kokeita LM-ympäristössä, jossa harvinaisten sanojen määrä on suuri, ja osoitamme suurta hämmennystä 50 kielellämme, erityisesti morfologisesti rikkailla kielillä. Koodimme ja tietojoukkomme ovat julkisesti saatavilla.</abstract_fi>
      <abstract_et>Neuraalsed arhitektuurid on keelemudelite ehitamisel silmapaistvad. Kuid sõnataseme prognoosimine on tavaliselt agnostiline alamsõnataseme teabest (märgid ja märkide järjestused) ja toimib suletud sõnavara kaudu, mis koosneb piiratud sõnakomplektist. Kuigi alamsõnateadlikud mudelid suurendavad jõudlust mitmesuguste NLP ülesannete puhul, ei hinnatud varasemates töödes nende mudelite võimet aidata kaasa järgmise sõna ennustamisele keele modelleerimise ülesannetes. Sellised alamsõna tasemel teadlikud mudelid peaksid olema eriti tõhusad morfoloogiliselt rikkate keelte puhul, millel on suur tüübi ja märgi suhe. Käesolevas töös tutvustame laiaulatuslikku LM-uuringut 50 tüpoloogiliselt mitmekesise keele kohta, mis hõlmavad mitmesuguseid morfoloogilisi süsteeme, ning pakume kogukonnale uusi LM-võrdlusnäitajaid, arvestades alamsõna tasemel teavet. Meie töö peamine tehniline panus on uudne meetod alamsõnataseme info süstimiseks semantilistesse sõnavaktoritesse, mis on integreeritud neurokeele modelleerimise koolitusse, et hõlbustada sõnataseme ennustamist. Me teeme katseid LM seadistuses, kus harvaesinevate sõnade arv on suur, ja näitame tugevat segadust meie 50 keeles, eriti morfoloogiliselt rikkate keelte puhul. Meie kood ja andmekogumid on avalikult kättesaadavad.</abstract_et>
      <abstract_ha>An ƙayyade tsarin neural cikin an gina misãlai na harshe (LM). Babu kasa, wani abu na daidaita maganar-daraja ya zama ana gannostic wa data na subword-levels (characters and sequences of character) kuma yana yi amfani da kan wata takardar da aka rufe shi, mai ƙunsa da wani magana na ƙayyade. Na gaske, a lokacin da misãlai masu fahimta masu ƙaranci ga mafarin aiki masu cikin wasu aikin NLP, bai ƙaddara aikin da ya gabata ba, kan taimako da abincin waɗannan misãlai da ke ƙara cikin aikin mai motsi da harshe. @ info: whatsthis Daga wannan aikin, Munã halatar da LM-muhalli mai girma a kan harshen 50 masu turɓãya masu haɗi wasu na'uran fofologi masu yawa, kuma munã gaya misãlai na LM zuwa jamii, a lokacin da za'a yi tunãni ga zane-zane-zane. Bayanin kimada na aikin aikinmu yana da hanyari mai node wa za'a shigar da data na subword-leveli zuwa shiryori masu semantic, wanda aka haɗa a cikin shirin misalin harshen neural, dõmin ya sauƙin bayani ga ƙanni-daraja. Munã samun jarrabãwa a cikin muhallin LM, inda yawan maganar da aka baka ta girma, kuma za mu nuna masu shakka mai ƙarfi a cikin lugha 50, kuma da haske ga lugha masu rikin mutane. Ana sami kodi da data</abstract_ha>
      <abstract_sk>Nevralne arhitekture so vidne pri gradnji jezikovnih modelov (LM). Vendar pa je napoved na ravni besed običajno agnostika informacij na ravni podbesed (znaki in zaporedja znakov) in deluje preko zaprtega besedišča, ki je sestavljen iz omejenega nabora besed. Medtem ko modeli, ki se zavedajo podbesed, povečujejo učinkovitost pri različnih opravilih NLP, predhodno delo ni ocenilo sposobnosti teh modelov za pomoč pri napovedovanju naslednjih besed pri opravilih jezikovnega modeliranja. Takšni modeli na ravni podbesed bi morali biti zlasti učinkoviti za morfološko bogate jezike (MRL), ki imajo visoko razmerje med vrsto in žetonom. V tem delu predstavljamo obsežno študijo LM na 50 tipološko različnih jezikih, ki pokrivajo različne morfološke sisteme in skupnosti ponujamo nove referenčne vrednosti LM ob upoštevanju informacij na ravni podbesed. Glavni tehnični prispevek našega dela je nova metoda vbrizganja podbesednih informacij v semantične besedne vektorje, integrirana v usposabljanje za modeliranje nevronskega jezika, da bi olajšala napovedovanje besednih ravni. Izvajamo eksperimente v LM okolju, kjer je število redkih besed veliko, in dokazujemo močno zmedenost v naših 50 jezikih, zlasti pri morfološko bogatih jezikih. Naše kode in nabori podatkov so javno dostopni.</abstract_sk>
      <abstract_jv>Arkturaturanan Neral sing mengko buku nggawe model sing luwih (LM). politenessoffpolite"), and when there is a change ("assertivepoliteness Tulung, hale model apa-awake sistem sembol dadi nggawe barang NLP sampeyan karo akeh operasi sing paling nggawe modèl kuwi tindakan nggawe barang langgar sampeyan winih. Laptop" and "Desktop Nang gunggo iki, kita mulai akeh basa luwih-kalawih lan ngaweh sistem sing perusahaan dengan LM kuwi nggawe kalih perusahaan dengan sampek, lan akeh sistem sistem sing di sistem modorologi, lan nganggep sistem sing dibutuhke LM kuwi nggawe komunitas, uga ngebeki perusahaan langkung sampek. Awak dhéwé nglangno teknik urip nggawe barang nggawe sistem dadi aturan kanggo nyenggawe Subword-evel informasi seneng semanti word vectors, ingregan Go model urip nggawe Neral lenguasi model, nggawe aliter word-evel nggawe Awak dhéwé éntuk éntuk nggawe LM tentang kanggo wong kuwi kesempatan kanggo langgar kuwi, lan mungkahi kuwi kesempatan kanggo langgar sapa-sapa sing gawe barang awak dhéwé, ngomong kebutuha kanggo langgambar kuwi nggawe tarjamahan. Punika dipunangé karo data kang dipunangé</abstract_jv>
      <abstract_he>הארכיטקטורות העצביות הן בראשות בבניית דוגמני שפה (LMs). בכל אופן, צפוי רמת מילים הוא בדרך כלל אגנוסטי של מידע רמה תת מילים (דמויות ורצועי דמויות) ומפעל על רשום מילים סגור, שמכיל מסגרת מילים מוגבלת. בעצם, בעוד דוגמנים מודעים למילים תת-מילים מגבירים ביצועים ברחבי מגוון של משימות NLP, עבודה קודמת לא הערכה את היכולת של דוגמנים אלה לסייע לחזוי מילה הבאה במשימות דוגמני שפה. דוגמנים מוודעים על רמה תת מילים כאלה צריכים להיות יעילים במיוחד לשפות עשירות מורפולוגית (MRLs) שמראות יחסים גבוהים מסוג לסימנים. In this work, we present a large-scale LM study on 50 typologically diverse languages covering a wide variety of morphological systems, and offer new LM benchmarks to the community, while considering subword-level information.  התרומה הטכנית העיקרית של העבודה שלנו היא שיטה חדשה להזרקת מידע על רמת המילים לתוך ווקטורי מילים סמנטיים, מושלמים לאימוני הדוגמה לשפת העצבית, כדי להקל בחזוי על רמת מילים. אנו מבצעים ניסויים במסגרת LM שבו מספר המילים הלא נדירות הוא גדול, ולהראות זכויות של בלכות חזקות ברחבי 50 שפות שלנו, במיוחד לשפות עשירות מורפולוגית. קודים ומערכת הנתונים שלנו זמינות לציבור.</abstract_he>
      <abstract_bo>སྐད་རིགས་མིང་དཔེ་གཞུང་ནང་གི་སྒེར་གྱི་བཟོ་བརྩིས་ཆེན་ཤིག་རེད། However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set. དངོས་གནས་སྟངས་དང་ཉིད་བརྗོད་པའི་མ་དཔེ་དབྱེ་བ་དག་གི་ལས་འགུལ་གྱི་སྣ་ཚོགས་རྣམས་མཐུན་རྐྱེན་བཟོས་ཀྱང་། སྔོན་གྱི་ལས་འགུལ་གྱི་མ་དཔེ་དབྱེ་བ་འདིའི་ལ Such subword-level informed models should be particularly effective for morphologically-rich languages (MRLs) that exhibit high type-to-token ratios. In this work, we present a large-scale LM study on 50 typologically diverse languages covering a wide variety of morphological systems, and offer new LM benchmarks to the community, while considering subword-level information. The main technical contribution of our work is a novel method for injecting subword-level information into semantic word vectors, integrated into the neural language modeling training, to facilitate word-level prediction. ང་ཚོས་LM་གི་སྒྲིག་ཚད་ནང་དུ་བརྟག་དཔྱད་བྱས་པའི་གྲངས་ཀ་གཟུགས་རིས་ཆེ་ཆུང་ཡོད། ང་ཚོའི་ཨང་དང་སྒྲིག་ཆ་སྒྲིག་འགོད་མང་ཙམ་སྤྱོད་ཐུབ་པ</abstract_bo>
      </paper>
    <paper id="33">
      <title>Detecting Institutional Dialog Acts in Police Traffic Stops</title>
      <author><first>Vinodkumar</first><last>Prabhakaran</last></author>
      <author><first>Camilla</first><last>Griffiths</last></author>
      <author><first>Hang</first><last>Su</last></author>
      <author><first>Prateek</first><last>Verma</last></author>
      <author><first>Nelson</first><last>Morgan</last></author>
      <author><first>Jennifer L.</first><last>Eberhardt</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <doi>10.1162/tacl_a_00031</doi>
      <abstract>We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in <a href="https://en.wikipedia.org/wiki/Traffic_stop">traffic stops</a>. Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78 % F-score) and stop (89 % F-score) level. We then develop speech recognition and segmentation algorithms to detect these acts at the stop level from raw camera audio (81 % F-score, with even higher accuracy for crucial acts like conveying the reason for the stop). We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches. This work may therefore inform and aid efforts to ensure the procedural justice of police-community interactions.</abstract>
      <pages>467–481</pages>
      <url hash="3eb694fb">Q18-1033</url>
      <video href="https://vimeo.com/285803587" />
      <bibkey>prabhakaran-etal-2018-detecting</bibkey>
    <title_ar>كشف أعمال الحوار المؤسسي في مواقف الشرطة المرورية</title_ar>
      <title_pt>Detecção de Atos de Diálogo Institucional em Paradas de Trânsito Policial</title_pt>
      <title_fr>Détecter les actes de dialogue institutionnel dans les arrêts de police</title_fr>
      <title_es>Detección de actos de diálogo institucional en paradas de tráfico policial</title_es>
      <title_ja>警察のトラフィックストップにおける機関のダイアログの検出</title_ja>
      <title_hi>पुलिस यातायात बंद हो जाता है में संस्थागत संवाद अधिनियमों का पता लगाना</title_hi>
      <title_zh>检警察通截</title_zh>
      <title_ru>Обнаружение актов институционального диалога на дорожных остановках полиции</title_ru>
      <title_ga>Na hAchtanna um Idirphl챕 Institi첬ideach a Bhrath i Stadanna Tr찼chta P처il챠n챠</title_ga>
      <title_ka>ინსტისტუციალური დიალოგის მოქმედება პოლიციის ტრაფიკური დასრულებაში</title_ka>
      <title_hu>Az intézményi párbeszéd intézkedéseinek felderítése a rendőrségi forgalom megállításában</title_hu>
      <title_el>Ανίχνευση θεσμικών πράξεων διαλόγου σε στάσεις κυκλοφορίας της αστυνομίας</title_el>
      <title_kk>Полиция трафик тоқтатуларында институттық диалог әрекеттерін анықтау</title_kk>
      <title_it>Rilevare gli atti di dialogo istituzionale nelle fermate del traffico di polizia</title_it>
      <title_lt>Institucinių dialogo veiksmų nustatymas policijos eismo sustabdymuose</title_lt>
      <title_mk>Детектирање институционални дејства за дијалог во застанувањата на полицискиот сообраќај</title_mk>
      <title_ms>Detecting Institutional Dialog Acts in Police Traffic Stops</title_ms>
      <title_mt>L-identifikazzjoni ta’ Atti ta’ Djalogu Istituzzjonali f’waqfiet tat-Traffiku tal-Pulizija</title_mt>
      <title_ml>പോലീസ് ട്രാഫിക് നിര്‍ത്തുന്നതിലെ ഇന്‍സ്റ്റിഷ്ടിക്കല്‍ ഡയലോഗ് നടപടികള്‍ കണ്ടുപിടിക്കുന്നു</title_ml>
      <title_mn>Сургуулийн диалогын үйл ажиллагааг олох</title_mn>
      <title_no>Finn institusjonelle dialoghandlingar i politiske trafikstørrar</title_no>
      <title_pl>Wykrywanie działań dialogu instytucjonalnego w policyjnych zatrzymaniach ruchu</title_pl>
      <title_ro>Detectarea actelor de dialog instituțional în opririle traficului poliției</title_ro>
      <title_so>Shaqeynta diyaarinta iskuulka ee booliska</title_so>
      <title_si>පොලිසිය ස්ථානය සංවාදය හොයාගන්න</title_si>
      <title_sr>Otkrivanje institucionalnog dijaloga u policijskim stanicama</title_sr>
      <title_sv>Upptäckt av institutionella dialogåtgärder vid polistrafikstopp</title_sv>
      <title_ta>தொழில்நுட்ப உரையாடல் விதிமுறைகளை கண்டுபிடிக்கிறது</title_ta>
      <title_ur>پولیس ٹراافکس ٹوپٹوں میں انٹیسٹیونٹیسٹ ڈیلوگ کے اعمال پتچا رہے ہیں</title_ur>
      <title_vi>Phát hiện di động liên lạc cục cảnh sát</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Откриване на действията на институционалния диалог при спиранията на полицейския трафик</title_bg>
      <title_da>Afsløring af institutionelle dialoghandlinger i polititrafikstop</title_da>
      <title_nl>Detectie van institutionele dialooghandelingen in verkeersstops van politie</title_nl>
      <title_ko>경찰 교통정거장의 행위를 검측하다</title_ko>
      <title_hr>Otkrivanje institucionalnog dijaloga u policijskim stanicama</title_hr>
      <title_fa>شناسایی عملکرد گفتگو سازمانی در قطعه های ترافیک پلیس</title_fa>
      <title_sw>Detecting Institutional Dialog Acts in Police Traffic Stops</title_sw>
      <title_id>Mengeteksi tindakan dialog institusi dalam berhenti lalu lintas polisi</title_id>
      <title_de>Aufdeckung institutioneller Dialoghandlungen bei Verkehrsstopps der Polizei</title_de>
      <title_sq>Duke zbuluar veprimet e dialogut institucional në ndalimet e trafikut policor</title_sq>
      <title_hy>Ուստիկանության ճանապարհորդության կանգնած գործողությունների ինստիտուցիոնալ հաղորդագրությունների հայտնաբերումը</title_hy>
      <title_tr>Polisiýa Traffici Durumlarynda Ullanyş Dialog Weziplerini keşif edilýär</title_tr>
      <title_af>Ontdekking van institusiele dialoog aktiwiteite in Polise Traffic Stoppe</title_af>
      <title_bn>পুলিশ ট্রাফিক স্টপে ইনস্টিটিভাল ডায়ালগের আইন সনাক্ত করা হচ্ছে</title_bn>
      <title_az>Polis Traffic Stops'da İnstitüsal Dialoog Oxumlarını keşif edir</title_az>
      <title_ca>Detecting Institutional Dialog Acts in Police Traffic Stop</title_ca>
      <title_bs>Otkrivanje institucionalnog dijaloga u policijskim stanicama</title_bs>
      <title_am>የፖሊስ የመስጠት መቆጣጠሪያ ጥያቄ</title_am>
      <title_cs>Detekce institucionálních dialogů v policejních dopravních zastávkách</title_cs>
      <title_fi>Institutionaalisten vuoropuhelutoimien havaitseminen poliisiliikenteen pysähdyksissä</title_fi>
      <title_et>Institutsioonilise dialoogi toimingute tuvastamine politseiliikluse peatustes</title_et>
      <title_jv>Digehi Daftar dialog Institugal</title_jv>
      <title_he>Detecting Institutional Dialog Acts in Police Traffic Stops</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Odkrivanje dejanj institucionalnega dialoga pri zaustavitvah policijskega prometa</title_sk>
      <title_bo>Polis Traffic Stop(S)ནང་གི་སྲིད་གཞུང་གི་ཌའི་ལོག་བློ་གཏོང་སྟོན་པ</title_bo>
      <abstract_ar>نحن نطبق أساليب الحوار الحسابي على لقطات الكاميرا التي ترتديها الشرطة على الجسم لنمذجة المحادثات بين ضباط الشرطة وأفراد المجتمع في محطات المرور. بالاعتماد على نظرية الحديث المؤسسي ، نقوم بتطوير مخطط وضع العلامات على خطاب الشرطة أثناء توقف حركة المرور ، و tagger للكشف عن أفعال الحوار المؤسسي (الأسباب ، عمليات البحث ، تقديم المساعدة) من النص المكتوب عند المنعطف (78٪ درجة F) و توقف (89٪ درجة F) المستوى. نقوم بعد ذلك بتطوير خوارزميات التعرف على الكلام والتجزئة لاكتشاف هذه الأفعال على مستوى التوقف من صوت الكاميرا الخام (81٪ درجة F ، مع دقة أعلى للأفعال الحاسمة مثل نقل سبب التوقف). نوضح أن هياكل الحوار التي أنتجها برنامج tagger الخاص بنا يمكن أن تكشف عما إذا كان الضباط يتبعون معايير إنفاذ القانون مثل التعريف بأنفسهم ، وشرح سبب التوقف ، وطلب الإذن بالبحث. وبالتالي ، قد يُعلم هذا العمل ويساعد الجهود المبذولة لضمان العدالة الإجرائية للتفاعلات بين الشرطة والمجتمع.</abstract_ar>
      <abstract_fr>Nous appliquons des méthodes de dialogue informatique aux séquences vidéo portées par les policiers afin de modéliser les conversations entre les policiers et les membres de la communauté dans les arrêts de circulation. En nous appuyant sur la théorie de la discussion institutionnelle, nous développons un système d'étiquetage pour le discours de la police pendant les arrêts de circulation, et un tagger pour détecter les actes de dialogue institutionnels (motifs, recherches, offres d'aide) à partir de texte transcrit au niveau du virage (78% F-score) et de l'arrêt (89% F-score). Nous développons ensuite des algorithmes de reconnaissance vocale et de segmentation pour détecter ces actes au niveau de l'arrêt à partir de l'audio brut de la caméra (score F de 81 %, avec une précision encore plus élevée pour les actes cruciaux comme la transmission du motif de l'arrêt). Nous démontrons que les structures de dialogue produites par notre tagger peuvent révéler si les agents suivent les normes d'application de la loi, comme se présenter, expliquer la raison de l'arrêt et demander l'autorisation pour les fouilles. Ce travail peut donc éclairer et aider les efforts visant à garantir la justice procédurale des interactions entre la police et la communauté.</abstract_fr>
      <abstract_pt>Aplicamos métodos de diálogo computacional a filmagens de câmeras de policiais usadas no corpo para modelar conversas entre policiais e membros da comunidade em paradas de trânsito. Apoiando-nos na teoria da fala institucional, desenvolvemos um esquema de rotulagem para a fala policial durante as paradas de trânsito e um tagger para detectar atos de diálogo institucional (Motivos, Buscas, Oferta de Ajuda) a partir do texto transcrito na virada (78% F-score) e nível de parada (89% F-score). Em seguida, desenvolvemos algoritmos de reconhecimento e segmentação de fala para detectar esses atos no nível de parada do áudio bruto da câmera (81% F-score, com precisão ainda maior para atos cruciais, como transmitir o motivo da parada). Demonstramos que as estruturas de diálogo produzidas por nosso pichador podem revelar se os policiais seguem as normas de aplicação da lei, como se apresentar, explicar o motivo da parada e pedir permissão para buscas. Este trabalho pode, portanto, informar e auxiliar os esforços para garantir a justiça processual das interações polícia-comunidade.</abstract_pt>
      <abstract_es>Aplicamos métodos de diálogo computacional a las imágenes de las cámaras de la policía para modelar las conversaciones entre oficiales de policía y miembros de la comunidad en las paradas de tráfico. Basándonos en la teoría del diálogo institucional, desarrollamos un esquema de etiquetado para el discurso policial durante las paradas de tráfico, y un etiquetador para detectar actos de diálogo institucional (Razones, Búsquedas, Ofrecer ayuda) a partir del texto transcrito en el nivel de giro (puntuación F del 78%) y parada (puntaje F del 89%). Luego, desarrollamos algoritmos de segmentación y reconocimiento de voz para detectar estos actos en el nivel de parada a partir del audio de la cámara sin procesar (puntaje F del 81%, con una precisión aún mayor para actos cruciales como transmitir el motivo de la parada). Demostramos que las estructuras de diálogo producidas por nuestro etiquetador podrían revelar si los oficiales siguen las normas de aplicación de la ley, como presentarse, explicar el motivo de la detención y pedir permiso para los registros. Por lo tanto, este trabajo puede informar y ayudar a los esfuerzos para garantizar la justicia procesal de las interacciones policía-comunidad.</abstract_es>
      <abstract_ja>トラフィックストップでの警察官とコミュニティメンバーの会話をモデル化するために、警察のボディーカメラ映像に計算ダイアログメソッドを適用しています。機関談話の理論に基づいて、交通停止中の警察の発言のラベリングスキームと、ターン（ 78 ％ Fスコア）および停止（ 89 ％ Fスコア）レベルでの文字起こしテキストから機関の対話行為（理由、検索、提供ヘルプ）を検出するタグを開発します。次に、RAWカメラオーディオから停止レベルでこれらの行為を検出するための音声認識およびセグメンテーションアルゴリズムを開発します（ 81 ％ Fスコア、停止の理由を伝えるような重要な行為の場合はさらに高い精度で）。私たちは、タガーによって作成されたダイアログ構造が、警察官が自己紹介、停止の理由の説明、および検索の許可を求めるなどの法執行機関の規範に従っているかどうかを明らかにすることができることを実証します。したがって、この作業は、警察とコミュニティの相互作用の手続き上の正義を確保するための努力に役立つかもしれません。</abstract_ja>
      <abstract_zh>吾将计当用于警察之摄像机镜头,以拟警察社区之通站点之间。 因局言理,为交通遮截间警察言开一标签方案,并发一标签器,施于转曲(78%F分数)与停车(89%F分数)级从转录本中检对(由,搜索助)。 然后发音分算,自始摄像头音频(81%F分数)止于止级,其于传止之要,精度愈高。 臣等标记器对构可以揭示官守法,如自陈说止之由及请索可也。 故可以为保警察与社区互动之序公正之力为信助。</abstract_zh>
      <abstract_hi>हम यातायात स्टॉप में पुलिस अधिकारियों और समुदाय के सदस्यों के बीच बातचीत को मॉडल करने के लिए पुलिस बॉडी-वियर्ड कैमरा फुटेज के लिए कम्प्यूटेशनल संवाद विधियों को लागू करते हैं। संस्थागत वार्ता के सिद्धांत पर निर्भर करते हुए, हम यातायात स्टॉप के दौरान पुलिस भाषण के लिए एक लेबलिंग योजना विकसित करते हैं, और बारी (78% एफ-स्कोर) और स्टॉप (89% एफ-स्कोर) स्तर पर लिखित पाठ से संस्थागत संवाद कृत्यों (कारण, खोज, सहायता की पेशकश) का पता लगाने के लिए एक टैगर विकसित करते हैं। फिर हम कच्चे कैमरे ऑडियो (81% एफ-स्कोर, स्टॉप के कारण को व्यक्त करने जैसे महत्वपूर्ण कृत्यों के लिए भी उच्च सटीकता के साथ) से स्टॉप स्तर पर इन कृत्यों का पता लगाने के लिए भाषण मान्यता और विभाजन एल्गोरिदम विकसित करते हैं। हम प्रदर्शित करते हैं कि हमारे टैगर द्वारा उत्पादित संवाद संरचनाएं यह प्रकट कर सकती हैं कि क्या अधिकारी कानून प्रवर्तन मानदंडों का पालन करते हैं जैसे कि खुद को पेश करना, स्टॉप का कारण समझाना, और खोजों के लिए अनुमति मांगना। इसलिए यह काम पुलिस-समुदाय इंटरैक्शन के प्रक्रियात्मक न्याय को सुनिश्चित करने के प्रयासों को सूचित और सहायता कर सकता है।</abstract_hi>
      <abstract_ru>Мы применяем методы вычислительного диалога к видеозаписям с камер с телом полицейского для моделирования разговоров между полицейскими и членами сообщества во время остановок на дорогах. Опираясь на теорию институциональной речи, мы разрабатываем схему маркировки полицейской речи во время остановок на дорогах, а также теггер для обнаружения институциональных диалоговых актов (Reasons, Searches, Offering Help) из транскрибируемого текста на уровне Turn (78% F-score) и Stop (89% F-score). Затем мы разрабатываем алгоритмы распознавания и сегментации речи, чтобы обнаружить эти действия на уровне остановки из необработанного аудио камеры (81% F-оценка, с еще более высокой точностью для критических действий, таких как передача причины остановки). Мы демонстрируем, что диалоговые структуры, созданные нашим тагером, могут показать, соблюдают ли сотрудники правоохранительных органов такие нормы, как представление, объяснение причины остановки и запрос разрешения на обыск. Таким образом, эта работа может послужить основой и подспорьем в усилиях по обеспечению процессуального правосудия при взаимодействии между полицией и общиной.</abstract_ru>
      <abstract_ga>Cuirimid modhanna dialóige ríomhaireachtúla i bhfeidhm ar phíosaí scannáin ceamara a chaitear le coirp na bpóilíní chun comhráití a eiseamláiriú idir oifigigh póilíní agus baill den phobal i stadanna tráchta. Ag brath ar theoiric na cainte institiúideach, forbraímid scéim lipéadaithe do chaint na bpóilíní le linn stadanna tráchta, agus clibeálaí chun gníomhartha dialóige institiúideacha (Cúinsí, Cuardach, Tairiscint Cabhair) a bhrath ó théacs tras-scríofa ag an cas (78% F-scór) agus leibhéal stad (89% F-scór). Forbróimid ansin halgartaim aitheantais cainte agus deighilte chun na gníomhartha seo a bhrath ag an leibhéal stad ó fhuaim ceamara amh (81% F-scór, le cruinneas níos airde fós le haghaidh gníomhartha ríthábhachtacha mar an chúis leis an stad a chur in iúl). Léirímid go bhféadfadh na struchtúir dialóige a tháirgeann ár gclibálaí a léiriú an leanann oifigigh noirm forghníomhaithe an dlí mar iad féin a thabhairt isteach, an chúis atá leis an stad a mhíniú, agus cead a iarraidh le haghaidh cuardaigh. D’fhéadfadh an obair seo, mar sin, eolas agus cúnamh a thabhairt d’iarrachtaí chun ceartas nós imeachta idirghníomhaíochtaí póilíneachta-pobail a chinntiú.</abstract_ga>
      <abstract_hu>Számítástechnikai párbeszédmódszereket alkalmazunk a rendőrség testviselt kamera felvételeire, hogy modellezzük a rendőrök és a közösség tagjai közötti beszélgetéseket a közlekedési megállóknál. Az intézményi beszélgetés elméletére támaszkodva kidolgozunk egy címkézési sémát a rendőrségi beszédhez a forgalmi megállások során, valamint egy címkézőt az intézményi párbeszédek (ok, keresések, segítség felajánlása) felismerésére a turn (78% F pontszám) és stop (89% F pontszám) szintjén. Ezt követően beszédfelismerő és szegmentációs algoritmusokat fejlesztünk ki, hogy ezeket a cselekményeket stop szinten észleljük a nyers kamera hangjából (81% F pontszám, még nagyobb pontossággal olyan fontos cselekmények esetén, mint a megállás okának közvetítése). Bemutatjuk, hogy a címkézőnk által létrehozott párbeszédstruktúrák megmutatják, hogy a tisztviselők betartják-e a bűnüldözési normákat, mint például bemutatkoznak, magyarázzák a leállítás okait, és engedélyt kérnek a keresésre. Ez a munka ezért tájékoztathatja és segítheti a rendőrség és a közösség közötti kapcsolatok eljárási igazságszolgáltatásának biztosítására irányuló erőfeszítéseket.</abstract_hu>
      <abstract_el>Εφαρμόζουμε υπολογιστικές μεθόδους διαλόγου σε πλάνα κάμερας που φοράνε το σώμα της αστυνομίας για να μοντελοποιήσουμε συζητήσεις μεταξύ αστυνομικών και μελών της κοινότητας σε στάσεις κυκλοφορίας. Βασιζόμενοι στη θεωρία της θεσμικής συζήτησης, αναπτύσσουμε ένα σύστημα σήμανσης για την αστυνομική ομιλία κατά τη διάρκεια των στάσεων κυκλοφορίας, και ένα σύστημα για την ανίχνευση θεσμικών πράξεων διαλόγου (Λόγοι, Αναζήτηση, προσφορά βοήθειας) από το μεταγραφμένο κείμενο στο επίπεδο στροφής (78% σκορ) και σταμάτημα (89% σκορ). Στη συνέχεια αναπτύσσουμε αλγόριθμους αναγνώρισης ομιλίας και κατακερματισμού για να ανιχνεύσουμε αυτές τις πράξεις στο επίπεδο στάσεων από ακατέργαστο ήχο κάμερας (81% σκορ, με ακόμα μεγαλύτερη ακρίβεια για κρίσιμες πράξεις όπως η μετάδοση του λόγου για τη διακοπή). Αποδεικνύουμε ότι οι δομές διαλόγου που παράγονται από το μαρκάρισμα μας θα μπορούσαν να αποκαλύψουν αν οι αξιωματικοί ακολουθούν κανόνες επιβολής του νόμου όπως η εισαγωγή τους, η εξήγηση του λόγου για τη διακοπή και η αίτηση άδειας για έρευνες. Συνεπώς, το έργο αυτό μπορεί να ενημερώσει και να βοηθήσει τις προσπάθειες για τη διασφάλιση της διαδικαστικής δικαιοσύνης των αλληλεπιδράσεων αστυνομίας-κοινότητας.</abstract_el>
      <abstract_ka>ჩვენ კომპუტაციონალური დიალოგის მეტირების გამოყენება პოლიციის კომერას კამერას მოდელური პარამეტრებისთვის პოლიციის ადამიანებისთვის და საზოგადოებო ადამ ინსტისტუციოლური საუბრის თეორიაზე შესახებ, ჩვენ პოლიციის საუბრილობა სქემის განვითარებით, რომელიც ტრაფიკაციის დარჩენების დროში, და ტეგჯერი ინსტისტუციოლური დიალოგის ქემის განვითარებით (მიზეზები, ძიება, დახმარება)  შემდეგ ჩვენ განვითარებთ სიტყვების განაცნობა და სეგენდაციის ალგორიტემი, რომელიც ამ აქტის განაცნობაში გადაწყვეტილი კამერის აუდიოდან (81% F-score, კი უფრო მეტი მარტივია მნიშვნელოვანი აქტი ჩვენ გამოჩვენებთ, რომ ჩვენი ტეგერიდან გამოვიყენებული დიალოგის სტრუქტურები შეუძლიათ აღმოჩვენოთ თუ არა უფლებელი მართლას წინასწორებელი ნორმები, როგორც ჩვენი თავიდან ჩვენი შეც ამიტომ ეს სამუშაო შეიძლება ინფორმაცია და დახმარება ძალიან, რომ დაახმარება პროცესტური სამართლად პოლიცია-საზოგადოებო ინტერ</abstract_ka>
      <abstract_it>Applichiamo metodi di dialogo computazionali ai filmati delle telecamere indossati dalla polizia per modellare le conversazioni tra agenti di polizia e membri della comunità nelle fermate del traffico. Basandoci sulla teoria del discorso istituzionale, sviluppiamo uno schema di etichettatura per il discorso della polizia durante le fermate del traffico e un tagger per rilevare gli atti di dialogo istituzionale (Ragioni, Ricerche, Offerta di Aiuto) dal testo trascritto a livello di turn (78% F-score) e stop (89% F-score). Sviluppiamo quindi algoritmi di riconoscimento vocale e segmentazione per rilevare questi atti a livello di stop dall'audio grezzo della fotocamera (81% F-score, con una precisione ancora maggiore per atti cruciali come trasmettere il motivo dello stop). Dimostriamo che le strutture di dialogo prodotte dal nostro tagger potrebbero rivelare se gli agenti seguono le norme delle forze dell'ordine come presentarsi, spiegare il motivo dell'arresto e chiedere il permesso per le perquisizioni. Questo lavoro può quindi informare e aiutare gli sforzi volti a garantire la giustizia procedurale delle interazioni tra polizia e comunità.</abstract_it>
      <abstract_lt>We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in traffic stops.  Remdamiesi institucinių kalbų teorija, mes parengiame policijos kalbos ženklinimo sistemą eismo sustojimo metu ir ženklinimo sistemą, skirtą nustatyti institucinius dialogo veiksmus (priežastys, paieškos, pagalbos teikimas) iš transkripto teksto sukimo (78 % F-taško) ir sustojimo (89 % F-taško) lygiu. Tuomet parengiame kalbos pripažinimo ir segmentacijos algoritmus, siekiant nustatyti šiuos veiksmus sustabdymo lygiu nuo neapdorotos kameros garso (81 % F balas, dar tikslesnis svarbiausiems veiksmams, pavyzdžiui, pranešimui apie sustabdymo priežastį). Mes demonstruojame, kad mūsų žymeklio sukurtos dialogo struktūros galėtų atskleisti, ar pareigūnai laikosi teisėsaugos normų, pvz., pasiūlydami save, paaiškindami sustojimo priežastį ir prašydami leidimo paieškoti. Todėl šis darbas gali informuoti ir padėti užtikrinti policijos ir bendruomenės sąveikos procesinį teisingumą.</abstract_lt>
      <abstract_kk>Біз компьютерлік диалог әдістерін полицейские офицерлер мен трафик тоқтатындағы коммуналық мүшелер арасындағы сұрақтар үлгісіне қолданып тұрамыз. Институциялық сөйлесу теориясына қатынап, трафик тоқтату кезінде полициялық сөйлесу сұлбасын жазып, институттық диалог әрекеттерін (себептері, Іздеу, Көмекті жеткізу) деңгейінде (78% F- score) жазылған мәтінден (89% F- score) тоқтату үшін тег Содан кейін бұл әрекеттерді бақылау деңгейінде табу үшін сөздерді анықтау және сегментациялық алгоритмдерді жасаймыз (81% F- нүктесі, тоқтатудың себебін табу үшін дұрыстығы дұрыстығы бар). Біз белгілеріміздің диалог құрылымызды көрсету үшін көмекшілер өзінің орындау нормаларына қатынау, тоқтатудың себебін түсіндіру және іздеу рұқсаттарын сұрайтынын көрсетуге болады. Сондықтан бұл жұмыс полицияның көмектесіліктерінің процессуалдық тәртібін қамтамасыз ету және көмектесуі мүмкін.</abstract_kk>
      <abstract_mk>Ние ги применуваме методите на компјутативниот дијалог за снимките од камерите носени од полициското тело на моделите на разговорите помеѓу полицајците и членовите на заедницата на сообраќајните застаноци. Со зависност од теоријата на институционалните разговори, развиваме шема за означување на полицискиот говор за време на сообраќајните застаноци, и означувач за детектирање на институционалните дејства на дијалог (Причини, Барања, понуда на помош) од транскриптираниот текст на нивото на врт (78 отсто F-оценка) и застанување (89 от We then develop speech recognition and segmentation algorithms to detect these acts at the stop level from raw camera audio (81% F-score, with even higher accuracy for crucial acts like conveying the reason for the stop).  We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches.  Оваа работа може да ги информира и помогне напорите за обезбедување на процедурната правда на интеракциите помеѓу полицијата и заедницата.</abstract_mk>
      <abstract_ml>ട്രാഫിക് നിര്‍ത്തുന്നതില്‍ പോലീസുകാര്‍ക്കും സമൂഹത്തിന്‍റെ അംഗങ്ങള്‍ക്കും തമ്മില്‍ സംസാരിക്കാന്‍ പോലീസ് ശരീരത്തില്‍ ധര സ്ഥാനത്തിലെ സംസാരം സംബന്ധിച്ചുള്ള തിയറിയില്‍ നമ്മള്‍ ട്രാഫിക്ക് നിര്‍ത്തുമ്പോള്‍ പോലീസ് സംസാരിക്കുന്ന ഒരു ലേബില്‍ പദ്ധതിയുണ്ടാക്കുന്നു. ട്രാഫിക്ക് സ്റ്റോപ്പില്‍ സ പിന്നീട് നമ്മള്‍ സംസാരം തിരിച്ചറിയുന്നതും സംഘത്തിന്റെ ആല്‍ഗോരിറ്റികളും നിര്‍മ്മിക്കുന്നു. ഈ പ്രവര്‍ത്തനങ്ങള്‍ സ്റ്റോപ്പ് നില്‍ക്കുന്നതില്‍ നിന നമ്മുടെ ടാഗ്ഗര്‍ നിര്‍മ്മിക്കുന്ന ഡയലോഗ് ഘടനകള്‍ നമ്മുടെ സംഘടിപ്പിക്കുന്നത് തെളിയിച്ചുകൊടുക്കുന്നതാണ് ഓഫീസര്‍മെന്‍റ് നിയമങ്ങള്‍  അതുകൊണ്ട് ഈ ജോലി പോലീസ് സമൂഹത്തിന്റെ പരസ്പരം ന്യായീകരിക്കുന്നതിനെ ഉറപ്പാക്കാനും സഹായിക്കാനും ശ്രമ</abstract_ml>
      <abstract_ms>Kami melaksanakan kaedah dialog komputasi untuk rakaman kamera yang dipakai oleh badan polis untuk model perbualan antara pegawai polis dan ahli komuniti dalam hentian lalu lintas. Bergantung pada teori percakapan institusi, kami mengembangkan skema label untuk ucapan polis semasa berhenti lalu lintas, dan tag untuk mengesan tindakan dialog institusi (Alasan, Carian, Menawarkan Bantuan) dari teks ditranskrip pada aras pusingan (78% skor F) dan berhenti (89% skor F). Kemudian kami mengembangkan algoritma pengenalan dan segmen ucapan untuk mengesan tindakan-tindakan ini pada tahap hentian dari audio kamera mentah (skor F 81%, dengan akurat lebih tinggi untuk tindakan penting seperti menyampaikan alasan untuk hentian). Kami menunjukkan bahawa struktur dialog yang dibuat oleh tag kami boleh mengungkapkan sama ada pegawai mengikut norm pemerintahan undang-undang seperti memperkenalkan diri mereka sendiri, menjelaskan alasan untuk berhenti, dan meminta izin untuk mencari. Kerja ini mungkin memberitahu dan membantu usaha untuk memastikan keadilan prosedur interaksi polis-komuniti.</abstract_ms>
      <abstract_mt>Aħna napplikaw metodi ta’ djalogu komputattiv għall-immaġni tal-kamera mġarrba mill-pulizija biex nimmudellaw konverżjonijiet bejn l-uffiċjali tal-pulizija u l-membri tal-komunità fil-waqfiet tat-traffiku. Abbażi tat-teorija tat-taħditiet istituzzjonali, a ħna niżviluppaw skema ta’ tikkettar għad-diskors tal-pulizija waqt il-waqfiet tat-traffiku, u tikkettar biex jinstabu atti ta’ djalogu istituzzjonali (Raġunijiet, Tfittxijiet, Għajnuna Offerta) minn test traskritt fil-livell tad-dawra (78% punteġġ F) u waqfien (89% punteġġ F). Imbagħad niżviluppaw algoritmi tar-rikonoxximent tad-diskors u tas-segmentazzjoni biex nidentifikaw dawn l-atti fil-livell ta’ waqfien mill-awdjo tal-kamera mhux ipproċessata (punteġġ F ta’ 81 %, b’preċiżjoni saħansitra ogħla għal atti kruċjali bħat-trasmissjoni tar-raġuni għall-waqfien). We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches.  Dan ix-xogħol jista’ għalhekk jinforma u jgħin l-isforzi biex tiġi żgurata l-ġustizzja proċedurali tal-interazzjonijiet bejn il-pulizija u l-komunità.</abstract_mt>
      <abstract_mn>Бид компьютерийн диалог аргыг цагдааны биеийн камерын зурагт цагдааны оффицер болон нийгмийн гишүүн хоорондын ярилцлага загварчлахад хэрэглэдэг. Байгууллагын ярианы онолын тухай бид цахилгаан зогсоох үед цагдааны ярианы жагсаалт схемийг хөгжүүлж, байгууллагын диалог үйл ажиллагааг (шалтгаан, шалтгаан, хайх, тусламжтайгаар) шинэчлэгдсэн текст (78% F-score) болон зогсоох (89% F-score). Дараа нь бид илтгэлийн танихыг болон загварын алгоритмыг хөгжүүлдэг. Энэ үйл явдлыг цэвэр камерын аудиосын зогсоох түвшинд олж мэдэхэд (81% F-score, зогсоох шалтгааныг илүү тодорхойлж байгаа нь илүү их тодорхойлж байна Бид өөрсдийгөө танилцуулах, зогсоох шалтгааныг тайлбарлаж, хайрлах боломжуудыг хүлээн зөвшөөрөх эсэхийг харуулж чадна. Иймээс энэ ажил цагдаа болон нийгмийн харилцааны процессуалд шударга ёс байдлыг гаргах боломжтой тусламжтай байж болно.</abstract_mn>
      <abstract_pl>Wykorzystujemy obliczeniowe metody dialogu do nagrania z kamer noszonych ciałem policji do modelowania rozmów między funkcjonariuszami policji a członkami społeczności na przystankach drogowych. Opierając się na teorii rozmów instytucjonalnych, opracowujemy schemat etykietowania mowy policyjnej podczas przystanków drogowych oraz tagger do wykrywania instytucjonalnych aktów dialogowych (Powody, Wyszukiwania, Oferowanie Pomocy) z transkrypcji tekstu na poziomie skrętu (78% F-score) i stop (89% F-score). Następnie opracowujemy algorytmy rozpoznawania mowy i segmentacji, aby wykrywać te akty na poziomie stop z surowego dźwięku kamery (81% F-score, z jeszcze większą dokładnością dla kluczowych aktów, takich jak przekazanie przyczyny zatrzymania). Pokazujemy, że struktury dialogowe tworzone przez naszego tagera mogą ujawnić, czy funkcjonariusze przestrzegają norm ścigania, takich jak przedstawienie się, wyjaśnienie powodu zatrzymania się i proszenie o zgodę na przeszukania. Dlatego też działania te mogą pomóc w wysiłkach mających na celu zapewnienie sprawiedliwości proceduralnej w interakcjach policja-społeczność.</abstract_pl>
      <abstract_no>Vi bruker datamaskiner-dialogmetodar til biletformatet med korp-kameraer til å modellere samtaler mellom poliofficer og fellesskapslinjer i trafikstepp. I tillegg til teorien om institusjonell tale, utviklar vi eit merkelapp for politiske tale under trafikkbytingar, og ein merkelapp for å finna institusjonelle dialoghandlingar (grunn, søk, tilbyr hjelp) frå transkripte tekst på turnen (78% F- score) og stopp (89% F- score). Vi utviklar så tale gjenkjenning og segmenteringsalgoritme for å finna disse handlingane på stoppnivået frå råkameraludio (81% F- score, med enda høgare nøyaktighet for nøyaktige handlingar som å konvertera grunnen for stoppen). Vi demonstrerer at dialogstrukturene som er produsert av merkelappen vår kunne opna om kontorene følgjer lovforskjellingsnorme som introduserer seg selv, forklarer grunnen for stoppen og spørja løyve for søk. Dette arbeidet kan derfor informere og hjelpe innsatt for å sikre prosessorsrettigheten på politiske og fellesskapsrektane.</abstract_no>
      <abstract_ro>Aplicăm metode de dialog computațional înregistrărilor cu camerele purtate de poliție pentru a modela conversațiile dintre ofițerii de poliție și membrii comunității în stațiile de trafic. Bazându-ne pe teoria discuției instituționale, dezvoltăm o schemă de etichetare a discursului poliției în timpul opririi traficului și un etichetor pentru detectarea actelor de dialog instituțional (Motive, Căutări, Oferirea de Ajutor) din textul transcris la nivel de viraj (78% F-scor) și stop (89% F-scor). Apoi dezvoltăm algoritmi de recunoaștere a vorbirii și segmentare pentru a detecta aceste acte la nivel de stop din audio brut camera (81% F-scor, cu o precizie și mai mare pentru acte cruciale, cum ar fi transmiterea motivului opririi). Demonstrăm că structurile de dialog produse de etichetatorul nostru ar putea dezvălui dacă ofițerii respectă normele de aplicare a legii, cum ar fi introducerea ei înșiși, explicarea motivului opririi și cererea permisiunii pentru percheziții. Prin urmare, această activitate poate informa și sprijini eforturile de asigurare a justiției procedurale a interacțiunilor polițienești-comunitate.</abstract_ro>
      <abstract_sr>Mi primjenjujemo računalne metode dijaloga na snimke kamere sa policijskim telom na model razgovora između policijskih časnika i članova zajednice u saobraćajnim stanicama. S obzirom na teoriju institucionalnog razgovora, razvijamo šemu označavanja za policijski govor tokom saobraćajnih stanica, i označavač za otkrivanje institucionalnih dijalogskih akcija (razloge, potražnje, ponuditi pomoć) od prepisanog teksta na okviru (78% F-rezultata) i zaustavljamo nivo (89% F-rezultata). Zatim razvijamo algoritme priznanja govora i segmentacije kako bi otkrili ove akcije na nivou stanja od zvuka sirovine kamere (81% F-rezultata, sa još većom preciznošću za ključne akcije kao što su konverzacija razloga stanja). Pokazujemo da su strukture dijaloga proizvođene od strane našeg etiketera mogle otkriti da li službenici prate pravila provedbe zakona poput predstavljanja sebe, objašnjavanja razloga stanja i traže dozvolu za potragu. Ovaj rad stoga može obavijestiti i pomoći naporima kako bi osigurala procesualnu pravdu policijske i zajedničke interakcije.</abstract_sr>
      <abstract_sv>Vi tillämpar beräkningsdialogmetoder på poliskroppsburna kamerabilder för att modellera samtal mellan poliser och samhällsmedlemmar i trafikstopp. Utifrån teorin om institutionellt samtal utvecklar vi ett märkningssystem för polistal vid trafikstopp och en tagger för att upptäcka institutionella dialoghandlingar (Reasons, Searches, Offering Help) från transkriberad text på turn (78% F-poäng) och stopp (89% F-poäng). Vi utvecklar sedan taligenkännings- och segmenteringsalgoritmer för att upptäcka dessa handlingar på stoppnivå från rå kameraljud (81% F-poäng, med ännu högre noggrannhet för viktiga handlingar som att förmedla orsaken till stoppet). Vi visar att de dialogstrukturer som produceras av vår taggare kan avslöja om tjänstemän följer brottsbekämpande normer som att introducera sig, förklara orsaken till stoppet och be om tillstånd för sökningar. Detta arbete kan därför utgöra underlag för och stödja insatserna för att säkerställa processrättslig rättvisa i samverkan mellan polis och samhälle.</abstract_sv>
      <abstract_ta>நாங்கள் கணக்கிட்ட உரையாடல் முறைமைகளை போலீஸ் உடல் அணிந்த கேமிரா படத்திற்கு பயன்படுத்துகிறோம் போலீசாளர் மற்றும் சமூகத்தின நிறுவனமான பேச்சு திட்டத்தின் தொடர்பு கொண்டிருக்கும் போலீஸ் பேச்சின் முறைமையை நாம் உருவாக்குகிறோம் போது, மற்றும் எழுதப்பட்ட உரையாடல் உரையாடல் செயல்களை கண்டறியும் (காரணம், தேடு பின்னர் நாம் பேச்சு அடையாளம் மற்றும் பிரிவுகள் பிரிவுகளை உருவாக்குகிறோம் மற்றும் நிறுத்தப்பட்ட நிலைமையில் இந்த செயல்களை கண்டறியும் (81% F- score, நி எங்கள் குறிப்பாக்கி உருவாக்கப்பட்ட உரையாடல் உரையாடல் உரையாடல் அமைப்புகள் தெரிவிக்க முடியும் அதிகாரிகள் தங்களை அறிவிக்கும் போது சட்ட நிற எனவே இந்த வேலை போலீஸ் சமூகத்திற்கான செயல்முறையில் நியாயத்தை உறுதிப்படுத்துவதற்கு அறிவித்து உதவி முயற்</abstract_ta>
      <abstract_si>අපි පරීක්ෂණ සංවාදය විදිහට පොලිසියේ කැමරාව ඇඳුම් කරලා තියෙන්නේ පොලිසිය නිලධාරිය සහ සමාජ සමාජාත් සංස්ථාවික කතාවගේ සිද්ධාව සඳහා අපි පොලිසිය කතාවට ලේබිල් ස්කම්පයක් විස්තර කරනවා, සහ සංස්ථාවික සංවාද ක්‍රියාවක් හොයාගන්න ටැගර් ක්‍රියාත්මක (හේතුව, ස අපි ඊට පස්සේ කතාව අඳුරගන්න සහ කැමරා ඇල්ගෝරිතම් විශ්වාස කරනවා මේ ක්‍රියාව හොයාගන්න ස්ථානයේ කැමරා අඩියෝගෙන් නවත්තන්න ස්ථානය අපි ප්‍රකාශ කරනවා අපේ ටැගර් වලින් නිර්මාණය කරපු සංවාද සංවාදය ප්‍රකාශ කරන්න පුළුවන් කියලා, නියෝජිත නියෝජිතය නියෝ ඉතින් මේ වැඩේ පොලිසිය සමාජිකය සම්බන්ධතාවක් ගැන පරීක්ෂණය සඳහා ප්‍රශ්නයක් තියෙන්න සහ උදව</abstract_si>
      <abstract_so>Shaqooyin xisaabta ah ayaannu booliska ka codsanaynaa kamerada booliska meydka ah si aan u sameynno sameynta hadalka ka dhexeeya saraakiisha booliska iyo xubnaha bulshada ee safarka. Ku xiriirta fikrada hadalka iskuulka ah, waxaynu horumarinnaa qorshe sawir ah oo ku qoran hadalka booliska marka uu joogo gaadiidka, iyo bandhig in lagu ogaado falimaha diyaarinta iskuulka (sababta, raadinta, caawimaadda la siiyo) laga soo qoro saxanka qoraalka (78% F-scorta) kadibna joojinno (89% F-score). Markaas waxaynu horumarinaa aqoonsashada hadalka iyo qeybaha si aan u ogaano falimahaas heerka joogista ka soo baxno codka kamerada (81% F-scorta, xittaa aad ugu sahlan waxyaabaha muhiimka ah sida sababta joojinta). Waxaynu muujinnaa in dhismaha dialogka ee warqaddayada lagu soo qoray ay ay muujin karaan in saraakiisha ay raacaan xeerarka saraakiisha, sida in ay isu soo bandhigaan sababta joojinta iyo in ay ogolaanshiyo raadinta. Sidaa darteed shaqadaas wuxuu ogeysiin karaa iyo caawimaad u sameyn karaa in caddaaladda lagu xaqiijiyo iskaashatada bulshada.</abstract_so>
      <abstract_ur>ہم کمپیوٹریشن ڈالیلوگ طریقے پولیس کے جسم کا کامرا فیٹیج کے لئے پولیس افسروں اور کمونٹی جماعتوں کے درمیان رابطہ کی مدل کے لئے استعمال کرتے ہیں. اور ہم نے ترافیکٹ ایستوں میں پولیس کی بات کی تئوری کے بارے میں ایک لابلینگ طریقہ ایجاد کیا ہے اور ایک ٹاگر کو ترافیکٹ ایستوں کے بارے میں لکھی ہوئی پیغام کے بارے میں لکھی ہوئی پیغام سے پہچان سکتا ہے اور (89% F-score) سطح سے روک سکتا ہے۔ اس کے بعد ہم کلام کی شناسایی اور سگریٹ الگوریٹم کو ایجاد کریں گے کہ ان عمل کو روئیں کامری آڈیو سے روئیں سطح سے پہچان سکیں (81% F-اسکور، اور اس سے بھی زیادہ ضروری کے کاموں کے لئے زیادہ دقیق ہے جیسے روئیں کے دلیل پہچان سکیں)۔ ہم نشان دیتے ہیں کہ ہمارے ٹیجر کے ذریعے پیدا ہوئے ڈالیجر کی ساختاری ظاہر کر سکتے ہیں کہ کیا افسران قانون کے مطابق قوانین کی پیروی کریں جیسے اپنے آپ کو معلوم کریں، روکنے کے دلیل کی توضیح کریں اور جہاد کے لئے اجازت طلب کریں اس لئے یہ کام پولیس-کمیونٹی تعاملات کی پردازشی عدالت کے مطابق بتائی اور مدد کی کوشش کرتی ہے.</abstract_ur>
      <abstract_uz>Biz kompyuter muloqat usullarini polisi qo'llangan kameraga foydalanamiz, transportlar to ʻxtatishda polish officials va jamiyatlarning hammasidagi axborot modelida muloqat qilamiz. Tashkilot haqida o'zgarishda, biz shifokorlar to ʻxtatishda polish gapirishni qo'shish qolipini yaratib, va tizim muloqat oynasini aniqlash (sabablar, qidirish, yordam qilish) bilan yozib qo'yilgan matn (78% F scorida) davomida toʻxtatish imkoniyatini yaratumiz va 89% F scorini toʻxtatish. Keyin biz bu amallarni to ʻxtatish darajadagi amallarni aniqlash uchun gapiruvchining tanlash va ajratish algoritlarini tahlil qilamiz (81% F scorida o'zgartirish uchun eng muhim amalga oshirish mumkin). Biz yordam berilgan muloqat tuzuvlarimiz bilan yaratilgan muloqat tuzuvlarini ko'rsatishimiz mumkin. Oʻzgarishlar qoidani ishga tushirish uchun qoidalarni boshqarishi mumkin, toʻxtatish uchun sababini o'rganish va qidirish uchun ruxsat soʻrashi mumkin. Шундай қилиб, бу ишда Polish jamiyatlarning xizmatlarini aniqlashga harakat qilish va yordam berishi mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi sử dụng các phương pháp thoại tính cho cảnh sát băng hình được đeo trên người để mô hình cuộc đối thoại giữa cảnh sát và thành viên cộng đồng trong các trạm dừng giao thông. Dựa vào giả thuyết về ngôn ngữ nội bộ, chúng tôi phát triển một kế hoạch đánh dấu cho ngôn ngữ cảnh sát khi giao thông dừng lại, và một khẩu phần để phát hiện các hoạt động trong hộp thoại chính thống (Lý do, Tìm kiếm, Trợ giúp) khỏi những đoạn được ghi lại tại trình xoay (7897. F-score) và dừng (897. F-score). Sau đó chúng tôi phát triển thuật to án nhận dạng giọng nói và phân đoạn để phát hiện những hành động này ở mức dừng từ ghi âm máy quay thô (81 tổng số F, với độ chính xác thậm chí cao hơn cho các hành động quan trọng như là cung cấp nguyên nhân của việc dừng lại). Chúng tôi chứng minh rằng các cấu trúc hộp thoại sản xuất bởi người chụp có thể tiết lộ liệu các sĩ quan có tuân theo các quy tắc thực thi pháp luật như tự giới thiệu mình, giải thích nguyên nhân của việc dừng lại, và xin phép tìm kiếm. Việc này có thể cung cấp và hỗ trợ các nỗ lực nhằm đảm bảo công lý thủ tục về các mối quan hệ giữa cảnh sát và cộng đồng.</abstract_vi>
      <abstract_da>Vi anvender beregningsmæssige dialogmetoder til politiets kropsbårne kameraoptagelser til at modellere samtaler mellem politifolk og lokalsamfundsmedlemmer i trafikstop. Med udgangspunkt i teorien om institutionel tale udvikler vi en mærkningsskema for politiets tale under trafikstop, og en tagger til at opdage institutionelle dialoghandlinger (Årsager, Søgninger, Tilbyder Hjælp) fra transskriberet tekst på turn (78% F-score) og stop (89% F-score) niveau. Vi udvikler derefter talegenkendelse og segmentering algoritmer til at registrere disse handlinger på stopniveau fra rå kameralyd (81% F-score, med endnu højere nøjagtighed for vigtige handlinger som formidling af årsagen til stoppet). Vi demonstrerer, at dialogstrukturerne produceret af vores tagger kunne afsløre, om betjente følger retshåndhævelsesnormer som at introducere sig selv, forklare årsagen til stoppet og bede om tilladelse til eftersøgninger. Dette arbejde kan derfor danne grundlag for og støtte bestræbelserne på at sikre retfærdigheden i forbindelse med samspil mellem politi og samfund.</abstract_da>
      <abstract_hr>Primjenjujemo računalne metode dijaloga na snimke kamere koje nose policijski tijelo na model razgovora između policijskih časnika i članova zajednice u saobraćajnim stanicama. S obzirom na teoriju institucionalnog razgovora, razvijemo program označavanja za govor policije tijekom saobraćajnih stanica, i označavač za otkrivanje institucionalnih dijalogskih aktova (Reasons, Searches, Offering Help) od prepisanog teksta na okviru (78% F-score) i zaustaviti (89% F-score). Zatim razvijamo algoritme priznanja govora i segmentacije kako bi otkrili ove akcije na razini zaustavljanja zvuka sirovine kamere (81% F-rezultata, s čak većom preciznošću za ključne akcije kao što su konverzacija razloga zaustavljanja). Pokazujemo da su strukture dijaloga proizvođene od strane našeg značkara mogle otkriti da li službenici prate pravila provedbe zakona poput uvođenja sebe, objašnjavajući razlog stanja i tražiti dozvolu za potragu. Ovaj rad stoga može obavijestiti i pomoći napore kako bi se osigurala proceduralna pravda interakcija policije i zajednice.</abstract_hr>
      <abstract_id>We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in traffic stops.  Bergantung pada teori pembicaraan institusi, kami mengembangkan skema label untuk pembicaraan polisi selama berhenti lalu lintas, dan tag untuk mendeteksi tindakan dialog institusi (Alasan, Pencarian, Menawarkan Bantuan) dari teks transkrip pada tingkat pusingan (78% skor F) dan berhenti (89% skor F). Kemudian kami mengembangkan algoritma pengenalan pidato dan segmentasi untuk mendeteksi tindakan ini pada tingkat berhenti dari audio kamera mentah (81% skor F, dengan akurasi bahkan lebih tinggi untuk tindakan penting seperti menyampaikan alasan untuk berhenti). Kami menunjukkan bahwa struktur dialog yang dibuat oleh tagger kami dapat mengungkapkan apakah petugas mengikuti norma pemerintahan hukum seperti memperkenalkan diri mereka sendiri, menjelaskan alasan untuk berhenti, dan meminta izin untuk mencari. Pekerjaan ini mungkin menginformasi dan membantu usaha untuk memastikan keadilan prosedur dari interaksi polisi-komunitas.</abstract_id>
      <abstract_nl>We passen computerdialogmethoden toe op camerabeelden van politieagenten om gesprekken tussen politieagenten en gemeenschapsleden in verkeersstops te modelleren. Op basis van de theorie van institutioneel gesprek ontwikkelen we een labelschema voor politiespreken tijdens verkeersstops, en een tagger om institutionele dialoghandelingen (Redens, Zoekopdrachten, Offering Help) te detecteren van getranscribeerde tekst op het niveau van bocht (78% F-score) en stop (89% F-score). Vervolgens ontwikkelen we spraakherkennings- en segmentatiealgoritmes om deze handelingen op stopniveau te detecteren vanuit ruwe cameraaudio (81% F-score, met nog hogere nauwkeurigheid voor cruciale handelingen zoals het overbrengen van de reden van de stop). We tonen aan dat de dialoogstructuren van onze tagger kunnen onthullen of agenten wetshandhavingsnormen volgen, zoals zichzelf voorstellen, de reden van de stop uitleggen en toestemming vragen voor zoekopdrachten. Dit werk kan derhalve bijdragen aan de inspanningen om de procedurele rechtvaardigheid van de interactie tussen politie en gemeenschap te waarborgen.</abstract_nl>
      <abstract_bg>Ние прилагаме изчислителни диалогови методи за кадри от камери, носени от полицейско тяло, за да моделираме разговори между полицаи и членове на общността при спиране на трафика. Разчитайки на теорията на институционалния разговор, разработваме схема за етикетиране на полицейската реч по време на спиране на трафика, както и тагер за откриване на институционални диалогови действия (причини, търсения, предлагане на помощ) от транскрибирания текст на завоя (78% F-score) и стоп (89% F-score) ниво. След това разработваме алгоритми за разпознаване на речта и сегментиране, за да открием тези действия на ниво стоп от необработен звук на камерата (81% F-score, с още по-висока точност за важни действия като предаване на причината за спирането). Ние демонстрираме, че диалоговите структури, създадени от нашия маркер, могат да разкрият дали служителите следват нормите на правоохранителните органи, като представяне, обясняване на причината за спирането и искане за разрешение за претърсване. Поради това тази работа може да информира и да подпомогне усилията за осигуряване на процесуално правосъдие при взаимодействията между полицията и общността.</abstract_bg>
      <abstract_de>Wir wenden computergestützte Dialogmethoden auf körpergetragenes Kameramaterial der Polizei an, um Gespräche zwischen Polizeibeamten und Gemeindemitgliedern an Verkehrshaltestellen zu modellieren. Basierend auf der Theorie des institutionellen Gesprächs entwickeln wir ein Beschriftungsschema für Polizeisprache bei Verkehrsstopps und einen Tagger, um institutionelle Dialoghandlungen (Gründe, Suchanfragen, Hilfeangebote) aus transkribiertem Text auf Kurven- (78% F-Score) und Stop- (89% F-Score) Ebene zu erkennen. Anschließend entwickeln wir Spracherkennungs- und Segmentierungsalgorithmen, um diese Akte auf Stop-Ebene aus rohem Kameraaudio (81% F-Score) zu erkennen, mit noch höherer Genauigkeit für entscheidende Akte wie die Vermittlung der Ursache für den Stopp. Wir zeigen, dass die Dialogstrukturen unseres Taggers zeigen könnten, ob Beamte Strafverfolgungsnormen befolgen, wie sich vorzustellen, den Grund für den Stopp zu erklären und um Erlaubnis für Durchsuchungen zu bitten. Diese Arbeit kann daher die Bemühungen unterstützen, die Verfahrensgerechtigkeit von polizeilichen und gemeinschaftlichen Interaktionen sicherzustellen.</abstract_de>
      <abstract_sw>Tunatumia mbinu za mazungumzo ya kompyuta katika video za video za polisi waliovaa miili ya kamera ili kuonyesha mazungumzo kati ya maafisa wa polisi na wanachama wa jamii katika kusitisha mafuta. Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78% F-score) and stop (89% F-score) level.  Kisha tunaendelea kutambua hotuba na vipengele vya mchanganyiko ili kutambua vitendo hivi kwenye kiwango cha kusimama kutokana na sauti mbaya za kamera (vipimo vya asilimia 81 F, ikiwa ni sahihi zaidi kwa vitendo muhimu kama vile kutangaza sababu ya kusitishwa). Tunaonyesha kuwa miundombinu ya mazungumzo yaliyotengenezwa na tagge yetu inaweza kuonyesha ikiwa maafisa wanafuata utaratibu wa sheria kama vile kuwasilisha wenyewe, na kuelezea sababu ya kusitisha, na kuomba ruhusa kwa kutafuta. Kwa hiyo kazi hii inaweza kutoa taarifa na kusaidia jitihada za kuhakikisha haki za utaratibu wa mahusiano ya kijamii ya polisi.</abstract_sw>
      <abstract_tr>Biz polisiýa ofisleri we jemgyýet adamlary arasyndaky gürrüňler bilen söhbetmäge kömekleşik dialog yöntemlerini trafik duranlarynda polisiýa düzülen kamera wideoýasyna uygulapdyrys. Institucional gürrüň teoriýasyna görä, trafik duraklarynda polisiýa sözleriniň üçin etiketleme taslamasyny we duranlar (78% F-score) derejesinden ýazylan metin tanymak üçin etiketleme taslamasyny çykarýarys we duranlar (89% F-score). Sonra bu hereketleri dury kameradan tapmak üçin çykyş tanamak we segmentasiýa algoritmalaryny geliştirdik (81% F अंda, haltyň sebäbini söňlemek ýaly möhüm hereketleriň dogrylygyny bilen deňleýäris). Tiglarymyz tarapyndan üretilen dialogyň düzümleriniň kanunlaryň özlerini daşartmak ýaly kanunlaryň daly goramagyny, duranyň sebäbini düşündirip, gözlemek üçin rugsat soramagyny görkezip bilerdigini görkezip bilerdik. Şonuň üçin bu işi polisiýa-jemgyýetçiliklerin işleýän adalatlygyny garamazlyk üçin bilip biler we kömekleýän çabalary bilýär.</abstract_tr>
      <abstract_af>Ons het rekenaar dialoog metodes aangepas na polisie liggaam-kamera-fotasie na model gesprekke tussen polisieoffisiere en gemeenskap-lede in trafikstappe. Aangaande die teorie van institusielle praat, ontwikkel ons 'n etiket skema vir polisie spreek tydens trafikstappe, en 'n etiket om institusiele dialoog aktiwiteite (Redigerings, Soektog, Toestel Hulp) te ontdek van transkripte teks by die draai (78% F- telling) en stop (89% F- score) vlak. Ons ontwikkel dan spraak herkening en segmentasie algoritme om hierdie aktiwiteite by die stop vlak van rooi kamera oudio (81% F- score, met selfs hoër presisie vir kruipende aktiwiteite soos die rede vir die stop te verkry). Ons wys dat die dialoog strukture wat deur ons merker uitgevoer is, kan openbaar of offisiërs volg wetenforcement norme soos hulleself voorsien, die rede vir die stop verduidelik en die regte vir soektog vra. Hierdie werk kan dan versoek en help om die prosedureel regverdigheid van polisie-gemeenskap interaksies te verseker.</abstract_af>
      <abstract_sq>Ne aplikojmë metodat e dialogut kompjuterik për filmimet e kamerave të veshura nga trupi i policisë për të modeluar bisedimet midis oficerëve të policisë dhe anëtarëve të komunitetit në ndalesat e trafikut. Duke u mbështetur në teorinë e bisedimeve institucionale, ne zhvillojmë një skemë etiketash për bisedimet e policisë gjatë ndalimeve të trafikut dhe një etiketë për të zbuluar veprimet e dialogut institucional (arsye, kërkime, ofrim ndihmë) nga teksti i transkriptuar në nivelin e kthesës (78% F-score) dhe ndalim (89% F-score). Pastaj zhvillojmë algoritme njohjeje dhe segmentimi të fjalës për të zbuluar këto veprime në nivelin e ndalimit nga audio i kamerave të papërpunuara (81% F-score, me saktësi edhe më të lartë për veprime vendimtare si tregimi i arsyeve për ndalimin). Ne demonstrojmë se strukturat e dialogut të prodhuara nga shënuesi ynë mund të zbulojnë nëse oficerët ndjekin normat e zbatimit të ligjit si prezantimi i vetvetes, shpjegimi i arsyeve për ndalimin dhe kërkesa për leje për kërkime. Ky punë mund kështu të informojë dhe të ndihmojë përpjekjet për të siguruar drejtësinë procedurore të ndërveprimeve polici-komunitet.</abstract_sq>
      <abstract_am>የፖሊስ ባለሥልጣናት እና የፖሊስ ባለሥልጣናት እና የጦማሪያን አባላት በመንጋፍ ላይ የሚቆሙትን ንግግር እናደርጋለን፡፡ በተካሄደው አካባቢ ንግግር ታሪክ ላይ በተመለከተ ጊዜ የፖሊስ ንግግር እና የኢስቲካዊ ዝርዝሮች (ምክንያት፣ ፈልጎች፣ እርዳታ) በተጻፈው ጽሑፍ (78 በመቶ F-score) እና መቆም (89 በመቶ F-score)ን ለማግኘት የመዝገብ ዝርዝር እናደርጋለን፡፡ በኋላም የንግግር ማስታወቂያ እና የግንኙነት አቋርጦችን ማግኘት እናደርጋለን፡፡ በጦማሪያችን የተዘጋጀውን የጦማሪያን መክፈት፣ ባለሥልጣናት የሕግ ሥርዓቶችን እንደሚያሳዩ፣ የመቆም ምክንያት እንዲጠይቁ እና ለመፈለግ እንዲጠይቁ እናስታውቃለን፡፡ ስለዚህም ይህ ሥራ የፖሊስ-ማኅበረሰብ ግንኙነት የፍርድን እንዲያረጋግጥ ይችላል፡፡</abstract_am>
      <abstract_ko>우리는 경찰이 휴대하고 있는 카메라 렌즈에 대화 방법을 계산해 경찰과 교통정류장 지역사회 구성원 간의 대화를 모의할 것이다.기구 대화의 이론을 바탕으로 우리는 교통 정박 기간에 경찰이 말하는 표기 방안과 표기기를 개발하여 모퉁이(78% F-score)와 주차(89% F-score) 단계에서 기록 텍스트에서 기구의 대화 행위(원인, 검색, 도움말 제공)를 측정하는 데 사용한다.그리고 우리는 음성인식과 분할 알고리즘을 개발하여 원시 카메라의 오디오(81%의 F점수, 주차 원인 전달 등 관건적인 행위에 대해 더욱 높은 정확성을 가진다)에서 주차 등급의 이러한 행위를 측정했다.우리는 우리의 표기기가 생성한 대화 구조가 경찰이 법 집행 규범을 준수하는지, 예를 들어 자기소개, 정지 원인 설명, 수사 허가 청구 등을 밝힐 수 있음을 증명한다.따라서 이 작업은 경찰과 지역사회의 상호작용을 확보하는 절차에 공정한 정보와 도움을 제공할 수 있다.</abstract_ko>
      <abstract_hy>We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in traffic stops.  Հաշվի առնելով ինստիտուցիոնալ ելույթի տեսության վրա, մենք զարգանում ենք ոստիկանության ելույթի պիտակավորման ծրագիր ճանապարհորդության կանգման ժամանակ, և պիտակավորում, որպեսզի հայտնաբերենք ինստիտուցիոնալ հաղորդակցման գործողությունները (Պատճառներ, որոնումներ, օգնություն առաջարկելը) թարգմանված տեքստից Այնուհետև մենք զարգանում ենք խոսքի ճանաչման և սեգմետրացիայի ալգորիթմներ, որպեսզի հայտնաբերենք այս գործողությունները անմշակ տեսախցիկի ձայնային մակարդակի վրա (81 տոկոս F-գնահատականներ, որոնք նույնիսկ ավելի ճշգրիտ են կարևոր գործողությունների համար Մենք ցույց ենք տալիս, որ մեր նշանի կողմից ստեղծված երկխոսային կառուցվածքները կարող են բացահայտել, թե արդյոք պաշտոնյաները հետևում են օրենքի պաշտոնյան կանոններին, ինչպես օրինակ իրենց ներկայացումը, կանգ առնելու պատճառը բացատրել Այսպիսով, այս աշխատանքը կարող է տեղեկացնել և օգնել ջանքերին ոստիկանության և համայնքի շփումների գործընթացի արդարության ապահովելու համար:</abstract_hy>
      <abstract_az>Kompüterlik dialog metodlarını trafik durmaları arasında polis ofisləri və toplum üyeləri arasındakı görüşmələr üçün polis bəzək kamera fotoğraflarına uygulayırıq. İnstitüsal danışmanın teoriyasına bağlı olaraq, trafik duranları sırasında polis danışmanın etiketlənməsi üçün etiketlənməsi taslağı təşkil edirik, və institucional dialoğu işləri (Reasons, Searches, offer Help) tərəfindən yazılmış mətn tərəfindən (78% F-score) və (89% F-score) səviyyəsini təşkil edirik. Sonra bu əməlləri səviyyədə durma səviyyəsində keçmək üçün sözlərin tanıması və segmentasiya algoritmi təhsil edirik (81% F-score, bu səviyyədə duran səviyyəsindən daha yüksək dəqiqliyi ilə dəyişdiririk). Biz göstəririk ki, etiketçimizin yaratdığı диалог quruları özünü tanıdırmaq, duracağımız səbəbini açıq-aydınlaşdırmaq və arama izin istəmək kimi ofislərin qanunların istifadə etməyi təsdiqləyə bilər. Beləliklə, bu işin polis-toplum müxtəlif təşkilərin procedural ədalətini təsdiqləmək üçün xəbər verib yardım edə bilər.</abstract_az>
      <abstract_bs>Mi primjenjujemo računalne metode dijaloga na snimke kamere koje nose policijski tijelo na model razgovora između policijskih časnika i članova zajednice u saobraćajnim stanicama. S obzirom na teoriju institucionalnog razgovora, razvijamo šemu označavanja za policijski govor tijekom saobraćajnih stanica, i označavač za otkrivanje institucionalnih dijalogskih aktova (Reasons, Searches, Offering Help) iz transkrivenog teksta na okviru (78% F-score) i zaustavljamo nivo (89% F-score). Zatim razvijamo algoritme priznanja govora i segmentacije kako bi otkrili ove akcije na nivou stanja od zvuka sirovine kamere (81% F-rezultata, sa čak većom preciznošću za ključne akcije kao što su konverzacija razloga stanja). Pokazujemo da su strukture dijaloga proizvođene od strane našeg etiketera mogle otkriti da li službenici prate norme provedbe zakona poput predstavljanja sebe, objašnjavanja razloga stanja i traže dozvolu za potragu. Ovaj rad stoga može obavijestiti i pomoći naporima kako bi se osigurala proceduralna pravda interakcija policije i zajednice.</abstract_bs>
      <abstract_ca>Aplicam mètodes de diàleg computacional a les imatges de càmera portades per la policia per a modelar converses entre policials i membres de la comunitat en estacions de tràfic. Confiant en la teoria de la xerrada institucional, desenvolupem un esquema d'etiqueta de la xerrada policial durant les parades de tràfic, i un etiquetador per detectar actes de diàleg institucional (raons, cerca, oferir ajuda) de text transcrit a nivell de gir (78% puntuació F) i parar (89% puntuació F). Després desenvolupem algoritmes de reconeixement del discurs i segmentació per detectar aquests actes a nivell d'aturació de l'àudio de càmera bruta (puntuació F del 81%, amb una precisió encara més alta per actes crucials com la de comunicar la raó de l'aturació). Demonstrem que les estructures de diàleg produïdes pel nostre etiquetador podrien revelar si els oficials segueixen normes d'aplicació de la llei, com la seva pròpia presentació, explicant la raó de l'atur, i demanant permís per buscar. Aquesta feina pot, per tant, informar i ajudar els esforços per assegurar la justícia procedimental de les interaccions policia-comunitat.</abstract_ca>
      <abstract_bn>ট্রাফিক বন্ধে পুলিশ কর্মকর্তা এবং সম্প্রদায়ের সদস্যদের মধ্যে আলোচনার মডেল করার জন্য পুলিশের শরীর পরিশোধিত ক্যামেরা ফুটেজের প্রতিষ্ঠানিক কথোপকথনের তত্ত্ব নিয়ে আমরা ট্রাফিক থামানোর সময় পুলিশ ভাষণের জন্য একটি লেবেলিং পরিকল্পনা তৈরি করি এবং প্রতিষ্ঠানিক ডায়ালগের আচরণ (কারণ, অনুসন্ধান, সাহায্য প্রদান করার জন্য ট্ তারপর আমরা ভাষণের স্বীকৃতি এবং বৈশিষ্ট্যের অ্যালগরিদম তৈরি করি যাতে এই ক্যামেরা অডিও থেকে দেখা যায় (১৮% এফ স্কোর, এমনকি এই থামানোর কারণে গুরুত্বপূর আমরা দেখাচ্ছি যে আমাদের ট্যাগারের দ্বারা নির্মাণ করা ডায়ালগ কাঠামো প্রকাশ করতে পারে যে কর্মকর্তারা নিজেদের নিজেদের পরিচালনা করার মত আইন প্রয় তাই এই কাজ পুলিশ-সম্প্রদায়ের আন্তর্জাতিক বিচার নিশ্চিত করার প্রচেষ্টা সম্পর্কে জানিয়ে দিতে পারে এবং</abstract_bn>
      <abstract_et>Me rakendame arvutuslikke dialoogimeetodeid politseikehaga kantud kaameramaterjalile, et modelleerida vestlusi politseiametnike ja kogukonna liikmete vahel liikluspeatustes. Institutsionaalse vestluse teooriale tuginedes töötame välja politseikõne märgistusskeemi liikluspeatuste ajal ning sildistaja, mis tuvastab institutsionaalse dialoogi toiminguid (põhjused, otsingud, abi pakkumine) transkribeeritud tekstist pöörde (78% F-skoor) ja peatuse (89% F-skoor) tasemel. Seejärel töötame välja kõnetuvastuse ja segmenteerimise algoritmid, et tuvastada need toimingud peatustasemel kaamera helist (81% F-skoor, veelgi suurem täpsus oluliste toimingute puhul, näiteks peatuse põhjuse edastamine). Näitame, et meie sildistaja loodud dialoogistruktuurid võivad näidata, kas ametnikud järgivad õiguskaitsenorme, näiteks tutvustavad ennast, selgitavad peatuse põhjust ja küsivad loa läbiotsimiseks. See töö võib seega teavitada ja aidata kaasa jõupingutustele, et tagada politsei ja kogukonna vahelise suhtluse menetlusõigus.</abstract_et>
      <abstract_fi>Sovellamme laskennallisia dialogimenetelmiä poliisin kehossa käytettävään kamerakuvaan mallintamaan poliisin ja yhteisön jäsenten välisiä keskusteluja liikennepysähdyksissä. Institutionaalisen keskustelun teoriaan nojautuen kehitämme merkintäjärjestelmän poliisin puheelle liikennepysähdysten aikana sekä taggerin, joka havaitsee institutionaalisen dialogin teot (syyt, etsinnät, avun tarjoaminen) käännöksen tekstistä (78% F-score) ja pysähdystason (89% F-score). Kehitämme sitten puheentunnistus- ja segmentointialgoritmeja havaitsemaan nämä teot pysäytystasolla kameran raa'asta äänestä (81% F-pisteet, jopa suuremmalla tarkkuudella tärkeisiin tekoihin, kuten pysähdyksen syyn välittämiseen). Osoitamme, että taggerimme luomat dialogirakenteet voivat paljastaa, noudattavatko poliisit lainvalvonnan normeja, kuten esittäytyvät, selittävät pysähdyksen syyn ja pyytävät lupaa etsintöihin. Tällä työllä voidaan näin ollen tiedottaa ja tukea toimia, joilla varmistetaan poliisin ja yhteisön välisen vuorovaikutuksen prosessioikeus.</abstract_fi>
      <abstract_cs>Používáme výpočetní dialogové metody na záběry z kamery nošené policií k modelování konverzací mezi policisty a členy komunity na dopravních zastávkách. Na základě teorie institucionálního mluvení vyvíjíme schéma označování policejního řeči při zastávkách dopravy a tagger pro detekci institucionálních dialogových aktů (důvody, hledání, nabídka pomoci) z přepisovaného textu na úrovni zatáčky (78% F-skóre) a stop (89% F-skóre). Následně vyvíjíme algoritmy rozpoznávání řeči a segmentace pro detekci těchto činů na úrovni stop z surového zvuku kamery (81% F-skóre, s ještě vyšší přesností pro klíčové činy, jako je sdělení důvodu zastavení). Ukazujeme, že dialogové struktury vytvořené naším tagerem by mohly odhalit, zda policisté dodržují normy vymáhání práva, jako je představení, vysvětlení důvodu zastavení a požádání o povolení k prohledávání. Tato práce proto může informovat a pomoci úsilí o zajištění procesní spravedlnosti interakcí policie a komunity.</abstract_cs>
      <abstract_fa>ما روش گفتگوی کامپیوتری را برای فیلم دوربین پوشیده از بدن پلیس برای مدل گفتگوی بین افسران پلیس و اعضای جامعه در ایستگاه های ترافیک استفاده می کنیم. بر اساس تئوری صحبت موسساتی، ما یک برنامه برنامه ریزی برای سخنرانی پلیس در طول پایگاه‌های ترافیک توسعه می‌کنیم، و یک برنامه ریزی برای شناسایی فعالیت‌های گفتگوی موسساتی (دلیل‌ها، جستجوها، پیشنهاد کمک) از متن ترجمه‌شده در طول (78% F-score) و متوقف (89% F-score). سپس ما الگوریتم‌های شناسایی سخنرانی و جدایی را توسعه می‌کنیم تا این عمل را در سطح متوقف از صدای دوربین خالی (81 درصد F-score، با حتی دقیق بالاتر برای عمل های مهم مثل رسیدن دلیل متوقف) شناسایی کنیم. ما نشان می دهیم که ساختارهای محاورۀ محاورۀ توسط تاجر ما می‌توانند نشان دهند که آیا افسران از قوانین عملکرد قانونی مانند خودشان را معرفی کنند، دلیل وابسته‌ها را توضیح می‌دهند و اجازه برای جستجوها را می‌خواهند. بنابراین این کار ممکن است به تلاش و کمک‌ها اطلاع دهد تا به عدالت پردازی اجتماعی پلیس و اجتماعی اطلاع دهد.</abstract_fa>
      <abstract_jv>Awak dhéwé ngerasakno karo perangkat dolanan sampeyan kanggo nganggo dolanan karo dolanan nggawe dolanan kaya vector nggawe dolanan poliki karo perusahaan dumadhil Nyong nggawe theori sing sampeyan institusi, awake dhéwé nggawe etiket barêng langgar nggawe stampen kanggo kalah bantayan negoro nggawe, lan tagger kanggo nambah dialog-aké institusi (Reyes, Search, offer Help) sing berarti teks terus berlanjut cara nggawe sekondi (75% F-item) lan wis dumadhi (64% F-item). Awakdhéwé éntuk dhéwé éntukno karo perusahaan karo segurasi Algorithm sing ditambah nggawe barang iki dadi sabanjuré katong dolanan surat (basa gambar 1% F), dadi wis nggawe barang langgar sabanjuré sakjane nggawe gerakan sakjane Kemerdekaan. Awak dhéwé éntukno ngono nggawe dialog-kanggo tukang ning acara dhéwé iso mbukakipon sapa poliki sing beraksi perbudhakan winih kanggo ngubah dhéwé, dipanyusikno perusahaan kanggo mbatalé dhéwé, lan ujolan perusahaan kanggo nyambukakipun Awak iki ngono nggawe informasi lan susahe kanggo ngerasakno adalah perusahaan kanggo ngilangno sak komunitas.</abstract_jv>
      <abstract_ha>Tuna amfani da shiryoyin zauren akwatin bayani na lissafa zuwa fomat wanda aka huwa a cikin shirin kamera dõmin ka motsa magana a tsakanin maafisci na Police da jamii sunã cikin hanyoyin matafiya. Amma da jiyyan mazaɓa na aikin ayuka da aka shigar, muna developer wani muhalli wa hoto na Police a lokacin da za'a yi matafiya, da wata tagger dõmin ya gane abun zauren akwatin bayani na masu shida (Sababu, Searches, Ana Aiki) daga matsayin da aka rubũta (score 78% F-score) da za'a tsaye (score 89% F-score). Sa'an nan kuma Muke buɗe zaɓen bayani na magana da algoritori don mu gane waɗannan aiki a cikin daraja da aka goge daga saurin raw kamera (81% F-score, da kuma mafi tsari ga aikin muhimmi kamar da za'a iya haɗa saba wa dawwama). Tuna nũna zauren akwatin zauren akwatin bayani wanda aka samar da tagger daga gare mu, za'a iya bayyana, ma'abũta maafisa sunã bi'anar law enforce kamar da za'a introduce kansu, sunã bayyana saban ya tsaya, kuma suna tambayi ruwan nẽman searches. Wannan aikin yana iya gaya wa aikin da zai taimake aikin da za'a sikre gareshi da ãdalci na mutane.</abstract_ha>
      <abstract_sk>Uporabljamo metode računalniškega dialoga za posnetke kamer, ki jih nosi policija, za modeliranje pogovorov med policisti in člani skupnosti na prometnih postajah. Na podlagi teorije institucionalnega pogovora razvijamo shemo označevanja policijskega govora med postankami prometa in označevalnik za odkrivanje institucionalnih dialogskih aktov (Razlogi, Iskanje, Ponujanje pomoči) iz prepisanega besedila na zavoju (78% F-score) in stop (89% F-score). Nato razvijamo algoritme za prepoznavanje govora in segmentacijo, s katerimi zaznavamo ta dejanja na stopnji ustavitve iz surovega zvoka kamere (81% F-score, še večja natančnost za ključna dejanja, kot je sporočanje razloga za ustavitev). Pokazujemo, da lahko dialogne strukture, ki jih izdeluje naš označevalec, razkrijejo, ali policisti sledijo pravilom organov pregona, kot so predstavitev, pojasnitev razloga za ustavitev in vprašanje za dovoljenje za iskanje. To delo lahko zato obvešča in pomaga pri zagotavljanju procesne pravičnosti medsebojnega delovanja policije in skupnosti.</abstract_sk>
      <abstract_he>אנו משתמשים בשיטות דיאלוג מחשבי על צילומי מצלמות שנלבשו ע"י גוף המשטרה לשיחות דוגמניות בין שוטרים ואנשי הקהילה בתחנות תנועה. בהתבסס על התיאוריה של שיחות מוסדיות, אנחנו מפתחים תכנית תיקון לנאום המשטרה במהלך עצרות תנועה, ותגיג כדי לגלות פעולות דיאלוג מוסדיים (סיבות, חיפושים, הצעה עזרה) מהטקסט משותף ברמה (78% נקודת F) ולעצור (89% נקודת F). ואז אנחנו מפתחים אלגוריתמים זיהוי הנאום והסגרציה כדי לזהות את הפעולות האלה ברמה המעצרת מקלטת אודיו (81% נקודת F, עם מדויקה אפילו גבוהה עבור פעולות קריטיות כמו להעביר את הסיבה לעצור). אנחנו מראים שהמבנים הדיולוגים שנוצרים על ידי המתג שלנו יכולים לחשוף אם השוטרים עוקבים אחרי נורמות אכיפת החוק כמו להציג את עצמם, להסביר את הסיבה לעצירה, ולבקש רשות לחיפוש. העבודה הזאת יכולה לכן להודיע ומאמצי עזרה כדי להבטיח את הצדק הנהלי של אינטראקציות משטרה-קהילה.</abstract_he>
      <abstract_bo>ང་ཚོས་རྩིས་འཁོར་གྱི་གློག་རྩིས་འཁོར་གྱི་ཌའི་ལོག Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78% F-score) and stop (89% F-score) level. འུ་ཚོས་གཞི་བཙུགས་ཀྱི་སྒྲ་བརྙན་རྟོགས་དང་ཆ་རྐྱེན་གྲངས་སྒྲིག་གི་ཆ་རྐྱེན་དེ་དག་དྲན་མཐུན་དགོས་པ་ལས་(81% F-score)ནང་དུ་ཡོད། ང་ཚོས་ཤོག་བྱང་པ་ཞིག་གིས་གསར་བསྐྲུན་པའི་ཌའི་ལོག་ལས་བཟོ་བརྒྱུད དེར་བརྟེན། ལས་འགན་འདིས་སྔོན་སྒྲིག་གི་ཉེན་ཁ་འབྲེལ་བ་དང་མཐུན་འགྱུར་བ་གྱི་ལས་འགུལ་གྱི་ཉེན་ཁ་ཇུས་ཡོ</abstract_bo>
      </paper>
    <paper id="36">
      <title>Neural Lattice Language Models</title>
      <author><first>Jacob</first><last>Buckman</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <doi>10.1162/tacl_a_00036</doi>
      <abstract>In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities : neural lattice language models. These models construct a lattice of possible paths through a sentence and marginalize across this <a href="https://en.wikipedia.org/wiki/Lattice_(group)">lattice</a> to calculate sequence probabilities or optimize parameters. This approach allows us to seamlessly incorporate linguistic intuitions   including <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a> and the existence of multiword lexical items   into our <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> by 9.95 % relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> by 20.94 % relative to a character-level baseline.</abstract>
      <pages>529–541</pages>
      <url hash="0d2c3822">Q18-1036</url>
      <bibkey>buckman-neubig-2018-neural</bibkey>
      <pwccode url="https://github.com/jbuckman/neural-lattice-language-models" additional="false">jbuckman/neural-lattice-language-models</pwccode>
    <title_ar>نماذج اللغة العصبية الشبكية</title_ar>
      <title_es>Modelos de lenguaje de redes neuronales</title_es>
      <title_fr>Modèles de langage de réseau neuronal</title_fr>
      <title_pt>Modelos de linguagem de rede neural</title_pt>
      <title_ja>神経格子言語モデル</title_ja>
      <title_zh>神经晶格语言模样</title_zh>
      <title_ru>Языковые модели нейронной решетки</title_ru>
      <title_hi>तंत्रिका जाली भाषा मॉडल</title_hi>
      <title_ga>Samhlacha Néaracha Teanga Laitíse</title_ga>
      <title_ka>ნეიროლური ლატტიკის ენის მოდელები</title_ka>
      <title_hu>Neurális hálózati nyelvmodellek</title_hu>
      <title_el>Μοντέλα γλώσσας Νευρικού πλέγματος</title_el>
      <title_lt>Neuralinės raidės kalbos modeliai</title_lt>
      <title_it>Modelli linguistici del reticolo neurale</title_it>
      <title_kk>Неврал латтикалық тіл үлгілері</title_kk>
      <title_ms>Neural Lattice Language Models</title_ms>
      <title_mk>Neural Lattice Language Models</title_mk>
      <title_ml>നെയുറല്‍ ലാറ്റിക്സ് ഭാഷ മോഡലുകള്‍</title_ml>
      <title_mn>Цөмийн латтикийн хэл загварууд</title_mn>
      <title_no>Neurallatiske språk- modeller</title_no>
      <title_pl>Modele językowe siatek neuronowych</title_pl>
      <title_mt>Mudelli tal-Lingwa Lattika Newrali</title_mt>
      <title_ro>Modele lingvistice ale rețelelor neurale</title_ro>
      <title_sr>Neuralni jezik</title_sr>
      <title_sv>Språkmodeller för neurala gitter</title_sv>
      <title_si>න්‍යූරල් ලැටික් භාෂාව මඩේල්ස්</title_si>
      <title_so>Modelooyinka luqada ee asalka</title_so>
      <title_ta>மொழி மாதிரி வகைகள்</title_ta>
      <title_ur>نیورال لاٹیک زبان موڈل</title_ur>
      <title_uz>Language modellari</title_uz>
      <title_vi>Chế độ ngôn ngữ thần kinh</title_vi>
      <title_bg>Модели на езика на нервната решетка</title_bg>
      <title_nl>Taalmodellen voor neurale roosters</title_nl>
      <title_da>Neural gittersprogsmodeller</title_da>
      <title_hr>Neuralni jezički modeli</title_hr>
      <title_de>Sprachmodelle für neuronale Gitter</title_de>
      <title_sw>Modeli za Lugha za Kiasili</title_sw>
      <title_fa>مدل زبان عصبی</title_fa>
      <title_id>Model Bahasa Lattice Neural</title_id>
      <title_ko>신경격 언어 모형</title_ko>
      <title_am>ቋንቋ</title_am>
      <title_sq>Modelet e gjuhës</title_sq>
      <title_tr>Hatlar</title_tr>
      <title_hy>Նյարդային լատիկայի լեզվի մոդելներ</title_hy>
      <title_bn>Neural Lattice Language Models</title_bn>
      <title_ca>Models neurolàtics de llenguatge</title_ca>
      <title_af>Name</title_af>
      <title_cs>Jazykové modely neuronální mřížky</title_cs>
      <title_et>Närvivõre keele mudelid</title_et>
      <title_fi>Neurolirkon kielimallit</title_fi>
      <title_az>N칬ral Lattik Dili Modell톛ri</title_az>
      <title_bs>Neuralni jezički modeli</title_bs>
      <title_jv>structural navigation</title_jv>
      <title_sk>Modeli jezikovnega jezika živčnih mrež</title_sk>
      <title_he>דוגמני שפת העצבים</title_he>
      <title_ha>@ action</title_ha>
      <title_bo>སྣང་བྲལ་ཤིག་གི་སྐད་རིགས་མ་དབྱིབས</title_bo>
      <abstract_ar>في هذا العمل ، نقترح نموذجًا جديدًا لنمذجة اللغة لديه القدرة على تنفيذ كل من التنبؤ والاعتدال في تدفق المعلومات عند مستويات متعددة: نماذج اللغة العصبية الشبكية. تنشئ هذه النماذج شبكة من المسارات المحتملة من خلال جملة وتهمش عبر هذه الشبكة لحساب احتمالات التسلسل أو تحسين المعلمات. يتيح لنا هذا النهج دمج الحدس اللغوي بسلاسة - بما في ذلك تعدد المعاني ووجود عناصر معجمية متعددة الكلمات - في نموذج لغتنا. تُظهر التجارب على مهام النمذجة بلغات متعددة أن نماذج اللغة الإنجليزية الشبكية العصبية التي تستخدم الزخارف متعددة المعاني قادرة على تحسين الارتباك بنسبة 9.95٪ مقارنة بخط الأساس على مستوى الكلمة ، وأن النموذج الصيني الذي يتعامل مع الرموز متعددة الأحرف قادر على تحسين الارتباك من خلال 20.94٪ نسبة إلى خط الأساس على مستوى الشخصية.</abstract_ar>
      <abstract_pt>Neste trabalho, propomos um novo paradigma de modelagem de linguagem que tem a capacidade de realizar tanto a previsão quanto a moderação do fluxo de informação em múltiplas granularidades: modelos de linguagem de rede neural. Esses modelos constroem uma rede de caminhos possíveis através de uma frase e marginalizam essa rede para calcular probabilidades de sequência ou otimizar parâmetros. Essa abordagem nos permite incorporar perfeitamente intuições linguísticas – incluindo polissemia e a existência de itens lexicais multipalavras – em nosso modelo de linguagem. Experimentos em tarefas de modelagem de vários idiomas mostram que os modelos de linguagem de rede neural em inglês que utilizam incorporações polissêmicas são capazes de melhorar a perplexidade em 9,95% em relação a uma linha de base de nível de palavra, e que um modelo chinês que lida com tokens de vários caracteres é capaz de melhorar a perplexidade por 20,94% em relação a uma linha de base de nível de personagem.</abstract_pt>
      <abstract_fr>Dans ce travail, nous proposons un nouveau paradigme de modélisation du langage qui a la capacité d'effectuer à la fois la prédiction et la modération du flux d'informations à de multiples granularités : les modèles de langage de réseau neuronal. Ces modèles construisent un réseau de chemins possibles à travers une phrase et marginalisent ce réseau pour calculer les probabilités de séquence ou optimiser les paramètres. Cette approche nous permet d'intégrer de manière transparente des intuitions linguistiques, y compris la polysémie et l'existence d'éléments lexicaux à plusieurs mots, dans notre modèle linguistique. Des expériences sur des tâches de modélisation de plusieurs langues montrent que les modèles de langage de réseau neuronal anglais qui utilisent des intégrations polysémiques sont capables d'améliorer la perplexité de 9,95 % par rapport à une base au niveau du mot, et qu'un modèle chinois qui gère des jetons à caractères multiples peut améliorer la perplexité de 20,94 % par rapport à une ligne de base au niveau du personnage.</abstract_fr>
      <abstract_es>En este trabajo, proponemos un nuevo paradigma de modelado del lenguaje que tiene la capacidad de realizar tanto la predicción como la moderación del flujo de información en múltiples granularidades: modelos de lenguaje de red neuronal. Estos modelos construyen un entramado de posibles caminos a través de una oración y se marginan a lo largo de este entramado para calcular las probabilidades de secuencia u optimizar los parámetros. Este enfoque nos permite incorporar a la perfección intuiciones lingüísticas, incluida la polisemia y la existencia de elementos léxicos de varias palabras, en nuestro modelo de lenguaje. Los experimentos en tareas de modelado de múltiples idiomas muestran que los modelos lingüísticos de red neuronal inglesa que utilizan incrustaciones polisémicas pueden mejorar la perplejidad en un 9,95% en relación con una línea de base a nivel de palabra, y que un modelo chino que maneja tokens de múltiples caracteres puede mejorar la perplejidad en un 20,94% en relación con una línea base a nivel de personaje.</abstract_es>
      <abstract_zh>新语建模范,多粒度行信息流调,神经格语模样。 凡此诸格,或通句径之格,并于此格中边缘化,以次概率优化参数。 使吾能直言直觉(多义词、多词词汇目之存)无间整合入吾言。 多言建模事之实验,以多义嵌之英语神经格对单词级基线能以困惑增9.95%,而处多字符标之文以对字符级基线将困惑以重20.94%。</abstract_zh>
      <abstract_ja>この研究では、複数の粒度での情報フローの予測とモデレーションの両方を実行する能力を持つ新しい言語モデリングパラダイム、ニューラル格子言語モデルを提案します。これらのモデルは、文を通る可能性のある経路の格子を構築し、この格子全体で周縁化して、シーケンス確率を計算するか、パラメータを最適化します。このアプローチにより、多義性と複数語の語彙項目の存在を含む言語学的直感を言語モデルにシームレスに組み込むことができます。複数の言語モデリングタスクの実験では、多義的埋め込みを利用する英語のニューラル格子言語モデルは、単語レベルのベースラインと比較して9.95 ％の混乱を改善することができ、多文字トークンを扱う中国のモデルは、文字レベルのベースラインと比較して20.94 ％の混乱を改善することができることが示されている。</abstract_ja>
      <abstract_ru>В этой работе мы предлагаем новую парадигму языкового моделирования, которая обладает способностью выполнять как предсказание, так и модерацию информационного потока при множественных деталях: нейронные решетчатые языковые модели. Эти модели строят решетку возможных путей через предложение и маргинализируют через эту решетку для вычисления вероятностей последовательности или оптимизации параметров. Такой подход позволяет нам плавно интегрировать лингвистические интуиции — в том числе полисемию и существование многословных лексических элементов — в нашу языковую модель. Эксперименты над задачами моделирования нескольких языков показывают, что модели английского языка нейронных решеток, использующие многочленные вложения, способны улучшить недоумение на 9,95% по сравнению с базовой линией на уровне слов, и что китайская модель, которая обрабатывает многосимвольные токены, способна улучшить недоумение на 20,94% по сравнению с базовой линией на уровне символов.</abstract_ru>
      <abstract_hi>इस काम में, हम एक नए भाषा मॉडलिंग प्रतिमान का प्रस्ताव करते हैं जिसमें कई ग्रैन्युलैरिटीज़ पर सूचना प्रवाह की भविष्यवाणी और मॉडरेशन दोनों करने की क्षमता है: तंत्रिका जाली भाषा मॉडल। ये मॉडल एक वाक्य के माध्यम से संभावित पथों की एक जाली का निर्माण करते हैं और अनुक्रम संभावनाओं की गणना करने या मापदंडों को अनुकूलित करने के लिए इस जाली में हाशिए पर हैं। यह दृष्टिकोण हमें मूल रूप से भाषाई अंतर्ज्ञान को शामिल करने की अनुमति देता है - जिसमें पॉलीसेमी और मल्टीवर्ड लेक्सिकल आइटम का अस्तित्व शामिल है - हमारे भाषा मॉडल में। एकाधिक भाषा मॉडलिंग कार्यों पर प्रयोगों से पता चलता है कि अंग्रेजी तंत्रिका जाली भाषा मॉडल जो पॉलीसेमस एम्बेडिंग का उपयोग करते हैं, एक शब्द-स्तरीय आधार रेखा के सापेक्ष 9.95% तक उलझन में सुधार करने में सक्षम हैं, और यह कि एक चीनी मॉडल जो बहु-चरित्र टोकन को संभालता है, चरित्र-स्तर की आधार रेखा के सापेक्ष 20.94% तक उलझन में सुधार करने में सक्षम है।</abstract_hi>
      <abstract_ga>Sa saothar seo, molaimid paradigm samhaltaithe teanga nua a bhfuil an cumas ann sreabhadh faisnéise a thuar agus a mhodhnú ag iolrachtaí iolracha: múnlaí teanga laitíse néaracha. Tógann na samhlacha seo laitíse de bhealaí féideartha trí phianbhreith agus cuireann siad imeallú trasna na laitíse seo chun dóchúlachtaí seicheamhacha a ríomh nó paraiméadair a bharrfheabhsú. Ligeann an cur chuige seo dúinn intuitions teanga a ionchorprú gan uaim – lena n-áirítear polysemy agus míreanna foclóireachta ilfhocail – inár múnla teanga. Léiríonn turgnaimh ar thascanna samhaltaithe teanga iolracha go bhfuil samhlacha néaracha teanga laitíse Béarla a úsáideann leabaithe ilghnéitheacha in ann an perplexity a fheabhsú 9.95% i gcoibhneas le bonnlíne leibhéal focal, agus go bhfuil samhail Síneach a láimhseálann comharthaí ilcharachtar in ann perplexity a fheabhsú trí. 20.94% i gcoibhneas le bonnlíne leibhéal carachtair.</abstract_ga>
      <abstract_ka>ამ სამუშაოში ჩვენ ახალი ენის მოდელინო პარადიგმის შესაძლებლობა, რომელიც ინფორმაციის გამოწვება და მოდელირება მრავალ გრანულაციაში: ნეიროლური ლატისური ენის მოდელი. ეს მოდელები შესაძლებელი გზების ლატიკის შექმნა და ამ ლატიკის გარეშე მართნალიზება, რომ წერტილების შესაძლებლობა ან ოპრამეტრების ოქტიმიზება გამოყენებთ. ეს პროგრამა გვაქვს, რომ ჩვენ სიტყვების მოდელში სიტყვების ინტეუციების გარეშე მრავალური ლექსიკალური ელექტიკალური ელექტიკალური ელექტიკალური ელექტიკალური მოდელ მრავალ ენის მოდელების გამოცდილებების გამოცდილება ჩვენებს, რომ ინგლისური ნეიროლ ლატისური ენის მოდელები, რომლებიც პოლისემის გამოყენებას გამოყენებს, შეუძლიათ 9,95% უფრო მეტი სიტყვების ფესური ხაზის შესახებ, და რომ ჩინეთის მოდელი, რომელიც მრავალ</abstract_ka>
      <abstract_el>Στην παρούσα εργασία, προτείνουμε ένα νέο πρότυπο γλωσσικής μοντελοποίησης που έχει την ικανότητα να εκτελεί τόσο την πρόβλεψη όσο και τον μετριασμό της ροής πληροφοριών σε πολλαπλές κοκκοποιότητες: μοντέλα γλωσσών νευρωνικών δικτύων. Αυτά τα μοντέλα κατασκευάζουν ένα πλέγμα από πιθανές διαδρομές μέσα από μια πρόταση και περιθωριοποιούν σε αυτό το πλέγμα για να υπολογίσουν τις πιθανότητες ακολουθίας ή να βελτιστοποιήσουν τις παραμέτρους. Αυτή η προσέγγιση μας επιτρέπει να ενσωματώσουμε απρόσκοπτα γλωσσικές διαισθήσεις, συμπεριλαμβανομένης της πολυσεμίας και της ύπαρξης πολυλέξεων λεξικών στοιχείων στο γλωσσικό μας μοντέλο. Τα πειράματα σε εργασίες μοντελοποίησης πολλαπλών γλωσσών δείχνουν ότι τα αγγλικά μοντέλα γλωσσών νευρωνικού πλέγματος που χρησιμοποιούν πολυσυναισθηματικές ενσωματώσεις είναι σε θέση να βελτιώσουν την σύγχυση κατά 9,95% σε σχέση με μια γραμμή βάσης επιπέδου λέξεων και ότι ένα κινεζικό μοντέλο που χειρίζεται μάρκες πολλαπλών χαρακτήρων είναι σε θέση να βελτιώσει την σύγχυση κατά 20,94% σε σχέση με μια γραμμή βάσης επιπέδου χαρακτήρων.</abstract_el>
      <abstract_hu>Ebben a munkában egy új nyelvmodellezési paradigmát javasolunk, amely képes az információáramlás előrejelzésére és moderálására egyaránt többféle granularitásban: neurális rácsos nyelvmodellek. Ezek a modellek a lehetséges útvonalak rácsát építik fel egy mondaton keresztül, és ezen a rácson keresztül marginálják a szekvencia valószínűségeinek kiszámításához vagy a paraméterek optimalizálásához. Ez a megközelítés lehetővé teszi számunkra, hogy zökkenőmentesen beépítsük a nyelvi intuíciókat - beleértve a poliszemiát és a többszós lexikai elemek létezését - a nyelvi modellünkbe. Többnyelvű modellezési feladatokkal végzett kísérletek azt mutatják, hogy a poliszmemous beágyazásokat használó angol neurális hálózati nyelvű modellek 9,95%-kal képesek javítani a zavartságot egy szószintű alaphoz képest, és hogy egy többkarakteres tokeneket kezelő kínai modell képes 20,94%-kal javítani a zavartságot egy karakterszintű alaphoz képest.</abstract_hu>
      <abstract_it>In questo lavoro, proponiamo un nuovo paradigma di modellazione linguistica che ha la capacità di eseguire sia la previsione che la moderazione del flusso di informazioni a granularità multiple: modelli di linguaggio reticolare neurale. Questi modelli costruiscono un reticolo di possibili percorsi attraverso una frase e marginalizzano attraverso questo reticolo per calcolare probabilità di sequenza o ottimizzare i parametri. Questo approccio ci permette di integrare senza soluzione di continuità intuizioni linguistiche - compresa la polisemia e l'esistenza di elementi lessicali multiword - nel nostro modello linguistico. Esperimenti su attività di modellazione di più lingue mostrano che i modelli di linguaggio del reticolo neurale inglese che utilizzano incorporazioni polisemose sono in grado di migliorare la perplessità del 9,95% rispetto a una linea di base a livello di parola, e che un modello cinese che gestisce token multi-carattere è in grado di migliorare la perplessità del 20,94% rispetto a una linea di base a livello di carattere.</abstract_it>
      <abstract_lt>Šiame darbe siūlome naują kalbų modeliavimo paradigm ą, kuris gali atlikti tiek informacijos srautų prognozavimą, tiek vidutinimą daugeliu granuliarumų: nervinių lazdinių kalbų modelius. Šie modeliai sukuria galimų kelių plokštelę per sakinį ir marginalizuoja visą šią plokštelę, kad būtų apskaičiuotos sekos tikimybės arba optimizuojami parametrai. Šis požiūris suteikia mums galimybę į mūsų kalbos model į nuosekliai įtraukti kalbines intuicijas, įskaitant polisemiją ir daugiakalbių leksinių straipsnių egzistavimą. Įvairių kalbų modeliavimo užduočių eksperimentai rodo, kad anglų neuralinių lazdinių kalbų modeliai, kuriuose naudojami polizieminiai įterpimai, gali padidinti perpleksiją 9,95 proc., palyginti su žodžių lygio pradiniu lygiu, ir kad Kinijos model is, kuris tvarko daugiašalius ženklus, gali padidinti perpleksiją 20,94 proc., palyginti su simbolių lygio pradiniu lygiu.</abstract_lt>
      <abstract_kk>Бұл жұмыс ішінде біз жаңа тіл моделинген парадигмін ұсынамыз. Бірнеше грануляриялық мәліметтердің алдын- ала алдын- ала алдын- ала мәліметтерді алдын- ала алу мүмкіндігін жұмыс і Бұл үлгілер мәліметтерді есептеу немесе параметрлерді оптимизациялау үшін мәлімет жолдардың латицесін құрып, латице арасында шектеу үшін құрылады. Бұл жағдай бізге тіл үлгісімізге лингвистикалық интуицияларды, полизиясы және көп сөздің лексикалық нысандары бар болуы мүмкіндік береді. Бірнеше тілді моделдеу тапсырмаларындағы тәжірибелер ағылшын невраллық латис тіл үлгілерін көрсетеді, олар полиземді ендіру үлгілерін қолдану үлгілері сөз деңгейінің негізгі сызығына сәйкес 9,95% деңгейінде жұмыс істеуге болады, және көп таңбаларды белгілейт</abstract_kk>
      <abstract_ml>ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ പുതിയ ഭാഷ മോഡല്‍ മാതൃകയില്‍ പ്രാദോധിപ്പിക്കുന്നു. വിവരങ്ങളുടെ പ്രവചനവും പ്രവചനങ്ങളുടെ മാതൃകയും പ്രവചിപ്പി ഈ മോഡലുകള്‍ സാധ്യതയുള്ള വഴികളുടെ ലാറ്റിസ് നിര്‍മ്മിക്കുകയും ഈ ലാറ്റിക്സിന്‍റെ മുകളിലൂടെ മാറ്റിയിടുകയും ചെയ്യുന്നു. സെക്കന്‍സ് സ ഈ സമീപത്തില്‍ നമ്മള്‍ക്ക് സീലിസ്റ്റിക്ക് ഭാഷകങ്ങളില്‍ ഉള്‍പ്പെടുത്താന്‍ അനുവദിക്കുന്നു. പോളിസിയും പല്ലിവാര്‍ഡ് ലെക്സിക്കല പല ഭാഷകളുടെ മോഡലിങ്ങ് ജോലികളില്‍ പരീക്ഷണങ്ങള്‍ കാണിക്കുന്നു ഇംഗ്ലീഷ് ന്യൂറല്‍ ലാറ്റിക്സ് ഭാഷ മോഡലുകള്‍ ഉപയോഗിക്കുന്നത് ഒരു വാക്ക്- ലേയര്‍ ബെസ്ലൈനിലേക്ക് ബന്ധപ്പെട്ടിരിക്കുന്ന 9.95% കൂടിയാണ</abstract_ml>
      <abstract_mt>F’dan ix-xogħol, qed nipproponu paradigm a ġdida ta’ mudell tal-lingwi li għandha l-kapaċità li twettaq kemm it-tbassir kif ukoll il-moderazzjoni tal-fluss tal-informazzjoni f’granularitajiet multipli: mudelli tal-lingwa tal-lattika newrali. Dawn il-mudelli jibnu lattiċi ta’ mogħdijiet possibbli permezz ta’ sentenza u jimmarġinalizzaw madwar din il-lattiċi biex jikkalkulaw il-probabilitajiet tas-sekwenza jew jottimizzaw il-parametri. Dan l-approċċ jippermettilna li inkorporaw intwazzjonijiet lingwistiċi mingħajr xkiel - inkluża l-polisemija u l-eżistenza ta’ oġġetti lexiċi multikliem - fil-mudell lingwistiku tagħna. Esperimenti fuq kompiti ta’ mudellar ta’ diversi lingwi juru li mudelli lingwistiċi tal-lattika newrali Ingliża li jużaw inkorporazzjonijiet poliżimali jistgħu jtejbu l-perplessità b’9.95% meta mqabbla ma’ linja bażi tal-livell tal-kliem, u li mudell Ċiniż li jimmaniġġja tokens b’ħafna karattri jista’ jtejjeb il-perplessità b’20.94% meta mqabbel ma’ linja bażi tal-livell tal-karattri.</abstract_mt>
      <abstract_mn>Энэ ажлын хувьд бид олон гранулацийн мэдээллийн урсгалыг таамаглах боломжтой шинэ хэл загварчлах парадигм гэж санал болно. Эдгээр загварууд өгүүлбэрээр боломжтой замыг бүтээж, дарааллын магадлал эсвэл параметрыг тооцоолох боломжтой байдлыг тооцоолох боломжтой болно. Энэ арга нь бидэнд хэлний загвар руу хэлний үзэл бодлогыг бүрдүүлэх боломжтой болгодог. Ихэнх хэл загварын даалгаварын туршилтын туршилт нь хэлбэрийн мэдрэлийн латис хэл загваруудыг хэрэглэдэг англи хэл загварууд нь хэлбэрийн суурь шулуунтай харьцуулахын тулд 9.95%-аар хувьсгал хөгжүүлж чадна.</abstract_mn>
      <abstract_no>I denne arbeiden foreslår vi eit nytt språk- modelleringsparadigm som har kapasiteten til å utføra både foregåve og modereringa av informasjonsflytting på fleire granularitier: neurallattisespråk- modeller. Desse modelane konstruerer ein lattis av moglege baner gjennom eit setning og marginaliserer gjennom denne lattice for å rekna ut sannsynlighetane for sekvens eller optimalisere parametrar. Denne tilnærminga tillèt oss å inkludere langviske intuisjonar, inkludert polysemi og eksisterende av fleire ord leksiske elementer, i språkkmodellen vårt. Eksperimentar på fleire språk- modelleringar viser at engelske neurallattiske språk- modeller som brukar polysemiske innbygging kan forbedra perpleksitet med 9,95% i relativ til eit ordnivå- baseline, og at ein kinesisk modell som handterar fleire teikn kan forbedra perpleksitet med 20,94% i relativ til eit teiknivå- baseline.</abstract_no>
      <abstract_pl>W niniejszej pracy proponujemy nowy paradygmat modelowania językowego, który ma możliwość wykonywania zarówno przewidywania, jak i moderowania przepływu informacji przy wielu granularnościach: modelach językowych siatek neuronowych. Modele te konstruują siatkę możliwych ścieżek przez zdanie i marginalizują ją w celu obliczenia prawdopodobieństwa sekwencji lub optymalizacji parametrów. Takie podejście pozwala nam płynnie włączyć intuicje językowe, w tym polisemię i istnienie wielowłownych elementów leksykalnych, do naszego modelu językowego. Eksperymenty na zadaniach modelowania wielu języków pokazują, że angielskie modele językowe siatek neuronowych, które wykorzystują wielosemiczne osadzenia, są w stanie poprawić zdezorientowanie o 9,95% w stosunku do bazy bazowej na poziomie słowa, oraz że chiński model obsługujący tokeny wieloznakowe jest w stanie poprawić zagadnienie o 20,94% w stosunku do bazowej bazowej na poziomie znaków.</abstract_pl>
      <abstract_ro>În această lucrare, propunem o nouă paradigmă de modelare a limbajului care are capacitatea de a efectua atât predicția, cât și moderarea fluxului de informații la granularități multiple: modele de limbaj cu rețea neurală. Aceste modele construiesc o retea de trasee posibile printr-o propozitie si marginalizeaza prin aceasta retea pentru a calcula probabilitatile secventei sau optimiza parametrii. Această abordare ne permite să încorporăm fără probleme intuițiile lingvistice - inclusiv polisemia și existența elementelor lexicale multicuvânt - în modelul nostru lingvistic. Experimentele asupra activităților de modelare a mai multor limbi arată că modelele lingvistice neurale engleze care utilizează încorporări polisemoase sunt capabile să îmbunătățească perplexitatea cu 9,95% în raport cu un nivel de referință de cuvânt și că un model chinez care gestionează token-uri multi-caractere este capabil să îmbunătățească perplexitatea cu 20,94% în raport cu un nivel de referință de caracter.</abstract_ro>
      <abstract_ms>Dalam kerja ini, kami cadangkan paradigm a pemodelan bahasa baru yang mempunyai kemampuan untuk melaksanakan kedua-dua ramalan dan pemoderan aliran maklumat pada granulariti berbilang: model bahasa lattice saraf. Model ini membina laptik laluan yang mungkin melalui kalimat dan marginalisasi melalui laptik ini untuk mengira kebarangkalian urutan atau optimize parameter. This approach allows us to seamlessly incorporate linguistic intuitions - including polysemy and the existence of multiword lexical items - into our language model.  Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94% relative to a character-level baseline.</abstract_ms>
      <abstract_sr>U ovom poslu predlažemo novu paradigmu za modeliranje jezika koji ima sposobnost da izvede i predviđanje i moderaciju toka informacija na višestrukim granularitijama: modeli jezika neuralne lattice. Ovi modeli konstruiraju lakticu mogućih puteva kroz rečenicu i marginaliziraju širom ove lattice kako bi izračunali verovatnoće sekvence ili optimizirali parametre. Ovaj pristup nam omogućava da nepromišeno uključimo jezičke intuicije - uključujući polizmu i postojanje multiriječnih leksičkih predmeta - u naš jezički model. Eksperimenti o višestrukim jezičkim modelima pokazuju da su engleski neurološki jezički modeli koji koriste polizemske integracije sposobni da poboljšaju perpleksitet za 9,95% u odnosu na početnu liniju riječi, i da kineski model koji vodi višekarakterne znakove može poboljšati perpleksitet za 20,94% u odnosu na početnu liniju na nivou karaktera.</abstract_sr>
      <abstract_mk>In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities: neural lattice language models.  Овие модели конструираат лактица од можни патишта преку реченица и маргинализираат низ оваа лактица за да се пресметаат веројатностите на секвенца или оптимизираат параметри. Овој пристап ни овозможува да ги вклучиме јазичните интуиции - вклучувајќи ја и полисемијата и постоењето на мултизборни лексикални предмети - во нашиот јазички модел. Експериментите на повеќето задачи за моделирање на јазици покажуваат дека англиските модели на јазик на нервални латики кои користат полисемни вградувања можат да ја подобрат збунетоста за 9,95 отсто во однос на основното ниво на зборови, и дека кинескиот модел кој се справува со мултикарактеристички знаци може да ја подобри збунетоста за 20,94 отсто во</abstract_mk>
      <abstract_sv>I detta arbete föreslår vi ett nytt språkmodellparadigm som har förmågan att utföra både förutsägelse och moderering av informationsflödet vid flera granulariteter: neurala gitterspråksmodeller. Dessa modeller konstruerar ett gitter av möjliga vägar genom en mening och marginaliserar över detta gitter för att beräkna sekvenssannolikheter eller optimera parametrar. Detta tillvägagångssätt gör det möjligt för oss att sömlöst integrera språkliga intuitioner - inklusive polysemi och existensen av flerords lexikala objekt - i vår språkmodell. Experiment på flerspråkiga modelleringsuppgifter visar att engelska neurala gitterspråksmodeller som använder polyemous inbäddningar kan förbättra förvirringen med 9,95% jämfört med en ordnivå baslinje, och att en kinesisk modell som hanterar flerteckenspråkiga tokens kan förbättra förvirringen med 20,94% jämfört med en teckenivå baslinje.</abstract_sv>
      <abstract_so>Markaas waxan, waxaynu soo jeedinnaa tusaale ahaan luuqada cusub oo ku qoran kara awood u leh inuu sameeyo qaababka la sii daayo iyo qaabilaadda macluumaadka oo kala duduwan, tusaale ahaan luuqada neurada. Tusaaladan ayaa dhisa wadooyin suurtagal ah oo ku qoran fursad iyo marginalizi karta si ay u xisaabiso suurtagalnimada ama ay u bedeshaan parameters. Tan qaababkan ayaa inagu sahlan kara in aan si xadar ah nooga dhigno qalabka luuqadaha, kuwaas oo ah polysemi iyo jirka alaabta leksikada badan ee luuqadeena. Imtixaamo ku saabsan shaqooyin tusaale ahaan luuqado kala duduwan waxay muuqan karaan tusaalaha afka Ingiriiska neurada ah oo isticmaalaya qashinka polysemi ah, waxay bedelan karaan muraaq ku saabsan 9.95% oo ku saabsan qoraalka heerka ee qoraalka, iyo in modelka Shiino oo maamula calaamado badan oo ku saabsan calaamado badan, wuxuu beddeli karaa qalabka ku saabsan 20.94% oo ku saabsan heer-heer.</abstract_so>
      <abstract_ta>இந்த வேலையில், நாம் ஒரு புதிய மொழி மாதிரி வடிவமைப்பு அளபுருவை பரிந்துரைக்கிறோம், அது எதிர்பார்ப்பு மற்றும் அறிவிப்பு மாற்றத்தின்  இந்த மாதிரிகள் ஒரு வாக்கியத்தின் மூலம் சாத்தியமான பாதைகளை உருவாக்கி இந்த வாக்கியத்திற்கு முழுவதும் சீரமைக்கும் மற்றும் தொடர் சாத இந்த செயல்பாடு முழுமையாக மொழியில் உள்ள மொழியில் சேர்க்க அனுமதிக்கிறது - பலவார்த்தை மற்றும் பல வார்த்தை லெக்சிக்சியல் உருப்பட பல மொழி மாதிரி மாதிரி பணிகளில் சோதனைகள் காண்பிக்கப்படுகிறது ஆங்கிலத்தில் பிளாசிமெஸ் பொருள்களை பயன்படுத்தும் போலிசெம்பு மாதிரிகள் 9. 95% வார்த்தை அடிப்படையில் சொல்லும் பொருத்தத்தை மேம்படுத்தும்,</abstract_ta>
      <abstract_si>මේ වැඩේ අපි අළුත් භාෂාව මොඩිලිග්ම් එකක් ප්‍රයෝජනය කරන්න පුළුවන් තියෙන්නේ, ඒ වගේම තොරතුරු ග්‍රැන්ලුරිටිස් වලින් තොර මේ මොඩේල් වාර්තාවක් පුළුවන් වාර්තාවක් වලින් ලෙටිස් එකක් හදන්න සහ මේ ලෙටිස් වලින් මාර්ජනය කරන්න පුළුවන් විශේ මේ විදියට අපිට භාෂාත්මක විදියට සම්බන්ධ වෙන්න පුළුවන් වෙනවා, අපේ භාෂාත්මක විදියට සම්බන්ධ වෙන්න පුළුවන ඉංග්‍රීසි න්‍යූරාල් ලැටිස් භාෂාව මොඩල් වලට ප්‍රයෝජනය වෙන්න පුළුවන් විදිහට 9.95% විදිහට ප්‍රයෝජනය වෙන්න පුළුවන්</abstract_si>
      <abstract_ur>ہم نے اس کام میں ایک نوی زبان نمادلینگ پاراڈیگ پیش کرنا اور معلومات کی مدرسی کو بہت سی گرانولاریٹوں میں انجام دینے کی قابلیت رکھتی ہے: نورول لاتیس زبان نمادلیاں۔ یہ موڈلز ایک جماعت کے ذریعے ایک لاتیس مسیر بناتے ہیں اور اس لاتیس کے ذریعے اس طرح محدودیت کا شمار کرنا یا پارامیٹروں کو اچھی طرح کرنا چاہتے ہیں. یہ طریقہ ہمیں اپنے زبان مدل میں سیدھی طریقے سے ملنے کی اجازت دیتا ہے - پولیسمی اور multiword lexical items کی موجودگی میں۔ بہت سی زبان موڈلینگ کے کاموں کی آزمائش دکھاتی ہے کہ انگلیسی نیورل لاتیس زبان موڈل جو پولیسیم ایمبڈینگ کو استعمال کرتی ہیں 9.95% کے ساتھ ایک لفظ-سطح بنیس لین کے معاملہ میں تقسیم کرسکتے ہیں، اور یہ کہ ایک چینی موڈل جو بہت سی کارٹر ٹوکنز کے معاملہ میں استعمال کرتی ہے 20.94% سے تقسیم کرتی ہے</abstract_ur>
      <abstract_vi>Trong công việc này, chúng tôi đề xuất một mô hình ngôn ngữ mới có khả năng thực hiện cả dự đoán và sự giảm độ lượng của dòng thông tin với các quy mô hạt nhân nhiều: mô hình ngôn ngữ trên dây thần kinh. Những mô- đun này xây dựng một lưới các đường có thể qua một câu và bị cách ly bên lề trong cơ quan này để tính to án các khả năng ngẫu nhiên hoặc tối ưu các tham số. Cách tiếp cận này cho phép chúng ta kết hợp hoàn hảo ngôn ngữ... bao gồm cả đa dạng và tồn tại các chữ viết nhiều từ trong mô hình ngôn ngữ. Thử nghiệm trên nhiều công việc tạo mẫu ngôn ngữ cho thấy mô hình thần kinh của người Anh, mẫu ngôn ngữ bao quát sử dụng sự nhúng mũi polysemous có thể cải thiện sự phức tạp của 9.95. tương đương với một cơ sở cơ sở cơ bản từ cấp thấp, và một mô hình Trung Quốc nắm giữ các thẻ đa nhân cách có thể cải thiện tính trong khoảng 9999999997 so với một cơ sở trường chữ.</abstract_vi>
      <abstract_uz>Bu ishda, biz bir necha granulatsiya bilan bir necha granulatsiya tadbirlik va tadbirlik maʼlumot yozib olish imkoniyatini bajarishga ega yangi tillar modeli rivojlanamiz. Ushbu modellar soʻzni bir so'z orqali yaratish va bu lattika orqali seksiyatlarni hisoblash yoki parametrlarni moslash mumkin. Bu usul bizni o'rtacha tillarga o'zgartirish imkoniyatini o'zgartirish imkoniyatini beradi - polysemi va muloqat-so'zlar leksikal narsalarning mavjudligini o'zgartirish mumkin - til modelimizga. Bir nechta tilni modellash vazifalarini ko'rsatish imtiyozlarini koʻrsatish mumkin, ingliz tilining neyron lattik tili modellari polysemiz embedlaridan foydalanishi mumkin 9.95% soʻzning baseline bilan bogʻlanishi mumkin, va ko'plab-shakl belgilarini boshqaruvchi xitoycha modeli 20.94% harf darajaga bog'liq bo'lgan shaklni bajarish mumkin.</abstract_uz>
      <abstract_bg>В тази работа ние предлагаме нова парадигма за езиково моделиране, която има способността да извършва както прогнозиране, така и умереност на информационния поток при множество гранулитети: езикови модели на невронна решетка. Тези модели изграждат решетка от възможни пътища чрез изречение и маргинализират през тази решетка, за да изчислят вероятностите за последователност или да оптимизират параметрите. Този подход ни позволява безпроблемно да включим лингвистичните интуиции - включително полисемията и съществуването на многословни лексикални елементи - в нашия езиков модел. Експерименти по задачи за многозначно езиково моделиране показват, че английските модели на невронна решетка, които използват многослойни вграждания, са в състояние да подобрят объркването с 9,95% спрямо базовата линия на ниво дума и че китайският модел, който обработва многосимволни символи, е в състояние да подобри объркването с 20,94% спрямо базовата линия на ниво символи.</abstract_bg>
      <abstract_nl>In dit werk stellen we een nieuw taalmodelleringsparadigma voor dat de mogelijkheid heeft om zowel voorspelling als moderatie van informatiestroom uit te voeren bij meerdere granulariteiten: neurale lattice taalmodellen. Deze modellen construeren een raster van mogelijke paden door een zin en marginaliseren over dit raster om opeenvolgende waarschijnlijkheden te berekenen of parameters te optimaliseren. Deze benadering stelt ons in staat om linguïstische intuïties, waaronder polysemie en het bestaan van multiword lexicale items, naadloos te integreren in ons taalmodel. Experimenten met meertalige modelleringstaken tonen aan dat Engelse neurale roostertaaltalenmodellen die gebruik maken van meertalige inbeddingen, de verwarring met 9,95% ten opzichte van een basislijn op woordniveau kunnen verbeteren, en dat een Chinees model dat tokens met meerdere tekens verwerkt, de verwarring met 20,94% ten opzichte van een basislijn op tekenniveau kan verbeteren.</abstract_nl>
      <abstract_da>I dette arbejde foreslår vi et nyt sprogmodelingsparadigme, der har evnen til at udføre både forudsigelse og moderering af informationsstrømmen ved flere granulariteter: neurale gittersprogsmodeller. Disse modeller konstruerer et gitter af mulige stier gennem en sætning og marginaliserer på tværs af gitteret for at beregne sekvenssandsynligheder eller optimere parametre. Denne tilgang giver os mulighed for problemfrit at indarbejde sproglige intuitioner - herunder polysemi og eksistensen af flere ord leksikalske elementer - i vores sprogmodel. Eksperimenter med flere sprogmodelleringsopgaver viser, at engelske neurale gittersprogsmodeller, der anvender polystemøse indlejringer, er i stand til at forbedre forvirringen med 9,95% i forhold til en oprindelig ordniveau, og at en kinesisk model, der håndterer multi-tegn tokens, er i stand til at forbedre forvirringen med 20,94% i forhold til en oprindelig tegnniveau.</abstract_da>
      <abstract_hr>U ovom poslu predlažemo novu paradigmu za modeliranje jezika koji ima sposobnost izvršiti predviđanje i umjerenje toka informacija na višestrukim granularitima: modeli jezika neuralne lattice. Ovi modeli konstruiraju lattice mogućih puteva kroz rečenicu i marginaliziraju širom ove lattice kako bi izračunali vjerojatnosti sekvence ili optimizirali parametre. Ovaj pristup nam omogućava beznačajno uključiti jezičke intuicije - uključujući polizamiju i postojanje multiriječnih leksičkih predmeta - u naš jezički model. Eksperimenti o višestrukim jezičkim modelima pokazuju da su modeli engleskog nervnog lattice koji koriste polizemske integracije u stanju poboljšati perpleksitet za 9,95% u odnosu na početnu liniju riječi, te da kineski model koji vodi višestruke znakove može poboljšati perpleksitet za 20,94% u odnosu na početnu liniju na nivou karaktera.</abstract_hr>
      <abstract_de>In dieser Arbeit schlagen wir ein neues Sprachmodellierungsparadigma vor, das die Fähigkeit hat, sowohl Vorhersage als auch Moderation des Informationsflusses bei mehreren Granularitäten durchzuführen: neuronale Gittersprachmodelle. Diese Modelle konstruieren ein Gitter möglicher Pfade durch einen Satz und marginalisieren dieses Gitter, um Sequenzwahrscheinlichkeiten zu berechnen oder Parameter zu optimieren. Dieser Ansatz ermöglicht es uns, linguistische Intuitionen, einschließlich Polysemie und die Existenz von mehrwortigen lexikalischen Elementen, nahtlos in unser Sprachmodell zu integrieren. Experimente an Mehrsprachenmodellierungsaufgaben zeigen, dass englische neuronale Gittersprachenmodelle, die polyemotionale Einbettungen verwenden, in der Lage sind, die Verwirrung um 9,95% im Vergleich zu einer Basislinie auf Wortebene zu verbessern, und dass ein chinesisches Modell, das Mehrzeichen-Token verarbeitet, in der Lage ist, die Verwirrung gegenüber einer Basislinie auf Zeichenebene um 20,94% zu verbessern.</abstract_de>
      <abstract_id>Dalam pekerjaan ini, kami mengusulkan paradigm a model bahasa baru yang memiliki kemampuan untuk melakukan both prediksi dan moderasi aliran informasi pada banyak granularitas: model bahasa lattice saraf. Model ini membangun lapis dari jalan yang mungkin melalui kalimat dan marginalisasi melalui lapis ini untuk menghitung probabilitas urutan atau optimisasi parameter. This approach allows us to seamlessly incorporate linguistic intuitions - including polysemy and the existence of multiword lexical items - into our language model.  Eksperimen pada tugas model berbagai bahasa menunjukkan bahwa model bahasa neural lattice bahasa Inggris yang memanfaatkan penyembedding polisemus mampu meningkatkan kekacauan dengan 9,95% relatif dengan dasar tingkat kata, dan bahwa model Cina yang menangani token-token berbagai karakter mampu meningkatkan kekacauan dengan 20,94% relatif dengan dasar tingkat karakter.</abstract_id>
      <abstract_fa>در این کار، ما پیشنهاد می‌کنیم یک پارادیگ مدل‌سازی زبان جدید که توانایی برای پیش‌بینی و متوسط جریان اطلاعات در چندین گرانولاریتی است: مدل‌های زبان عصبی لاتیس. این مدل‌ها یک لاتیس از راه‌های ممکن را از طریق یک جمله ساخته می‌کنند و از طریق یک جمله محدودیت می‌کنند تا احتمالات رده‌ها را محاسبه کند یا پارامترها را بهترین کنید. این دستور به ما اجازه می دهد که به طور بی‌نظیر نظر زبان‌شناسی - شامل polysemy و وجود موجودات زبان‌شناسی چند کلمه - را در مدل زبان‌مان جمع کنیم. تجربه‌ها در مورد کارهای مدل‌سازی زبان‌های مختلف نشان می‌دهند که مدل‌های زبان‌های عصبی انگلیسی که استفاده می‌کنند انجمن‌سازی‌های مختلف می‌توانند با ۹.۹۵% نسبت به یک خط طبقه‌ی پایین‌مرحله‌ی کلمه‌ها بهتر کنند، و یک مدل چینی که مدل‌های معجزه‌های مختلف‌شخصیت‌ها را تحت</abstract_fa>
      <abstract_sw>Katika kazi hii, tunapendekeza namna mpya ya kuonyesha mifano ya lugha yenye uwezo wa kutekeleza utabiri na utoaji wa maendeleo ya taarifa kwa misingi mbalimbali: mifano ya lugha ya asili. Mifano hii hujenga vifaa vya njia zinazowezekana kupitia hukumu na kuingiza kwenye vifaa hiki kwa ajili ya kuhesabu uwezekano wa ufuatikano au kuboresha parameters. Hatua hii inaturuhusu kuingiza mitazamo ya lugha - ikiwa ni pamoja na polysemi na kuwepo kwa vitu vingi vya lexico - katika mtindo wa lugha yetu. Majaribio kuhusu kazi za mifano ya lugha mbalimbali zinaonyesha kuwa mifano ya lugha za Kiingereza za ya kitaaluma ya lugha inayotumia vifaa vya kisasa vinaweza kuboresha tetesi kwa asilimia 9.95 yanayohusiana na msingi wa maneno, na kwamba modeli ya Kichina inayohusiana na alama nyingi za wahusika inaweza kuboresha utata kwa asilimia 20.94 inayohusiana na msingi wa kiwango cha tabaka.</abstract_sw>
      <abstract_ko>이 작업에서 우리는 새로운 언어 모델링 모델을 제시했다. 이것은 다립도에서 정보 흐름인 신경결정 언어 모델을 동시에 예측하고 조절할 수 있다.이 모델들은 문장을 통과하는 가능한 경로 칸을 구축하고 이 칸에 가장자리를 만들어 서열 확률을 계산하거나 파라미터를 최적화시킨다.이런 방법은 우리로 하여금 다의와 다사 어휘항의 존재를 포함하여 언어의 직각을 우리의 언어 모델에 융합시킬 수 있게 한다.다국어 모델링 임무에서의 실험에 따르면 다의적으로 박힌 영어 신경격 언어 모델은 단어급 기선에 비해 9.95%의 곤혹도를 개선할 수 있고, 다문자 표기를 처리하는 중국어 모델은 문자급 기선에 비해 20.94%의 곤혹도를 개선할 수 있다.</abstract_ko>
      <abstract_sq>Në këtë punë, ne propozojmë një paradigm ë të re modelimi gjuhësh që ka aftësinë për të kryer si parashikimin, ashtu edhe moderimin e rrjedhjes së informacionit në granularitete të shumta: modelet e gjuhës nervore lattice. Këto modele ndërtojnë një pjesë të rrugëve të mundshme nëpërmjet një fjalimi dhe marginalizojnë nëpër këtë pjesë për të llogaritur probabilitetet e sekuencës apo optimizuar parametrat. Ky qasje na lejon të përfshijmë në mënyrë të papërshtatshme intuicionet gjuhësore - duke përfshirë polisiminë dhe ekzistencën e elementeve lexike të shumëfjalëshme - në modelin tonë gjuhësor. Eksperimentet mbi detyrat e modelimit të shumëfishtë gjuhësh tregojnë se modelet e gjuhës nervore angleze që përdorin përfshirje polisemore janë në gjendje të përmirësojnë perplexitetin me 9.95% në krahasim me një bazë të nivelit të fjalës dhe se një model kinez që trajton tokene shumëkarakterësh është në gjendje të përmirësojë perplexitetin me 20.94% në krahasim me një bazë të nivelit të karakterit.</abstract_sq>
      <abstract_am>በዚህ ሥራ፣ አዲስ ቋንቋ ምሳሌ ማሳየትን እና የመልእክት ውጤት ማቀናቀል እና ማቀናቀል የሚችለውን አዲስ የቋንቋ ምሳሌ ማሳየትን እናስባለን፡፡  These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters.  ይህም ሥርዓት የቋንቋ ቋንቋ አስተያየትን እና ብዙ ቃላት የሌክሲካዊ ነገሮች መኖራችንን ለቋንቋችን ምሳሌ ለማሳሰብ ይችላል፡፡ በብዛት ቋንቋ ምሳሌዎችን በሚያሳየው ሥራ ላይ ፈተናዎች የኢንጂልኛ የናውሬው የቋንቋ ቋንቋ ምሳሌዎች የፖሊስቲካዊ አካባቢዎችን በመጠቀም የሚችሉትን የ9.95 በመቶ ቃላት-ደረጃ መደገፊያውን እንዲያሳድጉ ይችላሉ፡፡</abstract_am>
      <abstract_hy>In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities: neural lattice language models.  Այս մոդելները կառուցում են նախադասության միջոցով հնարավոր ճանապարհների բաժինը և սահմանափակում այս բաժինը հաշվարկելու հաջորդականության հավանականությունների կամ օպտիմացման պարամետրերի համար: This approach allows us to seamlessly incorporate linguistic intuitions - including polysemy and the existence of multiword lexical items - into our language model.  Բազմաթիվ լեզվի մոդելավորման խնդիրների փորձարկումները ցույց են տալիս, որ անգլերեն նյարդային լատտիկ լեզվի մոդելները, որոնք օգտագործում են պոլիզեմային ներդրումներ, կարողանում են բարելավել խառնաշփոթը 9.95 տոկոսով, համեմատած բառի մակարդակի հիմքի վրա, և որ չինական մոդելը, որը վերահսկում է բա</abstract_hy>
      <abstract_bn>এই কাজে আমরা একটি নতুন ভাষার মডেলিং প্রস্তাব করছি যা প্রত্যেক ভাষায় ভবিষ্যত এবং তথ্য প্রবাহের আধুনিকভাবে বিভিন্ন গ্রানুলারিটিস ভাষার মড These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters.  এই পদ্ধতি আমাদেরকে সীমালভাবে ভাষার ভাষার অনুভূতির মধ্যে যুক্ত করতে দেয় - যার মধ্যে বহুশব্দের লেক্সিক্যাল জিনিসপত্র এবং আমাদের ভাষ বেশ কয়েকটি ভাষার মডেলিং কাজের পরীক্ষা দেখা যাচ্ছে যে ইংরেজী নিউরুল ল ল্যাটিস ভাষার মডেল ব্যবহার করে পালিসেমিউস ব্যবহার করে একটি শব্দ-স্তরের বেসালাইনের সাথে সম্পর্কিত ৯. ৯৫% ব্যবহার করতে পারে, এবং চীনা মডে</abstract_bn>
      <abstract_az>Bu işdə, biz yeni dil modelləşdirməsi paradigmi təklif edirik ki, bilgi akışını çoxlu granularitlərdə təmin edə bilər: nöral lattice dil modelləri. Bu modellər mümkün yollardan bir cümə vasitəsilə lattice inşa edir və bu lattice vasitəsilə seçmək mümkün olaraqlarını hesablamaq və ya parametrləri optimizləndirir. Bu tərzim bizim dil modelimizə çoxlu sözlərin və çoxlu sözlərin əlamətlərinin olmasına imkan verir. Çoxlu dil modelləşdirmək işlərində təcrübələr göstərir ki, polizem içərilərini istifadə edən İngiliz nöral lattice dil modelləri sözlərin səviyyəsinə bağlı olan bir söz səviyyəsinə bağlı olan 9,95% ilə müxləqiyyəti daha yaxşılaşdıra bilər, və ki, çoxlu karakter işaretlərini idarə edən Çin modeli 20,94% ilə müxləqiyyəti artıra bilər.</abstract_az>
      <abstract_ca>En aquesta feina, proposem un nou paradigm a de modelació de llenguatges que té l'habilitat de fer tant predicció com moderació del flux d'informació a múltiples granularitats: models de llenguatge neural lattice. These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters.  Aquest enfocament ens permet incorporar senzillament intuïcions lingüístiques - incloent la polissima i l'existència d'articles lexics multiparaules - al nostre model lingüístic. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94% relative to a character-level baseline.</abstract_ca>
      <abstract_bs>U ovom poslu predlažemo novu paradigmu za modeliranje jezika koji ima sposobnost izvršiti predviđanje i moderaciju toka informacija na višestrukim granulacijama: modeli jezika neuralne lattice. Ovi modeli konstruiraju lattice mogućih puteva kroz rečenicu i marginaliziraju preko ove lattice kako bi izračunali vjerojatnosti sekvence ili optimizirali parametre. Ovaj pristup nam omogućava bezvezno uključiti jezičke intuicije - uključujući polizamiju i postojanje multiriječnih leksičkih predmeta - u naš jezički model. Eksperimenti o višestrukim jezičkim modelima pokazuju da su modeli engleskog neuralnog jezika lattice koji koriste polizemske integracije u stanju poboljšati perpleksitet za 9,95% u odnosu na početnu liniju riječi, i da kineski model koji vodi višekarakterne znakove može poboljšati perpleksitet za 20,94% u odnosu na početnu liniju na nivou karaktera.</abstract_bs>
      <abstract_cs>V této práci navrhujeme nové jazykové modelování paradigma, které má schopnost provádět predikci i moderaci toku informací při více granularitách: neuronové mřížkové jazykové modely. Tyto modely konstruují mřížku možných cest skrze větu a marginalizují přes tuto mřížku pro výpočet pravděpodobností sekvence nebo optimalizaci parametrů. Tento přístup nám umožňuje bezproblémově začlenit jazykové intuice včetně polysémie a existence víceslovních lexikálních položek do našeho jazykového modelu. Experimenty na úlohách modelování více jazyků ukazují, že anglické neuronové mřížkové jazykové modely využívající polyemozní vložení jsou schopny zlepšit zmatenost o 9,95% ve srovnání se základní linií na úrovni slova a že čínský model, který zpracovává víceznakové tokeny, je schopen zlepšit zmatenost o 20,94% vzhledem k základní linii znaků.</abstract_cs>
      <abstract_et>Käesolevas töös pakume välja uue keele modelleerimise paradigma, millel on võime teostada nii infovoogu ennustamist kui ka mõõdukust mitme granulaarsusega: neuraalvõre keele mudelid. Need mudelid loovad lause kaudu võimalike teede võre ja marginaliseerivad selle võre, et arvutada jada tõenäosusi või optimeerida parameetreid. See lähenemine võimaldab meil sujuvalt kaasata keelelisi intuitsioone - sealhulgas polüseemia ja mitmesõnaliste leksikaalsete elementide olemasolu - meie keelemudelisse. Mitme keele modelleerimise ülesannete eksperimendid näitavad, et inglise neuraalvõre keelemudelid, mis kasutavad polüsemoosseid manustamisi, suudavad parandada hämmeldust 9,95% võrra võrreldes sõnataseme algväärtusega ning et hiina mudel, mis käsitleb mitme märgiga märke, suudab hämmeldust 20,94% võrra võrreldes algväärtusega.</abstract_et>
      <abstract_fi>Tässä työssä ehdotamme uutta kielimallinnusparadigmaa, jolla on kyky ennustaa ja moderoida tiedonkulkua usealla granulariditeetillä: neuroristikkokielimallit. Nämä mallit rakentavat ristikon mahdollisista poluista lauseen kautta ja marginalisoivat tämän ristikon läpi laskeakseen sekvenssin todennäköisyyksiä tai optimoidakseen parametreja. Tämä lähestymistapa mahdollistaa kielellisten intuitioiden saumattoman yhdistämisen kielimalliimme, mukaan lukien polysemia ja monisanaisten leksikoiden olemassaolo. Useiden kielimallinnustehtävien kokeet osoittavat, että monikielisiä upotuksia hyödyntävät englanninkieliset hermoristikkokielimallit pystyvät parantamaan hämmennystä 9,95% sanatason lähtötasoon verrattuna, ja että monikirjaimisia merkkejä käsittelevä kiinalainen malli pystyy parantamaan hämmennystä 20,94% merkkitason lähtötasoon verrattuna.</abstract_fi>
      <abstract_tr>Bu işde, biz täze bir dil modelleýän paradigmany teklip edip bilýäris. Bu şekilde näçe granularlyk bilen informasiýa akylyny hem öňden öňden geçirmekde mümkin. Bu nusgalar mümkin bir sözlem bilen bir lattice ýoluň edip, hatlaryň sanlyklaryny hasaplamak üçin bu lattice tarapyndan geçirmek üçin. Bu ýagdaý bize dillerimiz nusgasyna köpüräk bir şekilde çykyp biler. Birnäçe dil modellendirmek täbliklerinden örnekler iňlis neiral lattice dil modelleriniň polysemler içerisinde işleýän çözümleri 9.95% tarapynda söz derejesi baseline ýaly gelişmäge mümkin edip bilýär we birnäçe karakterler işeňleýän Çinçe modelleriniň 20.94% tarapyna gelişmäge mümkin edip bilýär.</abstract_tr>
      <abstract_af>In hierdie werk voorstel ons 'n nuwe taal modellering paradigme wat die moontlik het om beide voorskou en moderasie van inligting vloei te doen by veelvuldige granularisies: neurale laatistaal modele. Hierdie modele konstrukteer 'n lattice van moontlike paaie deur 'n seting en marginaliseer deur hierdie lattice om sekwensiewaarskynlikheite te bereken of optimaliseer parameters te bereken. Hierdie toegang laat ons toe om lingwisiese intuisies, insluitend polisemie en die eksistensie van multiwoorde leksiese items in ons taal model te inkorporeer. Eksperimente op veelvuldige taal modellering opdragte vertoon dat Engelse neurale lattice taal modele wat polisemus inbêdinge gebruik kan verbeter die perpleksie deur 9.95% relatief na 'n woord vlak basislien, en dat 'n Sjinese model wat multikarakter-tekens hanteer kan verbeter die perpleksie deur 20.94% relatief na 'n karaktervlak basislien.</abstract_af>
      <abstract_sk>V tem delu predlagamo novo paradigma jezikovnega modeliranja, ki ima sposobnost izvajati tako napovedovanje kot zmernost pretoka informacij pri več granulativnostih: jezikovni modeli nevralne mreže. Ti modeli gradijo mrežo možnih poti skozi stavek in marginalizirajo čez to mrežo, da izračunajo verjetnosti zaporedja ali optimizirajo parametre. Ta pristop nam omogoča nemoteno vključevanje jezikovnih intuicij - vključno s polisemijo in obstojem večbesednih leksikalnih elementov - v naš jezikovni model. Eksperimenti z nalogami modeliranja več jezikov kažejo, da lahko angleški jezikovni modeli nevronske mreže, ki uporabljajo večemozne vdelave, izboljšajo zmedenost za 9,95% glede na osnovno vrednost besed in da lahko kitajski model, ki obravnava večznakovne žetone, izboljša zmedenost za 20,94% glede na osnovno vrednost znakov.</abstract_sk>
      <abstract_ha>Daga wannan aikin, Munã buɗa wani misalin wata sabon da ke samar da shi yana da awon ya cika motsi da shirin haɗi da masu haɗi da shirin information bakin granufi masu yawa: misãlai na laptatice na neural. Wannan motel na samar da wata talati wa hanyõyi masu yiwuwa da za'a iya amfani da wani magana kuma a kiyaye shi a kan wannan laptori dõmin ya yi hisãbin masu yiwur sauri ko kuma ya ƙayyade parameteri. Wannan hanyor ya yarda mu haɗi fasalin linguin da ke cikin muhimmanci, kamar misalin misalin lingui da misalin misalin misalin mu. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94% relative to a character-level baseline.</abstract_ha>
      <abstract_bo>ལས་ཀ་འདིའི་ནང་དུ་ང་ཚོས་སྐད་ཀྱི་རྣམ་པ་གསར་བ་ཞིག་གི་སྔོན་ལྟར་དང་གནས་ཚུལ These models construct a lattice of possible paths through a sentence and marginalize across this lattice to calculate sequence probabilities or optimize parameters. འདི་ལྟ་བུའི་ལམ་ལུགས་འདིས་ང་ཚོར་སྐད་ཡིག་གཟུགས་པའི་སྣ་ཚིགས་དང་རྣམ་པ་མང་ཙམ་མང་གྱི་རྣམ་གྲངས་ཀྱི་ནང་དུ་བཅུག་གི་ཡོད། Experiments on multiple language modeling tasks show that English neural lattice language models that use polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve the perplexity by 20.94% relative to a character-level baseline.</abstract_bo>
      <abstract_jv>Nang barêng-barêng iki, kéné supoyo nggawe pararampun anyar nggawe ngubah winih sing apik dhéwé nggawe gerarané karo modère kuwi tindakan sistem sing wisata luwih: Laptop" and "Desktop Ndheke iki supaya awak dhéwé nggawe persilangan luwih-luwih éntuk karo akeh polisemi lan saiki ono limo akeh liyane saiki- ning modèl kuwi tindangana dhéwé. Peringatan karo sistem sing dadi nggambar nggambar obang-obang.</abstract_jv>
      <abstract_he>בעבודה הזו, אנו מציעים פרדיגמה חדשה לדוגמא שפה שיש לה את היכולת לבצע גם חזיון וגם מודרות של זרימת מידע במספר גרנולריות: דוגמאות שפת עצבי. הדוגמנים האלה בונים חטיפה של דרכים אפשריים דרך משפט ומעטפים ברחבי החטיפה הזאת כדי לחשב סבירות רצף או אופטימיזם פרמטרים. הגישה הזאת מאפשרת לנו להכניס אינטואיציות שפתיות באופן בלתי מתאים - כולל פוליזמיה וקיום של פריטים לקסיים רבים מילים - למודל השפה שלנו. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve perplexity by 9.95% relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve perplexity by 20.94% relative to a character-level baseline.</abstract_he>
      </paper>
    <paper id="37">
      <title>Planning, Inference and Pragmatics in Sequential Language Games</title>
      <author><first>Fereshte</first><last>Khani</last></author>
      <author><first>Noah D.</first><last>Goodman</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <doi>10.1162/tacl_a_00037</doi>
      <abstract>We study sequential language games in which two players, each with private information, communicate to achieve a common goal. In such games, a successful player must (i) infer the partner’s private information from the partner’s messages, (ii) generate messages that are most likely to help with the goal, and (iii) reason pragmatically about the partner’s strategy. We propose a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that captures all three characteristics and demonstrate their importance in capturing <a href="https://en.wikipedia.org/wiki/Human_behavior">human behavior</a> on a new goal-oriented dataset we collected using <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>.</abstract>
      <pages>543–555</pages>
      <url hash="aa924e10">Q18-1037</url>
      <bibkey>khani-etal-2018-planning</bibkey>
      <pwccode url="https://worksheets.codalab.org/worksheets/0x052129c7afa9498481185b553d23f0f9" additional="false">worksheets/0x052129c7</pwccode>
    <title_ar>التخطيط والاستدلال والبراغماتية في ألعاب اللغة المتسلسلة</title_ar>
      <title_fr>Planification, inférence et pragmatique dans les jeux linguistiques séquentiels</title_fr>
      <title_es>Planificación, inferencia y pragmática en juegos de lenguaje secuencial</title_es>
      <title_pt>Planejamento, Inferência e Pragmática em Jogos de Linguagem Sequencial</title_pt>
      <title_ja>シーケンシャル・ランゲージ・ゲームにおける計画、推論、および実用性</title_ja>
      <title_zh>次语戏中规画、推理、语用</title_zh>
      <title_hi>अनुक्रमिक भाषा खेलों में योजना, अनुमान और व्यावहारिकता</title_hi>
      <title_ru>Планирование, вывод и прагматика в последовательных языковых играх</title_ru>
      <title_ga>Pleanáil, Tátal agus Pragmataic i gCluichí Seicheamhacha Teanga</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Σχεδιασμός, Συμπέρασμα και Πραγματική σε διαδοχικά Γλωσσικά Παιχνίδια</title_el>
      <title_kk>Келесі тіл ойындарындағы жоспарлау, бақылау және прагматика</title_kk>
      <title_lt>Sekvencinių kalbų žaidimų planavimas, infrastruktūra ir pragmatika</title_lt>
      <title_mk>Планирање, инференција и прагматика во секвенцијалните јазични игри</title_mk>
      <title_hu>Tervezés, inferencia és pragmatika a szekvenciális nyelvi játékokban</title_hu>
      <title_ms>Perrancangan, Inferensi dan Pragmatik dalam Permainan Bahasa Sequential</title_ms>
      <title_it>Pianificazione, Inferenza e Pragmatica nei Giochi Linguistici Sequenziali</title_it>
      <title_ml>സെക്കന്റിയല്‍ ഭാഷ കളികളിലുള്ള പ്ലാനിങ്ങ്, മുന്നോട്ടും പ്രാഗ്മാറ്റിക്സ്</title_ml>
      <title_mn>Дараагийн хэл тоглоомын төлөвлөгөө, хүндрэл, прагматик</title_mn>
      <title_mt>Ippjanar, Inferenza u Pragmatika fil-Logħob tal-Lingwi Sekwenzjali</title_mt>
      <title_no>Name</title_no>
      <title_ro>Planificare, inferență și pragmatică în jocurile de limbi secvențiale</title_ro>
      <title_sr>Planiranje, poštovanje i pragmatika u sekvencijalnim jezičkim igrama</title_sr>
      <title_pl>Planowanie, wnioski i pragmatyka w sekwencyjnych grach językowych</title_pl>
      <title_si>සැලසුම්, ප්‍රාග්මේටික් සහ ප්‍රාග්මේටික්</title_si>
      <title_ur>نقشه، انفارئنس اور پراگماٹیکس سئوئنسیل زبان کھیلیں میں</title_ur>
      <title_sv>Planering, inferens och pragmatik i sekventiella språkspel</title_sv>
      <title_so>Qorshooyinka, kulanka iyo tijaabada luqada soo socda</title_so>
      <title_ta>பின்வரும் மொழி விளையாட்டு</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Chương trình, sự liên minh và các bí mật trong các cuộc thi ngôn ngữ</title_vi>
      <title_da>Planlægning, inferens og pragmatik i sekventielle sprogspil</title_da>
      <title_bg>Планиране, заключение и прагматика в последователни езикови игри</title_bg>
      <title_nl>Planning, Inference en Pragmatica in opeenvolgende taalspelletjes</title_nl>
      <title_hr>Planiranje, dodržavanje i pragmatice u sekvencijalnim jezičkim igrama</title_hr>
      <title_de>Planung, Schlussfolgerung und Pragmatik in Sequenziellen Sprachspielen</title_de>
      <title_id>Planning, Inference and Pragmatics in Sequential Language Games</title_id>
      <title_ko>순서 언어 게임에서의 계획, 추리와 언어 사용</title_ko>
      <title_sw>Mpango, Kuzungumzwa na Tamko katika Michezo ya Lugha</title_sw>
      <title_af>Name</title_af>
      <title_fa>برنامه‌ریزی، برنامه‌بندی و پراگرماتیک در بازی‌های زبان‌های بعدی</title_fa>
      <title_sq>Planifikimi, Inferenca dhe Pragmatika në Lojrat Sekuenciale të Gjuhave</title_sq>
      <title_am>Planning, Inference and Pragmatics in Sequential Language Games</title_am>
      <title_tr>Indiki dil oýunlarında planlaşdyrma, gözlemek we pragmatik</title_tr>
      <title_hy>Սեքսենցիալ լեզվի խաղերում պլանավորելը, ինֆերենսը և պրագմատիկան</title_hy>
      <title_bs>Planiranje, dodržavanje i pragmatike u sekvencijalnim jezičkim igrama</title_bs>
      <title_ca>Planificació, Inferència i Pragmàtica en Jocs de Llingua Seqüencial</title_ca>
      <title_az>Sequential Dil Oyunlarında Planlama, Inference və Pragmatik</title_az>
      <title_bn>সাধারণ ভাষার খেলায় পরিকল্পনা, এনফেরেন্স এবং প্রাগ্যামেটিক্স</title_bn>
      <title_et>Planeerimine, järeldus ja pragmaatika järjestikustes keelemängudes</title_et>
      <title_cs>Plánování, Inference a Pragmatika v sekvenčních jazykových hrách</title_cs>
      <title_fi>Suunnittelu, päättely ja pragmatiikka peräkkäisissä kielipeleissä</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>תכנון, אינפרננציה ופרגמטיקה במשחקי שפות רציניים</title_he>
      <title_sk>Načrtovanje, sklepanje in pragmatika v zaporednih jezikovnih igrah</title_sk>
      <title_bo>རྗེས་མའི་སྐད་རིགས་ཚོའི་འགོ་འཛུགས་དང་། ལྟ་བུའི་འགྲོ་སྟངས་དང་།</title_bo>
      <title_jv>Tulung luwih, ingkang dipune karo pragamtiki lan kelangenan langa Sekondêr</title_jv>
      <abstract_ar>ندرس الألعاب اللغوية المتسلسلة التي يتواصل فيها لاعبان ، كل منهما بمعلومات خاصة ، لتحقيق هدف مشترك. في مثل هذه الألعاب ، يجب على اللاعب الناجح (1) استنتاج معلومات الشريك الخاصة من رسائل الشريك ، (2) إنشاء رسائل من المرجح أن تساعد في تحقيق الهدف ، و (3) سبب عمليًا حول استراتيجية الشريك. نقترح نموذجًا يلتقط جميع الخصائص الثلاث ويظهر أهميتها في التقاط السلوك البشري في مجموعة بيانات جديدة موجهة نحو الهدف قمنا بجمعها باستخدام التعهيد الجماعي.</abstract_ar>
      <abstract_fr>Nous étudions des jeux linguistiques séquentiels dans lesquels deux joueurs, chacun disposant d'informations privées, communiquent pour atteindre un objectif commun. Dans de tels jeux, un joueur qui réussit doit (i) déduire les informations privées du partenaire à partir des messages du partenaire, (ii) générer des messages qui sont les plus susceptibles d'aider à atteindre l'objectif, et (iii) raisonner de manière pragmatique sur la stratégie du partenaire. Nous proposons un modèle qui capture les trois caractéristiques et démontre leur importance dans la capture du comportement humain dans un nouveau jeu de données axé sur les objectifs que nous avons collecté à l'aide du crowdsourcing.</abstract_fr>
      <abstract_es>Estudiamos juegos de idiomas secuenciales en los que dos jugadores, cada uno con información privada, se comunican para lograr un objetivo común. En estos juegos, un jugador exitoso debe (i) inferir la información privada del socio a partir de los mensajes del socio, (ii) generar mensajes que probablemente ayuden con el objetivo y (iii) razonar pragmáticamente sobre la estrategia del socio. Proponemos un modelo que capture las tres características y demuestre su importancia a la hora de capturar el comportamiento humano en un nuevo conjunto de datos orientado a objetivos que recopilamos mediante el uso de crowdsourcing.</abstract_es>
      <abstract_pt>Estudamos jogos de linguagem sequencial em que dois jogadores, cada um com informações privadas, se comunicam para atingir um objetivo comum. Nesses jogos, um jogador bem-sucedido deve (i) inferir as informações privadas do parceiro a partir das mensagens do parceiro, (ii) gerar mensagens com maior probabilidade de ajudar no objetivo e (iii) raciocinar pragmaticamente sobre a estratégia do parceiro. Propomos um modelo que captura todas as três características e demonstra sua importância na captura do comportamento humano em um novo conjunto de dados orientado a objetivos que coletamos usando crowdsourcing.</abstract_pt>
      <abstract_ja>私たちは、プライベートな情報を持つ2人のプレイヤーが、共通の目標を達成するためにコミュニケーションをとるシーケンシャルな言語ゲームを研究しています。そのようなゲームでは、成功したプレイヤーは、（ i ）パートナーのメッセージからパートナーのプライベート情報を推測し、（ ii ）目標に最も役立つ可能性の高いメッセージを生成し、（ iii ）パートナーの戦略について実用的に理由付けする必要があります。クラウドソーシングを使用して収集した新しい目標指向のデータセットで、3つの特徴すべてをキャプチャし、人間の行動をキャプチャする上での重要性を示すモデルを提案します。</abstract_ja>
      <abstract_zh>论次语言戏,其二玩家,人皆有私信,以合其流。 如此戏中,玩家须(i)从合作伙伴消息中推断出合作伙伴私信息,(ii)生最有可助实现目标消息,及(iii)合作伙伴策务实推理。 吾为一模,当尽得三特,而于吾用众包之新面向目标之数集上明其得人之大体也。</abstract_zh>
      <abstract_hi>हम अनुक्रमिक भाषा खेलों का अध्ययन करते हैं जिसमें दो खिलाड़ी, प्रत्येक निजी जानकारी के साथ, एक सामान्य लक्ष्य प्राप्त करने के लिए संवाद करते हैं। इस तरह के खेलों में, एक सफल खिलाड़ी को (i) साथी के संदेशों से साथी की निजी जानकारी का अनुमान लगाना चाहिए, (ii) ऐसे संदेश उत्पन्न करना चाहिए जो लक्ष्य के साथ मदद करने की सबसे अधिक संभावना रखते हैं, और (iii) साथी की रणनीति के बारे में व्यावहारिक रूप से कारण। हम एक मॉडल का प्रस्ताव करते हैं जो सभी तीन विशेषताओं को कैप्चर करता है और एक नए लक्ष्य-उन्मुख डेटासेट पर मानव व्यवहार को कैप्चर करने में उनके महत्व को प्रदर्शित करता है जिसे हमने क्राउडसोर्सिंग का उपयोग करके एकत्र किया था।</abstract_hi>
      <abstract_ru>Мы изучаем последовательные языковые игры, в которых два игрока, каждый с личной информацией, общаются для достижения общей цели. В таких играх успешный игрок должен (i) вывести личную информацию партнера из сообщений партнера, (ii) генерировать сообщения, которые, скорее всего, помогут в достижении цели, и (iii) прагматично рассуждать о стратегии партнера. Мы предлагаем модель, которая захватывает все три характеристики и демонстрирует их важность в захвате человеческого поведения на новом целеориентированном наборе данных, который мы собрали с помощью краудсорсинга.</abstract_ru>
      <abstract_ga>Déanaimid staidéar ar chluichí teanga seicheamhacha ina ndéanann beirt imreoir, gach ceann acu le faisnéis phríobháideach, cumarsáid chun sprioc choiteann a bhaint amach. I gcluichí den sórt sin, caithfidh imreoir rathúil (i) faisnéis phríobháideach an chomhpháirtí a bhaint as teachtaireachtaí an chomhpháirtí, (ii) teachtaireachtaí a ghiniúint is dóichí a chuideoidh leis an sprioc, agus (iii) réasúnú go pragmatach faoi straitéis an chomhpháirtí. Molaimid múnla a ghlacann na trí thréith go léir agus a léiríonn a thábhachtaí atá siad maidir le hiompar daonna a ghabháil ar thacar sonraí nua atá dírithe ar spriocanna a bhailíomar agus úsáid á baint as sluafhoinsiú.</abstract_ga>
      <abstract_el>Μελετάμε διαδοχικά γλωσσικά παιχνίδια στα οποία δύο παίκτες, ο καθένας με ιδιωτικές πληροφορίες, επικοινωνούν για να επιτύχουν έναν κοινό στόχο. Σε τέτοια παιχνίδια, ένας επιτυχημένος παίκτης πρέπει (i) να συναγάγει τις προσωπικές πληροφορίες του εταίρου από τα μηνύματα του εταίρου, (ii) να δημιουργήσει μηνύματα που είναι πιο πιθανό να βοηθήσουν στην επίτευξη του στόχου και (iii) να συλλογιστεί ρεαλιστικά σχετικά με τη στρατηγική του εταίρου. Προτείνουμε ένα μοντέλο που αποτυπώνει και τα τρία χαρακτηριστικά και καταδεικνύει τη σημασία τους στην καταγραφή της ανθρώπινης συμπεριφοράς σε ένα νέο στοχοθετημένο σύνολο δεδομένων που συλλέξαμε με τη χρήση crowdsourcing.</abstract_el>
      <abstract_ka>ჩვენ ვისწავლობთ სწორედ ენის თამაში, რომელიც ორი თამაშებელი, ყოველ პირადი ინფორმაციის შესახებ, კომუნიკაცია საერთო მისახებ. ასეთი თამაში წარმატებული მოთამაშებელი (i) პონტერნეტის პირადი ინფორმაციაზე, პონტერნეტის შეტყობინებებიდან, ii) შექმნა შეტყობინებები, რომლებიც უფრო შესაძლებელია მიზედან დახმარება, და iii) პრაგმატი ჩვენ მინდა მოდელს, რომელიც ყველა სამი განსაზღვრებულებების შესახებ და გამოჩვენება მათი მნიშვნელობა ადამიანის ქცევის შესახებ ახალი მიზეზის მონაცემების შესახებ, რომელი</abstract_ka>
      <abstract_kk>Біз кейінгі тіл ойындарын оқу үшін екі ойнатушы, әрбір жеке мәлімет бар, жалпы мақсатты жеткізу үшін байланысты. Бұл ойындарда сәтті ойнатушы (i) қатысушының жеке мәліметін қатысушының хаттарынан беру керек, ii) мақсатта көмектесетін хаттарды жасау керек, және iii) қатысушының стратегиясы туралы прагматикалық түрде. Біз бүкіл үш қасиеттерді алып, адамдардың әрекетін жаңа мақсатты деректер жинағындағы жаңа мақсатты деректер бағдарламасын түсіргенін көрсетеді.</abstract_kk>
      <abstract_hu>Szekvenciális nyelvi játékokat tanulmányozunk, amelyekben két játékos, mindegyik magáninformációval, kommunikál egy közös cél elérése érdekében. Ilyen játékokban a sikeres játékosnak (i) a partner üzeneteiből következtetnie kell a partner személyes információit, (ii) olyan üzeneteket kell generálnia, amelyek valószínűleg segítenek a cél elérésében, és (iii) pragmatikusan kell érvelnie a partner stratégiáját. Olyan modellt javasolunk, amely mindhárom jellemzőt megragadja, és bemutatja fontosságukat az emberi viselkedés rögzítésében egy új, célorientált adatkészleten, amelyet a crowdsourcing segítségével gyűjtöttünk össze.</abstract_hu>
      <abstract_it>Studiamo giochi linguistici sequenziali in cui due giocatori, ciascuno con informazioni private, comunicano per raggiungere un obiettivo comune. In tali giochi, un giocatore di successo deve (i) dedurre le informazioni private del partner dai messaggi del partner, (ii) generare messaggi che sono più suscettibili di aiutare con l'obiettivo, e (iii) ragionare pragmaticamente sulla strategia del partner. Proponiamo un modello che cattura tutte e tre le caratteristiche e dimostra la loro importanza nel catturare il comportamento umano su un nuovo set di dati orientati agli obiettivi che abbiamo raccolto utilizzando il crowdsourcing.</abstract_it>
      <abstract_ml>സാധാരണ ഭാഷയുടെ കളികള്‍ ഞങ്ങള്‍ പഠിക്കുന്നു. അതില്‍ രണ്ടു കളിക്കുന്നവര്‍, ഓരോരുത്തരും സ്വകാര്യ വിവരങ്ങള്‍ കൊണ്ട്, ഒരു സാ ഇങ്ങനെയുള്ള കളികളില്‍, പങ്കാളിയുടെ സ്വകാര്യ വിവരങ്ങള്‍ പങ്കാളിയുടെ സ്വകാര്യ വിവരങ്ങളില്‍ നിന്നും വിജയിച്ച ഒരു കളിക്കാരന്‍ (ഞാന്‍) കുറച്ചു വിവരങ്ങള്‍ ഉണ മൂന്നു വ്യക്തിത്വങ്ങളെയും പിടികൂടുകയും, മനുഷ്യരുടെ പ്രധാനപ്രകൃതിയെ പിടികൂടുകയും ചെയ്യുന്ന ഒരു പുതിയ ലക്ഷ്യത്തിലുള്ള ഡാറ്റാസറ്</abstract_ml>
      <abstract_lt>Mokome eilinius kalbų žaidimus, kuriuose du žaidėjai, kiekvienas su privačia informacija, bendrauja siekdami bendro tikslo. Tokiuose žaidimuose s ėkmingas žaidėjas turi i) i š partnerio pranešimų ištraukti privačią informaciją, ii) sukurti pranešimus, kurie labiausiai padėtų pasiekti tikslą, ir iii) pragmatiškai pagrįsti partnerio strategiją. Siūlome model į, kuriame apibūdinamos visos trys charakteristikos ir parodoma jų svarba capturuojant žmogaus elgesį naujoje tiksliniame duomenų rinkinyje, kurį surinkėme naudojant visuomenės išteklius.</abstract_lt>
      <abstract_mt>Aħna nistudjaw logħob lingwistiku sekwenzjali li fih żewġ parteċipanti, kull wieħed b’informazzjoni privata, jikkomunikaw biex jinkiseb għan komuni. F’logħob bħal dan, attur ta’ suċċess irid (i) jikkonkludi l-informazzjoni privata tas-sieħeb mill-messaġġi tas-sieħeb, (ii) jiġġenera messaġġi li x’aktarx jgħinu fil-kisba tal-għan, u (iii) jirrakkomanda b’mod pragmatiku dwar l-istrateġija tas-sieħeb. Aħna nipproponu mudell li jaqbad it-tliet karatteristiċi kollha u juri l-importanza tagħhom fil-qbid tal-imġiba umana fuq sett ġdid ta' dejta orjentat lejn il-miri li nġabru bl-użu tal-crowdsourcing.</abstract_mt>
      <abstract_no>Vi studerer sekvensiske språksspel der to spelarar, kvar med privat informasjon, kommuniserer til å oppnå eit felles mål. I slike spelar må ein vellykkeleg spelar (i) oppgje partnerens privat informasjon frå partnerens meldingar, (ii) laga meldingar som mest sannsynlegvis vil hjelpa med målet, og (iii) grunn pragmatisk om partnerens strategi. Vi foreslår eit modell som får alle tre karakteristikk og demonstrerer deres viktighet for å henta menneskelige oppførsel på eit ny målsorientert dataset vi samla med crowdsourcing.</abstract_no>
      <abstract_ms>We study sequential language games in which two players, each with private information, communicate to achieve a common goal.  Dalam permainan tersebut, pemain berjaya mesti (i) menyimpulkan maklumat peribadi rakan kongsi dari mesej rakan kongsi, (ii) menghasilkan mesej yang paling mungkin membantu dengan tujuan, dan (iii) alasan secara pragmatis mengenai strategi rakan kongsi. We propose a model that captures all three characteristics and demonstrate their importance in capturing human behavior on a new goal-oriented dataset we collected using crowdsourcing.</abstract_ms>
      <abstract_mk>Ние студираме секвенцијални јазички игри во кои двајца играчи, секој со приватна информација, комуницираат за да постигнат заедничка цел. Во ваквите игри успешниот играч мора (i) да ги инферира приватните информации на партнерот од пораките на партнерот, (ii) да генерира пораки кои најверојатно ќе помогнат во остварувањето на целта и (iii) да прифати прагматично за стратегијата на партнерот. We propose a model that captures all three characteristics and demonstrate their importance in capturing human behavior on a new goal-oriented dataset we collected using crowdsourcing.</abstract_mk>
      <abstract_pl>Badamy sekwencyjne gry językowe, w których dwóch graczy, każdy z prywatnymi informacjami, komunikuje się w celu osiągnięcia wspólnego celu. W takich grach gracz musi (i) wywnioskować prywatne informacje partnera z wiadomości partnera, (ii) generować wiadomości, które najprawdopodobniej pomogą w osiągnięciu celu, oraz (iii) pragmatycznie rozumieć strategię partnera. Proponujemy model, który uwzględnia wszystkie trzy cechy i demonstruje ich znaczenie w rejestrowaniu zachowań człowieka na nowym zbiorze danych, który zebraliśmy za pomocą crowdsourcingu.</abstract_pl>
      <abstract_sr>Proučavamo sekvenčne jezičke igre u kojima su dva igrača, svaka sa privatnim informacijama, komunicirala kako bi postigla zajednički cilj. U takvim igrama uspešan igrač mora i) uvesti privatne informacije partner a iz poruke partnera, ii) proizvesti poruke koje će najverovatnije pomoći cilju, i iii) razlog pragmatično o strategiji partnera. Predlažemo model koji uključuje sve tri karakteristike i pokazuje njihovu važnost u hvatanju ljudskog ponašanja na novi set podataka na cilju orijentiranog cilja koji smo sakupili koristeći crowdsourcing.</abstract_sr>
      <abstract_mn>Бид хоёр тоглогч, хувийн мэдээлэл, нийтлэг зорилго хүртэл холбоотой хэлний тоглоомуудыг судалдаг. Ийм тоглоомонд амжилттай тоглогч (i) хамтрагчдын хувийн мэдээллийг хамтрагчдын хамтрагчдын хувийн мэдээллээс илгээх хэрэгтэй, (ii) зорилготой хамгийн их туслах захирагдал гаргах хэрэгтэй, мөн (iii) хамтрагчдын стратегийнхаа талаар прагмат Бид гурван чанарыг барьж, хүн төрөлхтний үйл явцыг шинэ зорилготой өгөгдлийн санд цуглуулсан шинэ зорилготой өгөгдлийн сангийн чухал зүйлийг илэрхийлдэг загварыг сануулдаг.</abstract_mn>
      <abstract_ro>Studiem jocuri lingvistice secvențiale în care doi jucători, fiecare cu informații private, comunică pentru a atinge un obiectiv comun. În astfel de jocuri, un jucător de succes trebuie (i) să deducă informațiile private ale partenerului din mesajele partenerului, (ii) să genereze mesaje care sunt cel mai probabil să ajute la atingerea obiectivului și (iii) să raționeze pragmatic despre strategia partenerului. Propunem un model care surprinde toate cele trei caracteristici și demonstrează importanța acestora în captarea comportamentului uman pe un nou set de date orientat spre obiective pe care l-am colectat folosind crowdsourcing.</abstract_ro>
      <abstract_si>අපි පස්සේ භාෂාව සෙල්ලම් අධ්‍යානය කරනවා කියලා, සෙල්ලම් දෙකක්, හැමෝම පෞද්ගලික තොරතුරු සමග, සමා අනිවාර්ය සෙල්ලම් වලින්, සාමාන්‍ය සෙල්ලම් ක්‍රියාකරුවෙක් (i) සහයෝගිකයාගේ පුද්ගලික තොරතුරු පණිවිඩයෙන් පණිවිඩය සඳහා සහයෝගිකයාගේ ප අපි ප්‍රශ්නයක් කරනවා මොඩේල් එකක් සම්පූර්ණයෙන් සියළුම් තුනක් අල්ලගන්න සහ ඔවුන්ගේ වැදගත් ප්‍රශ්නයක් පෙන්වන්න</abstract_si>
      <abstract_ta>நாங்கள் பின்வரும் மொழி விளையாட்டுகளை படிக்கிறோம். அதில் இரண்டு விளையாட்டாளர்கள் ஒவ்வொரு தனிப்பட்ட தகவலுடன், ஒரு  இத்தகைய விளையாட்டுகளில், வெற்றிகரமான விளையாட்டாளர் (நான்) பங்குதாளியின் தனியார்ந்த தகவல்களை குறைக்க வேண்டும், i i) கூட்டாளியின் திட்டத்தை பற்றி உதவு நாம் அனைத்து மூன்று சிறப்புகளையும் பிடித்து அவர்களுடைய முக்கியத்தைக் காண்பிக்கிறோம் என்று ஒரு மாதிரி நாம் மக்கள் மூலம் சேகரித்து</abstract_ta>
      <abstract_so>Waxaynu baranaynaa ciyaaraha luqada dabadeed, kuwaas oo ay labada ciyaareer, mid kasta oo macluumaad gaar ah ku leeyihiin, si ay u gaadhaan goal caadiga ah. Ciyaaradaas waxaa waajib ah in qofka liibaanaya (i) uu macluumaadka saaxiibka ee lammaanaha ka dhigo warqada lammaanaha, (ii) uu sameeyo macluumaad aad u suurtowda inuu caawiyo goalka iyo sababta si caqli ah oo ku saabsan qoraalka lammaanaha. We propose a model that captures all three characteristics and demonstrate their importance in capturing human behavior on a new goal-oriented dataset we collected using crowdsourcing.</abstract_so>
      <abstract_sv>Vi studerar sekventiella språkspel där två spelare, var och en med privat information, kommunicerar för att uppnå ett gemensamt mål. I sådana spel måste en framgångsrik spelare (i) härleda partnerns privata information från partnerns meddelanden, (ii) generera meddelanden som är mest sannolikt att hjälpa till med målet, och (iii) resonera pragmatiskt om partnerns strategi. Vi föreslår en modell som fångar alla tre egenskaper och visar deras betydelse för att fånga mänskligt beteende på en ny målinriktad datauppsättning som vi samlat in med hjälp av crowdsourcing.</abstract_sv>
      <abstract_ur>ہم سفارشی زبان کھیلیں پڑھتے ہیں جن میں دو کھیلنے والے، ہر ایک شخصی معلومات کے ساتھ، ایک مشترک هدف پہنچانے کے لئے ارتباط کرتے ہیں. اس طرح کی کھیل میں ایک موفق کھیلنے والے کو (i) شریکوں کے پیغامات سے شریکوں کی خصوصی معلومات کے ذریعہ سے آزاد کرنا چاہیے, (ii) پیغامات پیدا کرنا چاہیے جو سب سے زیادہ موقع کے ساتھ مدد کریں، اور (iii) دلیل اس شریکوں کی استراتژی کے بارے میں اخلاق کر ہم ایک موڈل کو پیشنهاد کرتے ہیں جو تمام تین ویژگی کو پکڑتا ہے اور لوگوں کی رفتار کو نئی موقع کی طرف متوجہ کرنے کے لئے ان کی اثری دکھاتے ہیں جنہیں ہم جمع کررہے ہیں۔</abstract_ur>
      <abstract_uz>Biz keyingi tillar oʻyinlarini o'rganamiz. Bu yerda ikkita oddiy o'yinchalar, har biri shaxsiy maʼlumot bilan, bir umumiy maqsadni bajarish uchun xabar qilamiz. Bu yerda muvaffaqiyatli oʻyinlar bilan bogʻliq xabarlaridan boshqa maʼlumotni yaratishi kerak, (i i) muhit bo'lgan xabarlarni yaratish mumkin, va (iim) bogʻliq strategiya haqida foydalanishi mumkin. Biz hamma uchta hususiyatni qabul qiladigan modelni tahlil qilamiz va biz jamoatlar yordamida qo'yilgan yangi maqola asosiy maʼlumot tarkibini olish uchun ularning muhimligini ko'rsatamiz.</abstract_uz>
      <abstract_vi>Chúng tôi học các trận ngôn ngữ nối tiếp trong đó hai cầu thủ, mỗi người có thông tin riêng, giao tiếp để đạt được mục tiêu chung. Trong những trò chơi như vậy, một cầu thủ thành công phải (i) ra kết luận thông tin cá nhân của đối tác từ thông đi ệp của đối tác (i) tạo ra thông điệp có khả năng giúp ích cho mục tiêu, và (v) thực dụng về chiến lược của đối tác. Chúng tôi đề xuất một mô hình nắm bắt cả ba đặc điểm và thể hiện tầm quan trọng của họ trong việc bắt giữ hành vi con người trên một bộ dữ liệu hướng mục tiêu mới chúng tôi thu thập bằng cách dùng crodsouring.</abstract_vi>
      <abstract_hr>Proučavamo sekvenčne jezičke igre u kojima su dva igrača, svaka s privatnim informacijama, komunicirana kako bi postigla zajednički cilj. U takvim igrama uspješan igrač mora i) uvjeriti privatne informacije partner a iz poruka partnera, ii) proizvesti poruke koje će najvjerojatnije pomoći cilju, i iii) razlog pragmatično o strategiji partnera. Predlažemo model koji uključuje sve tri karakteristike i pokazuje njihovu važnost u hvatanju ljudskog ponašanja na novoj skupini podataka na cilju koje smo skupili koristeći crowdsourcing.</abstract_hr>
      <abstract_bg>Изучаваме последователни езикови игри, в които двама играчи, всеки с лична информация, общуват за постигане на обща цел. В такива игри успешният играч трябва (i) да извлече личната информация на партньора от съобщенията на партньора, (ii) да генерира съобщения, които най-вероятно ще помогнат за целта и (iii) да разсъждава прагматично за стратегията на партньора. Предлагаме модел, който улавя и трите характеристики и демонстрира тяхното значение при улавянето на човешкото поведение на нов целенасочен набор от данни, събрани с помощта на crowdsourcing.</abstract_bg>
      <abstract_de>Wir studieren sequentielle Sprachspiele, in denen zwei Spieler, jeweils mit privaten Informationen, kommunizieren, um ein gemeinsames Ziel zu erreichen. In solchen Spielen muss ein erfolgreicher Spieler (i) die privaten Informationen des Partners aus den Nachrichten des Partners ableiten, (ii) Nachrichten generieren, die am wahrscheinlichsten zum Ziel beitragen, und (iii) pragmatisch über die Strategie des Partners nachdenken. Wir schlagen ein Modell vor, das alle drei Merkmale erfasst und deren Bedeutung für die Erfassung menschlichen Verhaltens anhand eines neuen zielorientierten Datensatzes demonstriert, den wir mithilfe von Crowdsourcing gesammelt haben.</abstract_de>
      <abstract_da>Vi studerer sekventielle sprogspil, hvor to spillere, hver med private oplysninger, kommunikerer for at nå et fælles mål. I sådanne spil skal en succesfuld spiller (i) udlede partnerens private oplysninger fra partnerens meddelelser, (ii) generere meddelelser, der er mest sandsynlige for at hjælpe med målet, og (iii) begrunde pragmatisk om partnerens strategi. Vi foreslår en model, der indfanger alle tre karakteristika og demonstrerer deres betydning for at fange menneskelig adfærd på et nyt målorienteret datasæt, vi indsamlede ved hjælp af crowdsourcing.</abstract_da>
      <abstract_nl>We bestuderen opeenvolgende taalspellen waarin twee spelers, elk met privé informatie, communiceren om een gemeenschappelijk doel te bereiken. In dergelijke spellen moet een succesvolle speler (i) de persoonlijke informatie van de partner afleiden uit de berichten van de partner, (ii) berichten genereren die waarschijnlijk helpen met het doel, en (iii) pragmatisch redeneren over de strategie van de partner. We stellen een model voor dat alle drie de kenmerken vastlegt en hun belang aantoont bij het vastleggen van menselijk gedrag op een nieuwe doelgerichte dataset die we hebben verzameld met behulp van crowdsourcing.</abstract_nl>
      <abstract_fa>ما بازی‌های زبان‌های تعریف را مطالعه می‌کنیم که در آن دو بازیکن، هر یک با اطلاعات خصوصی، برای رسیدن هدف مشترک ارتباط می‌دهد. در این بازی، یک بازیکن موفق باید (i) اطلاعات خصوصی شریکی را از پیغام‌های شریکی آزاد کند, (ii) پیغام‌هایی را که احتمالاً به هدف کمک می‌کنند تولید کند، و (iii) دلیل پراگنماتی در مورد استراتژی شریکی است. ما یک مدل پیشنهاد می‌دهیم که همه سه ویژگی را گرفته و مهم آن را در دستگیر رفتار انسان در مجموعه‌ی داده‌های جدیدی که با استفاده از سرمایه‌گذاری گروهی جمع کرده‌ایم نشان می‌دهد.</abstract_fa>
      <abstract_id>Kami mempelajari permainan bahasa sekuensial di mana dua pemain, masing-masing dengan informasi pribadi, berkomunikasi untuk mencapai tujuan umum. Dalam permainan tersebut, pemain sukses harus (i) menyimpulkan informasi pribadi partnernya dari pesan partnernya, (ii) menghasilkan pesan yang paling mungkin membantu dengan tujuan, dan (iii) alasan pragmatis tentang strategi partnernya. Kami mengusulkan model yang menangkap tiga karakteristik dan menunjukkan kepentingan mereka dalam menangkap perilaku manusia pada set data yang baru orientasi tujuan yang kami kumpulkan menggunakan crowdsourcing.</abstract_id>
      <abstract_tr>Biz indiki dil oýunlarynda iki oýunçy, her biri hyzykly maglumat bilen, bir maksady başarmak üçin habarlaşýarys. Şol ýaly oýunlarda başarnykly oýunçy (i) ortaklygyň pesinden a ýratyn maglumatyny ortaklygyň mesajlaryndan alyp gitmeli, (ii) maksada kömek edip bilen mesajlary döretmeli, we (iii) ortaklygyň strategiýasy barada pragmatik sebäbi. Biz ähli üç özellikleri taýýarlap, adamlaryň davranışyny ýakynlamak üçin täze maksadyň üstünde toplanýan veri setirini maslahat berýäris.</abstract_tr>
      <abstract_af>Ons studeer sekwensielle taal speletjies waarin twee spelers, elkeen met privaat inligting, kommuniseer om 'n algemene doel te bereik. In sodanige speletjies moet 'n suksesvolle speler (i) die partner se privaat inligting van die partner se boodskappe inligting (ii) genereer boodskappe wat mees waarskynlik i s om te hulp met die doel, en (iii) rede pragmatisk oor die partner se strategie. Ons voorstel 'n model wat al drie karakteristieke opneem en hulle belangrikheid vertoon in die opneem van menslike gedrag op 'n nuwe doel-orienteerde datastel wat ons versamel het deur die gebruik van skarpsourcing.</abstract_af>
      <abstract_ko>우리는 연속 언어 게임을 연구하는데 그 중에서 두 명의 유저가 모두 개인 정보를 가지고 교류하여 하나의 공통된 목표를 실현한다.이런 게임에서 성공한 유저는 반드시 (i) 파트너의 정보에서 파트너의 개인 정보를 추정하고 (ii) 목표 실현에 가장 도움이 될 수 있는 정보를 생성하며 (iii) 파트너의 전략을 실용적으로 생각해야 한다.우리는 이 모델이 모든 세 가지 특징을 포착하고 우리가 패키지로 수집한 새로운 목표를 향한 데이터 집합에서 인류 행위를 포착하는 데 있어서의 중요성을 보여 주는 모델을 제시했다.</abstract_ko>
      <abstract_am>በኋላው የቋንቋ ጨዋታዎች እናስተምራለን፣ በዚህም ውስጥ ሁለቱ አጫዋቾች የግል ጉዳይ ለማግኘት የግል መረጃዎች ይኖራሉ፡፡ እንደዚህ በጨዋታ ውስጥ አግኝቷል (እኔ) የባልንጀራው የግል መረጃዎችን ከመልእክት (i i) ያሳስፋል፡፡ የሦስት ባሕላዊ ሁሉ እንዲያዝዝ እና የሰውን ድርጊት በአዲስ አዲስ አዲስ አዲስ አዲስ አዲስ የዳታ ማዕከል በመያሰብሰብን እናሳውቃለን፡፡</abstract_am>
      <abstract_az>İki oyuncu, hər biri kişilik məlumatları ilə birlikdə ortaq bir məqsəd yetirmək üçün müvəffəq dil oyunlarını təhsil edirik. Bütün oyunlarda, müvəffəqiyyətli oyuncu (i) ortağının məktublarından xüsusi məlumatlarını daxil etməlidir, (ii) məqsədilə kömək edə biləcək məlumatları yaratmalı və (iii) ortağının stratejisi haqqında pragmatik olaraq s əbəb verməlidir. Biz bütün üç xüsusiyyətləri tutan və insanların davranışlarını yeni məqsədilə təşkil etdiyimiz məlumatları ilə birlikdə topladığımız yeni məlumatlardan tutan bir modeli təklif edirik.</abstract_az>
      <abstract_hy>Մենք ուսումնասիրում ենք լեզվային խաղեր, որտեղ երկու խաղացողներ, յուրաքանչյուրը մասնավոր ինֆորմացիայի հետ, հաղորդակցվում են ընդհանուր նպատակի հասնելու համար: Այսպիսի խաղերում հաջողակ խաղացողը պետք է i) հանի գործընկերի մասնավոր տեղեկատվությունը գործընկերի հաղորդագրություններից, երկու) ստեղծի հաղորդագրություններ, որոնք ամենահավանականությամբ օգնեն նպատակի իրականացման համար, և երկրորդ խաղացողը պրաgmaտիկ պատճառ է տալիս գործ Մենք առաջարկում ենք մի մոդել, որը ներառում է բոլոր երեք հատկանիշները և ցույց է տալիս նրանց կարևորությունը մարդկային վարքագիծը գրավելու համար նոր նպատակային տվյալների համակարգի վրա, որը մենք հավաքեցինք օգտագործելով ժողովրդավարություն:</abstract_hy>
      <abstract_sw>Tunafundisha michezo ya lugha za baadae ambapo wachezaji wawili, kila mmoja kwa taarifa binafsi, huwasiliana ili kupata lengo la kawaida. Katika mchezo huu, mchezaji mwenye mafanikio ni lazima (mimi) nipunguze taarifa binafsi za mshirika huyo kutoka kwenye ujumbe wa washirika wake, (i i) kutengeneza ujumbe ambao una uwezekano mkubwa wa kusaidia lengo hilo, na (iii) sababu ya msingi kuhusu mkakati wa mshirika huyo. Tunazipendekeza mfano ambao unakamata sifa zote tatu na kuonyesha umuhimu wao katika kuchukua tabia za binadamu kwenye seti mpya ya taarifa tulizokusanya kwa kutumia vyanzo vya umma.</abstract_sw>
      <abstract_bn>আমরা পরবর্তী ভাষার খেলা পড়ি যেখানে দুই খেলোয়াড়, প্রত্যেকেই ব্যক্তিগত তথ্য দিয়ে সাধারণ লক্ষ্য অর্জনের জন্য যোগায এই ধরনের খেলায় একজন সফল খেলোয়াড়ক অবশ্যই (আমি) অংশীদারের বার্তা থেকে প্রাইভেট তথ্য কমিয়ে দিতে হবে (i i) বার্তা তৈরি করতে হবে যারা সম্ভবত লক্ষ্যের সাহায্য করতে পারে এব আমরা একটি মডেল প্রস্তাব করছি যা সব তিনটি চরিত্র ধরে রাখে এবং তাদের গুরুত্বপূর্ণ প্রদর্শন করে একটি নতুন লক্ষ্যের দিকে মানুষের আচরণ গুরুত্ব প্রদান কর</abstract_bn>
      <abstract_ca>Estudem jocs de llenguatge seqüencials en els quals dos jugadors, cada un amb informació privada, es comunican per aconseguir un objectiu comú. En aquests jocs, un jugador exitós ha de (i) deduir la informació privada de la parella dels missatges de la parella, (ii) generar missatges que més probablement ajudin a l'objectiu, i (iii) raonar pragmàticament sobre l'estratègia de la parella. Proposem un model que capture les tres característiques i demostre la seva importància en capturar el comportament humà en un nou conjunt de dades orientats als objectius que vam recollir fent servir crowdsourcing.</abstract_ca>
      <abstract_sq>Ne studiojmë lojra gjuhësore sekuencuese në të cilat dy lojtarë, secili me informacion privat, komunikojnë për të arritur një qëllim të përbashkët. Në lojra të tilla, një lojtar i suksesshëm duhet (i) të përfundojë informacioni privat i partnerit nga mesazhet e partnerit, (ii) të gjenerojë mesazhe që ka më shumë gjasa të ndihmojnë me qëllimin dhe (iii) të arsyetojë pragmatikisht rreth strategjisë s ë partnerit. Ne propozojmë një model që kapë të tre karakteristikat dhe demonstron rëndësinë e tyre në kapjen e sjelljes njerëzore në një grup të ri të dhënash të orientuar në qëllim që mbledhëm duke përdorur crowdsourcing.</abstract_sq>
      <abstract_fi>Tutkimme peräkkäisiä kielipelejä, joissa kaksi pelaajaa, joilla on yksityinen tieto, kommunikoivat yhteisen tavoitteen saavuttamiseksi. Tällaisissa peleissä menestyvän pelaajan on (i) pääteltävä kumppanin yksityiset tiedot kumppanin viesteistä, (ii) luotava viestejä, jotka todennäköisesti auttavat tavoitteessa, ja (iii) perusteltava pragmaattisesti kumppanin strategiaa. Ehdotamme mallia, joka tallentaa kaikki kolme ominaisuutta ja osoittaa niiden merkityksen ihmisten käyttäytymisen kuvaamisessa uudella tavoitteellisella aineistolla, jonka keräsimme joukkoistamme.</abstract_fi>
      <abstract_et>Me uurime järjestikuseid keelemänge, kus kaks mängijat, igaüks isikliku teabega, suhtlevad ühise eesmärgi saavutamiseks. Sellistes mängudes peab edukas mängija (i) partneri isikliku teabe järeldama partneri sõnumitest, (ii) looma sõnumeid, mis tõenäoliselt aitavad eesmärki saavutada, ja (iii) mõtlema pragmaatiliselt partneri strateegia üle. Pakume välja mudeli, mis kajastab kõik kolm omadust ja näitab nende tähtsust inimeste käitumise jäädvustamisel uue eesmärgile orienteeritud andmekogumi abil, mille kogusime.</abstract_et>
      <abstract_cs>Studujeme sekvenční jazykové hry, ve kterých dva hráči, každý s osobními informacemi, komunikují za účelem dosažení společného cíle. V takových hrách musí úspěšný hráč (i) odvodit soukromé informace partnera ze zpráv partnera, (ii) generovat zprávy, které s největší pravděpodobností pomohou s cílem, a (iii) pragmaticky uvažovat o strategii partnera. Navrhujeme model, který zachycuje všechny tři charakteristiky a demonstruje jejich důležitost pro zachycení lidského chování na nové cílově orientované datové sadě shromážděné pomocí crowdsourcingu.</abstract_cs>
      <abstract_bs>Proučavamo sekvenčne jezičke igre u kojima su dva igrača, svaka sa privatnim informacijama, komunicirala kako bi postigla zajednički cilj. U takvim igrama uspješan igrač mora i) donijeti privatne informacije partner a iz poruka partnera, ii) proizvesti poruke koje će najvjerojatnije pomoći cilju, i iii) razlog pragmatično o strategiji partnera. Predlažemo model koji uključuje sve tri karakteristike i pokazuje njihovu važnost u hvatanju ljudskog ponašanja na novoj grupi podataka orijentiranoj cilju koju smo sakupili koristeći crowdsourcing.</abstract_bs>
      <abstract_jv>Awak dhéwé milih dolanan langgar sewenih kanggo kelas telu, sampeyan karo informasi pribadi, komunikasi kanggo ngerasakno iki dadi sing dirampakan. Nang halaman dolanan sing mengko, sing kelompok kudu Awak dhéwé ngerasah model sing katora tanggal saben telu cara-saben ngono ngono hasil nêmên langkung nggawe barang dumadhi kuwi nggawe dataset sing gawe ngubah perusahaan bukané sing ujaran</abstract_jv>
      <abstract_he>אנחנו לומדים משחקי שפה רצופיים שבהם שני שחקנים, כל אחד עם מידע פרטי, מתקשרים כדי להשיג מטרה משותפת. במשחקים כאלה, שחקן מוצלח חייב (i) להוציא את המידע הפרטי של השותף מההודעות של השותף, (ii) ליצור הודעות שהסביר ביותר לעזור עם המטרה, ולiii) לסיבה פרגמטית על האסטרטגיה של השותף. אנחנו מציעים מודל שמכיל את שלושת האופיינים והוכיח את חשיבותיהם בלתפוס התנהגות האנושית על קבוצת נתונים חדשה שמיועד למטרה שאספנו בשימוש במקורי קהל.</abstract_he>
      <abstract_sk>Proučujemo zaporedne jezikovne igre, v katerih dva igralca, vsak z zasebnimi informacijami, komunicirata za dosego skupnega cilja. V takih igrah mora uspešen igralec (i) iz sporočil partnerja sklepati zasebne informacije, (ii) ustvariti sporočila, ki bodo najverjetneje pomagala pri doseganju cilja, in (iii) pragmatično razumeti partnerjevo strategijo. Predlagamo model, ki zajema vse tri značilnosti in dokazuje njihov pomen pri zajemanju človeškega vedenja na novem ciljno usmerjenem naboru podatkov, ki smo jih zbrali s pomočjo množičnega sourcinga.</abstract_sk>
      <abstract_ha>Tuna karanta games na harshe na dabam, a cikinsa mãsu player biyu ne, dukansu da masana ɗabi'a, sunã yin wasiyya dõmin su isa wani goal da ke daidaita. Daga gamuwa daga wannan, mai cin nasara ya kamata (s a i ni) in ƙara bayan bayan tsarin abõkan tarayya daga manzancin partneren aiki, (ii) ya ƙãga iyar da manzannin mafiya yinin su ƙara da amfani da goan, da kuma (3) saba mai fassarar bayan zartar da kimar abõkan tarayya. Tune bukãtar da wani misali wanda ke kãma duk takardar uku kuma ke nuna muhimu a kãma aikin mutum a kan wani danne-danne masu sãɓa da goani da muka samu da amfani da umarni.</abstract_ha>
      <abstract_bo>ང་ཚོས་རྗེས་སུ་འབྱུང་བའི་སྐད་རིགས་ཀྱི་རྩེདམོ་གཉིས་ཀྱིས་གཏོང་བྱེད་ཀྱི་ཡོད། འདི་ལྟ་བུའི་རྩེད་མོ་ཞིག་གིས་མཐུན་པའི་མི་འཕྲིན་ཡིག ང་ཚོས་མིགཟུགས་གསུམ་ཀྱི་ཁྱད་ཆོས་རྗེས་སུ་ཡོད་པའི་མིགཟུགས</abstract_bo>
      </paper>
    <paper id="38">
      <title>Probabilistic Verb Selection for Data-to-Text Generation</title>
      <author><first>Dell</first><last>Zhang</last></author>
      <author><first>Jiahao</first><last>Yuan</last></author>
      <author><first>Xiaoling</first><last>Wang</last></author>
      <author><first>Adam</first><last>Foster</last></author>
      <doi>10.1162/tacl_a_00038</doi>
      <abstract>In data-to-text Natural Language Generation (NLG) systems, computers need to find the right words to describe phenomena seen in the data. This paper focuses on the problem of choosing appropriate verbs to express the direction and magnitude of a percentage change (e.g., in stock prices). Rather than simply using the same verbs again and again, we present a principled data-driven approach to this problem based on Shannon’s noisy-channel model so as to bring variation and naturalness into the generated text. Our experiments on three large-scale real-world news corpora demonstrate that the proposed probabilistic model can be learned to accurately imitate human authors’ pattern of usage around verbs, outperforming the state-of-the-art method significantly.</abstract>
      <pages>511–527</pages>
      <video href="https://vimeo.com/385504366" permission="false" />
      <url hash="884435ee">Q18-1038</url>
      <bibkey>zhang-etal-2018-probabilistic</bibkey>
    <title_ar>اختيار الفعل الاحتمالي لتوليد البيانات إلى نص</title_ar>
      <title_pt>Seleção de verbo probabilístico para geração de dados para texto</title_pt>
      <title_fr>Sélection probabiliste de verbes pour la génération de données en texte</title_fr>
      <title_es>Selección probabilística de verbos para la generación de datos a texto</title_es>
      <title_ja>データからテキストへの生成のための確率的動詞選択</title_ja>
      <title_ru>Вероятностный выбор глагола для генерации данных в текст</title_ru>
      <title_zh>以数至文本生成者概率谓词择</title_zh>
      <title_hi>डेटा-टू-टेक्स्ट जनरेशन के लिए संभाव्य क्रिया चयन</title_hi>
      <title_ga>Roghnú Briathra Dóchúla le haghaidh Giniúint Sonraí go Téacs</title_ga>
      <title_ka>მონაცემების ტექსტის შექმნის შესაძლებლობითი გერბის არჩევა</title_ka>
      <title_hu>Valószínűsíthető igék kijelölése adat-szöveg generáláshoz</title_hu>
      <title_el>Πιθαντική επιλογή ρήμων για δημιουργία δεδομένων σε κείμενο</title_el>
      <title_it>Selezione probabilistica dei verbi per la generazione dati-testo</title_it>
      <title_lt>Tikėtinas žodžio pasirinkimas, skirtas duomenų į tekstą kūrimui</title_lt>
      <title_mk>Веројатно избор на реченици за генерација на податоци во текст</title_mk>
      <title_kk>Деректерден мәтінді құру үшін мүмкіндік тірб таңдауы</title_kk>
      <title_ms>Pemilihan Verb Kemungkinan untuk Jenerasi Data-ke-Teks</title_ms>
      <title_mt>Għażla Probabilistika tal-Verbi għall-Ġenerazzjoni tad-Dejta għat-Test</title_mt>
      <title_ml>വേര്‍ബ് തെരഞ്ഞെടുക്കുക</title_ml>
      <title_mn>Магадгүй өгөгдлийн болон текст үүсгэх</title_mn>
      <title_no>Val av sannsynleg verb for generering av data- til- tekst</title_no>
      <title_pl>Prawdopodobny wybór czasowników do generowania danych na tekst</title_pl>
      <title_ro>Selecția probabilistică a verbelor pentru generarea de date în text</title_ro>
      <title_si>Data- to- Text නිර්මාණය සඳහා සංභාවිත වර්බ් තෝරණය</title_si>
      <title_sr>Verovatno izbor verba za generaciju podataka na tekst</title_sr>
      <title_sv>Probabilistisk verbmarkering för data-till-text generering</title_sv>
      <title_ta>தரவு உரை உருவாக்கத்திற்கான சாத்தியமான பதிப்பு தேர்வு</title_ta>
      <title_so>Dalbashada warqada ah ee macluumaadka-ilaa-Text Generation</title_so>
      <title_ur>Data- to- Text Generation کے لئے احتمال ورب انتخاب</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Xác định phần chọn kết nối cho máy tạo dữ liệu sang văn bản</title_vi>
      <title_bg>Вероятен избор на глагол за генериране на данни в текст</title_bg>
      <title_hr>Vjerojatno izbor verbi za generaciju podataka do teksta</title_hr>
      <title_nl>Probabilistische woordenselectie voor het genereren van gegevens naar tekst</title_nl>
      <title_de>Wahrscheinliche Verbenauswahl für die Daten-zu-Text-Generierung</title_de>
      <title_fa>انتخاب احتمالات کلید برای تولید داده به متن</title_fa>
      <title_ko>데이터에서 텍스트로 생성되는 확률 동사 선택</title_ko>
      <title_da>Sandsynligt verbvalg for data- til- tekst- generering</title_da>
      <title_tr>Verb Metin Däpliginiň ehtimali Verb Saýlaw</title_tr>
      <title_sq>Zgjidhja e Zgjidhjes së Fjalëve për Gjenerimin e të dhënave në Tekst</title_sq>
      <title_id>Pemilihan Verb Kemungkinan untuk Generasi Data-ke-Teks</title_id>
      <title_sw>Probabilistic Verb Selection for Data-to-Text Generation</title_sw>
      <title_hy>Տեղեկատվության տեքստի ստեղծման համար հավանական բայերի ընտրությունը</title_hy>
      <title_af>Waarskynlik Verb Keuse vir Data- to- Text Generasie</title_af>
      <title_am>ምርጫ አጥፉ</title_am>
      <title_bs>Vjerojatno izbor verbi za generaciju podataka do teksta</title_bs>
      <title_ca>Selecció probable de verbs per a generar dades a text</title_ca>
      <title_az>Veri-t톛-Metin Yenilm톛si 칲칞칲n m칲mk칲n Verb Se칞imi</title_az>
      <title_cs>Pravděpodobný výběr slovesa pro generování dat na text</title_cs>
      <title_bn>তথ্য থেকে টেক্সট প্রজন্মের জন্য সম্ভবত ভার্ব নির্বাচন</title_bn>
      <title_et>Tõenäoline sõnade valik andmete tekstiks genereerimiseks</title_et>
      <title_fi>Todennäköinen verbivalinta datasta tekstiin -luontia varten</title_fi>
      <title_jv>Verb sing dipilelo kanggo data-to-text Generation</title_jv>
      <title_he>בחירת מילים סבירה לייצור מידע לטקסט</title_he>
      <title_ha>@ item Text character set</title_ha>
      <title_sk>Verjetnostni izbor glagolov za ustvarjanje podatkov v besedilo</title_sk>
      <title_bo>ཆེད་མཁན་གྱི་ཆ་འཕྲིན་ལ་ཡིག་ཆ་སྐྱེལ་པར་བྱ་རིམ་གདམ་པ</title_bo>
      <abstract_ar>في أنظمة توليد اللغة الطبيعية (NLG) لتحويل البيانات إلى نص ، تحتاج أجهزة الكمبيوتر إلى العثور على الكلمات الصحيحة لوصف الظواهر التي تظهر في البيانات. تركز هذه الورقة على مشكلة اختيار الأفعال المناسبة للتعبير عن اتجاه وحجم النسبة المئوية للتغير (على سبيل المثال ، في أسعار الأسهم). بدلاً من مجرد استخدام نفس الأفعال مرارًا وتكرارًا ، نقدم نهجًا مبدئيًا قائمًا على البيانات لهذه المشكلة استنادًا إلى نموذج قناة شانون الصاخبة لإضفاء التباين والطبيعية على النص الذي تم إنشاؤه. تُظهر تجاربنا على ثلاث مؤسسات إخبارية واسعة النطاق في العالم الحقيقي أنه يمكن تعلم النموذج الاحتمالي المقترح لتقليد نمط استخدام المؤلفين البشريين حول الأفعال بدقة ، متفوقًا بشكل كبير على أحدث الأساليب.</abstract_ar>
      <abstract_fr>Dans les systèmes de génération de langage naturel (GNL) de données en texte, les ordinateurs doivent trouver les bons mots pour décrire les phénomènes observés dans les données. Cet article se concentre sur le problème du choix des verbes appropriés pour exprimer la direction et l'ampleur d'une variation en pourcentage (par exemple, dans les cours des actions). Plutôt que de simplement utiliser les mêmes verbes encore et encore, nous présentons une approche fondée sur des principes basée sur les données pour résoudre ce problème, basée sur le modèle de canal bruyant de Shannon, afin d'apporter de la variation et du naturel au texte généré. Nos expériences sur trois grands corpus d'actualités du monde réel démontrent que le modèle probabiliste proposé peut être appris à imiter avec précision le modèle d'utilisation des verbes des auteurs humains, surpassant ainsi de manière significative la méthode de pointe.</abstract_fr>
      <abstract_es>En los sistemas de generación de lenguaje natural (NLG) de datos a texto, las computadoras necesitan encontrar las palabras adecuadas para describir los fenómenos observados en los datos. Este artículo se centra en el problema de elegir los verbos apropiados para expresar la dirección y la magnitud de un cambio porcentual (por ejemplo, en los precios de las acciones). En lugar de simplemente usar los mismos verbos una y otra vez, presentamos un enfoque basado en datos basado en principios para este problema basado en el modelo de canal ruidoso de Shannon para aportar variación y naturalidad al texto generado. Nuestros experimentos en tres cuerpos de noticias del mundo real a gran escala demuestran que el modelo probabilístico propuesto puede aprenderse para imitar con precisión el patrón de uso de los autores humanos alrededor de los verbos, superando significativamente al método más avanzado.</abstract_es>
      <abstract_pt>Em sistemas de geração de linguagem natural (NLG) de dados para texto, os computadores precisam encontrar as palavras certas para descrever os fenômenos vistos nos dados. Este artigo se concentra no problema de escolher verbos apropriados para expressar a direção e a magnitude de uma mudança percentual (por exemplo, nos preços das ações). Em vez de simplesmente usar os mesmos verbos repetidamente, apresentamos uma abordagem baseada em dados para esse problema baseada no modelo de canal barulhento de Shannon para trazer variação e naturalidade ao texto gerado. Nossos experimentos em três corpora de notícias do mundo real em grande escala demonstram que o modelo probabilístico proposto pode ser aprendido para imitar com precisão o padrão de uso dos autores humanos em torno dos verbos, superando significativamente o método de última geração.</abstract_pt>
      <abstract_ja>データ対テキスト自然言語生成（ NLG ）システムでは、コンピュータはデータに見られる現象を記述するために適切な単語を見つける必要があります。この論文では、パーセンテージ変化の方向と大きさを表現するために適切な動詞を選択する問題に焦点を当てている（例えば、株価）。単に同じ動詞を繰り返し使用するのではなく、生成されたテキストにバリエーションと自然さをもたらすために、シャノンのノイズの多いチャネルモデルに基づいて、この問題に対する原理的なデータ駆動型アプローチを提示します。私たちの3つの大規模な現実のニュース団体の実験は、提案された確率モデルが、動詞の周りの人間の著者の使用パターンを正確に模倣することを学ぶことができ、最先端の方法を大幅に上回っていることを示しています。</abstract_ja>
      <abstract_ru>В системах генерации естественного языка (NLG), компьютеры должны найти правильные слова для описания явлений, наблюдаемых в данных. В настоящем документе основное внимание уделяется проблеме выбора подходящих глаголов для выражения направления и величины процентного изменения (например, в ценах на акции). Вместо того, чтобы просто использовать одни и те же глаголы снова и снова, мы представляем принципиальный, основанный на данных подход к этой проблеме, основанный на модели шумных каналов Шеннона, чтобы привнести вариацию и естественность в сгенерированный текст. Наши эксперименты на трех крупномасштабных новостных корпусах показывают, что предлагаемую вероятностную модель можно выучить, чтобы точно имитировать паттерн использования человеческих авторов вокруг глаголов, значительно превосходя современный метод.</abstract_ru>
      <abstract_hi>डेटा-टू-टेक्स्ट प्राकृतिक भाषा जनरेशन (NLG) प्रणालियों में, कंप्यूटर को डेटा में देखी गई घटनाओं का वर्णन करने के लिए सही शब्द खोजने की आवश्यकता होती है। यह पेपर प्रतिशत परिवर्तन की दिशा और परिमाण को व्यक्त करने के लिए उपयुक्त क्रियाओं को चुनने की समस्या पर केंद्रित है (उदाहरण के लिए, स्टॉक की कीमतों में)। बस एक ही क्रिया का बार-बार उपयोग करने के बजाय, हम शैनन के शोर-चैनल मॉडल के आधार पर इस समस्या के लिए एक सैद्धांतिक डेटा-संचालित दृष्टिकोण प्रस्तुत करते हैं ताकि उत्पन्न पाठ में भिन्नता और स्वाभाविकता लाई जा सके। तीन बड़े पैमाने पर वास्तविक दुनिया के समाचार कॉर्पोरेट पर हमारे प्रयोगों से पता चलता है कि प्रस्तावित संभाव्य मॉडल को क्रियाओं के चारों ओर उपयोग के मानव लेखकों के पैटर्न की सटीक नकल करने के लिए सीखा जा सकता है, जो अत्याधुनिक विधि को काफी हद तक बेहतर बनाता है।</abstract_hi>
      <abstract_zh>数至文本自然语言成(NLG)统中,计算机须得正单词以述数中所见。 重言择其动词以示百分比方幅度(,股票价格)也。 吾不简而复用同动词,盖香农噪声之道,设一原则性之数以决之,以入变化自然性文也。 三大世界新闻语料库上实验明,可学概率模,以正人动词之用式,著优于先进之法。</abstract_zh>
      <abstract_ga>I gcórais Ghiniúint Teanga Nádúrtha (NLG) ó shonraí go téacs, ní mór do ríomhairí na focail chearta a aimsiú chun cur síos a dhéanamh ar fheiniméin a fheictear sna sonraí. Díríonn an páipéar seo ar an bhfadhb a bhaineann le briathra cuí a roghnú chun treo agus méid athraithe céatadáin a chur in iúl (m.sh., i bpraghsanna stoic). Seachas na briathra céanna a úsáid arís agus arís eile, cuirimid i láthair cur chuige bunaithe ar shonraí i leith na faidhbe seo bunaithe ar mhúnla cainéal nois na Sionainne chun éagsúlacht agus nádúrthacht a thabhairt isteach sa téacs ginte. Léiríonn ár dturgnaimh ar thrí chorpora nuachta fhíorscála ar mhórscála gur féidir an tsamhail dóchúlachta atá beartaithe a fhoghlaim chun aithris chruinn a dhéanamh ar phatrún úsáide na n-údar daonna timpeall na mbriathra, rud a sháraíonn go mór an modh úrscothach.</abstract_ga>
      <abstract_hu>Az adat-szöveg természetes nyelv generációs (NLG) rendszerekben a számítógépeknek meg kell találniuk a megfelelő szavakat az adatokban látható jelenségek leírásához. Ez a tanulmány a megfelelő igék kiválasztásának problémájára összpontosít, hogy kifejezze a százalékos változás irányát és nagyságát (pl. a részvényárak). Ahelyett, hogy újra és újra ugyanazokat az igéket használjuk, egy elvi adatközpontú megközelítést mutatunk be ennek a problémának Shannon zajos csatorna modelljén alapuló megközelítését, hogy variációt és természetességet hozzunk a generált szövegbe. Három nagyszabású valós hírcsoporán végzett kísérleteink azt mutatják, hogy a javasolt valószínűségi modell megtanulható, hogy pontosan utánozza az emberi szerzők igék körüli használati mintáját, jelentősen felülmúlva a korszerű módszert.</abstract_hu>
      <abstract_el>Στα συστήματα δημιουργίας φυσικής γλώσσας δεδομένων σε κείμενο, οι υπολογιστές πρέπει να βρουν τις σωστές λέξεις για να περιγράψουν φαινόμενα που παρατηρούνται στα δεδομένα. Η παρούσα εργασία επικεντρώνεται στο πρόβλημα της επιλογής κατάλληλων ρήμων για να εκφράσει την κατεύθυνση και το μέγεθος μιας μεταβολής ποσοστού (π.χ. στις τιμές μετοχών). Αντί να χρησιμοποιούμε τα ίδια ρήματα ξανά και ξανά, παρουσιάζουμε μια βασισμένη σε δεδομένα προσέγγιση σε αυτό το πρόβλημα βασισμένη στο μοντέλο θορυβωδών καναλιών της Σάνον, ώστε να φέρουμε παραλλαγή και φυσικότητα στο κείμενο που δημιουργείται. Τα πειράματά μας σε τρία μεγάλα σώματα ειδήσεων του πραγματικού κόσμου αποδεικνύουν ότι το προτεινόμενο πιθανολογικό μοντέλο μπορεί να μάθει να μιμείται με ακρίβεια το μοτίβο χρήσης των ανθρώπινων συγγραφέων γύρω από ρήματα, ξεπερνώντας σημαντικά τη σύγχρονη μέθοδο.</abstract_el>
      <abstract_ka>Data- to- text Natural Language Generation (NLG) სისტემებში, კომპიუტერები უნდა მოიძებნა სწორი სიტყვები, რომელიც მონაცემებში ჩვენებული ფენომენების შესახებ. ამ დოკუმენტის პრობლემაზე გადაყენება შესაძლებელი გერბების მისამართვა და სიმართვა პროცენტის ცვლილების (მაგალითად, stock prices). არა მხოლოდ ერთადერთი გერბების გამოყენება, ჩვენ ამ პრობლემაზე პრინციპური მონაცემების მიღება, რომელიც შანონის სიტყვა-კანალური მოდელზე დაბაზეულია, რომ გადავიტანოთ განცემები და ნარულ ჩვენი ექსპერიმენტები სამი დიდი მსოფლიო ინფორმაციის კოპორაში გამოწვება, რომ მოძლევებული შესაბამისი მოდელედ შეიძლება იმეპოვნოთ, რომ ადამიანის ავტორების სტრუქტურის გამოყენება გერბების გარეშე,</abstract_ka>
      <abstract_it>Nei sistemi data-to-text Natural Language Generation (NLG), i computer devono trovare le parole giuste per descrivere i fenomeni visti nei dati. Questo articolo si concentra sul problema della scelta di verbi appropriati per esprimere la direzione e l'entità di una variazione percentuale (ad esempio, nei prezzi delle azioni). Piuttosto che semplicemente usare gli stessi verbi più e più volte, presentiamo un approccio basato sui dati di principio a questo problema basato sul modello del canale rumoroso di Shannon in modo da portare variazione e naturalezza nel testo generato. I nostri esperimenti su tre corpora di notizie reali su larga scala dimostrano che il modello probabilistico proposto può essere imparato per imitare accuratamente il modello di utilizzo degli autori umani intorno ai verbi, superando significativamente il metodo all'avanguardia.</abstract_it>
      <abstract_lt>Duomenų į tekstą gamtos kalbų generacijos (NLG) sistemose kompiuteriai turi rasti tinkamus žodžius, kad aprašytų duomenų matomus reiškinius. Šiame dokumente daugiausia dėmesio skiriama tinkamų žodžių pasirinkimo problemai, siekiant išreikšti procentinio pokyčio kryptį ir dydį (pvz., atsargų kainomis). Užuot paprasčiausiai naudoję tuos pačius žodžius kartą ir kartą, mes pateikiame principinį duomenų pagrįstą požiūrį į šią problem ą, pagrįstą Shannono triukšmo kanalo modeliu, kad į sukauptą tekstą būtų įtraukta įvairovė ir natūralumas. Mūsų eksperimentai su trimis didelio masto realiojo pasaulio naujienų korporais rodo, kad pasiūlytas probabilistinis modelis gali būti išmoktas tiksliai imituoti žmogaus autorių naudojimo model į aplink žodžius ir gerokai viršyti pažangiausią metodą.</abstract_lt>
      <abstract_mk>Во системите на генерација на природен јазик (НЛГ) од податоци до текст, компјутерите мора да ги најдат вистинските зборови за да ги опишат феномените што се гледаат во податоците. Овој документ се фокусира на проблемот со изборот на соодветни јазици за изразување на насоката и големината на процентната промена (на пример, во цените на акциите). Наместо едноставно користејќи ги истите реченици повторно и повторно, претставуваме принципиран пристап на овој проблем врз основа на моделот на Шенон со шумни канали за да донесеме варијација и природност во генерираниот текст. Нашите експерименти на три големи новински корпора на реалниот свет покажуваат дека предложениот веројатен модел може да се научи да прецизно имитира шемата на користење на човековите автори околу глаголата, значително надминувајќи го најсовремениот метод.</abstract_mk>
      <abstract_kk>Деректерден мәтінде Түзіндік тілді құру (NLG) жүйелерінде компьютерлер деректерде көрінетін пайдалану үшін дұрыс сөздерді табу керек. Бұл қағаз проценттің өзгерістерінің бағыттауы мен өлшемін көрсету мәселесін таңдау (мысалы, акциялық мәндерінде). Шаннон дыбыс арнасының үлгісіне негізделген мәселеге негізделген деректерді қайталап қолданудың орнына бір көпшілігін келтірік. Біздің үш үлкен үлкен әлемді жаңалық корпорасындағы тәжірибелеріміз, ұсынылған ықтималдық моделі, адамдардың авторларының вербалардың жұмысын дұрыс түрлендіру үшін дұрыс түрлендіруге болады деп көрсетеді.</abstract_kk>
      <abstract_ms>Dalam sistem Generasi Bahasa Alami (NLG) data-ke-teks, komputer perlu cari perkataan yang betul untuk menggambarkan fenomena yang dilihat dalam data. Kertas ini fokus pada masalah memilih verb yang sesuai untuk mengekspresikan arah dan ukuran perubahan peratus (cth. dalam harga stok). Daripada menggunakan verb yang sama lagi dan lagi, kita memperkenalkan pendekatan data-pemacu prinsip kepada masalah ini berdasarkan model saluran-bunyi Shannon untuk membawa variasi dan kebiasaan ke dalam teks yang dijana. Eksperimen kami pada tiga korpora berita dunia nyata skala besar menunjukkan bahawa model probabilistik yang diusulkan boleh belajar untuk meniru dengan tepat corak penggunaan penulis manusia sekitar verb, melampaui kaedah state-of-the-art secara signifikan.</abstract_ms>
      <abstract_ml>ഡേറ്റാവില്‍ നിന്നും പദാവലിയിലേക്കുള്ള സ്വാഭാവിക ഭാഷയുടെ ജനിപ്പം (NLG) സിസ്റ്റത്തില്‍, ഡേറ്റായില്‍ കാണുന്ന സംഭവം വ ഈ പത്രത്തില്‍ ഒരു ശതമാനം മാറ്റങ്ങളുടെ തിരിച്ചറിയാനും വലിപ്പം പ്രകടനം തെരഞ്ഞെടുക്കുന്നതിനും പ്രശ്നത്തില്‍ ശ്രദ്ധിക്ക വീണ്ടും വീണ്ടും അതേ വാര്‍ത്തകള്‍ ഉപയോഗിക്കുന്നതിനെക്കാള്‍ മാത്രമാണ് ഞങ്ങള്‍ ശാന്നോനിന്റെ ശബ്ദം-ചാനല്‍ മോഡലിനെ അടിസ്ഥാനമാക്കിയ ഒരു പ്രധാനപ്പ മൂന്നു വലിയ വാര്‍ത്തകളില്‍ വെച്ച് ലോകത്തെ വാര്‍ത്തകളില്‍ നമ്മുടെ പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു പ്രാദോഷിപ്പിക്കപ്പെട്ട സാധ്യതയുള്ള മോഡല്‍ കൃത്യമ</abstract_ml>
      <abstract_mt>In data-to-text Natural Language Generation (NLG) systems, computers need to find the right words to describe phenomena seen in the data.  Dan id-dokument jiffoka fuq il-problem a tal-g ħa żla ta’ verbs xierqa biex jesprimu d-direzzjoni u d-daqs ta’ bidla perċentwali (pereżempju fil-prezzijiet tal-istokk). Minflok sempliċement nużaw l-istess verbs mill-ġdid u mill-ġdid, qed nippreżentaw approċċ ibbażat fuq id-dejta għal din il-problem a bbażat fuq il-mudell tal-kanal storbjuż ta’ Shannon sabiex inġibu varjazzjoni u naturalità fit-test iġġenerat. L-esperimenti tagħna fuq tliet korporazzjonijiet tal-aħbarijiet tad-dinja reali fuq skala kbira juru li l-mudell probabilistiku propost jista’ jitgħallem biex jimita b’mod preċiż ix-xejra tal-użu tal-awturi umani madwar il-verbs, li jeċċedi b’mod sinifikanti l-metodu l-aktar avvanzat.</abstract_mt>
      <abstract_pl>W systemach generowania języka naturalnego (NLG) dane-tekst komputery muszą znaleźć odpowiednie słowa do opisu zjawisk widocznych w danych. Niniejszy artykuł skupia się na problemie wyboru odpowiednich czasowników do wyrażenia kierunku i wielkości zmiany procentowej (np. w cenach akcji). Zamiast po prostu używać tych samych czasowników w kółko, prezentujemy zasadnicze podejście do tego problemu oparte na danych oparte na modelu szumowego kanału Shannon, aby wprowadzić zmiany i naturalność do generowanego tekstu. Nasze eksperymenty na trzech dużych korpusach informacyjnych świata rzeczywistego pokazują, że proponowany model probabilistyczny można nauczyć się dokładnie imitować wzorzec używania ludzkich autorów wokół czasowników, znacznie przewyższając najnowocześniejszą metodę.</abstract_pl>
      <abstract_ro>În sistemele de generare a limbajului natural (NLG) date-to-text, computerele trebuie să găsească cuvintele potrivite pentru a descrie fenomenele văzute în date. Această lucrare se concentrează pe problema alegerii verbelor adecvate pentru a exprima direcția și amploarea unei schimbări procentuale (de exemplu, în prețurile acțiunilor). În loc să folosim aceleași verbe din nou și din nou, prezentăm o abordare bazată pe principii de date a acestei probleme bazată pe modelul canalului zgomotos al lui Shannon, astfel încât să aducem variație și naturalitate în textul generat. Experimentele noastre pe trei corpuri de știri reale la scară largă demonstrează că modelul probabilistic propus poate fi învățat pentru a imita cu precizie modelul de utilizare al autorilor umani în jurul verbelor, depășind semnificativ metoda de stat-of-the-art.</abstract_ro>
      <abstract_no>I data- to- text Natural Language Generation (NLG) systemet må datamaskiner finna dei rette ord for å beskriva fenomenane som er synlege i data. Denne papiret fokuserer på problemet med å velja passende verbar for å uttrykke retning og storleiken på prosentforandringa (f.eks. i stokkprisar). I staden for å bruka samme verbar igjen og igjen, presenterer vi ein prinsippet datadrivt tilnærming til denne problemet basert på Shannon sin støykanal-modell slik at du vil henta variasjonar og naturalitet i den genererte teksten. Våre eksperimenter på tre stor verdens nyhetskområde viser at den foreslåde sannsynlige modellen kan lærast til å nøyaktig imitere mønsteret bruk av menneske forfattarane rundt verbar, som utfører metoden for kunsten betydelig.</abstract_no>
      <abstract_mn>Байгалийн хэл төрөлхтний системд компьютерүүд өгөгдлийн тодорхойлолтын тулд зөв үгийг тайлбарлах хэрэгтэй. Энэ цаас хувь хувийн өөрчлөлтийг илэрхийлэх зөв хэлнүүдийг сонгох асуудлыг төвлөрүүлдэг. Яг л адилхан үг ашиглахын оронд, бид Шаннон-ын чимээ загварын загвар дээр үндсэн өгөгдлийн хандлага өгөгдлийн загварыг үүсгэсэн текст руу оруулахын тулд үндсэн арга загвар өгдөг. Бидний 3 том жинхэнэ дэлхийн мэдээллийн корпора дахь туршилтууд нь хүний зохиолчдын хэрэглээний тухай дүрслэлийг тодорхой дүрслэх боломжтой, урлагийн үйл явдал дээр илүү чухал ажиллах боломжтой гэдгийг харуулж байна.</abstract_mn>
      <abstract_sr>U sistemima generacije prirodnog jezika (NLG) podataka do teksta, kompjuteri moraju pronaći prave reči da bi opisali fenomene videne u podacima. Ovaj papir se fokusira na problem izabranja odgovarajućih verba kako bi izrazila smjeru i veličinu promjene procenata (npr. u cenama dionica). Umesto da jednostavno upotrebimo iste verbe ponovo i ponovo, predstavljamo principalni pristup ovom problemu na osnovu Šenonovog model a bučnog kanala kako bi uveli varijaciju i prirodnost u proizvedeni tekst. Naši eksperimenti na tri velike svetske vijesti korporacije pokazuju da se predloženi verovatno model može naučiti da precizno imitira obrazac upotrebe ljudskih autora oko verba, što značajno iznosi metodu države umjetnosti.</abstract_sr>
      <abstract_so>Kambiyuutarka waxaa u baahan in uu helo erayo saxda ah si ay u sawiraan waxyaabaha lagu arko macluumaadka lagu arko. Warqadan wuxuu ku kalsoonaadaa dhibaatada doorashada hadallada habboon si uu u muujiyo hagitaanka iyo koritaanka isbedelka boqolkiiba (tusaale ahaan qiimaha stock). Isku isticmaalidda isku hadal oo kaliya mar iyo labaad, waxaynu soo bandhignaa halkan dhibaatada lagu wado oo ku saleysan tilmaamaha qaylada Shannon, si aan u keenno bedelka iyo dabiicadda warqadda la sameeyay. Imtixaankayada oo ku qoran saddex shirkad oo warqad ah oo dunida aad iyo aad u weyn waxay muujiyaan in tilmaamaha la soo jeeday la barto si saxda ah loo simiyo qaabka isticmaalka dadka oo qoraalka ku wareegsan, si muhiim ah loo sameeyo qaababka xaalada farshaxanka.</abstract_so>
      <abstract_sv>I data-to-text Natural Language Generation (NLG) system behöver datorer hitta rätt ord för att beskriva fenomen som ses i data. Denna uppsats fokuserar på problemet med att välja lämpliga verb för att uttrycka riktningen och omfattningen av en procentuell förändring (t.ex. i aktiekurser). Istället för att bara använda samma verb om och om igen presenterar vi ett principbaserat datadrivet tillvägagångssätt för detta problem baserat på Shannons bullerskanalmodell för att få variation och naturlighet i den genererade texten. Våra experiment på tre storskaliga nyhetskorpor visar att den föreslagna sannolikhetsmodellen kan läras sig att exakt efterlikna mänskliga författares användningsmönster kring verb, vilket avsevärt överträffar den senaste metoden.</abstract_sv>
      <abstract_ta>தரவு- to- text இயல்பான மொழி உருவாக்கம் (NLG) அமைப்புகளில், தரவில் பார்க்கப்பட்ட நடவடிக்கையை விவரிக்க கணினி இந்த தாள் பொருத்தமான சொல்லுக்களை தேர்ந்தெடுத்து சதவிகிதத்தின் திசையையும் அளவையும் வெளிப்படுத்துவதற்கான பிரச்னை மீண்டும் மீண்டும் அதே வார்த்தைகளை பயன்படுத்துவதற்கு பதிலாக, சான்னோனின் சப்தமான வழி மாதிரியை அடிப்படையில் கொண்டு ஒரு முதன்மையான தகவல் இயக்கி மு மூன்று பெரிய அளவில் உண்மையான செய்தி நிறுவனத்தில் எங்கள் சோதனைகள் காண்பிக்கிறது நிர்ணயிக்கப்பட்ட சாத்தியமான மாதிரி முறைமையை சரியாக மனித ஆசிரியர்களின் பயன்பாட்</abstract_ta>
      <abstract_si>Data- to- text Native language generation (NLG) පද්ධතියේදී, පරිගණකරුන් දත්තේ දැක්ක ප්‍රදේශයක් විස්තර කරන්න හරි වචන හොයාගන්න ඕනි. මේ පත්තුව ප්‍රශ්නයක් ප්‍රශ්නයක් වෙනස් වෙනුවෙන් ප්‍රශ්නයක් තෝරාගන්න ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් ව මේ ප්‍රශ්නයක් නිර්මාණය වෙනුවෙන් සිද්ධ වාර්තාවක් ආයෙත් සහ ආයෙත් භාවිත කරන්න, අපි මේ ප්‍රශ්නයකට ප්‍රධාන දත්ත ප්‍රශ්නයක් ප්‍රශ අපේ පරීක්ෂණ තුනක් විශාල ප්‍රවේශනය තියෙන්නේ ඇත්ත ලෝක ප්‍රවේශනය සම්බන්ධ විදියට ප්‍රවේශනය කරන්න පුළුවන් විදිහට මිනිස්සු ලේඛකයන්ගේ ප්‍රව</abstract_si>
      <abstract_ur>Data-to-text Natural Language Generation (NLG) سیسٹم میں، کمپیوٹروں کے لئے دائٹوں میں دیکھے ہوئے دقیق کلمات کا مطلب ہے۔ This paper focuses on the problem of choosing appropriate verbs for express in g the direction and magnitude of a percentage change (e.g., stock prices). ہم نے اس مسئلہ پر ایک نقطہ دکھانے والی دکھانے والی دکھانے کے بدلے شانون کی صدا چانال موڈل پر بنیاد رکھی ہے تاکہ تغییرات اور طبیعت پیدا کئے جائیں۔ ہمارے تین بڑے مطابق حقیقی دنیاوی خبروں کی کورپورا کی آزمائش دکھائی جاتی ہے کہ پیشنهاد کی امکانات کی موڈل سیکھی جاتی ہے کہ انسان لکھنے والوں کی مطابق باتوں کے اطراف استعمال کی طرح دقیق دکھائی جاتی ہے، اور آرتی کی روش سے زیادہ اضافہ کرتی ہے.</abstract_ur>
      <abstract_uz>Name Ushbu qogʻoz esa foiz oʻzgarishlarini koʻrsatish uchun mos keladigan soʻzlarni tanlash muammolarini anglatadi. Biz shu so'zlarni qaytadan boshqa ishlatish uchun Shannon'ning qiyin-kanal modeli asosida asosiy maʼlumot boshqaruvchi usulni ishga tushirish uchun o'zgarishni va tabiiy matnni yaratish uchun. Bizning uchta katta dunyo haqiqiqiy xabar korporiyasidagi jarayonlarimiz esa, iloji qilingan imkoniyat modeli o'rganish mumkin, o'sha so'zlarning atrofidagi foydalanuvchilarning shaklini aniqlashga o'rganish mumkin.</abstract_uz>
      <abstract_vi>Trong hệ thống cấu tạo ngôn ngữ tự nhiên (NLG) dữ liệu với văn bản, máy tính cần tìm từ thích hợp để miêu tả những hiện tượng được thấy trong dữ liệu. Bài báo này tập trung vào vấn đề chọn động từ thích hợp để diễn tả chiều hướng và độ lớn của sự thay đổi phần trăm (v. d. trong giá cổ phiếu). Thay vì đơn giản là s ử dụng các động từ một lần nữa, chúng tôi đưa ra một phương pháp dựa trên nguyên tắc, dựa trên mô hình kênh ồn ào của Shannon để mang theo sự biến đổi và tự nhiên trong văn bản đã tạo ra. Những thí nghiệm của chúng tôi trên ba bản tin trên diện rộng thế giới thực chứng minh rằng mô hình xác thực được đề xuất có thể bắt chước chính xác cách sử dụng của các tác giả trên động từ, vượt trội phương pháp hiện đại nghệ thuật.</abstract_vi>
      <abstract_nl>In data-to-text Natural Language Generation (NLG) systemen moeten computers de juiste woorden vinden om verschijnselen te beschrijven die in de gegevens worden gezien. Dit artikel richt zich op het probleem van het kiezen van geschikte werkwoorden om de richting en omvang van een procentuele verandering (bijvoorbeeld in aandelenkoersen) uit te drukken. In plaats van steeds weer dezelfde werkwoorden te gebruiken, presenteren we een principiële datagedreven benadering van dit probleem gebaseerd op Shannon's noisy-channel model om variatie en natuurlijkheid in de gegenereerde tekst te brengen. Onze experimenten met drie grootschalige real-world nieuws corpora tonen aan dat het voorgestelde probabilistische model kan worden geleerd om het gebruikspatroon van menselijke auteurs rond werkwoorden nauwkeurig te imiteren, wat de state-of-the-art methode aanzienlijk overtreft.</abstract_nl>
      <abstract_hr>U sustavima generacije prirodnog jezika (NLG) podataka do teksta, kompjuteri moraju pronaći prave riječi kako bi opisali fenomene vidjene u podacima. Ovaj papir se fokusira na problem izabranja odgovarajućih glasova kako bi izrazila smjeru i veličinu procentnih promjena (npr. u cijenama dionica). Umjesto da jednostavno koristimo iste verbe opet i opet, predstavljamo principalni pristup ovom problemu na temelju Shannonovog model a bučnog kanala kako bismo uveli varijaciju i prirodnost u proizvedeni tekst. Naši eksperimenti na tri veličanstvene vijestinske korporacije realnog svijeta pokazuju da se predloženi vjerojatni model može naučiti precizno imitirati obrazac uporabe ljudskih autora oko verba, što značajno iznosi metodu stanja umjetnosti.</abstract_hr>
      <abstract_bg>В системите за генериране на естествен език от данни към текст компютрите трябва да намерят правилните думи, за да опишат явленията, наблюдавани в данните. Настоящата статия се фокусира върху проблема с избора на подходящи глаголи за изразяване на посоката и величината на процентната промяна (напр. в цените на акциите). Вместо просто да използваме едни и същи глаголи отново и отново, ние представяме принципен подход към този проблем, базиран на модела на шумните канали на Шанън, така че да внесем вариация и естественост в генерирания текст. Нашите експерименти с три мащабни информационни корпорации в реалния свят демонстрират, че предложеният вероятностен модел може да се научи да имитира точно модела на използване на човешките автори около глаголите, като значително превъзхожда съвременния метод.</abstract_bg>
      <abstract_da>I data-to-text Natural Language Generation (NLG) systemer skal computere finde de rigtige ord til at beskrive fænomener set i dataene. Denne artikel fokuserer på problemet med at vælge passende verber til at udtrykke retningen og størrelsen af en procentvis ændring (f.eks. i aktiekurser). I stedet for blot at bruge de samme verber igen og igen, præsenterer vi en principbaseret datadrevet tilgang til dette problem baseret på Shannons støjekanal model for at bringe variation og naturlighed i den genererede tekst. Vores eksperimenter med tre store virkelige nyhedskorporaer viser, at den foreslåede probabilistiske model kan læres at efterligne menneskelige forfatteres brugsmønster omkring verber, hvilket overgår den nyeste metode betydeligt.</abstract_da>
      <abstract_de>In Daten-zu-Text Natural Language Generation (NLG)-Systemen müssen Computer die richtigen Wörter finden, um Phänomene zu beschreiben, die in den Daten gesehen werden. Diese Arbeit konzentriert sich auf das Problem der Auswahl geeigneter Verben, um die Richtung und Größe einer prozentualen Veränderung (z.B. in Aktienkursen) auszudrücken. Anstatt immer wieder dieselben Verben zu verwenden, präsentieren wir einen prinzipiellen datengetriebenen Ansatz, der auf Shannons Rauschkanalmodell basiert, um Variation und Natürlichkeit in den generierten Text zu bringen. Unsere Experimente an drei großen Nachrichtenkorpora aus der realen Welt zeigen, dass das vorgeschlagene probabilistische Modell erlernt werden kann, das Gebrauchsmuster menschlicher Autoren um Verben herum genau zu imitieren und die State-of-the-Art-Methode deutlich zu übertreffen.</abstract_de>
      <abstract_ko>데이터에서 텍스트로의 자연언어생성(NLG) 시스템에서 컴퓨터는 데이터의 현상을 설명하기 위해 적당한 단어를 찾아야 한다.본고는 주로 적당한 동사를 어떻게 선택하여 백분율 변화의 방향과 폭(예를 들어 주식 가격)을 표현하는지를 연구한다.우리는 같은 동사를 한 번 또 한 번 사용하는 것이 아니라 향농의 소음 채널 모델을 바탕으로 원칙적인 데이터 구동 방법을 제시하여 이 문제를 해결하고 생성된 텍스트에 변화와 자연성을 도입하도록 한다.우리가 세 개의 대규모 현실 세계 뉴스 자료 라이브러리에서 실험한 결과 제시된 확률 모델은 인류 작가가 동사에 대한 사용 모델을 정확하게 모방할 수 있고 가장 선진적인 방법보다 현저히 우수하다는 것을 알 수 있다.</abstract_ko>
      <abstract_id>Dalam sistem generasi bahasa alam (NLG) data-ke-teks, komputer harus menemukan kata-kata yang tepat untuk menggambarkan fenomena yang terlihat dalam data. Kertas ini fokus pada masalah memilih verb yang sesuai untuk mengekspresikan arah dan ukuran perubahan persentasi (misalnya dalam harga saham). Daripada menggunakan verb yang sama lagi dan lagi, kami mempersembahkan pendekatan berdasarkan prinsip data untuk masalah ini berdasarkan model saluran suara Shannon untuk membawa variasi dan alam ke dalam teks yang dibuat. Eksperimen kami pada tiga kopora berita dunia nyata skala besar menunjukkan bahwa model probabilistik yang diusulkan dapat belajar untuk dengan akurat imitasi pola penggunaan penulis manusia di sekitar verb, melebihi metode state-of-the-art dengan signifikan.</abstract_id>
      <abstract_tr>Maglumat we metin üçin Natal dil Jequirmek (NLG) sistemlerinde kompýuterler maglumatlarda görülen ähnleri tasvir etmek üçin dogry sözleri tapmaly. Bu häzir prosent üýtgewlerini a ýtmak üçin gowy wersiýalary saýlamak kynçylygyna üns berýär. Aynı s özleri tekrar kullanmak yerine, Şanon sesli kanallar modelinin tabanlı bir şekilde, çeşitlikleri ve doğallyklykları üretilen metin içine getirmek üçin bu sorunlara el koyulduk. Biziň 3 uly ölçekli dünýä täzelikli bagyt korporasymyzda munuň teklip eden mümkin modeliniň, adamlaryň wersiýalaryň töwereginde ulanylaryň nusgyny dogry bir şekilde daňlatmak üçin öwrenip biler.</abstract_tr>
      <abstract_sw>Katika mifumo ya Uzalishaji wa Lugha ya asili (NLG) ya data-hadi-text, kompyuta inahitaji kutafuta maneno sahihi ya kuelezea hali inayoonekana kwenye taarifa. Gazeti hili linalenga kwenye tatizo la kuchagua maneno yanayoweza kuonyesha mwelekeo na ukubwa wa mabadiliko ya asilimia (kwa mfano katika bei za stock). Badala ya kutumia maneno hayo yanayofanana tena na tena, tunaweka mbinu kuu ya takwimu zinazoendeshwa kwa tatizo hili kwa msingi wa mtindo wa sauti wa Shannon ili kuleta mabadiliko na asili katika ujumbe uliotengenezwa. Majaribio yetu kwenye kampuni ya habari yenye kiwango kikubwa duniani yanaonyesha kwamba mpango huu unaopendekezwa unaweza kujifunza kwa uhakika wa kuwafananisha mtindo wa matumizi ya waandishi wa binadamu katika maeneo mbalimbali ya maneno, ukifanya utaratibu wa hali ya sanaa kwa kiasi kikubwa.</abstract_sw>
      <abstract_fa>در سیستم‌های تولید زبان طبیعی (NLG) داده‌ها به متن، کامپیوترها نیاز دارند کلمات درستی را برای توصیف پدیده‌های دیده در داده‌ها پیدا کنند. این کاغذ روی مشکل انتخاب کلمات مناسب برای تعریف مسیر و بزرگی تغییر درصد (مثال در قیمت سهام) تمرکز می‌کند. به جای ساده استفاده از یک کلمه دیگر و دوباره، ما یک روش اصلی با داده‌های راهنمایی به این مشکل را پیشنهاد می‌کنیم که بر اساس مدل صدا-کانال شانون باشد تا تغییرات و طبیعیت را وارد متن تولید کنیم. آزمايشات ما در سه شرکت اخبار واقعي در مقياس بزرگ جهان نشون ميده که اين مدل احتمالي پيشنهاد داده ميشه ياد بگيره که الگوي استفاده از نويسنده هاي انسان رو دقيقا شبيه استفاده کنه در اطراف کلمات، بيشتر از انجام وضعيت هنري</abstract_fa>
      <abstract_sq>Në sistemet e Gjenerimit të Gjuhave Natyrore (NLG), kompjuterët duhet të gjejnë fjalët e duhura për të përshkruar fenomenet e parë në të dhëna. Ky dokument përqëndrohet në problem in e zgjedhjes së verbëve të përshtatshëm për të shprehur drejtimin dhe madhësinë e një ndryshimi përqindje (për shembull, në çmimet e aksioneve). Në vend që thjesht të përdorim të njëjtat verbe përsëri dhe përsëri, ne paraqesim një qasje kryesore të të dhënave për këtë problem bazuar në modelin e kanalit të zhurmshëm të Shannonit në mënyrë që të sjellim variacionin dhe natyrshmërinë në tekstin e gjeneruar. Eksperimentet tona në tre korpra të lajmeve të botës reale në shkallë të madhe demonstrojnë se modeli probabilist i propozuar mund të mësohet për të imituar saktësisht modelin e përdorimit të autorëve njerëzorë rreth verbeve, duke kaluar në mënyrë të rëndësishme metodën më të lartë të artit.</abstract_sq>
      <abstract_af>In data- to- text Natuurlike Taal Generasie (NLG) stelsels moet rekenaars die regte woorde vind om fenomene in die data gesien te beskryf. Hierdie papier fokus op die probleem van die kies van geskikte verbe om die rigting en magnitude van 'n persentasie verander te uitdruk (bv. in stoorproses). Herder a s eenvoudig die selfde verbe weer en weer gebruik, voorsien ons 'n vorderde data-gedruk toegang na hierdie probleem gebaseer op Shannon se geluidkanaal model sodat ons variasie en natuurlikheid in die genereerde teks bring. Ons eksperimente op drie groot-skaal reël-wêreld nuuskorpora bevestig dat die voorgestelde probabilistiese model kan leer word om die patroon van gebruik van mense outeurs rondom verbe te imiteer, wat die staat-van-kunstensmetode betekeurig uitvoer.</abstract_af>
      <abstract_hy>Տվյալների և տեքստի միջև բնական լեզուների ստեղծման համակարգերում համակարգիչները պետք է գտնեն ճիշտ բառերը, որոնք նկարագրում են տվյալներում տեսված երևույթները: Այս թղթին կենտրոնանում է հարմար բայերի ընտրության խնդիրը, որպեսզի արտահայտվի փոփոխության ուղղությունը և չափը (օրինակ, արժեքներում): Փոխարենը միայն նույն բայերը կրկին ու կրկին օգտագործելու փոխարեն, մենք ներկայացնում ենք այս խնդիրը տվյալների հիմնված սկզբունքային մոտեցում, որը հիմնված է Շանոնի աղմկոտ կանանների մոդելի վրա, որպեսզի տարբերությունը և բնական կարողությունը ներառվի ստեղծված տե Our experiments on three large-scale real-world news corpora demonstrate that the proposed probabilistic model can be learned to accurately imitate human authors' pattern of usage around verbs, outperforming the state-of-the-art method significantly.</abstract_hy>
      <abstract_az>Data-to-text Natural Language Generation (NLG) sistemlərində bilgisayarlar məlumatlarda görünən fenomenləri tanımlamaq üçün doğru sözləri tapmalı. Bu kağıt procent dəyişikliklərinin yönünü və böyüklüyünü ifadə etmək üçün uyğun verbləri seçmək problem in ə odaqlanır. Bu problem ə, Shannon'in s əs kanalı modeli ilə dəyişiklik və təbiətli mətnə gətirmək üçün, bir dəyişiklik və təbiətli təbiəti ilə dəyişiklik və təbiətli təbiəti ilə birlikdə istifadə edirik. Üç böyük dünya xəbəri korporasında çalışmalarımız təklif edilən mümkün modeli, insan yazıcıların verblərin ətrafında istifadə edilməsini təsdiqləyici, sanat metodumundan çox böyük tərzdə istifadə edilməsini göstərir.</abstract_az>
      <abstract_bs>U sistemima generacije prirodnog jezika (NLG) podataka do teksta, kompjuteri moraju pronaći prave riječi kako bi opisali fenomene viđene u podacima. Ovaj papir se fokusira na problem izabranja odgovarajućih verba kako bi izrazila smjeru i veličinu promjene procenata (npr. u cijenama dionica). Umesto da jednostavno upotrebimo iste verbe opet i opet, predstavljamo principalni pristup ovom problemu na temelju Shannonovog model a bučnog kanala kako bi doveli varijaciju i prirodnost u proizvedeni tekst. Naši eksperimenti na tri velike vijesti korporacije realnog svijeta pokazuju da se predloženi verovatno model može naučiti da precizno imitira obrazac upotrebe ljudskih autora oko verba, što značajno iznosi metodu stanja umjetnosti.</abstract_bs>
      <abstract_am>ኮምፒውተሮችን በአዳራዊ ቋንቋ ትውልድ (NLG) ስርዓቶች ውስጥ መረጃዎች ላይ የተመለከተውን ስህተት ለማግኘት እውነተኛ ቃል ያስፈልጋል። ይህ ፕሮግራም የመጠቀም ቃላትን በመምረጥ ላይ ትክክለኛለች፡፡ ከዚህም አንዲት ቃላት በቀር እና ሁለተኛ በመጠቀም፣ የሳንኖን ድምፅ-የቻይል ሞዴል በመጠቀም ለዚህ ጉዳይ የመጀመሪያ የዳታዎችን ሥርዓት እናደርጋለን፡፡ በሦስት ትልቁ የዓለም ዜና ኮርፖራ ላይ ፈተናዎቻችን የሥልጣን ተሟጋቾችን በቋንቋዎች ላይ የሚጠቀሙትን የሰው ጸሐፊዎች የጥያቄን ምሳሌ እንዲያስተምሩ ያሳያል፡፡</abstract_am>
      <abstract_cs>V systémech generování přirozeného jazyka (NLG) data-to-text musí počítače najít správná slova pro popis jevů viděných v datech. Tento článek se zaměřuje na problematiku výběru vhodných slovesa pro vyjádření směru a velikosti procentní změny (např. ceny akcií). Namísto používání stejných sloves znovu a znovu, představujeme principiální datově řízený přístup k tomuto problému založený na Shannonově šumovém modelu, abychom do generovaného textu přinesli variaci a přirozenost. Naše experimenty na třech velkých zpravodajských korpusech v reálném světě ukazují, že navržený pravděpodobnostní model lze naučit přesně imitovat vzorec používání lidských autorů kolem slovesa, což výrazně předčí nejmodernější metodu.</abstract_cs>
      <abstract_bn>ডাটা থেকে টেক্সট প্রাকৃতিক ভাষা প্রজন্ম (এনএলজি) সিস্টেমে কম্পিউটার তথ্যে দেখা যাচ্ছে তা বর্ণনা করার জন্য সঠিক শব্দ এই পত্রিকাটি একটি শতকরা পরিবর্তনের দিকে প্রকাশ করার জন্য যথেষ্ট ভার্ভ বেছে নেওয়ার সমস্যার উপর মনোযোগ দিয়েছে (উদাহরণস্বরূপ স্ট্যাক শ্যান্ননের শব্দ-চ্যানেল মডেল ভিত্তিক ভিত্তিক তথ্য-চ্যানেল ব্যবহার করার পরিবর্তে আমরা এই সমস্যার মূল ধারাবাহিক উপায় উপস্থাপন করি যাতে তা তৈরি করা হয় তিনটি বিশ্বব্যাপী সংবাদ কোর্পোরায় আমাদের পরীক্ষা প্রদর্শন করেছে যে প্রস্তাবিত সম্ভাব্য মডেল সঠিকভাবে মানুষের লেখকদের ব্যবহারের ধরনের অনুমোদনের শিক্ষা প্রদান করা</abstract_bn>
      <abstract_ca>En els sistemes de generació de llenguatges naturals (NLG), els ordinadors han de trobar les paraules correctes per descriure fenomens vists a les dades. Aquest article es centra en el problem a d'escollir verbs apropiats per expressar la direcció i la magnitud d'un canvi percental (per exemple, en els preus d'acció). En lloc d'utilitzar els mateixos verbs una vegada i una altra, presentem un enfocament basat en les dades sobre aquest problem a basat en el model de canal sorollós de Shannon per portar variació i naturalesa al text generat. Els nostres experiments en tres corpores de notícies a gran escala del món real demostren que el model probabilista proposat es pot aprendre a imitar amb precisió el patró d'ús dels autors humans al voltant dels verbs, superant significativament el mètode d'última generació.</abstract_ca>
      <abstract_et>Loomuliku keele genereerimise (NLG) süsteemides peavad arvutid leidma õiged sõnad andmetes nähtuste kirjeldamiseks. Käesolev töö keskendub probleemile valida sobivad tegusõnad, et väljendada protsendimuutuse suunda ja ulatust (nt aktsiahindades). Selle asemel, et kasutada samu tegusõnu ikka ja jälle, esitame põhimõttelise andmepõhise lähenemisviisi sellele probleemile, mis põhineb Shannoni mürakanali mudelil, et tuua genereeritud teksti variatsiooni ja loomulikkust. Meie eksperimendid kolme suuremahulise reaalmaailma uudistekorporaga näitavad, et väljapakutud tõenäosusmudelit saab õppida imiteerima täpselt inimautorite kasutusmustrit tegusõnade ümber, ületades oluliselt kaasaegset meetodit.</abstract_et>
      <abstract_fi>Data-to-text Natural Language Generation (NLG) -järjestelmissä tietokoneiden on löydettävä oikeat sanat kuvaamaan datassa havaittuja ilmiöitä. Tässä artikkelissa keskitytään ongelmaan valita sopivia verbejä ilmaisemaan prosenttimuutoksen suuntaa ja suuruutta (esim. osakehinnoissa). Sen sijaan, että käyttäisimme samoja verbejä uudelleen ja uudelleen, esittelemme periaatteellisen datavetoisen lähestymistavan tähän ongelmaan Shannonin meluisaan kanavamalliin, jotta luotuun tekstiin saataisiin vaihtelua ja luonnollisuutta. Kokeemme kolmella laajamittaisella reaaliaikaisella uutiskorpusella osoittavat, että ehdotettu todennäköisyysmalli voidaan oppia jäljittelemään tarkasti ihmisten kirjoittajien verbien käyttötapoja ja ylittämään merkittävästi uusimman menetelmän.</abstract_fi>
      <abstract_jv>Nang datang-to-text Generation Language Generation (NLG) sistem, komputer kudu nyimpen kelas justification string" in "context_BAR_stringLink Nyong sampeyan pancen sistem sing beraksi lan mulai, kita sampeyan data-sistem sing dadi nggawe pernik nggawe barang-sistem sing bisa basa Jejaring-channel Awak dhéwé éntuk karo telu kalih-kalih lan alam sing perusahaan anyar tentang anyar tentang kanggo ngerasakno dianggawe barang chang praksistik dhéwé iso nggawe ngubah perusahaan sing gambar nggawe bener, iso nggawe paten-kebutuhan langkung sampeyan operasi tambah bantuan.</abstract_jv>
      <abstract_he>In data-to-text Natural Language Generation (NLG) systems, computers need to find the right words to describe phenomena seen in the data.  העבודה הזאת מתמקדת בבעיה של לבחור פעולים מתאימים כדי להביע את הכיוון והגודל של שינוי אחוזי (למשל במחירי המניות). במקום פשוט להשתמש באותו מילים שוב ושוב, אנחנו מציגים גישה עקרונית מונעת על נתונים לבעיה זו מבוססת על מודל ערוץ הרעש של שאנון כדי להביא ויריאציה וטבעות לטקסט שנוצר. הניסויים שלנו על שלושה גופורות חדשות בעולם האמיתי בקנה מידה גדולה מראים שהמודל הפרובינציאלי המוצע יכול ללמוד כדי לחקות בדיוק את דפוס השימוש של הסופרים האנושיים סביב אלברים, מעל שיטת המדינה באופן משמעותי.</abstract_he>
      <abstract_ha>Daga tsarin tsarin LG na-matsayin-zuwa-matsayin Nazara (NLG) na buƙata, za'a gane kwamfyuta magana masu daidaita dõmin ya bayyana filin da aka gan cikin data. Wannan takarda na fokus a kan zartar da za'a zãɓi alƙaluman aiki masu daidai dõmin ya nuna shirin shiryuwa da girmama mai musanyawa cikin fomat (misali, cikin qiimar ajiya). Rather than simply using the same verbs again and again, we present a principled data-driven approach to this problem based on Shannon's noisy-channel model so as to bring variation and naturalness into the generated text.  Kayan jarrabõyinmu masu akan makampuni uku masu girma a cikin dũniya, sun nuna cewa, za'a iya sanar da misãlai mai yiwuwa ya iya daidaita kamar misalin mutane da ke amfani da shi a ƙarƙashin marubuci, kuma ya sami hanyar-state-of-the-art mai muhimmi.</abstract_ha>
      <abstract_sk>V sistemih za generiranje naravnega jezika (NLG) podatkov v besedilo morajo računalniki najti prave besede za opis pojavov, ki jih vidimo v podatkih. Prispevek se osredotoča na problem izbire ustreznih glagolov za izražanje smeri in obsega odstotne spremembe (npr. cene delnic). Namesto da bi vedno znova uporabljali iste glagole, predstavljamo načelno podatkovno usmerjen pristop k tej problemu, ki temelji na Shannonovem modelu hrupnega kanala, da bi v ustvarjeno besedilo prinesli variacijo in naravnost. Naši eksperimenti na treh obsežnih resničnih novinarskih korpusih kažejo, da se lahko predlagani verjetnostni model nauči natančno posnemati vzorec uporabe človeških avtorjev okoli glagolov, kar pomembno presega najsodobnejšo metodo.</abstract_sk>
      <abstract_bo>རང་བཞིན་པའི་སྐད་རིགས་ལ་ཆ་འཕྲིན་ཡིག་ཆའི་ནང་དུ་རྩིས་འཁོར་ཐོག་ཏུ། ཤོག་བྱང་འདིས་བྱ་ཚིག་གདམ་སའི་དཀའ་ངལ་འདོན་པར་མཐུན འོན་ཀྱང་། ང་ཚོས་རྣམ་གྲངས་ཀྱི་བྱ་ཚིག་གཅིག་ལས་སླེབས་པ་ལས་ངེད་ཚོའི་ནང་དུ་རྩོམ་པ་ཞིག་གི་ཐབས་ལམ་སྟོན་པའི་ཆོས་ཉིད་ཅིག ང་ཚོའི་ལས་འཚོལ་བྱ་ཚིག་ཆེ་བའི་འཇིག་རྟེན་བརྡ་སྤྱི་ཚོགས་གསུམ་ཀྱི་ལས་འཚོལ་བ་ཅིག་སྟོན་ན་ཏེ།</abstract_bo>
      </paper>
    <paper id="39">
      <title>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</title>
      <author><first>Xilun</first><last>Chen</last></author>
      <author><first>Yu</first><last>Sun</last></author>
      <author><first>Ben</first><last>Athiwaratkun</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <author><first>Kilian</first><last>Weinberger</last></author>
      <doi>10.1162/tacl_a_00039</doi>
      <abstract>In recent years great success has been achieved in sentiment classification for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, thanks in part to the availability of copious annotated resources. Unfortunately, most languages do not enjoy such an abundance of <a href="https://en.wikipedia.org/wiki/Data_(computing)">labeled data</a>. To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist. ADAN has two discriminative branches : a sentiment classifier and an adversarial language discriminator. Both branches take input from a shared feature extractor to learn hidden representations that are simultaneously indicative for the classification task and invariant across languages. Experiments on Chinese and Arabic sentiment classification demonstrate that ADAN significantly outperforms state-of-the-art systems.</abstract>
      <pages>557–570</pages>
      <url hash="ad37da57">Q18-1039</url>
      <video href="https://vimeo.com/306129914" />
      <bibkey>chen-etal-2018-adversarial</bibkey>
      <pwccode url="https://github.com/ccsasuke/adan" additional="true">ccsasuke/adan</pwccode>
    <title_ar>شبكات المتوسطات العميقة للخصم لتصنيف المشاعر عبر اللغات</title_ar>
      <title_pt>Adversarial Deep Averaging Networks para classificação de sentimento entre idiomas</title_pt>
      <title_es>Redes de promedios profundos adversarios para la clasificación de sentimientos en varios idiomas</title_es>
      <title_fr>Réseaux de moyenne approfondie contradictoire pour la classification des sentiments multilingues</title_fr>
      <title_zh>用跨语情类者对抗性深度均网络</title_zh>
      <title_hi>क्रॉस-लिंगुअल भावना वर्गीकरण के लिए प्रतिकूल गहरी औसत नेटवर्क</title_hi>
      <title_ja>クロスリンガルセンチメント分類のための対照的な深層平均化ネットワーク</title_ja>
      <title_ru>Противоречивые сети глубокого усреднения для межъязыковой классификации настроений</title_ru>
      <title_ga>Líonraí Meánmhéadaithe Dearfacha Sárscéimhe d'Aicmiú Mothúchán Trastheangach</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Αντίθετα βαθιά δίκτυα μέσης για τη διαγλωσσική ταξινόμηση συναισθημάτων</title_el>
      <title_hu>Adversarial Deep Averaging Networks for Cross-Language Sentiment Classification</title_hu>
      <title_it>Reti di media profonda avversaria per la classificazione dei sentimenti cross-lingual</title_it>
      <title_kk>Кеңіл тілікті сентиметтік классификациялау үшін белсендік түпнұсқа аудару желілері</title_kk>
      <title_lt>Nepageidaujami giliai vidutiniškai klasifikuojami tarpkalbinio jutimo tinklai</title_lt>
      <title_mk>Name</title_mk>
      <title_ms>Name</title_ms>
      <title_ml>ക്രോസ്- ലിങ്ഗല്‍ സെന്റിമെന്‍റ് ക്ലാസിഷന്‍റിനുള്ള ആഴത്തിലുള്ള നെറ്റ്വര്‍ക്കുകള്‍</title_ml>
      <title_mt>Netwerks Avversi Medji Profondi għall-Klassifikazzjoni tas-Sentiment Translingwali</title_mt>
      <title_mn>Дөрвөн хэлбэрийн мэдрэмжтэй хувилбаруудын тусламжтай гүнзгий хувилбарууд</title_mn>
      <title_pl>Sieci głębokiego średniego przeciwnika dla klasyfikacji sentymentów międzyjęzycznych</title_pl>
      <title_ro>Rețele adverse de medie profundă pentru clasificarea sentimentelor translingvistice</title_ro>
      <title_sr>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</title_sr>
      <title_no>Rekursarial dyppa gjennomsnittsverkt for krysslingssentralklassifikasjon</title_no>
      <title_sv>Adversarial Deep Averaging Networks för Cross-Language Sentiment Classification</title_sv>
      <title_si>Name</title_si>
      <title_ta>கிருஸ்- Lingual உணர்வு வகைப்படுத்தலுக்கான முன்னேறும் ஆழமான சராசரிபார்வை வலைப்பின்னல்கள்</title_ta>
      <title_so>Isticmaalka fasaxa fasaxa luuqada</title_so>
      <title_ur>Cross-Lingual Sentiment Classification for Adversarial Deep Averaging Networks</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Các mạng lưới Lãnh thổ Giao Dịch Ngôn ngữ</title_vi>
      <title_bg>Рекламни мрежи за дълбока средна стойност за междулингвистична класификация на чувствата</title_bg>
      <title_hr>Adversarial Deep Average Networks for Cross-Lingual Sentiment Classification</title_hr>
      <title_nl>Adversarial Deep Average Networks voor Cross-Lingual Sentiment Classification</title_nl>
      <title_da>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</title_da>
      <title_id>Rangkaian Average Deep Adversarial untuk Klasifikasi Sentiment Cross-Lingual</title_id>
      <title_ko>다중 언어 정서 분류에 사용되는 대항식 깊이 평균 네트워크</title_ko>
      <title_de>Adversarial Deep Averageing Networks für Cross-Lingual Sentiment Classification</title_de>
      <title_fa>شبکه‌های تحقیقات عمیق مخالفت برای کلاس‌شناسی مجموعه‌های زیادی زبان</title_fa>
      <title_sw>Mtandao wa Kupoteza kwa Kipindi cha Kusini</title_sw>
      <title_af>Adversariale Deep Gemiddelde Netwerke vir Kruis- Linguaal Sentiment Klassifikasie</title_af>
      <title_tr>Çoklu Dilli Sentiment Klassifikasyon için elamlı derin Averaging Ağlar</title_tr>
      <title_sq>Rrjete kundërshtare të thella mesatare për klasifikimin e ndjenjave ndërgjuhësore</title_sq>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Միջլեզվային զգացմունքների դասակարգման հակառակ խորը միջին ցանցերը</title_hy>
      <title_az>Çərz-Dilli Sentiment Klasifikasyonu üçün Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</title_az>
      <title_bn>ক্রস- লিঙ্গুয়াল সেন্টিমেন্ট ক্লাসিশনের জন্য প্রাক্তন গভীর গভীর নেটওয়ার্ক</title_bn>
      <title_bs>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</title_bs>
      <title_cs>Adversariální hluboké průměrování sítí pro klasifikaci citových vnímání</title_cs>
      <title_ca>Redes adversaries de mitjana profundaper la classificació del sentiment translíngua</title_ca>
      <title_et>Keeleülese tunnete klassifitseerimise vastastikused sügavad keskmised võrgustikud</title_et>
      <title_fi>Adversarial Deep Averaging Networks for Cross-Language Sentiment Classification</title_fi>
      <title_jv>Advertorial deep Averaged Network Works for Kros-Lingual Sentiment</title_jv>
      <title_sk>Nekatere mreže globokega povprečja za medjezikovno klasifikacijo čustev</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>Name</title_he>
      <title_bo>Cross-Lingual Sentiment Classification ཡོད་པའི་ཚོགས་སྐྱོན་བརྗོད་དྲ་བ</title_bo>
      <abstract_ar>تم تحقيق نجاح كبير في السنوات الأخيرة في تصنيف المشاعر للغة الإنجليزية ، ويرجع الفضل في ذلك جزئيًا إلى توافر الموارد المشروحة الوفيرة. لسوء الحظ ، لا تتمتع معظم اللغات بمثل هذه الوفرة من البيانات المصنفة. لمعالجة مشكلة تصنيف المشاعر في اللغات منخفضة الموارد بدون بيانات مشروحة كافية ، نقترح شبكة Adversarial Deep Averaging Network (ADAN1) لنقل المعرفة المستفادة من البيانات المصنفة على لغة مصدر غنية بالموارد إلى لغات منخفضة الموارد حيث تكون البيانات غير المصنفة فقط يوجد. لدى ADAN فرعين تمييزيين: مصنف المشاعر ومميز اللغة العدائية. يأخذ كلا الفرعين مدخلات من مستخرج ميزة مشتركة لتعلم التمثيلات المخفية التي تشير في نفس الوقت إلى مهمة التصنيف وثابتة عبر اللغات. توضح التجارب التي أجريت على تصنيف المشاعر الصينية والعربية أن نظام ADAN يتفوق بشكل كبير على أحدث الأنظمة.</abstract_ar>
      <abstract_fr>Ces dernières années, un grand succès a été obtenu dans la classification des sentiments pour l'anglais, en partie grâce à la disponibilité de nombreuses ressources annotées. Malheureusement, la plupart des langues ne bénéficient pas d'une telle abondance de données étiquetées. Pour résoudre le problème de classification des sentiments dans les langues à faibles ressources sans données annotées adéquates, nous proposons un réseau ADAN1 (Adversarial Deep Averaging Network) pour transférer les connaissances acquises à partir de données étiquetées sur une langue source riche en ressources vers des langues à faibles ressources où seules des données non étiquetées existent. L'ADAN possède deux branches discriminantes : un classificateur de sentiments et un discriminateur de langage contradictoire. Les deux branches reçoivent les données d'un extracteur d'entités partagé pour apprendre les représentations cachées qui indiquent simultanément la tâche de classification et sont invariantes d'une langue à l'autre. Des expériences sur la classification des sentiments chinois et arabes montrent que l'ADAN surpasse largement les systèmes de pointe.</abstract_fr>
      <abstract_es>En los últimos años se ha logrado un gran éxito en la clasificación de sentimientos para el inglés, gracias en parte a la disponibilidad de abundantes recursos anotados. Desafortunadamente, la mayoría de los idiomas no cuentan con tanta abundancia de datos etiquetados. Para abordar el problema de la clasificación de opiniones en lenguajes de bajos recursos sin datos anotados adecuados, proponemos una Red de Promedios Profundos Adversarios (ADAN1) para transferir el conocimiento aprendido de los datos etiquetados en un idioma fuente rico en recursos a idiomas de bajos recursos donde solo existen datos sin etiqueta. ADAN tiene dos ramas discriminatorias: un clasificador de sentimientos y un discriminador de lenguaje contradictorio. Ambas ramas reciben información de un extractor de características compartidas para aprender representaciones ocultas que son simultáneamente indicativas de la tarea de clasificación e invariables en todos los idiomas. Los experimentos sobre la clasificación de sentimientos en chino y árabe demuestran que ADAN supera significativamente a los sistemas de última generación.</abstract_es>
      <abstract_pt>Nos últimos anos, grande sucesso foi alcançado na classificação de sentimentos para o inglês, graças em parte à disponibilidade de copiosos recursos anotados. Infelizmente, a maioria das linguagens não possui uma abundância de dados rotulados. Para resolver o problema de classificação de sentimento em linguagens de poucos recursos sem dados anotados adequados, propomos uma Adversarial Deep Averaging Network (ADAN1) para transferir o conhecimento aprendido de dados rotulados em uma linguagem de origem rica em recursos para linguagens de poucos recursos, onde apenas dados não rotulados existir. O ADAN tem dois ramos discriminativos: um classificador de sentimento e um discriminador de linguagem adversarial. Ambas as ramificações recebem entrada de um extrator de recursos compartilhado para aprender representações ocultas que são simultaneamente indicativas para a tarefa de classificação e invariáveis entre os idiomas. Experimentos com classificação de sentimento em chinês e árabe demonstram que o ADAN supera significativamente os sistemas de última geração.</abstract_pt>
      <abstract_hi>हाल के वर्षों में अंग्रेजी के लिए भावना वर्गीकरण में बड़ी सफलता हासिल की गई है, प्रचुर मात्रा में एनोटेटेड संसाधनों की उपलब्धता के लिए धन्यवाद। दुर्भाग्य से, अधिकांश भाषाएं लेबल किए गए डेटा की इतनी बहुतायत का आनंद नहीं लेती हैं। पर्याप्त एनोटेट किए गए डेटा के बिना कम-संसाधन भाषाओं में भावना वर्गीकरण समस्या से निपटने के लिए, हम संसाधन-समृद्ध स्रोत भाषा पर लेबल किए गए डेटा से सीखे गए ज्ञान को कम-संसाधन भाषाओं में स्थानांतरित करने के लिए एक प्रतिकूल डीप एवरेजिंग नेटवर्क (ADAN1) का प्रस्ताव करते हैं जहां केवल लेबल रहित डेटा मौजूद है। ADAN की दो भेदभावपूर्ण शाखाएं हैं: एक भावना क्लासिफायर और एक प्रतिकूल भाषा भेदभावपूर्ण। दोनों शाखाएं एक साझा सुविधा चिमटा से इनपुट लेती हैं ताकि छिपे हुए अभ्यावेदन ों को सीखा जा सके जो एक साथ वर्गीकरण कार्य के लिए संकेतक होते हैं और भाषाओं में अपरिवर्तनीय होते हैं। चीनी और अरबी भावना वर्गीकरण पर प्रयोगों से पता चलता है कि ADAN राज्य के अत्याधुनिक प्रणालियों को काफी बेहतर बनाता है।</abstract_hi>
      <abstract_ja>近年、膨大な注釈付きリソースの利用可能性のおかげで、英語のセンチメント分類で大きな成功を収めています。残念ながら、ほとんどの言語は、このような豊富なラベル付けされたデータを享受していません。適切な注釈付きデータを持たない低資源言語のセンチメント分類問題に取り組むために、リソース豊富なソース言語のラベル付きデータから学んだ知識を、ラベルなしデータのみが存在する低資源言語に転送するためのAdversarial Deep Averageaging Network （ ADAN 1 ）を提案する。アダンには、感情分類器と対立言語識別器という2つの差別的な分岐がある。両方の分岐は、共有機能抽出器から入力を受けて、分類タスクのために同時に指示され、言語間で不変である隠された表現を学習する。中国語とアラビア語の感情分類に関する実験は、ADANが最先端のシステムを大幅に上回っていることを示しています。</abstract_ja>
      <abstract_zh>近年以来,英语情类取巨大成功,此必归功于带注之资也。 不幸者,多言无此丰盛之数。 为解不足注数者低资源言语情类,吾发一对抗性深均网络(ADAN1),将资源丰衍之源,从标数中学之知移于未标数之低资源。 ADAN有两歧视性:情分器对抗性言分器。 此二支者,皆取输于共享提取器,以学隐匿之文,以示分类、跨言之不变性。 文阿拉伯情类之实验,ADAN显优于先进之统。</abstract_zh>
      <abstract_ru>В последние годы был достигнут большой успех в классификации настроений для английского языка, отчасти благодаря наличию обширных аннотированных ресурсов. К сожалению, большинство языков не пользуются таким изобилием маркированных данных. Чтобы решить проблему классификации настроений на языках с низким уровнем ресурсов без адекватных аннотированных данных, мы предлагаем Соперническую сеть глубокого усреднения (ADAN1) для переноса знаний, полученных из помеченных данных на богатом ресурсами исходном языке, на языки с низким уровнем ресурсов, где существуют только немеченные данные. АДАН имеет две дискриминирующие ветви: классификатор настроений и состязательный дискриминатор языка. Обе ветви получают входные данные от общего экстрактора признаков для изучения скрытых представлений, которые одновременно указывают на задачу классификации и являются инвариантными между языками. Эксперименты по классификации китайских и арабских настроений показывают, что АДАН значительно превосходит современные системы.</abstract_ru>
      <abstract_ga>Le blianta beaga anuas tá an-rath ar aicmiú meon an Bhéarla, mar gheall go páirteach ar infhaighteacht acmhainní anótáilte iomadúla. Ar an drochuair, níl an oiread sin sonraí lipéadaithe ag formhór na dteangacha. Chun dul i ngleic leis an bhfadhb aicmithe meon i dteangacha íseal-acmhainne gan sonraí leordhóthanacha anótáilte, molaimid Líonra Meánmhéadaithe Doimhneacht Sáraíochta (ADAN1) chun an t-eolas a foghlaimíodh ó shonraí lipéadaithe ar theanga foinse atá saibhir ó thaobh acmhainní a aistriú go teangacha íseal-acmhainne nach bhfuil iontu ach sonraí neamhlipéadaithe. ann. Tá dhá bhrainse idirdhealaitheacha ag ADAN: aicmitheoir meon agus idirdhealaitheoir sáraíochta teanga. Glacann an dá bhrainse ionchur ó ghné-eastóscadh comhroinnte chun léirithe ceilte a fhoghlaim atá táscach go comhuaineach don tasc aicmithe agus athróg trasna teangacha. Léiríonn turgnaimh ar aicmiú meon na Síne agus na hAraibe go bhfuil i bhfad níos fearr ag ADAN na córais is nua-aimseartha.</abstract_ga>
      <abstract_hu>Az elmúlt években nagy sikert értek el az angol érzelmek osztályozásában, részben a bőséges jegyzetelt források rendelkezésre állásának köszönhetően. Sajnos a legtöbb nyelv nem élvez ilyen sok címkés adatot. Az alacsony erőforrású nyelveken a hangulatosztályozás problémájának kezelése érdekében, megfelelő jegyzetelt nélkül, javasoljuk egy Adversarial Deep Averaging Network (ADAN1) létrehozását, amely az erőforrásokban gazdag forrásnyelveken megjelölt adatokból származó ismereteket alacsony erőforrású nyelvekre továbbítja, ahol csak címke nélküli adatok léteznek. Az ADAN két diszkriminatív ága van: egy érzelmi osztályozó és egy ellenséges nyelvi diszkriminatív. Mindkét ág egy megosztott szolgáltatás-kivonótól származó bemeneteket vesz, hogy megtanulják a rejtett reprezentációkat, amelyek egyidejűleg indikatívak az osztályozási feladatra és invariánsak a nyelvek között. A kínai és arab hangulatosztályozással kapcsolatos kísérletek azt mutatják, hogy az ADAN jelentősen felülmúlja a legkorszerűbb rendszereket.</abstract_hu>
      <abstract_ka>ბოლოდან წლის შემდეგ დიდი წარმატები ინგლისური კლასიფიკაციაში დაიწყება, მადლობა კონფიკაციური ინგლისური წარმატებისთვის. მართლად, უფრო მეტი ენები არ იყვანენ რამდენიმე მონაცემები. სენტიმენტების კლასიფიკაციის პრობლემა მარტივი რესურსების ენაში, მარტივი ანოტირებული მონაცემები არაფერად, ჩვენ მინდომა კონტერაციალური სისტემა (ADAN1) გადავიტანოთ მონაცემები, რომელიც მარტივი რესურსების მხარეს ADAN აქვს ორი დისკრიმინატიური ქვეყნები: სენტიმენტის კლასიფიკაციატორი და განსაკუთრებული ენის დისკრიმინატორი. ორივე საქმედები იყენებენ გაყოფილი ფუნქციების ექსტრექტორიდან დასწავლა დაკლექტირებული რესპეცენტაციები, რომლებიც ერთადერთად კლასიფიკაციის რაოდენობისთვის და ვკჟოვპთმვნრთ ჱა კთრაიჟკთ თ აპაბჟკთ ჟვნრთმვნრ კლაჟთტთკაუთწ ოჲკაჱგარ, ფვ ADAN ვ მნჲდჲ ნაოპაგთლ ჟთჟრვმთრვ ნა ჟვჟრვმარა.</abstract_ka>
      <abstract_kk>Соңғы жылдар ағылшын тілінде көптеген сезімдердің көптеген сәттілігі жеткізілді, көптеген жаңалық ресурстардың жеткізіліктеріне рахмет. Кешіріңіз, тілдердің көпшілігі жарлық деректерінің көпшілігін көрсетпейді. Ресурстардың бағасы тілдерінің мәселелерін таңдау үшін керек мәліметтеріңіз болмаса, біз тек жазылмаған деректер тілдеріне жазылған мәліметтерді ресурстардың бағасы тілдерінен жазылған мәліметтерді таңдау үшін "Adversarial Deep Averaging Network" (ADAN1) деп таң ADAN екі дискриминациялық бөлігі бар: сезімдік классификация және қарсы тіл дискриминаторы. Екі бөлік бөлікті қасиеттерден кіріс береді. Бірақ бөліктеу тапсырмасын және тілдерден басқа қасиеттерді көрсету үшін жасырын тапсырмаларды үйрену үшін. Қытай және Араб сезімдерін шектеу тәжірибесінің ADAN әртүрлі әртүрлі жүйелердің күйіне жетпейді деп көрсетеді.</abstract_kk>
      <abstract_el>Τα τελευταία χρόνια έχει επιτευχθεί μεγάλη επιτυχία στην ταξινόμηση συναισθημάτων για τα αγγλικά, εν μέρει χάρη στη διαθεσιμότητα άφθονων σχολιασμένων πόρων. Δυστυχώς, οι περισσότερες γλώσσες δεν απολαμβάνουν μια τέτοια αφθονία ετικετών δεδομένων. Για την αντιμετώπιση του προβλήματος ταξινόμησης συναισθημάτων σε γλώσσες χαμηλής περιεκτικότητας χωρίς επαρκή σχολιασμένα δεδομένα, προτείνουμε ένα Δίκτυο Βαθύ Μέσου Μέσου Δυναμικού (για τη μεταφορά των γνώσεων που αποκτήθηκαν από τα επισημασμένα δεδομένα σε μια γλώσσα πηγής πλούσια σε πόρους σε γλώσσες χαμηλής περιεκτικότητας στις οποίες υπάρχουν μόνο δεδομένα χωρίς σήμανση. Το ADAN έχει δύο διακριτικούς κλάδους: έναν ταξινομητή συναισθημάτων και έναν αντίπαλο γλωσσικό διαχωριστή. Και οι δύο κλάδοι λαμβάνουν εισαγωγή από ένα κοινόχρηστο πρόγραμμα εξαγωγής χαρακτηριστικών για να μάθουν κρυφές αναπαραστάσεις που είναι ταυτόχρονα ενδεικτικές για την εργασία ταξινόμησης και αμετάβλητες μεταξύ των γλωσσών. Τα πειράματα για την ταξινόμηση κινέζικων και αραβικών συναισθημάτων δείχνουν ότι η ADAN ξεπερνά σημαντικά τα σύγχρονα συστήματα.</abstract_el>
      <abstract_lt>Pastaraisiais metais labai sėkmingai pasiekėme jausmų klasifikaciją anglų kalba, iš dalies dėl to, kad turima daug užrašytų išteklių. Deja, dauguma kalbų neturi tokių ženklintų duomenų. To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist.  ADAN turi dvi diskriminacines šakas: jausmų klasifikatorius ir priešingos kalbos diskriminatorius. Abu filialai naudoja bendrų savybių ekstraktoriaus įnašus, kad išsiaiškintų paslėptus atvaizdus, kurie vienu metu rodo klasifikavimo užduotį ir yra skirtingose kalbose. Kinijos ir arabų jautrumo klasifikavimo eksperimentai rodo, kad ADAN gerokai viršija modernias sistemas.</abstract_lt>
      <abstract_it>Negli ultimi anni è stato raggiunto un grande successo nella classificazione sentiment per l'inglese, anche grazie alla disponibilità di abbondanti risorse annotate. Purtroppo, la maggior parte delle lingue non gode di una tale abbondanza di dati etichettati. Per affrontare il problema della classificazione del sentiment in linguaggi a basso contenuto di risorse senza adeguati dati annotati, proponiamo una Adversarial Deep Averaging Network (ADAN1) per trasferire le conoscenze apprese dai dati etichettati su un linguaggio sorgente ricco di risorse a lingue a basso contenuto di risorse in cui esistono solo dati non etichettati. ADAN ha due rami discriminatori: un classificatore di sentimenti e un discriminatore di linguaggio avversario. Entrambi i rami prendono input da un estrattore di funzionalità condiviso per imparare rappresentazioni nascoste che sono contemporaneamente indicative per l'attività di classificazione e invarianti tra le lingue. Esperimenti sulla classificazione del sentiment cinese e arabo dimostrano che ADAN supera significativamente i sistemi all'avanguardia.</abstract_it>
      <abstract_mk>Во последниве години се постигна голем успех во класификацијата на чувствата за англиски, делумно благодарение на достапноста на кописки анотирани ресурси. За жал, повеќето јазици не уживаат во толку многу обележани податоци. За да се реши проблемот со класификацијата на чувствата на јазиците со ниски ресурси без соодветни анотирани податоци, предлагаме противничка длабока просечна мрежа (ADAN1) за пренесување на знаењето научиено од означени податоци на јазик од извор богат со ресурси на јазици со ниски ресурси каде што постојат само неозначени под АДАН има две дискриминативни гранки: класификатор на чувства и дискриминатор на противник јазик. Двете гранки земаат влог од споделениот екстрактор на карактеристики за да научат скриени претставувања кои се истовремено индикативни за класификациската задача и инваријантни низ јазиците. Експериментите на класификацијата на кинеските и арапските чувства покажуваат дека АДАН значително ги надминува најдобрите системи.</abstract_mk>
      <abstract_ms>In recent years great success has been achieved in sentiment classification for English, thanks in part to the availability of copious annotated resources.  Malangnya, kebanyakan bahasa tidak menikmati banyak data yang ditabel. Untuk mengatasi masalah klasifikasi perasaan dalam bahasa sumber rendah tanpa data yang dicatat yang cukup, kami cadangkan Rangkaian Average Deep Adversarial (ADAN1) untuk memindahkan pengetahuan yang dipelajari dari data yang dicatat pada bahasa sumber kaya sumber ke bahasa sumber rendah di mana hanya data tidak dicatat wujud. ADAN mempunyai dua cabang yang mendiskriminasi: pengklasifikasi perasaan dan pengdiskriminasi bahasa lawan. Kedua-dua cabang mengambil input dari pengekstraktor ciri-ciri berkongsi untuk belajar perwakilan tersembunyi yang bersamaan menunjukkan untuk tugas klasifikasi dan invarian melalui bahasa. Experiments on Chinese and Arabic sentiment classification demonstrate that ADAN significantly outperforms state-of-the-art systems.</abstract_ms>
      <abstract_mn>Сүүлийн жилүүдэд Англи хэлний сэтгэл хөдлөлийн хуваалцаанд гайхалтай амжилт гарч ирсэн. Нэг хэсэгт хамгийн сайхан сэтгэл хөдлөлийн баялаг гарч ирсэн. Харамсалтай нь ихэнх хэл тэмдэглэгдсэн өгөгдлийн маш их дуртай байхгүй. Маш бага боловсролын хэл дээрх мэдрэмжүүдийн хуваалтын асуудлыг зохицуулахын тулд бид зөвхөн тайлбарлаагүй өгөгдлийн хэл дээр сурсан мэдлэгийг бага боловсролын хэл дээр шилжүүлэх боломжтой мэдлэг (ADAN1) гэдэгт санал өгдөг. АДАН-д хоёр ялгаатай хуваагдах загвар байна: сэтгэл хөдлөлийн хуваагдагч, эсрэг хэл хуваагдагч. Хоёр захиа хоёулаа нь хуваалцаагүй хуваалцагч-ээс оруулалт авдаг. Хүмүүс хэл дахь нууцаагүй үзүүлэлтийг ойлгохын тулд хуваалцаагүй ажлыг харуулдаг. Хятад болон Араб мэдрэмжүүдийн хуваалтын туршилт нь АДАН-ын урлагийн тогтолцооны системийг маш чухал үр дүнтэй болгодог гэдгийг харуулдаг.</abstract_mn>
      <abstract_pl>W ostatnich latach osiągnięto ogromny sukces w klasyfikacji sentymentów dla języka angielskiego, częściowo dzięki dostępności bogatych zasobów adnotacyjnych. Niestety większość języków nie cieszy się taką obfitością etykietowanych danych. Aby rozwiązać problem klasyfikacji sentymentów w językach o niskich zasobach bez odpowiednich adnotacji, proponujemy sieć Adversarial Deep Average Network (ADAN1), aby przenieść wiedzę wyciągniętą z etykietowanych danych w języku źródłowym bogatym w zasoby do języków o niskich zasobach, w których istnieją tylko dane nieoznakowane. ADAN ma dwie gałęzie dyskryminacyjne: klasyfikator sentymentów i przeciwny dyskryminator językowy. Obie gałęzie biorą dane ze wspólnego ekstraktora funkcji, aby uczyć się ukrytych reprezentacji, które są jednocześnie wskazujące na zadanie klasyfikacji i niezmienne w różnych językach. Eksperymenty na temat klasyfikacji sentymentów chińskich i arabskich pokazują, że ADAN znacznie przewyższa najnowocześniejsze systemy.</abstract_pl>
      <abstract_ro>În ultimii ani s-a obținut un mare succes în clasificarea sentimentelor pentru limba engleză, datorită în parte disponibilității resurselor adnotate abundente. Din păcate, majoritatea limbilor nu se bucură de o astfel de abundență de date etichetate. Pentru a aborda problema clasificării sentimentelor în limbi cu resurse reduse fără date adnotate adecvate, propunem o Rețea Adversarial Deep Averaging (ADAN1) pentru a transfera cunoștințele învățate din datele etichetate pe o limbă sursă bogată în resurse scăzute în limbi cu resurse reduse, unde există numai date nelimitate. ADAN are două ramuri discriminatorii: un clasificator de sentimente și un discriminator de limbaj adversar. Ambele ramuri iau input de la un extractor de caracteristici partajate pentru a învăța reprezentări ascunse care sunt simultan indicative pentru activitatea de clasificare și invariante în toate limbile. Experimentele privind clasificarea sentimentelor chinezești și arabe demonstrează că ADAN depășește semnificativ sistemele de ultimă generație.</abstract_ro>
      <abstract_ml>അടുത്ത കൊല്ലങ്ങളില്‍ ഇംഗ്ലീഷിന്റെ വിവേകത ക്ലാസ്ഫിക്ഷനില്‍ വളരെ വിജയം പ്രാപിച്ചിരിക്കുന്നു. നിര്‍ഭാഗ്യവശാല്‍, അധികപേരും ഭാഷകള്‍ക്ക് ഇത്രയും അധികമായ വിവരങ്ങള്‍ ആസ്വദിക്കുന്നില്ല. ആവശ്യമായ വിവരങ്ങളൊന്നുമില്ലാതെ കുറഞ്ഞ വിഭവങ്ങളുടെ വിഭവങ്ങളുടെ വിഭവങ്ങളുടെ ക്ലാസ്ഫിക്കല്‍ പ്രശ്നമുണ്ടാക്കാന്‍, വിവരങ്ങളില്‍ നിന്നും പഠിച്ച വിവരങ്ങള്‍ ലേബെല്‍ഡ് ചെയ്ത വിവരങ്ങളി ADAN has two discriminative branches: a sentiment classifier and an adversarial language discriminator.  രണ്ടു ശാഖകളും പങ്കുചേര്‍ന്ന പ്രതിനിധികളില്‍ നിന്നും ഒളിഞ്ഞിരിക്കുന്ന പ്രതിനിധികള്‍ പഠിക്കുന്നതിനായി പങ്കെടുക്കുന് ചൈനീസും അറബിക വികാരണങ്ങളുടെയും പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു ADAN-ലെ സ്റ്റേറ്റ് സിസ്റ്റേറ്റ് സംവിധ</abstract_ml>
      <abstract_mt>F’dawn l-aħħar snin intlaħaq suċċess kbir fil-klassifikazzjoni tas-sentimenti għall-Ingliż, parzjalment grazzi għad-disponibbiltà ta’ riżorsi annotati kopji. Sfortunatament, il-biċċa l-kbira tal-lingwi ma jgawdux minn tali abbundanza ta’ dejta ttikkettata. To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist.  L-ADAN għandu żewġ fergħat diskriminatorji: klassifikatur tas-sentimenti u diskriminatur tal-lingwa avversarja. Iż-żewġ fergħat jieħdu input minn estrattur ta’ karatteristiċi kondiviżi biex jitgħallmu rappreżentazzjonijiet moħbija li huma simultanjament indikattivi għall-kompitu ta’ klassifikazzjoni u invarjanti fil-lingwi kollha. L-esperimenti dwar il-klassifikazzjoni tas-sentimenti Ċiniżi u Għarab juru li l-ADAN huwa ogħla b’mod sinifikanti mis-sistemi l-aktar avvanzati.</abstract_mt>
      <abstract_sr>Za poslednje godine, veliki uspeh je postignut u klasifikaciji sentimenta za engleski, zahvaljujući dio dostupnosti kopijskih annotiranih resursa. Nažalost, većina jezika ne uživaju u tolikoj opskrbi označenih podataka. Da bi se riješili problem klasifikacije sentiment a na jezicima niskih resursa bez odgovarajućih annotiranih podataka, predlažemo saveznu mrežu za duboku Averagaciju (ADAN1) da prebacimo znanje koje su naučene iz etiketiranih podataka o jeziku izvora bogatih resursa na jezike niskih resursa gde postoje samo podaci koji nisu obezbeđeni. ADAN ima dve diskriminacije: klasifikator sentiment a i diskriminacija protiv jezika. Obje grane uzimaju ulaz iz zajedničkog ekstraktora karakteristike kako bi naučili skrivene predstave koje su istovremeno indikativne za klasifikacijski zadatak i invariant na jezicima. Eksperimenti o klasifikaciji kineskih i arapskih sentimenta pokazuju da ADAN značajno iznosi državne umjetne sisteme.</abstract_sr>
      <abstract_no>I løpet av siste år er det oppnådd stor suksess i sentimentklassifikasjon for engelsk, takk i delvis på tilgjengeligheten av koplare oppmerkte ressursar. Dei fleste språka er likevel ikkje så mange merkelige data. For å løysa sentimentklassifikasjonspråket i låg ressursspråk utan tilgjengelege merknader, foreslår vi eit Adversarial Deep Averaging Network (ADAN1) for å overføra kunnskapen som er lært frå merknadene data på ein ressursryk kjeldespråk til låg ressursspråk der berre ikkje er merknadene data finst. ADAN har to diskriminasjonske greiner: ein sentimentklassifiserer og ein diskriminasjon av mottalespråk. Bege grener tar inndata frå ein delt funksjonsekstraktor for å lære gøymde representasjonar som er samtidig indikator for klassifikasjonspråket og invariant over språk. Eksperimentar på kinesisk og arabisk sentimentklassifikasjon viser at ADAN utfører betydelig tilstandssystemet for kunsten.</abstract_no>
      <abstract_si>අන්තිම අවුරුදු වලින් ගොඩක් සාර්ථක විශ්වාසයෙන් ඉංග්‍රීසියාව සඳහා ස්තූතියි, කොපියෙන් ප්‍රතිකාරියා අවාසනාවට, ගොඩක් භාෂාවල් එච්චර ලෙබෙල් තොරතුරු ගොඩක් සතුටු නෑ. ප්‍රශ්න භාෂාවට අඩුම සම්බන්ධ භාෂාවට ප්‍රශ්නයක් විදිහට අඩුම සම්බන්ධ විදිහට තොරතුරු නැති විදිහට ප්‍රශ්නයක් කරන්න, අපි ප්‍රශ්නයක් සම්බන්ධ විදිහ ADAN වලට විශේෂ ක්‍රියාත්මක දෙකක් තියෙනවා: විශේෂ ක්‍රියාත්මක සහ විරෝධ භාෂාවක් විශේෂකයෙක දෙන්නම් විශේෂණ වැඩක් සහ භාෂාවක් විසින් විශේෂණයක් ඉගෙන ගන්න. චීනි සහ අරාබි දේවල් විශ්වාසයේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට ADAN ගොඩක් විශේෂයෙන් විශ්වාස කරන</abstract_si>
      <abstract_sv>Under de senaste åren har stora framgångar uppnåtts i sentimentklassificeringen för engelska, delvis tack vare tillgången till rikliga kommenterade resurser. Tyvärr har de flesta språk inte ett sådant överflöd av märkta data. För att ta itu med problemet med sentimentklassificering på språk med låg resurs utan tillräckliga kommenterade data föreslår vi ett Adversarial Deep Averaging Network (ADAN1) för att överföra den kunskap som lärts från märkta data på ett resursrikt källspråk till språk med låg resurs där endast obemärkta data finns. ADAN har två diskriminerande grenar: en sentimentklassificerare och en motstridig språkdiskriminerare. Båda grenarna tar input från en delad funktionsextraktor för att lära sig dolda representationer som samtidigt är vägledande för klassificeringsuppgiften och invariant över språk. Experiment på kinesisk och arabisk sentimentklassificering visar att ADAN avsevärt överträffar de senaste systemen.</abstract_sv>
      <abstract_so>Sannadihii ugu dambeeyey waxaa liibaanay liibaan weyn oo ku qoran fasalka ingiriiska, qeyb ahaan waxaa lagu mahad naqayaa helitaanka maalmaha dhibaatada badan. Nasiib la’aanta, luuqadaha badankoodu ma raaxaystaan macluumaad badan oo la qoray. Si a an u tacliino dhibaatada fasixinta oo ku qoran luqadaha hoose-resource iyadoon ku filan macluumaad ku filan, waxaynu u proposaynaa shabakadda Adversarial Deep Averaging Network (ADAN1) si aan aqoonta loo wareejiyo macluumaadka la qoray oo lagu qoray luqada sourceed-rich luqada hoose-resource where only data aan la labeled exist. ADAN waxay leeyihiin laba laamo oo takoorista ah: takoorista fikrada iyo takoorista luqada ka geesta ah. Labada laamood waxay ka soo bandhigaan waxyaabaha la xiriiray si ay u bartaan noocyada qarsoon, kuwaas oo isla markaasna lagu sawiraa shaqada fasaxda iyo kuwa luqadaha ku soo gala. Imtixaanka ku saabsan fikrada Shiino iyo Carabi waxay muujiyaan in ADAN si muhiim ah u muujiyaa nidaamka farshaxanka.</abstract_so>
      <abstract_ta>சமீபத்தில் ஆங்கிலத்திற்கான உணர்வு வகைப்படுத்தலில் பெரிய வெற்றி பெற்றுவிட்டது, மிகவும் பெரிய விருப்பமான வளங்கள் கி துரதிர்ஷ்டவசமாக, பெரும்பாலான மொழிகள் இத்தகைய குறிப்பிட்ட தகவல்களை அனுபவிக்கவில்லை. குறைந்த மூலத்தின் வகைப்படுத்தல் பிரச்சினைகளை பொருத்துவதற்கு தேவையான அறிவிப்பு தகவல் இல்லாமல் குறைந்த மூலத்தின் பிரச்சினைகளை எதிர்பார்க்க, மேலும் ஆழமான ஆழமான சரிவு வலைப்பின்ன ADAN கிடைக்கும் இரண்டு வித்தியாசமான கிளைகள் உள்ளன: ஒரு உணர்வு வகுப்பாளர் மற்றும் ஒரு எதிர்மறை மொழி வகுப்பாளர். இரண்டு கிளைகளும் ஒரு பகிர்ந்த பண்புக்கூடிய வெளியீட்டிலிருந்து உள்ளீடுகளை எடுத்து மறைந்துள்ள பிரிவுகளை கற்றுக் கொள்ளும சீன மற்றும் அரபி உணர்வு வகைப்படுத்தல் சோதனைகள் காண்பிக்கிறது ADAN முக்கியமான கலைப்பு அமைப்புகளின் நிலைமைகளை வெளியேற்ற</abstract_ta>
      <abstract_ur>اگلے سالوں میں بہت بڑی کامیابی انگلیسی کے لئے احساس کلاسیفوں میں حاصل کی گئی ہے، کچھ حصہ سے شکریہ اس طرح کہ انگلیسی کے ذریعہ بہت زیادہ مضبوط رسولوں کے موجود ہیں۔ بدبختی، اکثر زبانیں ایسی بہت سی لکھی ہوئی ڈاٹی کے مزے نہیں لگتے۔ اس لئے کہ کم منطقی زبانوں میں حسن کا کلاسی مسئلہ حل کریں، بغیر مناسب اپنا اپنا اپنا اپنا اپنا ڈیٹا، ہم ایک اپنا اپنا اپنا اپنا اپنا نیٹورک (ADAN1) پیشنهاد کریں کہ اس علم کو لیبل کیا گیا ہے جو ایک سروست منطقی سورج زبان پر لکھی ہوئی ڈیٹا سے کم ADAN کے دو مختلف شاخہ ہیں: ایک احساس کلاسیر اور ایک مخالف زبان تقسیم کرنے والا۔ دونوں شاخہ ایک مشترک فائدہ اضافہ کرنے والے سے ایمپیٹ لیتے ہیں کہ چھپائے نمایش سکھاتے ہیں جو ایک دفعہ کلاسپیٹ کے کام اور زبانوں میں غیر اضافہ کرنے والے ہیں. چینی اور عربی احساسات کلاسپیٹ کی تجربے دکھاتے ہیں کہ ADAN بہت اچھی طرح آرتی سیستموں سے کام نہیں لیتا۔</abstract_ur>
      <abstract_uz>Yaqinda ko'pchilik yillarda ingliz tilida juda katta muvaffaqiyatli bo'ldi, bir qismda ko'p tashkilotli rasmlarni qo'llash uchun rahmat. Afsuski, ko'pchilik tillar bu ko'plab yozilgan maʼlumot ko'proq emas. @ info: status ADAN'da ikkita ta'minlovchi darajalar bor: hissiyotni ajratuvchi va diqqat tilni ajratish. @ info: whatsthis Name</abstract_uz>
      <abstract_vi>Trong những năm gần đây, tỉ lệ tình cảm dành cho người Anh đã thành công rất lớn nhờ có rất nhiều nguồn tài nguyên được ghi chép. Tiếc thay, hầu hết ngôn ngữ không có nhiều dữ liệu được dán nhãn như vậy. Để giải quyết vấn đề phân loại cảm xúc trong ngôn ngữ ít tài nguyên mà không có dữ liệu được ghi chú đầy đủ, chúng tôi đề nghị một mạng lưới Averaging Deep (ADAN1) để chuyển những kiến thức được học từ các dữ liệu ghi trên ngôn ngữ nguồn giàu tài nguyên sang ngôn ngữ thấp nguồn mà chỉ có những dữ liệu chưa được ghi rõ. ADAN có hai loại riêng biệt: người phân loại cảm xúc và người phân biệt ngôn ngữ đối nghịch. Cả hai chi nhánh được cung cấp từ một chuyên gia trích xuất có tính năng chia sẻ để học các biểu hiện ẩn định cùng lúc cho nhiệm vụ phân loại và xâm lược ngôn ngữ khác nhau. Thí nghiệm về phân loại cảm xúc Trung Quốc và Ả Rập cho thấy ADAN đạt được hệ thống hiện đại.</abstract_vi>
      <abstract_bg>През последните години е постигнат голям успех в класификацията на сантимента за английски език, отчасти благодарение на наличието на изобилие от анотирани ресурси. За съжаление, повечето езици не се радват на такова изобилие от етикетирани данни. За да се справим с проблема с класификацията на сентимента при езици с ниски ресурси без адекватни анотирани данни, предлагаме мрежа за рекламна дълбока средна стойност (АДАН1), която да прехвърли знанията, научени от етикетирани данни на богат на ресурси изходен език на езици с ниски ресурси, където съществуват само неетикетирани данни. АДАН има две дискриминационни клонове: класификатор на чувствата и дискриминатор на конкуренцията на езика. И двата клона получават вход от споделен екстрактор на функции, за да научат скрити представи, които едновременно са индикативни за задачата за класификация и инвариращи между езиците. Експериментите с китайската и арабската класификация показват, че АДАН значително превъзхожда най-съвременните системи.</abstract_bg>
      <abstract_hr>Za poslednje godine postignut je veliki uspjeh u klasifikaciji osjećaja za engleski, zahvaljujući djelomično dostupnosti kopijskih annotiranih resursa. Nažalost, većina jezika ne uživaju u takvoj opskrbi označenih podataka. Da bi se riješili problem klasifikacije osjećaja na jezicima niskih resursa bez odgovarajućih annotiranih podataka, predlažemo poručničku prosječnu mrežu (ADAN1) da prenese znanja koje su naučene iz označenih podataka o jeziku s bogatim izvorima resursa na jezicima niskih resursa, gdje postoje samo neizbiljni podaci. ADAN ima dvije diskriminacije: klasifikator osjećaja i diskriminacija protiv jezika. Obje grane uzimaju ulaz iz zajedničkog ekstraktora karakteristike kako bi naučili skrivene predstave koje su istovremeno indikativne za zadatak klasifikacije i invariant na jezicima. Eksperimenti o klasifikaciji kineskih i arapskih osjećaja pokazuju da ADAN značajno iznosi državne umjetničke sustave.</abstract_hr>
      <abstract_nl>De afgelopen jaren is er veel succes geboekt in sentimentclassificatie voor het Engels, mede dankzij de beschikbaarheid van overvloedige geannoteerde bronnen. Helaas hebben de meeste talen niet zo'n overvloed aan gelabelde gegevens. Om het sentimentclassificatieprobleem in low-resource talen zonder voldoende geannoteerde gegevens aan te pakken, stellen we een Adversarial Deep Average Network (ADAN1) voor om de kennis die is geleerd van gelabelde gegevens over te dragen op een bronrijke brontaal naar low-resource talen waar alleen onbetekende gegevens bestaan. ADAN heeft twee discriminerende takken: een sentimentclassificator en een tegenstrijdige taaldiscrimineraar. Beide branches nemen input van een gedeelde feature extractor om verborgen representaties te leren die tegelijkertijd indicatief zijn voor de classificatietaak en onveranderd zijn tussen talen. Experimenten met Chinese en Arabische sentimentclassificatie tonen aan dat ADAN aanzienlijk beter presteert dan state-of-the-art systemen.</abstract_nl>
      <abstract_da>I de senere år er der opnået stor succes i sentiment klassificering for engelsk, delvis takket være tilgængeligheden af rigelige kommenterede ressourcer. Desværre nyder de fleste sprog ikke sådan en overflod af mærkede data. For at løse problemet med sentimentklassifikation på sprog med lav ressource uden tilstrækkelige annoterede data foreslår vi et Adversarial Deep Averaging Network (ADAN1) til at overføre den viden, der er lært fra mærkede data på et ressourcerigt kildesprog til sprog med lav ressource, hvor der kun findes ikke-mærkede data. ADAN har to forskelsbehandling grene: en følelsesklassificator og en modstridende sprogdiskriminerer. Begge grene tager input fra en delt feature extractor for at lære skjulte repræsentationer, der samtidig er vejledende for klassificeringsopgaven og invariant på tværs af sprog. Eksperimenter med kinesisk og arabisk stemning klassificering viser, at ADAN betydeligt overgår state-of-the-art systemer.</abstract_da>
      <abstract_fa>در سال های اخیر موفقیت بزرگی در محرمانه احساسات برای انگلیسی به دست آورده شده است، بخشی از دسترسی منابع نازل شده است. متاسفانه، بیشتر زبانها از چنین بسیاری از اطلاعات مورد علامت لذت نمی برند. برای حل کردن مشکل تجارت احساسات در زبانهای کم منبع بدون داده‌های اظهار قابل توجه، یک شبکه تجارت عمیق (ADAN1) پیشنهاد می‌کنیم تا علم یافته از داده‌های برچسب‌شده بر زبان منبع منبع کم به زبان‌های منبع کم که تنها داده‌های بدون استفاده وجود دارند. ADAN دو شاخه جدایی دارد: یک محرمانه‌ی احساسات و یک جدایی‌کننده زبان دشمنی. هر دو شاخه از یک خارج کننده‌ی ویژه‌های مشترک وارد می‌شوند تا نمایش‌های مخفی را یاد بگیرند که همزمان برای وظیفه‌ی ویژه‌های مخفی و بی‌نیاز در زبانها نشان می‌دهند. تجربه‌های مختصات احساسات چینی و عربی نشان می‌دهند که ADAN بسیار زیادی سیستم‌های هنری را انجام می‌دهد.</abstract_fa>
      <abstract_de>In den letzten Jahren wurden große Erfolge in der Stimmungsklassifizierung für Englisch erzielt, unter anderem dank der Verfügbarkeit reichlich kommentierter Ressourcen. Leider genießen die meisten Sprachen nicht eine solche Fülle an markierten Daten. Um das Problem der Stimmungsklassifizierung in ressourcenarmen Sprachen ohne adäquate annotierte Daten anzugehen, schlagen wir ein Adversarial Deep Averaging Network (ADAN1) vor, um das aus markierten Daten gewonnene Wissen auf eine ressourcenreiche Quellsprache in ressourcenarme Sprachen zu übertragen, in denen nur ungekennzeichnete Daten existieren. ADAN hat zwei diskriminierende Zweige: einen Stimmungsklassifikator und einen gegensätzlichen Sprachdiskriminator. Beide Zweige verwenden Eingaben von einem gemeinsamen Feature Extractor, um versteckte Darstellungen zu lernen, die gleichzeitig indikativ für die Klassifizierungsaufgabe sind und über Sprachen hinweg invariant sind. Experimente zur Klassifizierung chinesischer und arabischer Stimmungen zeigen, dass ADAN moderne Systeme deutlich übertrifft.</abstract_de>
      <abstract_ko>최근 몇 년 동안 영어 감정 분류는 큰 성공을 거두었고 이 부분은 풍부한 주석 자원 덕분이다.불행하게도, 대부분의 언어는 이렇게 풍부한 표기 데이터를 누리지 못한다.저자원 언어에서 데이터를 충분히 주석하지 못한 감정 분류 문제를 해결하기 위해 우리는 자원이 풍부한 원시 언어의 표기 데이터에서 배운 지식을 표기하지 않은 데이터만 있는 저자원 언어로 옮기는 대항식 심도 평균 네트워크(ADAN1)를 제시했다.ADAN은 두 가지 구분이 있는데 그것이 바로 감정 분류기와 대항적 언어 분류기이다.이 두 가지 모두 공유 특징 추출기에서 입력을 가져와 숨겨진 표현을 배운다. 이 표시는 분류 작업을 지시하고 서로 다른 언어 사이에 변하지 않는다.중국어와 아랍어의 감정 분류에 대한 실험은 ADAN이 가장 선진적인 시스템보다 현저히 우수하다는 것을 나타냈다.</abstract_ko>
      <abstract_id>Selama bertahun-tahun terakhir sukses besar telah dicapai dalam klasifikasi sentimen untuk bahasa Inggris, sebagian terima kasih pada disponibilitas sumber daya yang dicatat. Sayangnya, kebanyakan bahasa tidak menikmati begitu banyak data yang ditabel. Untuk mengatasi masalah klasifikasi sentimen dalam bahasa sumber rendah tanpa data yang cukup dicatat, kami mengusulkan jaringan Average Deep Network (ADAN1) untuk memindahkan pengetahuan yang dipelajari dari data yang dicatat pada bahasa sumber kaya sumber sumber ke bahasa sumber rendah di mana hanya ada data yang tidak dicatat. ADAN memiliki dua cabang diskriminatif: seorang pemikir perasaan dan seorang pembunuh bahasa. Kedua cabang mengambil input dari ekstraktor karakteristik berbagi untuk belajar representation tersembunyi yang secara bersamaan indikasif untuk tugas klasifikasi dan invarian melalui bahasa. Experiments on Chinese and Arabic sentiment classification demonstrate that ADAN significantly outperforms state-of-the-art systems.</abstract_id>
      <abstract_tr>Soňky ýyllar iňlisçe duýgular ýagdaýynda örän uly gazanýar, nusgalan çeşmeler üçin birnäçesi üçin sag bol. Gynansakda köp diller şol ýaly etiket edilen maglumatlary halamaýarlar. Açmak üçin juwasyz dillerde ýeterlik näbelli berilmeýän maglumatlary ýok dillerde çözmek üçin, biz diňe a ýdylanmaýan maglumatlary bar diňe hasaplanýän mektuplardan etilen maglumatlary taýýarlamak üçin Adversarial Deep Averaging Network (ADAN1) teklip berýäris ADAN iki diskriminçy çagalary bar: duýgym klasifikatçy we söňgüli dil diskriminçy. Eki braýlar hem paylaşyk özelliklerinden girdi alan çykyş rolleri bilen gizli suratlary öwrenmek üçin girdi alaýar. Çinçe we Arapça duýgym klasifikasynda örän ukyplaryň ADAN sanat sistemalarynyň durumyny örän ýok edip bilýär.</abstract_tr>
      <abstract_sw>Katika miaka ya hivi karibuni mafanikio makubwa yamefanika katika kutangazwa kwa hisia kwa lugha ya Kiingereza, shukrani kwa upatikanaji wa rasilimali zinazoudhi. Kwa bahati mbaya, lugha nyingi hazifurahi takwimu hizi zilizowekwa. Ili kukabiliana na tatizo la kutangaza hisia katika lugha ndogo ya rasilimali bila taarifa za kutosha, tunapendekeza Mtandao wa Kuondoa kwa Kiongozi wa Kuondolewa kwa Kiongozi (ADAN1) kuhamisha maarifa yanayofunzwa kutoka kwenye taarifa zilizowekwa kwenye lugha ya rasilimali-tajiri kwenda lugha chini ya rasilimali ambapo taarifa zisizo na maana. ADAN ina matawi mawili yanayotofauti: mfanyakazi wa hisia na ubaguzi wa lugha tofauti. Vwili viwili vinachukua input kutoka kwa mtangazaji wa kipekee kinachoshirikiana ili kujifunza wakiwakilisha ambao kwa wakati ule unaonyesha kazi ya kutangaza na kuingia katika lugha mbalimbali. Majaribio yanayohusu hisia za Kichina na Kiarabu yanaonyesha kwamba ADAN inafanya mifumo ya sanaa.</abstract_sw>
      <abstract_am>ባለፈው ዓመታት በንግግሊዝኛ ላይ የስሜት መግለጫ አግኝቷል፡፡ በጥፋት፣ ብዙዎቹ ቋንቋዎች እንደዚህ ብዛት የጽሑፍ ዳታ አይደሰሙም፡፡ የድምፅ ቋንቋዎች በተጠቃሚ ዳታ ሳይኖር የስሜት መግለጫ ጉዳይ ለመቀበል እናስቸጋጅላለን፣ የጠለቅ ጥልቅ ጥልቅ ማቀናጃ መረብ (ADAN1) እውቀትን ከጽሑፍ ዳታ በተማረከ ሀብታም ቋንቋ ላይ ወደታችኛው ክፍተት ቋንቋዎች ወደታችኛው ክፍል ቋንቋዎች ማቅረብ እናዘጋጀዋለን፡፡ ADAN ሁለት ልዩናዊ ቅርንጫፎች አሉት፤ አስተያየት ታሳቢ እና ተቃዋሚ ቋንቋ አቃዋሚ ነው፡፡ ሁለቱ ቅርንጫፎች ከክፍሉ ምርጫዎች ተሸሽገው የተሰወረውን መልዕክቶች ለመማር እና ለቋንቋዎች እና ለመግለጫ የሚያስፈልጉ ናቸው፡፡ በቻይና እና በዐረብኛ ስሜት መግለጫ ላይ ተፈተናዎች ADAN የ-የ-አርማዊ ሥርዓት-ስርዓት ሥርዓቶችን በሚያሳየው ነው፡፡</abstract_am>
      <abstract_af>In die onlangse jaar is groot sukses in sentiment klasifikasie vir Engels bereik, dankie in deel tot die beskikbaarheid van kopieële annotateerde hulpbronne. Ongelukkig, die meeste tale het nie so 'n oorvloedigheid van gemerkte data gelukkig nie. Om die sentiment klassifikasie probleem in lae-hulpbronne tale te probeer sonder adequate annotateerde data, voorstel ons 'n Adversarial Deep Averaging Network (ADAN1) om die kennis geleer te oordra van die gemerkteerde data op 'n hulpbronne-ryk bron taal na lae-hulpbronne tale waar slegs ongeabelde data bestaan is. ADAN het twee diskriminasiewe takke: ân sentiment klassifiseerder en ân teëstandige taal diskriminasie. Beide takke neem invoer van 'n gedeelde funksie uittrekker om weggesteekte voorstellings te leer wat simultaan indiseer is vir die klassifikasie taak en invariant oor tale. Eksperimente op Sinees en Arabse sentiment klasifikasie wys dat ADAN betekenlik uitvoer staat-van-kunstenstelsels.</abstract_af>
      <abstract_sq>Në vitet e fundit sukses i madh është arritur në klasifikimin e ndjenjave për anglishtin, falë pjesërisht disponueshmërisë së burimeve kopjoze të shënuara. Fatkeqësisht, shumica e gjuhëve nuk gëzohen me një mjaft të dhënash të etiketuara. Për të trajtuar problem in e klasifikimit të ndjenjave në gjuhët me burime të ulëta pa të dhëna të përshtatshme të shënuara, propozojmë një Rrjet Ndërmjetësues të thellë kundërshtar (ADAN1) për të transferuar njohuritë e mësuara nga të dhënat e etiketuara në gjuhën me burime të pasura me burime në gjuhët me burime të ulëta ku ekzistojnë vetëm të dhënat pa etiket ADAN ka dy degë diskriminuese: një klasifikues ndjesh dhe një diskriminues kundërshtar gjuhës. Të dy degët marrin hyrje nga një ekstraktor i përbashkët për të mësuar përfaqësime të fshehta që janë në të njëjtën kohë tregues për detyrën e klasifikimit dhe invariante nëpërmjet gjuhëve. Eksperimentet në klasifikimin e ndjenjave kineze dhe arabe tregojnë se ADAN tejkalon ndjeshëm sistemet më të larta.</abstract_sq>
      <abstract_hy>Վերջին տարիների ընթացքում մեծ հաջողություն է հասել անգլերենի զգացմունքների դասակարգման մեջ, մասամբ շնորհիվ բազմաթիվ գրված ռեսուրսների հասանելիության: Դժբախտաբար, լեզուների մեծ մասը չի վայելում այդքան բավարար պիտակուցված տվյալներ: Որպեսզի լուծենք զգացմունքների դասակարգման խնդիրը ցածր ռեսուրսներով լեզուներում առանց բավարար նշումնավորված տվյալների, մենք առաջարկում ենք հակառակ խորը միջին ցանց (ADADAD1) փոխանցելու այն գիտելիքները, որոնք սովորել են ռեսուրսներով հարուստ աղբյուրների լեզուներում, այնտեղ, որտեղ գո ԱԴԱՆ-ն ունի երկու տարբերակող ճյուղեր. զգացմունքների դասակարգիչ և հակառակ լեզվի տարբերակող: Երկու ճյուղերը օգտագործում են ընդհանուր հատկանիշների արտադրողից ներմուծք, որպեսզի սովորեն թաքնված ներկայացումներ, որոնք միաժամանակ ցույց են տալիս դասակարգման առաջադրանքին և որոնք տարբեր լեզուներում անընդհատ են: Չինաստանի և արաբական զգացմունքների դասակարգման փորձարկումները ցույց են տալիս, որ ԱԴԱն նշանակալիորեն գերազանցում է ամենաբարձր համակարգերը:</abstract_hy>
      <abstract_ca>En els últims anys s'ha aconseguit un gran èxit en la classificació de sentiments per anglès, gràcies en part a la disponibilitat de còpies recursos anotats. Malauradament, la majoria de llengües no gaudeixen d'aquesta abundància de dades etiquetades. Per abordar el problem a de classificació de sentiments en llengües de baix recursos sense dades anotates adequades, proposem una xarxa adversaria de mitjana profunda (ADAN1) per transferir el coneixement aprengut de dades etiquetades en un llengüe de fonts ric en recursos a llengües de baix recursos on només hi ha dades no etiquetades. L'ADAN té dues branques discriminatives: un classificador de sentiments i un discriminator de llenguatge adversari. Ambdues branques prenen entrada d'un extractor de característiques compartits per aprendre representacions ocultes que indiquen simultàneament la tasca de classificació i invariants a través de llengües. Els experiments en la classificació del sentiment xinès i àrab demostren que l'ADAN supera significativament els sistemes més avançats.</abstract_ca>
      <abstract_az>Son illərdə böyük başarı İngilizce üçün hisslər klasifikasyonu içində başarılı oldu, bir qismində də çox gözlənilmiş kaynaqların mümkün olmasına şükür edir. Maalesef ki, çox dillər bu çox etiketli məlumatlardan faydalanmırlar. Düşük ressurs dillərində hisslər klasifikasyonu çəkmək üçün yeterli məlumatlar olmadan, biz ancaq məlumatlar olmayan məlumatların məlumatlarını istifadə etmək üçün Adversarial Deep Averaging Network (ADAN1) təklif edirik. ADAN iki ayrı-ayrı dəstələri var: sentiment klasifikatçısı və düşmənçi dil diskriminatçısı. İki dəstə də ayrı-ayrı xüsusiyyətdən istifadə edən gizli göstəriciləri öyrənmək üçün paylaşır. Çinli və Arapça hisslər klasifikasyonu təcrübələrin ADAN sanat sistemlərinin vəziyyətini çox üstün etdiyini göstərir.</abstract_az>
      <abstract_bs>Za poslednje godine veliki uspjeh postignut je u klasifikaciji sentimenta za engleski, zahvaljujući djelomično dostupnosti kopijskih annotiranih resursa. Nažalost, većina jezika ne uživaju u takvoj opskrbi označenih podataka. Da bi se riješili problem klasifikacije osjećaja na jezicima niskih resursa bez odgovarajućih annotiranih podataka, predlažemo rekonstruacijsku mrežu za proizvodnju duboke proizvodnje (ADAN1) da prenese znanja koje su naučene iz etiketiranih podataka o jeziku s bogatim izvorima resursa na jezicima niskih resursa gdje postoje samo neizbiljni podaci. ADAN ima dvije diskriminacije: klasifikator sentiment a i diskriminacija protiv jezika. Obje grane uzimaju ulaz iz zajedničkog ekstraktora karakteristike kako bi naučili skrivene predstave koje su istovremeno indikativne za zadatak klasifikacije i invariant na jezicima. Eksperimenti o klasifikaciji kineskih i arapskih osjećaja pokazuju da ADAN značajno nadmašuje državne umjetne sustave.</abstract_bs>
      <abstract_bn>সাম্প্রতিক বছরগুলোতে ইংরেজিতে অনুভূতির বিভাগে বেশী সফল হয়েছে। ক্ষতিগ্রস্ত সম্পদে ধন্যবাদ। Unfortunately, most languages do not enjoy such an abundance of labeled data.  যথেষ্ট পরিচিত তথ্য ছাড়াই নিম্নলিখিত ভাষায় অনুভূতিগ্রাফিকেশন সমস্যার সাথে মোকাবেলা করার জন্য আমরা প্রস্তাব করছি একটি অ্যাডভারেসারিয়াল ডিপে ডেভারেজিং নেটওয়ার্ক (ADAN1) যেখানে কোন সম্ এডানের মধ্যে দুটি বৈষম্য শাখা আছে: একটি আবেগ বিভাগ এবং একজন বিরোধী ভাষা বৈষম্য। দুই শাখা থেকে একটি শেয়ার করা বৈশিষ্ট্য এক্সট্রেক্টর থেকে ইনপুট গ্রহণ করে লুকিয়ে থাকা প্রতিনিধিত্ব শিখার জন্য যা একই সাথে সাথ চীনা এবং আরবী অনুভূতি বিভাগের পরীক্ষা প্রদর্শন করেছে যে এডান গুরুত্বপূর্ণ সিস্টেমের রাষ্ট্র-অফ-শিল্প ব্যবস্থা করে।</abstract_bn>
      <abstract_et>Viimastel aastatel on inglise keele tundete klassifitseerimisel saavutatud suurt edu, osaliselt tänu paljude märgitud ressursside kättesaadavusele. Kahjuks ei ole enamikul keeltel nii palju märgistatud andmeid. Vähese ressursiga keelte sentimentaalse klassifitseerimise probleemi lahendamiseks ilma piisavate märgistatud andmeteta pakume välja ADAN1 (Adversarial Deep Averaging Network), et edastada märgistatud andmetest saadud teadmised ressursirikkas lähtekeeles vähese ressursiga keeltesse, kus on olemas ainult märgistamata andmed. ADANil on kaks diskrimineerivat haru: sentimentaalne klassifitseerija ja konkurentsikeelne diskrimineerija. Mõlemad harud võtavad sisendit jagatud funktsioonide ekstraktorist, et õppida varjatud esitusi, mis on klassifitseerimisülesande jaoks samaaegselt indikaatorid ja invariandid eri keeltes. Hiina ja Araabia sentimentaalse klassifikatsiooni eksperimendid näitavad, et ADAN on oluliselt kõrgem kui kaasaegsed süsteemid.</abstract_et>
      <abstract_fi>Viime vuosina englanninkielisessä tunneluokituksessa on saavutettu suurta menestystä osittain runsaiden merkintöjen ansiosta. Valitettavasti useimmilla kielillä ei ole näin paljon merkittyä tietoa. Jotta vähäresurssisten kielten tunteiden luokitteluongelmaa voitaisiin ratkaista ilman riittäviä merkintöjä koskevia tietoja, ehdotamme Adversarial Deep Averaging Network (ADAN1) -verkostoa, joka siirtää merkityistä tiedoista oppimansa tiedot resurssitehokkaalla lähdekielellä vähäresurssisille kielille, joissa on vain merkitsemätöntä tietoa. ADANilla on kaksi syrjivää haaraa: tunteiden luokittelija ja vastakkainasettelija. Molemmat haarat ottavat syötteen jaetusta ominaisuuden uuttajasta oppiakseen piilotettuja esityksiä, jotka ovat samanaikaisesti luokittelutehtävän ohjeellisia ja invariantteja eri kielillä. Kiinalaisten ja arabialaisten tunteiden luokittelua koskevat kokeet osoittavat, että ADAN on huomattavasti parempi kuin uusimmat järjestelmät.</abstract_fi>
      <abstract_cs>V posledních letech bylo dosaženo velkého úspěchu v klasifikaci sentimentů pro angličtinu, částečně díky dostupnosti bohatých anotovaných zdrojů. Bohužel většina jazyků nemá takové množství označených dat. Pro řešení problému klasifikace sentimentů v jazycích s nízkými zdroji bez adekvátních anotovaných dat navrhujeme Adversarial Deep Average Network (ADAN1), která přenáší znalosti získané z označených dat na zdrojovém jazyce bohatém na zdroje do jazyků s nízkými zdroji, kde existují pouze data bez označení. ADAN má dvě diskriminační větve: klasifikátor sentimentů a protivník jazykový diskriminátor. Obě větve přijímají vstup ze sdíleného extraktoru funkcí, aby se naučily skryté reprezentace, které jsou současně indikační pro klasifikační úlohu a které jsou invariantní napříč jazyky. Experimenty na klasifikaci čínských a arabských sentimentů ukazují, že ADAN výrazně překonává nejmodernější systémy.</abstract_cs>
      <abstract_jv>Rasané sing berarti barêng-barêng sing berarti tau matan nêmên seneng ngêngêngêng, mbêng ngêngêng kuwi tindakan sing nêmên ngerasakno. Ngjalakno, luwih-luwih sing paling awak dhéwé kuwi nggawe data sing apik. translation" means "shift" / "displacement Language Cover Geweke Perusahaan kanggo ngerasasi Seneng Cino karo Perusahaan Rasang dipontrolan kanggo ngerasahan daké AN kuwi barang pengguna-saka karo layang-layang.</abstract_jv>
      <abstract_ha>A cikin watan shẽkaru na farko, an sami babban rabo a cikin fasalin na Ingiriya, kuma aka yi gõdiya game da misalin abincin na hasara. Babu'am, masu yawa na harshen ba su yi farin ciki da wannan da aka rubũta. To, in motsa wa fitina na na hisani cikin harshen wuri-resource idan ba da adequate data ba, za mu buƙata wani shirin Cire Deptar Depth Agreement Netware (ADAN1) zuwa ka motsar ilmi wanda aka sanar daga data na rubũti kan harshen resource-rich zuwa ƙasan-resource, inda kawai akwai data wanda ba'a ƙayyade ba. ADAN yana da duffai biyu masu bastarwa: mai fassara na kalma da wani mai tsakanin harshe. Dukan rasa biyu sunã karya inputi daga wata shirin bayani mai raba shi, dõmin su sanar masu ɓõye, waɗand a ake nuna wa aikin fassarar da kuma masu shiga a kowace harshen. Tajararin da ke kan siffantin ɗabi'a na Kiniya da Larabci sun nuna cewa ADAN yana samar da halin-na'ura.</abstract_ha>
      <abstract_sk>V zadnjih letih je bil dosežen velik uspeh pri klasifikaciji sentimenta za angleščino, deloma zahvaljujoč razpoložljivosti obilnih virov z oznakami. Na žalost večina jezikov ne uživa tako veliko označenih podatkov. Za reševanje problema klasifikacije občutkov v jezikih z nizkimi viri brez ustreznih označenih podatkov predlagamo Adssarial Deep Averaging Network (ADAN1) za prenos znanja, pridobljenega iz označenih podatkov o izvornem jeziku, bogatem z viri, v jezike z nizkimi viri, kjer obstajajo le neoznačeni podatki. ADAN ima dve diskriminativni veji: klasifikator čustev in kontradiktor jezikovnega diskriminatorja. Obe veji uporabljata vnos iz skupnega ekstraktorja funkcij, da se naučijo skritih predstavitev, ki so hkrati indikativne za opravilo klasifikacije in invariantne v vseh jezikih. Eksperimenti na kitajski in arabski klasifikaciji sentimenta kažejo, da ADAN bistveno presega najsodobnejše sisteme.</abstract_sk>
      <abstract_he>בשנים האחרונות הצלחה גדולה הושגה בהסגרת רגשות לאנגלית, הודות חלקית לקבלת משאבים משותפים. למרבה הצער, רוב השפות לא נהנות מהמידע המתוויד. כדי להתמודד עם בעיית מסווג הרגשות בשפות משאבים נמוכות ללא נתונים מועטפים מתאימים, אנו מציעים רשת מצביעה עמוקה (ADAN1) לעבור את הידע שנלמד מהנתונים המתווים על שפת מקור עשירה במקורים לשפות משאבים נמוכות היכן שיש רק נתונים לא מועטפים. לאדן יש שני ענפים דיסקרטיביים: מסווג רגשות ומדיסקרטיבי שפת נגד. שני הענפים לוקחים תוכנית ממוציאת תכונות משותפת כדי ללמוד מייצגים חבויים שהם באותו הזמן מצביעים למשימת ההקלטה והולכים דרך שפות. ניסויים על שיעור רגשות סיני וערבי מראים שהADAN יוצא משמעות מערכות חדשות.</abstract_he>
      <abstract_bo>འདས་བའི་ལོ་ངོ་ཚོའི་ནང་གི་གོ་སྐབས་དབྱིན་ཡིག་ཅིག་ལ་སྒྲིག་ཚིག་གི་མཐུན་རྐྱེན་གྱིས་བྱུང་། ལྷུགས་སྟེ། སྐད་རིགས་ཆེ་ཤོས་ཡིག་འཕྲིན་ཡིག་ཆ་སླར་མི་རེད། To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist. ADAN ན་ལ་ཚོར་བ་དེ་ཚོར་ཆེ་བ་གཉིས་ཡོད། སེམས་ཚོར་དབྱེ་བ་ཞིག་དང་། ཚོར་བ་སྤྱོད་པའི་སྐད་ཡིག་ཆ་སྐྱེན་གྱིས དབྱེ་སྟངས་གཉིས་པོ་ཞིག་ནས་དབྱེ་སྟངས་འཛིན་བྱེད་མཁན་ལས་ནང་འཇུག་འདུག རྒྱ་ནག་དང་ཨ་རབ་གི་སྣང་ཚོར་དབྱེ་སྟངས་ལ་ལག་ལེན་འཐབ་བྱེད་ན་ADAN་ནི་འཛམ་གླིང་གི་གནས་སྟངས་ལ་ཕན་ཚུན་བཀོད་</abstract_bo>
      </paper>
    <paper id="41">
      <title>Data Statements for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> : Toward Mitigating System Bias and Enabling Better Science</title>
      <author><first>Emily M.</first><last>Bender</last></author>
      <author><first>Batya</first><last>Friedman</last></author>
      <doi>10.1162/tacl_a_00041</doi>
      <abstract>In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of <a href="https://en.wikipedia.org/wiki/Technology">technology</a> for other populations. We present a form that <a href="https://en.wikipedia.org/wiki/Statement_(computer_science)">data statements</a> can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.</abstract>
      <pages>587–604</pages>
      <url hash="92d8ab4c">Q18-1041</url>
      <video href="https://vimeo.com/359686057" />
      <bibkey>bender-friedman-2018-data</bibkey>
    <title_ar>بيانات البيانات لمعالجة اللغة الطبيعية: نحو التخفيف من انحياز النظام وتمكين علم أفضل</title_ar>
      <title_fr>Déclarations de données pour le traitement du langage naturel : vers une atténuation des biais du système et une meilleure science</title_fr>
      <title_pt>Declarações de dados para processamento de linguagem natural: para mitigar o viés do sistema e permitir uma ciência melhor</title_pt>
      <title_es>Declaraciones de datos para el procesamiento del lenguaje natural: hacia la mitigación del sesgo del sistema y la mejora de la ciencia</title_es>
      <title_ja>自然言語処理のためのデータステートメント：システムバイアスを軽減し、より良い科学を可能にする</title_ja>
      <title_zh>用自然语言处数语句:旨在减统偏而致善科学</title_zh>
      <title_ru>Заявления Данных для Обработки Естественного Языка: К Смягчать Систему Предвзятости и Включать Лучшую Науку</title_ru>
      <title_hi>प्राकृतिक भाषा प्रसंस्करण के लिए डेटा कथन: सिस्टम पूर्वाग्रह को कम करने और बेहतर विज्ञान को सक्षम करने की ओर</title_hi>
      <title_ga>Ráitis Sonraí maidir le Próiseáil Teanga Nádúrtha: I dtreo Laofachta Córais a Mhaolú agus Eolaíocht Níos Fearr a Chumasú</title_ga>
      <title_hu>Adatszolgáltatások a természetes nyelv feldolgozásához: a rendszer hiányának enyhítése és a jobb tudomány lehetővé tétele felé</title_hu>
      <title_el>Δήλωση δεδομένων για την επεξεργασία φυσικής γλώσσας: Προς την άμβλυνση των προκαταλήψεων συστημάτων και τη δυνατότητα καλύτερης επιστήμης</title_el>
      <title_ka>მონაცემები სიტყვის პროცესისთვის მონაცემენტები: სისტემის ბიზებისთვის და უკეთესი მეცნიერებისთვის გაშვება</title_ka>
      <title_kk>Түзіндік тіл процессорының деректер кәдімгілері: Жүйелік бөлшегіне қарсы және жақсы ғылымды рұқсат ету</title_kk>
      <title_it>Dichiarazioni dei dati per l'elaborazione del linguaggio naturale: verso una mitigazione del bias del sistema e una migliore scienza</title_it>
      <title_lt>Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</title_lt>
      <title_mk>Декларации за процес на природен јазик: Надвор кон намалување на проблемите во системот и овозможување на подобра наука</title_mk>
      <title_mn>Байгалийн хэл процессорын өгөгдлийн загвар: Байгалийн системийн бис болон сайн шинжлэх ухааны талаар</title_mn>
      <title_ml>സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയയ്ക്കുള്ള ഡേറ്റാ വിവരങ്ങള്‍: മുകളിലേക്ക് മീറ്റിങ്ങിങ്ങ് സിസ്റ്റം ബിയാസു</title_ml>
      <title_mt>Dikjarazzjonijiet tad-Dejta għall-Ipproċessar tal-Lingwi Naturali: Lejn it-tnaqqis tal-ħsara fis-Sistema u l-Impjieg tax-Xjenza Aħjar</title_mt>
      <title_ms>Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</title_ms>
      <title_pl>Oświadczenia dotyczące przetwarzania języka naturalnego: w kierunku łagodzenia uprzedzeń systemowych i umożliwienia lepszej nauki</title_pl>
      <title_no>Data- statementer for naturspråk- prosessering: Gå til mittingssystemet Bias og slå på bedre vitenskap</title_no>
      <title_ro>Declarații de date pentru prelucrarea limbajului natural: către atenuarea deficiențelor sistemului și facilitarea științei mai bune</title_ro>
      <title_sr>Izjave podataka za proces prirodnog jezika: prema nagradnoj sistemi i uključivanju boljih nauka</title_sr>
      <title_si>ස්වාභාවික භාෂාව ප්‍රක්‍රියාසය සඳහා දත්ත ප්‍රතිචාරය: මිටිගේට් පද්ධතිය බියාස් වලට සහ හොඳ ව</title_si>
      <title_so>Heerarinta macluumaadka la xiriira baaritaanka afka asalka ah: Toward Mitiging System Bias and Activation Scientific Fiican</title_so>
      <title_ta>இயல்பான மொழி செயல்பாடு</title_ta>
      <title_ur>Name</title_ur>
      <title_sv>Datadeklarationer för behandling av naturligt språk: Mot att mildra systemBias och möjliggöra bättre vetenskap</title_sv>
      <title_uz>Name</title_uz>
      <title_vi>Thông tin về Bản quản lý ngôn ngữ tự nhiên: Hệ thống kiểm soát ràng buộc và Kích hoạt khoa học tốt hơn</title_vi>
      <title_bg>Декларация за данни за обработка на естествени езици: към смекчаване на системните наклонности и даване на възможност за по-добра наука</title_bg>
      <title_da>Dataerklæringer til behandling af natursprog: Mod at mindske systemfordrejninger og muliggøre bedre videnskab</title_da>
      <title_nl>Data Statements voor Natural Language Processing: Naar het verminderen van systeembias en het mogelijk maken van betere wetenschap</title_nl>
      <title_hr>Izvještaje podataka za proces prirodnog jezika: prema mještanju sustava Bias i omogućavanju boljih znanosti</title_hr>
      <title_de>Data Statements for Natural Language Processing: Auf dem Weg zur Abschwächung von Systemverzerrungen und zu besserer Wissenschaft</title_de>
      <title_sw>Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</title_sw>
      <title_fa>اعلام داده‌ها برای پرداخت زبان طبیعی: به سمت سیستم‌های پیچیدگی و فعال کردن علم بهتر</title_fa>
      <title_ko>자연 언어 처리 데이터 진술: 시스템 편차 감소와 더 나은 과학 실현</title_ko>
      <title_id>Data Statements for Natural Language Processing: Towards Mitigating System Bias and Enabling Better Science</title_id>
      <title_tr>Natal dil işlemek üçin Maglumat Beýikleri</title_tr>
      <title_af>Data Statemente vir Natuurlike Taal Prosessering: Na Mitigating Stelsel Bias en Aktiveer Beter Wetenskap</title_af>
      <title_sq>Deklaratat e të dhënave për procesimin e gjuhës natyrore: drejt përmirësimit të dëmeve të sistemit dhe mundësimit të shkencës më të mirë</title_sq>
      <title_am>የዳታ መግለጫ</title_am>
      <title_bn>স্বাভাবিক ভাষা প্রক্রিয়ার জন্য তথ্য বিবৃতি: উপরে মিটাইটিং সিস্টেম বায়াস এবং উৎকৃষ্ট বিজ্ঞান সক্রিয় করুন</title_bn>
      <title_hy>Բնական լեզվի վերաբերյալ վերաբերվող տվյալների հայտարարությունները. Մինչև նվազեցնել համակարգի շեղումները և հնարավորություն տալ ավելի լավ գիտություն</title_hy>
      <title_bs>Izvještaje podataka za proces prirodnog jezika: prema sistemu za mijenjanje i omogućavanje boljih nauka</title_bs>
      <title_az>Təbiətli Dil İşləməsi üçün verilən Statementlər: Təbiətli Sistem Biya tərəfində və Daha yaxşı Bilim Etilməsi</title_az>
      <title_cs>Prohlášení o údajích pro zpracování přirozeného jazyka: směrem ke zmírnění systémových předpokladů a umožnění lepší vědy</title_cs>
      <title_et>Looduskeele töötlemise andmed: süsteemi kallakute leevendamine ja parema teaduse võimaldamine</title_et>
      <title_fi>Luonnonkielen käsittelyn tiedonannot: Kohti järjestelmän vääristymien lieventämistä ja tieteen parantamista</title_fi>
      <title_ca>Declaracions de dades sobre el processament de llenguatges naturals: cap a mitigar els obstáculos del sistema i permetre una millor ciència</title_ca>
      <title_jv>Stat dadi kanggo Perusahaan langgambar Daftar: Tahur mitigating System Bias lan Ngawe Perintah Siensêm sing luwih apik</title_jv>
      <title_he>הצהרות מידע עבור עיבוד שפת טבעית: לכיוון המעטפות המערכת והאפשרות למדע טוב יותר</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Izjave o podatkih za obdelavo naravnega jezika: k ublažitvi sistemskih pristranskosti in omogočanju boljše znanosti</title_sk>
      <title_bo>Natural Language Processing for Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science</title_bo>
      <abstract_ar>في هذه الورقة ، نقترح بيانات البيانات كحل تصميم وممارسة مهنية لتقنيي معالجة اللغة الطبيعية ، في كل من البحث والتطوير. من خلال اعتماد بيانات البيانات واستخدامها على نطاق واسع ، يمكن أن يبدأ المجال في معالجة القضايا العلمية والأخلاقية الحرجة التي تنتج عن استخدام البيانات من مجموعات سكانية معينة في تطوير التكنولوجيا لفئات سكانية أخرى. نقدم نموذجًا يمكن أن تأخذه بيانات البيانات ونستكشف الآثار المترتبة على اعتمادها كجزء من الممارسة المنتظمة. نجادل بأن بيانات البيانات ستساعد في التخفيف من المشكلات المتعلقة بالاستبعاد والتحيز في تكنولوجيا اللغة ، وتؤدي إلى دقة أفضل في الادعاءات حول كيف يمكن لأبحاث معالجة اللغة الطبيعية أن تعمم وبالتالي نتائج هندسية أفضل ، وتحمي الشركات من الإحراج العام ، وتؤدي في النهاية إلى تكنولوجيا اللغة التي تلبي مستخدميها بأسلوبهم اللغوي المفضل ، علاوة على ذلك لا تحرفهم عن الآخرين.</abstract_ar>
      <abstract_fr>Dans cet article, nous proposons des relevés de données en tant que solution de conception et pratique professionnelle pour les technologues en traitement du langage naturel, tant dans la recherche que dans le développement. Grâce à l'adoption et à l'utilisation généralisée de déclarations de données, le domaine peut commencer à aborder des questions scientifiques et éthiques critiques qui résultent de l'utilisation de données provenant de certaines populations dans le développement de technologies pour d'autres populations. Nous présentons une forme que les déclarations de données peuvent prendre et nous explorons les implications de leur adoption dans le cadre de la pratique régulière. Nous soutenons que les déclarations de données aideront à atténuer les problèmes liés à l'exclusion et aux préjugés dans les technologies langagières, conduiront à une meilleure précision dans les affirmations sur la façon dont la recherche sur le traitement du langage naturel peut généraliser et donc de meilleurs résultats d'ingénierie, à protéger les entreprises de l'embarras public et, en fin de compte une technologie linguistique qui répond à ses utilisateurs dans leur propre style linguistique préféré et qui ne les déforme pas auprès des autres.</abstract_fr>
      <abstract_es>En este artículo, proponemos las declaraciones de datos como una solución de diseño y práctica profesional para los tecnólogos de procesamiento del lenguaje natural, tanto en investigación como en desarrollo. A través de la adopción y el uso generalizado de declaraciones de datos, el campo puede comenzar a abordar cuestiones científicas y éticas críticas que resultan del uso de datos de ciertas poblaciones en el desarrollo de tecnología para otras poblaciones. Presentamos una forma que pueden adoptar las declaraciones de datos y exploramos las implicaciones de adoptarlas como parte de la práctica habitual. Sostenemos que las declaraciones de datos ayudarán a aliviar los problemas relacionados con la exclusión y el sesgo en la tecnología del lenguaje, conducirán a una mayor precisión en las afirmaciones sobre cómo la investigación del procesamiento del lenguaje natural puede generalizar y, por lo tanto, mejorar los resultados de ingeniería, proteger a las empresas de la vergüenza pública y, en última instancia tecnología del lenguaje que satisface a sus usuarios en su propio estilo lingüístico preferido y, además, no los tergiversa ante los demás.</abstract_es>
      <abstract_pt>Neste artigo, propomos declarações de dados como uma solução de design e prática profissional para tecnólogos de processamento de linguagem natural, tanto em pesquisa quanto em desenvolvimento. Por meio da adoção e uso generalizado de declarações de dados, o campo pode começar a abordar questões científicas e éticas críticas que resultam do uso de dados de certas populações no desenvolvimento de tecnologia para outras populações. Apresentamos uma forma que as declarações de dados podem assumir e exploramos as implicações de adotá-las como parte da prática regular. Argumentamos que as declarações de dados ajudarão a aliviar questões relacionadas à exclusão e preconceito na tecnologia da linguagem, levar a uma melhor precisão nas alegações sobre como a pesquisa de processamento de linguagem natural pode generalizar e, portanto, melhores resultados de engenharia, proteger as empresas do constrangimento público e, finalmente, levar à tecnologia da linguagem que atende seus usuários em seu próprio estilo linguístico preferido e, além disso, não os deturpa para os outros.</abstract_pt>
      <abstract_ja>本稿では，研究開発の両面において，自然言語処理技術者のための設計ソリューションおよび専門的実践としてのデータステートメントを提案する．データステートメントの採用と広範な使用を通じて、フィールドは、特定の集団からのデータを他の集団のためのテクノロジーの開発に使用することから生じる重要な科学的および倫理的問題に取り組み始めることができます。私たちは、データステートメントが取ることができる形式を提示し、それらを通常の練習の一部として採用することの意味を探求します。私たちは、データステートメントは、言語テクノロジーにおける排斥と偏見に関連する問題を緩和するのに役立ち、自然言語処理研究がどのように一般化し、したがってより良いエンジニアリング結果を得ることができるかに関する主張の精度の向上につながり、企業を公的な恥ずかしさから保護し、最終的にはそのユーザーが好む言語スタイルで会う言語テクノロジーにつながり、さらに他者に誤解を与えないと主張しています。</abstract_ja>
      <abstract_zh>本文数据陈为自然语言技术人员计解决方案专业。 博用数陈,可以始开发技术群数之要科学伦。 陈可用之文,讨以为常。 臣等以为,数陈将有助于缓语之术,而更精言自然语言处究所推,而获其功果,护公司免公论,而终致言语技艺以自喜之语满足用户,且不能曲之于人。</abstract_zh>
      <abstract_hi>इस पेपर में, हम अनुसंधान और विकास दोनों में प्राकृतिक भाषा प्रसंस्करण प्रौद्योगिकीविदों के लिए एक डिजाइन समाधान और पेशेवर अभ्यास के रूप में डेटा बयानों का प्रस्ताव करते हैं। डेटा स्टेटमेंट के गोद लेने और व्यापक उपयोग के माध्यम से, क्षेत्र महत्वपूर्ण वैज्ञानिक और नैतिक मुद्दों को संबोधित करना शुरू कर सकता है जो अन्य आबादी के लिए प्रौद्योगिकी के विकास में कुछ आबादी से डेटा के उपयोग के परिणामस्वरूप होता है। हम एक ऐसा रूप प्रस्तुत करते हैं जो डेटा स्टेटमेंट नियमित अभ्यास के हिस्से के रूप में उन्हें अपनाने के निहितार्थों को ले और उनका पता लगा सकते हैं। हम तर्क देते हैं कि डेटा बयान भाषा प्रौद्योगिकी में बहिष्करण और पूर्वाग्रह से संबंधित मुद्दों को कम करने में मदद करेंगे, इस बारे में दावों में बेहतर सटीकता का नेतृत्व करेंगे कि प्राकृतिक भाषा प्रसंस्करण अनुसंधान कैसे सामान्यीकृत हो सकता है और इस प्रकार बेहतर इंजीनियरिंग परिणाम, कंपनियों को सार्वजनिक शर्मिंदगी से बचा सकता है, और अंततः भाषा प्रौद्योगिकी का नेतृत्व करता है जो अपने उपयोगकर्ताओं को अपनी पसंदीदा भाषाई शैली में मिलता है और इसके अलावा उन्हें दूसरों को गलत तरीके से प्रस्तुत नहीं करता है।</abstract_hi>
      <abstract_ru>В этой статье мы предлагаем заявления данных как проектное решение и профессиональную практику для технологов по обработке естественного языка, как в исследованиях, так и в разработках. Благодаря принятию и широкому использованию заявлений о данных на местах можно приступить к решению важнейших научных и этических вопросов, возникающих в результате использования данных о некоторых группах населения при разработке технологий для других групп населения. Мы представляем форму, которую могут принять заявления о данных, и изучаем последствия их принятия в рамках обычной практики. Мы утверждаем, что заявления данных помогут облегчить проблемы, связанные с исключением и предвзятостью в языковых технологиях, приведут к лучшей точности в утверждениях о том, как исследования по обработке естественного языка могут обобщить и, таким образом, улучшить результаты проектирования, защитить компании от общественного смущения и в конечном итоге привести к языковой технологии, которая отвечает своим пользователям в их собственном предпочтительном лингвистическом стиле и, кроме того, не искажает их для других.</abstract_ru>
      <abstract_ga>Sa pháipéar seo, molaimid ráitis sonraí mar réiteach dearaidh agus cleachtas gairmiúil do theicneolaithe próiseála teanga nádúrtha, i dtaighde agus i bhforbairt araon. Trí ráitis sonraí a ghlacadh agus a úsáid go forleathan, is féidir leis an réimse tosú ag tabhairt aghaidh ar shaincheisteanna ríthábhachtacha eolaíocha agus eiticiúla a eascraíonn as úsáid sonraí ó dhaonraí áirithe i bhforbairt teicneolaíochta do dhaonraí eile. Cuirimid foirm i láthair ar féidir le ráitis sonraí a ghlacadh agus fiosraíonn muid na himpleachtaí a bhaineann leo a ghlacadh mar chuid de chleachtas rialta. Áitímid go gcabhróidh ráitis sonraí le maolú a dhéanamh ar shaincheisteanna a bhaineann le heisiamh agus le claonadh i dteicneolaíocht teanga, go mbeidh beachtas níos fearr ann maidir le héilimh faoi conas is féidir le taighde próiseála teanga nádúrtha ginearálú agus mar sin torthaí innealtóireachta níos fearr, cuideachtaí a chosaint ó náire poiblí, agus sa deireadh thiar mar thoradh ar theicneolaíocht teanga. a fhreastalaíonn ar a cuid úsáideoirí ina rogha stíl teanga agus ina theannta sin nach ndéanann mífhaisnéis orthu do dhaoine eile.</abstract_ga>
      <abstract_ka>ჩვენ ამ დოკუნეში მონაცემების გამოსახულება როგორც დიზაინის განსახულება და პროფეციალური პროფეცია ტრაციური ენის პროცესი ტექნოლოგიებისთვის, როგორც ს მონაცემების გამოყენება და გაფარდებული გამოყენება გადავიწყება კრიტიკური მეცნიერო და ეტიკური პრობლემები, რომლებიც გამოყენება განსაკუთრებული პოლუციაზე განსაკუთრებული მონაცემების ჩვენ აჩვენებთ ფორმა, რომელიც მონაცემები შეუძლიათ გავაკეთოთ და გავაკეთოთ ინფორმაციების შესაძლებლობა, რომელიც მათ რეგილური პრაქტიკის ნაწილი ჩვენ ამბობით, რომ მონაცემები შეუძლიათ გადახმარება პრობლემები, რომელიც ენერგიის პროცესი შესაძლებელია გენერალიზაციის შესაძლებლობა და უკეთესი ინგენერიზაციის შესაძლებლობა, კომპანიების გადარ და საბოლოოდ ენის ტექნოლოგიას, რომელიც თავის მომხმარებელი თავისთან უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო</abstract_ka>
      <abstract_el>Στην παρούσα εργασία, προτείνουμε δηλώσεις δεδομένων ως σχεδιαστική λύση και επαγγελματική πρακτική για τους τεχνολογικούς επεξεργασίας φυσικής γλώσσας, τόσο στην έρευνα όσο και στην ανάπτυξη. Μέσω της υιοθέτησης και ευρείας χρήσης δηλώσεων δεδομένων, ο τομέας μπορεί να αρχίσει να αντιμετωπίζει κρίσιμα επιστημονικά και δεοντολογικά ζητήματα που προκύπτουν από τη χρήση δεδομένων από ορισμένους πληθυσμούς στην ανάπτυξη της τεχνολογίας για άλλους πληθυσμούς. Παρουσιάζουμε μια μορφή που μπορούν να λάβουν οι δηλώσεις δεδομένων και διερευνούμε τις επιπτώσεις της υιοθέτησής τους ως μέρος της τακτικής πρακτικής. Υποστηρίζουμε ότι οι δηλώσεις δεδομένων θα βοηθήσουν στην ανακούφιση των ζητημάτων που σχετίζονται με τον αποκλεισμό και την προκατάληψη στην γλωσσική τεχνολογία, θα οδηγήσουν σε μεγαλύτερη ακρίβεια στους ισχυρισμούς σχετικά με το πώς η έρευνα επεξεργασίας φυσικής γλώσσας μπορεί να γενικεύσει και συνεπώς καλύτερα αποτελέσματα μηχανικής, να προστατεύσει τις εταιρείες από δημόσια αμηχανία, και τελικά οδηγούν σε γλωσσική τεχνολογία που συναντά τους χρήστες της με το δικό τους προτιμώμενο γλωσσικό στυλ και επιπλέον δεν τους παρουσιάζει παραπλανητικά σε άλλους.</abstract_el>
      <abstract_hu>Ebben a tanulmányban a természetes nyelvfeldolgozó technológusok számára tervezési megoldásként és szakmai gyakorlatként javasoljuk az adatszolgáltatásokat mind a kutatás, mind a fejlesztés területén. Az adatszolgáltatások elfogadásával és széles körű használatával a terület megkezdheti a kritikus tudományos és etikai kérdéseket, amelyek egyes populációkból származó adatok más populációk technológiai fejlesztése során történő felhasználásából erednek. Bemutatunk egy olyan formanyomtatványt, amelyet az adatszolgáltatások használhatnak, és feltárjuk, milyen következményekkel járnak a rendszeres gyakorlat részeként történő elfogadásuk. Azzal érvelünk, hogy az adatszolgáltatások segítenek enyhíteni a nyelvtechnológia kirekesztésével és elfogultságával kapcsolatos problémákat, jobb pontosságot eredményeznek azon állításokban, amelyek arra vonatkoznak, hogy a természetes nyelv feldolgozásával kapcsolatos kutatások általánosíthatják és így jobb mérnöki eredményeket, megvédik a vállalatokat a nyilvános zavarból, és végső soron olyan nyelvtechnológiához vezet, amely megfelel a felhasználóknak a saját preferált nyelvi stílusukban, és ezenkívül nem téveszti őket mások előtt.</abstract_hu>
      <abstract_it>In questo articolo, proponiamo le dichiarazioni dei dati come soluzione progettuale e pratica professionale per i tecnici di elaborazione del linguaggio naturale, sia in ricerca che nello sviluppo. Attraverso l'adozione e l'uso diffuso di dichiarazioni di dati, il campo può iniziare ad affrontare criticità scientifiche ed etiche derivanti dall'uso di dati provenienti da alcune popolazioni nello sviluppo di tecnologie per altre popolazioni. Presentiamo una forma che le dichiarazioni di dati possono assumere ed esploriamo le implicazioni dell'adozione come parte della pratica regolare. Sosteniamo che le dichiarazioni di dati aiuteranno ad alleviare le questioni relative all'esclusione e al pregiudizio nella tecnologia linguistica, portare a una maggiore precisione nelle affermazioni su come la ricerca sull'elaborazione del linguaggio naturale può generalizzare e quindi migliori risultati ingegneristici, proteggere le aziende dall'imbarazzo pubblico, e, in ultima analisi, portare a una tecnologia linguistica che soddisfi i suoi utenti nel loro stile linguistico preferito e che inoltre non li rappresenti erroneamente agli altri.</abstract_it>
      <abstract_lt>Šiame dokumente siūlome duomenų pareiškimus kaip projektinį sprendimą ir profesinę praktiką natūralios kalbos apdorojimo technologijų darbuotojams tiek mokslinių tyrimų, tiek plėtros srityje. Priėmus ir plačiai naudojant duomenų pareiškimus, ši sritis gali pradėti spręsti svarbius mokslinius ir etinius klausimus, kylančius naudojant tam tikrų populiacijų duomenis plėtojant technologijas kitoms populiacijoms. Pateikiame form ą, kurią duomenys gali turėti ir išnagrinėti jų priėmimo kaip įprastos praktikos dalies pasekmes. Mes teigiame, kad duomenų pareiškimai padės sušvelninti klausimus, susijusius su atskirtimi ir šališkumu kalbų technologijose, padės geriau tikslinti teiginius apie tai, kaip gamtinių kalbų apdorojimo moksliniai tyrimai gali apskritai išplėsti ir taip geriau in žinerijos rezultatus, apsaugoti įmones nuo visuomenės gėdos, - ir galiausiai sukuria kalbų technologijas, kurios susitinka su savo naudotojais savo pačių pageidaujamu kalbiniu būdu, be to, jos nėra neteisingai atstovaujamos kitiems.</abstract_lt>
      <abstract_kk>Бұл қағазда, біз деректер мәліметтерін табиғи тілдерді өңдеу технологияларының, зерттеу мен жасау үшін дизайнды жасау және профессионалды практика ретінде ұсынамыз. Деректер мәліметтерін қолдану және көпшілікті қолдану арқылы, өріс басқа жиындар үшін технологиялық жасау үшін кейбір жиындардан деректерді қолдану және етикалық мәселелерді шешуге болад Біз деректер мәліметтері үлгі тәжірибенің бір бөлігі ретінде қолдануға болады. Біз деректер мәліметтері тіл технологиясындағы өзгерістік және өзгерістердің мәселелерін көмектеседі деп айтып, табиғи тілдерді өзгерту зерттеулерінің қалай жалпы түрлерді жасауға болады және осындай-ақ Соңында, тіл технологиясын өзіңіздің қолданушыларының қолданған лингвистикалық стиліне сәйкес келеді, сондай-ақ оларды басқаларға қате көрсетпейді.</abstract_kk>
      <abstract_mk>In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development.  Со усвојувањето и широката употреба на изјавите за податоци, областа може да почне да ги решава критичните научни и етички прашања кои резултираат од употребата на податоци од одредени популации во развојот на технологијата за другите популации. Презентираме формула која податочните изјави може да ја земат и да ги истражуваат импликациите од усвојувањето на нив како дел од редовната практика. Ние тврдиме дека изјавите за податоци ќе помогнат во олеснувањето на прашањата поврзани со исклучувањето и пристрасноста во јазичката технологија, ќе доведат до подобра прецизност во тврдењата за тоа како природното истражување за обработување јазик може да се генерализира и со тоа подобри инженерски И на крајот води до јазична технологија која ги сретнува своите корисници во нивниот префериран јазички стил и, понатаму, не ги погрешно ги претставува за другите.</abstract_mk>
      <abstract_ms>Dalam kertas ini, kami cadangkan pernyataan data sebagai penyelesaian rancangan dan praktek profesional untuk teknologi pemprosesan bahasa semulajadi, dalam kajian dan pembangunan. Melalui penerimaan dan penggunaan luas pernyataan data, medan ini boleh mula mengatasi isu saintifik dan etik kritik yang berasal dari penggunaan data dari populasi tertentu dalam pembangunan teknologi bagi populasi lain. Kami memperkenalkan bentuk yang pernyataan data boleh ambil dan mengeksplorasi implikasi adopsinya sebagai sebahagian dari latihan biasa. Kami menyangka bahawa pernyataan data akan membantu mengurangi isu-isu yang berkaitan dengan pengecualian dan bias dalam teknologi bahasa, membawa kepada ketepatan yang lebih baik dalam pernyataan bagaimana penyelidikan pemprosesan bahasa semulajadi boleh menyeluruhkan dan demikian hasil teknik yang lebih baik, melindungi syarikat dari malu awam, Dan akhirnya membawa kepada teknologi bahasa yang bertemu penggunanya dalam gaya bahasa yang mereka suka dan selain itu tidak salah mewakili mereka kepada orang lain.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍, നമ്മള്‍ ഡേറ്റാ പ്രഖ്യാപനങ്ങള്‍ സ്വാഭാവികമായ ഭാഷ പ്രവര്‍ത്തിപ്പിക്കുന്ന സാങ്കേതികവിദ്യയുടെ പരിഹാരം  ഡേറ്റാ വിവരങ്ങളുടെ പ്രഖ്യാപനത്തിനും വിശാലമായ ഉപയോഗിക്കുമ്പോള്‍ ഫീല്‍ഡ് മറ്റു ജനങ്ങള്‍ക്ക് വേണ്ടി സാങ്കേതികവിദ്യയുടെ വിവരങ്ങള്‍ ഉപയോഗി ഡേറ്റാ പ്രസ്താനങ്ങള്‍ എടുക്കുകയും പരിശോധിക്കുകയും ചെയ്യുന്ന ഒരു രീതിയില്‍ ഞങ്ങള്‍ കൊണ്ടുവരുന്നു. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, അവസാനം ഭാഷ സാങ്കേതികവിദ്യയില്‍ ഉപയോക്താക്കളെ കണ്ടുമുട്ടുന്ന ഭാഷ സാങ്കേതികവിദ്യയിലേക്ക് കൊണ്ടുപോകുന്നു. അതി</abstract_ml>
      <abstract_mt>F’dan id-dokument, qed nipproponu dikjarazzjonijiet tad-dejta bħala soluzzjoni ta’ disinn u prattika professjonali għat-teknoloġisti tal-ipproċessar tal-lingwi naturali, kemm fir-riċerka kif ukoll fl-iżvilupp. Permezz tal-adozzjoni u l-użu mifrux tad-dikjarazzjonijiet tad-dejta, il-qasam jista’ jibda jindirizza kwistjonijiet xjentifiċi u etiċi kritiċi li jirriżultaw mill-użu ta’ dejta minn ċerti popolazzjonijiet fl-iżvilupp tat-teknoloġija għal popolazzjonijiet oħra. Aħna nippreżentaw form a li d-dikjarazzjonijiet tad-dejta jistgħu jieħdu u jesploraw l-implikazzjonijiet tal-adozzjoni tagħhom bħala parti mill-prattika regolari. Aħna jargumentaw li d-dikjarazzjonijiet tad-dejta se jgħinu biex itaffu kwistjonijiet relatati mal-esklużjoni u l-preġudizzju fit-teknoloġija tal-lingwi, iwasslu għal preċiżjoni aħjar fid-dikjarazzjonijiet dwar kif ir-riċerka dwar l-ipproċessar naturali tal-lingwi tista’ tiġġeneralizza u b’hekk riżultati ta’ in ġinerija aħjar, jipproteġu lill-kumpaniji minn xkie • u fl-aħħar mill-aħħar iwasslu għal teknoloġija lingwistika li tiltaqa’ mal-utenti tagħha fl-istil lingwistiku ppreferut tagħhom stess u barra minn hekk ma tirrappreżentahomx ħażin lil oħrajn.</abstract_mt>
      <abstract_no>I denne papiret foreslår vi datauttrykk som utformingsløysing og profesjonell praksis for naturspråk-handteringsteknologistar, både forskning og utvikling. Gjennom bruken av data-uttrykk, kan feltet starta å handtera kritiske vitenskapelige og etiske problemar som resulterer av bruken av data frå enkelte populasjonar i utviklinga av teknologi for andre populasjonar. Vi presenterer eit form som datauttrykk kan ta og utforske implikasjonane for å adoptera dei som del av regulære praksis. Vi argumenterer at datauttrykk vil hjelpa til å redusere problemar relaterte til eksklusjon og forvirkning i språk-teknologi, føre til betre nøyaktighet i uttrykk om korleis naturlege språk-handteringsforskning kan generellisere og derfor betre in ženjeringsresultat, beskytte selskaper frå offentlige skade, Og til slutt fører språk-teknologi som møtar brukarane sine i sin eige foretrukte språk-stil, og likevel representerer dei ikkje feil til andre.</abstract_no>
      <abstract_mn>Энэ цаасан дээр бид өгөгдлийн хэвлэлийн үйлдвэрлэлийн технологи болон судалгааны болон хөгжлийн шийдвэр болон мэргэжлийн дасгал болгон өгөгдлийн хэлбэрүүдийг санал дэвшүүлнэ. Дасгал өгөгдлийн хэлэлцээг хүлээн зөвхөн шинжлэх ухааны, этикийн асуудлуудын тулд зарим хүмүүсийн технологийн хөгжлийн технологиос ашиглаж бусад хүмүүст өгөгдлийг ашиглаж эхэлж болно. Бид өгөгдлийн өгөгдлийн хэлбэрүүдийг энгийн дасгалын нэг хэсэг болгон хүлээн зөвшөөрөх боломжтой болон судалж болно. Бид өгөгдлийн захирал нь хэл технологид хамааралтай асуудлуудыг багасгаж, хэл технологиос хамааралтай асуудлуудыг багасгаж, байгалийн хэл үйлдвэрлэлийн судалгаа хэрхэн ерөнхийлөгч болох вэ гэхээр илүү сайн инженерийн үр дүн, компаниудыг Эцэст нь хэл технологийг хэрэглэгчиддээ өөрсдийн дуртай хэлний хэлбэрээр уулзаж буй хэлний технологийг бусад хүмүүст буруу илэрхийлж чадахгүй.</abstract_mn>
      <abstract_pl>W niniejszym artykule proponujemy deklaracje danych jako rozwiązanie projektowe i praktykę zawodową dla technologów przetwarzania języka naturalnego, zarówno w badaniach, jak i rozwoju. Poprzez przyjęcie i powszechne wykorzystywanie oświadczeń danych, dziedzina może zacząć rozwiązywać krytyczne kwestie naukowe i etyczne wynikające z wykorzystania danych pochodzących z określonych populacji w rozwoju technologii dla innych populacji. Przedstawiamy formę, jaką mogą przyjąć deklaracje danych i zbadamy implikacje ich przyjęcia w ramach regularnej praktyki. Twierdzimy, że oświadczenia danych pomogą złagodzić problemy związane z wykluczeniem i uprzedzeniami w technologii językowej, doprowadzą do większej precyzji twierdzeń o tym, jak badania nad przetwarzaniem języka naturalnego mogą uogólniać, a tym samym lepsze wyniki inżynierii, chronić firmy przed publicznym wstydem, i ostatecznie prowadzi do technologii językowej, która spotyka swoich użytkowników w ich własnym preferowanym stylu językowym, a ponadto nie przedstawia ich innym w błąd.</abstract_pl>
      <abstract_ro>În această lucrare, propunem declarații de date ca soluție de design și practică profesională pentru tehnologii de prelucrare a limbajului natural, atât în cercetare, cât și în dezvoltare. Prin adoptarea și utilizarea pe scară largă a declarațiilor de date, domeniul poate începe să abordeze problemele științifice și etice critice care rezultă din utilizarea datelor de la anumite populații în dezvoltarea tehnologiei pentru alte populații. Prezentăm o formă pe care declarațiile de date o pot lua și explorăm implicațiile adoptării lor ca parte a practicii regulate. Susținem că declarațiile de date vor ajuta la atenuarea problemelor legate de excluderea și părtinirea în tehnologia lingvistică, vor duce la o mai bună precizie în afirmațiile despre modul în care cercetarea de prelucrare a limbajului natural poate generaliza și, prin urmare, rezultatele inginerești mai bune, protejează companiile de jena publică, și, în cele din urmă, să conducă la o tehnologie lingvistică care să satisfacă utilizatorii săi în stilul lor lingvistic preferat și, în plus, să nu-i reprezinte greșit altora.</abstract_ro>
      <abstract_si>මේ පත්තරේ අපි දත්ත ප්‍රවේශනය කරනවා ස්වභාවික භාෂාව ප්‍රවේශනය සහ විශේෂ ප්‍රවේශනයක් විදිහට සහ ප්‍රවේශනය දත්ත ප්‍රවේශනය සහ විශාල ප්‍රවේශනයෙන් ප්‍රවේශනය කරන්න පුළුවන් විශේෂ විද්‍යාත්මක සහ විද්‍යාත්මක ප්‍රශ්ණය සඳහා විශේෂ අපි දැනගන්න පුළුවන් දත්ත ප්‍රවේශනයක් ඒවා සාමාන්‍ය ප්‍රවේශනයේ කොටසක් විදියට ගන්න සහ පරීක්ෂණය කරන්න අපි ප්‍රශ්නයක් කරනවා දත්ත ප්‍රශ්නයක් භාෂාව ප්‍රශ්නයක් සම්බන්ධ විදිහට සම්බන්ධ විදිහට සම්බන්ධ විදිහට උදව් කරයි, භාෂාව ප්‍රශ ඒ වගේම අන්තිමේදී භාෂාව තාක්ෂණය ලබාගන්න පුළුවන් එයාලගේ භාෂාවික විදියට සම්බන්ධ වෙන්න පුළුවන් වෙන්</abstract_si>
      <abstract_sr>U ovom papiru predlažemo izjave podataka kao dizajnska rešenja i profesionalna praksa za prirodne tehnologije obrade jezika, u istraživanju i razvoju. Kroz usvajanje i široku upotrebu izjava podataka, polje može početi da rješava kritične naučne i etičke probleme koje rezultuju korištenjem podataka iz određenih populacija u razvoju tehnologije za druge populacije. Predstavljamo formu koju izjave podataka mogu uzeti i istražiti implikacije usvajanja ih kao deo redovne prakse. Tvrdimo da će izjave podataka pomoći smanjiti pitanja vezane za isključivanje i pristrasnost jezičke tehnologije, dovesti do bolje preciznosti tvrdnji o tome kako istraživanje prirodnog jezika može generalizirati i tako bolje in ženjerstvo, zaštititi kompanije od javne sramote, I na kraju vode do jezičke tehnologije koje upoznavaju svoje korisnike u svom sopstvenom preferiranom jezičkom stilu, a dodatno ih ne misle predstavljaju drugima.</abstract_sr>
      <abstract_sv>I denna uppsats föreslår vi datadeklarationer som en designlösning och professionell praktik för naturspråkstekniker, både inom forskning och utveckling. Genom antagande och utbredd användning av datadeklarationer kan fältet börja ta itu med kritiska vetenskapliga och etiska frågor som följer av användningen av data från vissa populationer i utvecklingen av teknik för andra populationer. Vi presenterar en form som datadeklarationer kan ta och undersöker konsekvenserna av att anta dem som en del av regelbunden praxis. Vi hävdar att datauttalanden kommer att bidra till att lindra problem relaterade till uteslutning och bias i språkteknik, leda till bättre precision i påståenden om hur naturspråksbehandling forskning kan generalisera och därmed bättre tekniska resultat, skydda företag från offentlig skam, och i slutändan leda till språkteknik som möter sina användare i deras egen föredragna språkstil och dessutom inte misstolkar dem för andra.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில், நாம் தகவல் குறிப்புகளை வடிவமைப்பு தீர்வு மற்றும் தொழில்நுட்ப மொழி செயல்பாட்டு தொழில்நுட்ப முற தரவு கூற்றுகளை பயன்படுத்துதல் மற்றும் விரிவாக பயன்படுத்தல் மூலம், புலம் தொடர்ந்து கொள்ள முடியும் மற்ற மக்களுக்கான தொழில்நுட்பத்தை உருவாக்குவதற We present a form that data statements can take and explore the implications of adopting them as part of regular practice.  நாங்கள் விவாதம் செய்கிறோம் என்றால் தரவு கூற்றுகள் மொழி தொழில்நுட்பத்தில் வெளியேற்றுதல் மற்றும் பிரிவினை பற்றிய பிரச்சனைகளை எளிதாக்குவது உதவும மேலும் இறுதியாக மொழி தொழில்நுட்பம் காண்பிக்கும் அது பயனர்களை தன்னுடைய விருப்பமான மொழி பாணியில் சந்திக்கும் மற்றும</abstract_ta>
      <abstract_ur>اس کاغذ میں، ہم ڈیٹا سٹیٹمنٹ کو ایک طراحی حل اور مسئولیت تکنولوژی پردازی تکنولوژی دانشمندوں کے لئے پیشنهاد کرتے ہیں، دونوں تحقیق اور تکنولوژی میں۔ ڈیٹا سٹیٹمنٹ کے مطابق قبول کرنے اور گھیرے ہوئے استعمال کے ذریعہ، فیلڈ مطابق ضروری علمی اور اخلاقی مسائل کے بارے میں شروع کر سکتا ہے جو کچھ جماعتوں سے ڈیٹا استعمال کرنے کے نتیجہ سے دوسری جماعتوں کے لئے تکنو ہم ایک فرم پیش کرتے ہیں جس کے ذریعہ ڈیٹا ڈیٹ سٹیٹمنٹ ان کو معمول عمل کے حصے سے قبول کرنے اور تحقیق کر سکتے ہیں۔ ہم argue that data statements will help reduce issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, اور بالآخر زبان تکنولوژی کی طرف لے جاتا ہے جو اپنے کارساز کو اپنے پسندیدہ زبان تکنولوژی طریقے سے ملتا ہے اور اس کے علاوہ ان کو دوسروں کے لئے غلط نمایاں نہیں کرتا۔</abstract_ur>
      <abstract_so>Qoraalkan waxaynu u soo jeedinnaa warqaddan macluumaadka sida xafiiska qorshaha iyo tababar xirfadeed oo loo baaraandegayo teknolojiyada kala baaraandegista luqada dabiicadda ah, baaritaanka iyo horumarinta. Dalbashada iyo isticmaalka macluumaadka oo ballaadhan ayaa duurku bilaabi karaa inuu kala hadlo arimaha cilmiga muhiimka ah iyo cilmiga la'aanta ah oo ka soo jeedo isticmaalka macluumaadka dadka qaarkood ka yimid horumarinta teknolojiga dadka kale. Waxaynu soo bandhignaynaa foomka lagu sheegi karo warqada macluumaadku ay qaadan karto iyo baarayn karto saamaynta soo qaadashada caadooyinka caadiga ah. Waxaynu ka sheekaynaynaa in qoraalka macluumaadku uu caawinayo inuu fududeeyo arrimaha la xiriira iskuulka luuqada ku saabsan kala baaraandegista luqada dabiicadda ah iyo sidoo kale ku habboon karo arimaha injiilka, shirkadaha ka ilaalinaya ceebta dadweynaha, iyo ugu dambaysta waxay u hogaansamaan teknolojiga luqada, taasoo isticmaalayaasha ku kulma qaab afkiisa la doortay oo aan khalad u dhigin dadka kale.</abstract_so>
      <abstract_uz>Bu qogʻozda, biz oddiy tillar teknologiyani boshqarish uchun dizayn va proff tizim sifatida maʼlumot tajribalarini tahrirlash va taʼminlovchi taʼminotlar qilamiz. Maʼlumot taʼminotlarini olish va kengaytirish orqali, maydonni boshqa odamlar uchun foydalanish uchun muhim ilmiy va etik muammolarni boshlab boshlab oladi. We present a form that data statements can take and explore the implications of adopting them as part of regular practice.  Biz murakkab qilamiz, ma'lumotlar tajribalarini o'zgartirish va tilning texnologiyaning taʼminotlarini yoqishga yordam beradi, va asl tilni boshqarish natijasi qanday taʼminlovchisi yaratish mumkin, va shunday qilib muhandiya natijasi natijasi natijasi natijasi natijasi natijasi natijasida muzdalarini yaratish mum va oxirida ishlatilgan foydalanuvchilarning o'zida o'z o'z o'zim uslubini ko'rib turadi va yana boshqalarni xato qilmaydi.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi đề xuất các báo cáo dữ liệu như một giải pháp thiết kế và tập luyện chuyên nghiệp cho kỹ thuật xử lý ngôn ngữ tự nhiên, trong cả nghiên cứu và phát triển. Qua việc thông qua và sử dụng thông báo dữ liệu rộng rãi, lĩnh vực này có thể bắt đầu giải quyết các vấn đề khoa học và đạo đức quan trọng kết quả từ việc sử dụng dữ liệu từ một số dân số trong việc phát triển công nghệ cho các dân khác. Chúng tôi đưa ra một hình thức mà các báo cáo dữ liệu có thể hình dung và khám phá những tác động của việc nhận nuôi nó như một phần của hành vi thông thường. Chúng tôi ủng hộ việc cung cấp dữ liệu sẽ giúp giảm bớt các vấn đề liên quan đến loại trừ và khuynh hướng trong công nghệ ngôn ngữ, dẫn đến việc xác định rõ ràng hơn về cách làm thế nào để nghiên cứu chế biến ngôn ngữ tự nhiên có thể phát huy kết quả tốt hơn, bảo vệ công ty khỏi sự xấu hổ. và cuối cùng cũng dẫn tới công nghệ ngôn ngữ gặp người dùng theo kiểu ngôn ngữ riêng mà họ thích và còn không hiểu sai về họ với người khác.</abstract_vi>
      <abstract_hr>U ovom papiru predlažemo izjave podataka kao rješenje dizajna i profesionalna prakse za tehnologije obrade prirodnog jezika, u istraživanju i razvoju. Kroz usvajanje i široku uporabu izjava podataka polje može početi rješavati kritične znanstvene i etičke pitanja koje su rezultate uporabe podataka iz određenih populacija u razvoju tehnologije za druge populacije. Predstavljamo oblik kojim bi izjave podataka mogle uzeti i istražiti posljedice usvajanja ih kao dio redovne prakse. Tvrdimo da će izjave podataka pomoći smanjiti pitanja vezane za isključenje i pristrasnost jezičke tehnologije, dovesti do bolje preciznosti tvrdnji o tome kako istraživanje prirodnog obrade jezika može generalizirati i tako bolje in ženjerski rezultati, zaštititi tvrtke od javne sramote, i na kraju vode do jezičke tehnologije koje se susreću sa svojim korisnicima u svojem preferiranom jezičkom stilu i dodatno ih ne predstavlja pogrešno drugima.</abstract_hr>
      <abstract_da>I denne artikel foreslår vi dataerklæringer som en designløsning og professionel praksis for natursprogbehandlingsteknikere, både inden for forskning og udvikling. Gennem vedtagelse og udbredt brug af dataerklæringer kan området begynde at behandle kritiske videnskabelige og etiske spørgsmål, der skyldes brugen af data fra visse populationer i udviklingen af teknologi til andre populationer. Vi præsenterer en form, som dataerklæringer kan tage, og undersøger konsekvenserne af at vedtage dem som en del af regelmæssig praksis. Vi hævder, at dataudtalelser vil hjælpe med at lindre spørgsmål relateret til udelukkelse og bias i sprogteknologi, føre til bedre præcision i påstande om, hvordan natursprogbehandling forskning kan generalisere og dermed bedre tekniske resultater, beskytte virksomheder mod offentlig forlegenhed, og i sidste ende føre til sprogteknologi, der møder brugerne i deres egen foretrukne sproglige stil og desuden ikke misrepræsenterer dem over for andre.</abstract_da>
      <abstract_nl>In dit artikel stellen we data statements voor als ontwerpoplossing en professionele praktijk voor natuurtaalverwerkingstechnologen, zowel in onderzoek als ontwikkeling. Door de goedkeuring en wijdverbreid gebruik van gegevensverklaringen, kan het veld beginnen kritische wetenschappelijke en ethische kwesties aan te pakken die voortvloeien uit het gebruik van gegevens van bepaalde populaties bij de ontwikkeling van technologie voor andere populaties. We presenteren een vorm die gegevensverklaringen kunnen aannemen en onderzoeken de implicaties van het toepassen ervan als onderdeel van de reguliere praktijk. We argumenteren dat gegevensverklaringen zullen helpen bij het verlichten van problemen met betrekking tot uitsluiting en vooroordelen in taaltechnologie, leiden tot betere precisie in claims over hoe natuurtaalverwerking onderzoek kan generaliseren en dus betere engineering resultaten, beschermen bedrijven tegen publieke verlegenheid, en uiteindelijk leiden tot taaltechnologie die zijn gebruikers ontmoet in hun eigen taalstijl en hen bovendien niet verkeerd voorstelt aan anderen.</abstract_nl>
      <abstract_bg>В настоящата статия предлагаме изявления за данни като дизайнерско решение и професионална практика за технологиите за обработка на естествени езици, както в научноизследователската, така и в разработката. Чрез приемането и широко разпространеното използване на изявления за данни, областта може да започне да се занимава с критични научни и етични въпроси, които произтичат от използването на данни от определени популации в развитието на технологии за други популации. Представяме форма, която декларациите за данни могат да приемат и изследваме последиците от приемането им като част от редовната практика. Ние твърдим, че декларациите за данни ще помогнат за облекчаване на проблемите, свързани с изключването и пристрастието в езиковите технологии, ще доведат до по-добра прецизност в твърденията за това как изследванията за обработка на естествения език могат да обобщят и по този начин да подобрят инженерните резултати, да предпазят компаниите от публично неудобство, и в крайна сметка водят до езикова технология, която отговаря на потребителите в собствения им предпочитан езиков стил и освен това не ги представя погрешно пред другите.</abstract_bg>
      <abstract_de>In diesem Beitrag schlagen wir Datensätze als Designlösung und professionelle Praxis für Natursprachverarbeitungstechnologen in Forschung und Entwicklung vor. Durch die Annahme und weitverbreitete Verwendung von Datenerklärungen kann das Feld beginnen, kritische wissenschaftliche und ethische Fragen anzugehen, die sich aus der Verwendung von Daten bestimmter Bevölkerungsgruppen bei der Entwicklung von Technologie für andere Bevölkerungsgruppen ergeben. Wir präsentieren eine Form, die Datenaussagen annehmen können, und untersuchen die Auswirkungen ihrer Übernahme als Teil der regulären Praxis. Wir argumentieren, dass Datenaussagen dazu beitragen werden, Probleme im Zusammenhang mit Ausschluss und Verzerrung in der Sprachtechnologie zu lindern, zu einer besseren Präzision in Behauptungen darüber führen, wie Forschung zur Verarbeitung natürlicher Sprache verallgemeinern und damit bessere Engineering-Ergebnisse erzielen kann, Unternehmen vor öffentlicher Verlegenheit schützen, und letztlich zu einer Sprachtechnologie führen, die ihren Nutzern in ihrem eigenen bevorzugten Sprachstil begegnet und sie darüber hinaus nicht falsch darstellt.</abstract_de>
      <abstract_id>Dalam kertas ini, kami mengusulkan pernyataan data sebagai solusi desain dan praktek profesional untuk teknis proses bahasa alam, dalam penelitian dan pengembangan. Melalui adopsi dan penggunaan luas dari pernyataan data, bidang ini dapat mulai mengatasi masalah ilmiah dan etika kritis yang berasal dari penggunaan data dari populasi tertentu dalam pengembangan teknologi untuk populasi lain. Kami mempersembahkan bentuk bahwa pernyataan data dapat mengambil dan mengeksplorasi implikasi adopsinya sebagai bagian dari praktek biasa. Kami menyangka bahwa pernyataan data akan membantu mengurangi isu-isu yang berhubungan dengan pengecualian dan bias dalam teknologi bahasa, menyebabkan presisi yang lebih baik dalam klaim tentang bagaimana penelitian proses bahasa alami dapat menyebar dan oleh itu hasil teknik yang lebih baik, melindungi perusahaan dari malu publik, Dan akhirnya memimpin teknologi bahasa yang bertemu penggunanya dalam gaya bahasa yang mereka suka dan selain itu tidak salah mewakili mereka kepada orang lain.</abstract_id>
      <abstract_fa>در این کاغذ، ما گزارش داده ها را به عنوان یک راه حل طراحی و تمرین حرفه ای برای تکنولوژی‌های پرداخت زبان طبیعی پیشنهاد می‌دهیم، در هر دو تحقیقات و توسعه. از طریق adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. ما یک فرم را پیشنهاد می‌کنیم که اعلام داده‌ها می‌توانند اثرات قبول آنها را به عنوان بخشی از تمرین معمولی بگیرند و تحقیق کنند. ما بحث می‌کنیم که اعلام داده‌ها کمک می‌کنند مسائل‌هایی که ارتباط به خارج کردن و طبیعت در تکنولوژی زبان دارند، به دقیق‌تر در ادعا می‌دهند که چگونه تحقیقات تحقیقات زبان طبیعی می‌تواند ژنرال و به نتیجه‌های مهندسی بهت و بالاخره به تکنولوژی زبان هدایت می‌کند که کاربران خود را در طریق زبان‌شناسی ترجیح می‌دهد و در ضمن آنها را به دیگران اشتباه نمایش نمی‌دهد.</abstract_fa>
      <abstract_ko>본고에서 우리는 데이터 문구가 자연 언어 처리 기술자로서 연구와 개발 중인 디자인 해결 방안과 전문적인 실천을 제시했다.데이터 성명을 채택하고 광범위하게 사용함으로써 이 분야는 관건적인 과학과 윤리 문제를 해결하기 시작할 수 있다. 이런 문제들은 다른 사람들을 위해 기술을 개발할 때 특정한 사람들의 데이터를 사용해서 발생한 것이다.우리는 데이터 성명이 채택할 수 있는 형식을 제시했고 이를 일반적인 실천의 일부로 하는 데 미친 영향을 분석했다.우리는 데이터 성명은 언어 기술에서의 배척과 편견과 관련된 문제를 완화시키고 자연 언어 처리 연구를 어떻게 보급하는지의 정확성을 높여 더욱 좋은 공사 결과를 얻고 회사가 대중의 난처함을 받지 않도록 보호하는 데 도움이 될 것이라고 생각한다.결국 언어 기술은 사용자가 좋아하는 언어 스타일로 그들의 수요를 충족시키고 다른 사람에게 그들을 곡해하지 못하게 된다.</abstract_ko>
      <abstract_sw>Katika karatasi hii, tunapendekeza matamko ya taarifa kama ufumbuzi wa ubunifu na mazoea ya kitaalamu kwa wanateknolojia wa utafiti na maendeleo ya asili. Kwa kupitia utekelezaji na usambazaji wa tamko la taarifa, uwanja unaweza kuanza kukabiliana na masuala muhimu ya kisayansi na maadili yanayotokana na matumizi ya taarifa kutoka kwa idadi fulani katika maendeleo ya teknolojia kwa ajili ya watu wengine. Tunaweka picha ambazo tamko la taarifa zinaweza kuchukua na kuchunguza matokeo ya kuasili kama sehemu ya utaratibu wa kawaida. Tunajadili kwamba matamko ya taarifa yatasaidia kupunguza masuala yanayohusiana na kutengwa na upendeleo katika teknolojia ya lugha, yanasababisha maelezo mazuri katika madai ya namna utafiti wa lugha za asili unavyoweza kutengeneza na kwa hiyo utafiti bora wa kihandisi, kulinda makampuni yasiyo na aibu ya umma, na hatimaye hupelekea teknolojia ya lugha ambayo inawakutana watumiaji wake katika mitindo yao ya lugha yenyewe yanayopendelea na zaidi hayawakilishi vibaya kwa wengine.</abstract_sw>
      <abstract_tr>Bu kagyzda, biz munyň maglumatlaryny tebigy dil işleýän teknolojikleriň, hem ylmy hem gelişmelerde tassym çözüm we profesyonel praktika hökmünde teknolojiler görkeýäris. Maglumat sözlerini götürmek we geniş arzanlamak bilen, saha başga milletler üçin teknolojiň gelişmesi üçin wajyp bilim we etik meselelerinden üýtgedip biler. Biz veri ifadelerini düzenli praktika uýgunlaşdyryp biljek we çözebiliriz. Biz maglumat sözlerini dil teknolojisi ýagdaýyndan aýrylmak we biaslaryň meselelerini azaltmak üçin kömekleşer diýip pikir edip otyrýarys. Täbiýe dil işleýän araştyrmalaryň nähili döredilebilir we şonuň üçin gowy in ženjeriýa netijelerini, kompaniýalary halk utan We iň soňunda ullançylaryny öz isleýän dil teknolojisine görýär. Mundan hem olary başgalaryna ýalňyşlyk görýär.</abstract_tr>
      <abstract_af>In hierdie papier voorstel ons data uitleggings as 'n ontwerp oplossing en profesionale praksie vir natuurlike taal verwerking teknologiseerdes, in beide ondersoek en ontwikkeling. Deur die aanvaar en uitbreidige gebruik van data-opklaring kan die veld begin om kritiese wetenskaplike en etiese probleem te raak wat van die gebruik van data van sekere populasies in die ontwikkeling van teknologie vir ander populasies resultaat word. Ons stel 'n vorm wat data belangrikings kan neem en uitsoek die implikasies van hulle as deel van gewone praksie aanneem. Ons argumenteer dat data belangrikings sal help verlos probleme wat verwante is met uitsluiting en voorspoediging in taal tegnologie, lei na beter presisie in voorspoedings oor hoe natuurlike taal verwerking verwerking kan genereliseer en dus beter in ženieringsresultate, beskerm maatskappye van publieke skande, En eindelik lei na taal teknologie wat sy gebruikers in hul eie voorkeure lingwisiese styl ontmoet en daarna verkeerd hulle nie aan ander verteenwoordig nie.</abstract_af>
      <abstract_am>በዚህ ካላት፣ ለፍጥረቱ ቋንቋዎች የቴክኖሎጂዎችን ለመቀናቀል እና ለፍጥረተ ቋንቋ ማቀናጃ እና የባለሞያ ትምህርት ማድረግ እናሳልጋለን፡፡ በጥቅምት እና በተስፋፋው የዳታ ንግግር መጠቀም መሬት ለሌሎቹ ሕዝብ የዳታ ጥያቄን ለመጠቀም የሚችሉትን የሳይንስ እና የኢትዮጵያ ጉዳዮች ለመጠቀም ይችላል፡፡ የዳታ ግንኙነቶች የሚወስደውን እና የዘወትር ጉዳይ እንዲወስዱ የሚችሉትን መልክ እናደርጋለን፡፡ የዳታ ግንኙነቶች የቋንቋ ቴክኖጂ እና የቋንቋ ትክክለኛ ጉዳዮች ማቅረብ ይችላል፣ የፍጥረት ቋንቋ ተሟጋቾች እንዴት እንዲያሳየው እና እንዴት እንደሚሻል የኢንጂንጂንስ ፍሬዎችን እንዲያሳውቅ፣ ኮምፒዩተርናዎችን ከህዝብ አፍረት እንዲጠብቅ፣ በመጨረሻውም የቋንቋ ቴክኖጂ ተጠቃሚዎቹን በተወደዱት ቋንቋ ቋንቋ-ቋንቋ ዓይነት የሚገናኙትን እና ደግሞ ለሌሎች ስሕተት አያሳልፉም፡፡</abstract_am>
      <abstract_sq>Në këtë letër, propozojmë deklaratat e të dhënave si një zgjidhje dizajni dhe praktikë profesionale për teknologët e procesimit natyror të gjuhës, si në kërkim ashtu edhe në zhvillim. Nëpërmjet miratimit dhe përdorimit të gjerë të deklaratave të të dhënave, fusha mund të fillojë të trajtojë çështje kritike shkencore e etike që rezultojnë nga përdorimi i të dhënave nga disa popullsi në zhvillimin e teknologjisë për popullsi të tjera. Ne paraqesim një form ë që deklaratat e të dhënave mund të marrin dhe të eksplorojnë pasojat e miratimit të tyre si pjesë e praktikës së rregullt. Argumentojmë se deklaratat e të dhënave do të ndihmojnë të lehtësojnë çështjet lidhur me përjashtimin dhe paragjykimin në teknologjinë gjuhësore, do të çojnë në saktësi më të mirë në pretendimet se si mund të gjeneralizohet kërkimi i procesimit natyror të gjuhës dhe kështu rezultatet më të mira të inxhinierisë, do të mbrojnë kompanitë nga Dhe përfundimisht çojnë në teknologji gjuhësore që takon përdoruesit e saj në stilin e tyre gjuhësor të preferuar dhe më tej nuk i përfaqëson ato gabimisht për të tjerët.</abstract_sq>
      <abstract_az>Bu kańüńĪzda, t…ôbi…ôtli dil iŇül…ôm…ô teknolojil…ôri √ľ√ß√ľn t…ôbi…ôtli √ß…ôtinlikl…ôr v…ô t…ôhsil praksisi kimi m…ôlumat ifad…ôl…ôrini t…ôklif edirik. Veri ifad…ôl…ôrini q…ôbul etm…ôk v…ô geniŇüliyi istifad…ô etm…ôk vasit…ôsil…ô, sah…ô baŇüqa q√∂vml…ôr √ľ√ß√ľn teknoloji t…ôhsil etm…ôsind…ô b…ôzi q√∂vml…ôrd…ôn veril…ôn m…ôlumatlarńĪn istifad…ôsind…ôn √ß…ôkilm…ôy…ô baŇülayabilir. Biz m…ôlumatlarńĪn ifad…ôsi onlarńĪ d√ľzg√ľn praksinin bir par√ßas ńĪ olaraq istifad…ô ed…ô bil…ôc…ôyi v…ô t…ôŇükil ed…ô bil…ôc…ôyi bir formu g√∂st…ôririk. Biz bel…ô iddia edirik ki, m…ôlumat ifad…ôl…ôri dil teknolojisind…ô t…ôkrarlanma v…ô t…ôkrarlanma m…ôs…ôl…ôl…ôrini …ôskiltm…ôy…ô k√∂m…ôk ed…ôc…ôk, t…ôbi…ôtli dil iŇül…ôm…ô araŇütńĪrmalarńĪnńĪn n…ôl…ôr t…ôkrarlanmasńĪnńĪ v…ô b√∂ylece daha xeyirli in Ňĺenjeri sonu√ßlarńĪnńĪ, Ňüirketl…ôri halkńĪ utandńĪrmasńĪndan qoruyacaq, Sonu√ßta dil teknolojisin…ô yol g√∂st…ôrm…ôk √ľ√ß√ľn istifad…ô√ßil…ôrini √∂zl…ôrinin se√ßilmiŇü dil stilind…ô tanńĪŇümaq v…ô buna g√∂r…ô d…ô onlarńĪ baŇüqalarńĪna yanlńĪŇü g√∂st…ôrm…ôz.</abstract_az>
      <abstract_hy>Այս թղթի մեջ մենք առաջարկում ենք տվյալների հայտարարություններ որպես դիզայնի լուծում և մասնագիտական գործընթաց բնական լեզվի վերամշակման տեխնոլոգիաների համար, ինչպես հետազոտության, ինչպես նաև զարգացման մեջ: Տեղեկատվական հայտարարությունների ընդունելու և տարածված օգտագործման միջոցով դաշտը կարող է սկսել լուծել կարևոր գիտական և էթիկական հարցեր, որոնք առաջացնում են որոշ բնակչության տվյալների օգտագործման արդյունքում այլ բնակչության տեխնոլոգիաների զարգացման մեջ: Մենք ներկայացնում ենք մի ձև, որը տվյալների հայտարարությունները կարող են վերցնել և ուսումնասիրել դրանց ընդունելու հետևանքները որպես սովորական գործընթացի մաս: Մենք փաստարկում ենք, որ տվյալների հայտարարությունները կօգնեն նվազեցնել լեզվի տեխնոլոգիաների բացառությամբ և կողմնականությամբ կապված խնդիրները, կհանգեցնեն ավելի ճշգրիտ հայտարարությունների մեջ այն մասին, թե ինչպես կարող է բնական լեզվի վերաբերյալ ուսումնասի Եվ ի վերջո հանգեցնել լեզվի տեխնոլոգիաներին, որոնք հանդիպում են իրենց օգտագործողներին իրենց սեփական լեզվաբանական ոճով և նաև չեն սխալ ներկայացնում նրանց ուրիշների հետ:</abstract_hy>
      <abstract_ca>In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development.  Amb l'adopció i l'ús generalitzat de les declaracions de dades, el camp pot començar a abordar temes científics i ètics crítics que resulten de l'ús de dades de determinades poblacions en el desenvolupament de la tecnologia per a altres poblacions. Presentam una form a en la que les declaracions de dades poden prendre i explorar les implicacions d'adoptar-les com part de pràctica regular. Afirmem que les declaracions de dades ajudaran a alleviar problemes relacionats amb l'exclusió i el bias en la tecnologia lingüística, donaran lloc a una millor precisió en les afirmacions sobre com la recerca sobre el processament natural de llenguatges pot generalitzar i, per tant, millor resultats d'enginyeria, protegeixen les empreses de l'avergonyiment públic i finalment portar a tecnologia lingüística que coneix als seus usuaris en el seu propi estil lingüístic preferit i que no els representa mal als altres.</abstract_ca>
      <abstract_bn>এই কাগজটিতে আমরা ডিজাইন সমাধান এবং প্রাকৃতিক ভাষা প্রক্রিয়ার প্রযুক্তিগত প্রযুক্তিবিদের জন্য প্রযুক্তিগত প্রযুক্ Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations.  আমরা একটি ফর্ম উপস্থাপন করছি যে তথ্যের বিবৃতি নিতে পারে এবং সেগুলোকে নিয়মিত প্রযুক্তির অংশ হিসেবে বিবেচনা করত আমরা যুক্তি দিচ্ছি যে ডাটা বিবৃতি ভাষার প্রযুক্তির সাথে বিচ্ছিন্ন এবং বৈষম্যের সাথে সম্পর্কিত বিষয়গুলোর সাহায্য করবে, যার ফলে প্রাকৃতিক ভাষা প্রক্ এবং অবশেষে ভাষার প্রযুক্তির কাছে যা তার ব্যবহারকারীদের নিজেদের পছন্দের ভাষাভাষায় দেখা যায় এবং তাদের অন্যদের কাছে ভুল প্</abstract_bn>
      <abstract_cs>V tomto článku navrhujeme datová výkazy jako návrhové řešení a odbornou praxi pro technology zpracování přirozeného jazyka, a to jak ve výzkumu, tak ve vývoji. Prostřednictvím přijetí a širokého používání datových prohlášení může obor začít řešit kritické vědecké a etické otázky, které vyplývají z používání dat od určitých populací při vývoji technologií pro jiné populace. Představujeme formu, kterou mohou mít datová prohlášení a zkoumáme důsledky jejich přijetí jako součást běžné praxe. Tvrdíme, že datová prohlášení pomohou zmírnit problémy související s vyloučením a zaujatostí v jazykových technologiích, povedou k lepší přesnosti tvrzení o tom, jak může výzkum zpracování přirozeného jazyka zobecnit, a tím i lepší inženýrské výsledky, chránit firmy před veřejnými trapami, a nakonec vedou k jazykové technologii, která se setkává s uživateli v jejich vlastním preferovaném jazykovém stylu a navíc je nepředstavuje špatně ostatním.</abstract_cs>
      <abstract_bs>U ovom papiru predlažemo izjave podataka kao dizajnsko rješenje i profesionalno prakse za prirodne tehnologije obrade jezika, u istraživanju i razvoju. Kroz usvajanje i široku uporabu izjava podataka, polje može početi rješavati kritične znanstvene i etičke probleme koje su rezultate korištenja podataka iz određenih populacija u razvoju tehnologije za druge populacije. Predstavljamo formu koju izjave podataka mogu uzeti i istražiti implikacije usvajanja ih kao dio redovne prakse. Tvrdimo da će izjave podataka pomoći smanjiti pitanja vezane za isključenje i pristrasnost jezičke tehnologije, dovesti do bolje preciznosti tvrdnji o tome kako istraživanje prirodnog obrade jezika može generalizirati i tako bolje in ženjerstvo, zaštititi kompanije od javne sramote, I na kraju vode do jezičke tehnologije koje se susreće sa svojim korisnicima u sopstvenom preferiranom jezičkom stilu i dodatno ih ne misle predstavljaju drugima.</abstract_bs>
      <abstract_et>Käesolevas töös pakume välja andmete avaldused kui disainilahendus ja professionaalne praktika looduskeele töötlemise tehnoloogidele nii teadus- kui arendustegevuses. Andmete avalduste vastuvõtmise ja laialdase kasutamise kaudu võib valdkond hakata käsitlema kriitilisi teaduslikke ja eetilisi küsimusi, mis tulenevad teatud populatsioonide andmete kasutamisest tehnoloogia arendamisel teistele populatsioonidele. Esitame vormi, mida andmete avaldused võivad võtta, ja uurime nende regulaarse praktika raames vastuvõtmise tagajärgi. Väidame, et andmete avaldused aitavad leevendada keeltehnoloogia tõrjutuse ja erapooletusega seotud probleeme, viivad parema täpsuseni väitetes selle kohta, kuidas looduskeele töötlemise uuringud võivad üldistada ja seega paremaid inseneritulemusi kaitsta ettevõtteid avaliku häbi eest, ja lõppkokkuvõttes viib keeltehnoloogiani, mis vastab oma kasutajatele nende eelistatud keelelises stiilis ega esita neid teistele valesti.</abstract_et>
      <abstract_fi>Tässä työssä ehdotamme datalausuntoja muotoiluratkaisuna ja ammattikäytäntönä luonnonkielen käsittelyteknikoille sekä tutkimuksessa että kehityksessä. Tietolausuntojen käyttöönoton ja laajan käytön avulla ala voi alkaa käsitellä kriittisiä tieteellisiä ja eettisiä kysymyksiä, jotka johtuvat tiettyjen väestöryhmien tietojen käytöstä teknologian kehittämisessä muille väestöille. Esitämme lomakkeen, jonka tietolausunnot voivat omaksua, ja tarkastelemme niiden käyttöönoton vaikutuksia osana tavanomaista käytäntöä. Väitämme, että tietolausunnot auttavat lieventämään kieliteknologian syrjäytymiseen ja ennakkoluuloihin liittyviä kysymyksiä, johtavat tarkempaan tarkkuuteen väitteissä siitä, miten luonnollisen kielen käsittelytutkimus voi yleistää ja siten parantaa teknisiä tuloksia, suojella yrityksiä julkisuudelta häpeältä, ja lopulta johtaa kieliteknologiaan, joka kohtaa käyttäjiään heidän haluamallaan kielellisellä tyylillä eikä myöskään vääristele heitä muille.</abstract_fi>
      <abstract_jv>Nang kuwi iki, awak dhéwé ngerasakno perusahaan dadi kanggo nguasakno karo perusahaan tentang kanggo aliwat tentang kanggo ngerasakno panganan ingkang sampek Ato ngubah winih lan akeh perusahaan anyar dadi nggawe gerapakan, kesempatan iso mulai dadi sakjane biyensi lan etik sing gagal dhéwé kuwi ngéwé diuasakno dadi sakjane kanggo nggawe populasi sing berarti tekno nggawe populasi sing wis ana. Awak dhéwé éntuk akeh pernik dadi nggawe lan kelas kuwi nggawe gerakan kelas kuwi nggawe barang penggunaké ora bisa pasar kang biasane pratik biasane. Awak dhéwé sawetara data perusahaan nggawe ngubah perusahaan anyar tentang karo cah-ingkang karo perusahaan karo teknçologi luwih-ingkang, dadi kapan kanggo diangkat sing luwih apik dhéwé, akeh nyong nggawe ngubah perusahaan langkung sampeyan sak susahé sakjane lan sakjane akeh injer Sampeyan ngono nglanggar aturan teknôlogi sing dumadhi iki dadi pengguna-pengguna anyar tentang kanggo ngerasakno.</abstract_jv>
      <abstract_he>בעיתון הזה, אנו מציעים הצהרות של נתונים כפתרון עיצוב ופעולה מקצועית לטכנולוגי עיבוד שפה טבעית, גם במחקר וגם בפיתוח. באמצעות האימוץ והשימוש המפורסם של הצהרות הנתונים, השטח יכול להתחיל להתמודד עם בעיות מדעיות ואטיות קריטיות שהולכות מהשימוש בנתונים מאוכלוסיות מסוימות בפיתוח הטכנולוגיה לאוכלוסיות אחרות. אנחנו מציגים צורה שתצהרות נתונים יכולות לקחת ולחקר את השלכות של האימוץ אותם כחלק מהתרגיל הרגיל. אנחנו מתווכחים כי הצהרות נתונים יעזרו להקל את הנושאים הקשורים לברידה ולהיחידות בטכנולוגיה לשפה, להוביל לדיוק טוב יותר בטענות איך מחקר עיבוד שפה טבעי יכול להתרחב ולכן תוצאות הנדסה טובות יותר, להגן על חברות מהביישה הציבורית, ובסופו של דבר הוביל לטכנולוגיה לשפה שמפגשת את המשתמשים שלה בסגנון הלשוני המועדף שלהם ולא מייצג אותם בצורה לא נכונה לאחרים.</abstract_he>
      <abstract_sk>V prispevku predlagamo podatkovne izjave kot oblikovalsko rešitev in strokovno prakso za tehnologije obdelave naravnega jezika, tako v raziskavah kot v razvoju. S sprejetjem in široko uporabo podatkovnih izjav lahko področje začne obravnavati kritična znanstvena in etična vprašanja, ki izhajajo iz uporabe podatkov določenih populacij pri razvoju tehnologije za druge populacije. Predstavljamo obliko izjav o podatkih in raziskujemo posledice njihovega sprejemanja kot del redne prakse. Trdimo, da bodo izjave o podatkih pomagale ublažiti vprašanja, povezana z izključevanjem in pristranskostjo v jezikovni tehnologiji, vodile k boljši natančnosti pri trditvah o tem, kako lahko raziskave obdelave naravnega jezika posplošijo in s tem boljše inženirske rezultate, zaščitile podjetja pred javno zadrego, in končno vodijo do jezikovne tehnologije, ki uporabnikom ustreza v njihovem želenem jezikovnem slogu in jih poleg tega ne napačno predstavlja drugim.</abstract_sk>
      <abstract_ha>Ga wannan takardan, Munã buɗa bayani ga data kamar tamkar na'urar da mazaɓa wa masu zartar da zane-zane masu natsuwa, a cikin laban lõkaci da taƙaitãwa. Tafiyar da ɗauki da widen amfani da bayani na bayani na data, field yana iya fara ta tambayi masu muhimmi na masu sakan da aka sani na masu tsayi, da matsayi wanda ke ƙara amfani da data daga wasu jama'a cikin the developer technical ga wasu mutane. Tuna sami wani fomat da bayani za'a iya sami da kuma ke sami matsayin ya kamata su kamar rabo na daidaita. Tuna jãyayya cẽwa statements na danganta zai taimake masu sauƙaƙara masu husũma da cire-faɗi da ke cikin technical na harshen, yana ƙara mafiya ƙayyade a cikin madaidaita a kan cewa yadda mutane za'a iya ƙara fassarar harshen na asali, kuma don haka da fassarar masu da mafiya alhẽri na masu tsari makampuni daga aibu, kuma a ƙarshen ta gabatar zuwa technical lugha wanda ke haɗa masu amfani da shi a cikin misalin harshen na'anar da kuma yana da haka, bã ya halatta su ga wasu.</abstract_ha>
      <abstract_bo>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ལྟ་བུའི་ཐབས་ཤེས་དང་ལས་རྒྱུན་གྱི་སྣ་ཚོགས་ཀྱི་ཐབས་ཤེས་དང་། བྱ་བ་དང་ཞུན་དག་གི་སྤྱོད་པར་བརྗོད་ལ་ཞིབ་འཇུག་པའི་རྒྱུ་དངོས། ང་ཚོས་གསལ་བཤད་ཀྱི་དབྱིབས་ཞིག་ཡོད་པ་ལ་རྒྱུན་ལྡན་གྱི་ལག་ལེན་བྱེད་སྟངས་དང་འཚོལ་ཞིབ་བྱེད་ཐུབ། ང་ཚོས་བརྗོད་ཀྱི་གསལ་བཤད་ཆ་མཉམ་དུ་སྤྱི་ཚོགས་ལས་ཀར་རྐྱེན་བཟོ་བྱེད་ན། མཐའ་མཇུག་དུ་སྐད་ཡིག་འཕེལ་རིགས་ལ་སྤྱོད་མཁན་གྱི་རང་གི་སྤྱོད་མཁན་གྱི་སྐད་རིགས་སྤྲོད་ཀྱི་ཡོད།</abstract_bo>
      </paper>
    <paper id="44">
      <title>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</title>
      <author><first>Xiao</first><last>Pu</last></author>
      <author><first>Nikolaos</first><last>Pappas</last></author>
      <author><first>James</first><last>Henderson</last></author>
      <author><first>Andrei</first><last>Popescu-Belis</last></author>
      <doi>10.1162/tacl_a_00242</doi>
      <abstract>This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words. We first introduce three adaptive clustering algorithms for WSD, based on <a href="https://en.wikipedia.org/wiki/K-means_clustering">k-means</a>, Chinese restaurant processes, and <a href="https://en.wikipedia.org/wiki/Random_walk">random walks</a>, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data. We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system. We show that the concatenation of these <a href="https://en.wikipedia.org/wiki/Vector_space">vectors</a>, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones. This is demonstrated by <a href="https://en.wikipedia.org/wiki/Translation">translation</a> on five language pairs. The improvements are more than 1 BLEU point over strong NMT baselines, +4 % accuracy over all ambiguous nouns and verbs, or +20 % when scored manually over several challenging words.</abstract>
      <pages>635–649</pages>
      <video href="https://vimeo.com/385255818" />
      <url hash="30cfdcb8">Q18-1044</url>
      <bibkey>pu-etal-2018-integrating</bibkey>
      <pwccode url="https://github.com/idiap/sense_aware_NMT" additional="false">idiap/sense_aware_NMT</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    <title_ar>دمج توضيح معنى الكلمة الخاضع للإشراف الضعيف في ترجمة الآلة العصبية</title_ar>
      <title_fr>Intégration de la désambiguïsation du sens des mots faiblement supervisée dans la traduction</title_fr>
      <title_pt>Integrando a Desambiguação de Sentido de Palavras Fracamente Supervisionada na Tradução Automática Neural</title_pt>
      <title_es>Integración de la desambiguación del sentido de las palabras débilmente supervisada en la traducción automática neuronal</title_es>
      <title_ja>弱く監視されたワードセンスの曖昧さを神経機械翻訳に統合する</title_ja>
      <title_zh>将弱监词义消歧集成神经机器翻译中</title_zh>
      <title_hi>न्यूरल मशीन अनुवाद में कमजोर रूप से पर्यवेक्षित वर्ड सेंस बहुविकल्पी को एकीकृत करना</title_hi>
      <title_ru>Интеграция слабо контролируемого дезагрегированного восприятия слов в нейронный машинный перевод</title_ru>
      <title_ga>Ag Comhtháthú Dí-athbhrí Mothúchán Focal faoi Mhaoirseacht Lag san Aistriúchán Meaisín Néarach</title_ga>
      <title_ka>Name</title_ka>
      <title_it>Integrare la disambiguazione del senso delle parole debolmente supervisionata nella traduzione automatica neurale</title_it>
      <title_el>Ενσωμάτωση ασθενώς εποπτευόμενης αποσαφήνισης της αίσθησης λέξεων στη Νευρική Μηχανική Μετάφραση</title_el>
      <title_hu>A gyengén felügyelt szóérzék szétbontásának integrálása a neurális gépi fordításba</title_hu>
      <title_lt>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</title_lt>
      <title_ml>ആഴ്ചപ്പെടുത്തിയ വാക്കിന്റെ സെന്‍സിന്റെ അസംഭാഷണം നെയുറല്‍ മെഷീനിലേക്ക് ചേര്‍ക്കുന്നു</title_ml>
      <title_mk>Интегрирање на слабо надгледувано размислување на зборовите во превод на неврална машина</title_mk>
      <title_ms>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</title_ms>
      <title_mt>L-integrazzjoni tad-diżambigwar tas-Sens tal-kliem b’Superviżjoni dgħajfa fit-Traduzzjoni tal-Makkinarju Newrali</title_mt>
      <title_no>Integrerer vekkelig oversikt av ordførselsen i neiralt maskinsomsetjing</title_no>
      <title_pl>Integracja słabo nadzorowanego rozmysłu słowa w neuronowym tłumaczeniu maszynowym</title_pl>
      <title_ro>Integrarea dezambiguizării simțului cuvintelor slab supravegheate în traducerea automată neurală</title_ro>
      <title_sr>袠薪褌械谐褉邪褑懈褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褬褍褯懈 褋谢芯胁邪 薪邪写蟹芯褉械薪械 褋谢芯胁邪 写械邪屑斜懈谐胁邪褑懈褬褍褬褍褬褍褬褍褯械 褍 薪械胁褉邪谢薪芯谐 锌褉械胁芯写邪</title_sr>
      <title_si>සාමාන්‍ය බලාපොරොත්තු වචනය සම්බන්ධ කරනවා න්‍යූරල් මැෂින් පරිවර්තනයට අවශ්‍යය</title_si>
      <title_so>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</title_so>
      <title_sv>Att integrera svagt övervakad ordsinnesdeklaration i neural maskinöversättning</title_sv>
      <title_ta>வாரத்தில் பரிசோதிக்கப்பட்ட வார்த்தைக்கான மொழிபெயர்ப்புகளை புதிய இயந்திரம் மொழிபெயர்ப்பில் சேர்</title_ta>
      <title_ur>نائرل ماشین ترجمہ میں کم سامنے نظارت والی لفظ سنس نامبیواٹ</title_ur>
      <title_kk>Көңіл бақылап тұрған сөздер сезімін нейрондық машинаның аудармасына қосылу</title_kk>
      <title_mn>Төмөр хүндрэлтэй хүндрэлтэй үг мэдрэгч сэтгэл хөдлөл сэтгэл хөдлөлд</title_mn>
      <title_vi>Sự biến đổi trong việc lắp ghép máy thần kinh</title_vi>
      <title_uz>Query</title_uz>
      <title_nl>Integratie van zwak begeleide woordzintuig disambiguatie in neuronale machinevertaling</title_nl>
      <title_hr>Uključujući slabe nadzorne riječi Disambiguaciju osjećaja riječi u prevod neuroloških strojeva</title_hr>
      <title_da>Integrering af svagt overvåget ordsanse Disambiguation i Neural Machine Translation</title_da>
      <title_bg>Интегриране на слабо контролираното разочарование на словото в невралния машинен превод</title_bg>
      <title_de>Integration der schwach überwachten Wortsinn-Disambiguation in die neuronale maschinelle Übersetzung</title_de>
      <title_ko>약한 감독 단어의 뜻을 신경 기계 번역에 집적하다</title_ko>
      <title_fa>جمع کردن کلمه تحت نظارت ضعیف در ترجمه ماشین عصبی</title_fa>
      <title_id>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</title_id>
      <title_tr>Aýratyn Gözlenýän Sözler Senedleri Nural Makina Terjime Edilýär</title_tr>
      <title_sq>Integrimi i zhdukjes së ndjeshmërisë së fjalës me mbikqyrje të dobët në përkthimin e makinës nervore</title_sq>
      <title_am>ምርጫዎች</title_am>
      <title_sw>Kuunganisha neno linalohusishwa na Wiki</title_sw>
      <title_hy>Նյարդային մեքենայի թարգմանություն</title_hy>
      <title_bn>সপ্তাহে সুপার্টভিস্ট শব্দের সেন্স বিভ্রান্তি নিউরাল মেশিন অনুবাদে যুক্ত করা হচ্ছে</title_bn>
      <title_az>仃뙲慬⁍慫楮慴⁔즙牣쎼淃뱮즙⁁쒟쒱爠䟃뙺泉駅齤楲楬浩얟⁋敬業椠쒰浸慬⁅琊</title_az>
      <title_af>Comment</title_af>
      <title_bs>Uključujući slabe nadzorne riječi Disambiguaciju osjećaja riječi u neuronski prevod stroja</title_bs>
      <title_ca>Integrar el desambiguatge del sentit de paraules debidament supervisades a la traducció de màquines neuronals</title_ca>
      <title_et>Nõrgalt järelevalvestatud sõnatunde disambiguatsiooni integreerimine neuromasintõlkesse</title_et>
      <title_fi>Heikon valvotun sanaaistin hajottamisen integrointi neurokonekäännökseen</title_fi>
      <title_cs>Integrace slabě dohlížené disambiguace slovního smyslu do neurálního strojového překladu</title_cs>
      <title_ha>dictionary variant</title_ha>
      <title_jv>Subtitles</title_jv>
      <title_he>השתלב של חוש מילים ששולטים בצורה חלשה לתרגום מכונת עצבית</title_he>
      <title_sk>Vključevanje slabo nadzorovanega razočaranja besednega smisla v živčni strojni prevod</title_sk>
      <title_bo>Integrating Weakly Supervised Word Sense Disambiguation in Neural Machine Translation</title_bo>
      <abstract_ar>توضح هذه الورقة أن إزالة الغموض عن معنى الكلمة (WSD) يمكن أن يحسن الترجمة الآلية العصبية (NMT) من خلال توسيع سياق المصدر الذي يؤخذ في الاعتبار عند نمذجة حواس الكلمات التي يحتمل أن تكون غامضة. نقدم أولاً ثلاث خوارزميات تجميع تكيفية لـ WSD ، بناءً على الوسائل k ، وعمليات المطاعم الصينية ، والمشي العشوائي ، والتي يتم تطبيقها بعد ذلك على سياقات الكلمات الكبيرة الممثلة في مساحة منخفضة الرتبة وتقييمها على بيانات المهام المشتركة SemEval. نتعلم بعد ذلك متجهات الكلمات بشكل مشترك مع متجهات المعنى المحددة بواسطة أفضل طريقة WSD لدينا ، ضمن نظام NMT الحديث. نظهر أن تسلسل هذه النواقل ، واستخدام آلية اختيار الحواس على أساس المتوسط المرجح لمتجهات الحواس ، يتفوق على العديد من خطوط الأساس بما في ذلك تلك الواعية للحواس. يتضح هذا من خلال الترجمة على خمسة أزواج لغوية. التحسينات هي أكثر من نقطة BLEU واحدة على خطوط أساسية NMT قوية ، + 4٪ دقة على جميع الأسماء والأفعال الغامضة ، أو + 20٪ عند تسجيلها يدويًا على عدة كلمات صعبة.</abstract_ar>
      <abstract_es>Este artículo demuestra que la desambiguación del sentido de las palabras (WSD) puede mejorar la traducción automática neuronal (NMT) al ampliar el contexto fuente considerado al modelar los sentidos de palabras potencialmente ambiguas. Primero introducimos tres algoritmos de agrupamiento adaptativo para WSD, basados en k-means, procesos de restaurantes chinos y paseos aleatorios, que luego se aplican a contextos de palabras grandes representados en un espacio de rango bajo y se evalúan en datos de tareas compartidas de SemEval. Luego aprendemos vectores de palabras junto con vectores de sentido definidos por nuestro mejor método WSD, dentro de un sistema NMT de última generación. Mostramos que la concatenación de estos vectores, y el uso de un mecanismo de selección de sentido basado en el promedio ponderado de los vectores de sentido, supera a varias líneas de base, incluidas las que tienen en cuenta los sentidos. Esto se demuestra mediante la traducción en cinco pares de idiomas. Las mejoras son de más de 1 punto BLEU sobre las líneas de base NMT sólidas, +4% de precisión sobre todos los sustantivos y verbos ambiguos, o +20% cuando se puntúan manualmente en varias palabras desafiantes.</abstract_es>
      <abstract_fr>Cet article démontre que la désambiguïsation des sens des mots (WSD) peut améliorer la traduction automatique neuronale (NMT) en élargissant le contexte source pris en compte lors de la modélisation des sens de mots potentiellement ambigus. Nous introduisons d'abord trois algorithmes de clustering adaptatifs pour WSD, basés sur des k-means, des processus de restaurant chinois et des promenades aléatoires, qui sont ensuite appliqués à des contextes de mots larges représentés dans un espace de bas rang et évalués sur des données de tâches partagées SemEval. Nous apprenons ensuite les vecteurs de mots conjointement avec les vecteurs sens définis par notre meilleure méthode WSD, au sein d'un système NMT de pointe. Nous montrons que la concaténation de ces vecteurs, et l'utilisation d'un mécanisme de sélection de sens basé sur la moyenne pondérée des vecteurs de sens, surpasse plusieurs niveaux de référence, y compris ceux sensibles aux sens. Cela est démontré par la traduction sur cinq paires de langues. Les améliorations sont supérieures à 1 point BLEU par rapport aux bases NMT fortes, +4% de précision pour tous les noms et verbes ambigus, ou +20 % lorsqu'ils sont notés manuellement sur plusieurs mots difficiles.</abstract_fr>
      <abstract_pt>Este artigo demonstra que a desambiguação de sentido de palavra (WSD) pode melhorar a tradução automática neural (NMT) ampliando o contexto de origem considerado ao modelar os sentidos de palavras potencialmente ambíguas. Primeiro, introduzimos três algoritmos de agrupamento adaptativos para WSD, baseados em k-means, processos de restaurantes chineses e passeios aleatórios, que são então aplicados a contextos de palavras grandes representados em um espaço de baixa classificação e avaliados em dados de tarefas compartilhadas SemEval. Em seguida, aprendemos vetores de palavras em conjunto com vetores de sentido definidos pelo nosso melhor método WSD, dentro de um sistema NMT de última geração. Mostramos que a concatenação desses vetores e o uso de um mecanismo de seleção de sentido baseado na média ponderada dos vetores de sentido supera várias linhas de base, incluindo as sensíveis ao sentido. Isso é demonstrado pela tradução em cinco pares de idiomas. As melhorias são mais de 1 ponto BLEU sobre linhas de base NMT fortes, +4% de precisão sobre todos os substantivos e verbos ambíguos ou +20% quando pontuados manualmente em várias palavras desafiadoras.</abstract_pt>
      <abstract_ja>本論文は、潜在的に曖昧な単語の感覚をモデル化する際に考慮されるソースコンテキストを拡大することにより、単語センス曖昧化（ WSD ）が神経機械翻訳（ NMT ）を改善することができることを示している。 まず、K平均、中国のレストランプロセス、ランダムウォークに基づいたWSDのための3つの適応的なクラスタリングアルゴリズムを紹介します。これらのアルゴリズムは、低ランクのスペースで表される大きな単語コンテキストに適用され、SemEval共有タスクデータで評価されます。 そして、私たちは最先端のNMTシステム内で、最高のWSD法によって定義された感覚ベクトルと共同でワードベクトルを学びます。 これらのベクトルの連結と、センスベクトルの加重平均に基づくセンス選択メカニズムの使用は、センス認識ベクトルを含むいくつかのベースラインを上回ることを示しています。 これは、5つの言語ペアの翻訳によって実証されています。 改善点は、強力なNMTベースラインに対して1つ以上のBLEUポイント、すべての曖昧な名詞や動詞に対して+4%の精度、またはいくつかの困難な単語に対して手動でスコアを付けた場合+20%です。</abstract_ja>
      <abstract_zh>本文明白,词义消歧义(WSD)可以广模棱之义建模思虑之源上下文以改神经机器翻译(NMT)。 先言三 k 均值、中国餐馆流、游走之 WSD 自适聚类算法,然后施于卑秩空间之大单词上下文,而料之于 SemEval 。 然后先进之NMT统,将词向量与我最上WSD法义之官向量共学之。 臣等明此向量之联,及于感官向量加权平均值之感官择机制之用,优于感知基线在内数基线。 此可以五言对译证之也。 比之强NMT基线,其改进过1 BLEU分,于诸含糊不清名动词准确率为+4%,或数挑战性之单词手动评分为+20%。</abstract_zh>
      <abstract_hi>यह पेपर दर्शाता है कि शब्द भावना बहुविकल्पी (डब्ल्यूएसडी) संभावित रूप से अस्पष्ट शब्दों की इंद्रियों को मॉडलिंग करते समय विचार किए गए स्रोत संदर्भ को चौड़ा करके तंत्रिका मशीन अनुवाद (एनएमटी) में सुधार कर सकता है। हम पहले WSD के लिए तीन अनुकूली क्लस्टरिंग एल्गोरिदम पेश करते हैं, जो k-means, चीनी रेस्तरां प्रक्रियाओं और यादृच्छिक चलता है, जो तब कम रैंक वाले स्थान में प्रतिनिधित्व किए गए बड़े शब्द संदर्भों पर लागू होते हैं और SemEval साझा-कार्य डेटा पर मूल्यांकन किया जाता है। फिर हम अपने सर्वश्रेष्ठ डब्ल्यूएसडी विधि द्वारा परिभाषित भावना वैक्टर के साथ संयुक्त रूप से शब्द वैक्टर सीखते हैं, एक अत्याधुनिक एनएमटी प्रणाली के भीतर। हम दिखाते हैं कि इन वैक्टरों का संयोजन, और भावना वैक्टर के भारित औसत के आधार पर एक भावना चयन तंत्र का उपयोग, भावना-जागरूक लोगों सहित कई आधार रेखाओं को मात देता है। यह पांच भाषा जोड़े पर अनुवाद द्वारा प्रदर्शित किया जाता है। सुधार मजबूत NMT बेसलाइन पर 1 BLEU बिंदु से अधिक हैं, सभी अस्पष्ट संज्ञाओं और क्रियाओं पर +4% सटीकता, या कई चुनौतीपूर्ण शब्दों पर मैन्युअल रूप से स्कोर किए जाने पर +20% हैं।</abstract_hi>
      <abstract_ru>Эта статья демонстрирует, что дезактивация смысла слова (WSD) может улучшить нейронный машинный перевод (NMT), расширяя исходный контекст, рассматриваемый при моделировании чувств потенциально неоднозначных слов. Сначала мы вводим три адаптивных алгоритма кластеризации для WSD, основанных на k-средних, китайских ресторанных процессах и случайных прогулках, которые затем применяются к крупным контекстам слов, представленным в низкоранговом пространстве и оцениваемым по данным совместной задачи SemEval. Затем мы изучаем векторы слов совместно с векторами смысла, определенными нашим лучшим методом WSD, в самой современной системе NMT. Мы показываем, что конкатенация этих векторов и использование механизма выбора смысла, основанного на средневзвешенном значении векторов смысла, превосходит несколько базовых линий, в том числе и осознающих смысл. Это подтверждается переводом на пять языковых пар. Улучшения составляют более 1 балла BLEU по сравнению с сильными базовыми линиями НБ, точность +4% для всех неоднозначных существительных и глаголов или +20% при оценке вручную по нескольким сложным словам.</abstract_ru>
      <abstract_ga>Léiríonn an páipéar seo gur féidir le dí-athbhrí ar chiall na bhfocal (WSD) aistriúchán meaisín néarach (NMT) a fheabhsú tríd an comhthéacs foinse a breathnaíodh a leathnú agus céadfaí focail a d’fhéadfadh a bheith débhríoch a shamhaltú. Tugaimid isteach ar dtús trí algartam cnuasaithe oiriúnaitheach do WSD, bunaithe ar k-acmhainní, próisis bhialainne na Síne, agus siúlóidí randamacha, a chuirtear i bhfeidhm ansin ar chomhthéacsanna móra focal a léirítear i spás íseal-ranga agus a ndéantar meastóireacht orthu ar shonraí tasc comhroinnte SemEval. Ansin foghlaimímid veicteoirí focal i gcomhpháirt le veicteoirí céadfacha arna sainiú ag ár modh WSD is fearr, laistigh de chóras NMT úrscothach. Léirímid go sáraíonn comhchuibhiú na veicteoirí seo, agus úsáid meicníocht roghnúcháin céadfaí bunaithe ar mheán ualaithe na veicteoirí céadfaí, roinnt bonnlínte lena n-áirítear cinn atá feasach ar chiall. Léirítear é seo san aistriúchán ar chúig phéire teanga. Tá na feabhsuithe níos mó ná 1 phointe BLEU thar bhunlínte láidre NMT, +4% cruinneas thar gach ainmfhocal agus briathar débhríoch, nó +20% nuair a dhéantar é a scóráil de láimh thar roinnt focal dúshlánach.</abstract_ga>
      <abstract_hu>Ez a tanulmány bemutatja, hogy a szóérzékek egyértelműsítése (WSD) javíthatja az idegi gépi fordítást (NMT) azáltal, hogy kiterjeszti a potenciálisan kétértelmű szavak érzékeinek modellezésekor figyelembe vett forráskörnyezetet. Először három adaptív klaszterezési algoritmust vezetünk be a WSD-hez, amelyek k-jelentéseken, kínai éttermi folyamatokon és véletlenszerű sétákon alapulnak, majd alkalmazunk nagy szókontextusokra, amelyeket alacsony rangú térben reprezentálnak és értékelnek SemEval megosztott feladat adatain. Ezután a legjobb WSD módszerünkkel meghatározott érzékvektorokkal együtt tanulunk meg szóvektorokat egy korszerű NMT rendszeren belül. Megmutatjuk, hogy ezeknek a vektoroknak az összekapcsolódása, valamint az érzékszervektorok súlyozott átlagán alapuló érzékszerválasztási mechanizmusának alkalmazása több alapvonalat felülmúlja, beleértve az érzékszerválasztókat is. Ezt öt nyelvpáron történő fordítás bizonyítja. A fejlesztések több mint 1 BLEU pont az erős NMT alapvonalakhoz képest, +4% pontosság az összes kétértelmű főnevhez és igéhez képest, vagy +20% ha manuálisan értékelik több kihívást jelentő szót.</abstract_hu>
      <abstract_el>Η παρούσα εργασία καταδεικνύει ότι η αποσαφήνιση λέξεων μπορεί να βελτιώσει τη νευρωνική μηχανική μετάφραση διευρύνοντας το πλαίσιο προέλευσης που λαμβάνεται υπόψη κατά τη μοντελοποίηση των αισθήσεων πιθανώς διφορούμενων λέξεων. Αρχικά εισάγουμε τρεις προσαρμοστικούς αλγόριθμους ομαδοποίησης για το WSD, βασισμένους σε κινέζικες διαδικασίες εστιατορίων και τυχαίες βόλτες, οι οποίοι στη συνέχεια εφαρμόζονται σε μεγάλα πλαίσια λέξεων που αντιπροσωπεύονται σε ένα χώρο χαμηλής κατάταξης και αξιολογούνται σε δεδομένα κοινής εργασίας SemEval. Στη συνέχεια μαθαίνουμε διανύσματα λέξεων από κοινού με διανύσματα αισθήσεων που ορίζονται από την καλύτερη μέθοδο μας μέσα σε ένα υπερσύγχρονο σύστημα NMT. Δείχνουμε ότι η αλληλουχία αυτών των διανυσμάτων, και η χρήση ενός μηχανισμού επιλογής αισθήσεων βασισμένου στον σταθμισμένο μέσο όρο των διανυσμάτων αισθήσεων, ξεπερνά αρκετές γραμμές βάσης, συμπεριλαμβανομένων αυτών που έχουν επίγνωση των αισθήσεων. Αυτό αποδεικνύεται από τη μετάφραση σε πέντε γλωσσικά ζεύγη. Οι βελτιώσεις είναι πάνω από ένα σημείο πάνω από ισχυρές γραμμές βάσης, +4% ακρίβεια πάνω από όλα τα διφορούμενα ουσιαστικά και ρήματα, ή +20% όταν βαθμολογείται χειροκίνητα σε αρκετές δύσκολες λέξεις.</abstract_el>
      <abstract_it>Questo articolo dimostra che la disambiguazione dei sensi delle parole (WSD) può migliorare la traduzione automatica neurale (NMT) ampliando il contesto sorgente considerato quando si modellano i sensi di parole potenzialmente ambigue. Per prima cosa introduciamo tre algoritmi di clustering adattivo per WSD, basati su k-means, processi di ristorazione cinese e passeggiate casuali, che vengono poi applicati a contesti di parole di grandi dimensioni rappresentati in uno spazio di basso rango e valutati su dati di attività condivise SemEval. Impariamo i vettori di parole insieme ai vettori di senso definiti dal nostro miglior metodo WSD, all'interno di un sistema NMT all'avanguardia. Mostriamo che la concatenazione di questi vettori, e l'uso di un meccanismo di selezione dei sensi basato sulla media ponderata dei vettori di senso, supera diverse linee di base, comprese quelle sensitive. Lo dimostra la traduzione su cinque coppie linguistiche. I miglioramenti sono più di 1 punto BLEU rispetto alle linee di base NMT forti, +4% di precisione su tutti i sostantivi e verbi ambigui, o +20% se segnato manualmente su più parole impegnative.</abstract_it>
      <abstract_lt>Šiame dokumente parodoma, kad žodžių jausmų nedviprasmiškumas (WSD) gali pagerinti nervinį mašinų vertimą (NMT), išplečiant šaltinio kontekstą, į kurį atsižvelgiama modeliuojant potencialiai dviprasmiškus žodžius. Pirmiausia įvedame tris adaptacinius WSD klasterizavimo algoritmus, pagrįstus k priemonėmis, Kinijos restoranų procesais ir atsitiktiniais vaikščiojimais, kurie tuomet taikomi dideliems žodžių kontekstams, atstovaujamiems žemos rangos erdvėje ir vertinami remiantis SemEval dalijamojo uždavinio duomenimis. Tada mokome žodžių vektorius kartu su jausmų vektoriais, apibrėžtais geriausiu WSD metodu, moderniausioje NMT sistemoje. Mes parodome, kad šių vektorių sutrumpinimas ir jutimo atrankos mechanizmo, pagrįsto svertiniu jutimo vektorių vidurkiu, naudojimas viršija keletą bazinių linijų, įskaitant suprantamas jutimas. Tai įrodoma vertus penkiomis kalbomis. Gerėjimai yra daugiau kaip 1 BLEU taškas, palyginti su stipriomis NMT bazinėmis linijomis, +4 % tikslumas, palyginti su visais dviprasmiškais vardais ir žodžiais, arba +20 %, kai rankiniu būdu gaunamas rezultatas dėl kelių sunkių žodžių.</abstract_lt>
      <abstract_mk>Овој документ покажува дека раздвојувањето на зборовите (WSD) може да го подобри преводот на невровните машини (NMT) со проширување на изворот контекст кој се разгледува кога се моделираат сетилата на потенцијално двогумни зборови. Прво воведуваме три адаптивни алгоритми за кластерирање за ВСД, базирани на k-средства, кинески ресторански процеси и случајни прошетки, кои потоа се применуваат на големи зборни контексти претставени во нискоранг простор и евалуирани на податоци за делена задача на SemEval. Потоа научиме зборни вектори заедно со сетилни вектори дефинирани од нашиот најдобар метод ВСД, во рамките на најсовремениот НМТ систем. Ние покажуваме дека концентрацијата на овие вектори, и употребата на механизам за селекција на смисла базиран на тежираниот просек на селекторите на смисла, ги надминува неколку основни линии, вклучувајќи и оние со селекција. Ова е демонстрирано со превод на пет јазички парови. Подобрувањата се повеќе од 1 БЛЕУ поента во однос на силните бази на НМТ, +4 отсто точност во однос на сите двозначни именици и реченици, или +20 отсто кога се поставуваат рачно поради неколку предизвикувачки зборови.</abstract_mk>
      <abstract_ms>Kertas ini menunjukkan bahawa penyelesaian perasaan perkataan (WSD) boleh meningkatkan terjemahan mesin saraf (NMT) dengan memperluas konteks sumber yang dipertimbangkan bila memmodelkan perasaan perkataan yang berpotensi ambigu. We first introduce three adaptive clustering algorithms for WSD, based on k-means, Chinese restaurant processes, and random walks, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data.  We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system.  Kami menunjukkan bahawa persatuan vektor ini, dan penggunaan mekanisme pemilihan sensor berdasarkan rata-rata berat vektor sensor, melebihi beberapa garis dasar termasuk garis-dasar yang sedar-sedar. Ini dipaparkan oleh terjemahan pada lima pasangan bahasa. Perbaikan lebih dari 1 titik BLEU atas garis dasar NMT yang kuat, +4% akurasi atas semua nama dan verb yang ambiguh, atau +20% apabila dicetak secara manual atas beberapa perkataan yang mencabar.</abstract_ms>
      <abstract_ml>This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words.  നമ്മള്‍ ആദ്യം WSD-ന്റെ മൂന്ന് ആദ്യം ക്ലാസ്റ്റര്‍ ആല്‍ഗോരിത്മുകളെ പരിചയപ്പെടുത്തിയിട്ടുണ്ട്. കെ-മാന്ത്രം, ചൈനീസ് റെസ്റ്റോറന്റ് പ്രക്രിയകള്‍ അടിസ്ഥാനത്താണ്, ചൈ പിന്നീട് നമ്മുടെ ഏറ്റവും മികച്ച WSD രീതിയിലൂടെ വാക്ക് വെക്റ്റര്‍ വെക്റ്റര്‍ കൊണ്ട് നമ്മള്‍ പഠിക്കുന്നു. നമ്മുടെ സ് നമ്മള്‍ കാണിച്ചുകൊടുക്കുന്നു ഈ വെക്റ്ററുകളുടെ കൂട്ടത്തില്‍ നിന്നും ബുദ്ധിമുട്ടിയുള്ള തെരഞ്ഞെടുപ്പുകളുടെ ഉപയോഗിക്കുന്നതും ഭ ഇത് അഞ്ചു ഭാഷ ജോടികളില്‍ പരിഭാഷപ്പെടുത്തിയിരിക്കുന്നു. ശക്തിയുള്ള NMT ബേസ്റ്റ് ലൈനുകള്‍ക്കും മുന്നറിയിപ്പ് 1 ബെല്ലൂ പോയിന്‍റിനെക്കാള്‍ കൂടുതല്‍ മുന്നറിയിപ്പുകളാണ്, +4% കൃത്യമാണ് എല്</abstract_ml>
      <abstract_mt>Dan id-dokument juri li d-diżambigwazzjoni tas-sens tal-kelma (WSD) tista’ ttejjeb it-traduzzjoni tal-makkinarju newrali (NMT) billi twessa’ l-kuntest tas-sors ikkunsidrat meta jiġu mmudellati s-sensi ta’ kelmiet potenzjalment ambigwi. L-ewwel jintroduċu tliet algoritmi adattivi ta’ raggruppament għad-WSD, ibbażati fuq mezzi k, proċessi ta’ ristoranti Ċiniżi, u mixi aleatorji, li mbagħad jiġu applikati għal kuntesti kbar ta’ kliem rappreżentati fi spazju ta’ grad baxx u evalwati fuq dejta ta’ SemEval ta’ kompitu kondiviż. Imbagħad nitgħallmu vetturi tal-kliem flimkien ma’ vetturi tas-sens definiti mill-a ħjar metodu tagħna ta’ WSD, fi ħdan sistema NMT l-aktar avvanzata. Aħna nuru li l-konċentrazzjoni ta’ dawn il-vetturi, u l-użu ta’ mekkaniżmu ta’ għa żla tas-sens ibbażat fuq il-medja peżata tal-vetturi tas-sens, jaqbeż diversi linji bażi inklużi dawk li huma konxji tas-sens. Dan jintwera bit-traduzzjoni fuq ħames pari lingwistiċi. It-titjib huwa aktar minn punt BLEU wieħed fuq linji bażi qawwija tal-NMT, +4% preċiżjoni fuq l-ismijiet u l-verbs ambigwi kollha, jew +20% meta mqabbel manwalment fuq diversi kliem ta’ sfida.</abstract_mt>
      <abstract_mn>Энэ цаас нь мэдрэмжгүй байдал (WSD) гэдэг үг нь сэтгэл хөдлөлийн мэдрэмжүүдийн мэдрэмжүүдийг модельчлэхэд мэдрэмжүүдийг нэмэгдүүлж чадна гэдгийг харуулж байна. Эхлээд бид WSD-ийн гурван адаптийн алгоритмыг танилцуулж, k-means, Хятад ресторан процесс, санамсаргүй алхам, дараа нь маш бага хэмжээний орон зайд дүрслэгдсэн том үг орчинд хэрэглэгддэг, SemEval-ын хуваалтын ажлын мэдээлэл дээр үнэлдэг. Тэгээд бид үг векторуудыг бидний хамгийн шилдэг WSD аргаар тодорхойлж байгаа мэдрэмжтэй векторуудыг суралцдаг. Бид эдгээр векторуудын тодорхойлолт болон мэдрэмжтэй сонголтын механизмын хэрэглээ мэдрэмжтэй векторуудын дундаж жинтэй хэмжээний суурь шулуунуудыг мэдрэмжтэй болгон илүү олон суурь шулуунуудыг харуулдаг. Энэ нь таван хэл хоёр дээр орчуулсан. Сайжруулалт нь 1 БЛЕС цэгээс илүү хүчтэй НМТ суурь шугам дээр, 4% нь бүх хэмжээний нэр, үг дээр зөв байдал, эсвэл +20% нь хэдэн хэцүү үг дээр гараар тооцоолж байсан юм.</abstract_mn>
      <abstract_pl>Niniejszy artykuł pokazuje, że dyambiguation sense (WSD) może poprawić neuronowe tłumaczenie maszynowe (NMT) poprzez poszerzenie kontekstu źródłowego uwzględnianego przy modelowaniu zmysłów potencjalnie niejednoznacznych słów. Najpierw wprowadzamy trzy adaptacyjne algorytmy klastrowania dla WSD, oparte na średnich k, chińskich procesach restauracyjnych i losowych spacerach, które są następnie stosowane do dużych kontekstów słowowych reprezentowanych w przestrzeni niskiej rangi i oceniane na podstawie danych współdzielonych zadań SemEval. Następnie uczymy się wektorów słowa wspólnie z wektorami zmysłowymi zdefiniowanymi przez naszą najlepszą metodę WSD, w ramach najnowocześniejszego systemu NMT. Pokazujemy, że łączenie tych wektorów i zastosowanie mechanizmu selekcji zmysłów opartego na średniej ważonej wektorów zmysłów, przewyższa kilka linii bazowych, w tym te świadome zmysłów. Świadczy o tym tłumaczenie na pięciu parach językowych. Ulepszenia to więcej niż jeden punkt BLEU nad silnymi liniami bazowymi NMT, +4% dokładność nad wszystkimi niejednoznacznymi rzeczownikami i czasownikami lub +20% gdy oceniano ręcznie w kilku trudnych słowach.</abstract_pl>
      <abstract_ro>Această lucrare demonstrează că dezambiguizarea sensului cuvântului (WSD) poate îmbunătăți traducerea automată neurală (NMT) prin lărgirea contextului sursă luat în considerare atunci când modelează simțurile cuvintelor potențial ambigue. Introducem mai întâi trei algoritmi de clusterizare adaptivă pentru WSD, bazați pe k-means, procese restaurante chinezești și plimbări aleatorii, care sunt apoi aplicate contextelor mari de cuvinte reprezentate într-un spațiu de rang scăzut și evaluate pe datele de sarcină partajată SemEval. Apoi învățăm vectorii de cuvinte împreună cu vectorii de simț definiți de cea mai bună metodă WSD, în cadrul unui sistem NMT de ultimă generație. Arătăm că concatenarea acestor vectori și utilizarea unui mecanism de selecție a simțurilor bazat pe media ponderată a vectorilor simțului depășesc mai multe linii de bază, inclusiv cele conștiente de simț. Acest lucru este demonstrat prin traducerea pe cinci perechi de limbi. Îmbunătățirile sunt mai mult de 1 punct BLEU față de liniile de bază puternice NMT, +4% precizie față de toate substantivele și verbele ambigue sau +20% atunci când sunt marcate manual peste mai multe cuvinte provocatoare.</abstract_ro>
      <abstract_sr>Ovaj papir pokazuje da disambiguacija reči (WSD) može poboljšati prevod neuralne mašine (NMT) širenjem izvornog konteksta koji se razmatra kada modelira osjećaje potencijalno ambigućih reči. Prvo predstavljamo tri adaptivna algoritma skupljanja za WSD, na temelju k-sredstava, kineskih restoranskih procesa i nasumičnih šetnja, koji se zatim primjenjuju na velike rečne kontekste predstavljene u niskom redu prostoru i procjenjuju podatke o podacima zajedničkih zadataka SemEval. Onda naučimo rečne vektore zajedno sa osećajnim vektorima definisanim našim najboljim metodom WSD, u stanju umjetnog NMT sistema. Pokazujemo da je usklađenost ovih vektora i upotreba mehanizma selekcije osjećaja na temelju težine prosječnog vektora osjećaja iznosi nekoliko osnovnih linija uključujući svesne osjećaje. Ovo se pokazuje prevodom na pet jezičkih parova. Poboljšanja je više od 1 BLEU tačka nad jakim početnim linijama NMT-a, +4% tačnosti nad svim neobičnim imenima i verbima, ili +20% kada je rezultat ručno iznad nekoliko izazovnih reči.</abstract_sr>
      <abstract_ka>ეს დოკუმენტი აჩვენებს, რომ სიტყვის სიტყვის განსხვავება (WSD) შეუძლია უფრო მეტივად ნეიროლური მაქინის განსხვავება (NMT) შეიძლია გაუფეთქოთ, როცა მუშაობის კონტექსტი ჩვენ პირველად დავიყენებთ სამი ადაპტიგური კლასტერინგი ალგორიტემი WSD-ის, k-means, ჩინეთის რესტორანტის პროცესების დაბაზეული, და შემდეგ გამოყენება, რომლებიც შემდეგ გამოყენება დიდი სიტყვის კონტექსტებში, რომლებ შემდეგ ვისწავლით სიტყვის გვექტორები ერთადერთად სიტყვის გვექტორებით, რომელიც ჩვენი უკეთესი WSD მეტიდან განსაზღვრულია, NMT სისტემაში. ჩვენ ჩვენ აჩვენებთ, რომ ამ გვექტორის შემდეგ და სიგრძნობის მონიშნული მექანსიკის გამოყენება სიგრძნობის განსაზღვრებული განსაზღვრებული გვექტორის განსაზღვრებულია, რამდენიმე ფექტი ეს ხუთი ენის ზოგების გადაწყვეტა. უფრო უფრო მეტი BLEU წერტილი არის ძალიან NMT ბაზის წერტილებზე, +4% წერტილი ყველა უცნობიერი სახელი და გერტილებზე, ან +20% როდესაც მანძილურად შეუძლებელი სიტყვებზე.</abstract_ka>
      <abstract_so>Kanu warqaddan wuxuu muujiyaa in qoraalka kala soocsiga maanka ah (WSD) uu beddeli karo tarjumaadka maskinka neurada (NMT) marka loo sameynayo fikrada hadalka suurtagalka ah ee suurtagalka ah. Marka ugu horeysa waxaan WSD u soo bandhignaa saddex algoreem oo isku adag oo ku saabsan koorasyada qashinka Shiinaha iyo socodka kala duduwan, kuwaas oo lagu codsadaa kooxaha hadalka waaweyn oo ku qoran shahaado hoos ah, waxaana lagu qiimeynayaa macluumaadka saabsan ee SemEval. Markaas waxaynu barnaa wadajir ka mid ah wado qalabka waxgarashada ah oo ay noogu qoran yihiin nooca ugu wanaagsan WSD, marka lagu jiro xaalad-ka-art NMT. Waxaynu muujinnaa in la isku xiriiro wadooyinka iyo isticmaalka xulashada waxgarashada ah oo ku saleysan qiimaha ugu miisaamay jidhka waxgarashada, wuxuu soo saaraa saldhigyo badan oo ku saabsan waxgarashada. Tan waxaa lagu muujiyaa turjumaan shan luqadood oo labo ah. Horumarintu waxay ka badan yihiin 1 BLEU oo ka tirsan qoraal xoog leh ee NMT, +4% si rasmi ah ugu qoran dhammaan cuntada iyo warqadaha, ama +20% marka si gacan ah loo qoray erayo badan oo dhibaato leh.</abstract_so>
      <abstract_kk>Бұл қағаз сөздердің сезімін өзгерту (WSD) нейрондық компьютердің аударуын (NMT) үлкейту мүмкін емес сөздердің сезімдерін моделдеу үшін көзгертілген көзі контексті жасауға болады. Біз біріншіден WSD үш адаптикалық кластер алгоритмді келтіреміз, k-means, Кытай ресторантты процесстеріне негізделген, және кездейсоқ жүргізіміз. Содан кейінгі үлкен сөздердің контексттеріне қолданылады, олар төмен жоғары бос орында, SemEva Содан кейін біз сөздерді векторларымыздың ең жақсы WSD әдісімізмен біріктіріп, NMT жүйесінде анықталған векторларымызды үйренеміз. Біз бұл векторлардың біріктіру мен сезімді таңдау механизмінің қолдануын көрсетедік. Сезімдік векторлардың орташа жиілігіне негізделген, бірнеше негізгі сызықтарды бірнеше сезімді түсі Бұл бес тіл екеуіне аудару арқылы көрсетіледі. Бұл жақсартулар NMT негізгі жолдардан 1 BLEU нүктесінен артық, +4% деген дұрыс барлық немесе белгілі атаулар мен верботтардан артық, немесе +20% қолмен бірнеше қиын сөздерді қолдану үшін.</abstract_kk>
      <abstract_no>Denne papiret viser at disambiguasjonen av ordfølelsen (WSD) kan forbetra omsetjing av neuralmaskin (NMT) ved å brei kjeldekonteksten som er betra når du modeller følelsene av potensielt ambiguous ord. Vi introduserer først tre tilpassande klasseringsalgoritme for WSD, basert på k-means, kinesiske restaurantprosesser og tilfeldige gåver, som så vert brukt til store ord-kontekstar representerte i eit lågare plass og evaluert på semiEval delt oppgåvedata. Vi lærer så ordvektorar saman med følelsesvektorar definert med vår beste WSD-metode inne eit NMT-systemet for kunsten. Vi viser at sammenlikningen av desse vektorane og bruken av ein følelsesutval-mekanisme basert på den vekte gjennomsnittet av følelsesvektorane, utfører fleire baselinjer, inkludert følelsesvare. Dette vert demonstrert av omsetjinga på fem språkopar. Forbedringane er meir enn 1 BLEU-punkt over sterke NMT-baselinjer, +4% nøyaktighet over alle avgjengelege namn og verbar, eller +20% når det er oppretta manuelt over fleire vanskelege ord.</abstract_no>
      <abstract_sv>Denna uppsats demonstrerar att ord sense disambiguation (WSD) kan förbättra neural maskinöversättning (NMT) genom att bredda källkontexten som beaktas när man modellerar sinnena av potentiellt tvetydiga ord. Vi introducerar först tre adaptiva klusteringsalgoritmer för WSD, baserade på k-medel, kinesiska restaurangprocesser och slumpmässiga promenader, som sedan tillämpas på stora ordkontexter representerade i ett lågrank utrymme och utvärderas på SemEval delade uppgifter data. Vi lär oss sedan ordvektorer tillsammans med sinnesvektorer definierade av vår bästa WSD-metod, inom ett toppmodernt NMT-system. Vi visar att sammanslagningen av dessa vektorer, och användningen av en sinneselektionsmekanism baserad på det vägda genomsnittet av sinnesvektorer, överträffar flera baslinjer inklusive sinnesmedvetna. Detta framgår av översättning på fem språkpar. Förbättringarna är mer än 1 BLEU-punkt över starka NMT-baslinjer, +4% noggrannhet över alla tvetydiga substantiv och verb, eller +20% när poäng görs manuellt över flera utmanande ord.</abstract_sv>
      <abstract_ur>یہ کاغذ دکھاتا ہے کہ کلمات کا احساس نامبیوجیٹ (WSD) نیورال ماشین کی ترجمہ (NMT) کو زیادہ کر سکتا ہے۔ اس کے ذریعے سورج کنٹنس کو پھیلانے کے لئے سمجھ رکھا گیا ہے جب اس کے مطابق مشکل کلمات کے سنسوں کو نم ہم پہلی بار WSD کے لئے تین اڈپٹیٹ کلسٹر الگوریتم کو معرفی کرتے ہیں، k-means پر، چین رستورانٹ پروسس پر، اور ناقص چلتے ہیں، جو اس کے بعد بڑے کلمات کنٹکسٹوں پر لازم کیا جاتا ہے جو کم رقم جگہ میں معرفی کئے جاتے ہیں اور SemEval shared-task data پر ارزش کیا جاتا ہے. پھر ہم کلمات ویکتروں کو سمجھ ویکتروں کے ساتھ سیکھتے ہیں جو ہمارے بہترین WSD طریقے سے تعریف کیا گیا ہے، ایک ایست NMT سیستم میں۔ ہم دکھاتے ہیں کہ ان ویکتروں کی تعلق اور سمجھ کے انتخاب مکانیسم کا استعمال کرنا سمجھ کے متوسط ویکتروں کے متوسط بوجھ پر ہے، بہت سی بنسس لینوں سے زیادہ اضافہ کرتا ہے جیسے سمجھ کے متوجہ ہیں. یہ پانچ زبان جوڑوں پر ترجمہ سے دکھائی جاتی ہے۔ اس سے زیادہ زیادہ بلیوس پوینٹ NMT بنسلین پر ہے +4% تمام غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر</abstract_ur>
      <abstract_ta>இந்த காகிதத்தை காட்டுகிறது சாத்தியமான வார்த்தையின் உணர்வுகளை மாற்றும்போது புதிய இயந்திர மொழிமாற்றியை மேம்படுத்த முடியும் முதலில் நாம் WSD க்கான மூன்று ஒப்புக்கொள்ளும் குறைந்த இடத்தில் குறைந்த வார்த்தை முயற்சிக்கப்பட்டுள்ளோம் மற்றும் சீனா ரெஸ்டான்ட் செயல்களை அடிப்படையாக க குறைந் நாம் சிறந்த WSD முறைமையால் வரையறுக்கப்பட்ட வார்த்தை வெக்டார்களை ஒன்றாக கற்றுக் கொள்கிறோம், என்எம்டி முறைமையில் உள்ள நாம் இந்த நெறிகளின் ஒன்றிணைப்பு மற்றும் உணர்வு தேர்ந்தெடுப்பு முறைமையை பயன்படுத்துவதை காட்டுகிறோம். சராசரியான உணர்வு நெறிகள் அடிப்பட இது ஐந்து மொழி ஜோடிகளில் மொழிபெயர்ப்பில் காண்பிக்கப்பட்டது. அதிகரிப்பு NMT அடிப்படைக்கோடுகளின் மேல் 1 பிலியு புள்ளியை விட அதிகமாக இருக்கிறது +4% சரியானது அனைத்து விருப்பமான உணவுகள் மற்றும் வார்த்தை</abstract_ta>
      <abstract_si>මේ පත්තර ප්‍රකාශ කරනවා කියලා වචන අවස්ථාවය (WSD) විශ්වාස කරන්න පුළුවන් න්‍යූරාල මැෂින් අවවාදය (NMT) විශ්වාස කරන්න, ප්‍රභ අපි මුලින්ම WSD වෙනුවෙන් සම්පූර්ණ ක්‍ලාස්ටර් අල්ගෝරිතම් තුන්දෙන්න, k-means, චීනි රෙස්ටෝරෑන්ට් ප්‍රක්‍රියාවට, සහ අවසාන විදිහට ඇවිත් කරනවා, ඒ ප ඊට පස්සේ අපි වචන වෙක්ටර්ස් වෙක්ටර්ස් වෙක්ටර්ස් වෙක්ටර්ස් වෙනුවෙන් අනුවෙන් ඉගෙන ගන්නේ අපේ හොඳම WSD විදිය අපි පෙන්වන්නේ මේ වෙක්ටර්ස්ටෝන්ගේ සම්බන්ධයක්, ඒ වගේම තේරුම් වෙක්ටර්ස්ටෝන්ගේ සාමාන්‍ය භාවිතාවක්, අනුවෙන් අනු මේක භාෂාවක් පහක් වලින් අවවාදයෙන් පෙන්වන්න පුළුවන්. ප්‍රවෘත්තිය බ්ලූස් කිරීම් එකෙන් වඩා වඩා බලාපොරොත්තු NMT ප්‍රධාන ප්‍රධාන ප්‍රධානය, +4% සාමාන්‍ය ප්‍රධානය සහ වාර්තාවක් වලින්</abstract_si>
      <abstract_uz>Bu qogʻoz oddiy soʻzni o'zgartirish imkoniyatini koʻrsatish mumkin. Bu so'z ma'lumotni o'zgartirish mumkin. Biz birinchi marta WSD uchun uchta ta ta'sirlik algorithni ko'rib chiqaramiz, Xitoy restauranten jarayonlarida, va tarqatish yo'nalishimiz mumkin. Keyin keyin biz juda katta so'zlar darajada qo'llaniladi va SemEval'ning qiymatiga qaytarilgan vazifalar maʼlumotiga qiymatdir. Keyin biz eng yaxshi WSD usulida aniqlangan so'zlar vektorlarimiz bilan o'rganamiz, NMT tizimi davomida. We show that the concatenation of these vectors, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones.  Bu besh tilning ikki xil tomonida tarjima qiladi. Bu yaxshi o'zgarishlar bir necha qancha murakkab so'zlardan qo'llab qo'llangan so'zlardan foydalanayotganda 1 BLEU notoʻgʻri, +4% foydalanuvchi sonlarning hamma narsalar va verblardan foydalanishi mumkin.</abstract_uz>
      <abstract_vi>Bài báo này chứng minh rằng phân dạng từ nhạy cảm (WSD) có thể cải thiện dịch biến máy thần kinh (NMB) bằng cách mở rộng bối cảnh nguồn được cân nhắc khi thiết lập các giác quan của từ có khả năng mơ hồ. Đầu tiên chúng ta sẽ giới thiệu ba thuật to án phức tạp thích ứng với WSD, dựa trên k-means, China dinner, và ngẫu nhiên bước đi, mà sau đó được áp dụng vào các từ lớn đại diện trong một không gian thấp và đánh giá dựa trên dữ liệu chia sẻ nhiệm vụ của SemEvl. Chúng ta sẽ học các môi trường truyền hình từ cùng với các véc- tơ cảm giác xác định theo cách tốt nhất của chúng ta, trong hệ thống NMT hiện đại. Chúng tôi cho thấy rằng hợp tác của các véc- tơ này, và sử dụng một cơ chế chọn cảm giác dựa trên mức trung bình cân nặng của véc- tơ cảm giác, thực hiện nhiều đường cơ bản, bao gồm cả các đường dẫn nhận thức. Cái này được chứng minh bằng cách dịch bằng năm cặp ngôn ngữ. Sự cải tiến này nhiều hơn cả một tiếng bíp trên nền tảng NMT mạnh, +4 vi. độ chính xác trên tất cả danh từ và động từ mơ hồ, hoặc +20=. khi bị ghi bàn bằng tay trên nhiều từ khó khăn.</abstract_vi>
      <abstract_bg>Настоящата статия демонстрира, че разграничаването на смисъла на думата може да подобри невронния машинен превод (НМТ), като разшири контекста на източника, разглеждан при моделиране на сетивата на потенциално двусмислени думи. Първо въвеждаме три адаптивни алгоритма за клъстериране за WSD, базирани на к-means, китайски ресторантски процеси и случайни разходки, които след това се прилагат към големи текстови контексти, представени в ниско рангово пространство и оценени въз основа на споделени задачи. След това научаваме думични вектори съвместно със сетивни вектори, определени по най-добрия ни метод в рамките на най-съвременната система на НМТ. Показваме, че конкатенацията на тези вектори и използването на механизъм за подбор на сетива, базиран на среднопретеглената стойност на сетивните вектори, превъзхожда няколко базови линии, включително тези, които осъзнават сетивата. Това се доказва чрез превод на пет езикови двойки. Подобренията са повече от 1 точка над силните базови линии на НМТ, +4% точност над всички двусмислени съществителни и глаголи, или +20% при ръчна оценка върху няколко предизвикателни думи.</abstract_bg>
      <abstract_nl>Deze paper toont aan dat woordsense disambiguation (WSD) neuronale machinevertaling (NMT) kan verbeteren door de broncontext te verbreden die wordt overwogen bij het modelleren van de zintuigen van mogelijk dubbelzinnige woorden. We introduceren eerst drie adaptieve clustering algoritmes voor WSD, gebaseerd op k-middelen, Chinese restaurantprocessen en random walks, die vervolgens worden toegepast op grote woordcontexten vertegenwoordigd in een laagrangige ruimte en geëvalueerd op SemEval shared-task data. Vervolgens leren we woordvectoren samen met zintuigvectoren gedefinieerd door onze beste WSD methode, binnen een state-of-the-art NMT systeem. We tonen aan dat de aaneenschakeling van deze vectoren, en het gebruik van een zintuigselectiemechanisme gebaseerd op het gewogen gemiddelde van zintuigvectoren, verschillende basislijnen overtreft, waaronder zintuigbewuste. Dit wordt aangetoond door vertaling op vijf taalparen. De verbeteringen zijn meer dan één BLEU punt boven sterke NMT basislijnen, +4% nauwkeurigheid over alle dubbelzinnige zelfstandige naamwoorden en werkwoorden, of +20% wanneer handmatig gescoord over verschillende uitdagende woorden.</abstract_nl>
      <abstract_hr>Ovaj papir pokazuje da disambiguacija riječi (WSD) može poboljšati prevod neuralnih strojeva (NMT) proširenjem izvornog konteksta koji se razmatra kada modelira osjećaje potencijalno ambigućih riječi. Prvo predstavljamo tri adaptivne skupljanje algoritma za WSD, temeljene na k-sredstvima, kineskim restoranskim procesima i slučajnim šetnjama, koji se zatim primjenjuju na velike riječne kontekste predstavljene u niskom redu prostoru i procjenjuju na podacima podataka o zajedničkim zadatkima SemEval. Onda učimo riječi vektore zajedno s osjećajnim vektorima definiranim našim najboljim metodom WSD-a u stanju umjetnog NMT-a. Pokazujemo da je usklađenost ovih vektora i upotreba mehanizma izbora osjećaja na temelju težine prosječnog prosječnog vektora osjećaja iznosi nekoliko osnovnih linija uključujući svjesne osjećaje. To se pokazuje prevodom na pet jezičkih parova. Poboljšanja je više od 1 BLEU točka nad jakim početnim linijama NMT-a, +4% točnosti nad svim nesmišljivim imenima i glasovima ili +20% kada je rezultat ručno iznad nekoliko izazovnih riječi.</abstract_hr>
      <abstract_id>Kertas ini menunjukkan bahwa penyelesaian perasaan kata (WSD) dapat meningkatkan terjemahan mesin saraf (NMT) dengan memperluas konteks sumber yang dipertimbangkan ketika memmodelkan perasaan kata-kata yang berpotensi ambigu. Kami pertama-tama memperkenalkan tiga algoritma pengumpulan adaptif untuk WSD, berdasarkan k-means, proses restoran Cina, dan berjalan-jalan acak, yang kemudian diterapkan untuk konteks kata besar yang dirampaikan di ruang tingkat rendah dan diterapkan pada data SemEval berbagi tugas. Kemudian kita belajar vektor kata bersama dengan vektor sensor yang didefinisikan oleh metode WSD terbaik kita, dalam sistem NMT yang terbaik. Kami menunjukkan bahwa konatenasi vektor ini, dan penggunaan mekanisme seleksi sensor berdasarkan rata-rata berat vektor sensor, melebihi beberapa garis dasar termasuk garis dasar yang sadar. This is demonstrated by translation on five language pairs.  Perbaikan lebih dari 1 poin BLEU atas garis dasar NMT yang kuat, +4% akurasi atas semua nama dan verb yang ambigus, atau +20% ketika dicetak secara manual atas beberapa kata yang menantang.</abstract_id>
      <abstract_fa>این کاغذ نشان می دهد که تغییر حس کلمه (WSD) می‌تواند تولید ماشین عصبی (NMT) را به وسیع گسترش محیط منبع توجه می‌کند که در مدل‌سازی حس کلمه‌های احتمالا غیر قابل توجه است. اولین بار سه الگوریتم گروهی برای WSD را معرفی می‌کنیم، بر اساس k-means، فرایند رستوران چینی، و راه‌های تصادفی، که بعدش به محیط کلمه‌های بزرگ معرفی می‌شوند، در فضای پایین پایین و بر اطلاعات مشترک کار SemEval ارزیابی می‌شوند. سپس ویکتورهای کلمه را با ویکتورهای حسی که توسط بهترین روش WSD ما تعریف شده، در یک سیستم NMT هنری یاد می‌گیریم. ما نشان می دهیم که هماهنگی این ویکتورها و استفاده از یک مکانیسم انتخاب حس بر اساس متوسط وزن ویکتورهای حس بیشتر از چند خط پایین‌ها از جمله متوجه حس است. این توسط ترجمه به پنج جفت زبان نشان داده می شود. توسعه‌ها بیشتر از ۱ نقطه BLEU بر اساس خط‌های بنیادی NMT قوی هستند +۴ درصد دقیق بر روی همه نام‌ها و کلمات‌های غیر قابل توجه، یا +۲۰ درصد زمانی که با دستی بر روی چند کلمات سخت‌کننده امتیاز می‌دهند.</abstract_fa>
      <abstract_de>Diese Arbeit demonstriert, dass Wortsinn-Disambiguation (WSD) die neuronale maschinelle Übersetzung (NMT) verbessern kann, indem sie den Quellkontext erweitert, der bei der Modellierung der Sinne potenziell mehrdeutiger Wörter berücksichtigt wird. Zunächst stellen wir drei adaptive Clustering-Algorithmen für WSD vor, basierend auf k-Mittelwerten, chinesischen Restaurantprozessen und Zufallswanderungen, die dann auf große Wortkontexte angewendet werden, die in einem niederrangigen Raum dargestellt und auf SemEval Shared-Task-Daten ausgewertet werden. Anschließend lernen wir Wortvektoren gemeinsam mit Sinnesvektoren, die durch unsere beste WSD-Methode definiert werden, in einem hochmodernen NMT-System. Wir zeigen, dass die Verkettung dieser Vektoren und die Verwendung eines Sinnesauswahlmechanismus, der auf dem gewichteten Durchschnitt von Sinnesvektoren basiert, mehrere Baselines übertrifft, einschließlich sinnbewusster. Dies zeigt die Übersetzung an fünf Sprachpaaren. Die Verbesserungen sind mehr als ein BLEU-Punkt über starken NMT-Basislinien, +4% Genauigkeit über alle mehrdeutigen Substantive und Verben oder +20% wenn manuell über mehrere herausfordernde Wörter bewertet wird.</abstract_de>
      <abstract_sw>Makala hii inaonyesha kuwa ubaguzi wa maneno (WSD) unaweza kuboresha tafsiri ya mashine ya ubongo (NMT) kwa kuongeza muktadha wa chanzo kinachochukuliwa wakati wa kuonyesha hisia za maneno yenye uwezekano wa kuvutia. Kwanza tunaanzisha vipengele vitatu vya vifaa vya WSD, kwa kutumia mbinu, michakato ya mgahawa wa China, na maendeleo yasiyo ya kawaida, ambavyo vinatumika kwa mashindano makubwa ya maneno yanayowakilishwa katika nafasi ya chini na kutathmini takwimu za kazi za SemEval. Kisha tunajifunza vectori za maneno kwa pamoja na vectors wa akili zilizoelezwa na njia yetu bora ya WSD, ndani ya mfumo wa sanaa wa NMT. Tunaonyesha kuwa ushirikiano wa vectors hizi, na matumizi ya mfumo wa uchaguzi wa maana kwa kutumia wastani wa wastani wa vectors wa akili, huonyesha misingi kadhaa ikiwa ni pamoja na wale wenye uelewa wa akili. Hii imeonyesha kwa kutafsiri katika viwili mitano vya lugha. Mabadiliko ni zaidi ya 1 BLEU yenye misingi yenye nguvu ya NMT, +4% sahihi juu ya chakula na maneno yote yasiyoeleweka, au asilimia 20 wakati ulipogombea manufaa zaidi ya maneno ya changamoto kadhaa.</abstract_sw>
      <abstract_da>Denne artikel demonstrerer, at ordsans disambiguation (WSD) kan forbedre neural maskinoversættelse (NMT) ved at udvide kildekonteksten, der tages i betragtning, når sanserne af potentielt tvetydige ord modelleres. Vi introducerer først tre adaptive clustering algoritmer til WSD, baseret på k-betyder, kinesiske restaurantprocesser og tilfældige gåture, som derefter anvendes på store ordsammenhænge repræsenteret i et lavt rangrum og evalueret på SemEval delte opgavedata. Vi lærer derefter ordvektorer sammen med sansevektorer defineret ved vores bedste WSD metode, inden for et state-of-the-art NMT system. Vi viser, at sammenkoblingen af disse vektorer, og brugen af en sansevalgningsmekanisme baseret på det vægtede gennemsnit af sansevaktorer, overgår flere basislinjer, herunder sansebevidste dem. Dette fremgår af oversættelse på fem sprogpar. Forbedringerne er mere end 1 BLEU point over stærke NMT basislinjer, +4% nøjagtighed over alle tvetydige navneord og verber, eller +20% når scoret manuelt over flere udfordrende ord.</abstract_da>
      <abstract_af>Hierdie papier wys dat woord sin ontsamminging (WSD) kan verbeter neurale masjien vertaling (NMT) deur die bron konteks wat beskou word wanneer die sense van potensielik onbepaalde woorde te modelleer. Ons introduseer eerste drie adaptief klastering algoritme vir WSD, gebaseer op k-betekens, Sjinese restaurant prosesse en willekeurige wandel, wat dan toepassing word na groot woord konteks wat in 'n lae-rank spasie verteenwoordig is en evalueer op SemEval gedeelde-taak data. Ons leer dan woord vekteurs saam met sin vekteurs gedefinieer deur ons beste WSD metode binne 'n staat-van-die-kuns NMT stelsel. Ons wys dat die samelewing van hierdie vektore en die gebruik van 'n sens keuse mekanisme gebaseer op die geweegte gemiddelde van sens vektore, uitvoer verskeie basisline insluitend sens-bewyse. Hierdie is vertoon deur vertaling op vyf taal paar. Die verbeteringe is meer as 1 BLES punt oor sterke NMT basisline, +4% waarskynlik oor alle ongelukkige noume en verbe, of +20% wanneer handmatig oor verskeie pragtige woorde getel is.</abstract_af>
      <abstract_sq>Ky dokument demonstron se shpjegimi i kuptimit të fjalës (WSD) mund të përmirësojë përkthimin nervor të makinave (NMT) duke zgjeruar kontekstin e burimit të konsideruar kur modelon ndjenjat e fjalëve potencialisht të ambiguara. Ne fillimisht futim tre algoritme adaptuese grupimi për WSD, bazuar në k-mjete, procese restorante kineze dhe ecje të rastësishme, të cilat pastaj aplikohen në kontekste fjalësh të mëdha përfaqësuar në një hapësirë të rendit të ulët dhe vlerësuar në të dhënat SemEval të detyrave të përbashkëta. Pastaj mësojmë vektorët e fjalës së bashku me vektorët e sensit të përcaktuar nga metoda jonë më e mirë WSD, brenda një sistemi NMT më të lartë. Ne tregojmë se bashkëkalimi i këtyre vektorëve, dhe përdorimi i një mekanizmi zgjedhjeje të sensit bazuar në mesataren e peshuar të vektorëve të sensit, tejkalon disa linja bazë duke përfshirë ato të vetëdijshëm për sensin. Kjo demonstrohet nga përkthimi në pesë çifte gjuhësh. Përmirësimet janë më shumë se 1 pikë BLEU mbi linjat bazë të forta NMT, +4% saktësi mbi të gjitha emrat dhe verbët e qarta, apo +20% kur shënohen manualisht mbi disa fjalë sfiduese.</abstract_sq>
      <abstract_am>ይህ ገጽ የቃላት አእምሮ ግጭት (WSD) የነዌብ መሳሪያ ትርጉም (NMT) በመስፋት የኩነቱ ጽሑፍ ማሰናከል የቻልነት ቃላትን ማሳየት ሲችል ያሳያል፡፡ የቻይና restaurant ሥርዓት፣ እና ቀላል መሄድ በመሠረት ላይ ሦስት ተያያማሪ የጦማር አሌጎርቲዎችን እና በኋላም በዝቅተኛ ደረጃዎች ውስጥ የሚቆጠሩ ትልቅ ቃላት ተቃውሞ እና በሴምEval የተካፈለው የስራ ዳታዎችን ተካክሎታል፡፡ ከዚህም በኋላ በአውቀት የ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ.አ እናሳያቸዋለን እነዚህን vector ማሰናከል እና የዓይነት ምርጫ ማሰናከል በተመዘነ ብዛት የዓይነት ነጥቦች በመጠቀም እናሳየዋለን እናውቃለን፡፡ This is demonstrated by translation on five language pairs.  ጠንካራ የNMT መቀመጫዎች፣ 4% ፍጹም በማይታወቅ እና በንግግር ሁሉ ላይ፣ ወይም + 20 በመቶው በብዙ አዋቂዎች ቃላት ላይ በተቀራረበ ጊዜ የሚበዛው ብሊዩን ነጥብ ነው፡፡</abstract_am>
      <abstract_ko>본고는 의미 변조(WSD)가 잠재적 변조어의 의미를 모델링할 때 고려하는 소스 컨텍스트를 넓혀 신경기계번역(NMT)을 개선할 수 있음을 입증했다.우리는 먼저 k-means, 중국 식당 프로세스와 무작위 유동을 바탕으로 하는 WSD 자체 적응 분류 알고리즘 세 가지를 소개한 다음에 이를 저질 공간에서 표시된 대형 단어의 상하문에 응용하고SemEval 공유 임무 데이터에 대해 평가했다.그리고 우리는 가장 선진적인 NMT 시스템에서 단어 벡터와 최상의 WSD 방법이 정의한 의미 벡터를 결합시켜 배운다.우리는 이러한 벡터의 직렬연결과 벡터의 가중평균을 바탕으로 하는 감지선택 메커니즘의 사용이 감지벡터를 포함한 몇 개의 기선보다 우수하다는 것을 나타낸다.이것은 다섯 가지 언어의 옳은 번역을 통해 증명할 수 있다.강력한 NMT 기선에서 BLEU 포인트 1개 이상 올려 모든 이의명사와 동사에 대해 +4%의 정확도를 높이거나 몇몇 도전적인 단어에 수동으로 점수를 매길 때 +20%를 높였다.</abstract_ko>
      <abstract_bn>This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words.  কি-মানে, চীনা রেস্টুরেন্ট প্রক্রিয়ার ভিত্তিতে, এবং অন্যায়ভাবে হাঁটতে থাকার ভিত্তিতে আমরা উইএসডির জন্য তিনটি প্রযুক্তিশীল ক্লাস্টারিং অ্যালগরিদম পরিচিতি প্রথমে উপ তারপর আমরা শব্দ ভেক্টর একত্রে শিখতে পারি আমাদের সেরা ডিউএসডি পদ্ধতি দ্বারা সুন্দর ভেক্টরের সাথে যুক্ত, একটি রাষ্ট্র-অফ-শ আমরা দেখাচ্ছি যে এই ভেক্টরের একত্রিত এবং মানসিক নির্বাচনের মাধ্যমে ভিত্তিক গড়ে ভেক্টরের ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিতে বেশ কিছ এটা পাঁচ ভাষার জোড়ায় অনুবাদ দিয়ে প্রদর্শন করা হয়েছে। The improvements are more than 1 BLEU point over strong NMT baselines, +4% accuracy over all ambiguous nouns and verbs, or +20% when scored manually over several challenging words.</abstract_bn>
      <abstract_bs>Ovaj papir pokazuje da disambiguacija riječi (WSD) može poboljšati prevod neuralne mašine (NMT) širenjem izvornog konteksta koji se razmatra kada modelira osjećaje potencijalno ambigućih riječi. Prvo predstavljamo tri adaptivne skupljanje algoritma za WSD, temeljene na k-sredstvima, kineskim restoranskim procesima i nasumičnim šetnjama, koji se zatim primjenjuju na velike riječije kontekste predstavljene u niskom nivou prostora i procjenjuju na podacima podataka semiEval zajedničkog zadatka. Onda učimo vektore riječi zajedno sa vektorima osjećaja koji su definisani našim najboljim metodom WSD-a u stanju umjetnog NMT-a. Pokazujemo da je usklađenost ovih vektora i upotreba mehanizma selekcije osjećaja na temelju težine prosječnog vektora osjećaja iznosi nekoliko osnovnih linija uključujući svesne osjećaje. To se pokazuje prevodom na pet jezičkih parova. Poboljšanja je više od 1 BLEU točka nad jakim početnim linijama NMT-a, +4% tačnosti nad svim neobičnim imenima i glasovima, ili +20% kada je rezultat ručno iznad nekoliko izazovnih riječi.</abstract_bs>
      <abstract_tr>Bu kagyz senedi흫 g철rkezili힊igini (WSD) neural ma힊yny흫 terjimesini (NMT) 철r채n m철h체m s철zlerin du첵gulandyryp d체힊체n체l첵채n 챌e힊me kontekstini azalt첵ar. Ilkinji gezek biz WSD 체챌in 체챌 adaptiv clustering algoritmalaryny tany힊dyr첵arys, k-me첵dan챌asyna da첵an첵ar, 횉in 챌e restoran prosesleri we kasysal 첵철retm채ge da첵an첵ar, so흫ra da첵ak derejede alan uly s철z contextlara uygulandyryl첵arys we SemEval payla힊yk-t채zim maglumatlaryna de흫le첵채ris Sonra mant캇kl캇 vekt철rler, bizim en iyi WSD y철ntemimizle tan캇mlanm캇힊 mant캇kl캇 vekt철rler ile birlikte kelime 철휓reniyoruz. - Bu vekt철rlerin birle힊mesini ve duygu se챌me mekanizmas캇n캇, mant캇kl캇 vekt철rlerin ortalamas캇n캇 temel eden, bir챌ok temel 챌izgilerin fark캇nda mant캇kl캇 olanlardan daha y체ksek oldu휓unu g철steriyoruz. Bu be힊 dil 챌iftliklerinde terjime edendir. Geli힊dirmeler 1 BLEU k철p sany NMT k철p esaslarny흫 체st체nde degi힊lidir, +4% hemme m철h체m s철zler we verbleri흫 체st체nde degi힊lidir, 첵ada +20% birn채챌e 챌철z체mli s철zler 체st체nde degi힊lidir.</abstract_tr>
      <abstract_ca>Aquest article demostra que la desambiguació del sentit de la paraula (WSD) pot millorar la traducció neural de la màquina (NMT) ampliant el context de fonts considerat quan modelem els sentits de paraules potencialment ambigues. Primer introduïm tres algoritmes adaptatius d'agrupament per SDD, basats en k-mitjans, processos de restaurants xinesos i passes aleatoris, que després s'aplican a contextes de paraules grans representats en un espai de baix rangs i valorats a partir de dades de SemEval de tasca compartida. Després aprenem vectors de paraules juntament amb vectors de sentit definits pel nostre millor mètode d'ESD, dins un sistema NMT d'última generació. Mostrem que la concatenació d'aquests vectors, i l'ús d'un mecanisme de selecció sensorial basat en la mitjana ponderada dels vectors sensorials, supera diverses línies de base, incloent les que tenen consciència del sentit. Això es demostra amb la traducció en cinc parells de llengües. Les millores són més d'un punt BLEU sobre línies de base fortes de la NMT, +4% de precisió sobre tots els noms i verbs ambiguosos, o +20% quan es puntueix manualment sobre diverses paraules desafiantes.</abstract_ca>
      <abstract_cs>Tento článek ukazuje, že rozšířením zdrojového kontextu při modelování smyslů potenciálně nejednoznačných slov může zlepšit neuronový strojový překlad (NMT). Nejprve představujeme tři adaptivní clusterové algoritmy pro WSD založené na k-meanech, čínských restauračních procesech a náhodných procházkách, které jsou pak aplikovány na velké slovní kontexty reprezentované v nízké hodnotě prostoru a vyhodnocovány na základě dat sdílených úkolů SemEval. Následně se naučíme slovní vektory společně se smyslovými vektory definovanými naší nejlepší WSD metodou v rámci nejmodernějšího NMT systému. Ukazujeme, že řetězení těchto vektorů a použití mechanismu výběru smyslů založeného na váženém průměru smyslových vektorů předčí několik základních linek včetně smyslových. To je demonstrováno překladem na pěti jazykových párech. Vylepšení jsou více než jeden BLEU bod nad silnými NMT základními liniemi, +4% přesnost nad všemi nejednoznačnými podstatnými jmény a slovesami, nebo +20% při ručním zaznamenání několika náročných slov.</abstract_cs>
      <abstract_hy>Այս աշխատանքը ցույց է տալիս, որ բառի զգացմունքի բացատրությունը կարող է բարելավել նյարդային մեքենայի թարգմանությունը՝ ընդլայնելով աղբյուրի կոնտեքստը, որը դիտարկում է պոտենցիալ երկիմաստ բառերի զգացմունքները: Սկզբում մենք ներկայացնում ենք երեք ադապտիվ խմբավորող ալգորիթմներ, որոնք հիմնված են k-միջոցների, չինական ռեստորանների գործընթացների և պատահական քայլերի վրա, որոնք հետո կիրառվում են մեծ բառերի կոնտեքստների վրա, որոնք ներկայացված են ցածր աստիճանի տարածքում և որոնք գնահատվում We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system.  Մենք ցույց ենք տալիս, որ այս վեկտորների համեմատությունը և զգայական ընտրության մեխանիզմի օգտագործումը, հիմնված զգայական վեկտորների կենտրոնային միջինի վրա, գերազանցում է մի քանի հիմնական գծեր, ներառյալ զգայական մեխանիզմները: Սա ցույց է տալիս հինգ լեզվի զույգերի թարգմանման միջոցով: The improvements are more than 1 BLEU point over strong NMT baselines, +4% accuracy over all ambiguous nouns and verbs, or +20% when scored manually over several challenging words.</abstract_hy>
      <abstract_fi>Tämä artikkeli osoittaa, että sanaaistin erottelu (WSD) voi parantaa neurokonekäännöstä (NMT) laajentamalla lähdekontekstia, jota harkitaan mahdollisesti moniselitteisten sanojen aistien mallintamisessa. Ensin esittelemme kolme adaptiivista klusterointialgoritmia WSD:lle, jotka perustuvat k-means-, kiinalaisiin ravintolaprosesseihin ja satunnaisiin kävelyihin, joita sitten sovelletaan suuriin sanakonteksteihin, jotka on esitetty matalassa arvossa ja joita arvioidaan SemEvalin jaettujen tehtävien tietojen perusteella. Tämän jälkeen opimme sanavektorit yhdessä parhaan WSD-menetelmämme määrittelemien aistivektorien kanssa huipputekniikan NMT-järjestelmässä. Osoitamme, että näiden vektorien yhdistäminen ja aistivektorien painotettuun keskiarvoon perustuvan aistivalintamekanismin käyttö ylittää useita perusviivoja, myös aistitietoisia. Tämä osoitetaan kääntämällä viisi kieliparia. Parannukset ovat yli 1 BLEU-piste vahvojen NMT-perusviivojen yläpuolella, +4% tarkkuus kaikissa epäselvissä substantiiveissä ja verbeissä tai +20% manuaalisesti pisteytettynä useilla haastavilla sanoilla.</abstract_fi>
      <abstract_et>Käesolev töö näitab, et sõnatunde eristamine (WSD) võib parandada neuraalset masintõlket (NMT), laiendades lähtekonteksti, mida kaalutakse potentsiaalselt ebaselgete sõnade meelte modelleerimisel. Esiteks tutvustame WSD jaoks kolme adaptiivset klastritamisalgoritmi, mis põhinevad k-means, Hiina restoraniprotsessidel ja juhuslikel kõndimistel, mida seejärel rakendatakse suurtele sõnakontekstidele, mida esindatakse madala astme ruumis ja hinnatakse SemEvali jagatud ülesannete andmetel. Seejärel õpime sõnavaktorid koos meie parima WSD meetodiga määratletud tähtevektoritega kaasaegse NMT süsteemi raames. Näitame, et nende vektorite kokateneerimine ja meelevaliku mehhanismi kasutamine, mis põhineb meelevalike vektorite kaalutud keskmisel, ületab mitmeid baasjooni, sealhulgas meelteteadlikke. Seda tõendab tõlkimine viiele keelepaarile. Parandused on rohkem kui 1 BLEU punkt tugevate NMT baasjoonede suhtes, +4% täpsus kõigi ebaselgete nimisõnade ja tegusõnade suhtes või +20% käsitsi hinnatud mitme keerulise sõna kohta.</abstract_et>
      <abstract_az>Bu kağıt sözlərin məlumatlarının imkansız sözlərin duygularını modelləşdirən mənbə məlumatlarını genişləndirən nöral maşın çevirisini (NMT) yaxşılaşdıra biləcəyini göstərir. Biz ilk dəfə WSD üçün üç adaptiv clustering algoritmi təşkil edirik, k-means, Çin restoran proseslərinə dayandırılır, sonra böyük söz müxtəliflərinə uyğunlaşdırılır və SemEval paylaşılan işlər məlumatlarına değerlənərlər. Sonra sözlərin vektörlərini bizim ən yaxşı WSD metodumuz ilə tanınmış hiss vektörləri ilə birlikdə öyrənirik, NMT sistemində. Biz bu vektörlərin birləşdirilməsini və hiss seçmə mehanizmisinin istifadəsini hiss vektörlərin ortalaması ilə dəyişdirilməsini göstəririk, hiss sahibləri ilə çoxlu dəyişdirilməsini daha yaxşı göstərir. Bu beş dil çiftlərinin çeviri ilə göstərilir. İyileşmələr NMT səhifələrindən çox qüvvətli bir BLEU noktasından daha çox, +4% dəyişiklik bütün nömrələr və sözlər barəsində və ya +20% bir neçə çətin sözlərdən üstün tutduqda.</abstract_az>
      <abstract_jv>Awak-Awak iki diputara menehi nggambar mungkin nguasar seneng apakno (WSD) iso nglanggar tarjamahan apakno (NMT Awak dhéwé nambah tanggal telu kelas-clustering Algorithmu kanggo WSD, basan karo k-means, restoran Cino lan mulai-kiper vectors We show that the concatenation of this vectors, and the use of a Sensitive method, that is basate on the scale of the measurement reference point of the vectors, is extremely likely to go throughly astray, go throughly astray, go throughly astray. Nyong ngomongke tarjamahan ning limu dilangan. Labah bantayan langkung sampeyan kanggo 1 B luwih dumadhi sing titig liyane NMT sing luwih, + %4% kesempatan kanggo kalah bantayan pangan lan verb, uto + %2sing ditawak dhéwé manut kanggo kelas sing ditawak dhéwé.</abstract_jv>
      <abstract_ha>Wannan takardan na nuna cewa bambancin magana na manti (WSD) za ta fi ƙara fassarar masu ƙaranci na kanuni na neural (NMT) da za'a faɗaɗa muhalli da aka yi tunãni a lokacin da za'a motsar santsin masu iya ƙaranci ga maganar kwamfyuta. Kayyar da algoritori uku masu adapti na WSD, a kan ƙananan ko-ma'anar-aiki na China, da kuma masu tafiyar da sauri da sauri, wanda ake amfani da matsayin girma wanda ke cikin wani fili na wuri-daraja kuma an ƙaddara data da aka raba shi na Semeval. Sa'an nan kuma munã fahimta masu shiryoyi da ke haɗa da shiryoyi masu fahimta da hanyarmu na fi kyaun WSD, a cikin wata halin-na-art na NMT. Tuna nuna cewa, samun haɗilacin waɗannan masu shiryuwa, da amfani da ma'anar zaɓani, a kan karatun masu nau'i na nau'i, yana samun masu sani. @ action: button Suna keɓance ko da 1 BLEU pointi kan basasalin NMT mai ƙarfi, +4% na daidaita kan duk abinci da za'a saurara, ko kuma+20% idan an yi ƙari da hannunsa kan wasu kalmõmi masu kanana.</abstract_ha>
      <abstract_he>העבודה הזו מראה שהניתוח לחוש המילים (WSD) יכול לשפר את התרגום של מכונות עצביות (NMT) על ידי הרחבה של הקשר המקורי שנחשב כשדוגמנים את חושים של מילים פוטנציאליות שאותן שאומרות. We first introduce three adaptive clustering algorithms for WSD, based on k-means, Chinese restaurant processes, and random walks, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data.  ואז אנחנו לומדים ווקטורים מילים ביחד עם ווקטורים תחושה מוגדרים על ידי שיטת WSD הטובה ביותר שלנו, בתוך מערכת NMT מצוינת. אנחנו מראים שהשימוש של הוקטורים האלה, והשימוש במנגנון בחירה תחושה מבוסס על הממוצע המשקל של הוקטורים תחושה, עולה על מספר קווים בסיסיים כולל קווים מודעים לחוש. זה מוצג על ידי תרגום על חמש זוגות שפות. השיפורים הם יותר מ-1 נקודה BLEU מעל קווי בסיס NMT חזקים, +4% מדויקת על כל השמות ואיבות סביבות, או +20% כאשר נקודה ידנית על מספר מילים מאתגרות.</abstract_he>
      <abstract_sk>Ta prispevek dokazuje, da lahko razločitev besednega pomena (WSD) izboljša nevronsko strojno prevajanje (NMT), saj razširi izvorni kontekst, ki ga upošteva pri modeliranju čutov potencialno dvoumnih besed. Najprej smo predstavili tri prilagodljive algoritme grozdenja za WSD, ki temeljijo na k-means, kitajskih restavracijskih procesih in naključnih sprehodih, ki se nato uporabljajo v velikih besednih kontekstih, predstavljenih v nizkem prostoru in ocenjujejo na podlagi podatkov SemEval deljenih opravil. Nato se učimo besedne vektorje skupaj s čutnimi vektorji, določenimi z našo najboljšo metodo WSD, znotraj najsodobnejšega sistema NMT. Pokazali smo, da konatenacija teh vektorjev in uporaba mehanizma za izbiro čutov, ki temelji na tehtanem povprečju čutov vektorjev, presega več osnovnih črt, vključno s čutom, ki se zavedajo. To je dokazano s prevodom na petih jezikovnih parov. Izboljšave so več kot 1 točka BLEU nad močnimi osnovnimi črtami NMT, +4% natančnost nad vsemi dvoumnimi samostalniki in glagoli ali +20% pri ročnem ocenjevanju več zahtevnih besed.</abstract_sk>
      <abstract_bo>This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words. ངེད་གཉིས་ཀྱིས་དང་པོ་ནས་བཟོ་བཅོས་མཁན་གྱི་སྒྲིག་སྟངས་གསུམ་གྱི་སྤྱི་ཚོགས་ཀྱི་WSD ལ་བཤད་བྱས། k-means,རྒྱ་ནག་གནས་སྟངས་གནས་སྟངས་དང་མཉམ་རྗེས་ཐོག Then we learn word vectors jointly with sense vectors defined by our best WSD method, in a state-of-the-art NMT system. We show that the concatenation of these vectors, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones. Examples of this variable are also called "variables". འདི་སྐད་རིགས་གཉིས་ཀྱི་ཕུང་དང་བསྟུན་ནས་དབྱེ་བ་དང་བསྟུན་ནས་བཀྲམ་སྟོན་ཡོད། ཡར་རྒྱས་ཀྱི་ཚོགས་སྐྱོད་དང་བྱ་ཚིག་དག་ཚང་བའི་NMT གཞི་གཞི་ཚིག་དང་མཐུན་གྲངས་ཀ་གཅིག་ལས་མཐུན་གྲངས་ཀ་གསལ་བཤད་པ་ཡིན།</abstract_bo>
      </paper>
    <paper id="46">
      <title>Surface Statistics of an Unknown Language Indicate How to Parse It</title>
      <author><first>Dingquan</first><last>Wang</last></author>
      <author><first>Jason</first><last>Eisner</last></author>
      <doi>10.1162/tacl_a_00248</doi>
      <abstract>We introduce a novel <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for delexicalized dependency parsing in a <a href="https://en.wikipedia.org/wiki/Programming_language">new language</a>. We show that useful features of the target language can be extracted automatically from an unparsed corpus, which consists only of gold part-of-speech (POS) sequences. Providing these <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> to our neural parser enables <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> to parse sequences like those in the corpus. Strikingly, our <a href="https://en.wikipedia.org/wiki/System">system</a> has no supervision in the target language. Rather, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is a multilingual system that is trained end-to-end on a variety of other languages, so <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> learns a <a href="https://en.wikipedia.org/wiki/Feature_extraction">feature extractor</a> that works well. We show experimentally across multiple languages : (1) Features computed from the unparsed corpus improve parsing accuracy. (2) Including thousands of <a href="https://en.wikipedia.org/wiki/Synthetic_language">synthetic languages</a> in the training yields further improvement. (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work’s interpretable typological features that require parsed corpora or expert categorization of the language. Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past grammar induction work that does not use training languages (Naseem et al., 2010).</abstract>
      <pages>667–685</pages>
      <url hash="3143cc42">Q18-1046</url>
      <bibkey>wang-eisner-2018-surface</bibkey>
    <title_ar>تشير الإحصائيات السطحية للغة غير معروفة إلى كيفية تحليلها</title_ar>
      <title_es>Las estadísticas de superficie de un idioma desconocido indican cómo analizarlo</title_es>
      <title_fr>Les statistiques de surface d'une langue inconnue indiquent comment l'analyser</title_fr>
      <title_pt>Estatísticas de superfície de um idioma desconhecido indicam como analisá-lo</title_pt>
      <title_ja>未知の言語の表面統計は、それを解析する方法を示します</title_ja>
      <title_zh>未知语言外计信息指示如何解析之</title_zh>
      <title_hi>एक अज्ञात भाषा के सतही आँकड़े इंगित करते हैं कि इसे कैसे पार्स किया जाए</title_hi>
      <title_ru>Статистика поверхности неизвестного языка указывает, как ее анализировать</title_ru>
      <title_ga>Léiríonn Staitisticí Dromchla de Theanga Anaithnid Conas É a Pharsáil</title_ga>
      <title_ka>უცნობიერი ენის სახელი სტატისტიკა ინდექტირება თუ როგორ გადაწერა</title_ka>
      <title_it>Le statistiche di superficie di una lingua sconosciuta indicano come analizzarla</title_it>
      <title_el>Οι στατιστικές επιφάνειας μιας άγνωστης γλώσσας υποδεικνύουν πώς να την αναλύσετε</title_el>
      <title_hu>Ismeretlen nyelv felületi statisztikái mutatják, hogyan kell értelmezni</title_hu>
      <title_kk>Беймәлім тілдің үстінің статистикасы оны қалай талдау дегенді көрсетеді</title_kk>
      <title_lt>Nežinomos kalbos paviršiaus statistika rodo, kaip ją analizuoti</title_lt>
      <title_mk>Статистика на површината на непознатиот јазик покажува како да се анализира</title_mk>
      <title_ms>Statistik permukaan bahasa tidak diketahui Menunjukkan bagaimana menghurainya</title_ms>
      <title_mt>Surface Statistics of an Unknown Language Indicate How to Parse It</title_mt>
      <title_no>Overflatestatistikar for ein ukjend språk indikerer korleis det skal tolka</title_no>
      <title_mn>Тодорхойгүй хэлний гадаргуу статистикийн статистик үүнийг хэрхэн ажиллах вэ гэдгийг харуулдаг</title_mn>
      <title_ml>Surface Statistics of an Unknown Language Indicate How to Parse It</title_ml>
      <title_pl>Statystyki powierzchni nieznanego języka wskazują, jak go parsować</title_pl>
      <title_ro>Statisticile de suprafață ale unei limbi necunoscute indică cum se interpretează</title_ro>
      <title_sr>Statistika površine nepoznatog jezika pokazuje kako je analizirati</title_sr>
      <title_si>නොදන්න භාෂාවක් ගැන පිරිමූණ ස්ථානයක් කොහොමද ඒක විශ්ලේෂනය කරන්න පෙනුම</title_si>
      <title_so>Surface Statistics of an Unknown Language Indicate How to Parse It</title_so>
      <title_sv>Ytstatistik för ett okänt språk visar hur man tolkar det</title_sv>
      <title_ur>ایک ناشناختہ زبان کی سطح انٹیسٹیسی کس طرح مطالعہ کرنا مشخص کرتی ہے</title_ur>
      <title_ta>தெரியாத மொழி புள்ளிவிவரம்</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Thống kê mặt đất của một ngôn ngữ lạ Chỉ ra cách phân tích nó</title_vi>
      <title_bg>Повърхностната статистика на непознат език показва как да го анализираме</title_bg>
      <title_hr>Statistika površine nepoznatog jezika ukazuje kako je analizirati</title_hr>
      <title_nl>Surface Statistics van een onbekende taal geven aan hoe deze te analyseren</title_nl>
      <title_da>Overfladestatistik for et ukendt sprog indikerer, hvordan man fortolker det</title_da>
      <title_ko>알 수 없는 언어의 표면 통계 데이터는 그것을 어떻게 해석하는지 나타낸다</title_ko>
      <title_de>Oberflächenstatistiken einer unbekannten Sprache zeigen an, wie man sie analysiert</title_de>
      <title_id>Statistik Surface dari Bahasa Tak Diketahui Menindikasikan bagaimana menghurainya</title_id>
      <title_fa>آمار سطح یک زبان ناشناخته نشان دهد چگونه آن را تحلیل کند</title_fa>
      <title_sw>Takwimu za uso wa lugha isiyojulikana inawezekana</title_sw>
      <title_tr>Natanyş Diliň surat Statistikleri Nähili Taýýarlamasyny Görkez</title_tr>
      <title_am>የቋንቋ ቋንቋ ማሳየት የፊደል ቁጥጥር እንዴት ማሳየት</title_am>
      <title_af>Grootgesig Statistieke van 'n Onbekende Taal Indiek Hoe om dit te verwerk</title_af>
      <title_hy>Surface Statistics of an Unknown Language Indicate How to Parse It</title_hy>
      <title_az>Bilinməz Dilin Surat Statistikləri Nə Taşınacağını göstərər</title_az>
      <title_bs>Statistika površine nepoznatog jezika pokazuje kako je analizirati</title_bs>
      <title_sq>Surface Statistics of an Unknown Language Indicate How to Parse It</title_sq>
      <title_et>Tundmatu keele pinnastatistika näitab, kuidas seda parsitada</title_et>
      <title_ca>Surface Statistics of an Unknown Language Indicate How to Parse It</title_ca>
      <title_bn>অজানা ভাষার পরিসংখ্যানের পরিসংখ্যা কিভাবে পার্স করা হবে</title_bn>
      <title_cs>Povrchové statistiky neznámého jazyka ukazují, jak jej analyzovat</title_cs>
      <title_fi>Tuntemattoman kielen pinta-tilastot osoittavat, miten se tulkitaan</title_fi>
      <title_sk>Površinska statistika neznanega jezika kaže, kako ga razčleniti</title_sk>
      <title_bo>མི་ཤེས་པའི་སྐད་རིགས་ཀྱི་གདོང་རིས་ཚད་རྩིས་བརྟན་ན། ཇི་ལྟར་ཞིབ་བཤེར་བྱེད་ན་</title_bo>
      <title_he>סטטיסטיקות השטח של שפה לא ידועה מצביעות איך לפרסם אותה</title_he>
      <title_jv>structural navigation</title_jv>
      <title_ha>Statistical na fuskar face of an unknown language</title_ha>
      <abstract_ar>نقدم إطارًا جديدًا لتحليل التبعية غير المعتمد في لغة جديدة. نوضح أنه يمكن استخراج الميزات المفيدة للغة الهدف تلقائيًا من مجموعة غير مُحللة ، والتي تتكون فقط من تسلسلات جزء من الكلام الذهبي (POS). إن توفير هذه الميزات لمحللنا العصبي يمكّنه من تحليل تسلسلات مثل تلك الموجودة في الجسم. اللافت للنظر أن نظامنا لا يخضع للإشراف في اللغة الهدف. بدلاً من ذلك ، فهو نظام متعدد اللغات يتم تدريبه من البداية إلى النهاية على مجموعة متنوعة من اللغات الأخرى ، لذلك فهو يتعلم أداة استخراج الميزات التي تعمل بشكل جيد. نعرض بشكل تجريبي عبر لغات متعددة: (1) تعمل الميزات المحسوبة من المجموعة غير المحللة على تحسين دقة التحليل. (2) يؤدي تضمين آلاف اللغات الاصطناعية في التدريب إلى مزيد من التحسين. (3) على الرغم من كونها محسوبة من مجموعات غير مُحللة ، إلا أن ميزاتنا الخاصة بالمهام المكتسبة تتفوق على السمات التصنيفية للعمل السابق التي يمكن تفسيرها والتي تتطلب مجموعات مُحللة أو تصنيف خبير للغة. أدت أفضل طريقة لدينا إلى تحسين درجات المرفقات على لغات الاختبار التي لم يتم تجاوزها بمتوسط 5.6 نقطة مئوية عن العمل السابق الذي لا يفحص البيانات غير المحللة (McDonald et al. ، 2011) ، وبنسبة 20.7 نقطة على عمل "الاستقراء النحوي" السابق الذي لا يستخدم لغات التدريب (نسيم وآخرون ، 2010).</abstract_ar>
      <abstract_pt>Apresentamos uma nova estrutura para análise de dependência deslexicalizada em uma nova linguagem. Mostramos que características úteis da língua-alvo podem ser extraídas automaticamente de um corpus não analisado, que consiste apenas em sequências de parte de fala (POS) de ouro. Fornecer esses recursos ao nosso analisador neural permite analisar sequências como as do corpus. Surpreendentemente, nosso sistema não tem supervisão no idioma de destino. Em vez disso, é um sistema multilíngue treinado de ponta a ponta em uma variedade de outros idiomas, de modo que aprende um extrator de recursos que funciona bem. Mostramos experimentalmente em vários idiomas: (1) Os recursos calculados a partir do corpus não analisado melhoram a precisão da análise. (2) Incluir milhares de idiomas sintéticos no treinamento traz melhorias adicionais. (3) Apesar de serem calculados a partir de corpora não analisados, nossos recursos específicos de tarefas aprendidas superam os recursos tipológicos interpretáveis de trabalhos anteriores que exigem corpora analisados ou categorização especializada da linguagem. Nosso melhor método melhorou as pontuações de anexos em linguagens de teste em uma média de 5,6 pontos percentuais em relação ao trabalho anterior que não inspeciona os dados não analisados (McDonald et al., 2011) e em 20,7 pontos em relação ao trabalho anterior de “indução gramatical” que não usa linguagens de treinamento (Naseem et al., 2010).</abstract_pt>
      <abstract_es>Presentamos un marco novedoso para el análisis de dependencias delicadas en un nuevo lenguaje. Demostramos que las características útiles del idioma de destino se pueden extraer automáticamente de un corpus no analizado, que consiste solo en secuencias de oro de la parte del discurso (POS). Proporcionar estas características a nuestro analizador neuronal le permite analizar secuencias como las del cuerpo. Sorprendentemente, nuestro sistema no tiene supervisión en el idioma de destino. Más bien, es un sistema multilingüe que está entrenado de extremo a extremo en una variedad de otros idiomas, por lo que aprende un extractor de funciones que funciona bien. Mostramos experimentalmente en varios idiomas: (1) Las características calculadas a partir del corpus sin analizar mejoran la precisión del análisis. (2) La inclusión de miles de lenguajes sintéticos en el entrenamiento produce una mejora adicional. (3) A pesar de que se calculan a partir de cuerpos no analizados, nuestras características específicas de tareas aprendidas superan a las anteriores características tipológicas interpretables de la obra que requieren la categorización del lenguaje por parte de expertos o corpus analizados. Nuestro mejor método mejoró los puntajes de apego en los idiomas de prueba mantenidos en un promedio de 5,6 puntos porcentuales con respecto a trabajos anteriores que no inspeccionan los datos no analizados (McDonald et al., 2011), y en 20,7 puntos por encima de trabajos anteriores de «inducción gramatical» que no utilizan idiomas de entrenamiento (Naseem et al., 2010).</abstract_es>
      <abstract_fr>Nous introduisons un nouveau cadre pour l'analyse délexicalisée des dépendances dans un nouveau langage. Nous montrons que les fonctionnalités utiles de la langue cible peuvent être extraites automatiquement à partir d'un corpus non analysé, constitué uniquement de séquences de parties de discours (POS) dorées. Fournir ces fonctionnalités à notre analyseur neuronal lui permet d'analyser des séquences comme celles du corpus. Il est frappant de constater que notre système n'a aucune supervision dans la langue cible. Il s'agit plutôt d'un système multilingue qui est formé de bout en bout sur une variété d'autres langues, de sorte qu'il apprend un extracteur de fonctionnalités qui fonctionne bien. Nous montrons expérimentalement dans plusieurs langues : (1) Les fonctionnalités calculées à partir du corpus non analysé améliorent la précision de l'analyse. (2) L'inclusion de milliers de langages synthétiques dans la formation apporte une amélioration supplémentaire. (3) Bien qu'elles soient calculées à partir de corpus non analysés, nos fonctionnalités spécifiques aux tâches apprises surpassent les précédentes les caractéristiques typologiques interprétables de l'œuvre qui nécessitent des corpus analysés ou une catégorisation experte de la langue. Notre meilleure méthode a permis d'améliorer les scores des pièces jointes sur les langues de test tenues d'une moyenne de 5,6 points de pourcentage par rapport aux travaux antérieurs qui n'inspectent pas les données non analysées (McDonald et al., 2011), et de 20,7 points par rapport aux travaux antérieurs d' « initiation à la grammaire » qui n'utilisent pas de langues de formation (Naseem et al., 2010).</abstract_fr>
      <abstract_ja>新たな言語でのデレクシライズされた依存関係解析のための新しいフレームワークを紹介します。 ターゲット言語の有用な特徴は、ゴールド音声部分（ POS ）シーケンスのみで構成される解析されていないコーパスから自動的に抽出することができることを示しています。 これらの機能をニューラルパーサーに提供することで、コーパスのようなシーケンスを解析することができます。 驚くべきことに、私たちのシステムにはターゲット言語の監督はありません。 むしろ、他のさまざまな言語でエンドツーエンドでトレーニングされている多言語システムなので、うまく機能する機能抽出を学ぶことができます。 私たちは、複数の言語にわたって実験的に示されています。(1)解析されていないコーパスから計算された機能は、解析の精度を向上させます。(2)トレーニングに何千もの合成言語を含めると、さらなる改善がもたらされます。(3)解析されていないコーパスから計算されているにもかかわらず、私たちの学習されたタスク固有の機能は、解析されたコーパスまたは専門家による言語の分類を必要とする以前の研究の解釈可能な類型的特徴に勝っています。 私たちの最良の方法は、解析されていないデータを検査しない過去の作業よりも平均5.6パーセントポイント、およびトレーニング言語を使用しない過去の「文法帰納法」作業よりも20.7ポイント改善しました（ Naseem et al., 2010 ）。</abstract_ja>
      <abstract_zh>引入一新框架,以一新语中心化之赖解析。 吾言有以未解析者语料库自取之,语料库金词性(POS)序也。 供我神经解析器能,使能解析语料库序。 引人注目者,吾之系言不监也。 反是者,多言而统,端到端到而言,是以学行善提取器。 因实验展多种语言:(1)未尝解析者语料库计其解析准确性。 (2)于培训中数千种合成语言可更进。 (3)虽未解析之语料库计算出来,吾之所学特定破前事之可解者,解析语料库言语之家也。 臣等至法,将执试语言之依恋分数比往时不检未解析数事均升5.6百分点(McDonald等,2011)比旧不用训语者语法归纳20.7百分点(seNaem等,2010)。</abstract_zh>
      <abstract_hi>हम एक नई भाषा में delexicalized निर्भरता पार्सिंग के लिए एक उपन्यास रूपरेखा पेश करते हैं। हम दिखाते हैं कि लक्ष्य भाषा की उपयोगी विशेषताओं को स्वचालित रूप से एक अनपार्स्ड कॉर्पस से निकाला जा सकता है, जिसमें केवल सोने के पार्ट-ऑफ-स्पीच (पीओएस) अनुक्रम होते हैं। हमारे तंत्रिका पार्सर को इन सुविधाओं को प्रदान करना इसे कॉर्पस में उन जैसे अनुक्रमों को पार्स करने में सक्षम बनाता है। आश्चर्यजनक रूप से, हमारी प्रणाली का लक्ष्य भाषा में कोई पर्यवेक्षण नहीं है। इसके बजाय, यह एक बहुभाषी प्रणाली है जिसे विभिन्न अन्य भाषाओं पर एंड-टू-एंड प्रशिक्षित किया जाता है, इसलिए यह एक फीचर एक्सट्रैक्टर सीखता है जो अच्छी तरह से काम करता है। हम प्रयोगात्मक रूप से कई भाषाओं में दिखाते हैं: (1) अपरागत कॉर्पस से गणना की गई विशेषताएं पार्सिंग सटीकता में सुधार करती हैं। (2) प्रशिक्षण में हजारों सिंथेटिक भाषाओं को शामिल करने से और सुधार होता है। (3) अपरिभाषित कॉर्पोरेट से गणना किए जाने के बावजूद, हमारी सीखी गई कार्य-विशिष्ट विशेषताएं पिछले काम की व्याख्यायोग्य टाइपोलॉजिकल विशेषताओं को हरा देती हैं जिन्हें पार्स किए गए कॉर्पोरेट या भाषा के विशेषज्ञ वर्गीकरण की आवश्यकता होती है। हमारी सबसे अच्छी विधि ने पिछले काम पर 5.6 प्रतिशत अंकों के औसत से आयोजित-आउट परीक्षण भाषाओं पर अनुलग्नक स्कोर में सुधार किया है जो अनपार्स्ड डेटा (मैकडॉनल्ड्स एट अल।</abstract_hi>
      <abstract_ru>Введем новый фреймворк для делексикализованного синтаксического анализа зависимостей на новом языке. Показано, что полезные признаки целевого языка могут быть извлечены автоматически из неанализированного корпуса, состоящего только из золотых последовательностей части речи (POS). Предоставление этих функций нашему нейронному парсеру позволяет анализировать последовательности, подобные тем, которые находятся в корпусе. Поразительно, но наша система не контролирует целевой язык. Скорее, это многоязычная система, которая обучена сквозной на различных других языках, поэтому она изучает функцию извлечения, которая работает хорошо. Мы показываем экспериментально на нескольких языках: (1) функции, вычисленные из непарсированного корпуса, улучшают точность синтаксического анализа. (2) Включение тысяч синтетических языков в обучение дает дальнейшие улучшения. (3) Несмотря на то, что наши изученные особенности, связанные с конкретными задачами, вычислены из непарсированных корпусов, превзошли интерпретируемые типологические особенности предыдущей работы, которые требуют синтаксического анализа корпусов или экспертной категоризации языка. Наш лучший метод улучшил баллы прикрепления на языках, прошедших тестирование, в среднем на 5,6 процентных пункта за прошлую работу, которая не проверяет непарные данные (McDonald et al., 2011), и на 20,7 пункта за прошлую работу «грамматической индукции», которая не использует обучающие языки (Naseem et al., 2010).</abstract_ru>
      <abstract_ga>Tugaimid isteach creatlach nua le haghaidh parsáil spleáchais díleicseála i dteanga nua. Léirímid gur féidir gnéithe úsáideacha den sprioctheanga a bhaint go huathoibríoch as corpas neamhpharsáilte, nach bhfuil ann ach seichimh óir cuid de chaint (POS). Trí na gnéithe seo a chur ar fáil dár parsálaí néaracha cuireann sé ar a chumas seichimh mar iad siúd sa chorpas a pharsáil. Is iontach an rud é nach bhfuil aon mhaoirseacht ar ár gcóras sa sprioctheanga. Ina ionad sin, is córas ilteangach é atá oilte ó cheann ceann ar theangacha éagsúla eile, agus mar sin foghlaimíonn sé gné-eastóscadh a oibríonn go maith. Léirímid go turgnamhach thar teangacha iolracha: (1) Feabhsaíonn gnéithe a ríomhtar ón gcorpas neamhphasáilte cruinneas na parsála. (2) Má chuirtear na mílte teanga shintéiseacha san áireamh san oiliúint, tá feabhas breise ann. (3) In ainneoin a bheith á ríomh ó chorpora neamhphasáilte, sháraigh ár ngnéithe foghlamtha tasc-shonracha gnéithe tíopeolaíochta inléirmhínithe saothair roimhe seo a éilíonn corpora parsáilte nó catagóiriú saineolach ar an teanga. D’fheabhsaigh an modh is fearr na scóir iatáin ar theangacha tástála a coinníodh amach 5.6 pointe céatadáin ar an meán thar obair san am atá caite nach ndéanann cigireacht ar na sonraí neamhpharsáilte (McDonald et al., 2011), agus 20.7 pointe thar obair “ionduchtúcháin ghramadaí” san am atá thart. nach n-úsáideann teangacha oiliúna (Naseem et al., 2010).</abstract_ga>
      <abstract_hu>Új keretrendszert vezetünk be a delexikalizált függőség elemzésére egy új nyelven. Megmutatjuk, hogy a célnyelv hasznos tulajdonságai automatikusan kivonhatók egy nem értelmezett korpuszból, amely csak arany beszédrészből (POS) áll. Ezeket a funkciókat a neurális elemzőnknek biztosítva lehetővé teszi, hogy olyan szekvenciákat elemezzen, mint a korpuszban. Meglepő, hogy a rendszerünknek nincs felügyelete a célnyelven. Ez inkább egy többnyelvű rendszer, amelyet végtől-végig képeznek számos más nyelven, így megtanul egy jól működő funkcióelszívót. Kísérleti módon több nyelven mutatjuk be: (1) A feldolgozatlan korpuszból kiszámított funkciók javítják az elemzési pontosságot. (2) A képzésbe több ezer szintetikus nyelv bevonása további javulást eredményez. (3) Annak ellenére, hogy nem értelmezett corporákból számítottuk ki, tanult feladatspecifikus funkcióink meghaladják a korábbi munka értelmezhető tipológiai tulajdonságait, amelyek értelmezett corporákat vagy szakértői kategorizálást igényelnek a nyelv. Legjobb módszerünk átlagosan 5,6 százalékponttal javította a kitartott tesztnyelveken végzett mellékleti pontszámokat a múltbeli munkákhoz képest, amelyek nem vizsgálják a meg nem olvasható adatokat (McDonald et al., 2011), valamint 20,7 ponttal a múltbeli "nyelvtani indukciós" munkákhoz képest, amelyek nem használnak képzési nyelveket (Naseem et al., 2010).</abstract_hu>
      <abstract_ka>ჩვენ დავიყენებთ ნომალური ფრამეტრი დელექსიკურად დაახლოებისთვის პარასიზაციის ახალი ენაში. ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ მინიშვნელოვანი ენის გამოსახულებელი ფუნქციები შეიძლება ავტომატურად გააკექტირება, რომელიც მხოლოდ სილარული ნაწილის (POS) სკენექ ჩვენი ნეიროლური პასუტერისთვის ამ ფუნქციების გადაწყენება შესაძლებელია, როგორც კორპუსში. ჩვენი სისტემა არ აქვს მარტივი ენაში. მაგრამ, ეს არის მრავალენგური სისტემა, რომელიც საკუთარი ენების განსაკუთრებულია, ამიტომ ის სწავლის განსაკუთრებული ექსტრაქტორი, რომელიც მუშაობს. ჩვენ ექსპერიმენტიურად გამოჩვენებთ მრავალ ენების განმავლობაში: (2) ათასობით სინტეტიკური ენების შესახებ განსწავლებაში უფრო მეტი უფრო მეტია. (3) მუშაობის კომპუტირებით, თუმცა ჩვენი მოსწავლილი საქმების კომპუტირებით განსხვავებული ტიპოლოგიური ფუნქციები, რომლებიც მუშაობენ პანსპორა ან ექსპერტის კატეგ ჩვენი ყველაზე საუკეთესო პროცენტი დაკავშირებული წერტილებების შესაძლებლობით გააკეთება 5,6 პროცენტის წერტილებების განმავლობაში, რომლებიც წინ მუშაობის განმავლობაში მონაცემები (McDonald et al., 2011) და 20,7 წერტილებით წინ 'გრამიური ინდიქცია'</abstract_ka>
      <abstract_el>Εισάγουμε ένα νέο πλαίσιο για την ανάλυση της απεξαρτημένης εξάρτησης σε μια νέα γλώσσα. Δείχνουμε ότι χρήσιμα χαρακτηριστικά της γλώσσας-στόχου μπορούν να εξαχθούν αυτόματα από ένα μη καταρτισμένο σώμα, το οποίο αποτελείται μόνο από χρυσές ακολουθίες τμήματος ομιλίας (POS). Η παροχή αυτών των χαρακτηριστικών στον νευρικό μας αναλυτή επιτρέπει να αναλύει ακολουθίες όπως αυτές στο σώμα. Παραδόξως, το σύστημά μας δεν έχει εποπτεία στη γλώσσα-στόχο. Αντίθετα, είναι ένα πολύγλωσσο σύστημα που εκπαιδεύεται από το τέλος σε μια ποικιλία άλλων γλωσσών, έτσι μαθαίνει ένα εργαλείο εξαγωγής χαρακτηριστικών που λειτουργεί καλά. Δείχνουμε πειραματικά σε πολλές γλώσσες: (1) Χαρακτηριστικά που υπολογίζονται από το μη καταρτισμένο σώμα βελτιώνουν την ακρίβεια ανάλυσης. (2) Η ένταξη χιλιάδων συνθετικών γλωσσών στην εκπαίδευση επιφέρει περαιτέρω βελτίωση. (3) Παρά το γεγονός ότι υπολογίζονται από μη καταρτισμένα σώματα, τα μαθημένα χαρακτηριστικά συγκεκριμένων εργασιών μας ξεπερνούν τα ερμηνευτά τυπολογικά χαρακτηριστικά προηγούμενης εργασίας που απαιτούν αναλύσεις σωμάτων ή εξειδικευμένη κατηγοριοποίηση της γλώσσας. Η καλύτερη μέθοδος μας βελτίωσε τις βαθμολογίες συνημμένων γλωσσών δοκιμών κατά μέσο όρο 5,6 ποσοστών σε σχέση με την προηγούμενη εργασία που δεν επιθεωρεί τα μη καταρτισμένα δεδομένα (κ.α., 2011), και κατά 20.7 πόντους σε προηγούμενες εργασίες "επαγωγής γραμματικής" που δεν χρησιμοποιούν γλώσσες κατάρτισης (κ.α., 2010).</abstract_el>
      <abstract_kk>Біз делегсикалық тәуелдік талдау үшін жаңа тілде жаңа фреймін келтіреміз. Біз мақсатты тілдің пайдалы мүмкіндіктерін автоматты түрде өшірілмеген корпустан алып тастауға болады. Бұл тек алтын бөлігінің (POS) ретінде болады. Бұл мүмкіндіктерді біздің невралдық талдаушыларымыз корпустағы реттеулерді талдауға мүмкіндік береді. Біздің жүйеміздің мақсатты тілде қарау жоқ. Бұл бірнеше тілдерге бірнеше тілдерді аяқтау жүйесі, сондықтан ол жақсы жұмыс істейтін қасиеттерді үйренеді. Біз бірнеше тілдерге тәжірибелі түрлерді көрсетедік: (1) Өткізілмеген корпустың есептелген мүмкіндіктері талдау дұрыстығын өзгертеді. (2) Оқыту үшін мыңдаған синтетикалық тілдер қосылған болса, көптеген жақсартуларды жасайды. (3) Корпорадан есептелмеген, біздің үйренген тапсырманың ерекше мүмкіндіктеріміз алдыңғы жұмысының толыпты типтологиялық мүмкіндіктері, оларды талдау корпорада не тілдің эксперттердің категориясын Біздің ең жақсы әдіміміз өткен жұмыстың орташа 5,6 процент нүктелерін тексермейтін деректерді (McDonald et al., 2011) тексермейтін жұмыс тілдерінің орташа 20,7 нүктелерімен өткен 'грамматикалық индукциясы' жұмыс істемейтін тілдері (Naseem et al., 2010).</abstract_kk>
      <abstract_lt>Įdiegiame naują deleksilizuoto priklausomybės analizavimo naująja kalba sistemą. Mes parodome, kad naudingos tikslinės kalbos savybės gali būti automatiškai ištraukiamos iš neapdoroto korpuso, kurį sudaro tik auksinė kalbos dalis (POS). Šių savybių suteikimas mūsų nervų analizatoriui leidžia analizuoti sekas kaip kūne. Strikingly, our system has no supervision in the target language.  Tai yra daugiakalbė sistema, kuri iš vienos iki kitos mokoma įvairiomis kitomis kalbomis, taigi ji mokosi gerai veikiančio savybių ekstraktoriaus. Eksperimentiškai parodomi įvairiomis kalbomis: (1) Iš neapdoroto korpuso apskaičiuotos savybės pagerina analizavimo tikslumą. (2) Including thousands of synthetic languages in the training yields further improvement.  (3) Nepaisant to, kad jie apskaičiuojami iš neapdorotos korpros, mūs ų mokomos užduoties specifinės savybės viršija ankstesnio darbo aiškinamąsias tipologines savybes, kurios reikalauja ištirtos korpros arba kalbos ekspertų klasifikavimo. Mūsų geriausias metodas pagerino prisijungimo prie bandomųjų kalbų rezultatus vidutiniškai 5,6 procentinio punkto, palyginti su ankstesniu darbu, kuriame neatsižvelgiama į neparengtus duomenis (McDonald et al., 2011), ir 20,7 punkto, palyginti su ankstesniu „gramatinės indukcijos“ darbu, kuriame nenaudojamos mokymo kalbos (Naseem et al., 2010).</abstract_lt>
      <abstract_ms>We introduce a novel framework for delexicalized dependency parsing in a new language.  Kami menunjukkan bahawa ciri-ciri berguna bahasa sasaran boleh dikekstrak secara automatik dari korpus yang tidak terpasang, yang hanya terdiri dari urutan bahagian emas-dari-ucapan (POS). Providing these features to our neural parser enables it to parse sequences like those in the corpus.  Menakjubkan, sistem kita tidak mempunyai pengawasan dalam bahasa sasaran. Rather, it is a multilingual system that is trained end-to-end on a variety of other languages, so it learns a feature extractor that works well.  Kami menunjukkan secara eksperimen melalui berbagai bahasa: (1) Ciri-ciri yang dikira dari korpus tidak tersimpan meningkatkan ketepatan penghuraian. (2) Termasuk ribuan bahasa sintetik dalam latihan memberikan perkembangan lanjut. (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work's interpretable typological features that require parsed corpora or expert categorization of the language.  Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past 'grammar induction' work that does not use training languages (Naseem et al., 2010).</abstract_ms>
      <abstract_ml>നമ്മള്‍ പുതിയ ഭാഷയില്‍ ഡെക്സിക്സിക്കല്‍ ചെയ്ത ആശ്രമത്തിന് ഒരു നോവല്‍ ഫ്രെയിമെക്ക് പരിചയപ്പെടുത്തും. നമ്മള്‍ കാണിച്ചുകൊടുക്കുന്നു, ലക്ഷ്യഭാഷയുടെ ഉപയോഗങ്ങള്‍ സ്വയം പാര്‍ട്ടില്ലാത്ത കോര്‍പ്പുസില്‍ നിന്ന് പുറത്തെടുക്കാന്‍ സാധിക് നമ്മുടെ ന്യൂറല്‍ പരാജയപ്രകാരം ഈ വിശേഷങ്ങള്‍ കൊടുക്കുന്നത് കോര്‍പ്പുസിലെ പോലുള്ള സെക്കന്‍സുകള്‍ പാര്‍സ് ചെയ് കഠിനമായി, നമ്മുടെ സിസ്റ്റത്തിന് ലക്ഷ്യഭാഷയില്‍ നിരീക്ഷിക്കുന്നില്ല. മറ്റു പല ഭാഷകളിലും അവസാനം പരിശീലിക്കപ്പെടുന്ന പല ഭാഷകളിലും, അതുകൊണ്ട് അത് നല്ല പ്രവര്‍ത്തിക്കുന്ന ഒരു പ്രത്യേക വിശിഷ്ടമായ പ്രക നമ്മള്‍ പല ഭാഷകളിലും പരീക്ഷണത്തില്‍ കാണിച്ചുകൊടുക്കുന്നു: (1) പാര്‍സിങ്ങ് പാര്‍ക്ക് ചെയ്യുന്നതിന്റെ കൃത്യം  (2) പരിശീലനത്തില്‍ ആയിരക്കണക്കിന് സങ്കേതിക ഭാഷകള്‍ ചേര്‍ക്കുന്നത് കൂടുതല്‍ മെച്ചപ്പെടുത്തും. (3) പാര്‍ട്ട് ചെയ്തിട്ടില്ലാത്ത കോര്‍പ്പോരിയില്‍ നിന്നും കണക്ക് ചെയ്യപ്പെടുന്നതിന് ശേഷം, നമ്മുടെ പഠിച്ച പണിയുടെ പ്രത്യേക വിശേഷിപ്പുകള നമ്മുടെ ഏറ്റവും നല്ല രീതിയില്‍ സൂക്ഷിക്കപ്പെട്ട പരീക്ഷ ഭാഷകളിലുള്ള ബന്ധപ്പെടുത്തുന്ന സ്കോര്‍ മുന്‍കൂട്ടിയിരിക്കുന്നു. കഴിഞ്ഞ ജോലിയില്‍ 5.6 ശതമാന പോയിന്റുകള്‍ പരിശോധിക്കാത</abstract_ml>
      <abstract_mk>Ние воведуваме нова рамка за анализирање на делексикализираната зависност на нов јазик. Ние покажуваме дека корисните карактеристики на јазикот на метата може да се извлечат автоматски од непарсен корпус, кој се состои само од златен дел од говорот (POS). Поставувањето на овие карактеристики на нашиот нервен анализатор му овозможува да анализира секвенции како оние во телото. Нашиот систем нема надзор на јазикот на метата. Наместо тоа, тоа е мултијазичен систем кој е обучен од крај до крај на различни други јазици, па научи екстрактор на функции кој функционира добро. Ги покажуваме експериментално низ повеќе јазици: (1) Функциите кои се обчистуваат од непрочитаниот корпус ја подобруваат прецизноста на анализирањето. (2) Вклучувањето на илјадници синтетички јазици во обуката предизвикува понатамошно подобрување. (3) И покрај тоа што се компјутираат од непрочитана корпора, нашите научени специфични карактеристики ги претепуваат претходните типологички карактеристики кои бараат анализирана корпора или експертска категоризација на јазикот. Нашиот најдобар метод ги подобри резултатите на приклучувањето на тестираните јазици за просечно 5,6 процентни поени во однос на минатата работа која не ги инспектира непослободените податоци (McDonald et al., 2011), и за 20,7 поени во однос на минатата „граматска индукција“ која не користи јазици за обука (Naseem et al., 2010).</abstract_mk>
      <abstract_it>Introducemo un nuovo framework per l'analisi delle dipendenze delessicalizzate in un nuovo linguaggio. Mostriamo che le caratteristiche utili della lingua di destinazione possono essere estratte automaticamente da un corpus non cantato, che consiste solo di sequenze Gold part-of-speech (POS). Fornire queste caratteristiche al nostro parser neurale permette di analizzare sequenze come quelle nel corpo. Sorprendentemente, il nostro sistema non ha alcuna supervisione nella lingua di destinazione. Piuttosto, è un sistema multilingue che viene addestrato end-to-end su una varietà di altre lingue, quindi impara un estrattore di funzionalità che funziona bene. Mostriamo sperimentalmente in più lingue: (1) Le funzionalità calcolate dal corpus non tradotto migliorano l'accuratezza dell'analisi. (2) L'inclusione di migliaia di lingue sintetiche nella formazione comporta un ulteriore miglioramento. (3) Nonostante siano calcolate da corpora non cantata, le nostre caratteristiche specifiche per attività apprese superano le caratteristiche tipologiche interpretabili del lavoro precedente che richiedono corpora analizzata o categorizzazione esperta del linguaggio. Il nostro metodo migliore ha migliorato i punteggi degli allegati sulle lingue di prova tenute fuori di una media di 5,6 punti percentuali rispetto al lavoro passato che non ispeziona i dati non trattati (McDonald et al., 2011), e di 20,7 punti rispetto al lavoro passato di "induzione grammaticale" che non utilizza lingue di formazione (Naseem et al., 2010).</abstract_it>
      <abstract_mn>Бид шинэ хэл дээр шинэ хамааралтай хамааралтай байдлыг хуваалцахын тулд шинэ хэлбэрийг танилцуулдаг. Бид зориулагдсан хэлний хэрэглэгдэх чадварыг автоматаар ашиглаж чадна. Энэ нь зөвхөн алтын хэсэг (POS) хэлбэрээс л байдаг. Бидний мэдрэлийн шинжилгээнд эдгээр тохиолдолуудыг нь корпус дахь тохиолдолуудыг хуваалцах боломжтой болгодог. Харамсалтай нь бидний систем зорилготой хэл дээр ажиллаж чадахгүй. Үнэндээ, энэ бол олон хэлний систем, бусад хэл дээр төгсгөлд суралцаж байгаа, тиймээс энэ нь сайн ажилладаг шинж тэмдэглэгчийг суралцаж байна. Бид олон хэл дээр туршилт үзүүлдэг: (1) Хэрэглэгдэхгүй корпус-аас тооцогдсон боломжууд нь хуваалцах зөв байдлыг сайжруулдаг. (2) Сургуульд мянга мянга мянган синтетик хэл нэмэгдүүлэх нь илүү сайжруулдаг. (3) Холбогдолгүй корпорациас тооцоологдож байгаа ч, бидний сурсан ажлын тодорхойлолт нь өмнөх ажлын тодорхойлж чадахгүй типтологикийн хувилбаруудыг шаарддаг. Энэ нь хэлний хувилбар эсвэл мэргэжилтнүүдийн ху Бидний хамгийн шилдэг арга нь өнгөрсөн ажлын турш 5.6 хувийн цэгүүдийн дунджаар холбогдолтын оноо сайжруулсан бөгөөд сайжруулагдсан өгөгдлийг шалгахгүй (McDonald et al., 2011) болон өмнө нь 20.7 цэгүүдийн дараа нь "грамматик индукцийн" хэл ашиглахгүй ажлыг ашиглаж байгаа аж</abstract_mn>
      <abstract_mt>Aħna nintroduċu qafas ġdid għall-analiżi tad-dipendenza delessializzata f’lingwa ġdida. Aħna nuru li l-karatteristiċi utli tal-lingwa fil-mira jistgħu jiġu estratti awtomatikament minn korpus mhux ippressat, li jikkonsisti biss f’sekwenzi ta’ parti tad-deheb tad-diskors (POS). Providing these features to our neural parser enables it to parse sequences like those in the corpus.  B’mod strinġenti, is-sistema tagħna m’għandha l-ebda superviżjoni fil-lingwa fil-mira. Rather, it is a multilingual system that is trained end-to-end on a variety of other languages, so it learns a feature extractor that works well.  Aħna nuru esperimentalment f'diversi lingwi: (1) Karatteristiċi kkalkulati mill-korpus mhux ippressat itejbu l-preċiżjoni tal-analiżi. (2) Including thousands of synthetic languages in the training yields further improvement.  (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work's interpretable typological features that require parsed corpora or expert categorization of the language.  Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past 'grammar induction' work that does not use training languages (Naseem et al., 2010).</abstract_mt>
      <abstract_pl>Wprowadzamy nowe ramy do deleksykalizowanego parsowania zależności w nowym języku. Pokazujemy, że użyteczne cechy języka docelowego mogą być wyodrębnione automatycznie z nieparsowanego korpusu, który składa się tylko ze złotych sekwencji części mowy (POS). Dostarczenie tych funkcji naszemu parserowi neuronowemu umożliwia analizowanie sekwencji takich jak te w ciele. Co ciekawe, nasz system nie ma nadzoru w języku docelowym. Jest to raczej wielojęzyczny system, który jest szkolony od końca do końca w wielu innych językach, więc uczy się ekstraktora funkcji, który działa dobrze. Pokazujemy eksperymentalnie w wielu językach: (1) Funkcje obliczone z nieparsowanego korpusu poprawiają dokładność parsowania. (2) Włączenie tysięcy języków syntetycznych do szkolenia przynosi dalszą poprawę. (3) Pomimo obliczania z nieparsowanych korpusów, nasze nauczone cechy specyficzne dla zadań pokonują interpretowalne cechy typologiczne poprzednich prac, które wymagają parsowanych korpusów lub specjalistycznej kategoryzacji języka. Nasza najlepsza metoda poprawiła wyniki załączników dla wytrzymanych języków testowych o średnią 5,6 punktów procentowych w porównaniu z poprzednimi pracami, które nie sprawdzają nieparsowanych danych (McDonald et al., 2011), oraz o 20,7 punktów w porównaniu z poprzednimi pracami "indukcji gramatyki", które nie używają języków treningowych (Naseem et., 2010).</abstract_pl>
      <abstract_ro>Introducem un nou cadru pentru analizarea dependenței delexicalizate într-o limbă nouă. Noi arătăm că caracteristicile utile ale limbii țintă pot fi extrase automat dintr-un corpus neprezentat, care constă numai din secvențe aurii part-of-speech (POS). Furnizând aceste caracteristici parserului nostru neural îi permite să analizeze secvenţe ca cele din corp. În mod surprinzător, sistemul nostru nu are supraveghere în limba țintă. Mai degrabă, este un sistem multilingv care este instruit end-to-end pe o varietate de alte limbi, astfel încât să învețe un extractor de caracteristici care funcționează bine. Prezentăm experimental în mai multe limbi: (1) Caracteristicile calculate din corpul neprezentat îmbunătățesc acuratețea analizării. (2) Includerea în formare a mii de limbi sintetice duce la o îmbunătăţire suplimentară. (3) În ciuda faptului că sunt calculate din corpore neprezentate, caracteristicile noastre specifice sarcinilor învățate depășesc caracteristicile tipologice interpretabile ale lucrărilor anterioare care necesită corpore analizate sau categorizarea de experți a limbajului. Cea mai bună metodă a noastră a îmbunătățit punctajele de atașare pe limbile de testare susținute cu o medie de 5,6 puncte procentuale față de activitatea anterioară care nu inspectează datele neprezentate (McDonald et al., 2011) și cu 20,7 puncte față de activitatea anterioară de "inducție gramaticală" care nu utilizează limbi de formare (Naseem et al., 2010).</abstract_ro>
      <abstract_no>Vi introduserer eit nytt rammeverk for deleksisert tolking av avhengighet i eit ny språk. Vi viser at nyttige funksjonar på målspråket kan ekstraherast automatisk frå eit ugyldig korpus, som berre inneheld gull del av tale (POS) sekvensar. Tilbyr desse funksjonane til vår neuralanalyser, kan det tolka sekvensar som dei i korpusen. Strengt har systemet vårt ingen oversikt i målspråket. I staden er det ein fleirspråk system som er trent til slutten på mange andre språk, så det lærer ein funksjonsekstraktor som fungerer godt. Vi viser eksperimentelt på fleire språk: (1) Funksjonar rekna ut frå den ugjengelege korpusen forbetra tolkinga nøyaktighet. (2) Inkluderer tusenvis av syntetiske språk i opplæringa gjer meir forbetringar. (3) Tiltross å verta rekna ut frå ugjennomsiktige korpora, våre lærte oppgåve-spesifikke funksjonar slår typologiske funksjonar på tidlegare arbeid som krev tolka korpora eller ekspertkategorisering av språket. Våre beste metoden forbetra vedleggspråk på haldne testspråk med gjennomsnittlig 5,6 prosentpunkt over tidlegare arbeid som ikkje kontrollerer utvarte data (McDonald et al., 2011) og 20,7 punkt over tidlegare arbeidet «gramatisk induksjon» som ikkje brukar øvingsspråk (Naseem et al., 2010).</abstract_no>
      <abstract_sr>Predstavljamo novi okvir za analizu deleksikaliziranog zavisnosti na novom jeziku. Pokazujemo da korisne karakteristike ciljnog jezika mogu automatski izvući iz neoštećenog korpusa, koji se sastoji samo od zlatnih deo govora (POS) sekvencija. Obezbeđujući te karakteristike našem neuralnom analizatoru omogućava joj da analizira sekvence poput one u korpusu. Strašno, naš sistem nema nadzor na jeziku cilja. Umesto toga, to je multijezički sistem koji je obučen na kraju do kraja na raznim drugim jezicima, tako da nauči ekstraktor karakteristike koji dobro funkcioniše. Pokazujemo eksperimentalno na višestrukim jezicima: (1) Features računale iz nepasađenog korpusa poboljšavaju preciznost parsiranja. (2) Uključujući hiljade sintetičkih jezika u obuku, dodaje daljnje poboljšanje. (3) Uprkos raèunanju od neopržene korpore, naša naučena specifična zadatka pobijedila su tipološke karakteristike prethodnog rada koje zahtevaju analiziranu korporaciju ili kategoriju stručnjaka jezika. Naša najbolja metoda je poboljšala rezultate priključenja na testovima na prosjeku od 5,6 postotnih poena u prošlom poslu koji ne provjeravaju nepristojene podatke (McDonald et al., 2011) i za 20,7 poena u prošlom radu "gramatična indukcija" koja ne koristi jezike obuke (Naseem et al., 2010).</abstract_sr>
      <abstract_sv>Vi introducerar ett nytt ramverk för delegkaliserad beroendetolkning på ett nytt språk. Vi visar att användbara funktioner i målspråket kan extraheras automatiskt från en oparserad korpus, som endast består av guld part-of-speech (POS) sekvenser. Genom att tillhandahålla dessa funktioner till vår neurala parser kan den tolka sekvenser som de i korpusen. Slående nog har vårt system ingen övervakning på målspråket. Snarare är det ett flerspråkigt system som utbildas heltäckande på en mängd andra språk, så det lär sig en funktion extractor som fungerar bra. Vi visar experimentellt över flera språk: (1) Funktioner som beräknats från oparserad korpus förbättrar tolkningens noggrannhet. (2) Att inkludera tusentals syntetiska språk i utbildningen ger ytterligare förbättringar. (3) Trots att de beräknats från oparserade korpora slår våra lärda uppgiftsspecifika funktioner tidigare arbetes tolkningsbara typologiska funktioner som kräver tolkade korpora eller expertkategorisering av språket. Vår bästa metod förbättrade bilagornas betyg på hållna testspråk med i genomsnitt 5,6 procentenheter jämfört med tidigare arbete som inte inspekterar de oparserade uppgifterna (McDonald m.fl., 2011), och med 20,7 procentenheter jämfört med tidigare "grammatisk induktion" arbete som inte använder utbildningsspråk (Naseem m.fl., 2010).</abstract_sv>
      <abstract_ta>நாம் ஒரு புதிய மொழியில் பாசிங்குக்கு ஒரு புதிய புதிய விளிம்பை குறிப்பிடுகிறோம். இலக்கு மொழியின் பயனுள்ள குணங்களை தானாகவே வெளியேற்ற முடியும், அது தங்கக் கூடிய பேச்சின் பின்னணிகளில் மட்டும் இருக்கும். இந்த குணங்களை எங்கள் நெருரல் பகுதிக்கு வழங்குவது கூட்டத்தில் உள்ள தொடர்களை பார்க்க முடியும். கடுமையாக, எங்கள் கணினியில் இலக்கு மொழியில் கண்காணிப்பு இல்லை. அதற்கு பதிலாக, இது பல மொழிகளின் முடிவு முடிவில் பயிற்சி செய்யப்பட்டுள்ளது மற்ற மொழிகளில் முடிவு முடிவு ஆகும், அதனால் இது நன்றாக பல மொழிகளில் நாம் பரிசோதனையாக காட்டுகிறோம்: (1) பார்க்கப்படாத குறிப்புகளிலிருந்து கணக்கிடப்பட்ட சிலவற்றின் கு (2) பயிற்சியில் ஆயிரக்கணக்கான ஒருங்கிணைப்பு மொழிகளை சேர்த்து முன்னேற்றத்தை கொண்டு வருகிறத (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work's interpretable typological features that require parsed corpora or expert categorization of the language.  எங்கள் சிறந்த முறைமையில் உள்ள சோதனை மொழிகளில் இணைப்பு புள்ளிகளை மேம்படுத்தி 5.6 சதவிகிதம் புள்ளிகள் முந்தைய வேலையில் சராசரி 5.6 சதவிகிதம் புள்ளிகளால் அது பார்க்கவில்லையான தகவல்கள</abstract_ta>
      <abstract_so>We introduce a novel framework for delexicalized dependency parsing in a new language.  Waxaynu tusnaynaa in heerarka luqada caafimaadka ah waxaa si automati ah looga soo saari karaa koroor aan la sameyn karo, kaas oo ku jira qeyb dahab ah oo hadalka (POS) oo keliya. Providing these features to our neural parser enables it to parse sequences like those in the corpus.  Si adag, nidaamkayagu ma haysto ilaaliye afka goalka ah. Isku xiriir, waa nidaam luuqado kala duduwan oo lagu baranayo dhammaadka ugu dambaysta luuqado kala duduwan, sidaas darteed waxaa baranaya kharash dhaqaale oo si wanaagsan u shaqeeya. Waxaan si tijaab ah ugu muujinnaa luuqado kala duduwan: (1) Xiriimaha la xisaabiyay oo laga hormariyo saxda baaritaanka. (2) Waxbarashada ku jira kumanyaal luqadood oo israacsan waxay bixisaa hagaajin dheeraad ah. (3) Inta kastoo aan laga xisaabin shirkadaha aan la qorin, tayooyinkayagii la bartay oo khaas ah ayaa jabsaday heerka shaqada ee hore oo lagu turjumo noocyo ah oo u baahan yahay shirkad la soo bandhigay ama qeyb-dhigista aqoonta luqada. Shaqooyinkayada ugu wanaagsan ayaa hagaajiyey kooxaha jimicsiga oo ku qoran luqadaha lagu tijaabiyey, qiyaastii waa boqolkiiba 5.6 ee shaqada hore oo aan ka fiirsanayn macDonald et al., 2011) iyo 20.7 goor hore oo aan isticmaalin luuqadaha waxbarashada (Naseem et al., 2010).</abstract_so>
      <abstract_ur>蹃賲 丕蹖讴 賳卅蹖 夭亘丕賳 賲蹖诤 丕蹖讴 賳卅蹖 賮乇賲賵丿 倬蹖卮 讴乇蹖诤 诏蹝 噩賵 趫蹖賱爻讴蹖讴爻蹖讴爻蹖讴爻蹖讴爻蹖讴爻蹖讴爻蹖讴爻蹖夭蹖 丕毓鬲賲丕丿蹖 倬丕乇爻蹖賳诏 讴蹝 賱卅蹝 蹃蹝蹟 蹃賲 賳卮丕賳 丿蹖鬲蹝 蹃蹖诤 讴蹃 賲賵噩賵丿 夭亘丕賳 讴蹖 賲賮蹖丿 賵蹖跇蹝 丕俟诰丕卅蹝 噩丕鬲蹝 蹃蹖诤 丕蹖讴 睾蹖乇 賲丨賮賵馗 讴賵乇倬賵爻 爻蹝貙 噩賵 氐乇賮 爻賵賳蹝 讴蹝 俟讴趹蹝 (POS) 爻胤丨 爻蹝 蹃蹝蹟 蹃賲丕乇蹝 賳蹖賵乇丕賱 倬丕乇趩乇 讴蹝 賱卅蹝 蹖蹃 賮乇氐鬲 倬蹖卮 讴乇賳蹝 讴蹝 賱卅蹝 丕爻 讴賵 噩爻賲 讴蹖 胤乇丨 爻胤丨 讴丕 鬲賯爻蹖賲 讴乇賳丕 賲賲讴賳 蹃蹝蹟 毓噩蹖亘 胤賵乇 倬乇貙 蹃賲丕乇蹖 爻蹖爻俟賲 蹃丿丕蹖鬲 夭亘丕賳 賲蹖诤 讴賵卅蹖 賳馗乇 賳蹃蹖诤 蹃蹝蹟 亘賱讴蹃 蹖蹃 丕蹖讴 亘蹃鬲 爻蹖 夭亘丕賳 讴蹖 爻蹖爻鬲賲 蹃蹝 噩賵 亘蹃鬲 爻蹖 夭亘丕賳賵诤 倬乇 丌禺乇 賵 丌禺乇 讴蹖 鬲毓賱蹖賲 讴蹖 噩丕鬲蹖 蹃蹝貙 丕爻 賱卅蹝 蹖蹃 丕蹖讴 卮禺氐蹖鬲 丕囟丕賮蹃 讴乇賳蹝 賵丕賱丕 爻讴诰丕鬲丕 蹃蹝 噩賵 亘蹃鬲乇 讴丕賲 讴乇鬲丕 蹃蹝蹟 蹃賲 亘蹃鬲 爻蹖 夭亘丕賳賵诤 賲蹖诤 丌夭賲丕卅卮 讴蹝 爻丕鬲诰 丿讴诰丕鬲蹝 蹃蹖诤: (1) 睾蹖乇 賲丨賮賵馗鬲 讴蹖 噩爻賲 爻蹝 讴丕賲倬蹖賵鬲乇 讴蹖蹝 诏卅蹝 蹃蹖诤 讴蹃 倬丕乇爻 丿賯蹖賯蹖鬲 讴賵 亘蹃鬲乇 讴乇 丿蹖鬲蹝 蹃蹖诤蹟 (2) 鬲毓賱蹖賲 賲蹖诤 蹃夭丕乇賵诤 爻蹖賳俟蹖爻蹖 夭亘丕賳賵诤 賲蹖诤 卮丕賲賱 蹃賵鬲丕 蹃蹝 丕賵乇 丕囟丕賮蹃 讴乇鬲丕 蹃蹝蹟 (3) 亘睾蹖乇 賲丨賮賵馗 讴蹖 讴賲倬蹖賵俟乇 爻蹝 賲丨丕爻亘蹃 讴蹖蹝 噩丕鬲蹝 蹃蹖诤貙 蹃賲丕乇蹖 鬲毓賱蹖賲 讴蹖蹝 蹃賵卅蹝 讴丕賲 讴蹖 鬲毓賱蹖賲 爻蹝 倬蹃賱蹝 讴蹝 讴丕賲 讴蹖 鬲賮爻蹖乇 賯丕亘賱 鬲丕蹖倬賵賱賵跇蹖讴賵诤 讴蹖 鬲毓乇蹖賮 倬乇 囟乇賵乇鬲 丿蹖 噩丕鬲蹖 蹃蹝 噩賵 夭亘丕賳 讴蹖 賲禺賱賵賯丕鬲 蹖丕 賲禺賱賵賯丕鬲 讴蹖 鬲賯爻蹖賲 讴蹖 囟乇賵乇鬲 讴乇鬲蹖 蹃賲丕乇丕 亘蹃鬲乇蹖賳 胤乇蹖賯蹃 倬蹃賱蹝 讴丕乇賵诤 倬乇 5.6 賮蹖氐丿 倬賵蹖賳俟 讴蹝 賲鬲賵爻胤 爻蹝 丕俟蹖俟賲賳俟 丕爻讴賵乇俟 倬乇 丕爻鬲毓賲丕賱 讴蹖丕 诏蹖丕 鬲诰丕 噩賵 亘睾蹖乇 賲丨賮賵馗 趫丕俟 (McDonald et al., 2011) 丕賵乇 20.7 倬賵蹖賳俟 讴蹝 賲胤丕亘賯 '诏乇賲丕俟 丕蹖趫蹖讴卮賳' 讴蹝 賲胤丕亘賯 丕爻鬲毓賲丕賱 賳蹃蹖诤 讴乇鬲丕 (Naseem et al., 2010).</abstract_ur>
      <abstract_si>අපි අළුත් භාෂාවක් වලින් නිර්මාණය කරපු නිර්මාණය විශේෂ කරනවා. අපි පෙන්වන්නේ ඉලක්ෂ භාෂයේ ප්‍රයෝජනයක් ස්වයංක්‍රමයෙන් ප්‍රයෝජනය කරන්න පුළුවන් කොර්පස් වලින් ස්වයංක්‍රමයෙන අපේ න්‍යූරාල් විශේෂකයෙන් මේ විශේෂතාවක් දෙන්න පුළුවන් ඒක කෝපුස් වලින් විශේෂ කරන්න. අපේ පද්ධතියේ ලක්ෂණ භාෂයේ බලන්න කිසිම දෙයක් නෑ. වෙනස් වෙනස් භාෂාවක් වලින් ප්‍රශ්නයක් තියෙනවා, ඉතින් ඒක හොඳට වැඩ කරන්න ප්‍රශ්නයක් ඉගෙන ගන්නවා. අපි විශේෂ භාෂාවක් වලින් පරීක්ෂණයක් පෙන්වන්න පුළුවන්: (1) විශේෂ නැති කොර්පුස් වලින් පරීක්ෂ (2) සංවේදනය සම්පූර්ණයෙන් සංවේදන භාෂාවක් සම්පූර්ණය කරනවා. (3) නැති කොර්පෝරා වලින් පරික්ෂා කරලා තියෙන්නේ නමුත්, අපේ ඉගෙන ගත්ත වැඩක් විශේෂ විශේෂ අවශ්‍ය වැඩක් පසුගිය වැඩක් අන අපේ හොඳම විධානය සම්බන්ධ විදිහට පරීක්ෂණ භාෂාවට සුදුසුම් කරලා තියෙන්නේ පසුගිය වැඩේ 5.6 ප්‍රශ්නයක් ප්‍රශ්නයක් ප්‍රශ්නයක් පරීක්ෂණය කරලා තියෙන්නේ නෑ ව</abstract_si>
      <abstract_vi>Chúng tôi giới thiệu một cơ sở mới để phân tích sự phụ thuộc. Chúng tôi cho thấy những tính năng hữu ích của ngôn ngữ đích có thể được tự động lấy ra từ một cơ thể không đối trọng, chỉ có các chuỗi phần vàng trong ngôn ngữ (POS). Cung cấp những tính năng này cho phân tách thần kinh của chúng tôi cho phép phân tách các chuỗi giống như trong máu mủ. Rõ ràng là hệ thống không có sự giám sát trong ngôn ngữ mục tiêu. Thay vào đó, nó là một hệ thống ngôn ngữ đa dạng được đào tạo kết thúc trên nhiều ngôn ngữ khác nhau, nên nó sẽ học một chuyên gia trích xuất có tác dụng tốt. Chúng tôi hiện thử nghiệm trên nhiều ngôn ngữ: 1) Các chức năng được tính toán từ cơ thể không sạch sẽ tăng độ chính xác phân tách. (2) Kể cả ngàn ngôn ngữ nhân tạo vào cuộc huấn luyện sẽ cải thiện thêm. (3) Mặc dù được tính toán bằng hạng không đối đẳng, những tính năng đặc biệt của chúng tôi đã vượt qua các tính chất phân loại khác nhau của công việc trước đây, cần phải phân loại bằng cách phân tích ngôn ngữ. Cách tốt nhất của chúng ta là cải tiến điểm đính kèm trên các ngôn ngữ kiểm tra đã bị bỏ dở bằng tỉ lệ năm.6 trên các công việc trước không kiểm tra các dữ liệu không bị thay đổi (McDonald et al., 207 trên các công trình từ "lỗi ngữ" mà không dùng ngôn ngữ huấn luyện (Naseem et al., 2001).</abstract_vi>
      <abstract_uz>Biz yangi tillarda davom etish uchun novel freymini ishlatimiz. Biz qanday tilning foydalanuvchi xususiyatlarini avtomatik ravishda olib tashlash mumkin, bu faqat soʻzning qismi (POS) chegaralaridan iborat. Bu xususiyatlarni neural parametrlariga olish imkoniyatlarini qo'shish mumkin. Ko'pchilik, bizning tizimmiz qanday tilda taʼminlovchi emas. Shunday qilib, bu bir necha tillar tizimi boshqa tillardan oxiriga o'rganadi, shunday qilib u yaxshi ishlaydigan imkoniyatlarni o'rganadi. Biz bir necha tillar orqali tajriba qilamiz: (1) Ҳисоб қилмайдиган композициядан ҳисобланган ҳужжатларни аниқлашдир. (2) Including thousands of synthetic languages in the training yields further improvement.  (3) Ikkinchi kompaniyadan hisoblanmagan bo'lsa, bizning o'rganish vazifa- xossalarimiz o'rganish vazifa- xossalarimiz oldingi ishni tahrirlash uchun turolog xususiyatlarini bajaradi. Bu tillarni ajratishni yoki taʼminlovchi soʻzlarning taʼminlovchiga ega boʻlishi kerak. Bizning eng yaxshi usuli qo'shilgan sinov tillarida o'zgartirilgan 5.6 foiz davomida o'zgartirdi, past ishda hech qanday qilmagan maʼlumotni tekshirilmaydi (McDonald et al., 2011), va past 20.7 nuqta bilan "grammatika ishlashni" ishlab chiqarishi mumkin (Naseem et al., 2010).</abstract_uz>
      <abstract_bg>Въвеждаме нова рамка за делексикализирано анализиране на зависимост на нов език. Показваме, че полезните характеристики на целевия език могат да бъдат извлечени автоматично от непариран корпус, който се състои само от златна част от речта (ПОС). Предоставянето на тези функции на нашия неврален анализатор му позволява да анализира последователности като тези в корпуса. Удивително е, че нашата система няма надзор на целевия език. По-скоро това е многоезична система, която е обучена от край до край на различни други езици, така че тя научава екстрактор на функции, който работи добре. Показваме експериментално на няколко езика: (1) Функциите, изчислени от непарирания корпус, подобряват точността на анализирането. (2) Включването на хиляди синтетични езици в обучението води до допълнително подобрение. (3) Въпреки че са изчислени от непарирани корпуси, нашите научени специфични за задачата функции надминават тълкуваемите типологични характеристики на предишната работа, които изискват анализирани корпуси или експертна категоризация на езика. Нашият най-добър метод подобри оценките на прикачените файлове на проведените тестови езици средно с 5,6 процентни пункта спрямо предишна работа, която не проверява непрочетените данни (McDonald et al., 2011), и с 20,7 пункта спрямо предишната работа по "граматична индукция", която не използва обучителни езици (Naseem et al., 2010).</abstract_bg>
      <abstract_hr>Predstavljamo novi okvir za analizu deleksikaliziranog zavisnosti na novom jeziku. Pokazujemo da korisne karakteristike ciljnog jezika mogu automatski izvući iz neoštećenog korpusa, koji se sastoji samo od zlatnih dijela govora (POS) sekvencija. Osiguranje tih karakteristika našem neuralnom analizatoru omogućava joj analizirati sekvence poput one u korpusu. Strašno, naš sustav nema nadzor na ciljnom jeziku. Umjesto toga, to je multijezički sustav koji je obučen na kraju do kraja na raznim drugim jezicima, tako da nauči ekstraktor karakteristike koji dobro funkcionira. Pokazujemo eksperimentalno na višestrukim jezicima: (1) Features računale iz nezapaženog korpusa poboljšavaju preciznost analize. (2) Uključujući hiljade sintetičkih jezika u obuku, dodaje daljnje poboljšanje. (3) Uprkos računalom iz nezašćenog korporacija, naša učena specifična osobina zadatka pobijedila su tipološke karakteristike prethodnog rada koje zahtijevaju analiziranu korporaciju ili kategoriju stručnjaka jezika. Naša najbolja metoda je poboljšala rezultate priključenja na testovima na prosječnim jezicima od 5,6 procentnih točka tijekom prošlog posla koji ne provjeravaju nepristojene podatke (McDonald et al., 2011) i 20,7 točka tijekom prošlog rada "gramatičke indukcije" koji ne koristi jezike obuke (Naseem et al., 2010).</abstract_hr>
      <abstract_da>Vi introducerer en ny ramme for delekskaliseret afhængighed parsing på et nyt sprog. Vi viser, at nyttige funktioner i målsproget kan udtrækkes automatisk fra et upasset korpus, som kun består af guld part-of-speech (POS) sekvenser. At give disse funktioner til vores neurale fortolker gør det muligt at analysere sekvenser som dem i korpusset. Overraskende nok har vores system ingen overvågning på målsproget. Snarere er det et flersproget system, der er trænet end-to-end på en række andre sprog, så det lærer en feature extractor, der fungerer godt. Vi viser eksperimentelt på tværs af flere sprog: (1) Funktioner beregnet fra den uparserede korpus forbedrer fortolkningsnøjagtigheden. (2) Inddragelse af tusindvis af syntetiske sprog i uddannelsen giver yderligere forbedringer. (3) På trods af at være beregnet fra uparserede korpora, vores lærte opgavespecifikke funktioner slår tidligere arbejdes fortolkelige typologiske funktioner, der kræver parsed korpora eller ekspertkategorisering af sproget. Vores bedste metode forbedrede vedhæftningsscore på udholdte testsprog med et gennemsnit på 5,6 procentpoint i forhold til tidligere arbejde, der ikke inspicerer de upresserede data (McDonald m.fl., 2011), og med 20,7 point i forhold til tidligere 'grammatisk induktion'-arbejde, der ikke bruger uddannelsessprog (Naseem m.fl., 2010).</abstract_da>
      <abstract_nl>We introduceren een nieuw framework voor delexicaliseerde afhankelijkheidsparsing in een nieuwe taal. We laten zien dat nuttige kenmerken van de doeltaal automatisch kunnen worden geëxtraheerd uit een ongeparst corpus, dat alleen bestaat uit gouden part-of-speech (POS) sequenties. Het verstrekken van deze functies aan onze neurale parser stelt het in staat om sequenties zoals die in het corpus te parsen. Opvallend is dat ons systeem geen toezicht heeft in de doeltaal. Het is eerder een meertalig systeem dat end-to-end wordt getraind op een verscheidenheid van andere talen, zodat het leert een feature extractor die goed werkt. We tonen experimenteel in meerdere talen: (1) Functies berekend uit het ongeparste corpus verbeteren de nauwkeurigheid van het parsen. (2) Het opnemen van duizenden synthetische talen in de opleiding levert verdere verbetering op. (3) Ondanks dat ze zijn berekend uit ongeparste corpora's, verslaan onze geleerd taakspecifieke functies de interpreteerbare typologische kenmerken van vorig werk die geparsed corpora of deskundige categorisering van de taal vereisen. Onze beste methode verbeterde attachment scores op uitgestelde testtalen met een gemiddelde van 5,6 procentpunten ten opzichte van vorig werk dat de niet-geparseerde gegevens niet inspecteert (McDonald et al., 2011), en met 20,7 punten ten opzichte van eerdere 'grammatica inductie' werk dat geen trainingstalen gebruikt (Naseem et al., 2010).</abstract_nl>
      <abstract_id>We introduce a novel framework for delexicalized dependency parsing in a new language.  Kami menunjukkan bahwa ciri-ciri berguna dari bahasa sasaran dapat diekstraksi secara otomatis dari corpus yang tidak terpasang, yang hanya terdiri dari urutan bagian emas dari pidato (POS). Memberikan ciri-ciri ini pada parser saraf kita memungkinkannya untuk menghindari urutan seperti yang ada di mayat. Menakjubkan, sistem kita tidak memiliki pengawasan dalam bahasa sasaran. Sebaliknya, ini adalah sistem berbagai bahasa yang dilatih dari akhir ke akhir pada berbagai bahasa lain, sehingga ia mempelajari sebuah ekstraktor fitur yang bekerja dengan baik. Kami menunjukkan secara eksperimental melalui berbagai bahasa: (1) Ciri-ciri yang dihitung dari corpus tidak terpasang meningkatkan akurasi penghuraian. (2) Termasuk ribuan bahasa sintetis dalam pelatihan memberikan perkembangan lanjut. (3) Meskipun dihitung dari corpora yang belum dipasang, ciri-ciri tugas-spesifik kita belajar mengalahkan ciri-ciri tipologi pekerjaan sebelumnya yang diperlukan corpora yang dipindai atau kategorisasi ahli bahasa. Metode terbaik kami meningkatkan skor lampiran pada bahasa tes yang ditahan dengan rata-rata 5,6 poin persentasi dari pekerjaan masa lalu yang tidak memeriksa data yang belum dipasang (McDonald et al., 2011), dan dengan 20,7 poin dari pekerjaan 'induksi grammar' yang tidak menggunakan bahasa latihan (Naseem et al., 2010).</abstract_id>
      <abstract_ko>우리는 새로운 언어에서 탈서구화 의존 해석을 하는 데 사용되는 새로운 구조를 소개했다.목표 언어의 유용한 특징은 분석되지 않은 자료 라이브러리에서 자동으로 추출할 수 있으며, 이 자료 라이브러리는 황금어성(POS) 서열만 포함한다.우리의 신경 해상도에 이러한 기능을 제공하여 어료 라이브러리의 서열을 해석할 수 있도록 한다.눈에 띄는 것은 우리 시스템에 목표 언어의 감독이 없다는 것이다.반대로 이것은 다중 언어 시스템으로 각종 다른 언어에서 처음부터 끝까지 교육을 받기 때문에 잘 작동하는 특징 추출기를 배웠다.우리는 다양한 언어 사이에서 실험 연구를 진행했다. (1) 분석되지 않은 어료 라이브러리에서 계산된 특징은 분석의 정확성을 높였다.(2) 교육에 수천 개의 합성 언어를 추가하면 더욱 개선될 수 있다.(3) 분석하지 않은 자료 라이브러리에서 계산된 것이지만 우리가 배운 특정한 임무의 특징은 이전 작업에서 자료 라이브러리나 언어 전문가가 분류해야 하는 해석 가능한 유형학적 특징을 초과했다.우리의 가장 좋은 방법은 과거 분석되지 않은 데이터를 검사하지 않았던 업무에 비해 꾸준히 시험언어에 대한 애착 점수가 평균 5.6%포인트(McDonald 등, 2011년), 과거 교육언어를 사용하지 않았던'어법 귀납'작업에 비해 20.7%포인트(Naseem 등, 2010년) 높아졌다는 것이다.</abstract_ko>
      <abstract_fa>ما یک چهارچوب جدید برای پرداخت بستگی‌های دلسکیزی به زبان جدید معرفی می‌کنیم. ما نشان می‌دهیم که ویژگی‌های مفید زبان هدف می‌تواند از یک جسد بی‌پرداخته اخراج شود، که تنها از بخشی از زبان سخنرانی (POS) است. این ویژگی‌ها را برای ویژه‌کننده‌ی عصبی‌مون اجازه می‌دهد که آن را برای ویژه‌های مانند آن‌ها در کورپوس بررسی کند. به شدت، سیستم ما در زبان هدف هیچ نظری ندارد. در عوض، این یک سیستم بسیاری زبان است که به پایان و پایان آموزش داده می‌شود به گونه زبان دیگر، بنابراین یک خارج کننده ویژگی یاد می‌گیرد که خوب کار می‌کند. ما به طور آزمایشی در زبان‌های مختلف نشان می‌دهیم: (۱) ویژه‌های محاسبه شده از جسد غیر محاسبه‌شده، دقیق تحلیل کردن را بهتر می‌کند. (2) Including thousands of synthetic languages in the training yields further improvement. (3) با وجود محاسبه شدن از شرکت غیر محاسبه شده، ویژه‌های ویژه‌ای که به کار آموخته‌ایم تعبیر قابل تفسیر کار پیشینیان می‌کنند، ویژه‌های ویژه‌شناسی کار را شکست می‌دهند که نیاز به شکل‌گیری شرکت یا ویژه‌ بهترین روش پیوند ما در زبان آزمایش‌های خارج شده به وسیله ۵.۶ درصد درصد در کارهای گذشته بهتر شد که داده‌های غیر محفوظ (McDonald et al., 2011) را بررسی نمی‌کند، و با ۲۰.۷ نقطه در کارهای گذشته‌ای که از زبان آموزش استفاده نمی‌کند (Naseem et al., 2010).</abstract_fa>
      <abstract_de>Wir stellen ein neuartiges Framework für delexikalisiertes Dependency Parsing in einer neuen Sprache vor. Wir zeigen, dass nützliche Eigenschaften der Zielsprache automatisch aus einem nicht parsierten Korpus extrahiert werden können, der nur aus goldenen Part-of-Speech (POS)-Sequenzen besteht. Die Bereitstellung dieser Funktionen für unseren neuronalen Parser ermöglicht es ihm, Sequenzen wie jene im Korpus zu analysieren. Auffällig ist, dass unser System keine Überwachung in der Zielsprache hat. Vielmehr ist es ein mehrsprachiges System, das Ende-zu-Ende auf einer Vielzahl von anderen Sprachen trainiert wird, so dass es einen Feature Extractor lernt, der gut funktioniert. Wir zeigen experimentell in mehreren Sprachen: (1) Features, die aus dem nicht parsierten Korpus berechnet werden, verbessern die Parsing-Genauigkeit. (2) Die Einbeziehung tausender synthetischer Sprachen in die Ausbildung führt zu weiteren Verbesserungen. (3) Obwohl unsere erlernten aufgabenspezifischen Funktionen aus nicht parsierten Korpora berechnet wurden, übertreffen sie die interpretierbaren typologischen Merkmale früherer Arbeiten, die geparstete Korpora oder Expertenkategorierung der Sprache erfordern. Unsere beste Methode verbesserte die Attachment-Scores für ausgebrochene Testsprachen um durchschnittlich 5,6 Prozentpunkte gegenüber früheren Arbeiten, die nicht die ungeparsten Daten überprüfen (McDonald et al., 2011), und um 20,7 Punkte gegenüber früheren 'Grammatik-Induktionsarbeiten', die keine Trainingssprachen verwenden (Naseem et al., 2010).</abstract_de>
      <abstract_sw>Tunaonyesha mfumo wa riwaya kwa ajili ya kuchimba kitendo cha kutegemea kwa lugha mpya. We show that useful features of the target language can be extracted automatically from an unparsed corpus, which consists only of gold part-of-speech (POS) sequences.  Kutoa vipengele hivi kwa mchambuzi wetu wa neura unawezesha kujenga viwango kama vile vilivyokuwa kwenye barafu. Kwa kiasi kikubwa, mfumo wetu hauna ufuatiliaji katika lugha ya lengo. Badala yake, ni mfumo wa lugha mbalimbali unaoelekezwa mwisho wa mwisho wa lugha mbalimbali, kwa hiyo inajifunza mtangazaji wa lugha inayofanya kazi vizuri. Tunaonyesha majaribio katika lugha mbalimbali: (1) Tamko zinazohesabiwa kutoka kwenye makampuni yasiyopangwa kuboresha uhakika wa wimbo huo. (2) Kujumuisha maelfu ya lugha za pamoja katika mafunzo yanaleta maboresho zaidi. (3) Pamoja na kuchukuliwa kutoka kwenye makampuni yasiyoandikwa, vipengele vyetu vya kazi maalum vilivyojifunza vilishindwa vipengele vya kawaida vya kitaalamu vinavyotafsiriwa na kinachohitaji makampuni yanayochapishwa au makundi ya wataalam wa lugha hiyo. Utawala wetu bora uliboresha vipindi vya uangalizi katika lugha zilizotengenezwa kwa wastani wa asilimia 5.6 kwa kazi zilizopita ambazo hazitachunguza taarifa zisizo za kisasa (McDonald et al., 2011), na kwa pointi 20.7 zaidi ya kipindi kilichopita 'industri ya grammani' ambacho hakitumia lugha za mafunzo (Naseem et al., 2010).</abstract_sw>
      <abstract_sq>Ne prezantojmë një kuadër të ri për analizimin e varësisë të deleksializuar në një gjuhë të re. Ne tregojmë se karakteristikat e dobishme të gjuhës objektive mund të nxirren automatikisht nga një korpus i papërshtatshëm, i cili përbëhet vetëm nga sekuenca e pjesës së artë të fjalimit (POS). Duke i dhënë këto funksione analizuesit tanë nervor e mundëson analizimin e sekuencave si ato në trup. Shumë mirë, sistemi ynë nuk ka mbikqyrje në gjuhën e objektivit. Në vend të kësaj, është një sistem shumëgjuhës që është trajnuar nga fundi në fund në një shumëllojshmëri gjuhësh të tjera, kështu që mëson një ekstraktor funksionuese që funksionon mirë. We show experimentally across multiple languages: (1) Features computed from the unparsed corpus improve parsing accuracy.  (2) Duke përfshirë mijëra gjuhë sintetike në trainim jep përmirësim të mëtejshëm. (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work's interpretable typological features that require parsed corpora or expert categorization of the language.  Metoda jonë më e mirë përmirësoi rezultatet e lidhjes në gjuhët e testimit të mbajtura me një mesatare prej 5.6 pikë përqindje mbi punën e kaluar që nuk kontrollon të dhënat e papërpunuara (McDonald et al., 2011) dhe me 20.7 pikë mbi punën e kaluar të 'induksionit gramatik' që nuk përdor gjuhët e trajnimit (Naseem et al., 2010).</abstract_sq>
      <abstract_tr>Biz iňe bir dilde döwletlendirilen baglanylyk analysiýasynyň täze bir çerýädä taýýarlapdyr. Biz bu maksady diliniň peýdaly özelliklerini awtomatik taýýarlanmadyk bir korpusdan çykaryp biljekdigini görkeýäris. Bu diňe altyn bölüminden (POS) sanlarynda bar. Bu özellikleri näyral tansiýetimiz üçin üýtgetmek üçin bu sahypalary corpusda ýaly hatlary ayırmak üçin mümkin edýär. Mümkin däldir, sistemimiziň maksadyň dilinde hiç hili namaýyş ýok. Ýöne bu multi diller bolsa so ňunda başga dillerde okuwýan bir sistemdir, bu sebäbi gowy işleýän bir çekici öwrenip biler. Biz birnäçe dilde experimental görkezip görkeýäris: (1) Bejerilmedik korpusdan hasaplanýan hasaplaryň dogrylygyny gowylaşdyrýar. (2) Okuwçylygda müňlerçe syntetik diller hem gelişmelere kömekleýär. (3) Bejerilmedik korporatdan hasaplanyşyp bilen, öwrenmiş işimiz takykly hasaplanyşynyň öňki işiň terjime edilebilir tiplojik özelliklerini döwürdi. Bu durum üçin öňki işiň terjime edilen korporatyň ýa-da uzmanlaryň kategoriýasy gerek Biziň iň gowy metodamyz çykyş dilinde çykyş edilen test dilinde ortalama 5.6 prosent nokatlary geçen işiň üstünde çykyş edilmedik data (McDonald et al., 2011) we olaryň üstünde 20.7 punktlaryň öňki 'gramatik indukýon' dilinde ulanmaýan işi (Naseem et al., 2010).</abstract_tr>
      <abstract_af>Ons introduseer 'n nuwe raamwerk vir deleksikaliseerde afhanklikheid verwerking in 'n nuwe taal. Ons wys dat gebruiklike funksies van die doel taal outomaties van 'n ongearstelde korpus kan uitpak word, wat bestaan slegs van goud deel van spraak (POS) sekwensies. Die verskaffing van hierdie funksies aan ons neural ontleerder laat dit toe om sekwensies soos dié in die korpus te verwerk. Ons stelsel het geen supervisie in die doel taal nie. Dit is eerder 'n multitaalske stelsel wat die einde-tot-einde op 'n verskillende ander tale onderrig is, sodat dit leer 'n funksie uittrekker wat goed werk. Ons vertoon eksperimenteel oor veelvuldige tale: (1) Funksies bereken van die onverwerp korpus verbeter verwerking van presisiteit. (2) Insluit duisende sintetiese tale in die oefening verder verbetering. (3) Ons geleerde taak-spesifieke eienskappe het voorheende werk se uitleggbare tipologiese eienskappe geslaan wat verwerp korpora of ekspertiese kategorisasie van die taal benodig word. Ons beste metode verbeter aanhegsel telling op gehou-uit toets tale deur 'n gemiddelde van 5.6 persentasie punte oor verlede werk wat nie inspekteer die ongeverwerde data (McDonald et al., 2011), en deur 20.7 punte oor verlede 'grammatiese induksie' werk wat nie onderwerp taal gebruik nie (Naseem et al., 2010).</abstract_af>
      <abstract_bn>আমরা নতুন ভাষায় নির্ভরশীল পার্জিং এর জন্য একটি উপন্যাসের ফ্রেম পরিচয় করিয়ে দিচ্ছি। আমরা দেখাচ্ছি যে টার্গেট ভাষার ব্যবহারের বৈশিষ্ট্য স্বয়ংক্রিয়ভাবে অপার্স কর্পাস থেকে বের করা যাবে, যার মধ্যে শুধুমাত্র সোনার অং এই বৈশিষ্ট্য আমাদের নিউরাল প্যারেজ প্রদান করার সুযোগ প্রদান করতে পারে কোর্পাসের মতো সেকেন্ড পার্স করতে। আমাদের সিস্টেম টার্গেট ভাষায় কোন পর্যবেক্ষণ নেই। বরং এটা একটি বহুভাষার সিস্টেম যা অন্যান্য ভাষায় শেষ শেষ পর্যন্ত প্রশিক্ষণ প্রদান করা হয়েছে, তাই এটা একটি বৈশিষ্ট্যাবলী এক্সট্রেক্টর আমরা বেশ কয়েকটি ভাষায় পরীক্ষা দেখাচ্ছি: (১) অপার্স কর্পাস থেকে বৈশিষ্ট্যাবলী পার্সিং সঠিকভাবে উন্নত করা হয়েছে। (২) প্রশিক্ষণে হাজার হাজার হাজার সিন্টেটিক ভাষাসহ আরো উন্নতি ঘটে। (৩) অপার্স কর্পোরা থেকে হিসেবে গণনা করা সত্ত্বেও, আমাদের শিক্ষিত কাজ-নির্দিষ্ট বৈশিষ্ট্যাবলীর বৈশিষ্ট্যাবলীক বৈশিষ্ট্যাবলীক বৈশিষ্ট্ আমাদের সবচেয়ে ভালো পদ্ধতির সংযোগ স্কোর বাড়িয়ে দিয়েছে গত কাজের মধ্যে ৫.</abstract_bn>
      <abstract_am>We introduce a novel framework for delexicalized dependency parsing in a new language.  የአካባቢው ቋንቋ የጠቃሚ ምርጫዎች ከካፈረሱ ኮርፓስ አውጥተዋል፡፡ እነዚህን ምርጫዎች ለናውሮል ተፈላጊያችን በመስጠት በቆሮፓስ ውስጥ እንደሚኖሩት ድርጊቶች ለመለይ ይችላል፡፡ በብርቱ፣ ስርዓታችን በአካባቢው ቋንቋ ምንም መጠበቅ የለውም፡፡ በተጨማሪው የቋንቋ ቋንቋዎች መጨረሻ ይታወቀዋል፡፡ በብዙ ቋንቋዎች ላይ ተፈተና እናሳየዋለን:(1) ካልተፈቀደ ካርፓስ ምርጫዎች ማኅበረሰቢያውን ማሻሻል፡፡ (2) በሺሕዎች የሚቆጠሩ የሲንተርናዊ ቋንቋዎች ሲጨምሩ እየተጨማሪው ክፍተት ነው፡፡ (3) ምንም እንኳን ካልተፈቀደ ኮርፖርት ቢሆንም፣ የተማሩት ስራ-specific ምርጫዎቻችን የቀድሞውን የሥራ ትርጉም የኮርፖርት ወይም የቋንቋውን ክፍተት የሚያስፈልገውን ትርጉም ባሕላዊ ምርጫዎች መደገፍ ነው፡፡ የበለጠ ሥርዓታችን የክፍተት ቋንቋዎች በመተካከለኛ 5.6 በመቶ ነጥቦች ባለፉት ሥራ ላይ ያልተፈቀደውን ዳታ (ማክዶናሌት አል., 2011) እና ባለፉት ‘ትምህርት ቋንቋዎች’ በማይጠቀም 20.7 ነጥቦች በ20.</abstract_am>
      <abstract_hy>Մենք ներկայացնում ենք նոր շրջանակ, որպեսզի կարողանանք վերլուծել կախվածությունը նոր լեզվով: Մենք ցույց ենք տալիս, որ նպատակային լեզվի օգտակար հատկությունները կարող են ինքնաբերաբար դուրս գալ անխմբագրված մարմնից, որը կազմված է միայն խոսքի ոսկու մասի (POS) հաջորդականություններից: Այս առանձնահատկությունները մեր նյարդային վերլուծումը հնարավորություն է տալիս վերլուծել այնպիսի հաջորդականություններ, ինչպիսիք են մարմնի մեջ գտնվող հաջորդականությունները: Հետաքրքիրն այն է, որ մեր համակարգը նպատակային լեզուն վերահսկողություն չունի: Փոխարենը, դա բազլեզու համակարգ է, որը վերջ-վերջ սովորեցված է տարբեր այլ լեզուներով, ուստի սովորում է առանձնահատկություններ վերացնող, որը լավ է աշխատում: Մենք փորձարկումներով ցույց ենք տալիս բազմաթիվ լեզուներում: (1) Առարձակված մարմնից հաշվարկվող հատկությունները բարելավում են վերլուծության ճշգրտությունը: (2) Հազարավոր սինթետիկ լեզուներ ներառելը ուսուցման մեջ ավելի լավ է առաջացնում: (3) Չնայած, որ մենք հաշվարկվում ենք անխմբագրված մարմնից, մեր սովորված խնդիրների հատուկ հատկությունները հաղթահարում են նախորդ աշխատանքի թարգմանելի տիպոլոգիական հատկությունները, որոնք պահանջում են վերլուծված մարմնի կամ լեզվի մասնագետների խմբա Մեր լավագույն մեթոդը բարելավեց հավաքածության գնահատականները հեռացված փորձարկումների լեզուների վրա անցյալ աշխատանքի ընթացքում միջինում 5.6 տոկոսով, որը չի վերահսկում անբացահայտված տվյալները (McDonald et al., 2011), և 20.7 տոկոսով անցյալ "գրամական ինդուկցիայի" աշխատանքի վրա, որը չի օգտագործում ուսուցման լե</abstract_hy>
      <abstract_cs>Představujeme nový rámec pro delexikalizovanou analýzu závislostí v novém jazyce. Ukazujeme, že užitečné vlastnosti cílového jazyka lze automaticky extrahovat z neparsovaného korpusu, který se skládá pouze ze zlatých sekvencí části řeči (POS). Poskytnutí těchto funkcí našemu neuronovému parseru umožňuje analyzovat sekvence, jako jsou ty v korpusu. Náš systém nemá žádný dohled v cílovém jazyce. Jedná se spíše o vícejazyčný systém, který je trénován od konce do konce na řadě dalších jazyků, takže se učí extraktor funkcí, který funguje dobře. Experimentálně ukazujeme napříč několika jazyky: (1) Funkce vypočítané z neparsovaného korpusu zlepšují přesnost analýzy. (2) Zahrnutí tisíců syntetických jazyků do školení přináší další zlepšení. (3) Navzdory tomu, že jsou vypočítány z neparsovaných korpusů, naše naučené funkce specifické pro úlohy porazily předchozí interpretovatelné typologické funkce, které vyžadují parsované korpusy nebo expertní kategorizaci jazyka. Naše nejlepší metoda zlepšila skóre příloh u vydržených testovacích jazyků o průměr 5,6 procentních bodů v porovnání s minulou prácí, která nekontroluje neprovrováděná data (McDonald et al., 2011), a o 20,7 bodů v porovnání s předchozí "gramatickou indukcí", která nepoužívá tréninkové jazyky (Naseem et al., 2010).</abstract_cs>
      <abstract_et>Tutvustame uue raamistiku deleksikaliseeritud sõltuvuse parsimiseks uues keeles. Näitame, et sihtkeele kasulikke omadusi saab automaatselt ekstraheerida paljundamata korpusest, mis koosneb ainult kuldsest kõneosa järjestusest (POS). Nende funktsioonide pakkumine meie närviparserile võimaldab tal parsida järjestusi nagu need korpuses. Hämmastaval kombel ei ole meie süsteemil sihtkeeles järelevalvet. Pigem on see mitmekeelne süsteem, mis on koolitatud otsast otsa paljudes teistes keeltes, nii et see õpib funktsioonide ekstraktor, mis toimib hästi. Näitame eksperimentaalselt mitmes keeles: (1) Palseldamata korpusest arvutatud funktsioonid parandavad parsimise täpsust. (2) Tuhandete sünteetiliste keelte kaasamine koolitusse parandab veelgi. (3) Vaatamata sellele, et meie õppitud ülesandespetsiifilised funktsioonid on arvutatud arvutamata korpustest, võidavad meie eelmise töö tõlgendatavad tüpoloogilised omadused, mis nõuavad parsitud korpuseid või keele ekspertlikku kategooriat. Meie parim meetod parandas manustamiskoore läbiviidud testikeeltes keskmiselt 5,6 protsendipunkti võrra varasemate töödega, mis ei kontrolli esitamata andmeid (McDonald jt., 2011), ja 20,7 protsendipunkti võrra varasemate "grammatika induktsiooni" töödega, mis ei kasuta koolituskeelt (Naseem jt., 2010).</abstract_et>
      <abstract_fi>Esittelemme uuden kehyksen deleksikalisoituun riippuvuuden jäsentämiseen uudella kielellä. Osoitamme, että kohdekielen hyödylliset ominaisuudet voidaan poimia automaattisesti käsittelemättömästä korpusesta, joka koostuu vain kultaisista puheen osa-sekvensseistä (POS). Näiden ominaisuuksien tarjoaminen neuroparserille mahdollistaa sekvenssien jäsentämisen kuten korpusessa. On hämmästyttävää, että järjestelmässämme ei ole valvontaa kohdekielellä. Pikemminkin se on monikielinen järjestelmä, joka on koulutettu päästä päähän useilla muilla kielillä, joten se oppii ominaisuuden purkaja, joka toimii hyvin. Esitämme kokeellisesti useilla kielillä: (1) Käsittelemättömästä korpusesta lasketut ominaisuudet parantavat jäsennystarkkuutta. (2) Tuhansien synteettisten kielten sisällyttäminen koulutukseen parantaa entisestään. (3) Vaikka opitut tehtäväkohtaiset ominaisuudet on laskettu kirjoittamattomista korpusista, ne voittavat aiemman työn tulkittavissa olevat typologiset ominaisuudet, jotka edellyttävät jäsenneltyä korpusta tai kielen asiantuntijaluokittelua. Paras menetelmämme paransi liitetiedostojen pisteitä koekielillä keskimäärin 5,6 prosenttiyksikköä aikaisempaan työhön verrattuna, jossa ei tarkasteta käsittelemättömiä tietoja (McDonald et al., 2011), ja 20,7 prosenttiyksikköä aikaisempaan kieliopin induktiotyöhön verrattuna, jossa ei käytetä koulutuskieliä (Naseem et al., 2010).</abstract_fi>
      <abstract_bs>Predstavljamo novi okvir za analizu deleksikaliziranog zavisnosti na novom jeziku. Pokazujemo da korisne karakteristike ciljnog jezika mogu biti automatski izvučene iz neoštećenog korpusa, koji se sastoji samo od zlatnih deo govora (POS) sekvencija. Obezbeđujući te karakteristike našem neuralnom analizatoru omogućava joj analizirati sekvence poput one u korpusu. Strašno, naš sistem nema nadzor na jeziku cilja. Umesto toga, to je multijezički sistem koji je obučen na kraju do kraja na raznim drugim jezicima, tako da nauči ekstraktor karakteristike koji dobro funkcioniše. Pokazujemo eksperimentalno na višestrukim jezicima: (1) Features računale iz neparstenog korpusa poboljšavaju preciznost analize. (2) Uključujući hiljade sintetičkih jezika u obuci, dodaje daljnje poboljšanje. (3) Uprkos računalom iz neopržene korporacije, naša naučena specifična osobina zadataka pobijedila su tipološke karakteristike prethodnog rada koje zahtijevaju analiziranu korporaciju ili kategoriju stručnjaka jezika. Naša najbolja metoda je poboljšala rezultate priključenja na testnim jezicima prosječnim od 5,6 procentnih bodova u prošlom poslu koji ne provjeravaju nepromišene podatke (McDonald et al., 2011) i za 20,7 bodova u prošlom radu "gramatična indukcija" koja ne koristi jezike obuke (Naseem et al., 2010).</abstract_bs>
      <abstract_az>Biz deleksiksikalizat bağlılıqlarını yeni dildə ayırmaq üçün yeni bir çerçive təşkil edirik. Biz məqsəd dilinin faydalı özelliklərini avtomatik olaraq çıxarıla biləcəyini göstəririk ki, bu yalnız qızıl parçası sözlərin (POS) sıralarından olub. Bu xüsusiyyətləri nöral ayırıcımıza təmin etmək corpusda olanlar kimi sequences ayırılmasını qadir edir. Əksinə, sistemimizin məqsəd dilində gözləməsi yoxdur. Əksinə, bu çoxlu dil sistemidir ki, başqa dillərdə sona-sona təhsil edilir, bu yüzden yaxşı işləyən təhsil ekstraktörü öyrənir. Biz müxtəlif dillərdə təcrübə edirik: (1) Səfərlənmiş korpusdan hesablanmış xüsusiyyətlər təcrübəsini yaxşılaşdırır. (2) Müəllimlərdə minlərlə sintetik dillər də istifadə edir. (3) Öyrənməmiş korporadan hesaplanılmasına rağmen, öyrənmiş işimiz təsirli fərqlərimiz əvvəlki işin yorumlayıcı tipolojik fərqlərini yenmişdir ki, dilin parsed corpora ya da ekspertlər kategoriyasını istəyirlər. Bizim ən yaxşı yolumuz, əvvəlki işdə 5,6 procent noktaların ortalaması ilə istifadə edilməyən məlumatları (McDonald et al., 2011), və keçmiş 'grammatik induksyon' dillərinin istifadə etməyən təhsil dillərinin istifadə edilməyən 20,7 poçtalarına görə daha yaxşılaşdı.</abstract_az>
      <abstract_ca>We introduce a novel framework for delexicalized dependency parsing in a new language.  We show that useful features of the target language can be extracted automatically from an unparsed corpus, which consists only of gold part-of-speech (POS) sequences.  Donar aquestes característiques al nostre analitzador neuronal permet analitzar seqüències com les del cos. Sorprenentment, el nostre sistema no té supervisió en el llenguatge d'objectiu. Rather, it is a multilingual system that is trained end-to-end on a variety of other languages, so it learns a feature extractor that works well.  Mostrem experimentalment a través de múltiples llengües: (1) Les característiques computades del corpus sense parar milloren la precisió de l'analisi. (2) Incloure milers de llengües sintètiques en l'entrenament produeix millors més. (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work's interpretable typological features that require parsed corpora or expert categorization of the language.  Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past 'grammar induction' work that does not use training languages (Naseem et al., 2010).</abstract_ca>
      <abstract_ha>Munã ƙara wani firam na nowaya wa parse da aka yi daidai a cikin wata harshe na daban. Tuna nũna cewa masu amfani da ke iya tafiyar da wasu fassarai na cikin harshen da aka yi amfani da shi farat ɗaya daga wata nau'in da ba'a samu'a ba, wanda ke ƙunsa da rabon zĩnãriya da mazaɓa (PS) kawai. Ga ku bãyar da wannan feature zuwa parser neural na'ura yana iya amfani da su ga parse masu mutane kamar waɗanda ke cikin nau'in. A kan yin jiyya, na'urarmu bai da wani suryau cikin harshen wanda aka yi amfani da shi ba. Kayya, shi ne wata na'urar mulki-lingui wanda aka sanar da ƙarshen dawwama a kan wasu harshe daban-daban, don haka yana karanta wani taskacin mai aiki mai kyau. Tuna nuna fara cikin wasu harshe masu yawa: (1) Tafiyati masu ƙidãya daga kornau'in da ba'a sami tsarin parse. (2) Akwai da dubu cikin harshen na haɗatiki, yana ƙara ƙari. (3) Babu da aka lissafa shi daga wata firma ba da parsed, sai masu sanar aikin-ƙayyade masu buƙata wajen wani fassarar nau'i na zaman aikin da aka fassarar da shi mai fassarwa na zaman aikin, da kuma ana buƙata katoriori masu fitarwa ga firma ko masu sani na harshen. Babu mafi kyaun hanyoyinmu ya kyautata matsayin fanikin akan harshen wanda aka yi samun ta samu da gwargwadon matsayin 5.6 points a gaba ga aikin wanda bai jarraba ba (MacDonalet al., 2011), da kuma da 20.7 points a gabani na 'kunyar aikin grammar' wanda bã ya yin amfani da shiryarwa lugha (Naseem et al., 2010).</abstract_ha>
      <abstract_sk>Predstavljamo nov okvir za deleksikalizirano razčlenitev odvisnosti v novem jeziku. Pokazali smo, da je koristne lastnosti ciljnega jezika mogoče samodejno izvleči iz nepredstavljenega korpusa, ki je sestavljen samo iz zlatega dela govora (POS). Zagotavljanje teh funkcij našemu neuralnemu razčlenjevalniku omogoča razčlenjevanje sekvenc, kot so tiste v korpusu. Naš sistem nima nadzora v ciljnem jeziku. Namesto tega gre za večjezični sistem, ki je usposobljen od konca do konca na različnih drugih jezikih, tako da se nauči izvlečevalca funkcij, ki dobro deluje. Eksperimentalno prikazujemo v več jezikih: (1) Funkcije, izračunane iz nepredvidenega korpusa, izboljšajo natančnost razčlenitve. (2) Vključitev tisoč sintetičnih jezikov v usposabljanje prinaša nadaljnje izboljšave. (3) Kljub temu, da so bile izračunane iz nepredstavljenih korpusov, naše učene funkcije, specifične za opravilo, premagajo razlagane tipološke značilnosti prejšnjega dela, ki zahtevajo razčlenjene korpuse ali strokovno kategorizacijo jezika. Naša najboljša metoda je izboljšala rezultate priključkov na preskusnih jezikih za povprečno 5,6 odstotne točke v primerjavi s preteklim delom, ki ne pregleduje nepredstavljenih podatkov (McDonald et al., 2011), in za 20,7 točke v primerjavi s preteklim delom, ki ne uporablja jezikov usposabljanja (Naseem et al., 2010).</abstract_sk>
      <abstract_jv>Awak dhéwé nggawe barang nggawe barang kanggo kelas urip nggawe gerakan karo nggawe barang anyar. Awak dhéwé éntukno angkang dipunakno kanggo kelompok banjuré iki dadi ono ora bisa nguasai perusahaan karo hal-perusahaan, sing wis nambah ora kedhalan sudah-perusahaan (po S). Iyo nggawe akeh operasi iki banget kanggo sampeyan mroler Ngerti-Ngerti, sistem awak dhéwé ora ono mulasar kanggo langgal. Digawe, bungka sistem sing alih lengkang dadi sampeyan ngono sistem sing paling-sampeyan ngono akeh langgar, dadi njukke batasang pengguna sing ngerasah bantuan. (1) Cendelah (2) Minggo akeh sing luwih akeh sinaté kanggo nggawe geraraning nggawe luwih dumadhi. (3) Gak negoro ko komputer menong depasasi karo pakem depasasi karo pakem, kita öhenter task-special songan karo hal-pakem nggawe karo perusahaan type-logik songan sing dipolete Awak dhéwé sistem sing paling nggawe gerarangke sampeyan karo perusahaan kelas telas nang 5.6 perusahaan sing paling kanggo nggawe gerangkat kuwi tindan sing ora nggawe datayang sing gak dhéwé (MekDonet al, 2011), lan uga 10.7 puntu sing sumulakno kayuté 'gram ndukèn' sing bisa uwis kuwi tindan cara nggawe (Nasem et al, 2011).</abstract_jv>
      <abstract_he>אנחנו מציגים סגרת חדשה עבור מעבדת תלויות מחולקת בשפה חדשה. אנו מראים שהתכונות שימושיות של שפת המטרה יכולות להיוציא באופן אוטומטי מקורפוס חסר חסות, אשר מורכבת רק מהרצפים של חלק זהב של הנאום (POS). הספקת המאפיינים האלה למחקר העצבי שלנו מאפשרת לו לחקור רצפים כמו אלה בגופה. באופן מוזר, למערכת שלנו אין שום פיקוח בשפה המטרה. במקום זאת, זו מערכת רבות שפות שאומנת סוף-סוף על מגוון שפות אחרות, אז היא לומדת מחלץ תכונות שעובד היטב. אנחנו מראים מבחינה ניסיונית באמצעות שפות רבות: (1) אופיינים מחשבים מהגוף הלא מוצץ משתפרים את מדויקת ההעברה. (2) כולל אלפי שפות סינתטיות באימון נותנים שיפור נוסף. (3) למרות שהם מחשבים מהגופרה הלא מפורסמת, המאפיינים המסופרים למדתם שלנו מנצחים את המאפיינים הטיפולוגיים הנפשרים של העבודה הקודמת שדורשים גופרה מפורסמת או הקטגוריזציה מומחית של השפה. Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past 'grammar induction' work that does not use training languages (Naseem et al., 2010).</abstract_he>
      <abstract_bo>ང་ཚོས་སྐད་རིགས་གསར་པ་ཞིག་གིས་བསུབ་བཤིག་བྱེད་པའི་རྟེན་འབྲེལ་རྩིས་འབྲེལ་བ་ཞིག་གསར་གཏོང་བ། ང་ཚོས་དམིགས་ཡུལ་གྱི་སྤྱོད་མཁན་གྱི་ཁྱད་ཆོས་དེ་རང་འགུལ་གྱིས་མིང་ཡོད་པའི་སྒུལ་འཛིན་ལས་རང་འགུལ་གྱིས་འཕར་འདེགས་ཐུབ་པར་བྱེ ང་ཚོའི་དཔུད་རིས་དབྱེ་སྟངས་ལ་སྤྱོད་པའི་ཁྱད་ཆོས་འདི་དག་གི་དབུགས་ཀྱི་རྣམ་པ་ལ་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད། དངོས་འབྲེལ་མ་བརྟན་ན། ང་ཚོའི་མ་ལག་ལ་དམིགས་ཡུལ་སྐད་ཀྱི་ལྟ་རྟོག་མི་འདུག Rather, it is a multilingual system that is trained end-to-end on a variety of other languages, so it learns a feature extractor that works well. ང་ཚོས་སྒེར་གྱི་སྐད་རིགས་སྣ་མང་ཙམ་མང་ཙམ་སྟོན་གྱི་ཡོད: (1) མ་ཤེས་པའི་དབུགས་རྩིས་ལས་རྩིས་ཐོག་ལས་གྲངས་ས (2) སློབ་གྲྭར་གྱི་སྐད་རིགས་སྟོང་ཕྱུར་བའི་སྐད་ཡིག་ནང་དུ་ཡར་རྒྱས་གཏོང་བཅུག་པ་ཡིན། (3) མ་ཤེས་པའི་སྒེར་གྱི་རྩིས་ལས་རྩིས་བཏོན་པ་ལས་ང་ཚོའི་ལས་འགུལ་གྱི་ཁྱད་ཆོས་གསལ་པོ་ལ་བསླབས་ཡོད་པའི་སྔོན་གྱི་ལས་འགུལ་གྱི་དབྱེ་བ་ ང་ཚོའི་ཐབས་ལམ་ལྡན་པའི་མཐུད་སྒྲིག</abstract_bo>
      </paper>
    <paper id="47">
      <title>Attentive Convolution : Equipping CNNs with RNN-style Attention Mechanisms<fixed-case>CNN</fixed-case>s with <fixed-case>RNN</fixed-case>-style Attention Mechanisms</title>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <doi>10.1162/tacl_a_00249</doi>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, convolutional neural networks (CNNs) have benefited less than recurrent neural networks (RNNs) from attention mechanisms. We hypothesize that this is because the <a href="https://en.wikipedia.org/wiki/Attention">attention</a> in CNNs has been mainly implemented as attentive pooling (i.e., it is applied to pooling) rather than as attentive convolution (i.e., it is integrated into <a href="https://en.wikipedia.org/wiki/Convolution">convolution</a>). Convolution is the differentiator of CNNs in that it can powerfully model the higher-level representation of a word by taking into account its local fixed-size context in the input text tx. In this work, we propose an attentive convolution network, ATTCONV. It extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also from information extracted from nonlocal context by the attention mechanism commonly used in RNNs. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty. Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context. In particular, attentive convolution outperforms attentive pooling and is a strong competitor to popular attentive RNNs.1</abstract>
      <pages>687–702</pages>
      <url hash="d75d8b64">Q18-1047</url>
      <bibkey>yin-schutze-2018-attentive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    <title_ar>الالتفاف اليقظ: تجهيز شبكات CNN بآليات الانتباه على غرار RNN</title_ar>
      <title_fr>Convolution attentive : équiper les CNN de mécanismes d'attention de type RNN</title_fr>
      <title_es>Convolución atenta: equipar a las CNN con mecanismos de atención al estilo de las RNN</title_es>
      <title_pt>Convolução Atenta: Equipando CNNs com Mecanismos de Atenção no estilo RNN</title_pt>
      <title_ja>注意深い畳み込み： CNNにRNNスタイルのアテンションメカニズムを装備する</title_ja>
      <title_zh>细心卷积: CNN 备 RNN 式</title_zh>
      <title_hi>चौकस Convolution: RNN के साथ CNN सुसज्जित शैली ध्यान तंत्र</title_hi>
      <title_ru>Внимательная конволюция: оснащение CNN механизмами внимания в стиле RNN</title_ru>
      <title_ga>Convolution Aireach: Meicníochtaí Airde ar nós RNN a fheistiú do CNNs</title_ga>
      <title_ka>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_ka>
      <title_el>Προσεκτική σύσπαση: Εξοπλισμός με μηχανισμούς προσοχής στυλ</title_el>
      <title_hu>Figyelmes konvolúció: a CNN-ek RNN-stílusú figyelmi mechanizmusokkal való felszerelése</title_hu>
      <title_kk>Қатысушылық құрылғы: RNN стилімен CNNs теңдеу механизмі</title_kk>
      <title_mk>Антентивна конволуција: опремување на CNN со механизми за внимание во стил RNN</title_mk>
      <title_it>Convoluzione attenta: Equipaggiare CNN con meccanismi di attenzione in stile RNN</title_it>
      <title_lt>Atkreipiamoji konvolicija: CNN įranga su RNN tipo dėmesio mechanizmais</title_lt>
      <title_ms>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_ms>
      <title_mt>Konveluzzjoni Attenziva: It-tagħmir tas-CNNs b’Mekkaniżmi ta’ Attenzjoni tal-istil RNN</title_mt>
      <title_ml>ശ്രദ്ധിക്കുന്ന കണക്ഷന്‍: RNN-ശൈലിയുമായി CNNNs എടുക്കുന്നു</title_ml>
      <title_mn>Хэрэглэгч Хэрэглэгч: RNN-хэлбэртэй CNNs-тэй тэнцвэртэй</title_mn>
      <title_no>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_no>
      <title_ro>Convoluție atentivă: Echiparea CNN-urilor cu mecanisme de atenție în stil RNN</title_ro>
      <title_pl>Uważne zawinięcie: Wyposażenie CNN w mechanizmy uwagi w stylu RNN</title_pl>
      <title_sr>Pažnja konvolucija: Equiping CNNs with RNN-style Attention Mechanisms</title_sr>
      <title_so>Attentive Convolution: Equipping CNNs with RNN-style Attention mechanisms</title_so>
      <title_si>අවධානය සම්බන්ධය: RNN-ශේලි අවධානය සමග CNNs සම්බන්ධය</title_si>
      <title_sv>UppmĂ¤rksam konvulution: Utrusta CNN med RNN-liknande uppmĂ¤rksamhetsmekanismer</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_ur>
      <title_vi>Trình độ Thuyết trình: Chuẩn bị CNN với chế độ chú ý kiểu RNN.</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Внимателна конвелуция: Оборудване на CNN с механизми за внимание в стил RNN</title_bg>
      <title_hr>Pažnja konvolucija: Equipping CNNs with RNN-style Attention Mechanisms</title_hr>
      <title_da>Attentive Convolution: Udstyre CNN'er med RNN-stil opmærksomhedsmekanismer</title_da>
      <title_nl>Aandacht Convolutie: Uitrusten van CNN's met RNN-stijl Aandacht Mechanismen</title_nl>
      <title_id>Konvelusi Perhatian: Mempersiapkan CNN dengan Mekanisme Perhatian gaya RNN</title_id>
      <title_ko>주의 볼륨: CNN을 위한 RNN식 주의 메커니즘</title_ko>
      <title_fa>توجه مواظب: تنظیم CNNs با مکانیسم توجه به طریق RNN</title_fa>
      <title_sw>Tovuti kubwa: Kutoa CNNN kwa njia ya RNN</title_sw>
      <title_tr>Dikkati Dolaşma: Equipping CNNs with RNN-style Attention Mechanisms</title_tr>
      <title_de>Aufmerksame Faltung: Ausrüstung von CNNs mit RNN-artigen Aufmerksamkeitsmechanismen</title_de>
      <title_af>Aangaande Konvolusie: Aangaande CNN met RNN-styl Aangaande Mekanisme</title_af>
      <title_sq>Konvertimi i Veprimtarit: pajisja e CNN-ve me mekanizma të vëmendjes në stil RNN</title_sq>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_hy>
      <title_az>Attentive Convolution: RNN-stili Attention Mechanisms ilə CNNs eşidilən</title_az>
      <title_ca>Convolució atentiva: Equipar CNN amb mecanismes d'atenció d'estil RNN</title_ca>
      <title_bs>Pažnja konvolucija: Equipping CNNs with RNN-style Attention Mechanisms</title_bs>
      <title_bn>প্রত্যেকটিভ কনভোলেশন: RNN-শৈল্পিক মনোযোগ মেকানিজমের সাথে সিএনএন-এর সাথে বের করা হচ্ছে</title_bn>
      <title_et>TĂ¤helepanev konvolutsioon: CNN-ide varustamine RNN-stiilis tĂ¤helepanumehhanismidega</title_et>
      <title_cs>Pozornost Convoluce: Vybavení CNN pozornostními mechanismy RNN stylu</title_cs>
      <title_fi>Tarkka konvoluatio: CNN-laitteiden varustaminen RNN-tyylisillä huomiomekanismeilla</title_fi>
      <title_jv>Attentive</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Pozorna konvolucija: opremljanje CNN-jev z mehanizmi pozornosti v slogu RNN</title_sk>
      <title_he>שינוי תשומת לב: הציוד של CNN עם מכונות תשומת לב בסגנון RNN</title_he>
      <title_bo>Attentive Convolution: Equipping CNNs with RNN-style Attention Mechanisms</title_bo>
      <abstract_ar>في البرمجة اللغوية العصبية ، استفادت الشبكات العصبية التلافيفية (CNNs) أقل من الشبكات العصبية المتكررة (RNN) من آليات الانتباه. نفترض أن هذا يرجع إلى أن الاهتمام في شبكات CNN قد تم تنفيذه بشكل أساسي كتجميع يقظ (أي أنه يتم تطبيقه على التجميع) بدلاً من الالتفاف اليقظ (أي أنه مدمج في الالتواء). يعد الالتفاف هو العامل المميز لشبكات CNN في أنه يمكنه تصميم تمثيل عالي المستوى للكلمة بقوة من خلال مراعاة سياقها المحلي ذي الحجم الثابت في نص الإدخال tx. في هذا العمل ، نقترح شبكة التفاف يقظة ، ATTCONV. إنه يوسع نطاق سياق عملية الالتفاف ، ويشتق ميزات عالية المستوى لكلمة ليس فقط من السياق المحلي ، ولكن أيضًا من المعلومات المستخرجة من السياق غير المحلي بواسطة آلية الانتباه المستخدمة بشكل شائع في الشبكات اللاسلكية الوطنية. يمكن أن يأتي هذا السياق غير المحلي (1) من أجزاء من نص الإدخال تكون بعيدة أو (2) من سياقات إضافية (أي خارجية). تُظهر التجارب على نمذجة الجملة مع السياق الصفري (تحليل المشاعر) والسياق الفردي (الاستلزام النصي) والسياق المتعدد (التحقق من المطالبة) فعالية ATTCONV في تعلم تمثيل الجملة مع دمج السياق. على وجه الخصوص ، يتفوق الالتواء اليقظ على التجميع اليقظ وهو منافس قوي لـ RNNs اليقظة الشعبية.</abstract_ar>
      <abstract_fr>En PNL, les réseaux de neurones convolutifs (CNN) ont moins bénéficié que les réseaux neuronaux récurrents (RNN) des mécanismes de l'attention. Nous émettons l'hypothèse que cela est dû au fait que l'attention dans les CNN a été principalement mise en œuvre comme une mise en commun attentive (c'est-à-dire qu'elle est appliquée à la mise en commun) plutôt que comme une convolution attentive (c'est-à-dire qu'elle est intégrée à la convolution). La convolution est le facteur de différenciation des CNN en ce qu'elle peut modéliser puissamment la représentation de niveau supérieur d'un mot en tenant compte de son contexte local de taille fixe dans le texte d'entrée tx. Dans ce travail, nous proposons un réseau de convolution attentif, ATTCONV. Il étend la portée du contexte de l'opération de convolution, en dérivant des caractéristiques de niveau supérieur pour un mot non seulement à partir du contexte local, mais également à partir d'informations extraites d'un contexte non local par le mécanisme d'attention couramment utilisé dans les RNN. Ce contexte non local peut provenir (i) de parties du texte d'entrée tx qui sont distantes ou (ii) de contextes supplémentaires (c'est-à-dire externes) ty. Des expériences de modélisation de phrases avec un contexte zéro (analyse des sentiments), un contexte unique (implication textuelle) et un contexte multiple (vérification des revendications) démontrent l'efficacité d'ATTCONV dans l'apprentissage de la représentation de phrases avec l'intégration du contexte. En particulier, la convolution attentive surpasse la mise en commun attentive et est un concurrent important des RNN attentifs populaires.1</abstract_fr>
      <abstract_es>En PNL, las redes neuronales convolucionales (CNN) se han beneficiado menos que las redes neuronales recurrentes (RNN) de los mecanismos de atención. Presumimos que esto se debe a que la atención en las CNN se ha implementado principalmente como una agrupación atenta (es decir, se aplica a la agrupación) en lugar de como una convolución atenta (es decir, se integra en la convolución). La convolución es el diferenciador de las CNN en el sentido de que puede modelar poderosamente la representación de alto nivel de una palabra teniendo en cuenta su contexto local de tamaño fijo en el texto de entrada tx. En este trabajo, proponemos una red de circunvolución atenta, ATTCONV. Amplía el alcance del contexto de la operación de convolución, derivando características de nivel superior para una palabra no solo del contexto local, sino también de la información extraída del contexto no local por el mecanismo de atención comúnmente utilizado en las RNN. Este contexto no local puede provenir (i) de partes del texto de entrada tx que están distantes o (ii) de contextos extra (es decir, externos) ty. Los experimentos sobre el modelado de oraciones con contexto cero (análisis de sentimientos), contexto único (implicación textual) y contexto múltiple (verificación de afirmaciones) demuestran la eficacia de ATTCONV en el aprendizaje de la representación de oraciones con la incorporación del contexto. En particular, la convolución atenta supera a la agrupación atenta y es un fuerte competidor de los RNN atentos populares.1</abstract_es>
      <abstract_pt>Na PNL, as redes neurais convolucionais (CNNs) se beneficiaram menos do que as redes neurais recorrentes (RNNs) dos mecanismos de atenção. Nossa hipótese é que isso ocorre porque a atenção nas CNNs foi implementada principalmente como agrupamento atento (ou seja, é aplicada ao agrupamento) em vez de convolução atenta (ou seja, é integrada à convolução). A convolução é o diferencial das CNNs, pois pode modelar poderosamente a representação de nível superior de uma palavra, levando em consideração seu contexto local de tamanho fixo no texto de entrada tx. Neste trabalho, propomos uma rede de convolução atenta, ATTCONV. Ele estende o escopo de contexto da operação de convolução, derivando recursos de alto nível para uma palavra não apenas do contexto local, mas também de informações extraídas do contexto não local pelo mecanismo de atenção comumente usado em RNNs. Esse contexto não local pode vir (i) de partes do texto de entrada tx que estão distantes ou (ii) de contextos extras (ou seja, externos) ty. Experimentos de modelagem de sentenças com contexto zero (análise de sentimento), contexto único (encaixe textual) e contexto múltiplo (verificação de alegações) demonstram a eficácia do ATTCONV no aprendizado de representação de sentenças com a incorporação de contexto. Em particular, a convolução atenta supera o agrupamento atento e é um forte concorrente das RNNs atentas populares.1</abstract_pt>
      <abstract_ja>ＮＬＰでは、畳み込みニューラルネットワーク（ ＣＮＮ ）は、注意メカニズムからの再発ニューラルネットワーク（ ＲＮＮ ）よりも恩恵が少ない。 これは、CNNにおける注目が、注意深い畳み込み（すなわち、畳み込みに統合される）ではなく、注意深いプーリング（すなわち、プーリングに適用される）として主に実装されているためであると仮定する。 畳み込みは、入力テキストtxのローカル固定サイズコンテキストを考慮することによって、単語のより高いレベルの表現を強力にモデル化できるという点で、CNNの差別化要因である。 本作では、注意深い畳み込みネットワーク「ATTCONV」を提案します。 これは、畳み込み演算のコンテキスト範囲を拡張し、ローカルコンテキストだけでなく、RNNで一般的に使用される注意メカニズムによって非ローカルコンテキストから抽出された情報から、単語のより高レベルの特徴を導き出す。 この非ローカルコンテキストは、（ ｉ ）遠くにある入力テキストｔ ｘの一部から、または（ ｉ ｉ ）余分な（すなわち、外部の）コンテキストｔ ｙから来ることができる。 ゼロコンテキスト（センチメント分析）、シングルコンテキスト（テキストエンタテインメント）、マルチコンテキスト（クレーム検証）を用いた文章モデリングの実験は、コンテキストを取り入れた文章表現学習におけるATTCONVの有効性を示している。 特に、注意深い畳み込みは注意深いプーリングを上回り、人気のある注意深いRNNの強力な競合相手です。1</abstract_ja>
      <abstract_zh>NLP之中,卷积神经网络(CNN)益数少于递归神经网络(RNN)。 设以 CNN 意为主(即为集池,其用于池),不为细心卷积(即集成卷积中)。 卷积者, CNN 之别也,以其可以输文 tx 虑其本地定大小之上下文,有力于单词之高级建模。 于此等事,细心之卷积网络ATTCONV。 其广卷积操之上下文,不特从局上下文,又于RNNs中常用意机从非局上下文中提取信息,为单词派更高层次之征。 此非本地上下文可以(i)自输tx中距离远者,或(ii)自额外者(外)上下文。 零上下文(情析)、单上下文(文本蕴涵)、多上下文(声明验)之句建模实验验ATTCONV合上下文之有效性。 细心卷积优于专心池,流行 RNN 之强竞争对手。</abstract_zh>
      <abstract_hi>एनएलपी में, convolutional तंत्रिका नेटवर्क (CNN) ने ध्यान तंत्र से आवर्तक तंत्रिका नेटवर्क (RNNs) की तुलना में कम लाभ उठाया है। हम परिकल्पना करते हैं कि ऐसा इसलिए है क्योंकि CNN में ध्यान मुख्य रूप से चौकस पूलिंग के रूप में लागू किया गया है (यानी, यह पूलिंग पर लागू होता है) बजाय चौकस कनवल्शन के रूप में (यानी, यह कनवल्शन में एकीकृत है)। Convolution CNN का विभेदक है जिसमें यह इनपुट टेक्स्ट tx में अपने स्थानीय निश्चित आकार के संदर्भ को ध्यान में रखते हुए किसी शब्द के उच्च-स्तरीय प्रतिनिधित्व को शक्तिशाली रूप से मॉडल कर सकता है। इस काम में, हम एक चौकस कनवल्शन नेटवर्क, ATTCONV का प्रस्ताव करते हैं। यह कनवल्शन ऑपरेशन के संदर्भ दायरे का विस्तार करता है, न केवल स्थानीय संदर्भ से एक शब्द के लिए उच्च-स्तरीय सुविधाओं को प्राप्त करता है, बल्कि आमतौर पर RNNs में उपयोग किए जाने वाले ध्यान तंत्र द्वारा गैर-स्थानीय संदर्भ से निकाली गई जानकारी से भी प्राप्त करता है। यह nonlocal संदर्भ (i) इनपुट टेक्स्ट tx के कुछ हिस्सों से आ सकता है जो दूर हैं या (ii) अतिरिक्त (यानी, बाहरी) संदर्भों से ty हैं। शून्य-संदर्भ (भावना विश्लेषण), एकल-संदर्भ (पाठ्य अनिवार्यता) और एकाधिक-संदर्भ (दावा सत्यापन) के साथ वाक्य मॉडलिंग पर प्रयोग संदर्भ के निगमन के साथ वाक्य प्रतिनिधित्व सीखने में ATTCONV की प्रभावशीलता को प्रदर्शित करते हैं। विशेष रूप से, चौकस convolution चौकस पूलिंग outperforms और लोकप्रिय चौकस RNNs.1 के लिए एक मजबूत प्रतियोगी है</abstract_hi>
      <abstract_ru>В NLP сверточные нейронные сети (CNN) получили меньшую пользу, чем рекуррентные нейронные сети (RNN) от механизмов внимания. Мы предполагаем, что это связано с тем, что внимание в CNN было реализовано главным образом как внимательное объединение (то есть, оно применяется к объединению), а не как внимательная свертка (то есть, оно интегрировано в свертку). Свертка является отличительной особенностью CNN в том, что она может мощно моделировать представление слова на более высоком уровне, принимая во внимание его локальный фиксированный размер контекста во входном тексте tx. В этой работе мы предлагаем внимательную сеть свертки, ATTCONV. Он расширяет контекстный охват операции свертки, получая признаки более высокого уровня для слова не только из локального контекста, но и из информации, извлеченной из нелокального контекста с помощью механизма внимания, обычно используемого в RNN. Этот нелокальный контекст может исходить (i) от частей входного текста tx, которые удалены, или (ii) от дополнительных (т.е. внешних) контекстов ty. Эксперименты по моделированию предложений с нулевым контекстом (анализ настроений), одноконтекстным (текстовое влечение) и многоконтекстным (проверка утверждений) демонстрируют эффективность ATTCONV в обучении представлению предложений с учетом контекста. В частности, внимательная свертка превосходит внимательное объединение и является сильным конкурентом популярным внимательным RNN. 1</abstract_ru>
      <abstract_ga>I NLP, is lú an leas a bhain líonraí néaracha comhraonta (CNNanna) ná líonraí néaracha athfhillteacha (RNNanna) as meicníochtaí aire. Tugaimid hipitéis gurb é seo an fáth go bhfuil an aird i CNNanna curtha i bhfeidhm go príomha mar chomhthiomsú aireach (i.e. cuirtear i bhfeidhm é ar chomhthiomsú) seachas mar choinbhleacht aireach (i.e. tá sé lánpháirtithe sa convolution). Is é convolution an difreálaí CNNanna sa mhéid is gur féidir leis léiriú cumhachtach ar fhocal ardleibhéil a shamhaltú trína chomhthéacs áitiúil de mhéid seasta a chur san áireamh sa téacs ionchur tx. San obair seo, molaimid gréasán coinbhleachtaí aireach, ATCONV. Síneann sé raon feidhme comhthéacs na hoibríochta conbhlóide, ag díorthú gnéithe ardleibhéil d’fhocal ní hamháin ón gcomhthéacs áitiúil, ach freisin ó fhaisnéis a bhaintear as comhthéacs neamháitiúil leis an meicníocht aire a úsáidtear go coitianta sna RNNanna. Féadfaidh an comhthéacs neamháitiúil seo teacht (i) ó chodanna den téacs ionchuir tx atá i bhfad i gcéin nó (ii) ó chomhthéacsanna breise (i.e. seachtracha). Léiríonn turgnaimh ar shamhaltú abairtí le comhthéacs nialasach (anailís sentiment), comhthéacs singil (entualent entualment) agus il-chomhthéacs (fíorú éilimh) éifeachtacht ATCONV i bhfoghlaim léiriú abairtí agus comhthéacs a ionchorprú. Go háirithe, is fearr an comhthiomsú aireach ná an comhthiomsú aireach agus is iomaitheoir láidir é in aghaidh RNNanna aireacha a bhfuil an-tóir orthu.1</abstract_ga>
      <abstract_el>Στο ΝΛΠ, τα σύνθετα νευρωνικά δίκτυα (CNN) έχουν ωφεληθεί λιγότερο από τα επαναλαμβανόμενα νευρωνικά δίκτυα (RNN) από τους μηχανισμούς προσοχής. Υποθέτουμε ότι αυτό οφείλεται στο γεγονός ότι η προσοχή στα CNN έχει εφαρμοστεί κυρίως ως προσεκτική ομαδοποίηση (δηλαδή εφαρμόζεται στην ομαδοποίηση) και όχι ως προσεκτική σύγχυση (δηλαδή ενσωματώνεται σε σύγχυση). Η Σύγκλιση είναι ο διαφοροποιητής των στο ότι μπορεί να μοντελοποιήσει δυναμικά την ανώτερο επίπεδο αναπαράστασης μιας λέξης λαμβάνοντας υπόψη το τοπικό πλαίσιο σταθερού μεγέθους στο κείμενο εισαγωγής Στην παρούσα εργασία προτείνουμε ένα προσεκτικό δίκτυο Σύγκλισης, το ΑΤΚΟΝV. Επεκτείνει το πεδίο πλαισίου της λειτουργίας σύγχυσης, αντλώντας χαρακτηριστικά ανώτερου επιπέδου για μια λέξη όχι μόνο από το τοπικό πλαίσιο, αλλά και από πληροφορίες που εξάγονται από το μη τοπικό πλαίσιο από τον μηχανισμό προσοχής που χρησιμοποιείται συνήθως στα RNN. Αυτό το μη τοπικό πλαίσιο μπορεί να προέρχεται (i) από μέρη του κειμένου εισαγωγής tx που είναι μακρινά ή (ii) από πρόσθετα (δηλαδή εξωτερικά) πλαίσια ty. Τα πειράματα μοντελοποίησης προτάσεων με μηδενικό-πλαίσιο (ανάλυση συναισθημάτων), ενιαίο-πλαίσιο (περιεχόμενο κειμένου) και πολλαπλό-πλαίσιο (επαλήθευση αξιώσεων) καταδεικνύουν την αποτελεσματικότητα του στην εκμάθηση αναπαράστασης προτάσεων με την ενσωμάτωση του πλαισίου. Ειδικότερα, η προσεκτική σύγχυση ξεπερνά την προσεκτική συγκέντρωση και είναι ένας ισχυρός ανταγωνιστής των δημοφιλών προσεκτικών RNN. 1</abstract_el>
      <abstract_ka>Name ჩვენ ვფიქრობთ, რომ ეს იქნება, რადგან CNNs-ში აღმოჩენა მნიშვნელოვანი, როგორც აღმოჩენებული აღმოჩენება (ანუ, ეს აღმოჩენა ყველაზე) მაგრამ აღმოჩენებული აღმოჩენებული აღმოჩენება (ანუ, ეს კონტროლუ კონტულუცია არის CNN-ის განსხვავებელი, რომელიც შეუძლია ძალიან მოდელურად მოდელურად აღმოჩენოთ სიტყვას, რომელიც მისი ლოკალური განსხვავებული ზომის კონტექსტის შესახებ ტექსტი tx-ში. ამ სამუშაოში ჩვენ მინდომა ეს კონფექტურაციის მოქმედების კონტექსტური სკონტექტის სკონტექტის სკონტექტი, რომელიც მხოლოდ ლოკალური კონტექსტურის სიტყვებისთვის უფრო მეტი სიტყვებისთვის, მაგრამ ეს არ არის ლოკალური კონტექსტი შეიძლება i) შეიძლება შეიძლება გადატანა ტექსტის ნაწილადან tx, რომელიც განმავლობაში ან ii) განმავლობაში (მაგალითად, გარეშე) კონტექსტის გამოცდილება სიტყვების მოდელის ნულ-კონტექსტის (სიტყვების ანალიზაცია), ერთი-კონტექსტის (ტექსტური შესაძლებლობა) და მრავალ-კონტექსტის (სიტყვების შესაძლებლობა) გამოცდილობა ATTCONV- განსაკუთრებულად, აღმოჩენებული კონტულუცია უფრო მნიშვნელოვანია და უფრო ძალიან კონტუნტერია პოლიპური აღმოჩენებული RNN. 1</abstract_ka>
      <abstract_hu>Az NLP-ben a konvulu찼ci처s neur찼lis h찼l처zatok (CNN) kevesebb hasznot ny첬jtottak a figyelemmechanizmusokb처l, mint a visszat챕r흷 neur찼lis h찼l처zatok (RNN). Felt챕telezz체k, hogy ez az챕rt t철rt챕nik, mert a figyelmet a CNN-ekben els흷sorban figyelmes pooling (azaz pooling) form찼j찼ban val처s챠tj찼k meg, nem pedig figyelmes konvol첬ci처k챕nt (azaz konvol첬ci처ba integr찼l처dik). A konvol첬ci처 a CNN-ek megk체l철nb철ztet흷je abban, hogy er흷teljesen modellezheti egy sz처 magasabb szint킥 찼br찼zol찼s찼t, figyelembe v챕ve annak helyi fix m챕ret킥 kontextus찼t a tx beviteli sz철vegben. Ebben a munk찼ban egy figyelmes konvol첬ci처s h찼l처zatot, az ATTCONV-t javasoljuk. Kiterjeszti a konvolu찼ci처s m킥velet kontextus hat처k철r챕t, egy sz처 magasabb szint킥 jellemz흷it nemcsak a helyi kontextusb처l, hanem a nem helyi kontextusb처l nyert inform찼ci처kb처l is, amelyeket az RNN-ekben 찼ltal찼ban haszn찼lt figyelemmel k챠s챕r흷 mechanizmus haszn찼l. Ez a nem helyi kontextus (i) a tx beviteli sz철veg t찼voli r챕szeib흷l vagy (ii) extra (azaz k체ls흷) kontextusokb처l sz찼rmazhat. A z챕r처 kontextus (챕rzelmek elemz챕se), egy kontextus (sz철veges vonatkoz찼s) 챕s t철bb kontextus (찼ll챠t찼s ellen흷rz챕se) alkalmaz찼s찼val v챕gzett mondatmodellez챕si k챠s챕rletek bizony챠tj찼k az ATTCONV hat챕konys찼g찼t a kontextus be챕p챠t챕s챕vel kapcsolatban. K체l철n철sen a figyelmes konvol첬ci처 fel체lm첬lja a figyelmes pooling-t, 챕s er흷s versenyt찼rsa a n챕pszer킥 figyelmes RNN-eknek. 1</abstract_hu>
      <abstract_it>Nel PNL, le reti neurali convoluzionali (CNN) hanno beneficiato meno delle reti neurali ricorrenti (RNN) dai meccanismi di attenzione. Ipotizziamo che ciò sia dovuto al fatto che l'attenzione nelle CNN è stata principalmente implementata come attenta pooling (cioè applicata al pooling) piuttosto che come attenta convoluzione (cioè integrata nella convoluzione). La convoluzione è la differenziazione delle CNN in quanto può modellare con forza la rappresentazione di livello superiore di una parola tenendo conto del suo contesto locale a dimensione fissa nel testo di input tx. In questo lavoro, proponiamo una rete di convoluzione attenta, ATTCONV. Estende l'ambito contestuale dell'operazione di convoluzione, derivando caratteristiche di livello superiore per una parola non solo dal contesto locale, ma anche da informazioni estratte dal contesto non locale dal meccanismo di attenzione comunemente usato negli RNN. Questo contesto non locale può provenire (i) da parti del testo di input tx distanti o (ii) da contesti extra (cioè esterni) ty. Esperimenti sulla modellazione di frasi con contesto zero (analisi sentiment), contesto singolo (implicazione testuale) e contesto multiplo (verifica claim) dimostrano l'efficacia di ATTCONV nell'apprendimento della rappresentazione delle frasi con l'incorporazione del contesto. In particolare, la convoluzione attenta supera l'attento pooling ed è un forte concorrente di RNN attenti popolari. 1</abstract_it>
      <abstract_kk>NLP- де, конверсиялық невралдық желі (CNNs) қайталанатын невралдық желі (RNNs) механизмінен қайталанатын невралдық желілерден (қайталанатын) ашықтарды. Біз бұл сияқты таңдаймыз, себебі CNNs-тың тәртіпсіздігі негізінде тәртіпсіздік сәйкестігі (т.е. бұл сәйкестік сәйкестігіне қолданылатын) қызметтік сәйкестігі (т.е. бұл сәйкест Бұл жұмыс ішінде, ATTCONV деген тізімінің жергілікті жиі өлшемі контексті есептеп, сөздің жоғары деңгейін үлгілеу үшін CNN дифференциясы болады. Бұл қисық операциясының контексті масштабын кеңейту үшін, сөзді тек жергілікті контекстінен емес, сонымен қатар жергілікті контексті емес контекстінен, RNN механизмінде көбірек қолданылатын қызықтық механизмін Бұл жергілікті контекст (i) келтірілген tx мәтіннің бөлшектерінен не (ii) қосымша (яғни сыртқы) контекстерден келтіре алады. Сөздерді нөл контексті (сезімдік анализ), жалғыз контексті (мәтіндік) және бірнеше контексті (мәтіндік тексеру) тәртібі ATTCONV мәтіндіктерінің әсерілігін көрсетеді. Әрине, тәртіпсіздік құрылғы тәртіпсіздік тәртіпсіздік сәйкестігін жасайды. Бұл әлемдік тәртіпсіздік RNN-ге күшті тәртіпсіз. 1</abstract_kk>
      <abstract_ml>NLP-ല്‍ കുറ്റപ്പെട്ട ന്യൂറല്‍ ശൃംഖലങ്ങള്‍ (CNNNs) ആവര്‍ത്തിച്ചുകൊണ്ടിരിക്കുന്ന ന്യൂറല്‍ ശൃംഖലങ്ങളില്‍ നിന്നും കുറച്ച് ഉപ സിഎന്‍എന്‍സിലെ ശ്രദ്ധ പ്രവര്‍ത്തിക്കപ്പെട്ടിരിക്കുന്നത് പ്രധാനപ്പെട്ടിരിക്കുന്നു (അത് പൂലിങ്ങിന് പ്രയോഗിക്കപ്പെട്ടിരിക്കുന്നു) അതിനെക്ക വാക്കിന്റെ ഉയരത്തിന്റെ പ്രതിനിധിയിലെ വേര്‍തിരിച്ചറിയുന്നതിനാല്‍ അതിന്റെ പ്രാദേശ്യ-വലിപ്പം എണ്ണിപ്പൂട്ട് ടെക്സ്റ്റ് ടെക്സ്റ്റ് ടിക്സിലെ സ്ഥിരമ പ്രാദേശികമായ ഒരു വാക്ക് മാത്രമല്ല, പ്രാദേശികമായി ഉപയോഗിക്കുന്ന വിവരങ്ങളില്‍ നിന്നും പുറത്തെടുക്കുന്ന വിവരങ്ങളില്‍ നിന്നും സ്ഥാനമില്ലാത ഈ ലോക്കല്‍ കോണ്‍ട്ടെക്സ്റ്റോള്‍ അല്ലെങ്കില്‍ ദൂരെയുള്ള ഇന്‍പുട്ട് ടിക്സിന്റെ പദാവലിയുടെ ഭാഗങ്ങളില്‍ നിന്നും (i) വരാന്‍ സാധ Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context.  പ്രത്യേകിച്ച്, ശ്രദ്ധിക്കുന്ന കുഴപ്പത്തിന്റെ പ്രധാനപ്പെട്ട പൂലിങ്ങ് പ്രവര്‍ത്തിപ്പിക്കുന്നു. പ്രധാനപ് 1</abstract_ml>
      <abstract_mk>Во НЛП, конволуционалните нервни мрежи (ЦНН) имаат помалку корист од рецидентните нервни мрежи (РНН) од механизмите на внимание. We hypothesize that this is because the attention in CNNs has been mainly implemented as attentive pooling (i.e., it is applied to pooling) rather than as attentive convolution (i.e., it is integrated into convolution).  Конволуцијата е диференцијаторот на CNN во тоа што може моделирање на високо ниво на претставување на збор со земање во предвид на својот локален контекст со фиксна големина во вводниот текст tx. Во оваа работа, предложуваме внимателна конволуциска мрежа, ATTCONV. Истиот го проширува контекстниот објект на конволуционата операција, изведувајќи карактеристики на повисоко ниво за збор не само од локален контекст, туку и од информациите извадени од нелокален контекст од механизмот на внимание кој често се користи во РНН. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty.  Експериментите за моделирање на речениците со нула-контекст (анализа на чувствата), едно-контекст (текстуално вмешање) и повеќе-контекст (верификација на тврдеоето) ја демонстрираат ефикасноста на АТТЦОНВ во учењето на претставуваоето на речениците со вклучува Посебно, внимателната конволуција го надминува внимателното спојување и е силен конкурент на популарните внимателни РНН. 1</abstract_mk>
      <abstract_lt>NLP konvoliucinių nervų tinklų (CNN) dėmesio mechanizmai gavo mažiau naudos nei pasikartojančių nervų tinklų (RNN). Mes darome prielaidą, kad tai dėl to, kad dėmesys CNN daugiausia buvo skiriamas kaip atidus susijungimas (t. y. jis taikomas susijungimui), o ne kaip atidus susijungimas (t. y. jis integruotas į susijungimą). Konveliacija yra CNN diferenciatorius, nes ji gali stipriai modeliuoti aukštesnio lygio žodžio atstovavimą, atsižvelgdama į jo vietinį fiksuoto dydžio kontekstą įvesties tekste tx. Šiame darbe siūlome atidžiai konvliacijos tinklą, ATTCONV. Ji išplečia konvoliucijos operacijos konteksto taikymo sritį, nustatant aukštesnio lygio savybes žodžiui ne tik iš vietos konteksto, bet ir iš informacijos, gautos iš ne vietos konteksto pagal dėmesio mechanizmą, dažnai naudojamą RNR. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty.  Nuorodų modeliavimo su nuliniu kontekstu (jausmų analizė), vienu kontekstu (tekstinis įtraukimas) ir daugeliu kontekstų (reikalavimo patikra) eksperimentai rodo ATTCONV veiksmingumą mokymosi apie sakinių atstovavimą, įtraukiant kontekstą. Ypač daug dėmesio skiriama konvoliucijai, o tai yra aktyvus populiarių dėmesio skiriančių RNN konkurentas. 1</abstract_lt>
      <abstract_ms>Dalam NLP, rangkaian saraf konvolusi (CNN) telah menguntungkan kurang daripada rangkaian saraf berulang (RNN) dari mekanisme perhatian. Kami hipotesis bahawa in i kerana perhatian di CNN telah terutama dilaksanakan sebagai pengumpulan perhatian (i.e., ia dilaksanakan untuk pengumpulan) daripada sebagai konvolusi perhatian (i.e., ia terlibat dalam konvolusi). Convolution adalah pembezaan CNN dalam bahawa ia boleh dengan kuasa model perwakilan aras-tinggi perkataan dengan mempertimbangkan konteks saiz-tetap setempatnya dalam teks input tx. Dalam kerja ini, kami cadangkan rangkaian konvolution perhatian, ATTCONV. Ia memperluas skop konteks operasi konvolusi, menghasilkan ciri-ciri aras-tinggi untuk perkataan bukan sahaja dari konteks setempat, tetapi juga dari maklumat yang diekstrak dari konteks bukan setempat oleh mekanisme perhatian yang biasanya digunakan dalam RNN. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty.  Eksperimen mengenai pemodelan kalimat dengan konteks-sifar (analisis perasaan), konteks-tunggal (penyelesaian teks) dan konteks-berbilang (pengesahan tuntutan) menunjukkan efektivitas ATTCONV dalam pembelajaran mewakili kalimat dengan penyelesaian konteks. Terutama, pertumbuhan perhatian melebihi pengumpulan perhatian dan adalah seorang pesaing kuat untuk RNN perhatian populer. 1</abstract_ms>
      <abstract_mn>NLP-д сэтгэл санааны мэдрэлийн сүлжээнд (CNNs) анхаарлын механизмээс дахин дахин дахин сэтгэл мэдрэлийн сүлжээнээс бага ашигтай. Бид үүнийг анхаарлын төвлөрөмж төсөөлж байгаа учир нь ДНХ-ын анхаарлын төвлөрөмж нь анхаарлын төвлөрөмж (жишээ нь, үүнийг цуглуулахад хэрэглэгддэг) анхаарлын төвлөрөмж (жишээ нь, үүнийг цуглуулахад холбогдож байгаа юм). Энэ ажлын тухай бид анхаарлын хөгжлийн сүлжээ, ATTCONV-г анхаарлаа хандуулж чадна. Энэ нь зөвхөн орон нутгийн нөхцөлд биш, мөн орон нутгийн нөхцөлд нь анхаарлын механизм ашигладаг мэдээллээс гадна орон нутгийн нөхцөлд гарч ирсэн юм. Энэ газрын орчин нутгийн байдлаас (i) хол эсвэл (ii) нэмэлт (гадаад) байдлаас гарч ирж болно. Зөл-нөхцөл (мэдрэмж шинжилгээ), ганц-нөхцөл (текстур) болон олон-нөхцөл (хүлээн зөвшөөрөл) байдлын туршилт нь өгүүлбэр суралцах суралцаанд ATTCONV-ын үр дүнг харуулдаг. Ялангуяа, сэтгэл хөдлөл сэтгэл хөдлөл нь сэтгэл хөдлөл, сэтгэл хөдлөл сэтгэл хөдлөлтэй НХ-д хүчтэй өрсөлдөгч юм. 1</abstract_mn>
      <abstract_mt>Fl-NLP, in-netwerks newrali konvoluzzjonali (CNNs) ibbenefikaw inqas minn netwerks newrali rikorrenti (RNNs) minn mekkaniżmi ta’ attenzjoni. Aħna niipotesizzaw li dan huwa minħabba li l-attenzjoni fis-CNNs ġiet implimentata prinċipalment bħala ġbir flimkien attent (jiġifieri, hija applikata għall-ġbir flimkien) aktar milli bħala konvoluzzjoni attenta (jiġifieri, hija integrata fil-konvoluzzjoni). Il-konvoluzzjoni hija d-differenzjatur tas-CNNs peress li tista’ timmudella b’mod qawwi r-rappreżentazzjoni ta’ livell ogħla ta’ kelma billi tqis il-kuntest lokali tagħha ta’ daqs fiss fit-test ta’ input tx. F’dan ix-xogħol, nipproponu netwerk ta’ konvoluzzjoni attent, ATTCONV. Dan jestendi l-ambitu tal-kuntest tal-operazzjoni ta’ konvoluzzjoni, u joħloq karatteristiċi ta’ livell ogħla għal kelma mhux biss mill-kuntest lokali, iżda wkoll minn informazzjoni estratta minn kuntest mhux lokali mill-mekkaniżmu ta’ attenzjoni użat b’mod komuni fl-RNNs. Dan il-kuntest mhux lokali jista’ (i) jiġi minn partijiet tat-test ta’ input tx li huma distanti jew (ii) minn kuntesti ekstra (jiġifieri, esterni). L-esperimenti dwar l-immudellar tas-sentenzi b’kuntest żero (analiżi tas-sentimenti), kuntest uniku (involviment testwali) u kuntest multiplu (verifika tal-pretensjoni) juru l-effettività tal-ATTCONV fit-tagħlim tar-rappreżentazzjoni tas-sentenzi bl-inkorporazzjoni tal-kuntest. B’mod partikolari, konvoluzzjoni attenta tirriżulta minn pooling attent u hija kompetitur qawwi għal RNNs attenti popolari. 1</abstract_mt>
      <abstract_no>I NLP har konvolusjonelle nøyralnettverk (CNNs) brukt mindre enn rekurserande nøyralnettverk (RNN) frå oppmerkingsmekanismar. Vi hypotiserer at dette er fordi oppmerksomheten i CNN er hovudsakelig implementert som oppmerksomhet (t.d. det vert brukt til pooling) i staden for å gjere oppmerksomhet (t.d. det er integrert i konvolusjon). Konvolusjon er forskjelleren av CNN i at den kan styrke modellere den høgare nivårepresentasjonen av eit ord ved å ta inn i konteksten sitt lokale fast storleik i inndatateksten tx. I denne arbeidet foreslår vi ein attferdig konvolusjonsnettverk ATTCONV. Det utvidar kontekstområdet for konvolusjonsoperasjonen, og avhentar høgare nivåfunksjonar for eit ord ikkje berre frå lokalt kontekst, men også frå informasjonen utpakka frå ikkje lokalt kontekst av oppmerksmekanismen som ofte brukar i RNN. Denne ikkje-lokale konteksten kan komme i) frå deler av inndatateksten tx som er distant eller ii) frå ekstra (t.d. eksterne) kontekst- tyd. Eksperimentar om setningsmoduling med null-kontekst (sentimentanalyse), enkelkontekst (tekstinnholding) og fleire kontekst (etterskyving) viser effektiviteten av ATTCONV i setningsskyving med inkorporasjonen av kontekst. Spesielt er attentive konvolusjon utfører attentive samlingar og er ein sterk konkurent til populære attentive RNN. 1</abstract_no>
      <abstract_ro>În PNL, rețelele neuronale convoluționale (CNN) au beneficiat mai puțin decât rețelele neuronale recurente (RNN) de mecanismele de atenție. Ipotezăm că acest lucru se datorează faptului că atenția în CNN a fost implementată în principal ca pooling atent (adică este aplicată la pooling) mai degrabă decât ca convoluție atentă (adică este integrată în convoluție). Convoluția este diferențiatorul CNN prin faptul că poate modela puternic reprezentarea la nivel superior a unui cuvânt luând în considerare contextul local de dimensiuni fixe în textul de intrare tx. În această lucrare, propunem o rețea atentă de convoluție, ATTCONV. Acesta extinde domeniul de aplicare al contextului operațiunii de convoluție, derivând caracteristici de nivel superior pentru un cuvânt nu numai din contextul local, ci și din informații extrase din context nonlocal prin mecanismul de atenție utilizat în mod obișnuit în RNN. Acest context nonlocal poate veni (i) din părți ale textului de intrare tx care sunt îndepărtate sau (ii) din contexte extra (adică externe) ty. Experimentele de modelare a propozițiilor cu context zero (analiza sentimentului), context unic (implicare textuală) și context multiplu (verificarea revendicării) demonstrează eficacitatea ATTCONV în învățarea reprezentării propozițiilor cu încorporarea contextului. În special, convoluția atentă depășește pooling atent și este un concurent puternic pentru RNN-urile atente populare. 1</abstract_ro>
      <abstract_pl>W NLP konwolucyjne sieci neuronowe (CNN) korzystały mniej niż powtarzające się sieci neuronowe (RNN) z mechanizmów uwagi. Zakładamy hipotezę, że dzieje się tak dlatego, że uwaga w CNN została realizowana głównie jako uważne pooling (tj. stosuje się do pooling) a nie jako uważne zawinięcie (tj. jest zintegrowane z konwolucją). Konwolucja jest różnicownikiem CNN, ponieważ potrafi silnie modelować wyższy poziom reprezentacji słowa, uwzględniając jego lokalny kontekst o stałej wielkości w tekście wejściowym tx. W niniejszej pracy proponujemy uważną sieć konwolucyjną ATTCONV. Rozszerza zakres kontekstu operacji konwolucji, pobierając cechy wyższego poziomu dla słowa nie tylko z kontekstu lokalnego, ale także z informacji wydobytych z kontekstu nielokalnego za pomocą mechanizmu uwagi powszechnie stosowanego w RNN. Ten nielokalny kontekst może pochodzić (i) z części tekstu wejściowego tx, które są odległe lub (ii) z dodatkowych (tj. zewnętrznych) kontekstów ty. Eksperymenty na modelowaniu zdań z zerowym kontekstem (analiza sentymentów), pojedynczym kontekstem (zawieranie tekstu) i wielokontekstem (weryfikacja roszczeń) pokazują skuteczność ATTCONV w uczeniu się reprezentacji zdań z uwzględnieniem kontekstu. W szczególności uważne zawinięcie przewyższa uważne łączenie i jest silnym konkurentem popularnych uważnych RNN. 1</abstract_pl>
      <abstract_sr>U NLP-u konvolucionalne neuralne mreže (CNNs) koriste manje od rekonstruiranih neuralnih mreža (RNN) od pažnje mehanizma. Pretpostavljamo da je to zato što je pažnja CNN-a uglavnom provedena kao pažnja skupljanja (tj. primjenjena se na skupljanje) nego kao pažnja konvolucija (tj. integrisana je u konvoluciju). Konvolucija je diferencijator CNN-a u tome što može moćno modelirati predstavljanje višeg nivoa reči uzimajući u obzir svoj lokalni kontekst fiksne veličine u tekstu ulaska tx. U ovom poslu predlažemo pažljivu konvolucionu mrežu, ATTCONV. To proširi kontekstsku oblast konvolucije, proizveden visokim karakteristikama na nivou reči ne samo iz lokalnog konteksta, nego i iz informacija izvedenih iz nekolokalnog konteksta od strane mehanizma pažnje koje se uobičajeno koristi u RNN-ima. Ovaj ne-lokalni kontekst može doći i) iz delova teksta tx koji su daleki ili ii) od dodatnih (i.e. vanjskih) konteksta. Eksperimenti o modeliranju rečenica sa nulom kontekstom (analiza osjećanja), jednokontekstom (tekstualno zadržavanje) i višestrukim kontekstima (verificija tvrdnja) pokazuju učinkovitost ATTCONV u učenju predstavljanja rečenica sa uključenjem konteksta. Posebno, pažljiva konvolucija iznosi pažljivo okupljanje i je jaki konkurent za popularne pažljive RNN-e. 1</abstract_sr>
      <abstract_so>Shirkadaha neurada ee qasabka ah (CNNs) ee NLP waxay wax ka yar yihiin shabakado neurada oo soo socda (RNNs) oo ka mid ah macaamilooyinka maandooriyaha. Waxaynu u malaynaynaa in taas sababtoo ah daryeelka CNNs waxaa loo sameeyay sida dhaqaale aad u adag (tusaale ahaan waa in loo isticmaalaa dhaqaale) taasoo ayan u bedelan mid adag (tusaale ahaan waa mid la qabsadaa). Qoraalka waxaa ka mid ah kala duwan CNNs, taasoo aad u sameyn karto wadanka heerka sare ee ereyga, si uu ugu xisaabo kooxda deegaanka oo ku qoran taariikhda input tx. Waxay fidisaa hooska kooxaha waxqabadka bulshada, waxayna ka heleysaa aqoonta heerka sare si ay u helaan hadal aan kaliya ka imaanayn xiliga deegaanka, laakiin sidoo kale macluumaadka laga soo saaray kooxaha aan deegaanka ahayn ee lagu isticmaalo RNs. Degmooyinkan aan deegaanka aheyn (i) waxay ka imaan karaan qeybaha qoraalka tx e e ka fog ama (ii) xiliga dibadda ah (i.e. dibadda). Imtixaanka ku saabsan tilmaamaha imtixaanka oo ku qoran zero-context (xisaabta sentimental), hal-context (textual entailment) iyo koox kala duduwan (claim xaqiijinta) waxay muujiyaan saameyn u leh ATTCONV in lagu barto xiliga qoraalka. Si gaar ah, dabeecadda aad u taxadar leh wuxuu sameeyaa baaritaanka aad u adag, wuxuuna yahay khiyaano xoog badan oo u jeeda dadka RNN-ka caawinaya. 1</abstract_so>
      <abstract_si>Name අපි හිතන්නේ මේක තමයි CNNs වල අවධානය අවධානය අවධානය කරලා තියෙන්නේ (ඉතින්, ඒක සම්බන්ධ වෙනුවෙන්) අවධානය සම්බන්ධ වෙනුවෙන් වෙනුවෙන්. සම්පූර්ණය තමයි CNNs ගේ වෙනස් කරුණාකරුවෙන් ඒක බලවත් වෙන්න පුළුවන් වෙන්නේ වචනයක් වඩාවක් වඩාවක් විශ්වාස කරුණාකරණය සඳහා ස්ථානික ප්‍රමාණය සම් ඒක සම්පූර්ණය සම්පූර්ණයේ සම්පූර්ණය ස්ථානයක් වැඩ කරනවා, ස්ථානික සම්පූර්ණයෙන් විතරක් විතරක් විතරක් විතරක් විතරක් වචන මේ ස්ථානික සම්බන්ධතාව (i) පිළිබඳ පැත්ත tx වලින් දුරස්ථ වෙන්න පුළුවන් පරීක්ෂණය සඳහා වාක්ෂාව මොඩලින් සඳහා ශූන්ය-සම්බන්ධ විශ්ලේෂණය, එක-සම්බන්ධ විශ්ලේෂණය (පැත්තක් සම්බන්ධ) සඳහා විශ්ලේෂණය ( විශේෂයෙන්, අවධානය සම්පූර්ණයෙන් අවධානය සම්පූර්ණයෙන් අවධානය කරන්න පුළුවන් වෙනවා ඒ වගේම ප්‍රජා 1</abstract_si>
      <abstract_sv>I NLP har konvulutionella neurala nﾃ､tverk (CNN) gynnats mindre ﾃ､n ﾃ･terkommande neurala nﾃ､tverk (RNN) av uppmﾃ､rksamhetsmekanismer. Vi antar att detta beror pﾃ･ att uppmﾃ､rksamheten i CNN huvudsakligen har implementerats som uppmﾃ､rksam pooling (dvs. den tillﾃ､mpas pﾃ･ pooling) snarare ﾃ､n som uppmﾃ､rksam konvulution (dvs. den ﾃ､r integrerad i konvulution). Konvulution ﾃ､r differentieringen av CNN genom att den kraftfullt kan modellera den hﾃｶgre nivﾃ･n representation av ett ord genom att ta hﾃ､nsyn till dess lokala fasta storlek kontext i inmatningstexten tx. I detta arbete fﾃｶreslﾃ･r vi ett uppmﾃ､rksamt konvulutionsnﾃ､tverk, ATTCONV. Det utﾃｶkar sammanhangsomrﾃ･det fﾃｶr konvulutionsoperationen, hﾃ､rrﾃｶr funktioner pﾃ･ hﾃｶgre nivﾃ･ fﾃｶr ett ord inte bara frﾃ･n lokal kontext, utan ocksﾃ･ frﾃ･n information extraherad frﾃ･n icke-lokal kontext genom uppmﾃ､rksamhetsmekanismen som vanligtvis anvﾃ､nds i RNN. Denna icke-lokala kontext kan komma (i) frﾃ･n delar av inmatningstexten tx som ﾃ､r avlﾃ､gsna eller (ii) frﾃ･n extra (dvs. externa) kontexter ty. Experiment pﾃ･ meningsmodellering med nollkontext (sentimental analysis), enkelkontext (textinvolvering) och flerkontext (claim verifikation) visar effektiviteten av ATTCONV i meningsrepresentationsinlﾃ､rning med inkorporering av kontext. I synnerhet presterar uppmﾃ､rksam konvulution bﾃ､ttre ﾃ､n uppmﾃ､rksam pooling och ﾃ､r en stark konkurrent till populﾃ､ra uppmﾃ､rksam RNN. 1</abstract_sv>
      <abstract_ta>NLP-ல் தொழில்நுட்பமான புதிய பிணைய வலைப்பின்னல்கள் (CNNNs) கவனத்தின் முறைமைகளிலிருந்து திரும்ப நெருகிய வலைப்பின்னல்களை  நாங்கள் நினைக்கிறோம் என்று ஏனெனில் CNNகளின் கவனத்தை முக்கியமாக உபயோகிக்கப்பட்டுள்ளது (அதாவது, குளிர்ச்சிக்கு பயன்படுத்தப்படுகிறது) கவனமான குழப்பத்தை கூட் CNNs என்பது ஒரு சொல்லின் உயர்நிலையின் பிரிவினைப்பான்வேறுபாடாகும் அதன் உள்ளீட்டு உரையில் உள்ளீட்டு tx யில் உள்ள உள்ளிடும் நிலையான அளவு சூழலை எடுத்துக் கொண்ட It extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also from information extracted from nonlocal context by the attention mechanism commonly used in RNNs.  @ info சூழ்நிலையில் வாக்கு மாதிரி மாதிரியின் சோதனைகள் (உணர்வு ஆராய்ச்சி), ஒற்றைச் சூழல் (உரை நிரல் அறிவிப்பு) மற்றும் பல- சூழல் (தேர்வு செய்து உறுதிப்படுத்தல்) சாக குறிப்பிட்டு, கவனமான முரண்பாடுகள் கவனமான பூச்சியம் செய்கிறது மற்றும் பெரிய ஆர்என்னுக்கு உறுதியான போராட்டாளர். 1</abstract_ta>
      <abstract_ur>NLP میں، کنویروشن نیورل نیورل نیٹورک (CNNs) سے کم فائدہ اٹھایا گیا ہے۔ ہم سمجھتے ہیں کہ یہ اس لئے ہے کہ CNNs کی توجه عمدہ طور پر اچھی پولینگ (یعنی اسے پولینگ کے لئے لازم کیا جاتا ہے) بغیر اس کے کہ اچھی پولینگ (یعنی اسے پولینگ) کی توجه ہے۔ کانولوٹ سی نیز کا فرق ہے اس میں کہ یہ ایک لفظ کے بلند سطح کی نمونش پر قابل طور پر ماڈل کر سکتا ہے کہ اس کی محلی مضبوط سائز کائنات کو اپنا اینٹ ٹکس ٹکس میں حساب لیتے ہیں. اس کام میں ہم نے اپنا اچھا کام کرنا نیٹ ورک ATTCONV کی پیشنهاد کرتا ہے. یہ ایک کلمہ کے لئے بلند سطح کے فائولوں کو پھیلاتا ہے جو صرف موقعیت سے نہیں، بلکہ نیز موقعیت غیر موقعیت سے اخذہ کیا جاتا ہے جو RNN میں عام طور پر استعمال کیا جاتا ہے. یہ غیر محلی متصل (i) اینپیٹ متصل tx کے ٹکڑوں سے آسکتا ہے جو اضافہ (یعنی بیرونی) متصل سے دور ہیں۔ صفر کائنات (احساس تحلیل) کے ساتھ مجلس موڈلینگ کے بارے میں آزمائش، ایک کائنات (تنظیم تحلیل) اور بہت سی کائنات (ثابت کی تحقیق) کے بارے میں ATTCONV کی فعالیت کو محسوس کرتا ہے کہ کائنات کے شامل ہونے کے ساتھ سیکھنے کی تعلیم کے ذریعہ سے مخصوصاً مواظب غلط غلط بات مواظب پولینگ سے زیادہ اضافہ ہوتی ہے اور اس سے زیادہ مضبوط مسابقه ہے جو محبوب غلط RNN کے لئے ہے. 1" (msgctxt: "panel:showusername") to "1</abstract_ur>
      <abstract_vi>Trong chọc dò tủy sống, các mạng thần kinh rối loạn (CNN) đã thu nhập ít hơn các mạng thần kinh liên tục (RNN) từ các cơ chế tập trung. Chúng tôi cho rằng đi ều này là vì chúng tôi đã hết cách sự quan tâm của nó là chúng ta đặt sự chúng tạo hiểu quả như là chúng tạo hồn chúng (nó vậy, nó được giản vào thành trong hộp đô Thuyết phục là kẻ phân biệt ngôn ngữ CNN vì nó có khả năng mô tả cấp cao của một từ bằng cách cân nhắc nội dung cố định địa phương trong văn bản nhập. Trong công việc này, chúng tôi đề nghị một mạng lưới kết nạp cẩn thận, ATT. Nó mở rộng phạm vi ngữ cảnh của thao tác cấu trúc kết nối, tạo ra các tính năng cấp cao cho một từ không chỉ từ ngữ cảnh địa phương, mà còn từ thông tin chiết xuất từ ngữ cảnh không địa phương bởi cơ chế chú ý thường sử dụng trong RNN. Đây là ngữ cảnh không địa phương (i) có thể đến từ các phần của văn bản nhập. Tx mà ở rất xa hay (i) từ các mặt phụ (v.d., bên ngoài). Thí nghiệm về mô hình án với trường hợp không có ngữ cảnh (phân tích cảm xúc) một trường duy nhất (kết cấu) và nhiều trường hợp khác nhau (xác nhận lời xác nhận) chứng minh hiệu quả của ATT trong việc học đại diện phần tử bằng sự hợp lý ngữ cảnh. Đặc biệt, cẩn thận xảo trá ngoài việc gom góp cẩn thận và là một đối thủ mạnh mẽ với RNN chú ý nổi tiếng. L</abstract_vi>
      <abstract_uz>In NLP, convolutional neural networks (CNNs) have benefited less than recurrent neural networks (RNNs) from attention mechanisms.  Biz o'ylaymiz, chunki CNNNs'da muhimlik qo'shishga ishlatilgan edi, balki tashkilotni tasavvur qiladigan imkoniyatga ega bo'lishi mumkin. Name Name @ info: whatsthis Name Hullas, tashkilotli muvaffaqiyatlar juda muhim suhbat suhbatni bajaradi va u faqat muhimiy RNNS'ga ishlab chiqaradi. 1</abstract_uz>
      <abstract_da>I NLP har konvulutionelle neurale netværk (CNN'er) haft mindre gavn end tilbagevendende neurale netværk (RNN'er) fra opmærksomhedsmekanismer. Vi antager, at dette skyldes, at opmærksomheden i CNN'er hovedsageligt er blevet implementeret som opmærksom pooling (dvs. den anvendes til pooling) snarere end som opmærksom konvulution (dvs. den er integreret i konvulution). Konvolution er differentieringen af CNN'er, fordi den kan modellere den højere niveau repræsentation af et ord ved at tage højde for dens lokale faststørrelse kontekst i input tekst tx. I dette arbejde foreslår vi et opmærksomt konvolutionsnetværk, ATTCONV. Det udvider kontekst omfanget af konvulutionsoperationen, der stammer fra højere niveau funktioner for et ord ikke kun fra lokal kontekst, men også fra oplysninger udvundet fra ikke-lokal kontekst af opmærksomhedsmekanismen almindeligt anvendt i RNN'er. Denne ikke-lokale kontekst kan komme (i) fra dele af input tekst tx, der er fjerne eller (ii) fra ekstra (dvs. eksterne) kontekster ty. Eksperimenter med sætningsmodellering med nul-kontekst (sentiment analyse), single-kontekst (tekst involvering) og multiple-kontekst (krav verifikation) viser effektiviteten af ATTCONV i sætningsrepræsentation læring med inkorporering af kontekst. Især opmærksom konvulution overgår opmærksom pooling og er en stærk konkurrent til populære opmærksomme RNN'er. 1</abstract_da>
      <abstract_bg>В НЛП конволюционните невронни мрежи (CNN) са се възползвали по-малко от повтарящите се невронни мрежи (RNN) от механизмите на вниманието. Хипотезираме, че това се дължи на факта, че вниманието в ЦНН се осъществява главно като внимателно обединяване (т.е. се прилага към обединяване), а не като внимателна конволюция (т.е. тя е интегрирана в конволюцията). Конволюцията е диференциатор на ЦНН, тъй като може мощно да моделира представянето на дадена дума от по-високо ниво, като вземе предвид локалния контекст с фиксиран размер във входния текст В тази работа предлагаме внимателна конволюционна мрежа, АТКОНВ. Той разширява контекстния обхват на операцията на конволюцията, като извлича по-високи характеристики за дума не само от локалния контекст, но и от информация, извлечена от нелокалния контекст от механизма на вниманието, често използван в РНН. Този нелокален контекст може да дойде (i) от части от входния текст, които са отдалечени или (ii) от екстра (т.е., външни) контексти ти. Експерименти по моделиране на изречения с нулев контекст (анализ на сантимента), едноконтекст (текстово обвързване) и многоконтекст (проверка на претенции) демонстрират ефективността на АТКОНВ в обучението за представяне на изречения с включването на контекст. По-специално внимателната конволюция превъзхожда внимателното басейниране и е силен конкурент на популярните внимателни RNN. 1</abstract_bg>
      <abstract_nl>In NLP hebben convolutionele neurale netwerken (CNN's) minder baat gehad dan recidiverende neurale netwerken (RNN's) van aandachtsmechanismen. We veronderstellen dat dit komt doordat de aandacht in CNN's voornamelijk is geïmplementeerd als attent pooling (d.w.z. het wordt toegepast op pooling) in plaats van als attent convolution (d.w.z., het is geïntegreerd in convolutie). Convolutie is het onderscheidende kenmerk van CNN's in dat het krachtig de hogere-level representatie van een woord kan modelleren door rekening te houden met de lokale vaste grootte context in de invoertekst tx. In dit werk stellen we een attent convolution netwerk voor, ATTCONV. Het breidt de context scope van de convolutie operatie uit, het afleiden van hogere-niveaukenmerken voor een woord niet alleen uit de lokale context, maar ook uit informatie die wordt geëxtraheerd uit niet-lokale context door het aandachtsmechanisme dat gewoonlijk wordt gebruikt in RNN's. Deze niet-lokale context kan (i) afkomstig zijn van delen van de invoertekst tx die ver weg zijn of (ii) uit extra (d.w.z. externe) contexten ty. Experimenten op zinsmodellering met nul-context (sentiment analyse), single-context (tekstuele implicatie) en multiple-context (claim verificatie) tonen de effectiviteit van ATTCONV in zinsrepresentatie leren met integratie van context. Met name, attente convolution overtreft attente pooling en is een sterke concurrent van populaire attente RNN's. 1</abstract_nl>
      <abstract_hr>U NLP-u konvolucionalne neuralne mreže (CNNs) koristili su manje od rekonstruiranih neuralnih mreža (RNN) iz pažnje mehanizma. Pretpostavljamo da je to zato što je pažnja u CNN-u uglavnom provedena kao pažljivo okupljanje (tj. primjena na skupljanje) nego kao pažljiva konvolucija (tj. integrirana u konvoluciju). Konvolucija je diferencijator CNN-a u tome što može moćno modelirati predstavljanje višeg nivoa riječi uzimajući u obzir svoj lokalni kontekst fiksne veličine u tekstu ulaska tx. U ovom poslu predlažemo pažljivu konvolucijsku mrežu, ATTCONV. To proširi kontekstski područje konvolucijske operacije, iz kojih se nalazi najviša karakteristika na razini riječi ne samo iz lokalnog konteksta, nego i iz informacija izvučena iz nekolokalnog konteksta mehanizam pažnje koji se uobičajeno koristi u RNN-ima. Ovaj neslokalni kontekst može doći i) iz dijelova teksta tx koji su daleki ili ii) iz dodatnih (tj. vanjskih) konteksta. Eksperimenti o modeliranju rečenica s nulom kontekstom (analiza osjećaja), jednokontekstom (tekstualno uključenje) i višestrukim kontekstima (provjera tvrdnja) pokazuju učinkovitost ATTCONV u učenju predstavljanja rečenica s uključenjem konteksta. Posebno, pažljiva konvolucija iznosi pažljivo okupljanje i je snažan konkurent za popularne pažljive RNN-e. 1</abstract_hr>
      <abstract_id>Dalam NLP, jaringan saraf konvolusi (CNN) telah menguntungkan kurang dari jaringan saraf rekuren (RNN) dari mekanisme perhatian. Kami hipotesis bahwa hal in i karena perhatian di CNN telah terutama dieksploitasi sebagai pengumpulan perhatian (i.e., ia diterapkan untuk pengumpulan) daripada sebagai konvolusi perhatian (i.e., ia terintegrasi dalam konvolusi). Konvelusi adalah diferenciator CNN dalam bahwa ia dapat dengan kuasa model representation tingkat tinggi dari kata dengan mempertimbangkan konteks ukuran-tetap lokal dalam teks input tx. Dalam pekerjaan ini, kami mengusulkan jaringan konvlusi perhatian, ATTCONV. Ini memperluas skop konteks operasi konvolusi, menghasilkan fitur tingkat tinggi untuk kata bukan hanya dari konteks lokal, tetapi juga dari informasi yang diekstraksi dari konteks non lokal oleh mekanisme perhatian yang biasanya digunakan dalam RNN. Konteks bukan lokal ini dapat datang (i) dari bagian dari teks input tx yang jauh atau (ii) dari konteks ekstra (i.e., ekstra) ty. Eksperimen dalam model kalimat dengan konteks nol (analisis sentimen), konteks tunggal (keterlibatan teks) dan konteks berbilang (verifikasi klaim) menunjukkan efektivitas ATTCONV dalam penemuan kalimat belajar dengan inkorporasi konteks. In particular, attentive convolution outperforms attentive pooling and is a strong competitor to popular attentive RNNs. 1</abstract_id>
      <abstract_de>In NLP haben Convolutional Neuronal Networks (CNNs) weniger von Aufmerksamkeitsmechanismen profitiert als rezidivierende Neuronale Netze (RNNs). Wir vermuten, dass dies darauf zurückzuführen ist, dass die Aufmerksamkeit in CNNs hauptsächlich als aufmerksames Pooling (d.h. es wird auf Pooling angewendet) statt als aufmerksame Faltung (d.h. sie ist in Faltung integriert) implementiert wurde. Convolution ist das Unterscheidungsmerkmal von CNNs, da es die übergeordnete Darstellung eines Wortes unter Berücksichtigung seines lokalen Fixed-Size-Kontexts im Eingabetext tx stark modellieren kann. In dieser Arbeit schlagen wir ein aufmerksames Faltungsnetzwerk vor, ATTCONV. Es erweitert den Kontextbereich der Faltungsoperation und leitet übergeordnete Merkmale für ein Wort nicht nur aus dem lokalen Kontext ab, sondern auch aus Informationen, die durch den in RNNs üblichen Aufmerksamkeitsmechanismus aus dem nichtlokalen Kontext extrahiert werden. Dieser nichtlokale Kontext kann (i) von Teilen des Eingabetextes tx stammen, die entfernt sind, oder (ii) von zusätzlichen (d.h. externen) Kontexten ty. Experimente zur Satzmodellierung mit Zero-Context (Sentiment Analyse), Single-Context (textual implication) und Multiple-Context (Claim Verification) zeigen die Effektivität von ATTCONV im Satzdarstellungslernen unter Einbeziehung von Kontext. Insbesondere die aufmerksame Faltung übertrifft das aufmerksame Pooling und ist ein starker Konkurrent zu beliebten aufmerksamen RNNs. 1</abstract_de>
      <abstract_ko>NLP에서는 역귀신경망(RNN)보다 볼륨신경망(CNN)이 주의 메커니즘에서 얻는 이익이 적었다.CNN의 주의력은 주로 주의력 탱크 (즉, 그것이 탱크에 적용되는 것) 가 아니라 주의력 권적 (즉, 그것은 권적에 집적된 것) 으로 실현되기 때문이라고 가정하자.볼륨은 CNN의 독특한 점이다. 입력 텍스트 tx의 부분적인 고정 크기 상하문을 고려하여 단어의 더 높은 표현을 유력하게 모의할 수 있기 때문이다. 이 작업에서 우리는 집중적인 볼륨 네트워크 ATTCONV를 제시했다.이것은 권적 연산의 상하문 범위를 확장하여 국부 상하문뿐만 아니라 RNN에서 자주 사용하는 주의 메커니즘이 비국부 상하문에서 추출한 정보에서 단어의 더욱 높은 등급 특징을 도출한다.이런 비 로컬 상하문은 (i) 입력 텍스트에서 거리가 먼 부분이나 (ii) 추가 (즉 외부) 상하문에서 올 수 있다.제로 언어 환경(감정 분석), 단일 언어 환경(텍스트 함축)과 다중 언어 환경(성명 검증)에서의 문장 모델링 실험은 ATTCONV가 언어 환경을 결합한 문장 표징 학습에서의 유효성을 증명했다.특히 주의 볼륨이 주의 풀보다 우수해 유행하는 주의 RNN의 강력한 경쟁자다.1</abstract_ko>
      <abstract_sw>Nchini NLP, mitandao ya kikatili ya neura (CNNNs) imefaidi chini ya mitandao ya taratibu yanayoendelea na uraia (RNNs) kutokana na mfumo wa kusikiliza. Tuna imani kwamba hili ni kwa sababu hisia za wananchi wa CNN zimekuwa imetekelezwa kwa kiasi kikubwa kama suala la makini (yaani, linatumiwa kupunguza mabadiliko) badala ya kuwa ni shambulio la kutisha (yaani, linajumuishwa na matatizo). Tamko hilo ni tofauti ya CNNN katika kuwa inaweza kuonyesha uwakilizaji wa ngazi ya juu wa neno kwa kuzingatia muktadha wake wa kiwango kikubwa katika teknolojia ya Tx. Katika kazi hii, tunapendekeza mtandao wa mashambulizi makubwa, ATTCONV. Inaongezea muktadha wa operesheni ya mapinduzi, kupata vipengele vya juu kwa neno si tu kutoka kwenye muktadha wa ndani, bali pia kutoka kwenye taarifa zilizotolewa kutoka kwenye mazingira yasiyo ya ndani na mfumo unaotumiwa mara nyingi katika RNN. Mazungumzo haya yasiyo ya ndani yanaweza kuja (i) kutoka sehemu za matokeo ya Tx ambayo ni mbali au (ii) kutoka kwenye maeneo ya nje (yaani, nje) yanayotokea. Majaribio juu ya hukumu inayoonyesha kwa muktadha usio na mazingira (uchambuzi wa hisia), muktadha mmoja (maarifa ya msingi) na mazingira mengi (madai ya kuthibitisha) yanaonyesha ufanisi wa ATTCONV katika hukumu wakilisha kujifunza kwa muktadha. hasa, mapinduzi ya kijeshi yanafanya mazingira makubwa na ni mshindani mkubwa wa wanachama maarufu wa RNN. 1</abstract_sw>
      <abstract_fa>در NLP، شبکه‌های عصبی (CNNs) کمتر از شبکه‌های عصبی (RNNs) از مکانیسم توجه استفاده کرده‌اند. ما فرض می‌کنیم که این بخاطر این است که توجه در CNN به عنوان جمع کردن مواظب (یعنی جمع کردن آن به عنوان جمع کردن) به جای جمع کردن مواظب است (یعنی جمع کردن آن به عنوان جمع کردن مواظب است). تغییر تغییر کننده CNN است که می تواند با قدرت نمایش سطح بالاتر یک کلمه را با توجه به محیط اندازه ثابت محلی خود در متن ورودی tx نمایش دهد. در این کار، ما یک شبکه تغییر توجه را پیشنهاد می کنیم ATTCONV. این محیط محیط عملیات کنترل را گسترش می‌دهد، که ویژه‌های سطح بالاتر برای یک کلمه نه تنها از محیط محلی، بلکه همچنین از اطلاعات که از محیط غیرمحلی توسط مکانیسم توجه که معمولاً در RNN استفاده می‌شود استفاده می‌شود. این محیط غیرمحلی می‌تواند از بخش‌های متن وارد tx که فاصله‌اند یا (i i) از محیط‌های اضافی (i) می‌تواند بیاید. تجربه‌هایی در مورد نمونه‌سازی مجازات با محیط صفر (تحلیل احساسات), یک محیط (تحلیل متن) و چندین محیط (تحقیق ادعا) نشان می‌دهند که فعالیت ATTCONV در نمونه‌سازی مجازات با تولید محیط را نشان می‌دهند. مخصوصاً تغییرات مواظب توجه بیشتر از جمع کردن مواظب توجه است و یک رقابت قوی برای RNN های مواظب محبوب است. ۱</abstract_fa>
      <abstract_tr>Name Biz muny d체힊체n첵채n di첵ip pikir ed첵채ris 챌체nki CNNs'i 흫 체ns체 (di첵mek bolsa, 철z체ni 첵ygnak bilen) seretsek bolmagyny흫 첵erine 철z체ne seretsek (di첵mek bolsa, k철챌체lenme bilen 체첵tgedilen) 체ns edildi. Bu 채pi힊g채ni흫 CNN senedi흫 g체첵챌li derejesinde bir s철z체흫 첵okary derejesini tx giri힊 metinde 챌ykylyk kontekstinde 챌ykaryp biljek 체챌in 첵okary derejesini d체zenleyebilir. 힇ol i힊de biz 철z체mize seresap ta첵첵arlyk 힊ebekesini teklip edip bil첵채ris. Bu konvolusi첵a operasi첵asyny흫 kontekst sahypasyny uzat첵ar, di흫e 첵erli kontekstden d채l bolmasa 첵okary derejesi 체챌in bir s철z 체챌in 첵okary derejesi 챌ykar, 첵철ne hem 첵erli kontekstden so흫ra RNN-larda ullan첵an 체ns me첵dan챌asynda gatna첵an informasi첵a. Bu 첵erlik b철legi (i) giri힊 metin tx t채plikten uzak 첵ada (ii) extra (mysel채m, da힊arky) senedi흫 b철leginden geler. S철zler 0-kontekst bilen 철rneklendiril첵채n denminatlar, tek-kontekst (tekstual entailment) we k철p-kontekst (claim verification) ATTCONV'i흫 s철zlem 철wrenmesini흫 etkinli휓ini du첵dur첵ar. A첵ratyn bolsa, 체nsli bolup n채sazlyk bilen 체nsli birle힊m채ge t채sirle첵채r we me첵dan챌a 체nsli RNN-lary흫 체st체nde g체첵챌li d철w체r체힊챌isidir. 1</abstract_tr>
      <abstract_sq>Në NLP, rrjetet nervore konvolutive (CNN) kanë përfituar më pak se rrjetet nervore të përsëritura (RNN) nga mekanizmat e vëmendjes. Ne hipotezojmë se kjo është sepse vëmendja në CNN është zbatuar kryesisht si bashkim i vëmendshëm (pra, është aplikuar në bashkim) sesa si konvolucion i vëmendshëm (pra, është integruar në konvolucion). Konvelimi është diferenciatori i CNN në atë që mund të modelojë fuqishëm përfaqësimin më të lartë të një fjale duke marrë parasysh kontekstin e saj lokal të madhësisë fikse në tekstin e hyrjes tx. Në këtë punë, ne propozojmë një rrjet të vëmendshëm konvolution, ATTCONV. Ajo zgjeron fushën kontekstike të operacionit të konvolutionit, duke nxjerrë karakteristika të nivelit më të lartë për një fjalë jo vetëm nga konteksti lokal, por gjithashtu nga informacioni i nxjerrë nga konteksti jo lokal nga mekanizmi i vëmendjes që përdoret zakonisht në RNN. Ky kontekst jo lokal mund të vijë (i) nga pjesë të tekstit të hyrjes tx që janë të largëta ose (ii) nga kontekstet ekstra (i.e., të jashtëm) ty. Eksperimentet mbi modelimin e fjalëve me kontekst zero (analiza e ndjenjave), kontekst të vetëm (përfshirje tekstuale) dhe kontekst të shumtë (verifikimi i pretendimeve) demonstrojnë efektshmërinë e ATTCONV në përfaqësimin e fjalëve në mësimin me përfshirjen e kontekstit. Veçanërisht, konvoluta e vëmendshme mbizotëron bashkimin e vëmendshëm dhe është një konkurent i fortë ndaj RNN të vëmendshme popullore. 1</abstract_sq>
      <abstract_af>In NLP het konvolusionele neuralnetwerke (CNN) minder as herhaalde neuralnetwerke (RNN) gebruik van aandag mekanisme. Ons hipotesis dat dit is omdat die aandag in KNs hoofsaaklik geïmplementeer is as aandaglike pooling (i.e. dit is aangepas na pooling) eerder as as aandaglike konvolusie (i.e. dit is integreer in konvolusie). Konvolusie is die verskiller van CNN in dat dit kragtig kan model die hoër vlak voorstelling van 'n woord deur te neem in rekening sy plaaslike vaste grootte konteks in die invoer teks tx. In hierdie werk voorstel ons 'n aandaglike konvolusie netwerk, ATTCONV. Dit uitbrei die konteksomvang van die konvolusie operasie, afgelei hoër vlak funksies vir 'n woord nie alleen van plaaslike konteks nie, maar ook van inligting uitgevoer van onplaaslike konteks deur die aandag mekanisme wat gewoonlik in RNN gebruik word. Hierdie nie- plaaslike konteks kan kom (i) van dele van die invoer teks tx wat is afstand of (ii) van ekstra (bv., eksterne) konteks tyd. Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entail) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context. In besonderhede, aandaglike konvolusie uitvoer aandaglike pooling en is 'n sterk mededinger vir populêre aandaglike RNN. 1</abstract_af>
      <abstract_hy>ՆՆՊ-ում, հակառակցող նյարդային ցանցերը (CNN-ները) ուշադրության մեխանիզմներից ավելի քիչ են օգտագործել, քան կրկնվող նյարդային ցանցերը (ՌՆՆ-ները): Մենք ենթադրում ենք, որ սա այն պատճառով է, որ ուշադրությունը CNN-ում հիմնականում կիրառվել է որպես ուշադիր համախմբում (այսինքն, այն կիրառվում է համախմբման համար) և ոչ որպես ուշադիր համախմբում (այսինքն, այն ինտեգրված է համախմբման մեջ): Սա CNN-ների տարբերակն է, որովհետև այն կարող է ուժեղ մոդելավորել բառի բարձր մակարդակի ներկայացումը, հաշվի առնելով իր տեղական հաստատուն չափի կոնտեքստը ներկայացման տեքստում tx-ում: Այս աշխատանքում մենք առաջարկում ենք ուշադիր հակառակցման ցանց, ATT-ԿոնV: Այն ընդլայնում է կոնտեքստի գործողության կոնտեքստի դիրքը, հանելով բառի բարձր մակարդակի հատկություններ ոչ միայն տեղական կոնտեքստից, այլ նաև ոչ տեղական կոնտեքստից ստացված ինֆորմացիայից, որը հաճախ օգտագործվում է ՌՆՆ-ում: This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty.  Փորձարկումները նախադասությունների մոդելավորման հետ զրոյական կոնտեքստով (զգացմունքների վերլուծում), մեկ կոնտեքստով (տեքստային ներգրավումը) և բազմաթիվ կոնտեքստով (փաստարկումների ստուգելը) ցույց են տալիս ATTCONV-ի արդյունավետությունը նախադա Հատկապես, ուշադրություն դարձնող հակամարտությունը արտադրում է ուշադրություն դարձնող համախմբումը և ուժեղ մրցակցում է հանրային ուշադրություն դարձնող ՌՆԹ-ների համար: 1</abstract_hy>
      <abstract_bn>এনএলপিতে (সিএনএন) নিউরাল নেটওয়ার্ক (সিএনএন) পুনরাবার নিউরেল নেটওয়ার্ক থেকে কম লাভ করেছে। আমরা বিশ্বাস করি যে এটা কারণ সিএনএন-এর মনোযোগ প্রধান পুলিং হিসেবে বাস্তবায়ন করা হয়েছে (যেমন এটা পুলিং করার জন্য প্রয়োগ করা হয়েছে) তার পরিবর্তে প্রত্যেক গুরুত্বপূর্ কনভোলেশন হচ্ছে সিএনএন-এর পার্থক্য যাতে এটি একটি শব্দের উচ্চপর্যায়ের প্রতিনিধিত্বের ক্ষমতাশালী মডেল করতে পারে ইনপুট ট টিক্সের স্থানীয় স্থানীয়-আকারের প্রতিনিধি এটি স্থানীয় প্রেক্ষাপট থেকে কেবল স্থানীয় প্রেক্ষাপট থেকে বেরিয়ে যাওয়ার জন্য এক শব্দের বিশেষ বৈশিষ্ট্য প্রদান করে, এছাড়াও স্থানীয় প্রেক্ এই স্থানীয় বিভিন্ন প্রেক্ষাপট টি টিক্সের অংশ থেকে আসতে পারে (i) যেগুলো দূরবর্তী অথবা (ii) অতিরিক্ত (উদাহরণস্বরূপ, বাইরে) প্র শুধুমাত্র বিশ্লেষণ, এক-কন্ট্রেক্ট (টেক্সটুয়াল এন্ট্যানেজেন্ট) এবং বেশ কন্টেক্সটেক্সটেন্ট (দাবি পরীক্ষা) বাক্যের প্রতিনিধিত্বে প্রতিনিধিত্বের ক বিশেষ করে, গুরুত্বপূর্ণ বিভ্রান্তিকর বিভ্রান্তির প্রতিযোগিতা প্রকাশ করে এবং জনপ্রিয় আরএনএন-এর প্রতি জনপ্রিয় প্রতিয ১</abstract_bn>
      <abstract_az>NLP içində, konvolucional nöral ağları (CNNs) dinləmə mehanizmilərindən daha az fayda vermişdir. Biz bunun nəzərdə edirik, çünki CNNs təsiri çox dikkatli birləşdirilmək üçün istifadə edilmişdir. Konvolusyon KNN-lərin dəyişiklikləridir ki, bu sözün yüksək seviyyətinin göstərilməsini, yerli fikir ölçü məlumatının tx məlumatında hesablayaraq, güclü olaraq modelləşdirə bilər. Bu işdə, biz dikkatli bir konvolusyon a ğı, ATTCONV təklif edirik. Bu, konvolusyon operasyonunun məlumatını genişləşdirir, bu sözün yüksək səviyyədə fəaliyyətlərini yalnız yerli məlumatdan deyil, lakin bu məlumatdan da RNN-lərdə çox alınan məlumatdan çıxarılır. Bu qeyri-yerli məlumat tx məlumatının bəzisindən uzaq və ya i i) əlavə məlumatdan gələ bilər. Sıfır-kontekst (hiss analizi), tək-kontekst (textual content) və çoxlu-kontekst (claim verification) modellərinin ATTCONV-nin fəaliyyətini cümlədən öyrənməsi ilə təhsil edilməsini göstərir. Özellikle, dikkatli birləşdirilmək dikkatli birləşdirilmək istifadə edir və popularlı növlər üçün güclü müqayisədir. 1" (msgctxt: "panel:showusername") to "1</abstract_az>
      <abstract_am>በNLP፣ የጠቅላላ የኔዌራዊ መረብ (CNNs) ከሚቀጥለው የኔural networks (RNNs) ከጥያቄ ማሰናከል ያጎድልበታል፡፡ ይህ ምክንያት የCNNs ጥያቄ በመጀመሪያው በአስማማማዊ ጉዳይ (ምናልባት ጉዳይ ለመቀላቀል ይደረግበታል) በማለት እናስፈራራለን፡፡ የCNNs መለያየት ነው የቃላትን የደረጃ ደረጃ መልዕክት በማስተካከል በጥያቄ ጽሑፍ tx ውስጥ ለመቆጣጠር በአካባቢ መጠን መጠን ይችላል፡፡ የአካባቢ ክልል ብቻ አይደለም፣ ነገር ግን ከlokal ክልል በተለየ መረጃዎች በተጠቃሚ በRNNs በተጠቃሚ ተጠቃሚ የተጠቃሚ ማህበረሰብ የተለየውን የውይይት አካባቢ ስርዓት ማሰናከል ይዘረጋል፡፡ ይህ የቦታ ግንኙነት (i) ከinput text tx ክፍሎች ሩቅ ወይም (ii) ከextra (i., external) contexts ty ሊመጣ ይችላል። Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context.  በተለይም፣ አዳማሚ ጉዳይ የውጤት ጉዳይ እና የRNNs ተቃውሞ የሚያስፈልግ ኃይለኛ ተጋቢ ነው፡፡ 1</abstract_am>
      <abstract_bs>U NLP-u konvolucionalne neuralne mreže (CNNs) koristile su manje od rekonstruiranih neuralnih mreža (RNN) iz pažnje mehanizma. Pretpostavljamo da je to zato što je pažnja u CNN-u uglavnom provedena kao pažljivo okupljanje (tj. primjena na okupljanje) nego kao pažljiva konvolucija (tj. integrirana u konvoluciju). Konvolucija je diferencijator CNN-a u tome što može moćno modelirati predstavljanje višeg nivoa riječi uzimajući u obzir svoj lokalni kontekst fiksne veličine u tekstu ulaska tx. U ovom poslu predlažemo pažljivu konvolucijsku mrežu, ATTCONV. To proširi kontekstski omjer konvolucijske operacije, izvlačujući karakteristike višeg nivoa za riječ ne samo iz lokalnog konteksta, već i iz informacija izvlačenih iz nekolokalnog konteksta mehanizam pažnje koji se uobičajeno koristi u RNN-ima. Ovaj nenlokalni kontekst može doći i) iz dijelova teksta tx koji su daleki ili ii) iz dodatnih (tj. vanjskih) konteksta ty. Eksperimenti o modeliranju rečenica sa nulom kontekstom (analiza osjećanja), jednokontekstom (tekstualno zadržavanje) i višestrukim kontekstima (provjera tvrdnja) pokazuju učinkovitost ATTCONV u učenju predstavljanja rečenica sa uključenjem konteksta. Posebno, pažljiva konvolucija iznosi pažljivo okupljanje i je jaki konkurent za popularne pažljive RNN-e. 1</abstract_bs>
      <abstract_ca>A la NLP, les xarxes neurals convolucionals han beneficiat menys que les xarxes neurals recurrents dels mecanismes d'atenció. Suposem que això és perquè l'atenció dels CNN s'ha implementat principalment com a agrupament atent (és a dir, s'aplica al agrupament) en comptes de com a convolució atenta (és a dir, s'integra en la convolució). La convolució és la diferenciadora dels CNN en que pot modelar poderosament la representació de nivell superior d'una paraula tenint en compte el seu context local de mida fixa en el text d'entrada tx. En aquest treball, proposem una xarxa de convolució atenta, ATTCONV. Amplia l'àmbit contextual de l'operació de convolució, derivant característiques de nivell superior per una paraula no només del context local, sinó també de la informació extraïda del context no local pel mecanisme d'atenció comument utilitzat en RNN. Aquest context no local pot venir (i) de parts del text d'entrada tx que són distants o (ii) de contextes extra (i.e., externs) ty. Els experiments en modelar frases amb contexte zero (anàlisi de sentiments), contexte únic (involucració textual) i contexte múltiple (verificació de reclamacions) demostren l'eficacia de l'ATTCONV en l'aprenentatge de representació de frases amb l'incorporació del context. En particular, la convolució atenta supera la concentració atenta i és un fort competidor dels RNN atents populars. 1</abstract_ca>
      <abstract_et>NLP-s on konvolutsioonilised nﾃ､rvivﾃｵrgud tﾃ､helepanumehhanismidest vﾃ､hem kasu kui korduvad nﾃ､rvivﾃｵrgud. Hﾃｼpoteesime, et see on tingitud sellest, et tﾃ､helepanu CNVs on rakendatud peamiselt tﾃ､helepaneliku koondamisena (st rakendatakse koondamisele), mitte tﾃ､helepaneliku koondamisena (st integreeritud konvolutsiooni). Konvolutsioon on CNN-ide diferentseerija selles osas, et see suudab vﾃｵimsalt modelleerida sﾃｵna kﾃｵrgemal tasemel esitust, arvestades selle kohalikku fikseeritud suurusega konteksti sisendtekstis tx. Selles tﾃｶﾃｶs pakume vﾃ､lja tﾃ､helepaneliku konvolutsioonivﾃｵrgu ATTCONV. See laiendab konvolutsiooni operatsiooni konteksti ulatust, tuletades sﾃｵna kﾃｵrgema taseme omadusi mitte ainult kohalikust kontekstist, vaid ka teabest, mis on saadud mittekohalisest kontekstist RNN-ides tavaliselt kasutatava tﾃ､helepanumehhanismi abil. See mittekohaline kontekst vﾃｵib tuleneda i) sisendteksti tx osadest, mis on kaugel vﾃｵi ii) ekstra (st vﾃ､lisest) kontekstist ty. Eksperimentid lausemodelleerimisel nullkonteksti (sentimentaalﾃｼﾃｼs), ﾃｼhe konteksti (tekstiline kaasamine) ja mitme konteksti (vﾃ､ite kontrollimine) abil nﾃ､itavad ATTCONV efektiivsust lausekujunduse ﾃｵppimisel koos konteksti kaasamisega. Eelkﾃｵige tﾃ､helepanelik konvolutsioon ﾃｼletab tﾃ､helepaneliku basseini kasutamise ja on tugev konkurent populaarsete tﾃ､helepanelike RNN-de jaoks. 1</abstract_et>
      <abstract_cs>V NLP konvoluční neuronové sítě (CNN) mají méně prospěch než recidivní neuronové sítě (RNN) z mechanismů pozornosti. Předpokládáme, že je to proto, že pozornost v CNN byla realizována hlavně jako pozorné pooling (tj. je aplikována na pooling) spíše než jako pozorná konvoluce (tj. je integrována do konvoluce). Convoluce je diferenciálem CNN v tom, že dokáže výkonně modelovat vyšší úrovně reprezentace slova s ohledem na lokální pevnou velikost kontextu ve vstupním textu tx. V této práci navrhujeme pozornou konvoluční síť ATTCONV. Rozšiřuje kontextový rozsah operace konvoluce, odvozuje vyšší vlastnosti slova nejen z lokálního kontextu, ale také z informací extrahovaných z nekomístního kontextu pomocí mechanismu pozornosti běžně používaného v RNN. Tento nekomístní kontext může pocházet (i) z částí vstupního textu tx, které jsou vzdálené nebo (ii) z externích kontextů ty. Experimenty na modelování vět s nulovým kontextem (sentimentová analýza), singlekontext (textová implikace) a multiple-kontext (verifikace nároku) demonstrují efektivitu ATTCONV při učení reprezentace vět s začleněním kontextu. Zejména pozorná konvoluce překonává pozorné sdílení a je silným konkurentem populárních pozorných RNN. 1</abstract_cs>
      <abstract_fi>NLP:ssä konvolutionaaliset hermoverkot (CNN) ovat hyötyneet huomiomekanismeista vähemmän kuin toistuvat hermoverkot (RNN). Hypoteesimme, että tämä johtuu siitä, että huomio CNN:issä on toteutettu lähinnä tarkkaavaisena yhdistämisenä (eli sitä sovelletaan yhdistämiseen) eikä tarkkaavaisena konvoluationa (eli se on integroitu konvoluatioon). Konvoluutio on CNN:ien erottelija siinä mielessä, että se pystyy voimakkaasti mallintamaan sanan ylemmän tason esitystä ottamalla huomioon sen paikallinen kiinteäkokoinen konteksti syöttötekstissä tx. Tässä työssä ehdotamme tarkkaavaista konvoluutioverkosta, ATTCONV. Se laajentaa konvoluutiotoiminnan kontekstin laajuutta, joka johtaa korkeamman tason ominaisuuksia sanalle ei vain paikallisesta kontekstista, vaan myös tiedoista, jotka on saatu ei-paikallisesta kontekstista RNN:issä yleisesti käytetyn huomiomekanismin avulla. Tämä ei-paikallinen konteksti voi tulla (i) syöttötekstin tx osista, jotka ovat kaukana tai (ii) ekstra (ts. ulkoinen) konteksti ty. Lausekkeiden mallinnuksen kokeet nollakontekstilla (tunteiden analyysi), yhden kontekstin (tekstuaalinen implementointi) ja monikontekstin (väitteiden verifiointi) avulla osoittavat ATTCONV:n tehokkuuden lauseiden esittämisen oppimisessa kontekstin liittämisen avulla. Erityisesti tarkkaavainen konvolution ylittää tarkkaavaisen poolingin ja on vahva kilpailija suosituille tarkkaavaisille RNN:ille. 1</abstract_fi>
      <abstract_jv>In NLP, convolution Neral Network (C NNs) Awak dhéwé ngerasai iki ngono kuwi nggawe sawian nggawe aturan anyar tentang kanggo nggawe winih (i.e. nik nggawe sawian nggawe dolanan ingkang dipunangé) kaya susahé convolution (i.e. ditambah, iso nggawe diolah convolution). The convolution is the contrast of C FindOK text-box-mode Name Jagat-ngopo sing, nglanggar ijol-ijol sing paling apik dadi sing paling apik tur angel karo perusahaan popolar neng DNN. 1</abstract_jv>
      <abstract_he>ב-NLP, רשתות עצביות משתנות (CNN) התרוויחו פחות ממרכזי תשומת לב משתנות. אנו מניחים שזה בגלל שהתשומת לב ב-CNN הופעלה בעיקר כריכוב תשומת לב (כלומר, היא מופעלת על ריכוב) במקום כהתפרצות תשומת לב (כלומר, היא מושלמת לתפרצות). השינוי הוא הדפירנציאטור של CNN שבתוך שהוא יכול לדוגמא בכוחות את היציגה ברמה גבוהה של מילה על ידי לקחת בחשבון את הקשר המקומי שלו בגודל קבוע בטקסט הכניסה tx. בעבודה הזו, אנו מציעים רשת השינוי תשומת לב, ATTCONV. הוא מורחב את המערכת הקשר של מבצע הפרעה, משיג תכונות רמה גבוהה יותר למילה לא רק מההקשר המקומי, אלא גם ממידע שנוצא מההקשר הלא מקומי על ידי מנגנון תשומת לב משתמש בדרך כלל ב RNN. הקשר הלא מקומי הזה יכול לבוא (i) מחלקים של טקסט ההכנסה tx שמרחקים או (ii) מחלקים נוספים (כלומר מחוץ) ty. Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context.  במיוחד, התפרצות תשומת לב מובילה בריכוז תשומת לב והיא מתחרה חזקה ל RNN תשומת לב פופולרית. 1</abstract_he>
      <abstract_sk>V NLP so konvolucijske nevronske mreže (CNN) koristile manj kot ponavljajoče se nevronske mreže (RNN) od mehanizmov pozornosti. Predpostavljamo, da je to zato, ker se pozornost v CNN izvaja predvsem kot pozorno združevanje (tj. uporablja se za združevanje) in ne kot pozorno združevanje (tj. integrirano je v združevanje). Konvolucija je diferenciator CNN-jev, saj lahko močno modelira višjo stopnjo predstavitve besede z upoštevanjem lokalnega konteksta fiksne velikosti v vhodnem besedilu tx. V tem delu predlagamo pozorno konvolucijsko mrežo ATTCONV. Razširi kontekstni obseg konvolucijske operacije, pri čemer izhaja iz višjih značilnosti besede ne le iz lokalnega konteksta, temveč tudi iz informacij, pridobljenih iz nelokalnega konteksta s pomočjo mehanizma pozornosti, ki se običajno uporablja v RNN-jih. Ta nelokalni kontekst lahko prihaja (i) iz delov vhodnega besedila tx, ki so oddaljeni ali (ii) iz ekstra (tj. zunanjih) kontekstov ty. Eksperimenti modeliranja stavkov z ničelnim kontekstom (analiza sentimenta), enokontekstnim (besedilno vključevanje) in večkontekstnim (preverjanje trditev) kažejo učinkovitost ATTCONV pri učenju predstavitve stavkov z vključitvijo konteksta. Zlasti pozorna konvolucija presega pozorno združevanje in je močan konkurent priljubljenim pozornim RNN-jem. 1</abstract_sk>
      <abstract_ha>In NLP, wasu taryutan neural na ƙididdige (CNNNs) sun amfani da ƙaranci masu tarakin neural (RNNNs) daga zanayen muhimmanci. Tuna gaskata cewa wannan ne, dõmin an karɓi muhimmin aikin CNN kamar poopoolin da ake yi (misali, an appla shi dõmin poopoolin) ko kuma don a zama fanati mai gaskatãwa (misali, an haɗa shi). Tsarin shirin ayuka na CNNS ne da za ta iya motsar da tsarin daraja mafi ƙarfi a maganar da za ta yi amfani da kwamfyutan tsarin mai lokaci cikin matsayin inputi tx. A cikin wannan aikin, Munã buƙata wani shirin shiryarwa mai gaskatãwa, ATTCONV. Yana shimfiɗa muhalli na aikin kwamfyutan ayuka da aka samu, yana sãmu masu tsari masu da daraja mafi girma wa wata magana not only daga mazaɓa mai lokal, kuma amma daga information wanda aka nuna daga mazaɓa wa lokal mai amfani da shi a cikin RNNs. Wannan context_action Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context.  Kayya da shi, rundunõnin da ke fara na samura da shirin sami mai saurari, kuma yana mai ƙaranci ga mutane da RNNs. 1</abstract_ha>
      <abstract_bo>NLP ནང་དུ་སྤྱིར་བཏང་བའི་ནུས་མཐུད་དྲ་བ(CNNs)ལ་ཉར་འཇུག་ཐབས་ལམ་ལས་ཕན་ཚུལ་འབྲེལ་བ་ཡོད། ངེད་ཚོས་འདི་དག་རྒྱུ་མཚན་ནི། CNNs ནང་གི་གནད་དོན་དག་གིས་རྟོགས་པའི་སྦྲེལ་མཐུན་ལ་ལག་ལེན་འཐབ་བྱས་ཡོད། Convolution is the differentiator of CNNs in that it can powerfully model the higher-level representation of a word by taking into account its local fixed-size context in the input text tx. In this work, we propose an attentive convolution network, ATTCONV. It extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also from information extracted from nonlocal context by the attention mechanism commonly used in RNNs. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty. Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context. ཁྱད་པར་ན། རྟོགས་པའི་ཆ་འཕྲིན་དེ་ནི་སྤྱིར་བཏང་བའི་ཚོགས་འབྲེལ་བ་ཡིན། 1</abstract_bo>
      </paper>
    </volume>
</collection>