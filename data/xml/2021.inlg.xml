<collection id="2021.inlg">
  <volume id="1" ingest-date="2021-09-20">
    <meta>
      <booktitle>Proceedings of the 14th International Conference on Natural Language Generation</booktitle>
      <editor><first>Anya</first><last>Belz</last></editor>
      <editor><first>Angela</first><last>Fan</last></editor>
      <editor><first>Ehud</first><last>Reiter</last></editor>
      <editor><first>Yaji</first><last>Sripada</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Aberdeen, Scotland, UK</address>
      <month>August</month>
      <year>2021</year>
      <url hash="fd554c4d">2021.inlg-1</url>
    </meta>
    <frontmatter>
      <url hash="61c58746">2021.inlg-1.0</url>
      <bibkey>inlg-2021-international</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Neural Methodius Revisited: Do Discourse Relations Help with Pre-Trained Models Too?</title>
      <author><first>Aleksandre</first><last>Maskharashvili</last></author>
      <author><first>Symon</first><last>Stevens-Guille</last></author>
      <author><first>Xintong</first><last>Li</last></author>
      <author><first>Michael</first><last>White</last></author>
      <pages>12&#8211;23</pages>
      <abstract>Recent developments in natural language generation (NLG) have bolstered arguments in favor of re-introducing explicit coding of discourse relations in the input to neural models. In the Methodius corpus, a meaning representation (MR) is hierarchically structured and includes discourse relations. Meanwhile pre-trained language models have been shown to implicitly encode rich linguistic knowledge which provides an excellent resource for NLG. By virtue of synthesizing these lines of research, we conduct extensive experiments on the benefits of using pre-trained models and discourse relation information in MRs, focusing on the improvement of discourse coherence and correctness. We redesign the Methodius corpus; we also construct another Methodius corpus in which MRs are not hierarchically structured but flat. We report experiments on different versions of the corpora, which probe when, where, and how pre-trained models benefit from MRs with discourse relation information in them. We conclude that discourse relations significantly improve NLG when data is limited.</abstract>
      <url hash="c3d2f45e">2021.inlg-1.2</url>
      <bibkey>maskharashvili-etal-2021-neural</bibkey>
      <pwccode url="https://github.com/aleksadre/methodiusneuralinlg2021" additional="false">aleksadre/methodiusneuralinlg2021</pwccode>
    </paper>
    <paper id="5">
      <title>Chefbot: A Novel Framework for the Generation of Commonsense-enhanced Responses for Task-based Dialogue Systems</title>
      <author><first>Carl</first><last>Strathearn</last></author>
      <author><first>Dimitra</first><last>Gkatzia</last></author>
      <pages>46&#8211;47</pages>
      <abstract>Conversational systems aim to generate responses that are accurate, relevant and engaging, either through utilising neural end-to-end models or through slot filling. Human-to-human conversations are enhanced by not only the latest utterance of the interlocutor, but also by recalling relevant information about concepts/objects covered in the dialogue and integrating them into their responses. Such information may contain recent referred concepts, commonsense knowledge and more. A concrete scenario of such dialogues is the cooking scenario, i.e. when an artificial agent (personal assistant, robot, chatbot) and a human converse about a recipe. We will demo a novel system for commonsense enhanced response generation in the scenario of cooking, where the conversational system is able to not only provide directions for cooking step-by-step, but also display <i>commonsense</i> capabilities by offering explanations of how objects can be used and provide recommendations for replacing ingredients.</abstract>
      <url hash="532dee8f">2021.inlg-1.5</url>
      <bibkey>strathearn-gkatzia-2021-chefbot</bibkey>
    </paper>
    <paper id="6">
      <title>Predicting Antonyms in Context using <fixed-case>BERT</fixed-case></title>
      <author><first>Ayana</first><last>Niwa</last></author>
      <author><first>Keisuke</first><last>Nishiguchi</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>48&#8211;54</pages>
      <abstract>We address the task of antonym prediction in a context, which is a fill-in-the-blanks problem. This task setting is unique and practical because it requires contrastiveness to the other word and naturalness as a text in filling a blank. We propose methods for fine-tuning pre-trained masked language models (BERT) for context-aware antonym prediction. The experimental results demonstrate that these methods have positive impacts on the prediction of antonyms within a context. Moreover, human evaluation reveals that more than 85% of predictions using the proposed method are acceptable as antonyms.</abstract>
      <url hash="ffc3387c">2021.inlg-1.6</url>
      <bibkey>niwa-etal-2021-predicting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="7">
      <title>Examining Covert Gender Bias: A Case Study in <fixed-case>T</fixed-case>urkish and <fixed-case>E</fixed-case>nglish Machine Translation Models</title>
      <author><first>Chloe</first><last>Ciora</last></author>
      <author><first>Nur</first><last>Iren</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>55&#8211;63</pages>
      <abstract>As Machine Translation (MT) has become increasingly more powerful, accessible, and widespread, the potential for the perpetuation of bias has grown alongside its advances. While overt indicators of bias have been studied in machine translation, we argue that covert biases expose a problem that is further entrenched. Through the use of the gender-neutral language Turkish and the gendered language English, we examine cases of both overt and covert gender bias in MT models. Specifically, we introduce a method to investigate asymmetrical gender markings. We also assess bias in the attribution of personhood and examine occupational and personality stereotypes through overt bias indicators in MT models. Our work explores a deeper layer of bias in MT models and demonstrates the continued need for language-specific, interdisciplinary methodology in MT model development.</abstract>
      <url hash="5260729e">2021.inlg-1.7</url>
      <bibkey>ciora-etal-2021-examining</bibkey>
      <pwccode url="https://github.com/NurIren/Gender-Bias-in-TR-to-EN-MT-Models" additional="false">NurIren/Gender-Bias-in-TR-to-EN-MT-Models</pwccode>
    </paper>
    <paper id="12">
      <title>Explaining Decision-Tree Predictions by Addressing Potential Conflicts between Predictions and Plausible Expectations</title>
      <author><first>Sameen</first><last>Maruf</last></author>
      <author><first>Ingrid</first><last>Zukerman</last></author>
      <author><first>Ehud</first><last>Reiter</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>114&#8211;127</pages>
      <abstract>We offer an approach to explain Decision Tree (DT) predictions by addressing potential conflicts between aspects of these predictions and plausible expectations licensed by background information. We define four types of conflicts, operationalize their identification, and specify explanatory schemas that address them. Our human evaluation focused on the effect of explanations on users&#8217; understanding of a DT&#8217;s reasoning and their willingness to act on its predictions. The results show that (1) explanations that address potential conflicts are considered at least as good as baseline explanations that just follow a DT path; and (2) the conflict-based explanations are deemed especially valuable when users&#8217; expectations disagree with the DT&#8217;s predictions.</abstract>
      <url hash="0a6f5d87">2021.inlg-1.12</url>
      <bibkey>maruf-etal-2021-explaining</bibkey>
    </paper>
    <paper id="14">
      <title>Underreporting of errors in <fixed-case>NLG</fixed-case> output, and what to do about it</title>
      <author><first>Emiel</first><last>van Miltenburg</last></author>
      <author><first>Miruna</first><last>Clinciu</last></author>
      <author><first>Ond&#345;ej</first><last>Du&#353;ek</last></author>
      <author><first>Dimitra</first><last>Gkatzia</last></author>
      <author><first>Stephanie</first><last>Inglis</last></author>
      <author><first>Leo</first><last>Lepp&#228;nen</last></author>
      <author><first>Saad</first><last>Mahamood</last></author>
      <author><first>Emma</first><last>Manning</last></author>
      <author><first>Stephanie</first><last>Schoch</last></author>
      <author><first>Craig</first><last>Thomson</last></author>
      <author><first>Luou</first><last>Wen</last></author>
      <pages>140&#8211;153</pages>
      <abstract>We observe a severe under-reporting of the different kinds of errors that Natural Language Generation systems make. This is a problem, because mistakes are an important indicator of where systems should still be improved. If authors only report overall performance metrics, the research community is left in the dark about the specific weaknesses that are exhibited by &#8216;state-of-the-art&#8217; research. Next to quantifying the extent of error under-reporting, this position paper provides recommendations for error identification, analysis and reporting.</abstract>
      <url hash="a17c8e0e">2021.inlg-1.14</url>
      <attachment type="Supplementary_Attachment" hash="302452fb">2021.inlg-1.14.Supplementary_Attachment.zip</attachment>
      <bibkey>van-miltenburg-etal-2021-underreporting</bibkey>
    </paper>
    <paper id="15">
      <title>What can Neural Referential Form Selectors Learn?</title>
      <author><first>Guanyi</first><last>Chen</last></author>
      <author><first>Fahime</first><last>Same</last></author>
      <author><first>Kees</first><last>van Deemter</last></author>
      <pages>154&#8211;166</pages>
      <abstract>Despite achieving encouraging results, neural Referring Expression Generation models are often thought to lack transparency. We probed neural Referential Form Selection (RFS) models to find out to what extent the linguistic features influencing the RE form are learned and captured by state-of-the-art RFS models. The results of 8 probing tasks show that all the defined features were learned to some extent. The probing tasks pertaining to referential status and syntactic position exhibited the highest performance. The lowest performance was achieved by the probing models designed to predict discourse structure properties beyond the sentence level.</abstract>
      <url hash="00e09a6e">2021.inlg-1.15</url>
      <attachment type="Supplementary_Attachment" hash="634b0c83">2021.inlg-1.15.Supplementary_Attachment.zip</attachment>
      <bibkey>chen-etal-2021-neural-referential</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/webnlg">WebNLG</pwcdataset>
    </paper>
    <paper id="21">
      <title><fixed-case>SAPPHIRE</fixed-case>: Approaches for Enhanced Concept-to-Text Generation</title>
      <author><first>Steven Y.</first><last>Feng</last></author>
      <author><first>Jessica</first><last>Huynh</last></author>
      <author><first>Chaitanya Prasad</first><last>Narisetty</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Varun</first><last>Gangal</last></author>
      <pages>212&#8211;225</pages>
      <abstract>We motivate and propose a suite of simple but effective improvements for concept-to-text generation called SAPPHIRE: Set Augmentation and Post-hoc PHrase Infilling and REcombination. We demonstrate their effectiveness on generative commonsense reasoning, a.k.a. the CommonGen task, through experiments using both BART and T5 models. Through extensive automatic and human evaluation, we show that SAPPHIRE noticeably improves model performance. An in-depth qualitative analysis illustrates that SAPPHIRE effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency.</abstract>
      <url hash="35a791e3">2021.inlg-1.21</url>
      <bibkey>feng-etal-2021-sapphire</bibkey>
      <pwccode url="https://github.com/styfeng/sapphire" additional="false">styfeng/sapphire</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/commongen">CommonGen</pwcdataset>
    </paper>
    <paper id="23">
      <title>Generation Challenges: Results of the Accuracy Evaluation Shared Task</title>
      <author><first>Craig</first><last>Thomson</last></author>
      <author><first>Ehud</first><last>Reiter</last></author>
      <pages>240&#8211;248</pages>
      <abstract>The Shared Task on Evaluating Accuracy focused on techniques (both manual and automatic) for evaluating the factual accuracy of texts produced by neural NLG systems, in a sports-reporting domain. Four teams submitted evaluation techniques for this task, using very different approaches and techniques. The best-performing submissions did encouragingly well at this difficult task. However, all automatic submissions struggled to detect factual errors which are semantically or pragmatically complex (for example, based on incorrect computation or inference).</abstract>
      <url hash="611b4355">2021.inlg-1.23</url>
      <bibkey>thomson-reiter-2021-generation</bibkey>
      <pwccode url="https://github.com/ehudreiter/accuracysharedtask" additional="false">ehudreiter/accuracysharedtask</pwccode>
    </paper>
    <paper id="24">
      <title>The <fixed-case>R</fixed-case>epro<fixed-case>G</fixed-case>en Shared Task on Reproducibility of Human Evaluations in <fixed-case>NLG</fixed-case>: Overview and Results</title>
      <author><first>Anya</first><last>Belz</last></author>
      <author><first>Anastasia</first><last>Shimorina</last></author>
      <author><first>Shubham</first><last>Agarwal</last></author>
      <author><first>Ehud</first><last>Reiter</last></author>
      <pages>249&#8211;258</pages>
      <abstract>The NLP field has recently seen a substantial increase in work related to reproducibility of results, and more generally in recognition of the importance of having shared definitions and practices relating to evaluation. Much of the work on reproducibility has so far focused on metric scores, with reproducibility of human evaluation results receiving far less attention. As part of a research programme designed to develop theory and practice of reproducibility assessment in NLP, we organised the first shared task on reproducibility of human evaluations, ReproGen 2021. This paper describes the shared task in detail, summarises results from each of the reproduction studies submitted, and provides further comparative analysis of the results. Out of nine initial team registrations, we received submissions from four teams. Meta-analysis of the four reproduction studies revealed varying degrees of reproducibility, and allowed very tentative first conclusions about what types of evaluation tend to have better reproducibility.</abstract>
      <url hash="f6d3a5f2">2021.inlg-1.24</url>
      <bibkey>belz-etal-2021-reprogen</bibkey>
    </paper>
    <paper id="27">
      <title>Automatic Verification of Data Summaries</title>
      <author><first>Rayhane</first><last>Rezgui</last></author>
      <author><first>Mohammed</first><last>Saeed</last></author>
      <author><first>Paolo</first><last>Papotti</last></author>
      <pages>271&#8211;275</pages>
      <abstract>We present a generic method to compute thefactual accuracy of a generated data summarywith minimal user effort. We look at the prob-lem as a fact-checking task to verify the nu-merical claims in the text. The verification al-gorithm assumes that the data used to generatethe text is available. In this paper, we describehow the proposed solution has been used toidentify incorrect claims about basketball tex-tual summaries in the context of the AccuracyShared Task at INLG 2021.</abstract>
      <url hash="87ee832b">2021.inlg-1.27</url>
      <bibkey>rezgui-etal-2021-automatic</bibkey>
    </paper>
    <paper id="31">
      <title>A Reproduction Study of an Annotation-based Human Evaluation of <fixed-case>MT</fixed-case> Outputs</title>
      <author><first>Maja</first><last>Popovi&#263;</last></author>
      <author><first>Anya</first><last>Belz</last></author>
      <pages>293&#8211;300</pages>
      <abstract>In this paper we report our reproduction study of the Croatian part of an annotation-based human evaluation of machine-translated user reviews (Popovic, 2020). The work was carried out as part of the ReproGen Shared Task on Reproducibility of Human Evaluation in NLG. Our aim was to repeat the original study exactly, except for using a different set of evaluators. We describe the experimental design, characterise differences between original and reproduction study, and present the results from each study, along with analysis of the similarity between them. For the six main evaluation results of Major/Minor/All Comprehension error rates and Major/Minor/All Adequacy error rates, we find that (i) 4/6 system rankings are the same in both studies, (ii) the relative differences between systems are replicated well for Major Comprehension and Adequacy (Pearson&#8217;s &gt; 0.9), but not for the corresponding Minor error rates (Pearson&#8217;s 0.36 for Adequacy, 0.67 for Comprehension), and (iii) the individual system scores for both types of Minor error rates had a higher degree of reproducibility than the corresponding Major error rates. We also examine inter-annotator agreement and compare the annotations obtained in the original and reproduction studies.</abstract>
      <url hash="d8082155">2021.inlg-1.31</url>
      <bibkey>popovic-belz-2021-reproduction</bibkey>
    </paper>
    <paper id="33">
      <title><fixed-case>D</fixed-case>ialog<fixed-case>S</fixed-case>um Challenge: Summarizing Real-Life Scenario Dialogues</title>
      <author><first>Yulong</first><last>Chen</last></author>
      <author id="yang-liu-edinburgh"><first>Yang</first><last>Liu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>308&#8211;313</pages>
      <abstract>We propose a shared task on summarizing real-life scenario dialogues, DialogSum Challenge, to encourage researchers to address challenges in dialogue summarization, which has been less studied by the summarization community. Real-life scenario dialogue summarization has a wide potential application prospect in chat-bot and personal assistant. It contains unique challenges such as special discourse structure, coreference, pragmatics, and social common sense, which require specific representation learning technologies to deal with. We carefully annotate a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of summarization models.</abstract>
      <url hash="5c2b25d1">2021.inlg-1.33</url>
      <bibkey>chen-etal-2021-dialogsum-challenge</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dream">DREAM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dialogsum">DialogSum</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mutual">MuTual</pwcdataset>
    </paper>
    <paper id="34">
      <title>Quality Evaluation of the Low-Resource Synthetically Generated Code-Mixed <fixed-case>H</fixed-case>inglish Text</title>
      <author><first>Vivek</first><last>Srivastava</last></author>
      <author><first>Mayank</first><last>Singh</last></author>
      <pages>314&#8211;319</pages>
      <abstract>In this shared task, we seek the participating teams to investigate the factors influencing the quality of the code-mixed text generation systems. We synthetically generate code-mixed Hinglish sentences using two distinct approaches and employ human annotators to rate the generation quality. We propose two subtasks, quality rating prediction and annotators&#8217; disagreement prediction of the synthetic Hinglish dataset. The proposed subtasks will put forward the reasoning and explanation of the factors influencing the quality and human perception of the code-mixed text.</abstract>
      <url hash="7ca3c662">2021.inlg-1.34</url>
      <bibkey>srivastava-singh-2021-quality</bibkey>
    </paper>
    <paper id="35">
      <title>Shared Task on Feedback Comment Generation for Language Learners</title>
      <author><first>Ryo</first><last>Nagata</last></author>
      <author><first>Masato</first><last>Hagiwara</last></author>
      <author><first>Kazuaki</first><last>Hanawa</last></author>
      <author><first>Masato</first><last>Mita</last></author>
      <author><first>Artem</first><last>Chernodub</last></author>
      <author><first>Olena</first><last>Nahorna</last></author>
      <pages>320&#8211;324</pages>
      <abstract>In this paper, we propose a generation challenge called Feedback comment generation for language learners. It is a task where given a text and a span, a system generates, for the span, an explanatory note that helps the writer (language learner) improve their writing skills. The motivations for this challenge are: (i) practically, it will be beneficial for both language learners and teachers if a computer-assisted language learning system can provide feedback comments just as human teachers do; (ii) theoretically, feedback comment generation for language learners has a mixed aspect of other generation tasks together with its unique features and it will be interesting to explore what kind of generation technique is effective against what kind of writing rule. To this end, we have created a dataset and developed baseline systems to estimate baseline performance. With these preparations, we propose a generation challenge of feedback comment generation.</abstract>
      <url hash="b671e03a">2021.inlg-1.35</url>
      <bibkey>nagata-etal-2021-shared</bibkey>
    </paper>
    </volume>
</collection>