<collection id="2021.ecnlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of The 4th Workshop on e-Commerce and NLP</booktitle>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Surya</first><last>Kallumadi</last></editor>
      <editor><first>Nicola</first><last>Ueffing</last></editor>
      <editor><first>Oleg</first><last>Rokhlenko</last></editor>
      <editor><first>Eugene</first><last>Agichtein</last></editor>
      <editor><first>Ido</first><last>Guy</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="82227aa8">2021.ecnlp-1</url>
    </meta>
    <frontmatter>
      <url hash="cbce110d">2021.ecnlp-1.0</url>
      <bibkey>ecnlp-2021-e</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Turn-Level User Satisfaction Estimation in <fixed-case>E</fixed-case>-commerce Customer Service</title>
      <author><first>Runze</first><last>Liang</last></author>
      <author><first>Ryuichi</first><last>Takanobu</last></author>
      <author><first>Feng-Lin</first><last>Li</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <author><first>Haiqing</first><last>Chen</last></author>
      <author><first>Minlie</first><last>Huang</last></author>
      <pages>26&#8211;32</pages>
      <abstract>User satisfaction estimation in the dialogue-based customer service is critical not only for helping developers find the system defects, but also making it possible to get timely human intervention for dissatisfied customers. In this paper, we investigate the problem of user satisfaction estimation in E-commerce customer service. In order to apply the estimator to online services for timely human intervention, we need to estimate the satisfaction score at each turn. However, in actual scenario we can only collect the satisfaction labels for the whole dialogue sessions via user feedback. To this end, we formalize the turn-level satisfaction estimation as a reinforcement learning problem, in which the model can be optimized with only session-level satisfaction labels. We conduct experiments on the dataset collected from a commercial customer service system, and compare our model with the supervised learning models. Extensive experiments show that the proposed method outperforms all the baseline models.</abstract>
      <url hash="c3f2bb8f">2021.ecnlp-1.4</url>
      <doi>10.18653/v1/2021.ecnlp-1.4</doi>
      <bibkey>liang-etal-2021-turn</bibkey>
    </paper>
    <paper id="11">
      <title>Unsupervised Class-Specific Abstractive Summarization of Customer Reviews</title>
      <author><first>Thi Nhat Anh</first><last>Nguyen</last></author>
      <author><first>Mingwei</first><last>Shen</last></author>
      <author><first>Karen</first><last>Hovsepian</last></author>
      <pages>88&#8211;100</pages>
      <abstract>Large-scale unsupervised abstractive summarization is sorely needed to automatically scan millions of customer reviews in today&#8217;s fast-paced e-commerce landscape. We address a key challenge in unsupervised abstractive summarization &#8211; reducing generic and uninformative content and producing useful information that relates to specific product aspects. To do so, we propose to model reviews in the context of some topical classes of interest. In particular, for any arbitrary set of topical classes of interest, the proposed model can learn to generate a set of class-specific summaries from multiple reviews of each product without ground-truth summaries, and the only required signal is class probabilities or class label for each review. The model combines a generative variational autoencoder, with an integrated class-correlation gating mechanism and a hierarchical structure capturing dependence among products, reviews and classes. Human evaluation shows that generated summaries are highly relevant, fluent, and representative. Evaluation using a reference dataset shows that our model outperforms state-of-the-art abstractive and extractive baselines.</abstract>
      <url hash="c17e4456">2021.ecnlp-1.11</url>
      <doi>10.18653/v1/2021.ecnlp-1.11</doi>
      <bibkey>nguyen-etal-2021-unsupervised</bibkey>
    </paper>
    <paper id="15">
      <title>Detect Profane Language in Streaming Services to Protect Young Audiences</title>
      <author><first>Jingxiang</first><last>Chen</last></author>
      <author><first>Kai</first><last>Wei</last></author>
      <author><first>Xiang</first><last>Hao</last></author>
      <pages>123&#8211;131</pages>
      <abstract>With the rapid growth of online video streaming, recent years have seen increasing concerns about profane language in their content. Detecting profane language in streaming services is challenging due to the long sentences appeared in a video. While recent research on handling long sentences has focused on developing deep learning modeling techniques, little work has focused on techniques on improving data pipelines. In this work, we develop a data collection pipeline to address long sequence of texts and integrate this pipeline with a multi-head self-attention model. With this pipeline, our experiments show the self-attention model offers 12.5% relative accuracy improvement over state-of-the-art distilBERT model on profane language detection while requiring only 3% of parameters. This research designs a better system for informing users of profane language in video streaming services.</abstract>
      <url hash="5bb25fbd">2021.ecnlp-1.15</url>
      <doi>10.18653/v1/2021.ecnlp-1.15</doi>
      <bibkey>chen-etal-2021-detect</bibkey>
    </paper>
    </volume>
</collection>