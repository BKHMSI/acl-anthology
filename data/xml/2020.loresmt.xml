<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.loresmt">
  <volume id="1" ingest-date="2020-12-02">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</booktitle>
      <editor><first>Alina</first><last>Karakanta</last></editor>
      <editor><first>Atul Kr.</first><last>Ojha</last></editor>
      <editor><first>Chao-Hong</first><last>Liu</last></editor>
      <editor><first>Jade</first><last>Abbott</last></editor>
      <editor><first>John</first><last>Ortega</last></editor>
      <editor><first>Jonathan</first><last>Washington</last></editor>
      <editor><first>Nathaniel</first><last>Oco</last></editor>
      <editor><first>Surafel Melaku</first><last>Lakew</last></editor>
      <editor><first>Tommi A</first><last>Pirinen</last></editor>
      <editor><first>Valentin</first><last>Malykh</last></editor>
      <editor><first>Varvara</first><last>Logacheva</last></editor>
      <editor><first>Xiaobing</first><last>Zhao</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Suzhou, China</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="c7b02162">2020.loresmt-1.0</url>
      <bibkey>loresmt-2020-technologies</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Bridging Philippine Languages With Multilingual Neural Machine Translation<fixed-case>P</fixed-case>hilippine Languages With Multilingual Neural Machine Translation</title>
      <author><first>Renz Iver</first><last>Baliber</last></author>
      <author><first>Charibeth</first><last>Cheng</last></author>
      <author><first>Kristine Mae</first><last>Adlaon</last></author>
      <author><first>Virgion</first><last>Mamonong</last></author>
      <pages>14–22</pages>
      <abstract>The Philippines is home to more than 150 languages that is considered to be low-resourced even on its major languages. This results into a lack of pursuit in developing a <a href="https://en.wikipedia.org/wiki/Translation">translation system</a> for the underrepresented languages. To simplify the process of developing translation system for multiple languages, and to aid in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research. However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation. In this paper, we benchmarked <a href="https://en.wikipedia.org/wiki/Translation">translation</a> for several <a href="https://en.wikipedia.org/wiki/Languages_of_the_Philippines">Philippine Languages</a>, provided an analysis of a multilingual NMT system for morphologically rich and low-resource languages in terms of its effectiveness in translating zero-resource languages with zero-shot translations. To further evaluate the capability of the multilingual NMT model in translating unseen language pairs in training, we tested the model to translate between <a href="https://en.wikipedia.org/wiki/Tagalog_language">Tagalog</a> and <a href="https://en.wikipedia.org/wiki/Cebuano_language">Cebuano</a> and compared its performance with a simple NMT model that is directly trained on a parallel Tagalog and Cebuano data in which we showed that zero-shot translation outperforms a directly trained model in some instances, while utilizing English as a pivot language in translating outperform both approaches.</abstract>
      <url hash="947402a7">2020.loresmt-1.2</url>
      <bibkey>baliber-etal-2020-bridging</bibkey>
    <title_ar>تجسير اللغات الفلبينية مع الترجمة الآلية العصبية متعددة اللغات</title_ar>
      <title_es>Unir las lenguas filipinas con la traducción automática neuronal multilingüe</title_es>
      <title_pt>Unindo as línguas filipinas com a tradução automática neural multilíngue</title_pt>
      <title_fr>Relier les langues philippines avec la traduction automatique neuronale multilingue</title_fr>
      <title_hi>बहुभाषी तंत्रिका मशीन अनुवाद के साथ फिलीपीन भाषाओं ब्रिजिंग</title_hi>
      <title_zh>多语言神经机器译桥接菲律宾语</title_zh>
      <title_ja>多言語ニューラル機械翻訳でフィリピンの言語を橋渡しする</title_ja>
      <title_ru>Сочетание филиппинских языков с многоязычным нейронным машинным переводом</title_ru>
      <title_ukr>Зв 'язок філіппінських мов за допомогою багатомовного нейронного машинного перекладу</title_ukr>
      <title_ga>Teangacha Filipíneacha a Dhruidim le hAistriúchán Inneall Néarach Ilteangach</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>A fülöp-szigeteki nyelvek összekapcsolása többnyelvű idegi fordítással</title_hu>
      <title_isl>Name</title_isl>
      <title_el>Γέφυρα των Φιλιππίνων με την πολύγλωσση νευρωνική μηχανική μετάφραση</title_el>
      <title_it>Collegare le lingue filippine con la traduzione automatica neurale multilingue</title_it>
      <title_kk>Филиппин тілдерін бірнеше тілді нейралық машинаның аудармасымен түрлендіру</title_kk>
      <title_lt>Filipinų kalbų derinimas su daugiakalbėmis neurologinėmis mašinomis</title_lt>
      <title_mk>Name</title_mk>
      <title_ms>Name</title_ms>
      <title_ml>Bridging Philippine Languages With Multilingual Neural Machine Translation</title_ml>
      <title_mt>Bridging Philippine Languages With Multilingual Neural Machine Translation</title_mt>
      <title_mn>Филиппин хэл дээр олон хэл мэдрэлийн машин хөгжүүлэхэд</title_mn>
      <title_no>Bridging av Filippinske språk med fleirspråk neuralmaskinsomsetjing</title_no>
      <title_pl>Połączenie języków filipińskich z wielojęzycznym neuronowym tłumaczeniem maszynowym</title_pl>
      <title_ro>Îmbinarea limbilor filipineze cu traducerea automată neurală multilingvă</title_ro>
      <title_sr>Bridging Filipinske jezike sa mnogijezičkim neuronskim prevodom mašine</title_sr>
      <title_sv>Att överbrygga filippinska språk med flerspråkig neural maskinöversättning</title_sv>
      <title_si>Name</title_si>
      <title_so>Bridging Philippine Languages With Multilingual Neural Machine Translation</title_so>
      <title_ta>பல மொழிகளின் நெருக்கல் இயந்திரம் மொழிபெயர்ப்புடன் பிரிட்டிங் பிலிப்பைன் மொழிகள்</title_ta>
      <title_ur>فلپیپین زبانوں کو بہت سی زبان کی نیورال ماشین ترجمہ کے ساتھ بریج کیا جاتا ہے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Kết nối Ngôn ngữ Philippines Với máy thần kinh đa ngôn ngữ</title_vi>
      <title_bg>Свързване на филипинските езици с многоезичен неврален машинен превод</title_bg>
      <title_nl>Filipijnse talen overbruggen met meertalige neurale machinevertaling</title_nl>
      <title_hr>Bridging Filipinske jezike sa mnogijezičkim neuronskim prevodom</title_hr>
      <title_da>Forening af filippinske sprog med flersproget neural maskinoversættelse</title_da>
      <title_de>Philippinische Sprachen mit mehrsprachiger neuronaler maschineller Übersetzung überbrücken</title_de>
      <title_ko>다국어 신경기계로 필리핀 언어 연결</title_ko>
      <title_fa>زبانهای فیلیپین با ترجمه ماشین عصبی چند زبان</title_fa>
      <title_id>Menyebar Bahasa Filipina Dengan Penerjemahan Mesin Neural Berbahasa</title_id>
      <title_sw>Tafsiri za lugha za Kifilipino</title_sw>
      <title_tr>Filipin dillerini köp dilli närarl Maşynyň terjimesini bilen söndürmek</title_tr>
      <title_af>Name</title_af>
      <title_am>የፊልጵስዩን ቋንቋዎች መግለጫዎች በብዙ ቋንቋዎች የኔural machine ትርጉም</title_am>
      <title_sq>Ngjitja e gjuhëve filipine me përkthimin e makinave nervore shumëgjuhëse</title_sq>
      <title_hy>Ֆիլիպպինյան լեզուների համախմբումը բազլեզու նյարդային մեքենայի թարգմանման միջոցով</title_hy>
      <title_bn>Bridging Philippine Languages With Multilingual Neural Machine Translation</title_bn>
      <title_az>Çoxlu dil nöral maşına çevirilən Filipin dillərini Bridging</title_az>
      <title_bs>Bridging Filipinski jezici sa mnogijezičkim neuronskim prevodom</title_bs>
      <title_cs>Spojení filipínských jazyků s vícejazyčným neuronovým strojovým překladem</title_cs>
      <title_ca>Bringing Philippine Languages With Multilingual Neural Machine Translation</title_ca>
      <title_et>Filipiinide keelte ühendamine mitmekeelse neuraalse masintõlkega</title_et>
      <title_fi>Filippiinien kielten yhdistäminen monikielisellä neuroalisella konekäännöksellä</title_fi>
      <title_jv>Piring</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>הגשר שפות פיליפינות עם תרגום של מכונות נוירות רבות שפות</title_he>
      <title_sk>Premostitev filipinskih jezikov z večjezičnim nevralnim strojnim prevajanjem</title_sk>
      <title_fil>Ang mga wikang Filipino na may multilingual Neural Machine Translation</title_fil>
      <title_bo>Bridging Philippine Languages With Multilingual Neural Machine Translation</title_bo>
      <abstract_ar>الفلبين هي موطن لأكثر من 150 لغة تعتبر منخفضة الموارد حتى في لغاتها الرئيسية. ينتج عن هذا عدم السعي لتطوير نظام ترجمة للغات الممثلة تمثيلا ناقصا. لتبسيط عملية تطوير نظام الترجمة للغات متعددة ، وللمساعدة في تحسين جودة الترجمة من الصفر إلى اللغات منخفضة الموارد ، أصبحت NMT متعددة اللغات مجالًا نشطًا للبحث. ومع ذلك ، فإن الأعمال الحالية في NMT متعددة اللغات تتجاهل تحليل نموذج متعدد اللغات على مجموعة لغة وثيقة الصلة وذات موارد منخفضة في سياق الترجمة المحورية والترجمة الصفرية. في هذه الورقة ، قمنا بقياس الترجمة للعديد من اللغات الفلبينية ، وقدمنا تحليلاً لنظام NMT متعدد اللغات للغات الغنية شكليًا وقليلة الموارد من حيث فعاليتها في ترجمة اللغات الخالية من الموارد مع ترجمات من الصفر. لمزيد من تقييم قدرة نموذج NMT متعدد اللغات في ترجمة أزواج اللغات غير المرئية في التدريب ، اختبرنا النموذج للترجمة بين التاغالوغ والسيبوانو وقارننا أدائه بنموذج NMT البسيط الذي تم تدريبه بشكل مباشر على بيانات تاجالوج وسيبوانو موازية حيث لقد أظهرنا أن الترجمة بدون طلقة تتفوق في الأداء على نموذج مدرب بشكل مباشر في بعض الحالات ، بينما استخدام اللغة الإنجليزية كلغة محورية في الترجمة يتفوق على كلا النهجين.</abstract_ar>
      <abstract_pt>As Filipinas abrigam mais de 150 idiomas que são considerados de poucos recursos, mesmo em seus principais idiomas. Isso resulta em uma falta de busca no desenvolvimento de um sistema de tradução para os idiomas sub-representados. Para simplificar o processo de desenvolvimento de sistemas de tradução para vários idiomas e ajudar a melhorar a qualidade da tradução de zero a idiomas com poucos recursos, a NMT multilíngue tornou-se uma área ativa de pesquisa. No entanto, os trabalhos existentes em NMT multilíngue desconsideram a análise de um modelo multilíngue em um grupo de idiomas intimamente relacionado e de poucos recursos no contexto de tradução baseada em pivô e tradução zero. Neste artigo, comparamos a tradução para várias línguas filipinas, fornecemos uma análise de um sistema NMT multilíngue para idiomas morfologicamente ricos e de poucos recursos em termos de sua eficácia na tradução de idiomas de recursos zero com traduções de tiro zero. Para avaliar ainda mais a capacidade do modelo NMT multilíngue em traduzir pares de idiomas não vistos em treinamento, testamos o modelo para traduzir entre Tagalog e Cebuano e comparamos seu desempenho com um modelo NMT simples que é treinado diretamente em dados paralelos Tagalog e Cebuano em que mostramos que a tradução zero-shot supera um modelo treinado diretamente em alguns casos, enquanto a utilização do inglês como idioma principal na tradução supera ambas as abordagens.</abstract_pt>
      <abstract_es>Filipinas alberga más de 150 idiomas que se consideran de bajos recursos, incluso en sus idiomas principales. Esto se traduce en una falta de búsqueda en el desarrollo de un sistema de traducción para los idiomas subrepresentados. Para simplificar el proceso de desarrollo del sistema de traducción para varios idiomas, y para ayudar a mejorar la calidad de la traducción de idiomas de cero a pocos recursos, la NMT multilingüe se convirtió en un área activa de investigación. Sin embargo, los trabajos existentes en NMT multilingüe no tienen en cuenta el análisis de un modelo multilingüe en un grupo lingüístico estrechamente relacionado y de pocos recursos en el contexto de la traducción basada en pivote y la traducción cero. En este artículo, comparamos la traducción para varios idiomas filipinos, proporcionamos un análisis de un sistema NMT multilingüe para idiomas ricos morfológicamente y de bajos recursos en términos de su eficacia en la traducción de idiomas de cero recursos con traducciones de cero posibilidades. Para evaluar más a fondo la capacidad del modelo NMT multilingüe para traducir pares de idiomas invisibles en el entrenamiento, probamos el modelo para traducir entre tagalo y cebuano y comparamos su rendimiento con un modelo NMT simple que se entrena directamente en datos paralelos de tagalo y cebuano en el que mostramos que la traducción cero supera a un modelo directamente entrenado en algunos casos, mientras que el uso del inglés como idioma clave en la traducción supera a ambos enfoques.</abstract_es>
      <abstract_fr>Les Philippines abritent plus de 150 langues qui sont considérées comme peu dotées, même pour les principales langues. Il en résulte un manque de recherche dans le développement d'un système de traduction pour les langues sous-représentées. Afin de simplifier le processus de développement d'un système de traduction pour plusieurs langues et d'aider à améliorer la qualité de la traduction des langues zéro à faible ressource, la NMT multilingue est devenue un domaine de recherche actif. Cependant, les travaux existants dans le domaine de la traduction multilingue ne tiennent pas compte de l'analyse d'un modèle multilingue sur un groupe linguistique étroitement lié et à faibles ressources dans le contexte de la traduction basée sur pivot et de la traduction zero-shot. Dans cet article, nous avons comparé la traduction pour plusieurs langues philippines, fourni une analyse d'un système NMT multilingue pour les langues morphologiquement riches et à faible ressource en termes d'efficacité dans la traduction de langues sans ressources avec des traductions zéro. Pour évaluer plus en détail la capacité du modèle NMT multilingue à traduire des paires de langues inédites pendant la formation, nous avons testé le modèle à traduire entre le tagalog et le cebuano et comparé ses performances avec un modèle NMT simple qui est directement entraîné sur des données parallèles de tagalog et de Cebuano dans lesquelles nous avons montré que la traduction zero-shot surpasse un modèle directement entraîné dans certains cas, tandis que l'utilisation de l'anglais comme langue pivot dans la traduction surpasse les deux approches.</abstract_fr>
      <abstract_ja>フィリピンには150以上の言語があり、主要言語であっても資源が少ないと考えられています。 これは、表現不足の言語の翻訳システムの開発における追求の欠如につながります。 複数の言語の翻訳システムを開発するプロセスを簡素化し、ゼロから低資源言語への翻訳品質の向上を支援するために、多言語NMTが研究の活発な分野となりました。 しかし、多言語NMTにおける既存の研究は、ピボットベース翻訳とゼロショット翻訳の文脈で、密接に関連する低リソース言語グループ上の多言語モデルの分析を無視している。 この論文では、いくつかのフィリピンの言語の翻訳をベンチマークし、ゼロショット翻訳でゼロリソース言語を翻訳する効果の観点から、形態的に豊富で低リソースの言語のための多言語NMTシステムの分析を提供しました。 トレーニングでの見えない言語ペアの翻訳における多言語NMTモデルの能力をさらに評価するために、私たちはタガログ語とセブアノ語の間で翻訳するモデルをテストし、そのパフォーマンスを並行したタガログ語とセブアノ語のデータで直接トレーニングされた単純なNMTモデルと比較しました。このモデルでは、ゼロショット翻訳が、いくつかの例では直接トレーニングされたモデルよりも優れていることを示しましたが、両方のアプローチを翻訳する際にピボット言語として英語を利用しました。</abstract_ja>
      <abstract_zh>菲律宾有150多种语言,虽大言亦以为资源匮乏。 此致代表性不足者语文译者阙焉。 开多种语言译统,助零到卑言,多言NMT为生跃之域。 然多言NMT者忽于枢轴之译,零镜头译之背景,相关于资源匮乏之语。 于本文中,略试菲律宾言语,析形多言NMT系零资言语、零镜头译之有效性。 论多言 NMT 译不见之能,试之以加禄语宿务语之间,与直基并行禄语宿务数据之约 NMT 较之,其明零次转优于直教者也。  兼用英语为译之要言,而优于此二者。</abstract_zh>
      <abstract_ru>На Филиппинах насчитывается более 150 языков, которые, как считается, не обеспечены достаточными ресурсами даже на основных языках. Это приводит к тому, что не предпринимаются усилия по разработке системы письменного перевода для недопредставленных языков. Для упрощения процесса разработки системы перевода для нескольких языков, а также для содействия улучшению качества перевода с нулевого на малоресурсный язык, многоязычная НМТ стала активной областью исследований. Тем не менее, существующие работы в многоязычной НМТ игнорируют анализ многоязычной модели на близкородственной и малоресурсной языковой группе в контексте поворотного перевода и нулевого перевода. В этой статье мы сравнили перевод для нескольких филиппинских языков, провели анализ многоязычной системы НМТ для морфологически богатых и малоресурсных языков с точки зрения ее эффективности в переводе языков с нулевыми ресурсами с нулевыми переводами. Чтобы дополнительно оценить возможности многоязычной модели НМТ в переводе невидимых языковых пар в обучении, мы протестировали модель для перевода между тагальским и себуанским языками и сравнили ее производительность с простой моделью НМТ, которая непосредственно обучается на параллельных данных тагальского и себуанского языков, в которой мы показали, что перевод с нулевым выстрелом в некоторых случаях превосходит непосредственно обученную модель, при этом используя английский язык в качестве сводного языка при переводе превосходит оба подхода.</abstract_ru>
      <abstract_hi>फिलीपींस 150 से अधिक भाषाओं का घर है जिसे इसकी प्रमुख भाषाओं पर भी कम संसाधन वाला माना जाता है। इसके परिणामस्वरूप कम प्रतिनिधित्व वाली भाषाओं के लिए एक अनुवाद प्रणाली विकसित करने में पीछा करने की कमी होती है। कई भाषाओं के लिए अनुवाद प्रणाली विकसित करने की प्रक्रिया को सरल बनाने के लिए, और कम-संसाधन वाली भाषाओं में शून्य की अनुवाद गुणवत्ता में सुधार करने में सहायता करने के लिए, बहुभाषी एनएमटी अनुसंधान का एक सक्रिय क्षेत्र बन गया। हालांकि, बहुभाषी एनएमटी में मौजूदा कार्य धुरी-आधारित अनुवाद और शून्य-शॉट अनुवाद के संदर्भ में एक निकटसे संबंधित और कम-संसाधन भाषा समूह पर एक बहुभाषी मॉडल के विश्लेषण की उपेक्षा करते हैं। इस पेपर में, हमने कई फिलीपीन भाषाओं के लिए अनुवाद बेंचमार्क किया, शून्य-शॉट अनुवाद के साथ शून्य-संसाधन भाषाओं का अनुवाद करने में इसकी प्रभावशीलता के संदर्भ में रूपात्मक रूप से समृद्ध और कम-संसाधन भाषाओं के लिए एक बहुभाषी एनएमटी प्रणाली का विश्लेषण प्रदान किया। प्रशिक्षण में अनदेखी भाषा जोड़े का अनुवाद करने में बहुभाषी एनएमटी मॉडल की क्षमता का मूल्यांकन करने के लिए, हमने तागालोग और सेबुआनो के बीच अनुवाद करने के लिए मॉडल का परीक्षण किया और इसके प्रदर्शन की तुलना एक साधारण एनएमटी मॉडल के साथ की जो सीधे एक समानांतर तागालॉग और सेबुआनो डेटा पर प्रशिक्षित है जिसमें हमने दिखाया है कि शून्य-शॉट अनुवाद कुछ उदाहरणों में सीधे प्रशिक्षित मॉडल को मात देता है,  जबकि अंग्रेजी का उपयोग एक धुरी भाषा के रूप में अनुवाद दोनों दृष्टिकोणों से बेहतर प्रदर्शन में करते हैं।</abstract_hi>
      <abstract_ukr>На Філіппінах є понад 150 мов, які вважаються малозабезпеченими навіть основними мовами. Це призводить до відсутності прагнення до розробки системи перекладу для недопредставлених мов. Для спрощення процесу розробки системи перекладу для декількох мов, а також для сприяння підвищенню якості перекладу з нульових мов до мов з низькими ресурсами, багатомовний НМТ став активним напрямком досліджень. Однак, існуючі роботи в багатомовній НМТ ігнорують аналіз багатомовної моделі на тісно пов 'язаній і малоресурсній мовній групі в контексті перекладу на основі поворотів і перекладу без знімків. У цій роботі ми порівняли переклад для кількох філіппінських мов, надали аналіз багатомовної системи НМТ для морфологічно багатих та малоресурсних мов з точки зору її ефективності при перекладі мов з нульовими ресурсами з нульовими знімками. Для подальшої оцінки можливостей багатомовної моделі НМТ у перекладі небачених мовних пар у навчанні, ми перевірили модель для перекладу між тагальською та себуанською мовами та порівняли її продуктивність з простою моделлю НМТ, яка безпосередньо навчається на паралельних даних тагальської та себуанської мов, в якій ми показали, що переклад з нульовим знімком у деяких випадках перевершує безпосередньо навчену модель, одночасно використовуючи англійську мову як опорну мову при перекладі перевершує обидва підходи.</abstract_ukr>
      <abstract_ga>Tá níos mó ná 150 teanga sna hOileáin Fhilipíneacha a mheastar a bheith íseal-acmhainní fiú sna mórtheangacha. Is é an toradh a bhíonn air seo ná go mbíonn easpa tóra ar chóras aistriúcháin a fhorbairt do na teangacha tearcionadaíochta. Chun an próiseas a bhaineann le forbairt an chórais aistriúcháin d’iltheangacha a shimpliú, agus chun cabhrú le feabhas a chur ar cháilíocht an aistriúcháin ó náid go teangacha íseal-acmhainne, rinneadh réimse gníomhach taighde de NMT ilteangach. Mar sin féin, ní thugann saothair atá ann cheana féin in NMT ilteangach aird ar an anailís ar shamhail ilteangach ar ghrúpa teangacha a bhfuil dlúthbhaint acu leis agus a bhfuil acmhainní ísle acu i gcomhthéacs an aistriúcháin pivot-bhunaithe agus an t-aistriúchán nialasach. Sa pháipéar seo, rinneamar tagarmharcáil ar aistriúchán do roinnt Teangacha Filipíneacha, chuireamar anailís ar fáil ar chóras ilteangach NMT do theangacha moirfeolaíocha saibhir agus íseal-acmhainne i dtéarmaí a éifeachtúlachta maidir le teangacha gan acmhainní a aistriú le haistriúcháin náid. Chun tuilleadh meastóireachta a dhéanamh ar chumas na samhla ilteangach NMT maidir le péirí teangacha neamhfheicthe a aistriú san oiliúint, rinneamar tástáil ar an tsamhail chun aistriúchán idir Tagálaigis agus Cebuano agus chuireamar a fheidhmíocht i gcomparáid le samhail simplí NMT atá oilte go díreach ar shonraí comhthreomhara Tagálaigis agus Cebuano ina bhfuil. léirigh muid go n-éiríonn níos fearr le haistriúchán gan urchar ná samhail atá oilte go díreach i gcásanna áirithe, agus é ag úsáid an Bhéarla mar theanga mhaighdeogach san aistriúchán is fearr an dá chur chuige.</abstract_ga>
      <abstract_hu>A Fülöp-szigetek több mint 150 nyelvnek ad otthont, amelyek még a főbb nyelveken is alacsony forrásokkal rendelkeznek. Ez az alulreprezentált nyelvek fordítási rendszerének kifejlesztésére irányuló törekvések hiányát eredményezi. A többnyelvű fordítási rendszer fejlesztésének folyamatának egyszerűsítése érdekében, valamint a nullától alacsony erőforrású nyelvek fordítási minőségének javítása érdekében a többnyelvű NMT aktív kutatási területévé vált. A többnyelvű NMT-ben már meglévő munkák azonban figyelmen kívül hagyják egy többnyelvű modell elemzését egy szorosan kapcsolódó és alacsony erőforrással rendelkező nyelvi csoporton a pivot alapú fordítás és a zero-shot fordítás kontextusában. Ebben a tanulmányban több fülöp-szigeteki nyelv fordításának összehasonlítását vizsgáltuk, elemzést nyújtottunk egy többnyelvű NMT rendszer morfológiailag gazdag és alacsony erőforrású nyelvek fordításának hatékonyságáról a nulla erőforrású nyelvek fordításában. Annak érdekében, hogy tovább értékeljük a többnyelvű NMT modell képességét a láthatatlan nyelvpárok fordítására a képzés során, teszteltük a tagalog és Cebuano közötti fordításra szánt modellt, és összehasonlítottuk teljesítményét egy egyszerű NMT modellel, amely közvetlenül képzett tagalog és cebuano adatokon alapul, amelyekben kimutattuk, hogy a zero-shot fordítás bizonyos esetekben felülmúlja a közvetlenül képzett modellt, miközben az angol nyelvet fordítási nyelvként használja, mindkét megközelítést felülmúlja.</abstract_hu>
      <abstract_el>Οι Φιλιππίνες είναι η πατρίδα για περισσότερες από 150 γλώσσες που θεωρείται ότι έχουν χαμηλούς πόρους ακόμη και στις κύριες γλώσσες τους. Αυτό οδηγεί σε έλλειψη επιδίωξης για την ανάπτυξη ενός συστήματος μετάφρασης για τις υποεκπροσωπούμενες γλώσσες. Για να απλουστευθεί η διαδικασία ανάπτυξης συστήματος μετάφρασης για πολλαπλές γλώσσες και να βοηθήσει στη βελτίωση της ποιότητας μετάφρασης γλωσσών μηδενικών σε γλώσσες χαμηλής περιεκτικότητας σε πόρους, η πολυγλωσσική NMT έγινε ένας ενεργός τομέας έρευνας. Ωστόσο, τα υπάρχοντα έργα στο πολυγλωσσικό NMT αγνοούν την ανάλυση ενός πολυγλωσσικού μοντέλου σε μια στενά συνδεδεμένη και χαμηλής περιεκτικότητας γλωσσική ομάδα στο πλαίσιο της μετάφρασης με βάση τον άξονα και της μετάφρασης μηδενικού πυροβολισμού. Στην παρούσα εργασία, αξιολογήσαμε τη μετάφραση για αρκετές Φιλιππινέζικες γλώσσες, παρείχαμε μια ανάλυση ενός πολύγλωσσου συστήματος για μορφολογικά πλούσιες και χαμηλής περιεκτικότητας σε γλώσσες όσον αφορά την αποτελεσματικότητά του στη μετάφραση γλωσσών μηδενικού πόρου με μεταφράσεις μηδενικού σκοπού. Για να αξιολογηθεί περαιτέρω η ικανότητα του πολύγλωσσου μοντέλου NMT στη μετάφραση αθέητων γλωσσικών ζευγαριών στην εκπαίδευση, δοκιμάσαμε το μοντέλο μετάφρασης μεταξύ Tagalog και Cebuano και συγκρίναμε την απόδοσή του με ένα απλό μοντέλο NMT που εκπαιδεύεται άμεσα σε παράλληλα δεδομένα Tagalog και Cebuano στα οποία αποδείξαμε ότι η μηδενική μετάφραση ξεπερνά ένα άμεσα εκπαιδευμένο μοντέλο σε ορισμένες περιπτώσεις, ενώ χρησιμοποιεί τα Αγγλικά ως βασική γλώσσα στη μετάφραση ξεπερνά και τις δύο προσεγγίσεις.</abstract_el>
      <abstract_ka>ფილიპინები 150-ზე მეტი ენების სახლში, რომლებიც აღმოჩნდება, რომ მისი დიდი ენაზე უფრო დამატებულია. ეს შეიძლება შემდეგ გადაწყვეტილი სისტემის განვითარებაში, რომელიც არაფერად გადაწყვეტილი ენებისთვის. მრავალური ენების განვითარების პროცესის განვითარება და უფრო მეტი ენების განვითარების გასაკეთებლად ნულის უფრო მეტი რესურსის ენების გასაკეთებლად, მრავალური NMT იყო აქტიური განსხვ მაგრამ, მრავალენგური NMT-ში მუშაობაში მრავალენგური მოდელის ანალიზაციას არ უნდა დაახლოებით და ცოტა რესურსის ენის ჯგუფის კონტექსტში pivot-დაბათებული თარგუმების და nul-shot ამ დომენტში, ჩვენ ბენქმარტირებულია რამდენიმე ფილიპიონიური ენათებისთვის, მრავალენგური NMT სისტემის ანალიზაციას მორპოლოგიურად ბეჭდვი და ცოტა რესურსის ენათებისთვის ეფექტიურობის შესა დამატებით მრავალური NMT მოდელის შესაძლებლობას შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი NMT მოდელით, რომელიც პონალელურ როცა ინგლისური სიტყვალის გამოყენება როგორც პირველი სიტყვალის გამოყენებაში გამოყენება.</abstract_ka>
      <abstract_isl>Filippínar eru heima til meira en 150 tungumál sem talin er lítil auðlinda jafnvel á stóru tungumálinu. Þetta leiðir til skorts á eftirliti með því a ð þróa þýðingarkerfi fyrir ófullnægjandi tungumál. Til að einfalda ferlið til að þróa þýðingarkerfi fyrir mörg tungumál og hjálpa til við að bæta þýðingargæði núll í tungumál með lítil áhrif, varð fjöltunguleg NMT virkt svæði rannsóknar. Hins vegar eru verk sem eru til staðar í fjöltungu NMT ekki tekin tillit til greiningar á fjöltungu líkani á náið tengdum og litlum upprunalegum tungumálhópi í tengslum við þýðingu sem byggir á lykjum og núll-mynd þýðingu. Í þessu blaði höfum við borið saman þýðingu fyrir nokkrar Filippínska tungur, greiningu á fjöltungu NMT kerfi fyrir myndfræðilega ríka og litla auðlinda tungumál hvað varðar virkni þess við þýðingu núll auðlinda tungumál með núll-skot þýðingu. Til a ð meta frekar hæfni fjöltungu NMT líkans við þýðingu ósýnilegra tungumál í þjálfun prófuðum við líkann til að þýða milli Tagalog og Cebuano og borðum saman framkvæmd þess við einfalda NMT líkan sem er beint þjálfað á samhliða Tagalog og Cebuano gögnum þar sem við sýndum að núll-skot þýðing er meiri en beint þjálfað líkan í sumum tilvikum, - á meðan ensku er notað sem lykiltungumál við þýðingu framleiðir báðar a ðferðir.</abstract_isl>
      <abstract_kk>Филиппиндер 150-ден артық тілдерді өзінің негізгі тілдерінде де төмен ресурстар деп ойлайды. Бұл аудармалы тілдердің аудармалы жүйесін жасау үшін жоқ болады. Бірнеше тілдердің аудармалы жүйесін жасау және нөл тілдердің аудармалы сапатын төмен ресурстар тілдеріне жақсарту үшін көмектесу үшін, көп тілдердің NMT белсенді зерттеу аумағы болды. Бірақ көп тілді NMT жұмыс істерінде көп тілді моделінің анализациясын, pivot- негізінде аудару және нөл- шоттың аудармасының контексті жақын және төмен ресурстар тілді тобына қатысты. Бұл қағазда бірнеше Филиппин тілдері үшін аудармасын белгілеп, морфологиялық және төмен ресурс тілдері үшін нөл ресурс тілдерін аудару үшін бірнеше тілді NMT жүйесін анализ етіп бердік. Тагалог мен Себуано арасында аудару үшін көптеген NMT үлгісінің мүмкіндігін бағалау үшін, біз түрлі тілдер екеуін аудару үшін моделін тексердік және оның әрекетін кейбір мәселелерде параллелі тагалог мен Себуано деректеріне тәуелдірілген қарапайым NMT үлгісімен салыстырып, біз нөл Ағылшынша тілді жалпы тілді аудару үшін екі жағдай жағдайды қолдануға болады.</abstract_kk>
      <abstract_it>Le Filippine ospitano più di 150 lingue che sono considerate scarse risorse anche nelle lingue principali. Ciò comporta una mancanza di impegno nello sviluppo di un sistema di traduzione per le lingue sottorappresentate. Per semplificare il processo di sviluppo del sistema di traduzione per più lingue e per contribuire a migliorare la qualità della traduzione delle lingue da zero a basse risorse, la NMT multilingue è diventata un'area attiva di ricerca. Tuttavia, i lavori esistenti in NMT multilingue ignorano l'analisi di un modello multilingue su un gruppo linguistico strettamente correlato e a basso contenuto di risorse nel contesto della traduzione basata su pivot e della traduzione zero-shot. In questo articolo, abbiamo valutato la traduzione comparativa per diverse lingue filippine, fornito un'analisi di un sistema NMT multilingue per lingue morfologicamente ricche e a basso contenuto di risorse in termini di efficacia nella traduzione di lingue a zero risorse con traduzioni zero-shot. Per valutare ulteriormente la capacità del modello NMT multilingue di tradurre coppie linguistiche invisibili in formazione, abbiamo testato il modello da tradurre tra Tagalog e Cebuano e confrontato le sue prestazioni con un semplice modello NMT che è direttamente addestrato su dati paralleli Tagalog e Cebuano in cui abbiamo dimostrato che la traduzione zero-shot supera un modello addestrato direttamente in alcuni casi, mentre l'inglese come lingua pivot nella traduzione supera entrambi gli approcci.</abstract_it>
      <abstract_lt>Filipinuose yra daugiau kaip 150 kalbų, kurios laikomos mažai išteklių netgi pagrindinėmis kalbomis. Dėl to trūksta pastangų kurti vertimo sistemą nepakankamai atstovaujamoms kalboms. Siekiant supaprastinti kelių kalbų vertimo sistemos kūrimo procesą ir padėti gerinti vertimo kokybę nuo nulio iki mažai išteklių turinčių kalbų, daugiakalbė NMT tapo aktyvia mokslinių tyrimų sritimi. Tačiau esamuose daugiakalbių NMT kūriniuose neatsižvelgiama į daugiakalbio modelio analizę glaudžiai susijusioje ir mažai išteklių turinčioje kalbų grupėje, atsižvelgiant į vertimą žodžiu ir vertimą nuliniu atžvilgiu. In this paper, we benchmarked translation for several Philippine Languages, provided an analysis of a multilingual NMT system for morphologically rich and low-resource languages in terms of its effectiveness in translating zero-resource languages with zero-shot translations.  Siekdami toliau įvertinti daugiakalbio NMT modelio gebėjimą išversti nematomų kalbų porų mokymo metu, mes išbandėme model į išversti tarp Tagalog ir Cebuano ir palyginome jo rezultatus su paprastu NMT modeliu, kuris tiesiogiai mokomas lygiagrečiais Tagalog ir Cebuano duomenimis, kuriuose parodėme, kad nulinis vertimas kai kuriais atvejais yra didesnis už tiesiogiai mokomą modelį, Vertinant anglų kalbą vertimas viršija abu metodus.</abstract_lt>
      <abstract_ml>ഫിലിപ്പൈന്‍സ് 150 ഭാഷകള്‍ക്ക് കൂടുതല്‍ വീട്ടിലാണ്. അതിന്റെ പ്രധാനഭാഷകളില്‍ പോലും കുറഞ്ഞ വിഭവങ്ങള്‍ വിചാര ഇത് പ്രതിനിധിക്കപ്പെട്ട ഭാഷകള്‍ക്കുള്ള ഒരു പരിഭാഷയുടെ സിസ്റ്റത്തിന്റെ പിന്തുടരുന്നതിന്റെ കുറവാണ പല ഭാഷകള്‍ക്ക് വേണ്ടി പരിഭാഷപ്രക്രിയയുടെ പ്രക്രിയയെ ലളിതമാക്കുവാനും, പൂജ്യത്തിന്റെ വിഭാഷകളുടെ വിഭാഷപ്രഭാഷണത്തിന്റെ ഗുണവും കുറഞ എന്നാലും പിവോട്ട് അടുത്തുചേര്‍ത്ത് ബന്ധപ്പെട്ടിരിക്കുന്ന, കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷ കൂട്ടത്തില്‍ പല ഭാഷകങ്ങളിലുള്ള NMT-ല്‍ നിലവിലുള്ള ഈ പത്രത്തില്‍ ഞങ്ങള്‍ പല ഫിലിപ്പൈന്‍ ഭാഷകള്‍ക്കും വേണ്ടി പരിഭാഷപ്പെടുത്തിയിരിക്കുന്നു. മൊര്‍ഫോളജിക്കല്‍ സമ്പന്നരും കുറഞ്ഞ വിഭവഭാഷകള്‍ക്കും ഒരു മണ്ണില്‍ NMT സിസ്റ് അഭൌതിക ഭാഷയിലെ ജോടികളെ പരിശീലിപ്പിക്കുന്നതിന്റെ കഴിവിന്റെ അധികാരത്തെക്കുറിച്ച് വിശദീകരിക്കാന്‍, ടാഗാലോഗിനും സെബുയാനോയുടെയും ഇടയില്‍ പരിഭാഷപ്പെടുത്താന്‍ മോഡല്‍ പരീക്ഷിച്ചു, അതിന്റെ പ്രദര്‍ശനം നേ ഇംഗ്ലീഷില്‍ ഒരു പിവോട്ട് ഭാഷ ആയി ഉപയോഗിക്കുമ്പോള്‍ രണ്ട് പ്രാവശ്യം പരിഭാഷപ്പെടുത്തുന്നതില്‍.</abstract_ml>
      <abstract_ms>The Philippines is home to more than 150 languages that is considered to be low-resourced even on its major languages.  Ini menghasilkan kekurangan pengejaran dalam mengembangkan sistem terjemahan untuk bahasa yang tidak terwakil. Untuk mempermudahkan proses pembangunan sistem terjemahan untuk berbilang bahasa, dan untuk membantu memperbaiki kualiti terjemahan sifar ke bahasa sumber rendah, NMT berbilang bahasa menjadi kawasan penyelidikan aktif. Namun, kerja yang wujud dalam NMT berbilang bahasa mengabaikan analisis model berbilang bahasa pada kumpulan bahasa yang berkaitan dan sumber rendah dalam konteks terjemahan berdasarkan pivot dan terjemahan-sifar. Dalam kertas ini, kami benchmarked terjemahan untuk beberapa Bahasa Filipina, menyediakan analisis sistem NMT berbilang bahasa untuk bahasa yang kaya secara morfologik dan sumber rendah dalam terma efektif dalam terjemahan bahasa sumber-sifar dengan terjemahan-sifar. Untuk meneliti lebih lanjut kemampuan model NMT berbilang bahasa dalam menerjemahkan pasangan bahasa yang tidak terlihat dalam latihan, kami menguji model untuk menerjemahkan antara Tagalog dan Cebuano dan membandingkan prestasinya dengan model NMT sederhana yang secara langsung dilatih pada data Tagalog dan Cebuano paralel di mana kami menunjukkan bahawa terjemahan-sifar melampaui model yang dilatih langsung dalam beberapa kes, Sementara menggunakan bahasa Inggeris sebagai bahasa pivot dalam menerjemahkan melampaui kedua-dua pendekatan.</abstract_ms>
      <abstract_mk>Филипините се наоѓаат во дом на повеќе од 150 јазици кои се сметаат за ниски ресурси дури и на своите главни јазици. Ова резултира со недостаток на потрага за развој на преведувачки систем за недопретставени јазици. За да го поедностави процесот на развој на преводен систем за повеќе јазици и да помогне во подобрувањето на квалитетот на превод на нула на јазици со ниски ресурси, мултијазичниот НМТ стана активна област на истражување. Сепак, постоечките дела во мултијазичниот НМТ ја игнорираат анализата на мултијазичен модел на блиски поврзана и нискоресурсна јазичка група во контекст на превод базиран на пивот и нултиран превод. Во овој весник, ние го проценивме преводот за неколку филипински јазици, обезбедивме анализа на мултијазичен НМТ систем за морфолошки богати и ниски ресурси јазици во поглед на неговата ефикасност во преводот на јазици со нула ресурси со нула превод. За понатамошна проценка на способноста на мултијазичниот модел на НМТ во преведувањето на невидливи јазички парови во обуката, го тестиравме моделот за преведување помеѓу Тагалог и Чебано и ја споредивме неговата резултат со едноставен НМТ модел кој е директно обучен на паралелни податоци на Тагалог и Чебано во кои покажавме дека нуларниот превод во некои - додека англискиот јазик се користи како вртен јазик во преведувањето на двете пристапи.</abstract_mk>
      <abstract_mt>Il-Filippini għandhom aktar minn 150 lingwa li huma meqjusa li għandhom riżorsi baxxi anke fil-lingwi ewlenin tagħhom. Dan jirriżulta f’nuqqas ta’ segwitu fl-iżvilupp ta’ sistema ta’ traduzzjoni għall-lingwi sottorappreżentati. To simplify the process of developing translation system for multiple languages, and to aid in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research.  Madankollu, xogħlijiet eżistenti f’NMT multilingwi ma jikkunsidrawx l-analiżi ta’ mudell multilingwi fuq grupp lingwistiku relatat mill-qrib u b’riżorsi baxxi fil-kuntest ta’ traduzzjoni bbażata fuq il-pivot u traduzzjoni b’zero shot. F’dan id-dokument, a ħna kklassifikajna t-traduzzjoni għal diversi Lingwi Filippini, ipprovdejna analiżi ta’ sistema NMT multilingwi għal lingwi morfoloġikament rikki u b’riżorsi baxxi f’termini tal-effettività tagħha fit-traduzzjoni ta’ lingwi b’riżorsi żero bi traduzzjonijiet mingħajr skop. Biex tivvaluta aktar il-kapaċità tal-mudell multilingwi NMT fit-traduzzjoni ta’ pari lingwistiċi mhux viżibbli fit-taħriġ, ittestjajna l-mudell għat-traduzzjoni bejn Tagalog u Cebuano u qabblu l-prestazzjoni tiegħu ma’ mudell sempliċi NMT li huwa mħarreġ direttament fuq dejta parallel a Tagalog u Cebuano li fiha wrew li t-traduzzjoni mingħajr skop tirrappreżenta mudell imħarreġ direttament f’xi każijiet, • waqt li tuża l-Ingliż bħala lingwa ewlenija fit-traduzzjoni tirrappreżenta ż-żewġ approċċi.</abstract_mt>
      <abstract_no>Filipinane er heime til fleire enn 150 språk som vert anslått for å vera låg ressursert sjølv på dei store språka. Dette resulterer i ein mangling av følgje i å utvikla eit omsetjingssystem for dei underrepresenterte språka. For å forenkla prosessen for å utvikla omsetjingssystemet for fleire språk, og for å hjelpa med å forbetra omsetjingskvaliteten til null til låg ressursspråk, ble fleirspråk NMT ein aktiv forskningsområde. Det eksisterande arbeider imidlertid i fleirspråk NMT, vil ikkje gjere analysen av ein fleirspråk modell på ein nærare relatert og låg ressursspråk-gruppe i konteksten av omsetjing basert på pivot og null-skot. I denne papiret har vi benchmarkerte omsetjinga for fleire Filippinske språk, og oppgjeve ein analyse av ein multispråk NMT-system for morfologisk rike og låg ressursspråk i uttrykk av effektiviteten til å omsetja null-ressursspråk med null-skriftomsetjingar. For å meir evaluera kapasiteten for multispråk NMT-modellen i å oversette ugjennomsiktige språkparar i opplæring, testa vi modellen for å oversette mellom Tagalog og Cebuano og samanlikna utviklinga med ein enkel NMT-modell som er direkte trent på ein parallell Tagalog og Cebuano-data, der vi viste at nullstort-omsetjinga utfører eit direkte trent modell i nokre instansar, Med å bruka engelsk som ein pivotspråk i omsetjinga utføra begge tilnærmingar.</abstract_no>
      <abstract_pl>Filipiny są domem dla ponad 150 języków, które są uważane za niskie zasoby nawet w swoich głównych językach. Skutkuje to brakiem dążenia do opracowania systemu tłumaczeń dla niedostatecznie reprezentowanych języków. W celu uproszczenia procesu opracowywania systemu tłumaczeń dla wielu języków oraz pomocy w poprawie jakości tłumaczeń języków zerowych na języki niskich zasobów, wielojęzyczne NMT stało się aktywnym obszarem badań. Jednakże istniejące prace w wielojęzycznym NMT nie uwzględniają analizy modelu wielojęzycznego na ściśle powiązanej i niskiej ilości zasobów grupie językowej w kontekście tłumaczenia pivot-based i zero-shot. W niniejszym artykule porównaliśmy tłumaczenia dla kilku języków filipińskich, przeprowadziliśmy analizę wielojęzycznego systemu NMT dla języków bogatych morfologicznie i niskich zasobów pod kątem jego skuteczności w tłumaczeniu języków zero-resource z tłumaczeniami zero-shot. Aby dokładniej ocenić możliwości wielojęzycznego modelu NMT w tłumaczeniu niewidocznych par językowych w szkoleniu, przetestowaliśmy model do tłumaczenia pomiędzy Tagalog i Cebuano i porównaliśmy jego wydajność z prostym modelem NMT, który jest bezpośrednio trenowany na równoległych danych Tagalog i Cebuano, w których wykazaliśmy, że tłumaczenie zero-shot przewyższa model bezpośrednio przeszkolony w niektórych przypadkach, Podczas wykorzystania języka angielskiego jako języka pivot w tłumaczeniu przewyższa oba podejścia.</abstract_pl>
      <abstract_ro>Filipine găzduiește peste 150 de limbi care sunt considerate a fi cu resurse reduse chiar și în limbile sale majore. Acest lucru duce la o lipsă de efort în dezvoltarea unui sistem de traducere pentru limbile subreprezentate. Pentru a simplifica procesul de dezvoltare a sistemului de traducere pentru mai multe limbi și pentru a ajuta la îmbunătățirea calității traducerii de la zero la limbi cu resurse reduse, NMT multilingv a devenit un domeniu activ de cercetare. Cu toate acestea, lucrările existente în NMT multilingv ignoră analiza unui model multilingv pe un grup lingvistic strâns înrudit și cu resurse reduse în contextul traducerii bazate pe pivot și al traducerii zero-shot. În această lucrare, am evaluat traducerea comparativă pentru mai multe limbi filipineze, am oferit o analiză a unui sistem multilingv NMT pentru limbi bogate din punct de vedere morfologic și cu resurse reduse în ceea ce privește eficiența sa în traducerea limbilor cu resurse zero cu traduceri zero-shot. Pentru a evalua în continuare capacitatea modelului multilingv NMT în traducerea perechilor de limbi nevăzute în curs de formare, am testat modelul de traducere între Tagalog și Cebuano și am comparat performanța acestuia cu un model simplu NMT instruit direct pe date paralele Tagalog și Cebuano în care am arătat că traducerea zero-shot depășește un model instruit direct în unele cazuri, în timp ce utilizarea limbii engleze ca limbă pivot în traducere depășește ambele abordări.</abstract_ro>
      <abstract_mn>Филиппинууд 150-аас илүү олон хэл байдаг. Үндсэн хэл дээр ч бага байдаг. Энэ нь бага зэрэг дүрслэгдсэн хэл дээр орчуулах системийг хөгжүүлэхэд хүлээн зөвшөөрөхгүй байдаг. Ихэнх хэл дээр орчуулах системийг хөгжүүлэхийн тулд хялбарчлах, тэгш хэл дээр бага боловсролын хэл руу хөгжүүлэхийн тулд олон хэл NMT нь судалгааны актив хэсэг болсон. Гэхдээ олон хэлний NMT-д байгаа ажиллагаа нь pivot-д суурилсан орнууд болон 0-шүтлэг орнуудын тухай ойролцоогоор хамааралтай, бага нөөц хэлний хэл бүлэгтэй олон хэлний загварын шинжилгээг анзаарахгүй. Энэ цаасан дээр бид олон Филиппин хэл дээр орчуулагдсан, олон хэл NMT системийн талаар морфологийн баян болон бага баялаг асуудлын хэл дээр 0-нүүрстөрөгчийн хэл болон 0-нүүрстөрөгчийн орчуулалтын үр дүнтэй талаар шинжилгээ өгсөн. Олон хэлний NMT загварын чадварыг дахин үнэлэхэд бид тагалог болон Себуано хоорондын оролцох загварыг шалгаж, үүнийг параллел Тагалог болон Себуано өгөгдлийн дээр шууд сургалтын загвартай харьцуулсан энгийн NMT загвартай харьцуулсан. Тэр үед 0-шарх орноос шууд сургалтын загварыг зарим тохиолдлуудад Англи хэлний хувьд хоёр ойлголтыг илэрхийлж чаддаг.</abstract_mn>
      <abstract_sr>Filipini su domaći više od 150 jezika koje se smatra niskim resursima čak i na svojim velikim jezicima. To rezultira u nedostatak traženja u razvoju prevodnog sistema za nepreprezentativne jezike. Da bi se pojednostavili proces razvoja prevodnog sistema za višestruke jezike i pomogla u poboljšanju kvalitete prevoda nule na jezike niskih resursa, multijezički NMT postao je aktivan područje istraživanja. Međutim, postojeći rad u multijezičkim NMT-ima odbacuje analizu multijezičkog model a o bliskom povezanim i niskim jezičkim grupama u kontekstu prevoda na pivotu i prevoda na nulu. U ovom papiru smo prevodili prevod za nekoliko Filipinskih jezika, pružili analizu multijezičkog NMT-ovog sistema za morfološki bogate i niske resurse u smislu njene efikasnosti u prevodu jezika nula resursa sa sa nulom prevodom. Da bismo dalje procenili sposobnost multijezičkog model a NMT-a u prevodu nevidljivih jezičkih parova u obuci, testirali smo model da prevodi između Tagaloga i Cebuana i usporedili njegove izvedbe sa jednostavnim modelom NMT-a koji je direktno obučen na paralelnim podacima Tagaloga i Cebuana u kojima smo pokazali da prevod nule-snimke iznosi direktno obučen model u nekim slučajevima, Dok se koristi engleski kao jezik pivot a u prevodu nadmaženja obje pristupe.</abstract_sr>
      <abstract_so>Filipinos wuxuu ku yaalaa in ka badan 150 luqadood oo loo tiriyo in ay tahay in laga soo qaato xitaa luqadaha ugu waaweyn. Taas waxay sababtaa u baahnaanshaha horumarinta nidaamka turjumista ee luqadaha laga soo bandhigayo. Si loo fududeeyo baaritaanka horumarinta nidaamka turjumista ee luuqado kala duduwan, iyo in lagu caawiyo hagaajinta tarjumaadda qiimaha zero-hoose-resource luqadaha, waxaa laga noqday qayb aad u shaqeeya waxbarasho. Si kastaba ha ahaatee, shuqullada ku jira oo ku qoran af luuqado kala duduwan NMT wuxuu ka jeedaa analysis of model luuqadeed oo ku qoran koox luuqadeed ku dhow oo ku saabsan iyo hoos-hoos-resource koox ku qoran turjuman pivot-based iyo zero-shot. Kanu warqadan, waxaynu ku qornay tarjumaan luuqado badan oo Filipino ah, waxaana sameynay analysis of a system of NMT oo luuqadaha luuqadaha kala duduwan oo morphologically hodan iyo hoos-resource luqadaha ku saabsan faa’iidadooda turjumidda luqadaha zero-resource with zero-shot turjuman. Si aan u sii qiimeyno awoodda modelka afka kala duduwan oo aan ku turjumno labo labo ah oo aan aqoonin luuqadaha, waxaan imtixaanay modelka si aan u tarjumno between Tagalog iyo Cebuano, waxaana sameynnay sameynta sameynta sameynta noocyo fudud oo u sahlan muusikada NMT oo toos loo baray parallel Tagalog iyo Cebuano data, taasoo aan tusnay in tarjuma nuurka-shot uu sameeyo model toos wax baran qaarkood, Inta lagu isticmaalayo Ingiriiska sida luqada pivot oo lagu turjumayo labada qaabilaad.</abstract_so>
      <abstract_sv>Filippinerna är hem för mer än 150 språk som anses ha låga resurser även på sina större språk. Detta leder till bristande strävan efter att utveckla ett översättningssystem för de underrepresenterade språken. För att förenkla processen med att utveckla översättningssystem för flera språk och för att bidra till att förbättra översättningskvaliteten för noll till lågresursspråk blev flerspråkig NMT ett aktivt forskningsområde. I befintliga verk inom flerspråkig NMT bortses dock analysen av en flerspråkig modell på en nära besläktad och resurssnål språkgrupp i samband med pivot-baserad översättning och noll-shot översättning. I denna uppsats har vi benchmarkat översättning för flera filippinska språk, gett en analys av ett flerspråkigt NMT-system för morfologiskt rika och lågresursspråk i termer av dess effektivitet när det gäller att översätta nollresursspråk med noll-shot översättningar. För att ytterligare utvärdera den flerspråkiga NMT-modellens förmåga att översätta osynliga språkpar under utbildningen testade vi modellen att översätta mellan tagalog och cebuano och jämförde dess prestanda med en enkel NMT-modell som är direkt utbildad på en parallell tagalog och cebuano data där vi visade att noll-skott översättning överträffar en direkt utbildad modell i vissa fall. samtidigt som engelska används som ett pivot språk i översättning överträffar båda tillvägagångssätten.</abstract_sv>
      <abstract_ta>பிலிப்பைன்ஸ் 150 க்கு மேற்பட்ட மொழிகளுக்கு வீட்டில் உள்ளது அது அதன் முக்கிய மொழிகளில் கூட குறைந்த வளர்ச் இது குறைந்த மொழிகளுக்கு ஒரு மொழிபெயர்ப்பு அமைப்பை உருவாக்குவதற்கான குறைவாக முடியாது. பல மொழிகளுக்கான மொழிமாற்று மொழிகளை உருவாக்குவதற்கான முயற்சியை எளிதாக்குவதற்காகவும், பூஜ்ஜியின் மொழிமாற்ற மொழிகளின் மொழிமாற்று தர பிவாட்- அடிப்படையில் உள்ள மொழிமாற்றம் மற்றும் பூச்சு- ஷாட் மொழிமாற்றும் மொழி குழுவில் பல மொழிகளில் உள்ள வேலைகளை புறக்கணிக்கவில்லை. இந்த காக்கியத்தில், நாம் பல பிலிப்பைன் மொழிகளுக்கான மொழிபெயர்ப்பை பொருளாக்கி விட்டோம். மொழிபெருமையாக வளர்ந்த மற்றும் குறைந்த மூலம் மொழிகளை பூஜ்ஜியமாக ம மேலும் பல மொழி NMT மாதிரியின் தன்மையை மொழிபெயர்த்தும் மறையாத மொழி ஜோடிகளை பயிற்சியில் மொழிபெயர்ப்பதற்கு, நாம் மாதிரி மொழியை மொழிபெயர்ப்பதற்கு, Tagalog மற்றும் செபுயானோவுக்கும் இடையே மாற்ற முடியும் மற ஆங்கிலத்தை பிவாட் மொழியாக பயன்படுத்தும் போது இரு வழிகளையும் மொழிபெயர்ப்பில்.</abstract_ta>
      <abstract_si>ෆිලිපින්ස් වල භාෂා 150ක් වඩා වඩා ගෙදර ඉන්නවා ඒ භාෂාවට අඩු භාෂාවක් තියෙනවා. මේක ප්‍රතිචාරයක් නැති භාෂාවක් විශ්වාසයෙන් පරිවර්තන පද්ධතියක් නිර්මාණය කරනවා. ගොඩක් භාෂාව සඳහා වාර්ථාව පද්ධතිය විස්තර කරන්න, සුන්ධ භාෂාව සඳහා වාර්ථාව ක්‍රියාත්මක විශේෂය සඳහා උදව් කරන්න, බො නමුත්, බොහොම භාෂාවක් NMT වලින් තියෙන්නේ විශ්ලේෂණය ගොඩක් භාෂාවක් වලින් සම්බන්ධ වලින් සම්බන්ධ වලින් භාෂාවක් වල මේ පැත්තේ, අපි ෆිලිපින් භාෂාවක් වලින් භාෂාවක් වෙනුවෙන් බෙන්ච්මාර්ක් කළා, විශ්ලේෂණයක් ගොඩක් භාෂා NMT පද්ධතියේ විශ්ලේෂණ අපි ටැගොලෝග් සහ සෙබුයානෝ අතර පරිවර්තනය කරන්න පුළුවන් වැඩි භාෂාවික NMT මොඩේල් එක්ක සමහර විශ්වාස කරන්න, අපි පරීක්ෂා කරලා තැගොලෝග් සහ සෙබුයානෝ දත්තේ සමහර විශ්වාස කරලා තැගො ඉංග්‍රීසි භාෂාව ප්‍රයෝජනය කරන්න පුළුවන් දෙන්නම ප්‍රයෝජනය කරන්න.</abstract_si>
      <abstract_ur>فلیپین 150 سے زیادہ زبان کے گھر ہیں جن کو اس کی بڑی زبانوں پر بھی کم سازی سمجھا جاتا ہے۔ اس کا نتیجہ اس کے پیچھے کمی کی زبانوں کے لئے ایک ترجمہ سیسٹم کو ایجاد کرنے کے لئے ہے۔ بہت سی زبانوں کے لئے ترجمہ سیسٹم کی پیدائش کو سادھا کرنے کے لئے، اور صفر کی ترجمہ کیفیت کو کم رسسوس زبانوں تک بہتر کرنے کے لئے مدد کرنے کے لئے، بہت سی زبان کی NMT نے تحقیق کا فعال منطقه بنایا۔ However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation. اس کاغذ میں ہم نے چند فیلیپین زبانوں کے لئے ترجمہ سنچم کر دیا، ایک متعدد زبان NMT سیستم کی تحلیل دے دی کہ اس کی عمدگی کے مطابق صفر-منبع زبانوں کو صفر-شٹ ترجمہ کے مطابق اس کی فعالیت کے مطابق اس کے منبع زبانوں کے ذریعہ مطابق کریں۔ ہم نے ٹاگلوگ اور سیبوانو کے درمیان ترجمہ کرنے کے لئے مدلک کی بہت سی زبانی NMT موڈل کے قابلیت کا مطالبہ تحقیق کرنے کے لئے آزمائش کی اور اس کی عملیات کو ایک ساده NMT موڈل کے ساتھ مطالبہ کردیا ہے جو مستقیماً ایک ٹاگلوگ اور سیبوانو ڈیٹے پر تطالب کی جاتی ہے جس میں ہم نے دکھایا ہے کہ صفر-شٹ ترجمہ ایک مستقیما ترجمہ موڈل کو جب انگلیسی کو پیوٹ زبان کے طور پر استعمال کرتا ہے تو دونوں طریقے سے زیادہ اضافہ کرتا ہے</abstract_ur>
      <abstract_vi>The Philippines ở nhiều ngôn ngữ hơn 150 mà được cho là rất ít nguồn lực kể cả ở các ngôn ngữ chính của mình. Điều này dẫn đến việc thiếu nỗ lực phát triển một hệ thống dịch chuyển cho các ngôn ngữ kém đại diện. Để đơn giản tiến trình phát triển hệ thống dịch cho nhiều ngôn ngữ, và để giúp cải thiện chất lượng dịch không đến các ngôn ngữ có nguồn ít, NMB đa dạng đã trở thành một khu vực nghiên cứu tích cực. Tuy nhiên, các tác phẩm đa dạng NMT đã bỏ qua việc phân tích một mô hình ngôn ngữ đa dạng về một nhóm ngôn ngữ có liên quan và ít tài nguyên trong phạm vi dịch vụ pivot và dịch không bắn. Trong tờ giấy này, chúng tôi phân tích cách dịch phân tích nhiều ngôn ngữ Philippines, cung cấp một bản phân tích một hệ thống NMT đa dạng cho ngôn ngữ giàu có và ít tài nguyên theo hướng nó có hiệu quả dịch ngôn ngữ không nguyên liệu bằng cách bắn súng. Để đánh giá thêm khả năng của mô hình NMB ngôn ngữ đa dạng trong khi dịch chuyển một cặp ngôn ngữ vô hình trong huấn luyện, chúng tôi đã thử nghiệm mô hình dịch giữa Tagalog và Cebuano và so sánh thành quả của nó với một mô hình NMB đơn giản được huấn luyện trực tiếp trên một dữ liệu đồng của Tagalog và Cebuano mà chúng tôi đã cho thấy rằng dịch không bắn hoàn thành một mô hình được huấn luyện trực tiếp trong một số trường hợp, sử dụng tiếng Anh như một ngôn ngữ pivot trong dịch thành hai phương pháp.</abstract_vi>
      <abstract_uz>Filippining eng 150 tildan ortiq uy bo'ladi. Bu o'z asosiy tillarda ko'proq murakkab bo'lishi deb hisoblanadi. Bu natijada tashqi tillar uchun tarjima tizimni yaratishda yetishmaydi. Bir necha tillar uchun tarjima tizimni tahrirlash jarayoni soddalashtirish uchun va bir necha tillar uchun tarjima sifatini o'zgartirish uchun yordam berish uchun muloqat tili NMT taʼminlovchisi bo'ldi. Ammo, bir necha tilda (NMT) mavjud vazifalar pivot- asosiy tarjima va null- shot tarjima tarjima tarjima tarjimasida bir necha tillar modeli aniqlanishga eʼtibor berilmadi. In this paper, we benchmarked translation for several Philippine Languages, provided an analysis of a multilingual NMT system for morphologically rich and low-resource languages in terms of its effectiveness in translating zero-resource languages with zero-shot translations.  Ko'pchilik NMT modelini o'rganish uchun, biz tagalog va Cebuano орасида tarjima qilish modelini o'rganish uchun modelni sinab ko'rsatdik va uning natijasini oddiy NMT modelida o'rganish uchun oddiy nazar tagalog va Cebuano maʼlumot bilan o'rganish mumkin. Mana shu yerda zero'n tarjima qilishni bir xil tilda o'rganish modelini ko'rsatdik, Inglizcha tilni pivot sifatida ishlatishda ikkita usullarni tarjima qilish uchun.</abstract_uz>
      <abstract_bg>Филипините са дом на повече от 150 езика, които се смятат за нискоресурсни дори на основните си езици. Това води до липса на стремеж към разработване на преводаческа система за недостатъчно представените езици. За да се опрости процеса на разработване на преводаческа система за множество езици и да се подпомогне подобряването на качеството на превода от езици с нулев до ниско ресурс, многоезичната НМТ стана активна област на научни изследвания. Съществуващите произведения в многоезичната НМТ обаче пренебрегват анализа на многоезичен модел върху тясно свързана и нискоресурсна езикова група в контекста на превода, базиран на пивот и нулев превод. В тази статия сравнихме превода на няколко филипински езика, предоставихме анализ на многоезична система за езика с морфологично богати и нискоресурсни езици по отношение на ефективността й при превода на езици с нулеви ресурси с нулеви преводи. За по-нататъшна оценка на способността на многоезичния модел за превеждане на невиждани езикови двойки по време на обучение, тествахме модела за превеждане между тагалог и цебуано и сравнихме ефективността му с прост модел, който е директно обучен на паралелни тагалогски и цебуански данни, в които показахме, че нулевият превод в някои случаи надминава пряко обучен модел, докато използването на английски като основен език при превода надминава двата подхода.</abstract_bg>
      <abstract_hr>Filipini su domaći više od 150 jezika koje se smatra niskim resursima čak i na svojim glavnim jezicima. To rezultira u nedostatku potrage za razvojom sustava prevoda za nepreprezentativne jezike. Kako bi se pojednostavio proces razvoja sustava prevoda za višestruke jezike i pomoći u poboljšanju kvalitete prevoda nule na jezike niskih resursa, multijezički NMT postao je aktivan područje istraživanja. Međutim, postojeći radovi u multijezičkim NMT-ima odbacuju analizu multijezičkog model a o bliskom povezanim i niskim jezičkim grupama u kontekstu prevoda na pivotu i prevoda na nulu. U ovom papiru, prevodili smo se za nekoliko Filipinskih jezika, pružili analizu multijezičkog NMT-ovog sustava za morfološki bogate i niske resurse jezike u smislu njene učinkovitosti u prevodu jezika nula resursa sa prevodom nula snimka. Da bismo dalje procijenili sposobnost multijezičkog model a NMT-a u prevodu nevidljivih jezičkih parova u obuci, testirali smo model da prevodi između Tagaloga i Cebuano i usporedili njegove učinke s jednostavnim modelom NMT-a koji je direktno obučen na paralelnim podacima Tagaloga i Cebuano u kojima smo pokazali da prevod nule-snimke iznosi direktno obučen model u nekim slučajevima, Dok se koristi engleski kao jezik pivot a u prevodu nadmaženja obje pristupe.</abstract_hr>
      <abstract_nl>De Filippijnen zijn de thuisbasis van meer dan 150 talen die worden beschouwd als laag-resourced, zelfs op de belangrijkste talen. Dit leidt tot een gebrek aan pogingen om een vertaalsysteem voor de ondervertegenwoordigde talen te ontwikkelen. Om het proces van de ontwikkeling van een vertaalsysteem voor meerdere talen te vereenvoudigen en de vertaalkwaliteit van nul- naar lage-resourcetalen te verbeteren, werd meertalige NMT een actief onderzoeksgebied. Bestaande werken in meertalige NMT negeren echter de analyse van een meertalig model op een nauw verwante en weinig resource taalgroep in de context van pivot-gebaseerde vertaling en zero-shot vertaling. In dit artikel hebben we de vertaling voor verschillende Filippijnse talen benchmarked, een analyse gemaakt van een meertalig NMT systeem voor morfologisch rijke en low-resource talen in termen van de effectiviteit ervan bij het vertalen van zero-resource talen met zero-shot vertalingen. Om de capaciteit van het meertalige NMT model in het vertalen van ongeziene taalparen in training verder te evalueren, hebben we het model getest om te vertalen tussen Tagalog en Cebuano en de prestaties vergeleken met een eenvoudig NMT model dat direct getraind is op een parallelle Tagalog en Cebuano data waarin we aantoonden dat zero-shot vertaling in sommige gevallen beter presteert dan een direct getraind model, Terwijl Engels als spitstaal wordt gebruikt in het vertalen presteren beide benaderingen beter.</abstract_nl>
      <abstract_de>Die Philippinen sind die Heimat von mehr als 150 Sprachen, die selbst in ihren Hauptsprachen als ressourcenarm gelten. Dies führt zu mangelndem Streben nach der Entwicklung eines Übersetzungssystems für die unterrepräsentierten Sprachen. Um den Prozess der Entwicklung eines Übersetzungssystems für mehrere Sprachen zu vereinfachen und die Übersetzungsqualität von Null- in ressourcenarme Sprachen zu verbessern, wurde mehrsprachiges NMT zu einem aktiven Forschungsgebiet. Bestehende Arbeiten im mehrsprachigen NMT ignorieren jedoch die Analyse eines mehrsprachigen Modells auf einer eng verwandten und ressourcenarmen Sprachgruppe im Kontext von Pivot-basierter Übersetzung und Zero-Shot-Übersetzung. In diesem Beitrag haben wir die Übersetzung für mehrere philippinische Sprachen benchmarkiert und ein mehrsprachiges NMT-System für morphologisch reiche und ressourcenarme Sprachen hinsichtlich seiner Effektivität bei der Übersetzung von Null-Ressourcen-Sprachen mit Null-Schuss-Übersetzungen analysiert. Um die Fähigkeit des mehrsprachigen NMT-Modells, unsichtbare Sprachpaare im Training zu übersetzen, weiter zu bewerten, haben wir das Modell getestet, um zwischen Tagalog und Cebuano zu übersetzen und seine Leistung mit einem einfachen NMT-Modell verglichen, das direkt auf einem parallelen Tagalog- und Cebuano-Modell trainiert wird, in dem gezeigt wurde, dass Zero-Shot-Übersetzung in einigen Fällen ein direkt trainiertes Modell übertrifft. Beim Einsatz von Englisch als Pivot-Sprache bei der Übersetzung übertreffen beide Ansätze.</abstract_de>
      <abstract_da>Filippinerne er hjemsted for mere end 150 sprog, der anses for at være lav ressource selv på sine største sprog. Dette resulterer i manglende bestræbelser på at udvikle et oversættelsessystem for de underrepræsenterede sprog. For at forenkle processen med udvikling af oversættelsessystem til flere sprog og for at hjælpe med at forbedre oversættelseskvaliteten for nul til lav ressource sprog blev flersprogede NMT et aktivt forskningsområde. Eksisterende værker i flersproget NMT ignorerer imidlertid analysen af en flersproget model på en nært beslægtet sproggruppe med lav ressource i forbindelse med pivot-baseret oversættelse og zero-shot oversættelse. I denne artikel har vi benchmarkeret oversættelse for flere filippinske sprog, leveret en analyse af et flersproget NMT-system til morfologisk rige og lav ressource sprog med hensyn til dets effektivitet i oversættelse af nul ressource sprog med nul-shot oversættelser. For yderligere at evaluere den flersprogede NMT-models evne til at oversætte usynlige sprogpar under uddannelse, testede vi modellen til at oversætte mellem tagalog og cebuano og sammenlignede dens ydeevne med en simpel NMT-model, der er direkte uddannet på en parallel tagalog og cebuano data, hvor vi viste, at zero-shot oversættelse i nogle tilfælde overstiger en direkte uddannet model. mens du bruger engelsk som et pivot sprog i oversættelse overgår begge tilgange.</abstract_da>
      <abstract_fa>فیلیپین ها بیش از ۱۵۰ زبان خانه دارند که حتی در زبان های بزرگ آن به نظر می رسند کمترین منابع هستند. این نتیجه به ناتوانی تعقیب در توسعه سیستم ترجمه برای زبانهای زیر نمایش داده شده است. برای ساده‌سازی فرایند سیستم ترجمه برای زبان‌های زیادی، و برای بهترین کیفیت ترجمه صفر به زبان‌های کم منابع، NMT multilingual became an active area of research. ولی کارهای موجود در NMT چندین زبان، تحلیل یک مدل چندین زبان در گروه زبان نزدیک و کم منابع در محیط ترجمه‌ای بر اساس pivot و ترجمه‌ای صفر را نادیده می‌دهد. در این کاغذ، ما ترجمه‌ی چند زبان فیلیپین را ترجمه کردیم، و یک تحلیل از سیستم NMT multilingual برای زبان‌های مورفولوژیکی ثروتمند و کم منابع در ترجمه‌ی زبان‌های منبع صفر با ترجمه‌های شلیک صفر دادیم. برای further evaluation of the multilingual NMT model in translating unknown languages pairs in training, we tested the model to translate between Tagalog and Cebuano and compared its performance with a simple NMT model that is directly trained on a parallel Tagalog and Cebuano data in which we showed that zero-shot translation outperforms a directly trained model in some instances, در حالی که انگلیسی را به عنوان زبان کوچک استفاده می‌کند در ترجمه از هر دو نزدیک‌ها.</abstract_fa>
      <abstract_id>Filipina memiliki lebih dari 150 bahasa yang dianggap sebagai sumber daya rendah bahkan dalam bahasa utamanya. Ini menghasilkan kekurangan pengejaran dalam mengembangkan sistem terjemahan untuk bahasa yang tidak terwakil. Untuk mempermudahkan proses mengembangkan sistem terjemahan untuk berbagai bahasa, dan untuk membantu memperbaiki kualitas terjemahan dari nol ke bahasa sumber daya rendah, NMT berbagai bahasa menjadi daerah penelitian aktif. Namun, pekerjaan yang ada di NMT berbagai bahasa mengabaikan analisis model berbagai bahasa pada kelompok bahasa yang terhubung dan sumber daya rendah dalam konteks terjemahan berdasarkan pivot dan terjemahan nol. Dalam kertas ini, kami membandingkan terjemahan untuk beberapa Bahasa Filipina, menyediakan analisis dari sistem NMT berbilang bahasa untuk bahasa morfologis kaya dan sumber daya rendah dalam terma efektifnya dalam terjemahan bahasa sumber daya nol dengan terjemahan nol. Untuk mengevaluasi lebih lanjut kemampuan model NMT berbagai bahasa dalam menerjemahkan pasangan bahasa yang tidak terlihat dalam latihan, kami menguji model untuk menerjemahkan antara Tagalog dan Cebuano dan membandingkan prestasinya dengan model NMT sederhana yang secara langsung dilatih pada data Tagalog dan Cebuano paralel di mana kami menunjukkan bahwa terjemahkan nol lebih berhasil melatih model secara langsung dalam beberapa kasus, Sementara menggunakan bahasa Inggris sebagai bahasa pivot dalam menerjemahkan melebihi kedua pendekatan.</abstract_id>
      <abstract_sw>Ufilipino ni nyumbani kwa zaidi ya lugha 150 ambazo zinaonekana kuwa ni rasilimali chini hata kwa lugha zake kubwa. Hii inasababisha kutokuwepo kwa ufuatiliaji katika kutengeneza mfumo wa tafsiri kwa lugha zisizo na uwakilishi. Ili kuboresha mchakato wa kuendeleza mfumo wa kutafsiri kwa lugha mbalimbali, na kusaidia katika kuboresha tafsiri sifuri ya lugha za asili hadi rasilimali ndogo, NMT kwa lugha mbalimbali ilikuwa eneo la utafiti. Hata hivyo, kazi zinazopo katika lugha mbalimbali za NMT hupuuza uchambuzi wa modeli ya lugha mbalimbali kwenye kundi la lugha inayohusiana na rasilimali ndogo katika muktadha wa tafsiri yenye asili ya pivot na tafsiri yenye risasi sifuri. Katika karatasi hii, tulitafsiri kwa lugha kadhaa za Ufilipino, tulitoa uchambuzi wa mfumo wa NMT wa lugha mbalimbali kwa lugha zenye utajiri na rasilimali ndogo kwa sababu ya ufanisi wake katika kutafsiri lugha zenye rasilimali zisizo na tafsiri zisizo za risasi. Ili kuelezea uwezo wa modeli ya NMT kwa lugha mbalimbali katika kutafsiri ndoa za lugha isiyo na siri katika mafunzo, tulijaribu mtindo wa kutafsiri kati ya Tagalog na Cebuano na kulinganisha utendaji wake na mtindo rahisi wa NMT ambao umefundishwa moja kwa moja kwenye taarifa za Tagalog na Cebuano ambazo tulionyesha kwamba tafsiri ya sifuri inafanya mfano wa moja kwa moja kwa moja katika wakati fulani, wakati wakitumia Kiingereza kama lugha ya kupiga kura katika kutafsiri mbinu zote.</abstract_sw>
      <abstract_ko>필리핀은 150여 개의 언어를 보유하고 있으며 주요 언어에서도 자원이 부족하다고 여겨진다.대표적으로 부족한 언어 개발을 위한 번역 시스템의 노력이 부족해졌다.다국어 번역 시스템의 개발 과정을 간소화하고 0에서 저자원 언어로의 번역 질을 향상시키는 데 도움을 주기 위해 다국어 NMT는 활발한 연구 분야가 되었다.그러나 기존의 다국어 NMT 연구는 축심 번역과 제로 렌즈 번역을 바탕으로 밀접한 관계를 가진 저자원 언어 그룹의 다국어 모델에 대한 분석을 무시했다.본고에서 우리는 몇 가지 필리핀 언어의 번역에 대해 기준 테스트를 실시하여 형태가 풍부하고 저자원 언어를 대상으로 하는 다중 언어 NMT 시스템이 제로 자원 언어와 제로 렌즈 번역의 유효성을 분석했다.다중 언어 NMT 모델이 훈련에서 보이지 않는 언어를 번역하는 능력을 한층 더 평가하기 위해 우리는 이 모델이 타갈로어와 세브아노어 간의 번역을 테스트하고 그 성능을 평행 타갈로어와 세브아노어 데이터에서 직접 훈련한 간단한 NMT 모델과 비교했다. 그 중에서 일부 상황에서 제로 렌즈 번역이 직접 훈련한 모델보다 우수하다는 것을 알 수 있다.영어를 핵심 언어로 번역하는 효과는 이 두 가지 방법보다 낫다.</abstract_ko>
      <abstract_tr>Filippinler 150-den köp dillerinde hem esasy dillerinde hem esasy dillerde bolup kabul edilýärler. Bu ýerde az ifade edilen diller üçin terjime sistemasyny bejermek ýok bolýar. Birnäçe diller üçin terjime sistemini geliştirmek we 0-iň iň azajyk dillere terjime etmek üçin kömek etmek üçin, birnäçe diller NMT-iň barlamak üçin janlaşdy. Ýöne, birnäçe dilde bar NMT-de işleýän işleýän işleýänler pivot-dan daşarylan terjime we 0-shot terjime edeniň daşarynda gaty we az-resurslar dili toparynda. Bu kagyzda, birnäçe Filipin dilleri üçin terjime etdik, näçe dilli NMT sistemasyny morfologik we iň baý we iň-kaynaklı dilleri üçin 0-resurs dilini terjime etmek üçin çözümlendirdik. Görmeýän dil çiftlerini öňünde bir nusga çykarmak üçin, Tagalog we Cebuano arasynda terjime etmek üçin nusga synanyşdyrdyk we onuň etkinleşigini parallel tägalogda we Cebuano maglumatynda görkezilýän basit bir NMT nusga bilen gurlyşdyrylyp çykardyk. Bu nusga terjime edilen käbir ýagdaýda ýüz tutuldygyny görkezilýän nusga üçin, Iňlisçe örän wajyp dili terjime etmek üçin ikisi ýakynlaşyp barýar.</abstract_tr>
      <abstract_sq>Filipinat janë shtëpia e më shumë se 150 gjuhëve që konsiderohen të pakufishme edhe në gjuhët e saj kryesore. Kjo rezulton në një mungesë ndjekjeje në zhvillimin e një sistemi përkthimi për gjuhët e nënpërfaqësuara. Për të thjeshtuar procesin e zhvillimit të sistemit të përkthimit për gjuhë të shumta dhe për të ndihmuar në përmirësimin e cilësisë së përkthimit të zero në gjuhë me burime të ulëta, NMT shumëgjuhëse u bë një fushë aktive kërkimi. However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation.  Në këtë letër, ne paraqitëm përkthimin për disa gjuhë filipine, ofruam një analizë të një sistemi NMT shumëgjuhës për gjuhë morfologjikisht të pasura dhe me burime të ulëta lidhur me efektshmërinë e saj në përkthimin e gjuhëve zero-burimi me përkthime zero-shot. Për të vlerësuar më tej aftësinë e modelit shumëgjuhës NMT në përkthimin e çifteve të fshehta gjuhësh në trajnim, ne e testuam model in për të përkthyer midis Tagalog dhe Cebuano dhe krahasuam performancën e tij me një model të thjeshtë NMT që është trajnuar drejtpërdrejt në një të dhëna paralele Tagalog dhe Cebuano në të cilën treguam se përkthimi zero-shot ekziston në disa raste një model të trajnuar drejtpërdrejt, Ndërsa përdorimi i anglishtit si një gjuhë kryesore në përkthimin ekziston mbi të dy qasjet.</abstract_sq>
      <abstract_af>Die Filippines is tuis na meer as 150 taal wat aangeneem word as lae-hulpbron selfs op sy hoofde tale. Hierdie resultaat in 'n ontbreek van volg in die ontwikkeling van 'n vertalingsstelsel vir die ondersteunde tale. Om die proses van die ontwikkeling van vertalingsstelsel vir veelvuldige tale te eenvoudig en om die vertalingskwaliteit van nul tot lae hulpbron tale te verbeter, het veelvuldige NMT 'n aktiewe area van ondersoek geword. Maar bestaande werke in multilinglike NMT verwyder die analiseer van 'n multilinglike model op 'n naby verwante en lae hulpbron taal groep in die konteks van pivot-gebaseerde vertaling en nul-skoot vertaling. In hierdie papier, ons benchmarkeer oorsetting vir verskeie Filippiese tale, verskaf ons 'n analiseer van 'n multitaalstelsel NMT stelsel vir morfologiese ryk en lae hulpbron tale in terms van sy effektiviteit in die vertaling van nul-hulpbron tale met nul-skoot vertalings. Om die moontlikheid van die multitaal NMT-model te verdere evalueer in die vertaling van ongesiende taal paar in onderwerp, het ons die model toegetest om te vertaal tussen Tagalog en Cebuano en sy uitvoedsel te vergelyk met 'n eenvoudige NMT-model wat direk onderwerp is op 'n parallele Tagalog en Cebuano-data waarin ons vertoon het dat zero-shot-vertaling 'n direk onderwerp model in sommige voorbeelde uitvoer terwyl Engels as 'n pivottaal gebruik word in te vertaling uitvoer beide toegang.</abstract_af>
      <abstract_am>ፊልጶስፓንስቲ በዋነኛው ቋንቋዎች ላይ እንኳ ዝቅተኛ የተደረገው 150 ቋንቋዎች ውስጥ ነው፡፡ ይህ የቋንቋዎች ትርጉም ሲስተካከል በመፍጠር ምክንያት የጎደለው ነው፡፡ ለብዙዎች ቋንቋዎች ትርጉም ሲስመር ማድረግ እና የ0 ወደታህል resource ቋንቋዎች ትርጉም ማድረግ ለመረዳት፣ የብዙ ቋንቋዎች የNMT ጥያቄ ትርጉም መሆኑን ለመጠንቀቅ ነው፡፡ However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation.  በዚህ ፕሮግራም፣ ለብዙ ፊልጶስፓንቲ ቋንቋዎች የፊልጶስ ቋንቋዎች ትርጓሜዎችን አቅርብ እና ለሞፎሎጂ ባለጠጋ እና ታናሽ የክፍል ቋንቋዎች በzero-resource ቋንቋዎች በመተርጓሜ እና በzero-shot ትርጓሜዎችን ለማድረግ እና ለብዙ ቋንቋዎች የNMT ስርዓት አስተርጓል፡፡ በብዙ ቋንቋዎች የNMT ሞዴል ልዩን የቋንቋ ቋንቋ ዓይነቶች ለመተማርር እና በይቡአና መካከል ለመተርጓም ሞዴላውን ሞዴል ሞክረን ሞክረናል እና አካሄዱን በተለይታ በቴክሎግ እና ስቡአና ዳታዎችን አስተማርተናል፡፡ እንግሊዝኛ በሁለቱ ደረጃዎችን በመተርጓም የፎቶ ቋንቋን በመጠቀም ጊዜ፡፡</abstract_am>
      <abstract_az>Filipinlər 150-dən daha çox dillərin evindədir ki, ən böyük dillərində də hətta düşük məlumatlar hesab edilir. Bu, a şağı göstərilmiş dillər üçün bir tercümə sistemini inkişaf etmək üçün istifadə edilməyən bir tədbir olaraq. Çoxlu dillər üçün tercümə sistemini təhsil etmək və sıfır dillərin tercümə keyfiyyətini azaltmaq üçün yardım etmək üçün, çoxlu dil NMT təhsil edilən araştırma bölgesi oldu. Ancaq çoxlu dildə olan NMT işləri pivot-tabanlı tercümə və sıfır-shot tercüməsi ilə yaxınlaşdırılmış və düşük çoxlu dil qrupunda çoxlu dil model in in analizisini görmürlər. Bu kağızda, bir neçə Filipin dillərinə çevirildik, çoxlu dil NMT sistemini morfolojik zəngin və düşük ressurs dillərinin faydalanması haqqında sıfır-ressurs dillərini sıfır-shot çevirilə çevirildik. Və çoxlu dil NMT model in in qabiliyyətini təhsil etmək üçün, təhsil etmək üçün, Tagalog və Cebuano arasında təhsil etmək üçün modelini təhsil etdik və onun performansını, paralel Tagalog və Cebuano verilənlərinin doğrudan təhsil edilmiş bir NMT modeli ilə müqayisədə saldıq. Biz sıfır çəkilməsinin bəzi məsəllərdə düzgün təhsil edilməsini göstərdik. İngilizce dilini ilk dil kimi istifadə edərkən hər ikisinin yaxınlıqlarını tərcümə edərkən.</abstract_az>
      <abstract_hy>Ֆիլիպպիններն ավելի քան 150 լեզու են, որոնք համարվում են ցածր ռեսուրսներ նույնիսկ իր հիմնական լեզուներում: Սա հանգեցնում է թերներկայացված լեզուների թարգմանման համակարգի զարգացման հետևանքի պակաս: Շատ լեզուների համար թարգմանման համակարգի զարգացման գործընթացը պարզ դարձնելու համար և օգնելու զրոյի թարգմանման որակը բարելավելու համար ցածր ռեսուրսների լեզուներին, բազլեզու ՆՄԹ-ը դարձավ հետազոտության ակտիվ ոլորտ However, existing works in multilingual NMT disregards the analysis of a multilingual model on a closely related and low-resource language group in the context of pivot-based translation and zero-shot translation.  Այս թղթի մեջ մենք համեմատեցինք մի քանի Ֆիլիպպինյան լեզուների թարգմանությունը, ապահովեցինք բազմալեզու NMT համակարգի վերլուծություն մորֆոլոգիապես հարուստ և ցածր ռեսուրսների լեզուների համար դրա արդյունավետության առումով զրո ռեսուրսների լեզուների թարգմանման համար զրո Որպեսզի ավելի ուշ գնահատենք բազմալեզու NMT մոդելի կարողությունը թարգմանելու համար անտեսանելի լեզվի զույգեր ուսումնասիրության մեջ, մենք փորձեցինք թարգմանելու մոդելը Տագալոգի և Չեբյուանոյի միջև և համեմատեցինք դրա արտադրողությունը մի պարզ NMT մոդելի հետ, որը ուղղակի ուսուցանվում է զուգահեռ Տագալոգի և Չեբյու Մինչ անգլերենը օգտագործվում է որպես կենտրոնային լեզու թարգմանելու համար, երկու մոտեցումները դուրս են գալիս:</abstract_hy>
      <abstract_bn>ফিলিপাইনের বাড়িতে ১৫০ জনের বেশী ভাষায় আছে যা তাদের প্রধান ভাষায় কম সম্পদ হিসেবে বিবেচনা করা হচ্ছে। এর ফলে অনপ্রতিনিধিত্বিত ভাষার জন্য একটি অনুবাদ সিস্টেম উন্নয়নের অভাবে তারা অনুসরণ করেছে। To simplify the process of developing translation system for multiple languages, and to aid in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research.  তবে পিভোট ভিত্তিক অনুবাদ এবং শূন্য-গুলি অনুবাদের প্রেক্ষাপটে অনুবাদের কাছে কাছাকাছি সংশ্লিষ্ট এবং কম সম্পর্কিত ভাষার ভাষার গ্রুপের বিশ্ল এই কাগজটিতে আমরা বেশ কয়েকটি ফিলিপাইন ভাষার জন্য অনুবাদ প্রদান করেছি, যার ফলে মৃত্যুত্তিক সমৃদ্ধ এবং কম সম্পদ ভাষার বিশ্লেষণ প্রদান করেছি শুধু শুরু করা অনুবাদের মাধ্যমে। প্রশিক্ষণ অনুবাদ করার জন্য আমরা ট্যাগালগ এবং সেবুয়ানোর মধ্যে অনুবাদ করার মডেল পরীক্ষা করেছি এবং তার প্রদর্শনের তুলনা করেছি একটি সাধারণ এনএমটি মডেলের সাথে যা সরাসরি প্রশিক্ষণ করা হয়েছে একটি প্যারালেল ট্যাগালোগ এবং সেবুয়ানোর যেখানে ইংরেজি ব্যবহার করা হচ্ছে পিভোট ভাষা হিসেবে দুটি প্রতিক্রিয়া অনুবাদ করার জন্য।</abstract_bn>
      <abstract_bs>Filipini su domaći više od 150 jezika koje se smatra niskim resursima čak i na svojim glavnim jezicima. To rezultira u nedostatak potražnje u razvoju sustava prevoda za neposredne jezike. Da bi se pojednostavio proces razvoja sustava prevoda za višestruke jezike i pomoći u poboljšanju kvalitete prevoda nule na jezike niskih resursa, multijezički NMT postao je aktivan područje istraživanja. Međutim, postojeći rad u multijezičkim NMT-ima se ne obraća analizu multijezičkog modela o bliskom povezanoj i niskoj resursnoj grupi jezika u kontekstu prevoda na pivotu i prevoda na nulu snimku. U ovom papiru, prevodili smo se za nekoliko Filipinskih jezika, pružili analizu multijezičkog NMT-ovog sistema za morfološki bogate i niske resurse jezika u smislu njene učinkovitosti u prevodu jezika nula resursa sa prevodom nula pucnjave. Da bismo dalje procenili sposobnost multijezičkog model a NMT-a u prevodu nevidljivih jezičkih parova u obuci, testirali smo model da prevodi između Tagaloga i Cebuano i usporedili njegove učinke sa jednostavnim modelom NMT-a koji je direktno obučen na paralelnim podacima Tagaloga i Cebuano u kojima smo pokazali da prevod nule-snimke iznosi direktno obučen model u nekim slučajevima, Dok se koristi engleski kao govorni jezik u prevodu nadmaženja obje pristupe.</abstract_bs>
      <abstract_cs>Filipíny jsou domovem více než 150 jazyků, které jsou považovány za nízké zdroje i ve svých hlavních jazycích. To má za následek nedostatek úsilí o vývoj překladatelského systému pro nedostatečně zastoupené jazyky. S cílem zjednodušit proces vývoje překladatelského systému pro více jazyků a pomoci zlepšit kvalitu překladu jazyků nulových do nízkých zdrojů, se vícejazyčná NMT stala aktivní oblastí výzkumu. Stávající práce ve vícejazyčném NMT však ignorují analýzu vícejazyčného modelu na úzce příbuzné jazykové skupině s nízkými zdroji v kontextu pivotového překladu a nulového překladu. V tomto článku jsme porovnali překlad pro několik filipínských jazyků, poskytli analýzu vícejazyčného NMT systému pro morfologicky bohaté a nízké zdroje jazyků z hlediska jeho efektivity při překladu jazyků nulových zdrojů s nulovými překlady. Pro další zhodnocení schopnosti vícejazyčného NMT modelu při překladu neviditelných jazykových párů v tréninku jsme testovali model pro překlad mezi Tagalog a Cebuano a porovnali jeho výkon s jednoduchým NMT modelem, který je přímo trénován na paralelních Tagalog a Cebuano datech, ve kterých jsme ukázali, že nulový překlad v některých případech překonává přímo trénovaný model. při využití angličtiny jako pivot jazyka při překladu překonává oba přístupy.</abstract_cs>
      <abstract_ca>Les Filipines tenen més de 150 llengües que es consideran poc recursos fins i tot en les seves principals llengües. This results into a lack of pursuit in developing a translation system for the underrepresented languages.  To simplify the process of developing translation system for multiple languages, and to aid in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research.  No obstant això, les obres existents en la MTN multilingüe ignoren l'anàlisi d'un model multilingüe en un grup de llengües estretament relacionat i amb baixos recursos en el context de traducció basada en pivots i traducció zero. En aquest paper, vam comparar la traducció per diverses llengües filipines, vam proporcionar una an àlisi d'un sistema multilingüe de MTN per llengües morfològicament rics i de baix recursos en termes d'eficacia en traduir llengües de recursos zero amb traduccions de zero. Per a seguir evaluant la capacitat del model multilingüe de la NMT de traduir parelles de llenguatges no vistes en entrenament, vam provar el model de traducció entre Tagalog i Cebuano i vam comparar el seu desempeny amb un model simple de la NMT que està entrenat directament en una data paralèl·lela de Tagalog i Cebuano en la qual vam demostrar que la traducció de fotografies zero supera un model entrenat directament en alguns casos, mentre utilitza l'anglès com una llengua pivot per traduir supera ambdós enfocaments.</abstract_ca>
      <abstract_et>Filipiinid on koduks enam kui 150 keele, mida peetakse vähese ressursiga isegi oma peamistes keeltes. Selle tagajärjel puuduvad püüdlused alaesindatud keelte tõlkesüsteemi väljatöötamisel. Selleks et lihtsustada mitme keele tõlkesüsteemi väljatöötamist ja aidata parandada tõlkekvaliteeti nullkeeltest vähese ressursiga keelteni, muutus mitmekeelne NMT aktiivseks uurimisvaldkonnaks. Olemasolevates mitmekeelsetes NMT-töödes ei võeta siiski arvesse tihedalt seotud ja vähese ressursiga keelerühma mitmekeelse mudeli analüüsi pivot-põhise tõlke ja nullkõlke kontekstis. Käesolevas töös analüüsisime mitme Filipiini keele tõlkimist, analüüsisime mitmekeelset NMT-süsteemi morfoloogiliselt rikkalike ja vähese ressursiga keelte jaoks selle tõhusust nullressursiga keelte tõlkimisel nullressursiga. Selleks et täiendavalt hinnata mitmekeelse NMT mudeli võimet tõlkida väljaõppes nähtamatuid keelepaare, testisime mudelit tõlkida tagalogi ja cebuano vahel ning võrdlesime selle jõudlust lihtsa NMT mudeliga, mida koolitatakse otse paralleelsete tagalogi ja cebuano andmete põhjal, kus näitasime, et null-shot tõlkimine ületab mõnel juhul otse koolitatud mudelit, inglise keele kui pöördekeele kasutamine tõlkimisel ületab mõlemat lähenemisviisi.</abstract_et>
      <abstract_fi>Filippiineillä asuu yli 150 kieltä, joita pidetään vähäisinä jopa sen pääkielillä. Tämä johtaa siihen, että ei pyritä kehittämään käännösjärjestelmää aliedustetuille kielille. Monikielisestä NMT:stä tuli aktiivinen tutkimusalue useiden kielten käännösjärjestelmän kehittämiseksi ja nollakielisten käännösten laadun parantamiseksi vähävaraisiksi kieliksi. Monikielisessä NMT:ssä jo olemassa olevissa teoksissa ei kuitenkaan oteta huomioon monikielisen mallin analysointia läheisesti toisiinsa läheisessä ja vähäresurssisessa kieliryhmässä pivot-pohjaisen käännöksen ja nollakäännöksen yhteydessä. Tässä artikkelissa vertailimme käännöksiä useille Filippiinin kielille, toimitimme analyysin monikielisestä NMT-järjestelmästä morfologisesti rikkaille ja vähän resursseja sisältäville kielille sen tehokkuuden kääntämisessä nollaresursseja sisältävillä kielillä. Arvioidaksemme monikielisen NMT-mallin kykyä kääntää näkymättömiä kielipareja koulutuksessa, testasimme mallia kääntämään Tagalogin ja Cebuanon välillä ja vertasimme sen suorituskykyä yksinkertaiseen NMT-malliin, joka on suoraan koulutettu rinnakkaisella Tagalogin ja Cebuanon datalla, jossa osoitimme, että nollakäännös suoriutuu joissakin tapauksissa suoraan koulutetusta mallista, Englannin kielen hyödyntäminen kääntämisessä on molempia lähestymistapoja parempi.</abstract_fi>
      <abstract_he>הפיליפינים נמצאות בבית של יותר מ-150 שפות שנחשבו כמוצאות נמוכות אפילו בשפות העיקריות שלה. זה מוביל לחסר רדוף בפיתוח מערכת תרגום לשפות המיוצגות הלא מוגבלות. כדי לפשט את תהליך הפיתוח מערכת התרגום למספר שפות, ולעזור לשפר את איכות התרגום של אפס לשפות משאבים נמוכות, NMT רבשפות הפכה לאזור פעיל של מחקר. עם זאת, עבודות קיימות ב NMT רבות שפות מתעלמות מהניתוח של דוגמא רבות שפות על קבוצת שפת שקשורה קרובה ומפחית משאבים בקשר לתרגום מבוסס על פיוט ותרגום אפס. במסמך הזה, סיפקנו את התרגום למספר שפות פיליפינות, סיפקנו ניתוח של מערכת NMT רבת שפות עבור שפות עשירות מורפולוגית וממשאבים נמוכות במונחים של יעילותה בתרגום שפות אפס משאבים עם תורגם אפס. כדי להעריך נוסף את היכולת של מודל NMT רב-שפוי בתרגום זוגות שפות בלתי נראות באימון, בדקנו את המודל לתרגם בין Tagalog ו Cebuano ולהשוות את ההופעה שלו עם מודל NMT פשוט אשר מאומן ישירות על מידע Tagalog ומקביל שבה הראינו כי התרגום אפס-יריות עולה על מודל מאומן ישירות במקרים מסוימים, בעוד השימוש באנגלית כשפת הפיבוט בתרגום מתגבר על שני גישות.</abstract_he>
      <abstract_sk>Na Filipinih je doma več kot 150 jezikov, ki veljajo za majhne vire tudi v svojih glavnih jezikih. To povzroči pomanjkanje prizadevanj za razvoj prevajalskega sistema za premalo zastopane jezike. Za poenostavitev procesa razvoja prevajalskega sistema za več jezikov in pomoč pri izboljšanju kakovosti prevajanja ničelnih jezikov v jezike z nizkimi viri je večjezična NMT postala dejavno področje raziskav. Vendar obstoječa dela v večjezični NMT ne upoštevajo analize večjezičnega modela v tesno povezani jezikovni skupini z nizkimi viri v kontekstu prevajanja na osnovi pivot in ničelnega prevajanja. V tem prispevku smo primerjali prevode za več filipinskih jezikov in analizirali večjezični sistem NMT za morfološko bogate in nizko-virovne jezike z vidika njegove učinkovitosti pri prevajanju jezikov brez virov z ničelnimi prevodi. Da bi nadalje ocenili zmožnost večjezičnega modela NMT pri prevajanju nevidnih jezikovnih parov med usposabljanjem, smo testirali model prevajanja med Tagalogom in Cebuano ter primerjali njegovo zmogljivost s preprostim NMT modelom, ki se neposredno usposablja na vzporednih podatkih Tagalog in Cebuano, v katerem smo pokazali, da ničelni prevod v nekaterih primerih presega neposredno usposobljen model, Medtem ko uporabljamo angleščino kot ključnega jezika pri prevajanju boljša od obeh pristopov.</abstract_sk>
      <abstract_ha>The Philippines is home to more than 150 languages that is considered to be low-resourced even on its major languages.  Wannan yana ƙara wa'adin ƙaranci da za'a buɗe wani tsari na fassarar wa harshen da ba'a rage. Ina sauƙi da jararin ta buɗe tsarin translation wa ziman masu yawa, kuma dõmin ya taimake taimako da wajen kyautata fassarar sifiri na sifiri zuwa ƙasan-resource, na'urar mulki-linguin NMT ya kasance wani dalilin na aikin research. Amma, wanda ke da aiki a cikin multi-lingui na NMT yana ƙyãma ga anayyar da wani misãlan multilala na kan wani jama'a na rufe da kuma ƙasan-resource cikin context of translation na pivot-based and no-shot translation. In wannan takardar, we set up translation for several Filipino languages, but we gave an analyza of a system of NMT in mulki-languages for morfologically rich and lower-resource languages in the form of its Effective in translation of null-resource languages with no-shot translation. To, dõmin ka ƙara ƙaddara abincin misalin NMT cikin fassarar misalin multi-lingui cikin fassarar nau'in lugha da ba'a sani ba, Mun jarraba motsi dõmin a translate tsakanin Tagalog da Cebuan kuma a sami aikin shi da wani misali na NMT mai sauƙi wanda aka yi wa shirin a parallel Tagalog da Cebuan data, a cikinsa, mun nuna cewa fassarar-shot na samar da wani motel wanda aka yi wa shirya ko da wani misali, dictionary variant</abstract_ha>
      <abstract_bo>Filipines ནི་སྐད་ཡིག་ཆ་གཅིག་ལས་མཐོ་ཤིང་མིན་པར་རང་གི་སྐད་ཡིག་ཆ་མཐོ་དཀོན་པོ་ཞིག་ཡིན་པ་དང་། འདིས་ཕལ་རྟོགས་པའི་སྐད་རིགས་ལ་ཚོར་ཡིག་ལག་ཅིག་ཡར་རྒྱས་སྤེལ་བའི་འཚོལ་བ་གཅིག་མཐུན་མེད། To simplify the process of developing translation system for multiple languages, and to help in improving the translation quality of zero to low-resource languages, multilingual NMT became an active area of research. ཡིན་ནའང་། གནས་ཡུལ་གྱི་སྐད་ཡིག་NMT ནང་དུ་ཡོད་བཞིན་པའི་སྐད་ཡིག In this paper, we benchmarked translation for several Philippine Languages, provided an analysis of a multilingual NMT system for morphologically rich and low-resource languages in terms of its effectiveness in translating zero-resource languages with zero-shot translations. To further evaluate the ability of the multilingual NMT model in translating unseen language pairs in training, we tested the model to translate between Tagalog and Cebuano and compared its performance with a simple NMT model that is directly trained on a parallel Tagalog and Cebuano data in which we showed that zero-shot translation outperforms a directly trained model in some instances, དབྱིན་ཡིག་གཟུགས་པའི་སྐད་རིགས་ལ་ལག་ལེན་འཐབ་སྐབས།</abstract_bo>
      <abstract_fil>Ang mga Filipino ay nasa bahay ng higit kay sa 150 wika na iniisip na mababa-resourced kahit sa mga dakilang wika. Ito ay nagkakailangan ng pagkahabol sa pagbubuhay ng sistema ng paglilikat para sa mga wikang di-represented. Upang maganap ang proseso ng pagliwanag ng sistema ng pagliliwanag para sa maraming wika, at upang tulungan ang pagliliwanag ng kalidad ng pagliliwanag ng nulo hanggang sa mababang mga wika ng mga resource, ang multilingual NMT ay naging aktibo na lugar ng paglilingkod. Gayon ma'y nagkaroon ng mga gawa sa multilingual NMT na hindi naniniwalang analisi ng multilingual model sa isang malapit na relasyon at maliit na wikang grupo sa pagbabago ng pagbabago ng pivot at ng pagbabago ng nulo-shot. Sa papiro na ito, kami ay nagbabanggit ng paglilikat para sa ibang wika ng Filipina, nagbigay ng analisi ng multilingual NMT system para sa mga wika ng morfologically mayaman at mababang resource ayon sa paglilikat ng mga wika ng zero-resource na may nulo-shot na paglilikat. Upang iba pa ang kapangyarihan ng multilingual NMT model sa paglilikat ng di nakikita na paris ng wika sa pag-aaral, sinubok namin ang modelo upang paglilikat sa pagitan ng Tagalog at Cebuano at ipagtibay ang gawain niyaon sa isang simpleng modelo ng NMT na itinuturo sa parallel na Tagalog at data ng Cebuano na ipinakita namin na ang paglilikat ng zero-shot ay nagtataglay ng directo na modelo sa ilang mga instances, Samantalang ginagamit ang Ingles na pinaka-pivot na wika sa paglilingkod ng labis sa dalawang paglalapit.</abstract_fil>
      <abstract_jv>Piliné awak dhéwé luwih manut karo apat kanggo sabanjuré manut karo nganggo langa sing luwih basa. Ngomongke iki nganggo alèhku maneh kanggo nggawe sistem itolekak kanggo nganggo langkang apa-apa. Ngawe jeneng nggawe sistem tarjamahan kanggo nggawe luwih akeh urip lan bantuan kanggo nggawe kalite tarjamahan kanggo ingkang nula kanggo kuwi nggambar barang kelas, NMT sing wis ngerasai kapan kanggo tukang. Nanging, karo akeh gunane ing multi-lengkang NMT gak bener kanggo ngerasakno karo akeh modèl multi-lengkang nang kelompok bantuan karo nggawe barang kelompok barang kanggo nganggo urip pirot sing basa gambar dan terjamahan 0. Nang pepulan iki, kita bendhèké tarjamahan kanggo saboh tanggal Piliné, nggunakake karo sistem multilengkang NMT kanggo masalah kapèh lan basa sing nêmêr nggawe gerakan kaya sistem sing dadi nggawe balêh lan basa sing paling nggawe gerarané kawat 0-pas karo perusahaan tarjamahan. Ing langkung bantuan nggawe kapan karo model NMT multilengkang kapan kanggo terusah pawaran langgambar gak enyangno, kéné ujian model kanggo terusah etiket karo taglog karo Cebuane karo ngregani kapan sistem sing dadi NMT sampeyan seneng dadi tau dadi padha taglog karo Cebuane dadi tau dadi, ning kebonan kuwi nul-atan terusah dumateng sumulakno yang seneng model sing bisa pasan anyar Jagad ingkang dipulungan Inggris nganggo urip pirot</abstract_jv>
      </paper>
    <paper id="4">
      <title>Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages<fixed-case>L</fixed-case>o<fixed-case>R</fixed-case>es<fixed-case>MT</fixed-case> 2020 Shared Task on Zero-Shot for Low-Resource languages</title>
      <author><first>Atul Kr.</first><last>Ojha</last></author>
      <author><first>Valentin</first><last>Malykh</last></author>
      <author><first>Alina</first><last>Karakanta</last></author>
      <author><first>Chao-Hong</first><last>Liu</last></author>
      <pages>33–37</pages>
      <abstract>This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages. This task was organised as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020. The focus was on the zero-shot approach as a notable development in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> to build MT systems for language pairs where parallel corpora are small or even non-existent. The shared task experience suggests that back-translation and domain adaptation methods result in better <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> for small-size datasets. We further noted that, although <a href="https://en.wikipedia.org/wiki/Translation">translation</a> between similar languages is no cakewalk, linguistically distinct languages require more data to give better results.</abstract>
      <url hash="4c23d3af">2020.loresmt-1.4</url>
      <bibkey>ojha-etal-2020-findings</bibkey>
    <title_ar>نتائج مهمة LoResMT 2020 المشتركة حول Zero-Shot للغات منخفضة الموارد</title_ar>
      <title_fr>Résultats de la tâche partagée LoreSMT 2020 sur le Zero-Shot pour les langues à faibles ressources</title_fr>
      <title_pt>Descobertas da tarefa compartilhada LoResMT 2020 em Zero-Shot para linguagens de poucos recursos</title_pt>
      <title_es>Hallazgos de la tarea compartida LoreSMT 2020 sobre el tiro cero para idiomas de bajos recursos</title_es>
      <title_ja>低資源言語のゼロショットに関するLoResMT 2020共有タスクの調査結果</title_ja>
      <title_hi>लोरेसएमटी 2020 के निष्कर्ष कम-संसाधन भाषाओं के लिए शून्य-शॉट पर साझा कार्य</title_hi>
      <title_zh>LoResMT 2020低资源言零拍摄之共同任务也</title_zh>
      <title_ru>Результаты совместной задачи LoResMT 2020 по нулевому снимку для языков с низким уровнем ресурсов</title_ru>
      <title_ukr>Висновки спільного завдання LoResMT 2020 щодо нульових знімків для мов з низьким рівнем ресурсів</title_ukr>
      <title_ga>Torthaí Thasc Roinnte LoResMT 2020 ar Zero-Shot do theangacha Ísealcmhainne</title_ga>
      <title_isl>Niðurstöður LoResMT 2020 sameiginlegs verkefnis á núll-skot fyrir tungumál með lítil efni</title_isl>
      <title_hu>A LoResMT 2020 megosztott feladatának eredményei az alacsony erőforrású nyelvek zéró felvételéről</title_hu>
      <title_el>Ευρετήματα της κοινής εργασίας LoResMT 2020 σχετικά με την μηδενική λήψη για γλώσσες χαμηλής περιεκτικότητας σε πόρους</title_el>
      <title_ka>LoResMT 2020 საერთო პარამეტრების მისამართების მონახვა</title_ka>
      <title_kk>LoResMT 2020 жалпы ресурс тілдерінің ортақ тапсырмасын табу</title_kk>
      <title_mk>Најдењата на заедничката задача LoResMT 2020 за нула пукање за јазици со ниски ресурси</title_mk>
      <title_it>Risultati dell'attività condivisa LoResMT 2020 su Zero-Shot per linguaggi a basso consumo di risorse</title_it>
      <title_ms>Carian Tugas Berkongsi LoResMT 2020 pada Zero-Shot untuk bahasa Sumber Terrendah</title_ms>
      <title_lt>Bendros LoResMT 2020 m. užduoties, susijusios su mažai išteklių turinčių kalbų nuliniu nuotoliu, išvados</title_lt>
      <title_ml>LoresMT 2020 പങ്കാളിയുള്ള ജോലിയില്‍ വെടിവെക്കപ്പെട്ട ജോലിയുടെ കണ്ടുപിടിക്കുന്നു</title_ml>
      <title_mt>Sejbiet tal-Kompitu Konġunt LoResMT 2020 dwar Żero-Shot għal-lingwi b'Riżorsi Bażi</title_mt>
      <title_mn>LoResMT 2020-ын нийтлэг нийтлэг боловсролын хэлний 0-Shot-ын хуваалтын ажил олох</title_mn>
      <title_pl>Wyniki wspólnego zadania LoResMT 2020 dotyczącego zero-strzału dla języków niskich zasobów</title_pl>
      <title_no>Finn av delt oppgåve LoResMT 2020 på null-skytt for låg ressursspråk</title_no>
      <title_ro>Concluziile activității partajate LoResMT 2020 cu privire la zero-shot pentru limbi cu resurse reduse</title_ro>
      <title_sr>Pronaći zajednički zadatak LoResMT 2020. na nulo-pucanju za jezike niskih resursa</title_sr>
      <title_si>LoResMT 2020ක් සාමාන්‍ය වැඩක් හොයාගන්න සිරෝව-ශෝට් වලින් අඩුම සම්පති භාෂාවට</title_si>
      <title_so>Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource</title_so>
      <title_ta>LoResMT 2020 பகிர்ந்த பணி</title_ta>
      <title_sv>Resultat av LoResMT 2020 delad uppgift om noll-skott för språk med låg resurs</title_sv>
      <title_ur>LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages</title_ur>
      <title_uz>Comment</title_uz>
      <title_vi>Kết quả của công việc chia sẻ LoResMT 2020 Name</title_vi>
      <title_bg>Резултати от споделената задача за нулев изстрел за езици с нисък ресурс</title_bg>
      <title_hr>Pronaći zajednički zadatak LoResMT 2020. na nulo-pucanju za jezike niskih resursa</title_hr>
      <title_da>Resultater af LoResMT 2020 delt opgave om Zero-Shot for lav ressource sprog</title_da>
      <title_nl>Resultaten van de LoResMT 2020 Shared Task over Zero-Shot voor Low Resource talen</title_nl>
      <title_de>Ergebnisse der LoResMT 2020 Shared Task on Zero-Shot für ressourcenarme Sprachen</title_de>
      <title_id>Penemuan Tugas Berkongsi LoResMT 2020 pada Zero-Shot untuk bahasa Sumber Terrendah</title_id>
      <title_fa>Finding of the LoResMT 2020 Shared Task on Zero-Shot for Low Resource languages</title_fa>
      <title_ko>LoResMT 2020 저자원 언어 제로 사격에 대한 공유 작업 발견</title_ko>
      <title_sw>Matokeo ya kazi ya LoResMT 2020 ilishirikishwa kwenye risasi zisizo na rasilimali za chini</title_sw>
      <title_tr>LoResMT 2020'yň Az-Ressourt dilleri üçin 0-Shot'da bölünen zadynyň tapylmak</title_tr>
      <title_af>Finnings van die LoResMT 2020 Gedeelde Opdrag op Nuwe-Shot vir Lae-Hulpbron tale</title_af>
      <title_sq>Gjetjet e detyrës së përbashkët LoResMT 2020 për gjuhët me burime të ulta</title_sq>
      <title_am>የLoResMT 2020 የተሰራረበ ስራዎችን በጽሑፍ-Shot ላይ ለማንበብ-resource ቋንቋዎች</title_am>
      <title_hy>LoReMT 2020-ի ընդհանուր առաջադրանքի բացահայտումները ցածր ռեսուրսների լեզուների զրո-կրակի վրա</title_hy>
      <title_az>LoResMT 2020 paylaşılmış işlərin tapılması</title_az>
      <title_bn>LoResMT ২০২০ সালে শেয়ার করা কাজের অনুসন্ধান নিম্ন- সম্পদ ভাষার জন্য শেয়ার করা হয়েছে</title_bn>
      <title_ca>Results of the LoResMT 2020 Shared Task on Zero-Shot for Low Resource Languages</title_ca>
      <title_cs>Zjištění sdíleného úkolu LoResMT 2020 týkajícího se Zero-Shotu pro jazyky s nízkými zdroji</title_cs>
      <title_et>LoResMT 2020 ühise ülesande tulemused vähese ressursiga keelte puhul, mis käsitlevad null-shoti</title_et>
      <title_bs>Pronaći zajednički zadatak LoResMT 2020. na nulu pucnjavu za jezike niskih resursa</title_bs>
      <title_fi>LoResMT 2020:n yhteisen tehtävän tulokset nollashotista vähävaraisille kielille</title_fi>
      <title_jv>Finding of the LOResMT 2020 shared task on nulo-shot for low-Source</title_jv>
      <title_sk>Ugotovitve skupne naloge LoResMT 2020 o ničelnem strelu za jezike z nizkimi viri</title_sk>
      <title_he>מציאות משימה משותפת LoResMT 2020 על אפס-ירי לשפות משאבים נמוכות</title_he>
      <title_ha>Findings of the LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages</title_ha>
      <title_fil>Mga pagkahanap ng LoResMT 2020 Shared Task sa Zero-Shot para sa mga wikang Low-Resource</title_fil>
      <title_bo>LoResMT 2020 Shared Task on Zero-Shot for Low-Resource languages</title_bo>
      <abstract_ar>تعرض هذه الورقة نتائج المهمة المشتركة LoResMT 2020 بشأن الترجمة بدون طلقة للغات منخفضة الموارد. تم تنظيم هذه المهمة كجزء من ورشة العمل الثالثة حول تقنيات الترجمة الآلية للغات منخفضة الموارد (LoResMT) في AACL-IJCNLP 2020. كان التركيز على نهج إطلاق النار باعتباره تطورًا ملحوظًا في الترجمة الآلية العصبية لبناء أنظمة الترجمة الآلية للغة أزواج حيث تكون المجموعات المتوازية صغيرة أو حتى غير موجودة. تشير تجربة المهام المشتركة إلى أن أساليب الترجمة المرتدة وتكييف المجال تؤدي إلى دقة أفضل لمجموعات البيانات صغيرة الحجم. لاحظنا كذلك أنه على الرغم من أن الترجمة بين اللغات المتشابهة ليست سهلة ، إلا أن اللغات المتميزة لغويًا تتطلب المزيد من البيانات لإعطاء نتائج أفضل.</abstract_ar>
      <abstract_fr>Cet article présente les résultats de la tâche partagée LoreSMT 2020 sur la traduction zero-shot pour les langues à faibles ressources. Cette tâche a été organisée dans le cadre du 3e atelier sur les technologies pour la traduction automatique des langues à faible ressource (LoresMT) à l'AACL-IJCNLP 2020. L'accent a été mis sur l'approche zero-shot en tant que développement notable de la traduction automatique neuronale pour construire des systèmes de TA pour les paires de langues où les corpus parallèles sont petits, voire inexistants. L'expérience des tâches partagées suggère que les méthodes de rétro-traduction et d'adaptation de domaine permettent d'obtenir une meilleure précision pour les ensembles de données de petite taille. Nous avons également noté que, bien que la traduction entre langues similaires ne soit pas un jeu d'enfant, des langues distinctes sur le plan linguistique nécessitent davantage de données pour donner de meilleurs résultats.</abstract_fr>
      <abstract_es>Este artículo presenta los hallazgos de la tarea compartida LoreSMT 2020 sobre la traducción cero para idiomas de bajos recursos. Esta tarea se organizó como parte del 3er Workshop on Technologies for MT of Low Resource Languages (LoreSMT) en AACL-IJCNLP 2020. La atención se centró en el enfoque zero-shot como un desarrollo notable en la traducción automática neuronal para crear sistemas de traducción automática para pares de idiomas en los que los cuerpos paralelos son pequeños o incluso inexistentes. La experiencia de tareas compartidas sugiere que los métodos de retrotraducción y adaptación de dominios dan como resultado una mayor precisión para los conjuntos de datos de tamaño pequeño. Observamos además que, aunque la traducción entre idiomas similares no es pan comido, los idiomas lingüísticamente distintos requieren más datos para obtener mejores resultados.</abstract_es>
      <abstract_pt>Este artigo apresenta as descobertas da Tarefa Compartilhada LoResMT 2020 sobre tradução zero-shot para idiomas com poucos recursos. Esta tarefa foi organizada como parte do 3º Workshop sobre Tecnologias para TA de Linguagens de Baixo Recurso (LoResMT) na AACL-IJCNLP 2020. O foco estava na abordagem zero-shot como um desenvolvimento notável em Tradução Automática Neural para construir sistemas de TA para linguagem pares onde corpora paralelos são pequenos ou mesmo inexistentes. A experiência de tarefa compartilhada sugere que os métodos de retrotradução e adaptação de domínio resultam em melhor precisão para conjuntos de dados de tamanho pequeno. Observamos ainda que, embora a tradução entre idiomas semelhantes não seja moleza, idiomas linguisticamente distintos exigem mais dados para fornecer melhores resultados.</abstract_pt>
      <abstract_ja>本稿では、低資源言語のゼロショット翻訳に関するLoResMT 2020共有タスクの調査結果を紹介する。このタスクは、AACL - IJCNLP 2020における低資源言語（ LoResMT ）のMTのための技術に関する第3回ワークショップの一部として組織されました。ニューラル・マシン・トランスレーションにおける注目すべき発展として、並列体が小さい、または存在しない言語ペアのためのMTシステムを構築するためのゼロショット・アプローチに焦点を当てた。共有されたタスクの経験は、バックトランスレーションとドメインの適応方法が、小さなサイズのデータセットの精度を向上させることを示唆しています。さらに、類似言語間の翻訳はケークウォークではないが、言語学的に異なる言語は、より良い結果をもたらすためにより多くのデータを必要とすることに注目した。</abstract_ja>
      <abstract_hi>यह पेपर कम संसाधन भाषाओं के लिए शून्य-शॉट अनुवाद पर LoResMT 2020 साझा कार्य के निष्कर्षों को प्रस्तुत करता है। यह कार्य AACL-IJCNLP 2020 में कम संसाधन भाषाओं (LoResMT) के एमटी के लिए प्रौद्योगिकियों पर तीसरी कार्यशाला के हिस्से के रूप में आयोजित किया गया था। भाषा जोड़े के लिए एमटी सिस्टम बनाने के लिए न्यूरल मशीन ट्रांसलेशन में एक उल्लेखनीय विकास के रूप में शून्य-शॉट दृष्टिकोण पर ध्यान केंद्रित किया गया था, जहां समानांतर कॉर्पोरेट छोटे या यहां तक कि गैर-मौजूद हैं। साझा कार्य अनुभव से पता चलता है कि बैक-अनुवाद और डोमेन अनुकूलन विधियों के परिणामस्वरूप छोटे आकार के डेटासेट के लिए बेहतर सटीकता होती है। हमने आगे नोट किया कि, हालांकि समान भाषाओं के बीच अनुवाद कोई केकवॉक नहीं है, भाषाई रूप से अलग-अलग भाषाओं को बेहतर परिणाम देने के लिए अधिक डेटा की आवश्यकता होती है।</abstract_hi>
      <abstract_zh>本文LoResMT 2020共低资源语零次性译。 此所以为AACL-IJCNLP 2020第三届低资源言语机器翻译术(LoResMT)研讨会之分也。 夫重者,零镜头之法也,此神经机器翻译之显也,为并行语料库小而不存之语MT系焉。 共享事验,回溯译和域自宜小大规模数集之准确性。 虽类语言之译并非易事,而言语之多者,乃可为善。</abstract_zh>
      <abstract_ru>В настоящем документе представлены выводы совместной задачи LoResMT 2020 по переводу с нулевым снимком для языков с ограниченными ресурсами. Эта задача была организована в рамках 3-го семинара по технологиям для МП малоресурсных языков (LoResMT) на AACL-IJCNLP 2020. Основное внимание было уделено подходу с нулевым выстрелом в качестве заметной разработки в нейронном машинном переводе для создания систем МП для языковых пар, где параллельные корпуса небольшие или даже отсутствуют. Общий опыт выполнения задач позволяет предположить, что методы обратного перевода и адаптации домена приводят к повышению точности для небольших наборов данных. Мы далее отметили, что, хотя перевод между похожими языками не является прогулкой, языковые различия требуют больше данных, чтобы дать лучшие результаты.</abstract_ru>
      <abstract_ukr>У цій статті представлені висновки спільного завдання LoResMT 2020 щодо перекладу без знімків для мов з низьким рівнем ресурсів. Це завдання було організовано в рамках 3-го семінару з технологій МП малоресурсних мов (LoResMT) на AACL-IJCNLP 2020. Акцент був зроблений на підході «нульового знімка» як помітному розвитку в нейронному машинному перекладі для побудови систем МП для мовних пар, де паралельні корпуси невеликі або навіть не існують. Спільний досвід виконання завдань свідчить про те, що методи зворотного перекладу та адаптації домену призводять до кращої точності для малогабаритних наборів даних. Ми також зазначили, що, хоча переклад між подібними мовами не є прогулянкою, лінгвістично відмінні мови вимагають більше даних, щоб дати кращі результати.</abstract_ukr>
      <abstract_ga>Cuireann an páipéar seo i láthair tátail Thasc Roinnte LoResMT 2020 ar aistriúchán nialasach do theangacha lagacmhainne. Eagraíodh an tasc seo mar chuid den 3ú Ceardlann ar Theicneolaíochtaí le haghaidh MT na dTeangacha Ísle Acmhainne (LoResMT) ag AACL-IJCNLP 2020. Díríodh ar an gcur chuige náid mar fhorbairt shuntasach in Neural Machine Translation chun córais MT don teanga a thógáil. péirí ina bhfuil corpora comhthreomhara beag nó fiú nach bhfuil ann. Tugann an taithí taisc chomhroinnte le fios go mbíonn cruinneas níos fearr do thacair sonraí ar mhionmhéid mar thoradh ar mhodhanna aisaistrithe agus oiriúnaithe fearainn. Thugamar faoi deara freisin, cé nach bhfuil aistriúchán idir teangacha comhchosúla ar siúl, go dteastaíonn tuilleadh sonraí ó theangacha sainiúla chun torthaí níos fearr a thabhairt.</abstract_ga>
      <abstract_ka>ამ დოკუმენტის შესახებ LoResMT 2020-ის საზოგადოებული დავალების შესახებ, რომელიც ნულ-სურათის გაგრძელებაში, ცოტა რესურსის ენათებისთვის. ეს დავალება AACL-IJCNLP 2020 წლის სამუშაო ტექნოლოგიების სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო ქმნის პროგრა ტუკუნსტი იყო ნუალური მაქსინის გადაწყვებაში, როგორც მნიშვნელოვანი განვითარებაში MT სისტემის შექმნა ენის ზოგებისთვის, რომლებიც პარალელური კორპორა ცოტა ან არსებობს საზოგადოებული დავალების გამოცდილობა იტყვებს, რომ back-translation და domain adaptation methods result in better accuracy for small size datasets. ჩვენ აღმოჩნეთ, რომ, თუმცა განსხვავებული ენების შორის განსხვავება არ არის კონკონკონტიკური ენების განსხვავება უფრო მეტი მონაცემები, რომ უფრო მეტი შედე</abstract_ka>
      <abstract_el>Η παρούσα εργασία παρουσιάζει τα πορίσματα της κοινής εργασίας σχετικά με τη μετάφραση μηδενικών πυροβολισμών για γλώσσες χαμηλού πόρου. Το έργο αυτό οργανώθηκε στο πλαίσιο του 3ου Εργαστηρίου Τεχνολογίας για τη ΜΤ γλωσσών χαμηλού πόρου (LoResMT) στο AACL-IJCNLP 2020. Η εστίαση ήταν στην προσέγγιση μηδενικού πυροβολισμού ως μια αξιοσημείωτη εξέλιξη στην Νευρική Μηχανική Μετάφραση για την κατασκευή συστημάτων ΜΤ για γλωσσικά ζεύγη όπου τα παράλληλα σώματα είναι μικρά ή ακόμη και ανύπαρκτα. Η κοινή εμπειρία εργασιών υποδηλώνει ότι οι μέθοδοι αντίστροφης μετάφρασης και προσαρμογής τομέων οδηγούν σε καλύτερη ακρίβεια για μικρά σύνολα δεδομένων. Σημειώσαμε επίσης ότι, αν και η μετάφραση μεταξύ παρόμοιων γλωσσών δεν είναι εύκολη, οι γλωσσικά διακριτές γλώσσες απαιτούν περισσότερα δεδομένα για να δώσουν καλύτερα αποτελέσματα.</abstract_el>
      <abstract_hu>Ez a tanulmány bemutatja a LoResMT 2020 Shared Task eredményeit az alacsony erőforrású nyelvekre vonatkozó zéró fordításról. Ezt a feladatot az AACL-IJCNLP 2020 keretében szervezték meg az alacsony erőforrású nyelvek MT technológiáinak (LoResMT) technológiáiról szóló harmadik workshop keretében. A fókuszban a nulla lövéses megközelítésre helyeztük a Neural Machine Translation figyelemre méltó fejlesztését, amely MT rendszereket épített olyan nyelvpárokhoz, ahol a párhuzamos corporák kicsik vagy akár nem léteznek. A megosztott feladatok tapasztalata azt sugallja, hogy a visszafordítási és domain adaptációs módszerek nagyobb pontosságot eredményeznek a kis méretű adatkészletek esetében. Megjegyeztük továbbá, hogy bár a hasonló nyelvek közötti fordítás nem szokásos, a nyelvi szempontból eltérő nyelvek több adatot igényelnek a jobb eredmények eléréséhez.</abstract_hu>
      <abstract_it>Questo articolo presenta i risultati dell'attività condivisa LoResMT 2020 sulla traduzione zero-shot per lingue a basso contenuto di risorse. Questo compito è stato organizzato nell'ambito del 3° Workshop sulle tecnologie per la MT dei linguaggi a bassa risorsa (LoResMT) presso AACL-IJCNLP 2020. L'attenzione era sull'approccio zero-shot come uno sviluppo notevole nella Neural Machine Translation per costruire sistemi MT per coppie linguistiche in cui i corpi paralleli sono piccoli o addirittura inesistenti. L'esperienza di attività condivisa suggerisce che i metodi di back-translation e adattamento del dominio comportano una maggiore precisione per set di dati di piccole dimensioni. Abbiamo inoltre notato che, sebbene la traduzione tra lingue simili non sia un gioco da ragazzi, lingue linguisticamente distinte richiedono più dati per dare risultati migliori.</abstract_it>
      <abstract_kk>Бұл қағаз LoResMT 2020 ортақтастырылған тапсырманың тапсырмасын бағасы ресурстар тілдерінің ортақтастыру үшін null- shot аудармасынан табылады. Бұл тапсырма AACL-IJCNLP 2020 жылы Төменгі ресурс тілдері (LoResMT) үшін технологиялардың 3- ші жұмысының бөлігі болды. Тілді екеуі үшін MT жүйелерін құру үшін нейрондық машинаның аудармасында белгілі жасау үшін нөл түрлендіру тәсілдеріне назар аудару керек. Ортақ тапсырманың тәжірибесі, қайта аудару мен доменнің адаптациялау әдістері кішкентай өлшемінің деректер жиындарының дұрыстығын көрсетеді. Біз осы тілдер арасындағы аудармалар керек болмаса да, тілдер тілдерінің көптеген мәліметтері жақсы нәтижелерді беру үшін көптеген деректерді талап етеді.</abstract_kk>
      <abstract_isl>횧essi papp챠r s첵nir ni챨urst철챨ur LoResMT 2020 sameiginlegs verkefnis um n첬ll-skotf챈ra 첸첵챨ingu fyrir litla upprunalega tungum찼l. 횧essi verkefni var skipulagt sem hluti af 첸ri챨ju vinnuve챨fer챨inni um t챈kni fyrir MT 챠 langvarandi tungum찼l (LoResMT) 찼 AACL-IJCNLP 2020. Einbeitingurinn var 찼 n첬ll-skotf챈ri sem s챕rstakur 첸r처un 챠 taugav챕lar첸첵챨ingu til a 챨 byggja MT kerfi fyrir tungum철rk 첸ar sem samhli챨a l챠kama eru l챠til e챨a jafnvel ekki til sta챨ar. Sameiginleg verkefnisreynsla bendir til 첸ess a챨 endurtekningar og a챨l철gun sv챈챨is lei챨a til betri n찼kv챈mni fyrir litla gagnagrunn. Vi챨 t처kum frekar eftir 첸v챠 a챨 첸처tt 첸첵챨ing milli svipa챨ra tungum찼la s챕 engin k철kug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngug철ngum.</abstract_isl>
      <abstract_lt>Šiame dokumente pateikiamos bendros užduoties „LoResMT 2020“ išvados, susijusios su nuliniu vertimu mažai išteklių turinčiomis kalbomis. Ši užduotis buvo surengta kaip trečiojo mažų išteklių kalbų MT technologijų seminaro (LoResMT) dalis AACL-IJCNLP 2020 m. Daugiausia dėmesio buvo skiriama nuliniam požiūriui, kaip pažangiam vystymuisi neurologinių mašin ų vertimo srityje kuriant MT sistemas kalbų poroms, kuriose lygiagrečios korpros yra mažos arba net neegzistuoja. Iš bendros užduoties patirties matyti, kad grįžtamojo vertimo ir srities pritaikymo metodai užtikrina geresnį mažų duomenų rinkinių tikslumą. Be to, atkreipėme dėmesį į tai, kad nors vertimas tarp panašių kalbų nėra klaidingas, kalbomis reikia daugiau duomenų, kad būtų pasiekti geresni rezultatai.</abstract_lt>
      <abstract_mk>Овој документ ги претставува заклучоците на заедничката задача LoResMT 2020 за превод со нула снимка за јазици со ниски ресурси. Оваа задача беше организирана како дел од третиот работилник за технологии за МТ на јазиците со ниски ресурси (LoResMT) на ААКЛ-IJCNLP 2020. Фокусот се фокусираше на пристапот со нула пукање како значителен развој во преведувањето на невралните машини за изградба на МТ системи за јазичките парови каде паралелните корпора се мали или дури и непостоечки. Соделеното искуство со задачите покажува дека методите на превод и адаптација на домените резултираат со подобра прецизност за малите податоци. Покрај тоа истакнавме дека, иако преводот помеѓу сличните јазици не е прошетка, јазички различните јазици бараат повеќе податоци за да дадат подобри резултати.</abstract_mk>
      <abstract_ms>Kertas ini memperkenalkan penemuan Tugas Berkongsi LoResMT 2020 mengenai terjemahan-sifar untuk bahasa sumber rendah. Tugas ini telah diatur sebagai sebahagian dari Workshop ketiga Teknologi untuk MT bahasa Sumber Terrendah (LoResMT) di AACL-IJCNLP 2020. Fokus adalah pada pendekatan tembakan sifar sebagai pembangunan yang terkenal dalam Perjemahan Mesin Neural untuk membina sistem MT untuk pasangan bahasa di mana corpora selari adalah kecil atau bahkan tidak wujud. Pengalaman tugas berkongsi menunjukkan bahawa kaedah terjemahan-belakang dan penyesuaian domain mengakibatkan ketepatan yang lebih baik bagi set data saiz kecil. Kami juga menyatakan bahawa walaupun terjemahan antara bahasa yang sama bukanlah cakewalk, bahasa yang berbeza secara bahasa memerlukan lebih banyak data untuk memberikan keputusan yang lebih baik.</abstract_ms>
      <abstract_ml>ഈ പത്രത്തില്‍ ലോറെസ്എംടി 2020 പങ്കാളിയുള്ള ടാസ്കിന്റെ കണ്ടുപിടികള്‍ കാണിച്ചുകൊടുക്കുന്നു. പൂജ്യ വിഭവങ് എഎക്സില്‍- IJCNLP 2020-ല്‍ എംടി ഓഫ് കുറഞ്ഞ റിസോര്‍സ് ഭാഷകള്‍ക്കുള്ള ടെക്നോളജികളുടെ മൂന്നാം വാര്‍ക്ക് ഷോപ്പില്‍ ഒരു ഭാഗമായി ഈ ജോലി സം ഈ ഫോക്സോക്സ് നെയുറല്‍ മെഷീന്‍ പരിഭാഷകളിലെ പൂര്‍ണ്ണമായ വിവരങ്ങളായിരുന്നു. ഭാഷ ജോടികള്‍ക്കായി എംടി സിസ്റ്റം ഉണ്ടാക്കുവാന്‍ മാത്രം  പങ്കാളിയുള്ള ജോലിയുടെ അനുഭവങ്ങള്‍ പിന്നിലെ പരിഭാഷവും ഡൊമെയിന്‍ അഡാപ്റ്റേഷന്‍ രീതികളും ചെറിയ വലിപ്പം ഡാറ് ഞങ്ങള്‍ കൂടുതല്‍ നോക്കിയിരിക്കുന്നു, ഇതുപോലുള്ള ഭാഷകള്‍ക്കിടയിലെ പരിഭാഷകങ്ങള്‍ കേക്കേവ്വ് അല്ലെങ്കിലും, ഭാഷ വ്യത്</abstract_ml>
      <abstract_mn>Энэ цаас LoResMT 2020 оны хуваалтын ажил нь бага баялаг боловсролын хэл дээр 0-shot орчуулалтын тухай илтгэдэг. Энэ ажил AACL-IJCNLP 2020 оны MT-н Бага Нийтийн хэлний (LoResMT) технологийн 3-р ажлын нэг хэсэг болсон. Үүний гол санаа нь хэл хоёр төрлийн MT системийг бүтээх гэсэн мэдрэлийн машины хөгжлийн тодорхой хөгжлийн тодорхойлолт юм. Бүлэг хэмжээний ажлын туршлага буцаагдах болон холбоотой адилтгах арга нь жижиг хэмжээний өгөгдлийн санг илүү зөв болгодог. Бид өөр хэлбэл төстэй хэл хоорондын орчуулалт нь бялуун хэл биш ч гэсэн, хэлний ялгаатай хэл нь илүү сайн үр дүнг өгөхийн тулд илүү олон өгөгдлийн шаардлагатай гэдгийг анзаарсан.</abstract_mn>
      <abstract_mt>Dan id-dokument jippreżenta s-sejbiet tal-Kompitu Konġunt LoResMT 2020 dwar traduzzjoni mingħajr skop għal lingwi b’riżorsi baxxi. Dan il-kompitu ġie organizzat bħala parti mit-tielet Workshop dwar it-Teknoloġiji għall-MT ta’ Lingwi b’Riżorsi Baxxi (LoResMT) f’AACL-IJCNLP 2020. L-enfasi kienet fuq l-approċċ zero-shot bħala żvilupp notevoli fit-Traduzzjoni tal-Makkinarju Newrali biex jinbnew sistemi MT għal pari lingwistiċi fejn il-korpura parallel a hija żgħira jew saħansitra mhux eżistenti. L-esperjenza ta’ kompiti kondiviżi tissuġġerixxi li l-metodi ta’ traduzzjoni lura u adattament tad-dominju jirriżultaw f’preċiżjoni aħjar għal settijiet ta’ dejta ta’ daqs żgħir. Barra minn hekk innotaw li, għalkemm it-traduzzjoni bejn lingwi simili mhijiex mixja, lingwi lingwistikament distinti jeħtieġu aktar dejta biex jagħtu riżultati aħjar.</abstract_mt>
      <abstract_no>Denne papiret viser finningane av LoResMT 2020- delt oppgåve ved omsetjing av null- shot for låg ressursspråk. Denne oppgåva vart organisert som del av den tredje arbeidsområdet på teknologi for MT av låg ressursspråk (LoResMT) på AACL-IJCNLP 2020. Fokuseret var på tilnærminga med null-foto som eit merkelig utvikling i Neuralmaskinsomsetjing for å bygge MT-systemet for språkparar der parallelle korpora er små eller til og med ikkje eksisterande. Den delte oppgåveopplevelsen tyder på at tilbakeomsetjingsmetodar og domenetilpassingsmetodar fører til betre nøyaktighet for små storleik dataset. Vi merkte meir at, selv om omsetjinga mellom like språk er ingen køykeverk, treng språk for å gje betre resultat fleire data.</abstract_no>
      <abstract_pl>Niniejszy artykuł przedstawia wyniki wspólnego zadania LoResMT 2020 dotyczącego tłumaczenia zero-shot dla języków niskich zasobów. Zadanie to zostało zorganizowane w ramach III Warsztatów Technologii dla MT języków niskich zasobów (LoResMT) w AACL-IJCNLP 2020. Skupiono się na podejściu zero-shot jako istotnym rozwoju w neuronowym tłumaczeniu maszynowym w celu budowy systemów MT dla par językowych, w których korpusy równoległe są małe lub nawet nie istnieją. Wspólne doświadczenie zadań sugeruje, że metody tłumaczenia wstecznego i adaptacji domeny zapewniają lepszą dokładność dla małych zbiorów danych. Zauważyliśmy również, że chociaż tłumaczenie pomiędzy podobnymi językami nie jest łatwe, językowo odrębne języki wymagają więcej danych, aby dać lepsze wyniki.</abstract_pl>
      <abstract_sr>Ovaj papir predstavlja nalaze zajedničkog zadatka LoResMT 2020 o prevodu nula pucnjave za niske jezike resursa. Ovaj zadatak je organizovan kao deo 3. radionice o tehnologiji za MT jezika niskih resursa (LoResMT) na AACL-IJCNLP 2020. godini. Fokus je bio na pristupu nule pucnjave kao poznati razvoj u Neuralnoj prevodi mašine da izgradi MT sisteme za parove jezika gde su paralelna korpora mala ili čak i ne postoje. Podijeljeno iskustvo zadatka ukazuje na to da metode adaptacije povratka i domena rezultuju bolju tačnost za male veličine podataka. Dodatno smo primetili da, iako prevod između sličnih jezika nije kolač, jezici koji su različiti zahtevaju više podataka da bi dobili bolji rezultat.</abstract_sr>
      <abstract_ro>Această lucrare prezintă constatările activității partajate LoResMT 2020 privind traducerea zero-shot pentru limbi cu resurse reduse. Această sarcină a fost organizată în cadrul celui de-al treilea atelier de lucru privind tehnologiile pentru MT de limbi cu resurse reduse (LoResMT) la AACL-IJCNLP 2020. Accentul a fost pus pe abordarea zero-shot ca o dezvoltare notabilă în Neural Machine Translation pentru a construi sisteme MT pentru perechi de limbi în care corpurile paralele sunt mici sau chiar inexistente. Experiența partajată a sarcinilor sugerează că metodele de traducere înapoi și adaptare a domeniilor duc la o mai bună precizie pentru seturile de date de dimensiuni mici. De asemenea, am remarcat faptul că, deși traducerea între limbi similare nu reprezintă o simplă plimbare, limbile distincte lingvistic necesită mai multe date pentru a oferi rezultate mai bune.</abstract_ro>
      <abstract_si>මේ පැත්ත පෙනුවෙන් LoResMT 2020යි සාමාන්‍ය වැඩක් හොයාගන්න පුළුවන් විදියට සුන්ධ- ශෝට් විදියට පහළ භ මේ වැඩය AACL-IJCNLP දී තේක්ෂණාවික භාෂාව (LoResMT) සඳහා MT ගැන තේක්ෂණාවික භාෂාව සඳහා තුන්වෙනි වැඩසටහන් කොටස් වලි සුන්ධ වෙඩි තියෙන්නේ න්‍යූරාල් මැෂින් පරිවර්තනයේ සුන්ධ වෙඩි තියෙන්නේ MT පද්ධතිය සඳහා භාෂාවක් ජෝඩාවක් නිර සමාගත වැඩක් අභ්‍යාගයක් ප්‍රයෝජනය කරන්න පුළුවන් විදිහට පස්සේ අවවාදය සහ ඩෝමේන් සැකසුම් විදිහට ප අපි දැනගත්තා කියලා, වගේ භාෂාවල් අතර වාර්තාවක් නෙවෙයි, භාෂාවික විශේෂ භාෂාවිතයෙන් වඩා තොරතුර</abstract_si>
      <abstract_so>Kanu waa qoraalkaas oo ku qoran koontarooyinka la xiriiray Shaqada LoResMT 2020 oo lagu sharciyey tarjumaadda zero-shot ee luqadaha hoose resource. Shaqadan waxaa loo qabanqaabiyey as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020. Fogta waxaa ku qoran qoraalka zero-shot ah oo ah horumar aad u yaqaan qoraalka baabuurta ee Neural Mashine Turjumidda si uu u dhiso MT nidaamka labo luqada ah, kaasoo shirkadda lambarka ah ay yaryihiin ama xataa aan jirin. Gargaarka shaqada ee la qaybsan waxaa loola jeedaa in qalabka ku habboonaanta dib-turjumista iyo dalabka bedelka ee gudaha lagu sameeyo ay ku sababto sax ka fiican saxda kooxda macluumaadka yar. Waxaynu sii soconnay, in kastoo turjumidda luuqadaha oo isku mid ah aysan ahayn waddooyinka qashinka, luuqadaha kala duduwan waxay u baahan yihiin macluumaad dheeraad ah si ay u helaan resulto ka wanaagsan.</abstract_so>
      <abstract_sv>Denna uppsats presenterar resultaten av LoResMT 2020 Shared Task om noll-shot översättning för språk med låg resurs. Denna uppgift organiserades som en del av den tredje workshopen om teknik för MT för lågresursspråk (LoResMT) vid AACL-IJCNLP 2020. Fokus låg på nollskottsmetoden som en anmärkningsvärd utveckling inom Neural Machine Translation för att bygga MT-system för språkpar där parallella korporar är små eller till och med obefintliga. Den delade uppgiftserfarenheten tyder på att bakåtöversättnings- och domänanpassningsmetoder ger bättre noggrannhet för små datauppsättningar. Vi noterade vidare att även om översättningar mellan liknande språk inte är en lättgångare kräver språkligt skilda språk mer data för att ge bättre resultat.</abstract_sv>
      <abstract_ta>This paper presents the findings of the LoResMT 2020 Shared Task on zero- shot translation for low resource languages. AACL- IJCNLP 2020-ல் MT இன் குறைந்த மூன்றாம் மூன்றாம் தொழில்நுட்ப வார்த்தைகளின் பகுதியாக இந்த செயல் அமைக்கப்பட்டது. The focus was on the zero- shot approach as a notable development in Neural machine Translation for building MT systems for language pairs where parallel corpora is small or even non existent. பகிர்ந்த பணியின் அனுபவத்தின் மீண்டும் மொழிபெயர்ப்பு மற்றும் domain adaptation முறைமை நாம் மேலும் குறிப்பிட்டுக் கொண்டோம், போன்ற மொழிகளுக்கிடையே மொழிபெயர்ப்பு கேக்காவ் இல்லை என்றாலும், மொழி</abstract_ta>
      <abstract_ur>This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages. یہ کام AACL-IJCNLP 2020 میں نیچے سرمایہ زبانوں کے MT کے لئے تیسرے کارشکپ کے حصے میں سازمان کیا گیا تھا۔ مٹی سیسٹم کو زبان جوڑوں کے لئے بنانے کے لئے نورول ماشین کی ترجمہ میں مشخص طریقے کے ذریعہ صفر-شٹ کی طریقے پر فعال کیا گیا تھا جہاں parallel corpora چھوٹے یا حتی بغیر موجود ہیں. مشترک دنیا کا تجربہ یہ سفارش دیتا ہے کہ پیچھے-ترجمہ اور ڈومین ادامه کا طریقہ چھوٹے سائز ڈاٹ سٹ کے لئے بہترین دقیق کا نتیجہ ہوتا ہے. اور ہم نے بھی یاد کیا کہ، اگرچہ ان جیسی زبانوں کے درمیان ترجمہ کیک واک نہیں ہے، زبان کی مختلف زبانوں کے لئے بہتر نتیجے عطا کرنے کے لئے زیادہ دیٹا ضرورت ہے.</abstract_ur>
      <abstract_uz>Bu qadam LoResMT 2020 shartlangan vazifaning natijalarini qisqa manba tillar uchun hech narsa yoʻq tarjima qilishini koʻrsatiladi. Name Name @ info: whatsthis Biz bir necha ko'rsatganimiz, agar bir xil tillar orasidagi tarjima ma'lumot yoʻq, tillarda bir xil tilda yaxshi natijalarni bajarish uchun qo'shimcha maʼlumot kerak.</abstract_uz>
      <abstract_vi>Tờ giấy này trình bày kết quả của công việc chia sẻ LoResMT 2020 về phiên dịch không bắn cho ngôn ngữ ít tài nguyên. Nhiệm vụ này được tổ chức như một phần của tập đoàn Ba Công nghệ về Giao thông Kỷ nguyên Kiến Tạo (LoResMT) tại AAA-IJCNchọc 2020. Tập trung vào phương pháp bắn không là một phát triển đáng chú ý trong dịch lắp máy thần kinh để xây dựng các hệ thống MTV cho các cặp ngôn ngữ nơi mà cơ thể song song song song cũng nhỏ hoặc thậm chí không tồn tại. Kinh nghiệm chia sẻ nhiệm vụ cho thấy phương pháp phục dịch lại và sửa chữa miền có hiệu quả tốt hơn cho các tập tin nhỏ. Chúng tôi cũng nhận thấy rằng, mặc dù dịch giữa ngôn ngữ tương tự không dễ dàng, nhưng ngôn ngữ khác nhau cần nhiều dữ liệu hơn để có kết quả tốt hơn.</abstract_vi>
      <abstract_bg>В настоящата статия са представени констатациите от Споделената задача за превод с нулев изстрел за езици с нисък ресурс. Тази задача бе организирана като част от Третия семинар по технологии за МТ на нискоресурсните езици (ЛоРЕСМТ) в ААКЛ-ИДНЛП 2020. Фокусът беше върху подхода с нулев изстрел като забележително развитие в невралния машинен превод за изграждане на МТ системи за езикови двойки, където паралелните корпуси са малки или дори липсват. Опитът с споделените задачи предполага, че методите за обратен превод и адаптиране на домейна водят до по-добра точност за малки масиви от данни. Освен това отбелязахме, че макар преводът между сходни езици да не е лесно, езиково отделните езици изискват повече данни, за да дадат по-добри резултати.</abstract_bg>
      <abstract_nl>Dit document presenteert de bevindingen van de LoResMT 2020 Shared Task over zero-shot vertaling voor talen met weinig resources. Deze taak werd georganiseerd in het kader van de 3e Workshop Technologieën voor MT van Low Resource Languages (LoResMT) bij AACL-IJCNLP 2020. De focus lag op de zero-shot benadering als een opmerkelijke ontwikkeling in Neural Machine Translation om MT systemen te bouwen voor taalparen waar parallelle corpora klein of zelfs niet bestaan. De gedeelde task ervaring suggereert dat back-translation en domeinaanpassingsmethoden resulteren in een betere nauwkeurigheid voor kleine datasets. We merkten verder op dat, hoewel vertaling tussen vergelijkbare talen geen makkie is, taalkundig verschillende talen meer gegevens vereisen om betere resultaten te geven.</abstract_nl>
      <abstract_hr>Ovaj novinar predstavlja nalaze zajedničkog zadatka LoResMT 2020 o prevodu nula snimka za niske jezike resursa. Ovaj zadatak je organiziran kao dio 3. radionice o tehnologijama za MT jezika niskih resursa (LoResMT) na AACL-IJCNLP 2020. godini. Fokus je bio na pristupu nule pucnjave kao poznati razvoj u Neuralnom prevodu strojeva za izgradnju MT sustava za jezičke pare gdje su paralelna korpora mala ili čak i ne postoje. Podijeljeno iskustvo zadatka ukazuje na to da metode prilagodbe natrag i domena rezultiraju bolju preciznost za male veličine podataka. Dodatno smo primjetili da, iako prevod između sličnih jezika nije kolač, jezički različiti jezici zahtijevaju više podataka za pružanje boljih rezultata.</abstract_hr>
      <abstract_da>Dette dokument præsenterer resultaterne af LoResMT 2020 Shared Task om nulskudsoversættelse til sprog med lave ressourcer. Denne opgave blev organiseret som en del af 3. Workshop om teknologier til MT af lav ressource sprog (LoResMT) på AACL-IJCNLP 2020. Fokus var på nul-shot tilgang som en bemærkelsesværdig udvikling i Neural Machine Translation til at bygge MT-systemer til sprogpar, hvor parallelle korpora er små eller endda ikke-eksisterende. Den delte opgaveoplevelse tyder på, at metoder til backoversættelse og domænetilpasning resulterer i bedre nøjagtighed for små datasæt. Vi bemærkede endvidere, at selv om oversættelse mellem lignende sprog ikke er nogen kagewalk, kræver sprogligt adskilte sprog flere data for at give bedre resultater.</abstract_da>
      <abstract_de>Dieser Beitrag stellt die Ergebnisse der LoResMT 2020 Shared Task zur Zero-Shot-Übersetzung für ressourcenarme Sprachen vor. Diese Aufgabe wurde im Rahmen des dritten Workshops zu Technologien für MT von Low Resource Languages (LoResMT) am AACL-IJCNLP 2020 organisiert. Der Fokus lag auf dem Zero-Shot-Ansatz als bemerkenswerte Entwicklung in der neuronalen maschinellen Übersetzung, um MT-Systeme für Sprachpaare zu bauen, bei denen parallele Korpora klein oder gar nicht vorhanden sind. Die gemeinsame Aufgabenerfahrung deutet darauf hin, dass Backtranslation und Domänenanpassungsmethoden zu einer besseren Genauigkeit für kleine Datensätze führen. Wir stellten ferner fest, dass, obwohl die Übersetzung zwischen ähnlichen Sprachen kein Kinderspiel ist, linguistisch getrennte Sprachen mehr Daten benötigen, um bessere Ergebnisse zu erzielen.</abstract_de>
      <abstract_id>This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages.  Tugas ini diatur sebagai bagian dari Workshop ketiga Teknologi untuk MT dari bahasa sumber daya rendah (LoResMT) di AACL-IJCNLP 2020. The focus was on the zero-shot approach as a notable development in Neural Machine Translation to build MT systems for language pairs where parallel corpora are small or even non-existent.  Pengalaman tugas berbagi menunjukkan bahwa metode penerjemah belakang dan adaptasi domain menghasilkan akurasi yang lebih baik untuk set data ukuran kecil. Kami juga memperhatikan bahwa, meskipun terjemahan antara bahasa yang sama bukan cakewalk, bahasa yang berbeda secara bahasa membutuhkan lebih banyak data untuk memberikan hasil yang lebih baik.</abstract_id>
      <abstract_sw>This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages.  Kazi hii iliandaliwa kama sehemu ya warsha ya tatu ya Teknolojia kwa ajili ya MT ya Lugha za Rasilimali Bora (Low Resource MT) katika AACL-IJCNLP 2020. Lengo lilikuwa juu ya mbinu zisizo za kisasa kama maendeleo maarufu katika Tafsiri ya Mashine ya Neural ili kujenga mfumo wa MT kwa ajili ya wanandoa wa lugha ambapo makampuni yanafanana ni ndogo au hata haipo. uzoefu wa kazi zilizoshirikishwa unaonyesha kuwa tafsiri na mbinu za kubadilisha ndani zinazosababisha uhakika bora kwa seti za data ndogo. Tulifuatilia zaidi kwamba, ingawa tafsiri kati ya lugha hizo hazina mkaa, lugha tofauti za lugha zinahitaji data zaidi kutoa matokeo bora.</abstract_sw>
      <abstract_fa>این کاغذ نشان می‌دهد که نتیجه‌هایی از کار مشترک LoResMT 2020 در ترجمه‌های صفر برای زبانهای منابع کم را نشان می‌دهد. این وظیفه به عنوان بخشی از سومین کارگاه روی تکنولوژی برای MT از زبانهای منابع کم (LoResMT) در AACL-IJCNLP ۲۰۰۲ سازمان شده است. تمرکز روی روش صفر فشار به عنوان توسعه مشخص در ترجمه ماشین عصبی برای ساختن سیستم‌های MT برای جفت زبان جایی که شرکت پارالی کوچک یا حتی وجود ندارد. تجربه کار مشترک پیشنهاد می‌دهد که روش‌های تغییر برگشتن و تغییر‌سازی دومین‌ها برای مجموعه‌های داده‌های اندازه‌های کوچک بهتر به نتیجه می‌رسد. اگرچه ترجمه بین زبانهای مشابه کیک نیست، زبانهای متفاوتی به زبان نیاز دارند داده های بیشتری برای دادن نتایج بهتر.</abstract_fa>
      <abstract_tr>Bu kagyz LoResMT 2020-nji ýylyň beýleki zadynyň çykyş dilleri üçin 0-shot terjime edilmesinden çykýar. Bu zady AACL-IJCNLP 2020'de, MT'iň iň az ResMT dilleri (LoResMT) üçin tehnologiýaly üçin 3-nji Workshop on Technologies (3-nji Workshop on Technology) tarapynda düzenlenýär. Bu tema näyräk atjylyk (zero-shot) ýagdaýynda, näyral maşynyň terjimesinde, MT sistemalary dil çiftleri üçin gurmak üçin, parallel korpora kiçi ýa-da hiç bar. Ýabşyrlanan täblisaň terjime edilen arka-terjime we domain adaptasyon metodlarynyň kiçi-ululyk datajylar üçin has dogrylyklygyny üýtgedýär. Biz diňe-de "ýaly diller arasynda terjime edilen çykyş däldir" diýip hasapladyk. Diller bolsa has gowy netijelere bermek üçin köp maglumaty gerek.</abstract_tr>
      <abstract_af>Hierdie papier stel die gevindings van die LoResMT 2020 Gedeelde Opdrag op nulskoot vertaling vir lae hulpbron tale. Hierdie taak is organiseer as deel van die derde werkshop op Tehnologies vir MT van Lae Hulpbron Taal (LoResMT) by AACL-IJCNLP 2020. Die fokus was op die nul-skoot toegang as 'n notabele ontwikkeling in Neural Masjien Vertaling om MT stelsels vir taal paar te bou waar parallele korpora klein of selfs nie-bestaan is. Die gedeelde taak erfaring stel voorstel dat terugvertaling en domein aanpassing metodes resulteer in beter presisie vir klein grootte datastelle. Ons het verder opgemerk dat, alhoewel vertaling tussen soortgelyke tale is geen koekweelk nie, lingwisieslik verskillende tale het meer data nodig om beter resultate te gee.</abstract_af>
      <abstract_sq>Ky dokument paraqet gjetjet e LoResMT 2020 Task Shared mbi përkthimin zero-shot për gjuhët e ulëta të burimeve. Kjo detyrë u organizua si pjesë e seminarit të tretë mbi teknologjitë për MT të gjuhëve me burime të ulta (LoResMT) në AACL-IJCNLP 2020. Fokusi ishte në qasjen zero-shot si një zhvillim i rëndësishëm në Translacionin e Makinës Neurale për të ndërtuar sisteme MT për çifte gjuhësh ku korpra paralele janë të vogla apo madje jo ekzistuese. Përvoja e përbashkët e detyrave sugjeron se metodat e përkthimit mbrapsht dhe të përshtatjes së domenit rezultojnë në saktësi më të mirë për të dhënat e madhësisë së vogël. Ne vumë në dukje më tej se, megjithëse përkthimi midis gjuhëve të ngjashme nuk është kërcim, gjuhët gjuhësore të ndryshme kërkojnë më shumë të dhëna për të dhënë rezultate më të mira.</abstract_sq>
      <abstract_am>ይህ ገጽ የLoResMT 2020 የተሰራጨውን ስራዎችን በzero-shot ትርጓሜ ለማንበብ ምዕራፍ ቋንቋዎች ላይ ያሳያል፡፡ This task was organised as part of the 3rd Workshop on Technologies for MT of Low Resource Languages (LoResMT) at AACL-IJCNLP 2020.  ምኩስቡም የኮርፖርት ትንሽ ወይም እንኳ የማይገኙበት የቋንቋ ሁኔታ MT ስርዓቶችን ለመሥራት በኔural Machine ትርጓሜ ላይ ጥሩ ሆኖ ነበር፡፡ ትርጉም እና ዶሜን አስተካክል ማድረግ ማድረጊያውን ለትንሽ ትልቅ ዳታ ማሰናከል ያሳያል፡፡ በተለያዩ ቋንቋዎች መካከል ትርጓሜ ካኬኬክ መሄድ ቢሆን የቋንቋ ቋንቋዎች በተለየ ቋንቋ ላይ የተሻለ ፍሬዎችን እንዲሰጥ ዳታ ያስፈልጋል፡፡</abstract_am>
      <abstract_az>Bu kağıt LoResMT 2020'nin paylaşılmış işlərinin sonsuz-şəkil çevirilməsi üçün düşük ressurs dillərinin istifadəsinə gətirir. Bu görev AACL-IJCNLP 2020-də Təknoloji dillərinin MT (LoResMT) üçüncü çalışmalarının bir parças ı olaraq organize edildi. Nöral Makina Çevirməsi üçün, paralel korpora kiçik və ya hətta olmayan dil çiftləri üçün MT sistemlərini in şa etmək üçün nöral maşın tərzində fərqli tərzdə tərzdə tərzdə tərzdə idi. Bölünən təcrübə təcrübəsi geri-tercümə və domain adaptasiya metodlarının, kiçik böyüklük veri quruları üçün daha doğruluğu olaraq təcrübə edir. Biz də belə bildik ki, bənzər dillər arasındakı tərcümə çəkilməyə baxmayaraq, dillərin müxtəlif dilləri daha yaxşı sonuçlar vermək üçün daha çox məlumat lazımdır.</abstract_az>
      <abstract_bn>এই পত্রিকাটি লোরেসএমটি ২০২০ শেয়ার করা কাজের ফলাফলের উপস্থাপন করেছে যারা নিম্নলিখিত সম্পদ ভাষার জন্য শুরু করেছে। এACL-IJCNLP ২০২০ এ এমটি অফ নিম্ন রিসোর্স ভাষার জন্য প্রযুক্তির তৃতীয় ওয়ার্কশপের অংশ হিসেবে এই কাজ আয়োজন করা হয়েছে। ভাষা জোড়ার জন্য এমটি সিস্টেম নির্মাণ করার জন্য নিউরাল মেশিনের অনুবাদ হিসেবে শূন্য-গুলির প্রতিক্রিয়ার উপর মনোযোগ ছিল যেখানে প্যারা শেয়ার করা কাজের অভিজ্ঞতা প্রস্তাব করে যে ব্যাক-ভাষায় অনুবাদ এবং ডোমেইন অ্যাডাপেটশন পদ্ধতি ছোট-size ডাটাসেটের জন্ আমরা আরো উল্লেখ করেছি যে যদিও একই ভাষার মধ্যে অনুবাদ ক্যাকেওয়ার নেই, তবে ভাষায় ভাষায় ভিন্ন ভিন্ন ভাষায় আরো ভালো ফলাফল দেয়</abstract_bn>
      <abstract_hy>Այս աշխատանքը ներկայացնում է LoReMT 2020-ի ընդհանուր հանձնարարության եզրակացությունները ցածր ռեսուրսների լեզուների համար զրոյի թարգմանման մասին: Այս հանձնարարությունը կազմակերպել է AAC-IJCNLP 2020-ի AAC-ում ցածր ռեսուրսների լեզուների MT-ի տեխնոլոգիաների երրորդ աշխատասենյակում: Սկզբունքն այն էր, որ նյարդային մեքենայի թարգմանման մեջ զրոյի մոտեցումն է, որպես նշանակալի զարգացում ստեղծելու համար լեզվի զույգերի MT համակարգեր, որտեղ զուգահեռ մարմինները փոքր են, կամ նույնիսկ չգոյություն Ընդհանուր խնդիրների փորձը ցույց է տալիս, որ վերադարձ թարգմանությունը և բնագավառի ադապտացիայի մեթոդները ավելի ճշգրիտ են հանգեցնում փոքրիկ տվյալների համակարգերի համար: Մենք նաև նկատեցինք, որ չնայած, որ նման լեզուների միջև թարգմանությունը պարզ չէ, լեզվաբանական տարբեր լեզուներն ավելի շատ տվյալներ են պահանջում ավելի լավ արդյունքներ տալու համար:</abstract_hy>
      <abstract_ko>본고는 LoResMT 2020의 저자원 언어 제로 렌즈 번역 공유 임무에 대한 연구 결과를 소개한다.이 임무는 제3차 저자원 언어 기계번역기술 세미나(LoResMT)의 일부로 AACL-IJCNLP 2020에서 조직되었다.제로 렌즈 방법에 중점을 두는 것은 신경 기계 번역의 현저한 발전으로 평행 어료 라이브러리가 비교적 작고 심지어 존재하지 않는 언어를 위해 기계 번역 시스템을 구축할 수 있다.공유된 임무 경험에 따르면 소규모 데이터 집합에 대해 역방향 번역과 역 적응 방법은 정확성을 높일 수 있다.우리는 비록 비슷한 언어 간의 번역은 쉽지 않지만, 언어가 다른 언어는 더 많은 데이터를 필요로 해야만 더 좋은 결과를 얻을 수 있다는 것을 더욱 알아차렸다.</abstract_ko>
      <abstract_bs>Ovaj novinar predstavlja nalaze zajedničkog zadatka LoResMT 2020 o prevodu nula snimka za niske jezike resursa. Ovaj zadatak je organiziran kao dio 3. radionice o tehnologijama za MT jezika niskih resursa (LoResMT) na AACL-IJCNLP 2020. godini. Fokus je bio na pristupu nule pucnjave kao poznati razvoj u Neuralnoj prevodi mašine za izgradnju MT sistema za jezičke pare gdje su paralelna korpora mala ili čak i ne postoje. Podijeljeno iskustvo zadatka ukazuje na to da metode adaptacije natrag i domena rezultiraju bolju preciznost za male veličine podataka. Dodatno smo primjetili da, iako prevod između sličnih jezika nije kolač, jezici različitih zahtijevaju više podataka kako bi dati bolji rezultat.</abstract_bs>
      <abstract_ca>This paper presents the findings of the LoResMT 2020 Shared Task on zero-shot translation for low resource languages.  Aquesta tasca va ser organitzada com part de la tercera taller sobre tecnologies per MT de llengües de baix recursos (LoResMT) a AACL-IJCNLP 2020. El foc va ser en l'enfocament de zero-shot com un desenvolupament notable en la Translació de Máquines Neurals per construir sistemes MT per parelles de llenguatges on corpores paralèls són petits o fins i tot no existents. L'experiència compartida de les tasques suggereix que els mètodes de retrotraducció i adaptació de dominis donen lloc a una millor precisió per a petits conjunts de dades. També vam notar que, tot i que la traducció entre llengües similars no és un passeig, llengües lingüísticament diferents requereixen més dades per donar millors resultats.</abstract_ca>
      <abstract_cs>Tento článek představuje zjištění sdíleného úkolu LoResMT 2020 o nulovém překladu pro jazyky s nízkými zdroji. Tento úkol byl uspořádán v rámci třetího workshopu o technologiích pro MT nízkých zdrojů jazyků (LoResMT) na AACL-IJCNLP 2020. Důraz byl kladen na nulový přístup jako významný vývoj v neuronovém strojovém překladu k vytvoření MT systémů pro jazykové páry, kde jsou paralelní korpusy malé nebo dokonce neexistují. Sdílené zkušenosti s úkoly naznačují, že metody zpětného překladu a adaptace domény vedou k lepší přesnosti pro malé datové sady. Dále jsme poznamenali, že ačkoli překlad mezi podobnými jazyky není žádný problém, jazykově odlišné jazyky vyžadují více dat, aby byly dosaženy lepších výsledků.</abstract_cs>
      <abstract_et>Käesolevas dokumendis esitatakse LoResMT 2020. aasta jagatud ülesande tulemused vähese ressursiga keelte nullkatse kohta. See ülesanne korraldati AACL-IJCNLP 2020 raames kolmanda vähese ressursiga keelte MT tehnoloogiate seminari (LoResMT) raames. Keskendus oli null-shot lähenemisviisile kui märkimisväärsele arengule neuromasintõlkes, et ehitada MT süsteeme keelepaaridele, kus paralleelkorporid on väikesed või isegi puuduvad. Jagatud ülesannete kogemus näitab, et tagatõlke- ja domeenikohandamismeetodid annavad väikeste andmekogumite jaoks parema täpsuse. Lisaks märkisime, et kuigi tõlkimine sarnaste keelte vahel ei ole lihtne, vajavad keeleliselt erinevad keeled paremate tulemuste saavutamiseks rohkem andmeid.</abstract_et>
      <abstract_fi>Tässä artikkelissa esitellään LoResMT 2020 Shared Task -ohjelman tulokset nollakäännöksestä vähävaraisille kielille. Tämä tehtävä järjestettiin osana 3. Workshop on Technologies for MT of Low Resource Languages (LoResMT) AACL-IJCNLP 2020 -tapahtumassa. Painopisteenä oli nolla-shot-lähestymistapa, joka on merkittävä kehitysaskel neurokonekäännöksessä MT-järjestelmien rakentamiseksi kielipareille, joissa rinnakkaiset korpuset ovat pieniä tai jopa olemattomia. Yhteisen tehtäväkokemuksen perusteella voidaan todeta, että takaisinkääntäminen ja verkkotunnuksen mukauttaminen parantavat pienikokoisten aineistojen tarkkuutta. Huomasimme myös, että vaikka kääntäminen samankaltaisten kielten välillä ei ole helppoa, kielellisesti erilliset kielet tarvitsevat enemmän tietoa tuottaakseen parempia tuloksia.</abstract_fi>
      <abstract_sk>V tem članku so predstavljene ugotovitve skupne naloge LoResMT 2020 o ničelnem prevajanju za jezike z nizkimi viri. Ta naloga je bila organizirana v okviru 3. delavnice o tehnologijah za MT nizkih virov jezikov (LoResMT) na AACL-IJCNLP 2020. Poudarek je bil na ničelnem pristopu kot pomembnem razvoju nevralnega strojnega prevajanja za gradnjo MT sistemov za jezikovne pare, kjer so vzporedni korpusi majhni ali celo neobstoječi. Izkušnje s skupnimi opravili kažejo, da metode nazaj prevajanja in prilagajanja domen zagotavljajo boljšo natančnost manjših naborov podatkov. Poleg tega smo ugotovili, da čeprav prevajanje med podobnimi jeziki ni zapleteno, jezikovno različni jeziki potrebujejo več podatkov za boljše rezultate.</abstract_sk>
      <abstract_he>העבודה הזו מציגה את המצאות של משימה משותפת LoResMT 2020 על התרגום אפס-צילומים לשפות משאבים נמוכות. המשימה הזאת אורגנה כחלק מהעבדת השלישית על טכנולוגיות לט.טי. של שפות משאבים נמוכות (LoResMT) ב-AACL-IJCNLP 2020. המרכז היה על גישה אפס-ירי כפיתוח משמעותי בתרגום מכונות נוירואליות כדי לבנות מערכות MT לזוגות שפות שבו גופות מקבילות קטנות או אפילו לא קיימות. חווית המשימה המשותפת מצביעה ששיטות התרגום בחזרה ושיטות ההתאמה לתחום גורמות לדיוקת טובה יותר לקבוצות נתונים קטנות. בנוסף הבחננו כי למרות שהתרגום בין שפות דומות הוא לא הליכה, שפות שונות מבחינה שפתית דורשות יותר נתונים כדי לתת תוצאות טובות יותר.</abstract_he>
      <abstract_ha>@ info Wannan aikin aka organize as part of the 3 workworkgroup on Technical for MT of Low Resource languages (LoResMT) at AAAAACNLP 2020. Fokus na kan zartar da haske-shot kamar wata cire kwamfyuta mai kyau a cikin Tafsiri na Neural Mai Motsi dõmin ya gina tsarin MT wa mazaɓa wa lingui sauran da parallel Corpo masu ƙarami ko kuma don da. Jiyyarin da aka raba aikin da shi yana son sunan faɗaɗawa da shiryoyin shiryarwa na hagu-tarjiwa da ke ƙarami. Ba mu ƙara ba, kuma, lalle, ingawa fassarar a tsakanin lugha kamar wannan bai zama mai tafiya ba, sai lugha masu bayyani cikin harshen, sun ƙayyade wasu data dõmin su bãyar da matsalar mafi alhẽri.</abstract_ha>
      <abstract_jv>Gambar iki bakal ngewehhot nyimpen nang LOResMT 2020 Sampeyan task nang nul-uput terjamahan kanggo langgambar kelas. Perempi iki wis jagatining barêng tanggal 3 Workspace na Teknôlogi kanggo MT Bilih Daerah ResMT (LOResMT) ning AAAAAL-IjCLLP 2020 Ing dipontrol kuwi nganggo dolanan sing nul kanggo nguasai perusahaan liyane mung liyane nan ingkang Neral Masine terjamahan kanggo nggawe sistem MT kanggo alih perusahaan karo perusahaan langkung sampeyan liyane or a bisa mbok. The share task description offline Awak dhéwé éntuk ngerti, tho cara-cara mbutuhak tindang luwih kaya mbok gak tentang, langgar sapa-lukan luwih akeh operasi kanggo ngerasakno dadi sing luwih apik.</abstract_jv>
      <abstract_fil>Ang papiro na ito ay nagbibigay ng mga hanap ng LoResMT 2020 Shared Task tungkol sa nulo-shot translation para sa mababang wika ng mga resource. Ang gawang ito ay inihanda na bahagi ng ikatlong Workshop sa Teknoloji para sa MT ng Low Resource Languages (LoResMT) sa AACL-IJCNLP 2020. Ang focus ay sa paglapit ng zero-shot bilang isang notable development sa Neural Machine Translation upang magtayo ng MT systems para sa mga pares ng wika na ang parallel corpora ay maliit o wala pa rin. Ang karanasang nagbabahagi ng task ay nagpapasusumpungan na ang back-translation at domain adaptation methods ay nagbibigay ng lalong mabuting katunayan sa maliit na size datasets. Nakikilala natin na, bagaman ang paglilikat sa mga wikang gayon din ay walang cakewalk, ang mga wikang wika ay nangangailangan ng lalong mabuti ng data upang magbigay ng mabuti ng mga resulta.</abstract_fil>
      <abstract_bo>ཤོག བྱ་འགུལ་འདི་ནི MT of Low Resource Languages (LoResMT) ཡི་Technologies (Technology) ལ་མཉམ་དུ་གྲངས་སྤྱོད་ཀྱི་ཆ་འཕྲིན་གསུམ་ཀྱི་ཆ་ཤས་ཞིག་ཆགས་སྤྲོད་རྒྱུ་དེ་རེད། འདི་ལྟ་བུའི་གཟུགས་བརྙན་གྱི་ཐབས་ལམ་ལ་བློ་གཏད་འདོད་པ་ལས་རྐྱེན་བཟོ་བརྩོན་བ་ཞིག་ཡིན་པའི་(zero)རྩིས་འཁོར་གཞུང་དང་འཁྲིལ་སྐྱོད་མེད མཉམ་སྤྱོད་པའི་བྱ་འགུལ་གྱི་تجربད་ལ་བསྟར་ན། back-translation་དང་domain་གླེང་སྒྲུབ་ཀྱི་ཐབས་ལམ་དེ་ཉེན་ཁ་ཡོད་ཚད་ཆུང་ཀྱི་གནས་སྟ ང་ཚོས་ཀྱིས་དབར་གཅིག་མཐུན་གྱི་སྐད་ཡིག</abstract_bo>
      </paper>
    <paper id="5">
      <title>Zero-Shot Neural Machine Translation : Russian-Hindi @LoResMT 2020<fixed-case>R</fixed-case>ussian-<fixed-case>H</fixed-case>indi @<fixed-case>L</fixed-case>o<fixed-case>R</fixed-case>es<fixed-case>MT</fixed-case> 2020</title>
      <author><first>Sahinur Rahman</first><last>Laskar</last></author>
      <author><first>Abdullah Faiz Ur Rahman</first><last>Khilji</last></author>
      <author><first>Partha</first><last>Pakray</last></author>
      <author><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>38–42</pages>
      <abstract>Neural machine translation (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one natural language to another natural language. Although, NMT shows remarkable performance in both high and low resource languages, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> needs sufficient training corpus. The availability of a <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a> in low resource language pairs is one of the challenging tasks in MT. To mitigate this issue, NMT attempts to utilize a monolingual corpus to get better at <a href="https://en.wikipedia.org/wiki/Translation">translation</a> for low resource language pairs. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT. Here, the <a href="https://en.wikipedia.org/wiki/Parallel_text">parallel corpus</a> is not used and only monolingual corpora is allowed. We have participated in the same shared task with our team name CNLP-NITS for the Russian-Hindi language pair. We have used masked sequence to sequence pre-training for language generation (MASS) with only monolingual corpus following the unsupervised NMT architecture. The evaluated results are declared at the LoResMT 2020 shared task, which reports that our system achieves the bilingual evaluation understudy (BLEU) score of 0.59, precision score of 3.43, recall score of 5.48, F-measure score of 4.22, and rank-based intuitive bilingual evaluation score (RIBES) of 0.180147 in Russian to Hindi translation. And for Hindi to Russian translation, we have achieved <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>, <a href="https://en.wikipedia.org/wiki/Precision_and_recall">recall</a>, <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a>, and <a href="https://en.wikipedia.org/wiki/International_Bureau_of_Weights_and_Measures">RIBES score</a> of 1.11, 4.72, 4.41, 4.56, and 0.026842 respectively.</abstract>
      <url hash="b77fd717">2020.loresmt-1.5</url>
      <bibkey>laskar-etal-2020-zero</bibkey>
    <title_ar>الترجمة الآلية العصبية بدون طلقة: روسية-هنديةLoResMT 2020</title_ar>
      <title_fr>Traduction automatique neuronale Zero-Shot : russe-hindi @LoResMT 2020</title_fr>
      <title_pt>Tradução automática neural Zero-Shot: russo-hindi @LoResMT 2020</title_pt>
      <title_es>Traducción automática neuronal de tiro cero: ruso-hindi @LoResMT 2020</title_es>
      <title_ja>ゼロショット神経機械翻訳：ロシア語-ヒンディー語@ LoResMT 2020</title_ja>
      <title_zh>零镜头神经机器译:俄语 - 印地语@LoResMT 2020</title_zh>
      <title_ru>Нейронный машинный перевод Zero-Shot: Russian-Hindi @LoResMT 2020</title_ru>
      <title_hi>ज़ीरो-शॉट न्यूरल मशीन अनुवाद: रूसी-हिंदी @LoResMT 2020</title_hi>
      <title_ga>Aistriúchán Meaisín Néarach Zero-Shot: Rúisis-Hiondúis @LoResMT 2020</title_ga>
      <title_ukr>Нейронний машинний переклад Zero-Shot: Russian-Hindi @LoResMT 2020</title_ukr>
      <title_ka>Zero-Shot ნეიროლური მაქინის გადატყვება: პროსია-ჰინდი @LoResMT 2020</title_ka>
      <title_hu>Zero-Shot Neural Gépi Fordítás: orosz-hindi @LoResMT 2020</title_hu>
      <title_el>Νευρική μηχανική μετάφραση μηδενικού πυροβολισμού: Ρωσικά-Χίντι @LoResMT 2020</title_el>
      <title_it>Traduzione automatica neurale a colpo zero: russo-hindi @LoResMT 2020</title_it>
      <title_kk>Null-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_kk>
      <title_lt>Zero-Shot Neural Machine vertimas: rusų-hindų @LoResMT 2020</title_lt>
      <title_mk>Превод на нула-пукана неврална машина: руски-хинди @LoResMT 2020</title_mk>
      <title_ml>പൂജ്യ- ഷൂട്ട് നെയുറല്‍ മെഷീന്‍ പരിഭാഷപ്പെടുത്തുക: റഷ്യന്‍ - ഹിന്ദി @ലോറസ്എംടി 2020</title_ml>
      <title_ms>Terjemahan Mesin Neural Zero-Shot: Rusia-Hindi @LoResMT 2020</title_ms>
      <title_mt>Traduzzjoni tal-Magna Newrali Żero-Shot: Russu-Indjan @LoResMT 2020</title_mt>
      <title_mn>Нэг-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_mn>
      <title_no>Null-skytt neuralmaskinsomsetjing: Russisk-hindisk @LoResMT 2020</title_no>
      <title_pl>Zero-Shot neuronalne tłumaczenie maszynowe: rosyjsko-hindi @LoResMT 2020</title_pl>
      <title_ro>Zero-Shot Neural Machine Traducere: rusă-hindi @LoResMT 2020</title_ro>
      <title_sr>Neuralni prevod: ruski-hindi @LoResMT 2020</title_sr>
      <title_isl>Núllskút taugavél Týking: Rússka-hindíska @LoResMT 2020</title_isl>
      <title_si>Zero-Shot නිර්මාණ මැෂින් වාර්තාව: රුසියාන්-හින්දි @LoResMT 2020Name</title_si>
      <title_so>Turjumista mashiinka Neural ee Zero-Shot: Ruush-Hindi @LoResMT 2020</title_so>
      <title_sv>Zero-Shot Neural Machine Översättning: ryska-hindi @LoResMT 2020</title_sv>
      <title_ta>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_ta>
      <title_ur>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_ur>
      <title_uz>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_uz>
      <title_vi>Máy thần kinh quay không quay: tiếng Nga- Hindi@ LoResMT 2020</title_vi>
      <title_hr>Nulo-pucanje Neuralnog prevoda stroja: ruski-hindi @LoResMT 2020</title_hr>
      <title_da>Zero-Shot Neural maskinoversættelse: russisk-hindi @LoResMT 2020</title_da>
      <title_nl>Zero-Shot Neural Machine Translation: Russisch-Hindi @LoResMT 2020</title_nl>
      <title_bg>Нулева неврална машина превод: Руско-хинди @ЛоРезМТ 2020</title_bg>
      <title_de>Zero-Shot neuronale maschinelle Übersetzung: Russisch-Hindi @LoResMT 2020</title_de>
      <title_id>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_id>
      <title_ko>제로렌즈 신경 기계 번역: 러시아어 인디언@LoResMT 2020</title_ko>
      <title_fa>ترجمه ماشین عصبی zero-Shot: روسی-هندی @LoResMT 2020</title_fa>
      <title_tr>Nusgala maşynyň terjimesi: Rusça-Hindi @LoResMT 2020</title_tr>
      <title_af>Nuwe-Shot Neurale Masjien Vertaling: Russies-Hindi @LoResMT 2020</title_af>
      <title_sw>Tafsiri ya mashine ya kisasa ya risasi: Urusi-Hindi @LoResMT 2020</title_sw>
      <title_am>Zero-Shot Neural Machine ትርጉም: Russian-Hindi @LoResMT 2020</title_am>
      <title_az>Nullu-Shot Nöral Makina Çeviri: Rus-Hindi @LoResMT 2020</title_az>
      <title_hy>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_hy>
      <title_ca>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_ca>
      <title_bs>Neuralni prevod: ruski-hindi @LoResMT 2020</title_bs>
      <title_cs>Nulový neuronový strojový překlad: rusko-hindština @LoResMT 2020</title_cs>
      <title_et>Zero-Shot neuroalne masintõlge: vene-hindi @LoResMT 2020</title_et>
      <title_fi>Zero-Shot Neural Machine Translation: venäjä-hindi @LoResMT 2020</title_fi>
      <title_sq>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_sq>
      <title_bn>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_bn>
      <title_jv>Ngucap-Ngucap Nyuralan Inggal Tulisan: Rusi-Ngucap@LOResMT 2020</title_jv>
      <title_ha>@ LoResMT 2020</title_ha>
      <title_sk>Strojni prevod nevronov ničelnega strela: rusko-hindujščina @LoResMT 2020</title_sk>
      <title_he>מכונת עצבית אפס-ירי תרגום: רוסי-הינדי @LoResMT 2020</title_he>
      <title_fil>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_fil>
      <title_bo>Zero-Shot Neural Machine Translation: Russian-Hindi @LoResMT 2020</title_bo>
      <abstract_ja>ニューラル機械翻訳（ NMT ）は、機械翻訳（ MT ）コミュニティで広く受け入れられているアプローチであり、ある自然言語から別の自然言語に翻訳されます。 NMTは、高リソース言語と低リソース言語の両方で卓越したパフォーマンスを示していますが、十分なトレーニングコーパスが必要です。 低リソース言語ペアでの並列コーパスの利用可能性は、MTにおける困難なタスクの1つです。 この問題を軽減するために、NMTは単一言語コーパスを利用して、低リソース言語ペアの翻訳を改善しようとしています。 低リソース言語のMTのための技術に関するワークショップ（ LoResMT 2020 ）は、ゼロショットNMTを使用した低リソース言語ペア翻訳の共有タスクを組織しました。 ここでは、平行コーパスは使用されず、単一言語コーパスのみが許可されます。 私たちは、ロシア語とヒンディー語のペアについて、チーム名CNLP - NITSと同じ共有タスクに参加しました。 私たちは、監督されていないNMTアーキテクチャに従った単一言語コーパスのみを使用して、言語生成（マス）のためのシーケンス事前トレーニングにマスクされたシーケンスを使用しました。 評価された結果は、LoResMT 2020共有タスクで宣言され、当社のシステムは、ロシア語からヒンディー語への翻訳で、0.59のバイリンガル評価アンダースタディ（ BLEU ）スコア、3.43の精度スコア、5.48のリコールスコア、4.22のFメジャースコア、および0.180147のランクベースの直感的バイリンガル評価スコア（ RIBES ）を達成することを報告しています。 そして、ヒンディー語からロシア語への翻訳では、BLEU、精度、リコール、Fメジャー、RIBESスコア1.11を達成しました。
それぞれ、4.72、4.41、4.56、及び0.026842を参照されたい。</abstract_ja>
      <abstract_pt>A tradução automática neural (NMT) é uma abordagem amplamente aceita na comunidade de tradução automática (MT), traduzindo de uma linguagem natural para outra linguagem natural. Embora o NMT mostre um desempenho notável em linguagens de alto e baixo recurso, ele precisa de um corpus de treinamento suficiente. A disponibilidade de um corpus paralelo em pares de idiomas com poucos recursos é uma das tarefas desafiadoras em TA. Para mitigar esse problema, o NMT tenta utilizar um corpus monolíngue para melhorar a tradução de pares de idiomas com poucos recursos. O Workshop sobre Tecnologias para MT de Idiomas de Baixos Recursos (LoResMT 2020) organizou tarefas compartilhadas de tradução de pares de idiomas de baixo recurso usando NMT zero-shot. Aqui, o corpus paralelo não é usado e apenas corpora monolíngue é permitido. Participamos da mesma tarefa compartilhada com nosso nome de equipe CNLP-NITS para o par de idiomas russo-hindi. Usamos sequência mascarada para sequenciar o pré-treinamento para geração de linguagem (MASS) com apenas corpus monolíngue seguindo a arquitetura NMT não supervisionada. Os resultados avaliados são declarados na tarefa compartilhada LoResMT 2020, que relata que nosso sistema atinge a pontuação de avaliação bilíngue (BLEU) de 0,59, pontuação de precisão de 3,43, pontuação de recall de 5,48, pontuação de F-measure de 4,22 e pontuação baseada em classificação pontuação de avaliação bilíngue intuitiva (RIBES) de 0,180147 na tradução do russo para o hindi. E para a tradução do hindi para o russo, alcançamos BLEU, precisão, recall, F-measure e pontuação RIBES de 1,11,
4,72, 4,41, 4,56 e 0,026842, respectivamente.</abstract_pt>
      <abstract_fr>La traduction automatique neuronale (NMT) est une approche largement acceptée dans la communauté de la traduction automatique (MT), qui consiste à traduire d'une langue naturelle vers une autre langue naturelle. Bien que la NMT affiche des performances remarquables dans les langues à ressources élevées et faibles, elle nécessite un corpus de formation suffisant. La disponibilité d'un corpus parallèle dans des paires de langues à faibles ressources est l'une des tâches difficiles de la traduction automatique. Pour pallier ce problème, NMT tente d'utiliser un corpus monolingue afin d'améliorer la traduction pour les paires de langues à faibles ressources. Workshop on Technologies for MT of Low Resource Languages (LoresMT 2020) a organisé des tâches partagées de traduction de paires de langues à faibles ressources à l'aide de la NMT zero-shot. Ici, le corpus parallèle n'est pas utilisé et seuls les corpus monolingues sont autorisés. Nous avons participé à la même tâche partagée avec le nom de notre équipe CNLP-NITS pour le couple russe-hindi. Nous avons utilisé une pré-formation séquence à séquence masquée pour la génération de langage (MASS) avec uniquement un corpus monolingue suivant l'architecture NMT non supervisée. Les résultats évalués sont déclarés lors de la tâche partagée LoreSMT 2020, qui indique que notre système atteint le score de doublure d'évaluation bilingue (BLEU) de 0,59, le score de précision de 3,43, le score de rappel de 5,48, le score de mesure F de 4,22 et le score d'évaluation bilingue intuitif basé sur les classements (RIBES) de 0,180147 Traduction du russe vers l'hindi. Et pour la traduction de l'hindi vers le russe, nous avons obtenu le score BLEU, précision, rappel, mesure F et RIBES de 1,11
4,72, 4,41, 4,56 et 0,026842 respectivement.</abstract_fr>
      <abstract_ar>الترجمة الآلية العصبية (NMT) هي طريقة مقبولة على نطاق واسع في مجتمع الترجمة الآلية (MT) ، حيث تترجم من لغة طبيعية إلى لغة طبيعية أخرى. على الرغم من أن NMT تُظهر أداءً رائعًا في كل من اللغات ذات الموارد العالية والمنخفضة ، إلا أنها تحتاج إلى مجموعة تدريب كافية. يعد توافر مجموعة نصية متوازية في أزواج اللغات منخفضة الموارد إحدى المهام الصعبة في الترجمة الآلية. للتخفيف من هذه المشكلة ، تحاول NMT الاستفادة من مجموعة لغة واحدة لتحسين الترجمة لأزواج اللغات منخفضة الموارد. نظمت ورشة عمل حول تقنيات الترجمة الآلية للغات منخفضة الموارد (LoResMT 2020) المهام المشتركة لترجمة أزواج اللغات منخفضة الموارد باستخدام NMT بدون طلقة. هنا ، لا يتم استخدام المجموعة الموازية ويسمح فقط بالجماعات أحادية اللغة. لقد شاركنا في نفس المهمة المشتركة مع اسم فريقنا CNLP-NITS للزوج اللغوي الروسي-الهندي. لقد استخدمنا التسلسل المقنع لتسلسل التدريب المسبق لتوليد اللغة (MASS) مع بنية أحادية اللغة فقط تتبع بنية NMT غير الخاضعة للإشراف. يتم الإعلان عن النتائج التي تم تقييمها في المهمة المشتركة LoResMT 2020 ، والتي تفيد بأن نظامنا يحقق درجة التقييم ثنائي اللغة (BLEU) من 0.59 ، ودرجة الدقة 3.43 ، ودرجة الاسترجاع 5.48 ، ودرجة قياس F من 4.22 ، والمستندة إلى الرتبة درجة تقييم ثنائية اللغة بديهية (RIBES) تبلغ 0.180147 في الترجمة الروسية إلى الهندية. وبالنسبة للترجمة الهندية إلى الروسية ، فقد حققنا درجة BLEU والدقة والاستدعاء وقياس F و RIBES البالغة 1.11 ،
4.72 و 4.41 و 4.56 و 0.026842 على التوالي.</abstract_ar>
      <abstract_es>La traducción automática neuronal (NMT) es un enfoque ampliamente aceptado en la comunidad de traducción automática (MT), que traduce de un idioma natural a otro idioma natural. Aunque la NMT muestra un rendimiento notable en lenguajes de recursos altos y bajos, necesita un corpus de capacitación suficiente. La disponibilidad de un corpus paralelo en pares de idiomas con pocos recursos es una de las tareas desafiantes de MT. Para mitigar este problema, NMT intenta utilizar un corpus monolingüe para mejorar la traducción de pares de idiomas con pocos recursos. Workshop on Technologies for MT of Low Resource Languages (LoreSMT 2020) organizó tareas compartidas de traducción de pares de idiomas de bajos recursos utilizando NMT de tiro cero. En este caso, no se utiliza el corpus paralelo y solo se permiten los corpus monolingües. Hemos participado en la misma tarea compartida con el nombre de nuestro equipo CNLP-NITS para el par de idiomas ruso-hindi. Hemos utilizado la secuencia enmascarada para secuenciar el preentrenamiento para la generación de lenguaje (MASS) con solo corpus monolingües siguiendo la arquitectura NMT no supervisada. Los resultados evaluados se declaran en la tarea compartida LoreSMT 2020, que informa que nuestro sistema logra una puntuación de suplente de evaluación bilingüe (BLEU) de 0.59, una puntuación de precisión de 3.43, una puntuación de recuperación de 5.48, una puntuación de medida F de 4.22 y una puntuación de evaluación bilingüe intuitiva basada en rangos (RIBES) de 0.180147 en Traducción del ruso al hindi. Y para la traducción del hindi al ruso, hemos logrado una puntuación BLEU, precisión, memoria, medida F y RIBES de 1,11.
4.72, 4.41, 4.56 y 0.026842 respectivamente.</abstract_es>
      <abstract_ukr>Нейронний машинний переклад (НМП) - це широко прийнятий підхід у спільноті машинного перекладу (МП), переклад з однієї природної мови на іншу природну мову. Хоча, НМТ демонструє вражаючу продуктивність як у мовах з високим, так і низьким рівнем ресурсів, він потребує достатнього навчального корпусу. Наявність паралельного корпусу в мовних парах з низьким рівнем ресурсів є однією з найскладніших задач в МП. Щоб пом 'якшити цю проблему, НМТ намагається використовувати одномовний корпус, щоб краще перекладати для мовних пар з низьким рівнем ресурсів. Семінар з технологій МП мов з низьким рівнем ресурсів (LoResMT 2020) організував спільні завдання перекладу мовної пари з низьким рівнем ресурсів з використанням нульового знімка НБ. Тут паралельне тіло не використовується і допускаються тільки одномовні тіла. Ми брали участь у тому ж спільному завданні з нашою командою CNLP-NITS для російсько-хіндійської мовної пари. Ми використовували масковану послідовність для попереднього навчання для генерації мови (МАСИ) з тільки одномовним корпусом, що дотримується неконтрольованої архітектури НБ. Оцінені результати оголошуються на спільному завданні LoResMT 2020, яке повідомляє, що наша система досягає балу двомовного оцінювання дублера (Bleu) 0,59, балу точності 3,43, балу відкликання 5,48, балу F-вимірювання 4,22 та рангового інтуїтивного двомовного оцінювання (RIBES) 0,180147 в перекладі з російської на хінді. І для перекладу з гінді на російську мову ми досягли Bleu, точності, відкликання, F-вимірювання та RIBES оцінки 1,11,
4,72, 4,41, 4,56 та 0,026842 відповідно.</abstract_ukr>
      <abstract_ru>Нейронный машинный перевод (NMT) - это широко принятый подход в сообществе машинного перевода (MT), перевод с одного естественного языка на другой естественный язык. Хотя НБМ демонстрирует замечательные результаты как на языках с высоким, так и низким объемом ресурсов, он нуждается в достаточной подготовке кадров. Наличие параллельного корпуса в языковых парах с низким ресурсом является одной из сложных задач в МП. Чтобы смягчить эту проблему, НБП пытается использовать одноязычный корпус, чтобы улучшить перевод для языковых пар с низким ресурсом. Семинар по технологиям для МТ языков с низким уровнем ресурсов (LoResMT 2020) организовал совместные задачи перевода языковых пар с низким уровнем ресурсов с использованием нулевого снимка НБ. Здесь параллельное тело не используется и разрешены только одноязычные тела. Мы участвовали в одной и той же совместной задаче с нашей командой CNLP-NITS для русско-хиндийской языковой пары. Мы использовали маскированную последовательность для последовательного предварительного обучения для генерации языка (МАССЫ) только с одноязычным корпусом, следуя неконтролируемой архитектуре НБ. Оцениваемые результаты объявлены в общей задаче LoResMT 2020, которая сообщает, что наша система достигает баллов дублера двуязычной оценки (BLEU) 0,59, балла прецизионности 3,43, балла отзыва 5,48, балла F-измерения 4,22 и балла ранговой интуитивной двуязычной оценки (RIBES) 0,180147 в переводе с русского на хинди. И для перевода с хинди на русский, мы достигли BLEU, точность, вспомнить, F-измерение, и RIBES балл 1,11,
4,72, 4,41, 4,56 и 0,026842 соответственно.</abstract_ru>
      <abstract_zh>神经机器翻译(NMT)者,机器翻译(MT)社区之广受,别自然语言翻译成一自然语言也。 虽 NMT 高资言语低资源语皆著能,然足以练语料库。 低资源言并行语料库机器翻译有挑战性之一也。 缓之,NMT试用单语语料库来益译低资源语对。 低资源言语机器翻译术研讨会(LoResMT 2020)为零镜头NMT低资源言语共之。 此处不用并行语料库,止许用单语语料库。 与吾团队名CNLP-NITS同功,施于俄语 - 印地语对。 臣等以屏蔽序(MASS)语言成预训练,惟单语语料库循无监督之NMT架构。 评估果于LoResMT 2020共享事中宣布,该告我们的系统在俄语到印地语译中成了0.59的双语估(BLEU)分数,3.43的精度分数,召还率得分5.48,F测量得分为4.22,基于等第的直观双语评估分数(RIBES)为0.180147。 其于印地语俄语译,我得BLEU,精度召率,F量RIBES为1.11。
曰 4.72、4.41、4.56 、 0.026842。</abstract_zh>
      <abstract_hi>तंत्रिका मशीन अनुवाद (NMT) मशीन अनुवाद (एमटी) समुदाय में एक व्यापक रूप से स्वीकृत दृष्टिकोण है, जो एक प्राकृतिक भाषा से दूसरी प्राकृतिक भाषा में अनुवाद करता है। हालांकि, एनएमटी उच्च और निम्न संसाधन दोनों भाषाओं में उल्लेखनीय प्रदर्शन दिखाता है, इसे पर्याप्त प्रशिक्षण कॉर्पस की आवश्यकता होती है। कम संसाधन भाषा जोड़े में एक समानांतर कॉर्पस की उपलब्धता एमटी में चुनौतीपूर्ण कार्यों में से एक है। इस मुद्दे को कम करने के लिए, NMT कम संसाधन भाषा जोड़े के लिए अनुवाद में बेहतर होने के लिए एक मोनोलिंगुअल कॉर्पस का उपयोग करने का प्रयास करता है। कम संसाधन भाषाओं के एमटी के लिए प्रौद्योगिकियों पर कार्यशाला (LoResMT 2020) ने शून्य-शॉट एनएमटी का उपयोग करके कम संसाधन भाषा जोड़ी अनुवाद के साझा कार्यों का आयोजन किया। यहां, समानांतर कॉर्पस का उपयोग नहीं किया जाता है और केवल मोनोलिंगुअल कॉर्पोरेट की अनुमति है। हमने रूसी-हिंदी भाषा जोड़ी के लिए अपनी टीम के नाम CNLP-NITS के साथ एक ही साझा कार्य में भाग लिया है। हमने अप्रकाशित एनएमटी आर्किटेक्चर के बाद केवल मोनोलिंगुअल कॉर्पस के साथ भाषा पीढ़ी (मास) के लिए पूर्व-प्रशिक्षण को अनुक्रमित करने के लिए नकाबपोश अनुक्रम का उपयोग किया है। मूल्यांकन किए गए परिणाम LoResMT 2020 साझा कार्य में घोषित किए जाते हैं, जो रिपोर्ट करता है कि हमारी प्रणाली 0.59 के द्विभाषी मूल्यांकन अंडरस्टडी (BLEU) स्कोर, 3.43 के सटीक स्कोर, 5.48 के रिकॉल स्कोर, 4.22 के एफ-माप स्कोर, और रैंक-आधारित सहज ज्ञान युक्त द्विभाषी मूल्यांकन स्कोर (RIBES) को प्राप्त करती है रूसी से हिंदी अनुवाद में 0.180147। और हिंदी से रूसी अनुवाद के लिए, हमने BLEU, परिशुद्धता, याद, F-माप, और 1.11 के RIBES स्कोर को प्राप्त किया है,
क्रमशः 4.72, 4.41, 4.56, और 0.026842।</abstract_hi>
      <abstract_ga>Is cur chuige é an t-aistriúchán meaisín néaraíoch (NMT) a nglactar leis go forleathan i bpobal an mheaisínaistriúcháin (MT), a aistríonn ó theanga nádúrtha amháin go teanga nádúrtha eile. Cé go léiríonn NMT feidhmíocht iontach i dteangacha ardacmhainne agus íseal-acmhainní, tá corpas oiliúna leordhóthanach ag teastáil uaidh. Ceann de na tascanna dúshlánacha a bhaineann le MT ná corpas comhthreomhar a bheith ar fáil i mbeirteanna teanga ar acmhainní ísle. Chun an tsaincheist seo a mhaolú, déanann NMT iarracht corpas aonteangach a úsáid le dul i bhfeabhas ar an aistriúchán do phéirí teanga ar bheagán acmhainní. D’eagraigh Ceardlann ar Theicneolaíochtaí le haghaidh MT na dTeangacha Ísealacmhainne (LoResMT 2020) tascanna comhroinnte d’aistriúchán péire teangacha íseal-acmhainne ag baint úsáide as NMT gan lámhaigh. Anseo, ní úsáidtear an corpas comhthreomhar agus ní cheadaítear ach corpas aonteangach. Táimid tar éis páirt a ghlacadh sa tasc comhroinnte céanna lenár n-ainm foirne CNLP-NITS don phéire teanga Rúisis-Hiondúis. Tá seicheamh folaithe úsáidte againn chun réamhoiliúint do ghiniúint teanga (MASS) a chur in ord agus gan ach corpas aonteangach i ndiaidh ailtireacht NMT gan mhaoirseacht. Déantar na torthaí meastóireachta a dhearbhú ag tasc comhroinnte LoResMT 2020, a thuairiscíonn go mbaineann ár gcóras amach an scóráil understudy meastóireachta dátheangach (BLEU) de 0.59, scór beachtas 3.43, scór aisghairme 5.48, scór beart F de 4.22, agus scór bunaithe ar chéim. scór meastóireachta iomasach dátheangach (RIBES) de 0.180147 in aistriúchán Rúisise go Hiondúis. Agus maidir le haistriúchán Hiondúis go Rúisis, tá scór BLEU, beachtas, aisghairm, beart-F agus RIBES de 1.11 bainte amach againn,
4.72, 4.41, 4.56, agus 0.026842 faoi seach.</abstract_ga>
      <abstract_ka>ნეიროლური მანქანის გაგრძელება (NMT) არის მანქანის გაგრძელება (MT) საზოგადოებაში, რომელიც ერთი ნაირადი ენერგიდან სხვა ნაირადი ენერგიდან გაგრძელება. მაგრამ, NMT იჩვენებს მარტივი სამუშაო სამუშაო სამუშაო და მარტივი რესურსების ენაში, მას უნდა მსგავსი სამუშაო სამუშაო პარალელი კორპუსის ხელსაწყობა მარტივი რესურსის ზოგში არის MT-ში ყველა შესაძლებელი მოქმედების ერთი. ამ პრობლემას შემცირებად, NMT მოცდილობა მონოლენგური კორპუსს გამოყენება, რომ გადაწყენებული რესურსის ზოგები სამუშაო რესურსის ენების MT-ის ტექნოლოგიების სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო სამუშაო აქ, პარალელური კორპუსი არ გამოყენება და მხოლოდ მონოლენგური კორპორა დაუყენება. ჩვენ იგივე საერთო დაყოფილი საქაღალდეში ჩვენი სახელის სახელით CNLP-NITS-ს პროსია-ჰინდის სახელისთვის. ჩვენ მხოლოდ მონოლენგური კორპუსი გამოიყენეთ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ მხოლოდ NMT არქტიქტურის შემდეგ. რომელსაც ჩვენი სისტემა 0,59 წარმოდგენა, 3,43 წარმოდგენის წარმოდგენა, 5,48 წარმოდგენა, 4,22 წარმოდგენა F-მარტივი წარმოდგენა და 0,180147 წარმოდგენა კონტუტიგური წარმოდგენის წარმოდგენა. და ჰინდური პროსური გაგრძნობისთვის, ჩვენ მივიღეთ BLEU, წესიერება, დახმარება, F-მარტილება და RIBES-ის 1.11 წესიერება,
4. 72, 4. 41, 4. 56 და 0. 026842.</abstract_ka>
      <abstract_hu>A neurális gépi fordítás (NMT) széles körben elfogadott megközelítés a gépi fordítás (MT) közösségében, amely egyik természetes nyelvről a másik természetes nyelvre fordít. Bár az NMT figyelemreméltó teljesítményt mutat mind a magas, mind az alacsony erőforrású nyelveken, elegendő képzési corpusra van szüksége. A párhuzamos korpusz elérhetősége alacsony erőforrású nyelvpárokban az MT egyik kihívást jelent. A probléma enyhítése érdekében az NMT megpróbál egynyelvű korpuszt használni, hogy jobban fordítsa az alacsony erőforrású nyelvpárokat. A Low Resource Languages MT technológiái című workshop (LoResMT 2020) megosztott feladatokat szervezett az alacsony erőforrású nyelvpáros fordítással kapcsolatban, nulla-shot NMT segítségével. Itt a párhuzamos korpusz nem használható, és csak egynyelvű korpusz engedélyezett. Ugyanebben a közös feladatban vettünk részt a CNLP-NITS nevű csapatunkkal az orosz-hindi nyelvpárra. Maszkos szekvenciát használtunk a nyelvgeneráció (MASS) előkészítésének szekvenciájára, csak egynyelvű korpusz segítségével, felügyelet nélküli NMT architektúrát követve. Az értékelt eredményeket a LoResMT 2020 közös feladat jelenti, amely szerint rendszerünk a kétnyelvű értékelő helyettesítő (BLEU) pontszámot 0,59, precíziós pontszámot 3,43, visszahívási pontszámot 5,48, F-mérési pontszámot 4,22, rangalapú intuitív kétnyelvű értékelő pontszámot (RIBES) ér el orosz-hindi fordításban. És a hindi-orosz fordítás esetében elértük a BLEU, precizitás, visszahívás, F-mérés és RIBES pontszámot 1,11,
4, 72, 4, 41, 4, 56, illetve 0, 026842.</abstract_hu>
      <abstract_it>La traduzione automatica neurale (NMT) è un approccio ampiamente accettato nella comunità della traduzione automatica (MT), traducendo da una lingua naturale a un'altra lingua naturale. Anche se l'NMT mostra notevoli prestazioni sia nei linguaggi ad alta che a bassa risorsa, ha bisogno di un corpus di formazione sufficiente. La disponibilità di un corpus parallelo in coppie di lingue a basso contenuto di risorse è uno dei compiti impegnativi in MT. Per mitigare questo problema, NMT tenta di utilizzare un corpus monolingue per migliorare la traduzione per coppie di lingue a basso contenuto di risorse. Workshop sulle tecnologie per la MT delle lingue a bassa risorsa (LoResMT 2020) ha organizzato attività condivise di traduzione di coppie di lingue a bassa risorsa utilizzando NMT zero-shot. Qui, il corpus parallelo non è utilizzato e solo corpora monolingue è consentito. Abbiamo partecipato allo stesso compito condiviso con il nome del nostro team CNLP-NITS per la coppia di lingue russo-hindi. Abbiamo usato la sequenza mascherata per sequenziare il pre-training per la generazione del linguaggio (MASS) con solo corpus monolingue seguendo l'architettura NMT non supervisionata. I risultati valutati sono dichiarati nel compito condiviso LoResMT 2020, che riporta che il nostro sistema raggiunge il punteggio bilingue di valutazione sostitutiva (BLEU) di 0,59, il punteggio di precisione di 3,43, il punteggio di richiamo di 5,48, il punteggio F-measure di 4,22 e il punteggio di valutazione bilingue intuitivo (RIBES) di 0,180147 in traduzione russo-hindi. E per la traduzione dall'hindi al russo, abbiamo ottenuto BLEU, precisione, richiamo, F-measure e RIBES punteggio di 1,11,
4,72, 4,41, 4,56 e 0,026842 rispettivamente.</abstract_it>
      <abstract_el>Η νευρωνική μηχανική μετάφραση (ΜΤ) είναι μια ευρέως αποδεκτή προσέγγιση στην κοινότητα της μηχανικής μετάφρασης (ΜΤ), η οποία μεταφράζει από μια φυσική γλώσσα σε μια άλλη φυσική γλώσσα. Αν και η NMT παρουσιάζει αξιοσημείωτη απόδοση τόσο σε γλώσσες υψηλών όσο και σε γλώσσες χαμηλών πόρων, χρειάζεται επαρκές εκπαιδευτικό σώμα. Η διαθεσιμότητα ενός παράλληλου σώματος σε ζεύγη γλωσσών χαμηλού πόρου είναι ένα από τα δύσκολα καθήκοντα στο Για να μετριάσει αυτό το ζήτημα, το προσπαθεί να χρησιμοποιήσει ένα μονογλωσσικό σώμα για να βελτιωθεί στη μετάφραση για ζεύγη γλωσσών χαμηλού πόρου. Το εργαστήριο Τεχνολογίες για τη ΜΤ γλωσσών χαμηλών πόρων οργάνωσε κοινές εργασίες μετάφρασης γλωσσικών ζευγαριών χαμηλών πόρων με τη χρήση μηδενικού πυροβολισμού NMT. Εδώ δεν χρησιμοποιείται το παράλληλο σώμα και επιτρέπονται μόνο μονογλωσσικά σώματα. Έχουμε συμμετάσχει στην ίδια κοινή εργασία με το όνομα της ομάδας μας για το ζευγάρι ρωσικών-ινδικών γλωσσών. Χρησιμοποιήσαμε μασκοποιημένη ακολουθία για την προετοιμασία ακολουθίας για την παραγωγή γλωσσών (MASS) με μονογλωσσικό σώμα που ακολουθεί την αρχιτεκτονική χωρίς επίβλεψη. Τα αποτελέσματα που αξιολογήθηκαν δηλώνονται στην κοινή εργασία η οποία αναφέρει ότι το σύστημά μας επιτυγχάνει τη δίγλωσση βαθμολογία αντικαταστάτη αξιολόγησης (BLEU) 0.59, βαθμολογία ακρίβειας 3.43, βαθμολογία ανάκλησης 5.48, βαθμολογία μέτρησης 4.22 και διαισθητική δίγλωσση βαθμολογία αξιολόγησης (RIBES) 0.180147 στη ρωσική προς ινδική μετάφραση. Και για τη μετάφραση Χίντι στα ρωσικά, έχουμε επιτύχει BLEU, ακρίβεια, ανάκληση, μέτρηση F, και βαθμολογία RIBES 1.11,
4.72, 4.41, 4.56 και 0.026842 αντίστοιχα.</abstract_el>
      <abstract_kk>Нейрондық машинаның аударуы (NMT) машинаның аударуы (MT) коммуникасында көп қабылданған тәсілі, бір табиғи тілден басқа табиғи тіліне аударылады. Бірақ NMT көп, төмен ресурс тілдерінде белгілі жұмыс істеуді көрсетеді, ол корпус жеткілікті оқыту керек. Төменгі ресурс тілдерінде параллель корпус қолдануға мүмкіндік беру - MT- дің көпшілікті тапсырмалардың бірі. Бұл мәселеді көшірмелеу үшін NMT бір тілді корпус қолдануға тырыс ресурс тілдерінде аудару үшін бі MT төменгі ресурс тілдерінің технологияларының (LoResMT 2020) жұмыс істеу үшін ресурс тілдерінің төменгі тілдерінің ортақтастырылған тапсырмаларын NMT көмегімен ортақтастырды. Мұнда параллел корпус қолданылмайды және тек монолингі корпора рұқсат етіледі. Біз бір бөлек тапсырмаға CNLP-NITS атауымыздың бір бөлек тапсырмаға қатынасыз. Біз тілдерді құру үшін алдын- оқыту үшін қалқан кезектерді қолдандық (MASS) тек бір тілді корпус архитектурасынан кейін тек бір тілді корпус болып тұрады. Байланып тұрған нәтижелер LoResMT 2020 ортақ тапсырмасында жазылады. Бұл жүйеміздің екі тілді оқиға (BLEU) 0,59 деген, 3,43 деген дұрыс, 5,48 деген, 4,22 деген F-өлшемі, және 0,180147 деген руссиялық тілінде 0,180147 дұрыс оқиға (RIBES) дегенді жазылады. Осылайша, хинди руссияның аудармасына, біз BLEU, дәл-дәл, еске салу, F-өлшемі және RIBES 1.11 деп жеткіздік.
4. 72, 4. 41, 4. 56 және 0. 026842.</abstract_kk>
      <abstract_isl>Þýðing í taugavélum (Neural Machine Translation, NMT) er breitt samþykkt a ðferð í þýðingu véla (Machine Translation, MT) samfélagið, þýðing frá einu náttúrulegu tungumáli til annars náttúrulegs tungumális. Þrátt fyrir að NMT sýni sérstaka árangur á bæði háum og lágum upprunalegum tungumáli þarf það nægilegt þjálfunarhóp. The availability of a parallel corpus in low resource language pairs is one of the challenging tasks in MT. To mitigate this issue, NMT attempts to utilize a monolingual corpus to get better at translation for low resource language pairs.  Verkefni um tækni fyrir MT af langvarandi tungumálum (LoResMT 2020) skipulagði sameiginlegar verkefni með langvarandi tungumálumþýðingu með núllskotum NMT. Hér er samhliða líkamanum ekki notað og aðeins eintungumál líkamanum er leyft. Við höfum tekið þátt í sömu sameiginlegri verkefni með hópnum CNLP-NITS fyrir rússnesku-hindísku tungumál par. Við höfum notað falda röð til að ræða for þjálfun fyrir tungumyndun (MASS) með aðeins eintungu líkama eftir óeftirlit NMT arhitektúru. Mataðar niðurstöður eru tilkynntar við LoResMT 2020 sameiginlegt verkefni, sem tilkynnir að kerfið okkar nái tveggja tungumálið (BLEU) skori 0,59, nákvæmu skori 3,43, minnisskori 5,48, F-mælisskori 4,22 og innvitunda tveggja tungumálið (RIBES) skori 0,180147 í rússnesku til hindísku þýðingu. Og hvað varðar hindíska til rússneskrar þýðingar, höfum við náð BLEU, nákvæmni, minningu, F-mæli, og RIBES skor 1,11,
4,72, 4,41, 4,56 og 0,026842 í sömu röð.</abstract_isl>
      <abstract_mk>Неуралниот машински превод (НМТ) е широко прифатен пристап во заедницата за машински превод (МТ), превод од еден природен јазик на друг природен јазик. Иако НМТ покажува извонредни резултати на јазиците со високи и ниски ресурси, му треба доволно обука. Достапноста на паралелен корпус во парови со ниски ресурси е една од предизвикувачките задачи во МТ. За да го олесни ова прашање, НМТ се обидува да користи монојазичен корпус за да се подобри преводот за парови со ниски ресурси. Сервисникот за технологии за МТ на јазиците со ниски ресурси (LoResMT 2020) организираше заеднички задачи за превод на пар јазици со ниски ресурси користејќи нула-снимка НМТ. Тука паралелниот корпус не е употребен и дозволено е само монојазичен корпус. Ние учествувавме во истата заедничка задача со името на нашиот тим CNLP-NITS за парот руско-хиндиски јазик. Користевме маскирана секвенца за секвенција на предобука за генерација на јазици (MASS) со само монојазичен корпус по ненадгледуваната архитектура на НМТ. Оценетите резултати се прогласени на заедничката задача LoResMT 2020, која известува дека нашиот систем постигнува оценка на двојјазичната оценка (БЛЕУ) од 0,59, точност од 3,43, потсетна оценка од 5,48, оценка на F-мерка од 4,22 и оценка на интуитивна двојјазична оценка (РИБЕС) од 0,180147 на превод од руски до хинди. И за Хинди на руски превод, постигнавме БЛЕ, прецизност, потсетување, F-мерка и РИБЕС резултат од 1,11,
4, 72, 4, 41, 4, 56 и 0, 026842.</abstract_mk>
      <abstract_lt>Neural in is mašin ų vertimas (NMT) yra plačiai pripažintas metodas mašinų vertimo (MT) bendruomenėje, vertimas iš vienos natūralios kalbos į kitą natūralią kalbą. Nors NMT įrodo nepaprastus rezultatus tiek didelėmis, tiek mažomis išteklių kalbomis, jai reikia pakankamo mokymo korpuso. Galimybė naudotis lygiagrečiu korpusu mažai išteklių turinčiomis kalbų poromis yra viena iš sunkių MT užduočių. Siekiant sušvelninti šį klausimą, NMT bando naudoti vienkalbinį korpusu, kad būtų geriau vertimas mažai išteklių turinčiomis kalbų poromis. Mažų išteklių kalbų MT technologijų seminare (LoResMT 2020) buvo organizuojamos bendros užduotys, susijusios su mažų išteklių kalbų poros vertimu naudojant nulinį NMT. Čia paralelinis korpusas nenaudojamas ir leidžiama naudoti tik vienakalbį korpusą. Mes dalyvavome toje pačioje bendroje užduotyje su mūsų komandos pavadinimu CNLP-NITS rusų ir hindų kalbų porai. We have used masked sequence to sequence pre-training for language generation (MASS) with only monolingual corpus following the unsupervised NMT architecture.  Įvertinti rezultatai deklaruojami LoResMT 2020 bendroje užduotyje, kurioje nurodoma, kad mūsų sistema pasiekia dvikalbį vertinimo nepakankamumą (BLEU) 0,59, tikslų 3,43, prisiminimo 5,48, F-matavimo 4,22 ir rankiniu intuityviu dvikalbiu vertinimo (RIBES) 0,180147 vertėmis rusų ir Hindi. Ir kalbant Hindi į rusų vertimą, pasiekėme BLEU, tikslumą, atšaukimą, F-matavimą ir RIBES 1,11 balai,
4.72, 4.41, 4.56, and 0.026842 respectively.</abstract_lt>
      <abstract_ms>Terjemahan mesin saraf (NMT) adalah pendekatan yang diterima secara luas dalam komuniti terjemahan mesin (MT), terjemahan dari satu bahasa alami ke bahasa alami lain. Although, NMT shows remarkable performance in both high and low resource languages, it needs sufficient training corpus.  The availability of a parallel corpus in low resource language pairs is one of the challenging tasks in MT. To mitigate this issue, NMT attempts to utilize a monolingual corpus to get better at translation for low resource language pairs.  Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT. Di sini, corpus selari tidak digunakan dan hanya corpora monobahasa dibenarkan. Kami telah berpartisipasi dalam tugas yang sama dengan nama pasukan kami CNLP-NITS untuk pasangan bahasa Rusia-Hindi. Kami telah menggunakan jujukan bertopeng untuk jujukan praselatihan untuk generasi bahasa (MASS) hanya dengan korpus monobahasa mengikut arkitektur NMT yang tidak diawasi. Hasil yang dipastikan diterangkan pada tugas kongsi LoResMT 2020, yang melaporkan bahawa sistem kita mencapai skor pemastian bilingual (BLEU) 0.59, skor ketepatan 3.43, skor ingatan 5.48, skor F-ukuran 4.22, dan skor penilaian bilingual intuitif berdasarkan rangka (RIBES) 0.180147 dalam terjemahan Rusia ke Hindi. Dan untuk terjemahan Hindi ke Rusia, kita telah mencapai BLEU, ketepatan, ingatan, F-ukuran, dan RIBES skor 1.11,
4.72, 4.41, 4.56, dan 0.026842 respectively.</abstract_ms>
      <abstract_mt>It-traduzzjoni tal-magni newrali (NMT) hija approċċ a ċċettat b’mod wiesa’ fil-komunità tat-traduzzjoni tal-magni (MT), li tittraduċi minn lingwa naturali għal lingwa naturali oħra. Għalkemm, l-NMT turi prestazzjoni notevoli kemm f’lingwi b’riżorsi għoljin kif ukoll baxxi, jeħtieġ korpus ta’ taħriġ suffiċjenti. Id-disponibbiltà ta’ korpus parallel f’pari ta’ lingwi b’riżorsi baxxi hija waħda mill-kompiti ta’ sfida fl-MT. Biex tittaffa din il-kwistjoni, l-NMT tipprova tuża korpus monolingwi biex tikseb a ħjar fit-traduzzjoni għal pari ta’ lingwi b’riżorsi baxxi. Workshop dwar it-Teknoloġiji għall-MT ta’ Lingwi b’Riżorsi Baxxi (LoResMT 2020) organizza kompiti kondiviżi ta’ traduzzjoni b’pari ta’ lingwi b’riżorsi baxxi bl-użu ta’ NMT zero-shot. Hawnhekk, il-korpus parallel ma jintużax u huwa permess biss il-korpus monolingwi. Parteċipajna fl-istess kompitu kondiviż bl-isem tat-tim tagħna CNLP-NITS għall-par tal-lingwa Russa-Indjana. Użajna sekwenza maskrata biex issegwi taħriġ minn qabel għall-ġenerazzjoni tal-lingwi (MASS) b’korpus monolingwi biss wara l-arkitettura NMT mhux sorveljata. Ir-riżultati evalwati huma ddikjarati fil-kompitu kondiviż LoResMT 2020, li jirrapporta li s-sistema tagħna tilħaq il-punteġġ ta’ sottostudju ta’ evalwazzjoni billingwi (BLEU) ta’ 0.59, punteġġ ta’ preċiżjoni ta’ 3.43, punteġġ ta’ tfakkir ta’ 5.48, punteġġ ta’ kejl F ta’ 4.22, u punteġġ ta’ evalwazzjoni billingwi intwittiv ibbażat fuq il-grad (RIBES) ta’ 0.180147 fit-traduzzjoni Russa għal Hindi. U għat-traduzzjoni Indjana għar-Russu, kisbet il-punteġġ BLEU, preċiżjoni, tfakkir lura, kejl F, u RIBES ta’ 1.11,
4. 72, 4. 41, 4. 56, u 0. 026842 rispettivament.</abstract_mt>
      <abstract_mn>Цэцгийн машин хөгжүүлэлт (NMT) нь машины хөгжүүлэлт (MT) нийгэмд шинэ хүлээн зөвшөөрөгдсөн арга юм. Нэг байгалийн хэлээс өөр байгалийн хэл руу орчуулдаг. Хэдийгээр НMT нь өндөр болон бага баялаг эдийн засгийн хэл дээр гайхалтай үйл ажиллагааг харуулдаг ч, үүнд хангалттай сургалтын корпус хэрэгтэй. Бага боловсролын хэлний хооронд параллел корпус хэрэглэгдэх нь MT-ийн хамгийн чухал ажил юм. Энэ асуудлыг багасгахын тулд NMT нь нэг хэлний корпус ашиглаж, бага боловсролын хэлний хооронд илүү сайн орчуулахыг хичээдэг. MT of Low Resource Languages (LoResMT 2020) технологийн талаар ажиллах үйл ажиллагаа нь бага боловсролын хэл хоёр хөрөнгө хөрөнгө оруулах үйл ажиллагааг 0-shot NMT ашиглаж зохион байгуулсан. Энд параллел корпус хэрэглэгддэггүй, зөвхөн ганц хэл корпора зөвхөн боломжтой. Бид багийн нэртэй CNLP-NITS-г Орос-Хинди хэл хоёрын хувьд ижил хуваалцаанд оролцсон. Бид хэл төрөлхтний өмнө дасгал хөдөлгөөний дараа ганц хэлний корпус зөвхөн ганц хэлний корпус ашиглаж байна. Дэлхийн үр дүнг нь LoResMT 2020-ийн хуваалцааны ажил дээр тайлбарлаж байна. Энэ нь бидний систем хоёр хэлний дүгнэлтийн доогуур судалгааны 0.59 оноо, 3.43 оноо, 5.48 оноо, 4.22 оноо F-хэмжээтэй, 2 хэлний дүгнэлтийн дүгнэлтийн оноо (RIBES) нь 0.180147 руу хоёр хэлний хэлний хувьд Хинди хэлний хувилбарт. Хинди руссан орчуудад бид БЛЕУ-г, тодорхой, санамж, F-хэмжээг, RIBES-г 1.11 гаргасан.
4.72, 4.41, 4.56, 0.026842.</abstract_mn>
      <abstract_ml>ന്യൂറല്‍ മെഷീന്‍ പരിഭാഷകങ്ങള്‍ (NMT) എന്ന മെഷീന്‍ പരിഭാഷകളില്‍ ഒരു വിശാലമായി സ്വീകരിക്കപ്പെട്ട സാധാരണ ഭാഷയിലേക്ക് മറ്റൊരു  എന്നാലും എംഎംടി ഉയരത്തിലും കുറഞ്ഞ വിഭവഭാഷകളിലും മാന്യമായ പ്രകടനം കാണിച്ചിരിക്കുന്നുവെങ്കിലും, അതിന് മതി കുറഞ്ഞ വിഭവഭാഷയിലെ ജോടികളില്‍ ഒരു പാരാളില്‍ കോര്‍പ്പുസിന്റെ ലഭ്യമല്ലെങ്കില്‍ എംടിയിലെ വിലപിടിക്കുന്ന ജോലികളില്‍ ഒന്നാണ്. ഈ പ്രശ്നത്തില്‍ മുഴുക്കുവാന എംടി ഓഫ് കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകള്‍ക്കുള്ള ടെക്നോളജികളില്‍ പങ്കെടുത്ത ജോലികള്‍ നിര്‍മ്മിക്കുന്നു Here, the parallel corpus is not used and only monolingual corpora is allowed.  ഞങ്ങള്‍ നമ്മുടെ ടീമില്‍ പങ്കെടുത്ത ഒരേ ജോലിയില്‍ പങ്കുചേര്‍ന്നിരിക്കുന്നു. റഷ്യന്‍ - ഹിന്ദി ഭാഷ ജോടിയുടെ സിന്‍ നിര്‍മ്മിക്കപ്പെടാത്ത NMT ആര്‍ക്കിട്ടറിക്കുമ്പോള്‍ മോണോളില്‍ ഭാഷ തലമുറയുടെ (MASS) മുമ്പില്‍ പരിശീലനത്തിന് മുമ്പ് പരിശീലനത്ത ലോറെസ്എംടി 2020 പങ്കെടുത്ത ജോലിയില്‍ നിന്നും വിജയിക്കപ്പെടുന്ന ഫലങ്ങള്‍ പ്രഖ്യാപിക്കപ്പെടുന്നു, നമ്മുടെ സിസ്റ്റത്തില്‍ നമ്മുടെ രണ്ടു ഭാഷ വിലയ്ക്കുന്ന അസ്ഥിതി പ്രാപിക്കുന്നു (ബിലിയു) സ്കോര്‍ 0. 59, മിസ്റ് ഹിന്ദിയ്ക്ക് റഷ്യന്‍ പരിഭാഷയ്ക്ക് വേണ്ടി ഞങ്ങള്‍ ബിലൂയിലേക്ക് എത്തിയിട്ടുണ്ട്, പ്രിസിഷന്‍, ഓർമ്മിക്കുന്നു, എഫ് മേ
4. 72, 4. 41, 4. 56, 0. 026842.</abstract_ml>
      <abstract_ro>Traducerea automată neurală (NMT) este o abordare larg acceptată în comunitatea traducerii automate (MT), traducând dintr-o limbă naturală în altă limbă naturală. Deși NMT prezintă performanțe remarcabile atât în limbile cu resurse ridicate, cât și în limbile cu resurse reduse, are nevoie de un corp de formare suficient. Disponibilitatea unui corpus paralel în perechi de limbi cu resurse reduse este una dintre sarcinile dificile din MT. Pentru a atenua această problemă, NMT încearcă să utilizeze un corpus monolingv pentru a deveni mai bun la traducere pentru perechi de limbi cu resurse reduse. Atelierul de lucru privind tehnologiile pentru MT de limbi cu resurse reduse (LoResMT 2020) a organizat sarcini comune de traducere a perechilor de limbi cu resurse reduse utilizând NMT zero-shot. Aici corpul paralel nu este folosit și numai corpurile monolingve sunt permise. Am participat la aceeași sarcină comună cu numele echipei noastre CNLP-NITS pentru perechea de limbi ruso-hindi. Am folosit secvența mascată pentru a secvența pregătirea pentru generarea limbilor (MASS) cu corpuri monolingve care urmează arhitectura NMT nesupravegheată. Rezultatele evaluate sunt declarate în cadrul sarcinii comune LoResMT 2020, care raportează că sistemul nostru obține scorul de dublare de evaluare bilingvă (BLEU) de 0,59, scorul de precizie de 3,43, scorul de rechemare de 5,48, scorul de măsură F de 4,22 și scorul intuitiv de evaluare bilingvă (RIBES) de 0,180147 în traducerea rusă în hindi. Și pentru traducerea hindi în rusă, am obținut BLEU, precizie, rechemare, F-measure, și RIBES scor de 1.11,
4, 72, 4, 41, 4, 56, respectiv 0, 026842.</abstract_ro>
      <abstract_no>Neuralmaskinsomsetjing (NMT) er ein veldig godteken tilnærming i samfunnet med maskinsomsetjing (MT), som omsetjer frå ein naturspråk til ein annan naturspråk. Selv om NMT viser merkelige utviklingar i både høg og låg ressursspråk, treng det nok opplæringskorpus. Tilgjengeleg eit parallell korpus i låg ressursspråk er ein av dei vanskelege oppgåva i MT. For å minne dette, prøver NMT å bruka ein monospråk korpus for å få bedre i omsetjinga for låg ressursspråk. Arbeidshop på teknologiar for MT av låg ressursspråk (LoResMT 2020) organisert delte oppgåver med låg ressursspråk- par omsetjing med null- shot NMT. Her er det parallelle korpusen ikkje brukt, og berre monospråk korpora er tillatt. Vi har delta i den same delte oppgåva med gruppenamnet vårt CNLP-NITS for den russiske-hindiske språkopla. Vi har brukt maskerte sekvens for å sekvensera før opplæring for språk-generering (MASS) med berre monospråk korpus etter ikkje-oppretta NMT-arkitekturen. Den evaluerte resultatene er deklarert på delt oppgåva LoResMT 2020, som rapporterer at systemet vårt når det understudierer med bilinguelt evaluering (BLEU) er 0,59, nøyaktighetspoeng med 3,43, rekna opp poeng med 5,48, F-målspoeng med 4,22, og rankbasert intuitivt bilinguelt evalueringspoeng (RIBES) av 0,180147 i russisk til hindisk omsetjing. Og for Hindi til russisk omsetjing har vi nådd BLEU, nøyaktig, rekning, F-mål og RIBES-poeng på 1,11,
4, 72, 4, 41, 4, 56 og 0, 026842 respectively.</abstract_no>
      <abstract_pl>Neuronalne tłumaczenie maszynowe (NMT) to powszechnie akceptowane podejście w społeczności tłumaczeń maszynowych (MT), tłumaczenie z jednego języka naturalnego na inny język naturalny. Chociaż NMT wykazuje niezwykłą wydajność zarówno w językach o wysokich jak i niskich zasobach, potrzebuje wystarczającego korpusu szkoleniowego. Dostępność równoległego korpusu w parach językowych o niskich zasobach jest jednym z trudnych zadań w MT. Aby złagodzić ten problem, NMT stara się wykorzystać korpus jednojęzyczny, aby poprawić tłumaczenie par językowych o niskich zasobach. Warsztat Technologii dla MT języków niskich zasobów (LoResMT 2020) zorganizował wspólne zadania tłumaczenia par językowych niskich zasobów przy użyciu zero-shot NMT. Tutaj korpus równoległy nie jest używany i dozwolone są tylko korpusy jednojęzyczne. Uczestniczyliśmy w tym samym wspólnym zadaniu z naszym zespołem CNLP-NITS dla pary językowej rosyjsko-hindi. Zastosowaliśmy sekwencję maskowaną do sekwencji wstępnego szkolenia do generowania języka (MASS) z jedynie jednojęzycznym korpusem według architektury NMT bez nadzoru. Oceniane wyniki deklarowane są w zadaniu wspólnym LoResMT 2020, które zgłasza, że nasz system osiąga dwujęzyczny wynik oceny dublera (BLEU) 0.59, wynik precyzyjny 3.43, wynik przywołania 5.48, wynik miary F 4.22 oraz rankingowy intuicyjny dwujęzyczny wynik oceny (RIBES) 0.180147 w tłumaczeniu rosyjskim na hindi. A dla tłumaczenia z hindi na rosyjski osiągnęliśmy BLEU, precyzję, przypomnienie, F-miarę i RIBES wynik 1.11,
Odpowiednio 4.72, 4.41, 4.56 i 0.026842.</abstract_pl>
      <abstract_si>න්‍යූරාල් මැෂින් භාෂාව (NMT) විශාල භාෂාව ප්‍රවේශ කරනවා මැෂින් භාෂාව (MT) සමාජයේදී, එක ස්වභාවි නමුත්, NMT එක පෙන්වන්නේ ප්‍රශ්නයක් විශ්වාස කරන්න පුළුවන් භාෂාවක් වගේම, ඒකෙන් පුළුවන් ප්‍ර MT වලින් ප්‍රශ්ණ භාෂාවයේ සමාන්‍ය කොර්පුස් වලින් ප්‍රශ්ණතාවක් තියෙන්න පුළුවන්. මෙම ප්‍රශ්ණාව මහත්තර කරන්න, NMT ප්‍රශ්ණාවක් එක භාෂ MT of low source language (LoResMT 202) විශාල භාෂාව සඳහා තාක්ෂණාත්මක භාෂාව සඳහා විශාල විධානය සඳහා සංවිධානය කරලා තියෙන්නේ අඩු මෙතන, සමාන්‍ය කොර්පස් භාවිතා කරන්නේ නැහැ ඒ වගේම එක භාෂාවක් කොර්පෝරා විතරයි අවසර වෙන අපි අපේ කණ්ඩායමේ නම CNLP-NITS එක්ක එකම ක්‍රියාත්මක වෙනුවෙන් රූසිය-හින්දි භාෂාවක් ජෝඩායට සමාගත්ත අපි භාෂා විශාලය (MASS) විශාලයෙන් ප්‍රධානය කරලා තියෙන්නේ මුහුණු ක්‍රමය භාවිත කරලා තියෙන්නේ නැහැ NMT විශා The evaluted score are proclaimed at the LoResMT 202 shared job, that report that our system has the Bilngual evalution understudy (BLUES) score of 0.59, Precity score of 3.43, recall score of 5.48, F-Measuring score of 4.22, and rang-based Intuitive Bilngual evalution score (RIBES) of 0.180147 in Russian to Hindi translation. ඒ වගේම හින්දි රුසියානු වාර්තාවෙන් අපිට ලැබුනා BLUE, අවශ්‍යය, මතකය, F-මාර්තාව, සහ RIBES ස්කෝර් 1.11,
4.72, 4.41, 4.56, සහ 0.517842 විශේෂයෙන්.</abstract_si>
      <abstract_so>Turjumista neural machine (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one language natural to another language natural. Inta kastoo ay NMT muujiyaan muuqashada farsamada badan oo ku qoran luqadaha sare iyo hoose ee noocyada nololeed, waxay u baahan tahay barashada ku filan. Helitaanka korpus lambarka luqada hoose ee noocyada rasmi ah waa mid ka mid ah shaqada dhibaatada ee MT. Si loo fududeeyo arimahan, NMT wuxuu isku dayaa in uu u isticmaalo korpus af monoli ah si uu ugu fiican u noqdo turjumidda luqada hoose ee noocyo badan. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT.  Halkan lama isticmaalo qofka lambarka ah, waxaa la ogolaan karaa shirkadda afka oo kaliya. Waxaannu ka qayb galnay shuqulkaas isku mid ah ee kooxdayaga magaca CNLP-NITS ee labada luqada Ruushka-Hindi. Waxaannu u isticmaalnay dabool-masked si aan u soo bandhignayno barbaarin-horaadka oo afka (MASS) oo kaliya qofka afka ah oo kaliya, taas oo ka dib dhismaha aan la ilaalinayn NMT. Abaalka qiimeynta waxaa lagu sheegaa shaqada la qaybsaday LoResMT 2020, taas oo ku qoran in nidaamkayagu uu gaadho kooxda qiimeynta labada luqadood (BLEU) ee 0.59, kooxda saxda ah 3.43, xusuuso scorka 5.48, kooxda F-qiyaasta 4.22, iyo kooxda qiimeynta labada luqadood oo si fiican u qoran (RIBES) oo ku qoran 0.180147 oo ku qoran Ruushka ilaa Hindi. Xindi ilaa turjumista Ruushka, waxaynu gaadhnay BLEU, saxda, xusuustana, F-measure iyo RIBES scoro 1.11,
4.72, 4.41, 4.56 iyo 0.026842.</abstract_so>
      <abstract_sv>Neural maskinöversättning (NMT) är ett allmänt accepterat tillvägagångssätt inom maskinöversättning (MT) gemenskapen, som översätter från ett naturligt språk till ett annat naturligt språk. Även om NMT uppvisar anmärkningsvärda prestanda på både hög- och lågresursspråk, behöver det tillräckligt med träningscorpus. Tillgängligheten av en parallell korpus i språkpar med låga resurser är en av de utmanande uppgifterna i MT. För att mildra detta problem försöker NMT använda en enspråkig korpus för att bli bättre på översättning för språkpar med låga resurser. Workshop om teknik för MT för lågresursspråk (LoResMT 2020) organiserade delade uppgifter för översättning av lågresursspråk med hjälp av noll-skott NMT. Här används inte parallellkorpus och endast enspråkiga korpus är tillåtna. Vi har deltagit i samma gemensamma uppgift med vårt teamnamn CNLP-NITS för det ryska-hindi språkparet. Vi har använt maskerad sekvens för att sekvensera pre-training för språkgenerering (MASS) med endast enspråkig korpus efter den oövervakade NMT-arkitekturen. De utvärderade resultaten redovisas vid LoResMT 2020 delad uppgift, som rapporterar att vårt system uppnår tvåspråkig utvärderingsdokument (BLEU) poäng på 0,59, precisionspoäng på 3,43, återkallelsepoäng på 5,48, F-mått poäng på 4,22 och rankbaserad intuitiv tvåspråkig utvärdering score (RIBES) på 0,180147 i ryska till hindi översättning. Och för hindi till rysk översättning har vi uppnått BLEU, precision, återkallande, F-mått och RIBES poäng på 1,11,
4, 72, 4, 41, 4, 56 respektive 0, 026842.</abstract_sv>
      <abstract_ta>கணினி மொழிபெயர்ப்பு (MT) சமூகத்தில் ஒரு பெரிய ஏற்றுக் கொள்ள இயந்திர மொழியை மொழிபெயர்ப்பு, ஒரு இயல்பான மொழியிலிருந்து மற எனினும், NMT உயர்ந்த மற்றும் குறைந்த மூலத்தின் மொழிகளிலும் பெரிய செயல்பாட்டை காட்டுகிறது, அது போதுமான பயிற குறைந்த மூலத்தின் ஜோடிகளில் ஒரு இணைய கூட்டு குறைந்த மொழி ஜோடியின் கிடைக்கும் பொருள் MT-ல் ஒரு சவாலிக்கும் பணிகளில் ஒன்று. இந்த பிரச்சனை முறைப்பதற்கு, NMT ம Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT.  இங்கே இணைய கோர்பாஸ் பயன்படுத்தப்படவில்லை மற்றும் மானோலிங் கோர்போர் மட்டுமே அனுமதிக்கப்படுகிறது. நாங்கள் ஒரே பகிர்ந்த பணியில் பங்கிடப்பட்டுள்ளோம் நம் குழு பெயர் CNLP-NITS ருஷ்யன் ஹின்டி மொழி ஜோடி. நாங்கள் முகப்பு தொடர்ச்சியை பயன்படுத்தி மொழி தலைப்புக்கு முன் பயிற்சியை தொடர்ந்து கொள்ள பயன்படுத்தியுள்ளோம் ( MASS) மட்டும் மொனோ மதிப்பிடப்பட்ட முடிவுகள் லோரிஸ்எம்ட் 2020 பகிர்ந்த பணியில் அறிவிக்கப்படுகிறது, அது நம் கணினியில் இருமொழி evaluation understude பெறுகிறது 0. 59, துல்லியமான மதிப்பு score of 3. 43, 5. 48, F- measure score of 4. 22, மற்றும் rank- based இருமுழு evaluation score (RIBES) of 0. 180147 in மற்றும் ருஷ்யன் மொழிபெயர்ப்பிற்கு, நாங்கள் BLEU, துல்லியம், நினைவு, F-அளவு, மற்றும் RIBES மதிப்பு 1.11,
4. 72, 4. 41, 4. 56, மற்றும் 0. 026842.</abstract_ta>
      <abstract_ur>نیورال ماشین ترجمہ (NMT) ماشین ترجمہ (MT) کمونٹی میں بہت سی قبول کی طرح ہے، ایک طبیعی زبان سے دوسری طبیعی زبان تک ترجمہ کرتا ہے۔ اگرچہ NMT ان دونوں بلند اور کم سرمایہ زبانوں میں اچھی طرح کی فعالیت دکھاتا ہے، اس کے لئے کافی تربیت کرپوس کی ضرورت ہے. نیچے سراسر زبان جوڑوں میں پارالی کورپوس کا موجود MT میں سے ایک مشکل کام ہے. اس مسئلہ کو کمزور کرنے کے لئے NMT ایک ایک زبان کورپوس کا استعمال کرنا کوشش کرتا ہے کہ کم سراسر زبان جوڑوں کے لئے بہتر ترجمہ کرے۔ نیچے رسسور زبانوں کے MT کی تکنولوژی پر کارشاپ (LoResMT 2020) نیچے رسسور زبانوں کی جوڑی ترجمہ کے مطابق نیچے رسسور زبانوں کی جڑی ترجمہ کا کام سازما کیا گیا ہے. یہاں، parallel corpus کا استعمال نہیں کیا جاتا اور صرف ایک زبان کی corpora اجازت دی جاتی ہے. ہم نے اپنے ٹیم کا نام CNLP-NITS کے ساتھ ایک ہی شریک کام میں شریک کیا ہے روسی-ہندی زبان جوڑے کے لئے۔ ہم نے زبان کی نسل (MASS) کے لئے پہلے آموزش کے لئے ماسک کڑھا استعمال کیا ہے۔ صرف ایک زبان کڑھا کے ساتھ NMT معماری کے پیچھے۔ ارزیابی نتائج LoResMT 2020 کے مشترک کام میں اعلام کی جاتی ہیں، جو ہماری سیستم کی تعلیم 0.59 کی دو زبان کی ارزیابی (BLEU) اسکور پہنچ جاتی ہے، 3.43 کی دقیق اسکور، 5.48 کی اسکور یاد کرو، 4.22 کی F-measure اسکور اور 0.180147 کی دو زبان کی ارزیابی اسکور (RIBES) کی نسبت رکھتی ہے۔ اور ہندی کو روسی ترجمہ کے لئے ہم نے BLEU کو پہنچایا ہے، دقیق، یاد، F-measure، اور RIBES score 1.11،
4.72, 4.41, 4.56 اور 0.026842.</abstract_ur>
      <abstract_sr>Neuralni prevod mašine (NMT) je široko prihvaćen pristup u zajednici prevoda mašine (MT), prevodeći se iz jednog prirodnog jezika na drugi prirodni jezik. Iako, NMT pokazuje izvanrednu predstavu na visokim i niskim jezicima resursa, potrebno je dosta korpusa za obuku. Dostupnost paralelnog korpusa u parovima niskih resursa je jedan od izazovnih zadataka u MT-u. Za smanjenje ovog pitanja, NMT pokušava iskoristiti monojezički korpus kako bi se bolje priključio za parove niskih resursa. Radionica o tehnologijama za MT jezika niskih resursa (LoResMT 2020) organizovala je zajednički zadatak prevođenja par niskih resursa sa nulom snimkom NMT. Ovde, paralelni korpus se ne koristi i samo monojezička korpusa je dozvoljena. Mi smo sudjelovali u istom zajedničkom zadatku sa tim imenom CNLP-NITS za rusko-hindski parov. Koristili smo maskiranu sekvencu da bi sekvencirali predobuku za generaciju jezika (MASS) sa samo monojezičkim korpusom nakon neodređene arhitekture NMT-a. Procjenjeni rezultati su objavljeni na zajedničkom zadatku LoResMT 2020, koji prijavljuje da naš sistem postigne rezultat ispitivanja dvojezika (BLEU) od 0,59, precizni rezultat od 3,43, sećate rezultat od 5,48, rezultat F-mjere od 4,22, i rezultat intuitivnog dvojezičkog procjene (RIBES) od 0,180147 na ruskom i hindskom prevodu. A za Hindi na ruski prevod, postigli smo BLEU, preciznost, sjećanje, F-mjera i RIBES rezultat od 1,11,
4,72, 4,41, 4,56 i 0,026842.</abstract_sr>
      <abstract_uz>@ info: whatsthis Agar NMT yuqori va kichkina manbaning tilida ajoyib bajarish natijasini ko'rsatadi, u yetarli taʼminlovchi kompyuter kerak. Name Name Bu yerda parallel corpus ishlatilmaydi va faqat monolingan kompaniya ishlatadi. Biz Ruscha-Hindi tili ikki xil bo'lgan CNLP-NITS (CNLP-NITS) sohasida bir xil vazifani o'rganimiz. Biz tilning foydalanuvchi oldin foydalanishni faqat monolingual corpus bilan ishlab chiqarish uchun qo'yib qo'yib chiqaramiz. The evaluated results are declared at the LoResMT 2020 shared task, which reports that our system achieves the bilingual evaluation understudy (BLEU) score of 0.59, precision score of 3.43, recall score of 5.48, F-measure score of 4.22, and rank-based intuitive bilingual evaluation score (RIBES) of 0.180147 in Russian to Hindi translation.  Hindiga Ruscha tarjima qilish uchun biz BLEU, murakkablik, eslab qolamiz, F-metrli va RIBES 1.11 scori topdik,
4.72, 4.41, 4.56, and 0.026842 respectively.</abstract_uz>
      <abstract_vi>Dịch về máy thần kinh (NMB) là một phương pháp được chấp nhận rộng rãi trong cộng đồng dịch vụ máy, dịch từ ngôn ngữ tự nhiên sang ngôn ngữ tự nhiên khác. Tuy nhiên, công nghệ NMT có hiệu quả đáng chú ý cả ngôn ngữ chất lượng cao và thấp, nhưng nó cần có tập thể huấn đầy đủ. Việc có thể có một tập đoàn song song song trong các cặp ngôn ngữ ít tài nguyên là một trong những công việc khó khăn ở MTV. Để giảm thiểu vấn đề này, NMT đã cố sử dụng một tập thể độc ngôn để có thể dịch tốt hơn cho các cặp ngôn ngữ ít tài nguyên. Workshop in Technology for MTV of Low Resource Ngôn ngữ (LoResMT 2020) đã tổ chức các công việc chia sẻ của dịch đôi ngôn ngữ ít tài nguyên bằng NMT không bắn được. Ở đây không sử dụng tế bào song song và chỉ có thể là hạ sĩ ngôn ngữ. Chúng tôi đã tham gia cùng một nhiệm vụ chung với tên của đội CNchọc-NITS cho cặp ngôn ngữ Nga-Ấn. Chúng tôi đã dùng chế độ đeo mặt nạ để lặp lại giai đoạn trước đào tạo ngôn ngữ (MASS) với một cơ thể độc ngôn ngữ theo kiến trúc NMB không được giám sát. Những kết quả đánh giá được tuyên bố tại công việc chia sẻ của LoResMTV, báo cáo rằng hệ thống này đạt được kết quả hai chiều cao của đánh giá hai thứ (bắn nguyên số) của 0.59, tỉ số chính xác của 3 Và để dịch tiếng Hindi đến tiếng Nga, ta đã đạt được nguyên tắc: bắn nguyên, chính xác, rút lại, F-thước và mã số I.11,
Hợp lý 4.72, 4.41, 4.56, và 0.268402.</abstract_vi>
      <abstract_nl>Neural machine translation (NMT) is een algemeen geaccepteerde benadering in de machinevertaling (MT) gemeenschap, het vertalen van de ene natuurlijke taal naar een andere natuurlijke taal. Hoewel NMT opmerkelijke prestaties vertoont in zowel hoge als lage resourcetalen, heeft het voldoende trainingscorpus nodig. De beschikbaarheid van een parallel corpus in lage resource taalparen is een van de uitdagende taken in MT. Om dit probleem te verminderen, probeert NMT een monolingual corpus te gebruiken om beter te worden in vertaling voor lage resource taalparen. Workshop over technologieën voor MT of Low Resource Languages (LoResMT 2020) organiseerde gedeelde taken van low resource talenpaar vertaling met behulp van zero-shot NMT. Hier wordt het parallelle corpus niet gebruikt en is alleen eentalige corpora toegestaan. We hebben deelgenomen aan dezelfde gedeelde taak met onze teamnaam CNLP-NITS voor het Russisch-Hindi taalpaar. We hebben gemaskerde volgorde gebruikt om pre-training voor taalgeneratie (MASS) te sequenceren met slechts eentalig corpus volgens de niet-begeleide NMT architectuur. De geëvalueerde resultaten worden gedeclareerd bij de LoResMT 2020 gedeelde taak, die meldt dat ons systeem de tweetalige evaluatie understudy (BLEU) score van 0.59, precisie score van 3.43, recall score van 5.48, F-meet score van 4.22 en rank-based intuïtieve tweetalige evaluatie score (RIBES) van 0.180147 in Russisch naar Hindi vertaling bereikt. En voor Hindi naar Russisch vertaling hebben we BLEU, precisie, recall, F-maat en RIBES score van 1.11,
4.72, 4.41, 4.56 en 0.026842 respectievelijk.</abstract_nl>
      <abstract_de>Neuronale maschinelle Übersetzung (NMT) ist ein weit verbreiteter Ansatz in der maschinellen Übersetzung (MT) Gemeinschaft, die Übersetzung von einer natürlichen Sprache in eine andere natürliche Sprache. Obwohl NMT sowohl in High- als auch Low-Resource-Sprachen bemerkenswerte Leistungen aufweist, bedarf es eines ausreichenden Trainingskorpus. Die Verfügbarkeit eines parallelen Korpus in ressourcenarmen Sprachpaaren ist eine der herausfordernden Aufgaben in der MT. Um dieses Problem zu beheben, versucht NMT, einen einsprachigen Korpus zu verwenden, um die Übersetzung von ressourcenarmen Sprachpaaren besser zu machen. Der Workshop über Technologien für MT von Low Resource Languages (LoResMT 2020) organisierte gemeinsame Aufgaben der Low Resource Language Pair Übersetzung mit Zero-Shot NMT. Hier wird der parallele Korpus nicht verwendet und nur einsprachige Korpora sind erlaubt. Wir haben an der gleichen gemeinsamen Aufgabe mit unserem Teamnamen CNLP-NITS für das Russisch-Hindi Sprachpaar teilgenommen. Wir haben maskierte Sequenz verwendet, um das Vorbereitungstraining für die Sprachgenerierung (MASS) mit nur einem einsprachigen Korpus nach der unüberwachten NMT-Architektur zu sequenzieren. Die ausgewerteten Ergebnisse werden bei der gemeinsamen Aufgabe LoResMT 2020 deklariert, die berichtet, dass unser System die zweisprachige Evaluation Understudy (BLEU) Score von 0.59, Präzisionsscore von 3.43, Recall Score von 5.48, F-Measure Score von 4.22 und rank-basierte intuitive zweisprachige Evaluation Score (RIBES) von 0.180147 in der Russisch-Hindi Übersetzung erreicht. Und für die Übersetzung von Hindi ins Russische haben wir BLEU, Präzision, Rückruf, F-Maß und RIBES Score von 1.11 erreicht.
4.72, 4.41, 4.56 und 0.026842 jeweils.</abstract_de>
      <abstract_da>Neural maskinoversættelse (NMT) er en bredt accepteret tilgang i maskinoversættelsesfællesskabet, der oversætter fra et naturligt sprog til et andet naturligt sprog. Selvom NMT viser bemærkelsesværdig ydeevne på både høje og lave ressourcer sprog, har det brug for tilstrækkelig træningskorpus. Tilgængeligheden af et parallelt korpus i sprogpar med lave ressourcer er en af de udfordrende opgaver i MT. For at afhjælpe dette problem forsøger NMT at udnytte et ensproget korpus for at blive bedre til oversættelse for sprogpar med lave ressourcer. Workshop om teknologier til MT af lav ressource sprog (LoResMT 2020) organiserede delte opgaver med lav ressource sprogpar oversættelse ved hjælp af zero-shot NMT. Her anvendes det parallelle korpus ikke, og kun ensprogede korpus er tilladt. Vi har deltaget i den samme fælles opgave med vores teamnavn CNLP-NITS for russisk-hindi sprogpar. Vi har brugt maskeret sekvens til at sekvensere pre-training for language generation (MASS) med kun ensproget korpus efter den uopvågede NMT arkitektur. De evaluerede resultater er erklæret ved LoResMT 2020 delte opgave, som rapporterer, at vores system opnår den tosprogede evalueringsdubleater (BLEU) score på 0,59, præcisionsscore på 3,43, tilbagekaldelsescore på 5,48, F-måle score på 4,22 og rangbaseret intuitiv tosproget evalueringsscore (RIBES) på 0,180147 i russisk til hindi oversættelse. Og for hindi til russisk oversættelse, har vi opnået BLEU, præcision, tilbagekaldelse, F-måling og RIBES score på 1,11,
Henholdsvis 4, 72, 4, 41, 4, 56 og 0, 026842.</abstract_da>
      <abstract_hr>Neuralni prevod strojeva (NMT) je široko prihvaćen pristup u zajednici prevoda strojeva (MT), prevodeći se iz jednog prirodnog jezika na drugi prirodni jezik. Iako, NMT pokazuje izvanrednu učinku na visokim i niskim jezicima resursa, potrebno je dovoljno obuke korpusa. Dostupnost paralelnog korpusa u parovima s niskim resursima je jedan od izazovnih zadataka u MT-u. Za smanjenje ovog pitanja, NMT pokušava iskoristiti monojezički korpus kako bi se poboljšao u prevodu za parove niskih resursa. Radionica o tehnologijama za MT jezika niskih resursa (LoResMT 2020) organizirala je zajednički zadatak prevoda par niskih resursa s nulom snimkom NMT. Ovdje, paralelni korpus se ne koristi i samo monojezička korpusa je dozvoljena. Učestvovali smo u istom zajedničkom zadatku s imenom našeg tima CNLP-NITS za ruski-hindski parov. Koristili smo maskiranu sekvencu kako bi sekvencirali predobuku za generaciju jezika (MASS) sa samo monojezičkim korpusom nakon neodređene arhitekture NMT-a. Procjenjeni rezultati su objavljeni na zajedničkom zadatku LoResMT 2020. godine, koji izvještava da naš sustav postigne rezultat podispitivanja dvojezika (BLEU) od 0,59, precizni rezultat od 3,43, sjeti rezultat od 5,48, rezultat F-mjere od 4,22, i rezultat intuitivnog dvojezičkog procjene (RIBES) od 0,180147 na ruskom i hindskom prevodu. A za Hindi na ruski prevod, postigli smo BLEU, preciznost, sjećanje, F-mjera i RIBES rezultat od 1,11,
4,72, 4,41, 4,56 i 0,026842.</abstract_hr>
      <abstract_bg>Невровият машинен превод (НМТ) е широко приет подход в общността на машинните преводи (МТ), превеждащ от един естествен език на друг естествен език. Въпреки че НМТ показва забележителни резултати както на езици с висок, така и с нисък ресурс, тя се нуждае от достатъчно обучителен корпус. Наличието на паралелен корпус в езикови двойки с нисък ресурс е една от предизвикателствата в МТ. За да смекчи този проблем, НМТ се опитва да използва едноезичен корпус, за да се подобри превода за езикови двойки с нисък ресурс. Семинар "Технологии за МТ на нискоресурсните езици" (ЛоРеМТ 2020) организира споделени задачи за превод на двойки езици с нисък ресурс, използвайки нулева НМТ. Тук паралелният корпус не се използва и се допускат само едноезични корпуси. Участвахме в същата споделена задача с името на екипа ни за двойката руско-хинди език. Използвахме маскирана последователност, за да последователизираме предварителното обучение за езиково генериране (МАСС) само с едноезичен корпус, следващ неподдържаната архитектура на НМТ. Оценените резултати са декларирани на споделената задача, която отчита, че нашата система постига двуезичен резултат от 0,59, прецизност от 3,43, реконструкционен резултат от 5,48, F-мярка от 4,22 и интуитивен двуезичен резултат от 0,180147 в превод на руски на хинди. А за превода от хинди на руски, постигнахме прецизност, повторение, F-мярка и оценка RIBES от 1,11,
4, 72, 4, 41, 4, 56 и 0, 026842 съответно.</abstract_bg>
      <abstract_sw>Tafsiri ya mashine ya asili (NMT) ni mbinu inayokubalika sana katika jamii ya kutafsiri mashine (MT), inayotafsiri kutoka lugha moja ya asili hadi lugha nyingine ya asili. Although, NMT shows remarkable performance in both high and low resource languages, it needs sufficient training corpus.  Upatikanaji wa vifaa vinavyofanana katika viwili vya asili chini vya rasilimali ni moja ya kazi za changamoto nchini MT. Kupunguza suala hili, jaribio la NMT linalotumia makampuni ya lugha za kiimla ili kupata vizuri katika tafsiri kwa ajili ya viwili vya chini vya rasilimali. Warsha ya Teknolojia kwa ajili ya MT ya Lugha za chini za rasilimali (LoResMT 2020) ilishiriki kazi za kutafsiri lugha ndogo ya rasilimali kwa kutumia NMT isiyopigwa risasi. Hapa, makampuni hayo yanayofanana hayatumika na kampuni ya utamaduni pekee inaruhusiwa. Tumeshiriki katika kazi hiyo hiyo na timu yetu inayoitwa CNLP-NITS kwa ajili ya wawili wa lugha ya Kirusi na Kihindi. Tumetumia mfululizo wa vifusi ili kutangaza mafunzo ya awali kwa ajili ya kizazi cha lugha (MASS) yenye makampuni pekee ya lugha kufuatia majengo ya NMT isiyohifadhiwa. Matokeo yaliyothibitiwa yametangazwa katika kazi ya LoResMT 2020, ambayo inaripoti kwamba mfumo wetu unapata msingi wa uchunguzi wa lugha mbili (BLEU) wa 0.59, score sahihi ya 3.43, kumbuka score 5.48, score ya F-measure ya 4.22, na score ya tafiti za lugha yenye msingi wa rangi (RIBES) ya 0.180147 nchini Urusi hadi tafsiri ya Hindi. Na kwa Wahindi hadi kutafsiri Urusi, tumefanikiwa BLEU, uhakika, kumbuka, F-measure, na vipimo vya RIBES 1.11,
4.72, 4.41, 4.56 na 0.026842.</abstract_sw>
      <abstract_ko>신경기계번역(NMT)은 기계번역(MT)계에서 널리 받아들여지는 방법으로 자연어를 다른 자연어로 번역한다.비록 NMT는 고자원과 저자원 언어에서 현저한 성능을 나타냈지만, 충분한 훈련 자료 라이브러리가 필요하다.저자원 언어의 중평행 자료 라이브러리에 대한 가용성은 기계 번역에서 도전적인 임무 중 하나이다. 이 문제를 완화하기 위해 NMT는 단어 자료 라이브러리를 이용하여 저자원 언어 라이브러리를 더욱 잘 번역하고자 한다.저자원언어 기계번역기술 세미나(LoResMT 2020)는 제로포 NMT의 저자원언어로 번역에 대한 공유 임무를 조직했다.여기는 평행 자료 라이브러리를 사용하지 않고 단어 자료 라이브러리만 사용할 수 있습니다.팀 CNLP-NITS와 같은 공유 임무에 참여했습니다. 이 팀의 이름은 러시아어-인디언 쌍입니다.우리는 복면 서열을 사용하여 언어 생성 예훈련(MASS)을 정렬하고 단어 자료 라이브러리만 사용하며 감독이 없는 NMT 체계 구조를 따른다.평가 결과는 LoResMT 2020 공유 임무에서 발표됐으며, 이 임무보고서는 우리 시스템이 러시아어부터 인디언어 번역까지 이중언어평가대체(BLEU) 점수 0.59, 정확도 3.43, 회상 점수 5.48, F 측정 점수 4.22와 등급 기반의 직관 이중언어평가점수(RIBES) 0.180147을 기록했다.인디언에서 러시아어까지의 번역에 대해 우리는 이미 BLEU, 정확성, 회상성, F-measure와 RIBES 점수를 1.11로 실현했다.
4.72, 4.41, 4.56, 0.026842.</abstract_ko>
      <abstract_fa>ترجمه ماشین عصبی (NMT) یک دستور بسیار پذیرفته در جامعه ترجمه ماشین (MT) است که از یک زبان طبیعی به زبان طبیعی دیگر ترجمه می‌کند. اگرچه NMT به زبانهای بالا و کم منابع عملکرد فوق العاده را نشان می دهد، آن به کمپوس آموزش کافی نیاز دارد. موجودات یک کورپوس متفاوتی در جفت زبان کم منابع یکی از کارهای مشکل در MT است. برای کمبود کردن این مسئله NMT سعی می‌کند که یک کورپوس متفاوتی را استفاده کند تا در ترجمه برای جفت زبان کم منابع بهتر شود. کارگاه روی تکنولوژی‌ها برای MT زبان‌های منابع کم (LoResMT 2020) کار‌های مشترک از ترجمه‌های جفت زبان منابع کم با استفاده از NMT صفر ساخته شده است. اینجا، کورپوس متفاوتی استفاده نمی‌شود و تنها کورپورا متفاوتی اجازه می‌دهد. ما در یک کار مشترک با نام تیم ما CNLP-NITS برای جفت زبان روسی-هندی شرکت کردیم. ما از ترکیب ماسک استفاده کرده ایم تا پیش آموزش برای نسل زبان (MASS) را تعریف کنیم، با تنها یک کورپوس زبان دنبال معماری NMT غیرقابل تحمل کنیم. نتایج ارزیابی در کار مشترک LoResMT 2020 اعلام می‌شود، که گزارش می‌دهد که سیستم ما امتیاز زیر تحقیق دو زبان (BLEU) 0.59 می‌رسد، امتیاز دقیق 3.43، امتیاز 5.48، امتیاز F-اندازه 4.22، و امتیاز ارزیابی دو زبان (RIBES) در صف 0.180147 در ترجمه روسی به هندی می‌رسد. و برای ترجمه هندی به روسیه، ما به BLEU رسیدیم، دقیق، یادآوری، اندازه F و امتیاز RIBES ۱.۱۱،
4.72, 4.41, 4.56 و 0.026842 respectively.</abstract_fa>
      <abstract_am>የኔural machine translation (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one natural language to another natural language. ምንም እንኳን፣ NMT ከፍተኛ እና ዋናው የክፍለ ዕቃ ቋንቋዎች የሚያሳየው የአፍሪካዊ ድምፅ፣ ተግባር የሞላው ኮርፓስ ያስፈልጋል፡፡ በጥቂት resource ቋንቋ ዓይነቶች ውስጥ ተቃዋሚ የፓርላማ ኮፓስ መግኘት MT-ን ከሚያቃጥለው ስራ አንዲቱ ነው። ይህንን ጉዳይ ለማቀናቀል፣ NMT በሞሎልቋንቋ ኮፓስ ለመጠቀም ለመጠቀም ከታናሹ ምዕራፍ ቋንቋ ሁለት ለማሻል ይፈልጋል፡፡ የቴክኖሎጂ ላይ MT of Low Resource Languages እዚህ፣ የፓርላማ ኮርፓስ አይጠቀሙም እና የሞሎ ቋንቋ ኮርፖርት ብቻ ተፈቅዶአል፡፡ በጦማሪያችን CNLP-NITS ለራሲ-Hindi ቋንቋ ሁለታችንን በተካፈሉት ስራ ተጋርተናል፡፡ የቋንቋ ትውልድ (MASS) በተጠበቀው የNMT መሠረት ተከትሎ ብቻ የሞሎልቋንቋ ኮርፓስ ለመቀናቀል ጥቅረት ተጠቃሚ ነበር፡፡ በሎResMT 2020 የተካፈሉት ፍጥረቶች የተሰራረቡ ናቸው፡፡ And for Hindi to Russian translation, we have achieved BLEU, precision, recall, F-measure, and RIBES score of 1.11,
4.72፣ 4.41፣ 4.56 እና 0.026842።</abstract_am>
      <abstract_af>Neurale masjien vertaling (NMT) is 'n vaste aanvaardige toegang in die masjien vertaling (MT) gemeenskap, vertaling van een natuurlike taal na 'n ander natuurlike taal. Alhoewel, NMT wys betekende prestasie in hoë en lae hulpbron tale, dit benodig genoeg onderwerp corpus. Die beskikbaarheid van 'n parallele korpus in lae hulpbron taal paar is een van die verwagte taak in MT. Om hierdie probleem te verminder, probeer NMT om 'n monolinglike korpus te gebruik om beter te kry by vertaling vir lae hulpbron taal paar. Werkvoop op Tehnologies vir MT van Lae Hulpbron Taal (LoResMT 2020) het gedeelde taak van lae hulpbron taal paar vertaling georganiseer met zero-shot NMT. Hier, die parallele korpus is nie gebruik en slegs monolinglike korpora is toegelaat. Ons het gedeel in dieselfde gedeelde taak met ons span naam CNLP-NITS vir die Russe-Hindi taal paar. Ons het maskeerde volgorde gebruik om voor-oefening vir taal generasie (MASS) te volg met slegs monolinglike korpus volgens die onverondersteunde NMT-arkitektuur. Die evalueerde resultate word verkondig by die Gedeelde taak LoResMT 2020, wat rapporteer dat ons stelsel die twee tale evalueringsondersoek (BLEU) aantal van 0,59, presisie aantal van 3,43, reken aantal aantal van 5,48, F-maat aantal van 4,22, en rank-gebaseerde intuitiewe twee tale evalueringsaantal (RIBES) van 0,180147 in Russiese na Hindi vertaling. En vir Hindi tot Russiese vertaling, het ons BLEU, presisie, rekening, F-maat en RIBES-aantal van 1.11 bereik,
4. 72, 4. 41, 4. 56 en 0. 026842 respectively.</abstract_af>
      <abstract_hy>Նյարդային մեքենայի թարգմանությունը (NMT) լայնորեն ընդունված մոտեցում է մեքենայի թարգմանության (MT) համայնքում, թարգմանվում է մեկ բնական լեզվից մյուս բնական լեզվին: Չնայած, որ NMT-ը ցույց է տալիս արտահայտություն բարձր և ցածր ռեսուրսների լեզուներում, այն հարկավոր է բավարար ուսուցման կորպուս: ՄԹ-ի միջոցով պարամեռ կորպուսի հասանելիությունը ցածր ռեսուրսներ ունեցող զույգերում MT-ի հետ կապված խնդիրներից մեկն է: Այս խնդիրը նվազեցնելու համար NMT-ն փորձում է օգտագործել միալեզվով կորպուսը, որպեսզի ավելի լավ ստանան ցածր ռե Նվագ ռեսուրսների լեզուների MT-ի տեխնոլոգիաների աշխատասենյակը (LoReMT 2020) կազմակերպեց ցածր ռեսուրսների լեզուների զույգ թարգմանման ընդհանուր խնդիրներ՝ օգտագործելով զրոյական NMT: Here, the parallel corpus is not used and only monolingual corpora is allowed.  Մենք մասնակցել ենք նույն ընդհանուր խնդրին մեր թիմի անունով CNLP-Niks-ի համար ռուս-հինդի լեզվի զույգի համար: Մենք օգտագործել ենք ծածկված հաջորդականություն լեզվի ստեղծման նախապատրաստման հաջորդականության համար (MASS ի) միայն մեկլեզու կորպոսի հետ, որը հետևում է անվերահսկված NMT ճարտարապետությանը: Ագնահատված արդյունքները հայտարարվում են LoReMT 2020-ի ընդհանուր խնդրի ժամանակ, որտեղ հայտարարվում է, որ մեր համակարգը հասնում է 0.59-ի երկլեզու գնահատման թերագնահատման (ԲԼԵՎ) գնահատման, 3.43-ի ճշգրիտ գնահատման, 5.48-ի հիշողության գնահատման, 4.22-ի F-չափության գնահատման և 0.180047-ի դասարանի հիմնված երկլեզու գնահատման (RIBES) գնահ Հինդիայի և ռուսերենի թարգմանման համար մենք հասել ենք բլեուզ, ճշգրտություն, հիշեցում, F-չափով և RIBES-ի 1.11 գնահատականի,
4.72, 4.41, 4.56 և 0.02.6842:</abstract_hy>
      <abstract_az>NMT maşına çevirilməsi maşın çevirilməsi (MT) toplumunda geniş qəbul edilən tərzidir, təbiətli dildən başqa təbiətli dilə çevirir. NMT hər ikisinin yüksək və düşük ressurs dillərində möhtəşəm performansı göstərir, buna kifayət təhsil korpusu lazımdır. Bu məsələni azaltmaq üçün, NMT düşük ressurs dili çiftlərində paralel korpusun faydalanması MT'nin çətin işlərindəndir. Bu məsələni azaltmaq üçün, düşük ressurs dillərinin çift üçün daha yaxşısını tərcümə etmək üçün monodil korpusu istifadə etməyə çalışır. MT of Low Resource Languages (LoResMT 2020) üçün Təknolojilər haqqında çalışma işləri, 0-shot NMT vasitəsilə düşük ressurs dillərinin cüt çeviri ilə paylaşdırılmış işləri düzəltdi. Burada paralel korpus istifadə edilməz və yalnız monodil korpora izin verilir. Biz Rus-Hindi dil çiftərimizin adı CNLP-NITS ilə aynı paylaşılmış iş işə katıldıq. Biz dil dövrünün əvvəlcə təhsilini seçmək üçün maske sıralarını istifadə etdik. NMT arhitektarının ardınca yalnız monodil korpusu ilə. Müəyyən edilmiş sonuçlar LoResMT 2020 paylaşdırılmış görevlərdə təbliğ edilir. Sistemimizin 0.59 dil çəkilməsi dəyişdirilməsini təbliğ edir, 3.43 dəyişdirilməsini təbliğ edir, 5.48 dəyişdirilməsini xatırlayın, 4.22 dəyişdirilməsini F-ölçü dəyişdirilməsini və 0.180147 dəyişdirilməsi dəyişdirilməsi dəyişdirilməsini təbliğ edir. Hindistan ilə Rus çevirinə gəldikdə, biz BLEU, precision, recall, F-measure və RIBES dərəcəsini 1.11 qədər qəbul etdik.
4.72, 4.41, 4.56 və 0.026842.</abstract_az>
      <abstract_id>Terjemahan mesin saraf (NMT) adalah pendekatan yang diterima secara luas dalam komunitas terjemahan mesin (MT), terjemahan dari satu bahasa alami ke bahasa alami lainnya. Meskipun, NMT menunjukkan prestasi yang luar biasa dalam bahasa sumber daya tinggi dan rendah, itu membutuhkan corpus pelatihan yang cukup. Keadaan corpus paralel dalam pasangan bahasa sumber daya rendah adalah salah satu tugas tantangan dalam MT. Untuk mengurangi masalah ini, NMT mencoba untuk menggunakan corpus monobahasa untuk mendapatkan lebih baik dalam terjemahan untuk pasangan bahasa sumber daya rendah. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT.  Here, the parallel corpus is not used and only monolingual corpora is allowed.  Kami telah berpartisipasi dalam tugas yang sama dengan nama tim kami CNLP-NITS untuk pasangan bahasa Rusia-Hindi. Kami telah menggunakan urutan bertopeng untuk urutan pre-pelatihan untuk generasi bahasa (MASS) dengan hanya corpus monobahasa mengikuti arsitektur NMT yang tidak diawasi. Hasil yang diteliti dideklarasikan pada tugas berbagi LoResMT 2020, yang melaporkan bahwa sistem kita mencapai nilai evaluasi dua bahasa bawah studi (BLEU) 0,59, nilai presisi 3,43, nilai ingatan 5,48, nilai F-ukur 4,22, dan nilai evaluasi dua bahasa berdasarkan rangka (RIBES) 0,180147 dalam terjemahan Rusia ke Hindi. And for Hindi to Russian translation, we have achieved BLEU, precision, recall, F-measure, and RIBES score of 1.11,
4.72, 4.41, 4.56, dan 0.026842 respectively.</abstract_id>
      <abstract_tr>NMT maşynyň terjimesini maşynyň terjimesinde (MT) jemgyýetinde a ňsatly kabul edilen yaklaşyk, bir tebigy dilden beýleki dile terjime edilýär. NMT-iň ýokary we ýokary çeşme dilinde örän möhüm taýýarlanmagy görkezýär, ýöne köpüsi ýeterlik taýýarlanmagy gerek. Aýak ressurs çiftlerinde paralel korpusyň bar bar bolmagy MT'de gaty kyn zadyň biridir. Bu meseleni azatmak üçin, NMT düşük ressurs çiftleri üçin bir monolingüs korpusyny ulanmak üçin synanyşýar. MT of Low Resource Languages (LoResMT 2020) tehnologiýasynda ýakyn ressurs dili çift terjimelerinden paýlaşdy. Bu ýerde, parallel korpus ulanmaýar we diňe monodil korpora rugsat berilýär. Biz öz toparymyzyň adymyz CNLP-NITS üçin bir topara goşuldyk. Biz diller döretmäge öň-okuwçylygy (MASS) üçin diňe monodil korpus bilen NMT arhitegi täzeden soňra maskele terjimeleri ulandyk. Berilen netijeler LoResMT We Hindilere Rusça terjime etmek üçin, biz BLEU'a, dogrudylyk, ýatlamak, F-ölçüsi we RIBES 1.11 derejesini ýetdik.
4.72, 4.41, 4.56, we 0.026842 respectively.</abstract_tr>
      <abstract_bs>Neuralni prevod strojeva (NMT) je široko prihvaćen pristup u zajednici prevoda strojeva (MT), prevodeći se iz jednog prirodnog jezika na drugi prirodni jezik. Iako, NMT pokazuje izvanrednu učinku na visokim i niskim jezicima resursa, potreban je dovoljno korpusa za obuku. Dostupnost paralelnog korpusa u parovima niskih resursa je jedan od izazovnih zadataka u MT-u. Za smanjenje ovog pitanja, NMT pokušava iskoristiti monojezički korpus kako bi se poboljšao u prevodu za parove niskih resursa. Radionica o tehnologijama za MT jezika niskih resursa (LoResMT 2020) organizovala je zajednički zadatak prevoda par niskih resursa s nulom snimkom NMT. Ovdje, paralelni korpus se ne koristi i samo monojezička korpusa je dozvoljena. Učestvovali smo u istom zajedničkom zadatku sa imenom našeg tima CNLP-NITS za ruski-hindski parov. Koristili smo maskiranu sekvencu da bi sekvencirali predobuku za generaciju jezika (MASS) sa samo monojezičkim korpusom nakon neodređene arhitekture NMT-a. Procjenjivani rezultati su objavljeni na zajedničkom zadatku LoResMT 2020, koji prijavljuje da naš sistem postigne rezultat ispitivanja dvojezika (BLEU) od 0,59, precizni rezultat od 3,43, sjeti rezultat od 5,48, rezultat F-mjere od 4,22, i rezultat intuitivnih dvojezičkih procjena (RIBES) od 0,180147 na ruskom i hindskom prevodu. A za Hindi na ruski prevod, postigli smo BLEU, preciznost, sjećanje, F-mjera i RIBES rezultat od 1,11,
4,72, 4,41, 4,56 i 0,026842.</abstract_bs>
      <abstract_bn>নিউরেল মেশিন অনুবাদ (এনএমটি) মেশিন অনুবাদের (এমটি) সম্প্রদায়ের একটি ব্যাপকভাবে গ্রহণযোগ্য উপায়, যা একটি প্রাকৃতিক ভা যদিও এনএমটি উচ্চ এবং কম রিসোর্স ভাষায় চমৎকার কার্যক্রম দেখাচ্ছে, তবে তার প্রশিক্ষণের জন্য যথেষ্ট প্রশিক্ষণ দরকার। নিম্নলিখিত রিসোর্স জোড়ায় একটি প্যারালেল কোর্পাস প্রদান করা হচ্ছে এমটির একটি চ্যালেঞ্জার কাজ। এই বিষয়টি কমিয়ে দেওয়ার জন্য এনএমটি একটি মোনোলিভাল কোর্পাস ব্যবহার কর নিম্ন রিসোর্স ভাষার (লোরেসিএমটি ২০২০) নিম্ন রিসোর্স ভাষার জন্য প্রযুক্তির কার্যকর কর্মশালা শেয়ার করেছে এনএমটি ব্যবহার করে নিম্ন সম্পদ এখানে, প্যারালেল কোর্পাস ব্যবহার করা হয় না এবং শুধুমাত্র মোনোলিভাল কর্পোরা অনুমতি দেয়া হয়। আমরা রাশিয়ান-হিন্দি ভাষার জোড়ার জন্য আমাদের দলের নাম সিএনএলপি-এনআইটিসের সাথে একই কাজে অংশগ্রহণ করেছি। আমরা ভাষা প্রজন্মের পূর্ব প্রশিক্ষণের জন্য মুখোশের সেকেন্ড ব্যবহার করেছি যার ফলে শুধুমাত্র মোনোলিভাল কোর্পাস নির্ধারণ করা হয়েছে এনএম এই মূল্যবান ফলাফল লোরেসএমটি ২০২০ শেয়ার কর্মসূচীতে ঘোষণা করা হয়েছে, যেখানে রিপোর্ট করেছে যে আমাদের সিস্টেম ০. ৫৯ এর দুই ভাষার মূল্যের মূল্য অর্জন করেছে (বিলিউ) স্কোর অর্জন করেছে, ঠিক স্কোর ৩. আর রাশিয়ান অনুবাদের জন্য আমরা বিলু, সঠিক, স্মরণ করি, F-মাপ এবং রিবিসের স্কোর ১. ১১,
৪. 72, ৪. 41, ৪. 56 এবং ০. 026842.</abstract_bn>
      <abstract_cs>Neurální strojový překlad (NMT) je široce uznávaný přístup v komunitě strojového překladu (MT), který překládá z jednoho přirozeného jazyka do jiného přirozeného jazyka. Přestože NMT vykazuje pozoruhodný výkon v jazycích s vysokými i nízkými zdroji, potřebuje dostatečný školicí korpus. Dostupnost paralelního korpusu v jazykových párech s nízkými zdroji je jedním z náročných úkolů v MT. K zmírnění tohoto problému se NMT snaží využít monojazyčný korpus pro zlepšení překladu pro jazykové páry s nízkými zdroji. Workshop o technologiích pro MT nízkých zdrojů jazyků (LoResMT 2020) organizoval sdílené úkoly překladu jazykových párů s nízkými zdroji pomocí nulového NMT. Zde se nepoužívá paralelní korpus a povoleny jsou pouze jednojjazyčné korpusy. Podíleli jsme se na stejném společném úkolu s naším týmovým jménem CNLP-NITS pro rusko-hindský jazykový pár. Použili jsme maskovanou sekvenci k sekvenci předškolení pro generaci jazyků (MASS) s pouze jednojjazyčným korpusem podle architektury bez dozoru NMT. Vyhodnocené výsledky jsou deklarovány na sdíleném úkolu LoResMT 2020, který hlásí, že náš systém dosahuje dvojjazyčného hodnocení náhradníka (BLEU) 0.59, přesného hodnocení 3.43, stahovacího skóre 5.48, F-měřicího skóre 4.22 a hodnocení založeného na intuitivním dvojjazyčném hodnocení (RIBES) 0.180147 v ruštině do hindštiny. A pro překlad z hindštiny do ruštiny jsme dosáhli BLEU, přesnosti, odvolání, F-míry a RIBES skóre 1.11,
4.72, 4.41, 4.56 a 0.026842.</abstract_cs>
      <abstract_ca>La traducció de màquines neurals (NMT) és un enfocament generalment acceptat en la comunitat de traducció de màquines (MT), traducció d'un llenguatge natural a un altre llenguatge natural. Malgrat que la NMT mostra un rendiment notable en llengües de baix i alts recursos, necessita un corpus de formació suficient. La disponibilitat d'un corpus paral·lel en parells de llenguatges de baix recursos és una de les tasques desafiantes de MT. Per atenuar aquest problema, NMT intenta utilitzar un corpus monolingüe per millorar la traducció per parells de llenguatges de baix recursos. La taller sobre tecnologies per MT de llengües de baix recursos (LoResMT 2020) va organitzar tasques compartides de traducció de parells de llengües de baix recursos fent servir NMT de zero. Aquí no s'utilitza el cos paral·leli només es permet el corpore monolingüe. Hem participat en la mateixa tasca compartida amb el nostre equip CNLP-NITS per al parell ruso-hindí. Hem utilitzat seqüència mascarada per seqüenciar la pré-entrenament per la generació de llengües (MASS) amb només un cos monolingüe segons l'arquitectura NMT sense supervisió. Els resultats evaluats són declarats a la tasca compartida LoResMT 2020, que diu que el nostre sistema aconsegueix una puntuació bilingüe de 0,59, una puntuació de precisió de 3,43, una puntuació de recordació de 5,48, una puntuació F de 4,22 i una puntuació bilingüe intuïtiva basada en rangs (RIBES) de 0,180147 en traducció russa a Hindi. I per a la traducció hindí a russa, hem aconseguit una puntuació BLEU, precisió, recordació, F-mesura i RIBES de 1,11,
4,72, 4,41, 4,56 i 0,026842 respectivament.</abstract_ca>
      <abstract_sq>Neural machine translation (NMT) is a widely accepted approach in the machine translation (MT) community, translating from one natural language to another natural language.  Although, NMT shows remarkable performance in both high and low resource languages, it needs sufficient training corpus.  Për të lehtësuar këtë çështje, NMT përpiqet të përdorë një korpus monogjuhës për të përfituar më mirë në përkthimin e çështjeve të ulët të gjuhës. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organizoi detyra të përbashkëta të përkthimit të dy gjuhëve me burime të ulta duke përdorur NMT zero-shot. Këtu, korpusi paralel nuk përdoret dhe vetëm korpura monogjuhësore është lejuar. We have participated in the same shared task with our team name CNLP-NITS for the Russian-Hindi language pair.  Ne kemi përdorur sekuencë të maskuar për të sekuencuar parastërvitjen për gjenerimin e gjuhëve (MASS) me vetëm një korpus monogjuhës pas arkitekturës së NMT-së të pazgjidhur. Rezultatet e vlerësuara deklarohen në detyrën e përbashkët të LoResMT 2020, e cila raporton se sistemi ynë arrin pikën e nënstudimit dygjuhësor (BLEU) 0.59, pikën e saktësisë 3.43, pikën e kujtimit 5.48, pikën e F-masës 4.22 dhe pikën e vlerësimit dygjuhësor intuitiv (RIBES) 0.180147 në përkthimin rush-Hindi. Dhe për përkthimin Hindi në Rusi, ne kemi arritur BLEU, saktësi, kujtim, F-masë, dhe RIBES rezultat 1.11,
4.72, 4.41, 4.56 dhe 0.026842 respektivisht.</abstract_sq>
      <abstract_et>Neuraalne masintõlge (NMT) on laialdaselt tunnustatud lähenemisviis masintõlke (MT) kogukonnas, tõlkides ühest looduskeelest teise looduskeelde. Kuigi NMT näitab märkimisväärset tulemuslikkust nii suure kui ka vähese ressursiga keeltes, vajab see piisavalt koolituskorpust. Paralleelse korpuse kättesaadavus madala ressursiga keelepaarides on MT üks keerulisi ülesandeid. Selle probleemi leevendamiseks püüab NMT kasutada ühekeelset korpust, et tõlkida paremini vähese ressursiga keelepaaride puhul. Madala ressursiga keelte MT tehnoloogiate seminar (LoResMT 2020) korraldas madala ressursiga keelepaari tõlkimise jagatud ülesandeid, kasutades null-shot NMT-d. Siin ei kasutata paralleelkorpust ja lubatud on ainult ühekeelsed korpused. Oleme osalenud samas ühises ülesandes vene-hindi keele paari meeskonna nimega CNLP-NITS. Oleme kasutanud maskeeritud järjestust keele genereerimise eelkoolituse järjestamiseks (MASS) ainult ühekeelse korpusega, mis järgib järelevalveta NMT arhitektuuri. Hinnatud tulemused deklareeritakse LoResMT 2020 jagatud ülesandel, mis annab teada, et meie süsteem saavutab kakskeelse hindamise asendusuuringu (BLEU) skoori 0,59, täpsuskoori 3,43, tagasikutsumise skoori 5,48, F-meetme skoori 4,22 ja auastmepõhise intuitiivse kakskeelse hindamise skoori (RIBES) 0,180147 vene-hindi tõlkes. Hindi-vene tõlke puhul oleme saavutanud BLEU, täpsuse, tagasikutsumise, F-mõõdu ja RIBES skoori 1,11,
4, 72, 4, 41, 4, 56 ja 0, 026842.</abstract_et>
      <abstract_fi>Neuraalinen konekäännös (NMT) on yleisesti hyväksytty lähestymistapa konekäännösyhteisössä, joka kääntää yhdestä luonnollisesta kielestä toiselle luonnolliselle kielelle. Vaikka NMT osoittaa huomattavaa suorituskykyä sekä korkean että matalan resurssin kielillä, se tarvitsee riittävästi koulutusta. Rinnakkaisen korpusen saatavuus vähäresurssisissa kielipareissa on yksi haastavista tehtävistä MT:ssä. Ongelman lieventämiseksi NMT pyrkii hyödyntämään monikielistä korpusta, jotta se voisi paremmin kääntää vähäresurssisia kielipareja. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) järjesti jaettuja tehtäviä matalaresurssisen kieliparin kääntämisestä nollashotin NMT:n avulla. Täällä rinnakkaista korpusta ei käytetä ja vain yksikielisiä korpusia sallitaan. Olemme osallistuneet samaan yhteiseen tehtävään tiimimme nimellä CNLP-NITS venäjä-hindi kieliparille. Olemme käyttäneet masked sekvenssiä kielen generoinnin esikoulutukseen (MASS), jossa on vain yksikielinen korpus valvomattoman NMT-arkkitehtuurin mukaisesti. Arvioidut tulokset ilmoitetaan LoResMT 2020 -yhteisessä tehtävässä, jonka mukaan järjestelmämme saavuttaa kaksikielisen arvioinnin sijaiskokeen (BLEU) pisteen 0,59, tarkkuuskokeen 3,43, muistipisteen 5,48, F-mittapisteen 4,22 ja rankkipohjaisen intuitiivisen kaksikielisen arviointipisteen (RIBES) 0,180147 venäjäksi hindiin käännettäessä. Hindi venäjäksi käännöksessä olemme saavuttaneet BLEU:n, tarkkuuden, takaisinkutsun, F-mitta ja RIBES-pisteen 1,11,
4, 72, 4, 41, 4, 56 ja 0, 026842.</abstract_fi>
      <abstract_jv>Nyural kelendangan sistem (NMT) kang sampeyan kang gabung ing nggunakake karo komunitas Inggal (MT), terjamahan ning saben idisa anyar kanggo nganggo perusahaan bangsa anyar. Mangkin, NMT ngomong akeh operasi sing mengko awak dhéwé lan akeh langkung banjur, kudu berarti cara-cara ngono akeh podho. Rasané perusahaan karo akeh-perusahaan nganggo langgampun sing gak nggawe MT iki dadi kaé nggawe barang nggawe gerakan kanggo nggawe kesempatan iki, NMT iso nggawe nguasai perusahaan bangka sing paling dumadhi kanggo nyenggap oleh dumadhi kaya perusahaan langgampun. Workstop Punika, akeh akeh paramelu kuwi ora bisa nggambar sampeyan liyane Awak dhéwé wis ngubah barêng-barêng wong iki banget karo nganggo pangan sing nggawe "KLP-NITS" kanggo kelas barang rusak-barang. Awak dhéwé wis nggambar cara-cara sistem kanggo nguasai tanggal banter kanggo ngilangno urip (MASS) nganggo perusahaan lang sampeyan akeh dhéwé, akhire NMT gak dhéwé. Rejection Karo nganggo barang pang barang rusu, kita sampeyan panjenengan entuk blok, dadi, pangalan, terus-sampeyan, F-sampeyan lan RIBES liyane kotak 1.11,
4.75, 4.04, 4.06, lan 0.441</abstract_jv>
      <abstract_sk>Nevralno strojno prevajanje (NMT) je široko sprejet pristop v skupnosti strojnega prevajanja (MT), ki prevaja iz enega naravnega jezika v drugega naravnega jezika. Čeprav ima NMT izjemno uspešnost v jezikih z visokimi in nizkimi viri, potrebuje zadostno usposabljanje. Razpoložljivost vzporednega korpusa v jezikovnih parih z nizkimi viri je ena izmed zahtevnih nalog v MT. Da bi to težavo ublažili, NMT poskuša uporabiti enojezični korpus za boljše prevajanje za jezikovne pare z nizkimi viri. Delavnica o tehnologijah za MT nizkih virov jezikov (LoResMT 2020) je organizirala skupne naloge prevajanja nizkih virov jezikovnih parov z uporabo ničelne NMT. Tukaj se vzporedni korpus ne uporablja in dovoljeni so samo enojezični korpusi. Pri isti skupni nalogi smo sodelovali z imenom naše ekipe CNLP-NITS za rusko-hindijski jezikovni par. Za zaporedje predusposabljanja za generiranje jezikov (MASS) smo uporabili masked zaporedje z enojezičnim korpusom, ki sledi neizvajani arhitekturi NMT. Ocenjeni rezultati so prijavljeni na skupni nalogi LoResMT 2020, ki poroča, da naš sistem doseže rezultat dvojezičnega evalvacijskega nadomestka (BLEU) 0,59, natančnosti 3,43, rezultat odpoklica 5,48, rezultat F-merjenja 4,22 in intuitivne dvojezične ocene (RIBES) 0,180147 v prevodu ruščine v hindijščino. In za prevod hindijščine v ruščino smo dosegli BLEU, natančnost, odpoklic, F-merilo in RIBES oceno 1,11,
4, 72, 4, 41, 4, 56 oziroma 0, 026842.</abstract_sk>
      <abstract_fil>Ang pagsasalat ng neural machine (NMT) ay malaking tinatanggap na paraan sa pagsasalat ng makina (MT) na komunidad, na nagbabalat mula sa isang natural na wika sa ibang natural na wika. Bagaman ang NMT ay nagpapakita ng maraming gawain sa mataas at mababa na wika ng mga ressourse, kailangan nito ng sapat na pag-aaral ng corpus. Ang pag-gamit ng isang parallel na corpus sa ibang mga wikang masamang pag-aral ay is a sa mga mahirap na gawa sa MT. Upang magbabago ng problemang ito, pinagsisikapan ng NMT na gumagamit ng isang monolingual corpus upang magpakamagaling sa pagsuwi sa ibang mga wikang masamang pag-aral. Workshop on Technologies for MT of Low Resource Languages Dito, ang parallel corpus ay hindi ginagamit at ang monolingual corpora lamang ay tinatanggap. Nag-sama tayo sa gayon ding pagkakabahagi sa pangalan ng ating grupo CNLP-NITS para sa pare ng wikang Ruso-Hindi. Kami ay gumamit ng masked sequence para sa sequence pre-training para sa wikang generation (MASS) na may monolingual corpus lamang pagkatapos ng hindi-suportado na NMT architecture. Ang mga resulta na inanyuan ay ipinahayag sa LoResMT 2020 na binahagi, na nagtataglay na ang aming sistema ay nakatataglay ng biling evaluation understudy (BLEU) score ng 0.59, precision score ng 3.43, recall score ng 5.48, F-measure score ng 4.22, at rank-based intuitive bilingual evaluation score (RIBES) ng 0.180147 sa Russian to Hindi translation. At tungkol sa pagliliwanag ng Hindi sa Russian, nakatagumpay kami ng BLEU, precision, recall, F-measure, at RIBES score ng 1.11,
4.72, 4.41, 4.56, at 0.026842 respectively.</abstract_fil>
      <abstract_he>תורגם ע"י מכונות נוירות (NMT) הוא גישה מקובל רחב בקהילה של תורגם מכונות (MT), תורגם משפה טבעית אחת לשפה טבעית אחרת. למרות, NMT מראה ביצועים מדהימים בשפות משאבים גבוהות ומנמוכות, הוא זקוק לקורפוס אימון מספיק. ההזדמנות של קורפוס מקביל בזוגי שפת משאבים נמוכים היא אחת מהמשימות המתאגרות ב- MT. כדי להקל את הנושא הזה, NMT מנסה להשתמש בקורפוס monolingual כדי להשתפר בתרגום לזוגי שפת משאבים נמוכים. Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) ארגן משימות משותפות של זוג שפת משאבים נמוכות באמצעות NMT אפס-ירי. כאן, הקורפוס המקביל לא משתמש ורק הקורפורה מונושפתית מותר. השתתפנו באותה משימה משותפת עם שם הצוות שלנו CNLP-NITS לזוג שפת הרוסי-הינדי. השתמשנו ברצף מסוכן כדי לרצף האימונים הקדמיים לדור שפות (MASS) עם רק קופוס מונושפתי בעקבות ארכיטקטורת NMT ללא השגחה. התוצאות המערכות הוכרשות במשימה המשותפת LoResMT 2020, שבה מדווחים שהמערכת שלנו משיגה את נקודת הערכה השולשית (BLEU) של 0.59, נקודת מדויקה של 3.43, נקודת זיכרון של 5.48, נקודת F-מדידה של 4.22, נקודת הערכה השולשית האינטואיטיבית (RIBES) של 0.180147 בתרגום הרוסי-הינדי. ולהינדי לתרגום רוסי, השגנו BLEU, מדויק, זיכרון, F-מדידה, וציון RIBES של 1.11,
4.72, 4.41, 4.56, 0.026842 בהתאם.</abstract_he>
      <abstract_ha>translation Ingawa, NMT yana nũna wani aikin mai girma cikin lugha masu sarki da kuma masu ƙaranci, sai yana da amfani da matsayi mai isa. Tilayan wata parallel nau'i cikin nau'in ƙasan resource-par is one of the competitive tasks in MT. To mitaɗa wannan masu zartar, NMT yana jarraba su yi amfani da nau'in monoli-language to get mafi alhẽri at translation for lower resource parse. QUnicodeControlCharacterMenu A nan, ba za'a yi amfani da takardar rubutu ba kuma ana yarda komana guda kawai na sauri. Mun yi rabo da shi da sunan jama'a CNLP-NItS wa harshen Ruushi-Hindki. Mun yi amfani da baƙi don ya yi amfani da matsayin da aka yi wa mai amfani da shi gaba-wa wa'azi na harshe (MASS) da nau'in monolilulu kawai bayan an tsare shi na NMT. Ana bayyana fassaran da aka raba a LoResMT 2020 da aka raba wani aikin LoResMT, wanda ke bãyar da bayani da ya cika muhimmar aikin na biblican (BLEU) scori na 0.59, yana kasar naun tabbatarwa na 3.43, kuma yana ambaci score na 5.48, scori na F-balanci na 4.22, da score na rabo da matsayin biblical evaluation (RiBES) na 0.180147 a cikin Rusi zuwa fassarar Hidi. Kuma don fassarar Hindiya zuwa Ruushi, mun sami BLEU, na daidai, kuma tuna, F-metode da RiBES na nufi 1.11,
henyu 4,42, 4,41, 4,46 da 0,016842.</abstract_ha>
      <abstract_bo>ནུས་ཤུགས་མིན་འདུག NMT ཡིས་སྐད་རིགས་མཐོ་དང་མཐོ་པོ་གཉིས་ཀྱི་ནང་དུ་ལས་འཕར་རིམ་བཀྲམ་སྟོན་པ་ཡིན་ནའང་། དེ་ལས་སྦྱོར་མཐུད་དང་མཐུན MT ནང་དུ་མཐུན་རིམ་པ་ཞིག་གི་ཡིག་ཆ་ཉུང་བའི་མིང་དང་ཆ་ཁག་ཅིག་གི་ཐོག་ལས་གནད་དོན་དགོས་པ་ཞིག་ཡིན། Workshop on Technologies for MT of Low Resource Languages (LoResMT 2020) organized shared tasks of low resource language pair translation using zero-shot NMT. འདིར་སྔོན་གྱི་དབུས་པ་དེ་སྤྱོད་མི་ཐུབ་པ་ལས་སྐད་ཡིག་ཆ་གཅིག་གི་དབང་ཆ་ཁོ་ན་ཞིག་མེད། ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་མིང་CNLP-NITS་ནང་དུ་རྒྱ་ནག་གི་སྐད་རིགས་གཉིས་ཀྱི་བརྗོད་སྤྱོད་གཅིག་གི་ནང ང་ཚོས་སྐད Evaluated results are declared at the LoResMT 2020 shared task, which reports that our system achieves the bilingual evaluation understudy (BLEU) score of 0.59, precision score of 3.43, recall score of 5.48, F-measure score of 4.22, and rank-based intuitive bilingual evaluation score (RIBES) of 0.180147 in Russian to Hindi translation. ང་ཚོས་རྒྱ་ནག་ལ་རྒྱ་ནག་དང་། ཨིན་སྐར་ཡིན་ཐབས་ལམ་ལ་འགྲོ་བར་མཁན་དུ་ཡོད། དོན་དག་ཚད། F-мерུ ས་དང་། RIBES་གྲངས་སྒྲིག་ཚད་༡༡༡་
4.72, 4.41, 4.56 དང་། 0.026842 respectively.</abstract_bo>
      </paper>
    <paper id="6">
      <title>Unsupervised Approach for Zero-Shot Experiments : BhojpuriHindi and MagahiHindi@LoResMT 2020<fixed-case>B</fixed-case>hojpuri–<fixed-case>H</fixed-case>indi and <fixed-case>M</fixed-case>agahi–<fixed-case>H</fixed-case>indi@<fixed-case>L</fixed-case>o<fixed-case>R</fixed-case>es<fixed-case>MT</fixed-case> 2020</title>
      <author><first>Amit</first><last>Kumar</last></author>
      <author><first>Rajesh Kumar</first><last>Mundotiya</last></author>
      <author><first>Anil Kumar</first><last>Singh</last></author>
      <pages>43–46</pages>
      <abstract>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the BhojpuriHindi and MagahiHindi language pairs at LoResMT 2020 shared task. We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages. Task organizers provide the development and the test sets for evaluation and the monolingual data for training. Our <a href="https://en.wikipedia.org/wiki/Software_development_process">approach</a> is a hybrid approach of <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> and <a href="https://en.wikipedia.org/wiki/Translation_(biology)">back-translation</a>. Metrics used to evaluate the trained model are BLEU, RIBES, <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">Precision</a>, Recall and <a href="https://en.wikipedia.org/wiki/F-measure">F-measure</a>. Our approach gives relatively promising results, with a wide range, of 19.5, 13.71, 2.54, and 3.16 BLEU points for <a href="https://en.wikipedia.org/wiki/Bhojpuri_language">Bhojpuri</a> to <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, Magahi to Hindi, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> to Bhojpuri and <a href="https://en.wikipedia.org/wiki/Hindi">Hindi to Magahi language pairs</a>, respectively.</abstract>
      <url hash="63ed8bbc">2020.loresmt-1.6</url>
      <bibkey>kumar-etal-2020-unsupervised</bibkey>
    <title_ar>نهج غير خاضع للإشراف لتجارب إطلاق النار الصفري: بهوجبوري - هندي وماغاهي - هندي @ LoResMT 2020</title_ar>
      <title_fr>Approche non supervisée pour les expériences Zero Shot : Bhojpuri — Hindi et Magahi—Hindi @LoResMT 2020</title_fr>
      <title_pt>Abordagem não supervisionada para experimentos Zero-Shot: Bhojpuri–Hindi e Magahi–Hindi@LoResMT 2020</title_pt>
      <title_es>Enfoque no supervisado para experimentos de tiro cero: Bhojpuri—Hindi y Magahi—Hindi @LoResMT 2020</title_es>
      <title_ja>ゼロショット実験のための監督なしのアプローチ： Bhojpuri - HindiとMagahi - Hindi @ LoResMT 2020</title_ja>
      <title_zh>零射实验无监督法:Bhojpuri-HindiMagahi-Hindi@LoResMT 2020</title_zh>
      <title_hi>शून्य-शॉट प्रयोगों के लिए असुरक्षित दृष्टिकोण: भोजपुरी-हिंदी और मगही-Hindi@LoResMT 2020</title_hi>
      <title_ru>Неконтролируемый подход для экспериментов с нулевым выстрелом: Bhojpuri-Hindi и Magahi–Hindi@LoResMT 2020</title_ru>
      <title_ukr>Неконтрольований підхід для експериментів з нульовими знімками: Bhojpuri-Hindi та Magahi–Hindi@LoResMT 2020</title_ukr>
      <title_ga>Cur Chuige Gan Mhaoirseacht maidir le Turgnaimh Nialais: Bhojpuri–Hiondúis agus Magahi–Hindi@LoResMT 2020</title_ga>
      <title_ka>ბოჯპური-ჰინდი და მადაჰია Hindi@LoResMT 2020</title_ka>
      <title_hu>Felügyeletlen megközelítés Zero Shot kísérletekhez: Bhojpuri-Hindi és Magahi- Hindi@LoResMT  2020</title_hu>
      <title_el>Μη εποπτευμένη προσέγγιση για πειράματα μηδενικού πυροβολισμού: Bhojpuri-Hindi και Magahi- Hindi@LoResMT  2020</title_el>
      <title_it>Approccio non supervisionato per esperimenti a colpo zero: Bhojpuri-Hindi e Magahi- Hindi@LoResMT  2020</title_it>
      <title_isl>Unsupervised Approach for Zero-Shot Experiments: Bhojpuri-Hindi and Magahi- Hindi@LoResMT  2020</title_isl>
      <title_kk>Нөл түсірілген тәжірибелер үшін қолданбаған қатынау: Бojpuri-хинди және Магахи- Hindi@LoResMT 2020</title_kk>
      <title_lt>Neaprižiūrimas metodas nuliniams bandymams: Bhojpuri-Hindi ir Magahi- Hindi@LoResMT 2020 m.</title_lt>
      <title_ms>Pendekatan tanpa pengawasan untuk Eksperimen Zero-Shot: Bhojpuri-Hindi dan Magahi- Hindi@LoResMT 2020</title_ms>
      <title_mt>Unsupervised Approach for Zero-Shot Experiments: Bhojpuri-Hindi and Magahi- Hindi@LoResMT 2020</title_mt>
      <title_mn>Зөл-шүлгээний туршилтын төлөөлбөргүй ойлголт: Бojpuri-Хинди, Магахи Hindi@LoResMT 2020</title_mn>
      <title_no>Ikkje oppretta tilgang til null-skytte eksperimenter: Bhojpuri-Hindi og Magahi- Hindi@LoResMT 2020</title_no>
      <title_pl>Niekontrolowane podejście do eksperymentów zerowych: Bhojpuri-hindi i Magahi- Hindi@LoResMT  2020</title_pl>
      <title_ro>Abordare nesupravegheată pentru experimentele Zero-Shot: Bhojpuri-Hindi și Magahi- Hindi@LoResMT  2020</title_ro>
      <title_sr>Neodobren pristup eksperimentima iz nule pucnjave: Bhojpuri-Hindi i Magahi- Hindi@LoResMT 2020</title_sr>
      <title_so>Imtixaanka kooro-Shot: Bhojpuri-Hindi iyo Magahi- Hindi@LoResMT  2020</title_so>
      <title_sv>Icke övervakad strategi för Zero-Shot Experiment: Bhojpuri-Hindi och Magahi- Hindi@LoResMT  2020</title_sv>
      <title_mk>Ненадгледуван пристап за нуларни експерименти: Бујпури-Хинди и Магахи- Hindi@LoResMT  2020</title_mk>
      <title_si>සීරෝවෙඩි පරීක්ෂණාව සඳහා අපරික්ෂා වෙනුවෙන් අවස්ථාවක් නැහැ: බොජ්පුරි-හින්දි සහ මගාහි- Hindi@LoResMT 2020යි.</title_si>
      <title_ml>പൂര്‍ണ്ണഷോട്ട് പരീക്ഷണങ്ങള്‍ക്കായി നിരീക്ഷിക്കപ്പെടാത്ത വഴി: ഭോജ്പൂരി-ഹിന്ദി-മാഗഹി- Hindi@LoResMT  2020</title_ml>
      <title_ta>பூஜ்பூரி- சூட் சோதனைகளுக்கு கண்காணிக்கப்படவில்லை Hindi@LoResMT 2020</title_ta>
      <title_ur>صفر کی آزمائش کے لئے غیر قابل تقریبا ہے: بوجوجوپوری هندی اور مہائی۔ Hindi@LoResMT 2020</title_ur>
      <title_uz>Name Hindi@LoResMT 2020</title_uz>
      <title_vi>Không giám sát tiếp cận thử nghiệm Zero-Shot: Bojpur-Hindi và Magahe- Hindi@LoResMT 2020</title_vi>
      <title_da>Userved Approach for Zero-Shot Eksperimenter: Bhojpuri-Hindi og Magahi- Hindi@LoResMT  2020</title_da>
      <title_bg>Неконтролиран подход за експерименти с нулев изстрел: Бходжпури-хинди и Магахи- Hindi@LoResMT  2020</title_bg>
      <title_hr>Neodređen pristup eksperimentima iz nule pucnjave: Bhojpuri-Hindi i Magahi- Hindi@LoResMT 2020</title_hr>
      <title_nl>Onbewaakte aanpak voor Zero-Shot Experimenten: Bhojpuri-Hindi en Magahi- Hindi@LoResMT  2020</title_nl>
      <title_de>Unbeaufsichtigter Ansatz für Zero-Shot Experimente: Bhojpuri-Hindi und Magahi- Hindi@LoResMT  2020</title_de>
      <title_ko>제로 포 실험의 무감독 방법: Bhojpri Hindi와 Magahi-Hindi@LoResMT2020</title_ko>
      <title_sw>Utafiti usiothibitiwa kwa ajili ya jaribio la risasi zisizo na maana: Bhojpuri-Hindi na Magahi- Hindi@LoResMT 2020</title_sw>
      <title_tr>0-topar deneyleri üçin gözlenmedik Approach: Bhojpuri-Hindi we Magahi- Hindi@LoResMT 2020</title_tr>
      <title_af>Onondersoekte toegang vir Zero-Shot Experiments: Bhojpuri-Hindi en Magahi- Hindi@LoResMT 2020</title_af>
      <title_am>Unsupervised Approach for Zero-Shot Experiments: Bhojpuri-Hindi and Magahi- Hindi@LoResMT 2020</title_am>
      <title_sq>Përqasje e pazgjidhur për eksperimentet zero-Shot: Bhojpuri-Hindi dhe Magahi- Hindi@LoResMT  2020</title_sq>
      <title_id>Pendekatan Tidak Disupervisi untuk Eksperimen Zero-Shot: Bhojpuri-Hindi dan Magahi- Hindi@LoResMT 2020</title_id>
      <title_bn>জিরো-শুট পরীক্ষার জন্য অনলাইন পর্যবেক্ষণের পথ: ভোজপুরি-হিন্দি এবং মাগাহি- Hindi@LoResMT ২০২০</title_bn>
      <title_fa>نزدیک ناپذیر برای تجربه‌های صفر: بوجوپوری-هندی و ماگاهی Hindi@LoResMT 2020</title_fa>
      <title_hy>Unsupervised Approach for Zero-Shot Experiments: Bhojpuri-Hindi and Magahi- Hindi@LoResMT 2020</title_hy>
      <title_az>Sıfır-vuruş təcrübələri üçün müdafiə edilməmiş Yaxınlıq: Bhojpuri-Hindi və Magahi- Hindi@LoResMT 2020</title_az>
      <title_bs>Neodobren pristup eksperimentima nule pucnjave: Bhojpuri-Hindi i Magahi- Hindi@LoResMT 2020.</title_bs>
      <title_et>Järelevalveta lähenemisviis Zero-Shot eksperimentidele: Bhojpuri-Hindi ja Magahi- Hindi@LoResMT  2020</title_et>
      <title_cs>Nehlídaný přístup k nulovým experimentům: Bhojpuri-hindi a Magahi- Hindi@LoResMT  2020</title_cs>
      <title_fi>Valvontaton lähestymistapa nollalaukauksen kokeiluihin: Bhojpuri-Hindi ja Magahi- Hindi@LoResMT  2020</title_fi>
      <title_ca>Pròxim sense supervisió d'experiments de zero tirs: Bhojpuri-Hindi i Magahi- Hindi@LoResMT 2020</title_ca>
      <title_jv>Ngucap Aksesuk Gak Manyang paling nggo rerampungan 0-uwong: Bhojpur-endi lan Makahi- Hindi@LoResMT 2020</title_jv>
      <title_ha>Unvisited Approach for Zero-shot Experiments: Bhojpari-Hidi and Magahi- Hindi@LoResMT 2020</title_ha>
      <title_he>גישה ללא השגחה לניסויים של אפס יריות: בוג'יפורי-הינדי ומגאהי- Hindi@LoResMT 2020</title_he>
      <title_sk>Nenadzorovan pristop za eksperimente z ničelnim strelom: Bhojpuri-Hindi in Magahi- Hindi@LoResMT  2020</title_sk>
      <title_bo>Zero-Shot བརྟག་ཞིབ་ལ་སྔོན་སྒྲིག་མེད་པའི་གྲྭར་ཞུགས་བྱ་ཚུལ། བོ་ཇོ་puri-རྒྱ་ནག་དང་ མ་ཤི་ཡི། Hindi@LoResMT 2020</title_bo>
      <title_fil>Hindi pinagtibay ang paglapit sa mga pagsubok ng Zero-Shot: Bhojpuri-Hindi at Magahi- Hindi@LoResMT 2020</title_fil>
      <abstract_ar>تشير هذه الورقة إلى نظام الترجمة الآلية (MT) الذي قدمه فريق NLPRL لأزواج اللغة البهوجبرية - الهندية والماغاهي - الهندية في مهمة LoResMT 2020 المشتركة. استخدمنا نهجًا غير خاضع للإشراف للتكيف مع المجال يعطي نتائج واعدة للغات صفر أو لغات منخفضة الموارد للغاية. يوفر منظمو المهام التطوير ومجموعات الاختبار للتقييم والبيانات أحادية اللغة للتدريب. نهجنا هو نهج هجين لتكييف المجال والترجمة العكسية. المقاييس المستخدمة لتقييم النموذج المدرب هي BLEU و RIBES و Precision و Recall و F. يعطي نهجنا نتائج واعدة نسبيًا ، مع نطاق واسع ، من 19.5 ، و 13.71 ، و 2.54 ، و 3.16 نقطة BLEU لـ Bhojpuri إلى الهندية ، و Magahi إلى الهندية ، والهندية إلى Bhojpuri ، والهندية إلى أزواج Magahi ، على التوالي.</abstract_ar>
      <abstract_es>Este documento informa sobre un sistema de traducción automática (MT) presentado por el equipo de la NLPRL para las parejas de idiomas Bhojpuri—hindi y magahi—hindi en la tarea compartida LoreSMT 2020. Utilizamos un enfoque de adaptación de dominio no supervisado que ofrece resultados prometedores para lenguajes de recursos cero o extremadamente bajos. Los organizadores de tareas proporcionan el desarrollo y los conjuntos de pruebas para la evaluación y los datos monolingües para la capacitación. Nuestro enfoque es un enfoque híbrido de adaptación de dominios y retrotraducción. Las métricas utilizadas para evaluar el modelo entrenado son BLEU, RIBES, Precision, Recall y F-measure. Nuestro enfoque ofrece resultados relativamente prometedores, con una amplia gama de 19,5, 13,71, 2,54 y 3,16 puntos BLEU para los pares de idiomas bhojpuri a hindi, magahi a hindi, hindi a bhojpuri e hindi a magahi, respectivamente.</abstract_es>
      <abstract_pt>Este artigo relata um sistema de tradução automática (MT) enviado pela equipe da NLPRL para os pares de idiomas Bhojpuri–Hindi e Magahi–Hindi na tarefa compartilhada LoResMT 2020. Usamos uma abordagem de adaptação de domínio não supervisionada que fornece resultados promissores para linguagens com recursos zero ou extremamente baixos. Os organizadores de tarefas fornecem o desenvolvimento e os conjuntos de teste para avaliação e os dados monolíngues para treinamento. Nossa abordagem é uma abordagem híbrida de adaptação de domínio e tradução reversa. As métricas usadas para avaliar o modelo treinado são BLEU, RIBES, Precision, Recall e F-measure. Nossa abordagem fornece resultados relativamente promissores, com uma ampla faixa de 19,5, 13,71, 2,54 e 3,16 pontos BLEU para pares de idiomas Bhojpuri para Hindi, Magahi para Hindi, Hindi para Bhojpuri e Hindi para Magahi, respectivamente.</abstract_pt>
      <abstract_fr>Cet article présente un système de traduction automatique (TA) soumis par l'équipe NLPRL pour les paires de langues bhojpuri—hindi et magahi—hindi lors de la tâche partagée LoresMT 2020. Nous avons utilisé une approche d'adaptation de domaine non supervisée qui donne des résultats prometteurs pour les langues à ressources nulles ou extrêmement faibles. Les organisateurs de tâches fournissent le développement et les ensembles de tests pour l'évaluation et les données unilingues pour la formation. Notre approche est une approche hybride d'adaptation de domaine et de rétro-traduction. Les mesures utilisées pour évaluer le modèle formé sont BLEU, RIBES, Precision, Recall et F-measure. Notre approche donne des résultats relativement prometteurs, avec un large éventail de 19,5, 13,71, 2,54 et 3,16 points UEBL pour les paires de langues Bhojpuri à l'hindi, Magahi à Hindi, Hindi à Bhojpuri et Hindi à Magahi, respectivement.</abstract_fr>
      <abstract_zh>本文奏NLPRL团队在LoResMT 2020共享为Bhojpuri-Hindi与Magahi-Hindi言语交机器翻译(MT)系统。 吾用无监之域,当为零极低资源言有冀也。 任组织者供估发、试集及训练单语数。 吾法者,领地应反译之混合也。 以料练模之指标,BLEU、RIBES、精度、召率、F 量。 吾道与之相望,广为19.5,13.71为2.54与3.16 BLEU分,为Bhojpuri至印地语,Magahi至印地语,印地语至Bhojpuri印地语至Magahi言。</abstract_zh>
      <abstract_ja>本稿では、LoResMT 2020のBhojpuri - HindiとMagahi - Hindiの言語ペアの共有タスクのためにNLPRLチームが提出した機械翻訳（ MT ）システムについて報告する。私たちは、ゼロまたは極めてリソースの少ない言語で有望な結果をもたらす、監督されていないドメイン適応アプローチを使用しました。タスクオーガナイザーは、評価のための開発とテストセット、およびトレーニングのための単一言語データを提供します。私たちのアプローチは、ドメイン適応と逆翻訳のハイブリッドアプローチです。訓練されたモデルを評価するために使用される指標は、BLEU、RIBES、Precision、Recall、およびF - measureです。私たちのアプローチは、ボジュプル語からヒンディー語、マガヒ語からヒンディー語、ヒンディー語からボジュプル語、ヒンディー語からマガヒ語のペアについて、それぞれ19.5、13.71、2.54、3.16のブルーポイントの幅広い範囲で、比較的有望な結果をもたらします。</abstract_ja>
      <abstract_hi>यह पेपर LoResMT 2020 साझा कार्य में भोजपुरी-हिंदी और मगही-हिंदी भाषा जोड़े के लिए एनएलपीआरएल टीम द्वारा प्रस्तुत एक मशीन अनुवाद (एमटी) प्रणाली की रिपोर्ट करता है। हमने एक असुरक्षित डोमेन अनुकूलन दृष्टिकोण का उपयोग किया जो शून्य या बेहद कम संसाधन भाषाओं के लिए आशाजनक परिणाम देता है। कार्य आयोजकों विकास और मूल्यांकन के लिए परीक्षण सेट और प्रशिक्षण के लिए monolingual डेटा प्रदान करते हैं। हमारा दृष्टिकोण डोमेन अनुकूलन और बैक-अनुवाद का एक संकर दृष्टिकोण है। प्रशिक्षित मॉडल का मूल्यांकन करने के लिए उपयोग किए जाने वाले मीट्रिक BLEU, RIBES, परिशुद्धता, रिकॉल और F-माप हैं। हमारा दृष्टिकोण अपेक्षाकृत आशाजनक परिणाम देता है, जिसमें क्रमशः 19.5, 13.71, 2.54, और 3.16 BLEU अंक भोजपुरी से हिंदी, हिंदी से भोजपुरी और हिंदी से मगही भाषा के जोड़े के लिए 19.5, 13.71, 2.54, और 3.16 BLEU अंकों की एक विस्तृत श्रृंखला के साथ, क्रमशः हिंदी से हिंदी, मगही को हिंदी और हिंदी को मगही भाषा जोड़े।</abstract_hi>
      <abstract_ru>В этой статье сообщается о системе машинного перевода (MT), представленной командой NLPRL для языковых пар Бходжпури-Хинди и Магахи-Хинди на совместном задании LoResMT 2020. Мы использовали неконтролируемый подход к адаптации домена, который дает многообещающие результаты для нулевых или крайне низких языков ресурсов. Организаторы заданий обеспечивают разработку и тестовые наборы для оценки и одноязычные данные для обучения. Наш подход - это гибридный подход к адаптации домена и обратному переводу. Метриками, используемыми для оценки обученной модели, являются BLEU, RIBES, Precision, Recall и F-measure. Наш подход дает относительно многообещающие результаты, с широким диапазоном, 19,5, 13,71, 2,54 и 3,16 баллов БЛЮ для языковых пар Бходжпури - Хинди, Магахи - Хинди, Хинди - Бходжпури и Хинди - Магахи, соответственно.</abstract_ru>
      <abstract_ukr>Ця робота повідомляє про систему машинного перекладу (МП), подану командою NLPRL для мовних пар Бходжпурі-Хінді та Магахі-Хінді на спільному завданні LoResMT 2020. Ми використовували неконтрольований підхід до адаптації домену, який дає перспективні результати для нульових або надзвичайно низьких ресурсів мов. Організатори завдань забезпечують розробку та тестові набори для оцінки та одномовні дані для навчання. Наш підхід - це гібридний підхід до адаптації домену та зворотного перекладу. Метриками, що використовуються для оцінки навченої моделі, Є Bleu, RIBES, Precision, Recall та F-мір. Наш підхід дає відносно перспективні результати, з широким діапазоном, 19,5, 13,71, 2,54 та 3,16 балів БЛЮ для мовних пар Бходжпурі - гінді, Магахі - хінді, Хінді - Бходжпурі та Хінді - Магахі відповідно.</abstract_ukr>
      <abstract_ga>Tuairiscíonn an páipéar seo córas Aistriúcháin Meaisín (MT) a chuir foireann NLPRL isteach le haghaidh na bpéirí teanga Bhojpuri-Hiondúis agus Magahi-Hiondúis ag LoResMT 2020. D’úsáideamar cur chuige oiriúnaithe fearainn gan mhaoirseacht a thugann torthaí dóchais do theangacha nialasacha nó fíor-íseal acmhainní. Soláthraíonn eagraithe tasc an fhorbairt agus na tacair tástála don mheastóireacht agus na sonraí aonteangacha le haghaidh oiliúna. Is cur chuige hibrideach é ár gcur chuige maidir le hoiriúnú fearainn agus cúl-aistriúchán. Is iad na méadrachtaí a úsáidtear chun an tsamhail oilte a mheas ná BLEU, RIBES, Beachtas, Athghairm agus F-tomhais. Tugann ár gcur chuige torthaí réasúnta gealladh, le raon leathan, de 19.5, 13.71, 2.54, agus 3.16 pointe BLEU do Bhojpuri go Hindi, Magahi go Hindi, Hiondúis go Bhojpuri agus Hiondúis go péirí teangacha Magahi, faoi seach.</abstract_ga>
      <abstract_hu>Ez a tanulmány az NLPRL csapata által benyújtott Gépi Fordítás (MT) rendszerről számol be a bhojpuri-hindi és magahi-hindi nyelvpárokra a LoResMT 2020 megosztott feladaton. Felügyelet nélküli domain adaptációs megközelítést alkalmaztunk, amely ígéretes eredményeket biztosít a nulla vagy rendkívül alacsony erőforrású nyelvek esetében. A feladatszervezők biztosítják az értékeléshez szükséges fejlesztési és tesztkészleteket, valamint a képzéshez szükséges egynyelvű adatokat. Megközelítésünk a domain adaptáció és a visszafordítás hibrid megközelítése. A képzett modell értékeléséhez használt mércék a BLEU, RIBES, Precision, Recall és F-measure. Megközelítésünk viszonylag ígéretes eredményeket ad, széles skálával 19,5, 13,71, 2,54 és 3,16 BLEU pontok Bhojpuri Hindi, Magahi Hindi Bhojpuri, Hindi Bhojpuri és Hindi Magahi nyelvpárok esetében.</abstract_hu>
      <abstract_el>Η παρούσα εργασία αναφέρει ένα σύστημα μηχανικής μετάφρασης (ΜΤ) που υποβλήθηκε από την ομάδα για τα γλωσσικά ζεύγη Bhojpuri-Hindi και Magahi-Hindi στο LoResMT 2020. Χρησιμοποιήσαμε μια προσέγγιση προσαρμογής χωρίς επίβλεψη που δίνει ελπιδοφόρα αποτελέσματα για γλώσσες μηδέν ή εξαιρετικά χαμηλών πόρων. Οι διοργανωτές εργασιών παρέχουν την ανάπτυξη και τα σετ δοκιμών για αξιολόγηση και τα μονογλωσσικά δεδομένα για την κατάρτιση. Η προσέγγισή μας είναι μια υβριδική προσέγγιση προσαρμογής τομέων και αντίστροφης μετάφρασης. Τα μέτρα που χρησιμοποιούνται για την αξιολόγηση του εκπαιδευμένου μοντέλου είναι BLEU, RIBES, Precision, Recall και F-Measure. Η προσέγγισή μας δίνει σχετικά ελπιδοφόρα αποτελέσματα, με ένα ευρύ φάσμα σημείων 19.5, 13.71, 2.54 και 3.16 για ζεύγη γλωσσών Bhojpuri προς Hindi, Magahi προς Hindi, Hindi προς Bhojpuri και Hindi προς Magahi αντίστοιχα.</abstract_el>
      <abstract_it>Questo articolo riporta un sistema di traduzione automatica (MT) presentato dal team NLPRL per le coppie linguistiche Bhojpuri-Hindi e Magahi-Hindi al compito condiviso LoResMT 2020. Abbiamo utilizzato un approccio di adattamento del dominio non supervisionato che dà risultati promettenti per linguaggi a risorse zero o estremamente basse. Gli organizzatori delle attività forniscono lo sviluppo e i set di test per la valutazione e i dati monolingue per la formazione. Il nostro approccio è un approccio ibrido di adattamento del dominio e back-translation. Le metriche utilizzate per valutare il modello addestrato sono BLEU, RIBES, Precisione, Recall e F-measure. Il nostro approccio dà risultati relativamente promettenti, con una vasta gamma, di 19,5, 13,71, 2,54 e 3,16 punti BLEU per le coppie linguistiche da Bhojpuri a Hindi, da Magahi a Hindi, da Hindi a Bhojpuri e da Hindi a Magahi.</abstract_it>
      <abstract_lt>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the Bhojpuri-Hindi and Magahi-Hindi language pairs at LoResMT 2020 shared task.  We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Užduočių organizatoriai pateikia vertinimo ir bandymų rinkinius bei mokymo vienkalbius duomenis. Our approach is a hybrid approach of domain adaptation and back-translation.  Metrics used to evaluate the trained model are BLEU, RIBES, Precision, Recall and F-measure.  Our approach gives relatively promising results, with a wide range, of 19.5, 13.71, 2.54, and 3.16 BLEU points for Bhojpuri to Hindi, Magahi to Hindi, Hindi to Bhojpuri and Hindi to Magahi language pairs, respectively.</abstract_lt>
      <abstract_isl>Í þessu pappíri er greint frá vélþýðingarkerfi (MT) sem NLPRL-liðið hefur lagt fram fyrir Bhojpuri-Hindi og Magahi-Hindi tungumál par í LoResMT 2020 sameiginlegt verkefni. Viđ notuđum ķeftirfylgjandi ađlögun á svæđi sem gefur loforđandi niđurstöđur fyrir núll eđa mjög lítiđ málefni tungumál. Task organizers provide the development and the test sets for evaluation and the monolingual data for training.  Our approach is a hybrid approach of domain adaptation and back-translation.  Metrics used to evaluate the trained model are BLEU, RIBES, Precision, Recall and F-measure.  Our approach gives relatively promising results, with a wide range, of 19.5, 13.71, 2.54, and 3.16 BLEU points for Bhojpuri to Hindi, Magahi to Hindi, Hindi to Bhojpuri and Hindi to Magahi language pairs, respectively.</abstract_isl>
      <abstract_kk>Бұл қағаз Бojpuri-Hindi және Magahi-Hindi тілінің LoResMT 2020 жалпы тапсырмасында NLPRL тобының жұмысының машина аудару (MT) жүйесін хабарлады. Біз домен адаптациясын қолдандық, бұл нәтижесі нәтижелерді нәтижелерді нәтижелерді нәтижелерді нәтижелерді нәтижелерді нәтижелерді нә Тапсырмалар бақылаушылары оқу және бірнеше тілді деректерді бақылау үшін жасау және сынақ баптауларын береді. Біздің тәсіліміміз домен адаптациясының және қайта аудармасының гибридтік тәсілі. Оқылған үлгісін бағалау үшін қолданылатын метрикалар - BLEU, RIBES, дұрыс, қайталау және F- өлшемі. Біздің тәсіліміміз 19,5, 13,71, 2,54 және 3,16 БлоП нәтижелерін бұджпуриге хинди, магахи хинди, буджпуриге және хинди тілдерге магахи тілдерге салыстырып береді.</abstract_kk>
      <abstract_mk>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the Bhojpuri-Hindi and Magahi-Hindi language pairs at LoResMT 2020 shared task.  We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Task organizers provide the development and the test sets for evaluation and the monolingual data for training.  Our approach is a hybrid approach of domain adaptation and back-translation.  Metrics used to evaluate the trained model are BLEU, RIBES, Precision, Recall and F-measure.  Нашиот пристап дава релативно ветувачки резултати, со широк опсег, од 19,5, 13,71, 2,54 и 3,16 БЛЕ поени за Бујпури до Хинди, Магахи до Хинди, Хинди до Бујпури и Хинди до парови на јазик Магахи, односно.</abstract_mk>
      <abstract_mt>Dan id-dokument jirrapporta sistema ta’ Traduzzjoni tal-Magni (MT) ippreżentata mit-tim NLPRL għall-pari lingwistiċi Bhojpuri-Hindi u Magahi-Hindi fil-kompitu kondiviż LoResMT 2020. We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Task organizers provide the development and the test sets for evaluation and the monolingual data for training.  Our approach is a hybrid approach of domain adaptation and back-translation.  Il-metriċi użati biex jiġi evalwat il-mudell imħarreġ huma BLEU, RIBES, Preċiżjoni, Riċessjoni u Miżura F. L-approċċ tagħna jagħti riżultati relattivament promettenti, b’firxa wiesgħa, ta’ 19.5, 13.71, 2.54, u 3.16 punti BLEU għal Bhojpuri għal Hindi, Magahi għal Hindi, Hindi għal Bhojpuri u Hindi għal pari tal-lingwa Magahi, rispettivament.</abstract_mt>
      <abstract_mn>Энэ цаас ЛоресMT 2020 оны Хятад хэлний хэлний хоёр болон Магахи-Хинди хэлний NLPRL багийнхаа дамжуулагдсан машины хөрөнгө (MT) системийг мэддэг. Бид 0 эсвэл маш бага боловсролын хэл дээр амлалтай үр дүнг өгдөг хүрээлэн буй хүрээлэн буй хүрээлэн буй хүрээлэн буй загварыг ашигласан. Тапсыг зохион байгуулагчид үнэлгээ болон сургалтын нэг хэл өгөгдлийг хөгжүүлэх, шалгалтын багцлагыг хангадаг. Бидний ойлголт бол холбоотой адилтгал болон буцаад орчуулалтын гибрид арга зам юм. Сургуулсан загварыг үнэлэхэд хэрэглэгддэг метрик нь BLEU, RIBES, Шагнал, Дургуул, F-хэмжээтэй. Бидний ойлголт нь 19.5, 13.71, 2.54 бөгөөд 3.16 БОХП цэгүүдийг Хинди, Магахи, Хинди, БОХПури, Хинди, Магахи хэлний хооронд харьцангуй амлалтай үр дүнг өгдөг.</abstract_mn>
      <abstract_ml>ഈ പത്രത്തില്‍ ലോറെസ്എംടി 2020 ല്‍ പങ്കുചേര്‍ത്ത ജോലിയിലെ NLPRL ടീമില്‍ നിന്നും ബോജ്പൂരി- ഹിന്ദിയില്‍ നിന്നും മാഗഹി- ഹിന്ദിയിലെ ഭാഷ ജോ സൂക്ഷിക്കപ്പെടാത്ത ഡൊമെന്‍ അഡാപ്റ്റേഷന്‍ നടപടികള്‍ ഞങ്ങള്‍ ഉപയോഗിച്ചു. അത് പൂജ്യം അല്ലെങ്കില്‍ വളരെ കുറഞ്ഞ വിഭവഭാ ജോലി സംഘടനക്കാര്‍ പരിശോധനത്തിനും പരീക്ഷണത്തിന്റെ സജ്ജീകരണങ്ങളും പരിശോധനത്തിന്റെ വിവരങ്ങളും പരിശോധനത്തി നമ്മുടെ അടുത്തേക്ക് ഒരു ഹൈബ്രിഡ് വഴിയാണ് ഡോമെന്‍ അഡാപ്റ്റേഷന്‍ ചെയ്യുന്നതും പിന്നില്‍ പരിഭാ പരിശീലന മോഡലിനെ വിലാസപ്പെടുത്താന്‍ ഉപയോഗിക്കുന്ന മെറ്റിക്കുകള്‍ ബിലൂ, റിബെസ്, പ്രിസിസിഷന്‍, റെക്കല്‍ റെക്കല നമ്മുടെ അടുത്തുനിന്നുള്ള പ്രത്യേക ഫലങ്ങള്‍ കൊടുക്കുന്നു. 19.5, 13.71, 2.54, 3.16 ബിലിയു പോയിന്റുകള്‍ ഭോജ്പൂരിയിലേക്ക് വേണ്ടി ഹിന്ദി, ഹിന്ദിയിലേക്ക് ഭോജ്പൂരിയിലേക്</abstract_ml>
      <abstract_pl>W niniejszym artykule przedstawiono system tłumaczenia maszynowego (MT) przesłany przez zespół NLPRL dla par językowych Bhojpuri-Hindi i Magahi-Hindi w ramach wspólnego zadania LoResMT 2020. Zastosowaliśmy bez nadzoru podejście do adaptacji domen, które daje obiecujące rezultaty dla języków zerowych lub bardzo niskich zasobów. Organizatorzy zadań zapewniają opracowywanie i zestawy testów do oceny oraz dane jednojęzyczne do szkolenia. Nasze podejście to hybrydowe podejście adaptacji domen i backtranslacji. Metryki używane do oceny przeszkolonego modelu to BLEU, RIBES, Precision, Recall i F-miary. Nasze podejście daje stosunkowo obiecujące rezultaty, z szerokim zakresem punktów 19.5, 13.71, 2.54 i 3.16 BLEU dla par językowych Bhojpuri do Hindi, Magahi do Hindi, Hindi do Bhojpuri i Hindi do Magahi.</abstract_pl>
      <abstract_ro>Această lucrare raportează un sistem de traducere automată (MT) depus de echipa NLPRL pentru perechile de limbi Bhojpuri-Hindi și Magahi-Hindi la sarcina partajată LoResMT 2020. Am folosit o abordare nesupravegheată a adaptării domeniului care oferă rezultate promițătoare pentru limbi cu resurse zero sau extrem de scăzute. Organizatorii de sarcini furnizează seturile de dezvoltare și testare pentru evaluare și datele monolingve pentru formare. Abordarea noastră este o abordare hibridă a adaptării domeniului și a traducerii înapoi. Metricile utilizate pentru evaluarea modelului instruit sunt BLEU, RIBES, Precision, Recall și F-measure. Abordarea noastră oferă rezultate relativ promițătoare, cu o gamă largă de 19,5, 13,71, 2,54 și 3,16 puncte BLEU pentru perechile de limbi Bhojpuri la Hindi, Magahi la Hindi, Hindi la Bhojpuri și, respectiv, Hindi la Magahi.</abstract_ro>
      <abstract_sr>Ovaj papir prijavljuje sistem za prevod mašine (MT) podignut tim NLPRL za parove Bhojpuri-Hindi i Magahi-Hindi na delnom zadatku LoResMT 2020. Koristili smo neodređeni pristup adaptaciji domena koji daje obećavajuće rezultate za jezike nule ili izuzetno niske resurse. Organizatori zadataka pružaju razvoj i testove za procjenu i monojezičke podatke za obuku. Naš pristup je hibridni pristup adaptacije domena i prevode nazad. Metrike koje se koriste za procjenu obučenog modela su BLEU, RIBES, preciznost, sjećanje i mjera F. Naš pristup daje relativno obećavajuće rezultate, sa širom rasponom od 19,5, 13,71, 2,54 i 3,16 BLEU bodova za Bhojpuri na hindi, Magahi na hindi, Hindi na Bhojpuri i Hindi na Magahi jezičke parove.</abstract_sr>
      <abstract_ms>Kertas ini melaporkan sistem Terjemahan Mesin (MT) yang dihantar oleh pasukan NLPRL untuk pasangan bahasa Bhojpuri-Hindi dan Magahi-Hindi pada tugas kongsi LoResMT 2020. We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Pengurus tugas menyediakan pembangunan dan set ujian untuk penilaian dan data monobahasa untuk latihan. Our approach is a hybrid approach of domain adaptation and back-translation.  Metrik yang digunakan untuk menilai model terlatih adalah BLEU, RIBES, Precision, Recall dan F-measure. Our approach gives relatively promising results, with a wide range, of 19.5, 13.71, 2.54, and 3.16 BLEU points for Bhojpuri to Hindi, Magahi to Hindi, Hindi to Bhojpuri and Hindi to Magahi language pairs, respectively.</abstract_ms>
      <abstract_si>මේ පැත්තේ මැෂින් භාෂාව (MT) පද්ධතියක් වාර්තා කරනවා බෝජුපුරි-හින්දී සහ මගාහී-හින්දි භාෂාව භාෂාවක් ජෝඩාව ලෝ අපි ප්‍රශ්නයක් නැති ඩෝමින් සැකසුම් විධානයක් පාවිච්චි කරලා තියෙනවා, ඒකෙන් සුන්ධ නැති නැ කාර්ය සංයෝජකයෝ විකාශය සහ පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ප්‍රේෂණය සඳහා එක භා අපේ ප්‍රවේශනය තමයි ප්‍රවේශනය සහ පස්සේ අනුවාදනයේ හිබ්‍රිඩ් ප්‍රවේශනයක්. ප්‍රධානය කරලා තියෙන මෝඩල් අවශ්‍යය කරන්න ප්‍රයෝජනය විශ්වාස කරන්න ප්‍රයෝජනය බ්ලූස්, රිබෙස්, ප්‍රධා අපේ ප්‍රවේශනය සාමාන්‍යයෙන්ම ප්‍රතිචාර ප්‍රතිචාරයක් දෙනවා, 19.5, 13.71, 2.54, සහ 3.16 BLUE ප්‍රතිචාරයක් තියෙනවා බෝජුපුරිට හින්දි, මාගාහිට හින්දි, බෝජුප</abstract_si>
      <abstract_so>Kanu warqaddan wuxuu wargeliyaa nidaamka wax turjuma (MT) ee kooxda NLPRL u soo dhiibay Bhojpuri-Hindi iyo Magahi-Hindi labada nooc oo ah LoResMT 2020. Waxaannu isticmaalnay qaab bedelka deegaanka oo aan la ilaalinayn, taas oo suurtagal u leh luuqadaha nooca ah ama aad u yaraan luqadaha rasmiga. Waxqabadka shaqadu waxay qabanqaabiyaan horumarinta iyo bandhigyada imtixaanka ee lagu qiimeeyo iyo macluumaadka waxbarashada afka hooyo. Dhaqdhaqaalkayagu waa habka isbedelka deegaanka iyo turjumidda dib loo dhigo. Tusaalada tababarka lagu qiimeeyo waa BLEU, RIBES, Sirix, Recall iyo F. Dhaqdhaqaalkayagu wuxuu si qarsoodi ah u helaa resultooyin ballaadhan oo ah 19.5, 13.71, 2.54, iyo 3.16 BLEU barta Bhojpuri ilaa Hindi, Magahi ilaa Hindi, Hindi iyo Bhojpuri iyo Hindi waxay u jeedaan labada luqadood oo Magahi ah.</abstract_so>
      <abstract_sv>Denna uppsats rapporterar ett maskin철vers채ttningssystem (MT) som l채mnats in av NLPRL-teamet f철r spr책kparen Bhojpuri-hindi och Magahi-hindi vid LoResMT 2020 delade uppgift. Vi anv채nde en o철vervakad dom채nanpassning som ger lovande resultat f철r noll- eller extremt l책ga resursspr책k. Arbetsorganisat철rerna tillhandah책ller utvecklings- och testupps채ttningar f철r utv채rdering och enspr책kiga data f철r utbildning. V책rt tillv채gag책ngss채tt 채r en hybrid ansats av dom채nanpassning och back철vers채ttning. Metrik som anv채nds f철r att utv채rdera den utbildade modellen 채r BLEU, RIBES, Precision, Recall och F-measure. V책rt tillv채gag책ngss채tt ger relativt lovande resultat, med ett brett utbud av 19,5, 13,71, 2,54 och 3,16 BLEU-po채ng f철r Bhojpuri till Hindi, Magahi till Hindi, Hindi till Bhojpuri respektive Hindi till Magahi spr책kpar.</abstract_sv>
      <abstract_ta>Name பூஜ்ஜியமாக அல்லது மிகவும் குறைந்த மூலங்களுக்கு வாக்களிக்கப்பட்ட முடிவுகளை கொடுக்கும் ஒரு பாதுகாப்பாக்கப்பட பணி அமைப்பாளர்கள் முன்னேற்றம் மற்றும் சோதனை அமைப்புகளை மதிப்பிற்கும் மற்றும் பயிற்சிக்கு மானோலிங்க எங்கள் அணுக்கம் என்னவென்றால் களம் ஒழுங்கு மற்றும் பின் மொழிபெயர்ப்பின் ஒரு ஹைப்ரி செயல்பாடு. பயிற்சி மாதிரியை மதிப்பிட பயன்படுத்தப்பட்ட மெட்ரிக்கள் BLEU, RIBES, திருத்தம், நிகழ்வு மற்றும் F-அளவு. நம்முடைய செயல்பாடு வாக்குறுதியான விளைவுகள் கொடுக்கிறது, 19.5, 13.71, 2.54, மற்றும் 3.16 பிலியு புள்ளிகள் இருக்கும் போஜ்பூரிக்கு, இந்தி, போஜ்பூரி மற்றும் ஹிந்தி மொழி ஜோட</abstract_ta>
      <abstract_ka>ამ დოკუნტის შეტყობინება, რომელიც NLPRL ჯგუფი-ჰინდი და მაგი-ჰინდი ენის ზოგებისთვის, რომლებიც LoResMT 2020-ში გაყობინებულია. ჩვენ გამოიყენეთ არაფერიზებული დიომინის ადაპტიფიკაციის პროგრამა, რომელიც უნდა ან ძალიან მარტივი რესურსის ენათებისთვის გვეუბნება. დავალების ორგანიზატორიები განვითარება და ტესტის კონფიგურაციის და მონოლენგური მონაცემების განათლებისთვის დააყენებენ. ჩვენი პროგორმაცია არის დიომინის ადაპრატიკაციის ჰიბრიტური პროგორმაცია და დაბრუნება. მეტრიკები, რომლებიც გამოყენებული მოდელის გაუმუშაობისთვის, არის BLEU, RIBES, Precision, Recall and F-measure. ჩვენი პროგორმაცია გვაქვს relatively promising results, with a wide range, 19.5, 13.71, 2.54, and 3.16 BLEU points for Bhojpuri to Hindi, Magahi to Hindi, Hindi to Bhojpuri and Hindi to Magahi language pairs respectively.</abstract_ka>
      <abstract_ur>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the Bhojpuri-Hindi and Magahi-Hindi language pairs at LoResMT 2020 shared task. ہم نے ایک غیر محفوظ ڈومین ادامه کا طریقہ استعمال کیا ہے جو صفر یا بہت کم سراسر زبانوں کے لئے وعدہ دینے والے نتیجے دیتے ہیں۔ ٹاکس سائنٹر کی تطالب کے لئے تطالب کے لئے توسعہ اور تطالب کے لئے تطالب کے لئے تطالب کے لئے تطالب کرتا ہے۔ ہمارا طریقہ ڈومین ادامه اور پیچھے ترجمہ کا ایک ہیبراڈ طریقہ ہے۔ تعلیم کی موڈل کا ارزش کرنے کے لئے استعمال کئے جاتے ہیں BLEU, RIBES, precision, Recall and F-measure. ہماری طریقہ سے نسبتا وعدہ دینے والی نتیجے دیتے ہیں، 19.5, 13.71, 2.54 اور 3.16 بلوپ پوینٹوں کے ساتھ جو بوجوپوری کے لئے ہندی، مہائی کے ساتھ، ہندی کے بوجوپوری اور ہندی کے ساتھ مہائی زبان جوڑوں کے ساتھ۔</abstract_ur>
      <abstract_no>Denne papiret rapporterer eit maskinsomsetjingssystem (MT) som NLPRL-gruppa sendt for Bhojpuri-Hindi og Magahi-Hindi-språkparar i LoResMT 2020 delt oppgåve. Vi brukte eit ikkje-oppretta domenetilpassing som gjev promiserende resultat for null eller ekstremt låg ressursspråk. Oppgåveorganisatorene gjev utviklinga og testsettet for evaluering og dataene for opplæring. Tilnærming vårt er ein hybrid tilnærming av domeneadaptasjon og tilbakeomsetjing. Metriske som er brukt til å evaluera den trengte modellen er BLEU, RIBES, nøyaktig, rekollering og F-mål. Tilnærminga vårt gjev relativt promiserende resultat, med breidde område, 19,5, 13,71, 2,54 og 3,16 BLEU-punkt for Bhojpuri til Hindi, Magahi til Hindi, Hindi til Bhojpuri og Hindi til Magahi-språkpare.</abstract_no>
      <abstract_vi>Tờ giấy này báo cáo một hệ thống Dịch Cỗ Máy (MTV) được đội NLLLLL gửi cho đội Bojpur-Hindi và Magati-Hindi giải đồng bộ LoResMT 2020. Chúng tôi đã sử dụng một phương pháp thích nghi miền không giám sát đem lại kết quả hứa hẹn cho ngôn ngữ không nguyên tử hay cực thấp. Các tổ chức làm việc cung cấp các bộ phát triển và các bộ thử nghiệm để đánh giá và các dữ liệu ngôn ngữ để đào tạo. Cách tiếp cận của chúng ta là một phương pháp nhân bản sửa chữa miền và dịch lại. Âm thanh được dùng để đánh giá mô hình được huấn luyện là NINA, RIBS, Precision, Recall và F-thước đo. Cách tiếp cận của chúng ta mang lại kết quả tương đối hứa hẹn, với một khoảng cách rộng rãi, là 19.5, 13.71, 2.54, và 3.16 tiếng bíp dành cho Bojui rồi Ấn Độ, Magaahi đến Hindi, Hindi đến Bhaojthanh và Hindi đến cặp ngôn ngữ Magati.</abstract_vi>
      <abstract_uz>Name Biz muvaffaqiyatli domen tahrirlash usulini ishlatdik, bu nuqta yoki juda qisqa manbaning tillariga ishlatiladi. Vazifaning mualliflari taʼminlovchi va taʼminlovchi uchun tuzuvchi maʼlumot bajariladi. Our approach is a hybrid approach of domain adaptation and back-translation.  Taʼminlovchi modelni qiymatlashga ishlatiladigan metriklar BLEU, RIBES, Aniqlik, Qaytarish va F-metrlari. Bizning murakkablarimiz juda yaxshi natijalar bilan 19.5, 13.71, 2.54 va 3.16 BLEU nuqta Bhojpuri Hindiga, Magahi Hindiga, Hindiga Bhojpuri va Hindiga bir xil tilga ega bo'ladi.</abstract_uz>
      <abstract_bg>В настоящата статия е представена система за машинен превод (МТ), представена от екипа на НЛПРЛ за езиковите двойки Бходжпури-хинди и Магахи-хинди на споделената задача на LoResMT 2020. Използвахме подход за приспособяване на домейни без надзор, който дава обещаващи резултати за езици с нулеви или изключително ниски ресурси. Организаторите на задачите предоставят разработката и тестовите комплекти за оценка и едноезичните данни за обучение. Нашият подход е хибриден подход на адаптация на домейна и обратен превод. Метериците, използвани за оценка на обучения модел, са Блеу, RIBES, Precision, Recall и F-measure. Нашият подход дава сравнително обещаващи резултати, с широк диапазон от 19,5, 13,71, 2,54 и 3,16 точки за езикови двойки Бходжпури до хинди, Магахи до хинди, Хинди до Бходжпури и Хинди до Магахи.</abstract_bg>
      <abstract_nl>Deze paper rapporteert een Machine Translation (MT) systeem ingediend door het NLPRL team voor de Bhojpuri-Hindi en Magahi-Hindi taalparen bij LoResMT 2020 gedeelde taak. We gebruikten een onbeheerde aanpak van domeinaanpassing die veelbelovende resultaten oplevert voor nul of extreem lage resource talen. Taakorganisatoren leveren de ontwikkeling en de testsets voor evaluatie en de eentalige gegevens voor training. Onze aanpak is een hybride aanpak van domeinaanpassing en back-translation. Metieken die worden gebruikt om het getrainde model te evalueren zijn BLEU, RIBES, Precision, Recall en F-measure. Onze aanpak geeft relatief veelbelovende resultaten, met een breed scala, van 19.5, 13.71, 2.54 en 3.16 BLEU punten voor respectievelijk Bhojpuri naar Hindi, Magahi naar Hindi, Hindi naar Bhojpuri en Hindi naar Magahi taalparen.</abstract_nl>
      <abstract_de>Diese Arbeit berichtet über ein Machine Translation (MT)-System, das vom NLPRL-Team für die Bhojpuri-Hindi und Magahi-Hindi Sprachpaare bei LoResMT 2020 eingereicht wurde. Wir haben einen unüberwachten Domänenanpassungsansatz verwendet, der vielversprechende Ergebnisse für Null- oder extrem ressourcenarme Sprachen liefert. Aufgabenorganisationen stellen die Entwicklungs- und Testsets zur Auswertung und die einsprachigen Daten für das Training zur Verfügung. Unser Ansatz ist ein hybrider Ansatz aus Domänenanpassung und Rückübersetzung. Metriken zur Bewertung des trainierten Modells sind BLEU, RIBES, Precision, Recall und F-Measure. Unser Ansatz liefert relativ vielversprechende Ergebnisse, mit einer breiten Palette von 19.5, 13.71, 2.54 und 3.16 BLEU Punkten für Bhojpuri zu Hindi, Magahi zu Hindi, Hindi zu Bhojpuri und Hindi zu Magahi Sprachpaaren, jeweils.</abstract_de>
      <abstract_hr>Ovaj papir prijavljuje sustav za prevod strojeva (MT) podignut tim NLPRL za parove Bhojpuri-Hindi i Magahi-Hindi na zajedničkom zadatku LoResMT 2020. Koristili smo neodređeni pristup prilagodbi domena koji daje obećavajuće rezultate za nulu ili izuzetno niske jezike resursa. Organizatori zadataka pružaju razvoj i testove za procjenu i monojezičke podatke za obuku. Naš pristup je hibridni pristup adaptacije domena i povratnog prevoda. Metrike koje se koriste za procjenu obučenog modela su BLEU, RIBES, preciznost, sjećanje i mjera F. Naš pristup daje relativno obećavajuće rezultate, s širom rasponom od 19,5, 13,71, 2,54 i 3,16 BLEU bodova za Bhojpuri na Hindi, Magahi na Hindi, Hindi na Bhojpuri i Hindi na Magahi jezičke parove.</abstract_hr>
      <abstract_da>Dette papir rapporterer om et maskinoversættelsessystem (MT) indsendt af NLPRL-teamet til sprogparrene Bhojpuri-hindi og Magahi-hindi på LoResMT 2020 delte opgave. Vi brugte en uautoriseret tilpasning til domæner, der giver lovende resultater for nul eller ekstremt lave ressourcer sprog. Opgavearrangørerne leverer udviklings- og testsæt til evaluering og ensprogede data til træning. Vores tilgang er en hybrid tilgang af domænetilpasning og back-translation. De målinger, der anvendes til at evaluere den trænede model, er BLEU, RIBES, Precision, Recall og F-measure. Vores tilgang giver relativt lovende resultater, med et bredt udvalg, på 19,5, 13,71, 2,54 og 3,16 BLEU point for Bhojpuri til Hindi, Magahi til Hindi, Hindi til Bhojpuri og Hindi til Magahi sprogpar, henholdsvis.</abstract_da>
      <abstract_ko>본고는 NLPRL팀이 LoResMT 2020 공유 임무에 제출한 기계번역(MT) 시스템을 보고하여 보이프리-인디언과 마가시-인디언 쌍에 사용한다.우리는 무감독의 영역 적응 방법을 사용했고 제로 자원 또는 극히 낮은 자원에 대한 언어에 대해 이 방법은 희망적인 결과를 제시했다.임무 조직자는 평가에 사용되는 개발과 테스트 집합, 그리고 교육에 사용되는 단어 데이터를 제공한다.우리의 방법은 영역 적응과 역방향 번역의 혼합 방법이다.훈련 모델을 평가하는 지표로는 BLEU, RIBES, 정확도, 리콜율, F-measure가 있다.우리의 방법은 상대적으로 유망한 결과를 제시했다. 보이푸리어가 인디언, 마가시어가 인디언, 인디언이 보이푸리어, 인디언이 마가시어에 대한 BLEU 점수 범위는 각각 19.5, 13.71, 2.54, 3.16이다.</abstract_ko>
      <abstract_fa>این کاغذ گزارش داده است که یک سیستم ترجمه ماشین (MT) توسط تیم NLPRL برای جفت زبان بوجوپوری-هندی و مگاهی-هندی در کار مشترک LoResMT 2020 ارائه شده است. ما از طریق تغییر تغییر دادن دامنی استفاده کردیم که نتیجه‌های قول‌دهنده برای زبانهای صفر یا بسیار کم منابع می‌دهد. Organizers Task provide the development and the test sets for evaluation and the monolingual data for training. دستور ما یک دستور hybrid از تعادل دامنی و ترجمه عقب است. متریک‌هایی که برای ارزیابی مدل آموزش استفاده می‌کنند، BLEU، RIBES، precision, Recall and F-measure هستند. دستور ما نتایج نسبتا قول‌دهنده‌ای را می‌دهد، که در حدود 19.5، 13.71، 2.54 و 3.16 نقطه‌های بلوپ برای بوجوپوری به هندی، مگاهی به هندی، هندی به بوجوپوری و هندی به جفت زبان مگاهی است.</abstract_fa>
      <abstract_id>Kertas ini melaporkan sistem Translation Mesin (MT) yang dikirim oleh tim NLPRL untuk pasangan bahasa Bhojpuri-Hindi dan Magahi-Hindi di LoResMT 2020 berbagi tugas. We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Organiser tugas menyediakan perkembangan dan set tes untuk evaluasi dan data monobahasa untuk pelatihan. Our approach is a hybrid approach of domain adaptation and back-translation.  Metrik yang digunakan untuk mengevaluasi model terlatih adalah BLEU, RIBES, Precision, Recall dan F-measure. pendekatan kita memberikan hasil yang relatif berjanji, dengan jangkauan luas, 19,5, 13,71, 2,54, dan 3,16 poin BLEU untuk Bhojpuri ke Hindi, Magahi ke Hindi, Hindi ke Bhojpuri dan Hindi ke pasangan bahasa Magahi, sesuai.</abstract_id>
      <abstract_af>Hierdie papier rapporteer 'n Masjien Vertaling (MT) stelsel wat deur die NLPRL-span voorgestuur word vir die Bhojpuri-Hindi en Magahi-Hindi taal pare by LoResMT 2020 gedeelde taak. Ons gebruik 'n onverondersteunde domein aanpassing toegang wat beloftende resultate gee vir nul of ekstrem lae hulpbron tale. Opdragorganiseerders verskaf die ontwikkeling en die toets stel vir evaluering en die monolinglike data vir onderwerp. Ons toegang is 'n hybrid toegang van domein aanpassing en terugvertaling. Metrike wat gebruik word om die opgelees model te evalueer is BLEU, RIBES, Presisie, Rekkel en F-maat. Ons toegang gee relatiewe beloftende resultate, met 'n wyde omvang, van 19.5, 13.71, 2.54 en 3.16 BLEU punte vir Bhojpuri tot Hindi, Magahi tot Hindi, Hindi tot Bhojpuri en Hindi tot Magahi taal pare.</abstract_af>
      <abstract_sw>Makala hii inaripoti mfumo wa Tafsiri ya Mashine (MT) uliotolewa na timu ya NLPRL kwa ajili ya wanandoa wa lugha ya Bhojpuri-Hindi na Magahi-Hindi katika kazi ya LoResMT 2020. Tulitumia mbinu za kubadilisha huduma za ndani zisizo sahihi ambazo zinaleta matokeo yanayoahidi kwa lugha sifuri au kwa kiasi kikubwa cha rasilimali. Waandaaji wa kazi wanatoa maendeleo na seti za majaribio kwa ajili ya kutathmini na taarifa za lugha za kiutamaduni kwa ajili ya mafunzo. Hatua yetu ni mbinu ya usafirishaji wa ndani na kutafsiri kwa nyuma. Metrics used to evaluate the trained model are BLEU, RIBES, Precision, Recall and F-measure.  Hatua yetu inaleta matokeo makubwa, kwa kiwango kikubwa, kati ya 19.5, 13.71, 2.54 na 3.16 BLEU kwa ajili ya Bhojpuri kwenda Hindi, Magahi kwenda Hindi, Hindi hadi Bhojpuri na Hindi kwa viwili vya lugha ya Magahi.</abstract_sw>
      <abstract_am>ይህ ገጽ የሆjpuri-Hindi እና ማህሒ-Hindi ቋንቋ ሁለት ሁለት በLoResMT 2020 የተካፈሉ ስራ የNLPRL ተርጓሚ (MT) ስርዓት ሰብቷል፡፡ የዶሜን አካባቢ አካባቢ ለመፍጠር የተስፋ ፍሬዎችን በ0 ወይም በጣም ትንሽ የክፍለ ምዕራብ ቋንቋዎች የሚሰጠው ነው፡፡ የስራ ተሟጋቾች ግንኙነቱን እና የሞክራዊውን እና ለትምህርት የሚያደርጉትን የሞክራዊ ቋንቋዎች ዳታ የሚያደርጉ ናቸው፡፡ የውይይት አካባቢ እና የመረጃ ትርጓሜ ማድረግ ነው፡፡ የተጠቃሚው ሞዴል ቢሊዩና፣ RIBES፣ ቁጥጥር፣ ቁጥጥር እና F-መስፈሪያ ናቸው፡፡ ልግስናችን በተስፋ የተስፋ ውጤቶች አቀረበ፡፡</abstract_am>
      <abstract_hy>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the Bhojpuri-Hindi and Magahi-Hindi language pairs at LoResMT 2020 shared task.  Մենք օգտագործեցինք անվերահսկված բնագավառի ադապտացիայի մոտեցում, որը խոստացնող արդյունքներ է տալիս զրոյի կամ չափազանց ցածր ռեսուրսների լեզուների համար: Տեղադրողները ապահովում են գնահատման զարգացման և փորձարկումների համակարգերը, ինչպես նաև կրթության միալեզու տվյալները: Մեր մոտեցումը տիեզերքի ադապտացիայի և վերադարձման հիբրիդ մոտեցումն է: Մոդելը գնահատելու համար օգտագործված մետրիկներն են ԲԼԵՎ, ՌիԲԵՍ, Ճշմարտություն, Հաշվի առնելը և F-չափումը: Մեր մոտեցումը համեմատաբար խոստացնող արդյունքներ է տալիս, բազմաթիվ տարբերակներով՝ 19.5, 13.71, 2.54 և 3.16 Բհոյփուրիի համար Բհոյփուրիի, Հինդի, Հինդի, Բհոյփուրիի, Հինդի և Մագահի լեզվի զույգերի համար:</abstract_hy>
      <abstract_az>Bu kağıt LoResMT 2020 qonaqlarında Bhojpuri-Hindi və Magahi-Hindi dil çiftləri üçün NLPRL takımının göndərilmiş maşın çeviri sistemini bildirir. Biz sıfır ya da çox düşük ressurs dillərinə vəd verən sonuçları ilə müəyyən edilməmiş domeinin uyğunlaşdırma metodlarını kullandıq. Gözəl organizatorları təhsil etmək üçün təhsil və təhsil qurğularını təhsil edir. Bizim yaxınlığımız domenin uyğunlaşdırması və geri dönüşümüzdür. Eğitimli modeli değerləşdirmək üçün istifadə edilən metriklər BLEU, RIBES, precision, Recall və F-measure idir. Bizim yolumuz 19.5, 13.71, 2.54 və 3.16 BLEU nöqtələri Hindi, Magahi Hindi, Bhojpuri və Hindi dili çiftləri ilə görünür.</abstract_az>
      <abstract_bn>এই পত্রিকাটি লোরেসএমটি ২০২০ সালে ভোজপুরি-হিন্দি এবং মাগাহি হিন্দি ভাষার জোড়ার জন্য এনএলপিআরএল দলের একটি মেশিন অনুবাদ (এমটি) সিস্টেম প্রদা আমরা একটি অরক্ষিত ডোমেইন অ্যাডাপেশনের ক্ষেত্রে ব্যবহার করেছি যা শূন্য অথবা অত্যন্ত কম সম্পদ ভাষার প্রতিশ্রুতিশীল ফলাফল দেয় Task organizers provide the development and the test sets for evaluation and the monolingual data for training.  আমাদের প্রতিযোগিতা হচ্ছে ডোমেইনের আপডেট এবং পিছনের অনুবাদ প্রশিক্ষিত মডেলের মূল্যের জন্য ব্যবহৃত মেট্রিক হচ্ছে বিলু, রিবেস, সমালোচনা, রিস্কেল এবং F-মাপ। আমাদের প্রতিযোগিতায় প্রতিশ্রুতিশীল ফলাফল প্রদান করা হয়েছে, ১৯. ৫, ১৩. ৭১, ২. ৫৪ এবং ৩.</abstract_bn>
      <abstract_ca>Aquest article diu que un sistema de traducció màquina (MT) presentat per l'equip NLPRL per a parelles de llenguatges Bhojpuri-Hindi i Magahi-Hindi a LoResMT 2020 va compartir tasca. Vam utilitzar un enfocament d'adaptació sense supervisió de dominis que dóna resultats prometedors per llengües de recursos zero o extremament baixos. Els organitzadors de tasques proporcionen el desenvolupament i els conjunts de proves per a l'evaluació i les dades monolingües per a l'entrenament. El nostre enfocament és un enfocament híbridde l'adaptació de dominis i la traducció posterior. Els mètrics utilitzats per avaluar el model entrenat són BLEU, RIBES, Precisió, Recall i mesura F. El nostre enfocament dóna resultats relativament prometedors, amb una gran gamma, de 19,5, 13,71, 2,54 i 3,16 punts BLEU per Bhojpuri a Hindi, Magahi a Hindi, Hindi a Bhojpuri i Hindi a parelles de llenguatges Magahi, respectivament.</abstract_ca>
      <abstract_tr>Bu kagyz LoResMT 2020-nji ýylda NLPRL toparynyň ýerleşýän maşynyň terjime (MT) sistemini ýazylýar. Biz nul ýa-da gaty düşük ressurs dillerine söz berýän domeniň adaptasiýasyny ulandyk. Görevler düzenleyicileri deňlenmek üçin gelişme we synaglama düzümlerini temin edýärler. Bizim yaklaşymyz domeniň adaptasyonuň we arka terjime edilmesiniň hybrid yaklaşymyzdyr. Edilen nusgany çykmak üçin ulanylan metriler BLEU, RIBES, Taýik, Rekal we F-ölçüdir. Biziň ýalaýyşymyz 19.5, 13.71, 2.54 we 3.16 BLEU sany Hindi, Magahi bilen Hindi, Bhojpuri bilen Hindiler we Magahi dilleriniň çift nokatlaryna görä söz berýär.</abstract_tr>
      <abstract_sq>Ky dokument raporton një sistem të përkthimit të makinave (MT) të paraqitur nga ekipi NLPRL për çiftet e gjuhës Bhojpuri-Hindi dhe Magahi-Hindi në LoResMT 2020. Ne përdorëm një metodë përshtatjeje jo të mbikqyrur në domeni që jep rezultate premtuese për gjuhët zero apo ekstremisht të ulëta të burimeve. Organizuesit e detyrave ofrojnë zhvillimin dhe grupet e provave për vlerësimin dhe të dhënat monogjuhësore për trajnimin. Përqafimi ynë është një përqafim hibridik i përshtatjes në domeni dhe përkthimit prapa. Metrikat e përdorura për të vlerësuar modelin e trajnuar janë BLEU, RIBES, Precision, Recall dhe F-measure. Përqasja jonë jep rezultate relativisht premtuese, me një gamë të gjerë, prej 19.5, 13.71, 2.54 dhe 3.16 pikë BLEU për Bhojpurin ndaj Hindi, Magahin ndaj Hindi, Hindi ndaj Bhojpurit dhe Hindi ndaj çifteve të gjuhës Magahi respektivisht.</abstract_sq>
      <abstract_et>Käesolevas artiklis esitatakse NLPRLi meeskonna poolt Bhojpuri-hindi ja magahi-hindi keelepaaride jaoks esitatud masintõlke süsteem LoResMT 2020 jagatud ülesandel. Kasutasime järelevalveta domeeni kohandamise lähenemisviisi, mis annab paljulubavaid tulemusi null- või äärmiselt madala ressursiga keelte puhul. Ülesannete korraldajad annavad arendus- ja testikomplektid hindamiseks ning ühekeelsed andmed koolituseks. Meie lähenemisviis on hübriidne lähenemisviis domeenide kohandamisele ja tagasitõlkele. Koolitatud mudeli hindamiseks kasutatakse näitajaid BLEU, RIBES, Precision, Recall ja F-measure. Meie lähenemisviis annab suhteliselt paljulubavaid tulemusi, laia vahemikuga 19,5, 13,71, 2,54 ja 3,16 BLEU punkti Bhojpuri hindi, Magahi hindi, Hindi Bhojpuri ja Hindi Magahi keelepaaride jaoks vastavalt.</abstract_et>
      <abstract_cs>Tento článek popisuje systém strojového překladu (MT) předložený týmem NLPRL pro jazykové páry Bhojpuri-hindi a Magahi-hindi na společném úkolu LoResMT 2020. Použili jsme přístup bez dozoru k adaptaci domén, který poskytuje slibné výsledky pro jazyky nulových nebo extrémně nízkých zdrojů. Organizátoři úkolů poskytují vývoj a testovací sady pro hodnocení a jednojjazyčná data pro školení. Náš přístup je hybridní přístup doménové adaptace a zpětného překladu. Metriky používané k vyhodnocení trénovaného modelu jsou BLEU, RIBES, Precision, Recall a F-measure. Náš přístup poskytuje relativně slibné výsledky, s širokým rozsahem, 19.5, 13.71, 2.54 a 3.16 BLEU bodů pro Bhojpuri do Hindi, Magahi do Hindi, Hindi do Bhojpuri a Hindi do Magahi jazykové páry, resp.</abstract_cs>
      <abstract_bs>Ovaj papir prijavljuje sistem za prevod mašine (MT) podignut tim NLPRL za parove Bhojpuri-Hindi i Magahi-Hindi na zajedničkom zadatku LoResMT 2020. Koristili smo neodređeni pristup adaptaciji domena koji daje obećavajuće rezultate za jezike nule ili izuzetno niske resurse. Organizatori zadataka pružaju razvoj i testove za procjenu i monojezičke podatke za obuku. Naš pristup je hibridni pristup adaptacije domena i povratnog prevoda. Metrike koje se koriste za procjenu obučenog modela su BLEU, RIBES, preciznost, sjećanje i mjera F. Naš pristup daje relativno obećavajuće rezultate, sa širom rasponom od 19,5, 13,71, 2,54 i 3,16 BLEU bodova za Bhojpuri na Hindi, Magahi na Hindi, Hindi na Bhojpuri i Hindi na Magahi jezičke parove.</abstract_bs>
      <abstract_fi>Tﾃ､mﾃ､ artikkeli raportoi NLPRL-tiimin toimittamasta konekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmﾃ､stﾃ､ Bhojpuri-hindi- ja Magahi-hindi-kielipareille LoResMT 2020 -yhteisessﾃ､ tehtﾃ､vﾃ､ssﾃ､. Kﾃ､ytimme valvomatonta verkkotunnuksen sopeutumista, joka antaa lupaavia tuloksia nollakielille tai erittﾃ､in vﾃ､hﾃ､resurssisille kielille. Tehtﾃ､vien jﾃ､rjestﾃ､jﾃ､t toimittavat kehittﾃ､mis- ja testisarjat arviointia varten sekﾃ､ monikielisen tiedon koulutusta varten. Lﾃ､hestymistapamme on hybridi-lﾃ､hestymistapa, johon kuuluu toimialojen mukauttaminen ja takaisinkﾃ､ﾃ､ntﾃ､minen. Koulutetun mallin arvioinnissa kﾃ､ytettyjﾃ､ mittareita ovat BLEU, RIBES, Precision, Recall ja F-measure. Lﾃ､hestymistapamme antaa suhteellisen lupaavia tuloksia, laaja vaihteluvﾃ､li, 19,5, 13,71, 2,54 ja 3,16 BLEU pistettﾃ､ Bhojpurista hindiin, Magahista hindiin, Hindista Bhojpuriin ja Hindista magahiin kielipareihin.</abstract_fi>
      <abstract_sk>Ta prispevek poroča o sistemu strojnega prevajanja (MT), ki ga je ekipa NLPRL predložila za jezikovne pare Bhojpuri-hindi in Magahi-hindi na skupni nalogi LoResMT 2020. Uporabili smo nenadzorovan pristop prilagajanja domen, ki daje obetavne rezultate za jezike z ničelnimi ali izjemno nizkimi viri. Organizatorji nalog zagotavljajo razvoj in testne sklope za ocenjevanje ter enojezične podatke za usposabljanje. Naš pristop je hibridni pristop prilagajanja domenskih področij in prevajanja nazaj. Merila, ki se uporabljajo za oceno usposobljenega modela, so BLEU, RIBES, Precision, Recall in F-measure. Naš pristop daje sorazmerno obetavne rezultate s širokim obsegom 19,5, 13,71, 2,54 in 3,16 točk BLEU za jezikovne pare Bhojpuri do Hindi, Magahi do Hindi, Hindi do Bhojpuri in Hindi do Magahi.</abstract_sk>
      <abstract_ha>@ info: whatsthis We used an unsupervised domain adaptation approach that gives promising results for zero or extremely low resource languages.  Task organizers provide the development and the test sets for evaluation and the monolingual data for training.  TaurayinMu ne wata hanyarwa ta samu'a da baka-tarjima. Metrics used to evaluate the trained model are BLEU, RIBES, Precision, Recall and F-measure.  MataimakinMu yana da fassarar masu yi wa'adi da gwargwadon, wato 19.5, 13.71, 2.54 da 3.16BLEU points na BhojPeri zuwa Hidi, Magahi to Hidi, Hind zuwa Bhojpari da Hindi zuwa harshen Magahi.</abstract_ha>
      <abstract_he>This paper reports a Machine Translation (MT) system submitted by the NLPRL team for the Bhojpuri-Hindi and Magahi-Hindi language pairs at LoResMT 2020 shared task.  השתמשנו באמצעות גישה להתאים לתחום ללא השגחה שמעניקה תוצאות מבטיחות לאפס או לשפות משאבים נמוכות מאוד. מאורגני המשימה מספקים את התפתחות ומערכות הבדיקות להערכה והנתונים המונושפתיים לאימונים. הגישה שלנו היא גישה היברידית של התאמה לתחום ותרגום מאחור. המטריקות שנמשכות להעריך את המודל המאמן הן BLEU, RIBES, מדויק, חזרה ומידד F. הגישה שלנו נותנת תוצאות מבטיחות יחסית, עם טווח רחב, של 19.5, 13.71, 2.54, ו-</abstract_he>
      <abstract_jv>Perintah iki tatis sistem Pakan Terjamahan (MT) sing ngewehi nggawe perintah NLPRL nganggo kelompok Bhojpur-hini lan Makahi-hini nganggo perusahaan lenggal apa nang LOResMT 2020. We used an unaffirmed domain Adjustment method that offrs a compromising output for null or extremely small source language. Organiser We method is a HyBridge method of domain modification and back-translation. unit-format Ndheke awak dhéwé menyang paling-awak dhéwé, nganggo sak luwih, 19.5, 13.1, 2.5, lan 3.16.</abstract_jv>
      <abstract_fil>Ang paper na ito ay nagbibigay ng isang sistema ng Machine Translation (MT) na ibinigay ng pulutong NLPRL para sa mga pare ng wika ng Bhojpuri-Hindi at Magahi-Hindi sa LoResMT 2020 na may kabahagi na gawain. Naggamit kami ng di-upervised domain adaptation approach na nagbibigay ng pangako ng mga resulta para sa mga wikang walang kabuluhan o totoong mababa ng mga resource. Ang mga organizador ng Task ay nagbibigay ng pag-unlad at ng test sets para sa evaluasyon at ng monolingual data para sa pag-aaral. Ang ating pagdating ay hibrid approach ng domain adaptation at back-translation. Ang mga metrika na ginagamit para evaluhin ang modelo na trained ay BLEU, RIBES, Precision, Recall at F-measure. Ang aming paglapit ay nagbibigay ng relatively promising results, na may malaking range, ng 19.5, 13.71, 2.54, at 3.16 BLEU points para sa Bhojpuri sa Hindi, Magahi sa Hindi, Hindi sa Bhojpuri at Hindi sa Magahi.</abstract_fil>
      <abstract_bo>ཤོག་བྱང་འདིས་རྩིས་འཁོར་གཞུང་གི་འགོད་སྐྱོང་པ(MT)མ་ལག་གི་མ་ལག་གིས་བཏོན་གཏོང་ཡོད། ང་ཚོས་རྒྱས་ཁབ་ཀྱི་འབྱུང་རྐྱེན་ཐང་ཡིན་ཡང་ན་ཆེན་ཤུགས་ཀྱི་སྐད་རིགས་ལ་ཉར་མེད་པའི་གྲངས་སྒྲིག བྱ་འགུལ་འཛིན་སྐྱོང་པ་དེ་ལྟ་ཞིབ་བཤེར་བྱེད་ནི་དང་ལྟ་ཞིབ་བྱེད་ཀྱི་ཆ་འཕྲིན་དང་། ང་ཚོའི་གཟུགས་འབྲི་ནི་འདྲ་ཞིག་གི་ཆེ་མཐུན་སྒྲིག་དང་ལོག་འགྲེལ་གྱི་ཐབས་ལམ་ཞིག་རེད། གྲངས་ཚད་ལ་སྒྲིག་འཛིན་པའི་མ་དབྱིབས་ཞིབ་ཐང་ནི་BLEU、RIBES ། གསལ་འཛིན། བསྡུས་དང་། F-ཚད་གཞན་ཞིག་ཡིན། ང་ཚོའི་ཐབས་ལམ་དུ་བྱ་ཚིག་དང་འབྲེལ་ཁག་མཁན་པའི་གྲངས་འབྲེལ་བ་མང་པོ་ཞིག་ཡོད།</abstract_bo>
      </paper>
    <paper id="12">
      <title>Towards Machine Translation for the <a href="https://en.wikipedia.org/wiki/Kurdish_languages">Kurdish Language</a><fixed-case>K</fixed-case>urdish Language</title>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <author><first>Maraim</first><last>Masoud</last></author>
      <pages>87–98</pages>
      <abstract>Machine translation is the task of translating texts from one language to another using <a href="https://en.wikipedia.org/wiki/Computer">computers</a>. It has been one of the major tasks in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> and <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational linguistics</a> and has been motivating to facilitate <a href="https://en.wikipedia.org/wiki/Human_communication">human communication</a>. Kurdish, an <a href="https://en.wikipedia.org/wiki/Indo-European_languages">Indo-European language</a>, has received little attention in this realm due to the language being less-resourced. Therefore, in this paper, we are addressing the main issues in creating a <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation system</a> for the <a href="https://en.wikipedia.org/wiki/Kurdish_languages">Kurdish language</a>, with a focus on the <a href="https://en.wikipedia.org/wiki/Sorani">Sorani dialect</a>. We describe the available scarce <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallel data</a> suitable for training a neural machine translation model for Sorani Kurdish-English translation. We also discuss some of the major challenges in Kurdish language translation and demonstrate how fundamental text processing tasks, such as <a href="https://en.wikipedia.org/wiki/Lexical_analysis">tokenization</a>, can improve <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance.</abstract>
      <url hash="a37f9948">2020.loresmt-1.12</url>
      <bibkey>ahmadi-masoud-2020-towards</bibkey>
      <pwccode url="https://github.com/sinaahmadi/KurdishMT" additional="false">sinaahmadi/KurdishMT</pwccode>
    <title_ar>نحو ترجمة آلية للغة الكردية</title_ar>
      <title_fr>Vers une traduction automatique pour la langue kurde</title_fr>
      <title_es>Hacia la traducción automática para el idioma kurdo</title_es>
      <title_pt>Rumo à tradução automática para a língua curda</title_pt>
      <title_ja>クルド語の機械翻訳に向けて</title_ja>
      <title_zh>迈向库尔德语之机器翻译</title_zh>
      <title_ru>К машинному переводу на курдский язык</title_ru>
      <title_hi>कुर्द भाषा के लिए मशीन अनुवाद की ओर</title_hi>
      <title_ukr>До машинного перекладу курдської мови</title_ukr>
      <title_ga>I dTreo Aistriúchán Meaisín don Teanga Coirdis</title_ga>
      <title_ka>Name</title_ka>
      <title_isl>Í átt að vélþýðingu fyrir kurdska tunguna</title_isl>
      <title_hu>A kurd nyelv gépi fordítása felé</title_hu>
      <title_el>Προς τη μηχανική μετάφραση της κουρδικής γλώσσας</title_el>
      <title_lt>Kurdų kalbos vertimo mašina link</title_lt>
      <title_mk>Курдски јазик</title_mk>
      <title_it>Verso la traduzione automatica della lingua curda</title_it>
      <title_kk>Курд тілінің машинаның аудармасына қарсы</title_kk>
      <title_ms>Ke arah Terjemahan Mesin untuk Bahasa Kurd</title_ms>
      <title_mn>Курдын хэл дээр машины хөгжлийн хөгжлийн төлөө</title_mn>
      <title_pl>W kierunku tłumaczenia maszynowego dla języka kurdyjskiego</title_pl>
      <title_mt>Lejn Traduzzjoni tal-Magni għall-Lingwa Kurda</title_mt>
      <title_ml>കുര്‍ദിഷ് ഭാഷിക്കുവേണ്ടി മുകളിലേക്ക് മെഷീന്‍ പരിഭാഷപ്പെടുത്തുക</title_ml>
      <title_sr>Do prevoda mašine za kurdski jezik</title_sr>
      <title_si>Name</title_si>
      <title_no>Til maskineoversettelse for kurdspråket</title_no>
      <title_ro>Către traducerea automată a limbii kurde</title_ro>
      <title_so>Turjumista mashiinka ee luqada Kurdishka</title_so>
      <title_ta>குர்டிஷ் மொழிக்கு மேலே இயந்திரத்தின் மொழிபெயர்ப்பு</title_ta>
      <title_ur>کوردی زبان کے لئے ماشین ترجمہ کی طرف</title_ur>
      <title_sv>Mot maskinöversättning för det kurdiska språket</title_sv>
      <title_uz>Name</title_uz>
      <title_vi>♪ Hướng tới một cỗ máy dịch ngôn ngữ Kurd</title_vi>
      <title_hr>prema prevodu strojeva za kurdski jezik</title_hr>
      <title_bg>Към машинен превод на кюрдския език</title_bg>
      <title_da>På vej mod maskinoversættelse af det kurdiske sprog</title_da>
      <title_nl>Naar machinevertaling voor de Koerdische taal</title_nl>
      <title_de>Auf dem Weg zur maschinellen Übersetzung für die kurdische Sprache</title_de>
      <title_ko>쿠르드어</title_ko>
      <title_id>Menuju Penerjemahan Mesin untuk Bahasa Kurd</title_id>
      <title_fa>به سوی ترجمه ماشین برای زبان کوردی</title_fa>
      <title_sw>Tafsiri kwa lugha ya Kikurdi</title_sw>
      <title_af>Gaan na Masjien Vertaling vir die Kurdstaal</title_af>
      <title_tr>Kurtçe diliniň maşynyň terjimesine görä</title_tr>
      <title_sq>Për përkthimin e makinave për gjuhën kurde</title_sq>
      <title_hy>Քուրդյան լեզու մեքենային թարգմանություն</title_hy>
      <title_am>Towards Machine Translation for the Kurdish Language</title_am>
      <title_bn>কুর্দি ভাষার জন্য মেশিন অনুবাদ</title_bn>
      <title_az>Kürd dilinin maşına çevirilməsinə tərəf</title_az>
      <title_et>Kurdi keele masintõlke suunas</title_et>
      <title_bs>prema prevodu mašine za kurdski jezik</title_bs>
      <title_ca>Vers la traducció màquina de la llengua curda</title_ca>
      <title_cs>K strojovému překladu pro kurdský jazyk</title_cs>
      <title_fi>Kurdin kielen konekäännös</title_fi>
      <title_jv>Tulung Mahine Terjamahan kanggo Language Kidhis</title_jv>
      <title_sk>Proti strojnemu prevajanju kurdskega jezika</title_sk>
      <title_ha>@ action</title_ha>
      <title_he>לכיוון תרגום מכונות לשפה הקורדית</title_he>
      <title_fil>Pandaan sa Machine Translation para sa wikang Kurdish</title_fil>
      <title_bo>Kurdish སྐད་ཡིག་ཆ་ལ་ལག་འཁྱེར་གྱི་ཚིག་བརྒྱུད་</title_bo>
      <abstract_ar>الترجمة الآلية هي مهمة ترجمة النصوص من لغة إلى أخرى باستخدام أجهزة الكمبيوتر. لقد كانت واحدة من المهام الرئيسية في معالجة اللغة الطبيعية واللغويات الحاسوبية وكانت محفزة لتسهيل التواصل البشري. لم تحظ اللغة الكردية ، وهي لغة هندو أوروبية ، باهتمام كبير في هذا المجال بسبب قلة مواردها. لذلك ، في هذه الورقة ، نتناول القضايا الرئيسية في إنشاء نظام ترجمة آلية للغة الكردية ، مع التركيز على اللهجة السورانية. نصف البيانات المتوازية النادرة المناسبة لتدريب نموذج الترجمة الآلية العصبية لترجمة سوراني الكردية-الإنجليزية. نناقش أيضًا بعض التحديات الرئيسية في ترجمة اللغة الكردية ونوضح كيف يمكن لمهام معالجة النص الأساسية ، مثل الترميز ، أن تحسن أداء الترجمة.</abstract_ar>
      <abstract_fr>La traduction automatique consiste à traduire des textes d'une langue vers une autre à l'aide d'ordinateurs. C'est l'une des tâches majeures du traitement du langage naturel et de la linguistique computationnelle et elle a été motivante pour faciliter la communication humaine. Le kurde, langue indo-européenne, a reçu peu d'attention dans ce domaine en raison de la diminution des ressources de la langue. C'est pourquoi, dans cet article, nous abordons les principaux problèmes liés à la création d'un système de traduction automatique pour la langue kurde, en mettant l'accent sur le dialecte sorani. Nous décrivons les rares données parallèles disponibles qui conviennent à l'entraînement d'un modèle de traduction automatique neuronale pour la traduction kurde-anglais sorani. Nous discutons également de certains des principaux défis de la traduction en kurde et montrons comment les tâches fondamentales de traitement de texte, telles que la tokenisation, peuvent améliorer les performances de traduction.</abstract_fr>
      <abstract_pt>A tradução automática é a tarefa de traduzir textos de um idioma para outro usando computadores. Tem sido uma das principais tarefas em processamento de linguagem natural e linguística computacional e tem sido motivador para facilitar a comunicação humana. O curdo, uma língua indo-européia, recebeu pouca atenção neste domínio devido ao fato de a língua ter menos recursos. Por isso, neste artigo, abordamos as principais questões na criação de um sistema de tradução automática para a língua curda, com foco no dialeto sorani. Descrevemos os escassos dados paralelos disponíveis adequados para treinar um modelo de tradução automática neural para tradução Sorani Curdo-Inglês. Também discutimos alguns dos principais desafios na tradução do idioma curdo e demonstramos como tarefas fundamentais de processamento de texto, como tokenização, podem melhorar o desempenho da tradução.</abstract_pt>
      <abstract_es>La traducción automática es la tarea de traducir textos de un idioma a otro mediante ordenadores. Ha sido una de las principales tareas en el procesamiento del lenguaje natural y la lingüística computacional y ha motivado a facilitar la comunicación humana. El kurdo, una lengua indoeuropea, ha recibido poca atención en este ámbito debido a que el idioma tiene menos recursos. Por lo tanto, en este artículo abordamos los principales problemas en la creación de un sistema de traducción automática para el idioma kurdo, con un enfoque en el dialecto sorani. Describimos los escasos datos paralelos disponibles adecuados para entrenar un modelo de traducción automática neuronal para la traducción kurdo-inglés de Sorani. También analizamos algunos de los principales desafíos de la traducción al idioma kurdo y demostramos cómo las tareas fundamentales de procesamiento de textos, como la tokenización, pueden mejorar el rendimiento de la traducción.</abstract_es>
      <abstract_ja>機械翻訳は、コンピュータを使用してテキストをある言語から別の言語に翻訳する作業です。自然言語処理と計算言語学における主要な課題の一つであり、人間のコミュニケーションを促進する動機付けとなってきました。インド・ヨーロッパ語族であるクルド語は、その言語の資源が少ないため、この分野ではほとんど注目されていない。そこで本稿では、ソラニ方言を中心にクルド語の機械翻訳システムを構築する上での主な課題を扱う。ソラニ・クルド語-英語翻訳のニューラルマシン翻訳モデルのトレーニングに適した利用可能な希少な並列データについて説明します。また、クルド語の翻訳における主要な課題のいくつかについても説明し、トークン化などの基本的なテキスト処理タスクが翻訳パフォーマンスを向上させる方法を示します。</abstract_ja>
      <abstract_zh>机器翻译者,用计算机将文本从一言翻译成一言也。 常为自然语言计语言学之要,而激厉人流。 库尔德语者,印欧语系言也,资源少,故在此域罕所关注。 是以本文之中,将为库尔德语创机器翻译统之要,重为索拉尼方言。 言可以训练索拉尼库尔德语 - 英语翻译神经机器翻译可以稀缺并行。 论库尔德语译之要,演其本务(标其化)何以重其能。</abstract_zh>
      <abstract_ru>Машинный перевод - это задача перевода текстов с одного языка на другой с помощью компьютеров. Это была одна из основных задач в области обработки естественного языка и вычислительной лингвистики, и она была мотивирована для облегчения общения людей. Курдскому языку, индоевропейскому языку, уделяется мало внимания в этой области из-за того, что этот язык является менее обеспеченным ресурсами. Поэтому в данной работе мы рассматриваем основные вопросы создания системы машинного перевода для курдского языка с акцентом на соранский диалект. Мы описываем имеющиеся скудные параллельные данные, подходящие для обучения нейронной модели машинного перевода для курдско-английского перевода Sorani. Мы также обсуждаем некоторые из основных проблем в переводе на курдский язык и демонстрируем, как фундаментальные задачи обработки текста, такие как токенизация, могут улучшить производительность перевода.</abstract_ru>
      <abstract_hi>मशीन अनुवाद कंप्यूटर का उपयोग करके एक भाषा से दूसरी भाषा में ग्रंथों का अनुवाद करने का कार्य है। यह प्राकृतिक भाषा प्रसंस्करण और कम्प्यूटेशनल भाषाविज्ञान में प्रमुख कार्यों में से एक रहा है और मानव संचार को सुविधाजनक बनाने के लिए प्रेरित कर रहा है। कुर्दिश, एक इंडो-यूरोपीय भाषा, भाषा के कम संसाधन होने के कारण इस दायरे में बहुत कम ध्यान दिया गया है। इसलिए, इस पेपर में, हम कुर्द भाषा के लिए एक मशीन अनुवाद प्रणाली बनाने में मुख्य मुद्दों को संबोधित कर रहे हैं, जिसमें सोरानी बोली पर ध्यान केंद्रित किया गया है। हम सोरानी कुर्द-अंग्रेजी अनुवाद के लिए एक तंत्रिका मशीन अनुवाद मॉडल के प्रशिक्षण के लिए उपयुक्त उपलब्ध दुर्लभ समानांतर डेटा का वर्णन करते हैं। हम कुर्द भाषा अनुवाद में कुछ प्रमुख चुनौतियों पर भी चर्चा करते हैं और प्रदर्शित करते हैं कि कैसे मौलिक पाठ प्रसंस्करण कार्य, जैसे टोकनीकरण, अनुवाद प्रदर्शन में सुधार कर सकते हैं।</abstract_hi>
      <abstract_ukr>Машинний переклад - завдання перекладу текстів з однієї мови на іншу за допомогою комп 'ютерів. Це було одне з основних завдань в обробці природної мови та обчислювальної лінгвістики і було мотивацією для полегшення людського спілкування. Курдська мова, індоєвропейська мова, не приділяється достатньої уваги в цій царині через те, що мова має менше ресурсів. Тому в цій роботі ми розглядаємо основні питання створення системи машинного перекладу курдської мови з акцентом на соранський діалект. Ми описуємо наявні дефіцитні паралельні дані, придатні для навчання моделі нейронного машинного перекладу для курдсько-англійського перекладу Сорані. Ми також обговорюємо деякі основні проблеми в перекладі курдською мовою та демонструємо, як фундаментальні завдання обробки тексту, такі як токенізація, можуть покращити ефективність перекладу.</abstract_ukr>
      <abstract_ga>Is éard atá i gceist le haistriúchán meaisín ná téacsanna a aistriú ó theanga amháin go teanga eile ag úsáid ríomhairí. Bhí sé ar cheann de na tascanna móra i bpróiseáil teanga nádúrtha agus teangeolaíocht ríomhaireachtúil agus tá sé á spreagadh chun cumarsáid dhaonna a éascú. Is beag aird a tugadh sa réimse seo ar an gCoirdis, teanga Ind-Eorpach, toisc nach bhfuil mórán acmhainní aici. Mar sin, sa pháipéar seo, táimid ag tabhairt aghaidh ar na príomhcheisteanna maidir le córas aistriúcháin meaisín a chruthú don teanga Coirdis, le fócas ar chanúint Sorani. Déanaimid cur síos ar na sonraí comhthreomhara atá gann agus atá oiriúnach chun samhail néar-aistriúcháin meaisín a oiliúint le haghaidh aistriúchán Sorani Coirdis-Béarla. Déanaimid plé freisin ar chuid de na dúshláin mhóra a bhaineann le haistriúchán teanga Coirdis agus léirímid conas is féidir le tascanna bunúsacha próiseála téacs, amhail comharthaíocht, feidhmíocht aistriúcháin a fheabhsú.</abstract_ga>
      <abstract_ka>მაქსინური გაგრძელება არის ტექსტის გაგრძელება ერთი ენაზე კომპიუტერების გამოყენებით. ეს იყო ნაირადი ენის პროცესი და კომპუტერციონალური ენგუმისტიკის ერთი მნიშვნელოვანი დავალების და მოტივირება ადამიანის კომუნიკაციას. კურდის, ინდო-ევროპოული ენაში, ამ მსოფლიოში ცოტა აღმოჩენა, რადგან ენაზე უფრო მცირე რესურსურსური იყო. ამიტომ, ამ დომენტში, ჩვენ კურდის ენათის მაქსინური გადაწყვეტილების სისტემის შექმნა, რომელიც სორანი დიალექტის ფონსკურება დავწყებთ. ჩვენ აღწერეთ შესაძლებელი პარალელური მონაცემები, რომელიც საჭირო ნეიროლური მაქანის გაგრძელების მოდელს სორანი კურდის-ანგლისური გაგრძელებისთ ჩვენ ასევე განსაკუთრებით კურდის ენის გადაწყვეტილებაში, რამდენიმე ფუნდამეტური ტექსტის გადაწყვეტილება, როგორც ტოკენიზაცია, შეუძლიათ გადაწყვეტილება.</abstract_ka>
      <abstract_el>Η μηχανική μετάφραση είναι το καθήκον της μετάφρασης κειμένων από τη μία γλώσσα στην άλλη χρησιμοποιώντας υπολογιστές. Αποτελεί ένα από τα κύρια καθήκοντα της επεξεργασίας φυσικής γλώσσας και της υπολογιστικής γλωσσολογίας και έχει αποτελέσει κίνητρο για τη διευκόλυνση της ανθρώπινης επικοινωνίας. Τα κουρδικά, μια ινδοευρωπαϊκή γλώσσα, έχουν λάβει ελάχιστη προσοχή σε αυτό το πεδίο λόγω της έλλειψης πόρων της γλώσσας. Ως εκ τούτου, σε αυτή την εργασία, εξετάζουμε τα κύρια ζητήματα για τη δημιουργία ενός συστήματος μηχανικής μετάφρασης για την κουρδική γλώσσα, με έμφαση στη διάλεκτο Σοράνι. Περιγράφουμε τα διαθέσιμα σπάνια παράλληλα δεδομένα κατάλληλα για την εκπαίδευση ενός μοντέλου νευρολογικής μηχανικής μετάφρασης για κουρδική-αγγλική μετάφραση Sorani. Συζητούμε επίσης μερικές από τις μεγαλύτερες προκλήσεις στη μετάφραση της κουρδικής γλώσσας και καταδεικνύουμε πώς θεμελιώδεις εργασίες επεξεργασίας κειμένου, όπως η επισήμανση, μπορούν να βελτιώσουν τις μεταφραστικές επιδόσεις.</abstract_el>
      <abstract_isl>Þýðing véla er verkefni að þýða texta úr einu tungumáli í annað með tölvum. Það hefur verið einn af helstu verkefnum í náttúrulegum tungumáli og tölvulegum tungumáli og hefur verið ástæða til að auðvelda samskipti manna. Kurdish, an Indo-European language, has received little attention in this realm due to the language being less-resourced.  Því erum við í þessu pappíri a ð ræða helstu vandamál við að búa til vélbreytingarkerfi fyrir kurdska tungumálið, með einbeitingu á Sorani dialect. Við lýsum fáanlegar sjaldgæfar samhliða upplýsingar sem henta til a ð þjálfa taugavélarþýðingarlíkani fyrir Sorani kurdsk-enska þýðingu. Við ræðum einnig nokkrar af helstu vandamálunum í kurdsku tungumál þýðingu og sýnum hvernig grundvallar textamyndunarstöður, svo sem tokenization, geta bætt þýðingarframkvæmd.</abstract_isl>
      <abstract_hu>A gépi fordítás feladata a szövegek fordítása egyik nyelvről a másikra számítógép segítségével. Ez volt az egyik legfontosabb feladat a természetes nyelvfeldolgozásban és a számítástechnikai nyelvészetben, és motiválta az emberi kommunikáció megkönnyítését. A kurd, egy indoeurópai nyelv, kevés figyelmet kapott ezen a területen, mivel a nyelv kevésbé erőforrásokkal rendelkezik. Ezért ebben a tanulmányban a kurd nyelvre vonatkozó gépi fordítási rendszer létrehozásának legfontosabb kérdéseivel foglalkozunk, különös tekintettel a Sorani nyelvjárásra. Leírjuk a rendelkezésre álló szűk párhuzamos adatokat, amelyek alkalmasak egy idegi gépi fordítási modell képzésére Sorani kurd-angol fordításhoz. Megbeszéljük a kurd nyelvű fordítás néhány fő kihívását, és bemutatjuk, hogy az alapvető szövegfeldolgozási feladatok, mint például a tokenizáció, hogyan javíthatják a fordítási teljesítményt.</abstract_hu>
      <abstract_lt>Mašininis vertimas – tekstų vertimas iš vienos kalbos į kitą naudojant kompiuterius. Tai buvo viena iš svarbiausių užduočių natūralaus kalbų apdorojimo ir skaičiavimo kalbų srityje ir paskatino palengvinti žmonių komunikaciją. Kurdų kalba, indoeuropietiška, šioje srityje šiek tiek dėmesio skyrė, nes kalba yra mažiau išteklių. Todėl šiame dokumente sprendžiame pagrindinius klausimus kuriant kurdų kalbos vertimo mašin a sistemą, daugiausia dėmesio skiriant Sorani dialektui. Mes apibūdiname turimus ribotus lygiagrečius duomenis, tinkamus mokymui nervinių mašinų vertimo modeliui Sorani kurdų ir anglų vertimui. Taip pat aptariame kai kuriuos pagrindinius kurdų kalbos vertimo uždavinius ir parodysime, kaip pagrindinės tekstų apdorojimo užduotys, pvz., tokenizacija, gali pagerinti vertimo rezultatus.</abstract_lt>
      <abstract_mk>Машински превод е задача за превод на тексти од еден јазик на друг користејќи компјутери. Тоа беше една од главните задачи во природното обработување на јазикот и компјутативната јазика и мотивираше да ја олесни човечката комуникација. Курдски, индуевропски јазик, доби мало внимание во оваа област поради тоа што јазикот е помалку ресурсиран. Затоа, во овој весник, ги решаваме главните прашања во создавањето на систем за машински превод на курдскиот јазик, со фокус на дијалектот Сорани. Ние ги опишуваме достапните ретки паралелни податоци соодветни за обука на модел на превод на неврални машини за превод на Сорани курдско-англиски. Ние, исто така, разговараме за некои од главните предизвици во преводот на курдскиот јазик и демонстрираме како фундаменталните задачи за обработување на текст, како што е токенизацијата, можат да ја подобрат перформансата на преводот.</abstract_mk>
      <abstract_it>La traduzione automatica è il compito di tradurre testi da una lingua all'altra utilizzando computer. È stato uno dei compiti principali nell'elaborazione del linguaggio naturale e nella linguistica computazionale ed è stato motivante per facilitare la comunicazione umana. Il curdo, una lingua indoeuropea, ha ricevuto poca attenzione in questo ambito a causa della mancanza di risorse linguistiche. Pertanto, in questo articolo, stiamo affrontando i principali problemi nella creazione di un sistema di traduzione automatica per la lingua curda, con particolare attenzione al dialetto Sorani. Descriviamo gli scarsi dati paralleli disponibili adatti alla formazione di un modello neurale di traduzione automatica per la traduzione Kurdo-Inglese Sorani. Discutiamo anche alcune delle principali sfide della traduzione in lingua curda e mostriamo come compiti fondamentali di elaborazione del testo, come la tokenizzazione, possano migliorare le prestazioni della traduzione.</abstract_it>
      <abstract_ms>Terjemahan mesin adalah tugas untuk menerjemahkan teks dari satu bahasa ke bahasa lain menggunakan komputer. Ia adalah salah satu tugas utama dalam pemprosesan bahasa alam dan bahasa komputasi dan telah mendorong untuk memudahkan komunikasi manusia. Bahasa Kurdi, bahasa Indo-Eropah, telah menerima sedikit perhatian di dunia ini kerana bahasa kurang sumber daya. Therefore, in this paper, we are addressing the main issues in creating a machine translation system for the Kurdish language, with a focus on the Sorani dialect.  We describe the available scarce parallel data suitable for training a neural machine translation model for Sorani Kurdish-English translation.  Kami juga membincangkan beberapa cabaran utama dalam terjemahan bahasa Kurd dan menunjukkan bagaimana tugas pemprosesan teks dasar, seperti tokenization, boleh meningkatkan prestasi terjemahan.</abstract_ms>
      <abstract_ml>ഒരു ഭാഷയില്‍ നിന്നും മറ്റൊരു ഭാഷയിലേക്കും ഉപയോഗിക്കുന്ന മെഷീന്‍ പരിഭാഷപ്പെടുത്തുന്ന ജോലി. സ്വാഭാവ ഭാഷയുടെ പ്രക്രിയഭാഷ പ്രവര്‍ത്തനങ്ങളിലും കണക്കുണ്ടാക്കുന്ന ഭാഷകളിലും പ്രധാനപ്പെട്ട ജോലികളില്‍ ഒന്നാണ് അത ഈ രാജ്യത്തില്‍ കുര്‍ദ്ദിക്ക് കുറച്ച് ശ്രദ്ധ കിട്ടിയിട്ടുണ്ട്. ഭാഷ കുറച്ച് വിഭവങ്ങള്‍ കുറഞ്ഞിട്ടുണ്ട്. Therefore, in this paper, we are addressing the main issues in creating a machine translation system for the Kurdish language, with a focus on the Sorani dialect.  സോറാനി കുര്‍ദിഷ്- ഇംഗ്ലീഷ് പരിഭാഷണത്തിനുള്ള ഒരു നെയൂറല്‍ യന്ത്രത്തിന്റെ പരിശീലനത്തിനുള്ള പരിശീലനത്തിന് ലഭ്യമ കുര്‍ദിഷ് ഭാഷ പരിഭാഷയിലെ പ്രധാനപ്പെട്ട ചില വ്യാല്‍ക്കുകളെപ്പറ്റി ഞങ്ങള്‍ സംസാരിക്കുകയും ചെയ്യുന്നു. പ്രധാനപൂര്‍ണ്ണമായ ടെ</abstract_ml>
      <abstract_kk>Компьютерді қолданатын мәтіндерді бір тілден басқа тілде аудару тапсырмасы. Бұл табиғи тілдерді өңдеу және компьютерлік лингвистикасының негізгі тапсырмалардың бірі болды және адамдардың коммуникациясын көмектесу үшін мотивацияланды. Индо-Еуропалық тілі Курд тілінде бұл елдің тілінің көмегімен көмегімен көмегімен байланысты болды. Сондықтан бұл қағаздың негізгі мәселелерін Курд тіліне аудару жүйесін құру үшін, Сорани диалектіне назар аудару жүйесін жасап жатыр. Біз сорани Курд- ағылшын аудармасының невралдық компьютердің аудармасының үлгісін оқыту үшін қолданылатын параллельдік деректерді таңдаймыз. Мұндай-ақ біз Курд тілінің аудармасында негізгі мәтін өңдеу тапсырмаларын, мысалы, токенизациясы, аудармасының әрекеттерін жақсарту мүмкіндігін көрсетуге болады.</abstract_kk>
      <abstract_mt>Machine translation is the task of translating texts from one language to another using computers.  Kien wieħed mill-kompiti ewlenin fl-ipproċessar tal-lingwi naturali u l-lingwistika komputattiva u kien qed jimmotiva biex jiffaċilita l-komunikazzjoni umana. Il-Kurdu, lingwa Indo-Ewropea, irċieva ftit attenzjoni f’dan il-qasam minħabba li l-lingwa hija inqas riżorsi. Għalhekk, f’dan id-dokument, qed nindirizzaw il-kwistjonijiet ewlenin fil-ħolqien ta’ sistema ta’ traduzzjoni bil-magna għall-lingwa Kurda, b’enfasi fuq id-dijalekt Sorani. Aħna niddeskrivu d-dejta parallel skarsa disponibbli adattata għat-taħriġ ta’ mudell ta’ traduzzjoni tal-magni newrali għat-traduzzjoni Kurda-Ingliż Sorani. Aħna niddiskutu wkoll xi wħud mill-isfidi ewlenin fit-traduzzjoni tal-lingwa Kurda u nippruvaw kif kompiti fundamentali tal-ipproċessar tat-test, bħat-tokenizzazzjoni, jistgħu jtejbu l-prestazzjoni tat-traduzzjoni.</abstract_mt>
      <abstract_no>Maskineoversettelsa er oppgåva for å oversette tekstar frå ein språk til ein annan med datamaskin. Det har vært ein av dei viktige oppgåvene i naturspråk-handsaming og datamaskinelske språk og har motivert til å gjere menneskelige kommunikasjon. Kurdsk, ein Indoeuropeisk språk, har fått liten oppmerksomhet i denne regionen på grunn av språket som er mindre ressursert. I denne papiret vert vi derfor handsama dei hovudproblemene i å laga ei maskinsomsetjingssystem for kurdske språk, med fokus på Soranske dialekten. Vi beskriver dei tilgjengelege kraftige parallelle data som er passande for å lære eit neuralmaskinsomsetjingsmodul for soranisk- engelsk omsetjing. Vi diskuterer også noen av dei viktige utfordringane i omsetjinga av kurdske språk og demonstrerer korleis grunnleggjande teksthandsamingsoppgåver, som tokenisering, kan forbetra omsetjingsfunksjonen.</abstract_no>
      <abstract_mn>Машин орчуулалт бол нэг хэлээс өөр компьютерийг ашиглаж өгсөн текстүүдийг орчуулах үйл ажил юм. Энэ бол байгалийн хэл болон тооцооллын хэлний үйлдвэрлэлийн хамгийн чухал даалгавар юм. Энэ нь хүн төрөлхтний харилцааны түвшинд урам зориулсан. Индо-Европын хэл Курд хэл хэлэхдээ бага хүчин зүйл байхын тулд энэ хэл дээр бага анхаарал авсан. Тиймээс энэ цаасан дээр бид Курдын хэл дээр машин орчуулах системийг бүтээх гол асуудлуудыг асууж байна. Сорани диалект дээр анхаарлаа анхаарлаа хандуулж байна. Бид Сорани Курд-Англи хэлний хөрөнгө оруулахын тулд мэдрэлийн хөрөнгө оруулахын тулд зөв параллел өгөгдлийг тайлбарлаж байна. Мөн бид Курдын хэлний орчуулалтын зарим чухал сорилтуудыг ярьж, хэрхэн үндсэн текст үйлдвэрлэлийн үйлдвэрлэлүүд, жишээ нь тодорхойлолтын үйлдвэрлэлийг сайжруулж чадна гэдгийг харуулж байна.</abstract_mn>
      <abstract_sr>Prevedenje mašine je zadatak prevoda teksta iz jednog jezika na drugi korištenje kompjutera. To je jedan od najvećih zadataka prirodnog jezika i računalnog jezika i motivirao je da olakša ljudsku komunikaciju. Kurdski, Indoevropski jezik, je dobio malo pažnje u ovom svetu zbog jezika koji je manje resursa. Stoga, u ovom papiru, rješavamo glavne probleme u stvaranju sistema prevoda mašine za kurdski jezik, sa fokusom na Sorani dijalekt. Opišemo dostupne manje paralelne podatke odgovarajuće za obuku model a prevoda neuralne mašine za prevod kurdskog-engleskog suranskog. Takođe razgovaramo o nekim od velikih izazova na prevodu kurdskog jezika i pokazujemo kako temeljni zadaci obrade teksta, poput tokenizacije, mogu poboljšati izvođenje prevoda.</abstract_sr>
      <abstract_pl>Tłumaczenie maszynowe to zadanie tłumaczenia tekstów z jednego języka na drugi za pomocą komputerów. Jest to jedno z głównych zadań w przetwarzaniu języka naturalnego i lingwistyce obliczeniowej i motywuje do ułatwienia komunikacji z ludźmi. Kurdyjski, język indoeuropejski, zwrócił niewiele uwagi w tej dziedzinie ze względu na mniejsze zasoby języka. Dlatego w niniejszym artykule poruszamy główne zagadnienia związane z tworzeniem systemu tłumaczenia maszynowego dla języka kurdyjskiego, ze szczególnym uwzględnieniem dialektu Sorani. Opisujemy dostępne niewielkie dane równoległe nadające się do treningu neuronowego modelu tłumaczenia maszynowego dla tłumaczenia kurdyjsko-angielskiego Sorani. Omówimy również niektóre z głównych wyzwań związanych z tłumaczeniem języka kurdyjskiego i pokazujemy, jak podstawowe zadania przetwarzania tekstu, takie jak tokenizacja, mogą poprawić wydajność tłumaczenia.</abstract_pl>
      <abstract_ro>Traducerea automată este sarcina traducerii textelor dintr-o limbă în alta folosind calculatoare. A fost una dintre sarcinile majore în procesarea limbajului natural și lingvistica computațională și a fost motivant pentru a facilita comunicarea umană. Kurda, o limbă indo-europeană, a primit puțină atenție în acest domeniu datorită faptului că limba nu are resurse. Prin urmare, în această lucrare abordăm principalele probleme în crearea unui sistem de traducere automată pentru limba kurdă, cu accent pe dialectul Sorani. Descriem datele paralele limitate disponibile potrivite pentru formarea unui model neural de traducere automată pentru traducerea kurdă-engleză Sorani. De asemenea, discutăm câteva dintre provocările majore în traducerea limbii kurde și demonstrăm modul în care sarcinile fundamentale de procesare a textului, cum ar fi tokenizarea, pot îmbunătăți performanța traducerii.</abstract_ro>
      <abstract_so>Turjumista machine is the task of translating texts from one language to another using computers. It has been one of the major tasks in natural language processing and computational linguistics and has been motivating to facilitate human communication.  Luqada Indo-Yurub ee Kurdish ayaa aad u fiirsatay boqortooyadan sababtoo ah luqada aan ka yarayn karin. Sidaa darteed waxaynu ka sheekeysanaynaa warqaddan arimaha ugu muhiimsan ee aan abuurno nidaamka turjumista machine ee luqada Kurdish, kaas oo focus ugu leh qoraalka Sorani. Waxaannu sawirannaa macluumaadka lambarka ah oo aad u eg tahay waxbarashada tusaale ahaan turjumista maskaxda neurada ee turjumista Sorani Kurdish-Ingiriis. Sidoo kale waxaynu kala sheekeynaynaa dhibaatooyin muhiim ah oo ku qoran turjumidda luqada Kurdish, waxaana tusnaynaa siduu u beddeli karo shaqooyinka baaraandegista qoraalka aasaasiga ah, tusaale ahaan calaamadda, horumarinta turjumista.</abstract_so>
      <abstract_sv>Maskinöversättning är uppgiften att översätta texter från ett språk till ett annat med hjälp av datorer. Det har varit en av de viktigaste uppgifterna inom naturspråksbehandling och datorlingvistik och har varit motiverande att underlätta mänsklig kommunikation. Kurdiska, ett indoeuropeiskt språk, har fått liten uppmärksamhet på detta område på grund av att språket har mindre resurser. Därför behandlar vi i denna uppsats huvudfrågorna i skapandet av ett maskinöversättningssystem för det kurdiska språket, med fokus på Sorani-dialekten. Vi beskriver tillgängliga knappa parallella data som lämpar sig för att träna en neural maskinöversättningsmodell för Sorani kurdisk-engelsk översättning. Vi diskuterar också några av de stora utmaningarna inom kurdiska språköversättning och visar hur grundläggande textbearbetningsuppgifter, såsom tokenisering, kan förbättra översättningens prestanda.</abstract_sv>
      <abstract_ta>இயந்திரம் மொழிமாற்றுதல் என்பது ஒரு மொழியிலிருந்து மற்றொரு கணினிகளை பயன்படுத்தி மொழிமாற்றும் உரைகள இது இயற்கையான மொழி செயல்படுத்தல் மற்றும் கணக்கிட மொழிகளில் முக்கிய பணிகளில் ஒன்றாக இருந்தது மற்றும் மனித த தொடர்பு முறைய இந்தோ ஐரோப்பிய மொழியில் குர்டிஷ் குறைந்த மொழி குறைந்த வளர்ச்சியாக இருக்கும் காரணத்தால் இந்த ராஜ்வில்  எனவே, இந்த காகிதத்தில், நாங்கள் முக்கிய பிரச்சனைகளை குர்திஷ் மொழிக்கு ஒரு இயந்திர மொழிமாற்று அமைப்பை உருவாக்குவதில், சோரான நாம் கிடைக்கும் குறைவான இணைப்பு தகவலை விவரிக்கும் சோரனி குர்டிஷ்- ஆங்கிலம் மொழிபெயர்ப்பிற்கு பொருத்தமான ஒரு  நாம் குர்தி மொழி மொழிமாற்றியில் சில முக்கிய சவால்களை விவாதம் செய்து காண்பிக்கிறோம் மற்றும் அடிப்படை உரை செயல்படுத்தல் பண</abstract_ta>
      <abstract_si>යන්ත්‍රය අවවාදය තමයි එක භාෂාවෙන් පණිවිඩය භාවිත කරනවා පණිවිඩය වලට පණිවිඩය ගැන වැඩය ඒක ස්වාභාවික භාෂාව සහ පරිගණක භාෂාවිද්‍යාත්මක වලින් ප්‍රධාන වැඩක් එකක් වෙලා තියෙනවා. මිනිස්සු සම් කුර්ඩිෂ්, ඉන්ඩෝයෝරෝපිය භාෂාවක්, මේ රාජ්‍යයේ පොඩි අවධානයක් ලැබුණා නිසා භාෂාව පොඩි සම්බ ඉතින්, මේ පත්තරේ අපි ප්‍රධාන ප්‍රශ්නයක් ලැබෙනවා කුර්දිස් භාෂාව සඳහා පත්තර පද්ධතියක් නිර්මාණය කරනවා, සොරාන අපි සෝරානි කුර්ඩිෂ්-ඉංග්‍රීසි භාවිතාව සඳහා ප්‍රශ්නයක් කරන්න පුළුවන් සාමාන්‍ය මැෂින් භාවිතා අපි කුර්දිස් භාෂාවේ වාර්තාවේ ප්‍රධාන ප්‍රශ්ණ ප්‍රශ්ණ ප්‍රශ්ණ ප්‍රශ්ණ ප්‍රශ්ණ ප්‍රශ්ණ ප්‍රශ්ණ වැඩ</abstract_si>
      <abstract_ur>ماشین ترجمہ ایک زبان سے ایک دوسرے کی کمپیوٹر کے مطابق پیغام ترجمہ کرنے کا کام ہے. یہ طبیعی زبان پردازش اور کمپیوٹریشن زبان شناسی میں سب سے بڑے کام میں سے ایک ہے اور انسان کی ارتباط آسانی کرنے کے لئے ہدایت کرتا ہے۔ کوردیش، ایک انڈو یورپی زبان، اس ملک میں تھوڑی توجه حاصل کی گئی ہے اس زبان کے سبب جو کم کم حاصل کی گئی ہے۔ لہٰذا، اس کاغذ میں، ہم کوردی زبان کے لئے ایک ماشین ترجمہ سیستم بنانے کے لئے اصلی مسئلہ کے بارے میں مشکل کررہے ہیں، سورانی دیالکت کے ذریعہ سے تمرکز کررہے ہیں۔ ہم نے سورانی کوردی-انگلیسی ترجمہ کے لئے نیورال ماشین ترجمہ موڈل کی تعلیم کے لئے مناسب موجود پارالیل ڈیٹا کو توصیح دیتے ہیں. ہم بھی کوردی زبان کی ترجمہ میں بہت بڑے چالوں میں سے کچھ بحث کرتے ہیں اور دکھاتے ہیں کہ کس طرح بنیادی ٹیکسٹ پرسس کرنے کے کام، جیسے ٹوکنیزی، ترجمہ کے کام کو بہتر کر سکتے ہیں۔</abstract_ur>
      <abstract_uz>@ info: whatsthis Bu tabiiy tilni boshqarish va kompyuterlar tillarida eng muhim vazifalar edi va inson aloqalarini foydalanishga tayyorlaydi. Indo-European tili Kurdish tili bu davlatda juda qisqat murakkab bo'lganligini qabul qildi. Hullas, bu qogʻozda, biz Kurdish tilning asosiy tarjima tizimini yaratish uchun asosiy muammolar bilan boshqaramiz, Sorani dialektika fokuslangan. @ info Biz Kurdish tilida tarjima qilish uchun bir necha katta qiymatlar bilan javob beramiz va bir xil matn boshqarish vazifalarini ko'rsatishmiz mumkin, huddi tashkilotni tasavvur qilish imkoniyatini o'zgartirish imkoniyatini oshirish mumkin.</abstract_uz>
      <abstract_vi>Dịch cỗ máy là nhiệm vụ dịch chuyển văn bản từ ngôn ngữ này sang ngôn ngữ khác bằng máy tính. Nó là một trong những công việc quan trọng trong việc xử lý ngôn ngữ tự nhiên và ngôn ngữ vi tính và đã thúc đẩy việc phát triển thông tin con người. Người Kurd, một ngôn ngữ Indo-Châu-Âu, nhận được ít sự quan tâm trong lĩnh vực này bởi vì ngôn ngữ kém nguồn lực. Vì vậy, trong bài báo này, chúng ta đang giải quyết vấn đề chính trong việc tạo ra một hệ thống dịch chuyển máy cho ngôn ngữ Kurd, với tập trung vào thổ ngữ Sorani. Chúng tôi mô tả những dữ liệu song song song hiếm có sẵn để đào tạo một mô hình dịch cỗ máy thần kinh cho phiên dịch Kurd-English. Chúng ta cũng thảo luận về một số thử thách lớn trong phiên dịch ngôn ngữ của người Kurd và giải thích cách xử lý văn bản cơ bản, như đồ vật, có thể cải thiện thành quả dịch chuyển.</abstract_vi>
      <abstract_bg>Машинният превод е задачата да превеждате текстове от един език на друг с помощта на компютри. Тя е една от основните задачи в обработката на естествения език и изчислителната лингвистика и е мотивираща за улесняване на човешката комуникация. Кюрдският, индоевропейски език, е получил малко внимание в тази сфера поради по-малко ресурси на езика. Ето защо в настоящата статия разглеждаме основните въпроси при създаването на система за машинен превод на кюрдския език с акцент върху соранския диалект. Описваме наличните оскъдни паралелни данни, подходящи за обучение на модел на невронен машинен превод за сорански кюрдско-английски превод. Ние също така обсъждаме някои от основните предизвикателства при превода на кюрдски език и демонстрираме как фундаменталните задачи по обработка на текста, като например токенизацията, могат да подобрят ефективността на превода.</abstract_bg>
      <abstract_da>Maskinoversættelse er opgaven med at oversætte tekster fra et sprog til et andet ved hjælp af computere. Det har været en af de største opgaver inden for naturlig sprogbehandling og beregningslingvistik og har været motiverende til at lette menneskelig kommunikation. Kurdisk, et indoeuropæisk sprog, har fået ringe opmærksomhed på dette område, fordi sproget er mindre ressourcer. Derfor behandler vi i denne artikel de vigtigste spørgsmål i forbindelse med at skabe et maskinoversættelsessystem for det kurdiske sprog med fokus på Sorani-dialekten. Vi beskriver de tilgængelige knappe parallelle data egnet til træning af en neural maskinoversættelsesmodel til Sorani kurdisk-engelsk oversættelse. Vi diskuterer også nogle af de store udfordringer inden for kurdisk sprogoversættelse og viser, hvordan grundlæggende tekstbehandlingsopgaver, såsom tokenisering, kan forbedre oversættelsesevnen.</abstract_da>
      <abstract_nl>Machinevertaling is de taak van het vertalen van teksten van de ene taal naar de andere met behulp van computers. Het is een van de belangrijkste taken in de natuurlijke taalverwerking en computerlinguïstiek geweest en heeft gemotiveerd om menselijke communicatie te vergemakkelijken. Koerdisch, een Indo-Europese taal, heeft op dit gebied weinig aandacht gekregen omdat de taal minder middelen heeft. Daarom behandelen we in dit artikel de belangrijkste kwesties bij het creëren van een machinevertaalsysteem voor de Koerdische taal, met een focus op het Sorani dialect. We beschrijven de beschikbare schaarse parallelle gegevens die geschikt zijn voor het trainen van een neuraal machinevertaalmodel voor Sorani Koerdisch-Engels vertaling. We bespreken ook enkele van de grote uitdagingen bij het vertalen van Koerdische talen en tonen aan hoe fundamentele tekstverwerkingstaken, zoals tokenisering, vertaalprestaties kunnen verbeteren.</abstract_nl>
      <abstract_hr>Prijevod strojeva je zadatak prevoda teksta iz jednog jezika na drugi korištenje računala. To je jedan od najvećih zadataka prirodnog jezika obrađivanja i računalnog jezika i motivirala se olakšati ljudsku komunikaciju. Kurdski, Indo-europski jezik, u ovom svijetu dobio je malo pažnje zbog jezika manje resursa. Stoga, u ovom papiru rješavamo glavne probleme u stvaranju sustava prevoda stroja za kurdski jezik, s fokusom na Sorani dijalekt. Opisujemo dostupne manje paralelne podatke odgovarajuće za obuku model a prevoda neuralnih strojeva za prevod Soranija kurdskog i engleskog jezika. Također razgovaramo o nekim od glavnih izazova na prevodu kurdskih jezika i pokazujemo kako temeljni zadaci obrade teksta, poput tokenizacije, mogu poboljšati učinkovitost prevoda.</abstract_hr>
      <abstract_ko>기계번역은 컴퓨터로 텍스트를 한 언어에서 다른 언어로 번역하는 작업이다.그것은 자연 언어 처리와 계산 언어학의 주요 임무 중 하나이며 인류의 교류를 추진하고 있다.쿠르드어는 인구어계의 언어로 자원이 부족하기 때문에 이 분야에서 주목을 받지 못한다.따라서 본고에서 우리는 쿠르드 언어를 위해 기계 번역 시스템을 구축하는 주요 문제를 토론할 것이다. 중점은 소라니 사투리다.우리는 Sorani-Kurdish의 영어 번역을 훈련하는 데 사용할 수 있는 신경 기계 번역 모델의 희소한 병행 데이터를 묘사했다.우리는 또한 쿠르드어 번역 중의 몇 가지 주요 도전을 토론했고 기본 텍스트 처리 임무(예를 들어 표기화)가 어떻게 번역 성능을 향상시키는지 보여 주었다.</abstract_ko>
      <abstract_de>Maschinelle Übersetzung ist die Aufgabe, Texte von einer Sprache in eine andere mit Computern zu übersetzen. Es war eine der Hauptaufgaben in der Verarbeitung natürlicher Sprache und Computerlinguistik und motivierte die menschliche Kommunikation zu erleichtern. Kurdisch, eine indoeuropäische Sprache, hat in diesem Bereich wenig Aufmerksamkeit erhalten, da die Sprache weniger Ressourcen hat. Daher befassen wir uns in diesem Beitrag mit den Hauptproblemen bei der Schaffung eines maschinellen Übersetzungssystems für die kurdische Sprache, mit einem Schwerpunkt auf dem Sorani-Dialekt. Wir beschreiben die verfügbaren knappen parallelen Daten, die für das Training eines neuronalen maschinellen Übersetzungsmodells für die kurdisch-englische Übersetzung von Sorani geeignet sind. Wir diskutieren auch einige der großen Herausforderungen bei der kurdischen Übersetzung und zeigen auf, wie grundlegende Textverarbeitungsaufgaben, wie Tokenisierung, die Übersetzungsleistung verbessern können.</abstract_de>
      <abstract_id>Terjemahan mesin adalah tugas untuk menerjemahkan teks dari satu bahasa ke bahasa lain menggunakan komputer. Ini adalah salah satu tugas utama dalam proses bahasa alam dan bahasa komputasi dan telah mendorong untuk memudahkan komunikasi manusia. Bahasa Kurd, bahasa Indo-Eropa, telah menerima sedikit perhatian di dunia ini karena bahasa kurang sumber daya. Oleh karena itu, di kertas ini, kita mengatasi masalah utama dalam menciptakan sistem terjemahan mesin untuk bahasa Kurd, dengan fokus pada dialekt Sorani. Kami menggambarkan data paralel yang tak terdapat yang cocok untuk melatih model terjemahan mesin saraf untuk terjemahan Sorani Kurdi-Inggris. Kami juga mendiskusikan beberapa tantangan utama dalam terjemahan bahasa Kurd dan menunjukkan bagaimana tugas memproses teks dasar, seperti tokenization, dapat meningkatkan prestasi terjemahan.</abstract_id>
      <abstract_fa>ترجمه ماشین کار ترجمه کردن متن از یک زبان به دیگر با استفاده از کامپیوتر است. این یکی از مهمترین وظیفه‌های پرداخت زبان طبیعی و زبان‌شناسی کامپیوتری است و برای آسانیش ارتباط انسانی انگیز می‌کند. کوردی، یک زبان Indo-European، توجه کمی در این ملک به دلیل زبان کمتر از منابع است. بنابراین، در این کاغذ، ما در مورد مسائل اصلی در ایجاد یک سیستم ترجمه ماشین برای زبان کوردی با تمرکز روی دیالکت سورانی صحبت می کنیم. ما اطلاعات مشکلی را برای آموزش یک مدل ترجمه ماشین عصبی برای ترجمه کوردی و انگلیسی سورانی توصیف می کنیم. ما همچنین در مورد بعضی از چالش های بزرگی در ترجمه زبان کوردی صحبت می کنیم و نشان می دهیم که چگونه کار های پرداخت متن بنیادی، مثل توکین، می توانند عملکرد ترجمه را بهتر کند.</abstract_fa>
      <abstract_af>Masjien vertaling is die taak van vertaling van teks van een taal na 'n ander rekenaar. Dit is een van die grootste opdragte in natuurlike taal verwerking en rekenaarsjonale lingvistike en het motiveer om menslike kommunikasie te eenvoudig. Kurdish, 'n Indo-Europeese taal het klein aandag ontvang in hierdie aarde vanweë die taal wat minder-hulpbron is. Daarom, in hierdie papier, word ons die hoofde probleme in die skep van 'n masjien vertalingsstelsel vir die Kurdstaal, met 'n fokus op die Sorani dialekte. Ons beskryf die beskikbare skaars parallele data wat geskik is vir die onderwerp van 'n neurale masjien vertaling model vir Sorani Kurdish- Engels vertaling. Ons bespreek ook sommige van die hoofde uitdagings in die Kurdske taal vertaling en wys hoe fondamentele teks verwerking opdragte kan, soos tokenisasie, verbeter vertaling.</abstract_af>
      <abstract_sw>Tafsiri ya mashine ni jukumu la kutafsiri maandishi kutoka lugha moja hadi nyingine kwa kutumia kompyuta. Ni moja ya kazi muhimu katika utaratibu wa lugha za asili na lugha za kompyuta na imekuwa ikihamasisha kuwezesha mawasiliano ya binadamu. Kikurdi, lugha ya Kihindi-Ulaya, kimepokea macho kidogo katika ufalme huu kwa sababu ya lugha isiyo na rasilimali. Kwa hiyo, katika gazeti hili, tunajadili masuala muhimu katika kutengeneza mfumo wa kutafsiri mashine kwa lugha ya Kikurdi, wenye lengo la mtazamo wa Sorani. Tunaelezea taarifa zinazopatikana kwa kiasi kikubwa zinazofanana kwa ajili ya mafunzo ya mfumo wa tafsiri wa mashine ya kidini kwa ajili ya tafsiri ya Kiingereza ya Ki-Sorani. Pia tunajadili baadhi ya changamoto kubwa katika tafsiri ya lugha ya Kikurdi na kuonyesha jinsi kazi za msingi za ufuatiliaji wa maandishi, kama vile uthibitisho, inaweza kuboresha utendaji wa tafsiri.</abstract_sw>
      <abstract_tr>Maşynyň terjime edilen hat bir dilden kompýuterleri ulanan metinleri terjime etmek üçin zady. Bu tebigy diller işleýän we kompýuter dilleriniň esasy görevlerinden biri we adamlaryň habarlaryny bejermek üçin täsirleýär. Kürdçe, Indo-Ýewropa dili, bu ýerlerde azajyk bolan dilleriň sebäbi biraz üns berildi. Şol sebäpli, bu kagyzda biz Kurdi dilinde maşynyň terjime sistemasyny bejermek üçin esasy meselelere çözýäris we Sorani dialektesine fokus berýäris. Biz Sorani Kurtçe-Iňlisçe terjime etmek üçin ýeterli parallel maglumatlaryny tashylaýarys. Biz hem Kurtçe dilinde esasy kynçylyklaryň käbir meselelerini gürrüň edýäris we bellenen metin işlemleriniň nähili esasy meselelerini gowylaşdyryp bilýändigini görkez.</abstract_tr>
      <abstract_sq>Përkthimi i makinave është detyra e përkthimit të teksteve nga një gjuhë në një tjetër duke përdorur kompjutera. Ajo ka qenë një nga detyrat kryesore në procesimin natyror të gjuhës dhe gjuhës llogaritare dhe ka qenë motivuese për të lehtësuar komunikimin njerëzor. Kurde, një gjuhë indoevropiane, ka marrë pak vëmendje në këtë fushë për shkak se gjuha është më pak me burime. Prandaj, në këtë letër, ne po trajtojmë çështjet kryesore në krijimin e një sistemi përkthimi makinash për gjuhën kurde, me një fokus në dialektin Sorani. Ne përshkruajmë të dhënat paralele të pakta të disponueshme të përshtatshme për trajnimin e një modeli përkthimi nervor për përkthimin kurd-anglez Sorani. Ne diskutojmë gjithashtu disa nga sfidat kryesore në përkthimin e gjuhës kurde dhe demonstrojmë se si detyrat themelore të procesimit të tekstit, të tilla si tokenizimi, mund të përmirësojnë performancën e përkthimit.</abstract_sq>
      <abstract_hy>Մեքենային թարգմանությունը հաղորդագրություններ մեկ լեզվից մյուսին թարգմանելու խնդիրն է համակարգիչների միջոցով: Դա բնական լեզվի վերամշակման և հաշվարկների լեզվաբանության մեծ խնդիրներից մեկն է, և դրդապատճառ է եղել մարդկային հաղորդակցման հեշտացնելու համար: Քուրդդական, հնդեվրոպական լեզու, այս ոլորտում քիչ ուշադրություն է ստացել, քանի որ լեզուն ավելի քիչ ռեսուրսներ ունի: Այսպիսով, այս թղթի մեջ մենք լուծում ենք գլխավոր խնդիրները՝ ստեղծելով կորդական լեզու մեքենային թարգմանման համակարգ, կենտրոնացնելով Սորանի դիալեկտի վրա: Մենք նկարագրում ենք հասանելի հազվադեպ զուգահեռ տվյալները, որոնք համապատասխանում են սորանի կորդի-անգլերեն թարգմանման նյարդային մեքենայի մոդելի ուսումնասիրելու համար: Մենք նաև քննարկում ենք որոշ կարևոր մարտահրավերներ կուրդյան լեզվի թարգմանման մեջ և ցույց ենք տալիս, թե ինչպես հիմնական տեքստի վերաբերյալ խնդիրները, ինչպիսիք են օրինակ թոկենիզացիան, կարող են բարելավել</abstract_hy>
      <abstract_am>Machine translation is the task of translating texts from one language to another using computer. አካባቢ ቋንቋ እና ቋንቋ ቋንቋዎች ማቀናቀል ትልቁ ስራዎች አንዲቱ ነው፣ ሰውንም ማቀናቀል ማግኘት ማግኘት ነው፡፡ የኢንዶ-አውሮፓዊ ቋንቋ የኩርዲ ቋንቋ ቋንቋ ትንሽ ክፍል ሲሆን በዚህ መንግሥት ላይ ጥቂት ጥያቄ ተቀበለ፡፡ ስለዚህም በዚህ ገጽ፣ የኮርዲ ቋንቋ መሳሪያ ትርጉም ስርዓት በመፍጠር፣ በሶራኒ አካባቢ ላይ ትኩረት እናደርጋለን፡፡ ለሶራኒ ኩርድስ-እንግሊዘኛ ትርጓሜዎችን ለማግኘት የሚችሉትን የናውሬው የሜክስል ትርጉም ሞዴል እናሳውቃለን፡፡ በኩርዲ ቋንቋ ትርጉም ላይ አንዳንዶችን ዋንጫ እናሳውቃለን፡፡</abstract_am>
      <abstract_az>Makinat çevirilməsi bir dildən məktubları başqasına çevirilməkdir. Bu, təbiətli dil işləməsində və hesablama dilində olan ən böyük işlərdən biri idi və insan iletişimi olaraq çox asanlaşdırmaq üçün motiv edir. İndo-Avropa dili Kurdi dili bu dünyada çox az məlumat verir. Beləliklə, bu kağızda, biz Kurdi dilinin maşına çevirim sistemini yaratmaq üçün ən böyük məsələlərə çəkirik, Sorani dialektinə odaqlanırıq. Biz Sorani Kurt-İngilizə çevirilməsi üçün nöral maşına çevirilməsi modeli təhsil etmək üçün mümkün paralel məlumatları təfsil edirik. Biz də Kürd dilində böyük çətinliklərdən bəzilərini mübahisə edirik və təkrarlama işləri kimi, təkrarlama kimi, əsas mətn işləməsi işlərinin nə qədər yaxşılaşdırdığını göstəririk.</abstract_az>
      <abstract_bs>Prevod je zadatak prevoda teksta iz jednog jezika na drugu koristeći kompjutere. To je bio jedan od najvećih zadataka prirodnog jezika i računalnog jezika i motivirao je da olakša ljudsku komunikaciju. Kurdski, Indo-evropski jezik, u ovom svijetu dobio je malo pažnje zbog jezika manje resursa. Stoga, u ovom papiru, rješavamo glavne probleme u stvaranju sustava prevoda mašine za kurdski jezik, sa fokusom na Sorani dijalekt. Mi opisujemo dostupne manje paralelne podatke odgovarajuće za obuku model a prevoda neuronskih strojeva za prevod kurdskih i engleskih suranskih jezika. Također razgovaramo o nekim od velikih izazova na prevodu kurdskih jezika i pokazujemo kako temeljni zadaci obrade teksta, poput tokenizacije, mogu poboljšati učinkovitost prevoda.</abstract_bs>
      <abstract_bn>মেশিন অনুবাদ হচ্ছে একটি ভাষা থেকে আরেকটি কম্পিউটার ব্যবহার করে টেক্সট অনুবাদ করার কাজ। এটা প্রাকৃতিক ভাষা প্রক্রিয়া এবং গণনাত্রিক ভাষার প্রধান কাজ এবং মানুষের যোগাযোগের সুবিধা প্রদানের উদ্দেশ্যে উ ভাষা কম সম্পদের কারণে কুর্দী ভাষায় এই রাজ্যে খুব কম মনোযোগ পেয়েছেন। তাই এই কাগজটিতে আমরা কুর্দি ভাষার জন্য একটি মেশিন অনুবাদ সিস্টেম তৈরি করার প্রধান বিষয়ের বিষয় নিয়ে আলোচনা করছি, যেখানে সোরানি ভাষার আমরা সোরানি কুর্দি ইংরেজী অনুবাদের জন্য নিউরেল মেশিন অনুবাদ মডেল প্রশিক্ষণের জন্য প্রযুক্ত তথ্যের সামান্য সংখ্য আমরা কুর্দি ভাষার অনুবাদের কিছু প্রধান চ্যালেঞ্জ নিয়ে আলোচনা করি এবং প্রদর্শন করি কিভাবে মৌলিক টেক্সট প্রক্রিয়ার কাজ, যেমন টোকান</abstract_bn>
      <abstract_ca>La traducció màquina és la tasca de traduir textos d'una llengua a l'altra utilitzant ordinadors. Ha estat una de les principals tasques en el processament natural del llenguatge i la lingüística computacional i ha estat motivant per facilitar la comunicació humana. El curd, una llengua indoeuropea, ha rebut poca atenció en aquest àmbit degut a que la llengua no té més recursos. Per tant, en aquest article, estem abordant els temes principals de crear un sistema de traducció màquina per a la llengua curda, centrant-nos en el dialecte Sorani. Descrivem les escasses dades paralleles disponibles adequades per a entrenar un model de traducció neural per a la traducció kurda-anglès de Sorani. També discutem alguns dels principals reptes de la traducció de la llengua curda i demostrem com les tasques fonamentals de processament de textos, com la tocenització, poden millorar el rendiment de la traducció.</abstract_ca>
      <abstract_cs>Strojový překlad je úkolem překladu textů z jednoho jazyka do druhého pomocí počítačů. Byl jedním z hlavních úkolů v oblasti zpracování přirozeného jazyka a výpočetní lingvistiky a motivuje k usnadnění lidské komunikace. Kurdština, indoevropský jazyk, se v této oblasti věnovala málo pozornosti, protože jazyk je méně zdrojů. Proto se v tomto článku zabýváme hlavními otázkami vytvoření systému strojového překladu kurdského jazyka se zaměřením na soránský dialekt. Popisujeme dostupná vzácná paralelní data vhodná pro trénink neuronového strojového překladu pro Sorani kurdsko-anglický překlad. Diskutujeme také některé z hlavních výzev v překladu kurdského jazyka a ukazujeme, jak základní úkoly zpracování textu, jako je tokenizace, mohou zlepšit výkon překladu.</abstract_cs>
      <abstract_et>Masintõlge on ülesanne tõlkida tekste ühest keelest teise arvutite abil. See on olnud üks peamisi ülesandeid looduskeele töötlemisel ja arvutuslingvistikas ning on motiveerinud inimeste suhtlemist. Kurdi keel, Indo-Euroopa keel, on selles valdkonnas vähe tähelepanu saanud, kuna keel on vähem ressursse. Seetõttu käsitleme käesolevas dokumendis kurdi keele masintõlkesüsteemi loomise peamisi probleeme, keskendudes Sorani murdele. Kirjeldame kättesaadavaid väheseid paralleelseid andmeid, mis sobivad Sorani kurdi-inglise tõlke neuraalse masintõlke mudeli koolitamiseks. Arutame ka kurdi keele tõlke mõningaid peamisi väljakutseid ja näitame, kuidas põhilised tekstitöötlusülesanded, nagu tokeniseerimine, võivad tõlketõhusust parandada.</abstract_et>
      <abstract_fi>Konek채채nn철s on teht채v채 k채채nt채채 tekstej채 kielelt채 toiselle tietokoneiden avulla. Se on ollut yksi t채rkeimmist채 teht채vist채 luonnollisen kielen k채sittelyss채 ja laskennallisessa kielitieteess채 ja motivoiva helpottaa ihmisten viestint채채. Kurdi, indoeurooppalainen kieli, on saanut v채h채n huomiota t채ll채 alalla, koska kieli on v채hemm채n resursseja. T채m채n vuoksi k채sittelemme t채ss채 asiakirjassa p채채kysymyksi채 kurdin kielen konek채채nn철sj채rjestelm채n luomisessa, jossa keskityt채채n soranin murteeseen. Kuvaamme saatavilla olevia niukkoja rinnakkaistietoja, jotka soveltuvat neurokonek채채nn철smallin kouluttamiseen Soranin kurdi-englanti-k채채nn철kseen. Keskustelemme my철s kurdin kielen k채채nt채misen suurimmista haasteista ja osoitamme, miten keskeiset tekstink채sittelyteht채v채t, kuten tokenisointi, voivat parantaa k채채nn철sten suorituskyky채.</abstract_fi>
      <abstract_jv>Tulungan Mas Rasané awak dhéwé éntuk sing nik nggawe perusahaan anyar tentang karo aléng-aléng karo ingkang kompjuter Kikurde, lenggal manuk-Yuripe, durung kelas nang kana mungkin kuwi jenis mengko awak dhéwé kuwi mau. Kaya, nang mapun iki, kéné bakal nggawe perusahaan langkung panjenengan kanggo nggawe sistem tarjamahan kanggo idiwang kurd, nganggo langkung urip kanggo dialecto Soani. Awakdhéwé éntuk nggambar data yang karo perusahaan banget kanggo nggawe modèl itolet karo perusahaan Neral kanggo tarjamahan surat Kisud-Inggris Awak dhéwé pisan karo perbudhakan langkung wigatining tentang kanggo nggawe tarjamahan karo nggambar cara nggambar textil sing basa, kaya nggambar token, iso nglanggar tarjamahan.</abstract_jv>
      <abstract_sk>Strojno prevajanje je naloga prevajanja besedil iz enega jezika v drugega z uporabo računalnikov. Je ena glavnih nalog v obdelavi naravnega jezika in računalniškem jezikoslovju ter spodbuja človeško komunikacijo. Kurdski jezik, indoevropski jezik, je na tem področju dobil malo pozornosti zaradi manj virov jezika. Zato v tem prispevku obravnavamo glavna vprašanja pri oblikovanju sistema strojnega prevajanja za kurdski jezik s poudarkom na soranskem narečju. Opisujemo razpoložljive redke vzporedne podatke, primerne za usposabljanje modela nevronskega strojnega prevajanja za soransko kurdsko-angleško prevajanje. Razpravljamo tudi o nekaterih glavnih izzivih pri prevajanju kurdskega jezika in prikazujemo, kako lahko temeljne naloge obdelave besedila, kot je žetonizacija, izboljšajo učinkovitost prevajanja.</abstract_sk>
      <abstract_he>תרגום מכונות הוא המשימה של תרגום טקסטים משפה אחת לשפה אחרת באמצעות מחשבים. היא היתה אחת מהמשימות העיקריות בעבודת שפת טבעית והשפת מחשבית והייתה מוטיבציה כדי להקל בתקשורת אנושית. קורדית, שפה אינדו-אירופאית, קיבלה מעט תשומת לב בממלכה הזאת בגלל שפה פחות ממוצעים. לכן, בעיתון הזה, אנחנו מתייחסים לנושאים העיקריים ביצירת מערכת תרגום מכונת לשפה הקורדית, עם התמקדות בדיאלקט סורני. We describe the available scarce parallel data suitable for training a neural machine translation model for Sorani Kurdish-English translation.  אנחנו גם מדברים על חלק מהאתגרים הגדולים בתרגום לשפה הקורדית ולהראות כיצד משימות עיבוד טקסט בסיסיות, כמו טוקניזציה, יכולות לשפר את ההופעה של התרגום.</abstract_he>
      <abstract_ha>translation Tana daga cikin muhimman aikin da ke aiki na fassarar harshen asiyya da lissafan lissafa na lissafa na ƙidãya, kuma ta yi amfani da mutane. Kurdi, a harshen Indo-Yurubi, ya motsa muhimmi kaɗan a cikin wannan mulki sababin harshen da aka ƙara-resource. Saboda haka, cikin wannan takarda, Munã tambayar masu muhimmi a samun ka samun ta'urar da tsarin tarjibu na cikin harshen Kurdi, da fokus a kan dialin Sorani. Tuna bayyana bayani ga data masu iya amfani da daidai da kwamfyuta wanda ya yi amfani da wa wa'anar fassarar mashine na neural wa translation na Sorani Kurdi-Ingiriya. Haƙĩƙa, Munã jãyayya masu ƙaranci cikin fassarar harshen Kurdi kuma Muke nuna jinsi aikin masu aiki na rubutu, kamar sifati, za'a ƙara fassarar fassarar.</abstract_ha>
      <abstract_fil>Ang paglilit ng makina ay gawa ng paglilit ng mga teksto mula sa isang wika hanggang sa ibang paggamit ng mga kompyuter. Isa ito sa mga pangulong gawa sa natural language processing at computational linguistics at nagbibigay-motivasyon upang maganap ang mga komunikasyon ng tao. Ang Kurdish, isang wikang Indo-Europeo, ay tumanggap ng kaunting pakinig sa kaharian dahil sa wikang walang kapangyarihan. Dahil dito, sa papiro na ito, kami ay nagbibigay ng mga pangulong problema sa paglikha ng sistema ng paglilikat ng makina para sa wikang Kurdo, na may focus sa dialecto ng Sorani. Pinapaliwanag namin ang mga may maliit na paralelong datos na katulad para sa pag-aaral ng model ng pagliliwanag ng neural machine para sa pagliliwanag ng Sorani Kurdish-English. Nagsasalita rin naman kami ng ilan sa mga pangulong kaguluhan sa paglilikat ng wikang Kurdo at nagpapakita kung gaano ang mga gawang pang-processing ng teksto, tulad ng tokenizasyon, makapagpapabago ng paglilikat.</abstract_fil>
      <abstract_bo>རྩིས་འཁོར་གྱི་ཡིག་རྗེས་འདི་སྐད་རིགས་གཅིག་ནས་རྩིས་འཁོར་ཐོག དེ་ནི་རང་བཞིན་ཡུལ་གྱི་སྐད་རིགས་ལས་སྦྱོར་བརྩིས་དང་རྩིས་འཁོར་གྱི་སྐད་རིགས་ཆེ་ཤོས་ཀྱི་ལས་ཀ་གཅིག་ཡིན་ནའང་མི་འབྲེ འོད་ལྟ་བུའི་རྒྱལ་ཁབ་ ཨིན་ཌོ་ནོ་ཡུ་རིའི་སྐད་ཡིག་ནང་དུ་ཆ་ཀྱང་ཉུང་བའི་སྐད་རིགས་ལ་བསྟེན་ནས། དེར་བརྟེན། འུ་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ང་ཚོས་རྩ་བའི་དཀའ་ངལ་ཆ་ལུགས་ཀྱི་མ་ལག་ཅིག་གསར་བསྐྲུན་བྱེད་དུ་ཡོད་པ་དང་། སོ་ར་ནི་ཌ ང་ཚོས་Sorani་ཀུར་ཌིས་དབྱིན་ཡིག་ཆ་ལ་སྨུག་ཅིག་གི་མཐུན་རྐྱེན་གྱི་ཐབས་ལམ་གནང་བ་དང་ཉུང་བའི་ཚད་གཞུང་མཚམས་ཡིག ང་ཚོས་ཀུས་ཡིག་སྐད་ཡིག་ནང་དུ་གདོང་ལེན་ཁག་ཅིག</abstract_bo>
      </paper>
    <paper id="15">
      <title>Investigating Low-resource Machine Translation for English-to-Tamil<fixed-case>E</fixed-case>nglish-to-<fixed-case>T</fixed-case>amil</title>
      <author><first>Akshai</first><last>Ramesh</last></author>
      <author><first>Venkatesh</first><last>Balavadhani parthasa</last></author>
      <author><first>Rejwanul</first><last>Haque</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>118–125</pages>
      <abstract>Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural models</a> produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios. Despite some success, none of the present-day benchmarks that have tried to overcome this problem can be regarded as a universal solution to the problem of <a href="https://en.wikipedia.org/wiki/Translation">translation</a> of many low-resource languages. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration. In particular, we produce rankings of our MT systems via a social media platform-based human evaluation scheme, and demonstrate our findings in the low-resource domain-specific text translation task.</abstract>
      <url hash="89533ef3">2020.loresmt-1.15</url>
      <bibkey>ramesh-etal-2020-investigating</bibkey>
    <title_ar>التحقيق في الترجمة الآلية منخفضة الموارد للغة الإنجليزية إلى التاميلية</title_ar>
      <title_pt>Investigando a tradução automática de poucos recursos para inglês para tâmil</title_pt>
      <title_es>Investigación de la traducción automática de pocos recursos para el inglés al tamil</title_es>
      <title_fr>À la recherche de la traduction automatique de l'anglais vers le tamoul</title_fr>
      <title_zh>按英语至泰米尔语低资源机器翻译</title_zh>
      <title_ja>英語からタミル語への低資源機械翻訳の調査</title_ja>
      <title_hi>जांच कम संसाधन मशीन अनुवाद के लिए अंग्रेजी से तमिल के लिए</title_hi>
      <title_ru>Исследование малоресурсного машинного перевода с английского на тамильский</title_ru>
      <title_ga>Imscrúdú a dhéanamh ar Aistriúchán Meaisín ar Acmhainn Íseal don Bhéarla go Tamailis</title_ga>
      <title_ukr>Дослідження малоресурсного машинного перекладу з англійської на тамільську</title_ukr>
      <title_ka>Name</title_ka>
      <title_isl>Investigating Low-resource Machine Translation for English-to-Tamil</title_isl>
      <title_hu>Alacsony erőforrású gépi fordítás vizsgálata angol-tamil nyelvre</title_hu>
      <title_el>Έρευνα χαμηλής περιεκτικότητας σε μηχανική μετάφραση για τα Αγγλικά-στα-Ταμίλ</title_el>
      <title_it>Indagine sulla traduzione automatica a basso contenuto di risorse per l'inglese-tamil</title_it>
      <title_kk>Ағылшын тілінен тамил үшін төмен ресурстар аудармасын зерттеу</title_kk>
      <title_ms>Menyelidiki Terjemahan Mesin Sumber rendah untuk Bahasa Inggeris-ke-Tamil</title_ms>
      <title_ml>ഇംഗ്ലീഷ്- താമിലില്‍ നിന്നും കുറഞ്ഞ വിഭവങ്ങള്‍ മെഷീന്‍ പരിഭാഷപ്പെടുത്തുന്നു</title_ml>
      <title_mt>Investigating Low-resource Machine Translation for English-to-Tamil</title_mt>
      <title_mk>Истражување на машински превод со ниски ресурси за англиски на тамилски</title_mk>
      <title_lt>Mažų išteklių mašinų vertimo anglų kalba į tamilį tyrimas</title_lt>
      <title_mn>Англи-т-Тамиллийн бага ресурс машины хөгжлийн судалгаа</title_mn>
      <title_no>Investigerer omsetjing av lavressursmaskinen for engelsk- til- Tamil</title_no>
      <title_pl>Badanie niskich zasobów tłumaczenia maszynowego dla języka angielskiego na tamilski</title_pl>
      <title_ro>Investigarea traducerii automate cu resurse reduse pentru engleză-tamilă</title_ro>
      <title_sr>Istražujem prevod mašine sa niskim resursima za engleski na tamil</title_sr>
      <title_si>Name</title_si>
      <title_sv>Utredning av maskinöversättning med låg resurs för engelsk-tamil</title_sv>
      <title_so>Tilmaamaha tarjumaadda Ingiriis-to-Tamil</title_so>
      <title_ta>Name</title_ta>
      <title_ur>انگلیسی سے تامیل کے لئے کم رسورس ماشین ترجمہ کا تحقیق کیا جا رہا ہے</title_ur>
      <title_uz>Inglizchadan Tamil uchun Qidirish vositasiName</title_uz>
      <title_vi>Điều tra Cỗ Máy Kiến Tạo Dịch Tiếng Anh đến Tamil</title_vi>
      <title_bg>Разследване на машинен превод с нисък ресурс за английски на тамилски език</title_bg>
      <title_nl>Onderzoek naar Machine Translation met weinig bronnen voor Engels-naar-Tamil</title_nl>
      <title_da>Undersøgelse af maskinoversættelse med lav ressource til engelsk-til-tamil</title_da>
      <title_hr>Istraživanje prevoda mašine s niskim resursima za engleski do tamilski</title_hr>
      <title_de>Untersuchung ressourcenarmer maschineller Übersetzung für Englisch-ins-Tamil</title_de>
      <title_id>Menyelidiki Penerjemahan mesin sumber daya rendah untuk bahasa Inggris-ke-Tamil</title_id>
      <title_ko>영어에서 타밀어까지의 저자원 번역 연구</title_ko>
      <title_sw>Tafsiri kwa Kiingereza-hadi-Tamil</title_sw>
      <title_fa>تحقیقات ترجمه ماشین کم منابع برای انگلیسی به تامیل</title_fa>
      <title_af>Name</title_af>
      <title_tr>Iňlisçe-we-Tamil üçin Az Ressurat Maşynyň terjimesini barlýa</title_tr>
      <title_sq>Hetimi i përkthimit të makinave me burime të ulëta për anglisht në tamil</title_sq>
      <title_hy>Անգլերեն-տամիլ-անգլերեն թարգմանման ցածր ռեսուրսների մեքենայի հետազոտությունը</title_hy>
      <title_am>ምርጫዎች</title_am>
      <title_az>İngilizə-tə-Tamil üçün aşağı çoxlu maşın tərcümünü incidir</title_az>
      <title_bn>ইংরেজি থেকে তামিলের জন্য অনুবাদ অনুবাদ অনুসন্ধান করা হচ্ছে</title_bn>
      <title_cs>Vyšetřování strojového překladu s nízkými zdroji pro angličtinu do tamilštiny</title_cs>
      <title_ca>Investigar traducció de màquines de baix recursos per anglès a tamil</title_ca>
      <title_bs>Istražujem prevod mašine s niskim resursima za engleski do tamilski</title_bs>
      <title_et>Madala ressursiga masintõlke uurimine inglise keelest tamilisse</title_et>
      <title_fi>Vähävaraisen konekäännöksen tutkiminen englanniksi tamiliksi</title_fi>
      <title_ha>@ item Text character set</title_ha>
      <title_sk>Preiskava strojnega prevajanja z nizkimi viri za angleščino v tamilščino</title_sk>
      <title_jv>politenessoffpolite"), and when there is a change ("assertive</title_jv>
      <title_he>חוקר תרגום מכונת משאבים נמוכים לאנגלית לטמיל</title_he>
      <title_bo>དབྱིན་ཡིག་ལས་ཊ་མིལ་ལ་མཚོན་པའི་རྒྱུ་དངོས་ཉུང་བའི་ལག་འཁྱེར་ལ་གཏོང་བ་བཙལ་ཞིབ་བྱེད་པ</title_bo>
      <title_fil>Investigating Low-resource Machine Translation para sa Ingles-to-Tamil</title_fil>
      <abstract_fr>La traduction automatique statistique (SMT), qui était le paradigme dominant dans la recherche en traduction automatique (MT) pendant près de trois décennies, a récemment été remplacée par les approches d'apprentissage profond de bout en bout de la TA. Bien que les modèles neuronaux profonds produisent des résultats de pointe dans de nombreuses tâches de traduction, on constate qu'ils sont moins performants dans les scénarios nécessitant peu de ressources. Malgré un certain succès, aucun des critères actuels qui ont tenté de surmonter ce problème ne peut être considéré comme une solution universelle au problème de la traduction de nombreuses langues à faibles ressources. Dans ce travail, nous étudions les performances de la SMT basée sur des phrases (PB-SMT) et de la TA neuronale (NMT) sur une paire de langues à faibles ressources rarement testée, l'anglais vers le tamoul, en tenant compte d'un domaine de données spécialisé (localisation logicielle). En particulier, nous établissons des classements de nos systèmes de TA via un système d'évaluation humaine basé sur une plateforme de médias sociaux, et nous démontrons nos résultats dans la tâche de traduction de texte spécifique à un domaine à faibles ressources.</abstract_fr>
      <abstract_ar>الترجمة الآلية الإحصائية (SMT) التي كانت النموذج السائد في أبحاث الترجمة الآلية (MT) لما يقرب من ثلاثة عقود قد حلت محلها مؤخرًا مناهج التعلم العميق الشاملة في الترجمة الآلية. على الرغم من أن النماذج العصبية العميقة تنتج نتائج متطورة في العديد من مهام الترجمة ، فقد وجد أنها أقل أداءً في سيناريوهات ضعف الموارد. على الرغم من بعض النجاح ، لا يمكن اعتبار أي من المعايير الحالية التي حاولت التغلب على هذه المشكلة حلاً شاملاً لمشكلة ترجمة العديد من اللغات منخفضة الموارد. في هذا العمل ، نحقق في أداء SMT القائم على العبارة (PB-SMT) و MT العصبية (NMT) على زوج لغوي منخفض الموارد تم اختباره نادرًا ، من الإنجليزية إلى التاميل ، مع أخذ مجال بيانات متخصص (توطين البرامج ) بعين الاعتبار. على وجه الخصوص ، نحن ننتج تصنيفات لأنظمة الترجمة الآلية الخاصة بنا عبر مخطط تقييم بشري قائم على منصة التواصل الاجتماعي ، ونعرض النتائج التي توصلنا إليها في مهمة ترجمة النص الخاصة بمجال محدّد الموارد.</abstract_ar>
      <abstract_es>La traducción automática estadística (SMT), que fue el paradigma dominante en la investigación de la traducción automática (MT) durante casi tres décadas, ha sido sustituida recientemente por los enfoques de aprendizaje profundo de extremo a extremo de la MT. Si bien los modelos neuronales profundos producen resultados de última generación en muchas tareas de traducción, se ha descubierto que tienen un rendimiento inferior en escenarios con pocos recursos. A pesar de cierto éxito, ninguno de los puntos de referencia actuales que han intentado superar este problema puede considerarse una solución universal al problema de la traducción de muchos idiomas de bajos recursos. En este trabajo, investigamos el rendimiento de SMT basado en frases (PB-SMT) y MT neuronal (NMT) en un par de idiomas de pocos recursos poco probado, del inglés al tamil, teniendo en cuenta un dominio de datos especializado (localización de software). En particular, elaboramos clasificaciones de nuestros sistemas de MT a través de un esquema de evaluación humana basado en plataformas de redes sociales y demostramos nuestros hallazgos en la tarea de traducción de textos específicos de dominio de pocos recursos.</abstract_es>
      <abstract_pt>A tradução automática estatística (SMT), que foi o paradigma dominante na pesquisa de tradução automática (MT) por quase três décadas, foi recentemente substituída pelas abordagens de aprendizado profundo de ponta a ponta para MT. Embora os modelos neurais profundos produzam resultados de última geração em muitas tarefas de tradução, eles apresentam baixo desempenho em cenários com poucos recursos. Apesar de algum sucesso, nenhum dos benchmarks atuais que tentaram superar esse problema pode ser considerado uma solução universal para o problema da tradução de muitas línguas de poucos recursos. Neste trabalho, investigamos o desempenho de SMT baseado em frase (PB-SMT) e MT neural (NMT) em um par de idiomas de poucos recursos raramente testado, inglês para tâmil, tomando um domínio de dados especializado (localização de software ) em consideração. Em particular, produzimos classificações de nossos sistemas de MT por meio de um esquema de avaliação humana baseado em plataforma de mídia social e demonstramos nossas descobertas na tarefa de tradução de texto específica de domínio de poucos recursos.</abstract_pt>
      <abstract_zh>三十年来,计机器翻译(SMT)素机器翻译(MT)主导范式,近为机器翻译端深度学术所代。 虽深神经于译事之中,皆先进也,其於资源匮乏也。 虽有成功,然目前试克之,皆不可视为多资匮语译之普遍办法。 于此之事,究其短语之SMT(PB-SMT)、神经MT(NMT)之少试英语至于泰米尔语,兼思专数(软件本地化)。 特以社交媒体平台之工评方案,机器翻译系统排名,并展于资源匮乏之域特定文本译职之中。</abstract_zh>
      <abstract_ja>機械翻訳（ MT ）研究で30年近く支配的なパラダイムであった統計的機械翻訳（ SMT ）は、最近、MTへのエンドツーエンドの深層学習アプローチに取って代わられている。深部ニューラルモデルは、多くの翻訳タスクで最先端の結果を生み出すが、リソース不足のシナリオではパフォーマンスが低いことがわかった。いくつかの成功にもかかわらず、この問題を克服しようとした現在のベンチマークは、多くの低資源言語の翻訳の問題に対する普遍的な解決策と見なすことはできません。この研究では、専門的なデータドメイン（ソフトウェアローカリゼーション）を考慮して、稀にテストされた低リソース言語ペア、英語からタミル語へのSMT （ PB - SMT ）とニューラルMT （ NMT ）のパフォーマンスを調査します。特に、ソーシャルメディアプラットフォームベースの人間評価スキームを介してMTシステムのランキングを作成し、低リソースドメイン固有のテキスト翻訳タスクで調査結果を実証します。</abstract_ja>
      <abstract_hi>सांख्यिकीय मशीन अनुवाद (एसएमटी) जो लगभग तीन दशकों तक मशीन अनुवाद (एमटी) अनुसंधान में प्रमुख प्रतिमान था, हाल ही में एमटी के लिए अंत-से-अंत गहरे सीखने के दृष्टिकोण से हटा दिया गया है। यद्यपि गहरे तंत्रिका मॉडल कई अनुवाद कार्यों में अत्याधुनिक परिणामों का उत्पादन करते हैं, वे संसाधन-खराब परिदृश्यों पर अंडर-परफॉर्म करने के लिए पाए जाते हैं। कुछ सफलता के बावजूद, वर्तमान बेंचमार्क में से कोई भी इस समस्या को दूर करने की कोशिश नहीं की गई है, जिसे कई कम-संसाधन भाषाओं के अनुवाद की समस्या के लिए एक सार्वभौमिक समाधान के रूप में माना जा सकता है। इस काम में, हम वाक्यांश-आधारित एसएमटी (पीबी-एसएमटी) और तंत्रिका एमटी (एनएमटी) के प्रदर्शन की जांच करते हैं, जो शायद ही कभी कम-संसाधन भाषा-जोड़ी, अंग्रेजी-से-तमिल पर परीक्षण किया जाता है, एक विशेष डेटा डोमेन (सॉफ़्टवेयर स्थानीयकरण) को ध्यान में रखते हुए। विशेष रूप से, हम एक सोशल मीडिया प्लेटफ़ॉर्म-आधारित मानव मूल्यांकन योजना के माध्यम से अपने एमटी सिस्टम की रैंकिंग का उत्पादन करते हैं, और कम-संसाधन डोमेन-विशिष्ट पाठ अनुवाद कार्य में हमारे निष्कर्षों का प्रदर्शन करते हैं।</abstract_hi>
      <abstract_ru>Статистический машинный перевод (SMT), который был доминирующей парадигмой в исследованиях машинного перевода (MT) в течение почти трех десятилетий, недавно был заменен сквозными подходами к глубокому обучению MT. Хотя глубокие нейронные модели дают самые современные результаты во многих задачах перевода, они оказываются неэффективными при сценариях с ограниченными ресурсами. Несмотря на некоторый успех, ни один из нынешних контрольных показателей, которые пытаются преодолеть эту проблему, не может рассматриваться как универсальное решение проблемы перевода многих языков с ограниченными ресурсами. В этой работе мы исследуем производительность основанных на фразе SMT (PB-SMT) и нейронного MT (NMT) на редко тестируемой малоресурсной языковой паре английский-тамильский, принимая во внимание специализированную область данных (локализацию программного обеспечения). В частности, мы составляем рейтинги наших систем MT с помощью основанной на платформе социальных сетей схемы оценки человеческого потенциала и демонстрируем наши результаты в задаче перевода текста с низким объемом ресурсов.</abstract_ru>
      <abstract_ukr>Статистичний машинний переклад (SMT), який був домінуючою парадигмою в дослідженні машинного перекладу (MT) протягом майже трьох десятиліть, нещодавно був витіснений кінцевими підходами до глибокого навчання MT. Хоча глибинні нейронні моделі дають найсучасніші результати в багатьох завданнях перекладу, вони, як виявилося, недостатньо ефективні для сценаріїв з низьким рівнем ресурсів. Незважаючи на певний успіх, жоден із сучасних орієнтирів, які намагалися подолати цю проблему, не можна розглядати як універсальне рішення проблеми перекладу багатьох малоресурсних мов. У цій роботі ми досліджуємо продуктивність SMT (PB-SMT) та нейронного MT (NMT) на основі фраз на рідкісно перевіреній низькоресурсній мовній парі, англійсько-тамільській, беручи до уваги спеціалізовану область даних (локалізацію програмного забезпечення). Зокрема, ми складаємо рейтинги наших систем МП за допомогою схеми оцінки людини на основі платформи соціальних медіа та демонструємо наші результати у завданні перекладу тексту з низьким рівнем ресурсів.</abstract_ukr>
      <abstract_ga>Tá an t-aistriúchán meaisín staidrimh (SMT), a bhí ar an bparadigm ceannasach i dtaighde ar aistriúchán meaisín (MT) le beagnach trí scór bliain, curtha in ionad na cuir chuige domhainfhoghlama ceann go ceann i leith MT le déanaí. Cé go n-eascraíonn samhlacha néaracha doimhin torthaí úrscothacha i go leor tascanna aistriúcháin, faightear amach go bhfuil tearcfheidhmíocht acu ar chásanna nach bhfuil mórán acmhainní acu. In ainneoin roinnt rathúlachta, ní féidir breathnú ar aon cheann de na tagarmharcanna reatha a rinne iarracht an fhadhb seo a shárú mar réiteach uilíoch ar fhadhb aistriúcháin go leor teangacha íseal-acmhainne. San obair seo, déanaimid imscrúdú ar fheidhmíocht SMT frása-bhunaithe (PB-SMT) agus MT néarúil (NMT) ar phéire teanga-acmhainní íseal, Béarla go Tamailis a ndéantar tástáil orthu go hannamh, ag glacadh le sainfhearann sonraí (logánú bogearraí ) san áireamh. Go háirithe, déanaimid rátálacha dár gcórais MT a tháirgeadh trí scéim mheastóireachta daonna atá bunaithe ar ardán meán sóisialta, agus léirímid ár dtorthaí sa tasc aistriúcháin téacs a bhaineann go sonrach le fearann a bhfuil acmhainní íseal aige.</abstract_ga>
      <abstract_ka>Statistical machine translation (SMT), რომელიც იყო დომინტური პარადიგმა მანქანის განგორმაციაში (MT) სწავლის შემდეგ სამი ათწლის განმავლობაში, მხოლოდ მხოლოდ სამი ათწლის განმავლობაში, MT-ს მიღებული ძალიან ძალიან სწავლის მიღებები. მაგრამ ძალიან ნეიროლური მოდელები ამ პრობლემას წარმატებით არაფერი წარმატებით, რომლებიც ამ პრობლემას გადავიწყებენ, უნდა იყოს უნივერსალური პასუხისთვის მრავალური რესურსის წარმატებისთვის. ამ სამუშაოში, ჩვენ განსხვავებთ ფრაზების SMT (PB-SMT) და ნეირალური MT (NMT) მუშაობით ცოტა რესურსის სახელი, ანგლისური-დან-ტამილზე, სპეციალური მონაცემების დიომინის (პროგრამიზაცია ლოკალიზაცია) პროგ განსაკუთრებულია, ჩვენ MT სისტემის რენგენციები სოციალური მედია პლატატიფიკაციის სქემის გამოყენება და ჩვენი მონაცემები ჩვენი მონაცემებით სპეციფიკალური ტექსტის განსაგ</abstract_ka>
      <abstract_hu>A statisztikai gépi fordítás (SMT), amely közel három évtizeden át domináns paradigmája volt a gépi fordítás (MT) kutatásában, a közelmúltban felváltották a végpontos mélytanulási megközelítések a MT. Bár a mélyneurális modellek számos fordítási feladatban a legkorszerűbb eredményeket eredményeznek, úgy találták, hogy nem teljesítenek erőforrásszegény forgatókönyveken. Bizonyos sikerek ellenére a jelenlegi referenciaértékek egyike sem tekinthető univerzális megoldásnak számos alacsony forrású nyelv fordításának problémájára. Ebben a munkában a kifejezésalapú SMT (PB-SMT) és neurális MT (NMT) teljesítményét vizsgáljuk egy ritkán tesztelt, alacsony erőforrású nyelvpáron, angol-tamil nyelven, figyelembe véve egy speciális adat domaint (szoftver lokalizáció). Különösen egy közösségi média platformon alapuló emberi értékelési rendszer segítségével állítjuk elő MT rendszereink rangsorolását, és bemutatjuk eredményeinket az alacsony erőforrású domain-specifikus szövegfordítási feladatban.</abstract_hu>
      <abstract_isl>Tölfræðileg þýðing véla (SMT) sem var yfirvaldandi paradigm í þýðingu véla (MT) í næstum þrjá áratugi hefur nýlega verið skipt yfir með lok til lok djúpt læring nálægt MT. Þótt djúp taugalíkanir framleiða state-of-the-art niðurstöður í mörgum þýðingarverkum, finnst að þær eru ófullnægjandi á auðlindafátækum tilvikum. Þrátt fyrir nokkra árangur er ekki hægt a ð líta á nein núverandi viðmiðunarmarka sem hafa reynt að komast yfir þetta vandamál sem alþjóðleg lausn á vandamálið með þýðingu margra tungumál með lítil áhrif. Í þessu verki rannsakum við framkvæmd SMT (PB-SMT) og taugaMT (NMT) á sjaldgæfum prófum litlum upprunalegum tungumál-par, ensku-til-tamíl, með tilliti til sérstakra gagnasvæða (staðsetning forritis). Sérstaklega framleiðum við flokkun á MT kerfum okkar með samfélagslegum fjölmiðlunarplattformum sem byggir á mat á mönnum og sýnum niðurstöður okkar í textaverkunni sem hefur lítið efni á sértækum textaverkunum.</abstract_isl>
      <abstract_el>Η στατιστική μηχανική μετάφραση (το οποίο ήταν το κυρίαρχο παράδειγμα στην έρευνα για σχεδόν τρεις δεκαετίες έχει πρόσφατα αντικατασταθεί από τις ολοκληρωμένες προσεγγίσεις βαθιάς μάθησης στη Παρόλο που τα βαθιά νευρωνικά μοντέλα παράγουν αποτελέσματα τελευταίας τεχνολογίας σε πολλές μεταφραστικές εργασίες, διαπιστώνεται ότι δεν αποδίδουν σε σενάρια φτωχά σε πόρους. Παρά ορισμένες επιτυχίες, κανένα από τα σημερινά κριτήρια αναφοράς που προσπάθησαν να ξεπεράσουν αυτό το πρόβλημα δεν μπορεί να θεωρηθεί καθολική λύση στο πρόβλημα της μετάφρασης πολλών γλωσσών χαμηλού πόρου. Σε αυτή την εργασία, διερευνούμε την απόδοση του με βάση φράσεις (PB-SMT) και του νευρικού ΜΤ (NMT) σε ένα σπανίως δοκιμασμένο γλωσσικό ζεύγος χαμηλής περιεκτικότητας, Αγγλικά-Ταμίλ, λαμβάνοντας υπόψη έναν εξειδικευμένο τομέα δεδομένων (εντοπισμός λογισμικού). Ειδικότερα, παράγουμε βαθμολογίες των συστημάτων μας μέσω ενός συστήματος ανθρώπινης αξιολόγησης βασισμένου σε πλατφόρμες κοινωνικών μέσων και καταδεικνύουμε τα ευρήματά μας στο έργο μετάφρασης κειμένου με χαμηλούς πόρους.</abstract_el>
      <abstract_it>La traduzione automatica statistica (SMT), che è stata il paradigma dominante nella ricerca della traduzione automatica (MT) per quasi tre decenni, è stata recentemente sostituita dagli approcci end-to-end di deep learning alla MT. Sebbene i modelli neurali profondi producano risultati all'avanguardia in molte attività di traduzione, si è scoperto che non funzionano in modo adeguato su scenari poveri di risorse. Nonostante qualche successo, nessuno degli attuali parametri di riferimento che hanno cercato di superare questo problema può essere considerato una soluzione universale al problema della traduzione di molte lingue a basso contenuto di risorse. In questo lavoro, analizziamo le prestazioni di SMT (PB-SMT) e MT neurale (NMT) su una coppia di lingue a basso consumo raramente testata, dall'inglese al tamil, prendendo in considerazione un dominio di dati specializzato (localizzazione software). In particolare, produciamo classifiche dei nostri sistemi MT tramite uno schema di valutazione umana basato su piattaforme di social media e dimostriamo i nostri risultati nell'attività di traduzione di testo specifica del dominio a basso contenuto di risorse.</abstract_it>
      <abstract_kk>Статистикалық машинаны аудару (SMT) деген компьютердің аудару (MT) зерттеулерінің доминистік парадигмі (MT) деген жақын үш жылдық жылдық зерттеулері MT- ге жақын аяқтау арқылы өзгертілді. Алыс невралдық моделдері көп аудару тапсырмаларды жасағанда, олар ресурстар күш сцен Кейбір сәттіліктерге қарамастан, бұл мәселеді көтеру үшін қазіргі кезіндегі баптаулардың көп ресурс тілдерінің аудару мәселесіне әдетті шешім болмайды. Бұл жұмыс ішінде біз фраза негізінде SMT (PB-SMT) және невралдық MT (NMT) және невралдық тілдер мен ағылшын тілден тамил тілдерінің тескерілігін зерттеп, өзгертілген деректер доменін (бағдарлама локализациясы) қарастырмыз. Мәселе, біз MT жүйелерімізді социалдық медиа платформасындағы адамды оқу сұлбасы арқылы жасап, олардың іздеулерімізді доменге арналған мәтін аудару тапсырмасында көрсетеді.</abstract_kk>
      <abstract_lt>Statistinis mašin ų vertimas (SMT), kuris beveik tris dešimtmečius buvo dominuojantis mašinų vertimo (MT) mokslinių tyrimų paradigmas, neseniai buvo pakeistas baigiamuoju giliavandenio mokymosi metodu MT. Nors giliavandenių nervų modelių rezultatai yra pažangiausi daugelio vertimo užduočių metu, nustatyta, kad jie yra nepakankamai veiksmingi dėl nepakankamų išteklių scenarijų. Nepaisant tam tikros sėkmės, nė vienas iš dabartinių lyginamųjų rodiklių, kurie bandė įveikti šią problem ą, negali būti laikomas universaliu daugelio mažai išteklių turinčių kalbų vertimo problemos sprendimu. Šiame darbe tiriame frazėmis pagrįsto SMT (PB-SMT) ir neurologinio MT (NMT) rezultatus retai išbandytoje mažai išteklių turinčioje kalbų poroje anglų–tamilų kalbomis, atsižvelgiant į specializuotą duomenų sritį (programinės įrangos lokalizaciją). Visų pirma rengiame MT sistemų klasifikacijas pagal social in ės žiniasklaidos platformomis grindžiamą žmogaus vertinimo sistemą ir parodysime savo išvadas, susijusias su mažai išteklių turinčia konkrečia teksto vertimo užduotimi.</abstract_lt>
      <abstract_mk>Статистичкиот машински превод (СМТ), кој беше доминантниот парадигм во машинските преводи (МТ) истражувања скоро три децении, неодамна е заменет со крајните пристапи на длабоко учење кон МТ. Иако длабоките невронски модели произведуваат најсовремени резултати во многу преводни задачи, се открива дека тие се недостасуваат на сцен И покрај одреден успех, ниту еден од сегашните референтни значки кои се обидоа да го надминат овој проблем не може да се смета за универзално решение на проблемот на преводот на многу јазици со ниски ресурси. Во оваа работа, ја истражуваме изведбата на СМТ (ПБ-СМТ) и нервен МТ (НМТ) базирани на фрази на ретко тестиран пар јазик со ниски ресурси, англиски до тамилски, земајќи во предвид специјализиран домен на податоци (софтверска локализација). Особено, ние произведуваме рангирање на нашите МТ системи преку шема на човечка проценка базирана на социјалните медиуми, и ги демонстрираме нашите откритија во задачата за превод на текст специфична за ниски ресурси.</abstract_mk>
      <abstract_ms>Terjemahan mesin statistik (SMT) yang merupakan paradigma dominan dalam kajian terjemahan mesin (MT) selama hampir tiga dekad baru-baru ini telah digantikan oleh pendekatan belajar dalam akhir-akhir ke akhir ke MT. Walaupun model saraf dalam menghasilkan keputusan-state-of-the-art dalam banyak tugas terjemahan, mereka ditemukan untuk melaksanakan dalam skenario yang kurang sumber. Walaupun beberapa kejayaan, tiada tanda referensi hari ini yang telah cuba untuk mengatasi masalah ini boleh dianggap sebagai penyelesaian universal untuk masalah terjemahan bahasa yang banyak sumber rendah. Dalam kerja ini, kami menyelidiki prestasi SMT (PB-SMT) berdasarkan frasa dan MT saraf (NMT) pada pasangan bahasa-sumber rendah-diuji yang jarang diuji, bahasa-bahasa-ke-Tamil, mempertimbangkan domain data khas (lokasi perisian). Secara khususnya, kami menghasilkan rangkaian sistem MT kami melalui skema penilaian manusia berdasarkan platform media sosial, dan menunjukkan penemuan kami dalam tugas terjemahan teks khusus-sumber rendah.</abstract_ms>
      <abstract_ml>മെഷീന്‍ പരിഭാഷത്തിന്റെ (എംടി) പരിശോധനത്തിന്റെ പ്രധാനപ്പെട്ട സ്റ്റേറ്റിസ്റ്റിക്കല്‍ മെഷീന്‍ പരിഭാഷണമായിരുന്നു. അടുത്ത മൂന്ന് decades അവസാനം മുതല്‍ ആഴമുള്ള വിദ്യാഭ്യാസത്തിന്റെ അടുത്ത് മാറ്റി എന്തെങ്കിലും വിജയകരമായാലും ഈ പ്രശ്നം ജയിക്കാന്‍ ശ്രമിച്ചിട്ടുള്ള ബെന്‍മാര്‍ക്കുകളില്‍ ഒരു പ്രധാനപ്പെട്ട പരിഭാഷയായി നിരീക്ഷ ഈ പ്രവര്‍ത്തനത്തില്‍ ഞങ്ങള്‍ വാക്ക് അടിസ്ഥാനമാക്കിയ SMT (PB-SMT) പിന്നെ ന്യൂറല്‍ MT (NMT) പ്രവര്‍ത്തനത്തെ അന്വേഷിക്കുന്നു. കുറച്ച് പരീക്ഷിക്കപ്പെട്ട വിഭവങ്ങളുടെ ഭാഷ ഇണകള്‍, ഇ പ്രത്യേകിച്ച്, നമ്മുടെ MT സിസ്റ്റത്തിന്റെ രാജ്യങ്ങള്‍ നമ്മുടെ സാമൂഹ്യ മീഡിയ പ്ലാറ്റ്ഫോമില്‍ അടിസ്ഥാനമായി മനുഷ്യരുടെ വിന്യാജപ്രക്രിയ</abstract_ml>
      <abstract_mt>It-traduzzjoni tal-makkinarju statistiku (SMT) li kienet il-paradigma dominanti fir-riċerka tat-traduzzjoni tal-makkinarju (MT) għal kważi tliet deċennji reċentement ġiet sostitwita mill-approċċi ta’ tagħlim profond ta’ tmiem sa tmiem għall-MT. Għalkemm mudelli newrali profondi jipproduċu riżultati l-aktar avvanzati f’ħafna kompiti ta’ traduzzjoni, instabu li ma jwettqux biżżejjed fuq xenarji fqira fir Minkejja xi suċċess, l-ebda wieħed mill-punti ta’ riferiment attwali li ppruvaw jegħlbu din il-problem a ma jista’ jitqies bħala soluzzjoni universali għall-problema tat-traduzzjoni ta’ ħafna lingwi b’riżorsi baxxi. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration.  B’mod partikolari, nipproduċu klassifikazzjonijiet tas-sistemi MT tagħna permezz ta’ skema ta’ evalwazzjoni umana bbażata fuq pjattaforma tal-midja soċjali, u nippruvaw is-sejbiet tagħna fil-kompitu tat-traduzzjoni tat-test speċifiku għall-qasam b’riżorsi baxxi.</abstract_mt>
      <abstract_mn>Машин хөрөнгө оруулах (MT) судалгааны статистикийн машин хөрөнгө оруулах (SMT) нь ойролцоогоор гурван жилийн турш машин хөрөнгө оруулах парадигм байсан юм. МТ-ийн хамгийн гүн гүнзгий суралцах ойлголтын тулд саяхан өнгөрсөн арга загвар нь олон төрлийн хөрөнгө оруулах үйлдлийн үр дүн Зарим амжилтыг хүртэл, энэ асуудлыг даван туслахыг хичээсэн орчин үеийн тохиолдолд хэн ч бага боловсролын хэлний орчуулалтын асуудлын ертөнцөд шийдэл гэж үзэх боломжгүй. Энэ ажил дээр бид хэлбэртэй SMT (PB-SMT) болон мэдрэлийн MT (NMT) ховор шалгалтын бага хэлбэртэй хэлний хоёр, Англи-ээс Тамил болон ялангуяа өгөгдлийн холбоо (програм хангамжийн оролцоог) судалж байлаа. Ялангуяа бид нийгмийн медиа хэвлэлийн платформ дээр хүн төрөлхтний оюутнуудын төлөвлөгөөс MT системийн цуврал бүтээж, мөн бидний ололтуудыг бага нөөцийн домжтой хэмжээний текст хэвлэлийн ажил дээр</abstract_mn>
      <abstract_no>Statistiske maskinsomsetjing (SMT) som var dominerende paradigma i maskinsomsetjinga (MT) forskning i nesten tre tiånader er nyleg overført av dei dype læringstilnærmingane til MT. Selv om dype neuralmodeller produserer status-of-the-art resultater i mange omsetjingsprogrammer, finn dei under utføring av ressurs-poor scenarioar. Til tross nokre suksess kan ingen av den gjeldande benchmarken som har prøvd å overføra dette problemet bli kalla til ein universell løysing til problemet med omsetjing av mange låg ressursspråk. I denne arbeida undersøker vi utføringen av frasebasert SMT (PB-SMT) og neural MT (NMT) på ein rart testert låg ressursspråk-par, English-to-Tamil, og ta opp eit spesialisert datadomene (programvarlokalisering). I særskilt produserer vi rankingar av MT-systemet våre via eit menneskelig evalueringsplan på sosialmedia-plattform, og demonstrerer våre opplysningar i den låg ressursdomene-spesifikke tekstomsetjinga.</abstract_no>
      <abstract_ro>Traducerea automată statistică (SMT), care a fost paradigma dominantă în cercetarea de traducere automată (MT) timp de aproape trei decenii, a fost recent înlocuită de abordările end-to-end de învățare profundă a MT. Deși modelele neuronale profunde produc rezultate de ultimă oră în multe sarcini de traducere, se descoperă că acestea nu funcționează în scenarii lipsite de resurse. În ciuda unui anumit succes, niciunul dintre criteriile actuale care au încercat să depășească această problemă nu poate fi considerat o soluție universală la problema traducerii multor limbi cu resurse reduse. În această lucrare, investigăm performanța SMT bazată pe fraze (PB-SMT) și MT neural (NMT) pe o pereche de limbi rareori testate cu resurse reduse, engleză-tamil, luând în considerare un domeniu specializat de date (localizarea software). În special, producem clasamente ale sistemelor noastre MT printr-o schemă de evaluare umană bazată pe platforma de social media și demonstrăm constatările noastre în sarcina de traducere a textului specifică domeniului cu resurse reduse.</abstract_ro>
      <abstract_pl>Statystyczne tłumaczenie maszynowe (SMT), które było dominującym paradygmatem w badaniach nad tłumaczeniem maszynowym (MT) przez prawie trzy dekady, zostało ostatnio zastąpione przez kompleksowe podejście do głębokiego uczenia się do MT. Chociaż głębokie modele neuronowe dają najnowocześniejsze wyniki w wielu zadań tłumaczeniowych, stwierdza się, że są one niewystarczające w przypadku scenariuszy niskiej ilości zasobów. Pomimo pewnego sukcesu żaden z obecnych wskaźników odniesienia, które próbowały przezwyciężyć ten problem, nie może być uznany za uniwersalne rozwiązanie problemu tłumaczenia wielu języków o niskich zasobach. W niniejszej pracy badamy wydajność fraze-based SMT (PB-SMT) i neuronowego MT (NMT) na rzadko testowanej parze językowej, angielsko-tamilskiej, biorąc pod uwagę specjalistyczną domenę danych (lokalizacja oprogramowania). W szczególności tworzymy rankingi naszych systemów MT za pośrednictwem platformy mediów społecznościowych opartej na systemie oceny ludzkiej i demonstrujemy nasze wyniki w zakresie niskich zasobów zadania tłumaczenia tekstów specyficznych dla danej domeny.</abstract_pl>
      <abstract_sr>Statistički prevod mašine (SMT) koji je bio dominantna paradigma u istraživanju prevoda mašine (MT) skoro tri desetljeća nedavno je zamijenjen pristupima dubokog učenja MT-u. Iako duboki neuronski modeli proizvode stanje umjetnosti rezultate u mnogim prevodnim zadacima, nalaze se da su pod izvršenjem scenarija siromašnih resursa. Uprkos nekim uspjehom, nijedna od današnjih kriterija koji su pokušali da prevare ovaj problem ne može biti smatrana univerzalnim rješenjem problem a prevođenja mnogih jezika niskih resursa. U ovom poslu istražujemo provedbu fraza baziranog SMT (PB-SMT) i neuralnog MT (NMT) na rijetko testiranom parom jezika sa niskim resursima, engleskog do Tamil a, uzimajući u obzir specijalizovanu domenu podataka (lokalizacija softvera). Posebno, proizvodimo redove našeg MT-sistema putem režima ljudske procjene na platformi socijalnih medija, i pokazujemo naše nalaze u zadatku prevoda teksta specifičnog domena niskih resursa.</abstract_sr>
      <abstract_sv>Statistisk maskinöversättning (SMT), som var det dominerande paradigmet inom maskinöversättning (MT) forskning i nästan tre decennier, har nyligen ersatts av djupinlärningsmetoder för MT. Även om djupa neurala modeller ger state-of-the-art resultat i många översättningsuppgifter, har de visat sig underprestera på resursfattiga scenarier. Trots vissa framgångar kan ingen av dagens riktmärken som har försökt övervinna detta problem betraktas som en universell lösning på problemet med översättning av många språk med låg resurs. I detta arbete undersöker vi prestandan av frasbaserad SMT (PB-SMT) och neural MT (NMT) på ett sällan testat lågresursspråkpar, engelska-till-tamil, med beaktande av en specialiserad datadomän (programvarulikalisering). Framför allt producerar vi rankningar av våra MT-system via ett socialt medieplattformsbaserat mänskligt utvärderingssystem och demonstrerar våra resultat i den domänspecifika textöversättningsuppgiften med låg resurs.</abstract_sv>
      <abstract_si>ස්ථානික පණිවිඩය (SMT) කිරීමේ පණිවිඩය (MT) පරීක්ෂණයේ ප්‍රධාන පාර්ඩිග්ම වෙනුවෙන් පරීක්ෂණය ගොඩක් දහස් තුනක් වෙනුවෙන් අවසානය කරලා තියෙන්නේ. ගොඩක් න්‍යූරාල් මොඩේල්ස මේ ප්‍රශ්නයක් ප්‍රශ්නයක් නැත්තම්, මේ ප්‍රශ්නයක් ප්‍රශ්නයක් නිසා කිසිම ප්‍රශ්නයක් විතරක් හිතන්න පුළුවන් විශේෂ මේ වැඩේ අපි පරීක්ෂණය කරනවා ප්‍රශ්නයක් අධාරිත SMT (PB-SMT) සහ න්‍යූරාල MT (NMT) වලින් පරීක්ෂණය කරලා ප්‍රශ්නයක් පරීක්ෂණය කරලා තියෙන්නේ අංග්‍රීසිය ව විශේෂයෙන්, අපි අපේ MT පද්ධතියේ පද්ධතිය සාමාජික මිඩියාව පද්ධතියෙන් මිනිස්සු විශ්ලේෂණ පද්ධතියෙන් ප්‍රවේශනය කර</abstract_si>
      <abstract_so>Turjumista takhasuska machine (SMT) oo ahaa baaritaanka ugu sarreeya baaritaanka machine (MT) baaritaanka ugu dhowaad saddex sano ayaa lagu gudbiyey muddo ugu dhow saddex sano oo dhammaad-to-end waxbarasho deegaan u soo jeeda MT. In kastoo modellada deep neural ah ay soo saaraan state-of-art results in badan tasks tarjuman, waxaa laga helaa hoos-performed on resource-poor scenarios. Inta kastoo uu guulaysto qaar suurtagal ah, marna mid kamid ah oo isku dayay in ay dhibaatadan ka adkaystaan looma tirin karo sida xal caalami ah oo turjumaadda luuqado badan oo hoose-resource ah. Markaas waxan, waxaynu ka baaraynaa sameynta SMT (PB-SMT) iyo neural MT (NMT) oo lagu tijaabiyey luqada hoose-resource noocyo yar, Ingiriis-to-Tamil, waxaana ka fiirsanaynaa domain gaar ah (Software localisation). Si gaar ah, waxaynu nidaamka MT ku soo bandhignaa qorshaha qiimeynta dadka ee shabakadda bulshada ah, waxaana muujinaynaa falimahayaga ku qoran macluumaadka tarjumaadda ee hoos-maalmeedka.</abstract_so>
      <abstract_ta>புள்ளிவிவரமான இயந்திரம் மொழிபெயர்ப்பு (MT) என்பது கணினி மொழிபெயர்ப்பில் மொழிமாற்றம் (MT) ஆராய்ச்சியில் மிக மூன்று ஆண்டுகளுக்கு சமீபத்தில் முடிவில் இருந்து முடிவு ஆழமான கல்வி மொழிமாற்றம் MT- க சில வெற்றியடைந்தாலும், இந்த பிரச்சனையை வெற்றியடையும் தற்போதைய நாளில் எந்த பிரச்சனையும் முயற்சித்துள்ள பிரச்னையின் ம இந்த வேலையில், நாம் ஒரு குறைவாக சோதிக்கப்பட்ட குறைந்த மூலத்தின் ஜோடி, ஆங்கிலத்தில் இருந்து தாமில், சிறப்பு தகவல் தளம் (மென்பொருள் localization) எடுத்து கொள்ள வேண்டிய சொற்றொடர் சார்ந குறிப்பிட்டு, நாம் எங்கள் MT அமைப்புகளின் வரிசைகளை உருவாக்குகிறோம் ஒரு சமூக ஊடக முறைமையில் சார்ந்த மனித பரிசோதனை முறைமையில் மூலம், குறிப்ப</abstract_ta>
      <abstract_ur>Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades recently replaced by the end-to-end deep learning approaches to MT. Although deep neural models produce state-of-the-art tasks in many translation tasks, they are found to be underperformed on resource-poor scenarios. کچھ موفقیت کے بغیر، آج کے دن میں سے کوئی سنچمارک نہیں ہے جو اس مسئلہ پر غالب رہنے کی کوشش کرتی ہے، بہت سے کم منطقی زبانوں کی ترجمہ کے مسئلہ کے لئے ایک عمومی حل سمجھ سکتا ہے. اس کام میں ہم نے فریزوں کی بنیادی SMT (PB-SMT) اور نیورال MT (NMT) کی پرورشش کی تحقیق کی تھی ایک کم آزمائش کی کم منبع زبان جوڑی، انگلیسی-سے تامیل، ایک مخصوص ڈاٹ ڈومین (سوفٹیور لکولایزی) کے ذریعہ مطالبہ کر لیا۔ مخصوصاً ہم اپنے MT سیستموں کی رانڈنگ پیدا کرتے ہیں ایک سوسیل میڈیا میڈیا پٹروم پر بنیاد رکھی ہوئی انسان کی ارزیابی طرح کے ذریعہ، اور ہمارے نتیجے کم-resource domain-specific text translation task میں دکھاتے ہیں.</abstract_ur>
      <abstract_uz>Masofadagi tarjima tarjima (MT) asosiy tarjima qilingan statistik tarjima (SMT) yangi 3 yil davomida yaqinda uchta yil ichida o'rganish muvaffaqiyatlarini MT'ga o'rganish muvaffaqiyatlariga o'zgartirdi. Chunki juda uzun neyural modellari ko'plab tarjima vazifalarining holati tarjima qilishi natijalariga bajariladi, ularni resource-poor scenarioslarida bajariladi. @ info: whatsthis Bu vazifani biz juda qisqa sinab ko'p imkoniyatlarni ingliz tildan Tamil tilidan qo'yilgan so'zlar asosida SMT (PB-SMT) va neyural MT (NMT) bajariladigan imkoniyatlarini aniqlamiz. Shunday qilib, biz jamiyat media platformidagi inson qiymatning qolipi orqali MT tizimlarimizning chegaralarini yaratib, va bizning natijalarimizni qidirish imkoniyatlarimizni yaratdik.</abstract_uz>
      <abstract_vi>Dịch vụ máy tính thống kê (SMT) đã là biểu tượng chủ yếu trong nghiên cứu về dịch chuyển cỗ máy gần ba thập kỷ gần đây đã bị thay thế bởi các phương pháp học sâu đến kết thúc của kênh MTV. Mặc dù các mô hình thần kinh sâu có kết quả tối tân trong nhiều công việc dịch chuyển, nhưng chúng được tìm thấy chưa thực hiện được trong các viễn cảnh nghèo đói tài nguyên. Bất chấp một số thành công, không những tiêu chuẩn ngày nay đã cố gắng để vượt qua vấn đề này có thể được coi là một giải pháp chung cho vấn đề dịch thuật của nhiều ngôn ngữ nghèo. Trong công việc này, chúng tôi điều tra khả năng kết quả của kênh SMT từ điển thành ngữ (PB-SMT) và mạng lưới thần kinh (NMB) trên một đôi ngôn ngữ ít được kiểm tra, English-to-Tamil, lấy một miền dữ liệu chuyên biệt (cục bộ phần mềm) trong cân nhắc. Chúng tôi sản xuất hạng các phương tiện truyền thông qua một kế hoạch đánh giá nhân loại dựa trên các phương tiện truyền thông xã hội, và chứng minh những phát hiện của chúng tôi trong nhiệm vụ dịch văn bản nông nổi.</abstract_vi>
      <abstract_bg>Статистическият машинен превод (СМТ), който е доминиращата парадигма в изследванията за машинен превод (МТ) в продължение на почти три десетилетия, наскоро е заменен от подходите на задълбочено обучение към МТ от край до край. Въпреки че дълбоките невронни модели дават най-съвременни резултати в много преводачески задачи, се установява, че те са недостатъчни при сценарии с бедни ресурси. Въпреки известния успех, нито един от съвременните критерии, които се опитаха да преодолеят този проблем, не може да се разглежда като универсално решение на проблема с превода на много езици с нисък ресурс. В тази работа се изследва ефективността на фразово-базиран СМТ (PB-SMT) и неврален МТ (NMT) върху рядко тествана езикова двойка с нисък ресурс, английски-тамилски, като се има предвид специализирана област на данни (локализация на софтуера). По-специално, ние изготвяме класиране на нашите системи за МТ чрез базирана на платформа за социална медия схема за оценка на човека и демонстрираме нашите открития в задачата за превод на текстове, специфични за нискоресурсите домейни.</abstract_bg>
      <abstract_da>Statistisk maskinoversættelse (SMT), som var det dominerende paradigme inden for maskinoversættelse (MT) forskning i næsten tre årtier, er for nylig blevet erstattet af end-to-end deep learning tilgange til MT. Selvom dybe neurale modeller producerer state-of-the-art resultater i mange oversættelsesopgaver, er de fundet at underyde på ressourcefattige scenarier. Trods en vis succes kan ingen af de nuværende benchmarks, der har forsøgt at overvinde dette problem, betragtes som en universel løsning på problemet med oversættelse af mange sprog med lav ressource. I dette arbejde undersøger vi udførelsen af sætningsbaseret SMT (PB-SMT) og neural MT (NMT) på et sjældent testet lav ressource sprogpar, engelsk-til-tamil, under hensyntagen til et specialiseret datadomæne (softwarelokalisering). Vi producerer især placeringer af vores MT-systemer via en social medieplatform baseret menneskelig evalueringsordning og demonstrerer vores resultater i den domænespecifikke tekstoversættelsesopgave med lav ressource.</abstract_da>
      <abstract_hr>Statistički prevod strojeva (SMT) koji je bio dominantna paradigma u istraživanju prevoda strojeva (MT) skoro tri desetljeća nedavno je zamijenjen pristupima dubokog učenja MT-u. Iako duboki neuronski modeli proizvode stanje umjetnosti rezultate u mnogim prevodnim zadacima, nalaze se da su nedovoljno izvršeni na scenarijama siromašnih resursa. Uprkos nekim uspjehom, nijedna od današnjih kriterija koji su pokušali prevladati ovaj problem ne može se smatrati univerzalnim rješenjem problem a prevođenja mnogih jezika niskih resursa. U ovom poslu istražujemo učinkovitost SMT (PB-SMT) i neuralnog MT (NMT) na rijetko testiranom parom jezika s niskim resursima, engleskog do Tamil a, uzimajući u obzir specijaliziranu domenu podataka (lokalizacija softvera). Posebno, proizvodimo redove našeg MT sustava putem sustava za procjenu ljudskih procjena na platformi društvenih medija i pokazujemo naše nalaze u zadatku prevoda teksta specifičnog domena s niskim resursima.</abstract_hr>
      <abstract_nl>Statistische machine translation (SMT), dat bijna drie decennia lang het dominante paradigma was in het onderzoek naar machine translation (MT), is onlangs vervangen door de end-to-end deep learning benaderingen voor MT. Hoewel diepe neurale modellen state-of-the-art resultaten opleveren in veel vertaaltaken, blijkt dat ze onvoldoende presteren op scenario's met weinig middelen. Ondanks enige successen kan geen van de huidige benchmarks die hebben geprobeerd dit probleem op te lossen, worden beschouwd als een universele oplossing voor het probleem van de vertaling van veel talen met weinig middelen. In dit werk onderzoeken we de prestaties van phrase-based SMT (PB-SMT) en neural MT (NMT) op een zelden getest low-resource taalpaar, Engels-to-Tamil, waarbij rekening wordt gehouden met een gespecialiseerd datadomein (softwarelokalisatie). Met name maken we rankings van onze MT-systemen via een social media platform gebaseerd human evaluation schema en demonstreren onze bevindingen in de low-resource domeinspecifieke tekstvertaaltaak.</abstract_nl>
      <abstract_id>Terjemahan mesin statistik (SMT) yang merupakan paradigma dominan dalam penelitian terjemahan mesin (MT) selama hampir tiga dekade baru-baru ini telah diganti oleh pendekatan belajar dalam akhir-akhir ke akhir untuk MT. Meskipun model saraf dalam menghasilkan hasil state-of-the-art dalam banyak tugas terjemahan, mereka ditemukan untuk melampaui batas pada skenario yang kurang sumber daya. Meskipun beberapa sukses, tidak ada tanda referensi saat ini yang telah mencoba mengatasi masalah ini dapat dianggap sebagai solusi universal untuk masalah terjemahan banyak bahasa sumber day a rendah. In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialised data domain (software localisation) into consideration.  Terutama, kami menghasilkan rangkaian dari sistem MT kami melalui skema evaluasi manusia berdasarkan platform media sosial, dan menunjukkan penemuan kami dalam tugas terjemahan teks spesifik sumber daya rendah.</abstract_id>
      <abstract_de>Statistische maschinelle Übersetzung (SMT), das seit fast drei Jahrzehnten das dominierende Paradigma in der maschinellen Übersetzung (MT) Forschung war, wurde kürzlich durch die End-to-End Deep Learning Ansätze für die MT ersetzt. Obwohl Deep Neuronal Modelle in vielen Übersetzungsaufgaben State-of-the-Art Ergebnisse liefern, werden sie in ressourcenarmen Szenarien als unzureichend angesehen. Trotz einiger Erfolge kann keines der heutigen Benchmarks, die versucht haben, dieses Problem zu überwinden, als universelle Lösung für das Problem der Übersetzung vieler ressourcenarmer Sprachen angesehen werden. In dieser Arbeit untersuchen wir die Leistungsfähigkeit von phrasenbasiertem SMT (PB-SMT) und neuronalem MT (NMT) auf einem selten getesteten Low-Resource-Sprachpaar Englisch-Tamil unter Berücksichtigung einer speziellen Datendomäne (Softwarelokalisierung). Insbesondere erstellen wir Rankings unserer MT-Systeme über ein Social Media-Plattform-basiertes Human Evaluation Schema und demonstrieren unsere Erkenntnisse in der ressourcenarmen domänenspezifischen Textübersetzungsaufgabe.</abstract_de>
      <abstract_tr>Statistik maşynyň terjimesini (SMT) ol maşynyň terjimesinde näçe ýoluň üç ýyldan bäri domini paradigm(MT) araştyrmasynyň MT'a golaý öwrenmek üçin iň soňra golaý golaýynyň golaýyndan geçirildi. Ýöne derin näyral modelleriň gaty möhüm modalarynyň kän terjime eden zadynyň netijesi bolsa bolsa, ol resurslar- Birnäçe üstünlik gazanyna rağmen, bu meseleyi üstden çykarmak isleýän güniň hiçbiri iň az ressurs dilleriniň terjime etmek kynçylygynyň uniwersal çözümi diýip kabul edilmez. Bu işde fraz tabanly SMT (PB-SMT) we neural MT Aýratyn bolsa, biz MT sistemalarymyzyň düzümlerini sosial mediýa platformasynda adamlaryň deňlenme taslamasynda görkeýäris we mektuplarymyzy a şak resurslar domaýynyň belli metin terjimesinde görkezilýäris.</abstract_tr>
      <abstract_fa>ترجمه ماشین آماری (SMT) که در تحقیقات ترجمه ماشین (MT) برای تقریباً سه دهه اخیرا توسط رسیده‌های یادگیری عمیق به MT جایگزین شده است. اگرچه مدل‌های عصبی عمیق در حالت‌های هنری به کار بسیاری از ترجمه‌ها نتیجه می‌دهد، آنها در سناریو‌های فقیر منبع کمتر انجام می‌یابند. با وجود برخی موفقیت، هیچ کدام از نقشه‌های امروزی که سعی کردند این مشکل را غلبه کند نمی‌تواند به عنوان راه حل جهانی برای ترجمه کردن زبانهای بسیاری از منابع کم بگیرد. در این کار، ما عملکرد SMT (PB-SMT) و MT عصبی (NMT) بر یک جفت زبان کم از منابع کم آزمایش شده‌ایم، انگلیسی-تا تامیل را تحقیق می‌کنیم، با توجه به دامین داده‌های ویژه (محل نرم‌افزار) بررسی می‌کنیم. مخصوصا، ما از طریق یک برنامه ارزیابی انسان بر اساس یک برنامه رسانه‌های اجتماعی صفحه‌های سیستم‌های MT‌مان تولید می‌کنیم، و نتیجه‌هایمان را در مورد ترجمه‌ی متن خاصی به دامنه‌های کم منبع نشان</abstract_fa>
      <abstract_ko>통계기계번역(SMT)은 최근 30년 동안 기계번역(MT) 연구의 주도적인 모델로 최근 기계번역의 끝에서 끝까지의 깊이 있는 학습 방법에 의해 대체되었다. 비록 깊이신경모델은 많은 번역 임무에서 가장 선진적인 결과를 얻었지만 자원이 부족한 상황에서 그들의 활약은 좋지 않다.비록 약간의 성공을 거두었지만, 현재 이 문제를 극복하려는 기준은 많은 저자원 언어 번역 문제를 해결하는 통용적인 해결 방안으로 간주될 수 없다.이 작업에서 우리는 짧은 언어를 바탕으로 하는 SMT(PB-SMT)와 신경기계번역(NMT)이 아주 적게 테스트되는 저자원 언어의 대(영어에서 테밀어까지)에서의 성능을 연구하고 전문적인 데이터 영역(소프트웨어 현지화)을 고려했다.특히 우리는 소셜미디어 플랫폼을 바탕으로 하는 인류 평가 방안을 통해 기계 번역 시스템을 랭킹하고 저자원 분야의 특정 텍스트 번역 임무에서 발견한 것을 보여준다.</abstract_ko>
      <abstract_sw>Tafsiri ya mashine ya takwimu (SMT) ambayo ilikuwa ni utafiti mkubwa katika tafsiri ya mashine (MT) kwa takriban miongo mitatu hivi karibuni umetawaliwa na mbinu za kujifunza kwa mwisho wa mwisho wa mwisho wa kufikia MT. Ingawa mifano ya kina ya kejeli inatengeneza hali ya sanaa katika majukumu mengi ya kutafsiri, hugunduliwa kufanya kazi zisizo na msingi wa rasilimali. Pamoja na mafanikio fulani, hakuna moja ya bendera za sasa zilizojaribu kushinda tatizo hili linaweza kuchukuliwa kama suluhisho la kimataifa la kutafsiri lugha nyingi za rasilimali za chini. Katika kazi hii, tunachunguza utendaji wa SMT (PB-SMT) na MT ya neura (NMT) katika lugha ndogo ya chini ya rasilimali, Kiingereza-hadi-Tamil, tukichukua maeneo maalum ya taarifa (mahali ya programu). Kwa hakika, tunatengeneza rangi za mfumo wetu wa MT kupitia mpango wa uchunguzi wa kimataifa wa mitandao ya kijamii, na kuonyesha matokeo yetu katika kazi ya tafsiri ya maandishi yenye rasilimali ya chini.</abstract_sw>
      <abstract_af>Statistiese masjien vertaling (SMT) wat was die dominante paradigm in masjien vertaling (MT) ondersoek vir byna drie dekades is onlangs vervang deur die end- to- end diep leer toegang tot MT. Alhoewel diep neurale modele produseer state- of- the- art resultate in baie vertaling opdragte, word hulle gevind om onder- uitvoer op hulpbron- arme scenarios te doen. Onthou sommige sukses, geen van die huidige daglike benchmarke wat probeer het om hierdie probleem te oorwin kan wees aangesien as 'n universele oplossing vir die probleem van vertaling van baie lae- hulpbron tale. In hierdie werk, ons ondersoek die prestasie van frase-gebaseerde SMT (PB-SMT) en neurale MT (NMT) op 'n rarely-testeerde lae-hulpbronne taal-pair, Engels-na-Tamil, neem 'n spesialiseerde data domein (sagteware lokalisering) in aandag. Ons produseer spesifieke rankings van ons MT-stelsels deur 'n sosiale media-platformgebaseerde menslike evalueringsskema en wys ons vindings in die lae-hulpbron domein-spesifieke teks-vertalingstaak.</abstract_af>
      <abstract_sq>Përkthimi statistik i makinave (SMT) i cili ishte paradigma dominuese në kërkimin e përkthimit të makinave (MT) për gati tre dekada kohët e fundit është zëvendësuar nga metodat e mësimit të thellë nga fundi në fund në MT. Megjithëse modelet e thella neuronale prodhojnë rezultate më të larta në shumë detyra përkthimi, ato gjenden të munguara në skenarë të varfëra në burime. Megjithë disa sukses, asnjë nga pikat e referimit të sotme që kanë përpjekur të kapërcejnë këtë problem nuk mund të konsiderohet si një zgjidhje universale për problemin e përkthimit të shumë gjuhëve me burime të ulëta. Në këtë punë, ne hetojmë performancën e SMT (PB-SMT) dhe MT neuronale (NMT) bazuar në fraza në një çift gjuhësh me burime të ulta të testuara rrallë, anglisht-në-tamil, duke marrë në konsideratë një domeni të dhënash të specializuara (lokalizim programi). Në veçanti, ne prodhojmë renditje të sistemeve tona MT nëpërmjet një skeme vlerësimi njerëzor bazuar në platform ën e medias shoqërore dhe demonstrojmë gjetjet tona në detyrën e përkthimit të tekstit me burime të ulta specifike për domenin e burimeve.</abstract_sq>
      <abstract_am>Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although deep neural models produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios.  ምንም እንኳን አግኝታ ቢሆንም፣ ዛሬ የዚህን ጉዳይ ለማሸንፍ የሞከሩ ማንኛውም የዋና-resource ቋንቋዎች ለመተርጓም ጉዳይ አቀማሚ መፍትሄ አይችልም፡፡ በዚህ ሥራ፣ የድምፅ ቃላት SMT (PB-SMT) እና የnerural MT (NMT) እና በአጭር የተፈተና የዝግዝና ቋንቋ-ቋንቋ-ዓይነቶች፣ እንግሊዘኛ-ወደ-ታሚል እና የተለየ ዳታ ዶሜን (ሶፍትዌር localisation) ለመወሰን እናሳይቃለን፡፡ በተለይም፣ ማኅበራዊ አውታር ማኅበራዊ ሚዲያ ማረጋገጫ ፕሮግራም የተደረገውን የMT ስርዓቶችን ከፍተኛ እናደርጋለን፡፡</abstract_am>
      <abstract_hy>Մոտ երեք տասնամյակների ընթացքում վիճակագրական մեքենայի թարգմանման (SMT), որը մեքենայի թարգմանման (MT) ուսումնասիրության գերիշխող պարադիգմանն էր, վերջերս փոխարինվել է MT-ի վերջ-վերջ խորը ուսումնասիրության մոտեցումներով: Չնայած, որ խորը նյարդային մոդելները ստեղծում են բարձր արդյունքներ թարգմանման Չնայած որոշ հաջողություններին, ներկայիս համեմատական կետերից ոչ մեկը, որ փորձել է հաղթահարել այս խնդիրը, չի կարելի համաշխարհային լուծում համարվել շատ ցածր ռեսուրսների լեզուների թարգմանման խնդիրը: Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք արտահայտությամբ հիմնված SMT (PB-SMT) և նյարդային MT (NMT) արտադրողությունները հազվադեպ փորձարկված ցածր ռեսուրսների լեզվի զույգի վրա, անգլերեն-թամիլ, հաշվի առնելով մասնագիտական տվյալների ոլորտ (ծրագր Մենք հատկապես ստեղծում ենք մեր MT համակարգերի գնահատականները սոցիալական լրատվամիջոցների պլատֆորմացիայի հիմնված մարդկային գնահատականների ծրագրի միջոցով և ցույց ենք տալիս մեր հայտնաբերությունները ցածր ռեսուրսների բնագավառներով հա</abstract_hy>
      <abstract_bn>পরিসংখ্যান মেশিন অনুবাদ (এসএমটি) যা প্রায় তিন দশক ধরে মেশিন অনুবাদের (এমটি) গবেষণায় প্রধান পরিসংখ্যান ছিল, সম্প্রতি এমটির শেষ পর্যন্ত গভীর গভীর শিক্ষার ক্ষেত্রে পরিচালিত হয়েছে। কিছু সাফল্য সত্ত্বেও, বর্তমানে এই সমস্যাকে জয়ী করার চেষ্টা করেছে কেউ এই সমস্যাকে বিশ্বব্যাপী সমাধান হিসেবে বিবেচনা করা যায় না অনেক কম সম্পদে এই কাজে আমরা ব্যাক্তিভিত্তিক SMT (পিবি-এসএমটি) এবং নিউরাল এমটি (এনএমটি) এর প্রভাব অনুসন্ধান করি একটি কমপক্ষে পরীক্ষা করা কম-সম্পদের ভাষার জোড়া, ইংরেজী থেকে তামিল, একটি বিশেষ তথ্য ডো বিশেষ করে, আমরা একটি সামাজিক মিডিয়া প্লাটফর্ম ভিত্তিক মানুষের মুল্যায়ন পরিকল্পনার মাধ্যমে আমাদের এমটি সিস্টেমের রাঙ্গান্না তৈরি করি এবং কম সম্</abstract_bn>
      <abstract_bs>Statistički prevod mašine (SMT) koji je bio dominantna paradigma u istraživanju prevoda mašina (MT) skoro tri desetljeća nedavno je zamijenjen pristupima dubokog učenja MT-u. Iako duboki neuronski modeli proizvode stanje umjetnosti rezultate u mnogim prevodnim zadacima, nalaze se da su pod izvršenom scenarijama siromašnih resursa. Uprkos nekim uspjehom, nijedna od današnjih kriterija koji su pokušali da prevare ovaj problem ne može biti smatrana univerzalnim rješenjem problem a prevođenja mnogih jezika niskih resursa. U ovom poslu istražujemo učinkovitost SMT (PB-SMT) i neuralnog MT (NMT) na rijetko testiranom parom jezika s niskim resursima, engleskog do Tamil a, uzimajući u obzir specijalizovanu domenu podataka (lokalizacija softvera). Posebno, proizvodimo redove našeg MT-ovog sustava putem sustava za procjenu ljudskih procjena na platformi socijalnih medija i pokazujemo naše nalaze u zadatku prevoda teksta specifičnog domena niskih resursa.</abstract_bs>
      <abstract_ca>La traducció estadística de màquines (SMT), que va ser el paradigma dominant en la recerca de traducció màquina (MT) durant gairebé tres dècades, s'ha substituït recentment pels enfocaments d'aprenentatge profund fins al final a MT. Encara que els models neuronals profunds produeixen resultats més avançats en moltes tasques de traducció, es troba que són insuficients en escenaris pocs recursos. Malgrat algun èxit, cap dels punts de referència actuals que han intentat superar aquest problem a pot ser considerat una solució universal al problema de la traducció de moltes llengües de baix recursos. En aquesta feina, investigam el rendiment de SMT basat en frases (PB-SMT) i MT neural (NMT) en un parell de llenguatges poc recursos, anglès-tamil, amb un domini de dades especialitzats (localització del software). En particular, produïm classificacions dels nostres sistemes MT a través d'un esquema d'evaluació humana basat en plataformes de mitjans socials, i demostram els nostres descobriments en la tasca de traducció de textos específica de baix recursos.</abstract_ca>
      <abstract_az>Yaklaşık üç on il boyunca maşın çevirilməsindəki statistik maşına çevirilməsi (SMT) kimi maşın çevirilməsindəki araştırmaların üstünlü paradigmi MT ilə yaxınlaşdırılmışdır. Halbuki derin nöral modellər çox çevirilmiş işlərdə təşkil edirlər, çoxlu çoxlu təşkil etmə işlərinə görə, çoxlu mənbəzi zəif scenariolarda çoxlu işlər görünərlər. Bazı müvəffəqiyyətlərə rağmen, bu problem ə üstün gəlməyə çalışan günümüzdeki benchmarklərdən heç kəs çox zəif ressurs dillərinin çevirilməsi problemlərinin universal çözümü olar. Bu işdə, fraz tabanlı SMT (PB-SMT) və nöral MT (NMT) və nadir sınaqları düşük ressurs dili çift, İngilizə-Tamil, özlərinə məlumat domeini (yazılım yerləşdirilməsi) gözləyirik. Özellikle, biz MT sistemlərinin səviyyələrini sosyal media platformu ilə insan değerlendirməsi taslağı vasitəsilə ürəkləyirik və a şağı ressurs domeini məlumat qurğulaması işində bulunduqlarımızı göstəririk.</abstract_az>
      <abstract_et>Statistiline masintõlke (SMT), mis oli peaaegu kolm aastakümmet domineeriv paradigma masintõlke (MT) uuringutes, on hiljuti asendatud läbimõeldud sügavõppe lähenemisviisidega. Kuigi sügavnärvimudelid annavad paljudes tõlketöödes kaasaegseid tulemusi, leitakse, et need on ressursivaheste stsenaariumide puhul alajõudnud. Vaatamata teatavale edule ei saa ühtegi tänapäevasest võrdluskriteeriumist, mis on püüdnud seda probleemi lahendada, pidada universaalseks lahenduseks paljude vähese ressursiga keelte tõlkimise probleemile. Käesolevas töös uurime fraasipõhise SMT (PB-SMT) ja neuraalse MT (NMT) jõudlust harva testitud madala ressursiga keelepaaril inglise-tamili keelel, võttes arvesse spetsialiseeritud andmevaldkonda (tarkvara lokaliseerimine). Eelkõige koostame oma MT süsteemide järjestused sotsiaalmeedia platvormipõhise inimhindamisskeemi kaudu ja demonstreerime oma tulemusi vähese ressursiga valdkonnaspetsiifilise tekstitõlke ülesande kohta.</abstract_et>
      <abstract_cs>Statistický strojový překlad (SMT), který byl dominantním paradigmatem ve výzkumu strojového překladu (MT) po téměř tři desetiletí, byl v poslední době nahrazen komplexními přístupy hlubokého učení k MT. Navzdory určitému úspěchu nelze žádný z dnešních měřítek, které se snažily tento problém překonat, považovat za univerzální řešení problému překladu mnoha jazyků s nízkými zdroji. V této práci zkoumáme výkon frázového SMT (PB-SMT) a neuronového MT (NMT) na zřídka testovaném jazykovém páru angličtina-tamilština s ohledem na specializovanou datovou doménu (lokalizaci softwaru). Zejména vytváříme žebříčky našich MT systémů prostřednictvím systému založeného na platformě sociálních médií pro lidské hodnocení a demonstrujeme naše poznatky v oblasti překladu textů s nízkými zdroji.</abstract_cs>
      <abstract_fi>Tilastollinen konekﾃ､ﾃ､nnﾃｶs (SMT), joka oli hallitseva paradigma konekﾃ､ﾃ､nnﾃｶstutkimuksessa lﾃ､hes kolmen vuosikymmenen ajan, on viime aikoina syrjﾃ､yttﾃ､nyt end-to-end -syvﾃ､oppimisen lﾃ､hestymistavat. Vaikka syvﾃ､neuromallit tuottavat viimeisintﾃ､ tekniikkaa monissa kﾃ､ﾃ､nnﾃｶstehtﾃ､vissﾃ､, niiden todetaan olevan alisuoria resurssipuhalleissa skenaarioissa. Joistakin onnistumisista huolimatta mitﾃ､ﾃ､n nykyisistﾃ､ vertailuarvoista, joilla tﾃ､tﾃ､ ongelmaa on yritetty ratkaista, ei voida pitﾃ､ﾃ､ yleismaailmallisena ratkaisuna monien vﾃ､hﾃ､varaisten kielten kﾃ､ﾃ､ntﾃ､miseen. Tﾃ､ssﾃ､ tyﾃｶssﾃ､ tutkitaan fraasipohjaisen SMT:n (PB-SMT) ja neuraalisen MT:n (NMT) suorituskykyﾃ､ harvoin testatussa vﾃ､hﾃ､resurssisessa kieliparissa, englanti-tamili, ottaen huomioon erikoistunut tietoalue (ohjelmistolokalisointi). Erityisesti laadimme MT-jﾃ､rjestelmiemme rankingit sosiaalisen median alustapohjaisen inhimillisen arviointijﾃ､rjestelmﾃ､n avulla ja esittelemme havaintojamme vﾃ､hﾃ､resurssisesta verkkotunnuskohtaisesta tekstikﾃ､ﾃ､nnﾃｶksestﾃ､.</abstract_fi>
      <abstract_jv>@SMT.org Nanging kabeh luwih akeh pengguna nêmên, gak dhéwé dengané nggawe gerarané nggawe kesempatan iki iso nggawe gerarané karo perusahaan universal kanggo tarjamahan kanggo kelangan langa sing paling dhéwé. Nang barêng-barêng iki, kita ranjut cara nggawe barang kelas SMT (PB-SMT) lan NMT (NMT) nganggep kuwi wis diperawat-ujaran langgambar, ingles-to-Tamil, gawan tanggal data domain (software lokalisation) nggawe nguasakno. Juara-Juara, we make rangings of the MT</abstract_jv>
      <abstract_sk>Statistično strojno prevajanje (SMT), ki je bila skoraj tri desetletja prevladujoča paradigma v raziskavah strojnega prevajanja (MT), je v zadnjem času nadomestil pristop do konca globokega učenja k MT. Čeprav globoki nevronski modeli prinašajo najsodobnejše rezultate pri številnih prevajalskih nalogah, je ugotovljeno, da so premalo uspešni pri scenarijih, ki primanjkujejo vire. Kljub določenemu uspehu se nobena od sedanjih meril, ki so poskušala premagati ta problem, ne more obravnavati kot univerzalna rešitev problema prevajanja številnih jezikov z nizkimi viri. V tem delu smo raziskali učinkovitost fraznega SMT (PB-SMT) in nevronskega MT (NMT) na redko testiranem jezikovnem paru z nizkimi viri, angleško-tamilščini, ob upoštevanju specializirane podatkovne domene (lokalizacija programske opreme). Zlasti izdelujemo lestvice naših sistemov MT prek platforme socialnih medijev, ki temelji na ocenjevanju človeka, in prikazujemo naše ugotovitve pri nalogi prevajanja besedil, specifičnih za domeno z nizkimi viri.</abstract_sk>
      <abstract_he>התרגום המכונה הסטטיסטית (SMT), שהיה הפרדיגמה השליטנית במחקר התרגום המכונה (MT) במשך כמעט שלושה עשורים, הוחלף לאחרונה על ידי גישות למידה עמוקה בסוף לסוף ל MT. למרות שדוגמנים עצביים עמוקים יוצרים תוצאות מוקדמות במשימות רבות של התרגום, נמצאים שהם לא מושלמים במקרים עניים במשאבים משאבים. למרות הצלחה מסוימת, אף אחד מהנקודות הנוכחיות שניסו להתגבר על הבעיה הזאת לא יכול להיחשב כפתרון אוניברסלי לבעיה של התרגום של שפות נמוכות רבות. בעבודה הזו, אנו חוקרים את ביצועים של SMT מבוסס על ביטויים (PB-SMT) ו MT עצבי (NMT) על זוג שפת נמוך-משאבים שנבדק נדירות, אנגלית-לטמיל, בהתחשב בתחום נתונים מיוחד (מקום התוכנה). במיוחד, אנו יוצרים את הדרגות של מערכות MT שלנו באמצעות מערכת הערכה אנושית מבוססת על פלטפורמת תקשורת חברתית, ולהראות את הממצאים שלנו במשימת התרגום טקסט ספציפית למקור נמוך.</abstract_he>
      <abstract_fil>Ang pagsasanggalang ng estatistika ng makina (SMT) na siyang dominante paradigm sa pagsasanggalang ng makina (MT) ng pagsasanggalang ng malapit na tatlong taon, ay hindi pa nangyari ng mga pagsasanggalang ng malalim na pag-aaral sa MT. Bagaman ang malalim na mga modelo ng neural ay nagbubuhat ng state-of-the-art sa maraming pagsasanggalang na gawa, masusumpungan silang malalim sa pagsasanggalang ng mga masamang scenario ng resources Gayon ma'y may tagumpay, wala sa mga benchmarks ng araw na ito na pinagsisikapan ng paglabas ng problemang ito na maaari na bilang universal solusyon sa problem a ng paglilikat ng maraming mababa na wika. Sa trabahong ito, aming pinagsisiyasat ang performance ng SMT (PB-SMT) at neural MT Dahil dito, nagbubuhat tayo ng mga rankings ng ating MT systems sa pamamagitan ng isang eskema ng evaluasyon ng mga tao na ginagamit sa social media platform, at nagpapakita ng ating mga hanap sa mababang-resource domain specific text translation task.</abstract_fil>
      <abstract_bo>Statistical machine translation (SMT) which was the dominant paradigm in machine translation (MT) research for nearly three decades has recently been superseded by the end-to-end deep learning approaches to MT. Although deep neural models produce state-of-the-art results in many translation tasks, they are found to under-perform on resource-poor scenarios. གྲུབ་འབྲས་གཞན་ཞིག་ཡིན་ནའང་དུས་མཚམས་འཇོག་པའི་དཀའ་རིམ་བཀྲམ་སྤེལ་བ་ཡིན་ནའང་མེད་པའི་དཀའ་འཁོར་སྐྱོད་ཀྱི་རྐྱེན་ཚུལ་དེ་ལ In this work, we investigate the performance of phrase-based SMT (PB-SMT) and neural MT (NMT) on a rarely-tested low-resource language-pair, English-to-Tamil, taking a specialized data domain (software localization) into consideration. In particular, we produce rankings of our MT systems via a social media platform-based human evaluation scheme, and demonstrate our findings in the low-resource domain-specific text translation task.</abstract_bo>
      <abstract_ha>@ info: status Babu da wani babban rabo, babu wani matsayi na kanzu, wanda suka yi jarraba domin wannan mataimaki a yanzu, ba za'a gane shi kamar wata suluya mai fassarar harshen masu ƙaranci-resource. Daga wannan aikin, Munã yin ƙidãya da aikin SMT (PB-SMT) da neural MT (NMT) a kan wata jarraba nau'i-nau'i-nau'in lugha-nau'i, Ingiriya-zuwa-Tamilli, kuma munã sami wani danne da aka ƙayyade (localisation of kwamfyutan ayuka). Kayyaki, muna samun ransakar masu tsarin MT da ke samar da wani shirin evaluation na mutane na mitandai da jamii, kuma munã nuna matsayinmu a cikin aikin fassarar-littãfin da aka ƙayyade wuri-resource.</abstract_ha>
      </paper>
  </volume>
</collection>