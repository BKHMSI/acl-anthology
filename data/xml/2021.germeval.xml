<collection id="2021.germeval">
  <volume id="1" ingest-date="2021-10-22">
    <meta>
      <booktitle>Proceedings of the GermEval 2021 Shared Task on the Identification of Toxic, Engaging, and Fact-Claiming Comments</booktitle>
      <editor><first>Julian</first><last>Risch</last></editor>
      <editor><first>Anke</first><last>Stoll</last></editor>
      <editor><first>Lena</first><last>Wilms</last></editor>
      <editor><first>Michael</first><last>Wiegand</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Duesseldorf, Germany</address>
      <month>September</month>
      <year>2021</year>
      <url hash="a6114ee1">2021.germeval-1</url>
    </meta>
    <frontmatter>
      <url hash="d35277ad">2021.germeval-1.0</url>
      <bibkey>germeval-2021-germeval</bibkey>
    </frontmatter>
    <paper id="4">
      <title><fixed-case>DFKI</fixed-case> <fixed-case>SLT</fixed-case> at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Multilingual Pre-training and Data Augmentation for the Classification of Toxicity in Social Media Comments</title>
      <author><first>Remi</first><last>Calizzano</last></author>
      <author><first>Malte</first><last>Ostendorff</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>25&#8211;31</pages>
      <abstract>We present our submission to the first subtask of GermEval 2021 (classification of German Facebook comments as toxic or not). Binary sequence classification is a standard NLP task with known state-of-the-art methods. Therefore, we focus on data preparation by using two different techniques: task-specific pre-training and data augmentation. First, we pre-train multilingual transformers (XLM-RoBERTa and MT5) on 12 hatespeech detection datasets in nine different languages. In terms of F1, we notice an improvement of 10% on average, using task-specific pre-training. Second, we perform data augmentation by labelling unlabelled comments, taken from Facebook, to increase the size of the training dataset by 79%. Models trained on the augmented training dataset obtain on average +0.0282 (+5%) F1 score compared to models trained on the original training dataset. Finally, the combination of the two techniques allows us to obtain an F1 score of 0.6899 with XLM- RoBERTa and 0.6859 with MT5. The code of the project is available at: https://github.com/airKlizz/germeval2021toxic.</abstract>
      <url hash="ba6470d5">2021.germeval-1.4</url>
      <bibkey>calizzano-etal-2021-dfki</bibkey>
      <pwccode url="https://github.com/airklizz/germeval2021toxic" additional="false">airklizz/germeval2021toxic</pwccode>
    </paper>
    <paper id="5">
      <title><fixed-case>WLV</fixed-case>-<fixed-case>RIT</fixed-case> at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Multitask Learning with Transformers to Detect Toxic, Engaging, and Fact-Claiming Comments</title>
      <author><first>Skye</first><last>Morgan</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>32&#8211;38</pages>
      <abstract>This paper addresses the identification of toxic, engaging, and fact-claiming comments on social media. We used the dataset made available by the organizers of the GermEval2021 shared task containing over 3,000 manually annotated Facebook comments in German. Considering the relatedness of the three tasks, we approached the problem using large pre-trained transformer models and multitask learning. Our results indicate that multitask learning achieves performance superior to the more common single task learning approach in all three tasks. We submit our best systems to GermEval-2021 under the team name WLV-RIT.</abstract>
      <url hash="b8a3edc3">2021.germeval-1.5</url>
      <bibkey>morgan-etal-2021-wlv</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="10">
      <title><fixed-case>TUW</fixed-case>-<fixed-case>I</fixed-case>nf at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val2021: Rule-based and Hybrid Methods for Detecting Toxic, Engaging, and Fact-Claiming Comments</title>
      <author><first>Kinga</first><last>G&#233;mes</last></author>
      <author><first>G&#225;bor</first><last>Recski</last></author>
      <pages>69&#8211;75</pages>
      <abstract>This paper describes our methods submitted for the GermEval 2021 shared task on identifying toxic, engaging and fact-claiming comments in social media texts (Risch et al., 2021). We explore simple strategies for semi-automatic generation of rule-based systems with high precision and low recall, and use them to achieve slight overall improvements over a standard BERT-based classifier.</abstract>
      <url hash="9143b01d">2021.germeval-1.10</url>
      <bibkey>gemes-recski-2021-tuw</bibkey>
    </paper>
    <paper id="13">
      <title>Data Science Kitchen at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: A Fine Selection of Hand-Picked Features, Delivered Fresh from the Oven</title>
      <author><first>Niclas</first><last>Hildebrandt</last></author>
      <author><first>Benedikt</first><last>Boenninghoff</last></author>
      <author><first>Dennis</first><last>Orth</last></author>
      <author><first>Christopher</first><last>Schymura</last></author>
      <pages>88&#8211;94</pages>
      <abstract>This paper presents the contribution of the Data Science Kitchen at GermEval 2021 shared task on the identification of toxic, engaging, and fact-claiming comments. The task aims at extending the identification of offensive language, by including additional subtasks that identify comments which should be prioritized for fact-checking by moderators and community managers. Our contribution focuses on a feature-engineering approach with a conventional classification backend. We combine semantic and writing style embeddings derived from pre-trained deep neural networks with additional numerical features, specifically designed for this task. Ensembles of Logistic Regression classifiers and Support Vector Machines are used to derive predictions for each subtask via a majority voting scheme. Our best submission achieved macro-averaged F1-scores of 66.8%, 69.9% and 72.5% for the identification of toxic, engaging, and fact-claiming comments.</abstract>
      <url hash="275a546f">2021.germeval-1.13</url>
      <bibkey>hildebrandt-etal-2021-data</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>H</fixed-case>unter<fixed-case>S</fixed-case>peech<fixed-case>L</fixed-case>ab at <fixed-case>G</fixed-case>erm<fixed-case>E</fixed-case>val 2021: Does Your Comment Claim A Fact? Contextualized Embeddings for <fixed-case>G</fixed-case>erman Fact-Claiming Comment Classification</title>
      <author><first>Subhadarshi</first><last>Panda</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <pages>100&#8211;104</pages>
      <abstract>In this paper we investigate the efficacy of using contextual embeddings from multilingual BERT and German BERT in identifying fact-claiming comments in German on social media. Additionally, we examine the impact of formulating the classification problem as a multi-task learning problem, where the model identifies toxicity and engagement of the comment in addition to identifying whether it is fact-claiming. We provide a thorough comparison of the two BERT based models compared with a logistic regression baseline and show that German BERT features trained using a multi-task objective achieves the best F1 score on the test set. This work was done as part of a submission to GermEval 2021 shared task on the identification of fact-claiming comments.</abstract>
      <url hash="a9c73794">2021.germeval-1.15</url>
      <bibkey>panda-levitan-2021-hunterspeechlab</bibkey>
    </paper>
    </volume>
</collection>