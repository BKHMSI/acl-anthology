<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.conll">
  <volume id="1" ingest-date="2020-11-05">
    <meta>
      <booktitle>Proceedings of the 24th Conference on Computational Natural Language Learning</booktitle>
      <editor><first>Raquel</first><last>Fernández</last></editor>
      <editor><first>Tal</first><last>Linzen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="92d9bf6e">2020.conll-1.0</url>
      <bibkey>conll-2020-natural</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Neural Proof Nets</title>
      <author><first>Konstantinos</first><last>Kogkalidis</last></author>
      <author><first>Michael</first><last>Moortgat</last></author>
      <author><first>Richard</first><last>Moot</last></author>
      <pages>26–40</pages>
      <abstract>Linear logic and the linear -calculus have a long standing tradition in the study of natural language form and <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">meaning</a>. Among the proof calculi of linear logic, <a href="https://en.wikipedia.org/wiki/Proof_nets">proof nets</a> are of particular interest, offering an attractive geometric representation of derivations that is unburdened by the bureaucratic complications of conventional prooftheoretic formats. Building on recent advances in set-theoretic learning, we propose a neural variant of proof nets based on Sinkhorn networks, which allows us to translate <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> as the problem of extracting syntactic primitives and permuting them into alignment. Our methodology induces a batch-efficient, end-to-end differentiable architecture that actualizes a formally grounded yet highly efficient neuro-symbolic parser. We test our approach on Thel, a dataset of type-logical derivations for written Dutch, where it manages to correctly transcribe raw text sentences into proofs and terms of the linear -calculus with an accuracy of as high as 70 %.</abstract>
      <url hash="dfb23f26">2020.conll-1.3</url>
      <doi>10.18653/v1/2020.conll-1.3</doi>
      <bibkey>kogkalidis-etal-2020-neural</bibkey>
      <pwccode url="https://github.com/konstantinosKokos/neural-proof-nets" additional="false">konstantinosKokos/neural-proof-nets</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aethel">aethel</pwcdataset>
    </paper>
    <paper id="6">
      <title>On the Frailty of Universal POS Tags for Neural UD Parsers<fixed-case>POS</fixed-case> Tags for Neural <fixed-case>UD</fixed-case> Parsers</title>
      <author><first>Mark</first><last>Anderson</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>69–96</pages>
      <abstract>We present an analysis on the effect UPOS accuracy has on <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> performance. Results suggest that leveraging UPOS tags as fea-tures for neural parsers requires a prohibitively high tagging accuracy and that the use of gold tags offers a non-linear increase in performance, suggesting some sort of exceptionality. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem.</abstract>
      <url hash="27be3738">2020.conll-1.6</url>
      <doi>10.18653/v1/2020.conll-1.6</doi>
      <bibkey>anderson-gomez-rodriguez-2020-frailty</bibkey>
    <title_ar>حول هشاشة علامات نقاط البيع العامة لمحللي UD العصبي</title_ar>
      <title_pt>Sobre a fragilidade das tags POS universais para analisadores UD neurais</title_pt>
      <title_es>Sobre la fragilidad de las etiquetas POS universales para analizadores neuronales de UD</title_es>
      <title_zh>凡神经UD解析器之通用POS标签之弱</title_zh>
      <title_hi>तंत्रिका UD पार्सर्स के लिए यूनिवर्सल पीओएस टैग की कमजोरी पर</title_hi>
      <title_ja>ニューラルUDパーサー用ユニバーサルPOSタグの弱点について</title_ja>
      <title_ga>Ar Lagacht na gClibeanna POS Uilíoch le haghaidh Parsers Neural UD</title_ga>
      <title_ka>უნივერსალური POS ჭდეების ფრანქტი ნეიროლური UD პერსერებისთვის</title_ka>
      <title_hu>Az univerzális POS címkék törékenységéről Neurális UD parserekhez</title_hu>
      <title_el>Σχετικά με την αδυναμία των καθολικών ετικετών POS για τους νευρωνικούς αναλυτές UD</title_el>
      <title_it>Sulla fragilità dei tag POS universali per analizzatori UD neurali</title_it>
      <title_kk>Неуралдық UD парзерлерінің Universal POS тегтерінің бөлігі</title_kk>
      <title_ms>Pada kelemahan Tag POS Universal untuk Parser UD Neural</title_ms>
      <title_mk>Name</title_mk>
      <title_ml>നെയുറല്‍ യുഡി പാര്‍സറുകള്‍ക്കുള്ള പൊസ് ടാഗുകളുടെ ഫ്രെയില്ലിറ്റിയില്‍</title_ml>
      <title_mt>Dwar il-Fraġilità tat-Tags Universali tal-POS għall-Parsers Newrali tal-UD</title_mt>
      <title_mn>Неурал UD парзерүүдийн универсал POS тегтүүд дээр</title_mn>
      <title_lt>Neuralinių UD analizatorių visuotinių POS žymenų pažeidžiamumas</title_lt>
      <title_pl>O słabości uniwersalnych znaczników POS dla neuronowych parserów UD</title_pl>
      <title_no>På breidda av universelle POS-merker for neurale UD-tillesarar</title_no>
      <title_sr>Na slobodi univerzalnih POS znakova za neurološke UD roditelje</title_sr>
      <title_ro>Despre fragilitatea etichetelor POS universale pentru parserele UD neurale</title_ro>
      <title_si>න්‍යූරාල UD පාර්සර්ස්ට වෙනුවෙන් ජාතික POS ටැග් ගැන ප්‍රශ්නය</title_si>
      <title_so>On the Frailty of the Universal POS tags for Neural UD Parsers</title_so>
      <title_sv>Om bräckligheten hos Universal POS Taggar för Neural UD Parsers</title_sv>
      <title_ta>பொதுவான POS ஒட்டுகளின் சட்டத்தில்</title_ta>
      <title_ur>نیورال UD پارسر کے لئے Universal POS ٹاگ کے فریلٹی پر</title_ur>
      <title_vi>Trên lọc của các thẻ vị trí vũ trụ cho bố già thần kinh UD</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>За слабостта на универсалните ПОС тагове за неврални анализатори</title_bg>
      <title_da>Om skrøbeligheden af Universal POS Tags til Neural UD Parsers</title_da>
      <title_nl>Over de kwetsbaarheid van universele POS-tags voor neurale UD-parsers</title_nl>
      <title_hr>Na slobodi univerzalnih POS znakova za neurološke UD roditelje</title_hr>
      <title_de>Zur Schwäche universeller POS-Tags für neuronale UD-Parser</title_de>
      <title_id>Pada Frailty of Universal POS Tags for Neural UD Parsers</title_id>
      <title_fa>در قطعه برچسب‌های POS جهانی برای پزشکان UD عصبی</title_fa>
      <title_ko>신경 UD 해석기 공통어 라벨의 취약성</title_ko>
      <title_sw>Kuhusu Uchaguzi wa mabango ya POS ulimwenguni kote kwa ajili ya mabango ya Umoja wa Mataifa</title_sw>
      <title_af>Op die Frailty van Universele POS etikette vir Neural UD Parsers</title_af>
      <title_tr>Neural UD tansçylar üçin Universal POS tägleri</title_tr>
      <title_am>አቀማመጥ</title_am>
      <title_sq>Në brishtësinë e etiketave universale POS për analizuesit neurolë UD</title_sq>
      <title_hy>Նյարդային UD վերլուծումների համաշխարհային POS նշանների փխրությունը</title_hy>
      <title_az>N칬ral UD Parserl톛ri 칲칞칲n Universal POS etiketl톛rinin Frailty</title_az>
      <title_bn>নিউরাল ইউডি প্যারাসারের জন্য বিশ্ববিদ্যুত POS ট্যাগের ফ্রেইলিস্ট</title_bn>
      <title_bs>Na slobodi univerzalnih POS znakova za neurološke UD roditelje</title_bs>
      <title_cs>O slabosti univerzálních POS značek pro neuronové UD parsery</title_cs>
      <title_et>Neuraalsete UD parserite universaalsete POS sildide nõrkuse kohta</title_et>
      <title_fi>Neuraalisten UD-parsereiden universaalien POS-tunnisteiden heikkoudesta</title_fi>
      <title_ca>En la fragilitat de les etiquetes universals de POS per a analitzadors neuronals UD</title_ca>
      <title_he>על הפרייטיות של תוויות POS Universal עבור מערכי UD נוירואלים</title_he>
      <title_ha>@ action</title_ha>
      <title_bo>Neural UD དཔེ་དབྱིབས་སྤྱོད་ཀྱི་ཆ་རྐྱེན་གྱི་ཡིག་རྟགས་ཀྱི་ནང་དོན</title_bo>
      <title_jv>Nang Frail kanggo Universal ponS tags kanggo Neral UT Paraser</title_jv>
      <title_sk>O šibkosti univerzalnih oznak POS za nevronske UD parserje</title_sk>
      <abstract_ar>نقدم تحليلاً لتأثير دقة UPOS على تحليل الأداء. تشير النتائج إلى أن الاستفادة من علامات UPOS باعتبارها ميزات للمحللين العصبيين تتطلب دقة عالية في وضع العلامات وأن استخدام العلامات الذهبية يوفر زيادة غير خطية في الأداء ، مما يشير إلى نوع من الاستثناء. نتحرى أيضًا عن جوانب علامات UPOS المتوقعة التي تؤثر على دقة التحليل أكثر ، مع إبراز بعض الجوانب اللغوية التي يحتمل أن تكون ذات مغزى للمشكلة.</abstract_ar>
      <abstract_pt>Apresentamos uma análise sobre o efeito que a precisão do UPOS tem no desempenho de análise. Os resultados sugerem que alavancar tags UPOS como recursos para analisadores neurais requer uma precisão de marcação proibitivamente alta e que o uso de tags gold oferece um aumento não linear no desempenho, sugerindo algum tipo de excepcionalidade. Também investigamos quais aspectos das tags UPOS previstas afetam mais a precisão da análise, destacando algumas facetas linguísticas potencialmente significativas do problema.</abstract_pt>
      <abstract_es>Presentamos un análisis sobre el efecto que tiene la precisión de UPOS en el rendimiento del análisis. Los resultados sugieren que aprovechar las etiquetas UPOS como funciones para los analizadores neuronales requiere una precisión de etiquetado prohibitivamente alta y que el uso de etiquetas doradas ofrece un aumento no lineal del rendimiento, lo que sugiere algún tipo de excepcionalidad. También investigamos qué aspectos de las etiquetas UPOS previstas afectan más la precisión del análisis, destacando algunas facetas lingüísticas potencialmente significativas del problema.</abstract_es>
      <abstract_ja>UPOS精度が構文解析性能に及ぼす影響についての分析を提示します。結果は、ニューラル構文解析器のためのフィーチャーとしてUPOSタグを活用するには、圧倒的に高いタグ付け精度が必要であり、ゴールドタグの使用はパフォーマンスの非線形な増加を提供し、何らかの例外性を示唆していることを示唆している。私たちはまた、予測されたUPOSタグのどの側面が解析精度に最も影響を与えるかを調査し、問題のいくつかの潜在的に有意義な言語的側面を強調します。</abstract_ja>
      <abstract_hi>हम प्रदर्शन पार्सिंग पर यूपीओएस सटीकता के प्रभाव पर एक विश्लेषण प्रस्तुत करते हैं। परिणाम बताते हैं कि तंत्रिका पार्सर के लिए fea-tures के रूप में UPOS टैग का लाभ उठाने के लिए एक निषेधात्मक रूप से उच्च टैगिंग सटीकता की आवश्यकता होती है और सोने के टैग का उपयोग प्रदर्शन में गैर-रैखिक वृद्धि प्रदान करता है, जो किसी प्रकार की असाधारणता का सुझाव देता है। हम यह भी जांच करते हैं कि अनुमानित यूपीओएस टैग के कौन से पहलू पार्सिंग सटीकता को सबसे अधिक प्रभावित करते हैं, समस्या के कुछ संभावित सार्थक भाषाई पहलुओं को उजागर करते हैं।</abstract_hi>
      <abstract_zh>吾论UPOS准确性解析性能也。 结果表明以UPOS标为神经解析器者fea-tures须极高标准确性,且以黄金标供非线性性性升擢,明某特殊性也。 论占者UPOS标签之哪些方面,解析准确性之大者,隐于有义之言。</abstract_zh>
      <abstract_ga>Cuirimid anailís i láthair ar an éifeacht atá ag cruinneas UPOS ar fheidhmíocht parsála. Tugann na torthaí le fios go dteastaíonn cruinneas clibeála ró-ard chun clibeanna UPOS a ghiaráil mar ghnéithe do pharsálaithe néaracha agus go dtugann úsáid clibeanna óir méadú neamhlíneach ar fheidhmíocht, rud a thugann eisceacht de chineál éigin le fios. Déanaimid imscrúdú freisin ar na gnéithe de chlibeanna UPOS tuartha is mó a mbíonn tionchar acu ar chruinneas parsála, ag cur béime ar roinnt gnéithe teangeolaíocha den fhadhb a bhféadfadh brí a bheith leo.</abstract_ga>
      <abstract_ka>ჩვენ შევაჩვენეთ ანალიზი UPOS წარმოდგენისთვის წარმოდგენისთვის. შედეგი შესაძლებელია, რომ UPOS-ის ჭდეები როგორც fea-tures ნეიროლური პარასერებისთვის უნდა დარწმუნებელად უფრო დიდი ჭდეების მართლა და რომ დალანური ჭდეების გამოყენება უფრო დიდი პროცესტის გამოყენება, რომელი ჩვენ ასევე განსხვავებთ რას აპექტირებული UPOS ტეგექტების აპექტირება იქნება საკუთარი წარმოწმება, რომელიც პრობლემის შესაძლებელად მნიშვნელოვანი ენგოსტიკური ფექტი</abstract_ka>
      <abstract_hu>Elemzést mutatunk be az UPOS pontosságának az elemzési teljesítményre gyakorolt hatásáról. Az eredmények azt sugallják, hogy az UPOS címkék idegi elemzők fejlesztéseként való felhasználása tiltottan magas címkézési pontosságot igényel, és hogy az arany címkék használata nem lineáris növekedést kínál a teljesítményben, ami valamilyen kivételességre utal. Azt is vizsgáljuk, hogy az előrejelzett UPOS címkék milyen aspektusai befolyásolják a legjobban az elemzési pontosságot, kiemelve a probléma néhány potenciálisan jelentős nyelvi aspektusait.</abstract_hu>
      <abstract_el>Παρουσιάζουμε μια ανάλυση σχετικά με την επίδραση που έχει η ακρίβεια στην απόδοση ανάλυσης. Τα αποτελέσματα δείχνουν ότι η αξιοποίηση των ετικετών ως χαρακτηριστικών για τους νευρωνικούς αναλυτές απαιτεί μια απαγορευμένη υψηλή ακρίβεια ετικετών και ότι η χρήση των χρυσών ετικετών προσφέρει μια μη γραμμική αύξηση της απόδοσης, υποδηλώνοντας κάποιο είδος εξαιρετικότητας. Ερευνούμε επίσης ποιες πτυχές των προβλεπόμενων ετικετών επηρεάζουν περισσότερο την ακρίβεια ανάλυσης, αναδεικνύοντας ορισμένες δυνητικά σημαντικές γλωσσικές πτυχές του προβλήματος.</abstract_el>
      <abstract_it>Presentiamo un'analisi sull'effetto che la precisione UPOS ha sulle prestazioni di analisi. I risultati suggeriscono che utilizzare i tag UPOS come features per i parser neurali richiede una precisione di tagging proibitiva e che l'uso di tag gold offre un aumento non lineare delle prestazioni, suggerendo una sorta di eccezionalità. Analizziamo anche quali aspetti dei tag UPOS previsti influiscono maggiormente sull'accuratezza dell'analisi, evidenziando alcuni aspetti linguistici potenzialmente significativi del problema.</abstract_it>
      <abstract_kk>Біз UPOS дұрыстығын талдау әрекетінің анализациясын көрсетедік. Нәтижелер UPOS тегтерін невралдық талдаушылар үшін fea- tures деп қолдану үшін негізінде жоғары тегтердің дұрыстығын талап етеді және алтын тегтердің қолдануы жоғары жоғары тегтердің көтерілуін талап етеді және бірнеше түрлі тыс Мұндай-ақ біз UPOS тегтерінің қандай аспектерін зерттеп, оның дұрыстығын талдау үшін ең дұрыстығын шешуге әсер етеді, мәселенің кейбір мүмкіндікті лингвистикалық мәселелерін боя</abstract_kk>
      <abstract_mk>Презентираме анализа за ефектот на прецизноста на УПОС на анализата на изведувањето. Резултатите укажуваат на тоа дека употребата на УПОС ознаките како пердури за нервни анализатори бара забранително висока прецизност на ознаките и дека употребата на златни ознаки нуди нелинијарно зголемување на резултатите, што укажува на некаква исклучителност. Исто така, истражуваме какви аспекти од предвидените УПОС ознаки најмногу влијаат на анализата на прецизноста, истакнувајќи некои потенцијално значајни јазички аспекти на проблемот.</abstract_mk>
      <abstract_ms>Kami perkenalkan analisis kesan kepakuan UPOS pada prestasi penghuraian. Hasil menunjukkan bahawa penggunaan tag UPOS sebagai bulu bagi penghurai saraf memerlukan ketepatan tag yang sangat tinggi dan bahawa penggunaan tag emas menawarkan peningkatan prestasi yang tidak linear, menunjukkan semacam keanehan. Kami juga menyelidiki apa aspek tag UPOS terduga yang paling mempengaruhi penghuraian ketepatan, menyatakan beberapa aspek bahasa yang berpotensi bermakna bagi masalah.</abstract_ms>
      <abstract_mt>Aħna nippreżentaw analiżi dwar l-effett li l-preċiżjoni tal-UPOS għandha fuq il-prestazzjoni tal-analiżi. Ir-riżultati jissuġġerixxu li l-ingranaġġ tat-tikketti UPOS bħala fea tures għall-analizzaturi newrali jeħtieġ preċiżjoni tat-tikketti projbittivament għolja u li l-użu tat-tikketti tad-deheb joffri żieda mhux lineari fil-prestazzjoni, li tissuġġerixxi xi tip ta’ eċċezzjoni. Investigaw ukoll liema aspetti tat-tikketti UPOS imbassra għandhom l-aktar impatt fuq l-analiżi tal-preċiżjoni, filwaqt li jenfasizzaw xi aspetti lingwistiċi potenzjalment sinifikanti tal-problema.</abstract_mt>
      <abstract_lt>Pateikiame UPOS tikslumo poveikio analizės rezultatams analizę. Rezultatai rodo, kad UPOS žymenų naudojimas kaip neuralinių analizatorių plunksnų reikalauja pernelyg didelio žymenų tikslumo ir kad naudojant auksinius žymenus gali padidėti ne linijiniai rezultatai, o tai rodo tam tikrą išskirtinį pobūdį. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem.</abstract_lt>
      <abstract_mn>Бид UPOS-ын зөв тодорхойлолтыг хуваалцах үйл ажиллагаанд шинжилгээ үзүүлнэ. Үүний үр дүнд нь мэдрэлийн парссерүүдийн fea-tures гэдэг UPOS тегтүүдийг ашиглах нь хамааралтай өндөр маркингийн зөв байдлыг шаарддаг ба алтын тегтүүдийн хэрэглэх нь шугам биш шугам байдлыг нэмэгдүүлж, зарим төрлийн гайхамшигтай байдлыг илэрхийлж ча Бид мөн UPOS-ын таамаглалтын асуудлыг судалж, асуудлын зарим магадгүй үнэ цэнэтэй хэлний хэлбэрүүдийг тодорхойлдог.</abstract_mn>
      <abstract_no>Vi presenterer ein analyse på effekten UPOS-nøyaktighet har på tolking av utviklinga. Resultater foreslår at å leverara UPOS-taggar som fea-turer for neiralanalyserar krev eit forhindringsfarge høg tagging nøyaktig og at bruken av gull-taggar tilbyr ein ikkje-lineær økning i utviklinga, som foreslår nokre typar unntak. Vi undersøker også kva aspektar av forventa UPOS-taggar påvirkar å tolka nøyaktighet mest, og markerer nokre potensielt betydelige lingviske ansiktar av problemet.</abstract_no>
      <abstract_pl>Przedstawiamy analizę wpływu dokładności UPOS na wydajność parsowania. Wyniki sugerują, że wykorzystanie znaczników UPOS jako cech dla parserów neuronowych wymaga niezbyt wysokiej dokładności tagowania, a zastosowanie złotych tagów oferuje nieliniowy wzrost wydajności, sugerując pewien rodzaj wyjątkowości. Badamy również, jakie aspekty przewidywanych tagów UPOS najbardziej wpływają na dokładność parsowania, podkreślając niektóre potencjalnie znaczące aspekty językowe problemu.</abstract_pl>
      <abstract_ro>Vă prezentăm o analiză a efectului pe care acuratețea UPOS îl are asupra performanței de analiză. Rezultatele sugerează că utilizarea etichetelor UPOS ca features pentru analizoarele neurale necesită o precizie prohibitivă ridicată a etichetării și că utilizarea etichetelor aurii oferă o creștere non-liniară a performanței, sugerând un fel de excepționalitate. De asemenea, investigăm ce aspecte ale etichetelor UPOS preconizate influențează cel mai mult precizia analizării, evidențiind unele aspecte lingvistice potențial semnificative ale problemei.</abstract_ro>
      <abstract_sr>Predstavljamo analizu na tačnost UPOS-a na analizu izvedbe. Rezultati sugeriraju da uključivanje oznake UPOS kao fea-tures za neuralne analizatore zahteva zabranjivo visoka tačnost oznake i da upotreba zlatnih oznake nudi neolinearno povećanje učinka, sugerirajući neku vrstu izuzetnosti. Istražujemo i šta aspekti predviđenih oznake UPOS-a utiču na najprecizniju analizu preciznosti, naglašavajući neke potencijalno značajne jezičke lica problema.</abstract_sr>
      <abstract_ml>യുപോസിന്റെ ശരിയായ പ്രഭാവം പാര്‍സിങ്ങ് ചെയ്യുന്നതിനെക്കുറിച്ച് ഞങ്ങള്‍ ഒരു അന്വേഷണം കൊടുക് ന്യൂറല്‍ പാര്‍സറുകള്‍ക്കുള്ള യുപോസ് ടാഗുകള്‍ ഉപയോഗിക്കുന്നത് നിഷിദ്ധമായ ഉയര്‍ന്ന ടാഗിന്റെ വിശേഷതകളായി യുപോസ് ടാഗുകള്‍ ഉപയോഗിക്കുന്നതിന് ഒരു വ്യത്യസ്ത പ്രശ്നത്തിന്റെ സാധ്യതയുള്ള ചില ഭാഷകങ്ങളുടെ മുഖങ്ങള്‍ പ്രഖ്യാപിക്കുന്നതിന്റെ കാര്യങ്ങള്‍ ഞങ്ങള്‍ അന്വേഷിക്കുന്നു.</abstract_ml>
      <abstract_si>අපි UPOS හරියට විශ්ලේෂණයක් පෙන්වන්න පුළුවන් විශ්ලේෂණයක් තියෙනවා. ප්‍රතිචාර ප්‍රශ්නයක් ප්‍රශ්නය කරනවා කියලා UPOS ටැග් වලින් fea-turis වලින් ප්‍රශ්නයක් නිර්භාවිත විශ්වාස කරනවා නිර්භාවිත විශ්වාස කරනවා සහ සු අපි පරීක්ෂණය කරනවා UPOS ටැග් වලින් ප්‍රශ්නයක් විශ්වාස කරනවා කියලා, ප්‍රශ්නයක් විශ්වාස කරනවා සමහර විශ්වාසිකව භාෂ</abstract_si>
      <abstract_so>Analyo baaritaan saameyn ku saabsan saxda UPOS waxay ku leedahay sameynta baaritaanka. Resultiyada waxaa looga jeedaa in la soo diro alaabta UPOS sida goobaha baarlamaha neurada ah looga baahan yahay si xalaal ah oo aad looga baahdo, iyo in isticmaalka alaabta dahabka ah uu kordhiyo cayiman, si uu u jeedo cayiman cayn ah. Sidoo kale waxaynu baaraynaa waxyaabaha ay ku saameysan yihiin bandhigyada UPOS inay saameyn ku leedahay si saxda ah, waxaana tusinayaa qaar ka mid ah wejiyada luuqadda ee muhiimka ah ee dhibaatada.</abstract_so>
      <abstract_sv>Vi presenterar en analys av vilken effekt UPOS noggrannhet har på tolkningens prestanda. Resultaten tyder på att utnyttjande av UPOS-taggar som features för neurala tolkare kräver en orimligt hög märkningsnoggrannhet och att användningen av guldtaggar erbjuder en icke-linjär ökning av prestanda, vilket tyder på någon form av exceptionellt. Vi undersöker också vilka aspekter av förutspådda UPOS-taggar påverkar tolkningens noggrannhet mest, och belyser några potentiellt meningsfulla språkliga aspekter av problemet.</abstract_sv>
      <abstract_ta>UPOS தெளிவாக்கத்தின் விளைவில் ஒரு ஆய்வு கொண்டு வருகிறோம். @ info: whatsthis நாம் பிரச்சனையின் சில மொழி மொழி முகங்களை வெளிப்படுத்தும் பாதிக்கும் பொருட்களின் எத்தனை விளைவுகளை ஆய்வு செய்கிறோம்.</abstract_ta>
      <abstract_ur>ہم ایک تحلیل پیش کرتے ہیں UPOS دقیق کے بارے میں پارس کرنا پر ہے. نتیجے اس کی پیش کرتی ہیں کہ UPOS ٹاگ کو نائرول پارس کے لئے fea-tures کے طور پر لیورڈ کرنے کی ضرورت ہے کہ ایک منع سے بالا ٹاگ دقیق کی ضرورت ہے اور سونے ٹاگ کے استعمال کے ذریعہ ایک غیر لینیاری اضافہ کرتا ہے، اور کچھ طرح اضافہ کی پیش کرتا ہے. ہم بھی تحقیق کرتے ہیں کہ UPOS ٹاگنوں کی کس طرح کی تغییریں مسئلہ کے بہترین سمجھانے پر اثر دیتی ہیں، اس کے بعض احتمالاً معنی زبان صحیح چہروں کو اثر دیتی ہیں۔</abstract_ur>
      <abstract_uz>Biz UPOS tashkilotlari haqida taʼlumotni bajarishga ega. Natijalar shunday talab qiladi, neyrol parserlarning xususiyatlari sifatida UPOS taglarni qoʻshish kerak va bir necha xil qoʻllanmalarning foydalanishi mumkin. Biz kutilgan UPOS taglarining qanday qismlarini o'rganamiz, bu muammolarning eng muhimiga muhimi fikrlarni ko'rsatish mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi đưa ra một bản phân tích về kết quả chính xác UPOS đã phân tích năng lượng. Kết quả cho thấy việc sử dụng các thẻ UPOS như kiểu biểu tượng gan dạ cho các phân viên thần kinh đòi hỏi độ chính xác theo dấu cực cao và rằng sử dụng các thẻ vàng mang lại hiệu suất không tuyến, cho thấy một số loại tính cách khác đặc biệt. Chúng tôi cũng điều tra các khía cạnh của các thẻ UPOS đã đoán trước nhiều hơn về độ chính xác, quét sạch những khía cạnh ngôn ngữ có tiềm năng của vấn đề này.</abstract_vi>
      <abstract_bg>Представяме анализ на ефекта на точността върху ефективността на анализа. Резултатите показват, че използването на тагове като характеристики за неврални анализатори изисква прекалено висока точност на етикетиране и че използването на златни тагове предлага нелинейно увеличаване на производителността, което предполага някакъв вид изключителност. Също така изследваме какви аспекти на прогнозираните тагове оказват най-голямо влияние върху точността на анализирането, като подчертаваме някои потенциално значими лингвистични аспекти на проблема.</abstract_bg>
      <abstract_da>Vi præsenterer en analyse af den effekt UPOS nøjagtighed har på fortolkningens ydeevne. Resultaterne tyder på, at udnyttelse af UPOS-tags som features for neurale fortolkere kræver en forbudt høj tagging nøjagtighed, og at brugen af gold tags giver en ikke-lineær stigning i ydeevnen, hvilket tyder på en slags usædvanlighed. Vi undersøger også, hvilke aspekter af forudsigede UPOS-tags påvirker fortolkningsnøjagtigheden mest og fremhæver nogle potentielt meningsfulde sproglige aspekter af problemet.</abstract_da>
      <abstract_nl>We presenteren een analyse van het effect dat UPOS nauwkeurigheid heeft op parsing prestaties. Resultaten suggereren dat het inzetten van UPOS tags als features voor neurale parsers een onbetaalbaar hoge tagging nauwkeurigheid vereist en dat het gebruik van gouden tags een niet-lineaire toename in prestaties biedt, wat een soort van uitzonderlijkheid suggereert. We onderzoeken ook welke aspecten van voorspelde UPOS-tags de nauwkeurigheid van het parsen het meest beïnvloeden, waarbij we enkele mogelijk betekenisvolle linguïstische facetten van het probleem benadrukken.</abstract_nl>
      <abstract_hr>Predstavljamo analizu učinka tačnosti UPOS-a na analizu učinka. Rezultati sugeriraju da primjena oznake UPOS-a kao fea-tures za neuroanalizatore zahtijeva zabranično visoka preciznost oznake i da uporaba zlatnih oznake nudi neolinearno povećanje učinka, što predlaže neku vrstu izuzetnosti. Također istražujemo kakve aspekte predviđenih UPOS znakova utječe na najprecizniju analizu preciznosti, naglašavajući neke potencijalno značajne jezičke lica problema.</abstract_hr>
      <abstract_de>Wir präsentieren eine Analyse zum Einfluss von UPOS Genauigkeit auf die Parsing Performance. Die Ergebnisse deuten darauf hin, dass die Verwendung von UPOS-Tags als Features für neuronale Parser eine unerschwinglich hohe Tagging-Genauigkeit erfordert und dass die Verwendung von Gold-Tags eine nicht-lineare Leistungssteigerung bietet, was auf eine Art Ausnahmefall hindeutet. Wir untersuchen auch, welche Aspekte vorhergesagter UPOS-Tags die Genauigkeit der Parsing-Analyse am meisten beeinflussen, wobei einige potenziell bedeutsame linguistische Facetten des Problems hervorgehoben werden.</abstract_de>
      <abstract_ko>UPOS의 정확성이 분석 성능에 미치는 영향을 분석했습니다.그 결과 UPOS 마커를 신경해석기의 특징으로 활용하려면 높은 마커 정밀도가 필요한데, 황금 마커를 사용하면 비선형으로 성능을 높일 수 있다는 것은 예외가 있음을 보여준다.또한 예측된 UPOS 태그가 해석의 정확성에 가장 큰 영향을 미치는 부분도 조사했고 문제의 잠재적인 의미 있는 언어도 강조했다.</abstract_ko>
      <abstract_fa>ما یک تحلیل بر اثر دقیق UPOS روی تحلیل اجرای تحلیل می کنیم. نتیجه‌ها پیشنهاد می‌دهند که استفاده از نقاشی طلا یک افزایش غیر خطی در کاربرد را پیشنهاد می‌دهد، که یک نوع خاصی را پیشنهاد می‌دهد. ما همچنین تحقیق می‌کنیم که چهره‌هایی از نقاشی‌های پیش‌بینی UPOS تاثیر می‌دهند که دقیقات را بیشتر تحلیل می‌کنند، و بعضی چهره‌های زبان‌شناسی که ممکن است معنی‌اثر آن مشکل را تشکیل می‌دهد</abstract_fa>
      <abstract_tr>UPOS dogrudygynyň çykyşynyň bardygyny barlap çözümleşdirip görkezip. Netijenler UPOS tägleri neural parsleriň fea-türleri ýaly çykarmak üçin ýokary derejesi ýok taglamak üçin gerek bolmagy maslahat berýär we altyn tägleriň ullanyşy çyzgyrmazlyk etmäniň ýokary ýok bir artmagy täsir edýändigini maslahat berýär. Biz hem UPOS tägleriň önlenýän sahypalarynyň nähili meselelerin dogrudygyny barlaýarys, meselelerin beýleki wajyp bilen meňzeş dil sahypalaryny ýagtylaýarys.</abstract_tr>
      <abstract_sw>Tunatoa uchambuzi wa athari za ukweli wa UPOS zinazohusu utendaji. Matokeo yanapendekeza kuwa kutuma alama za UPOS kama alama za mabunge ya neura zinahitaji ufanisi wa vifaa vya juu na kwamba matumizi ya alama za dhahabu inatoa ongezeko lisilo la msingi, linalopendekeza a in a fulani ya udanganyifu. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem.</abstract_sw>
      <abstract_af>Ons stel 'n analiseer op die effek UPOS-presies op verwerking van prestasie. Resultate voorstel dat die verwysing van UPOS etikette as fea-tures vir neurale verwerkers 'n prohibitief hoë etiketting presisie nodig en dat die gebruik van goue etikette 'n nie-lineêre vergroting in presisie aanbied, voorstel sommige soort uitsondering. Ons ondersoek ook wat aspekte van voorskoude UPOS-etikette invloek om die meeste presisie te verwerk, verlig sommige potensielik betekende lingwisiese aangesigte van die probleem.</abstract_af>
      <abstract_id>Kami mempersembahkan analisis tentang efek akurasi UPOS pada penanalisan prestasi. Hasil menunjukkan bahwa penggunaan tags UPOS sebagai bulu untuk parser saraf membutuhkan akurasi tagging yang sangat tinggi dan bahwa penggunaan tags emas menawarkan meningkat prestasi yang tidak linear, menunjukkan semacam keanehan. Kami juga menyelidiki aspek-aspek dari tags UPOS yang diprediksi mempengaruhi penghuraian akurasi yang paling, mempertimbangkan beberapa aspek bahasa yang potensial berarti dari masalah.</abstract_id>
      <abstract_am>የUPOS እርግጠኛ ውጤት በማኅበረሰብ ላይ ያለውን አስተያየትን እናቀርባለን፡፡ ፍጥረቶቹ የኦፖএস ምልክቶች ለኔural ፓርራር ማሰናከል የተከለከለ የረጅም ማረፊያ ግንኙነት እንዲያስፈልጋል፣ የወርቅ ምልክቶች ማቀናቀል በተለየ ልዩ ልዩነት እንዲያሳየው ማድረግ ማድረግ እንዲያስፈልጋል፡፡ የUPOS ምልክቶች ምን ያህል አካሄዱን በማስተካከል እናምርመራለን፤ የችሎታዊ የቋንቋ ቋንቋ ፊቶችን እናሳውቃለን፡፡</abstract_am>
      <abstract_sq>Ne paraqesim një analizë mbi efektin që saktësia e UPOS ka në analizimin e performancës. Rezultatet sugjerojnë se përdorimi i etiketave UPOS si pengesa për analizuesit nervorë kërkon një saktësi të lartë ndaluese të etiketave dhe se përdorimi i etiketave të artë ofron një rritje jo-lineare në performancë, duke sugjeruar një lloj të jashtëzakonshme. Ne gjithashtu hetojmë se cilat aspekte të etiketave të parashikuara UPOS ndikojnë më së shumti në analizimin e saktësisë, duke theksuar disa aspekte gjuhësore potencialisht të rëndësishme të problemit.</abstract_sq>
      <abstract_hy>We present an analysis on the effect UPOS accuracy has on parsing performance.  Արդյունքները ցույց են տալիս, որ UPO-ի նշանների օգտագործումը որպես նյարդային վերամշակողների փետուրներ պահանջում է անհրաժեշտ բարձր նշանների ճշգրտություն և որ ոսկու նշանների օգտագործումը հնարավորություն է տալիս ոչ գծային բարձրացում արտադրողականության վրա, առաջարկում է Մենք նաև ուսումնասիրում ենք, թե UPO-ի կանխատեսված նշանների ինչպիսի ասպեկտները ամենաազդում են ճշգրտության վերլուծության վրա, ներկայացնելով որոշ պոտենցիալ իմաստալից լեզվական հատվածներ:</abstract_hy>
      <abstract_az>Biz UPOS ədaləti təhsil etdiyi təqdirdə analizi göstəririk. Sonuçlar təbliğ edir ki, nöral analizacılar üçün fea-tures olaraq UPOS etiketlərinin istifadə etməsi qadağan edilən yüksək etiketlərin doğruluğu və altın etiketlərin istifadəsi müəyyən edilməsini təbliğ edir, bir tür istifadə edir. Biz də tədbir edilmiş UPOS etiketlərin növ aspektlərinin növbəsini təşkil edirik, probleminin bəzi potensial anlamlı dil üzlərini təşkil edirik.</abstract_az>
      <abstract_bn>আমরা ইউপোসের সঠিকভাবে পার্সিং এর প্রভাবের উপর এক বিশ্লেষণ উপস্থাপন করছি। ফলাফল পরামর্শ দিয়েছে যে নিউরুল পার্সারের জন্য বৈশিষ্ট্য হিসেবে UPOS ট্যাগ প্রদান করার বিষয়বস্তু হিসেবে নিষেধাজ্ঞা করা উচ্চট্যাগের সঠিকভাবে প্রয়োজন এবং সোন এই সমস্যার কিছু সম্ভাব্য ভাষার গুরুত্বপূর্ণ ভাষার মুখোমুখি তুলে ধরা যায়।</abstract_bn>
      <abstract_bs>Predstavljamo analizu na učinak tačnosti UPOS-a na analizu učinka. Rezultati sugeriraju da uključivanje oznake UPOS kao fea-tures za neuroanalizatore zahtijeva zabranično visoka preciznost oznake i da upotreba zlatnih oznake nudi neolinearno povećanje učinka, sugerirajući neku vrstu izuzetnosti. Također istražujemo kakve aspekte predviđenih UPOS znakova utiču na najprecizniju analizu preciznosti, naglašavajući neke potencijalno značajne jezičke lica problema.</abstract_bs>
      <abstract_ca>Presentam una an àlisi sobre l'efecte que la precisió UPOS té en l'analització del rendiment. Els resultats suggereixen que utilitzar etiquetes UPOS com plomes per analitzadors neuronals requereix una precisió prohibitivament alta d'etiquetes i que l'ús d'etiquetes d'or ofereix un augment no linear en el rendiment, suggerint alguna mena d'excepció. We also investigate what aspects of predicted UPOS tags impact parsing accuracy the most, highlighting some potentially meaningful linguistic facets of the problem.</abstract_ca>
      <abstract_cs>Předkládáme analýzu vlivu přesnosti UPOS na výkon parsování. Výsledky naznačují, že využití UPOS tagů jako funkcí pro neuronové parsery vyžaduje nepříliš vysokou přesnost tagování a že použití zlatých tagů nabízí nelineární zvýšení výkonu, což naznačuje určitou výjimečnost. Dále zkoumáme, jaké aspekty předpokládaných značek UPOS ovlivňují přesnost analýzy nejvíce, a zdůrazňujeme některé potenciálně smysluplné jazykové aspekty problému.</abstract_cs>
      <abstract_et>Esitame analüüsi UPOS täpsuse mõju parsimise jõudlusele. Tulemused näitavad, et UPOS siltide kasutamine neuroparserite omadustena nõuab liiga suurt sildistamistäpsust ning kuldsete siltide kasutamine pakub mittelineaarset jõudlust, mis viitab mingisugusele erandlikkusele. Samuti uurime, millised aspektid prognoositud UPOS sildid mõjutavad parsimise täpsust kõige rohkem, tuues esile probleemi mõned potentsiaalselt olulised keelelised aspektid.</abstract_et>
      <abstract_fi>Esitämme analyysin UPOS:n tarkkuuden vaikutuksesta jäsentämisen suorituskykyyn. Tulokset viittaavat siihen, että UPOS-tunnisteiden hyödyntäminen neuroparserien ominaisuuksina edellyttää kohtuuttoman suurta merkintätarkkuutta ja että kultatunnisteiden käyttö tarjoaa epälineaarista suorituskykyä, mikä viittaa jonkinlaiseen poikkeuksellisuuteen. Tutkimme myös, mitkä UPOS-tunnisteiden osatekijät vaikuttavat eniten jäsennystarkkuuteen ja korostamme ongelman mahdollisesti merkityksellisiä kielellisiä näkökohtia.</abstract_fi>
      <abstract_sk>Predstavljamo analizo učinka natančnosti UPOS na zmogljivost razčlenitve. Rezultati kažejo, da izkoriščanje oznak UPOS kot lastnosti za nevronske razčlenjevalnike zahteva prepovedano visoko natančnost označevanja in da uporaba zlatih oznak ponuja nelinearno povečanje zmogljivosti, kar kaže na nekakšno izjemnost. Prav tako raziskujemo, kateri vidiki napovedanih oznak UPOS najbolj vplivajo na natančnost razčlenjanja, pri čemer poudarjamo nekatere potencialno pomembne jezikovne vidike problema.</abstract_sk>
      <abstract_jv>Geweke nambah kelas nyong ng pansesi kapan kelas nang nggawe sawian nggawe Sugeng menehi arêp ngomong nik nggawe pêrbên iki bakal terus 'Fea-turas' kanggo urêp nggawe gerangkamu dhéwé, akeh dhéwé ngewehku etiket sing ngewehku dhéwé lan nambah etiket sing nambah dhéwé. Awak dhéwé éntuk ujian sing paling nggawe barang penggunaké karo nggawe Perancis, nggawe barang nggawe aturan sing paling nggawe barang kelangan</abstract_jv>
      <abstract_ha>Tuna zo da wani anayyani a kan aikin gaskiya na UPS kan parse. Matamako na gaya cewa, mai bãyar da tagogi na UPS kamar tayari wa parser ɗin neural na ƙayyade tsari mai girma ga tagogi na haramta kuma da amfani da alama na zĩnãriya ya ƙara girma ga aikin na-line, yana son wani abu na ƙayyade. Kayya, Munã tambaya masu da matsayin tagogi na gane UPS sun yi amfani ga parse da haske mafi gaskiya, kuma yana sarrafa wasu fassaran harsheski masu yiwuwa da muhimu na so.</abstract_ha>
      <abstract_he>We present an analysis on the effect UPOS accuracy has on parsing performance.  התוצאות מציעות ששימוש בתגים UPOS כפיצות עבור מחקרי עצבים דורש מדויקת תגים גבוהה באופן אסוף ושהשימוש בתגים זהב מציע עלייה לא לינרית ביצועים, מציעה סוג כלשהו של יוצא דופן. אנחנו חוקרים גם איזה היבטים של תוויות UPOS צפויות משפיעים על בדיקת בדיקת ביותר, ומדגישים כמה פנים שפתיים פוטנציאליים משמעותיים של הבעיה.</abstract_he>
      <abstract_bo>ང་ཚོས་UPOS་བདེན་བཤད་ཀྱི་དབྱེ་ཞིབ་གཅིག་སྟོན་པ་ཡིན་ན་གྲུབ་བཤད་ཀྱི་ལས་འགུལ་བཤད་ཡོད། Results suggest that leveraging UPOS tags as fea-tures for neural parsers requires a prohibitively high tagging accuracy and that the use of gold tags offers a non-linear increase in performance, suggesting some sort of exceptionality. ང་ཚོས་དུས་མཐུན་པའི་(UPOS)ཤོག་བྱང་གི་ཆེས་གང་ཞིག་གིས་གསལ་བཤད་ཀྱི་ཡོད་པ་ཞིག་དཔྱད་ཞིབ་བྱེད་ཀྱི་ཡོད་པ་དང་མཐའ་ཉེས</abstract_bo>
      </paper>
    <paper id="11">
      <title>Bridging Information-Seeking Human Gaze and Machine Reading Comprehension</title>
      <author><first>Jonathan</first><last>Malmaud</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <author><first>Yevgeni</first><last>Berzak</last></author>
      <pages>142–152</pages>
      <abstract>In this work, we analyze how human gaze during <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> is conditioned on the given <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension question</a>, and whether this signal can be beneficial for machine reading comprehension. To this end, we collect a new eye-tracking dataset with a large number of participants engaging in a multiple choice reading comprehension task. Our analysis of this data reveals increased fixation times over parts of the text that are most relevant for answering the question. Motivated by this finding, we propose making automated reading comprehension more human-like by mimicking human information-seeking reading behavior during <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>. We demonstrate that this approach leads to performance gains on multiple choice question answering in English for a state-of-the-art reading comprehension model.</abstract>
      <url hash="42856397">2020.conll-1.11</url>
      <doi>10.18653/v1/2020.conll-1.11</doi>
      <bibkey>malmaud-etal-2020-bridging</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopqa">OneStopQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
    </paper>
    <paper id="12">
      <title>A Corpus of Very Short Scientific Summaries</title>
      <author><first>Yifan</first><last>Chen</last></author>
      <author><first>Tamara</first><last>Polajnar</last></author>
      <author><first>Colin</first><last>Batchelor</last></author>
      <author><first>Simone</first><last>Teufel</last></author>
      <pages>153–164</pages>
      <abstract>We present a new summarisation task, taking <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific articles</a> and producing journal table-of-contents entries in the chemistry domain. These are one- or two-sentence author-written summaries that present the key findings of a paper. This is a first look at this summarisation task with an open access publication corpus consisting of titles and abstracts, as input texts, and short author-written advertising blurbs, as the ground truth. We introduce the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and evaluate <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> with state-of-the-art summarisation methods.</abstract>
      <url hash="aee8def9">2020.conll-1.12</url>
      <doi>10.18653/v1/2020.conll-1.12</doi>
      <bibkey>chen-etal-2020-corpus</bibkey>
      <pwccode url="https://github.com/atulkum/pointer_summarizer" additional="false">atulkum/pointer_summarizer</pwccode>
    </paper>
    <paper id="16">
      <title>Identifying Incorrect Labels in the CoNLL-2003 Corpus<fixed-case>C</fixed-case>o<fixed-case>NLL</fixed-case>-2003 Corpus</title>
      <author><first>Frederick</first><last>Reiss</last></author>
      <author><first>Hong</first><last>Xu</last></author>
      <author><first>Bryan</first><last>Cutler</last></author>
      <author><first>Karthik</first><last>Muthuraman</last></author>
      <author><first>Zachary</first><last>Eichenberger</last></author>
      <pages>215–226</pages>
      <abstract>The CoNLL-2003 corpus for English-language named entity recognition (NER) is one of the most influential corpora for NER model research. A large number of publications, including many landmark works, have used this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> as a source of ground truth for NER tasks. In this paper, we examine this corpus and identify over 1300 incorrect labels (out of 35089 in the corpus). In particular, the number of incorrect labels in the test fold is comparable to the number of errors that state-of-the-art models make when running <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a> over this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>. We describe the process by which we identified these incorrect labels, using novel variants of techniques from <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>. We also summarize the types of errors that we found, and we revisit several recent results in <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">NER</a> in light of the corrected data. Finally, we show experimentally that our corrections to the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> have a positive impact on three state-of-the-art models.</abstract>
      <url hash="b111e911">2020.conll-1.16</url>
      <doi>10.18653/v1/2020.conll-1.16</doi>
      <bibkey>reiss-etal-2020-identifying</bibkey>
      <pwccode url="https://github.com/codait/text-extensions-for-pandas" additional="true">codait/text-extensions-for-pandas</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll">CoNLL++</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rcv1">RCV1</pwcdataset>
    </paper>
    <paper id="20">
      <title>Cross-lingual Embeddings Reveal Universal and Lineage-Specific Patterns in Grammatical Gender Assignment</title>
      <author><first>Hartger</first><last>Veeman</last></author>
      <author><first>Marc</first><last>Allassonnière-Tang</last></author>
      <author><first>Aleksandrs</first><last>Berdicevskis</last></author>
      <author><first>Ali</first><last>Basirat</last></author>
      <pages>265–275</pages>
      <abstract>Grammatical gender is assigned to nouns differently in different languages. Are all factors that influence <a href="https://en.wikipedia.org/wiki/Sex_assignment">gender assignment</a> idiosyncratic to languages or are there any that are universal? Using cross-lingual aligned word embeddings, we perform two experiments to address these questions about <a href="https://en.wikipedia.org/wiki/Language_typology">language typology</a> and <a href="https://en.wikipedia.org/wiki/Cognition">human cognition</a>. In both experiments, we predict the gender of nouns in language X using a <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> trained on the nouns of language Y, and take the <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier’s accuracy</a> as a measure of transferability of gender systems. First, we show that for 22 <a href="https://en.wikipedia.org/wiki/Indo-European_languages">Indo-European languages</a> the <a href="https://en.wikipedia.org/wiki/Language_transfer">transferability</a> decreases as the <a href="https://en.wikipedia.org/wiki/Phylogenetic_tree">phylogenetic distance</a> increases. This correlation supports the claim that some gender assignment factors are idiosyncratic, and as the languages diverge, the proportion of shared inherited idiosyncrasies diminishes. Second, we show that when the <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> is trained on two <a href="https://en.wikipedia.org/wiki/Afroasiatic_languages">Afro-Asiatic languages</a> and tested on the same 22 <a href="https://en.wikipedia.org/wiki/Indo-European_languages">Indo-European languages</a> (or vice versa), its performance is still significantly above the chance baseline, thus showing that universal factors exist and, moreover, can be captured by word embeddings. When the <a href="https://en.wikipedia.org/wiki/Classifier_(linguistics)">classifier</a> is tested across families and on inanimate nouns only, the performance is still above baseline, indicating that the universal factors are not limited to <a href="https://en.wikipedia.org/wiki/Sex">biological sex</a>.</abstract>
      <url hash="65b7a793">2020.conll-1.20</url>
      <doi>10.18653/v1/2020.conll-1.20</doi>
      <bibkey>veeman-etal-2020-cross</bibkey>
    </paper>
    <paper id="21">
      <title>Modelling Lexical Ambiguity with Density Matrices</title>
      <author><first>Francois</first><last>Meyer</last></author>
      <author><first>Martha</first><last>Lewis</last></author>
      <pages>276–290</pages>
      <abstract>Words can have multiple senses. Compositional distributional models of meaning have been argued to deal well with finer shades of meaning variation known as <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy</a>, but are not so well equipped to handle word senses that are etymologically unrelated, or <a href="https://en.wikipedia.org/wiki/Homonym">homonymy</a>. Moving from <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vectors</a> to <a href="https://en.wikipedia.org/wiki/Density_matrix">density matrices</a> allows us to encode a <a href="https://en.wikipedia.org/wiki/Probability_distribution">probability distribution</a> over different senses of a word, and can also be accommodated within a compositional distributional model of meaning. In this paper we present three new neural models for learning <a href="https://en.wikipedia.org/wiki/Density_matrix">density matrices</a> from a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, and test their ability to discriminate between <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a> on a range of compositional datasets. When paired with a particular composition method, our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms existing vector-based compositional models as well as strong sentence encoders.</abstract>
      <url hash="a6b0e982">2020.conll-1.21</url>
      <attachment type="OptionalSupplementaryMaterial" hash="1cb732f8">2020.conll-1.21.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2020.conll-1.21</doi>
      <bibkey>meyer-lewis-2020-modelling</bibkey>
    </paper>
    <paper id="25">
      <title>Word Representations Concentrate and This is Good News !</title>
      <author><first>Romain</first><last>Couillet</last></author>
      <author><first>Yagmur Gizem</first><last>Cinar</last></author>
      <author><first>Eric</first><last>Gaussier</last></author>
      <author><first>Muhammad</first><last>Imran</last></author>
      <pages>325–334</pages>
      <abstract>This article establishes that, unlike the legacy tf*idf representation, recent natural language representations (word embedding vectors) tend to exhibit a so-called concentration of measure phenomenon, in the sense that, as the representation size p and database size n are both large, their behavior is similar to that of large dimensional Gaussian random vectors. This phenomenon may have important consequences as <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning algorithms</a> for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language data</a> could be amenable to improvement, thereby providing new theoretical insights into the field of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>.<i>concentration of measure phenomenon</i>, in the sense that, as the representation size <tex-math>p</tex-math> and database size <tex-math>n</tex-math> are both large, their behavior is similar to that of large dimensional Gaussian random vectors. This phenomenon may have important consequences as machine learning algorithms for natural language data could be amenable to improvement, thereby providing new theoretical insights into the field of natural language processing.</abstract>
      <url hash="559aa2de">2020.conll-1.25</url>
      <doi>10.18653/v1/2020.conll-1.25</doi>
      <bibkey>couillet-etal-2020-word</bibkey>
      <pwccode url="https://github.com/ygcinar/nlp-concentration" additional="false">ygcinar/nlp-concentration</pwccode>
    </paper>
    <paper id="26">
      <title>LazImpa : Lazy and Impatient neural agents learn to communicate efficiently<fixed-case>L</fixed-case>az<fixed-case>I</fixed-case>mpa”: Lazy and Impatient neural agents learn to communicate efficiently</title>
      <author><first>Mathieu</first><last>Rita</last></author>
      <author><first>Rahma</first><last>Chaabouni</last></author>
      <author><first>Emmanuel</first><last>Dupoux</last></author>
      <pages>335–343</pages>
      <abstract>Previous work has shown that <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">artificial neural agents</a> naturally develop surprisingly non-efficient codes. This is illustrated by the fact that in a referential game involving a speaker and a listener neural networks optimizing accurate transmission over a discrete channel, the emergent messages fail to achieve an optimal length. Furthermore, frequent messages tend to be longer than infrequent ones, a pattern contrary to the Zipf Law of Abbreviation (ZLA) observed in all natural languages. Here, we show that near-optimal and ZLA-compatible messages can emerge, but only if both the speaker and the listener are modified. We hence introduce a new <a href="https://en.wikipedia.org/wiki/Communication_system">communication system</a>, LazImpa, where the speaker is made increasingly lazy, i.e., avoids long messages, and the listener impatient, i.e., seeks to guess the intended content as soon as possible.</abstract>
      <url hash="38192e0a">2020.conll-1.26</url>
      <attachment type="OptionalSupplementaryMaterial" hash="df2dd4d9">2020.conll-1.26.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2020.conll-1.26</doi>
      <bibkey>rita-etal-2020-lazimpa</bibkey>
    </paper>
    <paper id="36">
      <title>Analysing Word Representation from the Input and Output Embeddings in Neural Network Language Models</title>
      <author><first>Steven</first><last>Derby</last></author>
      <author><first>Paul</first><last>Miller</last></author>
      <author><first>Barry</first><last>Devereux</last></author>
      <pages>442–454</pages>
      <abstract>Researchers have recently demonstrated that tying the neural weights between the input look-up table and the output classification layer can improve training and lower perplexity on sequence learning tasks such as <a href="https://en.wikipedia.org/wiki/Language_model">language modelling</a>. Such a procedure is possible due to the design of the softmax classification layer, which previous work has shown to comprise a viable set of semantic representations for the model vocabulary, and these these output embeddings are known to perform well on word similarity benchmarks. In this paper, we make meaningful comparisons between the input and output embeddings and other SOTA distributional models to gain a better understanding of the types of information they represent. We also construct a new set of word embeddings using the output embeddings to create locally-optimal approximations for the intermediate representations from the <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>. These locally-optimal embeddings demonstrate excellent performance across all our evaluations.</abstract>
      <url hash="ecbb9454">2020.conll-1.36</url>
      <attachment type="OptionalSupplementaryMaterial" hash="3590f41e">2020.conll-1.36.OptionalSupplementaryMaterial.pdf</attachment>
      <doi>10.18653/v1/2020.conll-1.36</doi>
      <bibkey>derby-etal-2020-analysing</bibkey>
      <pwccode url="https://github.com/stevend94/conll2020" additional="false">stevend94/conll2020</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mpqa-opinion-corpus">MPQA Opinion Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="40">
      <title>Do n’t Parse, Insert : Multilingual Semantic Parsing with Insertion Based Decoding</title>
      <author><first>Qile</first><last>Zhu</last></author>
      <author><first>Haidar</first><last>Khan</last></author>
      <author><first>Saleh</first><last>Soltan</last></author>
      <author><first>Stephen</first><last>Rawls</last></author>
      <author><first>Wael</first><last>Hamza</last></author>
      <pages>496–506</pages>
      <abstract>Semantic parsing is one of the key components of <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding systems</a>. A successful <a href="https://en.wikipedia.org/wiki/Parsing">parse</a> transforms an input utterance to an action that is easily understood by the <a href="https://en.wikipedia.org/wiki/System">system</a>. Many <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> have been proposed to solve this problem, from conventional rule-based or statistical slot-filling systems to shift-reduce based neural parsers. For complex parsing tasks, the state-of-the-art method is based on an autoregressive sequence to sequence model that generates the parse directly. This model is slow at inference time, generating <a href="https://en.wikipedia.org/wiki/Parsing">parses</a> in O(n) decoding steps (n is the length of the target sequence). In addition, we demonstrate that this method performs poorly in zero-shot cross-lingual transfer learning settings. In this paper, we propose a non-autoregressive parser which is based on the insertion transformer to overcome these two issues. Our approach 1) speeds up decoding by 3x while outperforming the <a href="https://en.wikipedia.org/wiki/Autoregressive_model">autoregressive model</a> and 2) significantly improves cross-lingual transfer in the low-resource setting by 37 % compared to autoregressive baseline. We test our approach on three wellknown monolingual datasets : ATIS, SNIPS and TOP. For cross-lingual semantic parsing, we use the MultiATIS++ and the multilingual TOP datasets.</abstract>
      <url hash="aba91e7a">2020.conll-1.40</url>
      <doi>10.18653/v1/2020.conll-1.40</doi>
      <bibkey>zhu-etal-2020-dont</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snips">SNIPS</pwcdataset>
    </paper>
    <paper id="49">
      <title>Cloze Distillation : Improving Neural Language Models with Human Next-Word Prediction</title>
      <author><first>Tiwalayo</first><last>Eisape</last></author>
      <author><first>Noga</first><last>Zaslavsky</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <pages>609–619</pages>
      <abstract>Contemporary autoregressive language models (LMs) trained purely on corpus data have been shown to capture numerous features of human incremental processing. However, past work has also suggested dissociations between <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus probabilities</a> and human next-word predictions. Here we evaluate several state-of-the-art <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> for their match to human next-word predictions and to reading time behavior from <a href="https://en.wikipedia.org/wiki/Eye_movement">eye movements</a>. We then propose a novel method for distilling the linguistic information implicit in human linguistic predictions into pre-trained LMs : Cloze Distillation. We apply this method to a baseline neural LM and show potential improvement in reading time prediction and <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> to held-out human cloze data.</abstract>
      <url hash="3828b793">2020.conll-1.49</url>
      <doi>10.18653/v1/2020.conll-1.49</doi>
      <bibkey>eisape-etal-2020-cloze</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-103">WikiText-103</pwcdataset>
    </paper>
    <paper id="52">
      <title>From Dataset Recycling to Multi-Property Extraction and Beyond</title>
      <author><first>Tomasz</first><last>Dwojak</last></author>
      <author><first>Michał</first><last>Pietruszka</last></author>
      <author><first>Łukasz</first><last>Borchmann</last></author>
      <author><first>Jakub</first><last>Chłędowski</last></author>
      <author><first>Filip</first><last>Graliński</last></author>
      <pages>641–651</pages>
      <abstract>This paper investigates various Transformer architectures on the WikiReading Information Extraction and Machine Reading Comprehension dataset. The proposed dual-source model outperforms the current state-of-the-art by a large margin. Next, we introduce WikiReading Recycled-a newly developed public dataset, and the task of multiple-property extraction. It uses the same data as WikiReading but does not inherit its predecessor’s identified disadvantages. In addition, we provide a human-annotated test set with diagnostic subsets for a detailed analysis of <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance.</abstract>
      <url hash="ed5e0dcc">2020.conll-1.52</url>
      <doi>10.18653/v1/2020.conll-1.52</doi>
      <bibkey>dwojak-etal-2020-dataset</bibkey>
      <pwccode url="https://github.com/applicaai/multi-property-extraction" additional="false">applicaai/multi-property-extraction</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikireading-recycled">WikiReading Recycled</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikireading">WikiReading</pwcdataset>
    </paper>
    </volume>
  <volume id="shared" ingest-date="2020-11-05">
    <meta>
      <booktitle>Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</booktitle>
      <editor><first>Stephan</first><last>Oepen</last></editor>
      <editor><first>Omri</first><last>Abend</last></editor>
      <editor><first>Lasha</first><last>Abzianidze</last></editor>
      <editor><first>Johan</first><last>Bos</last></editor>
      <editor><first>Jan</first><last>Hajič</last></editor>
      <editor><first>Daniel</first><last>Hershcovich</last></editor>
      <editor><first>Bin</first><last>Li</last></editor>
      <editor><first>Tim</first><last>O'Gorman</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <editor><first>Daniel</first><last>Zeman</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="3e727ac8">2020.conll-shared.0</url>
      <bibkey>conll-2020-conll</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Hitachi at MRP 2020 : Text-to-Graph-Notation Transducer<fixed-case>MRP</fixed-case> 2020: Text-to-Graph-Notation Transducer</title>
      <author><first>Hiroaki</first><last>Ozaki</last></author>
      <author><first>Gaku</first><last>Morio</last></author>
      <author><first>Yuta</first><last>Koreeda</last></author>
      <author><first>Terufumi</first><last>Morishita</last></author>
      <author><first>Toshinori</first><last>Miyoshi</last></author>
      <pages>40–52</pages>
      <abstract>This paper presents our proposed <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> for the shared task on Meaning Representation Parsing (MRP 2020) at CoNLL, where participant systems were required to parse five types of <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> in different languages. We propose to unify these tasks as a text-to-graph-notation transduction in which we convert an input text into a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph notation</a>. To this end, we designed a novel Plain Graph Notation (PGN) that handles various <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graphs</a> universally. Then, our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> predicts a PGN-based sequence by leveraging Transformers and biaffine attentions. Notably, our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> can handle any PGN-formatted graphs with fewer framework-specific modifications. As a result, ensemble versions of the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> tied for 1st place in both cross-framework and cross-lingual tracks.</abstract>
      <url hash="2a4dc896">2020.conll-shared.4</url>
      <doi>10.18653/v1/2020.conll-shared.4</doi>
      <bibkey>ozaki-etal-2020-hitachi</bibkey>
    </paper>
    <paper id="7">
      <title>HUJI-KU at MRP 2020 : Two Transition-based Neural Parsers<fixed-case>HUJI</fixed-case>-<fixed-case>KU</fixed-case> at <fixed-case>MRP</fixed-case> 2020: Two Transition-based Neural Parsers</title>
      <author><first>Ofir</first><last>Arviv</last></author>
      <author><first>Ruixiang</first><last>Cui</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <pages>73–82</pages>
      <abstract>This paper describes the HUJI-KU system submission to the shared task on CrossFramework Meaning Representation Parsing (MRP) at the 2020 Conference for Computational Language Learning (CoNLL), employing TUPA and the HIT-SCIR parser, which were, respectively, the baseline system and winning system in the 2019 MRP shared task. Both are transition-based parsers using BERT contextualized embeddings. We generalized TUPA to support the newly-added MRP frameworks and languages, and experimented with multitask learning with the HIT-SCIR parser. We reached 4th place in both the crossframework and cross-lingual tracks.</abstract>
      <url hash="6a26281e">2020.conll-shared.7</url>
      <doi>10.18653/v1/2020.conll-shared.7</doi>
      <bibkey>arviv-etal-2020-huji</bibkey>
    </paper>
    </volume>
</collection>