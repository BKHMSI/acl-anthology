<?xml version='1.0' encoding='utf-8'?>
<collection id="2019.gwc">
  <volume id="1" ingest-date="2021-02-07">
    <meta>
      <booktitle>Proceedings of the 10th Global Wordnet Conference</booktitle>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Christiane</first><last>Fellbaum</last></editor>
      <publisher>Global Wordnet Association</publisher>
      <address>Wroclaw, Poland</address>
      <month>July</month>
      <year>2019</year>
      <url hash="b9a36b9f">2019.gwc-1</url>
    </meta>
    <frontmatter>
      <url hash="15aafacc">2019.gwc-1.0</url>
      <bibkey>gwc-2019-global</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Making Sense of schema.org with <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a><fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Csaba</first><last>Veres</last></author>
      <pages>1–9</pages>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Schema.org">schema.org initiative</a> was designed to introduce machine readable metadata into the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a>. This paper investigates conceptual biases in the schema through a mapping exercise between schema.org types and WordNet synsets. We create a <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">mapping ontology</a> which establishes the relationship between schema metadata types and the corresponding everyday concepts. This in turn can be used to enhance metadata annotation to include a more complete description of knowledge on the Web of data.</abstract>
      <url hash="3b98056b">2019.gwc-1.1</url>
      <bibkey>veres-2019-making</bibkey>
    </paper>
    <paper id="4">
      <title>Including Swiss Standard German in GermaNet<fixed-case>S</fixed-case>wiss Standard <fixed-case>G</fixed-case>erman in <fixed-case>G</fixed-case>erma<fixed-case>N</fixed-case>et</title>
      <author><first>Eva</first><last>Huber</last></author>
      <author><first>Erhard</first><last>Hinrichs</last></author>
      <pages>24–32</pages>
      <abstract>GermaNet (Henrich and Hinrichs, 2010 ; Hamp and Feldweg, 1997) is a comprehensive wordnet of Standard German spoken in the Federal Republic of Germany. The GermaNet team aims at modelling the basic vocabulary of the <a href="https://en.wikipedia.org/wiki/Language">language</a>. German is an official language or a minority language in many countries. It is an official language in <a href="https://en.wikipedia.org/wiki/Austria">Austria</a>, <a href="https://en.wikipedia.org/wiki/Germany">Germany</a> and <a href="https://en.wikipedia.org/wiki/Switzerland">Switzerland</a>, each with its own codified standard variety (Auer, 2014, p. 21), and also in <a href="https://en.wikipedia.org/wiki/Belgium">Belgium</a>, Liechtenstein, and Luxemburg. German is recognized as a minority language in thirteen additional countries, including <a href="https://en.wikipedia.org/wiki/Brazil">Brasil</a>, <a href="https://en.wikipedia.org/wiki/Italy">Italy</a>, <a href="https://en.wikipedia.org/wiki/Poland">Poland</a>, and <a href="https://en.wikipedia.org/wiki/Russia">Russia</a>. However, the different standard varieties of <a href="https://en.wikipedia.org/wiki/German_language">German</a> are currently not represented in <a href="https://en.wikipedia.org/wiki/GermaNet">GermaNet</a>. With this project, we make a start on changing this by including one <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">variety</a>, namely <a href="https://en.wikipedia.org/wiki/Swiss_Standard_German">Swiss Standard German</a>, into <a href="https://en.wikipedia.org/wiki/GermaNet">GermaNet</a>. This shall give a more inclusive perspective on the <a href="https://en.wikipedia.org/wiki/German_language">German language</a>. We will argue that Swiss Standard German words, Helvetisms, are best included into the already existing wordnet GermaNet, rather than creating them as a separate wordnet.</abstract>
      <url hash="3bce8e57">2019.gwc-1.4</url>
      <bibkey>huber-hinrichs-2019-including</bibkey>
    </paper>
    <paper id="5">
      <title>Danish in Wikidata lexemes<fixed-case>D</fixed-case>anish in <fixed-case>W</fixed-case>ikidata lexemes</title>
      <author><first>Finn Årup</first><last>Nielsen</last></author>
      <pages>33–38</pages>
      <abstract>Wikidata introduced support for lexicographic data in 2018. Here we describe the lexicographic part of <a href="https://en.wikipedia.org/wiki/Wikidata">Wikidata</a> as well as experiences with setting up <a href="https://en.wikipedia.org/wiki/Lexeme">lexemes</a> for the <a href="https://en.wikipedia.org/wiki/Danish_language">Danish language</a>. We note various possible annotations for <a href="https://en.wikipedia.org/wiki/Lexeme">lexemes</a> as well as discuss various choices made.</abstract>
      <url hash="f6a92f6d">2019.gwc-1.5</url>
      <bibkey>nielsen-2019-danish</bibkey>
    </paper>
    <paper id="12">
      <title>Towards interpretable, data-derived distributional meaning representations for <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a> : A dataset of properties and concepts</title>
      <author><first>Pia</first><last>Sommerauer</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>85–98</pages>
      <abstract>This paper proposes a <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for investigating which types of <a href="https://en.wikipedia.org/wiki/Semantic_property">semantic properties</a> are represented by <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional data</a>. The core of our <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> consists of relations between concepts and properties. We provide hypotheses on which <a href="https://en.wikipedia.org/wiki/Property_(philosophy)">properties</a> are reflected in <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional data</a> or not based on the type of relation. We outline strategies for creating a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of positive and negative examples for various semantic properties, which can not easily be separated on the basis of general similarity (e.g. fly : seagull, penguin). This way, a <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional model</a> can only distinguish between positive and negative examples through evidence for a target property. Once completed, this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> can be used to test our hypotheses and work towards data-derived interpretable representations.</abstract>
      <url hash="891ae9b6">2019.gwc-1.12</url>
      <bibkey>sommerauer-etal-2019-towards</bibkey>
    </paper>
    <paper id="13">
      <title>Connections between the semantic layer of Walenty valency dictionary and <a href="https://en.wikipedia.org/wiki/PlWordNet">PlWordNet</a><fixed-case>P</fixed-case>l<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Elzbieta</first><last>Hajnicz</last></author>
      <author><first>Tomasz</first><last>Bartosiak</last></author>
      <pages>99–107</pages>
      <abstract>In this paper we discuss how <a href="https://en.wikipedia.org/wiki/Walenty">Walenty</a> is using PLWORDNET to represent <a href="https://en.wikipedia.org/wiki/Semantic_Web">semantic information</a>. We decided to use PLWORDNET lexical units and synsets to describe both the predicate meaning and the semantic fields of its arguments. The original design decision required some further refinement caused by the structure of PLWORDNET and complex relations between arguments.</abstract>
      <url hash="187c4ba0">2019.gwc-1.13</url>
      <bibkey>hajnicz-bartosiak-2019-connections</bibkey>
    </paper>
    <paper id="14">
      <title>Sense Vocabulary Compression through the Semantic Knowledge of <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> for Neural Word Sense Disambiguation<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for Neural Word Sense Disambiguation</title>
      <author><first>Loïc</first><last>Vial</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>108–117</pages>
      <abstract>In this article, we tackle the issue of the limited quantity of manually sense annotated corpora for the task of <a href="https://en.wikipedia.org/wiki/Word_sense_disambiguation">word sense disambiguation</a>, by exploiting the semantic relationships between senses such as <a href="https://en.wikipedia.org/wiki/Synonym">synonymy</a>, <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy</a> and <a href="https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy">hyponymy</a>, in order to compress the sense vocabulary of <a href="https://en.wikipedia.org/wiki/Princeton_WordNet">Princeton WordNet</a>, and thus reduce the number of different sense tags that must be observed to disambiguate all words of the lexical database. We propose two different methods that greatly reduce the size of neural WSD models, with the benefit of improving their coverage without additional <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a>, and without impacting their <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a>. In addition to our methods, we present a WSD system which relies on pre-trained BERT word vectors in order to achieve results that significantly outperforms the state of the art on all WSD evaluation tasks.</abstract>
      <url hash="7eb838b3">2019.gwc-1.14</url>
      <bibkey>vial-etal-2019-sense</bibkey>
      <pwccode url="https://github.com/getalp/disambiguate" additional="true">getalp/disambiguate</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2013">SemEval 2013</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/word-sense-disambiguation-a-unified">Word Sense Disambiguation: a Unified Evaluation Framework and Empirical Comparison</pwcdataset>
    </paper>
    <paper id="16">
      <title>Merging DanNet with Princeton Wordnet<fixed-case>D</fixed-case>an<fixed-case>N</fixed-case>et with <fixed-case>P</fixed-case>rinceton <fixed-case>W</fixed-case>ordnet</title>
      <author><first>Bolette Sandford</first><last>Pedersen</last></author>
      <author><first>Sanni</first><last>Nimb</last></author>
      <author><first>Ida Rørmann</first><last>Olsen</last></author>
      <author><first>Sussi</first><last>Olsen</last></author>
      <pages>125–134</pages>
      <abstract>In this paper we describe the merge of the Danish wordnet, DanNet, with <a href="https://en.wikipedia.org/wiki/Princeton_Wordnet">Princeton Wordnet</a> applying a two-step approach. We first link from the <a href="https://en.wikipedia.org/wiki/English_language">English Princeton core</a> to <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a> (5,000 base concepts) and then proceed to linking the rest of the <a href="https://en.wikipedia.org/wiki/Danish_language">Danish vocabulary</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a>, thus going from <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a> to <a href="https://en.wikipedia.org/wiki/English_language">English</a>. Since the Danish wordnet is built bottom-up from Danish lexica and corpora, all taxonomies are monolingually based and thus not necessarily directly compatible with the coverage and structure of the Princeton WordNet. This fact proves to pose some challenges to the linking procedure since a considerable number of the links can not be realised via the preferred cross-language synonym link which implies a more or less precise correlation between the two concepts. Instead, a subpart of the links are realised through near synonym or hyponymy links to compensate for the fact that no precise translation can be found in the target resource. The tool WordnetLoom is currently used for manual linking but procedures for a more automatic procedure in future is discussed. We conclude that the two resources actually differ from each other quite more than expected, both vocabulary and structure-wise.</abstract>
      <url hash="52cc903c">2019.gwc-1.16</url>
      <bibkey>pedersen-etal-2019-merging</bibkey>
    </paper>
    <paper id="18">
      <title>Synthetic, yet natural : Properties of WordNet random walk corpora and the impact of rare words on embedding performance<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et random walk corpora and the impact of rare words on embedding performance</title>
      <author><first>Filip</first><last>Klubička</last></author>
      <author><first>Alfredo</first><last>Maldonado</last></author>
      <author><first>Abhijit</first><last>Mahalunkar</last></author>
      <author><first>John</first><last>Kelleher</last></author>
      <pages>140–150</pages>
      <abstract>Creating <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> that reflect semantic relationships encoded in lexical knowledge resources is an open challenge. One approach is to use a random walk over a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> to generate a pseudo-corpus and use this <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> to train embeddings. However, the effect of the shape of the <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> on the generated pseudo-corpora, and on the resulting <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, has not been studied. To explore this, we use <a href="https://en.wikipedia.org/wiki/WordNet">English WordNet</a>, constrained to the taxonomic (tree-like) portion of the <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph</a>, as a case study. We investigate the properties of the generated pseudo-corpora, and their impact on the resulting <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. We find that the distributions in the psuedo-corpora exhibit properties found in natural corpora, such as Zipf’s and Heaps’ law, and also observe that the proportion of rare words in a pseudo-corpus affects the performance of its embeddings on word similarity.</abstract>
      <url hash="664ac0d4">2019.gwc-1.18</url>
      <bibkey>klubicka-etal-2019-synthetic</bibkey>
    </paper>
    <paper id="20">
      <title>Visualising WordNet Embeddings : some preliminary results<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Embeddings: some preliminary results</title>
      <author><first>Csaba</first><last>Veres</last></author>
      <pages>160–165</pages>
      <abstract>AutoExtend is a method for learning unambiguous vector embeddings for <a href="https://en.wikipedia.org/wiki/Word_sense">word senses</a>. We visualise these <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> with <a href="https://en.wikipedia.org/wiki/T-SNE">t-SNE</a>, which further compresses the vectors to the x, y plane. We show that the t-SNE co-ordinates can be used to reveal interesting semantic relations between word senses, and propose a new method that uses the simple x, y coordinates to compute semantic similarity. This can be used to propose new links and alterations to existing ones in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>. We plan to add this approach to the existing toolbox of methods in an attempt to understand learned semantic relations in <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>.</abstract>
      <url hash="6c821842">2019.gwc-1.20</url>
      <bibkey>veres-2019-visualising</bibkey>
    </paper>
    <paper id="22">
      <title>Evaluating the <a href="https://en.wikipedia.org/wiki/Wordnet">Wordnet</a> and CoRoLa-based Word Embedding Vectors for <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian</a> as Resources in the Task of Microworlds Lexicon Expansion<fixed-case>W</fixed-case>ordnet and <fixed-case>C</fixed-case>o<fixed-case>R</fixed-case>o<fixed-case>L</fixed-case>a-based Word Embedding Vectors for <fixed-case>R</fixed-case>omanian as Resources in the Task of Microworlds Lexicon Expansion</title>
      <author><first>Elena</first><last>Irimia</last></author>
      <author><first>Maria</first><last>Mitrofan</last></author>
      <author><first>Verginica</first><last>Mititelu</last></author>
      <pages>176–184</pages>
      <abstract>Within a larger frame of facilitating <a href="https://en.wikipedia.org/wiki/Human–robot_interaction">human-robot interaction</a>, we present here the creation of a <a href="https://en.wikipedia.org/wiki/Core_vocabulary">core vocabulary</a> to be learned by a robot. It is extracted from two tokenised and lemmatized scenarios pertaining to two imagined microworlds in which the robot is supposed to play an assistive role. We also evaluate two <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">resources</a> for their utility for expanding this <a href="https://en.wikipedia.org/wiki/Vocabulary">vocabulary</a> so as to better cope with the robot’s communication needs. The language under study is <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian</a> and the resources used are the <a href="https://en.wikipedia.org/wiki/Romanian_language">Romanian wordnet</a> and word embedding vectors extracted from the large representative corpus of contemporary Romanian, CoRoLa. The evaluation is made for two situations : one in which the words are not semantically disambiguated before expanding the lexicon, and another one in which they are disambiguated with senses from the Romanian wordnet. The appropriateness of each resource is discussed.</abstract>
      <url hash="9b9c07ac">2019.gwc-1.22</url>
      <bibkey>irimia-etal-2019-evaluating</bibkey>
    </paper>
    <paper id="24">
      <title>Thinking globally, acting locally   Progress in the African Wordnet Project<fixed-case>A</fixed-case>frican <fixed-case>W</fixed-case>ordnet Project</title>
      <author><first>Marissa</first><last>Griesel</last></author>
      <author><first>Sonja</first><last>Bosch</last></author>
      <author><first>Mampaka Lydia</first><last>Mojapelo</last></author>
      <pages>191–196</pages>
      <abstract>The African Wordnet Project (AWN) includes all nine indigenous South African languages, namely <a href="https://en.wikipedia.org/wiki/Zulu_language">isiZulu</a>, <a href="https://en.wikipedia.org/wiki/Xhosa_language">isiXhosa</a>, <a href="https://en.wikipedia.org/wiki/Tswana_language">Setswana</a>, Sesotho sa Leboa, Tshivenda, <a href="https://en.wikipedia.org/wiki/Sotho_language">Siswati</a>, <a href="https://en.wikipedia.org/wiki/Sotho_language">Sesotho</a>, <a href="https://en.wikipedia.org/wiki/Southern_Ndebele_language">isiNdebele</a> and <a href="https://en.wikipedia.org/wiki/Tsonga_language">Xitsonga</a>. The AWN currently includes 61 000 synsets as well as definitions and usage examples for a large part of the synsets. The project recently received extended funding from the South African Centre for Digital Language Resources (SADiLaR) and aims to update all aspects of the current resource, including the seed list used for new development, software tools used and mapping the AWN to the latest version of PWN 3.1. As with any resource development project, it is essential to also include phases of focused quality assurance and updating of the basis on which the resource is built. The <a href="https://en.wikipedia.org/wiki/Languages_of_Africa">African languages</a> remain under-resourced. This paper describes progress made in the development of the <a href="https://en.wikipedia.org/wiki/AWN">AWN</a> as well as recent technical improvements.</abstract>
      <url hash="3354369e">2019.gwc-1.24</url>
      <bibkey>griesel-etal-2019-thinking</bibkey>
    </paper>
    <paper id="25">
      <title>Commonsense Reasoning Using <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and SUMO : a Detailed Analysis<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et and <fixed-case>SUMO</fixed-case>: a Detailed Analysis</title>
      <author><first>Javier</first><last>Álvez</last></author>
      <author><first>Itziar</first><last>Gonzalez-Dios</last></author>
      <author><first>German</first><last>Rigau</last></author>
      <pages>197–205</pages>
      <abstract>We describe a detailed analysis of a sample of large benchmark of commonsense reasoning problems that has been automatically obtained from <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a>, SUMO and their mapping. The objective is to provide a better assessment of the quality of both the <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmark</a> and the involved knowledge resources for advanced commonsense reasoning tasks. By means of this analysis, we are able to detect some knowledge misalignments, mapping errors and lack of knowledge and resources. Our final objective is the extraction of some guidelines towards a better exploitation of this commonsense knowledge framework by the improvement of the included resources.</abstract>
      <url hash="2665f7f4">2019.gwc-1.25</url>
      <bibkey>alvez-etal-2019-commonsense</bibkey>
    <title_ar>منطق العموم باستخدام WordNet و SUMO: تحليل مفصل</title_ar>
      <title_es>Razonamiento de sentido común con WordNet y SUMO: un análisis detallado</title_es>
      <title_fr>Raisonnement de bon sens à l'aide de WordNet et SUMO : une analyse détaillée</title_fr>
      <title_pt>Raciocínio de senso comum usando WordNet e SUMO: uma análise detalhada</title_pt>
      <title_ja>WordNetと相撲を使った常識的な推論：詳細な分析</title_ja>
      <title_zh>用WordNet、SUMO常识推理详细分析</title_zh>
      <title_hi>WordNet और SUMO का उपयोग करके Commonsense Reasoning: एक विस्तृत विश्लेषण</title_hi>
      <title_ru>Обоснование здравого смысла с использованием WordNet и SUMO: подробный анализ</title_ru>
      <title_ga>Réasúnaíocht Commonsense ag Úsáid WordNet agus SUMO: Anailís Mhionsonraithe</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Λογισμός κοινής λογικής χρησιμοποιώντας το και μια λεπτομερή ανάλυση</title_el>
      <title_hu>A WordNet és a SUMO használatával használt általános érvelés: részletes elemzés</title_hu>
      <title_it>Ragionamento di commonsese utilizzando WordNet e SUMO: un'analisi dettagliata</title_it>
      <title_kk>WordNet және SUMO қолданылатын Commonsense себебі: Егжей- тегжейі анализ</title_kk>
      <title_lt>Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis</title_lt>
      <title_ml>വാര്‍ഡ് നെറ്റും SUMO ഉപയോഗിക്കുന്നതിന്റെ കമോണ്‍സണ്‍സ് റികോണ്‍സ് ചെയ്യുന്നു: വിശദീകരിച്ച അന്യായം</title_ml>
      <title_mt>Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis</title_mt>
      <title_no>Redigering av kommunikasjon Bruk WordNet og SUMO: ein detaljert analyse</title_no>
      <title_mk>Компонентно размислување со користење на WordNet и SUMO: детална анализа</title_mk>
      <title_pl>Rozumowanie powszechnego rozumu za pomocą WordNet i SUMO: szczegółowa analiza</title_pl>
      <title_ms>Alasan Komuni Menggunakan WordNet dan SUMO: Analisi Terperinci</title_ms>
      <title_ro>Utilizarea WordNet și SUMO: o analiză detaliată</title_ro>
      <title_sr>Razlog Komunikacije Koristenja WordNet i SUMO: Detaljna analiza</title_sr>
      <title_si>WordNet සහ SUMO පාවිච්චි කරන්න සම්බන්ධ කාරණය: විස්තර විශ්ලේෂණයක්</title_si>
      <title_so>Qoraalka isticmaalka WordNet iyo SUMO: A detailed Analysis</title_so>
      <title_mn>WordNet болон SUMO-г ашиглах хамтын шалтгаан: Detailed Analysis</title_mn>
      <title_sv>Commonsense Resoning Använda WordNet och SUMO: En detaljerad analys</title_sv>
      <title_ta>வார்த்தையையும் SUMO யையும் பயன்படுத்தும் பொருள் காரணம்: விவரமான விளக்கம்</title_ta>
      <title_ur>WordNet اور SUMO کا استعمال کرنا کمنسنسس کا دلیل</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Động cơ lý lẽ chung dùng WordNet và SUMO: A Spider Analysis</title_vi>
      <title_nl>Redenen met behulp van WordNet en SUMO: een gedetailleerde analyse</title_nl>
      <title_bg>Обикновено разсъждаване с помощта на УърдНет и СУМО: подробен анализ</title_bg>
      <title_da>Grundlæggende årsager ved hjælp af WordNet og SUMO: en detaljeret analyse</title_da>
      <title_hr>Razlog zajedničkog korištenja WordNet i SUMO: detaljna analiza</title_hr>
      <title_de>Commonsense Reasoning mit WordNet und SUMO: eine detaillierte Analyse</title_de>
      <title_ko>WordNet과 SUMO를 사용한 상식 추리: 상세한 분석</title_ko>
      <title_id>Reasoning Komunis Menggunakan WordNet dan SUMO: Analisi Rincian</title_id>
      <title_sw>Maoni yanayotumia Mtandao wa WordNet na SUMO: Uchambuzi wa kina</title_sw>
      <title_tr>Commonsense WordNet ve SUMO kullanımı sebepleri: Ayrıntılı Analizi</title_tr>
      <title_fa>دلیل استفاده از WordNet و SUMO: یک تحلیل جزئیات</title_fa>
      <title_am>የመዝገበ ቃላት እና SUMO በመጠቀም ላይ አቀማመጥ</title_am>
      <title_hy>Comment</title_hy>
      <title_bn>কমান্সনসেন্স ওয়ার্ডনেট এবং SUMO ব্যবহার করা হচ্ছে: বিস্তারিত বিশ্লেষণ</title_bn>
      <title_sq>Për arsye të zakonshme duke përdorur WordNet dhe SUMO: një analizë e detajuar</title_sq>
      <title_bs>Razlog zajedničkog korištenja WordNet i SUMO: detaljna analiza</title_bs>
      <title_az>WordNet v톛 SUMO istifad톛 etm톛k 칲칞칲n Commonsense Reasoning: Detailed Analysis</title_az>
      <title_cs>Commonsense odůvodnění pomocí WordNet a SUMO: podrobná analýza</title_cs>
      <title_et>WordNeti ja SUMO kasutamine: üksikasjalik analüüs</title_et>
      <title_af>Commonsense Reasoning Gebruik WordNet en Sumo: ' n Gedetaileerde Analisie</title_af>
      <title_ca>Reasoning Commons Using WordNet and SUMO: una anàlisi detallada</title_ca>
      <title_fi>Yleinen järkeily WordNetin ja SUMO:n avulla: yksityiskohtainen analyysi</title_fi>
      <title_jv>Sampeyan Ngusungguna Ketoke Word net karo SUMO: Ndelengno Detayed</title_jv>
      <title_sk>Splošno razumevanje uporabe WordNet in SUMO: podrobna analiza</title_sk>
      <title_he>הגיון משותף באמצעות WordNet וסומו: ניתוח מפורט</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>Commonsense Reasoning Using WordNet and SUMO: a Detailed Analysis</title_bo>
      <abstract_fr>Nous décrivons une analyse détaillée d'un échantillon de grands repères de problèmes de raisonnement de bon sens qui ont été automatiquement obtenus à partir de WordNet, SUMO et de leur mappage. L'objectif est de fournir une meilleure évaluation de la qualité de l'indice de référence et des ressources de connaissances impliquées pour les tâches avancées de raisonnement de bon sens. Grâce à cette analyse, nous sommes en mesure de détecter certains défauts d'alignement des connaissances, des erreurs de cartographie et un manque de connaissances et de ressources. Notre objectif final est l'extraction de quelques lignes directrices pour une meilleure exploitation de ce cadre de connaissances de bon sens par l'amélioration des ressources incluses.</abstract_fr>
      <abstract_ar>نصف تحليلاً مفصلاً لعينة من المعايير الكبيرة لمشاكل التفكير المنطقي التي تم الحصول عليها تلقائيًا من WordNet و SUMO ورسم الخرائط الخاصة بهم. الهدف هو تقديم تقييم أفضل لجودة كل من المعيار المعياري وموارد المعرفة المعنية لمهام التفكير المنطقي المتقدمة. من خلال هذا التحليل ، نحن قادرون على اكتشاف بعض اختلالات المعرفة ورسم الخرائط ونقص المعرفة والموارد. هدفنا النهائي هو استخراج بعض المبادئ التوجيهية نحو استغلال أفضل لإطار عمل المعرفة المنطقي هذا من خلال تحسين الموارد المضمنة.</abstract_ar>
      <abstract_pt>Descrevemos uma análise detalhada de uma amostra de grande referência de problemas de raciocínio de senso comum que foi obtida automaticamente do WordNet, SUMO e seu mapeamento. O objetivo é fornecer uma melhor avaliação da qualidade tanto do benchmark quanto dos recursos de conhecimento envolvidos para tarefas avançadas de raciocínio de senso comum. Por meio dessa análise, conseguimos detectar alguns desalinhamentos de conhecimento, erros de mapeamento e falta de conhecimento e recursos. Nosso objetivo final é a extração de algumas diretrizes para uma melhor exploração desse arcabouço de conhecimento do senso comum através do aprimoramento dos recursos incluídos.</abstract_pt>
      <abstract_es>Describimos un análisis detallado de una muestra de grandes puntos de referencia de problemas de razonamiento de sentido común que se ha obtenido automáticamente de WordNet, SUMO y su mapeo. El objetivo es proporcionar una mejor evaluación de la calidad tanto del punto de referencia como de los recursos de conocimiento involucrados para tareas avanzadas de razonamiento de sentido común. Mediante este análisis, podemos detectar algunos desajustes de conocimiento, errores de mapeo y falta de conocimientos y recursos. Nuestro objetivo final es la extracción de algunas pautas para una mejor explotación de este marco de conocimiento de sentido común mediante la mejora de los recursos incluidos.</abstract_es>
      <abstract_ja>WordNet、SUMO、およびそれらのマッピングから自動的に得られた常識的推論問題の大きなベンチマークのサンプルの詳細な分析について説明します。目的は、高度な常識的推論タスクのためのベンチマークと関連する知識リソースの両方の品質のより良い評価を提供することです。この分析によって、私たちはいくつかの知識のずれ、マッピングエラー、および知識とリソースの欠如を検出することができます。私たちの最終的な目的は、含まれるリソースの改善によって、この常識的な知識フレームワークをよりよく活用するためのいくつかのガイドラインの抽出です。</abstract_ja>
      <abstract_hi>हम सामान्य ज्ञान तर्क समस्याओं के बड़े बेंचमार्क के नमूने के एक विस्तृत विश्लेषण का वर्णन करते हैं जो स्वचालित रूप से वर्डनेट, SUMO और उनके मानचित्रण से प्राप्त किया गया है। इसका उद्देश्य उन्नत कॉमनसेंस तर्क कार्यों के लिए बेंचमार्क और शामिल ज्ञान संसाधनों दोनों की गुणवत्ता का बेहतर मूल्यांकन प्रदान करना है। इस विश्लेषण के माध्यम से, हम कुछ ज्ञान misalignments, मानचित्रण त्रुटियों और ज्ञान और संसाधनों की कमी का पता लगाने में सक्षम हैं। हमारा अंतिम उद्देश्य शामिल संसाधनों के सुधार द्वारा इस सामान्य ज्ञान के ढांचे के बेहतर दोहन की दिशा में कुछ दिशानिर्देशों का निष्कर्षण है।</abstract_hi>
      <abstract_zh>言从WordNet,SUMO及射中自得常识推理大体,准试样本详细分析。 所以为高常识推理的基准和所及的知识资源的质量评估。 以此论之,能检得失,映误乏资。 吾最终目标取则,以改入所苞益用常识性知框架。</abstract_zh>
      <abstract_ru>Мы описываем подробный анализ выборки больших эталонов проблем здравого смысла, которые были автоматически получены из WordNet, SUMO и их картирования. Цель заключается в том, чтобы лучше оценить качество как эталонных, так и связанных с ними ресурсов знаний для решения сложных задач, связанных с здравым смыслом. С помощью этого анализа мы можем обнаружить некоторые несоответствия в знаниях, ошибки картирования и отсутствие знаний и ресурсов. Наша конечная цель состоит в том, чтобы получить некоторые руководящие принципы для лучшего использования этой системы знаний здравого смысла путем улучшения включенных ресурсов.</abstract_ru>
      <abstract_ga>Déanaimid cur síos ar anailís mhionsonraithe ar shampla de thagarmharc mór d'fhadhbanna réasúnaíochta ciallmhara a fuarthas go huathoibríoch ó WordNet, SUMO agus a gcuid mapála. Is é an cuspóir measúnú níos fearr a sholáthar ar cháilíocht an tagarmhairc agus na n-acmhainní eolais lena mbaineann le haghaidh ardtascanna réasúnaíochta ciallmhara. Trí bhíthin na hanailíse seo, táimid in ann roinnt mí-ailínithe eolais, earráidí mapála agus easpa eolais agus acmhainní a bhrath. Is é an cuspóir deiridh atá againn ná roinnt treoirlínte a bhaint amach chun leas níos fearr a bhaint as an gcreat eolais chiallmhar seo trí fheabhas a chur ar na hacmhainní atá san áireamh.</abstract_ga>
      <abstract_hu>Részletes elemzést írunk le a WordNet, SUMO és azok feltérképezéséből automatikusan megszerzett, közértelmes érvelési problémák nagymértékű referenciaértékének mintájáról. A cél az, hogy jobb értékelést nyújtson mind a referenciaérték, mind a részt vevő tudásforrások minőségéről a fejlett közértelmes érvelési feladatokhoz. Ennek az elemzésnek köszönhetően képesek vagyunk felismerni néhány ismerethibát, feltérképezési hibát, valamint az ismeretek és erőforrások hiányát. Végső célkitűzésünk néhány iránymutatás kidolgozása ennek a közértelmes tudási keretnek a jobb kiaknázása érdekében a bevont erőforrások javításával.</abstract_hu>
      <abstract_el>Περιγράφουμε μια λεπτομερή ανάλυση ενός δείγματος μεγάλου βαθμού αναφοράς προβλημάτων λογικής κοινής λογικής που έχει ληφθεί αυτόματα από το WordNet, το SUMO και τη χαρτογράφηση τους. Στόχος είναι η καλύτερη αξιολόγηση της ποιότητας τόσο του δείκτη αναφοράς όσο και των σχετικών πόρων γνώσης για προηγμένα καθήκοντα λογικής. Μέσω αυτής της ανάλυσης, είμαστε σε θέση να εντοπίσουμε κάποιες λανθασμένες ευθυγραμμίσεις γνώσης, λάθη χαρτογράφησης και έλλειψη γνώσης και πόρων. Ο τελικός μας στόχος είναι η εξαγωγή ορισμένων κατευθυντήριων γραμμών για την καλύτερη αξιοποίηση αυτού του πλαισίου κοινής λογικής γνώσης με τη βελτίωση των περιεχομένων πόρων.</abstract_el>
      <abstract_it>Descriviamo un'analisi dettagliata di un campione di grandi benchmark di problemi di ragionamento di senso comune che è stato ottenuto automaticamente da WordNet, SUMO e la loro mappatura. L'obiettivo è quello di fornire una migliore valutazione della qualità sia del benchmark che delle risorse di conoscenza coinvolte per compiti avanzati di ragionamento di buon senso. Attraverso questa analisi, siamo in grado di rilevare alcuni disallineamenti della conoscenza, errori di mappatura e mancanza di conoscenze e risorse. Il nostro obiettivo finale è l'estrazione di alcune linee guida per un migliore sfruttamento di questo quadro di conoscenza comune attraverso il miglioramento delle risorse incluse.</abstract_it>
      <abstract_kk>Біз WordNet, SUMO және олардың картасынан автоматты түрде алған көпшілік сезімдік мәселелердің үлкен тегжейлі анализ үлгісін анықтаймыз. Мақсат - бағыттау белгісінің сапасын және қосымша білім ресурстарының көптеген көптеген тапсырмалар үшін жақсы оқу. Бұл анализ арқылы бір білім қатесін, қатесін картап, білім мен ресурстардың жоқ болуын анықтай аламыз. Біздің соңғы мақсатымыз - кейбір бағыттау жолдарын, бұл көпшілік мәліметтердің қолдануын жақсы қолдануға арналған ресурстарды жақсартуға көмектесу.</abstract_kk>
      <abstract_mk>Ние опишуваме детална анализа на примерок на големи референтни значки на заеднички проблеми со размислување кои се автоматски добиени од WordNet, SUMO и нивното мапирање. The objective is to provide a better assessment of the quality of both the benchmark and the involved knowledge resources for advanced commonsense reasoning tasks.  Со оваа анализа, можеме да откриеме некои недоразбирања на знаењето, мапирање грешки и недостаток на знаење и ресурси. Нашата конечна цел е извлекувањето на некои насоки кон подобро искористување на оваа заедничка рамка на знаење со подобрување на вклучените ресурси.</abstract_mk>
      <abstract_lt>Mes aprašome išsamią didelės bendro pagrįstumo problemų, gautų automatiškai iš WordNet, SUMO ir jų žemėlapių, lyginamosios analizę. Tikslas – geriau įvertinti lyginamojo rodiklio ir susijusių žinių išteklių kokybę pažangioms bendroms pagrįstoms užduotims atlikti. Taikant šią analizę galime nustatyti kai kuriuos žinių sutrikimus, klaidų žemėlapių nustatymą ir žinių bei išteklių trūkumą. Our final objective is the extraction of some guidelines towards a better exploitation of this commonsense knowledge framework by the improvement of the included resources.</abstract_lt>
      <abstract_ms>Kami menggambarkan analisis terperinci sampel benchmark besar masalah penyebab yang biasa yang telah diambil secara automatik dari WordNet, SUMO dan petakan mereka. Tujuan adalah untuk menyediakan penilaian yang lebih baik kualiti kedua-dua tanda referensi dan sumber pengetahuan yang terlibat untuk tugas pemikiran umum lanjut. Dengan analisis ini, kita mampu mengesan beberapa penyesuaian pengetahuan, petakan ralat dan kekurangan pengetahuan dan sumber. Tujuan akhir kita adalah pengekstrakan beberapa arah ke arah pengeksploitasi yang lebih baik dari kerangka pengetahuan umum ini dengan peningkatan sumber yang termasuk.</abstract_ms>
      <abstract_ml>വാര്‍ഡ്നെറ്റ്, SUMO, അവരുടെ മാപ്പിങ്ങില്‍ നിന്നും സ്വയം കിട്ടിയ പ്രശ്നങ്ങളുടെ ഒരു വലിയ ബെന്‍ച്മാര്‍ക്കിന്‍റെ ഒരു മാതൃകയെപ്പറ്റി വ ഈ ലക്ഷ്യത്തിന്റെ ലക്ഷ്യത്തില്‍ മെച്ചപ്പെടുത്തുന്ന ബെന്‍ച്മാര്‍ക്കിന്‍റെ വ്യവസ്ഥയെയും ഉള്‍പെടുത്തുന്ന ജ്ഞാന വിഭ ഈ അന്വേഷണത്തിന്‍റെ മുഖാന്തരം നമുക്ക് കുറച്ച് അറിവ് തെറ്റുകള്‍ കണ്ടെത്താന്‍ കഴിയും, തെറ്റുകള്‍ മാപ്പ് ചെയ്യാനും, അറി നമ്മുടെ അവസാനത്തെ ലക്ഷ്യത്തില്‍ ഉള്‍പ്പെടുത്തിയ വിഭവങ്ങളുടെ മെച്ചപ്പെടുത്തുന്നതിനാല്‍ കൂടുതല്‍ മെച്ചപ്പെട്ട ഈ കമ</abstract_ml>
      <abstract_mt>Aħna niddeskrivu analiżi dettaljata ta’ kampjun ta’ punt ta’ riferiment kbir ta’ problemi ta’ raġunament komuni li nkisbu awtomatikament minn WordNet, SUMO u l-immappjar tagħhom. L-għan huwa li tiġi pprovduta valutazzjoni a ħjar tal-kwalità kemm tal-punt ta’ riferiment kif ukoll tar-riżorsi tal-għarfien involuti għal kompiti avvanzati ta’ raġunament komuni. Permezz ta’ din l-analiżi, nistgħu ninsabu xi allinjamenti żbaljati fl-għarfien, żbalji fl-immappjar u nuqqas ta’ għarfien u riżorsi. Our final objective is the extraction of some guidelines towards a better exploitation of this commonsense knowledge framework by the improvement of the included resources.</abstract_mt>
      <abstract_ka>ჩვენ აღწერეთ ყველაზე დიდი ბენქმენტის პარამენტის პრობლემების მაგალითის განსაზღვრებული ანალიზი, რომელიც WordNet, SUMO და მათი კაპრაფიკაციის ავტომატურად მიღებულია. მიზეზი არის უკეთესი განსაზღვრება, რომელიც კონფერმაქტის კაalitეტის და შესახებ კონფიგურაციის რესურსების განსაზღვრება საზოგადოებო საზოგადოებო პასუ ამ ანალიზაციის გამოყენებით, ჩვენ შეგვიძლია განვიცნოთ ზოგიერთი ცნობიერების შეცდომა, შეცდომა და ცნობიერების და რესურსის არსებობა. ჩვენი საბოლოო მიზეზი არის სხვა მიზეზების გამოყენება, რომელიც უკეთესი გამოყენება ამ საბოლოო მეცნიერების პარამეტრების გამოყენება, რომელიც გამოყენებული რეს</abstract_ka>
      <abstract_pl>Opisujemy szczegółową analizę próbki dużych referencji problemów rozumowania zdrowego rozsądku, która została automatycznie uzyskana z WordNet, SUMO i ich mapowania. Celem jest zapewnienie lepszej oceny jakości zarówno wskaźnika referencyjnego, jak i zaangażowanych zasobów wiedzy do zaawansowanych zadań rozumowania zdrowego rozsądku. Dzięki tej analizie jesteśmy w stanie wykryć pewne niedopasowania wiedzy, błędy mapowania oraz brak wiedzy i zasobów. Naszym ostatecznym celem jest wydobycie pewnych wytycznych w celu lepszego wykorzystania tych ram wiedzy zdrowego rozsądku poprzez poprawę zasobów.</abstract_pl>
      <abstract_sr>Opišemo detaljnu analizu uzorka velikih kritika problema sa razumanjem uobičajenog razuma koji je automatski dobijen od WordNet, SUMO i njihove mapiranje. Cilj je osigurati bolju procjenu kvalitete referencije i uključenih znanstvenih resursa za napredne zadatke razumljivanja zajedničkog smisla. Uz ovu analizu možemo otkriti neke nepravde znanja, mapiranje grešaka i nedostatak znanja i resursa. Naš zadnji cilj je izvlačenje nekih vodiča prema boljoj ekspluataciji ovog okvira znanja zajedničkog smisla poboljšanjem uključenih resursa.</abstract_sr>
      <abstract_mn>Бид WordNet, SUMO болон газрын зурагтаас автоматаар гарсан олон чухал ойлголтын асуудлуудын жишээний нарийвчлалтай шинжилгээг тайлбарлаж байна. Цахилгаан нь дэвшилтэй ойлголтын даалгаварын талаар илүү сайн оюун ухааны баялаг болон мэдлэг боловсруулах боломжтой баялаг өгөх юм. Энэ шинжилгээний аргаар бид зарим мэдлэг буруу байдлыг, алдаа, мэдлэг, эх үүсвэрийн алдаа газрын зураг олох боломжтой болно. Бидний төгсгөл зорилго бол зарим загваруудыг илүү сайн ашиглах гэх мэт санааны мэдлэг үйл ажиллагааг нэмэгдүүлэх юм.</abstract_mn>
      <abstract_so>Anagaa sawiranaya sameynta badan oo ku saabsan dhibaatooyin ku saabsan arrimaha sababta ah oo ay si automatic ah uga helay WordNet, SUMO iyo kartooyinkooda. Ujeedadu waa in la siiyo qiimeyn ka fiican qiimeynta qiimeynta bangiga iyo hantida aqoonta ee la xiriira shaqooyinka horumarinta shirkadda. Analyskaas darteed waxaynu awoodi karnaa inaannu ogaanno qaar khalad aqoonta ah, baaritaanno qaladyada iyo baahida aqoonta iyo resources. goalkayaga ugu dambaysta ah waa soo bixinta hogaamiyayaal qaarkood oo loogu talagalay si fiican u isticmaalka qasnadahan aqoonta shirkadda ee horumarinta lacagaha ku jira.</abstract_so>
      <abstract_sv>Vi beskriver en detaljerad analys av ett urval av stora riktmärken för allmännyttiga resonemangsproblem som automatiskt erhållits från WordNet, SUMO och deras kartläggning. Målet är att ge en bättre bedömning av kvaliteten på både referensvärdet och de inblandade kunskapsresurserna för avancerade allmännyttiga resonemangsuppgifter. Med hjälp av denna analys kan vi upptäcka vissa kunskapsfel, kartfel och brist på kunskap och resurser. Vårt slutliga mål är att ta fram några riktlinjer för ett bättre utnyttjande av denna allmännyttiga kunskapsram genom att förbättra de inkluderade resurserna.</abstract_sv>
      <abstract_ro>Descriem o analiză detaliată a unui eșantion de referință mare de probleme de raționament comun care a fost obținută automat din WordNet, SUMO și cartografierea acestora. Obiectivul este de a oferi o mai bună evaluare a calității atât a criteriului de referință, cât și a resurselor de cunoștințe implicate pentru sarcini avansate de raționament de bun sens. Prin intermediul acestei analize, suntem capabili să detectăm unele dezalinieri ale cunoștințelor, erori de cartografiere și lipsă de cunoștințe și resurse. Obiectivul nostru final este extragerea unor orientări pentru o mai bună exploatare a acestui cadru de cunoaștere comun prin îmbunătățirea resurselor incluse.</abstract_ro>
      <abstract_ta>வார்ட்நெட், SUMO மற்றும் வரைப்படத்திலிருந்து தானாகவே பெறப்பட்ட பிரச்சனைகளின் பெரிய பென்க்மேக் பிரச்சனையின் ஒரு விவரமான ஆய பென்க்மார்க் மற்றும் சேர்க்கப்பட்ட அறிவிப்பு மூலம் மேம்பட்ட தொழில் கூறும் வேலைகளுக்கு சிறந்த மதிப்பினை கொடு By means of this analysis, we are able to detect some knowledge misalignments, mapping errors and lack of knowledge and resources.  எங்கள் இறுதியின் இலக்கு என்னவென்றால் சில வழிகாட்டிகளை வெளியேற்றுதல் என்பது சேர்க்கப்பட்ட வளங்களை மேம்படுத்துவதால் இந்த த</abstract_ta>
      <abstract_si>අපි විස්තර කරන්නේ විස්තර විශ්ලේෂණයක් විස්තර කරන්නේ විස්තර විශ්ලේෂණයක් වගේ ලොකු බෙන්ච්මාර්ක් වලින් සාමාන්‍ය විස් අරමුණය තමයි බෙන්ච්මාර්ක් එක්ක හොඳ විශේෂයක් සහ සම්බන්ධ විශේෂය සම්බන්ධ විශේෂය සම්බන්ධ විශේෂය මේ විශ්ලේෂණය සඳහා අපිට පුළුවන් දැනගන්න බැරි දේවල් සමහර දේවල් හොයාගන්න, දැනගන්න පුළුවන් වැරදි සැ අපේ අන්තිම අරමුණ අරමුණ තමයි සමහර මාර්ගය පිළිගන්නේ මේ සාමාන්‍ය දැනගන්න අවස්ථාවක් ගැන හොඳ ප්‍රයෝජනය</abstract_si>
      <abstract_ur>ہم ایک بڑے بنچم مارک کی مثال کی تفصیل بیان کرتے ہیں جو WordNet, SUMO اور ان کے نقشه نقشه سے اپنا استعمال کیا گیا ہے۔ مسئلہ یہ ہے کہ بنچم مارک اور مشترک علم سرمایہ کے لئے بہترین ارزش دے۔ اس تحلیل کے ذریعہ ہم کچھ علم غلط باتوں کو پہچان سکتے ہیں، غلطوں کو نقشه بنا سکتے ہیں اور علم اور منابع کے کمزور ہیں۔ ہمارا آخر مقصد یہ ہے کہ بعض راہ دکھانے والی راہ دکھانے کے لئے اس معمولی علم فرمود کی بہترین استعمال کرنا ہے جس طرح شامل ہونے والی سرمایہ کی تدبیر کے ذریعہ۔</abstract_ur>
      <abstract_no>Vi beskriver ein detaljert analyse av eit prøve av stor benchmarke med vanleg rasjonsbruk som er automatisk henta frå WordNet, SUMO og kartlegginga. Målet er å gje ein bedre vurdering av kvaliteten til både benchmarket og dei tilgjengelege kunnskap-ressursane for avanserte fellesskapsrettingsoppgåver. Med denne analysen kan vi finne nokre kunnskap feil, kartlegging av feil og mangling av kunnskap og ressursar. Det siste målet vår er utpakking av nokre retningslinjer mot ein betre ekspluatasjon av denne vanleg kunnskap rammeverket ved forbetringa av dei inkluderte ressursane.</abstract_no>
      <abstract_uz>Biz OrdNet, SUMO va ularning diagrammasini avtomatik olib tashlangan muammolar uchun katta benchmark misol haqida taʼrif qilamiz. Mavzu esa, benchmark va eng yaxshi taʼminlovchi ma'lumot manbalarini o'rganish uchun o'zgartirish mumkin. Bu taʼminlovchi orqali biz bir necha ilmiy notoʻgʻri notoʻgʻri aniqlashni, xatolarni ko'ramiz va ilm va rasmlarning manbalari yo'q. Bizning oxirgi maqsadimizning bir necha qoidalarni ajratish, qo'shilgan rasmlarni o'zgartirish orqali yaxshi foydalanish mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi mô tả một cuộc phân tích chi tiết về một mẫu vật chứa lớn các vấn đề lý lẽ phổ biến mà tự động được lấy từ WordNet, SUMO và bản đồ của chúng. Mục tiêu là cung cấp một đánh giá tốt hơn về chất lượng của cả tiêu chuẩn và nguồn kiến thức liên quan đến các công việc lập luận dạng phổ thông minh tiên tiến. Bằng cách phân tích này, chúng ta có thể phát hiện lỗi nhận thức, lỗi vẽ bản đồ và thiếu kiến thức và nguồn lực. Mục tiêu cuối cùng của chúng ta là rút ra vài hướng dẫn về một cách khai thác tốt hơn trong phạm vi kiến thức thông thường này bằng cách cải thiện nguồn tài nguyên bao gồm.</abstract_vi>
      <abstract_bg>Описваме подробен анализ на извадка от голям бенчмарк на проблемите на разумното разсъждение, която е получена автоматично от и тяхното картографиране. Целта е да се осигури по-добра оценка на качеството както на референтните, така и на свързаните с тях ресурси от знания за напреднали задачи по разумно разсъждаване. Чрез този анализ ние сме в състояние да открием някои несъответствия в знанията, грешки в картографирането и липса на знания и ресурси. Крайната ни цел е извличането на някои насоки за по-добро използване на тази рамка на разумно знание чрез подобряване на включените ресурси.</abstract_bg>
      <abstract_nl>We beschrijven een gedetailleerde analyse van een steekproef van grote benchmark van gezond verstand redeneren problemen die automatisch is verkregen uit WordNet, SUMO en hun mapping. Het doel is om een betere beoordeling te bieden van de kwaliteit van zowel de benchmark als de betrokken kennisbronnen voor geavanceerde gezond verstand redeneren taken. Door middel van deze analyse zijn we in staat om bepaalde kennismislijnen, mapfouten en gebrek aan kennis en middelen op te sporen. Ons uiteindelijke doel is het verkrijgen van enkele richtlijnen voor een betere exploitatie van dit gezond verstand kenniskader door de verbetering van de opgenomen middelen.</abstract_nl>
      <abstract_de>Wir beschreiben eine detaillierte Analyse einer Stichprobe großer Benchmarks für Probleme des gesunden Menschenverstandes, die automatisch aus WordNet, SUMO und deren Mapping gewonnen wurden. Ziel ist es, eine bessere Beurteilung der Qualität des Benchmarks und der beteiligten Wissensressourcen für fortgeschrittene Aufgaben des gesunden Menschenverstandes zu ermöglichen. Mit Hilfe dieser Analyse sind wir in der Lage, einige Wissensfehlstellungen, Mapping-Fehler und fehlende Kenntnisse und Ressourcen zu erkennen. Unser letztes Ziel ist es, einige Richtlinien für eine bessere Nutzung dieses gesunden Wissensrahmens durch die Verbesserung der enthaltenen Ressourcen zu extrahieren.</abstract_de>
      <abstract_id>Kami menggambarkan analisis terperinci dari sampel benchmark besar dari masalah pemikiran umum yang secara otomatis diperoleh dari WordNet, SUMO dan peta mereka. Tujuannya adalah untuk menyediakan penilaian yang lebih baik dari kualitas benchmark dan sumber pengetahuan yang terlibat untuk tugas pemikiran umum yang maju. Dengan analisis ini, kita dapat mendeteksi beberapa kesalahan pengetahuan, peta kesalahan dan kekurangan pengetahuan dan sumber daya. Objektif akhir kami adalah ekstraksi beberapa petunjuk menuju eksploitasi yang lebih baik dari kerangka pengetahuan umum ini dengan peningkatan sumber daya yang termasuk.</abstract_id>
      <abstract_da>Vi beskriver en detaljeret analyse af en prøve af store benchmark af almindelige ræsonnementsproblemer, der automatisk er opnået fra WordNet, SUMO og deres kortlægning. Målet er at give en bedre vurdering af kvaliteten af både benchmark og de involverede videnressourcer til avancerede almindelige ræsonnementsopgaver. Ved hjælp af denne analyse er vi i stand til at opdage nogle vidensfejl, kortlægningsfejl og mangel på viden og ressourcer. Vores endelige mål er at udtrække nogle retningslinjer for en bedre udnyttelse af denne almindelige videnramme ved at forbedre de inkluderede ressourcer.</abstract_da>
      <abstract_ko>WordNet, SUMO, 그리고 그 매핑에서 자동으로 얻어지는 대량의 상식 추리 문제의 기준에 대한 상세한 분석을 묘사했다.고급 상식 추리 임무의 기준과 관련 지식 자원의 질을 더욱 잘 평가하는 것이 목적이다.이런 분석을 통해 우리는 일부 지식의 오차, 반사 오류와 지식과 자원의 결핍을 발견할 수 있다.우리의 최종 목표는 일부 지도 방침을 추출하여 포함된 자원을 개선함으로써 이 상식지식의 틀을 더욱 잘 이용하는 것이다.</abstract_ko>
      <abstract_hr>Opišemo detaljnu analizu uzorka velikih kritika problema s razumanjem uobičajenih smisla koji su automatski dobiti od WordNet, SUMO i njihovih mapiranja. Cilj je obezbijediti bolju procjenu kvalitete referencije i uključenih znanstvenih resursa za napredne zadatke razumljivanja zajedničkog smisla. Uz ovu analizu možemo otkriti neke nepravde znanja, mapiranje grešaka i nedostatak znanja i resursa. Naš konačni cilj je izvlačenje nekih vodiča prema boljoj iskorištavanju ovog okvira znanja zajedničkog smisla poboljšanjem uključenih resursa.</abstract_hr>
      <abstract_sw>Tunaelezea uchambuzi wa kina wa sampuli kubwa ya bendera za umma zinazohusu matatizo yanayotokana na WordNet, SUMO na ramani zao. Lengo ni kutoa tathmini bora ya ubora wa ubora huo pamoja na rasilimali za maarifa kwa kazi zinazoelezea biashara. Kwa njia ya uchambuzi huu, tunaweza kugundua baadhi ya mabaya ya maarifa, kutengeneza makosa na ukosefu wa maarifa na rasilimali. Lengo letu la mwisho ni utekelezaji wa baadhi ya miongozo kwa matumizi bora ya ufahamu huu wa jumuiya kwa maendeleo ya rasilimali zilizojumuisha.</abstract_sw>
      <abstract_tr>Biz WordNet, SUMO ve mappinglerinden alınan büyük mantıklı mantıklı çözüm sorunlarının örneğini detaylar analizi çözeriz. Mazmuny şudyr: benchmarkyň kalitesini hem gelişmäk duýdury düşünüp görenler üçin bilim çeşmelerini gowurak çykarmakdyr. Bu analýusyň ýüzünde biz birnäçe bilim ýalňyşlyklaryny, mappa hatalaryny we bilgi we resurslaryň ýok bolmagyny göz öňe getirip bilýäris. Biziň iň soňky maksadymyz bolan şu düýbürli bilim çerçevesiniň gowy ulanmagy üçin käbir gurlap çykarmakdır.</abstract_tr>
      <abstract_am>ከWordNet፣ SUMO እና ከክፍለ ገጾቻቸው የተገኘውን ትልቅ የኮንቨርስስ አነስተኛ ምሳሌን እናሳውቃለን፡፡ አጋቢው የውይይት ብልሃት እና የውቀት ሀብት ለጥቅማዊ ትግባር ማሰናከል ነው፡፡ በዚህ ትምህርት ምክንያት እውቀት ስህተት እና እውቀትና መብቶች የጎደለኝነት ስህተቶችን መዘርጋት እንችላለን፡፡ የመጨረሻው አካሄዳችን የዚህን የውይይት እውቀት አካባቢ በመጠቀም በሚያሳድጉ ሀብትን በመጠቀም የሚሻል መሪ ማውጣት ነው፡፡</abstract_am>
      <abstract_fa>ما یک تحلیل جزئیات از نمونه‌ای از نقاشی بزرگ از مشکلات منطقی معمولی را توصیف می‌کنیم که از WordNet، SUMO و نقاشی آنها به طور خودکار گرفته شده است. هدف این است که یک ارزیابی بهتر از کیفیت صندوق و منابع علم مشترک برای وظیفه‌های منطقی معمولی پیشرفت را بدهیم. با وسیله این تحلیل، ما قادر هستیم برخی از غلطهای علمی را شناسایی کنیم، اشتباهی را نقشه‌بندی کنیم و کمبود دانش و منابع را شناسایی کنیم. هدف نهایی ما این است که برخی از هدایت‌های هدایت به سوی استفاده بهتر از این چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچ</abstract_fa>
      <abstract_af>Ons beskrywe 'n gedetale analiseer van 'n voorbeeld van groot benchmark van gemeenskaplike redekende probleme wat outomaties van WordNet, SuMO en hul kaart ontvang is. Die doel is om 'n beter evaluering van die kwaliteit van beide die benchmark en die betrokke kennis hulpbron te verskaf vir gevorderde gemeenskaplike redekende taak. Deur hierdie analisie kan ons 'n paar kennis verkeerde verkeerde verwerking, mapeer foute en die ontbreek van kennis en hulpbronne. Ons eindelike doel is die uitpakking van sommige gidsline tot 'n beter uitpakking van hierdie gemeenskaplike kennis ramme deur die verbetering van die inkluiteerde hulpbronne.</abstract_af>
      <abstract_sq>Ne përshkruajmë një analizë të detajuar të një shembulli referencimi të madh të problemeve të arsyetimit të zakonshëm që është marrë automatikisht nga WordNet, SUMO dhe hartimi i tyre. Objektivi është të ofrohet një vlerësim më i mirë i cilësisë së si referencës, ashtu dhe burimeve të njohurive të përfshira për detyrat e përparuara të arsyetimit të përbashkët. Me këtë analizë, ne jemi në gjendje të zbulojmë disa gabime të njohurive, të hartojmë gabimet dhe mungesën e njohurive dhe burimeve. Objektivi ynë përfundimtar është nxjerrja e disa drejtimeve drejt një shfrytëzimi më të mirë të këtij kuadri të njohurive të përbashkëta me përmirësimin e burimeve të përfshira.</abstract_sq>
      <abstract_bs>Mi opisujemo detaljnu analizu uzorka velikih kritika problema razuma zajedničkih razuma koji su automatski dobiti od WordNet, SUMO i njihove mapiranja. Cilj je osigurati bolju procjenu kvalitete referencije i uključenih znanstvenih resursa za napredne zadatke razumljivanja zajedničkog smisla. Uz ovu analizu možemo otkriti neke nepravde znanja, mapiranje grešaka i nedostatak znanja i resursa. Naš konačni cilj je izvlačenje nekih vodiča prema boljoj ekspluataciji ovog okvira znanja zajedničkog smisla poboljšanjem uključenih resursa.</abstract_bs>
      <abstract_hy>We describe a detailed analysis of a sample of large benchmark of commonsense reasoning problems that has been automatically obtained from WordNet, SUMO and their mapping.  Նրա նպատակն է ավելի լավ գնահատել հարաբերականի որակը, ինչպես նաև ներառված գիտելիքի ռեսուրսները զարգացած ընդհանուր մտածողական խնդիրների համար: Այս վերլուծության միջոցով մենք կարող ենք հայտնաբերել որոշ գիտելիքների սխալ հարաբերություններ, քարտեզի սխալներ և գիտելիքների և ռեսուրսների բացակայությունը: Մեր վերջնական նպատակն է որոշ ուղղությունների վերացումը, որպեսզի այս ընդհանուր գիտելիքների շրջանակը ավելի լավ օգտագործվի ներառված ռեսուրսների բարելավման միջոցով:</abstract_hy>
      <abstract_az>Biz WordNet, SUMO və mappingdən автоматik olaraq alınan böyük benchmark problemlərinin örneğini təfsil edirik. Gördüyüm məqsəd, həmçinin benchmark, həmçinin bilim kaynaqlarının daha xeyirli qiymətini təmin etməkdir. Bu analizi vasitəsilə, bəzi bilgi haqsızlıqları, xətaları maplama və elm və resursu yoxdur. Bizim son məqsədimiz, içərisində olanların yaxşılıqlarına görə bu çoxlu bilgi çarşığını daha yaxşı istifadə etmək üçün bəzi hidayətlərin çıxarılmasıdır.</abstract_az>
      <abstract_cs>Popisujeme detailní analýzu vzorku velkého benchmarku problémů zdravého rozumu, který byl automaticky získán z WordNet, SUMO a jejich mapování. Cílem je poskytnout lepší hodnocení kvality referenčního měřítka a zapojených znalostních zdrojů pro pokročilé úkoly zdravého rozumu uvažování. Pomocí této analýzy jsme schopni odhalit některé nesrovnalosti znalostí, chyby mapování a nedostatek znalostí a zdrojů. Naším konečným cílem je získání některých směrnic k lepšímu využití tohoto rámce zdravého rozumu znalostí zlepšením zahrnutých zdrojů.</abstract_cs>
      <abstract_fi>Kuvaamme yksityiskohtaisen analyysin otoksesta, joka on automaattisesti saatu WordNetistä, SUMO:sta ja niiden kartoituksesta. Tavoitteena on arvioida paremmin sekä vertailuarvon että siihen liittyvien tietoresurssien laatua kehittyneissä järkeviä päättelytehtäviä varten. Tämän analyysin avulla pystymme havaitsemaan joitain tiedon vääristymiä, kartoitusvirheitä sekä tiedon ja resurssien puutetta. Lopullisena tavoitteenamme on laatia joitakin suuntaviivoja, joiden avulla tätä yleistä järkeä koskevaa tietokehystä voitaisiin hyödyntää paremmin parantamalla siihen sisältyviä resursseja.</abstract_fi>
      <abstract_bn>আমরা একটি বিস্তারিত বিশেষ বিশ্লেষণের ব্যাখ্যা করছি কমন্সেন্সের বিশাল বেনম্যার্কের সমস্যা যা স্বয়ংক্রিয়ভাবে ওয়ার্ডনেট, এসউএমও উদ্দেশ্য হচ্ছে বেনম্যার্কের মান এবং উন্নত কমিউনিসেন্সের কাজের জন্য যুক্ত জ্ঞান সম্পদের সাথে যুক্ত হয়েছে। এই বিশ্লেষণের মাধ্যমে আমরা কিছু জ্ঞানের ভুল পরিকল্পনা সনাক্ত করতে পারি, ভুল মানচিত্র এবং জ্ঞান ও সম্পদের অভাব। আমাদের শেষ উদ্দেশ্য হচ্ছে যে অন্তর্ভুক্ত সম্পদের উন্নয়নের মাধ্যমে এই কমিউনিসেন্সের জ্ঞানের কাঠামো ব্যবহারের জন্য কিছু নির্</abstract_bn>
      <abstract_ca>Descrivem una anàlisi detallada d'una mostra de grans punts de referència de problemes de raonament comuns que s'ha obtenit automàticament de WordNet, SUMO i el seu mapatge. L'objectiu és proporcionar una millor evaluació de la qualitat tant del punt de referència com dels recursos de coneixement involucrats per a tasques avançades de raonament comú. Amb aquesta anàlisi, podem detectar alguns desconeguts, errors de mapejament i falta de coneixement i recursos. El nostre objectiu final és l'extracció d'algunes directrices cap a una millor explotació d'aquest marc comú de coneixement mitjançant la millora dels recursos inclosos.</abstract_ca>
      <abstract_et>Kirjeldame üksikasjalikku analüüsi, mis on automaatselt saadud WordNetist, SUMO-st ja nende kaardistamisest. Eesmärk on anda parem hinnang nii võrdlusaluse kui ka sellega seotud teadmiste ressursside kvaliteedile täiustatud mõistlike arutlusülesannete jaoks. Selle analüüsi abil suudame tuvastada teadmiste ebaõigsusi, kaardistamisvigu ning teadmiste ja ressursside puudumist. Meie lõppeesmärk on võtta välja mõned suunised selle üldise mõistliku teadmiste raamistiku paremaks kasutamiseks kaasatud ressursside parandamise teel.</abstract_et>
      <abstract_jv>Anyone Tarjamahan punika ingkang nggawe asserti sing luwih apik, nggawe gerakan kanggo ngilanggar nggawe barang nggawe gerakan kanggo awak dhéwé, ingkang dipunangé awak dhéwé, mengko awak dhéwé. Mangkin karo hal-hal dadi iki, awak dhéwé iso nggawe ngerti tindang karo cewisan, iso nggawe barang karo kesempatan lan alam-alam kuwi duluran. Awak dhéwé aksi iki luwih nggawe barang kelas piyambak gerakan kanggo nggawe nguasai luwih apik dhéwé kuwi tindakan kesempatan kanggo ngerasai perusahaan anyar.</abstract_jv>
      <abstract_ha>Tuna bayyana wani rabo na misali mai girma bankbangon commonce masu husũma masu yiwuwa da aka mottar ta farat ɗaya daga WdNet, SUMO da mapmaporinsu. Haƙin ya zama a ƙara mafiya ƙaddara ga sifar bonkimar da kuma masu hususan da maɓallin ilmi wa taskõkin masu gabatar da mataimaki. Ina iya iya amfani da wannan analũri, za mu iya gane wasu misãlai na ilmi, kuma mu karɓi ɓata da kuma bã da ilmi da resource. Gajeyinmu na ƙarshen ni'anar misalin wasu zuwa ga mafiya amfani da wannan fassarar kunnuwan da aka samu da mafarinta na da.</abstract_ha>
      <abstract_sk>Opisujemo podrobno analizo vzorca obsežnih referenčnih referenčnih problemov razmišljanja, ki smo jih avtomatično pridobili iz WordNet, SUMO in njihovega kartiranja. Cilj je zagotoviti boljšo oceno kakovosti referenčne vrednosti in vključenih virov znanja za napredne naloge splošnega razmišljanja. S pomočjo te analize smo sposobni zaznati nekatere neusklajenosti znanja, napake pri kartiranju ter pomanjkanje znanja in virov. Naš končni cilj je pridobitev nekaterih smernic za boljše izkoriščanje tega splošnega smiselnega okvira znanja z izboljšanjem vključenih virov.</abstract_sk>
      <abstract_he>We describe a detailed analysis of a sample of large benchmark of commonsense reasoning problems that has been automatically obtained from WordNet, SUMO and their mapping.  המטרה היא לספק עריכה טובה יותר של איכות המרמז ובמשאבי הידע המעורבים למשימות הגיון משותפות. באמצעות הניתוח הזה, אנחנו מסוגלים לגלות כמה שינויים של ידע, טעויות במפה וחסר ידע ומשאבים. המטרה הסופית שלנו היא להוציא כמה כיוונים לכיוון ניצול טוב יותר של המסגרת הידע המשותפת הזאת על ידי השיפור של המשאבים הכוללים.</abstract_he>
      <abstract_bo>ང་ཚོས་རང་འགུལ་གྱིས་WordNet, SUMO དང་ཁོང་ཚོའི་རྣམ་གྲངས་ཀྱི་དཔེ་བརྗོད་ཆེན་ཡོད་པའི་དཔེ་བརྗོད་ཞིབ་གསལ་བཤད་བྱས་ན་མིན་འདུག དམིགས་ཡུལ་ནི་བསམ་བློ་གཏོང་ཁང་གི་གནས་ཚུལ་དང་མཉམ་དུ་ཡོད་པའི་མཐུན་རིམ་དང་རྒྱུ་མཚན་དག་གི་ཁྱད་ཚད་ལ་ཕར་རིས་མཐུན་ར ཞིབ་དཔྱད་འདི་དག་བརྟེན་ནས། ང་ཚོས་ཤེས་པའི་གནས་ཚུལ་ཉུང་བའི་གནས་ཚུལ་གཞན་ཞིག་རྙེད་ཐུབ་པ་དང་། ང་ཚོའི་མཐའ་མཇུག་གི་དམིགས</abstract_bo>
      </paper>
    <paper id="26">
      <title>Building the Cantonese Wordnet<fixed-case>C</fixed-case>antonese <fixed-case>W</fixed-case>ordnet</title>
      <author><first>Joanna Ut-Seong</first><last>Sio</last></author>
      <author><first>Luis Morgado Da</first><last>Costa</last></author>
      <pages>206–215</pages>
      <abstract>This paper reports on the development of the Cantonese Wordnet, a new wordnet project based on <a href="https://en.wikipedia.org/wiki/Hong_Kong_Cantonese">Hong Kong Cantonese</a>. It is built using the expansion approach, leveraging on the existing Chinese Open Wordnet, and the Princeton Wordnet’s semantic hierarchy. The main goal of our project was to produce a high quality, human-curated resource   and this paper reports on the initial efforts and steady progress of our building method. It is our belief that the lexical data made available by this <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a>, including Jyutping romanization, will be useful for a variety of future uses, including many language processing tasks and linguistic research on <a href="https://en.wikipedia.org/wiki/Cantonese">Cantonese</a> and its interactions with other <a href="https://en.wikipedia.org/wiki/Varieties_of_Chinese">Chinese dialects</a>.</abstract>
      <url hash="44dd4b0e">2019.gwc-1.26</url>
      <bibkey>sio-costa-2019-building</bibkey>
      <pwccode url="https://github.com/lmorgadodacosta/cantonesewn" additional="false">lmorgadodacosta/cantonesewn</pwccode>
    </paper>
    <paper id="29">
      <title>Fitting Semantic Relations to Word Embeddings</title>
      <author><first>Eric</first><last>Kafe</last></author>
      <pages>228–237</pages>
      <abstract>We fit WordNet relations to word embeddings, using 3CosAvg and LRCos, two set-based methods for analogy resolution, and introduce 3CosWeight, a new, weighted variant of 3CosAvg. We test the performance of the resulting semantic vectors in lexicographic semantics tests, and show that none of the tested classifiers can learn symmetric relations like <a href="https://en.wikipedia.org/wiki/Synonym">synonymy</a> and <a href="https://en.wikipedia.org/wiki/Opposite_(semantics)">antonymy</a>, since the source and target words of these relations are the same set. By contrast, with the asymmetric relations (hyperonymy / hyponymy and meronymy), both 3CosAvg and LRCos clearly outperform the baseline in all cases, while 3CosWeight attained the best scores with hyponymy and meronymy, suggesting that this new method could provide a useful alternative to previous approaches.</abstract>
      <url hash="af0e5d73">2019.gwc-1.29</url>
      <bibkey>kafe-2019-fitting</bibkey>
    </paper>
    <paper id="34">
      <title>OntoLex as a possible Bridge between <a href="https://en.wikipedia.org/wiki/WordNet">WordNets</a> and full lexical Descriptions<fixed-case>O</fixed-case>nto<fixed-case>L</fixed-case>ex as a possible Bridge between <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>ets and full lexical Descriptions</title>
      <author><first>Thierry</first><last>Declerck</last></author>
      <author><first>Melanie</first><last>Siegel</last></author>
      <pages>264–271</pages>
      <abstract>In this paper we describe our current work on representing a recently created German lexical semantics resource in OntoLex-Lemon and in conformance with WordNet specifications. Besides presenting the representation effort, we show the utilization of OntoLex-Lemon to bridge from WordNet-like resources to full lexical descriptions and extend the coverage of WordNets to other types of lexical data, such as decomposition results, exemplified for German data, and inflectional phenomena, here outlined for English data.</abstract>
      <url hash="0cd59942">2019.gwc-1.34</url>
      <bibkey>declerck-siegel-2019-ontolex</bibkey>
    </paper>
    <paper id="36">
      <title>Enhancing Conceptual Description through Resource Linking and Exploration of Semantic Relations</title>
      <author><first>Ivelina</first><last>Stoyanova</last></author>
      <author><first>Svetlozara</first><last>Leseva</last></author>
      <pages>280–289</pages>
      <abstract>The paper presents current efforts towards linking two large lexical semantic resources   <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a>   to the end of their mutual enrichment and the facilitation of the access, extraction and analysis of various types of semantic and syntactic information. In the second part of the paper, we go on to examine the relation of <a href="https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)">inheritance</a> and other semantic relations as represented in <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> and <a href="https://en.wikipedia.org/wiki/FrameNet">FrameNet</a> and how they correspond to each other when the resources are aligned. We discuss the implications with respect to the enhancement of the two resources through the definition of new relations and the detailisation of conceptual frames.</abstract>
      <url hash="d49eab51">2019.gwc-1.36</url>
      <bibkey>stoyanova-leseva-2019-enhancing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="41">
      <title>A collaborative system for building and maintaining <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</title>
      <author><first>Tomasz</first><last>Naskręt</last></author>
      <pages>323–328</pages>
      <abstract>A collaborative system for wordnet construction and maintenance is presented. Its key modules include WordnetLoom editor, Wordnet Tracker and JavaScript Graph. They offer a number of functionalities that allow solving problems on every stage of building, editing and aligning wordnets by teams of lexicographers working in parallel. The experience collected in recent years has allowed us to refine <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> and add new <a href="https://en.wikipedia.org/wiki/Modular_programming">modules</a> to provide the best user experience in a reliable and easily maintainable way.</abstract>
      <url hash="b1302c5a">2019.gwc-1.41</url>
      <bibkey>naskret-2019-collaborative</bibkey>
    </paper>
    <paper id="42">
      <title>Enriching Keywords Database UsingWordnets   a Case Study<fixed-case>U</fixed-case>sing<fixed-case>W</fixed-case>ordnets – a Case Study</title>
      <author><first>Tomasz</first><last>Jastrząb</last></author>
      <author><first>Grzegorz</first><last>Kwiatkowski</last></author>
      <pages>329–335</pages>
      <abstract>In the paper, we study the case of building a keywords database related to the Polish Classification of Activities (PKD 2007). The <a href="https://en.wikipedia.org/wiki/Database">database</a> enables automatic classification of the companies to the industry branches. The <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">classification</a> is performed based on the company’s activity description. We present the initial design of the keywords database and the ways in which <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a> were used to enrich it. Finally, we present the preliminary statistical evaluation of the produced resource.</abstract>
      <url hash="050feaa2">2019.gwc-1.42</url>
      <bibkey>jastrzab-kwiatkowski-2019-enriching</bibkey>
    </paper>
    <paper id="44">
      <title>Testing Zipf’s meaning-frequency law with wordnets as sense inventories<fixed-case>Z</fixed-case>ipf’s meaning-frequency law with wordnets as sense inventories</title>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Arkadiusz</first><last>Janz</last></author>
      <author><first>Marek</first><last>Maziarz</last></author>
      <author><first>Ewa</first><last>Rudnicka</last></author>
      <pages>342–352</pages>
      <abstract>According to George K. Zipf, more frequent words have more senses. We have tested this law using corpora and wordnets of <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/Polish_language">Polish</a>, <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>. We have proved that the law works pretty well for all of these languages if we take-as Zipf did-mean values of meaning count and averaged ranks. On the other hand, the <a href="https://en.wikipedia.org/wiki/Scientific_law">law</a> disastrously fails in predicting the number of senses for a single lemma. We have also provided the evidence that slope coefficients of Zipfian log-log linear model may vary from language to language.</abstract>
      <url hash="392284b7">2019.gwc-1.44</url>
      <bibkey>bond-etal-2019-testing</bibkey>
    </paper>
    <paper id="45">
      <title>plWordNet 4.1-a Linguistically Motivated, Corpus-based Bilingual Resource<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et 4.1 - a Linguistically Motivated, Corpus-based Bilingual Resource</title>
      <author><first>Agnieszka</first><last>Dziob</last></author>
      <author><first>Maciej</first><last>Piasecki</last></author>
      <author><first>Ewa</first><last>Rudnicka</last></author>
      <pages>353–362</pages>
      <abstract>The paper presents the latest release of the Polish WordNet, namely plWordNet 4.1. The most significant developments since 3.0 version include new relations for <a href="https://en.wikipedia.org/wiki/Noun">nouns</a> and <a href="https://en.wikipedia.org/wiki/Verb">verbs</a>, mapping semantic role-relations from the valency lexicon Walenty onto the plWordNet structure and sense-level inter-lingual mapping. Several statistics are presented in order to illustrate the development and contemporary state of the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnet</a>.</abstract>
      <url hash="a74c9915">2019.gwc-1.45</url>
      <bibkey>dziob-etal-2019-plwordnet</bibkey>
    </paper>
    <paper id="47">
      <title>Portuguese Manners of Speaking<fixed-case>P</fixed-case>ortuguese Manners of Speaking</title>
      <author><first>Valeria</first><last>de Paiva</last></author>
      <author><first>Alexandre</first><last>Rademaker</last></author>
      <pages>373–377</pages>
      <abstract>Lexical resources need to be as complete as possible. Very little work seems to have been done on <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a>, the smallest part of speech class in <a href="https://en.wikipedia.org/wiki/Princeton_WordNet">Princeton WordNet</a> counting the number of synsets. Amongst <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a>, manner adverbs ending in ‘-ly’ seem the easiest to work with, as their meaning is almost the same as the one of the associated adjective. This phenomenon seems to be parallel in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>, where these <a href="https://en.wikipedia.org/wiki/Manner_of_articulation">manner adverbs</a> finish in the suffix ‘-mente’. We use this correspondence to improve the coverage of <a href="https://en.wikipedia.org/wiki/Adverb">adverbs</a> in the lexical resource OpenWordNet-PT, a <a href="https://en.wikipedia.org/wiki/WordNet">wordnet</a> for <a href="https://en.wikipedia.org/wiki/Portuguese_language">Portuguese</a>.</abstract>
      <url hash="bc373684">2019.gwc-1.47</url>
      <bibkey>de-paiva-rademaker-2019-portuguese</bibkey>
    </paper>
    <paper id="49">
      <title>GeoNames Wordnet (geown): extracting wordnets from <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a><fixed-case>G</fixed-case>eo<fixed-case>N</fixed-case>ames <fixed-case>W</fixed-case>ordnet (geown): extracting wordnets from <fixed-case>G</fixed-case>eo<fixed-case>N</fixed-case>ames</title>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Arthur</first><last>Bond</last></author>
      <pages>387–393</pages>
      <abstract>This paper introduces a new multilingual lexicon of geographical place names. The <a href="https://en.wikipedia.org/wiki/Toponymy">names</a> are based on (and linked to) the GeoNames collection. Each location is treated as a new synset, which is linked by instance_hypernym to a small set of supertypes. These supertypes are linked to the collaborative interlingual index, based on mappings from GeoDomainWordnet. If a location is already in the interlingual index, then it is also linked to the entry, using <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mappings</a> from the Geo-Wordnet. Finally, if <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a> places the location in a larger location, this is linked using the mero_location link. Wordnets can be built for any language in <a href="https://en.wikipedia.org/wiki/GeoNames">GeoNames</a>, we give results for those wordnets in the Open Multilingual Wordnet. We discuss how <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is mapped and the characteristics of the extracted <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</abstract>
      <url hash="62cfadab">2019.gwc-1.49</url>
      <bibkey>bond-bond-2019-geonames</bibkey>
    </paper>
    <paper id="50">
      <title>New Polysemy Structures in Wordnets Induced by Vertical Polysemy</title>
      <author><first>Ahti</first><last>Lohk</last></author>
      <author><first>Heili</first><last>Orav</last></author>
      <author><first>Kadri</first><last>Vare</last></author>
      <author><first>Francis</first><last>Bond</last></author>
      <author><first>Rasmus</first><last>Vaik</last></author>
      <pages>394–403</pages>
      <abstract>This paper aims to study auto-hyponymy and auto-troponymy relations (or vertical polysemy) in 11 wordnets uploaded into the new Open Multilingual Wordnet (OMW) webpage. We investigate how vertical polysemy forms <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> (or sense clusters) in semantic hierarchies of the <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>. Our main results and discoveries are new polysemy structures that have not previously been associated with vertical polysemy, along with some inconsistencies of semantic relations analysis in the studied wordnets, which should not be there. In the case study, we turn attention to polysemy structures in the Estonian Wordnet (version 2.2.0), analyzing <a href="https://en.wikipedia.org/wiki/Estonian_language">them</a> and giving the lexicographers comments. In addition, we describe the detection algorithm of <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> and an overview of the state of <a href="https://en.wikipedia.org/wiki/Polysemy">polysemy structures</a> in 11 <a href="https://en.wikipedia.org/wiki/Wordnet">wordnets</a>.</abstract>
      <url hash="2b4daefe">2019.gwc-1.50</url>
      <bibkey>lohk-etal-2019-new</bibkey>
    </paper>
    </volume>
</collection>