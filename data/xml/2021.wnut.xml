<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.wnut">
  <volume id="1" ingest-date="2021-11-12">
    <meta>
      <booktitle>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</booktitle>
      <editor><first>Wei</first><last>Xu</last></editor>
      <editor><first>Alan</first><last>Ritter</last></editor>
      <editor><first>Tim</first><last>Baldwin</last></editor>
      <editor><first>Afshin</first><last>Rahimi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="375a0bef">2021.wnut-1.0</url>
      <bibkey>wnut-2021-noisy</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Text Simplification for Comprehension-based Question-Answering</title>
      <author><first>Tanvi</first><last>Dadu</last></author>
      <author><first>Kartikey</first><last>Pant</last></author>
      <author><first>Seema</first><last>Nagar</last></author>
      <author><first>Ferdous</first><last>Barbhuiya</last></author>
      <author><first>Kuntal</first><last>Dey</last></author>
      <pages>1–10</pages>
      <abstract>Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning. Text simplification has been exploited in NLP applications like <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, <a href="https://en.wikipedia.org/wiki/Semantic_role_labeling">semantic role labeling</a>, and <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks. In this work, we investigate the effect of <a href="https://en.wikipedia.org/wiki/Text_simplification">text simplification</a> in the task of <a href="https://en.wikipedia.org/wiki/Question_answering">question-answering</a> using a <a href="https://en.wikipedia.org/wiki/Context_(language_use)">comprehension context</a>. We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset. Firstly, we outline each step in the dataset creation pipeline, including style transfer, thresholding of sentences showing correct transfer, and offset finding for each answer. Secondly, we verify the quality of the transferred sentences through various <a href="https://en.wikipedia.org/wiki/Methodology">methodologies</a> involving both automated and human evaluation. Thirdly, we benchmark the newly created <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and perform an ablation study for examining the effect of the simplification process in the SQuAD-based question answering task. Our experiments show that simplification leads to up to 2.04 % and 1.74 % increase in <a href="https://en.wikipedia.org/wiki/Exact_Match">Exact Match</a> and F1, respectively. Finally, we conclude with an analysis of the transfer process, investigating the types of edits made by the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, and the effect of <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a> on the transfer model.</abstract>
      <url hash="7f5d9cfb">2021.wnut-1.1</url>
      <bibkey>dadu-etal-2021-text</bibkey>
      <doi>10.18653/v1/2021.wnut-1.1</doi>
      <pwccode url="https://github.com/kartikeypant/text-simplification-qa-www2021" additional="false">kartikeypant/text-simplification-qa-www2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisplit">WikiSplit</pwcdataset>
    <title_ar>تبسيط النص للإجابة على الأسئلة المستندة إلى الفهم</title_ar>
      <title_pt>Simplificação de texto para respostas a perguntas baseadas em compreensão</title_pt>
      <title_es>Simplificación de textos para respuestas a preguntas basadas en la comprensión</title_es>
      <title_fr>Simplification du texte pour répondre aux questions basées sur la compréhension</title_fr>
      <title_ja>理解ベースの質問に答えるためのテキストの簡略化</title_ja>
      <title_zh>盖解答之文本简也</title_zh>
      <title_hi>समझ-आधारित प्रश्न-उत्तर के लिए पाठ सरलीकरण</title_hi>
      <title_ru>Упрощение текста для ответов на вопросы на основе понимания</title_ru>
      <title_ga>Téacs a Shimpliú le haghaidh Freagraí Ceistbhunaithe</title_ga>
      <title_ka>Comment</title_ka>
      <title_el>Απλοποίηση κειμένου για την απάντηση ερωτήσεων με βάση την κατανόηση</title_el>
      <title_hu>A szöveg egyszerűsítése az átfogó kérdések megválaszolásához</title_hu>
      <title_kk>Сұрақ- жауап беру негізінде мәтінді қарапайым</title_kk>
      <title_lt>Text Simplification for Comprehension-based Question-Answering</title_lt>
      <title_it>Semplificazione del testo per rispondere alle domande basate sulla comprensione</title_it>
      <title_mk>Name</title_mk>
      <title_ms>Simplifikasi Teks untuk Jawapan soalan berdasarkan pemahaman</title_ms>
      <title_mt>Simplifikazzjoni tat-test għat-tweġibiet għall-mistoqsijiet ibbażati fuq il-komprensjoni</title_mt>
      <title_no>Comment</title_no>
      <title_ml>പൂര്‍ത്തിയാക്കുന്നതിനു് അടിസ്ഥാനമായ ചോദ്യം ചെയ്യുന്നതിനു് പദാവലി ലളിതമാക്കുക</title_ml>
      <title_ro>Simplificarea textului pentru răspunsurile la întrebări bazate pe înțelegere</title_ro>
      <title_pl>Uproszczenie tekstu w odpowiedzi na pytania oparte na zrozumieniu</title_pl>
      <title_mn>Үйлдлийн үндсэн асуулт-хариултын текст хялбарчлал</title_mn>
      <title_sr>Jednostavnost teksta za odgovor na pitanja na osnovu kompresije</title_sr>
      <title_si>Name</title_si>
      <title_so>Soo fududeynta jawaabta su'aalka aasiga ah</title_so>
      <title_sv>Textförenkling för begripligt besvarande av frågor</title_sv>
      <title_ta>சார்ந்த கேள்வி- பதில் சொல்லுதலுக்கு உரை சுலபமாக்கம்</title_ta>
      <title_ur>Comment</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Đơn giản hóa văn bản cho câu hỏi tổng quát</title_vi>
      <title_bg>Опростяване на текста за отговор на въпроси въз основа на разбиране</title_bg>
      <title_nl>Tekstvereenvoudiging voor op begrip gebaseerde vragen beantwoorden</title_nl>
      <title_da>Forenkling af teksten med henblik på forståelsesbaseret spørgsmål</title_da>
      <title_hr>Jednostavnost teksta za odgovor na pitanja na osnovu kompresije</title_hr>
      <title_de>Textvereinfachung für die verständnisbasierte Beantwortung von Fragen</title_de>
      <title_id>Simplifikasi Teks untuk Jawaban Pertanyaan Berdasarkan Pemahaman</title_id>
      <title_fa>Comment</title_fa>
      <title_ko>이해 기반의 문답 텍스트 간소화</title_ko>
      <title_sw>Simplified text for Composition based Question-answering</title_sw>
      <title_af>Comment</title_af>
      <title_tr>Sykmak-tabanly sorag-jogapy üçin metin Besitlendirmek</title_tr>
      <title_sq>Simplifikimi i tekstit për përgjigjet e pyetjeve të bazuara në përfshirje</title_sq>
      <title_am>ጥያቄ-መልስ</title_am>
      <title_hy>Text Simplification for Comprehension-based Question-Answering</title_hy>
      <title_az>쥓暙쥬璙琭扡湡쑬₱畳污挭癡扡쌠쎼쎧溼洠瑥湩戠獡瑩쥬얙撟物汩쥭玙੩</title_az>
      <title_bn>প্রশ্ন- উত্তরের জন্য টেক্সট সাধারণ</title_bn>
      <title_ca>Simplificació del text per respondre preguntes basades en la comprensió</title_ca>
      <title_cs>Zjednodušení textu pro odpovědi na otázky založené na porozumění</title_cs>
      <title_bs>Jednostavnost teksta za odgovor na pitanja na osnovu kompresije</title_bs>
      <title_et>Teksti lihtsustamine arusaadaval küsimustele vastamisel</title_et>
      <title_fi>Tekstin yksinkertaistaminen kattavaan kysymykseen vastaamista varten</title_fi>
      <title_jv>transform-type</title_jv>
      <title_he>Name</title_he>
      <title_ha>@ action</title_ha>
      <title_sk>Poenostavitev besedila za odgovarjanje na vprašanja na podlagi razumevanja</title_sk>
      <title_bo>Comprehension-based Question-Answering for Text Simplification</title_bo>
      <abstract_ar>تبسيط النص هو عملية تقسيم الجملة وإعادة صياغتها إلى سلسلة من الجمل مما يسهل قراءتها وفهمها مع الحفاظ على المحتوى وتقريب المعنى الأصلي. تم استغلال تبسيط النص في تطبيقات البرمجة اللغوية العصبية مثل الترجمة الآلية ، والتلخيص ، ووسم الأدوار الدلالية ، واستخراج المعلومات ، مما يفتح مجالًا واسعًا لاستغلاله في المهام النهائية القائمة على الفهم والإجابة على الأسئلة. في هذا العمل ، نتحرى تأثير تبسيط النص في مهمة الإجابة على الأسئلة باستخدام سياق الفهم. أصدرنا Simple-SQuAD ، وهو نسخة مبسطة من مجموعة بيانات SQuAD المستخدمة على نطاق واسع. أولاً ، نحدد كل خطوة في خط أنابيب إنشاء مجموعة البيانات ، بما في ذلك نقل النمط ، وعتبة الجمل التي تظهر النقل الصحيح ، وإيجاد الإزاحة لكل إجابة. ثانيًا ، نتحقق من جودة الجمل المنقولة من خلال منهجيات مختلفة تتضمن التقييم الآلي والبشري. ثالثًا ، نقوم بقياس الجسم الذي تم إنشاؤه حديثًا وإجراء دراسة الاجتثاث لفحص تأثير عملية التبسيط في مهمة الإجابة على الأسئلة المستندة إلى SQuAD. تظهر تجاربنا أن التبسيط يؤدي إلى زيادة تصل إلى 2.04٪ و 1.74٪ في المطابقة التامة و F1 على التوالي. أخيرًا ، نختتم بتحليل عملية النقل ، والتحقيق في أنواع التعديلات التي أجراها النموذج ، وتأثير طول الجملة على نموذج النقل.</abstract_ar>
      <abstract_pt>A simplificação de texto é o processo de dividir e reformular uma frase em uma sequência de frases, tornando-a mais fácil de ler e entender, preservando o conteúdo e aproximando o significado original. A simplificação de texto foi explorada em aplicativos de PNL, como tradução automática, sumarização, rotulagem de função semântica e extração de informações, abrindo um amplo caminho para sua exploração em tarefas posteriores de respostas a perguntas baseadas em compreensão. Neste trabalho, investigamos o efeito da simplificação de texto na tarefa de responder perguntas usando um contexto de compreensão. Lançamos o Simple-SQuAD, uma versão simplificada do conjunto de dados SQuAD amplamente utilizado. Em primeiro lugar, descrevemos cada etapa no pipeline de criação do conjunto de dados, incluindo transferência de estilo, limiar de sentenças mostrando a transferência correta e descoberta de deslocamento para cada resposta. Em segundo lugar, verificamos a qualidade das sentenças transferidas por meio de várias metodologias envolvendo avaliação automatizada e humana. Em terceiro lugar, comparamos o corpus recém-criado e realizamos um estudo de ablação para examinar o efeito do processo de simplificação na tarefa de resposta a perguntas baseada em SQuAD. Nossos experimentos mostram que a simplificação leva a um aumento de até 2,04% e 1,74% em Exact Match e F1, respectivamente. Por fim, concluímos com uma análise do processo de transferência, investigando os tipos de edições feitas pelo modelo e o efeito do comprimento da sentença no modelo de transferência.</abstract_pt>
      <abstract_es>La simplificación del texto es el proceso de dividir y reformular una oración en una secuencia de oraciones para que sea más fácil de leer y entender, a la vez que se preserva el contenido y se aproxima al significado original. La simplificación del texto se ha aprovechado en aplicaciones de PNL como la traducción automática, el resumen, el etiquetado semántico de roles y la extracción de información, lo que abre un amplio camino para su explotación en tareas posteriores de respuesta a preguntas basadas en la comprensión. En este trabajo, investigamos el efecto de la simplificación del texto en la tarea de preguntas y respuestas utilizando un contexto de comprensión. Lanzamos Simple-Squad, una versión simplificada del ampliamente utilizado conjunto de datos sQuad. En primer lugar, describimos cada paso en el proceso de creación del conjunto de datos, incluida la transferencia de estilos, el establecimiento de umbrales de oraciones que muestran la transferencia correcta y la búsqueda de compensación para cada respuesta. En segundo lugar, verificamos la calidad de las sentencias transferidas a través de varias metodologías que implican evaluación tanto automática como humana. En tercer lugar, comparamos el cuerpo recién creado y realizamos un estudio de ablación para examinar el efecto del proceso de simplificación en la tarea de respuesta a preguntas basada en Escuadrón. Nuestros experimentos muestran que la simplificación conduce a un aumento de hasta un 2,04% y un 1,74% en la coincidencia exacta y la F1, respectivamente. Finalmente, concluimos con un análisis del proceso de transferencia, investigando los tipos de ediciones realizadas por el modelo y el efecto de la longitud de la oración en el modelo de transferencia.</abstract_es>
      <abstract_fr>La simplification de texte est le processus qui consiste à diviser et à reformuler une phrase en une séquence de phrases afin de la rendre plus facile à lire et à comprendre tout en préservant le contenu et en approximant le sens original. La simplification de texte a été exploitée dans des applications de TAL telles que la traduction automatique, la synthèse, l'étiquetage sémantique des rôles et l'extraction d'informations, ouvrant ainsi une large voie à son exploitation dans les tâches en aval de réponse aux questions basées sur la compréhension. Dans ce travail, nous étudions l'effet de la simplification du texte dans la tâche de répondre aux questions à l'aide d'un contexte de compréhension. Nous publions Simple-squad, une version simplifiée du jeu de données SQuad largement utilisé. Tout d'abord, nous décrivons chaque étape du pipeline de création de jeu de données, y compris le transfert de style, le seuillage des phrases indiquant le transfert correct et la recherche de décalage pour chaque réponse. Ensuite, nous vérifions la qualité des phrases transférées au moyen de différentes méthodologies impliquant à la fois une évaluation automatisée et une évaluation humaine. Troisièmement, nous comparons le corpus nouvellement créé et effectuons une étude d'ablation pour examiner l'effet du processus de simplification dans la tâche de réponse aux questions basée sur l'escouade. Nos expériences montrent que la simplification entraîne une augmentation allant jusqu'à 2,04 % et 1,74 % de la correspondance exacte et de la F1, respectivement. Enfin, nous terminons par une analyse du processus de transfert, en examinant les types de modifications apportées par le modèle et l'effet de la longueur de la phrase sur le modèle de transfert.</abstract_fr>
      <abstract_ja>テキストの簡略化とは、文章を分割して文章のシーケンスに置き換え、内容を保持しながら本来の意味に近づけながら、読みやすく理解しやすくするプロセスです。 テキストの簡素化は、機械翻訳、要約、セマンティックロールラベリング、情報抽出などのNLPアプリケーションで利用されており、理解に基づく質問に答える下流タスクでの利用のための広範な手段を開いています。 本研究では，理解コンテキストを用いた質疑応答の課題におけるテキストの簡略化の効果を検討する． 広く使用されているSQuADデータセットの簡略化版であるSimple - SQuADをリリースします。 まず、データセット作成パイプラインの各ステップを概説します。これには、スタイルの転送、正しい転送を示す文章のしきい値付け、各回答のオフセット検出などが含まれます。 第二に、自動評価と人間評価の両方に関わる様々な方法論を通じて、転送された文章の品質を検証する。 第三に、新しく作成されたコーパスをベンチマークし、SQuADベースの質問応答タスクで簡略化プロセスの効果を検討するためのアブレーション研究を実施する。 私たちの実験によると、簡素化はそれぞれ、Exact MatchとF 1で最大2.04 ％と1.74 ％の増加につながることが示されています。 最後に、転送処理の解析を行い、モデルによる編集の種類と転送モデルに対する文章長の影響を調査する。</abstract_ja>
      <abstract_zh>文本简化,改写句拆分为一系句,使易读解,兼存近义。 文本简化已于机器翻译、摘要、语义角、信息提取等NLP应用中用,为在解问下流之用简开广路。 于此,论文简于用解上下文问答之用也。 吾发Simple-SQuAD,此博用之SQuAD数也。 先是,余概述数集创管道每步驿,包式转移,示正移句阈值及每答案偏移查。 次及自与人工评料诸法以验移句之质。 其三曰,试于新造之语料库,以省简化过程于SQuAD之间。 臣等实验明,简致精匹F1各增2.04%1.74%。 最后析其移徙,究其编辑,及句度转移模型。</abstract_zh>
      <abstract_hi>पाठ सरलीकरण एक वाक्य को वाक्यों के अनुक्रम में विभाजित करने और फिर से प्रस्तुत करने की प्रक्रिया है जिससे सामग्री को संरक्षित करने और मूल अर्थ को अनुमानित करते समय पढ़ना और समझना आसान हो जाता है। मशीन अनुवाद, सारांशीकरण, शब्दार्थ भूमिका लेबलिंग, और सूचना निष्कर्षण जैसे एनएलपी अनुप्रयोगों में पाठ सरलीकरण का शोषण किया गया है, जो समझ-आधारित प्रश्न-उत्तर देने वाले डाउनस्ट्रीम कार्यों में इसके शोषण के लिए एक व्यापक एवेन्यू खोलता है। इस काम में, हम एक समझ संदर्भ का उपयोग करके प्रश्न-उत्तर देने के कार्य में पाठ सरलीकरण के प्रभाव की जांच करते हैं। हम सरल-SQuAD जारी करते हैं, जो व्यापक रूप से उपयोग किए जाने वाले SQuAD डेटासेट का एक सरलीकृत संस्करण है। सबसे पहले, हम डेटासेट निर्माण पाइपलाइन में प्रत्येक चरण की रूपरेखा तैयार करते हैं, जिसमें शैली स्थानांतरण, सही हस्तांतरण दिखाने वाले वाक्यों की थ्रेशोल्डिंग और प्रत्येक उत्तर के लिए ऑफसेट खोज शामिल है। दूसरे, हम स्वचालित और मानव मूल्यांकन दोनों को शामिल करने वाले विभिन्न तरीकों के माध्यम से स्थानांतरित वाक्यों की गुणवत्ता को सत्यापित करते हैं। तीसरा, हम नव निर्मित कॉर्पस को बेंचमार्क करते हैं और SQuAD-आधारित प्रश्न उत्तर देने वाले कार्य में सरलीकरण प्रक्रिया के प्रभाव की जांच करने के लिए एक एब्लेशन अध्ययन करते हैं। हमारे प्रयोगों से पता चलता है कि सरलीकरण सटीक मैच और एफ 1 में क्रमशः 2.04% और 1.74% की वृद्धि की ओर जाता है। अंत में, हम हस्तांतरण प्रक्रिया के विश्लेषण के साथ निष्कर्ष निकालते हैं, मॉडल द्वारा किए गए संपादन के प्रकारों की जांच करते हैं, और स्थानांतरण मॉडल पर वाक्य की लंबाई के प्रभाव की जांच करते हैं।</abstract_hi>
      <abstract_ru>Упрощение текста - это процесс разделения и перефразирования предложения на последовательность предложений, что облегчает его чтение и понимание при сохранении содержания и приближении первоначального значения. Упрощение текста было использовано в приложениях NLP, таких как машинный перевод, обобщение, семантическая маркировка ролей и извлечение информации, открывая широкий путь для его использования в задачах, основанных на понимании вопросов. В этой работе мы исследуем эффект упрощения текста в задаче ответа на вопрос с использованием контекста понимания. Мы выпускаем Simple-SQuAD, упрощенную версию широко используемого набора данных SQuAD. Во-первых, мы описываем каждый шаг в конвейере создания набора данных, включая перенос стиля, пороговые значения предложений, показывающих правильный перенос, и поиск смещения для каждого ответа. Во-вторых, мы проверяем качество передаваемых приговоров с помощью различных методологий, включающих как автоматизированную, так и человеческую оценку. В-третьих, мы сравниваем вновь созданный корпус и выполняем абляционное исследование для изучения эффекта процесса упрощения в задаче ответов на вопросы на основе SQuAD. Наши эксперименты показывают, что упрощение приводит к увеличению Exact Match и F1 до 2,04% и 1,74% соответственно. Наконец, мы завершаем анализ процесса переноса, исследуя типы правок, сделанных моделью, и влияние длины предложения на модель переноса.</abstract_ru>
      <abstract_ga>Is éard is simpliú téacs ann ná an próiseas ina scoilteadh agus ina athfhrásaítear abairt go seicheamh abairtí a fhágfaidh go mbeidh sé níos éasca é a léamh agus a thuiscint agus an t-ábhar á chaomhnú agus an bhunchiall a chomhfhogasú. Baineadh leas as simpliú téacs in fheidhmchláir NLP cosúil le haistriú meaisín, achoimriú, lipéadú ról shéimeantach, agus eastóscadh faisnéise, ag oscailt bealach leathan chun é a shaothrú i gcúraimí iartheachtacha atá bunaithe ar thuiscint. San obair seo, déanaimid imscrúdú ar éifeacht simpliú téacs ar thasc na bhfreagraí ceisteanna ag baint úsáide as comhthéacs tuisceana. Eisímid Simple-SQuAD, leagan simplithe den tacar sonraí SQuAD a úsáidtear go forleathan. Ar an gcéad dul síos, déanaimid breac-chuntas ar gach céim sa phíblíne cruthú sonraí, lena n-áirítear aistriú stíle, tairseacha abairtí a thaispeánann aistriú ceart, agus aimsiú fritháirimh do gach freagra. Ar an dara dul síos, déanaimid cáilíocht na n-abairtí aistrithe a fhíorú trí mhodheolaíochtaí éagsúla a bhaineann le meastóireacht uathoibrithe agus daonna araon. Ar an tríú dul síos, déanaimid tagarmharcáil ar an gcorpas nuachruthaithe agus déanaimid staidéar eisbhleachta chun scrúdú a dhéanamh ar éifeacht an phróisis simplithe sa tasc freagartha ceisteanna atá bunaithe ar SQuAD. Léiríonn ár dturgnaimh go leanann simpliú suas le 2.04% agus méadú 1.74% ar Match Beacht agus F1, faoi seach. Mar fhocal scoir, cuirimid i gcrích le hanailís ar an bpróiseas aistrithe, ag fiosrú na cineálacha athruithe a rinne an múnla, agus éifeacht fad na habairte ar an múnla aistrithe.</abstract_ga>
      <abstract_ka>ტექსტის განვითარება არის სიტყვას გაყოფილი და განვითარების პროცესი სიტყვას, რომელიც უფრო მარტივია წაკითხვა და პასუხის შემდეგ შემდგომარების შემდგომარება და დაახლობა. ტექსტის გამოყენება NLP პროგრამებში გამოყენებულია, როგორც მაქსინური გაგრძელება, სიმპანტიკური პროლის ნიშანები, და ინფორმაციის გამოყენება, გახსნა უფრო დიდი საზოგადო ექსპლუტიაციაში, როგორ ამ სამუშაოში, ჩვენ ტექსტის განსახულების ეფექტის გამოყენება კითხვის პასუხის შესახებ. ჩვენ განვითარებთ Simple-SQuAD, განვითარებული ვერსია SQuAD მონაცემების გარეშე. პირველად, ჩვენ ყველა მონაცემების შექმნაში მონაცემების კონფიგურაცია, სტილის გადატანსტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტრისტ მეორე, ჩვენ დავწერეთ გადატანსულებული სიტყვების კაalitეტის განსხვავებული მეტოდოლოგიებით, რომლებიც ორივე ავტომატურებული და ადამიანის განსაზღვრება. მესამე, ჩვენ ახალი შექმნილი კორპუსს გავაკეთებთ და გავაკეთებთ შესაძლებელი სწავლა, რომ SQuAD-ის განხორციელების პროცესის ეფექტის შესახებ გავაკეთებთ კითხვების დასაუბრუნოს ჩვენი ექსპერიმენტები გამოჩვენება, რომ განვითარება 2,04% და 1,74% უფრო მეტია მართლაც და F1. საბოლოოდ, ჩვენ გადასრულეთ გადასრულებული პროცესის ანალიზაციით, მოდელზე შექმნილი რედაქტირების ტიპების შესახებ, და ტრანსტრინტის მოდელზე წესის სიგრძე ეფ</abstract_ka>
      <abstract_el>Η απλοποίηση κειμένου είναι η διαδικασία διαχωρισμού και επαναδιατύπωσης μιας πρότασης σε μια ακολουθία προτάσεων που καθιστά ευκολότερη την ανάγνωση και την κατανόηση διατηρώντας το περιεχόμενο και προσεγγίζοντας την αρχική έννοια. Η απλοποίηση κειμένου έχει αξιοποιηθεί σε εφαρμογές όπως η μηχανική μετάφραση, η σύνοψη, η σημασιολογική σήμανση ρόλων και η εξαγωγή πληροφοριών, ανοίγοντας μια ευρεία οδό για την αξιοποίησή της σε εργασίες που βασίζονται στην κατανόηση. Σε αυτή την εργασία, διερευνούμε την επίδραση της απλούστευσης κειμένου στο έργο της απάντησης ερωτήσεων χρησιμοποιώντας ένα πλαίσιο κατανόησης. Απελευθερώνουμε μια απλοποιημένη έκδοση του ευρέως χρησιμοποιούμενου συνόλου δεδομένων SQuAD. Πρώτον, περιγράφουμε κάθε βήμα στη γραμμή δημιουργίας συνόλου δεδομένων, συμπεριλαμβανομένης της μεταφοράς στυλ, της δημιουργίας προτάσεων που δείχνουν σωστή μεταφορά και της εύρεσης μετατόπισης για κάθε απάντηση. Δεύτερον, επαληθεύουμε την ποιότητα των μεταφερόμενων ποινών μέσω διαφόρων μεθοδολογιών που περιλαμβάνουν τόσο αυτοματοποιημένη όσο και ανθρώπινη αξιολόγηση. Τρίτον, αξιολογούμε το νεοδημιουργημένο σώμα και διεξάγουμε μια μελέτη αφαίρεσης για την εξέταση της επίδρασης της διαδικασίας απλοποίησης στην εργασία απάντησης ερωτήσεων που βασίζεται στο SQuAD. Τα πειράματά μας δείχνουν ότι η απλοποίηση οδηγεί σε αύξηση μέχρι 2,04% και 1,74% στην ακριβή αντιστοίχιση και αντίστοιχα. Τέλος, ολοκληρώνουμε με μια ανάλυση της διαδικασίας μεταφοράς, διερευνώντας τους τύπους των επεξεργασιών που γίνονται από το μοντέλο και την επίδραση του μήκους της πρότασης στο μοντέλο μεταφοράς.</abstract_el>
      <abstract_hu>A szöveg egyszerűsítése az a folyamat, amely egy mondatot feloszt és átfogalmaz egy mondatsorozatra, így könnyebben olvasható és érthető, miközben megőrzi a tartalmat és közelíti az eredeti jelentést. A szövegegyszerűsítést kihasználták az NLP alkalmazásokban, mint például a gépi fordítás, az összefoglalás, a szemantikai szerepkörcímkézés és az információkinyerés, ami széles körű utat nyitott meg a felhasználáshoz a megértési alapú kérdésekre vonatkozó downstream feladatokban. Ebben a munkában a szövegegyszerűsítés hatását vizsgáljuk a kérdések megértési kontextusban történő megválaszolásának feladatában. Kiadjuk a Simple-SQUAD-et, a széles körben használt SQUAD adatkészlet egyszerűsített verzióját. Először is felvázoljuk az adatkészlet létrehozásának minden lépését, beleértve a stílusátvitelt, a megfelelő átvitelt mutató mondatok küszöbértékét és az egyes válaszok ellensúlyozását. Másodszor az átadott mondatok minőségét különböző módszerekkel ellenőrizzük automatizált és emberi értékeléssel. Harmadszor, összehasonlítjuk az újonnan létrehozott korpuszt, és ablációs tanulmányt végzünk az egyszerűsítési folyamat hatásának vizsgálatára az SQUAD alapú kérdésválasztási feladatban. Kísérleteink azt mutatják, hogy az egyszerűsítés akár 2,04%-os, illetve 1,74%-os növekedést eredményez az Exact Match, illetve az F1. Végezetül az átviteli folyamat elemzésével zárjuk, vizsgáljuk a modell által végzett szerkesztések típusát, valamint a mondathossz hatását az átviteli modellre.</abstract_hu>
      <abstract_it>La semplificazione del testo è il processo di suddividere e riformulare una frase in una sequenza di frasi che ne facilita la lettura e la comprensione preservandone il contenuto e approfondendone il significato originale. La semplificazione del testo è stata sfruttata nelle applicazioni NLP come la traduzione automatica, la sintesi, l'etichettatura semantica dei ruoli e l'estrazione delle informazioni, aprendo un'ampia strada per il suo sfruttamento nelle attività a valle di risposta alle domande basate sulla comprensione. In questo lavoro, analizziamo l'effetto della semplificazione del testo nel compito di rispondere alle domande utilizzando un contesto di comprensione. Rilasciamo Simple-SQUAD, una versione semplificata del set di dati SQUAD ampiamente utilizzato. In primo luogo, delineamo ogni passo nella pipeline di creazione del set di dati, incluso il trasferimento di stile, la thresholding di frasi che mostrano il trasferimento corretto e la ricerca di offset per ogni risposta. In secondo luogo, verifichiamo la qualità delle frasi trasferite attraverso varie metodologie che coinvolgono sia la valutazione automatizzata che umana. In terzo luogo, valutiamo il corpus appena creato ed eseguiamo uno studio di ablazione per esaminare l'effetto del processo di semplificazione nel compito di risposta alle domande basato su SQUAD. I nostri esperimenti dimostrano che la semplificazione porta ad un aumento del 2,04% e dell'1,74% rispettivamente di Exact Match e F1. Infine, concludiamo con un'analisi del processo di trasferimento, indagando i tipi di modifiche apportate dal modello e l'effetto della lunghezza della frase sul modello di trasferimento.</abstract_it>
      <abstract_mk>Процесот на поедноставување на текстот е процесот на поделба и префразирање на реченица во секвенца на реченици што го олеснува читањето и разбирањето на содржината и приближувањето на оригиналното значење. Текст-поедноставувањето е искористено во апликациите на НЛП како што се машинскиот превод, резултатот, семантичното означување на улогата и извлекувањето информации, отворајќи широка патека за неговото искористување во одговорот на прашања на основа на разбирање на понатамошните зад Во оваа работа, го истражуваме ефектот на поедноставувањето на текстот во задачата на одговорите на прашањата користејќи контекст на разбирање. We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset.  Прво, го опишуваме секој чекор во гасоводот за создавање на податоци, вклучувајќи го и трансферот на стил, ограничувањето на речениците кои покажуваат точен трансфер и наоѓањето на отстранување за секој одговор. Второ, го проверуваме квалитетот на пренесените реченици преку различни методологии кои вклучуваат и автоматизирана и човечка проценка. Трето, го споредуваме новоформираниот корпус и спроведуваме аплациска студија за испитување на ефектот на процесот на едноставување во задачата за одговор на прашањата базирана на SQuAD. Нашите експерименти покажуваат дека едноставувањето води до зголемување од 2,04 отсто, односно 1,74 отсто на точниот совпаѓање и F1. Конечно, заклучуваме со анализа на процесот на трансфер, истражувајќи ги видовите на уредувања направени од моделот, и ефектот на должината на реченицата на моделот на трансфер.</abstract_mk>
      <abstract_kk>Мәтінді қарапайым - мәтінді сақтау және бастапқы мазмұнын сақтау және түсініктерді оқу және түсініктеу үшін мәтінді бөлу және қайталау процесі. Мәтін қарапайым NLP қолданбаларында, мысалы, машинаны аудару, тұжырымдамасы, семантикалық роль жарлығы және мәліметті тарқату, оның түсініктеріне негізделген сұрақ жауап беру тапсырмаларында жұмыс жолын ашу ү Бұл жұмыс ішінде біз мәтінді қарапайым жауап беру тапсырмасының нәтижесін түсініктеме контексті арқылы зерттеп тұрамыз. Қарапайым SQuAD деректер жиынының қарапайым нұсқасын шығару. Біріншіден, деректер қорларының құрылғысының әрбір қадамын жазып, стильді тасымалдау, сұлбаларының шегін жазып, әрбір жауап үшін іздеу үшін жылжыту. Екіншіден, автоматты түрде және адамдардың оқиғасы бар әртүрлі методологиялар арқылы аударылған сөздердің сапатын тексереміз. Үшіншіден, біз жаңа құрылған корпус бағыттап, SQuAD негіздеген сұрақ жауап беру тапсырмасының қарапайым процесінің эффектін тексеру үшін жұмыс істейміз. Біздің тәжірибеміз қарапайым 2,04% мен 1,74% дегенді көрсетеді. Соңында, біз тасымалдау процесінің анализациясы, үлгі жасалған редактордың түрлерін және сөздердің ұзындығын тасымалдау үлгісінің эффекті шешуге болады.</abstract_kk>
      <abstract_ml>പദാവലിയുടെ എളുപ്പമാണ് വാക്ക് വേര്‍തിരിക്കുകയും വാക്കുകളുടെ പ്രക്രിയയെ വീണ്ടെടുക്കുകയും ചെയ്യുന്നത്. വാക്കുകള്‍ വായിക്കുകയും മനസ്സി എണ്‍എല്‍പി പ്രയോഗങ്ങളില്‍ പദാവലിയുടെ എളുപ്പമുള്ള എളുപ്പം ഉപയോഗിക്കപ്പെട്ടിരിക്കുന്നു. യന്ത്രങ്ങളുടെ പരിഭാഷവും, സംസാരിപ്പിക്കുന്നതും, സെമാന്റിക് റോള്‍ ല ഈ ജോലിയില്‍ ഞങ്ങള്‍ ചോദ്യം ചെയ്യുന്നതിന്റെ എളുപ്പത്തിന്റെ പ്രഭാവം പരിശോധിക്കുന്നു. ഒരു സൂക്ഷ്മമായ കോണ We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset.  ആദ്യം, ഡാറ്റാസറ്റ് സൃഷ്ടിക്കുന്ന പൈപ്പെലിനില്‍ ഓരോ പടിയും നാം പുറത്ത് വരുത്തുന്നു. ശൈലി മാറ്റുന്നതും ശരിയായ മാറ്റം കാണിക്കുന രണ്ടാമതായി, മാറ്റപ്പെട്ട വാക്കുകളുടെ ഗുണമെന്ന് നമ്മള്‍ ഉറപ്പ് വരുത്തുന്നു. സ്വയമാക്കിയും മനുഷ്യരുടെ വിലാസവും ഉള് മൂന്നാമത്തെ ഞങ്ങള്‍ പുതിയ കോര്‍പ്പുസ് സൃഷ്ടിച്ചുണ്ടാക്കിയിരിക്കുന്നു എന്നിട്ട് എസ്ക്വാഡ് അടിസ്ഥാനമായ ചോദ്യത്തിന്റെ പ നമ്മുടെ പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നത് എളുപ്പമാണ് 2.04% കൂടുതല്‍ 1.74% കൂടുതല്‍ എക്സ്കെക്സ് മാച്ചും എഫ അവസാനം, നമ്മള്‍ മോഡല്‍ ഉണ്ടാക്കിയ എഡിറ്റുകള്‍ അന്വേഷിക്കുന്നതും, വാക്കിന്റെ നീളം മാറ്റുന്ന മോഡലിന്റെ പ്രഭാവം അന്വേഷിക്കുന</abstract_ml>
      <abstract_mn>Текст хялбарчлал бол өгүүлбэрийг хувааж, дахин хувааж өгүүлбэрүүдийн дарааллаар илүү амархан уншиж, ойлгох үйл явц юм. Мэдээлэл хялбарчлалыг NLP хэрэглээнд машины хөрөнгө оруулалт, жишээлбэл, semantic role labeling, мэдээлэл татах мэт хэрэглэгдсэн. Мэдээлэл нь ойлголтын үндсэн асуултын хариулт буюу доорх үйл ажиллагаанд ашиглах олон зам ашиглаж байна. Энэ ажлын тулд бид асуулт хариултын үйлдэл дээр текст хялбарчлалын нөлөөг судалж байна. Бид энгийн SQuAD-г олон ашигласан SQuAD өгөгдлийн сангийн хялбар хувилбарыг гаргаж өгдөг. Эхлээд бид өгөгдлийн сангийн бүтээгдэхүүний хоолойн шугам бүрийн алхам бүрийг тайлбарлаж, стиль шилжүүлэлт, өгүүлбэр зөв шилжүүлэлт, хариулт бүрт оффис олж байна. Хоёрдугаарт, бид автоматжуулсан болон хүн төрөлхтний үнэлгээ холбоотой олон аргаар шилжүүлсэн өгүүлбэрийн качестыг баталж байна. Гурав дахь, бид шинээр бүтээсэн корпус багтаж, SQuAD-ын асуулт асуултын хариултын үр дүнг шалгахын тулд ашиглах судалгааг хийдэг. Бидний туршилтууд хялбарчлал нь 2.04% болон 1.74% нь тохиолдолд тохиолддог. Эцэст нь бид шилжүүлэх процессийн шинжилгээ, загварын бүтээгдэхүүний төрлүүдийг судалж, шилжүүлэх загварын уртын нөлөө.</abstract_mn>
      <abstract_lt>Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning.  Tekstų supaprastinimas buvo panaudotas NLP programose, pavyzdžiui, mašin ų vertimui, santraukai, semantinio vaidmens ženklinimui ir informacijos gavimui, atveriant plataus masto galimybę ją naudoti atsakant į klausimus, pagrįstus supratimu, tolesnėse užduotyse. In this work, we investigate the effect of text simplification in the task of question-answering using a comprehension context.  We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset.  Pirma, apibūdiname kiekvieną duomenų rinkinio kūrimo vamzdyno etapą, įskaitant stilių perdavimą, sakinių, rodančių teisingą perdavimą, ribinę vertę ir kiekvieno atsakymo kompensavimo nustatymą. Secondly, we verify the quality of the transferred sentences through various methodologies involving both automated and human evaluation.  Trečia, mes lyginame naujai sukurtą korpusą ir atliekame abliacijos tyrimą, skirtą išnagrinėti supaprastinimo proceso poveikį atsakant į klausimus, pagrįstus SQuAD. Our experiments show that simplification leads to up to 2.04% and 1.74% increase in Exact Match and F1, respectively.  Finally, we conclude with an analysis of the transfer process, investigating the types of edits made by the model, and the effect of sentence length on the transfer model.</abstract_lt>
      <abstract_ms>Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning.  Text simplification has been exploited in NLP applications like machine translation, summarization, semantic role labeling, and information extraction, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks.  In this work, we investigate the effect of text simplification in the task of question-answering using a comprehension context.  We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset.  Firstly, we outline each step in the dataset creation pipeline, including style transfer, thresholding of sentences showing correct transfer, and offset finding for each answer.  Kedua, kita mengesahkan kualiti kalimat yang dipindahkan melalui berbagai metodologi yang melibatkan penilaian automatik dan manusia. Ketiga, kita benchmark corpus yang baru dicipta dan melakukan kajian ablasi untuk memeriksa kesan proses pemudahan dalam tugas menjawab soalan berdasarkan SQuAD. Our experiments show that simplification leads to up to 2.04% and 1.74% increase in Exact Match and F1, respectively.  Akhirnya, kami berakhir dengan analisis proses pemindahan, menyelidiki jenis edit yang dibuat oleh model, dan kesan panjang kalimat pada model pemindahan.</abstract_ms>
      <abstract_mt>Is-simplifikazzjoni tat-test hija l-proċess tal-qsim u r-riformulazzjoni ta’ sentenza f’sekwenza ta’ sentenzi li tagħmilha aktar faċli biex tinqara u tinftiehem filwaqt li jiġi ppreservat il-kontenut u jiġi approssimat it-tifsira oriġinali. Is-simplifikazzjoni tat-test ġiet sfruttata fl-applikazzjonijiet tal-NLP bħat-traduzzjoni tal-magni, is-sommarju, it-tikkettar tar-rwol semantiku, u l-estrazzjoni tal-informazzjoni, li fetaħ triq wiesgħa għall-isfruttament tagħha fil-kompiti downstream li jwieġbu għall-mistoqsijiet ibbażati fuq il-komprensjoni. F’dan ix-xogħol, ninvestigaw l-effett tas-simplifikazzjoni tat-test fil-kompitu tat-tweġiba għall-mistoqsijiet bl-użu ta’ kuntest ta’ komprensjoni. Aħna nirrilaxxaw Simple-SQuAD, verżjoni ssimplifikata tas-sett tad-dejta SQuAD użat ħafna. L-ewwel nett, aħna niddeskrivu kull pass fil-pipeline tal-ħolqien tas-sett tad-dejta, inkluż it-trasferiment tal-istil, il-limitu tas-sentenzi li juru trasferiment korrett, u s-sejba ta’ kumpens għal kull tweġiba. Secondly, we verify the quality of the transferred sentences through various methodologies involving both automated and human evaluation.  It-tielet nett, nagħmlu referenza għall-korpus li għadu kif in ħoloq u nagħmlu studju ta’ abblazzjoni biex jeżaminaw l-effett tal-proċess ta’ simplifikazzjoni fil-kompitu tat-tweġiba għall-mistoqsijiet ibbażat fuq l-SQuAD. L-esperimenti tagħna juru li s-simplifikazzjoni twassal għal żieda sa 2.04% u 1.74% fil-Match Exact u F1, rispettivament. Fl-aħħar nett, nikkonkludu b’analiżi tal-proċess ta’ trasferiment, ninvestigaw it-tipi ta’ editjar magħmul mill-mudell, u l-effett tat-tul tas-sentenza fuq il-mudell ta’ trasferiment.</abstract_mt>
      <abstract_ro>Simplificarea textului este procesul de împărțire și reformulare a unei propoziții într-o secvență de propoziții, făcând mai ușor de citit și înțeles, păstrând în același timp conținutul și aproximând sensul original. Simplificarea textului a fost exploatată în aplicațiile PNL, cum ar fi traducerea automată, rezumarea, etichetarea rolurilor semantice și extragerea informațiilor, deschizând o cale largă pentru exploatarea acestuia în sarcinile din aval bazate pe înțelegere. În această lucrare, investigăm efectul simplificării textului în sarcina de a răspunde la întrebări folosind un context de înțelegere. Lansăm Simple-SQUAD, o versiune simplificată a setului de date SQUAD utilizat pe scară largă. În primul rând, prezentăm fiecare pas în conducta de creare a setului de date, inclusiv transferul stilului, limitele propozițiilor care arată transferul corect și găsirea offset pentru fiecare răspuns. În al doilea rând, verificăm calitatea propozițiilor transferate prin diferite metodologii care implică atât evaluarea automată, cât și evaluarea umană. În al treilea rând, analizăm corpul nou creat și efectuăm un studiu de ablație pentru examinarea efectului procesului de simplificare în sarcina de răspuns la întrebări bazată pe SQUAD. Experimentele noastre arată că simplificarea duce la o creștere de până la 2,04% și 1,74% în Exact Match și, respectiv, F1. În cele din urmă, încheiem cu o analiză a procesului de transfer, investigând tipurile de editări efectuate de model și efectul lungimii propoziției asupra modelului de transfer.</abstract_ro>
      <abstract_pl>Uproszczenie tekstu to proces podziału i przeformułowania zdania na sekwencję zdań ułatwiający odczytanie i zrozumienie przy jednoczesnym zachowaniu treści i zbliżeniu oryginalnego znaczenia. Uproszczenie tekstu zostało wykorzystane w aplikacjach NLP, takich jak tłumaczenie maszynowe, podsumowanie, semantyczne oznaczanie roli i ekstrakcja informacji, otwierając szeroką możliwość jego wykorzystania w dalszych zadaniach opartych na zrozumieniu. W niniejszej pracy badamy wpływ uproszczenia tekstu w zadaniu odpowiedzi na pytania z wykorzystaniem kontekstu zrozumienia. Wydajemy Simple-SQuAD, uproszczoną wersję szeroko stosowanego zbioru danych SQuAD. Po pierwsze, zarysujemy każdy krok w pipelinie tworzenia zbiorów danych, w tym transfer stylu, thresholding zdań pokazujących prawidłowe przeniesienie oraz znalezienie offsetu dla każdej odpowiedzi. Po drugie, weryfikujemy jakość przeniesionych zdań za pomocą różnych metodologii obejmujących zarówno zautomatyzowaną, jak i ludzką ocenę. Po trzecie, porównujemy nowo utworzony korpus i przeprowadzamy badanie ablacji w celu zbadania efektu procesu uproszczenia w zadaniu odpowiedzi na pytania opartym na SQuAD. Nasze eksperymenty pokazują, że uproszczenie prowadzi do wzrostu odpowiednio do 2,04% i 1,74% w Exact Match i F1. Na koniec przedstawiamy analizę procesu transferu, zbadanie rodzajów edycji dokonywanych przez model oraz wpływ długości zdania na model transferu.</abstract_pl>
      <abstract_si>පාළ සරලීකරණය තමයි වාක්ෂාවක් පෙන්වන්න සහ ආපහු පෙන්වන්න සඳහා වාක්ෂාවක් කියලා කියලා කියලා තේරුම් ගන්න සඳහා ප්‍රතිලිප Name මේ වැඩේ අපි පරීක්ෂණය කරනවා ප්‍රශ්න ප්‍රතික්‍රියාවට ප්‍රශ්න ප්‍රතික්‍රියාවට ප්‍රශ්න ප්‍රතික්‍රියාවට ප්‍ර අපි සාමාන්‍ය SQuAD විකාශ කරනවා, විශාල පාවිච්චි SQuAD දත්ත සෙට්ටුවේ සරල සංවිධානයක්. මුලින්ම, අපි දත්ත සැකසුම් පායිප්ලින් වල හැම පැත්තක්ම පැත්තක්ම පැත්තක්ම පැත්තක්ම පැත්තක් තියෙන්නේ, වාර්තාව ගැන දෙවෙනි විදියටම, අපි ස්වයංක්‍රියාත්මක සහ මිනිස්සුන්ගේ විශේෂය සඳහා ස්වයංක්‍රියාත්මක විශේෂය ප්‍රති තුන්වෙනි විදියට, අපි අළුත් නිර්මාණය කරපු කොර්පස් එක බෙන්ච්මාර්ක් කරනවා ඒ වගේම ප්‍රශ්න ප්‍රශ්නයක් ප්‍රතික්ෂණය කරන් අපේ පරීක්ෂණය පෙන්වන්නේ සාමාන්‍ය විශ්වාසය 2.04% සහ 1.74% විශ්වාසයෙන් විශ්වාස කරන්න පුළුවන් කියලා. අන්තිමේදි, අපි ප්‍රවේශනයේ විශ්ලේෂණය සමඟ අවසන් කරනවා, මොඩේල් වලින් කරපු සංවේශනයේ වර්ගයක් පරීක්ෂණය කරනවා, ස</abstract_si>
      <abstract_sv>Textförenkling är processen att dela upp och omformulera en mening till en sekvens av meningar som gör det lättare att läsa och förstå samtidigt som innehållet bevaras och den ursprungliga innebörden närmar sig. Textförenkling har utnyttjats i NLP-applikationer som maskinöversättning, sammanfattning, semantisk rollmärkning och informationsutvinning, vilket öppnar en bred väg för dess utnyttjande i förståelsebaserade frågesvarsuppgifter nedströms. I detta arbete undersöker vi effekten av textförenkling i uppgiften att besvara frågor med hjälp av ett förståelsesammanhang. Vi släpper Simple-SQUAD, en förenklad version av den allmänt använda SQUAD-datauppsättningen. För det första beskriver vi varje steg i datauppsättningens skapandepipeline, inklusive stilöverföring, tröskelsättning av meningar som visar korrekt överföring och offset sökning för varje svar. För det andra kontrollerar vi kvaliteten på de överförda meningarna genom olika metoder som involverar både automatiserad och mänsklig utvärdering. För det tredje benchmarkar vi den nyskapade korpusen och genomför en ablationsstudie för att undersöka effekten av förenklingsprocessen i den SQUAD-baserade frågeställningsuppgiften. Våra experiment visar att förenkling leder till upp till 2,04% och 1,74% ökning i Exact Match respektive F1. Slutligen avslutar vi med en analys av överföringsprocessen, där vi undersöker vilka typer av ändringar som görs av modellen, och effekten av meningslängd på överföringsmodellen.</abstract_sv>
      <abstract_no>Tekstforenklinga er prosessen for å dele og gjenoppretta eit setning til ei rekkjefølgje setningar som gjer det lettere å lesa og forstå medan innhaldet er lagra og nærmer den originale betydninga. Tekstforenklinga er ekspluatert i NLP-program som maskinsomsetjing, samansering, semantisk rolletiketting og utpakking av informasjon, og opnar ein brett avenue for ekspluatasjonen i oppgåver med forståelse basert spørsmål-svarande nedstrekkoppgåver. I denne arbeiden undersøker vi effekten av tekstforenklinga i oppgåva av spørsmålssvar med ein forstålskontekst. Vi løyser Simple-SQuAD, ein forenkla versjon av den breidde brukte SQuAD- datasettet. Først strekar vi kvar steg i datasettopprettingspipelinja, inkludert stiloverføring, grenseverding av setningar som viser rett overføring, og forskyving for kvar svar. I andre stader vi kontrollerer kvaliteten på dei overførte setningane gjennom ulike metodar som involverer både automatiserte og menneske evaluering. Tredje, vi benchmarkerer den nye oppretta korpusen og utfører ein aktiveringsstudie for å undersøke effekten av forenklingsprosessen i SQuAD-basert spørsmål som svarar på oppgåva. Eksperimentane våre viser at forenklinga fører til 2,04% og 1,74% økt i nøyaktig treff og F1. I slutten er vi avslutta med ein analyse av overføringsprosessen, og undersøker typar redigeringar lagt av modellen, og effekten av setningslinga på overføringsmodulen.</abstract_no>
      <abstract_sr>Jednostavnost teksta je proces razdvajanja i ponovnog represiranja rečenice sekvenciji rečenica koja olakšava čitanje i razumevanje dok čuva sadržaj i približava originalno značenje. Jednostavnost teksta je iskorištena u aplikacijama NLP poput prevoda mašine, sažetka, semantičke etikete uloge i izvlačenja informacija, otvaranja široke avente za njegovu ekspluataciju u odgovorima na pitanja na osnovu razumevanja. U ovom poslu istražujemo učinak pojednostavljanja teksta u zadatku odgovora na pitanje koristeći kontekst razumevanja. Puštamo jednostavnu SQuAD, jednostavnu verziju široko korištenog seta podataka SQuAD. Prvo, pokazujemo svaki korak u cijevi stvaranja podataka, uključujući prijenos stila, prašinu rečenica pokazujući ispravan prijenos, i pronalaženje offset za svaki odgovor. Drugo, provjeravamo kvalitetu prenesenih rečenica kroz različite metode uključujući i automatsku i ljudsku procjenu. Treće, osnovali smo novog stvorenog korpusa i izvršili proučavanje ablacije za pregled učinka procesa pojednostavljanja u odgovornom zadatku na SQuAD-u. Naši eksperimenti pokazuju da pojednostavljanje vodi do 2,04% i povećanja od 1,74% to čnog matcha i F1. Konačno, zaključili smo sa analizom procesa prijenosa, istražujući vrste editora koji je napravio model, i učinak dužine rečenice na model prijenosa.</abstract_sr>
      <abstract_so>Isfududeynta qoraalka waa baaritaanka kala soocmaalka iyo dib u celinta hadalka uu u fududeeyaa akhriska iyo garashada marka la ilaaliyo waxyaabaha ku jira iyo ku xigta micneheeda asalka ah. Soo fududeynta qoraalka waxaa lagu isticmaalay codsiga NLP, sida turjumista machine, summarinta, halka qayb-qayb ah, iyo macluumaadka la soo saaray, oo lagu furan karo macluumaad ballaadhan oo lagu isticmaalayo goobaha su'aalaha hoosstream ka jawaabaya. Markaas waxan shaqada, waxaynu baaraynaa saamaynta fududaanshada text ee shaqada jawaabta su'aalaha isticmaalka kooxaha. Waxaynu siinnaa sahlan SQuAD, warqad sahlan oo ah SQuAD macluumaadka lagu isticmaalay widely-used. Marka ugu horeysa, waxaynu ku qornaa tallaabo kasta oo lagu sameeyo macluumaadka, kuwaas oo ka mid ah wareejinta qaababka, meelaha lagu wado wareejinta saxda ah, waxaana laga ridaa helitaanka jawaab walba. Second, waxaynu xaqiijinnaa qiimeynta nidaamka la wareejiyey qaabab kala duduwan oo ka mid ah qiimeynta bilowga iyo dadka. Saddexda, waxaynu bannaanaynaa qofka cusub ee la abuuray islamarkaasna waxaynu sameynaynaa waxbarashada dalbashada dhaqaalaha si aan u baaritaanno saamaynta arimaha fududaada ee ku saabsan su'aalaha SQuAD-based. Imtixaankayada waxay muuqataa in fududaadka waxay u kordhaa ugu fudud 2.04 boqolkiiba iyo 1.74 boqolkiiba kordhiya Eksi Match iyo F1. Ugu dambaysta, waxaynu ku dhamaystirnaa baaritaan baaritaanka sameynta qaababka hagitaanka iyo saamaynta dhererka ciqaabka sameynta qaababka wareejinta.</abstract_so>
      <abstract_ur>Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning. NLP کاربریوں میں لکھا گیا ہے جیسے ماشین ترجمہ، سامنٹی رول لیبلینگ، اور اطلاعات اضافہ، اس کے استعمال کے لئے ایک وسیع طریقہ کھولا گیا ہے۔ اس کام میں ہم ایک سمجھنے کے متصلہ کے مطابق سوال کے جواب کے کام میں تفصیل کے تفصیل کا اثر تحقیق کرتے ہیں. ہم سائل-SQuAD کو آزاد کریں، ایک سائل نسخہ جسے SQuAD ڈاٹ سٹ کا استعمال کیا گیا ہے۔ پہلی بار، ہم ہر قدم کو ڈاٹ سٹ پیدائش پائپ لین میں روشن کر رہے ہیں، اسٹیل ترنسفور کے شامل، مفصلوں کی ترنسفور دکھاتے ہیں، اور ہر جواب کے لئے آفاسٹ تلاش کرتے ہیں. دوسرا، ہم نے مختلف طریقوں کے ذریعہ سے منتقل کئے ہوئے جماعتوں کی کیفیت کی تصدیق کرتی ہے جو آٹوٹی اور انسان کی ارزش میں شامل ہوتی ہیں۔ تیسرا، ہم نے نئی پیدا کی کورپوس کو سنچم کر رکھا ہے اور اسکوڈ کے سوال جواب کرنے کے کام میں سفارش کے پروسس کا اثر دیکھنے کے لئے ایک آبلس تحقیق کریں۔ ہماری آزمائش دکھاتی ہے کہ سادگی 2.04% تک اور 1.74% تک اضافہ ہوتی ہے۔ آخر میں ہم نے انتقال پروسس کے ایک تحلیل کے ساتھ فیصلہ کیا ہے، مدل کے ذریعہ بنائے ہوئے ویڈیٹوں کی طرح تحقیق کریں، اور انتقال موڈل پر sentence length کے اثر.</abstract_ur>
      <abstract_ta>உரை எளிதாக்கம் என்பது பிரித்து வாக்கியத்தை ஒரு வரிசையில் மீண்டும் பிரித்து பிரிக்கும் செயல் Name இந்த வேலையில், நாம் உரை எளிதாக்கத்தின் விளைவை தேடுகிறோம். கேள்வி பதில் கேட்கையில் ஒரு சூழ்நிலையை பயன்படு நாம் எளிதாக SQuAD வெளியிடுகிறோம், ஒரு எளிதாக்கப்பட்ட SQuAD தரவுத்தளத்தின் பதிப்பு. Firstly, we outline each step in the dataset creation pipeline, including style transfer, thresholding of sentences showing correct transfer, and offset finding for each answer.  இரண்டாவது, நாம் மாற்றப்பட்ட வாக்குகளின் தரம் சரிபார்க்கிறோம். தானியங்கியாக மற்றும் மனித மதிப்பும் இருந்து முறைமைகள மூன்றாவது, எளிதாக்கம் 2.04% மற்றும் 1.74% சரியான பொருத்தம் மற்றும் F1 க்கு அதிகரிக்கும் என்பதை எங்கள் சோதனைகள் காட்டுகிறது. இறுதியில், நாம் மாற்றும் செயல்பாட்டின் ஒரு ஆய்வு முடிவுடன் முடிவு செய்து, மாதிரி உருவாக்கப்பட்ட திருத்தங்கள் வகைகளையும், மாற</abstract_ta>
      <abstract_uz>Name Name Bu ishda, biz matnning soddalashtirishning effektini o'rganamiz, savol javob beruvchi vazifani kompyuterdan foydalanish mumkin. Biz oddiy SQuAD, soddalashtirilgan SQuAD maʼlumot setining sodda versiyasini chiqaramiz. Birinchi marta, maʼlumotlar toʻplami yaratish roʻyxatidagi har bir qadam tuzilamiz, uslub transfer, toʻgʻri transfer koʻrsatilgan so'zlar tartibi, va har bir javob topish uchun ofset topilmadi. Ikkinchi so'zlarning sifatini avtomatik va inson qiymatlari bilan bir xil usullar bilan tasdiqlash imkoniyatini tekshirish. Thirdly, we benchmark the newly created corpus and perform an ablation study for examining the effect of the simplification process in the SQuAD-based question answering task.  Bizning imtiyozlarimiz esa oddiylikni 2.04% va 1.74% dan foydalanadi. Oxirgi, biz transfer jarayonini analyzer bilan tugatamiz, modelning turlarini qidirish va maxfiy soʻzning uzun modelida o'zgartirish natijasini o'rganamiz.</abstract_uz>
      <abstract_vi>Đơn giản văn bản là quá trình chia tách và bồi thường một câu thành một chuỗi các câu làm cho dễ đọc và hiểu, trong khi giữ lại nội dung và mô phỏng ý nghĩa gốc. Đơn giản văn bản đã được khai thác trong các ứng dụng NLP, như là dịch sửa máy, tóm tắt, mô tả các vai và khai thác thông tin, mở ra một phương pháp rộng để khai thác nó trong các nhiệm vụ theo dòng. Trong công việc này, chúng tôi nghiên cứu hiệu quả của việc đơn giản văn bản trong nhiệm vụ trả lời câu hỏi bằng ngữ cảnh thấu hiểu. Chúng tôi công bố đơn giản SCOAD, một phiên bản đơn giản của bộ dữ liệu SQurAD được phổ biến. Trước tiên, chúng ta mô tả từng bước trong đường dẫn cấu hình nhà dữ liệu, bao gồm chuyển kiểu, chia cắt ba phần câu từ hiển thị chuyển nhượng đúng, và số lượng từ điểm tìm kiếm cho mỗi câu trả lời. Thứ hai, chúng tôi kiểm tra chất lượng của các câu đã truyền qua các phương pháp có liên quan cả tự động lẫn nhân loại. Thứ ba, chúng tôi xem xét tập đoàn mới được tạo ra và thực hiện một nghiên cứu cắt bỏ để kiểm tra hiệu quả của tiến trình mô phỏng trong nhiệm vụ trả lời câu hỏi dựa trên SCOAD. Những thí nghiệm của chúng ta cho thấy sự đơn giản dẫn đến độ 2.04=và1.74=tốlãi suất tăng so với số Exact Match và F1. Cuối cùng, chúng ta kết thúc bằng một phân tích tiến trình chuyển nhượng, nghiên cứu các loại soạn thảo theo mẫu, và tác động của độ dài hạn của câu vào mẫu chuyển nhượng.</abstract_vi>
      <abstract_bg>Опростяването на текста е процес на разделяне и преформулиране на изречение в последователност от изречения, което улеснява четенето и разбирането му, като същевременно запазва съдържанието и приближава първоначалното значение. Опростяването на текста е експлоатирано в приложения за НЛП като машинен превод, обобщаване, семантично етикетиране на роли и извличане на информация, което отваря широк път за неговото използване в задачи, основани на разбиране, за отговор на въпроси надолу по веригата. В тази работа изследваме ефекта от опростяването на текста в задачата за отговор на въпроси чрез контекст на разбирането. Издаваме опростена версия на широко използвания набор от данни. Първо, очертаваме всяка стъпка в процеса на създаване на набор от данни, включително прехвърляне на стил, прагово определяне на изречения, показващи правилното прехвърляне, и намиране на компенсация за всеки отговор. Второ, проверяваме качеството на прехвърлените присъди чрез различни методологии, включващи както автоматизирана, така и човешка оценка. Трето, сравняваме новосъздадения корпус и извършваме аблационно проучване за изследване на ефекта от процеса на опростяване в задачата за отговор на въпроси, базирана на СКУАД. Нашите експерименти показват, че опростяването води до съответно до 2,04% и 1,74% увеличение на точния мач и Ф1. Накрая завършваме с анализ на процеса на прехвърляне, изследвайки видовете редакции, направени от модела, и ефекта на продължителността на присъдата върху модела на прехвърляне.</abstract_bg>
      <abstract_nl>Tekstvereenvoudiging is het proces van het splitsen en herformuleren van een zin in een reeks zinnen, waardoor deze gemakkelijker te lezen en te begrijpen is, terwijl de inhoud behouden blijft en de oorspronkelijke betekenis benaderd wordt. Tekstvereenvoudiging is benut in NLP-toepassingen zoals machinevertaling, samenvatting, semantische rollabeling en informatie-extractie, waardoor een brede weg wordt geopend voor de exploitatie ervan in op begrip gebaseerde vragenbeantwoordingstaken. In dit werk onderzoeken we het effect van tekstvereenvoudiging bij het beantwoorden van vragen met behulp van een begripscontext. We brengen Simple-SQuAD uit, een vereenvoudigde versie van de veelgebruikte SQuAD dataset. Ten eerste schetsen we elke stap in de dataset creatie pipeline, inclusief stijl overdracht, thresholding van zinnen met correcte overdracht en offset vinden voor elk antwoord. Ten tweede verifiëren we de kwaliteit van de overgebrachte zinnen door middel van verschillende methodologieën die zowel geautomatiseerde als menselijke evaluatie omvatten. Ten derde benchmarken we het nieuw gecreëerde corpus en voeren we een ablatieonderzoek uit om het effect van het vereenvoudigingsproces in de op SQuAD gebaseerde vragenantwoordtaak te onderzoeken. Onze experimenten tonen aan dat vereenvoudiging leidt tot respectievelijk 2,04% en 1,74% toename in Exact Match en F1. Tot slot sluiten we af met een analyse van het overdrachtsproces, onderzoek naar de soorten bewerkingen gemaakt door het model, en het effect van de lengte van de zin op het overdrachtsmodel.</abstract_nl>
      <abstract_da>Tekstforenkling er processen med at opdele og omformulere en sætning til en række sætninger, der gør det lettere at læse og forstå, samtidig med at indholdet bevares og tilnærmes den oprindelige betydning. Tekstforenkling er blevet udnyttet i NLP applikationer som maskinoversættelse, opsummering, semantisk rollemærkning og informationsudvinding, hvilket åbner en bred mulighed for dens udnyttelse i forståelsesbaserede spørgsmål-besvarelse downstream opgaver. I dette arbejde undersøger vi effekten af tekstforenkling i opgaven med at besvare spørgsmål ved hjælp af en forståelseskontekst. Vi udgiver Simple-SQUAD, en forenklet version af det udbredte SQUAD datasæt. For det første skitserer vi hvert trin i datasætteoprettelsesrørledningen, herunder stiloverførsel, tærskelægning af sætninger, der viser korrekt overførsel, og offset finding for hvert svar. For det andet kontrollerer vi kvaliteten af de overførte sætninger gennem forskellige metoder, der involverer både automatiseret og menneskelig evaluering. For det tredje sammenligner vi det nyoprettede korpus og udfører en ablationsundersøgelse for at undersøge effekten af forenklingsprocessen i den SQUAD-baserede spørgsmålsbesvarelsesopgave. Vores eksperimenter viser, at forenkling fører til op til 2,04% og 1,74% stigning i henholdsvis Exact Match og F1. Endelig afslutter vi med en analyse af overførselsprocessen, hvor vi undersøger typerne af redigeringer foretaget af modellen, og effekten af sætningslængden på overførselsmodellen.</abstract_da>
      <abstract_hr>Jednostavnost teksta je proces razdvajanja i rephraviranja rečenice u sekvencu rečenica koji olakšava čitanje i razumijevanje dok čuva sadržaj i približava originalno značenje. Jednostavnost teksta je iskorištena u aplikacijama NLP-a poput prevoda strojeva, sažetka, semantičke oznake uloge i izvlačenja informacija, otvaranja široke avenije za njegovu iskorištavanje u potpunim zadatkima odgovarajućim na pitanja na osnovu razumijevanja. U ovom poslu istražujemo učinak pojednostavljanja teksta u zadatku odgovora na pitanje koristeći kontekst razumijevanja. Puštamo jednostavnu SQuAD, jednostavnu verziju široko korišćene SQuAD podataka. Prvo, pokazujemo svaki korak u cijevi stvaranja podataka, uključujući prijenos stila, prašinu rečenica pokazujući ispravan prijenos i pronalaženje offset za svaki odgovor. Drugo, potvrđujemo kvalitetu prenesenih rečenica kroz različite metode uključujući i automatsku i ljudsku procjenu. Treće, određujemo novog stvorenog korpusa i izvršimo ispitivanje za ispitivanje učinka procesa pojednostavljanja u odgovornom zadatku na SQuAD-u pitanja. Naši eksperimenti pokazuju da pojednostavljenje vodi do 2,04% i povećanja od 1,74% to čne odgovornosti i F1. Konačno, zaključili smo s analizom procesa prijenosa, istražujući vrste uredova modela i učinak dužine kazne na model prijenosa.</abstract_hr>
      <abstract_de>Textvereinfachung ist der Prozess des Aufspaltens und Umformulierens eines Satzes in eine Satzfolge, die es leichter macht, ihn zu lesen und zu verstehen, während der Inhalt erhalten bleibt und sich der ursprünglichen Bedeutung annähert. Die Textvereinfachung wurde in NLP-Anwendungen wie maschinelle Übersetzung, Zusammenfassung, semantische Rollenbeschriftung und Informationsextraktion ausgenutzt, was eine breite Möglichkeit für ihre Nutzung in verständnisbasierten Fragestellungen eröffnet. In dieser Arbeit untersuchen wir den Effekt der Textvereinfachung bei der Fragestellung anhand eines Verständniskontextes. Wir veröffentlichen Simple-SQuAD, eine vereinfachte Version des weit verbreiteten SQuAD-Datensatzes. Zunächst skizzieren wir jeden Schritt in der Datensatzerstellungspipeline, einschließlich Stilübertragung, Thresholding von Sätzen, die korrekte Übertragung zeigen, und Offsetfindung für jede Antwort. Zweitens überprüfen wir die Qualität der übertragenen Sätze durch verschiedene Methoden, die sowohl automatisierte als auch menschliche Evaluierungen beinhalten. Drittens benchmarken wir den neu erstellten Korpus und führen eine Ablationsstudie durch, um den Effekt des Vereinfachungsprozesses in der SQuAD-basierten Fragebeantwortung zu untersuchen. Unsere Experimente zeigen, dass Vereinfachung zu einem Anstieg von bis zu 2,04% und 1,74% bei Exact Match bzw. F1 führt. Abschließend wird eine Analyse des Transferprozesses durchgeführt, wobei die Art der Bearbeitungen des Modells und die Auswirkung der Satzlänge auf das Transfermodell untersucht werden.</abstract_de>
      <abstract_fa>ساده‌سازی متن فرایند جدا کردن و بازگرداندن یک جمله به مجموعه‌ی جمله‌ها است که آن را برای خواندن و درک آسان‌تر می‌کند در حالی که محتویات را حفظ می‌کند و به نزدیک معنی اصلی نزدیک می‌شوند. ساده‌سازی متن در کاربردهای NLP مانند ترجمه‌سازی ماشین، جمع‌سازی، نقشه‌های semantic و استخراج اطلاعات استفاده می‌شود، باز کردن یک راه گسترده برای استفاده از آن در کار‌های پایین‌سازی سوال‌های بفهمید. در این کار، ما تاثیر ساده‌سازی متن را در کار جواب سوال با استفاده از یک محیط درک تحقیق می‌کنیم. ما ساده SQuAD را آزاد می‌کنیم، یک نسخه ساده‌ای از مجموعه داده‌های SQuAD استفاده می‌شود. اول، ما هر قدم را در خط آفرینش مجموعه داده‌ها روشن می‌کنیم، شامل تغییر استیل، تغییر داده‌های جمله‌ها که انتقال درست را نشان می‌دهند، و پیدا کردن برای هر جواب تغییر می‌دهیم. دوم، ما کیفیت جمله‌های منتقل شده را با روش‌های مختلف با ارزیابی خودکار و انسان تحقیق می‌کنیم. سوم، ما یک مطالعه تازه ساخته شده کورپوس را ترکیب می‌کنیم و یک مطالعه فعالیت برای تحقیق اثر فرایند ساده‌سازی در پاسخ جواب سوال‌های SQuAD انجام می‌دهیم. آزمایش‌های ما نشان می‌دهند که ساده‌سازی به حدود 2.04% و 1.74% افزایش در مسابقه دقیق و F1 را می‌رساند. بالاخره، ما با تحلیل فرایند انتقال، تحقیق از نوع ویدئاتی که توسط مدل ساخته شده، و تاثیر طول جمله بر مدل انتقال، پایان می دهیم.</abstract_fa>
      <abstract_sw>Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning.  Uurahisi wa maandishi umetumiwa katika matumizi ya NLP kama vile tafsiri ya mashine, muhtasari, jukumu la kimapenzi, na utoaji wa taarifa, kufungua ujumbe mkubwa wa matumizi yake katika kazi za maswali yenye msingi na kujibu miti ya chini ya mto. Katika kazi hii, tunachunguza madhara ya urahisi wa maandishi katika kazi ya kujibu maswali kwa kutumia muktadha wa jumla. Tunaachia huduma nyepesi ya SQuAD, toleo rahisi la seti ya taarifa za SQuAD zilizotumika kwa ujumla. Kwanza, tunaonyesha kila hatua katika kutengeneza pipeline za taarifa, ikiwa ni pamoja na usafirishaji wa mtindo, kufungiwa kwa sentensi zinazoonyesha uhamishaji sahihi, na kutoa nafasi kwa kila jibu. Pili, tunathibitisha kiwango cha hukumu zilizobadilishwa kupitia mbinu mbalimbali zinazohusiana na utafiti wa binadamu. Katika tatu, tunaweka kurasa mpya iliyotengenezwa na kutekeleza utafiti wa kuchunguza madhara ya mchakato wa urahisi katika kazi ya kujibu maswali ya SQuAD. Majaribio yetu yanaonyesha kuwa urahisi unapelekea hadi asilimia 2.04 na kuongezeka kwa asilimia 1.74 kwa asilimia moja ya Matanikio ya Haki na F1. Mwisho, tunahitimisha kwa uchambuzi wa mchakato wa uhamiaji, tunachunguza aina ya wahariri zilizotengenezwa na modeli, na athari ya mrefu wa hukumu juu ya modeli ya uhamishaji.</abstract_sw>
      <abstract_ko>텍스트 단순화는 한 문장을 분리하여 일련의 문장으로 재해석하는 과정으로 읽기와 이해를 더욱 쉽게 하는 동시에 내용을 보존하고 원시적인 의미에 가깝게 하는 것이다.텍스트 간소화는 기계 번역, 요약, 의미 역할 표시와 정보 추출 등 자연 언어 처리 응용에서 광범위하게 응용되었고 이해를 바탕으로 하는 문답 하류 임무에서의 응용에 광범위한 경로를 열었다.이 작업에서 우리는 텍스트가 언어 환경을 이해하는 데 있어서의 문답 임무를 간소화하는 작용을 연구했다.Simple SQuaD를 발표했습니다. 널리 사용되는 SQuaD 데이터 세트의 간략한 버전입니다.먼저, 우리는 데이터 집합 생성 파이프의 모든 절차를 개괄했다. 스타일 변환, 정확한 변환을 표시하는 문장 한도값 설정, 그리고 모든 답안의 편이량 찾기를 포함한다.그 다음으로 우리는 자동과 인공 평가와 관련된 각종 방법을 통해 문장의 질을 검증한다.셋째, 우리는 새로 만든 어료 라이브러리에 대해 기준 테스트를 하고 간소화 과정이 반을 바탕으로 하는 문답 임무에서의 효과에 대해 연구했다.우리의 실험은 간소화 후의 정확한 일치와 F1이 각각 2.04%와 1.74% 높아졌다는 것을 나타냈다.마지막으로 우리는 이동 과정에 대해 분석을 하고 모델이 편집한 유형과 문장의 길이가 이동 모델에 미친 영향을 연구했다.</abstract_ko>
      <abstract_id>Simplifikasi teks adalah proses pembagian dan mengubah kalimat ke urutan kalimat yang membuatnya lebih mudah untuk dibaca dan memahami sementara menyimpan isi dan mendekati arti asli. Simplifikasi teks telah dieksploitasi dalam aplikasi NLP seperti terjemahan mesin, ringkasan, label peran semantis, dan ekstraksi informasi, membuka jalan luas untuk eksploitasinya dalam menjawab pertanyaan berdasarkan pemahaman tugas turun. Dalam pekerjaan ini, kami menyelidiki efek penyimplifikasi teks dalam tugas menjawab pertanyaan menggunakan konteks pemahaman. Kami melepaskan Simple-SQuAD, versi sederhana dari set data SQuAD yang sering digunakan. Pertama, kita menggambarkan setiap langkah dalam pipeline penciptaan set data, termasuk transfer gaya, pembatasan kalimat menunjukkan transfer yang benar, dan menemukan offset untuk setiap jawaban. Kedua, kita mengkonfirmasi kualitas kalimat yang dipindahkan melalui berbagai metodologi yang melibatkan evaluasi otomatis dan manusia. Ketiga, kita benchmark corpus yang baru diciptakan dan melakukan studi ablasi untuk memeriksa efek proses penyimplifikasi dalam tugas menjawab pertanyaan berdasarkan SQuAD. Eksperimen kami menunjukkan bahwa penyimplifikasi membawa hingga 2,04% dan 1,74% peningkatan dalam persamaan eksakt dan F1, respectively. Akhirnya, kami menyelesaikan dengan analisis proses transfer, menyelidiki jenis edit yang dibuat oleh model, dan efek panjang kalimat pada model transfer.</abstract_id>
      <abstract_tr>Metin bejermek we sözleriň dizigine a ýratmak we ýene-täzeden sözleriň mahalini saýlamak we düşünmek aňsatlyk bilen aňsatlyk bilen okamak we düşünmekdir. NLP uygulamalarynda maşynyň terjime, jeminatlama, semantik roli etitlemeleri ýaly metin bejermek üçin ullanýar. Biz bu işde sorag-jogabat täsirinde metin esaslaşdyrmanyň täsirini düşündirdik. Basit-SQuAD'i, ullanýan SQuAD maglumatynyň basit bir wersiýasyny çykarýarys. Ilkinji gezek, biz veri setir baglançynyň pipeliniň her adıny çykarýarys, stil göçürmäge dahil, sözlemler dogry göçürmäge görkezilýän süýşiklikler we her jogaba üçin süýşiklik edip süýşirdik. Ikinjisi, sözleriň howpsuzlygyny otomatik we ynsan deňlemesi bilen meňzeş methodologiýa bilen barlaýarys. Üçüncüsü, täze bir korpusy düzenledik we SQuAD'da sorag jogaplarynyň etkisini barlamak üçin etkinleşik bir çalışma yaptık. Biziň deneylerimiz bejerilmek 2,04% we 1,74% derejesi derejesi Eýtgeýän we F1-e ýokarynda ýokarylýar. Soňunda, biz transfers prosesiniň analizi bilen çykypdyk, nusga tarapyndan eden düzenleriň türlerini we sözlemler uzynyň täsirini terjime etmek üçin kararynda çykypdyk.</abstract_tr>
      <abstract_am>የጽሑፍ ቀላልነት የጽሑፉን ውይይት ለመለየት እና ወደ ክፍለ ቁጥጥር ማሰናከል እና ማስተዋል ማሰናከል እና ማህበረቱን በመጠበቅ እና አካባቢ ማሰራትን ማቅረብ የሚያስቀናው ነው፡፡ የጽሑፍ ቀላል በመፍጠር ላይ በመጠቀም ላይ የጥያቄ ትርጉም፣ ማስታወቂያ፣ የsemantic role labeling እና የመረጃ ምርጫዎች በNLP ፕሮግራሞች ላይ ተጠቃሚ ሆኖአል፡፡ በዚህ ሥራ የጽሑፍ ቀላልነት በጥያቄ መልስ በመጠቀም ጥያቄን በጽሑፍ ውጤት እናመርመራለን፡፡ ቀላል-SQuAD (SQuAD) የስፋት የSQuAD ዳታተር ጽሑፍ እናወጣለን፡፡ በመጀመሪያ፣ ሁሉንም ደረጃዎች በመፍጠር ላይ አቀማመጥ እናስቀራለን፡፡ በሁለተኛው፣ የተለወጠውን ቃላት ብዛት እና በሰው ማስታወቂያ በተለወጠው ልማድ እናረጋግጣለን፡፡ በሦስተኛው፣ አዲስ የተፈጠረውን ኮፕስ እና የSQuAD ጥያቄ መልስ በሚደረገው ጥያቄን ለመፈለግ የሚችሉትን ትምህርት እናደርጋለን፡፡ Our experiments show that simplification leads to up to 2.04% and 1.74% increase in Exact Match and F1, respectively.  በመጨረሻውም፣ የtransfer ፕሮግራሙን በማስተካከል እና በሞዴል የተደረገውን አስተካክል እና የፍርዱ ርዝመት በtransfer model ላይ ነው፡፡</abstract_am>
      <abstract_af>Teks vereenvoudiging is die proses van 'n spreiding en herverspreiding van 'n setsing na' n volgorde van setnings wat dit makliker om te lees en te verstaan terwyl die inhoud bewaar en die oorspronklike betekening aankoms. Teks eenvoudiging is gebruik in NLP toepassings soos masjien vertaling, opsomming, semantiese rol etiketting en inligting uitvoer, oopmaak 'n breë avenue vir sy uitvoering in verstanding-gebaseerde vraag-antwoord onderstreem taak. In hierdie werk, ons ondersoek die effek van teks eenvoudiging in die taak van vraag-antwoord met 'n verstandige konteks. Ons verlos eenvoudige- SQuAD, 'n eenvoudige weergawe van die vaste gebruikte SQuAD datastel. Eerste, ons uittrek elke stap in die datastel skep pyplyn, insluitend styl oordrag, drukking van teikene wat korrek oordrag vertoon, en offset soek vir elke antwoord. Tweede, ons bevestig die kwaliteit van die oordragte setings deur verskeie metodologies wat beide outomatiese en menslike evaluering invoer. Derde, ons benchmark die nuwe geskepte korpus en uitvoer 'n ablasie studie vir ondersoek die effek van die eenvoudiging proses in die SQuAD-gebaseerde vraag antwoord taak. Ons eksperimente vertoon dat eenvoudiging lei na 2. 04% en 1. 74% verhoog in Exact Match en F1, respectively. Eindelik, ons sluit met 'n analiseer van die oordragproses, ondersoek die tipes redigeerders wat deur die model gemaak is, en die effek van setlingte op die oordragmodel.</abstract_af>
      <abstract_sq>Simplifikimi i tekstit është procesi i ndarjes dhe rishformimit të një fjalie në një sekuencë fjalësh që e bën më të lehtë të lexohet dhe të kuptohet ndërsa ruan përmbajtjen dhe afrohet kuptimi origjinal. Simplifikimi i tekstit është shfrytëzuar në aplikacionet NLP si përkthimi i makinave, përmbledhja, etiketa semantike e rolit dhe nxjerrja e informacionit, duke hapur një rrugë të gjerë për shfrytëzimin e saj në përgjigjen e pyetjeve të bazuara në kuptim të detyrave poshtë. Në këtë punë, ne hetojmë efektin e thjeshtimit të tekstit në detyrën e përgjigjes së pyetjeve duke përdorur një kontekst kuptimi. Ne lëshojmë Simple-SQuAD, një version i thjeshtë të grupit të të dhënave SQuAD të përdorur gjerësisht. Së pari, ne përshkruajmë çdo hap në tubacionin e krijimit të të dhënave, duke përfshirë transferimin e stilit, pragun e fjalëve që tregojnë transferimin e saktë dhe gjetjen e kompensimit për çdo përgjigje. Secondly, we verify the quality of the transferred sentences through various methodologies involving both automated and human evaluation.  Së treti, ne paraqesim korpusin e ri të krijuar dhe kryejmë një studim ablacioni për shqyrtimin e efektit të procesit të thjeshtësimit në detyrën e përgjigjes së pyetjeve bazuar në SQuAD. Eksperimentet tona tregojnë se thjeshtimi çon deri në 2.04% dhe 1.74% rritje respektivisht në Match Exact dhe F1. Më në fund, përfundojmë me një analizë të procesit të transferimit, duke hetuar llojet e ndryshimeve të bërë nga modeli dhe efektin e gjatësisë së fjalës në modelin e transferimit.</abstract_sq>
      <abstract_az>Metin sadiqləndirməsi məlumatı bölüşdürmək və cümləyi təkrarlamaq məlumatı saxlayaraq oxumaq və anlamaq üçün asanlaşdırmaq və təkrarlamaq prosesidir. NLP proqramlarında mətn sadiqlənməsi, maşın çevirilməsi, yığışdırma, semantik rol etiketi və məlumatların çıxarması kimi istifadə edildi, anlama-tabanlı sual-cavab verməsi üçün geniş bir yol a çar. Bu işdə, bir anlama məlumatı vasitəsilə sorğu-cavab vermək məlumatının təsirini araşdırırıq. Basit-SQuAD, geniş istifadə edilən SQuAD veri qutusunun basit bir versiyonu yayındırırıq. Əvvəlcə, hər adımı verilən qutusu yaratma boru çizgisində yazırıq, istifadə tərəfindən istifadə edilir, tərəfindən doğru tərəfindən göstərilən cümlələrin sütunu və hər cavab üçün tərəfindən istifadə edirik. İkincisi, təkrar edilmiş cümlələrin keyfiyyətini təsdiqləyirik, hər ikisi də automatik və insan değerlendirməsi ilə müxtəlif metodolojilərlə. Üçüncüsü, biz yeni yaratdığı korpusu müəyyən edirik və SQuAD-in əskilmə prosesinin cavab verəcəyi sual işlərinin etkisini sınamaq üçün fəaliyyəti təhsil edirik. Bizim təcrübələrimiz bu təcrübə 2,04%-ə və 1,74%-ə istifadə edir. Sonunda, daşıma procesinin analizi ilə, modellərin düzəltdikləri editlərin türünü və cümlənin uzunluğunu daşıma modellərinin etkisini incidirik.</abstract_az>
      <abstract_hy>Տեքստի պարզաբանությունը նախադասությունը բաժանելու և վերաձևավորելու գործընթացն է նախադասությունների հաջորդականությամբ, որը հեշտացնում է կարդալը և հասկանալը, պահպանելով պարունակությունը և մոտենալով սկզբնական իմաստը: Տեքստի պարզաբանությունը օգտագործվել է ՆԼՊ-ի ծրագրերում, ինչպիսիք են մեքենայի թարգմանությունը, համառոտագրությունը, սեմանտիկ դերի պիտակումը և տեղեկատվության վերացումը, բացելով լայն ճանապարհ այն օգտագործելու համար ընկալումն հիմնված հարցերի պատասխանելիս Այս աշխատանքի ընթացքում մենք ուսումնասիրում ենք տեքստի պարզաբանության ազդեցությունը հարցերի պատասխանելու խնդրում՝ օգտագործելով ընկալումների կոնտեքստը: Մենք հրապարակում ենք Պարզ-SQUADը, լայնորեն օգտագործված SQUADի տվյալների մի պարզ տարբերակ: Առաջինը, մենք նկարագրում ենք տվյալների համակարգի ստեղծման խողովակաշարի յուրաքանչյուր քայլ, ներառյալ ոճի փոխանցումը, նախադասությունների սահմանները, որոնք ցույց են տալիս ճիշտ փոխանցումը, և յուրաքանչյուր պատասխանի Երկրորդ, մենք ստուգում ենք փոխանցված նախադասությունների որակը տարբեր մեթոդոլոգիաների միջոցով, որոնք ներառում են ինչպես ավտոմատիկ, ինչպես նաև մարդկային գնահատականներ: Երրորդ, մենք համեմատում ենք նոր ստեղծված մարմինը և կատարում ենք աբլացիոն ուսումնասիրություն, որպեսզի ուսումնասիրենք պարզաբանության գործընթացի ազդեցությունը SQUADի հիմնված հարցերի պատասխանատվության խնդրում: Մեր փորձարկումները ցույց են տալիս, որ պարզաբանությունը հանգեցնում է մինչև 2.04 և 1.74 տոկոսի աճի Exacti Match-ում և F1-ում: Վերջապես, մենք ավարտեցինք փոխանցման գործընթացի վերլուծությամբ, ուսումնասիրեցինք մոդելի ստեղծված խմբագրությունների տեսակները և նախադասության երկարության ազդեցությունը փոխանցման մոդելի վրա:</abstract_hy>
      <abstract_bn>টেক্সটের সুস্পষ্ট প্রক্রিয়া হচ্ছে বিভক্ত এবং বিভিন্ন বাক্য পুনরায় প্রতিরোধ করার প্রক্রিয়া যেখানে বিষয়বস্তু সংরক্ষণ করা এবং মূল অর্থ সংরক মেশিন অনুবাদ, সংক্ষেপ, সামেন্টিক ভূমিকা লেবেলিং এবং তথ্য ব্যবহারের মত এনএলপি অ্যাপ্লিকেশনে লেখার সুস্পষ্ট ব্যবহার করা হয়েছে, যেমন গুরুত্বপূর্ণ প্রশ্নের এই কাজে আমরা লেখার সুস্পষ্ট প্রভাব তদন্ত করছি প্রশ্নের উত্তর ব্যবহার করার কাজে। আমরা সাধারণ SQuAD-কে মুক্ত করি, ব্যাপক ব্যবহৃত SQuAD ডাটাসেটের একটি সংস্করণ। প্রথমত, আমরা ডাটাসেট সৃষ্টির পাইপেলাইনে প্রত্যেকটি পদক্ষেপ উল্লেখ করি, যার মধ্যে স্টাইল ট্রান্সফার্নার, সঠিক স্থানান্তর দেখান দ্বিতীয়, আমরা স্বয়ংক্রিয়ভাবে এবং মানুষের মূল্যের মাধ্যমে বিভিন্ন পদ্ধতির মাধ্যমে পরিবর্তিত বাক্যের মান পরীক্ষ তৃতীয়তমানে, আমরা নতুন তৈরি কর্পাসের বেনমার্ক করেছি এবং এসকুয়াড ভিত্তিক প্রশ্নের উত্তর প্রশ্নের প্রভাব পরীক্ষা করার জন্য একটি আগুনের গবে আমাদের পরীক্ষাগুলো দেখাচ্ছে যে সহজেকভাবে ২. শেষ পর্যন্ত আমরা পরিবর্তনের প্রক্রিয়ার বিশ্লেষণের সাথে পরিণত হয়েছি, মডেলের দ্বারা যে ধরনের সম্পাদক তৈরি করা হয়েছে তা তদন্ত করেছি এবং সেই ধর</abstract_bn>
      <abstract_cs>Zjednodušení textu je proces rozdělení a přeformulování věty na sekvenci vět, která usnadňuje čtení a porozumění při zachování obsahu a přibližování původního významu. Zjednodušení textu bylo využito v aplikacích NLP, jako je strojový překlad, shrnutí, značení sémantických rolí a extrakce informací, což otevírá širokou cestu pro jeho využití v následných úkolech založených na porozumění. V této práci zkoumáme vliv zjednodušení textu v úkolu odpovědi na otázky pomocí kontextu porozumění. Vydáváme Simple-SQuAD, zjednodušenou verzi široce používané datové sady SQuAD. Nejprve nastíníme každý krok v potrubí vytváření datových sad, včetně přenosu stylu, thresholding vět ukazujících správný přenos a offsetového hledání pro každou odpověď. Za druhé ověřujeme kvalitu přenesených trestů různými metodikami zahrnujícími automatizované i lidské hodnocení. Za třetí srovnáme nově vytvořený korpus a provedeme ablační studii pro zkoumání vlivu procesu zjednodušení v úkolu zodpovědět otázky založené na SQuAD. Naše experimenty ukazují, že zjednodušení vede ke zvýšení počtu Exact Match a F1 až do 2,04% a 1,74% . Závěrem je analýza procesu přenosu, zkoumání typů úprav provedených modelem a vlivu délky věty na přenosový model.</abstract_cs>
      <abstract_ca>La simplificació del text és el procés de dividir i reesformar una frase en una seqüència de frases que faci més fàcil llegir i entendre mentre conserva el contingut i aproxima el significat original. La simplificació del text s'ha explotat en aplicacions NLP com traducció màquina, resum, etiquetar el paper semàntic i extracció d'informació, obrint una gran via d'explotació en resposta a preguntes basada en la comprensió a tasques avall. En aquest treball, investigam l'efecte de la simplificació del text en la tasca de respondre a preguntes utilitzant un context de comprensió. Vam publicar Simple-SQuAD, una versió simplificada del conjunt de dades SQuAD generalitzat. En primer lloc, esboquem cada pas en el tub de creació del conjunt de dades, incloent la transfer ència d'estil, el límit de les frases que mostren la transferència correcta, i el descobriment de compensació per cada resposta. En segon lloc, verifiquem la qualitat de les frases transferides mitjançant diverses metodologies que impliquen una evaluació tant automatitzada com humana. En tercer lloc, comparem el cos nou creat i fem un estudi d'ablació per examinar l'efecte del procés de simplificació en la tasca de resposta a preguntes basada en SQuAD. Els nostres experiments demostren que la simplificació porta a un increment de 2,04% i 1,74% en Exact Match i F1, respectivament. Finalment, vam concluir amb una an àlisi del procés de transfer ència, investigant els tipus d'edicions fets pel model, i l'efecte de la llargada de frases en el model de transferència.</abstract_ca>
      <abstract_bs>Jednostavnost teksta je proces razdvajanja i ponovnog represiranja rečenice na sekvencu rečenica koji olakšava čitanje i razumijevanje dok čuva sadržaj i približava originalno značenje. Jednostavnost teksta je iskorištena u aplikacijama NLP-a poput prevoda strojeva, sažetka, semantičke etikete uloge i izvlačenja informacija, otvaranja široke avente za njegovu ekspluataciju u potpunim zadatkima odgovarajućim na pitanja na osnovu razumijevanja. U ovom poslu istražujemo učinak pojednostavljanja teksta u zadatku odgovora na pitanje koristeći kontekst razumijevanja. Puštamo jednostavnu SQuAD, jednostavnu verziju široko korištenog seta podataka SQuAD. Prvo, pokazujemo svaki korak u cijevi stvaranja podataka, uključujući prijenos stila, prašinu rečenica pokazujući ispravan prijenos, i pronalaženje offset za svaki odgovor. Drugo, potvrđujemo kvalitetu prenesenih rečenica kroz različite metode uključujući i automatsku i ljudsku procjenu. Treće, kreiramo novog stvorenog korpusa i izvršimo ispitivanje ablacije za pregled učinka procesa pojednostavljanja u odgovornom zadatku na SQuAD-u. Naši eksperimenti pokazuju da pojednostavljanje vodi do 2,04% i povećanja od 1,74% to čnog odgovora i F1. Konačno, zaključili smo s analizom procesa prijenosa, istražujući vrste editora koje je napravio model, i učinak dužine kazne na model prijenosa.</abstract_bs>
      <abstract_et>Teksti lihtsustamine on lause jagamise ja ümbersõnastamise protsess lausete järjestuseks, mis lihtsustab lugemist ja mõistmist, säilitades samas sisu ja lähendades algset tähendust. Teksti lihtsustamist on kasutatud uue tööprogrammi rakendustes, nagu masintõlge, kokkuvõtlus, semantiline rollimärgistus ja teabe väljavõtmine, avades laia võimaluse selle kasutamiseks arusaamisepõhistes küsimustele vastamise järgmistes ülesannetes. Käesolevas töös uurime teksti lihtsustamise mõju küsimustele vastamise ülesandele arusaamise konteksti abil. Me avaldame Simple-SQuAD, lihtsustatud versiooni laialdaselt kasutatavast SQuAD andmekogumist. Esiteks kirjeldame andmekogumi loomise kõiki samme, sealhulgas stiilide ülekandmist, lausete piiramist, mis näitavad õiget ülekandmist ja tasakaalustamist iga vastuse jaoks. Teiseks kontrollime ülekantud karistuste kvaliteeti erinevate metoodikate abil, mis hõlmavad nii automatiseeritud kui ka inimlikku hindamist. Kolmandaks võrdleme äsja loodud korpuse ja teostame ablatsiooniuuringu lihtsustamisprotsessi mõju uurimiseks SQuAD-põhises küsimustele vastamise ülesandes. Meie katsed näitavad, et lihtsustamine toob kaasa vastavalt kuni 2,04% ja 1,74% kasvu täpne vaste ja F1. Lõpetuseks analüüsime ülekandeprotsessi, uurime mudeli tehtud muudatuste tüüpe ja karistuse pikkuse mõju ülekandemudelile.</abstract_et>
      <abstract_fi>Tekstin yksinkertaistaminen on prosessi, jossa lause jaetaan ja muotoillaan uudelleen lausesarjaksi, mikä helpottaa lukemista ja ymmärtämistä säilyttäen samalla sisällön ja lähentäen alkuperäistä merkitystä. Tekstin yksinkertaistamista on hyödynnetty NLP-sovelluksissa, kuten konekäännöksessä, tiivistelmässä, semanttisessa roolimerkinnässä ja tiedonhankinnassa, mikä avaa laajan väylän sen hyödyntämiselle ymmärtämiseen perustuvissa kysymyksiin vastaamisessa jatkojalostustehtävissä. Tässä työssä tutkitaan tekstin yksinkertaistamisen vaikutusta kysymyksiin vastaamiseen ymmärtämisen kontekstin avulla. Julkaisemme Simple-SQuAD:n, yksinkertaistetun version laajasti käytetystä SQuAD-aineistosta. Ensinnäkin hahmottelemme jokaisen vaiheen tietoaineiston luomisessa, mukaan lukien tyylinsiirto, lauseiden raja-arvot, jotka osoittavat oikean siirron, ja offset-löydöt jokaiselle vastaukselle. Toiseksi tarkistamme siirrettyjen tuomioiden laadun erilaisin menetelmin, joihin sisältyy sekä automatisoitu että inhimillinen arviointi. Kolmanneksi vertailemme vastikään luotua korpusta ja suoritamme ablaatiotutkimuksen yksinkertaistamisprosessin vaikutusta SQuAD-pohjaiseen kysymykseen vastaamiseen. Kokeemme osoittavat, että yksinkertaistaminen johtaa jopa 2,04%:n ja 1,74%:n lisäykseen täsmälleen osumassa ja F1:ssä. Lopuksi analysoimme siirtoprosessia, selvitämme mallin tekemien muokkausten tyyppejä ja rangaistuksen pituuden vaikutusta siirtomalliin.</abstract_fi>
      <abstract_he>הפשטות טקסט היא תהליך החלק והשינוי משפט לרצף משפטים שמקל יותר לקרוא ולהבין בזמן לשמור על התוכן ולהתקרב את המשמעות המקורית. Text simplification has been exploited in NLP applications like machine translation, summarization, semantic role labeling, and information extraction, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks.  In this work, we investigate the effect of text simplification in the task of question-answering using a comprehension context.  אנחנו משחררים את SQuAD Simple, גרסה פשוטה של קבוצת מידע SQuAD משתמשת רחבה. Firstly, we outline each step in the dataset creation pipeline, including style transfer, thresholding of sentences showing correct transfer, and offset finding for each answer.  שנית, אנו מאשרים את איכות המשפטים המועברים באמצעות שיטות שונות שמעניינות גם הערכה אוטומטית וגם האנושית. שלישית, אנו מצביעים את הקורפוס החדש שנוצר ונבצע מחקר אובלציה לבדיקה את ההשפעה של תהליך ההפשטה במשימת תשובת שאלות בסיס SQuAD. הניסויים שלנו מראים שהפשטות מובילה לגובה של 2.04% ולגבוה של 1.74% במתאם בדיוק ולF1, בהתאם. סוף סוף, אנחנו מסתיימים עם ניתוח של תהליך ההעברה, לחקור את סוגי הערכות שנעשו על ידי המודל, וההשפעה של אורך המשפט על מודל ההעברה.</abstract_he>
      <abstract_ha>Tsarin matsayi na zama jararin ka raba shi kuma ya mayar da gefen zuwa wani matsayi na ƙara matsayi, yana da sauƙin karanta da fahimta a lokacin da ke tsare maɓallin da ke kusanta ma'anar farko. Text simplification has been exploited in NLP applications like machine translation, summarization, semantic role labeling, and information extraction, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks.  Daga wannan aikin, munã ƙidãya mai sauƙin rubutun matsayi a cikin aikin da za'a karɓa wa tambaya da wani muhimman mazaɓa. Munã sakar da Simle-SQuAD, wani version na da aka yi amfani da shi mai yawa na SQuAD. Na farkon, za mu ƙayyade kowace ƙõfõfi cikin tsarin da aka halitta pibeline, tare da transfer salon, mai tunkuɗe shiryoyin ayuka da ke nuna transfer da gaske, kuma an offset gane wa kowace jibar. Na ƙara, Munã gaskata sifar maganar da aka shige a cikin hanyõyi daban-daban da za'a ƙunsa da bincike da mutum. Duna, za mu haƙur da shirin nan da aka halitta kowace kuma mu cika wani karatun na firam dõmin a jarraba ma'anar jarrabar masu sayarwa a cikin tambayar SQuAD-based. TajararinMu ke nũna cewa saurin ta ƙara zuwa 2.04% da 1.74% na ƙara Gani ga Exact Match da F1. Ga ƙarshe, za mu ƙara da Ana yi anadi ga aikin transfer, yana tambaya nau'in editori waɗanda aka samar da shi na motel, da fassaran cire a kan misalin transfer.</abstract_ha>
      <abstract_jv>Simplification FullName Nang lan iki, kéné ujarane efes perusahaan seneng nggawe barang langgambar barang langgambar barang langgambar barang seneng pisan. Two Awak dhéwé, kita mulai saben pas ing dataset nggawe lanjut Sijejer-warni, kéné ngerasai kaliwat kanggo didasar Ndheke, kita buktu nggawe kno perusahaan anyari nggawe lan ijol-ijolan winih kanggo ngilangno sistêm kanggo ngilangno sistêm nggawe barang seneng nggawe Ketoke Where am I Lha wih-wih, awak dhéwé wis dipileh kanggo anaransi perusahaan nggawe nungsak perusahaan anyar neng modèl, lan nganggo perusahaan kanggo nguasai perusahaan nggawe modèl.</abstract_jv>
      <abstract_sk>Poenostavitev besedila je postopek razdelitve in preoblikovanja stavka v zaporedje stavkov, ki olajša branje in razumevanje, hkrati pa ohranja vsebino in približuje izvirni pomen. Poenostavitev besedila je bila izkoriščena v aplikacijah NLP, kot so strojno prevajanje, povzetek, semantično označevanje vlog in pridobivanje informacij, kar je odprlo široko pot za njegovo izkoriščanje pri opravilih, ki temeljijo na razumevanju odgovorov na vprašanja. V tem delu raziskujemo učinek poenostavitve besedila pri nalogi odgovarjanja na vprašanja z uporabo konteksta razumevanja. Izdajamo Simple-SQuAD, poenostavljeno različico široko uporabljenega nabora podatkov SQuAD. Najprej opišemo vsak korak v načrtu ustvarjanja nabora podatkov, vključno s prenosom slogov, mejnim stavkom, ki kažejo pravilen prenos, in odstopanjem iskanja za vsak odgovor. Drugič, kakovost prenesenih kazni preverjamo z različnimi metodologijami, ki vključujejo avtomatizirano in človeško ocenjevanje. Tretjič, primerjamo novo ustvarjeni korpus in opravimo ablacijsko študijo za preučitev učinka postopka poenostavitve v nalogi odgovarjanja na vprašanja, ki temelji na SQuAD. Naši poskusi kažejo, da poenostavitev vodi do 2,04% povečanja točnega ujemanja oziroma do 1,74% povečanja točnega ujemanja oziroma F1. Na koncu smo zaključili z analizo procesa prenosa, preučili vrste urejanj modela in učinek dolžine kazni na model prenosa.</abstract_sk>
      <abstract_bo>ཡི་གེ་སྔོན་འཛུགས་ནི་ཚིག་རྐང་འདི་བཤད་པ་དང་ཚིག་རྟགས་ཀྱི་གོ་རིམ་ལ་བསྐྱར་བཟོ་བྱེད་སྐབས། Text simplification has been exploited in NLP applications like machine translation, summarization, semantic role labeling, and information extraction, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks. ང་ཚོས་ཀྱི་ལས་ཀ་འདིའི་ནང་དུ་རྟོགས་བསམ་བློ་གཏོང་གི་གནོད་འཚོལ་ཞིབ་དཔྱད་པ་ཞིག་གིས་རྟོགས་བསམ་བློ་གཏོང་ག We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset. དང་པོ་མཉམ་དུ། འུ་ཚོས་གྲངས་རེ་རེར་སྒྲིག གཉིས་པ། ང་ཚོས་རང་འགུལ་གྱིས་ཞིབ་དཔྱད་བྱས་པའི་ཚིག་རྟགས་ཀྱི་རང་འགུལ་གྱིས་མིའི་དཔྱད་སྒྲུབ་གྱི་ཐབས་ལམ་མི་འདྲ་བ་དང་མ Thirdly, we benchmark the new corpus and perform an ablation study for examining the effect of the simplification process in the SQuAD-based question answering task. ང་ཚོའི་བརྟག་ཞིག་གིས་གསལ་འཇལ་རིམ་འདི་གསལ་བྱ་ཚིག་དང་ཕྱོགས་གཉིས་བར་མཐུན་འགྲོ་བ་ཡིན། Finally, we conclude with an analysis of the transfer process, investigating the types of edits made by the model, and the effect of sentence length on the transfer model.</abstract_bo>
      </paper>
    <paper id="4">
      <title>Keyphrase Extraction with Incomplete Annotated Training Data</title>
      <author><first>Yanfei</first><last>Lei</last></author>
      <author><first>Chunming</first><last>Hu</last></author>
      <author><first>Guanghui</first><last>Ma</last></author>
      <author><first>Richong</first><last>Zhang</last></author>
      <pages>26–34</pages>
      <abstract>Extracting keyphrases that summarize the main points of a document is a fundamental task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Supervised approaches to keyphrase extraction(KPE) are largely developed based on the assumption that the training data is fully annotated. However, due to the difficulty of keyphrase annotating, KPE models severely suffer from incomplete annotated problem in many scenarios. To this end, we propose a more robust <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training method</a> that learns to mitigate the misguidance brought by unlabeled keyphrases. We introduce negative sampling to adjust training loss, and conduct experiments under different scenarios. Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines. Extensive experiments on five scientific domain datasets of different scales demonstrate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is competitive with the state-of-the-art method.</abstract>
      <url hash="f5db7d3a">2021.wnut-1.4</url>
      <attachment type="Software" hash="429484a1">2021.wnut-1.4.Software.zip</attachment>
      <bibkey>lei-etal-2021-keyphrase</bibkey>
      <doi>10.18653/v1/2021.wnut-1.4</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/kp20k">KP20k</pwcdataset>
    <title_es>Extracción de frases clave con datos de entrenamiento anotados incompletos</title_es>
      <title_fr>Extraction de phrases clés avec données d'apprentissage annotées incomplètes</title_fr>
      <title_ja>不完全な注釈付きトレーニングデータを使用したキーフレーズ抽出</title_ja>
      <title_zh>用不完注训练数取要短语</title_zh>
      <title_ar>استخراج العبارة الرئيسية مع بيانات تدريب مشروحة غير مكتملة</title_ar>
      <title_pt>Extração de frase-chave com dados de treinamento anotados incompletos</title_pt>
      <title_hi>अपूर्ण एनोटेटेड प्रशिक्षण डेटा के साथ Keyphrase निष्कर्षण</title_hi>
      <title_ru>Извлечение ключевых фраз с неполными аннотированными обучающими данными</title_ru>
      <title_ga>Eastóscadh Eochairfhrása le Sonraí Oiliúna Anótáilte Neamhiomlána</title_ga>
      <title_ka>გასაღების ფრაზის ექსტრექცია დასრულებული მონაცემებით</title_ka>
      <title_hu>Kulcsszavak kivonása hiányos jegyzetelt képzési adatokkal</title_hu>
      <title_it>Estrazione di frasi chiave con dati di formazione annotati incompleti</title_it>
      <title_lt>Pagrindinės frazės ekstrahavimas su neišsamiais pažymėtais mokymo duomenimis</title_lt>
      <title_mk>Екстракција на клучната фраза со некомплетни анотирани податоци за обука</title_mk>
      <title_kk>Кілттің сөздерін аяқталмаған оқыту деректерімен тарқату</title_kk>
      <title_ms>Ekstraksi Frasa Kunci dengan Data Latihan Annotasi Tidak Selesai</title_ms>
      <title_el>Εξαγωγή φράσης κλειδιού με ελλιπή σχολιασμένα δεδομένα εκπαίδευσης</title_el>
      <title_mt>Keyphrase Extraction with Incomplete Annotated Training Data</title_mt>
      <title_no>Utpakking av nøkkelfrasar med ikkje fullstendig oppmerkingsdata</title_no>
      <title_mn>Бүтэлгүйтгүй дасгал өгөгдлийн түлхүүр өгүүлбэр</title_mn>
      <title_pl>Ekstrakcja fraz kluczowych z niekompletnymi komentowanymi danymi szkoleniowymi</title_pl>
      <title_ro>Extragerea frazelor cheie cu date de instruire adnotate incomplete</title_ro>
      <title_ml>പൂര്‍ണ്ണമായ പഠിപ്പിക്കാത്ത വിവരങ്ങളുമായി വാക്കുകള്‍ എടുക്കുക</title_ml>
      <title_sr>Ekstrakcija ključne fraze sa nepokolnim notiranim podacima obuke</title_sr>
      <title_ta>முழுமையான பயிற்சி தரவுடன் விசைப்பலகை வெளியேற்றுதல்</title_ta>
      <title_ur>ناکامل ٹرینینگ ڈاٹ کے ساتھ کیفی فریز اخراج</title_ur>
      <title_si>සම්පූර්ණ නිර්ණය කරපු ප්‍රධාන දත්ත සඳහා යතුරු ප්‍රශ්නයක් නිර්මාණය</title_si>
      <title_so>Kalluumeynta ka soo bixinta macluumaadka waxbarashada</title_so>
      <title_sv>Extraktion av nyckelfraser med ofullständiga noterade träningsdata</title_sv>
      <title_vi>Chỉ dẫn thoát bằng đoạn Đào tạo chú thích chưa hoàn tất</title_vi>
      <title_uz>Name</title_uz>
      <title_nl>Uittrekking van sleutelzin met onvolledige geannoteerde trainingsgegevens</title_nl>
      <title_bg>Извличане на ключови фрази с непълни анотирани данни за обучение</title_bg>
      <title_de>Schlüsselwortextraktion mit unvollständigen kommentierten Trainingsdaten</title_de>
      <title_id>Ekstraksi frasa kunci dengan Data Latihan Annotasi Tidak lengkap</title_id>
      <title_ko>훈련 데이터를 완전하게 표시하지 않은 키워드 추출</title_ko>
      <title_sw>Utoa wa maneno na Taarifa zisizo na ujuzi</title_sw>
      <title_tr>Tamamlanmyk Taryh Edilen Maglumaty bilen Kiçi fraz Açmak</title_tr>
      <title_af>Sleutelfrase uitpakking met Onvolledige Opleiding Data</title_af>
      <title_da>Uddrag af nøglesætninger med ufuldstændige noterede træningsdata</title_da>
      <title_hr>Ekstrakcija ključne fraze sa nepokolnim notiranim podacima obuke</title_hr>
      <title_am>የፊደል ቅርጽ ምርጫዎች</title_am>
      <title_sq>Ekstraktimi i frazës kyçe me të dhënat e stërvitjes të papërkryera të anotuara</title_sq>
      <title_hy>Comment</title_hy>
      <title_fa>اخراج کلید با داده‌های آموزش ناکام</title_fa>
      <title_az>TamamlanmńĪŇü t…ôhsil m…ôlumatńĪ il…ô anahtar s√∂zl…ôri √ßńĪxart</title_az>
      <title_bs>Ekstrakcija ključne fraze sa nepokolnim notiranim podacima obuke</title_bs>
      <title_cs>Extrakce klíčové fráze s neúplnými anotovanými tréninkovými daty</title_cs>
      <title_bn>Keyphrase Extraction with Incomplete Annotated Training Data</title_bn>
      <title_ca>Extracció de frases clau amb dades d'entrenament anotats incompletes</title_ca>
      <title_et>Märksõnade ekstraheerimine ebatäielike annoteeritud koolitusandmetega</title_et>
      <title_fi>Avainlausen poisto epätäydellisillä huomautuksilla varustetuilla harjoitustiedoilla</title_fi>
      <title_he>Keyphrase Extraction with Incomplete Annotated Training Data</title_he>
      <title_ha>@ action</title_ha>
      <title_bo>མཇུག་བསྡུས་མེད་པའི་སྙན་སྐད་བརྗོད་ཕྱིར་འདོན་པ</title_bo>
      <title_jv>echoH e l l o space w o r l d periodHelloworldHello worldkey echo</title_jv>
      <title_sk>Izvleček ključnih fraz z nepopolnimi opisani podatki o usposabljanju</title_sk>
      <abstract_es>Extraer frases clave que resuman los puntos principales de un documento es una tarea fundamental en el procesamiento del lenguaje natural. Los enfoques supervisados para la extracción de frases clave (KPE) se desarrollan en gran medida sobre la base de la suposición de que los datos de entrenamiento están completamente anotados. Sin embargo, debido a la dificultad de anotar palabras clave, los modelos KPE sufren graves problemas anotados incompletos en muchos escenarios. Con este fin, proponemos un método de entrenamiento más sólido que aprenda a mitigar la desorientación provocada por las frases clave sin etiqueta. Introducimos el muestreo negativo para ajustar la pérdida de entrenamiento y realizamos experimentos en diferentes escenarios. Los estudios empíricos sobre conjuntos de datos sintéticos y conjuntos de datos de dominio abierto muestran que nuestro modelo es sólido para un problema anotado incompleto y supera las líneas de base anteriores. Experimentos exhaustivos en cinco conjuntos de datos de dominio científico de diferentes escalas demuestran que nuestro modelo es competitivo con el método más avanzado.</abstract_es>
      <abstract_ar>يعد استخراج العبارات الرئيسية التي تلخص النقاط الرئيسية للمستند مهمة أساسية في معالجة اللغة الطبيعية. تم تطوير الأساليب الخاضعة للإشراف لاستخراج عبارة المفاتيح (KPE) إلى حد كبير بناءً على افتراض أن بيانات التدريب مشروحة بالكامل. ومع ذلك ، نظرًا لصعوبة شرح العبارة الرئيسية ، تعاني نماذج KPE بشدة من مشكلة مشروحة غير مكتملة في العديد من السيناريوهات. لتحقيق هذه الغاية ، نقترح طريقة تدريب أكثر قوة تتعلم كيفية التخفيف من الضلال الناجم عن العبارات الرئيسية غير المسماة. نقدم أخذ العينات السلبية لتعديل فقدان التدريب ، وإجراء التجارب في ظل سيناريوهات مختلفة. تُظهر الدراسات التجريبية على مجموعات البيانات التركيبية ومجموعة بيانات المجال المفتوح أن نموذجنا قوي لمشكلة مشروحة غير مكتملة ويتجاوز خطوط الأساس السابقة. تُظهر التجارب المكثفة على خمس مجموعات بيانات للمجال العلمي بمقاييس مختلفة أن نموذجنا قادر على المنافسة مع أحدث الأساليب.</abstract_ar>
      <abstract_ja>文書の要点を要約したキーフレーズを抽出することは、自然言語処理の基本的な作業です。キーフレーズ抽出（ KPE ）に対する監視されたアプローチは、トレーニングデータが完全に注釈付きであるという前提に基づいて主に開発されています。しかし、キーフレーズのアノテーションが困難なため、多くのシナリオでKPEモデルは不完全なアノテーション問題に深刻に苦しんでいます。そのために、ラベル付けされていないキーフレーズがもたらす誤解を軽減するための、より堅牢なトレーニング方法を提案します。トレーニングロスを調整するためにネガティブサンプリングを導入し、さまざまなシナリオで実験を行います。合成データセットおよびオープンドメインデータセットに関する実証研究は、当社のモデルが不完全な注釈付き問題に対して堅牢であり、以前のベースラインを上回っていることを示しています。異なるスケールの5つの科学的ドメインデータセットに関する広範な実験は、当社のモデルが最先端の方法と競合していることを示しています。</abstract_ja>
      <abstract_pt>Extrair frases-chave que resumem os pontos principais de um documento é uma tarefa fundamental no processamento de linguagem natural. Abordagens supervisionadas para extração de frase-chave (KPE) são amplamente desenvolvidas com base na suposição de que os dados de treinamento são totalmente anotados. No entanto, devido à dificuldade de anotação de frase-chave, os modelos KPE sofrem severamente com problemas de anotação incompleta em muitos cenários. Para isso, propomos um método de treinamento mais robusto que aprenda a mitigar os erros de orientação trazidos por frases-chave não rotuladas. Introduzimos amostragem negativa para ajustar a perda de treinamento e conduzimos experimentos em diferentes cenários. Estudos empíricos em conjuntos de dados sintéticos e conjuntos de dados de domínio aberto mostram que nosso modelo é robusto a problemas anotados incompletos e supera as linhas de base anteriores. Extensos experimentos em cinco conjuntos de dados de domínio científico de diferentes escalas demonstram que nosso modelo é competitivo com o método de última geração.</abstract_pt>
      <abstract_fr>L'extraction de phrases clés qui résument les principaux points d'un document est une tâche fondamentale dans le traitement du langage naturel. Les approches supervisées de l'extraction de phrases clés (KPE) sont largement développées sur la base de l'hypothèse que les données de formation sont entièrement annotées. Cependant, en raison de la difficulté d'annoter des phrases clés, les modèles KPE souffrent gravement d'un problème annoté incomplet dans de nombreux scénarios. À cette fin, nous proposons une méthode de formation plus robuste qui apprend à atténuer les erreurs d'orientation provoquées par des phrases clés non étiquetées. Nous introduisons un échantillonnage négatif pour ajuster la perte d'entraînement et menons des expériences dans différents scénarios. Des études empiriques sur des ensembles de données synthétiques et des ensembles de données de domaine ouvert montrent que notre modèle est robuste face aux problèmes annotés incomplets et dépasse les niveaux de référence précédents. Des expériences approfondies sur cinq ensembles de données scientifiques de différentes échelles démontrent que notre modèle est compétitif par rapport à la méthode de pointe.</abstract_fr>
      <abstract_ru>Извлечение ключевых фраз, обобщающих основные моменты документа, является фундаментальной задачей в обработке естественного языка. Контролируемые подходы к извлечению ключевых фраз (KPE) в значительной степени разработаны на основе предположения, что обучающие данные полностью аннотированы. Однако из-за сложности аннотирования ключевых фраз модели KPE сильно страдают от неполной аннотированной проблемы во многих сценариях. С этой целью мы предлагаем более надежный метод обучения, который научится смягчать заблуждение, вызванное немеченными ключевыми фразами. Мы вводим отрицательную выборку для корректировки потерь в обучении и проводим эксперименты по разным сценариям. Эмпирические исследования синтетических наборов данных и наборов данных открытого домена показывают, что наша модель является устойчивой к неполным аннотированным проблемам и превосходит предыдущие базовые линии. Обширные эксперименты на пяти наборах научных данных разного масштаба показывают, что наша модель конкурентоспособна с современным методом.</abstract_ru>
      <abstract_zh>提总文档要短语自然语言治之一务也。 密钥短语取(KPE)监督之法,盖取全注之伪设而发之。 然短语注之难,KPE 形多不全。 为言强训练方法,可学损短语。 引入负抽样调练损失,并于场景下实验之。 合成数集及开放域数之实证明之,臣等模形对不尽注有鲁棒性,且过前基线。 五尺之科学,领域之广实验明,与先进之法有竞争力。</abstract_zh>
      <abstract_ga>Is tasc bunúsach i bpróiseáil nádúrtha teanga é eochairfhrásaí a asbhaint a dhéanann achoimre ar phríomhphointí doiciméad. Forbraítear cineálacha cur chuige maoirsithe maidir le baint eochairfhrása (KPE) den chuid is mó ar an mbonn tuisceana go bhfuil anótáil iomlán ar na sonraí oiliúna. Mar sin féin, mar gheall ar dheacracht anótáil eochairfhrása, bíonn fadhbanna anótáilte neamhiomlána ag samhlacha KPE go mór i go leor cásanna. Chuige sin, molaimid modh oiliúna níos láidre a fhoghlaimíonn chun an mhíthreoir a thagann as eochairfhrásaí neamhlipéadaithe a mhaolú. Tugaimid isteach sampláil diúltach chun caillteanas oiliúna a choigeartú, agus déanaimid turgnaimh faoi chásanna éagsúla. Léiríonn staidéir eimpíreacha ar thacair shonraí shintéiseacha agus ar thacar sonraí fearainn oscailte go bhfuil ár samhail láidir chun fadhb neamhiomlán anótáilte a chomhlánú agus go sáraíonn sé bunlínte roimhe seo. Léiríonn turgnaimh fhairsing ar chúig thacar sonraí fearainn eolaíochta ar scálaí éagsúla go bhfuil ár múnla iomaíoch leis an modh úrscothach.</abstract_ga>
      <abstract_hi>किसी दस्तावेज़ के मुख्य बिंदुओं को संक्षेप में प्रस्तुत करने वाले keyphrases को निकालना प्राकृतिक भाषा प्रसंस्करण में एक मौलिक कार्य है। Keyphrase निष्कर्षण (KPE) के लिए पर्यवेक्षित दृष्टिकोण काफी हद तक इस धारणा के आधार पर विकसित किए जाते हैं कि प्रशिक्षण डेटा पूरी तरह से एनोटेट किया गया है। हालांकि, keyphrase annotating की कठिनाई के कारण, KPE मॉडल गंभीर रूप से कई परिदृश्यों में अपूर्ण एनोटेट समस्या से पीड़ित हैं। इस अंत के लिए, हम एक अधिक मजबूत प्रशिक्षण विधि का प्रस्ताव करते हैं जो बिना लेबल वाले कीफ्रेज़ द्वारा लाए गए गुमराही को कम करना सीखता है। हम प्रशिक्षण हानि को समायोजित करने के लिए नकारात्मक नमूना पेश करते हैं, और विभिन्न परिदृश्यों के तहत प्रयोग करते हैं। सिंथेटिक डेटासेट और खुले डोमेन डेटासेट पर अनुभवजन्य अध्ययनों से पता चलता है कि हमारा मॉडल अपूर्ण एनोटेटेड समस्या के लिए मजबूत है और पूर्व बेसलाइन को पार करता है। विभिन्न पैमानों के पांच वैज्ञानिक डोमेन डेटासेट पर व्यापक प्रयोगों से पता चलता है कि हमारा मॉडल अत्याधुनिक विधि के साथ प्रतिस्पर्धी है।</abstract_hi>
      <abstract_ka>კლავიფრაზების გამოყენება, რომლებიც დოკუმენტის მნიშვნელოვანი წერტილებების გამოყენება, არის ფუნდამენტური რაოდენტი ნახვა ენის პროცესიაში. დანარწმუნებული კლავიფრეზის ექსტრექცია (KPE) უფრო დიდ განვითარებულია, რომელიც შესაძლებელია, რომ განვითარება მონაცემები ყველაფერად მონიშნულია. მაგრამ კლავიფრაზის ამოტვირთვის შესაძლებლობად KPE მოდელები ძალიან ძალიან დარწმუნებული პრობლემადან ბევრი სენარიოში არაფრძელებული პრობლემადან. ჩვენ უფრო ძალიან ძალიან სწავლებელი მეტი, რომელიც სწავლის შეცდომის შეცდომების შეცდომას, რომელიც არაფერილი კლავიფრაზების გამოყენებულია. ჩვენ განვიყენებთ განსაკუთრებული გამოსახულების შესაძლებლობად განვითარება და განსხვავებული სინარიოში ექსპერიმენტები. სინტეტიკური მონაცემების და დიომენის გახსნა მონაცემების კონფიგურაციების შესახებ ჩვენი მოდელი უფრო ძალიან დააკეთებული პრობლემების და წინაღმდე დააკეთებული ფეს ხუთი მეცნიერო დიომენტის მონაცემების განსხვავებული სკალების განსხვავებული ექსპერიმენტები გამოჩვენება, რომ ჩვენი მოდელი კონპექტიურია კონპექტიური მეც</abstract_ka>
      <abstract_hu>A dokumentum főbb pontjait összefoglaló kulcskifejezések kivonása alapvető feladat a természetes nyelvfeldolgozásban. A kulcskifejezések kivonásának (KPE) felügyelt megközelítései nagyrészt azon a feltételezésen alapulnak, hogy a képzési adatok teljes mértékben jegyzetelve vannak. A kulcskifejezések jegyzetelésének nehézsége miatt azonban a KPE modellek számos forgatókönyvben súlyosan szenvednek hiányos jegyzetelési problémáktól. Ennek érdekében erőteljesebb képzési módszert javasolunk, amely megtanulja enyhíteni a címke nélküli kulcskifejezések által okozott félrevezetést. Negatív mintavételt vezetünk be az edzésveszteség beállítására, és különböző forgatókönyvek szerint kísérleteket végezünk. A szintetikus adatkészletek és nyílt domain adatkészletek empirikus tanulmányai azt mutatják, hogy modellünk robusztus a hiányos jegyzetelt problémákra, és meghaladja a korábbi alapköveteket. Öt különböző skálájú tudományos adatkészleten végzett kiterjedt kísérletek bizonyítják, hogy modellünk versenyképes a korszerű módszerrel.</abstract_hu>
      <abstract_el>Η εξαγωγή φράσεων κλειδιά που συνοψίζουν τα κύρια σημεία ενός εγγράφου είναι ένα θεμελιώδες έργο στην επεξεργασία φυσικής γλώσσας. Οι εποπτευόμενες προσεγγίσεις για την εξαγωγή λέξεων-κλειδιών (KPE) αναπτύσσονται σε μεγάλο βαθμό με βάση την υπόθεση ότι τα δεδομένα κατάρτισης είναι πλήρως σχολιασμένα. Ωστόσο, λόγω της δυσκολίας της παρατήρησης λέξεων κλειδιά, τα μοντέλα υποφέρουν σοβαρά από ελλιπές σχολιασμό σε πολλά σενάρια. Για το σκοπό αυτό, προτείνουμε μια πιο ισχυρή μέθοδο εκπαίδευσης που μαθαίνει να μετριάζει την παραπλάνηση που προκαλείται από τις μη επισημάνσεις κλειδιών. Εισάγουμε αρνητική δειγματοληψία για να προσαρμόσουμε την απώλεια κατάρτισης, και διεξάγουμε πειράματα κάτω από διαφορετικά σενάρια. Εμπειριακές μελέτες σε συνθετικά σύνολα δεδομένων και ανοιχτά σύνολα δεδομένων δείχνουν ότι το μοντέλο μας είναι ανθεκτικό στο ελλιπές σχολιασμένο πρόβλημα και ξεπερνά τις προηγούμενες γραμμές βάσης. Εκτεταμένα πειράματα σε πέντε επιστημονικά σύνολα δεδομένων διαφορετικών κλιμάκων αποδεικνύουν ότι το μοντέλο μας είναι ανταγωνιστικό με τη μέθοδο τελευταίας τεχνολογίας.</abstract_el>
      <abstract_it>Estrarre frasi chiave che riassumono i punti principali di un documento è un compito fondamentale nell'elaborazione del linguaggio naturale. Gli approcci supervisionati all'estrazione delle parole chiave (KPE) sono in gran parte sviluppati sulla base del presupposto che i dati di formazione siano completamente annotati. Tuttavia, a causa della difficoltà di annotazione delle frasi chiave, i modelli KPE soffrono gravemente di problemi annotati incompleti in molti scenari. A tal fine, proponiamo un metodo di allenamento più robusto che impara a mitigare la guida sbagliata causata dalle frasi chiave non etichettate. Introduciamo il campionamento negativo per regolare la perdita di allenamento e conduciamo esperimenti in diversi scenari. Studi empirici su set di dati sintetici e set di dati a dominio aperto mostrano che il nostro modello è robusto a problemi annotati incompleti e supera le linee di base precedenti. Esperimenti approfonditi su cinque set di dati scientifici di diverse scale dimostrano che il nostro modello è competitivo con il metodo all'avanguardia.</abstract_it>
      <abstract_lt>Pagrindinių dokumento punktų santrauką apibendrinančių raktų frazių ekstrahavimas yra pagrindinė užduotis natūralios kalbos apdorojimo srityje. Priežiūrėti pagrindinių frazių išgavimo metodai (KPE) iš esmės plėtojami remiantis prielaida, kad mokymo duomenys yra visiškai užrašyti. Tačiau dėl sunkumų anotuoti pagrindines frazes, daugelyje scenarijų KPE modeliai labai kenčia nuo neišsamios anotuotos problemos. Šiuo tikslu siūlome patikimesnį mokymo metodą, kuris išmoktų sušvelninti klaidingas gaires, kurias sukelia nepažymėtos pagrindinės frazės. Įvedame neigiamą mėginių ėmimą mokymo praradimui koreguoti ir įvairiais scenarijais atliekame eksperimentus. Empiriniai sintetinių duomenų rinkinių ir atviro domeno duomenų rinkinio tyrimai rodo, kad mūsų model is yra tvirtas, kad užpildyta neišsami anotuota problema ir viršija ankstesnes bazines linijas. Extensive experiments on five scientific domain datasets of different scales demonstrate that our model is competitive with the state-of-the-art method.</abstract_lt>
      <abstract_kk>Құжаттың негізгі нүктелерін таңдайтын перне сөздерді тарқату - табиғи тіл процессінде негізгі тапсырма. Кілттерді тарқату (KPE) дегенге бақылау арқылы көпшілікті көпшілікті оқыту деректерінің толық мәліметті белгілеп тұрады. Бірақ, перне сөздерді анықтау қиындығында KPE үлгілері көпшілікті сценарияларда толық мәселелерден өтеді. Бұл үшін біз көп оқыту әдісін ұстап береміз. Кілттер сөздерінің жарамсыз бағыттауын көшірмелеу үшін үйренеміз. Біз тәжірибенің жоғалуын түзету үшін негативті мәліметтерді таңдап, әртүрлі сценариялар бойынша тәжірибелерді жасаймыз. Синтетикалық деректер қорлары және доменге ашылған деректер қорларының империялық зерттеулері біздің үлгіміздің толық мәселелері және алдыңғы негізгі жолдардың үстінен өткізілмегенін Бес ғылым доменның деректер қорларының кеңейтілген тәжірибелері, біздің үлгіміз өзгерту әдісімен әртүрлі деп көрсетеді.</abstract_kk>
      <abstract_ml>ഒരു രേഖയുടെ പ്രധാന പോയിന്റുകള്‍ ചുരുക്കിക്കൊടുക്കുന്ന വാക്കുകള്‍ പുറത്തെടുക്കുന്നത് സ്വാഭാവിക ഭാഷയുട ട്രെയിനിങ്ങളുടെ വിവരങ്ങള്‍ പൂര്‍ണ്ണമായും വിഷമമാക്കുന്നുവെന്ന് കരുതിയിരിക്കുന്നു. എന്നിട്ടും കീവോര്‍ട്ട്രെയിസിന്റെ പ്രശ്നത്തിന്റെ കാരണം കെപിഇ മോഡലുകള്‍ പൂര്‍ണ്ണമായ പ്രശ്നങ്ങളില്‍ നിന്നും കഠിനമായി  ഈ അവസാനത്തിനു വേണ്ടി നമ്മള്‍ ഒരു കൂടുതല്‍ റോബോസ്റ്റ് ട്രെയിനിങ്ങളുടെ രീതിയില്‍ പഠിക്കുന്നു. അടയാളപ്പെടാത്ത കീ പരിശീലനഷ്ടത്തിന്റെ പരീക്ഷണം മാറ്റുവാനും വ്യത്യസ്ത പരീക്ഷണങ്ങളില്‍ പരീക്ഷിക്കാനും നമുക്ക് നേരിട്ട ട സിന്തിറ്റിക്ക് ഡാറ്റാസറ്റുകളെയും തുറന്ന ഡൊമെയിന്‍ ഡാറ്റാസറ്റുകളെയും എമിരിക്കല്‍ പഠിപ്പിക്കുന്നത് നമ്മുടെ മോഡല്‍ പൂ അഞ്ചു ശാസ്ത്ര ജോമെന്‍ ഡേറ്റാസെറ്റുകളില്‍ വ്യത്യസ്ത ത തൂക്കങ്ങളുടെ വിശേഷ പരീക്ഷണങ്ങള്‍ വ്യക്തമായി കാണിക്കുന്നു നമ്മുടെ</abstract_ml>
      <abstract_mk>Extracting keyphrases that summarize the main points of a document is a fundamental task in natural language processing.  Supervised approaches to keyphrase extraction(KPE) are largely developed based on the assumption that the training data is fully annotated.  Сепак, поради тешкотијата во анотирањето на клучната фраза, моделите на КПЕ сериозно страдаат од нецелосен анотиран проблем во многу сценарија. За оваа цел, предложуваме посилен метод на обука кој ќе научи да го намали погрешното насочување донесено од неозначени клучни фрази. Ние воведуваме негативно примероци за прилагодување на загубата на обуката, и спроведуваме експерименти под различни сценарија. Импирските студии на синтетичките податоци и отворените податоци на домените покажуваат дека нашиот модел е силен за нецелосен анотиран проблем и ги надминува претходните бази линии. Експериментите на пет научни податоци од различни скали покажуваат дека нашиот модел е конкурентен со најсовремениот метод.</abstract_mk>
      <abstract_mn>Документын гол цэгүүдийг нэмэгдүүлэх түлхүүр үг бол байгалийн хэл процессийн үндсэн үйл ажиллагаа. Үндсэн үгийг хадгалах (KPE) гэх мэт удирдлагатай аргыг ихэвчлэн хөгжүүлдэг бөгөөд сургалтын өгөгдлийн бүрэн сэтгэл хөдлөл байдаг. Гэхдээ түлхүүр өгүүлбэрийн хэцүү хэцүү болохоор KPE загварууд олон хувилбаруудад бүтэлгүйтгэгдсэн асуудлыг хүндрэлтэй болгодог. Үүний тулд бид илүү хүчтэй суралцах арга зам зааж өгдөг. Бид дасгал хөдөлгөөн алдагдахын тулд сөрөг жишээг тайлбарлаж, өөр төрлийн хувилбаруудын дотор туршилтыг хийдэг. Синтетик өгөгдлийн сан болон нээлттэй холбоотой өгөгдлийн сангийн үндсэн судалгаанууд бидний загвар нь бүтэлгүйтгэгдсэн асуудал болон өмнө нь суурь шулуунуудыг дамжуулдаг гэдгийг харуулдаг. Таван шинжлэх ухааны өгөгдлийн хэмжээний өргөн туршилтууд бидний загвар нь урлагийн хувьд өрсөлдөг гэдгийг харуулдаг.</abstract_mn>
      <abstract_no>Pakk ut nøkkelfrasar som samanserer hovudpunktane i eit dokument er ein grunnleggjande oppgåve i naturspråkshandsaming. Overvakte tilnærmingar til utpakking av nøkkelfrasar (KPE) er stort utvikla basert på assumpsjonen at opplæringsdata er fullstendig merking. Men på grunn av vanskeligheten til nøkkelfrasen, er KPE-modeller vanskeleg i mange scenarioar i ikkje fullstendig oppmerking av problem. I denne slutten foreslår vi ein meir robust treningsmetode som lærer å minne feilrettinga som blir henta av ikkje-merkte nøkkelfrasar. Vi introduserer negativ prøveprøver for å justera tapt på øvinga og gjera eksperimenter under ulike scenarior. Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines. Ekstra eksperimenter på fem vitenskapelige domenedataset med ulike skalar viser at modellen vårt er konkurrentivt med kunstmetoden.</abstract_no>
      <abstract_pl>Wyodrębnianie fraz kluczowych, które podsumowują główne punkty dokumentu jest podstawowym zadaniem w przetwarzaniu języka naturalnego. Nadzorowane podejścia do ekstrakcji fraz kluczowych (KPE) są w dużej mierze opracowywane w oparciu o założenie, że dane treningowe są w pełni adnotacjonowane. Jednak ze względu na trudności z adnotacją fraz kluczowych, modele KPE poważnie cierpią na niekompletny problem adnotacji w wielu scenariuszach. W tym celu proponujemy bardziej solidną metodę szkoleniową, która uczy się łagodzić błędne wskazówki wynikające z nieoznakowanych fraz kluczowych. Wprowadzamy negatywne próbkowanie w celu dostosowania strat treningowych i przeprowadzamy eksperymenty w różnych scenariuszach. Badania empiryczne dotyczące syntetycznych zbiorów danych i zbiorów danych otwartych pokazują, że nasz model jest solidny do niekompletnych adnotacji problemów i przewyższa poprzednie linie bazowe. Obszerne eksperymenty na pięciu zestawach danych domen naukowych o różnych skalach pokazują, że nasz model jest konkurencyjny z najnowocześniejszą metodą.</abstract_pl>
      <abstract_ro>Extragerea frazelor cheie care rezumă principalele puncte ale unui document este o sarcină fundamentală în procesarea limbajului natural. Abordările supravegheate pentru extragerea frazelor cheie (KPE) sunt dezvoltate în mare măsură pe baza presupunerii că datele de formare sunt complet adnotate. Cu toate acestea, datorită dificultății adnotării frazelor cheie, modelele KPE suferă grav de probleme adnotate incomplete în multe scenarii. În acest scop, propunem o metodă de formare mai robustă, care învață să atenueze ghidarea greșită adusă de frazele cheie fără etichete. Introducem eșantionarea negativă pentru a ajusta pierderile de antrenament și efectuăm experimente în diferite scenarii. Studiile empirice privind seturile de date sintetice și seturile de date deschise arată că modelul nostru este robust la problemele adnotate incomplete și depășește liniile de referință anterioare. Experimente extinse pe cinci seturi de date științifice de diferite scale demonstrează că modelul nostru este competitiv cu metoda de ultimă generație.</abstract_ro>
      <abstract_si>දස්තාවෙන් ප්‍රධාන පින්දුවන් ප්‍රධාන පින්දුවන් ප්‍රධාන ක්‍රියාවක් ස්වභාවික භාෂාව ප්‍රකාර නිරීක්ෂණය විදිහට යතුරු ප්‍රශ්නය (KPE) ප්‍රශ්නයක් ප්‍රශ්නයක් නිර්මාණය කරලා තියෙන්නේ ප්‍රශ්නය දත්ත සම්ප නමුත්, යතුරු ප්‍රශ්නයක් ප්‍රශ්නයක් නිර්දේශනය කරනවා නිසා, KPE මොඩේල් ගොඩක් අමුල් ප්‍රශ්නයක් ගොඩක් සිනාරිය මේ අවසානයෙන්, අපි ප්‍රශ්නයක් කරනවා තව ප්‍රශ්නයක් ඉගෙන ගන්න පුළුවන් විධානයක් ඉගෙන ගන්න පුළුවන් විදි අපි ප්‍රශ්නයක් නැති වෙනුවෙන් නිර්මාණය කරගන්න අනුක්‍රිය සැම්ප්ලීම් කරනවා, වගේම වෙනස් සිනාරිය සංවිධානය දත්ත සැටි සහ විවෘත දත්ත සැට් සඳහා සංවිධානය ප්‍රශ්නයක් පෙන්වන්න පුළුවන් කියලා අපේ මොඩේල් අවසාන විවිධ විද්‍යාත්මක දත්ත සේට් පහයේ විශේෂ පරීක්ෂණ පරීක්ෂණ ප්‍රශ්නයක් පෙන්වන්නේ අපේ මොඩේල් එක ප්‍රශ්</abstract_si>
      <abstract_sr>Izvlačenje ključnih fraza koje sažetaju glavne tačke dokumenta je osnovni zadatak u procesu prirodnog jezika. Nadzorni pristupi ekstrakciji ključne fraze (KPE) se u velikoj mjeri razvijaju na osnovu pretpostavke da su podaci obuke potpuno annotirani. Međutim, zbog teškoće izjave ključne fraze, modeli KPE teško pate od nepotpunog annotiranog problema u mnogim scenarijama. Za taj cilj predlažemo robniji metod obuke koji nauèi da smanjuje pogrešno uputstvo koje donose nepoznate ključne fraze. Predstavljamo negativne uzorke kako bi prilagodili gubitak treninga i proveli eksperimente pod različitim scenarijama. Impiričke studije o sintetičkim setima podataka i otvorenim setima podataka domena pokazuju da je naš model jak do nepotpunog annotiranog problema i prelazi pre početnih linija. Eksperimenti na pet znanstvenih domena podataka različitih skala pokazuju da je naš model konkurentan sa metodom umetnosti.</abstract_sr>
      <abstract_mt>L-estrazzjoni ta’ frażijiet ewlenin li jiġbru fil-qosor il-punti ewlenin ta’ dokument hija kompitu fundamentali fl-ipproċessar tal-lingwi naturali. L-approċċi sorveljati għall-estrazzjoni tal-frażi ewlenija (KPE) huma żviluppati fil-biċċa l-kbira abbażi tas-suppożizzjoni li d-dejta tat-taħriġ hija annotata kompletament. However, due to the difficulty of keyphrase annotating, KPE models severely suffer from incomplete annotated problem in many scenarios.  Għal dan il-għan, qed nipproponu metodu ta’ taħriġ aktar robust li jitgħallem biex jittaffa l-gwida żbaljata li ġġib magħha frażijiet ewlenin mhux immarkati. Aħna nintroduċu teħid ta’ kampjuni negattiv biex naġġustaw it-telf tat-taħriġ, u nagħmlu esperimenti taħt xenarji differenti. Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines.  Esperimenti estensivi fuq ħames settijiet ta’ dejta f’oqsma xjentifiċi ta’ skali differenti juru li l-mudell tagħna huwa kompetittiv mal-metodu l-aktar avvanzat.</abstract_mt>
      <abstract_ms>Mengekstrak frasa kunci yang mengurangkan titik utama dokumen adalah tugas asas dalam pemprosesan bahasa alami. pendekatan yang diawasi untuk ekstraksi frasa kunci (KPE) kebanyakan dikembangkan berdasarkan asumsi bahawa data latihan telah dicatat sepenuhnya. Namun, disebabkan kesulitan untuk anotasi frasa kunci, model KPE menderita berat dari masalah anotasi tidak lengkap dalam banyak skenario. Untuk tujuan ini, kami cadangkan kaedah latihan yang lebih kuat yang belajar untuk mengurangi petunjuk salah yang dibawa oleh frasa kunci tanpa label. Kami memperkenalkan sampel negatif untuk menyesuaikan kehilangan latihan, dan melakukan eksperimen di bawah skenario yang berbeza. kajian empirik pada set data sintetik dan set data domain terbuka menunjukkan bahawa model kita kuat untuk masalah yang tidak lengkap yang dicatat dan melebihi garis dasar terdahulu. Eksperimen luas pada lima set data domain saintifik skala yang berbeza menunjukkan bahawa model kita bersaing dengan kaedah terbaik.</abstract_ms>
      <abstract_so>Extracting keyphrases that summarize the main points of a document is a fundamental task in natural language processing.  Dhaqdhaqaalaha la ilaaliyo soo bixinta kaliyada (KPE) waxaa loo horumariyey sida loo malaynayo in macluumaadka waxbarashadu ay si buuxda u dhibaataysan. Si kastaba ha ahaatee dhibaatooyin ay ku jirto dhibaatooyin ay ku dhibaatayso afka kaliyada ah, tusaalayaasha KPE waxay si adag ugu xanuunsadaan dhibaatooyin aan dhamaanin oo aad u dhibaataysan. Taas darteed waxaynu soo jeedaynaa qaab ka badan waxbarasho khatarta ah oo baranaya in la koobi karo khaladda la'aanta oo la soo keenay erayo aan la qorin. Tusaale negativ ah waxaan sameynaa si aan u beddelno khasaarada waxbarashada, waxaana sameynaa imtixaamo kala duduwan. Waxbarashada jimicsiga ah oo ku saabsan kooxda macluumaadka la xiriira iyo sawirada furan ee domain waxay muujiyaan in modelkayagu uu u isticmaalaa dhibaatada aan dhamaan karin iyo in uu horay u sii dhaafo saldhigyada hore. Imtixaano dheeraad ah oo shan saynuunka macluumaad oo kala duduwan ku yaala waxay muujiyaan in modellkayagu ay ku saabsan qaababka farshaxanka.</abstract_so>
      <abstract_ur>کلی فریزز کو اٹھا لیا جاتا ہے جو ایک دفتر کی اصلی پوینٹوں کو ذخیره کرتی ہے، یہ طبیعی زبان پرینس میں ایک بنیادی کام ہے۔ کلیف فریز اضافہ (KPE) کے زیادہ مطابق مطابق اضافہ ہونے کی تقریبا بہت زیادہ تولید کی جاتی ہے کہ ترینسی ڈیٹا پورے طور پر اضافہ کی جاتی ہے۔ However, due to the difficulty of keyphrase annotating, KPE models severely suffer from incomplete annotated problem in many scenarios. اس کے لئے ہم ایک مضبوط تربیت طریقہ پیش کرتے ہیں جو سکھاتا ہے کہ بغیر معلوم کلیفوں کے ذریعہ بہکا ہوا گمراہی کو کمزور کرے۔ ہم تدریس خسارہ کے ساتھ منفی نمونے کو معلوم کرتے ہیں اور مختلف سناریوں کے اندر آزمائش کرتے ہیں۔ سینٹیسیک ڈاٹسٹ اور ڈومین ڈاٹسٹ کے بارے میں عمومی تحقیقات دکھاتے ہیں کہ ہمارا موڈل بے پوری مشکل کے لئے مضبوط ہے اور پہلے بیس لین سے زیادہ اضافہ ہوتا ہے۔ پانچ سائنس ڈومین ڈیٹ سٹ کے پھیرے ہوئے آزمائش دکھاتے ہیں کہ ہمارا مدل آهنت کی روش سے مساوی ہے</abstract_ur>
      <abstract_ta>ஆவணத்தின் முதன்மையான புள்ளிகளை சுருக்கும் விசைகளை வெளியேற்றுவது இயற்கையான மொழி செயல்பாட்டில் ஒரு அடிப்படை பயிற்சி தகவல் முழுவதும் குறிப்பிடப்பட்டுள்ளது என்று எண்ணிக்கையில் பெரும்பாலாக தேர்ந்தெடுக்கப்பட்டுள்ளது. ஆயினும், விசைசொற்றொடர் குறிப்பிடும் கடினமான காரணத்தால், KPE மாதிரிகள் முழுமையான குறிப்பிட்ட பிரச்சனைகளில் இருந் இந்த முடிவிற்கு, நாம் ஒரு மேலும் ரோப்டாஸ் பயிற்சி முறைமையை கற்றுக் கொள்ளுகிறோம் என்று குறிப்பிடாத விசைகள் க நாம் எதிர்மறை மாதிரி பயிற்சி இழப்பை சரிபார்க்க, மற்றும் வேறு பார்வைகளின் கீழ் சோதனைகளை செய்யும். கூட்டிணைப்பு தரவுத்தளங்கள் மற்றும் திறந்த டோமைன் தரவுத்தளத்தில் வெறுமையான ஆய்வு ஐந்து அறிவியல் களத்தின் தகவல் அமைப்புகளின் விரிவான பரிசோதனைகள் வெவ்வேறு அளவுகளில் உள்ளன என்று காண்பிக்கிறது நமது மாதிரி மாதிரி</abstract_ta>
      <abstract_sv>Att extrahera nyckelfraser som sammanfattar huvudpunkterna i ett dokument är en grundläggande uppgift i naturlig språkbehandling. Övervakade metoder för nyckelfrasutvinning (KPE) utvecklas till stor del utifrån antagandet att utbildningsdata är fullt kommenterade. På grund av svårigheten med att kommentera nyckelfraser lider KPE-modeller allvarligt av ofullständiga kommenterade problem i många scenarier. För detta ändamål föreslår vi en mer robust träningsmetod som lär sig att mildra den felaktiga vägledning som orsakas av omärkta nyckelfraser. Vi introducerar negativ provtagning för att justera träningsförlusten och genomför experiment under olika scenarier. Empiriska studier av syntetiska dataset och open domain dataset visar att vår modell är robust till ofullständiga kommenterade problem och överträffar tidigare baslinjer. Omfattande experiment på fem vetenskapliga domändatauppsättningar av olika skalor visar att vår modell är konkurrenskraftig med den senaste metoden.</abstract_sv>
      <abstract_uz>Name @ info Lekin, tugmalar birikmasini tahrirlash muvaffaqiyatsiz sababi, KPE modellari ko'pchilik aniqlangan muammolarga juda katta ishlatiladi. Shuning uchun biz notoʻgʻri maxsus soʻzlarni kamaytirishni o'rganadigan ko'proq foydalanish usulini o'rganamiz. Biz ta'lim taplarini o'zgartirish uchun negativ misollarni ko'rib chiqaramiz va boshqa tashkilotlarda tajriba qilamiz. Name besh ilmiy domen maʼlumotlar tarkibida kengaytirilgan tajribalar boshqa shakllar tarkibini ko'rsatadi. Bu modelimizning davlat usuli bilan rivojlanishimiz mumkin.</abstract_uz>
      <abstract_vi>Việc rút những cụm từ chính tổng hợp các điểm chính của một tài liệu là một nhiệm vụ cơ bản trong việc xử lý ngôn ngữ tự nhiên. Các phương pháp giám sát để khai thác các cụm từ khóa (KPE) được phát triển rộng rãi dựa trên giả thuyết rằng dữ liệu đào tạo được ghi chú đầy đủ. Tuy nhiên, vì khó khăn để ghi chú các cụm từ chính tả, các mô- đun KPEK bị hư hại nặng trong nhiều kịch bản. Chúng tôi đề xuất một phương pháp huấn luyện mạnh mẽ hơn để học cách giảm thiểu sự hướng dẫn sai lầm do các cụm từ không được nhắc. Chúng tôi đưa ra các mẫu âm tính để điều chỉnh sự mất tập luyện, và thực hiện các thí nghiệm theo các kịch bản khác nhau. Các nghiên cứu quét từ các dữ liệu tổng hợp và bộ dữ liệu miền mở cho thấy rằng mẫu của chúng ta vững chắc đến vấn đề ghi chú chưa đầy đủ và vượt qua các bản mẫu trước. Những thí nghiệm đầy đủ trên năm tập đoàn dữ liệu khoa học với cán cân khác nhau chứng minh rằng mô hình của chúng ta cạnh tranh với phương pháp hiện đại.</abstract_vi>
      <abstract_da>Udtrækning af nøglesætninger, der opsummerer hovedpunkterne i et dokument, er en grundlæggende opgave i naturlig sprogbehandling. Overvågede tilgange til nøglesætningsudtrækning (KPE) er stort set udviklet ud fra den antagelse, at træningsdataene er fuldt kommenteret. På grund af vanskeligheden ved at kommentere nøglesætninger lider KPE-modeller imidlertid alvorligt af ufuldstændige kommenterede problem i mange scenarier. Til dette formål foreslår vi en mere robust træningsmetode, der lærer at afhjælpe den fejlvejledning, som ikke-mærkede nøglesætninger medfører. Vi introducerer negativ prøveudtagning for at justere træningstab, og udfører eksperimenter under forskellige scenarier. Empiriske undersøgelser af syntetiske datasæt og open domain datasæt viser, at vores model er robust til ufuldstændige kommenterede problem og overgår tidligere basislinjer. Omfattende eksperimenter på fem videnskabelige domænedatasæt af forskellige skalaer viser, at vores model er konkurrencedygtig med den nyeste metode.</abstract_da>
      <abstract_nl>Het extraheren van sleutelzinnen die de belangrijkste punten van een document samenvatten is een fundamentele taak in de verwerking van natuurlijke taal. Toegevoegde benaderingen voor keyfrase extractie (KPE) worden grotendeels ontwikkeld op basis van de veronderstelling dat de trainingsgegevens volledig geannoteerd zijn. Vanwege de moeilijkheid van het annoteren van sleutelzinnen hebben KPE-modellen echter in veel scenario's ernstige last van onvolledige annoteren. Daartoe stellen we een robuustere trainingsmethode voor die leert de misleiding van niet-gelabelde sleutelzinnen te beperken. We introduceren negatieve sampling om trainingsverlies aan te passen, en voeren experimenten uit onder verschillende scenario's. Empirische studies naar synthetische datasets en open domein dataset tonen aan dat ons model robuust is tot onvolledig geannoteerd probleem en eerdere baselines overtreft. Uitgebreide experimenten op vijf wetenschappelijke domeindatasets van verschillende schalen tonen aan dat ons model concurrerend is met de state-of-the-art methode.</abstract_nl>
      <abstract_hr>Izvlačenje ključnih fraza koji sažetaju glavne točke dokumenta je temeljni zadatak u procesu prirodnog jezika. Nadzoreni pristupi ekstrakciji ključne fraze (KPE) se u velikoj mjeri razvijaju na temelju pretpostavke da su podaci obuke potpuno annotirani. Međutim, zbog teškoće označavanja ključnih fraza, modeli KPE teško pate od nepotpunog annotiranog problema u mnogim scenarijama. Za taj cilj predlažemo robniji metod obuke koji nauči smanjiti pogrešno uputstvo koje su donijele nepoznate ključne rečenice. Predstavljamo negativan uzorak kako bi se prilagodili gubitak treninga i provodili eksperimenti pod različitim scenarijama. Empirička ispitivanja o sintetičkim podacima i otvorenim podacima domena pokazuju da je naš model jačan na nepotpuni annotirani problem i prelazi prije početnih linija. Prošireni eksperimenti na pet znanstvenih domena podataka različitih skala pokazuju da je naš model konkurentan s metodom umjetnosti.</abstract_hr>
      <abstract_de>Das Extrahieren von Schlüsselphrasen, die die wichtigsten Punkte eines Dokuments zusammenfassen, ist eine grundlegende Aufgabe in der Verarbeitung natürlicher Sprache. Überwachte Ansätze zur Keyphrasenextraktion (KPE) basieren weitgehend auf der Annahme, dass die Trainingsdaten vollständig annotiert sind. Aufgrund der Schwierigkeit der Keyphrase-Annotation leiden KPE-Modelle jedoch in vielen Szenarien stark unter unvollständigen annotaierten Problemen. Zu diesem Zweck schlagen wir eine robustere Trainingsmethode vor, die lernt, die Fehlführung durch nicht beschriftete Keyphrasen zu mildern. Wir führen negative Stichproben ein, um Trainingsverluste anzupassen, und führen Experimente unter verschiedenen Szenarien durch. Empirische Studien zu synthetischen Datensätzen und Open-Domain-Datensätzen zeigen, dass unser Modell robust gegenüber unvollständigen annotierten Problemen ist und frühere Baselines übertrifft. Umfangreiche Experimente an fünf wissenschaftlichen Domänendatensätzen unterschiedlicher Skalen zeigen, dass unser Modell mit der State-of-the-Art-Methode konkurrenzfähig ist.</abstract_de>
      <abstract_ko>문서의 요점을 요약하는 관건적인 단어를 추출하는 것은 자연 언어 처리의 기본적인 임무이다.감독이 있는 관건적인 단어 추출(KPE) 방법은 어느 정도에 훈련 데이터에 대해 완전한 주석을 달았다는 가설을 바탕으로 발전되었다.그러나 KPE 모델은 주요 구문 주석의 어려움으로 인해 주석이 불완전한 경우가 많습니다.이를 위해 우리는 관건적인 단어가 표시되지 않은 오도를 줄이는 방법을 배울 수 있는 보다 건전한 훈련 방법을 제시했다.우리는 마이너스 샘플링을 도입하여 훈련 손실을 조정하고 서로 다른 장면에서 실험을 진행한다.합성 데이터 집합과 개방역 데이터 집합에 대한 실증 연구에 의하면 우리의 모델은 불완전한 표기 문제에 대해 노봉성을 가지고 이전의 기선보다 우수하다는 것을 알 수 있다.다섯 개의 서로 다른 규모의 과학 분야 데이터 집합에서 진행된 대량의 실험은 우리의 모델과 가장 선진적인 방법이 경쟁력을 가지고 있음을 나타냈다.</abstract_ko>
      <abstract_bg>Извличането на ключови фрази, които обобщават основните точки на документа, е основна задача в обработката на естествения език. Наблюдаваните подходи за извличане на ключови фрази (КПЕ) до голяма степен се разработват въз основа на предположението, че данните от обучението са напълно анотирани. Въпреки това, поради трудността при анотирането на ключови фрази, моделите страдат сериозно от непълни анотирани проблеми в много сценарии. За тази цел предлагаме по-здрав метод на обучение, който да се научи да смекчава заблуждаването, причинено от незабелязаните ключови фрази. Въвеждаме отрицателни проби за коригиране на загубите от обучение и провеждаме експерименти при различни сценарии. Емпирични проучвания на синтетични набори от данни и открити домейни показват, че нашият модел е здрав до непълн анотиран проблем и надминава предишните базови линии. Обширни експерименти върху пет научни домейни от различни мащаби показват, че нашият модел е конкурентен на най-съвременния метод.</abstract_bg>
      <abstract_sw>Extracting keyphrases that summarize the main points of a document is a fundamental task in natural language processing.  Matokeo makubwa ya uteuzi wa maneno (KPE) yanaendelea kwa kiasi kikubwa na dhana kwamba taarifa za mafunzo zimekuwa za kuchanganyikiwa kabisa. Hata hivyo, kwa sababu ya matatizo ya neno la ufundi yanakera, mifano ya KPE yanakabiliwa vibaya kutokana na tatizo lisilo kamili katika mitazamo mengi. Kwa mwisho huu, tunapendekeza mbinu zaidi ya mafunzo ya kibaguzi ambayo inajifunza kupunguza upotofu uliotolewa na maneno yasiyoeleweka. Tunaonyesha sampuli hasi ya kuboresha hasi ya mafunzo, na kufanya majaribio chini ya hali mbalimbali. Tafiti za kipekee kuhusu seti za taarifa za pamoja na seti za wazi za domain zinaonyesha kuwa model yetu imelazimika kuingia tatizo lisilo la kutisha na kupitia mistari ya awali. Majaribio mengi kwenye seti za takwimu za kisayansi za ndani tano zinaonyesha kuwa mtindo wetu una ushindani wa namna ya sanaa.</abstract_sw>
      <abstract_id>Mengekstrak frasa kunci yang mengungkapkan titik utama dokumen adalah tugas dasar dalam proses bahasa alami. pendekatan yang diawasi untuk ekstraksi frasa kunci (KPE) kebanyakan dikembangkan berdasarkan asumsi bahwa data latihan sepenuhnya dicatat. Namun, karena kesulitan untuk anotasi frasa kunci, model KPE sangat menderita dari masalah yang tidak lengkap anotasi dalam banyak skenario. Untuk tujuan ini, kami mengusulkan metode latihan yang lebih kuat yang belajar untuk mengurangi kesalahan yang dibawa oleh frasa kunci yang tidak ditandai. Kami memperkenalkan sampel negatif untuk menyesuaikan kehilangan pelatihan, dan melakukan eksperimen di bawah skenario yang berbeda. Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines.  Eksperimen luas pada lima set data domain ilmiah skala berbeda menunjukkan bahwa model kita kompetitif dengan metode terbaik.</abstract_id>
      <abstract_fa>اخراج کردن جمله‌های کلید که نقطه‌های اصلی یک سند را جمع می‌کند یک کار بنیادی در پرداخت زبان طبیعی است. نزدیک‌های مراقبت به اخراج کلید (KPE) بسیار زیادی بر اساس فرض که داده‌های آموزشی کاملاً اخراج می‌شود، توسعه می‌کنند. با این حال، به دلیل مشکل کلید عبارت کردن، مدل KPE از مشکل ناکام در بسیاری از سناریوها رنج می‌برد. برای این قسمت، ما یک روش آموزش قوی تر پیشنهاد می کنیم که یاد می گیرد که هدایت اشتباهی که توسط عبارت کلید غیرقابل نوشته شده را کاهش دهد. ما نمونه‌های منفی را معرفی می‌کنیم تا خسارت آموزش را تغییر دهیم و آزمایش‌های مختلف را تحت صحنه‌های مختلف انجام دهیم. مطالعه‌های امپراتیک در مجموعه‌های داده‌های سناتیک و مجموعه‌های داده‌های دامنی باز نشان می‌دهند که مدل ما به مشکل ناکام مشخص شده و پیش از خط‌های پایین‌گذاری می‌کند قوی است. آزمایش های گسترده روی پنج مجموعه داده های علمی از مقیاس های مختلف نشان می دهند که مدل ما با روش وضعیت هنر مسابقه است.</abstract_fa>
      <abstract_tr>Senediň esasy noktalaryny bellenen a çylmak tebigy dil işleminde esasy zadyr. Ewezam Maglumaty Açmak üçin gözlenen golaýlary (KPE) gaty bir şekilde üýtgedýär. Açmak maglumaty doly gaýtgedýändir diýip pikir edýän. Ýöne KPE nusgalarynyň görkezilişi kynçylykdan dolanýan kynçylykdan üçin KPE nusgalarynyň köpüri senarylarda hiç hili bolmadykdan soňra çykýar. Bu sebäpden, biz esasy bolmadyk kelläpler tarapyndan ýalňyşlygyny azaltmak üçin öwreneniň has güýçli bir eğitim yöntemi teklip edýäris. Biz okuwçylygy ýitirmek üçin negatif näme öränini tanyşdyrýarys we farklı senarylaryň altynda deneyler çykýarys. Sintetik veri setirlerinde empirik araştırmalar ve açyk domena veri setirlerinde modelimiz boşaltmadyk mesele ve öňki baz setirlerinde geçmek üçin güçlü olduğunu gösteriyor. Beş bilim sistemasynda dürli ölçeklerde döwletli deneyler, modelimiz sanat yöntemi bilen döwletlidir.</abstract_tr>
      <abstract_am>የሰነድ አቅራቢያ ቦታዎችን ማሳየት የቁልፎች ቃላት ለማውጣት የፍጥረት ቋንቋ ማቀናጃ ስራ ነው። የክፍለ ቃላት መግለጫ (KPE) የተጠቃሚ ዳራዎችን በሙሉ እንዳስታወቀ በመስመር የተመሳሳይ ነው፡፡ ነገር ግን ከቁልፍ መግለጫ ምክንያት KPE ዓይነቶች በብዙ ስዕይታዎች ውስጥ ያልተጨነቀ መከራ በሙሉ ተጨነቀዋል፡፡ ለዚህ ምክንያት የስሕተት ግንኙነትን ለማቀናቀል የሚማር የስህተት ግንኙነትን ለማቀናቀል እናስባለን፡፡ የግንኙነት መሳሳይ እናሳውቃለን፡፡ የሳንቲካዊ ዳታዎችን እና የዶሜን ዳታ ሳትሰርት የውይይት ምርጫዎች ሞዴሌያችን ለመሙላት ስህተት እና በመጀመሪያው መሳሪያ ላይ ለመስጠት የሚችል ነው፡፡ በአምስት የሳይንቀሳዊ ዶሜን ዳታዎችን በተለያዩ መስኮቶች ላይ የሚጨማሪ ፈተናዎች ሞዴሌያችን በሀገር-የ-አርጤ ሥርዓት ላይ ይዋጋሉ፡፡</abstract_am>
      <abstract_sq>Ekstraktimi i frazave kyçe që përmbledhin pikat kryesore të një dokumenti është një detyrë thelbësore në procesimin natyror të gjuhës. Përqasjet e mbikqyrura për nxjerrjen e frazës kyçe (KPE) janë zhvilluar kryesisht bazuar në supozimin se të dhënat e stërvitjes janë shënuar plotësisht. Megjithatë, për shkak të vështirësisë së anotimit të frazës kyçe, modelet e KPE vuajnë rëndë nga problem të pakompletuar të anotuar në shumë skenarë. Për këtë qëllim, ne propozojmë një metodë më të fortë stërvitjeje që mëson për të lehtësuar gabimin e sjellë nga frazat kyçe pa etiketë. We introduce negative sampling to adjust training loss, and conduct experiments under different scenarios.  Studimet imperiale mbi të dhënat sintetike dhe të dhënat e domainit të hapur tregojnë se modeli ynë është i fortë për të mos kompletuar problemin e anotuar dhe kalon linjat bazë të mëparshme. Eksperimentet e zgjeruara në pesë grupe të dhënash shkencore të shkallëve të ndryshme tregojnë se modeli ynë është konkurrues me metodën më të lartë.</abstract_sq>
      <abstract_hy>Հիմնական արտահայտությունները, որոնք համառոտագրում են փաստաթղթի հիմնական կետերը, բնական լեզվի վերամշակում հիմնական խնդիր են: Հիմնականում ստեղծագործական արտահայտությունների վերահսկվող մոտեցումները զարգանում են հիմնված այն ենթադրության վրա, որ վարժեցման տվյալները ամբողջովին գրված են: Այնուամենայնիվ, հիմնական արտահայտության դժվարության պատճառով, շատ սցենարների ընթացքում ԿՊԵ մոդելները խիստ տառապում են ոչ ամբողջական արտահայտված խնդիրից: Այսպիսով, մենք առաջարկում ենք ավելի ուժեղ ուսումնասիրության մեթոդ, որը սովորում է նվազեցնել բացահայտված հիմնական արտահայտությունների առաջացած սխալ ուղղությունները: Մենք ներկայացնում ենք բացասական նմուշներ ուսումնասիրության կորստի հարմարեցնելու համար և տարբեր սցենարների ընթացքում փորձեր կատարելու համար: Սինտետիկ տվյալների համակարգերի և բաց տիեզերքի տվյալների համակարգի կայսրական ուսումնասիրությունները ցույց են տալիս, որ մեր մոդելը ուժեղ է ոչ ամբողջական նշումնավորված խնդիրների համար և գերազանցում է նախորդ հիմնական գծ Հինգ գիտական ոլորտի տվյալների բազմաթիվ փորձեր ցույց են տալիս, որ մեր մոդելը մրցակցում է ամենաբարձր մեթոդի հետ:</abstract_hy>
      <abstract_af>Uitpak sleutelfrase wat die hoofpunte van 'n dokument opsomming is 'n fundamentele taak in natuurlike taal verwerking. Ondergesien toegang tot sleutelfrase uitpakking( KPE) is groot ontwikkeld gebaseer op die aanvaar dat die onderwerking data is volledig aangekies. Maar, vanweë die moeilikheid van sleutelfrase aanmerking, Kpe modelle swaar lyk van onvolledige aanmerkte probleem in baie scenarios. Op hierdie einde, voorstel ons 'n meer sterkte onderwerking metode wat leer om die verkeerde gids te verminder wat deur onbekende sleutelfrase gebring is. Ons introduseer negatiewe versameling om onderwerp verlies te korrigeer en eksperimente onder verskillende scenarios te doen. Enige studie op sintetiese datastelle en oop domein datastel vertoon dat ons model is kragtig na onvolledige annotateerde probleem en verbygegaan vooraf basisline. Ekstensiewe eksperimente op vyf wetenskaplike domein datastel van verskillende skale bevestig dat ons model is kompetief met die state-of-the-art metode.</abstract_af>
      <abstract_ca>Extraer frases clau que resumen els punts principals d'un document és una tasca fonamental en el processament natural de llenguatges. Els enfocaments supervisats a l'extracció de frases clau (KPE) es desenvolupen en gran part basant-se en la suposició de que les dades d'entrenament estan totalment anotates. Però, a causa de la dificultat d'anotar les frases clau, els models KPE pateixen gravement un problema anotat incomplet en molts escenaris. A aquest efecte, proposem un mètode d'entrenament més robust que aprenga a mitigar l'equivocació produïda per frases clau sense etiqueta. Introduem mostres negatius per ajustar la pèrdua d'entrenament i fer experiments en diferents escenaris. Els estudis empírics sobre conjunts de dades sintètiques i conjunts de dades de dominis oberts mostran que el nostre model és robust a un problema anotat incomplet i supera les línies de base anteriors. Extensive experiments on five scientific domain datasets of different scales demonstrate that our model is competitive with the state-of-the-art method.</abstract_ca>
      <abstract_az>Təbiətli dil işləməsində əsl nöqtələrini qeyd edən anahtar sözləri çıxarılır. Növbəti sözlərin açmağı (KPE) təhsil edilməsi təhsil verilənlərin tamamlanması üçün çox böyük təhsil edilmişdir. Ancaq, anahtar ifadəsinin yazılması çətinliklərinə görə KPE modelləri çoxlu senaryolarda tamamlanmış problemlərdən çox çətin sıxılır. Bu səbəbdən biz daha qüvvətli təhsil metodlarını təklif edirik ki, əlavə edilməmiş anahtar sözləri ilə gələn azğınlığı azaltmaq üçün öyrənir. Biz təhsil ziyanını düzəltmək üçün negatif nümunələri təşkil edirik və müxtəlif senaryolar altında eksperimentləri təşkil edirik. Sintetik veri qurğuları və açıq domena veri qurğuları barəsindəki impirik təhsil işləri modelimiz tamamlanmış problemlərə güclüdür və əvvəlkilərin baz çətinlərini aşır. Beş bilimsel domenin verilənlərin müxtəlif ölçülərdə genişliyi eksperimentlər modelimizin sanat metodları ilə müqayisədə olduğunu göstərir.</abstract_az>
      <abstract_bs>Izvlačenje ključnih fraza koji sažetaju glavne tačke dokumenta je osnovni zadatak u procesu prirodnog jezika. Nadzorni pristupi ekstrakciji ključne fraze (KPE) se u velikoj mjeri razvijaju na temelju pretpostavke da su podaci o obuci potpuno annotirani. Međutim, zbog teškoće izjave ključne fraze, modeli KPE teško pate od nepotpunog annotiranog problema u mnogim scenarijama. Za taj cilj predlažemo robniji metod obuke koji nauči da smanji pogrešno uputstvo koje donose nenabelovane ključne fraze. Predstavljamo negativni uzorak kako bi se prilagodili gubitak treninga i provodili eksperimenti pod različitim scenarijama. Empirička ispitivanja o sintetičkim setima podataka i otvorenom setu podataka domena pokazuju da je naš model jak do nepotpunog annotiranog problema i prelazi prije početnih linija. Eksperimenti na pet znanstvenih domena podataka različitih skala pokazuju da je naš model konkurentan sa metodom stanja umjetnosti.</abstract_bs>
      <abstract_et>Dokumendi põhipunkte kokku võtvate märksõnade ekstraheerimine on loomuliku keele töötlemise põhiülesanne. Võtmerfraaside ekstraheerimise (KPE) järelevalve all olevad lähenemisviisid on suures osas välja töötatud eeldusel, et koolitusandmed on täielikult märgitud. Võtmefraaside annoteerimise raskuse tõttu kannatavad KPE mudelid paljudes stsenaariumides tõsiselt mittetäielike annoteeritud probleemide tõttu. Selleks pakume välja tugevama koolitusmeetodi, mis õpib leevendama märgistamata märksõnade põhjustatud valejuhtimist. Tutvustame negatiivseid proove treeningkaotuste korrigeerimiseks ja teeme katseid erinevates stsenaariumides. Empiirilised uuringud sünteetiliste andmekogumite ja avatud domeenide andmekogumite kohta näitavad, et meie mudel on tugev kuni mittetäielik annoteeritud probleem ja ületab varasemad lähtejooned. Ulatuslikud eksperimendid viie erineva skaalaga teadusvaldkonna andmekogumiga näitavad, et meie mudel on konkurentsivõimeline kaasaegse meetodiga.</abstract_et>
      <abstract_cs>Extrahování klíčových frází, které shrnují hlavní body dokumentu, je základním úkolem ve zpracování přirozeného jazyka. Sledované přístupy k extrakci klíčových frází (KPE) jsou z velké části vyvíjeny na základě předpokladu, že tréninková data jsou plně anotována. Nicméně vzhledem k obtížnosti s anotováním klíčových frází KPE modely vážně trpí neúplným anotovaným problémem v mnoha scénářích. Za tímto účelem navrhujeme robustnější tréninkovou metodu, která se naučí zmírnit chybné vedení přinášené neoznačenými klíčovými frázemi. Zavádíme negativní vzorkování pro úpravu tréninkových ztrát a provádíme experimenty v různých scénářích. Empirické studie syntetických datových sad a open domain datových sad ukazují, že náš model je robustní až k neúplnému anotovanému problému a překonává předchozí základní linie. Rozsáhlé experimenty na pěti datových sadách různých vědeckých oblastí ukazují, že náš model je konkurenceschopný s nejmodernější metodou.</abstract_cs>
      <abstract_fi>Asiakirjan pääkohdat tiivistävien avainlauseiden purkaminen on luonnollisen kielen käsittelyn perustehtävä. Valvottuja lähestymistapoja avainlauseiden poistoon (KPE) kehitetään suurelta osin olettamalla, että harjoitustiedot on merkitty täysin muistiin. Avainlausemerkintöjen vaikeuden vuoksi KPE-mallit kärsivät kuitenkin monissa skenaarioissa puutteellisista huomautuksista. Tätä varten ehdotamme vankempaa harjoitusmenetelmää, joka oppii lieventämään merkitsemättömien avainlauseiden aiheuttamaa harhaanjohtamista. Otamme käyttöön negatiivisen näytteenoton harjoitushäviön säätämiseksi ja teemme kokeita eri skenaarioissa. Empiiriset tutkimukset synteettisistä aineistoista ja avoimen verkkotunnuksen aineistoista osoittavat, että mallimme on vankka tai puutteellinen annotoitu ongelma ja ylittää aiemmat lähtökohdat. Laajat kokeet viidellä eri mittakaavalla varustetulla tieteellisellä aineistolla osoittavat, että mallimme on kilpailukykyinen uusimman menetelmän kanssa.</abstract_fi>
      <abstract_bn>প্রাকৃতিক ভাষার প্রক্রিয়ায় একটি মৌলিক কাজ। প্রশিক্ষণের তথ্য পুরোপুরি বিরক্তিকর। কিন্তু কীবাক্ষরের কষ্টের কারণে কেপের মডেল অনেক দৃশ্যের অসম্পূর্ণ বিরক্তিকর সমস্যা থেকে কঠিন ভুগছে। এই পর্যন্ত আমরা আরো রোবটস্ট প্রশিক্ষণের পদ্ধতি প্রস্তাব করি যা শিখে অলীক্ষিত কীবোর্ডের মাধ্যমে যে ভুল ভুলের মাত্রা প্রদ We introduce negative sampling to adjust training loss, and conduct experiments under different scenarios.  সিন্টেটিক ডাটাসেট এবং খোলা ডোমেইন ডাটাসেট সম্পর্কে সামাজিক গবেষণা দেখাচ্ছে যে আমাদের মডেল অসম্পূর্ণ সমস্যা এবং বেসেলাইনের পূ পাঁচটি বৈজ্ঞানিক ডোমেইন ডাটাসেটের বিশেষ পরীক্ষা প্রদর্শন করে যে আমাদের মডেল প্রতিযোগিতার সাথে প্রতিযোগিতা করছে শিল্পের রাষ</abstract_bn>
      <abstract_jv>Ngawe politenessoffpolite"), and when there is a change ("assertive politenessoffpolite"), and when there is a change ("assertivepoliteness Ngomongke iki, kita supoyo nggawe sistem tukang layang luwih apik lan ngerasah nggawe barang apik batir Anyone empircal tutorial on senetic dataset and open domain dataset show that we model is jobt to Incomplete Annuted question and surpass before basic lines. OU = VeriSign Trust Network (OU = VeriSign Language)</abstract_jv>
      <abstract_ha>Fitarwa maɓallin maganar da ke ƙarfafa muhimmin point na takardar, shi ne wani aikin muhimmi cikin aikin da za'a yi aiki da fassara. An tsohon da aka yi amfani da zuwa cire faɗi na kalma(KLE) za'a samar da shi mafi girma a kan zato da za'a zartar da data mai amfani da shi cikakken zartar da. Amma, don haka, don me a zartar da misãlin KLE masu cũtar da matsayin da aka cika ba da haske a cikin masu yawa. Daga wannan, Muke goyyar da wata hanyor wa mafarinta na fara, wanda ya sanar ya cire misalin da aka zo da misalin da ba'a rubutu ba. Tuna goge misali nega dõmin a gyara hasara na mafarin aiki, kuma Mu sami jarrabo a cikin sanako dabam-daban. Empirical research on tsari na haɗi da kuma tsarin danne-danne da aka buɗe ɗamfyuta, yana nuna cewa an riƙe misalinmu zuwa a cikakken shida ba'a taƙaita ba, kuma yana sura gaba ga layin basu-bane. Akwai jarrabo masu yawa kan danne-danne masu sakan da ke cikin fili shan, sun nuna cewa misalinmu yana ta yi ƙunci a cikin hanyar-the-art.</abstract_ha>
      <abstract_he>הוציאה משפטים מפתחים שמסכם את נקודות העיקריות של מסמך היא משימה בסיסית בעבודת שפת טבעית. Supervised approaches to keyphrase extraction(KPE) are largely developed based on the assumption that the training data is fully annotated.  בכל אופן, בגלל הקשה של הערות של ביטוי מפתח, דוגמנים KPE סובלים ברצינות מבעיה לא מושלמת מועטפת במקרים רבים. To this end, we propose a more robust training method that learns to mitigate the misguidance brought by unlabeled keyphrases.  אנחנו מציגים דגימות שליליות כדי להתאים אובדן אימון, ולביצע ניסויים תחת תרחישים שונים. מחקרים אימפריים על קבוצות נתונים סינטטיים וקבוצת נתונים של שטח פתוח מראים שהמודל שלנו חזק לבעיה לא מושלמת ומעברת את קווי הבסיס הקודמים. Extensive experiments on five scientific domain datasets of different scales demonstrate that our model is competitive with the state-of-the-art method.</abstract_he>
      <abstract_sk>Izvlečevanje ključnih fraz, ki povzemajo glavne točke dokumenta, je temeljna naloga pri obdelavi naravnega jezika. Nadzorovani pristopi k ekstrakciji ključnih fraz (KPE) so večinoma razviti na podlagi predpostavke, da so podatki o usposabljanju v celoti označeni. Vendar pa zaradi težavnosti pri označevanju ključnih fraz modeli KPE v številnih scenarijih močno trpijo zaradi nepopolnih težav z označbami. V ta namen predlagamo robustnejšo metodo usposabljanja, ki se nauči ublažiti napačno usmerjanje, ki ga prinašajo neoznačene ključne fraze. Uvajamo negativno vzorčenje za prilagoditev izgube treninga in izvajamo eksperimente v različnih scenarijih. Empirične študije o sintetičnih podatkovnih naborih in naboru podatkov odprte domene kažejo, da je naš model robusten do nepopolnega problematičnega označevanja in presega prejšnje osnovne vrstice. Obsežni poskusi na petih znanstvenih domenskih podatkovnih nizov različnih lestvic kažejo, da je naš model konkurenčen z najsodobnejšo metodo.</abstract_sk>
      <abstract_bo>ཡིག Supervised approaches to keyphrase extraction(KPE)are largely developed based on the assumption that the training data is fully annotated. ཡིན་ནའང་། གནད་སྡུད་ཚིག་འགོ་བཤད་ཀྱི་དཀའ་ངལ་བ་དེ་ལྟ་བུའི་མིག་དཔེ་གཞི་ཚོགས་སྣང་མེད་པའི་དཀའ་ངལ་གང་ཡང་ལྷག་འདུག། འོན་ཀྱང་། ང་ཚོས་བློ་གཏོང་གི་ཐབས་ལམ་ལྟར་བདེ་སྐྱིད་འཛིན་གྱི་ཐབས་ལམ་ཞིག་བྱེད་རྒྱུ་དང་། ང་ཚོས་ཤེས་བྱས་པའི་དཔེ་དབྱངས་ཚད་ལྡན་པར་སྒྲིག་འགོད་བྱེད་པ་མི་འདྲ་བྱེད་ཀྱི་ཡོད། Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines. Extensive experiments on five scientific domain datasets of different scales demonstrate that our model is competitive with the state-of-the-art method.</abstract_bo>
      </paper>
    <paper id="5">
      <title>Fine-grained Temporal Relation Extraction with Ordered-Neuron LSTM and Graph Convolutional Networks<fixed-case>LSTM</fixed-case> and Graph Convolutional Networks</title>
      <author><first>Minh</first><last>Tran Phu</last></author>
      <author><first>Minh Van</first><last>Nguyen</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>35–45</pages>
      <abstract>Fine-grained temporal relation extraction (FineTempRel) aims to recognize the durations and timeline of event mentions in text. A missing part in the current deep learning models for FineTempRel is their failure to exploit the <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structures</a> of the input sentences to enrich the <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation vectors</a>. In this work, we propose to fill this gap by introducing novel methods to integrate the <a href="https://en.wikipedia.org/wiki/Syntax">syntactic structures</a> into the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> for FineTempRel. The proposed <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> focuses on two types of syntactic information from the <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">dependency trees</a>, i.e., the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context words</a> for the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">event mentions</a>. We also present two novel techniques to facilitate the knowledge transfer between the subtasks of FineTempRel, leading to a novel model with the state-of-the-art performance for this task.</abstract>
      <url hash="81e1333c">2021.wnut-1.5</url>
      <bibkey>tran-phu-etal-2021-fine</bibkey>
      <doi>10.18653/v1/2021.wnut-1.5</doi>
    <title_ar>استخراج الارتباط الزمني دقيق الحبيبات باستخدام الشبكات التلافيفية للخلايا العصبية LSTM والشبكات التلافيفية للرسم البياني</title_ar>
      <title_pt>Extração de relações temporais refinadas com LSTM de neurônios ordenados e redes convolucionais de gráficos</title_pt>
      <title_fr>Extraction fine de relations temporelles avec LSTM de neurones ordonnés et réseaux convolutionnels de graphes</title_fr>
      <title_es>Extracción de relaciones temporales de grano fino con LSTM de neuronas ordenadas y redes convolucionales de grafos</title_es>
      <title_ja>有秩序ニューロンLSTMおよびグラフ畳み込みネットワークを用いた細粒度時間関係抽出</title_ja>
      <title_zh>用序神经元 LSTM 图卷积网络者细粒度时也</title_zh>
      <title_hi>आदेश-न्यूरॉन LSTM और ग्राफ Convolutional नेटवर्क के साथ ठीक दानेदार अस्थायी संबंध निष्कर्षण</title_hi>
      <title_ru>Тонкозернистая экстракция височной связи с помощью сетей свертки упорядоченных нейронов LSTM и графиков</title_ru>
      <title_ga>Eastóscadh Caidreamh Sealadach mínghlan le LSTM Ordaithe-Neuron agus Líonraí Comhráiteacha Graf</title_ga>
      <title_ka>საკუთარი ტემპორალური შესახებ ექსტრაქცია შესახებ ნეირონის LSTM და გრაფის შესახებ ქსელებით</title_ka>
      <title_el>Εκχύλισμα λεπτόκοκκης χρονικής σχέσης με δίκτυα διακεκριμένων νευρώνων και καμπυλωτά γραφήματα</title_el>
      <title_hu>Finom szemű időszaki kapcsolat extrakció rendezett neuron LSTM és grafikon konzolúciós hálózatokkal</title_hu>
      <title_it>Estrazione di relazione temporale a grana fine con LSTM Ordinato Neuron e Reti Convoluzionali Grafiche</title_it>
      <title_mk>Name</title_mk>
      <title_lt>Nuolatinių grūdų laikinųjų santykių ekstrakcija su užsakytaisiais neuronų LSTM ir grafinių konvoliucinių tinklų tinklais</title_lt>
      <title_kk>Түзіндік температуралық қатынас тарқатуы реттегі неврон LSTM және график қатынас желілерімен</title_kk>
      <title_ms>Fine-grained Temporal Relation Extraction with Ordered-Neuron LSTM and Graph Convolutional Networks</title_ms>
      <title_ml>ക്രമീകരിക്കപ്പെട്ട നെയോരോണ്‍ എല്‍സ്റ്റിം, ഗ്രാഫ് കോണ്‍പ്ലോയേഷന്‍ നെറ്റ്‌വര്‍ക്കുകളും</title_ml>
      <title_mt>Estrazzjoni ta’ Relazzjoni Temporali b’Ħruġ Fin ma’ Netwerks ta’ Konveluzzjoni tan-Newroni Ordnati LSTM u Graph</title_mt>
      <title_mn>Сайн тарианы Температур харилцааны хамаарал Хэрэглэгдсэн мэдрэлийн LSTM болон Графын Хэрэглэгдсэн Желүүд</title_mn>
      <title_no>Ekstrasjon med ordna neuron LSTM og graf- konvolusjonelle nettverk</title_no>
      <title_pl>Drobnoziarnista ekstrakcja relacji czasowych z użyciem LSTM i sieci konwolucyjnych układanych neuronów</title_pl>
      <title_ro>Extracție temporală fină de relații cu neuroni ordonați LSTM și rețele convoluționale grafice</title_ro>
      <title_si>හොඳ ග්‍රේන්ඩ් තාමාවික සම්බන්ධ නිර්මාණය නිර්මාණය</title_si>
      <title_sr>Fino zrno ekstrakcija Temporalnih odnosa sa naređenim neuronskim LSTM i konvolucionalnim mrežama grafika</title_sr>
      <title_so>Soo saarista waqtiga ku meelgaarka ah</title_so>
      <title_sv>Finkornig temporal relationsextraktion med beställd neuron LSTM och grafkonvulutionsnätverk</title_sv>
      <title_ta>வரிசைப்படுத்தப்பட்ட LSTM மற்றும் வரையறை தொகுப்பு வலைப்பின்னல்களுடன் சரியான கிடைக்கப்பட்ட தற்காலிக இணைப்பு பிரித</title_ta>
      <title_ur>اچھی دانے تیموال رابطہ اٹھانے کے ساتھ اچھی نائرون LSTM اور گراف کنویلوژن نیٹورک کے ساتھ</title_ur>
      <title_uz>Comment</title_uz>
      <title_vi>Cấu trúc thời gian tuyệt đối chiết xuất với hệ thống thần kinh được lệnh HTTM và cấu hình dạng</title_vi>
      <title_bg>Екстракция на фина времева връзка с подредени невронни ЛСТМ и графични конвелуционни мрежи</title_bg>
      <title_da>Finkornet Temporal Relation Ekstraktion med Ordered Neuron LSTM og Graf Konvulutionsnetværk</title_da>
      <title_nl>Fijnkorrelige Temporale Relatie Extractie met Ordered-Neuron LSTM en Graph Convolutional Networks</title_nl>
      <title_hr>Fino zrno ekstrakcija Temporalnih odnosa s naređenim neuronskim LSTM i konvolucionalnim mrežama grafika</title_hr>
      <title_de>Feinkörnige temporale Beziehungsextraktion mit Ordnered-Neuron LSTM und Graph Convolutional Networks</title_de>
      <title_id>Ekstraksi Hubungan Temporal dengan LSTM Neuron Terperintah dan Rangkaian Konvelusi Graf</title_id>
      <title_fa>اخراج رابطه معمولی با شبکه‌های مختلف‌های عصبی‌های سفارشی LSTM و گراف‌ها</title_fa>
      <title_tr>Taýikça Taýikça Derjesi Açmak</title_tr>
      <title_af>Name</title_af>
      <title_sq>Ekstraktimi i lidhjes së përkohshme me rrjetet e rregulluara të neuronëve LSTM dhe Graph Convolutional</title_sq>
      <title_ko>질서정연한 신경원 LSTM과 도권적 네트워크를 바탕으로 세립도 시간 관계 추출</title_ko>
      <title_am>ምርጫዎች</title_am>
      <title_sw>Utoa wa Uhusiano wa muda mfupi kwa ajili ya LSTM na Mtandao wa Kujitoleza</title_sw>
      <title_hy>Comment</title_hy>
      <title_bs>Fino zrno ekstrakcija Temporalnih odnosa s naređenim neuronskim LSTM i konvolucionalnim mrežama grafika</title_bs>
      <title_bn>নিউরন LSTM এবং গ্রাফ কনভোলোশনেশন নেটওয়ার্ক দ্বারা সুন্দর পর্যায়ের সম্পর্ক এক্সট্র্যাকশন</title_bn>
      <title_az>SńĪradan n√∂ron LSTM v…ô Grafik Konvolucional S…ôn…ôl…ôri il…ô yaxŇüńĪ d…ôn…ôli Temporal Relationship Extraction</title_az>
      <title_ca>Extracció de relació temporal fina amb xarxes de conversió de neurons ordenats LSTM i gràfics</title_ca>
      <title_cs>Jemnozrnná extrakce časových vztahů pomocí uspořádaných neuronových LSTM a grafových konvelučních sítí</title_cs>
      <title_et>Peeneteraline ajalise suhte ekstraheerimine ordered-neuron LSTM ja graafilise konvolutsioonivõrkudega</title_et>
      <title_fi>Hienorakeinen aikasidoksen uuttaminen tilattujen neuronien LSTM- ja graafisten konvoluutioiden avulla</title_fi>
      <title_jv>Fine</title_jv>
      <title_he>מחלץ מערכת יחסים זמנית עם LSTM נוירוני מסודרים ורשתות שינוי גרף</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Ekstrakcija drobnozrnate časovne relacije z naročenimi nevronskimi LSTM in grafičnimi konvolucijskimi omrežji</title_sk>
      <title_bo>Fine-grained Temporal Relation Extraction with Ordered-Neuron LSTM and Graph Convolutional Networks</title_bo>
      <abstract_pt>A extração de relação temporal refinada (FineTempRel) visa reconhecer as durações e a linha do tempo das menções de eventos no texto. Uma parte que falta nos atuais modelos de aprendizado profundo para o FineTempRel é sua falha em explorar as estruturas sintáticas das sentenças de entrada para enriquecer os vetores de representação. Neste trabalho, propomos preencher essa lacuna introduzindo novos métodos para integrar as estruturas sintáticas nos modelos de aprendizado profundo para FineTempRel. O modelo proposto se concentra em dois tipos de informações sintáticas das árvores de dependência, ou seja, as pontuações de importância baseadas em sintaxe para aprendizado de representação das palavras e as conexões sintáticas para identificar palavras de contexto importantes para as menções do evento. Apresentamos também duas novas técnicas para facilitar a transferência de conhecimento entre as subtarefas do FineTempRel, levando a um novo modelo com desempenho de última geração para esta tarefa.</abstract_pt>
      <abstract_ar>يهدف استخراج العلاقة الزمنية الدقيقة (FineTempRel) إلى التعرف على المدد والجدول الزمني للإشارة إلى الأحداث في النص. يتمثل الجزء المفقود في نماذج التعلم العميق الحالية لـ FineTempRel في فشلها في استغلال الهياكل النحوية لجمل الإدخال لإثراء متجهات التمثيل. في هذا العمل ، نقترح سد هذه الفجوة من خلال إدخال طرق جديدة لدمج الهياكل النحوية في نماذج التعلم العميق لـ FineTempRel. يركز النموذج المقترح على نوعين من المعلومات النحوية من أشجار التبعية ، أي درجات الأهمية القائمة على النحو لتعلم التمثيل للكلمات والصلات النحوية لتحديد كلمات السياق المهمة التي يذكرها الحدث. نقدم أيضًا تقنيتين جديدتين لتسهيل نقل المعرفة بين المهام الفرعية لـ FineTempRel ، مما يؤدي إلى نموذج جديد بأداء متطور لهذه المهمة.</abstract_ar>
      <abstract_es>La extracción detallada de relaciones temporales (FineTemprel) tiene como objetivo reconocer las duraciones y el cronograma de las menciones de eventos en el texto. Una parte que falta en los modelos actuales de aprendizaje profundo para FineTemprel es su incapacidad para explotar las estructuras sintácticas de las oraciones de entrada para enriquecer los vectores de representación. En este trabajo, proponemos llenar este vacío introduciendo métodos novedosos para integrar las estructuras sintácticas en los modelos de aprendizaje profundo para FineTemprel. El modelo propuesto se centra en dos tipos de información sintáctica de los árboles de dependencias, es decir, las puntuaciones de importancia basadas en la sintaxis para el aprendizaje de representación de las palabras y las conexiones sintácticas para identificar palabras de contexto importantes para las menciones de eventos. También presentamos dos técnicas novedosas para facilitar la transferencia de conocimientos entre las subtareas de FineTemprel, lo que lleva a un modelo novedoso con el rendimiento más avanzado para esta tarea.</abstract_es>
      <abstract_fr>L'extraction fine de relations temporelles (FineTemprel) vise à reconnaître les durées et la chronologie des mentions d'événements dans le texte. Une partie manquante des modèles d'apprentissage profond actuels pour FineTemprel est leur incapacité à exploiter les structures syntaxiques des phrases d'entrée pour enrichir les vecteurs de représentation. Dans ce travail, nous proposons de combler cette lacune en introduisant de nouvelles méthodes pour intégrer les structures syntaxiques dans les modèles d'apprentissage profond pour FineTemprel. Le modèle proposé se concentre sur deux types d'informations syntaxiques provenant des arbres de dépendance, à savoir les scores d'importance basés sur la syntaxe pour l'apprentissage de la représentation des mots et les connexions syntaxiques pour identifier les mots contextuels importants pour les mentions d'événements. Nous présentons également deux nouvelles techniques pour faciliter le transfert de connaissances entre les sous-tâches de FineTemprel, menant à un nouveau modèle doté des performances de pointe pour cette tâche.</abstract_fr>
      <abstract_ja>細粒度時間関係抽出（ FineTempRel ）は、テキスト内のイベントメンションの持続時間とタイムラインを認識することを目的としています。FineTempRelの現在のディープラーニングモデルで欠けている部分は、表現ベクトルを豊かにするために入力文の構文構造を利用することができなかったことです。この研究では、FineTempRelのディープラーニングモデルに構文構造を統合するための新たな方法を導入することで、このギャップを埋めることを提案します。提案されたモデルは、依存関係ツリーからの2種類の構文情報、すなわち、単語の表現学習のための構文ベースの重要性スコアと、イベントが言及する重要な文脈単語を識別するための構文接続に焦点を当てている。また、FineTempRelのサブタスク間の知識移転を促進するための2つの新たなテクニックを提示し、このタスクのための最先端のパフォーマンスを備えた新規モデルにつながります。</abstract_ja>
      <abstract_zh>细粒度时关取(FineTempRel)指识文本事提持续时间线。 FineTempRel 之深者,未能输句语法结构以示向量也。 于是建议引入新法,集句法于FineTempRel深学模形以补之。 所立侧重于依树之句法,所以为学于单词者,语法之大分,识事之上下文单词句法接也。 设二新之术,以趋FineTempRel子之知,以供先进之新。</abstract_zh>
      <abstract_hi>ठीक दानेदार अस्थायी संबंध निष्कर्षण (FineTempRel) का उद्देश्य पाठ में उल्लिखित घटना की अवधि और समयरेखा को पहचानना है। FineTempRel के लिए वर्तमान गहरी सीखने के मॉडल में एक लापता हिस्सा प्रतिनिधित्व वैक्टर को समृद्ध करने के लिए इनपुट वाक्यों की वाक्यात्मक संरचनाओं का शोषण करने में उनकी विफलता है। इस काम में, हम FineTempRel के लिए गहरी सीखने के मॉडल में वाक्यात्मक संरचनाओं को एकीकृत करने के लिए उपन्यास विधियों को पेश करके इस अंतर को भरने का प्रस्ताव करते हैं। प्रस्तावित मॉडल निर्भरता पेड़ों से दो प्रकार की वाक्यात्मक जानकारी पर केंद्रित है, यानी, शब्दों के प्रतिनिधित्व सीखने के लिए वाक्यविन्यास-आधारित महत्व स्कोर और घटना के लिए महत्वपूर्ण संदर्भ शब्दों की पहचान करने के लिए वाक्यविन्यास-आधारित महत्व स्कोर। हम FineTempRel के उप-कार्यों के बीच ज्ञान हस्तांतरण को सुविधाजनक बनाने के लिए दो उपन्यास तकनीकों को भी प्रस्तुत करते हैं, जिससे इस कार्य के लिए अत्याधुनिक प्रदर्शन के साथ एक उपन्यास मॉडल होता है।</abstract_hi>
      <abstract_ru>Извлечение мелкозернистых временных связей (FineTempRel) направлено на распознавание длительности и временной шкалы упоминаний событий в тексте. Недостающей частью современных моделей глубокого обучения для FineTempRel является их неспособность использовать синтаксические структуры входных предложений для обогащения векторов представления. В этой работе мы предлагаем заполнить этот пробел путем внедрения новых методов интеграции синтаксических структур в модели глубокого обучения для FineTempRel. Предлагаемая модель фокусируется на двух типах синтаксической информации из деревьев зависимостей, то есть на баллах важности на основе синтаксиса для изучения репрезентации слов и синтаксических связях для определения важных контекстных слов для упоминания события. Мы также представляем два новых метода для облегчения передачи знаний между подзадачами FineTempRel, что приводит к созданию новой модели с современным исполнением для этой задачи.</abstract_ru>
      <abstract_ga>Tá sé mar aidhm ag eastóscadh caidreamh ama mionghruthaithe (FineTempRel) tréimhsí agus amlíne na n-imeachtaí a luaitear sa téacs a aithint. Cuid atá in easnamh sna múnlaí domhainfhoghlama atá ann faoi láthair do FineTempRel is ea an teip atá orthu leas a bhaint as struchtúir chomhréire na n-abairtí ionchuir chun na veicteoirí ionadaíochta a shaibhriú. San obair seo, tá sé beartaithe againn an bhearna seo a líonadh trí mhodhanna núíosacha a thabhairt isteach chun na struchtúir chomhréire a chomhtháthú sna samhlacha domhainfhoghlama do FineTempRel. Díríonn an tsamhail mholta ar dhá chineál faisnéise comhréire ó na crainn spleáchais, i.e., na scóir tábhachta bunaithe ar chomhréir chun na focail a fhoghlaim agus na naisc chomhréire chun focail thábhachtacha chomhthéacs a aithint don imeacht a luaitear. Cuirimid dhá theicníc nua i láthair freisin chun an t-aistriú eolais idir na subtascanna de chuid FineTempRel a éascú, as a dtiocfaidh samhail nua le feidhmíocht den scoth don tasc seo.</abstract_ga>
      <abstract_el>Η λεπτόκοκκη εξαγωγή χρονικών σχέσεων (στοχεύει στην αναγνώριση της διάρκειας και της χρονογραμμής των αναφορών γεγονότων στο κείμενο. Ένα μέρος που λείπει στα σημερινά μοντέλα βαθιάς μάθησης για το FineTempRel είναι η αποτυχία τους να εκμεταλλευτούν τις συντακτικές δομές των προτάσεων εισαγωγής για να εμπλουτίσουν τα διανύσματα αναπαράστασης. Στην παρούσα εργασία, προτείνουμε να καλυφθεί αυτό το κενό εισάγοντας νέες μεθόδους ενσωμάτωσης των συντακτικών δομών στα μοντέλα βαθιάς μάθησης για το FineTempRel. Το προτεινόμενο μοντέλο επικεντρώνεται σε δύο τύπους συντακτικών πληροφοριών από τα δέντρα εξάρτησης, δηλαδή στις βαθμολογίες σπουδαιότητας που βασίζονται στη σύνταξη για την εκμάθηση αναπαράστασης των λέξεων και στις συντακτικές συνδέσεις για τον προσδιορισμό σημαντικών λέξεων περιβάλλοντος για τις αναφορές συμβάντος. Παρουσιάζουμε επίσης δύο νέες τεχνικές για τη διευκόλυνση της μεταφοράς γνώσεων μεταξύ των επιμέρους εργασιών του οδηγώντας σε ένα νέο μοντέλο με την υπερσύγχρονη απόδοση για αυτό το έργο.</abstract_el>
      <abstract_ka>FineTempRel მიზეზიან ტექსტის მოვლენების სივრცე და დრო ხაზი. FineTempRel- ის მიმდინარე სინტაქტიური სტრუქტურების სინტაქტიური სტრუქტურების გამოყენება, რომ გამოყენება გვექტურაციის გამოყენება. ამ სამუშაოში, ჩვენ გვეძლევა, რომ ამ განსხვავებას გაუყენოთ, რომელიც პრომენტიკური მეტოვებით, რომ სინტექტიკური სტრუქტურები FineTempRel-ის ძალიან სწავლების მოდელში პროგრამების მოდელეში ორი ტიპის სინტაქტიური ინფორმაციაზე, როგორც განსახულებელობის ხელებიდან, ანუ სინტაქქსის გასახულებელობის მნიშვნელობის მონაცემები სიტყვების და სინტაქტიური კავშირების გასახულებლად მო ჩვენ ასევე ორი პრომენტიკური ტექნოგიები გავამუშავებთ, რომ FineTempRel-ის სტრანსტრესტის შორის ცნობილის გარეშე, რომელიც პრომენტიკური მოდელში, რომელიც ამ საქმენოს სტრანსტრე</abstract_ka>
      <abstract_it>FineTempRel (FineTempRel) mira a riconoscere la durata e la timeline delle menzioni di eventi nel testo. Una parte mancante negli attuali modelli di deep learning per FineTempRel è la loro incapacità di sfruttare le strutture sintattiche delle frasi di input per arricchire i vettori di rappresentazione. In questo lavoro, proponiamo di colmare questa lacuna introducendo nuovi metodi per integrare le strutture sintattiche nei modelli di deep learning per FineTempRel. Il modello proposto si concentra su due tipi di informazioni sintattiche provenienti dagli alberi delle dipendenze, cioè i punteggi di importanza basati sulla sintassi per l'apprendimento della rappresentazione delle parole e le connessioni sintattiche per identificare parole di contesto importanti per le menzioni dell'evento. Presentiamo anche due nuove tecniche per facilitare il trasferimento di conoscenze tra le sottoattività di FineTempRel, portando a un nuovo modello con prestazioni all'avanguardia per questo compito.</abstract_it>
      <abstract_lt>FineTempRel (Fine-grained temporal relationship extraction, FineTempRel) tikslas – pripažinti tekste nurodytų įvykių trukmę ir laiką. Dabartiniuose FineTempRel gilaus mokymosi modeliuose trūksta dalies, nes jie nepasinaudoja įvesties sakinių sintaktinėmis struktūromis, kad praturtintų reprezentacinius vektorius. Šiame darbe siūlome užpildyti šią spragą įvedant naujus metodus sintaksinėms struktūroms integruoti į FineTempRel gilaus mokymosi modelius. Siūlomame modelyje daugiausia dėmesio skiriama dviejų rūši ų sintaktinei priklausomybės medžių informacijai, t. y. sintaksinėmis reikšmėmis pagrįstiems žodžių reprezentacijos mokymosi svarbos rezultatams ir sintaksinėms sąsajoms, skirtoms nustatyti svarbius kontekstinius žodžius renginiui paminėti. Taip pat pristatome du naujus metodus, kuriais siekiama palengvinti žinių perdavimą tarp FineTempRel subtaskų, ir taip sukurti naują model į, kuriame būtų moderniausi šios užduoties rezultatai.</abstract_lt>
      <abstract_kk>FineTempRel мәтіндегі оқиғалардың ұзақтығын мен уақыт жолын анықтау мақсаты. FineTempRel үшін қазіргі терең оқыту үлгілерінде жоқ бөлігі - олардың келтірілген векторды бағалау үшін келтірілген сөздердің синтактикалық құрылымын орындау қатесі. Бұл жұмыс ішінде, FineTempRel үшін синтактикалық құрылғыларды терең оқыту үлгілеріне ендіру арқылы, осы бос орынды толтыруды таңдаймыз. Келтірілген үлгі тәуелсіздік ағаштардың екі түрлі синтактикалық мәліметіне назар береді, яғни оқиғалардың маңызды контексті сөздерін анықтау үшін синтаксис негіздеген мәліметтері мен синтактикалық қосылымдарды көрсету Сонымен қатар, FineTempRel бағдарламасының білім беруді көмектесу үшін екі романдық техникаларды таңдаймыз. Бұл тапсырманың күй- жайындағы әрекеттерінің романдық үлгісін өзгерту үшін.</abstract_kk>
      <abstract_ms>Pengekstraksi hubungan sementara (FineTempRel) bermaksud untuk mengenali durasi dan garis masa bagi penyelesaian peristiwa dalam teks. Bahagian yang hilang dalam model belajar dalam semasa untuk FineTempRel adalah kegagalan mereka untuk mengeksploitasi struktur sintaktik kalimat input untuk memperkaya vektor perwakilan. Dalam kerja ini, kami cadangkan untuk mengisi ruang ini dengan memperkenalkan kaedah baru untuk mengintegrasikan struktur sintaktik ke dalam model belajar dalam FineTempRel. Model yang diusulkan fokus pada dua jenis maklumat sintaktik dari pokok dependensi, iaitu skor penting berdasarkan sintaks untuk mewakili belajar perkataan dan sambungan sintaktik untuk mengenalpasti perkataan konteks penting bagi sebutan peristiwa. Kami juga mempersembahkan dua teknik baru untuk memudahkan pemindahan pengetahuan antara subtasks FineTempRel, yang membawa kepada model baru dengan prestasi terbaik untuk tugas ini.</abstract_ms>
      <abstract_mk>Екстракција на фино-зелени временски односи (FineTempRel) има за цел препознавање на траењето и временската линија на спомените на настаните во текстот. Недостаток дел од актуелните модели на длабоко учење за FineTempRel е нивниот неуспех да ги искористат синтактичките структури на вводните реченици за богатство на векторите на претставување. Во оваа работа, предлагаме да ја пополниме оваа празнина со воведување нови методи за интеграција на синтактичките структури во моделите за длабоко учење на FineTempRel. Предложениот модел се фокусира на два вида синтактички информации од дрвјата на зависноста, т.е., оценките на важност базирани на синтаксија за претставување на учењето на зборовите и синтактичките врски за идентификување важни контекстни зборови за споменувањето на настанот. Ние, исто така, претставуваме две нови техники за олеснување на пренесувањето на знаење помеѓу потпрашањата на FineTempRel, што води до нов модел со најсовремена изведба за оваа задача.</abstract_mk>
      <abstract_hu>A FineTempRel (FineTempRel) célja, hogy felismerje az eseményemlítések időtartamát és idővonalát a szövegben. A FineTempRel jelenlegi mélytanulási modelljeinek hiányzó része, hogy nem tudják kihasználni a bemeneti mondatok szintaktikus struktúráit a reprezentációs vektorok gazdagítására. Ebben a munkában azt javasoljuk, hogy ezt a hiányt új módszereket vezessünk be a szintaktikus struktúrák integrálására a FineTempRel mélytanulási modelljeibe. A javasolt modell két típusú szintaktikai információra összpontosít a függőségi fákból, azaz a szavak reprezentációs tanulásához szükséges szintaktikai pontszámokra és a szintaktikai kapcsolatokra az esemény említéseihez szükséges fontos kontextusszavak azonosítására. Két újszerű technikát is bemutatunk a FineTempRel alterületei közötti tudásátadás megkönnyítésére, amelyek egy új modell kialakításához vezetnek, amely a legkorszerűbb teljesítményt nyújtja erre a feladatra.</abstract_hu>
      <abstract_ml>പാഠത്തില്‍ ഉല്‍കൃഷ്ടമായ സമയ ബന്ധപ്പെടുത്തുന്നതിനുള്ള സമയം തിരിച്ചറിയാന്‍ ഉദ്ദേശിക്കുന്നു. ഇപ്പോഴത്തെ ആഴത്തെ പഠിക്കുന്ന മോഡലുകളില്‍ നിന്നും കാണാത്ത ഒരു ഭാഗമാണ് ഫിനെട്ടെമ്പ്രെലിന്‍റെ പ്രതിനിധിയുടെ വെക്റ്റര്‍ക്ക്  ഈ പ്രവര്‍ത്തനത്തില്‍, നോവല്‍ രീതികള്‍ പരിചയപ്പെടുത്താന്‍ ഞങ്ങള്‍ പ്രാര്‍ത്ഥിക്കുന്നു, ഫിനെട്ടെമ്പ്റെലിന്റെ ആഴമായ പഠിക്കുന്ന ആശ്രയിച്ച വൃക്ഷങ്ങളില്‍ നിന്നുള്ള രണ്ടു തരം സിന്‍ടാക്റ്റിക്ക് വിവരങ്ങളില്‍ ശ്രദ്ധിക്കുന്നു. അതായത് വാക്കുകള്‍ പഠിക്കുന്നതിനുള്ള സിന്റാക്സ് അടിസ് We also present two novel techniques to facilitate the knowledge transfer between the subtasks of FineTempRel, leading to a novel model with the state-of-the-art performance for this task.</abstract_ml>
      <abstract_no>FineTempRel- utpakking med finn tidslinje for hendingar (FineTempRel) vil gjenkjenna tidslinja og tidslinja for hendingar som er oppgjeven i tekst. Det manglar ein del i den gjeldande dyppa læringsmodellen for FineTempRel. Dette er mislukka å bruka syntaktiske strukturen til innsetningsetningane for å rykke representasjonsvectorane. I denne arbeiden foreslår vi å fylle dette mellomrommet ved å introdusera novelle metodar for å integrere syntaktiske strukturene i dei dype læringsmodelane for FineTempRel. Den foreslåde modellen fokuserer på to typar syntaktiske informasjon frå avhengighetstrøka, t.d. syntaksbaserte viktige poeng for å representera læring av ord og syntaktiske tilkoplingar for å identifisera viktige kontekstord for hendinga. Vi presenterer også to novel teknikk for å gjere kunnskaps mellom underoppslagane av FineTempRel, som fører til eit romanmodell med kunsthandlinga for denne oppgåva.</abstract_no>
      <abstract_mt>L-estrazzjoni tar-relazzjoni temporali b’żerriegħa fina (FineTempRel) għandha l-għan li tirrikonoxxi d-dewmien u l-iskeda taż-żmien tal-avvenimenti msemmija fit-test. Parti nieqsa fil-mudelli attwali ta’ tagħlim profond għal FineTempRel hija n-nuqqas tagħhom li jisfruttaw l-istrutturi sintattiċi tas-sentenzi ta’ input biex isaħħu l-vetturi ta’ rappreżentazzjoni. In this work, we propose to fill this gap by introducing novel methods to integrate the syntactic structures into the deep learning models for FineTempRel.  The proposed model focuses on two types of syntactic information from the dependency trees, i.e., the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important context words for the event mentions.  Aħna nippreżentaw ukoll żewġ tekniki ġodda biex niffaċilitaw it-trasferiment tal-għarfien bejn is-sottomistoqsijiet ta’ FineTempRel, li jwasslu għal mudell ġdid bil-prestazzjoni l-aktar avvanzata għal dan il-kompitu.</abstract_mt>
      <abstract_pl>Delikatna ekstrakcja relacji czasowych (FineTempRel) ma na celu rozpoznanie czasu trwania i osi czasu wzmianek zdarzeń w tekście. Brakującą częścią obecnych modeli głębokiego uczenia FineTempRel jest ich niewykorzystanie struktur składni zdań wejściowych do wzbogacenia wektorów reprezentacji. W niniejszej pracy proponujemy wypełnienie tej luki poprzez wprowadzenie nowych metod integracji struktur składni z modelami głębokiego uczenia FineTempRel. Proponowany model skupia się na dwóch rodzajach informacji składniowych z drzew zależności, tj. wynikach znaczenia opartych na składni dla uczenia się reprezentacji słów oraz połączeniach składniowych w celu identyfikacji ważnych słów kontekstowych dla wydarzenia. Przedstawiamy również dwie nowatorskie techniki ułatwiające transfer wiedzy między podzadaniami FineTempRel, prowadzące do opracowania nowatorskiego modelu z najnowocześniejszymi wykonaniami dla tego zadania.</abstract_pl>
      <abstract_mn>FineTempRel (FineTempRel) хугацааны цаг хугацааны хамаарал нь текст дээр ярьж байгаа үйл явдлын цаг хугацааны цаг хугацааны зураг ойлгох зорилго юм. FineTempRel-ын орчин үеийн гүн гүнзгий суралцах загварын нэг хэсэг нь тэдний үзүүлэлтийн векторуудыг багасгах боломжийг ашиглаж чадахгүй. Энэ ажлын тулд бид энэ зай дүүргэхийг санал болгож, FineTempRel-ын гүн гүнзгий суралцах загваруудыг нэгтгэх шинэ арга загварыг тайлбарлаж байна. Өөрчлөлтийн загвар нь хамааралтай модын хоёр төрлийн синтактик мэдээллийг төвлөрүүлдэг, т.е. үгийг сурах болон синтактик холбоонуудыг тодорхойлох чухал тохиолдол юм. Мөн бид FineTempRel-ын доторх мэдлэгийг хөгжүүлэх хоёр шинэ технологийг тайлбарлаж байна. Энэ ажлын төлөө урлагийн үйл ажиллагааны шинэ загвар руу шинэ загвар болгож байна.</abstract_mn>
      <abstract_ro>Extracția relațiilor temporale fine (FineTempRel) își propune să recunoască durata și calendarul mențiunilor de evenimente în text. O parte lipsă în modelele actuale de învățare profundă pentru FineTempRel este eșecul lor de a exploata structurile sintactice ale propozițiilor de intrare pentru a îmbogăți vectorii de reprezentare. În această lucrare, propunem să umplem acest decalaj prin introducerea unor metode noi de integrare a structurilor sintactice în modelele de învățare profundă pentru FineTempRel. Modelul propus se concentrează pe două tipuri de informații sintactice din arborii de dependență, și anume scorurile de importanță bazate pe sintaxă pentru învățarea reprezentării cuvintelor și conexiunile sintactice pentru identificarea cuvintelor contextuale importante pentru mențiunile evenimentului. De asemenea, prezentăm două tehnici noi pentru a facilita transferul de cunoștințe între subsarcinile FineTempRel, conducând la un model nou cu performanțe de ultimă generație pentru această sarcină.</abstract_ro>
      <abstract_sr>FineTempRel je cilj da prepozna trajanje i vremensku liniju događaja spomenunih u tekstu. Nedostajan deo u trenutnim dubokim modelima učenja za FineTempRel je njihov neuspjeh da iskoriste sintaktičke strukture ulaznih rečenica da bi obogatili vektore zastupanja. U ovom poslu predlažemo da napunimo taj praznik uvođenjem novih metoda da integrišemo sintaktičke strukture u duboke modele učenja za FineTempRel. Predloženi model se fokusira na dve vrste sintaktičkih informacija iz drveća zavisnosti, to je značajni rezultati na sintaksiji bazirani na značaju za predstavljanje učenja riječi i sintaktičkih veza da identifikuju važne kontekstske reči za spominjanje događaja. Takođe predstavljamo dve nove tehnike kako bi olakšali prenos znanja između podstavljanja FineTempRel a, koji vodi do novog modela sa stanjem umjetnosti za ovaj zadatak.</abstract_sr>
      <abstract_so>Dhaqaalaha xiriirka ku meelgaarka ah (FineTempRel) waxaa loogu talogaley in lagu aqoonsado waqtiga iyo waqtiga lagu xusto qoraalka. Qayb ka maqnaaday samooyinka waxbarashada moolka dheer ee FineTempRel waa suurtooyinka u baaraandegista dhismaha halqabsiga ee ereyga soo gelinta si uu u hodansiiyo vectoriyada wakiilka. Markaas waxan, waxaynu soo jeedaynaa in aan buuxino qaababkan saxda ah si aan u wada qabsato dhismaha iskuulka ee mool dheer ee FineTempRel. Tusaale la soo jeeday wuxuu ku qoran yahay laba nooc oo macluumaad la xiriira geedaha ku xiran e e la xiriira, tusaale ahaan kooxaha muhiimka ah ee la xiriira barashada hadallada iyo xiriirka isku xiriirka si ay u aqoonsadaan erayo muhiim ah ee dhacdooyinka. Waxaynu sidoo kale keennaa laba qalabka warqada ah si aan u fududayno wareejinta aqoonta oo u dhexeeya shaqada FineTempRel, kaas oo ku hoggaamiya model warqad ah oo sameynta sameynta farshaxanka.</abstract_so>
      <abstract_sv>Finkornig temporal relationsextraktion (FineTempRel) syftar till att känna igen varaktigheten och tidslinjen för händelseomnämningar i text. En del som saknas i de nuvarande djupinlärningsmodellerna för FineTempRel är deras misslyckande att utnyttja de syntaktiska strukturerna i inmatningsmeningarna för att berika representationsvektorerna. I detta arbete föreslår vi att fylla denna lucka genom att introducera nya metoder för att integrera syntaktiska strukturer i djupinlärningsmodellerna för FineTempRel. Den föreslagna modellen fokuserar på två typer av syntaktisk information från beroendeträden, dvs syntaxbaserade betydelsepoäng för representationsinlärning av orden och de syntaktiska kopplingarna för att identifiera viktiga sammanhangsord för händelseomnämnanden. Vi presenterar också två nya tekniker för att underlätta kunskapsöverföring mellan underuppgifterna i FineTempRel, vilket leder till en ny modell med toppmodern prestanda för denna uppgift.</abstract_sv>
      <abstract_si>හොඳ ග්‍රේන්ඩ් කාලකාලික සම්බන්ධය (FineTempRE) ලක්ෂණය ලක්ෂණය ලක්ෂණය කරනවා පාළුවේ කියපු වෙලාව සහ කාලකාලය සඳහා අව FineTempreName මේ වැඩේ අපි ප්‍රශ්නයක් කරනවා මේ අවධානය සම්පූර්ණ විදිහට ප්‍රශ්නයක් වෙනුවෙන් සම්පූර්ණ විදිහට සම්පූර්ණ ව ප්‍රශ්නය කරපු මොඩේලය ප්‍රකාර දෙකක් සංකේතික තොරතුරු වර්ගයෙන් පිළිබඳින්න, ඉතින්, සංකේතය අධ්‍යාත්මක වැදගත් වර්ගය සහ සංකේතය සම අපි සමහරවිට නියම විද්‍යාවක් දෙකක් පෙන්වන්නේ FineTempREල් වලින් දැනගන්න දැනගන්න, මේ වැඩේ විද්‍යාවක් සඳහා නියෝජිත විද්‍යාවක්</abstract_si>
      <abstract_ur>پاکیزہ دانے کے ذریعہ تخلیق (FineTempRel) کے مطابق تخلیق کے ذریعہ کا مطابق ہے کہ تخلیق میں ذکر ہونے والوں کی مدت اور وقت لین کو پہچان لیں۔ FineTempRel کے لئے موجود عمیق سیکھنے کی موڈل میں ایک حصہ گم ہوتا ہے کہ ان کی غلطی ہے کہ ان کے منظور ویکتروں کو ثروت کے لئے وارد ویکتروں کی سینٹکتیک ساختاروں کو استعمال کریں۔ اس کام میں ہم نے یہ فائدہ بھر جانے کی پیشنهاد کرتا ہے تاویل طریقے کے ذریعہ جو فین ٹمپرل کے لئے سینٹکتیک ساختاروں کو سینٹکتیک ساختاروں میں جمع کریں۔ پیغمبر کی مدل دو نوع سینٹاکتیک معلومات پر منتظر ہوتی ہے، یعنی ایڈینٹ کے ذریعہ اہم کلمات کی تعلیم کرنے کے لئے سینٹکس بنیاد اہم اسکور اور سینٹاکتیک اتصال کی تعلیم کرنے کے لئے۔ ہم نے بھی دو نور تکنیک پیش کیے ہیں تاکہ FineTempRel کے معاملات کے درمیان علم کا انتقال آسان کرے، اس کام کے لئے ایک نور مدل کی طرف آئے۔</abstract_ur>
      <abstract_ta>கிடைக்கப்பட்ட தற்காலிக தொடர்பு பிரிப்பு (FineTempRel) உரையில் நிகழ்வு குறிப்பிடும் நேரம் மற்றும் நேரம் வரியின் காலம் மற்ற FineTempRel க்கான தற்போதைய ஆழமான கற்றுக்கொள்ளும் மாதிரிகளில் ஒரு பகுதி காணவில்லை என்பது உள்ளீட்டு வாக்கியங்களின் ஒத்திசைப்படையான உரு இந்த வேலையில், நாம் இந்த இடைவெளியை நிரப்ப விரும்புகிறோம் புதிய முறைமைகளை introduce the syntactic structures to integrate into deep learning models for FineTempRel. முந்திருக்கப்பட்ட மாதிரி சார்ந்த மரங்களில் இருந்து இரண்டு வகையான ஒத்திசைப்படுத்தல் தகவலை குறிப்பிடுகிறது, அதாவது, வார்த்தைகளை கற்றுக் கொள்ளும் முக்கி FineTempRel துணை பணிகளுக்கிடையே அறிவு மாற்றுவதற்கு நாம் இரண்டு புதிய தொழில்நுட்பத்தை கொண்டு வருகிறோம், இந்த பணிக்கு ஒரு புதிய மாதிரியை கொண்</abstract_ta>
      <abstract_uz>@ info: whatsthis Name Bu ishda, biz bu gap tizimni qo'yish uchun novel usullarini ishlatish uchun, sintaktik tuzuvlarini FineTempRel uchun eng yuqori o'rganish modellariga birlashtirish mumkin. Name Biz FineTempRel vazifalari orasidagi ma'lumot uzatishni foydalanishimiz uchun ikkita novel metodini hozir qilamiz. Bu vazifaning davlatning holati-art bajarishi bilan yangi modelga ega bo'ladi.</abstract_uz>
      <abstract_vi>Rút các mối liên hệ thời gian ổn định (FineTempRell) muốn nhận diện các khoảng thời gian và thời gian của sự kiện được đề cập trong văn bản. Một phần thiếu trong các mô hình học sâu của FineTempRell là họ không tận dụng cấu trúc cú pháp của các câu nhập để cải tiến các môi trường đại diện. Trong công việc này, chúng tôi đề nghị lấp đầy khoảng trống này bằng cách tạo ra các phương pháp mới để hoà nhập cấu trúc cú pháp vào các mô hình học sâu của FineTempRell. Người mẫu đã đề nghị tập trung vào hai loại thông tin cú pháp từ cây phụ thuộc, tức là đi ểm quan trọng dựa vào cú pháp để phân tích các từ và kết nối cú pháp để xác định các từ ngữ ngữ ngữ cảnh quan trọng cho sự kiện đề cập. Chúng tôi cũng đưa ra hai kỹ thuật mới để dễ dàng chuyển giao tri thức giữa các phần phụ của FineTempRell, dẫn đến một mô hình mới với các trình diễn hiện đại nhất cho nhiệm vụ này.</abstract_vi>
      <abstract_bg>Финозърнестото извличане на времеви релации (има за цел да разпознае продължителността и времевата линия на споменаването на събития в текста. Липсваща част от настоящите модели за дълбоко учене е неуспехът им да използват синтактичните структури на входните изречения, за да обогатят векторите на представянето. В тази работа предлагаме да се запълни тази празнота чрез въвеждане на нови методи за интегриране на синтактичните структури в моделите на дълбоко обучение за ФинеТемпъл. Предложеният модел се фокусира върху два типа синтактична информация от дърветата на зависимостта, т.е. синтаксисовите оценки за значимост за изучаване на изображението на думите и синтактичните връзки за идентифициране на важни контекстни думи за споменаването на събитието. Представяме и две нови техники за улесняване на трансфера на знания между подзадачите на водещи до нов модел с най-съвременните постижения за тази задача.</abstract_bg>
      <abstract_nl>FineTempRel (FineTempRel) is bedoeld om de duur en tijdlijn van gebeurtenisvermeldingen in tekst te herkennen. Een ontbrekend onderdeel in de huidige deep learning modellen voor FineTempRel is hun falen om de syntactische structuren van de invoerzinnen te exploiteren om de representatievectoren te verrijken. In dit werk stellen we voor om deze kloof op te vullen door nieuwe methoden te introduceren om de syntactische structuren te integreren in de deep learning modellen voor FineTempRel. Het voorgestelde model richt zich op twee soorten syntactische informatie uit de afhankelijkheidsbomen, namelijk de syntaxis-gebaseerde belang scores voor representatie leren van de woorden en de syntactische verbindingen om belangrijke contextwoorden voor de gebeurtenisvermeldingen te identificeren. We presenteren ook twee nieuwe technieken om de kennisoverdracht tussen de subtaken van FineTempRel te vergemakkelijken, wat leidt tot een nieuw model met de state-of-the-art prestaties voor deze taak.</abstract_nl>
      <abstract_id>Ekstrasi hubungan temporal benih (FineTempRel) bertujuan untuk mengenali durasi dan garis waktu peristiwa yang disebutkan dalam teks. A missing part in the current deep learning models for FineTempRel is their failure to exploit the syntactic structures of the input sentences to enrich the representation vectors.  Dalam pekerjaan ini, kami mengusulkan untuk mengisi ruang ini dengan memperkenalkan metode baru untuk mengintegrasikan struktur sintaksi ke dalam model belajar dalam FineTempRel. Model yang diusulkan fokus pada dua jenis informasi sintaks dari pohon dependensi, i.e., skor penting berdasarkan sintaks untuk penemuan pelajaran kata-kata dan koneksi sintaks untuk mengidentifikasi kata-kata konteks penting untuk menyebutkan peristiwa. Kami juga mempersembahkan dua teknik baru untuk memudahkan transfer pengetahuan antara subtasks FineTempRel, yang membawa ke model baru dengan prestasi terbaik untuk tugas ini.</abstract_id>
      <abstract_ko>세분도 시간 관계식 추출(FineTempRel)은 텍스트에서 이벤트에 언급된 기간과 타임라인을 식별하기 위해 설계되었습니다.현재 FineTempRel 딥러닝 모델에서 부족한 부분은 입력 문장의 문법 구조를 이용하여 벡터를 풍부하게 표현하지 못했다는 것이다.이 작업에서, 우리는 새로운 방법을 도입하여 이 공백을 메우고, 문법 구조를 FineTempRel의 심도 있는 학습 모델에 통합하는 것을 건의합니다.이 모델은 주로 트리에 의존하는 두 가지 문법 정보, 즉 문법의 중요성 점수를 바탕으로 단어의 표징 학습에 사용하고 이벤트가 언급한 중요한 상하문 단어를 식별하는 문법 연결에 주목한다.우리는 또한 두 가지 새로운 기술을 제시하여FineTempRel 하위 임무 간의 지식 이동을 추진하고 이 임무를 위해 가장 선진적인 성능을 가진 새로운 모델을 세웠다.</abstract_ko>
      <abstract_hr>FineTempRel ima cilj prepoznati trajanje i vremensku liniju događaja spominjanih u tekstu. Nedostajan dio u trenutnim dubokim modelima učenja za FineTempRel je njihov neuspjeh iskoristiti sintaktičke strukture ulaznih rečenica kako bi obogatili vektore zastupanja. U ovom poslu predlažemo ispuniti taj praznik uvođenjem novih metoda za integraciju sintaktičkih struktura u duboke modele učenja za FineTempRel. Predloženi model se fokusira na dvije vrste sintaktičkih informacija iz drveća ovisnosti, tj. rezultate važnosti na sintaksiji za predstavljanje učenja riječi i sintaktičkih veza kako bi identifikovali važne kontekstske riječi za spominjanje događaja. Također predstavljamo dvije nove tehnike kako bi olakšali prijenos znanja između podmetaka FineTempRel a, koji vodi do novog modela s državnim učinkom umjetnosti za ovaj zadatak.</abstract_hr>
      <abstract_da>Finkornet tidsrelationsekstraktion (FineTempRel) har til formål at genkende varigheden og tidslinjen for begivenhedsnævnelser i tekst. En manglende del i de nuværende deep learning modeller for FineTempRel er deres manglende udnyttelse af de syntaktiske strukturer i input sætninger til at berige repræsentationsvektorer. I dette arbejde foreslår vi at udfylde dette hul ved at introducere nye metoder til at integrere de syntaktiske strukturer i deep learning modellerne for FineTempRel. Den foreslåede model fokuserer på to typer syntaktiske oplysninger fra afhængighedstræerne, dvs. de syntaksbaserede vigtighedspoint for repræsentation læring af ordene og de syntaktiske forbindelser for at identificere vigtige kontekstord for begivenhedens nævnelser. Vi præsenterer også to nye teknikker til at lette vidensoverførslen mellem underopgaverne i FineTempRel, hvilket fører til en ny model med state-of-the-art performance til denne opgave.</abstract_da>
      <abstract_de>FineTempRel (FineTempRel) zielt darauf ab, die Dauer und Timeline von Ereigniserwähnungen im Text zu erkennen. Ein fehlender Teil in den aktuellen Deep Learning Modellen für FineTempRel ist ihr Versagen, die syntaktischen Strukturen der Eingabesätze zu nutzen, um die Repräsentationsvektoren anzureichern. In dieser Arbeit schlagen wir vor, diese Lücke zu schließen, indem wir neuartige Methoden zur Integration der syntaktischen Strukturen in die Deep Learning Modelle für FineTempRel einführen. Das vorgeschlagene Modell konzentriert sich auf zwei Arten von syntaktischen Informationen aus den Abhängigkeitsbäumen, d.h. die syntaxbasierten Wichtigkeitsscores für das Darstellungslernen der Wörter und die syntaktischen Verbindungen, um wichtige Kontextwörter für die Ereigniserwähnungen zu identifizieren. Außerdem stellen wir zwei neuartige Techniken vor, um den Wissenstransfer zwischen den Teilaufgaben von FineTempRel zu erleichtern, was zu einem neuartigen Modell mit dem neuesten Stand der Technik für diese Aufgabe führt.</abstract_de>
      <abstract_sw>Utoa wa mahusiano ya muda mzuri (FineTempRel) unalenga kutambua muda na mfululizo wa kutajwa kwa matukio. A missing part in the current deep learning models for FineTempRel is their failure to exploit the syntactic structures of the input sentences to enrich the representation vectors.  Katika kazi hii, tunapendekeza kulijaza gaidi hili kwa kuanzisha njia za riwaya ili kuunganisha muundo wa pamoja katika miundo ya kujifunza kwa ajili ya FineTempRel. Mfano huu unapendekezwa unajikita kwenye aina mbili ya taarifa za ushirikiano kutoka kwenye miti ya kutegemea, yaani, vipimo muhimu vya umuhimu kwa kuwakilisha kujifunza maneno na viungo vya ushirikiano ili kutambua maneno muhimu ya muktadha wa tukio hilo. Pia tunaweka mbinu mbili za riwaya ili kusaidia usafirishaji wa maarifa kati ya kazi za FineTempRel, na kuongoza mifano ya riwaya yenye hali ya sanaa kwa kazi hii.</abstract_sw>
      <abstract_tr>FineTempRel FineTempRel için ağımdaki derin öğrenme modellerindeki bir parça ifade edilen vektörlerini zengin etmek için sintaktik yapılarını kullanmadı. Bu işde biz bu gaplary FineTempRel üçin sintaktik düzgünlerini gol öwrenmek nusgalaryna taýýarlap, novel yönlerden doldurmagy teklip edýäris. Önerleven nusga daşary agaçlardan iki hili sintaktik maglumaty oňa üns bermek üçin syntaks tabanly möhüm notlary we syntaks baglaýyşlaryny olar barada möhüm kontekst sözleri tanyşdyrmak üçin guruldyrylýar Biz hem FineTempRel subtaskalarynyň arasynda bilim transferini kömek etmek üçin iki roman teknikini görkeýäris, bu işiň durumynda ýazgyt eserleşmesi bilen nowelläk nusgasyna gidirýäris.</abstract_tr>
      <abstract_af>Fine- grained tydelike verwanting uitpakking (FineTempRel) doel om die duur en tydline van gebeurtenis in teks te herken. Name In hierdie werk, voorstel ons om hierdie afstand te vul deur novele metodes te introduseer om die sintaktieke strukture in die diepe leer modele vir FineTempRel te integreer. Die voorgestelde model fokus op twee tipes sintaktika inligting van die afhanklikheidsboom, t.d. die sintaks-gebaseerde belangrike punte vir voorstelling leer van die woorde en die sintaktika verbindings om belangrike kontekswoorde te identifiseer vir die gebeurtenis bepaal. Ons stel ook twee nuwe teknike voor om die kennis oordrag tussen die subtaske van FineTempRel te maak, wat na 'n nuwe model lei met die staat-van-kunstens-prestasie vir hierdie taak.</abstract_af>
      <abstract_fa>استخراج رابطه موقتی (FineTempRel) با دانه‌های پاکیزه، هدف می‌دهد تا مدت و خط زمانی رویداد که در متن می‌گویند را شناسایی کند. یک بخش گم شده در مدل یادگیری عمیق فعلی برای FineTempRel است که شکست آنها در استفاده از ساختارهای سنتاکتیک از جمله‌های ورودی برای ثروت کردن ویکتورهای نمایش است. در این کار، ما پیشنهاد می کنیم که این فاصله را پر کنیم با توجه به روش‌های نویسی تا ساختمان‌های سنتاکتیک را به مدل‌های یادگیری عمیق برای FineTempRel متصل کنیم. مدل پیشنهاد بر دو نوع اطلاعات سنتاکتیک از درختان بستگی تمرکز می‌کند، یعنی امتیاز مهم بر اساس سنتاکس برای یادگیری از کلمات و ارتباطات سنتاکتیک برای شناسایی کلمات محیط مهم برای یادگیری از رویداد. ما همچنین دو تکنیک رمانی را برای آسانی انتقال علم بین زیرپاسهای FineTempRel پیشنهاد می‌کنیم، که به یک مدل رمانی با انجام وضعیت هنری برای این کار رخ می‌دهد.</abstract_fa>
      <abstract_sq>Ekstracioni i lidhjes së përkohshme me kokrra të holla (FineTempRel) synon të njohë gjatësinë dhe afatin e kohës të përmendimeve të ngjarjeve në tekst. A missing part in the current deep learning models for FineTempRel is their failure to exploit the syntactic structures of the input sentences to enrich the representation vectors.  Në këtë punë, propozojmë të mbushim këtë boshllëk duke paraqitur metoda të reja për të integruar strukturat sintaktike në modelet e mësimit të thellë për FineTempRel. Modeli i propozuar përqëndrohet në dy lloje informacioni sintaktik nga pemët e varësisë, i.e., rezultatet e rëndësishme të bazuara në sintaks për përfaqësimin e mësimit të fjalëve dhe lidhjeve sintaktike për të identifikuar fjalë të rëndësishme konteksti për përmendimet e ngjarjes. Ne prezantojmë gjithashtu dy teknika të reja për të lehtësuar transferimin e njohurive midis nëndetyrave të FineTempRel, duke çuar në një model të ri me shfaqjen më të lartë për këtë detyrë.</abstract_sq>
      <abstract_am>የአሁኑን ፋይል አስቀምጥ የአሁኑ ጥልቅ ትምህርት ዓይነቶች ለFineTempRel የሚጠቅመው ክፍል የኢንተርኔት መክፈቻን በመጠቀም አይቻልላቸውም፡፡ በዚህ ስራ፣ የነጥብ ሥርዓቶች ለFineTempRel ጥልቅ ትምህርት ሞዴላዎችን ለመቀላቀል እናስፈልጋለን፡፡ በተዘጋጀው ሞዴል በተጠቃሚ ዛፎች ላይ ሁለት ዓይነት የSyntactic መረጃዎችን ያስተካክላል፤ ምናልባት ቃሎችን ለመማር እና የግንኙነቱን ጠንካራዊ ቃል ለማግኘት የሲንካስብ ግንኙነት እና ለመግለጫ ያስተካክሎታል፡፡ የፊንTempRel ጉዳዮች መካከል ማስታወቂያውን ለማቀናቀል ሁለት የመረጃ ዘዴኖች እናደርጋለን፤ ለዚህም ስራ የ-አርእስት ሥርዓት አካባቢ አካባቢ እናደርጋለን፡፡</abstract_am>
      <abstract_hy>FineTextComment FineTEMPREL-ի ներկայիս խորը ուսումնասիրության մոդելների բացակայությունը նրանում է, որ նրանք չեն օգտագործում ներկայացված նախադասությունների սինտակտիկ կառուցվածքները ներկայացման վեկտորների հարստացման համար: Այս աշխատանքի ընթացքում մենք առաջարկում ենք լրացնել այս բացը ներկայացնելով նոր մեթոդներ, որոնք օգնում են ինտեգրել սինտակտիկ կառուցվածքները FineTEMPREL-ի խորը ուսումնասիրության մոդելների մեջ: Առաջարկված մոդելը կենտրոնանում է կախվածության ծառերից երկու տեսակի սինտակտիկ տեղեկատվության վրա, այսինքն, սինտաքսի հիմնված կարևորության գնահատականների վրա բառերի և սինտակտիկ կապերի ներկայացման համար, որպեսզի բառերի կարևոր կոնտեքստի բառերը Մենք նաև ներկայացնում ենք երկու նոր տեխնիկա, որպեսզի հեշտացնենք գիտելիքների փոխանցումը FineTEMPREL ենթախնդիրների միջև, ինչը հանգեցնում է նոր մոդելի, որն ունի այս խնդրի համար ամենաբարձր արդյունքներ:</abstract_hy>
      <abstract_az>FineTempRel mətndə danışan vaxt səviyyəsini və vaxt səviyyəsini tanımmaq məqsədilə gözləyir. FineTempRel üçün ağımdaki derin öyrənmə modellərində küfr edilən bir parçası göstəricisi vektörlərini zənginləymək üçün giriş cümlələrinin sintaktik quruluşlarını istifadə etməkdir. Bu işdə, biz bu boşluğu FineTempRel üçün sintaktik yapıları çoxlu öyrənmə modellərinə birləşdirmək üçün yeni metodları ilə doldurmağı təklif edirik. Önülləşdirilmiş modellər bağımlılıq ağaclarından iki növ sintaktik məlumatlarına odaqlanır, məsələn, sözlərin öyrənməsini və sintaktik bağlantıları təsdiqlənmək üçün sintaks tabanlı möhüm məlumatlarını təsdiqləyir. Biz də FineTempRel aparıcıların arasındakı bilgi transferisini asanlaşdırmaq üçün iki yeni tekniki təklif edirik, bu iş üçün yeni bir model göstərir.</abstract_az>
      <abstract_ca>L'extracció de relació temporal fina (FineTempRel) té l'objectiu de reconèixer les duracions i la línia de temps de les mencions d'eventos en el text. Una part que falta en els models actuals d'aprenentatge profund de FineTempRel és el seu fracàs d'explotar les estructures sinàctiques de les frases d'entrada per enriquecer els vectors de representació. En aquesta feina, proposem llençar aquest buit introduint nous mètodes per integrar les estructures sinàctiques als models d'aprenentatge profund de FineTempRel. El model proposat es centra en dos tipus d'informació sinàctica dels arbres de dependencia, és a dir, les puntuacions d'importància basades en la sintaxi per l'aprenentatge de representació de les paraules i les connexions sinàctiques per identificar paraules contextuals importants per a les mencions d'eventos. També presentem dues noves tècniques per facilitar la transfer ència de coneixement entre les subtaskes de FineTempRel, portant a un model novel amb l'actuació més avançada d'aquesta tasca.</abstract_ca>
      <abstract_cs>Jemnozrnná extrakce časových vztahů (FineTempRel) má za cíl rozpoznat trvání a časovou osu zmínek událostí v textu. Chybějící součástí současných modelů hlubokého učení pro FineTempRel je jejich neschopnost využít syntaktické struktury vstupních vět k obohacení reprezentačních vektorů. V této práci navrhujeme vyplnit tuto mezeru zavedením nových metod pro integraci syntaktických struktur do modelů hlubokého učení pro FineTempRel. Navržený model se zaměřuje na dva typy syntaktických informací ze stromů závislostí, tj. syntaktické skóre důležitosti pro reprezentaci učení slov a syntaktické spojení pro identifikaci důležitých kontextových slov pro zmínky události. Dále představujeme dvě nové techniky pro usnadnění přenosu znalostí mezi dílčími úkoly FineTempRel, což vede k novému modelu s nejmodernějším výkonem pro tento úkol.</abstract_cs>
      <abstract_bn>ভালো গ্রেফতার করা সময়ের সংযোগ বিনিময় (FineTempRel) লক্ষ্য হচ্ছে টেক্সটে অনুষ্ঠান উল্লেখ করার সময় ও সময় লাইন চিনতে পারে। ফিনেটেমপ্রিলের জন্য বর্তমান গভীর শিক্ষার মডেলে একটি হারিয়ে যাওয়া অংশ হচ্ছে তাদের প্রতিনিধিত্বের ভেক্টর সমৃদ্ধ করার জন্য ইনপুটের বাক এই কাজের মধ্যে আমরা প্রস্তাব করছি এই ভূমিকা পূর্ণ করার মাধ্যমে উপন্যাসের মাধ্যমে সাধারণ কাঠামোগুলোকে গভীর শিক্ষার মডেলে যুক্ত করার The proposed model focuses on two types of syntactic information from the dependency trees, i.e., the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important context words for the event mentions.  এছাড়াও আমরা ফিনেট টেমপ্রিলের সাবটার্কের মধ্যে জ্ঞান পরিবর্তনের সুবিধা প্রদানের দুটি উপযুক্ত কৌশল উপস্থাপন করি, যার ফলে এই কাজের রাষ্ট্র-অফ</abstract_bn>
      <abstract_fi>FineTempRel (FineTempRel) pyrkii tunnistamaan tapahtumamainintojen keston ja aikajanan tekstissä. FineTempRelin nykyisistä syväoppimisen malleista puuttuu se, että ne eivät pysty hyödyntämään syöttölauseiden syntaktisia rakenteita esitysvektorien rikastamiseksi. Tässä työssä ehdotamme tämän aukon täyttämistä ottamalla käyttöön uusia menetelmiä, joilla syntaktiset rakenteet voidaan integroida FineEmpRelin syväoppimisen malleihin. Ehdotettu malli keskittyy kahdentyyppisiin riippuvuuspuiden syntaktisiin tietoihin eli syntaksipohjaisiin merkittävyyspisteisiin sanojen representaatiooppimisessa ja syntaktisiin yhteyksiin tärkeiden asiasanojen tunnistamiseksi tapahtumamaininnoille. Esittelemme myös kaksi uutta tekniikkaa, jotka helpottavat tiedonsiirtoa FineTempRelin alitehtävien välillä ja johtavat uudenlaiseen malliin, jossa on tähän tehtävään uusinta suorituskykyä.</abstract_fi>
      <abstract_bs>FineTempRel ima cilj prepoznati trajanje i vremensku liniju događaja spominjanih u tekstu. Nedostajan dio u trenutnim dubokim modelima učenja za FineTempRel je njihov neuspjeh iskoristiti sintaktičke strukture ulaznih rečenica da bi obogatili vektore predstavljanja. U ovom poslu predlažemo da napunimo taj praznik uvođenjem novih metoda da integrišemo sintaktičke strukture u duboke modele učenja za FineTempRel. Predloženi model se fokusira na dvije vrste sintaktičkih informacija iz drveća zavisnosti, tj. rezultate važnosti na sintaksiji za predstavljanje učenja riječi i sintaktičkih veza za identifikaciju važnih kontekstskih riječi za spominjanje događaja. Također predstavljamo dvije nove tehnike kako bi olakšali prijenos znanja između poduzeća FineTempRela, koji vodi do novog modela sa stanjem umjetnosti za ovaj zadatak.</abstract_bs>
      <abstract_et>Peeneteralise ajalise seose ekstraheerimise (FineTempRel) eesmärk on tuvastada sündmuste märkimise kestust ja ajajoont tekstis. FineTempReli praeguste sügavõppe mudelite puuduv osa on nende suutmatus kasutada sisendlausete süntaktilisi struktuure esitusvektorite rikastamiseks. Selles töös teeme ettepaneku täita see lünk, tutvustades uudseid meetodeid süntaktiliste struktuuride integreerimiseks FineTempReli sügavõppe mudelitesse. Kavandatud mudel keskendub kahele süntaktilisele informatsioonile sõltuvuspuudest, s.o süntaksipõhisele tähtsusskoorile sõnade esindamise õppimiseks ja süntaktilistele seostele sündmuse märkimise oluliste kontekstisõnade tuvastamiseks. Samuti tutvustame kahte uudset tehnikat, mis hõlbustavad teadmiste edasiandmist FineTempReli alamülesannete vahel, mis viivad uudse mudelini, millel on selle ülesande jaoks kaasaegsed tulemused.</abstract_et>
      <abstract_ha>Socket error code ConnectionTimeout Wani rabon da ba'a gane ba cikin misãlai masu sanar da kai yanzu wa FineTempRel na kasa yin amfani da tsarin tsarin da aka shigar da shi ga masu motsi. Daga wannan aikin, Munã kwaɗayin mu cika wannan gap da za'a introduce metoden nohanna dõmin su haɗa tsarin da ake yi syntactic cikin misãlai masu ƙari da aka sani wa FineTempRel. @ action: button Kuma kamar haka, Muke ƙayyade masu hanyoyi biyu ta hanyoyi dõmin ka sauƙa ƙara transfer da ilmi a tsakanin task õkin FineTempRel, kuma ke ƙara wani motel na novela da halin-da-sanar wa wannan aikin.</abstract_ha>
      <abstract_sk>FineTempRel (FineTempRel) je namenjen prepoznavanju trajanja in časovne linije omenjanja dogodkov v besedilu. Manjkajoč del trenutnih modelov globokega učenja za FineTempRel je njihovo neuspešno izkoriščanje sintaktičnih struktur vhodnih stavkov za obogatitev vektorjev reprezentacije. V tem delu predlagamo zapolnitev te vrzeli z uvedbo novih metod za vključitev sintaktičnih struktur v modele globokega učenja FineTempRel. Predlagani model se osredotoča na dve vrsti sintaktičnih informacij iz dreves odvisnosti, tj. na sintaksno osnovane ocene pomembnosti za učenje reprezentacije besed in sintaktične povezave za identifikacijo pomembnih kontekstnih besed za omenjanje dogodka. Predstavljamo tudi dve novi tehniki za olajšanje prenosa znanja med podnalogami FineTempRel, ki vodijo do novega modela z najsodobnejšo izvedbo za to nalogo.</abstract_sk>
      <abstract_he>חוטפת מערכת יחסים זמנית מעולה (FineTempRel) מתכוונת לזהות את התקופה וקו הזמן של הזכרות של אירועים בטקסט. חלק חסר במודלים הלימודים העמוקים הנוכחים של FineTempRel הוא הכישלון שלהם לנצל את מבנים הסינטקטיים של משפטי הכניסה בעבודה הזו, אנו מציעים למלא את הפער הזה בכך שהציגנו שיטות חדשות כדי להשתלב את המבנים הסינטקטיים לדוגמאות הלימודים העמוקים של FineTempRel. The proposed model focuses on two types of syntactic information from the dependency trees, i.e., the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important context words for the event mentions.  אנחנו גם מציגים שתי טכניקות חדשות כדי להקל את העברת הידע בין השאלות של FineTempRel, שמובילות למודל חדש עם ההופעה המאודמת למשימה הזאת.</abstract_he>
      <abstract_jv>FineTime Rel A error message Nang barêng-barêng iki, kita unêmên nggawe gap iki dadi ngewehku perusahaan anyari bagian sing bisa ngubah sampek simbol sing sampek bantuan kanggo model model model model sing nggawe FineTime Rel. Model sing supoyo macem nang karo sistem sing dibutuhke informasi sistem sing wis dipun Awak dhéwé éntuk sistem durung sing nyumbang kanggo ngejaraké kesempatan ning mbukakipun tarjamahan kanggo tarjamahan FineTime Rel, nambah dhéwé modèl kanggo kalawartané state-of-the-arts nggawe mungkin iki.</abstract_jv>
      <abstract_bo>Fine-grained temporal relation extraction (FineTempRel) aims to recognize the durations and timeline of event mentions in text. A missing part in the current deep learning models for FineTempRel is their failure to exploit the syntactic structures of the input sentences to enrich the representation vectors. In this work, we propose to fill this gap by introducing novel methods to integrate the syntactic structures into the deep learning models for FineTempRel. The proposed model focuses on two types of syntactic information from the dependency trees, i.e. the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important context words for the event mentions. Examples: ང་ཚོས་ཀྱང་གསར་གཏོད་ཀྱི་ཐབས་ལམ་གཉིས་ཀྱང་དབྱིབས་ཆེན་དུ་FineTempRel་ཡི་subtasks་དབར་གྱི་གནས་སྟངས་ལ་སྐྱེལ་འདྲེན་དང་། འདི་ནི་བྱ་འགུལ་འདིའི་གནས་སྟངས</abstract_bo>
      </paper>
    <paper id="9">
      <title>A Text Editing Approach to Joint Japanese Word Segmentation, <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">POS Tagging</a>, and Lexical Normalization<fixed-case>J</fixed-case>apanese Word Segmentation, <fixed-case>POS</fixed-case> Tagging, and Lexical Normalization</title>
      <author><first>Shohei</first><last>Higashiyama</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Taro</first><last>Watanabe</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>67–80</pages>
      <abstract>Lexical normalization, in addition to <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a> and <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>, is a fundamental task for Japanese user-generated text processing. In this paper, we propose a text editing model to solve the three task jointly and methods of pseudo-labeled data generation to overcome the problem of data deficiency. Our experiments showed that the proposed <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> achieved better <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> performance when trained on more diverse pseudo-labeled data.</abstract>
      <url hash="16c82883">2021.wnut-1.9</url>
      <bibkey>higashiyama-etal-2021-text</bibkey>
      <doi>10.18653/v1/2021.wnut-1.9</doi>
    <title_ar>أسلوب تحرير النص لتجزئة الكلمات اليابانية المشتركة ، وعلامات نقاط البيع ، والتطبيع المعجمي</title_ar>
      <title_pt>Uma abordagem de edição de texto para segmentação conjunta de palavras em japonês, marcação POS e normalização léxica</title_pt>
      <title_es>Un enfoque de edición de texto para la segmentación conjunta de palabras en japonés, el etiquetado de PDV y la normalización léxica</title_es>
      <title_fr>Une approche d'édition de texte pour la segmentation conjointe des mots japonais, le balisage POS et la normalisation lexicale</title_fr>
      <title_ja>共同日本語の単語セグメンテーション、POSタグ付け、および正規化へのテキスト編集アプローチ</title_ja>
      <title_zh>一以合日语分词、POS 标、词法规范化文本辑法</title_zh>
      <title_ru>Подход текстового редактирования к совместной сегментации японского слова, маркировке POS и лексической нормализации</title_ru>
      <title_hi>संयुक्त जापानी वर्ड सेगमेंटेशन, पॉस टैगिंग और लेक्सिकल सामान्यीकरण के लिए एक पाठ संपादन दृष्टिकोण</title_hi>
      <title_ga>Cur Chuige Eagarthóireachta Téacs maidir le Comhdheighilt Focal Seapánach, Clibeáil POS, agus Normalú Foclóra</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Μια προσέγγιση επεξεργασίας κειμένου για κοινή ιαπωνική τμηματοποίηση λέξεων, επισήμανση και Lexical Normalization</title_el>
      <title_hu>Szövegszerkesztési megközelítés a közös japán szószegmentációhoz, POS-címkézéshez és Lexikai Normalizációhoz</title_hu>
      <title_it>Un approccio di modifica del testo alla segmentazione congiunta giapponese delle parole, all'etichettatura POS e alla normalizzazione lessicale</title_it>
      <title_lt>Tekstų redagavimo metodas jungtinei Japonijos žodžių segmentacijai, POS ženklinimui ir leksiniam normalizavimui</title_lt>
      <title_mk>Name</title_mk>
      <title_kk>Жапон сөз сегментациясының, POS тегтері және лексикалық нормализациясының мәтінді өңдеу қатынасы</title_kk>
      <title_ms>Name</title_ms>
      <title_ml>ജാപ്പാനീസ് വാക്ക് സങ്കല്‍പ്പിക്കുന്നതിനും പോസ് ടാഗ്ഗിങ്ങും ലെക്സിക്കല്‍ നോര്‍മിലേഷനും</title_ml>
      <title_mt>Approċċ għall-Edizzjoni tat-Test għas-Segmentazzjoni Konġunta tal-Kliem Ġappuniżi, it-Tagging POS, u n-Normalizzazzjoni Lessika</title_mt>
      <title_mn>Нэгдсэн Японы үг Segmentation, POS Tagging, Lexical Normalization</title_mn>
      <title_no>Name</title_no>
      <title_ro>O abordare de editare a textului pentru segmentarea comună japoneză a cuvintelor, etichetarea POS și normalizarea lexicală</title_ro>
      <title_pl>Podejście do edycji tekstu do wspólnej segmentacji japońskich słów, tagowania POS i normalizacji leksykalnej</title_pl>
      <title_sr>Pristup editiranja teksta za zajedničku japansku segmentaciju riječi, označavanje POS-a i leksičku normalizaciju</title_sr>
      <title_so>A Text Editing Approach to Joint Japanese Word Segmentation, POS Tagging, and Lexical Normalization</title_so>
      <title_sv>En textredigeringsmetod för gemensam japansk ordsegmentering, POS-märkning och Lexical Normalisering</title_sv>
      <title_si>Name</title_si>
      <title_ta>A Text Editing Approach to Joint Japanese Word Segmentation, POS Tagging, and Lexical Normalization</title_ta>
      <title_ur>Name</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Một phương pháp sửa soạn văn bản cho đoạn ghi chép bằng văn bản, thẻ vị trí và chỉnh hoá ngôn ngữ.</title_vi>
      <title_bg>Подход за редактиране на текст към съвместна японска сегментация на думи, етикетиране и лексикална нормализация</title_bg>
      <title_nl>Een tekstbewerkingsaanpak voor gezamenlijke Japanse woordsegmentatie, POS-tagging en Lexische normalisatie</title_nl>
      <title_hr>Pristup uredbe teksta za zajedničku japansku segmentaciju riječi, označavanje POS-a i leksičku normalizaciju</title_hr>
      <title_da>En tekstredigeringsmetode til fælles japansk ordsegmentering, POS-mærkning og Lexical Normalisering</title_da>
      <title_id>Penyunting Teks Mendekati Segmentasi Perkataan Jepang, Tagging POS, dan Normalisasi Lexik</title_id>
      <title_de>Ein Textbearbeitungsansatz zur gemeinsamen japanischen Wortsegmentierung, POS-Tagging und Lexikal Normalisierung</title_de>
      <title_fa>Name</title_fa>
      <title_ko>일본어 분사, 어성 표기, 어휘 규범화에 사용되는 텍스트 편집 방법</title_ko>
      <title_sw>Mhariri wa maandishi Inakaribia kuunganisha neno la Japani, Uchaguzi wa POS, na Udhalilishaji wa Kilexico</title_sw>
      <title_tr>Japonça söz segmentasiýasy, POS etiketlemesi we Leksik Devamlamasi üçin Metin Editlemesi ýakynlaşýar</title_tr>
      <title_af>Name</title_af>
      <title_sq>A Text Editing Approach to Joint Japanese Word Segmentation, POS Tagging, and Lexical Normalization</title_sq>
      <title_am>የጽሑፍ ማቀናጃ ወደ Joint Japanese Word Segmentation, POS Tagging and Lexical Normalization</title_am>
      <title_hy>Comment</title_hy>
      <title_az>Bir Yaponca Sözlük Segmentasyonu, POS Tagging və Leksik Normalizasyonu üçün Metin Editing Approach</title_az>
      <title_bn>জাপানি শব্দ বিভাগ, পোস ট্যাগিং এবং লেক্সিকাল স্বাভাবিক</title_bn>
      <title_bs>Pristup editiranja teksta za zajedničku japansku segmentaciju riječi, označavanje POS-a i leksičku normalizaciju</title_bs>
      <title_ca>Un enfocament d'edició de textos a la segmentació de paraules japoneses conjuntes, etiqueta POS i normalització lèxica</title_ca>
      <title_cs>Přístup k úpravám textu ke společné segmentaci japonských slov, značení POS a Lexikální normalizaci</title_cs>
      <title_et>Teksti redigeerimise lähenemisviis Jaapani sõnasegmentatsioonile, POS-märgistusele ja leksilisele normaliseerimisele</title_et>
      <title_fi>Tekstin muokkausmenetelmä japanilaiseen sanasegmentointiin, POS-merkintään ja lexikaaliseen normalisointiin</title_fi>
      <title_he>הגישה לעוררת טקסטים לשיתוף מילים יפני משותף, תגים POS, ונורמליזציה לקסיקה</title_he>
      <title_jv>text-editor-action</title_jv>
      <title_bo>ཡི་གེ་ཞུན་བསྒྱུར་བཅོས་ཀྱི་མཐུན་སྒྲིག་ཉེན་ཡིག་གི་ཚིག་ཆ་སྒྲིག་དང་། POS Tagging, and Lexical Normalization</title_bo>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Pristop za urejanje besedila za skupno japonsko segmentacijo besed, označevanje POS in leksično normalizacijo</title_sk>
      <abstract_pt>A normalização léxica, além da segmentação de palavras e marcação de parte da fala, é uma tarefa fundamental para o processamento de texto gerado pelo usuário japonês. Neste artigo, propomos um modelo de edição de texto para resolver as três tarefas em conjunto e métodos de geração de dados pseudo-rotulados para superar o problema de deficiência de dados. Nossos experimentos mostraram que o modelo proposto obteve melhor desempenho de normalização quando treinado em dados pseudo-rotulados mais diversos.</abstract_pt>
      <abstract_ar>يعد التطبيع المعجمي ، بالإضافة إلى تجزئة الكلمات وعلامات جزء من الكلام ، مهمة أساسية لمعالجة النصوص التي ينشئها المستخدمون اليابانيون. في هذه الورقة ، نقترح نموذجًا لتحرير النص لحل المهام الثلاث بشكل مشترك وطرق توليد البيانات ذات العلامات الزائفة للتغلب على مشكلة نقص البيانات. أظهرت تجاربنا أن النموذج المقترح حقق أداء تطبيع أفضل عند تدريبه على بيانات أكثر تنوعًا ذات علامات زائفة.</abstract_ar>
      <abstract_es>La normalización léxica, además de la segmentación de palabras y el etiquetado de partes del habla, es una tarea fundamental para el procesamiento de textos generados por los usuarios japoneses. En este artículo, proponemos un modelo de edición de texto para resolver las tres tareas de forma conjunta y métodos de generación de datos pseudoetiquetados para superar el problema de la deficiencia de datos. Nuestros experimentos mostraron que el modelo propuesto logró un mejor rendimiento de normalización cuando se entrenó con datos pseudoetiquetados más diversos.</abstract_es>
      <abstract_fr>La normalisation lexicale, en plus de la segmentation des mots et du balisage des parties du discours, est une tâche fondamentale pour le traitement de texte généré par les utilisateurs japonais. Dans cet article, nous proposons un modèle d'édition de texte pour résoudre conjointement les trois tâches et des méthodes de génération de données pseudo-étiquetées pour surmonter le problème de la déficience des données. Nos expériences ont montré que le modèle proposé permettait d'obtenir de meilleures performances de normalisation lorsqu'il était entraîné sur des données pseudo-marquées plus diverses.</abstract_fr>
      <abstract_ja>単語のセグメンテーションや音声タグ付けに加えて、語彙の正規化は、日本語のユーザー生成テキスト処理の基本的な作業です。本稿では、3つの課題を共同で解決するテキスト編集モデルと、データ不足の問題を克服するための擬似ラベルデータ生成の手法を提案する。我々の実験は、提案されたモデルが、より多様な擬似標識データで訓練されたときに、より良い正規化パフォーマンスを達成したことを示した。</abstract_ja>
      <abstract_zh>自分词、词性之外,词法规范化犹日语用户成之本务也。 本文举一本编模,共解三务及伪标数生成之法,以克数不足。 臣等实验明,所陈模形,于更多样化伪标数训练,以成归一化性。</abstract_zh>
      <abstract_ru>Лексическая нормализация, в дополнение к сегментации слов и частичной пометке речи, является фундаментальной задачей для японской пользовательской обработки текста. В данной работе мы предлагаем модель редактирования текста для совместного решения трех задач и методы генерации псевдомеченных данных для преодоления проблемы дефицита данных. Наши эксперименты показали, что предлагаемая модель достигла лучших показателей нормализации при обучении на более разнообразных псевдомеченых данных.</abstract_ru>
      <abstract_hi>लेक्सिकल सामान्यीकरण, शब्द विभाजन और पार्ट-ऑफ-स्पीच टैगिंग के अलावा, जापानी उपयोगकर्ता-जनित पाठ प्रसंस्करण के लिए एक मौलिक कार्य है। इस पेपर में, हम डेटा की कमी की समस्या को दूर करने के लिए संयुक्त रूप से तीन कार्य और छद्म लेबल वाले डेटा पीढ़ी के तरीकों को हल करने के लिए एक पाठ संपादन मॉडल का प्रस्ताव करते हैं। हमारे प्रयोगों से पता चला है कि प्रस्तावित मॉडल ने अधिक विविध छद्म लेबल वाले डेटा पर प्रशिक्षित होने पर बेहतर सामान्यीकरण प्रदर्शन हासिल किया।</abstract_hi>
      <abstract_ga>Is tasc bunúsach é normalú foclóireachta, chomh maith le deighilt focal agus clibeáil pháirteach cainte, do phróiseáil téacs a ghineann úsáideoirí na Seapáine. Sa pháipéar seo, molaimid múnla eagarthóireachta téacs chun na trí thasc a réiteach i gcomhpháirt agus modhanna giniúna sonraí lipéadaithe pseudo chun fadhb an easnaimh sonraí a shárú. Léiríodh inár dturgnaimh gur bhain an tsamhail bheartaithe feidhmíocht normalaithe níos fearr amach nuair a cuireadh oiliúint ar shonraí bréige-lipéadaithe níos éagsúla.</abstract_ga>
      <abstract_el>Η λεξική εξομάλυνση, εκτός από την κατάτμηση λέξεων και την επισήμανση μέρους ομιλίας, αποτελεί θεμελιώδη εργασία για την επεξεργασία κειμένου που δημιουργείται από τους χρήστες της Ιαπωνίας. Στην παρούσα εργασία, προτείνουμε ένα μοντέλο επεξεργασίας κειμένου για την επίλυση των τριών καθηκόντων από κοινού και μεθόδους δημιουργίας ψευδομαρτωμένων δεδομένων για την αντιμετώπιση του προβλήματος της ανεπάρκειας δεδομένων. Τα πειράματά μας έδειξαν ότι το προτεινόμενο μοντέλο πέτυχε καλύτερη απόδοση ομαλοποίησης όταν εκπαιδεύτηκε σε πιο διαφορετικά ψευδο-σημαδεμένα δεδομένα.</abstract_el>
      <abstract_hu>A lexikai normalizálás a szószegmentálás és a beszédrész címkézés mellett alapvető feladat a japán felhasználók által generált szövegfeldolgozás számára. Ebben a tanulmányban egy szövegszerkesztési modellt javasolunk a három feladat közös megoldására, valamint a pszeudo jelölésű adatgyártás módszereit javasoljuk az adathiány problémájának leküzdésére. Kísérleteink azt mutatták, hogy a javasolt modell jobb normalizációs teljesítményt ért el, ha sokszínűbb pszeudo-címkézett adatokra képzett.</abstract_hu>
      <abstract_it>La normalizzazione lessicale, oltre alla segmentazione delle parole e al tag part-of-speech, è un compito fondamentale per l'elaborazione del testo generato dagli utenti giapponesi. In questo articolo, proponiamo un modello di editing del testo per risolvere congiuntamente i tre compiti e metodi di generazione di dati pseudo-etichettati per superare il problema della carenza di dati. I nostri esperimenti hanno dimostrato che il modello proposto ha raggiunto migliori prestazioni di normalizzazione quando addestrato su dati pseudo-etichettati più diversi.</abstract_it>
      <abstract_lt>Leksinė normalizacija, be žodžių segmentacijos ir kalbos dalies žymėjimo, yra pagrindinė Japonijos naudotojų sukurto teksto apdorojimo užduotis. Šiame dokumente siūlome teksto redakcijos model į, kuris padėtų išspręsti tris užduotis kartu ir pseudo ženklintų duomenų kūrimo metodus, kad būtų pašalinta duomenų trūkumo problem a. Mūsų eksperimentai parodė, kad siūlomas modelis pasiekė geresnius normalizavimo rezultatus, mokydamas įvairiausius pseudo ženklintus duomenis.</abstract_lt>
      <abstract_kk>Лексикалық нормализация, сөздердің сегментациясы мен сөздердің бір бөлігіне қосып, япония пайдаланушыларды жасаған мәтін процесінің негізгі тапсырмасы. Бұл қағазда, мәтін өңдеу үлгісін біріктіру үшін, псевдо- жарлық деректерді құру әдістерін өзгерту үшін мәтін өңдеу үлгісін таңдаймыз. Біздің тәжірибеміз келтірілген модель көптеген псевдо жарлық деректеріне оқылған кезде жақсы нормализациялау мүмкіндігін жеткізгенін көрсетті.</abstract_kk>
      <abstract_mk>Лексикалната нормализација, покрај сегментацијата на зборовите и означувањето на делот од говорот, е фундаментална задача за јапонското преработување на текст генерирано од корисниците. Во овој весник предлагаме модел за уредување на текст за заедничко решавање на трите задачи и методите на генерација на псевдо-означени податоци за надминување на проблемот со недостатокот на податоци. Our experiments showed that the proposed model achieved better normalization performance when trained on more diverse pseudo-labeled data.</abstract_mk>
      <abstract_ms>Normalisasi leksikal, selain segmentasi perkataan dan tag-bahagian-ucapan, adalah tugas asas untuk pemprosesan teks yang dijana oleh pengguna Jepun. Dalam kertas ini, kami cadangkan model penyuntingan teks untuk menyelesaikan tiga tugas bersama-sama dan kaedah generasi data pseudo-labeled untuk mengatasi masalah kekurangan data. Eksperimen kami menunjukkan bahawa model yang diusulkan mencapai prestasi normalisasi yang lebih baik apabila dilatih pada data yang lebih berbeza dengan label-pseudo.</abstract_ms>
      <abstract_mt>In-normalizzazzjoni lexika, minbarra s-segmentazzjoni tal-kliem u t-tikkettar ta’ parti mid-diskors, hija kompitu fundamentali għall-ipproċessar tat-test iġġenerat mill-utent Ġappuniż. F’dan id-dokument, qed nipproponu mudell ta’ edizzjoni tat-test biex jissolvew it-tliet kompiti b’mod konġunt u metodi ta’ ġenerazzjoni ta’ dejta psewdotikkettata biex tingħeleb il-problem a tan-nuqqas ta’ dejta. L-esperimenti tagħna wrew li l-mudell propost kiseb prestazzjoni ta’ normalizzazzjoni aħjar meta mħarreġ fuq dejta psewdotikkettata aktar diversifikata.</abstract_mt>
      <abstract_ml>ലെക്സിക്സിക്കല്‍ സാധാരണമാക്കുന്നത്, വാക്കിന്റെ സംവിധാനവും ഭാഗവാക്കുകളുടെ ഭാഗവും പ്രസംഗിക്കുന്നതിനു ശേഷം, ജാപ്പാന ഈ പത്രത്തില്‍ നമ്മള്‍ ഒരു ടെക്സ്റ്റ് ചിട്ടപ്പെടുത്തുന്ന മോഡല്‍ പരിശോധിക്കുന്നു. വിവരങ്ങളുടെ കുഴപ്പം പരിജയപ്പെടുത്താന്‍ മൂന്ന നമ്മുടെ പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരുന്നത് പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്‍ നല്ല സാധാരണ പ്രവര്‍ത്തനങ്ങള്‍ നേടിയെടുത</abstract_ml>
      <abstract_mn>Японы хэрэглэгчийн бүтээгдэхүүний текст үйлдвэрлэлийн үндсэн даалгавар юм. Энэ цаасан дээр бид өгөгдлийн алдагдлын асуудлыг даван туулахын тулд гурван даалгаварыг хамтдаа шийдэх, pseudo-label өгөгдлийн бүтээгдэхүүний арга загварыг зааж өгдөг. Бидний туршилтууд санал өгсөн загвар нь олон төрлийн pseudo-маркилган өгөгдлийг суралцах үед илүү сайн нормализацийн үйл ажиллагааг гаргасан.</abstract_mn>
      <abstract_ka>ლექსიკალური ნორმალიზაცია, სიტყვების სეგმენტაციის და სიტყვების ნაწილი ტექსტის პროცესისთვის დამატებით, იაპონიკალური მომხმარებელი ტექსტის პროც ამ დომენტში, ჩვენ მოვეხსენებთ ტექსტის რედაქტირების მოდელი, რომ სამი დავაკეთოთ საერთო დავაკეთება და პესეუდო დანიშნული მონაცემების რედაქტირების პრობლემას გადავიწყებ ჩვენი ექსპერიმენტები გამოჩვენეთ, რომ მოდელი უფრო მეტი ნორმალიზაციის გამოყენება, როდესაც უფრო განსხვავებული პესეუდო მართლაზე განსხვავებული მო</abstract_ka>
      <abstract_pl>Leksykalna normalizacja, oprócz segmentacji słów i tagowania części mowy, jest podstawowym zadaniem japońskiego przetwarzania tekstu generowanego przez użytkownika. W niniejszym artykule proponujemy model edycji tekstu w celu wspólnego rozwiązania trzech zadań oraz metody generowania pseudoznakowanych danych w celu przezwyciężenia problemu niedoboru danych. Nasze eksperymenty wykazały, że proponowany model osiągnął lepszą wydajność normalizacji podczas treningu na bardziej zróżnicowanych pseudoznakowanych danych.</abstract_pl>
      <abstract_no>Leksiske normalisering, i tillegg til ordsegmentasjon og del av talemerking, er ein grunnleggjande oppgåve for teksthandsaming med japansk brukar. I denne papiret foreslår vi eit tekstredigeringsmodell for å løysa dei tre oppgåva saman og metodane for pseudomerket datagenerering for å overføra problemet med data-deficienc. Eksperimentane våre viste at den foreslåde modellen oppnådd bedre normaliseringsfunksjon når det trenga på fleire pseudomerkelige data.</abstract_no>
      <abstract_ro>Normalizarea lexicală, în plus față de segmentarea cuvintelor și etichetarea parțială a vorbirii, este o sarcină fundamentală pentru procesarea textului generat de utilizatorii japonezi. În această lucrare, propunem un model de editare a textului pentru a rezolva împreună cele trei sarcini și metode de generare a datelor pseudo-etichetate pentru a depăși problema deficienței de date. Experimentele noastre au arătat că modelul propus a obținut o performanță mai bună de normalizare atunci când a fost instruit pe date pseudo-etichetate mai diverse.</abstract_ro>
      <abstract_so>Qoriga caadiga ah ee Leksikal, marka laga bilaabo qeyb ka mid ah hadalka, waa shaqo muhiim ah oo la sameeyo qoraal baaraandegista isticmaalka japaniya. Qoraalkan waxaan ku soo jeedaynaa model qoraal ah oo ku hagaajiya sadexda shaqada oo wada wadajir ah iyo qaababta qarniga macluumaadka ee pseudo-labeled si aan u overcome dhibaatada baahida data. Imtixaankayadii waxay muuqatay in modelkii la soo jeeday ay ay soo gaadhay sameynta qaabilaad ka fiican marka lagu tababaray macluumaadyo kala duduwan oo la qoray pseudo.</abstract_so>
      <abstract_sv>Lexisk normalisering, förutom ordsegmentering och märkning av del av tal, är en grundläggande uppgift för japansk användargenererad textbehandling. I denna uppsats föreslår vi en textredigeringsmodell för att lösa de tre uppgifterna gemensamt och metoder för pseudomärkt datagenerering för att övervinna problemet med databrist. Våra experiment visade att den föreslagna modellen uppnådde bättre normaliseringsprestanda när den tränas på mer varierande pseudomärkta data.</abstract_sv>
      <abstract_ta>வார்த்தை பிரித்தல் மற்றும் பேச்சு பிரிவு குறிப்புகளை கூட்டுதல் லெக்சிக்சியல் சாதாரண செயல், ஜப்பானிய பயனர் உரை செயல்படுத் இந்த காகிதத்தில், நாம் ஒரு உரை தொகுப்பு மாதிரியை தீர்வு செய்ய மூன்று பணிகள் ஒன்றாக மற்றும் முறைகளில் மூன்று குறிப்பிட்ட தகவல் உர எங்கள் பரிந்துரைப்படுத்தப்பட்ட மாதிரி சிறந்த சாதாரண செயல்பாடு செய்தது என்று காண்பித்தது மேலும் வேறு வித்தியாசமா</abstract_ta>
      <abstract_ur>لکسکسیسی عاملی، لفظ سیگنٹ اور ٹاگ کی حصہ کے علاوہ، جاپانی کارساز کی پیدائش کے لئے ایک بنیادی کام ہے. اس کاغذ میں ہم ایک ٹیکسٹ ویڈینگ موڈل کو پیشنهاد کرتے ہیں کہ ان تین کاموں کو ایک ساتھ حل کرنے کے لئے اور سیدھے لکڑے ہوئے ڈیٹ ناکامی کے مسئلہ پر غالب آئیں۔ ہماری آزمائش نے دکھائی کہ پیشنهاد کی موڈل بہتر عامل کرنا کامل پہنچ گیا جب ان سے زیادہ مختلف طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح</abstract_ur>
      <abstract_sr>Leksička normalizacija, osim segmentacije riječi i dijelogovorne etikete, je osnovni zadatak za obradivanje teksta iz japanskog korisnika. U ovom papiru predlažemo model editiranja teksta kako bi zajedno riješili tri zadatka i metode generacije pseudo-označene podataka kako bi preuzeli problem nedostatka podataka. Naši eksperimenti su pokazali da je predloženi model postigao bolju normalizaciju kada je obučen na više različitih pseudooznačenih podataka.</abstract_sr>
      <abstract_si>Name මේ පත්තරේ අපි ප්‍රතිචාරයක් සම්බන්ධ කරන්න පාළුවක් සම්බන්ධ කරන්න ප්‍රශ්නයක් තුනක් සහ ප්‍රශ්නයක් සම්බන්ධ විදිහට සහ අපේ පරීක්ෂණය පෙන්වන්න පුළුවන් විදිහට සාමාන්‍ය විදිහට පරීක්ෂණය කරලා තියෙනවා කියලා, වඩා විවිදිහට ප්‍</abstract_si>
      <abstract_uz>Name Bu qogʻozda, biz bu uchta vazifani birlashtirish va tuzuvchiga qo'yilgan maʼlumot yaratish usullarini o'zgartirish mumkin. Bizning imtiyozlarimizni ko'rsatadi, talab qilingan modeli ko'proq ko'proq ko'proq pseudo lab-lab qolgan maʼlumot haqida o'rganilganda yaxshi normal natijasini bajaradi.</abstract_uz>
      <abstract_vi>Cộng với việc phân chia từ và định vị bằng một phần ngôn ngữ, là một nhiệm vụ cơ bản cho việc xử lý văn bản do người dùng Nhật tạo ra. Trong tờ giấy này, chúng tôi đề nghị một mô hình soạn thảo để giải quyết ba nhiệm vụ cùng nhau và các phương pháp tạo dữ liệu giả được dán nhãn để giải quyết vấn đề thiếu dữ liệu. Những thí nghiệm của chúng tôi cho thấy mô hình đề xuất đạt hiệu suất ổn định hơn khi được huấn luyện dựa trên các dữ liệu có nhãn giả khác nhau.</abstract_vi>
      <abstract_bg>Лексикалното нормализиране, в допълнение към сегментацията на думите и маркирането на част от речта, е фундаментална задача за японската обработка на текста, генерирана от потребителя. В настоящата статия предлагаме модел за редактиране на текст за съвместно решаване на трите задачи и методи за генериране на псевдо-маркирани данни за преодоляване на проблема с дефицита на данни. Нашите експерименти показаха, че предложеният модел постига по-добра нормализация, когато се обучава върху по-разнообразни псевдо-маркирани данни.</abstract_bg>
      <abstract_da>Lexisk normalisering, ud over ordsegmentering og del-af-tale tagging, er en grundlæggende opgave for japansk brugergenereret tekstbehandling. I denne artikel foreslår vi en tekstredigeringsmodel til at løse de tre opgaver i fællesskab og metoder til pseudomærket datagenerering til at overvinde problemet med datamangel. Vores eksperimenter viste, at den foreslåede model opnåede bedre normalisering ydeevne, når den trænede på mere forskelligartede pseudo-mærkede data.</abstract_da>
      <abstract_nl>Lexische normalisatie is, naast woordsegmentatie en het taggen van woorddelen, een fundamentele taak voor Japanse tekstverwerking door gebruikers. In dit artikel stellen we een tekstbewerkingsmodel voor om de drie taken gezamenlijk op te lossen en methoden voor het genereren van pseudo-gelabelde gegevens om het probleem van datatekorten op te lossen. Onze experimenten toonden aan dat het voorgestelde model betere normalisatieprestaties behaalde wanneer getraind op meer diverse pseudo-gelabelde gegevens.</abstract_nl>
      <abstract_hr>Leksička normalizacija, osim segmentacije riječi i dijelogovorne oznake, je osnovni zadatak za obradu teksta proizvođenog japanskog korisnika. U ovom papiru predlažemo model editiranja teksta kako bi zajedno riješili tri zadatka i metode proizvodnje pseudooznačenih podataka kako bi prevazili problem nedostatka podataka. Naši eksperimenti pokazali su da je predloženi model postigao bolju normalizaciju kada je obučen na raznim podacima označenim pseudom.</abstract_hr>
      <abstract_de>Lexikale Normalisierung ist neben der Wortsegmentierung und der Wortteiltagging eine grundlegende Aufgabe für die japanische benutzergenerierte Textverarbeitung. In diesem Beitrag schlagen wir ein Textbearbeitungsmodell vor, um die drei Aufgaben gemeinsam zu lösen und Methoden der Pseudo-Labeled Datengenerierung, um das Problem des Datenmangels zu überwinden. Unsere Experimente zeigten, dass das vorgeschlagene Modell eine bessere Normalisierungsleistung erzielt, wenn es auf vielfältigeren pseudo-markierten Daten trainiert wurde.</abstract_de>
      <abstract_id>Normalisasi Lexik, selain segmentasi kata dan tagging bagian dari pidato, adalah tugas dasar untuk proses teks yang dibuat oleh pengguna Jepang. Dalam kertas ini, kami mengusulkan model penyuntingan teks untuk memecahkan tiga tugas bersama-sama dan metode generasi data pseudo-labeled untuk mengatasi masalah kekurangan data. Eksperimen kami menunjukkan bahwa model yang diusulkan mencapai prestasi normalisasi yang lebih baik ketika dilatih pada data yang lebih berbeda dengan pseudo-label.</abstract_id>
      <abstract_fa>نورمال‌سازی سکسیکی، در addition to word segmentation and part-of-speech tagging, is a basic task for the Japanese user generated text processing. در این کاغذ، ما یک مدل ویرایش متن را پیشنهاد می‌کنیم تا سه کار را با هم حل کند و روش‌هایی از نسل داده‌های pseudo-labeled برای تغییر مشکل کمبود داده‌ها. آزمایش های ما نشان دادند که مدل پیشنهاد بهتر عملکرد عامل کردن موقع آموزش داده های متفاوتی با نوشته های pseudo.</abstract_fa>
      <abstract_sw>Utawala wa Lexico, pamoja na kuchaguliwa kwa maneno na sehemu ya kuongeza maneno, ni kazi ya msingi kwa ajili ya upasuaji wa maandishi yanayotengenezwa nchini Japani. Katika karatasi hii, tunapendekeza modeli ya kuhariri ujumbe wa maandishi ili kutatua juhudi hizi tatu pamoja na njia za kizazi cha data kinachoitwa pseudo ili kushinda tatizo la ukosefu wa taarifa. Majaribio yetu yalionyesha kuwa muundo wa pendekezo ulifanikiwa kufanya kazi bora ya kawaida wakati ulipofundishwa kwa taarifa mbalimbali za pseudo.</abstract_sw>
      <abstract_ko>분사와 어성 표시를 제외하고 어휘 규범화는 일본어 사용자가 텍스트 처리를 만드는 기본적인 임무이다.본고에서 우리는 텍스트 편집 모델을 제시하여 이 세 가지 임무를 공동으로 해결하고 위조 표기 데이터 생성 방법을 제시하여 데이터 부족을 극복했다.우리의 실험은 더욱 다양한 위조 표기 데이터에서 훈련할 때 이 모델이 더욱 좋은 귀일화 성능을 얻었다는 것을 보여 주었다.</abstract_ko>
      <abstract_tr>Name Bu kagyzda, üç zady birlikte çözmek üçin metin düzenleme modelini pseudo-etilen veri eksikliğinin problemlerini çözmek üçin teklif edip teklif ediyoruz. Biziñ deneylerimiz teklip eden nusgasynyň has dürli pseudo etilgeli maglumatlarda has gowy normalizasyon etmäge ýetip bardygyny görkezildi.</abstract_tr>
      <abstract_sq>Normalizimi leksikal, përveç segmentimit të fjalëve dhe shënimit të pjesës së fjalës, është një detyrë thelbësore për procesimin e tekstit të gjeneruar nga përdoruesit japonez. In this paper, we propose a text editing model to solve the three task jointly and methods of pseudo-labeled data generation to overcome the problem of data deficiency.  Eksperimentet tona treguan se modeli i propozuar arriti performancë më të mirë normalizimi kur u trajnua në të dhëna më të ndryshme pseudo-etiketuara.</abstract_sq>
      <abstract_am>ሌክሲካዊ ትምህርት፣ ከንግግር ግንኙነት እና ክፍለ ንግግር ተጨማሪ፣ የጃፓን ተጠቃሚ የጽሑፍ ማቀናቀል የዋና ስራ ነው፡፡ በዚህ ካላት የጽሑፍ ማቀናጃ ሞዴል የሦስቱን ስራ በተጠቃሚ እና የዳታ ትውልድ አካላንት የዳታ ጉዳትን ለማሸንፍ እና ልማድ መፍታትን እናስባለን፡፡ ፈተናዎቻችን የተዘጋጀው ሞዴል በተለየ የpseudo-labelled ዳታዎችን በተማረ ጊዜ የተሻለ የድምፅ ውጤት አግኝቷል፡፡</abstract_am>
      <abstract_af>Leksiese normalisering, in addition to word segmentation and part-of-speech tagging, is 'n fundamental task for Japanese user-generated text processing. In hierdie papier, voorstel ons 'n teks redigeerder model om die drie taak saam en metodes van pseudo-etiketeerde data genereering te los om die probleem van data ontbreiding te oorwin. Ons eksperimente het vertoon dat die voorgestelde model beter normalisering effektuur bereik het wanneer op meer verskeie pseudo-etiketeerde data opgelei het.</abstract_af>
      <abstract_hy>Լեքսիկական նորմալիզացիան բառերի սեգմետրացիայի և խոսքի մասի բացառությամբ հիմնական խնդիր է ճապոնացի օգտագործողների կողմից ստեղծված տեքստի վերլուծության համար: Այս թղթի մեջ մենք առաջարկում ենք տեքստի խմբագրման մոդել, որպեսզի միասին լուծենք երեք խնդիրը և կեղծ պիտակ տվյալների ստեղծման մեթոդները, որպեսզի հաղթահարենք տվյալների բացակայության խնդիրը: Մեր փորձարկումները ցույց տվեցին, որ առաջարկած մոդելը ավելի լավ նորմալիզացիայի արդյունք է ստացել, երբ սովորեցրել է ավելի բազմազան կեղծ պիտակ նշված տվյալների վրա:</abstract_hy>
      <abstract_bn>লেক্সিক্সিয়াল স্বাভাবিক স্বাভাবিকভাবে, শব্দ বিভাগ এবং ভাষণের অংশের ট্যাগিং ছাড়া, জাপানি ব্যবহারকারী তৈরি করা টেক্সট প এই কাগজটিতে আমরা একটি টেক্সট সম্পাদক মডেল প্রস্তাব করছি যেন তিনটি কাজ সমাধান করতে পারি যাতে ডাটা অসস্তাহের সমস্যা জয় করার জন্য। আমাদের পরীক্ষাগুলো দেখিয়েছিল যে প্রস্তাবিত মডেল বিভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভ</abstract_bn>
      <abstract_az>Söz segmentasyonu və sözlərin bir parçasını etiketləməsini sağlayaraq, Japon istifadəçisi təşkil etdiyi mətn işləməsi üçün əsas bir iş. Bu kağızda, üç işi birlikdə çəkmək və pseudo-etiketli verilən məlumatların problemlərini üstün etmək üçün məlumat düzəltmə modelini təklif edirik. Bizim təcrübələrimiz göstərdi ki, təcrübə edilmiş modellərin daha müxtəlif pseudo etiketli məlumatlarda təhsil edildiyi zaman daha yaxşı normalizasyon performansını başa çatdı.</abstract_az>
      <abstract_ca>La normalització lèxica, a més de la segmentació de paraules i l'etiqueta part-of-speech, és una tasca fonamental per al processament de text generat per l'usuari japonès. En aquest paper, proposem un model d'edició de text per resoldre conjuntament les tres tasques i els mètodes de generació de dades pseudoetiquetades per superar el problem a de la carencia de dades. Els nostres experiments van demostrar que el model proposat va aconseguir millor rendiment de normalització quan es va entrenar en dades pseudoetiquetades més diverses.</abstract_ca>
      <abstract_et>Lisaks sõnasegmenteerimisele ja kõneosalisele sildistamisele on lexikaalne normaliseerimine Jaapani kasutaja loodud teksti töötlemise põhiülesanne. Käesolevas töös pakume välja teksti redigeerimise mudeli kolme ülesande ühiseks lahendamiseks ja pseudomärgistatud andmete genereerimise meetodite abil andmepuuduse probleemi ületamiseks. Meie eksperimendid näitasid, et kavandatud mudel saavutas parema normaliseerimisjõudluse, kui seda koolitati mitmekesisemate pseudomärgistatud andmetega.</abstract_et>
      <abstract_cs>Lexikální normalizace je kromě segmentace slov a tagování části řeči základním úkolem japonského uživatelského zpracování textu. V tomto článku navrhujeme model editace textu pro společné řešení tří úloh a metody generování pseudoznačených dat k překonání problému nedostatku dat. Naše experimenty ukázaly, že navržený model dosáhl lepšího normalizačního výkonu při trénování na různorodějších pseudoznačených datech.</abstract_cs>
      <abstract_bs>Leksička normalizacija, osim segmentacije riječi i dijelogovorne etikete, je osnovni zadatak za obradivanje teksta iz japanskog korisnika. U ovom papiru predlažemo model editiranja teksta kako bi zajedno riješili tri zadatka i metode generacije pseudo-etiketiranih podataka kako bi prevazili problem nedostatka podataka. Naši eksperimenti pokazali su da je predloženi model postigao bolju normalizaciju kada je obučen na raznim pseudo-etiketiranim podacima.</abstract_bs>
      <abstract_fi>Tekstin segmentoinnin ja puheen osan tagauksen lisäksi lexikaalinen normalisointi on japanilaisen käyttäjän luoman tekstin käsittelyn perustehtävä. Tässä työssä ehdotamme tekstinkäsittelymallia kolmen tehtävän ratkaisemiseksi yhdessä sekä pseudoleimatun datan tuottamisen menetelmiä datavajeen ratkaisemiseksi. Kokeet osoittivat, että ehdotettu malli saavutti paremman normalisointisuorituskyvyn, kun se oli koulutettu monipuolisemmille pseudomerkityille tiedoille.</abstract_fi>
      <abstract_sk>Lexikalna normalizacija je poleg segmentacije besed in označevanja dela govora temeljna naloga za japonsko obdelavo besedila, ki jo ustvarijo uporabniki. V prispevku predlagamo model urejanja besedila za skupno reševanje treh nalog in metode psevdo označenega generiranja podatkov za premagovanje problema pomanjkljivosti podatkov. Naši eksperimenti so pokazali, da je predlagani model dosegel boljšo zmogljivost normalizacije, ko je treniral na bolj raznolikih psevdo označenih podatkih.</abstract_sk>
      <abstract_he>נורמליזציה לקסיקלית, בנוסף לסגמנטציה מילים וחלק מהדיבור, היא משימה בסיסית עבור עיבוד טקסט יוצר ע"י משתמשים יפנים. בעיתון הזה, אנו מציעים מודל עורך טקסט כדי לפתור את שלושת המשימה ביחד ושיטות של יוצר נתונים עם תווים פסאודו כדי להתגבר על בעיה של חוסר נתונים. Our experiments showed that the proposed model achieved better normalization performance when trained on more diverse pseudo-labeled data.</abstract_he>
      <abstract_ha>KCharselect unicode block name Ga wannan takardan, Munã buɗa wata misali mai editi na matsayi dõmin mu sola wa aikin uku wadangan da kuma metode na danne-danne da aka rubũta cewa don ya rinjãye mataimaki ga manaicin data. Kayan jarrabõyinmu suka nuna cewa misalin da aka buƙata shi ya sami mafiya kyauta a lokacin da aka sanar da shi a kan wasu mutane da aka rubũta shi.</abstract_ha>
      <abstract_jv>text-tool-action Wi-Fi/Ethernet punika ingkang dipuluhaan kelompok punika ingkang dipuluhaan kelompok Where's that</abstract_jv>
      <abstract_bo>འོན་ཀྱང་གཟུགས་རིས་སྤྲོད་ཀྱི་རྒྱུན་ལྡན་ཞིག་འཇུག་བྱེད་སྐབས་ཡི་གེ་དང་ཆ་ཤས་ཀྱི་ཁ་ཡིག་གི་ཤུགས་ཀྱི་ནང་དོན་ཡིན་པ་ In this paper, we propose a text editing model to solve the three task jointly and methods of pseudo-labeled data generation to overcome the problem of data deficiency. Our experiments showed that the proposed model achieved better normalization performance when trained on more diverse pseudo-labeled data.</abstract_bo>
      </paper>
    <paper id="10">
      <title>Intrinsic evaluation of language models for <a href="https://en.wikipedia.org/wiki/Code-switching">code-switching</a></title>
      <author><first>Sik Feng</first><last>Cheong</last></author>
      <author><first>Hai Leong</first><last>Chieu</last></author>
      <author><first>Jing</first><last>Lim</last></author>
      <pages>81–86</pages>
      <abstract>Language models used in <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> are often either evaluated intrinsically using <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> on test data, or extrinsically with an automatic speech recognition (ASR) system. The former <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> does not always correlate well with <a href="https://en.wikipedia.org/wiki/Signaling_(telecommunications)">ASR</a> performance, while the latter could be specific to particular <a href="https://en.wikipedia.org/wiki/Signaling_(telecommunications)">ASR systems</a>. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer. Underlying such an <a href="https://en.wikipedia.org/wiki/Evaluation">evaluation</a> is the assumption that the generated sentences are linguistically incorrect. In this paper, we first put this assumption into question, and observe that alternatively generated sentences could often be linguistically correct when they differ from the ground truth by only one edit. Secondly, we showed that by using multi-lingual BERT, we can achieve better performance than previous work on two code-switching data sets. Our implementation is publicly available on Github at https://github.com/sikfeng/language-modelling-for-code-switching.</abstract>
      <url hash="dab0802c">2021.wnut-1.10</url>
      <bibkey>cheong-etal-2021-intrinsic</bibkey>
      <doi>10.18653/v1/2021.wnut-1.10</doi>
      <pwccode url="https://github.com/sikfeng/language-modelling-for-code-switching" additional="false">sikfeng/language-modelling-for-code-switching</pwccode>
    <title_ar>التقييم الجوهري لنماذج اللغة من أجل تبديل الشفرة</title_ar>
      <title_es>Evaluación intrínseca de modelos de lenguaje para el cambio de código</title_es>
      <title_fr>Évaluation intrinsèque des modèles de langage pour la commutation de code</title_fr>
      <title_pt>Avaliação intrínseca de modelos de linguagem para troca de código</title_pt>
      <title_ja>コードスイッチングのための言語モデルの本質的評価</title_ja>
      <title_zh>代码切换言模者内在评估</title_zh>
      <title_hi>कोड-स्विचिंग के लिए भाषा मॉडल का आंतरिक मूल्यांकन</title_hi>
      <title_ru>Внутренняя оценка языковых моделей для переключения кода</title_ru>
      <title_ga>Meastóireacht intreach ar shamhlacha teanga le haghaidh códmhalartaithe</title_ga>
      <title_el>Εσωτερική αξιολόγηση γλωσσικών μοντέλων για αλλαγή κώδικα</title_el>
      <title_hu>A kódváltáshoz szükséges nyelvi modellek belső értékelése</title_hu>
      <title_kk>Код ауыстыру үшін тіл үлгілерінің ішкі оқу</title_kk>
      <title_lt>Kodų keitimo kalbos modelių atliktas išsamus vertinimas</title_lt>
      <title_ka>ენის მოდელების ინტერესტიკური განსაზღვრება</title_ka>
      <title_it>Valutazione intrinseca dei modelli linguistici per il cambio di codice</title_it>
      <title_mt>Evalwazzjoni intrinsika tal-mudelli lingwistiċi għall-bdil tal-kodiċi</title_mt>
      <title_mk>Интринска проценка на јазичките модели за промена на кодови</title_mk>
      <title_ms>Intrinsic evaluation of language models for code-switching</title_ms>
      <title_ml>കോഡ്- മാറ്റുന്നതിനുള്ള ഭാഷ മോഡലുകളുടെ ഇന്റ്രിനിസിക്ക് വിലാസപ്പെടുത്തുക</title_ml>
      <title_mn>Код-өөрчлөлтийн хэл загварын доторх үнэлгээ</title_mn>
      <title_no>Intrinsic evaluation of language models for code switching</title_no>
      <title_pl>Wewnętrzna ocena modeli językowych dla przełączania kodu</title_pl>
      <title_ro>Evaluarea intrinsecă a modelelor lingvistice pentru schimbarea codurilor</title_ro>
      <title_sr>Intrinsic evaluation of language models for code switching</title_sr>
      <title_si>Name</title_si>
      <title_so>Qiimeynta qoraalka luuqada</title_so>
      <title_sv>Inbyggd utvärdering av språkmodeller för kodväxling</title_sv>
      <title_ta>குறிமுறைமாற்றுவதற்கான மொழி மாதிரிகளின் முன்னிருப்பு மதிப்பு</title_ta>
      <title_ur>کوڈ-سوچینگ کے لئے زبان موڈل کی داخلی ارزیابی</title_ur>
      <title_uz>Kodlash usuli uchun tillar modellari qiymati</title_uz>
      <title_vi>Sự đánh giá giới hạn ngôn ngữ cho việc chuyển đổi mã</title_vi>
      <title_bg>Вътрешна оценка на езиковите модели за превключване на кодове</title_bg>
      <title_nl>Intrinsieke evaluatie van taalmodellen voor code-switching</title_nl>
      <title_da>Indgående evaluering af sprogmodeller til kodeskift</title_da>
      <title_id>Evaluasi intrinsik dari model bahasa untuk penggantian kode</title_id>
      <title_de>Intrinsische Evaluation von Sprachmodellen für Code-Switching</title_de>
      <title_ko>코드 변환 언어 모델의 내재적 평가</title_ko>
      <title_hr>Intrinska procjena jezičkih modela za promjenu kod</title_hr>
      <title_af>Intrinsic evaluation of language models for code- switching</title_af>
      <title_sw>Intrinsic evaluation of language models for code-switching</title_sw>
      <title_fa>ارزیابی داخلی مدل زبانی برای تغییر کد</title_fa>
      <title_tr>Dil nusgalary ködleme üçin çalyşyrlybdyr</title_tr>
      <title_sq>Vlerësimi brendshëm i modeleve gjuhësore për shkëmbimin e kodeve</title_sq>
      <title_am>የቋንቋ ሞዴላዎችን ለመለወጥ ማተካት</title_am>
      <title_bn>কোড- পরিবর্তনের জন্য ভাষা মডেলের ইন্ট্রিনিস্ক মান</title_bn>
      <title_hy>Գործիք փոխելու լեզվի մոդելների ներքին գնահատումը</title_hy>
      <title_bs>Intrinsic evaluation of language models for code switching</title_bs>
      <title_az>Kod-dəyişdirmək üçün dil modellərinin içərisində müəyyən edilməsi</title_az>
      <title_ca>Evaluació intrínsica dels models de llenguatge per canviar codis</title_ca>
      <title_cs>Intrinsické vyhodnocení jazykových modelů pro přepínání kódu</title_cs>
      <title_fi>Koodinvaihdon kielimallien sisäinen arviointi</title_fi>
      <title_et>Koodi vahetamise keelemudelite sisemine hindamine</title_et>
      <title_jv>Language</title_jv>
      <title_ha>Intrinsic evaluation of language models for code-switching</title_ha>
      <title_he>הערכה אינטרינסית של דוגמני שפה עבור החלפת קודים</title_he>
      <title_sk>Notranja vrednotenja jezikovnih modelov za preklapljanje kod</title_sk>
      <title_bo>སྐད་ཡིག་ཐབས་ལམ་བསྒྱུར་བཅོས་བྱེད་ཀྱི་ནང་ལྟ་བུ་བཏོན་པ</title_bo>
      <abstract_ar>غالبًا ما يتم تقييم نماذج اللغة المستخدمة في التعرف على الكلام إما جوهريًا باستخدام الارتباك في بيانات الاختبار ، أو خارجيًا باستخدام نظام التعرف التلقائي على الكلام (ASR). لا يرتبط التقييم السابق دائمًا بشكل جيد بأداء ASR ، بينما يمكن أن يكون الأخير خاصًا بأنظمة ASR معينة. اقترح العمل الأخير لتقييم نماذج اللغة باستخدامها لتصنيف جمل الحقيقة الأساسية بين جمل بديلة مماثلة صوتيًا تم إنشاؤها بواسطة محول طاقة دقيق. يستند هذا التقييم إلى افتراض أن الجمل التي تم إنشاؤها غير صحيحة لغويًا. في هذه الورقة ، وضعنا هذا الافتراض موضع تساؤل أولاً ، ولاحظنا أن الجمل التي تم إنشاؤها بدلاً من ذلك يمكن أن تكون غالبًا صحيحة لغويًا عندما تختلف عن الحقيقة الأساسية من خلال تعديل واحد فقط. ثانيًا ، أظهرنا أنه باستخدام BERT متعدد اللغات ، يمكننا تحقيق أداء أفضل من العمل السابق على مجموعتي بيانات تبديل التعليمات البرمجية. تطبيقنا متاح للجمهور على Github على https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ar>
      <abstract_fr>Les modèles de langage utilisés dans la reconnaissance vocale sont souvent évalués soit de manière intrinsèque en utilisant la perplexité des données de test, soit de manière extrinsèque avec un système de reconnaissance vocale automatique (ASR). La première évaluation ne correspond pas toujours bien à la performance ASR, tandis que la seconde pourrait être spécifique à des systèmes ASR particuliers. Des travaux récents ont proposé d'évaluer des modèles de langage en les utilisant pour classer les phrases de vérité fondamentale parmi des phrases phonétiquement similaires générées par un transducteur d'état fin. Cette évaluation repose sur l'hypothèse que les phrases générées sont incorrectes sur le plan linguistique. Dans cet article, nous remettons d'abord cette hypothèse en question et observons que les phrases générées alternativement peuvent souvent être linguistiquement correctes lorsqu'elles diffèrent de la vérité de base par une seule modification. Deuxièmement, nous avons montré qu'en utilisant le BERT multilingue, nous pouvons obtenir de meilleures performances que les travaux précédents sur deux ensembles de données de commutation de code. Notre implémentation est accessible au public sur Github à l'adresse https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_fr>
      <abstract_es>Los modelos de lenguaje utilizados en el reconocimiento de voz a menudo se evalúan intrínsecamente mediante la perplejidad de los datos de prueba o extrínsecamente con un sistema de reconocimiento automático de voz (ASR). La primera evaluación no siempre se correlaciona bien con el rendimiento de ASR, mientras que la segunda podría ser específica de determinados sistemas de ASR. Un trabajo reciente propuso evaluar los modelos de lenguaje usándolos para clasificar oraciones de verdad básicas entre oraciones alternativas fonéticamente similares generadas por un transductor de estado fino. La base de esta evaluación es la suposición de que las oraciones generadas son lingüísticamente incorrectas. En este artículo, primero cuestionamos esta suposición y observamos que las oraciones generadas de forma alternativa a menudo podrían ser lingüísticamente correctas cuando difieren de la verdad fundamental en una sola edición. En segundo lugar, demostramos que mediante el uso de BERT multilingüe, podemos lograr un mejor rendimiento que el trabajo anterior en dos conjuntos de datos de cambio de código. Nuestra implementación está disponible públicamente en Github en https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_es>
      <abstract_pt>Os modelos de linguagem usados no reconhecimento de fala geralmente são avaliados intrinsecamente usando perplexidade nos dados de teste ou extrinsecamente com um sistema de reconhecimento automático de fala (ASR). A primeira avaliação nem sempre se correlaciona bem com o desempenho de ASR, enquanto a última pode ser específica para determinados sistemas de ASR. Um trabalho recente propôs avaliar modelos de linguagem usando-os para classificar sentenças de verdade entre sentenças alternativas foneticamente semelhantes geradas por um transdutor de estado fino. Subjacente a tal avaliação está a suposição de que as sentenças geradas são linguisticamente incorretas. Neste artigo, primeiro colocamos essa suposição em questão e observamos que sentenças geradas alternativamente podem muitas vezes ser linguisticamente corretas quando diferem da verdade básica por apenas uma edição. Em segundo lugar, mostramos que, usando o BERT multilíngue, podemos obter um desempenho melhor do que o trabalho anterior em dois conjuntos de dados de comutação de código. Nossa implementação está disponível publicamente no Github em https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_pt>
      <abstract_ja>音声認識で使用される言語モデルは、多くの場合、テストデータ上の困惑を使用して本質的に評価されるか、または自動音声認識（ ＡＳＲ ）システムを使用して本質的に評価されるかのいずれかである。 前者の評価は、ASRのパフォーマンスと常に良好に相関するわけではないが、後者は特定のASRシステムに特有である可能性がある。 最近の研究では、言語モデルを使用して、細かい状態トランスデューサによって生成された代替の音声学的に類似した文の中に接地真理文を分類することによって、言語モデルを評価することが提案された。 このような評価の根底には、生成された文が言語学的に不正確であるという仮定がある。 この論文では、まずこの仮定を疑問視し、代替的に生成された文章が、たった一つの編集だけで事実と異なる場合、言語学的に正しいことが多いことを観察した。 第二に、多言語のBERTを使用することで、2つのコードスイッチングデータセットで以前の作業よりも優れたパフォーマンスを達成できることを示しました。 当社の実装はGithubで一般公開されています。https://github.com/sikfeng/language-modelling-for-code-switching</abstract_ja>
      <abstract_hi>भाषण पहचान में उपयोग किए जाने वाले भाषा मॉडल का मूल्यांकन अक्सर या तो परीक्षण डेटा पर उलझन का उपयोग करके आंतरिक रूप से किया जाता है, या बाहरी रूप से स्वचालित भाषण मान्यता (एएसआर) प्रणाली के साथ किया जाता है। पूर्व मूल्यांकन हमेशा एएसआर प्रदर्शन के साथ अच्छी तरह से सहसंबंधित नहीं होता है, जबकि उत्तरार्द्ध विशेष एएसआर सिस्टम के लिए विशिष्ट हो सकता है। हाल के काम ने भाषा मॉडल का मूल्यांकन करने के लिए प्रस्तावित किया, जिसमें उनका उपयोग करके वैकल्पिक ध्वन्यात्मक रूप से समान वाक्यों के बीच जमीनी सच्चाई वाक्यों को वर्गीकृत करने के लिए एक ठीक राज्य ट्रांसड्यूसर द्वारा उत्पन्न किया गया था। इस तरह के मूल्यांकन के अंतर्निहित यह धारणा है कि उत्पन्न वाक्य भाषाई रूप से गलत हैं। इस पेपर में, हमने पहले इस धारणा को प्रश्न में रखा, और देखा कि वैकल्पिक रूप से उत्पन्न वाक्य अक्सर भाषाई रूप से सही हो सकते हैं जब वे केवल एक संपादन द्वारा जमीनी सच्चाई से भिन्न होते हैं। दूसरे, हमने दिखाया कि बहुभाषी BERT का उपयोग करके, हम दो कोड-स्विचिंग डेटा सेट पर पिछले काम की तुलना में बेहतर प्रदर्शन प्राप्त कर सकते हैं। हमारा कार्यान्वयन सार्वजनिक रूप से https://github.com/sikfeng/language-modelling-for-code-switching पर Github पर उपलब्ध है।</abstract_hi>
      <abstract_zh>语音识用语言模常用测试数据困惑固有评估,或用自语音识(ASR)系统外评。 前评非恒与ASR性相关,而后者特定于特定之ASR统。 近事议质言语模样,用其本末句分换能器语音相似者代之。 此评本虚生句在语为非。 于本文中,先设质疑,并观代成句与本事一编不同,其常可于言为是。 其次,吾明用多言BERT,可以两代码切换数集上得其善于前者也。 吾道在 Github https://github.com/sikfeng/language-modelling-for-code-switching 上公给。</abstract_zh>
      <abstract_ru>Языковые модели, используемые в распознавании речи, часто оцениваются либо по существу с использованием недоумения в отношении тестовых данных, либо извне с помощью системы автоматического распознавания речи (ASR). Первая оценка не всегда хорошо коррелирует с показателями ASR, в то время как вторая оценка может быть специфической для конкретных систем ASR. Недавняя работа предложила оценить языковые модели, используя их для классификации предложений истины среди альтернативных фонетически аналогичных предложений, генерируемых преобразователем тонкого состояния. В основе такой оценки лежит предположение о том, что сгенерированные предложения лингвистически неверны. В этой статье мы сначала ставим это предположение под сомнение и замечаем, что альтернативно сгенерированные предложения часто могут быть лингвистически правильными, когда они отличаются от основной истины только одним редактированием. Во-вторых, мы показали, что с помощью многоязычного BERT мы можем достичь лучшей производительности, чем предыдущая работа над двумя наборами данных переключения кода. Наша реализация доступна в открытом доступе на Github по адресу https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ru>
      <abstract_ga>Is minic a dhéantar samhlacha teanga a úsáidtear in aithint cainte a mheas go bunúsach trí úsáid a bhaint as seachránacht ar shonraí tástála, nó go seachtrach le córas uathaitheanta cainte (ASR). Ní bhíonn comhghaol idir an chéad mheastóireacht agus feidhmíocht RSR i gcónaí, agus d’fhéadfadh an dara ceann a bheith sainiúil do chórais RSR ar leith. Moladh obair le déanaí chun múnlaí teanga a mheas trína n-úsáid chun abairtí fhírinneachta a rangú i measc abairtí comhchosúla foghraíochta a ghineann trasduchtóir mínstaid. Mar bhonn le meastóireacht den sórt sin tá an toimhde go bhfuil na habairtí ginte mícheart ó thaobh teanga de. Sa pháipéar seo, cuirimid an toimhde seo i gceist ar dtús, agus tugaimid faoi deara go bhféadfadh abairtí a ghintear de rogha air a bheith ceart go teanga go minic nuair nach mbíonn siad difriúil ach leis an bhfírinne ar an talamh in eagar amháin. Ar an dara dul síos, léirigh muid, trí úsáid a bhaint as BERT ilteangach, gur féidir linn feidhmíocht níos fearr a bhaint amach ná an obair a rinneadh roimhe seo ar dhá thacar sonraí maidir le malartú cód. Tá ár gcur chun feidhme ar fáil go poiblí ar Github ag https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ga>
      <abstract_el>Τα γλωσσικά μοντέλα που χρησιμοποιούνται στην αναγνώριση ομιλίας αξιολογούνται συχνά είτε εγγενώς χρησιμοποιώντας σύγχυση στα δεδομένα δοκιμής, είτε εξωτερικά με ένα σύστημα αυτόματης αναγνώρισης ομιλίας (ASR). Η πρώτη αξιολόγηση δεν συσχετίζεται πάντα καλά με την απόδοση ASR, ενώ η τελευταία μπορεί να είναι ειδική για συγκεκριμένα συστήματα ASR. Πρόσφατες εργασίες πρότειναν να αξιολογηθούν γλωσσικά μοντέλα χρησιμοποιώντας αυτά για να ταξινομηθούν οι βασικές προτάσεις αλήθειας μεταξύ εναλλακτικών φωνητικά παρόμοιων προτάσεων που παράγονται από έναν μετατροπέα λεπτής κατάστασης. Βασίζεται σε μια τέτοια αξιολόγηση η υπόθεση ότι οι προτάσεις που δημιουργούνται είναι γλωσσικά εσφαλμένες. Σε αυτή την εργασία, θέτουμε πρώτα υπό αμφισβήτηση αυτή την υπόθεση, και παρατηρούμε ότι εναλλακτικά δημιουργημένες προτάσεις θα μπορούσαν συχνά να είναι γλωσσικά σωστές όταν διαφέρουν από τη βασική αλήθεια με μία μόνο επεξεργασία. Δεύτερον, αποδείξαμε ότι με τη χρήση πολυγλωσσικού BERT, μπορούμε να επιτύχουμε καλύτερες επιδόσεις από προηγούμενες εργασίες σε δύο σύνολα δεδομένων αλλαγής κώδικα. Η εφαρμογή μας είναι δημόσια διαθέσιμη στο Github στη διεύθυνση https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_el>
      <abstract_ka>სიტყვების მოდელები, რომელიც გამოიყენებულია სიტყვების განახლებაში, ბევრად ინტერნექციურად გამოყენებულია ტესტის მონაცემებზე, ან ექსტრინციურად ავტომატური სიტყვების პირველი განსაზღვრება არ ყოველთვის მსგავსი ASR კონფიგურაციას, მაგრამ ეს შეიძლება განსაზღვრებული ASR სისტემისთვის იყოს. ახალი სამუშაო სამუშაო მუშაო ენის მოდელების შესახებ გამოიყენება, რომელიც სამუშაო სიმართლეების კლასიფიკაციაში ალტენტერტული ფონეტიკურად მსგავ ასეთი განსაზღვრება არის წარმოდგენა, რომ შექმნილი წარმოდგენები ენგისტიკურად არსწორია. ჩვენ პირველად ამ წერტილის შესახებ დავწერეთ ამ წერტილის შესახებ, რომ ალტენტიგურად შეიქმნა წერტილი სიტყვები ძალიან სიტყვებით იქნება, როცა ისინი მხოლოდ ერთი რედაქტირებ მეორე, ჩვენ ჩვენ გამოჩვენეთ, რომ მრავალენგური BERT გამოყენებით, ჩვენ შეგვიძლია უკეთესი გამოყენება, ვიდრე წინა სამუშაო მუშაო მუშაო მუშა ჩვენი გამოყენება საშუალოდ გახსნა Github-ში https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ka>
      <abstract_hu>A beszédfelismerésben használt nyelvi modelleket gyakran vagy lényegében értékelik a tesztadatok zavaróságával, vagy külsőleg egy automatikus beszédfelismerő (ASR) rendszerrel. Az előbbi értékelés nem mindig áll jól összefüggésben az ASR teljesítményével, míg az utóbbi specifikus lehet egyes ASR rendszerekre. A közelmúltbeli munka azt javasolta, hogy értékeljük a nyelvi modelleket úgy, hogy ezeket a mondatokat a finom állapotátalakító által generált alternatív fonetikailag hasonló mondatok közé soroljuk. Az ilyen értékelés alapja az a feltételezés, hogy a létrehozott mondatok nyelvi szempontból helytelenek. Ebben a tanulmányban először megkérdőjeleztük ezt a feltételezést, és megfigyeljük, hogy alternatív mondatok gyakran nyelvileg helyesek lehetnek, ha csak egy szerkesztéssel különböznek az alapvető igazságtól. Másodszor megmutattuk, hogy a többnyelvű BERT használatával jobb teljesítményt érhetünk el, mint a korábbi két kódkapcsoló adatkészleten végzett munka. A megvalósításunk nyilvánosan elérhető a Github webhelyen https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_hu>
      <abstract_lt>Kalbos modeliai, naudojami kalbos atpažinimui, dažnai vertinami iš esmės naudojant bandymų duomenų perpleksiją arba iš išor ės naudojant automatinio kalbos atpažinimo (ASR) sistemą. The former evaluation does not always correlate well with ASR performance, while the latter could be specific to particular ASR systems.  Neseniai pasiūlyta įvertinti kalbų modelius, naudojant juos, kad būtų galima klasifikuoti foniškai panašius žodžius kaip alternatyvius foniškai panašius žodžius, kuriuos sukuria smulkios būsenos transliuotojas. Toks vertinimas grindžiamas prielaida, kad sukaupti sakiniai yra kalbiniu požiūriu neteisingi. Šiame dokumente mes pirmiausia abejojame šia prielaida ir pastebime, kad alternatyviai sukurti sakiniai dažnai gali būti kalbiniu požiūriu teisingi, kai jie skiriasi nuo esminės tiesos tik vienu redakciju. Antra, parodėme, kad naudojant daugiakalbį BERT galime pasiekti geresnius rezultatus nei ankstesnis darbas dviejuose kodų keitimo duomenų rinkiniuose. Mūsų įgyvendinimas viešai skelbiamas Github tinklalapyje https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_lt>
      <abstract_ms>Language models used in speech recognition are often either evaluated intrinsically using perplexity on test data, or extrinsically with an automatic speech recognition (ASR) system.  Evaluasi sebelumnya tidak sentiasa berkorrelasi dengan prestasi ASR, manakala yang terakhir boleh spesifik kepada sistem ASR tertentu. Kerja baru-baru ini dicadangkan untuk menilai model bahasa dengan menggunakannya untuk mengklasifikasikan kalimat kebenaran tanah diantara kalimat fonetik yang sama alternatif yang dijana oleh pengubah keadaan yang baik. Pada dasar penilaian seperti ini adalah asumsi bahawa kalimat yang dijana adalah bahasa yang salah. Dalam kertas ini, kita pertama-tama mempersoalkan asumsi ini, dan memperhatikan bahawa kalimat yang dijana secara alternatif sering benar secara bahasa apabila mereka berbeza dari kebenaran asas hanya dengan satu edit. Kedua, kami menunjukkan bahawa dengan menggunakan BERT berbilang-bahasa, kami boleh mencapai prestasi yang lebih baik daripada kerja sebelumnya pada dua set data penggantian kod. Pelaksanaan kami tersedia secara awam di Github di https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ms>
      <abstract_mk>Моделите на јазик кои се користат за препознавање на говорот честопати се проценуваат или внатрешно користејќи заглуженост на тестовите податоци, или надворешно со автоматско препознавање на говорот (АСР). Поранешната оценка не секогаш се корелира добро со резултатите на АСР, додека последната може да биде специфична за одредени системи на АСР. Неодамнешната работа предложи проценка на јазичките модели со користење на нив за класификување на речениците на основната вистина меѓу алтернативните фонетски слични реченици генерирани од фин државен трансдуктор. Основата на ваквата оценка е претпоставката дека генерираните реченици се јазички неправилни. Во овој весник, прво ја ставивме во прашање оваа претпоставка, и забележуваме дека алтернативно генерираните реченици честопати можат да бидат јазички точни кога се разликуваат од основната вистина само со еден уред. Второ, покажавме дека со користење на мултијазички БЕРТ, можеме да постигнеме подобра резултат од претходната работа на два набори податоци за промена на кодови. Нашата имплементација е јавно достапна на Гитуб на https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_mk>
      <abstract_it>I modelli linguistici utilizzati nel riconoscimento vocale sono spesso valutati intrinsecamente utilizzando perplessità sui dati di prova, o estrinsecamente con un sistema di riconoscimento vocale automatico (ASR). La prima valutazione non sempre correla bene con le prestazioni ASR, mentre la seconda potrebbe essere specifica per particolari sistemi ASR. Recenti lavori hanno proposto di valutare modelli linguistici utilizzandoli per classificare frasi di verità di base tra frasi foneticamente simili alternative generate da un trasduttore di stato fine. Alla base di tale valutazione c'è l'ipotesi che le frasi generate siano linguisticamente errate. In questo articolo, per prima cosa mettiamo in discussione questa ipotesi, e osserviamo che le frasi generate alternativamente potrebbero spesso essere linguisticamente corrette quando differiscono dalla verità di base con una sola modifica. In secondo luogo, abbiamo dimostrato che utilizzando BERT multilingue, possiamo ottenere prestazioni migliori rispetto ai lavori precedenti su due set di dati di commutazione del codice. La nostra implementazione è disponibile pubblicamente su Github all'indirizzo https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_it>
      <abstract_ml>സംസാരം തിരിച്ചറിയുന്നതില്‍ ഉപയോഗിക്കുന്ന ഭാഷ മോഡലുകള്‍ പലപ്പോഴും പരീക്ഷണവിവരങ്ങളില്‍ പെര്‍പ്പിക്സിറ്റി ഉപയോഗിക്കുന്നതിനെപ്പറ മുമ്പുള്ള വിലാസങ്ങള്‍ എസ്ആര്‍ പ്രവര്‍ത്തനത്തോടൊപ്പം നന്നായി ബന്ധപ്പെടുന്നില്ല, അവസാനം പ്രത്യേകിച്ച് ASR സിസ അടുത്ത പ്രവര്‍ത്തിക്കുന്നത് ഭാഷ മോഡലുകള്‍ വിലാസപ്പെടുത്തുവാന്‍ പ്രൊദ്ദേശിച്ചിരിക്കുന്നു. ഒരു നല്ല രാജ്യത്തിലെ ട്രാന്‍സ ഇങ്ങനെയുള്ള വിലാസങ്ങള്‍ ഭാഷയില്‍ തെറ്റാണെന്ന് കരുതിയിരിക്കുന്നു. ഈ പത്രത്തില്‍ നമ്മള്‍ ആദ്യം ഈ ഊഹം ചോദ്യം ചെയ്യുന്നു. മറ്റൊരു വാക്കുകള്‍ ഉണ്ടാക്കിയിരിക്കുന്നു വാക്കുകള്‍ മാത്രം ഭാഷക്കായി ശരിയ രണ്ടാമതായി, ഞങ്ങള്‍ കാണിച്ചു കൊടുത്തത് പല ഭാഷക്കാര്‍ ബെര്‍ട്ടി ഉപയോഗിച്ചാല്‍, മുമ്പ് രണ്ട് കോഡ് മാറ്റുന്ന ഡേറ്റാ സജ്ജീ ഞങ്ങളുടെ പ്രവര്‍ത്തനം ഗിത്തുബില്‍ പ്രസിദ്ധമാണ്. https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ml>
      <abstract_kk>Сөздерді анықтау үлгілерінде қолданылатын тіл үлгілері сынақтар деректерінде қарапайым, немесе автоматты сөздерді анықтау (ASR) жүйесінде қарапайым болады. Бұрынғы оқиға әрқашан ASR жүйелеріне қатынасыз болмайды, бірақ соңғы ASR жүйелеріне қатынасыз болуы мүмкін. Жуырдағы жұмыс тіл үлгілерін бағалау үшін оларды қолдану үшін қолданылатын альтернативті фонетикалық ұқсас сөздер арасындағы шындық сөздерді бағалау үшін қолданылады. Бұл оқиғаның негізінде жасалған сөздердің тілінде дұрыс емес деп ойлау. Бұл қағазда, біріншіден бұл таңдау сұраққа тастадық, және басқа жасалған сөйлемелерді тек бір өңдеу арқылы түрленгенде тілдік тілдігінен айырмалы болуы мүмкін. Екіншіден, біз көп тілді BERT қолданғанда, екі код ауыстыру деректерінің алдыңғы жұмысынан жақсы жұмыс істей аламыз. Біздің жұмыс істеуіміз жалпы жұмыс істеуіміз https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_kk>
      <abstract_mn>Холбоо таних үед хэрэглэгддэг хэл загварууд ихэвчлэн шалгалт өгөгдлийн хувьд гүйцэтгэлийг ашиглаж, эсвэл автоматик ярианы таних системтэй (ASR) байдаг. Өмнөх шалгалт нь АСР үйл ажиллагаатай үргэлж сайн холбоотой байхгүй. Харин эдгээр нь тодорхой АСР системд тодорхой байж болно. Шинэ хугацаанд хэл загварыг үнэлгээд үзүүлэхэд санал болгосон ажил нь үнэн үгийг өөрчлөгдөхөд байгууллагын орнуудын хувьд гаргасан утгатай илэрхийллийн хоорондоо хуваалцах боломжтой. Үүний үнэлгээ нь бий болсон өгүүлбэрүүд нь хэл хэлний буруу гэж үздэг. Энэ цаасан дээр бид эхлээд энэ тодорхойлолтыг асуулт оруулж, өөрчлөгдсөн өгүүлбэрүүдийг зөвхөн нэг засварлаад хэл хэлний зөв байж болно. Хоёрдугаарт, бид олон хэлний BERT-г ашиглаж, хоёр кодын шилжүүлэх өгөгдлийн хэлбэрээс илүү сайн үйл ажиллагааг гаргаж чадна. Бидний үйлдвэрлэл Гитюб дээр олон нийтэд https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_mn>
      <abstract_pl>Modele językowe stosowane w rozpoznawaniu mowy są często albo analizowane wewnętrznie przy użyciu zagadnień na danych testowych, albo zewnętrznie za pomocą systemu automatycznego rozpoznawania mowy (ASR). Pierwsza ocena nie zawsze koreluje dobrze z wydajnością ASR, natomiast ta druga może być specyficzna dla poszczególnych systemów ASR. W ostatnich pracach zaproponowano ocenę modeli językowych poprzez ich wykorzystanie do klasyfikacji zdań podstawowych wśród alternatywnych zdań fonetycznie podobnych generowanych przez przetwornik stanu drobnego. Podstawą takiej oceny jest założenie, że wygenerowane zdania są językowo niepoprawne. W niniejszym artykule najpierw kwestionujemy to założenie i zauważamy, że alternatywnie generowane zdania mogą być często poprawne językowo, gdy różnią się one od prawdy podstawowej tylko jedną edycją. Po drugie, pokazaliśmy, że dzięki zastosowaniu wielojęzycznego BERT możemy osiągnąć lepszą wydajność niż poprzednie prace nad dwoma zbiorami danych przełączającymi kod. Nasza implementacja jest publicznie dostępna na Github pod adresem: https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_pl>
      <abstract_ro>Modelele lingvistice utilizate în recunoașterea vorbirii sunt adesea fie evaluate intrinsec folosind perplexitatea datelor de testare, fie extrins cu un sistem de recunoaștere automată a vorbirii (ASR). Prima evaluare nu corelează întotdeauna bine cu performanța ASR, în timp ce cea din urmă ar putea fi specifică anumitor sisteme ASR. Lucrarea recentă a propus evaluarea modelelor lingvistice utilizându-le pentru clasificarea frazelor adevărului de bază între fraze fonetic similare alternative generate de un traductor de stare fină. La baza unei astfel de evaluări se află presupunerea că propozițiile generate sunt incorecte din punct de vedere lingvistic. În această lucrare, punem mai întâi în discuție această ipoteză și observăm că propozițiile generate alternativ pot fi adesea corecte lingvistic atunci când diferă de adevărul de bază printr-o singură editare. În al doilea rând, am arătat că prin utilizarea BERT multilingv, putem obține performanțe mai bune decât lucrările anterioare privind două seturi de date de comutare a codului. Implementarea noastră este disponibilă public pe Github la https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ro>
      <abstract_no>Språk- modeller som brukar i tale- gjenkjenning er ofte evaluert enten med perpleksitet på test data, eller ekstrinsic med eit automatisk tale- gjenkjenning (ASR). Den tidlegare evalueringa korrelatert ikkje alltid godt med ASR-utviklinga, mens dei siste kunne vera spesifikke til spesifikke ASR-systemer. Nyleg foreslått arbeid for å evaluera språk- modeller ved å bruka dei for å klassifisera grunnsannhetssetningar mellom alternativ fonetisk liknande setningar som er generert av ein fint tilstand- transducer. Underlysing av slike evaluering er assumpsjonen at dei genererte setningane er språk feil. I denne papiret sett vi først denne assumpsjonen inn i spørsmålet, og observerer at alternativ genererte setningar kan ofte vera språk rett når dei forskjeller frå bakgrunnsannheten med berre ein redigering. Sekundert viste vi at ved å bruka fleire språk BERT kan vi oppnå bedre utviklingar enn tidlegare arbeid på to datasett for å byta kodar. Implementasjonen vårt er offentlig tilgjengeleg på Github på https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_no>
      <abstract_sr>Jezikovi modeli koji se koriste u prepoznavanju govora često se procjenjuju ili koriste perpleksitu na testnim podacima ili ekstrinsicno sa automatskim prepoznavanjem govora (ASR). Bivša procjena ne uvek dobro povezuje sa ASR-om, dok bi poslednja mogla biti specifična za posebne ASR-ove sisteme. Nedavni rad predložio je procjenu jezičkih modela koristeći ih kako bi klasifikovao zemaljske rečenice istine među alternativnim fonetički sličnim rečenicama koje je proizvela fin državni prevoditelj. Na temelju takve procjene je pretpostavka da su proizvedene rečenice jezički nepravedne. U ovom papiru, prvo smo postavili ovu pretpostavku na pitanje i posmatrali da alternativno proizvedene rečenice često mogu biti jezički ispravne kada se razlikuju od zemlje istine samo jednim editorom. Drugo, pokazali smo da koristeći višejezički BERT, možemo postići bolju izvedbu nego prethodni rad na dva seta prebacivanja kodova. Naša provedba je javno dostupna na Githubu https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_sr>
      <abstract_si>භාෂා මොඩේල් භාවිතා කතා පරීක්ෂණය සඳහා ස්වයංක්‍රීය කතා පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා භාවිතා කතා පරීක්ෂණය සඳහා භ පළවෙනි විශ්ලේෂණය හැමවෙලේම ASR ප්‍රමාණය සමග හොඳ සම්බන්ධ වෙන්නේ නෑ, පළවෙනි විශේෂ ASR පද්ධතිය සමග අන්තිම වැඩේ භාෂාව මොඩේල්ස් විශ්වාස කරන්න ප්‍රයෝජනය කරන්න ප්‍රයෝජනය කරන්න ප්‍රයෝජනය කරලා භාෂාව ඇත්ත කිරීම ස ඒ වගේ විශ්ලේෂණයක් තියෙන්නේ නිර්මාණය විශ්ලේෂණයක් භාෂාවික වැරදියි කියලා හිතන්නේ. මේ පත්තරේ අපි මුලින්ම මේ විශ්වාසය ප්‍රශ්නයක් දාලා තියෙනවා, ඒ වගේම ප්‍රශ්නයක් දැනගන්න පුළුවන් කියලා බලන්න, ඒ වගේ දෙවෙනි විදියටම, අපි පෙන්වන්නේ ඒක ගොඩක් භාෂාවක් BERT භාවිතා කරන්න, අපිට පුළුවන් කලින් කෝඩ් සැට් දෙකට වෙනස්  අපේ පරීක්ෂණය ජිතුබ් වලින් ප්‍රතිකාරයෙන් ප්‍රවේශ වෙන්න පුළුවන් https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_si>
      <abstract_mt>Il-mudelli lingwistiċi użati fir-rikonoxximent tad-diskors spiss jiġu evalwati jew b’mod intrinsiku bl-użu ta’ perplessità fuq id-dejta tat-test, jew b’mod estern b’sistema ta’ rikonoxximent awtomatiku tad-diskors (ASR). L-evalwazzjoni preċedenti mhux dejjem tikkorrelata tajjeb mal-prestazzjoni tal-ASR, filwaqt li din tal-aħħar tista’ tkun speċifika għal sistemi tal-ASR partikolari. Xogħol reċenti propost biex jiġu evalwati l-mudelli lingwistiċi billi jintużaw biex jiġu kklassifikati sentenzi tal-verità tal-art fost sentenzi alternattivi fonetikament simili ġġenerati minn trasdutur tal-istat fin. Il-bażi ta’ tali evalwazzjoni hija s-suppożizzjoni li s-sentenzi ġġenerati huma lingwistikament inkorretti. F’dan id-dokument, l-ewwel qajmu din is-suppożizzjoni f’dubju, u osservaw li sentenzi ġenerati alternattivament ħafna drabi jistgħu jkunu lingwistikament korretti meta jkunu differenti mill-verità tal-bażi b’edizzjoni waħda biss. It-tieni nett, urejna li bl-użu ta’ BERT multilingwi, nistgħu niksbu prestazzjoni aħjar minn ħidma preċedenti fuq żewġ settijiet ta’ dejta li jaqilbu l-kodiċijiet. L-implimentazzjoni tagħna hija disponibbli pubblikament fuq Github fuq https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_mt>
      <abstract_so>Tilmaamaha aqoonsashada luuqada waxaa inta badan lagu qiimeeyaa mid ka mid ah macluumaadka imtixaanka, ama si gaar ah waxaa lagu qiimeeyaa nidaamka aqoonsiga hadalka (ASR). Qiimeyntii hore marwalba si wanaagsan uma xiriiro sameynta ASR, marka ugu dambaystu ay gaar u tahay nidaamka ASR. Shaqo la soo dhowaaday waxaa lagu talo galay in lagu qiimeeyo noocyada luuqada ee lagu isticmaalo si ay u kala qeybeeyaan xukunka runta ah ee ku dhex jira erayo kala duduwan oo afka internetka ah oo la mid ah oo uu soo dhashay wadamada wanaagsan. Qiimeynta caynkaas ah waxaa ku hoos jira malaynaya in maxalkii soo dhashay ay si luuqad ah u khatar yihiin. Marka ugu horeysa waxaynu ka fekernay malayaashan, waxaynu fiirinaynaa in erayo kala duwan loo soo dhashay ay si luqad ah u hagaajin karto marka ay runta ka kala duwan yihiin marka ay isku hagaajiyaan. Second, waxan tusnay in lagu isticmaalo luuqado kala duduwan BERT, waxaynu heli karnaa wax ka wanaagsan sameyn karno shaqo hore oo ku qoran labada kooban oo macluumaad beddelaya. Aqoonsashadeeda waxa lagu helaa Github https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_so>
      <abstract_ta>பேச்சு அறிவிப்பில் பயன்படுத்தப்படும் மொழி மாதிரிகள் பெரும்பாலும் சோதனை தரவில் பிரச்சனையை உபயோகிக்கும் உள்ளிருந்தாலும் அல்லத முந்தைய evaluation is not always good with ASR performance, while the latter can be specific ASR systems. சமீபத்தில் வேலை மொழி மாதிரிகளை மதிப்பீடு செய்ய உபயோகித்து, மாற்று போன்டெச்சிக்காக ஒரு நல்ல நாட்டு மாற்றுபவரால் உருவாக்க இவ்வாறு ஒரு மதிப்பினை கீழே உருவாக்கப்பட்ட வாக்கியங்கள் மொழியில் தவறானது என்று எண்ணுகிறது. இந்த காகிதத்தில், நாம் முதலில் இந்த கருத்துவத்தை கேள்வியில் வைத்தோம். மாற்று உருவாக்கப்பட்ட வாக்குகள் மொழியில் சரியாக இருக்கும இரண்டாவது, பல மொழிகள் BERT பயன்படுத்தினால், முந்தைய இரண்டு குறிமுறை மாற்றும் தரவு அமைப்புகளில் மேலும் சிறந்த செயல்பாட்டை நாம எங்கள் செயல்பாடு கித்துப் மீது பொதுவாக கிடைக்கும் https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ta>
      <abstract_ur>زبان کی معلومات میں استعمال کی زبان کی موڈل اغلبہ طور پر آزمائش کرتا ہے یا آزمائش ڈیٹوں پر پرلکسٹی کے استعمال کرتا ہے یا آزمائش کی بات کی شناخت (ASR) سیسٹم کے ساتھ خارجی سے۔ پہلی ارزیابی ہمیشہ ASR کے ساتھ اچھی طرح تعلق نہیں کرتی، حالانکہ آخری طرح مخصوص ASR سیستم کے لئے خاص ہو سکتی ہے. اگلے کام کی پیشنهاد کی تھی کہ زبان موڈل کا ارزش کریں ان کے استعمال کریں کہ زمین حقیقی کلیزوں کو ایک اچھی حالت مترجم کرنے والے کے ذریعے پیدا کیا جاتا ہے۔ اس طرح کی ارزیابی کے نیچے یہ گمان ہے کہ پیدا کئے ہوئے جماعت زبان سے غلط ہیں. اس کاغذ میں ہم پہلی بار اس فرضی کو سوال میں ڈال دیتے ہیں اور دیکھتے ہیں کہ اچھی طرح پیدا کئے ہوئے کلمات اکثر زبان کے ساتھ درست ہوسکتے ہیں جب وہ زمین سے صرف ایک سمجھ سے مختلف ہوتے ہیں۔ دوسرا، ہم نے دکھایا کہ multi-lingual BERT کے استعمال سے، ہم پہلے سے دو کوڈ-سوچینگ ڈیٹ سٹ پر بہتر کام پہنچا سکتے ہیں۔ ہماری عملکرد جتّوب پر ظاہر طور پر موجود ہے https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ur>
      <abstract_sv>Språkmodeller som används vid taligenkänning utvärderas ofta antingen i sig själva med hjälp av förvirring på testdata, eller extrinskt med ett system för automatisk taligenkänning (ASR). Den förra utvärderingen korrelerar inte alltid väl med ASR-prestanda, medan den senare kan vara specifik för vissa ASR-system. Nyligen föreslagna arbeten för att utvärdera språkmodeller genom att använda dem för att klassificera grundsanningar bland alternativa fonetiskt liknande meningar genererade av en fintillståndstranducer. Bakgrunden för en sådan utvärdering är antagandet att de genererade meningarna är språkligt felaktiga. I denna uppsats ifrågasätter vi först detta antagande, och observerar att alternativt genererade meningar ofta kan vara språkligt korrekta när de skiljer sig från grundsanningen genom endast en redigering. För det andra visade vi att vi genom att använda flerspråkig BERT kan uppnå bättre prestanda än tidigare arbete med två datauppsättningar för kodväxling. Vår implementering är offentligt tillgänglig på Github på https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_sv>
      <abstract_uz>Name Oldingi qiymatlar har doim ASR amalning bajarishi bilan yaxshi bogʻ'lanmaydi, ammo oxirgi ASR tizimlari notoʻgʻri bo'lishi mumkin. Yaqinda ishni tilning modellarini qiymatlashni istaysizmi, boshqa fonetga oʻxshagan so'zlar tarkibini o'zgartirish uchun soʻng haqiqiqiy so'zlarini o'rganadi. Bunday qiymatning asosida, yaratilgan so'zlar tillarda notoʻgʻri deb hisoblanadi. Bu qogʻozda biz buni birinchi savol qilamiz. Ko'rib chiqqamiz, boshqa natijasida so'zlar o'zgarishda o'zgarishlar faqat bir tahrirlar bilan bir so'zlarni o'zgartirishda o'zgarishda o'zgarishda o'zgarishdir. Ikkinchi so'zda, biz bir necha tillar BERT yordamida bir necha tilni ko'rsatdik, biz ikki kodlash maʼlumot tarkibini o'zgartirishdan yaxshi ishni bajaramiz mumkin. Bizning ishlashimiz Github'da https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_uz>
      <abstract_vi>Ngôn ngữ được sử dụng trong việc nhận dạng ngôn ngữ thường được đánh giá bằng tính phức tạp trên dữ liệu thử nghiệm, hoặc với một hệ thống nhận dạng ngôn ngữ tự động (ASR). Một bản kiểm tra trước không hợp với khác năng ASR, trong khi nó có thể chính xác với một bộ hệ thống ASR đặc biệt. Công việc gần đây đã đề nghị đánh giá các mô hình ngôn ngữ bằng cách sử dụng chúng để phân loại các câu nói chân trần giữa các câu khác nhau nhau nhau tạo ra bởi một người chuyển biến bang. Dựa trên đánh giá này là giả định các câu đã tạo ra là không đúng ngôn ngữ. Trong tờ giấy này, chúng ta đầu tiên đặt sự giả định này vào nghi vấn, và quan sát rằng các câu từ tạo ra theo cách khác thường có thể được chính thức ngôn ngữ chính xác khi chúng khác nhau với thực tại bằng một bản soạn thảo duy nhất. Thứ hai, chúng tôi đã cho thấy bằng ngôn ngữ rộng Berlin, chúng tôi có thể đạt kết quả tốt hơn việc làm trước trên hai bộ truyền dữ liệu. Việc thực hiện của chúng ta công khai tại Gita ở https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_vi>
      <abstract_bg>Езиковите модели, използвани в разпознаването на речта, често се оценяват интензивно чрез използване на объркване върху тестови данни, или външно чрез система за автоматично разпознаване на речта (АСР). Първата оценка не винаги корелира добре с ефективността на АСР, докато последната може да бъде специфична за определени АСР системи. Последна работа предлага да се оценят езикови модели, като се използват за класифициране на основни изречения на истината сред алтернативни фонетично подобни изречения, генерирани от фин трансдуктор. В основата на такава оценка е предположението, че генерираните изречения са лингвистично неправилни. В тази статия първо поставяме под въпрос това предположение и наблюдаваме, че алтернативно генерираните изречения често могат да бъдат лингвистично правилни, когато се различават от основната истина само с една редакция. Второ, показахме, че с помощта на многоезичен BERT можем да постигнем по-добри резултати от предишната работа по два набора данни за превключване на кодове. Нашата имплементация е публично достъпна в Гитхъб на https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_bg>
      <abstract_da>Sprogmodeller, der anvendes i talegenkendelse, evalueres ofte enten i sig selv ved hjælp af forvirring på testdata, eller eksternt ved hjælp af et automatisk talegenkendelsessystem (ASR). Den førstnævnte evaluering korrelerer ikke altid godt med ASR ydeevne, mens sidstnævnte kunne være specifik for bestemte ASR systemer. Nylige arbejder foreslog at evaluere sprogmodeller ved at bruge dem til at klassificere grundsandhedssætninger blandt alternative fonetisk lignende sætninger genereret af en fin tilstand transducer. Grundlaget for en sådan vurdering er antagelsen om, at de genererede sætninger er sprogligt forkerte. I denne artikel sætter vi først spørgsmålstegn ved denne antagelse og bemærker, at alternativt genererede sætninger ofte kan være sprogligt korrekte, når de adskiller sig fra grundsandheden ved kun én redigering. For det andet viste vi, at vi ved at bruge flersproget BERT kan opnå bedre ydeevne end tidligere arbejde med to kodeskift datasæt. Vores implementering er offentligt tilgængelig på Github på https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_da>
      <abstract_hr>Jezički modeli koji se koriste u priznanju govora često se procjenjuju ili koriste perpleksitu na ispitivanju podataka ili ekstrinsicno s automatskim priznanjem govora (ASR). Bivša procjena ne uvijek dobro povezuje s ASR-om, dok je posljednja mogla biti specifična za posebne ASR sustave. Nedavni rad predložio je procjenu jezičkih modela koristeći ih kako bi klasifikirali zemaljske kazne istine među alternativnim fonetički sličnim rečenicama koje je proizvela fin državni prevoditelj. Na temelju takve procjene je pretpostavka da su proizvedene rečenice jezički nepravedne. U ovom papiru smo prvi put stavili ovu pretpostavku u pitanje i posmatrali da alternativno proizvedene rečenice često mogu biti jezički ispravne kada se razlikuju od temeljne istine samo jednim uredom. Drugo, pokazali smo da koristeći višejezički BERT, možemo postići bolji učinkovit nego prethodni rad na dva seta prebacivanja kodova podataka. Naša provedba je javno dostupna na Githubu https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_hr>
      <abstract_nl>Taalmodellen die worden gebruikt in spraakherkenning worden vaak ofwel intrinsiek geëvalueerd met behulp van verwarring op testgegevens, ofwel extrinsiek met een automatisch spraakherkenningssysteem (ASR). De eerste evaluatie correleert niet altijd goed met ASR prestaties, terwijl de laatste specifiek kan zijn voor bepaalde ASR systemen. Recent werk stelde voor om taalmodellen te evalueren door ze te gebruiken om basiswaarheidszinnen te classificeren onder alternatieve fonetisch vergelijkbare zinnen gegenereerd door een fijne state transducer. Aan een dergelijke evaluatie ligt de veronderstelling ten grondslag dat de gegenereerde zinnen taalkundig onjuist zijn. In dit artikel stellen we eerst deze veronderstelling ter discussie en stellen we vast dat alternatief gegenereerde zinnen vaak taalkundig correct kunnen zijn wanneer ze met slechts één bewerking van de basiswaarheid verschillen. Ten tweede hebben we laten zien dat we met meertalige BERT betere prestaties kunnen behalen dan eerder werk aan twee codeswitching datasets. Onze implementatie is openbaar beschikbaar op Github op https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_nl>
      <abstract_de>Sprachmodelle, die in der Spracherkennung verwendet werden, werden oft entweder intrinsisch anhand von Ratlosigkeit auf Testdaten ausgewertet, oder extern mit einem automatischen Spracherkennungssystem (ASR). Die erste Bewertung korreliert nicht immer gut mit der ASR-Leistung, während letztere spezifisch für bestimmte ASR-Systeme sein könnte. Neuere Arbeiten schlugen vor, Sprachmodelle zu bewerten, indem sie verwendet werden, um Grundwahrheitssätze unter alternativen phonetisch ähnlichen Sätzen zu klassifizieren, die von einem Feinzustandswandler erzeugt werden. Grundlage einer solchen Bewertung ist die Annahme, dass die generierten Sätze sprachlich falsch sind. In diesem Beitrag stellen wir diese Annahme zunächst in Frage und beobachten, dass alternativ generierte Sätze oft sprachlich korrekt sein könnten, wenn sie sich nur um einen Schnitt von der Grundwahrheit unterscheiden. Zweitens haben wir gezeigt, dass wir durch den Einsatz von mehrsprachigem BERT eine bessere Leistung erzielen können als bisherige Arbeiten an zwei Code-Switching-Datensätzen. Unsere Implementierung ist öffentlich auf Github unter https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_de>
      <abstract_fa>مدل‌های زبانی که در شناسایی سخنرانی استفاده می‌شود اغلب با استفاده از پرچسبی در داده‌های آزمایش یا با سیستم شناسایی سخنرانی خودکار (ASR) ارزیابی می‌شوند. ارزیابی قبلی همیشه با کاربرد ASR به خوبی ارتباط ندارد، در حالی که آن‌ها می‌توانند برای سیستم‌های مخصوص ASR خاص باشند. کارهای اخیرا پیشنهاد داده شده که از طریق استفاده از آنها مدل زبانی را ارزیابی کند تا جمله‌های حقیقت زمینی را در میان جمله‌های جایگزینه‌ای که توسط یک ترجمه‌کننده ایالت خوب تولید می‌کند، تحریک کند. بر اساس این ارزیابی فرض است که جمله‌های تولید شده به زبان غلط هستند. در این کاغذ، ما اولین بار این فرضیه را به سوال پرسیدیم، و مشاهده کردیم که جمله‌های پیدا شده‌ای اغلب می‌تواند با زبان‌شناسی درست باشند، وقتی آنها با تنها یک تغییر از حقیقت زمین اختلاف می‌کنند. دوم، ما نشان دادیم که با استفاده از BERT متعدد زبان، ما می توانیم عملکرد بهتر از کار قبلی در مجموعه‌های تغییر داده‌های کودک رسیده باشیم. عمليات ما در جيتوب در عمومي موجود است https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_fa>
      <abstract_id>Model bahasa yang digunakan dalam pengenalan pidato sering diteliti secara intrinsik menggunakan kekacauan pada data ujian, atau secara ekstrinis dengan sistem pengenalan pidato otomatis (ASR). Evaluasi sebelumnya tidak selalu berkorelasi dengan prestasi ASR, sementara yang terakhir bisa spesifik pada sistem ASR tertentu. Pekerjaan baru-baru ini diusulkan untuk mengevaluasi model bahasa dengan menggunakannya untuk mengklasifikasikan kalimat kebenaran tanah diantara kalimat alternatif fonetik mirip yang dihasilkan oleh transdutor negara yang baik. Menasakan evaluasi seperti itu adalah asumsi bahwa kalimat yang dihasilkan adalah bahasa yang salah. Dalam kertas ini, kita pertama-tama mempertanyakan asumsi ini, dan memperhatikan bahwa kalimat yang secara alternatif dapat sering benar secara bahasa ketika mereka berbeda dari kebenaran dasar hanya dengan satu edit. Kedua, kami menunjukkan bahwa dengan menggunakan BERT berbagai bahasa, kami dapat mencapai prestasi yang lebih baik dari pekerjaan sebelumnya pada dua set data penggantian kode. Implementasi kami tersedia publik di Github di https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_id>
      <abstract_ko>음성인식에 사용되는 언어모델은 일반적으로 테스트 데이터에서 복잡도를 사용하여 내재적인 평가를 하거나 자동음성인식(ASR) 시스템에서 외재적인 평가를 한다.앞의 평가가 항상 ASR 성능과 잘 연관된 것은 아니지만, 뒤의 평가는 특정한 ASR 시스템에 특정될 수 있다.최근의 작업에서는 기본적인 진리 문장을 정세상태 센서로 생성된 음성과 비슷한 대체문장으로 분류하는 언어모델을 평가하고 있다.이런 평가의 기초는 생성된 문장이 언어적으로 정확하지 않다고 가정하는 것이다.본고에서 우리는 먼저 이 가설에 대해 의문을 제기하고 번갈아 생성된 문장이 기본적인 사실과 한 번의 차이로 편집될 때 언어적으로 정확하다는 것을 관찰했다.그 다음으로 우리는 다국어 BERT를 사용하여 두 개의 코드 교환 데이터 집합에서 이전보다 더 좋은 성능을 얻을 수 있음을 증명했다.Github에 공개https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ko>
      <abstract_sw>Mradi wa lugha unaotumiwa kwa kutambua hotuba mara nyingi huvutiwa ama kwa kutumia utatibu wa taarifa za jaribio, au kwa upande mwingine kwa mfumo wa kutambua hotuba (ASR). Utafiti wa zamani haujahusiana vizuri na utendaji wa ASR, wakati mwisho unaweza kuwa na mifumo maalum ya ASR. Kazi ya hivi karibuni ilipendekezwa kutathmini mifano ya lugha kwa kutumia hizo kwa kutangaza hukumu za ukweli kati ya hukumu mbadala za simu za mkononi zilizotengenezwa na mwanzilishaji mzuri wa serikali. Kufuatia tathmini kama hizi ni dhana kwamba hukumu zilizozaliwa zimo sahihi kwa lugha. Katika karatasi hii, kwa mara ya kwanza tunaweka dhana hii kuhoji, na kuona kuwa hukumu mbadala zilizotengenezwa kwa lugha mara nyingi inaweza kuwa sahihi wakati wanatofautiana na ukweli wa ardhi kwa kuhariri moja tu. Pili, tulionyesha kwamba kwa kutumia lugha mbalimbali ya BERT, tunaweza kupata ufanisi bora kuliko kazi iliyopita katika seti mbili za kubadilisha taarifa. Utumiaji wetu unapatikana hadharani kwenye Github https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_sw>
      <abstract_af>Taal modelles gebruik word in spraak herkening dikwels of intrinsiese deur te gebruik perpleksie op toets data, of ekstrinsic met 'n outomatiese spraak herkening (ASR) stelsel. Die vorige evaluasie doen nie altyd goed korrelaat met ASR-prestasie, terwyl die laaste kon spesifieke wees vir spesifieke ASR-stelsels. Onlangse werk het voorgestel om taal modele te evalueer deur hulle te gebruik om grondwaarheid te klassifiseer onder alternatiewe fonetiese gelyke setinge wat deur 'n fyn staatsoordrager genereer word. Onderlys sodanige 'n evaluasie is die aanvaar dat die genereerde setinge lingwisies verkeerd is. In hierdie papier het ons eerste hierdie aanvaar in vraag gesit en aanhou dat alternatiewe genereerde setinge dikwels lingwisieslik korrek kan wees wanneer hulle verskillig is van die grond waarheid deur slegs een redigeer. Tweede, ons het vertoon dat deur multi-tale BERT te gebruik, ons kan beter prestasie bereik as vorige werk op twee kode-wissel data stelle. Ons implementasie is openbaar beskikbaar op Github https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_af>
      <abstract_tr>Sözler tanamakda ullanýan dil nusgalary köplenç testiň maglumatynda, ýada awtomatik çykyş tanamakda (ASR) sistemi bilen girişikde deňlenýär. Öňki çykyş ASR ukyplary bilen elmydama gowy görnüşmez, diňki ASR sistemalara takyk bolup biler. Ýakynda işleýän işler dil nusgalaryny çykarmak üçin olaryň ýerli sözlerini ajaýyp durum terjime eden sözleriň arasynda klasifik etmek üçin üýtgedildi. Şol ýaly çözümlenme üçin döredilen sözleriň dil ýalňyş diýip pikir edýär. Bu kagyzda ilkinji gezek biz bu pikirleri soraga berdik we başga bir şekilde üretilen sözleri diňe bir edit bilen tapawutlyklarynda lingwistiki düzgün bolup bilerdik. Ikinjisi, birnäçe dilli BERT ulanarak, öňki işiň iki köd üýtgetmeginden has gowy etkinlik başaryp bileris. Biziň implementasimiz Githubda publikak bar https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_tr>
      <abstract_sq>Modelet gjuhësore të përdorura në njohjen e fjalës shpesh vlerësohen në mënyrë të brendshme duke përdorur perplexitetin në të dhënat e testit ose jashtë me një sistem automatik njohjeje të fjalës (ASR). Vlerësimi i mëparshëm nuk korrelon gjithmonë mirë me performancën e ASR, ndërsa e fundit mund të jetë specifik për sistemet e posaçme të ASR. Puna e fundit propozoi për të vlerësuar modelet gjuhësore duke i përdorur a to për të klasifikuar fjalët e vërtetë të themeluara midis fjalëve alternative fonetikisht të ngjashme të gjeneruara nga një transducer i mirë shteti. Nën bazë të një vlerësimi të tillë është supozimi se fjalët e gjeneruara janë gjuhësisht të gabuara. Në këtë letër, ne fillimisht e vëmë në dyshim këtë supozim, dhe vëzhgojmë se fjalët e gjeneruara alternativisht shpesh mund të jenë gjuhësisht të sakta kur ato ndryshojnë nga e vërteta themelore vetëm me një editim. Së dyti, ne treguam se duke përdorur BERT shumëgjuhës, ne mund të arrijmë performancë më të mirë se puna e mëparshme në dy grupe të dhënash për ndërrimin e kodeve. Zbatimi ynë është në dispozicion publik në Github në https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_sq>
      <abstract_am>በንግግር ማስታወቂያ የሚጠቀሙ የቋንቋ ሞዴላዎች ብዙ ጊዜ በሥርዓት ዳታዎችን በመጠቀም ወይም በአውራጭ በንግግር ማውቀት (ASR) ስርዓት የተጠቃቀሙ ናቸው፡፡ የቀድሞው ማስታወቂያ ሁልጊዜ በASR ፈቃድ መልካም አይታሰርም፣ የመጨረሻውም ለአASR ስርዓት የተለየ ነው፡፡ በአሁኑ ጊዜ የቋንቋ ምሳሌዎች በመጠቀም የእውነትን ቃል በመለየል በመስመር በተለይ ፎንጤክስቲካዊ በመስጠት በተደረገ የመሬት ቃላት እንዲለይ ተዘጋጅቷል፡፡ እንደዚህ ያለ ማስታወቂያ ውስጥ የተፈጠሩት የቋንቋ ቃላት ስህተት ነው፡፡ በዚህ ካላት፣ አስቀድመን ይህንን ስህተት ለመጠየቅ እናስባለን፣ በተለይ የተፈጠረውን ቃላት ከመሬት እውነትን በተለየ ጊዜ በቋንቋ ማሳየት ይችላል፡፡ ሁለተኛውም፣ በብዙ ቋንቋ BERT በመጠቀም፣ የቀድሞው የዳታ-ማተላለፊያ ስራ ላይ ከመጠቀም የበለጥን ሥራ እናደርጋለን፡፡ የግቶብ አካባቢነታችን በጊቱብ ላይ የተገኘ ነው https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_am>
      <abstract_hy>Լեզվային մոդելները, որոնք օգտագործվում են խոսքի ճանաչման մեջ, հաճախ գնահատվում են կամ ներքին առումով՝ օգտագործելով փորձարկման տվյալների խառնաշփոթ, կամ արտաքին առումով՝ ավտոմատիկ խոսքի ճանաչման (ASR)  Առաջին գնահատումը միշտ լավ չի կապված ASR-ի արդյունքների հետ, մինչդեռ վերջինը կարող է հատուկ լինել որոշակի ASR-ի համակարգերի հետ: Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer.  Այսպիսի գնահատման հիմքում ենթադրվում է, որ ստեղծված նախադասությունները լեզվաբանական սխալ են: Այս թղթի մեջ մենք սկզբում հարցեր ենք տալիս այս ենթադրությունը և հետևում ենք, որ այլընտրանքային կերպ ստեղծված նախադասությունները հաճախ լեզվաբանական ճիշտ են, երբ դրանք տարբերվում են հիմնական ճշմարտությունից միայն մեկ խմբագրությամբ: Երկրորդ, մենք ցույց տվեցինք, որ օգտագործելով բազլեզու BER-ը, մենք կարող ենք ավելի լավ արդյունք հասնել, քան նախորդ աշխատանքը երկու կոդ փոխելու տվյալների համակարգերի վրա: Մեր իրականացումը հանրային հասանելի է https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_hy>
      <abstract_bn>ভাষার মডেল প্রায়শই পরীক্ষার তথ্যে ব্যবহার করে ভাষার স্বীকৃতি স্বীকৃতি ব্যবহার করা হয়, অথবা স্বয়ংক্রিয় ভাষণ স্বীকৃতির (ASR) সিস্টেম প্রাক্তন মূল্যের মূল্য সবসময় ASR প্রদর্শনের সাথে ভালোভাবে সংশ্লিষ্ট নয়, কিন্তু পরবর্তীতে এসআর সিস্টেমের বিশেষ বি সাম্প্রতিক কাজের প্রস্তাব করা হয়েছে ভাষার মডেল বিকল্প ফোনেটিক্যালিকভাবে একটি ভাল রাষ্ট্রের ট্রান্সপ্রেসিডারের দ্বারা  এই ধরনের মূল্যের ভিত্তিতে এই ধারণা যে সৃষ্টিকর্তা ভাষায় ভাষায় ভুল। এই কাগজটিতে আমরা প্রথমে এই ধারণাকে প্রশ্ন করি এবং দেখি যে বিকল্প ভাবে তৈরি হয়েছে যে ভাষায় শাস্তি প্রায়শই ভাষায় সঠিক হতে পারে যখন তারা মাট দ্বিতীয়, আমরা দেখিয়েছিলাম যে মাল্টিভাষায় বেরেট ব্যবহার করে আমরা পূর্বের কাজের চেয়ে ভালো কাজ অর্জন করতে পারি দুই কোড-পরিবর্তন আমাদের ব্যবস্থা গিথুবে প্রকাশ্যে পাওয়া যাচ্ছে https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_bn>
      <abstract_az>Sözlük tanımasında istifadə edilən dil modelləri sınaq verilən məlumatlarda müxtəlif tərzdə istifadə edərək və ya avtomatik danışma sistemi ilə istifadə edilərlər. Əvvəlki değerlendirmə həmişə ASR performansı ilə yaxşı bir bağlı deyildir, amma sonuncusu müəyyən ASR sistemlərinə müəyyən edilə bilər. Əvvəlki işlər dil modellərini değerləşdirmək üçün təbliğ edilmişdir. Onları istifadə edərək yerli həqiqət sözlərini seçmək üçün seçmişdir. Əlbəttə, eyni vəziyyət tərcümcisi tarafından yaratdığı alternatif fonetik kimi cüm Bütün bu təcrübələrin əslində təşkil edilmiş cümlələrin dilində yanlış olduğunu iddia edir. Bu kağızda ilk dəfə bu zənnə sual çəkdik və başqa təşkil edilmiş cümlələr yalnız bir düzəltmə ilə təşkil edildikdə dilində düzgün olar. İkincisi, çoxlu dilli BERT vasitəsilə, əvvəlki işlərdə iki kodu dəyişdirən verilən qutulardan daha yaxşı performansı olaraq göstərdik. Bizim həyatımız Github'da https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_az>
      <abstract_bs>Jezički modeli koji se koriste u prepoznavanju govora često se procjenjuju ili koriste perpleksitu na testnim podacima ili ekstrinsicno sa automatskim prepoznavanjem govora (ASR). Bivša procjena ne uvijek dobro povezuje s ASR-om, dok bi to mogla biti specifična za posebne ASR-ove sisteme. Nedavni rad predložio je procjenu jezičkih modela koristeći ih kako bi klasifikovao zemaljske rečenice istine među alternativnim fonetički sličnim rečenicama koje je proizvela fin državni prevoditelj. Na temelju takve procjene je pretpostavka da su proizvedene rečenice jezički nepravedne. U ovom papiru, prvo smo postavili ovu pretpostavku u pitanje, i posmatrali da alternativno proizvedene rečenice često mogu biti jezički ispravne kada se razlikuju od temeljne istine samo jednim uredom. Drugo, pokazali smo da koristeći višejezički BERT, možemo postići bolji učinkovit nego prethodni rad na dva seta prebacivanja kodova podataka. Naša provedba je javno dostupna na Githubu https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_bs>
      <abstract_cs>Jazykové modely používané při rozpoznávání řeči jsou často vyhodnocovány buď intrinsicky pomocí zmatenosti na testovacích datech, nebo extrinzně pomocí systému automatického rozpoznávání řeči (ASR). První hodnocení ne vždy dobře koreluje s výkonem ASR, zatímco druhé může být specifické pro konkrétní ASR systémy. Nedávná práce navrhla vyhodnocení jazykových modelů pomocí nich klasifikovat základní věty pravdy mezi alternativní foneticky podobné věty generované jemným stavovým převodníkem. Základem takového hodnocení je předpoklad, že generované věty jsou jazykově nesprávné. V tomto článku nejprve tento předpoklad zpochybňujeme a pozorujeme, že alternativně generované věty mohou být často jazykově správné, pokud se liší od základní pravdy pouze jednou editací. Za druhé jsme ukázali, že použitím vícejazyčného BERT můžeme dosáhnout lepšího výkonu než předchozí práce na dvou datových sadách přepínání kódu. Naše implementace je veřejně dostupná na Githubu na adrese https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_cs>
      <abstract_ca>Els models de llenguatge utilitzats en el reconeixement de la fala sovint s'evaluen intrínsecament fent servir la perplexitat en les dades de prova, o extrinsicament amb un sistema de reconeixement automàtic de la fala (ASR). The former evaluation does not always correlate well with ASR performance, while the latter could be specific to particular ASR systems.  Una feina recent va proposar valorar els models lingüístics utilitzant-los per classificar frases fonèticament semblants entre frases alternatives generades per un transdutor d'estat fins. Sobre la base d'aquesta evaluació es suposa que les frases generades són lingüísticament incorrectes. En aquest article, primer vam posar en dubte aquesta suposició, i observem que les frases generades alternativament sovint podrien ser lingüísticament correctes quan difereixen de la veritat fonamental només per una edició. En segon lloc, vam demostrar que utilitzant BERT multilingüe podem aconseguir millor rendiment que la feina anterior en dos conjunts de dades de canvi de codi. La nostra implementació està disponible públicament a Github https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ca>
      <abstract_fi>Puheentunnistuksessa käytettävät kielimallit arvioidaan usein joko luonnostaan testidatan hämmennyksen avulla tai ulkoisesti automaattisella puheentunnistusjärjestelmällä (ASR). Edellinen arviointi ei aina korreloi hyvin ASR-suorituskyvyn kanssa, kun taas jälkimmäinen voisi koskea tiettyjä ASR-järjestelmiä. Viimeaikainen työ ehdotti kielimallien arvioimista luokittelemalla pohjatotuuslauseet vaihtoehtoisiin foneettisesti samankaltaisiin lauseisiin, jotka on luotu hienosäätimellä. Tällaisen arvioinnin taustalla on oletus siitä, että luodut lauseet ovat kielellisesti virheellisiä. Tässä artikkelissa asetamme ensin tämän olettamuksen kyseenalaiseksi ja huomaamme, että vaihtoehtoisesti luodut lauseet voivat usein olla kielellisesti oikeita, kun ne eroavat perustason totuudesta vain yhdellä muokkauksella. Toiseksi osoitimme, että monikielisen BERT-järjestelmän avulla voimme saavuttaa paremman suorituskyvyn kuin aikaisempi työ kahden koodinvaihtodatan parissa. Toteutus on julkisesti saatavilla Githubissa osoitteessa https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_fi>
      <abstract_et>Kõnetuvastuses kasutatavaid keelemudeleid hinnatakse sageli kas olemuslikult testiandmete segaduse abil või automaatse kõnetuvastuse (ASR) süsteemi abil. Esimene hindamine ei ole alati hästi seotud ASR-i jõudlusega, samas kui viimane võib olla spetsiifiline konkreetsetele ASR-süsteemidele. Hiljutises töös tehti ettepanek hinnata keelemudeleid, kasutades neid aluslausete klassifitseerimiseks alternatiivsete foneetiliselt sarnaste lausete hulka, mida tekitab peenoseisundiandur. Sellise hindamise aluseks on eeldus, et loodud laused on keeleliselt ebaõiged. Selles raamatus, me kõigepealt seame selle oletuse kahtluse alla ja täheldame, et alternatiivselt genereeritud laused võivad sageli olla keeleliselt õiged, kui nad erinevad põhitõest vaid ühe redigeerimisega. Teiseks näitasime, et mitmekeelse BERTi kasutamisega saame saavutada parema tulemuse kui varasem töö kahe koodi vahetamise andmekogumiga. Meie rakendus on avalikult kättesaadav Githubis aadressil https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_et>
      <abstract_jv>Validity Wurung perusahaan sing ora luwih nggawe barang kelas ASR seneng pisan, awak dhéwé sapa nik sistem ASR sing apik jhe. Algorithm Cubo mbok saiki pancene kuwi nggunakake kuwi susahe awak dhéwé buturan kanggo kelangan langgar. Nang mapun iki, awak dhéwé isih beraksi iki ning perspekan, lan nglanggar-awak dhéwé supoyo supaya awak dhéwé éntuk kanggo nguasakno sistem sing bisa basa luwih apik soalé dhéwé, akeh sing paling beraksi sing bakal terus tambah. Sikondhe, kita ngomongke sampeyan ngono sistem Multi-Lingui BERT, kita iso dianggap luwih apik sing luwih apik karo perusahaan podho sing bisa ngubah dhéwé. Jejaring-jejaring kita punika dipun ciptaaken neng GTub https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_jv>
      <abstract_sk>Jezikovni modeli, ki se uporabljajo pri prepoznavanju govora, se pogosto ocenjujejo bodisi intrinzično z uporabo zmedenosti na testnih podatkih, bodisi zunaj s sistemom samodejnega prepoznavanja govora (ASR). Prva ocena ni vedno dobro povezana z učinkovitostjo ASR, slednja pa bi lahko bila specifična za določene ASR sisteme. Nedavno delo je predlagalo vrednotenje jezikovnih modelov z njihovo uporabo za klasifikacijo osnovnih resničnih stavkov med alternativnimi fonetično podobnimi stavki, ki jih ustvari pretvornik finega stanja. Temelj take ocene je predpostavka, da so ustvarjeni stavki jezikovno napačni. V tem prispevku najprej postavimo pod vprašaj to domnevo in ugotavljamo, da so lahko alternativno ustvarjeni stavki pogosto jezikovno pravilni, če se od osnovne resnice razlikujejo samo z eno ureditvijo. Drugič, pokazali smo, da lahko z uporabo večjezičnega BERT dosežemo boljšo učinkovitost kot prejšnje delo na dveh naborih podatkov za preklop kod. Naša implementacija je javno dostopna na Githubu na spletni strani https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_sk>
      <abstract_he>דוגמני שפת שמשתמשים בזיהוי הנאום לעתים קרובות או מוערכים באופן פנימי בשימוש בלבול על נתוני מבחן, או מבחוץ עם מערכת זיהוי הנאום אוטומטי (ASR). הערכה הקודמת לא תמיד מתחברת היטב לביצוע ASR, בעוד האחרונה יכולה להיות ספציפית למערכות ASR מסוימות. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer.  בהתחשב בערכה כזו, הניחוש שהמשפטים הנוצרים לא נכונים בשפה. בעיתון הזה, אנחנו קודם שמים את ההנחה הזאת בספק, ומציפים כי משפטים שנוצרים באופן אלטרנטיבי יכולים לעתים קרובות להיות תקינים בשפה כשהם שונים מהאמת האדמה על ידי עורך אחד בלבד. שנית, הראינו כי על ידי השימוש במרבה שפות BERT, אנחנו יכולים להשיג ביצועים טובים יותר מהעבודה הקודמת על שני קבוצות נתונים להחליף קודים. ההפעלה שלנו זמינה בפומבי ב https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_he>
      <abstract_ha>Tildalun harshe da aka yi amfani da cikin sunan faɗaɗawa ana ƙayyade ko ana amfani da perfeksiya a cikin shirin jarraba data, ko a bayani, da sunan faɗaɗawa farat ɗaya (ATR). Babu ƙaddara na farko ba ta daidai da mai kyau game da performance na ATR, kuma amma ƙarshen za'a iya ƙayyade wasu na'urar haske. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer.  Ana ƙari da wannan an ƙaddara shi ne zato da aka ƙãga maganar a cikin harshen ƙarya ba'a gaskiya ba. Ga wannan takardan, za mu tambaye wannan zato na farko, kuma munã gani cewa, a matsayin da aka ƙãga wasu kalmõmi, za'a iya daidaita a lugha ko da yaushe suka sãɓã daga ƙasa da gaskiyar ta da editi guda kawai. Na ƙarshe, muka nũna cẽwa, da za mu iya sãmu mafiya alhẽri game da aikin farko a kan kodi biyu masu musanya data. Kayyadamu na da bayani a kan GiThb https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_ha>
      <abstract_bo>སྐད་ཡིག་Models used in speech recognition are often evaluated using perplexity on test data, or extrinsically with an automatic speech recognition (ASR) system. རྗེས་མཇུག་གི་བཟོ་ཚིག་དེ་གཞི་རྩ་བརྟན་པར་ཨ་སི་ཨར་གནས་སྟངས་དང་མཐུན་རྟགས་པར་མཐུན་མི་འདུག། དེ་ལས་མཇུག་ནི་ASR་མ་ སྔོན་ལ་གྱི་ལས་ཀ་དེ་ལྟར་སྔོན་སྒྲིག་ནི་སྐད་ཡིག་གཟུགས་རིས་ལྟར་ཞིབ་བྱེད་པ་ལས་ཕན་རིས་གཞུང་ཕྱོགས་བདེན་ཚོར་ཚུལ རྨས་གཞི་འདི་ལྟ་བུའི་དཔྱད་ཞིག་ནི་ཚིག་རྐྱང་ཡོད་པའི་ཚིག་རྟགས་སྐད་ཡིག་འབྲེལ་མེད་པར་ཕལ་མེད་རེད། ང་ཚོས་ཤོག་བྱས་འདིའི་ནང་དུ་ཚོས་ཐོག་མར་བསམ་བློ་གཏད་པའི་ཚིག་རྐང་ཡིག་འགྱུར་བ་དང་ཁ་ཤས་ཀྱིས་ཡོད་པའི་སྐད་རིགས་ལ་འགྱུར་བ Secondly, we showed that by using multi-lingual BERT, we can achieve better performance than previous work on code-switching data sets. ང་ཚོའི་ལག་སྟར་བྱེད་སྟངས་མང་ཆེ་བའི་Github ཐོག་ཏུ་སྤྱོད་ཐུབ་པ་རེད། https://github.com/sikfeng/language-modelling-for-code-switching.</abstract_bo>
      </paper>
    <paper id="12">
      <title>Perceived and Intended Sarcasm Detection with Graph Attention Networks</title>
      <author><first>Joan</first><last>Plepi</last></author>
      <author><first>Lucie</first><last>Flek</last></author>
      <pages>97–105</pages>
      <abstract>Existing sarcasm detection systems focus on exploiting <a href="https://en.wikipedia.org/wiki/Marker_(linguistics)">linguistic markers</a>, <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a>, or user-level priors. However, social studies suggest that the relationship between the author and the audience can be equally relevant for the sarcasm usage and interpretation. In this work, we propose a <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> jointly leveraging (1) a user context from their historical tweets together with (2) the social information from a user’s conversational neighborhood in an interaction graph, to contextualize the interpretation of the post. We use graph attention networks (GAT) over users and tweets in a conversation thread, combined with dense user history representations. Apart from achieving state-of-the-art results on the recently published dataset of 19k Twitter users with 30 K labeled tweets, adding 10 M unlabeled tweets as context, our results indicate that the model contributes to interpreting the sarcastic intentions of an author more than to predicting the sarcasm perception by others.</abstract>
      <url hash="fc846cee">2021.wnut-1.12</url>
      <bibkey>plepi-flek-2021-perceived</bibkey>
      <doi>10.18653/v1/2021.wnut-1.12</doi>
      <pwccode url="https://github.com/caisa-lab/sarcasm_detection" additional="false">caisa-lab/sarcasm_detection</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/spirs">SPIRS</pwcdataset>
    <title_es>Detección de sarcasmo percibido e intencionado con redes de atención gráfica</title_es>
      <title_ar>كشف السخرية المدركة والمقصودة مع شبكات الاهتمام بالرسم البياني</title_ar>
      <title_pt>Detecção de sarcasmo percebida e pretendida com redes de atenção de gráfico</title_pt>
      <title_ja>グラフアテンションネットワークによる知覚および意図された皮肉検出</title_ja>
      <title_zh>图形网络感期之刺</title_zh>
      <title_hi>ग्राफ ध्यान नेटवर्क के साथ कथित और इरादा व्यंग्य का पता लगाना</title_hi>
      <title_ru>Обнаружение воспринимаемого и предполагаемого сарказма с помощью сетей, привлекающих внимание к графикам</title_ru>
      <title_fr>Détection des sarcasmes perçus et intentionnels avec les réseaux d'attention Graph</title_fr>
      <title_ga>Brath Sarcasm Braite agus Beartaithe le Líonraí Airde Grafa</title_ga>
      <title_el>Αντιλαμβανόμενη και προβλεπόμενη ανίχνευση σαρκασμού με δίκτυα προσοχής γραφήματος</title_el>
      <title_ka>გრაფის ატვირციის საქაღალებით პერსექტივებულია და დარწმუნებულია საპკასმის განსაზღვრება</title_ka>
      <title_hu>Érzékelt és tervezett szarkazmus detektálás grafikus figyelem hálózatokkal</title_hu>
      <title_kk>Графикалық түрту желілерімен пайызды және мақсатты саркасстың анықтауы</title_kk>
      <title_it>Rilevamento del sarcasmo percepito e previsto con reti di attenzione grafiche</title_it>
      <title_lt>Pastebėtas ir numatomas sarkazmo nustatymas naudojant grafinio dėmesio tinklus</title_lt>
      <title_mk>Детектирање на приметен и намерен сарказам со мрежи за графско внимание</title_mk>
      <title_ms>Pengesanan Sarkasma Diperhatikan dan Berniat dengan Rangkaian Perhatian Graf</title_ms>
      <title_ml>Perceived and Intended Sarcasm Detection with Graph Attention Networks</title_ml>
      <title_mt>Sejbien ta’ Sarkazmu Perspettat u Intent b’Netwerks ta’ Attenzjoni Grafika</title_mt>
      <title_mn>График анхаарлын сүлжээлүүдтэй хувьсагдсан болон төсөөлөмж</title_mn>
      <title_no>Prosessivt og intensert sarkasm- oppdaging med grafikkatteringsnettverk</title_no>
      <title_pl>Postrzegane i zamierzone wykrywanie sarkazmu za pomocą sieci uwagi grafu</title_pl>
      <title_ro>Detectarea sarcasmului percepută și intenționată cu rețelele grafice de atenție</title_ro>
      <title_sr>Provjerena i namjerena detekcija Sarkasma sa mrežama pozornosti grafika</title_sr>
      <title_si>ග්‍රාෆ් අවධානය ජාලය සමග සාර්කාස් හොයාගන්න</title_si>
      <title_so>Perceived and Intended Sarcasm Detection with Graph Attention Network</title_so>
      <title_sv>Uppfattad och avsedd sarkasm detektering med graf uppmärksamhetsnätverk</title_sv>
      <title_ta>Comment</title_ta>
      <title_ur>گراف اٹینٹ نیٹورک کے ساتھ پرسیڈ اور انتظار دار سارکاسم اچانک</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Phát hiện Sarcass (mũ) với mạng chú ý đồ họa</title_vi>
      <title_bg>Усещано и планирано откриване на сарказъм с графични мрежи за внимание</title_bg>
      <title_hr>Procentirano i namjerno otkrivanje sarkasma sa mrežama pozornosti grafika</title_hr>
      <title_nl>Waargenomen en beoogde sarcasme detectie met grafiek Attention Networks</title_nl>
      <title_da>Opfattet og påtænkt sarkasme detektion med graf opmærksomhedsnetværk</title_da>
      <title_de>Wahrgenommene und beabsichtigte Sarkasmus-Erkennung mit Graph Attention Networks</title_de>
      <title_fa>با شبکه های توجه گراف بازرسی سارکاسم</title_fa>
      <title_id>Deteksi Sarkasme Diperhatikan dan Berniat Dengan Rangkaian Perhatian Graf</title_id>
      <title_sw>Kuchunguzwa na Kuchunguza Sarcasm kwa Mtandao wa Uchunguzi wa Graph</title_sw>
      <title_ko>도형 주의 네트워크를 바탕으로 하는 감지와 의도 풍자 검측</title_ko>
      <title_af>Perseiewe en Intendeerde Sarkasm-beskrywing met Grafie Aantmerking Netwerke</title_af>
      <title_sq>Detektimi i perceptuar dhe i synuar i sarkazmit me rrjetet e vëmendjes grafike</title_sq>
      <title_az>Grafik Attention Netikləri ilə Perseived and Intended Sarcasm Detection with Graph Attention Networks</title_az>
      <title_bn>গ্রাফ মনোযোগ নেটওয়ার্কের সাথে অনুমতি দেয়া এবং পরিশেষ সার্কাম ডিটেক্টর</title_bn>
      <title_tr>Grafik Attention Ağları ile Persirlenmiş ve Kalkanlı Sarkasm Tanması</title_tr>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Գրաֆի ուշադրության ցանցերով ընկած և մտադրված Սարկազմի հայտնաբերումը</title_hy>
      <title_ca>Detecció perceptiva i intencionada del sarcasme amb xarxes d'atenció gráfica</title_ca>
      <title_fi>Havaittu ja suunniteltu sarkasmin tunnistus graafisten huomioverkkojen avulla</title_fi>
      <title_et>tajutud ja kavandatud sarkasmi tuvastamine graafiliste tähelepanuvõrkudega</title_et>
      <title_bs>Provjerena i namjerena detekcija Sarkasma sa mrežama pozornosti grafika</title_bs>
      <title_cs>Vnímaná a zamýšlená detekce sarkasmu s grafovými pozornostními sítěmi</title_cs>
      <title_sk>Zaznavanje in načrtovano zaznavanje sarkazma z grafičnimi omrežji za pozornost</title_sk>
      <title_he>זיהוי סרקזם מוכר ומתכוון עם רשתות תשומת לב Graph</title_he>
      <title_jv>Percejed lan entented Sarkasm detection with Graph Attention Network</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>རྣམ་པ་དང་Intended Sarcasm Detection with Graph Attention Networks</title_bo>
      <abstract_ar>تركز أنظمة الكشف عن السخرية الحالية على استغلال العلامات اللغوية أو السياق أو المقدمات على مستوى المستخدم. ومع ذلك ، تشير الدراسات الاجتماعية إلى أن العلاقة بين المؤلف والجمهور يمكن أن تكون ذات صلة بنفس القدر باستخدام السخرية والتفسير. في هذا العمل ، نقترح إطارًا يستفيد بشكل مشترك من (1) سياق مستخدم من تغريداتهم التاريخية جنبًا إلى جنب مع (2) المعلومات الاجتماعية من حي محادثة المستخدم في رسم بياني للتفاعل ، لوضع سياق لتفسير المنشور. نحن نستخدم شبكات انتباه الرسم البياني (GAT) على المستخدمين والتغريدات في سلسلة محادثات ، جنبًا إلى جنب مع تمثيلات سجل المستخدم الكثيفة. بصرف النظر عن تحقيق أحدث النتائج على مجموعة البيانات المنشورة مؤخرًا لـ 19 ألفًا من مستخدمي Twitter مع 30 ألف تغريدة معنونة ، إضافة 10 مليون تغريدة غير مصنفة كسياق ، تشير نتائجنا إلى أن النموذج يساهم في تفسير النوايا الساخرة للمؤلف أكثر من مجرد توقع تصور السخرية من قبل الآخرين.</abstract_ar>
      <abstract_es>Los sistemas de detección de sarcasmo existentes se centran en explotar los marcadores lingüísticos, el contexto o los antecedentes a nivel de usuario. Sin embargo, los estudios sociales sugieren que la relación entre el autor y la audiencia puede ser igualmente relevante para el uso y la interpretación del sarcasmo. En este trabajo, proponemos un marco que aproveche conjuntamente (1) el contexto de un usuario de sus tuits históricos junto con (2) la información social del vecindario conversacional de un usuario en un gráfico de interacción, para contextualizar la interpretación de la publicación. Utilizamos redes de atención gráfica (GAT) sobre los usuarios y los tuits en un hilo de conversación, combinadas con representaciones densas del historial de usuarios. Además de lograr resultados de vanguardia en el conjunto de datos recientemente publicado de 19 000 usuarios de Twitter con 30 000 tuits etiquetados, agregando 10 millones de tuits sin etiqueta como contexto, nuestros resultados indican que el modelo contribuye a interpretar las intenciones sarcásticas de un autor más que a predecir la percepción del sarcasmo por otros.</abstract_es>
      <abstract_fr>Les systèmes existants de détection du sarcasme se concentrent sur l'exploitation des marqueurs linguistiques, du contexte ou des antécédents au niveau de l'utilisateur. Cependant, des études sociales suggèrent que la relation entre l'auteur et le public peut être tout aussi pertinente pour l'utilisation et l'interprétation du sarcasme. Dans ce travail, nous proposons un cadre utilisant conjointement (1) un contexte utilisateur à partir de ses tweets historiques ainsi que (2) les informations sociales du voisinage conversationnel d'un utilisateur dans un graphique d'interaction, afin de contextualiser l'interprétation de la publication. Nous utilisons des réseaux d'attention graphique (GAT) sur les utilisateurs et les tweets dans un fil de conversation, combinés à des représentations denses de l'historique des utilisateurs. En plus d'obtenir des résultats de pointe sur l'ensemble de données récemment publié de 19 000 utilisateurs de Twitter avec 30 000 tweets étiquetés, en ajoutant 10 millions de tweets non étiquetés comme contexte, nos résultats indiquent que le modèle contribue à interpréter les intentions sarcastiques d'un auteur plus qu'à prédire la perception du sarcasme par d'autres.</abstract_fr>
      <abstract_pt>Os sistemas de detecção de sarcasmo existentes concentram-se na exploração de marcadores linguísticos, contexto ou anteriores no nível do usuário. No entanto, estudos sociais sugerem que a relação entre o autor e o público pode ser igualmente relevante para o uso e interpretação do sarcasmo. Neste trabalho, propomos um framework que alavanca conjuntamente (1) um contexto de usuário a partir de seus tweets históricos juntamente com (2) as informações sociais da vizinhança conversacional de um usuário em um gráfico de interação, para contextualizar a interpretação do post. Usamos redes de atenção gráfica (GAT) sobre usuários e tweets em um segmento de conversa, combinados com representações densas do histórico do usuário. Além de obter resultados de última geração no conjunto de dados recentemente publicado de 19 mil usuários do Twitter com 30 mil tweets rotulados, adicionando 10 milhões de tweets não rotulados como contexto, nossos resultados indicam que o modelo contribui mais para interpretar as intenções sarcásticas de um autor do que para prevendo a percepção de sarcasmo por outros.</abstract_pt>
      <abstract_ja>既存の皮肉検出システムは、言語マーカー、文脈、またはユーザーレベルの前科を利用することに焦点を当てています。しかし、社会的研究では、著者と聴衆との関係は皮肉の用法と解釈に等しく関連している可能性があることが示唆されている。この研究では、(1)過去のツイートからのユーザーコンテキストを、(2)インタラクショングラフでのユーザーの会話エリアからのソーシャル情報と一緒に活用して、投稿の解釈を文脈化するフレームワークを提案します。濃密なユーザー履歴表現と組み合わせて、会話スレッド内のユーザーとツイートにグラフアテンションネットワーク（ GAT ）を使用します。最近発表された19,000人のTwitterユーザーのデータセットで、30,000件のラベル付きツイートで最先端の結果を達成し、1000万件のラベルなしツイートをコンテキストとして追加することに加えて、私たちの結果は、このモデルが他者による皮肉の感覚を予測するよりも、作者の皮肉な意図を解釈することに貢献していることを示しています。</abstract_ja>
      <abstract_zh>今刺检系统专注于语言标记、上下文或用户级先验。 然世论明白,或与刺说相关。 于是建一框架,共用(1)史推文用户上下文及(2)交图用户对社区社交息,以上下文帖之说。 吾于线程中用图形网络(GAT)以覆用户推文,而合用户史。 自近出19000名Twitter用户据集上得最先进者,其中有30000标之推文,添1000万条未标之推文以为上下文,臣等之的结果表明,当模形有助于解作者之意,非测人之刺感也。</abstract_zh>
      <abstract_hi>मौजूदा व्यंग्य का पता लगाने वाली प्रणालियां भाषाई मार्करों, संदर्भ, या उपयोगकर्ता-स्तर की प्राथमिकताओं का शोषण करने पर ध्यान केंद्रित करती हैं। हालांकि, सामाजिक अध्ययनों से पता चलता है कि लेखक और दर्शकों के बीच संबंध व्यंग्य उपयोग और व्याख्या के लिए समान रूप से प्रासंगिक हो सकते हैं। इस काम में, हम संयुक्त रूप से एक रूपरेखा का लाभ उठाने का प्रस्ताव करते हैं (1) उनके ऐतिहासिक ट्वीट्स से एक उपयोगकर्ता संदर्भ के साथ-साथ (2) एक इंटरैक्शन ग्राफ में उपयोगकर्ता के संवादी पड़ोस से सामाजिक जानकारी, पोस्ट की व्याख्या को संदर्भित करने के लिए। हम उपयोगकर्ताओं पर ग्राफ अटेंशन नेटवर्क (जीएटी) का उपयोग करते हैं और एक वार्तालाप थ्रेड में ट्वीट्स करते हैं, जो घने उपयोगकर्ता इतिहास प्रतिनिधित्व के साथ संयुक्त होते हैं। 30K लेबल वाले ट्वीट्स के साथ 19k ट्विटर उपयोगकर्ताओं के हाल ही में प्रकाशित डेटासेट पर अत्याधुनिक परिणाम प्राप्त करने के अलावा, संदर्भ के रूप में 10M अनलेबल किए गए ट्वीट्स को जोड़ते हुए, हमारे परिणाम इंगित करते हैं कि मॉडल दूसरों द्वारा व्यंग्यात्मक धारणा की भविष्यवाणी करने की तुलना में लेखक के व्यंग्यात्मक इरादों की व्याख्या करने में योगदान देता है।</abstract_hi>
      <abstract_ru>Существующие системы обнаружения сарказма сосредоточены на использовании лингвистических маркеров, контекста или приводов на уровне пользователя. Однако социальные исследования предполагают, что отношения между автором и аудиторией могут быть одинаково актуальны для использования и интерпретации сарказма. В этой работе мы предлагаем фреймворк, совместно использующий (1) пользовательский контекст из их исторических твитов вместе с (2) социальной информацией из разговорного соседства пользователя в графике взаимодействия, чтобы контекстуализировать интерпретацию поста. Мы используем сети графового внимания (GAT) над пользователями и твитами в потоке разговоров, в сочетании с плотными представлениями истории пользователей. Помимо достижения самых современных результатов в недавно опубликованном наборе данных 19 тысяч пользователей Twitter с 30 тысячами помеченных твитов, добавляя 10 МИЛЛИОНОВ немеченных твитов в качестве контекста, наши результаты показывают, что модель вносит вклад в интерпретацию саркастических намерений автора больше, чем в предсказание восприятия сарказма другими.</abstract_ru>
      <abstract_ga>Díríonn na córais braite searbhas atá ann faoi láthair ar shaothrú marcóirí teanga, comhthéacs nó tosaíochtaí ag leibhéal an úsáideora. Mar sin féin, tugann staidéir shóisialta le fios go bhféadfadh an gaol idir an t-údar agus an lucht féachana a bheith chomh hábhartha céanna maidir le húsáid agus léiriú searbhas. San obair seo, molaimid creat a ghiaráil i gcomhpháirt (1) comhthéacs úsáideora óna gcuid tweets stairiúla mar aon le (2) an fhaisnéis shóisialta ó chomharsanacht chomhrá úsáideora i ngraf idirghníomhaíochta, chun léirmhíniú an phoist a chomhthéacsú. Bainimid úsáid as líonraí aird ghraif (GAT) thar úsáideoirí agus tweets i snáithe comhrá, in éineacht le huiríll dlúth stair úsáideoirí. Seachas torthaí úrscothacha a bhaint amach ar an tacar sonraí a foilsíodh le déanaí de 19k úsáideoirí Twitter le tweets lipéadaithe 30K, ag cur 10M tweets neamhlipéadaithe mar chomhthéacs, léiríonn ár dtorthaí go gcuidíonn an tsamhail le hintinn sarcastic an údair a léirmhíniú níos mó ná a dearcadh searbhas daoine eile a thuar.</abstract_ga>
      <abstract_hu>A meglévő szarkazmusfelismerő rendszerek a nyelvi markerek, kontextusok vagy felhasználói szintű priuszok kihasználására összpontosítanak. A szociális tanulmányok azonban azt sugallják, hogy a szerző és a közönség közötti kapcsolat ugyanolyan releváns lehet a szarkazmus használata és értelmezése szempontjából. Ebben a munkában olyan keretrendszert javasolunk, amely (1) a felhasználói kontextust a történelmi tweetjeikből és (2) a felhasználó beszélgetési környékéből származó közösségi információkat egy interakciós grafikonban használja fel, hogy kontextualizálja a bejegyzés értelmezését. Graf figyelemmel kísérő hálózatokat (GAT) használunk a felhasználók felett és tweeteket egy beszélgetési szálban, kombinálva sűrű felhasználói előzményekkel. Azon kívül, hogy 19 ezer Twitter felhasználó 30 ezer tweettel nemrégiben publikált adatkészletéről szóló legkorszerűbb eredményeket értünk el, 10 millió címke nélküli tweettel összefüggésben, eredményeink azt mutatják, hogy a modell inkább hozzájárul egy szerző szarkasztikus szándékainak értelmezéséhez, mint hogy mások szarkasztikus érzékeléséhez.</abstract_hu>
      <abstract_el>Τα υπάρχοντα συστήματα ανίχνευσης σαρκασμού επικεντρώνονται στην εκμετάλλευση γλωσσικών δεικτών, πλαισίου ή προηγούμενων αρχείων σε επίπεδο χρήστη. Ωστόσο, κοινωνικές μελέτες δείχνουν ότι η σχέση μεταξύ του συγγραφέα και του κοινού μπορεί να είναι εξίσου σημαντική για τη χρήση και ερμηνεία του σαρκασμού. Στην παρούσα εργασία, προτείνουμε ένα πλαίσιο από κοινού που αξιοποιεί (1) ένα περιβάλλον χρήστη από τα ιστορικά τουίτ του μαζί με (2) τις κοινωνικές πληροφορίες από τη συνοικία συζήτησης ενός χρήστη σε ένα γράφημα αλληλεπίδρασης, για να πλαισιώσει την ερμηνεία της ανάρτησης. Χρησιμοποιούμε δίκτυα προσοχής γραφήματος πάνω από χρήστες και tweets σε ένα νήμα συνομιλίας, σε συνδυασμό με πυκνές αναπαραστάσεις ιστορικού χρηστών. Εκτός από την επίτευξη των πιο σύγχρονων αποτελεσμάτων στο πρόσφατα δημοσιευμένο σύνολο δεδομένων χρηστών του 19Κ με ετικέτες 30Κ, προσθέτοντας ως πλαίσιο 10Μ χωρίς ετικέτα tweets, τα αποτελέσματα μας δείχνουν ότι το μοντέλο συμβάλλει περισσότερο στην ερμηνεία των σαρκαστικών προθέσεων ενός συγγραφέα παρά στην πρόβλεψη της αντίληψης του σαρκασμού από άλλους.</abstract_el>
      <abstract_ka>არსებობს სისტემები სისტემების განაკვირება სისტემები, სისტემები, კონტექსტური, ან გამოყენებელი დონეზე წინ გამოიყენება. მაგრამ სოციალური სწავლის შესახებ, რომ ავტორის და აუდისონის შორის შესახებ შეიძლება იგივე მნიშვნელოვანია საპკასომის გამოყენება და ინტერპუქციის შესახე ამ სამუშაოში, ჩვენ ერთადერთად გამოყენება (1) გამოყენებელი კონტექსტის ისტორიური tweets-დან ერთად (2) სოციალური ინფორმაცია გამოყენებელი კონტაქტიური საზოგადოებაში ინტერქსტაციის გრაფიკაში, რომ პოსტის ჩვენ გამოყენებთ გრაფიკური ინტერნექციის ქსელები (GAT) მომხმარებელი და რვიტების გარეშე პარამეტრების კონფიგურაციაში, რომელიც კონფიგურაცია მომ მიმდინარე მომხმარების შესახებ, რომელიც ახლა მომხმარებული მონაცემების შესახებ, რომელიც 30K წერტილით გარუტებულია, დამატებული 10M წერტილი გარუტებულია როგორც კონტექსტის შესახებ, ჩვენი შესახებ გვეუბნება, რომ მოდელის შესახებ ავტორის</abstract_ka>
      <abstract_it>I sistemi esistenti di rilevamento del sarcasmo si concentrano sullo sfruttamento di marcatori linguistici, contesto o precedenti a livello di utente. Tuttavia, studi sociali suggeriscono che la relazione tra l'autore e il pubblico può essere ugualmente rilevante per l'uso e l'interpretazione del sarcasmo. In questo lavoro, proponiamo un framework che sfrutta congiuntamente (1) un contesto utente dai loro tweet storici insieme (2) le informazioni sociali provenienti dal quartiere conversazionale di un utente in un grafico di interazione, per contestualizzare l'interpretazione del post. Usiamo reti di attenzione dei grafici (GAT) sugli utenti e sui tweet in un thread di conversazione, combinate con rappresentazioni dense della cronologia degli utenti. Oltre a ottenere risultati all'avanguardia sul set di dati recentemente pubblicato di 19k utenti Twitter con 30K tweet etichettati, aggiungendo 10M tweet non etichettati come contesto, i nostri risultati indicano che il modello contribuisce a interpretare le intenzioni sarcastiche di un autore più che a predire la percezione sarcastica da parte di altri.</abstract_it>
      <abstract_lt>Dabartinėmis sarkazmo nustatymo sistemomis daugiausia dėmesio skiriama kalbinių žymenų, konteksto ar naudotojo lygio ankstesnių naudojimui. Tačiau socialiniai tyrimai rodo, kad autorių ir auditorijos santykiai gali būti vienodai svarbūs sarkazmo naudojimui ir aiškinimui. Šiame darbe siūlome bendrą sistemą, kurioje (1) naudotojų kontekstas iš jų istorinių tweetų būtų naudojamas kartu su (2) socialine informacija iš naudotojų pokalbių kaimynystės s ąveikos grafikoje, kad būtų atsižvelgta į post aiškinimą. Naudojame grafinio dėmesio tinklus (GAT) per naudotojus ir tweetus pokalbio grandinėje, kartu su tankiais naudotojų istorijos rodymais. Iš mūsų rezultatų matyti, kad modelis padeda aiškinti autoriaus sarkastinius ketinimus, o ne prognozuoti sarkazmo suvokimą kitiems.</abstract_lt>
      <abstract_kk>Бар саркассмды анықтау жүйелері лингвистикалық маркерлерді, контексті немесе пайдаланушының деңгейінің алдындағыларын қолдану үшін назар ауыстырылады. Бірақ әлеуметтік зерттеулері автор мен аудиториялар арасындағы қатынасы сарказм пайдалану мен түсініктеме үшін тең қатынасы болуы мүмкін. Бұл жұмыс ішінде, жұмыс істеу графикасында пайдаланушылардың ақпараттық мәліметін (1) қосымша қосымша қосымша (2) қосымша қосымша қосымша қосымша қосымша қосымша қосымша қосымша қосымша қосымша Біз пайдаланушылар мен tweets тізімінен графикалық назарды (GAT) қолданамыз, жұмыс пайдаланушылардың журналы көрсеткіштерімен біріктіріледі. Біздің нәтижелеріміз, жаңа жаңа жарияланған 19k Твиттер пайдаланушыларының жарияланған жарияланған тейттер жиынына қарай, 10 М жарияланбаған тейттерді контекст ретінде қосуға болады. Біздің нәтижелеріміз, моделі автордың саркастикалық мақсаттарын түсініп, басқаларды</abstract_kk>
      <abstract_ml>നിലവിലുള്ള സർക്കാസം കണ്ടുപിടിക്കുന്ന സിസ്റ്റം ഭാഷ അടയാളങ്ങള്‍, കോണ്ടെക്സ്റ്റേഷന്‍, അല്ലെങ്കില്‍ ഉപയോക്ത എന്നാലും സാമൂഹിക വിവരണങ്ങള്‍ നിര്‍ദേശിക്കുന്നു, എഴുത്തുകാരനും കാഴ്ചക്കാരും തമ്മിലുള്ള ബന്ധം സമമായിരിക്കും പരിശ ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ ഒരു ഫ്രെയിമെക്കോര്‍ക്ക് പ്രൊദ്ദേശിക്കുന്നു. (1) അവരുടെ ചരിത്രത്തിലെ ടൂട്ടുകളില്‍ നിന്നും ഒരു ഉപയോക്താവിന്‍റെ ചരിത്ര കണക്ട ഞങ്ങള്‍ ഉപയോക്താക്കള്‍ക്കും ടൂട്ടുകള്‍ക്കും മേല്‍ ഗ്രാഫ് ശ്രദ്ധ നെറ്റുകള്‍ ഉപയോഗിക്കുന്നു. സംസാരിക്കുന്നതിന്റെ ത് 19k ട്രൂട്ടര്‍ ഉപയോക്താക്കളുടെ അടുത്ത് പ്രസിദ്ധമായ ഡാറ്റാസെറ്റ് പ്രസിദ്ധമാക്കുന്നതിന് ശേഷം നമ്മുടെ ഫലങ്ങള്‍ ലഭ്യമാക്കുന്നതിന് ശേഷം 30K ടൂട്ടുകള്‍ കൂട്ടിച്ചേര്‍ക്കുന്നതിന് മാത്രമാ</abstract_ml>
      <abstract_mk>Постојаните системи за детекција на сарказам се фокусираат на искористувањето на лингвистичките маркери, контекст или претходно ниво на корисник. Сепак, социјалните студии покажуваат дека односот помеѓу авторот и публиката може да биде еднакво релевантен за користењето и интерпретацијата на сарказмот. Во оваа работа, предложуваме рамка заеднички користејќи (1) кориснички контекст од нивните историски твитови заедно со (2) социјалните информации од разговарачкиот соседство на корисникот во интеракционален график, за контекстуално интерпретација на постот. Ние користиме мрежи за внимание на графот (GAT) преку корисниците и твитови во контакт низа, комбинирани со густи претставувања на историјата на корисниците. Освен постигнувањето на најсовремени резултати на неодамна објавените податоци на 19.000 корисници на Твитер со 30.000 обележани Твитер, додавајќи 10.000 необележани Твитер како контекст, нашите резултати покажуваат дека моделот придонесува за интерпретација на саркастичните намери на авторот повеќе отколку за предвидување на перцепцијата на сарказмот од страна на друг</abstract_mk>
      <abstract_mt>Is-sistemi eżistenti ta’ detezzjoni tas-sarkazmu jiffukaw fuq l-isfruttar ta’ markaturi lingwistiċi, kuntest, jew prijoritajiet fil-livell tal-utent. Madankollu, studji soċjali jissuġġerixxu li r-relazzjoni bejn l-awtur u l-udjenza tista’ tkun rilevanti ugwalment għall-użu u l-interpretazzjoni tas-sarkazmu. F’din il-ħidma, qed nipproponu qafas li jinbena b’mod konġunt (1) kuntest ta’ utent mit-tweets storiċi tagħhom flimkien ma’ (2) l-informazzjoni soċjali mill-viċinat ta’ konverżjoni ta’ utent f’graff ta’ interazzjoni, biex tiġi kuntestwalizzata l-interpretazzjoni tal-post. Aħna nużaw netwerks ta’ attenzjoni grafika (GAT) fuq l-utenti u t-tweets f’ħajt ta’ konverżjoni, flimkien ma’ rappreżentazzjonijiet densi tal-istorja tal-utenti. Minbarra li nkisbu riżultati l-aktar avvanzati dwar is-sett ta’ dejta ppubblikat reċentement ta’ 19k utent ta’ Twitter b’tweets ittikkettati b’30K, billi żiedu 10M tweets mhux ittikkettati bħala kuntest, ir-riżultati tagħna jindikaw li l-mudell jikkontribwixxi għall-interpretazzjoni tal-intenzjonijiet sarkastiċi ta’ awtur aktar milli għat-tbassir tal-perċezzjoni tas-sarkazmu minn oħrajn.</abstract_mt>
      <abstract_ms>Sistem pengesan sarkasma yang wujud fokus pada mengeksploitasi penanda bahasa, konteks, atau priori aras pengguna. Namun, kajian sosial menunjukkan bahawa hubungan antara penulis dan penonton boleh sama relevan untuk penggunaan dan interpretasi sarkasme. Dalam kerja ini, kami melamar kerangka bersama-sama menggunakan (1) konteks pengguna dari tweet sejarah mereka bersama-sama (2) maklumat sosial dari lingkungan pembicaraan pengguna dalam graf interaksi, untuk mengkonteksualisasi interpretasi pos. Kami menggunakan rangkaian perhatian graf (GAT) melalui pengguna dan tweet dalam benang perbualan, bergabung dengan perwakilan sejarah pengguna yang padat. Selain mencapai keputusan state-of-the-art pada set data yang baru-baru ini diterbitkan oleh pengguna Twitter 19k dengan tweet 30K yang ditabel, menambah tweet 10M yang tidak ditabel sebagai konteks, keputusan kami menunjukkan bahawa model menyumbang untuk menerangkan niat sarkastik penulis lebih daripada untuk meramalkan perasaan sarkasma oleh orang lain.</abstract_ms>
      <abstract_no>Det eksisterande sarkasme-oppdagingssystemet fokuserer på å bruka språkmarker, kontekst eller brukarnivå førre. Men sosiale studiar tyder på at forholdet mellom forfatteren og publikum kan vera likevel relevant for bruk av sarkasm og tolking. I denne arbeida foreslår vi eit rammeverk som kopla leverer (1) ein brukarnamn frå sine historiske tweeter sammen med (2) den sosiale informasjonen frå eit brukaren konvertasjonal nabo i eit interaksjonsgraf, for å kontekstualisera tolkinga av post. Vi brukar grafikkoppmerksnettverk (GAT) over brukarar og tweeter i eit samtaletråd, kombinasjon med tette brukaragentskinstillingar. I staden for å få tilstanden av kunsten til det siste utgjevne datasettet av 19k Twitter-brukarar med 30K-etikette tweets, og legg til 10M-utgjevne tweeter som kontekst, viser resultatet våre at modellen bidrar til å tolka sarkastiske viljonane til ein forfattar meir enn å forventa forståkinga av sarkasma av andre.</abstract_no>
      <abstract_pl>Istniejące systemy wykrywania sarkazmu koncentrują się na wykorzystaniu znaczników językowych, kontekstu lub wcześniejszych wyroków na poziomie użytkownika. Badania społeczne sugerują jednak, że relacja między autorem a publicznością może być równie istotna dla użycia sarkazmu i interpretacji. W niniejszej pracy proponujemy framework wspólnie wykorzystujący (1) kontekst użytkownika z jego historycznych tweetów wraz z (2) informacjami społecznościowymi z okolicy konwersacyjnej użytkownika w wykresie interakcji, aby kontekstować interpretację postu. Używamy sieci uwagi wykresów (GAT) nad użytkownikami i tweetami w wątku konwersacji, w połączeniu z gęstymi reprezentacjami historii użytkowników. Oprócz osiągnięcia najnowocześniejszych wyników na niedawno opublikowanym zbiorze danych użytkowników Twittera 19k z oznaczonymi 30K tweetami, dodawania 10M nieoznaczonych tweetów jako kontekstu, nasze wyniki wskazują, że model przyczynia się bardziej do interpretacji sarkastycznych intencji autora niż do przewidywania postrzegania sarkazmu przez innych.</abstract_pl>
      <abstract_mn>Өнөөдөр байгаа саркассмын тогтоох системүүд хэлний маркертүүд, нөхцөл, хэрэглэгчийн түвшинд өмнө нь ашиглаж байдаг. Гэвч нийгмийн судалгаагаар зохиолч болон сонсогчид хоорондын харилцаа нь харилцааны хэрэглээ болон түүхийн тулд тэнцүү харилцаа байж болох юм. Энэ ажлын тухай бид түүхийн tweets-ээс хамтран хэрэглэгчдийн харилцааны хөршөөний нийгмийн мэдээллийг харилцааны график дээр хамтран ашиглах (1) хэрэглэгчдийн тухай хамтран ашиглах боломжтой байдлыг санал болгодог. Бид хэрэглэгчид болон tweets дээр график анхаарлын сүлжээг хэрэглэгчид ашиглаж байна. Хүмүүсийн түүхийн хэлбэртэй холбоотой. Саяхан нийтлэгдсэн 19k Твиттерийн хэрэглэгчдийн хувьд 30K жагсаалт бичигдсэн tweets болон 10M жагсаалгүй tweets нэмэгдсэнээс гадна бидний үр дүнд энэ загвар нь бусдын тархалтын ойлголтыг таамаглахаас илүү сайхан зохиолчдын зорилготой зорилготой байдлыг илүү ойлгож өгдөг.</abstract_mn>
      <abstract_ro>Sistemele existente de detectare a sarcasmului se concentrează pe exploatarea markerilor lingvistici, a contextului sau a antecedentelor la nivel de utilizator. Cu toate acestea, studiile sociale sugerează că relația dintre autor și public poate fi la fel de relevantă pentru utilizarea și interpretarea sarcasmului. În această lucrare, propunem un cadru care valorifică împreună (1) un context de utilizator din tweeturile lor istorice împreună cu (2) informațiile sociale din cartierul conversațional al unui utilizator într-un grafic de interacțiune, pentru a contextualiza interpretarea postării. Utilizăm rețele de atenție grafică (GAT) peste utilizatori și tweet-uri într-un fir de conversație, combinate cu reprezentări dense ale istoricului utilizatorilor. Pe lângă obținerea de rezultate de ultimă oră pe setul de date recent publicat de 19k de utilizatori Twitter cu 30K de tweet etichetate, adăugând 10M de tweet fără etichetare ca context, rezultatele noastre indică faptul că modelul contribuie mai mult la interpretarea intențiilor sarcastice ale unui autor decât la predicția percepției sarcasmului de către alții.</abstract_ro>
      <abstract_sr>Postojeći sistemi detekcije sarkazma fokusiraju se na upotrebu jezičkih markera, konteksta ili razine korisnika. Međutim, socijalne studije sugeriraju da odnos između autora i publike može biti jednako relevantan za korištenje sarkazma i interpretaciju. U ovom poslu predlažemo okvir koji zajedno utiče na (1) kontekst korisnika iz njihovih istorijskih tweeta zajedno s (2) socijalne informacije iz konverzacionog susjedstva korisnika u grafiku interakcije, da bi kontekstualizirali interpretaciju pošta. Koristimo grafičke mreže pažnje (GAT) nad korisnicima i tweetom u konverziji, kombinirane sa gustim predstavljanjem povijesti korisnika. Osim postizanja rezultata umetnosti na nedavno objavljenoj seriji podataka od 19k korisnika Twitter sa 30K označenim tweetima, dodajući 10M bezabeliranih tweets kao kontekst, naši rezultati ukazuju na to da model doprinosi interpretaciji sarkastičnih namera autora više nego predviđanju percepcije sarkazma od strane drugih.</abstract_sr>
      <abstract_si>ඉතින් ඉතින් සාර්කාස්ම් හොයාගන්න පද්ධතිය භාෂාවික සංඥාවක්, සංවේදනය, නැත්තම් භාෂාවික ස්ථ ඒත් සාමාජික පරීක්ෂණය ප්‍රශ්නයක් තියෙනවා ලේඛකය සහ ප්‍රේක්ෂකයෙන් අතර සම්බන්ධය සමඟ සම්බන්ධය සමාන්‍ය වි මේ වැඩේ අපි ප්‍රයෝජනයක් සම්බන්ධ වෙන්න ප්‍රයෝජනයක් (1) ඔවුන්ගේ ඉතිහාසික ට්විට් වලින් ප්‍රයෝජනයක් සමග (2) සමග සමාජ තොරතුරු ප්‍රයෝජනයේ  අපි ග්‍රාෆ් අවධානය ජාලය (GAT) භාවිතා කරුණාකරණය සහ ට්විට් වලට භාවිත කරනවා, සම්බන්ධ කරුණාකරණය ඉ 30K ලේබල් තියෙන්නේ තියෙන්නේ 19k ට්විටර් ප්‍රකාශකයේ දත්ත සෙට් එකේ ස්ථානයක් ලැබෙන්න පුළුවන් විතරයි, 10M නැති ට්විට් එක සම්බන්ධයක් විතරයි, අපේ ප්‍රතිචාර ප්‍රතිචා</abstract_si>
      <abstract_sv>Befintliga system för detektering av sarkasm fokuserar på att utnyttja språkliga markörer, sammanhang eller användarnivåer. Sociala studier tyder dock på att relationen mellan författaren och publiken kan vara lika relevant för sarkasmens användning och tolkning. I detta arbete föreslår vi ett ramverk som gemensamt utnyttjar (1) en användarkontext från deras historiska tweets tillsammans med (2) den sociala informationen från en användares samtalsområde i en interaktionsgraf, för att kontextualisera tolkningen av inlägget. Vi använder grafiska uppmärksamhetsnätverk (GAT) över användare och tweets i en konversationstråd, kombinerat med täta användarhistorikrepresentationer. Förutom att uppnå state-of-the-art resultat på den nyligen publicerade datauppsättningen av 19k Twitter-användare med 30K märkta tweets och lägga till 10M obemärkta tweets som sammanhang, indikerar våra resultat att modellen bidrar till att tolka en författars sarkastiska avsikter mer än att förutsäga andras sarkasms uppfattning.</abstract_sv>
      <abstract_ta>Existing sarcasm detection systems focus on exploiting linguistic markers, context, or user-level priors.  ஆயினும், சமூக ஆராய்ச்சிகள் ஆசிரியர் மற்றும் பார்ப்பவருக்கும் இடையே தொடர்பு சரியாக இருக்க முடியும் என்று தெரிவிக இந்த வேலையில், நாம் ஒரு சட்டத்தை ஒன்றாக கொண்டு வழங்கும் (1) ஒரு பயனர் சூழ்ச்சியை அவர்களுடைய வரலாற்றில் இருந்து ஒரு பயனர் சூழலில் இருந்து மேலும் (2) ஒரு பயனரின் பே நாங்கள் பயனர்கள் மற்றும் தொடர்பு பேச்சு தூரத்தில் வரைப்படம் கவனம் வலைப்பின்னல்களை பயன்படுத்துகிறோம், சூழ்நிலையான பயனர சமீபத்தில் வெளிப்படையிடப்பட்ட தகவல் அமைப்புகளின் முடிவுகளை பெறுவதற்கு தவிர, 30K குறிப்பிடப்பட்ட twitter கூட்டு, 10M குறிப்பிடப்படாத த தொடர்புகளை சேர்த்து, எங்கள் முடிவு</abstract_ta>
      <abstract_ur>Existing sarcasm detection systems focus on using linguistic markers, context, or user-level priors. اگرچہ، سوسیل تحقیقات کی توصیف کرتی ہے کہ لکھنے اور دیکھنے والوں کے درمیان رابطہ سارکاسم کا استعمال اور تعبیر کے لئے برابر معاملہ ہے۔ اس کام میں ہم ایک فرم کی پیشنهاد کرتے ہیں کہ ایک گراف میں ایک کارساز کی تفصیل سے (1) ان کی تاریخی ٹیوٹوں سے ایک کارساز کی تفصیل (2) کے ساتھ ایک کارساز کی مکالمانی معلومات کے ساتھ (2) ایک کارساز کی مکالمانی گراف میں ایک مکالمانی گراف میں لے آئیں، اس کے تفصی ہم یوسٹر اور ٹویٹ پر گراف اظہار نیٹورک (GAT) استعمال کرتے ہیں، ایک صحبت ترید میں، گہرے یوسٹر تاریخ کی تصاویرات کے ساتھ ملے ہوئے۔ 30K لیبل ٹویٹ کے ساتھ 19k ٹویٹر کارساز کے ڈاٹ سٹ کے نتائج پہنچ جانے کے علاوہ، ہمارے نتائج یہ نشان دیتے ہیں کہ مدل ایک لکھنے والے کے سارکاسٹ کا انتظام کرنے کے لئے زیادہ اضافہ کرتا ہے اور اس سے زیادہ اضافہ کرتا ہے</abstract_ur>
      <abstract_so>nidaamka baaritaanka sarcasm ee joogta waxay ku cusbooneysaa isticmaalka alaabta luqada, kooxda, ama heerka isticmaalaha. Si kastaba ha ahaatee waxbarashada bulshada waxaa loola jeedaa in xiriirka uu u dhexeeyo qoraalka iyo dhaqaalaha ay si isku mid ah ugu muhiimsan karaan isticmaalka cashuurta iyo turjumaadda. Markaas waxan, waxaynu u soo jeedaynaa shirkad si wadajir ah u soo diritaan (1) mid isticmaal ah oo ka soo jeeda tweetkooda taariikhda ah iyo (2) macluumaadka bulshada ee degmada kala sheekeysan ee isticmaalaha, si a an uga fikiro fasirka warqada. Waxaynu isticmaalnaa shabakado warbixinta jimicsiga (GAT) oo isticmaalaya isticmaalayaasha iyo tweetka oo ku qoran wadanka hadalka, waxaana ku darsameynaa noocyada taariikhda ee fudud ee isticmaalayaasha. Inta aan helin arimaha farshaxanka ee ugu dhowaantii la soo daabacay taariikhda ee 19k ee isticmaalayaasha Twitter oo ay leeyihiin 30K oo tweeti labo ah, waxayna ku daraysaa 10M oo aan la lab karin sida mukhtada ah, resultimadayada ayaa ka muuqata in modelku faa’iido ku leedahay turjumaadka sarkaalka qoraalka ah in ka badan la sii sheego aragtida sarcasm ee kale.</abstract_so>
      <abstract_vi>Các hệ thống phát hiện mỉa mai đang sử dụng các đánh dấu ngôn ngữ, ngữ cảnh, hay ưu tiên người dùng. Tuy nhiên, các nghiên cứu xã hội cho thấy mối quan hệ giữa tác giả và khán giả cũng có thể liên quan đến cách sử dụng và diễn giải mỉa mai. Trong công việc này, chúng tôi đề nghị một cơ s ở điều chỉnh nhân sự (1) ngữ cảnh của người dùng từ những dòng tweet lịch sử của họ cùng với (2) thông tin xã hội từ khu đối thoại của người dùng trong một đồ thị giao tiếp, để áp chế tính cách giải thích bài báo. Chúng tôi sử dụng mạng chú ý đồ thị (Văn bản GAT) trên người dùng và tweet trong một sợi dây trò chuyện, kết hợp với các biểu hiện lịch sử người dùng dày đặc. Ngoài việc đạt được kết quả hiện đại trên tập tin được công bố gần đây của các người dùng Twitter theo giá 30K đã đánh dấu tweet, thêm 10M các dòng tweet bất hợp pháp thành ngữ cảnh, kết quả của chúng ta cho thấy rằng mô hình này có góp phần giải thích ý định mỉa mai của một tác giả nhiều hơn là dự đoán sự nhận thức mỉa mai của người khác.</abstract_vi>
      <abstract_uz>Name Lekin, jamiyatlar o'rganishni anglatadi, mualliflar va tinglovchilar orasidagi munosabatlar sarkasm foydalanish va tarjima uchun teng muhim bo'lishi mumkin. Bu ishda, biz tarixi Twitterdan foydalanuvchi tarkibini birlashtirishni boshqarish imkoniyatini boshqarish bilan (2) foydalanuvchining muloqat grafikdagi ijtimoiy maʼlumoti bilan birlashtiramiz, bu pochta orzusini taqlash uchun. Biz foydalanuvchilar va Twitter haqida grafik taʼminlovchi tarmoqlar (GAT) dan foydalanuvchilarga foydalanuvchi va foydalanuvchi tarixi taʼminlovlari bilan birlashtiramiz. Yaqinda ochilgan 19k Twitter foydalanuvchilari haqida saqlash natijalarini bajarishdan oldin, 30K yorliq tweeti bilan qo'shish mumkin va 10M yozilmagan tweetilarni muktadha qo'shish mumkin, natijalarimizning natijalarimiz bu modelni mualliflarning sarkazlik g'oyalarini o'rganishga yordam beradi, boshqalarga sarkasm fikrini oldin oldini oldin.</abstract_uz>
      <abstract_nl>Bestaande sarcasme detectiesystemen richten zich op het uitbuiten van taalkundige markers, context of eerdere straffen op gebruikersniveau. Sociale studies suggereren echter dat de relatie tussen de auteur en het publiek even relevant kan zijn voor het gebruik en interpretatie van sarcasme. In dit werk stellen we een raamwerk voor dat gezamenlijk (1) een gebruikerscontext uit hun historische tweets combineert met (2) de sociale informatie uit de gespreksbuurt van een gebruiker in een interactiegrafiek, om de interpretatie van het bericht te contextualiseren. We gebruiken grafiekaandachtsnetwerken (GAT) over gebruikers en tweets in een conversation thread, gecombineerd met dichte gebruikersgeschiedenis representaties. Naast het behalen van state-of-the-art resultaten op de recent gepubliceerde dataset van 19k Twittergebruikers met 30K gelabelde tweets en het toevoegen van 10M ongelabelde tweets als context, geven onze resultaten aan dat het model meer bijdraagt aan het interpreteren van de sarcastische intenties van een auteur dan aan het voorspellen van de sarcasme perceptie door anderen.</abstract_nl>
      <abstract_da>Eksisterende systemer til detektering af sarkasme fokuserer på at udnytte sproglige markører, kontekst eller forudsætninger på brugerniveau. Samfundsundersøgelser tyder dog på, at forholdet mellem forfatteren og publikum kan være lige så relevant for sarkasmens brug og fortolkning. I dette arbejde foreslår vi en ramme, der i fællesskab udnytter (1) en brugerkontekst fra deres historiske tweets sammen med (2) de sociale oplysninger fra en brugers samtalekvarter i en interaktionsgraf, for at kontekstualisere fortolkningen af indlægget. Vi bruger grafopmærksomhedsnetværk (GAT) over brugere og tweets i en samtaletråd, kombineret med tætte brugerhistorik repræsentationer. Udover at opnå state-of-the-art resultater på det nyligt offentliggjorte datasæt af 19.000 Twitter-brugere med 30.000 mærkede tweets og tilføje 10.000 uafhængige tweets som kontekst, indikerer vores resultater, at modellen bidrager til at fortolke en forfatters sarkastiske intentioner mere end til at forudsige andres sarkasme opfattelse.</abstract_da>
      <abstract_bg>Съществуващите системи за откриване на сарказъм се фокусират върху използването на лингвистични маркери, контекст или приоритети на ниво потребител. Социалните изследвания обаче предполагат, че отношенията между автора и публиката могат да бъдат еднакво релевантни за използването и интерпретацията на сарказма. В тази работа предлагаме рамка, която съвместно използва (1) потребителски контекст от техните исторически туитове заедно със (2) социалната информация от разговорния квартал на потребителя в диаграма за взаимодействие, за да контекстуализира интерпретацията на публикацията. Използваме графични мрежи за внимание (ГАТ) над потребители и туитове в разговорна нишка, съчетани с плътни представяне на историята на потребителите. Освен че постигаме най-съвременни резултати върху наскоро публикувания набор от данни от 19000 потребители на Туитър с 30 000 маркирани туитове, добавяйки 10 милиона немаркирани туитове като контекст, нашите резултати показват, че моделът допринася повече за интерпретирането на саркастичните намерения на автора, отколкото за предсказването на възприятието на сарказма от другите.</abstract_bg>
      <abstract_hr>Postojeći sustavi otkrivanja sarkazma fokusiraju se na upotrebu jezičkih znakova, konteksta ili razine korisnika. Međutim, socijalna ispitivanja ukazuju na to da odnos između autora i publike može biti jednako relevantan za korištenje sarkazama i interpretaciju. U ovom poslu predlažemo okvir zajedničkog primjene (1) konteksta korisnika iz njihovih istorijskih tweets zajedno s (2) socijalne informacije iz razgovornog susjedstva korisnika u grafiku interakcije, kako bi kontekstualizirali interpretaciju postaje. Koristimo grafičke mreže pažnje (GAT) nad korisnicima i tweetovima u konverziji razgovora, kombinirane s gustima predstavljanja povijesti korisnika. Osim postignuća rezultata umjetnosti na nedavno objavljenoj seriji podataka 19k korisnika Twitter-a s 30K označenim tweetom, dodajući 10M nezabelovane tweets kao kontekst, naši rezultati ukazuju na to da model doprinosi interpretaciji sarkastičnih namera autora više nego predviđati percepciju sarkasma od strane drugih.</abstract_hr>
      <abstract_id>Existing sarcasm detection systems focus on exploiting linguistic markers, context, or user-level priors.  Namun, studi sosial menunjukkan bahwa hubungan antara penulis dan penonton dapat sama relevan untuk penggunaan dan interpretasi sarkasme. Dalam pekerjaan ini, kami mengusulkan sebuah rangkaian bersama-sama menggunakan (1) konteks pengguna dari tweet sejarah mereka bersama-sama (2) informasi sosial dari lingkungan percakapan pengguna dalam grafik interaksi, untuk mengkonteksualisasi interpretasi pos. Kami menggunakan jaringan perhatian grafik (GAT) melalui pengguna dan tweet dalam benang percakapan, bergabung dengan representation sejarah pengguna yang padat. Selain mencapai hasil state-of-the-art pada set data yang baru-baru ini diterbitkan oleh pengguna Twitter 19.000 dengan tweet 30K, menambah tweet 10.000 tanpa label sebagai konteks, hasil kami menunjukkan bahwa model berkontribusi untuk menerjemahkan niat sarkastik seorang penulis lebih daripada untuk memprediksi persepsi sarkasme oleh orang lain.</abstract_id>
      <abstract_ko>기존의 풍자 탐지 시스템은 언어 표기, 상하문 또는 사용자 등급의 선험 정보를 이용하는 데 중심을 두었다.그러나 사회 연구에 따르면 작가와 관중 간의 관계는 풍자의 사용과 해석에도 마찬가지로 중요하다.이 작업에서 우리는 (1) 사용자의 역사 추문에서 온 사용자의 상하문과 (2) 사용자가 상호작용도에서 온 대화 이웃의 사회 정보를 연합하여 활용하여 게시물의 해석에 대해 상하문 분석을 하는 구조를 제시했다.Google은 대화 루트에서 사용자와 트윗의 도형 주의 네트워크 (GAT) 를 사용하고 밀집된 사용자 역사 표시를 결합합니다.최근 발표된 데이터 세트에서 가장 선진적인 결과를 얻은 것을 제외하고 이 모델은 저자의 풍자 의도를 해석하는 데 기여한 바가 풍자에 대한 타인의 감지를 예측하는 것보다 크다는 것을 알 수 있다. 이 데이터 세트는 19k명의 트위터 사용자를 포함하고 그 중 30K개의 트윗과 1000만 개의 미표시 트윗을 상하문으로 추가했다.</abstract_ko>
      <abstract_fa>سیستم‌های شناسایی سارکاسم موجود روی استفاده از علامت‌های زبان‌شناسی، محیط یا سطح‌های کاربر تمرکز می‌کند. با این حال، تحقیقات اجتماعی پیشنهاد می‌دهد که رابطه بین نویسنده و تماشاگران برای استفاده کردن و تعبیر سارکاسم برابر ارتباط داشته باشد. در این کار، ما یک چهارچوب را پیشنهاد می‌کنیم که با همدیگر یک محیط کاربر (۱) از tweets تاریخی آنها با (۲) اطلاعات اجتماعی از محله‌های مکالمه‌ای از یک کاربر در یک گراف تعامل، برای تفسیر تعامل پست را متوجه کنیم. ما از شبکه های توجه گرافیک (GAT) بر روی کاربران و توئیت در یک طبقه مکالمه استفاده می‌کنیم، که با نمایش تاریخ کاربران داغ است. غیر از رسیدن نتایج هنری در مجموعه داده های اخیر منتشر شده از کاربران توئیتر ۱۹ک با توئیت‌های ۳۰ کیلومتر با توئیت‌های نامیده شده، به عنوان محیط اضافه کردن توئیت‌های ۱۰ میلیون نامیده شده، نتایج ما نشان می‌دهند که این مدل برای تعبیر کردن قصد‌های سارکاستیک یک نویسنده بیشتر از پیش بینی کردن</abstract_fa>
      <abstract_sw>Mfumo wa uchunguzi wa kemikali uliopo unajikita kutumia alama za lugha, muktadha, au vipaumbele vya mtumiaji. Hata hivyo, utafiti wa kijamii unapendekeza kuwa uhusiano kati ya mwandishi na hadhira unaweza kuwa na umuhimu wa matumizi ya kejeli na tafsiri. Katika kazi hii, tunapendekeza mfumo wa pamoja wa kutumia mfumo wa mtumiaji (1) kutoka kwenye twiti zao za kihistoria pamoja na (2) taarifa za kijamii kutoka kwenye maeneo ya mazungumzo ya mtumiaji katika picha ya mahusiano, ili kutafakari tafsiri ya makala hiyo. Tunatumia mitandao ya uchunguzi wa picha (GAT) kwa watumiaji na twiti katika mitandao ya mazungumzo, ikiwa ni pamoja na uwakilishi wa historia nzito wa watumiaji. Pamoja na matokeo ya hali ya sanaa juu ya seti ya taarifa zilizochapishwa hivi karibuni ya watumiaji wa Twita wa 19k wakiwa na twiti 30K zilizobainishwa, kuongeza twiti zilizoonyeshwa kama muktadha, matokeo yetu yanaonyesha kuwa mtindo huu unachangia kutafsiri malengo ya kejeli ya mwandishi zaidi ya kutabiri mtazamo wa kejeli na wengine.</abstract_sw>
      <abstract_de>Bestehende Sarkasmus-Erkennungssysteme konzentrieren sich auf die Ausnutzung linguistischer Marker, Kontext oder Priors auf Benutzerebene. Sozialstudien legen jedoch nahe, dass die Beziehung zwischen Autor und Publikum gleichermaßen relevant für die Verwendung und Interpretation des Sarkasmus sein kann. In dieser Arbeit schlagen wir ein Framework vor, das (1) einen Nutzerkontext aus ihren historischen Tweets zusammen mit (2) die sozialen Informationen aus der Konversationsumgebung eines Nutzers in einem Interaktionsgraphen nutzt, um die Interpretation des Beitrags zu kontextualisieren. Wir verwenden Graph Attention Networks (GAT) über Benutzer und Tweets in einem Konversationsthread, kombiniert mit dichten Darstellungen der Benutzerhistorie. Abgesehen davon, dass wir State-of-the-Art-Ergebnisse auf dem kürzlich veröffentlichten Datensatz von 19k Twitter-Nutzern mit 30K markierten Tweets erzielen und 10M unbeschriftete Tweets als Kontext hinzufügen, deuten unsere Ergebnisse darauf hin, dass das Modell mehr dazu beiträgt, die sarkastischen Absichten eines Autors zu interpretieren als die Sarkasmus-Wahrnehmung durch andere vorherzusagen.</abstract_de>
      <abstract_af>Bestaande sarkasme-oppdagingsstelsels fokus op die gebruik van lingwisiese merkers, konteks of gebruiker-vlak vooraf. Maar sosiale studies beveel dat die verwanting tussen die outeur en die publiek gelyk relevant kan wees vir die sarkasme gebruik en uitlegging. In hierdie werk voorstel ons 'n raamwerk wat saamstig (1) ân gebruikersamekontekst van hul historiese tweets saam met (2) die sosiale inligting van ân gebruiker se konversasionale naboosheid in ân interaksie grafiek aanwys, om die uitlegging van die pos te contekteer. Ons gebruik graaf aandag netwerke (GAT) oor gebruikers en tweets in 'n gesprekslys draad, gekombineer met dens gebruiker geskiedenis voorstellings. Behalwe van die toestand-van-kuns-resultate van die onlangs gepubliseerde datastel van 19k Twitter gebruikers met 30K etiketeerde tweets, toe 10M ongeabelde tweete as konteks byvoeg, vertoon ons resultate dat die model bydra om die sarkasiese intensies van 'n outeur te interpreteer meer as om die voorskou van die sarkasme oordeel deur ander te voorskou.</abstract_af>
      <abstract_tr>Öň bar sarkasm deteksi sistemleri dil işaretçilerini, kontekstleri we ullançy derejesini öňünden ulanmakda fokus edýärler. Ýöne sosyal araştyrmalar awtoryň we arzuwçylaryň arasyndaky baglaşyklaryň, sarkasy ulanylygy we terjimeleri üçin deňe-deňleýän bolmagyny maslahat berýärler. Bu işde ullançylaryň (1) taryhy tweetlerinden sosial maglumaty (2) uzanyşyň soňlaşyk mahallesinden bir terjime grafiklerinde çykmak üçin bir nusga çykmak teklip edýäris. Biz ulananlar we tweets dilinde grafik üns a ňlaryny (GAT) ulanýarys, gürrüňe geçmişi tuýtalaryň derejesi bilen birleşýäris. 19k Twitter Ullançylarynyň 30K etilen tweets bolan 19k sanat netijesini başarmakdan başga, netijesimiz bu nusga awtoryň sarkasy niýetlerini başarmakdan kömekleyär.</abstract_tr>
      <abstract_am>የሥርዓት ምርጫዎች However, social studies suggest that the relationship between the author and the audience can be equally relevant for the sarcasm usage and interpretation.  በዚህ ሥራ ውስጥ (1) የተባለው ታሪካዊ ትዊተኞቹን የተጠቃሚ ማኅበራዊ መረጃዎችን (2) በተጠቃሚ የአካባቢው ግንኙነት ማኅበራዊ ማህበራዊ መረጃዎችን በመጠቀም ግንኙነት ላይ ለመጠቀም እናስባለን፡፡ በተጠቃሚዎች እና በትዊተሮች ላይ ጥያቄዎችን እና ጥያቄን እናስጠጋለን፡፡ ከቅርብ ዘመን በ19k ትዊተር ተጠቃሚዎች ላይ የተለወጠውን የሀብት ፍቺዎች ካደረገ በቀር 30K የተጻፈውን ትዊተሮች እና 10M ያልታወቀ Tweets እንደተጨመረ አካባቢ፣ ፍሬታችን ምሳሌው የሳርካሲ አቃውሞ የጸሐፊውን አዋጅ ለመተረጉም ይችላል፡፡</abstract_am>
      <abstract_az>Existing sarkasm keŇüif sisteml…ôri dil iŇüaret√ßil…ôrini, kontekstl…ôrini v…ô istifad…ô√ßil…ôrinin s…ôviyy…ôsini …ôvv…ôll…ôr istifad…ô etm…ôy…ô odaqlanńĪr. Lakin sosyal t…ôhsil t…ôhsil edir ki, yazńĪcńĪ v…ô seyircil…ôr arasńĪndakńĪ iliŇükisi sarkasm istifad…ôsi v…ô t…ôfsil √ľ√ß√ľn eyni olaraq …ôlaq…ô ed…ô bil…ôr. Bu iŇüd…ô, istifad…ô√ßil…ôrin m√ľzakir…ô grafńĪndan qoŇüulan sosyal m…ôlumatlarńĪ il…ô birlikd…ô (2) istifad…ô√ßil…ôrinin istifad…ô√ßil…ôrind…ôn birlikd…ô (1) istifad…ô√ßi m…ôlumatlarńĪnńĪ birlikd…ô istifad…ô√ßil…ôrinin m√ľzakir…ô grafńĪndan t…ôklif etm…ôyi t…ôklif edirik. Biz qonaqlńĪq dilind…ô istifad…ô√ßil…ôrin v…ô tweetl…ôrin √ľz…ôrind…ô grafik m…ôlumatlarńĪnńĪ (GAT) istifad…ô edirik, yox istifad…ô√ßil…ôrin ke√ßmiŇüi g√∂st…ôricisi il…ô birlikd…ô. YaxńĪnlarda 19k Twitter istifad…ô√ßil…ôrinin yeni yayńĪnlanan veril…ôr qutusundan baŇüqa, 30K etiketli twetl…ôr olan, 10M etiketsiz twetl…ôri kontekst olaraq …ôlav…ô etdiyimiz m…ôs…ôl…ôl…ôrimiz g√∂st…ôrir ki, modell…ôrin yazńĪcńĪnńĪn sarkastik niyy…ôtl…ôrini baŇüqalarńĪnńĪn sarkasm g√∂r√ľn√ľŇü√ľn√ľ t…ômin etm…ôsind…ôn daha √ßox t…ômin edir.</abstract_az>
      <abstract_bn>বর্তমান বিদ্রোহী সনাক্ত ব্যবস্থা ভাষাগত চিহ্ন, প্রেক্ষাপট, ব্যবহারকারী স্তরের পূর্বে মনোযোগ প্রদান করে। তবে সামাজিক গবেষণা পরামর্শ দেয় যে লেখক এবং দর্শকদের মধ্যে সম্পর্ক একই রকম বিদ্রূপ ব্যবহার এবং ব্যাখ্যার জন্য প্রয়োজন। এই কাজে আমরা তাদের ঐতিহাসিক টুইট থেকে একটি ব্যবহারকারীর প্রেক্ষাপট প্রস্তাব করছি (১) যোগাযোগ করার প্রস্তাব দিচ্ছি (২) একটি ব্যবহারকারীর আলোচনাকারী এলাকার সামাজ আমরা ব্যবহারকারীদের উপর গ্রাফ মনোযোগ নেটওয়ার্ক (GAT) ব্যবহার করি এবং টুইট করে একটি কথোপকথন স্থানে ব্যবহার করি, যার সাথে সংকীর্ণ ব সাম্প্রতিক ১৯কি টুইটার ব্যবহারকারীদের প্রকাশিত তথ্যের ফলাফল পাওয়ার পরিবর্তে ৩০০০০ টুইট ব্যবহারকারীদের টুইটের সাথে যোগ করে আমাদের ফলাফল নির্দেশ দেয় যে অন্যান্য লেখকের দ্বারা বিদ্রূপ ধারণা প্রদর্শন</abstract_bn>
      <abstract_sq>Existing sarcasm detection systems focus on exploiting linguistic markers, context, or user-level priors.  Megjithatë, studimet shoqërore sugjerojnë se marrëdhënia midis autorit dhe publikut mund të jetë e barabartë për përdorimin dhe interpretimin e sarkazmit. Në këtë punë, ne propozojmë një kuadër që bashkëpunon (1) një kontekst përdorues nga tweetet e tyre historike s ë bashku me (2) informacionin social nga një lagje bisedimore të përdoruesit në një grafik ndërveprimi, për të kontekstualizuar interpretimin e postit. Ne përdorim rrjetet e vëmendjes grafike (GAT) mbi përdoruesit dhe tweetet në një filë bisedimi, të kombinuar me përfaqësime të dendura të historisë së përdoruesve. Përveç arritjes së rezultateve më të moderne në grupin e të dhënave të publikuara kohët e fundit të përdoruesve të Twitter-it 19.000 me tweets të etiketuar 30.000, duke shtuar 10.000 tweets të paetiketuar si kontekst, rezultatet tona tregojnë se modeli kontribuon në interpretimin e qëllimeve sarkastike të një autori më shumë se në parashikimin e perceptimit të sarkazmit nga të tjerët.</abstract_sq>
      <abstract_ca>Els sistemes de detecció del sarcasme existents es centren en explotar els marcadors lingüístics, el context o els antecedents a nivell d'usuari. No obstant això, estudis socials suggereixen que la relació entre l'autor i l'audiència pot ser igualment rellevant per l'ús i l'interpretació del sarcasme. In this work, we propose a framework jointly leveraging (1) a user context from their historical tweets together with (2) the social information from a user's conversational neighborhood in an interaction graph, to contextualize the interpretation of the post.  Utilitzem xarxes d'atenció al gràfic (GAT) per als usuaris i tweets en un fil de conversa, combinat amb representacions denses de la història dels usuaris. A part d'aconseguir resultats més avançats sobre el conjunt de dades publicat recentment de 19.000 usuaris de Twitter amb tweets etiquetats de 30.000, afegint tweets no etiquetats de 10.000 com contexte, els nostres resultats indican que el model contribueix a interpretar les intencions sarcàstiques d'un autor més que a predir la percepció del sarcasme d'altres.</abstract_ca>
      <abstract_cs>Stávající systémy detekce sarkasmu se zaměřují na využití jazykových značek, kontextu nebo uživatelských předchozích záznamů. Sociální studie však naznačují, že vztah mezi autorem a publikem může být stejně relevantní pro použití sarkasmu a interpretaci. V této práci navrhujeme rámec společně využívající (1) uživatelský kontext z historických tweetů společně s (2) sociálními informacemi z konverzačního okolí uživatele v interakčním grafu pro kontextualizaci interpretace příspěvku. Používáme grafové pozornostní sítě (GAT) nad uživateli a tweety v konverzačním vlákně v kombinaci s hustými reprezentacemi historie uživatelů. Kromě dosažení nejnovějších výsledků na nedávno zveřejněném datovém souboru uživatelů 19k Twitteru s 30K označenými tweety, přidání 10M neoznačených tweetů jako kontext, naše výsledky ukazují, že model spíše přispívá k interpretaci sarkastických záměrů autora než k predikci sarkasmu vnímání ostatními.</abstract_cs>
      <abstract_et>Olemasolevad sarkasmi tuvastamise süsteemid keskenduvad keeleliste markerite, konteksti või kasutajatasandi prioriteetide kasutamisele. Sotsiaaluuringud näitavad siiski, et autori ja publiku vaheline suhe võib sarkasmi kasutamise ja tõlgendamise seisukohalt olla sama oluline. Selles töös pakume välja raamistiku, mis ühiselt võimendab (1) kasutaja konteksti nende ajaloolistest säutsudest koos (2) kasutaja vestluslikust naabruskonnast pärit sotsiaalset infot interaktsioonigraafikus, et kontekstualiseerida postituse tõlgendamist. Kasutame graafilise tähelepanu võrgustikke (GAT) kasutajate üle ja vestluslõime säutseid koos tihedate kasutajaajaloo esitustega. Lisaks sellele, et viimasel ajal avaldatud 19k Twitteri kasutaja andmekogumil on 30K märgistatud säutsud, lisades kontekstiks 10M märgistamata säutsud, näitavad meie tulemused, et mudel aitab tõlgendada autori sarkastilisi kavatsusi rohkem kui ennustada sarkasmi tajumist teiste poolt.</abstract_et>
      <abstract_hy>Գոյություն ունի սարկազմի հայտնաբերման համակարգեր, որոնք կենտրոնանում են լեզվաբանական մարկերների, կոնտեքստի կամ օգտագործողի մակարդակի նախկին օգտագործման վրա: Սակայն սոցիալական ուսումնասիրությունները ցույց են տալիս, որ հեղինակի և հանդիսատեսի միջև կապը կարող է նույնքան կարևոր լինել սարկազմի օգտագործման և մեկնաբանության համար: Այս աշխատանքի ընթացքում մենք առաջարկում ենք մի շրջանակ, որը միասին օգտագործում է (1) օգտագործողի կոնտեքստը իրենց պատմական թվիթերից միասին (2) օգտագործողի հաղորդակցման հարևանքի սոցիալական տեղեկատվությունը փոխազդեցության գրաֆիկի մեջ, որպեսզի կարողանանք կոնտեքստ Մենք օգտագործում ենք գծագրային ուշադրության ցանցեր (ԳԱԹ) օգտագործողների և թվիթերի վրա խոսակցության թեման մեջ, համադրված խիստ օգտագործողների պատմության ներկայացումների հետ: Ավելին վերջերս հրատարակված 19k թվիթերի օգտագործողների տվյալների համակարգի վերջերս արդյունքներ ստանալուց 30K-ի թվիթերի վրա, ավելացնելով 10M-ը որպես կոնտեքստ, մեր արդյունքները ցույց են տալիս, որ մոդելը օգնում է մեկնաբանել հեղինակի սարկաստական մտադրությունները ավելի շատ, քան կանխատեսել ուրիշների սարկազմի ընկալու</abstract_hy>
      <abstract_bs>Postojeći sistemi detekcije sarkazma fokusiraju se na upotrebu jezičkih markera, konteksta ili razine korisnika. Međutim, socijalne studije sugeriraju da odnos između autora i publike može biti jednako relevantan za korištenje sarkazma i interpretaciju. U ovom poslu predlažemo okvir koji zajednički utiče na (1) kontekst korisnika iz njihovih istorijskih tweeta zajedno s (2) socijalne informacije iz razgovornog susjedstva korisnika u grafiku interakcije, kako bi kontekstualizirali interpretaciju post a. Koristimo grafičke mreže pažnje (GAT) nad korisnicima i tweetom u konverziji razgovora, zajedno sa gustima predstavljanja povijesti korisnika. Osim postignuća rezultata države umjetnosti na nedavno objavljenoj seriji podataka od 19k korisnika Twitter-a s 30K označenim tweetom, dodajući 10M nezabeliranih tweeta kao kontekst, naši rezultati ukazuju na to da model doprinosi interpretaciji sarkastičnih namera autora više nego predviđati percepciju sarkazma od strane drugih.</abstract_bs>
      <abstract_fi>Olemassa olevat sarkasmin tunnistusjärjestelmät keskittyvät kielellisten merkkien, kontekstin tai käyttäjätason prioriteettien hyödyntämiseen. Sosiaaliset tutkimukset kuitenkin viittaavat siihen, että tekijän ja yleisön välinen suhde voi olla yhtä merkittävä sarkasmin käytön ja tulkinnan kannalta. Tässä työssä ehdotamme viitekehystä, jossa hyödynnetään (1) käyttäjäkontekstia heidän historiallisista twiitteistään yhdessä (2) käyttäjän keskustelualueen sosiaalisen informaation kanssa vuorovaikutuskaaviossa, kontekstualisoidakseen artikkelin tulkintaa. Käytämme graafisen huomion verkostoja (GAT) käyttäjien päälle ja twiittejä keskusteluketjussa yhdistettynä tiheisiin käyttäjähistorian esityksiin. Tuloksemme osoittavat, että malli auttaa tulkitsemaan kirjoittajan sarkastisia aikomuksia enemmän kuin ennustamaan sarkasmin havaintoa muiden taholta.</abstract_fi>
      <abstract_jv>Sistem Alpha Nanging, uwong-uwong pisan resmi sing ngerasahan kanggo resmi seneng pisan karo perusahaan lan ora iso nggawe barang nggawe sarkasma nggo ngerasahan. Nang arjamahan iki, kita nggunakake sistem kanggo nggawe nggawe (1) kontèks user ditawak nyebuturan karo (2) informasi sotiki nang nggawe ngubah barêng-barêng wong liyane karo ingkang nggawe geraraning nggawe geraraning nggawe geraraning daftar wigatahan. Awak dhéwé nggunakake seneng nggambar barang gambar lan tuytir tentang ing conversations threads, ditambah karo pergambar tarjamahan Mbok iso nggawe gerambut-perusahaan karo hal-perusahaan karo ngono data sing dipului luwih dumadhi 19 k Tutor karo 30 K sing etiket tuket, nambah 10 M kuwi dituruti sing gak perusahaan, dadi nambah dhéwé kuwi model nyenggawe tarjamahan kanggo ngerasai perusahaan sarkastik sing bisa dumadhi perusahaan maneh sing bisa gedhéwé karo perusahaan sarkasma sing bisa</abstract_jv>
      <abstract_ha>Existing sarcasm detection systems focus on exploiting linguistic markers, context, or user-level priors.  A lokacin da fassarar mutane sun shauri cẽwa, zumunta da ma'abũcin marubuci da saurãre za'a iya daidai da amfani da fassarar sarki. Daga wannan aikin, Muke goyyade wani firam mai amfani da shi wadangan da ke samarari (1) da mazaɓa daga littafansu na historical wato tãre da (2) da ma'anar jama'a daga mazaɓan mai haɗuwa da mai amfani da shi cikin grafyutan interaction, dõmin ya kafo fassarar fassarar posten. Tuna yi amfani da wagon muhalli na grafika (GAT) kan mãsu amfani da watumishi da wato biyu cikin wani hoton da ke cikin mazaɓa, sami da masu motsi na historin mai nauyi. Babu gaskata matsalar-sanar da aka samu da fassarar mutane na farkon da aka nuna na fassarar da watumin Twitter na 19k, wato 30,000 na rubutu, sunã ƙara 10M wanda ba'a rubutu da shi ba kamar mazaɓa, matsalayinmu yana ƙarfafa da fassarar sarcasti na fassarar wani marubucin na rubuci ko da ya yi bayani ga kalmar sarkasm na daban.</abstract_ha>
      <abstract_bo>Existing་ཡོད་པའི་སྐད་རིགས་བཀོད་པའི་ལག་ལེན་པ་ཚོར་སྤྱོད་པའི་རྣམ་གྲངས ཡིན་ནའང་། སྤྱི་ཚོགས་ཀྱི་ལས་འཚོལ་ཞིབ་ནི་རྩོམ་པ་པོ་དང་རྣམ་པ་གཉིས་ཀྱི་འབྲེལ་བ་ནི་ཚོར་བ་དང་མཚུངས་པ་མཚུངས་ནི་ཕན་ར འོན་ཀྱང་། ང་ཚོས་བྱ་རིམ་འདིའི་ནང་དུ་སྤྱོད་མཁན་གྱི་ཟིན་ཐོ་ཞིག་གི་མཉམ་དུ་འཇུག་སྤྱོད་མཁན་གྱི་གྲོང་ཁྱེར་ཚོགས་ལས་ཕན་ཚུལ་བཤད་བྱེད་རྒྱུ་དང་། ང་ཚོས་སྤྱོད་མཁན་གཙོ་རིམ་དྲ་བ་དང་གླེང་མོལ་གྱི་གླེང་སྒྲོམ་གྱི་ཤོག་བྱང་ཐོག་ཏུ། Apart from achieving state-of-the-art results on the recently published dataset of 19k Twitter users with 30K labeled tweets, adding 10M unlabeled tweets as context, our results indicate that the model contributes to interpreting the sarcastic intentions of an author more than to predicting the sarcasm perception by others.</abstract_bo>
      <abstract_sk>Obstoječi sistemi za odkrivanje sarkazma se osredotočajo na izkoriščanje jezikovnih označevalcev, konteksta ali predhodnih ugotovitev na ravni uporabnika. Vendar pa družbene študije kažejo, da je odnos med avtorjem in občinstvom lahko enako pomemben za uporabo sarkazma in interpretacijo. V tem delu predlagamo okvir, ki skupaj uporablja (1) uporabniški kontekst iz njihovih zgodovinskih tweetov skupaj z (2) socialnimi informacijami iz uporabnikove pogovorne soseske v interakcijskem grafu, da kontekstualizira interpretacijo objave. Uporabljamo grafske pozornosti omrežja (GAT) preko uporabnikov in tweete v pogovorni niti, v kombinaciji z gostimi predstavitvami zgodovine uporabnikov. Poleg doseganja najsodobnejših rezultatov na nedavno objavljenem naboru podatkov 19k uporabnikov Twitterja s 30K označenimi tweeti in dodajanja 10M neoznačenih tweetov kot kontekst, naši rezultati kažejo, da model prispeva k interpretaciji sarkastičnih namenov avtorja bolj kot k napovedovanju zaznavanja sarkazma s strani drugih.</abstract_sk>
      <abstract_he>מערכות גילוי סרקזם קיימות מתמקדות בניצחון סימנים שפתיים, הקשר או קודמות ברמה משתמש. למרות זאת, מחקרים חברתיים מציעים שהמערכת יחסים בין הסופר לקהל יכולה להיות רלוונטית באותה מידה לשימוש בסרקזם ולפרשנות. בעבודה הזו, אנו מציעים מסגרה משותפת (1) קשר משתמש מהטוויטים ההיסטוריים שלהם יחד עם (2) המידע החברתי משכונה השיחה של משתמש בגרף אינטראקציה, כדי לקונטליזם את הפרשנות של הפוסט. אנו משתמשים ברשתות תשומת לב לגרף (GAT) על משתמשים וטוויטים באthread שיחה, בשילוב עם מייצגי היסטוריה של משתמשים צפופים. חוץ מלהשיג תוצאות מוקדמות על קבוצת המידע המפורסמת לאחרונה של משתמשים בטוויטר של 19 אלף עם טוויטרים עם תוויטרים עם תוויטרים עם תוויטרים עם תוויטרים עם תוויטרים של 30 אלף, הוספת טוויטרים ללא תוויטרים עם תוויטרים ללא תוויטרים בתור קונטקסט, התוצאות שלנו מצביעות שהמודל תורם לפרשנות כוונות הסרקסט</abstract_he>
      </paper>
    <paper id="18">
      <title>Comparing Grammatical Theories of Code-Mixing</title>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>Monojit</first><last>Choudhury</last></author>
      <pages>158–167</pages>
      <abstract>Code-mixed text generation systems have found applications in many downstream tasks, including <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>, <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>. A paradigm of these generation systems relies on well-defined grammatical theories of code-mixing, and there is a lack of comparison of these <a href="https://en.wikipedia.org/wiki/Theory">theories</a>. We present a large-scale human evaluation of two popular grammatical theories, Matrix-Embedded Language (ML) and Equivalence Constraint (EC). We compare them against three heuristic-based models and quantitatively demonstrate the effectiveness of the two <a href="https://en.wikipedia.org/wiki/Grammatical_theory">grammatical theories</a>.</abstract>
      <url hash="251fcc03">2021.wnut-1.18</url>
      <bibkey>pratapa-choudhury-2021-comparing</bibkey>
      <doi>10.18653/v1/2021.wnut-1.18</doi>
    <title_es>Comparación de teorías gramaticales de la mezcla de códigos</title_es>
      <title_ar>مقارنة النظريات النحوية لخلط الشفرات</title_ar>
      <title_fr>Comparaison des théories grammaticales du mélange de codes</title_fr>
      <title_pt>Comparando teorias gramaticais de mixagem de códigos</title_pt>
      <title_zh>校代码混合语法论</title_zh>
      <title_ja>コード混合の文法理論の比較</title_ja>
      <title_hi>कोड-मिक्सिंग के व्याकरणिक सिद्धांतों की तुलना करना</title_hi>
      <title_ru>Сравнение грамматических теорий смешивания кода</title_ru>
      <title_ga>Comparáid a dhéanamh idir Teoiricí Gramadaí Chódmheasctha</title_ga>
      <title_hu>A kódkeverés nyelvtani elméleteinek összehasonlítása</title_hu>
      <title_el>Σύγκριση των γραμματικών θεωριών της ανάμειξης κώδικα</title_el>
      <title_ka>Name</title_ka>
      <title_lt>Comparing Grammatical Theories of Code-Mixing</title_lt>
      <title_it>Confronto delle teorie grammaticali della miscelazione di codici</title_it>
      <title_kk>Код араласуының граматикалық теорияларын салыстыру</title_kk>
      <title_ml>കോഡ്- മിക്സിങ്ങിന്റെ ഗ്രാമാറ്റിക്കല്‍ തിയോറികള്‍ ചേര്‍ക്കുക</title_ml>
      <title_mt>It-tqabbil tat-Teoriji Grammatiċi tat-Taħlita tal-Kodiċi</title_mt>
      <title_mk>Споредување на граматски теории за мешање кодови</title_mk>
      <title_pl>Porównanie teorii gramatycznych mieszania kodów</title_pl>
      <title_ro>Compararea teoriilor gramaticale ale amestecării codurilor</title_ro>
      <title_no>Samanliknar grammatiske teorier om kode- mixing</title_no>
      <title_sr>Uspoređujući gramatičke teorije miješanja kodova</title_sr>
      <title_ms>Comparing Grammatical Theories of Code-Mixing</title_ms>
      <title_so>Isbarbardhigga tiyaatarada takhasuska</title_so>
      <title_si>Name</title_si>
      <title_ur>کوڈ میکسنگ کی گرماتیک تئوریوں کے مقابلہ میں</title_ur>
      <title_mn>Код-холбогдолтын граматикийн теорийг харьцуулах</title_mn>
      <title_sv>Jämföra grammatiska teorier om kodblandning</title_sv>
      <title_ta>குறியீடு- கலக்குதலின் சிறந்த தோற்றங்களை ஒப்பிடுகிறது</title_ta>
      <title_uz>Kodlash usulini moslash</title_uz>
      <title_vi>So sánh các định lí giải mã trộn lẫn</title_vi>
      <title_da>Sammenligning af grammatiske teorier om kodeblanding</title_da>
      <title_nl>Vergelijking van grammaticale theorieën van codemenging</title_nl>
      <title_bg>Сравняване на граматическите теории на кодовото смесване</title_bg>
      <title_hr>Uspoređujući gramatičke teorije miješanja kodova</title_hr>
      <title_ko>코드 혼합의 문법 이론 비교</title_ko>
      <title_de>Vergleich der grammatischen Theorien der Code-Mixing</title_de>
      <title_id>Membandingkan Teori Grammatis Pengcampuran Kode</title_id>
      <title_fa>مقایسه تئوری گراماتیکی از پیوند کد</title_fa>
      <title_sw>Kulinganisha Makala ya KiGrammatiki ya Kuunganisha</title_sw>
      <title_tr>Gramatik Teoriýalary Karışma</title_tr>
      <title_af>Vergelyk Gramatiese Teories van Kode- Menger</title_af>
      <title_sq>Duke krahasuar teoritë grammatike të përzierjes së kodeve</title_sq>
      <title_hy>Կոդի խառնման գրամմատիկ տեսությունների համեմատությունը</title_hy>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_az>Kod-KarńĪŇümasńĪnńĪn Gramatik Teoril…ôri</title_az>
      <title_bs>Uspoređujući gramatičke teorije miješanja kodova</title_bs>
      <title_ca>Comparar teories gramàtiques de la mistura de codis</title_ca>
      <title_bn>কোড- মিক্সিং এর গ্রামাটিক্যাল থিওর তুলনা করা হচ্ছে</title_bn>
      <title_cs>Srovnání gramatických teorií smíšení kódu</title_cs>
      <title_et>Koodisegustamise grammatiliste teooriate võrdlemine</title_et>
      <title_fi>Koodien sekoittamisen kielioppiteorioiden vertailu</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>Comparing Grammatical Theories of Code-Mixing</title_he>
      <title_sk>Primerjava slovničnih teorij mešanja kod</title_sk>
      <title_jv>Name</title_jv>
      <title_bo>Comparing Grammatical Theories of Code-Mixing</title_bo>
      <abstract_ar>وجدت أنظمة إنشاء النص المختلط بالشفرات تطبيقات في العديد من المهام النهائية ، بما في ذلك التعرف على الكلام والترجمة والحوار. يعتمد نموذج أنظمة الجيل هذه على نظريات نحوية محددة جيدًا لخلط الشفرات ، وهناك نقص في المقارنة بين هذه النظريات. نقدم تقييمًا بشريًا واسع النطاق لاثنين من النظريات النحوية الشائعة ، لغة المصفوفة المضمنة (ML) وقيد التكافؤ (EC). قمنا بمقارنتها مع ثلاثة نماذج قائمة على الكشف عن مجريات الأمور ونوضح كميًا فعالية النظريتين النحويتين.</abstract_ar>
      <abstract_pt>Os sistemas de geração de texto de código misto encontraram aplicações em muitas tarefas downstream, incluindo reconhecimento de fala, tradução e diálogo. Um paradigma desses sistemas de geração baseia-se em teorias gramaticais bem definidas de mistura de códigos, e há uma falta de comparação dessas teorias. Apresentamos uma avaliação humana em larga escala de duas teorias gramaticais populares, Matrix-Embedded Language (ML) e Equivalence Constraint (EC). Nós os comparamos com três modelos baseados em heurística e demonstramos quantitativamente a eficácia das duas teorias gramaticais.</abstract_pt>
      <abstract_fr>Les systèmes de génération de texte à code mixte ont trouvé des applications dans de nombreuses tâches en aval, notamment la reconnaissance vocale, la traduction et le dialogue. Un paradigme de ces systèmes de génération repose sur des théories grammaticales bien définies du mélange de codes, et il y a un manque de comparaison entre ces théories. Nous présentons une évaluation humaine à grande échelle de deux théories grammaticales populaires, Matrix-Embedded Language (ML) et Equivalence Constraint (EC). Nous les comparons à trois modèles heuristiques et démontrons quantitativement l'efficacité des deux théories grammaticales.</abstract_fr>
      <abstract_es>Los sistemas de generación de texto con código mixto han encontrado aplicaciones en muchas tareas posteriores, como el reconocimiento de voz, la traducción y el diálogo. Un paradigma de estos sistemas de generación se basa en teorías gramaticales bien definidas de la mezcla de códigos, y hay una falta de comparación de estas teorías. Presentamos una evaluación humana a gran escala de dos teorías gramaticales populares, Matrix-Embedded Language (ML) y Equivalence Constraint (EC). Los comparamos con tres modelos heurísticos y demostramos cuantitativamente la eficacia de las dos teorías gramaticales.</abstract_es>
      <abstract_ja>コード混合テキスト生成システムは、音声認識、翻訳、対話を含む多くの下流タスクにアプリケーションを見つけました。これらの生成システムのパラダイムは、明確に定義されたコード混合の文法理論に依存しており、これらの理論の比較が不足している。マトリックス埋め込み言語（ ML ）と等価制約（ EC ）という2つの一般的な文法理論の大規模な人間評価を提示します。3つのヒューリスティックベースのモデルと比較し、2つの文法理論の有効性を定量的に実証します。</abstract_ja>
      <abstract_ru>Системы генерации текста со смешанным кодом нашли применение во многих последующих задачах, включая распознавание, перевод и диалог. Парадигма этих систем генерации основана на четко определенных грамматических теориях смешивания кода, и сравнение этих теорий отсутствует. Мы представляем широкомасштабную оценку человеком двух популярных грамматических теорий: матрично-вложенного языка (ML) и ограничения эквивалентности (EC). Мы сравниваем их с тремя моделями, основанными на эвристике, и количественно демонстрируем эффективность двух грамматических теорий.</abstract_ru>
      <abstract_zh>代码混合文本生成系统已于下流求用,兼语音识别、译和对话。 此范式所以明义代码混语法论,而阙其比也。 二者语法论,矩阵嵌入式言(ML)等效(EC)。 比之三启发式,量验二语法之有效性。</abstract_zh>
      <abstract_hi>कोड-मिश्रित पाठ पीढ़ी प्रणालियों ने भाषण मान्यता, अनुवाद और संवाद सहित कई डाउनस्ट्रीम कार्यों में अनुप्रयोग पाए हैं। इन पीढ़ी प्रणालियों का एक प्रतिमान कोड-मिश्रण के अच्छी तरह से परिभाषित व्याकरणिक सिद्धांतों पर निर्भर करता है, और इन सिद्धांतों की तुलना की कमी है। हम दो लोकप्रिय व्याकरणिक सिद्धांतों, मैट्रिक्स-एम्बेडेड लैंग्वेज (एमएल) और तुल्यता बाधा (ईसी) का एक बड़े पैमाने पर मानव मूल्यांकन प्रस्तुत करते हैं। हम उनकी तुलना तीन हेरिस्टिक-आधारित मॉडलों के खिलाफ करते हैं और मात्रात्मक रूप से दो व्याकरणिक सिद्धांतों की प्रभावशीलता का प्रदर्शन करते हैं।</abstract_hi>
      <abstract_ga>Tá feidhmchláir aimsithe ag córais ginte téacs cód-mheasctha i go leor tascanna iartheachtacha, lena n-áirítear aithint cainte, aistriúchán agus idirphlé. Braitheann paraidím de na córais ghiniúna seo ar theoiricí dea-shainithe gramadaí maidir le códmheascadh, agus tá easpa comparáide idir na teoiricí sin. Cuirimid i láthair meastóireacht dhaonna ar scála mór ar dhá theoiric ghramadaí mhóréilimh, Matrix-Embedded Language (ML) agus Coibhéis Srianadh (CE). Déanaimid iad a chur i gcomparáid le trí mhúnla heorastúla-bhunaithe agus léirímid go cainníochtúil éifeachtacht an dá theoiric ghramadaí.</abstract_ga>
      <abstract_el>Τα συστήματα δημιουργίας κειμένου μικτού κώδικα έχουν βρει εφαρμογές σε πολλές μεταγενέστερες εργασίες, συμπεριλαμβανομένης της αναγνώρισης ομιλίας, της μετάφρασης και του διαλόγου. Ένα παράδειγμα αυτών των συστημάτων παραγωγής βασίζεται σε καλά καθορισμένες γραμματικές θεωρίες της ανάμειξης κώδικα, και υπάρχει έλλειψη σύγκρισης αυτών των θεωριών. Παρουσιάζουμε μια μεγάλης κλίμακας ανθρώπινη αξιολόγηση δύο γνωστών γραμματικών θεωριών, της μητρικής-ενσωματωμένης γλώσσας (και του περιορισμού ισοδυναμίας (ΕΚ). Τα συγκρίνουμε με τρία ευριστικά μοντέλα και καταδεικνύουμε ποσοτικά την αποτελεσματικότητα των δύο γραμματικών θεωριών.</abstract_el>
      <abstract_ka>Name ამ წარმოდგენების სისტემის პარადიგმა მხოლოდ განსაზღვრებული გრამიკალური თეორია, რომელიც კოდის შემთხვევაში არსებობს ამ თეორიაების შემთხვევაში. ჩვენ გვეჩვენებთ ორი პოლუმეტური გრამიკალური ტეორიების, მარრიქსის შებრუნებული ენაში (ML) და ეკვალუმენციის განმავლობა (EC). ჩვენ ისინი სამი ჰერისტიკური მოდელთან გადასწორებთ და კოლუტატიურად გამოჩვენებთ ორი გრამეტური ტეორიების ეფექტიურობა.</abstract_ka>
      <abstract_hu>A kódkeverékes szöveggeneráló rendszerek számos további feladatban találtak alkalmazást, beleértve a beszédfelismerést, a fordítást és a párbeszédet. Ezeknek a generációs rendszereknek a paradigmája a kódkeverés jól meghatározott nyelvtani elméleteire támaszkodik, és ezeknek az elméleteknek nincs összehasonlítása. Két népszerű nyelvtani elmélet, a Matrix-Embedded Language (ML) és az Equivalence Constraint (EC) nagyszabású emberi értékelését mutatjuk be. Összehasonlítjuk őket három heurisztikai alapú modellel és mennyiségileg bemutatjuk a két nyelvtani elmélet hatékonyságát.</abstract_hu>
      <abstract_kk>Код араластырылған мәтін құру жүйелері көпшілікті тапсырмаларда қолданбаларды табылды, сөздерді анықтау, аудару және диалогын қоса алады. Бұл жалғастыру жүйелерінің парадигмі код арасындағы грамматикалық теорияларына тәуелді. Бұл теорияларды салыстыру жоқ. Біз екі жалпы грамматикалық теориялар, матриксті ендірілген тіл (ML) және тең тең шектеу (EC) үлкен адамның оқиғасын көрсетедік. Біз оларды үш геуристикалық үлгілерімен салыстырып, екі грамматикалық теориясының эффективнігін көрсетеді.</abstract_kk>
      <abstract_mk>Системите за генерација на текст со мешани кодови најдоа апликации во многу понатамошни задачи, вклучително и препознавање на говорот, превод и дијалог. Парадигмата на овие генерациски системи се потпира на добро дефинирани граматички теории за мешање на кодови, и постои недостаток на споредба на овие теории. Презентираме голема човечка проценка на две популарни граматички теории, Метрикс-вграден јазик (ML) и Екваливалентни ограничувања (ЕК). Ги споредуваме со три хористички модели и квантитивно ја демонстрираме ефикасноста на двете граматички теории.</abstract_mk>
      <abstract_ms>Code-mixed text generation systems have found applications in many downstream tasks, including speech recognition, translation and dialogue.  Paradigma sistem generasi ini bergantung pada teori grammatik yang ditentukan dengan baik untuk campuran kod, dan terdapat kekurangan perbandingan teori-teori ini. Kami memperkenalkan penilaian manusia skala besar bagi dua teori grammatik populer, Bahasa Terisi Matriks (ML) dan Kebatasan Kesamaan (EC). Kami membandingkan mereka dengan tiga model berdasarkan heuristik dan kuantitatif menunjukkan kegunaan dua teori grammatik.</abstract_ms>
      <abstract_it>I sistemi di generazione di testi misti in codice hanno trovato applicazioni in molte attività a valle, tra cui il riconoscimento vocale, la traduzione e il dialogo. Un paradigma di questi sistemi di generazione si basa su teorie grammaticali ben definite del code-mixing, e c'è una mancanza di confronto di queste teorie. Presentiamo una valutazione umana su larga scala di due teorie grammaticali popolari, Matrix-Embedded Language (ML) e Equivalence Constraint (EC). Li confrontiamo con tre modelli euristici e dimostriamo quantitativamente l'efficacia delle due teorie grammaticali.</abstract_it>
      <abstract_mt>Sistemi ta’ ġenerazzjoni ta’ testi mħallta bil-kodiċi sabu applikazzjonijiet f’ħafna kompiti downstream, inkluż ir-rikonoxximent tad-diskors, it-traduzzjoni u d-djalogu. Paradigma ta’ dawn is-sistemi ta’ ġenerazzjoni tiddependi fuq teoriji grammatiċi definiti sew tat-taħlit tal-kodiċi, u hemm nuqqas ta’ paragun ta’ dawn it-teoriji. Aħna nippreżentaw evalwazzjoni umana fuq skala kbira ta’ żewġ teoriji grammatiċi popolari, Lingwa Integrata b’Matrix (ML) u Limitazzjoni ta’ Ekwivalenza (KE). We compare them against three heuristic-based models and quantitatively demonstrate the effectiveness of the two grammatical theories.</abstract_mt>
      <abstract_ml>കോഡ്- mixed text generation systems have found applications in many downstream tasks, including speech recognition, translation and dialogue. ഈ തലമുറകളുടെ സിസ്റ്റത്തിന്റെ ഒരു പരാദ്യം നല്ല നിര്‍ണ്ണയിക്കപ്പെട്ട ഗ്രാമാറ്റിക്കല്‍ തീയറികളില്‍ ആശ്രയിച്ചിരിക്കുന്നു. ഈ തിയറ നമ്മള്‍ രണ്ട് പ്രധാനപ്പെട്ട ഗ്രാമാറ്റിക്കല്‍ തിയോറികള്‍, മാട്രിക്സ്- എമ്പെഡ് ഭാഷ (എംഎല്‍) എന്നിവയുടെയും സമമായ കോണ്‍സ്റ്റ്രെന്‍ മൂന്നു ഹൂരിസ്റ്റിക്ക് അടിസ്ഥാനമായ മോഡലുകള്‍ക്കെതിരായി നമ്മള്‍ അവരെ തുല്യമാക്കുന്നു. രണ്ട് ഗ്രാമാറ്റിക്കല്‍ തിയോ</abstract_ml>
      <abstract_no>Name Eit paradigm av desse generasjonssystema er avhengig av godt definerte grammatiske teorier om kodmelding, og det er mange sammenligningar av desse teorien. Vi presenterer ein stor menneskelig evaluering av to populære grammatiske teorier, Matrix-innebygd språk (ML) og likevekslingsbegrensning (EC). Vi samanliknar dei med tre heuristiske modeller og kvantitativ viser effektiviteten av to grammatiske teorier.</abstract_no>
      <abstract_mn>Код-холбогдсон текст бүтээлч системүүд олон доорх үйл ажиллагаанд програмыг олж, илтгэл таних, орчуулах, диалог байдаг. Эдгээр үеийн системийн парадигм нь код холбогдохын сайн тодорхойлогдсон грамматик теориуд дээр хамааралтай. Эдгээр теориудын харьцуулахгүй байдаг. Бид хоёр олон алдартай грамматик теориг, Матрикс-Ингээгдсэн Хол (ML) болон тэнцүү байдлын хязгаарлалтыг үнэлгээ үзүүлсэн. Бид тэднийг гурван геуристик суурилсан загвартай харьцуулж, хоёр грамматик теорийн үр дүнг тодорхойлдог.</abstract_mn>
      <abstract_lt>Iš kodų mišrių tekstų kūrimo sistemų buvo rastos programos daugelyje tolesnių užduočių, įskaitant kalbos pripažinimą, vertimą ir dialogą. Šių kartų sistemų paradigm a grindžiama gerai apibrėžtomis gramatinėmis kodų maišymo teorijomis ir šių teorijų palyginimo stoka. Pateikiame plataus masto žmogaus vertinimą dviem populiarioms gramatinėms teorijoms, įterpta į matricą kalba (ML) ir lygiavertiškumo apribojimais (EB). Palyginame juos su trimis heuristiniais modeliais ir kiekybiškai įrodome dviejų gramatinių teorijų veiksmingumą.</abstract_lt>
      <abstract_pl>Systemy generowania tekstu mieszanego kodem znalazły zastosowanie w wielu dalszych zadaniach, w tym w rozpoznawaniu mowy, tłumaczeniu i dialogu. Paradygmat tych systemów generacyjnych opiera się na dobrze zdefiniowanych teoriach gramatycznych mieszania kodu, a brak porównania tych teorii. Przedstawiamy szeroką skalę ludzką ocenę dwóch popularnych teorii gramatycznych, języka macierzowego (ML) i ograniczenia równoważności (EC). Porównujemy je z trzema modelami heurystycznymi i ilościowo demonstrujemy skuteczność obu teorii gramatycznych.</abstract_pl>
      <abstract_ro>Sistemele de generare a textului mixt de coduri au găsit aplicații în multe sarcini din aval, inclusiv recunoașterea vorbirii, traducerea și dialogul. O paradigmă a acestor sisteme de generație se bazează pe teorii gramaticale bine definite ale amestecării codurilor și există o lipsă de comparație a acestor teorii. Prezentăm o evaluare umană la scară largă a două teorii gramaticale populare, Matrix-Embedded Language (ML) și Echivalent Constraint (EC). Le comparăm cu trei modele euristice și demonstrăm cantitativ eficacitatea celor două teorii gramaticale.</abstract_ro>
      <abstract_so>nidaamka muuqashada qoraalka ee isku xiran waxaa laga helay codsiyooyin badan oo ka mid ah shaqaalaha hoose-dureerka, kuwaas oo ah aqoonsashada hadalka, turjumista iyo dialogue. Isticmaalka qarnigan waxay ku xiran tahay tiyaatarada aad u yaqaan, waxaana laga baahan yahay mid isbardhiga tiyaataradan. Waxaannu soo bandhignaa qiimeynta dadka oo aad u weyn, labo tiyaataro maaruf ah, Luqada Matrix-Embedded (ML) iyo Isu eg (EC). Waxaynu isbarbarbardhignaa saddex tusaale oo horuristi ku saleysan iyo si qiyaas ah ayaannu muujinnaa shaqaalaha labada tiyaatarada grammatika.</abstract_so>
      <abstract_sr>Sistemi generacije teksta koji su pomešani kod pronašli su aplikacije u mnogim zadacima, uključujući priznanje govora, prevod i dijalog. Paradigma ovih generacijskih sistema se oslanja na dobro definisane gramatičke teorije miješanja koda, i nema usporedbe ovih teorija. Predstavljamo veliku ljudsku procjenu dve popularne gramatičke teorije, Matrix-Embedded jezika (ML) i ograničenja ekvivalence (EK). Uspoređujemo ih sa tri heurističke modela i kvantitativno pokazujemo efikasnost dve gramatičke teorije.</abstract_sr>
      <abstract_ta>Name இந்த தலைமுறை அமைப்புகளின் அளபுருக்கம் நன்றாக குறிமுறையிடப்பட்ட கிராமாட்டிக் கருத்துகளை சார்ந்து கொண்டிருக்கிறது, இந்த குறி நாம் பெரிய அளவில் மனித மதிப்பிடும் இரண்டு பிரபலமான கிராமாட்டிக் குறிப்பிட்ட திடீரிகள், மாட்ரிக்ஸ்- உட்பொதிந்த மொழி( ML) மற்ற மூன்று ஹூரிஸ்டிக் அடிப்படையிலுள்ள மாதிரிகளுக்கு எதிராக நாம் அவர்களை ஒப்பிடுகிறோம் மற்றும் அளவில் இந்த இரண்டு குறிப</abstract_ta>
      <abstract_si>Name මේ පරීක්ෂණ පද්ධතියේ පාර්ඩිග්මයක් හොඳටම විශ්වාස කරලා තියෙන්නේ කෝඩ් මිශ්රණය ගැන විශ්වාසික සිද්ධාවක්  අපි ලොකු මිනිස්සුන්ගේ විශේෂණයක් පෙන්වන්නේ ලොකු විශේෂණයක් දෙකක්, මැට්‍රික්ස් සම්බන්ධ භාෂාව (ML) සහ සමාන්‍ය අපි ඔවුන්ව හයුරිස්ටික් අධාරණය තුනක් විරුද්ධ වෙනුවෙන් සම්පූර්ණය කරනවා ඒ වගේම ප්‍රමාණයෙන් විශේෂ</abstract_si>
      <abstract_ur>Name ان کی نسل سیستموں کی ایک پارادیگ بہترین مقرر کردہ گراماتیکی نظریوں پر اعتماد ہے، اور ان نظریوں کی مقایسہ کی کمی ہے. ہم دو محبوب گراماتیکی نظریوں کی ایک بڑی مطابق انسان کی ارزیابی پیش کرتے ہیں، ماتریکس-جمع زبان (ML) اور Equivalence Constraint (EC). ہم نے ان کو تین ہوریستیک موڈل کے ساتھ مقایسہ کر دیا ہے اور دو گراماتیکی نظریوں کی عمدگی دکھاتے ہیں۔</abstract_ur>
      <abstract_sv>Systemen för kodblandad textgenerering har hittat tillämpningar i många efterföljande uppgifter, inklusive taligenkänning, översättning och dialog. Ett paradigm för dessa generationssystem bygger på väl definierade grammatiska teorier om kodblandning, och det finns en brist på jämförelse av dessa teorier. Vi presenterar en storskalig mänsklig utvärdering av två populära grammatiska teorier, Matrix-Embedded Language (ML) och Equivalence Constraint (EC). Vi jämför dem mot tre heuristiska modeller och visar kvantitativt hur effektiva de två grammatiska teorierna är.</abstract_sv>
      <abstract_uz>Name Bu foydalanuvchi tizimning paradigm yaxshi aniqlangan grammatikal teorilarga ishlatadi, va bu teoriga kamaytirishda yetarli mavjud emas. Biz ikkita muammolar grammatika teori, Matrix-Embedded Tilning (ML) va EC (EC) qiymatini ko'payapmiz. Biz ularni uchta heuristik asosida kamaytirimiz va ikkita grammatika teori effektini ko'rsatadi.</abstract_uz>
      <abstract_vi>Hệ thống sản xuất văn bản hỗn hợp đã tìm thấy ứng dụng trong nhiều công việc xuôi dòng, bao gồm nhận ngôn ngữ, dịch và thoại. Một mô hình của các hệ thống thế hệ này dựa trên các học thuyết theo ngữ pháp xác định về sự pha trộn mật, và không có sự so sánh của các học thuyết này. Chúng tôi giới thiệu một bài đánh giá người trên diện rộng về hai học thuyết ngữ pháp phổ biến, Ngôn ngữ Ma Trận nhúng (ML) và Điều chế độ tương đồng (EC). Chúng tôi so sánh chúng với ba phương pháp phi thường và cũng thế giới cho thấy hiệu quả của hai học thuyết ngôn ngữ.</abstract_vi>
      <abstract_da>Kodeblandede tekstgenereringssystemer har fundet applikationer i mange downstream-opgaver, herunder talegenkendelse, oversættelse og dialog. Et paradigme for disse generationssystemer er baseret på veldefinerede grammatiske teorier om kode-blanding, og der er en mangel på sammenligning af disse teorier. Vi præsenterer en omfattende menneskelig evaluering af to populære grammatiske teorier, Matrix-Embedded Language (ML) og Equivalence Restraint (EC). Vi sammenligner dem med tre heuristiske baserede modeller og demonstrerer kvantitativt effektiviteten af de to grammatiske teorier.</abstract_da>
      <abstract_bg>Системите за генериране на текст, смесени с кодове, са намерили приложения в много задачи надолу по веригата, включително разпознаване на реч, превод и диалог. Една парадигма на тези генерационни системи разчита на добре дефинирани граматически теории за смесване на кодове и липсва сравнение на тези теории. Представяме мащабна човешка оценка на две популярни граматически теории, Матрично-вграден език (МЛ) и Ограничение на еквивалентността (ЕК). Сравняваме ги с три евристично базирани модела и количествено демонстрираме ефективността на двете граматически теории.</abstract_bg>
      <abstract_hr>Sistemi proizvodnje teksta koji su pomiješani kod pronašli su aplikacije u mnogim zadacima, uključujući priznanje govora, prevod i dijalog. Paradigma ovih generacijskih sustava oslanja se na dobro definirane gramatičke teorije miješanja koda, a nedostaje usporedbe ovih teorija. Predstavljamo veliku ljudsku procjenu dvije popularne gramatičke teorije, Matrix-Embedded jezika (ML) i ograničenja jednakosti (EC). Upoređujemo ih s tri heurističke modela i kvantitativno pokazujemo učinkovitost dvije gramatičke teorije.</abstract_hr>
      <abstract_nl>Codegemengde tekstgenereringssystemen hebben toepassingen gevonden in veel downstreamtaken, waaronder spraakherkenning, vertaling en dialoog. Een paradigma van deze generatiesystemen berust op goed gedefinieerde grammaticale theorieën van code-menging, en er is een gebrek aan vergelijking van deze theorieën. We presenteren een grootschalige menselijke evaluatie van twee populaire grammaticale theorieën, Matrix-Embedded Language (ML) en Equivalentie Constraint (EC). We vergelijken ze met drie heuristische modellen en tonen kwantitatief de effectiviteit van de twee grammaticale theorieën aan.</abstract_nl>
      <abstract_de>Code-Mixed-Text-Generierungssysteme haben Anwendungen in vielen nachgelagerten Aufgaben gefunden, einschließlich Spracherkennung, Übersetzung und Dialog. Ein Paradigma dieser Generationssysteme beruht auf klar definierten grammatikalischen Theorien der Codemischung, und es fehlt an einem Vergleich dieser Theorien. Wir präsentieren eine groß angelegte menschliche Bewertung von zwei populären grammatischen Theorien, Matrix-Embedded Language (ML) und Äquivalenz Constraint (EC). Wir vergleichen sie mit drei heuristisch basierten Modellen und demonstrieren quantitativ die Wirksamkeit der beiden grammatischen Theorien.</abstract_de>
      <abstract_fa>سیستم‌های تولید متن با کد پیدا کردند که کاربردها در بسیاری از کارهای پایین پایین پیدا کردند، شامل شناسایی سخنرانی، ترجمه و محاورۀ سخنرانی. یک پارادیگ از این سیستم‌های نسل به نظریه‌های گراماتیکی خوب تعریف شده از ترکیب کد بستگی دارد، و کمبود مقایسه از این نظریه‌ها وجود دارد. ما یک ارزیابی انسان بسیار بزرگ از دو نظریه گراماتیک مشهور، زبان متریکس (ML) و محدودیت برابری (EC) را پیشنهاد می‌کنیم. ما آنها را در مقایسه با سه مدل بر اساس هوریستیک مقایسه می کنیم و به اندازه کافی موثیت دو نظریه گراماتیک را نشان می دهیم.</abstract_fa>
      <abstract_sw>Mfumo wa uzalishaji wa simu za mkononi umechanganyika umepata matumizi katika kazi nyingi za miti, ikiwa ni pamoja na kutambua hotuba, tafsiri na mazungumzo. Mfumo wa kizazi hiki unategemea nadharia za ubora zinazoelezwa vizuri za mchanganyiko wa kodi, na kuna ukosefu wa kulinganisha nadharia hizi. We present a large-scale human evaluation of two popular grammatical theories, Matrix-Embedded Language (ML) and Equivalence Constraint (EC).  Tunawalinganisha dhidi ya mifano mitatu ya heuristi na kwa kiasi kikubwa tunaonyesha ufanisi wa nadharia hizo mbili za kiuchumi.</abstract_sw>
      <abstract_tr>Açmak üçin karıştırılýan metin döredilme sistemleri birnäçe netijesinde programler tapdy. Bu nesil sistemlerinin paradigmi gowy tanımlanmış gramatik karıştırma teoriýasyna dayanýar we bu teoriýalaryň karşılaştırmanyň ýetmesi ýok. Biz iki meýdança gramatik teoriýasy, Matrix-Edilmiş Dil Biz olaryň üç heuristik nusgalary bilen karşılaştyrýarys we iki gramatik teoriýanyň täsirini görkez.</abstract_tr>
      <abstract_ko>코드 혼합 텍스트 생성 시스템은 음성 인식, 번역, 대화를 포함한 많은 하위 작업에서 응용되었다.이러한 생성 시스템의 범례는 정의가 좋은 코드 혼합 문법 이론에 의존하고 이런 이론에 대한 비교가 부족하다.우리는 두 가지 유행하는 문법 이론인 매트릭스 삽입 언어(ML)와 등가 제약(EC)에 대해 대규모의 인류 평가를 실시했다.우리는 그것들을 세 가지 계발식 모델을 바탕으로 비교하고 이 두 가지 문법 이론의 유효성을 정량적으로 증명했다.</abstract_ko>
      <abstract_id>Sistem generasi teks kode-campuran telah menemukan aplikasi dalam banyak tugas turun, termasuk pengenalan pidato, terjemahan dan dialog. Sebuah paradigm a dari sistem generasi ini bergantung pada teori grammatik yang terdefinisikan dengan baik tentang campuran kode, dan ada kekurangan perbandingan teori-teori ini. We present a large-scale human evaluation of two popular grammatical theories, Matrix-Embedded Language (ML) and Equivalence Constraint (EC).  Kami membandingkan mereka dengan tiga model berdasarkan heuristik dan kuantitatif menunjukkan efektif dari dua teori grammatik.</abstract_id>
      <abstract_hy>Կոդի խառնված տեքստի ստեղծման համակարգերը գտել են ծրագրեր շատ հետագա աշխատանքներում, ներառյալ խոսքի ճանաչելը, թարգմանությունը և հաղորդագրությունը: Այս սերնդի համակարգերի պարադիգման հիմնված է կոդի խառնման լավ սահմանված գրամատիկական տեսությունների վրա, և այս տեսությունների համեմատության պակաս կա: Մենք ներկայացնում ենք երկու հայտնի գրամատիկական տեսությունների, Մատրիքսի ներգրավված լեզուների (ML) և հավասարության սահմանափակումների (ԵԿ) մարդկային մեծ գնահատումը: Մենք համեմատում ենք դրանք երեք հորիստիկ մոդելների հետ և քանակությամբ ցույց ենք տալիս երկու գրամատիկ տեսությունների արդյունավետությունը:</abstract_hy>
      <abstract_az>Kod-karışıqlı mətn nəzəriyyəti sistemləri çox aşağı-aşağı işlərdə proqramlar tapmışdır, danışma tanıması, tercümə və диалог içərisində. Bu nəsil sistemlərinin paradigmi yaxşı tanımlanmış còd karışması nəzəriyyələrinə bağlı və bu nəzəriyyətlərin karşılaşdırması yoxdur. Biz iki məşhur gramatik teorisi, Matrix-Embedded Language (ML) və Equivalence Constraint (EC) ilə böyük ölçülü insan değerlendirməsini göstəririk. Biz onları üç heuristik modellərlə qarşılaşdırırıq və kvantitatlı olarak iki grammatik teorislərin etkinliğini göstəririk.</abstract_az>
      <abstract_sq>Sistemet e krijimit të tekstit të përzier me kod kanë gjetur aplikime në shumë detyra poshtë, duke përfshirë njohjen e fjalës, përkthimin dhe dialogun. Një paradigm ë e këtyre sistemeve të gjeneratës mbështetet në teoritë grammatike të përziera të kodeve, dhe ka një mungesë krahasimi të këtyre teorive. Ne paraqesim një vlerësim njerëzor në shkallë të madhe të dy teorive grammatike popullore, gjuhën e integruar me Matrix (ML) dhe kufizimin e ekvivalencës (KE). Ne i krahasojmë ato me tre modele me bazë heuristike dhe në mënyrë kuantitative demonstrojmë efektshmërinë e dy teorive grammatike.</abstract_sq>
      <abstract_bn>কড- মিশ্রিত টেক্সট প্রজন্ম সিস্টেম অনেক নিচের কাজে অ্যাপলিকেশন পাওয়া গেছে, যার মধ্যে ভাষণ স্বীকৃতি, অনুবাদ এবং  এই প্রজন্ম সিস্টেমের একটি প্যারাডিম নির্ভর করে কোড মিশ্রিত গ্রাম্যাটিক্যাল ধারণার উপর এবং এই তত্ত্বাবধানের তুলনার অভাব রয়েছে। আমরা দুটি জনপ্রিয় গ্রামাটিক্স তত্ত্ব, ম্যাট্রিক্স-Embeded ভাষা (এমএল) এবং সমান কনস্ট্রেন্ট (ইসি) সম্পর্কে একটি বিশাল মানুষের মানুষ আমরা তিনটি হিউরিস্টিক ভিত্তিক মডেলের বিরুদ্ধে তুলনা করি এবং এই দুটি গ্রামাটিক্যাল থিওরিয়ার কার্যকর প্রদর্শন করি।</abstract_bn>
      <abstract_af>Name 'n paradigm van hierdie generasie stelsels is op goed gedefinieerde grammatiese teoriee van kode-gemenging, en daar is 'n mankaak van vergelyking van hierdie teoriee. Ons stel 'n groot-skaal menslike evaluering van twee populêre grammatiese teoriee, Matrix-inbetelde Taal (ML) en Equivalence Constraint (EC). Ons vergelyk hulle teen drie heuristiese-gebaseerde modele en kvantitatiewe wys die effektiviteit van die twee grammatiese teoriee.</abstract_af>
      <abstract_bs>Sistemi generacije teksta koji su pomiješani kod pronašli su aplikacije u mnogim zadacima, uključujući prepoznavanje govora, prevod i dijalog. Paradigma ovih generacijskih sustava se oslanja na dobro definirane gramatičke teorije miješanja koda, a nema usporedbe ovih teorija. Predstavljamo veliku ljudsku procjenu dvije popularne gramatičke teorije, Matrix-Embedded jezika (ML) i ograničenja ekvivalence (EC). Upoređujemo ih sa tri heurističke modela i kvantitativno pokazujemo učinkovitost dvije gramatičke teorije.</abstract_bs>
      <abstract_ca>Els sistemes de generació de textos combinats amb codis han trobat aplicacions en moltes tasques avall, incloent el reconeixement del discurs, la traducció i el diàleg. Un paradigm a d'aquests sistemes de generació es basa en teories gramàtiques ben definides de la combinació de codis, i hi ha una falta de comparació d'aquestes teories. Presentam una evaluació human a a gran escala de dues teories gramàtiques populars, la llengua incorporada en matrix (ML) i la restricció d'equivalença (EC). Els comparam amb tres models basats en heurístics i demostrem quantitativament l'eficacia de les dues teories gramàtiques.</abstract_ca>
      <abstract_cs>Systémy pro generování textu se smíšeným kódem našly aplikace v mnoha následných úkolech, včetně rozpoznávání řeči, překladu a dialogu. Paradigma těchto generačních systémů se opírá o dobře definované gramatické teorie míchání kódu a neexistuje srovnání těchto teorií. Představujeme rozsáhlé lidské hodnocení dvou populárních gramatických teorií, Matrix-Embedded Language (ML) a Equivalence Constraint (EC). Porovnáváme je se třemi heuristickými modely a kvantitativně demonstrujeme efektivitu obou gramatických teorií.</abstract_cs>
      <abstract_am>የጽሑፍ ትውልድ ስርዓት በተለየ የጽሑፍ ትውልድ ስርዓቶች በተጨማሪው ውጤቶች፣ ንግግር ማስታወቂያ፣ ትርጉም እና መdialog ውስጥ ብዙ ፕሮግራሞች ተገኝተዋል። A paradigm of these generation systems relies on well-defined grammatical theories of code-mixing, and there is a lack of comparison of these theories.  ሁለትም የግራማቲካዊ ተሪካ፣ ማትሪክስ-Embedded ቋንቋ (ML) እና ትክክል ድጋፍ (EC) በሚያሳየው የሰው ማስታወቂያ አቆይተናል፡፡ በሦስት ሀሪክኛ ምሳሌ እናሳያታለን እና በቁጥር የሁለቱን የግራማቲካዊ ጥያቄን እናሳያቸዋለን፡፡</abstract_am>
      <abstract_et>Koodidega segatud teksti genereerimise süsteemid on leidnud rakendusi paljudes järgnevates ülesannetes, sealhulgas kõnetuvastus, tõlkimine ja dialoog. Nende generatsioonisüsteemide paradigma tugineb hästi määratletud grammatilistele koodide segamise teooriatele ja nende võrdlemine puudub. Esitleme laiaulatuslikku inimlikku hinnangut kahele populaarsele grammatikateooriale, maatriksi-manustatud keelele (ML) ja ekvivalentsuspiirangule (EC). Me võrdleme neid kolme heuristilise mudeliga ja näitame kvantitatiivselt kahe grammatilise teooria efektiivsust.</abstract_et>
      <abstract_fi>Koodi-sekoitetut tekstintuotantojﾃ､rjestelmﾃ､t ovat lﾃｶytﾃ､neet sovelluksia moniin loppupﾃ､ﾃ､n tehtﾃ､viin, kuten puheentunnistukseen, kﾃ､ﾃ､ntﾃ､miseen ja vuoropuheluun. Nﾃ､iden sukupolvijﾃ､rjestelmien paradigma perustuu hyvin mﾃ､ﾃ､riteltyihin kieliopillisiin teorioihin koodien sekoittamisesta, ja nﾃ､itﾃ､ teorioita ei ole vertailtu keskenﾃ､ﾃ､n. Esitﾃ､mme laajamittaisen ihmisarvioinnin kahdesta suositusta kieliopillisesta teoriasta, Matrix-Embedded Language (ML) ja Equivalence Restraint (EC). Vertaamme niitﾃ､ kolmeen heuristiseen malliin ja osoitamme kvantitatiivisesti nﾃ､iden kahden kieliopillisen teorian tehokkuuden.</abstract_fi>
      <abstract_jv>Sistem Jejaring Teks Karo kode Jejaring Rasané sing sistem Generation iki dadi paling-uripé supoyata barang-urip kuwi kayalakno nyong, lan ora ono sampek karo perusahaan nyong theori iki. Awak dhéwé éntukno sistem barêng-kalang langgambar uwong ing nggawe gerarané iki populer gêrmatik, Matrix-embeded Language Awak dhéwé ngregani karo model sing basa gambaran karo telu heuristik lan nganggep kuwi kesempatan pisan neng pisan ngéwé kuwi banjuré dhéwé kuwi theori sing duwé.</abstract_jv>
      <abstract_ha>@ info: whatsthis Wata paradigm na'urar wannan zagon na'ura, yana dõgara ga teori mai kyau-defined grammatisk kode-blendin, kuma yana da ƙidãya ga misalin wannan zato. Tuna halatar da rabon mutum masu girma ga littafan biyu masu ƙarani, matrix-Emailed Lugha (ML) da Cikakci (EC). Munã samfane su a kan misalin misãlai uku na heuristic kuma ke nuna nufi'ar littafan biyu grammati.</abstract_ha>
      <abstract_sk>Sistemi za ustvarjanje besedila z mešanimi kodami so našli aplikacije pri številnih nadaljnjih nalogah, vključno s prepoznavanjem govora, prevajanjem in dialogom. Paradigma teh generacijskih sistemov temelji na dobro opredeljenih slovničnih teorijah mešanja kod, pri čemer je pomanjkanje primerjave teh teorij. Predstavljamo obsežno človeško vrednotenje dveh priljubljenih slovničnih teorij, matrično vgrajenega jezika (ML) in enakovredne omejitve (EC). Primerjamo jih s tremi heurističnimi modeli in kvantitativno dokazujemo učinkovitost obeh slovničnih teorij.</abstract_sk>
      <abstract_he>מערכות יוצרת טקסט מעורבות עם קוד מצאו שימושים במשימות רבות מתחתיות, כולל זיהוי נאום, תרגום ודיולוג. פרדיגמה של מערכות הדור הללו תלויה בתיאוריות גרמטיות מוגדרות היטב של מערבב קודים, ויש חוסר השוואה של התיאוריות הללו. אנחנו מציגים עריכה אנושית ברמה גדולה של שתי תאוריות גרמטיקות פופולריות, שפה מוקפת במטריקס (ML) ומגבלת שוויון (EC). אנחנו משוותים אותם עם שלושה דוגמנים מבוססים על היוריסטיקה ומוכיחים באופן כמוני את היעילות של שתי התיאוריות הגרמטיקות.</abstract_he>
      <abstract_bo>འོག་གྲངས་ཀྱི་ལས་འགུལ་ལ་མང་པོ་ནང་དུ་ཉེར་སྤྱོད་རིགས་འདུག སྔོན་གྱི་མ་ལག་གི་ཕྱོགས་སྣང་བ་དེ་དག་གིས་དམིགས་འཛུགས་ཀྱི་རྣམ་པ་ལྟར་འཛིན་པའི་གྲངས་སྒྲིག་འགོད་དང་མཐུན་སྒྲིག ང་ཚོས་རྒྱུན་ལྡན་གྱི་དཔེ་རིགས་གཉིས་ཀྱི་ཆོས་ཉིད་ཅིག་གི་ཚད་ལྡན་ཆེ་བའི་མི་རིམ་པ་ཞིག་སྟོན་ཡོད། ང་ཚོས་དེ་དག་གི་རྩིས་བ་གཞི་གཞི་རྩིས་ཅན་གྱི་ཐབས་ལམ་གསུམ་དང་གྲངས་འབྲེལ་བ་དེ་གི་གྲངས་འབྲེལ་གྱི་དཔོན་རིམ་གཉིས་ཀྱི་ལྕ</abstract_bo>
      </paper>
    <paper id="21">
      <title>Mitigation of Diachronic Bias in Fake News Detection Dataset</title>
      <author><first>Taichi</first><last>Murayama</last></author>
      <author><first>Shoko</first><last>Wakamiya</last></author>
      <author><first>Eiji</first><last>Aramaki</last></author>
      <pages>182–188</pages>
      <abstract>Fake news causes significant damage to society. To deal with these <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>, several studies on building detection models and arranging datasets have been conducted. Most of the fake news datasets depend on a specific time period. Consequently, the detection models trained on such a dataset have difficulty detecting novel <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> generated by political changes and social changes ; they may possibly result in biased output from the input, including specific person names and organizational names. We refer to this problem as Diachronic Bias because it is caused by the creation date of news in each dataset. In this study, we confirm the <a href="https://en.wikipedia.org/wiki/Bias">bias</a>, especially <a href="https://en.wikipedia.org/wiki/Proper_noun">proper nouns</a> including <a href="https://en.wikipedia.org/wiki/Personal_name">person names</a>, from the deviation of phrase appearances in each dataset. Based on these findings, we propose masking methods using <a href="https://en.wikipedia.org/wiki/Wikidata">Wikidata</a> to mitigate the influence of person names and validate whether they make fake news detection models robust through experiments with in-domain and out-of-domain data.</abstract>
      <url hash="6b3d5998">2021.wnut-1.21</url>
      <bibkey>murayama-etal-2021-mitigation</bibkey>
      <doi>10.18653/v1/2021.wnut-1.21</doi>
    <title_ar>التخفيف من التحيز غير المتزامن في مجموعة بيانات الكشف عن الأخبار المزيفة</title_ar>
      <title_pt>Mitigação do viés diacrônico no conjunto de dados de detecção de notícias falsas</title_pt>
      <title_fr>Atténuation du biais diachronique dans l'ensemble de données de détection des fausses nouvelles</title_fr>
      <title_es>Mitigación del sesgo diacrónico en el conjunto de datos de detección de noticias</title_es>
      <title_ja>フェイクニュース検出データセットにおけるダイアクロニックバイアスの緩和</title_ja>
      <title_zh>假新闻检数集历偏差之解</title_zh>
      <title_hi>नकली समाचार का पता लगाने डेटासेट में Diachronic पूर्वाग्रह का शमन</title_hi>
      <title_ru>Смягчение диахронической систематической ошибки в наборе данных обнаружения фейковых новостей</title_ru>
      <title_ga>Laofacht Dhiachrónach a Mhaolú i Thacar Sonraí Braite Nuachta Bréige</title_ga>
      <title_ka>Name</title_ka>
      <title_it>Mitigazione delle bias diacroniche nel set di dati di rilevamento di notizie false</title_it>
      <title_el>Μείωση των διαχρονικών προκαταλήψεων στο σύνολο δεδομένων ανίχνευσης πλαστών ειδήσεων</title_el>
      <title_hu>Diakrónikus Bias enyhítése hamis hírek detektálási adatokban</title_hu>
      <title_lt>Diachroninių kliūčių mažinimas suklastotų naujienų aptikimo duomenų rinkinyje</title_lt>
      <title_mk>Намалување на дијахроничните навреди во датотеката за детектирање лажни вести</title_mk>
      <title_ml>ഫെയിക്ക് വാര്‍ത്തകള്‍ ഡേറ്റാറ്റീസറില്‍ ഡയക്രോണിക് ബിയാസിന്റെ ക്രമീകരണം</title_ml>
      <title_kk>Жаңалықтарды анықтау деректерінде диагроникалық бөлшектерді шектеу</title_kk>
      <title_ms>Penyelamatan Bias Diakronik dalam Set Data Pengesan Berita Salah</title_ms>
      <title_mt>It-tnaqqis tal-ħsara dijakronika fid-Dataset tad-Detezzjoni tal-Aħbarijiet Falsi</title_mt>
      <title_no>Name</title_no>
      <title_pl>Łagodzenie diachronicznych uprzedzeń w zestawie danych o wykrywaniu fałszywych wiadomości</title_pl>
      <title_ro>Atenuarea bolilor diacronice în setul de date de detectare a știrilor false</title_ro>
      <title_sr>Минигација диагронических бија у данатису фалшивих новина</title_sr>
      <title_so>Mitigation of diakronic Bias in lagu sameeyo macluumaad baabuur ah</title_so>
      <title_sv>Minskning av diakronisk bias i falska nyhetsdetekteringsdataset</title_sv>
      <title_mn>Хуудлын мэдээллийн мэдээллийн мэдээллийн газрын биасын төвшин</title_mn>
      <title_ta>போலி செய்தி கண்டுபிடிப்பு தகவல் அமைப்பில் உள்ள டையாக்ரோனிக் பையாஸ் குறைக்கும்</title_ta>
      <title_si>Name</title_si>
      <title_ur>افسوس خبریں شناسایی ڈاٹیسٹ میں دیاگرنیک بیوں کی پیدائش</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Kiểm tra tiêu cực của Diamãn Con trong bộ xử lý tin giả</title_vi>
      <title_nl>Vermindering van diachrone bias in nepnieuws detectie dataset</title_nl>
      <title_da>Mindskelse af diakronisk bias i falske nyheder detektion datasæt</title_da>
      <title_hr>Smanjivanje dijagroničkih bija u podacima za otkrivanje lažnih vijesti</title_hr>
      <title_de>Reduzierung von diachronen Bias in Fake News Detection Dataset</title_de>
      <title_bg>Намаляване на диахроничните наклонности в набора от данни за откриване на фалшиви новини</title_bg>
      <title_id>Melawankan kekacauan diakronis dalam dataset deteksi berita palsu</title_id>
      <title_fa>Name</title_fa>
      <title_sw>Kudhibiti Bias katika Taarifa za Kugundua Habari za Udanganyiko</title_sw>
      <title_tr>Kesgen Jaňlar Aňlamak Maglumatynyň Däşemeleri</title_tr>
      <title_ko>허위 뉴스 검측 데이터 집중 시간 편차 완화</title_ko>
      <title_sq>Mjaftimi i ngatërresave diakronike në bazën e të dhënave për zbulimin e lajmeve të rreme</title_sq>
      <title_af>Name</title_af>
      <title_am>ፋይል sን መክፈት አልቻለም፦ %s፦ %s</title_am>
      <title_hy>Դիախրոնիկ շեղումների նվազեցնելը կեղծ նորությունների հայտնաբերման տվյալների համակարգում</title_hy>
      <title_bn>ফ্যাক সংবাদ তথ্য সনাক্তির তথ্যের মধ্যে ডায়ারোনিক বায়াসের মাইকেট</title_bn>
      <title_bs>Smanjivanje dijagroničkih bija u podacima za lažne novine</title_bs>
      <title_az>YaxŇüńĪ Haber TapńĪlmasńĪ veril…ônl…ôrind…ô Diakronisk Bias-l…ôrin birl…ôŇüdirilm…ôsi</title_az>
      <title_ca>Mitigation of Diachronic Bias in False News Detection Dataset</title_ca>
      <title_cs>Zmírnění diachronických předsudků v databázi detekce falešných zpráv</title_cs>
      <title_fi>Diakroonisten harhaluulojen lieventäminen fake news detection datasetissä</title_fi>
      <title_et>Diakrooniliste kallakute leevendamine valeuudiste tuvastamise andmekogumis</title_et>
      <title_he>להקל את הבעיה הדיאכרונית בתוכנית נתונים לגילוי חדשות מזויפות</title_he>
      <title_jv>mitigation of diahroc Bias in Fake Info detection dataset</title_jv>
      <title_sk>Blažitev diakroničnih pristranskosti v naboru podatkov o odkrivanju lažnih novic</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>འོད་མེད་པའི་བརྡ་འཕྲིན་བཙལ་བཤེར་གྱི་བྱ་སྤྱོད་ཀྱི་འགྲེལ་བཤད་ཀྱི་སྒྲ་སྐད</title_bo>
      <abstract_es>Las noticias falsas causan un daño significativo a la sociedad. Para hacer frente a estas noticias falsas, se han realizado varios estudios sobre la creación de modelos de detección y la organización de conjuntos de datos. La mayoría de los conjuntos de datos de noticias falsas dependen de un período de tiempo específico. En consecuencia, los modelos de detección entrenados en un conjunto de datos de este tipo tienen dificultades para detectar nuevas noticias falsas generadas por cambios políticos y sociales; posiblemente den como resultado resultados sesgados de la entrada, incluidos nombres de personas específicas y nombres de organizaciones. Nos referimos a este problema como sesgo diacrónico porque es causado por la fecha de creación de las noticias en cada conjunto de datos. En este estudio, confirmamos el sesgo, especialmente los sustantivos propios, incluidos los nombres de personas, de la desviación de la aparición de frases en cada conjunto de datos. Basándonos en estos hallazgos, proponemos métodos de enmascaramiento que utilizan Wikidata para mitigar la influencia de los nombres de las personas y validar si hacen que los modelos de detección de noticias falsas sean robustos mediante experimentos con datos dentro y fuera del dominio.</abstract_es>
      <abstract_fr>Les fausses nouvelles causent des dommages importants à la société. Pour faire face à ces fausses nouvelles, plusieurs études sur les modèles de détection des bâtiments et l'organisation des ensembles de données ont été menées. La plupart des ensembles de données sur les fausses informations dépendent d'une période spécifique. Par conséquent, les modèles de détection formés sur un tel ensemble de données ont du mal à détecter de nouvelles fausses nouvelles générées par des changements politiques et sociaux ; ils peuvent éventuellement entraîner une sortie biaisée à partir de l'entrée, y compris des noms de personnes spécifiques et des noms d'organisations. Nous appelons ce problème le biais diachronique car il est causé par la date de création des actualités dans chaque jeu de données. Dans cette étude, nous confirmons le biais, en particulier les noms propres, y compris les noms de personnes, par rapport à la déviation de l'apparence des phrases dans chaque ensemble de données. Sur la base de ces résultats, nous proposons des méthodes de masquage utilisant Wikidata pour atténuer l'influence des noms de personnes et valider s'ils rendent les modèles de détection des fausses nouvelles robustes grâce à des expériences avec des données dans le domaine et hors domaine.</abstract_fr>
      <abstract_pt>As notícias falsas causam danos significativos à sociedade. Para lidar com essas notícias falsas, vários estudos sobre construção de modelos de detecção e organização de conjuntos de dados foram realizados. A maioria dos conjuntos de dados de notícias falsas depende de um período de tempo específico. Consequentemente, os modelos de detecção treinados em tal conjunto de dados têm dificuldade em detectar novas notícias falsas geradas por mudanças políticas e sociais; eles podem resultar em saídas tendenciosas da entrada, incluindo nomes de pessoas específicas e nomes de organizações. Chamamos esse problema de Viés Diacrônico porque é causado pela data de criação das notícias em cada conjunto de dados. Neste estudo, confirmamos o viés, especialmente nomes próprios incluindo nomes de pessoas, do desvio de aparências de frases em cada conjunto de dados. Com base nessas descobertas, propomos métodos de mascaramento usando o Wikidata para mitigar a influência de nomes de pessoas e validar se eles tornam robustos os modelos de detecção de notícias falsas por meio de experimentos com dados no domínio e fora do domínio.</abstract_pt>
      <abstract_ar>الأخبار الكاذبة تسبب ضررا كبيرا للمجتمع. للتعامل مع هذه الأخبار الكاذبة ، تم إجراء العديد من الدراسات حول بناء نماذج الكشف وترتيب مجموعات البيانات. تعتمد معظم مجموعات بيانات الأخبار المزيفة على فترة زمنية محددة. وبالتالي ، فإن نماذج الكشف المدربة على مجموعة البيانات هذه تواجه صعوبة في اكتشاف الأخبار المزيفة الجديدة الناتجة عن التغيرات السياسية والتغيرات الاجتماعية ؛ قد تؤدي إلى إخراج متحيز من المدخلات ، بما في ذلك أسماء الأشخاص المعينين والأسماء التنظيمية. نشير إلى هذه المشكلة على أنها انحياز زمني لأنها ناتجة عن تاريخ إنشاء الأخبار في كل مجموعة بيانات. في هذه الدراسة ، نؤكد التحيز ، وخاصة أسماء العلم بما في ذلك أسماء الأشخاص ، من انحراف ظهور العبارات في كل مجموعة بيانات. بناءً على هذه النتائج ، نقترح طرق إخفاء باستخدام ويكي بيانات للتخفيف من تأثير أسماء الأشخاص والتحقق مما إذا كانت تجعل نماذج اكتشاف الأخبار المزيفة قوية من خلال التجارب مع البيانات داخل المجال وخارج النطاق.</abstract_ar>
      <abstract_zh>假新闻大损于世。 为此假新闻,已行几项构检模形,置数集焉。 多假新闻数集决于特定之时间段。 故其数集上难检出由政化之所生也新假新闻; 其或输输有差,特定人名伍。 余谓此为Diachronic Bias,盖数集新闻创日也。 于此论之,证每数集短语外观偏差,特为专有名词,兼人名也。 发其维基数以轻人名之屏蔽,验其对域内域外之数实验使假新闻检而强之。</abstract_zh>
      <abstract_hi>नकली समाचार समाज को महत्वपूर्ण नुकसान पहुंचाते हैं। इन नकली खबरों से निपटने के लिए, पहचान मॉडल बनाने और डेटासेट की व्यवस्था करने पर कई अध्ययन किए गए हैं। अधिकांश नकली समाचार डेटासेट एक विशिष्ट समय अवधि पर निर्भर करते हैं। नतीजतन, इस तरह के डेटासेट पर प्रशिक्षित डिटेक्शन मॉडल को राजनीतिक परिवर्तनों और सामाजिक परिवर्तनों द्वारा उत्पन्न उपन्यास नकली समाचारों का पता लगाने में कठिनाई होती है; वे संभवतः इनपुट से पक्षपाती आउटपुट में परिणाम कर सकते हैं, जिसमें विशिष्ट व्यक्ति के नाम और संगठनात्मक नाम शामिल हैं। हम इस समस्या को डायक्रोनिक पूर्वाग्रह के रूप में संदर्भित करते हैं क्योंकि यह प्रत्येक डेटासेट में समाचार की निर्माण तिथि के कारण होता है। इस अध्ययन में, हम पूर्वाग्रह की पुष्टि करते हैं, विशेष रूप से प्रत्येक डेटासेट में वाक्यांश दिखावे के विचलन से व्यक्ति के नाम सहित उचित संज्ञाएं। इन निष्कर्षों के आधार पर, हम व्यक्ति के नामों के प्रभाव को कम करने के लिए विकिडेटा का उपयोग करके मास्किंग विधियों का प्रस्ताव करते हैं और यह सत्यापित करते हैं कि क्या वे इन-डोमेन और आउट-ऑफ-डोमेन डेटा के साथ प्रयोगों के माध्यम से नकली समाचार का पता लगाने वाले मॉडल को मजबूत बनाते हैं।</abstract_hi>
      <abstract_ja>フェイクニュースは社会に大きな被害をもたらす。これらのフェイクニュースに対処するために、検出モデルの構築とデータセットの配置に関するいくつかの研究が行われている。フェイクニュースデータセットのほとんどは、特定の期間に依存します。したがって、そのようなデータセットでトレーニングされた検出モデルは、政治的変化および社会的変化によって生成された新規のフェイクニュースを検出することが困難であり、特定の人名および組織名を含む入力からの偏った出力をもたらす可能性があります。この問題は、各データセット内のニュースの作成日によって生じるため、Diachronic Biasと呼びます。この研究では、各データセットのフレーズの表示の逸脱からのバイアス、特に人名を含む固有名詞を確認します。これらの知見を踏まえ、ウィキデータを用いたマスキング手法を提案し、個人名の影響を緩和し、ドメイン内およびドメイン外データの実験を通じてフェイクニュース検出モデルを堅牢にするかどうかを検証する。</abstract_ja>
      <abstract_ru>Фейковые новости наносят значительный ущерб обществу. Для борьбы с этими фейковыми новостями было проведено несколько исследований по построению моделей обнаружения и упорядочению наборов данных. Большинство наборов данных фейковых новостей зависят от конкретного периода времени. Следовательно, модели обнаружения, обученные на таком наборе данных, испытывают трудности с обнаружением новых фейковых новостей, генерируемых политическими и социальными изменениями; они могут приводить к необъективному выходу из входных данных, включая имена конкретных лиц и названия организаций. Мы называем эту проблему диахронической систематической ошибкой, потому что она вызвана датой создания новостей в каждом наборе данных. В этом исследовании мы подтверждаем смещение, особенно собственные существительные, включая имена лиц, от отклонения появления фраз в каждом наборе данных. Основываясь на этих выводах, мы предлагаем методы маскировки с использованием Викидата, чтобы смягчить влияние имен людей и проверить, делают ли они модели обнаружения фальшивых новостей надежными посредством экспериментов с внутридоменными и внедоменными данными.</abstract_ru>
      <abstract_ga>Déanann nuacht falsa damáiste suntasach don tsochaí. Chun déileáil leis an nuacht bhréige seo, rinneadh roinnt staidéar ar mhúnlaí braite a thógáil agus ar thacair sonraí a shocrú. Braitheann an chuid is mó de na tacair sonraí nuachta bréige ar thréimhse ama ar leith. Mar thoradh air sin, bíonn deacracht ag na samhlacha braite atá oilte ar thacar sonraí den sórt sin nuacht bhréige úrnua a thagann as athruithe polaitiúla agus athruithe sóisialta a bhrath; d’fhéadfadh go mbeadh aschur claonta ón ionchur dá bharr, lena n-áirítear ainmneacha daoine sonracha agus ainmneacha eagraíochtúla. Déanaimid tagairt don fhadhb seo mar Laofacht Dhiachrónach toisc gur dáta cruthaithe nuachta i ngach tacar sonraí is cúis leis. Sa staidéar seo, deimhnímid an claonadh, go háirithe ainmfhocail chearta lena n-áirítear ainmneacha daoine, ón imeacht ó chuma frásaí i ngach tacar sonraí. Bunaithe ar na torthaí seo, molaimid modhanna cumhdaigh a úsáideann Wikidata chun tionchar ainmneacha daoine a mhaolú agus chun a bhailíochtú an ndéanann siad samhlacha braite nuachta bréige láidir trí thurgnaimh le sonraí laistigh agus lasmuigh den fhearann.</abstract_ga>
      <abstract_el>Τα ψεύτικα νέα προκαλούν σημαντική ζημιά στην κοινωνία. Για να αντιμετωπιστούν αυτές οι ψεύτικες ειδήσεις, έχουν διεξαχθεί αρκετές μελέτες για την κατασκευή μοντέλων ανίχνευσης και την οργάνωση συνόλων δεδομένων. Τα περισσότερα από τα σύνολα δεδομένων ψεύτικων ειδήσεων εξαρτώνται από μια συγκεκριμένη χρονική περίοδο. Κατά συνέπεια, τα μοντέλα ανίχνευσης που εκπαιδεύονται σε ένα τέτοιο σύνολο δεδομένων δυσκολεύονται να εντοπίσουν νέες ψεύτικες ειδήσεις που παράγονται από πολιτικές αλλαγές και κοινωνικές αλλαγές. μπορεί ενδεχομένως να οδηγήσουν σε προκατειλημμένη παραγωγή από την εισαγωγή, συμπεριλαμβανομένων συγκεκριμένων ονομάτων προσώπων και ονομάτων οργανώσεων. Αναφερόμαστε σε αυτό το πρόβλημα ως διαχρονική προκατάληψη επειδή προκαλείται από την ημερομηνία δημιουργίας των ειδήσεων σε κάθε σύνολο δεδομένων. Στην παρούσα μελέτη επιβεβαιώνουμε την προκατάληψη, ειδικά τα ίδια ουσιαστικά συμπεριλαμβανομένων των ονομάτων προσώπων, από την απόκλιση των εμφανίσεων φράσεων σε κάθε σύνολο δεδομένων. Με βάση αυτά τα ευρήματα, προτείνουμε μεθόδους απόκρυψης που χρησιμοποιούν για να μετριάσουν την επιρροή των ονομάτων προσώπων και να επικυρώσουν αν κάνουν τα μοντέλα ανίχνευσης ψεύτικων ειδήσεων ανθεκτικά μέσα από πειράματα με δεδομένα εντός και εκτός τομέα.</abstract_el>
      <abstract_ka>ლყზნთ ნჲგთნთ ოპთფთრარ მნჲდჲ სškoრვნთწ ნა ჟჲბღვჟრგჲრჲ. ამ ტალქტური ნუტაციების შესახებ, რამდენიმე მოდელების შესახებ და მონაცემების შესახებ გავაკეთებულია. ძალიან ძალიან ახალი მონაცემების უფრო მეტი განსაზღვრებული დრო პერიოდიდან დააყენება. შემდეგ მოდელები, რომლებიც ასეთი მონაცემების კონფიგურაციაში განახლებული მოდელები, შეუძლებელია განახლება პოლიტიკური ცვლილებებით და სოციალური ცვლილებებით შექმნა შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება შეიძლება ჩვენ ამის პრობლემა ვიყენებთ როგორც დიაჰრონიკური ბია, რადგან ის მოქმედება ყველა მონაცემების თარიღის შექმნა. ამ კვლევაში, ჩვენ დარწმუნეთ წარმოდგენება, განსაკუთრებით მსგავსი სახელი, რომელიც ადამიანის სახელიდან, ყველა მონაცემების წარმოდგენება. ამ მონაცემების ბაზაზე, ჩვენ მინდომებით გავაკეთებთ მაქსინური მეტოვები, რომელიც გამოყენება ვიკიდეტატის გამოყენება, რომ გავაკეთებთ ადამიანის სახელების და გავაკეთებთ თუ ისინი გავაკეთებენ ტალქტიურ</abstract_ka>
      <abstract_hu>A hamis hírek jelentős károkat okoznak a társadalomnak. A hamis hírek kezelése érdekében számos tanulmányt végeztek az építési modellek építéséről és az adatkészletek rendezéséről. A legtöbb hamis hír adatkészlet egy adott időtartamtól függ. Következésképpen az ilyen adatkészletre képzett detektálási modellek nehézségeket okoznak a politikai változások és társadalmi változások által keltett új hamis hírek felismerésének; esetleg elfogult kimenetet eredményezhetnek a bemenetből, beleértve a meghatározott személyek nevét és szervezeti nevét is. Ezt a problémát Diakrónikus Biasnak nevezzük, mert azt az okozza, hogy az egyes adatokban a hírek létrehozásának dátuma. Ebben a tanulmányban megerősítjük az elfogultságot, különösen a saját főneveket, beleértve a személyek nevét is, az egyes adatokban a kifejezések megjelenésének eltérésétől. Ezen eredmények alapján a Wikidata álcázási módszereket javasoljuk, hogy enyhítsék a személyek neveinek hatását, és ellenőrizzék, hogy a hamis hírek észlelési modelleket robusztussá tegyék-e a domain belüli és a domain kívüli adatokkal végzett kísérletek révén.</abstract_hu>
      <abstract_lt>Klaidingos žinios daro didelę žalą visuomenei. To deal with these fake news, several studies on building detection models and arranging datasets have been conducted.  Dauguma suklastotų naujienų duomenų rinkinių priklauso nuo tam tikro laiko. Todėl tokiu duomenų rinkiniu parengti nustatymo modeliai turi sunkumų nustatyti naujų suklastotų žinių, atsiradusių dėl politinių pokyčių ir socialinių pokyčių; jie gali sukelti nešališką išėjimą iš įrašo, įskaitant konkrečių asmenų pavadinimus ir organizacinius pavadinimus. Šią problem ą vadiname Diachroniška kliūtimi, nes ją sukelia žinių sukūrimo data kiekviename duomenų rinkinyje. Šiame tyrime patvirtiname, kad kiekviename duomenų rinkinyje esančios frazės išvaizdos nukrypsta, ypač tinkami vardai, įskaitant asmens vardus. Remiantis šiais duomenimis, siūlome paslėpti Wikidata metodus asmenų vardų įtakai sušvelninti ir patvirtinti, ar jie užtikrina, kad suklastotų naujienų aptikimo modeliai būtų patikimi atliekant eksperimentus su domeniniais ir ne domeniniais duomenimis.</abstract_lt>
      <abstract_mk>Лажните вести предизвикуваат значителна штета на општеството. За да се справат со овие лажни вести, се спроведени неколку студии за изградба на модели за детекција и организација на податоци. Повеќето лажни новински податоци зависат од одреден временски период. Поради тоа, детективните модели обучени на ваков податок имаат тешкотии да откријат нови лажни вести генерирани од политичките промени и социјалните промени; тие можат да резултираат со предрасудени излези од внесувањето, вклучувајќи ги и специфичните имиња на личностите и организациските имиња. Ние го нарекуваме овој проблем Дијахроничен бес бидејќи е предизвикан од датумот на создавање на вести во секој податок. In this study, we confirm the bias, especially proper nouns including person names, from the deviation of phrase appearances in each dataset.  На основа на овие откритија, предложуваме методи за маскирање со користење на Викидата за намалување на влијанието на имињата на личностите и потврдување дали тие прават лажни новински детективни модели силни преку експерименти со податоци во домен и надвор од домен.</abstract_mk>
      <abstract_it>Le notizie false causano danni significativi alla società. Per affrontare queste fake news, sono stati condotti diversi studi sui modelli di rilevamento della costruzione e sull'organizzazione di set di dati. La maggior parte dei set di dati delle fake news dipendono da un periodo di tempo specifico. Di conseguenza, i modelli di rilevamento formati su tale set di dati hanno difficoltà a rilevare nuove fake news generate da cambiamenti politici e cambiamenti sociali; possono eventualmente risultare in output parziali dall'input, inclusi nomi di persone specifiche e nomi organizzativi. Ci riferiamo a questo problema come Bias diacronica perché è causato dalla data di creazione delle notizie in ogni set di dati. In questo studio, confermiamo il bias, in particolare i sostantivi propri compresi i nomi delle persone, dalla deviazione delle apparizioni delle frasi in ogni set di dati. Sulla base di questi risultati, proponiamo metodi di mascheramento che utilizzano Wikidata per mitigare l'influenza dei nomi delle persone e convalidare se rendono solidi i modelli di rilevamento delle fake news attraverso esperimenti con dati in-domain e fuori-domain.</abstract_it>
      <abstract_kk>Жалғыз жаңалықтар қоғамдылыққа маңызды қиындықтар. Бұл жалғыз жаңалықтарды бірнеше зерттеу үшін анықтау үлгілері мен деректер жинақтау бағдарламалары жасалған. Жалғасты жаңалық деректер жиындарының көпшілігі керек уақыт кезіне тәуелді. Сондықтан бұл деректер қорларында оқыту үлгілері саяси өзгерістер мен әлеуметтік өзгерістер бойынша жалғыз жаңалықтарды анықтау қиын болды. Олар келтірілген келтірілген нәтижелердің атауын және бағдарламалық атауларын қоса алады. Біз бұл мәселеді диахроникалық биас деп қалаймыз, себебі ол әрбір деректер қорларында жаңалықтар күні құрылған. Бұл зерттеулерде, әрбір деректер қорларындағы сөздердің ауыстыруынан, өзінде адамдардың атауларынан, өзінде дұрыс сөздерді құптаймыз. Бұл тапсырмалардың негізінде, біз Викидеректерді қолдану арқылы адамдардың атауларының әсерін азайту үшін, олар доменге және доменге тыс деректермен тәжірибелер арқылы жалғыз жаңалық анықтау үлгілерін табу үлгі</abstract_kk>
      <abstract_mt>Fake news causes significant damage to society.  To deal with these fake news, several studies on building detection models and arranging datasets have been conducted.  Il-biċċa l-kbira tad-datasets tal-a ħbarijiet foloz jiddependu fuq perjodu ta’ żmien speċifiku. Consequently, the detection models trained on such a dataset have difficulty detecting novel fake news generated by political changes and social changes;  jistgħu possibbilment jirriżultaw f’output biased mill-input, inklużi ismijiet speċifiċi ta’ persuni u ismijiet organizzattivi. Aħna nirreferu għal din il-problema bħala Bias Dijakroniku għaliex hija kkawżata mid-data tal-ħolqien tal-aħbarijiet f’kull sett ta’ dejta. F’dan l-istudju, nikkonfermaw il-preġudizzju, speċjalment ismijiet xierqa inklużi ismijiet ta’ persuni, mid-devjazzjoni tad-dehra tal-frażi f’kull sett ta’ dejta. Abbażi ta' dawn is-sejbiet, qed nipproponu metodi ta' masking bl-użu ta' Wikidata biex itaffu l-influwenza tal-ismijiet tal-persuni u jivvalidaw jekk jagħmlux mudelli ta' individwazzjoni tal-aħbarijiet foloz robusti permezz ta' esperimenti b'dejta f'dominju u barra d-dominju.</abstract_mt>
      <abstract_ms>Fake news causes significant damage to society.  Untuk menangani berita palsu ini, beberapa kajian tentang membina model pengesan dan mengatur set data telah dilakukan. Kebanyakan set data berita palsu bergantung pada masa tertentu. Oleh itu, model pengesan yang dilatih pada set data seperti ini mempunyai kesulitan mengesan berita palsu novel yang dijana oleh perubahan politik dan perubahan sosial; ia mungkin menghasilkan output bias dari input, termasuk nama orang tertentu dan nama organisasi. Kami merujuk kepada masalah ini sebagai Bias Diakronik kerana ia disebabkan oleh tarikh penciptaan berita dalam setiap set data. Dalam kajian ini, kami mengesahkan bias, terutama nama yang betul termasuk nama orang, dari penyelesaian penampilan frasa dalam setiap set data. Berdasarkan penemuan ini, kami cadangkan kaedah topeng menggunakan Wikidata untuk mengurangi pengaruh nama orang dan sahkan sama ada mereka membuat model pengesan berita palsu kuat melalui eksperimen dengan data dalam domain dan luar domain.</abstract_ms>
      <abstract_no>Falske nyhetar fører til signifikante skade til samfunnet. For å handtera disse falske nyhetane, har fleire studiar om oppdagingsmodeller og datasett er utført. Dei fleste falske nyhetsinnstillingane avhengig av ein spesifikke tidspunkt. Det er derfor vanskeleg å finna nyhetar som er laga av politiske endringar og sosiale endringar i oppdagingsmodellen som er trengte på slike dataset. dei kan kanskje føre til utskrift frå inndata, inkludert spesifikke personnamn og organisasjonsnamn. Vi refererer til dette problemet som Diachronic Bias fordi det er forårsaket av opprettingsdatoen av nyhetar i kvar datasett. I denne studien stadfestar vi forsvinninga, spesielt rette namn inkludert personnamn, frå avviklinga av frasene i kvar datasett. Basert på disse finningane, foreslår vi maskeringsmetodar med Wikidata for å redusera påvirkninga av personnamn og validera om dei gjer falske informasjonsoppdagingsmodeller sterkt gjennom eksperimenter med i-domene og ut-domenedata.</abstract_no>
      <abstract_mn>Хуудлалтай мэдээ нийгэмд маш чухал нөлөөлдөг. Эдгээр хуурамч мэдээллийг зохицуулахын тулд олон судалгаанууд мэдээллийн загвар бүтээх, өгөгдлийн санг зохицуулахын тулд хийгдсэн. Ихэнх хуурамч мэдээлэл өгөгдлийн сангууд тодорхой цаг хугацаанд хамааралтай. Үүнээс улс төрийн өөрчлөлт болон нийгмийн өөрчлөлт үүсгэсэн шинэ шинэ мэдээг олох хэцүү байдаг. Нэг хүний нэр болон байгууллагын нэр бүрдүүлж болох боломжтой. Бид энэ асуудлыг Диахроник Биас гэж нэрлэдэг. Учир нь энэ нь өгөгдлийн сангийн бүх мэдээллийн үеэс үүсгэсэн үед. Энэ судалгаанд бид өгөгдлийн санд харагдах хэлбэрээс ялангуяа зөв нэрлүүдийг баталдаг. Эдгээр ололтуудын үндсэнд бид Wikidata-ыг ашиглаж, хүмүүсийн нэрлүүдийн нөлөөг багасгаж, худлаа мэдээллийн шийдвэрлэх загваруудыг тодорхойлох боломжтой туршилтаар шийдвэрлэх арга загварыг санал болгож байна.</abstract_mn>
      <abstract_pl>Fałszywe wiadomości powodują poważne szkody społeczeństwu. Aby poradzić sobie z tymi fałszywymi wiadomościami, przeprowadzono kilka badań nad budową modeli detekcji i aranżacją zbiorów danych. Większość zbiorów danych fałszywych wiadomości zależy od określonego okresu czasu. W konsekwencji modele wykrywania przeszkolone na takim zbiorze danych mają trudności z wykrywaniem nowych fałszywych wiadomości generowanych przez zmiany polityczne i zmiany społeczne; mogą prowadzić do stronniczego wyjścia z danych wejściowych, w tym określonych nazwisk osób i nazwisk organizacyjnych. Nazywamy ten problem Diachronicznym Biasem, ponieważ jest on spowodowany datą tworzenia wiadomości w każdym zbiorze danych. W niniejszym badaniu potwierdzamy stronniczość, w szczególności rzeczowników właściwych, w tym imion osób, od odchylenia wyglądu fraz w każdym zbiorze danych. Na podstawie tych ustaleń proponujemy metody maskowania wykorzystujące Wikidane, aby złagodzić wpływ nazwisk osób i sprawdzić, czy modele wykrywania fałszywych wiadomości są solidne poprzez eksperymenty z danymi wewnątrz domeny i poza domeną.</abstract_pl>
      <abstract_ml>കള്ള വാര്‍ത്തകള്‍ സമൂഹത്തിന് വലിയ നഷ്ടമാണ്. ഈ കള്ള വാര്‍ത്തകളുമായി കൈകാര്യം ചെയ്യാന്‍, ഡേറ്റാസറ്റുകള്‍ നിര്‍മ്മിക്കുന്നതിനെപ്പറ്റി പല പഠനങ്ങളും നടപ് പ്രത്യേക സമയത്തിന്റെ പ്രത്യേക സമയത്തില്‍ മുഴുവന്‍ തെറ്റായ വാര്‍ത്ത വിവരങ്ങളുടെ ഡാറ്റാസറ്റു അതുകൊണ്ട്, ഇതുപോലുള്ള ഡാറ്റാസറ്റില്‍ പരിശീലിക്കപ്പെട്ട മോഡലുകള്‍ രാഷ്ട്രീയ മാറ്റങ്ങളും സാമൂഹ്യമാറ്റങ്ങളും ഉല്‍പ they may possibly result in biased output from the input, including specific person names and organizational names.  നമ്മള്‍ ഈ പ്രശ്നം ഡയറോണിക് ബിയാസ് എന്ന് വിളിക്കുന്നു. കാരണം അത് ഓരോ ഡാറ്റാസറ്റിലും വാര്‍ത്തകളുടെ തീയതിയ ഈ പഠനത്തില്‍ നമ്മള്‍ പ്രത്യേകിച്ച് വ്യക്തിയുടെ പേരുകളില്‍ നിന്നും പ്രത്യേകിച്ച് വാക്കുകള്‍ പ്രത്യക്ഷപ്പെടുന്നതിന ഈ കണ്ടുപിടികളുടെ അടിസ്ഥാനത്തില്‍, വികിഡിതാതയെ ഉപയോഗിക്കുന്ന മുഖം മൂടുന്ന രീതികള്‍ ഞങ്ങള്‍ പ്രാര്‍ത്ഥിക്കുന്നു. വ്യക്തിക്ക് പേരുകളുടെ പ്രഭാവം നഷ്</abstract_ml>
      <abstract_so>Wararka beenta ah waxey bulshada ku sababtaa waxyeelo badan. Si loo kala macaamiloodo warqadan been ah, waxaa la sameeyay wax lagu baranayo tusaale baaritaanka sameynta iyo hagitaanka kooxaha macluumaadka. Most of the fake news datasets depend on a specific time period.  Sababtaas darteed waxaa ku adag in la soo ogaado warqada been ah oo ku soo dhashay beddelaadka siyaasada iyo beddelaadka bulshada; waxay suurtagal ahaan u noqon karaan in laga soo bixiyo warbixinta laga soo galo, kuwaas oo ka mid ah magacyada qof gaar ah iyo magacyada ururada. Dhibaatadan waxaa looga jeedaa Diakronik Bias, sababtoo ah waxaa sabab u ah abuuridda taariikhda warbixinta ee macluumaad walba. Waxbarashadan waxaynu ku xaqiijinaynaa qaybaha, khusuusan noocyada saxda ah, kuwaas oo ah magaca qofka, marka lagu beddelo hadalka lagu soo jeedo macluumaad kasta. Sida lagu saleynayo baaritaankaas, waxaynu soo jeedaynaa qaababka lagu isticmaalayo Wikidata in lagu qiyaaso saameyn ku yeelashada magaca qofka iyo in loo xaqiijiyo in ay sameynayaan muusiko baaritaanka warbixinta been ah oo lagu baaraandegay jirrabaadka internetka iyo macluumaadka aan degaanka ka ahayn.</abstract_so>
      <abstract_si>බොරු ආරංචියක් සමාජට විශේෂ විනාශ කරනවා. මේ බොරු වාර්තාව සම්බන්ධ වෙනුවෙන්, සොයාගන්න විදිහට සහ දත්ත සේට් සැකසුම් විදිහට පරීක්ෂණය කරනවා. ගොඩක් බොරු වාර්තාව දත්ත සෙට් විශේෂ වෙලාවක් විතරයි. ඉතින්, ඒ වගේ දත්ත සෙට් එකේ ප්‍රධානය කරපු පරීක්ෂණ මොඩේල් අවස්ථාවක් තියෙනවා ජාතික වෙනස් සහ සමාජික වෙනස ඔවුන් පුළුවන් විශේෂ විශේෂ මිනිස්සු නම් සහ සංස්ථානය නම් වලින් ප්‍රතිචාර ප්‍රතිචා අපි මේ ප්‍රශ්නයක් දියාක්‍රොනික බියාස් කියලා කියනවා මොකද ඒක හැම තොරතුරු සෙට්ටුවේ වාර්තාව නිර්මාණය මේ පරීක්ෂණයේදී, අපි ප්‍රශ්නයක් තහවුරු කරනවා, විශේෂයෙන්ම ප්‍රශ්නයක් වලින් ප්‍රශ්නයක් වලින් ප්‍රශ්න මේ හොයාගන්න පුළුවන්, අපි විකිඩේටා භාවිතා කරන්න වික්‍රියාවක් ප්‍රශ්නය කරනවා මිනිස්සුන් නම් වලට පරීක්ෂණය සහ විශ්වාස කරන්න සඳහා වික්‍</abstract_si>
      <abstract_ro>Știrile false provoacă daune semnificative societății. Pentru a face față acestor știri false, au fost efectuate mai multe studii privind modelele de detectare a clădirilor și aranjarea seturilor de date. Majoritatea seturilor de date de știri false depind de o anumită perioadă de timp. În consecință, modelele de detectare instruite pe un astfel de set de date au dificultăți în detectarea noilor știri false generate de schimbările politice și sociale; acestea pot avea ca rezultat obținerea unor rezultate părtinitoare din intrare, inclusiv numele de persoane specifice și numele organizației. Ne referim la această problemă ca Bias Diacronic deoarece este cauzată de data de creare a știrilor în fiecare set de date. În acest studiu, confirmăm părtinirea, în special substantivele proprii, inclusiv numele persoanelor, de la abaterea apariției frazelor în fiecare set de date. Pe baza acestor constatări, propunem metode de mascare folosind Wikidata pentru a atenua influența numelor persoanelor și pentru a valida dacă acestea fac modele de detectare a știrilor false robuste prin experimente cu date din domeniu și din afara domeniului.</abstract_ro>
      <abstract_sr>Lažne vesti uzrokuju značajnu štetu društvu. Da bi se riješili ovim lažnim vestima, provedeno je nekoliko studija o izgradnji modela detektiva i organizaciji podataka. Većina lažnih podataka zavisi od određenog vremenskog period a. Stoga, modeli otkrivanja obučenih na takvom setu podataka imaju teškoće otkrivanje novih lažnih vijesti koje su proizveli političke promjene i socijalne promjene; Možda bi mogli rezultirati predrasudan izlaz iz ulaza, uključujući posebne imena osoba i organizacijske imene. Smatramo ovaj problem kao Diachronic Bias jer je uzrok datuma stvaranja vijesti u svakoj seti podataka. U ovoj studiji potvrđujemo predrasude, posebno odgovarajuće imena uključujući imena osoba, iz odstupanja fraza pojavljivanja u svakoj seti podataka. Na osnovu tih nalaza, predlažemo maskiranje metoda koristeći Wikidata kako bi smanjili uticaj imena osoba i potvrdili da li praviju lažne modele za detekciju novosti jačane kroz eksperimente sa podacima u domenu i izvan domena.</abstract_sr>
      <abstract_sv>Falska nyheter orsakar betydande skador på samhället. För att hantera dessa falska nyheter har flera studier genomförts om att bygga detektionsmodeller och ordna datauppsättningar. De flesta av de falska nyhetsdatauppsättningarna beror på en viss tidsperiod. Följaktligen har de detektionsmodeller som utbildats på sådana datamängder svårt att upptäcka nya falska nyheter som genereras av politiska förändringar och sociala förändringar. de kan eventuellt resultera i partisk output från inmatningen, inklusive specifika personnamn och organisationsnamn. Vi hänvisar till detta problem som Diakronisk Bias eftersom det orsakas av skapandet av nyheter i varje dataset. I denna studie bekräftar vi bias, särskilt egensubstantiv inklusive personnamn, från avvikelsen av frasutseenden i varje dataset. Baserat på dessa resultat föreslår vi maskeringsmetoder med hjälp av Wikidata för att mildra påverkan av personnamn och validera om de gör falska nyhetsdetekteringsmodeller robusta genom experiment med in- och out-of-domain data.</abstract_sv>
      <abstract_ta>பொய் செய்திகள் சமூகத்திற்கு மிகவும் பெரிய காரணத்தை கொண்டுள்ளது. இந்த பொய் செய்திகளை நிர்வகிக்க, கண்டுபிடிப்பு மாதிரிகளை உருவாக்கும் மற்றும் தரவு அமைப்புகளை அமைப்பதற்கு பல பொய் செய்தி தகவல் அமைப்புகளில் பெரும்பாலும் குறிப்பிட்ட நேரத்தை சார்ந்திருக்கிறது. Consequently, the detection models trained on such a dataset have difficulty detecting novel fake news generated by political changes and social changes;  குறிப்பிட்ட நபர் பெயர் மற்றும் நிறுவனம் பெயர்கள் உள்ளீட்டிலிருந்து வெளியீட்டை கொண்டு வருவார்கள். நாம் இந்த பிரச்சனையை Diakronisk Bias என்று குறிப்பிடுகிறோம். ஏனென்றால் அது ஒவ்வொரு தரவுத்தளத்திலும் செய்திய இந்த ஆராய்ச்சியில், நாம் ஒவ்வொரு தரவுத்தளத்திலும் சொற்றொடர் தோன்றத்திலிருந்தும் சரியான பெயர்களை உறுதி செய்கிற இந்த கண்டுபிடிப்புகளை அடிப்படையில், நாம் விகிடிட்டாவை பயன்படுத்தி மூடும் முறைமைகளை பயன்படுத்தி நபர் பெயரின் விளைவுகளை குறைக்க மற்றும் பொய் செய்தி கண</abstract_ta>
      <abstract_ur>جھوٹی خبریں اجتماعی کے لئے بڑا نقصان اٹھاتی ہیں۔ ان غلط خبروں کے بارے میں بہت سی مطالعہ ڈیٹ سٹ بنانے کے بارے میں کیا گیا ہے۔ بہت سے جھوٹی خبر ڈیٹ سٹ ایک مقررہ وقت مدت پر اعتماد رکھتے ہیں. لہٰذا، ایسے ڈاٹ سٹ پر آموزش کیا گیا تھا کہ سیاسی تغییرات اور سوسیال تغییرات کے ذریعہ پیدا کئے ہوئے نئی غلط خبریں کا تشخیص کرنا مشکل ہے۔ یہ ممکن ہے کہ انٹیپ سے منحصر نکالے جاتے ہیں، ایک شخص کے نام اور سازمانی نام شامل ہوتے ہیں. ہم اس مسئلہ کو Diachronic Bias بناتے ہیں کیونکہ یہ ہر ڈیٹ سٹ میں خبروں کی پیدائش کی تاریخ کی وجہ سے ہے. اس مطالعہ میں، ہم نے بحث کی تصدیق کی، مخصوصاً اچھی نام، جو شخص نام شامل ہوتے ہیں، ہر ڈیٹ سٹ میں فریزوں کی مخالفت سے۔ یہ نتیجے پر، ہم ویکیڈائٹ کے مطابق ماسک کرنے کے طریقے پیشنهاد کرتے ہیں کہ انسان کے ناموں کے تاثیر کو کمزور کریں اور ان کی تصدیق کریں کہ ان کو دھوکہ خبر شناسایی موڈل بناتے ہیں جو ڈومین میں اور خارج ڈومین کے مطابق آزمائش کے ذریعے مضبوط</abstract_ur>
      <abstract_uz>Fake news causes significant damage to society.  Bu fake news bilan boshqarish uchun, aniqlash modellarini yaratish va maʼlumot satrlarini boshqarish uchun bir nechta o'rganishlar bajarildi. @ info: whatsthis Shunday sababi, bu maʼlumotlar sahifadagi o'rganish modellarini o'rganish muvaffaqiyatli, siyatiy o'zgarishlar va jamiyat o'zgarishlari sabab boʻlgan fake news aniqlash qiyin edi; ularni kiritishdan foydalanish mumkin, uning foydalanuvchi nomi va organizational nomlari kabi. Biz bu muammolarni Diakronisk Bias deb ataymiz chunki u har bir maʼlumotlar sahifa yaratish sanasi sababchi sababchi. Bu taʼminotda biz bir maʼlumot sahifadagi bir so'zlarning o'zgarishdan foydalanuvchilarni ishlatimiz, hususan oddiy nomlarni qo'shish mumkin. Bu natijalar asosida, biz Wikidata yordamida qo'shish usullarini qo'yish uchun qo'l nomini kamaytirish va ular domen va domen maʼlumotdan tasdiqlash uchun falsk xabar qidirish modellarini yaratishni to ʻgʻri qilamiz.</abstract_uz>
      <abstract_vi>Tin giả gây ảnh hưởng lớn đến xã hội. Để xử lý những tin giả này, đã tiến hành nhiều nghiên cứu về các mô hình phát hiện xây dựng và sắp xếp các bộ dữ liệu. Hầu hết các tập tin tin giả phụ thuộc vào một thời gian cụ thể. Do đó, các mô hình phát hiện được huấn luyện trên một bộ dữ liệu như vậy khó tìm ra những tin giả tạo từ thay đổi chính trị và thay đổi xã hội. chúng có thể dẫn đến sản xuất có thiên vị từ dữ liệu nhập, bao gồm tên người đặc biệt và tên tổ chức. Chúng tôi gọi vấn đề này là sa mạc Diamãn Do nó gây ra bởi ngày tạo tin trong mỗi tập tin. Trong nghiên cứu này, chúng tôi xác nhận thành kiến, đặc biệt là danh từ chính đáng, kể cả tên người, từ sự lệch lạc của các cụm từ trong mỗi tập tin. Dựa trên những kết quả này, chúng tôi đề nghị sử dụng phương pháp che giấu bằng WikiLdata để giảm ảnh hưởng của tên người và xác minh liệu chúng có thể tạo ra các mô hình giả trinh thám tin (bóc) được dùng qua thí nghiệm với dữ liệu nội trong và ngoài miền.</abstract_vi>
      <abstract_bg>Фалшивите новини причиняват значителни щети на обществото. За справяне с тези фалшиви новини са проведени няколко проучвания за изграждане на модели за откриване и подреждане на набори от данни. Повечето от наборите от данни за фалшиви новини зависят от определен период от време. Следователно моделите за откриване, обучени по такъв набор от данни, трудно откриват нови фалшиви новини, генерирани от политически промени и социални промени; те могат да доведат до предубедени резултати от входящите данни, включително конкретни имена на лица и организационни имена. Ние наричаме този проблем диахронични отклонения, защото той е причинен от датата на създаване на новини във всеки набор от данни. В това проучване потвърждаваме пристрастието, особено правилните съществителни, включително имената на лица, от отклонението на появата на фразите във всеки набор от данни. Въз основа на тези констатации предлагаме методи за маскиране, използващи Уикиданни, за да смекчат влиянието на имената на лица и да проверят дали те правят моделите за откриване на фалшиви новини стабилни чрез експерименти с данни в домейн и извън домейн.</abstract_bg>
      <abstract_hr>Lažne vijesti uzrokuju značajnu štetu društvu. Za rješavanje tih lažnih vijesti provedena je nekoliko ispitivanja o izgradnji modela otkrivanja i organizaciji podataka. Većina lažnih datoteka ovisi o određenom vremenskom razdoblju. Stoga, modeli otkrivanja obučenih na takvom sastavu podataka imaju teškoće otkriti nove lažne vijesti koje su proizveli političke promjene i socijalne promjene; oni mogu vjerojatno rezultirati predrasudan izlaz iz ulaza, uključujući specifična imena osoba i organizacijska imena. Smatramo ovaj problem kao Diachronic Bias jer je uzrok datuma stvaranja vijesti u svakoj skupini podataka. U ovom ispitivanju potvrđujemo predrasude, posebno odgovarajuće imena uključujući imena osoba, iz odstupanja pojava fraza u svakoj seti podataka. Na temelju tih otkrića, predlažemo maskiranje metoda koristeći Wikidata kako bi smanjili utjecaj imena osoba i potvrdili da li čine lažne modele otkrivanja vijesti jačane kroz eksperimente s podacima u domenu i izvan domena.</abstract_hr>
      <abstract_nl>Nepnieuws veroorzaakt aanzienlijke schade aan de samenleving. Om dit fake news aan te pakken, zijn verschillende studies uitgevoerd naar het bouwen van detectiemodellen en het rangschikken van datasets. De meeste fake news datasets zijn afhankelijk van een specifieke periode. Bijgevolg hebben de detectiemodellen die op een dergelijke dataset zijn getraind, moeite om nieuw nepnieuws te detecteren dat is gegenereerd door politieke veranderingen en sociale veranderingen; ze kunnen leiden tot een biased output van de invoer, inclusief specifieke personen- en organisatienamen. We noemen dit probleem diachrone bias omdat het wordt veroorzaakt door de aanmaakdatum van nieuws in elke dataset. In deze studie bevestigen we de bias, met name eigennaamwoorden inclusief persoonsnamen, van de afwijking van de uitdrukkingen in elke dataset. Op basis van deze bevindingen stellen we maskeringsmethoden voor die Wikidata gebruiken om de invloed van persoonsnamen te beperken en te valideren of ze fake news detection modellen robuust maken door experimenten met in-domein en out-of-domein data.</abstract_nl>
      <abstract_de>Fake News verursachen erheblichen Schaden für die Gesellschaft. Um mit diesen Fake News umzugehen, wurden mehrere Studien zum Aufbau von Erkennungsmodellen und zur Anordnung von Datensätzen durchgeführt. Die meisten Fake News Datensätze hängen von einem bestimmten Zeitraum ab. Folglich haben die auf einem solchen Datensatz trainierten Detektionsmodelle Schwierigkeiten, neue Fake News zu erkennen, die durch politische Veränderungen und soziale Veränderungen verursacht werden; Sie können möglicherweise zu verzerrten Ausgaben aus der Eingabe führen, einschließlich bestimmter Personen- und Organisationsnamen. Wir bezeichnen dieses Problem als diachrone Bias, da es durch das Erstellungsdatum der Nachrichten in jedem Datensatz verursacht wird. In dieser Studie bestätigen wir die Verzerrung, insbesondere Eigensubstantive einschließlich Personennamen, von der Abweichung der Phrasenbilder in jedem Datensatz. Basierend auf diesen Erkenntnissen schlagen wir Maskierungsmethoden vor, die Wikidata verwenden, um den Einfluss von Personennamen zu mindern und durch Experimente mit In- und Out-of-Domain-Daten zu validieren, ob sie Fake News Erkennungsmodelle robust machen.</abstract_de>
      <abstract_da>Falske nyheder forårsager betydelig skade på samfundet. For at håndtere disse falske nyheder er der gennemført adskillige undersøgelser af bygningsmodeller og arrangering af datasæt. De fleste af de fake news datasæt afhænger af en bestemt tidsperiode. Derfor har detektionsmodeller, der er uddannet på et sådant datasæt, svært ved at opdage nye falske nyheder, der er skabt som følge af politiske ændringer og sociale ændringer. de kan muligvis resultere i partisk output fra input, herunder specifikke personnavne og organisationsnavne. Vi henviser til dette problem som Diakronisk Bias, fordi det skyldes oprettelsesdatoen for nyheder i hvert datasæt. I denne undersøgelse bekræfter vi bias, især egennavnene herunder personnavne, fra afvigelsen af sætninger udseende i hvert datasæt. Baseret på disse resultater foreslår vi maskeringsmetoder ved hjælp af Wikidata til at mindske indflydelsen af personnavne og validere, om de gør falske nyheder detekteringsmodeller robuste gennem eksperimenter med in-domæne og out-of-domæne data.</abstract_da>
      <abstract_ko>허위 뉴스는 사회에 중대한 손해를 끼친다.이런 가짜 뉴스에 대응하기 위해 검측 모델 구축과 데이터 집합 정리에 관한 몇 가지 연구가 진행되었다.대부분의 가짜 뉴스 데이터 집합은 특정한 시간대에 달려 있다.따라서 이런 데이터 집합에서 훈련된 검측 모델은 정치 변화와 사회 변화로 인한 새로운 가짜 뉴스를 검측하기 어렵다.그것들은 특정한 사람 이름과 조직 이름을 포함하여 입력의 출력에 편차가 생길 수 있다.우리는 이 문제를 시간적 편차라고 부른다. 왜냐하면 모든 데이터가 뉴스의 창설 날짜에 집중되기 때문이다.이 연구에서 우리는 모든 데이터 집중 단어에 나타난 편차에서 편차, 특히 인명을 포함한 전문 명사를 확인했다.이러한 발견을 토대로 우리는 위키데이터를 사용하는 엄폐 방법을 제시하여 인명의 영향을 줄이고, 역내와 역외 데이터의 실험을 통해 가짜 뉴스 검출 모델이 노봉성을 가지는지 검증했다.</abstract_ko>
      <abstract_fa>اخبار دروغ باعث آسیب بزرگی به جامعه است. برای حل با این خبرهای دروغ، چندین مطالعه در مورد ساختن مدل های شناسایی و ساختن مجموعه داده ها انجام شده است. بیشتر مجموعه‌های داده‌های دروغ به یک مدت زمانی بستگی دارد. بنابراین، مدلهای شناسایی که روی چنین مجموعه داده آموزش داده شده‌اند سختی دارند که اخبار‌های دروغ‌بندی‌ها را شناسایی کنند که توسط تغییرات سیاسی و تغییرات اجتماعی تولید می‌کنند. ممکن است نتیجه‌ی نتیجه‌ای از ورودی مختلف باشد، شامل نام‌های شخص و نام‌های سازمانی. ما به این مشکل به عنوان دیاکرونیک بیس ارائه می کنیم چون آن به عنوان تاریخ ایجاد اخبار در هر مجموعه داده باعث شده است. در این مطالعه، ما تأیید می‌کنیم، مخصوصاً نام‌های مناسب، شامل نام‌های شخصی، از تغییر توجه‌های عبارت در هر مجموعه‌ی داده‌ها. بر اساس این نتیجه‌ها، ما روش‌های ماسک‌سازی را با استفاده از ویکیداده‌ها پیشنهاد می‌کنیم تا تاثیر نام‌های شخصی را کم کند و تاثیر دهند که آیا آنها مدل‌های شناسایی خبری‌های دروغگویی را با آزمایش‌ها با داده‌های خارج از دامنه‌</abstract_fa>
      <abstract_sw>Habari za uongo zinasababisha uharibifu mkubwa kwa jamii. Ili kukabiliana na habari hizi bandia, tafiti kadhaa kuhusu kutengeneza mifano ya uchunguzi na kuandaa seti za taarifa zimefanyika. Taarifa za habari bandia zinategemea kipindi maalumu. Kwa hiyo, miundo mbinu ya kutambua yaliyofundishwa kwenye seti ya taarifa hiyo ina vigumu kugundua habari bandia zilizotengenezwa na mabadiliko ya kisiasa na mabadiliko ya kijamii; wanaweza kusababisha matokeo yanayopingwa kutoka kwenye kituo hicho, ikiwa ni pamoja na majina maalum na majina ya shirika. Tunaita tatizo hili kama Diakroc Bias kwa sababu inasababishwa na kutengeneza tarehe ya habari katika kila seti ya taarifa. Katika utafiti huu, tunathibitisha upendeleo huu, hususani wale wanaoishi jina sahihi ikiwa ni pamoja na majina ya mtu, kutokana na kubadilishwa kwa maneno yanayotokea kwenye kila seti ya data. Kwa mujibu wa matokeo haya, tunapendekeza njia za kufungia vifaa kwa kutumia Wikidata ili kupunguza ushawishi wa majina ya mtu na kuhakikisha ikiwa wanatengeneza mifano ya uchunguzi wa habari potofu yanayochapishwa kupitia majaribio ya ndani na kutoa taarifa za ndani.</abstract_sw>
      <abstract_tr>Ýok haberler jemgyýetçilige örän hasaplanýar. Bu ýalňyş haberler bilen çözmek üçin, aňry tanyş modellerini bejermek we veri setirlerini düzenlemek üçin birnäçe öwrenme edildi. ýalňyş haberler setirleriniň köpüsi wagtyň bir wagtyna ynamly. Şol sebäpli, ýaly veri setirinde bilinmeli nusgalar syýasy üýtgeşmeler we sosial üýtgeşmeler tarapyndan döredilen ýalany täzelikleri tapmakda kynçylyk ýok. Çikgi üçin belli adamlaryň adyny we organizasiýa adlarynyň içine netijesi bolup biler. Biz bu meseleni Diakroniki Biýas diýip synanyşýarys çünki ol, her data setinde täzelikler döredişi. Bu araşdyrmada, biz özümiziň närazlygyny, özellikle kişiň adlary dahil edilýän adlary, her veri setirinde sözlerin gaýşandyrylygyndan onaylaýarys. Bu çözgülere göre, biz Wikidata kullanarak kişin in adlarının etkisini azaltmak üçin maskeler yöntemlerini teklif edip, adam adlarının etkisini azaltmak üçin sahte haber değerlendirmek modellerini domain ve dış-domeny verileri ile robust deneyler yaratmak üçin teklif ediyoruz.</abstract_tr>
      <abstract_af>Laag nuus veroorsaak betekende skade aan samelewing. Om hierdie falske nuus te behandel, het 'n paar studie op die bou van opdekking modele en regstelling van datastelle gedoen. Die meeste van die falske nuus datastelle afhang van 'n spesifieke tydperk. Daarom het die opdekking-modelles wat op so 'n datastel opgelei is, moeilikheid om novele falske nuus te ontdek wat gegenereer word deur politieke verander en sosiale veranderinge; hulle mag moontlik resultaat in biased uitvoer van die invoer, insluitend spesifieke persoon name en organizasionale name. Ons verwys na hierdie probleem as Diachronic Bias omdat dit veroorsaak word deur die skep datum van nuus in elke datastel. In hierdie studie bevestig ons die bias, veral regte noume insluitend persoonnaams, van die afwyking van frase verskyning in elke datastel. Ons voorstel om maskeringsmetodes te gebruik met Wikidata om die influens van persoonnaams te verminder en die geldigheid of hulle falsies nuusdeteksie modele gemaak wat sterk deur eksperimente met in-domein en uit-domein data te maak.</abstract_af>
      <abstract_sq>Lajmet e rreme shkaktojnë dëme të rëndësishme në shoqëri. Për të trajtuar këto lajme të rreme, janë kryer disa studime mbi ndërtimin e modeleve të zbulimit dhe rregullimin e të dhënave. Shumica e të dhënave të rreme të lajmeve varen nga një periudhë kohore e caktuar. Për shkak të kësaj, modelet e zbulimit të trajnuar në një set të tillë të dhënash kanë vështirësi të zbulojnë lajme të reja të rreme të krijuara nga ndryshimet politike dhe ndryshimet shoqërore; ata mund të rezultojnë në dalje të paragjykuar nga hyrja, duke përfshirë emra specifike të personave dhe emra organizative. Ne e referojmë këtë problem si Bias Diakronike sepse është shkaktuar nga data e krijimit të lajmeve në çdo set të dhënash. Në këtë studim, ne konfirmojmë paragjykimin, veçanërisht emrat e duhura duke përfshirë emrat e personave, nga devijimi i paraqitjeve të frazës në çdo set të dhënash. Bazuar në këto gjetje, ne propozojmë metoda maskimi duke përdorur Wikidata për të lehtësuar ndikimin e emrave të personave dhe për të vlerësuar nëse ato bëjnë modele të rreme të zbulimit të lajmeve të fuqishëm nëpërmjet eksperimenteve me të dhëna në domeni dhe jashtë domeni.</abstract_sq>
      <abstract_id>Berita palsu menyebabkan kerusakan yang signifikan pada masyarakat. Untuk menangani berita palsu ini, beberapa studi tentang membangun model deteksi dan mengatur set data telah dilakukan. Kebanyakan dataset berita palsu bergantung pada waktu tertentu. Oleh karena itu, model deteksi yang dilatih pada set data seperti itu memiliki kesulitan mendeteksi berita palsu novel yang dihasilkan oleh perubahan politik dan perubahan sosial; mereka mungkin menghasilkan output bias dari input, termasuk nama-nama orang spesifik dan nama organisasi. Kami menyebut masalah ini sebagai Bias Diakronis karena disebabkan oleh tanggal penciptaan berita dalam setiap set data. Dalam penelitian ini, kami mengkonfirmasi bias, terutama nama yang tepat termasuk nama orang, dari deviasi dari penampilan frasa di setiap set data. Berdasarkan penemuan ini, kami mengusulkan metode penyamaran menggunakan Wikidata untuk mengurangi pengaruh nama orang dan memastikan apakah mereka membuat model deteksi berita palsu robust melalui eksperimen dengan data di domain dan luar domain.</abstract_id>
      <abstract_am>የውሸት ዜና ማኅበረሰብ ብዙ ጉዳይ ነው፡፡ እነዚህን የሐሰት ዜናዎች ለመቀበል፣ የግንኙነት ምሳሌዎች እና ዳታዎችን ለመቀናቀል ብዙዎች ተማርከዋል፡፡ የውሸት ዜና ዳታዎችን አብዛኞቻቸው በተወሰነ ጊዜ ላይ ይጠጋሉ። ስለዚህም፣ እንደዚህ በዳታ ሰርቨሮች የተማሩ የሐሰት ዜና በፖለቲካ ለውጦች እና ማኅበራዊ ለውጦች የተደረገውን የሐሰት ዜና ማግኘት ጭንቀት ነው፡ ከውይይት ውስጥ፣ የተለየ የአካባቢ ስም እና ድርጅት ስም ውስጥ የተደረገ ውጤት እንዲያገኙ ይችላል፡፡ ይህንን ጉዳይ በሁሉም ዳታተሮች ውስጥ የዜና ቀን በመፍጠር ነው ብለን እናስባለን፡፡ በዚህ ትምህርት፣ በተለይ የራሳቸውን ስሞች እናስፈልጋለን፡፡ እነዚህን ፍጥረቶች በመጠቀም፣ Wikidata የሰው ስም ማቀናቀል እና የውሸት ዜና ማግኘት ምሳሌዎችን በዲሞናዊ እና ከውጭ የዶሜን ዳታዎች በመፈተን የውሸት የዜና ማግኘት እናደርጋለን፡፡</abstract_am>
      <abstract_hy>Կատար նորությունները մեծ վնաս են պատճառում հասարակության վրա: Այս կեղծ նորությունների հետ կապված որոշ ուսումնասիրություններ են կատարվել հայտնաբերման մոդելների կառուցման և տվյալների համակարգերի կազմակերպման մասին: Կատար նորությունների տվյալների մեծ մասը կախված է որոշակի ժամանակահատվածից: Հետևաբար, այսպիսի տվյալների համակարգում սովորեցված հայտնաբերման մոդելները դժվարությամբ են հայտնաբերում կեղծ նորություններ, որոնք առաջացել են քաղաքական փոփոխությունների և սոցիալական փոփոխությունների արդյունքում: they may possibly result in biased output from the input, including specific person names and organizational names.  Մենք այս խնդիրը անվանում ենք Դիախրոնիկ Բեսա, քանի որ այն պատճառ ունի յուրաքանչյուր տվյալների համակարգում նորությունների ստեղծման օրվանից: In this study, we confirm the bias, especially proper nouns including person names, from the deviation of phrase appearances in each dataset.  Հիմնվելով այս հայտնաբերությունների վրա, մենք առաջարկում ենք Վիքիդատայի օգտագործման ծածկումների մեթոդներ մարդկանց անունների ազդեցության նվազեցնելու և ստուգելու համար, արդյոք նրանք կեղծ նորությունների հայտնաբերման մոդելներ ուժեղ են դարձնում տիեզերքում և տիեզերքում տեղեկատվության</abstract_hy>
      <abstract_az>Yaxşı xəbərlər sosyalə böyük zərər verir. Bu sahte xəbərlər ilə çəkilmək üçün, keşf modellərini inşa etmək və veri setlərini düzəltmək məqsədilə bir neçə təhsil edildi. Yaxşı xəbər veri qurularının çoxu müəyyən vaxt müddətinə bağlı. Beləliklə, böyük verilən qurğuda təhsil edilmiş keşif modelləri siyasi dəyişikliklər və sosial dəyişikliklər tarafından yaratdığı yeni sahte xəbərləri keşif etmək çətindir. belə olar ki, içərisindən müəyyən kişilərin adları və organizasiya adları dahil olmaqla mümkün olar. Biz bu problem ə Diachronic Bias kimi danışırıq, çünki bu, hər veri qutusunda xəbərlər yaratma tarihinə səbəb edir. Bu təhsil içində, hər veri qutusunda fərz görünüşünün dəyişməsindən təsdiqlənirik, özlərinə də insan adlarının içində uyğun adlarını təsdiqləyirik. Bu tapılara baxmayaraq, biz Wikidata vasitəsilə masking metodlarını təklif edirik ki, insanların adlarının təsirini azaltmaq və onlar sahte xəbər keşf modellərini domeində və dış domenin məlumatları ilə istifadə edirlər.</abstract_az>
      <abstract_bs>Lažne vijesti uzrokuju značajnu štetu društvu. Da bi se riješili ovim lažnim vijestima, provedeno je nekoliko studija o izgradnji modela detektiva i organizaciji podataka. Većina lažnih novosti ovisi o određenom vremenskom periodu. Stoga modeli otkrivanja obučenih na takvom kompletu podataka imaju teškoće otkriti nove lažne vijesti koje su proizveli političke promjene i socijalne promjene; Možda bi mogli rezultirati predrasudan izlaz iz ulaza, uključujući specifična imena osoba i organizacijska imena. Smatramo ovaj problem kao Diachronic Bias jer je uzrok datuma stvaranja vijesti u svakoj seti podataka. U ovoj studiji potvrđujemo predrasude, posebno odgovarajuće imena uključujući imena osoba, iz odstupanja pojava fraza u svakoj seti podataka. Na temelju tih nalaza, predlažemo maskiranje metoda koristeći Wikidata kako bi smanjili utjecaj imena osoba i potvrdili da li praviju lažne modele za detekciju novosti jačane kroz eksperimente sa podacima iz domena i izvan domena.</abstract_bs>
      <abstract_ca>Les notícies falses causen danys significatius a la societat. To deal with these fake news, several studies on building detection models and arranging datasets have been conducted.  La majoria dels conjunts de dades de notícies falses depenen d'un període de temps específic. En conseqüència, els models de detecció entrenats en aquest conjunt de dades tenen dificultats per detectar noves notícies falses generades pels canvis polítics i els canvis socials; they may possibly result in biased output from the input, including specific person names and organizational names.  Aquest problema es diu Bias Diacrònic perquè és causat per la data de creació de notícies en cada conjunt de dades. En aquest estudi, confirmam el bias, especialment noms adequats incloent noms de persones, de la desviació de les aparències de frases en cada conjunt de dades. Sobre la base d'aquests descobriments, proposem mètodes de mascarament que utilitzen Wikidata per mitigar l'influència dels noms de persones i validar si fan robustos models de detecció de notícies falses a través d'experiments amb dades en domini i fora de domini.</abstract_ca>
      <abstract_cs>Falešné zprávy způsobují značnou škodu společnosti. Pro řešení těchto falešných zpráv bylo provedeno několik studií o budování detekčních modelů a uspořádání datových sad. Většina datových sad falešných zpráv závisí na konkrétním časovém období. Proto mají detekční modely trénované na takovém datovém souboru potíže s detekcí nových falešných zpráv vyvolaných politickými změnami a sociálními změnami; mohou mít za následek zkreslený výstup ze vstupu, včetně jmen konkrétních osob a organizačních jmen. Tento problém označujeme jako diachronický bias, protože je způsoben datem vytvoření zpráv v každém datovém souboru. V této studii potvrzujeme zaujatost, zejména vlastní podstatná jména včetně jmen osob, od odchylky vzhledu frází v jednotlivých datových sadách. Na základě těchto zjištění navrhujeme maskovací metody využívající Wikidata ke zmírnění vlivu jmen osob a ověření, zda dělají modely detekce falešných zpráv robustní prostřednictvím experimentů s daty v doméně i mimo doménu.</abstract_cs>
      <abstract_bn>মিথ্যা সংবাদ সমাজের জন্য গুরুত্বপূর্ণ ক্ষতিগ্রস্ত। এই মিথ্যা সংবাদের সাথে চুক্তি করার জন্য বেশ কিছু গবেষণা করা হয়েছে আবিষ্কারের মডেল এবং ডাটাসেট সংগঠনের উপর। বেশীরভাগ মিথ্যা সংবাদ তথ্য নির্ভর করে একটি নির্দিষ্ট সময়ের উপর। এর ফলে এই ধরনের ডাটাসেটে প্রশিক্ষণ প্রদান করা মডেল রাজনৈতিক পরিবর্তন এবং সামাজিক পরিবর্তনের কারণে তৈরি হয়েছে রাজনৈতিক পরিবর্তন এবং সং তারা সম্ভবত ইনপুট থেকে বিদ্রোহী আউটপুটের ফলাফল হতে পারে, যার মধ্যে রয়েছে ব্যক্তির নাম এবং সংগঠনের নাম। আমরা এই সমস্যাকে ডায়ারোনিক বায়াস হিসেবে উল্লেখ করি কারণ এটি প্রতিটি ডাটাসেটে সংবাদ সৃষ্টির তারিখ। এই গবেষণায় আমরা বিশেষ করে যে ব্যক্তির নাম রয়েছে তা নিশ্চিত করি, যার মধ্যে ব্যক্তিগত নাম রয়েছে, তারা প্রত্যেক ডাটাসেটে বাক্য এই আবিস্কারের ভিত্তিতে আমরা উইকিডিতাটা ব্যবহার করে মুখোশ মুখোশের পদ্ধতি প্রস্তাব করি ব্যক্তির নাম ম মাত্রার প্রভাব কমাতে এবং তারা ভুয়া সংবাদ আবিষ্কার মড</abstract_bn>
      <abstract_et>Valeuudised tekitavad ühiskonnale märkimisväärset kahju. Nende valeuudistega tegelemiseks on läbi viidud mitmeid uuringuid tuvastusmudelite ehitamise ja andmekogumite korraldamise kohta. Enamik valeuudiste andmekogumitest sõltub konkreetsest ajavahemikust. Sellest tulenevalt on sellise andmekogumi põhjal koolitatud avastamismudelitel raske tuvastada poliitiliste muutuste ja sotsiaalsete muutuste põhjustatud uusi valeuudiseid; need võivad põhjustada sisendi, sealhulgas konkreetsete isikute ja organisatsioonide nimed, erapooletuid tulemusi. Me nimetame seda probleemi diakrooniliseks kalduvuseks, sest see on põhjustatud uudiste loomise kuupäevast igas andmekogumis. Käesolevas uuringus kinnitame fraaside esinemise kõrvalekaldeid igas andmekogumis, eriti õigeid nimisõnu, sealhulgas inimnimesid. Nende tulemuste põhjal pakume välja Wikiandmeid kasutavad maskeerimismeetodid, et leevendada isikunimede mõju ja kinnitada, kas need muudavad valeuudiste tuvastamise mudelid tugevaks domeenisiseste ja väliste andmete eksperimentide kaudu.</abstract_et>
      <abstract_fi>Väärät uutiset aiheuttavat merkittävää vahinkoa yhteiskunnalle. Näiden valeuutisten käsittelemiseksi on tehty useita tutkimuksia havaitsemismallien rakentamisesta ja aineistojen järjestämisestä. Suurin osa fake news -aineistoista riippuu tietystä ajanjaksosta. Näin ollen tällaisiin tietoaineistoihin koulutetuilla havaitsemismalleilla on vaikeuksia havaita poliittisten muutosten ja yhteiskunnallisten muutosten synnyttämiä uusia valeuutisia. ne voivat mahdollisesti johtaa syötteen vääristyneeseen tuotokseen, mukaan lukien tiettyjen henkilöiden ja organisaatioiden nimet. Kutsumme tätä ongelmaa diakrooniseksi biaksi, koska se johtuu uutisten luomispäivästä kussakin aineistossa. Tässä tutkimuksessa vahvistamme harhan, erityisesti varsinaiset substantiivit, henkilönimet mukaan lukien, fraasien esiintymisen poikkeamasta kussakin aineistossa. Näiden löydösten perusteella ehdotamme Wikidatan peittämismenetelmiä, joilla lievennetään henkilönimien vaikutusta ja validoidaan, tehdäänkö niistä luotettavia valeuutisten havaitsemismalleja käyttämällä kokeiluja verkkotunnuksen sisäisillä ja ulkopuolisilla tiedoilla.</abstract_fi>
      <abstract_jv>Perintah sing perbudhakan uwis seneng pisan-pakan kanggo sabanjuré. Mbok yo nganggo alam sing gak dhèwèké, akeh layang-layang kanggo nggawe model ono wektu nggawe dataset kuwi nggawe barang. Daftar dhéwé sing luwih akeh pisan neng pisan neng kana dhéwé. Yo wih-wih, model sing ditambah akeh lan akeh dataset kuwi susah-susahe kanggo ngilangno dolanan sing nyimpen batar sing nganggo gambaran politik lan cendelo sak susahe; biasing Awak dhéwé ngerasakno perbudhakan iki diahron Bias lak dadi iki dadi nggawe dataset Nang barêng-barêng iki, kéné patingêngké biasane, ngomong sak barêng-barêng sing nêmên uwong, lan uwong kuwi ngêmên patingêng seneng pisan Manual Basa on this find, we proposal Masking Methods used Wicdata to minimate the affect of someone names and Valdate about their make fale information detection modes bot through out the testing with in-domain and out-of-domain data.</abstract_jv>
      <abstract_sk>Lažne novice povzročajo veliko škodo družbi. Za obravnavo teh lažnih novic je bilo izvedenih več študij o izdelavi modelov za odkrivanje in urejanju naborov podatkov. Večina naborov podatkov o lažnih novicah je odvisna od določenega časovnega obdobja. Posledično imajo modeli odkrivanja, usposobljeni na podlagi takega nabora podatkov, težave z odkrivanjem novih lažnih novic, ki nastanejo zaradi političnih sprememb in družbenih sprememb; lahko povzročijo pristranske rezultate vnosa, vključno z imeni določenih oseb in organizacij. To težavo imenujemo Diakronična pristranskost, ker jo povzroča datum ustvarjanja novic v vsakem naboru podatkov. V tej študiji potrjujemo pristranskost, zlasti ustrezni samostalniki, vključno z imeni oseb, od odstopanja pojava fraz v vsakem naboru podatkov. Na podlagi teh ugotovitev predlagamo metode maskiranja, ki uporabljajo Wikipodatke za ublažitev vpliva imen oseb in preverjanje, ali so modeli odkrivanja lažnih novic robustni s poskusi s podatki znotraj in zunaj domene.</abstract_sk>
      <abstract_ha>Habari na ƙarya zasa wata hasara mai girma ga jamii. To deal with these fake news, several studies on building detection models and arranging datasets have been conducted.  Babu mafi yawan data na ƙarya sun ƙayyade kan wani lokaci na ƙayyade. Daga wannan, misãlai wanda aka sanar da shi a kan wannan zane-danne sun yi ƙunci a gane wa yangon ƙarya wanda aka ƙãga musanyi na kisa da musanyawa na jamii; za su iya ƙara matsayin bayani daga shirin ayuka, kamar sunayen mutane da sunayen shirin ayuka. Munã ƙayyade wannan muammãni kamar Diaronic Bias ne don a sami shi da aka halitta kwanan na lãbãri a cikin kowane danne-danne. Daga wannan littafin, Munã gaskata misalin haske masu inganci, da sunayen mutane, daga juyin magana masu cikin kowane dataset. Basan da wannan gannai, Munã buɗa hanyoyin makafi da Wikidata don ya sauƙaƙara haske wa sunayen mutum kuma masu inganci, ko lalle ne, su sami misãlai masu gane ƙarya da aka kife shi a cikin-Domen da ba'a samun data na guda ba.</abstract_ha>
      <abstract_he>חדשות מזויפות גורמות נזק משמעותי לחברה. כדי להתמודד עם החדשות המזויפות האלה, נעשו מספר מחקרים על בניית דוגמני זיהוי ומארגנים קבוצות נתונים. רוב נתוני החדשות המזויפות תלויים בתקופה מסוימת של זמן. כתוצאה מכך, לדוגמאות הבדיקה מאומנות על קבוצת מידע כזו קשות לגלות חדשות מזויפות חדשות חדשות שנוצרות על ידי שינויים פוליטיים ושינויים חברתיים; הם עלולים להוביל תוצאה משותפת מהכניסה, כולל שמות אדם מסויימים ושמות ארגונים. אנו מתייחסים לבעיה הזאת כסבל דיאכרוני כי היא נגרמת על ידי תאריך יצירת חדשות בכל קבוצת נתונים. In this study, we confirm the bias, especially proper nouns including person names, from the deviation of phrase appearances in each dataset.  Based on these findings, we propose masking methods using Wikidata to mitigate the influence of person names and validate whether they make fake news detection models robust through experiments with in-domain and out-of-domain data.</abstract_he>
      <abstract_bo>སྐྱོན་བརྗོད་དེ་ནི་སྤྱི་ཚོགས་ལ་ཉུང་བའི་ཉེན་ཁ་གཏུག་པ་རེད། སྙིང་མེད་པའི་བརྡ་ཞིག་འདི་དག་ལ་བཤད་ན་ལྟ་བུའི་ནང་དུ་བསམ་བློ་གཏོང་གི་མིག་སྒྲིག སྐྱོ་བརྗོད་བྱས་བའི་ཆེ་ཆུང་གིས་དུས་ཚོད་དམིགས་བསལ་བྱེད་པ་དང་། དེར་བརྟེན། གསལ་བཤད་ཀྱི་མིག་གཟུགས་རིས་འདི་དག་གི་སྒྲིག་ཆ་འཕྲིན་ཡིག་ཆའི་འགྱུར་བ They may possibly result in biased output from the input, including specific person names and organizational names. ང་ཚོས་དཀའ་ངལ་འདི་ཆ་འཕྲིན་གྱི་བྱ་ཚིག་ལ་བཤད་ཀྱི་ཡོད། རྒྱུ་མཚན་ནི་འདི་གནས་སྡུད་ཚན་རེ་རེའི་ནང་དུ་གསར་འགོད ལྟ་བ་འདིའི་ནང་དུ་ང་ཚོས་རང་བཞིན་རྒྱུན་ལྡན་བྱེད་དགོས་མིང་དང་། ཁྱད་པར་མིང་གང་ཡིན་པའི་ནང་དུ་ཡིག་ཆའི་མིང་ཐུབ་ Based on these findings, we propose masking methods using Wikidata to mitigate the influence of person names and validate whether they make fake news detection models robust through experiments with in-domain and out-of-domain data.</abstract_bo>
      </paper>
    <paper id="24">
      <title>Changes in Twitter geolocations : Insights and suggestions for future usage<fixed-case>T</fixed-case>witter geolocations: Insights and suggestions for future usage</title>
      <author><first>Anna</first><last>Kruspe</last></author>
      <author><first>Matthias</first><last>Häberle</last></author>
      <author><first>Eike J.</first><last>Hoffmann</last></author>
      <author><first>Samyo</first><last>Rode-Hasinger</last></author>
      <author><first>Karam</first><last>Abdulahhad</last></author>
      <author><first>Xiao Xiang</first><last>Zhu</last></author>
      <pages>212–221</pages>
      <abstract>Twitter data has become established as a valuable source of data for various application scenarios in the past years. For many such <a href="https://en.wikipedia.org/wiki/Application_software">applications</a>, it is necessary to know where Twitter posts (tweets) were sent from or what location they refer to. Researchers have frequently used exact coordinates provided in a small percentage of tweets, but <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> removed the option to share these <a href="https://en.wikipedia.org/wiki/Coordinate_system">coordinates</a> in mid-2019. Moreover, there is reason to suspect that a large share of the provided coordinates did not correspond to <a href="https://en.wikipedia.org/wiki/Global_Positioning_System">GPS coordinates</a> of the user even before that. In this paper, we explain the situation and the 2019 policy change and shed light on the various options of still obtaining location information from <a href="https://en.wikipedia.org/wiki/Twitter">tweets</a>. We provide usage statistics including changes over time, and analyze what the removal of exact coordinates means for various common research tasks performed with Twitter data. Finally, we make suggestions for future research requiring geolocated tweets.</abstract>
      <url hash="80627891">2021.wnut-1.24</url>
      <bibkey>kruspe-etal-2021-changes</bibkey>
      <doi>10.18653/v1/2021.wnut-1.24</doi>
    <title_ar>التغييرات في المواقع الجغرافية على Twitter: رؤى واقتراحات للاستخدام المستقبلي</title_ar>
      <title_fr>Changements dans les géolocalisations Twitter : informations et suggestions pour une utilisation future</title_fr>
      <title_pt>Mudanças nas geolocalizações do Twitter: insights e sugestões para uso futuro</title_pt>
      <title_es>Cambios en las geolocalizaciones de Twitter: información y sugerencias para su uso futuro</title_es>
      <title_zh>Twitter 地理之变,未来之见也</title_zh>
      <title_ja>Twitterの地理的位置情報の変更：今後の使用に関する洞察と提案</title_ja>
      <title_ru>Изменения в геолокации Twitter: идеи и предложения для будущего использования</title_ru>
      <title_hi>चहचहाना geolocations में परिवर्तन: अंतर्दृष्टि और भविष्य के उपयोग के लिए सुझाव</title_hi>
      <title_ga>Athruithe i geoshuímh Twitter: Léargais agus moltaí maidir le húsáid sa todhchaí</title_ga>
      <title_ka>ცვლილებები Twitter-ის ჯეოლოგიაციებში: მომავალე გამოყენება</title_ka>
      <title_el>Αλλαγές στις γεωγραφικές τοποθεσίες του Twitter: Γνώσεις και προτάσεις για μελλοντική χρήση</title_el>
      <title_hu>Változások a Twitter földrajzi helyzetében: ismertetések és javaslatok a jövőbeli használatra</title_hu>
      <title_mk>Промени во геолокациите на Твитер: Нагледувања и предлози за идна употреба</title_mk>
      <title_lt>Twitter geolokacijos pokyčiai: Apžvalgos ir pasiūlymai dėl būsimo naudojimo</title_lt>
      <title_it>Modifiche nelle geolocalizzazioni di Twitter: approfondimenti e suggerimenti per l'utilizzo futuro</title_it>
      <title_kk>Твиттердің геоорналасуындағы өзгерістер</title_kk>
      <title_ms>Perubahan dalam lokasi geo Twitter: Penglihatan dan cadangan untuk penggunaan masa depan</title_ms>
      <title_ml>ടൂട്ടര്‍ ജോവിസ്ഥലങ്ങളില്‍ മാറ്റങ്ങള്‍: ഭാവിയുടെ ഉപയോഗിക്കുന്നതിനുള്ള ഉപദേശങ്ങള്‍</title_ml>
      <title_mn>Твиттерийн географийн өөрчлөлт: ирээдүйн хэрэглээний санал, санал</title_mn>
      <title_ro>Modificări în locațiile geografice Twitter: Informații și sugestii pentru utilizarea viitoare</title_ro>
      <title_pl>Zmiany geolokalizacji Twittera: Wglądy i sugestie dotyczące przyszłego wykorzystania</title_pl>
      <title_mt>Bidliet fil-ġeolokazzjonijiet ta’ Twitter: Ħarsiet u suġġerimenti għall-użu futur</title_mt>
      <title_no>Endringar i Twitter-geolokasjonar: Insights og forslag for framtidige bruk</title_no>
      <title_sr>Promjene u geolokacijama Twitter-a: Inzistencije i predlog za buduću upotrebu</title_sr>
      <title_si>ට්විටර් භාවිතයේ වෙනස් කරන්න: අනාගතයේ භාවිතය සඳහා ප්‍රශ්නය</title_si>
      <title_sv>Ändringar i Twitters geografiska placeringar: insikter och förslag för framtida användning</title_sv>
      <title_so>Isbedelka goobaha Twitterka: Insights and suggestions for future use</title_so>
      <title_ta>தொடர் புவியியல் இடங்களில் மாற்றங்கள்:</title_ta>
      <title_ur>ٹویٹر کے جئوپیٹ میں بدل جاتے ہیں: مستقبل استعمال کے لئے ابتداء اور پیشنهاد</title_ur>
      <title_vi>Thay đổi địa điểm trên Twitter: Chiếu sáng và gợi ý cho việc sử dụng tương lai</title_vi>
      <title_uz>Comment</title_uz>
      <title_nl>Wijzigingen in Twitter geolocaties: Inzichten en suggesties voor toekomstig gebruik</title_nl>
      <title_hr>Promjene u geolokacijama Twitter: Insights i predlog za buduću uporabu</title_hr>
      <title_bg>Промени в геолокациите на Видения и предложения за бъдеща употреба</title_bg>
      <title_id>Perubahan di geolokasi Twitter: Penglihatan dan saran untuk penggunaan masa depan</title_id>
      <title_fa>تغییرات در جایگاه‌های جغرافی توئیتر: بصیرت و پیشنهاد برای استفاده از آینده</title_fa>
      <title_sw>Mabadiliko katika maeneo ya Twita: Maoni na mapendekezo kwa matumizi ya baadaye</title_sw>
      <title_da>Ændringer i Twitter geografiske placeringer: Indsigt og forslag til fremtidig brug</title_da>
      <title_de>Änderungen an Twitter-Geolocations: Einblicke und Anregungen für die zukünftige Nutzung</title_de>
      <title_af>Veranderinge in Twitter geolokasies: Inligtings en voorstellings vir toekomstige gebruik</title_af>
      <title_ko>트위터의 지리적 위치 변화: 미래 사용에 대한 견해와 건의</title_ko>
      <title_tr>Twittertiň ýerlerinde üýtgewler: Gelecek ulanmak üçin pikirler we maslahatlar</title_tr>
      <title_sq>Ndryshime në gjeolokalimet e Twitter-it: Shikime dhe sugjerime për përdorimin e ardhshëm</title_sq>
      <title_am>የTwitter geolocations: Insights and recommendations for future use</title_am>
      <title_hy>Թվիթերի երկրագծերի փոփոխությունները. Ապագա օգտագործման դիտարկումներ և առաջարկներ</title_hy>
      <title_bs>Promjene u geolokacijama Twitter-a: Inzistencije i predlog za buduću upotrebu</title_bs>
      <title_az>Twitter geolokasiyalarında dəyişikliklər: Geləcək istifadə üçün nəsihətlər və təsirlər</title_az>
      <title_bn>টুইটারের ভৌগলিক অবস্থানে পরিবর্তন: ভবিষ্যতের ব্যবহারের জন্য দৃষ্টিভঙ্গি এবং পরামর্শ</title_bn>
      <title_ca>Cambis en les geolocalitzacions de Twitter: Vistes i suggericions per a l'ús futur</title_ca>
      <title_cs>Změny geolokací Twitteru: Přehledy a návrhy pro budoucí využití</title_cs>
      <title_et>Muudatused Twitteri asukohas: ülevaated ja ettepanekud tulevaseks kasutamiseks</title_et>
      <title_fi>Muutokset Twitterin sijainnissa: näkemyksiä ja ehdotuksia tulevaa käyttöä varten</title_fi>
      <title_he>שינויים במיקומים גיאומיים של טוויטר: נראות וההצעות לשימוש בעתיד</title_he>
      <title_jv>Tulung kanggo jeograhan Google</title_jv>
      <title_ha>Sauya cikin wurãro na Twitter:</title_ha>
      <title_sk>Spremembe geolokacij Twitterja: Vpogledi in predlogi za prihodnjo uporabo</title_sk>
      <title_bo>Changes in Twitter geolocations: Insights and suggestions for future usage</title_bo>
      <abstract_ar>أصبحت بيانات Twitter مصدرًا قيمًا للبيانات لسيناريوهات التطبيق المختلفة في السنوات الماضية. بالنسبة للعديد من هذه التطبيقات ، من الضروري معرفة مكان إرسال منشورات Twitter (التغريدات) أو الموقع الذي تشير إليه. كثيرًا ما استخدم الباحثون الإحداثيات الدقيقة المقدمة في نسبة صغيرة من التغريدات ، لكن تويتر أزال خيار مشاركة هذه الإحداثيات في منتصف عام 2019. علاوة على ذلك ، هناك سبب للشك في أن نسبة كبيرة من الإحداثيات المقدمة لا تتوافق مع إحداثيات GPS للمستخدم حتى قبل ذلك. في هذه الورقة ، نوضح الموقف وتغيير سياسة عام 2019 ونلقي الضوء على الخيارات المختلفة لاستمرار الحصول على معلومات الموقع من التغريدات. نحن نقدم إحصاءات الاستخدام بما في ذلك التغييرات بمرور الوقت ، ونحلل معنى إزالة الإحداثيات الدقيقة لمختلف مهام البحث الشائعة التي يتم إجراؤها باستخدام بيانات Twitter. أخيرًا ، نقدم اقتراحات للأبحاث المستقبلية التي تتطلب تغريدات محددة الموقع الجغرافي.</abstract_ar>
      <abstract_fr>Les données Twitter sont devenues une source de données précieuse pour divers scénarios d'application au cours des dernières années. Pour de nombreuses applications de ce type, il est nécessaire de savoir d'où les publications Twitter (tweets) ont été envoyées ou à quel endroit elles se réfèrent. Les chercheurs ont fréquemment utilisé les coordonnées exactes fournies dans un faible pourcentage de tweets, mais Twitter a supprimé l'option de partage de ces coordonnées à la mi-2019. De plus, il y a lieu de soupçonner qu'une grande partie des coordonnées fournies ne correspondaient pas aux coordonnées GPS de l'utilisateur avant cela. Dans cet article, nous expliquons la situation et le changement de politique de 2019 et nous éclairons les différentes options permettant d'obtenir des informations de localisation à partir de tweets. Nous fournissons des statistiques d'utilisation, y compris les changements au fil du temps, et analysons ce que signifie la suppression des coordonnées exactes pour diverses tâches de recherche courantes effectuées avec les données Twitter. Enfin, nous formulons des suggestions pour les recherches futures nécessitant des tweets géolocalisés.</abstract_fr>
      <abstract_pt>Os dados do Twitter se estabeleceram como uma fonte valiosa de dados para vários cenários de aplicativos nos últimos anos. Para muitos desses aplicativos, é necessário saber de onde as postagens do Twitter (tweets) foram enviadas ou a que local elas se referem. Os pesquisadores usaram frequentemente as coordenadas exatas fornecidas em uma pequena porcentagem de tweets, mas o Twitter removeu a opção de compartilhar essas coordenadas em meados de 2019. Além disso, há motivos para suspeitar que uma grande parte das coordenadas fornecidas não correspondia às coordenadas GPS do usuário mesmo antes disso. Neste artigo, explicamos a situação e a mudança de política de 2019 e esclarecemos as várias opções de ainda obter informações de localização de tweets. Fornecemos estatísticas de uso, incluindo alterações ao longo do tempo, e analisamos o que a remoção de coordenadas exatas significa para várias tarefas de pesquisa comuns realizadas com dados do Twitter. Por fim, fazemos sugestões para pesquisas futuras que requeiram tweets geolocalizados.</abstract_pt>
      <abstract_es>Los datos de Twitter se han establecido como una valiosa fuente de datos para diversos escenarios de aplicación en los últimos años. Para muchas de estas aplicaciones, es necesario saber desde dónde se enviaron las publicaciones de Twitter (tuits) o a qué ubicación se refieren. Los investigadores han utilizado con frecuencia las coordenadas exactas proporcionadas en un pequeño porcentaje de tuits, pero Twitter eliminó la opción de compartir estas coordenadas a mediados de 2019. Además, hay motivos para sospechar que una gran parte de las coordenadas proporcionadas no correspondía a las coordenadas GPS del usuario incluso antes de eso. En este artículo, explicamos la situación y el cambio de política de 2019 y arrojamos luz sobre las diversas opciones para seguir obteniendo información de ubicación de los tuits. Proporcionamos estadísticas de uso, incluidos los cambios a lo largo del tiempo, y analizamos lo que significa la eliminación de coordenadas exactas para varias tareas de investigación comunes realizadas con datos de Twitter. Por último, hacemos sugerencias para futuras investigaciones que requieran tuits geolocalizados.</abstract_es>
      <abstract_ja>Twitterのデータは、過去数年間に様々なアプリケーションシナリオのための貴重なデータソースとして確立されてきました。多くのこのようなアプリケーションでは、Twitterの投稿（ツイート）がどこから送信されたか、またはそれらが参照する場所を知る必要があります。研究者は、わずかな割合で提供された正確な座標を頻繁に使用してきたが、Twitterは2019年半ばにこれらの座標を共有するオプションを削除した。さらに、提供された座標の大部分が、それ以前であってもユーザのGPS座標に対応していなかったことを疑う理由がある。本稿では、状況と2019年の方針変更について説明し、ツイートから位置情報を引き続き取得するためのさまざまな選択肢について明らかにします。当社は、経時的な変化を含む使用統計を提供し、正確な座標の削除が、Twitterデータを使用して実行されるさまざまな一般的な研究タスクを意味することを分析します。最後に、地理的に位置するツイートを必要とする今後の研究について提案します。</abstract_ja>
      <abstract_hi>चहचहाना डेटा पिछले वर्षों में विभिन्न अनुप्रयोग परिदृश्यों के लिए डेटा के एक मूल्यवान स्रोत के रूप में स्थापित हो गया है। ऐसे कई अनुप्रयोगों के लिए, यह जानना आवश्यक है कि ट्विटर पोस्ट (ट्वीट्स) कहां से भेजे गए थे या वे किस स्थान का उल्लेख करते हैं। शोधकर्ताओं ने अक्सर ट्वीट्स के एक छोटे प्रतिशत में प्रदान किए गए सटीक निर्देशांक का उपयोग किया है, लेकिन ट्विटर ने 2019 के मध्य में इन निर्देशांकों को साझा करने के विकल्प को हटा दिया है। इसके अलावा, यह संदेह करने का कारण है कि प्रदान किए गए निर्देशांक का एक बड़ा हिस्सा इससे पहले भी उपयोगकर्ता के जीपीएस निर्देशांक के अनुरूप नहीं था। इस पेपर में, हम स्थिति और 2019 नीति परिवर्तन की व्याख्या करते हैं और ट्वीट्स से स्थान की जानकारी प्राप्त करने के विभिन्न विकल्पों पर प्रकाश डालते हैं। हम समय के साथ परिवर्तन सहित उपयोग के आंकड़े प्रदान करते हैं, और विश्लेषण करते हैं कि ट्विटर डेटा के साथ किए गए विभिन्न सामान्य शोध कार्यों के लिए सटीक निर्देशांक को हटाने का क्या मतलब है। अंत में, हम भविष्य के अनुसंधान के लिए सुझाव देते हैं, जिसके लिए जियोलोकेटेड ट्वीट्स की आवश्यकता होती है।</abstract_hi>
      <abstract_zh>于往数年之中,Twitter数已成诸宝数据源。 其于应用程序也,有必知Twitter帖(推文)所从来,或指其所在。 论人常用一小推文以给确坐标,然Twitter于2019年中删除共享此坐标之选项。 此外有疑,虽在前,坐标有大分,与用户GPS坐标不应。 于本文中,解释情2019之政变,并明仍于推文中取位信息诸选。 臣等计数信息,随时变化,剖析精确坐标于用 Twitter 数,常见究事。 最后,我们为要地理定位推文的未来讲议。</abstract_zh>
      <abstract_ru>В последние годы данные из "Твиттера" превратились в ценный источник данных для различных сценариев применения. Для многих таких приложений необходимо знать, откуда были отправлены сообщения в Twitter (твиты) или на какое место они ссылаются. Исследователи часто использовали точные координаты, указанные в небольшом проценте твитов, но Twitter исключил возможность поделиться этими координатами в середине 2019 года. Более того, есть основания подозревать, что большая доля предоставленных координат еще до этого не соответствовала GPS-координатам пользователя. В этой статье мы объясняем ситуацию и изменения в политике 2019 года и проливаем свет на различные варианты получения информации о местоположении из твитов. Мы предоставляем статистику использования, включая изменения с течением времени, и анализируем, что означает удаление точных координат для различных общих исследовательских задач, выполняемых с данными Twitter. Наконец, мы делаем предложения для будущих исследований, требующих геолокации твитов.</abstract_ru>
      <abstract_ga>Tá sonraí Twitter bunaithe anois mar fhoinse luachmhar sonraí le haghaidh cásanna éagsúla feidhmchláir le blianta beaga anuas. I gcás go leor feidhmchlár den sórt sin, ní mór fios a bheith agat cá as ar seoladh postálacha Twitter (tweets) nó cén suíomh a dtagraíonn siad dó. Is minic a d’úsáid taighdeoirí comhordanáidí cruinne a cuireadh ar fáil i gcéatadán beag de thíteanna, ach bhain Twitter an rogha chun na comhordanáidí sin a roinnt i lár na bliana 2019. Ina theannta sin, tá cúis ann a bheith in amhras nach raibh sciar mór de na comhordanáidí a soláthraíodh ag freagairt do chomhordanáidí GPS an úsáideora fiú roimhe sin. Sa pháipéar seo, mínímid an cás agus an t-athrú beartais in 2019 agus cuirimid in iúl dúinn na roghanna éagsúla a bhaineann le faisnéis suímh a fháil ó thvuíteanna fós. Cuirimid staitisticí úsáide ar fáil lena n-áirítear athruithe le himeacht ama, agus déanaimid anailís ar cad a chiallaíonn deireadh a chur le comhordanáidí beachta do thascanna taighde coitianta éagsúla a dhéantar le sonraí Twitter. Ar deireadh, déanaimid moltaí le haghaidh taighde amach anseo a éilíonn tweets geolocation.</abstract_ga>
      <abstract_ka>Twitter-ის მონაცემები უფრო მნიშვნელოვანი მონაცემების მსოფლიოდ მონაცემების გამოყენება შემდეგ წლის სენარიოში. ბევრი ასეთი პროგრამებისთვის, უნდა იცოდეთ, სად Twitter წერტილებები (tweets) გაგზავნილია ან სად ადგილზე, რომელსაც ისინი განსაზღვრებენ. პროცექტორები ძალიან გამოიყენებენ წარმოადგილი კოორდინტები, რომელიც ცოტა პროცენტის წარმოდგენა, მაგრამ Twitter გადასრულეთ ამ კოორდინტების გაყოფილი 2019-ის შუალში დამატებით, არსებობს მიზეზი, რომ მომხმარებლის GPS კოორდინატების დიდი ნაწილი არ შემდეგ. ამ დომენტში, ჩვენ განვიხსნა სიტაციას და 2019 წლის ცვლილებას და გადავიწყეთ განსხვავებული პარამეტრების შესახებ, რომელიც კონფიკაციის ინფორმაციის მიღება tweets ჩვენ გამოყენება სტატისტიკის შესახებ, რომელიც ცვლილებები დროში და ანალიზაცით რას ნიშნავს მარტივი კოორდინატების გამოყენება განსხვავებული სხვა საერთო სწავლა საბოლოოდ, ჩვენ ვაკეთებთ მომავალეთ სწავლებისთვის, რომელიც გეოლოგიზაციული რვიტები მოჭირდება.</abstract_ka>
      <abstract_el>Τα δεδομένα του Twitter έχουν καθιερωθεί ως πολύτιμη πηγή δεδομένων για διάφορα σενάρια εφαρμογής τα τελευταία χρόνια. Για πολλές τέτοιες εφαρμογές, είναι απαραίτητο να γνωρίζουμε από πού στάλθηκαν οι δημοσιεύσεις του ή σε ποια τοποθεσία αναφέρονται. Οι ερευνητές έχουν συχνά χρησιμοποιήσει ακριβείς συντεταγμένες που παρέχονται σε ένα μικρό ποσοστό των tweets, αλλά το Twitter αφαίρεσε την επιλογή να μοιραστεί αυτές τις συντεταγμένες στα μέσα του 2019. Επιπλέον, υπάρχει λόγος να υποψιαστούμε ότι μεγάλο μέρος των παρεχόμενων συντεταγμένων δεν αντιστοιχούσε στις συντεταγμένες GPS του χρήστη ακόμη και πριν από αυτό. Σε αυτή την εργασία, εξηγούμε την κατάσταση και την αλλαγή πολιτικής 2019 και ρίχνουμε φως στις διάφορες επιλογές λήψης πληροφοριών τοποθεσίας από τα tweets. Παρέχουμε στατιστικά στοιχεία χρήσης συμπεριλαμβανομένων αλλαγών με την πάροδο του χρόνου και αναλύουμε τι σημαίνει η αφαίρεση ακριβών συντεταγμένων για διάφορες κοινές ερευνητικές εργασίες που εκτελούνται με δεδομένα του Twitter. Τέλος, κάνουμε προτάσεις για μελλοντική έρευνα που απαιτεί γεωεντοπισμένα tweets.</abstract_el>
      <abstract_hu>Az elmúlt években a Twitter-adatok értékes adatforrásként alakultak ki a különböző alkalmazási forgatókönyvek számára. Sok ilyen alkalmazás esetében tudni kell, hogy honnan küldték a Twitter bejegyzéseket (tweetek), vagy hogy milyen helyre utalnak. A kutatók gyakran használták a tweetek kis százalékában megadott pontos koordinátákat, de a Twitter 2019 közepén eltávolította a koordináták megosztásának lehetőségét. Ezenkívül indokolt gyanítani, hogy a megadott koordináták nagy része még azelőtt sem felelt meg a felhasználó GPS koordinátáinak. Ebben a tanulmányban elmagyarázzuk a helyzetet és a 2019-es szakpolitikai változást, és rávilágítunk arra a különböző lehetőségekre, hogy továbbra is megszerezzük a helyadatokat tweetekből. Használati statisztikákat biztosítunk, beleértve az időbeli változásokat is, és elemezzük, mit jelent a pontos koordináták eltávolítása a Twitter-adatokkal végzett különböző általános kutatási feladatok során. Végezetül javaslatokat teszünk a jövőbeli kutatásokhoz, amelyek földrajzi elhelyezkedésű tweeteket igényelnek.</abstract_hu>
      <abstract_lt>Twitter data has become established as a valuable source of data for various application scenarios in the past years.  Daugeliui tokių paraiškų būtina žinoti, iš kur buvo išsiųsti Twitter postai (tweetai) arba kokia jų vieta. Mokslininkai dažnai naudojosi tiksliomis koordinatėmis, pateiktomis mažoje tweetų procentinėje dalyje, tačiau Twitter panaikino galimybę 2019 m. viduryje dalytis šiomis koordinatėmis. Be to, yra pagrindo įtarti, kad didelė dalis pateiktų koordinačių netgi anksčiau neatitinka naudotojo GPS koordinačių. Šiame dokumente paaiškiname padėtį ir 2019 m. politikos pokyčius ir paaiškiname įvairias galimybes gauti informaciją apie vietą iš tweetų. Pateikiame naudojimo statistiką, įskaitant pokyčius laikui bėgant, ir analizuojame, ką tikslių koordinačių pašalinimas reiškia įvairioms bendroms mokslinių tyrimų užduotims, atliekamoms naudojant Twitter duomenis. Galiausiai siūlome ateityje vykdyti mokslinius tyrimus, kuriuose reikalingi geologiniai tweetai.</abstract_lt>
      <abstract_it>Negli ultimi anni i dati di Twitter sono diventati una preziosa fonte di dati per vari scenari applicativi. Per molte di queste applicazioni, è necessario sapere da dove sono stati inviati i post di Twitter (tweet) o a quale luogo si riferiscono. I ricercatori hanno spesso utilizzato le coordinate esatte fornite in una piccola percentuale di tweet, ma Twitter ha rimosso l'opzione di condividere queste coordinate a metà 2019. Inoltre, c'è motivo di sospettare che una gran parte delle coordinate fornite non corrispondesse alle coordinate GPS dell'utente anche prima di allora. In questo articolo spieghiamo la situazione e il cambiamento politico del 2019 e facciamo luce sulle varie opzioni per ottenere ancora informazioni sulla posizione dai tweet. Forniamo statistiche di utilizzo, comprese le modifiche nel tempo, e analizziamo cosa significa la rimozione delle coordinate esatte per varie attività di ricerca comuni eseguite con i dati di Twitter. Infine, forniamo suggerimenti per ricerche future che richiedono tweet geolocalizzati.</abstract_it>
      <abstract_mk>Податоците на Твитер се воспоставени како вреден извор на податоци за различни сценарија за апликација во изминатите години. За многу вакви апликации е потребно да се знае од каде се испратени Твитер постови (твитови) или на која локација се посочуваат. Истражувачите често користат точни координати обезбедени во мал процент на твитови, но Твитер ја отстрани опцијата да ги сподели овие координати во средината на 2019 година. Покрај тоа, постои причина да се сомнева дека голем дел од обезбедените координати не се совпаѓаат со GPS координати на корисникот дури и пред тоа. Во овој весник ја објаснуваме ситуацијата и промената на политиката во 2019 година и ги објаснуваме различните опции за сé уште да се добијат информации за локацијата од твитовите. Ние обезбедуваме статистика за употреба вклучувајќи ги промените со текот на времето, и анализираме што значи отстранувањето на точните координати за различни заеднички истражувачки задачи извршени со податоци на Твитер. Конечно, даваме предлози за идните истражувања кои бараат геолоцирани твитови.</abstract_mk>
      <abstract_kk>Твиттер деректері өткен жылдар бойынша әртүрлі қолданбалардың сценариясының мәні деректер көзі ретінде орнатылды. Бұл бағдарламалардың көпшілігі үшін Твиттер жіберілген (tweets) жіберілген (tweets) жіберілген немесе олардың қай жерінен жіберілгенін білу керек. Исследоварлары көп жағдайда жалғыз пайызында tweets ортасында келтірілген координаттарды қолданады, бірақ Twitter бұл координаттарды 2019 жылдың ортасында ортақтастыру параметрін алып тастады. Келтірілген координаттардың үлкен бөлігі пайдаланушының GPS координаттарына бұрын да сәйкес келмегеніне күтпеу себебі бар. Бұл қағазда, 2019 жылы саясат өзгерістерін түсіндіреміз және әлі жерге мәліметті tweets-ден алу әртүрлі параметрлеріне жарық түсіндіреміз. Біз уақыт бойынша өзгерістерді қолдану статистикасын қамтамасыз етіп, Твиттер деректерімен жасалған әртүрлі зерттеу тапсырмаларының түрлі координаттарын алып тастау үшін анализ Соңында, біз географиялық тейтеттерді талап ететін болашақ зерттеулердің ұсыныстарын жасаймыз.</abstract_kk>
      <abstract_ms>Data Twitter telah ditetapkan sebagai sumber data yang berharga untuk pelbagai skenario aplikasi dalam tahun-tahun lepas. Untuk banyak aplikasi tersebut, perlu tahu di mana pos Twitter (tweet) dihantar dari atau lokasi yang mereka rujuk. Researchers have frequently used exact coordinates provided in a small percentage of tweets, but Twitter removed the option to share these coordinates in mid-2019.  Selain itu, terdapat sebab untuk mencurigai bahawa sebahagian besar koordinat yang diberikan tidak sepadan dengan koordinat GPS pengguna walaupun sebelum itu. Dalam kertas ini, kami menjelaskan situasi dan perubahan polisi 2019 dan memberi cahaya kepada pelbagai pilihan untuk masih mendapatkan maklumat lokasi dari tweet. Kami menyediakan statistik penggunaan termasuk perubahan melalui masa, dan menganalisis apa makna pembuangan koordinat tepat untuk pelbagai tugas kajian umum dilakukan dengan data Twitter. Akhirnya, kami membuat cadangan untuk kajian masa depan yang memerlukan tweet geolokasi.</abstract_ms>
      <abstract_ml>കഴിഞ്ഞ വര്‍ഷങ്ങളില്‍ വിവിധ പ്രയോഗങ്ങള്‍ക്ക് വേണ്ടി വിവിധ വിവരങ്ങളുടെ വിലപ്പെട്ട വിവരങ്ങളായി ടൂട്ടര ഇതുപോലുള്ള പല പ്രയോഗങ്ങള്‍ക്കും, ട്രൂട്ടര്‍ പോസ്റ്റുകള്‍ (ടൂട്ടുകള്‍) എവിടെനിന്നാണ് അയച്ചതെന്നോ അല്ലെങ്കില്‍ ഏത പരിശോധിക്കുന്നവര്‍ എപ്പോഴും കൃത്യമായ ക്രമീകരണങ്ങള്‍ ഉപയോഗിച്ചിരിക്കുന്നു. ചെറിയ ശതമാനത്തില്‍ ടൂട്ടറുകള്‍ ഉപയോഗിച്ചിരിക് ഇതിനു മുമ്പ് ഉപയോക്താവിന്റെ ജിപിസ് ക്രമീകരണങ്ങള്‍ക്ക് പ്രത്യേകിച്ചിട്ടില്ലെന്ന് സംശയിക്കാന്‍ കാരണമുണ്ട്. ഈ പത്രത്തില്‍ ഞങ്ങള്‍ സ്ഥിതിയും 2019 പോലീസിയും വിശദീകരിക്കുകയും ടൂട്ടുകളില്‍ നിന്നും വിവിധ വിവരങ്ങള്‍ ലഭിക്കുകയും ചെയ്യു സമയത്തിനുമുമ്പ് മാറ്റങ്ങള്‍ ഉള്ള ഉപയോഗിക്കുന്ന വിവരങ്ങള്‍ ഞങ്ങള്‍ നല്‍കുന്നു. കൃത്യമായ ക്രമീകരണങ്ങള്‍ നീക്കം ചെയ്യുന്നതിന്‍ അവസാനം, ഭാവിയുടെ പരിശോധനത്തിന് വേണ്ടി നമ്മള്‍ പരാമര്‍ശിക്കുന്നു.</abstract_ml>
      <abstract_mt>Id-dejta fuq Twitter saret stabbilita bħala sors ta’ dejta ta’ valur għal diversi xenarji ta’ applikazzjoni fl-a ħħar snin. Għal ħafna applikazzjonijiet bħal dawn, huwa meħtieġ li wieħed ikun jaf minn fejn intbagħtu postijiet ta’ Twitter (tweets) jew minn fejn jirreferu. Ir-riċerkaturi ta’ spiss użaw koordinati eżatti pprovduti f’perċentwal żgħir ta’ tweets, iżda Twitter neħħa l-għa żla li jaqsmu dawn il-koordinati f’nofs l-2019. Barra minn hekk, hemm raġuni biex wieħed jissuspetta li sehem kbir mill-koordinati pprovduti ma jikkorrispondix mal-koordinati GPS tal-utent anke qabel dan. F’dan id-dokument, aħna nispjegaw is-sitwazzjoni u l-bidla fil-politika tal-2019 u nieħdu dawl fuq l-għażliet varji li għadhom jiksbu informazzjoni dwar il-post minn tweets. Aħna nipprovdu statistika dwar l-użu inkluż bidliet maż-żmien, u nianalizzaw x’tfisser it-tneħħija ta’ koordinati eżatti għal diversi kompiti ta’ riċerka komuni mwettqa bid-dejta ta’ Twitter. Fl-aħħar nett, nagħmlu suġġerimenti għal riċerka futura li teħtieġ tweets ġeolokati.</abstract_mt>
      <abstract_pl>W ostatnich latach dane z Twittera stały się cennym źródłem danych dla różnych scenariuszy zastosowań. W przypadku wielu takich aplikacji konieczne jest, aby wiedzieć, skąd zostały wysłane posty na Twitterze lub do jakiej lokalizacji się odnoszą. Naukowcy często używali dokładnych współrzędnych podanych w niewielkim odsetku tweetów, ale Twitter usunął opcję udostępniania tych współrzędnych w połowie 2019. Ponadto istnieje powód do podejrzenia, że duża część podanych współrzędnych nie odpowiadała współrzędnym GPS użytkownika jeszcze wcześniej. W niniejszym artykule wyjaśniamy sytuację i zmianę polityki 2019 oraz rzucamy światło na różne opcje pozyskiwania informacji o lokalizacji z tweetów. Dostarczamy statystyki użytkowania, w tym zmiany z biegiem czasu, oraz analizujemy, co oznacza usunięcie dokładnych współrzędnych dla różnych powszechnych zadań badawczych wykonywanych za pomocą danych Twittera. Wreszcie proponujemy przyszłe badania wymagające geolokalizacji tweetów.</abstract_pl>
      <abstract_mn>Твиттер өгөгдлийн мэдээллийг өнгөрсөн жилд олон хэрэглээний хувилбаруудын үнэ цэнэтэй эх үүсвэр болсон. Ийм олон хэрэглэгчдийн хувьд Твиттерийн хуудас (tweets) хаанаас явуулсан эсвэл хаанаас харуулсан талаар мэдэх хэрэгтэй. Судлаачид жижиг хувь нь tweets-ээр хангалттай тодорхой координатуудыг ихэвчлэн ашигладаг. Гэхдээ Twitter 2019 оны дунд эдгээр координатуудыг хуваалцах сонголтыг устгасан. Үүнээс ч өмнө нь хэрэглэгчийн GPS координатуудын ихэнх хэсэг байхгүй гэдгийг ойлгох шалтгаан байна. Энэ цаасан дээр бид нөхцөл байдал болон 2019 оны бодлогын өөрчлөлтийг тайлбарлаж, tweets-ээс мэдээллийг олох олон сонголтуудыг гэрэлтүүлсэн. Бид цаг хугацаанд өөрчлөлтүүдийг ашиглах статистикийг хангаж, Твиттерийн мэдээллээр хийгдсэн олон нийтийн судалгааны ажлын хувьд яг л координатуудыг устгах юу гэсэн үг вэ гэдгийг шинжилгээ хий Эцэст нь бид ирээдүйн судалгаанд географийн бичлэгүүд хэрэгтэй санал өгдөг.</abstract_mn>
      <abstract_ro>Datele Twitter au devenit o sursă valoroasă de date pentru diferite scenarii de aplicații în ultimii ani. Pentru multe astfel de aplicații, este necesar să știți de unde au fost trimise postările Twitter (tweets-uri) sau la ce locație se referă. Cercetătorii au folosit frecvent coordonatele exacte furnizate într-un procent mic de tweet-uri, dar Twitter a eliminat opțiunea de a partaja aceste coordonate la mijlocul anului 2019. Mai mult, există motive să suspectăm că o mare parte din coordonatele furnizate nu corespundeau coordonatelor GPS ale utilizatorului chiar înainte de aceasta. În această lucrare, explicăm situația și schimbarea politicii din 2019 și facem lumină asupra diferitelor opțiuni de a obține în continuare informații despre locație din tweet-uri. Furnizăm statistici de utilizare, inclusiv modificări în timp, și analizăm ce înseamnă eliminarea coordonatelor exacte pentru diferite sarcini comune de cercetare efectuate cu datele Twitter. În cele din urmă, facem sugestii pentru cercetările viitoare care necesită tweet-uri geolocalizate.</abstract_ro>
      <abstract_no>Twitter-data er sett opp som eit verdileg kjelde for data for ulike program-scenarioar i siste år. For mange slike program er det nødvendig å vite kor Twitter-post (tweets) vert sendt frå eller kva plassering dei refererer til. Forskere har ofte brukt nøyaktige koordinatar som er tilgjengelege i ein liten prosent av tweet, men Twitter fjerna valet for å dele desse koordinatane i midten av 2019. Det finst også grunn til å tvinge at ein stor del av de oppgjevne koordinatene ikkje tilsvarar GPS-koordinatene til brukaren sjølv før det. I denne papiret forklarer vi situasjonen og endringane av politikk 2019 og lager lys på ulike innstillingane for å framleis få informasjon om stad frå tweets. Vi gjev brukstatistikk, inkludert endringar over tid, og analyser kva for å fjerna nøyaktige koordinata betyr for ulike felles forskningsoppgåver utført med Twitter-data. Til slutt lager vi forslag for framtidige forskning som krev geolokarte tweeter.</abstract_no>
      <abstract_si>ට්විටර් දත්ත ස්ථාපනය කරලා තියෙන්නේ අවුරුදු අවුරුදු වලින් විවිධ අනුවිධ අනුවිධ අනුවිධ අනිවාර්ය භාවිතානයක් වෙනුවෙන්, ට්විටර් පොස්ට්ස් (ට්විට්) කොහෙන්ද පැත්තුවේ නැත්තම් එයාලා කොහෙන විශ්වාස කරුණාකරුන්ට පොඩි ප්‍රතිශාතයක් ටිවිට් වලින් ප්‍රතිශේෂකයෙන් ප්‍රයෝජනය කරලා තියෙනවා, ඒත් ටිවිටර්  ඒවගේම, පෙන්වන්න පුළුවන් ප්‍රයෝජකයාගේ GPS කෝඩියෝන්ස් එක්ක ඒකට කලින් සම්බන්ධ වෙන්නේ නැති කියලා සැක මේ පත්තරේ අපි තත්වය සහ 2019 පොලිසි වෙනස් කරනවා සහ තාමත් තැන තොරතුරු තේරුම් ගන්න තියෙන්නේ විවිධ විකල්පයක්  අපි පරීක්ෂණ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණ පරීක්ෂණය සමග වෙනස් වෙනුවෙන් සමග විශ්ලේෂණය කරනවා, සමග විශේෂණය අන්තිමේදි, අපි අනාගතයේ පරීක්ෂණය සඳහා ප්‍රශ්නයක් කරනවා ජෝයෝජාතික ට්විට් වලට.</abstract_si>
      <abstract_sv>Twitter-data har under de senaste åren etablerats som en värdefull datakälla för olika applikationsscenarier. För många sådana applikationer är det nödvändigt att veta var Twitter-inlägg (tweets) skickades från eller vilken plats de hänvisar till. Forskare har ofta använt exakta koordinater som anges i en liten andel tweets, men Twitter tog bort möjligheten att dela dessa koordinater i mitten av 2019. Dessutom finns det anledning att misstänka att en stor del av de angivna koordinaterna inte motsvarade användarens GPS-koordinater redan innan dess. I denna uppsats förklarar vi situationen och policyförändringen 2019 och belyser de olika alternativen för att fortfarande få platsinformation från tweets. Vi tillhandahåller användningsstatistik inklusive förändringar över tid och analyserar vad borttagning av exakta koordinater innebär för olika vanliga forskningsuppgifter som utförs med Twitter-data. Slutligen ger vi förslag till framtida forskning som kräver geolokaliserade tweets.</abstract_sv>
      <abstract_sr>Twitter podaci su postavljeni kao vrijedan izvor podataka za različite scenarije aplikacije u proteklih godina. Za mnoge takve aplikacije, potrebno je znati odakle su poslani Twitter posti (tweets) ili odakle se odnose na lokaciju. Istraživači su često koristili tačne koordinate koje su pružene u malom procenatu tweeta, ali Twitter je uklonio opciju da podijeli te koordinate sred 2019. godine. Osim toga, postoji razlog da sumnjamo da veliki deo osiguranih koordinata nisu odgovarali GPS koordinatima korisnika čak i prije toga. U ovom papiru objašnjavamo situaciju i promjenu politike 2019. i osvetljavamo različite opcije da još uvek dobijemo informacije o lokaciji iz tweets. Mi pružamo statistiku korištenja uključujući izmjene tijekom vremena, i analiziramo šta uklanjanje tačnih koordinata znači za različite zajedničke istraživačke zadatke izvršene sa podacima Twitter. Konačno predlažemo buduće istraživanje koje zahtevaju geolokacione tweets.</abstract_sr>
      <abstract_ur>ٹویٹر ڈیٹا پچھلے سالوں میں مختلف کاربرد سناریوں کے لئے ایک ارزش دار ڈیٹا کا سورج بنا دیا گیا ہے. بہت سی ایسی کاربریوں کے لئے یہ ضرورت ہے کہ جان لیں کہ ٹویٹر پوسٹ (ٹیوٹ) کو کہاں سے بھیجے گئے یا کس جگہ سے وہ کہتے ہیں۔ تحقیقات کرنے والوں نے بہت زیادہ توئیٹوں کے اندر ایک چھوٹے فیصد میں سفارش کیے ہیں، لیکن توئیٹر نے 2019 کے درمیان ان ان coordinates کا شریک کرنے کے لئے اختیار کو دور کردیا ہے. اور اس سے پہلے بھی یوسف کے GPS koordinates کے مطابق شک کرنے کا سبب ہے۔ اس کاغذ میں، ہم نے وضعیت اور 2019 سیاسی تغییرات کی توضیح دی اور ٹویٹوں سے جگہ معلومات حاصل کرنے کی مختلف اختیاروں پر روشنی دی۔ ہم وقت میں تغییرات کے ساتھ استعمال کی آمار دیتے ہیں، اور ٹویٹر ڈاٹی کے ساتھ کیا معلوم ہے کہ دقیق koordinates کو ہٹانے کا مطلب کیا ہے؟ بالآخر، ہم آینده تحقیقات کے لئے پیشنهاد کرتے ہیں جو جئولیٹ ٹیوٹ کی ضرورت ہے.</abstract_ur>
      <abstract_so>Twitter data has become established as a valuable source of data for various application scenarios in the past years.  Waxaad u baahan tahay in aad ogaato meesha ay ka soo direen warqadaha Twitterka (twitter) ama meesha ay looga jeedo. Baaritaanayaal inta badan waxay isticmaaleen koorsooyin sax ah oo ku qoran boqolkiiba yar oo tweetka, laakiin Twitter ayaa ka qaaday fursadii uu koorsooyinkaas qaybsado sanadkii 2019 dhexe. Sidoo kale waxaa jirta sabab aad uga shakiso in kooxerooyin badan oo la siiyay aysan u dhigin kooxerooyinka GPS ee isticmaalaha, xataa horay. Warqadan ayaannu ku caddaynaynaa xaaladda iyo beddelka siyaasada 2019, waxaana ku qoraynaa iftiin fursad kala duduwan oo ay weli ka heli karto macluumaadka degmada ee Tweetka. Takyaatarada isticmaalka waxaan siinaynaa, kuwaas oo ah beddelka wakhtiga dheer, waxaana baaritaannaa in la soo qaado kooxaha si rasmi ah looga jeedo shaqooyin kala duduwan oo waxbarasho ah oo lagu sameeyo macluumaadka Twitterka. Ugu dambaysta, waxaynu soo jeedinnaa in baaritaanka mustaqbalka ah looga baahan yahay tweeti meelaha lagu qoray.</abstract_so>
      <abstract_ta>முந்தைய ஆண்டுகளில் பல பயன்பாட்டு காட்சிகளுக்கான தரவு மூலமாக துவக்கப்பட்டுள்ளது. இது போன்ற பல பயன்பாடுகளுக்கு, Twitter posts (tweets) எங்கிருந்து அல்லது என்ன குறிப்பிடுகிறது என்பதை அறிய வேண்டும். ஆராய்ச்சியாளர்கள் வழங்கப்பட்ட ஒரு சிறிய விழுக்காட்டில் சரியான ஒருங்கிணைப்புகளை பயன்படுத்தி இருக்கின்றனர், ஆனால் தொடர்பு 201 மேலும், வழங்கப்பட்ட ஒருங்கிணைப்புகளில் பெரிய ஒருங்கிணைப்புகள் ஜிபிஎஸ் ஒருங்கிணைப்பை பயன்படுத்துபவருக்கு முன்பு இந்த காகிதத்தில், நாம் நிலைமை மற்றும் 2019 கொள்கை மாற்றம் விளக்குகிறோம் மற்றும் தேர்வுகளை இன்னும் இருந்து இருந்த நாம் பயன்பாட்டு புள்ளிவிவரங்களை வழங்குகிறோம், மேலும் மாற்றங்களைச் சேர்த்து, சரியான ஒருங்கிணைப்பை நீக்குவது என்னவென இறுதியாக, நாம் எதிர்காலத்திற்கு ஆராய்ச்சிக்கு பரிந்துரைப்புகள் செய்கிறோம் புவியியல்</abstract_ta>
      <abstract_uz>@ info: whatsthis Ko'pchilik dasturlar uchun Twitter postlari (Twitter) qanday yoki qanday manzilga ega bo'lganligini bilish kerak. Taʼminlovchilar oddiy foydalanuvchilar Twitterdan kichkina foiz bilan bir foiz qoidalardan foydalanadi, lekin Twitterda 2019-yilda bu koordinatalarni qayta qilish imkoniyatini olib tashlaydi. Koʻrsatilgan bir nechta bir nechta koordinata foydalanuvchi GPS koordinatoriga ishonch kelmaydi. Bu hujjatda, biz holatni va 2019 qoidagi o'zgarishni o'rganamiz va Twitterdan boshqa manzil maʼlumotni olish uchun boshqa parametrlarni ko'rsamiz. Biz foydalanuvchining statistikasi, vaqtdan ortiq o'zgarishlarni qo'shish mumkin va Twitter maʼlumoti bilan bajarilgan har xil taʼminlovchi tashkilotlarni olib tashlashga qanday narsalarni aniqlash mumkin. Endi, biz kelajakdagi o'rganishni tasavvur qilamiz. Joyalangan tweetilar kerak bo'lgan.</abstract_uz>
      <abstract_vi>Twitter đã trở thành một nguồn dữ liệu đáng giá cho các viễn cảnh ứng dụng khác nhau trong những năm qua. Đối với nhiều ứng dụng như vậy, cần phải biết những bài đăng trên Twitter được gửi từ đâu hoặc nơi nào họ liên quan. Các nhà nghiên cứu thường sử dụng tọa độ chính xác được cung cấp trong một phần trăm nhỏ các tweet, nhưng Twitter đã xóa bỏ khả năng chia sẻ tọa độ này ở giữa-209. Hơn nữa, có lý do để nghi ngờ rằng một phần lớn của tọa độ cung cấp không tương ứng với tọa độ GPS của người dùng trước đó. Trong tờ báo này, chúng tôi giải thích tình hình và thay đổi chính sách ở 99 và làm sáng tỏ các lựa chọn khác nhau về việc lấy thông tin địa điểm trên Twitter. Chúng tôi cung cấp thống kê sử dụng, bao gồm thay đổi theo thời gian, và phân tích những tọa độ chính xác có nghĩa là gì cho các công việc nghiên cứu chung được thực hiện với dữ liệu Twitter. Cuối cùng, chúng tôi đưa ra gợi ý cho nghiên cứu tương lai đòi hỏi tweet.</abstract_vi>
      <abstract_da>Twitter data er blevet etableret som en værdifuld datakilde for forskellige applikationsscenarier i de seneste år. For mange sådanne applikationer er det nødvendigt at vide, hvor Twitter-indlæg (tweets) blev sendt fra, eller hvilket sted de henviser til. Forskere har ofte brugt nøjagtige koordinater angivet i en lille procentdel af tweets, men Twitter fjernede muligheden for at dele disse koordinater i midten af 2019. Desuden er der grund til at mistænke, at en stor del af de angivne koordinater ikke svarede til brugerens GPS-koordinater endnu før. I denne artikel forklarer vi situationen og politiske ændringer i 2019 og kaster lys over de forskellige muligheder for stadig at få lokaliseringsoplysninger fra tweets. Vi leverer brugsstatistikker, herunder ændringer over tid, og analyserer, hvad fjernelse af nøjagtige koordinater betyder for forskellige almindelige forskningsopgaver, der udføres med Twitter-data. Endelig kommer vi med forslag til fremtidig forskning, der kræver geolokaliserede tweets.</abstract_da>
      <abstract_nl>Twitter data is de afgelopen jaren een waardevolle bron van gegevens geworden voor verschillende toepassingsscenario's. Voor veel dergelijke toepassingen is het noodzakelijk om te weten waar Twitter posts (tweets) vandaan zijn verzonden of naar welke locatie ze verwijzen. Onderzoekers hebben vaak gebruik gemaakt van exacte coördinaten in een klein percentage tweets, maar Twitter verwijderde de optie om deze coördinaten halverwege 2019 te delen. Bovendien is er reden om te vermoeden dat een groot deel van de verstrekte coördinaten nog niet overeenkwam met GPS-coördinaten van de gebruiker. In dit artikel leggen we de situatie en de beleidswijziging 2019 uit en werpen we licht op de verschillende opties om nog locatiegegevens te verkrijgen via tweets. We leveren gebruiksstatistieken, inclusief veranderingen in de loop van de tijd, en analyseren wat het verwijderen van exacte coördinaten betekent voor verschillende gemeenschappelijke onderzoekstaken uitgevoerd met Twitter-gegevens. Tot slot doen we suggesties voor toekomstig onderzoek dat geolocated tweets vereist.</abstract_nl>
      <abstract_hr>Twitter podaci su postavljeni kao vrijedan izvor podataka za različite scenarije prijave u proteklih godina. Za mnoge takve aplikacije, potrebno je znati odakle su poslani Twitter postovi (tweets) ili odakle se odnose na lokaciju. Istraživači su često koristili to čne koordinate koje su pružene u malim procenatu tweeta, ali Twitter je uklonio opciju da podijeli te koordinate u sredini 2019. godine. Osim toga, postoji razlog sumnjati da veliki dio određenih koordinata nisu odgovarali GPS koordinatima korisnika čak i prije toga. U ovom papiru objašnjavamo situaciju i promjenu politike 2019. godine i osvjetljavamo različite opcije dobivanja informacija o lokaciji iz tweets. Mi pružamo statistiku korištenja uključujući izmjene tijekom vremena i analiziramo što uklanjanje točnih koordinata znači za različite zajedničke istraživačke zadatke izvršene s podacima Twitter. Konačno predložimo buduće istraživanje koje zahtijevaju geolokacione tweets.</abstract_hr>
      <abstract_bg>Данните в Туитър се утвърдиха като ценен източник на данни за различни сценарии на приложение през последните години. За много такива приложения е необходимо да знаете откъде са изпратени публикациите в Туитър (туитове) или на какво място се отнасят. Изследователите често използват точни координати, предоставени в малък процент от туитовете, но в средата на 2019 г. премахна възможността да споделя тези координати. Освен това има основание да се подозира, че голяма част от предоставените координати не съответстват на координатите на потребителя още преди това. В тази статия обясняваме ситуацията и промяната в политиката през 2019 г. и хвърляме светлина върху различните възможности за все още получаване на информация за местоположението от туитове. Ние предоставяме статистика за използването, включително промени във времето, и анализираме какво означава премахването на точни координати за различни общи изследователски задачи, извършвани с данни в Туитър. И накрая, правим предложения за бъдещи изследвания, изискващи геолокализирани туитове.</abstract_bg>
      <abstract_ko>지난 몇 년 동안 트위터 데이터는 각종 응용 장면의 귀중한 데이터 원천이 되었다.많은 이런 앱들은 트위터 게시물(twitters)이 어디에서 발송되었는지, 어떤 위치를 가리키는지 알 필요가 있다.연구진은 추문에서 제공한 정확한 좌표 일부를 자주 사용하지만, 추문은 2019년 중 이들 좌표를 공유하는 옵션을 없앴다.또 그 이전에도 제공된 좌표 중 상당 부분이 사용자의 GPS 좌표와 일치하지 않았다고 의심할 이유가 있다.본고에서 우리는 이러한 상황과 2019년의 정책 변화를 설명하고 여전히 트윗에서 위치 정보를 얻을 수 있는 다양한 선택을 천명했다.시간에 따른 변화를 포함한 사용 통계 데이터를 제공하고 트위터 데이터로 수행되는 다양한 흔한 연구 임무에 대한 정확한 좌표 삭제가 무엇을 의미하는지 분석합니다.마지막으로 우리는 지리적 포지셔닝 추문이 필요한 미래 연구에 대해 건의를 한다.</abstract_ko>
      <abstract_id>Data Twitter telah menjadi sumber data yang berharga untuk berbagai skenario aplikasi di tahun-tahun terakhir. Untuk banyak aplikasi seperti itu, perlu tahu dari mana posting Twitter (tweet) dikirim atau lokasi yang mereka sebutkan. Peneliti sering menggunakan koordinat tepat yang diberikan dalam persentase kecil dari tweet, tapi Twitter menghapus pilihan untuk berbagi koordinat ini di tengah-2019. Moreover, there is reason to suspect that a large share of the provided coordinates did not correspond to GPS coordinates of the user even before that.  Dalam kertas ini, kami menjelaskan situasi dan perubahan kebijakan 2019 dan memberi cahaya pada berbagai pilihan untuk masih mendapatkan informasi lokasi dari tweet. Kami menyediakan statistik penggunaan termasuk perubahan melalui waktu, dan menganalisis apa artinya penghapusan koordinat tepat untuk berbagai tugas penelitian umum yang dilakukan dengan data Twitter. Akhirnya, kami membuat saran untuk penelitian masa depan yang membutuhkan tweet geolokasi.</abstract_id>
      <abstract_de>Twitter-Daten haben sich in den vergangenen Jahren als wertvolle Datenquelle für verschiedene Anwendungsszenarien etabliert. Für viele solche Anwendungen ist es notwendig zu wissen, woher Twitter-Beiträge (Tweets) gesendet wurden oder auf welchen Ort sie sich beziehen. Forscher haben häufig exakte Koordinaten verwendet, die in einem kleinen Prozentsatz der Tweets angegeben werden, aber Twitter hat die Option entfernt, diese Koordinaten Mitte 2019 zu teilen. Darüber hinaus besteht Grund zu der Annahme, dass ein großer Teil der bereitgestellten Koordinaten noch nicht den GPS-Koordinaten des Nutzers entsprach. In diesem Beitrag erläutern wir die Situation und die Änderung der Richtlinie 2019 und beleuchten die verschiedenen Möglichkeiten, noch Standortinformationen aus Tweets zu erhalten. Wir erstellen Nutzungsstatistiken einschließlich Änderungen im Laufe der Zeit und analysieren, was das Entfernen exakter Koordinaten für verschiedene gemeinsame Forschungsaufgaben mit Twitter-Daten bedeutet. Schließlich machen wir Vorschläge für zukünftige Forschungen, die geolokalisierte Tweets erfordern.</abstract_de>
      <abstract_fa>داده‌های توئیتر در سال گذشته به عنوان منبع ارزشمند داده‌ها برای سناریوهای مختلف کاربرد ساخته شده است. برای بسیاری از این کاربردها، لازم است بدانید که از کجا می‌فرستند و از کجا می‌گویند. تحقیقات کنندگان اغلب در درصد کوچک از tweets استفاده می‌کنند، ولی توئیتر گزینه‌ای را برای تقسیم این coordinates در نیمه ۲۰۱۹ حذف کرد. علاوه بر این، دلیل وجود دارد که مظنون باشید که یک بخش بزرگی از koordinاتهای پیشنهاد با koordinاتهای GPS از کاربر حتی قبل از آن هم نسبت به آن نیست. در این کاغذ، ما موقعیت و تغییرات سیاست ۲۰۱۹ را توضیح می‌دهیم و روشن می‌کنیم بر گزینه‌های مختلف اطلاعات جایگاهی که هنوز از توئیت می‌گیریم. ما آمار استفاده را به عنوان تغییرات در طول زمان تغییر می دهیم، و تحلیل می کنیم که حذف koordinاتهای دقیق برای کار تحقیقات مشترک با داده های توئیتر چه معنی دارد. بالاخره، ما برای تحقیقات آینده پیشنهاد می‌کنیم که نیاز به توئیت‌های جغرافی وجود دارد.</abstract_fa>
      <abstract_sw>Takwimu za Twita zimeanzishwa kama chanzo cha taarifa muhimu kwa matukio mbalimbali ya matumizi katika miaka iliyopita. Kwa matumizi mengi kama hayo, ni muhimu kujua wapi makala za Twita (twita) zilitumwa kutoka au sehemu gani wanayoiita. Watafiti mara nyingi wametumia uratibu sahihi uliotolewa katika asilimia ndogo ya twiti, lakini Twita iliondoa chaguo la kushirikisha uratibu huu katikati ya mwaka 2019. Zaidi ya hayo, kuna sababu ya kudhani kuwa sehemu kubwa ya uratibu uliotolewa haijajibu uratibu wa GPS wa mtumiaji hata kabla ya hilo. Katika karatasi hii, tunaeleza hali hii na mabadiliko ya sera ya mwaka 2019 na kuonyesha mwangaza wa namna mbalimbali za kuendelea kupata taarifa kutoka kwenye twita. Tunatoa takwimu za matumizi ikiwa ni pamoja na mabadiliko ya muda mrefu, na anachambua kile kinachoondolewa kwa uratibu sahihi ni maana ya kazi mbalimbali za utafiti zilizofanyika kwa takwimu za Twita. Mwisho, tunapendekeza tafiti za baadaye zinazohitaji twiti zilizoko eneo hilo.</abstract_sw>
      <abstract_tr>Twitter maglumaty geçen ýyllar içinde näçe uygulama senaryony üçin değerli bir çeşme hasaplanýar. Şol ýaly köpürler üçin Twitter postalarynyň (tweets) nireden gönderildigini ýa-da nähili ýerinden gönderildigini bilmek gerek. Araştyranlar köplenç tweets ýüzünde berilýän takyk koordinatlary ulanýarlar, ýöne Twitter 2019-njy ortasynda bu koordinatlary paylaşmak üçin seçenekleri çykardy. Munuň üçin bellenen koordinatlaryň uly bölegi özünden öň hem Ullançylaryň GPS koordinatlara meňzeşligi ýok diýip şübhelenmek üçin bir sebäbi bar. Bu kagyzda, biz durumyny we 2019-njy politika üýtgetmegini we tweets-lerden ýer maglumaty almak üçin dürli seçeneklerde aydyrýarys. Biz wagtyň arasynda üýtgewler bilen ulanmak istatistiklerini saýlaýrys we Twitter maglumaty bilen edilen düzgün koordinatlaryň çykarmasının nähili adil edildiğini çözümleýäris. Soňunda, gelejekki araştyrmalaryň geoýe-ýerleşýän tweetlere gerek maslahat berýäris.</abstract_tr>
      <abstract_sq>Twitter data has become established as a valuable source of data for various application scenarios in the past years.  Për shumë aplikime të tilla, është e domosdoshme të dini nga janë dërguar postimet e Twitter-it (tweets) ose nga ku referohen. Kërkimtarët shpesh kanë përdorur koordinatat e sakta të dhëna në një përqindje të vogël të tweeteve, por Twitter hoqi opsionin për të ndarë këto koordinata në mes të 2019. Përveç kësaj, ka arsye për të dyshuar se një pjesë e madhe e koordinatave të ofruara nuk korrespondonte me koordinatat GPS të përdoruesit edhe më parë. Në këtë letër, ne shpjegojmë gjendjen dhe ndryshimin e politikës 2019 dhe hedhim dritë mbi opsionet e ndryshme të marrjes së informacionit të vendndodhjes nga tweetet. Ne ofrojmë statistika përdorimi duke përfshirë ndryshime gjatë kohës dhe analizojmë se çfarë do të thotë heqja e koordinatave ekzakte për detyra të ndryshme të përbashkëta kërkimi të kryera me të dhënat e Twitter. Më në fund, ne bëjmë sugjerime për kërkimet e ardhshme që kërkojnë tweet gjeolokuar.</abstract_sq>
      <abstract_hy>Twitter data has become established as a valuable source of data for various application scenarios in the past years.  Շատ այդպիսի ծրագրերի համար անհրաժեշտ է իմանալ, թե որտեղից են ուղարկվել Թվիթերի (թվիթերի) տեղադրությունները կամ որտեղից են դրանք նշանակում: Հետազոտողները հաճախ օգտագործել են ճշգրիտ կոորդինատներ, որոնք տրվում են թվիթերի փոքր տոկոսով, բայց Թվիթերը հեռացրեց 2019 թվականի կեսին այս կոորդինատները կիսվելու ընտրությունը: Ավելին, կա պատճառ կասկածել, որ տրամադրված կոորդինատների մեծ մասը չի համապատասխանում օգտագործողի GPS կոորդինատներին նույնիսկ նախքան դա: Այս թղթի մեջ մենք բացատրում ենք իրավիճակը և 2019 թվականի քաղաքականության փոփոխությունը և լուսավորում ենք տարբեր տարբերակները՝ մինչ այժմ տեղեկատվություն ստանալու թվիթերից: Մենք տրամադրում ենք օգտագործման վիճակագրություն, ներառյալ փոփոխությունները ժամանակի ընթացքում, և վերլուծում ենք, թե ինչ է նշանակում ճշգրիտ կոորդինատների հեռացնելը Թվիթերի տվյալների միջոցով կատարվող տարբեր ընդհանուր Վերջապես, մենք առաջարկում ենք ապագա հետազոտությունների համար, որոնք պահանջում են երկրագտնվող թվիթեր:</abstract_hy>
      <abstract_am>Twitter data has become established as a valuable source of data for various application scenarios in the past years.  እንደዚህ ብዙዎች ፕሮግራሞች፣ የትዊተር ጽሑፎች (Tweets) ከየት ወይም የት ስፍራ የተላከ መሆኑን ማወቅ ያስፈልጋል፡፡ ምርምርተኞች ብዙ ጊዜ በትዊተሮች በሚያነሳው ጥቂት በመቶው የሚቆጠሩ ኮርማኖችን ይጠቀማሉ፤ ነገር ግን በትዊተር በ2019 መካከል እነዚህን ማሰናከል ማሰናከል የመረጃ ማቀናቀል አስወግዶአል፡፡ በተጨማሪም፣ ከአሁን በፊት ብዙ ክፍል የተሰጠ ኮርማኖችን ለGPS ኮርማቲ እንዳልተገናኘ በመጠራጠር ምክንያት አለበት፡፡ በዚህ ገጽ፣ ሁኔታውን እና የ2019 ፖሊሲ ለውጥ እና ከTwitter የቦታ መረጃዎችን ለማግኘት የልዩ ምርጫዎች ላይ እናብራራለን፡፡ በተጨማሪው ዘመን ላይ የሚለውጡ የጥያቄውን ተርታፊዎች እና በትዊተር ዳታዎች የተደረገውን የጥያቄ ትርጓሜዎችን ለማስወግድ ምን እንደሆነ እናስተውል፡፡ በመጨረሻም፣ የግንኙነቱ ትዊተሮች እንዲያስፈልጋቸው ለፊት ትምህርት ማስታወቂያ እናደርጋለን፡፡</abstract_am>
      <abstract_af>Twitter data is geïnstalleer as 'n waardelike bron van data vir verskeie aansoek scenarios in die verlede jaar. Vir baie sodanige toepassings is dit nodig om te weet waar Twitter-pos (tweets) gestuur word van of waar ligging hulle verwys. Resekers het dikwels egte koordinate gebruik wat in 'n klein persentasie tweet verskaf word, maar Twitter het die opsie verwyder om hierdie koordinate te deel in midde-2019. Ook, daar is rede om te suspekteer dat 'n groot deel van die verskaf koordinate nie ooreenstem met GPS koordinate van die gebruiker selfs voor dit nie. In hierdie papier, ons verduidelik die situasie en die 2019 beleid verander en laat lig op die verskillende opsies van nog steeds ligging inligting van tweets verkry. Ons verskaf gebruik statistiek insluitend veranderinge oor tyd, en analiseer wat die verwydering van presies koordinate beteken vir verskeie gemeenskaplike ondersoek opdragte wat met Twitter data uitgevoer is. Eindelik maak ons voorstellings vir toekomstige ondersoek wat geolokaliseerde tweets nodig.</abstract_af>
      <abstract_bn>গত বছরে বিভিন্ন অ্যাপ্লিকেশনের দৃশ্যের জন্য টুইটারের তথ্যের মূল্যবান উৎস হিসেবে প্রতিষ্ঠিত হয়েছে। এই ধরনের অনেক অ্যাপ্লিকেশনের জন্য, জানা দরকার যে টুইটার পোস্ট (টুইট) কোথায় পাঠানো হয়েছে অথবা কোন স্থান থেকে তারা য গবেষকেরা প্রায়শই টুইটের একটি ছোট শতকরা ব্যবহার করেছে, কিন্তু টুইটারের মধ্যে ২০১৯ সালের মধ্যে এই সমন্বয় শেয়ার করার বিকল্প ছিল। Moreover, there is reason to suspect that a large share of the provided coordinates did not correspond to GPS coordinates of the user even before that.  এই পত্রিকায় আমরা পরিস্থিতি এবং ২০১৯ সালের নীতির পরিবর্তন ব্যাখ্যা করি এবং টুইট থেকে বিভিন্ন স্থানের তথ্য পাওয়ার বিষয়ে আলো  আমরা ব্যবহারের পরিসংখ্যান প্রদান করি যার মধ্যে সময়ের পরিবর্তন রয়েছে এবং বিশ্লেষণ করি টুইটার তথ্য দিয়ে বিভিন্ন সাধারণ গবেষণার কাজের জন অবশেষে, আমরা ভবিষ্যত গবেষণার জন্য পরামর্শ প্রদান করি যেখানে ভূমিকম্পের টুইট প্রয়োজন।</abstract_bn>
      <abstract_ca>Les dades de Twitter s'han establit com una fontde dades valiosa per a diversos escenaris d'aplicació en els últims anys. Per a moltes d'aquestes aplicacions, és necessari saber d'on es van enviar posts de Twitter o a quin lloc es refereixen. Els investigadors han utilitzat sovint coordenadas exactes proporcionades en un petit percentatge de tweets, però Twitter va eliminar l'opció de compartir aquestes coordenadas a mitjans del 2019. Moreover, there is reason to suspect that a large share of the provided coordinates did not correspond to GPS coordinates of the user even before that.  En aquest paper, explicem la situació i el canvi de política del 2019 i donem llum a les diverses opcions d'obtenir informació sobre el lloc a partir de tweets. Oferecem estadístiques d'ús, incloent canvis amb el temps, i analitzem què significa la remoció de coordenades exactes per diverses tasques comunes de recerca fetes amb dades de Twitter. Finalment, fem suggericions per a futures recerca que requereixen tweets geolocalitzats.</abstract_ca>
      <abstract_az>Twitter məlumatları son illərdə müxtəlif uyğulama senaryosu üçün qiymətli məlumatların mənbəsi olaraq quruldu. Bütün bu proqramlar üçün Twitter postalarının haradan göndərildiyini və ya hansı məlumatlarına danışdığını bilmək lazımdır. Araştırmacılar sık-sık twetlərin kiçik yüzdə təmin edilmiş tam koordinatları istifadə edirlər, amma Twitter 2019-in ortasında bu koordinatları paylaşmaq üçün seçimləri sildi. Bundan əvvəl də istifadəçinin GPS koordinatlarına uyğun olmadığına şübhə etmək üçün bir səbəb var. Bu kağızda, bizim durumun və 2019 siyasi dəyişikliyini açıqlayır və twetdən istifadə etmək üçün müxtəlif seçimlərə işıq açarıq. Biz vaxtlarda dəyişikliklər də istifadə etdik və Twitter məlumatları ilə işlədilən müxtəlif araştırma işləri üçün tam koordinatların silinməsini analiz edirik. Sonunda, gələcək araştırmaların geolocativ twetlarına ehtiyacı olması üçün təklif edirik.</abstract_az>
      <abstract_bs>Twitter podaci su postavljeni kao vrijedan izvor podataka za različite scenarije prijave u proteklih godina. Za mnoge takve aplikacije, potrebno je znati odakle su poslani Twitter postovi (tweets) ili odakle se odnose na lokaciju. Istraživači su često koristili tačne koordinate koje su pružene u malim procenatom tweeta, ali Twitter je uklonio opciju da podijeli te koordinate u sredini 2019. godine. Osim toga, postoji razlog da sumnjamo da veliki dio osiguranih koordinata nisu odgovarali GPS koordinatima korisnika čak i prije toga. U ovom papiru objašnjavamo situaciju i promjenu politike 2019. i osvjetljavamo različite opcije da još uvijek dobijemo informacije o lokaciji iz tweets. Mi pružamo statistiku korištenja uključujući izmjene tijekom vremena i analiziramo što uklanjanje tačnih koordinata znači za različite zajedničke istraživačke zadatke izvršene sa podacima Twitter. Konačno predlažemo buduće istraživanje koje zahtijevaju geolokacione tweets.</abstract_bs>
      <abstract_cs>Data z Twitteru se v posledních letech stala cenným zdrojem dat pro různé aplikační scénáře. U mnoha takových aplikací je nutné vědět, odkud byly příspěvky na Twitteru odeslány nebo na jaké místo se odkazují. Výzkumníci často používali přesné souřadnice uvedené v malém procento tweetů, ale Twitter odstranil možnost sdílet tyto souřadnice v polovině 2019. Kromě toho existuje důvod se domnívat, že velká část poskytnutých souřadnic neodpovídala GPS souřadnicím uživatele ještě předtím. V tomto článku vysvětlíme situaci a změnu politiky 2019 a vrháme světlo na různé možnosti stále získávání informací o poloze z tweetů. Poskytujeme statistiky využití včetně změn v průběhu času a analyzujeme, co znamená odstranění přesných souřadnic pro různé běžné výzkumné úkoly prováděné s daty Twitteru. Nakonec předkládáme návrhy pro budoucí výzkum vyžadující geolokalizované tweety.</abstract_cs>
      <abstract_et>Twitteri andmed on viimastel aastatel kujunenud väärtuslikuks andmeallikaks erinevate rakendusstsenaariumide jaoks. Paljude selliste taotluste puhul on vaja teada, kust Twitteri postitused (säutsud) saadeti või millisele asukohale need viitavad. Teadlased on sageli kasutanud täpseid koordinaate, mis on esitatud väikeses protsendis säutsudest, kuid Twitter eemaldas võimaluse neid koordinaate jagada 2019. aasta keskpaigas. Lisaks on põhjust kahtlustada, et suur osa esitatud koordinaatidest ei vastanud kasutaja GPS-koordinaatidele isegi enne seda. Käesolevas dokumendis selgitame olukorda ja 2019. aasta poliitikamuutust ning valgustame erinevaid võimalusi asukohateabe saamiseks säutsidest. Pakume kasutusstatistikat, sealhulgas muutusi aja jooksul, ning analüüsime, mida täpsete koordinaatide eemaldamine tähendab erinevate Twitteri andmetega tehtavate tavaliste uurimisülesannete puhul. Lõpuks teeme ettepanekuid tulevaste uuringute jaoks, mis nõuavad geoloogiliselt paiknevaid säutseid.</abstract_et>
      <abstract_fi>Twitter-datasta on viime vuosina tullut arvokas tietolähde erilaisissa sovellusskenaarioissa. Monissa tällaisissa sovelluksissa on tiedettävä, mistä Twitter-viestit (twiitit) lähetettiin tai mihin paikkaan ne viittaavat. Tutkijat ovat usein käyttäneet tarkkoja koordinaatteja pienessä prosentissa tweeteistä, mutta Twitter poisti mahdollisuuden jakaa koordinaatit vuoden 2019 puolivälissä. Lisäksi on syytä epäillä, että suuri osa annetuista koordinaateista ei vastannut käyttäjän GPS-koordinaatteja jo ennen sitä. Tässä artikkelissa selitämme tilannetta ja vuoden 2019 politiikan muutosta sekä valotamme eri vaihtoehtoja paikkatiedon saamiseksi edelleen tweeteistä. Toimitamme käyttötilastoja, mukaan lukien muutokset ajan mittaan, ja analysoimme, mitä tarkkojen koordinaattien poistaminen tarkoittaa erilaisissa yleisissä Twitter-tiedoilla tehdyissä tutkimustehtävissä. Lopuksi teemme ehdotuksia tulevalle tutkimukselle, joka edellyttää paikkasidonnaisia twiittejä.</abstract_fi>
      <abstract_jv>D-data nang Tom isih diutag-sistem sing perusahaan data kanggo seneng aplikasi sing sampeyan mruput nang gula sing dumadhi. kanggo akèh aplikasi sing dipun, kudu ngerti nêmên ngerti kawe peus dipun Google (tuet) seneng pisan neng pisan sing arep terusan. politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pemilih iki, awak dhéwé ngerwih akeh durung lan banjur politik 2011 lan nganggo langgar oleh apik dhéwé kuwi tindakan informasi sing isih turang tuwit. Awak dhéwé ngewehku dadi nggawe tarjamahan kanggo ngubah ujaran ning aku, lan ujaran piye pangan nggawe gerakan kanggo ngilangno wektu nggawe dolanan sing dibutuhke tarjamahan kanggo sampek dadi Tom. Tulung, kéné gawe nggunakake tresnaning kanggo urêh dumadhi kayané tiket Jeogras.</abstract_jv>
      <abstract_sk>Podatki Twitter so se v zadnjih letih uveljavili kot dragocen vir podatkov za različne scenarije aplikacije. Za številne takšne aplikacije je treba vedeti, od kod so bile Twitter objave (tweeti) poslane ali na katero lokacijo se nanašajo. Raziskovalci so pogosto uporabljali natančne koordinate, navedene v majhnem odstotku tweetov, vendar je Twitter sredi leta 2019 odpravil možnost delitve teh koordinat. Poleg tega obstaja razlog za sum, da velik delež navedenih koordinat še pred tem ni ustrezal GPS koordinatam uporabnika. V prispevku pojasnjujemo stanje in spremembo politike v letu 2019 ter osvetlimo različne možnosti za še vedno pridobivanje informacij o lokaciji iz tweetov. Zagotavljamo statistiko uporabe, vključno s časovnimi spremembami, in analiziramo, kaj pomeni odstranitev natančnih koordinat za različne skupne raziskovalne naloge, ki se izvajajo s Twitterjevimi podatki. Na koncu podamo predloge za prihodnje raziskave, ki zahtevajo geolocirane tweete.</abstract_sk>
      <abstract_ha>@ info Ga masu yawa daga shiryoyin ayukan wannan, ana buƙata, ka san inda aka saka posten Twitter (Twitter) daga ko wane wuri da ake amfani da su. Wata kebiyun sun yi amfani da kodi masu lissafa da aka gaura cikin foshi kaɗan na Twitter, kuma Twitter ya kange zaɓallin ya yi raba waɗannan manyan ajiya a tsakanin 2019. Da haka, akwai wani saba da za'a yi shakka cẽwa rabin rabon shirin da aka bã su daidai da tsarin GPS na amfani da shi kõ da ya gabani. In this paper, we explain the situation and the 2019 policy change and shed light on the various options of still obtaining location information from tweets.  Mu bãyar da statistics ga amfani da shi, kamar musanyi cikin lokaci, kuma Mu yi anayya ga tafiyar da shirin ajiya masu haske na amfani da su ga taskõkin mutane da aka aikata da data na Twitter. Haƙĩƙa, Munã ƙarfafa da misãlai ga littafin nan gaba, da abin da ke bukãta na Twitter.</abstract_ha>
      <abstract_he>נתוני טוויטר הוקמו כמקור ערך של נתונים עבור תרחישים שימוש שונים בשנים האחרונות. עבור שימושים רבים כאלה, צריך לדעת מאיפה הושלחו פוסטים טוויטר (טוויטרים) או לאיזה מיקום הם מתייחסים אליו. חוקרים השתמשו לעתים קרובות בתקופות מדויקות שנספקות באחריון קטן של טוויטרים, אך טוויטר הוציא את האפשרות לחלוק את התקופות האלה באמצע 2019. חוץ מזה, יש סיבה לחשוד שחלק גדול מהנקודות המסופקות לא התאימו לקורדינטות GPS של המשתמש אפילו לפני זה. בעיתון הזה, אנחנו מסבירים את המצב והשינוי המדיניות של 2019 ולהשליך אור על האפשרויות השונים של עדיין להשיג מידע מיקום מתוך טוויטים. אנחנו מספקים סטטיסטיקות השימוש כולל שינויים במהלך הזמן, ונבחן מה ההסירה של נקודות תואמות מדויקות משמעות עבור משימות מחקר משותפות שונות שעושות עם נתונים טוויטר. סוף סוף, אנחנו מציעים הצעות למחקר עתיד שדורש טוויטים גיאולוקים.</abstract_he>
      <abstract_bo>ཌིས་ཌིར་སྤྱོད་ཆས་འདིའི་ལོ་ངོ་འདས་པའི་ནང་གི་ཉེར་སྤྱོད་ཀྱི་ཆ་རྐྱེན་གྱིས་རྩ་འབྲེལ་བ་ཞིག་ཆགས་བྱུང་། འདི་ལྟ་བུའི་ཉེར་སྤྱོད་མང་པོ་ཞིག་ལ་ཌིས་ཌིར་གྱིས་གནས་ཡུལ་གང་ཞིག་གཏང་བ་ཡིན་པ་ཤེས་དགོས་པ་རེད། དབྱེ་ཞིབ་པ་ཚོས་རྒྱ་ནག་གིས་དྲ་རྒྱ་སྟངས་ཀྱི་ཕྱོགས་སྟོན་པའི་གྲངས་སྒྲིག་ཕྱོགས་ཉུང་ཀིང་ལག་ལེན་འཐབ་ཡོད། ཡིན་ནའང་། ཌིས་ཌི འདི་ལས་བརྟེན། བྱིན་ཡོད་པའི་སྒྲིག་སྟངས་ཆེ་ཆུང་བ་འདིས་སྤྱོད་མཁན་གྱི་GPS་སྒྲིག་སྟངས་འདི་མ་མཐུན་པ་རེད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་དུས་གནས་སྟངས་དང་། 2019ཡི་སྲིད་འགྱུར་བའི་ཐབས་ལམ་ལ་འགྲེལ་བཤད་བྱེད་ཀྱི་ཡོད། ང་ཚོས་དུས་དང་བསྟུན་ནས་བཟོ་བཅོས་བྱེད་པའི་ཚད་རྩིས་འབྲེལ་བ་དང་མཉམ་དུ་བསྡུར་ན་གྱི་གནད་སྡུད་ཕྱིར་གཏན་ཁེལ་བྱེད་པའི་ Finally, we make suggestions for future research requiring geolocated tweets.</abstract_bo>
      </paper>
    <paper id="32">
      <title>Coping with Noisy Training Data Labels in Paraphrase Detection</title>
      <author><first>Teemu</first><last>Vahtola</last></author>
      <author><first>Mathias</first><last>Creutz</last></author>
      <author><first>Eetu</first><last>Sjöblom</last></author>
      <author><first>Sami</first><last>Itkonen</last></author>
      <pages>291–296</pages>
      <abstract>We present new state-of-the-art benchmarks for <a href="https://en.wikipedia.org/wiki/Paraphrase_detection">paraphrase detection</a> on all six languages in the Opusparcus sentential paraphrase corpus : <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Finnish_language">Finnish</a>, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, and <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a>. We reach these <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> by fine-tuning BERT. The best results are achieved on smaller and cleaner subsets of the training sets than was observed in previous research. Additionally, we study a translation-based approach that is competitive for the languages with more limited and noisier training data.</abstract>
      <url hash="d302747c">2021.wnut-1.32</url>
      <bibkey>vahtola-etal-2021-coping</bibkey>
      <doi>10.18653/v1/2021.wnut-1.32</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opusparcus">Opusparcus</pwcdataset>
    <title_es>Cómo hacer frente a etiquetas de datos de entrenamiento ruidosas en la detección de paráfrasis</title_es>
      <title_pt>Lidando com rótulos de dados de treinamento barulhentos na detecção de paráfrase</title_pt>
      <title_ar>التعامل مع تسميات بيانات التدريب الصاخبة في اكتشاف إعادة الصياغة</title_ar>
      <title_fr>Faire face aux étiquettes de données d'entraînement bruyantes dans la détection de paraphrase</title_fr>
      <title_ja>パラフレーズ検出におけるノイズの多いトレーニングデータラベルへの対応</title_ja>
      <title_zh>于释义检处噪声训练数据标签</title_zh>
      <title_ru>Работа с шумными ярлыками обучающих данных при обнаружении парафраз</title_ru>
      <title_hi>पैराफ़्रेज़ डिटेक्शन में शोर प्रशिक्षण डेटा लेबल के साथ मुकाबला करना</title_hi>
      <title_ga>Déileáil le Lipéid Sonraí Oiliúna Noisy i mBraith Athfhrása</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>Zajos edzési adatcímkék kezelése a parafrázis detektálásban</title_hu>
      <title_el>Αντιμετώπιση των θορυβωδών ετικετών δεδομένων κατάρτισης στην ανίχνευση παραφράσεων</title_el>
      <title_kk>Парафразды анықтау үшін дыбыс оқыту деректер жарлықтарымен көшірмелеу</title_kk>
      <title_it>Affrontare le etichette dei dati di allenamento rumoroso nel rilevamento delle parafrasi</title_it>
      <title_mk>Копирање со ознаките на податоци за шумна обука во детекција на парафрази</title_mk>
      <title_lt>Coping with Noisy Training Data Labels in Paraphrase Detection</title_lt>
      <title_ms>Menyalin dengan Label Data Latihan Bunyi dalam Pengesanan Parafrasa</title_ms>
      <title_mt>Kopjar mat-Tikketti tad-Dejta dwar it-Taħriġ bl-Istorbju fid-Detezzjoni tal-Parafrażi</title_mt>
      <title_ml>പാരാഫ്രായിസ് ഡേറ്റാ ലേബലുകളുമായി പരിശീലിക്കുന്ന വിവരങ്ങള്‍ ലഭ്യമാക്കുന്നു</title_ml>
      <title_mn>Парафрейз тогтоохын тулд шууд дасгал өгөгдлийн найзуудтай хууль</title_mn>
      <title_no>Comment</title_no>
      <title_pl>Radzenie sobie z hałasowymi etykietami danych treningowych w wykrywaniu parafraz</title_pl>
      <title_ro>Gestionarea etichetelor de date de instruire zgomotoasă în detectarea parafrazelor</title_ro>
      <title_sr>Kopirajući sa etiketama podataka za obuku u parafrazi</title_sr>
      <title_si>Name</title_si>
      <title_so>Codsashada baaritaanka macluumaadka waxbarashada noocyada ah ee baaritaanka Paraphrase</title_so>
      <title_sv>Hantera bullriga träningsdataetiketter i parafrasedetektering</title_sv>
      <title_ta>தேவையற்ற தகவல் விளக்கச்சீட்டுகளுடன் இணைப்பு</title_ta>
      <title_ur>پارافریز اچانک میں نویسی ٹرینینگ ڈاٹ لیبل کے ساتھ کپی کیا جاتا ہے</title_ur>
      <title_vi>Đang xử lý các thẻ sửa chữa nhiễu trong phát thanh Paracụm từ</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Справяне с етикетите за данни за шумно обучение при откриване на парафрази</title_bg>
      <title_da>Håndtering af støjende træningsdataetiketter i parafraseregistrering</title_da>
      <title_hr>Kopirajući s etiketama podataka za vježbanje glasina u otkrivanju parafraze</title_hr>
      <title_nl>Omgaan met ruige trainingsgegevenslabels in parafrasedetectie</title_nl>
      <title_de>Umgang mit lärmenden Trainingsdatenetiketten in der Paraphrasenerkennung</title_de>
      <title_id>Coping with Noisy Training Data Labels in Paraphrase Detection</title_id>
      <title_fa>Name</title_fa>
      <title_ko>해석 검측 중 소음 훈련 데이터 라벨 처리</title_ko>
      <title_sw>Kuunganisha na mabango ya mafunzo ya Taarifa isiyo ya kawaida katika Ugunduzi wa Paraphrase</title_sw>
      <title_tr>Parafraz Aňlamak Derjesi bilen nusgala</title_tr>
      <title_af>Name</title_af>
      <title_sq>Kopjimi me etiketat e të dhënave të trajnimit të zhurmshëm në zbulimin e parafrazave</title_sq>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Փարաֆրեսի հայտնաբերման ընթացքում աղմկոտ փորձի տվյալների պիտակների հետ հաղթահարելը</title_hy>
      <title_az>Parafrazidə keşfetməsində Söyüd Eğitimi Veri Etiketleri ilə Kopyalanır</title_az>
      <title_bn>প্যারাফ্রাজের ডাটা লেবেলের সাথে কোপিং</title_bn>
      <title_bs>Kopirajući sa etiketama podataka za vježbanje Noisy u detekciji parafraze</title_bs>
      <title_ca>Comprar amb les etiquetes de dades d'entrenament ruidosa en la detecció de parafrases</title_ca>
      <title_cs>Zvládání šumových štítků tréninkových dat v detekci parafráz</title_cs>
      <title_et>Mürakate koolitusandmete märgistega toimetulek parafraaside tuvastamisel</title_et>
      <title_fi>Meluisten harjoitustietomerkint√∂jen k√§sittely parafraasien tunnistuksessa</title_fi>
      <title_jv>gagal</title_jv>
      <title_he>עותק עם תוויות מידע אימון רעש בחקירה של פראפרזיה</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Obvladovanje hrupnih nalepk podatkov o usposabljanju pri zaznavanju parafraz</title_sk>
      <title_bo>Paraphrase Detection ནང་གི་Noisy Training Data Labels དང་མཉམ་དུ་འདྲ་བཤུ་བྱེད་པ</title_bo>
      <abstract_ar>نقدم أحدث المعايير الجديدة لاكتشاف إعادة الصياغة على جميع اللغات الست في مجموعة إعادة صياغة النص Opusparcus: الإنجليزية ، والفنلندية ، والفرنسية ، والألمانية ، والروسية ، والسويدية. نصل إلى خطوط الأساس هذه من خلال ضبط BERT. يتم تحقيق أفضل النتائج على مجموعات فرعية أصغر وأنظف من مجموعات التدريب مما لوحظ في البحث السابق. بالإضافة إلى ذلك ، ندرس نهجًا قائمًا على الترجمة قادرًا على المنافسة للغات مع بيانات تدريب أكثر محدودية وأكثر ضجيجًا.</abstract_ar>
      <abstract_fr>Nous présentons de nouveaux repères de pointe pour la détection de la paraphrase dans les six langues du corpus de paraphrase sententielle Opusparcus : anglais, finnois, français, allemand, russe et suédois. Nous atteignons ces niveaux de référence en ajustant le BERT. Les meilleurs résultats sont obtenus sur des sous-ensembles plus petits et plus propres des ensembles d'entraînement que ceux observés dans les recherches précédentes. De plus, nous étudions une approche basée sur la traduction qui est compétitive pour les langues dont les données d'apprentissage sont plus limitées et plus bruyantes.</abstract_fr>
      <abstract_pt>Apresentamos novos benchmarks de última geração para detecção de paráfrases em todos os seis idiomas do corpus de paráfrases sentenciais do Opusparcus: inglês, finlandês, francês, alemão, russo e sueco. Alcançamos essas linhas de base ajustando o BERT. Os melhores resultados são alcançados em subconjuntos menores e mais limpos dos conjuntos de treinamento do que foi observado em pesquisas anteriores. Além disso, estudamos uma abordagem baseada em tradução que é competitiva para os idiomas com dados de treinamento mais limitados e mais barulhentos.</abstract_pt>
      <abstract_es>Presentamos nuevos parámetros de referencia de última generación para la detección de paráfrasis en los seis idiomas del corpus de paráfrasis oracional de Opusparcus: inglés, finés, francés, alemán, ruso y sueco. Alcanzamos estas líneas de base ajustando BERT. Los mejores resultados se obtienen en subconjuntos más pequeños y limpios de los conjuntos de entrenamiento que los observados en investigaciones anteriores. Además, estudiamos un enfoque basado en la traducción que sea competitivo para los idiomas con datos de formación más limitados y ruidosos.</abstract_es>
      <abstract_ja>Opusparcusセンセーショナル・パラフレーズ・コーパス（英語、フィンランド語、フランス語、ドイツ語、ロシア語、スウェーデン語）のすべての6言語でパラフレーズ検出のための最新のベンチマークを提供しています。BERTを微調整することで、これらのベースラインに到達します。最良の結果は、以前の研究で観察されたものよりも小さく、より清潔な訓練セットのサブセットで達成される。さらに、より限定的で騒音の大きいトレーニングデータを持つ言語に対して競争力のある翻訳ベースのアプローチを研究しています。</abstract_ja>
      <abstract_zh>臣等条上新最先进之准,施于Opusparcus句释义语料库中所有六语释义检:英语,芬兰语,法语,德语,俄语瑞典语。 微 BERT 以致基线。 比之前所观,在更小,更净练集上取最佳。 又考之于译法,其于训练有限,噪声语有竞争力。</abstract_zh>
      <abstract_ru>Мы представляем новые современные эталоны для обнаружения парафраз на всех шести языках в корпусе парафраз Opusparcus: английском, финском, французском, немецком, русском и шведском. Мы достигаем этих базовых линий, точно настраивая БЕРТА. Наилучшие результаты достигаются в отношении меньших и более чистых подмножеств учебных наборов, чем это было отмечено в предыдущих исследованиях. Кроме того, мы изучаем подход, основанный на переводе, который является конкурентоспособным для языков с более ограниченными и более шумными данными обучения.</abstract_ru>
      <abstract_hi>हम ओपसपारकस सेंटेन्शियल पैराफ्रेज कॉर्पस में सभी छह भाषाओं पर पैराफ्रेज डिटेक्शन के लिए नए अत्याधुनिक बेंचमार्क प्रस्तुत करते हैं: अंग्रेजी, फिनिश, फ्रेंच, जर्मन, रूसी और स्वीडिश। हम BERT को ठीक ट्यून करके इन आधार रेखाओं तक पहुंचते हैं। पिछले शोध में देखे गए प्रशिक्षण सेटों के छोटे और क्लीनर सबसेट पर सबसे अच्छे परिणाम प्राप्त किए जाते हैं। इसके अतिरिक्त, हम एक अनुवाद-आधारित दृष्टिकोण का अध्ययन करते हैं जो अधिक सीमित और शोर प्रशिक्षण डेटा वाली भाषाओं के लिए प्रतिस्पर्धी है।</abstract_hi>
      <abstract_ga>Cuirimid tagarmharcanna úrscothacha i láthair chun athinsint a bhrath ar gach ceann de na sé theanga i gcorpas athinsint sentential Opussparcus: Béarla, Fionlainnis, Fraincis, Gearmáinis, Rúisis agus Sualainnis. Bainimid na bunlínte sin amach trí BERT a mhionchoigeartú. Baintear na torthaí is fearr amach ar fho-thacair níos lú agus níos glaine de na tacair oiliúna ná mar a breathnaíodh i dtaighde roimhe seo. Ina theannta sin, déanaimid staidéar ar chur chuige bunaithe ar aistriúchán atá iomaíoch do na teangacha le sonraí oiliúna níos teoranta agus níos torannaí.</abstract_ga>
      <abstract_ka>ჩვენ ჩვენ ახალი სურათის ბენქმარკები პრაფრეზის განახლებისთვის ყველა შვიდი ენაში Opusparcus sentential paraphrase corpus: ანგლისური, ფინური, ფრანგური, გერმანური, პირუსი და შვედიული. ჩვენ მივიღეთ ეს ფესური ხაზების შესახებ BERT. ყველაზე საუკეთესო წარმოდგენა, რომლებიც უფრო პატარა და უფრო ფრთხოვრებული სპესტებში, ვიდრე წინა სწავლა სწავლა. დამატებით, ჩვენ შევსწავლობთ გადაწყვეტილების მიხედვილი, რომელიც კონპექტიურია ენებისთვის, რომელიც უფრო დავზრუნდებული და უფრო ბუნდა განა</abstract_ka>
      <abstract_hu>Új, korszerű referenciaértékeket mutatunk be az Opusparcus sentintial parafrázis corpus mind a hat nyelvén: angol, finn, francia, német, orosz és svéd. A BERT finomhangolásával érjük el ezeket az alapokat. A legjobb eredményeket a korábbi kutatásoknál megfigyelhetőnél kisebb és tisztább részhalmazokon érjük el. Továbbá olyan fordításalapú megközelítést tanulmányozunk, amely versenyképes a korlátozottabb és zajosabb képzési adatokkal rendelkező nyelvek számára.</abstract_hu>
      <abstract_el>Παρουσιάζουμε νέα πρότυπα αναφοράς τελευταίας τεχνολογίας για την ανίχνευση παραφράσεων και στις έξι γλώσσες στο σώμα παραφράσεων Opusparcus sentential: αγγλικά, φινλανδικά, γαλλικά, γερμανικά, ρωσικά και σουηδικά. Φτάνουμε σε αυτές τις γραμμές βάσης με την τελειοποίηση του BERT. Τα καλύτερα αποτελέσματα επιτυγχάνονται σε μικρότερα και καθαρότερα υποσύνολα των εκπαιδευτικών συνόλων από ό,τι παρατηρήθηκε σε προηγούμενη έρευνα. Επιπλέον, μελετούμε μια προσέγγιση βασισμένη στη μετάφραση που είναι ανταγωνιστική για τις γλώσσες με πιο περιορισμένα και θορυβώδη δεδομένα κατάρτισης.</abstract_el>
      <abstract_kk>Біз Opusparcus sentential paraphrase corpus: ағылшын, финск, француз, неміс, руссиян және шведша тілдерінің барлық алты тілдерін анықтау үшін жаңа күй- жай бағдарламаларды таңдаймыз. Біз бұл негізгі сызықтарды BERT баптауына жеткіземіз. Ең жақсы нәтижелер кейінгі зерттеу бағдарламаларының кіші және тазалау бағдарламаларының ішінде болады. Сонымен қатар, біз тілдерге көмектесетін және дыбыс оқыту деректері бар аудармаларды негіздеген тәсілді зерттейміз.</abstract_kk>
      <abstract_it>Presentiamo nuovi benchmark all'avanguardia per il rilevamento di parafrasi in tutte e sei le lingue del corpus sentimentale di parafrasi Opusparcus: inglese, finlandese, francese, tedesco, russo e svedese. Raggiungiamo queste linee di base regolando BERT. I risultati migliori si ottengono su sottoinsiemi più piccoli e più puliti dei set di formazione rispetto a quelli osservati nelle ricerche precedenti. Inoltre, studiamo un approccio basato sulla traduzione che è competitivo per le lingue con dati di formazione più limitati e rumorosi.</abstract_it>
      <abstract_mk>Презентираме нови најсовремени референтни значки за детекција на парафрази на сите шест јазици во Опуспаркускиот реченствен парафразен тел: англиски, фински, француски, германски, руски и шведски. We reach these baselines by fine-tuning BERT.  Најдобрите резултати се постигнати за помали и почисти подгрупи на наборите на обуки отколку што беа забележани во претходните истражувања. Покрај тоа, студираме пристап базиран на превод кој е конкурентен за јазиците со поголеми ограничени и повисоки податоци за обука.</abstract_mk>
      <abstract_ml>ഓപുസ്പാര്‍ക്കുസിന്റെ സെന്റെന്റില്‍ ആറു ഭാഷകള്‍ കണ്ടുപിടിക്കുന്നതിനുള്ള പുതിയ സ്റ്റേറ്റ് ഫ്രെഞ്ച്, ജര്‍മ്മന്‍, റഷ്യന്‍, സ്വീഷ്യന്‍ നമ്മള്‍ ഈ ബെസ്റ്റ് ലൈനുകളിലേക്ക് എത്തുന്നത് നല്ല ടൂണിങ്ങ് ബെര്‍ട്ട്. പരിശീലനത്തിന്റെ ചെറിയ വിഭവങ്ങളില്‍ ഏറ്റവും മികച്ച ഫലങ്ങള്‍ നേടിയിരിക്കുന്നു. മുമ്പ് പരിശീലനത്തിനെക്ക കൂടാതെ, ഞങ്ങള്‍ ഒരു പരിഭാഷയുടെ അടിസ്ഥാനത്തില്‍ പരിശോധിക്കുന്ന പ്രായോഗ്യം പഠിക്കുന്നു. അത് ഭാഷകള്‍ക്ക് വേണ്ട</abstract_ml>
      <abstract_ms>We present new state-of-the-art benchmarks for paraphrase detection on all six languages in the Opusparcus sentential paraphrase corpus: English, Finnish, French, German, Russian, and Swedish.  Kita mencapai garis dasar ini dengan memperbaiki BERT. Hasil terbaik dicapai pada subkumpulan kecil dan lebih bersih set latihan daripada yang dilihat dalam kajian sebelumnya. Additionally, we study a translation-based approach that is competitive for the languages with more limited and noisier training data.</abstract_ms>
      <abstract_no>Vi presenterer nye benchmarker for parafrase-oppdaging på alle seks språk i Opusparcus sentencial parafrase korpus: engelsk, finsk, fransk, tysk, russisk og svensk. Vi når desse grunnlinjene ved å finna BERT. Den beste resultatene er oppnådd på mindre og reinere undergruppene av opplæringssettet enn det ble observert i førre forskning. I tillegg studerer vi eit omsetjingsbasert tilnærming som er konkurentivt for språka med meir begrenset og større opplæringsdata.</abstract_no>
      <abstract_mn>Бид Opusparcus өгүүлбэрийн үгийн 6 хэл дээр шинэ урлагийн багц багц дээр тайлбарлаж байна: Англи, Финляйн, Француз, Герман, Орос, Швед. Бид эдгээр суурь шугам хүртэл БЕРТ-г сайжруулж чадна. Хамгийн сайн үр дүнг нь өмнөх судалгаанд ажиглагдсан бага болон цэвэрлэх сургалтын хэсэг дээр гарч ирсэн. Мөн бид хэл дээр илүү хязгаарлагдсан, илүү чимээгүй сургалтын өгөгдлийн талаар өрсөлдөг орнуудыг судалдаг.</abstract_mn>
      <abstract_ro>Vă prezentăm noi criterii de referință de ultimă generație pentru detectarea parafrazelor pe toate cele șase limbi din corpul de parafrază sentimentală Opusparcus: engleză, finlandeză, franceză, germană, rusă și suedeză. Ajungem la aceste linii de bază prin reglarea fină a BERT. Cele mai bune rezultate sunt obținute pe subseturi mai mici și mai curate ale seturilor de formare decât s-a observat în cercetările anterioare. În plus, studiem o abordare bazată pe traduceri, care este competitivă pentru limbile cu date de formare mai limitate și mai zgomotoase.</abstract_ro>
      <abstract_pl>Przedstawiamy nowe najnowocześniejsze standardy wykrywania parafraz we wszystkich sześciu językach w korpusie parafraz Opusparcus sentential: angielskim, fińskim, francuskim, niemieckim, rosyjskim i szwedzkim. Dotrzemy do tych linii podstawowych poprzez dostosowanie BERT. Najlepsze wyniki osiąga się na mniejszych i czystszych podzbiorach zestawów szkoleniowych niż obserwowano w poprzednich badaniach. Dodatkowo badamy podejście oparte na tłumaczeniach, które jest konkurencyjne dla języków z bardziej ograniczonymi i głośniejszymi danymi szkoleniowymi.</abstract_pl>
      <abstract_si>අපි අළුත් ස්ථානය-of-the-art benches පෙන්වන්නේ පැරැෆ්‍රේස් හොයාගන්න සියළු භාෂාවල් හතරක් හොයාගන්න පුළුවන්: ඉංග්‍රීසි, ෆින්ලි අපි මේ ප්‍රධාන පැත්තෙන් පොඩ්ඩක් ප්‍රවේශනය කරනවා BERT එක්ක. හොඳම ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රත තවත්, අපි භාෂාවට අභිවාදයක් අධ්‍යානය කරනවා ඒක තරම් සීමාවිත සහ ශ්‍රීෂාවක් තොරතුරක් තියෙනවා.</abstract_si>
      <abstract_so>Waxaannu soo bandhignaynaa qoraalka farshaxanka ee ku qoran lix luqadood oo dhan oo ku qoran qoraalka farshaxanka ee Opusparcus: Ingiriis, Finnish, Faraansiis, Jarmal, Ruush iyo Iswidish. Waxaynu gaadhnaa heerarkaas oo ku qoran BERT Midhaha ugu wanaagsan waxaa laga helaa kooxaha waxbarashada ka yar iyo ka nadiifsan kooxaha waxbarashada ee ugu horeeyay. Sidoo kale waxaynu baranaynaa qaabab turjuman oo ku dadaalaya luqadaha oo ku qoran macluumaad waxbarasho aad u xadan iyo aad u dhawaaq.</abstract_so>
      <abstract_sv>Vi presenterar nya toppmoderna riktmärken för parafrasdetektering på alla sex språk i Opusparcus sentential parafrascorpus: engelska, finska, franska, tyska, ryska och svenska. Vi når dessa baslinjer genom att finjustera BERT. De bästa resultaten uppnås på mindre och renare delgrupper av träningsuppsättningar än vad som observerats i tidigare forskning. Dessutom studerar vi ett översättningsbaserat tillvägagångssätt som är konkurrenskraftigt för språken med mer begränsade och bullriga utbildningsdata.</abstract_sv>
      <abstract_ta>நாங்கள் ஒபுஸ்பார்க்ஸ் சென்டியல் கார்புஸ் மூலம் அனைத்து ஆறு மொழிகள் கண்டுபிடிப்பதற்கான புதிய மாநிலை குறிப்புகளை கூட்டுகிறோம்: ஆங்கிலம்,  நாம் இந்த அடிப்படைக்கோடுகளை நல்ல தூண்டுதல் பெர்ட் மூலம் அடையும். முந்தைய ஆய்வுகளில் பார்க்கப்பட்டதை விட சிறிய மற்றும் சுத்தமான பயிற்சி அமைப்புகளின் சிறந்த முடிவு மேலும், நாம் மொழிகளுக்கு பொருத்தமான ஒரு மொழிபெயர்ப்பு அடிப்படையான செயல்பாட்டை படிக்கிறோம். அது மிகவும் வரம்</abstract_ta>
      <abstract_lt>Pateikiame naujus naujausius lyginamuosius rodiklius parafrazėms aptikti visomis šešiomis Opusparcus baudžiamosios parafrazės korpusais: anglų, suomių, prancūzų, vokiečių, rusų ir švedų. Mes pasiekiame šias bazines linijas patobulindami BERT. The best results are achieved on smaller and cleaner subsets of the training sets than was observed in previous research.  Be to, mes tiriame vertimo principu grindžiamą požiūrį, kuris yra konkurencingesnis kalboms, turinčioms ribotesnius ir triukšmingesnius mokymo duomenis.</abstract_lt>
      <abstract_mt>Aħna nippreżentaw punti ta’ riferiment moderni ġodda għall-identifikazzjoni tal-parafrażi fis-sitt lingwi kollha fil-parafrażi sentenzjali tal-Opusparcus corpus: Ingliż, Finlandiż, Franċiż, Ġermaniż, Russu u Żvediż. Aħna nilħqu dawn il-linji bażi permezz ta’ aġġustament fin tal-BERT. The best results are achieved on smaller and cleaner subsets of the training sets than was observed in previous research.  Barra minn hekk, nistudjaw approċċ ibbażat fuq it-traduzzjoni li huwa kompetittiv għall-lingwi b’dejta ta’ taħriġ aktar limitata u aktar storbjuża.</abstract_mt>
      <abstract_sr>Predstavljamo nove standarde za detekciju parafraze na svih šest jezika na opusparcuskom sentencijalnom parafrazu korpusu: engleskom, finskom, francuskom, njemačkom, ruskom i švedskom. Došli smo do osnovnih linija sa središtem BERT-a. Najbolji rezultati su postignuti na manjim i čišćem podskupinama obuke nego što je posmatrano u prethodnim istraživanjima. Osim toga, proučavamo pristup na prevodu koji je konkurentniji za jezike sa ograničenijim i bukovijim podacima o obuci.</abstract_sr>
      <abstract_ur>ہم نے انگلیسی, فنلاندی, فرانسوی, جرمانی, روسی اور سوئڈی کے سارے چھ زبانوں پر پارافریز شناسایی کے لئے نئی حالت بنچ مارک پیش کیے ہیں۔ ہم ان بنیاس لینوں کو ٹھیک تنظیم BERT کے ذریعہ پہنچ رہے ہیں. سب سے بہترین نتیجے چھوٹے اور پاکیزہ ترینس سٹوں پر پہنچ گئے ہیں جو پہلے تحقیقات میں دیکھی گئی تھی۔ اور اضافہ، ہم ایک ترجمہ پر بنیادی طریقہ کی تلاش کرتے ہیں جو زبانوں کے لئے زیادہ محدودہ اور زیادہ صوت ترجمہ ڈیٹا کے ساتھ مساوی ہے.</abstract_ur>
      <abstract_uz>Biz Opusparcus sentensial paraphrase corpusida hamma lixda tillarni aniqlash uchun yangi holatning imkoniyatlarini hosil qilamiz: Inglizcha, Finnchacha, Fransuzcha, Olmoncha, Ruscha va Shvetsiya. Biz bu asboblarni BERT bilan yaxshi ko'rinishimiz mumkin. Eng yaxshi natijalar oldingi taʼminlovchi ko'proq taʼminlovchi bir nechta va yaxshi bir guruhlarda bajariladi. Additionally, we study a translation-based approach that is competitive for the languages with more limited and noisier training data.</abstract_uz>
      <abstract_vi>Chúng tôi giới thiệu những tiêu chuẩn cao cấp mới cho việc phát hiện tập ảnh dài tập thể hình của tất cả sáu ngôn ngữ trong tập thể hình thành của người Anh, Phần Lan, Pháp, Đức, Nga và Thụy Điển. Chúng ta sẽ hoàn thành nền văn phòng bằng rượu. Những kết quả tốt nhất được đạt được trên các nhóm nhỏ hơn và sạch sẽ trong các bộ huấn luyện hơn so với những nghiên cứu trước. Hơn nữa, chúng tôi nghiên cứu một phương pháp dịch dựa trên cạnh tranh cho ngôn ngữ với thông tin về huấn luyện ngắn và đa dạng hơn.</abstract_vi>
      <abstract_bg>Представяме нови най-съвременни показатели за откриване на парафрази на всичките шест езика в корпуса на парафразата: английски, финландски, френски, немски, руски и шведски. Достигаме тези базови линии чрез фина настройка на BERT. Най-добрите резултати се постигат при по-малки и по-чисти подгрупи от обучителните групи, отколкото е наблюдавано в предишни изследвания. Освен това изучаваме подход, базиран на преводи, който е конкурентен за езиците с по-ограничени и шумни данни за обучение.</abstract_bg>
      <abstract_nl>We presenteren nieuwe state-of-the-art benchmarks voor parafrasedetectie op alle zes talen in het Opusparcus sentential parafrasedecorpus: Engels, Fins, Frans, Duits, Russisch en Zweeds. We bereiken deze basislijnen door BERT te finetunen. De beste resultaten worden bereikt op kleinere en schonere subsets van de trainingssets dan in vorig onderzoek werd waargenomen. Daarnaast bestuderen we een vertaalgebaseerde aanpak die concurrerend is voor de talen met meer beperkte en luidruchtige trainingsgegevens.</abstract_nl>
      <abstract_da>Vi præsenterer nye state-of-the-art benchmarks for parafrasedetektion på alle seks sprog i Opusparcus sentential parafrase corpus: engelsk, finsk, fransk, tysk, russisk og svensk. Vi når disse grundlinjer ved at finjustere BERT. De bedste resultater opnås på mindre og renere delmængder af træningssættene, end der blev observeret i tidligere forskning. Derudover studerer vi en oversættelsesbaseret tilgang, der er konkurrencedygtig for sprogene med mere begrænsede og støjende træningsdata.</abstract_da>
      <abstract_hr>Predstavljamo nove kriterije za otkrivanje parafraze na svih šest jezika u Opusparcus sentencijalnom parafrazu korpusu: engleskom, finskom, francuskom, njemačkom, ruskom i švedskom. Stižemo do osnovnih linija sa dobrim sredstvima BERT-a. Najbolji rezultati su postignuti na manjim i čišćem podskupinama obuke nego što je promatrano u prethodnim istraživanjima. Osim toga, proučavamo pristup na temelju prevoda koji je konkurentniji za jezike s ograničenijim i bukovijim podacima o obuci.</abstract_hr>
      <abstract_de>Im Opusparcus sentential Paraphrasenkorpus präsentieren wir neue Benchmarks für die Paraphrasenerkennung in allen sechs Sprachen: Englisch, Finnisch, Französisch, Deutsch, Russisch und Schwedisch. Diese Grundlinien erreichen wir durch Feinabstimmung von BERT. Die besten Ergebnisse werden bei kleineren und saubereren Teilmengen der Trainingssets erzielt, als in früheren Untersuchungen beobachtet wurde. Darüber hinaus untersuchen wir einen übersetzungsbasierten Ansatz, der für die Sprachen mit begrenzteren und lauteren Trainingsdaten wettbewerbsfähig ist.</abstract_de>
      <abstract_id>Kami mempersembahkan benchmark terbaru untuk deteksi parafrasa pada semua enam bahasa dalam hukum Opusparcus parafrasa mayat: Inggris, Finlandia, Perancis, Jerman, Rusia, dan Swedia. Kita mencapai garis dasar ini dengan memperbaiki BERT. Hasil terbaik dicapai pada subset yang lebih kecil dan lebih bersih dari set pelatihan dibandingkan pada penelitian sebelumnya. Selain itu, kami mempelajari pendekatan berdasarkan terjemahan yang kompetitif untuk bahasa dengan data latihan yang lebih terbatas dan lebih bunyi.</abstract_id>
      <abstract_ko>우리는 Opusparcus 문장 해석 자료 라이브러리의 모든 6개 언어(영어, 핀란드어, 프랑스어, 독일어, 러시아어와 스웨덴어)에 최신 해석 검측 기준을 제공하였다.BERT를 미세하게 조정하여 이러한 베이스라인에 도달했습니다.이전 연구에 비해 더 작고 깨끗한 훈련 모음집에서 얻은 효과가 가장 좋다.그 밖에 우리는 번역을 바탕으로 하는 방법을 연구했는데 이런 방법은 훈련 데이터가 더욱 제한적이고 소음이 큰 언어에 경쟁력이 있다.</abstract_ko>
      <abstract_fa>ما نقشه‌های جدید در حالت هنر برای شناسایی پارافریز در تمام شش زبان در پارافریز مجازات Opusparcus corpus: انگلیسی، فنلاندی، فرانسوی، آلمانی، روسی و سوئدی را نشان می‌دهیم. ما به این خط پایین‌ها با توسط BERT درست کردن رسیدیم. بهترین نتیجه‌های کوچکتر و پاکیزه‌ترین مجموعه‌های آموزش از تحقیقات قبلی به دست آورده می‌شوند. به اضافه، ما یک روش بر اساس ترجمه را مطالعه می کنیم که برای زبانها با داده های آموزش محدودیت و صداتر رقابت می کند.</abstract_fa>
      <abstract_sw>Tunaweza kuweka bendera mpya ya hali ya sanaa kwa ajili ya kutambua lugha zote sita katika makampuni ya sentensi ya Opusparcus: Kiingereza, Kifaransa, Kijerumani, Urusi na Kiswahili. Tunapata mistari haya kwa kutumia vizuri vya BERT. Matokeo bora zaidi yamefikiliwa katika vipindi vidogo na safi zaidi vya vituo vya mafunzo kuliko vilivyoonekana katika utafiti uliopita. Zaidi ya hayo, tunasoma mbinu za kutafsiri inayohusiana na jitihada kwa lugha zenye taarifa za mafunzo mipango na sauti.</abstract_sw>
      <abstract_tr>Opusparcus duýularynda ähli alty diller gözlemek üçin täze sanat taýýarlaryny: Iňlisçe, Finçe, fransuzça, nemesçe, Rusça we Şwedçe Biz bu temel hatlary BERT taýýarlap ýetirip otyrys. Iň gowy netijede, okuwçylyk toparynyň kiçi we temizlik toparynda öňki araştyrmalarda gözleýän netijede berilýär. Hem, biz terjime etmäge tabanly bir ýazşy öwrenýärdik. Diller üçin ýakynlaşyk diýip çarpan we gürrüňli terjime etmeli maglumatlar bilen.</abstract_tr>
      <abstract_af>Ons stel nuwe staat-van-kuns benchmarke voor parafrase opdekking op alle ses tale in die Opusparcus sentenciele parafrase korpus: Engels, Finnish, Frans, Duits, Russies en Sweedse. Ons bereik hierdie basilyne deur fin-tuning BERT. Die beste resultate word ontvang op kleiner en skoonmaar subartikels van die onderwerp stelle as in vorige onderwerp aangesien word. Ons studiereer ook 'n oorsettingsbaseerde toegang wat vir die tale rekenaar is met meer beperk en gelukkiger onderwerking data.</abstract_af>
      <abstract_am>We present new state-of-the-art benchmarks for paraphrase detection on all six languages in the Opusparcus sentential paraphrase corpus: English, Finnish, French, German, Russian, and Swedish.  እነዚህን መሠረቶች BERT በመጠቀም እናደርጋለን፡፡ የቀድሞው ትምህርት ውስጥ ከመታወቂያው ይልቅ ትንሽ እና ንጹሕ የግንኙነት ክፍሎች ላይ የተደረገ ውጤቶች ይደረጋሉ፡፡ በተጨማሪም፣ ለቋንቋዎች በተቃራኒ እና የድምፅ ትርጓሜ ዳታዎችን በተጨማሪው የቋንቋዎች ሥርዓት እናስተማራለን፡፡</abstract_am>
      <abstract_az>Biz Opusparcus sentencial parafraz korpusu: İngilizce, Finlandiya, Fransız, Almanca, Rusya və İsveçə dillərində parafraz keşfetmək üçün yeni məlumatları göstəririk. Biz bu əsas sətirlərə BERT'u düzəltmək üçün çatdıq. Ən yaxşı sonuçlar əvvəlki araştırmalardan daha kiçik və daha temizlənmiş təhsil qurularında başarılır. Əksinə, biz həmin dillərə daha sınırlı və daha gürültülü təhsil məlumatları ilə müəllif olan çeviri tabanlı təhsil öyrənirik.</abstract_az>
      <abstract_hy>Մենք ներկայացնում ենք նոր բարձրագույն համեմատական նշաններ, որոնք օգտագործում են պարաֆրեզի հայտնաբերումը բոլոր վեց լեզուների վրա Օպուսպարկուս նախադասության պարաֆրեզիայի մարմնի վրա' անգլերեն, ֆինլարեն, ֆրանսերեն, գերմաներեն, ռուսերեն և We reach these baselines by fine-tuning BERT.  Լավագույն արդյունքները հասնում են կրթության համակարգերի փոքր և մաքուր ենթախմբերի վրա, քան նախորդ հետազոտություններում: Ավելին, մենք ուսումնասիրում ենք թարգմանման հիմնված մոտեցում, որը մրցակցում է լեզուների համար ավելի սահմանափակ և ձանձրալի ուսումնասիրության տվյալներով:</abstract_hy>
      <abstract_bn>We present new state-of-the-art benchmarks for paraphrase detection on all six languages in the Opusparcus sentential paraphrase corpus: English, Finnish, French, German, Russian, and Swedish.  আমরা ভালো টুনিং বের্টের মাধ্যমে এই বেসেলাইনে পৌঁছাই। পূর্ববর্তী গবেষণার চেয়ে ছোট এবং পরিষ্কার করা প্রশিক্ষণের সাবস্টগুলোতে সবচেয়ে ভাল ফলাফল অর্জন করা হয়েছে। এছাড়াও আমরা অনুবাদ ভিত্তিক উপায় গবেষণা করি যা ভাষার জন্য প্রতিযোগিতায় আরো সীমিত এবং শব্দের প্রশিক্ষণের তথ্য দিয়ে</abstract_bn>
      <abstract_sq>Ne paraqesim nivele të reja të larta për zbulimin e parafrazave në të gjashtë gjuhët në kufomën e parafrazave të dënimit Opusparcus: anglisht, finlandez, francez, gjerman, rus dhe suedez. Ne arrijmë këto linja bazë duke rregulluar BERT. Rezultatet më të mira arrihen në nëngrupe më të vogla dhe më të pastra të grupeve të trainimit sesa u vëzhguan në kërkimet e mëparshme. Përveç kësaj, ne studiojmë një qasje bazuar në përkthime që është konkurruese për gjuhët me të dhëna më të kufizuara dhe më të zhurmshme trainimi.</abstract_sq>
      <abstract_ca>Presentam nous punts de referència actuals per a la detecció de parafrases en totes les sis llengües del corps de parafrases sentencials Opusparcus: anglès, finlandès, francès, alemany, rus i suec. Arribem a aquestes línies de base ajustando BERT. Els millors resultats s'aconsegueixen en subgrups més petits i netes dels conjunts d'entrenament que en recerca anterior. A més, estudiem un enfocament basat en la traducció competitiu per a les llengües amb dades de formació més limitades i sorolloses.</abstract_ca>
      <abstract_bs>Predstavljamo nove kritike za otkrivanje parafraze na svih šest jezika na sentencijalnom parafrazu Opusparcus korpusu: engleskom, finskom, francuskom, njemačkom, ruskom i švedskom. Stižemo do osnovnih linija sa dobrim sredstvima BERT-a. Najbolji rezultati su postignuti na manjim i čišćem podskupinama obuke nego što je posmatrano u prethodnim istraživanjima. Osim toga, proučavamo pristup na temelju prevoda koji je konkurentniji za jezike sa ograničenijim i buknijim podacima o obuci.</abstract_bs>
      <abstract_cs>Představujeme nové nejmodernější měřítka pro detekci parafráze ve všech šesti jazycích v korpusu Opusparcus sentential parafráze: angličtina, finština, francouzština, němčina, ruština a švédština. Dosáhneme těchto základních linií jemným laděním BERT. Nejlepších výsledků je dosaženo na menších a čistších podskupinách tréninkových sad, než bylo pozorováno v předchozím výzkumu. Navíc studujeme přístup založený na překladu, který je konkurenceschopný pro jazyky s omezenějšími a hlučnějšími tréninkovými daty.</abstract_cs>
      <abstract_et>Esitleme Opusparcuse sentimental parafraasikorpuses uusi kaasaegseid parameetreid parafraaside tuvastamiseks kõigis kuues keeles: inglise, soome, prantsuse, saksa, vene ja rootsi keel. Me jõuame baasjooneni BERTi täpsustades. Parimad tulemused saavutatakse koolituskomplektide väiksematel ja puhtamatel alagruppidel, kui varasemates uuringutes täheldatud. Lisaks uurime tõlkepõhist lähenemisviisi, mis on konkurentsivõimeline keelte jaoks piiratumate ja mürarikamate koolitusandmetega.</abstract_et>
      <abstract_fi>Esittelemme Opusparcus sentential parafraasikorpusessa uusia viitearvoja parafraasien havaitsemiseen kaikilla kuudella kielellä: englanti, suomi, ranska, saksa, venäjä ja ruotsi. Saavutamme nämä perusviivat hienosäätämällä BERT:tä. Parhaimmat tulokset saavutetaan pienemmillä ja puhtaammilla koulutussarjojen osaryhmillä kuin aiemmassa tutkimuksessa havaittiin. Lisäksi tutkimme käännöksiin perustuvaa lähestymistapaa, joka on kilpailukykyinen kielille, joilla on rajallisempaa ja meluisampaa koulutustietoa.</abstract_fi>
      <abstract_jv>Awak dhéwé éntuk perusahaan langkung wih-wih nggawe gerakno kanggo ngerasakno sawar karo hal basa sing dibutungan karo perusahaan Opusual: Inggris, Finis, Perancis, Russisk, Russisk lan Suwiti. Awak dhéwé ngerti barang-barang iki dibenakake BERT . Ndoleh sing paling dhéwé kuwi nggawe aturan luwih lan akeh njaluk sak ning acara dadi, nik awak dhéwé kuwi duluran kanggo ranjut dhéwé. Mungkin maneh, awak dhéwé ngeremu dadi kanggo tarjamahan sing bisa gerakan kanggo langgar luwih apik lan akeh dhéwé kuwi nggawe gerakan.</abstract_jv>
      <abstract_he>אנו מציגים נקודות רמז חדשות של המצב המיוחד לגילוי המילים על כל ששת שפות במילים המשפטיים של אופוספארקוס: אנגלית, פינית, צרפתית, גרמנית, רוסית ושודית. אנחנו מגיעים לשורות הבסיס האלה על ידי התרגיל ברט. התוצאות הטובות ביותר נעשות על תת-קבוצות קטנות ונקיות יותר של קבוצות האימונים ממה שנצפה במחקר קודם. בנוסף, אנו לומדים גישה מבוססת על תרגום שהיא תחרותית לשפות עם נתונים אימונים מוגבלים יותר ויותר רעשים.</abstract_he>
      <abstract_ha>We present new state-of-the-art benchmarks for paraphrase detection on all six languages in the Opusparcus sentential paraphrase corpus: English, Finnish, French, German, Russian, and Swedish.  Mãsu kai ga waɗannan salaffi da ke samun BERT. Suna sami mafi kyaun matsala a kan ƙanƙanan da masu ƙaranci da mai tsari daga an gane su da zaman fitina. Ina ƙaranci, munã karatun wani hanyoyi mai fassarwa wanda ke ƙunci wa lugha da data masu tsari da saurãre ta ƙaranci.</abstract_ha>
      <abstract_sk>Predstavljamo nove najsodobnejše referenčne vrednosti za odkrivanje parafraz na vseh šestih jezikih v korpusu parafraze Opusparcus sentential: angleščina, finščina, francoščina, nemščina, ruščina in švedščina. Te temeljne črte dosežemo z natančnim nastavitvijo BERT. Najboljši rezultati so doseženi na manjših in čistejših podskupinah treningov, kot smo opazili v prejšnjih raziskavah. Poleg tega preučujemo prevajalski pristop, ki je konkurenčen za jezike z bolj omejenimi in hrupnimi podatki o usposabljanju.</abstract_sk>
      <abstract_bo>ང་ཚོས་རྒྱལ་ཁབ་ཀྱི་ཐབས་ལམ་ལ་གནད་སྡུད་མིག་གི་ནང་གི་སྐད་རིགས་གཟུགས་ཐག་མ་གསལ་བཤད་པ་ཚོར་བཀོད་སྟོན་ཡོད། ཨིན་ཇིའི་དང་ མཐའ་མ།(ཨོ་མར། ང་ཚོས་BERT་ལྟར་ཞིབ་ཀྱིས་གཞི་རྟེན་འདི་ཚོ་ཐོག་ཡོད། གྲུབ་འབྲས་འདི་ཚོ་ལས་ཉུང་ཤོས་བྱས་ཆོས་ཉུང་དང་གཙང་དག་བཟོ་བྱེད་ཀྱི་ཡོད་པ་རེད། འོན་ཀྱང་། ང་ཚོས་སྐད་ཡིག</abstract_bo>
      </paper>
    <paper id="35">
      <title>Detecting Cross-Geographic Biases in Toxicity Modeling on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></title>
      <author><first>Sayan</first><last>Ghosh</last></author>
      <author><first>Dylan</first><last>Baker</last></author>
      <author><first>David</first><last>Jurgens</last></author>
      <author><first>Vinodkumar</first><last>Prabhakaran</last></author>
      <pages>313–328</pages>
      <abstract>Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to <a href="https://en.wikipedia.org/wiki/Social_exclusion">marginalized groups</a>, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations / lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</abstract>
      <url hash="66cc0450">2021.wnut-1.35</url>
      <bibkey>ghosh-etal-2021-detecting</bibkey>
      <doi>10.18653/v1/2021.wnut-1.35</doi>
    <title_ar>الكشف عن التحيزات عبر المناطق الجغرافية في نمذجة السمية على وسائل التواصل الاجتماعي</title_ar>
      <title_es>Detección de sesgos geográficos cruzados en el modelado de toxicidad en las redes sociales</title_es>
      <title_fr>Détection des biais intergéographiques dans la modélisation de la toxicité sur les réseaux sociaux</title_fr>
      <title_pt>Detecção de vieses geográficos cruzados na modelagem de toxicidade nas mídias sociais</title_pt>
      <title_ja>ソーシャルメディア上の毒性モデリングにおける交差地理学的バイアスの検出</title_ja>
      <title_zh>检毒于社交媒体建模跨地偏差</title_zh>
      <title_hi>सामाजिक मीडिया पर विषाक्तता मॉडलिंग में क्रॉस-भौगोलिक पूर्वाग्रहों का पता लगाना</title_hi>
      <title_ru>Выявление кросс-географических предрассудков при моделировании токсичности в социальных сетях</title_ru>
      <title_ga>Laofachtaí Trasgheografacha a Bhrath i Samhaltú Tocsaineachta ar na Meáin Shóisialta</title_ga>
      <title_el>Ανίχνευση διαγραφικών προκαταλήψεων στη μοντελοποίηση τοξικότητας στα μέσα κοινωνικής δικτύωσης</title_el>
      <title_ka>სოციალური მედიაში მოდელირებაში კრესი გეგოგოგიური გაზრუნება</title_ka>
      <title_hu>Cross-Geographic Biases észlelése a toxicitás modellezésében a közösségi médiában</title_hu>
      <title_it>Rilevamento di biasi cross-geografici nella modellazione della tossicità sui social media</title_it>
      <title_lt>Social in ės žiniasklaidos toksiškumo modeliavimo tarpgeografinių kliūčių nustatymas</title_lt>
      <title_kk>Токсиктикалық үлгілеріндегі көшегеографиялық көшелерді табу</title_kk>
      <title_ml>സോഷ്യല്‍ മെഡിയയില്‍ സോഷ്യല്‍ മോഡില്‍ ക്രോസ്-ജിയോഗ്രാഫിക് ബൈസുകളെ കണ്ടുപിടിക്കുന്നു</title_ml>
      <title_mk>Детектирање на крстогеографски пречки во моделирањето на токсичноста на социјалните медиуми</title_mk>
      <title_ms>Mengesan Bias Cross-Geographic dalam Modeling Toxicity pada Media Sosial</title_ms>
      <title_no>Finn krysgeografiske opplysningar i toksikitetsmodellering på sosiale mediar</title_no>
      <title_pl>Wykrywanie uprzedzeń geograficznych w modelowaniu toksyczności w mediach społecznościowych</title_pl>
      <title_mt>L-identifikazzjoni ta’ ħsarat transġeografiċi fil-Mudellar tat-Tossiċità fuq il-Midja Soċjali</title_mt>
      <title_si>සාමාජික මාධ්‍යමත්වයේ ක්‍රොස්-භූතික බියාස් හොයාගන්න</title_si>
      <title_sr>Otkrivanje krstogeografijskih tržišta u modelu toksičnosti na socijalnim medijima</title_sr>
      <title_mn>Нийгмийн мэдээлэл дээр Toxicity Modeling in Cross-Geographic Biases Detected</title_mn>
      <title_sv>Att upptäcka tvärgeografiska missförhållanden i toxicitetsmodellering på sociala medier</title_sv>
      <title_ta>சமூக ஊடகங்களில் தொடர்புடைய மாதிரியில் கிராஸ்- ஜியோகிராபிக் பைஸ் கண்டறிதல்</title_ta>
      <title_ro>Detectarea biaselor cross-geografice în modelarea toxicității pe rețelele de socializare</title_ro>
      <title_ur>سوسیلی میڈیا پر ٹکسسیٹی موڈلینگ میں کروس-جغرافیک بیزوز کی تلاش کی</title_ur>
      <title_so>Ku baaraandegista iskuulka-Geographic Biases ee Toxicity Modeling on Social Media</title_so>
      <title_uz>Detecting Cross-Geographic Biases in Toxicity Modeling on Social Media</title_uz>
      <title_vi>Phát hiện thùy thái độ độc tố trên phương tiện xã hội</title_vi>
      <title_bg>Откриване на междугеографски предразсъдъци в моделирането на токсичността в социалните медии</title_bg>
      <title_nl>Detectie van Cross-Geographic Biases in toxiciteitsmodellering op sociale media</title_nl>
      <title_da>Afsløring af tværgående geografiske fordele i toksicitetsmodellering på sociale medier</title_da>
      <title_hr>Otkrivanje Cross-Geographic Biases in Toxicity Modeling on Social Media</title_hr>
      <title_de>Erkennung geographischer Vorurteile bei der Toxizitätsmodellierung in sozialen Medien</title_de>
      <title_id>Mengeteksi Kecelakaan Cross-Geographic dalam Modeling Toksitas di Media Sosial</title_id>
      <title_ko>소셜 미디어 독성 모델에서 지역 간 편견을 검출하다</title_ko>
      <title_fa>شناسایی بین‌های Cross-Geographic در مدل توکسیسیتی در رسانه‌های اجتماعی</title_fa>
      <title_sw>Kugundua mabadiliko ya Msalaba wa Geographic katika Utoaji Mkuu katika Vyombo vya habari vya kijamii</title_sw>
      <title_tr>Toxicity Modeling on Social Media</title_tr>
      <title_af>Kies kruisgeografiese beelde in Toxicity Modeling on Social Media</title_af>
      <title_sq>Duke zbuluar dëmet ndërgjeografike në modelimin e toksicitetit në mediat sociale</title_sq>
      <title_am>መስቀል-የግዮግራፊ ቢሶችን በማኅበራዊ ሚዲያ ላይ ማግኘት</title_am>
      <title_az>Sosyal Medya'da Toxicity Modeling'in Cross-Geographic Biases Detecting on Social Media</title_az>
      <title_hy>Սոցիալական լրատվամիջոցների վրա թունավորության մոդելավորման միջազգային գեոգրաֆիկ շեղումների հայտնաբերումը</title_hy>
      <title_bs>Otkrivanje Cross-Geographic Biases in Toxicity Modeling on Social Media</title_bs>
      <title_bn>সামাজিক প্রচার মাধ্যমে সামাজিক মিডিয়ায় ক্রস-জিওগ্রাফিক বায়েস সনাক্ত করা হচ্ছে</title_bn>
      <title_ca>Detecting Cross Geographic Biases in Toxicity Modelling on Social Media</title_ca>
      <title_cs>Detekce cross-geografických předsudků v modelování toxicity na sociálních médiích</title_cs>
      <title_et>Geograafiliste eelarvamuste tuvastamine toksilisuse modelleerimisel sotsiaalmeedias</title_et>
      <title_fi>Cross-Geographic Biases tunnistaminen myrkyllisyysmallinnassa sosiaalisessa mediassa</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Odkrivanje medgeografskih pristranskosti pri modeliranju strupenosti na socialnih medijih</title_sk>
      <title_jv>Cêngno Krês-jeogras Biasar kanggo Toksi</title_jv>
      <title_bo>Cross-Geographic Biases in Toxicity Modeling on Social Media</title_bo>
      <title_he>גילוי נזקים גאוגרפיים בצורת מודל רעילות במדיה חברתית</title_he>
      <abstract_ar>تعتمد منصات الوسائط الاجتماعية عبر الإنترنت بشكل متزايد على تقنيات معالجة اللغة الطبيعية (NLP) لاكتشاف المحتوى المسيء على نطاق واسع من أجل التخفيف من الأضرار التي يسببها لمستخدميها. ومع ذلك ، فإن هذه التقنيات تعاني من تحيزات مختلفة لأخذ العينات وترابط موجودة في بيانات التدريب ، مما يؤدي غالبًا إلى أداء دون المستوى على المحتوى ذي الصلة بالفئات المهمشة ، مما قد يؤدي إلى زيادة الأضرار غير المتناسبة تجاههم. ركزت الدراسات حول مثل هذه التحيزات حتى الآن على عدد قليل فقط من محاور التباينات والمجموعات الفرعية التي لديها شروح / معاجم متاحة. وبالتالي ، يتم تجاهل التحيزات المتعلقة بالسياقات غير الغربية إلى حد كبير في الأدبيات. في هذه الورقة ، نقدم طريقة خاضعة للإشراف الضعيف لاكتشاف التحيزات المعجمية بقوة في السياقات الجغرافية الثقافية الأوسع. من خلال دراسة حالة حول نموذج الكشف عن السمية المتاح للجمهور ، نوضح أن طريقتنا تحدد المجموعات البارزة من الأخطاء الجغرافية ، وفي متابعة ، نوضح أن هذه المجموعات تعكس الأحكام البشرية للغة مسيئة وغير مؤذية في تلك السياقات الجغرافية. نجري أيضًا تحليلًا لنموذج تم تدريبه على مجموعة بيانات مع تسميات الحقيقة الأساسية لفهم هذه التحيزات بشكل أفضل ، وتقديم تجارب التخفيف الأولية.</abstract_ar>
      <abstract_es>Las plataformas de redes sociales en línea confían cada vez más en las técnicas de procesamiento del lenguaje natural (NLP) para detectar contenido abusivo a escala con el fin de mitigar los daños que causa a sus usuarios. Sin embargo, estas técnicas sufren de varios sesgos de muestreo y asociación presentes en los datos de entrenamiento, lo que a menudo resulta en un rendimiento inferior al promedio en el contenido relevante para los grupos marginados, lo que podría aumentar los daños desproporcionados hacia ellos. Los estudios sobre estos sesgos hasta ahora se han centrado en solo un puñado de ejes de disparidades y subgrupos que tienen anotaciones/léxicos disponibles. En consecuencia, los sesgos relacionados con contextos no occidentales se ignoran en gran medida en la literatura. En este artículo, presentamos un método débilmente supervisado para detectar de manera sólida los sesgos léxicos en contextos geoculturales más amplios. A través de un estudio de caso sobre un modelo de detección de toxicidad disponible públicamente, demostramos que nuestro método identifica grupos destacados de errores intergeográficos y, en un seguimiento, demostramos que estas agrupaciones reflejan los juicios humanos sobre el lenguaje ofensivo e inofensivo en esos contextos geográficos. También realizamos análisis de un modelo entrenado en un conjunto de datos con etiquetas de verdad sobre el terreno para comprender mejor estos sesgos y presentamos experimentos preliminares de mitigación.</abstract_es>
      <abstract_pt>As plataformas de mídia social online contam cada vez mais com técnicas de processamento de linguagem natural (NLP) para detectar conteúdo abusivo em escala, a fim de mitigar os danos que causa aos seus usuários. No entanto, essas técnicas sofrem de vários vieses de amostragem e associação presentes nos dados de treinamento, muitas vezes resultando em desempenho abaixo da média em conteúdo relevante para grupos marginalizados, potencialmente causando danos desproporcionais a eles. Os estudos sobre tais vieses até agora se concentraram em apenas alguns eixos de disparidades e subgrupos que possuem anotações/léxicos disponíveis. Conseqüentemente, preconceitos relativos a contextos não-ocidentais são amplamente ignorados na literatura. Neste artigo, apresentamos um método fracamente supervisionado para detectar de forma robusta os vieses lexicais em contextos geoculturais mais amplos. Por meio de um estudo de caso em um modelo de detecção de toxicidade disponível publicamente, demonstramos que nosso método identifica grupos salientes de erros geográficos cruzados e, em um acompanhamento, demonstramos que esses agrupamentos refletem julgamentos humanos de linguagem ofensiva e inofensiva nesses contextos geográficos. Também realizamos a análise de um modelo treinado em um conjunto de dados com rótulos de verdade para entender melhor esses vieses e apresentamos experimentos preliminares de mitigação.</abstract_pt>
      <abstract_fr>Les plateformes de réseaux sociaux en ligne s'appuient de plus en plus sur les techniques de traitement du langage naturel (NLP) pour détecter les contenus abusifs à grande échelle afin d'atténuer les préjudices qu'ils causent à leurs utilisateurs. Cependant, ces techniques souffrent de divers biais d'échantillonnage et d'association présents dans les données de formation, ce qui se traduit souvent par des performances médiocres sur le contenu pertinent pour les groupes marginalisés, ce qui peut aggraver les préjudices disproportionnés à leur égard. Jusqu'à présent, les études sur de tels biais se sont concentrées sur une poignée d'axes de disparités et de sous-groupes pour lesquels des annotations/lexiques sont disponibles. Par conséquent, les préjugés concernant les contextes non occidentaux sont largement ignorés dans la littérature. Dans cet article, nous présentons une méthode faiblement supervisée pour détecter de manière robuste les biais lexicaux dans des contextes géoculturels plus larges. Au moyen d'une étude de cas portant sur un modèle de détection de la toxicité accessible au public, nous démontrons que notre méthode identifie les principaux groupes d'erreurs intergéographiques et, dans un suivi, nous démontrons que ces regroupements reflètent les jugements humains sur le langage offensant et inoffensif dans ces contextes géographiques. Nous effectuons également l'analyse d'un modèle formé sur un ensemble de données avec des étiquettes de vérité de terrain afin de mieux comprendre ces biais, et présentons des expériences préliminaires d'atténuation.</abstract_fr>
      <abstract_ja>オンラインソーシャルメディアプラットフォームは、ユーザーに与える害を軽減するために、自然言語処理（ NLP ）技術に依存して、不正なコンテンツを大規模に検出することが増えています。 しかし、これらのテクニックは、トレーニングデータに存在する様々なサンプリングおよび関連バイアスに苦しみ、多くの場合、過疎化されたグループに関連するコンテンツのパフォーマンスが低い結果となり、それらに対する過度の害をさらに拡大する可能性があります。 このようなバイアスに関する研究は、これまで、注釈/辞書が利用可能なわずかな格差軸とサブグループに焦点を当ててきました。 したがって、非西洋の文脈に関するバイアスは、文献ではほとんど無視される。 本稿では、より広範な地理的文化的文脈における語彙バイアスを堅牢に検出するための弱い監督下の方法を紹介する。 公的に入手可能な毒性検出モデルのケーススタディを通じて、私たちの方法がクロスジオグラフィックエラーの顕著なグループを識別し、フォローアップでは、これらのグループがそれらの地理的文脈における攻撃的および非攻撃的言語の人間の判断を反映していることを実証します。 また、これらのバイアスをよりよく理解するために、グラウンドトゥルースラベルを備えたデータセットでトレーニングされたモデルの分析を行い、予備的な緩和実験を提示します。</abstract_ja>
      <abstract_ru>Онлайн-платформы социальных сетей все чаще используют методы обработки естественного языка (NLP) для обнаружения оскорбительного контента в масштабе, чтобы уменьшить вред, который он наносит их пользователям. Вместе с тем эти методы страдают от различных систематических ошибок в выборочных и сопоставительных данных, присутствующих в данных о профессиональной подготовке, что зачастую приводит к получению результатов по содержанию, относящемуся к маргинализированным группам, что потенциально усугубляет причинение им несоразмерного вреда. До настоящего времени исследования по таким систематическим отклонениям были сосредоточены лишь на нескольких осях различий и подгруппах, в которых имеются аннотации/лексиконы. Следовательно, предвзятость в отношении незападных контекстов в значительной степени игнорируется в литературе. В этой статье мы вводим слабо контролируемый метод для надежного обнаружения лексических искажений в более широком геокультурном контексте. Посредством тематического исследования на общедоступной модели обнаружения токсичности мы демонстрируем, что наш метод идентифицирует основные группы кросс-географических ошибок, и в дальнейшем демонстрируем, что эти группировки отражают человеческие суждения оскорбительных и не оскорбительных формулировок в этих географических контекстах. Мы также проводим анализ модели, обученной на наборе данных с наземными метками истины, чтобы лучше понять эти смещения, и представляем предварительные эксперименты по смягчению последствий.</abstract_ru>
      <abstract_zh>在线社交媒体台益恃自然语言(NLP)术以大检滥,以轻其伤用户。 然而训练数抽样,关联偏差,往往致于边缘化群体之间,可得而伤不成比例也。 至目前为止,偏见者集少数几个注/词典悬差轴和子组上。 是以非西语境之偏见于文献者大矣。 本文引一弱监督之法,以广地理文化背景下稳检词汇差。 以明毒检模形之案,证吾法识跨地之非,而续治之,证人之犯无攻击性言也。 又于地面真标之数集上训练之法,以善知其偏差,并陈初步之缓实验。</abstract_zh>
      <abstract_hi>ऑनलाइन सोशल मीडिया प्लेटफ़ॉर्म तेजी से प्राकृतिक भाषा प्रसंस्करण (एनएलपी) तकनीकों पर भरोसा करते हैं ताकि वे अपने उपयोगकर्ताओं को होने वाले नुकसान को कम करने के लिए पैमाने पर अपमानजनक सामग्री का पता लगा सकें। हालांकि, ये तकनीकें प्रशिक्षण डेटा में मौजूद विभिन्न नमूनाकरण और एसोसिएशन पूर्वाग्रहों से पीड़ित हैं, जिसके परिणामस्वरूप अक्सर हाशिए के समूहों के लिए प्रासंगिक सामग्री पर उप-बराबर प्रदर्शन होता है, संभावित रूप से उनके प्रति असमान नुकसान को आगे बढ़ाता है। इस तरह के पूर्वाग्रहों पर अध्ययन ने अब तक असमानताओं और उपसमूहों के केवल कुछ मुट्ठी भर अक्षों पर ध्यान केंद्रित किया है जिनके पास एनोटेशन / शब्दकोश उपलब्ध हैं। नतीजतन, गैर-पश्चिमी संदर्भों से संबंधित पूर्वाग्रहों को साहित्य में काफी हद तक अनदेखा किया जाता है। इस पेपर में, हम व्यापक भू-सांस्कृतिक संदर्भों में लेक्सिकल पूर्वाग्रहों का मजबूती से पता लगाने के लिए एक कमजोर पर्यवेक्षित विधि पेश करते हैं। एक सार्वजनिक रूप से उपलब्ध विषाक्तता का पता लगाने के मॉडल पर एक मामले के अध्ययन के माध्यम से, हम प्रदर्शित करते हैं कि हमारी विधि क्रॉस-भौगोलिक त्रुटियों के प्रमुख समूहों की पहचान करती है, और, एक अनुवर्ती में, यह प्रदर्शित करती है कि ये समूह उन भौगोलिक संदर्भों में आक्रामक और अपमानजनक भाषा के मानव निर्णयों को दर्शाते हैं। हम इन पूर्वाग्रहों को बेहतर ढंग से समझने के लिए जमीनी सच्चाई लेबल के साथ डेटासेट पर प्रशिक्षित मॉडल का विश्लेषण भी करते हैं, और प्रारंभिक शमन प्रयोगों को प्रस्तुत करते हैं।</abstract_hi>
      <abstract_ga>Bíonn ardáin meán sóisialta ar líne ag brath níos mó ar theicnící Próiseála Teanga Nádúrtha (NLP) chun ábhar mí-úsáideach a bhrath ar scála chun na dochair a dhéanann sé dá n-úsáideoirí a mhaolú. Mar sin féin, tá na teicníochtaí seo thíos le claontaí samplála agus comhlachais éagsúla atá i sonraí oiliúna, rud a fhágann go mbíonn feidhmíocht fo-par ar ábhar a bhaineann le grúpaí imeallaithe go minic, rud a d’fhéadfadh díobháil dhíréireach ina leith a chur chun cinn. Dhírigh staidéir ar laofachtaí den sórt sin go dtí seo ar dornán d’aiseanna éagsúlachtaí agus d’fhoghrúpaí a bhfuil nótaí/léacsanna ar fáil acu. Dá bhrí sin, déantar neamhaird den chuid is mó sa litríocht ar laofachtaí a bhaineann le comhthéacsanna neamh-Iartharacha. Sa pháipéar seo, tugaimid isteach modh faoi mhaoirseacht lag chun laofachtaí foclóireachta a bhrath go láidir i gcomhthéacsanna geochultúrtha níos leithne. Trí chás-staidéar ar shamhail braite tocsaineachta atá ar fáil go poiblí, léirímid go n-aithnítear inár modh grúpaí suntasacha earráidí trasgheografacha, agus, mar athleanúint, léirímid go léiríonn na grúpálacha seo breithiúnais daonna ar theanga maslach agus neamhionsaitheach sna comhthéacsanna geografacha sin. Déanaimid anailís freisin ar shamhail atá oilte ar thacar sonraí le lipéid fhírinneachta chun tuiscint níos fearr a fháil ar na laofachtaí sin, agus cuirimid i láthair turgnaimh mhaolaithe tosaigh.</abstract_ga>
      <abstract_hu>Az online közösségi média platformok egyre inkább a Natural Language Processing (NLP) technikákra támaszkodnak a visszaélő tartalmak nagyságrendű felismerésére annak érdekében, hogy enyhítsék a felhasználóknak okozott károkat. Ezek a technikák azonban a képzési adatokban jelen lévő különböző mintavételi és asszociációs előítéletektől szenvednek, amelyek gyakran a marginalizált csoportok számára releváns tartalom alatti teljesítményt eredményeznek, ami aránytalanul nagy károkat okozhat számukra. Az ilyen előítéletekkel kapcsolatos tanulmányok eddig csak néhány tengelyre és alcsoportra összpontosítottak, amelyek rendelkezésre állnak jegyzetek/lexikonok. Következésképpen a nem nyugati kontextusokra vonatkozó elfogultságokat nagymértékben figyelmen kívül hagyják az irodalomban. Ebben a tanulmányban egy gyengén felügyelt módszert mutatunk be a lexikális elfogultságok robusztus felismerésére szélesebb geokulturális kontextusokban. Egy nyilvánosan hozzáférhető toxicitás detektálási modellre vonatkozó esettanulmány révén kimutatjuk, hogy módszerünk azonosítja a földrajzi hibák kiemelkedő csoportjait, és egy nyomon követésben kimutatjuk, hogy ezek a csoportok tükrözik a sértő és ártalmatlan nyelv emberi ítéletét ezekben a földrajzi kontextusokban. Ezen előítéletek jobb megértése érdekében egy adatkészletre képzett modell elemzését is elvégezzük, amely alapvető igazságcímkékkel rendelkezik, és előzetes enyhítési kísérleteket mutatunk be.</abstract_hu>
      <abstract_ka>Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. მაგრამ, ეს ტექნოგიები განსხვავებული მონაცემების და აზოციაციის წარმოდგენებიდან დაკავშირებული მონაცემების შესახებ, რომლებიც შეიძლება მარტინალიზებული ჯგუფთან მნიშვნელოვანი წარმოდგენების შესახე ასეთი წარმოდგენების შესახებ მხოლოდ განსხვავებულებების და სებჯგუფების კონუქტირებაზე, რომლებიც აქვს წარმოდგენები/ლექსიკონები. შემდეგ, დასავლეთ კონტექსტში არ არის დასავლეთ კონტექსტზე მნიშვნელოვანია ლიტერატურაში. ამ დოკუტურაში ჩვენ ჩვენ შევცვალოთ ძალიან უფრო დიო-კულტურალური კონტექსტში ლექსიკალური წარმოდგენება. სურათის შესახებ სახელსაწინო ტექსტიკური მოდელზე, ჩვენ გამოჩვენებთ, რომ ჩვენი მეთოდი განსაზღვრავს კრესი გეგოგოფიკური შეცდომილებების სურათი ჯგუფების და, შემდეგ შემდეგ, გამოჩვენება, რომ ეს ჯგუფები განსაზღვრავს ადამიანი ჩვენ ასევე გავაკეთებთ მოდელის ანალიზაციას, რომელიც მონაცემების კონფიგურაციაში გავაკეთებთ სინამდვილეებით, რომ უფრო უფრო გავიგეთ ეს წინასწორებები, და ახლა</abstract_ka>
      <abstract_el>Οι διαδικτυακές πλατφόρμες κοινωνικών μέσων βασίζονται όλο και περισσότερο στις τεχνικές επεξεργασίας φυσικής γλώσσας (για τον εντοπισμό καταχρηστικού περιεχομένου σε κλίμακα, προκειμένου να μετριαστούν οι βλάβες που προκαλεί στους χρήστες τους. Ωστόσο, οι τεχνικές αυτές υποφέρουν από διάφορες προκατάληψη δειγματοληψίας και συσχέτισης που υπάρχουν στα δεδομένα κατάρτισης, συχνά με αποτέλεσμα την κατώτερη απόδοση του περιεχομένου που σχετίζεται με περιθωριοποιημένες ομάδες, προκαλώντας ενδεχομένως δυσανάλογες βλάβες προς αυτές. Μελέτες σχετικά με τέτοιες προκατάληψη έχουν επικεντρωθεί μέχρι στιγμής σε μια χούφτα αξόνων ανισοτήτων και υποομάδες που έχουν διαθέσιμα σχόλια/λεξικά. Κατά συνέπεια, οι προκαταλήψεις σχετικά με τα μη Δυτικά πλαίσια αγνοούνται σε μεγάλο βαθμό στη βιβλιογραφία. Στην παρούσα εργασία, εισάγουμε μια αδύναμη εποπτευόμενη μέθοδο για την εύρωστη ανίχνευση λεξικών προκατάληψης σε ευρύτερα γεωπολιτισμικά πλαίσια. Μέσα από μια μελέτη περίπτωσης σε ένα δημοσίως διαθέσιμο μοντέλο ανίχνευσης τοξικότητας, καταδεικνύουμε ότι η μέθοδος μας εντοπίζει σημαντικές ομάδες διαγραφικών σφαλμάτων και, σε συνέχεια, αποδεικνύει ότι αυτές οι ομάδες αντικατοπτρίζουν ανθρώπινες κρίσεις προσβλητικής και αβλαβούς γλώσσας σε αυτά τα γεωγραφικά πλαίσια. Επίσης, διεξάγουμε ανάλυση ενός μοντέλου εκπαιδευμένου σε ένα σύνολο δεδομένων με ετικέτες βάσεων αλήθειας για να κατανοήσουμε καλύτερα αυτές τις προκαταλήψεις, και παρουσιάζουμε προκαταρκτικά πειράματα μετριασμού.</abstract_el>
      <abstract_kk>Онлайн социаллық медиа платформалары өзінің пайдаланушыларының қауіпсіздіктерін көшірмелеу үшін, қауіпсіздік мазмұнын анықтау (NLP) технологияларына тәуелді. Бірақ бұл технологиялар бірнеше мәліметтерді баптауға және бөлімдерінің бірнеше тәжірибелерінен тәжірибелерінен тәжірибеледі, көбінде бөлімдерге қатысты мазмұның көбінде тәжірибеле Бұл тәртіптердің зерттеулері тек бірнеше бөлшектерді және ішкі топтардың бірнеше бөлшектеріне көздеген. Сондықтан Батыс-Батыс контексттерінің қатынасы әдебиетте көбінде елемейді. Бұл қағаздың көбірек гео-мәдениеттің көбірек жағдайларында лексикалық өзгерістерді анықтау үшін бақылау әдісін келтіреміз. Осы топтарды көпшілік жеткізу үлгісін табу үлгісінің арқылы біз әдіміздің көпшілік географиялық қателер топтарын анықтай алатынын көрсетедік. Бұл топтар географиялық тәртіптерінде адамдардың тәртіптерін көрсетеді. Сонымен қатар, бұл өзгерістерді жақсы түсінуге және алдындағы өзгерістерді түсінуге арналған деректер қорларында оқыту үлгісін анализ істейміз.</abstract_kk>
      <abstract_it>Le piattaforme di social media online si affidano sempre più alle tecniche di Natural Language Processing (NLP) per rilevare contenuti abusivi su larga scala al fine di mitigare i danni che causano ai loro utenti. Tuttavia, queste tecniche soffrono di vari pregiudizi di campionamento e associazione presenti nei dati di formazione, spesso con conseguente performance sub-par sui contenuti rilevanti per i gruppi emarginati, con potenziali danni sproporzionati nei loro confronti. Gli studi su tali pregiudizi finora si sono concentrati solo su una manciata di assi di disparità e sottogruppi che hanno annotazioni/lessici disponibili. Di conseguenza, i pregiudizi riguardanti contesti non occidentali sono ampiamente ignorati nella letteratura. In questo articolo, introduciamo un metodo debolmente supervisionato per rilevare in modo solido i pregiudizi lessicali in contesti geo-culturali più ampi. Attraverso un caso di studio su un modello di rilevazione della tossicità pubblicamente disponibile, dimostriamo che il nostro metodo identifica gruppi salienti di errori cross-geografici e, in un follow-up, dimostriamo che questi raggruppamenti riflettono giudizi umani di linguaggio offensivo e inoffensivo in quei contesti geografici. Conduciamo anche analisi di un modello addestrato su un set di dati con etichette di verità di base per comprendere meglio questi pregiudizi e presentiamo esperimenti preliminari di mitigazione.</abstract_it>
      <abstract_ml>സ്വാഭാവിക ഭാഷ പ്രവര്‍ത്തനത്തിന്‍റെ (NLP) സാങ്കേതികവിദ്യയുടെ ഉപയോക്താക്കള്‍ക്ക് വേണ്ടി അതിന്‍റെ ഉപദ്രവങ്ങള്‍ കുറയ്ക്കാനുള്ള ഉപയോക്താ എന്നാലും പരിശീലനത്തിലുള്ള വ്യത്യസ്ത പരീക്ഷണത്തില്‍ നിന്നും ഈ സാങ്കേതികവിദ്യകള്‍ അനുഭവിക്കുന്നു. പലപ്പോഴും കൂട്ടത്തില്‍ ബന്ധപ്പെട്ട വിഭവങ്ങളില്‍ സു ഇങ്ങനെയുള്ള വ്യത്യാസങ്ങളെക്കുറിച്ചുള്ള പഠനങ്ങള്‍ മാത്രമേ ശ്രദ്ധിച്ചിരിക്കുന്നുള്ളൂ വ്യത്യാസങ്ങളുടെയും സബ്ഗ അതുകൊണ്ട്, പടിഞ്ഞാറന്‍ അല്ലാത്ത പദ്ധതികളെക്കുറിച്ചുള്ള പൊരുത്തകള്‍ സാഹിത്യത്തില്‍ ഏറ്റവും അശ്രദ്ധയില ഈ പത്രത്തില്‍, നമ്മള്‍ ദുര്‍ബലമായി നിരീക്ഷിക്കപ്പെട്ട ഒരു രീതിയില്‍ പരിചയപ്പെടുത്തുന്നു. ലെക്സിക്കല്‍ പ്രശ്നങ്ങള്‍ കാണാന്‍  പ്രസിദ്ധമായ ഒരു കേസ് പഠനത്തിലൂടെ നാം കാണിക്കുന്നു, നമ്മുടെ രീതിയില്‍ ക്രൂസ്രോഗ്രാഫിക് തെറ്റുകള്‍ തിരിച്ചറിയുന്നു എന്ന് നമ്മുടെ രീതിയില്‍ പ്രത്യക്ഷപ്പെടുത്തുന് ഭൂമിയിലുള്ള സത്യ ചിട്ടയുമുള്ള ഒരു ഡാറ്റാസെറ്റില്‍ പരിശീലിക്കപ്പെട്ട മോഡലിന്‍റെ അന്വേഷണം ഞങ്ങള്‍ പ്രവര്‍ത്തിക്കുന്നു. ഈ</abstract_ml>
      <abstract_mk>Онлајн платформите на социјалните медиуми сé повеќе се потпираат на техниките за процес на природен јазик (НЛП) за детектирање на злоупотребна содржина на скала со цел да се намали штетата што ја предизвикува за нивните корисници. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially furthering disproportionate harms towards them.  Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available.  Поради тоа, предрасудите во врска со незападните контексти се во голема мера игнорирани во литературата. Во овој весник, воведуваме слабо надгледуван метод за силно детектирање на лексикалните предрасуди во пошироки гео-културни контексти. Преку случајна студија за јавно достапен модел за детекција на токсичност, ние демонстрираме дека нашиот метод идентификува основни групи на крстогеографски грешки, и, како следење, демонстрираме дека овие групи одразуваат човечки пресуди на офанзивниот и непријателен јазик во тие географски контексти. Ние, исто така, спроведуваме анализа на модел обучен на податоци со основни ознаки на вистината за подобро да ги разбереме овие предрасуди и да претставиме прелиминарни експерименти за олеснување.</abstract_mk>
      <abstract_lt>Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users.  Tačiau šie metodai kenčia nuo įvairių mokymo duomenise esančių mėginių ėmimo ir asociacijos sąlyčių, dėl kurių dažnai atsiranda mažesnis kiekio lygis, susijęs su marginalizuotomis grupėmis, ir dėl to gali būti daroma neproporcinga žala jiems. Iki šiol atlikti tokių pusiausvyrų tyrimai daugiausia dėmesio skyrė tik kelioms skirtumų a šims ir pogrupiams, kuriuose yra anotacijų ir (arba) leksikonų. Taigi literatūroje iš esmės ignoruojami ne Vakarų konteksto iškraipymai. Šiame dokumente įvedame silpnai prižiūrėtą metodą, skirtą tvirtai nustatyti leksinius nukrypimus platesnėse geokultūrinėse aplinkybėse. Atliekant atvejų tyrimą dėl viešai prieinamo toksiškumo nustatymo modelio mes įrodome, kad mūsų metodas nustato svarbias tarpgeografinių klaidų grupes ir, tolesniais veiksmais, įrodo, kad šios grupės atspindi žmogiškuosius nusikalstamos ir žalingos kalbos sprendimus šiose geografinėse aplinkybėse. Taip pat atliekame modelio, parengto duomenų rinkinyje su antžeminėmis tiesos etiketėmis, analizę, kad geriau suprastume šiuos šalutinius aspektus ir pristatytume preliminarius švelninimo eksperimentus.</abstract_lt>
      <abstract_mt>Pjattaformi tal-midja soċjali onlajn dejjem aktar jiddependu fuq tekniki tal-ipproċessar tal-lingwi naturali (NLP) biex jinstabu kontenut abbużiv fuq skala sabiex jittaffew il-ħsarat li jikkawża lill-utenti tagħhom. Madankollu, dawn it-tekniki jsofru minn diversi preġudizzji għat-teħid ta’ kampjuni u assoċjazzjoni preżenti fid-dejta tat-taħriġ, li spiss jirriżultaw fi prestazzjoni sub-pari fuq il-kontenut rilevanti għal gruppi marġinalizzati, li potenzjalment jippromwovu ħsara sproporzjonata għalihom. L-istudji dwar tali preġudizzji s’issa ffukaw biss fuq ftit assi ta’ disparitajiet u sottogruppi li għandhom annotazzjonijiet/lexicons disponibbli. Konsegwentement, il-preġudizzji li jikkonċernaw kuntesti mhux tal-Punent huma fil-biċċa l-kbira injorati fil-letteratura. F’dan id-dokument, a ħna nintroduċu metodu b’superviżjoni dgħajfa biex niskopru b’mod robust il-preġudizzji lexiċi f’kuntesti ġeo-kulturali usa’. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts.  Għandna nagħmlu wkoll analiżi ta’ mudell imħarreġ fuq sett ta’ dejta b’tikketti tal-verità tal-art biex nifhmu a ħjar dawn il-preġudizzji, u nippreżentaw esperimenti preliminari ta’ mitigazzjoni.</abstract_mt>
      <abstract_ms>Platform media sosial online semakin bergantung pada teknik Proses Bahasa Alami (NLP) untuk mengesan kandungan yang melampaui batas pada skala untuk mengurangi kerosakan yang disebabkan kepada pengguna mereka. Namun, teknik-teknik ini menderita dari pelbagai biases pengumpulan sampel dan asosiasi yang ada dalam data latihan, sering menghasilkan prestasi sub-par pada kandungan yang berkaitan dengan kumpulan marginalisasi, yang berpotensi melanjutkan kerosakan yang tidak proporsional terhadap mereka. Studi tentang biases seperti ini sejauh ini telah fokus pada hanya beberapa paksi ketidaksamaan dan subkumpulan yang mempunyai anotasi/leksikon tersedia. Oleh sebab itu, biases mengenai konteks bukan Barat kebanyakan diabaikan dalam literatur. Dalam kertas ini, kami memperkenalkan kaedah yang terpantau lemah untuk mengesan secara kuat bias lexik dalam konteks geo-budaya yang lebih luas. Melalui kajian kes mengenai model pengesan toksiciti yang tersedia pada masyarakat, kami menunjukkan bahawa kaedah kami mengenalpasti kumpulan-kumpulan yang penting ralat-ralat melintasi geografi, dan, dalam kejadian, menunjukkan bahawa kumpulan-kumpulan ini mencerminkan penilaian manusia bahasa yang menyerang dan tidak menyerang dalam konteks geografi tersebut. We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</abstract_ms>
      <abstract_ro>Platformele de social media online se bazează din ce în ce mai mult pe tehnicile Natural Language Processing (NLP) pentru a detecta conținutul abuziv la scară, pentru a atenua daunele pe care le provoacă utilizatorilor lor. Cu toate acestea, aceste tehnici suferă de diferite prejudecăți ale eșantionării și asocierii prezente în datele de formare, adesea rezultând în performanțe sub-par cu privire la conținutul relevant pentru grupurile marginalizate, ceea ce ar putea duce la prejudicii disproporționate pentru acestea. Studiile privind astfel de prejudecăți s-au concentrat până în prezent pe doar o mână de axe de disparități și subgrupuri care au adnotări / lexicoane disponibile. În consecință, prejudecățile privind contextele non-occidentale sunt ignorate în mare măsură în literatură. În această lucrare, introducem o metodă slab supravegheată pentru detectarea robustă a prejudecăților lexicale în contexte geo-culturale mai largi. Printr-un studiu de caz pe un model de detectare a toxicității accesibil publicului, demonstrăm că metoda noastră identifică grupuri importante de erori cross-geografice și, într-o continuare, demonstrăm că aceste grupuri reflectă judecățile umane de limbaj ofensator și inofensiv în acele contexte geografice. De asemenea, efectuăm analiza unui model instruit pe un set de date cu etichete de adevăr de bază pentru a înțelege mai bine aceste prejudecăți și prezentăm experimente preliminare de atenuare.</abstract_ro>
      <abstract_pl>Platformy internetowe mediów społecznościowych coraz częściej opierają się na technikach przetwarzania języka naturalnego (NLP), aby wykrywać na skalę nadużywające treści, aby złagodzić szkody, jakie wyrządza ich użytkownikom. Techniki te cierpią jednak z powodu różnych uprzedzeń dotyczących próbek i skojarzeń występujących w danych szkoleniowych, co często prowadzi do niskiej wydajności treści istotnych dla grup marginalizowanych, co potencjalnie powoduje nieproporcjonalne szkody dla nich. Do tej pory badania nad takimi uprzedzeniami skupiały się tylko na kilku osiach dysproporcji i podgrupach, które mają dostępne adnotacje/leksykony. W związku z tym uprzedzenia dotyczące kontekstów niezachodnich są w dużej mierze ignorowane w literaturze. W niniejszym artykule przedstawiamy słabo nadzorowaną metodę solidnego wykrywania uprzedzeń leksykalnych w szerszych kontekstach geokulturowych. Poprzez studium przypadku publicznie dostępnego modelu wykrywania toksyczności, wykazujemy, że nasza metoda identyfikuje istotne grupy błędów między geograficznymi, a w dalszym ciągu wykazuje, że grupy te odzwierciedlają ludzkie osądy obraźliwego i nieszkodliwego języka w tych kontekstach geograficznych. Przeprowadzamy również analizę modelu przeszkolonego na zbiorze danych z etykietami gruntowymi prawdy w celu lepszego zrozumienia tych uprzedzeń oraz przedstawiamy wstępne eksperymenty łagodzące.</abstract_pl>
      <abstract_sr>Онлайн социални медији платформе већ се осећавају на технике природног језика (NLP) за откривање злоупредног содержања на масштабу kako bi смалио ужар који причини њиховим потребителима. Međutim, ove tehnike pate od različitih predrasuda uzoraka i udruženja koji su prisutni u podacima obuke, što često rezultira pod-par učinkovitosti sadržaja relevantnog marginaliziranim grupama, potencijalno unaprijeđujući neproporcione štete prema njima. Istraživanja o takvim predrasudama do sada su fokusirane na samo gomilu sjekira različitih i podskupina koja imaju dostupne annotacije/leksione. Stoga, predrasude u vezi nezapadnih konteksta uglavnom se ignoriraju u literaturi. U ovom papiru predstavljamo slabu nadzornu metodu da bi opšte otkrili leksičke predrasude u širima geokulturnim kontekstima. Kroz istraživanje slučajeva o javno dostupnom modelu otkrivanja toksičnosti, pokazujemo da naša metoda identifikuje salijante grupe cross-geografskih grešaka, i u praćenju pokazuje da ove grupe odražavaju ljudske osude o uvredljivom i neinfektivnom jeziku u tim geografskim kontekstima. Takođe vodimo analizu model a obučenog na setu podataka sa oznakema istine kako bi bolje razumeli te predrasude, i predstavljali preliminarne eksperimente za smanjenje.</abstract_sr>
      <abstract_mn>Онлайн нийгмийн хэвлэлийн платформ нь байгалийн хэл процесс (NLP) технологийг ихэвчлэн хэрэглэгчиддээ үүнийг зориулахын тулд хүчирхийллэг content-г олж мэдэх боломжтой. Гэвч эдгээр техникууд сургалтын өгөгдлийн талаар байгаа олон жишээн хэлбэрээс холбогдох болон нийгмийн алдагдлыг шаналж, ихэвчлэн холбогдсон бүлэгтэй холбогдолтой бүлэгтэй холбогдолтой төвөгтэй байдаг. Орчин үед иймэрхүү өргөн талаар судалгаа нь зөвхөн олон тэнхлэгүүд болон суббагтаас илэрхийлэл/лексиконууд ашиглаж байна. Үүнээс баруун бус нөхцөл байдлын тухай өрөөсгөл ойлголт уран зохиолд ихэвчлэн үзэгддэг. Энэ цаасан дээр бид илүү өргөн гео-соёлын нөхцөлд лексикийн зан чанарыг олохын тулд бага зэрэг удирдлагатай аргыг тайлбарлаж байна. Олон нийтийн шинжлэх ухааны загварын тухай судалгаагаагаар бидний арга нь олон географик алдааны шинжлэх ухааны бүлгүүдийг тодорхойлдог гэдгийг харуулж байна. Дараагийн дараа нь эдгээр бүлгүүд хүн төрөлхтний шийдвэрлэлийг харуулж байна. Мөн бид үүнийг илүү ойлгохын тулд сургалтын өгөгдлийн сан дээр сургалтын загварын талаар шинжилгээ хийдэг.</abstract_mn>
      <abstract_sv>Sociala medieplattformar online förlitar sig alltmer på Natural Language Processing (NLP) tekniker för att upptäcka kränkande innehåll i stor skala för att mildra de skador som det orsakar för sina användare. Dessa tekniker lider dock av olika provtagnings- och associeringsformigheter som förekommer i utbildningsdata, vilket ofta leder till underordnad prestanda på innehåll som är relevant för marginaliserade grupper, vilket kan leda till oproportionerliga skador för dem. Studier av sådana fördomar har hittills fokuserat på endast en handfull axlar av skillnader och undergrupper som har kommentarer/lexikon tillgängliga. Följaktligen ignoreras fördomar gällande icke-västerländska sammanhang i stor utsträckning i litteraturen. I denna uppsats introducerar vi en svagt övervakad metod för att robust upptäcka lexikala fördomar i bredare geo-kulturella sammanhang. Genom en fallstudie på en offentligt tillgänglig toxicitetsdetektionsmodell visar vi att vår metod identifierar framträdande grupper av tvärgeografiska fel, och i en uppföljning visar vi att dessa grupperingar återspeglar mänskliga bedömningar av stötande och ofarligt språk i dessa geografiska sammanhang. Vi genomför även analys av en modell som tränats på ett dataset med marksanningsetiketter för att bättre förstå dessa fördomar och presenterar preliminära begränsningsexperiment.</abstract_sv>
      <abstract_si>ඇන්ලයින් සාමාජික මිඩියාව ප්‍රවේශය විශ්වාස කරනවා නියම භාෂාව ප්‍රවේශනය (NLP) තේක්ෂණාවට පරීක්ෂණය කරන්න සැලසුම්  නමුත්, මේ තාක්ෂණාවල් විවිදිහට සැම්පල් එක්ක සම්බන්ධතාවක් සහ සම්බන්ධතාවක් තියෙනවා ප්‍රීක්ෂණා දත්තේ තියෙන්නේ, සාමාන්‍ය විදිහ අතර දැනටම අධ්‍යානය සඳහා අධ්‍යානය සඳහා අධ්‍යානය සඳහා අධ්‍යානය සඳහා අධ්‍යානය සඳහා අධ්‍යානය සඳහා අධ්‍යානය ස ඉතින්, පැත්තෙන් නැති සම්බන්ධ සංවේදනය ගැන ප්‍රශ්නයක් ප්‍රශ්නයක් විශාල විශාල විශාල මේ පත්තරේ අපි දුර්වලින් බලන්න ප්‍රමාණයක් පෙන්වන්නේ ලෙක්සිකාලික ප්‍රමාණයක් පරීක්ෂණය කරන්න. සාමාන්‍ය විශ්වාසයෙන් පිළිගන්න පුළුවන් විශ්වාසයක් හොයාගන්න ප්‍රමාණය, අපි ප්‍රකාශ කරනවා අපේ විධානය ක්‍රිස්ත භූතික වැරැද්ධ කණ්ඩායමක් පරික්ෂා ක අපි පරීක්ෂණය කරනවා මොඩල් එකක් ප්‍රධානය කරලා තියෙන්නේ පුළුවන් ඇත්ත ලේබල් එකක් තියෙන්නේ මොඩල් එක්ක විශ්ලේෂණය හො</abstract_si>
      <abstract_so>Jardiinooyinka shabakada bulshada ee shabakadda ah waxey si badan ugu kalsoonaadaan iskuulka ka baaraandegista afka asalka ah (NLP) si ay u cadaadiyaan waxyaabaha isticmaalka. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially furthering disproportionate harms towards them.  Waxbarashada caynkaas ah ilaa waqti la joogo waxay ku kalsoonaadaan faasas kala duduwan iyo kooxo kala duduwan oo ay leeyihiin dhibaatooyin/leksis. Sababtaas darteed waxyaabaha la xiriira qoraalka aan galbeed-galbeed looga jeedo warqadda badan. Qoraalkan waxaynu ku soo bandhignaa qaab la ilaaliyo oo taag yar in la soo caddeeyo tababaro la xiriira dhaqanka. Tusaale baaritaanka baaritaanka dhimirka ee dadweynaha waxaan muujinnaa in qaababkayagu uu koox koox ka mid ah qaladyada iskujoofsan, waxaana soo socota ka muujinaynaa in kooxadanadu ay ka muuqato xukummada dadka oo ku qoran afka caasinimada ah oo aan waxqaban karin. Sidoo kale waxaynu sameynaa baaritaanka tusaale lagu tababaray taariikhda runta ah, si aan ugu fiican u garanayno tababaradan, waxaana soo wadanaa imtixaanka jidhka ee hore.</abstract_so>
      <abstract_ta>இணைய சமூக ஊடகம் தளங்கள் இயற்கையான மொழி செயல்பாடு (NLP) தொழில்நுட்பத்திற்கு நம்பிக்கை கொண்டிருக்கிறது பயன்படுத்துபவர்களுக்கு அதனால் காரணத்தை  ஆனால், இந்த தொழில்நுட்பம் பயிற்சி தரவில் இருக்கும் பல மாதிரி மற்றும் இணைப்பு பாவங்களிலிருந்தும் பாதிக்கப்படுகிறது, பெரும்பாலும் துணை குழுக்களுடன இந்த பொருட்களின் மீது ஆய்வுகள் மட்டுமே கவனம் செலுத்தி இருக்கின்றன எதிர்பார்ப்புகள் மற்றும் துணை குழுக்கள் கிடைக்கு அதனால், மேற்கு அல்லாத முறைகள் பற்றிய பிரச்சனைகள் மிக பெரும்பாலானது இக்காரணத்தில் தவிர்க்கப்படுகிறது. இந்த காகிதத்தில், நாம் ஒரு பலவீனமான கண்காணிக்கப்பட்ட முறையை அறிவிக்க முடியும். ஒரு பொதுவான புவியியல் கண்டுபிடிப்பு மாதிரியில் நாம் காண்பிக்கிறோம், எங்கள் முறைமையில் விற்பனை குழுக்களை குறிப்பிடும் பிழைகள் என்பதை குறிப்பிடுகிறது, பின்பற்றி இந் நாம் ஒரு தகவல் அமைப்பில் பயிற்சி ஒரு மாதிரியை செயல்படுத்துகிறோம் சிறந்த நிலத்தில் உண்மை சிட்டைகளை புரிந்து கொள்ள, முதல்</abstract_ta>
      <abstract_ur>اولاین سوسیل میڈیا پٹرومٹ اضافہ ہونے کے لئے طبیعی زبان پرینس (NLP) تکنیک پر اعتماد رکھتے ہیں کہ ان کے کارساز کے لئے اس نقصان کا ذلیل کرنے کے لئے اضافہ کریں۔ However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to marginalized groups, potentially adding disproportionate harms to them. یہاں تک تک اس طرح کی تحقیقات صرف ایک چند قسم کے مکڑوں اور زیربگروپ پر تمرکز کیا گیا ہے جن کے پاس نوٹیزوں/لکسیون موجود ہیں. لہٰذا غیر مغرب کی کنٹکسٹس کے معاملہ میں بہت زیادہ غفلت کی جاتی ہیں۔ ہم اس کاغذ میں ایک کمزور نظارت کی طریقہ پہنچاتے ہیں کہ زیادہ گھیری جئوثی-سنگتی کنٹکسٹکس میں لکسیکل کی بغیر تلاش کریں۔ ایک مطالعہ کے ذریعہ مطالعہ کے ذریعہ ایک ظاہری موجود کے موجود کے ذریعہ مطالعہ سے ہم نشان دیتے ہیں کہ ہماری طریقہ مختلف جغرافی خطاؤں کے سائل گروہوں کو پہچان دیتا ہے، اور ان گروہوں کو نشان دیتا ہے کہ یہ گروہوں نے ان جغرافی موضوع میں انسان کے مطالعہ اور غیراضافی زبان ہم نے بھی ایک موڈل کی تحلیل کرتی ہیں جو زمین حقیقت لابل کے ساتھ تعلیم کی جاتی ہے کہ ان کی بحثوں کو بہتر سمجھ سکیں اور پہلی دھوکے کی آزمائش پیش کریں۔</abstract_ur>
      <abstract_no>Internett sosiale mediaplattformar er større tilbakekalla på naturspråk-prosessering (NLP) teknikkar for å finna abusive innhald i skala for å redusera skadene som fører til brukarane sine. Desse teknikkene kjører imidlertid frå ulike forskjellige samlingar og assosiasjonsforstyringar som finst i opplæringsdata, som ofte resulterer i underpar utviklingar på innhaldet som er relevant til marginaliserte grupper, og potensielt forbetrar desse forskjellige skader mot dei. Studier om slike forskjellingar så langt har fokusert på berre ein hånd av aksar med ulike forskjellingar og undergrupper som har tilgjengelege notasjonar/leksikoner. Det er derfor forvirkningar om ikkje-Vest-kontekstar er stort ignorert i literaturen. I denne papiret introduserer vi ein viktig oversikt metode for å oppdaga leksiske forsikt i breire geokulturelle kontekstar. Gjennom ein tilfeldige studie om eit offentlig tilgjengeleg toksiktsmodell, viser vi at metoden vårt identifiserer salient grupper av krysgeografiske feil, og i eit oppfølgje viser at desse gruppene reflekserer menneske språk om offensiv og ikkje-effektiv språk i desse geografiske kontekstane. Vi gjer også analyse av eit modell trent på eit dataset med grunnleggjande sannhetsmerkelapp for å bedre forstå desse følgjande forstålingane, og gjer følgjande forståking eksperimenter.</abstract_no>
      <abstract_vi>Mạng truyền thông trên mạng ngày càng dựa vào kỹ thuật xử lý ngôn ngữ tự nhiên (chọc ngoáy ngôn ngữ) để phát hiện nội dung lạm dụng trên quy mô để giảm thiểu thiệt hại mà nó gây ra cho người dùng. Tuy nhiên, các kỹ thuật này bị thay đổi trong dữ liệu huấn luyện, phân biệt biệt biệt biệt biệt chủng tộc, và gây ra ảnh hưởng nội dung nhỏ đối với những nhóm bị cách ly, có khả năng gây tổn hại lớn cho họ. Những nghiên cứu về giả dạng này cho đến nay chỉ tập trung vào một số ít trục của sự khác biệt và phân loại có ghi chú/ngôn ngữ sẵn sàng. Do đó, giả thuyết liên quan đến các liên tiếp không Tây Âu bị bỏ qua hầu hết trong văn học. Trong tờ giấy này, chúng ta sẽ áp dụng một phương pháp được giám sát thiếu sót để phát hiện giả dạng trong các nền văn hóa rộng hơn. Bằng một nghiên cứu về mô hình phát hiện độc tính công khai, chúng tôi chứng minh rằng phương pháp của chúng tôi xác định được các nhóm nổi bật các lỗi địa lý khác nhau, và sau đó, cho thấy những nhóm này phản ánh những phán quyết con người về ngôn ngữ tấn công và vô hại trong các mặt địa lý đó. Chúng tôi cũng tiến hành phân tích một mô hình được đào tạo trên một bộ dữ liệu có nhãn mặt đất để hiểu rõ hơn các giả lập này, và đưa ra thí nghiệm sơ bộ giảm thiểu.</abstract_vi>
      <abstract_uz>Name Lekin, bu teknologiz taʼminlovchi ma'lumotlarda maʼlumot bajarayotgan muloqatlar va bog'liq taʼminotlardan ham qo'shiladi. Ko'p paytda qo'llaniladigan guruhlar bilan bog'liq mavzu tarkibini o'zgartiradi. Bu usullar ularga yetarli qo'llanilmaydi. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available.  Va shunday qilib, Gʻarbiy muammolari haqida o'xshash taʼminlovchilar o'zgarishga o'xshagan. Bu qogʻozda, biz juda ko'proq geo-cultural xizmatlarda o'zgarishni o'rganish uchun qo'llab-qo'llangan usulni o'rganamiz. Bu shaxsiy tizimni aniqlash modelidagi o'rganish orqali biz o'ylab ko'rsatumiz, bizning o'zgarish guruhlarimiz cross-geographik xatolarini aniqlaydi, va bir xizmatda, bu guruhlar bu geographik tartiblarida qo'shish va ishlab boʻlmaydigan tillarni ko'rsatadi. Biz bu tablarni yaxshi o'rganish uchun asboblar yordamida o'rganilgan maʼlumot yordamida o'rganish modelini bajaramiz va birinchi taʼminlovchi tizimni hozir qilamiz.</abstract_uz>
      <abstract_nl>Online social media platforms vertrouwen steeds meer op Natural Language Processing (NLP) technieken om misbruikende content op schaal te detecteren om de schade die het veroorzaakt voor hun gebruikers te beperken. Deze technieken hebben echter te maken met verschillende bemonsterings- en associatiefouten die aanwezig zijn in opleidingsgegevens, wat vaak resulteert in mindere prestaties op inhoud die relevant is voor gemarginaliseerde groepen, wat mogelijk onevenredige schade voor hen kan veroorzaken. Studies over dergelijke vooroordelen hebben zich tot nu toe gericht op slechts een handvol assen van dispariteiten en subgroepen die annotaties/lexicons beschikbaar hebben. Bijgevolg worden vooroordelen ten aanzien van niet-westerse contexten grotendeels genegeerd in de literatuur. In dit artikel introduceren we een zwak begeleide methode om lexicale vooroordelen robuust te detecteren in bredere geo-culturele contexten. Aan de hand van een casestudie naar een publiek beschikbaar toxiciteitsdetectiemodel tonen we aan dat onze methode opvallende groepen van cross-geografische fouten identificeert, en, in een vervolg, laten we zien dat deze groepen menselijke oordelen over beledigende en onschadelijke taal in die geografische contexten weerspiegelen. We voeren ook analyse uit van een model dat getraind is op een dataset met ground truth labels om deze vooroordelen beter te begrijpen en presenteren voorlopige mitigatie experimenten.</abstract_nl>
      <abstract_da>Online sociale medieplatforme er i stigende grad afhængige af Natural Language Processing (NLP) teknikker til at opdage misbrug af indhold i omfang for at mindske de skader, det forårsager for deres brugere. Disse teknikker lider imidlertid af forskellige prøveudtagnings- og associeringsforstyrrelser, der findes i træningsdata, hvilket ofte resulterer i subpar performance på indhold, der er relevant for marginaliserede grupper, og som potentielt kan fremme uforholdsmæssigt store skader over for dem. Undersøgelser af sådanne fordomme har indtil videre kun fokuseret på en håndfuld akser af uligheder og undergrupper, der har noteringer/leksikoner til rådighed. Derfor ignoreres fordomme vedrørende ikke-vestlige sammenhænge stort set i litteraturen. I denne artikel introducerer vi en svagt overvåget metode til robust opdagelse af leksikalske fordomme i bredere geo-kulturelle sammenhænge. Gennem et casestudie på en offentligt tilgængelig toksicitetsdetektionsmodel viser vi, at vores metode identificerer vigtige grupper af tværgeografiske fejl, og i en opfølgning viser vi, at disse grupperinger afspejler menneskelige vurderinger af stødende og uhensigtsmæssigt sprog i disse geografiske sammenhænge. Vi gennemfører også analyse af en model trænet på et datasæt med jordsandhedsmærker for bedre at forstå disse fordomme, og præsenterer foreløbige afbødningseksperimenter.</abstract_da>
      <abstract_hr>Online socijalne medijske platforme sve više oslanjaju se na tehnike proizvodnje prirodnog jezika (NLP) za otkrivanje nasilnog sadržaja u skali kako bi se smanjila šteta koje uzrokuje njihovim korisnicima. Međutim, te tehnike pate od različitih pristrasnosti uzoraka i udruženja prisutnih u podacima obuke, što često rezultira pod-par učinkovitosti sadržaja relevantnog marginaliziranim grupama, potencijalno unaprijeđujući neproporcione štete prema njima. Ispitivanja o takvim predrasudama do sada su usredotočena samo na gomilu sjekira različitih i podskupina koja imaju dostupne annotacije/leksije. Stoga, predrasude u vezi nezapadnih konteksta uglavnom se ignoriraju u književnosti. U ovom papiru predstavljamo slabu nadzornu metodu kako bi se opće otkrilo leksičke predrasude u širijim geokulturnim kontekstima. Kroz istraživanje slučajeva o javno dostupnom modelu otkrivanja toksičnosti, pokazujemo da naša metoda identificira salijante grupe cross-geografskih grešaka, i u praćenju pokazuju da te grupe odražavaju ljudske osude o uvredljivom i neprofešnom jeziku u tim geografskim kontekstima. Također provodimo analizu model a obučenog na kompletu podataka s oznakema istine kako bi bolje razumjeli te predrasude, i predstavljali preliminarni eksperiment za smanjenje.</abstract_hr>
      <abstract_de>Online-Social-Media-Plattformen setzen zunehmend auf Natural Language Processing (NLP)-Techniken, um missbräuchliche Inhalte in großem Umfang zu erkennen, um den Schaden, den sie für ihre Nutzer verursachen, zu mindern. Diese Techniken leiden jedoch unter verschiedenen Stichproben- und Assoziationsverzerrungen, die in den Trainingsdaten vorhanden sind, und führen oft zu einer minderwertigen Leistung bei Inhalten, die für marginalisierte Gruppen relevant sind, und möglicherweise zu unverhältnismäßigen Schäden für sie führen. Studien zu solchen Verzerrungen haben sich bisher nur auf eine Handvoll Achsen von Disparitäten und Untergruppen konzentriert, die über Annotationen/Lexikone verfügen. Folglich werden Vorurteile bezüglich nichtwestlicher Kontexte in der Literatur weitgehend ignoriert. In diesem Beitrag stellen wir eine schwach überwachte Methode vor, um lexikalische Verzerrungen in breiteren geokulturellen Kontexten robust zu erkennen. Anhand einer Fallstudie über ein öffentlich zugängliches Toxizitätsnachweismodell zeigen wir, dass unsere Methode signifikante Gruppen von geographischen Fehlern identifiziert und in einer Folgemaßnahme zeigen wir, dass diese Gruppen menschliche Urteile über beleidigende und harmlose Sprache in diesen geografischen Kontexten widerspiegeln. Wir führen auch Analysen eines Modells durch, das auf einem Datensatz mit Ground Truth Labels trainiert wurde, um diese Verzerrungen besser zu verstehen, und stellen vorläufige Minderungsexperimente vor.</abstract_de>
      <abstract_fa>Plataforma‌های رسانه‌های اجتماعی در آنلاین بیشتر بر تکنیک‌های پردازش زبان طبیعی (NLP) وابسته می‌شود تا محتوای زبان‌آزار را در مقیاس شناسایی کند تا آسیب‌هایی که باعث می‌شود برای کاربران‌شان کم با این حال، این تکنیک‌ها از طریق نمونه‌های مختلف و همکاری که در داده‌های آموزش وجود دارند رنج می‌برند، اغلب به نتیجه عملکرد زیر پاره‌ای بر محتویات مربوط به گروه‌های متحد شده، که احتمالاً به زیان آسیب‌های مختلف بر آنها می‌رسد. مطالعه‌ها در مورد چنین پیش‌بینی‌ها فقط روی چند دسته‌ای از متفاوت‌ها و زیر گروه‌ها تمرکز شده‌اند که توضیح‌ها/زبان‌ها در دسترس دارند. به همین دلیل، توجه‌های غیر غیر غربی در ادبیات بیشتر نادیده می‌شوند. در این کاغذ، ما یک روش ضعیف تحت نظر قرار می دهیم تا به شدت توضیح الکتریکی را در محیط جغرافی و فرهنگی گسترده تر شناسایی کنیم. از طریق یک مطالعه پرونده در مورد یک مدل شناسایی سمی که در دسترس عمومی موجود است، نشان می دهیم که روش ما گروه‌هایی از اشتباه‌های مختلف جغرافی را شناسایی می‌کند، و در یک پیروی، نشان می‌دهد که این گروه‌ها تصمیم‌گیری‌های انسان را از زبان‌های تجاوز و بی‌اثر در این موضوع ج ما همچنین تحلیل یک مدل که روی یک مجموعه داده آموزش یافته شده با نقاشی حقیقت زمینی انجام می دهیم تا بهتر این پیشرفتها را درک کنیم، و آزمایش های پیشینیان کم کردن را پیش می دهیم.</abstract_fa>
      <abstract_ko>온라인 소셜미디어 플랫폼은 점점 더 자연언어처리(NLP) 기술에 의존해 남용 콘텐츠를 대규모로 검출해 사용자에게 주는 피해를 줄이고 있다.그러나 이런 기술은 교육 데이터에 존재하는 각종 표본 추출과 관련 편차의 영향을 받아 변두리화 단체와 관련된 내용에 좋지 않은 모습을 보이고 그들에게 어울리지 않는 상처를 줄 수 있다.지금까지 이런 편견에 대한 연구는 주석/어휘가 있는 소수의 차이축과 아조에만 집중되었다.따라서 비서양적 언어 환경에 대한 편견은 문헌에서 기본적으로 소홀히 여겨졌다.본고에서 우리는 약한 감독 방법을 도입하여 더욱 광범위한 지리 문화 배경에서 어휘 편견을 노봉적으로 검출했다.공개된 독성 검출 모델에 대한 사례 연구를 통해 우리는 우리의 방법이 지리적 오류를 식별하는 현저한 그룹을 증명했고 후속 연구에서 이러한 그룹은 인류가 이런 지리 환경에서 공격성과 비공격적인 언어에 대한 판단을 반영했다는 것을 증명했다.이러한 편차를 더욱 잘 이해하기 위해 우리는 지면 진상 라벨이 달린 데이터 집합에서 훈련하는 모델을 분석하고 초보적인 완화 실험을 제시했다.</abstract_ko>
      <abstract_bg>Онлайн социалните медии все повече разчитат на техники за обработка на естествения език (НЛП), за да откриват злоупотреба със съдържание в мащаб, за да смекчат вредите, които причинява на потребителите им. Тези техники обаче страдат от различни отклонения при вземане на проби и асоциации, присъстващи в данните за обучение, които често водят до непропорционални резултати по отношение на съдържанието, свързано с маргинализираните групи, което потенциално увеличава непропорционалната вреда за тях. Проучванията на подобни пристрастия досега са се фокусирали върху само шепа оси на различията и подгрупи, които имат налични анотации/лексикони. Следователно предразсъдъците, отнасящи се до незападния контекст, до голяма степен се пренебрегват в литературата. В тази статия въвеждаме слабо контролиран метод за надеждно откриване на лексикални пристрастия в по-широки геокултурни контексти. Чрез проучване на случай на публично достъпен модел за откриване на токсичност ние демонстрираме, че нашият метод идентифицира значими групи от кръстосани географски грешки и в последващи действия демонстрираме, че тези групировки отразяват човешките преценки за обиден и невреден език в тези географски контексти. Също така провеждаме анализ на модел, обучен върху набор от данни с етикети на истината, за да разберем по-добре тези пристрастия, и представяме предварителни експерименти за смекчаване на последиците.</abstract_bg>
      <abstract_tr>Çaltylyk sosyal medýdançalar platformlary Natural Language Processing (NLP) tehnikalaryna ýetişdirmek üçin bu nusgalary azaltmak üçin janlaşdyrmak üçin janlaşdyrylyp bilýärler. Ýöne bu tekniklerde okuwçy maglumatlarda bolan näçe örän nusgalar we birleşmeler kynçylyklaryndan çykyp barýarlar. Köplenç bu tekniklerde daşary taýýarlanan toparlara baglanýan maksadyň üstünde sub-par netijesi bolar, olaryň üstüne ýüregisiz bir zararlar Bu häzirki öňüne meýilleşdirýän işlemler diňe birnäçe a ýratyşlyklar we ilat gruplary üçin üns berildi. Şol sebäpli, Günbatar-günbatar däplikleri barada pikirler edebiýatda köp bölegi görmeýär. Bu kagyzda, güýçli gözetleýän bir yöntemi geýo-kültürel tesislerinde gaty bir hereket edip otyrýarys. Birnäçe mejbur toksiýet deteksiýasynyň nusgasyna görä, biz öz yönümimiziň gaty-geografik ýalňyşlyklaryň tusgasyny tanyýandygyny görkezýäris we bu toparlaryň bu geografik ýagdaýda adamlaryň judgamalaryny görkezýäris. Biz hem şu bialary gowy düşünmek üçin daýlyk setirinde bilinmeli bir nusga analyzasyny çykarýarys, we öňki azaltmak deneylerini çykarýarys.</abstract_tr>
      <abstract_id>Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users.  Namun, teknik-teknik ini menderita dari berbagai bias sampel dan asosiasi yang ada dalam data latihan, sering mengakibatkan prestasi sub-par pada isi yang relevan untuk kelompok marginalisasi, potensi melanjutkan kerusakan yang tidak proporsional terhadap mereka. Studi tentang biases tersebut sejauh ini telah fokus pada hanya sekelompok paksi ketidakpersamaan dan subkelompok yang memiliki anotasi/leksikon tersedia. Oleh karena itu, biases mengenai konteks bukan Barat kebanyakan diabaikan dalam literatur. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts.  Melalui sebuah studi kasus tentang model deteksi toksicitas yang tersedia publik, kami menunjukkan bahwa metode kami mengidentifikasi kelompok yang saling dari kesalahan trans-geografik, dan, dalam tindakan berikutnya, menunjukkan bahwa kelompok-kelompok ini mencerminkan penilaian manusia bahasa yang menyerang dan tidak menyerang dalam konteks geografik tersebut. Kami juga melakukan analisis model yang dilatih di dataset dengan label kebenaran tanah untuk memahami lebih baik biases ini, dan mempersembahkan percobaan pemalu awal.</abstract_id>
      <abstract_sq>Platformet e medias sociale online mbështeten gjithnjë e më shumë në teknikat e Procesimit të Gjuhave Natyrore (NLP) për të zbuluar përmbajtjen abuzive në shkallë me qëllim që të lehtësohen dëmet që shkakton për përdoruesit e tyre. Megjithatë, këto teknika vuajnë nga paragjykime të ndryshme mosmarrëveshjeje dhe shoqërimi të pranishme në të dhënat e trainimit, që shpesh rezultojnë në performancë nënparitare mbi përmbajtjen e rëndësishme për grupet e marginalizuara, duke nxitur potencialisht dëme të papërcaktuara ndaj tyre. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations/lexicons available.  Në pasojë të kësaj, paragjykimet lidhur me kontekstet jo-perëndimore janë kryesisht injoruar në letërsi. Në këtë letër, ne futim një metodë të mbikqyrur dobësisht për të zbuluar me forcë paragjykimet lexike në kontekste gjeo-kulturore më të gjera. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts.  Ne kryejmë gjithashtu analizën e një modeli të stërvitur në një grup të dhënash me etiketa tokësore të të vërtetës për të kuptuar më mirë këto paragjykime dhe për të paraqitur eksperimente paragjyqësore për lehtësimin.</abstract_sq>
      <abstract_sw>Jukwaa la mitandao ya kijamii linategemea mbinu za mchakato wa lugha za asili (NLP) ili kutambua maudhui yanayodhalilisha kwa kiasi kikubwa ili kupunguza madhara yanayosababisha watumiaji wao. Hata hivyo, mbinu hizi zinakabiliwa na upendeleo mbalimbali wa sampuli na ushirikiano unaoendelea katika taarifa za mafunzo, mara nyingi zinasababisha utendaji wa vifaa vikuu vinavyohusiana na makundi yanayohusiana na makundi ya vijijini, pengine kuwasaidia madhara yasiyo ya kibaguzi dhidi yao. Utafiti wa upendeleo huu mpaka sasa umejikita tu kwenye maeneo mengi ya tofauti na makundi ya chini yanayopatikana na matatizo/lexico. Kwa hiyo, upendeleo kuhusu mikutano yasiyo ya Magharibi unapuuzwa sana katika fasihi. Katika gazeti hili, tunaonyesha njia inayofuatiliwa kwa udhaifu wa kutambua upendeleo wa kijinsia katika matatizo mengi ya kitamaduni. Kupitia utafiti wa kesi juu ya muundo wa kutambua ukosefu wa kisaikolojia unaopatikana hadharani, tunaonyesha kuwa mbinu yetu inaonyesha makundi madogo ya makosa ya kijiografia, na, kwa ufuatiliaji huo, inaonyesha kwamba makundi haya yanaonyesha hukumu za binadamu za lugha ya uchochezi na isiyo na ufanisi katika matatizo hayo ya kijiografia. Pia tunafanya uchambuzi wa mifano inayofundishwa kwenye seti ya taarifa yenye alama za kweli za ardhi ili kuelewa vizuri hivi upendeleo, na kwa sasa tunafanya majaribio ya mitandao ya awali.</abstract_sw>
      <abstract_af>Online ële sosiale media platforme wat verminder vertrou word op Natuurlike Taal Prosessering (NLP) teknike om onheilige inhoud op skaal te ontdek om die skade wat dit veroorsaak het aan hul gebruikers te verminder. Hierdie teknike lyk tog van verskillende versameling en assosiasie voorskyning wat in onderwerp data is, wat dikwels resulteer in sub-par prestasie op inhoud wat relevant aan marginaliseerde groepe is, potensieal verder onversameling skade teenoor hulle. Studie op sodanige voorskrifte tot so toe het op slegs 'n halwe asse van verskillende en subgroepe gefokus wat notasies/leksies beskikbaar het. Daarom word voorspoedies aangaande nie-Westelike kontekste groot in die literateit geïgnoreer. In hierdie papier, introduseer ons 'n swak ondersoekte metode om meksikaal voorspoedings in die breede geokulturele kontekste te ontdek. Deur 'n geval studie oor 'n publiek beskikbaar toksikiteit-opdekking model, wys ons dat ons metode salient groepe van kruisgeografiese foute identifiseer, en in 'n volgende opdrag, wys dat hierdie groepe menslike oordelinge van offensiv en oneffektief taal in dié geografiese kontekste reflekteer. Ons doen ook analiseer van 'n model wat op 'n datastel opgelei is met grond waarheid etikette om hierdie voorspoedige te beter te verstaan en voorstel voorspoediging eksperimente te verminder.</abstract_af>
      <abstract_az>İnternettə sosyal media platformları təbiətli dil işləməsi (NLP) tehniklərinə təvəkkül edirlər ki, istifadəçilərinə zərər vurmaq üçün istifadəçilərinə zərər verər. Ancaq bu tehniklər təhsil məlumatlarında olan müxtəlif nümunələr və birlikləri təhsil məlumatlarından çəkilir, çox çox dəyişiklik dəyişiklik dəyişiklik dəyişiklik məlumatlarına bənzəyir, mümkün olaraq onlara münasibətli zərər artırar. Şimdiye qədər böyük tədbirlər barəsində təhsil edirlər, yalnız bir neçə dəyişiklik və ilahi qrupların istifadə edilməsi və məlumatların faydalanması barəsində odaqlanırlar. Bəlkə, qərbi olmayan məsələlər barəsindəki təsirlər məsələdə çox məsələn məsələdə məhv edilir. Bu kağızda çox geniş geo-kültürlü müxtəliflərdə leksik tərzlərini çox təşkil etmək üçün zəif gözləyirik. Yaxşı olaraq faydalanır zehirli tanıtma modeli barəsində, metodumuzun çox çətinlikli xətaların qruplarını tanıdığını göstərdik və bu dəstələrin bu ģeogrāfiski müxtəliflərdə insan hökmünü göstərdik. Biz həmçinin həqiqət etiketləri ilə təhsil edilmiş bir modelin analizisini daha yaxşı anlamaq üçün və əvvəlki küçük eksperimentləri təhsil edirik.</abstract_az>
      <abstract_hy>Օնլայն սոցիալական լրատվամիջոցների պլատֆորմները ավելի ու ավելի հիմնված են բնական լեզվի մշակույթի (ՆԼՊ) տեխնոլոգիաների վրա, որոնք օգտագործում են չարաշահույթ պարունակություն գտնելու համար, որպեսզի նվազեցնեն այն Այնուամենայնիվ, այս տեխնոլոգիաները տառապում են տարբեր նմուշներ վերցնելու և ասոցացիայի կողմնակալություններից, որոնք գոյություն ունեն ուսումնասիրության տվյալների մեջ, և որոնք հաճախ հանգեցնում են մագնիսացված խմբերի հետ կապված պարունակության ենթազուգավոր արդ Այսպիսի կողմնականությունների ուսումնասիրությունները մինչ այժմ կենտրոնացել են միայն մի քանի առանձնահատուկ առանցքների և ենթախմբերի վրա, որոնք հասանելի են նոտացիաներ և լեքսիկոններ: Հետևաբար, ոչ-արևմտյան կոնտեքստների կողմնականությունները գրականության մեջ հիմնականում անտեսվում են: Այս թղթի մեջ մենք ներկայացնում ենք թույլ վերահսկված մեթոդ, որպեսզի ուժեղ հայտնաբերենք լեքսիկական կոնտեքստները ավելի լայն երկրամշակութային կոնտեքստներում: Առաջապես հասանելի թունավորության հայտնաբերման մոդելի միջոցով մենք ցույց ենք տալիս, որ մեր մեթոդը բացահայտում է միջերկրային սխալների հիմնական խմբերը և հետևում ցույց է տալիս, որ այս խմբավորումները արտացոլում են մարդկային դատողությունները, որոնք վերաբերում են գրավիչ և անվտանգավոր լեզուներին այդ երկրային կոնտեքստ We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</abstract_hy>
      <abstract_am>የመስመር ማኅበራዊ አውታር ሚዲያዎች ፕሮግራሞች በዘላለም የሚታመሙ የዘርብ ቋንቋ ክፍተት (NLP) ስልጣናዎችን በመጠቀም ላይ የሚያስጨንቁትን ጉዳት ለመጠቀም በተጠቃሚዎቹ ላይ እንዲያቆሙ ነው፡፡ ምንም እንኳን፣ እነዚህ ጥያቄዎች ከዓይነቱ ምሳሌ እና ማኅበረሰብ ጥያቄዎች በመጠቀም ዳራዎችን በመቀበል የሚደርሱ ናቸው፡፡ እስከ ዛሬ ድረስ እንደነዚህ ባለ ጥያቄዎች ላይ ተማርተዋል፣ በተቃውሞው እና የደብዳቤ ክፍሎች ላይ የሚቆጠሩ ጥያቄዎች ብቻ ነው፡፡ ስለዚህም ምዕራባዊ ግንኙነት ሳይሆን የውይይት ግንኙነት በጽሕፈት ብዛት ተሳሳትተዋል፡፡ In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts.  በጉዳዩ ግልፅ በተገኘው የtokስክሲ አካባቢ ምሳሌ ላይ በተመሳሳይ ማሳየት፣ ማወቃችን የግንኙነት ክፍተቶችን የሚያሳውቃለን፡፡ እና የመሬት እውነተኛ ምልክቶችን ለማስተዋል የመሬት ምልክቶች ላይ የተማረከውን ምሳሌ እናደርጋለን፡፡</abstract_am>
      <abstract_bs>Online socijalne medijske platforme sve više oslanjaju se na tehnike procesiranja prirodnog jezika (NLP) za otkrivanje nasilnog sadržaja u skali kako bi se smanjila šteta koje uzrokuje njihovim korisnicima. Međutim, ove tehnike pate od različitih predrasuda uzoraka i udruženja koje su prisutne podacima o obuci, često rezultirajući pod-par učinkovitosti sadržaja relevantnog marginaliziranim grupama, potencijalno unaprijeđujući neproporcione štete prema njima. Istraživanja o takvim predrasudama do sada su usredotočene samo na gomilu sjekira različitih i podskupina koja imaju dostupne annotacije/leksione. Stoga predrasude u vezi nezapadnih konteksta uglavnom se ignoriraju u literaturi. U ovom papiru predstavljamo slabu nadzornu metodu da bi opljačkano otkrili leksičke predrasude u širijim geokulturnim kontekstima. Kroz istraživanje slučajeva o javno dostupnom modelu otkrivanja toksičnosti, pokazujemo da naša metoda identificira salijante grupe cross-geografskih grešaka, i u praćenju pokazuje da te grupe odražavaju ljudske osude na ofanzivne i neprofesivne jezike u tim geografskim kontekstima. Također provodimo analizu model a obučenog na kompletu podataka s oznakema istine kako bi bolje razumijeli te predrasude, i predstavili preliminarni eksperiment za smanjenje.</abstract_bs>
      <abstract_bn>অনলাইন সামাজিক প্রচার মাধ্যমের প্লাটফর্ম বাড়তে থাকে প্রাকৃতিক ভাষা প্রক্রিয়া (এনএলপি) প্রযুক্তির উপর নির্ভর করে যাতে তারা ব্যবহারকারীদ তবে প্রশিক্ষণের তথ্যে উপস্থিত এই প্রযুক্তি বিভিন্ন ধরনের উদাহরণ এবং সংস্থার বিভিন্ন প্রযুক্তি থেকে কষ্ট পেয়েছে, যার ফলে প্রায়শই সাব-পারের প্রদর্শনে এতদিন পর্যন্ত এই ধরনের বৈষম্যের উপর গবেষণা শুধুমাত্র কয়েকটি বৈচিত্র্য এবং সাবগ্রুপের উপর মনোযোগ প্রদান করেছে যাদের বিরুদ্ধ এর ফলে পশ্চিমা প্রতিযোগিতার বিরুদ্ধে বিদ্বেষতা বেশীরভাগ সাহিত্যে উপেক্ষা করা হয়। এই কাগজটিতে আমরা দুর্বল পর্যবেক্ষনের একটি পদ্ধতি পরিচয় করিয়ে দিচ্ছি যাতে লেক্সিক্যাল বিদ্রোহ সনাক্ত করতে পারি ব্যাপক ভো-সংস্কৃ একটি প্রকাশ্য ব্যাক্তিগত গবেষণার মাধ্যমে আমরা দেখাচ্ছি যে আমাদের পদ্ধতি ক্রিস্ট্রোগ্রাফিক গ্রুপের ক্ষেত্রে ব্যবস্থা চিহ্নিত করা হয়েছে, আর অনুসরণ করে দেখাচ্ছে যে এই গ্রুপগুলো  আমরা একটি ডেটাসেটে প্রশিক্ষিত মডেলের বিশ্লেষণ করি যেটা ভূমিতে সত্যি লেবেলের সাথে ভালোভাবে বুঝতে পারি, আর প্রাথমিক মিশিশন পর</abstract_bn>
      <abstract_ca>Les plataformes de mitjans socials en línia confien cada vegada més en tècniques de processament de llenguatges naturals (NLP) per detectar continguts abusius a escala per mitigar els danys que provoca als seus usuaris. No obstant això, aquestes tècniques pateixen de diversos prejudicis de recolliment de mostres i associació presents en les dades d'entrenament, que sovint resulten en un desempeny sub-par àgic en contingut rellevant als grups marginats, potencialment promovint danys desproporcionats cap a ells. Els estudis sobre aquestes tendències fins ara s'han centrat en només una munta d'eixes de disparitats i subgrups que tenen anotacions/lexicons disponibles. En conseqüència, les tendències relacionades amb contextos no occidentals es ignoren en gran part en la literatura. En aquest paper, introduïm un mètode debilment supervisat per detectar de manera robusta biases lècsiques en contextes geoculturals més amplis. A través d'un estudi de cas sobre un model de detecció de toxicitat públicament disponible, demostram que el nostre mètode identifica grups salients d'errors transgeogràfics i, en un seguiment, demostra que aquests grups reflecteixen els judicis humans de llenguatge ofensiu i inofensiv en aquests contextos geogràfics. També fem anàlisi d'un model entrenat en un conjunt de dades amb etiquetes de veritat fonamental per a entendre millor aquests prejudicis i presentar experiments preliminars de mitigació.</abstract_ca>
      <abstract_fi>Sosiaalisen median verkkoalustat luottavat yhä enemmän luonnollisen kielen käsittelytekniikoihin (NLP) väärinkäyttävän sisällön havaitsemiseksi mittakaavassa vähentääkseen sen käyttäjille aiheuttamia haittoja. Nämä tekniikat kärsivät kuitenkin erilaisista koulutustiedoissa esiintyvistä otanta- ja assosiaatiovääristymistä, jotka usein johtavat syrjäytyneille ryhmille merkitykselliseen sisältöön, mikä saattaa aiheuttaa niille kohtuuttomia haittoja. Tällaisia ennakkoluuloja koskevat tutkimukset ovat toistaiseksi keskittyneet vain kouralliseen erojen akseliin ja alaryhmiin, joissa on saatavilla huomautuksia/sanastoja. Tämän vuoksi ei-länsimaisia konteksteja koskevat ennakkoluulot jätetään kirjallisuudessa suurelta osin huomiotta. Tässä työssä esittelemme heikosti valvotun menetelmän, jolla voidaan havaita vankasti lexikaalisia vääristymiä laajemmissa geokulttuurisissa yhteyksissä. Julkisesti saatavilla olevaa myrkyllisyyden havaitsemismallia koskevan tapaustutkimuksen avulla osoitamme, että menetelmämme tunnistaa merkittäviä maantieteellisten virheiden ryhmiä, ja osoitamme, että nämä ryhmittymät heijastavat ihmisten arvioita loukkaavasta ja loukkaavasta kielestä näissä maantieteellisissä yhteyksissä. Analysoimme myös mallin, joka on koulutettu pohjatotuusmerkillä varustetun aineiston pohjalta ymmärtääksemme paremmin näitä harhaluuloja, ja esitämme alustavat lieventämiskokeet.</abstract_fi>
      <abstract_cs>Online platformy sociálních médií se stále více spoléhají na techniky zpracování přirozeného jazyka (NLP), aby odhalily zneužívající obsah v rozsahu s cílem zmírnit škody, které způsobuje jejich uživatelům. Tyto techniky však trpí různými vzorkovými a asociačními předsudky přítomnými v údajích o výcviku, což často vede k nepřiměřenému výkonu obsahu relevantního pro marginalizované skupiny, což potenciálně k nepřiměřené újmě vůči nim. Studie těchto předsudků se zatím zaměřují pouze na hrstku os disparit a podskupin, které mají k dispozici anotace/lexikony. V důsledku toho jsou v literatuře do značné míry ignorovány předsudky týkající se nezápadních kontextů. V tomto článku představujeme slabě dohlíženou metodu robustního detekce lexikálních předsudků v širších geokulturních kontextech. Prostřednictvím případové studie veřejně dostupného modelu detekce toxicity ukazujeme, že naše metoda identifikuje významné skupiny mezi geografickými chybami a v následném sledování prokáže, že tyto skupiny odrážejí lidské úsudky urážlivého a neškodného jazyka v těchto geografických kontextech. Dále provádíme analýzu modelu trénovaného na datové sadě se základními značkami pravdy, abychom lépe porozuměli těmto předsudkům, a prezentujeme předběžné zmírňovací experimenty.</abstract_cs>
      <abstract_et>Interneti sotsiaalmeedia platvormid toetuvad üha enam loodusliku keele töötlemise (NLP) tehnikatele, et avastada kuritarvitavat sisu ulatuslikult, et leevendada kahju, mida see oma kasutajatele põhjustab. Kõnealused meetodid kannatavad siiski koolitusandmetes esinevate erinevate valimi- ja assotsiatsioonipärasuste tõttu, mille tulemuseks on sageli marginaliseeritud rühmade jaoks oluline sisu, mis võib suurendada ebaproportsionaalset kahju neile. Seni on selliseid kallakusi käsitlevad uuringud keskendunud vaid käputäisele erinevuste telgedele ja alarühmadele, millel on olemas annotatsioonid/leksikonid. Sellest tulenevalt ignoreeritakse kirjanduses suuresti eelarvamusi mitte-lääne kontekstis. Käesolevas töös tutvustame nõrgalt kontrollitud meetodit leksikaalsete kallakute kindlakstegemiseks laiemates geokultuurilistes kontekstides. Avalikult kättesaadava toksilisuse tuvastamise mudeli juhtumiuuringu kaudu näitame, et meie meetod tuvastab geograafiliste vigade olulised rühmad, ning järelmeetmete käigus näitame, et need rühmitused peegeldavad inimeste otsuseid solvava ja ebasobiva keele kohta nendes geograafilistes kontekstides. Samuti analüüsime mudelit, mis on koolitatud andmekogumi põhjal, millel on aluseks tõemärgid, et paremini mõista neid kallakuid, ning esitame esialgseid leevenduskatseid.</abstract_et>
      <abstract_jv>Awakdhéwé éntuk sistem tambah-sistem komunitas sing luwih nggawe nguasai tentang ing Language Progressing (NLP) nggawe aturan ingkang alih pengguna-pengguna kuwi nggawe nguasai perusahaan sing bakal nggawe nguasai nggawe nguasai perusahaan. politenessoffpolite, politenessoffpolite"), and when there is a change ("assertivepoliteness Workspace %1 Awak dhéwé, biasane kuwi kontèkter Gak-Pasent sing isih luwih iso ngulinakake batar Dino pehar iki, kita mulasah akeh yŏnŏ pukan luhur nggawe nguasah basa luhur Ato bener gadhakan langkung itêmên kuwi model ngêwongké kesempatan éné, kéné bisalahan ngêmên ngerasakno karo hal-jeografèké kesempatan kanggo ngerasakno iki, lan nganggep ngêmên, résumé iki ngono ngêmên ngerasakno uwong. Awak dhéwé éntuk beraksi perusahaan model sing tukang mrambat kanggo nganggo perusahaan sing katêpakan karo hal-hal sing luwih apik dhéwé, lan nganggo perusahaan mulai kuwi tindakan.</abstract_jv>
      <abstract_sk>Spletne platforme družbenih omrežij se vedno bolj zanašajo na tehnike obdelave naravnega jezika (NLP) za odkrivanje zlorabe vsebine v obsegu, da bi ublažile škodo, ki jo povzroča njihovim uporabnikom. Vendar pa te tehnike trpijo zaradi različnih pristranskosti vzorčenja in povezovanja, prisotnih v podatkih o usposabljanju, kar pogosto povzroči podvrednost učinkovitosti glede vsebine, pomembne za marginalizirane skupine, kar bi lahko povzročilo nesorazmerno škodo zanje. Študije o takih pristranskostih so se doslej osredotočile na le peščico osi razlik in podskupin, ki imajo na voljo opombe/leksikone. Posledično se pristranskosti v zvezi z nezahodnimi konteksti v literaturi v veliki meri ignorirajo. V prispevku predstavljamo šibko nadzorovano metodo za robustno odkrivanje leksikalnih pristranskosti v širših geokulturnih kontekstih. S študijo primera javno dostopnega modela za odkrivanje toksičnosti dokazujemo, da naša metoda identificira pomembne skupine medgeografskih napak, in v nadaljnjem ukrepanju dokazujemo, da te skupine odražajo človeške presoje o žaljivem in neškodljivem jeziku v teh geografskih kontekstih. Izvedli smo tudi analizo modela, usposobljenega na podatkovnem naboru z oznakami resnice, da bi bolje razumeli te pristranskosti in predstavili predhodne poskuse ublažitve.</abstract_sk>
      <abstract_he>פלטפורמות התקשורת החברתית באינטרנט סומכות יותר ויותר על טכניקות תהליך שפת טבעית (NLP) כדי לזהות תוכן מתעלל בקנה מידה כדי להקל את הפגיעות שהוא גורם למשתמשים שלהם. בכל אופן, הטכניקות האלה סובלות מכוונות דגימות ואיגוד שונים הנוכחים בנתונים האימונים, לעתים קרובות יוצרים ביצועים מתחת לפאר על תוכן רלוונטי לקבוצות מוגבלות, פוטנציאלית להמשיך פגיעות לא פרופורציונות כלפיהם. מחקרים על חיווקים כאלה עד כה התמקדו רק בכמה גזעים של שווים ולקבוצות תת שיש להם ציונים/לקסיקונים זמינים. כתוצאה מכך, ההתמחות בנוגע לקשר לא מערבי מתעלמות בעיקר בספרות. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts.  באמצעות מחקר מקרים על דוגמנית גילוי רעילות זמינה לציבור, אנו מראים שהשיטה שלנו מזהה קבוצות מפורסמות של טעויות גאוגרפיות צלולות, ובמעקב, מראים שהקבוצות האלה משקפים את השיפוטים האנושיים של שפה פגיעה ולא פגיעה בתוך הקשר הגאוגרפי הללו. אנחנו גם מבצעים ניתוח של דוגמנית מאומנת על קבוצת נתונים עם תוויות אמת קרקעית כדי להבין טוב יותר את ההתמחות האלה, ולהציג ניסויים מקדימים למקלה.</abstract_he>
      <abstract_ha>Ana ƙayyade zangaren mutane na mitandai masu jamii a mitandaki na ƙara yana dõgara a kan aikin da Lugha na Natural (NLP) technical dõmin su gane maɓallin abuse a tsakanin, dõmin ya sauƙaƙara zarar da ke saba da amfani da su. Kayya, ko da yaushe, waɗannan technyoyi sunã cũtar wa misãlai da association da ke halatta cikin data, ko da yawa sunã ƙara fassarar-par a kan ƙananan-par masu hushi da jama'a masu marginalized, mai yiwuwa yana ƙara wata hasãra a kansu. Kayan karatun kan wannan taɓallu har zuwa yanzu, sun zura maki kawai da kalma guda na rabo da jama'a waɗanda ke da matalauta/leksisi. Saboda haka, misãlai masu husũma masu cikin muhimmada na-gabas ba za'a ƙyale mafi yawa a littafin. Ga wannan karatun, za mu introduce wata hanyoyi mai rauni da za'a yi sauri ga kugunta karkacin littafa a cikin muhimmada zafi na geo-kultur. Ga bayan wani jarraba a kan misalin misalin gizariya da ake iya nuna, tuna nuna cewa metoden mu na gane jama'a-jama'a na kore-geographic, kuma, cikin wani ƙari, sai ka nuna cewa, waɗannan ƙungiyõyi suna yin takardar mutane da mistakanci na zartar da kuma bã ya da amfani a cikin wurãren sigogi. Kayya, Munã yi anayya da misali wanda aka sanar da shi a kan data set da alama masu gaskiya dõmin su fahimta kanzu, kuma a yanzu jarrabar mitihani da ta farko.</abstract_ha>
      <abstract_bo>དྲ་ཐོག་ཏུ་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གླིང་གི་ཆ་རྐྱེན་སྒྲིག་འགོད་ཀྱི་ཐབས་ལམ་ལ་རྒྱ་ཆེ་ཤོས་ཏེ། ཡིན་ནའང་། ཐབས་ལམ་འདི་དག་གཟུགས་འབྲི་བ་དང་། སྤྱི་ཚོགས་ཀྱི་ཆ་འཕྲིན་ཡིག་ཆ་ནང་དུ་བཏུབ་པའི་རྒྱུ་རྐྱེན་ལས། འདི་ལྟ་བུའི་བཟོ་བཅོས་དང་། ད་ལྟ་བུའི་ནང་གི་མིང་རྣམས་ལས་ཕན་འབྲས་མེད་པའི་ལྟ་བུ་ཚོའི་ནང་དུ་དམིགས་བསལ་བྱས་ཡོད། དེར་བརྟེན། ནུབ་ཕྱོགས་མེད་པའི་གནས་སྟངས་ལ་བཀའ་དྲིས་ཡིག་ཆ་ནང་གི་སྣང་མེད་སྣང་བྱེད་ཡོད། In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. དཔེར་ན་འཕགས་རིས་ལྟ་བུ་ཞིག་གིས་ཕན་ཚུན་འབྲེལ་བའི་གནད་དོན་རྙེད་ཐུབ་པའི་མ་དཔེ་གཞི་ཐོག་ལས། ང་ཚོའི་ལམ་ལུགས་འདིས་མཐུན་སྟངས་འཛིན་བྱེད་པའི་ཚོ་ཁག་ལས་འཕགས་རིས་འཁྲུལ་བ་ད We also conduct analysis of a model trained on a dataset with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</abstract_bo>
      </paper>
    <paper id="36">
      <title>Detection of Puffery on the <a href="https://en.wikipedia.org/wiki/English_Wikipedia">English Wikipedia</a><fixed-case>E</fixed-case>nglish <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Amanda</first><last>Bertsch</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>329–333</pages>
      <abstract>On <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, an online crowdsourced encyclopedia, volunteers enforce the encyclopedia’s editorial policies. Wikipedia’s policy on maintaining a neutral point of view has inspired recent research on bias detection, including <a href="https://en.wikipedia.org/wiki/Weasel_word">weasel words</a> and <a href="https://en.wikipedia.org/wiki/Hedge_(finance)">hedges</a>. Yet to date, little work has been done on identifying <a href="https://en.wikipedia.org/wiki/Puffery">puffery</a>, phrases that are overly positive without a verifiable source. We demonstrate that collecting training data for this task requires some care, and construct a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> by combining <a href="https://en.wikipedia.org/wiki/Wikipedia_community">Wikipedia editorial annotations</a> and <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval techniques</a>. We compare several approaches to predicting puffery, and achieve 0.963 <a href="https://en.wikipedia.org/wiki/F-number">f1 score</a> by incorporating <a href="https://en.wikipedia.org/wiki/Citation">citation features</a> into a RoBERTa model. Finally, we demonstrate how to integrate our model with Wikipedia’s public infrastructure to give back to the Wikipedia editor community.</abstract>
      <url hash="17a682c2">2021.wnut-1.36</url>
      <bibkey>bertsch-bethard-2021-detection</bibkey>
      <doi>10.18653/v1/2021.wnut-1.36</doi>
      <pwccode url="https://github.com/abertsch72/wikipedia-puffery-detection" additional="false">abertsch72/wikipedia-puffery-detection</pwccode>
    <title_ar>الكشف عن Puffery على ويكيبيديا الإنجليزية</title_ar>
      <title_es>Detección de Puffery en la Wikipedia en inglés</title_es>
      <title_pt>Detecção de Puffery na Wikipedia em inglês</title_pt>
      <title_fr>Détection de puffery sur Wikipédia en anglais</title_fr>
      <title_ja>英語版ウィキペディアでのパフリーの検出</title_ja>
      <title_zh>检肿英语维基百科上</title_zh>
      <title_hi>अंग्रेजी विकिपीडिया पर पफरी का पता लगाना</title_hi>
      <title_ru>Обнаружение Puffery в английской Википедии</title_ru>
      <title_ga>Puffery a bhrath ar an Vicipéid Béarla</title_ga>
      <title_ka>ინგლისური ვიკიპედიაზე პუფერის განსახულება</title_ka>
      <title_el>Ανίχνευση του Puffery στην αγγλική Βικιπαίδεια</title_el>
      <title_hu>Puffery felismerése az angol Wikipédián</title_hu>
      <title_it>Rilevamento di Puffery sulla Wikipedia inglese</title_it>
      <title_kk>Ағылшын Википедиядағы Puffery- ді анықтау</title_kk>
      <title_lt>Puffery aptikimas anglų Vikipedijoje</title_lt>
      <title_ml>ഇംഗ്ലീഷ് വിക്കിപിഡിയയില്‍ പുഫെരിയുടെ കണ്ടുപിടിക്കുക</title_ml>
      <title_mk>Detection of Puffery on the English Wikipedia</title_mk>
      <title_ms>Pengesanan Puffery di Wikipedia Inggeris</title_ms>
      <title_pl>Wykrywanie Puffery w angielskiej Wikipedii</title_pl>
      <title_no>Oppdaging av Puffery på engelsk Wikipedia</title_no>
      <title_mn>Англи хэлний Wikipedia дээр Пуферийн мэдлэг</title_mn>
      <title_ro>Detectarea lui Puffery pe Wikipedia în limba engleză</title_ro>
      <title_sr>Otkrivanje Pufferyja na engleskoj Vikipediji</title_sr>
      <title_si>Name</title_si>
      <title_so>Baaritaanka Puffery ee Ingiriis Wikipedia</title_so>
      <title_sv>Upptäckt av Puffery på engelska Wikipedia</title_sv>
      <title_ur>انگلیسی ویکیپیڈیا پر پوفری کا اظہار</title_ur>
      <title_ta>ஆங்கிலம் விகிபிடியாவில் புபரியின் கண்டுபிடிப்பு</title_ta>
      <title_mt>Sejbien ta’ Puffery fuq il-Wikipedia Ingliża</title_mt>
      <title_uz>Inglizcha Wikipediya tilida Pufferni aniqlash</title_uz>
      <title_vi>Việc phát hiện Puffery trên Wikipedia của Anh.</title_vi>
      <title_bg>Откриване на подпухналост в Уикипедия</title_bg>
      <title_da>Opdagelse af Puffery på den engelske Wikipedia</title_da>
      <title_nl>Detectie van Puffery op de Engelse Wikipedia</title_nl>
      <title_hr>Otkrivanje Pufferyja na engleskoj Wikipediji</title_hr>
      <title_de>Erkennung von Puffery in der englischen Wikipedia</title_de>
      <title_sw>Uteuzi wa Puffery kwenye Wikipedia ya Kiingereza</title_sw>
      <title_id>Deteksi Puffery di Wikipedia Inggris</title_id>
      <title_tr>Iňlisçe Wikipediýada Pufferiň tanyşy</title_tr>
      <title_ko>영문 위키백과에서 허장성세가 검출되다</title_ko>
      <title_am>በንግግሊዝኛ Wikipedia ላይ ፉፉር ማግኘት</title_am>
      <title_af>Name</title_af>
      <title_fa>شناسایی پافری در ویکیپدیا انگلیسی</title_fa>
      <title_hy>Անգլերենի Վիքիփեդիայում Պաֆերի հայտնաբերումը</title_hy>
      <title_az>İngilizə Wikipediyasında Puffery'nin keşfeti</title_az>
      <title_bn>Detection of Puffery on the English Wikipedia</title_bn>
      <title_sq>Detektimi i Puffery në Wikipedia Angleze</title_sq>
      <title_et>Puffery avastamine Eesti Vikipeedias</title_et>
      <title_fi>Pufferyn tunnistaminen englanniksi Wikipediasta</title_fi>
      <title_ca>Detecció de Puffery a la Wikipedia anglesa</title_ca>
      <title_cs>Detekce Puffery na anglické Wikipedii</title_cs>
      <title_bs>Otkrivanje Pufferyja na engleskoj Wikipediji</title_bs>
      <title_jv>Tatanan Puffy kanggo Wiipedya Inggris</title_jv>
      <title_sk>Zaznavanje puffery v angleški Wikipediji</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>དབྱིན་ཡིག་གི་Wikipedia་ཐོག་ཏུ་Puffery སྟོན་ཞུགས་བྱེད་པ</title_bo>
      <title_he>גילוי של פאפרי בוויקיפדיה האנגלית</title_he>
      <abstract_ar>على ويكيبيديا ، موسوعة التعهيد الجماعي على الإنترنت ، يفرض المتطوعون السياسات التحريرية للموسوعة. ألهمت سياسة ويكيبيديا بشأن الحفاظ على وجهة نظر محايدة الأبحاث الحديثة حول اكتشاف التحيز ، بما في ذلك "كلمات ابن عرس" و "التحوط". حتى الآن ، لم يتم إنجاز سوى القليل من العمل لتحديد العبارات "المنتفخة" ، وهي عبارات إيجابية بشكل مفرط دون مصدر يمكن التحقق منه. نوضح أن جمع بيانات التدريب لهذه المهمة يتطلب بعض العناية ، وننشئ مجموعة بيانات من خلال الجمع بين التعليقات التوضيحية التحريرية على ويكيبيديا وتقنيات استرجاع المعلومات. قارنا عدة طرق للتنبؤ بالانتفاخ ، وحققنا 0.963 درجة f1 من خلال دمج ميزات الاقتباس في نموذج RoBERTa. أخيرًا ، نوضح كيفية دمج نموذجنا مع البنية التحتية العامة لـ Wikipedia لرد الجميل لمجتمع محرر Wikipedia.</abstract_ar>
      <abstract_pt>Na Wikipedia, uma enciclopédia online de crowdsourcing, os voluntários aplicam as políticas editoriais da enciclopédia. A política da Wikipédia de manter um ponto de vista neutro inspirou pesquisas recentes sobre detecção de viés, incluindo “palavras de doninha” e “hedges”. No entanto, até o momento, pouco trabalho foi feito na identificação de “puffery”, frases que são excessivamente positivas sem uma fonte verificável. Demonstramos que coletar dados de treinamento para esta tarefa requer alguns cuidados e construir um conjunto de dados combinando anotações editoriais da Wikipedia e técnicas de recuperação de informações. Comparamos várias abordagens para prever o puffery e alcançamos uma pontuação de 0,963 f1 incorporando recursos de citação em um modelo RoBERTa. Por fim, demonstramos como integrar nosso modelo com a infraestrutura pública da Wikipédia para retribuir à comunidade de editores da Wikipédia.</abstract_pt>
      <abstract_es>En Wikipedia, una enciclopedia en línea colaborativa, los voluntarios hacen cumplir las políticas editoriales de la enciclopedia. La política de Wikipedia de mantener un punto de vista neutral ha inspirado investigaciones recientes sobre la detección de sesgos, incluidas las «palabras comadrejas» y las «coberturas». Sin embargo, hasta la fecha, se ha hecho poco trabajo en la identificación de frases «puffery» que son demasiado positivas sin una fuente verificable. Demostramos que la recopilación de datos de capacitación para esta tarea requiere cierto cuidado, y construimos un conjunto de datos combinando anotaciones editoriales de Wikipedia y técnicas de recuperación de información. Comparamos varios enfoques para predecir el puffery y logramos una puntuación de 0.963 f1 mediante la incorporación de características de citación en un modelo RoBerta. Finalmente, demostramos cómo integrar nuestro modelo con la infraestructura pública de Wikipedia para retribuir a la comunidad de editores de Wikipedia.</abstract_es>
      <abstract_fr>Sur Wikipedia, une encyclopédie participative en ligne, les bénévoles appliquent les politiques éditoriales de l'encyclopédie. La politique de Wikipédia sur le maintien d'un point de vue neutre a inspiré de récentes recherches sur la détection des biais, y compris les « mots belettes » et les « haies ». Pourtant, à ce jour, peu de travail a été fait pour identifier les « boufferies », des phrases trop positives sans source vérifiable. Nous démontrons que la collecte de données de formation pour cette tâche nécessite un certain soin et créons un ensemble de données en combinant les annotations éditoriales Wikipédia et les techniques de récupération d'informations Nous comparons plusieurs approches pour prédire la bouffée et obtenons un score f1 de 0,963 en incorporant des caractéristiques de citation dans un modèle Roberta. Enfin, nous montrons comment intégrer notre modèle à l'infrastructure publique de Wikipédia pour redonner à la communauté des éditeurs de Wikipédia.</abstract_fr>
      <abstract_ja>オンラインのクラウドソーシングされた百科事典であるウィキペディアでは、ボランティアが百科事典の編集方針を実施しています。中立的な視点を維持するというウィキペディアの方針は、最近のバイアス検出に関する研究にインスピレーションを与えています。その中には、「やつらの言葉」や「ヘッジ」も含まれます。しかしながら、検証可能なソースなしで過剰にポジティブな「ふわふわ」フレーズを特定する作業は、現在までほとんど行われていません。このタスクのためにトレーニングデータを収集するには注意が必要であることを実証し、ウィキペディアの編集注釈と情報取得技術を組み合わせてデータセットを構築します。ふくらみを予測するためのいくつかのアプローチを比較し、RoBERTaモデルに引用特徴を組み込むことによって、0.963 f 1スコアを達成する。最後に、ウィキペディアのエディターコミュニティに還元するために、ウィキペディアのパブリックインフラストラクチャーとモデルを統合する方法を実演します。</abstract_ja>
      <abstract_zh>维基百科上,一在线众包百科全书,志愿者行百科全书编辑之政。 维基百科持中立论激近偏见检测,兼"黄鼠狼词"、"对冲"。 然迄今为止浮夸之事寡,短语无可验证之极也。 证其训练数须慎,并合维基百科辑注信息检索术以立数集。 余校数占浮肿之法,并引特征于RoBERTa模以成0.963 f1分。 最后,我们演示了我们模样和维基百科的公共基础设施集成,以回馈维基百科编辑社区。</abstract_zh>
      <abstract_hi>विकिपीडिया पर, एक ऑनलाइन क्राउडसोर्स्ड विश्वकोश, स्वयंसेवक विश्वकोश की संपादकीय नीतियों को लागू करते हैं। एक तटस्थ दृष्टिकोण को बनाए रखने पर विकिपीडिया की नीति ने पूर्वाग्रह का पता लगाने पर हाल के शोध को प्रेरित किया है, जिसमें "वीज़ल शब्द" और "हेजेज" शामिल हैं। फिर भी आज तक, "पफरी" की पहचान करने पर बहुत कम काम किया गया है, वाक्यांश जो एक सत्यापन योग्य स्रोत के बिना अत्यधिक सकारात्मक हैं। हम प्रदर्शित करते हैं कि इस कार्य के लिए प्रशिक्षण डेटा एकत्र करने के लिए कुछ देखभाल की आवश्यकता होती है, और विकिपीडिया संपादकीय एनोटेशन और सूचना पुनर्प्राप्ति तकनीकों के संयोजन से डेटासेट का निर्माण करना पड़ता है। हम पफरी की भविष्यवाणी करने के लिए कई दृष्टिकोणों की तुलना करते हैं, और एक RoBERTA मॉडल में उद्धरण सुविधाओं को शामिल करके 0.963 f1 स्कोर प्राप्त करते हैं। अंत में, हम प्रदर्शित करते हैं कि विकिपीडिया संपादक समुदाय को वापस देने के लिए विकिपीडिया के सार्वजनिक बुनियादी ढांचे के साथ हमारे मॉडल को कैसे एकीकृत किया जाए।</abstract_hi>
      <abstract_ru>В Википедии, онлайновой краудсорсинговой энциклопедии, волонтеры обеспечивают соблюдение редакционной политики энциклопедии. Политика Википедии по сохранению нейтральной точки зрения вдохновила недавние исследования по обнаружению предвзятости, включая «ласковые слова» и «изгороди». Тем не менее, на сегодняшний день мало что было сделано для выявления «пышных» фраз, которые являются чрезмерно позитивными без поддающегося проверке источника. Мы демонстрируем, что сбор обучающих данных для этой задачи требует некоторой осторожности, и создаем набор данных, комбинируя редакционные аннотации Википедии и методы поиска информации. Мы сравниваем несколько подходов к прогнозированию отечности и получаем 0,963 балла f1 путем включения признаков цитирования в модель RoBERTa. Наконец, мы демонстрируем, как интегрировать нашу модель с публичной инфраструктурой Википедии, чтобы вернуть ее сообществу редакторов Википедии.</abstract_ru>
      <abstract_ga>Ar Vicipéid, chiclipéid sluafhoinsithe ar líne, forfheidhmíonn oibrithe deonacha beartais eagarthóireachta na chiclipéid. Spreag polasaí Vicipéid maidir le dearcadh neodrach a choinneáil taighde le déanaí ar bhrath laofachta, lena n-áirítear “focail easal” agus “fálta”. Go dtí seo, is beag obair atá déanta go dtí seo chun frásaí “puffery” a aithint atá ró-dhearfach gan foinse infhíoraithe. Léirímid go dteastaíonn cúram áirithe le sonraí oiliúna a bhailiú don tasc seo, agus tógaimid tacar sonraí trí nótaí eagarthóireachta Vicipéide agus teicnící aisghabhála faisnéise a chomhcheangal. Déanaimid comparáid idir cuir chuige éagsúla chun puffery a thuar, agus bainimid amach scór 0.963 f1 trí ghnéithe lua a ionchorprú i múnla RoBERTa. Ar deireadh, léirímid conas ár múnla a chomhtháthú le bonneagar poiblí Vicipéid chun a thabhairt ar ais do phobal eagarthóirí Vicipéid.</abstract_ga>
      <abstract_ka>ვიკიპედიაში, online crowdsourced encyclopedia, ბოლონტერები ინციკლოპედიის რედაქტიური პოლიტიკის გაუკეთებენ. ვიკიპედიის პოლიტიკა, რომელიც ნეირრალური ხედვის შესაძლებელად დააყენება, უკვე ახალი პასუხის შესაძლებელად გააღმოჩენება, შესაძლებელად 'სულ სიტყვები' და ' მაგრამ ახლა, პატარა სამუშაო იდენტიფიკაციისთვის გავაკეთებულია, რომლებიც ძალიან პოტიფიკაციური გამოიყენებულია. ჩვენ გამოჩვენებთ, რომ ამ დავალებისთვის მონაცემების კოლექციის მონაცემები უნდა დარწმუნოთ, და მონაცემების კონფიგურაციის რედაქტირება და ინფორმაციის მიღების ტექნოგიების შე ჩვენ რამდენიმე მიღება პუფერის წარმოდგენისთვის და 0.963 f1 წარმოდგენისთვის პუბერტია მოდელში ჩვენ დავყენებთ. საბოლოოდ, ჩვენ მოვიდენსებთ, როგორ ჩვენი მოდელს ვიკიპედიაში საზოგადო ინფრაქტურაციაში ინტერგურაციას, რომ ვიკიპედიაში რედაქტორის საზოგადო</abstract_ka>
      <abstract_hu>A Wikipédián, egy online közösségi forrásból származó enciklopédián az önkéntesek betartják az enciklopédia szerkesztési irányelveit. A Wikipédia semleges nézőpontjának fenntartására irányuló politikája inspirálta az elfogultságok felismerésére irányuló közelmúltbeli kutatásokat, beleértve a "menyétszavakat" és a "sövényeket". A mai napig azonban kevés munkát végeztek a "puffadás" kifejezések azonosításán, amelyek túlságosan pozitívak, ellenőrizhető forrás nélkül. Bemutatjuk, hogy az erre a feladatra vonatkozó képzési adatok gyűjtése némi gondosságot igényel, és a Wikipédia szerkesztői jegyzeteinek és információvisszakeresési technikáinak kombinálásával készítünk egy adatkészletet. Számos megközelítést hasonlítunk össze a puffery előrejelzésére, és 0,963 f1 pontszámot érünk el a RoBERTa modellbe való beépítésével. Végül bemutatjuk, hogyan integráljuk modellünket a Wikipédia nyilvános infrastruktúrájába, hogy visszaadjuk a Wikipédia szerkesztői közösségének.</abstract_hu>
      <abstract_el>Στη Βικιπαίδεια, μια διαδικτυακή εγκυκλοπαίδεια με πλήθη πηγή, οι εθελοντές επιβάλλουν τις συντακτικές πολιτικές της εγκυκλοπαίδειας. Η πολιτική της Βικιπαίδειας για τη διατήρηση μιας ουδέτερης απόψεως ενέπνευσε την πρόσφατη έρευνα σχετικά με την ανίχνευση προκατάληψης, συμπεριλαμβανομένων των "λέξεων νυφίδας" και των "φρακτών". Ωστόσο, μέχρι σήμερα, ελάχιστα έχει γίνει για τον εντοπισμό "φουσκωτών", φράσεων που είναι υπερβολικά θετικές χωρίς επαληθεύσιμη πηγή. Αποδεικνύουμε ότι η συλλογή δεδομένων κατάρτισης για αυτό το έργο απαιτεί κάποια προσοχή και κατασκευάζουμε ένα σύνολο δεδομένων συνδυάζοντας σχολιασμούς σύνταξης της Βικιπαίδειας και τεχνικές ανάκτησης πληροφοριών. Συγκρίνουμε διάφορες προσεγγίσεις για την πρόβλεψη της φυσαλίδας και επιτυγχάνουμε 0.963 f1 βαθμολογία ενσωματώνοντας χαρακτηριστικά παραπομπής σε ένα μοντέλο RoBERTa. Τέλος, καταδεικνύουμε πώς μπορούμε να ενσωματώσουμε το μοντέλο μας με τη δημόσια υποδομή της Βικιπαίδειας για να δώσουμε πίσω στην κοινότητα των εκδότων της Βικιπαίδειας.</abstract_el>
      <abstract_it>Su Wikipedia, un'enciclopedia online crowdsourcing, i volontari applicano le politiche editoriali dell'enciclopedia. La politica di Wikipedia sul mantenimento di un punto di vista neutrale ha ispirato recenti ricerche sul rilevamento dei pregiudizi, tra cui "parole donnole" e "siepi". Tuttavia, finora, poco lavoro è stato fatto per identificare le frasi "gonfie", che sono eccessivamente positive senza una fonte verificabile. Dimostriamo che la raccolta dei dati di formazione per questo compito richiede una certa cura, e costruiamo un set di dati combinando annotazioni editoriali di Wikipedia e tecniche di recupero delle informazioni. Confrontiamo diversi approcci per predire il puffery e raggiungiamo un punteggio di 0,963 f1 incorporando caratteristiche di citazione in un modello RoBERTa. Infine, mostriamo come integrare il nostro modello con l'infrastruttura pubblica di Wikipedia per restituirlo alla comunità di editori di Wikipedia.</abstract_it>
      <abstract_kk>Википедияда, онлайн көпшілікті енциклопедиясы, көпшіліктер енциклопедияның редакториялық саясаттарын орындайды. Википедияның тәуелсіз көрініс нәтижесін сақтау ережесі жаңа тәуелсіздік анықтау үшін зерттеулерді түсіндіреді, сондай-ақ 'желілік сөздер' және 'желіктер' деген Бірақ қазірше 'puffery' дегенді анықтау үшін кішкентай жұмыс істеді, тексерілмейтін көзі болмаса, толық оң жақсы сөздерді анықтау үшін. Біз бұл тапсырманың оқыту деректерін жинау керектігін көрсетедік. Википедия редакторлық жазбаларын және мәліметті алу технологияларын біріктіріп, деректер жинағын құру керек. Біз пуферияны бақылау үшін бірнеше арқылы салыстырып, 0, 963 f1 нүктесін RoBERTa моделіне таңдап тастадық. Соңында, біз Википедия редакторының көпшілік инфраструктурасына қалай моделімізді келтіру үшін көрсетедік.</abstract_kk>
      <abstract_mk>На Википедија, онлајн енциклопедија од публика, доброволците ја спроведуваат редактивната политика на енциклопедијата. Политиката на Википедија за одржување на неутрална точка на поглед инспирираше неодамнешно истражување за детекција на предрасуди, вклучувајќи и „зборови за женски“ и „заштити“. Сепак, досега малку работа е направена за идентификување на фразите „пуфери“, кои се премногу позитивни без верификувачки извор. Демонстрираме дека собирањето на податоци за обуката за оваа задача бара некаква внимание и изградба на податок со комбинација на уредничките анатации на Википедија и техники за преземање информации. Ние споредуваме неколку пристапи за предвидување на пуферија, и постигнуваме 0,963 ф1 оценки со вклучување на цитатни карактеристики во модел на RoBERTa. Конечно, демонстрираме како да го интегрираме нашиот модел со јавната инфраструктура на Википедија за да ја вратиме заедницата на уредниците на Википедија.</abstract_mk>
      <abstract_lt>Vikipedijoje, internetinėje visuomeninėje enciklopedijoje, savanoriai įgyvendina enciklopedijos redakcijos politiką. Vikipedijos politika išlaikyti neutral ų požiūrį įkvėpė neseniai atliktus mokslinius tyrimus, susijusius su s ąmoningumo nustatymu, įskaitant "nuodėmių žodžius" ir "apsidraudimus". Vis dėlto iki šiol nedaug buvo atlikta nustatant "puffery" frazes, kurios yra pernelyg teigiamos be tikrinamo šaltinio. Mes demonstruojame, kad rengiant mokymo duomenis šiai užduotims reikia tam tikros atsargumo ir sukuriant duomenų rinkinį derinant Wikipedia redakcines anotacijas ir informacijos gavimo metodus. Palyginame keletą metodų, kaip prognozuoti trūkumą, ir siekiame 0,963 f1 balai, įtraukdami citacijos savybes į RoBERTa model į. Finally, we demonstrate how to integrate our model with Wikipedia's public infrastructure to give back to the Wikipedia editor community.</abstract_lt>
      <abstract_ms>Di Wikipedia, enciklopedia sumber ramai online, sukarelawan memaksa polisi editorial enciklopedia. Polisi Wikipedia untuk mempertahankan titik pandangan neutral telah menginspirasikan kajian baru-baru ini mengenai pengesan bias, termasuk 'perkataan weasel' dan 'hedges'. Namun hingga kini, sedikit kerja telah dilakukan untuk mengenalpasti 'puffery,' frasa yang terlalu positif tanpa sumber yang boleh disahkan. Kami menunjukkan bahawa mengumpulkan data latihan untuk tugas ini memerlukan beberapa perhatian, dan membina set data dengan menggabungkan anotasi editorial Wikipedia dan teknik pemulihan maklumat. Kami membandingkan beberapa pendekatan untuk meramalkan puffery, dan mencapai skor 0.963 f1 dengan memasukkan ciri citasi ke dalam model RoBERTa. Finally, we demonstrate how to integrate our model with Wikipedia's public infrastructure to give back to the Wikipedia editor community.</abstract_ms>
      <abstract_ml>വിക്കിപിഡിയയില്‍, ഓണ്‍ലൈന്‍ കൂട്ടുകാരുടെ എക്സിക്ലോപിഡിയയില്‍ സ്വേച്ഛാര്‍ത്തകര്‍ എക്സിക്ലോപിഡിയയുടെ എഡിറ് വിക്കിപിഡിയയുടെ ന്യൂട്ടല്‍ കാഴ്ചപ്പെടുത്തുന്നതിനുള്ള പോളിസിക്കിപ്പിയയുടെ നിയമപ്പെടുത്തിയിരിക്കുന്നു. പി എന്നിട്ടും തീര്‍ച്ചയായും ഉറപ്പില്ലാത്ത സ്രോതസ്സുമില്ലാത്ത വാക്കുകള്‍ പരിചയപ്പെടുത്തുന്നതിനെക്കുറിച്ച് ച ഈ ജോലിക്കുള്ള പരിശീലന വിവരങ്ങള്‍ സംഘടിപ്പിക്കുന്നതിന് കുറച്ച് ശ്രദ്ധ ആവശ്യമുണ്ടെന്നും വിക്കിപിഡിയയുടെ എഡിറ്ററിയല്‍ വിവരങ് We compare several approaches to predicting puffery, and achieve 0.963 f1 score by incorporating citation features into a RoBERTa model.  അവസാനം, നമ്മുടെ മോഡല്‍ വിക്കിപിഡിയയുടെ പൊതു അടിസ്ഥാനത്തോടൊപ്പം ഒരുമിച്ചുകൂട്ടുന്നത് എങ്ങനെയാണെന്ന് ഞങ്ങള്‍ കാണിച്</abstract_ml>
      <abstract_mt>Fuq il-Wikipedia, enċiklopedija onlajn b’crowdsourced, il-voluntiera jinfurzaw il-politiki editorjali tal-enċiklopedija. Wikipedia's policy on maintaining a neutral point of view has inspired recent research on bias detection, including 'weasel words' and 'hedges'.  Madankollu sal-lum, ftit sar xogħol biex jiġu identifikati frażijiet li huma pożittivi wisq mingħajr sors verifikabbli. Aħna nuru li l-ġbir tad-dejta dwar it-taħriġ għal dan il-kompitu jeħtieġ xi attenzjoni, u nibnu sett ta’ dejta billi nikkombinaw annotazzjonijiet editorjali tal-Wikipedia u tekniki ta’ ġbir ta’ informazzjoni. Aħna nqabblu diversi approċċi għat-tbassir tal-puffery, u niksbu punteġġ ta’ 0.963 f1 billi ninkorporaw karatteristiċi ta’ ċitazzjoni f’mudell RoBERTa. Fl-aħħar nett, nagħmlu xhieda dwar kif nistgħu nintegraw il-mudell tagħna mal-infrastruttura pubblika tal-Wikipedia biex nirritornaw lill-komunità editorjali tal-Wikipedia.</abstract_mt>
      <abstract_no>På Wikipedia får eit internett crowdsourced encyclopedia, friviljarane påkraft redigeringspolitikk på encyclopedia. Wikipedia s politikk om å vedlikehalda eit nøytralt synspunkt har inspirert nyleg forskning om oppdaging av bias, inkludert «weasel words» og «hedges». Men til dag er liten arbeid gjort ved identifisering av « puffery », fraser som er overpositivt utan eit stadfestig kjelde. Vi viser at å samla opplæringsdata for denne oppgåva krev nokre opplæring, og konstruer ein dataset ved å kombinere Wikipedia- redigeringsnotasjonar og informasjonshendingstekningar. Vi samanliknar fleire tilnærmingar til å forventa puffery, og oppnå 0,963 f1- poeng ved å inkludere siteringsfunksjonar i ein RoBERTa- modell. I slutt viser vi korleis modellen vårt skal integrera med offentlige infrastruktur til Wikipedia for å gjera tilbake til fellesskapen for Wikipedia-redigering.</abstract_no>
      <abstract_mn>Wikipedia дээр онлайн олон нийгмийн эрчим хүчний хувьд сайн дурын сайн дурын дурын захирал бодлогыг шаарддаг. Википедийн засгийн гайхалтай үзэл бодлогын тухай саяхан үзэл бодлогын тухай сэтгэл хөдлөл ойлголтын тухай судалгаа "багахан үг" болон "багахан" гэх мэт судалгаанд урам зориулсан. Гэвч одоо хүртэл бага ажиллагаа шалгаж чаддаг эх үүсвэргүй маш эерэг өгүүлбэрүүдийг тодорхойлж чадсан. Бид энэ үйл ажилд сургалтын өгөгдлийг цуглуулах нь зарим ухаан шаардлагатай, Wikipedia-ын редакторын захирал, мэдээлэл авах технологийг цуглуулж өгөгдлийн санг бүтээж байна. Бид буферийг таамаглах олон арга барилгыг харьцуулж, 0.963 f1 оноо хүртэл Роберта загвар руу шилжүүлж байна. Эцэст нь бид Wikipedia-ын нийтийн бүтээгдэхүүний загварыг Wikipedia-ын редакторын нийгэмд хэрхэн нэгтгэх вэ гэдгийг харуулж байна.</abstract_mn>
      <abstract_pl>Na Wikipedii, internetowej encyklopedii crowdsourcingowej wolontariusze egzekwują politykę redakcyjną encyklopedii. Polityka Wikipedii dotycząca utrzymania neutralnego punktu widzenia zainspirowała ostatnie badania nad wykrywaniem stronniczości, w tym "słowa łasica" i "hedges". Jednak do tej pory niewiele pracy zostało zrobione nad identyfikacją "pustych", zwrotów, które są zbyt pozytywne bez weryfikowalnego źródła. Pokazujemy, że zbieranie danych szkoleniowych do tego zadania wymaga pewnej staranności i budujemy zbiór danych poprzez łączenie adnotacji redakcyjnych Wikipedii i technik pobierania informacji. Porównujemy kilka podejść do przewidywania puffery i osiągamy wynik 0.963 f1 poprzez włączenie cech cytowania do modelu RoBERTa. Wreszcie pokazujemy, jak zintegrować nasz model z publiczną infrastrukturą Wikipedii, aby oddać coś społeczności edytorów Wikipedii.</abstract_pl>
      <abstract_sr>Na Wikipediji, internetska crowdsourced encyclopedia, dobrovoljci primjenjuju editorialnu politiku enciklopedije. Politika Wikipedije o održavanju neutralnog pogleda inspirisala je nedavno istraživanje o otkrivanju predrasude, uključujući "slabe riječi" i "ograde". Ipak, do sada, mali posao je obavljen na identifikaciji "puffery", rečenica koja su previše pozitivna bez potvrðenog izvora. Pokazujemo da prikupljanje podataka o obuci za ovaj zadatak zahteva neku pažnju i izgraditi podatak kombiniranjem editorialnih annotacija i tehnika prikupljanja informacija u Vikipediji. Uspoređujemo nekoliko pristupa predviđanju pufferija i postižemo 0,963 f1 rezultat uključujući ciljanje karakteristike u model RoBERTa. Konačno, pokazujemo kako da integrišemo naš model sa javnom infrastrukturom Wikipedije da se vratimo zajednici editora Wikipedije.</abstract_sr>
      <abstract_si>විකිපිඩියා වලින්, අන්තර්ජාතික සම්පූර්ණ සම්පූර්ණයක්, ස්වායෝජිකයෝ සම්පූර්ණ විධානය කරනවා  විකිපිඩියාගේ ප්‍රතිස්ථානය ප්‍රතිස්ථානයක් තියාගන්න පුළුවන් ප්‍රතිස්ථානයක් තියාගත්තා විකිපිඩියාගේ ප නමුත්, අවස්ථානයෙන්, පොඩි වැඩ කරලා තියෙනවා 'puffery' කිරීමේ අඳුරගන්න, ප්‍රශ්නයක් විශ්වාස කරන්න පුළුවන අපි පැහැදිලි කරනවා මේ වැඩේ වෙනුවෙන් ප්‍රීක්ෂණා දත්ත සම්බන්ධ කරනවා කියලා, විකිපිඩියාවේ සංපාදනය සහ තොරතුරු ප්‍රවේශ අපි පෆරි විශ්වාස කරන්න විදිහට සම්බන්ධ කරනවා, ඒ වගේම 0.963 f1 ප්‍රමාණයක් ලැබෙනවා, රොබෙර්ටා මෝඩේල් එකක් සම්බන්ධ කර අන්තිමට, අපි පෙන්වන්නම් විකිපිඩියාගේ සාමාජික සංස්ථානයෙන් අපේ මොඩේල් එක්කරගන්න පුළුවන් විකිපිඩ</abstract_si>
      <abstract_ro>Pe Wikipedia, o enciclopedie online crowdsourced, voluntarii aplică politicile editoriale ale enciclopediei. Politica Wikipedia privind menținerea unui punct de vedere neutru a inspirat cercetări recente privind detectarea prejudecăților, inclusiv "cuvinte nevăstuice" și "garduri vii". Cu toate acestea, până în prezent, s-au făcut puține eforturi pentru identificarea frazelor "puffery", care sunt prea pozitive fără o sursă verificabilă. Demonstrăm că colectarea datelor de instruire pentru această sarcină necesită o anumită atenție și construim un set de date prin combinarea adnotărilor editoriale Wikipedia și a tehnicilor de recuperare a informațiilor. Comparăm mai multe abordări pentru a predice puffery și obținem scorul de 0.963 f1 prin încorporarea caracteristicilor de citare într-un model RoBERTa. În cele din urmă, demonstrăm cum să integrăm modelul nostru cu infrastructura publică Wikipedia pentru a da înapoi comunității editorilor Wikipedia.</abstract_ro>
      <abstract_so>Wikipediya waxaa laga helaa shabakadda koonfureed oo ay leeyihiin encyklopedia, kuwa iskaa ahuna waxay qabanqaabiyaan siyaasadaha hagitaanka ee encyklopedia. Ceymiska Wikipedia oo ku saabsan xafiiska aragtida ee nøytral ah ayaa waxyooday baaritaanka ku saabsan baaritaanka, kuwaas oo ka mid ah 'hadalka weasel' iyo 'hedges'. Hadaba ilaa waqtiga la joogo waxaa la sameeyay shaqo yar oo la aqoonsaday 'puffery', hadallada aad u wanaagsan oo aan la hubin. Waxaynu muujinnaa in la soo ururiyo macluumaadka waxbarashada shaqadan looga baahan yahay daryeel qaarkood, waxaana sameynaa sawir macluumaad ah si ay u soo ururiyaan tahririyada Wikipedia iyo qalabka helitaanka macluumaadka. Waxaynu isbarbardhignaa qaabab badan oo ku saabsan ka hor dhigidda naafada, waxaynu gaadhnaa koox 0.963 f1, waxaana ku qoraynaa kooxo bareecada oo ku qoraya sameynta RoBERTA. Ugu dambaysta, waxaynu muujinnaa sida modelkeenna u wada qabsato dhismaha dadweynaha ee Wikipedia si aan ugu celino bulshada edbinta Wikipedia.</abstract_so>
      <abstract_sv>På Wikipedia, en online crowdsourcing encyklopedi, upprätthåller volontärer encyklopedias redaktionella policy. Wikipedias policy för att upprätthålla en neutral synvinkel har inspirerat den senaste forskningen om bias detection, inklusive "vesselord" och "häckar". Ändå har det hittills inte gjorts mycket arbete med att identifiera "puffery", fraser som är alltför positiva utan en verifierbar källa. Vi visar att insamlingen av utbildningsdata för denna uppgift kräver viss omsorg, och skapar ett dataset genom att kombinera Wikipedias redaktionella kommentarer och informationshämtningstekniker. Vi jämför flera metoder för att förutsäga puffery och uppnår 0,963 f1 poäng genom att införliva citationsfunktioner i en RoBERTa modell. Slutligen visar vi hur vi integrerar vår modell med Wikipedias offentliga infrastruktur för att ge tillbaka till Wikipedias redaktörscommunity.</abstract_sv>
      <abstract_ta>விகிபிடியியாவில், ஒரு ஆன்லைனல் மக்கள் மூலம் மூலம் சுழற்சி செய்யப்பட்ட எக்சிக்லோபிடியா தொகுப்பு கொள்கைகளை இயக்குகி விக்கிபிடியாவின் கொள்கை ஒரு நியூக புள்ளியை பாதுகாக்குவதற்காக அண்மையில் பியாஸ் கண்டுபிடிப்பதற்கு ஆராய்ச்சி தெரிவ இன்னும் தேதிக்கு, உறுதிப்படுத்தக்கூடிய மூலம் இல்லாமல் 'புப்பரி' என்ற சொற்றொடரை அடையாளம் சிறிய வேலை செய்யப்பட்டது. இந்த பணிக்கான பயிற்சி தகவலை சேகரிக்க வேண்டும் மற்றும் விகிபிடியா தொகுப்பு அறிவிப்புகளையும் தகவல் பெறுதல் தொழில்நுட்பத்தையும நாம் எதிர்பார்க்கும் முறைகளை ஒப்பிடுகிறோம், மற்றும் 0.963 f1 புள்ளிகளை ஒரு ரோபெர்டா மாதிரியில் சேர்க்கும் போது 0.963 ப இறுதியில், விக்கிபிடியாவின் பொது அடிப்படையுடன் எங்கள் மாதிரியை எப்படி ஒருங்கிணைக்க வேண்டும் என்பதை நாம் குறிப்பிடு</abstract_ta>
      <abstract_ur>ویکیپیڈیا میں، ایک آنلاین جماعت کی آنسیکلوپیڈیا میں، سرمایہ داروں نے انسیکلوپیڈیا کی سمجھانے کی سیاست کو مضبوط کر دیا۔ ویکیپیڈیا کی پولیسی نظر کی نائرٹی پوینٹ کی حفاظت کرنے کے لئے اچھی تحقیقات کی تحقیقات کی وجہ سے ہوئی ہے، جیسے 'ویزل کلمات' اور 'ہڈز' کے ساتھ۔ لیکن یہاں تک، بہت کم کام کیا گیا ہے "مغفری" کو پہچان کرنے کے لئے، مثبت کے بغیر ایک سچی سورج کے مطابق بہت مثبت ہیں. ہم دکھاتے ہیں کہ اس کام کے لئے ترینسی ڈیٹا جمع کرنا کچھ حفاظت کی ضرورت ہے، اور ویکیپیڈیا سمجھانے کے ذریعہ ایک ڈیٹ سٹ بنانا ہے اور معلومات حاصل کرنے کی تکنیک. ہم پفری کی پیش بینی کے لئے بہت سی طریقے مقایسہ کرتے ہیں، اور 0.963 f1 اسکور کو پہنچاتے ہیں، روBERTa موڈل میں نیٹ ویٹی ویٹیوں کو شامل کر۔ آخر میں، ہم نشان دیتے ہیں کہ ویکیپیڈیا کی عمومی سازمانی کے ساتھ ہماری مدل کو ویکیپیڈیا ویکیپیڈیا ویڈیٹر کی کمونٹی کو واپس دے سکتے ہیں.</abstract_ur>
      <abstract_uz>Wikipediya, Onlayn kompyuterning tarkibi encyklopediya, o'smirlar eng tahrirlik qoidalarini bajaradi. Wikipediya qoidasi katta koʻrinishini davom etish qoidasi yangi paytlarni aniqlashga imkoniyat beradi. Hozir hozirda, tasdiqlash imkoniyatini aniqlash uchun kichkina ishni bajarildi. Biz bu vazifa uchun taʼminlovchi maʼlumotni olish uchun bir necha taʼminlov kerak va Wikipedia tahrirlash tahrirchisi tahrirchi tahrirlari va maʼlumot olish tugmalarini birlashtirish mumkin. Biz bir necha ta'sirlarni tahrirlash uchun kamaytirimiz, va 0.963 f1 scorini RoBERTA modeliga qo'yish mumkin. Oxirgi biz Wikipediya shaxsiy infrastructurini qanday birlashtirishni tushunamiz va Wikipedia tahrirchi jamiyatga qaytadi.</abstract_uz>
      <abstract_vi>Trên Wikipedia, có cả một bách khoa bị chứng khoán online, tình nguyện luôn củng cố các chính s ách xuất bản của bách khoa. Chính s ách của Wikipedia đã nuôi dưỡng một quan điểm trung lập đã truyền cảm hứng cho nghiên cứu về việc phát hiện khuynh hướng, bao gồm'những từ chồn'và'hàng rào'. Tuy nhiên, cho tới nay, đã có rất ít việc để xác định "đức giả", những cụm từ quá tích cực mà không có một nguồn có thể xác định. Chúng tôi chứng minh việc thu thập dữ liệu đào tạo cho nhiệm vụ này cần một chút cẩn thận, và xây dựng một tập tin bằng cách kết hợp biên bản Wikipedia và kỹ thuật thu thập thông tin. Chúng tôi so sánh các phương pháp dự đoán trên nó, và ghi ghi số 0.963 f1 bằng cách nhập các chức năng ghi chú vào mô hình RozerTa. Cuối cùng, chúng tôi s ẽ chứng minh cách tích hợp mô hình của chúng tôi với hệ thống công cộng của Wikipedia.</abstract_vi>
      <abstract_bg>В Уикипедия, онлайн енциклопедия, доброволците прилагат редакционните политики на енциклопедията. Политиката на Уикипедия за поддържане на неутрална гледна точка вдъхнови неотдавнашни изследвания за откриване на пристрастия, включително "думи на невестулки" и "живи плетове". И все пак до днешна дата е направена малка работа по идентифицирането на "подпухналост", фрази, които са прекалено положителни без проверяем източник. Ние демонстрираме, че събирането на данни за обучение за тази задача изисква известно внимание и конструираме набор от данни чрез комбиниране на редакционни анотации на Уикипедия и техники за извличане на информация. Сравняваме няколко подхода за прогнозиране на подпухналост и постигаме резултат 0.963 чрез включване на цитационни функции в модела на РоБЕРТА. И накрая, демонстрираме как да интегрираме нашия модел с публичната инфраструктура на Уикипедия, за да се върнем на общността на редакторите в Уикипедия.</abstract_bg>
      <abstract_da>På Wikipedia, en online crowdsourcing encyklopædi, håndhæver frivillige encyklopædiens redaktionelle politikker. Wikipedia's politik om at opretholde et neutralt synspunkt har inspireret nylig forskning om bias detektion, herunder 'væsel ord' og 'hække'. Men indtil videre er der ikke gjort meget arbejde med at identificere "puffery", sætninger, der er alt for positive uden en verificerbar kilde. Vi demonstrerer, at indsamling af træningsdata til denne opgave kræver en vis omhu, og konstruerer et datasæt ved at kombinere Wikipedias redaktionelle annotationer og informationshentningsteknikker. Vi sammenligner flere tilgange til at forudsige puffery, og opnår 0,963 f1 score ved at indarbejde citationsfunktioner i en RoBERTa model. Endelig demonstrerer vi, hvordan vi integrerer vores model med Wikipedias offentlige infrastruktur for at give tilbage til Wikipedias redaktørfællesskab.</abstract_da>
      <abstract_nl>Op Wikipedia, een online crowdsourcing encyclopedie, handhaven vrijwilligers het redactionele beleid van de encyclopedie. Wikipedia's beleid om een neutraal standpunt te handhaven heeft recent onderzoek naar bias detectie geïnspireerd, waaronder 'wezelwoorden' en 'hedges'. Toch is er tot op heden weinig werk gedaan aan het identificeren van 'puffery', zinnen die overdreven positief zijn zonder verifieerbare bron. We tonen aan dat het verzamelen van trainingsgegevens voor deze taak enige zorg vereist, en bouwen een dataset op door Wikipedia redactionele annotaties en informatie retrieval technieken te combineren. We vergelijken verschillende benaderingen om puffery te voorspellen, en bereiken 0.963 f1 score door citatie functies in een RoBERTa model te integreren. Ten slotte demonstreren we hoe we ons model kunnen integreren met de openbare infrastructuur van Wikipedia om iets terug te geven aan de Wikipedia editor community.</abstract_nl>
      <abstract_id>Di Wikipedia, sebuah enciklopedia sumber daya online, sukarelawan memaksa kebijakan editorial enciklopedia. Kebijakan Wikipedia untuk mempertahankan titik pandangan yang netral telah menginspirasi penelitian baru-baru ini mengenai deteksi bias, termasuk 'kata-kata weasel' dan 'hedges'. Namun sampai saat ini, sedikit pekerjaan telah dilakukan untuk mengidentifikasi 'puffery,' frasa yang terlalu positif tanpa sumber yang dapat diperiksa. We demonstrate that collecting training data for this task requires some care, and construct a dataset by combining Wikipedia editorial annotations and information retrieval techniques.  Kami membandingkan beberapa pendekatan untuk memprediksi puffery, dan mencapai skor 0,963 f1 dengan memasukkan fitur citasi ke dalam model RoBERTa. Akhirnya, kami menunjukkan bagaimana untuk mengintegrasikan model kami dengan infrastruktur publik Wikipedia untuk memberikan kembali kepada komunitas editor Wikipedia.</abstract_id>
      <abstract_hr>Na Wikipedia, online crowdsourced encyclopedia, dobrovoljci primjenjuju uredničku politiku enciklopedije. Politika Wikipedije o održavanju neutralnog pogleda inspirirala je nedavno istraživanje o otkrivanju pristrasnosti, uključujući 'slabe riječi' i 'ograde'. Ipak, do sada, mali rad je obavljen na identifikaciji "puffery", rečenica koje su previše pozitivne bez potvrđenog izvora. Pokazujemo da prikupljanje podataka o obuci za ovaj zadatak zahtijeva neku pažnju i izgradnju podataka kombiniranjem editornih annotacija i tehnika prikupljanja informacija u Wikipediji. Uspoređujemo nekoliko pristupa predviđanju pufferyja i postići 0,963 f1 rezultat uključujući osiguranje karakteristika u model RoBERTa. Konačno, pokazujemo kako integrirati naš model sa javnom infrastrukturom Wikipedije da se vratimo zajednici urednika Wikipedije.</abstract_hr>
      <abstract_sw>Kwenye mtandao wa Wikipedia, shirika la watu mtandaoni linalopatikana na encyclopedia, wanaojitolea wanalazimisha sera za kuhariri na encyklopedia. Sera ya Wikipedia kuhusu kuendeleza mtazamo usio wa kawaida imehamasisha utafiti wa hivi karibuni juu ya uchunguzi wa upendeleo, ikiwa ni pamoja na 'maneno ya kivuli' na 'hedges'. Hata hivyo mpaka sasa, kazi ndogo imefanywa katika kutambua maneno ya 'pumzi', ambayo ni chanya zaidi bila chanzo kinachothibitishwa. Tunaonyesha kuwa kukusanya taarifa za mafunzo kwa kazi hii inahitaji huduma, na kujenga seti ya taarifa kwa kuunganisha matangazo ya kihariri na teknolojia za kupata taarifa za Wikipedia. Tunawalinganisha mbinu kadhaa za kutabiri utabiri, na kufikia score 0.963 f1 kwa kuingiza tamko hilo linahusisha katika mtindo wa RoBERTa. Mwisho, tunaonyesha namna ya kuunganisha muundo wetu na miundombinu ya umma ya Wikipedia ili kurudisha tena kwa jamii ya mhariri wa Wikipedia.</abstract_sw>
      <abstract_fa>در ویکیپدییا، یک انسیکلوپیدیا در آنلاین، داوطلب‌کنندگان سیاست‌های ویکیپلوپیدیا را اجرا می‌کنند. سیاست ویکیپدیا در مورد حفظ یک نقطه مستقل دید تحقیقات اخیرا در مورد شناسایی پیشرفت الهام داده است، شامل «کلمات ضعیف» و «حفظ» است. با این حال، کارهای کوچک در identification of 'puffery', جمله‌های زیادی مثبت بدون یک منبع قابل تأیید انجام شده است. ما نشان می دهیم که جمع داده های آموزشی برای این کار نیاز به کمک مراقبت است، و یک مجموعه داده را با ترکیب گزارش‌های ویکیپدیا و تکنیک گیری اطلاعات ساخت. ما چند دستور برای پیش بینی کردن پافری را مقایسه می کنیم، و با توجه به عنوان ویژه‌های نوشته به یک مدل RoBERTa به امتیاز 0.963 f1 رسیدیم. بالاخره، ما نشان می دهیم چگونه مدل خود را با ساختمان عمومی ویکیپدیا متصل کنیم تا به جامعه ویکیپدیا ویکیپدیا برگردیم.</abstract_fa>
      <abstract_ko>온라인 백과사전 위키백과에서 자원봉사자들이 백과사전 편집 정책을 집행한다.위키백과가 중립적인 관점을 유지하는 정책은 최근 편견 검출에 관한 연구를 불러일으켰다. '족제비 단어' 와 '모호한 제한어' 를 포함한다.그러나 지금까지'허장성세'를 식별하는 일은 드물었고 이런 단어들은 너무 적극적이어서 증명할 만한 출처가 없었다.우리는 이 임무를 위해 훈련 데이터를 수집하는 데 어느 정도 신중해야 한다는 것을 증명했고, 위키백과 편집 주석과 정보 검색 기술을 결합시켜 데이터 집합을 구축했다.우리는 몇 가지 과장된 예측 방법을 비교했는데 인용문의 특징을 RoBERTA모델에 포함시켜 f1의 득점은 0.963에 달했다.마지막으로, 우리는 우리의 모델을 위키백과의 공공 인프라 시설과 통합시켜 위키백과 편집 커뮤니티에 보답하는 방법을 보여줄 것이다.</abstract_ko>
      <abstract_sq>Në Wikipedia, një enciklopedi në internet me burime publike, vullnetarët zbatojnë politikat editoriale të enciklopedisë. Politika e Wikipedia s për mbajtjen e një pikëpamje neutrale ka frymëzuar kërkimet e fundit mbi zbulimin e paragjykimeve, duke përfshirë 'fjalët e lodhurave' dhe 'hedges'. Megjithatë deri tani, nuk është bërë shumë punë për identifikimin e frazave "puffery", që janë tepër pozitive pa një burim të verifikuar. Ne demonstrojmë se mbledhja e të dhënave të trajnimit për këtë detyrë kërkon disa kujdes, dhe ndërtimi i një grupi të dhënash duke kombinuar anotacionet editoriale të Wikipedias dhe teknikat e marrjes së informacionit. We compare several approaches to predicting puffery, and achieve 0.963 f1 score by incorporating citation features into a RoBERTa model.  Më në fund, ne demonstrojmë si të integrojmë modelin tonë me infrastrukturën publike të Wikipedia s për t'i kthyer komunitetit redaktor të Wikipedias.</abstract_sq>
      <abstract_de>Auf Wikipedia, einer Online-Crowdsourcing-Enzyklopädie, setzen Freiwillige die redaktionellen Richtlinien der Enzyklopädie durch. Wikipedias Politik zur Aufrechterhaltung eines neutralen Standpunkts hat die jüngste Forschung zur Bias Detection inspiriert, einschließlich "Wiesel Words" und "Hedges". Bisher wurde jedoch wenig daran gearbeitet, "puffery", Phrasen zu identifizieren, die ohne nachweisbare Quelle übermäßig positiv sind. Wir zeigen, dass das Sammeln von Trainingsdaten für diese Aufgabe etwas Sorgfalt erfordert, und konstruieren einen Datensatz, indem wir Wikipedia-redaktionelle Anmerkungen und Informationsabruftechniken kombinieren. Wir vergleichen verschiedene Ansätze zur Vorhersage von Puffery und erzielen 0.963 f1 Score, indem wir Zitationsmerkmale in ein RoBERTa Modell integrieren. Abschließend zeigen wir, wie wir unser Modell in die öffentliche Infrastruktur von Wikipedia integrieren können, um der Wikipedia-Editor-Community etwas zurückzugeben.</abstract_de>
      <abstract_am>በWikipedia፣ የኢንስክሎፕዲያ የድምፅ ጉዳይ የኢንስክሎፕዲያ ፖለቲካዎችን የሚያስፈልጋል፡፡ የWikipedia ፖለቲካ የውይይት ዓይነት ማሳየትን በመጠበቅ የቅርብ ዘመን የውይይት ግንኙነት እና 'የውጤት ቃላት' እና 'ድምፅ' እያደረገ የውይይይት ግንኙነትን በማሳወቅ ያስተምረዋል፡፡ Yet to date, little work has been done on identifying 'puffery,' phrases that are overly positive without a verifiable source.  ለዚህ ስራ የሚያስተምር ዳታዎችን እንዲሰበስብ እና Wikipedia ማቀናጃ ማቀናጃ እና መረጃ ማግኘት ስኬተቶችን በመጠቀም ዳታዎችን እንዲያስፈልጋል እና መግለጫ እንዲያስፈልጋለን፡፡ አካባቢውን ለመቀበል ብዙዎችን ደረጃዎች እና 0.963 f1 ደረጃዎችን ለመቀበል እናደርጋለን፡፡ Finally, we demonstrate how to integrate our model with Wikipedia's public infrastructure to give back to the Wikipedia editor community.</abstract_am>
      <abstract_hy>Վիքիփեդիայում, համացանցում ժողովրդավար հանրագիտարան, կամավորները կատարում են հանրագիտարանի խմբագրական քաղաքականությունը: Վիքիփեդիայի չեզոք տեսանկյունից պահպանելու քաղաքականությունը ոգեշնչեց վերջին ուսումնասիրությունները կողմնականության հայտնաբերման մասին, ներառյալ "կաթվածի բառեր" և "հոգեզներ": Սակայն մինչև հիմա քիչ աշխատանք է արվել բացահայտելով "խեղճ", արտահայտություններ, որոնք չափազանց դրական են առանց ստուգելի աղբյուրի: Մենք ցույց ենք տալիս, որ այս խնդրի համար ուսուցման տվյալներ հավաքելը որոշ խնամք է պահանջում, և կառուցել տվյալների համակարգ՝ միավորելով Վիքիփեդիայի խմբագրական annoտացիաներ և տեղեկատվության վերադարձման մեթոդներ: Մենք համեմատում ենք բազմաթիվ մոտեցումներ, որպեսզի կանխատեսենք խեղճը, և հասնենք 0.1963 f1 գնահատականը՝ ներառելով մեջբերման հատկանիշներ Ռոբերտա մոդելի մեջ: Վերջապես, մենք ցույց ենք տալիս, թե ինչպես ինտեգրել մեր մոդելը Վիքիփեդիայի հանրային ենթակառուցվածքի հետ, որպեսզի վերադարձնենք Վիքիփեդիայի խմբագրողների համայնքին:</abstract_hy>
      <abstract_bn>উইকিপিডিয়াতে একটি অনলাইন জনসোর্স সূত্র এনসাইক্লোপিডিয়া, স্বেচ্ছাসেবকরা এনক্সিক্লোপিডিয়ার সম্পাদকীয় নীতি বাধ্য উইকিপিডিয়ার নীতি একটি নিরপেক্ষ দৃষ্টিভঙ্গি রাখার বিষয়ে সাম্প্রতিক গবেষণা প্রদান করেছে, যার মধ্যে রয়েছে 'উইজেল শব্দ' এবং 'হে এখন পর্যন্ত 'পাফারি' চিহ্নিত বাক্যের সামান্য কাজ করা হয়েছে, যা কোন নিশ্চিত উৎস ছাড়া অত্যন্ত ইতিবাচক। আমরা দেখাচ্ছি যে এই কাজের জন্য প্রশিক্ষণের তথ্য সংগ্রহ করার কিছু সেবা দরকার এবং উইকিপিডিয়া সম্পাদকীয় বিষয়বস্তু এবং তথ্য পুনরুদ্ধার কৌ আমরা বেশ কয়েকটি উপায়ের তুলনা করি ভবিষ্যদ্বাণী করার জন্য এবং ০. 963 এফ১ স্কোর অর্জন করি রোবের্তা মডেলে তুলনা করে। শেষ পর্যন্ত আমরা আমাদের মডেল কিভাবে উইকিপিডিয়ার জনগণের কাঠামোর সাথে একত্রিত করতে পারি যাতে উইকিপিডিয়া সম্পাদক সম্পাদক সম্</abstract_bn>
      <abstract_tr>Wikipediýada, online köpürli enciklopediýa, meýletinçiler enciklopediýanyň editorial politikalaryny dowam edýärler. Wikipediýanyň neutral görnüş noktasyny goramak üçin ýakyn zamanlarda bias deteksiyony barlamagyna rugsat berdi. Indi şu wagt dowam edilen çeşme bolmadyk sözleri 'saýlaw üçin kiçi iş edildi. Biz bu zadyň üçin okuwçylyk maglumatyny ýygnamak üçin biraz seretmäge gerek bolandygyny görkeýäris we Wikipediýa editorial duýdurmalar we maglumaty almak tekniklerini birleşdirerek bir dataseti düzenleyärik. Biz pafüri önlemek üçin birnäçe golaýlary we 0.963 f1 अंश sykylaşdyrylyp, täze möhümlerniň RoBERTa nusgasyna girdirip barýarys. Soňunda, biz Vikipediýanyň halk infrastrukturyny Wikipediýanyň düzenleyici toplumyna yzyna getirmek üçin modelimizi nädip birleşdirmelidigini görkezdik.</abstract_tr>
      <abstract_af>Op Wikipedia, is 'n onlinene skakelskakelskakelige enkyclopedia, vroliewers verskaf die redigeringsbeleid van enkyclopedia. Wikipedia se beleid om 'n neutrale punt van besigtig te onderhou het onlangse ondersoek oor voorspoedie-opdekking, insluitend 'weasel words' en 'hedges'. Nog tot dag, is 'n klein werk gedoen op die identifiseer van 'puffery,' frase wat oorvloedig positief is sonder 'n bevestig bron. Ons wys dat die versameling van onderwerp data vir hierdie taak benodig sommige sorg en konstrukteer 'n datastel deur die kombinasie van Wikipedia redigeerdere notasies en inligting ontvang tekniks te kombinerer. Ons vergelyk verskeie toegange na voorskou puffery, en bereik 0. 963 f1 punt deur die inkorporeer van siteringsfunksies in 'n RoBERTa model. Eindelik, ons wys hoe ons model met die publieke infrastruktuur van Wikipedia integreer moet word om terug te gee aan die Wikipedia redigeerder gemeenskap.</abstract_af>
      <abstract_ca>A Wikipedia, una enciclopèdia d'on-line, els voluntaris aplican les polítiques editorial s de l'enciclopèdia. La política de la Wikipedia de mantenir un punt de vista neutral ha inspirat recentment recent s investigacions sobre la detecció de bias, incloent "paraules de lesbiana" i "hedges". Tot i així, fins ara, no s'ha fet gaire feina per identificar frases que són massa positives sense una font verificable. Demostram que la col·lecció de dades d'entrenament per aquesta tasca necessita cuidat i construeix un conjunt de dades combinant anotacions editorials de Wikipedia i tècniques de recuperació d'informació. Comparem diversos enfocaments per predir la confusió, i aconseguim una puntuació de 0,963 f1 incorporant característiques de citació en un model RoBERTa. Finalment, demostram com integrar el nostre model amb l'infraestructura pública de Wikipedia per donar-li de nou a la comunitat editorial de Wikipedia.</abstract_ca>
      <abstract_az>Wikipediyada, online qüvvətli enciklopedija, gönülləşdiricilər enciklopediyinin editorial siyasətini gerçəkləşdirirlər. Vikipediyanın nörtral bir görünüş nöqtəsini qorumaq məqsədilə "zəif s özlər" və "hedges" barəsində yeni təhsil keşfetməsi haqqında ilham verdi. Ancaq bu gündə, təsdiqlənməz çox pozitif sözləri təsdiqlənmək üçün küçük işlər işlədi. Biz göstəririk ki, bu işin təhsil məlumatlarını toplayaraq bəzi gözləmə ehtiyacı vardır, Wikipedia editorial annotations və məlumat alma tekniklərini birləşdirərək verilən quruluş quruluruq. Biz puffery'i tədbir etmək üçün bir neçə yolla salırıq, və 0.963 f1 nöqtəsini RoBERTa modeli ilə birləşdiririk. Sonunda, biz modelimizi Wikipediyanın halkı infrastrukturasıyla Wikipedia editörü toplumuna geri qaytarmaq üçün necə birləşdirməki göstəririk.</abstract_az>
      <abstract_bs>Na Wikipediji, internetska crowdsourced encyclopedia, dobrovoljci primjenjuju editorialnu politiku enciklopedije. Politika Wikipedije o održavanju neutralnog pogleda inspirirala je nedavno istraživanje o otkrivanju pristrasnosti, uključujući 'slabe riječi' i 'ograde'. Ipak, do sada, mali posao je obavljen na identifikaciji "puffery", rečenica koja su previše pozitivna bez potvrđenog izvora. Pokazujemo da prikupljanje podataka o obuci za ovaj zadatak zahtijeva neku pažnju i izgradnju podataka kombiniranjem editornih annotacija i tehnika prikupljanja informacija u Wikipediji. Uspoređujemo nekoliko pristupa predviđanju puffery, i postići 0,963 f1 rezultat uključujući ciljane karakteristike u model RoBERTa. Konačno, pokazujemo kako da integriramo naš model sa javnom infrastrukturom Wikipedije da se vratimo zajednici urednika Wikipedije.</abstract_bs>
      <abstract_cs>Na Wikipedii, online crowdsourcingové encyklopedii, dobrovolníci prosazují redakční politiky encyklopedie. Politika Wikipedie zachování neutrálního názoru inspirovala nedávný výzkum detekce zaujatostí, včetně "lasičích slov" a "živých plotů". Přesto bylo dosud vykonáno jen málo práce na identifikaci "nafoukaných", frází, které jsou příliš pozitivní bez ověřitelného zdroje. Ukazujeme, že shromažďování tréninkových dat pro tento úkol vyžaduje určitou péči, a sestavujeme datovou sadu kombinací redakčních anotací Wikipedie a technik vyhledávání informací. Porovnáváme několik přístupů k predikci puffery a dosáhneme 0.963 f1 skóre začleněním citačních prvků do modelu RoBERTa. Nakonec demonstrujeme, jak integrovat náš model do veřejné infrastruktury Wikipedie, abychom to vrátili komunitě editorů Wikipedie.</abstract_cs>
      <abstract_et>Vikipeedias, internetiühise entsüklopeedia, jõustavad vabatahtlikud entsüklopeedia toimetuspoliitikat. Vikipeedia poliitika neutraalse seisukoha säilitamisel on inspireerinud hiljutisi uuringuid eelarvamuste tuvastamise kohta, sealhulgas "nirgisõnad" ja "hekid". Praeguseks on aga vähe tööd tehtud, et tuvastada väljendeid, mis on liiga positiivsed ilma kontrollitava allikata. Näitame, et koolitusandmete kogumine selle ülesande jaoks nõuab mõningast hoolsust ning koostame andmekogumi, kombineerides Wikipedia toimetuslikke märkusi ja teabe hankimise tehnikaid. Me võrdleme mitmeid lähenemisviise puffery prognoosimiseks ja saavutame 0,963 f1 skoori lisades tsiteerimisfunktsioonid RoBERTa mudelile. Lõpuks näitame, kuidas integreerida meie mudel Vikipeedia avaliku infrastruktuuriga, et anda tagasi Vikipeedia toimetajate kogukonnale.</abstract_et>
      <abstract_fi>Wikipediassa, verkossa crowdsourcing-tietosanakirjassa vapaaehtoiset valvovat tietosanakirjan toimituksellisia käytäntöjä. Wikipedian politiikka puolueettoman näkökulman säilyttämisestä on inspiroinut viimeaikaisia tutkimuksia ennakkoluulojen havaitsemisesta, mukaan lukien "näädän sanat" ja "pensasaidat". Tähän mennessä ei ole tehty juurikaan työtä "puffery", lauseiden tunnistamiseksi, jotka ovat liian positiivisia ilman todennettavia lähteitä. Osoitamme, että koulutustiedon kerääminen tätä tehtävää varten vaatii hieman huolellisuutta, ja rakennamme aineiston yhdistämällä Wikipedian toimituksellisia huomautuksia ja tiedonhakutekniikoita. Vertaamme useita lähestymistapoja puhkeamisen ennustamiseen ja saavutamme 0,963 f1 pisteen sisällyttämällä viittauksia RoBERTa-malliin. Lopuksi näytämme, miten voimme integroida mallimme Wikipedian julkiseen infrastruktuuriin antaaksemme takaisin Wikipedian editoriyhteisölle.</abstract_fi>
      <abstract_jv>Nang Winipedya, mbok sing wis rampungan online sa akeh yclopedian, bon-voluhan yo nggawe politik sing dikarepaké mbiyen an yclopedian. politenessoffpolite"), and when there is a change ("assertive" Ere wih-wih durung, akeh gunane saiki nggawe 'puffy' seneng dadi luwih dumateng, ora mbok sing susahe seneng pisan tho. Awak dhéwé éntuk nggambar data nggawe kanggo nggawe nggawe akeh sistem iki dadi soalé sak, lan nggawe dataset kuwi nggawe aturan tambah aturan tambah lan ngawe informasi ngetik dhéwé. Awak dhéwé ngerasakno karo akeh sampeyan kanggo ngerasakno nglanggar puffi, ngono nggawe barang 0. Lha wih-wih, awak dhéwé mungkin ngerasakno akeh model nang sampeyan ingkang software publika kanggo mbatalke tarjamahan kanggo ngubah editor Winipeda.</abstract_jv>
      <abstract_sk>V Wikipediji, spletni enciklopediji množičnih virov, prostovoljci uveljavljajo uredniške politike enciklopedije. Wikipedijina politika ohranjanja nevtralnega stališča je navdihnila nedavne raziskave o odkrivanju pristranskosti, vključno z besedami podlasic in živimi mejami. Vendar je bilo do danes opravljenega malo dela pri prepoznavanju besednih zvez, ki so preveč pozitivni brez preverljivega vira. Dokazujemo, da zbiranje podatkov o usposabljanju za to nalogo zahteva nekaj previdnosti, in zgradimo nabor podatkov s kombinacijo uredniških opomb Wikipedije in tehnik pridobivanja informacij. Primerjamo več pristopov k napovedovanju puffery in dosežemo rezultat 0,963 f1 z vključitvijo značilnosti citatov v RoBERTa model. Na koncu predstavljamo, kako integrirati naš model z javno infrastrukturo Wikipedije, da se vrne skupnosti urednikov Wikipedije.</abstract_sk>
      <abstract_ha>A kan Wikiledia, an samun mutane da aka rufe ceksillopediya, mutane na lazimta musamman na aikin littafan aksiklopediya. Rukacin Wikiledia na tsare wani point na ƙayyade na gannai, ya yi amfani da research na kwanan nan a kan gannai biyar, kamar sunan 'hotel' da 'hejjes'... Babu yanzu, an aikata aiki kaɗan a kan gane 'Puffy' magana waɗanda ke da yawa masu jidar da bã da wani source mai gaskatãwa ba. Tuna nuna cewa samun data na tsarin wa wannan aikin na ƙayyade masu tsari, kuma za'a sami wani tsarin da za'a haɗa taƙaitori na Wikimedia da masu motsi. Munã samfani wasu hanyõyi dõmin ka yi bayani ga masu basĩri, kuma mu sami score 0.963 f1, da kuma za'a sami cikin shirin ayukan ayuka na RoBERTA. Gani, za mu nuna jini za mu haɗa misalinmu da rukacin na Wikimedia dõmin a mayar da shi zuwa jama'ar waharin Wikimedia.</abstract_ha>
      <abstract_he>בוויקיפדיה, אנציקלופדיה מקורשת באינטרנט, מתנדבים מאכילים את מדיניות העורכים של האנציקלופדיה. המדיניות של ויקיפדיה לשמור על נקודת מבט נוטרלית השראה מחקר לאחרונה על זיהוי ההתמחות, כולל "מילים משונות" ו"גדרים". ועדיין, מעט עבודה נעשתה על זיהוי "פאפרי", ביטויים חיוביים מדי ללא מקור אפשרי לאמת. אנו מראים שאספת נתונים אימונים למשימה הזאת דורשת טיפול מסוים, ובניית קבוצת נתונים על ידי שילוב ציונים עורך ויקיפדיה וטכניקות השיגת מידע. אנחנו משוותים כמה גישות לחזות פאפרי, ולהשיג נקודה 0.963 f1 על ידי שילוב תכונות ציטוט לדוגמא RoBERTa. סוף סוף, אנחנו מראים איך להשתלב את המודל שלנו עם התשתית הציבורית של ויקיפדיה כדי להחזיר לקהילת עורך ויקיפדיה.</abstract_he>
      <abstract_bo>དྲ་དམངས་སྤྱི་ཚོགས་པ་(Wikipedia)ནང་དུ་གླེང་སྒྲུབ་མང་པོ་ཞིག་ཡོད། སྐོར་བརྗོད་ཀྱི་ཐབས་ལམ་དུ་གཏོང་ཁང་ཀྱི་མཐོང་སྣང་གནས་སྟངས་ཀྱི་ཐབས་ལམ་གྱི་ནང་དུ་འཕྲོ་མཐུད་དུ་གཏོང་ཡོད། འོན་ཀྱང་། ད་ལྟ་བུའི་ནང་དུ་ལས་ཀ་ཆུང་ཆུང་ཞིག་བདེན་རུང་བའི་ཐོག་ཁུངས་མེད་པའི་ཚིག་རྟགས་བཀོད་སྟོན་བྱུང་། ང་ཚོས་བྱ་འགུལ་འདིའི་དོན་ལ་སླར་གསོག་ཐབས་ཀྱི་གསལ་བཤད་ཀྱི་ཡོད་པ་དེ་དག་གི་ཡིག་ཆ་སྒྲིག་ཡིག་ཆ་གསར་འཛུགས་བྱེད་ཀྱི་ཡོད། We compare several approaches to predicting puffery, and achieve 0.963 f1 score by incorporating citation (help) features into a RoBERTa model. མཐའ་མར་ང་ཚོས་Wikipedia་ཡི་སྤྱི་ཚོགས་ཆས་ཀྱི་སྒྲིག་ཆ་སྤྱི་ཚོགས་ཁང་ལ་རྟོགས་ཐབས་ལམ་སྒྲིག་བྱེད་དགོས་མིན་འདུག་</abstract_bo>
      </paper>
    <paper id="37">
      <title>Robustness and Sensitivity of BERT Models Predicting Alzheimer’s Disease from Text<fixed-case>BERT</fixed-case> Models Predicting <fixed-case>A</fixed-case>lzheimer’s Disease from Text</title>
      <author><first>Jekaterina</first><last>Novikova</last></author>
      <pages>334–339</pages>
      <abstract>Understanding robustness and <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">sensitivity</a> of BERT models predicting Alzheimer’s disease from text is important for both developing better classification models and for understanding their capabilities and limitations. In this paper, we analyze how a controlled amount of desired and undesired text alterations impacts performance of BERT. We show that BERT is robust to natural linguistic variations in text. On the other hand, we show that BERT is not sensitive to removing clinically important information from text.</abstract>
      <url hash="02c68688">2021.wnut-1.37</url>
      <bibkey>novikova-2021-robustness</bibkey>
      <doi>10.18653/v1/2021.wnut-1.37</doi>
    <title_ar>متانة وحساسية نماذج بيرت التي تتنبأ بمرض الزهايمر من النص</title_ar>
      <title_fr>Robustesse et sensibilité des modèles BERT prédisant la maladie d'Alzheimer à partir de textes</title_fr>
      <title_pt>Robustez e sensibilidade dos modelos BERT que prevêem a doença de Alzheimer a partir de texto</title_pt>
      <title_es>Robustez y sensibilidad de los modelos BERT que predicen la enfermedad de Alzheimer a partir del texto</title_es>
      <title_hi>BERT मॉडल की मजबूती और संवेदनशीलता पाठ से अल्जाइमर रोग की भविष्यवाणी</title_hi>
      <title_ja>テキストからアルツハイマー病を予測するBERTモデルの堅牢性と感度</title_ja>
      <title_zh>从文本占阿尔茨海默病BERT模鲁棒性灵敏度</title_zh>
      <title_ru>Устойчивость и чувствительность моделей БЕРТА, предсказывающих болезнь Альцгеймера из текста</title_ru>
      <title_ga>Neart agus Íogaireacht Múnlaí BERT a Thuar Galar Alzheimer ón Téacs</title_ga>
      <title_ka>BERT მოდელების სიცნობიერება და სიცნობიერება, რომელიც ტექსტიდან ალცჰეიმერის დაავადება</title_ka>
      <title_hu>Az Alzheimer-kórt megelőző BERT modellek robusztussága és érzékenysége szövegből</title_hu>
      <title_el>Ανθεκτικότητα και ευαισθησία των μοντέλων που προβλέπουν τη νόσο Αλτσχάιμερ από κείμενο</title_el>
      <title_it>Robustezza e sensibilità dei modelli BERT che predicono la malattia di Alzheimer dal testo</title_it>
      <title_kk>BERT үлгілерінің қарапайым және сезімділігі Альцхаймер ауруларының мәтінінен</title_kk>
      <title_lt>Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease from Text</title_lt>
      <title_ms>Kekuatan dan Sensitiviti Model BERT yang Menimbangkan penyakit Alzheimer dari Teks</title_ms>
      <title_mk>Сигурност и чувствителност на моделите BERT кои предвидуваат алцхајмерска болест од текст</title_mk>
      <title_ml>ബെര്‍ട്ടി മോഡലുകളുടെ റോബസ്റ്റിന്റെയും സെന്‍സിറ്റിവിറ്റി</title_ml>
      <title_mt>Is-saħħa u s-sensittività tal-mudelli BERT li jipprevedu l-marda ta’ Alzheimer mit-test</title_mt>
      <title_mn>БЕРТ загварын хүчтэй, сэтгэл хөдлөл Алцхаймер өвчнийг Текстээс илэрхийлж байна.</title_mn>
      <title_no>Gjennomsiktighet og følsomsiktighet av BERT-modeller som forventar Alzheimer-sykdommen frå teksten</title_no>
      <title_pl>Wytrzymałość i wrażliwość modeli BERT przewidujących chorobę Alzheimera z tekstu</title_pl>
      <title_ro>Robustetatea și sensibilitatea modelelor BERT care predicționează boala Alzheimer din text</title_ro>
      <title_sr>Pljačkost i osetljivost modela BERT-a predviđajući Alzheimerovu bolest iz teksta</title_sr>
      <title_so>Rugta iyo dhaqdhaqaalaha BERT Models Predicting Alzheimer's cudur text</title_so>
      <title_sv>Robusthet och känslighet hos BERT-modeller som förutspår Alzheimers sjukdom från text</title_sv>
      <title_si>BERT මොඩේල්ස් වල සංවේදනය සහ සංවේදනය අල්ජායිමර්ගේ රෝගය පෙන්වන්න පුළුවන්</title_si>
      <title_ta>Comment</title_ta>
      <title_ur>BERT موڈلز کی مضبوطی اور سنسیتی جو الزہیمر کی بیماری کو متن سے پیش کرتی ہے</title_ur>
      <title_uz>Comment</title_uz>
      <title_vi>Sự khỏe mạnh và nhạy cảm của mô- đun giao thông đoán bệnh Alzheimer's Disease from Text</title_vi>
      <title_bg>Здравина и чувствителност на моделите за предсказване на болестта на Алцхаймер от текст</title_bg>
      <title_hr>Pločnost i osjetljivost modela BERT-a predviđajući Alzheimerovu bolest iz teksta</title_hr>
      <title_da>Robusthed og følsomhed af BERT modeller, der forudsiger Alzheimers sygdom fra tekst</title_da>
      <title_nl>Robustheid en gevoeligheid van BERT-modellen die de ziekte van Alzheimer voorspellen op basis van tekst</title_nl>
      <title_de>Robustheit und Sensitivität von BERT-Modellen zur Vorhersage der Alzheimer-Krankheit aus Text</title_de>
      <title_ko>텍스트에서 알츠하이머병을 예측하는 버트 모델의 안정성과 민감성</title_ko>
      <title_fa>استعداد و احساسات مدل BERT که پیش‌بینی بیماری الزهایمر از متن دارند</title_fa>
      <title_tr>BERT Modelleriniň görkezilişi we duyarlygyny Alzheimer hasaplaryny metinden öňden gelen</title_tr>
      <title_af>Kragtigheid en Sensitiviteit van BERT Models wat Alzheimer se siekte voorskou van teks</title_af>
      <title_am>የኤልዚሜር ደዌ ከጽሑፍ ማቀናቀል የBERT ሞዴል ስህተት እና ስህተት</title_am>
      <title_id>Kekuatan dan Sensitivitas Model BERT yang memprediksi penyakit Alzheimer dari Teks</title_id>
      <title_az>Alzheimer'in x…ôst…ôliyini Metind…ôn t…ôsdiql…ôy…ôn BERT Modell…ôrinin s …ôrtlik v…ô duyarlńĪńüńĪ</title_az>
      <title_sw>Utafiti na Uhisia wa Modeli wa BERT wakikabiliana na ugonjwa wa Alzheimer kutoka kwa Matambo</title_sw>
      <title_bn>টেক্সট থেকে আলজহেমারের রোগের স্বীকার করে বেরেট মোডেলের ব্যবস্থা এবং সংবেদনশীলতা</title_bn>
      <title_bs>Pljačkost i osjetljivost modela BERT-a predviđajući Alzheimerovu bolest iz teksta</title_bs>
      <title_ca>La robustet i la sensibilitat dels models BERT que predien la malaltia d'Alzheimer pel text</title_ca>
      <title_sq>Rroftësia dhe ndjeshmëria e modeleve BERT që parashikojnë s ëmundjen e Alzheimerit nga teksti</title_sq>
      <title_fi>Alzheimerin tautia ennustavien BERT-mallien kestävyys ja herkkyys tekstistä</title_fi>
      <title_hy>ԲԵՌԹ մոդելների ուժեղությունը և զգացմունքը, որոնք ենթարկում են Ալցհեյմերի հիվանդությունը տեքստից</title_hy>
      <title_cs>Robustnost a citlivost modelů BERT predikce Alzheimerovy choroby z textu</title_cs>
      <title_et>BERT mudelite tugevus ja tundlikkus Alzheimeri tõve ennustamiseks tekstist</title_et>
      <title_jv>Rusahan lan Sensitiv sing model BERT Daerah Aldhejer's layang Teks</title_jv>
      <title_he>Robustness and Sensitivity of BERT Models Predicting Alzheimer's Disease from Text</title_he>
      <title_ha>QShortcut</title_ha>
      <title_sk>Robustnost in občutljivost BERT modelov za napovedovanje Alzheimerjeve bolezni iz besedila</title_sk>
      <title_bo>BERT མ་དབྱིབས་གྱི་སྣང་ཚུལ་དང་བློ་གཏོང་རྣམ་པ།</title_bo>
      <abstract_fr>Comprendre la robustesse et la sensibilité des modèles BERT prédisant la maladie d'Alzheimer à partir de textes est important à la fois pour développer de meilleurs modèles de classification et pour comprendre leurs capacités et leurs limites. Dans cet article, nous analysons l'impact d'une quantité contrôlée de modifications de texte souhaitées et indésirables sur les performances du BERT. Nous montrons que le BERT est robuste face aux variations linguistiques naturelles du texte. D'autre part, nous montrons que le BERT n'est pas sensible à la suppression d'informations cliniquement importantes du texte.</abstract_fr>
      <abstract_ar>يعد فهم متانة وحساسية نماذج BERT التي تتنبأ بمرض الزهايمر من النص أمرًا مهمًا لتطوير نماذج تصنيف أفضل وفهم قدراتها وقيودها. في هذه الورقة ، نقوم بتحليل كيفية تأثير المقدار المتحكم فيه من التعديلات النصية المرغوبة وغير المرغوب فيها على أداء BERT. نظهر أن BERT قوي في التعامل مع الاختلافات اللغوية الطبيعية في النص. من ناحية أخرى ، نظهر أن BERT ليس حساسًا لإزالة المعلومات المهمة سريريًا من النص.</abstract_ar>
      <abstract_es>Comprender la solidez y la sensibilidad de los modelos BERT que predicen la enfermedad de Alzheimer a partir del texto es importante tanto para desarrollar mejores modelos de clasificación como para comprender sus capacidades y limitaciones. En este artículo, analizamos cómo una cantidad controlada de alteraciones de texto deseadas y no deseadas afecta el rendimiento de BERT. Demostramos que BERT es resistente a las variaciones lingüísticas naturales en el texto. Por otro lado, demostramos que BERT no es sensible a eliminar información clínicamente importante del texto.</abstract_es>
      <abstract_pt>Compreender a robustez e a sensibilidade dos modelos BERT que predizem a doença de Alzheimer a partir de texto é importante tanto para desenvolver melhores modelos de classificação quanto para entender suas capacidades e limitações. Neste artigo, analisamos como uma quantidade controlada de alterações de texto desejadas e indesejadas afeta o desempenho do BERT. Mostramos que o BERT é robusto a variações linguísticas naturais no texto. Por outro lado, mostramos que o BERT não é sensível à remoção de informações clinicamente importantes do texto.</abstract_pt>
      <abstract_ja>テキストからアルツハイマー病を予測するBERTモデルの堅牢性と感度を理解することは、より良い分類モデルを開発するためにも、それらの能力と制限を理解するためにも重要です。本論文では、所望および所望でないテキストの変更の制御された量が、BERTの性能にどのように影響するかを分析する。私たちは、BERTがテキストの自然な言語的変動に対して堅牢であることを示しています。一方、BERTは、テキストから臨床的に重要な情報を削除することに敏感ではないことを示しています。</abstract_ja>
      <abstract_zh>知从文本阿尔茨海默病之BERT,鲁棒性敏感性之善,知局限性之要。 于本文之中,论受控数之所需,与不欲之文,更BERT性能。 吾证BERT文本之自然语言化为健也。 又明BERT删临床重信不敏。</abstract_zh>
      <abstract_hi>पाठ से अल्जाइमर रोग की भविष्यवाणी करने वाले BERT मॉडल की मजबूती और संवेदनशीलता को समझना बेहतर वर्गीकरण मॉडल विकसित करने और उनकी क्षमताओं और सीमाओं को समझने के लिए दोनों के लिए महत्वपूर्ण है। इस पेपर में, हम विश्लेषण करते हैं कि वांछित और अवांछित पाठ परिवर्तनों की एक नियंत्रित मात्रा BERT के प्रदर्शन को कैसे प्रभावित करती है। हम दिखाते हैं कि BERT पाठ में प्राकृतिक भाषाई विविधताओं के लिए मजबूत है। दूसरी ओर, हम दिखाते हैं कि BERT पाठ से नैदानिक रूप से महत्वपूर्ण जानकारी को हटाने के प्रति संवेदनशील नहीं है।</abstract_hi>
      <abstract_ru>Понимание устойчивости и чувствительности моделей BERT, предсказывающих болезнь Альцгеймера из текста, важно как для разработки лучших классификационных моделей, так и для понимания их возможностей и ограничений. В этой статье мы анализируем, как контролируемое количество желаемых и нежелательных изменений текста влияет на производительность БЕРТА. Мы показываем, что БЕРТ устойчив к естественным языковым вариациям в тексте. С другой стороны, мы показываем, что БЕРТ не чувствителен к удалению клинически важной информации из текста.</abstract_ru>
      <abstract_ga>Tá sé tábhachtach stóinseacht agus íogaireacht mhúnlaí CRET a thuar ó théacs le galar Alzheimer a thuiscint chun samhlacha aicmithe níos fearr a fhorbairt agus chun a gcumas agus a dteorainneacha a thuiscint. Sa pháipéar seo, déanaimid anailís ar an gcaoi a mbíonn tionchar ag méid rialaithe athruithe téacs inmhianaithe agus neamh-inmhianaithe ar fheidhmíocht CRET. Léirímid go bhfuil BET láidir i leith éagsúlachtaí nádúrtha teangeolaíochta sa téacs. Ar an láimh eile, léirímid nach bhfuil BERT íogair maidir le faisnéis atá tábhachtach go cliniciúil a bhaint de théacs.</abstract_ga>
      <abstract_ka>BERT მოდელების ძალიან ძალიან და სიგრძნობით, რომლებიც ტექსტიდან ალცჰეიმერის დაავადებას წინასწარმოდგინეთ, უფრო მნიშვნელოვანია ორივე უფრო კლასიფიკაციის მოდელების განვითარე ამ დომენტში ვაანალიზებთ როგორ კონტროლურად მოთხოვრებული და არ მოთხოვრებული ტექსტის ცვლილებების შესაძლებლობას BERT-ის გამოყენება. ჩვენ ჩვენ აჩვენებთ, რომ BERT არის ძალიან ტექსტის ნაირადი ლენგურისტიკური გარიაციებისთვის. მეორე მხარეს, ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ BERT არ უნდა კლინიკურად მნიშვნელოვანი ინფორმაციას ტექსტიდან წაშლა.</abstract_ka>
      <abstract_hu>Az Alzheimer-kórt előrejelző BERT modellek robusztusságának és érzékenységének szövegből történő megértése fontos mind a jobb osztályozási modellek kidolgozásához, mind a képességeik és korlátaik megértéséhez. Ebben a tanulmányban elemezzük, hogy a kívánt és nem kívánt szövegmódosítások mennyisége hogyan befolyásolja a BERT teljesítményét. Megmutatjuk, hogy a BERT erőteljes a szöveg természetes nyelvi változataival szemben. Másrészt megmutatjuk, hogy a BERT nem érzékeny a klinikailag fontos információk eltávolítására a szövegből.</abstract_hu>
      <abstract_el>Η κατανόηση της ανθεκτικότητας και της ευαισθησίας των μοντέλων που προβλέπουν τη νόσο Αλτσχάιμερ από το κείμενο είναι σημαντική τόσο για την ανάπτυξη καλύτερων μοντέλων ταξινόμησης όσο και για την κατανόηση των δυνατοτήτων και των περιορισμών τους. Σε αυτή την εργασία, αναλύουμε πώς μια ελεγχόμενη ποσότητα επιθυμητών και ανεπιθύμητων αλλαγών κειμένου επηρεάζει την απόδοση του BERT. Δείχνουμε ότι το BERT είναι ανθεκτικό στις φυσικές γλωσσικές παραλλαγές του κειμένου. Από την άλλη πλευρά, αποδεικνύουμε ότι ο BERT δεν είναι ευαίσθητος στην αφαίρεση κλινικά σημαντικών πληροφοριών από το κείμενο.</abstract_el>
      <abstract_it>Comprendere la robustezza e la sensibilità dei modelli BERT che predicono il morbo di Alzheimer dal testo è importante sia per sviluppare modelli di classificazione migliori che per comprenderne le capacità e i limiti. In questo articolo analizziamo come una quantità controllata di modifiche di testo desiderate e indesiderate influisca sulle prestazioni di BERT. Mostriamo che BERT è robusto alle variazioni linguistiche naturali del testo. D'altra parte, dimostriamo che BERT non è sensibile alla rimozione di informazioni clinicamente importanti dal testo.</abstract_it>
      <abstract_lt>Understanding robustness and sensitivity of BERT models predicting Alzheimer's disease from text is important for both developing better classification models and for understanding their capabilities and limitations.  Šiame dokumente analizuojame, kaip kontroliuojamas pageidaujamų ir nepageidaujamų teksto pakeitimų kiekis daro poveikį BERT veiklos rezultatams. Mes rodome, kad BERT tvirtai vertina teksto kalbų skirtumus. Kita vertus, mes rodome, kad BERT nėra jautrus pašalinti kliniškai svarbią informaciją iš teksto.</abstract_lt>
      <abstract_mk>Разбирањето на силноста и чувствителноста на моделите на БЕРТ кои предвидуваат болест на Алцхајмер од текстот е важно за развојот на подобри модели за класификација и за разбирање на нивните способности и ограничувања. In this paper, we analyze how a controlled amount of desired and undesired text alterations impacts performance of BERT.  We show that BERT is robust to natural linguistic variations in text.  Од друга страна, покажуваме дека БЕРТ не е чувствителен на отстранувањето клинички важни информации од текстот.</abstract_mk>
      <abstract_kk>Альцхаймердің ауруларын мәтіннен таңдау үшін BERT үлгілерінің дұрыс және сезімділігін түсіну - жақсы классификациялық үлгілерін жасау үшін және олардың мүмкіндіктерін және шекте Бұл қағазда біз қалаған және қалаған мәтін өзгерістерінің BERT әрекетінің нәтижесін қалай бақылау керектігін анықтап көрдік. Біз BERT мәтіндегі лингвистикалық айырмашыларына құнды деп көрсетедік. Біріншіден, BERT мәтіннен клиникалық маңызды мәліметті өшіруге сезім бермейді.</abstract_kk>
      <abstract_ml>ബെര്‍ട്ടി മോഡലുകളുടെ ബ്രോസ്റ്റിന്‍റെ രോഗവും മനസ്സിലാക്കുന്നത് അല്‍സ്ഹീമെരിന്‍റെ രോഗവും പദാവലിയില്‍ നിന്നും മെച്ചപ്പെടുത്തുന്നത് ഗ ഈ പത്രത്തില്‍, നിയന്ത്രിക്കപ്പെട്ട എണ്ണം നിയന്ത്രിക്കപ്പെട്ടിരിക്കുന്നു എങ്ങനെയെന്നും ബെര്‍ട്ടിന്‍റെ പ്രകട നമ്മള്‍ കാണിക്കുന്നത് ബെര്‍ട്ടി സ്വാഭാവികമായ ഭാഷ വ്യത്യാസങ്ങളിലേക്കാണെന്നാണ്. മറുവശത്ത് നാം കാണിക്കുന്നത് ബെര്‍ട്ടി വാചകത്തില്‍ നിന്ന് പ്രധാനപ്പെട്ട വിവരങ്ങള്‍ നീക്കം ചെയ്യാന്‍ സ</abstract_ml>
      <abstract_ms>Memahami ketepatan dan sensitiviti model BERT yang meramalkan penyakit Alzheimer dari teks adalah penting untuk mengembangkan model kelasukan yang lebih baik dan untuk memahami kemampuan dan keterangan mereka. Dalam kertas ini, kami menganalisis bagaimana jumlah kawal perubahan teks yang diinginkan dan tidak diinginkan mempengaruhi prestasi BERT. Kami menunjukkan bahawa BERT adalah kuat kepada variasi bahasa semulajadi dalam teks. Di sisi lain, kami menunjukkan bahawa BERT tidak sensitif untuk menghapuskan maklumat penting klinik dari teks.</abstract_ms>
      <abstract_mn>БЕРТ загварын хүчтэй, мэдрэмжтэй байдлыг ойлгох нь Альцхаймер өвчнийг текстээс таамаглах нь хамгийн чухал юм. Энэ цаасан дээр бид хэрхэн хяналттай хүсэлтэй, хүсэлтэй бичиг өөрчлөлт нь BERT-ын үйл ажиллагаанд нөлөөлдөг талаар шинжилгээ хийдэг. Бид БЕРТ-г байгалийн хэлний өөрчлөлтийг харуулж байна. Нөгөө талаар, бид БЕРТ-г текстээс эмнэлгийн чухал мэдээллийг устгахад чухал биш гэдгийг харуулж байна.</abstract_mn>
      <abstract_no>For å forstå kraftighet og følsomhet av BERT-modeller som foregår Alzheimer-sykdommen frå teksten er viktig for både utvikla bedre klassifikasjonsmodular og for å forstå dei kapasitetene og grensene. I denne papiret analyserer vi korleis ein kontrollert mengd av ønskte og undesirerte tekstendringar påvirkar BERT. Vi viser at BERT er sterkt til naturlige lingviske variasjonar i tekst. On the other hand, we show that BERT is not sensitive to removing clinically important information from text.</abstract_no>
      <abstract_mt>Il-fehim tar-robustezza u s-sensittività tal-mudelli BERT li jipprevedu l-marda ta’ Alzheimer mit-test huwa importanti kemm għall-iżvilupp ta’ mudelli ta’ klassifikazzjoni aħjar kif ukoll għall-fehim tal-kapaċitajiet u l-limitazzjonijiet tagħhom. F’dan id-dokument, nagħmlu analiżi ta’ kif ammont ikkontrollat ta’ tibdiliet fit-test mixtieqa u mhux mixtieqa jaffettwa l-prestazzjoni tal-BERT. Aħna nuru li l-BERT huwa robust għal varjazzjonijiet lingwistiċi naturali fit-test. Min-naħa l-oħra, nuru li l-BERT mhuwiex sensittiv għat-tneħħija ta’ informazzjoni klinikament importanti mit-test.</abstract_mt>
      <abstract_pl>Zrozumienie solidności i wrażliwości modeli BERT przewidujących chorobę Alzheimera na podstawie tekstu jest ważne zarówno dla opracowywania lepszych modeli klasyfikacji, jak i dla zrozumienia ich możliwości i ograniczeń. W niniejszym artykule analizujemy, w jaki sposób kontrolowana ilość pożądanych i niepożądanych zmian tekstowych wpływa na wydajność BERT. Pokazujemy, że BERT jest solidny na naturalne warianty językowe w tekście. Z drugiej strony pokazujemy, że BERT nie jest wrażliwy na usuwanie istotnych klinicznie informacji z tekstu.</abstract_pl>
      <abstract_sr>Razumevanje robotnosti i osjetljivosti modela BERT-a koji predviđaju Alzheimerovu bolest iz teksta je važno za razvoj boljih modela klasifikacije i za razumevanje njihovih sposobnosti i ograničenja. U ovom papiru analiziramo kako kontrolirana količina željnih i neočekivanih promjena teksta utječe na učinku BERT-a. Pokazujemo da je BERT jačan prirodnim jezičkim varijacijama teksta. S druge strane, pokazujemo da BERT nije osjetljiv prema uklanjanju klinički važnih informacija iz teksta.</abstract_sr>
      <abstract_ro>Înțelegerea robusteții și sensibilității modelelor BERT care prezic boala Alzheimer din text este importantă atât pentru dezvoltarea unor modele mai bune de clasificare, cât și pentru înțelegerea capacităților și limitărilor acestora. În această lucrare, analizăm modul în care o cantitate controlată de modificări de text dorite și nedorite influențează performanța BERT. Arătăm că BERT este robust la variațiile lingvistice naturale ale textului. Pe de altă parte, arătăm că BERT nu este sensibil la eliminarea informațiilor importante din punct de vedere clinic din text.</abstract_ro>
      <abstract_si>BERT මොඩේල්ස් වලින් සාධාරණය සහ සංවේදනය තේරුම් ගන්න අල්ජායිමර්ගේ රෝගය පාළුවන් පෙළුවන් ඉන්න ප්‍රශ්නයක් වැඩි වෙන් මේ පත්තරේ අපි විශ්ලේෂණය කරනවා කොහොමද කියලා බලන්න අවශ්‍ය සහ අවශ්‍ය වෙනස් කරන්නේ පත්තර පරීක්ෂණය BERT ගේ ප්‍ අපි පෙන්වන්නේ BERT ස්වභාවික භාෂාවික වෙනස් වලට සාමාන්‍යයි. අනිත් පැත්තෙන්, අපි පෙන්වන්නේ BERT එක පෙන්වන්නේ පැත්තෙන් ප්‍රශ්නය වැදගත් තොරතුරු නැති කියලා.</abstract_si>
      <abstract_so>Waxgarashada qalabka BERT waxyaabaha la arko cudurka Alzheimer ee qoraalka waxaa muhiim u ah inuu horumariyo qaababka fasaxda iyo garashada awooddooda iyo xadarradooda. Qoraalkan waxaynu baaraynaa sida ay u saameyn karto beddelaadka qoraalka ee la xiriiray iyo si aan la aqoon karin ay ku saameyn karto sameynta BERT. Waxaynu muujinnaa in BERT lagu tuuro isbedelka afka dabiiciga ah ee qoraalka. Hada kale waxaynu muujinnaa in BERT uusan xil u ahayn in laga qaado macluumaadka muhiimka ah ee dhakhtarka.</abstract_so>
      <abstract_sv>Att förstå robusthet och känslighet hos BERT-modeller som förutspår Alzheimers sjukdom från text är viktigt både för att utveckla bättre klassificeringsmodeller och för att förstå deras kapacitet och begränsningar. I denna uppsats analyserar vi hur en kontrollerad mängd önskade och oönskade textändringar påverkar BERT:s prestanda. Vi visar att BERT är robust mot naturliga språkliga variationer i text. Å andra sidan visar vi att BERT inte är känslig för att ta bort kliniskt viktig information från text.</abstract_sv>
      <abstract_ta>பிரெட்டி மாதிரிகளின் தொழிலும் உணர்வும் புரிந்து அல்சைமரின் நோயை உரையிலிருந்து முன்விரும்புகிறது சிறந்த வகுப்பு மாதிரிகளை உருவா இந்த காகிதத்தில், நாம் எவ்வாறு கட்டுப்படுத்தப்பட்ட தேவைப்படுத்தப்பட்ட அளவு மற்றும் தீர்க்கப்படாத உரை மாற்றங்கள் BER BERT என்பதை உரையில் இயற்கையான மொழி மாறுபாடுகளுக்கு நாம் காட்டுகிறோம். மற்ற பக்கத்தில், BERT உரையிலிருந்து சிகிச்சைக்கு முக்கியமான தகவலை நீக்குவதற்கு உணர்வு இல்லை என்று நாம் கா</abstract_ta>
      <abstract_ur>BERT موڈل کے مطابق مضبوطی اور احساساتی کا سمجھنا، جو Alzheimer کے بیماری کو متن سے پیش بینی کرتی ہے، ان دونوں کے لئے بہتر کلاسیک موڈل اور ان کے قابلیت اور حدود سمجھنے کے لئے اہم ہے. اس کاغذ میں ہم تحقیق کرتے ہیں کہ کس طرح ایک کاغذ کا کنٹرول کیا گیا اور ناپسندیدہ پیغام بدلنے کے باعث BERT کے عمل کا تأثیر کرتا ہے۔ ہم دکھاتے ہیں کہ BERT پیغام میں طبیعی زبان اختلاف کے لئے مضبوط ہے۔ دوسری طرف، ہم دکھاتے ہیں کہ BERT ٹیکسٹ سے کلینیکی اہم معلومات کو ہٹانے کے لئے حساس نہیں ہے.</abstract_ur>
      <abstract_vi>Hiểu được s ức mạnh và độ nhạy của các mô hình thiếu sót sót của thiếu sót sót sót sót. Để dự đoán bệnh Alzheimer khỏi chữ viết là quan trọng cho cả việc phát triển các mô hình phân loại tốt hơn và để hiểu khả năng và giới hạn của nó. Trong tờ giấy này, chúng tôi phân tích cách những thay đổi văn bản được kiểm soát tác động đến hiệu suất của BERT. Chúng tôi cho thấy BERT kiên cường với ngôn ngữ tự nhiên trong văn bản. Tuy nhiên, chúng tôi cho thấy rằng BERT không nhạy cảm khi loại bỏ thông tin về mặt lâm sàng quan trọng khỏi văn bản.</abstract_vi>
      <abstract_uz>Alzheimer kasalligini o'rganish uchun BERT modellarini tasavvur qilish mumkin, matnning kasalligini tasavvur qilish mumkin. Ularning yaxshi darajalashtirish modellarini yaratish va ularning qobiliyatlarini va chegaralarini tushunish uchun muhim. Bu qogʻozda, biz qanday boshqarilgan qanday boshqaruv soni va undan o'zgarishlar BERT bajarishni bajaradi. Biz BERT'ni matnning tabiiy tillarda o'zgarishga ko'rsatishimiz mumkin. Boshqa tomonda biz BERT matnning muhim maʼlumotni olib tashlash juda qiziqarli emas.</abstract_uz>
      <abstract_hr>Razumijevanje robotnosti i osjetljivosti modela BERT-a koji predviđaju Alzheimerovu bolest iz teksta je važno za razvoj boljih modela klasifikacije i za razumijevanje njihovih sposobnosti i ograničenja. U ovom papiru analiziramo kako kontrolirana količina željnih i neočekivanih promjena teksta utječe na učinku BERT-a. Pokazujemo da je BERT jačan prirodnim jezičkim varijacijama teksta. S druge strane, pokazujemo da BERT nije osjetljiv prema uklanjanju klinički važnih informacija iz teksta.</abstract_hr>
      <abstract_nl>Het begrijpen van de robuustheid en gevoeligheid van BERT-modellen die de ziekte van Alzheimer voorspellen op basis van tekst is belangrijk voor zowel het ontwikkelen van betere classificatiemodellen als voor het begrijpen van hun mogelijkheden en beperkingen. In dit artikel analyseren we hoe een gecontroleerde hoeveelheid gewenste en ongewenste tekstwijzigingen de prestaties van BERT beïnvloedt. We laten zien dat BERT robuust is tegen natuurlijke taalvariaties in tekst. Aan de andere kant laten we zien dat BERT niet gevoelig is voor het verwijderen van klinisch belangrijke informatie uit tekst.</abstract_nl>
      <abstract_da>Det er vigtigt at forstå robustheden og følsomheden af BERT-modeller, der forudsiger Alzheimers sygdom fra tekst, både for at udvikle bedre klassifikationsmodeller og for at forstå deres evner og begrænsninger. I denne artikel analyserer vi, hvordan en kontrolleret mængde ønskede og uønskede tekstændringer påvirker BERT's ydeevne. Vi viser, at BERT er robust over for naturlige sproglige variationer i tekst. På den anden side viser vi, at BERT ikke er følsom over for at fjerne klinisk vigtige oplysninger fra teksten.</abstract_da>
      <abstract_de>Das Verständnis der Robustheit und Sensitivität von BERT-Modellen zur Vorhersage der Alzheimer-Krankheit anhand von Texten ist sowohl für die Entwicklung besserer Klassifikationsmodelle als auch für das Verständnis ihrer Fähigkeiten und Grenzen wichtig. In diesem Beitrag analysieren wir, wie sich eine kontrollierte Menge an gewünschten und unerwünschten Textänderungen auf die Leistung von BERT auswirkt. Wir zeigen, dass BERT robust gegenüber natürlichen sprachlichen Variationen im Text ist. Auf der anderen Seite zeigen wir, dass BERT nicht empfindlich ist, klinisch wichtige Informationen aus Texten zu entfernen.</abstract_de>
      <abstract_id>Memahami kekuatan dan sensitivitas model BERT yang memprediksi penyakit Alzheimer dari teks adalah penting untuk mengembangkan model klasifikasi yang lebih baik dan untuk memahami kemampuan dan batasan mereka. In this paper, we analyze how a controlled amount of desired and undesired text alterations impacts performance of BERT.  Kami menunjukkan bahwa BERT kuat untuk variasi bahasa alam dalam teks. Di sisi lain, kami menunjukkan bahwa BERT tidak sensitif untuk menghapus informasi klinik penting dari teks.</abstract_id>
      <abstract_ko>텍스트에서 알츠하이머병을 예측하는 버트 모델의 안정성과 민감성을 이해하는 것은 더 좋은 분류 모델을 개발하고 그 능력과 한계를 이해하는 데 매우 중요하다.본고에서 우리는 제어된 수량의 기대와 기대하지 않는 텍스트 변경이 BERT의 성능에 어떻게 영향을 미치는지 분석했다.우리는 텍스트의 자연 언어 변화에 대한 BERT의 노봉성을 증명했다.다른 한편, BERT는 임상에서 중요한 정보를 텍스트에서 삭제하는 데 민감하지 않다는 것을 발견했다.</abstract_ko>
      <abstract_sw>Kuelewa uvumi na ufahamu wa mifano ya BERT kutabiri ugonjwa wa Alzheimer kutoka kwa ujumbe wa maandishi ni muhimu kwa ajili ya kuelewa uwezo wao na mipaka yao. Katika karatasi hii, tunachambua jinsi kiasi cha udhibiti unavyotaka na mabadiliko yasiyoeleweka yanaathiri utendaji wa BERT. Tunaonyesha kwamba BERT imevurugwa kwenye mabadiliko ya lugha asilia kwa maandishi. Kwa upande mwingine, tunaonyesha kuwa BERT haina uelewa wa kuondoa taarifa muhimu za kliniki kutoka kwa maandishi.</abstract_sw>
      <abstract_fa>درک استعداد و احساسات مدل BERT که پیش بینی بیماری الزهیمر از متن دارد برای توسعه مدل‌های classification بهتر و برای درک توانایی و محدودیت‌هایشان مهم است. در این کاغذ، ما تحلیل می کنیم که چگونه یک مقدار کنترل از تغییرات متن خواسته و ناخواسته اثر فعالیت BERT را تأثیر می دهد. ما نشان می دهیم که BERT به تغییرات زبان طبیعی در متن قوی است. از طرف دیگر، نشان می دهیم که BERT احساساتی برای حذف اطلاعات کلینیک مهم از متن نیست.</abstract_fa>
      <abstract_tr>BERT modelleriniň ukyplygyny we hasyslygyny düşünmek Alzheimeriň hastalanynyň metinden geçirmegi hem gowy klasifikasyon modellerini geliştirmek we olaryň ukyplaryny we çärelerini düşünmek üçin wajypdyr. Bu kagyzda, biz bejerilip islän we niýetlenmän metin üýtgewleriniň BERT'yň eserini nähili etjekdigini çözümleýäris. BERT'iň tebigy dil üýtgewleriniň metinde ukypdygyny görkezýäris. Diňe tarapyndan, BERT'yň tekstden klinikiýa wajyp maglumatlary çykarmagyna hasaplamaýandygyny görkeýäs.</abstract_tr>
      <abstract_sq>Përkuptimi i fuqisë dhe ndjeshmërisë s ë modeleve BERT që parashikojnë sëmundjen e Alzheimerit nga teksti është i rëndësishëm si për zhvillimin e modeleve më të mirë klasifikimi, ashtu edhe për kuptimin e aftësive dhe kufizimeve të tyre. Në këtë letër, ne analizojmë se si një sasi e kontrolluar e ndryshimeve të dëshiruara dhe të padëshiruara të tekstit ndikon në performancën e BERT. We show that BERT is robust to natural linguistic variations in text.  Nga ana tjetër, ne tregojmë se BERT nuk është i ndjeshëm për heqjen e informacionit klinikisht të rëndësishëm nga teksti.</abstract_sq>
      <abstract_am>የBERT ዓይነቶች ድምፅ ከጽሑፍ ለመቀበል እና ማስተዋል የሚሻለውን የመለያየት ዓይነቶች እና ኃይላቸውን እና ግንኙነታቸውን ለማስተዋል ያስፈልጋል፡፡ በዚህ ካላት፣ የሥልጣን ብዛት የጽሑፍ ለውጦች BERT ውጤት እንዴት እንደሚያሳየው እናስተምር፡፡ BERT በጽሑፍ ውስጥ የፍጥረታዊ ቋንቋዊ ለውጥ እንደሆነ እናሳየዋለን፡፡ በሌላው ክፍል BERT ከጽሑፍ የተጠቃሚ መረጃ ለማስወግድ ማሳየት እንደሆነ እናሳየዋለን፡፡</abstract_am>
      <abstract_bg>Разбирането на здравината и чувствителността на моделите за прогнозиране на болестта на Алцхаймер от текст е важно както за разработването на по-добри модели за класификация, така и за разбирането на техните възможности и ограничения. В настоящата статия анализираме как контролирано количество желани и нежелани текстови промени влияе върху изпълнението на БРТ. Показваме, че е здрав към естествените лингвистични вариации в текста. От друга страна, ние показваме, че BERT не е чувствителна към премахването на клинично важна информация от текста.</abstract_bg>
      <abstract_hy>Understanding robustness and sensitivity of BERT models predicting Alzheimer's disease from text is important for both developing better classification models and for understanding their capabilities and limitations.  Այս թղթի մեջ մենք վերլուծում ենք, թե ինչպես ցանկացած և անցանկացած տեքստի փոփոխությունների կառավարվող քանակը ազդում է BER-ի արդյունքի վրա: Մենք ցույց ենք տալիս, որ BER-ն ուժեղ է տեքստի բնական լեզվաբանական տարբերություններին: Մյուս կողմից, մենք ցույց ենք տալիս, որ BER-ը զգայուն չէ կլինիկապես կարևոր տեղեկությունը տեքստից հեռացնելու համար:</abstract_hy>
      <abstract_af>Die verstaan van kragtigheid en sensitiviteit van BERT modele wat Alzheimer se siekte van teks voorskou is, is belangrik vir beide beter klasifikasie modele te ontwikkel en vir verstaan hul kapasiteite en beperkings. In hierdie papier, ons analiseer hoe 'n kontroleerde hoeveelheid van gewens en onversoekte teks veranderinge uitwerk van BERT. Ons wys dat BERT kragtig is tot natuurlike lingwisiese veranderinge in teks. Op die ander kant wys ons dat BERT nie sensitief is om kliniese belangrike inligting van teks te verwyder nie.</abstract_af>
      <abstract_bs>Razumijevanje robotnosti i osjetljivosti modela BERT-a koji predviđaju Alcheimerovu bolest iz teksta je važno za razvoj boljih modela klasifikacije i za razumijevanje njihovih sposobnosti i ograničenja. U ovom papiru analiziramo kako kontrolirana količina željnih i neočekivanih promjena teksta utječe na učinku BERT-a. Pokazujemo da je BERT jačan prirodnim jezičkim varijacijama teksta. S druge strane, pokazujemo da BERT nije osjetljiv prema uklanjanju klinički važnih informacija iz teksta.</abstract_bs>
      <abstract_ca>Entendre la robustet i la sensibilitat dels models BERT que predien la malaltia d'Alzheimer pel text és important tant per desenvolupar millors models de classificació com per entendre les seves capacitats i limitacions. En aquest paper, analitzem com una quantitat controlada de canvis de text desitjats i no desitjats afecta el rendiment del BERT. We show that BERT is robust to natural linguistic variations in text.  D'altra banda, demostram que BERT no és sensible a eliminar informació clínicament important del text.</abstract_ca>
      <abstract_cs>Pochopení robustnosti a citlivosti BERT modelů předpovídajících Alzheimerovu chorobu z textu je důležité jak pro vývoj lepších klasifikačních modelů, tak pro pochopení jejich schopností a omezení. V tomto článku analyzujeme, jak kontrolované množství požadovaných a nežádoucích změn textu ovlivňuje výkon BERT. Ukazujeme, že BERT je robustní vůči přirozeným jazykovým variacím textu. Na druhou stranu ukazujeme, že BERT není citlivý na odstraňování klinicky důležitých informací z textu.</abstract_cs>
      <abstract_et>Alzheimeri tõve prognoosivate BERT mudelite tugevuse ja tundlikkuse mõistmine tekstist on oluline nii paremate klassifitseerimismudelite väljatöötamiseks kui ka nende võimekuse ja piirangute mõistmiseks. Käesolevas töös analüüsime, kuidas kontrollitud hulk soovitud ja soovimatuid tekstimuudatusi mõjutab BERT jõudlust. Näitame, et BERT on tugev loomulike keeleliste variatsioonide suhtes tekstis. Teisest küljest näitame, et BERT ei ole tundlik kliiniliselt olulise teabe eemaldamise suhtes tekstist.</abstract_et>
      <abstract_fi>Alzheimerin tautia ennustavien BERT-mallien kestävyyden ja herkkyyden ymmärtäminen tekstistä on tärkeää sekä parempien luokitusmallien kehittämiseksi että niiden valmiuksien ja rajoitusten ymmärtämiseksi. Tässä artikkelissa analysoidaan, miten kontrolloitu määrä toivottuja ja ei-toivottuja tekstimuutoksia vaikuttaa BERT:n suorituskykyyn. Osoitamme BERT:n tukevan tekstin luonnollista kielellistä vaihtelua. Toisaalta osoitamme, että BERT ei ole herkkä poistamaan tekstistä kliinisesti tärkeitä tietoja.</abstract_fi>
      <abstract_az>Alzheimer hastalığını metindən təmin edən BERT modellerinin güclülüyünü və duyarlığını anlamaq hər ikisinin daha yaxşı klasifikasiya modellərini və onların yetkinliklərini və s ınırlarını anlamaq üçün vacibdir. Bu kağızda, istənilən və istənilməyən mətn dəyişikliklərinin BERT performansını necə etkisini çəkdiyini analiz edirik. Belə göstəririk ki, BERT təbiətli dil dəyişikliklərinə möhkəmdir. Digər tərəfindən, BERT mətndən kliniki möhüm məlumatları silməyə məcburiyyətli deyildir.</abstract_az>
      <abstract_bn>বেরেটি মডেলের রোগের ধারণা এবং সুবিধা বুঝতে পারে যে টেক্সট থেকে আলজেমারের রোগের ভবিষ্যদ্বাণী করা হয়েছে তা উভয়ের জন্য গুরুত্বপূর্ণ, য এই কাগজটিতে আমরা বিশ্লেষণ করি কিভাবে নিয়ন্ত্রণের পরিমাণ চালানো এবং অচিরেই লেখা পরিবর্তন বিবেরেটের প্রভাব ফেলে। আমরা দেখাচ্ছি যে বেরেট টি প্রাকৃতিক ভাষার ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্নের কাছ অন্যদিকে, আমরা দেখাচ্ছি যে বেরেট টি টেক্সট থেকে গুরুত্বপূর্ণ তথ্য সরিয়ে নেওয়ার জন্য সুবিধাজনক নয়।</abstract_bn>
      <abstract_he>להבין את החזקה והרגישות של דוגמנים BERT שחזויים את מחלת אלצהיימר מהטקסט חשוב גם לפיתוח דוגמנים מסווגים טובים יותר ולהבן את היכולות והגבלות שלהם. בעיתון הזה, אנו מנתחים כיצד כמות שליטה של שינויים טקסטים רצויים ולא רצויים משפיעים על ביצועים של BERT. אנו מראים שברט חזק לשינויים שפתיים טבעיים בטקסט. מצד שני, אנחנו מראים כי BERT הוא לא רגיש להסירה מידע חשוב קלינית מהטקסט.</abstract_he>
      <abstract_ha>An fahimta ustawi da saniya na misãlai na BERT na yi bayani ga aikin Alzheimar daga matsayin, yana da muhimu a danne misãlai masu ƙaranci da kuma ana fahimta abincinsu da sararin su. In a cikin wannan takardan, Munã yi anayya a kan jinsi da aka lissafa ma'aunin marubuci da ba'a samu da musanyawa ba ta yi amfani da aikin BERT. Tuna nũna BERT an goge zuwa variant na littafin da ke cikin littãfi. Ga da hagan, Munã nũna BERT bai zama mai sauƙi ba ga tafiyar da bayani na kima daga matsayin.</abstract_ha>
      <abstract_jv>Yuta ngerasai s êmbot karo Sensitif sami model BERT kang alat i ngluwih sak Aldhéir susahé seneng nggawe model sing luwih apik, lan ngregani kapasituran karo perusahaan sami nggawe kapasituran karo perusahaan. Nang pepulan iki, kita ranjelisar piye ngerasar tentang layang seneng pisan anyar tentang karo nganggep nggawe barang seneng pisan seneng pisan BERT. Awak dhéwé ngomong nik BERT kuwi nggawe barang langgambar kapan ning teks. Nanging kabeh-kabeh, kita ngomong nik BERT kuwi metu nggawe informasi sing dikarepaké nêmêr</abstract_jv>
      <abstract_sk>Razumevanje robustnosti in občutljivosti BERT modelov, ki napovedujejo Alzheimerjevo bolezen iz besedila, je pomembno tako za razvoj boljših modelov klasifikacije kot za razumevanje njihovih zmožnosti in omejitev. V prispevku analiziramo, kako nadzorovana količina želenih in neželenih sprememb besedila vpliva na delovanje BERT-a. Pokazujemo, da je BERT robusten do naravnih jezikovnih variacij besedila. Po drugi strani pa pokažemo, da BERT ni občutljiv na odstranjevanje klinično pomembnih informacij iz besedila.</abstract_sk>
      <abstract_bo>Understanding robustness and sensitivity of BERT models predicting Alzheimer's disease from text is important for both developing better classification models and for understanding their capabilities and limitations. ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་ལྟ་བུའི་ཚད་ལྟར་ཉེས་ཡོད་པ་དང་རྩོམ་མེད་པའི་ཡིག་གེ་བསྒྱུར་བཅོས་ནི་BERT ཡི་སྒྲུབ་ ང་ཚོས་BERT(BERT)ཡི་མིང་ནང་གི་སྐད་རིགས་ཀྱི་ཁྱད་པར་གཅིག་སྟོན་པ་ཡིན་པས། ཕྱོགས་གཞན་ཞིག་ནས་ འུ་ཅག་གིས་BERT་ཡི་གེ་ནང་དུ་གཏོང་གལ་ཆེན་གྱི་གནས་ཚུལ་འདོར་བ་སྐྱེན་མེད་པ་ཡིན་པས།</abstract_bo>
      </paper>
    <paper id="39">
      <title>CIDEr-R : Robust Consensus-based Image Description Evaluation<fixed-case>CIDE</fixed-case>r-<fixed-case>R</fixed-case>: Robust Consensus-based Image Description Evaluation</title>
      <author><first>Gabriel</first><last>Oliveira dos Santos</last></author>
      <author><first>Esther Luna</first><last>Colombini</last></author>
      <author><first>Sandra</first><last>Avila</last></author>
      <pages>351–360</pages>
      <abstract>This paper shows that CIDEr-D, a traditional evaluation metric for image description, does not work properly on datasets where the number of words in the sentence is significantly greater than those in the MS COCO Captions dataset. We also show that CIDEr-D has performance hampered by the lack of multiple reference sentences and high variance of <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a>. To bypass this problem, we introduce CIDEr-R, which improves CIDEr-D, making it more flexible in dealing with <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> with high sentence length variance. We demonstrate that CIDEr-R is more accurate and closer to human judgment than CIDEr-D ; CIDEr-R is more robust regarding the number of available references. Our results reveal that using Self-Critical Sequence Training to optimize CIDEr-R generates descriptive captions. In contrast, when CIDEr-D is optimized, the generated captions’ length tends to be similar to the reference length. However, the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> also repeat several times the same word to increase the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a>.</abstract>
      <url hash="1e750212">2021.wnut-1.39</url>
      <bibkey>oliveira-dos-santos-etal-2021-cider</bibkey>
      <doi>10.18653/v1/2021.wnut-1.39</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco-captions">COCO Captions</pwcdataset>
    <title_ar>CIDEr-R: تقييم قوي لوصف الصورة قائم على الإجماع</title_ar>
      <title_pt>CIDEr-R: Avaliação robusta de descrição de imagem baseada em consenso</title_pt>
      <title_es>Cider-R: evaluación sólida de la descripción de imágenes basada en el consenso</title_es>
      <title_fr>Cider-R : évaluation robuste de description d'image basée sur le consensus</title_fr>
      <title_zh>CIDEr-R:共识鲁棒图评</title_zh>
      <title_ja>CIDEr - R ：堅牢なコンセンサスベースの画像説明の評価</title_ja>
      <title_ru>CIDEr-R: Надежная оценка описания изображения на основе консенсуса</title_ru>
      <title_hi>CIDEr-R: मजबूत आम सहमति-आधारित छवि विवरण मूल्यांकन</title_hi>
      <title_ga>CIDEr-R: Measúnú Cur Síos Íomhá Láidir Bunaithe ar Chomhdhearcadh</title_ga>
      <title_ka>CIDEr</title_ka>
      <title_hu>CIDEr-R: Robusztus konszenzuson alapuló kép Leírás Értékelés</title_hu>
      <title_el>Ισχυρή αξιολόγηση περιγραφής εικόνας βάσει συναίνεσης</title_el>
      <title_it>CIDEr-R: Robusta immagine basata sul consenso Descrizione Valutazione</title_it>
      <title_kk>CIDEr- R: Робст консенсус негіздеген кескіндің сипаттамасын бағалау</title_kk>
      <title_mk>CIDEr- R: Оценка на описот на сликата базирана на силен консензус</title_mk>
      <title_lt>CIDEr-R: patikimas konsensusu pagrįstas vaizdo aprašymo vertinimas</title_lt>
      <title_ml>CIDEr- R: റോബസ്റ്റ് കോണ്‍സെന്‍സ്റ്റ്- അടിസ്ഥാനമായ ചിത്ര വിവരണം</title_ml>
      <title_ms>CIDEr-R: Evaluasi Keterangan Imej Berasas Kesenangan Kuat</title_ms>
      <title_mn>CIDEr-R: Бүтэн консенсусын үндсэн зураг тодорхойлолтын үнэлгээ</title_mn>
      <title_mt>CIDEr-R: Evalwazzjoni robusta tad-Deskrizzjoni tal-Immaġni bbażata fuq il-Konsens</title_mt>
      <title_ro>CIDEr-R: Imagine robustă bazată pe consens Descriere Evaluare</title_ro>
      <title_pl>CIDEr-R: Solidna ocena opisu obrazu oparta na konsensusie</title_pl>
      <title_no>CIDEr-R: Evaluering av robust konsensbasert biletsbeskrivelse</title_no>
      <title_si>CIDEr- R: ශක්තිමත් පින්තූර විස්තර විශේෂණය</title_si>
      <title_so>CIDEr-R: Aqoonsiga sawirka ku saleysan ee Robust Consensus</title_so>
      <title_sr>CIDEr-R: Evaluacija opisa slika na osnovu koncensusa</title_sr>
      <title_sv>CIDEr-R: Robust konsensusbaserad bildbeskrivning Utvärdering</title_sv>
      <title_ur>CIDEr-R: سخت کنسوس-بنیادی تصویر سفارش ارزیابی</title_ur>
      <title_ta>CIDEr- R: சுழற்சி கான்சென்ஸ்- அடிப்படையிலுள்ள பிம்பம் விவரிப்பு மதிப்பு</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>CID-R: giá trị mô tả ảnh bền vững</title_vi>
      <title_bg>CIDER-R: Robust Consensus based Image Description Evaluation</title_bg>
      <title_nl>CIDEr-R: Robuuste op consensus gebaseerde beeldbeschrijving evaluatie</title_nl>
      <title_hr>CIDEr-R: Evaluacija opisa slika na temelju stabilnog konsenzusa</title_hr>
      <title_da>CIDEr-R: Robust konsensusbaseret billedbeskrivelse Evaluering</title_da>
      <title_de>CIDEr-R: Robuste konsensusbasierte Bildbeschreibung Bewertung</title_de>
      <title_id>CIDEr-R: Robust Consensus-based Image Description Evaluation</title_id>
      <title_ko>CIDEr-R: 일치성 기반 루팡 이미지 설명 평가</title_ko>
      <title_fa>CIDEr-R: ارزیابی توصیف تصویر بر پایه ثابت کنسوس</title_fa>
      <title_sw>CIDEr-R: Uthibitisho wa Picha inayotokana na Mtazamo wa Picha</title_sw>
      <title_af>Name</title_af>
      <title_sq>CIDEr-R: Vlerësim i fortë i përshkrimit të imazhit bazuar në konsensus</title_sq>
      <title_am>undo-type</title_am>
      <title_tr>CIDEr-R: Robust Consensus-based Image Description Evaluation</title_tr>
      <title_hy>CIDEr-R. Կոնսենսուսի հիմնված ուժեղ նկարի նկարագրության գնահատում</title_hy>
      <title_az>CIDEr-R: Q√ºvv…ôtli Konsens-tabanlƒ± R …ôsm Tasvir Qƒ±dƒ±mlarƒ±</title_az>
      <title_bn>CIDEr-R: রোবাস্ট কনসেন্স-ভিত্তিক ছবি বিবরণ</title_bn>
      <title_bs>CIDEr-R: Evaluacija opisa slika na temelju koncensusa</title_bs>
      <title_cs>CIDEr-R: Robustní vyhodnocení popisu obrazu založeného na konsensus</title_cs>
      <title_ca>CIDEr-R: Evaluació robusta de la descripció d'imatges basada en el consens</title_ca>
      <title_fi>CIDer-R: Robust Consensus-based Image Description Evaluation</title_fi>
      <title_et>CIDER-R: tugev konsensuspõhine pildi kirjeldus Hindamine</title_et>
      <title_he>CIDEr-R: Robust Consensus-based Image Description Evaluation</title_he>
      <title_sk>CIDER-R: Robust Soglasje temelji na oceni opisa slike</title_sk>
      <title_bo>CIDEr-R: Robust Consensus-based Image Description Evaluation</title_bo>
      <title_jv>CIDEr-R</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <abstract_fr>Cet article montre que Cider-D, une métrique d'évaluation traditionnelle pour la description des images, ne fonctionne pas correctement sur les ensembles de données où le nombre de mots dans la phrase est significativement plus élevé que ceux de l'ensemble de données MS COCO Captions. Nous montrons également que les performances de Cider-D sont entravées par l'absence de phrases de référence multiples et la grande variance de la longueur des phrases. Pour contourner ce problème, nous introduisons Cider-R, qui améliore Cider-D, le rendant plus flexible dans le traitement des ensembles de données avec une variance de longueur de phrase élevée. Nous démontrons que Cider-R est plus précis et plus proche du jugement humain que Cider-D ; Cider-R est plus robuste en ce qui concerne le nombre de références disponibles. Nos résultats révèlent que l'utilisation de l'entraînement séquentiel autocritique pour optimiser Cider-R génère des légendes descriptives. En revanche, lorsque Cider-D est optimisé, la longueur des sous-titres générés tend à être similaire à la longueur de référence. Cependant, les modèles répètent également plusieurs fois le même mot pour augmenter la longueur de la phrase.</abstract_fr>
      <abstract_ar>توضح هذه الورقة أن CIDEr-D ، وهو مقياس تقييم تقليدي لوصف الصورة ، لا يعمل بشكل صحيح على مجموعات البيانات حيث يكون عدد الكلمات في الجملة أكبر بكثير من تلك الموجودة في مجموعة بيانات MS COCO Captions. نظهر أيضًا أن أداء CIDEr-D يعوقه عدم وجود جمل مرجعية متعددة والتباين الكبير في طول الجملة. لتجاوز هذه المشكلة ، نقدم CIDEr-R ، الذي يحسن CIDEr-D ، مما يجعله أكثر مرونة في التعامل مع مجموعات البيانات ذات التباين العالي في طول الجملة. نثبت أن CIDEr-R أكثر دقة وأقرب إلى الحكم البشري من CIDEr-D ؛ CIDEr-R أكثر قوة فيما يتعلق بعدد المراجع المتاحة. تكشف نتائجنا أن استخدام تدريب التسلسل الذاتي النقدي لتحسين CIDEr-R يولد تسميات توضيحية وصفية. في المقابل ، عندما يتم تحسين CIDEr-D ، يميل طول التسميات التوضيحية الناتجة إلى أن يكون مشابهًا لطول المرجع. ومع ذلك ، تكرر النماذج أيضًا نفس الكلمة عدة مرات لزيادة طول الجملة.</abstract_ar>
      <abstract_pt>Este artigo mostra que o CIDEr-D, uma métrica de avaliação tradicional para descrição de imagens, não funciona adequadamente em conjuntos de dados em que o número de palavras na frase é significativamente maior do que no conjunto de dados MS COCO Captions. Mostramos também que o CIDEr-D tem desempenho prejudicado pela falta de múltiplas sentenças de referência e alta variância de comprimento de sentença. Para contornar esse problema, introduzimos o CIDEr-R, que melhora o CIDEr-D, tornando-o mais flexível para lidar com conjuntos de dados com alta variação de comprimento de sentença. Demonstramos que o CIDEr-R é mais preciso e mais próximo do julgamento humano do que o CIDEr-D; O CIDEr-R é mais robusto quanto ao número de referências disponíveis. Nossos resultados revelam que o uso do Treinamento de Sequência Autocrítica para otimizar o CIDEr-R gera legendas descritivas. Por outro lado, quando o CIDEr-D é otimizado, o comprimento das legendas geradas tende a ser semelhante ao comprimento de referência. No entanto, os modelos também repetem várias vezes a mesma palavra para aumentar o comprimento da frase.</abstract_pt>
      <abstract_es>Este documento muestra que Cider-D, una métrica de evaluación tradicional para la descripción de imágenes, no funciona correctamente en conjuntos de datos donde el número de palabras en la oración es significativamente mayor que en el conjunto de datos de subtítulos de MS COCO. También mostramos que el rendimiento de Cider-D se ve obstaculizado por la falta de múltiples oraciones de referencia y la alta varianza de la longitud de las oraciones. Para evitar este problema, presentamos Cider-R, que mejora Cider-D, lo que lo hace más flexible al tratar con conjuntos de datos con una alta variación en la longitud de las oraciones. Demostramos que Cider-R es más preciso y está más cerca del juicio humano que Cider-D; Cider-R es más sólido en cuanto al número de referencias disponibles. Nuestros resultados revelan que el uso del entrenamiento de secuencias autocríticas para optimizar Cider-R genera subtítulos descriptivos. Por el contrario, cuando se optimiza Cider-D, la longitud de los subtítulos generados tiende a ser similar a la longitud de referencia. Sin embargo, los modelos también repiten varias veces la misma palabra para aumentar la longitud de la oración.</abstract_es>
      <abstract_ja>本稿では、画像記述のための従来の評価指標であるCIDEr - Dが、文中の単語数がMS COCO Captionsデータセットよりも有意に多いデータセットでは適切に動作しないことを示した。また、CIDEr - Dは、複数の参照文の欠如と文の長さの多様性によってパフォーマンスが阻害されていることを示している。この問題を回避するために、CIDEr - Dを改良したCIDEr - Rを導入し、文の長さのばらつきの大きいデータセットをより柔軟に扱えるようにしました。我々は、CIDEr - RがCIDEr - Dよりも正確であり、ヒトの判断に近いことを実証し、CIDEr - Rは利用可能な参照の数に関してより堅牢である。我々の結果は、CIDEr - Rを最適化するために自己臨界シーケンストレーニングを使用すると、記述的なキャプションが生成されることを明らかにした。対照的に、CIDEr - Dが最適化されると、生成されたキャプションの長さは、参照長さに類似する傾向がある。しかし、モデルは同じ単語を数回繰り返して、文章の長さを増やします。</abstract_ja>
      <abstract_ru>Эта статья показывает, что CIDEr-D, традиционная оценочная метрика для описания изображения, не работает должным образом в наборах данных, где количество слов в предложении значительно больше, чем в наборе данных MS COCO Captions. Мы также показываем, что CIDEr-D имеет производительность, которой препятствует отсутствие нескольких ссылочных предложений и высокая вариативность длины предложения. Чтобы обойти эту проблему, мы вводим CIDEr-R, который улучшает CIDEr-D, делая его более гибким в работе с наборами данных с высокой дисперсией длины предложения. Мы демонстрируем, что CIDEr-R точнее и ближе к суждению человека, чем CIDEr-D; CIDEr-R более надежен в отношении количества доступных ссылок. Наши результаты показывают, что использование обучения самокритичной последовательности для оптимизации CIDEr-R генерирует описательные подписи. Напротив, когда CIDEr-D оптимизирован, длина сгенерированных подписей, как правило, аналогична эталонной длине. Тем не менее, модели также повторяют несколько раз одно и то же слово, чтобы увеличить длину предложения.</abstract_ru>
      <abstract_zh>本文明CIDEr-D(一以象述旧法评估指标)于句中单词数显大于MS COCO Captions数集单词数集上不得其常。 又明CIDEr-D以少参句句之高异也。 为绕过这件事,引入了CIDEr-R,改进了CIDEr-D,使在处理有高句子长度方差的数据集时更加灵活。 吾证CIDEr-R确于CIDEr-D,更近于人。 CIDEr-R 于可用之数益坚。 臣等考结果表明,用自临界序训练优化CIDEr-R可以成描述性字幕。 反此者, CIDEr-D 之优化也,生字幕之长,往往与参相似。 然模形数复同单词以增句长。</abstract_zh>
      <abstract_hi>इस पेपर से पता चलता है कि सीआईडीईआर-डी, छवि विवरण के लिए एक पारंपरिक मूल्यांकन मीट्रिक, डेटासेट पर ठीक से काम नहीं करता है जहां वाक्य में शब्दों की संख्या एमएस कोको कैप्शन डेटासेट में उन लोगों की तुलना में काफी अधिक है। हम यह भी दिखाते हैं कि CIDEr-D में कई संदर्भ वाक्यों की कमी और वाक्य की लंबाई के उच्च विचरण के कारण प्रदर्शन बाधित होता है। इस समस्या को बायपास करने के लिए, हम सीआईडीईआर-आर पेश करते हैं, जो सीआईडीईआर-डी में सुधार करता है, जिससे यह उच्च वाक्य लंबाई विचरण वाले डेटासेट से निपटने में अधिक लचीला हो जाता है। हम प्रदर्शित करते हैं कि सीआईडीईआर-आर सीआईडीईआर-डी की तुलना में अधिक सटीक और मानव निर्णय के करीब है; सीआईडीईआर-आर उपलब्ध संदर्भों की संख्या के संबंध में अधिक मजबूत है। हमारे परिणामों से पता चलता है कि CIDEr-R को अनुकूलित करने के लिए स्व-महत्वपूर्ण अनुक्रम प्रशिक्षण का उपयोग करना वर्णनात्मक कैप्शन उत्पन्न करता है। इसके विपरीत, जब CIDEr-D ऑप्टिमाइज़ किया जाता है, तो उत्पन्न कैप्शन की लंबाई संदर्भ लंबाई के समान होती है। हालांकि, मॉडल वाक्य की लंबाई बढ़ाने के लिए एक ही शब्द को कई बार दोहराते हैं।</abstract_hi>
      <abstract_ga>Léiríonn an páipéar seo nach n-oibríonn CIDEr-D, méadrach meastóireachta traidisiúnta le haghaidh cur síos ar íomhá, i gceart ar thacair sonraí ina bhfuil líon na bhfocal san abairt i bhfad níos mó ná iad siúd i tacar sonraí MS COCO Captions. Léirímid freisin go bhfuil feidhmíocht CIDEr-D curtha isteach ag an easpa abairtí tagartha iolracha agus éagsúlachtaí ard i bhfad na pianbhreithe. Chun an fhadhb seo a sheachaint, tugaimid isteach CIDEr-R, a fheabhsaíonn CIDEr-D, rud a fhágann go bhfuil sé níos solúbtha agus muid ag déileáil le tacair shonraí a bhfuil ardathraitheas ar fhad abairtí acu. Léirímid go bhfuil CIDEr-R níos cruinne agus níos gaire do bhreithiúnas daonna ná CIDEr-D; Tá CIDEr-R níos láidre maidir le líon na dtagairtí atá ar fáil. Léiríonn ár dtorthaí go ngineann úsáid a bhaint as Oiliúint Seicheamh Féin-Chriticiúil chun CIDEr-R a bharrfheabhsú fotheidil thuairisciúla. I gcodarsnacht leis sin, nuair a dhéantar CIDEr-D a bharrfheabhsú, is gnách go mbíonn fad na bhfotheideal ginte cosúil leis an fad tagartha. Mar sin féin, déanann na samhlacha an focal céanna arís agus arís eile freisin chun fad na habairte a mhéadú.</abstract_ga>
      <abstract_hu>Ez a tanulmány azt mutatja, hogy a CIDEr-D, egy hagyományos értékelési mutató a kép leírására, nem működik megfelelően olyan adatkészleteken, ahol a mondatban szereplő szavak száma jelentősen nagyobb, mint az MS COCO feliratok adatkészletében. Azt is megmutatjuk, hogy a CIDEr-D teljesítményét akadályozza a többszörös referencia mondat hiánya és a mondathossz nagy eltérése. A probléma megkerülése érdekében bevezetjük a CIDEr-R-t, amely javítja a CIDEr-D-t, rugalmasabbá téve a nagy mondathosszú eltéréssel rendelkező adatkészletek kezelését. Bemutatjuk, hogy a CIDEr-R pontosabb és közelebb áll az emberi ítélőképességhez, mint a CIDEr-D; A CIDEr-R erősebb a rendelkezésre álló referenciák számát illetően. Eredményeink azt mutatják, hogy a CIDEr-R optimalizálására használt önkritikus szekvencia tréning leíró feliratokat generál. Ezzel szemben a CIDEr-D optimalizálásakor a generált feliratok hossza általában hasonló a referencia hosszához. Ugyanakkor a modellek többször is ugyanazt a szót ismétlik, hogy növeljék a mondat hosszát.</abstract_hu>
      <abstract_el>Η παρούσα εργασία δείχνει ότι το CIDEr-D, μια παραδοσιακή μετρική αξιολόγησης για την περιγραφή εικόνας, δεν λειτουργεί σωστά σε σύνολα δεδομένων όπου ο αριθμός λέξεων στην πρόταση είναι σημαντικά μεγαλύτερος από εκείνους στο σύνολο δεδομένων του MS COCO. Δείχνουμε επίσης ότι η απόδοση του έχει παρεμποδιστεί από την έλλειψη πολλαπλών προτάσεων αναφοράς και την υψηλή διακύμανση του μήκους της πρότασης. Για να παρακάμψουμε αυτό το πρόβλημα, εισάγουμε το το οποίο βελτιώνει το καθιστά πιο ευέλικτο στην αντιμετώπιση συνόλων δεδομένων με μεγάλη διακύμανση μήκους προτάσεων. Αποδεικνύουμε ότι η CIDEr-R είναι πιο ακριβής και πιο κοντά στην ανθρώπινη κρίση από την CIDEr-D. Το CIDEr-R είναι πιο ισχυρό όσον αφορά τον αριθμό των διαθέσιμων αναφορών. Τα αποτελέσματά μας αποκαλύπτουν ότι η χρήση της αυτοκριτικής εκπαίδευσης ακολουθίας για τη βελτιστοποίηση δημιουργεί περιγραφικές λεζάντες. Αντίθετα, όταν βελτιστοποιείται το μήκος των παραγόμενων λεζάντων τείνει να είναι παρόμοιο με το μήκος αναφοράς. Ωστόσο, τα μοντέλα επαναλαμβάνουν επίσης αρκετές φορές την ίδια λέξη για να αυξήσουν το μήκος της πρότασης.</abstract_el>
      <abstract_kk>Бұл қағаз кескін сипаттамасының традиционалдық оқиға метрикалық CIDEr- D сөздер саны MS COCO айдарының деректер қорларындағылардан артық болатын деректер қорларында дұрыс жұмыс істемейді. Мұндай-ақ CIDEr-D дегені бірнеше сілтеме сөздерінің жоғары және сөздердің ұзындығының жоғары түрлендірілмегенін көрсетедік. Бұл мәселені өзгерту үшін, CIDEr-R дегенді таңдаймыз. Бұл CIDEr-D дегенді жақсартып, деректер қорларының ұзындығын өзгерту үшін көптеген мәселелердің ұзындығын көптеген Біз CIDEr-R CIDEr-D дегеннен адамдардың дұрыстығына жақын және адамдардың дұрыстығына жақын екенін көрсетедік. CIDEr- R қол жеткізетін сілтемелер саны туралы күшті. Біздің нәтижелеріміз CIDEr-R оптимизациялау үшін Өзіміздің критикалық реттеу оқытуы қолданылады. Контрастырлығында, CIDEr- D оптимизацияланғанда, құрылған айдарлардың ұзындығы сілтеменің ұзындығына ұқсас болады. Бірақ үлгілер мәліметтің ұзындығын көтеру үшін бірнеше рет бір сөзді қайталады.</abstract_kk>
      <abstract_it>Questo articolo mostra che CIDEr-D, una metrica di valutazione tradizionale per la descrizione delle immagini, non funziona correttamente su set di dati in cui il numero di parole nella frase è significativamente superiore a quelli nel set di dati MS COCO Captions. Mostriamo anche che CIDEr-D ha prestazioni ostacolate dalla mancanza di frasi di riferimento multiple e dall'elevata varianza della lunghezza della frase. Per aggirare questo problema, introduciamo CIDEr-R, che migliora CIDEr-D, rendendolo più flessibile nell'affrontare set di dati con elevata varianza di lunghezza delle frasi. Dimostriamo che CIDEr-R è più accurato e più vicino al giudizio umano di CIDEr-D; CIDEr-R è più robusto per quanto riguarda il numero di referenze disponibili. I nostri risultati rivelano che l'utilizzo di Self-Critical Sequence Training per ottimizzare CIDEr-R genera didascalie descrittive. Al contrario, quando CIDEr-D è ottimizzato, la lunghezza delle didascalie generate tende ad essere simile alla lunghezza di riferimento. Tuttavia, i modelli ripetono anche più volte la stessa parola per aumentare la lunghezza della frase.</abstract_it>
      <abstract_ka>ამ წიგნის ჩვენება, რომ CIDEr-D, ტრადიციონალური გამოსახულების განსახულებისთვის განსახულებისთვის მეტრიკა, არ მუშაობს მონაცემების კონფიგურაციაში, სადაც წიგნის სიტყვების რაოდენობა მ ჩვენ ასევე გამოჩვენებთ, რომ CIDEr-D უფრო მეტი რეფერენციური სიტყვების და მარტივი სიტყვების სიტყვების განსხვავებას გადარჩენა. ამ პრობლემას გადავიწყოთ, ჩვენ CIDEr-R, რომელიც CIDEr-D-ს უფრო მეტად გავაკეთებთ, და უფრო მეტად გავაკეთებთ მონაცემების კონფიგურაციის განსხვავებაში. ჩვენ გამოჩვენებთ, რომ CIDEr-R უფრო უფრო წესიერია და ადამიანის წესიერებას უფრო დამატებული, ვიდრე CIDEr-D-ზე; CIDEr-R უფრო ძალიან ძალიან შესაძლებელი რეფერენციების რაოდენობაზე. ჩვენი წარმოდგენები აღმოჩნენ, რომ თავიდან კრიტიკური წარმოდგენების გამოყენება CIDEr-R-ის ოპტიმიზაციაში შექმნა განახლებელი წარმოდგენები. კონტრასტში, როდესაც CIDEr- D ოპტიმიზებულია, შექმნილი თარიღების სიგრძე უნდა იყოს განსხვავებული სიგრძე. მაგრამ, მოდელები ასევე რამდენიმე ჯერ ერთი სიტყვას, რომელიც სიტყვას უფრო მეტია.</abstract_ka>
      <abstract_ml>ഈ പത്രത്തില്‍ കാണിക്കുന്നത് CIDEr-D, ചിത്ര വിവരണത്തിനുള്ള പാരമ്പര്യമായ വിലാസപ്രകാരം മെട്രിക്ക്, വാക്കിലുള്ള വാക്കുകളുടെ എണ്ണം എസ്സ് കോ_ക്യ നമ്മളും കാണിക്കുന്നു സിഐഡിയര്‍ ഡി പ്രകടനം പല പ്രഖ്യാപന വാക്കുകളുടെ കുറവും വാക്കിന്റെ നീളവും കൂടുതല്‍ വ്യത്യാസവും കൊ ഈ പ്രശ്നത്തിലൂടെ കടന്നുപോകാന്‍ CIDEr-R-നെ പരിചയപ്പെടുത്തുന്നു. അത് CIDEr-D മെച്ചപ്പെടുത്തുന്നു. വാക്കിന്റെ നീളം വേര്‍വ്യത് CIDEr-R എന്നതിനെക്കാള്‍ മനുഷ്യന്റെ വിധി കൂടുതല്‍ അടുത്തതാണെന്ന് ഞങ്ങള്‍ പ്രത്യക്ഷപ്പെടുത്തുന്നു. ലഭ്യമല്ലാത്ത വിവരങ്ങളുടെ എണ്ണം കുറിച്ച് CIDEr-R കൂടുതല്‍ റോബ്സ്റ്റ് ആണ്. നമ്മുടെ ഫലങ്ങള്‍ വെളിപ്പെടുത്തുന്നത് സ്വയം ക്രിസ്റ്റിക്കല്‍ പരിശീലനം ഉപയോഗിച്ച് CIDEr-R ഉപയോഗിക്കാന്‍ വിശദീകരിക്ക വിരോധത്തില്‍, CIDEr-D ഐച്ഛികമാക്കപ്പെടുമ്പോള്‍, നിര്‍മ്മിച്ച തലക്കെട്ടുകളുടെ നീളം റെഫന്‍സന്‍ നീളവിനോട് സമമ എന്നാലും ഈ മോഡലുകളും വാക്കിന്റെ നീളം വര്‍ദ്ധിപ്പിക്കുന്നതിനായി ഒരുപാട് തവണ ആവര്‍ത്തിക്കുന്ന</abstract_ml>
      <abstract_lt>Šis dokumentas rodo, kad CIDEr-D, tradicinis vaizdo aprašymo vertinimo rodiklis, netinkamai veikia duomenų rinkiniuose, kuriuose žodžių skaičius sakinyje yra gerokai didesnis nei valstybių narių COCO skyrių duomenų rinkinyje. Mes taip pat parodome, kad CIDEr-D veiklos rezultatai trukdo, nes trūksta kelių pamatinių sakinių ir labai skiriasi bausmės trukmė. Siekiant išvengti šios problemos, įvedame CIDEr-R, kuris pagerina CIDEr-D, todėl ji tampa lankstesnė sprendžiant duomenų rinkinius, kurių ilgis labai skiriasi. Mes įrodome, kad CIDEr-R yra tikslesnis ir artimesnis žmogaus sprendimui nei CIDEr-D; CIDEr-R is more robust regarding the number of available references.  Mūsų rezultatai rodo, kad naudojant savikritinį sekos mokymą CIDEr-R optimizavimui sukuriami aprašomi pavadinimai. Priešingai, kai CIDEr-D optimizuojamas, sukauptų antraščių ilgis paprastai yra panašus į atskaitos ilgį. Tačiau modeliai taip pat kartoja kelis kartus tą patį žodį, kad būtų padidintas sakinio ilgis.</abstract_lt>
      <abstract_ms>Kertas ini menunjukkan bahawa CIDEr-D, metrik penilaian tradisional untuk keterangan imej, tidak berfungsi dengan betul pada set data di mana bilangan perkataan dalam kalimat adalah jauh lebih besar daripada yang dalam set data Capsi COCO MS. Kami juga menunjukkan bahawa CIDEr-D mempunyai prestasi yang dicegah oleh kekurangan kalimat rujukan berbilang dan variasi tinggi panjang kalimat. Untuk mengelak masalah ini, kami memperkenalkan CIDEr-R, yang memperbaiki CIDEr-D, membuatnya lebih fleksibel dalam menghadapi set data dengan variasi panjang kalimat tinggi. Kami menunjukkan bahawa CIDEr-R lebih tepat dan lebih dekat kepada penilaian manusia daripada CIDEr-D; CIDEr-R lebih kuat mengenai bilangan rujukan yang tersedia. Hasil kami menunjukkan bahawa menggunakan Latihan Sekuensi Kritik Sendiri untuk optimize CIDEr-R menghasilkan tajuk deskriptif. Sebaliknya, apabila CIDEr-D dipeptimalkan, panjang tajuk yang dijana cenderung sama dengan panjang rujukan. Namun, model juga mengulang beberapa kali perkataan yang sama untuk meningkatkan panjang kalimat.</abstract_ms>
      <abstract_mk>Овој документ покажува дека CIDEr-D, традиционална метрика за проценка на описот на сликата, не функционира правилно на датотеките каде бројот на зборови во реченицата е значително поголем од оние во податоците на капициите на MS COCO. Исто така покажуваме дека ЦИДЕР-Д ја попречува резултатот со недостатокот на повеќе референциски реченици и висока варијанција на должината на речениците. За да го избегнеме овој проблем, воведуваме CIDEr-R, што го подобрува CIDEr-D, што го прави пофлексибилен во справувањето со податоци со висока разлика на должина на речениците. Демонстрираме дека ЦИДЕР-Р е попрецизен и поблиску до човечкото судење отколку ЦИДЕР-Д; CIDEr-R е појак во врска со бројот на достапни референции. Нашите резултати откриваат дека користејќи се самокритички тренинг за секвенција за оптимизација на CIDEr-R генерира описни наслови. За разлика од тоа, кога CIDEr-D е оптимизиран, должината на генерираните наслови обично е слична на референтната должина. Сепак, моделите, исто така, неколку пати го повторуваат истиот збор за зголемување на должината на реченицата.</abstract_mk>
      <abstract_mt>Dan id-dokument juri li CIDEr-D, metrika ta’ evalwazzjoni tradizzjonali għad-deskrizzjoni tal-immaġni, ma taħdimx kif suppost fuq settijiet ta’ dejta fejn in-numru ta’ kliem fis-sentenza huwa sinifikanti akbar minn dawk fis-sett ta’ dejta tal-Kapitoli COCO tal-Istati Membri. Aħna nuru wkoll li CIDEr-D ixekkel il-prestazzjoni minħabba n-nuqqas ta’ sentenzi ta’ referenza multipli u varjanza għolja fit-tul tas-sentenza. To bypass this problem, we introduce CIDEr-R, which improves CIDEr-D, making it more flexible in dealing with datasets with high sentence length variance.  Aħna nuru li CIDEr-R huwa aktar preċiż u eqreb lejn is-sentenza umana minn CIDEr-D; CIDEr-R huwa aktar robust fir-rigward tan-numru ta’ referenzi disponibbli. Our results reveal that using Self-Critical Sequence Training to optimize CIDEr-R generates descriptive captions.  B’kuntrast ma’ dan, meta CIDEr-D jiġi ottimizzat, it-tul tal-intestaturi ġġenerati għandu t-tendenza li jkun simili għat-tul ta’ referenza. Madankollu, il-mudelli jirrepetu wkoll diversi drabi l-istess kelma biex iżidu t-tul tas-sentenza.</abstract_mt>
      <abstract_mn>Энэ цаас харуулж байна гэвэл CIDEr-D, зураг дүрслэлийн уламжлалтын дүрслэлийн метрик гэдэг нь өгөгдлийн сангийн тоо нь MS COCO цөмийн өгөгдлийн сангийн хэмжээсүүдээс илүү их байдаг. Мөн бид CIDEr-D-г олон Reference өгүүлбэр болон өгүүлбэрийн урт өндөр өөрчлөлттэй байдлаас хамаарч байгааг харуулж байна. Энэ асуудлыг дуусахын тулд бид CIDEr-R-г танилцуулна. Энэ нь CIDEr-D-г сайжруулж өгөгдлийн сангуудыг өндөр өгүүлбэрийн урт өөрчлөлтийг ашиглах боломжтой болгодог. Бид CIDEr-R нь CIDEr-D-с илүү зөв бөгөөд хүний шүүмжлээ илүү ойрхон байдгийг харуулж байна. CIDEr-R нь хэрэглэгдэх тоо баримтуудын тухай илүү хүчтэй. Бидний үр дүнд өөрсдийгөө хувьсгал дарааллын дасгал хөдөлгөөн ашиглаж CIDEr-R-г сайжруулахын тулд тодорхойлолт бий болгодог. Харамсалтай нь CIDEr-D багасгах үед бий болсон үлгэрүүдийн урт нь багасгал урттай төстэй байдаг. Гэхдээ загварууд мөн хэдэн дахин ижил үг давтагдаж өгүүлбэрийг нэмэх гэсэн үг юм.</abstract_mn>
      <abstract_pl>Niniejszy artykuł pokazuje, że CIDEr-D, tradycyjna metryka oceny opisu obrazu, nie działa poprawnie na zbiorach danych, w których liczba słów w zdaniu jest znacznie większa niż w zbiorze danych MS COCO Captions. Pokazujemy również, że wydajność CIDEr-D jest utrudniona brakiem wielu zdań referencyjnych i dużą wariancją długości zdania. Aby ominąć ten problem, wprowadzamy CIDEr-R, który usprawnia CIDEr-D, dzięki czemu jest bardziej elastyczny w obsłudze zbiorów danych o dużej wariancji długości zdania. Wykazujemy, że CIDEr-R jest dokładniejszy i bliższy ludzkiej ocenie niż CIDEr-D; CIDEr-R jest bardziej solidny pod względem liczby dostępnych referencji. Nasze wyniki pokazują, że korzystanie z Self-Critical Sequence Training do optymalizacji CIDEr-R generuje opisowe napisy. Natomiast gdy CIDEr-D jest zoptymalizowany, długość generowanych napisów jest zazwyczaj podobna do długości referencyjnej. Jednak modele powtarzają również kilka razy to samo słowo, aby zwiększyć długość zdania.</abstract_pl>
      <abstract_sr>Ovaj papir pokazuje da CIDEr-D, tradicionalna procjena metrika za opis slika, ne funkcioniše dobro na setima podataka gde je broj reči u rečenici značajno veći od onih u setu podataka MS COCO kapcija. Takoðe pokazujemo da je CIDEr-D sprijeèio izvedbu nedostatak višestrukih referentnih rečenica i visoke varijacije dužine rečenice. Da bismo prekinuli ovaj problem, predstavljamo CIDEr-R, koji poboljšava CIDEr-D, čini to fleksibilnijim u rješavanju seta podataka sa varijancijom dužine rečenice. Pokazujemo da je CIDEr-R tačniji i bliži ljudskoj presudi nego CIDEr-D; CIDEr-R je jači u vezi broja dostupnih referencija. Naši rezultati otkrivaju da korištenje treninga samozkritične sekvence za optimizaciju CIDEr-R stvara opisivne kapije. U suprotnom, kada se CIDEr-D optimizira, dužina proizvedenih naslova navodno je slična referentnoj dužini. Međutim, modeli takođe ponovljaju nekoliko puta iste reči da bi povećali dužinu rečenice.</abstract_sr>
      <abstract_si>මේ පත්තුව පෙන්වන්නේ CIDEr-D, පින්තූර විස්තරය සඳහා පාරමාන්‍ය විස්තරයක් විස්තර කරනවා කියලා, වාක්යේ වචන සංඛ්‍යා MS COCO කැප්ටන් දත අපි පෙන්වන්නේ CIDEr-D එක්කම ප්‍රමාණයක් තියෙනවා කියලා වාර්තාවක් අවස්ථාවක් සහ වාර්තාවක් වෙනුවෙන් වෙනස මේ ප්‍රශ්නය බායිප්ස් කරන්න, අපි CIDEr-R වෙනස් කරනවා, ඒක CIDEr-D වැඩි කරනවා, ඒක වැඩි වෙනස් කරනවා දත්ත සෙට් එක්ක ගොඩක් විශ්වාසය අපි පෙන්වන්නම් CIDEr-R කියලා CIDEr-D වඩා මිනිස්සුන් විශ්වාස කරනවා කියලා; CIDEr අපේ ප්‍රතිචාරය පෙන්වන්නේ ස්විත-විශේෂ විශේෂ ප්‍රධානය සඳහා CIDEr-R විශේෂ විශේෂ ප්‍රධානය කරන්න. ප්‍රතිදේශයෙන්, CIDEr-D විශ්වාස කරලා තියෙනකොට, නිර්මාණය විශ්වාස කරපු ප්‍රතිදේශයේ ලොකුව ප්‍රතිදේශය ස නමුත්, මොඩල් එක්ක වතාවක් වතාවක් ආයුතු කරනවා වචනය වැඩ කරන්න.</abstract_si>
      <abstract_no>Denne papiret viser at CIDEr-D, ein tradisjonell evalueringsmetrik for biletsbeskrivelsen, fungerer ikkje rett på datasett der antallet ord i setninga er betydelig større enn dei i datasettet MS COCO-tittel. Vi viser også at CIDEr-D har utviklinga avbroten av manglende fleire referanse setningar og høg varianse av setningsslengde. For å unngå dette problemet, introduserer vi CIDEr-R, som forbedrar CIDEr-D, og gjør det fleksibel i å handtera datasett med høg setningsverdi. Vi viser at CIDEr-R er meir nøyaktig og nærmere menneske sprøytebruk enn CIDEr-D. CIDEr-R er meir sterkt om talet på tilgjengelege referanser. Resultatet våre viser at ved å bruka Sjølvkritisk sekvensøving for å optimalisera CIDEr-R generer beskrivelige tittel. I contrast, when CIDEr- D is optimized, the generated captions length tends to be similar to the reference length. Modellene gjentar også fleire ganger det same ordet for å auka setninga.</abstract_no>
      <abstract_sv>Denna uppsats visar att CIDEr-D, en traditionell utvärderingsmetod för bildbeskrivning, inte fungerar korrekt på datauppsättningar där antalet ord i meningen är betydligt större än dem i MS COCO Captions datauppsättningen. Vi visar också att CIDEr-D har prestanda som hämmas av bristen på flera referensmeningar och hög variation av meningslängd. För att kringgå detta problem introducerar vi CIDEr-R, som förbättrar CIDEr-D, vilket gör det mer flexibelt att hantera datauppsättningar med hög meningslängd varians. Vi visar att CIDEr-R är mer exakt och närmare mänskligt omdöme än CIDEr-D; CIDEr-R är mer robust när det gäller antalet tillgängliga referenser. Våra resultat visar att användningen av Self-Critical Sequence Training för att optimera CIDEr-R genererar beskrivande bildtexter. Däremot, när CIDEr-D optimeras, tenderar de genererade bildtexternas längd att likna referenslängden. Modellerna upprepar dock också flera gånger samma ord för att öka meningslängden.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் CIDEr-D, பிம்பத்தை விளக்கத்திற்கான மரபார்ந்த மதிப்பீடு மெட்ரிக் காட்டுகிறது, தகவல் அமைப்பில் வாக்கியின் எண்ணிக்கையில் உள்ள வ நாம் காண்பிக்கிறோம் CIDEr-D செயல்பாடு பல குறிப்பு வாக்கியங்கள் குறைந்தது மற்றும் வாக்கியின் நீளத்தின் உயர்ந்த இந்த பிரச்சனையை கடந்து செல்ல, CIDEr-R, அது CIDEr-D, அதை மேம்படுத்துகிறது, அது தகவல் அமைப்புகளை உயர் வாக்கின் நீளம் மாறுபாடுகளை கொண்டு  CIDEr-R என்பதை CIDEr-D விட நெருங்கிய மற்றும் மனித தீர்ப்பு நெருங்கியிருக்கிறது என்று காண்பிக்கிறோம். கிடைக்கும் குறிப்புகள் எண்ணிக்கை எங்கள் முடிவுகள் தெரிவிக்கப்படுகிறது சிடிடி- ஆர் மேம்படுத்துவதற்கு சாத்தியமான பயிற்சியை பயன்படுத்தி விவரிப்பான பி மாறாக, CIDEr- D தேர்வு செய்யப்பட்டால், உருவாக்கப்பட்ட தலைப்புகளின் நீளம் குறிப்பு நீளத்திற்கு சமமாக இருக்கும். ஆனால், மாதிரிகள் அதே வாக்கின் நீளம் அதிகரிக்க பல முறை அதே வார்த்தையும் திரும்புகின்றன.</abstract_ta>
      <abstract_ro>Această lucrare arată că CIDEr-D, o metrică tradițională de evaluare pentru descrierea imaginii, nu funcționează corespunzător pe seturi de date în care numărul de cuvinte din propoziție este semnificativ mai mare decât cele din setul de date MS COCO Captions. De asemenea, arătăm că CIDEr-D are performanțe împiedicate de lipsa mai multor propoziții de referință și variația ridicată a lungimii propozițiilor. Pentru a ocoli această problemă, introducem CIDEr-R, care îmbunătățește CIDEr-D, făcându-l mai flexibil în tratarea seturilor de date cu variație mare a lungimii propozițiilor. Demonstrăm că CIDEr-R este mai precis și mai aproape de judecata umană decât CIDEr-D; CIDEr-R este mai robust în ceea ce privește numărul de referințe disponibile. Rezultatele noastre dezvăluie faptul că utilizarea instruirii secvențelor auto-critice pentru optimizarea CIDEr-R generează subtitrări descriptive. În schimb, atunci când CIDEr-D este optimizat, lungimea subtitrărilor generate tinde să fie similară cu lungimea de referință. Cu toate acestea, modelele repetă, de asemenea, de mai multe ori același cuvânt pentru a crește lungimea propoziției.</abstract_ro>
      <abstract_so>This paper shows that CIDEr-D, a traditional evaluation metric for image description, does not work properly on datasets where the number of words in the sentence is significantly greater than those in the MS COCO Captions dataset.  Sidoo kale waxaynu muujinnaa in CIDEr-D ay ku dhibaataysan dhamaadka codsiyada kala duduwan iyo dhererka ciqaabka sare. Si aan dhibaatadan u dhaafno, waxaan soo bandhignaa CIDEr-R, taasoo kordhisa CIDEr-D, waxaana ka dhigaynaa mid ka sii flexilsan macluumaadka sameynta sameynta sameynta muddo dheer oo xafiiska. Waxaynu muujinnaa in CIDEr-R ay ka sii sahlan tahay xukunka dadkana ugu dhaw tahay CIDEr-D; CIDEr-R waxey ka badan tahay in la xiriiro tirada codsiga lagu helo. Mataaradeenna waxay muuqataa in isticmaalka waxbarashada self-Critical Sequence si ay u optimizaan CIDEr-R waxay generaan baaritaanka qoraalka. Iska duwan marka CIDEr-D la optimizo, dhererka dhalashada ayaa la mid ah dhererka farsamada. Si kastaba ha ahaatee tusaalooyinku waxay sidoo kale ku soo celiyaan hadal isku mid ah si ay u kordhiso dhererka hadalka.</abstract_so>
      <abstract_ur>This paper shows that CIDEr-D, a traditional evaluation metric for image description, doesn't work properly on datasets where the sentence's number of words is significantly greater than those in the MS COCO Captions dataset. ہم نے بھی دکھایا ہے کہ CIDEr-D نے عملکرد کثیر ارتباط جماعتوں کے ناکام اور مجلس کی بلند متفاوت سے منع کیا ہے. اس مسئلہ کے باعث ہم CIDEr-R کو معرفی کرتے ہیں، جو CIDEr-D کو سودا کرتا ہے، اس سے زیادہ مہربانی کرتا ہے جبکہ ڈاٹ سٹ کے ساتھ بہت زیادہ مہربانی کرتا ہے۔ ہم دکھاتے ہیں کہ CIDEr-R CIDEr-D سے زیادہ صحیح اور نزدیک ہے۔ CIDEr-R موجود منظوروں کی تعداد کے بارے میں زیادہ طاقتور ہے. ہمارے نتیجے نشان دیتے ہیں کہ سیڈر-آر کو مزید مزید مزید دکھانے کے لئے Self-Critical Sequence Training کے مطابق مزید مزید کرتا ہے۔ مقابلہ میں، جب CIDEr-D optimized کیا جاتا ہے، پیدا کیا جاتا ہے کپٹینز کی لمبی کمی کی طرح ہوتی ہے. However, the models also repeat several times the same word to increase the length.</abstract_ur>
      <abstract_uz>Name Биз ҳам кўрсатамиз, CIDEr-D ҳужжати кўп ҳужжатлар ва ҳужжатлар жиҳатида катта ўзгаришларига эга бўлиши мумкин. Bu muammolarni almashtirish uchun CIDEr-R (CIDEr-D) ni ko'proq ko'proq maxfiy soʻzni boshqarish mumkin. Biz CIDEr-R'ni CIDEr-D'dan ko'proq inson xudding haqiqida ham yaqinligini ko'rsamiz; Name Our results reveal that using Self-Critical Sequence Training to optimize CIDEr-R generates descriptive captions.  Ikkinchi darajada, CIDEr-D moslama boʻlsa, yaratilgan sarlavhaning uzunligi bogʻ uzunligiga oʻxshaydi. Lekin modellar bir necha marta so'z so'zni oshirish uchun bir necha marta qaytadi.</abstract_uz>
      <abstract_vi>Tờ giấy này cho thấy CID-D, một hệ thống đánh giá truyền thống cho mô tả ảnh, không hoạt động đúng với bộ dữ liệu nơi số từ trong câu đó lớn hơn nhiều so với số ghi trong tập tin chụp SMS CO. Chúng tôi cũng cho thấy CID-D có hành động bị cản trở bởi việc không có nhiều câu tham khảo và sự khác biệt cao độ dài bản án. Để vượt qua vấn đề này, chúng tôi giới thiệu CID-R, nó cải thiện CID-D, và làm cho nó linh hoạt hơn trong việc xử lý các bộ dữ liệu với âm tính dài hạn cao án. Chúng tôi cho thấy CID-R chính xác hơn và gần với phán xét con người hơn CID-D; CID-R mạnh hơn về số tài liệu có sẵn. Những kết quả của chúng tôi cho thấy rằng nhờ Tập đoàn Đua tự phê bình, sẽ tạo ra các tác phẩm mô tả. Tuy nhiên, khi CID-D được nâng cao, độ dài tạo ra có xu hướng giống với độ dài tham chiếu. Tuy nhiên, các mô hình cũng lặp lại nhiều lần cùng một từ để tăng độ dài câu.</abstract_vi>
      <abstract_bg>Тази статия показва, че традиционният метод за оценка за описание на изображенията не работи правилно върху набори от данни, при които броят на думите в изречението е значително по-голям от тези в набора от данни на MS COCO Captions. Показваме също, че изпълнението е затруднено от липсата на множество референтни изречения и висока вариация на дължината на изречението. За да заобиколим този проблем, въвеждаме CIDER-R, който подобрява CIDER-D, което го прави по-гъвкав при работа с набори от данни с висока вариация на дължината на изречението. Ние демонстрираме, че е по-точен и по-близък до човешката преценка от този; CIDER-R е по-стабилен по отношение на броя на наличните референции. Нашите резултати показват, че използването на Обучение за самокритични последователности за оптимизиране генерира описателни надписи. За разлика от това, когато е оптимизирана, дължината на генерираните надписи обикновено е подобна на референтната дължина. Моделите обаче повтарят няколко пъти една и съща дума, за да увеличат дължината на изречението.</abstract_bg>
      <abstract_hr>Ovaj papir pokazuje da CIDEr-D, tradicionalna procjena metrika za opis slika, ne funkcioniše kako treba na setovima podataka gdje je broj riječi u rečenici značajno veći od onih u setu podataka MS COCO kapcija. Također pokazujemo da je CIDEr-D uspješnost ometana nedostatkom višestrukih referentnih rečenica i visokom varijancijom dužine rečenice. Da bismo prekinuli ovaj problem, predstavljamo CIDEr-R, koji poboljšava CIDEr-D, čini ga fleksibilnijim u rješavanju seta podataka s varijancijom dužine rečenice. Pokazujemo da je CIDEr-R precizniji i bliži ljudskoj procjeni nego CIDEr-D; CIDEr-R je jači u vezi broja dostupnih referencija. Naši rezultati pokazuju da korištenje treninga samozkritične sekvence za optimizaciju CIDEr-R stvara opisivne kapije. Nasuprotno, kada se CIDEr-D optimizira, dužina proizvedenih naslova često je slična referentnim dužinom. Međutim, modeli su također ponovili nekoliko puta iste riječi kako bi povećali dužinu rečenice.</abstract_hr>
      <abstract_nl>Dit document toont aan dat CIDEr-D, een traditionele evaluatiemetriek voor beeldbeschrijving, niet goed werkt op datasets waarbij het aantal woorden in de zin aanzienlijk groter is dan dat in de MS COCO Captions dataset. We tonen ook aan dat CIDEr-D prestaties belemmerd heeft door het ontbreken van meerdere referentiezinnen en een hoge variatie in de lengte van de zin. Om dit probleem te omzeilen, introduceren we CIDEr-R, die CIDEr-D verbetert, waardoor het flexibeler wordt in het omgaan met datasets met een hoge variantie van zinnenlänges. We tonen aan dat CIDEr-R nauwkeuriger en dichter bij het menselijk oordeel is dan CIDEr-D; CIDEr-R is robuuster wat betreft het aantal beschikbare referenties. Onze resultaten tonen aan dat het gebruik van Self-Critical Sequence Training om CIDEr-R te optimaliseren beschrijvende bijschriften genereert. Wanneer CIDEr-D daarentegen geoptimaliseerd is, is de lengte van de gegenereerde bijschriften meestal vergelijkbaar met de referentielengte. De modellen herhalen echter ook meerdere malen hetzelfde woord om de lengte van de zin te vergroten.</abstract_nl>
      <abstract_da>Dette dokument viser, at CIDEr-D, en traditionel evalueringsmetrik for billedbeskrivelse, ikke fungerer korrekt på datasæt, hvor antallet af ord i sætningen er betydeligt større end dem i MS COCO Captions datasættet. Vi viser også, at CIDEr-D har ydeevne hæmmet af manglen på flere referencesætninger og høj varians af sætningslængden. For at omgå dette problem introducerer vi CIDEr-R, som forbedrer CIDEr-D, hvilket gør det mere fleksibelt i håndteringen af datasæt med høj sætningslængde varians. Vi demonstrerer, at CIDEr-R er mere præcis og tættere på menneskelig dømmekraft end CIDEr-D; CIDEr-R er mere robust med hensyn til antallet af tilgængelige referencer. Vores resultater viser, at brug af selvkritisk sekvenstræning til at optimere CIDEr-R genererer beskrivende billedtekster. I modsætning hertil, når CIDEr-D er optimeret, har de genererede billedteksters længde tendens til at ligne referencelængden. Modellerne gentager dog også flere gange det samme ord for at øge sætningens længde.</abstract_da>
      <abstract_de>Diese Arbeit zeigt, dass CIDEr-D, eine traditionelle Auswertungsmetrik für die Bildbeschreibung, nicht ordnungsgemäß auf Datensätzen funktioniert, bei denen die Anzahl der Wörter im Satz deutlich größer ist als im MS COCO Captions Datensatz. Wir zeigen auch, dass CIDEr-D durch das Fehlen mehrerer Referenzsätze und eine hohe Varianz der Satzlänge die Leistung behindert. Um dieses Problem zu umgehen, führen wir CIDEr-R ein, das CIDEr-D verbessert und es flexibler im Umgang mit Datensätzen mit hoher Satzlängen-Varianz macht. Wir zeigen, dass CIDEr-R genauer und näher am menschlichen Urteilsvermögen ist als CIDEr-D; CIDEr-R ist robuster in Bezug auf die Anzahl der verfügbaren Referenzen. Unsere Ergebnisse zeigen, dass mithilfe von Self-Critical Sequence Training zur Optimierung von CIDEr-R beschreibende Untertitel generiert werden. Wenn CIDEr-D optimiert wird, ähnelt die Länge der generierten Untertitel der Referenzlänge. Die Modelle wiederholen jedoch auch mehrmals dasselbe Wort, um die Satzlänge zu erhöhen.</abstract_de>
      <abstract_fa>این کاغذ نشان می‌دهد که CIDEr-D، یک متریک ارزیابی سنتی برای توصیف تصویر، بر مجموعه‌های داده‌ها به طور درست کار نمی‌کند که تعداد کلمات در این جمله significantly greater than those in the MS COCO Captions dataset است. ما همچنین نشان می دهیم که CIDEr-D اجرایی را با کمبود جمله‌های متفاوت و متفاوت بلند از طول جمله محدود کرده است. برای عبور این مشکل، ما CIDEr-R را معرفی می‌کنیم که CIDEr-D را بهتر می‌کند، و در کنار مجموعه‌های داده‌ها با تغییر طول جمله‌ای بالا آن را بیشتر آسان می‌سازیم. ما نشان می دهیم که CIDEr-R دقیق تر و نزدیک تر به حکم انسان از CIDEr-D است. CIDEr-R در مورد تعداد ارتباطات موجود قوی تر است. نتیجه‌های ما نشان می‌دهند که با استفاده از آموزش تعلیم‌های خودکریتی برای optimization CIDEr-R، عنوان توصیف‌کننده تولید می‌کند. در مقابل، وقتی CIDEr-D optimized می‌شود، طول عنوان تولید شده مانند طول مربوط است. ولی مدل‌ها همچنین چند بار همان کلمه را برای افزایش طول جمله تکرار می‌کنند.</abstract_fa>
      <abstract_id>Kertas ini menunjukkan bahwa CIDEr-D, metrik evaluasi tradisional untuk deskripsi gambar, tidak bekerja dengan benar pada set data di mana jumlah kata dalam kalimat adalah jauh lebih besar dari yang dalam set data Captions MS COCO. Kami juga menunjukkan bahwa CIDEr-D telah prestasi terhalang oleh kekurangan kalimat referensi berbilang dan variasi tinggi panjang kalimat. Untuk menghindari masalah ini, kami memperkenalkan CIDEr-R, yang memperbaiki CIDEr-D, membuatnya lebih fleksibel dalam menghadapi set data dengan variasi panjang kalimat tinggi. We demonstrate that CIDEr-R is more accurate and closer to human judgment than CIDEr-D;  CIDEr-R lebih kuat mengenai jumlah referensi yang tersedia. Our results reveal that using Self-Critical Sequence Training to optimize CIDEr-R generates descriptive captions.  Sebaliknya, ketika CIDEr-D optimisasi, panjang captions yang dihasilkan cenderung menjadi mirip dengan panjang referensi. Namun, model juga mengulangi beberapa kali kata yang sama untuk meningkatkan panjang kalimat.</abstract_id>
      <abstract_ko>본고는 전통적인 이미지 묘사 평가 지표인 CIDEr-D가 문장의 글자 수가 MS COCO 자막 데이터가 집중된 글자 수보다 현저히 많은 데이터 집합에서 정상적으로 작동하지 못한다는 것을 보여준다.여러 참고 문장과 문장 길이의 고도의 변이가 부족해 사과주-D의 표현이 방해를 받았다는 사실도 밝혀졌다.이 문제를 빙빙 돌리기 위해, 우리는 CIDEr-R을 도입했다. 이것은 CIDEr-D를 개선하여 문장의 길이 변화가 비교적 큰 데이터 집합을 처리할 때 더욱 유연하게 한다.우리는 사과주 R이 사과주 D보다 더 정확하고 인간의 판단에 가깝다는 것을 증명했다.참고문헌의 수량으로 볼 때 사과주-R이 더 믿을 만하다.우리의 결과에 따르면, 임계 서열 훈련을 사용하여 CIDEr-R을 최적화하면 묘사적인 자막을 생성할 수 있다.이에 비해 CIDEr-D를 최적화할 때 생성된 자막의 길이는 참고 길이와 비슷한 경우가 많다.그러나 이 모델들도 문장의 길이를 늘리기 위해 같은 단어를 몇 번 반복한다.</abstract_ko>
      <abstract_sw>Gazeti hili linaonyesha kwamba CIDEr-D, mbinu ya utamaduni ya uchunguzi wa picha, haifanya kazi vizuri kwenye seti za data ambapo idadi ya maneno katika hukumu hiyo ni kubwa zaidi ya wale katika seti ya taarifa za chama cha MS CO. Tunaonyesha pia kuwa utendaji wa CIDEr-D umehambuliwa na ukosefu wa hukumu mbalimbali za maoni na tofauti kubwa ya hukumu. Kupitia tatizo hili, tunaonyesha CIDEr-R, ambalo linaboresha CIDEr-D, na kufanya hivyo kuwa na ubunifu zaidi katika kushughulikia seti za data yenye tofauti kubwa ya hukumu. Tunaonyesha kwamba CIDEr-R ni sahihi na karibu zaidi na uamuzi wa binadamu kuliko CIDEr-D; CIDEr-R ni vibaya zaidi kuhusiana na idadi ya maoni yanayopatikana. Matokeo yetu yanaonyesha kwamba kwa kutumia mafunzo ya kujitegemea kwa ajili ya kuboresha CIDEr-R inatengeneza maoni ya maelezo. In contrast, when CIDEr-D is optimized, the generated captions' length tends to be similar to the reference length.  Hata hivyo, mifano pia inarudia mara kadhaa kwa neno hilo ili kuongeza lengo la hukumu.</abstract_sw>
      <abstract_tr>Bu kagyz CIDEr-D, surat waspy üçin däpli deňlemek metriki, sözlemde sözlerin sany MS COCO Käpşenler sanynda has möhüm bolan sözleri üçin dogry işlemeýändir. Biz hem CIDEr Bu meseleyi geçirmek üçin, CIDEr-R'i tanyşdyrýarys, bu da CIDEr-D'i geliştirir we muny ýük sözlem uzunluğu warianslary bilen bermek üçin daha fleksibdir. Biz CIDEr DER Bizim netijelerimiz, kendi-Kritik Hat Eğitimi kullanarak, Gerçekten, CIDEr-D iyileştirildiğinde, üretilen käpşenlerin uzunluğu referens uzunluğuna benziyor. Bu şekilde modeller sözläniň uzunlygyny artmak üçin birnäçe gezek ayny sözläni gaýtalaýarlar.</abstract_tr>
      <abstract_af>Hierdie papier wys dat CIDEr-D, 'n tradisionele evaluasie metrie vir beeldbeskrywing nie goed werk op datastelle waar die nommer van woorde in die seting is betekenlik groter as wat in die MS COCO Kapitensies datastel is. Ons wys ook dat CIDEr-D die prestasie het deur die ontbreek van veelvuldige verwysing setinge en hoë verandering van sin lengte afgebreek. Om hierdie probleem te verbygaan, introduseer ons CIDEr-R, wat CIDEr-D verbeter, maak dit meer fleksibel in te handel met datastelle met hoë setlengte varians. Ons wys dat CIDEr-R is meer presies en naby aan menslike oordeel as CIDEr-D; CIDEr-R is meer kragtige aangaande die nommer van beskikbare verwysing. Ons resultate vertoon dat gebruik Self-Critical Sequence Training om CIDEr-R optimaliseer te genereer beskrywende titels. In kontras, wanneer Cider- D optimaliseer is, die genereerde titel se lengte tendeer na wees gelyk aan die verwysing lengte. Maar die modelles herhaal ook veelvuldige maal dieselfde woord om die setlingte te vermeerder.</abstract_af>
      <abstract_sq>Ky dokument tregon se CIDEr-D, një metrik tradicional vlerësimi për përshkrimin e imazhit, nuk funksionon siç duhet në grupet e të dhënave ku numri i fjalëve në fjalim është ndjeshëm më i madh se ato në grupin e të dhënave të kapitujve të MS COCO. Ne gjithashtu tregojmë se CIDEr-D ka shfaqje të penguara nga mungesa e fjalëve të shumëfishta të referimit dhe varianca e lartë e gjatësisë së fjalëve. Për të shmangur këtë problem, ne futim CIDEr-R, e cila përmirëson CIDEr-D, duke e bërë më fleksible në trajtimin e grupeve të dhënash me variancë të lartë të gjatësisë së fjalimit. Ne demonstrojmë se CIDEr-R është më i saktë dhe më afër gjykimit njerëzor se CIDEr-D; CIDEr-R është më i fortë lidhur me numrin e referencave të disponueshme. Rezultatet tona zbulojnë se përdorimi i trajnimit të Sekuencës Vetëkritike për të optimizuar CIDEr-R gjeneron tituj përshkrimtar. Në ndryshim, kur CIDEr-D është optimizuar, gjatësia e titujve të gjeneruar ka tendencë të jetë e ngjashme me gjatësinë e referencës. Megjithatë, modelet përsëriten gjithashtu disa herë të njëjtin fjalë për të rritur gjatësinë e fjalës.</abstract_sq>
      <abstract_bn>এই পত্রিকাটি দেখাচ্ছে যে সিআইডিয়ার-ডি, ছবির বর্ণনার জন্য একটি ঐতিহ্যবাহী মূল্য মেট্রিক, তথ্যের সংখ্যা সঠিকভাবে কাজ করে না, যেখানে বাক্যের সংখ্যা  আমরা একই সাথে দেখাচ্ছি যে সিআইডিয়ার-ডি কার্যক্রম বেশ কিছু লেখার অভাব এবং শাস্তির দীর্ঘ বিভিন্ন বিভিন্ন বিভিন্ন বি এই সমস্যাটি পাশ করার জন্য আমরা CIDEr-R পরিচয় প্রদান করি, যা সিডিয়ার-D এর উন্নতি প্রদান করে, যা ডাটাসেটের দীর্ঘদিনের মাধ্যমে ডাটা সেটের মাধ্যমে  আমরা দেখাচ্ছি যে সিডিয়ার-আর সিডিয়ার-ডির চেয়ে মানুষের বিচারের কাছে আরো কাছে; বিদ্যমান সংখ্যার সংখ্যা সম্পর্কে CIDEr-R বেশী রোবট। আমাদের ফলাফল প্রকাশ করে যে সিআইডিয়ার-আর অপ্রায়শিক্ষা করার জন্য স্বাধীন ক্রিয়াল সেকেন্স প্রশিক্ষণ ব্যবহার করে বিস্তারিত বিপরীতে, যখন CIDEr-D অপ্রাসঙ্গিক করা হয়, তৈরি করা শিরোনামের দীর্ঘকে রেফারেন্সের দীর্ঘের সাথে সমান। তবে মডেলগুলো একই শব্দে বেশ কয়েকবার বার বাড়িয়ে দেয়ার জন্য।</abstract_bn>
      <abstract_az>Bu kağıt göstərir ki, CIDEr-D, şəkillərin tanımlaması üçün nəticəli değerlendirmə metrik, cümlədə olan sözlərin sayı MS COCO başlıqları verilənlər qutusundan daha böyükdüyü verilən verilən qutularda düzgün çalışmır. Biz də göstəririk ki, CIDEr-D müxtəlif cümlələr və cümlələrin uzunluğunun yüksək dəyişiklik olmasına səbəb edilmiş performans. Bu problemi həddi aşmaq üçün, CIDEr-R'i tanıdırırıq ki, CIDEr-D'i daha yaxşılaşdırır, verilən qurğuları yüksək sözlərin uzunluğu dəyişiklikləri ilə qarşılaşdırmaq üçün daha fleksib olar. Biz CIDEr-R CIDEr-D-dən daha doğru və daha yaxın olduğunu göstəririk. CIDEr-R mövcud referans sayı haqqında daha qüvvətlidir. Bizim sonuçlarımız, CIDEr-R optimizlənmək üçün Öz-Kritik Sequence Eğitimi istifadə etmək üçün müəyyən edilən başlıqlar yaratdığını göstərir. Əksinə, CIDEr-D optimizləndikdə, ürəkləndirilmiş başlıqların uzunluğu referens uzunluğuna bənzəyir. Lakin modellər həmçinin cümlənin uzunluğunu artırmaq üçün bir neçə dəfə eyni sözü də tekrar edirlər.</abstract_az>
      <abstract_hy>Այս հոդվածը ցույց է տալիս, որ CIDEr-D, պատկերի նկարագրման ավանդական գնահատման մետրիկը, չի աշխատում ճիշտ տվյալների համակարգերի վրա, որտեղ նախադասության բառերի թիվը շատ ավելի մեծ է, քան այն բառերը, որոնք գտնվում են SM COCOCOCaption տվյալների Մենք նաև ցույց ենք տալիս, որ CIDEr-D-ն ունի արդյունքներ, որոնք խոչընդոտում են նախադասության երկարության բազմաթիվ վերաբերյալ նախադասությունների բացակայությունից և բարձր տարբերություններից: Այս խնդիրը խուսափելու համար մենք ներկայացնում ենք CIDEr-R-ը, որը բարելավում է CIDEr-D-ը, դարձնելով այն ավելի ճկուն տվյալների համակարգերի հետ կապված, որոնք բարձր նախադասության երկարության տարբերություն ունեն: Մենք ցույց ենք տալիս, որ CIDEr-R-ը ավելի ճշգրիտ է և ավելի մոտ է մարդկային դատողությանը, քան CIDEr-D-ը: CIDEr-R-ը ավելի ուժեղ է հասանելի հղումների քանակի վերաբերյալ: Մեր արդյունքները բացահայտում են, որ օգտագործելով ինքնաքննադատական հաջորդականության ուսումնասիրությունը CIDEr-R-ի օպտիմացման համար ստեղծում է նկարագրական վերնագրեր: Դրան հակառակ, երբ CIDEr-D-ը օպտիմացվում է, ստեղծված վերնագրերի երկարությունը հակված է նմանվել վերաբերյալ երկարությանը: Այնուամենայնիվ, մոդելները նույն բառը բազմաթիվ անգամ կրկնում են նախադասության երկարությունը աճելու համար:</abstract_hy>
      <abstract_ca>Aquest paper mostra que CIDEr-D, una metèrica tradicional d'evaluació de la descripció de la imatge, no funciona adequadament en conjunts de dades on el nombre de paraules de la frase és significativament més gran que el de la descripció de les Capcions de MS COCO. També demostram que el CIDEr-D té el rendiment obstruït per la falta de múltiples frases de referència i la gran variació de la llargada de frases. Per evitar aquest problema, introduïm CIDEr-R, que millora CIDEr-D, fent-ho més flexible en tractar amb conjunts de dades amb una gran variació de longitud de frases. Demonstrem que el CIDEr-R és més precis i més proper al judici humà que el CIDEr-D; CIDEr-R és més robust en relació al nombre de referències disponibles. Els nostres resultats revelen que utilitzar l'entrenament de seqüència autocrítica per optimitzar el CIDEr-R genera títulos descriptius. En canvi, quan CIDEr-D és optimitzat, la llargada dels títulos generats tendeix a ser similar a la llargada de referència. No obstant això, els models també repeten diverses vegades la mateixa paraula per augmentar la llargada de la frase.</abstract_ca>
      <abstract_bs>Ovaj papir pokazuje da CIDEr-D, tradicionalna procjena metrika za opis slika, ne funkcioniše kako treba na setima podataka gdje je broj riječi u rečenici značajno veći od onih u setu podataka MS COCO kapcija. Također pokazujemo da je CIDEr-D spriječio izvedbu zbog nedostatka višestrukih referentnih rečenica i visoke varijacije dužine rečenice. Da bismo prekinuli ovaj problem, predstavljamo CIDEr-R, koji poboljšava CIDEr-D, čini to fleksibilnijim u rješavanju seta podataka sa varijancijom dužine rečenice. Pokazujemo da je CIDEr-R precizniji i bliži ljudskoj presudi nego CIDEr-D; CIDEr-R je jači u vezi broja dostupnih referencija. Naši rezultati otkrivaju da korištenje treninga samozkritične sekvence za optimizaciju CIDEr-R stvara opisivne kapije. U suprotnom, kada se CIDEr-D optimizira, dužina proizvedenih naslova često je slična referentnoj dužini. Međutim, modeli također ponovljaju nekoliko puta iste riječi da bi povećali dužinu rečenice.</abstract_bs>
      <abstract_fi>Tämä artikkeli osoittaa, että CIDER-D, perinteinen kuvankuvauksen arviointimetriikka, ei toimi kunnolla aineistoissa, joissa lauseen sanojen määrä on huomattavasti suurempi kuin MS COCO Captions -aineistossa. Osoitamme myös, että CIDer-D:n suorituskykyä haittaavat usean viitelauseen puute ja lauseen pituuden suuri vaihtelu. Tämän ongelman ohittamiseksi esittelemme CIDer-R:n, joka parantaa CIDer-D:tä ja tekee siitä joustavamman käsitellä datakokonaisuuksia, joilla on suuri lauseen pituus varianssi. Osoitamme, että CIDER-R on tarkempi ja lähempänä ihmisen arviointia kuin CIDER-D; CIDer-R on vankempi saatavilla olevien viitteiden määrän suhteen. Tuloksemme osoittavat, että itsekriittisen sekvenssikoulutuksen käyttäminen CIDer-R:n optimointiin tuottaa kuvailevia tekstityksiä. Sitä vastoin, kun CIDer-D on optimoitu, luotujen tekstitysten pituus on yleensä samanlainen kuin viitepituus. Mallit kuitenkin toistavat useita kertoja saman sanan pidentääkseen lauseen pituutta.</abstract_fi>
      <abstract_am>ይህ ገጽ CIDEr-D, የባሕላዊ የኢሜএস ኮ አካላት ዳታ ማህበረሰብ በሚያሳየው ዳታተሮችን በሚያስተካክሉ መክፈት ውስጥ የቃላት ቁጥር በሚያበዛበት ከዳታ አይሠራም፡፡ እናም የCIDER-D ድምፅ በብዛት የሥርዓት ግንኙነት እና የፍርድ ርዝመት ከፍተኛ ውይይት እንዳስደነቀው እናሳየዋለን፡፡ ይህንን ጉዳይ ለመለፍ CIDEr-R እናሳውቃለን፡፡ CIDEr-R ከCIDEr-D ይልቅ ለሰው ፍርድ በጣም የቀረበ እንደሆነ እናስታውቃለን፤ ምርጫዎች ፍሬዎቻችን የራሳቸውን የክስርዓት ትምህርት ማቀናጃ ለመሻለል CIDEr-R የሚያስፈልገውን ግልፅ የሚያደርጋል፡፡ በተለካ ጊዜ CIDEr-D በተለየ ጊዜ የፍጥረቱ ርዝመት የፊደል ርዝመት በመስመር ይታያል። ነገር ግን ሞዴላዎቹ ደግሞ የፍርዱን ርዝመት እንዲጨምር በአንድ ቃል ብዙ ጊዜ ይደጋግማሉ።</abstract_am>
      <abstract_et>Käesolev töö näitab, et CIDER-D, traditsiooniline pildi kirjeldamise hindamismeeter, ei tööta korralikult andmekogumites, mille sõnade arv lauses on märkimisväärselt suurem kui MS COCO pealkirjade andmekogumis. Samuti näitame, et CIDER-D sooritust takistavad mitmekordsete võrdluslausete puudumine ja lausepikkuse suur varieeruvus. Sellest probleemist mööda hiilimiseks tutvustame CIDER-R, mis parandab CIDER-D-d, muutes selle paindlikumaks suure lausepikkuse hälvega andmekogumitega tegelemisel. Me näitame, et CIDER-R on täpsem ja lähemal inimese hinnangule kui CIDER-D; CIDER-R on kättesaadavate viidete arvu osas tugevam. Meie tulemused näitavad, et enesekriitilise järjestuse koolituse kasutamine CIDER-R optimeerimiseks tekitab kirjeldavaid pealkirju. Seevastu CIDER-D optimeerimisel kipub loodud pealdiste pikkus olema sarnane võrdluspikkusega. Kuid mudelid kordavad ka mitu korda sama sõna lause pikkuse suurendamiseks.</abstract_et>
      <abstract_cs>Tento článek ukazuje, že CIDEr-D, tradiční hodnotící metrika pro popis obrazu, nefunguje správně na datových sadách, kde je počet slov ve větě výrazně vyšší než v datové sadě MS COCO Titions. Dále ukazujeme, že CIDEr-D má výkon omezený nedostatkem více referenčních vět a vysokým rozptylem délky věty. Abychom tento problém obešli, představujeme CIDEr-R, který zlepšuje CIDEr-D, čímž je flexibilnější při řešení datových sad s vysokým rozptylem délky věty. Dokazujeme, že CIDEr-R je přesnější a blíže lidskému úsudku než CIDEr-D; CIDEr-R je robustnější, pokud jde o počet dostupných referencí. Naše výsledky ukazují, že použití Self-Critical Sequence Training k optimalizaci CIDEr-R generuje popisné titulky. Naproti tomu, když je CIDEr-D optimalizován, délka generovaných titulků má tendenci být podobná referenční délce. Modely však také opakují několikrát stejné slovo, aby se zvýšila délka věty.</abstract_cs>
      <abstract_ha>Wannan takardar na nuna cewa, CIDAr-D, wata metriki mai ƙidãya wa misalin zane na daban, bã ya aiki properly a kan daidaita tsaro, inda ƙidãyar maganar da ke cikin gargaɗin na yi girma mai girma daga waɗanda ke cikin tsarin na MACO. Tuna nuna cewa CIDAr-D ya yi mataimaki ko kuma ba da haske da saurin mutane mãsu yawa da kuma tsakanin cire tsawo. Domin ka gudu da wannan mataimaki, za mu ƙara CIDAr-R, wadda ke kyautata CIDAr-D, kana sanya shi mafi fleksibo ga ka yi danganta da daidaita danne-danne da variant tsawo na gefen. Muna nũna cCIDAr-R ne mafi gaskiya kuma mafi kusanta ga hukuncin mutum daga CIDAr-D; CIDEr-R is more robust regarding the number of available references.  MatamayinMu na bayyana cewa, a yi amfani da Shirin na Tayyar da Self-Kikritisk zuwa a buƙata, CIDAr-R na zaɓi wasu keɓanni na descriptive. In da tsoho, idan an yi amfani da CIDAr-D, tsawo wa sunan keɓanni da aka ƙãga, ya zama daidai da tsawo na fassaran. A lokacin da, misãlai yana dubu sau biyu da shi ga ƙara cire.</abstract_ha>
      <abstract_he>העבודה הזאת מראה כי CIDEr-D, מטריקת הערכה מסורתית לתיאור התמונה, לא עובדת כראוי על קבוצות נתונים שבו מספר המילים במשפט גדול באופן משמעותי מאלה שבקבוצת נתונים של קוקו MS. אנחנו גם מראים כי CIDEr-D יש ביצועים מוחסמים על ידי חוסר משפטים רבים בהייחסות וגבוהה של אורך המשפט. To bypass this problem, we introduce CIDEr-R, which improves CIDEr-D, making it more flexible in dealing with datasets with high sentence length variance.  אנחנו מוכיחים כי CIDEr-R יותר מדויק וקרוב לשיפוט אנושי מאשר CIDEr-D; CIDEr-R הוא חזק יותר בנוגע למספר התייחסות זמינות. התוצאות שלנו מראות שהשימוש באימוני רצף קריטי עצמי כדי לאופטיזם CIDEr-R יוצר כותרות תיאור. בניגוד לזה, כאשר CIDEr-D אופטימיזם, אורך הכותבים הנוצרים נוטה להיות דומה לאורך התייחס. עם זאת, הדוגמנים חוזרים גם מספר פעמים את אותה מילה כדי להעלות את אורך המשפט.</abstract_he>
      <abstract_jv>Perintah sing paling iki, CIDEr-D, dadi bener pancening metik kanggo Keterangan gambar, gak bener dataset sing gak bener @DER Tool Options, Layersdock Awak dhéwé éntukno CIDEr-R wis akèh barêng lan tambah kapan uwong luwih karo CIDEr-D; lan tambah kuwi mau CIDEr-R mbutuhak sing paling nggawe barang manung Rejalaké awak dhéwé ngerasakno ngono nggawe Self-criteric Seyenge Learning nggawe nyimpen CIDEr-R nggawe barang akeh basa gambaran drawable-action Nanging, model kuwi bisa diguwarpi kabeh wektu kelas telu, dadi kapan tanggal kuwi.</abstract_jv>
      <abstract_sk>Ta prispevek kaže, da CIDER-D, tradicionalna merila ocenjevanja za opis slik, ne deluje pravilno na naborih podatkov, pri katerih je število besed v stavku bistveno večje od besed v naboru podatkov MS COCO Captions. Pokazali smo tudi, da ima CIDER-D zmogljivost ovira pomanjkanje večkratnih referenčnih stavkov in visoka varianca dolžine stavka. Da bi izognili težavo, uvajamo CIDER-R, ki izboljšuje CIDER-D, zaradi česar je prilagodljivejši pri obravnavi naborov podatkov z visoko varianco dolžine stavka. Dokazujemo, da je CIDER-R natančnejši in bližje človeški presoji kot CIDER-D; CIDER-R je trdnejši glede na število razpoložljivih referenc. Naši rezultati kažejo, da uporaba samokritičnega usposabljanja za optimizacijo CIDER-R ustvarja opisne napise. Nasprotno, ko je CIDER-D optimiziran, je dolžina ustvarjenih napisov običajno podobna referenčni dolžini. Vendar pa modeli tudi večkrat ponavljajo isto besedo, da povečajo dolžino stavka.</abstract_sk>
      <abstract_bo>This paper shows that CIDEr-D, a traditional evaluation metric for image description, does not work properly on datasets where the number of words in the sentence is significantly greater than those in the MS COCO Captions dataset. This paper shows that CIDEr-D, a traditional evaluation metric for image description, does not work properly on datasets where the number of words in the sentence is significantly greater than those in the MS COCO Captions dataset. ང་ཚོས་CIDEr-D་ལྟ་བུའི་མཐུན་སྣེ་ཚོར་མང་པོ་ཞིག་ཡོད་པའི་ཚིག་རྟགས་མང་པོ་ཞིག་བྱས་ཡོད། To bypass this problem, we introduce CIDEr-R, which improves CIDEr-D, making it more flexible in dealing with datasets with high sentence length variance. ང་ཚོས་CIDEr-R་དང་མི་མང་གི་ཉེ་མཐོང་ཚད་CIDEr-D་ལས་ཉེ་མཐོང་བ་ཡིན་པ་ཤར་བྱེད། CIDEr-R ནི་ཐོབ་པའི་ཁུངས་གཏོང་གི་ཨང་གྲངས་སྐོར་ཡུལ་ཆེན་ཡིན། ང་ཚོའི་འབྲས་བུ In contrast, when CIDEr-D is optimized, the generated captions' length tends to be similar to the reference length. འོན་ཀྱང་། མིག་ལམ་དེ་ཚིག་ཚིག་ཚིག་རྩིས་པ་ལ་གཅིག་པ་རྒྱ་བསྐྱེད་ཚད་གཅིག་པ་མཚུངས་རེད།</abstract_bo>
      </paper>
    <paper id="42">
      <title>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</title>
      <author><first>Shubhanshu</first><last>Mishra</last></author>
      <author><first>Aria</first><last>Haghighi</last></author>
      <pages>381–388</pages>
      <abstract>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation. Our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on source language task data and evaluate the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> in the target language. In particular, we focus on language pairs where <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> is difficult for mBERT : those where source and target languages are different in script, <a href="https://en.wikipedia.org/wiki/Vocabulary">vocabulary</a>, and <a href="https://en.wikipedia.org/wiki/Linguistic_typology">linguistic typology</a>. We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from <a href="https://en.wikipedia.org/wiki/English_language">English</a> to <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>, and <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> on two social media tasks : NER (a 37 % average relative improvement in F1 across target languages) and sentiment classification (12 % relative improvement in F1) on social media text, while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7 % relative improvement in accuracy). Our results are promising given the lack of social media bitext corpus. Our code can be found at : https://github.com/twitter-research/multilingual-alignment-tpp.</abstract>
      <url hash="d9d16d6b">2021.wnut-1.42</url>
      <bibkey>mishra-haghighi-2021-improved</bibkey>
      <doi>10.18653/v1/2021.wnut-1.42</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimatrix">WikiMatrix</pwcdataset>
    <title_es>Preentrenamiento mejorado del modelo lingüístico multilingüe para textos de redes sociales mediante la predicción de pares de traducción</title_es>
      <title_fr>Préapprentissage amélioré du modèle linguistique multilingue pour le texte de médias sociaux via la prédiction de paires de traductions</title_fr>
      <title_ar>تم تحسين نموذج اللغة متعدد اللغات للتدريب المسبق على نص وسائل التواصل الاجتماعي من خلال توقع أزواج الترجمة</title_ar>
      <title_pt>Pré-treinamento aprimorado do modelo de idioma multilíngue para texto de mídia social por meio da previsão de pares de tradução</title_pt>
      <title_hi>अनुवाद जोड़ी भविष्यवाणी के माध्यम से सामाजिक मीडिया पाठ के लिए बेहतर बहुभाषी भाषा मॉडल Pretraining</title_hi>
      <title_ja>翻訳ペア予測によるソーシャルメディアテキストの多言語モデルの事前トレーニングの改善</title_ja>
      <title_zh>译对测改社交媒体文本多言模预训练</title_zh>
      <title_ru>Улучшенная многоязычная языковая модель предварительного обучения для текста в социальных сетях с помощью предсказания пары переводов</title_ru>
      <title_ga>Samhail Teanga Ilteangach Feabhsaithe Réamhoiliúint le haghaidh Téacs Meáin Shóisialta trí Thuar Péire Aistriúcháin</title_ga>
      <title_hu>Továbbfejlesztett többnyelvű nyelvi modell a közösségi média szövegének előkészítése fordítási pár előrejelzésével</title_hu>
      <title_ka>მრავალენგური სახელის მოდელის შესაბამისი საზოგადომი მედიატის ტექსტის შესაბამისი შესაბამისი შესაბამისი შესაბამისი მრავალენგური მოდელიName</title_ka>
      <title_el>Βελτιωμένη προετοιμασία πολυγλωσσικού μοντέλου γλώσσας για κείμενο κοινωνικών μέσων μέσω πρόβλεψης ζευγαριού μετάφρασης</title_el>
      <title_it>Modello linguistico multilingue migliorato Pretraining per il testo dei social media tramite la previsione della coppia di traduzioni</title_it>
      <title_kk>Қолданысты тіл үлгісін жақсы түрлендіру үлгісі Ақпараттың мәтініне аудару парақтың алдындағы көптеген тіл үлгісін өзгерту</title_kk>
      <title_lt>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</title_lt>
      <title_mk>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</title_mk>
      <title_mt>It-Titjib fil-Mudell Multilingwi ta’ Tħarriġ għal Test tal-Midja Soċjali permezz tat-Tbassir tal-Pawġi tat-Traduzzjoni</title_mt>
      <title_ms>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</title_ms>
      <title_ml>സോഷ്യല്‍ മീഡിയയുടെ പദാവലിയ്ക്കുള്ള വാചകത്തിനുള്ള മുന്‍ഗ്രേനിപ്പു് മെച്ചപ്പെടുത്തിയ പല ഭാഷ മ</title_ml>
      <title_mn>Олон хэл хэл загварын хөгжүүлэг Нийгмийн Мэдээлэл Мэдээлэл Мэдээлэл Мэдээлэл Мэдээлэл Мэдээлэл Мэдээлэл</title_mn>
      <title_no>Forbetra fleirspråk- modellen Omsetjingsmodul for sosiale media- tekst gjennom omsetjingsmodul</title_no>
      <title_sr>Poboljšan multijezički model pretvaranja za socijalni medijski tekst preko predviđanja par prevoda</title_sr>
      <title_ro>Modelul lingvistic multilingv îmbunătățit Pretraining pentru textul social media prin predicția perechii de traduceri</title_ro>
      <title_pl>Ulepszone wstępne szkolenie wielojęzycznego modelu językowego dla tekstu w mediach społecznościowych poprzez predykcję pary tłumaczeń</title_pl>
      <title_si>සාමාජික මිඩියාව පාළුව සඳහා ගොඩක් භාෂාවික භාෂාවක් මොඩේල් ප්‍රීට්‍රීන් කරනවා</title_si>
      <title_so>Horumarinta u diyaarinta qoraalka macluumaadka sooshalka ee horumarinta qoraalka luuqadaha kala duduwan</title_so>
      <title_ur>سوسیل میڈیا ٹیکسٹ کے لئے بہت سی زبان کی موڈل تحریرینڈ کیے جاتے ہیں</title_ur>
      <title_sv>Förbättrad flerspråkig språkmodell Pretraining för sociala medier text via översättningspar förutsägelse</title_sv>
      <title_ta>Name</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Cách chuẩn ngôn ngữ đa dạng tốt hơn Hình thức chờ truyền thông xã hội văn bản thông qua dự đoán cặp đôi dịch</title_vi>
      <title_hr>Poboljšan multijezički model pretvaranja za tekst socijalnih medija putem predviđenja par prevoda</title_hr>
      <title_da>Forbedret flersproget sprogmodel, der foregiver tekst på sociale medier via forudsigelse af oversættelsespar</title_da>
      <title_bg>Подобрено многоезично езиково обучение за текст в социалните медии чрез прогноза за двойка преводи</title_bg>
      <title_nl>Verbeterde meertalige taalmodel pretraining voor sociale media tekst via vertaalpaar voorspelling</title_nl>
      <title_fa>Model Multilingual Language Improved Pretraining for Social Media Text via Translation Pair Prediction</title_fa>
      <title_id>Model Bahasa Berbahasa Diperkembangkan Melakukan Teks Media Sosial melalui Prediksi Pasangan Terjemahan</title_id>
      <title_de>Verbesserte mehrsprachige Sprachmodellvorbereitung für Social Media Text durch Translation Pair Prediction</title_de>
      <title_tr>Çoklu dilli Diller Modeli Sosial Media Metini terjime Parlaky</title_tr>
      <title_ko>예측 기반의 소셜 미디어 텍스트 다국어 언어 사전 훈련 모델 개선</title_ko>
      <title_sw>Tayarisho la Utamaduni wa Lugha za Kiingereza kwa ajili ya Maandishi ya Mitandao ya Kijamii kupitia Utafiti wa Tafsiri Pair</title_sw>
      <title_af>Geverbeterde Veelvuldige Taal Model Verskyning vir Sosiale Media Teks deur Vertaling Pair Voorwoording</title_af>
      <title_sq>Modeli i përmirësuar i gjuhës me shumëgjuhë duke paraqitur tekstin e medias sociale nëpërmjet parashikimit të çiftit të përkthimit</title_sq>
      <title_am>ማኅበራዊ ሚዲያ ጽሑፍ በመትርጉም Pair Preferences</title_am>
      <title_bn>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</title_bn>
      <title_bs>Poboljšan multijezički model pretvaranja za socijalni medijski tekst preko predviđanja par prevoda</title_bs>
      <title_hy>Բազլեզու մոդելը բարելավված սոցիալական լրատվամիջոցների տեքստի համար թարգմանման զույգերի կանխատեսման միջոցով</title_hy>
      <title_az>칂eviri T톛rc칲m톛 캻칞in 칐yr톛nm톛si vasit톛sil톛 Sosyal Media Metni 칲칞칲n 칞oxlu dil Modeli</title_az>
      <title_cs>Vylepšené předškolení modelu vícejazyčného jazyka pro text sociálních médií prostřednictvím predikce překladových párů</title_cs>
      <title_et>Täiustatud mitmekeelse keelemudeli eelõpetamine sotsiaalmeedia tekstile tõlkepaari prognoosi kaudu</title_et>
      <title_fi>Parannettu monikielinen kielimalli esikoulutus sosiaalisen median tekstiin käännösparin avulla</title_fi>
      <title_ca>Model Multilingüe millorat de pretensió del text dels mitjans socials mitjançant predicció de parelles de traducció</title_ca>
      <title_jv>Ngawe ngubah layang Mulang</title_jv>
      <title_ha>@ action</title_ha>
      <title_he>מודל שפת רבות שפות משפר מתאמן לטקסט מדיה חברתית דרך ציון זוג תרגום</title_he>
      <title_sk>Izboljšano predvajanje večjezičnega jezikovnega modela za besedilo na družbenih omrežjih prek napovedi prevajalskih parov</title_sk>
      <title_bo>སྤྱི་ཚོགས་འབྲེལ་མཐུད་ཡིག་གཟུགས་ཀྱི་སྐད་རིགས་མ་དབྱིབས་ཡར་རྒྱས་གཏོང་ཀྱི་ཡིག་ཆ་དང་བསྟུན</title_bo>
      <abstract_ar>نقوم بتقييم نهج بسيط لتحسين النقل متعدد اللغات لـ mBERT على مجموعة وسائل التواصل الاجتماعي من خلال إضافة مهمة ما قبل التدريب تسمى التنبؤ بزوج الترجمة (TPP) ، والتي تتنبأ بما إذا كان زوج من النصوص متعددة اللغات ترجمة صحيحة. يفترض نهجنا الوصول إلى الترجمات (الدقيقة أو التقريبية) بين أزواج لغة المصدر والهدف ، حيث نقوم بضبط نموذج على بيانات مهمة لغة المصدر وتقييم النموذج في اللغة الهدف. على وجه الخصوص ، نركز على الأزواج اللغوية التي يصعب فيها نقل التعلم على mBERT: تلك التي تختلف فيها اللغات المصدر والهدف في النص والمفردات والتصنيف اللغوي. نعرض تحسينات من التدريب المسبق عبر بروتوكول TPP على mBERT وحده في النقل بدون طلقة من الإنجليزية إلى الهندية والعربية واليابانية في مهمتين لوسائل التواصل الاجتماعي: NER (متوسط التحسن النسبي 37٪ في F1 عبر اللغات المستهدفة) وتصنيف المشاعر (12٪ نسبي) التحسين في F1) على نصوص وسائل التواصل الاجتماعي ، بينما يتم أيضًا قياس الأداء على مهمة وسائط غير اجتماعية تتمثل في وضع علامات POS للاعتماد العالمي (تحسن نسبي بنسبة 6.7 ٪ في الدقة). نتائجنا واعدة بالنظر إلى نقص نصوص الوسائط الاجتماعية. يمكن العثور على الكود الخاص بنا على: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ar>
      <abstract_fr>Nous évaluons une approche simple pour améliorer le transfert multilingue zero-shot de MBerT sur le corpus de médias sociaux en ajoutant une tâche de pré-apprentissage appelée prédiction de paires de traductions (TPP), qui prédit si une paire de textes multilingues est une traduction valide. Notre approche suppose l'accès aux traductions (exactes ou approximatives) entre les paires de langues source-cible, où nous affinons un modèle sur les données de tâche de la langue source et évaluons le modèle dans la langue cible. En particulier, nous nous concentrons sur les paires de langues dans lesquelles l'apprentissage par transfert est difficile pour MBerT : celles où les langues source et cible sont différentes en termes d'écriture, de vocabulaire et de typologie linguistique. Nous montrons des améliorations par rapport à la pré-formation TPP par rapport au mBERt seul dans le transfert zéro de l'anglais vers l'hindi, l'arabe et le japonais sur deux tâches liées aux réseaux sociaux : NER (une amélioration relative moyenne de 37 % en F1 dans les langues cibles) et la classification des sentiments (amélioration relative de 12 % en F1) sur les textes des réseaux sociaux, tandis que également une analyse comparative sur une tâche non liée aux médias sociaux de marquage Universal Dependency POS (amélioration relative de 6,7 % de la précision). Nos résultats sont prometteurs compte tenu de l'absence de corpus bitexte sur les réseaux sociaux. Notre code se trouve à l'adresse suivante : https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_fr>
      <abstract_es>Evaluamos un enfoque simple para mejorar la transferencia multilingüe de mBert en el corpus de las redes sociales mediante la adición de una tarea de preentrenamiento llamada predicción de pares de traducción (TPP), que predice si un par de textos en varios idiomas son una traducción válida. Nuestro enfoque supone el acceso a las traducciones (exactas o aproximadas) entre las combinaciones de idiomas de origen y destino, en las que ajustamos un modelo sobre los datos de tareas del idioma de origen y evaluamos el modelo en el idioma de destino. En particular, nos centramos en los pares de idiomas en los que el aprendizaje por transferencia es difícil para MBert: aquellos en los que los idiomas de origen y de destino son diferentes en escritura, vocabulario y tipología lingüística. Mostramos mejoras del preentrenamiento del TPP sobre mBert solo en la transferencia cero del inglés al hindi, el árabe y el japonés en dos tareas de redes sociales: NER (una mejora relativa promedio del 37% en F1 en todos los idiomas de destino) y la clasificación de sentimientos (mejora relativa del 12% en F1) en los textos de las redes sociales, mientras que También se realiza una evaluación comparativa en una tarea no social de etiquetado POS de Dependencia Universal (mejora relativa del 6,7% en la precisión). Nuestros resultados son prometedores dada la falta de corpus bitext en las redes sociales. Puede encontrar nuestro código en: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_es>
      <abstract_pt>Avaliamos uma abordagem simples para melhorar a transferência multilíngue de tiro zero de mBERT no corpus de mídia social, adicionando uma tarefa de pré-treinamento chamada previsão de pares de tradução (TPP), que prevê se um par de textos multilíngues é uma tradução válida. Nossa abordagem pressupõe o acesso a traduções (exatas ou aproximadas) entre pares de idiomas de origem-destino, onde ajustamos um modelo nos dados da tarefa do idioma de origem e avaliamos o modelo no idioma de destino. Em particular, nos concentramos em pares de idiomas onde a transferência de aprendizagem é difícil para o mBERT: aqueles em que os idiomas de origem e de destino são diferentes em script, vocabulário e tipologia linguística. Mostramos melhorias do pré-treinamento TPP em relação ao mBERT sozinho na transferência zero-shot de inglês para hindi, árabe e japonês em duas tarefas de mídia social: NER (uma melhoria relativa média de 37% na F1 em todos os idiomas de destino) e classificação de sentimento (12% relativo melhoria em F1) no texto de mídia social, ao mesmo tempo em que faz benchmarking em uma tarefa de mídia não social de marcação de POS de Dependência Universal (melhoria relativa de 6,7% na precisão). Nossos resultados são promissores, dada a falta de corpus bitexto de mídia social. Nosso código pode ser encontrado em: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_pt>
      <abstract_ja>私たちは、翻訳ペア予測（ TPP ）と呼ばれる事前トレーニングタスクを追加して、ソーシャルメディアコーパス上のmBERTのゼロショット多言語転送を改善するための単純なアプローチを評価します。これは、一対のクロスリンガルテキストが有効な翻訳であるかどうかを予測します。 私たちのアプローチは、ソース-ターゲット言語ペア間の翻訳（正確または近似）へのアクセスを前提としており、ソース言語タスクデータのモデルを微調整し、ターゲット言語のモデルを評価します。 特に、mBERTにとって転送学習が困難な言語ペアに焦点を当てています。これは、ソース言語とターゲット言語がスクリプト、ボキャブラリー、言語類型で異なるものです。 私たちは、英語からヒンディー語、アラビア語、日本語へのゼロショット転送におけるmBERT単独でのTPP事前トレーニングから、2つのソーシャルメディアタスクの改善を示しています。NER （ターゲット言語間でのF 1の平均相対的な改善）とセンチメント分類（ F 1の12 ％相対的な改善）ですが、ユニバーサル依存性POSタグ付けの非ソーシャルメディアタスクのベンチマーク（精度の6.7 ％相対的な改善）。 ソーシャルメディアのビットテキストコーパスがないため、私たちの結果は有望です。 コードは、https://github.com/twitter-research/multilingual-alignment-tppでご覧いただけます。</abstract_ja>
      <abstract_zh>评一简之法,添一谓之译(TPP)预训练任务以改社交媒体语料库上mBERT零次多言传输,当占跨语言文本非效也。 吾法设访源-语言间译(精确近),对源语数为微调,并以招言质模。 专于mBERT难移学语对:语言在脚本,词汇与言类型学异者是也。 二社交媒体之任,自英语至于印地语、阿拉伯语、日语之零镜头传输,TPP 预训练比 mBERT 有所改善:NER(言 F1 之均改为 37%)、社交媒体文本之情类(F1 相对改入 12%),而通用赖 POS 标记之非社交媒体以准试(准确性相高 6.7%)。 鉴无社交媒体双文本语料库,我实有望。 吾代码得下位:https://github.com/twitter-research/multilingual-alignment-tpp。</abstract_zh>
      <abstract_hi>हम अनुवाद जोड़ी भविष्यवाणी (टीपीपी) नामक एक प्रीट्रेनिंग कार्य जोड़कर सोशल मीडिया कॉर्पस पर mBERT के शून्य-शॉट बहुभाषी हस्तांतरण में सुधार करने के लिए एक सरल दृष्टिकोण का मूल्यांकन करते हैं, जो भविष्यवाणी करता है कि क्रॉस-भाषी ग्रंथों की एक जोड़ी एक वैध अनुवाद है या नहीं। हमारा दृष्टिकोण स्रोत-लक्ष्य भाषा जोड़े के बीच अनुवाद (सटीक या अनुमानित) तक पहुंच मानता है, जहां हम स्रोत भाषा कार्य डेटा पर एक मॉडल को ठीक करते हैं और लक्ष्य भाषा में मॉडल का मूल्यांकन करते हैं। विशेष रूप से, हम भाषा जोड़े पर ध्यान केंद्रित करते हैं जहां हस्तांतरण सीखना mBERT के लिए मुश्किल है: जहां स्रोत और लक्ष्य भाषाएं स्क्रिप्ट, शब्दावली और भाषाई टाइपोलॉजी में अलग-अलग हैं। हम दो सोशल मीडिया कार्यों पर अंग्रेजी से हिंदी, अरबी और जापानी में शून्य-शॉट हस्तांतरण में अकेले mBERT पर TPP pretraining से सुधार दिखाते हैं: एनईआर (लक्ष्य भाषाओं में F1 में 37% औसत सापेक्ष सुधार) और सोशल मीडिया पाठ पर भावना वर्गीकरण (F1 में 12% सापेक्ष सुधार), जबकि यूनिवर्सल निर्भरता पीओएस टैगिंग (सटीकता में 6.7% सापेक्ष सुधार) के गैर-सोशल मीडिया कार्य पर भी बेंचमार्किंग करते हैं। हमारे परिणाम सामाजिक मीडिया bitext कॉर्पस की कमी को देखते हुए आशाजनक हैं. हमारा कोड पर पाया जा सकता है: https://github.com/twitter-research/multilingual-alignment-tpp।</abstract_hi>
      <abstract_ru>Мы оцениваем простой подход к улучшению многоязычной передачи mBERT с нулевым снимком в корпусе социальных сетей, добавляя задачу предварительного обучения, называемую прогнозированием пары переводов (TPP), которая предсказывает, является ли пара межязычных текстов допустимым переводом. Наш подход предполагает доступ к переводам (точным или приблизительным) между исходными и целевыми языковыми парами, где мы тонко настраиваем модель на исходные языковые данные задачи и оцениваем модель на целевом языке. В частности, мы фокусируемся на языковых парах, где обучение переносу трудно для mBERT: тех, где исходные и целевые языки различны по написанию, лексике и лингвистической типологии. Мы демонстрируем улучшения от предварительного обучения TPP по сравнению с mBERT только в передаче нулевого выстрела с английского на хинди, арабский и японский по двум задачам социальных сетей: NER (среднее относительное улучшение на 37% в F1 для целевых языков) и классификация настроений (относительное улучшение на 12% в F1) в тексте социальных сетей, а также сравнение с задачей несоциальных СМИ, связанной с маркировкой POS-терминалов с универсальной зависимостью (относительное улучшение точности на 6,7%). Наши результаты многообещающие, учитывая отсутствие битекста в социальных сетях. Наш код можно найти по адресу: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ru>
      <abstract_ga>Déanaimid meastóireacht ar chur chuige simplí maidir le feabhas a chur ar aistriú ilteangach mBERT ar chorpas na meán sóisialta trí thasc réamhoiliúint a chur leis ar a dtugtar tuar péirí aistriúcháin (TPP), a thuar cé acu is aistriúchán bailí iad péire de théacsanna tras-teangacha. Glacann ár gcur chuige rochtain ar aistriúcháin (beacht nó gar) idir péirí teangacha foinse-sprioc, áit a ndéanaimid mionchoigeartú ar shamhail ar shonraí tascanna teanga foinse agus ina ndéanaimid measúnú ar an múnla sa sprioctheanga. Dírímid go háirithe ar phéirí teanga ina bhfuil foghlaim aistrithe deacair do mBERT: iad siúd ina bhfuil foinsí agus sprioctheangacha difriúil ó thaobh scripte, stór focal agus tíopeolaíocht theangeolaíoch. Léirímid feabhsuithe ó réamhoiliúint TPP thar mBERT amháin in aistriú nialasach ó Bhéarla go Hiondúis, san Araibis agus sa tSeapáinis ar dhá thasc meán sóisialta: NER (feabhsú coibhneasta meánach 37% ar F1 thar sprioctheangacha) agus aicmiú meon (12% coibhneasta). feabhas ar F1) ar théacs na meán sóisialta, agus tagarmharcáil á dhéanamh freisin ar thasc neamhshóisialta de chlibeáil POS Spleáchais Uilíoch (feabhsú coibhneasta 6.7% ar chruinneas). Tá ár dtorthaí tuar dóchais inti mar gheall ar an easpa corpas bíothéacs ar na meáin shóisialta. Is féidir ár gcód a fháil ag: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ga>
      <abstract_ka>ჩვენ გავამუშავებთ უფრო საერთო პროგრამა, რომ mBERT-ის მულტი ენგრამეტური გადატანისათვის სოციალური მედია კოპუსში, რომელიც დამატებით უფრო მუშაობელი რაოდენობა, რომელიც განსაზღვრება, თუ კრესი ენგრა ჩვენი პროგრამის შესაძლებლობა წარმოიდგინდება შესაძლებლობა (მარტივი ან დასაწყებელი) მსოფლიო ენის ზოგების შორის, სადაც ჩვენ მსოფლიო ენის მონაცემების მონაცემების მოდენ განსაკუთრებულია, ჩვენ ვიყავით ენახის ზოგზე, სადაც ტრანსპერტის სწავლება mBERT-ისთვის ძალიან რთულია: სადაც მსოფლიო და მინიშვნელოვანი ენახი სკრიპტი, სიტყვა ჩვენ აჩვენებთ TPP-დან უკეთესია, რომელიც mBERT-ზე უკეთესია ნულ-სტრანსტრენსტში ინგლისდან, აპაბიდან და იაპონური ორი საზოგადო მედიაში: NER (საზოგადო მუშაო მედიაში 37% უკეთესი უკეთესია F1-ში უკეთესი მაგრამ სოციალური მისამართლეობის POS-ის ჩანაწერის არსოციალური მედიაზე (6.7%-ის შესაბამისი დამატება). ნაქთრვ პვჱსლრართ ჟვ ჲბვღაგარ, ჱაღჲრჲ ჟჲუთალნთრვ მვეთ ნვ ჟა სბთრთ კჲპოსჟ. ჩვენი კოდის შესაძლებელია: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ka>
      <abstract_el>Αξιολογούμε μια απλή προσέγγιση για τη βελτίωση της μηδενικής πολυγλωσσικής μεταφοράς του στο σώμα κοινωνικών μέσων προσθέτοντας μια εργασία προεπιλογής που ονομάζεται πρόβλεψη ζευγαριού μετάφρασης (η οποία προβλέπει εάν ένα ζευγάρι διαγώνινων κειμένων είναι έγκυρη μετάφραση. Η προσέγγισή μας προϋποθέτει πρόσβαση σε μεταφράσεις (ακριβείς ή κατά προσέγγιση) μεταξύ ζευγαριών γλώσσας προέλευσης-στόχου, όπου συντονίζουμε ένα μοντέλο σε δεδομένα εργασιών γλώσσας προέλευσης και αξιολογούμε το μοντέλο στη γλώσσα-στόχο. Ειδικότερα, εστιάζουμε σε γλωσσικά ζεύγη όπου η εκμάθηση μεταφοράς είναι δύσκολη για το ΜBERT: εκείνα όπου οι γλώσσες προέλευσης και στόχου διαφέρουν στη γραφή, το λεξιλόγιο και τη γλωσσική τυπολογία. Παρουσιάζουμε βελτιώσεις από την προεπιλογή TPP πέρα από το mBERT μόνο σε μεταφορά μηδενικού πυροβολισμού από τα αγγλικά στα Χίντι, τα αραβικά και τα ιαπωνικά σε δύο εργασίες κοινωνικής δικτύωσης: NER (μια 37% μέση σχετική βελτίωση στο F1 στις γλώσσες στόχων) και ταξινόμηση συναισθημάτων (12% σχετική βελτίωση στο F1) στο κείμενο των μέσων κοινωνικής δικτύωσης, ενώ επίσης συγκριτική αξιολόγηση σχετικά με μια εργασία μη κοινωνικής δικτύωσης της σήμανσης καθολικής εξάρτησης POS (6.7% σχετική βελτίωση της ακρίβειας). Τα αποτελέσματά μας είναι ελπιδοφόρα δεδομένης της έλλειψης δικτύων κοινωνικής δικτύωσης. Ο κωδικός μας μπορεί να βρεθεί στο: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_el>
      <abstract_lt>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation.  Mūsų metodas apima galimybę gauti vertimus (tikslius arba apytikslius) tarp šaltinio ir tikslinės kalbos poros, kuriose tiksliai pritaikome model į, kuriame pateikiami šaltinio kalbos užduočių duomenys, ir vertiname modelį tiksline kalba. In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology.  We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from English to Hindi, Arabic, and Japanese on two social media tasks: NER (a 37% average relative improvement in F1 across target languages) and sentiment classification (12% relative improvement in F1) on social media text,  while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7% relative improvement in accuracy).  Mūsų rezultatai yra perspektyvūs, atsižvelgiant į socialinės žiniasklaidos trūkumą. Our code can be found at:  https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_lt>
      <abstract_mk>Ние го проценуваме едноставниот пристап до подобрување на нулта-снимка мултијазичкиот трансфер на mBERT на корпусот на социјалните медиуми со додавање на предтренинг задача наречена преведување пар предвидување (TPP), која предвидува дали пар крстојазични тексти се валиден превед. Нашиот пристап претпоставува пристап до преводи (точни или приближни) помеѓу паровите на јазик извор-мета, каде што ние финетизираме модел на податоците на задачите на извор-јазик и го оценуваме моделот на мета јазик. In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology.  Ние покажуваме подобрувања од претренирањето на ТПП над само mBERT во префрлање со нула снимка од англиски на хиндиски, арапски и јапонски на две задачи на социјалните медиуми: НЕР (просечно 37 отсто релативно подобрување на F1 во целните јазици) и класификација на чувствата (12 отсто релативно подобру Исто така, во однос на несоцијалната медиумска задача со означувањето на универзалната зависност POS (6,7 отсто релативно подобрување на прецизноста). Our results are promising given the lack of social media bitext corpus.  Our code can be found at:  https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_mk>
      <abstract_ms>Kami menilai pendekatan sederhana untuk meningkatkan pemindahan berbilang bahasa bernilai sifar dari mBERT pada korpus media sosial dengan menambahkan tugas pralatihan yang dipanggil ramalan pasangan terjemahan (TPP), yang meramalkan sama ada sepasang teks salib bahasa adalah terjemahan yang sah. Our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a model on source language task data and evaluate the model in the target language.  In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology.  Kami menunjukkan peningkatan dari TPP pretraining melalui mBERT sahaja dalam pemindahan 0-shot dari Inggeris ke Hindi, Arab dan Jepun pada dua tugas media sosial: NER (37% rata-rata peningkatan relatif dalam F1 melalui bahasa sasaran) dan kelasukan perasaan (12% relatif peningkatan dalam F1) pada teks media sosial, Sementara juga benchmarking pada tugas media bukan sosial bagi penanda POS Dependensi Universal (6.7% peningkatan relatif dalam ketepatan). Our results are promising given the lack of social media bitext corpus.  Kod kita boleh ditemui di: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ms>
      <abstract_ml>സാമൂഹിക മീഡിയ കോര്‍പ്പുസില്‍ മൂല്ല്ലില്‍ മാറ്റുന്നതിനെ മുന്‍കൂട്ടുവാന്‍ ഞങ്ങള്‍ ഒരു എളുപ്പമുള്ള വഴിയില്‍ വിലാസപ്പെടുത്തുന്നു. ടിപിപി എന്ന പേരിലുള്ള ഒരു പ്രവചനം  നമ്മുടെ സമ്പ്രദായം സൂര്യലക്ഷ്യമായ ഭാഷ ജോട്ടുകാര്‍ക്കിടയില്‍ പരിഭാഷകങ്ങള്‍ക്ക് (കൃത്യമായ അല്ലെങ്കില്‍ അടുത്ത) അനുവാദം ഉണ്ടാക്കുന്നതാണ്  പ്രത്യേകിച്ച്, നമ്മള്‍ ഭാഷ ജോട്ടുകാരെ ശ്രദ്ധിക്കുന്നു. എംബെര്‍ട്ടിന് വേണ്ടി പഠിക്കുന്നത് ബുദ്ധിമുട്ടാണ്: സ്രിപ്റ്റ്, പദ ടിപിപിപിയില്‍ നിന്നും മെബെര്‍ട്ടിനെക്കുറിച്ച് മുന്‍ഗണന മുന്‍ഗണനം കാണിക്കുന്നു. ഇംഗ്ലീഷില്‍ നിന്നും ഇംഗ്ലീഷിലേക്കും അറബിയിലേക്കും ജാപ്പനീസിലേക്കും മാറ്റുന്നത് മുന്‍ഗ  while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7% relative improvement in accuracy).  നമ്മുടെ ഫലങ്ങള്‍ പ്രതീക്ഷിക്കുന്നത് സാമൂഹ്യ മാധ്യമങ്ങളുടെ കാര്യത്തില്‍ പെട്ടെന്നാണ്. നമ്മുടെ കോഡ് കണ്ടെത്താം: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ml>
      <abstract_hu>Egy egyszerű megközelítést értékelünk az mBERT zéró többnyelvű transzferének javítására a közösségi média korpuszon egy olyan előkészítő feladat hozzáadásával, amely a fordítási pár predikciójának (TPP) nevű előkészítésével jósolja meg, hogy egy pár keresztnyelvű szöveg érvényes-e fordítás. Megközelítésünk feltételezi a forrás-célnyelv párok közötti fordításokhoz (pontos vagy hozzávetőleges) való hozzáférést, ahol finomhangoljuk a modellt a forrásnyelv feladatok adataira és értékeljük a modellt a célnyelven. Különösen azokra a nyelvpárokra összpontosítunk, ahol a transzfertanulás nehéz az mBERT számára: azokra, ahol a forrás- és célnyelvek különbözőek a szöveg, a szókincs és a nyelvi tipológia tekintetében. A TPP előkészítésének javulását mutatjuk az egyedül mBERT-hez képest az angolról hindi, arabról és japánra történő zéró átvitel során két közösségi média feladatban: NER (37%-os átlagos relatív javulás F1-ben a célnyelveken) és hangulatosztályozás (12%-os relatív javulás F1-ben) a közösségi média szövegén, ugyanakkor teljesítményértékelés a Universal Dependency POS címkézéssel kapcsolatos, nem közösségi médián belüli feladatokról (6,7%-os relatív javulás a pontosságban). Eredményeink ígéretesek, tekintettel a közösségi média bitext corpus hiányára. A kódunk a következő címen található: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_hu>
      <abstract_mn>Бид нийгмийн хэвлэлийн корпус дээр mBERT-ын олон хэлний шилжүүлэлтийг сайжруулахын тулд энгийн арга барилгыг үнэлгээд орчуулах хоёр хэлний таамаглал (TPP) гэж нэрлэж буй даалгавар нэмэгдүүлдэг. Бидний ойлголт нь эх үүсвэртэй хэл хоёр хоорондох (яг эсвэл ойролцоогоор) орчуулагддаг. Бид эх үүсвэрийн хэл даалгаварын өгөгдлийн загварыг тодорхойлж, загварыг зориулагдсан хэл дээр үнэлдэг. Ялангуяа, бид хэл хоёрын төвд мBERT-д шилжүүлэх суралцах нь хэцүү байдаг: эх үүсвэр, зорилготой хэл нь бичил, үг хэлний, хэлний хэлбэрт өөр өөр байдаг. Бид TPP-ээс зөвхөн mBERT-ээс англи, араб, япон хоёр нийгмийн хэвлэлийн ажил дээр 0-шууд хураагдаж байгааг харуулж байна: NER (нийгмийн хэл дээр 37% дундаж харьцангуй хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгжлийн хөгж Мөн нийгмийн хэвлэл бус нийгмийн хэвлэлийн ажил нь Universal dependency POS tagging (6.7% relative improvement in accuracy). Бидний үр дүнд нийгмийн мэдээллийн хэрэглэгч, корпус байхгүй учраас амлалтай. Бидний код бол: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_mn>
      <abstract_mt>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation.  Our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a model on source language task data and evaluate the model in the target language.  In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology.  We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from English to Hindi, Arabic, and Japanese on two social media tasks: NER (a 37% average relative improvement in F1 across target languages) and sentiment classification (12% relative improvement in F1) on social media text,  while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7% relative improvement in accuracy).  Ir-riżultati tagħna huma promettenti minħabba n-nuqqas ta’ midja soċjali bitext corpus. Our code can be found at:  https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_mt>
      <abstract_it>Valutiamo un approccio semplice per migliorare il trasferimento multilingue zero-shot di mBERT sul corpus dei social media aggiungendo un compito di pre-formazione chiamato translation pair prediction (TPP), che prevede se una coppia di testi cross-lingual sia una traduzione valida. Il nostro approccio presuppone l'accesso alle traduzioni (esatte o approssimative) tra coppie di lingue sorgente-target, dove perfezioniamo un modello sui dati delle attività della lingua sorgente e valutiamo il modello nella lingua di destinazione. In particolare, ci concentriamo sulle coppie linguistiche in cui l'apprendimento di trasferimento è difficile per mBERT: quelle in cui le lingue di origine e di destinazione sono diverse per script, vocabolario e tipologia linguistica. Abbiamo mostrato miglioramenti dal pretraining TPP rispetto al solo mBERT nel trasferimento zero shot dall'inglese all'hindi, dall'arabo e dal giapponese su due attività sui social media: NER (un miglioramento medio relativo del 37% in F1 nelle lingue di destinazione) e classificazione sentiment (miglioramento relativo del 12% in F1) sul testo dei social media, ma anche benchmarking su un compito non social media di Universal Dependency POS tagging (miglioramento relativo dell'accuratezza del 6,7%). I nostri risultati sono promettenti data la mancanza di corpus bitext dei social media. Il nostro codice può essere trovato all'indirizzo: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_it>
      <abstract_pl>Oceniamy proste podejście do poprawy zero-shot wielojęzycznego transferu mBERT na korpus mediów społecznościowych poprzez dodanie zadania wstępnego zwanego predykcją pary tłumaczeń (TPP), które przewiduje, czy para tekstów wielojęzycznych jest prawidłowym tłumaczeniem. Nasze podejście zakłada dostęp do tłumaczeń (dokładnych lub przybliżonych) pomiędzy parami języka źródłowego-docelowego, gdzie dostosowujemy model na podstawie danych zadań języka źródłowego i oceniamy model w języku docelowym. W szczególności skupiamy się na parach językowych, w których nauka transferowa jest trudna dla mBERT: w których języki źródłowe i docelowe różnią się pod względem pisma, słownictwa i typologii językowej. Pokazujemy poprawę wstępnego treningu TPP w stosunku do samego mBERT w transporcie zero-shot z angielskiego na hindi, arabski i japoński w dwóch zadaniach mediów społecznościowych: NER (średnia względna poprawa F1 w 37% w językach docelowych) i klasyfikacja sentymentów (12% względna poprawa F1) w tekście mediów społecznościowych, również porównawcze na temat zadania niespołecznościowego tagowania Universal Dependency POS (6,7% względna poprawa dokładności). Nasze wyniki są obiecujące biorąc pod uwagę brak korpusu bitekstu mediów społecznościowych. Nasz kod można znaleźć na stronie: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_pl>
      <abstract_ro>Evaluăm o abordare simplă pentru îmbunătățirea transferului multilingv zero-shot al mBERT pe corpul social media prin adăugarea unei sarcini de pregătire numită predicția perechilor de traduceri (TPP), care prezice dacă o pereche de texte încrucișate sunt o traducere validă. Abordarea noastră presupune accesul la traduceri (exacte sau aproximative) între perechile de limbi sursă-țintă, în cazul în care ajustăm un model pe datele de sarcini ale limbii sursă și evaluăm modelul în limba țintă. În special, ne concentrăm pe perechile lingvistice în care învățarea transferului este dificilă pentru mBERT: cele în care limbile sursă și țintă sunt diferite în scris, vocabular și tipologia lingvistică. Am arătat îmbunătățiri de la pretraining TPP față de mBERT numai în transferul zero-shot de la engleză la hindi, arabă și japoneză în două sarcini de social media: NER (o îmbunătățire relativă medie de 37% în F1 în limbile țintă) și clasificarea sentimentelor (12% îmbunătățire relativă în F1) pe textul social media, în același timp, evaluarea comparativă a unei sarcini non-sociale de etichetare a POS-urilor Universal Dependency (îmbunătățire relativă a acurateții cu 6,7%). Rezultatele noastre sunt promițătoare având în vedere lipsa corpului bitext social media. Codul nostru poate fi găsit la: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ro>
      <abstract_sr>Procjenjujemo jednostavan pristup unaprjeđivanju multijezičkog prijenosa mBERT na socijalne medijske korpuse, dodajući predviđanje predviđanja prevodnih parova (TPP), koji predviđa da li su par međujezičkih tekstova validan prevod. Naš pristup pretpostavlja pristup prevodima (taèno ili približno) između parova izvorskog jezika, gde ispravljamo model na podacima izvorskog jezika i procjenjujemo model na ciljnom jeziku. Posebno, fokusiramo se na jezičke pare gde je učenje prijenosa teško za mBERT: one gde su izvori i ciljni jezici različiti u skriptu, rečniku i jezičku tipologiju. Mi pokazujemo poboljšanje od TPP pretresanja preko mBERT samog u prenošenju nulog snimka sa engleskog na hindije, arapske i japanske na dva zadatka društvenih medija: NER (prosjeèno relativno poboljšanje u F1 na ciljnim jezicima 37%) i klasifikaciju osjećanja (12% relativno poboljšanje u F1) na tekstu društvenih medija, Dok se takođe nalazi i kritika na zadatku neodruštvenih medija univerzalne zavisnosti označavanja POS-a (relativno poboljšanje preciznosti od 6,7%). Naši rezultati obećavaju s obzirom na nedostatak socijalnih medija ugriznog korpusa. Naš kod se nalazi u: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_sr>
      <abstract_kk>МЕБЕРТ көпшілікті көпшілікті мЕРТ көпшілікті көпшілікті көпшілікті мЕРТ көмегімен көпшілікті медиа корпусында аудармалардың параметрлері (TPP) деп аталатын тапсырманы қосу арқылы, ол Біздің қасиетіміз көздегі тілдің екеуі арасындағы аудармаларға (дұрыс немесе жақсы) қатынау мүмкіндігін есептеп, көздегі тілдің тапсырмаларының деректерінің үлгісін таңдап, мақсатт МЕРТ үшін көзі мен мақсатты тілдер скрипті, сөздік және лингвистикалық типологиясында айырмалы тілдер екеуіне назар береміз. Ағылшынша, араб және жапониялық медиа тапсырмаларында бір-бірінші мBERT арқылы нөл түрлендіру үшін TPP жақсартуларын көрсетедік: NER (нақты тілдерінің орташа 37% жақсартылық жақсартулары) және көздерді (F1 деген 12% жақсартылы Сонымен қатар, әлеуметтік медиа тапсырмасының әлемдік Тәуелсіздік POS тегтерінің (6,7% салыстырылық жақсартуы). Біздің нәтижелеріміз социалдық медиақтардың бағытты корпус жоқ болуына әсер етіп тұр. Біздің кодмыз табылады: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_kk>
      <abstract_so>Waxaynu qiimeynaynaa qaab fudud si aan u hagaajinno wareejinta muBERT oo luuqado badan ah oo ku qoran shabakada sooshaalka, waxaana ku daraynaa shaqada hore oo lagu qorayo turjumidda labaad (TPP), kaasoo wax sheegaya in qoraalo kala duwan oo luqadaha ah ay yihiin mid shaqeyn. Dhaqdhaqaaqyadayadu waxay leedahay in aad turjumid (si sax ah ama dhowr) u dhexeyso labo luqada oo ay ku nooshahay, taasoo aan ku qorno model ku saabsan macluumaadka shaqada luqada source ah, waxaana qiimeynaya modelka afka goanka. Si gaar ah, waxaynu ku kalsoonaynaa labada noocyo oo luqada ah, meesha ay ku adag tahay in waxbarashada la wareejiyo ay ku adag tahay mBERT: kuwaas oo ah meesha ay luuqadaha iyo luqadaha la hago ay ku kala duwan yihiin karraaniga, hadalka iyo qoraalka luuqadda. Waxaannu ka muujinnaa hagaajinta TPP oo ka soo hor jeedaya mBERT oo kaliya, marka laga soo wareejiyo Ingiriis-Ingiriis-Hindi, Carabi iyo Jabanees labada shaqooyin oo macluumaadka bulshada ah: NER (qiyaastii 37% kordhinta afka caadiga ah ee F1 oo dhan) iyo kalajarida xisaabta (12% relative u bedeshahay afka bulshada ee F1) Markaas xittaa waxaa lagu soo bandhigi karaa shaqo aan sooshalka ahayn oo lagu qorayo qoraal-xirfadeedka POS ee jaamacadda (6.7% relative improvement si saxda ah). Midhahayaga waxaa loo ballanqaadaa baahida baahida macluumaadka bulshada. Aqoonkayada waxaa laga heli karaa: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_so>
      <abstract_ta>மொழிபெயர்ப்பு ஜோடி மொழிபெயர்ப்பு (TPP) என்பதை சேர்த்து மொழிபெயர்ப்பு மொழிபெயர்ப்பு மொழியில் மாற்றுவதற்கு எளிய முறையை மேம்படுத்த முடியும் என்பதை நாம் மதிப்பி எங்கள் முறைமையில் மொழி ஜோடிகளுக்கு இடையே மொழிபெயர்ப்புகள் (சரியாக அல்லது அருகில்) அணுகல் எடுத்துக் கொள்கிறது, அங்கு நாம் மூல மொழி பணி தரவில்  குறிப்பிட்டு, நாம் மொழி ஜோடிகளை கவனத்தில் கவனம் செலுத்துகிறோம் எம்பிரெட்டுக்கு மாற்றும் கற்றல் கடினமாகும்: மூலம் மற்றும் இலக்கு ம நாம் டிபிபி மட்டும் எம்பெர்ட் மட்டுமே பூஜ்ஜியமாக மாற்றுவதை காட்டுகிறோம் என்பதை காண்பிக்கிறோம் என்பதை நாம் பூஜ்ஜியமாக மாற்றி ஆங்கிலத்திலிருந்து ஹன்டி, அரபி மற்றும் ஜப்பானியர பொதுவான சார்ந்த சார்பு POS குறியீட்டின் பொதுவான சமூக ஊடகங்கள் செயல்பாட்டில் பெரும்பாட்டில் நீக்கப்படுகிறது (சரியான எங்கள் முடிவுகள் நம்முடைய வாக்குறுதி அளிக்கப்பட்டுள்ளது சமூக ஊடகங்களின் குறைப்பு கார்ப்ஸ் Our code can be found at:  https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ta>
      <abstract_si>Name අපේ ප්‍රවේශය අනුවෙන් අවශ්‍ය විදිහට (හරියටම හෝ අවශ්‍ය) භාෂාවක් සම්බන්ධ විදිහට ප්‍රවේශනය කරන්න පුළුවන් වෙනවා, අපි මූල විශේෂයෙන්, අපි භාෂා ජෝඩුවට අවධානය කරනවා මෙබෙර්ට් විදියට ඉගෙන ගන්න අමාරුයි: මුළු සහ ඉලක්ෂ භාෂාවය ලිපිට අපි TPP ප්‍රීට්‍රින්ස් වලින් මෙබෙර්ට් වලින් ඉංග්‍රීසිය, අරාබියා වලින් ජාපාන් වලින් ඉංග්‍රීසියාවෙන් ඉංග්‍රීසියාවෙන් හින්දි, අරාබියා වලින් ජාපානි සාමාජික මිඩියාවක් නොවිශ්වාසික විශේෂතාව POS ටැග් එකේ බෙන්ච්මාර්ක් කරනවා වගේම (6.7% සාමාජික විශේෂතාව ස අපේ ප්‍රතිචාරයක් පොරොන්දු කරනවා සාමාජික මාධ්‍යමය බිට් කොර්පුස් නැති විදියට. අපේ කේතය හොයාගන්න පුළුවන්: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_si>
      <abstract_sv>Vi utvärderar ett enkelt tillvägagångssätt för att förbättra noll-shot flerspråkig överföring av mBERT på sociala medier corpus genom att lägga till en förberedelseuppgift kallad translation pair prediction (TPP), som förutspår om ett par korspråkiga texter är en giltig översättning. Vårt tillvägagångssätt förutsätter tillgång till översättningar (exakta eller ungefärliga) mellan käll-målspråkspar, där vi finjusterar en modell på källspråksuppgifter och utvärderar modellen på målspråket. Särskilt fokuserar vi på språkpar där överföringsinlärning är svårt för mBERT: de där käll- och målspråk skiljer sig åt i skrift, ordförråd och språktypologi. Vi visar förbättringar från TPP pre-training jämfört med mBERT enbart i noll-shot överföring från engelska till hindi, arabiska och japanska på två sociala medier uppgifter: NER (en genomsnittlig relativ förbättring på 37% i F1 över målspråk) och sentimentklassificering (12% relativ förbättring i F1) på sociala medier text, samtidigt som benchmarking av en icke-social media uppgift med Universal Dependency POS-märkning (6,7% relativ förbättring i noggrannhet). Våra resultat är lovande med tanke på bristen på sociala medier bitext corpus. Vår kod finns på: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_sv>
      <abstract_no>Vi evaluerer ein enkel tilnærming til å forbedra 0-shot multispråk overføring av mBERT på sosiale media-korpus ved å leggja til eit prøveverksame oppgåve kalla omsetjingspråk-foregåve (TPP), som foregår om ei par av krysspråk-tekstar er ein gyldig oversettelse. Tilnærminga vårt gjer tilgang til omsetjingar (nøyaktig eller nøyaktig) mellom kjeldemålspråkopar, der vi finn ein modell på kjeldespråksoppgåvedata og evaluerer modellen i målspråket. I særskilt fokuserer vi på språkopar der læring av overføring er vanskeleg for mBERT: dei der kjeldespråk og målspråk er ulike i skript, ordbokstav og linguistisk typologi. Vi viser forbetringar frå TPP som fører seg over mBERT alene i nullsatt overføring frå engelsk til hindisk, arabisk og japansk på to sosiale media-oppgåver: NER (ein gjennomsnittlig forbetring i F1 over målspråk) og sentimentklassifikasjon (12% relative forbedring i F1) på sosiale media-tekst, medan også benchmarking på eit ikkje-sosiale media-oppgåve av universell avhengighet-POS-merking (6,7 % relativt forbedring i nøyaktighet). Resultatet våre blir forslått gjeven mangling av sosiale media-bittekstkorpus. Koden vårt kan finnast på: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_no>
      <abstract_ur>ہم ایک ساده طریقہ کا ارزش کریں گے کہ mBERT کی مختلف زبان ترنسیٹ کو سوسیل میڈیا کورپوس پر مزید زبان کی ترنسیٹ کرنے کے لئے مزید زبان کا مزید ترنسیٹ کرے، اس طرح ترنسیٹ جوڑ کی پیش بینی (TPP) کا ایک زیادہ ترنسیٹ کریں، جو پیش بینی کرتا ہے ہمارا طریقہ یہ ہے کہ سورج-target زبان جوڑوں کے درمیان تغییرات (مضبوط یا تقریباً) کے لئے پہنچنے کے لئے پہنچ جاتے ہیں، جہاں ہم سورج زبان ٹاکس ڈاٹ پر ایک موڈل کو ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھیک ٹھ مخصوصاً ہم زبان جوڑوں پر تمرکز کرتے ہیں جہاں ترنسیس سیکھنا mBERT کے لئے مشکل ہے: وہ جہاں سورج اور موجود زبانیں لکھنے کے لئے مختلف ہیں۔ ہم ٹی پی پی سے مBERT پر صرف صفر شٹ ترنسیٹ میں دو سوسیل میڈیا ٹاکس پر مزید ترنسیٹ کریں گے۔ اور یونلور ڈیفاندنس پوس ٹاگ کے غیر سوسیلی میڈیا کا کام پر بنچم کر رہا ہے (6.7% مستقیم صلاحیت کے ساتھ)۔ ہمارے نتیجے وعدہ دیتے ہیں کہ سوسیل میڈیا بیٹکس کورپوس کی کمی ہے۔ ہمارا کوڈ اس میں پا سکتا ہے: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ur>
      <abstract_uz>Biz bir oddiy usulni qiymatlashimiz mumBERT haqida jamiyat medya kompyuterdagi bir necha tilni o'zgarishni o'zgartirish va tarjima qilish (TPP) deb nomlangan vazifani qoʻshish mumkin. Bu bir necha tillar matnlari haqiqiqiy tarjima qilishini anglatadi. Bizning fikrimiz manba tilning chegarasini tarjima qilish (tashqi yoki yaqinlik) tarjima qilishiga ega bo'ladi. Bu yerda biz manba tillar vazifa maʼlumotidagi modelni yozib olib kelamiz va goal tilidagi modelni qiymatmiz. Ko'pchilik, biz o'rganish muBERT uchun qiyin bo'lgan tillar qoʻllarini foydalanamiz: manba va hodisa tillar skript, vosita, tillar va lingʻatlik turologida o'zgarishlar qiyin. Biz MBERT tomonidan Inglizcha, Ereb va Yaponchadan ikkita jamiyat medya vazifalarini o'zgartirishda faqat o'zgarishni tasavvur qilamiz, TPP dan o'zgarishni ko'rsatdik: NER (shaxsiy tillar bilan F1'ga bog'liq o'zgarishga 37% yaxshi o'zgarishga ega) va hissiyot darajasini (F1'da qiziqarli darajada yaxshi yaxshi  while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7% relative improvement in accuracy).  Bizning natijalarimiz jamiyatli medya qismlari qo'shli qo'shlari yozib beradi. Kodlash mumkin: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_uz>
      <abstract_vi>Chúng tôi đánh giá một phương pháp đơn giản để cải thiện việc chuyển giao mBERT đến mạng xã hội truyền thông càng nhiều. Bằng cách thêm vào tập đoàn sản xuất một nhiệm vụ được gọi là dự đoán cặp đôi dịch (TPP). Cách tiếp cận của chúng tôi nắm bắt quyền truy cập dịch dịch (chính xác hoặc ước lượng) giữa các cặp ngôn ngữ đích nguồn, nơi chúng tôi chọn một mô hình về các dữ liệu ngôn ngữ riêng và đánh giá mô hình trong ngôn ngữ đích. Chúng tôi tập trung vào cặp ngôn ngữ nơi rất khó khăn cho mBERT: những nơi mà ngôn ngữ gốc và mục tiêu khác nhau trong văn bản, từ điển và ngôn ngữ. Chúng tôi cho thấy sự cải tiến từ tiền sản TPP hóa trên mBERT một mình trong việc chuyển từ tiếng Anh sang tiếng Hindi, Ả Rập và Nhật Bản về hai công việc truyền thông xã hội: NER (một 37=$tiến bộ tương đối trong F1 vượt qua ngôn ngữ đích) và phân loại cảm xúc (12=$tương đối cải tiến trong F1) về văn bản phương xã hội, cũng như so sánh một nhiệm vụ không phải của truyền thông xã hội về nhận định mối quan hệ về nhiệt độ chung Kết quả của chúng tôi rất có triển vọng vì thiếu các phương tiện truyền thông xã hội. Mật mã của chúng tôi có thể tìm thấy ở: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_vi>
      <abstract_nl>We evalueren een eenvoudige aanpak om de zero-shot meertalige overdracht van mBERT op social media corpus te verbeteren door een pretraining taak toe te voegen genaamd translation pair prediction (TPP), die voorspelt of een paar meertalige teksten een geldige vertaling zijn. Onze aanpak veronderstelt toegang tot vertalingen (exact of bij benadering) tussen bron-doeltaalparen, waarbij we een model verfijnen op brontaaltaakgegevens en het model evalueren in de doeltaal. We richten ons in het bijzonder op taalparen waar transferleren moeilijk is voor mBERT: die waar bron- en doeltalen verschillen in script, woordenschat en taaltypologie. We tonen verbeteringen van TPP pretraining boven mBERT alleen in zero-shot transfer van Engels naar Hindi, Arabisch en Japans op twee sociale media taken: NER (een 37% gemiddelde relatieve verbetering in F1 in doeltalen) en sentiment classificatie (12% relatieve verbetering in F1) op sociale media tekst, Ook benchmarking op een niet-sociale media taak van Universal Dependency POS tagging (6,7% relatieve verbetering in nauwkeurigheid). Onze resultaten zijn veelbelovend gezien het ontbreken van social media bitext corpus. Onze code is te vinden op: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_nl>
      <abstract_hr>Procjenjujemo jednostavan pristup unaprjeđivanju multijezičkog prijenosa mBERT-a na socijalne medijske korpuse, dodajući predviđanje predviđanja prevoditeljskih parova (TPP), koji predviđa je li par međujezičkih tekstova vrijedan prevod. Naš pristup pretpostavlja pristup prevodima (to čno ili približno) između parova izvorskog jezika, gdje ćemo odrediti model na podacima izvorskog jezika i procijeniti model na ciljnom jeziku. Posebno, fokusiramo se na jezičke pare gdje je učenje prijenosa teško za mBERT: one gdje su izvori i ciljni jezici različiti u skriptu, rečniku i jezičku tipologiju. Mi pokazujemo poboljšanje od TPP-a pretvaranja preko mBERT samog u prenošenju nule snimke iz engleskog na hindu, arapske i japanske na dva zadatka društvenih medija: NER (prosječna relativna poboljšanja u F1 u ciljnim jezicima od 37% i klasifikacija osjećanja (12% relativna poboljšanja u F1) na tekstu društvenih medija, Dok se također nalazi kriterija na zadatku neodruštvenih medija univerzalne zavisnosti označavanja POS-a (relativno poboljšanje točnosti od 6,7%). Naši rezultati obećavaju s obzirom na nedostatak socijalnih medija ugriznog korpusa. Naš kod se nalazi na: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_hr>
      <abstract_de>Wir evaluieren einen einfachen Ansatz zur Verbesserung der zero-shot mehrsprachigen Übertragung von mBERT auf Social Media Corpus, indem wir eine Vorbereitungsaufgabe namens Translation Pair Prediction (TPP) hinzufügen, die vorhersagt, ob ein Paar mehrsprachiger Texte eine gültige Übersetzung ist. Unser Ansatz setzt den Zugriff auf Übersetzungen (exakt oder approximativ) zwischen Quell-Ziel-Sprachpaaren voraus, wobei wir ein Modell auf Quell-Sprachaufgabendaten verfeinern und das Modell in der Zielsprache bewerten. Insbesondere konzentrieren wir uns auf Sprachpaare, bei denen Transferlernen für mBERT schwierig ist: bei denen Ausgangs- und Zielsprachen in Schrift, Vokabular und sprachlicher Typologie unterschiedlich sind. Wir zeigen Verbesserungen des TPP-Vortrainings gegenüber mBERT allein im Zero-Shot-Transfer von Englisch nach Hindi, Arabisch und Japanisch auf zwei Social-Media-Aufgaben: NER (eine 37% durchschnittliche relative Verbesserung in F1 über Zielsprachen) und Sentiment-Klassifizierung (12% relative Verbesserung in F1) auf Social-Media-Text, während auch Benchmarking auf eine nicht soziale Media-Aufgabe des Universal Dependency POS Tagging (6,7% relative Verbesserung der Genauigkeit). Unsere Ergebnisse sind vielversprechend angesichts des Fehlens von Social Media Bitext Corpus. Unser Code finden Sie unter: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_de>
      <abstract_id>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation.  pendekatan kita menganggap akses ke tradukti (tepat atau dekat) antara pasangan bahasa sumber-sasaran, di mana kita memperbaiki model pada data tugas bahasa sumber dan mengevaluasi model dalam bahasa sasaran. Terutama, kita fokus pada pasangan bahasa di mana pengajaran transfer sulit untuk mBERT: mereka di mana bahasa sumber dan sasaran berbeda dalam skrip, vokbulari, dan tipologi bahasa. Kami menunjukkan peningkatan dari TPP pretraining lebih dari mBERT sendirian dalam transfer zero-shot dari Inggris ke Hindi, Arab, dan Jepang pada dua tugas media sosial: NER (rata-rata 37% peningkatan relatif di F1 melalui bahasa sasaran) dan klasifikasi sentimen (12% peningkatan relatif di F1) pada teks media sosial, - sementara juga benchmarking pada tugas media bukan sosial dari Universal Dependency POS tagging (6,7% relative improvement in accuracy). Hasil kita berjanji karena kekurangan media sosial bitext corpus. Kode kami dapat ditemukan di: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_id>
      <abstract_fa>ما یک روش ساده را برای بهترین انتقال متحده زبان صفر از mBERT در رسانه‌های اجتماعی با اضافه کردن یک وظیفه پیش‌بینی جفت ترجمه (TPP) که پیش‌بینی می‌کند آیا یک جفت متن متحده زبان یک ترجمه قابل است. دستور ما دسترسی به ترجمه‌ها (دقیقا یا نزدیک) بین جفت زبان‌های منبع هدف می‌گیرد، جایی یک مدل را بر داده‌های کار زبان منبع تنظیم می‌کنیم و مدل را در زبان هدف ارزیابی می‌کنیم. مخصوصا، ما روی جفت زبان تمرکز می کنیم که یادگیری انتقال برای mBERT سخت است: کسانی که منبع و زبان هدف در نوشته‌ها، کلمه‌شناسی و نوشته‌شناسی متفاوت هستند. ما توسعه‌هایی از TPP که تنها در انتقال صفر از انگلیسی به هندی، عربی و ژاپنی در دو کار رسانه‌های اجتماعی نشان می‌دهیم: NER (توسعه‌های متوسط 37 درصد نسبت به توسعه F1 در زبان هدف) و تشکیل احساسات (توسعه نسبت به ۱۲ درصد در متن رسانه‌های اجتماعی) در حالی که نیز بر یک کار رسانه‌های غیر اجتماعی نشان دادن POS بستگی جهانی (بهترین نسبت به ۶.۷ درصد در دقیق). نتیجه‌های ما قول می‌دهند به خاطر اینکه ناتوانی از رسانه‌های اجتماعی کورپوس جامعه‌ای است. رمز ما در: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_fa>
      <abstract_bg>Ние оценяваме един прост подход за подобряване на нулевия многоезичен трансфер на МБЕРТ в корпуса на социалните медии чрез добавяне на предварително тренировъчна задача, наречена предсказване на двойки преводи (ТПП), която прогнозира дали двойка междуезични текстове са валиден превод. Нашият подход предполага достъп до преводи (точни или приблизителни) между двойките източник-целеви езици, където фино настройваме модела на данните от задачите на изходния език и оценяваме модела на целевия език. По-специално, ние се фокусираме върху езиковите двойки, където трансферното обучение е трудно за тези, където изходните и целевите езици са различни по скрипт, речник и лингвистична типология. Показваме подобрения от предварителното обучение на ТЕЦ над МБЕРТ само при нулев трансфер от английски на хинди, арабски и японски по две задачи в социалните медии: средно 37% относително подобрение във Формула 1 в целевите езици) и класификация на сентимента (12% относително подобрение във Формула 1) в социалните медии текст, като същевременно сравнително оценяване на задача, която не е свързана със социалните медии, за маркиране на ПОС с универсална зависимост (6,7% относително подобрение на точността). Резултатите ни са обещаващи предвид липсата на битекст корпус в социалните медии. Нашият код може да бъде намерен на: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_bg>
      <abstract_ko>우리는 간단한 방법으로 번역 대 예측(translation pair prediction, TPP)이라는 훈련 전 임무를 추가하여 소셜 미디어 자료 라이브러리에 있는 mBERT의 0렌즈 다중 언어 이동을 개선함으로써 이 임무는 한 쌍의 다중 언어 텍스트가 효과적인 번역인지 예측한다.우리의 방법은 원본-목표 언어 간의 번역(정확하거나 근사)에 접근할 수 있다고 가정하고 원본언어 임무 데이터에서 모델을 미세하게 조정하고 목표 언어에서 모델을 평가한다.특히 우리가 주목하는 언어는 이동 학습에 mBERT에 있어 어려운 것이다. 원시 언어와 목표 언어는 스크립트, 어휘와 언어 유형에 있어 다르다.우리는 두 가지 소셜 미디어 임무에서 TPP 예비 훈련이 영어에서 인디언, 아랍어, 일본어로의 제로 사거리 전환에서 mBERT보다 단독으로 진행된 개선을 보여 주었다. NER(목표 언어의 F1 평균 상대 개선 37%)와 소셜 미디어 텍스트의 감정 분류(F1 상대 개선 12%).또한 유니버설 의존어성 표시라는 비소셜미디어 임무에 대한 기준 테스트(정확도가 상대적으로 6.7% 향상)도 실시했다.소셜 미디어 이중 텍스트 자료 라이브러리의 부족을 감안하면 우리의 연구 결과는 매우 희망적이다.코드는 다음 웹 사이트에서 찾을 수 있습니다.https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ko>
      <abstract_sw>Tutathmini mbinu rahisi ya kuboresha usafirishaji wa lugha mbalimbali wa mBERT kwenye makampuni ya mitandao ya kijamii kwa kuongeza jukumu la kuchora linaloitwa kutabiri mbili za kutafsiri (TPP), ambalo linabashiri kama jumbe mbili za maandishi ya lugha yenye lugha mbalimbali ni tafsiri halisi. Hatua yetu inachukua upatikanaji wa tafsiri (sahihi au karibu) kati ya wanandoa wa lugha zenye lengo, ambapo tunaweka mfano mzuri katika takwimu za kazi za lugha na kutathmini mtindo huo kwa lugha inayolenga. Kwa hakika, tunajikita kwenye viwili vya lugha ambapo kuhamisha kujifunza ni vigumu kwa mBERT: wale ambao chanzo na lugha zinazolenga ni tofauti katika maandiko, lugha, lugha na utamaduni wa lugha. Tunaonyesha maendeleo kutoka TPP kwa kutazama mBERT peke yake katika usafirishaji usio na risasi kutoka Kiingereza hadi Kiingereza, Kiarabu na Kijapani katika kazi mbili za mitandao ya kijamii: NERS (wastani wa asilimia 37 ya kuboreshwa kwa lugha za F1 kote zinazolenga) na kutangaza hisia (asilimia 12 yenye kuboreshwa kwa F1) kwenye maandishi ya mitandao ya kijamii, Wakati pia wakiweka bendera katika jukumu la mitandao ya kijamii isiyotegemea Uchaguzi wa POS ulimwengu kote (asilimia 6.7 yenye maendeleo yanayohusiana na ukweli). Matokeo yetu yanaahidi kutokuwepo kwa viungo vya mitandao ya kijamii. Utawala wetu unaweza kupatikana kwa: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_sw>
      <abstract_sq>Ne vlerësojmë një qasje të thjeshtë për përmirësimin e transferit shumëgjuhësor zero-shot të mBERT në korpus social media duke shtuar një detyrë parastërvitëse të quajtur parashikimi i çiftit të përkthimit (TPP), i cili parashikon nëse një çift tekstesh ndërgjuhësore janë një përkthimi i vlefshëm. Përqasja jonë merr qasjen e përkthimeve (saktë apo afërsisht) midis çifteve të gjuhës burim-objektiv, ku ne rregullojmë një model mbi të dhënat e gjuhës burim dhe vlerësojmë model in në gjuhën objektiv. Në veçanti, ne përqëndrohemi në çiftet gjuhësh ku mësimi i transferimit është i vështirë për mBERT: ato ku gjuhët burimore dhe shënjestra janë të ndryshme në skript, fjalor dhe tipologji gjuhësore. Ne tregojmë përmirësime nga TPP duke parastërvitur mbi mBERT vetëm në transferimin zero-shot nga anglisht në Hindi, arabisht dhe japonezë në dy detyra të medias sociale: NER (një përmirësim mesatar relativ 37% në F1 nëpër gjuhët objektive) dhe klasifikimin e ndjenjave (12% përmirësim relativ në F1) në tekstin e medias sociale, Ndërsa gjithashtu përcaktohet një detyrë jo-shoqërore e medias për etiketën e Varësisë Universale POS (6.7% përmirësim relativ në saktësi). Rezultatet tona janë premtuese duke pasur parasysh mungesën e medias sociale të trupit. Kodi ynë mund të gjendet në: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_sq>
      <abstract_tr>Biz seretsel mediýan korpusynda mBERT'iň köp dilini geliştirmek üçin basit bir golaýy çykýarys. Bu, terjime çift önümlemesi (TPP) diýip atlandyrylýan täze täze ekleýän täze bir täze ekleýän. Biziň ýaryşymyz çeşmeler (dakyk ýa-da gollanşyk) çeşmeleriň çiftleri arasynda terjime etmegi düşünýär. Biz çeşme dilinde bir nusga çykýan we maksadyň dilinde nusgany çykýan. Aýratyn bolsa, biz dil çiftlere mBERT üçin öwrenmek kyn ýerde üns berýäris: mekdepler we maksadat dilleri skriptde, sözlük we lingwistiki tipologiýada üýtgeşirilýär. Biz TPP'den mBERT'den ýeke-de iňlis dilinden Hindistan, Arapça we Japonça iki sosyal medýä meselelerinde täzelikler görkezilýäris: NER (hedef dillerinde 37% ösümli gelişmeleri) we duýgular klasifikasy (F1'de 12% ösümli gelişmeleri) sosyal medýä metinde, Universal dependency POS tagging (6.7% relative improvement in accuracy). Biziň netijelerimiz sosyal mediýalylaryň ýok bolmagyna söz berýärler. Biziň kodymyz şol ýerde tapylýar: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_tr>
      <abstract_af>Ons evalueer 'n eenvoudige toegang om nul-skoot multitaal oordrag van mBERT op sosiale media korpus te verbeter deur 'n voortrekende taak by te voeg wat genoem vertaling paar voorskou (TPP), wat voorskou of 'n paar kruistale teks 'n geldige oordrag is. Ons toegang aanvaar toegang tot vertalings (presies of omtrent) tussen bron-doel taal paar, waar ons 'n model op bron taal taak data fin-tune en die model in die doel taal evalueer. Spesifieke, ons fokus op taal paar waar oordrag leer moeilik is vir mBERT: die waar bron en doel tale verskillend is in skrip, woordeboek en lingwisiese tipologie. Ons wys verbeteringe van TPP wat alleen oor mBERT trek in nul-skoot oordrag van Engels na Hindi, Arabiese en Japaanse op twee sosiale media opdragte: NER ( 'n 37% gemiddelde relatiewe verbetering in F1 oor doel tale) en sentiment klassifikasie (12% relatiewe verbetering in F1) op sosiale media teks, terwyl ook benchmarking op 'n nie-sosiale media opdrag van Universele afhanklikheid POS merking (6.7% relatiewe verbetering in presisiteit). Ons resultate is belowe gegee dat die ontbreek van sosiale media byte korpus is. Ons kode kan gevind word op: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_af>
      <abstract_hy>Մենք գնահատում ենք մի պարզ մոտեցում, որպեսզի բարելավենք mBER-ի զրոլեզվով բազլեզվով փոխանցումը սոցիալական լրատվամիջոցների կորպոսի վրա ավելացնելով նախադասական առաջադրանք, որը կոչվում է թարգմանման զույգ կանխատեսում (TՊ), որը կանխատեսում է, թե երկու Մեր մոտեցումը ենթադրում է (ճշգրիտ կամ մոտավորապես) թարգմանությունների հնարավորություն աղբյուր-նպատակային լեզվի զույգերի միջև, որտեղ մենք բարձրացնում ենք աղբյուր լեզվի խնդիրների տվյալների մոդելը և գնահատում ենք մոդելը նպատակ In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology.  Մենք ցույց ենք տալիս զարգացումներ ԹՊՊ-ից միայն mBER-ի վերաբերյալ զրոյական կրակի փոխանցումը անգլերենից Հինդի, արաբերական և ճապոնացի երկու սոցիալական լրատվամիջոցների առաջադրանքների վրա. ՆԵՌ (37 տոկոս միջին հարաբերական զարգացում F1-ում նպատակային լեզուներում) և զգացմու Միևնույն ժամանակ նաև համեմատական վերաբերյալ վերաբերյալ ոչ սոցիալական լրատվամիջոցների խնդիրներին, որը կապված է համաշխարհային կախվածության POS նշաններով (ճշգրտության հարաբերական զարգացում 6.7 տոկոսով): Մեր արդյունքները խոստացնող են, հաշվի առնելով սոցիալական լրատվամիջոցների բացակայությունը: Մեր կոդը գտնվում է https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_hy>
      <abstract_da>Vi evaluerer en enkel tilgang til at forbedre zero-shot flersproget overførsel af mBERT på sociale medier ved at tilføje en forudgående opgave kaldet translation pair prediction (TPP), som forudsiger, om et par tværsprogede tekster er en gyldig oversættelse. Vores tilgang forudsætter adgang til oversættelser (nøjagtige eller omtrentlige) mellem kilde-mål sprogpar, hvor vi finjusterer en model på kildesprogsopgavedata og evaluerer modellen på målsproget. Vi fokuserer især på sprogpar, hvor overførsel af læring er vanskelig for mBERT: dem, hvor kilde- og målsprog er forskellige i skrift, ordforråd og sprogtypologi. Vi viser forbedringer fra TPP forud for mBERT alene i nulskudsoverførsel fra engelsk til hindi, arabisk og japansk på to sociale medieopgaver: NER (en gennemsnitlig relativ forbedring på 37% i F1 på tværs af målsprog) og sentiment klassificering (12% relativ forbedring i F1) på sociale medier tekst, samtidig med benchmarking af en ikke-sociale medieopgave med Universal Dependency POS tagging (6,7% relativ forbedring i nøjagtighed). Vores resultater er lovende i betragtning af manglen på sociale medier bitekst corpus. Vores kode kan findes på: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_da>
      <abstract_am>በሙሉ ማኅበራዊ ሚዲያ ካርፓስ ላይ የክፍለ ቋንቋ መቀናቀል እናስተዋልታለን፡፡ የቋንቋ ቋንቋ-ቋንቋ ሁለት መካከለኛ መግለጫ (ቁጥጥር ወይም ቁጥጥር) መግለጫ ነው፡፡ በተለይም የቋንቋ ዓይነቶች እና MBERT ለመለወጥ የሚችሉትን የቋንቋ ዓይነቶች ላይ እናስማራለን፤ ምንጭ እና የጉዳዩ ቋንቋዎች በጽሑፍ፣ ቋንቋ እና ቋንቋ ተቋማኝነት የተለየ ናቸው፡፡ በሁለት ማኅበራዊ አውታር ሚዲያ ስራ ላይ ከኢንጂንድ፣ አረቢያ እና ጃፓንውያን በሁለት ማኅበራዊ ሚዲያ ስራዎችን ከቴፕP ብቻውን በzero-shot በመዘርጋት እናሳየዋለን፡፡ በተጨማሪም ጊዜ፣ የዓለማዊ ድጋፍ የፖስቲካ ተቃውሞ በማኅበራዊ ሚዲያ ስራ በማድረግ ላይ benchmarking፡፡ Our results are promising given the lack of social media bitext corpus.  ከ: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_am>
      <abstract_ca>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation.  El nostre enfocament suposa l'accés a traduccions (exactes o aproximades) entre parelles de llenguatges d'origen-alvo, on ajuntem un model en dades de tasca de llenguatge d'origen i evaluem el model en el llenguatge d'alvo. En particular, ens centrem en parelles de llengües on l'aprenentatge de transfer ència és difícil per mBERT: aquells on les llengües fonts i alvos són diferents en escriptura, vocabulari i tipologia lingüística. We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from English to Hindi, Arabic, and Japanese on two social media tasks: NER (a 37% average relative improvement in F1 across target languages) and sentiment classification (12% relative improvement in F1) on social media text, i també comparant una tasca no social dels mitjans de comunicació amb etiquetes POS de Dependencia Universal (millora relativa del 6,7%). Els nostres resultats són prometedors, dada la falta de mitjans socials. El nostre codi es troba a: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ca>
      <abstract_cs>Vyhodnocujeme jednoduchý přístup ke zlepšení nulového vícejazyčného přenosu mBERT na korpus sociálních médií přidáním úlohy předškolení zvané predikce překladové páry (TPP), která předpovídá, zda je pár textů více jazyků platným překladem. Náš přístup předpokládá přístup k překladům (přesným nebo přibližným) mezi zdrojovými jazykovými páry, kde doladíme model na úlohách zdrojového jazyka a vyhodnotíme model v cílovém jazyce. Zaměřujeme se zejména na jazykové páry, u nichž je přenosové učení pro mBERT obtížné: ty, kde se zdrojové a cílové jazyky liší skriptem, slovní zásobou a jazykovou typologií. Ukazujeme zlepšení z předškolení TPP oproti samotnému mBERT při přenosu nulového záběru z angličtiny do hindštiny, arabštiny a japonštiny na dvou úlohách sociálních médií: NER (37% průměrné relativní zlepšení F1 v cílových jazycích) a klasifikaci sentimentu (12% relativní zlepšení v F1) na textu sociálních médií, současně také srovnávací hodnocení mimo sociální média úlohy Universal Dependency POS tagging (6,7% relativní zlepšení přesnosti). Naše výsledky jsou slibné vzhledem k nedostatku korpusu bitextu sociálních médií. Náš kód naleznete na adrese: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_cs>
      <abstract_az>Biz sıfır dillərin çoxlu mBERT'nin sosyal media korpusu ilə birləşdirmək üçün asanlıq bir yolu çəkirik. Bu, çeviriş çift tədbirlərinin çoxlu dil tədbirlərinin dəyişdirilməsini təmin edir. Bizim tərzimiz mənbəzi dil çiftlərinin arasında tərcümlərə (həqiqi və ya yaxın tərəflər arasında) istifadə edilməsini qəbul edir. Biz mənbəzi dil məlumatının məlumatının modelini düzəltdiyimiz və modelini məqsəd dilində değerləşdiririk. Özellikle, hərəkət öyrənməsi mBERT üçün çətin olan dil çiftlərə odaqlanırıq: mənbə və məqsəd dilləri skriptlər, sözlər və dil tipologiyasında fərqli olanlar. İki sosyal media işində TPP-dən fərqli mBERT-dən yalnız 0-shot İngilizdən Hindistan, Arapçadan və Japonca ilə birlikdə iki sosyal media işində təşkil edilən təmizlənmələri göstəririk: NER (məqsəd dillərində 37% orta təşkil təşkil edilməsi) və sentiment klasifikasyonu (F1'də 12% əlaqəli təşkil edilməsi) sosyal Universal bağımlılıq POS etiketlərinin sosyal olmayan media işlərini də müəyyən etdiyimiz halda (6.7% - yaxşılıq dəyişdirilməsi). Bizim sonuçlarımız sosyal mediyaların ucuz olmasına görə vəd edir. Kodumuz tapılabilir: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_az>
      <abstract_et>Hindame lihtsat lähenemisviisi mBERT-i mitmekeelse ülekande parandamisele sotsiaalmeedia korpuses, lisades koolituseelse ülesande, mida nimetatakse tõlkepaari ennustamiseks (TPP), mis ennustab, kas paar keeleüleseid tekste on õige tõlge. Meie lähenemisviis eeldab juurdepääsu tõlketele (täpsetele või ligikaudsetele) lähtekeele paaride vahel, kus me täpsustame lähtekeele ülesannete mudeli ja hindame mudelit sihtkeeles. Eelkõige keskendume keelepaaridele, kus siirdeõpe on mBERTi jaoks raske: need, kus lähte- ja sihtkeeled on kirjade, sõnavara ja keelelise tüpoloogia poolest erinevad. Me näitame, et TPP eeltreeningu tulemused võrreldes mBERT-iga on paranenud null-shot ülekandel inglise keelest hindi, araabia ja jaapani keelde kahel sotsiaalmeedia ülesandel: NER (37% keskmine suhteline paranemine F1 sihtkeeltes) ja sentimentaalne klassifikatsioon (12% suhteline paranemine F1) sotsiaalmeedia tekstis, samas võrdlusanalüüs universaalse sõltuvuse kassade märgistamise ülesandele, mis ei ole sotsiaalmeedia (6,7% suhteline täpsuse paranemine). Meie tulemused on paljulubavad, arvestades sotsiaalmeedia bitext korpuse puudumist. Meie kood on kättesaadav aadressil: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_et>
      <abstract_bn>আমরা সামাজিক মিডিয়া কোর্পাসে মাল্টিভাষায় মাল্টিভাষায় মাল্টিভাষা পরিবর্তনের জন্য একটি সহজ উপায়ের মূল্য মূল্যায়ন করি যার মাধ্যমে অনুবাদের জোড়া ভবিষ্যৎবাণী (টিপিপি)  আমাদের প্রতিযোগিতার মাধ্যমে সূত্র-লক্ষ্য ভাষার জোড়ার মধ্যে অনুবাদ (সঠিক অথবা প্রায়) অনুবাদের প্রবেশ করা যায়, যেখানে আমরা সোর্স ভাষার কাজ বিশেষ করে, আমরা ভাষার জোড়ার দিকে মনোযোগ দিয়ে মনোযোগ দিচ্ছি যেখানে MBERT এর জন্য বিনিময় শিক্ষা কঠিন: যেখানে উৎস এবং লক্ষ্যবস্তুতে ভাষা স্ আমরা টিপিপি থেকে শুধুমাত্র এমবের্টি থেকে ইংরেজী থেকে হিন্দি, আরবী এবং জাপানীদের বিনিময়ে শুধুমাত্র গুলি পরিবর্তনের বিষয়টি দেখাচ্ছি: সামাজিক প্রচার মাধ্যমের টেক্সটে সামাজিক মি বিশ্ববিদ্যালয়ের নির্ভরিত পোস ট্যাগিং এর একটি অসামাজিক প্রচার মাধ্যমের কাজে বেনম্যাঙ্কিং করছে (সঠিকভাবে ৬. আমাদের ফলাফল প্রতিশ্রুতি দেয়া হচ্ছে সামাজিক প্রচার মাধ্যমের ক্ষতির অভাব। আমাদের কোড পাওয়া যাবে: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_bn>
      <abstract_bs>Procjenjujemo jednostavan pristup unaprjeđivanju multijezičkog prijenosa mBERT-a na socijalne medijske korpuse, dodajući predviđanje predviđanja prevodnih parova (TPP), koji predviđa da li su par međujezičkih tekstova validan prevod. Naš pristup pretpostavlja pristup prevodima (tačno ili približno) između parova izvorskog jezika, gdje ispravljamo model podataka izvorskog jezika i procjenjujemo model na ciljnom jeziku. Posebno, fokusiramo se na jezičke pare gdje je učenje prijenosa teško za mBERT: one gdje su izvori i ciljni jezici različiti u skriptu, rečniku i jezičku tipologiju. Mi pokazujemo poboljšanje od TPP-a pretvaranja preko mBERT samog u prenošenju nule snimke sa engleskog na hindu, arapske i japanske na dva zadatka društvenih medija: NER (prosječna relativna poboljšanja u F1 u ciljnim jezicima od 37% i klasifikacija osjećanja (12% relativna poboljšanja u F1) na tekstu društvenih medija, Dok se također nalazi kriterija na zadatku neodruštvenih medija univerzalne zavisnosti označavanja POS-a (relativno poboljšanje preciznosti 6,7%). Naši rezultati obećavaju s obzirom na nedostatak socijalnih medija ugriznog korpusa. Naš kod se nalazi na: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_bs>
      <abstract_fi>Arvioimme yksinkertaista lähestymistapaa parantaa mBERT:n monikielistä siirtoa sosiaalisen median korpusessa lisäämällä esikoulutuksen tehtävän nimeltä translation pair prediction (TPP), joka ennustaa, ovatko monikieliset tekstit kelvollisia käännöksiä. Lähestymistapamme edellyttää pääsyä käännöksiin (tarkkoihin tai likimääräisiin) lähdekieliparin välillä, joissa hienosäädämme lähdekielen tehtävätietojen mallin ja arvioimme mallin kohdekielellä. Keskitymme erityisesti kielipareihin, joissa siirtooppiminen on vaikeaa mBERTin kannalta: niihin, joissa lähtö- ja kohdekielet ovat erilaisia kirjoitusten, sanaston ja kielellisen typologian osalta. Esitämme parannuksia TPP:n esikoulutuksesta mBERT:iin verrattuna nollashotin siirtoon englannista hindiin, arabiaan ja japaniin kahdessa sosiaalisen median tehtävässä: NER (keskimääräinen suhteellinen parannus F1:ssä kohdekielillä 37%) ja tunteiden luokittelu (12% suhteellinen parannus F1:ssä) sosiaalisen median tekstissä, samalla kun vertaillaan yleismaailmallisen riippuvuuden kassajärjestelmien merkintää, joka ei liity sosiaaliseen mediaan (tarkkuuden suhteellinen paraneminen 6,7%). Tuloksemme ovat lupaavia sosiaalisen median bitext-korpusen puutteen vuoksi. Koodimme löytyvät osoitteesta: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_fi>
      <abstract_jv>Awak dhéwé nggunakake sistem sampeyan kanggo nggunakake nggawe 0-ot sistem multilenguang nggawe mBERT kuwi nggunakake media sotiki nang nambah bantuan nggawe Perintah Panjenengan (PPP), sing apik dhéwé, paling nggawe barang kelas kotang langgar-langgar sampeyan tambah. Awak dhéwé nggunakake tresnaning kanggo tarjamahan (exact obang kapan ingkang angkang dadi, ingkang punika)tindang nggawe barang-tarjamahan, dibutuhke kéné sampek modèl kanggo langkung nggunaken task data nggo kuwi nggawe model nang nggawe tarjamahan banget. Ere ngomong, kéné dipun nggo langkung pawaran kanggo nggawe mulai nggo mBERT: wong sing pernak karo alêng nggo langa kuwi wis dipun ciptaaken, sawar-sesuk lan tipik nggo langa. Awak dhéwé éntuk nglanggar aturan PP luwih nggawe mBERT nik nggawe barang kelas telu nggawe barang nggambar inggiles kanggo uruh, barang, lan japanya kanggo awak dhéwé multimedia sothik: NUR politenessoffpolite"), and when there is a change ("assertivepoliteness Rejalaké awak dhéwé mengko urip-urip kuwi ora bênêkno ngerasah barang komunitas. Coverage https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_jv>
      <abstract_ha>Tuna ƙaddara wani hanyoyi mai sauƙi zuwa improve shifo-shekara na sifiri-sifanci multilala na mBERT a kan mita jami da kuma Mu ƙara wani aikin mai ƙayyade fassarar da ake kallo taƙaitãwa biyu na fassarar (TPP), wanda ke gane ko wani nau'i biyu na rubutun-lugha ne mai inganci. Tsarakanmu na ƙunsa da fassarar fassarar (tabbas ko makusanci) a tsakanin nau'in lugha-nau'in-maimmani, inda muna kiyaye wata motsi kan data na aikin harshen maganar source kuma mu ƙaddara motel cikin harshen wanda aka yi goani. Kayya, munã fokusar a kan sauri biyu na harshen wanda za'a iya shige learning yana mai nau'i ga mBERT: waɗanda ke duk inda source da harsunan da ake amfani da su daban-daban cikin littãfi, maganar da lingui. Tuna nũna mafiya kyauta daga TPP kafin da ya yi amfani da mBERT kawai a cikin shige da sifro-shot daga Ingiriya zuwa Hindu, Larabci da Yajabanci a kan aikin mitanda biyu: NER (a kan sauri 37% wa girmama mafiya amfani da F1 duk harshen aimakin da aka yi amfani da shi) da darafõfi (12% dan muhimmin improvement in F1) a kan matsayin mitanda na jamii, @ info: whatsthis Our results are promising given the lack of social media bitext corpus.  Ana iya sãmun koden mu a: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_ha>
      <abstract_sk>Preprost pristop k izboljšanju ničelnega večjezičnega prenosa mBERT na korpus družbenih omrežij ocenjujemo z dodajanjem naloge predusposabljanja, imenovane Prevod par prevodov (TPP), ki napoveduje, ali je par medjezičnih besedil veljaven prevod. Naš pristop predvideva dostop do prevodov (natančnih ali približnih) med paroma izvornega jezika in ciljnega jezika, kjer natančno nastavimo model na podatkih opravil izvornega jezika in ocenimo model v ciljnem jeziku. Osredotočamo se zlasti na jezikovne pare, kjer je transferno učenje težko za mBERT: tiste, kjer so izvorni in ciljni jeziki različni po pisavi, besedišču in jezikovni tipologiji. Prikazujemo izboljšave s predusposabljanjem TPP v primerjavi s samo mBERT pri ničelnem prenosu iz angleščine v hindijščino, arabščino in japonščino pri dveh nalogah družbenih omrežij: NER (37-odstotno povprečno relativno izboljšanje F1 v ciljnih jezikih) in klasifikaciji sentimentalnih občutkov (12-odstotno relativno izboljšanje F1) v besedilu družbenih omrežjih, hkrati pa primerjalna analiza označevanja prodajnih mest Univerzalne odvisnosti (6,7% relativno izboljšanje natančnosti) pri nalogi, ki niso v družbenih omrežjih. Naši rezultati so obetavni glede na pomanjkanje bitext korpusa socialnih medijev. Naša koda je na voljo na: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_sk>
      <abstract_bo>ང་ཚོས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་སྤྲོད་ཀྱི་ཐབས་ལམ་ཞིག་གིས་བདེན་བཤད་ཀྱི་ཐབས་ལམ་སླ་གཏོང་རྩོལ་མོ་ཞིག་བཟོ་བ་འདུག། ང་ཚོའི་གཟུགས་སྐོར་འདྲི་ཞིབ་པར་སྐད་ཡིག་གཟུགས In particular, we focus on language pairs where transfer learning is difficult for mBERT: those where source and target languages are different in script, vocabulary, and linguistic typology. ང་ཚོས་TPP་ལས་ཕར་རྒྱས་གཏོང་བའི་སྐྱོན་བརྗོད་པ་ཞིག་གིས་ ཨིན་རིའི་ནང་ལས་ ཨིན་རིའི་ནང་ལས་ སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་གཉིས་ལས་འཕར་རིས་མང་ཙམ་སྟོན་བྱས། NER (སྤྱི་ཚོགས་འབྲེལ སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ལས་ཀ་གསལ་བཤད་ཀྱི་མིན་པར་འཛིན་གྱི་ཡོད། ང་ཚོའི་གྲུབ་འབྲས་བ་དེ་ཚོར་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱ་ཀྱི་ཆ་མཉམ་དུ་ཆུང་དུ་འཇུག་གི་མེད། ང་ཚོའི་ཨང་ཀིས་འདི་རྙེད་ཐུབ་པ： https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_bo>
      <abstract_he>We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation.  הגישה שלנו לוקחת גישה לתרגשות (מדויקת או מתקרבת) בין זוגות שפת מקור-מטרה, שבו אנחנו מציינים מודל על נתוני משימה שפת מקור ולעריך את המודל בשפת המטרה. במיוחד, אנחנו מתמקדים על זוגות שפות שבו לימוד העברה קשה עבור mBERT: אלה שבו שפות מקור ומטרה שונות בתסריט, מילים וטיפולוגיה שפותית. אנו מראים שיפורים מהטי.פי.פי.איי.פי על mBERT לבד בהעברה אפס-ירי מאנגלית להינדי, ערבית, ויפנית על שני משימות תקשורת חברתית: NER (שיפור יחסי ממוצע 37% ב-F1 בין שפות המטרה) והקליזציה של רגשות (שיפור יחסי 12% ב-F1) על טקסט תקשו בנוסף לפרנס על משימה של תקשורת לא חברתית של תווים POS של תלויות יוניברסליות (שיפור יחסי של 6.7%). התוצאות שלנו מבטיחות בהתחשב בחסר התקשורת החברתית הקורפוס. הקוד שלנו נמצא ב: https://github.com/twitter-research/multilingual-alignment-tpp.</abstract_he>
      </paper>
    <paper id="46">
      <title>Character Transformations for Non-Autoregressive GEC Tagging<fixed-case>GEC</fixed-case> Tagging</title>
      <author><first>Milan</first><last>Straka</last></author>
      <author><first>Jakub</first><last>Náplava</last></author>
      <author><first>Jana</first><last>Straková</last></author>
      <pages>417–422</pages>
      <abstract>We propose a character-based non-autoregressive GEC approach, with automatically generated character transformations. Recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder GEC systems. We show that word replacement edits may be suboptimal and lead to explosion of rules for <a href="https://en.wikipedia.org/wiki/Spelling">spelling</a>, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus. Finally, we train character transformation models for <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a> and <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, reaching solid results and dramatic speedup compared to autoregressive systems. The source code is released at https://github.com/ufal/wnut2021_character_transformations_gec.</abstract>
      <url hash="23583507">2021.wnut-1.46</url>
      <bibkey>straka-etal-2021-character</bibkey>
      <doi>10.18653/v1/2021.wnut-1.46</doi>
      <pwccode url="https://github.com/ufal/wnut2021_character_transformations_gec" additional="false">ufal/wnut2021_character_transformations_gec</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/akces-gec">AKCES-GEC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
    <title_fr>Transformations de caractères pour le balisage GEC non autorégressif</title_fr>
      <title_es>Transformaciones de caracteres para el etiquetado GEC no autorregresivo</title_es>
      <title_ja>非自動回帰的GECタグ付けのための文字変換</title_ja>
      <title_ar>تحويلات الأحرف لوضع علامات GEC غير ذاتي الانحدار</title_ar>
      <title_pt>Transformações de caracteres para marcação GEC não autorregressiva</title_pt>
      <title_ru>Преобразования символов для неавторегрессивной маркировки GEC</title_ru>
      <title_zh>非自归 GEC 字符转换</title_zh>
      <title_hi>गैर-Autoregressive GEC टैगिंग के लिए वर्ण परिवर्तन</title_hi>
      <title_ga>Athruithe Carachtair le haghaidh Clibeáil GEC Neamh-Uath-chéimneach</title_ga>
      <title_it>Trasformazioni dei caratteri per l'etichettatura GEC non autoregressiva</title_it>
      <title_ka>არ ავტორეგრესიგური GEC ჭდელისთვის სიმბოლობის გარგენაცია</title_ka>
      <title_el>Μεταμορφώσεις χαρακτήρων για μη αυτοανακριτική σήμανση GEC</title_el>
      <title_kk>Авто- регрессивні емес GEC тегтерінің таңбаларын түрлендіру</title_kk>
      <title_mk>Трансформации на знаци за неавтоматско GEC означување</title_mk>
      <title_lt>Ženklų keitimai neautoregresiniam GEC ženklinimui</title_lt>
      <title_ms>Transformasi Aksara untuk Tag GEC Tidak-Autoregressive</title_ms>
      <title_hu>Karaktertranszformációk nem automatikus GEC-címkézéshez</title_hu>
      <title_mt>Trasformazzjonijiet tal-Karatters għal Tagging GEC Mhux Awtoregressiv</title_mt>
      <title_mn>Автоматаар сэргээгдэхгүй GEC тагжингийн харин шилжилт</title_mn>
      <title_no>Teiknversjonar for ikkje- autoregressiv GEC- merking</title_no>
      <title_ml>സ്വയം രേഖപ്പെടുത്തുന്ന ജിസി ടാഗ്ഗിങ്ങിനുള്ള അക്ഷരസഞ്ചയങ്ങള്‍</title_ml>
      <title_pl>Transformacje znaków dla nieautoresywnego oznaczania GEC</title_pl>
      <title_si>ස්වයංක්‍රියාත්මක නැති GEC ටැග් එක්ක අක්ෂර රූපණය</title_si>
      <title_sv>Teckenomvandlingar för icke-autoregressiv GEC-märkning</title_sv>
      <title_ta>தானியங்கி கட்டுப்படுத்தாத GEC ஒட்டுதலுக்கான எழுத்து மாற்றம்</title_ta>
      <title_sr>transformacija karaktera za neo-autoregresivnu oznake GEC</title_sr>
      <title_so>Tilmaamaha xarafka ee aan Autoregressive GEC Tagging</title_so>
      <title_ro>Transformări de caractere pentru etichetarea GEC non-autoregresivă</title_ro>
      <title_ur>غیر-اٹوگریسٹی GEC ٹاگ کے لئے کارٹر تبدیل</title_ur>
      <title_uz>Comment</title_uz>
      <title_vi>Thay đổi ký tự cho thẻ GED Khác tự động</title_vi>
      <title_bg>Трансформации на знаците за неавторегресивно GEC етикетиране</title_bg>
      <title_da>Tegntransformationer for ikke- autoregressiv GEC- mærkning</title_da>
      <title_nl>Tekentransformaties voor niet-autoregressieve GEC-tagging</title_nl>
      <title_hr>Transformacija znakova za neo-autoregresivno označavanje GEC-a</title_hr>
      <title_de>Charaktertransformationen für nicht autoregressives GEC-Tagging</title_de>
      <title_fa>تغییرات شخصیت برای برچسب GEC غیر خودکار</title_fa>
      <title_id>Transformasi Karakter untuk Tagging GEC Non-Autoregressive</title_id>
      <title_ko>회귀하지 않은 GEC 태그의 문자 변환</title_ko>
      <title_sw>Mabadiliko ya Kialama kwa Kigezo cha GEC</title_sw>
      <title_tr>Otomatik gaýd etmek üçin Karkater üýtgewleri</title_tr>
      <title_af>Karakter Transformasies vir Non- Autoregressive GEC etiket</title_af>
      <title_sq>Transformimi i karakterëve për etiketën GEC jo-autoregresive</title_sq>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Սիմպերի փոխակերպումներ ոչ ավտոռեգրեսիվ</title_hy>
      <title_az>Otomatik-regressiv GEC etiketi 칲칞칲n Karakter T톛rc칲m톛l톛ri</title_az>
      <title_bn>অক্ষর- স্বয়ংক্রিয়ভাবে GEC ট্যাগিং এর জন্য অক্ষর পরিবর্তন</title_bn>
      <title_ca>Transformacions de caràcters per etiquetar GEC no autoregressiv</title_ca>
      <title_bs>Transformacija karaktera za ne-autoregresivnu oznake GEC-a</title_bs>
      <title_cs>Transformace znaků pro neautoregresivní GEC tagování</title_cs>
      <title_et>Mitte-autoregressiivse GEC märgistamise tähemärkide teisendused</title_et>
      <title_fi>Merkkimuutokset ei-autoregressiiviselle GEC-tunnisteelle</title_fi>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Preoblikovanje znakov za nesamoregresivno označevanje GEC</title_sk>
      <title_he>Character Transformations for Non-Autoregressive GEC Tagging</title_he>
      <title_jv>GEC</title_jv>
      <title_bo>GEC མཚོན་རྟགས་མེད་པའི་རང་འགུལ་གྱིས་མཚོན་རྟགས་ལ་འགྱུར་བ</title_bo>
      <abstract_fr>Nous proposons une approche GEC non autorégressive basée sur les caractères, avec des transformations de caractères générées automatiquement. Récemment, la classification par mot des modifications de correction s'est révélée être une alternative efficace et parallélisable aux systèmes GEC codeur-décodeur actuels. Nous montrons que les modifications de remplacement de mots peuvent être sous-optimales et entraîner une explosion des règles d'orthographe, de diacritisation et d'erreurs dans les langues morphologiquement riches, et proposons une méthode pour générer des transformations de caractères à partir du corpus GEC. Enfin, nous entraînons des modèles de transformation de caractères pour le tchèque, l'allemand et le russe, obtenant des résultats solides et une accélération spectaculaire par rapport aux systèmes autorégressifs. Le code source est publié à l'adresse https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_fr>
      <abstract_ar>نقترح نهج GEC غير ذاتي الانحدار القائم على الشخصية ، مع تحويلات شخصية يتم إنشاؤها تلقائيًا. في الآونة الأخيرة ، أثبت التصنيف لكل كلمة لتعديلات التصحيح أنه بديل فعال وقابل للتوازي لأنظمة GEC الحالية لفك التشفير والتشفير. نوضح أن تعديلات استبدال الكلمات قد تكون دون المستوى الأمثل وتؤدي إلى انفجار قواعد التهجئة والتشكيل والأخطاء في اللغات الغنية شكليًا ، ونقترح طريقة لتوليد تحويلات الأحرف من مجموعة GEC. أخيرًا ، نقوم بتدريب نماذج تحويل الشخصية للغة التشيكية والألمانية والروسية ، للوصول إلى نتائج قوية وتسريع كبير مقارنة بأنظمة الانحدار الذاتي. تم تحرير كود المصدر على https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ar>
      <abstract_pt>Propomos uma abordagem GEC não autorregressiva baseada em caracteres, com transformações de caracteres geradas automaticamente. Recentemente, a classificação por palavra de edições de correção provou ser uma alternativa eficiente e paralelizável aos atuais sistemas GEC de codificador-decodificador. Mostramos que as edições de substituição de palavras podem ser subótimas e levar à explosão de regras de ortografia, diacritização e erros em línguas morfologicamente ricas, e propomos um método para gerar transformações de caracteres a partir do corpus GEC. Por fim, treinamos modelos de transformação de caracteres para tcheco, alemão e russo, alcançando resultados sólidos e aceleração dramática em comparação com sistemas autorregressivos. O código-fonte está disponível em https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_pt>
      <abstract_es>Proponemos un enfoque GEC no autorregresivo basado en caracteres, con transformaciones de personajes generadas automáticamente. Recientemente, la clasificación por palabra de las ediciones de corrección ha demostrado ser una alternativa eficiente y paralelizable a los sistemas GEC de codificador-decodificador actuales. Demostramos que las ediciones de reemplazo de palabras pueden no ser óptimas y dar lugar a una explosión de reglas de ortografía, diacritización y errores en lenguajes ricos morfológicamente, y proponemos un método para generar transformaciones de caracteres a partir del corpus de GEC. Finalmente, entrenamos modelos de transformación de personajes para checo, alemán y ruso, alcanzando resultados sólidos y una aceleración espectacular en comparación con los sistemas autorregresivos. El código fuente se publica en https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_es>
      <abstract_zh>立字符者非自归GEC法,有自生者转换之。 近者,正编辑每字分类已证当今编码器 - 解码器GEC系统之高效,可并行化者代方案。 明单词代辑或非佳,而形容富语之拼写,变音符号化谬之则爆炸式长,发GEC语料库成字符转换之法。 终于捷克语、德语、俄语训字符转换模型,比之自归,其效著也速。 源代码发于 https://github.com/ufal/wnut2021_character_transformations_gec 。</abstract_zh>
      <abstract_hi>हम एक चरित्र-आधारित गैर-autoregressive जीईसी दृष्टिकोण का प्रस्ताव करते हैं, जिसमें स्वचालित रूप से उत्पन्न चरित्र परिवर्तन होते हैं। हाल ही में, सुधार संपादन के प्रति-शब्द वर्गीकरण ने वर्तमान एनकोडर-डिकोडर जीईसी सिस्टम के लिए एक कुशल, समानांतर विकल्प साबित किया है। हम दिखाते हैं कि शब्द प्रतिस्थापन संपादन सबऑप्टिमल हो सकते हैं और रूपात्मक रूप से समृद्ध भाषाओं में वर्तनी, डायक्रिटाइजेशन और त्रुटियों के लिए नियमों के विस्फोट का कारण बन सकते हैं, और जीईसी कॉर्पस से चरित्र परिवर्तन उत्पन्न करने के लिए एक विधि का प्रस्ताव करते हैं। अंत में, हम चेक, जर्मन और रूसी के लिए चरित्र परिवर्तन मॉडल को प्रशिक्षित करते हैं, जो ऑटोरिग्रेसिव सिस्टम की तुलना में ठोस परिणाम और नाटकीय गति तक पहुंचते हैं। स्रोत कोड https://github.com/ufal/wnut2021_character_transformations_gec पर जारी किया जाता है।</abstract_hi>
      <abstract_ja>自動生成された文字変換を含む、文字ベースの非自動回帰GECアプローチを提案します。最近、修正編集の単語ごとの分類は、現在のエンコーダデコーダＧＥＣシステムの効率的で並列化可能な代替手段であることが証明されている。単語置換編集は最適ではなく、形態的に豊富な言語でのスペル、ダイアクリティカル、エラーの規則の拡大につながる可能性があることを示し、GECコーパスから文字変換を生成する方法を提案します。最後に、チェコ、ドイツ、ロシア向けの文字変換モデルをトレーニングし、自動回帰システムと比較して確かな結果と劇的なスピードアップに到達します。ソースコードはhttps://github.com/ufal/wnut2021_character_transformations_gecで公開されています。</abstract_ja>
      <abstract_ru>Мы предлагаем основанный на персонажах неавторегрессивный подход GEC с автоматически генерируемыми преобразованиями символов. В последнее время классификация правок коррекции по словам оказалась эффективной, параллельной альтернативой существующим системам кодировщик-декодер GEC. Показано, что правки замены слов могут быть неоптимальными и приводить к взрыву правил орфографии, диакритизации и ошибок в морфологически богатых языках, и предложен метод генерации преобразований символов из корпуса GEC. Наконец, мы тренируем модели трансформации персонажей для чешских, немецких и русских, достигая твердых результатов и резкого ускорения по сравнению с авторегрессивными системами. Исходный код выпускается по адресу https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ru>
      <abstract_ga>Molaimid cur chuige GEC neamh-uathchéimnitheach atá bunaithe ar charachtair, le claochluithe carachtar ginte go huathoibríoch. Le déanaí, tá aicmiú in aghaidh an fhocail ar athruithe ceartúcháin cruthaithe mar rogha eile éifeachtach, comhthreomhar le córais reatha ionchódóra-díchódóra GEC. Léirímid go bhféadfadh athruithe athsholáthair focal a bheith fo-optamach agus go dtiocfaidh pléascadh ar rialacha litrithe, diacritization agus earráidí i dteangacha atá saibhir ó thaobh moirfeolaíochta de, agus molaimid modh chun claochluithe carachtar a ghiniúint ó chorpas GEC. Ar deireadh, déanaimid oiliúint ar mhúnlaí claochlaithe carachtar don tSeicis, don Ghearmáinis agus don Rúisis, ag baint amach torthaí daingne agus luasghéarú drámatúil i gcomparáid le córais uath-aischéimnitheacha. Eisítear an cód foinse ag https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ga>
      <abstract_el>Προτείνουμε μια προσέγγιση που βασίζεται σε χαρακτήρες, με αυτόματα παραγόμενους μετασχηματισμούς χαρακτήρων. Πρόσφατα, η ανά λέξη ταξινόμηση διορθωτικών επεξεργασιών έχει αποδειχθεί μια αποτελεσματική, παράλληλη εναλλακτική λύση στα τρέχοντα συστήματα κωδικοποιητή-αποκωδικοποιητή. Δείχνουμε ότι οι επεξεργασίες αντικατάστασης λέξεων μπορεί να είναι υποβέλτιστες και να οδηγήσουν σε έκρηξη κανόνων ορθογραφίας, διαλριτικής και σφαλμάτων σε μορφολογικά πλούσιες γλώσσες, και προτείνουμε μια μέθοδο για τη δημιουργία μετασχηματισμών χαρακτήρων από το σώμα της ΓΕΚ. Τέλος, εκπαιδεύουμε μοντέλα μετασχηματισμού χαρακτήρων για τσεχικά, γερμανικά και ρωσικά, επιτυγχάνοντας σταθερά αποτελέσματα και δραματική επιτάχυνση σε σύγκριση με τα αυτοανακριτικά συστήματα. Ο πηγαίος κώδικας δημοσιεύεται στο https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_el>
      <abstract_ka>ჩვენ აჩვენებთ სიმბოლოების უფრო ავტორეგრესიგური GEC პროგრამი, რომელიც ავტომატურად შექმნილი სიმბოლოების განცვლებით. მიმდინარე, რედაქტირება რედაქტირების კლასიფიკაცია ერთ სიტყვებით ეფექტიური, პარალელიზაციური ალტენტიფიკაცია მიმდინარე რედაქტირების GEC სისტემაში. ჩვენ გამოჩვენებთ, რომ სიტყვის შეცვლის რედაქტირები შეიძლება იყოს სუპოტიმალური და გამოყენება სიტყვის, დიაკრიტიზაციის და შეცდომას მორპოლოგიურად ბედნიერი ენაში, და შეგიძლია GEC corpus-ის სიტყვირ საბოლოოდ, ჩვენ ფექი, გერმანეთი და პროსიის რესტრანფორმაციის მოდელების გასწავლავთ, რომლებიც ძალიან წარმოდგენები და დირამატიკური სიგრძნობა, რომლებიც ავტორეგ მხოლოდ კოდის გახსნა https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ka>
      <abstract_hu>Karakteralapú, nem autoregresszív GEC megközelítést javasolunk, automatikusan generált karakter transzformációkkal. Az utóbbi időben a korrekciós szerkesztések szónkénti osztályozása hatékony, párhuzamosan használható alternatívát bizonyított a jelenlegi kódoló-dekóder GEC rendszerekkel szemben. Megmutatjuk, hogy a szóhelyettesítő szerkesztések optimálisak lehetnek, és morfológiailag gazdag nyelveken a helyesírásra, a diakritizációra és a hibákra vonatkozó szabályok robbanásához vezethetnek, továbbá javaslatot teszünk egy módszerrel a GEC corpusból történő karakter transzformációk generálására. Végezetül a karakter transzformációs modelleket képezünk cseh, német és orosz számára, szilárd eredményeket és drámai gyorsulást érve el az autoregresszív rendszerekhez képest. A forráskód a következő címen kerül kiadásra: https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_hu>
      <abstract_lt>Siūlome ne autoregresinį GEC metodą, pagrįstą simboliais, su automatiškai sukurtais simbolių transformavimais. Pastaruoju metu korekcinių redakcijų vienažodžiu klasifikavimas parodė veiksmingą, paralelizuojamą alternatyvą dabartinėms GEC kodavimo sistemoms. We show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus.  Galiausiai mokome Čekijos, Vokietijos ir Rusijos simbolių pertvarkymo modelius, pasiekiančius tvirtus rezultatus ir dramatišką greitį, palyginti su autoregressinėmis sistemomis. Šaltinis kodas skelbiamas https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_lt>
      <abstract_it>Proponiamo un approccio GEC non autoregressivo basato sui caratteri, con trasformazioni dei caratteri generate automaticamente. Recentemente, la classificazione per parola delle modifiche di correzione si è dimostrata un'alternativa efficiente e parallela agli attuali sistemi GEC encoder-decoder. Mostriamo che le modifiche di sostituzione delle parole possono essere subottimali e portare all'esplosione di regole per l'ortografia, la diacritizzazione e gli errori nei linguaggi morfologicamente ricchi, e proponiamo un metodo per generare trasformazioni dei caratteri dal corpus GEC. Infine, addestriamo modelli di trasformazione dei personaggi per ceco, tedesco e russo, raggiungendo risultati solidi e velocità drammatiche rispetto ai sistemi autoregressivi. Il codice sorgente è rilasciato a https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_it>
      <abstract_kk>Біз таңбалар негіздеген авторегрессивні емес GEC қасиетін, автоматты түрде құрылған таңбалар түрлендіруді таңдаймыз. Соңғы уақытта, өзгертулерді түзету үшін сөздердің классификациясы назардағы кодер- декодердің GEC жүйелеріне эффективні, параллелизациялық альтернативті көрсетті. Біз сөздерді алмастыру өзгертулері ішкі оптималдық болып, емлеу, диакритизациялау және қателерді морфологиялық бағатты тілдерде жұмыс істейді, және GEC корпустағы таңбаларды түрлендіру әдісін жасау арқылы Соңында, біз таңбаларды түрлендіру үлгілерін Чех, Неміс және Орус үшін ұқсатып, авторегрессивнің жүйелеріне салыстырып, қатты нәтижелерді және драматикалық жылдамдығы Бастапқы код тасталған https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_kk>
      <abstract_mk>Предложуваме неавторегресивен пристап на генерални симболи, со автоматски генерирани трансформации на симболи. Неодамна, класификацијата по збор на корекциски уредувања се покажа како ефикасна, паралелизирана алтернатива на актуелните системи на кодер-декодер GEC. Покажуваме дека уредувањата за замена на зборови можат да бидат неоптимални и да водат до експлозија на правилата за правопис, дијакритизација и грешки на морфолошки богати јазици, и предложуваме метод за генерирање трансформации на карактери од ГЕЦ корпус. Finally, we train character transformation models for Czech, German and Russian, reaching solid results and dramatic speedup compared to autoregressive systems.  Изворниот код е објавен на https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_mk>
      <abstract_ml>സ്വയമായി സൃഷ്ടിച്ചിരിക്കുന്ന അക്ഷരരൂപത്തിന്റെ അടിസ്ഥാനമില്ലാത്ത ജിസിയുടെ പ്രോഗത്തില്‍ നാം പ്രായശ്ച അടുത്തിടെ സംഭവിച്ചിരിക്കുന്ന സംവിധാനങ്ങളുടെ ഒരു വാക്കിന്റെ ക്ലാസ്ഫിക്ഷന്‍ നിര്‍ണ്ണയിച്ചിരിക്കുന്നു. ഇപ്പോഴത്തെ ക വാക്ക് മാറ്റുന്നതിന്റെ എഡിറ്ററുകള്‍ സബ്പ്രാപ്റ്റിമാല്‍ ആയിരിക്കാം. വാക്ക് മാറ്റുന്നതിനുള്ള നിയമങ്ങള്‍ പൊട്ടിപ്പിടിക്കുന്നതിനായിരിക്കാം.  അവസാനം, നമ്മള്‍ ചെക്ക്, ജര്‍മ്മന്‍, റഷ്യന്‍ എന്നിവര്‍ക്കുള്ള അക്ഷരരൂപത്തിന്റെ മാതൃകങ്ങള്‍ പരിശീലിപ്പിക്കുന്നു. സ്വയം രോഗിക്കുന്ന സ ഉറവിട കോഡ് വിടുന്നു https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ml>
      <abstract_ms>Kami cadangkan pendekatan GEC bukan-autoregresif berdasarkan aksara, dengan perubahan aksara yang dijana secara automatik. Baru-baru ini, klasifikasi per-perkataan edit penyesuaian telah membuktikan alternatif yang efisien, boleh bersamaan dengan sistem GEC pengekod-penyesuaian semasa. We show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus.  Akhirnya, kita melatih model pengubahan aksara untuk Czech, Jerman dan Rusia, mencapai keputusan yang kuat dan kecepatan dramatik dibandingkan dengan sistem autoregresif. Kod sumber dibebaskan pada https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ms>
      <abstract_mt>Aħna nipproponu approċċ GEC mhux awtoregressiv ibbażat fuq il-karattri, bi trasformazzjonijiet tal-karattri ġġenerati awtomatikament. Dan l-aħħar, il-klassifikazzjoni ta’ kull kelma tal-edits tal-korrezzjoni wriet alternattiva effiċjenti u parallelizzabbli għas-sistemi attwali tal-GEC tal-kodifikatur. Aħna nuru li l-editjar tas-sostituzzjoni tal-kliem jista’ jkun subottimali u jwassal għal splużjoni ta’ regoli għall-ortografija, id-dijakritizzazzjoni u l-iżbalji f’lingwi morfoloġikament rikki, u nipproponu metodu għall-ġenerazzjoni ta’ trasformazzjonijiet tal-karattri mill-GEC corpus. Finally, we train character transformation models for Czech, German and Russian, reaching solid results and dramatic speedup compared to autoregressive systems.  Il-kodiċi tas-sors jiġi rilaxxat fuq https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_mt>
      <abstract_no>Vi foreslår ein ikkje-autoregressiv GEC-tilnærming med automatisk genererte teikn-transformasjonar. Nyleg har det vist ein effektiv, paralleliserbar alternativ for gjeldande GEC-koderingssystemer for kvar ordklassifikasjon av korrigeringsredigeringar. Vi viser at orderstatningsredigeringar kan vera underoptimal og føre til eksplodering av reglar for staving, diakritisering og feil i morfologisk rike språk, og foreslår ein metode for å laga teiknverstatningar frå GEC corpus. I slutt treng vi teiknstransformasjonsmodeller for tsjekkisk, tysk og russisk, når vi når solide resultat og dramatiske raskaren sammenlignet med autoregressive systemer. Kjeldekode vert sletta på https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_no>
      <abstract_pl>Proponujemy podejście GEC oparte na znakach, z automatycznie generowanymi transformacjami znaków. Ostatnio klasyfikacja na słowo edycji korekcyjnych okazała się skuteczną, równoległą alternatywą dla obecnych systemów kodera-dekodera GEC. Pokazujemy, że edycje zastępcze słów mogą być nieoptymalne i prowadzić do eksplozji reguł pisowni, diakrytyzacji i błędów w językach bogatych morfologicznie, oraz proponujemy metodę generowania transformacji znaków z korpusu GEC. Wreszcie szkolimy modele transformacji postaci dla czeskich, niemieckich i rosyjskich, osiągając solidne wyniki i dramatyczne przyspieszenie w porównaniu z systemami autoregresywnymi. Kod źródłowy jest publikowany pod adresem: https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_pl>
      <abstract_mn>Бид үүнийг автоматжуулах биш, автоматжуулах бус GEC арга замыг автоматжуулан бий болгон өөрчлөлт хийсэн. Саяхан зөв засварлалтын нэг үг хуваалтын нэг хэлбэрээр өнөөгийн кодчуудын GEC системийн эффектив, параллелизацийн альтернативийг баталсан. Бид үгийг орлуулах загварын загварын төгсгөл нь бага зэрэгцээ байж болох бөгөөд үгийг бичих, диаграматик болон алдаа дэвшүүлэх загварын төлөвлөгөөг харуулж болно. Эцэст нь бид Чех, Герман, Оросын харьцааны өөрчлөлтийн загварын загварыг суралцаж автоматжуулах системтэй харьцуулахад хатуу үр дүнг, хурдан хүрэх болно. Гэхдээ эх үүсвэрийн код https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_mn>
      <abstract_sr>Predlažemo neodresivan GEC pristup na karakteru, sa automatskim generiranim transformacijama karaktera. Nedavno je klasifikacija redaktora korekcije na reèi dokazala efikasnu, parallelizivu alternativu za trenutne GEC sisteme kodera-dekodera. Pokazujemo da redakcije zamjene reči mogu biti suboptimalne i dovesti do eksplozije pravila za pisanje, dijakritizaciju i greške na morfološki bogatim jezicima, i predlažemo metodu za stvaranje karakterskih transformacija iz GEC korpusa. Konačno treniramo modele transformacije karaktera za češke, nemačke i ruske, postižeći čvrste rezultate i dramatične ubrzanje u usporedbi sa autoregresivnim sistemima. Izvorni kod je objavljen na https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_sr>
      <abstract_ro>Propunem o abordare GEC non-autoregresivă bazată pe caractere, cu transformări generate automat de caractere. Recent, clasificarea pe cuvânt a editărilor de corecție s-a dovedit a fi o alternativă eficientă, paralelizabilă la sistemele actuale de codificator-decodor GEC. Arătăm că editările de înlocuire a cuvintelor pot fi suboptime și pot duce la explozia regulilor de ortografie, diacritizare și erori în limbi bogate din punct de vedere morfologic, și propunem o metodă de generare a transformărilor caractere din corpul GEC. În cele din urmă, pregătim modele de transformare a personajelor pentru cehă, germană și rusă, atingând rezultate solide și viteză dramatică comparativ cu sistemele autoregresive. Codul sursă este lansat la https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ro>
      <abstract_si>අපි ස්වයංක්‍රියාත්මකයෙන් ස්වයංක්‍රියාත්මක වෙනස් කරන්න පුළුවන්, ස්වයංක්‍රියාත්මක වෙනස් කරන අවසානයෙන්, වාර්තාවක් වෙනුවෙන් වාර්තාවක් පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ප්‍රයෝජනයක් ප්‍රතික්‍රීය, සමාන්තිකය අපි පෙන්වන්නේ වචන වෙනස් සම්ප්‍රතිකාරය සම්ප්‍රතිකාරය වෙනුවෙන් ප්‍රතිකාරයක් වෙන්න පුළුවන් විදිහට සහ ප්‍රතිකාරයක් වෙන්න පුළුවන් වෙ අන්තිමේදී, අපි චෙක්, ජර්මන් සහ රුසියාන් වලට ප්‍රමාණය වෙනස් මොඩේල් කිරීම් කරනවා, ස්වයංක්‍රීය පද්ධතිය සමග සාමා මූල කෝඩ් නිදහස් කරලා තියෙනවා https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_si>
      <abstract_so>Waxaynu soo jeedaynaa qaab aan iskumar aheyn GEC, taasoo lagu beddelo isbedelka xarafka. Muddii u dhowaaday, fasax-fasax-si-u-qorista hagaajinta ayaa caddey mid faa’iido leh oo isku eg kara nidaamka GEC-ka. Waxaynu tusnaynaa in qoraalka beddelashada hadalka ay noqon karaan suboptimal, waxaana laga yaabaa in la soo firdhiyo sharciyada ku qoran hadalka, kaluumeysiga iyo qaladka afka hodanka ah, iyo in loo soo jeediyo qaab ay ku soo bedelaan isbedelka qoyska GEC. Ugu dambaysta, waxaynu tababarinnaa qaabab beddelasho oo ku saabsan nidaamka iskumarka ah ee Czech, Jarmalka iyo Ruushka, waxaynu gaadhnaa resultooyin adag iyo dhaqdhaqaaq aad u badan. Kaarka asalka ayaa lagu furaa https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_so>
      <abstract_ta>தானாகவே உருவாக்கப்பட்ட எழுத்து மாற்றங்களை உருவாக்கிய எழுத்து அடிப்படையில்லாத GEC முறைமை சமீபத்தில், திருத்தம் தொகுப்புகளின் ஒவ்வொரு வார்த்தை வகைப்படுத்தல் தற்போதைய குறியீட்டு குறியீட்டாளர் GEC அமைப்புகளுக்கு  வார்த்தை மாற்றுதல் திருத்தல் துணை உப்பாரிப்பாக இருக்கலாம் மற்றும் எழுத்து, குறிப்பிடுதல் மற்றும் பிழைகளில் பிழைகள் விதிக்கப்படும் விதிகளை காட்டு இறுதியில், நாம் செக்கு, ஜெர்மன் மற்றும் ரஷ்ஷிக்கான எழுத்து மாற்றங்கள் மாதிரிகளை பயிற்சி செய்கிறோம், உறுதியான முடிவுகள் மற்ற The source code is released at  https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ta>
      <abstract_sv>Vi föreslår ett karaktärsbaserat icke-autoregressivt GEC-tillvägagångssätt, med automatiskt genererade teckenförändringar. Nyligen har klassificering per ord av korrigeringar visat sig vara ett effektivt, parallellt alternativ till nuvarande kodare-avkodare GEC-system. Vi visar att ordersättningsredigeringar kan vara suboptimala och leda till explosion av regler för stavning, diakritik och fel i morfologiskt rika språk, och föreslår en metod för att generera teckenförändringar från GEC corpus. Slutligen tränar vi karaktärsomvandlingsmodeller för tjeckiska, tyska och ryska och uppnår goda resultat och dramatisk snabbhet jämfört med autoregressiva system. Källkoden släpps på https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_sv>
      <abstract_ur>ہم ایک شخصت بنیادی غیر autoregressive GEC طریقے سے پیشنهاد کرتے ہیں، جسے اپنے ساتھ پیدا کیا گیا شخصت تبدیل کرنے کے ساتھ۔ اچھے سے، اصلاح ویڈیٹوں کی ہر کلیفوں کی کلیفوں نے ایک مفید، parallelizable GEC سیسٹم کے لئے موجود Encoder-decoder سیسٹموں کی alternativa ثابت کی ہے. ہم دکھاتے ہیں کہ کلمات بدلنے کی ویڈیوں میں زیادی اچھی ہو سکتی ہیں اور اسپے سمجھنے کی، دیاکریٹیزی اور خطاؤں کے لئے فیصلہ کرنے کی قوانین کی وجہ سے ہوسکتی ہے، اور GEC کورپوس سے شخصیٹ تبدیل کرنے کے لئے ایک طریقہ پیش کرتا ہے۔ آخر میں ہم چک, جرمن اور روسی کے لئے شخصیت تبدیل کی موڈل کی تعلیم دیتے ہیں، مضبوط نتیجے پہنچ رہے ہیں اور اٹو ریگرسی سیستموں کے مقابلہ میں بہت جلد سرعت پہنچ رہے ہیں. سورس کوڈ اس میں منتشر کیا گیا ہے https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ur>
      <abstract_uz>Biz avtomatik yaratilgan belgilarni avtomatik o'zgartirish bilan avto'g'ri raqamlarni qoʻllash. Yaqinda, tasdiqlash tahrirchini bir so'zlar tahrirlash imkoniyatini joriy kod- dekoder GEC tizimlariga yetarli boʻlgan va moslama koʻrsatadi. Biz so'zlarni almashtirish tahrirlarini suboptimal bo'lishi mumkin va o'zgarishni o'zgartirish qoidalarini o'zgartirish mumkin, o'zgartirish va yordamida o'zgartirish qoidalarini o'zgartirish mumkin, o'zgarishni boshqarishi mumkin va GEC kompyuterdagi chegaralardan o'zgartirish usulini tayyorlash. Oxirgi biz Chekscha, Olmon va Ruscha uchun qobiliyat o'zgarishni o'rganamiz, va avto-regressiv tizimlarga o'xshash natijalari va dramatik tezligini o'rganamiz. Manba kodi https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_uz>
      <abstract_vi>Chúng tôi đề nghị một phương pháp chiều cao không có ký tự, với các biến đổi nhân cách tự động. Gần đây, tỉ lệ các sửa chữa từng từ đã chứng minh một thay đổi hiệu quả, tương song có thể so sánh với hệ thống mã hóa trang. Chúng tôi cho thấy rằng các chuỗi thay thế từ có thể không tối ưu và dẫn đến việc phá vỡ các quy tắc về đánh vần, nhật tính và lỗi trong các ngôn ngữ có độ phong phú, và đề nghị một phương pháp tạo ra biến đổi nhân vật từ cơ thể GED. Cuối cùng, chúng tôi huấn luyện các mô hình biến đổi nhân cách cho người Séc, Đức và Nga, đạt được kết quả tích cực và tăng tốc kịch tính so với hệ thống tự vệ. Nguồn mã được phát ra tại https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_vi>
      <abstract_bg>Предлагаме базиран на знаци неавторегресивен подход с автоматично генерирани преобразувания на знаците. Напоследък класификацията на корекционните редакции на една дума се оказа ефективна, успоредна алтернатива на текущите кодер-декодерни системи. Показваме, че редакциите за заместване на думата могат да бъдат неоптимални и да доведат до експлозия на правила за правопис, диакритизация и грешки в морфологично богати езици и предлагаме метод за генериране на трансформации на знаците от корпуса. Накрая тренираме модели за трансформация на герои за чешки, немски и руски, достигайки солидни резултати и драматично ускорение в сравнение с авторегресивните системи. Изходният код се издава на https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_bg>
      <abstract_da>Vi foreslår en karakterbaseret ikke-autoregressiv GEC-tilgang, med automatisk genererede tegn transformationer. For nylig har pr. ord klassificering af korrektionsredigeringer vist sig at være et effektivt, parallelt alternativ til nuværende encoder-dekoder GEC systemer. Vi viser, at orderstatning redigeringer kan være suboptimale og føre til eksplosion af regler for stavning, diakritik og fejl i morfologisk rige sprog, og foreslår en metode til at generere tegn transformationer fra GEC corpus. Endelig træner vi figurtransformationsmodeller til tjekkiske, tyske og russiske og opnår solide resultater og dramatisk hastighed sammenlignet med autoregressive systemer. Kildekoden udgives på https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_da>
      <abstract_hr>Predlažemo neodresivan pristup GEC-a na karakteru, s automatskim proizvedenim transformacijama karaktera. Nedavno je klasifikacija redaktora korekcije na riječima dokazala učinkovitu, paralleliziranu alternativu za trenutne GEC sustave kodera-dekodera. Pokazujemo da editori zamjene riječi mogu biti podoptimalni i dovesti do eksplozije pravila za pisanje, diakritizaciju i greške na morfološki bogatim jezicima i predložiti metodu za stvaranje transformacija karaktera iz GEC corpus a. Konačno treniramo modele transformacije karaktera za češke, nemačke i ruske, postižeći čvrste rezultate i dramatične ubrzanje u usporedbi s autoregresivnim sustavima. Izvorni kod je objavljen na https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_hr>
      <abstract_nl>We stellen een karaktergebaseerde niet-autoregressieve GEC-benadering voor, met automatisch gegenereerde karaktertransformaties. Recent is de classificatie per woord van correctiebewerkingen een efficiënt, parallelliseerbaar alternatief gebleken voor huidige encoder-decoder GEC-systemen. We tonen aan dat woordvervangende bewerkingen suboptimaal kunnen zijn en leiden tot explosie van regels voor spelling, diacritisatie en fouten in morfologisch rijke talen, en stellen een methode voor het genereren van tekentransformaties uit GEC corpus voor. Ten slotte trainen we karaktertransformatiemodellen voor Tsjechisch, Duits en Russisch, met solide resultaten en een dramatische versnelling in vergelijking met autoregressieve systemen. De broncode wordt vrijgegeven op: https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_nl>
      <abstract_de>Wir schlagen einen charakterbasierten, nicht autoregressiven GEC-Ansatz mit automatisch generierten Zeichentransformationen vor. In jüngster Zeit hat sich die Pro-Wort-Klassifizierung von Korrekturbearbeitungen als effiziente, parallelisierbare Alternative zu aktuellen Encoder-Decoder GEC-Systemen bewährt. Wir zeigen, dass Wortersatz-Bearbeitungen suboptimal sind und zu einer Explosion von Regeln für Rechtschreibung, Diakritisierung und Fehler in morphologisch reichen Sprachen führen können, und schlagen eine Methode vor, um Zeichentransformationen aus GEC-Korpus zu generieren. Schließlich trainieren wir Charaktertransformationsmodelle für Tschechisch, Deutsch und Russisch, um solide Ergebnisse und dramatische Beschleunigungen im Vergleich zu autoregressiven Systemen zu erzielen. Der Quellcode wird veröffentlicht unter https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_de>
      <abstract_ko>우리는 문자를 기반으로 하는 비자귀환 GEC 방법을 제시하여 문자 변환을 자동으로 생성했다.최근에 교정 편집의 모든 글자 분류는 현재 인코더 - 디코더 GEC 시스템의 유효하고 병행 가능한 대체 방안으로 증명되었다.우리는 형태가 풍부한 언어에서 단어 교체 편집이 최우선일 수 있음을 증명하고 맞춤법, 변음, 오류 규칙의 폭발적인 증가를 초래하며 GEC 어료 라이브러리에서 문자 변환을 생성하는 방법을 제시했다.마지막으로 우리는 체코, 독일, 러시아의 문자 변환 모델을 훈련시켜 자귀환 시스템에 비해 믿을 만한 결과와 현저한 가속화를 얻었다.소스 코드 게시https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ko>
      <abstract_id>Kami mengusulkan pendekatan GEC bukan-autoregresif berdasarkan karakter, dengan transformasi karakter yang dibuat secara otomatis. Baru-baru ini, klasifikasi per kata dari edit koreksi telah membuktikan sebuah alternatif efisien, yang dapat disertai dengan sistem GEC pengekode-dekoder saat ini. Kami menunjukkan bahwa edit pengganti kata mungkin tidak optimal dan menyebabkan ledakan peraturan untuk mengeja, diakritisasi dan kesalahan dalam bahasa morfologis kaya, dan mengusulkan metode untuk menghasilkan transformasi karakter dari GEC corpus. Akhirnya, kami melatih model transformasi karakter untuk Ceko, Jerman dan Rusia, mencapai hasil yang kuat dan kecepatan dramatis dibandingkan dengan sistem autoregresif. The source code is released at  https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_id>
      <abstract_sw>Tunazipendekeza mbinu za GEC zisizo na tabia zisizo na kibinafsi, yenye mabadiliko ya tabia. Hivi karibuni, usambazaji wa uharibifu wa kila maneno umethibitisha kuwa ni mbadala yenye ufanisi na inayofanana na mifumo ya GEC ya sasa ya kodi. We show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus.  Mwisho, tunafundisha mifano ya mabadiliko ya wahusika kwa ajili ya Czech, Ujerumani na Urusi, kufikia matokeo imara na kasi ya haraka ukilinganishwa na mifumo ya kudhibiti. Kodi la chanzo limetolewa kwenye https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_sw>
      <abstract_fa>ما پیشنهاد می‌کنیم یک روش GEC غیر خودگریسی بر روی شخصیت با تغییرات شخصیت خودکار تولید شده. اخیرا، کلیسازی هر کلمه از ویدئات اصلاح یک جایگزینه موثرت و پارالی قابل تغییر برای سیستم‌های سیستم‌های اکندیدر GEC فعلی ثابت کرده است. ما نشان می دهیم که ویدئات جایگزینی کلمات ممکن است زیر optimal باشد و به انفجار قوانین برای نوشتن، دیکریتازی و اشتباهی در زبانهای پولدار مورفولوژیکی باشد، و یک روش برای تولید تغییرات شخصیت از کورپوس GEC پیشنهاد می دهد. بالاخره، ما مدل تغییر شخصیت را برای چک، آلمان و روسی آموزش می دهیم، به نتیجه محکم و سرعت dramatic در مقایسه با سیستم‌های خودگریسی رسیدیم. کد منبع در https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_fa>
      <abstract_tr>Biz karakterlere tabalanmaýan otoregressiv GEC metodlary teklip edip, karakterlere otomatik üretildi. Soňra, düzeltmek editlerniň sözleriň klasifikasynda häzirki kodeýçler GEC sistemlerine etkinlik, parallelitik bir alternatiw bardyr. Biz sözleri almak düzenlerini suboptimal bolup biler we morfolojik baý dillerde ýüz tutmak, karakter üýtgewlerini GEC korpusdan döretmek üçin bir yöntemi üýtgedip biler. Soňunda biz Karakter üýtgetmeli nusgalary Çehiýa, Almança we Rusça üçin öwrenip otyrdyk, awtomatik regressiv sistemalara görä gaty netijelere ýetirdik. %s-iň üstine bellenilýär. https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_tr>
      <abstract_af>Ons voorstel 'n karaktergebaseerde non- autoregressive GEC toegang, met outomaties genereerde karaktertransformasies. Onlangs het 'n effektief, paralleliseerbare alternatief vir huidige enkoder- dekoder GEC stelsels bevestig. Ons wys dat woord vervang redigeerders dalk suboptimal kan wees en lei na uitbreiding van reëls vir spel, diakritisering en foute in morfologiese ryk tale en voorstel 'n metode vir die genereer van karaktertransformasies van GEC corpus. Eindelik, ons tref karakter transformasie modele vir Tsjechse, Duits en Russe, bereik solide resultate en dramatiese speedskouer in vergelyking met autoregressiewe stelsels. Die bronkode is verlos by https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_af>
      <abstract_sq>Ne propozojmë një metodë jo-autoregressive GEC me karaktere të gjeneruara automatikisht. Recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder GEC systems. Ne tregojmë se modifikimet e zëvendësimit të fjalëve mund të jenë jo optimale dhe të çojnë në shpërthim të rregullave për shkrimin, diakritizimin dhe gabimet në gjuhë morfologjikisht të pasura, dhe propozojnë një metodë për krijimin e transformimeve të karakterit nga korpusi GEC. Më në fund, ne trajnojmë modelet e transformimit të karakterit për çeket, gjermanët dhe rusët, duke arritur rezultate të forta dhe shpejtësi dramatike krahasuar me sistemet autoregressive. Kodi burimi është lëshuar në https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_sq>
      <abstract_am>በአካላት አካባቢ የGEC ሥርዓት፣ የሠሌዳዊ አካባቢ ለውጥ እናስጀራለን፡፡ በቅርብ ጊዜ የቃላት ትክክለኛ ማቀናጃ ማቀናጃ በአሁኑ የሆኑት የencoder-decoder GEC ስርዓቶች የሚለይ ክፍተት አግኝቷል፡፡ እናሳያቸዋለን የንግግር ተካውሎ ማቀናጃ ትክክል መሆኑን እና በሞሮፎሎጂ ባለ ሀብታሞች ቋንቋዎች የቃላት አካላት እና ስህተቶችን ለመፍጠር እና ከGEC ኮርፖስስ የሥርዓት ለውጥ ማቅረብ ማቅረብ ማቅረብ ማቅረብ ነው፡፡ በመጨረሻው፣ ለቻክክ፣ ጀርመን እና ሮሽኛ ያሉትን የሥርዓት ለውጥ ምሳሌዎችን እናስተምራለን፡፡ ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_am>
      <abstract_hy>Մենք առաջարկում ենք բնավորության հիմքով ոչ ինքնագրավիչ մոտեցում, որոնք ավտոմատ ստեղծվում են բնավորության փոխակերպումներ: Վերջերս, կարգավորման խմբագրությունների բառային դասակարգումը ապացուցել է արդյունավետ, զուգահեռելի այլընտրանք ներկայիս կոդեր-կոդեր համակարգերի համար: Մենք ցույց ենք տալիս, որ բառերի փոխարինման խմբագրությունները կարող են ենթաօպտիմալ լինել և հանգեցնել գրության, դիակրիտիզացիայի և սխալների պայթյուններին մորֆոլոգիապես հարուստ լեզուներում, և առաջարկել են մեթոդ, որպեսզի ստեղծվի բնավորության փոխակերպումներ ԳԵԿ Վերջապես, մենք վարժեցնում ենք հերոսների վերափոխման մոդելներ Չեխի, Գերմանիայի և Ռուսաստանի համար, որոնք հասնում են հաստատ արդյունքների և դրամատիկ արագությունների, համեմատած ինքնագրավիչ համակարգերի հետ: Առաջին կոդը հրապարակում է https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_hy>
      <abstract_az>Biz karakter-tabanlńĪ, autoregressiv olmayan GEC approach t…ôklif edirik, avtomatik √ľr…ôkl…ôndirilmiŇü karakter d…ôyiŇüiklikl…ôri il…ô. Son zamanlarda, d√ľzeltme d√ľzenleyicil…ôrin h…ôr s√∂z klasifikasiyasńĪ ańüńĪmdaki kodlayńĪcńĪ GEC sisteml…ôrinin faydalńĪ, paralleliz…ô edil…ôn alternatifi t…ôsdiql…ôdi. Biz s√∂zl…ôri d…ôyiŇüdirm…ôyi g√∂st…ôririk ki, s√∂zl…ôrin d…ôyiŇüdirilm…ôsi altoptimal olar v…ô yazmaq, diakritizat v…ô x…ôtalarńĪ morfolojik z…ôngin dill…ôrind…ô istifad…ô ed…ôr v…ô GEC corpusdan karakter d…ôyiŇüdirilm…ôsi √ľ√ß√ľn bir yol t…ôklif ed…ôr. Sonunda, biz Ňü…ôkill…ôrin d…ôyiŇüiklik modell…ôrini √áehir, Alman v…ô Rus √ľ√ß√ľn t…ôhsil edirik, autoregressiv sisteml…ôrl…ô qarŇüńĪlaŇüdńĪńüńĪ m√∂hk…ôm sonu√ßlarńĪ v…ô dramatik hńĪzlandńĪrmańüńĪ t…ôhsil edirik. Kaynak kodu a√ßńĪlńĪr https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_az>
      <abstract_bn>আমরা অক্ষরের ভিত্তিক অক্ষরিক জিসি প্রতিক্রিয়া প্রস্তাব করি, স্বয়ংক্রিয়ভাবে অক্ষরের পরিবর্তন। সম্প্রতি সংশোধন সম্পাদকের প্রতি শব্দের ক্লাস্ফিকেশন বর্তমান এনকোডার-ডেকোডার জিসি সিস্টেমের কাছে কার্যকর, প্রমাণ করেছে। আমরা দেখাচ্ছি যে শব্দ প্রতিস্থাপন সম্পাদক সম্পাদক সম্পাদক সম্ভবত সাবপ্রাপ্ত এবং নৈতিক ভাষায় বানান, ডায়ারিক্রিটিজেশন এবং ভুল বিস্ফোরণের জন্যে নিয়ম বিস্ অবশেষে, আমরা চেক, জার্মান এবং রাশিয়ার চরিত্র পরিবর্তনের মডেল প্রশিক্ষণ দেই, স্বয়ংক্রিয় সিস্টেমের তুলনায় সুদৃঢ় ফলাফল এবং ন্যায়াম্ব The source code is released at  https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_bn>
      <abstract_bs>Predlažemo neodresivan GEC pristup na karakteru, s automatskim generiranim transformacijama karaktera. Nedavno je klasifikacija redaktora korekcije na riječi dokazala učinkovitu, parallelizibilnu alternativu za trenutne GEC sisteme kodera-dekodera. Pokazujemo da editori zamjene riječi mogu biti podoptimalni i dovesti do eksplozije pravila za pisanje, diakritizaciju i greške na morfološki bogatim jezicima, i predlažemo metodu za stvaranje transformacija karaktera iz GEC corpus a. Konačno, treniramo modele transformacije karaktera za češke, nemačke i ruske, ostvarimo čvrste rezultate i dramatične ubrzanje u usporedbi s autoregresivnim sistemima. Izvorni kod je objavljen na https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_bs>
      <abstract_ca>Proposem un enfocament GEC no autoregressiu basat en caràcters, amb transformacions de caràcters generades automàticament. Recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder GEC systems.  Mostrem que les edicions de substitució de paraules poden ser suboptimals i portar a una explosió de regles per ortografia, diacritització i errors en llengües morfològicament rics, i proposem un mètode per generar transformacions de caràcter del corpus GEC. Finalment, entrenem models de transformació de caràcter per a cec, alemany i russos, arribant a resultats sólits i a velocitats dràstices comparats amb els sistemes autoregressius. El codi fonts s'allibera a https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ca>
      <abstract_cs>Navrhujeme znakový non-autoregresivní GEC přístup s automaticky generovanými znakovými transformacemi. V poslední době se klasifikace korekčních editací na slovo ukázala jako efektivní, paralelní alternativa k současným systémům snímače-dekódování GEC. Ukazujeme, že editace nahrazení slov mohou být suboptimální a vést k explozi pravidel pravopisu, diakritizace a chyb v morfologicky bohatých jazycích, a navrhujeme metodu generování znakových transformací z korpusu GEC. Nakonec trénujeme modely transformace znaků pro češtinu, němčinu a ruštinu, dosahující solidních výsledků a dramatické zrychlení ve srovnání s autoregresivními systémy. Zdrojový kód je uvolněn na adrese https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_cs>
      <abstract_fi>Ehdotamme merkkipohjaista ei-autoregressiivistä GEC-lähestymistapaa, jossa on automaattisesti luotu merkkimuunnos. Viime aikoina korjausmuokkausten sanakohtainen luokittelu on osoittautunut tehokkaaksi ja rinnastettavaksi vaihtoehdoksi nykyisille kooderi-dekooderijärjestelmille. Osoitamme, että sanankorotuksen muokkaukset saattavat olla epäoptimaalisia ja johtaa oikeinkirjoitus-, diakritisointi- ja virheiden räjähdykseen morfologisesti rikkaissa kielissä, ja ehdotamme menetelmää merkkimuunnoksen tuottamiseksi GEC-korpusesta. Lopuksi harjoittelemme hahmonmuutosmalleja tšekkiläisille, saksalaisille ja venäläisille, saavuttaen vankkoja tuloksia ja dramaattista nopeutta autoregressiivisiin järjestelmiin verrattuna. Lähdekoodi julkaistaan osoitteessa https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_fi>
      <abstract_et>Pakume välja märgipõhise mittearregressiivse GEC lähenemisviisi, millel on automaatselt genereeritud märgimuundused. Viimasel ajal on parandusmuudatuste sõna kaupa klassifitseerimine osutunud tõhusaks ja paralleelseks alternatiiviks praegustele kodeerija-dekooder GEC süsteemidele. Näitame, et sõnavahetused võivad olla ebaoptimaalsed ja põhjustada õigekirja, diakriitiseerimise ja vigade plahvatust morfoloogiliselt rikkalikes keeltes ning pakume välja meetodi, kuidas genereerida tähemärkide muundamist GEC korpusest. Lõpuks koolitame tšehhi, saksa ja vene karakterite muundamise mudeleid, saavutades kindlad tulemused ja dramaatilise kiirenduse võrreldes autoregressiivsete süsteemidega. Lähtekood avaldatakse aadressil https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_et>
      <abstract_ha>Munã goyyar da wata gesi wanda ba ya samar da rubutun-kanal ba-regressive, da musanyi-gefen farat ɗaya. Recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder GEC systems.  Tuna nũna cewa musamman magana za'a kasance sub-Optical kuma za'a iya ƙara buƙata masu hushi wa masu yin rubutu, dikritization da ɓarna cikin lugha matalauci na mutane, kuma muna goyyade wata hanyor da za'a ƙiƙiro canza hanyoyi daga nau'in GEC. Haƙĩƙa, munã kõre misãlai mai canza hanyoyi wa Czech, jeron da Ruushi, kuma munã sami matsala masu ƙarfi da haraka da tsohon da aka sami'a na'urar-regressive. Ana sakar da kodi na source https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_ha>
      <abstract_sk>Predlagamo pristop, ki temelji na znakih in ne-avtoregresivni GEC, s samodejno generiranimi transformacijami znakov. V zadnjem času se je klasifikacija korekcijskih ureditev na besedo izkazala za učinkovito in vzporedno alternativo trenutnim sistemom kodirnika-dekoderja GEC. Pokazali smo, da so ureditve zamenjave besed lahko neoptimalne in povzročijo eksplozijo pravil za črkovanje, diakritizacijo in napake v morfološko bogatih jezikih, ter predlagali metodo za generiranje transformacij znakov iz korpusa GEC. Na koncu usposabljamo modele transformacije znakov za češko, nemško in rusko ter dosegamo trdne rezultate in dramatično pospešitev v primerjavi z avtoregresivnimi sistemi. Izvorna koda se objavi na https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_sk>
      <abstract_jv>GEC biasane Awak dhéwé éntuk perusahaan kelangan anyar luwih apik lan kelangan langgar sampeyan gewis ngerasai winih kanggo kelangan winih, diakletike lan kelangan langgar sampeyan luwih Soalé, kéné beraksi model penting caratar ampuhi kanggo Ketch, Sampeyan karo Rusi, dadi sing ditambah barang bakal dumadhi lan basa sing dirampek dhéwé karo sistem autoRegresan. Sumber kode mbukak ing kene https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_jv>
      <abstract_bo>ང་ཚོས་རང་འགུལ་གྱིས་ཡིག་འབྲུ་གཞི་བརྟེན་ནས་རང་འགུལ་གྱིས་རྒྱུན་མེད་པའི་GEC་གཟུགས་སྐོར་བྱེད་དགོས འཕྲལ་མ་དེ་ལྟར་འགྱུར་བའི་བསྒྱུར་བཅོས་ཀྱི་གསལ་རིམ We show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus. མཐའ་མར་དུ། ང་ཚོས་ཡིག་འབྲུ་གསར་བསྐྲུན་ཐབས་ལམ་གྱི་དཔེ་དབྱིབས་ཅེག་དང་སྐད་རྒྱ་ནག་དང་། ཐོག་མའི་ཨང་རིས་འདིའི་ནང་དུ་ཉར་ཚར་བ https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_bo>
      <abstract_he>אנו מציעים גישה לא אוטומטית מבוססת על אוטומטיות GEC, עם שינויים אוטומטיים יוצרים. לאחרונה, מסווג על מילה של עורכי תיקון הוכיח אלטרנטיבה יעילה, משותפת למערכות GEC של הקודר-מפענח הנוכחי. We show that word replacement edits may be suboptimal and lead to explosion of rules for spelling, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus.  Finally, we train character transformation models for Czech, German and Russian, reaching solid results and dramatic speedup compared to autoregressive systems.  קוד המקור משוחרר ב https://github.com/ufal/wnut2021_character_transformations_gec.</abstract_he>
      </paper>
    <paper id="47">
      <title>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</title>
      <author><first>Arij</first><last>Riabi</last></author>
      <author><first>Benoît</first><last>Sagot</last></author>
      <author><first>Djamé</first><last>Seddah</last></author>
      <pages>423–436</pages>
      <abstract>Recent impressive improvements in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages. Building language mod- els and, more generally, NLP systems for non- standardized and low-resource languages remains a challenging task. In this work, we fo- cus on North-African colloquial dialectal Arabic written using an extension of the <a href="https://en.wikipedia.org/wiki/Latin_script">Latin script</a>, called NArabizi, found mostly on social media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a> and dependency parsing to that of monolingual and multilingual models. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> in low-resource and high language variability set- tings.</abstract>
      <url hash="0dee8f63">2021.wnut-1.47</url>
      <bibkey>riabi-etal-2021-character</bibkey>
      <doi>10.18653/v1/2021.wnut-1.47</doi>
    <title_ar>هل يمكن لنماذج اللغة القائمة على الأحرف تحسين أداء المهام النهائية في سيناريوهات اللغة منخفضة الموارد والصاخبة؟</title_ar>
      <title_pt>Os modelos de linguagem baseados em caracteres podem melhorar o desempenho das tarefas downstream em cenários de linguagem com poucos recursos e ruídos?</title_pt>
      <title_es>¿Pueden los modelos lingüísticos basados en caracteres mejorar el rendimiento de las tareas posteriores en escenarios lingüísticos ruidosos y de bajos recursos?</title_es>
      <title_ja>文字ベースの言語モデルは、低リソースでノイズの多い言語シナリオでダウンストリームタスクのパフォーマンスを向上させることができますか？</title_ja>
      <title_fr>Les modèles de langage basés sur des caractères peuvent-ils améliorer les performances des tâches en aval dans des scénarios linguistiques bruyants et à faibles ressources ?</title_fr>
      <title_hi>क्या चरित्र-आधारित भाषा मॉडल निम्न-संसाधन और शोर भाषा परिदृश्यों में डाउनस्ट्रीम कार्य प्रदर्शन में सुधार कर सकते हैं?</title_hi>
      <title_ru>Могут ли основанные на символах языковые модели улучшать выполнение последующих задач в сценариях малоресурсного и шумного языка?</title_ru>
      <title_zh>盖字符之言,能增低资源与嘈杂言场之下流乎?</title_zh>
      <title_ga>An féidir le Múnlaí Teanga Carachtar-bhunaithe Feidhmíocht Tasc Iartheachtach a Fheabhsú i gCásanna Teanga atá Íseal-Acmhainne agus Torainn?</title_ga>
      <title_ka>შეიძლება სიმბოლოების მხარეს რესურსის და სიმბოლოების სენერიოების შესაძლებლობა სიმბოლოების შესაძლებლობა ჩატვირთვა დაკავშირება?</title_ka>
      <title_hu>A karakterek alapú nyelvi modellek javíthatják-e az alacsony erőforrású és zajos nyelvi forgatókönyvekben végzett feladatok teljesítményét?</title_hu>
      <title_el>Μπορούν τα γλωσσικά μοντέλα βασισμένα σε χαρακτήρες να βελτιώσουν τις επιδόσεις εργασιών σε σενάρια γλώσσας χαμηλού πόρων και θορυβώδη;</title_el>
      <title_it>I modelli linguistici basati sui caratteri possono migliorare le prestazioni delle attività a valle in scenari linguistici a basso contenuto di risorse e rumorosi?</title_it>
      <title_mk>Може ли јазичните модели базирани на карактери да ги подобрат извршувањата на долните задачи во сценарија со ниски ресурси и бучни јазици?</title_mk>
      <title_lt>Ar simboliais pagrįsti kalbos modeliai gali pagerinti mažai išteklių turinčių ir triukšmingų kalbų darbų rezultatus?</title_lt>
      <title_ms>Boleh Model Bahasa Berasas Aksara meningkatkan Performasi Tugas Turun Dalam Skenario Bahasa Sumber Terrendah dan Bunyi?</title_ms>
      <title_ml>കുറഞ്ഞ വിഭവങ്ങളിലും നോയിസി ഭാഷ സ്കെയിനേറ്റിയിലുമുള്ള അക്ഷരസഞ്ചയം ഭാഷ മോഡലുകള്‍</title_ml>
      <title_mt>Il-mudelli lingwistiċi bbażati fuq il-karattri jistgħu jtejbu l-prestazzjonijiet tal-kompiti downstream f’xenarji lingwistiċi b’riżorsi baxxi u bi storbju?</title_mt>
      <title_pl>Czy modele językowe oparte na znakach mogą poprawić wydajność zadań kolejnych w scenariuszach językowych o niskich zasobach i hałasowych?</title_pl>
      <title_no>Kan teiknbaserte språk- modeller forbedra nedstremde oppgåver i låg ressursar og støyspråk- scenarioar?</title_no>
      <title_mn>Тархины үндсэн хэл загварууд доорх үйл ажиллагааны үйл ажиллагааг бага болон үндсэн хэл хувилбарууд дээр сайжруулж чадах уу?</title_mn>
      <title_sr>Može li na karakteru bazirani jezički modeli poboljšati funkcije ispod zadataka u scenariji niskog resursa i glasnog jezika?</title_sr>
      <title_ro>Modelele lingvistice bazate pe caractere pot îmbunătăți performanțele activităților în aval în scenarii lingvistice cu resurse scăzute și zgomotoase?</title_ro>
      <title_si>අක්ෂර අධාරිත භාෂාව මොඩේල්ස් අඩුප්‍රවේශ කාර්යාලයට අඩුප්‍රවේශ සහ නෝයිසි භාෂාව සීනාරියෝ වලට වැ</title_si>
      <title_kk>Таңбалар негіздеген тіл үлгілері төменгі тапсырмаларды төменгі ресурс және дыбыс тіл сценариясында жақсарту мүмкін емес пе?</title_kk>
      <title_sv>Kan teckenbaserade språkmodeller förbättra aktiviteternas prestanda nedströms i lågresurs- och bullriga språkscenarier?</title_sv>
      <title_so>Macluumaadka afka ee ku saleysan ee ku qoran xarafka Models miyey Improve Tasks Downstream In Low-Resource and Noisy Luqad Scenarios?</title_so>
      <title_ta>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</title_ta>
      <title_ur>کیا کریٹر بنیادی زبان موڈل نیچے رسورس اور نویسی زبان سناریوں میں ڈونسٹریم ٹاکس کی عملکرد اضافہ کر سکتے ہیں؟</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Có thể diễn biến ngôn ngữ văn bản phục hồi công việc dưới luồng năng lượng thấp và ngôn ngữ ồn ào?</title_vi>
      <title_bg>Могат ли базираните на знаци езикови модели да подобрят изпълнението на задачите надолу по веригата при сценарии с ниски ресурси и шум?</title_bg>
      <title_da>Kan tegnbaserede sprogmodeller forbedre downstream opgaveydelser i lave ressourcer og støjende sprogscenarier?</title_da>
      <title_nl>Kunnen karaktergebaseerde taalmodellen de prestaties van downstreamtaken verbeteren in taalscenario's met weinig bronnen en lawaai?</title_nl>
      <title_de>Können charakterbasierte Sprachmodelle die Leistung nachgeschalteter Aufgaben in ressourcenarmen und lauten Sprachszenarien verbessern?</title_de>
      <title_hr>Može li modeli jezika bazirani na znakovima poboljšati funkcije ispod zadataka u scenariji niskog resursa i glasnog jezika?</title_hr>
      <title_id>Bisakah Model Bahasa Berdasarkan Karakter meningkatkan Performasi Tugas Downstream Dalam Scenario Bahasa Terrendah-Sumber dan Suara?</title_id>
      <title_ko>낮은 자원과 시끄러운 언어 장면에서 문자를 바탕으로 하는 언어 모델은 하위 작업의 성능을 개선할 수 있습니까?</title_ko>
      <title_fa>آیا مدلهای زبانی بر اساس شخصیت‌ها می‌توانند عملکرد کارهای پایین‌ترین در نمایش‌های زبان‌های کم منبع و صدا را بهتر کنند؟</title_fa>
      <title_sw>Mradi wa lugha yenye makala inaweza kuboresha Tamko za Kupitia Mtandao katika rasilimali ya chini na Asili ya Lugha Zisizo na maana?</title_sw>
      <title_tr>Karakter-tabanly Diller Astlary Görevlerini Az-Ressourt we Açyk Diller Senedlerinde bejersin mi?</title_tr>
      <title_af>Kan Karakter-gebaseerde Taal Modele Onderstroom Opdrag Performasies in Lae-Hulpbron en Noisy Taal Skenarios verbeter?</title_af>
      <title_sq>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</title_sq>
      <title_am>የፊደል ቅርጽ ምርጫዎች</title_am>
      <title_hy>Կարո՞ղ են նշաններով հիմնված լեզվի մոդելները բարելավել ներքևի գործողությունները ցածր ռեսուրսների և աղմկոտ լեզվի սցենարներում:</title_hy>
      <title_az>Karakter-tabanlı Dil Modelləri Aşağı Göndərilən Göndərilən Göndərilən Göndərilən Göndərilənləri Aşağı-Kaynaq və Cənnət Dili Sənirələrində yaxşılaşdıra bilərmi?</title_az>
      <title_bn>অক্ষরের ভিত্তিক ভাষার মোডেল কি নীচের সম্পদ এবং নিজস্ব ভাষা স্কেনারিয়ার মধ্যে নিম্নলিখিত কাজের কার্যক্রম উন্নতি করতে পা</title_bn>
      <title_bs>Može li modeli jezika bazirani na karakterima poboljšati funkcije u snimku niskih resursa i glasnih jezika?</title_bs>
      <title_ca>Els models de llenguatge basats en caràcters poden millorar els desempenys de tasques descendents en escenaris de baix recursos i ruits?</title_ca>
      <title_cs>Mohou jazykové modely založené na znakách zlepšit výkon následných úkolů ve scénářích s nízkými zdroji a hlučnými jazyky?</title_cs>
      <title_et>Kas märgipõhised keelemudelid võivad parandada järgnevaid ülesandeid vähese ressursi ja müraga keelestsenaariumides?</title_et>
      <title_fi>Voivatko merkkipohjaiset kielimallit parantaa loppupään tehtävien suorituskykyä vähävaraisissa ja meluisissa kieliskenaarioissa?</title_fi>
      <title_sk>Ali lahko znakovni jezikovni modeli izboljšajo učinkovitost opravil v scenarijih z nizkimi viri in hrupom?</title_sk>
      <title_jv>Opo iso ngubah Karakter-basa Gambar Modem Bukake Delokan Download Job</title_jv>
      <title_ha>@ action: button</title_ha>
      <title_he>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</title_he>
      <title_bo>ཡིག་འབྲུ་གཞི་བརྟེན་ནས་སྐད་རིགས་དཔེ་དབྱིབས་ཀྱི་འོག་གི་ལས་ཀ་འགྲུལ་སྐྱོད་ནུས་མཐུན་བཟོ་ཐུབ་པ།</title_bo>
      <abstract_ar>التحسينات الحديثة المثيرة للإعجاب في البرمجة اللغوية العصبية ، والتي تستند إلى حد كبير على نجاح نماذج اللغة العصبية السياقية ، تم عرضها في الغالب على أكثر من بضع عشرات من اللغات عالية الموارد. لا يزال بناء نماذج اللغة ، وبشكل أعم ، أنظمة البرمجة اللغوية العصبية للغات غير المعيارية وقليلة الموارد مهمة صعبة. في هذا العمل ، نركز على اللهجة العامية في شمال إفريقيا المكتوبة باستخدام امتداد للنص اللاتيني ، يسمى NArabizi ، الموجود في الغالب على وسائل التواصل الاجتماعي والرسائل. في سيناريو الموارد المنخفضة هذا مع عرض البيانات لمستوى عالٍ من التباين ، نقارن أداء المصب لنموذج اللغة المستند إلى الأحرف في وضع علامات على جزء من الكلام وتحليل التبعية مع النماذج أحادية اللغة ومتعددة اللغات. لقد أظهرنا أن النموذج المستند إلى الشخصية الذي تم تدريبه على 99 ألف جملة فقط من NArabizi وتم ضبطه على ضفة شجرة صغيرة من هذه اللغة يؤدي إلى أداء قريب من تلك التي تم الحصول عليها بنفس البنية التي تم تدريبها مسبقًا على نماذج كبيرة متعددة اللغات وأحادية اللغة. بتأكيد هذه النتائج على مجموعة بيانات أكبر بكثير من المحتوى الفرنسي الصاخب الذي أنشأه المستخدم ، فإننا نجادل بأن نماذج اللغة القائمة على الأحرف يمكن أن تكون أحد أصول معالجة اللغات الطبيعية في الإعدادات منخفضة الموارد وذات التباين اللغوي العالي.</abstract_ar>
      <abstract_es>Las impresionantes mejoras recientes en la PNL, basadas en gran medida en el éxito de los modelos de lenguaje neuronal contextual, se han demostrado en su mayoría en un par de docenas de lenguajes de recursos altos. Construir modelos de lenguaje y, de manera más general, sistemas de PNL para lenguajes no estandarizados y de bajos recursos sigue siendo una tarea difícil. En este trabajo, nos centramos en el árabe dialectal coloquial norafricano escrito con una extensión de la escritura latina, llamada Narabizi, que se encuentra principalmente en las redes sociales y la comunicación por mensajería. En este escenario de bajos recursos con datos que muestran un alto nivel de variabilidad, comparamos el rendimiento descendente de un modelo de lenguaje basado en caracteres en el etiquetado de partes del habla y el análisis de dependencias con el de los modelos monolingües y multilingües. Demostramos que un modelo basado en caracteres entrenado en solo 99k oraciones de NaraBizi y afinado en un pequeño banco de árboles de este idioma conduce a un rendimiento cercano a los obtenidos con la misma arquitectura previamente entrenada en grandes modelos multilingües y monolingües. Confirmando estos resultados en un conjunto de datos mucho más amplio de contenido ruidoso generado por los usuarios franceses, argumentamos que estos modelos de lenguaje basados en caracteres pueden ser una ventaja para la PNL en entornos de bajos recursos y alta variabilidad lingüística.</abstract_es>
      <abstract_pt>Recentes e impressionantes melhorias na PNL, em grande parte baseadas no sucesso dos modelos de linguagem neural contextual, foram demonstradas principalmente em no máximo algumas dúzias de linguagens de alto recurso. Construir modelos de linguagem e, mais geralmente, sistemas de PNL para linguagens não padronizadas e de poucos recursos continua sendo uma tarefa desafiadora. Neste trabalho, nos concentramos no árabe dialetal coloquial norte-africano escrito usando uma extensão da escrita latina, chamada NArabizi, encontrada principalmente em mídias sociais e comunicação de mensagens. Neste cenário de poucos recursos com dados exibindo um alto nível de variabilidade, comparamos o desempenho downstream de um modelo de linguagem baseado em caracteres na marcação de parte da fala e análise de dependência com o de modelos monolíngues e multilíngues. Mostramos que um modelo baseado em caracteres treinado em apenas 99k sentenças de NArabizi e ajustado em um pequeno treebank dessa linguagem leva a um desempenho próximo ao obtido com a mesma arquitetura pré-treinada em grandes modelos multilíngues e monolíngues. Confirmando esses resultados em um conjunto de dados muito maior de conteúdo gerado pelo usuário francês barulhento, argumentamos que tais modelos de linguagem baseados em caracteres podem ser um trunfo para a PNL em configurações de baixo recurso e alta variabilidade de linguagem.</abstract_pt>
      <abstract_fr>Les améliorations impressionnantes récentes de la PNL, largement basées sur le succès des modèles de langage neuronal contextuels, ont été principalement démontrées sur au plus une vingtaine de langues à ressources élevées. Construire des modèles de langage et, plus généralement, des systèmes NLP pour des langues non normalisées et à faibles ressources reste une tâche ardue. Dans cet ouvrage, nous nous concentrons sur l'arabe dialectal familier nord-africain écrit à l'aide d'une extension de l'écriture latine, appelée nArabizi, que l'on trouve principalement sur les réseaux sociaux et la communication par messagerie. Dans ce scénario à faibles ressources avec des données affichant un haut niveau de variabilité, nous comparons les performances en aval d'un modèle de langage basé sur les caractères sur le balisage de parties du discours et l'analyse des dépendances à celles des modèles monolingues et multilingues. Nous montrons qu'un modèle basé sur des caractères formé sur seulement 99k phrases de NaraBizi et affiné sur une petite banque d'arbres de cette langue conduit à des performances proches de celles obtenues avec la même architecture pré-entraînée sur de grands modèles multilingues et monolingues. Confirmant ces résultats sur un ensemble de données beaucoup plus vaste de contenu bruyant généré par les utilisateurs en français, nous soutenons que de tels modèles linguistiques basés sur des caractères peuvent être un atout pour la PNL dans des environnements à faibles ressources et à forte variabilité linguistique.</abstract_fr>
      <abstract_ja>主に文脈神経言語モデルの成功に基づいて、NLPの最近の印象的な改善は、ほとんどが最大でも数十の高資源言語で実証されている。 非標準化および低資源言語のために言語モジュールを構築し、より一般的にはNLPシステムを構築することは、依然として困難な課題である。 この研究では、NArabiziと呼ばれるラテン文字の拡張を使用して書かれた北アフリカのコロコロ方言アラビア語を研究しています。主にソーシャルメディアやメッセージングコミュニケーションで使用されています。 データ表示が高いレベルの変動性を持つこの低リソースシナリオでは、音声タグ付けと依存性解析に関する文字ベースの言語モデルのダウンストリームパフォーマンスを、単一言語および多言語モデルのパフォーマンスと比較します。 わずか99,000文のNArabiziで訓練され、この言語の小さなツリーバンクで微調整された文字ベースのモデルは、大規模な多言語および単語モデルで事前に訓練された同じアーキテクチャで得られたものに近いパフォーマンスにつながることを示しています。 これらの結果を、騒々しいフランスのユーザー生成コンテンツのより大きなデータセットで確認することで、そのようなキャラクターベースの言語モデルは、低リソースおよび高言語変動性セットにおけるNLPの資産になり得ると主張する。</abstract_ja>
      <abstract_zh>NLP近令人印象深改,盖上下文神经言模形之成功,大抵已验于最多几十种高资言。 为非标准化与低资源言语模块,更凡言,NLP系统犹一挑战性之任也。 于此等事,究北非口语方言阿拉伯语,当阿拉伯语用拉丁语脚本之广(谓之NArabizi)编,主于社交媒体、消息通书。 此有高可变性之低资源,将基于字符之言词性标而恃之解析上下之性,与单语多言之性相校也。 此言小树库微,近言与单语同架构单语也。 大嘈杂之法语用户,生成数集上证之,以为字符之言,可以为低资源高语可变性合中NLP之资。</abstract_zh>
      <abstract_hi>एनएलपी में हाल ही में प्रभावशाली सुधार, काफी हद तक प्रासंगिक तंत्रिका भाषा मॉडल की सफलता पर आधारित है, ज्यादातर कुछ दर्जन उच्च संसाधन भाषाओं पर प्रदर्शित किया गया है। निर्माण भाषा mod-els और, अधिक आम तौर पर, गैर-मानकीकृत और कम संसाधन वाली भाषाओं के लिए एनएलपी सिस्टम एक चुनौतीपूर्ण कार्य बना हुआ है। इस काम में, हम लैटिन लिपि के विस्तार का उपयोग करके उत्तर-अफ्रीकी बोलचाल की बोलचाल की अरबी पर ध्यान केंद्रित करते हैं, जिसे नारबीज़ी कहा जाता है, जो ज्यादातर सोशल मीडिया और मैसेजिंग संचार पर पाया जाता है। डेटा के साथ इस कम-संसाधन परिदृश्य में परिवर्तनशीलता के एक उच्च स्तर को प्रदर्शित करते हुए, हम मोनोलिंगुअल और बहुभाषी मॉडल के लिए पार्ट-ऑफ-स्पीच टैगिंग और निर्भरता पार्सिंग पर एक चरित्र-आधारित भाषा मॉडल के डाउनस्ट्रीम प्रदर्शन की तुलना करते हैं। हम दिखाते हैं कि एक चरित्र-आधारित मॉडल को NArabizi के केवल 99k वाक्यों पर प्रशिक्षित किया गया है और इस भाषा के एक छोटे से ट्रीबैंक पर जुर्माना लगाया गया है, जो बड़े बहुभाषी और मोनोलिंगुअल मॉडल पर प्रशिक्षित एक ही वास्तुकला के साथ प्राप्त लोगों के करीब प्रदर्शन की ओर जाता है। इन परिणामों की पुष्टि करते हुए शोर फ्रांसीसी उपयोगकर्ता-जनित सामग्री के बहुत बड़े डेटा सेट पर, हम तर्क देते हैं कि इस तरह के चरित्र-आधारित भाषा मॉडल कम-संसाधन और उच्च भाषा परिवर्तनशीलता सेट-टिंग्स में एनएलपी के लिए एक संपत्ति हो सकते हैं।</abstract_hi>
      <abstract_ru>Недавние впечатляющие улучшения в NLP, в значительной степени основанные на успехе контекстуальных нейронных языковых моделей, были в основном продемонстрированы максимум на паре десятков высокоресурсных языков. Построение языковых модулей и, в более общем плане, систем NLP для нестандартизированных и малоресурсных языков остается сложной задачей. В этой работе мы изучаем североафриканский разговорный диалектный арабский язык, написанный с использованием расширения латинского алфавита, называемого NArabizi, которое встречается в основном в социальных сетях и общении при обмене сообщениями. В этом сценарии с низким объемом ресурсов и высоким уровнем вариабельности данных мы сравниваем производительность языковой модели, основанной на символах, при частичном тегировании речи и парсинге зависимостей с производительностью одноязычных и многоязычных моделей. Мы показываем, что основанная на персонажах модель, обученная только 99 тысячам предложений NArabizi и оштрафованная на небольшом берегу деревьев этого языка, приводит к производительности, близкой к тем, которые получены с той же архитектурой, предварительно обученной на больших многоязычных и одноязычных моделях. Подтверждая эти результаты на гораздо большем наборе данных шумного французского пользовательского контента, мы утверждаем, что такие основанные на символах языковые модели могут быть активом для NLP в условиях низкой ресурсной и высокой языковой изменчивости.</abstract_ru>
      <abstract_ga>Léiríodh feabhsuithe suntasacha le déanaí ar NLP, bunaithe go mór ar an rath a bhí ar mhúnlaí néartheanga comhthéacsúla, i gcúpla dosaen teanga ard-acmhainne ar a laghad. Is tasc dúshlánach fós é samhlacha teanga a thógáil agus, níos ginearálta, córais NLP do theangacha neamhchaighdeánaithe agus íseal-acmhainne. Sa saothar seo, dírímid ar Araibis canúinteach colloquial na hAfraice Thuaidh scríofa ag baint úsáide as síneadh ar an script Laidine, ar a dtugtar NArabizi, atá le fáil go príomha ar na meáin shóisialta agus cumarsáid teachtaireachtaí. Sa chás íseal-acmhainne seo ina bhfuil ardleibhéal inathraitheachta á léiriú ag sonraí, déanaimid comparáid idir feidhmíocht iartheachtach samhail teanga bunaithe ar charachtar ar chlibeáil pháirteach cainte agus parsáil spleáchais le samhlacha aonteangacha agus ilteangacha. Léirímid go n-eascraíonn múnla atá bunaithe ar charachtair a oiltear ar pianbhreitheanna 99k de NArabizi amháin agus a ndéantar mionchoigeartú air ar chrann crann beag den teanga seo go bhfuil feidhmíocht gar dóibh siúd a fuarthas leis an ailtireacht chéanna réamh-oilte ar mhúnlaí móra ilteangacha agus aonteangacha. Agus na torthaí seo á ndeimhniú agus ar thacar sonraí i bhfad níos mó d’ábhar Fraincise torainn a ghintear ag an úsáideoir, áitímid gur féidir le samhlacha teanga carachtar-bhunaithe den sórt sin a bheith ina n-acmhainn ag NLP i socruithe íseal-acmhainne agus ard-inathraitheachta teanga.</abstract_ga>
      <abstract_hu>Az NLP legutóbbi lenyűgöző fejlesztéseit, amelyek nagyrészt a kontextuális neurális nyelvmodellek sikerén alapulnak, legfeljebb néhány tucat nagy erőforrású nyelven mutatták be. A nem szabványosított és alacsony erőforrással rendelkező nyelvek nyelvi modelleinek és általában az NLP rendszereinek kiépítése továbbra is kihívást jelent. Ebben a munkában a latin írás kiterjesztésével írt észak-afrikai dialektuális arabról, NArabizi-ról fókuszálunk, amely elsősorban a közösségi médiában és az üzenetküldő kommunikációban található. Ebben az alacsony erőforrású forgatókönyvben, amely nagy változékonysággal rendelkezik, összehasonlítjuk egy karakter alapú nyelvi modell downstream teljesítményét a beszédrész-címkézéssel és függőség-elemzéssel az egynyelvű és többnyelvű modellekkel. Megmutatjuk, hogy egy karakter alapú modell, amely mindössze 99 ezer mondatra képzett NArabizi és ennek a nyelvnek a kis fából álló lapján finomhangolt, közel áll azokhoz a teljesítményhez, amelyeket ugyanazzal az architektúrával kaptak, előre képzett nagy többnyelvű és egynyelvű modelleken. Ezeket az eredményeket megerősítve a zajos francia felhasználók által generált tartalmak sokkal nagyobb adatkészletére vonatkozóan érveljük, hogy az ilyen karakter alapú nyelvi modellek előnyösek lehetnek az NLP számára alacsony erőforrás- és nagy nyelvváltozékonyságú beállításokban.</abstract_hu>
      <abstract_ka>NLP-ში მხოლოდ შემდეგ ინტეპექციური დაახლოები, ძალიან კონტექსტური ნეირალური ენის მოდელების წარმატებით დაბაზიან, უფრო მეტი მოდენსტურებული უფრო რამდენიმე ეზა ენის mod- els და, უფრო საერთოდ, NLP სისტემების შექმნა არ- სტანდარტულებული და ცოტა რესურსისების ენებისთვის მუშაობა შესაძლებელი რაოდენობა. ამ სამუშაოში ჩვენ კოლოკური დიალექტალური აპაბიური კოლოკური კოლოკური დავწერით ლატინული სკრიპტის გაფართლების გამოყენებით, რომელიც NArabizi, ძალიან სოციალური მედიაში ამ ცოტა რესურსის სინარიოში მონაცემების გამოსახულება - სხვადასხვების მაღალი დონე, ჩვენ ჩვენ ჩვენ მონაცემების კონფიგურაციას, რომელიც სინაცემების მუშაობაში სინაცემების მოდელეტის ნაწილად დავწყ ჩვენ ჩვენ აჩვენებთ, რომ სახელსაწყოთა მოდელი, რომელიც ნარაბიზის 99k წესებით და ამ ენის პატარა კონფიგურაციის მარტივი კონფიგურაციის მარტივი მარტივი მარტივი მარტივი მარტივის და მონოლენგურაციის მარტივის პროგრამი ამ შედეგების დარწმუნება ფრანუსის მომხმარებელი შექმნილი შეცდომის ძალიან დიდი მონაცემების კონფიგურაციაში, ჩვენ ვარგუნეთ, რომ ასეთი სიმბოლოების მოდელები შეიძლება იყოს NLP-ის აღტი მა</abstract_ka>
      <abstract_el>Πρόσφατες εντυπωσιακές βελτιώσεις στο ΝΛΠ, που βασίζονται σε μεγάλο βαθμό στην επιτυχία των μοντέλων νευρωνικής γλώσσας στο πλαίσιο, έχουν αποδειχθεί ως επί το πλείστον σε δύο ντουζίνες γλώσσες υψηλής περιεκτικότητας. Η οικοδόμηση γλωσσικών μοντέλων και, γενικότερα, συστημάτων για μη τυποποιημένες και χαμηλής περιεκτικότητας σε γλώσσες παραμένει ένα δύσκολο έργο. Στην εργασία αυτή, εστιάζουμε στη βορειοαφρικανική ομιλητική διαλεκτική αραβική γραφή που γράφτηκε χρησιμοποιώντας μια επέκταση της λατινικής γραφής, που ονομάζεται NArabizi, που βρίσκεται κυρίως στα μέσα κοινωνικής δικτύωσης και στην επικοινωνία μηνυμάτων. Σε αυτό το σενάριο χαμηλής περιεκτικότητας πόρων με δεδομένα που εμφανίζουν υψηλό επίπεδο μεταβλητότητας, συγκρίνουμε την απόδοση ενός γλωσσικού μοντέλου βασισμένου σε χαρακτήρες στην επισήμανση τμημάτων ομιλίας και ανάλυση εξάρτησης με αυτή των μονογλωσσικών και πολυγλωσσικών μοντέλων. Δείχνουμε ότι ένα μοντέλο βασισμένο σε χαρακτήρες εκπαιδευμένο μόνο σε προτάσεις 99κ του NArabizi και συντονισμένο σε μια μικρή όχθη δέντρου αυτής της γλώσσας οδηγεί σε απόδοση κοντά σε αυτές που επιτυγχάνονται με την ίδια αρχιτεκτονική προ-εκπαιδευμένη σε μεγάλα πολυγλωσσικά και μονογλωσσικά μοντέλα. Επιβεβαιώνοντας αυτά τα αποτελέσματα σε ένα πολύ μεγαλύτερο σύνολο δεδομένων θορυβώδες γαλλικό περιεχόμενο που παράγεται από χρήστες, υποστηρίζουμε ότι τέτοια μοντέλα γλώσσας βασισμένα σε χαρακτήρες μπορούν να αποτελέσουν πλεονέκτημα για τη χρήση σε σύνολα μεταβλητότητας χαμηλής περιεκτικότητας και υψηλής γλωσσικής μεταβλητότητας.</abstract_el>
      <abstract_it>Recenti miglioramenti impressionanti nella PNL, in gran parte basati sul successo dei modelli di linguaggio neurale contestuale, sono stati per lo più dimostrati su un paio di dozzine di linguaggi ad alta risorsa. Costruire mods- i linguaggi e, più in generale, sistemi NLP per linguaggi non standardizzati e a basso contenuto di risorse rimane un compito impegnativo. In questo lavoro, ci occupiamo dell'arabo dialettale colloquiale nordafricano scritto utilizzando un'estensione della scrittura latina, chiamata NArabizi, trovato principalmente sui social media e sulla comunicazione di messaggistica. In questo scenario a basso contenuto di risorse con visualizzazione di dati ad alto livello di variabilità, confrontiamo le prestazioni a valle di un modello linguistico basato sui caratteri sul tag part-of-speech e sull'analisi delle dipendenze con quelle dei modelli monolingue e multilingue. Mostriamo che un modello basato sul carattere addestrato su soli 99k frasi di NArabizi e messo a punto su una piccola alberatura di questa lingua porta a prestazioni simili a quelle ottenute con la stessa architettura pre-addestrata su grandi modelli multilingue e monolingue. Confermando questi risultati su un set di dati molto più ampio di contenuti rumorosi generati dagli utenti francesi, sosteniamo che tali modelli linguistici basati sui caratteri possono essere una risorsa per NLP in set di bassa risorsa e alta variabilità linguistica.</abstract_it>
      <abstract_lt>Neseniai įspūdingi NLP patobulinimai, daugiausia pagrįsti kontekstinių neuralinių kalbų modelių sėkme, daugiausia buvo parodyti ne daugiau kaip keliomis tuzinomis didelių išteklių kalbų. Kalbos modulių ir apskritai NLP sistemų kūrimas standartizuotoms ir mažai išteklių turinčioms kalboms tebėra sudėtinga užduotis. Šiame darbe daugiausia dėmesio skiriame Šiaurės Afrikos kolektyviniam dialektiniam arabų kalbai, parašytam naudojant Lotynų scenarijaus išplėtimą, vadinamą NArabizi, dažniausiai rastą socialinėje žiniasklaidoje ir pranešimų perdavime. Šiame mažai išteklių turinčiame scenarijuje, kai duomenų rodymas yra labai kintamas, palyginame simboliu pagrįsto kalbos modelio rezultatus su kalbos dalies žymėjimu ir priklausomybės analize su monokalbių ir daugiakalbių modelių rezultatais. Mes parodome, kad simboliu pagrįstas modelis, apmokytas tik 99k NArabizi sakiniais ir patobulintas mažame šios kalbos medžio langelyje, sukuria rezultatus, artimus tiems, kurie buvo įgyti naudojant tą pačią architektūrą, iš anksto apmokytas dideliais daugiakalbiais ir vienakalbiais modeliais. Patvirtindami šiuos rezultatus daug didesniam triukšmingo prancūzų naudotojų sukaupto turinio duomenų rinkiniui, teigiame, kad tokie simboliais pagrįsti kalbos modeliai gali būti naudingi NLP mažų išteklių ir didelio kalbų kintamumo rinkiniuose.</abstract_lt>
      <abstract_mk>Неодамнешните импресивни подобрувања во НЛП, главно базирани на успехот на контекстуалните модели на невровниот јазик, се демонстрирани претежно на најмалку неколку десетици јазици со високи ресурси. Изградбата на јазички модели и, погенерално, на НЛП системи за нестандардизирани и ниски ресурси јазици останува предизвикувачка задача. Во оваа работа, се фокусираме на северно-африканскиот колокуален арапски дијалектал напишан со користење на проширувањето на латинскиот скрипт наречен Нарабизи, најден претежно на социјалните медиуми и комуникацијата со пораки. Во овој сценарио со ниски ресурси со прикажување на податоци - со високо ниво на варијабилност, ја споредуваме понатамошната резултата на јазичкиот модел базиран на карактери со означување на дел од говорот и анализирање на зависноста со оној на монојазичните и мултијазичните модели. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models.  Потврдувајќи ги овие резултати на многу поголем набор на податоци на бучни француски содржини генерирани од корисниците, тврдиме дека ваквите јазички модели базирани на карактери може да бидат заслуга за НЛП во поставувања со ниски ресурси и високи јазички</abstract_mk>
      <abstract_kk>Жуырдағы NLP үшін көптеген жақсы жақсартулар, көптеген контексті невралдық тіл үлгілерінің сәттілігіне негізделген, көптеген көптеген бірнеше деңгейі ресурс тілдерінде көрсетілді Тілді mod- els құру және, кәдімгінше, стандартталмаған және төмен ресурс тілдерінің NLP жүйелерін құру мүмкіндік тапсырмасы бар. Бұл жұмыс ішінде Солтүстік Африканың колокуалды диалекталды араб тілінде NArabizi деп аталатын латын скрипттің кеңейтуі арқылы жазылған, көпшілігімен социалдық медиақтар мен хабарлау коммуникациясын Бұл төменгі ресурстар сценариясында деректерді көрсету - өзгерістер жоғары деңгейіндегі көп деңгейінде, біз таңбалар негіздеген тіл үлгісінің төменгі әдістерін монолингі және көп тіл үлгілеріне тәуелдік талдау мен Біз тек 99k NArabizi сөздеріне бағытталған, бұл тілдің кішкентай тілінің шегінде бағытталған, бір архитектура көп тілді және монолингі моделдерінде бірдей архитектура арқылы алдындағыларға жақын болады дегенді көрсетедік. Бұл нәтижелерді ағылшын французша пайдаланушылардың мазмұның көп үлкен деректер жиынын анықтау үшін, біз бұл таңбалардың негіздеген тіл моделдері NLP ресурстардың төмен және тілдің айнымалылығының баптаулар</abstract_kk>
      <abstract_ms>Perbaikan yang menakjubkan baru-baru ini dalam NLP, kebanyakan berdasarkan kejayaan model bahasa saraf kontekstual, kebanyakan telah dipaparkan pada paling tidak beberapa lusin bahasa sumber tinggi. Bina mod- els bahasa dan, secara umum, sistem NLP untuk bahasa yang tidak standardisasi dan bahasa sumber rendah tetap tugas yang mencabar. Dalam kerja ini, kami fokus pada Arab dialektal Afrika Utara yang ditulis menggunakan sambungan skrip Latin, yang dipanggil NArabizi, ditemui kebanyakan di media sosial dan komunikasi mesej. Dalam skenario sumber rendah ini dengan paparan data- memaparkan tingkat variabiliti tinggi, kita membandingkan prestasi bawah dari model bahasa berdasarkan aksara pada tag-sebahagian-ucapan dan penghuraian dependensi dengan model monobahasa dan berbilang bahasa. Kami menunjukkan bahawa model berdasarkan aksara dilatih pada hanya kalimat 99k NArabizi dan ditetapkan-ditetapkan pada batang pokok kecil bahasa ini membawa kepada prestasi yang dekat dengan yang diperoleh dengan arkitektur yang sama dilatih-dilatih pada model berbilang bahasa besar dan monobahasa. Mengesahkan hasil ini pada set data yang lebih besar bagi kandungan yang dibina oleh pengguna Perancis yang bunyi, kami menyangka bahawa model bahasa berdasarkan aksara seperti ini boleh menjadi aset untuk NLP dalam set variabiliti bahasa yang rendah-sumber dan tinggi.</abstract_ms>
      <abstract_ml>Recent impressive improvements in NLP, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages.  ഭാഷ മോഡ്- എലുകള്‍ നിര്‍മ്മിക്കുന്നു. പിന്നെ അതില്‍ കൂടുതല്‍ സാധാരണമായി നിര്‍മ്മിക്കപ്പെടാത്ത NLP സിസ്റ്റമുകള്‍ വിലപിട ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ വടക്ക്-ആഫ്രിക്കയിലെ കോളോക്കിയാല്‍ അറബിയില്‍ നിന്നും നാറാബിസിയെന്ന ലാറ്റിന്‍ സ്ക്രിപ്റ്റിന്‍റെ വിശാലമായ ഈ കുറഞ്ഞ വിഭവങ്ങളുടെ കൂടെ ഡേറ്റാ പ്രദര്‍ശിപ്പിക്കുന്നതിന്റെ ഉയര്‍ന്ന നിലയില്‍ മാറ്റമുള്ള ഭാഷയുടെ അടിസ്ഥാനത്തിലുള്ള ഭാഷ മോഡലിന്റെ പ്രഭാവം നമ്മള്‍ താരതമ് നമ്മള്‍ കാണിച്ചുകൊടുക്കുന്നത് നാറാബിസിയുടെ 99k വാക്കുകള്‍ മാത്രമേ പരിശീലിക്കപ്പെടുകയും ഈ ഭാഷയിലെ ചെറിയ ട്രീബാങ്കിന്‍മേല്‍ മുഴുവന്‍ പരിശീലിക്കപ്പെടുകയും ചെയ്തുള ഈ ഫലങ്ങള്‍ ഉറപ്പാക്കുന്നത് ഫ്രെഞ്ച് ഉപയോക്താവിന്റെ ഉള്ളടക്കം കൂടുതല്‍ വലിയ വിവരങ്ങളുടെ കൂട്ടത്തിലാണെന്നാണ്. ഇത്തരം അക്ഷരരൂപത്തിന്റെ അടിസ്ഥാനമായ ഭ</abstract_ml>
      <abstract_mt>Titjib impressjonanti riċenti fil-NLP, ibbażat fil-biċċa l-kbira fuq is-suċċess tal-mudelli tal-lingwi newrali kuntestwali, intwera l-aktar fuq mhux aktar minn żewġ dożi ta’ lingwi b’riżorsi għoljin. Il-bini ta’ moduli lingwistiċi u, b’mod aktar ġenerali, sistemi NLP għal lingwi mhux standardizzati u b’riżorsi baxxi għadu kompitu ta’ sfida. F’din il-ħidma, aħna niffokaw fuq l-Arabu kollokwujali dijalektali Afrikan ta’ Fuq miktuba bl-użu ta’ estensjoni tal-kitba Latina, imsejħa NArabizi, li tinsab l-aktar fuq il-midja soċjali u l-komunikazzjoni ta’ messaġġi. F’dan ix-xenarju ta’ riżorsi baxxi b’wiri tad-dejta li juri livell għoli ta’ varjabilità, a ħna nqabblu l-prestazzjoni downstream ta’ mudell lingwistiku bbażat fuq karattri fuq tikkettar ta’ parti mid-diskors u l-analiżi tad-dipendenza ma’ dik ta’ mudelli monolingwi u multilingwi. Aħna nuru li mudell ibbażat fuq il-karattru mħarreġ fuq biss 99k sentenza ta’ NArabizi u ffinat fuq bażi żgħira ta’ siġar ta’ din il-lingwa jwassal għal prestazzjoni qrib dawk miksuba bl-istess arkitettura mħarrġa minn qabel fuq mudelli multilingwi u monolingwi kbar. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for NLP in low-resource and high language variability set- tings.</abstract_mt>
      <abstract_pl>Ostatnie imponujące ulepszenia NLP, w dużej mierze oparte na sukcesie kontekstowych modeli języka neuronowego, zostały przedstawione głównie na co najwyżej kilkudziesięciu językach o wysokich zasobach. Budowanie modułów językowych i, bardziej ogólnie, systemów NLP dla języków niestandaryzowanych i niskich zasobów, pozostaje trudnym zadaniem. W niniejszej pracy zajmujemy się potocznym dialektalnym arabskim północnoafrykańskim napisanym przy użyciu rozszerzenia pisma łacińskiego, zwanego NArabizi, występującym głównie w mediach społecznościowych i komunikacji komunikacyjnej. W tym scenariuszu o niskiej ilości zasobów, w którym dane wyświetlają wysoki poziom zmienności, porównujemy wydajność modelu języka opartego na znakach w zakresie tagowania części mowy i analizy zależności do modeli jednojęzycznych i wielojęzycznych. Pokazujemy, że model oparty na znakach trenowany tylko na 99k zdaniach NArabizi i zdefiniowany na małym brzegu drzewa tego języka prowadzi do wydajności zbliżonej do tych uzyskanych przy tej samej architekturze wstępnie przeszkolonych na dużych modelach wielojęzycznych i jednojęzycznych. Potwierdzając te wyniki na znacznie większym zbiorze danych szumownych treści generowanych przez francuskiego użytkownika, argumentujemy, że takie modele językowe oparte na znakach mogą być atutem dla NLP w zbiorach niskich zasobów i wysokiej zmienności językowej.</abstract_pl>
      <abstract_ro>Recentele îmbunătățiri impresionante în PNL, bazate în mare parte pe succesul modelelor de limbaj neural contextual, au fost demonstrate în cea mai mare parte pe cel mult două duzini de limbi cu resurse ridicate. Construirea de moduri lingvistice și, mai general, de sisteme PNL pentru limbi nespecificate și cu resurse reduse rămâne o sarcină dificilă. În această lucrare, ne concentrăm pe arabă dialectală colocvială nord-africană scrisă folosind o extensie a scriptului latin, numită NArabizi, găsită mai ales pe social media și comunicare de mesagerie. În acest scenariu cu resurse reduse, cu afișarea datelor un nivel ridicat de variabilitate, comparăm performanța în aval a unui model de limbaj bazat pe caractere privind etichetarea parțială de vorbire și analizarea dependenței cu cea a modelelor monolingve și multilingve. Noi arătăm că un model bazat pe caractere instruit pe doar 99k de propoziții din NArabizi și amendat pe un braț mic al acestei limbi duce la performanțe apropiate de cele obținute cu aceeași arhitectură pre-instruită pe modele multilingve și monolingve mari. Confirmând aceste rezultate pe un set de date mult mai mare de conținut zgomotos generat de utilizatori francezi, susținem că astfel de modele lingvistice bazate pe caractere pot fi un avantaj pentru PNL în setări cu resurse scăzute și variabilitate ridicată a limbii.</abstract_ro>
      <abstract_mn>Сүүлийн үед НLP-ийн гайхалтай сайхан хөгжлийн улам, ихэнх нь орчин үеийн мэдрэлийн хэл загварын амжилтын үндсэн, ихэнх нь хэдэн арван нийтлэг хэл дээр харагдсан. Холбооны mod-els болон, ихэвчлэн, стандарт биш болон бага нөөцийн хэлний NLP системийг бүтээх нь хэцүү ажил. Энэ ажлын тулд бид Хойд Африкийн диалектикийн Араб хэлснээр Латин шинжлэх ухааны нэмэлтийг ашиглаж бичсэн юм. Нарабизийн нэмэлт бичиг нь ихэнхдээ нийгмийн хэвлэл болон хаягдлын холбоотой байдаг. Энэ бага эдийн засгийн хувилбарт өгөгдлийн дэвшүүлэлт - өөрчлөлтийн өндөр түвшинд, бид харьцааны үндсэн хэл загварын давхар үйл ажиллагааг нэг хэл болон олон хэл загваруудын нэг хэсэгт хамааралтай талаар харьцуулж байна. Бид энэхүү хэлний жижиг хэлбэрээр сургалтын загвар нь NArabizi 99k өгүүлбэрээр сургалтын загвар нь ижил архитектур, олон хэл болон ганц хэл загвар дээр сургалтын өмнө сургалтын хийгдсэн хүмүүстэй ойрхон ажиллагааг харуулж байна. Эдгээр үр дүн нь Француз хэрэглэгчдийн бүтээгдэхүүний маш том өгөгдлийн хэлбэрийг тодорхойлох боломжтой. Бид хэлбэрээр суурилсан хэл загварууд нь бага болон өндөр хэлний өөрчлөлтийн хэлбэрээр NLP-ийн асуудал болох болом</abstract_mn>
      <abstract_no>Nyleg uttrykkelige forbetringar i NLP, hovudsakelig basert på suksessen av kontekstlege neuralspråk- modeller, er mest demonstrert på fleste fleire tusen høg- ressursspråk. Name I denne arbeida har vi fokusert på Nord-Afrikanske kollektiske dialektiske arabiske skriven med eit utviding av latinsk skript, kalla NArabizi, som finst hovudsakelig på sosiale medier og meldingskomunikasjon. I denne låg ressursscenarioen med datavisning som er høg nivå på variabelnaden, sammenlignar vi nedstrømmen av eit teiknbasert språk-modell på ein del av talemerking og tillesing av avhengighet til det av monospråk og multispråk-modeller. Vi viser at eit teiknbasert modell som er trent på bare 99k setningar av NArabizi og fint opp på ein liten treebank av dette språket fører til å utføre nær dei som er fått med same arkitektur før- trent på store multispråk og monospråk modeller. Bestemmer desse resultatene på mykje større datasett av støyleg fransk brukarnamn generert innhald, så argumenterer vi at slike teiknbaserte språk-modeller kan vera eit aktiv for NLP i låg ressursar og høg språk-variabilitet.</abstract_no>
      <abstract_sr>Nedavno impresivno poboljšanje NLP-a, uglavnom zasnovano na uspjehu kontekstualnih neuralnih jezičkih modela, uglavnom se pokazalo na najviše nekoliko desetina visokih jezika resursa. Izgradavanje jezika mod-els i, općenito, NLP sistema za nepstandardizovane i niske resurse, ostaje izazovni zadatak. U ovom poslu, fokusiramo se na koleksijalnu dijalektnu arapsku, napisanu na severnoafričkom dijalektnom arabskom jeziku, koristeći produženje latinskog skripta, nazvan NArabizi, koji se uglavnom nalazi na društvenim medijima i komunikaciji poruke. U ovom scenariju s niskim resursima sa pokazivanjem podataka - visokom nivou variabilnosti, uspoređujemo niz izvođenje jezičkog model a na karakteru na dijelu govornog oznake i analizu zavisnosti sa monojezičkim i multijezičkim modelima. Pokazujemo da model na karakteru obučen samo na 99k rečenica NArabizi i napravljen na malom krevetu ovog jezika vodi do izvođenja blizu onih koji su dobili iste arhitekture pre-obučene na velikim multijezičkim i monojezičkim modelima. Potvrđujući te rezultate na mnogo većem setu podataka o buknim sadržajima francuskog korisnika, tvrdimo da takvi jezički modeli na karakteru mogu biti imovina za NLP u setovima niskih resursa i visokih jezičkih variabilnosti.</abstract_sr>
      <abstract_si>NLP වලින් අලුත් ප්‍රශ්නයක් ප්‍රශ්නයක් තියෙනවා, ප්‍රශ්නයක් ප්‍රශ්නයක් නිර්මාණය භාෂාවයේ සාර්ථක විශ්වාසිත විද භාෂාව මඩ්- එල්ස් හා වඩා සාමාන්‍යයෙන්, NLP පද්ධතිය නොස්ටැන්ඩාර්ඩිස් වෙනුවෙන් සහ අඩු සම්බන්ධ භාෂාවට මේ වැඩේ අපි උතුරු අෆ්‍රිකානික් සංවේදනය අරාබියාවේ ලැටින් ස්ක්‍රිප්ට් එකේ විස්තරයක් භාවිත කරන්න ලියලා තියෙන්නේ, NArabiz කිය මේ අඩුම සම්බන්ධ සිනාරියේ දත්ත ප්‍රදර්ශනය සමඟ දත්ත ප්‍රදර්ශනය- වෙනස් ස්ථානයක් වෙනුවෙන්, අපි අකුරු භාෂාවක් අධාරිත භාෂාවක් මොඩේල අපි පෙන්වන්නේ නැරාබිසියේ 99k වචනයක් විතරයි මේ භාෂයේ පුංචි ට්‍රෙබැන්ක් වලින් ප්‍රශ්නයක් ප්‍රශ්නයක් විතරයි කියලා ප්‍රශ්නයක් ප්‍රශ්නයක් වෙන මේ ප්‍රතිචාරයක් ස්ථාපනය කරන්න ප්‍රංචි භාවිතාව නිර්මාණය කරපු විශාල දත්ත සූදානයක් විතරයි, අපි ප්‍රතිචාරය කරනවා ඒ වගේ අක්ෂර භ</abstract_si>
      <abstract_so>Horumarinta hore ee NLP, si badan ku saleysan liibaanka modelalka afka neurada ee joogtada ah, waxaa lagu muujiyey ugu badnaan labo dozen luuqadood oo sare oo resource. Bulshada qaababka luuqada iyo si ka badan nidaamka NLP ee luqadaha aan la standardisey iyo noocyada hoose ee noocyada luqadu waa mid dhibaataysan. Shaqadan, waxaynu ku qornaa qoraalka afka Waqooyi-Afrika oo ku qoran qoraal dheeraad ah oo la yidhaahdo NArabizi, waxaana laga helay macluumaadka bulshada iyo warqada messagiga. Muuqashadan hoos-resource ah iyo muuqashada data- muuqashada heer sare oo kala beddelaya, waxaynu isbarbardhignaa muuqashada hoose ee muuqashada afka ku qoran ee ku qoran qeyb ka mid ah tagging hadalka iyo ku xiran baaritaanka noocyada luuqadaha iyo luuqadaha kala duduwan. Waxaynu tusnaynaa in tusaale ahaan lagu baray 99k kaliya oo lagu baro Narabizi oo lagu qoray qoraal yar oo luqadan lagu qoray ay uu ku hoggaami karo kuwa la helay dhismo isku mid ah oo lagu baray tusaalooyin badan oo luuqadaha kala duduwan iyo noocyo luqad ah. Si a an u xaqiijinno arimahan waxaa looga dhigi karaa macluumaad aad u weyn oo ay ka buuxaan waxyaabaha afka faransa ee isticmaalayaasha, waxaynu ka doodaynaa in noocyada luqada oo kale ee xarafka lagu qoray ay ay ahaan karaan hanti u ah NLP, taas oo ay tahay noocyada hoose-resource iyo heerka kala bedeli kara luuqada sare.</abstract_so>
      <abstract_sv>De senaste imponerande förbättringarna av NLP, till stor del baserade på framgången av kontextuella neurala språkmodeller, har huvudsakligen visats på högst ett par dussin högresursspråk. Att bygga språkmod och mer generellt NLP-system för icke-standardiserade och lågresursspråk är fortfarande en utmaning. I detta arbete fokuserar vi på nordafrikanska dialektiska arabiska skrivna med hjälp av en förlängning av det latinska skriptet, kallad NArabizi, som främst återfinns på sociala medier och meddelandekommunikation. I det här lågresursscenariot med datavisning med hög variabilitet jämför vi prestandan nedströms hos en teckenbaserad språkmodell för delmärkning och beroendetolkning med prestandan hos enspråkiga och flerspråkiga modeller. Vi visar att en karaktärsbaserad modell tränad på endast 99k meningar av NArabizi och finjusterad på en liten trädbank av detta språk leder till prestanda nära dem som erhålls med samma arkitektur pre-tränad på stora flerspråkiga och enspråkiga modeller. För att bekräfta dessa resultat på mycket större datamängd bullrigt franskt användargenererat innehåll hävdar vi att sådana teckenbaserade språkmodeller kan vara en tillgång för NLP i inställningar med låg resurs och hög språkvariation.</abstract_sv>
      <abstract_ta>அண்மையில் NLP வெற்றியை அடிப்படையால் அண்மையான முன்னேற்றங்கள் செய்யப்பட்டுள்ளது, பெரும்பாலாவது சில பத்தான உயர்ந்த மூலங்கள் மொழிகளை  @ info இந்த வேலையில், நாங்கள் வடக்கு ஆப்ரிக்காவின் கூட்டாள்வியல் அரபி மொழியில் புதுப்பிக்கிறோம். நாராபிஸ் என்ற லாட்டின் விரிவாக்கத்தை பயன் இந்த குறைந்த மூலத்தின் காட்சியில் தரவு காட்சியில் அதிக நிலை மாறிகளை காட்டுகிறது, எழுத்து அடிப்படையான மொழி மாதிரியின் செயல்பாட்டை ஒப்பிடுகிறோம் பேச்சு  நாம் காட்டுகிறோம் ஒரு எழுத்து அடிப்படையான மாதிரி நாராபிசியின் 99k வாக்கியங்கள் மட்டும் பயிற்சி செய்யப்பட்டுள்ளது மற்றும் ஒரு சிறிய மொழியின் மீது வெளியேற்றப்பட இந்த முடிவுகளை உறுதிப்படுத்துகிறது அதிகப்பெரிய தகவல் அமைப்பு பிரஞ்சு பயனர் உருவாக்கப்பட்ட உள்ளடக்கங்களின் மீது, இவ்வாறு எழுத்து அடிப்படையான மொழி மாதிரி</abstract_ta>
      <abstract_ur>NLP میں اچھا اثر اثر انگیز تغییرات، جو اکثر متوسط نئورل زبان کی مدلکوں کی موفقیت پر بنیاد ہیں، بہت زیادہ سے چند دگن زیادہ سراسر زبانوں میں دکھائے گئے ہیں. زبان mod- els بنانا اور، زیادہ عمومی، NLP سیسٹم نااستاندارڈیز اور کم منبع زبانوں کے لئے ایک مشکل کام ہے۔ اس کام میں ہم نے سوسیل میڈیا اور پیغام رسانے کی تعلیم کے مطابق لکھی ہوئی عربی نام کے ذریعہ سے نوشتہ ہوئی سوچولی آفریقا کے ساتھ فو-کوس کیا۔ اس کم منبع سیناریو میں ڈاٹ ڈیسائل کے ساتھ، ایک بلند سطح کی متفاوت کے ساتھ، ہم ایک شخصت کی زبان میں بنیاد رکھی زبان موڈل کے نیچے کامیابی کو ایک قسم کی ٹاگ اور ایک زبان اور متعدل زبان موڈل کے ساتھ پارسی کرنے کے لئے مقایسہ کرتے ہیں. ہم نشان دیتے ہیں کہ ایک شخص بنیاد مدل جو NArabizi کی 99k جماعتوں پر آموزش کی گئی ہے اور اس زبان کی ایک چھوٹی ٹریب بانک پر فینڈ ٹینڈ ٹینڈ کی گئی ہے ان لوگوں کے نزدیک عمل کرتا ہے جو بڑے زبان اور ایک زبان مدل پر پہلے آموزش کی گئی ہے۔ یہ نتائج مطمئن کرنے کے لئے بہت بڑے فرانسوی یوسٹ کے سامنے پیدا ہوئے منصوبات کے ذریعہ ڈیٹ سٹ پر ہے، ہم جھگڑتے ہیں کہ ایسے شخص بوسیدہ زبان موڈل NLP کے لئے کم منصوبات اور بلند زبان متفاوت سٹ-ٹینگ کے ذریعہ ایک ام</abstract_ur>
      <abstract_uz>Yaqinda, NLP'da eng yaxshi o'zgarishlar muvaffaqiyatga asoslangan oddiy neyron tili modellariga ko'p ko'pchilik ko'plab ko'pgina dozen yuqori rasmlar tilida ko'rsatilgan. Tilning moduli- els yaratish, va umumiy boʻlgan, andoza boʻlmagan va kichik manbaning tillari uchun NLP tizimlari qiymati vazifasi qoladi. Bu ishda biz Shimol-Afrika Colekquial Dialectal Arabiga yozilamiz, Narabizi deb nomlangan Latin skriptning kengaytmasi yordamida yozilgan, ko'pchilik jamiyatli medyaya va xabar tarkibini topdik. @ info Biz buni ko'rsatganimiz, Narabizining 99k so'zlarida o'rganilgan shakl modeli va bu tillarning kichkina treebangga qo'shilgan bir xil tillar va monolingan modellarda o'rganishga o'rganish mumkin. Bu natijalarni tasdiqlash uchun juda katta maʼlumot tarkibini ishlatish mumkin. Biz bu harflar asosida boʻlgan tillar modellarini nazar manbalar va eng yuqori tillar oʻzgarishni oʻrnatish mumkin.</abstract_uz>
      <abstract_vi>Những tiến bộ ấn tượng gần đây của ngôn ngữ thần kinh, chủ yếu dựa trên thành công của các mô hình liên tiếp trên ngôn ngữ thần kinh, đã được hiển thị hầu hết là trên vài chục ngôn ngữ có nguồn cao. Xây dựng ngôn ngữ mod- el và, nói chung, hệ thống ngôn ngữ ngôn ngữ ngôn ngữ không chuẩn và ít tài nguyên vẫn là một nhiệm vụ khó khăn. Trong tác phẩm này, chúng tôi tập trung vào tiếng địa phương Bắc Phi viết bằng một phần mở rộng văn bản Latin, được gọi là NArabizi, được tìm thấy hầu hết trên truyền thông xã hội và truyền thông điệp. Trong trường hợp với mức độ biến đổi cao, chúng ta so sánh hiệu suất theo dòng của một mô hình ngôn ngữ dựa trên phần phát âm và độ phụ thuộc phân biệt ngôn ngữ, theo cách phân biệt ngôn ngữ và đa dạng. Chúng tôi cho thấy một mô hình nhân cách được huấn luyện chỉ dựa vào những câu 99 của Nazca và chỉnh sửa theo một bản vẽ nhỏ của ngôn ngữ này dẫn đến hiệu suất gần với những người được cung cấp với kiến trúc tương tự được đào tạo trước các mô hình bự, đa dạng và ngôn ngữ. Xác nhận kết quả này là dựa trên một tập tin dữ liệu lớn hơn nhiều về những chất lượng ồn ào của người dùng Pháp, chúng tôi cho rằng những mô hình ngôn ngữ dựa vào tính cách đó có thể trở thành tài sản cho đài NLP trong việc cung cấp ít tài nguyên và độ thay đổi ngôn ngữ cao.</abstract_vi>
      <abstract_bg>Последните впечатляващи подобрения в НЛП, основно базирани на успеха на контекстуалните невронни езикови модели, са демонстрирани най-вече на няколко дузини високоресурсни езика. Изграждането на езикови модули и, по-общо, системи за НЛП за нестандартни и нискоресурсни езици остава трудна задача. В тази работа се фокусираме върху северноафриканския колоквиален диалектален арабски език, написан с помощта на разширение на латинската писменост, наречена НАрабици, намираща се предимно в социалните медии и комуникацията с съобщения. В този сценарий с нисък ресурс с показване на данни с високо ниво на променливост, сравняваме ефективността надолу по веригата на езиков модел, базиран на знаци, при маркиране на част от речта и анализ на зависимостта с тази на моноезичните и многоезичните модели. Показваме, че модел базиран на символи, обучен само върху 99к изречения на нарабици и финирано настроен на малък триъгълник на този език, води до изпълнение, близко до тези, получени със същата архитектура, предварително обучен на големи многоезични и едноезични модели. Потвърждавайки тези резултати при много по-голям набор от данни от шумно генерирано от потребителите съдържание на френски език, ние твърдим, че такива езикови модели, базирани на знаци, могат да бъдат предимство за НЛП при набор от ниски ресурси и висока езикова вариабилност.</abstract_bg>
      <abstract_da>Nylige imponerende forbedringer i NLP, hovedsagelig baseret på succesen af kontekstuelle neurale sprogmodeller, er for det meste blevet demonstreret på højst et par dusin high-resource sprog. Opbygning af sprogmodninger og mere generelt NLP-systemer til ikke-standardiserede sprog og lav ressource sprog er fortsat en udfordrende opgave. I dette arbejde fokuserer vi på nordafrikansk dialektisk arabisk skrevet ved hjælp af en udvidelse af det latinske skrift, kaldet NArabizi, som hovedsagelig findes på sociale medier og messaging kommunikation. I dette scenarie med lav ressource, hvor data viser et højt niveau af variabilitet, sammenligner vi ydeevnen i efterstrømmen af en tegnbaseret sprogmodel på delt-af-tale tagging og afhængighedsanalyse med ydeevnen i ensprogede og flersprogede modeller. Vi viser, at en karakterbaseret model trænet på kun 99k sætninger af NArabizi og finjusteret på en lille treebank af dette sprog fører til performance tæt på dem, der opnås med den samme arkitektur forudtrænet på store flersprogede og ensprogede modeller. Ved at bekræfte disse resultater på langt større datasæt af støjende fransk brugergenereret indhold argumenterer vi for, at sådanne tegnbaserede sprogmodeller kan være et aktiv for NLP i lav ressource- og høj sprogvariabilitet sæt.</abstract_da>
      <abstract_nl>Recente indrukwekkende verbeteringen in NLP, grotendeels gebaseerd op het succes van contextuele neurale taalmodellen, zijn meestal gedemonstreerd op maximaal een paar dozijn high-resource talen. Het bouwen van taalmod- len en, meer in het algemeen, NLP-systemen voor niet-gestandaardiseerde en low-resource talen blijft een uitdagende taak. In dit werk richten we ons op Noord-Afrikaans dialectisch Arabisch geschreven met behulp van een uitbreiding van het Latijnse schrift, genaamd NArabizi, dat vooral te vinden is op social media en messaging communicatie. In dit low-resource scenario met een hoge mate van variabiliteit, vergelijken we de downstream prestaties van een karaktergebaseerd taalmodel op part-of-speech tagging en afhankelijkheidsparsing met die van eentalige en meertalige modellen. We tonen aan dat een karaktergebaseerd model getraind op slechts 99k zinnen van NArabizi en gefineerd op een kleine boombank van deze taal leidt tot prestaties die vergelijkbaar zijn met die welke worden verkregen met dezelfde architectuur, voorgetraind op grote meertalige en eentalige modellen. Om deze resultaten te bevestigen op een veel grotere dataset van ruisige Franse user-generated content, stellen we dat dergelijke karaktergebaseerde taalmodellen een aanwinst kunnen zijn voor NLP in low resource en high language variability sets.</abstract_nl>
      <abstract_hr>Nedavno impresivno poboljšanje u NLP-u, uglavnom temeljeno na uspjehu kontekstualnih neuralnih jezika, uglavnom se pokazalo na najviše nekoliko tuceta jezika visokog resursa. Izgradavanje jezičkih mod- els i, općenito, NLP sustava za nepstandardizirane i niske resurse, ostaje izazovni zadatak. U ovom poslu, mi se fokusiramo na koleksijalnu dijalektnu arapsku dijalektnu, napisanu koristeći proširenje latinskog skripta po imenu NArabizi, koji se uglavnom nalazi na društvenim medijima i komunikaciji poruke. U ovom scenariju s niskim resursima s pokazivanjem podataka - visokom nivou variabilnosti, uspoređujemo donjeg učinka jezičkog model a baziranog na karakterima na dijelu govornog oznake i analizu zavisnosti s onim monojezičkim i multijezičkim modelima. Pokazujemo da model na karakteru obučen samo na 99k rečenica NArabizi i napravljen na malom krevetu ovog jezika vodi do izvođenja blizu onih koji su dobili istim arhitekturom predobučenim na velikim multijezičkim i monojezičkim modelima. Potvrđivanje tih rezultata na mnogo većem sastavu podataka o bučnom sadržaju Francuskog korisnika, tvrdimo da takvi jezički modeli na karakteru mogu biti imovina NLP-a u nizim resursima i određivanju velikih jezičkih varijabilita.</abstract_hr>
      <abstract_de>Neuere beeindruckende Verbesserungen in NLP, die größtenteils auf dem Erfolg kontextueller neuronaler Sprachmodelle beruhen, wurden meist auf höchstens ein paar Dutzend High-Resource-Sprachen demonstriert. Der Aufbau von Sprachmodalitäten und allgemein NLP-Systemen für nicht standardisierte und ressourcenarme Sprachen bleibt eine herausfordernde Aufgabe. In dieser Arbeit beschäftigen wir uns mit nordafrikanischem umgangssprachlichem dialektalem Arabisch, das mit einer Erweiterung der lateinischen Schrift namens NArabizi geschrieben wird, die hauptsächlich in sozialen Medien und Nachrichtenkommunikation zu finden ist. In diesem ressourcenarmen Szenario mit hoher Variabilität der Daten vergleichen wir die nachgelagerte Leistung eines charakterbasierten Sprachmodells für Sprachteiltagging und Dependency Parsing mit der von ein- und mehrsprachigen Modellen. Wir zeigen, dass ein charakterbasiertes Modell, das nur auf 99k Sätzen von NArabizi trainiert und auf einem kleinen Baumstamm dieser Sprache fein abgestimmt ist, zu einer Performance führt, die denen nahe kommt, die mit derselben Architektur erreicht wird, die auf großen mehrsprachigen und einsprachigen Modellen vortrainiert wurde. Wir bestätigen diese Ergebnisse auf einem viel größeren Datensatz von rauschendem französischem User-Generated Content und argumentieren, dass solche charakterbasierten Sprachmodelle für NLP bei ressourcenarmen und hohen Sprachvariabilitätssätzen von Vorteil sein können.</abstract_de>
      <abstract_ko>최근 NLP의 현저한 개선은 주로 상하문 신경 언어 모델의 성공을 바탕으로 하고 있으며 최대 몇 십 가지 고자원 언어에서 증명되었다.비표준화되고 저자원적인 언어를 위해 언어 모델을 구축하고 더욱 보편적인 NLP 시스템을 구축하는 것은 여전히 도전적인 임무이다.이 작업에서 우리가 주목하는 것은 북아프리카 방언 아랍어이다. 라틴어의 확장자인 나라비지(Narabizi)는 주로 소셜 미디어와 메시지 통신에 나타난다.이런 데이터가 고도로 가변적인 저자원 장면에서 우리는 문자를 바탕으로 하는 언어 모델이 단어성 표시와 의존성 분석에 있어 단어와 다국어 모델의 하류 성능을 비교했다.우리는 문자 기반 모델이 나라비치의 99k문에서만 훈련되고 이 언어의 작은 트리 라이브러리에서 미세하게 조정되는 것을 증명했다. 그 성능은 대형 다중 언어와 단어 모델에서 미리 훈련된 같은 구조에서 얻은 성능에 가깝다.우리는 이러한 문자 기반 언어 모델이 낮은 자원과 높은 언어의 가변성 상황에서 NLP의 자산이 될 수 있어 더욱 큰 데이터 집합에서 이러한 결과를 증명할 수 있다고 생각한다.</abstract_ko>
      <abstract_id>Perbaikan yang mengesankan baru-baru ini di NLP, kebanyakan berdasarkan sukses dari model bahasa saraf kontekstual, telah kebanyakan diajukan pada paling tidak beberapa lusin bahasa sumber daya tinggi. Membangun mod- els bahasa dan, secara umum, sistem NLP untuk bahasa yang tidak standar dan bahasa sumber daya rendah tetap tugas yang mencabar. Dalam pekerjaan ini, kami fokus pada bahasa Arab dialektal Afrika Utara ditulis menggunakan ekstensi skrip Latin, bernama NArabizi, ditemukan kebanyakan di media sosial dan komunikasi pesan. Dalam skenario sumber daya rendah ini dengan penampilan data- menampilkan tingkat tinggi variabilitas, kita membandingkan prestasi turun dari model bahasa berdasarkan karakter pada tagging bagian dari pidato dan penghuraian dependensi dengan model monobahasa dan multibahasa. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models.  Mengkonfirmasi hasil ini pada set data yang jauh lebih besar dari konten yang dibuat oleh pengguna Perancis yang berisik, kami menyangka bahwa model bahasa berdasarkan karakter tersebut dapat menjadi aset untuk NLP dalam set variabilitas bahasa rendah dan tinggi sumber daya.</abstract_id>
      <abstract_sw>Maboresho ya hivi karibuni katika NLP, kwa kiasi kikubwa kutokana na mafanikio ya mifano ya lugha za kisasa, yameonyeshwa kwa kiasi kikubwa katika lugha mbili za rasilimali zilizo juu. Kujenga nyenzo za lugha na, kwa ujumla zaidi, mfumo wa NLP kwa lugha zisizo za kawaida na rasilimali zisizo chini bado unabaki kuwa na changamoto. Katika kazi hii, tunajikita katika lugha ya Kiarabu ya Kiarabu ya Kusini-Afrika ya Kaskazini iliyoandikwa kwa kutumia ukurasa wa kitabu cha Kusini, kinachoitwa NArabizi, tunapatikana zaidi kwenye mitandao ya kijamii na mawasiliano ya ujumbe. Katika tukio hili la rasilimali duni na kuonyesha taarifa - kuonyesha kiwango kikubwa cha mabadiliko, tunalinganisha utendaji wa mito ya muonekano wa lugha yenye msingi wa wahusika juu ya sehemu ya wimbo wa kujieleza na kutegemea kuimba kwa mifano ya lugha za kiutamaduni na lugha nyingine. Tunaonyesha kuwa muundo wa msingi wa wahusika ulioelekezwa kwa sentensi 99 tu ya NArabizi na kuwekwa vizuri kwenye benki ndogo ya mitatu ya lugha hii unapelekea kufanya kazi karibu na wale waliopata katika ujenzi huo ule uliojifundishwa kwa mifano mingi ya lugha na kimonolinguli. Kuthibitisha matokeo haya yanahusiana na takwimu kubwa zaidi ya maudhui ya mtumiaji wa Kifaransa yanayozaliwa na kelele, tunahoji kuwa mifano ya lugha ya kibinafsi yanaweza kuwa rasilimali kwa ajili ya NLP katika hali ya chini ya rasilimali na mabadiliko ya lugha ya juu.</abstract_sw>
      <abstract_tr>NLP'da iň soňky täsirli gelişmeler, möhüm teksirli neural dil nusgalarynyň başarnygyna dayanýar, köplenç on düýn ýokary çeşme dilinde görkezilýär. Diller mod-els guralýar we, adatça, NLP sistemleri standartlanmadyk we iň az resurslar dili üçin çykyş täze bir işdir. Bu işde biz North-African koloksiýal dialektal arapça dilektal dilektal dilektal dilektal dilinde NArabizi adlanan latin skriptlerini ulanyp, köplenç sosyal mediýalarda we görkezmelerde tapdyk. Bu iň az kaynakça senaryýada maglumat görkezilmesi bilen - görkezilişinde üýtgeşmeler ýokary derejesi we karakterlerde tabanly dil nusgasyny monodil we multi dil nusgasyna karşılaştyrýarys. Biz Karakter tabanly bir nusga diňe NArabizi ň 99k sözlerine we bu diliň kiçi çyzygynda düzülen, beýleki multi dil we monodil nusgalarynda öňki arhitektura geçirilen adamlaryň ýakynda täsirleşeni gösterip bilýäris. Bu netijeleri Fransuzça ullançylar tarapyndan gaty uly maglumatyň halkara bardygyny tassyklaýarys, biz şol karakterlerde tabanly dil nusgalary NLP üçin iň az resurslar we ýokary dil üýtgeýänlik düzümlerniň bardygyny a ýdýarys.</abstract_tr>
      <abstract_fa>پیشرفتهای اخیرا تحت تاثیر انگیز در NLP، بسیار زیادی بر اساس موفقیت مدلهای زبان عصبی فصلی، بیشتر در بیشتر دو دوازه زبان منابع بالا نشان داده شده‌اند. ساختن mod- els زبان و، بیشتر عمومی، سیستم NLP برای زبانهای غیر استاندارد و کم منابع باقی ماند یک کار مشکل است. در این کار، ما با استفاده از استفاده از نوشته لاتین نوشته شده‌ایم که به نام نارابیزی نامیده می‌شود، بیشتر در رسانه‌های اجتماعی و ارتباط پیغام پیغام یافته‌ایم. در این سناریو منبع پایین با نمایش داده ها- با نمایش یک سطح بالا از تغییرات، عملکرد پایین‌ترین یک مدل زبان بر اساس شخصیت بر پایین‌های نقاشی و بستگی با آن از مدل‌های یک زبان و چند زبان مقایسه می‌کنیم. ما نشان می دهیم که یک مدل بر اساس شخصیت بر اساس فقط 99k جمله نارابیزی آموزش یافته و بر اساس یک چوب کوچک از این زبان پاداش یافته شده به انجام نزدیک کسانی که با یک معماری پیش از آموزش یافته شده در مدل های بزرگ زبان و یک زبان آموزش یافته اند، به انجام نزدیک کسانی که با یک معماری پیش از تأييد کردن اين نتايج‌ها در مجموعه‌ي اطلاعات بزرگ‌تر از محتويات ساخته شده از کاربر فرانسه‌ها صوت مي‌گيريم که اين مدل‌هاي زبان روي شخصيت‌ها مي‌توانند محتويات NLP باشند در مجموعه‌هاي تغييرات زبان‌هاي پايين و بالا</abstract_fa>
      <abstract_af>Onlangse inpresieële verbeteringe in NLP, groot gebaseer op die sukses van contextual neurale taal modele, is meeste gewys op die meeste van 'n paar dozen hoë- hulpbron tale. Bou taal mod- els en, meer algemeen, NLP stelsels vir nie- standardiseerde en lae- hulpbron tale bly 'n pragtige taak. In hierdie werk het ons fokus op Noord-Afrikaanse kolleksiele dialektiese Arabiese geskryf met 'n uitbreiding van die Latynskrip, NArabizi genoem, meeste gevind op sosiale media en boodskapkommunikasie. In hierdie lae-hulpbron scenario met data vertoon - met 'n hoë vlak van veranderlikheid, vergelyk ons die onderstreem prestasie van 'n karakter-gebaseerde taal model op deel-van-woorde etiketing en afhanklikheid verwerking tot daardie van monolinglike en multilinglike modele. Ons wys dat 'n karakter-gebaseerde model wat slegs 99k setnings van NArabizi onderwerp is en gefin-tuned op 'n klein treebank van hierdie taal lei na uitvoer naby aan die wat verkry is met dieselfde architektur voor-onderwerp op groot multitaalse en monotaalse modele. Bevestig hierdie resultate 'n op baie groter data stel van geluidige Franse gebruiker genereerde inhoud, ons argueer dat so karaktergebaseerde taal modele kan 'n asset wees vir NLP in lae- hulpbron en hoë taal veranderlike stellings.</abstract_af>
      <abstract_sq>Përmirësimet e fundit mbresëlënëse në NLP, kryesisht bazuar në suksesin e modeleve kontekstuale të gjuhës nervore, janë demonstruar më së shumti në disa duzina gjuhësh me burime të larta. Ndërtimi i moduleve gjuhësore dhe, më përgjithësisht, sistemi NLP për gjuhët jo-standardizuara dhe me burime të ulëta mbetet një detyrë sfiduese. Në këtë punë, ne përqëndrohemi në dialektalin arab dialektal verior-afrikan të shkruar duke përdorur një zgjerim të skriptit latin, të quajtur NArabizi, gjetur kryesisht në media sociale dhe komunikimin mesazh. Në këtë skenar me burime të ulëta me shfaqjen e të dhënave- duke treguar një nivel të lartë variabiliteti, ne krahasojmë paraqitjen poshtë të një modeli gjuhësor bazuar në karakter në shënimin e pjesës së fjalimit dhe analizimin e varësisë me atë të modeleve monogjuhësore dhe shumëgjuhësore. Ne tregojmë se një model me bazë karakteri i stërvitur me vetëm fjalë 99k të NArabizit dhe i rregulluar në një bazë pemësh të vogël të kësaj gjuhe çon në shfaqje pranë atyre të arritur me të njëjtën arkitekturë të stërvitur para-stërvitur në modele të mëdha shumëgjuhësore dhe monogjuhësore. Duke konfirmuar këto rezultate një sërë të dhënash shumë më të mëdha të përmbajtjeve të gjeneruara nga përdoruesit francez, ne argumentojmë se modelet e tilla gjuhësh të bazuara në karakter mund të jenë një pasuri për NLP në set-tings me burime të ulëta dhe variabiliteti të lartë gjuhësh.</abstract_sq>
      <abstract_am>በአሁኑ ወቅት የኒጀራዊ ቋንቋ ምሳሌዎችን በመጠቀም የNLP አካባቢ የበለጠ የበለጠ ሁለት እጥፍ ከፍተኛ የክፍለ ምዕራፍ ቋንቋዎች በመጠቀም ታይተዋል፡፡ ቋንቋ-ዓይነት-els በመሠረት ላይ እና በተጨማሪም የNLP ስርዓቶች ለባይደናዳዊ እና ትንሽ resource ቋንቋዎች የሚያስተናክሉ ስራ ነው፡፡ በዚህ ሥራ በሰሜን-አፍሪካ ኮሌክያዊ ቋንቋ አረብኛ ላይ የተጻፈን ናራቢ በሚባል የላቲን ጽሑፍ መዘርጋት በተጻፈ እና አብዛኛውን በማኅበራዊ አውታር ማኅበራዊ ሚዲያ እና የመልእክት ግንኙነት ላይ የተገኘን ነው፡፡ በዚህ ታናሽ resource scenario ከዳታ አሳይቷል - ከፍተኛ ደረጃው የልዩዩነት አካባቢ እና በንግግር ማተሚያ እና በመደገፍ እና በብዙ ቋንቋዎች ዓይነቶች ላይ ማዘጋጀትን እናስተያየዋለን፡፡ በ ቋንቋ ላይ በ99k የናረባሲ ቃላት ብቻ የተጠቃሚ የፊደል ሞዴል እና በዚህ አንዲት ትልቅ ድምፅ ላይ የተገኘውን እናሳየዋለን፡፡ እነዚህን ፍሬዎች የፋንሳይኛ ተጠቃሚ የቋንቋ አካባቢ የድምፅ መረጃዎችን በማረጋገጥ እና እንደምናረጋግጥ የፊደል ቋንቋ ምሳሌዎች ከታናሹ ክፍል እና ከፍተኛ ቋንቋ የተለየ ልውጤት ማሰናከል ለNLP ሀብት እንዲሆን እንከራከራለን፡፡</abstract_am>
      <abstract_hy>Recent impressive improvements in NLP, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages.  Լեզվային մոդելների կառուցվածքը և, ավելի ընդհանուր առմամբ, ոչ ստանդարտիզացված և ցածր ռեսուրսներ ունեցող լեզուների ՆԼՊ համակարգերը դեռևս դժվար խնդիր է: In this work, we fo- cus on North-African colloquial dialectal Arabic written using an extension of the Latin script, called NArabizi, found mostly on social media and messaging communication.  Այս ցածր ռեսուրսների սցենարիայում, որտեղ տվյալները ցույց են տալիս բազմազանության բարձր մակարդակը, մենք համեմատում ենք հերոսներով հիմնված լեզվի մոդելի ներքևի արտադրողությունը խոսքի մի մասի վրա և կախվածությունը միալեզվի և բազլեզվի մոդելների հետ: Մենք ցույց ենք տալիս, որ բնավորության հիմնված մոդելը, որը կրթություն է ստացվել NARABIZI-ի միայն 99k նախադասություններով և որն այդ լեզվի փոքր ծառի վրա պատրաստված է, հանգեցնում է նույն ճարտարապետությամբ ստացած ներկայացումներին, որոնք կրթություն են ստացվել մեծ բազլեզու Այս արդյունքները հաստատելով ֆրանսիացի օգտագործողի կողմից ստեղծված աղմկոտ պարունակության շատ ավելի մեծ տվյալների համակարգի, մենք փաստարկում ենք, որ այսպիսի բնորոշ լեզվի մոդելները կարող են լինել ՆԼՊ-ի առավելություն ցածր ռեսուրսների և բարձր լե</abstract_hy>
      <abstract_bn>এনএলপিতে সম্প্রতি বেশীরভাগ নিউরেল ভাষা মডেলের সাফল্যের ভিত্তিতে সাম্প্রতিক ভালো উন্নতি প্রদর্শন করা হয়েছে, বেশীরভাগ কয়েক ডজন হাজার উচ্চ সম্পদ ভাষা মোড- এল নির্মাণ করা হচ্ছে এবং আরও বেশি সাধারণত না স্বাভাবিক এবং নিম্ন রিসোর্স ভাষার জন্য এনএলপি সিস্টেম চ্যালেঞ্জ এই কাজে আমরা উত্তর-আফ্রিকার কলোকিয়াল ডায়ালেক্টাল আরবী ব্যবহার করে লিখেছি ল্যাটিন স্ক্রিপ্টের এক বিস্তারিত ব্যবহার করে, যার নারাবিজি নামে পাওয়া  In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models.  আমরা দেখাচ্ছি যে একটি চরিত্র ভিত্তিক মডেল নারাবাজির মাত্র ৯৯ কি শাস্তি প্রশিক্ষিত এবং এই ভাষার একটি ছোট ট ট্রাইব্যাংকে শিক্ষিত করা হয়েছে তাদের কাছে যারা একই স্থাপত্তি  এই ফলাফল নিশ্চিত করে ফ্রেঞ্চ ব্যবহারকারী উৎপাদন করা বিষয়বস্তুর বেশী বড় তথ্যের সেটে আমরা যুক্তি দিচ্ছি যে এই ধরনের অক্ষর-ভিত্তিক ভিত্তিক ভাষার মডেল কম সম</abstract_bn>
      <abstract_az>NLP'də son günlərdə təsirli düzəltmələr, çox müxtəlif nöral dil modellərinin başarısına dayanan, çox çox bir düzine yüksək ressurs dillərində göstərilmişdir. Dil mod-els inşaat və, daha çox, standartizli və düşük ressurs dillərinin NLP sistemlərini inşa etmək çətin bir işdir. Bu işdə, Şimali-Afrikanlı kolleksiyal dialektal ərəbcə NArabizi adlı Latinci skriptlərin uzaqlaşdırılmasının vasitəsilə yazılmış, çox çox sosyal media və mesajlaşma əlaqəsində bulunduq. Bu düşük kaynaqlar scenariosində verilər göstəricisi ilə yüksək dəyişiklik səviyyəsi ilə, biz, sözlərin bir parçasının etiketi və bağlılığı monodil və çoxlu dil modellərin istifadəsi ilə indirilən bir dil modelinin performansını salırıq. Biz göstəririk ki, NArabizi'nin 99k cümlələrində təhsil edilmiş və bu dilin küçük bir çöpünə təhsil edilmiş, böyük çoxlu dil və monodil modellərdə təhsil edilmiş eyni arhitektə sahib olanlara yaxınlaşdırır. Bu sonuçları təsdiqləyici Fransızca istifadəçilərin yaratdığı səsl məlumatların çox böyük məlumatlarından təsdiqləyici olaraq, biz bu karakter-tabanlı dil modelləri düşük ressurs və yüksək dil dəyişiklik quruluşlarında NLP üçün istifadə edə bilər.</abstract_az>
      <abstract_ca>Les recents millores impressionants en NLP, basades principalment en l'èxit dels models de llenguatges neurals contextuals, s'han demostrat principalment en una dotzena de llenguatges de recursos alts. Building language mod- els and, more generally, NLP systems for non- standardized and low-resource languages remains a challenging task.  En aquesta obra, ens centrem en l'àrab dialectal nord-african escrit fent servir una extensió de l'escriptura llatí anomenada NArabizi, trobada principalment en mitjans socials i comunicació de missatges. En aquest escenari de baix recursos amb la visualització de dades, amb un alt nivell de variabilitat, comparem el rendiment avall d'un model de llenguatge basat en caràcters amb etiquetes de part de la fala i la comparació de dependencia amb el de models monolingües i multilingües. Mostrem que un model basat en caràcters entrenat en només 99k frases de NArabizi i ajustad finament en un petit banc d'arbres d'aquesta llengua condueix a un rendiment prop d'aquells obtinguts amb la mateixa arquitectura, entrenat en grans models multilingües i monolingües. Confirmant aquests resultats en un conjunt de dades molt més gran de continguts sorollosos generats per l'usuari francès, argumentem que aquests models lingüístics basats en caràcters poden ser un avantatge per a NLP en conjunts de baix recursos i alta variabilitat lingüística.</abstract_ca>
      <abstract_cs>Nedávná působivá zlepšení NLP, založená na úspěchu kontextových neuronových jazykových modelů, byla většinou demonstrována na nejvýše několika desítkách jazyků s vysokými zdroji. Vytváření jazykových modulů a obecněji NLP systémů pro nestandardizované jazyky s nízkými zdroji zůstává náročným úkolem. V této práci se zabýváme severoafrickou hovorovou dialektální arabštinou psanou rozšířením latinského písma NArabizi, které se nachází převážně na sociálních médiích a komunikaci zpráv. V tomto scénáři s nízkými zdroji s daty zobrazujícími vysokou úroveň variability porovnáváme následný výkon jazykového modelu založeného na znakách při tagování části řeči a analýze závislostí s výkonem jednojjazyčných a vícejazyčných modelů. Ukazujeme, že znakový model trénovaný pouze na 99k větách NArabizi a definovaný na malém stromovém břehu tohoto jazyka vede k výkonu blízkému těm získaným se stejnou architekturou předcvičeným na velkých vícejazyčných a jednojjazyčných modelech. Potvrzením těchto výsledků na mnohem větší datové sadě hlučného francouzského uživatelského obsahu tvrdíme, že tyto znakové jazykové modely mohou být přínosem pro NLP v nízkých zdrojích a vysokých jazykových variabilitách.</abstract_cs>
      <abstract_bs>Nedavno impresivno poboljšanje NLP-a, uglavnom temeljeno na uspjehu kontekstualnih neuralnih jezičkih modela, uglavnom se pokazalo na najviše nekoliko desetina visokih jezika resursa. Izgradavanje jezičkih mod- els i, općenito, NLP sustava za nepstandardizovane i niske resurse, ostaje izazovni zadatak. U ovom poslu, mi se fokusiramo na koleksijalno dijalektno arapsko dijalektno napisano koristeći produženje latinskog skripta, nazvan NArabizi, koji se uglavnom nalazi na društvenim medijima i komunikaciji poruke. U ovom scenariju s niskim resursima s pokazivanjem podataka - visokom nivou variabilnosti, uspoređujemo niz izvođenje jezičkog model a baziranog na karakteru na dijelu govornog oznake i analizu zavisnosti s onim monojezičkim i multijezičkim modelima. Pokazujemo da model na karakteru obučen samo na 99k rečenica NArabizi i napravljen na malom krevetu ovog jezika vodi do izvođenja blizu onih koji su dobili istim arhitekturom predobučenim na velikim multijezičkim i monojezičkim modelima. Potvrđivanje tih rezultata na mnogo većem setu podataka o buknim sadržajima Francuskog korisnika, tvrdimo da takvi jezički modeli na karakteru mogu biti aktivni za NLP u setovima niskih resursa i visokih jezičkih variabilnosti.</abstract_bs>
      <abstract_et>Hiljutised muljetavaldavad uue õppekava edusammud, mis põhinevad peamiselt kontekstiliste neuraalsete keelemudelite edul, on näidatud enamasti mitme tosina suure ressursiga keele puhul. Keelemoodulite ja üldisemalt NLP-süsteemide ehitamine mittestandardsetele ja vähese ressursiga keeltele on jätkuvalt keeruline ülesanne. Käesolevas töös käsitleme Põhja-Aafrika dialektuaalset araabia keelt, mis on kirjutatud ladina skripti laiendusega NArabizi, mida leidub peamiselt sotsiaalmeedias ja sõnumitevahetuses. Selles vähese ressursi stsenaariumis, kus andmete kuvamine on suur varieeruvus, võrdleme märgipõhise keelemudeli järgnevat jõudlust kõneosa märgistamisel ja sõltuvuse parsimisel ühe- ja mitmekeelsete mudelitega. Näitame, et karakteripõhine mudel, mis on koolitatud ainult 99k NArabizi lausetel ja mis on täpsustatud selle keele väikesel puuserval, viib tulemuseni, mis on sarnane sama arhitektuuriga, mis on eelnevalt koolitatud suurte mitmekeelsete ja ühekeelsete mudelitega. Kinnitades neid tulemusi palju suurema müraka Prantsuse kasutajate loodud sisu andmekogumi kohta, väidame, et sellised märgipõhised keelemudelid võivad olla uue õppekava eeliseks vähese ressursi ja suure keelelise varieeruvusega komplektides.</abstract_et>
      <abstract_fi>NLP:n viimeaikaisia vaikuttavia parannuksia, jotka perustuvat pitkälti kontekstuaalisten neurokielimallien menestykseen, on osoitettu enimmäkseen parilla tusinalla korkean resurssin kielellä. Kielimuodojen ja yleisemmin NLP-järjestelmien rakentaminen standardittomille ja vähäresurssisille kielille on edelleen haastava tehtävä. Tässä työssä perehdytään pohjoisafrikkalaiseen dialektiseen arabiaan, joka on kirjoitettu latinalaisen kirjoituksen laajennuksella, nimeltään NArabizi, jota esiintyy pääasiassa sosiaalisessa mediassa ja viestiviestinnässä. Tässä matalan resurssin skenaariossa, jossa tietojen näyttäminen on hyvin vaihtelevaa, vertaamme merkkipohjaisen kielimallin loppupään suorituskykyä puheen osamerkintään ja riippuvuuden jäsentämiseen yksikielisiin ja monikielisiin malleihin. Osoitamme, että hahmopohjainen malli, joka on koulutettu vain 99k NArabizin lauseisiin ja hienoviritetty tämän kielen pienelle puupenkille, johtaa suorituskykyyn, joka on lähellä samaa arkkitehtuuria, joka on etukäteen koulutettu suurilla monikielisillä ja monikielisillä malleilla. Vahvistamme nämä tulokset paljon suuremmasta meluisasta ranskalaisesta käyttäjien tuottamasta sisällöstä, ja väitämme, että tällaiset merkkipohjaiset kielimallit voivat olla hyödyksi NLP:lle vähäresurssisissa ja suurissa kielivaihtelevissa kokoonpanoissa.</abstract_fi>
      <abstract_he>שיפורים מרשים לאחרונה ב-NLP, מבוססים בעיקר על הצלחה של דוגמני שפת עצבית קונטקסטיים, הוצגו בעיקר בכמה תריסר שפות משאבים גבוהים. בניית מודל- אלס שפה, ובכלל יותר, מערכות NLP לשפות לא סטנדרטיזציות ומוצאות נמוכות, נשארות משימה מאתגרת. בעבודה הזו, אנו מתמקדים בצפון-אפריקאי דיאלקטל ערבי, כתוב באמצעות התאריך של התסריט הלטיני, שנקרא נארביזי, נמצא בעיקר בתקשורת חברתית ותקשורת הודעות. בתרחיש הזה עם משאבים נמוכים עם ההצגה של נתונים - עם רמה גבוהה של שונות, אנחנו משווה את ההופעה למטה של מודל שפה מבוסס על אופים על תג חלק מהנאום ומעברת תלויות לאותו של מודלים מונושפות ומרבות שפות. אנו מראים שמודל מבוסס על אופיים מאומן רק על משפטים 99k של נארביזי ומעוצב על קצה עץ קטן של השפה הזאת מוביל להופעה קרובה לאלה שנקבלו עם אותה ארכיטקטורה מאומנת מראש על דוגמנים רבים ושונשפתיים גדולים. לאשר את התוצאות האלה על קבוצת נתונים הרבה יותר גדולה של תוכן שנוצר ע"י משתמשים צרפתיים רעש, אנחנו טוענים שמודלים שפות מבוססים על אופים כאלה יכולים להיות נכס עבור NLP בתוצאות משאבים נמוכים ומוצאות שונות שפות גבוהות.</abstract_he>
      <abstract_jv>text-tool-action Ngawe mod-el lan, sakjane ngomong, NLP sistem kanggo awak-awak dhéwé lan kelas-pengguna kuwi wis nggawe task. Nang barêng-barêng iki, kéné Fo-kucus karo dikoleksi dialectal ning-Afrika Normal Normal Normal kuwi basa gambar kuwi padha katêpakan seng Latin é, jeneng Narabisi, awak dhéwé basa sing nyebutaké ning media sothik lan komunikasi sing nggawe Nang semarani iki banget karo data Display Awak dhéwé ngerasakno karo model sing ditambah akeh caratar, dadi dipunangé awak dhéwé ning Nine kuwi mau ning acara barang nggawe barang nyong, kuwi mau ning awak dhéwé kuwi tindakan iki bakal ngelarang petani soko warisan karo sakjane perusahaan layang sampek awak dhéwé, kuwi mau banget lan sampek banget kuwi text-tool-action</abstract_jv>
      <abstract_ha>An nuna mafiya kyakkyawan improvements a cikin NLP, mainli, a kan cin nasara na misãlai na lugha na farko, ko da yawa an nuna shi a kan harshen sauri guda biyu. Yin tsarin mod-els na harshen harshen, kuma, a jumla'a, na'ura, na'urar NLP's system na waɗanda ba'a daidaita da kuma ƙasan-resource na ƙari, yana da wani aikin mai ƙayyade. Daga wannan aikin, za'a samu a kan karatun littafin littãfin Kiarabu na North-African na rubutu da aka rubuta a littafin littafin littãfin Latin, wanda aka jina Narabizi, an sãmi mafiya yawa a kan mitandaki na jamii da mawasicin messagi. Daga wannan wurin da aka ƙara-resource da data ke nuna wata daraja mai girma wa variablewa, muna samfanar da aikin ƙarami na salon da misalin harshen na rubutu kan rabon-part tagning da kuma masu inganci ga parse zuwa da wasu misãlai na monoli da multilala. Tuna nũna cewa wani misali wanda aka yi wa karatun a kan salon karatun na Narabizi ne 99k kawai kuma aka yi finjãwa a kan wani sauri mai ƙarami na lugha wannan lugha, yana ƙaranci ga waɗanda aka sãmu da shi sami matsayin da aka tsare shi a kan misãlai masu yawa na multilala da monoli-lugha. Ina gaskata waɗannan matsalar a kan data masu girma da aka daidaita kayan aiki na faransa da wanda aka haife shi, za'a yi musu jãyayya cewa, misãlai masu yin rubutun da ke rubutun, za'a iya zama ma'auni ga NLP cikin ƙan an an-resource da kuma an daidaita variabilin harshen sarrafiya.</abstract_ha>
      <abstract_sk>Nedavne impresivne izboljšave NLP, ki temeljijo predvsem na uspehu kontekstualnih nevronskih jezikovnih modelov, so bile večinoma dokazane na največ nekaj ducatih jezikih z visokimi viri. Izgradnja jezikovnih modulov in splošneje sistemov NLP za nestandardizirane jezike in jezike z nizkimi viri ostaja zahtevna naloga. V tem delu se osredotočamo na severnoafriško kolokvično dialektualno arabščino, napisano z razširitvijo latinske pisave NArabizi, ki jo najdemo predvsem na družbenih medijih in sporočilnih komunikacijah. V tem scenariju z nizkimi viri prikazovanja podatkov z visoko stopnjo variabilnosti primerjamo učinkovitost znakov temelječega jezikovnega modela pri označevanju dela govora in razčlenitvi odvisnosti z učinkovitostjo enojezičnih in večjezičnih modelov. Pokazali smo, da model, ki temelji na značaju, usposobljen na samo 99k stavkih NArabiškega jezika in natančno nastavljen na majhni drevesni plošči tega jezika, vodi do nastopa blizu tistim, pridobljenim z isto arhitekturo, predhodno usposobljen na velikih večjezičnih in enojezičnih modelih. Ker potrjujemo te rezultate o mnogo večjem naboru podatkov hrupnih francoskih uporabnikov ustvarjenih vsebin, trdimo, da so takšni jezikovni modeli na podlagi znakov lahko prednost za NLP v naboru nizkih virov in visoke jezikovne variabilnosti.</abstract_sk>
      <abstract_bo>NLP ནང སྐད་རིགས་mod-els་དང་བསྟུན་ནས་བཟོ་བཅོས་ནུས་མེད་པའི་སྐད་རིགས་ལ་NLP མ་གནས་སྟངས་དང་ཐོག་ཁུངས་ཀྱི་སྐད In this work, we fo- cus on North-African colloquial dialectal Arabic written using an extension of the Latin script, called NArabizi, found mostly on social media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on part-of-speech tagging and dependency parsing to that of monolingual and multilingual models. ང་ཚོའི་ཁྱད་ཆོས་ཀྱི་མིག་གཟུགས་གཅིག་ལ་སྨྱུག་བའི་རྣམ་པ་ཞིག་གིས་NArabizi(NArabizi)ཡི་གནད་སྡུད་99k གནད་ཅིག་དང་སྐད་རིགས་ཆུང་ཀྱི་བཀྲམ་སྒྲིག་ཅིག་ནང་གི་སྒྲིག་ འོན་ཀྱང་། རྩིས་འབྲས་འདི་དག་གི་དབྱེ་བ་སྤྱོད་མཁན་གྱི་ནང་དོན་མང་ཆེ་བའི་ཚད་གཞི་བརྟན་ཏེ།</abstract_bo>
      </paper>
    <paper id="48">
      <title>Something Something Hota Hai ! An Explainable Approach towards <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">Sentiment Analysis</a> on Indian Code-Mixed Data<fixed-case>I</fixed-case>ndian Code-Mixed Data</title>
      <author><first>Aman</first><last>Priyanshu</last></author>
      <author><first>Aleti</first><last>Vardhan</last></author>
      <author><first>Sudarshan</first><last>Sivakumar</last></author>
      <author><first>Supriti</first><last>Vijay</last></author>
      <author><first>Nipuna</first><last>Chhabra</last></author>
      <pages>437–444</pages>
      <abstract>The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data. Sentiment analysis of this <a href="https://en.wikipedia.org/wiki/Data">data</a> can provide integral insights into people’s perspectives and opinions. Code-mixed data is often noisy in nature due to multiple spellings for the same word, lack of definite order of words in a sentence, and random abbreviations. Thus, working with code-mixed data is more challenging than monolingual data. Interpreting a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s predictions allows us to determine the <a href="https://en.wikipedia.org/wiki/Robust_statistics">robustness</a> of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> against different forms of <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a>. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to integrate explainable approaches into code-mixed sentiment analysis. By interpreting the predictions of <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis models</a> we evaluate how well the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to adapt to the implicit noises present in code-mixed data.</abstract>
      <url hash="8350c695">2021.wnut-1.48</url>
      <bibkey>priyanshu-etal-2021-something</bibkey>
      <doi>10.18653/v1/2021.wnut-1.48</doi>
    <title_es>«¡Algo Algo Hota Hai!» Un enfoque explicable para el análisis de sentimientos en datos mixtos de códigos indios</title_es>
      <title_fr>« Quelque chose Hota Hai ! » Une approche explicable de l'analyse du sentiment sur des données mixtes de code indien</title_fr>
      <title_ar>"شيء ما هوتا هاي!" نهج قابل للتفسير نحو تحليل المشاعر على البيانات الهندية المختلطة كود</title_ar>
      <title_pt>“Algo Algo Hota Hai!” Uma abordagem explicável para a análise de sentimentos em dados mistos de código indiano</title_pt>
      <title_ja>「何かホタハイ！ ”インドのコードミックスデータに対するセンチメント分析への説明可能なアプローチ</title_ja>
      <title_zh>"某事何物! 印度代码合数情析之可解也</title_zh>
      <title_hi>"कुछ कुछ होता है! भारतीय कोड-मिश्रित डेटा पर भावना विश्लेषण के प्रति एक स्पष्ट दृष्टिकोण</title_hi>
      <title_ru>«Что-то Хота Хай!« Объяснимый подход к анализу настроений на основе смешанных данных индийского кодекса</title_ru>
      <title_ga>“Rud éigin Hota Hai!” Cur Chuige Inmhínithe i dtreo Anailís Mothúcháin ar Shonraí Cód-Mheasctha Indiach</title_ga>
      <title_ka>'ნვღჲ ნვღჲ ჳჲრა ჳვი!' Name</title_ka>
      <title_el>"Κάτι καυτό Hai!" Μια επεξηγημένη προσέγγιση για την ανάλυση συναισθημάτων σε δεδομένα μικτού κώδικα Ινδίας</title_el>
      <title_it>"Qualcosa di Hota Hai!" Un approccio spiegabile verso l'analisi dei sentimenti sui dati misti indiani</title_it>
      <title_mk>"Нешто нешто жешко Хаи!" Објаснувачки пристап кон анализа на чувствата на индиски код- мешани податоци</title_mk>
      <title_lt>"Kažkas kažkas karšto Hai!" Paaiškinamas požiūris į Indijos kodų mišrių duomenų jautrumo analizę</title_lt>
      <title_hu>Valami Hota Hai! Magyarázható megközelítés az indiai kódolt adatokon alapuló érzelmek elemzésére</title_hu>
      <title_ms>'Sesuatu Sesuatu Hota Hai!' An Explainable Approach towards Sentiment Analysis on Indian Code-Mixed Data</title_ms>
      <title_kk>"Қата Хай бір нәрсе"! Индиялық код араластырылған деректерінің Sentiment анализациясының түсінікті жағдайыName</title_kk>
      <title_ml>എന്തോ ഹോട്ട ഹായ്! ഇന്ത്യന്‍ കോഡ്- മിക്സഡ് ഡേറ്റായിലേക്കു് സെന്റിമെന്റ് അന്വേഷണത്തിലേക്കു് വ്യക്തമാക്കാവുന്ന ഒരു</title_ml>
      <title_mt>"Xi ħaġa Xi ħaġa Hota Hai!" Approċċ Spjegabbli lejn Analiżi tas-Sentiment dwar Data mħallta bil-Kodiċi Indjan</title_mt>
      <title_mn>"Хота Хай нэг зүйл!" Энэтхэгийн код-холбогдсон өгөгдлийн Sentiment Analysis-ын тухай тодорхойлолтой ойлголт</title_mn>
      <title_ro>"Ceva Hota Hai!" O abordare explicabilă a analizei sentimentelor pe baza datelor mixte de coduri indiene</title_ro>
      <title_no>"Noe noko Hota Hai!" Name</title_no>
      <title_pl>"Coś gorącego Hai!" Wyjaśnione podejście do analizy sentymentów na indyjskich danych kodowych</title_pl>
      <title_so>wax walbo Hota Hai! Kaalmada Caddayn ee Sentiment Analysis on Indian Code-Mixed Data</title_so>
      <title_sv>"Någonting Hota Hai!" En förklarande metod för sentimentalanalys på indiska kodblandade data</title_sv>
      <title_ta>'Hota Hai ஏதாவது' Name</title_ta>
      <title_ur>'Something Hota Hai!' Name</title_ur>
      <title_sr>Nešto Hota Hai! Objašnjivi pristup analiziranju sentimenta o indijskim kodovima</title_sr>
      <title_si>'හොටා හායි දෙයක්!' Name</title_si>
      <title_vi>"Cái gì đó nóng hổi." Giải thích phương pháp phân tích tình cảm trên dữ liệu hoà trộn da đỏ</title_vi>
      <title_uz>'Hota Hai biror narsa! ' Name</title_uz>
      <title_nl>'Iets Hota Hai!' Een uitlegbare benadering van sentimentanalyse op Indiase code-gemengde data</title_nl>
      <title_bg>"Нещо Нещо Хота Хай!" Обясняем подход към анализа на чувствата върху индийските кодови смесени данни</title_bg>
      <title_da>"Noget Hota Hai!" En forklarelig metode til følelsesanalyse på indiske kodeblandede data</title_da>
      <title_hr>Nešto Hota Hai! Objašnjivi pristup prema sentimentnoj analizi o indijskim mješanim podacima</title_hr>
      <title_ko>"뭐야, 뭐야!"인도 코드 혼합 데이터 정서 분석의 해석 가능한 방법</title_ko>
      <title_de>"Etwas Hota Hai!" Ein erklärbarer Ansatz zur Sentimentanalyse auf indischen Code-Mixed Daten</title_de>
      <title_id>'Something Something Hota Hai!'  An Explainable Approach towards Sentiment Analysis on Indian Code-Mixed Data</title_id>
      <title_tr>"Hota Hai birzat!" Hindistan Kod Karıştırılýan Maglumaty Sentiment Analizisine Görünüşe Birleşik Girişi</title_tr>
      <title_af>"Iets iets Hota Hai!" Name</title_af>
      <title_fa>يه چيزي هوتا هايي Name</title_fa>
      <title_sw>'Kuna kitu cha Hota Hai!' Maelezo yanayoelezea kuelekea Uchambuzi wa Taarifa za Mijingo ya Uhindi</title_sw>
      <title_hy>"Ինչ-որ բան, ինչ-որ տաք Հա"։ Հնդկաստանի կոդի խառնված տվյալների զգացմունքների վերլուծության համար բացատրելի մոտեցում</title_hy>
      <title_sq>'Something Something Hota Hai!'  Një metodë e shpjegueshme drejt analizës së ndjenjave mbi të dhënat e përziera me kod indian</title_sq>
      <title_az>"Hota Hai bir şey!" Hindistan Kodu Karıştırılmış Veriləri barəsində Sentiment Analizi üçün Açılabilir Yaxınlıq</title_az>
      <title_am>'Hota Hai አንዳች ነገር!' ፋይል sን መክፈት አልቻለም፦ %s፦ %s</title_am>
      <title_bs>Nešto Hota Hai! Objašnjiv pristup prema analizi sentimenta o indijskim kodovima pomiješanim podacima</title_bs>
      <title_bn>'হোটা হাই কিছু কিছু! ' ভারতীয় কোড-মিক্স ডাটা</title_bn>
      <title_fi>"Jotain Hota Hai!" Selitettävä lähestymistapa Intian koodisekoitettujen tietojen tunteiden analysointiin</title_fi>
      <title_cs>Něco sexy Hai! Vysvětlitelný přístup k analýze sentimentů na indických kódových datech</title_cs>
      <title_et>"Midagi midagi Hota Hai!" Selgitatav lähenemisviis India koodisegaandmete tunnete analüüsile</title_et>
      <title_ca>"Alguna cosa calorosa!" Un enfocament explicable cap a l'anàlisi de sentiments sobre les dades combinades amb codi Índic</title_ca>
      <title_jv>'Rahi kelas pirang mas Hota Hai !' Name</title_jv>
      <title_sk>"Nekaj nekaj Hota Hai!" Razložljiv pristop k analizi čustev o indijskih mešanih kodeksih podatkov</title_sk>
      <title_ha>"Babu wani abu ya Hota hai!" KCharselect unicode block name</title_ha>
      <title_he>"משהו משהו חם הי!" גישה מוסברת לכיוון ניתוח רגשות על נתונים מעורבים קודים אינדיאניים</title_he>
      <title_bo>'嬋㏅스善뗠숯嬋꿋펻嬋㏅스善뗠퐯善뗠퐨嬋꾝펻嬋섁퐠嬋섁펻嬋묂슈善뗠퐛嬋꿋펻嬋왽쉿嬋귖펻嬋□쉿嬋볙펾' 嬋№풎宣긍펻嬋귖숱善뗠퐘宣긍쉿善뗠퐠嬋뷕퐪善뗠퐗善뗠쉐宣녀펻嬋뽤쉐宣꿋스善뗠퐭嬋졷쉿善뗠퐜善뗠퐷嬋뺖쓰嬋꿋퐪善뗠숯嬋꿋퐘善뗠퐜善뗠숲宣잀숱善뗠퐘嬋뤲슨嬋꾝펻嬋뽤퐷嬋꿋펻Approach</title_bo>
      <abstract_fr>L'utilisation croissante des sites de médias sociaux dans des pays comme l'Inde a donné lieu à d'importants volumes de données mixtes de codes. L'analyse des sentiments de ces données peut fournir des informations complètes sur les points de vue et les opinions des personnes. Les données de code mixte sont souvent bruyantes en raison de l'orthographe multiple d'un même mot, de l'absence d'ordre défini des mots dans une phrase et d'abréviations aléatoires. Il est donc plus difficile de travailler avec des données mixtes de code que des données monolingues. L'interprétation des prévisions d'un modèle nous permet de déterminer la robustesse du modèle par rapport aux différentes formes de bruit. Dans cet article, nous proposons une méthodologie pour intégrer des approches explicables dans l'analyse des sentiments à code mixte. En interprétant les prévisions des modèles d'analyse de sentiment, nous évaluons la capacité du modèle à s'adapter aux bruits implicites présents dans les données mixtes de code.</abstract_fr>
      <abstract_es>El uso cada vez mayor de los sitios de redes sociales en países como la India ha dado lugar a grandes volúmenes de datos de código mixto. El análisis de sentimientos de estos datos puede proporcionar información integral sobre las perspectivas y opiniones de las personas. Los datos de código mixto suelen ser ruidosos por naturaleza debido a la ortografía múltiple de la misma palabra, la falta de un orden definido de las palabras en una oración y las abreviaturas aleatorias. Por lo tanto, trabajar con datos de código mixto es más difícil que con datos monolingües. La interpretación de las predicciones de un modelo nos permite determinar la robustez del modelo frente a diferentes formas de ruido. En este artículo, proponemos una metodología para integrar enfoques explicables en el análisis de sentimientos de código mixto. Al interpretar las predicciones de los modelos de análisis de sentimientos, evaluamos qué tan bien el modelo es capaz de adaptarse a los ruidos implícitos presentes en los datos de código mixto.</abstract_es>
      <abstract_pt>O uso crescente de sites de mídia social em países como a Índia deu origem a grandes volumes de dados mistos de código. A análise de sentimentos desses dados pode fornecer insights integrais sobre as perspectivas e opiniões das pessoas. Os dados mistos de código geralmente são barulhentos por natureza devido a várias grafias para a mesma palavra, falta de ordem definida das palavras em uma frase e abreviações aleatórias. Assim, trabalhar com dados de código misto é mais desafiador do que com dados monolíngues. Interpretar as previsões de um modelo nos permite determinar a robustez do modelo contra diferentes formas de ruído. Neste artigo, propomos uma metodologia para integrar abordagens explicáveis na análise de sentimentos mistos. Ao interpretar as previsões dos modelos de análise de sentimentos, avaliamos o quão bem o modelo é capaz de se adaptar aos ruídos implícitos presentes nos dados mistos de código.</abstract_pt>
      <abstract_ar>أدى الاستخدام المتزايد لمواقع التواصل الاجتماعي في بلدان مثل الهند إلى ظهور كميات كبيرة من البيانات المختلطة بالشفرات. يمكن أن يوفر تحليل المشاعر لهذه البيانات رؤى متكاملة لوجهات نظر الناس وآرائهم. غالبًا ما تكون البيانات المختلطة بالشفرات صاخبة بطبيعتها بسبب تعدد الهجاء للكلمة نفسها ، وعدم وجود ترتيب محدد للكلمات في الجملة ، والاختصارات العشوائية. وبالتالي ، فإن العمل مع البيانات المختلطة بالشفرات يعد أكثر صعوبة من البيانات أحادية اللغة. يسمح لنا تفسير تنبؤات النموذج بتحديد متانة النموذج في مواجهة أشكال الضوضاء المختلفة. في هذه الورقة ، نقترح منهجية لدمج الأساليب القابلة للتفسير في تحليل المشاعر المختلطة بالشفرة. من خلال تفسير تنبؤات نماذج تحليل المشاعر ، نقوم بتقييم مدى قدرة النموذج على التكيف مع الضوضاء الضمنية الموجودة في البيانات المختلطة بالكود.</abstract_ar>
      <abstract_ja>インドのような国々では、ソーシャルメディアサイトの利用が増えているため、大量のコードミックスデータが発生しています。このデータの感情分析は、人々の視点と意見を統合的に理解することができます。コードミックスされたデータは、同じ単語の複数のスペル、文章内の単語の確実な順序の欠如、およびランダムな略語のために、しばしば騒々しい性質を持っています。したがって、コード混合データを使用することは、単一言語データよりも困難です。モデルの予測を解釈することで、異なる形式のノイズに対するモデルの堅牢性を決定することができます。本稿では，コード混合感情分析に説明可能なアプローチを統合する方法論を提案する．感情分析モデルの予測を解釈することで、モデルがコード混合データに存在する暗黙のノイズにどの程度適応できるかを評価します。</abstract_ja>
      <abstract_hi>भारत जैसे देशों में सोशल मीडिया साइट्स के बढ़ते उपयोग ने बड़ी मात्रा में कोड-मिश्रित डेटा को जन्म दिया है। इस डेटा का भावना विश्लेषण लोगों के दृष्टिकोण और राय में अभिन्न अंतर्दृष्टि प्रदान कर सकता है। कोड-मिश्रित डेटा अक्सर एक ही शब्द के लिए कई वर्तनी, एक वाक्य में शब्दों के निश्चित क्रम की कमी और यादृच्छिक संक्षेप के कारण प्रकृति में शोर होता है। इस प्रकार, कोड-मिश्रित डेटा के साथ काम करना मोनोलिंगुअल डेटा की तुलना में अधिक चुनौतीपूर्ण है। एक मॉडल की भविष्यवाणियों की व्याख्या करने से हमें शोर के विभिन्न रूपों के खिलाफ मॉडल की मजबूती निर्धारित करने की अनुमति मिलती है। इस पेपर में, हम कोड-मिश्रित भावना विश्लेषण में व्याख्यायोग्य दृष्टिकोण को एकीकृत करने के लिए एक पद्धति का प्रस्ताव करते हैं। भावना विश्लेषण मॉडल की भविष्यवाणियों की व्याख्या करके हम मूल्यांकन करते हैं कि मॉडल कोड-मिश्रित डेटा में मौजूद अंतर्निहित शोर के अनुकूल होने में कितनी अच्छी तरह सक्षम है।</abstract_hi>
      <abstract_ru>Все более широкое использование сайтов социальных сетей в таких странах, как Индия, привело к появлению больших объемов смешанных кодов данных. Сентиментальный анализ этих данных может дать целостное представление о взглядах и мнениях людей. Смешанные с кодом данные часто являются шумными по своей природе из-за множественного написания одного и того же слова, отсутствия определенного порядка слов в предложении и случайных сокращений. Таким образом, работать со смешанными кодовыми данными сложнее, чем с одноязычными данными. Интерпретация прогнозов модели позволяет определить устойчивость модели к различным формам шума. В этой статье мы предлагаем методологию интеграции объяснимых подходов в анализ смешанных кодов. Интерпретируя прогнозы моделей анализа настроений, мы оцениваем, насколько хорошо модель способна адаптироваться к неявным помехам, присутствующим в смешанных данных кода.</abstract_ru>
      <abstract_zh>在印度诸国,社交媒体网站用益多,催生大代码混合数据。 凡此数者,可以备见说之体。 同单词数拼写,句少单词明次及随机缩写,代码混数本常嘈杂。 故用代码混合比单语数更具挑战性。 说模之占,使吾能定其噪声之鲁棒性。 于本文中,发一将可解释之法集成到代码混合情析之法。 以说情分析模型之占,评模适代码合数之隐式噪声。</abstract_zh>
      <abstract_ga>Tá líon mór sonraí cód-mheasctha mar thoradh ar úsáid mhéadaithe láithreán meán sóisialta i dtíortha mar an India. Is féidir le hanailís meon ar na sonraí seo léargais dhílis a sholáthar ar dhearcthaí agus ar thuairimí daoine. Is minic a bhíonn sonraí cód-mheasctha torannach i nádúr mar gheall ar litriú iolrach don fhocal céanna, easpa ord cinnte focal in abairt, agus giorrúcháin randamacha. Mar sin, tá sé níos dúshlánaí oibriú le sonraí cód-mheasctha ná sonraí aonteangacha. Trí thuar na samhla a léirmhíniú, is féidir linn stóinseacht an mhúnla i gcoinne cineálacha éagsúla torainn a chinneadh. Sa pháipéar seo, molaimid modheolaíocht chun cineálacha cur chuige inmhínithe a chomhtháthú le hanailís ar mheon cód-mheasctha. Trí léirmhíniú a dhéanamh ar shamhlacha anailíse meon a thuar déanaimid measúnú ar cé chomh maith agus atá an tsamhail in ann oiriúnú do na torainn intuigthe atá i sonraí cód-mheasctha.</abstract_ga>
      <abstract_ka>სოციალური მედია საზოგადოებების გამოყენება, როგორც ინდოეთის ქვეყნებში, უფრო დიდი მონაცემების შესაძლებელობა. ამ მონაცემების შეცდომა ანალიზი შეიძლება ადამიანის პეროვკუტირების და მიხედვილების შესაძლებელი ინტერგულური მიხედვის. Name ამიტომ, მუშაობა კოდის შესაბამისი მონაცემებით უფრო შესაბამისია, ვიდრე მონოლენგური მონაცემებით. მოდელის წინტერპორტირება მოდის, რომ ჩვენ მოდელის ძალიან ძალიან განსაზღვრებას განსხვავებული ფორმების ძალიან. ჩვენ ამ წიგნის შესაძლებელია მეტიოლოგია, რომელიც კოდენტიმენტის ანალიზაციაში გააკეთება შესაძლებელი გააკეთება. სენტიმენტის ანალიზის მოდელების წარმოდგენების გამოყენებით ჩვენ გავაკეთებთ რამდენი კარგი მოდელეც შეუძლია აპექტირება ინფლიციტური ბუნებისთვის, რომლებიც კოდის შე</abstract_ka>
      <abstract_el>Η αυξανόμενη χρήση ιστοσελίδων κοινωνικής δικτύωσης σε χώρες όπως η Ινδία έχει προκαλέσει μεγάλους όγκους δεδομένων μικτού κώδικα. Η ανάλυση συναισθημάτων αυτών των δεδομένων μπορεί να παρέχει ολοκληρωμένες πληροφορίες σχετικά με τις προοπτικές και τις απόψεις των ανθρώπων. Τα δεδομένα μικτού κώδικα είναι συχνά θορυβώδη λόγω πολλαπλών ορθογραφικών χαρακτήρων για την ίδια λέξη, έλλειψης καθορισμένης σειράς λέξεων σε μια πρόταση και τυχαίων συντομεύσεων. Έτσι, η εργασία με δεδομένα μικτού κώδικα είναι πιο δύσκολη από τα μονογλωσσικά δεδομένα. Η ερμηνεία των προβλέψεων ενός μοντέλου μας επιτρέπει να προσδιορίσουμε την ανθεκτικότητα του μοντέλου έναντι διαφορετικών μορφών θορύβου. Στην παρούσα εργασία, προτείνουμε μια μεθοδολογία για την ενσωμάτωση επεξηγηματικών προσεγγίσεων στην ανάλυση κωδικών-μικτών συναισθημάτων. Με την ερμηνεία των προβλέψεων των μοντέλων ανάλυσης συναισθημάτων αξιολογούμε πόσο καλά το μοντέλο είναι σε θέση να προσαρμοστεί στους έμμεσους θορύβους που υπάρχουν σε δεδομένα μικτού κώδικα.</abstract_el>
      <abstract_kk>Үндістан секілді елдерде социалдық медиа сайттарының қолдануын көптеген көптеген код араластырылған деректерді көптеген. Бұл деректердің сентиметті анализиясы адамдардың қарағандарына және түсініктеріне тұрақтық түсініктерді бере алады. Код араластырылған деректері бір сөздің бірнеше емлелелеріне көбірек дыбыс, сөздердің анықтамаған реті жоқ және кездейсоқ қысқартуларына көбірек болады. Сонымен, код араластырылған деректермен жұмыс істеу монолингі деректерінен артық. Үлгінің таңдау үлгісін түрлі дыбыс түрлеріне қарсы құндылығын анықтауға мүмкіндік береді. Бұл қағазда, код араластырылған сезімдердің анализациясына түсінікті жағдайларын біріктіруге арналған методология ұсындық. Сөздерді анализ үлгілерін түсіндіру арқылы, үлгісін код араластырылған деректерде қанша жақсы қолдануға мүмкіндік бере алатын дыбыстарды түсіндіреміз.</abstract_kk>
      <abstract_hu>A közösségi média oldalak növekvő használata olyan országokban, mint India, nagy mennyiségű kódkeverék adatot eredményezett. Ezen adatok érzelmi elemzése integrált betekintést nyújthat az emberek nézőpontjába és véleményébe. A kódkeverék adatok gyakran zajos jellegűek ugyanazon szó többszörös helyesírása, egy mondat határozott sorrendjének hiánya és véletlenszerű rövidítések miatt. Így a kódokkal kevert adatokkal való munka nagyobb kihívást jelent, mint az egynyelvű adatok. Egy modell előrejelzéseinek értelmezése lehetővé teszi számunkra, hogy meghatározzuk a modell robusztusságát a zaj különböző formáival szemben. Jelen tanulmányban olyan módszertant javasolunk, amely magyarázható megközelítéseket integrál a kódkevert érzelmek elemzésébe. Az érzelmi elemzési modellek előrejelzéseinek értelmezésével értékeljük, hogy a modell mennyire képes alkalmazkodni a kódkevert adatokban jelen lévő implicit zajokhoz.</abstract_hu>
      <abstract_it>Il crescente utilizzo di siti di social media in paesi come l'India ha dato luogo a grandi volumi di dati codificati. L'analisi sentimentale di questi dati può fornire approfondimenti integrali sulle prospettive e le opinioni delle persone. I dati misti in codice sono spesso rumorosi a causa di più ortografie per la stessa parola, mancanza di ordine definito di parole in una frase e abbreviazioni casuali. Pertanto, lavorare con dati misti in codice è più difficile dei dati monolingue. Interpretare le previsioni di un modello ci permette di determinare la robustezza del modello rispetto a diverse forme di rumore. In questo articolo, proponiamo una metodologia per integrare approcci spiegabili nell'analisi del sentiment code-mixed. Interpretando le previsioni dei modelli di sentiment analysis valutiamo quanto bene il modello sia in grado di adattarsi ai rumori impliciti presenti nei dati code-mixed.</abstract_it>
      <abstract_lt>Vis dažniau naudojamos social in ės žiniasklaidos svetainės tokiose šalyse kaip Indija sukėldaug kodų mišrių duomenų. Sentiment analysis of this data can provide integral insights into people's perspectives and opinions.  Kodų mišrūs duomenys dažnai triukšmingi dėl daugelio to paties žodžio raidžių, aiškios žodžių eilės trūkumo sakinyje ir atsitiktinių santrumpų. Taigi bendradarbiauti su mišriais kodais duomenimis yra sudėtingesnis nei vienakalbiai duomenys. Modelio prognozių aiškinimas leidžia nustatyti modelio patikimumą įvairių triukšmo formų atžvilgiu. Šiame dokumente siūlome metodiką, pagal kurią paaiškinami metodai būtų integruojami į kodų mišrių sentiment ų analizę. Vertindami sentiment ų analizės modelių prognozes, vertiname, kaip gerai model is gali prisitaikyti prie netiesioginių triukšmų, esančių mišriuose koduose duomenise.</abstract_lt>
      <abstract_ms>Penggunaan semakin meningkat laman media sosial di negara-negara seperti India telah menyebabkan volum besar data campuran kod. Analisis perasaan data ini boleh memberikan pandangan integral kepada perspektif dan pendapat orang. Data campuran-kod sering bunyi dalam sifat disebabkan ejaan berbilang untuk perkataan yang sama, kekurangan tertib tertentu perkataan dalam kalimat, dan singkatan rawak. Jadi, bekerja dengan data campuran-kod lebih mencabar daripada data monobahasa. Menjelaskan ramalan model membolehkan kita menentukan kekuatan model melawan bentuk bunyi yang berbeza. Dalam kertas ini, kami cadangkan metodologi untuk mengintegrasikan pendekatan yang boleh dijelaskan ke dalam analisis perasaan-campuran kod. Dengan menerangkan ramalan model analisis perasaan, kita menilai betapa baik model boleh menyesuaikan dengan bunyi implicit yang ada dalam data campuran kod.</abstract_ms>
      <abstract_mk>Зголемената употреба на сајтовите на социјалните медиуми во земји како Индија предизвика голем број мешани податоци. Анализата на чувствата на овие податоци може да обезбеди интегрален поглед на перспективите и мислењата на луѓето. Податоците кои се мешани со кодот честопати се бучни во природата поради многуте правописи за истиот збор, недостаток на дефинитивен ред на зборови во реченица и случајни кратенија. Затоа, работата со кодови-мешани податоци е поважна од монојазичните податоци. Интерпретирањето на предвидувањата на моделот ни овозможува да ја одредиме силноста на моделот против различни форми на бучава. Во овој документ предложуваме методологија за интеграција на објаснливите пристапи во анализа на мешаните сентименти. Со интерпретација на предвидувањата на моделите на анализа на чувствата ние проценуваме колку добро моделот може да се адаптира на имплицитните звуци присутни во кодовите мешани податоци.</abstract_mk>
      <abstract_ml>The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data.  ഈ വിവരങ്ങളുടെ വിശദീകരണങ്ങള്‍ ആളുകളുടെ കാഴ്ചകളിലും അഭിപ്രായങ്ങളിലും ഉള്‍ക്കൊള്ളാന്‍ സാധിക്കും. ഒരേ വാക്കിനുള്ള പല വാക്കുകള്‍ കാരണം, വാക്കില്‍ നിര്‍ണ്ണയിക്കുന്ന വാക്കുകളുടെ കാര്യത്തില്‍ വ്യക്തിപരമായ ക്രമീകരിക്കുന്നില്ല അതുകൊണ്ട്, കോഡ് മിഷ്ടപ്പെട്ട ഡേറ്റായി പ്രവര്‍ത്തിക്കുന്നത് മോനോളില്‍ ഭാഷ വിവരങ്ങളെക്കാള്‍ വി ഒരു മോഡലിന്റെ പ്രവചനങ്ങളെ വിശദീകരിക്കാന്‍ ഞങ്ങള്‍ക്ക് അനുവദിക്കുന്നു വ്യത്യസ്ത തരം ശബ്ദങ്ങള്‍ക്കെതിരായി മോഡലി In this paper, we propose a methodology to integrate explainable approaches into code-mixed sentiment analysis.  നിരീക്ഷണത്തിന്റെ അന്വേഷണ മോഡലുകളുടെ പ്രവചനങ്ങള്‍ വ്യക്തമാക്കുന്നതിനാല്‍ മോഡല്‍ എത്ര നന്നായി മാറ്റാന്‍ സാധിക്കുന്നു</abstract_ml>
      <abstract_mn>Энэтхэг шиг улс орнуудад нийгмийн хэвлэлийн сайтуудын хэрэглээ ихэвчлэн ихэвчлэн код холбогдсон өгөгдлийн хэмжээг нэмэгдүүлсэн. Эдгээр мэдээллийн мэдээллийн сэтгэл санал нь хүмүүсийн үзэл, ойлголтын тухай бүрэн ойлголт гаргаж чадна. Код холбогдсон өгөгдлийн санаа нь ихэвчлэн ихэвчлэн ихэвчлэн ихэвчлэн нэг үг үгсийн шалтгаан, үгсийн тодорхойлолт, санамсаргүй тодорхойлолтуудын шалтгаан байдаг. Иймээс код холбогдсон өгөгдлийн талаар ажиллах нь нэг хэл өгөгдлийн талаас илүү хэцүү. Загварын таамаглалыг илэрхийлэх нь бидэнд өөр чимээгүй хэлбэртэй загварын чадварыг тодорхойлох боломжтой. Энэ цаасан дээр бид код холбогдсон сэтгэл хөдлөлийн шинжилгээнд тайлбарлах боломжтой аргыг нэгтгэх методологийг санал өгдөг. Боловсролын шинжилгээний загварын тодорхойлолтоор бид загварыг код холбогдсон мэдээллээр хэр сайн загварчлах боломжтой вэ гэдгийг үнэлдэг.</abstract_mn>
      <abstract_no>Den økte bruken av sosiale medianettstader i landene som India har oppgitt stor volum med kodeflekse data. Sentiment analyse av denne dataen kan gje integrale innsyningar i perspektiv og meningar til folk. Kodeflikte data er ofte støy i natur på grunn av fleire stavingar for det same ordet, manglar definitivt ordrekkefølgje i eit setning og tilfeldige forkortingar. Dette er derfor det mest vanskeleg å arbeide med kode-blandede data enn monospråk-data. Omsetjinga av eit modell foregår oss å bestemme styrken på modellen mot ulike form av støy. I denne papiret foreslår vi ein metodologi for å integrere forklarbare tilnærmingar i kodefeksa sentimentanalyse. Ved å tolka forhåndsvisingane av sentimentanalysemodeller, evaluerer vi kor godt modellen kan tilpassa til dei implisitte støyane som finst i kodefekserte data.</abstract_no>
      <abstract_mt>L-użu dejjem jikber tas-siti tal-midja soċjali f’pajjiżi bħall-Indja wassal għal volumi kbar ta’ dejta mħallta bil-kodiċi. Analiżi tas-sensazzjoni ta’ din id-dejta tista’ tipprovdi fehmiet integrali fil-perspettivi u l-opinjonijiet tan-nies. Dejta mħallta mal-kodiċi ta’ spiss hija storbjuża fin-natura minħabba ortografiji multipli għall-istess kelma, nuqqas ta’ ordni definita ta’ kliem f’sentenza, u taqsiriet aleatorji. Għalhekk, il-ħidma b’dejta mħallta bil-kodiċi hija aktar ta’ sfida minn dejta monolingwistika. Interpreting a model's predictions allows us to determine the robustness of the model against different forms of noise.  F’dan id-dokument, qed nipproponu metodoloġija biex jintegraw approċċi spjegabbli fl-analiżi tas-sentimenti mħallta tal-kodiċi. Permezz tal-interpretazzjoni tal-previżjonijiet tal-mudelli tal-analiżi tas-sentimenti, jivvalutaw kemm il-mudell huwa kapaċi jadatta tajjeb għall-istorbji impliċiti preżenti fid-dejta mħallta bil-kodiċi.</abstract_mt>
      <abstract_pl>Coraz większe korzystanie z serwisów społecznościowych w krajach takich jak Indie doprowadziło do powstania dużych ilości danych z kodem mieszanym. Analiza sentymentów tych danych może zapewnić integralny wgląd w perspektywy i opinie ludzi. Dane mieszane w kodzie są często hałaśliwe ze względu na wiele pisowni dla tego samego słowa, brak określonej kolejności słów w zdaniu i losowe skróty. Dlatego praca z danymi mieszanymi kodem jest większym wyzwaniem niż dane jednojęzyczne. Interpretacja przewidywań modelu pozwala nam określić solidność modelu w stosunku do różnych form hałasu. W niniejszym artykule proponujemy metodologię integracji wyjaśnionych podejść do analizy sentymentów kodowo-mieszanych. Interpretując prognozy modeli analizy sentymentów oceniamy, jak dobrze model jest w stanie dostosować się do szumów domyślnych obecnych w danych mieszanych kodem.</abstract_pl>
      <abstract_ro>Utilizarea tot mai mare a site-urilor de social media în țări precum India a dat naștere la volume mari de date combinate de coduri. Analiza sentimentelor acestor date poate oferi perspective integrale asupra perspectivelor și opiniilor oamenilor. Datele combinate de coduri sunt adesea zgomotoase în natură datorită ortografiilor multiple pentru același cuvânt, lipsei ordinii definite a cuvintelor într-o propoziție și abrevierilor aleatorii. Astfel, lucrul cu date combinate de coduri este mai dificil decât datele monolingve. Interpretarea predicțiilor unui model ne permite să determinăm robustețea modelului împotriva diferitelor forme de zgomot. În această lucrare, propunem o metodologie de integrare a abordărilor explicabile în analiza sentimentului cod-mixt. Interpretând previziunile modelelor de analiză sentimentală evaluăm cât de bine modelul este capabil să se adapteze la zgomotele implicite prezente în datele cod-mixte.</abstract_ro>
      <abstract_sr>Povećanje upotrebe društvenih medijskih sajtova u zemljama poput Indije povećalo se velikim volumima podataka mešanih kod. Sentimentna analiza ovih podataka može pružiti integralne uvide u perspektive i mišljenje ljudi. Podaci mešani kod često su bukovi u prirodi zbog višestrukih pisanja za istu reč, nedostatak određenog reda reči u rečenici i nasumičnih skrovišta. Dakle, rad sa podacima mešanim kod je mnogo izazovniji od monojezičkih podataka. Premišljanje predviđanja model a omogućava nam da odredimo robotu modela protiv različitih oblika buke. U ovom papiru predlažemo metodologiju da integrišemo objašnjive pristupe u analizu osećanja kombiniranih kod. Prema tumačenju predviđanja modela analize sentimenta procjenjujemo kako je model u mogućnosti prilagoditi implicitnim bukama koje postoje u podacima mešanim kodima.</abstract_sr>
      <abstract_si>ඉන්දියාව වගේ දේශ වල සාමාජික මාධ්‍යාත්මක ප්‍රයෝජනය විශාලනය කරලා තියෙනවා වගේ ලොකු කෝඩ් මිශ මේ දත්තේ සංවේදනය විශ්ලේෂණය පුළුවන් මිනිස්සුන්ගේ ප්‍රතිකාරය සහ හිත අදහස් වලට සංවිධානය ප කෝඩ් මික්ස් තොරතුරු ස්වභාවිතයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් විශේෂයෙන් වචනයක් නැති  ඉතින්, කෝඩ් මික්ස් තොරතුරු එක්ක වැඩ කරන්න එක භාෂාවක් තොරතුරු වඩා වඩා ප්‍රශ්නයි. මොඩල් එක්ක අනුවාදනය කරන්න අපිට පුළුවන් වෙනස් වර්ගයක් විරුද්ධ වෙනුවෙන් මොඩල් එක්ක ශක්තිමත් විරු මේ පත්තරේ අපි ප්‍රශ්නයක් සැලසුම් කරනවා කෝඩ් මිශ්‍රේෂණ විශ්ලේෂණයෙන් පැහැදිලි විස්තර කරන්න පුළුව දැනුම් විශ්ලේෂණ විශ්ලේෂණ මොඩේල්ස් ගැන අවශ්‍ය විශ්ලේෂණය සඳහා අපි අවශ්‍ය කරන්නේ මොඩේල්ස් කොච්චර හොඳයි කියල</abstract_si>
      <abstract_so>Inta korsocota isticmaalka shabakada bulshada ee wadamada sida India waxay u kordhisay tiro badan oo macluumaad kooban. Baaritaanka xilliga ah ee macluumaadkan waxay ka heli karaan aragtida la-qabsiga iyo fikrada dadka. Code-mixed data is often noisy in nature due to multiple spellings for the same word, lack of definite order of words in a sentence, and random abbreviations.  Sidaa darteed, shaqo la xiriira macluumaadka kaararka waa ka dhibaato badan yihiin macluumaadka afka. Turjumidda qaababka noocyada ayaa inagu ogolaan kara inaannu go'inno dabeecada oo ka gees ah noocyada codka kala duduwan. In this paper, we propose a methodology to integrate explainable approaches into code-mixed sentiment analysis.  Turjumidda qaababka kaleemeysiga, waxaynu qiimeynaynaa siduu u awoodi karo in uu u beddelo codka sawirro ah oo ku qoran macluumaadka kooxda.</abstract_so>
      <abstract_ta>இந்தியாவின் போன்ற நாடுகளில் சமூக ஊடக தளங்களை பயன்படுத்துவது அதிகமாக குறியீடு கலந்த தரவுகளின் பெரிய தொகுதி Sentiment analysis of this data can provide integral insights into people's perspectives and opinions.  ஒரே வார்த்தைக்கான பல சொல்லுக்கள், வாக்கியத்தில் குறிப்பிட்ட வரிசையின் குறிப்பிட்ட தகவல் மற்றும் குறிப்பிடாத குறிப்பிட் எனவே, குறியீடு கலக்கப்பட்ட தரவுடன் வேலை செய்வது மொழிமொழியில் தரவை விட சவாலானதாகும். ஒரு மாதிரியின் முன்னோட்டங்களை பொருத்துவது நமக்கு அனுமதிக்கிறது மாதிரியின் ஆட்டத்தை வித்தியாசமான சப்தத்தின்  இந்த காகிதத்தில், நாம் ஒரு முறைமையை பரிந்துரைக்கிறோம் குறியீடு கலக்கப்பட்ட உணர்வு ஆராய்ச்சிக்கு ஒரு முறை உணர்வு ஆய்வு மாதிரிகளின் முன்னோட்டங்களை விளக்கினால் மாதிரி எவ்வளவு முறைமையாக முடியும் என்பதை பரிசோதிக்க முடியும் குறிய</abstract_ta>
      <abstract_sv>Den ökande användningen av sociala medier i länder som Indien har gett upphov till stora volymer kodblandad data. Känsleanalys av dessa data kan ge integrerade insikter i människors perspektiv och åsikter. Kodblandade data är ofta bullriga till sin natur på grund av flera stavningar för samma ord, brist på bestämd ordordning i en mening och slumpmässiga förkortningar. Därför är det svårare att arbeta med kodblandade data än enspråkiga data. Genom att tolka en modells förutsägelser kan vi bestämma modellens robusthet mot olika former av buller. I denna uppsats föreslår vi en metod för att integrera förklaringbara förhållningssätt i kodblandad sentimentalanalys. Genom att tolka prediktionerna av sentimentalanalysmodeller utvärderar vi hur väl modellen kan anpassa sig till de implicita buller som finns i kodblandade data.</abstract_sv>
      <abstract_ur>انڈیا جیسی ملک میں سوسیل میڈیا سائٹوں کا استعمال بڑھا ہوا ہے، کڈ مmixed ڈیٹوں کی بڑی آوازوں پر اضافہ کیا گیا ہے۔ اس ڈیٹا کا حساس تحلیل لوگوں کی نظریں اور نظریں میں دائمی نظریں پیش کرسکتی ہیں. کوڈ میکس ڈیٹا اکثر طبیعت میں بہت سی باتوں کی وجہ سے آواز ہے، کلمات کی قطعی سفارش ہے، اور طرح طرح طرح کے سفارش کی وجہ سے. اس طرح، کوڈ میکس ڈیٹا کے ساتھ کام کرنا ایک زبان ڈیٹا سے زیادہ مشکل ہے۔ ایک موڈل کی پیش بینی کی تعلیم کرنا ہمیں موڈل کی قوت کی تعلیم دینے کی اجازت دیتا ہے مختلف صوت کی شکل سے۔ اس کاغذ میں ہم ایک طریقہ پیشنهاد کرتے ہیں کہ کوڈ میکسٹ احساسات تحلیل میں تفصیل کرسکتے ہیں۔ احساسات تحلیل موڈل کی پیش بینی کی تفسیر کے ذریعہ ہم مطالبہ کرتے ہیں کہ موڈل کس طرح اچھی طرح قابل ہے کہ کوڈ میکس ڈیٹ میں موجود ہونے والی غږوں کے ساتھ اضافہ کرسکے۔</abstract_ur>
      <abstract_uz>Hindiston davlatlaridagi jamiyat media saytlarini ko'paytirishni ko'paytirish uchun katta kodlash tarkibi maʼlumotga ega beradi. Ushbu maʼlumotning bir vaqt analyzeri odamning ko'rinishiga bir narsa ko'rinishiga ega oladi. @ info: whatsthis Shunday qilib, ko'paytirilgan maʼlumot bilan ishlash monolik tildan ham qiyin edi. Modelning tarjima qilishiga bizni boshqa shakllar bilan modelning robotini aniqlashga ruxsat beradi. Bu qogʻozda, biz ko'paytirilgan hissiyotni aniqlash uchun foydalanuvchini birlashtirish uchun o'ylaymiz. By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_uz>
      <abstract_vi>Sự phát triển của các trang mạng xã hội ở đất nước như Ấn Độ đã tạo ra một số lượng lớn các dữ liệu giữa các mã số. Bản phân tích tình cảm của dữ liệu này có thể cung cấp hiểu biết về góc nhìn và ý kiến của con người. Thông tin mã trộn thường gây ồn ào trong tự nhiên do nhiều từ cho cùng một từ, thiếu trật tự xác định từ trong một câu, và các loại viết tắt ngẫu nhiên. Làm việc với các dữ liệu trộn mã là khó khăn hơn cả các dữ liệu ngôn ngữ. Việc giải thích dự đoán của mô hình cho phép chúng tôi xác định độ bền vững của mô-đun dựa trên các dạng nhiễu khác nhau. Trong tờ giấy này, chúng tôi đề xuất một phương pháp để tích hợp các phương pháp giải thích trong phân tích đa cảm. Bằng cách giải thích dự đoán của các mô hình phân tích cảm xúc chúng tôi đánh giá cách thức của mô hình có khả năng thích ứng với âm ngầm trong các dữ liệu trộn mã.</abstract_vi>
      <abstract_hr>Povećanje uporabe društvenih medijskih sajtova u zemljama poput Indije povećalo se velikim volumima podataka o mješanju kodova. Sentimentna analiza tih podataka može pružiti integralne uvide u perspektive i mišljenje ljudi. Podaci mešani kod često su bukovi u prirodi zbog višestrukih pisanja za istu riječ, nedostatak definiranog reda riječi u rečenici i nasumičnih skraćenja. Dakle, raditi s podacima pomiješanim kod je izazovnije od monojezičkih podataka. Primjenjivanje predviđanja model a omogućava nam da utvrdimo snagu modela protiv različitih oblika buke. U ovom papiru predlažemo metodologiju za integraciju objašnjivih pristupa u analizu osjećaja kombiniranih kod. Prema tumačenju predviđanja modela analize osjećaja procjenjujemo kako je model u mogućnosti prilagoditi implicitnim bukama prisutnim u podacima mješanim kod.</abstract_hr>
      <abstract_bg>Нарастващото използване на социални медии в страни като Индия доведе до големи обеми данни, смесени с кодове. Анализът на сентимента на тези данни може да осигури цялостна представа за перспективите и мненията на хората. Смесените с кодове данни често са шумни по природа поради множество правописи за една и съща дума, липса на определен ред на думите в изречение и случайни съкращения. По този начин работата с кодово смесени данни е по-трудна от едноезичните данни. Тълкуването на прогнозите на модела ни позволява да определим здравината на модела срещу различни форми на шум. В настоящата статия предлагаме методология за интегриране на обясними подходи в кодово смесен анализ на сентимента. Чрез интерпретиране на прогнозите на моделите за анализ на сентимента оценяваме колко добре моделът е способен да се адаптира към имплицитните шумове, присъстващи в кодово смесени данни.</abstract_bg>
      <abstract_da>Den stigende brug af sociale medier i lande som Indien har givet anledning til store mængder kode-blandede data. Følelsesanalyse af disse data kan give integreret indsigt i folks perspektiver og meninger. Kodeblandede data er ofte støjende i naturen på grund af flere stavninger for det samme ord, manglende bestemt ordrækkefølge i en sætning og tilfældige forkortelser. Derfor er det mere udfordrende at arbejde med kodeblandede data end ensprogede data. Ved at fortolke en models forudsigelser kan vi bestemme modellens robusthed mod forskellige former for støj. I denne artikel foreslår vi en metode til at integrere forklarelige tilgange i kode-mixed sentiment analyse. Ved at fortolke forudsigelserne af sentimentalanalysemodeller vurderer vi, hvor godt modellen er i stand til at tilpasse sig de implicitte støj, der findes i kodeblandede data.</abstract_da>
      <abstract_nl>Het toenemende gebruik van social media sites in landen als India heeft geleid tot grote hoeveelheden code-mixed data. Sentiment analyse van deze data kan integraal inzicht geven in de perspectieven en meningen van mensen. Code-gemengde gegevens zijn vaak lawaaierig van aard door meerdere spellingen voor hetzelfde woord, gebrek aan duidelijke volgorde van woorden in een zin en willekeurige afkortingen. Het werken met code-mixed data is dus uitdagender dan eentalige data. Door de voorspellingen van een model te interpreteren, kunnen we de robuustheid van het model tegen verschillende vormen van ruis bepalen. In dit artikel stellen we een methodologie voor om verklarbare benaderingen te integreren in code-mixed sentiment analyse. Door de voorspellingen van sentimentanalysemodellen te interpreteren evalueren we hoe goed het model zich kan aanpassen aan de impliciete geluiden die aanwezig zijn in code-mixed data.</abstract_nl>
      <abstract_id>Penggunaan semakin meningkat dari situs media sosial di negara-negara seperti India telah memberikan suatu jumlah besar data campuran kode. Analisi sensor dari data ini dapat memberikan pandangan integral ke perspektif dan pendapat orang. Data campuran kode sering berbunyi dalam alam karena banyak ejaan untuk kata yang sama, kekurangan perintah jelas kata dalam kalimat, dan singkat acak. Jadi, bekerja dengan data campuran kode lebih menantang daripada data monobahasa. Menginterpretasi prediksi model memungkinkan kita untuk menentukan kekuatan model melawan bentuk berbeda suara. Dalam kertas ini, kami mengusulkan metodologi untuk mengintegrasikan pendekatan yang dapat dijelaskan ke analisis perasaan campuran kode. By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_id>
      <abstract_de>Die zunehmende Nutzung von Social-Media-Seiten in Ländern wie Indien hat zu großen Mengen an Code-Mixed-Daten geführt. Die Sentimentanalyse dieser Daten kann integrale Einblicke in die Perspektiven und Meinungen von Menschen liefern. Code-gemischte Daten sind oft laut aufgrund mehrerer Schreibweisen für dasselbe Wort, fehlender eindeutiger Reihenfolge von Wörtern in einem Satz und zufälliger Abkürzungen. Daher ist die Arbeit mit Code-Mixed-Daten anspruchsvoller als mit einsprachigen Daten. Die Interpretation der Vorhersagen eines Modells ermöglicht es uns, die Robustheit des Modells gegenüber verschiedenen Formen von Rauschen zu bestimmen. In diesem Beitrag schlagen wir eine Methodik vor, um erklärbare Ansätze in code-mixed sentiment Analysen zu integrieren. Durch die Interpretation der Vorhersagen von Sentiment-Analysemodellen bewerten wir, wie gut das Modell in der Lage ist, sich an die impliziten Geräusche in code-mixed Daten anzupassen.</abstract_de>
      <abstract_tr>Hindistan ýaly ýurtlarda sosyal medýdançalaryň ulanyşynyň kän ködlemeleri karmaşgalan maglumatlaryna üýtgedýär. Bu maglumatyň Sentiment analizi adamlaryň perspektiblerine we pikirlerine dair integral pikirleri getirip biler. Birnäçe sözler üçin garşyrlyk hasaplanýar, sözlerde tanyş sözler ýok we seýiksiz terjimeler ýok. Şol sebäpli, kodlardan karışık maglumatlar bilen işlemek monodil maglumatlardan has gaty kynçylykdyr. Modelin tahmin etmesi bize modelinin güçlüğünü farklı ses şeklinde karar vermemizi s a ğlar. Bu kagyzda, biz ködleşikli duýgular analyzasyna düşündirebilir ýagdaýlary integrleştirmek üçin bir metodologi teklip edip oturuyoruz. Duýgular analyzasy nusgalarynyň önümlerini çykaryp, nusgalaryň kodlarda karmaşgalan berüvlerde nähili gowy üýtgetmelidigini çykarýarys.</abstract_tr>
      <abstract_ko>인도 등 국가에서 소셜미디어 사이트의 사용이 갈수록 많아지면서 대량의 코드 혼합 데이터가 생겼다.이러한 데이터에 대한 정서 분석은 사람들의 관점과 관점에 완전한 견해를 제공할 수 있다.같은 단어의 여러 맞춤법, 문장에서 단어의 순서가 명확하지 않고 줄임말이 무작위로 나타나기 때문에 코드 혼합 데이터는 본질적으로 종종 시끄럽다.따라서 처리 코드 혼합 데이터는 단어 데이터 처리보다 도전적이다.해석 모델의 예측을 통해 우리는 모델이 서로 다른 형식의 소음에 대한 노봉성을 확정할 수 있다.본고에서 우리는 해석 가능한 방법을 코드 혼합 감정 분석에 집적하는 방법을 제시했다.정서 분석 모델의 예측을 해석함으로써 우리는 이 모델이 코드 혼합 데이터에 존재하는 스텔스 소음에 어느 정도 적응할 수 있는지 평가했다.</abstract_ko>
      <abstract_sq>Përdorimi në rritje i faqeve të medias shoqërore në vende si India ka dhënë origjinë për volume të mëdha të dhënash të përziera me kod. Analiza e ndjenjave e këtyre të dhënave mund të ofrojë pamje integrale në perspektivat dhe opinionet e njerëzve. Të dhënat e përziera me kod janë shpesh zhurmëshme në natyrë për shkak të shkrimeve të shumta për të njëjtin fjalë, mungesës së rendit të përcaktuar të fjalëve në një fjalë dhe shkurtimeve të rastësishme. Kështu, puna me të dhënat e përziera me kode është më e vështirë se të dhënat monogjuhësore. Interpretimi i parashikimeve të një modeli na lejon të përcaktojmë fuqinë e modelit kundër formave të ndryshme të zhurmës. Në këtë letër, propozojmë një metodologi për të integruar metodat e shpjegueshme në analizën e ndjenjave të përziera me kod. Duke interpretuar parashikimet e modeleve të analizës së ndjenjave ne vlerësojmë sa mirë modeli është në gjendje të përshtatet me zhurmat implicite të pranishme në të dhënat e përziera me kod.</abstract_sq>
      <abstract_fa>افزایش استفاده از سایت‌های رسانه‌های اجتماعی در کشورهای مانند هند به مجموعه‌های بزرگ داده‌های مختلف کد رشد داده است. تحلیل احساساتی از این داده‌ها می‌تواند بفهمه‌های بی‌نیاز را در نظر و نظر مردم تحریک کند. داده‌های ترکیب‌شده‌ی کد اغلب در طبیعت به دلیل کلمه‌های متعدد برای یک کلمه صدایی می‌باشد، کمی دستور قطعی از کلمه‌ها در یک جمله و ترکیب‌های تصادفی. بنابراین، کار با داده های مختلف کد بیشتر از داده های یک زبان سخت تر است. تفسیر پیش‌بینی‌های یک مدل اجازه می‌دهد که قدرت مدل را بر خلاف شکل‌های مختلف صدا تعیین کنیم. در این کاغذ، ما یک روش پیشنهاد می‌کنیم که با توضیح قابل توضیح به تحلیل احساسات متصل شده‌اند. با تعبیر پیش‌بینی‌های مدل تحلیل احساسات ما ارزیابی می‌کنیم که مدل چقدر خوب می‌تواند با صداهای معمولی که در داده‌های مختلف کد موجود است adapt کند.</abstract_fa>
      <abstract_sw>The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data.  Uchambuzi wa muda mfupi wa takwimu hizi unaweza kutoa mitazamo ya moja kwa moja katika mitazamo na maoni ya watu. Takwimu za mchanganyiko wa sheria mara nyingi huitwa kelele kwa sababu ya maneno kadhaa kwa neno hilo, ukosefu wa mfumo wa ufanisi wa maneno katika hukumu, na unyanyasaji wa taratibu. Kwa hiyo, kufanya kazi na taarifa zilizochanganyika kwa mfumo ni changamoto zaidi ya taarifa za lugha. Kutafsiri utabiri wa modeli unaruhusu kuamua nguo za modeli dhidi ya aina mbalimbali za sauti. Katika karatasi hii, tunapendekeza mbinu za kuunganisha mbinu zisizo na ufafanuzi katika uchambuzi wa hisia zilizochanganyika. Kwa kutafsiri utabiri wa mifano ya uchambuzi wa hisia tunapitia jinsi mwelekeo unavyoweza kuunganisha sauti zilizopo kwenye takwimu zilizochanganyika.</abstract_sw>
      <abstract_af>Die grootste gebruik van sosiale media tuistes in lande soos Indië het gegee tot groot volume van kode gemengde data. Sentiment analiseer van hierdie data kan integrale insigs verskaf binne mense se perspeksies en besonderhede. Kode-gemengde data is dikwels geluid in natuur vanweë veelvuldige speletjies vir dieselfde woord, mislukking van definieerde volgorde van woorde in 'n seting en willekeurige kruiging. So, werk met kode gemengde data is meer belangrik as monolinglike data. Om 'n model se voorskoue te interpreteer laat ons die kragtigheid van die model teen verskillende vorms van ruis bepaal. In hierdie papier voorstel ons 'n metodologie om verduidelike toegange in kode gemengde sentimentanalisie te integreer. Deur die voorskoue van sentimentanaliseerde modele te interpreteer ons evalueer hoe goed is die model in staat om te pas aan die inplisite ruise wat in kode gemengde data is.</abstract_af>
      <abstract_az>Hindistan kimi ülkelərdə sosyal media sitələrinin istifadəsi artırmağı böyük kodlar karıştırılmış məlumatların yüksəltdi. Bu məlumatların şiddətli analizi insanların görünüşünü və fikirlərini təsdiqləyə bilər. Kod karıştırılmış verilər təbiətdə çox səslədir, eyni söz üçün çoxlu imzalar, sözlərin müəyyən sıraları olmayan və rastgele qısqartmalar üçün. Beləliklə, kodla karışmış verilər ilə işləmək monodil verilərdən daha çətin. Modelin tədbirlərini çəkmək bizə modelinin s əslərin müxtəlif şəkillərinə qarşı səslərin gücünü təsdiqləməsinə imkan verir. Bu kağızda, kodla karışmış hisslər analizi ilə müfəssəl tərzlərini birləşdirmək üçün bir metodoloji təklif edirik. Duygusal analizi modellərin tədbirlərini yoxlayaraq modellərin nə qədər gözəl uyğunlaşdırdığını çəkirik.</abstract_az>
      <abstract_bn>ভারতের মতো দেশের সামাজিক প্রচার মাধ্যমের সাইট ব্যবহার বাড়ছে যা কোড মিশ্রিত তথ্যের বিশাল সংখ্যা বৃদ্ধি করে এই তথ্যের সেন্টাইমেন্ট বিশ্লেষণ মানুষের দৃষ্টিভঙ্গি এবং মতামতে প্রকাশ করতে পারে। কোড মিশ্রিত তথ্য প্রায়শই একই শব্দের জন্য বেশ কয়েকটি বানানোর কারণে প্রকৃতিতে আওয়াজ প্রকাশ করে, একটি বাক্যে নির্দিষ্ট ক্ষেত্রের অভা তাই, কোড-মিশ্রিত তথ্যের সাথে কাজ করার চ্যালেঞ্জের চেয়ে বেশী চ্যালেঞ্জ। Interpreting a model's predictions allows us to determine the robustness of the model against different forms of noise.  এই কাগজটিতে আমরা একটি পদ্ধতিতে প্রস্তাব করছি যাতে কোড মিশ্রিত অনুভূতিবিশ্লেষণে ব্যাখ্যা করা যায় না। অনুভূতি বিশ্লেষণ মডেলের ভবিষ্যদ্বাণী ব্যাখ্যা করার মাধ্যমে আমরা মূল্য করি কিভাবে মডেল কোড মিশ্রিত তথ্যের মধ্যে দেখা যাচ্ছে ত</abstract_bn>
      <abstract_am>እንደህንድ ሀገሮች ማኅበራዊ ሚዲያ ድረ ገጾችን የሚጨምሩ የኮድ-መቀላቀል ዳታዎችን በጥልቅ ድምፅ አቀረበ፡፡ የዚህ ዳታ አስተያየት የሰዎች ዓይነቶች እና አስተያየት የሚችል ስልጣናት፡፡ በአንድ ቃላት፣ በቁጥጥር እና በቁጥጥር እና በተደላደለ የቃላት ግንኙነት እና በተደላደለ ግንኙነት የቁጥጥር የተለየ ዳታ በሥርዓት ብዛት ድምፅ ነው፡፡ ስለዚህም ከኮድ-መቀላቀል ዳታ ጋር መሥራት ከሞሎ ቋንቋ ዳታዎች ይልቅ አዋቂ ነው፡፡ የሞዴል ትንቢት ለመፍረስ የሞዴል ልብስ በተለያዩ ዓይነት ድምፅ ላይ ለመፍጠር ይችላል፡፡ በዚህ ፕሮግራም፣ የቃላት የቆዳ እውቀት ማስተያየት የሚችሉትን የሥርዓት ማቀናቀል እናስባለን፡፡ By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_am>
      <abstract_bs>Povećanje uporabe društvenih medijskih sajtova u zemljama poput Indije povećalo se velikim volumima podataka o mešanju koda. Sentimentna analiza ovih podataka može pružiti integralne uvide u perspektive i mišljenje ljudi. Podaci mešani kod često su bukovi u prirodi zbog višestrukih pisanja za istu riječ, nedostatka definitivnog reda riječi u rečenici i nasumičnih skraćenja. Dakle, rad sa kodom pomiješanim podacima je izazovniji od monojezičkih podataka. Premišljanje predviđanja model a omogućava nam da utvrdimo robotu modela protiv različitih oblika buke. U ovom papiru predlažemo metodologiju za integraciju objašnjivih pristupa u analizu osjećaja kombiniranih kod. Prema tumačenju predviđanja modela analize sentimenta procjenjujemo kako je model u mogućnosti prilagoditi implicitnim bukama prisutnim u podacima mešanim kodom.</abstract_bs>
      <abstract_et>Sotsiaalmeedia saitide kasvava kasutamise tõttu sellistes riikides nagu India on tekkinud suur hulk koodisega andmeid. Nende andmete sentimentaalüüs võib anda tervikliku ülevaate inimeste perspektiividest ja arvamustest. Koodidega segatud andmed on sageli lärmakad, kuna sama sõna korduvad kirjad, lause kindla järjekorra puudumine ja juhuslikud lühendid. Seega on koodisegatud andmetega töötamine keerulisem kui ühekeelsed andmed. Mudeli prognooside tõlgendamine võimaldab määrata mudeli tugevuse erinevate müravormide suhtes. Käesolevas töös pakume välja metoodika, millega integreerida selgitatavad lähenemisviisid koodisega sentimentaalüüsi. Tundeanalüüsi mudelite prognooside tõlgendamisega hindame, kui hästi mudel suudab kohaneda koodisega andmetes esinevate kaudsete müradega.</abstract_et>
      <abstract_hy>The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data.  Sentiment analysis of this data can provide integral insights into people's perspectives and opinions.  Code-mixed data is often noisy in nature due to multiple spellings for the same word, lack of definite order of words in a sentence, and random abbreviations.  Այսպիսով, աշխատելը կոդի խառնված տվյալների հետ ավելի դժվար է, քան միալեզու տվյալները: Մոդելի կանխատեսումները մեկնաբանելը թույլ է տալիս մեզ որոշել մոդելի ուժեղությունը ձայնի տարբեր ձևերի դեմ: In this paper, we propose a methodology to integrate explainable approaches into code-mixed sentiment analysis.  By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_hy>
      <abstract_cs>Rostoucí využívání sociálních médií v zemích, jako je Indie, vedlo k velkému množství dat s kódem smíšených. Sentimentní analýza těchto dat může poskytnout integrální přehled o perspektivách a názorech lidí. Data smíšená kódem jsou často hlučná z důvodu více pravopisů pro stejné slovo, nedostatku určitého pořadí slov ve větě a náhodných zkratek. Práce s daty smíšenými kódem je tedy náročnější než s jednojzyčnými daty. Interpretace předpovědí modelu nám umožňuje určit robustnost modelu vůči různým formám šumu. V tomto článku navrhujeme metodiku integrace vysvětlitelných přístupů do analýzy smíšených sentimentů. Interpretací predikcí modelů sentimentní analýzy hodnotíme, jak dobře se model dokáže přizpůsobit implicitním šumům přítomným v kódově smíšených datech.</abstract_cs>
      <abstract_fi>Sosiaalisen median sivustojen lisääntyvä käyttö Intian kaltaisissa maissa on aiheuttanut suuria määriä koodisekoitettua dataa. Tunteanalyysi näistä tiedoista voi tarjota kokonaisvaltaista tietoa ihmisten näkökulmista ja mielipiteistä. Koodien sekaantuminen on usein luonteeltaan meluisaa, koska saman sanan useat kirjoitustavat, lauseen sanajärjestyksen puuttuminen ja satunnaiset lyhenteet aiheuttavat usein melua. Näin ollen koodisekoitetun datan käyttö on haastavampaa kuin yksikielinen data. Mallin ennusteiden tulkinta mahdollistaa mallin kestävyyden erilaisten melumuotojen suhteen. Tässä työssä ehdotamme menetelmää, jolla selitettävät lähestymistavat voidaan integroida koodisekoitettuun tunteiden analyysiin. Tunteanalyysimallien ennusteita tulkitsemalla arvioimme, miten hyvin malli pystyy sopeutumaan koodisekoitetussa datassa esiintyviin implisiittisiin ääniin.</abstract_fi>
      <abstract_ca>The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data.  Sentiment analysis of this data can provide integral insights into people's perspectives and opinions.  Code-mixed data is often noisy in nature due to multiple spellings for the same word, lack of definite order of words in a sentence, and random abbreviations.  Així, treballar amb dades combinades amb codis és més difícil que les dades monolingües. L'interpretació de les prediccions d'un model ens permet determinar la robustet del model contra diferents formes de soroll. In this paper, we propose a methodology to integrate explainable approaches into code-mixed sentiment analysis.  Interpretant les prediccions dels models d'anàlisi del sentiment evaluem com de bé el model es pot adaptar als sorolls implícits presents en dades combinades amb codis.</abstract_ca>
      <abstract_jv>Rasané dipunangé sistem sing media sotinêngé ning awak dhéwé, kaya barang-barang barang dagalah sing uwis seneng pisan winih sing dirangé data sing berarti. Sentiment string" in "context_BAR_stringLink Dadi, nggunakake karo kode-karo akeh basa sing luwih apik dikenal sing karo data Monoleng. Alpha Nanging paper iki, kita supoyo sistem kanggo nyelarakno karo hal-nyelaran ngerasakno Genjer-Genjer diunting perusahaan anyar samsul model sing beraksi dadi nggawe nguasai winih dhéwé nggawe modèl kuwi nggawe gerakan karo perusahaan anyar samsul dadi winih karo hal-nambah.</abstract_jv>
      <abstract_sk>Vedno večja uporaba spletnih mest družbenih omrežij v državah, kot je Indija, je povzročila velike količine podatkov, mešanih s kodami. Analiza čustva teh podatkov lahko zagotovi celovit vpogled v perspektive in mnenja ljudi. Podatki z mešanimi kodami so pogosto hrupni zaradi več črkovanj za isto besedo, pomanjkanja določenega vrstnega reda besed v stavku in naključnih okrajšav. Zato je delo z mešanimi kodami podatki bolj zahtevno kot enojezični podatki. Interpretacija napovedi modela nam omogoča določitev robustnosti modela proti različnim oblikam hrupa. V prispevku predlagamo metodologijo za vključitev pojasnljivih pristopov v kodno mešano analizo sentimenta. Z interpretacijo napovedi modelov sentimentalne analize ocenimo, kako dobro se model lahko prilagodi implicitnim hrupom, prisotnim v podatkih mešanih kod.</abstract_sk>
      <abstract_ha>Ina ƙara amfani da mitandai masu jamii a cikin mataifa kamar India, sun ƙara zuwa manyan mutane na kodi-da-haɗe data. Anarari na zaman shawara kan wannan data yana iya iya samar da gannai masu inganci cikin fikayar mutãne da kalmõmi. Takardan kodi da aka haɗa shi, yana da saurare a cikin naturen, wa'adin wasu misalin maganar da ke daidaita, kuma bã da wani tsari na ƙayyade maganar da ke cikin birane da baƙa ƙƙe a rana. Kayya, aikin da aka haɗa data na kode-da-gaura yana da mafi ƙaranci daga data masu yiwuwa. Ka bayyana bayani'anar misãlai na yarda mu ƙayyade tufãfin misalin ayuka don wata sauni na daban. Ga wannan takardan, Munã buɗa wata metodi da za'a haɗa hanyoyin abin da ba'a bayyana a cikin Anarari na kodi-da-haɗe. By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_ha>
      <abstract_he>השימוש הגדול של אתרי התקשורת החברתית במדינות כמו הודו נתן את התוצאה לכמות גדולות של נתונים מעורבים בקוד. ניתוח רגשי של הנתונים האלה יכול לספק תובנות אינטגרליות לתוך הנקודות והדעות של אנשים. נתונים מעורבים בקוד הם לעתים קרובות רעשים בטבע בגלל מילים רבות לאותה מילה, חוסר סדר מוחלט של מילים במשפט, וקצרות אקראיות. כך, לעבוד עם נתונים מעורבים קודים זה יותר מאתגר מאשר נתונים מונושפתיים. לפרסם את החזויות של מודל מאפשר לנו לקבוע את החזקה של המודל נגד צורות שונות של רעש. In this paper, we propose a methodology to integrate explainable approaches into code-mixed sentiment analysis.  By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_he>
      <abstract_bo>རྒྱ་གར་གྱི་རྒྱལ་ཁབ་ནང་དུ་རྒྱ་ནག Sentiment analysis of this data can provide integral insight into the people's perspective and opinions. སྐད་ཡིག་གཅིག་པ་ལ་ཡིག་གཟུགས་འགྱུར་བའི་ཆ་འཕྲིན་དེ་ཚོ་རྒྱུན་ལྡན་གྱིས་ཕལ་ཆེ་བ་ཡིན་པ། དེར་བརྟེན། འོན་ཀྱང་། ཆ་གཅིག་སྒྲིག་བྱས་པའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་མཉམ་སྤྱོད་ནི་ཆ་འཕྲིན་ཡིག མ་དབྱིབས་འགྱུར་བའི་སྔོན་བསམ་ཅིག་ཡིས་ང་ཚོས་དབྱིབས་བཀོད་པའི་མཐུན་རྐྱེན་ཚད་ལ་གཏོང་བཅུག་པ། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་ཐབས་ལམ་ཞིག་གིས་གསལ་བཤད་རུང་བའི་ཐབས་ལམ་ཞིག་ཡིན་པས། By interpreting the predictions of sentiment analysis models we evaluate how well the model is able to adapt to the implicit noises present in code-mixed data.</abstract_bo>
      </paper>
    <paper id="49">
      <title>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets<fixed-case>BERT</fixed-case>weet<fixed-case>FR</fixed-case> : Domain Adaptation of Pre-Trained Language Models for <fixed-case>F</fixed-case>rench Tweets</title>
      <author><first>Yanzhu</first><last>Guo</last></author>
      <author><first>Virgile</first><last>Rennard</last></author>
      <author><first>Christos</first><last>Xypolopoulos</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <pages>445–450</pages>
      <abstract>We introduce BERTweetFR, the first large-scale pre-trained language model for French tweets. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is initialised using a general-domain French language model CamemBERT which follows the base architecture of BERT. Experiments show that BERTweetFR outperforms all previous general-domain French language models on two downstream Twitter NLP tasks of offensiveness identification and <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> used in the offensiveness detection task is first created and annotated by our team, filling in the gap of such analytic datasets in <a href="https://en.wikipedia.org/wiki/French_language">French</a>. We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</abstract>
      <url hash="594c8dad">2021.wnut-1.49</url>
      <bibkey>guo-etal-2021-bertweetfr</bibkey>
      <doi>10.18653/v1/2021.wnut-1.49</doi>
      <pwccode url="" additional="true" />
    <title_ar>BERTweetFR: تكييف المجال لنماذج اللغة سابقة التدريب للتغريدات الفرنسية</title_ar>
      <title_pt>BERTweetFR: Adaptação de Domínio de Modelos de Linguagem Pré-Treinados para Tweets em Francês</title_pt>
      <title_fr>BertweetFR : Adaptation de domaines de modèles linguistiques pré-entraînés pour les tweets en français</title_fr>
      <title_es>BertweetFR: Adaptación de dominio de modelos lingüísticos preentrenados para tuits en francés</title_es>
      <title_ja>BERTweetFR ：フランス語のツイートのための事前トレーニングされた言語モデルのドメイン適応</title_ja>
      <title_hi>BERTweetFR: फ्रेंच Tweets के लिए पूर्व प्रशिक्षित भाषा मॉडल के डोमेन अनुकूलन</title_hi>
      <title_zh>BERTweetFR : 法语推文预训言模之域改</title_zh>
      <title_ru>BERTweetFR : Адаптация домена предварительно обученных языковых моделей для французских твитов</title_ru>
      <title_ga>BERTweetFR : Oiriúnú Fearainn ar Mhúnlaí Teanga RéamhOilte le haghaidh Tweetanna Fraincise</title_ga>
      <title_el>BERTweetFR: Προσαρμογή τομέων προσχεδιασμένων γλωσσικών μοντέλων για γαλλικά tweets</title_el>
      <title_hu>BERTweetFR: Az előképzett nyelvi modellek domain adaptációja francia tweetekhez</title_hu>
      <title_ka>BERTweetFR : ფრანუს ტივიტებისთვის მოდელების დომენის ადაპტიფიკაცია</title_ka>
      <title_it>BERTweetFR: Adattamento del dominio dei modelli linguistici pre-formati per i tweet francesi</title_it>
      <title_kk>BERTweetFR : Француз Tweets үшін алдын- оқылған тіл үлгілерінің домен адаптациясы</title_kk>
      <title_lt>BERTweetFR : Išankstinio mokymo kalbos modelių pritaikymas prancūzų dvietams</title_lt>
      <title_mk>BERTweetFR : Адаптација на доменот на предобучените јазички модели за француски твитови</title_mk>
      <title_ml>ബെര്‍ട്ട്വിറ്റ്‌എഫ്: ഫ്രെഞ്ച് ട്വീറ്റുകള്‍</title_ml>
      <title_mt>BERTweetFR : Adattament tad-dominju tal-mudelli lingwistiċi mħarrġa minn qabel għal Tweets Franċiżi</title_mt>
      <title_ms>BERTweetFR : Penyesuaian Domain Model Bahasa Latihan-Pra untuk Tweet Perancis</title_ms>
      <title_mn>BERTweetFR : Француз tweets-ын аль сургалтын хэл загварын зохицуулалт</title_mn>
      <title_pl>BERTweetFR: Adaptacja domen przeszkolonych modeli językowych dla tweetów francuskich</title_pl>
      <title_no>BERTweetFR : Domain Adaptation of Pre- Trained Language Models for French Tweets</title_no>
      <title_ro>BERTweetFR: Adaptarea domeniului modelelor lingvistice pre-instruite pentru tweeturile franceze</title_ro>
      <title_sr>BERTweetFR : Domena adaptacija predobučenih jezičkih modela za francuske Tweets</title_sr>
      <title_si>BERTWEtFR : ප්‍රෙන්ස් ට්විට්ස් වලට ප්‍රධානය කළ භාෂා මොඩේල්ස් වලට ඩොමේන් අනුමාණය</title_si>
      <title_so>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets</title_so>
      <title_sv>BERTweetFR: Domänanpassning av förberedda språkmodeller för franska tweets</title_sv>
      <title_ta>BERTweetFR : முன்பு பயிற்சி மொழி மாதிரியின் டொமைன் மாதிரியின் மாதிரி</title_ta>
      <title_ur>BERTweetFR : فرانسوی ٹویٹ کے لئے پیش ترین زبان موڈل کے دامین اڈپٹیٹ</title_ur>
      <title_uz>@ info: whatsthis</title_uz>
      <title_vi>Diễn văn kiểu ngôn ngữ đã học thuộc dòng</title_vi>
      <title_bg>Адаптация на домейни на предварително обучени езикови модели за френски туитове</title_bg>
      <title_da>BERTweetFR: Domænetilpasning af førtiltrænede sprogmodeller til franske tweets</title_da>
      <title_nl>BERTweetFR: Domeinaanpassing van voorgetrainde taalmodellen voor Franse Tweets</title_nl>
      <title_hr>BERTweetFR : Domena adaptacija predobučenih jezičkih modela za francuske Tweets</title_hr>
      <title_de>BERTweetFR: Domain Adaption von vortrainierten Sprachmodellen für französische Tweets</title_de>
      <title_id>BERTweetFR : Adaptasi Domain Model Bahasa Terlatih untuk Tweet Perancis</title_id>
      <title_ko>BERTweetFR: 프랑스어 트윗 예훈련 언어 모델의 영역 개편</title_ko>
      <title_fa>BERTweetFR : تغییرات دومین مدل های پیش آموزش زبان برای Tweets فرانسوی</title_fa>
      <title_sw>BERTweetFR : Toleo la Ujumbe wa Modeli za Lugha zilizojifunza kwa ajili ya Twita za Kifaransa</title_sw>
      <title_af>Constellation name (optional)</title_af>
      <title_tr>BERTweetFR : Fransuz Tweets üçin öňünden eğitilen dil nusgalarynyň ýerleşdirişi</title_tr>
      <title_sq>BERTweetFR : Adaptimi i domenit i modeleve të gjuhës së paratrajnuar për Tweets franceze</title_sq>
      <title_hy>BERWEtՖ՝ Ֆրանսիական թվիթերի նախապատրաստված լեզվի մոդելների դաշտային հարմարեցման համար</title_hy>
      <title_az>BERTweetFR : Fransız Tweets üçün öyrənmiş Dil Modellərinin Domain Adaptation of Pre-Trained Language Models</title_az>
      <title_am>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets</title_am>
      <title_bn>বেরুটুইটএফআর : ফরাসী টুইটের জন্য পূর্ব-ট্রেনিং ভাষা মডেলের ডোমেইন আড্যাপটেশন</title_bn>
      <title_ca>BERTweetFR : Adaptació del domini de models de llenguatge pré-capacitats per a Tweets franceses</title_ca>
      <title_bs>BERTweetFR : Domena adaptacija predobučenih jezičkih modela za francuske Tweets</title_bs>
      <title_et>BERTweetFR: Prantsuse tweetide eelõpetatud keelemudelite domeeni kohandamine</title_et>
      <title_cs>BERTweetFR: Doménová adaptace předškolených jazykových modelů pro francouzské tweety</title_cs>
      <title_fi>BERTweetFR: Esikoulutettujen kielimallien verkkotunnuksen mukauttaminen ranskan tweeteille</title_fi>
      <title_he>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets</title_he>
      <title_sk>BERTweetFR: Prilagoditev domenskih jezikovnih modelov za francoske tweete</title_sk>
      <title_ha>BERTwitter</title_ha>
      <title_jv>BERT week</title_jv>
      <title_bo>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets</title_bo>
      <abstract_ar>نقدم BERTweetFR ، أول نموذج لغوي مدرب مسبقًا واسع النطاق للتغريدات الفرنسية. تمت تهيئة نموذجنا باستخدام نموذج اللغة الفرنسية للمجال العام CamemBERT والذي يتبع البنية الأساسية لـ BERT. تُظهر التجارب أن BERTweetFR يتفوق في الأداء على جميع نماذج اللغة الفرنسية للمجال العام السابقة في مهمتين من مهام Twitter NLP النهائية لتحديد الهجوم والتعرف على الكيانات المسماة. يتم إنشاء مجموعة البيانات المستخدمة في مهمة الكشف عن الهجمة أولاً وتعليقها بواسطة فريقنا ، لملء فجوة مجموعات البيانات التحليلية هذه باللغة الفرنسية. نجعل نموذجنا متاحًا للجمهور في مكتبة المحولات بهدف تعزيز البحث المستقبلي في المهام التحليلية للتغريدات الفرنسية.</abstract_ar>
      <abstract_fr>Nous présentons BertweetFR, le premier modèle linguistique pré-formé à grande échelle pour les tweets en français. Notre modèle est initialisé à l'aide d'un modèle de langue française de domaine général CAMEMbert qui suit l'architecture de base du BERT. Les expériences montrent que BertweetFR surpasse tous les modèles de langue française du domaine général précédents sur deux tâches de PNL Twitter en aval, à savoir l'identification des offensives et la reconnaissance des entités nommées. Le jeu de données utilisé dans la tâche de détection d'offensivité est d'abord créé et annoté par notre équipe, comblant ainsi les lacunes de ces ensembles de données analytiques en français. Nous rendons notre modèle accessible au public dans la bibliothèque des transformateurs dans le but de promouvoir les recherches futures sur les tâches analytiques pour les tweets en français.</abstract_fr>
      <abstract_es>Presentamos BertweetFR, el primer modelo lingüístico preentrenado a gran escala para tuits en francés. Nuestro modelo se inicializa utilizando un modelo de dominio general en francés CamEMbert que sigue la arquitectura base de BERT. Los experimentos muestran que BertweetFR supera a todos los modelos anteriores del idioma francés de dominio general en dos tareas posteriores de la PNL de Twitter: identificación de ofensividad y reconocimiento de entidades nombradas. El conjunto de datos utilizado en la tarea de detección de la ofensiva es creado y anotado primero por nuestro equipo, llenando el vacío de dichos conjuntos de datos analíticos en francés. Ponemos nuestro modelo a disposición del público en la biblioteca transformers con el objetivo de promover la investigación futura en tareas analíticas para los tuits franceses.</abstract_es>
      <abstract_pt>Apresentamos o BERTweetFR, o primeiro modelo de linguagem pré-treinado em larga escala para tweets em francês. Nosso modelo é inicializado usando um modelo de domínio geral da língua francesa CamemBERT que segue a arquitetura base do BERT. Experimentos mostram que o BERTweetFR supera todos os modelos anteriores de domínio geral da língua francesa em duas tarefas downstream de NLP do Twitter de identificação de ofensividade e reconhecimento de entidade nomeada. O conjunto de dados usado na tarefa de detecção de ofensividade é primeiro criado e anotado por nossa equipe, preenchendo a lacuna desses conjuntos de dados analíticos em francês. Disponibilizamos nosso modelo publicamente na biblioteca de transformadores com o objetivo de promover pesquisas futuras em tarefas analíticas para tweets franceses.</abstract_pt>
      <abstract_ja>BERTweetFRをご紹介します。BERTweetFRは、フランス語のツイートのための最初の大規模な事前トレーニングされた言語モデルです。私たちのモデルは、BERTのベースアーキテクチャに従った一般ドメインのフランス語モデルCamemBERTを使用して初期化されます。実験によると、BERTweetFRは、不快感の識別と名前付きエンティティ認識の2つの下流のTwitter NLPタスクで、これまでのすべての一般ドメインフランス語モデルを上回っていることが示されています。不快感検出タスクで使用されるデータセットは、まず当社のチームによって作成され、注釈が付けられ、そのような分析データセットのギャップをフランス語で埋めます。私たちのモデルは、フランス語のツイートの分析タスクの将来の研究を促進することを目的として、トランスフォーマーライブラリで公開されています。</abstract_ja>
      <abstract_zh>吾言BERTweetFR,一法语推文之大预练言体也。 吾法用通域法语CamemBERT为初始化,循BERT之本架构。 实验明,BERTweetFR于两下之Twitter NLP(攻击性识名实)上优于通域法语。 进攻性检用之数,先自吾团队创注,补此法语析数集之空白。 吾于变压器库中明吾模样,所以趣进未来推文法国也。</abstract_zh>
      <abstract_hi>हम BERTweetFR पेश करते हैं, जो फ्रांसीसी ट्वीट्स के लिए पहला बड़े पैमाने पर पूर्व-प्रशिक्षित भाषा मॉडल है। हमारे मॉडल को एक सामान्य-डोमेन फ्रेंच भाषा मॉडल कैमबर्ट का उपयोग करके शुरू किया गया है जो BERT के आधार वास्तुकला का अनुसरण करता है। प्रयोगों से पता चलता है कि BERTweetFR आक्रामकता पहचान और नामित इकाई मान्यता के दो डाउनस्ट्रीम ट्विटर एनएलपी कार्यों पर सभी पिछले सामान्य डोमेन फ्रेंच भाषा मॉडल से बेहतर प्रदर्शन करता है। आक्रामकता का पता लगाने के कार्य में उपयोग किए जाने वाले डेटासेट को पहली बार हमारी टीम द्वारा बनाया और एनोटेट किया जाता है, जो फ्रेंच में इस तरह के विश्लेषणात्मक डेटासेट के अंतर को भरता है। हम फ्रांसीसी ट्वीट्स के लिए विश्लेषणात्मक कार्यों में भविष्य के अनुसंधान को बढ़ावा देने के उद्देश्य से ट्रांसफॉर्मर लाइब्रेरी में अपने मॉडल को सार्वजनिक रूप से उपलब्ध कराते हैं।</abstract_hi>
      <abstract_ru>Мы представляем BERTweetFR - первую масштабную предварительно обученную языковую модель для французских твитов. Наша модель инициализирована с использованием общедоменной модели французского языка CamemBERT, которая следует базовой архитектуре BERT. Эксперименты показывают, что BERTweetFR превосходит все предыдущие общедоменные модели французского языка по двум нижестоящим задачам Twitter NLP по идентификации наступательности и распознаванию именованных сущностей. Набор данных, используемый в задаче обнаружения наступательности, сначала создается и аннотируется нашей командой, заполняя пробел таких аналитических наборов данных на французском языке. Мы делаем нашу модель общедоступной в библиотеке трансформаторов с целью продвижения будущих исследований в аналитических задачах для французских твитов.</abstract_ru>
      <abstract_ga>Cuirimid BERTweetFR i láthair, an chéad mhúnla teanga réamhoilte ar mhórscála le haghaidh tweets Fraincise. Cuirtear ár samhail inisealaithe ag baint úsáide as múnla Fraincise ginearálta-fearainn CamemBERT a leanann bun-ailtireacht BERT. Léiríonn turgnaimh go n-éiríonn le BERTweetFR gach samhail teanga Fraincise ginearálta a bhí ann roimhe seo ar dhá thasc iartheachtacha Twitter NLP maidir le haithint maslaí agus aithint aonáin ainmnithe. Déanann ár bhfoireann an tacar sonraí a úsáideadh sa tasc braite maslaí a chruthú agus a anótáil ar dtús, ag líonadh bearna na dtacar sonraí anailíse sin sa Fhraincis. Cuirimid ár múnla ar fáil go poiblí i leabharlann na gclaochladáin agus é mar aidhm againn taighde a chur chun cinn sa todhchaí ar thascanna anailíse le haghaidh tweetanna Francacha.</abstract_ga>
      <abstract_ka>ჩვენ შევცვალოთ BERTweetFR, პირველი დიდი მაგალითი წინატრინული ტივიტებისთვის მოდელი. ჩვენი მოდელი დაიწყება, რომელიც BERT-ის ბაზის აქტიქტურაცია გამოყენებული ფრანუს ენის მოდელს გამოყენებით. Experiments show that BERTweetFR performs all previous general-domain language models on two downstream Twitter NLP tasks of offensiveness identification and named entity recognition. მონაცემების სექტი, რომელიც გამოიყენებულია მონაცემების განახლებაში, პირველად ჩვენი ჯგუფი შექმნილია და მონაცემებულია, რომელიც ასეთი ანალიტიკური მონაცემების გან ჩვენ ჩვენი მოდელის ადგილურად გავაკეთებთ ტრანფორმაციის ლიბიტურაში, მიზეზით, რომ მომავალეთ ანალიტიკური დავაკეთებაში ფრანქსის ტვიტებისთვის მომავალ</abstract_ka>
      <abstract_el>Παρουσιάζουμε το πρώτο μεγάλης κλίμακας προσχεδιασμένο γλωσσικό μοντέλο για γαλλικά tweets. Το μοντέλο μας αρχικοποιείται χρησιμοποιώντας ένα γενικό γαλλικό μοντέλο που ακολουθεί τη βασική αρχιτεκτονική του BERT. Τα πειράματα δείχνουν ότι το BERTweetFR ξεπερνά όλα τα προηγούμενα γαλλικά μοντέλα γενικού τομέα σε δύο μεταγενέστερες εργασίες του Twitter NLP αναγνώρισης επιθετικότητας και αναγνώρισης ονομαστικής οντότητας. Το σύνολο δεδομένων που χρησιμοποιείται στην εργασία ανίχνευσης επιθετικότητας δημιουργείται πρώτα και σχολιάζεται από την ομάδα μας, συμπληρώνοντας το κενό τέτοιων αναλυτικών συνόλων δεδομένων στα γαλλικά. Κάνουμε το μοντέλο μας δημοσίως διαθέσιμο στη βιβλιοθήκη μετασχηματιστών με στόχο την προώθηση της μελλοντικής έρευνας σε αναλυτικά καθήκοντα για γαλλικά tweets.</abstract_el>
      <abstract_hu>Bemutatjuk a BERTweetFR-t, az első nagyszabású, előképzett nyelvi modellt a francia tweetekhez. Modellünket egy általános domain francia nyelvű CamemBERT modellel inicializáljuk, amely a BERT alaparchitektúráját követi. A kísérletek azt mutatják, hogy a BERTweetFR az összes korábbi általános tartományú francia nyelvű modellt felülmúlja két további Twitter NLP feladaton, az offenzivitás azonosításán és a nevezett entitás felismerésén. Az offenzivitás felismerési feladat során használt adatkészletet először csapatunk hozza létre és jegyzeteli meg, ezzel kitölti az ilyen analitikai adatkészletek hiányát francia nyelven. Modellünket nyilvánosan hozzáférhetővé tesszük a transzformátorok könyvtárában azzal a céllal, hogy elősegítsük a francia tweetek analitikai feladatainak jövőbeni kutatását.</abstract_hu>
      <abstract_it>Presentiamo BERTweetFR, il primo modello linguistico pre-formato su larga scala per i tweet francesi. Il nostro modello è inizializzato utilizzando un modello di lingua francese di dominio generale CamemBERT che segue l'architettura di base di BERT. Gli esperimenti dimostrano che BERTweetFR supera tutti i precedenti modelli di lingua francese di dominio generale su due compiti a valle di Twitter NLP: identificazione dell'offensività e riconoscimento delle entità denominate. Il set di dati utilizzato nel compito di rilevamento dell'offensività viene creato e annotato dal nostro team, colmando il gap di tali set di dati analitici in francese. Rendiamo il nostro modello disponibile pubblicamente nella libreria dei trasformatori con l'obiettivo di promuovere la ricerca futura in compiti analitici per i tweet francesi.</abstract_it>
      <abstract_lt>Pateikiame BERTweetFR, pirmąjį plataus masto išankstinio mokymo kalbų model į prancūzų tweetams. Mūsų model is inicijuojamas naudojant bendrąjį prancūzų kalbos model į CamemBERT, kuris atitinka pagrindinę BERT architektūrą. Experiments show that BERTweetFR outperforms all previous general-domain French language models on two downstream Twitter NLP tasks of offensiveness identification and named entity recognition.  Mūsų komanda pirmą kartą sukuria ir užrašo duomenų rinkinį, kuris užpildo tokių analizinių duomenų rinkinių spragas prancūzų kalba. Mūsų model į skelbiame viešai transformatorių bibliotekoje, siekiant skatinti būsimus mokslinius tyrimus, susijusius su Prancūzijos tweetų analitinėmis užduotimis.</abstract_lt>
      <abstract_mk>Го претставуваме BERTweetFR, првиот голем предобучен јазик модел за француски твитови. Нашиот модел е иницијализиран користејќи генерален модел на француски јазик CamemBERT кој ја следи базата на архитектурата на BERT. Експериментите покажуваат дека BERTweetFR ги надминува сите претходни модели на генерален француски јазик на генерален домен на две задачи на Твитер НЛП за идентификација на навредливост и препознавање на именуваниот ентитет. Податоците кои се користат во задачата за детекција на навредливост првпат се создаваат и анотираат од нашиот тим, пополнувајќи ја празнината на ваквите аналитички податоци на француски. Нашиот модел го обезбедуваме јавно во библиотеката на трансформаторите со цел промовирање на идното истражување во аналитичките задачи за француските твитови.</abstract_mk>
      <abstract_kk>Біз BERTweetFR-ді, французша tweets үшін бірінші үлкен үлкен тіл үлгісін келтіреміз. Біздің үлгіміз BERT негізгі архитектурасына келеді француз тіл үлгісін қолданып инициализацияланды. Тәжірибелер BERTweetFR барлық алдыңғы жалпы доменге француз тіл үлгілерін екі төменгі Twitter NLP тапсырмаларының оқушылық идентификациясын және аталған нысанды анықтау үлгілерінен шығарып жа Біріншіден бірінші командамызды анықтау тапсырмасында қолданылатын деректер жиыны құру және белгілеп, французша аналитикалық деректер жиындарының аралығын толтыру. Біз моделімізді французша tweets үшін аналитикалық тапсырмаларды аналитикалық тапсырмалардың алдындағы зерттеулердің кітапханасында жалпы түрде қол жеткіземіз.</abstract_kk>
      <abstract_ms>Kami perkenalkan BERTweetFR, model bahasa pertama yang dilatih untuk tweet Perancis. Model kami diawalkan menggunakan model bahasa Perancis domain-umum CamemBERT yang mengikut arkitektur asas BERT. Eksperimen menunjukkan bahawa BERTweetFR melampaui semua model bahasa Perancis domain umum terdahulu pada dua tugas NLP turun Twitter pengenalan ofensif dan pengenalan entiti bernama. Set data yang digunakan dalam tugas pengesan ofensif pertama dicipta dan dicatat oleh pasukan kami, mengisi ruang set data analitik dalam bahasa Perancis. We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</abstract_ms>
      <abstract_mt>Aħna nintroduċu BERTweetFR, l-ewwel mudell lingwistiku mħarreġ minn qabel fuq skala kbira għal tweets Franċiżi. Il-mudell tagħna huwa inizjalizzat bl-użu ta’ mudell tal-lingwa Franċiża b’dominju ġenerali CamemBERT li jsegwi l-arkitettura bażi tal-BERT. L-esperimenti juru li l-BERTweetFR jaqbeż il-mudelli kollha preċedenti tal-lingwa Franċiża ta’ dominju ġenerali fuq żewġ kompiti downstream tal-NLP ta’ Twitter ta’ identifikazzjoni ta’ offensività u rikonoxximent tal-entità msemmi. Is-sett tad-dejta użat fil-kompitu ta’ detezzjoni tal-offensività huwa l-ewwel maħluq u annotat mit-tim tagħna, li jimla d-distakk ta’ settijiet tad-dejta analitiċi bħal dawn bil-Franċiż. Aħna nagħmlu l-mudell tagħna disponibbli għall-pubbliku fil-librerija tat-trasformaturi bil-għan li nippromwovu riċerka futura fil-kompiti analitiċi għat-tweets Franċiżi.</abstract_mt>
      <abstract_ml>ഫ്രെഞ്ച് ടൈറ്റുകള്‍ക്ക് ആദ്യത്തെ വലിയ മുന്‍പരിശീലന ഭാഷ മോഡല്‍ ബെര്‍ട്ടിട്ട് FR-നെ പരിചയപ്പെടുത്തുന്നു. നമ്മുടെ മോഡല്‍ തുടങ്ങിയിരിക്കുന്നു. ബെര്‍ട്ടിന്റെ അടിസ്ഥാനത്തിന്റെ അടിസ്ഥാനം പിന്തുടരുന്ന ഒരു ജനറല്‍- ഡൊമെയിന പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു BERTweetFR മുമ്പ് സാധാരണ-ഡൊമെയിന്‍ ഫ്രെഞ്ച് ഭാഷ മോഡലുകള്‍ പ്രവര്‍ത്തിപ്പിക്കുന്നത് രണ്ട് ത The dataset used in the offensiveness detection task is first created and annotated by our team, filling in the gap of such analytic datasets in French.  ഫ്രെഞ്ച് ടൂട്ടുകള്‍ക്കായി ഭാവിയായ പരിശോധന നടത്താനുള്ള ലക്ഷ്യത്തില്‍ ഞങ്ങള്‍ ഞങ്ങളുടെ മോഡല്‍ പ്രസ്താവിക്കുന്നു.</abstract_ml>
      <abstract_mn>Бид BERTweetFR-г Француз tweets-ын анхны том хэлний сургалтын загварыг танилцуулдаг. Бидний загвар нь Француз хэл загварын ерөнхий хэл загвар CamemBERT-г ашиглаж эхэлсэн. Энэ нь BERT-ын суурь архитектурыг дагадаг. Түүний туршилтууд BERTweetFR нь өмнө нь Француз хэл загваруудыг нэрлэж, нэрлэж буй хүмүүсийн танихын тулд Twitter NLP-ийн хоёр доорх даалгаварын ажил дээр гаргаж байгааг харуулдаг. Манай баг анхны шинжилгээний өгөгдлийн сангууд Французчаар ийм шинжилгээний өгөгдлийн сангуудын ялгааг дүүргэдэг. Бид өөрчлөгчийн номын санд загварыг олон нийтэд ашиглан Француз tweets-ын шинжилгээний ажлыг дэмжих зорилготой.</abstract_mn>
      <abstract_pl>Przedstawiamy BERTweetFR, pierwszy wielkoskalowy wstępnie przeszkolony model językowy dla francuskich tweetów. Nasz model jest inicjalizowany przy użyciu generalnego modelu języka francuskiego CamemBERT, który opiera się na podstawowej architekturze BERT. Eksperymenty pokazują, że BERTweetFR przewyższa wszystkie poprzednie generalne modele języka francuskiego w dwóch dalszych zadaniach NLP Twittera: identyfikacji ofensywności i rozpoznawania nazwanych podmiotów. Zestaw danych wykorzystywany w zadaniu wykrywania ofensywności jest najpierw tworzony i adnotacjonowany przez nasz zespół, wypełniając lukę takich zbiorów analitycznych w języku francuskim. Nasz model udostępniamy publicznie w bibliotece transformatorów w celu promowania przyszłych badań nad zadaniami analitycznymi dla francuskich tweetów.</abstract_pl>
      <abstract_ro>Introducem BERTweetFR, primul model lingvistic pre-instruit la scară largă pentru tweeturile franceze. Modelul nostru este inițializat folosind un model de limbă franceză de domeniu general CamemBERT, care urmează arhitectura de bază a BERT. Experimentele arată că BERTweetFR depășește toate modelele anterioare de limbă franceză de domeniu general în două sarcini din aval Twitter NLP de identificare a ofensivității și recunoaștere a entităților denumite. Setul de date utilizat în sarcina de detectare a ofensivității este creat și adnotat mai întâi de echipa noastră, umplând golul unor astfel de seturi de date analitice în limba franceză. Facem modelul nostru disponibil public în biblioteca transformatoarelor cu scopul de a promova cercetarea viitoare în sarcini analitice pentru tweeturile franceze.</abstract_ro>
      <abstract_no>Vi introduserer BERTweetFR, den første storskala første språk- modellen for fransk tweets. Modellen vårt er starta med ein generell- domenespråk- modell CamemBERT som følgjer basearkitekturen av BERT. Eksperimentar viser at BERTweetFR utfører alle førre generelle domene fransk språk-modeller på to nedstrekke Twitter NLP-oppgåver med offensivitetsidentifisering og gjenkjenning av entitet. Datasettet som vert brukt i oppgåva for offensivitet er først oppretta og oppmerkt av gruppa vår, og fyller mellomrom på slike analytiske datasett i fransk. Vi gjer modellen vårt offentlig tilgjengeleg i transformeringsbiblioteket med målet om framtidige forskning i analytiske oppgåver for franske tweet.</abstract_no>
      <abstract_so>Waxaannu soo bandhignaa BERTweetFR, tilmaamaha afka ugu horeysa ee ugu horeysa oo la baray afka Faraansiis ee TweetFR. Tusaalkayaga waxaa la bilaabay tusaale ahaan afka faransiiska ee ugu horeeya CamemBERT oo raacaya dhismaha aasaasiga ah ee BERT. Imtixaanka waxaa ka muuqda in BERTweetFR uu soo saaray dhammaan models oo afka faransiga ah ee hore oo general-domain French-language on two downstream Twitter NLP tasks of aqoonsiga dembilayaasha iyo magaca aqoonsiga entity. Macluumaadka looga isticmaali karo shaqada dembiga waxaa marka hore la abuuraa oo la dhibayo kooxdayaga, waxayna buuxiyaan burburka sawiradaas oo afka Faranshka ah. Tusaaleheenna si bayaan ah ayaannu u isticmaalnaa maktabadda is-beddelka, taas oo loogu talogalay in lagu horumariyo waxbarashada mustaqbalka ah oo lagu beddelo shaqooyinka baalalka ah ee twitter Faransiis.</abstract_so>
      <abstract_sr>Predstavljamo BERTweetFR, prvi veliki predobučeni jezički model za francuske tweets. Naš model je inicijaliziran koristeći općeg francuskog jezičkog model a CamemBERT koji prati baznu arhitekturu BERT-a. Eksperimenti pokazuju da BERTweetFR iznosi sve prethodne francuske jezičke modele u generalnom domenu na dva nedalekog zadatka Twitter NLP-a identifikacije ofenzivnosti i priznanja entiteta. Podaci koji su koristili u zadatku otkrivanja ofenzivnosti su prvi put stvorili i annotirali naš tim, ispunjavajući prazninu takvih analitičkih podataka na francuskom. Naš model je javno dostupan u biblioteci transformera sa ciljem unapređenja budućih istraživanja u analitičkim zadatkima za francuske tweets.</abstract_sr>
      <abstract_sv>Vi introducerar BERTweetFR, den första storskaliga förklädda språkmodellen för franska tweets. Vår modell initieras med hjälp av en allmän fransk språkmodell CamemBERT som följer BERT:s grundarkitektur. Experiment visar att BERTweetFR presterar bättre än alla tidigare allmänna franska språkmodeller på två senare Twitters NLP-uppgifter, nämligen offensivitetsidentifiering och namngiven entitetsigenkänning. Datauppsättningen som används för detekteringen av offensivitet skapas och kommenteras först av vårt team, vilket fyller i luckan i sådana analytiska datauppsättningar på franska. Vi gör vår modell offentligt tillgänglig i transformatorbiblioteket i syfte att främja framtida forskning inom analytiska uppgifter för franska tweets.</abstract_sv>
      <abstract_ta>BERTweetFR, முதல் பெரிய அளவு முன் பயிற்சி மொழி மாதிரியை நாம் குறிப்பிடுகிறோம். எங்கள் மாதிரி துவங்கப்பட்டுள்ளது பிரெட்டின் அடிப்படை உருவாக்கத்தைப் பின்பற்றும் பொதுவான- டோமைன் மொழி மாதிரி கே பரிசோதனைகள் BERTweetFR முந்தைய பொது டொமென் மொழி மொழி மாதிரிகளை வெளியேற்றுகிறது என்பதை காட்டுகிறது என்பது பிரெட்டுவிட்டால் இரு கீழ் த குற்றமில்லாத கண்டுபிடிப்பு பணியில் பயன்படுத்தப்பட்ட தகவல் அமைப்பு முதலில் எங்கள் குழு உருவாக்கப்பட்டுள்ளது மற்றும் துக்கப்படு நாங்கள் எங்கள் மாதிரி பொதுவாக கிடைக்கும் மாற்றங்கள் நூலகத்தில் பொதுவாக அனுப்புகிறோம் பிரெஞ்சு டிவிட்டுக்</abstract_ta>
      <abstract_ur>ہم نے BERTweetFR کو معرفی کریں، فرانسوی ٹویٹ کے لئے پہلی بڑی استعمال کی زبان کی مدل۔ ہمارا موڈل ایک فرانسوی زبان کی مدل کاممBERT کے مطابق آغاز کی گئی ہے جو BERT کی بنیاد معماری کے پیچھے چلتی ہے. تجربے دکھاتے ہیں کہ BERTweetFR تمام پہلے عمومی-ڈومین فرانسوی زبان مدل کو دو نیچے سطح توئیٹر NLP کے کاموں میں فساد شناسایی اور نام داری شناسایی کے ذریعہ نکالتا ہے. فانسیونس ڈیٹ سٹ کو پہلی بار ہمارے تیم سے پیدا کیا گیا ہے اور اظہار کیا گیا ہے، اس طرح فرنسیس میں ایسی تحلیل ڈیٹ سٹ کا فاصلہ پورا کرتا ہے۔ ہم نے ہمارا مدل فرانسوی ٹویٹوں کے لئے تحلیل کے کاموں میں پیش آنے کے مطابق تبدیل کرنے والوں کی لائیبری میں ظاہر طور پر موجود بنایا ہے۔</abstract_ur>
      <abstract_si>අපි BERTWEtFR විදිහට ප්‍රථම විශාල ප්‍රධානය කරපු භාෂාව ප්‍රධානය කරපු භාෂාව ප්‍රධානය කරනවා. අපේ මොඩල් පටන් ගත්තා පටන් ගත්තා ප්‍රංශි භාෂාවක් නිර්මාණය CamemBERT වලින් පටන් ගත්තා. පරීක්ෂණය පෙන්වන්නේ BERTWEtFR පිළිබඳ සියළුම සාමාන්‍ය-ඩෝමින් ෆ්‍රෑන්ස් භාෂා මොඩේල්ස් දෙකක් පිළිබඳු Twitter NLP වැඩේ  අපේ කණ්ඩායමෙන් පළමු සිද්ධ විශ්ලේෂණ දත්ත සෙට් ප්‍රවේශ කරලා තියෙන්නේ අපේ කණ්ඩායමෙන් ප්‍රවේශ කරලා තියෙන්නේ  අපි අපේ මොඩල් සාමාන්‍යයෙන් ප්‍රවේශකයේ පුළුවන් වෙන්න පුළුවන් වෙන්නේ ෆ්‍රෑන්ස් ට්විට්ට් වලට අනාගතයේ</abstract_si>
      <abstract_uz>Biz BERTweetFR, Fransuzcha Twitterlar uchun birinchi katta taʼminlovchi tilning modeli. Bizning modelimiz BERT asosiy arxituvchisi bilan birinchi darajada Fransuz tili modeli bilan ishga tushirilgan. Name Faylni aniqlash vazifasida ishlatilgan maʼlumotlar tarkibi birinchi guruhimizdan yaratiladi va tajriba qiladi. Bunday analytik maʼlumotlar tarkibini Fransuzcha soʻzda toʻldirish. Biz modelimizni o'zgarishlar kutubxonasida publicly imkoniyat qilamiz. Birinchi qanday o'qishni analytik vazifalarda o'rganish uchun o'zgarishlar kutubxonasida.</abstract_uz>
      <abstract_vi>Chúng tôi giới thiệu BERTweeter, mẫu ngôn ngữ đầu tiên được đào tạo trên phổ biến của tiếng Pháp. Mô hình của chúng tôi được khởi tạo bằng một mô hình ngôn ngữ Pháp chung thuộc, CamemBERT theo cấu trúc căn cứ của BERT. Các thí nghiệm cho thấy rằng BERTweeter đã hoàn thành tất cả các mô hình tiếng Pháp phổ biến trước đó trên hai công việc nhận diện mạo phạm tội và nhận diện thực thể tên tuổi. Bộ dữ liệu được dùng trong nhiệm vụ tìm ra mức độ tấn công được tạo ra và ghi chú bởi nhóm chúng tôi, lấp đầy khoảng trống của các bộ dữ liệu phân tích bằng tiếng Pháp. Chúng tôi công bố mẫu của mình trong thư viện chuyển hóa với mục đích phát triển nghiên cứu về các công việc phân tích của người Pháp trên Twitter.</abstract_vi>
      <abstract_nl>We introduceren BERTweetFR, het eerste grootschalige voorgetrainde taalmodel voor Franse tweets. Ons model is geïnitialiseerd met behulp van een algemeen-domein Frans taalmodel CamemBERT dat de basisarchitectuur van BERT volgt. Experimenten tonen aan dat BERTweetFR alle eerdere Franse taalmodellen voor algemeen domein overtreft op twee downstream Twitter NLP-taken van offensieve identificatie en naamsbekendheid. De dataset die wordt gebruikt voor de detectie van aanvallen wordt eerst gemaakt en geannoteerd door ons team, waardoor de lacune van dergelijke analytische datasets in het Frans wordt opgevuld. We maken ons model publiekelijk beschikbaar in de transformatorbibliotheek met als doel toekomstig onderzoek naar analytische taken voor Franse tweets te bevorderen.</abstract_nl>
      <abstract_bg>Представяме първия мащабен предварително обучен езиков модел за френски туитове. Нашият модел е инициализиран с помощта на общ домейн френски език модел който следва базовата архитектура на BERT. Експериментите показват, че BERTweetFR превъзхожда всички предишни модели на френски език с общ домейн при две задачи надолу по веригата на Туитър НЛП за идентифициране на нападателите и разпознаване на наименованите субекти. Наборът от данни, използван в задачата за откриване на нападение, първо се създава и анотира от нашия екип, запълвайки празнината на такива аналитични набори от данни на френски език. Ние правим нашия модел публично достъпен в библиотеката с трансформатори с цел насърчаване на бъдещи изследвания в аналитични задачи за френски туитове.</abstract_bg>
      <abstract_da>Vi introducerer BERTweetFR, den første store præuddannede sprogmodel til franske tweets. Vores model er initialiseret ved hjælp af en almindelig fransk model CamemBERT, som følger BERT's basisarkitektur. Eksperimenter viser, at BERTweetFR udfører alle tidligere franske sprogmodeller på to efterfølgende Twitter-NLP-opgaver med identifikation af offensivitet og navngivne enheder. Datasættet, der anvendes i opgaven til detektering af offensivitet, oprettes og kommenteres først af vores team, hvilket udfylder hullet i sådanne analytiske datasæt på fransk. Vi gør vores model offentligt tilgængelig i transformatorbiblioteket med det formål at fremme fremtidig forskning i analytiske opgaver til franske tweets.</abstract_da>
      <abstract_hr>Predstavljamo BERTweetFR, prvi veliki predobučeni jezički model za francuske tweets. Naš model je inicijaliziran s općem domenu francuskog jezičkog model a CamemBERT koji prati baznu arhitekturu BERT-a. Eksperimenti pokazuju da BERTweetFR iznosi sve prethodne francuske jezičke modele u generalnom domenu na dva nedalekog zadatka Twitter NLP-a identifikacije ofenzivnosti i priznanja entiteta. Podaci koje se koriste u zadatku otkrivanja ofenzivnosti prvo su stvorili i navodili naš tim, ispunjavajući prazninu takvih analitičkih podataka na francuskom. Objavljujemo naš model u biblioteci transformera s ciljem unapređenja budućih istraživanja u analitičkim zadatkima za francuske tweets.</abstract_hr>
      <abstract_id>Kami memperkenalkan BERTweetFR, model bahasa besar pertama yang terlatih untuk tweet Perancis. Model kami diinisialisasikan menggunakan model bahasa Perancis domain umum CamemBERT yang mengikuti arsitektur dasar BERT. Eksperimen menunjukkan bahwa BERTweetFR melampaui semua model bahasa Perancis domain umum sebelumnya pada dua tugas NLP Twitter turun dari identifikasi ofensif dan pengenalan entitas bernama. Set data yang digunakan dalam tugas deteksi ofensif pertama dibuat dan anotasi oleh tim kami, mengisi ruang dari set data analitis seperti itu dalam bahasa Perancis. Kami membuat model kami tersedia publik di perpustakaan transformer dengan tujuan mempromosikan penelitian masa depan dalam tugas analitis untuk tweet Perancis.</abstract_id>
      <abstract_de>Wir stellen BERTweetFR vor, das erste großformatige vortrainierte Sprachmodell für französische Tweets. Unser Modell wird mit einem allgemeinen französischen Sprachmodell CamemBERT initialisiert, das der Basisarchitektur von BERT folgt. Experimente zeigen, dass BERTweetFR bei zwei nachgelagerten Twitter NLP-Aufgaben der Offensivitätsidentifikation und Namenserkennung alle bisherigen französischen Sprachmodelle für allgemeine Domänen übertrifft. Der Datensatz, der für die Offensivitätserkennung verwendet wird, wird zuerst von unserem Team erstellt und kommentiert, wodurch die Lücke solcher analytischen Datensätze auf Französisch geschlossen wird. Wir stellen unser Modell in der Transformatorenbibliothek öffentlich zur Verfügung, um zukünftige Forschung zu analytischen Aufgaben für französische Tweets zu fördern.</abstract_de>
      <abstract_ko>프랑스어 트윗을 겨냥한 최초의 대규모 예훈련 언어 모델인 BERTweetFR을 소개합니다.우리의 모델은 유니버설 영역의 프랑스어 모델인 CamemBERT를 사용하여 초기화된 것으로 이 모델은 BERT의 기본 구조를 따른다.실험에 따르면 BERTweetFR은 공격적인 식별과 명명된 실체 식별 두 개의 하위 트위터 NLP 임무에서 이전의 통용적인 분야인 프랑스어 모델보다 우수한 모습을 보였다.공격적 탐지 임무에 사용된 데이터 집합은 먼저 우리 팀에서 만들고 주석을 달아 프랑스어 분석 데이터 집합의 공백을 메웠다.우리는 트랜스포머 도서관에서 우리의 모델을 공개했는데 그 목적은 앞으로 프랑스어 추문 분석 임무에 대한 연구를 추진하는 것이다.</abstract_ko>
      <abstract_fa>ما اولین مدل زبان پیش آموزش برای تویتهای فرانسوی BERTweetFR را معرفی می کنیم. مدل ما با استفاده از مدل زبان فرانسوی ژنرال آغاز شده است CamemBERT که از معماری بنیادی BERT پیروی می کند. تجربه‌ها نشان می‌دهند که BERTweetFR تمام مدل‌های زبان فرانسوی ژنرال ژنرال قبلی را در دو کار پایین توئیتر NLP از شناسایی شناسایی نافرمانی و شناسایی عنوان entity انجام می‌دهد. مجموعه داده‌ها که در کار شناسایی نافرمانی استفاده می‌شود، اول توسط تیم ما ایجاد شده و توضیح داده می‌شود، که در فاصله‌های چنین مجموعه داده‌های تحلیل در فرانسوی پر می‌شود. ما مدل خود را در کتابخانه تغییر دهندگان با هدف تحقیقات آینده در کار تحلیل برای tweets فرانسوی به طور عمومی در دسترس می دهیم.</abstract_fa>
      <abstract_sw>Tunawasilisha BERTweetFR, mtindo wa kwanza wa lugha iliyoendelea kwa ajili ya twiti za Kifaransa. Mradi wetu umeanzishwa kwa kutumia muundo wa lugha ya Kifaransa wa kawaida CamemBERT ambao unafuata ujenzi wa msingi wa BERT. Experiments show that BERTweetFR outperforms all previous general-domain French language models on two downstream Twitter NLP tasks of offensiveness identification and named entity recognition.  Taarifa zinazotumiwa katika kazi ya kutambua makosa ya jinai imetengenezwa na kusikitishwa na timu yetu, ikijaza katika tofauti ya seti za taarifa hizo za uchambuzi kwa lugha ya Kifaransa. Tunafanya mifano yetu kwa uwazi katika maktaba ya mabadiliko kwa lengo la kukuza utafiti wa baadaye katika kazi za uchambuzi kwa twiti za Kifaransa.</abstract_sw>
      <abstract_sq>Ne prezantojmë BERTweetFR, modelin e parë të gjuhës së stërvitur në shkallë të madhe për tweetet franceze. Modeli ynë është inicializuar duke përdorur një model gjuhësh të përgjithshme të domenit francez CamemBERT që ndjek arkitekturën bazë të BERT. Eksperimentet tregojnë se BERTweetFR paraqet të gjitha modelet e mëparshme të gjuhës së përgjithshme franceze në dy detyra poshtë në Twitter NLP të identifikimit të ofensivës dhe njohjes së emëruar të njësisë. Të dhënat e përdorura në detyrën e zbulimit të ofensivës krijohen dhe shënohen së pari nga ekipi ynë, duke mbushur boshllëkun e të dhënave të tilla analitike në francez. We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</abstract_sq>
      <abstract_tr>Biz BERTweetFR'i Fransuz tweetleri üçin ilkinji uly ölçekli dil nusgasyny tanyşdyrýarys. Biziň nusgasymyz BERT'yň esasy arhitekturuny ulanyp başlady. Denminatlar BERTweetFR öňki dünýä-domena fransuz dil nusgalarynyň 2 aşaky Twitter NLP hili işini tanamak we diýip atlandyrylýan nusgalarynyň üstine çykarýandygyny görkez. Gymmatçilik tanyşynyň işinde ullanýan veri seti biziň toparymyzyň tarapyndan ilkinji döredildi we täzeleştirildi. Bu ýaly analytik datasetleriň gapysyny Fransuzça doldurulýar. Biz modelimizi fransuz tweets üçin gelejekde analitik zadalary terjime etmek üçin transformer kitaphanesinde publika mejbur edip bilýäris.</abstract_tr>
      <abstract_af>Ons introduiseer BERTweetFR, die eerste groot-skaal voor-opgelei taal model vir Frans tweets. Ons model is geïnisialiseer deur gebruik van 'n algemene- domein Franse taal model CamemBERT wat volg die basis arkitektuur van BERT. Eksperimente vertoon dat BERTweetFR al die vorige generale-domein Frans taal modele uitvoer op twee onderstreem Twitter NLP opdragte van offensivenes identifikasie en genoem entiteiterkenning. Die datastel wat gebruik word in die onbeskerming opdekking opdrag is eerste geskep en aangetel deur ons span, met die afstand van sodanige analitiese datastel in Frans opvul. Ons maak ons model openlik beskikbaar in die transformers biblioteek met die doel om toekomstige ondersoek in analysiese taak vir Frans tweets te verkondig.</abstract_af>
      <abstract_am>BERTweetFR፣ የፊተኛው ትልቁ የቋንቋ ምሳሌ ለፈረንሳይ ትዊተሮች እናስታውቃለን፡፡ ሞዴሌያችን የብERT መሠረት መሠረት የሚከተለውን የፍሪስዊ ቋንቋ ምሳሌ በተጠቃሚ ነው፡፡ ፈተናዎች BERTweetFR የቀድሞውን የውይይት አረንሳይ-domain-ፈረንሳይ ቋንቋ ሞዴላዎችን በሁለቱ ውስጥና በትዊተር ትዊተር NLP ስራ የስሕተት ማወቃየት እና አካባቢ ማውቀትን የተባለውን ነው፡፡ በአሳማሚ ስራ ውስጥ የሚጠቀሙት ዳታተር በመጀመሪያ የተፈጠረ እና አሰቃየ በፋንሳይኛ እንደዚህ የዳታ አዳራሲ በመፍረስ በሚሞላበት ውጤት ነው፡፡ ለፈረንሳይ ትዊተሮች ለፍሪስኛ ትዊተሮችን ለመጠንቀቂያ ትርጓሜዎችን ለማድረግ በመለወጥ መጻሕፍት እናደርጋለን፡፡</abstract_am>
      <abstract_hy>Մենք ներկայացնում ենք BERWEtRF-ը, ֆրանսիական թվիթերի համար առաջին մեծ նախապատրաստված լեզվի մոդելը: Մեր մոդելը նախաձեռնվում է օգտագործելով ընդհանուր ֆրանսերեն լեզվի մոդելը, որը հետևում է BER-ի հիմնական ճարտարապետությանը: Փորձարկումները ցույց են տալիս, որ BERWEtRF-ը արտադրում է բոլոր նախորդ ընդհանուր ֆրանսերեն լեզվի մոդելները երկու հետագա Թվիթերի ՆԼՊ-ի առաջադրանքներում, որոնք նշանակում են հայտնաբերություն և անվանումներ: Առաջին անգամ մեր թիմը ստեղծում է և նկարագրում է այդ տվյալների համակարգը, որը լցնում է ֆրանսերենի այս վերլուծության տվյալների բացառությունը: Մենք մեր մոդելը հանրային հասանելիություն ենք դարձնում վերափոխողների գրադարանում, որպեսզի առաջացնենք ապագա հետազոտությունները ֆրանսիացի թվիթերի վերլուծության խնդիրներում:</abstract_hy>
      <abstract_az>Biz BERTweetFR'i, Fransız tweets üçün ilk böyük ölçüdə öyrənmiş dil modelini tanıdırıq. Bizim modellərimiz BERT'in əsas arhitektürünün ardınca gələn general-domain Fransız dil modeli ilə başlanğıçlandırılmışdır. Experiments göstərir ki, BERTweetFR, 2 aşağıdaki Twitter NLP günahsızlıq tanıması və adı verilən entitə tanıması üçün bütün əvvəlki general-domain Fransız dil modellerini daha üstün etmişdir. Belə analitik veri qurğuları Fransız dilində doldurur. Biz modellərimizi Fransız tweetlərin analitik işlərində gələcək təhsil etmək məqsədilə transformer kütüphanəsində yayınlaşdırırıq.</abstract_az>
      <abstract_bn>ফ্রেঞ্চ টুইটের জন্য প্রথম বিশাল প্রশিক্ষিত ভাষার মডেল বেরুটুইটএফআর-কে আমরা পরিচয় করিয়ে দিচ্ছি। আমাদের মডেল শুরু করা হয়েছে একটি জেনারেল-ডোমেইন ফরাসি ভাষার মডেল ক্যামেমবের্ট, যা বাইরেটের ভিত্তিক কাঠামো অনুসরণ কর পরীক্ষা দেখাচ্ছে যে বেরুটুইটারএফআর পূর্ববর্তী সাধারণ-ডোমেইন ফ্রেঞ্চ ভাষার মডেল দুটি নিচের টুইটার এনএলপি অপরাধীদের পরিচিতি এবং প্রত অপরাধী সনাক্ত করার কাজে ব্যবহার করা ডাটাসেট প্রথমে আমাদের দল তৈরি এবং বিরক্তিকর, ফ্রেঞ্চে এই ধরনের বিশ্লেষণীয় তথ্যের মধ্যে পূর্ ফ্রেঞ্চ টুইটের বিশ্লেষণীয় কাজে ভবিষ্যতের গবেষণা প্রচারের উদ্দেশ্যে আমরা আমাদের মডেল প্রকাশ্যে পাওয়া যাচ্ছি।</abstract_bn>
      <abstract_et>Tutvustame BERTweetFR-i, esimest suuremahulist eelõpetatud keelemudelit prantsuse säutsudele. Meie mudel on initsialiseeritud kasutades prantsuse keele üldmudelit CamemBERT, mis järgib BERT baasarhitektuuri. Katsed näitavad, et BERTweetFR ületab kõiki varasemaid prantsuse keele mudeleid kahe Twitteri uue programmi järgmise etapi ülesande puhul: rünnakute tuvastamine ja nimetatud üksuste tuvastamine. Rünnakute tuvastamise ülesandes kasutatud andmekogumi loob ja kommenteerib esmalt meie meeskond, täites selliste analüütiliste andmekogumite lünga prantsuse keeles. Teeme oma mudeli üldsusele kättesaadavaks trafode raamatukogus eesmärgiga edendada tulevasi uuringuid prantsuse säutsude analüütiliste ülesannete valdkonnas.</abstract_et>
      <abstract_ca>Introduïm BERTweetFR, el primer model de llenguatge pré-entrenat a gran escala per tweets francès. El nostre model es inicializa amb un model de domini general de llenguatge francès CamemBERT que segueix l'arquitectura bàsica de BERT. Els experiments demostren que BERTweetFR supera tots els models de llenguatge francès de domini general anteriors en dues tasques avançades de identificació d'ofensivitat a Twitter NLP i reconeixement d'entitats anomenats. El conjunt de dades utilitzat en la tasca de detecció de l'ofensivitat es crea i anota per primer cop pel nostre equip, llençant el buit d'aquests conjunts de dades analítiques en francès. We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</abstract_ca>
      <abstract_cs>Představujeme BERTweetFR, první rozsáhlý předškolený jazykový model pro francouzské tweety. Náš model je inicializován pomocí obecného francouzského jazykového modelu CamemBERT, který navazuje na základní architekturu BERT. Experimenty ukazují, že BERTweetFR překonává všechny předchozí modely francouzského jazyka obecné domény na dvou navazujících úkolech NLP Twitteru identifikace útočnosti a rozpoznávání pojmenovaných entit. Datová sada použitá při detekci útoku útoku je nejprve vytvořena a anotována naším týmem, čímž vyplňuje mezeru těchto analytických datových sad ve francouzštině. Náš model zveřejňujeme veřejně v knihovně transformátorů s cílem podpořit budoucí výzkum analytických úloh francouzských tweetů.</abstract_cs>
      <abstract_bs>Predstavljamo BERTweetFR, prvi veliki predobučeni jezički model za francuske tweets. Naš model je inicijaliziran s općem domenu francuskog jezičkog model a CamemBERT koji prati baznu arhitekturu BERT-a. Eksperimenti pokazuju da BERTweetFR nadmaže svim prethodnim francuskim jezičkim modelima u generalnoj domenu na dva nedavna zadatka Twitter NLP-a identifikacije ofenzivnosti i priznanja entiteta. Podaci koji se koriste u zadatku otkrivanja ofenzivnosti su prvi put stvorili i annotirali naš tim, ispunjavajući prazninu takvih analitičkih podataka na francuskom. Naš model je javno dostupan u biblioteci transformera sa ciljem unapređenja budućih istraživanja u analitičkim zadatkima za francuske tweets.</abstract_bs>
      <abstract_fi>Esittelemme BERTweetFR:n, ensimmäisen suuren mittakaavan esikoulutetun kielimallin ranskankielisille tweeteille. Mallimme on alustettu käyttäen yleistä ranskankielistä CamemBERT-mallia, joka noudattaa BERT:n perusarkkitehtuuria. Kokeet osoittavat, että BERTweetFR suoriutuu kaikista aiemmista yleisistä ranskankielisistä malleista kahdessa Twitterin NLP-toiminnon loppupään tehtävässä, jotka ovat hyökkäysten tunnistus ja nimetty kokonaisuus. Ryhmämme luo ja kommentoi ensin hyökkäystehtävässä käytettävän aineiston, joka täyttää tällaisten analyyttisten aineistojen aukon ranskaksi. Esitämme mallimme julkisesti saataville muuntajien kirjastossa tavoitteenamme edistää ranskalaisten twiittien analyyttisten tehtävien tutkimusta tulevaisuudessa.</abstract_fi>
      <abstract_sk>Predstavljamo vam BERTweetFR, prvi obsežni vnaprej usposobljen jezikovni model za francoske tweete. Naš model je inicializiran z uporabo splošnega domenskega francoskega jezikovnega modela CamemBERT, ki sledi osnovni arhitekturi BERT. Poskusi so pokazali, da BERTweetFR presega vse prejšnje modele francoskega jezika na splošni domeni pri dveh nadaljnjih nalogah Twitter NLP identifikacije napadalnosti in prepoznavanje imenovanih subjektov. Nabor podatkov, ki se uporablja pri opravilu odkrivanja napadalnosti, najprej ustvari in označi naša ekipa, s čimer zapolni vrzel takih analitičnih naborov podatkov v francoščini. Naš model je javno dostopen v knjižnici transformatorjev z namenom spodbujanja prihodnjih raziskav analitičnih nalog za francoske tweete.</abstract_sk>
      <abstract_he>אנחנו מציגים את BERTweetFR, המודל השפה הראשון במידה גדולה מאומן מראש לטוויטים צרפתיים. המודל שלנו מתחיל באמצעות מודל שפת צרפתית גנרלית שמעקב אחרי הארכיטקטורה הבסיסית של BERT. ניסויים מראים שברטווייט-פרק (BERTweetFR) פועל על כל דוגמני שפת צרפתית בשטח גנרלי קודם בשני משימות של טויטר NLP של זיהוי פגיעה ושם זיהוי ישות. קבוצת המידע שמשתמשת בתפקיד זיהוי הפגיעה נוצרה לראשונה ומכתבת על ידי הצוות שלנו, מלאה את הפער של קבוצות המידע הניתוחים האלה בצרפתית. אנו פועלים את המודל שלנו פנוי לציבור בספריית המעברים במטרה לקדם מחקר עתיד במשימות אנליטיות לטוויטים צרפתיים.</abstract_he>
      <abstract_bo>ང་ཚོས་BERTweetFR སྤྲོད་ནས་འཛམ་གླིང་གི་སྔོན་གྲངས་ཤིག་གི་སྔོན་གྲངས་བསྒྲིག་པའི་སྐད་རིགས་མ་དཔེ་གཏོང་། Our model is initialized using a general-domain French language model CamemBERT which follows the base architecture of BERT. Experiments show that BERTweetFR outperforms all previous general-domain French language models on two downstream Twitter NLP tasks of offensiveness identification and named entity recognition. offensiveness detection task་ནང་དུ་སྤྱོད་པའི་གནད་སྡུད་ཆ་འཕྲིན་དེ་ཚོ་དང་པོ་ཞིག་གིས་གསར་འཛུགས་དང་གསར་བསྐྲུན་བྱེད་ཡོད། ང་ཚོའི་མ་དབུགས་འདི་མང་ཆེ་མཐོང་ཐུབ་པ་དེ་བཟོ་བཅོས་པ་གྲྭར་ནང་གི་དམིགས་ཡུལ་ཡིན་པའི་མ་འོངས་ལས་འཚོལ་ཞིབ་སྐྱེལ</abstract_bo>
      <abstract_ha>Tuna nuna BERTwitter tFR, na farkon motsi mai girma wa zaman-wa'anar harshen na faransa. An fara misalinmu da wani misali mai zaman-Domin-French-language CamemBERT wanda ke biyar bakin layin BERT. Experiments show that BERTwitter tFR outperforms all previous-General- Domen French language motels on both downriver Twitter NLP tasks of criminous ID and name sunan authenci. @ info: whatsthis We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</abstract_ha>
      <abstract_jv>Awak dhéwé ngejaraké BERT witFra, sampek tanggal banter-scale kuwi wis luwih cara nggawe tarjamahan kanggo tuwit Perancis. We model is beginning with a generic-domain French language model KameBERT that sums the basic architecture of BERT. Name dataset iki dipunangé kanggo kalang nggunaké barang nggawe barang banget nggawe tarjamahan karo hal-hal nganggo koyok barang seneng dataset sing dipunangé barang kanggo Ketoké Awak dhéwé ngejaraké model nyeneng publik sing gawe nèng isih turang kanggo ngilanggar ujian winih kanggo nggawe dolanan surat kanggo tuwit Perancis.</abstract_jv>
      </paper>
    <paper id="50">
      <title>To What Extent Does Lexical Normalization Help English-as-a-Second Language Learners to Read Noisy English Texts?<fixed-case>E</fixed-case>nglish-as-a-Second Language Learners to Read Noisy <fixed-case>E</fixed-case>nglish Texts?</title>
      <author><first>Yo</first><last>Ehara</last></author>
      <pages>451–456</pages>
      <abstract>How difficult is it for English-as-a-second language (ESL) learners to read noisy English texts? Do <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL learners</a> need lexical normalization to read noisy English texts? These questions may also affect community formation on <a href="https://en.wikipedia.org/wiki/Social_networking_service">social networking sites</a> where differences can be attributed to <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL learners</a> and <a href="https://en.wikipedia.org/wiki/First_language">native English speakers</a>. However, few studies have addressed these questions. To this end, we built highly accurate readability assessors to evaluate the readability of texts for <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL learners</a>. We then applied these assessors to noisy English texts to further assess the readability of the texts. The experimental results showed that although intermediate-level ESL learners can read most noisy English texts in the first place, lexical normalization significantly improves the readability of noisy English texts for <a href="https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language">ESL learners</a>.</abstract>
      <url hash="4c6e5af1">2021.wnut-1.50</url>
      <bibkey>ehara-2021-extent-lexical</bibkey>
      <doi>10.18653/v1/2021.wnut-1.50</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
    <title_ar>إلى أي مدى يساعد التطبيع المعجمي متعلمي اللغة الإنجليزية كلغة ثانية على قراءة نصوص إنجليزية صاخبة؟</title_ar>
      <title_fr>Dans quelle mesure la normalisation lexicale aide-t-elle les apprenants de l'anglais langue seconde à lire des textes anglais bruyants ?</title_fr>
      <title_pt>Até que ponto a normalização léxica ajuda os alunos de inglês como segunda língua a ler textos em inglês barulhentos?</title_pt>
      <title_es>¿Hasta qué punto la normalización léxica ayuda a los estudiantes de inglés como segundo idioma a leer textos ruidosos en inglés?</title_es>
      <title_ja>語彙の正規化は、英語学習者が騒々しい英語のテキストを読むのにどの程度役立ちますか？</title_ja>
      <title_hi>किस हद तक लेक्सिकल सामान्यीकरण अंग्रेजी-ए-ए-दूसरी भाषा सीखने वालों को शोर अंग्रेजी ग्रंथों को पढ़ने में मदद करता है?</title_hi>
      <title_zh>词汇规范化助于多大程度英语为第二语言者读嘈杂英语本?</title_zh>
      <title_ru>В какой степени лексическая нормализация помогает изучающим английский как второй язык читать шумные английские тексты?</title_ru>
      <title_ga>Cé chomh Méid a Chuidíonn Normalú Foclaíochta le Foghlaimeoirí Béarla mar Dhara Teanga Téacsanna Béarla Torainn a Léigh?</title_ga>
      <title_ka>რომელსაც განზომილებაში ლექსიკალური ნორმალიზაცია ინგლისური-როგორც-მეორე ენერგიის სწავლებელების დახმარება ინგლისური ტექსტის კითხვა?</title_ka>
      <title_hu>Milyen mértékben segít a lexikai normalizáció az angol nyelvtanulóknak zajos angol szövegeket olvasni?</title_hu>
      <title_it>In che misura la normalizzazione lessicale aiuta gli studenti di inglese come seconda lingua a leggere testi in inglese rumorosi?</title_it>
      <title_kk>Лексикалық нормализациясы ағылшын тілінің оқу үшін екінші тілінің оқу оқушыларына көмектеседі?</title_kk>
      <title_lt>Kokiu mastu leksikalinė normalizacija padeda anglų kalbos mokytojams skaityti triukšmingus anglų tekstus?</title_lt>
      <title_ms>Ke Jarak Apa Normalisasi Leksik Membantu Pelajar Bahasa Inggeris-sebagai-Kedua untuk Baca Teks Bahasa Inggeris Berbunyi?</title_ms>
      <title_ml>എക്സ്റ്റെന്റ് ലെക്സിക്സിക്കല്‍ നോര്‍മാലിഷന്‍ ഇംഗ്ലീഷില്‍ - ആദ്യത്തെ ഭാഷ പഠിപ്പിക്കുന്നവരെ സഹായിക്കുന്നുണ</title_ml>
      <title_mt>Għal liema estensjoni n-Normalizzazzjoni Lessika tgħin lil dawk li jitgħallmu l-Ingliż bħala t-Tieni Lingwa biex jaqraw testi Ingliż storbjużi?</title_mt>
      <title_el>Σε ποιο βαθμό η Λεξική Κανονικοποίηση βοηθά τους Μαθητές Αγγλικών ως Δεύτερης Γλώσσας να διαβάζουν θορυβώδη Αγγλικά Κείμενα;</title_el>
      <title_no>Kva utviding hjelper leksisk normalisering engelsk som ein andre språk lærarar til å lesa lysstyrke engelsk tekstar?</title_no>
      <title_mn>Лексик нормализацийг хэн нэмэгдүүлэхэд англи хэл сурагчид дуу англи хэлний текст уншихын тулд тусалдаг вэ?</title_mn>
      <title_sr>Do kojeg proširenja leksička normalizacija pomaže učiteljima engleskog kao drugog jezika da čitaju engleski tekst?</title_sr>
      <title_pl>W jakim zakresie normalizacja leksykalna pomaga uczącym się języka angielskiego jako drugiego w czytaniu hałaśliwych tekstów angielskich?</title_pl>
      <title_ro>În ce măsură normalizarea lexicală ajută învățătorii de limbă engleză ca a doua să citească texte în engleză zgomotoase?</title_ro>
      <title_mk>To What Extent Does Lexical Normalization Help English-as-a-Second Language Learners to Read Noisy English Texts?</title_mk>
      <title_so>Halkaas oo kale ma caawinaysaa waxbarashada afka ingiriiska oo ah-a-Second si ay u akhriyaan qoraalka Ingiriiska ee noocyada ah?</title_so>
      <title_si>ලෙක්සිකාල් සාමාන්‍ය විදියට ඉංග්‍රීසි වලින් දෙවෙනි භාෂාවක් ඉගෙනිස් වලින් උදව් කරන්න පුළුවන්ද?</title_si>
      <title_ta>@ info: whatsthis</title_ta>
      <title_sv>I vilken utsträckning hjälper Lexisk Normalisering engelska-som-andraspråkslärare att läsa bullriga engelska texter?</title_sv>
      <title_ur>کس طرح لکسکسیکل عاملی کی مدد کرتا ہے انگلیسی کی ایک دوسری زبان تعلیم کرنے والوں کو نویسی انگلیسی ٹکسٹ پڑھنے کے لئے؟</title_ur>
      <title_vi>Có bao nhiêu bản chỉnh sửa ngôn ngữ dược giúp học tiếng Anh bằng cách đọc các văn bản tiếng Anh ồn?</title_vi>
      <title_uz>@ info: whatsthis</title_uz>
      <title_bg>До каква степен лексикалната нормализация помага на учениците по английски език да четат шумни текстове по английски език?</title_bg>
      <title_hr>Do kojeg proširenja leksička normalizacija pomaže učiteljima engleskog kao drugog jezika čitati engleski tekst?</title_hr>
      <title_da>I hvilket omfang hjælper Lexisk Normalisering engelsk-som-andet sprog lærere til at læse støjende engelske tekster?</title_da>
      <title_nl>In hoeverre helpt Lexical Normalization Engelstaligen om lawaaierige Engelse teksten te lezen?</title_nl>
      <title_id>Seberapa luas Normalisasi Lexik Membantu Pelajar Bahasa Inggris-sebagai-kedua untuk membaca Teks Bahasa Inggris Bersuara?</title_id>
      <title_ko>어휘의 규범화는 영어를 제2의 언어로 하는 학습자들이 시끄러운 영어 텍스트를 읽는 데 어느 정도 도움을 줍니까?</title_ko>
      <title_de>Inwieweit hilft Lexical Normalization Englischlernenden, laute englische Texte zu lesen?</title_de>
      <title_fa>به کدام وسیله معمول‌سازی لکسیکی به دانش‌آموزان زبان انگلیسی کمک می‌کند تا متن‌های انگلیسی صدایی بخونند؟</title_fa>
      <title_sw>To What Extent Does Lexical Normalization Help English-as-a-Second Language Learners to Read Noisy English Texts?</title_sw>
      <title_tr>Leksika Normalizacija I흫lis챌e-nji diller i흫lis챌e metinleri okamak 체챌in n채챌e gollany힊ynda k철mek ed첵채r?</title_tr>
      <title_sq>Për çfarë shkalle Normalizimi Leksikal ndihmon mësuesit e gjuhës angleze të lexojnë tekste të zhurmshme angleze?</title_sq>
      <title_af>Na Wat uitbreiding Help Leksiese Normaliseering Engels-as-a-tweede Taal Leerders om Noisy Engels Teks te lees?</title_af>
      <title_am>ወደ ምን External Lexical Normalization ይረዳል? እንግሊዘኛ-as-a-Second ቋንቋ-ቋንቋ አስተማሪዎችን የንግግሊዝኛ ጽሑፎችን ለማንበብ?</title_am>
      <title_hy>Ինչպե՞ս է լեքսիկական նորմալիզացիան օգնում անգլերեն-երկրորդ լեզվի սովորողներին կարդալ աղմկոտ անգլերեն տեքստներ:</title_hy>
      <title_az>İngilizə dil öyrənəniciləri İngilizə dilini oxumaq üçün nə uzaqlaşdırmağa kömək edir?</title_az>
      <title_bn>কোন বিদেশে লেক্সিক্যাল স্বাভাবিক স্বাভাবিকভাবে ইংরেজি হিসেবে দ্বিতীয় ভাষা শিক্ষকদের কি সাহায্য করবে না ইংর</title_bn>
      <title_bs>Koliko proširenje leksička normalizacija pomaže učiteljima engleskog kao drugog jezika da čitaju engleski tekst?</title_bs>
      <title_ca>A quin punt la normalització lèxica ajuda als aprenents de llenguatge anglès a llegir textos ruidosos?</title_ca>
      <title_fi>Missä määrin Lexical Normalization auttaa englantia toisena kielenä oppivia lukemaan meluisia englanninkielisiä tekstejä?</title_fi>
      <title_cs>Do jaké míry pomáhá Lexická normalizace učitelům angličtiny jako druhého jazyka číst hlučné anglické texty?</title_cs>
      <title_et>Millises ulatuses aitab lexikaalne normaliseerimine inglise keelena õppijatel lugeda müraseid inglise tekste?</title_et>
      <title_he>עד כמה נורמליזציה לקסיקה עוזרת ללמודים אנגלית בשנייה לקרוא טקסטים אנגליים רעשים?</title_he>
      <title_sk>V kakšnem obsegu leksična normalizacija pomaga učencem angleščine kot drugega jezika pri branju hrupnih angleških besedil?</title_sk>
      <title_ha>@ item Text character set</title_ha>
      <title_bo>རྒྱ་བསྐྱེད་ཚད་གང་ཞིག་ཡིན་ནའི་མིག་རྩལ་བ་སྤྲོད་ནས་དབྱིན་ཡིག་ཆ་ལ་རྒྱབ་སྐྱོར་མེད་གཏོང་།</title_bo>
      <title_jv>Wulangan Panjenengan langkung wigat Kemerdekaan Normalisi Tulungan Inggris-kara-tanggal Pak-tanggal Tulungan Kemerdekaan Inggris ?</title_jv>
      <abstract_ar>ما مدى صعوبة متعلمي اللغة الإنجليزية كلغة ثانية (ESL) لقراءة النصوص الإنجليزية المزعجة؟ هل يحتاج متعلمي اللغة الإنجليزية كلغة ثانية إلى التطبيع المعجمي لقراءة النصوص الإنجليزية المزعجة؟ قد تؤثر هذه الأسئلة أيضًا على تكوين المجتمع على مواقع الشبكات الاجتماعية حيث يمكن أن تُعزى الاختلافات إلى متعلمي اللغة الإنجليزية كلغة ثانية ومتحدثي اللغة الإنجليزية الأصليين. ومع ذلك ، تناولت دراسات قليلة هذه الأسئلة. تحقيقا لهذه الغاية ، قمنا ببناء أدوات تقييم قابلية القراءة عالية الدقة لتقييم قابلية قراءة النصوص لمتعلمي اللغة الإنجليزية كلغة ثانية. ثم طبقنا هؤلاء المقيّمين على نصوص إنجليزية صاخبة لتقييم سهولة قراءة النصوص. أظهرت النتائج التجريبية أنه على الرغم من أن متعلمي اللغة الإنجليزية كلغة ثانية في المستوى المتوسط يمكنهم قراءة معظم النصوص الإنجليزية المزعجة في المقام الأول ، فإن التطبيع المعجمي يحسن بشكل كبير من قابلية قراءة النصوص الإنجليزية الصاخبة لمتعلمي اللغة الإنجليزية كلغة ثانية.</abstract_ar>
      <abstract_fr>Dans quelle mesure est-il difficile pour les apprenants d'anglais langue seconde (ESL) de lire des textes anglais bruyants ? Les apprenants d'anglais langue seconde ont-ils besoin d'une normalisation lexicale pour lire des textes anglais bruyants ? Ces questions peuvent également affecter la formation de la communauté sur les sites de réseaux sociaux où les différences peuvent être attribuées aux apprenants d'anglais langue seconde et aux anglophones natifs. Cependant, peu d'études ont abordé ces questions. À cette fin, nous avons créé des évaluateurs de lisibilité très précis pour évaluer la lisibilité des textes pour les apprenants d'anglais langue seconde. Nous avons ensuite appliqué ces évaluateurs à des textes anglais bruyants afin d'évaluer davantage la lisibilité des textes. Les résultats expérimentaux ont montré que même si les apprenants d'anglais langue seconde de niveau intermédiaire peuvent lire la plupart des textes anglais bruyants en premier lieu, la normalisation lexicale améliore considérablement la lisibilité des textes anglais bruités pour les apprenants d'ALS.</abstract_fr>
      <abstract_pt>Quão difícil é para os alunos de inglês como segunda língua (ESL) lerem textos em inglês barulhentos? Os alunos de ESL precisam de normalização lexical para ler textos em inglês barulhentos? Essas perguntas também podem afetar a formação da comunidade em sites de redes sociais onde as diferenças podem ser atribuídas a alunos de ESL e falantes nativos de inglês. No entanto, poucos estudos abordaram essas questões. Para isso, construímos avaliadores de legibilidade altamente precisos para avaliar a legibilidade de textos para alunos de ESL. Em seguida, aplicamos esses avaliadores a textos em inglês barulhentos para avaliar melhor a legibilidade dos textos. Os resultados experimentais mostraram que, embora os alunos de ESL de nível intermediário possam ler a maioria dos textos em inglês barulhentos em primeiro lugar, a normalização lexical melhora significativamente a legibilidade de textos em inglês barulhentos para alunos de ESL.</abstract_pt>
      <abstract_es>¿Qué tan difícil es para los estudiantes de inglés como segunda lengua (ESL) leer textos en inglés ruidosos? ¿Los estudiantes de ESL necesitan una normalización léxica para leer textos en inglés ruidosos? Estas preguntas también pueden afectar la formación de la comunidad en los sitios de redes sociales donde las diferencias pueden atribuirse a los estudiantes de ESL y a los hablantes nativos de inglés. Sin embargo, pocos estudios han abordado estas cuestiones. Con este fin, creamos evaluadores de legibilidad altamente precisos para evaluar la legibilidad de los textos para los estudiantes de ESL. Luego aplicamos a estos asesores a textos ruidosos en inglés para evaluar mejor la legibilidad de los textos. Los resultados experimentales mostraron que, aunque los estudiantes de ESL de nivel intermedio pueden leer los textos en inglés más ruidosos en primer lugar, la normalización léxica mejora significativamente la legibilidad de los textos en inglés ruidosos para los estudiantes de ESL.</abstract_es>
      <abstract_ja>秒読み英語（ ESL ）学習者がうるさい英語のテキストを読むのはどの程度難しいですか？ ESL学習者は、騒々しい英語のテキストを読むために辞書の正規化を必要としますか？これらの質問はまた、ESL学習者とネイティブの英語話者に違いがあると考えられるソーシャルネットワーキングサイトでのコミュニティ形成に影響を与える可能性があります。しかし、これらの問題に取り組んだ研究はほとんどない。この目的のために、ESL学習者のためにテキストの読みやすさを評価するために、非常に正確な読みやすさ評価者を構築しました。次に、これらの評価者を騒々しい英語のテキストに適用して、テキストの読みやすさをさらに評価しました。実験結果は、中級レベルのESL学習者はそもそも最も騒音の大きい英語のテキストを読むことができるが、語彙的正規化はESL学習者にとって騒音の大きい英語のテキストの読みやすさを大幅に改善することを示した。</abstract_ja>
      <abstract_zh>英语为第二语言(ESL)学者读嘈杂英语文本多难? ESL学者词汇规范化读嘈杂英语本否? 亦可以社交网站上之社区成,其异可以归因于ESL学者英语母语士。 然少所讲求。 构高准之可读性评估器,以质ESL学之可读性。 然后以此评估器应用于嘈杂英语文本,更加评可读性。 实验结果表明虽中级ESL学者,先可读多嘈杂英语本,而词汇规范化显ESL学者嘈杂英语文本之可读性。</abstract_zh>
      <abstract_ru>Насколько трудно учащимся, изучающим английский язык как второй (ESL), читать шумные английские тексты? Нужна ли учащимся ESL лексическая нормализация для чтения шумных английских текстов? Эти вопросы также могут повлиять на формирование сообщества на сайтах социальных сетей, где различия могут быть приписаны учащимся ESL и носителям английского языка. Однако эти вопросы рассматривались лишь в немногих исследованиях. С этой целью мы создали высокоточных оценщиков читабельности для оценки читабельности текстов для учащихся ESL. Затем мы применили этих оценщиков к шумным текстам на английском языке, чтобы дополнительно оценить читабельность текстов. Экспериментальные результаты показали, что, хотя учащиеся среднего уровня ESL могут читать большинство шумных английских текстов в первую очередь, лексическая нормализация значительно улучшает читаемость шумных английских текстов для учащихся ESL.</abstract_ru>
      <abstract_hi>अंग्रेजी-ए-ए-दूसरी भाषा (ईएसएल) सीखने वालों के लिए शोर अंग्रेजी ग्रंथों को पढ़ना कितना मुश्किल है? क्या ईएसएल शिक्षार्थियों को शोर अंग्रेजी ग्रंथों को पढ़ने के लिए लेक्सिकल सामान्यीकरण की आवश्यकता होती है? ये प्रश्न सोशल नेटवर्किंग साइटों पर सामुदायिक गठन को भी प्रभावित कर सकते हैं जहां मतभेदों को ईएसएल शिक्षार्थियों और देशी अंग्रेजी बोलने वालों के लिए जिम्मेदार ठहराया जा सकता है। हालांकि, कुछ अध्ययनों ने इन सवालों को संबोधित किया है। इस अंत तक, हमने ईएसएल शिक्षार्थियों के लिए ग्रंथों की पठनीयता का मूल्यांकन करने के लिए अत्यधिक सटीक पठनीयता मूल्यांकनकर्ताओं का निर्माण किया। फिर हमने इन मूल्यांकनकर्ताओं को शोर अंग्रेजी ग्रंथों पर लागू किया ताकि ग्रंथों की पठनीयता का आकलन किया जा सके। प्रयोगात्मक परिणामों से पता चला है कि हालांकि मध्यवर्ती स्तर के ईएसएल शिक्षार्थी पहले स्थान पर सबसे अधिक शोर अंग्रेजी ग्रंथों को पढ़ सकते हैं, लेक्सिकल सामान्यीकरण ईएसएल शिक्षार्थियों के लिए शोर अंग्रेजी ग्रंथों की पठनीयता में काफी सुधार करता है।</abstract_hi>
      <abstract_ga>Cé chomh deacair is atá sé d’fhoghlaimeoirí Béarla mar dhara teanga (ESL) téacsanna fuaimiúla Béarla a léamh? An bhfuil normalú foclóireachta de dhíth ar fhoghlaimeoirí ESL chun téacsanna Béarla torainn a léamh? D’fhéadfadh tionchar a bheith ag na ceisteanna seo freisin ar fhoirmiú pobail ar shuíomhanna líonraithe sóisialta inar féidir difríochtaí a chur i leith foghlaimeoirí ESL agus cainteoirí dúchais Béarla. Mar sin féin, is beag staidéar a chuaigh i ngleic leis na ceisteanna seo. Chuige sin, chuireamar measúnóirí inléiteacht an-chruinn le chéile chun inléiteacht téacsanna d’fhoghlaimeoirí ESL a mheas. Chuireamar na measúnóirí seo i bhfeidhm ansin ar théacsanna torainneacha Béarla chun inléiteacht na dtéacsanna a mheasúnú tuilleadh. Léirigh na torthaí turgnamhacha, cé gur féidir le foghlaimeoirí meánleibhéil ESL an chuid is mó de théacsanna Béarla torannacha a léamh ar an gcéad dul síos, cuireann normalú foclóireachta go mór le hinléiteacht téacsanna fuaimiúla Béarla d’fhoghlaimeoirí ESL.</abstract_ga>
      <abstract_hu>Mennyire nehéz az angol nyelvű (ESL) tanulóknak zajos angol szövegeket olvasni? Az ESL tanulóknak szükségük van lexikális normalizációra ahhoz, hogy zajos angol szövegeket olvassanak? Ezek a kérdések befolyásolhatják a közösségi alapítást a közösségi oldalakon, ahol a különbségek az ESL tanulóknak és az anyanyelvűeknek tulajdoníthatók. Ezekkel a kérdésekkel azonban kevés tanulmány foglalkozott. Ennek érdekében rendkívül pontos olvashatósági értékelőket építettünk ki a szövegek olvashatóságának értékelésére az ESL tanulók számára. Ezt követően ezeket az értékelőket a zajos angol nyelvű szövegekre alkalmaztuk, hogy tovább értékeljük a szövegek olvashatóságát. A kísérleti eredmények azt mutatták, hogy bár a középszintű ESL tanulók elsősorban a legtöbb zajos angol szöveget tudják olvasni, a lexikális normalizáció jelentősen javítja a zajos angol szövegek olvashatóságát az ESL tanulók számára.</abstract_hu>
      <abstract_ka>თუ რამდენი რთულია ინგლისური მეორე ენაზე (ESL) სწავლებელებისთვის კითხვა სიტყვის ანგლისური ტექსტი? ESL სწავლებელი ლექსიკალური ნორმალიზაცია უნდა ინგლისური ტექსტის კითხვა? ეს კითხვები შეიძლება შეიძლება ასევე გააკეთება საზოგადოებო ფორმაციაზე საზოგადოებო ქსელის სახლში, სადაც განსხვავებები შეიძლება ატრიბუტირება ESL ს მაგრამ, რამდენიმე კვლევები ამ კითხვების შესახებ. ამ დასაწყისთვის, ჩვენ დავყენეთ ძალიან მარტივი კითხვა შესაძლებლობა სწავლებელებისთვის ტექსტის კითხვა შესაძლებლობა. შემდეგ ჩვენ ამ აღმოჩენებელი ინგლისური ტექსტისთვის გამოყენეთ ტექსტის კითხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვადასხვა. ექსპერიმენტიური წარმოდგენები გაჩვენება, რომ თუმცა სწავლებელი ESL სწავლებელი შეუძლიათ უფრო ძალიან ბუნდა ანგლისური ტექსტის წარმოდგენა პირველი ადგილზე, ლექსიკალური ნორმალიზაცია ძალ</abstract_ka>
      <abstract_it>Quanto è difficile per gli studenti di inglese come seconda lingua (ESL) leggere testi in inglese rumorosi? Gli studenti ESL hanno bisogno di normalizzazione lessicale per leggere testi in inglese rumorosi? Queste domande possono anche influenzare la formazione della comunità sui siti di social networking dove le differenze possono essere attribuite a studenti ESL e madrelingua inglese. Tuttavia, pochi studi hanno affrontato queste questioni. A tal fine, abbiamo creato valutatori di leggibilità altamente accurati per valutare la leggibilità dei testi per gli studenti ESL. Abbiamo poi applicato questi valutatori a testi inglesi rumorosi per valutare ulteriormente la leggibilità dei testi. I risultati sperimentali hanno mostrato che anche se gli studenti ESL di livello intermedio possono leggere la maggior parte dei testi inglesi rumorosi in primo luogo, la normalizzazione lessicale migliora significativamente la leggibilità dei testi inglesi rumorosi per gli studenti ESL.</abstract_it>
      <abstract_kk>Ағылшын тілінің екінші тілінде (ESL) оқытуға қанша қиын? ESL оқушыларына тыңдау ағылшын мәтіндерін оқу үшін лексикалық нормализация керек пе? Бұл сұрақтар сондай-ақ ЕСЛ оқытушыларға және негізгі ағылшын тілінде айырмашылығының көмектесетін социаллық желілер сайтында көмектесе алады. Бірақ бірнеше зерттеулер осы сұрақтарды шешу керек. Бұл үшін біз ESL оқушыларының оқу мүмкіндігін оқу үшін дұрыс оқу мүмкіндіктерін құрдық. Содан кейін бұл оқу мүмкіндігін бақылау үшін ағылшын тілдеріне қолдандық. Тәжірибелі нәтижелер ESL орташа деңгейіндегі оқушылар ең дыбыс ағылшын мәтіндерін біріншіден оқуға болады дегенді көрсетті. Лексикалық нормализация ESL оқушыларының дыбыс ағылшын мәтіндерінің</abstract_kk>
      <abstract_lt>Kaip sunku anglų kalbos mokytojams skaityti triukšmingus anglų tekstus? Do ESL learners need lexical normalization to read noisy English texts?  These questions may also affect community formation on social networking sites where differences can be attributed to ESL learners and native English speakers.  Tačiau šiems klausimams nagrinėta nedaug tyrimų. To this end, we built highly accurate readability assessors to evaluate the readability of texts for ESL learners.  We then applied these assessors to noisy English texts to further assess the readability of the texts.  Eksperimentiniai rezultatai parodė, kad nors vidutinio lygio ESL mokiniai iš esmės gali skaityti didžiausius triukšmingus anglų tekstus, leksikalinė normalizacija gerokai pagerina triukšmingų anglų tekstų skaitomumą ESL mokiniams.</abstract_lt>
      <abstract_mk>Колку е тешко за учениците на англиски јазик (ЕСЛ) да читаат гласни англиски тексти? Дали на учениците од ЕСЛ им треба лексикална нормализација за да читаат гласни англиски тексти? Овие прашања, исто така, можат да влијаат на формирањето на заедницата на страниците за социјална мрежа каде разликите можат да се припишат на учениците на ЕСЛ и родните англиски говорници. Сепак, неколку студии ги решија овие прашања. За ова, изградивме многу прецизни проценувачи на читливост за да ја процениме читливоста на текстовите за учениците на ЕСЛ. Потоа ги применивме овие проценки на гласните англиски тексти за понатамошна проценка на читливоста на текстите. Експерименталните резултати покажаа дека иако учениците на средното ниво на ЕСЛ можат да читаат најбучни англиски тексти на прво место, лексикалната нормализација значително ја подобрува читливоста на бучните англиски тексти за учениците на ЕСЛ.</abstract_mk>
      <abstract_ms>Seberapa sukar bagi pelajar bahasa Inggeris-sebagai-kedua (ESL) untuk membaca teks bahasa Inggeris yang bunyi? Adakah pelajar ESL memerlukan normalisasi leksikal untuk membaca teks bahasa Inggeris yang bunyi? Soalan ini juga boleh mempengaruhi pembangunan komuniti di laman rangkaian sosial di mana perbezaan boleh ditakrif kepada pelajar ESL dan pembicara Inggeris asli. Namun, beberapa kajian telah mengatasi soalan-soalan ini. Untuk tujuan ini, kami membina penilai pembacaan yang tepat untuk menilai pembacaan teks untuk pelajar ESL. We then applied these assessors to noisy English texts to further assess the readability of the texts.  Hasil percubaan menunjukkan bahawa walaupun pelajar ESL tahap tengah boleh membaca teks bahasa Inggeris yang paling bunyi di tempat pertama, normalisasi leksikal meningkatkan kemudahan membaca teks bahasa Inggeris yang bunyi bagi pelajar ESL.</abstract_ms>
      <abstract_ml>ഇംഗ്ലീഷ്-ആ-രണ്ടാം ഭാഷ പഠിക്കുന്നവര്‍ക്ക് ശബ്ദം ഇംഗ്ലീഷ് ടെക്സ്റ്റുകള്‍ വായിക്കാന്‍ എത്ര ബുദ്ധി ശബ്ദം ഇംഗ്ലീഷ് വായിക്കാന്‍ എസ്എല്‍ പഠിക്കുന്നവര്‍ക്ക് ലെക്സിക്കല്‍ സാധാരണ വേണോ? ഈ ചോദ്യങ്ങള്‍ സാമൂഹിക വെക്കേറ്റ് നെറ്റ്‌വര്‍ക്ക് സ്ഥലങ്ങളില്‍ വ്യത്യാസങ്ങള്‍ക്കും എസ്എല്‍ പഠിക്കുന്നവര്‍ക്കും നാട് എന്നാലും കുറച്ച് പഠനങ്ങള്‍ ഈ ചോദ്യങ്ങളെക്കുറിച്ച് സംസാരിച്ചിട്ടുണ്ട്. ഈ അവസാനത്തിനു വേണ്ടി, എസ്എല്‍ പഠിക്കുന്നവര്‍ക്കുള്ള പദാവലികളുടെ വായിക്കുവാനുള്ള വിശദീകരണത്തെ വിശദീകരിക്ക പിന്നീട് ഞങ്ങള്‍ ഇംഗ്ലീഷ് ടെക്സ്റ്റുകളുടെ വായിക്കാവുന്നത് കൂടുതല്‍ വിശദീകരിക്കാന്‍ പ്രയോഗിച്ചു. പരീക്ഷണ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു എന്തെങ്കിലും തമ്മിലുള്ള എസ്എല്‍ നിലവില്‍ പഠിക്കുന്നവര്‍ക്ക് ആദ്യ സ്ഥലത്ത് ഏറ്റവും ശബ്ദമായ ഇംഗ്ലീ</abstract_ml>
      <abstract_mt>How difficult is it for English-as-a-second language (ESL) learners to read noisy English texts?  L-istudenti tal-ESL jeħtieġu normalizzazzjoni lexika biex jaqraw testi bl-Ingliż storbjużi? Dawn il-mistoqsijiet jistgħu jaffettwaw ukoll il-formazzjoni komunitarja fuq siti ta’ netwerking soċjali fejn id-differenzi jistgħu jiġu attribwiti lil studenti tal-ESL u lil dawk li jitkellmu bl-Ingliż nattiv. Madankollu, ftit studji indirizzaw dawn il-mistoqsijiet. Għal dan il-għan, bnejna valutaturi tal-leġibbiltà preċiżi ħafna biex jevalwaw il-leġibbiltà tat-testi għal dawk li jitgħallmu l-ESL. Imbagħad applikajna dawn il-valutaturi għal testi bl-Ingliż storbjużi biex tivvaluta aktar il-leġibbiltà tat-testi. Ir-riżultati sperimentali wrew li għalkemm dawk li jitgħallmu l-ESL fuq livell intermedju jistgħu jaqraw l-aktar testi bl-Ingliż storbjużi fl-ewwel lok, in-normalizzazzjoni lexikali ttejjeb b’mod sinifikanti l-leġibbiltà tat-testi bl-Ingliż storbjużi għal dawk li jitgħallmu l-ESL.</abstract_mt>
      <abstract_mn>Англи хэл болон хоёр дахь хэл (ESL) сурагчдад чимээгүй Англи хэлний бичгийг унших нь хэцүү вэ? ESL сурагчид дуу англи хэлний бичгийг унших үед хэлний хэмжээсүүд хэрэгтэй юу? Эдгээр асуултууд мөн нийгмийн сүлжээний сайт үүсгэх боломжтой болно. ЭСЛ сурагчид болон энгийн Англи хэлнэгчдэд ялгаатай байх боломжтой. Гэхдээ хэд хэдэн судалгаа эдгээр асуултуудыг харуулсан. Энэ төгсгөлд бид ESL сурагчид унших чадварыг үнэлэхэд маш нарийн унших чадварыг баталсан. Дараа нь бид эдгээр оюутнуудыг текстүүдийн уншиж чадах чадварыг нэмэгдүүлэх зорилготой англи хэлний бичиг дээр ашигласан. Үүний туршилтын үр дүнд ESL дундаж түвшинд сурагчид англи хэлний хамгийн чимээгүй бичиг уншиж чадах боломжтой байсан ч, лексикийн хэмжээсүүд нь ESL сурагчид дунджаар англи хэлний бичиг унших чадварыг үнэхээр сайжруулдаг</abstract_mn>
      <abstract_no>Kor vanskeleg er det for å læra engelsk som ein andre språk (ESL) å lesa støy engelsk tekstar? Er ESL-lærarar nødvendig leksisk normalisering for å lesa støy engelsk tekstar? Desse spørsmålene kan også påvirke fellesskapsformasjonen på sosiale nettverksnettstader der forskjeller kan attributtast til ESL-lærarar og innbygge engelske taler. Fe studier har imidlertid addressert desse spørsmålene. I denne slutten bygge vi stor nøyaktig lesabilitetsassessorar for å evaluera lesabiliteten av tekstar for ESL-lærarar. Vi så brukte desse assessorane til støy engelsk tekstar for å vurdere lesabiliteten av tekstane. Eksperimentale resultatet viste at selv om mellomsnivået ESL-lærarane kan lesa mest støy engelsk tekstar på første plass, vil leksiske normalisering forbetra lesabiliteten av støy engelsk tekstar for ESL-lærarane.</abstract_no>
      <abstract_ro>Cât de dificil este pentru elevii de limba engleză ca a doua (ESL) să citească texte în engleză zgomotoase? Cursanții ESL au nevoie de normalizare lexicală pentru a citi texte în limba engleză zgomotoasă? Aceste întrebări pot afecta, de asemenea, formarea comunității pe site-urile de rețele sociale unde diferențele pot fi atribuite cursanților ESL și vorbitorilor nativi de engleză. Cu toate acestea, puține studii au abordat aceste întrebări. În acest scop, am construit evaluatori de lizibilitate foarte precis pentru a evalua lizibilitatea textelor pentru elevii ESL. Apoi am aplicat acești evaluatori textelor engleze zgomotoase pentru a evalua în continuare lizibilitatea textelor. Rezultatele experimentale au arătat că deși elevii ESL de nivel intermediar pot citi cele mai multe texte în limba engleză zgomotoase în primul rând, normalizarea lexicală îmbunătățește semnificativ lizibilitatea textelor în limba engleză zgomotoase pentru elevii ESL.</abstract_ro>
      <abstract_sr>Koliko je teško za učenike engleskog kao drugog jezika (ESL) čitati bučne engleske tekste? Da li učenici ESL trebaju leksičku normalizaciju da pročitaju bukve engleske tekste? Te pitanja mogu takođe utjecati na formaciju zajednice na sajtove socijalne mreže gdje se razlike mogu priključiti učenicima ESL-a i govornicima engleskog jezika. Međutim, nekoliko ispitivanja su riješilo te pitanja. Za taj cilj, izgradili smo vrlo tačne procjene čitljivosti kako bi procenili čitljivost tekstova za učenike ESL-a. Zatim smo primjenjivali ove procjene na bučne engleske tekste da bi dalje procenili čitljivost teksta. Eksperimentalni rezultati pokazali su da, iako učenici ESL-a na srednjem nivou mogu prvo pročitati najbučnije engleske tekste, leksička normalizacija značajno poboljšava čitljivost bučnih engleskih tekstova za učenike ESL-a.</abstract_sr>
      <abstract_si>ඉංග්‍රීසි වලින් දෙවෙනි භාෂාවක් වලින් (ESL) ඉංග්‍රීසි වලින් කියවන්න කොච්චර අමාරුයි? ESL ශීෂකයන්ට ලෙක්සික් සාමාන්‍යය කියවන්න ඕනද? මේ ප්‍රශ්න පුළුවන් සමාජික ජාතික වැඩසටහන් වලට සමාජික ජාතික වැඩසටහන් ප්‍රශ්නයක් වෙන්න පුළුවන්  ඒත් අධ්‍යානය කිහිපයක් මේ ප්‍රශ්නයක් ලැබුනා. මේ අවසානයෙන්, අපි හොඳටම හරියට ලියපු කියවන්න පුළුවන් විශ්වාස කරනවා ESL ඉගෙනගන්න පාළුවන්ට පාළුවන් ඊට පස්සේ අපි මේ විශ්වාස කරුණාකරුවන්ව ඉංග්‍රීසි පාළුවන්ට අනුවර්ථ කරලා පාළුවන්ගේ පාළු පරීක්ෂණ ප්‍රතිචාර ප්‍රතිචාරයක් පෙන්වන්න පුළුවන් කියලා තියෙනවා කියලා, පළමුවෙනි ඉංග්‍රීසි පාළුවන් ගොඩක් ශිෂ්ට භාෂාව</abstract_si>
      <abstract_so>Intee waa ku adag tahay in afka ingiriiska lagu barto qoraalka afka labaad (ESL) oo afka ingiriisiga ah ay ku adag yihiin in ay akhriyaan qoraalka afka ingiriiska? Waxbarashada ESL ma u baahan tahay in la akhriyo qoraalka afka Ingiriiska oo codsiga ah? Sidoo kale su'aalahan waxay saameyn ku yeelan karaan sameynta bulshada bogagga shabakadda bulshada, kuwaas oo ay kala duwanaan karaan waxbarashada ESL iyo luuqadaha Ingiriiska ee hooyo. Si kastaba ha ahaatee wax yar oo waxbarasho ah ayaa su'aalahan ka sheekaystay. Taas darteed waxaan dhisnay qiimeynta awoodda ee akhriska si aan u qiimeyno awoodda qoraalka waxbarashada ESL. Markaas waxan u dalbannay qiimeynta qoraalka afka Ingiriiska si aan ugu qiimeynayno awoodda qoraalka akhriska. Imtixaanka waxaa ka muuqday in kastoo ay ardayda ESL ee heerka dhexe ku baran karaan qoraalka afka Ingiriiska oo aad u dhaw, marka hore qoraalka afka Ingiriiska ayaa si weyn u hagaajiya karashada qoraalka afka Ingiriiska ee barashada ESL.</abstract_so>
      <abstract_el>Πόσο δύσκολο είναι για τους μαθητές της αγγλικής ως δεύτερης γλώσσας να διαβάσουν θορυβώδη αγγλικά κείμενα; Χρειάζονται οι μαθητές λεξική εξομάλυνση για να διαβάσουν θορυβώδη αγγλικά κείμενα; Αυτές οι ερωτήσεις μπορεί επίσης να επηρεάσουν τη διαμόρφωση κοινότητας σε ιστότοπους κοινωνικής δικτύωσης όπου οι διαφορές μπορούν να αποδοθούν σε μαθητές και φυσικούς ομιλητές αγγλικών. Ωστόσο, λίγες μελέτες έχουν εξετάσει αυτά τα ερωτήματα. Για το σκοπό αυτό, δημιουργήσαμε πολύ ακριβείς αξιολογητές αναγνωσιμότητας για να αξιολογήσουμε την αναγνωσιμότητα των κειμένων για τους εκπαιδευόμενους. Στη συνέχεια εφαρμόσαμε αυτούς τους αξιολογητές σε θορυβώδη αγγλικά κείμενα για να αξιολογήσουμε περαιτέρω την αναγνωσιμότητα των κειμένων. Τα πειραματικά αποτελέσματα έδειξαν ότι αν και οι μαθητές μεσαίου επιπέδου μπορούν να διαβάσουν τα περισσότερα θορυβώδη αγγλικά κείμενα εξ αρχής, η λεξική ομαλοποίηση βελτιώνει σημαντικά την αναγνωσιμότητα των θορυβωδών Αγγλικών κειμένων για τους εκπαιδευόμενους.</abstract_el>
      <abstract_sv>Hur svårt är det för elever i engelska som andraspråk (ESL) att läsa bullriga engelska texter? Behöver ESL-elever lexikal normalisering för att läsa bullriga engelska texter? Dessa frågor kan också påverka samhällsbildningen på sociala nätverkssidor där skillnader kan tillskrivas ESL-elever och infödda engelsktalande. Det finns dock få studier som behandlar dessa frågor. För detta ändamål byggde vi mycket exakta läsbarhetsbedömare för att utvärdera läsbarheten av texter för ESL-elever. Vi tillämpade sedan dessa bedömare på bullriga engelska texter för att ytterligare bedöma texternas läsbarhet. De experimentella resultaten visade att även om elever på medelnivå kan läsa de flesta bullriga engelska texter i första hand, förbättrar lexikal normalisering signifikant läsbarheten av bullriga engelska texter för ESL elever.</abstract_sv>
      <abstract_ta>ஆங்கிலத்தில் இருந்து இரண்டாவது மொழிக்கு எவ்வளவு கடினமாக இருக்கிறது சப்தமான ஆங்கிலத்தை படிப்பதற்கு? எஸ்எல் கற்றுக்கொள்பவர்கள் ஆங்கிலத்தை படிப்பதற்கு லெக்சிக்சியல் இயல்பாக்கம் தேவைப்படுகிறதா? இந்த கேள்விகள் சமூக வலைப்பின்னல் இணைப்பு தளங்களில் சமூகத்தின் வடிவமைப்பை பாதிக்கலாம் எஸ்எல் கற்றல்கள் மற்றும் சார்ந்த ஆனால், சில ஆய்வுகள் இந்த கேள்விகளைப் பற்றியுள்ளன. இந்த முடிவிற்கு, நாங்கள் எஸ்எல் கற்றுக்கொள்பவர்களுக்கு உரைகளின் படிப்பியலை மதிப்பிடுவதற்கு மிகவும் சரியான படிப்பி பிறகு நாங்கள் இந்த மதிப்பீடுகளை ஆங்கிலத்திற்கு ஆச்சரியமாக பயன்படுத்தினோம் மேலும் எழுத்துக்களின் படிக்க சோதனை முடிவு</abstract_ta>
      <abstract_pl>Jak trudno jest uczącym się języka angielskiego jako drugiego (ESL) czytać hałaśliwe teksty angielskiego? Czy uczący się ESL potrzebują normalizacji leksykalicznej, aby czytać głośne teksty angielskie? Pytania te mogą również mieć wpływ na tworzenie społeczności na portalach społecznościowych, gdzie różnice można przypisać uczącym się ESL i native speakerom języka angielskiego. Niewiele badań dotyczyło jednak tych kwestii. W tym celu zbudowaliśmy bardzo dokładne oceniacze czytelności tekstów dla uczących się ESL. Następnie zastosowaliśmy tych oceniaczy do głośnych tekstów angielskich, aby dokładniej ocenić czytelność tekstów. Wyniki eksperymentalne wykazały, że chociaż uczący się ESL na średnim poziomie potrafią w pierwszej kolejności czytać najbardziej hałaśliwe teksty angielskie, normalizacja leksykalna znacznie poprawia czytelność głośnych tekstów angielskich dla uczących się ESL.</abstract_pl>
      <abstract_ur>انگلیسی کی دوسری زبان (ESL) کی تلاوت کرنے والوں کے لئے کیا مشکل ہے؟ کیا ESL سکونٹنے والوں کو صوت انگلیسی پیغام پڑھنے کے لئے لکسیکل عاملی کی ضرورت ہے؟ یہ سؤال بھی ممکن ہے کہ سوسیل نیٹورکینگ سائٹوں پر اجتماعی فرمول پر بھی تاثیر کرسکتے ہیں جہاں اختلاف ESL سکونٹنے والوں اور ملک انگلیسی زبان کرنے والوں کے ساتھ مل سکتے ہیں. لیکن تھوڑے مطالعہ ان سوالوں سے دریافت کیا گیا ہے۔ اس کے لئے ہم نے بہت سیدھی پڑھنے کے قابل آزمائش کرنے والے بنائے کہ ESL یادگاروں کے لئے پیغام پڑھنے کی قابلیت کا ارزش کریں. اس کے بعد ہم نے ان آزمائش کرنے والوں کو آواز انگلیسی پیغام پر استعمال کیا تاکہ ان پیغام کے پڑھنے کی طاقت بھی اضافہ کریں۔ آزمائش نتیجے دکھائے گئے کہ اگرچہ ان کے متوسط-سطح ESL یادگاروں کو پہلی بار انگلیسی ٹیکسٹ پڑھ سکتے ہیں، لکسیکل عامل کرنا ESL یادگاروں کے لئے صوت انگلیسی ٹیکسٹ کے پڑھنے کی طاقت اضافہ کرتا ہے.</abstract_ur>
      <abstract_uz>Ingliz tilidagi ikkinchi tildan o'rganishga qancha qiyin bu ingliz tilini o'qishga o'rganadi? ESL o'rganishlari ingliz tili matnlarini o'qish uchun leksikal normalisiyatsiya kerak? Bu savollar jamiyat tarmoq sahifalarda o'zgarishga ega bo'lishi mumkin, balki o'zgarishlar ESL ta'lim o'rganishlar va natijasi ingliz tillariga ega bo'lishi mumkin. Lekin, bir nechta o'qituvchilar bu savollarni boshlagan. Shunday qilib, biz ESL o'rganishlar uchun matnlarni o'qish uchun juda yaxshi o'qituvchilarni yaratdik. Keyin biz bu qiymatlarni ingliz tilining textlariga qo'llab berdik va o'zlarning o'qituvchiligini davom etish uchun. Tasavvur natijalari ko'rsatadi, agar intermediate darajada ESL o'rganishlar birinchi boshida eng yuqori ingliz tili matnlarini o'qishi mumkin, lekksikal normalisiyatsiya ESL o'rganishlari uchun eng tili ingliz matnlarini o'qishga qiziqaradi.</abstract_uz>
      <abstract_vi>Những người học tiếng Anh ồn ào như ESL khó khăn thế nào? Những đứa học trò ESL có cần phải ăn chuẩn phòng để đọc văn bản tiếng Anh ồn không? Những câu hỏi này cũng có thể ảnh hưởng đến giáo trình cộng đồng trên các trang mạng xã hội nơi khác nhau được cho học trò ESL và người nói tiếng Anh bản xứ. Tuy nhiên, ít nghiên cứu đã giải quyết những vấn đề này. Chúng tôi đã xây dựng những chuyên gia đánh giá khả năng đọc rất chính xác để đánh giá khả năng đọc văn bản cho học viên ESL. Sau đó chúng tôi áp dụng những nhà đánh giá này vào văn bản Anh ồn ào để đánh giá sự dễ đọc của văn bản. Các kết quả thử nghiệm cho thấy mặc dù đệ tử ESL cấp trung có khả năng đọc được văn bản tiếng Anh ồn nhất, nhưng phải cải thiện mức độ ổn định ngôn ngữ văn bản tiếng Anh ồn cho học viên ESL dễ đọc hơn.</abstract_vi>
      <abstract_da>Hvor svært er det for engelsk-som-andet sprog (ESL) elever at læse støjende engelske tekster? Har ESL elever brug for leksikalsk normalisering for at læse støjende engelske tekster? Disse spørgsmål kan også påvirke fællesskabsdannelsen på sociale netværkssider, hvor forskelle kan tilskrives ESL-elever og indfødte engelsktalende. Kun få undersøgelser har imidlertid behandlet disse spørgsmål. Til dette formål har vi bygget meget nøjagtige læsbarhedsvurderingsfolk til at evaluere læsbarheden af tekster for ESL-elever. Vi anvendte derefter disse bedømmere på støjende engelske tekster for yderligere at vurdere teksternes læsbarhed. De eksperimentelle resultater viste, at selvom ESL-elever på mellemniveau kan læse de fleste støjende engelske tekster i første omgang, forbedrer leksikalsk normalisering betydeligt læsbarheden af støjende engelske tekster for ESL-elever.</abstract_da>
      <abstract_bg>Колко трудно е за учащите английски като втори език да четат шумни английски текстове? Нуждаят ли се от лексикална нормализация, за да четат шумни английски текстове? Тези въпроси могат да повлияят и на формирането на общността в сайтове за социални мрежи, където различията могат да бъдат приписани на обучаемите по учене и родните английски език. Въпреки това, малко проучвания са разгледали тези въпроси. За тази цел създадохме високо точни оценители за четливост, за да оценим четливостта на текстовете за обучаемите по учене. След това приложихме тези оценители към шумни английски текстове, за да оценим по-нататъшната четливост на текстовете. Експерименталните резултати показват, че въпреки че учениците от средно ниво могат да четат най-шумните английски текстове на първо място, лексикалното нормализиране значително подобрява четливостта на шумните английски текстове за учениците от ЕСЛ.</abstract_bg>
      <abstract_hr>Koliko je teško učiteljima engleskog kao drugog jezika (ESL) čitati bučne engleske tekste? Da li učnici ESL trebaju leksičku normalizaciju da pročitaju bučne engleske tekste? Te pitanja mogu također utjecati na formaciju zajednice na društvene mreže gdje se razlike mogu priključiti učiteljima ESL-a i govornicima engleskog jezika. Međutim, nekoliko ispitivanja riješilo su te pitanja. Za taj cilj, izgradili smo vrlo precizne procjene čitljivosti kako bi procijenili čitljivost tekstova za učenike ESL-a. Zatim smo primjenjivali ove procjene na bučne engleske tekste kako bi dalje procijenili čitljivost teksta. Eksperimentalni rezultati pokazali su da, iako učenici ESL-a na prosječnoj razini mogu pročitati najbučnije engleske tekste na prvom mjestu, leksička normalizacija značajno poboljšava čitljivost bučnih engleskih tekstova za učenike ESL-a.</abstract_hr>
      <abstract_de>Wie schwierig ist es für Lernende von Englisch als Zweitsprache (ESL), laute englische Texte zu lesen? Benötigen ESL-Lernende eine lexikalische Normalisierung, um laute englische Texte zu lesen? Diese Fragen können sich auch auf die Community-Bildung in sozialen Netzwerken auswirken, wo Unterschiede auf ESL-Lernende und englische Muttersprachler zurückgeführt werden können. Allerdings haben sich nur wenige Studien mit diesen Fragen befasst. Zu diesem Zweck haben wir hochpräzise Lesbarkeitsbewerter entwickelt, um die Lesbarkeit von Texten für ESL-Lernende zu bewerten. Diese Assessoren haben wir dann auf laute englische Texte angewendet, um die Lesbarkeit der Texte weiter zu beurteilen. Die experimentellen Ergebnisse zeigten, dass die lexikalische Normalisierung die Lesbarkeit von lauten englischen Texten für ESL-Lernende signifikant verbessert.</abstract_de>
      <abstract_nl>Hoe moeilijk is het voor studenten van Engels als tweede taal (ESL) om luidruchtige Engelse teksten te lezen? Hebben ESL-leerlingen lexicale normalisatie nodig om luidruchtige Engelse teksten te lezen? Deze vragen kunnen ook invloed hebben op gemeenschapsvorming op sociale netwerksites waar verschillen kunnen worden toegeschreven aan ESL-studenten en moedertaalsprekers Engels. Er is echter weinig onderzoek gedaan naar deze vragen. Hiervoor hebben we zeer nauwkeurige leesbaarheidsassessors gebouwd om de leesbaarheid van teksten voor ESL-leerlingen te evalueren. Vervolgens pasten we deze assessors toe op luidruchtige Engelse teksten om de leesbaarheid van de teksten verder te beoordelen. De experimentele resultaten toonden aan dat hoewel ESL-leerlingen op middelhoog niveau de meeste lawaaierige Engelse teksten in de eerste plaats kunnen lezen, lexicale normalisatie de leesbaarheid van luidruchtige Engelse teksten voor ESL-studenten aanzienlijk verbetert.</abstract_nl>
      <abstract_ko>영어는 제2언어(ESL) 학습자로서 시끄러운 영어 텍스트를 읽는 데 얼마나 어려운가?ESL 학습자는 시끄러운 영어 텍스트를 읽기 위해 어휘를 규범화해야 합니까?이런 문제들은 소셜네트워크서비스(SNS)의 지역사회 형성에도 영향을 미칠 수 있다. 소셜네트워크서비스(SNS)에서 차이는 ESL 학습자와 영어를 모국어로 하는 사람에게 기인할 수 있다.그러나 이런 문제들을 해결하는 연구는 드물다.이를 위해 EMC는 ESL 학습자의 텍스트 읽기 가능성을 평가할 수 있는 매우 정확한 가독성 평가원을 구축했습니다.그리고 우리는 이 평가원들을 시끄러운 영어 텍스트에 응용하여 텍스트의 가독성을 더욱 평가할 것이다.실험 결과에 따르면 중급 수준의 ESL 학습자는 먼저 대부분의 시끄러운 영어 텍스트를 읽을 수 있지만 어휘 규범화는 ESL 학습자의 시끄러운 영어 텍스트의 가독성을 현저히 향상시켰다.</abstract_ko>
      <abstract_id>Seberapa sulit bagi pelajar bahasa Inggris-sebagai-kedua (ESL) untuk membaca teks bahasa Inggris yang berisik? Do ESL learners need lexical normalization to read noisy English texts?  Pertanyaan-pertanyaan ini juga dapat mempengaruhi formasi komunitas di situs jaringan sosial di mana perbedaan dapat ditanggung oleh pelajar ESL dan pembicara Inggris asli. Namun, beberapa studi telah mengatasi pertanyaan-pertanyaan ini. To this end, we built highly accurate readability assessors to evaluate the readability of texts for ESL learners.  Kemudian kami menerapkan penilai-penilai ini untuk teks bahasa Inggris yang berisik untuk lebih lanjut menilai pembacaan teks-teks. Hasil percobaan menunjukkan bahwa meskipun para pelajar ESL tingkat intermedium dapat membaca teks bahasa Inggris yang paling berisik pada awalnya, normalisasi leksikal meningkatkan kemudahan membaca teks bahasa Inggris yang berisik bagi para pelajar ESL.</abstract_id>
      <abstract_sw>Ni vigumu sana kwa lugha ya pili ya Kiingereza (ESL) wanajifunza kusoma ujumbe wa sauti wa Kiingereza? Je, wanafunzi wa ESL wanahitaji utaratibu wa kawaida ili kusoma ujumbe wa sauti wa Kiingereza? Maswali haya yanaweza pia kuathiri utoaji wa jamii katika tovuti za mitandao ya kijamii ambapo tofauti zinaweza kutengeneza kwa wanafunzi wa ESL na wazungumzaji wa Kiingereza wenyewe. Hata hivyo, utafiti wachache umejadili maswali haya. Kwa mwisho huu, tulijenga tathmini sahihi za uwezo wa kusoma ili kutathmini uwezekano wa wasomaji wa maandishi kwa ajili ya wanafunzi wa ESL. Kisha tukatumia tathmini hizi kwa kupiga kelele ujumbe wa Kiingereza kutathmini uwezekano wa maandishi. Matokeo ya majaribio yalionyesha kwamba ingawa wanafunzi wa ESL katika ngazi ya kati wanaweza kusoma ujumbe wa sauti zaidi wa Kiingereza katika maeneo ya kwanza, utaratibu wa kawaida wa lexico unaongeza uwezo wa kusoma ujumbe wa sauti wa Kiingereza kwa ajili ya wanafunzi wa ESL.</abstract_sw>
      <abstract_sq>Sa e vështirë është për nxënësit e gjuhës angleze-si-një-të-dytë (ESL) të lexojnë tekste të zhurmshme angleze? Do ESL learners need lexical normalization to read noisy English texts?  Këto pyetje mund të ndikojnë gjithashtu në formimin e komunitetit në vendet e rrjetit shoqëror ku dallimet mund t'u atribuohen nxënësve të ESL dhe gjuhëtarëve të anglisht. However, few studies have addressed these questions.  Për këtë qëllim, ndërtuam vlerësues të saktë të lexueshmërisë për të vlerësuar lexueshmërinë e teksteve për nxënësit e ESL. Pastaj i aplikuam këta vlerësues në tekste të zhurmshme angleze për të vlerësuar më tej lexueshmërinë e teksteve. Rezultatet eksperimentale treguan se megjithëse nxënësit e nivelit të mesëm të ESL mund të lexojnë tekstet më të zhurmshëm angleze në fillim, normalizimi lexik përmirëson ndjeshëm lexueshmërinë e teksteve të zhurmshëm angleze për nxënësit e ESL.</abstract_sq>
      <abstract_tr>Iňlisçe-iňlisçe ikinji dilde (ESL) sesli tekstler okamak nähili kyn? ESL öwrenmeleriň gürrüňli iňlisçe metinleri okamak üçin lektik düzenlemesi gerekmi? Bu soraglar hem sosialy neteýän meýdançalaryň arasynda öwrenip biljek toplumyň döwletlerine täsirli bolup biler. Ýöne birnäçe öwrenmek bu soraglary çözdi. Bu sebäpä, biz ESL öwrenmegi üçin tekstiň okaýanlygyny deňleştirmek üçin gaty dogry okaýanlygy tassykatçylary etdik. Sonra bu sahypalary tekstleriň okanlygyny daşyrlamak üçin gürrüňli tekstlere uyguladyk. Denetim netijeleri ESL orta derejesi öwrenýänler ilkinji gezek iňlis dilinde gaty sesli tekstler okap biljekdigini görkezilýärler. Lektikalar normalizasyony ESL öwrenýänler üçin gaty tekstleriň okamak mümkinçiligini gowuraýar.</abstract_tr>
      <abstract_af>Hoe moeilik is dit vir Engels-as-a-tweede taal (ESL) leerders om gelukkige Engels teks te lees? Doen ESL leerneerders nodig leksiese normalisering om gelukkige Engels teks te lees? Hierdie vrae kan ook gemeenskapsformasie op sosiale netwerk tuistes be ïnvloor waar verskille aan ESL leerneerders en Natuurlike Engelske sprekkers kan beïnvloor word. Maar sommige studie het hierdie vraag aangesluit. Tot hierdie einde het ons baie presies leesbaardige asserder gebou om die leesbaarheid van teks vir ESL leerneers te evalueer. Ons het dan hierdie verwerkers toegewend na geluide Engelske teks om die leesbaarheid van die teks verder te asseer. Die eksperimentale resultate het vertoon dat alhoewel middelvlak ESL leerers mees gelukkige engelse tekste in die eerste plek kan lees, leksiese normalisering betekeurig verbeter die leesbaarheid van gelukkige engelse tekste vir ESL leerers.</abstract_af>
      <abstract_am>ኢንግሊዝኛ-በ-ሁለተኛ ቋንቋ (ESL) የድምፅ ንግግሊኛ ጽሑፎችን ለማነብ ምን ችግር ነው? የኢትዮጵያ ተማሪዎቹ ድምፅ የኢንግሊዝኛ ጽሑፎችን ለማንበብ የሚያስፈልጋቸው የሜክሲካዊ ድምፅ ያስፈልጋል? እነዚህ ጥያቄዎች ደግሞ የኢሜይል ተማሪዎች እና የአገሪክ ንግግሊኛ ንግግር ተማሪዎችን በሚደረጉበት ማኅበራዊ መረብ ገጾች ላይ ማኀበረሰብ ይችላሉ፡፡ ነገር ግን ጥቂቶች ትምህርት እነዚህን ጥያቄዎች ተከራከሩት፡፡ ለዚህም ምክንያት የኤስል ተማሪዎችን የጽሑፎችን ማስተካከል ለማስተዋል የቻይነትን ማስታወቂያ አካሄድን ከፍተኛ ፍጥረት ሠራን፡፡ በኋላም የጽሑፎችን መቃውሚያ ለመጠየቅ የኢንግሊዝኛ ጽሑፎችን አሰናብተን ነበር፡፡ የፈተናው ውጤቶች በመካከለኛው ደረጃ የኢስஎல_ተማሪዎችንምንም እንኳ በመጀመሪያው ድምፅ የኢንግሊዝኛ ጽሑፎችን የሚያነብቡ ቢችሉ፣ የሊክሲካዊ ድምፅ የኢሜስል ተማሪዎችን የድምፅ የኢንዝርት ጽሑፎችን አቀማመጥ በማድረግ በኩል ያበረታል፡፡</abstract_am>
      <abstract_hy>Ինչքա՞ն դժվար է անգլերեն-երկրորդ լեզվի (ԵՍԼ) ուսանողների համար աղմկոտ անգլերեն տեքստներ կարդալ: Արդյո՞ք ԷՍԼ-ի ուսանողներին կարիք ունի լեքսիկական նորմալիզացիա, որպեսզի կարդան աղմկոտ անգլերեն տեքստներ: Այս հարցերը կարող են նաև ազդել համայնքի կառուցվածքին սոցիալական ցանցերում, որտեղ տարբերությունները կարող են պատասխանվել ԷՍԼ-ի ուսանողներին և բնիկ անգլերեն խոսացողներին: Այնուամենայնիվ, մի քանի ուսումնասիրություններ լուծել են այս հարցերը: Այսպիսով, մենք կառուցեցինք շատ ճշգրիտ կարդալիության գնահատողներ, որպեսզի գնահատենք ԷՍԼ ուսանողների տեքստների կարդալիությունը: Այնուհետև մենք կիրառեցինք այս գնահատողներին աղմկոտ անգլերեն տեքստերի վրա, որպեսզի ավելի լավ գնահատենք տեքստերի կարդալիությունը: Փորձարկվող արդյունքները ցույց տվեցին, որ չնայած որ միջին մակարդակի ԷՍԼ ուսանողները կարող են ընթերցել անգլերենի ամենաաղմկոտ տեքստերը, լեքսիկական նորմալիզացիան նշանակալիորեն բարելավում է ԷՍԼ ուսանողների աղմկոտ անգլերենի տեքստերի կար</abstract_hy>
      <abstract_az>İngilizce dilində ikinci dil (ESL) öyrənənənlərə səslü İngilizce mətnlərini oxumaq nə çətin ola bilər? Məgər ESL öyrənənənlərin gürültü İngilizə mətnlərini oxumaq üçün leksi normalizasyona ehtiyacı var? Bu suallar də müxtəlif fərqlərə ESL öyrənənicilərə və yerli İngilizce danışanlara istifadə edilə biləcək sosyal şəbəkə sitələrində toplum qurmasına müvəffəq edə bilər. Ancaq az təhsil bu sualları çəkdi. Bu səbəbdə, ESL öyrənənənlərin oxuyabiləcəyi mətnlərin oxuyabiləcəyi qiyməti değerləşdirmək üçün çox ədalətli oxuyabiləcəyi xəbərdarlıqları inşa etdik. Sonra biz bu təşkiləri mətnlərin oxuyabiləcəyini daha çox təşkil etmək üçün gürültü İngilizə mətnlərinə uydurduq. Müxtəlif sonuçlar göstərdi ki, ESL öyrənəniciləri ilk dəfə ən səslü İngilizə məktublarını oxuya bilərlər, laksici normalizasyon ESL öyrəniciləri üçün səslü İngilizə məktubların oxuyabilməsini çox yaxşılaşdırır.</abstract_az>
      <abstract_bn>ইংরেজি এবং দ্বিতীয় ভাষার (এসএল) শিক্ষার জন্য কতটা কঠিন? এসএল শিক্ষার্থীদের কি শব্দ ইংরেজি টেক্সট পড়ার জন্য লেক্সিক্যাল স্বাভাবিকভাবে প্রয়োজন? এই প্রশ্ন সম্ভবত সামাজিক নেটওয়ার্কিং সাইটগুলোতে সম্প্রদায়ের গঠনের প্রভাব ফেলতে পারে, যেখানে এসএল শিক্ষার্থী এবং স্থা তবে কয়েকটি গবেষণা এই প্রশ্নের সাথে আলোচনা করেছে। এসএসএল শিক্ষার্থীদের লেখার পাঠকের ব্যাপারে মূল্য করার জন্য আমরা খুব সঠিকভাবে পাঠকতে বানিয়েছি। তারপর আমরা এই হিসাব গ্রহণ করেছিলাম ইংরেজী লেখাগুলোর পাঠকতার জন্য। পরীক্ষার ফলাফল দেখা যায় যে যদিও মাঝামাঝি স্তরে এসএল শিক্ষার্থীরা প্রথম স্থানে সবচেয়ে আওয়াজে ইংরেজি টেক্সট পড়তে পারে, তবে লেক্সিকাল স্বাভাবিক ব</abstract_bn>
      <abstract_ca>Què difícil és que els alumnes d'anglès en segon lloc llegeixin textos ruidosos d'anglès? Els alumnes d'ESL necessiten normalització lèxica per llegir textos ruidosos en anglès? Aquestes preguntes també poden afectar la formació de la comunitat en llocs de connexió social on les diferències poden ser atribuïdes als alumnes d'ESL i als anglès natius. Però pocs estudis han abordat aquestes preguntes. Per això vam construir assessors de llegibilitat molt precisos per avaluar la llegibilitat dels textos dels alumnes de l'ESL. Després vam aplicar aquests assessors als textos ruidosos en anglès per a seguir evaluant la llegibilitat dels textos. The experimental results showed that although intermediate-level ESL learners can read most noisy English texts in the first place, lexical normalization significantly improves the readability of noisy English texts for ESL learners.</abstract_ca>
      <abstract_fa>برای دانش آموزان انگلیسی به عنوان زبان دوم (ESL) چقدر سخت است که متن انگلیسی صدا را بخوانند؟ آیا دانش آموزان ESL نیاز دارند که متن انگلیسی صدا را بخوانند؟ این سوالات ممکن است همچنین بر سایت‌های شبکه‌های اجتماعی تأثیر دهد که تفاوت‌ها به دانش‌آموزان ESL و زبان‌دهندگان انگلیسی متحده می‌شوند. با این حال، چند مطالعه این سوالات را درباره‌ی آن حل کرده است. برای این کار، ما تحقیقات قابلیت خواندن بسیار دقیق ساختیم تا قابلیت خواندن texts برای دانش آموزان ESL را ارزیابی کنند. سپس ما این آزمایشگران را به متن های زبان انگلیسی استفاده کردیم تا بیشتر ارزیابی قابلیت خواندن متن را ارزیابی کنیم. نتیجه آزمایشی نشان داد که اگرچه دانش‌آموزان سطح بین‌المللی ESL می‌توانند بیشترین متن‌های زبان انگلیسی را در اول بخوانند، عادت زبان‌شناسی بسیار قابلیت خواندن متن‌های زبان انگلیسی برای دانش‌آموزان ESL را بهتر می‌کند</abstract_fa>
      <abstract_bs>Koliko je teško učiteljima engleskog kao drugog jezika (ESL) čitati bukve engleske tekste? Da li učenici ESL trebaju leksičku normalizaciju da pročitaju bučne engleske tekste? Te pitanja mogu također utjecati na formaciju zajednice na društvene mreže gdje se razlike mogu priključiti učenicima ESL-a i govornicima engleskog jezika. Međutim, nekoliko ispitivanja su riješilo te pitanja. Za taj cilj, izgradili smo vrlo precizne procjene čitljivosti kako bi procenili čitljivost tekstova za učenike ESL-a. Zatim smo primjenjivali ove procjene na bučne engleske tekste da bi dalje procenili čitljivost teksta. Eksperimentalni rezultati pokazali su da, iako učenici ESL-a na prosječnom nivou mogu pročitati najbučnije engleske tekste na prvom mjestu, leksička normalizacija značajno poboljšava čitljivost bučnih engleskih tekstova za učenike ESL-a.</abstract_bs>
      <abstract_cs>Jak obtížné je pro studenty angličtiny jako druhého jazyka (ESL) číst hlučné anglické texty? Potřebují studenti ESL lexikální normalizaci k čtení hlučných anglických textů? Tyto otázky mohou také ovlivnit formování komunity na sociálních sítích, kde mohou být rozdíly přičteny studentům ESL a rodilým mluvčím angličtiny. Na tyto otázky se však zabývalo jen málo studií. Za tímto účelem jsme vytvořili vysoce přesné hodnocení čitelnosti textů pro studenty ESL. Tyto hodnotící jsme pak aplikovali na hlučné anglické texty, abychom dále posoudili čitelnost textů. Experimentální výsledky ukázaly, že ačkoli středně pokročilí studenti ESL mohou číst nejvíce hlučných anglických textů v první řadě, lexikální normalizace výrazně zlepšuje čitelnost hlučných anglických textů pro studenty ESL.</abstract_cs>
      <abstract_et>Kui raske on inglise keele kui teise keelena õppijatel lugeda lärmakaid inglise keele tekste? Kas ESL õppijad vajavad leksikaalset normaliseerimist, et lugeda lärmakaid inglise keele tekste? Need küsimused võivad mõjutada ka kogukonna moodustamist sotsiaalvõrgustike saitidel, kus erinevusi võib omistada ESL õppijatele ja emakeelt inglise keelt kõnelevatele. Neid küsimusi on siiski käsitlenud vähesed uuringud. Selleks ehitasime välja väga täpsed loetavuse hindajad, et hinnata teksti loetavust ESL õppijatele. Seejärel rakendasime neid hindajaid lärmakate ingliskeelsete tekstide suhtes, et hinnata edaspidi teksti loetavust. Eksperimentaalsed tulemused näitasid, et kuigi keskmise taseme ESL õppijad oskavad lugeda kõige mürarikamaid inglise keele tekste, parandab leksikaalne normaliseerimine oluliselt mürarikkate inglise keele tekstide loetavust ESL õppijatele.</abstract_et>
      <abstract_fi>Kuinka vaikeaa englanti toisena kielenä (ESL) oppijoiden on lukea meluisia englanninkielisiä tekstejä? Tarvitsevatko ESL-oppijat sanaston normalisointia äänekkäiden englanninkielisten tekstien lukemiseen? Nämä kysymykset voivat myös vaikuttaa yhteisön muodostumiseen sosiaalisissa verkostoissa, joissa eroja voidaan pitää koulunkäynnin oppijoiden ja äidinkielenään englantia puhuvien keskuudessa. Näitä kysymyksiä on kuitenkin käsitelty vain harvoissa tutkimuksissa. Tätä varten rakensimme erittäin tarkkoja luettavuuden arvioijia arvioimaan tekstien luettavuutta ESL-oppijoille. Tämän jälkeen sovelsimme näitä arvioijia äänekkäisiin englanninkielisiin teksteihin arvioidaksemme edelleen tekstien luettavuutta. Kokeelliset tulokset osoittivat, että vaikka keskitason ESL-oppijat osaavat lukea äänekkäimpiä englanninkielisiä tekstejä ylipäätään, leksikaalinen normalisointi parantaa merkittävästi meluisten englanninkielisten tekstien luettavuutta ESL-oppijoille.</abstract_fi>
      <abstract_sk>Kako težko je za učence angleščine kot drugega jezika (ESL) brati hrupna angleška besedila? Ali učenci ESL potrebujejo leksikalno normalizacijo za branje hrupnih angleških besedil? Ta vprašanja lahko vplivajo tudi na oblikovanje skupnosti na spletnih mestih socialnih omrežij, kjer se razlike lahko pripišejo učencem ESL in maternim govorcem angleščine. Vendar pa so ta vprašanja obravnavale le malo študij. V ta namen smo zgradili zelo natančne ocenjevalce berljivosti za ocenjevanje berljivosti besedil za učence ESL. Nato smo te ocenjevalce uporabili za hrupna angleška besedila, da bi nadalje ocenili berljivost besedil. Eksperimentalni rezultati so pokazali, da čeprav učenci ESL srednje stopnje znajo brati najbolj hrupna angleška besedila, leksikalna normalizacija bistveno izboljša berljivost hrupnih angleških besedil za učence ESL.</abstract_sk>
      <abstract_he>כמה קשה ללמודים בשפה אנגלית (ESL) לקרוא טקסטים אנגליים רעשים? האם לומדים ESL צריכים נורמליזציה לקסיקה כדי לקרוא טקסטים אנגליים רעשים? השאלות האלה יכולות גם להשפיע על יצירת קהילה באתרי רשת חברתית שבו ההבדלים יכולים להיות מוגדרים למלמלמידי ESL ולדיבורים אנגליים מקומיים. עם זאת, מעט מחקרים התייחסו לשאלות אלה. למטרה זו, בנינו מערכי היכולת לקרוא מדויקים ביותר כדי להעריך את היכולת לקרוא טקסטים למלמידי ESL. ואז שימשנו את המערכים האלה לטקסטים אנגליים רעשים כדי להעריך יותר את היכולת לקרוא את הטקסטים. התוצאות הניסיוניים הראו שאפילו שמלמידי ESL ברמה בינונית יכולים לקרוא את הטקסטים האנגליים הרעשיים ביותר מלכתחילה, נורמליזציה לקסיקה משפר באופן משמעותי את היכולת לקרוא טקסטים האנגליים הרעשיים עבור למלמידי ESL.</abstract_he>
      <abstract_ha>Yãya nau'in da za'a karanta matsayin Ingiriya-da-na-na-sau (ESL) su yi sauti? Shin, za'a iya amfani da ESL, wa'anar kwamfyuta mai laƙaitar littãfin Ingiriya na sauti? Wannan masu tambayar za su yi amfani da tsarin jamii a kan sitayen mitandaki masu ƙarami, inda za a iya ƙiƙira difwalta zuwa masu baran ESL da saurãren Ingiriya masu native. A lokacin da, karatun kaɗan sun jayayya masu tambayar. Ga wannan, mun gina hakarin karatun masu karatun na karatun, dõmin an evaluate karatun matsayin masu karatun ESL. Sa'an nan kuma muka sami waɗannan muhimmada zuwa littafan Ingiriya da sauri, dõmin ya iya ƙara domin karatun littãfin. Matarin jarrabai sun nuna cewa, kuma kõ dã masu sanar da ESL-daraja ta tsakanin tsakanin, sai su iya karatun karãtun littãfin Ingiriya masu ƙaranci mafi sauti a farkon na farkon, masu kanana da karatun karãtun littattafai na Ingiriya na farko.</abstract_ha>
      <abstract_jv>Iso susah-susahe kanggo kelas Inggris-ngoko siji maneh (ESL) ? Opo kowe ESL luwih jaringan kelakon seneng pisan kelakon kanggo basa gambaran Inggris barang ? Galing-Galing iki iso nggawe informasi komunitas nang situs tambahan komunitas sing mengko karo perusahaan dumadhi kanggo kelas barang ESL karo akeh basa Inggris. Nanging, ketemut kanggo didalaman sing nganggo kesempatan iki. Saiki iki, awak dhéwé nggawe akeh bantuan kanggo Kemerdekaan kang kesempatan kanggo kelengawe kotak nggambar texting kanggo layar kanggo kelas ESL Awak dhéwé aplikasi nambah iki bakal nggambar luwih-luwih bantuan inggiles kanggo bantuan kanggo ngerasakno sing luwih bantuan. Reultaké sing paling nggambar na dhèwèké supaya nik kelas telas-kaling yen ESL sing bisa basa gambar kelas kuwi basa inglisan sing isih sabanjuré, ngerasakno luwih-luwih apik dhèwèké ngerasakno kanggo ngerasakno ketahanan inglisan kanggo layar-layar neng ESL.</abstract_jv>
      <abstract_bo>དབྱིན་ཡིག་གི་སྐད་ཡིག་གཟུགས་གཉིས་ཀྱི་དབྱིན་ཡིག་གཟུགས་རིས་ཀློག་པར་དཀའ་ངལ་ཡིན་ནམ། ESL སློབ་མཁན་གྱི་དབྱིན་ཡིག་གི་ཚིག་ཡིག་དཔར་གཏོང་བའི་སྐད་རྒྱུན་ལྡན་དགོས་སམ། འདྲི་ཚིག་འདི་དག་གིས་སྤྱི་ཚོགས་འབྲེལ་གྱི་དྲ་རྒྱའི་ནང་དུ་ཚོགས་སྤྱི་ཚོགས་ཀྱི་དབྱེ་རིགས་ཀྱང་འགྱུར་བ་དང་། ཁྱད་པར་རྣམས་སྒེར ཡིན་ནའང་། ལྟ་བུའི་ནང་དུ་ཚོར་དྲི་ཚིག་འདི་དག་བསམ་བློ་གཏོང་ཡོད། མཐའ་མ་དེར་བརྟེན། ང་ཚོས་ESL ཤེས་པ་ཚོར་གྱི་ཡིག་གེ་ལྷག་རུང་བའི་བྱ་ཚིག་གི་ཆོས་ཉིད་བདེ་ཞིབ་བཟོ་བྱེད་པའི་ འོན་ཀྱང་། འོག་གི་རྣམ་གྲངས་ཀྱི་མིག་ཡིག་གི་ལས་ཀློག ལག་འཁྱེར་གྱི་གྲུབ་འབྲས་དག་དེ་དག་གི་དབྱིན</abstract_bo>
      </paper>
    <paper id="51">
      <title>Multilingual Sequence Labeling Approach to solve Lexical Normalization</title>
      <author><first>Divesh</first><last>Kubal</last></author>
      <author><first>Apurva</first><last>Nagvenkar</last></author>
      <pages>457–464</pages>
      <abstract>The task of converting a <a href="https://en.wikipedia.org/wiki/Nonstandard_dialect">nonstandard text</a> to a standard and readable text is known as lexical normalization. Almost all the Natural Language Processing (NLP) applications require the text data in normalized form to build quality task-specific models. Hence, lexical normalization has been proven to improve the performance of numerous natural language processing tasks on <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. This study aims to solve the problem of Lexical Normalization by formulating the Lexical Normalization task as a Sequence Labeling problem. This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique. The goal is to use a single model to normalize text in various languages namely <a href="https://en.wikipedia.org/wiki/Croatian_language">Croatian</a>, <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a>, <a href="https://en.wikipedia.org/wiki/Dutch_language">Dutch</a>, <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Indonesian_language">Indonesian-English</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, <a href="https://en.wikipedia.org/wiki/Italian_language">Italian</a>, <a href="https://en.wikipedia.org/wiki/Serbian_language">Serbian</a>, <a href="https://en.wikipedia.org/wiki/Slovene_language">Slovenian</a>, <a href="https://en.wikipedia.org/wiki/Spanish_language">Spanish</a>, <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish</a>, and <a href="https://en.wikipedia.org/wiki/Turkish_language">Turkish-German</a>. This is a shared task in 2021 The 7th Workshop on Noisy User-generated Text (W-NUT) in which the participants are expected to create a system / model that performs lexical normalization, which is the translation of non-canonical texts into their canonical equivalents, comprising data from over 12 languages. The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation. Further, the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> achieves the highest Error Reduction Rate (ERR) score of 61.33 among the participants in the shared task.</abstract>
      <url hash="8be67a39">2021.wnut-1.51</url>
      <bibkey>kubal-nagvenkar-2021-multilingual</bibkey>
      <doi>10.18653/v1/2021.wnut-1.51</doi>
    <title_ar>نهج وسم التسلسل متعدد اللغات لحل التطبيع المعجمي</title_ar>
      <title_pt>Abordagem de rotulagem de sequência multilíngue para resolver a normalização léxica</title_pt>
      <title_fr>Approche d'étiquetage de séquence multilingue pour résoudre la normalisation lexicale</title_fr>
      <title_es>Enfoque de etiquetado secuencial multilingüe para resolver la normalización léxica</title_es>
      <title_ja>語彙正規化を解決するための多言語シーケンスラベリングアプローチ</title_ja>
      <title_zh>解词法规范化者多语言序记</title_zh>
      <title_hi>बहुभाषी अनुक्रम लेबलिंग दृष्टिकोण लेक्सिकल सामान्यीकरण को हल करने के लिए</title_hi>
      <title_ru>Подход к маркировке многоязычной последовательности для решения лексической нормализации</title_ru>
      <title_ga>Cur Chuige Ilteangach Lipéadaithe Seichimh chun Normalú Foclaíochta a réiteach</title_ga>
      <title_el>Πολυγλωσσική προσέγγιση επισήμανσης ακολουθίας για την επίλυση της Λεξικής κανονικοποίησης</title_el>
      <title_hu>Többnyelvű szekvencia címkézési megközelítés a Lexikai Normalizáció megoldásához</title_hu>
      <title_ka>მრავალენგური წერტილის მიღება ლვქსიკალური ნორმალიზაციის გარეშე</title_ka>
      <title_it>Approccio multilingue di etichettatura di sequenza per risolvere la normalizzazione lessica</title_it>
      <title_kk>Лексикалық нормализацияны шешу үшін көп тілдік реттеу жарлығы</title_kk>
      <title_lt>Daugiakalbis sekos ženklinimo metodas, skirtas išspręsti leksinę normalizaciją</title_lt>
      <title_mk>Повеќејазичен пристап до означување на секвенција за решавање на лексикалната нормализација</title_mk>
      <title_ms>Multilingual Sequence Labeling Approach to solve Lexical Normalization</title_ms>
      <title_ml>ലെക്സിക്സിക്കല്‍ നോര്‍മാലിഷന്‍ പരിഹരിക്കാനുള്ള പല ഭാഷകങ്ങളുടെ സെക്കന്‍സ് ലാബില്‍ങ്ങിന്‍റെ പുറത</title_ml>
      <title_mt>Approċċ Multilingwi tat-Tikkettar tas-Sekwenza biex tiġi solvuta n-Normalizzazzjoni Lessika</title_mt>
      <title_mn>Ихэнх хэлний дарааллаар Лексик Нормализацийг шийдэхэд</title_mn>
      <title_no>Fleirspråk merkelappenærming for å løysa leksisk normalisering</title_no>
      <title_pl>Podejście do etykietowania sekwencji wielojęzycznej w celu rozwiązania normalizacji leksykalnej</title_pl>
      <title_ro>Abordare multilingvă de etichetare a secvențelor pentru rezolvarea normalizării lexice</title_ro>
      <title_si>ලෙක්සිකාල් සාමාන්තිකරණය විසඳන්න ගොඩක් භාෂාවක් විසිද්ධ විසිද්ධ විසිද්ධ වෙන්න</title_si>
      <title_so>Luuqado kala duduwan Labeling Approach to solve Normalization Leksikal</title_so>
      <title_sv>Flerspråkig sekvensmärkningsmetod för att lösa Lexical Normalisering</title_sv>
      <title_sr>Mnogjezički pristup označavanja sekvence za rešenje leksičke normalizacije</title_sr>
      <title_ur>بہت سی زبان سکوئنس لابلینگ نزدیک لکسیسی نورملیزی حل کرنے کے لئے</title_ur>
      <title_ta>லெக்சிகியல் இயல்பாக்கத்தை தீர்வு செய்ய பல மொழி வரிசை</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Dùng nhãn hiệu ứng nhiều ngôn ngữ để giải quyết định chuẩn ngôn ngữ</title_vi>
      <title_nl>Meertalige sequence labeling aanpak om Lexical normalisatie op te lossen</title_nl>
      <title_hr>Pristup označavanja višejezičkih sekvencija za rješavanje leksičke normalizacije</title_hr>
      <title_id>Pendekatan Label Sekuensi Berbahasa untuk memecahkan Normalisasi Lexik</title_id>
      <title_de>Multilingual Sequence Labeling Ansatz zur Lösung der Lexikal Normalisierung</title_de>
      <title_bg>Многоезичен подход за етикетиране на последователности за решаване на лексикалната нормализация</title_bg>
      <title_da>Flersproget sekvensmærkning tilgang til løsning af Lexical Normalisation</title_da>
      <title_fa>نزدیک برچسب‌های تعداد زیادی زبان برای حل نورملازی لکسیکی</title_fa>
      <title_ko>단어 법규의 모범화를 해결하는 다중 언어 서열 표기 방법</title_ko>
      <title_sw>Mfumo wa lugha mbalimbali wa kukabiliana na kutatua Uhalifu wa Lexico</title_sw>
      <title_af>Veelvuldige volgorde etiket toegang om Leksiese Normaliseering te los</title_af>
      <title_sq>Përqafimi i etiketave të sekuencës shumëgjuhëse për të zgjidhur normalizimin leksikal</title_sq>
      <title_am>የቋንቋ ቋንቋዎች</title_am>
      <title_hy>Multilingual Sequence Labeling Approach to solve Lexical Normalization</title_hy>
      <title_tr>Çoklu diller</title_tr>
      <title_az>Çoxlu dil Sequence Labeling Approach to solve Lexical Normalization</title_az>
      <title_bn>লেক্সিকাল স্বাভাবিকভাবে সমাধানের জন্য বহুভাষী সেকেন্স লেবিলিং আগমন</title_bn>
      <title_cs>Přístup k vícejazyčnému popisování sekvencí k řešení Lexické normalizace</title_cs>
      <title_et>Mitmekeelse järjestikuse märgistamise lähenemisviis leksiilse normaliseerimise lahendamiseks</title_et>
      <title_ca>L'enfocament multilingüe d'etiquetar la seqüència per resoldre la normalització lexical</title_ca>
      <title_bs>Mnogjezički pristup označavanja sekvence za rešenje leksičke normalizacije</title_bs>
      <title_fi>Monikielinen sekvenssimerkintĂ¤menetelmĂ¤ Lexical Normalization -ratkaisun ratkaisemiseksi</title_fi>
      <title_ha>Labeling Approach to solve Lex normal</title_ha>
      <title_he>גישה לטביעות רצף רבות לשונות כדי לפתור נורמליזציה לקסית</title_he>
      <title_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness</title_jv>
      <title_sk>Pristop večjezičnega označevanja zaporedja za reševanje leksične normalizacije</title_sk>
      <title_bo>སྐད་རིགས་དབྱིབས་གྱི་དབྱེ་བ་ལྟར་པར་གནད་དོན་ཐལ་ཆེ་ཤོས་ཀྱི་སྤྱིར་བཏང་བ།</title_bo>
      <abstract_ar>تُعرف مهمة تحويل نص غير قياسي إلى نص قياسي وقابل للقراءة بالتطبيع المعجمي. تتطلب جميع تطبيقات معالجة اللغة الطبيعية (NLP) تقريبًا بيانات نصية في شكل عادي لبناء نماذج نوعية خاصة بالمهام. ومن ثم ، فقد ثبت أن التطبيع المعجمي يحسن أداء العديد من مهام معالجة اللغة الطبيعية على وسائل التواصل الاجتماعي. تهدف هذه الدراسة إلى حل مشكلة التطبيع المعجمي من خلال صياغة مهمة التطبيع المعجمي كمسألة تسمية التسلسل. يقترح هذا البحث نهج وسم التسلسل لحل مشكلة التطبيع المعجمي بالاشتراك مع تقنية محاذاة الكلمات. الهدف هو استخدام نموذج واحد لتطبيع النص بلغات مختلفة وهي الكرواتية والدانماركية والهولندية والإنجليزية والإندونيسية الإنجليزية والألمانية والإيطالية والصربية والسلوفينية والإسبانية والتركية والتركية الألمانية. هذه مهمة مشتركة في "2021 The 7th Workshop on Noisy User Made Text (W-NUT)" حيث يُتوقع من المشاركين إنشاء نظام / نموذج يقوم بالتطبيع المعجمي ، وهو ترجمة نصوص غير متعارف عليها إلى معادلاتها الأساسية ، والتي تشتمل على بيانات من أكثر من 12 لغة. يحقق النموذج الفردي متعدد اللغات المقترح درجة ERR إجمالية قدرها 43.75 في التقييم الذاتي ودرجة إجمالي مرفق مُصنَّف (LAS) تبلغ 63.12 في التقييم الخارجي. علاوة على ذلك ، تحقق الطريقة المقترحة أعلى درجة في معدل تقليل الخطأ (ERR) بلغت 61.33 بين المشاركين في
مهمة مشتركة. تسلط هذه الدراسة الضوء على تأثيرات استخدام بيانات تدريب إضافية للحصول على نتائج أفضل بالإضافة إلى استخدام نموذج لغوي مدرب مسبقًا ومدرب على لغات متعددة بدلاً من لغة واحدة فقط.</abstract_ar>
      <abstract_fr>La tâche de conversion d'un texte non standard en un texte standard et lisible est connue sous le nom de normalisation lexicale. Presque toutes les applications de traitement du langage naturel (NLP) nécessitent les données texte sous forme normalisée pour créer des modèles spécifiques aux tâches de qualité. Il a donc été prouvé que la normalisation lexicale améliore les performances de nombreuses tâches de traitement du langage naturel sur les réseaux sociaux. Cette étude vise à résoudre le problème de la normalisation lexicale en formulant la tâche de normalisation lexicale comme un problème d'étiquetage de séquence. Cet article propose une approche d'étiquetage de séquence pour résoudre le problème de la normalisation lexicale en combinaison avec la technique d'alignement de mots. L'objectif est d'utiliser un modèle unique pour normaliser le texte dans différentes langues, à savoir le croate, le danois, le néerlandais, l'anglais, l'indonésien-anglais, l'allemand, l'italien, le serbe, le slovène, l'espagnol, le turc et le turco-allemand. Il s'agit d'une tâche partagée dans « 2021 The 7th Workshop on Noisy User-generated Text (W-NUT) » dans laquelle les participants sont censés créer un système/modèle qui effectue une normalisation lexicale, c'est-à-dire la traduction de textes non canoniques dans leurs équivalents canoniques, comprenant des données provenant de plus de 12 langues. Le modèle multilingue unique proposé atteint un score ERR global de 43,75 pour l'évaluation intrinsèque et un score global de pièces jointes étiquetées (LAS) de 63,12 pour l'évaluation extrinsèque. En outre, la méthode proposée permet d'obtenir le score le plus élevé de taux de réduction d'erreur (ERR) de 61,33 parmi les participants au
tâche partagée. Cette étude met en évidence les effets de l'utilisation de données de formation supplémentaires pour obtenir de meilleurs résultats, ainsi que de l'utilisation d'un modèle linguistique pré-formé formé sur plusieurs langues plutôt que sur une seule langue.</abstract_fr>
      <abstract_es>La tarea de convertir un texto no estándar en un texto estándar y legible se conoce como normalización léxica. Casi todas las aplicaciones de procesamiento de lenguaje natural (NLP) requieren los datos de texto en forma normalizada para crear modelos específicos de tareas de calidad. Por lo tanto, se ha demostrado que la normalización léxica mejora el rendimiento de numerosas tareas de procesamiento del lenguaje natural en las redes sociales. Este estudio tiene como objetivo resolver el problema de la normalización léxica mediante la formulación de la tarea de normalización léxica como un problema de etiquetado de secuencias. Este artículo propone un enfoque de etiquetado de secuencias para resolver el problema de la normalización léxica en combinación con la técnica de alineación de palabras. El objetivo es utilizar un modelo único para normalizar el texto en varios idiomas, a saber, croata, danés, holandés, inglés, indonesio-inglés, alemán, italiano, serbio, esloveno, español, turco y turco-alemán. Esta es una tarea compartida en «2021 The 7th Workshop on Noisy User Generated Text (W-NUT)» en la que se espera que los participantes creen un sistema/modelo que realice la normalización léxica, que es la traducción de textos no canónicos a sus equivalentes canónicos, que comprende datos de más de 12 idiomas. El modelo multilingüe único propuesto logra una puntuación ERR general de 43,75 en la evaluación intrínseca y una puntuación general de apego etiquetado (LAS) de 63,12 en la evaluación extrínseca. Además, el método propuesto logra la puntuación más alta de la Tasa de Reducción de Errores (ERR) de 61,33 entre los participantes en el
tarea compartida. Este estudio destaca los efectos del uso de datos de capacitación adicionales para obtener mejores resultados, así como el uso de un modelo de idioma previamente entrenado y entrenado en varios idiomas en lugar de solo en un idioma.</abstract_es>
      <abstract_ja>非標準テキストを標準的で読み取り可能なテキストに変換するタスクは、辞書正規化として知られています。 ほとんどすべての自然言語処理（ NLP ）アプリケーションは、高品質のタスク固有のモデルを構築するために、正規化された形式のテキストデータを必要とします。 したがって、語彙的正規化は、ソーシャルメディア上の多数の自然言語処理タスクのパフォーマンスを改善することが証明されている。 本研究では、シーケンスラベリング問題として、Lexical Normizationタスクを定式化することで、Lexical Normizationの問題を解決することを目的としている。 本論文では、単語整列手法と組み合わせて、Lexical Normizationの問題を解決するためのシーケンス標識アプローチを提案した。 単一のモデルを使用して、クロアチア語、デンマーク語、オランダ語、英語、インドネシア語-英語、ドイツ語、イタリア語、セルビア語、スロベニア語、スペイン語、トルコ語、トルコ語-ドイツ語のさまざまな言語のテキストを正規化することを目標としています。 これは、「2021年Noisy User - Generated Text (W - NUT)に関する第7回ワークショップ」で共有されたタスクであり、参加者は、12以上の言語からのデータを含む、非正規テキストの正規化への翻訳である、辞書正規化を実行するシステム/モデルを作成することが期待されています。 提案された単一の多言語モデルは、内因性評価で43.75の全体的なエラースコアと、外因性評価で63.12の全体的なラベル付き添付スコア（ LAS ）スコアを達成する。 さらに、提案された方法は、
共有タスク。この研究では、追加のトレーニングデータを使用してより良い結果を得ることと、1つの言語のみではなく、複数の言語でトレーニングされた事前トレーニングされた言語モデルを使用することの効果を強調しています。</abstract_ja>
      <abstract_pt>A tarefa de converter um texto não padrão em um texto padrão e legível é conhecida como normalização léxica. Quase todos os aplicativos de processamento de linguagem natural (NLP) exigem os dados de texto em formato normalizado para construir modelos específicos de tarefas de qualidade. Assim, a normalização lexical provou melhorar o desempenho de inúmeras tarefas de processamento de linguagem natural nas mídias sociais. Este estudo visa resolver o problema de Normalização Lexical formulando a tarefa de Normalização Lexical como um problema de Rotulagem de Sequências. Este artigo propõe uma abordagem de rotulagem de sequências para resolver o problema de Normalização Lexical em combinação com a técnica de alinhamento de palavras. O objetivo é usar um único modelo para normalizar o texto em vários idiomas, como croata, dinamarquês, holandês, inglês, indonésio-inglês, alemão, italiano, sérvio, esloveno, espanhol, turco e turco-alemão. Esta é uma tarefa compartilhada no “2021 The 7th Workshop on Noisy User-generated Text (W-NUT)” em que se espera que os participantes criem um sistema/modelo que realize a normalização lexical, que é a tradução de textos não canônicos em seus equivalentes canônicos, compreendendo dados de mais de 12 idiomas. O modelo único multilíngue proposto alcança uma pontuação geral de ERR de 43,75 na avaliação intrínseca e uma pontuação geral de Labeled Attachment Score (LAS) de 63,12 na avaliação extrínseca. Além disso, o método proposto alcança a pontuação mais alta de Error Reduction Rate (ERR) de 61,33 entre os participantes do
tarefa compartilhada. Este estudo destaca os efeitos do uso de dados de treinamento adicionais para obter melhores resultados, bem como o uso de um modelo de idioma pré-treinado treinado em vários idiomas, em vez de apenas em um idioma.</abstract_pt>
      <abstract_zh>转非标准文本为率,可读谓之词法规范化。 凡诸自然语言处 (NLP) 应用程序皆须规范化文本数以构特定于任高质量。 故词汇规范化已证可以崇社交媒体众自然语言之性也。 本研旨在将词法规范化务表为序标记以决词法规范化。 本文立序标记之法,合词对齐术以决词法规范化问。 以单一模规范化诸语言本,即克罗地亚语、丹麦语、荷兰语、英语、印度尼西亚语-英语、德语、意大利语、塞尔维亚语、斯洛文尼亚语、西班牙语、土耳其语、土耳其语-德语。 此"2021年第7届嘈杂用户生成文本研讨会(W-NUT)"之一同务,其参与者创一行词汇规范化之统/,此将非规范文本转为规范等效项,盖出于过12之数也。 所言单一多言模在内评估之总体ERR分为43.75,外在评估之总体标记依评分(LAS)得分为63.12。 此外,受试者中最高差降低率(ERR)得分61.33。
共其事。 本研调额外训练数以得其善,及多种语言习言语模样(非徒一言练)之效也。</abstract_zh>
      <abstract_ru>Задача преобразования нестандартного текста в стандартный и читаемый текст известна как лексическая нормализация. Почти все приложения для обработки естественного языка (NLP) требуют текстовых данных в нормализованной форме для построения качественных моделей, специфичных для конкретных задач. Таким образом, было доказано, что лексическая нормализация улучшает выполнение многочисленных задач по обработке естественного языка в социальных сетях. Целью данного исследования является решение проблемы лексической нормализации путем постановки задачи лексической нормализации как задачи маркировки последовательностей. В данной работе предлагается подход к маркировке последовательностей для решения проблемы лексической нормализации в сочетании с методикой выравнивания слов. Цель состоит в том, чтобы использовать единую модель для нормализации текста на различных языках, а именно: хорватском, датском, голландском, английском, индонезийском-английском, немецком, итальянском, сербском, словенском, испанском, турецком и турецко-немецком. Это общая задача в «2021 7-ом семинаре по шумному пользовательскому тексту (W-NUT)», в котором участники, как ожидается, создадут систему/модель, которая выполняет лексическую нормализацию, то есть перевод неканонических текстов в их канонические эквиваленты, содержащие данные с более чем 12 языков. Предлагаемая единая многоязычная модель достигает общего балла ОШИБКИ 43,75 по внутренней оценке и общего балла меченого вложения (LAS) 63,12 по внешней оценке. Кроме того, предложенный способ обеспечивает наивысший балл по шкале Error Reduction Rate (ERR) 61,33 среди участников
это исследование подчеркивает эффекты использования дополнительных данных обучения для получения лучших результатов, а также использования предварительно обученной модели языка, обученной на нескольких языках, а не только на одном языке.</abstract_ru>
      <abstract_hi>एक गैर-मानक पाठ को एक मानक और पठनीय पाठ में परिवर्तित करने के कार्य को लेक्सिकल सामान्यीकरण के रूप में जाना जाता है। लगभग सभी प्राकृतिक भाषा प्रसंस्करण (एनएलपी) अनुप्रयोगों को गुणवत्ता कार्य-विशिष्ट मॉडल बनाने के लिए सामान्यीकृत रूप में पाठ डेटा की आवश्यकता होती है। इसलिए, लेक्सिकल सामान्यीकरण सोशल मीडिया पर कई प्राकृतिक भाषा प्रसंस्करण कार्यों के प्रदर्शन में सुधार करने के लिए साबित हुआ है। इस अध्ययन का उद्देश्य एक अनुक्रम लेबलिंग समस्या के रूप में लेक्सिकल सामान्यीकरण कार्य को तैयार करके लेक्सिकल सामान्यीकरण की समस्या को हल करना है। यह पेपर शब्द-संरेखण तकनीक के साथ संयोजन में लेक्सिकल सामान्यीकरण की समस्या को हल करने के लिए एक अनुक्रम लेबलिंग दृष्टिकोण का प्रस्ताव करता है। लक्ष्य क्रोएशियाई, डेनिश, डच, अंग्रेजी, इंडोनेशियाई-अंग्रेजी, जर्मन, इतालवी, सर्बियाई, स्लोवेनियाई, स्पेनिश, तुर्की और तुर्की-जर्मन जैसी विभिन्न भाषाओं में पाठ को सामान्य करने के लिए एक मॉडल का उपयोग करना है। यह "2021 में एक साझा कार्य है शोर उपयोगकर्ता-जनित पाठ (डब्ल्यू-एनयूटी) पर 7 वीं कार्यशाला" जिसमें प्रतिभागियों से एक प्रणाली / मॉडल बनाने की उम्मीद की जाती है जो लेक्सिकल सामान्यीकरण करता है, जो गैर-विहित ग्रंथों का अनुवाद है उनके विहित समकक्ष, जिसमें 12 से अधिक भाषाओं से डेटा शामिल है। प्रस्तावित एकल बहुभाषी मॉडल आंतरिक मूल्यांकन पर 43.75 का समग्र ERR स्कोर और बाह्य मूल्यांकन पर 63.12 का समग्र लेबल अनुलग्नक स्कोर (एलएएस) स्कोर प्राप्त करता है। इसके अलावा, प्रस्तावित विधि में प्रतिभागियों के बीच 61.33 की उच्चतम त्रुटि कमी दर (ERR) स्कोर प्राप्त करता है
साझा कार्य। यह अध्ययन बेहतर परिणाम प्राप्त करने के लिए अतिरिक्त प्रशिक्षण डेटा का उपयोग करने के साथ-साथ केवल एक भाषा के बजाय कई भाषाओं पर प्रशिक्षित पूर्व-प्रशिक्षित भाषा मॉडल का उपयोग करने के प्रभावों पर प्रकाश डालता है।</abstract_hi>
      <abstract_ga>Tugtar normalú foclóireachta ar an tasc a bhaineann le téacs neamhchaighdeánach a thiontú go téacs caighdeánach inléite. Éilíonn beagnach gach feidhmchlár um Phróiseáil Teanga Nádúrtha (NLP) na sonraí téacs i bhfoirm normalaithe chun samhlacha ardchaighdeáin a bhaineann go sonrach le tasc a chruthú. Mar sin, tá sé cruthaithe go gcuireann normalú foclóireachta feabhas ar fheidhmíocht iliomad tascanna próiseála teanga nádúrtha ar na meáin shóisialta. Tá sé mar aidhm ag an staidéar seo fadhb an normalaithe fhoclóra a réiteach tríd an tasc um Normalú Foclaíochta a fhoirmliú mar fhadhb Lipéadaithe Seichimh. Molann an páipéar seo cur chuige lipéadaithe seichimh chun fadhb an Normalaithe Foclóra a réiteach in éineacht leis an teicníc ailíniú focal. Is é an sprioc múnla amháin a úsáid chun téacs a normalú i dteangacha éagsúla, eadhon an Chróitis, an Danmhairgis, an Ollainnis, an Béarla, an Indinéisis-Béarla, an Ghearmáinis, an Iodáilis, an Seirbis, an tSlóivéinis, an Spáinnis, an Tuircis agus an Tuircis-Gearmáinis. Is tasc comhroinnte é seo in “2021 An 7ú Ceardlann ar Théacs Torann a Ghintear le hÚsáideoirí (W-NUT)” ina bhfuiltear ag súil go gcruthóidh na rannpháirtithe córas/múnla a dhéanann normalú foclóireachta, is é sin téacsanna neamhchanónacha a aistriú go téacsanna neamhchanónacha. a gcomhionann canónacha, ina bhfuil sonraí ó níos mó ná 12 theanga. Baineann an tsamhail ilteangach aonair atá beartaithe amach scór iomlán ERR de 43.75 ar mheastóireacht intreach agus scór foriomlán Scór Ceangailte Lipéadaithe (LAS) de 63.12 ar mheastóireacht eistreach. Ina theannta sin, baintear amach an scór is airde don Ráta Laghdaithe Earráide (ERR) de 61.33 i measc na rannpháirtithe sa mhodh molta.
tasc roinnte. Aibhsíonn an staidéar seo na héifeachtaí a bhaineann le sonraí oiliúna breise a úsáid chun torthaí níos fearr a fháil chomh maith le húsáid a bhaint as samhail Teanga réamh-oilte atá oilte ar iltheangacha seachas ar aon teanga amháin.</abstract_ga>
      <abstract_hu>A nem szabványos szöveg szabványos és olvasható szöveggé konvertálásának feladata lexikai normalizáció. Szinte az összes Natural Language Processing (NLP) alkalmazás szükségessé teszi a szövegadatokat normalizált formában ahhoz, hogy minőségi feladatspecifikus modelleket készítsen. Ezért a lexikai normalizáció bizonyítottan javítja számos természetes nyelvfeldolgozási feladat teljesítményét a közösségi médián. A tanulmány célja a Lexikai Normalizáció problémájának megoldása a Lexikai Normalizációs feladat megfogalmazása sorozatcímkézési problémaként. Ez a tanulmány egy szekvencia címkézési megközelítést javasol a Lexikai Normalizáció problémájának megoldására a szóigazítási technikával kombinálva. A cél egyetlen modell használata a különböző nyelveken, nevezetesen horvát, dán, holland, angol, indonéz-angol, német, olasz, szerb, szlovén, spanyol, török és török-német szövegek normalizálására. Ez egy közös feladat a "2021 The 7th Workshop on Noisy User-Generated Text (W-NUT)" című műhelyben, amelyben a résztvevők elvárják, hogy létrehozzanak egy olyan rendszert/modellt, amely lexikai normalizálást végez, ami a nem kanonikus szövegek kanonikus megfelelőjükre történő fordítása, amely több mint 12 nyelv adatait tartalmazza. A javasolt egyetlen többnyelvű modell a belső értékelés esetén 43,75 ERR pontszámot ér el, a külső értékelés esetén pedig 63,12 értéket ér el. Ezenkívül a javasolt módszer a legnagyobb hibacsökkentési arányt (ERR) érte el a résztvevők között 61,33-at.
közös feladat. Ez a tanulmány kiemeli a további képzési adatok jobb eredmények érdekében történő felhasználásának hatásait, valamint egy előre képzett nyelvi modell használatát, amely nem csak egy nyelven képzett.</abstract_hu>
      <abstract_el>Το έργο της μετατροπής ενός μη τυποποιημένου κειμένου σε ένα τυποποιημένο και αναγνώσιμο κείμενο είναι γνωστό ως λεξική ομαλοποίηση. Σχεδόν όλες οι εφαρμογές επεξεργασίας φυσικής γλώσσας απαιτούν τα δεδομένα κειμένου σε κανονικοποιημένη μορφή για την κατασκευή ποιοτικών μοντέλων ειδικά για την εργασία. Ως εκ τούτου, η λεξική ομαλοποίηση έχει αποδειχθεί ότι βελτιώνει την απόδοση πολλών εργασιών επεξεργασίας φυσικής γλώσσας στα μέσα κοινωνικής δικτύωσης. Η παρούσα μελέτη στοχεύει στην επίλυση του προβλήματος της Λεξικής Κανονικής Τυποποίησης διατυπώνοντας την εργασία Λεξικής Κανονικής Κανονικής ως πρόβλημα Επισήμανσης Ακολουθιών. Η παρούσα εργασία προτείνει μια προσέγγιση επισήμανσης ακολουθίας για την επίλυση του προβλήματος της Λεξικής Κανονικής Κανονικής σε συνδυασμό με την τεχνική ευθυγράμμισης λέξεων. Στόχος είναι η χρήση ενός ενιαίου μοντέλου για την ομαλοποίηση κειμένου σε διάφορες γλώσσες, συγκεκριμένα Κροατικά, Δανικά, Ολλανδικά, Αγγλικά, Ινδονησιακά-Αγγλικά, Γερμανικά, Ιταλικά, Σερβικά, Σλοβενικά, Ισπανικά, Τουρκικά και Τουρκικά-Γερμανικά. Αυτή είναι μια κοινή εργασία στο "2021 Το 7ο Εργαστήριο για το θορυβώδες κείμενο που δημιουργείται από τους χρήστες" (στο οποίο αναμένεται από τους συμμετέχοντες να δημιουργήσουν ένα σύστημα/μοντέλο που εκτελεί λεξική ομαλοποίηση, δηλαδή τη μετάφραση μη κανονικών κειμένων στα κανονικά ισοδύναμά τους, που περιλαμβάνει δεδομένα από πάνω από δώδεκα γλώσσες. Το προτεινόμενο ενιαίο πολύγλωσσο μοντέλο επιτυγχάνει μια συνολική βαθμολογία ΕΡ 43.75 στην εσωτερική αξιολόγηση και μια συνολική βαθμολογία επισυνάπωσης (LAS) 63.12 στην εξωτερική αξιολόγηση. Περαιτέρω, η προτεινόμενη μέθοδος επιτυγχάνει την υψηλότερη βαθμολογία ποσοστού μείωσης σφαλμάτων 61.33 μεταξύ των συμμετεχόντων στο διαγωνισμό.
κοινή εργασία. Αυτή η μελέτη υπογραμμίζει τις επιπτώσεις της χρήσης πρόσθετων δεδομένων κατάρτισης για την επίτευξη καλύτερων αποτελεσμάτων καθώς και της χρήσης ενός προ-εκπαιδευμένου μοντέλου γλώσσας εκπαιδευμένου σε πολλές γλώσσες και όχι μόνο σε μία γλώσσα.</abstract_el>
      <abstract_lt>Nestandartinio teksto konvertavimo į standartinį ir skaitomą tekstą užduotis vadinama leksiniu normalizavimu. Beveik visoms gamtinių kalbų apdorojimo (NLP) programoms reikalingi normalizuoti teksto duomenys, kad būtų sukurti kokybės uždaviniams būdingi modeliai. Taigi įrodyta, kad tekstinė normalizacija pagerino daugelio gamtinių kalbų apdorojimo užduočių socialinėje žiniasklaidoje vykdymą. Šiuo tyrimu siekiama išspręsti leksinio normalizavimo problem ą formuluojant leksinio normalizavimo užduotį kaip sekos ženklinimo problemą. This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique.  Tikslas – naudoti vieną model į tekstui normalizuoti įvairiomis kalbomis, būtent kroatijos, danų, olandų, anglų, indonezijos-anglų, vokiečių, italų, serbų, slovėnų, ispanų, turkų ir turkų-vokiečių kalbomis. Tai bendra užduotis "2021 m. 7-asis triukšmo vartotojų sukelto teksto seminaras (W-NUT)", kuriame dalyviai tikimasi sukurti sistemą ir (arba) model į, kuris atlieka leksinę normalizaciją, t. y. ne kanonikos tekstų vertimą į kanonikos ekvivalentus, apimančius daugiau kaip 12 kalbų duomenis. Siūlomas vienas daugiakalbis modelis pasiekia 43,75 bendro ERR vertinimo rezultatą dėl vidinio vertinimo ir 63,12 bendro pažymėto priedėlio vertinimo rezultatą dėl išorinio vertinimo. Be to, siūlomu metodu pasiektas didžiausias klaidų mažinimo koeficiento (ERR) rodiklis 61,33 tarp dalyvių
bendra užduotis. Šiame tyrime pabrėžiamas papildomų mokymo duomenų naudojimas siekiant geresnių rezultatų ir iš anksto parengto kalbos modelio, mokomo įvairiomis kalbomis, o ne tik viena kalba, poveikis.</abstract_lt>
      <abstract_it>Il compito di convertire un testo non standard in un testo standard e leggibile è noto come normalizzazione lessicale. Quasi tutte le applicazioni Natural Language Processing (NLP) richiedono i dati di testo in forma normalizzata per creare modelli di qualità specifici per attività. Pertanto, la normalizzazione lessicale ha dimostrato di migliorare le prestazioni di numerosi compiti di elaborazione del linguaggio naturale sui social media. Questo studio mira a risolvere il problema della normalizzazione lessicale formulando il compito di normalizzazione lessicale come problema di etichettatura di sequenza. Questo articolo propone un approccio di etichettatura sequenziale per risolvere il problema della normalizzazione lessicale in combinazione con la tecnica di allineamento delle parole. L'obiettivo è quello di utilizzare un unico modello per normalizzare il testo in varie lingue: croato, danese, olandese, inglese, indonesiano-inglese, tedesco, italiano, serbo, sloveno, spagnolo, turco e turco-tedesco. Si tratta di un compito condiviso nel '2021 The 7th Workshop on Noisy User-Generated Text (W-NUT)' in cui i partecipanti sono tenuti a creare un sistema/modello che esegue la normalizzazione lessicale, che è la traduzione di testi non canonici nei loro equivalenti canonici, comprendente dati provenienti da oltre 12 lingue. Il modello multilingue unico proposto raggiunge un punteggio ERR complessivo di 43,75 sulla valutazione intrinseca e un punteggio LAS (Labeled Attachment Score) complessivo di 63,12 sulla valutazione esterna. Inoltre, il metodo proposto raggiunge il punteggio più alto di Error Reduction Rate (ERR) di 61,33 tra i partecipanti al programma.
compito condiviso. Questo studio evidenzia gli effetti dell'utilizzo di ulteriori dati di formazione per ottenere risultati migliori e dell'utilizzo di un modello linguistico pre-addestrato addestrato su più lingue piuttosto che su una sola lingua.</abstract_it>
      <abstract_ka>ბოსტანდარტული ტექსტის გადაცვლა სტანდარტული და კითხვა ტექსტის დავამუშავება, როგორც ლექსიკალური ნორმალიზაცია. პირდაპირად ყველა ნაირადი ენის პროცესი (NLP) პროგრამები ტექსტის მონაცემების ნორმალურიზებული ფორმაში მოჭირდება, რომ კოლეტური დავალების განსაზღვრული ამიტომ, ლექსიკალური ნორმალიზაცია სოციალური მედიაში უფრო მრავალური ენერგიის პროცესი დავამუშავება. ამ სწავლების მიზეზია, რომ Lexical Normalization-ის პრობლემების გარეშე, როგორც Lexical Normalization-ის პრობლემების გარეშე. ამ დოკუმენტის შესაძლებელია სიტყვების დაწყვეტილების ტექნექციის პრობლემალიზაციის გარეშე. მიზეზი არის ერთი მოდელი გამოყენება, რომ ტექსტის ნორმალიზაციას განსხვავებული ენებით: ჰორვატი, დენური, დოლანდიული, ანგლისური, ინდონეთო- ანგლისური, დომიანი, თრალიანი, სერბული, ჟლოვანიანი, შ ეს არის '2021' შვიდი სამუშაო მომხმარებელი ტექსტის 7-ი სამუშაო, რომელიც მომხმარებელი შექმნა სისტემი/მოდელის შექმნა, რომელიც ლექსიკალური ნორმალიზაციას გავაკეთებს, რომელიც არ-კანონიკალური ტექსტის გადაწყვეტილი სამუშაო პროგრამის ერთი მრავალენგური მოდელის შესაძლებლობა 43.75 წერტილის შესაძლებლობა ინტერნექტური განსაზღვრებაში და საერთო დაკავშირებული დაკავშირების შესაძლებლობა (LAS) წერტილი 63.12 წერტილის შესაძლებლობაში. დამატებით, პროგრამის მიღება უფრო დიდი შეცდომის შემცირების სინამდვილეში 61.33 წერტილი.
გაყოფილი დავალება. ამ სწავლის შესაბამისი შესაბამისი მონაცემების გამოყენების ეფექტები, რომელიც უკეთესი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი შესაბამისი მდეგი ენაზე</abstract_ka>
      <abstract_ms>Tugas menukar teks bukan piawai ke teks piawai dan boleh dibaca dikenali sebagai normalisasi leksikal. Hampir semua aplikasi Pemprosesan Bahasa Alami (NLP) memerlukan data teks dalam bentuk normalisasi untuk membina model khusus tugas. Oleh itu, normalisasi leksikal telah terbukti untuk meningkatkan prestasi banyak tugas pemprosesan bahasa alam pada media sosial. Ujian ini bertujuan untuk menyelesaikan masalah Normalisasi Leksikal dengan membentuk tugas Normalisasi Leksikal sebagai masalah Labeling Sequence. Kertas ini mencadangkan pendekatan label urutan untuk menyelesaikan masalah Normalisasi Leksikal dalam kombinasi dengan teknik penyesuaian perkataan. The goal is to use a single model to normalize text in various languages namely Croatian, Danish, Dutch, English, Indonesian-English, German, Italian, Serbian, Slovenian, Spanish, Turkish, and Turkish-German.  Ini adalah tugas berkongsi pada '2021 Workshop ke-7 tentang Teks Yang Dijana oleh Pengguna Bunyi (W-NUT)' di mana peserta dijangka untuk mencipta sistem/model yang melaksanakan normalisasi leksikal, iaitu terjemahan teks bukan-kanonic ke dalam ekvivalen kanonical mereka, yang mengandungi data dari lebih dari 12 bahasa. Model berbilang bahasa tunggal yang diusulkan mencapai skor ERR umum 43.75 pada penilaian dalaman dan skor Lampiran Label (LAS) umum 63.12 pada penilaian luar. Further, the proposed method achieves the highest Error Reduction Rate (ERR) score of 61.33 among the participants in the
tugas berkongsi. kajian ini menyatakan kesan menggunakan data latihan tambahan untuk mendapatkan keputusan yang lebih baik serta menggunakan model bahasa yang dilatih-dilatih sebelum dilatih dalam bahasa berbilang daripada hanya dalam satu bahasa.</abstract_ms>
      <abstract_kk>Стандартты емес мәтінді стандартты және оқуға болатын мәтінде аудару тапсырмасы лексикалық нормализация деп белгіледі. Барлық Түзіндік тіл процессоры (NLP) қолданбаларының кәдімгі түрде мәтін деректері тапсырмалар үлгілерін құру үшін керек. Сондықтан, лексикалық нормализация социалдық медиақтағы көптеген табиғи тілдерді өңдеу тапсырмаларын жақсарту үшін көрсетілді. Бұл зерттеулер лексикалық нормализацияның мәселесін шешу үшін лексикалық нормализацияның тапсырмасын реттеу мәселесі ретінде формулизациялау үшін. Бұл қағаз лексикалық нормализацияның мәселесін біріктіру үшін келесі жарлық жарлықтау тәсілігін ұсынады. Мақсат - бір түрлі тілдерде мәтінді нормализациялау үшін қолдану - хорватша, Дания, Голландша, ағылшын, Индонезия- Англис, неміс, итальян, сербша, Словения, Испан, Түрк және Түрк- неміс. Бұл '2021' дегенде ортақтастырылған тапсырма. Жоқ пайдаланушылардың жасалған мәтін (W-NUT) 7- ші жұмыс салуы. Қатысушылардың лексикалық нормализацияны орындайтын жүйе/ моделі құрылады. Бұл - каноникалық емес мәтіндердің аудармасы, 12 тілден артық деректерді қо Бірнеше тілдік үлгі жалпы мәлімет түрлі оқу үшін 43,75 жалпы ERR нәтижесін жеткізеді және жалпы белгіленген тіркемелер нәтижесі (LAS) 63,12 жалпы оқу үшін. Келесіден бұл таңдалған әдіс қателердің 61, 33 деген жоғары қате қысқарту жиілігін жеткізеді.
ортақтастырылған тапсырма. Бұл зерттеулер қосымша оқыту деректерін қолдану үшін жақсы нәтижелерді және бір тілден емес, бірнеше тілде оқылған тіл үлгісін қолдану үшін қолданатын нәтижелерді белгілеп бер</abstract_kk>
      <abstract_mk>Задачата за претворање на нестандарден текст во стандарден и читлив текст е позната како лексикална нормализација. Скоро сите апликации за процес на природен јазик (NLP) бараат текстови податоци во нормализирана форма за изградба на квалитетни модели специфични за задачите. Затоа е докажано дека лексикалната нормализација ја подобрува извршноста на бројните природни задачи за обработување јазици на социјалните медиуми. Оваа студија има за цел решавање на проблемот со лексикалната нормализација со формулирање на задачата на лексикалната нормализација како проблем со означувањето на секвенцијата. Овој документ предложува пристап за означување на секвенца за решавање на проблемот со лексикалната нормализација во комбинација со техниката на зборови. The goal is to use a single model to normalize text in various languages namely Croatian, Danish, Dutch, English, Indonesian-English, German, Italian, Serbian, Slovenian, Spanish, Turkish, and Turkish-German.  This is a shared task in '2021 The 7th Workshop on Noisy User-generated Text (W-NUT)' in which the participants are expected to create a system/model that performs lexical normalization, which is the translation of non-canonical texts into their canonical equivalents, comprising data from over 12 languages.  Предложениот единствен мултијазичен модел постигнува целокупен резултат на ЕРР од 43,75 за внатрешна проценка и целокупен резултат на резултатот на означениот приклучок (ЛАС) од 63,12 за надворешна проценка. Покрај тоа, предложениот метод постигнува највисок резултат за намалување на стапката на грешки (ЕРР) од 61,33 помеѓу учесниците во
заедничка задача. Оваа студија ги истакнува ефектите од користењето на дополнителни податоци за обука за да се добијат подобри резултати, како и користењето на предобучен јазички модел обучен на повеќе јазици наместо само на еден јазик.</abstract_mk>
      <abstract_ml>ഒരു സാധാരണ പദാവലിയെ സാധാരണ വായിക്കാനും വായിക്കാവുന്ന പദാവലിയിലേക്ക് മാറ്റുന്നതിനുള്ള ജോലി സ്വാഭാവിക ഭാഷ പ്രവര്‍ത്തനങ്ങള്‍ (NLP) പ്രയോഗങ്ങള്‍ക്ക് സാധാരണ രീതിയിലുള്ള പദാവലിയുടെ വിവരങ്ങള്‍ സ്വാഭാവികമാക്കുന്നതിന അതുകൊണ്ട്, സാമൂഹിക മാധ്യമങ്ങളില്‍ ഒരുപാട് സ്വാഭാവിക ഭാഷ പ്രവര്‍ത്തിക്കുന്ന ജോലികളുടെ പ്രഭാവം മുന്‍കൂട്ടു ലെക്സിക്സിക്കല്‍ നോര്‍മാലിഷഷന്‍ ജോലി രൂപപ്പെടുത്തുന്നതിനാല്‍ ലെക്സിക്സിക്കല്‍ നോര്‍മാലിഷന്‍ പ്രശ്നം പരിഹരിക്കാന ഈ പത്രത്തില്‍ ലെക്സിക്സിക്കല്‍ നോര്‍മാലിസഷന്റെ പ്രശ്നം പരിഹരിക്കാന്‍ ഒരു സെക്കന്‍സ് ലേബിള്‍ ചെയ്യുന്ന വഴിയാണ് പ്രായ ലക്ഷ്യത്തിന്റെ ലക്ഷ്യം ക്രോവേഷ്യന്‍, ഡാനിഷ്, ഡച്ച്, ഇംഗ്ലീഷ്, ഇന്തോനേഷ്യന്‍ ഇംഗ്ലീഷ്, ജര്‍മ്മന്‍, ഇറ്റാലിയന്‍, സെര്‍ബിയന്‍, സ്ലോവേനിയന്‍, സ്പാനിഷ്, തുര്‍ക്കിഷ്, ജ '2021-ല്‍ പങ്കാളിയായ ഉപയോക്താവ് സൃഷ്ടിക്കുന്ന പദാവലിയുടെ (W-NUT) - ന്യൂട്ടിയുണ്ടാക്കുന്ന ഏഴാം വാര്‍ക്കെര്‍ക്കേഷനാണിതു് പങ്കാളികള്‍ ലെക്സിക്സിക്കല്‍ സാധാരണമാക്കുന്ന ഒരു സ The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation.  പിന്നീട്, പ്രൊദ്ദേശിച്ച രീതിയില്‍ പങ്കാളികളുടെ കൂട്ടത്തില്‍ 61. 33 സ്കോര്‍ ഏറ്റവും മികച്ച പിശക് കുറവ് വരുത്തുക
പങ്കുള്ള ജോലി. കൂടുതല്‍ പരിശീലന വിവരങ്ങള്‍ ഉപയോഗിക്കുന്നതിനുള്ള പ്രഭാവങ്ങള്‍ കൂടുതല്‍ ഉത്തമമായ ഫലങ്ങള്‍ ലഭ്യമാക്കുന്നതിനും ഒരു ഭാഷയില്‍ മാത്രം പരി</abstract_ml>
      <abstract_mt>The task of converting a nonstandard text to a standard and readable text is known as lexical normalization.  Kważi l-applikazzjonijiet kollha għall-ipproċessar tal-lingwi naturali (NLP) jeħtieġu d-dejta tat-test f’forma normalizzata biex jinbnew mudelli speċifiċi għall-kompiti ta’ kwalità. Għalhekk, intwera li n-normalizzazzjoni lexikali ttejjeb il-prestazzjoni ta’ bosta kompiti naturali ta’ pproċessar tal-lingwi fil-midja soċjali. Dan l-istudju għandu l-għan li jsolvi l-problem a tan-Normalizzazzjoni Lessika billi jifformula l-kompitu tan-Normalizzazzjoni Lessika bħala problema tat-Tikkettar tas-Sekwenza. Dan id-dokument jipproponi approċċ ta’ tikkettar tas-sekwenza biex tiġi solvuta l-problem a tan-Normalizzazzjoni Lessika flimkien mat-teknika tal-allinjament tal-kliem. L-għan huwa li jintuża mudell wieħed biex it-test jiġi normalizzat f’diversi lingwi, jiġifieri l-Kroat, id-Daniż, l-Olandiż, l-Ingliż, l-Indoneżjan-Ingliż, il-Ġermaniż, it-Taljan, is-Serb, is-Sloven, l-Ispanjol, it-Turkiż u t-Turkiż-Ġermaniż. Dan huwa kompitu kondiviż fl-'2021 Is-Seba' Workshop dwar it-Test Ġenerat mill-Utenti bi Storbju (W-NUT)' li fih il-parteċipanti huma mistennija joħolqu sistema/mudell li jwettaq normalizzazzjoni lexikali, li hija t-traduzzjoni ta' testi mhux kanoniċi fl-ekwivalenti kanoniċi tagħhom, li jinkludu dejta minn aktar minn 12-il lingwa. The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation.  Barra minn hekk, il-metodu propost jilħaq l-ogħla punteġġ tar-Rata ta’ Tnaqqis ta’ Żbalji (ERR) ta’ 61.33 fost il-parteċipanti fil-
kompitu komuni. Dan l-istudju jenfasizza l-effetti tal-użu ta’ dejta addizzjonali ta’ taħriġ biex jinkisbu riżultati a ħjar kif ukoll l-użu ta’ mudell ta’ Lingwa mħarreġ minn qabel imħarreġ fuq diversi lingwi aktar milli fuq lingwa waħda biss.</abstract_mt>
      <abstract_pl>Zadanie konwersji tekstu niestandardowego na tekst standardowy i czytelny jest znane jako normalizacja leksykalna. Prawie wszystkie aplikacje przetwarzania języka naturalnego (NLP) wymagają danych tekstowych w znormalizowanej formie do tworzenia jakościowych modeli specyficznych dla zadań. Stąd udowodniono, że normalizacja leksykalna poprawia wykonywanie licznych zadań przetwarzania języka naturalnego w mediach społecznościowych. Celem niniejszego opracowania jest rozwiązanie problemu normalizacji leksykalnej poprzez sformułowanie zadania normalizacji leksykalnej jako problemu etykietowania sekwencji. W artykule zaproponowano podejście do etykietowania sekwencji w celu rozwiązania problemu Lexical Normalization w połączeniu z techniką wyrównywania słów. Celem jest wykorzystanie jednego modelu do normalizacji tekstu w różnych językach: chorwackim, duńskim, holenderskim, angielskim, indonezyjskim-angielskim, niemieckim, włoskim, serbskim, słoweńskim, hiszpańskim, tureckim i turecko-niemieckim. Jest to wspólne zadanie w ramach "2021 Siódmego Warsztatu na temat szumu tekstu generowanego przez użytkownika" (W-NUT)", w ramach którego uczestnicy mają stworzyć system/model wykonujący normalizację leksykalną, czyli tłumaczenie tekstów niekanonicznych na ich odpowiedniki kanoniczne, zawierające dane z ponad 12-języków. Proponowany model wielojęzyczny osiąga ogólny wynik ERR 43,75 w ocenie wewnętrznej oraz ogólny wynik Labeled Attachment Score (LAS) 63,12 w ocenie zewnętrznej. Ponadto proponowana metoda osiąga najwyższy współczynnik redukcji błędów (ERR) wynoszący 61.33 wśród uczestników konkursu.
wspólne zadanie. W niniejszym badaniu podkreślono efekty wykorzystania dodatkowych danych szkoleniowych w celu uzyskania lepszych wyników, jak również zastosowania wstępnie przeszkolonego modelu języka przeszkolonego na wielu językach, a nie tylko na jednym języku.</abstract_pl>
      <abstract_no>Oppgåva til å konvertera eit ikkje standard tekst til ein standard og lesbar tekst er kjent som leksisk normalisering. Nærmest alle program for naturspråk- prosessering (NLP) krev tekstdata i normalisert form for å bygge kvalitetsverdiske modeller. Dette er derfor vist å forbetra utviklinga av mange naturspråk-handsamar på sosiale media. Denne studien må løysa problemet med leksiske normalisering ved å formera oppgåva med leksiske normalisering som eit problem med merkelappen. Denne papiret foreslår ein rekkjemerkelapp for å løysa problem med leksisk normalisering i kombinasjon med ordjusteringsteknikken. Målet er å bruka ein enkel modell for å normalisera tekst på ulike språk, som tyrkisk, dansk, nederlandsk, engelsk, indonesisk, tysk, italsk, serbisk, slovensk, spansk, tursk og tyrkisk. Dette er ei delt oppgåve i 2021 Det 7. arbeidsområdet på noisy User-generated Text (W-NUT)-en der deltakarane ventar å laga eit system/model som utfører leksisk normalisering, som er omsetjinga av ikkje-kanoniske tekstar i sin kanoniske ekvivalent, som inneheld data frå over 12 språk. Den foreslåde enkelte fleirspråksmodellen oppnår eit generell ERR- poeng med 43,75 på inntrådlag evaluering og eit generell merket vedleggskort (LAS) med 63,12 på ekstrinsske evaluering. Dette første metoden gjer det høgste feilreduksjonsrate (ERR) i 61,33 mellom deltakarane i
delt oppgåve. Denne studien markerer effekten av å bruka fleire opplæringsdata for å få bedre resultat, og bruka eit først opplært språk- modell trent på fleire språk i staden for berre på eitt språk.</abstract_no>
      <abstract_ro>Sarcina de a converti un text nestandard într-un text standard și lizibil este cunoscută sub numele de normalizare lexicală. Aproape toate aplicațiile Natural Language Processing (NLP) necesită datele text în formă normalizată pentru a construi modele de calitate specifice sarcinilor. Prin urmare, normalizarea lexicală s-a dovedit a îmbunătăți performanța numeroaselor sarcini de procesare a limbajului natural pe rețelele de socializare. Acest studiu își propune să rezolve problema normalizării lexice prin formularea sarcinii de normalizare lexică ca problemă de etichetare a secvențelor. Această lucrare propune o abordare de etichetare a secvențelor pentru a rezolva problema Normalizării Lexicale în combinație cu tehnica de aliniere a cuvintelor. Scopul este de a utiliza un singur model pentru a normaliza textul în diferite limbi și anume croată, daneză, olandeză, engleză, indoneziană-engleză, germană, italiană, sârbă, slovenă, spaniolă, turcă și turcă-germană. Aceasta este o sarcină comună în "2021 Cel de-al 7-lea Atelier privind Textul generat de utilizatori zgomotoși (W-NUT)" în care participanții sunt așteptați să creeze un sistem / model care efectuează normalizarea lexicală, care este traducerea textelor non-canonice în echivalentele lor canonice, cuprinzând date din peste 12 limbi. Modelul multilingv unic propus obține un scor ERR global de 43,75 la evaluarea intrinsecă și un scor global de atașament etichetat (LAS) de 63,12 la evaluarea extrinică. Mai mult, metoda propusă obține cel mai mare scor de reducere a erorilor (ERR) de 61,33 în rândul participanților la
sarcină comună. Acest studiu evidențiază efectele utilizării datelor suplimentare de formare pentru a obține rezultate mai bune, precum și utilizării unui model lingvistic pre-instruit instruit pe mai multe limbi, mai degrabă decât pe o singură limbă.</abstract_ro>
      <abstract_mn>Стандарт биш текстийг стандарт болон унших боломжтой текст руу шилжүүлэх үйлдэл нь лексикийн нормализал гэж нэрлэгддэг. Бараг бүх Байгалийн хэл Процессор (NLP) програмуудын хувьд хэвийн даалгаварын тодорхойлолтой загваруудыг бүтээхэд текст өгөгдлийг энгийн хэлбэрээр шаарддаг. Иймээс сэтгэл хөдлөл нь нийгмийн мэдээлэл дээр олон байгалийн хэл үйлдвэрлэлийн үйл ажиллагааг сайжруулахад баталсан. Энэ судалгаанд лексикийн нормализацийн асуудлыг лексикийн нормализацийн даалгаврыг даалгавраас шийдэх зорилготой. Энэ цаас лексикийн нормализацийн асуудлыг нэгтгэхэд хэлбэртэй холбогдохын тулд дарааллын тэмдэглэгдэх аргыг сануулдаг. Цаг нь Хорват, Дан, Дач, Англи, Индонез-Англи, Герман, Итали, Серб, Словени, Испан, Турк, Турк-Герман хэл дээр нэг загвар хэрэглэх юм. Энэ бол 2021 онд хуваалцагчдын 7-р ажиллах үйл ажиллагаа. Үүнд оролцогчдын оролцогчдын хуваалцагч нар лексикийн нормализацийг хийдэг систем/загвар бий болгох гэж найдаж байна. Энэ нь хуваалцагчдын 7-р ажиллах үйл ажиллагаа. Энэ нь хуваалцагчдын хуваалцагч нарын ху Олон хэл загварын нэг загвар нь дотоод дүгнэлт дээр 43.75 ERR оноо, нийтлэг Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэгдсэн Нэг Дараа нь, санал өгсөн арга нь хамгийн өндөр алдааны багасгах хувьд (ERR) 61.33 хүн оролцогчдын дунд
хуваалцах ажил. Энэ судалгаанд нэмэлт сургалтын өгөгдлийг ашиглан илүү сайн үр дүнг гаргах боломжтой. Мөн урьд сургалтын хэл загварыг зөвхөн нэг хэл дээр сургалтын хэл загвар ашиглах боломжтой нөл</abstract_mn>
      <abstract_sv>Uppgiften att konvertera en icke-standardiserad text till en vanlig och läsbar text kallas lexikal normalisering. Nästan alla Natural Language Processing (NLP) applikationer kräver textdata i normaliserad form för att bygga kvalitetsuppgiftsspecifika modeller. Därför har lexikal normalisering visat sig förbättra utförandet av många naturliga språkbehandlingsuppgifter på sociala medier. Denna studie syftar till att lösa problemet med Lexical Normalization genom att formulera Lexical Normalization uppgiften som ett Sequence Labeling problem. Denna uppsats föreslår en sekvensmärkningsmetod för att lösa problemet med Lexical Normalization i kombination med ordjusteringstekniken. Målet är att använda en enda modell för att normalisera texten på olika språk, nämligen kroatiska, danska, nederländska, engelska, indonesisk-engelska, tyska, italienska, serbiska, slovenska, spanska, turkiska och turkisk-tyska. Detta är en delad uppgift i '2021 The 7e Workshop on Noisy User-Generated Text (W-NUT)' där deltagarna förväntas skapa ett system/modell som utför lexikal normalisering, vilket är översättning av icke-kanoniska texter till sina kanoniska motsvarigheter, bestående av data från över 12 språk. Den föreslagna flerspråkiga modellen uppnår en total ERR-poäng på 43,75 vid intern utvärdering och en övergripande Labeled Attachment Score (LAS) poäng på 63,12 vid extern utvärdering. Vidare uppnår den föreslagna metoden den högsta Error Reduction Rate (ERR) poängen på 61,33 bland deltagarna i studien.
delad uppgift. Denna studie belyser effekterna av att använda ytterligare utbildningsdata för att få bättre resultat samt att använda en färdigutbildad språkmodell som är utbildad på flera språk snarare än bara på ett språk.</abstract_sv>
      <abstract_sr>Zadatak preobraćanja nenormalnog teksta na standardni i čitljivi tekst je poznat kao leksička normalizacija. Skoro svi aplikacije prirodnog procesa jezika (NLP) zahtevaju tekst podataka u normaliziranom obliku da izgradi kvalitetne modele specifičnih zadataka. Stoga je leksička normalizacija dokazana kako bi poboljšala provedbu brojnih prirodnih zadataka za obrađivanje jezika na društvenim medijima. Ova studija je cilj rešiti problem leksičke normalizacije formirajući zadatak leksičke normalizacije kao problem označavanja sekvence. Ovaj papir predlaže pristup označavanja sekvence kako bi rešio problem leksičke normalizacije u kombinaciji sa tehnikom poravnanja reči. Цел је да се користи један модел за нормализацију текста на различним езикама, а имени хрватских, данских, нидерских, английских, индонезијских, немацких, италианских, србијских, словенских, испанских, турских и турских-немацки Ovo je zajednički zadatak 2021. Sedmi radionici o tekstu proizvedenom korisniku Noisy (W-NUT)' u kojem se očekuje da će učesnici stvoriti sistem/model koji izvodi leksičku normalizaciju, što je prevod nekanoničkih tekstova u njihove kanoničke ekvivalente, uključujući podatke sa preko 12 jezika. Predloženi jedinstveni multijezički model postiže ukupni rezultat ERR od 43,75 na unutrašnjoj procjeni i ukupni rezultat označenog rezultata ataka (LAS) od 63,12 na izvanzemalnoj procjeni. Nadalje, predložena metoda postiže najveći rezultat smanjenja greška (ERR) od 61,33 među sudionicima u
zajednièki zadatak. Ova studija ukazuje na učinak korištenja dodatnih podataka o obuci kako bi dobili bolji rezultat, kao i koristiti predobučeni jezički model obučen na više jezika umjesto samo na jednom jeziku.</abstract_sr>
      <abstract_ur>ایک غیر استاندارڈ متن کو استاندارڈ اور پڑھنے کے قابل متن کی تبدیل کرنے کی کوشش لکسیکل عاملی کے طور پر پڑھی جاتی ہے. تقریبا سارے طبیعی زبان پرسس (NLP) کاربریوں کے لئے سارے سارے سارے ٹکسٹ ڈیٹ کی ضرورت ہے عام فرم میں کیفیت ٹاکس-خاص موڈل بنانے کے لئے۔ اسی وجہ سے لکسیکل عامل کرنا ثابت ہوا ہے کہ سوسیل میڈیا میں بہت سی طبیعی زبان پردازی کے کاموں کی عمدت کو بہتر کرے۔ اس تحقیق کا ارادہ ہے کہ Lexical Normalization کا مسئلہ حل کرنا چاہے لکسیکل Normalization کا مسئلہ ایک سکونس لابلینگ مسئلہ کے طور پر فرمول کریں. This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique. مقصد یہ ہے کہ مختلف زبانوں میں ایک موڈل استعمال کروٹی, ڈانشی, ڈنچ, انگلیسی, انڈونزی-انگلیسی, جرمانی, ایتالیایی, سربین, سلوووین, اسپانیایی, ترکیش اور ترکیش-جرمن کے ساتھ متعلق کریں۔ یہ ایک مشترک کام ہے '2021' میں نویسی یوسٹر کے پیدا کئے ہوئے متن (W-NUT) کے ساتھ ساتھا کارشاپ ہے جہاں شرکت کرنے والوں کو ایک سیستم/موڈل بنانے کی انتظار کی جاتی ہے جو لکسیکل عامل کرتا ہے، جو ان کے کانونیک برابریٹوں میں غیر کانونیک متن کی ترجمہ ہے، جو 12 زبانوں سے زیادہ سے ڈاٹے ہیں. پیغمبر کی ایک متعدد زبان موڈل 43.75 کی عمومی ERR score حاصل کرتا ہے اور ایک عمومی لابلی اٹیٹمنٹ Score (LAS) score of 63.12 on external evaluation. اس کے بعد، پیشنهاد کی طریقہ حد سے زیادہ خطا کے ذریعہ (ERR) سے 61.33 پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پورے پائیں گے
مشترک کام۔ یہ مطالعہ اضافہ ترینس ڈیٹا کے استعمال کرنے کے لئے اچھے نتیجے حاصل کرنے کے لئے اضافہ کرتا ہے اور ایک زبان کے بغیر ایک زبان پر آموزش کی پیش آموزش کی زبان مدل کی استعمال کرتا ہے۔</abstract_ur>
      <abstract_so>Shaqada ku beddelashada qoraal aan caadi ahayn oo loogu beddelo qoraal caadi ah oo la akhriyo waxaa loo yaqaan sida caadiga leksikal ah. Inta badan dhammaan codsiga shaqeynta afka asalka ah (NLP) waxay u baahan yihiin macluumaadka qoraalka si ay u dhisto qaab cayiman oo u gaar ah samooyinka shaqada. Sidaa darteed waxaa loo xaqiijiyey in la hagaajiyo sameynta hawlaha baaraandegista afka kala duduwan ee bulshada. Waxbarashadan waxaa loola jeedaa in ay ku xalaato dhibaatada Normalization Leksikal ku saabsan formulatidda shaqada Normalization Lexical as a Sequence Labeling dhibaato. This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique.  Ujeedadu waa in lagu isticmaalaa tusaale keliya oo lagu caadi karo luuqado kala duduwan oo ah Croatian, Danish, Dutch, Ingiriis, Indonesian-Ingiriis, Jarmal, Talyaani, Serbiyaan, Slovenian, Isbanish, Turki iyo Turki. Kanu waa shaqo la qaybsan yahay '2021 The 7th Workshop on Noisy User-Generated Text (W-NUT)' where participants are expected to create a system/model that performs lexical normalization, which is the translation of texts non-canonical in their canonical equivalents, comprising data from over 12 luqadood. Tusaale hal luuqad ah oo la soo jeedo wuxuu gaadhaa qiimeynta gudaha ah 43.75 oo isku qiimeeya ERR oo ku qoran qiimeynta gudaha gudaha ah iyo qiyaastii labka oo dhan (LAS) oo qiimeynta dibadda ah 63.12. Furthermore, qaabkii la soo jeeday wuxuu gaadhaa qiimaha ugu sarreeya khaladda Reduction (ERR) score 61.33 oo ka mid ah kuwa ka qayb gala
shaqo qayb ah. Waxbarashadan waxaa ku qoran saamaynta isticmaalka macluumaadka waxbarashada dheeraad ah, si aad u heli karto matooyin ka wanaagsan iyo isticmaalka model af-horaadka lagu baray oo luuqado kala duduwan ah, taasoo aan ku jirin hal luuqad oo kaliya.</abstract_so>
      <abstract_si>ප්‍රමාණයක් නැති පාළුවක් ප්‍රමාණය සහ කියවන්න පුළුවන් පාළුවක් වෙනුවෙන් ලෙක්සිකාලික සාමාන සාමාන්‍ය විශේෂ භාෂාව පරීක්ෂණය (NLP) යෝග්‍යාලයට පාළුවන් දත්ත සාමාන්‍ය විශේෂ විශේෂ විශේෂ ඉතින්, ලෙක්සිකාලික සාමාන්‍ය විස්තර කරලා සාමාජික මිඩියාවේ සාමාන්‍ය භාෂාව ප්‍රකාර කරපු වැඩේ සාම මේ පරීක්ෂණය ලබේලින් ප්‍රශ්නයක් වගේ ලෙක්සිකාල් සාමාන්තිකරණයේ ප්‍රශ්නයක් විසඳන්න ලෙක්සිකාල් සාමාන්තිකර මේ පැත්තේ ලෙක්සිකාල් සාමාන්‍ය විශ්වාසයේ ප්‍රශ්නයක් විසඳන්න ප්‍රශ්නයක් ලෙක්සිකාල් ලේබිල් විසඳන්න ප අරමුණය තමයි විවිධ භාෂාවට පාළුවක් සාමාන්‍ය විදියට පෙළුවක් භාවිත කරන්න, ක්‍රෝටියාන්, ඩැනිෂ්, ඩච්ච්, ඉංග්‍රීෂ්, ඉංඩ This is a shared job in '2021 The 7th WorkHop on Noisey user-generic text (W-NuT)' in where the partipartints are antialiased to make a system/Model that Perfects lexic Normization, that is the translation of non-Canonical texts in the Canonical Equivalents, comprises data from over 12 language. ප්‍රයෝජනය විශ්වාස කරන එකම භාෂාභාෂික මොඩේල් එක්ක 43.75 ගැන සම්පූර්ණ ERR ස්කෝර් විශ්වාස කරන්න පුළුවන් සහ සාමාන්‍ය විශ්වාස කරනවා ස තවත්, ප්‍රශ්න විධානය ප්‍රශ්න විධානය ප්‍රශ්න විශ්වාස කරනවා අංක 61.33 අංක 61.33 අංක අංක අංක
වෙනුවෙන් වැඩක්. මේ පරීක්ෂණය ප්‍රභාවිත කරනවා තවත් ප්‍රභාවිත දත්ත භාවිතා කරන්න හොඳ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ර</abstract_si>
      <abstract_ta>இயல்பான உரையை நிலையான மற்றும் படிக்கக்கூடிய உரையாக மாற்றும் செயல் லெக்சியல் இயல்பான ஆகும். இயல்பான மொழி செயல்பாடு (NLP) பயன்பாடுகள் தரம் பணி குறிப்பிட்ட மாதிரிகளை உருவாக்குவதற்கு இயல்பான வடிவத்தில் உள்ள உரை தரவு தேவ அதனால், சாதாரண மொழி செயல்பாடுகளின் செயல்பாட்டை மேம்படுத்த தெளிவாக்கப்பட்டுள்ளது. இந்த ஆராய்ச்சி லெக்சிக்சியல் இயல்பாக்கத்தின் பிரச்சினையை தீர்வு செய்யும் பொருள் தீர்வு செய்யும் பொருள் லெக்ச இந்த தாள் சொல்ல- ஒழுங்குபடுத்தும் தொழில்நுட்பத்துடன் தீர்வு செய்ய ஒரு தொடர் சிட்டைக்குறியீட்டு வழியை தீர்வு செ இலக்கு ஒரே மாதிரி பயன்படுத்துவதற்காக க்ரோவியன், டானிஷ், டாநிச், ஆங்கிலம், இந்தோனேசிய- ஆங்கிலம், ஜெர்மன், இத்தாலியன், செர்பியன், ஸ்லோவீனியன், ஸ்பானிஷ், துருக்கி, மற் '2021' ல் பங்கிடப்பட்ட பணியாகும் நோய் பயனர் உரையாக்கப்பட்ட உரையில் 7வது வேலைசெயலாகும். இதில் பங்கீட்டாளர்கள் ஒரு முறைமை/மாதிரியை உருவாக்குவதற்கு எதிர்பார்க்கப்படுகிறார்கள். இது கானோனிக்  பரிந்துரைக்கப்பட்ட ஒற்றை பல மொழி மாதிரி மொத்த ERR மதிப்பெண் 43. 75 பெறுகிறது உள்ளீட்டு evaluation மற்றும் மொத்த விளக்கச்சீட்டு புள்ளி மேலும், பரிந்துரைக்கப்பட்ட முறைமையாக, அதிக பிழை குறைவு (ERR) மதிப்பு 61. 33 க்கு அதிக மதிப்பெண்ணை பெறுகிறது
பகிர்ந்த பணி இந்த படிப்பாடு கூடுதல் பயிற்சி தரவை பயன்படுத்தி சிறந்த முடிவுகளை பெறுவதற்கும் மற்றும் ஒரு மொழியில் மட்டும் ஒரு முன் பயிற்சிக்கப்</abstract_ta>
      <abstract_uz>bo Ľlishilgan vazifa. Bu ta'lim qo Ľshimcha ta ľminlovchi ma ľlumot yordamida yaxshi natijalarni olish uchun va faqat bitta tillar bilan bir necha tillar yordamida o'rgangan tillar modelini ishlatish uchun foydalanishini ko Ľrsatish.</abstract_uz>
      <abstract_vi>Nhiệm vụ chung. Nghiên cứu này nhấn mạnh hiệu quả của việc sử dụng dữ liệu đào tạo thêm để có kết quả tốt hơn, cũng như sử dụng một mô hình ngôn ngữ được đào tạo trước trên nhiều ngôn ngữ hơn là chỉ trên một ngôn ngữ.</abstract_vi>
      <abstract_bg>споделена задача. Това проучване подчертава ефектите от използването на допълнителни данни за обучение за постигане на по-добри резултати, както и използването на предварително обучен езиков модел, обучен на няколко езика, а не само на един език.</abstract_bg>
      <abstract_da>delt opgave. Denne undersøgelse fremhæver virkningerne af at bruge yderligere træningsdata for at opnå bedre resultater samt bruge en forududdannet sprogmodel, der er trænet på flere sprog frem for kun på ét sprog.</abstract_da>
      <abstract_hr>zajednički zadatak. U ovom ispitivanju ukazuje na učinak korištenja dodatnih podataka o obuci kako bi dobili bolji rezultat, kao i koristiti predobučeni jezički model obučen na više jezika umjesto samo na jednom jeziku.</abstract_hr>
      <abstract_de>gemeinsame Aufgabe. Diese Studie beleuchtet die Auswirkungen der Verwendung zusätzlicher Trainingsdaten zur Erzielung besserer Ergebnisse sowie der Verwendung eines vortrainierten Sprachmodells, das auf mehreren Sprachen statt nur auf einer Sprache trainiert wird.</abstract_de>
      <abstract_id>tugas berbagi. Studi ini memperlihatkan efek dari menggunakan data pelatihan tambahan untuk mendapatkan hasil yang lebih baik serta menggunakan model bahasa yang dilatih sebelumnya dilatih dalam berbagai bahasa daripada hanya dalam satu bahasa.</abstract_id>
      <abstract_ko>작업을 공유합니다.이 연구는 한 언어만 훈련하는 것이 아니라 다양한 언어를 훈련하는 데 더 좋은 결과를 얻기 위해 추가 훈련 데이터를 사용하고 미리 훈련된 언어 모델을 사용하는 것을 강조했다.</abstract_ko>
      <abstract_sw>kazi inayoshirikiana. Utafiti huu unaonyesha madhara ya kutumia taarifa za mafunzo zaidi ili kupata matokeo bora na pia kwa kutumia mtindo wa lugha ulioendeshwa kabla kwa ujuzi wa lugha mbalimbali zaidi ya lugha moja tu.</abstract_sw>
      <abstract_nl>gedeelde taak. Deze studie belicht de effecten van het gebruik van aanvullende trainingsgegevens om betere resultaten te behalen, evenals het gebruik van een vooraf getraind Taalmodel dat is getraind op meerdere talen in plaats van slechts één taal.</abstract_nl>
      <abstract_am>አድራሻ This study highlights the effects of using additional training data to get better results as well as using a pre-trained Language model trained on multiple languages rather than only on one language.</abstract_am>
      <abstract_fa>کار مشترک. این مطالعه اثرات استفاده از داده های آموزش اضافه را برای گرفتن نتایج بهتر و استفاده از یک مدل پیش آموزش زبان آموزش یافته بر زبانهای متعدد به جای تنها یک زبان نشان می دهد.</abstract_fa>
      <abstract_hy>ընդհանուր խնդիր: Այս ուսումնասիրությունը ցույց է տալիս, թե ինչպես են օգտագործվում ավելացյալ ուսումնասիրության տվյալները ավելի լավ արդյունքներ ստանալու համար, ինչպես նաև նախապատրաստված լեզվի մոդելը, որը ուսումնասիրում է բազմաթիվ լեզուներով, և ոչ միայն մեկ</abstract_hy>
      <abstract_tr>paylaýyn täblisa. Bu çalışma diňe bir dilde öňünden öňünden eğitilen diller üçin gollaşdyrmak üçin gollaşdyran gollanma maglumatynyň etkisini ýagtylaýar.</abstract_tr>
      <abstract_az>paylaşılır. Bu təhsil ancaq bir dildən əvvəl təhsil edilmiş dil modelini istifadə etmək üçün çoxlu təhsil məlumatlarını istifadə etmək üçün təsirlərini işıqlandırır.</abstract_az>
      <abstract_af>gedeelde taak. Hierdie studie verlig die effekte van die gebruik van addisionele onderwerp data om beter resultate te kry as ook die gebruik van 'n voorwerp onderwerp taal model onderwerp op veelvuldige tale as net op een taal.</abstract_af>
      <abstract_sq>detyrë të përbashkët. Ky studim thekson efektet e përdorimit të të dhënave shtesë të trajnimit për të marrë rezultate më të mira si dhe përdorimin e një modeli gjuhësh të trajnuar para-trajnuar të trajnuar në gjuhë të shumta sesa vetëm në një gjuhë.</abstract_sq>
      <abstract_ca>tasca compartida. Aquest estudi destaca els efectes d'utilitzar dades adicionals de formació per aconseguir millors resultats i utilitzar un model de llenguatge pré-format format en múltiples llengües en comptes d'un llenguatge.</abstract_ca>
      <abstract_cs>sdílený úkol. Tato studie zdůrazňuje dopady použití dalších údajů o tréninku k dosažení lepších výsledků, stejně jako použití předškoleného jazykového modelu trénovaného na více jazycích, než jen na jednom jazyce.</abstract_cs>
      <abstract_et>ühine ülesanne. Selles uuringus rõhutatakse täiendavate koolitusandmete kasutamise mõju paremate tulemuste saavutamiseks ning eelõpetatud keelemudeli kasutamise mõju, mida koolitatakse mitmes keeles, mitte ainult ühes keeles.</abstract_et>
      <abstract_fi>yhteinen teht채v채. T채ss채 tutkimuksessa korostuu vaikutuksia, joita saadaan k채ytt채m채ll채 lis채koulutusdataa parempien tulosten saavuttamiseksi sek채 k채ytt채m채ll채 esikoulutettua kielimallia, joka on koulutettu useilla kielill채 eik채 vain yhdell채 kielell채.</abstract_fi>
      <abstract_bn>শেয়ার করা কাজ। এই গবেষণা শুধুমাত্র একটি ভাষায় শিক্ষিত ভাষায় প্রশিক্ষিত ভাষা মডেল ব্যবহার করার জন্য আরো ভালো প্রশিক্ষণের প্রভাব ব্যবহার করা হয়েছে।</abstract_bn>
      <abstract_bs>zajednički zadatak. Ova studija ukazuje na učinak korištenja dodatnih podataka o obuci kako bi dobili bolji rezultat, kao i koristiti predobučeni jezički model obučen na više jezika umjesto samo na jednom jeziku.</abstract_bs>
      <abstract_sk>Naloga pretvorbe nestandardnega besedila v standardno in berljivo besedilo je znana kot leksikalna normalizacija. Skoraj vse aplikacije za obdelavo naravnega jezika (NLP) zahtevajo besedilne podatke v normalizirani obliki za gradnjo kakovostnih modelov, specifičnih za opravila. Zato je bilo dokazano, da leksikalna normalizacija izboljšuje izvedbo številnih nalog obdelave naravnega jezika na družbenih omrežjih. Namen te študije je rešiti problem leksične normalizacije s formuliranjem naloge leksične normalizacije kot problem zaporednega označevanja. V prispevku je predlagan pristop označevanja zaporedja za reševanje problema leksične normalizacije v kombinaciji s tehniko poravnave besed. Cilj je uporabiti en sam model za normalizacijo besedila v različnih jezikih, in sicer hrvaškem, danskem, nizozemskem, angleškem, indonezijsko-angleškem, nemškem, italijanskem, srbskem, slovenskem, španskem, turškem in turško-nemškem. To je skupna naloga v '2021 7. delavnici o hrupnem besedilu, ki ga ustvarijo uporabniki (W-NUT)', v kateri se od udeležencev pričakuje, da ustvarijo sistem/model, ki izvaja leksikalno normalizacijo, tj. prevod nekonskih besedil v kanonske ekvivalente, ki vsebujejo podatke iz več kot 12 jezikov. Predlagani enojni večjezični model dosega skupno oceno ERR 43,75 pri notranji oceni in skupno oceno označenega pritrditve (LAS) 63,12 pri zunanji oceni. Poleg tega predlagana metoda dosega najvišjo oceno stopnje zmanjšanja napak (ERR) 61,33 med udeleženci v
skupna naloga. Ta študija poudarja učinke uporabe dodatnih podatkov o usposabljanju za doseganje boljših rezultatov in uporabe vnaprej usposobljenega jezikovnega modela, usposobljenega za več jezikov in ne samo za en jezik.</abstract_sk>
      <abstract_ha>An sani aikin ka mayar da wani matsayi na daidaita zuwa wani matsayi na daidaita da ake karanta, ana gane shi kamar normal mai leksiya. Almost all the Natural Language Processing (NLP) applications require the text data in normalized form to build quality task-specific models.  Daga wannan, an jarraba kabarinta na leksikali dõmin ya kyautata aikin masu aikin aiki na masu aikin lugha da bakwai a kan mitandai jamii. This research aims to solve the problemin Leksikal malization by forming the Leksical normal job as a Sequence Labeling problemo. Wannan karatun na buƙata wata matsayi mai fassara matsayin a matsayin yin soli ga mataimaki na Leksika cikin koma da gefen-juyi. Gagon ya yi amfani da wani misali da ya zama mai normal a cikin harshen daban-daban, KCharselect unicode block name Wannan wani aikin da aka raba shi a cikin '2021 Kida aka goyyade ɗabi'a mulki-lingui, yana sãmu wani luman ERR na cikakken muhalli na 43.75an kan evaluci guda da kimar aikin Attachment na cikin Label (LauS) score na 63.12 kan evaluci na ƙarshen. Furtheran, shirin da aka buƙata, za'a gaskata mafi girmar Kwamfyuta Kwamfyuta (ERR) score na 61.33 among mãsu shirin cikin the
shared task.  Wannan lõkaci na ƙayyade aikin yin amfani da data masu ƙaranci ga su sami matsala mafi alhẽri da kuma a yi amfani da wani misalin harshe wanda aka sanar da shi a cikin wasu harshe ko kuma ba su yi musamman kawai ba kan harshe guda kawai.</abstract_ha>
      <abstract_jv>task Open with: Kaya, ngerti luwih (Leksik) sakjane iso nggawe akeh pengguna adalah sing nganggep barang nggawe barang pengguna adalah sing nggawe media sotiki. Wurung iki lak aréwé urip ngbote kanggo ngerasahan seneng perbudhakan Leksik Normalisaan seneng nggawe nggawe gerangkat saben usul sing apik Ketoken Gambar iki ulih nggawe sistem sing beraksi kanggo nambah gerakan kanggo luwih bantuan Leksika Normalisaan seneng pisan karo teknik-alignment. Kapan awak dhéwé iso nggunakake model sing tek kanggo nggawe oleh-alat kanggo kelas karo akeh basa ning basa sing dirampa bantuan karo Krotot, Danis, Danis, Pakan, Inggris, Danis, Inggris, Inggris, Isilan, Jejaran, Itilyan, Sarbisa, Esoletan, Kasipan, tur karo aleman. Iki sampeyan nggawe sistem/model sing sampeyan luwih '2020 Sampeyan mruput Laptop" and "Desktop Lahore
bookmarks Lewat iki dadi bongkin nggambar efek bak ngubah data sithik tambah bantuan ngono nggawe sistem dadi sing luwih apik lan gambar sistem model Language sing dipunatus oleh tur lenggal sing tur dipunatus dipunatus kanggo langa sampeyan.</abstract_jv>
      <abstract_he>המשימה להפוך טקסט לא סטנדרטי לטקסט סטנדרטי וקריא ידועה כנורמליזציה לקסיקה. כמעט כל היישומים בתהליך השפה הטבעית (NLP) דורשים את נתוני הטקסט בצורה נורמלית כדי לבנות דוגמנים ספציפיים לאיכות משימה. לכן, נורמליזציה לקסית הוכחה לשפר את ביצועים של מספר משימות עיבוד שפת טבעיות בתקשורת חברתית. המחקר הזה מכוון לפתור את הבעיה של נורמליזציה לקסית על ידי ליצור את המשימה של נורמליזציה לקסית כבעיה של תווית רצף. העבודה הזו מציעה גישה לטיוטים רצף כדי לפתור את הבעיה של נורמליזציה לקסיקנית בשילוב עם טכניקת התאמת מילים. המטרה היא להשתמש במודל אחד כדי לנורמליז טקסט בשפות שונות, כלומר כרוטי, דני, הולנדי, אנגלי, אינדונזי-אנגלי, גרמני, איטלקי, סרבי, סלובני, ספרדי, טורקי, וטורקי-גרמני. זו משימה משותפת בשנת 2021, העבודה השביעית על טקסט שנוצר ע"י משתמשים רעשים (W-NUT)' שבה השתתפים מצפים ליצור מערכת/מודל שמבצע נורמליזציה לקסיקה, זאת התרגום של טקסטים לא קנוניקים לתוך שווים קנוניקים שלהם, כולל נתונים מעל 12 שפות. The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation.  בנוסף, השיטה המוצעת משיגה את נקודת שיעור חיסוי שגיאות (ERR) הגבוהה ביותר של 61.33 בין השתתפים
משימה משותפת. המחקר הזה מזכיר את ההשפעות של השימוש בנתונים האימונים נוספים כדי להשיג תוצאות טובות יותר, כמו גם להשתמש במודל שפה מאומן מראש מאומן על שפות רבות במקום רק על שפה אחת.</abstract_he>
      <abstract_bo>བྱ་འགུལ་ནི་རྒྱུན་ལྡན་མིན་པའི་ཡིག་གེ་ལ་ཚད་སྔོན་འཛུགས་དང་ཀློག་རུང་བའི་ཡིག་གེ་ལ་བསྒྱུར་ནི་ཤོག་བྱས་ སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་ཡིག་ལས་སྦྱོར་བའི་ཉེར་སྤྱོད་ཀྱིས་རྒྱུན་ལྡན་གྱི་དབྱིབས་ཡིག་ཆ་གསལ་བཤད་དགོས། དེར་བརྟེན། lexical རྒྱུན་ལྡན་ཞིབ་བཟོ་བྱས་ན་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དུ་མཐུན་རྐྱེན་གྱི་སྐད་རིགས གལ་ཅན་འདི་ལྟ་བུའི་དོན་ལ་དམིགས་ཡུལ་ནི་གནད་དོན་མིན་རྒྱུན་ལྡན་གྱི་དཀའ་ངལ་བཅས་ཀྱི་མི་རྐྱེན་ཚུལ་ལས་རྗེས་སུ་ཤོག་ This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique. དམིགས་ཡུལ་ནི་ཡིག་ཆ་སོ་སོ་སྤྱད་ནས་མིང་རྣམས་གཅིག་བྱས་ནས་སྐད་རིགས་ཤིག་འདི་རྣམས་Croatian, Danish, Dutch, English, Indonesian-English, German, Italian, Serbian, Slovenian, Spanish, Turkish, and Turkish-German. This is a shared task in '2021 The 7th Workshop on Noisy User-generated Text (W-NUT)' in which the participants are expected to create a system/model that performs lexical normalization, which is the translation of non-canonical texts into their canonical equivalents, comprising data from over 12 languages. The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation. དེ་མིན་ན། དམིགས་འཛུགས་ཀྱི་ལམ་ལུགས་འདིས་ནོར་འཁྲུལ་རྒྱ་ཚད་མཐོ་ཤིང་ཚད་མཐོ་ཤོས་བྱུང་།
མཉམ་སྤྱོད་བྱ་འགུལ་ This study highlights the effects of using additional training data to get better results as well as using a pre-trained Language model trained on multiple languages instead of only on one language.</abstract_bo>
      </paper>
    <paper id="52">
      <title>Sesame Street to Mount Sinai : BERT-constrained character-level Moses models for multilingual lexical normalization<fixed-case>BERT</fixed-case>-constrained character-level <fixed-case>M</fixed-case>oses models for multilingual lexical normalization</title>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <pages>465–472</pages>
      <abstract>This paper describes the HEL-LJU submissions to the MultiLexNorm shared task on multilingual lexical normalization. Our system is based on a BERT token classification preprocessing step, where for each token the type of the necessary transformation is predicted (none, uppercase, lowercase, capitalize, modify), and a character-level SMT step where the text is translated from original to normalized given the BERT-predicted transformation constraints. For some languages, depending on the results on development data, the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training data</a> was extended by back-translating OpenSubtitles data. In the final ordering of the ten participating teams, the HEL-LJU team has taken the second place, scoring better than the previous <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>.</abstract>
      <url hash="255f5f11">2021.wnut-1.52</url>
      <bibkey>scherrer-ljubesic-2021-sesame</bibkey>
      <doi>10.18653/v1/2021.wnut-1.52</doi>
    <title_ar>شارع سمسم إلى جبل سيناء: نماذج موسى على مستوى الأحرف المقيدة من قبل بيرت للتطبيع المعجمي متعدد اللغات</title_ar>
      <title_pt>Vila Sésamo ao Monte Sinai: modelos de Moisés em nível de caractere com restrição de BERT para normalização lexical multilíngue</title_pt>
      <title_fr>De Sesame Street au mont Sinaï : modèles Moses au niveau du caractère contraint par Bert pour la normalisation lexicale multilingue</title_fr>
      <title_es>De Barrio Sésamo al Monte Sinaí: modelos de Moses a nivel de personaje con restricciones de Bert para la normalización léxica multilingüe</title_es>
      <title_ja>セサミストリートからマウントシナイ：多言語の語彙正規化のためのBERT制約付き文字レベルのMosesモデル</title_ja>
      <title_zh>芝麻街至西奈山:用多言词汇规范化者BERT约字符级摩西模</title_zh>
      <title_hi>तिल स्ट्रीट माउंट सिनाई के लिए: बहुभाषी लेक्सिकल सामान्यीकरण के लिए BERT-विवश चरित्र-स्तर मूसा मॉडल</title_hi>
      <title_ru>Sesame Street to Mount Sinai: BERT-ограниченные модели Мозеса на уровне символов для многоязычной лексической нормализации</title_ru>
      <title_ga>Sráid Sesame go Sliabh Shíonái: Múnlaí Moses srianta ar leibhéal carachtair le haghaidh normalú foclóireachta ilteangach</title_ga>
      <title_el>Οδός Σεσάμι μέχρι το όρος Σινά: μοντέλα Μωυσή με περιορισμούς σε επίπεδο χαρακτήρων για πολυγλωσσική λεξική ομαλοποίηση</title_el>
      <title_hu>Szezám utca a Sínai hegyig: BERT-korlátozott karakterszintű Mózes modellek a többnyelvű lexikális normalizáláshoz</title_hu>
      <title_it>Sesame Street al Monte Sinai: modelli Moses a livello di carattere vincolati dal BERT per la normalizzazione lessicale multilingue</title_it>
      <title_ka>Sesame Street to Mount Sinai: BERT-restricted character-level Moses models for multilingual lexical normalization</title_ka>
      <title_lt>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_lt>
      <title_kk>Sesame Street to Mount Sinai: BERT- constrained character- level Moses models for multilingual lexical normalization</title_kk>
      <title_mk>Улица Сезаме до планината Синаи: Мозејските модели за мултијазична лексикална нормализација обврзани со BERT</title_mk>
      <title_ms>Jalan Sesame ke Gunung Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_ms>
      <title_ml>സെയോ സ്ട്രീറ്റ് സിനായി പര്‍വ്വതത്തിലേക്ക്: ബെര്‍ട്ടി- നിര്‍ബന്ധിതമായ അക്ഷരരൂപത്തിന്റെ നില മോസാ മോഡലുകള്‍</title_ml>
      <title_mt>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_mt>
      <title_mn>Sesame Street to Mount Sinai: BERT-bounded character-level Moses models for multilingual lexical normalization</title_mn>
      <title_no>Sesame Street to Mount Sinai: BERT-restricted character-level Moses models for multilingual lexical normalization</title_no>
      <title_ro>Sesam Street până la Muntele Sinai: Modele Moses la nivel de caracter constrâns BERT pentru normalizarea lexicală multilingvă</title_ro>
      <title_pl>Ulica sezamowa do góry Synaj: modele Mosesa z ograniczeniami BERT dla wielojęzycznej normalizacji leksykalicznej</title_pl>
      <title_si>සේසාම් වීදි සිනායි මන්ට්ටුව: BERT</title_si>
      <title_sr>Ulica Sesame na Mount Sinai: modeli na nivou karaktera koji su ograničeni na BERT-u za multijezičku leksičku normalizaciju</title_sr>
      <title_so>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_so>
      <title_ur>سیسم استریٹ سینا کے منٹ پر: BERT-constrained character-level Moses models for multilingual lexical normalization</title_ur>
      <title_ta>செய்யோ தெரு சைனாய் மலையில் இருந்து: பெர்ட்- கட்டுப்படுத்தப்பட்ட எழுத்து நிலை மூஸா மாதிரிகள் பல மொழி லெக்சிக்ச</title_ta>
      <title_sv>Sesamgatan till berget Sinai: BERT-begränsade Mosemodeller för flerspråkig lexikal normalisering</title_sv>
      <title_uz>Sesame Street Sinai Buyrugʻiga: BERT'ning quyidagi harf darajasi Moses modellari, multilinglar leksikal normalization uchun</title_uz>
      <title_vi>Đường Sesame to núi Sinai: Các mô- hình ký tự của BERT cho chế độ biến ngôn ngữ</title_vi>
      <title_bg>Улица от сусам до планината Синай: Мойсей с ограничени символи модели за многоезично лексикално нормализиране</title_bg>
      <title_nl>Sesamstraat tot Mount Sinai: Moses-modellen op karakterniveau met BERT-beperkingen voor meertalige lexicale normalisatie</title_nl>
      <title_hr>Sesame ulica na planinu Sinaj: modeli na razini karaktera koji su ograničeni na BERT-u Mosesi za multijezičku leksičku normalizaciju</title_hr>
      <title_da>Sesamgaden til Sinai-bjerget: BERT-begrænsede Mosemodeller til flersproget leksikalsk normalisering</title_da>
      <title_de>Sesamstraße bis Mount Sinai: BERT-eingeschränkte Moses-Modelle auf Zeichenebene für mehrsprachige lexikalische Normalisierung</title_de>
      <title_id>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_id>
      <title_fa>خیابان ساسم به کوه سینای: مدل‌های نورمیزی زبان‌های زیادی موسی به سطح شخصیت محدود BERT</title_fa>
      <title_ko>참깨 거리에서 시나산까지: 다국어 어휘 규범화에 사용되는 버트 제약 문자급 모시 모형</title_ko>
      <title_tr>Sinai ň daýyna gollanan Soňky</title_tr>
      <title_af>Sesame Straat na Mount Sinai: BERT- beheinde karaktervlak Moses modele vir multilinglike leksiese normalisering</title_af>
      <title_sw>Mtaa wa Sesame kwenda Mlima Sinai: Mfano wa kiwango cha wahusika kilichotengenezwa na BERT kwa ajili ya utaratibu wa lexico wa lugha mbalimbali</title_sw>
      <title_hy>Սեսամի փողոցը Սինա լերան վրա. BER-սահմանափակ բնավորության մակարդակի Մովսէսի մոդելներ բազլեզու լեքսիկական նորմալիզացիայի համար</title_hy>
      <title_am>የሲና ተራራ መንገድ</title_am>
      <title_sq>Rruga Sesame në Malin Sinai: modele BERT-kufizuar në nivelin e karakterit Moses për normalizimin lexik shumëgjuhës</title_sq>
      <title_bn>সেই স্ট্রীট সিনাই পর্বতের সাথে: বেরেট-নির্ধারিত চরিত্র-স্তর মোসার মডেল মালিক ভাষায় লেক্সিক্সিকাল স্বা</title_bn>
      <title_az>Sesame Street to Mount Sinai: BERT-restricted character-level Moses models for multilingual lexical normalization</title_az>
      <title_ca>Sesame Street to Mount Sinai: Models BERT-constrained character-level Moses for multilingual lexical normalization</title_ca>
      <title_et>Seesami tänav Siinai mäele: BERT-piiranguga märgitasemel Moosese mudelid mitmekeelseks leksikaalseks normaliseerimiseks</title_et>
      <title_cs>Sezamová ulice až po horu Sinai: Mojžíšské modely s omezením BERT pro vícejazyčnou lexikální normalizaci</title_cs>
      <title_bs>Ulica Sesame na planinu Sinaj: modeli na nivou karaktera ograničeni na BERT-u Mosesi za multijezičku leksičku normalizaciju</title_bs>
      <title_fi>Seesam Street Siinain vuorelle: BERT-rajoitetut merkkitason Mooseksen mallit monikieliseen sanaston normalisointiin</title_fi>
      <title_ha>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_ha>
      <title_he>רחוב סססם להר סינאי: דוגמנים ברמה אופי משה מוגבלים ברמה BERT</title_he>
      <title_sk>Sezamova ulica do Sinaja: Mojzesovi modeli na ravni znakov z omejitvami BERT za večjezično leksikalno normalizacijo</title_sk>
      <title_jv>Sesame Port to mount sinai: BERT-limited character-type</title_jv>
      <title_bo>Sesame Street to Mount Sinai: BERT-constrained character-level Moses models for multilingual lexical normalization</title_bo>
      <abstract_ar>تصف هذه الورقة عمليات تقديم HEL-LJU إلى مهمة MultiLexNorm المشتركة حول التطبيع المعجمي متعدد اللغات. يعتمد نظامنا على خطوة المعالجة المسبقة لتصنيف رمز BERT ، حيث يتم توقع نوع التحويل اللازم لكل رمز مميز (لا شيء ، أحرف كبيرة ، صغيرة ، تكبير ، تعديل) ، وخطوة SMT على مستوى الحرف حيث يتم ترجمة النص من الأصل إلى التطبيع نظرًا لقيود التحويل التي تنبأت بها BERT. بالنسبة لبعض اللغات ، اعتمادًا على النتائج على بيانات التطوير ، تم تمديد بيانات التدريب عن طريق إعادة ترجمة بيانات OpenSubtitles. في الترتيب النهائي للفرق العشرة المشاركة ، احتل فريق HEL-LJU المركز الثاني ، وسجل أفضل من أحدث الفرق السابقة.</abstract_ar>
      <abstract_fr>Cet article décrit les soumissions HEL-LJU à la tâche partagée MultilexNorm sur la normalisation lexicale multilingue. Notre système est basé sur une étape de prétraitement de classification des jetons BERT, où pour chaque jeton le type de transformation nécessaire est prédit (aucune, majuscule, minuscule, majuscule, modification), et une étape SMT au niveau du caractère où le texte est traduit de l'original en normalisé compte tenu de la prédiction BERT contraintes de transformation. Pour certaines langues, en fonction des résultats sur les données de développement, les données de formation ont été étendues par la rétro-traduction des données OpenSubtitles. Dans le classement final des dix équipes participantes, l'équipe HEL-LJU a pris la deuxième place, marquant un meilleur score que l'équipe de pointe précédente.</abstract_fr>
      <abstract_es>Este documento describe los envíos de HEL-LJU a la tarea compartida MultilexNorm sobre la normalización léxica multilingüe. Nuestro sistema se basa en un paso de preprocesamiento de clasificación de tokens BERT, donde para cada token se predice el tipo de transformación necesaria (ninguna, mayúscula, minúscula, capitalizar, modificar), y un paso SMT a nivel de caracteres donde el texto se traduce del original al normalizado según la predicción de BERT restricciones de transformación. Para algunos idiomas, dependiendo de los resultados de los datos de desarrollo, los datos de entrenamiento se ampliaron mediante la retrotraducción de los datos de OpenSubtitles. En el orden final de los diez equipos participantes, el equipo HEL-LJU ha ocupado el segundo lugar, anotando mejor que el estado de la técnica anterior.</abstract_es>
      <abstract_pt>Este artigo descreve as submissões HEL-LJU para a tarefa compartilhada MultiLexNorm na normalização léxica multilíngue. Nosso sistema é baseado em uma etapa de pré-processamento de classificação de token BERT, onde para cada token é previsto o tipo de transformação necessária (nenhuma, maiúscula, minúscula, capitalizar, modificar), e uma etapa SMT em nível de caractere onde o texto é traduzido do original para normalizado dadas as restrições de transformação previstas pelo BERT. Para alguns idiomas, dependendo dos resultados nos dados de desenvolvimento, os dados de treinamento foram estendidos pela retrotradução dos dados do OpenSubtitles. Na ordenação final das dez equipes participantes, a equipe HEL-LJU ficou em segundo lugar, pontuando melhor que o estado da arte anterior.</abstract_pt>
      <abstract_zh>本文介 HEL-LJU MultiLexNorm 多言词法规范化共其事。 其统 BERT 令牌类预处理步骤,其每令牌,候必转换之类(无、大写、小写、大写、改),及字符级 SMT 步驿,其文本自原始转为规范化,给定 BERT 测转换约束。 其于言语,随发数据,练数因回译OpenSubtitles数以广之。 十参赛终序,HEL-LJU队第二,得分优先进之球队。</abstract_zh>
      <abstract_ja>この論文では、多言語の語彙正規化に関するMultiLexNorm共有タスクへのHEL - LJU提出について説明する。当社のシステムは、各トークンについて必要な変換のタイプが予測されるBERTトークン分類前処理ステップ（なし、大文字、小文字、大文字、修正）と、BERT予測変換制約を考慮してテキストが元から正規化される文字レベルのSMTステップに基づいています。いくつかの言語では、開発データの結果に応じて、トレーニングデータはOpenSubtitlesデータを逆翻訳することによって拡張されました。参加10チームの最終順位では、HEL - LJUチームが2位となり、これまでの最先端チームよりも良い成績を収めました。</abstract_ja>
      <abstract_hi>यह पेपर बहुभाषी लेक्सिकल सामान्यीकरण पर MultiLexNorm साझा कार्य के लिए HEL-LJU प्रस्तुतियों का वर्णन करता है। हमारी प्रणाली एक BERT टोकन वर्गीकरण preprocessing कदम पर आधारित है, जहां प्रत्येक टोकन के लिए आवश्यक परिवर्तन के प्रकार की भविष्यवाणी की जाती है (कोई नहीं, अपरकेस, लोअरकेस, पूंजीकरण, संशोधित), और एक चरित्र-स्तर एसएमटी चरण जहां पाठ को मूल से सामान्यीकृत करने के लिए अनुवादित किया जाता है BERT-भविष्यवाणी परिवर्तन बाधाओं को देखते हुए। कुछ भाषाओं के लिए, विकास डेटा पर परिणामों के आधार पर, प्रशिक्षण डेटा को OpenSubtitles डेटा का बैक-ट्रांसलेटिंग करके बढ़ाया गया था। भाग लेने वाली दस टीमों के अंतिम क्रम में एचईएल-एलजेयू टीम ने पिछले अत्याधुनिक से बेहतर स्कोर करते हुए दूसरा स्थान हासिल किया है।</abstract_hi>
      <abstract_ru>Этот документ описывает представления HEL-LJU к совместной задаче MultiLexNorm на многоязычной лексической нормализации. Наша система основана на шаге предварительной обработки классификации токенов BERT, где для каждого токена прогнозируется тип необходимого преобразования (нет, заглавные, строчные, заглавные, изменить), и шаге SMT на уровне символов, где текст переводится из исходного в нормализованный, учитывая ограничения преобразования, предсказанные BERT. Для некоторых языков, в зависимости от результатов по данным разработки, данные обучения были расширены путем обратной трансляции данных OpenSubtitles. В финальном заказе десяти команд-участниц команда HEL-LJU заняла второе место, набрав больше очков, чем предыдущая современная команда.</abstract_ru>
      <abstract_ga>Déanann an páipéar seo cur síos ar na haighneachtaí HEL-LJU don tasc roinnte MultiLexNorm ar normalú foclóireachta ilteangach. Tá ár gcóras bunaithe ar chéim réamhphróiseála aicmithe comhartha BERT, áit a bhfuiltear ag tuar cineál an chlaochlaithe riachtanach do gach chomhartha (níl aon cheann, cás uachtair, cás íochtair, caipitligh, modhnaigh), agus céim SMT ar leibhéal carachtar ina n-aistrítear an téacs ón mbunleagan. a normalú mar gheall ar na srianta claochlaithe atá tuartha ag BERT. I gcás teangacha áirithe, ag brath ar thorthaí na sonraí forbartha, leathnaíodh na sonraí oiliúna trí shonraí OpenSubtitles a aisaistriú. In ordú deiridh na ndeich bhfoireann rannpháirteacha, tá foireann HEL-LJU tar éis an dara háit a bhaint amach, ag scóráil níos fearr ná an stát roimhe seo.</abstract_ga>
      <abstract_ka>ამ დოკუმენტი HEL- LJU მომხმარებას მრავალური ლექსიკალური ნორმალიზაციაზე გაყოფილი მომხმარებელი დავალება. ჩვენი სისტემა BERT-ის კლასიფიკაციის წინაპროცესების წინაპროცესების წინაპირება, სადაც ყოველ წინაპირებლად მოჭირდებული ტრანფორმაციის ტიპი წინაპირებულია (არაფერი, მარტივი, მარტივი, მარტივი, კარიტალიზაცია, შეცვლა) და SMT-სი ზოგიერთი ენაში, განვითარების შესახებ განვითარების მონაცემების შესახებ, განვითარების მონაცემები განვითარებული OpenSubtitles-ის მონაცემებით გაფარდება. ოჲჟლვენთწრ ნაპვე ნა ევჟვრ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ ჲრევლვნთ.</abstract_ka>
      <abstract_el>Η παρούσα εργασία περιγράφει τις υποβολές HEL-LJU στην κοινή εργασία MultiLexNorm σχετικά με την πολύγλωσση λεξική ομαλοποίηση. Το σύστημά μας βασίζεται σε ένα βήμα προεπεξεργασίας ταξινόμησης συμβολαίων όπου για κάθε σύμβολο προβλέπεται ο τύπος του απαραίτητου μετασχηματισμού (κανένα, κεφαλαία, μικρά γράμματα, κεφαλαία, τροποποίηση), και ένα βήμα σε επίπεδο χαρακτήρων όπου το κείμενο μεταφράζεται από το πρωτότυπο σε κανονικοποιημένο δεδομένο των προβλεπόμενων περιορισμών μετασχηματισμού. Για ορισμένες γλώσσες, ανάλογα με τα αποτελέσματα των δεδομένων ανάπτυξης, τα δεδομένα κατάρτισης επεκτάθηκαν με την αναδρομική μετάφραση δεδομένων OpenSubtitles. Στην τελική σειρά των δέκα συμμετεχόντων ομάδων, η ομάδα έχει πάρει τη δεύτερη θέση, σκοράροντας καλύτερα από την προηγούμενη υπερσύγχρονη.</abstract_el>
      <abstract_hu>Ez a tanulmány bemutatja a HEL-LJU beadványait a MultiLexNorm többnyelvű lexikális normalizációs feladathoz. Rendszerünk egy BERT tokenosztályozási előfeldolgozási lépésen alapul, ahol minden tokennél előre látjuk a szükséges átalakítás típusát (nincs, nagybetű, kisbetű, nagybetű, módosítás), és egy karakterszintű SMT lépésen alapul, ahol a szöveg eredetről normalizálódik, tekintettel a BERT által előre látható átalakítási korlátozásokra. Egyes nyelvek esetében a fejlesztési adatok eredményeitől függően a képzési adatokat OpenSubtitles adatok visszafordításával bővítettük. A tíz résztvevő csapat végső sorrendjében a HEL-LJU csapat a második helyezést érte el, jobban, mint az előző korszerű.</abstract_hu>
      <abstract_it>Questo articolo descrive i contributi HEL-LJU al compito condiviso MultiLexNorm sulla normalizzazione lessicale multilingue. Il nostro sistema si basa su un passaggio di pre-elaborazione della classificazione dei token BERT, in cui per ogni token viene previsto il tipo di trasformazione necessaria (nessuna, maiuscola, minuscola, maiuscola, modifica), e un passaggio SMT a livello di carattere in cui il testo viene tradotto da originale a normalizzato, dati i vincoli di trasformazione previsti da BERT. Per alcune lingue, a seconda dei risultati sui dati di sviluppo, i dati di formazione sono stati estesi traducendo i dati OpenSubtitles. Nell'ordine finale delle dieci squadre partecipanti, la squadra HEL-LJU ha conquistato il secondo posto, segnando meglio del precedente stato dell'arte.</abstract_it>
      <abstract_kk>Бұл қағаз HEL- LJU көптеген лексілік нормализациялау үшін көптеген тапсырманың HEL- LJU жіберілуін анықтайды. Біздің жүйеміз BERT таңбаларының классификациясының алдын- процессорының қадамына негізделген. Әрбір таңбалар үшін қажетті түрлендірудің түрін бақылады (жоқ, үлкен- кіші, кіші- кіші, үлкен- кіші, үлкен- кіші, түрлендіру, өзгерту) мен Кейбір тілдер үшін, жасау деректерінің нәтижелеріне тәуелді, OpenSubtitles деректерінен қайта аудару үшін, оқыту деректері кеңейтілген. 10 қатысушылық топтардың соңғы ретінде, HEL-LJU тобы екінші жерді алдыңғы орындағыдан жақсы түсіндіреді.</abstract_kk>
      <abstract_ms>Kertas ini menggambarkan penghantaran HEL-LJU kepada tugas berkongsi MultiLexNorm pada normalisasi leksikal berbilang bahasa. Sistem kami berdasarkan langkah pemprosesan kelasukan token BERT, di mana bagi setiap token jenis pengubahan yang diperlukan dijangka (tiada, huruf atas, huruf kecil, mengubah kapital), dan langkah SMT aras-aksara di mana teks diterjemahkan dari asal ke normalisasi mengingat kegunaan pengubahan yang dijangka-BERT. Untuk beberapa bahasa, bergantung kepada keputusan pada data pembangunan, data latihan telah dilambangkan dengan menerjemahkan semula data OpenSubtitles. Dalam perintah terakhir dari sepuluh pasukan yang berpartisipasi, pasukan HEL-LJU telah mengambil tempat kedua, mencetak lebih baik daripada kemajuan sebelumnya.</abstract_ms>
      <abstract_lt>Šiame dokumente aprašomos HEL-LJU pateiktos multiLexNorm bendros užduoties dėl daugiakalbės lexinės normalizacijos. Mūsų sistema grindžiama BERT žymenų klasifikavimo išankstiniu apdorojimo etapu, kuriame kiekvienam žymenui numatomas būtinos transformacijos tipas (nė vienas, didžioji, mažoji, didžioji, didžioji, pakeista) ir SMT žingsniu, kuriame tekstas vertamas iš originalo į normalizuotą atsižvelgiant į BERT numatytus transformacijos apribojimus. Atsižvelgiant į vystymosi duomenų rezultatus, kai kurioms kalboms mokymo duomenys buvo pratęsti grįžtamaisiais vertimais OpenSubtitles duomenimis. Paskutiniame dešimties dalyvaujančių komandų užsakyme HEL-LJU komanda užima antrą vietą, jos rezultatai yra geresni nei ankstesnės pažangos.</abstract_lt>
      <abstract_mk>Овој весник ги опишува поднесувањата на HEL-LJU на заедничката задача на MultiLexNorm за мултијазичката лексикална нормализација. Нашиот систем се базира на чекор за препроцес на класификација на берт знаци, каде за секој знак се предвидува типот на неопходната трансформација (ништо, голема буква, мала буква, капитализирајте, модификувајте), и чекор на СМТ ниво на карактери каде текстот се преведува од оригинален на нормализиран со оглед на обврските на транс За некои јазици, во зависност од резултатите на податоците за развој, податоците за обука беа продолжени со преведување на податоците за OpenSubtitles. In the final ordering of the ten participating teams, the HEL-LJU team has taken the second place, scoring better than the previous state-of-the-art.</abstract_mk>
      <abstract_ml>ഈ പേപ്പറിന്റെ പേപ്പറിന്റെ വിശദീകരിക്കുന്നു പല ഭാഷയിലെ ലെക്സിക്കല്‍ സ്വാധീനതയില്‍ പങ്കുചേര്‍ത്ത ജോലിയുടെ ഹെല്‍ നമ്മുടെ സിസ്റ്റത്തിന്റെ ബെര്‍ട്ടി ടോക്ക് ക്ലാസ്ഫിക്കേഷന്‍ പ്രൊസിസ്റ്റ് ചെയ്യുന്നതിന്റെ അടിസ്ഥാനത്താണ്. എല്ലാ അടയാളങ്ങള്‍ക്കും ആവശ്യമുള്ള മാറ്റങ്ങളുടെ തരം പ്രവചിക്കപ്പെടുന്നതാണ്. ( ചില ഭാഷകള്‍ക്ക്, വികസിപ്പിക്കുന്ന വിവരങ്ങളുടെ ഫലങ്ങള്‍ ആശ്രയിച്ചിരിക്കുന്നു, പരിശീലനത്തിന്റെ ഡേറ്റാ പിന്ന In the final ordering of the ten participating teams, the HEL-LJU team has taken the second place, scoring better than the previous state-of-the-art.</abstract_ml>
      <abstract_mn>Энэ цаас HEL-LJU-ын олон хэлний хэлний хэмжээний хэлэлцүүлэх талаар олон ЛексNorm-д хуваалцах үйлдлийг тайлбарладаг. Бидний систем БЕРТ тооны хэлбэрээр ажиллах алхам дээр суурилсан. БЕРТ тооны хэлбэрээр хэрэгтэй өөрчлөлтийн хэлбэрийг тодорхойлж чадахгүй. Зарим хэлний хувьд хөгжлийн өгөгдлийн үр дүнд хамааралтай, хөгжлийн өгөгдлийн талаар сургалтын өгөгдлийн мэдээллийг буцаад орчуулан OpenSubtitles өгөгдлийн хувьд нэмэгдүүлсэн. 10 оролцогчдын сүүлийн захирал дээр HEL-LJU баг хоёр дахь орон зааж, өмнөх урлагийн байгууллагаас илүү сайн дуудсан.</abstract_mn>
      <abstract_mt>Dan id-dokument jiddeskrivi s-sottomissjonijiet tal-HEL-LJU lill-kompitu kondiviż tal-MultiLexNorm dwar in-normalizzazzjoni lexikali multilingwi. Is-sistema tagħna hija bbażata fuq pass ta’ preproċessar tal-klassifikazzjoni tat-tokens BERT, fejn għal kull token it-tip tat-trasformazzjoni meħtieġa huwa mbassar (l-ebda, l-akbar frażi, l-iżgħar frażi, il-kapitalizzazzjoni, il-modifika), u pass SMT fuq livell ta’ karattru fejn it-test jiġi tradott minn oriġinali għal normalizzat minħabba r-restrizzjonijiet ta’ trasformazzjoni mbassra mill-BERT. Għal xi lingwi, skont ir-riżultati tad-dejta tal-iżvilupp, id-dejta tat-taħriġ ġiet estiża billi d-dejta OpenSubtitles ġiet tradotta lura. Fl-ordni finali tal-għaxar timijiet parteċipanti, it-tim HEL-LJU ħa t-tieni post, b’punteġġ aħjar mill-aktar avvanzat preċedenti.</abstract_mt>
      <abstract_no>Denne papiret beskriver HEL-LJU-tillegga til den delte multiLexNorm-oppgåva på fleirspråksnormalisering. Systemet vårt er basert på eit forhandteringssteg for BERT- token- klassifikasjon, der for kvar token vert forhåndsvisa typen av den nødvendige transformasjonen (ingen, store bokstavar, små bokstavar, små bokstavar, endring) og ein SMT- steg der teksten vert omsett frå originalen til normalisert, gjeven BERT- forhåndsvisa transformasjonsgrensesnittet. For nokre språk, avhengig av resultatet på utviklingsdata, opplæringsdata vart utvida av tilbakeoversettende OpenSubtitles-data. I den siste rekkefølgja av dei ti deltakarane gruppa har HEL-LJU-gruppa tatt den andre plassen, som skal skapa bedre enn den førre kunsttilstanden.</abstract_no>
      <abstract_pl>Niniejszy artykuł opisuje zgłoszenia HEL-LJU do wspólnego zadania MultiLexNorm dotyczącego wielojęzycznej normalizacji leksykalicznej. Nasz system opiera się na kroku wstępnego przetwarzania klasyfikacji tokenów BERT, w którym dla każdego tokenu przewidywany jest typ niezbędnej transformacji (none, duże, małe litery, wielkie litery, wielkie litery, modyfikacja), oraz kroku SMT na poziomie znaków, w którym tekst jest tłumaczony z oryginału na normalizowany ze względu na przewidywane przez BERT ograniczenia transformacji. W przypadku niektórych języków, w zależności od wyników danych rozwojowych, dane szkoleniowe zostały rozszerzone o wsteczne tłumaczenie danych OpenSubtitles. W ostatecznej kolejności dziesięciu uczestniczących zespołów zespół HEL-LJU zajął drugie miejsce, zdobywając lepsze punkty niż poprzedni state-of-the-art.</abstract_pl>
      <abstract_ro>Această lucrare descrie trimiterile HEL-LJU la sarcina comună MultiLexNorm privind normalizarea lexicală multilingvă. Sistemul nostru se bazează pe un pas de pre-procesare a clasificării token-urilor BERT, unde pentru fiecare token este prevăzut tipul transformării necesare (nimeni, majuscule, mici, majuscule, modificări), și un pas SMT la nivel de caractere în care textul este tradus de la original la normalizat având în vedere constrângerile de transformare prevăzute de BERT. Pentru unele limbi, în funcție de rezultatele datelor de dezvoltare, datele de instruire au fost extinse prin traducerea înapoi a datelor OpenSubtitles. În ordinea finală a celor zece echipe participante, echipa HEL-LJU a ocupat locul doi, marcând mai bine decât cea de ultimă generație.</abstract_ro>
      <abstract_sr>Ovaj papir opisuje podatke HEL-LJU multiLexNorm podijeljene zadatke o multijezičkoj leksičkoj normalizaciji. Naš sistem je zasnovan na koraku predobrađivanja klasifikacije BERT znakova, gde se za svaki znak predviđa tip neophodne transformacije (nijedan, gornji, mali, kapitalizacija, modifikacija), i korak SMT nivoa karaktera u kojem se tekst prevodi iz originala na normalizaciju s obzirom na ograničenja transformacije predviđene BERT-om. Za neke jezike, ovisno o rezultatima podataka o razvoju, podaci o obuci su prošireni podacima o povratku prevodu OpenSubtitles. U poslednjem naređenju deset sudionih timova, tim HEL-LJU je uzeo drugo mesto, izvlačio je bolje od prethodnog stanja umjetnosti.</abstract_sr>
      <abstract_so>This paper describes the HEL-LJU submissions to the MultiLexNorm shared task on multilingual lexical normalization.  nidaamkayagu wuxuu ku saleysan yahay tallaabo ka hor-baaraandegista calaamada BERT, meesha calaamad kasta looga hor dhigi karo nooca loo baahan yahay is-beddelka (none, uppercase, hoosaystiro, capitalize, is-beddelin), iyo tallaabo SMT oo xaraf-heer ah, meesha ay text looga turjumo asalka iyo si caadiga ah, iyadoo lagu qoray xadhigyada beddelka ee BERT-predicted. Luqadaha qaarkood, waxay ku xiran tahay resultiyada ku saabsan danbiyada horumarinta, macluumaadka waxbarashada waxaa lagu fidiyay macluumaadka dib-turjumidda OpenSubtitles. Marka ugu dambaysta lagu amray tobankii kooxda qayb-ka ah, kooxda HEL-LJU waxay qaatay meeshii labaad, taasoo aad uga wanaagsan tahay xaaladdii hore.</abstract_so>
      <abstract_sv>Denna uppsats beskriver HEL-LJU:s bidrag till MultiLexNorm delade uppgift om flerspråkig lexikal normalisering. Vårt system bygger på ett BERT-tokenklassificeringssteg, där för varje token förutses vilken typ av transformation som krävs (ingen, versaler, små bokstäver, versaler, ändra), och ett SMT-steg på teckenivå där texten översätts från original till normaliserad med tanke på BERT-förutspådda transformationsbegränsningar. För vissa språk, beroende på resultaten på utvecklingsdata, utökades utbildningsdata genom att bakåtöversätta OpenSubtitles-data. I den slutliga beställningen av de tio deltagande lagen har HEL-LJU-laget tagit andraplatsen och gjort bättre poäng än tidigare toppmoderna.</abstract_sv>
      <abstract_ta>இந்த தாள் HEL- LJU ஒப்புகளை பல LexNorm பகிர்ந்த பணிக்கு விளக்குகிறது பல மொழி லெக்சிக்சியல் வழக்கம் மீது. எங்கள் அமைப்பு BERT குறியீடு பிரிப்பு முன் செயல்படுத்தல் படியை அடிப்படையாக இருக்கிறது, ஒவ்வொரு குறியீட்டிற்கும் தேவையான மாற்றம் வகையின் மாற்றம் முன்னோக்கப்படுகிறது (எதுவும் இல்லை, பெரிதாக,  @ info பத்து குழுக்களின் கடைசி கட்டளையில், HEL-LJU குழு இரண்டாவது இடத்தில் எடுத்துள்ளது, முந்தைய நிலையில் கலை விட சிறந்த மதிப்பெண்.</abstract_ta>
      <abstract_si>මේ පත්තුව හෙල්-LJu සම්පූර්ණය ගොඩක් ලෙක්ස් නෝර්ම් වලින් භාෂාවක් සාමාන්‍ය විදියට හැදිලි වැඩක් විස අපේ පද්ධතිය BERT ටොකෙන් ක්‍රියාසිකරණය ප්‍රිප්‍රේසිකරණය පැත්තට අධාරිත වෙනවා, හැම තොකෙන්ම අවශ්‍ය වෙනස් වර්ගය ප්‍රමාණය (none, uppercase, low character, Capilize, Modifie), සහ character-level SMT පැත්තක් තියෙනවා මු සමහර භාෂාවට, විකාශ දත්තේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රති අන්තිම ක්‍රියාත්මක කණ්ඩායම් දහයි, HEL-LJu කණ්ඩායමයා දෙවෙනි තැන ගත්තා, පස්සේ ක්‍රියාත්මක වඩා හොඳයි.</abstract_si>
      <abstract_ur>This paper describes the HEL-LJU submissions to the MultiLexNorm shared task on multilingual language normalization. ہماری سیستم ایک BERT ٹوکنی کلاسیفوں کی پیش پرپروسی سٹح پر بنیاد ہے، جہاں ہر ٹوکنے کے لئے ضروری تغییر کی طرح پیش بینی کی جاتی ہے (کوئی نہیں، بڑے کیس، چھوٹے کیس، بڑے کیسٹ، بڑی کیسٹ، بڑی کیسٹ، تبدیل کرنا، تبدیل کرنا) اور ایک شخصت-سٹح SMT سٹح پر جہاں بعض زبانوں کے لئے، ڈولیپٹ ڈیٹا پر نتیجے پر اعتبار ہوتے ہیں، ترینسی ڈیٹا پچھلے ٹرانسٹ کرنے والی OpenSubtitles ڈیٹا کے ذریعے پھیلایا گیا ہے. دس شرکت کرنے والے تیموں کی آخری دستور میں HEL-LJU تیم نے دوسری جگہ لے لیا ہے، اس سے بہتر آواز لگا رہا ہے جو پہلے کی حالت آرتی سے بہتر ہے.</abstract_ur>
      <abstract_uz>Bu qogʻoz ko'pgina tillar to ʻgʻri leksikal normalisiyatsiya bilan bir necha LexNorm qanday qandaydir HEL-LJU imkoniyatlarini anglatadi. Bizning tizimmiz BERT tegi darajalashtirish bir darajasi asosida, har bir belgi boshqa oʻzgarishning turini koʻrsatiladi (yuqori, kichik, kichik, kichik, kattalashtirish, oʻzgartirish) va matnning asl darajasi bir darajada tarjima qilinadigan BERT- oldingan shizgarishning tarjimalari tarjima qilinadi. @ info: status 10 bo'lgan guruhlarning oxirgi tartibi bo'lganda, HEL-LJU guruhi birinchi joyga qo'shilgan holatdan yaxshi ko'paydi.</abstract_uz>
      <abstract_vi>Tờ giấy này mô tả các chương trình HAL-JU cho công việc đa LexNorm đã chia sẻ một nhiệm vụ ổn định ngôn ngữ đa dạng. Hệ thống của chúng ta dựa trên một bước hiệu ứng giao lưu thiếu sót sót sót sót, để mỗi biểu tượng có thể dự đoán kiểu biến đổi cần thiết (không, chữ cái, chữ cái, chữ cái, chữ cái, ghi âm, sửa đổi) và một bước dịch chuyển dạng dạng dạng dạng dạng dạng dạng trước, từ gốc đến bình thường, dựa vào hạn chế biến đổi dự đoán của BERT. Đối với một số ngôn ngữ, dựa trên kết quả về dữ liệu phát triển, dữ liệu đào tạo được mở rộng bằng thông tin dịch ngược về OpenSubtitles. Trong cuộc gọi cuối cùng của mười đội bóng tham gia, đội Hel-LJU đã vào vị trí thứ hai, ghi điểm tốt hơn tân tiến trước.</abstract_vi>
      <abstract_bg>Настоящата статия описва представянето на споделената задача за многоезична лексикална нормализация. Системата ни се основава на етапа на предварителна обработка на класификация на символи, където за всеки символ се предвижда типът на необходимата трансформация (никаква, главни, малки букви, главни, модифицирани), и стъпка на ниво символи, където текстът се превежда от оригинал в нормализиран предвид предвидените ограничения на трансформацията. За някои езици, в зависимост от резултатите от данните за разработката, данните за обучение са разширени чрез обратно превеждане на данни. При окончателното подреждане на десетте участващи отбора отборът на ХЕЛ-ЛЮ зае второто място, отбелязвайки по-добри резултати от предишните.</abstract_bg>
      <abstract_hr>Ovaj papir opisuje podatke HEL-LJU multiLexNorm dijeljenom zadatku o multijezičkoj normalizaciji jezika. Naš sustav se temelji na koraku predobrađivanja klasifikacije BERT znakova, gdje se za svaki znak predviđa vrsta potrebne transformacije (nijedna, glavna, niska, kapitalizacija, modifikacija), i korak SMT nivoa znakova u kojem se tekst prevodi iz originala na normalizaciju s obzirom na ograničenje predviđene transformacije BERT-a. Za neke jezike, ovisno o rezultatima podataka o razvoju, podaci o obuci proširili su podaci o povratku prevodu OpenSubtitles. U posljednjem naređenju deset sudjelujućih timova, tim HEL-LJU je uzeo drugo mjesto, izvlačio je bolje od prethodnog stanja umjetnosti.</abstract_hr>
      <abstract_nl>Dit document beschrijft de HEL-LJU inzendingen aan de gedeelde taak MultiLexNorm over meertalige lexicale normalisatie. Ons systeem is gebaseerd op een BERT-tokenclassificatiestap, waarbij voor elk token het type van de noodzakelijke transformatie wordt voorspeld (geen, hoofdletters, kleine letters, hoofdletters, hoofdletters, hoofdletters, hoofdletters, wijzigen), en een SMT-stap op tekenniveau waarbij de tekst wordt vertaald van origineel naar genormaliseerd gezien de BERT-voorspelde transformatiebeperkingen. Voor sommige talen, afhankelijk van de resultaten op ontwikkelingsgegevens, werden de trainingsgegevens uitgebreid door OpenSubtitles data terug te vertalen. In de definitieve volgorde van de tien deelnemende teams heeft het HEL-LJU team de tweede plaats ingenomen en scoort beter dan de vorige state-of-the-art.</abstract_nl>
      <abstract_da>Denne artikel beskriver HEL-LJU's indlæg til MultiLexNorm delte opgave om flersproget leksikal normalisering. Vores system er baseret på et BERT-tokenklassificeringstrin, hvor den nødvendige transformation for hvert token forudsiges (ingen, store bogstaver, små bogstaver, store bogstaver, ændre), og et SMT-trin på tegnniveau, hvor teksten oversættes fra original til normaliseret på grund af BERT-forudsigede transformationsbegrænsninger. For nogle sprog blev træningsdataene, afhængigt af resultaterne på udviklingsdata, udvidet ved at oversætte OpenSubtitles-data tilbage. I den endelige rækkefølge af de ti deltagende hold har HEL-LJU-holdet taget andenpladsen og scoret bedre end det tidligere state-of-the-art.</abstract_da>
      <abstract_ko>본고는 HEL-LJU가 다국어 어휘 규범화 다어휘 규범 공유 임무에 제출한 상황을 묘사한다.우리 시스템은 BERT 태그 분류 사전 처리 절차를 기반으로 하고 그 중에서 각 태그의 필요한 변환 유형은 예측(없음, 대문자, 소문자, 대문자, 수정), 그리고 문자급 SMT 절차를 바탕으로 한다. 이 단계에서 BERT 예측의 변환 제약을 주고 텍스트는 원본에서 규범화된다.일부 언어는 개발 데이터의 결과에 따라 OpenSubtitles 데이터를 번역하여 훈련 데이터를 확장한다.10개 참가 팀의 최종 순위에서 HEL-LJU는 2위를 차지해 이전 최첨단 수준보다 높은 점수를 받았다.</abstract_ko>
      <abstract_de>Dieser Beitrag beschreibt die HEL-LJU-Einreichungen zur gemeinsamen Aufgabe MultiLexNorm zur mehrsprachigen lexikalischen Normalisierung. Unser System basiert auf einem Vorverarbeitungsschritt der BERT-Token-Klassifizierung, bei dem für jedes Token der Typ der notwendigen Transformation vorhergesagt wird (keine, Groß- und Kleinschreibung, Groß-/Kleinschreibung, Groß-/Kleinschreibung, Modifikation), und einem SMT-Schritt auf Zeichenebene, bei dem der Text unter Berücksichtigung der BERT-vorhergesagten Transformationsbeschränkungen vom Original in normalisiert übersetzt wird. Für einige Sprachen wurden, abhängig von den Ergebnissen der Entwicklungsdaten, die Trainingsdaten durch Rückübersetzung von OpenSubtitles-Daten erweitert. In der Endbestellung der zehn teilnehmenden Teams belegt das HEL-LJU-Team den zweiten Platz und punktet besser als der bisherige Stand der Technik.</abstract_de>
      <abstract_id>Kertas ini menjelaskan pengiriman HEL-LJU ke tugas berbagi MultiLexNorm tentang normalisasi lexik berbagai bahasa. Sistem kami berdasarkan langkah preproses klasifikasi token BERT, di mana untuk setiap token tipe transformasi yang diperlukan diprediksi (tidak ada, huruf atas, huruf kecil, kapitalisasi, modifikasi), dan langkah SMT karakter-level di mana teks diterjemahkan dari asli ke normalisasi mengingat batas transformasi yang diprediksi BERT. Untuk beberapa bahasa, bergantung pada hasil dari data pengembangan, data latihan diperluaskan dengan menerjemahkan kembali data OpenSubtitles. Dalam perintah terakhir dari sepuluh tim yang berpartisipasi, tim HEL-LJU telah mengambil kedua tempat, mencetak lebih baik dari yang sebelumnya state-of-the-art.</abstract_id>
      <abstract_fa>این کاغذ تحویل HEL-LJU را به کارهای تعدادی LexNorm در مورد تعداد تعدادی زبان‌های زیادی توصیف می‌کند. سیستم ما بر روی قدم پیش‌پردازی پیش‌پردازی پیش‌فرض کردن ترکیب نشانه‌های BERT است، جایی که برای هر ترکیب نوع تغییر نیاز پیش‌بینی نمی‌شود (هیچ یک، بزرگ، کوچک، سرمایه‌گذاری، تغییر‌گذاری، تغییر‌گذاری) و یک قدم SMT با سطح شخصیت که متن از اصلی به تنظییر ت برای برخی زبانها، بستگی به نتایج داده های توسعه، داده های آموزش توسط داده های OpenSubtitles پشتیبانی گسترش داده شد. در سفارش نهایی از ده تیم شرکت کننده، تیم HEL-LJU دوم مکان را گرفته است، که بهتر از وضعیت هنر پیشین می‌داند.</abstract_fa>
      <abstract_tr>Bu kagyz HEL-LJU MultiLexNorm'a multi dilli leksiýal normalizasyonda paýlaşýar. Biziň sistemimiz BERT token klasifikasynda, ileri işlemek üçin, her token gerekli transformasiýanyň tipi täze tahmin edilýär (hiçbir, kiçi, kiçi, kiçi, beýik harplariň, beýik harplariň, beýik harplariň, üýtgetmek üçin), we karakter-derejesi SMT basamaýasynda metin orijinal tarapyndan bellenilýär we BERT-yň öňlenen terjime Käbir diller üçin, gelişme maglumatynyň netijelerine görä, OpenSubtitles maglumatynyň yzyna terjime eden maglumaty tarapyndan uzatlandyryldy. On toparyň iň soňky suratynda HEL-LJU toparynyň ikinji ýerini aldy we öňki sanat durumyndan gowy çekdi.</abstract_tr>
      <abstract_af>Hierdie papier beskryf die HEL- LJU onderskrywings aan die MultiLexNorm gedeelde taak op veelvuldige leksiese normalisering. Ons stelsel is gebaseer op 'n BERT token klasifikasie voorprosessering stap, waar vir elke token die tipe van die nodige transformasie is voorskou (geen, hoofletter, klein bokstav, kapitaliseer, verander), en 'n karaktervlak SMT stap waar die teks vertaal word van oorspronklike na normaliseer gegee het die BERT- voorskoude transformasie beheinings. Vir sommige tale, afhanklik van die resultate van ontwikkelingsdata, was die onderwerp data uitgebreid deur terugvertaling OpenSubtitles data. In die eindelike ordening van die tien deelnadeerde teams, het die HEL-LJU-team die tweede plek geneem en beter as die vorige staat van die kuns geskied.</abstract_af>
      <abstract_sq>Ky dokument përshkruan paraqitjet HEL-LJU ndaj detyrës së përbashkët MultiLexNorm mbi normalizimin lexik shumëgjuhës. Sistemi ynë është bazuar në një hap paraprocesues të klasifikimit të tokenave BERT, ku për çdo token parashikohet lloji i transformimit të nevojshëm (asnjë, lartë, vogël, kapitalizo, modifiko) dhe një hap SMT në nivelin e karakterit ku teksti përkthehet nga origjinal në normalizuar duke marrë parasysh kufizimet e transformimit të parashikuar nga BERT. Për disa gjuhë, në varësi të rezultateve në të dhënat e zhvillimit, të dhënat e stërvitjes u zgjeruan duke përkthyer përsëri të dhënat OpenSubtitles. Në urdhërimin përfundimtar të dhjetë ekipave pjesëmarrëse, ekipi HEL-LJU ka marrë vendin e dytë, duke shënuar më mirë se më i mëparshmi.</abstract_sq>
      <abstract_am>ይህ ገጽ የHEL-LJU አዋጅ ለMultiLexNorm በተለያዩ ቋንቋዎች በብዙ ልዩ ልኩስቲካዊ ተደጋፊነት ላይ የተሰራጨውን ስራ ይናገራል፡፡ ስርዓታችን BERT ምልክት መግለጫ በመሠረት ላይ ነው፡፡ For some languages, depending on the results on development data, the training data was extended by back-translating OpenSubtitles data.  አሥር ተጋሪዎች ቡድን በኋለኛው ትእዛዝ፣ HEL-LJU ቡድን ከቀድሞው ሀገራት ይልቅ ሁለተኛውን ስፍራ ወሰደ፡፡</abstract_am>
      <abstract_hy>Այս հոդվածը նկարագրում է, թե ինչպես են ներկայացնում իրենց ներկայացումները ՄոլիլեքսՆորմ-ի բազլեզու լեքսիկական նորմալիզացիայի մասին: Մեր համակարգը հիմնված է BER նշանների դասակարգման նախամշակման քայլի վրա, որտեղ յուրաքանչյուր նշանի համար կանխատեսվում է անհրաժեշտ վերափոխման տեսակը (ոչ մեկը, մեծ մասը, փոքրիկ մասը, կապիտալիզացնել, փոխել), և SMT քայլի վրա, որտեղ տեքստը թարգմանվում է սկզբնական և նորմալիզացված, հաշվի առնելով BE Որոշ լեզուների համար, կախված զարգացման տվյալների արդյունքներից, ուսուցման տվյալները ընդլայնվեցին Open Տաս մասնակցող թիմերի վերջնական դասավորման ժամանակ, ՀԵԼ-ԼՋուի թիմը երկրորդ տեղը վերցրեց, ավելի լավ գնահատում է, քան նախորդ տեխնոլոգիաները:</abstract_hy>
      <abstract_sw>Gazeti hili linaelezea ujumbe wa HEL-LJU wa jumbe la MultiLexNorm uliosambazwa na kazi ya utaratibu wa lugha mbalimbali. Mfumo wetu una msingi wa hatua ya kuendeleza alama ya BERT, ambapo kwa kila alama ya aina ya mabadiliko yanayohitajika inatabiriwa (hakuna, juu, pungufu, ubora, mabadiliko), na hatua yenye alama ya SMT ambapo maandishi yanatafsiriwa kutoka asili hadi kawaida kufuatia vikwazo vya mabadiliko yanayotarajiwa na BERT. Kwa baadhi ya lugha, kulitegemea matokeo ya takwimu za maendeleo, takwimu za mafunzo ziliongezwa kwa takwimu za OpenSubtitles zilizotafsiriwa kwa mara nyingine. Katika amri ya mwisho ya timu kumi ya ushiriki, timu ya HEL-LJU imechukua nafasi ya pili, ikichukua nafasi bora zaidi ya hali ya sanaa iliyopita.</abstract_sw>
      <abstract_ca>Aquest article descriu les presentacions de HEL-LJU a la tasca compartida de MultiLexNorm sobre normalització lexical multilingüe. El nostre sistema es basa en un pas de preprocessió de la classificació de fitxes BERT, on per cada fitxa es prediu el tipus de transformació necessària (cap, gran, petita, capitalitzar, modificar), i un pas SMT de nivell de caràcter on el text es tradueix d'original a normalitzat tenint en compte les restriccions de transformació predites per BERT. Per algunes llengües, segons els resultats de les dades de desenvolupament, les dades d'entrenament es van estendre traduïnt de nou les dades d'OpenSubtitles. En l'ordre final dels 10 equips participants, l'equip HEL-LJU ha pres el segon lloc, puntuant millor que l'última.</abstract_ca>
      <abstract_bs>Ovaj papir opisuje podatke HEL-LJU multiLexNorm-u zajedničkog zadatka o multijezičkoj normalizaciji jezika. Naš sistem je zasnovan na koraku predobrazovanja klasifikacije BERT znakova, gdje se za svaki znak predviđa tip neophodne transformacije (nijedna, glavna, mali, kapitalizacija, modifikacija), i korak SMT nivoa znakova u kojem se tekst prevodi iz originala na normalizaciju s obzirom na ograničenja transformacije predviđene BERT-om. Za neke jezike, ovisno o rezultatima podataka o razvoju, podaci o obuci su prošireni podacima o povratnom prevodu OpenSubtitles. U posljednjem naređenju deset sudjelujućih tima, tim HEL-LJU je preuzeo drugo mjesto, bolje od prethodnog stanja umjetnosti.</abstract_bs>
      <abstract_bn>এই পত্রিকাটি মাল্টিলেক্সনরমের প্রতি হেল-এলজুই প্রতিযোগিতা ব্যাখ্যা করেছে বহুভাষী লেক্সিক্সিকাল স্বাভাবিক ব আমাদের সিস্টেম ভিত্তিক একটি বেরেট টি টোকার প্রক্রিয়ার প্রোগ্রাসিং পদক্ষেপ, যেখানে প্রত্যেক চিহ্নের জন্য প্রয়োজনীয় পরিবর্তনের ধরনের ভবিষ্যদ্বাণী করা হয় (কোন, উচ্চত্র, কম, সম্পাদন, রাজধানী এবং  কিছু ভাষার জন্য, উন্নয়ন তথ্যের ফলাফলের উপর নির্ভর করে, প্রশিক্ষণের তথ্য পেছনের অনুবাদ করা ওপেন সাবটাইটেলের তথ্য দ্ব দশটি অংশগ্রহণকারী দলের শেষ নির্দেশে হেল-এলজুই দল দ্বিতীয় স্থান নিয়েছে, পূর্বের রাষ্ট্র-শিল্পের চেয়ে ভালো কাজ করছে।</abstract_bn>
      <abstract_az>Bu kağıt çoxlu dil normalizasyonda HEL-LJU tərzlərini çoxlu LexNorm'a paylaşır. Bizim sistemimiz BERT token klasifikasiyasının ön işləmə adına dayandırılır, hər token üçün lazım transformasiyanın növünü təmin edilir (heç bir, böyük, küçük, böyük, böyük, böyük, dəyişdirilmiş), və mətnin orijinal dəyişdirilməsindən normalizlənməsi üçün təmin edilir. Bazı dillər üçün, inkişaf məlumatlarının sonuçlarına bağlı olaraq, təhsil məlumatları geri çevirib OpenSubtitles məlumatları ilə genişləndirildi. On istifadə edən ekibinin son əmri ilə, HEL-LJU ekibi ikinci yeri aldı, əvvəlki sanatın eyaletindən daha yaxşısını göstərdi.</abstract_az>
      <abstract_cs>Tento článek popisuje podání HEL-LJU do sdíleného úkolu MultiLexNorm na vícejazyčné lexikální normalizaci. Náš systém je založen na kroku předzpracování klasifikace BERT tokenů, kde je pro každý token předpovídán typ potřebné transformace (žádná, velká, malá písmena, velká písmena, velká písmena, velká písmena, změna), a na SMT kroku na znakové úrovni, kde je text přeložen z originálu do normalizovaného vzhledem k omezením transformace předpovědi BERT. U některých jazyků, v závislosti na výsledcích vývojových dat, byla tréninková data rozšířena zpětným překladem dat OpenSubtitles. Ve finálním pořadí deseti zúčastněných týmů zaujal tým HEL-LJU druhé místo a skóroval lepší než předchozí moderní.</abstract_cs>
      <abstract_et>Käesolevas artiklis kirjeldatakse HEL-LJU esitusi MultiLexNormi jagatud ülesandele mitmekeelse leksikaalse normaliseerimise kohta. Meie süsteem põhineb BERT märkide klassifitseerimise eeltöötluse etapil, kus iga märgi puhul prognoositakse vajaliku transformatsiooni tüüpi (puudub, suurtähed, väiketähed, suurtähed, muudatused) ja märgitasemel SMT etapil, kus tekst tõlgitakse originaalist normaliseeritud, arvestades BERT-i prognoositud transformatsioonipiiranguid. Mõnede keelte puhul, sõltuvalt arendusandmete tulemustest, laiendati koolitusandmeid OpenSubtitles andmete tagasitõlkimisega. Kümne osaleva võistkonna viimases tellimuses on HEL-LJU meeskond võtnud teise koha, tulemused on paremad kui eelmine tipptasemel.</abstract_et>
      <abstract_fi>Tässä artikkelissa kuvataan HEL-LJU-ehdotuksia monikielisen sanaston normalisoinnin MultiLexNorm-yhteiseen tehtävään. Järjestelmämme perustuu BERT-tunnuksen luokittelun esikäsittelyvaiheeseen, jossa jokaiselle tunnukselle ennustetaan tarvittavan muunnoksen tyyppi (ei mitään, isoja, pieniä kirjaimia, isoja kirjaimia, muokkauksia), ja merkkitason SMT-vaiheeseen, jossa teksti käännetään alkuperäisestä normalisoituun BERT-ennustettujen muunnosrajoitusten mukaisesti. Joidenkin kielten koulutustietoja laajennettiin kehitysdatan tuloksista riippuen kääntämällä OpenSubtitles-tietoja taaksepäin. Kymmenen osallistuvan joukkueen lopullisessa tilauksessa HEL-LJU-joukkue on sijoittunut toiselle sijalle ja saanut parempia pisteitä kuin edellinen huipputekniikka.</abstract_fi>
      <abstract_sk>V prispevku so opisani prispevki HEL-LJU v skupno nalogo MultiLexNorm o večjezični leksični normalizaciji. Naš sistem temelji na koraku predobdelave klasifikacije žetonov BERT, kjer je za vsak žeton predvidena vrsta potrebne transformacije (nobena, velika, majhna, velika, velika, velika, velika, velika, spremenjena) in koraku SMT na ravni znakov, kjer je besedilo prevedeno iz izvirnika v normalizirano glede na BERT predvidene omejitve transformacije. Za nekatere jezike, odvisno od rezultatov razvojnih podatkov, so bili podatki o usposabljanju razširjeni s prevajanjem podatkov OpenSubtitles. V končnem naročilu desetih sodelujočih ekip je ekipa HEL-LJU zasedela drugo mesto in dosegla boljše rezultate od prejšnjih najsodobnejših.</abstract_sk>
      <abstract_he>העיתון הזה מתאר את ההעברות של HEL-LJU למשימה המשותפת של MultiLexNorm על נורמליזציה לקסיקה רבת שפתיים. המערכת שלנו מבוססת על צעד מערכת מערכת מערכת מערכת שינוי של סימנים BERT, שבו, לכל סימנים, ניתן לחזות את הסוג של השינוי הנדרש (שום דבר, מידה גבוהה, מידה נמוכה, מידה גבוהה, שינוי), ו צעד SMT ברמה האופים שבו הטקסט מתרגם ממקורי לנורמליזם בהתחשב במגבלות השינוי שנצפו על ידי BE עבור כמה שפות, בהתאם לתוצאות על נתוני פיתוח, נתוני האימונים הוארכו על ידי תרגום מאחור נתוני OpenSubtitles. בהזמנה הסופית של עשר הקבוצות המשתתפות, צוות HEL-LJU לקח את המקום השני, מצביע טוב יותר מהמצב המיוחד הקודם.</abstract_he>
      <abstract_ha>Wannan takardan na describe the EML-LJU elements to the mulLexNorthm share job on normal language. Babu tsarin mu a kan wata hanyor shiryarwa na BERT, inda za'a iya ƙayyade nau'in shiryoyin ayuka da aka ƙayyade (wani, mai girma, ƙarami, girma, girma, kuma da wata daraja na-SMT, inda aka tafsiri matsayin daga origina zuwa a normal da aka ƙayyade tsarin transformation na BERT-wanda aka ƙayyade. @ action: button Ga ƙarshen umurni na jama'a kumi mãsu haɗuwa, Team the EML-LJU has taken a matsayin na farko, yana ƙaranci mafiya alhẽri daga the previous state-of-art.</abstract_ha>
      <abstract_jv>Gambar iki rambarang nggawe HEL-Lju tarjamahan kanggo MultiLexNorm sing ngendalikno karo akeh langkung sane. Where Terus ing langkung, dipunangé langkung diputêt nang data nggawé, dadi téraning sing luwih bantuan karo data Open Subtitles. Omahmu uwis rampung sing sepisan sing dumadhi, ekip HEL-Ljuyu wis rampung dibuté, sawalik dhéwé sing luwih apik sing katêpakan karo perusahaan-perusahaan.</abstract_jv>
      <abstract_bo>ཤོག་བྱང་འདིས་HEL-LJU་གཟུགས་རིས་སྐད་རིགས་སྐད་ཀྱི་ཆ་རྒྱུན་ལྡན་གྱི་ལས་འགུལ་སྤྲོད་ཀྱི་ཡོད། Our system is based on a BERT token classification preprocessing step, where for each token the type of the necessary transformation is predicted (none, uppercase, lowercase, capitalize, modify), and a character-level SMT step where the text is translated from original to normalized given the BERT-predicted transformation constraints. The following information is available: སྐད་ཡིག་ལ་ཤས་ཀྱི་གནད་དོན་དག་ནི་ཡར་རྒྱས་འགྲོ་བརྗོད་ཀྱི་གནད་དོན་དག་འབྲེལ་བ་དང་མཉམ་དུ་གཏོང མཐའ་མཇུག་གི་དབུགས་བསྡད་པའི་དུས་མཇུག་གི་གོ་སྐབས་HEL-LJU མི་དབང་གིས་དུས་གཉིས་པ་དེ་ཐོག་ལས་ སྔོན་གྱི་གནས་སྟངས་དང་སྔོན་ག</abstract_bo>
      </paper>
    <paper id="53">
      <title>Sequence-to-Sequence Lexical Normalization with Multilingual Transformers</title>
      <author><first>Ana-Maria</first><last>Bucur</last></author>
      <author><first>Adrian</first><last>Cosma</last></author>
      <author><first>Liviu P.</first><last>Dinu</last></author>
      <pages>473–482</pages>
      <abstract>Current benchmark tasks for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> contain text that is qualitatively different from the text used in informal day to day digital communication. This discrepancy has led to severe performance degradation of state-of-the-art NLP models when fine-tuned on real-world data. One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, into a more standardized form. In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation problem</a>. As the noisy text is a pervasive problem across languages, not just <a href="https://en.wikipedia.org/wiki/English_language">English</a>, we leverage the multi-lingual pre-training of mBART to fine-tune it to our data. While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks. Our results show that while word-level, intrinsic, performance evaluation is behind other methods, our model improves performance on extrinsic, downstream tasks through <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">normalization</a> compared to models operating on raw, unprocessed, social media text.</abstract>
      <url hash="1fbf78c4">2021.wnut-1.53</url>
      <bibkey>bucur-etal-2021-sequence</bibkey>
      <doi>10.18653/v1/2021.wnut-1.53</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    <title_pt>Normalização Lexical de Sequência a Sequência com Transformadores Multilíngues</title_pt>
      <title_fr>Normalisation lexicale séquence par séquence à l'aide de transformateurs multilingues</title_fr>
      <title_ar>التطبيع المعجمي من التسلسل إلى التسلسل باستخدام محولات متعددة اللغات</title_ar>
      <title_es>Normalización léxica secuencia a secuencia con transformadores multilingües</title_es>
      <title_ja>多言語変圧器を使用したシーケンス間語彙正規化</title_ja>
      <title_zh>多言转换器序词法规范化</title_zh>
      <title_hi>बहुभाषी ट्रांसफॉर्मर के साथ अनुक्रम-से-अनुक्रम लेक्सिकल सामान्यीकरण</title_hi>
      <title_ru>Последовательная лексическая нормализация с многоязычными трансформаторами</title_ru>
      <title_ga>Normalú Foclaíochta Seicheamh-go-Seicheamh le Claochladáin Ilteangacha</title_ga>
      <title_hu>Szekvencia-szekvencia Lexikus normalizáció többnyelvű transzformátorokkal</title_hu>
      <title_el>Λεξικό κανονικοποίηση ακολουθίας σε ακολουθία με πολύγλωσσους μετασχηματιστές</title_el>
      <title_ka>მრავალენგური ტრანფორმეტრებით ლექსიკალური ნორმალიზაცია</title_ka>
      <title_kk>Көптілік түрлендірушілерімен лексикалдық қадамдастыру</title_kk>
      <title_it>Normalizzazione lessicale sequenziale con trasformatori multilingue</title_it>
      <title_ms>Normalisasi Leksik Sejukan-ke-Sejukan dengan Penukar Berbahasa</title_ms>
      <title_lt>Seka į seką lexinė normalizacija su daugiakalbiais transformatoriais</title_lt>
      <title_mk>Лексикална нормализација од секвенција до секвенција со мултијазички трансформирачи</title_mk>
      <title_mn>Олон хэл шилжүүлэгчидтэй лексикийн эзэмшил</title_mn>
      <title_pl>Leksykalna normalizacja sekwencji do sekwencji z transformatorami wielojęzycznymi</title_pl>
      <title_mt>Normalizzazzjoni Lessika minn Sekwenza għal Sekwenza bi Trasformaturi Multilingwi</title_mt>
      <title_ml>Multilingual Transformers</title_ml>
      <title_no>Sekvens- til- sekvens leksisk normalisering med fleirspråk transformerer</title_no>
      <title_si>ගොඩක් භාෂාවක් වෙනස් කරනවා ලෙක්සිකාල් සාමාන්‍ය කරනවා</title_si>
      <title_sv>Sekvens-till-sekvens Lexisk Normalisering med flerspråkiga transformatorer</title_sv>
      <title_ro>Normalizare lexică secvență-secvență cu transformatoare multilingve</title_ro>
      <title_sr>Sekvencija do sekvence leksička normalizacija sa višejezičkim transformatorima</title_sr>
      <title_so>Sequence-to-sequence Lexical Normalization with Multilingual Transformers</title_so>
      <title_ta>பல மொழிகள் மாற்றுபவர்களுடன் தொடர்ச்சியில் இருந்து வரிசைப்படுத்தல் லெக்சிக்சியல் இயல்பாக்கம்</title_ta>
      <title_ur>Multilingual Transformers کے ساتھ سکوئنس-تا-سکوئنس لکسیکل عامل کرنا</title_ur>
      <title_uz>Sequence-to-Sequence Lexical Normalization with Multilingual Transformers</title_uz>
      <title_vi>Kích hoạt ngôn ngữ tự động</title_vi>
      <title_da>Sekvens-til-Sekvens-Lexisk Normalisering med flersprogede transformatorer</title_da>
      <title_hr>Sekvencija do sekvence leksička normalizacija s višejezičkim transformatorima</title_hr>
      <title_nl>Sequence-to-Sequence Lexische normalisatie met meertalige transformatoren</title_nl>
      <title_bg>Лексикална нормализация от последователност към последователност с многоезични трансформатори</title_bg>
      <title_de>Sequenz-zu-Sequenz Lexische Normalisierung mit mehrsprachigen Transformatoren</title_de>
      <title_id>Normalisasi Sekuensi-ke-Sekuensi Lexik dengan Transformer Berbahasa</title_id>
      <title_fa>نسبت به نسبت نسبت به نسبت نسبت به نسبت نسبت به نسبت به نسبت نسبت به نسبت‌های نسبت به نسبت‌های نسبت به نسبت به نسبت‌های نسبت به نسبت به نسبت</title_fa>
      <title_sw>Uwezeshaji wa Kilexico kwa mara nyingi</title_sw>
      <title_sq>Sequence-to-Sequence Lexical Normalization with Multilingual Transformers</title_sq>
      <title_af>Sequence- to- sequence Lexical Normalisation with Multilingual Transformers</title_af>
      <title_am>undo-type</title_am>
      <title_hy>Հաջորդականության և հաջորդականության լեքսիկական նորմալիզացիա բազլեզու վերափոխողների հետ</title_hy>
      <title_az>Ă‡oxlu dil transformatĂ¶rlÉ™ri ilÉ™ sÄ±ralama-sÄ±ralama-sÄ±ralama</title_az>
      <title_bn>মাল্টিভাষার ট্রান্সফর্মারের সাথে সেকেন্ড- থেকে সেকেন্সেক্সিয়াল ল লেক্সিকাল স্বাভাবিক</title_bn>
      <title_bs>Sekvencija do sekvence leksička normalizacija sa mnogijezičkim transformatorima</title_bs>
      <title_ko>다언어 변환기를 사용하여 서열에서 서열까지의 어법 규범화를 실현하다</title_ko>
      <title_tr>Birnäçe dilli terjimeler bilen resmi-täsirlerden soňlaşdyrma</title_tr>
      <title_cs>Lexická normalizace sekvence na sekvenci s vícejazyčnými transformátory</title_cs>
      <title_fi>Sekvenssi sekvenssiin -normalisointi monikielisillä muuntajilla</title_fi>
      <title_et>Mitmekeelsete transformaatoritega lexikaalne normaliseerimine järjestusest järjestusesse</title_et>
      <title_ca>Sequence-to-Sequence Lexical Normalization with Multilingual Transformers</title_ca>
      <title_jv>Subtitles</title_jv>
      <title_sk>Lexična normalizacija zaporedja v zaporedje z večjezičnimi transformatorji</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>נורמליזציה לקסית מעקב לעקב עם מעצבים רבים שפותיים</title_he>
      <title_bo>དབྱེ་སྟངས་ལ་རྗེས་སུ་དབྱིབས་གྱི་སྤྱིར་བཏང་བའི་རྒྱུན་ལྡན་བྱེད་ཀྱི་དབྱིབས་སྒྱུར་བ</title_bo>
      <abstract_pt>As tarefas de referência atuais para processamento de linguagem natural contêm texto que é qualitativamente diferente do texto usado na comunicação digital informal do dia a dia. Essa discrepância levou a uma severa degradação do desempenho de modelos de PNL de última geração quando ajustados em dados do mundo real. Uma forma de resolver esse problema é por meio da normalização lexical, que é o processo de transformação de texto não padronizado, geralmente de mídia social, em uma forma mais padronizada. Neste trabalho, propomos um modelo de sequência a sequência em nível de sentença baseado em mBART, que enquadra o problema como um problema de tradução automática. Como o texto ruidoso é um problema generalizado em todos os idiomas, não apenas no inglês, aproveitamos o pré-treinamento multilíngue do mBART para ajustá-lo aos nossos dados. Embora as abordagens atuais operem principalmente no nível de palavra ou subpalavra, argumentamos que essa abordagem é direta do ponto de vista técnico e se baseia em redes de transformadores pré-treinados existentes. Nossos resultados mostram que, embora a avaliação de desempenho intrínseca e em nível de palavra esteja por trás de outros métodos, nosso modelo melhora o desempenho em tarefas extrínsecas e downstream por meio da normalização em comparação com modelos que operam em texto de mídia social bruto e não processado.</abstract_pt>
      <abstract_ar>تحتوي المهام المعيارية الحالية لمعالجة اللغة الطبيعية على نص يختلف نوعياً عن النص المستخدم في الاتصالات الرقمية غير الرسمية اليومية. أدى هذا التناقض إلى تدهور شديد في أداء نماذج البرمجة اللغوية العصبية الحديثة عند ضبطها على بيانات العالم الحقيقي. تتمثل إحدى طرق حل هذه المشكلة في التطبيع المعجمي ، وهو عملية تحويل النص غير القياسي ، عادةً من وسائل التواصل الاجتماعي ، إلى شكل أكثر توحيدًا. في هذا العمل ، نقترح نموذج التسلسل إلى التسلسل على مستوى الجملة بناءً على mBART ، والذي يضع المشكلة في إطار مشكلة الترجمة الآلية. نظرًا لأن النص الصاخب يمثل مشكلة منتشرة عبر اللغات ، وليس اللغة الإنجليزية فقط ، فإننا نستفيد من التدريب المسبق متعدد اللغات لـ mBART لضبطه وفقًا لبياناتنا. بينما تعمل الأساليب الحالية بشكل أساسي على مستوى الكلمة أو الكلمة الفرعية ، فإننا نجادل في أن هذا النهج مباشر من وجهة نظر فنية ويعتمد على شبكات المحولات الحالية المدربة مسبقًا. تظهر نتائجنا أنه في حين أن تقييم الأداء على مستوى الكلمات والجوهرية وراء الأساليب الأخرى ، فإن نموذجنا يعمل على تحسين الأداء في المهام الخارجية والمتلقية من خلال التطبيع مقارنة بالنماذج التي تعمل على نصوص وسائط اجتماعية خام وغير معالجة.</abstract_ar>
      <abstract_fr>Les tâches de référence actuelles pour le traitement du langage naturel contiennent du texte qualitativement différent du texte utilisé dans les communications numériques informelles quotidiennes. Cet écart a entraîné une grave dégradation des performances des modèles de PNL de pointe lorsqu'ils sont affinés sur des données réelles. Une façon de résoudre ce problème est la normalisation lexicale, qui consiste à transformer un texte non standard, généralement issu des médias sociaux, en une forme plus standardisée. Dans ce travail, nous proposons un modèle séquence-séquence au niveau de la phrase basé sur mBart, qui définit le problème comme un problème de traduction automatique. Comme le texte bruyant est un problème omniprésent dans toutes les langues, et pas seulement en anglais, nous tirons parti de la pré-formation multilingue de mBart pour l'adapter à nos données. Alors que les approches actuelles fonctionnent principalement au niveau des mots ou des sous-mots, nous soutenons que cette approche est simple d'un point de vue technique et repose sur des réseaux de transformateurs pré-entraînés existants. Nos résultats montrent que si l'évaluation intrinsèque des performances au niveau des mots est en retard par rapport aux autres méthodes, notre modèle améliore les performances sur les tâches extrinsèques en aval grâce à la normalisation par rapport aux modèles fonctionnant sur du texte brut non traité sur les réseaux sociaux.</abstract_fr>
      <abstract_es>Las tareas de referencia actuales para el procesamiento del lenguaje natural contienen texto que es cualitativamente diferente del texto utilizado en la comunicación digital informal del día a día. Esta discrepancia ha llevado a una grave degradación del rendimiento de los modelos de PNL de última generación cuando se ajustan con precisión a los datos del mundo real. Una forma de resolver este problema es mediante la normalización léxica, que es el proceso de transformar el texto no estándar, generalmente de las redes sociales, en una forma más estandarizada. En este trabajo, proponemos un modelo de secuencia a secuencia a nivel de oración basado en mBART, que enmarca el problema como un problema de traducción automática. Como el texto ruidoso es un problema generalizado en todos los idiomas, no solo en el inglés, aprovechamos la capacitación previa multilingüe de mBART para ajustarlo a nuestros datos. Si bien los enfoques actuales funcionan principalmente a nivel de palabra o subpalabra, sostenemos que este enfoque es directo desde un punto de vista técnico y se basa en las redes de transformadores preentrenadas existentes. Nuestros resultados muestran que, si bien la evaluación intrínseca del desempeño a nivel de palabra está detrás de otros métodos, nuestro modelo mejora el desempeño en tareas extrínsecas y posteriores a través de la normalización en comparación con los modelos que funcionan con texto de redes sociales sin procesar y sin procesar.</abstract_es>
      <abstract_ja>自然言語処理のための現在のベンチマークタスクには、非公式な日々のデジタルコミュニケーションで使用されるテキストとは質的に異なるテキストが含まれています。 この相違は、現実のデータを微調整すると、最先端のNLPモデルのパフォーマンス低下を招きます。 この問題を解決する1つの方法は、通常ソーシャルメディアから非標準テキストをより標準化された形式に変換するプロセスである、語彙的正規化を通じてです。 この研究では、mBARTに基づく文レベルのシーケンス間シーケンスモデルを提案し、問題を機械翻訳問題として枠組み化しています。 ノイズの多いテキストは、英語に限らず、言語全体にわたって広範囲にわたる問題であるため、mBARTの多言語事前トレーニングを活用して、データに微調整します。 現在のアプローチは主に単語またはサブワードレベルで動作しますが、このアプローチは技術的な観点から直接的であり、既存の事前にトレーニングされた変圧器ネットワークに基づいて構築されていると主張します。 私たちの結果は、ワードレベルの本質的なパフォーマンス評価が他の方法よりも遅れている一方で、当社のモデルは、生の未処理のソーシャルメディアテキスト上で動作するモデルと比較して、正規化を通じて外因的なダウンストリームタスクのパフォーマンスを向上させることを示しています。</abstract_ja>
      <abstract_zh>今自然语言处准试务包文本与非常数字通信所用文本有质不同。 其差最先进者NLP形于真数微调,性能大降。 一法因词汇规范化,将非标准文本(常自社交媒体)转为更标准化。 凡此诸事,mBART句序之,框定为机器翻译。 嘈杂之文,本跨言语(非独英语)之普问,故因 mBART 之多言预训练以应吾数。 虽在单词或子词级,吾以为易于术数,而立于豫练之变压器网络。 吾之的结果表明,虽单词级内在,性评后法,与在原始,未处理社交媒体文本,规范化外在下流。</abstract_zh>
      <abstract_hi>प्राकृतिक भाषा प्रसंस्करण के लिए वर्तमान बेंचमार्क कार्यों में पाठ होता है जो अनौपचारिक दिन-प्रतिदिन के डिजिटल संचार में उपयोग किए जाने वाले पाठ से गुणात्मक रूप से अलग होता है। इस विसंगति ने वास्तविक दुनिया के डेटा पर ठीक-ठाक होने पर अत्याधुनिक एनएलपी मॉडल के गंभीर प्रदर्शन में गिरावट का नेतृत्व किया है। इस मुद्दे को हल करने का एक तरीका लेक्सिकल सामान्यीकरण के माध्यम से है, जो गैर-मानक पाठ को बदलने की प्रक्रिया है, आमतौर पर सोशल मीडिया से, एक अधिक मानकीकृत रूप में। इस काम में, हम mBART पर आधारित एक वाक्य-स्तरीय अनुक्रम-से-अनुक्रम मॉडल का प्रस्ताव करते हैं, जो समस्या को मशीन अनुवाद समस्या के रूप में फ्रेम करता है। चूंकि शोर पाठ भाषाओं में एक व्यापक समस्या है, न केवल अंग्रेजी, हम अपने डेटा पर इसे ठीक करने के लिए mBART के बहुभाषी पूर्व-प्रशिक्षण का लाभ उठाते हैं। जबकि वर्तमान दृष्टिकोण मुख्य रूप से शब्द या सबवर्ड स्तर पर काम करते हैं, हम तर्क देते हैं कि यह दृष्टिकोण तकनीकी दृष्टिकोण से सीधा है और मौजूदा पूर्व-प्रशिक्षित ट्रांसफार्मर नेटवर्क पर बनाता है। हमारे परिणाम बताते हैं कि जबकि शब्द-स्तर, आंतरिक, प्रदर्शन मूल्यांकन अन्य तरीकों के पीछे है, हमारा मॉडल कच्चे, असंसाधित, सोशल मीडिया पाठ पर काम करने वाले मॉडल की तुलना में सामान्यीकरण के माध्यम से बाहरी, डाउनस्ट्रीम कार्यों पर प्रदर्शन में सुधार करता है।</abstract_hi>
      <abstract_ru>Текущие эталонные задачи для обработки естественного языка содержат текст, который качественно отличается от текста, используемого в неформальной повседневной цифровой коммуникации. Это несоответствие привело к серьезной деградации производительности современных моделей NLP при тонкой настройке на реальных данных. Одним из способов решения этой проблемы является лексическая нормализация, которая представляет собой процесс преобразования нестандартного текста, обычно из социальных сетей, в более стандартизированную форму. В этой работе мы предлагаем модель последовательности на уровне предложения, основанную на mBART, которая обрамляет задачу как задачу машинного перевода. Поскольку шумный текст является широко распространенной проблемой для разных языков, а не только для английского языка, мы используем многоязычное предварительное обучение mBART, чтобы точно настроить его на наши данные. Хотя нынешние подходы в основном работают на уровне слова или подслова, мы утверждаем, что этот подход прост с технической точки зрения и основан на существующих предварительно обученных трансформаторных сетях. Наши результаты показывают, что, хотя оценка производительности на уровне слов стоит за другими методами, наша модель улучшает производительность по внешним, последующим задачам за счет нормализации по сравнению с моделями, работающими с необработанным текстом в социальных сетях.</abstract_ru>
      <abstract_ga>Cuimsíonn tascanna tagarmharcála reatha do phróiseáil teanga nádúrtha téacs atá difriúil go cáilíochtúil leis an téacs a úsáidtear i gcumarsáid dhigiteach neamhfhoirmiúil ó lá go lá. Mar thoradh ar an neamhréireacht seo tá dian-dhíghrádú feidhmíochta ar mhúnlaí nua-aimseartha NLP nuair a dhéantar mionchoigeartú ar shonraí ón bhfíorshaol. Bealach amháin leis an tsaincheist seo a réiteach ná trí normalú foclóireachta, is é sin an próiseas chun téacs neamhchaighdeánach, de ghnáth ó na meáin shóisialta, a athrú go foirm níos caighdeánaithe. Sa obair seo, molaimid múnla seicheamh-go-seicheamh ag leibhéal abairtí bunaithe ar mBART, a fhrámaíonn an fhadhb mar fhadhb aistriúcháin mheaisín. Toisc gur fadhb fhorleatach thar theangacha é an téacs callánach, ní hamháin an Béarla, bainimid úsáid as réamhoiliúint ilteangach mBART chun é a mhionchoigeartú dár sonraí. Cé go n-oibríonn cur chuige reatha den chuid is mó ag leibhéal na bhfocal nó na bhfocal, áitímid go bhfuil an cur chuige seo simplí ó thaobh teicniúil de agus go dtógann sé ar líonraí claochladán réamhoilte atá ann cheana féin. Léiríonn ár dtorthaí, cé go bhfuil meastóireacht feidhmíochta ar leibhéal focal, intreach, taobh thiar de mhodhanna eile, go bhfeabhsaíonn ár múnla feidhmíocht ar thascanna eiseacha, iartheachtacha trí normalú i gcomparáid le samhlacha a fheidhmíonn ar théacs meáin shóisialta amh, neamhphróiseáilte.</abstract_ga>
      <abstract_el>Οι τρέχουσες εργασίες αναφοράς για την επεξεργασία φυσικής γλώσσας περιέχουν κείμενο που είναι ποιοτικά διαφορετικό από το κείμενο που χρησιμοποιείται στην άτυπη καθημερινή ψηφιακή επικοινωνία. Αυτή η ασυμφωνία έχει οδηγήσει σε σοβαρή υποβάθμιση της απόδοσης των μοντέλων αιχμής όταν συντονίζονται σε δεδομένα πραγματικού κόσμου. Ένας τρόπος για να επιλυθεί αυτό το ζήτημα είναι μέσω της λεξικής ομαλοποίησης, η οποία είναι η διαδικασία μετατροπής μη τυποποιημένου κειμένου, συνήθως από τα μέσα κοινωνικής δικτύωσης, σε μια πιο τυποποιημένη μορφή. Στην παρούσα εργασία, προτείνουμε ένα μοντέλο ακολουθίας σε επίπεδο πρότασης βασισμένο στο το οποίο πλαισιώνει το πρόβλημα ως πρόβλημα μηχανικής μετάφρασης. Καθώς το θορυβώδες κείμενο είναι ένα διάχυτο πρόβλημα σε όλες τις γλώσσες, όχι μόνο στα αγγλικά, αξιοποιούμε την πολύγλωσση προεκπαίδευση του για να το προσαρμόσουμε με τα δεδομένα μας. Ενώ οι τρέχουσες προσεγγίσεις λειτουργούν κυρίως σε επίπεδο λέξεων ή υπολέξεων, υποστηρίζουμε ότι αυτή η προσέγγιση είναι απλή από τεχνική άποψη και βασίζεται σε υπάρχοντα προ-εκπαιδευμένα δίκτυα μετασχηματιστών. Τα αποτελέσματά μας δείχνουν ότι ενώ η αξιολόγηση απόδοσης σε επίπεδο λέξεων, εγγενής, βρίσκεται πίσω από άλλες μεθόδους, το μοντέλο μας βελτιώνει την απόδοση σε εξωτερικές, μεταγενέστερες εργασίες μέσω ομαλοποίησης σε σύγκριση με μοντέλα που λειτουργούν σε ακατέργαστο, μη επεξεργασμένο κείμενο κοινωνικών μέσων.</abstract_el>
      <abstract_ka>მიმდინარე ბენქმერი დავალებები თავისუფალური ენის პროცესისთვის ტექსტის შესახებ, რომელიც კვალგატიტურად განსხვავებულია ტექსტის შესახებ ინფორმალური დღ ეს განსხვავება გადავიწყეთ ძალიან გამოსახულებელი განსხვავება NLP მოდელების განსხვავებას, როდესაც რეალური მსოფლიოს მონაცემების შესაძლებლობით დააკეთება. ერთი გზა ამ პრობლემას გადაწყვება არის ლექსიკალური ნორმალიზაციაზე, რომელიც არ არის სტანდარტატური ტექსტის პროცესი, რომელიც სოციალური მედიდიაზე, უფრო სტანდა ამ სამუშაოში, ჩვენ მBART-ზე დაბაზიან წესების წესების წესების წესების მოდელს, რომელიც პრობლემას მაქსინის წესების პრობლემა. როგორც სიმაღლე ტექსტი არის სიმაღლე პრობლემა ენაში, არა მხოლოდ ანგლისური, ჩვენ მხოლოდ ენგლისური წინატრიქციის წინატრიქციას ჩვენი მონაცემებისთვის გამოყენებთ. მიმდინარე მიღებულება სამუშაოდ სიტყვების ან სამუშაო სიტყვების დონეზე, ჩვენ არგებთ, რომ ეს პროგრამა ტექნონიკური სამუშაოდან უკეთესი და დავყენება მხოლოდ სამუ ჩვენი წარმოდგენები აჩვენებენ, რომ როცა სიტყვების დონე, ინტერენსიკური, პროცესტის გაუმუშავება სხვა მეტისების შემდეგ, ჩვენი მოდელი გაუფლება კეთესტრინსიკური, ჩვენი მოდელი ნორმალიზაციის</abstract_ka>
      <abstract_hu>A természetes nyelvfeldolgozás jelenlegi referenciafeladatai olyan szövegeket tartalmaznak, amelyek minőségi szempontból eltérnek az informális digitális kommunikációban használt szövegtől. Ez az eltérés a legkorszerűbb NLP modellek teljesítményének súlyos romlásához vezetett, amikor a valós adatokat finomhangolják. A probléma megoldásának egyik módja a lexikális normalizáció, amely a nem szabványos szövegek, általában a közösségi médiából, egy szabványosabb formába alakítása. Ebben a munkában egy mondatszintű szekvencia-szekvencia modellt javasolunk mBART alapján, amely a problémát gépi fordítási problémának tekinti. Mivel a zajos szöveg átfogó problémát jelent az egész nyelven, nem csak az angol nyelven, az mBART többnyelvű előképzését kihasználva finomhangoljuk az adatainkhoz. Míg a jelenlegi megközelítések elsősorban szó- vagy alszószinten működnek, azzal érvelünk, hogy ez a megközelítés technikai szempontból egyszerű, és a meglévő előre képzett transzformátorhálózatokra épül. Eredményeink azt mutatják, hogy míg a szószintű, intrinsec, teljesítményértékelés más módszerek mögött áll, modellünk normalizálással javítja a teljesítményt a külső, downstream feladatok teljesítményét a nyers, feldolgozatlan, közösségi média szövegen működő modellekhez képest.</abstract_hu>
      <abstract_it>Le attività di benchmark attuali per l'elaborazione del linguaggio naturale contengono testo qualitativamente diverso dal testo utilizzato nella comunicazione digitale informale quotidiana. Questa discrepanza ha portato a un grave degrado delle prestazioni dei modelli NLP all'avanguardia quando perfezionati su dati reali. Un modo per risolvere questo problema è attraverso la normalizzazione lessicale, che è il processo di trasformazione del testo non standard, di solito dai social media, in una forma più standardizzata. In questo lavoro, proponiamo un modello sequenza-sequenza a livello di frase basato su mBART, che inquadra il problema come un problema di traduzione automatica. Poiché il testo rumoroso è un problema diffuso in tutte le lingue, non solo in inglese, sfruttiamo la pre-formazione multilingue di mBART per adattarlo ai nostri dati. Mentre gli approcci attuali operano principalmente a livello di parola o sottoparola, sosteniamo che questo approccio è semplice da un punto di vista tecnico e si basa sulle reti di trasformatori pre-addestrate esistenti. I nostri risultati mostrano che, mentre la valutazione delle prestazioni a livello di parola, intrinseca, è dietro ad altri metodi, il nostro modello migliora le prestazioni sulle attività estrinseche a valle attraverso la normalizzazione rispetto ai modelli che operano su testi grezzi e non elaborati sui social media.</abstract_it>
      <abstract_kk>Табиғи тілдерді өңдеу үшін назардағы кеңістік тапсырмаларында күнделікті цифрлық коммуникациясында қолданылатын мәтіннен кәдімгі түрлі емес мәтін бар. Бұл айырмашылығы шын әлемдегі деректерге жақсы түзету кезінде NLP моделдерінің күйінің әдістерін деградациялауына болады. Бұл мәселеді шешу үшін лексикалық нормализациясы арқылы, бұл - стандартты мәтінді емес, әдетте социалдық медиадан, стандартты түрлендіру процесі. Бұл жұмыс ішінде mBART негіздеген мәселеді машина аудару мәселесі ретінде фреймдеу үлгісін қолданамыз. Дыбыс мәтіні тілдерде, тек ағылшынша емес, біз мәтіні көп тілдерді алдын- ала оқыту үшін көптеген мәселелерді көптеген көптеген мәселелерді біздің деректерімізге түзетуге Қолданыстағы жағдайда сөз не ішкі сөздер деңгейінде жұмыс істейді, біз бұл жағдайды техникалық қадамдастырып, барлық алдындағы түрлендіру желінде құрылады деп айтып тұрамыз. Біздің нәтижелеріміз сөздер деңгейінде, ішкі деңгейінде, әрекеттерді бағалау басқа әдістердің артында болғанда, біздің үлгіміз сыртқы, төменгі тапсырмаларды нормализациялау арқылы, жазылмаған, жазылмаған</abstract_kk>
      <abstract_lt>Current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication.  Šis neatitikimas lėmė smarkų pažangiausių NLP modelių veiksmingumo pablogėjimą, kai jie buvo tiksliai pritaikyti realiojo pasaulio duomenimis. Vienas iš būdų išspręsti šį klausimą – per leksinę normalizaciją, t. y. nestandartinio teksto, paprastai iš socialinės žiniasklaidos, transformavimą į labiau standartizuotą form ą. In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem.  Kadangi triukšmingas tekstas yra plačiai paplitusi problem a įvairiose kalbose, ne tik anglų kalboje, mes naudojame daugiakalbį mBART išankstinį mokymą, kad jį suderintume su mūsų duomenimis. Nors dabartiniai metodai daugiausia veikia žodžių ar žodžių paviršiaus lygmeniu, mes teigiame, kad šis metodas yra paprastas techniniu požiūriu ir grindžiamas esamais iš anksto parengtais transformatorių tinklais. Mūsų rezultatai rodo, kad nors žodžių lygis, vidinis, rezultatų vertinimas yra už kitų metodų, mūsų model is gerina išorinių ir tolesnių užduočių rezultatus normalizuojant, palyginti su modeliais, veikiančiais žaliaviniu, neapdorotu socialinės žiniasklaidos tekstu.</abstract_lt>
      <abstract_ms>Tugas tanda rujukan semasa untuk pemprosesan bahasa semulajadi mengandungi teks yang berbeza kualitatif dari teks yang digunakan dalam komunikasi digital secara tidak formal. Kegagalan ini telah menyebabkan kegagalan prestasi yang berat bagi model NLP state-of-the-art apabila disesuaikan dengan baik pada data dunia nyata. Satu cara untuk menyelesaikan isu ini adalah melalui normalisasi leksikal, yang adalah proses untuk mengubah teks bukan piawai, biasanya dari media sosial, ke bentuk yang lebih piawai. Dalam kerja ini, kami cadangkan model urutan-tahap kalimat-ke-urutan berdasarkan mBART, yang bingkai masalah sebagai masalah terjemahan mesin. Sebagaimana teks bunyi adalah masalah yang luas di seluruh bahasa, bukan hanya bahasa Inggeris, kita menggunakan pralatihan berbilang bahasa mBART untuk menyesuaikannya kepada data kita. Sementara pendekatan semasa terutama beroperasi pada aras perkataan atau subkata, kita menyangka pendekatan ini adalah langsung dari sudut pandang teknikal dan membina pada rangkaian pengubah yang terdapat. Hasil kita menunjukkan bahawa sementara aras perkataan, intrinsik, penilaian prestasi berada di belakang kaedah lain, model kita meningkatkan prestasi pada tugas extrinsic, turun melalui normalisasi dibandingkan dengan model yang berfungsi pada teks media sosial mentah, tidak diproses.</abstract_ms>
      <abstract_mk>Сегашните задачи за референтни значки за природното обработување јазик содржат текст кој е квалитетно различен од текстот кој се користи во неформалната дигитална комуникација секој ден. Оваа дискрепанција доведе до сериозна деградација на резултатите на најсовремените модели на НЛП кога се поправија со податоци од реалниот свет. Еден начин да се реши ова прашање е преку лексикална нормализација, која е процесот на трансформација на нестандарден текст, обично од социјалните медиуми, во постандардизирана форма. Во оваа работа, предложуваме модел од реченица до реченица базиран на mBART, кој го рамка проблемот како проблем со машински превод. Бидејќи гласниот текст е первазивен проблем низ јазиците, не само англиски, ние го искористуваме мултијазичниот предобук на mBART за да ги прилагодиме на нашите податоци. Додека актуелните пристапи функционираат главно на зборово или подзборово ниво, тврдиме дека овој пристап е едноставен од техничка точка и се гради на постојните преобучени трансформаторски мрежи. Нашите резултати покажуваат дека додека проценката на резултатот на зборот, внатрешно, стои зад другите методи, нашиот модел ја подобрува резултатот на надворешните, понатамошни задачи преку нормализација во споредба со моделите кои функционираат на суров, непроцесиран, соци</abstract_mk>
      <abstract_ml>സ്വാഭാവ ഭാഷ പ്രക്രിയയ്ക്കുവേണ്ടി ഇപ്പോഴത്തെ ബെന്‍ച്മാര്‍ക്ക് ജോലികളില്‍ പദാവലിയുണ്ട്. അതില്‍ നിന്നും വ്യത്യസ്തമാ ഈ വ്യത്യാസം യഥാര്‍ത്ഥ ലോകത്തിലെ വിവരങ്ങളില്‍ നല്ല വിവരങ്ങള്‍ സൂക്ഷിച്ചിരിക്കുമ്പോള്‍ രാജ്യത്തിന്റെ സ്റ്റേറ്റ് ഡിഗ ഈ പ്രശ്നം തീരുമാനിക്കാന്‍ ഒരു വഴിയാണ് ലെക്സിക്സിക്കല്‍ സാധാരണ വാചകം മാറ്റുന്നത്. സാമൂഹ്യ മീഡിയില്‍ നിന്നും സാധാരണമായ ഒരു സാ ഈ പ്രവര്‍ത്തനത്തില്‍ നമ്മള്‍ ഒരു വാക്കിന്റെ നിലനില സെക്കന്‍സ് മോഡല്‍ ഉപദേശിക്കുന്നു. എംബാര്‍ട്ടി അടിസ്ഥാനമായി വാക്ക് നില്‍ക As the noisy text is a pervasive problem across languages, not just English, we leverage the multi-lingual pre-training of mBART to fine-tune it to our data.  ഇപ്പോഴത്തെ അടുത്തുവരുമ്പോള്‍ വാക്ക് അല്ലെങ്കില്‍ സബ്വോര്‍ഡ് നിലയിലോ പ്രവര്‍ത്തിക്കുമ്പോള്‍ നമ്മള്‍ തര്‍ക്കിക്കുന്നു, ഈ നടപടി നേരെയാ നമ്മുടെ ഫലങ്ങള്‍ കാണിച്ചുകൊണ്ടിരിക്കുന്നു വാക്ക് നില, ആദ്യപര്യവസാനം, പ്രകടന വിലാസവും മറ്റു രീതികള്‍ക്ക് പിന്നിലാകുമ്പോള്‍, നമ്മുടെ മോഡല്‍ പ്രകടനത്തിന്</abstract_ml>
      <abstract_no>Gjeldande benchmarkoppgåver for naturspråkshandtering inneheld tekst som er kvalitativ ulike frå teksten som vert brukt i informalt dag til dag digitalt kommunikasjon. Denne skilnaden har ført til vanskeleg forstørring av NLP-modeller i tilstanden til kunsten når det er fint oppsett på verdensdata. Ein måte å løysa dette problemet er gjennom leksisk normalisering, som er prosessen for å transformera ikkje-standard tekst, vanlegvis frå sosiale media, til ein mer standardisert form. I denne arbeida foreslår vi eit setningsnivå-sekvens-til-sekvensmodell basert på mBART, som rammer problemet som eit problem med maskinsomsetjing. Som lydteksten er eit vassrett problem på språk, ikkje bare engelsk, vil vi levera fleire språk føreøving av mBART for å finne det til data våre. Mens det gjeldande nærminga fungerer hovudsakelig på ordet eller underordnivået, argumenterer vi at denne tilnærminga er rett frå ein teknisk standpunkt og bygger på eksisterande føretrainerte transformeringsnettverk. Resultatet våre viser at mens ordnivået, intrinsisk, effektevaluering er bak andre metodar, vårt modell forbetrar utviklinga på ekstrinsic, nedstrømte oppgåver gjennom normalisering sammenlignet med modeller som fungerer på råd, ikkje-prosessert, sosiale mediatekst.</abstract_no>
      <abstract_pl>Obecne zadania referencyjne dotyczące przetwarzania języka naturalnego zawierają tekst, który różni się jakościowo od tekstu stosowanego w codziennej nieformalnej komunikacji cyfrowej. Ta rozbieżność doprowadziła do poważnej degradacji wydajności najnowocześniejszych modeli NLP, gdy są dostrojone na rzeczywistych danych. Jednym ze sposobów rozwiązania tego problemu jest normalizacja leksykalna, czyli proces przekształcania niestandardowego tekstu, zwykle z mediów społecznościowych, w bardziej standaryzowaną formę. W niniejszej pracy proponujemy model sekwencji na poziomie zdania oparty na mBART, który ramuje problem jako problem tłumaczenia maszynowego. Ponieważ głośny tekst jest powszechnym problemem we wszystkich językach, a nie tylko w języku angielskim, wykorzystujemy wielojęzyczne wstępne szkolenie mBART, aby dostosować go do naszych danych. Podczas gdy obecne podejścia działają głównie na poziomie słów lub podsłów, argumentujemy, że podejście to jest proste z technicznego punktu widzenia i opiera się na istniejących wstępnie przeszkolonych sieciach transformatorów. Nasze wyniki pokazują, że podczas gdy ocena wydajności na poziomie słowa, wewnętrzna, stoi za innymi metodami, nasz model poprawia wydajność w zadaniach zewnętrznych poprzez normalizację w porównaniu z modelami działającymi na surowym, nieprzetworzonym tekście mediów społecznościowych.</abstract_pl>
      <abstract_ro>Sarcinile curente de referință pentru procesarea limbajului natural conțin text care este calitativ diferit de textul utilizat în comunicarea digitală informală de zi cu zi. Această discrepanță a dus la degradarea severă a performanțelor modelelor de ultimă generație NLP atunci când sunt reglate fin pe date din lumea reală. O modalitate de a rezolva această problemă este prin normalizarea lexicală, care este procesul de transformare a textului nestandard, de obicei din social media, într-o formă mai standardizată. În această lucrare, propunem un model secvență-la-secvență la nivel de propoziție bazat pe mBART, care încadrează problema ca o problemă de traducere automată. Deoarece textul zgomotos este o problemă cuprinzătoare în toate limbile, nu doar în limba engleză, folosim pregătirea multilingvă a mBART pentru a-l regla fin la datele noastre. În timp ce abordările actuale funcționează în principal la nivelul cuvântului sau subcuvântului, susținem că această abordare este simplă din punct de vedere tehnic și se bazează pe rețelele existente pre-instruite de transformatoare. Rezultatele noastre arată că, în timp ce evaluarea performanței la nivel de cuvânt, intrinsec, se află în spatele altor metode, modelul nostru îmbunătățește performanța la sarcini extrinsice, în aval prin normalizare comparativ cu modelele care operează pe text brut, neprelucrat, social media.</abstract_ro>
      <abstract_mt>Il-kompiti attwali ta’ referenza għall-ipproċessar tal-lingwi naturali fihom test li huwa kwalitattivament differenti mit-test użat fil-komunikazzjoni diġitali informali kuljum. Din id-diskrepanza wasslet għal degradazzjoni qawwija tal-prestazzjoni tal-mudelli NLP l-aktar avvanzati meta aġġustati fuq dejta tad-dinja reali. Mod wieħed biex tiġi solvuta din il-kwistjoni huwa permezz tan-normalizzazzjoni lexikali, li huwa l-proċess tat-trasformazzjoni ta’ test mhux standard, normalment mill-midja soċjali, f’form a aktar standardizzata. F’dan ix-xogħol, qed nipproponu mudell ta’ sekwenza għal sekwenza fuq livell ta’ sentenza bbażat fuq mBART, li jfassal il-problem a bħala problema ta’ traduzzjoni bil-magna. Peress li t-test storbjuż huwa problem a mifruxa fil-lingwi kollha, mhux biss fl-Ingliż, a ħna nħeġġu t-taħriġ minn qabel multilingwi tal-mBART biex idaħħluha fid-dejta tagħna. Filwaqt li l-approċċi attwali joperaw prinċipalment fil-livell tal-kelma jew tas-subkelma, a ħna jargumentaw li dan l-approċċ huwa sempliċi mil-lat tekniku u jibni fuq netwerks eżistenti ta’ trasformaturi mħarrġa minn qabel. Ir-riżultati tagħna juru li filwaqt li l-evalwazzjoni tal-prestazzjoni fil-livell tal-kliem, intrinsika, hija wara metodi oħra, il-mudell tagħna jtejjeb il-prestazzjoni fuq kompiti esterni u downstream permezz tan-normalizzazzjoni meta mqabbel ma’ mudelli li joperaw fuq test mhux ipproċessat u mhux ipproċessat tal-midja soċjali.</abstract_mt>
      <abstract_si>ස්වභාවික භාෂාව ප්‍රක්‍රියාපනය සඳහා මුළින් බෙන්ච්මාර්ක් වැඩසටහන් වලට පාළුවන් තියෙනවා ඒ පාළුවන්  මේ විරුද්ධතාවක් ඇත්ත ලෝකයේ දත්තේ සඳහා සිද්ධ වෙන්න පුළුවන් නිර්මාණය කරලා තියෙනවා. මේ ප්‍රශ්නය විසඳන්න එක ප්‍රශ්නයක් ලෙක්සිකාලික සාමාන්‍ය විසඳන්න, ඒක තමයි සාමාන්‍ය විස්තර නොප්‍රශ්නය පාළුවක්  මේ වැඩේ අපි ප්‍රශ්නයක් පරිවර්තනය කරන්නේ mBART විසින් ප්‍රශ්නයක් ප්‍රශ්නයක් පරිවර්තනය කරනවා. භාෂාවක් විතරයි, ඉංග්‍රීසි විතරයි, අපි mBART ගේ විශාල භාෂාවක් ප්‍රශ්නයක් විතරයි, ඒක අපේ දත්ත සඳහා සැකසුම් කරන්න. ප්‍රතිදේශ වචනය නැත්තම් වචනය සබ්වර්ඩ් වචනයෙන් වැඩ කරන්න පුළුවන් විදිහට, අපි ප්‍රතික්ෂා කරනවා මේ විදිහට ප්‍රතික්‍රියාත්මක අපේ ප්‍රතිචාරය පෙන්වන්නේ වචන ස්ථානය, ඇතුළත් ස්ථානය, ප්‍රතිචාරය අනුවෙන් විදියට පස්සේ, අපේ මොඩේල් ප්‍රතිචාරය ප්‍රතිචාරය සඳහා ප්‍</abstract_si>
      <abstract_sr>Trenutni rezervni zadatak prirodnog jezika sadrži tekst koji je kvalitativno različit od teksta korištenog u neformalnoj dnevnoj digitalnoj komunikaciji. Ova nedostatka je dovela do teške degradacije učinkovitosti modela države umjetnosti NLP-a kada su dobro navedeni na podatke o stvarnom svijetu. Jedan način da riješimo ovaj problem je kroz leksičku normalizaciju, što je proces transformacije nestandardnog teksta, obično iz društvenih medija, u standardizovaniji oblik. U ovom poslu predlažemo model rečenice na nivou rečenica na sekvenci baziran na mBART-u, koji predlaže problem kao problem sa prevodom mašine. Pošto je zvuk tekst širok problem na jezicima, ne samo engleskom, uvećavamo višejezičku predobuku mBART-a da bi ga ispravili našim podacima. Dok trenutni pristupi uglavnom funkcionišu na razini reči ili podriječi, tvrdimo da je taj pristup jednostavan iz tehničkog stanja i izgradi na postojećim predobučenim transformacijskim mrežama. Naši rezultati pokazuju da, iako je razina riječi, unutrašnja, procjena provedbe iza drugih metoda, naš model poboljšava izvanredne funkcije na ekstrinskom, donjem zadatku kroz normalizaciju u usporedbi sa modelima koji rade na sirovom, neprocesovanom, tekstu socijalnih medija.</abstract_sr>
      <abstract_mn>Байгалийн хэл үйлдвэрлэлийн орчин үеийн банкмарк үйлдвэрлэлүүд нь өдөр тутам тоон холбоотой хэлбэрээр хэрэглэгддэг текстээс өөр байдаг. Энэ ялгаа нь үнэндээ дэлхийн өгөгдлийг тодорхойлох үед NLP урлагийн загварын үндсэн үйл ажиллагааны бууруулалттай болсон. Эдгээр асуудлыг шийдэх нэг арга нь лексикийн нормализацийг ашиглаж байна. Энэ бол стандарт биш текст, ихэвчлэн нийгмийн хэвлэлээс илүү стандарт хэлбэрт шилжүүлэх процесс юм. Энэ ажил дээр бид mBART-ын үндсэн өгүүлбэр-түвшинд дарааллын дарааллын загварыг санал болгож байна. Энэ асуудлыг машин орчуулах асуудлын хэлбэрээр дүрслэж байна. Үнэндээ чимээгүй текст нь хэл, англи хэл биш л дээ. МБАРТын олон хэлний өмнө сургалтыг бидний мэдээллийг сайжруулахын тулд ашиглаж байна. Харин одоогийн ойлголтын тухай ихэнхдээ үг эсвэл суурь үг хэмжээнд ажиллаж байгаа ч бид энэ ойлголтыг техник хэмжээнээс шууд бий болгож, сургалтын өмнө сургалтын шилжүүлэгчийн сүлжээнд бүтээж байгаа Бидний үр дүнд үг хэмжээний түвшинд, интринзийн, үйл ажиллагааны үнэлгээ бусад арга замын ард байхад бидний загвар нь гадаадын, доорх үйл ажиллагааны үйл ажиллагааг нормализацийн арга хэмжээнд сайжруулж, хэрэггүй, нийгмийн ме</abstract_mn>
      <abstract_so>Shaqooyinka ku baaraandegista afka asalka ah waxaa ku jira qoraal aad u kala duwan karto qoraalka la isticmaalayo macluumaadka rasmiga ah maanta la xiriira digital. Takooristan waxay sababtay hoos u dhigista sameynta dowladda-sanadda ee NLP-da, marka lagu sameynayo macluumaadka arimaha caalamiga ah. Sida caadiga ah ayaa loo kala beddelaa macluumaadka bulshada si caadiga ah loo beddelo qoraal aan caadi aheyn, sida caadiga ah waxay uga bedelaan macluumaad bulshada oo u bedelaan foom ka mid ah mid ka mid ah. Markaas waxan, waxaynu soo jeedaynaa qaab imtixaan ah oo ku saleysan mBART, kaas oo dhibaatada ka dhigaya dhibaato turjumid machine ah. Sida uu qoraalka codku yahay dhibaato badan oo luuqadaha kala duduwan, ma aha ingiriiska oo keliya, waxaynu u dirnaa waxbarashada hore oo afka kala duduwan oo MBART si aan u hagaajinno macluumaadkayaga. Inta aad u soo dhowaato hadalka ama heerka hoos-hadalka, waxaynu ka fekeraynaa in dhaqdhaqaaqyadan si toos ah uga yimaado barta teknolojiga oo uu dhiso shabakado horay u tababariday. Abaalkayaga waxay muuqataa in marka qiimeynta waxyaabaha ku qoran, waxyaabaha hoos-dhexe, waxyaabaha lagu qiimeeyo waxyaabaha kale, modellkayaga ayaa bedesha tababar ka saara jardiinada dibadda ah, hawlaha hoosteeda lagu sameeyo si caadi ah, isbarbarbarbardhiga samooyinka ku shaqeeya sawir, aan lagu baaraandegayn, qorniinka macluumaadka bulshada.</abstract_so>
      <abstract_sv>Nuvarande referensuppgifter för bearbetning av naturligt språk innehåller text som kvalitativt skiljer sig från den text som används i informell daglig digital kommunikation. Denna avvikelse har lett till allvarlig försämring av prestanda av de senaste NLP-modellerna när de finjusteras på verkliga data. Ett sätt att lösa detta problem är genom lexikal normalisering, vilket är processen att omvandla icke-standardiserad text, vanligtvis från sociala medier, till en mer standardiserad form. I detta arbete föreslår vi en mening-nivå sekvens-till-sekvens modell baserad på mBART, som ramar in problemet som ett maskinöversättningsproblem. Eftersom den bullriga texten är ett genomgripande problem över språk, inte bara engelska, utnyttjar vi den flerspråkiga förkortningen av mBART för att finjustera den till våra data. Medan nuvarande tillvägagångssätt huvudsakligen fungerar på ord- eller underordsnivå, hävdar vi att detta tillvägagångssätt är okomplicerat ur ett tekniskt perspektiv och bygger på befintliga förkunskaperade transformatornätverk. Våra resultat visar att även om ordnivå, inneboende, prestandautvärdering ligger bakom andra metoder, förbättrar vår modell prestanda på yttre, nedströms uppgifter genom normalisering jämfört med modeller som arbetar på obehandlad, social media text.</abstract_sv>
      <abstract_ur>طبیعی زبان پردازش کے لئے اوسنی بنچم مارک کے کاموں میں متن لکھ رہے ہیں جو روزہ کے دن ڈیجیٹل کی ارتباط سے استعمال کیا جاتا ہے۔ یہ اختلاف ہے کہ جب واقعی دنیا کے ڈاٹوں پر مضبوط طریقے سے کامیابی کی حالت کی NLP موڈل کی دھوکا ہوئی ہے۔ اس مسئلہ کو حل کرنے کے لئے ایک طریقہ ہے لکسیکل عاملی کے ذریعہ، جو غیر استاندارڈ کے متن کو تبدیل کرنے کی پروسس ہے، معمولاً سوسیل میڈیا سے، اور زیادہ استاندارڈ کے فرم میں۔ اس کام میں ہم ایک جماعت سطح-سطح-سطح-سطح-سطح-سطح-سطح-سطح موڈل کی پیشنهاد کرتے ہیں mBART پر بنیاد، جس نے مسئلہ کو ماشین ترجمہ مسئلہ کے طور پر فرم کرتا ہے. جیسے آواز کی پیغام زبانوں میں ایک گھیری مشکل ہے، نہیں صرف انگلیسی، ہم نے mBART کی بہت سی زبان کی پیش آموزش کے لئے اس کو ہماری دادات کے ساتھ ٹھیک ٹھیک ٹھیک کر دکھائے۔ حاﻻنکہ موجود نزدیک کلمات یا زیر کلمات سطح پر کام کرتی ہے، ہم جھگڑتے ہیں کہ یہ تقریبا ایک تکنیکی استاندارپوینٹ سے مستقیم ہے اور موجود پیش آموزش کی تغییر نیٹورک پر بناتا ہے. ہمارے نتیجے دکھاتے ہیں کہ جب کلمات سطح، داخل سطح، فعالیت کا ارزش دوسرے طریقوں کے پیچھے ہے، ہماری مدل بغیری طریقوں کے ذریعہ، نارومیزی کے ذریعہ، نارومیزی کے ذریعہ، بغیر تحریک، سوسیل میڈیا متکس پر عمل کرنے والے نمڈلو</abstract_ur>
      <abstract_ta>இயல்பான மொழி செயல்பாட்டிற்கான தற்போதைய benchmark பணிகள் உள்ள உரையில் உள்ளது அது சரியாக வடிவமைக்கப்பட்ட உரையில் இருந்து இன்று தொடர் இந்த வேறுபாடு உண்மையான உலக தகவல்களில் சரியான மாதிரி நிலையின் நிலையில் உள்ள NLP மாதிரிகளின் குறைப்பு கொண்டுள்ளது. இந்த பிரச்சினையை தீர்க்க ஒரு வழி லெக்சிக்சியல் இயல்பாக்கத்தில் உள்ளது, அது நிலையான உரையை வழக்கமாக, சமூக ஊடகங்களிலிருந்து மாற்ற இந்த வேலையில், நாம் MBART அடிப்படையில் ஒரு வாக்கி- மட்டத்தின் வரிசை மாதிரியை பரிந்துரைக்கிறோம். அது பிரச்சனையை இயந்திர மொழ சப்தம் உரை என்பது மொழிகள் முழுவதும் பிரச்சனையாக இருக்கும் போது, ஆங்கிலத்தை மட்டும் அல்ல, நாம் MBART முன் பல மொழிகளின் முன் பயிற்சி ம While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks.  எங்கள் முடிவுகள் வார்த்தை மட்டத்தில், உள்ளடக்கம், செயல்பாடு மதிப்பு மற்ற முறைமைகளின் பின்னால், எங்கள் மாதிரி வெளியீட்டில் செயல்பாடு மாதிரி செயல்களை மேம்படுத</abstract_ta>
      <abstract_uz>Name Bu disklik haqiqiqiy dunyo maʼlumotlari bilan yaxshi bo'lganda, NLP modellarining holati holatini taqdimlashtirishga sabab beradi. Bu muammoga boshqarish uchun bir usul leksikal normalisiyatsiya orqali, bu oddiy sohalar media bilan andoza matnni o'zgartirish jarayonini ko'paytirish mumkin. Bu ishda, biz mBART asosida bir so'zlar darajasi seksiz modelini tahrirlash mumkin. Bu muammolarni maskin tarjima muammosi deb ataymiz. Tovushlar matni faqat ingliz tilida juda katta muammo emas, biz mBART uchun bir necha tillar o'rganishni bir necha tildan oldin o'rganish uchun buni ma'lumotlarga yaxshi ko'proq tizimga qo'llayapmiz. Joriy soʻz yoki tub soʻz darajada ishlab chiqarishda, biz murakkab qilamiz, bu usulni teknologiya istagan holatdan aniqlanamiz va mavjud vaqtdan oldin o'zgartirish tarmoqlarida ishlaydi. Our results show that while word-level, intrinsic, performance evaluation is behind other methods, our model improves performance on extrinsic, downstream tasks through normalization compared to models operating on raw, unprocessed, social media text.</abstract_uz>
      <abstract_vi>Tài liệu tiêu chuẩn hiện thời cho việc xử lý ngôn ngữ tự nhiên chứa văn bản hoàn to àn khác với văn bản được dùng trong giao tiếp kĩ thuật số. Sự khác biệt này đã dẫn đến một độ thoái hoá nghiêm trọng trong các mô hình đỉnh cao nhất. Một cách để giải quyết vấn đề này là thông qua chế độ hóa học, đó là quá trình biến văn bản không tiêu chuẩn, thường từ các phương tiện xã hội, thành một hình thức tiêu hóa hơn. Trong công việc này, chúng tôi đề nghị một kiểu lặp lại từng chữ dựa trên m BART, để cho vấn đề được xếp thành vấn đề dịch cỗ máy. Vì văn bản ồn ào là một vấn đề cấp bách trong các ngôn ngữ, không chỉ tiếng Anh, chúng tôi dùng việc huấn luyện đa ngôn ngữ trước khi tôi dán nó vào dữ liệu của chúng tôi. Trong khi các phương pháp hiện tại chủ yếu hoạt động ở mức chữ hay chữ con, chúng tôi cho rằng phương pháp này đơn giản từ một góc độ kỹ thuật và dựa trên các mạng máy biến hình được đào tạo trước. Những kết quả của chúng tôi cho thấy, mặc dù từ cấp độ cơ bản, khả năng đánh giá hiệu quả ẩn đằng sau các phương pháp khác, nhưng mẫu của chúng tôi tăng hiệu quả trên các công trình phụ theo dòng chảy, thông thường hơn các mô hình hoạt động trên văn bản nguyên tử, không sửa đổi.</abstract_vi>
      <abstract_nl>Huidige benchmarktaken voor de verwerking van natuurlijke taal bevatten tekst die kwalitatief verschilt van de tekst die wordt gebruikt in informele dagelijkse digitale communicatie. Deze discrepantie heeft geleid tot een ernstige verslechtering van de prestaties van state-of-the-art NLP-modellen wanneer verfijnd op real-world data. Een manier om dit probleem op te lossen is door lexicale normalisatie, dat is het proces van het transformeren van niet-standaard tekst, meestal van sociale media, in een meer gestandaardiseerde vorm. In dit werk stellen we een sequence-to-sequence model voor gebaseerd op mBART, dat het probleem kadert als een machinaal vertaalprobleem. Omdat de luidruchtige tekst een alomtegenwoordig probleem is in alle talen, niet alleen in het Engels, maken we gebruik van de meertalige pre-training van mBART om deze af te stemmen op onze gegevens. Hoewel de huidige benaderingen voornamelijk werken op woord- of subwoordniveau, stellen wij dat deze aanpak vanuit technisch oogpunt eenvoudig is en voortbouwt op bestaande voorgetrainde transformatornetwerken. Onze resultaten tonen aan dat hoewel woordniveau, intrinsieke, prestatieevaluatie achter andere methoden ligt, ons model prestaties verbetert op extrinsieke, downstream taken door normalisatie in vergelijking met modellen die werken op ruwe, onbewerkte, sociale media tekst.</abstract_nl>
      <abstract_da>Nuværende benchmark-opgaver til behandling af naturligt sprog indeholder tekst, der er kvalitativt forskellig fra den tekst, der anvendes i uformel dag til dag digital kommunikation. Denne uoverensstemmelse har ført til alvorlig ydeevne nedbrydning af state-of-the-art NLP modeller, når finjusteret på virkelige data. En måde at løse dette problem på er gennem leksikalsk normalisering, som er processen med at omdanne ikke-standard tekst, normalt fra sociale medier, til en mere standardiseret form. I dette arbejde foreslår vi en sætning-niveau sekvens-til-sekvens model baseret på mBART, som indrammer problemet som et maskinoversættelsesproblem. Da den støjende tekst er et gennemtrængende problem på tværs af sprog, ikke kun engelsk, udnytter vi den flersprogede foruddannelse af mBART til at finjustere den til vores data. Mens de nuværende tilgange primært opererer på ord- eller underordsniveau, hævder vi, at denne tilgang er ligetil fra et teknisk synspunkt og bygger på eksisterende forududdannede transformatornetværk. Vores resultater viser, at mens ordniveau, iboende, præstationsevaluering ligger bag andre metoder, forbedrer vores model ydeevnen på eksterne, downstream opgaver gennem normalisering sammenlignet med modeller, der opererer på rå, uforarbejdet tekst på sociale medier.</abstract_da>
      <abstract_bg>Текущите еталонни задачи за обработка на естествен език съдържат текст, който е качествено различен от текста, използван в неформалната ежедневна дигитална комуникация. Това несъответствие е довело до сериозно влошаване на производителността на най-съвременните модели на НЛП при фина настройка на данни от реалния свят. Един от начините за решаване на този проблем е чрез лексикално нормализиране, което е процесът на трансформиране на нестандартен текст, обикновено от социалните медии, в по-стандартизирана форма. В тази работа предлагаме модел на ниво изречение последователност към последователност, базиран на който рамкира проблема като проблем с машинен превод. Тъй като шумният текст е широко разпространен проблем на езиците, а не само на английски, ние използваме многоезичното предварително обучение на МБАРТ, за да го настроим фино към нашите данни. Докато настоящите подходи работят главно на ниво дума или поддума, ние твърдим, че този подход е прост от техническа гледна точка и се основава на съществуващи предварително обучени трансформаторни мрежи. Нашите резултати показват, че докато оценката на производителността на ниво думи стои зад други методи, нашият модел подобрява производителността при външни задачи надолу по веригата чрез нормализиране в сравнение с модели, работещи върху суров, непреработен, социален текст.</abstract_bg>
      <abstract_hr>Trenutni rezervni zadatak prirodnog obradivanja jezika sadrži tekst koji je kvalitetno različit od teksta korištenog u neformalnoj dnevnoj digitalnoj komunikaciji. Ova nedostatka dovela je do teške degradacije učinkovitosti modela stanja umjetnosti NLP-a kada su dobro određeni podacima o stvarnom svijetu. Jedan način rješavanja ovog pitanja je kroz leksičku normalizaciju, što je proces transformacije ne standardnog teksta, obično iz društvenih medija, u standardiziraniji oblik. U ovom poslu predlažemo model rečenica na razini rečenica na sekvenciji temeljni na mBART-u, koji okvira problem kao problem prevoda strojeva. Budući da je zvuk tekst širok problem na jezicima, ne samo engleskom, upotrebljavamo višejezičku predobuku mBART-a kako bi ga ispravili našim podacima. Iako trenutni pristupi uglavnom djeluju na razini riječi ili podriječi, tvrdimo da je taj pristup jednostavan iz tehničkog stanja i izgrađuje na postojećim predobučenim transformacijskim mrežama. Naši rezultati pokazuju da, iako je razina riječi, unutrašnja, procjena učinkovitosti iza drugih metoda, naš model poboljšava učinkovitost na ekstrinskim, donjim zadacima kroz normalizaciju u usporedbi s modelima koji rade na sirovom, neprocijeđenom, tekstu socijalnih medija.</abstract_hr>
      <abstract_id>Tugas benchmark saat ini untuk proses bahasa alami mengandung teks yang berbeda kualitatif dari teks yang digunakan dalam komunikasi digital informal sehari-hari. Kegagalan ini telah menyebabkan degradasi prestasi yang berat dari model NLP state-of-the-art ketika disesuaikan dengan data dunia nyata. Salah satu cara untuk menyelesaikan masalah ini adalah melalui normalisasi leksikal, yang adalah proses untuk mengubah teks bukan standar, biasanya dari media sosial, menjadi bentuk yang lebih standar. Dalam pekerjaan ini, kami mengusulkan model urutan-tahap kalimat-ke-urutan berdasarkan mBART, yang membentuk masalah sebagai masalah terjemahan mesin. Sebagai teks suara adalah masalah yang menyebar di berbagai bahasa, bukan hanya bahasa Inggris, kita menggunakan prapelatihan multibahasa mBART untuk memperbaikinya dengan data kita. Sementara pendekatan saat ini terutama beroperasi di tingkat kata atau kata bawah kata, kita berdebat bahwa pendekatan ini langsung dari sudut pandang teknis dan membangun pada jaringan transformer yang ada yang terlatih sebelumnya. Hasil kami menunjukkan bahwa sementara tingkat kata, intrinsik, evaluasi prestasi berada di belakang metode lain, model kami meningkatkan prestasi pada tugas ekstrinsik, turun melalui normalisasi dibandingkan dengan model yang beroperasi pada teks media sosial yang mentah, tidak proses.</abstract_id>
      <abstract_ko>현재 자연 언어 처리의 기준 임무는 비공식적인 일상 디지털 통신에서 사용하는 텍스트와 성질이 다른 텍스트를 포함한다.실제 데이터를 미세하게 조정할 때, 이러한 차이로 인해 가장 선진적인 NLP 모델의 성능이 심각하게 떨어진다.이 문제를 해결하는 방법의 하나는 어휘를 규범화하는 것이다. 이것은 비표준 텍스트(보통 소셜 미디어에서 온 것)를 더욱 표준적인 형식으로 전환하는 과정이다.이 작업에서 우리는 mBART의 문장급 서열을 바탕으로 서열 모델을 제시했는데 이 모델은 문제를 기계 번역 문제로 정의했다.시끄러운 텍스트는 영어뿐만 아니라 크로스 언어의 보편적인 문제이기 때문에 우리는 mBART의 다중 언어 예훈련을 이용하여 이를 미세하게 조정하여 우리의 데이터에 적응하도록 한다.현재의 방법은 주로 단어나 하위 단어의 단계에서 조작되고 있지만 기술적인 측면에서 볼 때 이런 방법은 직접적이고 기존의 사전 교육을 받은 변압기 네트워크를 바탕으로 세워진 것이라고 본다.우리의 연구 결과에 따르면 단어급, 내재적인 실적 평가는 다른 방법보다 뒤떨어지지만 우리의 모델은 원시적이고 처리되지 않은 소셜 미디어 텍스트에서 실행되는 모델이 아니라 외부, 하위 임무의 실적을 규범화함으로써 향상시켰다.</abstract_ko>
      <abstract_fa>وظیفه‌های صندوق فعلی برای پرداخت زبان طبیعی متن را دارد که با کیفیت متفاوت از متن استفاده می‌شود در روز رسمی به روز ارتباط دیجیتال متفاوت است. این اختلاف باعث افزایش عملکرد سخت از مدل های NLP ایالت هنری است وقتی به داده های دنیای واقعی تنظیم شده است. یک راهی برای حل این مسئله از طریق عادت زبانی است که فرایند تغییر متن غیر استاندارد است، معمولاً از رسانه‌های اجتماعی به یک فرم استاندارد‌تری است. در این کار، ما یک مدل طبقه‌ای از جمله‌ها بر اساس mBART پیشنهاد می‌کنیم که مشکل را به عنوان یک مشکل ترجمه ماشین می‌سازد. همانطور که متن صوتی یک مشکل گسترده در زبان است، نه تنها انگلیسی، ما پیش آموزش چندین زبان mBART را برای تغییر دادن آن به داده‌هایمان استفاده می‌کنیم. در حالی که نزدیک‌های فعلی بیشتر در سطح کلمه یا زیر کلمه عملکرد می‌کنیم، بحث می‌کنیم که این روش از یک نقطه فنی مستقیم است و روی شبکه‌های تغییر‌پذیر پیش آموزش شده است. نتیجه‌هایمان نشان می‌دهند که در حالی که ارزیابی کلمات، داخلی، ارزیابی عملکرد پشت روش‌های دیگر است، مدل ما عملکرد‌های خارجی، عملکرد‌های پایین‌ترین را با توجه به مدل‌های عملکرد روی متن رسانه‌های جامعه‌ای خارجی، بی‌پرواز، به مق</abstract_fa>
      <abstract_sw>Current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication.  Utofauti huu umesababisha udhalilishaji mkubwa wa utendaji wa hali ya aina ya sanaa ya NLP pale ambapo unaonyesha vizuri kwenye takwimu halisi za dunia. Njia moja ya kutatua suala hili ni kupitia utaratibu wa hali ya kawaida, ambayo ni mchakato wa kubadilisha maandishi yasiyo ya kawaida, kwa kawaida kutoka kwenye mitandao ya kijamii, katika mfumo wa kawaida zaidi. Katika kazi hii, tunapendekeza modeli ya mfululizo wa kiwango cha sentence kwa mfululizo unaofanywa na mBART, ambayo inaleta tatizo kama tatizo la kutafsiri mashine. Kama maandishi ya kelele ni tatizo kubwa sana katika lugha mbalimbali, sio tu Kiingereza, tunatumia mafunzo ya lugha mbalimbali ya mBART ili kuitunza takwimu zetu. Wakati ambapo hatua za sasa zinaingia kwa ujumla au maneno ya chini, tunahoji kuwa mbinu hii ni moja kwa moja kutoka kwenye vituo vya kiufundi na inajenga kwenye mitandao ya mabadiliko ya awali. Matokeo yetu yanaonyesha kuwa wakati uangalizi wa maneno, wa ndani, utafiti wa utendaji umebaki katika njia nyingine, mwelekeo wetu umeboresha ufanisi wa kazi za nje, mito ya chini kwa njia ya kawaida ukilinganishwa na mifano yanayofanya kazi za kawaida, bila kuchukuliwa, ujumbe wa mitandao ya kijamii.</abstract_sw>
      <abstract_de>Aktuelle Benchmark-Aufgaben für die Verarbeitung natürlicher Sprache enthalten Text, der sich qualitativ von dem Text unterscheidet, der in der informellen täglichen digitalen Kommunikation verwendet wird. Diese Diskrepanz hat zu erheblichen Leistungseinbußen moderner NLP-Modelle geführt, wenn sie auf realen Daten fein abgestimmt sind. Eine Möglichkeit, dieses Problem zu lösen, ist die lexikalische Normalisierung, d.h. der Prozess der Umwandlung von nicht standardisierten Texten, normalerweise aus sozialen Medien, in eine standardisierte Form. In dieser Arbeit schlagen wir ein auf mBART basierendes Sequenzmodell vor, das das Problem als maschinelles Übersetzungsproblem umrahmt. Da der laute Text ein allgemeines Problem in allen Sprachen ist, nicht nur in Englisch, nutzen wir das mehrsprachige Vortraining von mBART, um ihn auf unsere Daten abzustimmen. Während aktuelle Ansätze hauptsächlich auf Wort- oder Unterwortebene funktionieren, argumentieren wir, dass dieser Ansatz technisch einfach ist und auf bestehenden vortrainierten Transformatorennetzen aufbaut. Unsere Ergebnisse zeigen, dass, während Wortebene, intrinsische, Leistungsbewertung hinter anderen Methoden steht, unser Modell die Leistung bei extrinsischen, nachgelagerten Aufgaben durch Normalisierung verbessert, im Vergleich zu Modellen, die auf rohem, unverarbeitetem Social-Media-Text arbeiten.</abstract_de>
      <abstract_tr>Natal dil işlemek üçin häzirki benchmark görerleri metin edip görkezilýän metin diýip görkezilýän resmi günlerde digital komunikaçylardan ullanylýar. Bu çykyşyk Gerçek dünýä maglumaty üstünde düzelenýän wagtyň durumyny NLP nusgalarynyň çykarmagyna ýok edip ýöredi. Bu meseläni çözmek üçin bir ýoly, lektik normalizasyondan geçirilýän işleýän, adatça sosyal medýdanlardan daha standart bir şekilde üýtgetmekdir. Bu işde, mBART'a dayanan bir sözlem düzeyde-terjime modelini teklip edip, meseleniň maşynyň terjime meselesi ýaly çykarýar. Sesli metin dillerde örän wajyp mesele däl, diňe iňlisçe däl, biz mBART-yň birnäçe dil öňünden öňünden okuwçysyny bermek üçin üýtgedýäris. Häzirki ýakynlaşyk esasy sözler ýa-da alt sözler derejesinde işleýändir diýip pikir edýäris, bu ýakynlaşyk tekniki durumdan düzgün we bar öň-okuwçy transformer şebeklerde inşa edýär. Netijelerimiz kelime derejesi, iç daňky, eserleşmeler çykyşynyň arkasynda bolan ýagdaýyny görkezýär. Modelimiz çyzgyly, süýji we işlemsiz, sosial mediýa metinlerinde işlenýän modelleriň ýagdaýynda gowurar.</abstract_tr>
      <abstract_am>የአሁኑን ፋይል አስቀምጥ ይህ ጥያቄ የዓለም አካባቢ ዳታዎችን በመጠቀም ጊዜ የNLP ዓይነቶች የሥልጣን አካባቢ አካባቢ አዋቂ አዳራሽ አዋቂ አዋቂ ነው፡፡ ይህንን ጉዳይ ለመፈጸም አንድ መንገድ የሌክሲካዊ ድምፅ ነው፡፡ ይህም የተመሳሳይ ጽሑፎችን ከማኅበራዊ ሚዲያ ወደሚለወጥ በተለየ የተመሳሳይ ፎርማት ነው፡፡ In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem.  የድምፅ ጽሑፉ በቋንቋዎች ሁሉ ላይ የተለየ ጉዳይ ነው፣ እንግሊዘኛ ብቻ አይደለም፣ mBART ለዳራዎቻችን ለብዙዎች ቋንቋዎች ማስጠንቀቂያውን እናስጠጋለን፡፡ አሁን ወደ ቃላት ወይም ወደ ደብዳቤ ቃላት በመስጠት ሲደርስ፣ ይህች ሥርዓት ከቴክክክሎጂ ቦታ ቀጥተኛ ነው እና በተገኘው ቀድሞ ተማሪ ለውጥ መረብ ላይ ይሠራል ብለን እንከራከርለን፡፡ ፍሬዎቻችን የቃላት ደረጃ፣ ውጤት፣ የሥርዓት ማስታወቂያ ከሌሎች ደረጃዎች በኋላ ነው፣ ሞዴላያችን በአውራጭ፣ የመድረክ ሥርዓት በማድረግ እና ማኅበራዊ ሚዲያ ጽሑፎችን በመተካከል በሚያስተካክሉ ምሳሌዎችን ያሳድጋል፡፡</abstract_am>
      <abstract_sq>Detyrat e tanishme të referimit për procesimin natyror të gjuhës përmbajnë tekst që është cilësisht i ndryshëm nga teksti i përdorur në komunikimin dixhital të ditës jozyrtare. Ky mospërputhje ka shpjerë në degradim të rëndë të performancës së modeleve NLP më të lartë kur janë rregulluar në të dhënat e botës reale. Një mënyrë për të zgjidhur këtë çështje është nëpërmjet normalizimit lexik, i cili është procesi i transformimit të tekstit jo-standard, zakonisht nga media sociale, në një form ë më të standardizuar. Në këtë punë, ne propozojmë një model sekuencë-në-sekuencë të nivelit të fjalëve bazuar në mBART, i cili e kornizon problemin si një problem përkthimi automatik. Teksti i zhurmshëm është një problem i përhapur nëpër gjuhë, jo vetëm në anglisht, ne përdorim parastërvitjen shumëgjuhëse të mBART për t'i përshtatur a to me të dhënat tona. Ndërsa qasjet aktuale funksionojnë kryesisht në nivelin e fjalës apo nënfjalës, ne argumentojmë se kjo qasje është e thjeshtë nga një pikëpamje teknike dhe ndërtohet në rrjetet ekzistuese të transformuesve të paratrajnuar. Rezultatet tona tregojnë se ndërsa vlerësimi i nivelit të fjalës, i brendshëm, i performancës është pas metodave të tjera, modeli ynë përmirëson performancën në detyrat e jashtme dhe të poshtme nëpërmjet normalizimit krahasuar me modelet që funksionojnë në tekst të papërpunuar të medias sociale.</abstract_sq>
      <abstract_af>Huidige benchmarktaak vir natuurlike taal verwerking bevat teks wat kwaliteit verskillend is van die teks wat gebruik word in onformele dag tot dag digitale kommunikasie. Hierdie verskilligheid het gedoen tot swaar effektuurdigheid van staat-van-die-kunstenaar NLP modele wanneer fyn-toestel op reël-wêreld data. Een manier om hierdie probleem te oplos is deur leksiese normalisering, wat is die proses om nie-standaard teks te transformeer, gewoonlik van sosiale media, na 'n meer standaard vorm. In hierdie werk voorstel ons 'n sentence-level sequence-to-sequence model gebaseer op mBART, wat raam die probleem as 'n masjien vertaling probleem. Omdat die geluide teks 'n verskeidige probleem is oor tale, nie net Engels nie, het ons die multi-tale voor-oerwinning van mBART aangebring om dit te fyn-doen na ons data. Terwyl huidige toegang nader op die woord of subwoord vlak werk, argumenteer ons dat hierdie toegang gereed is vanaf 'n tegniese standpunt en bou op bestaande vooraf-opgelei transformeernetwerke. Ons resultate wys dat terwyl woord-vlak, intrinsiese, prestasieevaluering agter ander metodes is, ons model verbeter prestasie op extrinsic, onderstreem opdragte deur normalisering te vergelyk met modele wat op rou, onverwerking, sosiale media teks werk.</abstract_af>
      <abstract_bs>Trenutni rezervni zadatak prirodnog jezika sadrži tekst koji je kvalitetno različit od teksta korištenog u neformalnoj dnevnoj digitalnoj komunikaciji. Ova neslaganost dovela je do teške degradacije učinkovitosti modela države umjetnosti NLP-a kada su dobro određeni podacima o stvarnom svijetu. Jedan način za rješavanje ovog pitanja je kroz leksičku normalizaciju, što je proces transformacije nestandardnog teksta, obično iz društvenih medija, u standardiziraniji oblik. U ovom poslu predlažemo model rečenica na razini rečenica na sekvenciji baziran na mBART-u, koji okvira problem kao problem sa prevodom mašine. Budući da je bukni tekst širok problem na jezicima, ne samo engleskom, koristimo višejezičku predobuku mBART-a kako bi ga ispravili našim podacima. Dok trenutni pristupi uglavnom funkcionišu na razini riječi ili podriječi, tvrdimo da je taj pristup jednostavan iz tehničkog stanja i izgrađuje na postojećim predobučenim transformacijskim mrežama. Naši rezultati pokazuju da, iako je razina riječi, unutrašnja, procjena učinkovitosti iza drugih metoda, naš model poboljšava učinkovitost na ekstrinskom, donjem zadatku kroz normalizaciju u usporedbi s modelima koji rade na sirovom, neprocijeđenom, tekstu socijalnih medija.</abstract_bs>
      <abstract_hy>Բնական լեզվի վերամշակման ներկայիս համեմատական գործառույթները պարունակում են տեքստ, որը որականորեն տարբերվում է ոչ տեղեկատվական օրական թվային հաղորդակցման տեքստից: Այս անհամապատասխանությունը հանգեցրեց ամենաբարձր ՆԼՊ մոդելների արդյունավետության խիստ դեգրադացիայի, երբ դրանք բարձրացվել են իրական աշխարհի տվյալների վրա: Այս խնդիրը լուծելու մի միջոց է լեքսիկական նորմալիզացիայի միջոցով, որը ոչ ստանդարտ տեքստի փոխակերպման գործընթացն է, սովորաբար սոցիալական լրատվամիջոցներից, ավելի ստանդարտ ձևի: In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem.  Քանի որ աղմկոտ տեքստը տարածական խնդիր է լեզուների, ոչ միայն անգլերենի միջև, մենք օգտագործում ենք mBAR-ի բազմալեզու նախապատրաստման գործընթացը, որպեսզի այն կարելի է հարմարեցնել մեր տվյալներին: Մինչդեռ ներկայիս մոտեցումները հիմնականում գործում են բառերի կամ ենթաբառերի մակարդակում, մենք պնդում ենք, որ այս մոտեցումը հեշտ է տեխնիկական տեսանկյունից և հիմնված է գոյություն ունեցող նախապատրաստված վերափոխողների ցանցերի վրա: Մեր արդյունքները ցույց են տալիս, որ մինչդեռ բառի մակարդակը, ներքին, արդյունավետության գնահատումը մյուս մեթոդների ետևում է, մեր մոդելը բարելավում է արտաքին, ներքևի գործողությունների արդյունավետությունը նորմալիզացիայի միջոցով, համեմատած ոչ մշակված, սոցի</abstract_hy>
      <abstract_az>Təbiətli dil işləməsi üçün növbənöv benchmark işləri təbiətli günlərdə dijital iletişimi ilə istifadə edilən mətndən müxtəlif bir mətn içindədir. Bu müxtəlif həqiqət dünya məlumatlarını təmizlədiyi zaman NLP modellərin şiddətli performans düşürməsinə səbəb oldu. Bu məsələni çəkmək üçün bir yol leksik normalizasyon vasitəsindədir. Bu, standart olmayan metin, genellikle sosyal media vasitəsindən daha standardizlənmiş bir formaya çevirmək prosesidir. Bu işdə, mBART tabanlı cümlələr-səviyyədə-səviyyədə-səviyyədə-səviyyədə modeli təklif edirik. Bu problemi maşın çeviriş problemi olaraq çevirir. Sesli metin dillərdə çox geniş bir problemdir, ancaq İngilizce deyil, biz mBART'nin çoxlu dil əvvəl təhsil edilməsini məlumatlarımıza düzəltmək üçün istifadə edirik. Hazırkı yaxınlıqlar çox sözlərdə və ya alt sözlərdə işlədikləri halda, bu yaxınlıq tekniki tərzindən düzgün olduğunu iddia edirik və əvvəlcə təhsil edilmiş transformer a ğlarında inşa edir. Sonuçlarımız belə göstərir ki, söz seviyyəsi, içərisində, performans değerlendirməsi başqa metodların arxasında olsa da, modellərimiz extrinsic, düşük işlərimiz normalizasyon vasitəsilə, çəkilməmiş, istifadə edilməmiş, sosyal media metinləri ilə işləyən modellərlə qarşılaşdırılır</abstract_az>
      <abstract_cs>Současné referenční úkoly pro zpracování přirozeného jazyka obsahují text, který se kvalitativně liší od textu používaného v neformální každodenní digitální komunikaci. Tato nesrovnalost vedla k vážnému zhoršení výkonu nejmodernějších modelů NLP při jemném ladění na reálných datech. Jedním ze způsobů, jak tento problém vyřešit, je lexikální normalizace, což je proces transformace nestandardního textu, obvykle ze sociálních médií, do standardizovanější formy. V této práci navrhujeme model sekvence-sekvence na úrovni věty založený na mBART, který rámcuje problém jako problém strojového překladu. Vzhledem k tomu, že hlučný text je všudypřítomným problémem napříč jazyky, nejen angličtinou, využíváme vícejazyčné předškolení mBART k jemnému ladění s našimi daty. Zatímco současné přístupy fungují především na úrovni slov nebo podslov, argumentujeme, že tento přístup je z technického hlediska jednoduchý a staví na existujících předškolených transformátorových sítích. Naše výsledky ukazují, že zatímco hodnocení výkonnosti na úrovni slova, intrinské, je za jinými metodami, náš model zlepšuje výkon na extrinsických, následných úkolech normalizací ve srovnání s modely pracujícími na surovém, nezpracovaném textu sociálních médií.</abstract_cs>
      <abstract_ca>Les tasques actuals de referència per al processament natural de llenguatges contenen text qualitativament diferent del que s'utilitza en la comunicació digital diària informal. Aquesta discrepancia ha portat a una grave degradació del rendiment dels models NLP més avançats quan s'ha ajustat a dades del món real. One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from social media, into a more standardized form.  En aquest treball, proposem un model de seqüència a seqüència de nivell de frases basat en mBART, que encamina el problema com un problema de traducció màquina. Com que el text sorollós és un problem a generalitzat a les llengües, no només a l'anglès, utilitzem la pré-entrenament multilingüe de mBART per ajustar-la a les nostres dades. Mentre els enfocaments actuals funcionen principalment a nivell de paraules o subparaules, argumentem que aquest enfocament és senzill d'un punt de vista tècnic i es basa en xarxes de transformadors pré-entrenats existents. Els nostres resultats mostren que mentre l'evaluació del rendiment a nivell de paraules, intrínsec, està darrere d'altres mètodes, el nostre model millora el rendiment en tasques extrinsiques i avall a través de la normalització comparat amb models que operen en text social brut, sense processament.</abstract_ca>
      <abstract_et>Praegused looduskeele töötlemise võrdlusülesanded sisaldavad teksti, mis erineb kvalitatiivselt mitteametlikus igapäevases digitaalses suhtluses kasutatavast tekstist. See lahknevus on põhjustanud kaasaegsete uue tööprogrammi mudelite jõudluse tõsist halvenemist reaalsete andmete põhjal. Üks võimalus selle probleemi lahendada on leksikaalse normaliseerimise kaudu, mis on mittestandardse teksti, tavaliselt sotsiaalmeediast, muutmise protsess standardiseeritumaks vormiks. Käesolevas töös pakume välja mBART-il põhineva lausetaseme jada-jada mudeli, mis kujundab probleemi masintõlke probleemina. Kuna mürakas tekst on leviv probleem kõigis keeltes, mitte ainult inglise keeles, siis kasutame mBART-i mitmekeelset eelkoolitust, et seda meie andmetele täpsustada. Kuigi praegused lähenemisviisid toimivad peamiselt sõna- või alamsõna tasandil, väidame, et see lähenemisviis on tehnilisest seisukohast lihtne ja põhineb olemasolevatel eelkoolitud trafovõrkudel. Meie tulemused näitavad, et kuigi teiste meetodite taga on sõnatasemel sisemine jõudluse hindamine, parandab meie mudel normaliseerimise kaudu jõudlust väliste järgnevate ülesannete puhul võrreldes töötlemata sotsiaalmeedia tekstil töötavate mudelitega.</abstract_et>
      <abstract_fi>Luonnonkielen käsittelyn nykyiset vertailutehtävät sisältävät tekstiä, joka eroaa laadullisesti epävirallisessa digitaalisessa viestinnässä käytetystä tekstistä. Tämä poikkeama on johtanut uusimpien NLP-mallien suorituskyvyn vakavaan heikkenemiseen reaalimaailman datan hienosäätöissä. Yksi tapa ratkaista tämä ongelma on sanaston normalisointi, joka on prosessi, jossa epätavallinen teksti, yleensä sosiaalisesta mediasta, muutetaan standardoidummaksi muotoon. Tässä työssä ehdotamme mBART:hen perustuvaa lausetason sekvenssimallia, joka kehystää ongelman konekäännösongelmana. Koska meluisa teksti on yleinen ongelma kaikilla kielillä, ei vain englanniksi, hyödynnämme mBART:n monikielistä esikoulutusta hienosäätääksemme sen tietoihimme. Vaikka nykyiset lähestymistavat toimivat pääasiassa sana- tai alasanatasolla, väitämme, että tämä lähestymistapa on teknisesti yksinkertainen ja perustuu olemassa oleviin valmiiksi koulutettuihin muuntajaverkkoihin. Tuloksemme osoittavat, että vaikka sanatason, luontaisen suorituskyvyn arviointi on muiden menetelmien takana, mallimme parantaa ulkoisten, loppupään tehtävien suorituskykyä normalisoitumalla verrattuna käsittelemättömällä sosiaalisen median tekstillä toimiviin malleihin.</abstract_fi>
      <abstract_bn>প্রাকৃতিক ভাষা প্রক্রিয়ার জন্য বর্তমান বেনম্যার্ক কাজের মধ্যে লেখা আছে যা দিনে ডিজিটাল যোগাযোগে ব্যবহার করা লেখার মধ্ এই বৈষম্যের ফলে রাষ্ট্র-অফ-শিল্পী এনএলপি মডেলের গুরুত্বপূর্ণ ভাবে প্রদর্শন করা হয়েছে যখন বাস্তব বিশ্বের তথ্য সম্পর্কে ভা এই বিষয়টি সমাধানের একটি উপায় হচ্ছে লেক্সিক্সিয়াল স্বাভাবিকতার মাধ্যমে, যা সাধারণত সামাজিক প্রচার মাধ্যম থেকে আরো স্বাভাবিক ফর্ এই কাজে আমরা মিশিন অনুবাদের সমস্যা হিসেবে প্রস্তাব করি একটি বাক্য-স্তরের সেকেন্স-ব্যবহারের মোডেলের উপর ভিত্তি করে, যা মেশিন অনুবাদে যেহেতু শব্দের লেখা হচ্ছে সারা ভাষায় একটি বিশাল সমস্যা, শুধু ইংরেজি নয়, আমরা এমবার্টের মাল্টিভাষার প্রশিক্ষণের পূর্বের প্রশিক্ষণ দিয় যেখানে বর্তমানে প্রধান শব্দ বা সাবওয়ার্ড স্তরে কাজ করা যায়, আমরা যুক্তি দিচ্ছি যে এই প্রযুক্তিগত স্ট্যান্ডপয়েন্ট থেকে সোজা থাকে এবং  আমাদের ফলাফল দেখা যাচ্ছে যে যখন শব্দ-স্তরের মধ্যে ব্যবহৃত, অভ্যন্তরীণ, প্রকাশ্যের মূল্য অন্যান্য পদ্ধতির পেছনে রয়েছে, তখন আমাদের মডেল বেরিয়ে যাচ্ছে, স্বাভাবিক ক কাজ</abstract_bn>
      <abstract_jv>bench Dijewisan iki lak wis kondhe akeh nggawe gerarané duruh-karo model NLP sing berarti dadi barang-barêng. Sampeyan kang dipoleh sing perusahaan iki dadi aturan luwih Normal, sampeyan ngiye perusahaan kanggo teks sing bisa awak dhéwé, sadurungé sak media sotiki, kita disenyakake sistem sing berarti. Nang barêng-barêng iki, kéné supoyo mrogram-kuwi sekèn-to-sekèn model sing basa ning mBORT, sing titimpen kuwi nggawe boten nganggo kelompok tarjamahan. Teks nggambar luwih dumadhi sing perusahaan kanggo langgar, ora iso nggambar Inggris, awake dhéwé ngewehke bantuan luwih-luwih bantuan mBart kanggo ngerasakno dadi awakdhéwé. politenessoffpolite"), and when there is a change ("assertive Rejalaké kamu mengko ngono kuwi gambaran kelas telas telas telas telas, karo iso nggawe barang kelas telas telas telas telas telas telas telas telas telas telas telas telas telas telas wae, dadi model sing bisa nggawe barang tengas telas telas telas telas telas telas wae</abstract_jv>
      <abstract_sk>Trenutna referenčna naloga za obdelavo naravnega jezika vsebujejo besedilo, ki se kakovostno razlikuje od besedila, ki se uporablja v neformalni vsakodnevni digitalni komunikaciji. To razliko je privedlo do hudega poslabšanja učinkovitosti najsodobnejših modelov NLP, kadar so bili natančno prilagojeni podatki iz realnega sveta. Eden od načinov rešitve tega vprašanja je leksikalna normalizacija, ki je proces pretvorbe nestandardnega besedila, običajno iz družbenih medijev, v bolj standardizirano obliko. V tem delu predlagamo model zaporedja v zaporedje stavka, ki temelji na mBART, ki problem okvirja kot problem strojnega prevajanja. Ker je hrupno besedilo velik problem v vseh jezikih, ne samo angleščini, izkoristimo večjezično predusposabljanje mBART, da ga natančno prilagodimo našim podatkom. Medtem ko sedanji pristopi delujejo predvsem na ravni besed ali podbesed, trdimo, da je ta pristop s tehničnega stališča preprost in temelji na obstoječih vnaprej usposobljenih transformatorskih omrežjih. Naši rezultati kažejo, da medtem ko je za drugimi metodami vrednotenje učinkovitosti na ravni besed, notranja vrednotenja učinkovitosti, naš model izboljšuje učinkovitost pri zunanjih, nadaljnjih nalogah z normalizacijo v primerjavi z modeli, ki delujejo na surovem, nepredelanem besedilu na družbenih omrežjih.</abstract_sk>
      <abstract_bo>Current benchmark tasks for natural language processing contain text that is qualitatively different from the text used in informal day to day digital communication. discrepancy་འདི་གིས་གནས་སྟངས་གནས་ཚུལ་དང་འཛམ་གླིང་སྟེང་གནས་ཚུལ་དང་མཉམ་དུ་བཏོན་པའི་རྣམ་པ་སྣང་ཚུལ་ཁག་གཏོང་བ་རྐྱེན ཐབས་ལམ་གཅིག་གིས་གནད་དོན་འདི་མོས་མཐུན་བྱེད་པར་གནད་དོན་རྒྱུན་ལྡན་གྱི་རྒྱུན་རིམ་མེད་པའི་ཡིག་གེ་འགྱུར་བ་ལས་མི་རྒྱུན་ལྡ In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a machine translation problem. སྐད་ཡིག་གི་ནང་དུ་ཡིག While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds on existing pre-trained transformer networks. ང་ཚོའི་འབྲུག་བྱ་ཚིག་དག་གནས་ཚུལ་ལས་ཀར་བརྗོད་བྱེད་མི་འདུག</abstract_bo>
      <abstract_he>משימות רמז הנוכחיות לעבודת שפת טבעית מכילות טקסט שמשונה באופן איכותי מהטקסט שמשתמש בתקשורת דיגיטלית יום יום יום. ההחלטה הזו הובילה לפרעת ביצועים רצינית של מודלים NLP מצוינים כשמתאימים על נתונים בעולם האמיתי. One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from social media, into a more standardized form.  בעבודה הזו, אנו מציעים מודל רצף-לרמה משפטים-לרצף מבוסס על mBART, שמסגר את הבעיה כבעיה התרגום מכונת. כיוון שהטקסט הרעשני הוא בעיה שגרתית בכל שפות, לא רק באנגלית, אנו משתמשים באימונים מראשי-שפות של mBART כדי להתאים אותו למידע שלנו. בזמן שהגישות הנוכחיות פועלות בעיקר ברמה של מילים או מתחת מילים, אנו טוענים שהגישה הזאת היא ישירה מנקודת מבט טכנית ומבנה על רשתות משתנות מיומנות קודמות. התוצאות שלנו מראות כי בעוד מערכת ביצועים ברמה מילים, פנימית, מאחורי שיטות אחרות, המודל שלנו משפר ביצועים על משימות חיצוניות, למטה דרך נורמליזציה בהשוואה לדוגמנים שמפעילים על טקסט של תקשורת חברתית חסר שימוש, לא מושלם.</abstract_he>
      <abstract_ha>Yin aikin bangon faɗaɗar da ke ƙunsa da matsayi wanda aka yi amfani da shi a yanzu a haɗin digitalun a yinin. @ action: button Tsarin wannan masu zartar da shi, yana iya maras a shige taƙaitaccen littãfi na'ura, ko da yaushe, daga mitandan jamii, zuwa wani tsari mai daidaita. Daga wannan aikin, muna buƙata wani misali mai sauri-daraja zuwa-sequence kan mBRT, wanda ke ƙara mataimaki kamar wata fitina ta fassarar da mashine. Kama da matsayin saurãre ta zama wata matabbata mai yawa a cikin harshen, kuma ba ta zama kawai Ingiriya ba, muna komai da multi-linguin musamman wa mBaraT don ya sami-tune shi zuwa danganmu. While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks.  MatamayinMu na nũna cewa, a lokacin da ake iya cikin magana, yana ƙari, yana ƙari ga muhimmin aiki na dabam, kuma yana ƙari muhimmin musammalinmu a kan aikin na baki-rayi, da kuma a sami da misãlai masu yin amfani da kan raw, da ba'a yi aiki ba, da matsayin mitandaci na jami.</abstract_ha>
      </paper>
    <paper id="54">
      <title>FAL at MultiLexNorm 2021 : Improving Multilingual Lexical Normalization by Fine-tuning ByT5<fixed-case>ÚFAL</fixed-case> at <fixed-case>M</fixed-case>ulti<fixed-case>L</fixed-case>ex<fixed-case>N</fixed-case>orm 2021: Improving Multilingual Lexical Normalization by Fine-tuning <fixed-case>B</fixed-case>y<fixed-case>T</fixed-case>5</title>
      <author><first>David</first><last>Samuel</last></author>
      <author><first>Milan</first><last>Straka</last></author>
      <pages>483–492</pages>
      <abstract>We present the winning entry to the Multilingual Lexical Normalization (MultiLexNorm) shared task at W-NUT 2021 (van der Goot et al., 2021a), which evaluates lexical-normalization systems on 12 social media datasets in 11 languages. We base our solution on a pre-trained byte-level language model, ByT5 (Xue et al., 2021a), which we further pre-train on synthetic data and then fine-tune on authentic normalization data. Our system achieves the best performance by a wide margin in intrinsic evaluation, and also the best performance in extrinsic evaluation through dependency parsing. The source code is released at https://github.com/ufal/multilexnorm2021 and the fine-tuned models at https://huggingface.co/ufal.</abstract>
      <url hash="ba0bc551">2021.wnut-1.54</url>
      <bibkey>samuel-straka-2021-ufal</bibkey>
      <doi>10.18653/v1/2021.wnut-1.54</doi>
      <pwccode url="https://github.com/ufal/multilexnorm2021" additional="false">ufal/multilexnorm2021</pwccode>
    <title_es>ÜFAL en MultiLexNorm 2021: Mejora de la normalización léxica multilingüe mediante el ajuste fino de BYT5</title_es>
      <title_ar>ÜFAL في MultiLexNorm 2021: تحسين التطبيع المعجمي متعدد اللغات عن طريق ضبط ByT5</title_ar>
      <title_fr>ÜFAL au MultilexNorm 2021 : Améliorer la normalisation lexicale multilingue en ajustant avec précision ByT5</title_fr>
      <title_pt>ÜFAL na MultiLexNorm 2021: Melhorando a normalização lexical multilíngue por ajuste fino ByT5</title_pt>
      <title_ja>MultiLexNorm 2021のÜFAL ： ByT 5による微調整による多言語レキシカルな正規化の改善</title_ja>
      <title_zh>ÜFAL 在 MultiLexNorm 2021 :微 ByT5 多言词汇规范化</title_zh>
      <title_hi>MultiLexNorm 2021 में ÜFAL: ठीक ट्यूनिंग ByT5 द्वारा बहुभाषी लेक्सिकल सामान्यीकरण में सुधार</title_hi>
      <title_ru>ÜFAL на выставке MultiLexNorm 2021: Улучшение многоязычной лексической нормализации путем тонкой настройки по T5</title_ru>
      <title_ga>ÜFAL ag MultiLexNorm 2021: Normalú Foclóireachta Ilteangach a Fheabhsú trí ByT5 a mhionchoigeartú</title_ga>
      <title_ka>UFAL multiLexNorm 2021: მრავალენგური ლექსიკური ნორმალიზაცია ბიT5 გამოსახულება</title_ka>
      <title_hu>UFAL a MultiLexNorm 2021-en: A többnyelvű lexikai normalizáció javítása a ByT5 finomhangolásával</title_hu>
      <title_el>Βελτίωση της πολυγλωσσικής λεξικής κανονικοποίησης με τη βελτίωση του ByT5</title_el>
      <title_lt>2021 m. MultiLexNorm UFAL: Didinti daugiakalbę leksinę normalizaciją koreguojant ByT5</title_lt>
      <title_it>UFAL a MultiLexNorm 2021: migliorare la normalizzazione lessicale multilingue con la messa a punto di ByT5</title_it>
      <title_kk>UFAL көптеген LexNorm 2021: Көптеген лексикалық нормализациясын жасау</title_kk>
      <title_mk>UFAL на MultiLexNorm 2021: подобрување на мултијазичката лексикална нормализација со финетирање на ByT5</title_mk>
      <title_ms>UFAL di MultiLexNorm 2021: Menembangkan Normalisasi Lexik Berbahasa dengan Penyesuaian Baik ByT5</title_ms>
      <title_ml>മുള്‍ലെക്സ്നോര്‍മിലെ UFAL 2021: ഫൈന്‍ ടൂണിങ്ങ് ബിടി5ല്‍ മുന്‍കൂട്ടി ഭാഷ ലെക്സിക്കല്‍ നോര്‍മിലേഷന്‍ മുന്‍കൂട്ടുന്</title_ml>
      <title_mt>UFAL f’MultiLexNorm 2021: Titjib tan-Normalizzazzjoni Lessika Multilingwi permezz ta’ Aġġustament Irfinat tal-ByT5</title_mt>
      <title_mn>Олон LexNorm 2021 оны UFAL: Олон хэлний Lexical Normalization by Fine-tuning ByT5</title_mn>
      <title_no>UFAL på fleire læringsNorm 2021: Forbetra fleirspråk leksisk normalisering ved finnstilling av ByT5</title_no>
      <title_pl>UFAL na MultiLexNorm 2021: Poprawa wielojęzycznej normalizacji leksykalnej poprzez dostosowanie ByT5</title_pl>
      <title_ro>UFAL la MultiLexNorm 2021: Îmbunătățirea normalizării lexicale multilingve prin reglarea fină a ByT5</title_ro>
      <title_sr>UFAL na multiLexNorm 2021: poboljšanje multijezičke leksičke normalizacije po dobrom obliku ByT5</title_sr>
      <title_si>UFAL at MultiLexNorm 2021: Multilanguage Lexical Normallization by Fine-tuning ByT5</title_si>
      <title_so>UFAL at MultiLexNorm 2021: Improving Multilingual Lexical Normalization by Fine-tuning ByT5</title_so>
      <title_sv>UFAL på MultiLexNorm 2021: Förbättra flerspråkig Lexical Normalisering genom finjustering av ByT5</title_sv>
      <title_ta>பல்லெக்ஸ்Norm 2021-ல் UFAL: பல மொழி லெக்சிகல் இயல்பானத்தை மேம்படுத்துகிறது பைட்டி5 ஆல் மேம்படுத்துகிறது</title_ta>
      <title_ur>UFAL MultiLexNorm 2021: Multilingual Lexical Normalization by Fine-tuning ByT5</title_ur>
      <title_uz>MultiLexNorm 2021 (MultiLexNorm) UFAL: Pir- tuning ByT5 (Multi- Lugʻlik Leksikal) tartibizni oshirish</title_uz>
      <title_vi>Có thuyết trình nâng cao ngôn ngữ phân giải ngôn ngữ</title_vi>
      <title_bg>УФАЛ в Подобряване на многоезичната лексикална нормализация чрез фина настройка</title_bg>
      <title_hr>UFAL na multiLexNorm 2021: poboljšavanje višejezičke leksičke normalizacije preko dobrog oblika ByT5</title_hr>
      <title_nl>UFAL op MultiLexNorm 2021: Verbetering van meertalige Lexische Normalisatie door fine-tuning ByT5</title_nl>
      <title_da>UFAL på MultiLexNorm 2021: Forbedring af flersproget Lexical Normalisering ved finjustering af ByT5</title_da>
      <title_de>UFAL auf der MultiLexNorm 2021: Verbesserung der mehrsprachigen Lexikalnormalisierung durch Feinabstimmung von ByT5</title_de>
      <title_id>UFAL di MultiLexNorm 2021: Menembangkan Normalisasi Lexik Berbahasa Dengan Penyesuaian Baik ByT5</title_id>
      <title_ko>UFAL의 MultiLexNorm 2021: T5 미세조정을 통한 다국어 어휘 규범화</title_ko>
      <title_fa>UFAL در MultiLexNorm 2021: Improving Multilingual Lexical Normalization by Fine-tuning ByT5</title_fa>
      <title_sw>UFAL katika mtandao wa MultiLexNorm 2021: Kuboresha Uwezeshaji wa lugha nyingi wa Kilexico na Kutunza ByT5</title_sw>
      <title_sq>UFAL në MultiLexNorm 2021: Përmirësimi i Normalizacionit Lexikal Shumë-gjuhësor me Fine-tuning ByT5</title_sq>
      <title_af>UFAL by MultiLexNorm 2021: verbetering Multilingual Lexical Normalisation by Fine-tuning ByT5</title_af>
      <title_tr>UFAL at MultiLexNorm 2021: Multilingual Lexical Normalization by Fine-tuning ByT5</title_tr>
      <title_am>ŠČ†MultiLexNorm 2021: ŠČ†Multilingual Lexical Normalization by Fine-tuning ByT5</title_am>
      <title_hy>UFIL-ը 2021 թվականի "ՄոլիլեքսՆորմ": Բազլեզու լեքսիկական նորմալիզացիայի բարելավումը բարելավելով բարելավելով Բիթ5-ը</title_hy>
      <title_bn>UFAL at MultiLexNorm 2021: Improving Multilingual Lexical Normalization by Fine-tuning ByT5</title_bn>
      <title_ca>UFAL a MultiLexNorm 2021: millorar la normalització lexical multilingüe ajustando ByT5</title_ca>
      <title_cs>UFAL na MultiLexNorm 2021: Zlepšení vícejazyčné Lexické normalizace jemným laděním ByT5</title_cs>
      <title_et>UFAL MultiLexNorm 2021: mitmekeelse lexikaalse normaliseerimise parandamine peenhäälestusega ByT5</title_et>
      <title_fi>UFAL MultiLexNorm 2021: monikielisen lexikaalisen normalisoinnin parantaminen hienosäätämällä ByT5</title_fi>
      <title_az>MultiLexNorm 2021-də UFAL: Çoxlu Dili Leksikal Normalizasyonu İyi-T5 ilə yaxşılaşdırma</title_az>
      <title_bs>UFAL na multiLexNorm 2021: poboljšavanje multijezičke leksičke normalizacije od strane ByT5 fino-tuniranja</title_bs>
      <title_jv>UFaL nang MultiLexNorm 2020 1: Ngawe luwih-luwih Leksial Normalisi Daawe Fine-tuning bytes-5</title_jv>
      <title_ha>QUnicodeControlCharacterMenu</title_ha>
      <title_he>UFAL ב MultiLexNorm 2021: שיפור נורמליזציה לקסית רבת שפותית על ידי התאמה מיוחדת ByT5</title_he>
      <title_sk>UFAL na MultiLexNorm 2021: Izboljšanje večjezične leksične normalizacije s finim nastavitvijo ByT5</title_sk>
      <title_bo>UFAL at MultiLexNorm 2021: Improving Multilingual Lexical Normalization by Fine-tuning ByT5</title_bo>
      <abstract_pt>Apresentamos a entrada vencedora da tarefa compartilhada Multilingual Lexical Normalization (MultiLexNorm) no W-NUT 2021 (van der Goot et al., 2021a), que avalia sistemas de normalização lexical em 12 conjuntos de dados de mídia social em 11 idiomas. Baseamos nossa solução em um modelo de linguagem de nível de byte pré-treinado, ByT5 (Xue et al., 2021a), que pré-treinamos em dados sintéticos e depois ajustamos em dados de normalização autênticos. Nosso sistema alcança o melhor desempenho por uma ampla margem na avaliação intrínseca e também o melhor desempenho na avaliação extrínseca por meio da análise de dependência. O código-fonte é lançado em https://github.com/ufal/multilexnorm2021 e os modelos ajustados em https://huggingface.co/ufal.</abstract_pt>
      <abstract_fr>Nous présentons l'entrée gagnante de la tâche partagée de normalisation lexicale multilingue (MultilexNorm) au W-NUT 2021 (van der Goot et al., 2021a), qui évalue les systèmes de normalisation lexicale sur 12 ensembles de données de médias sociaux en 11 langues. Nous basons notre solution sur un modèle de langage au niveau octet pré-entraîné, ByT5 (Xue et al., 2021a), que nous préformons ensuite sur des données synthétiques, puis nous affinons sur des données de normalisation authentiques. Notre système obtient les meilleures performances dans une large mesure dans l'évaluation intrinsèque, ainsi que les meilleures performances en évaluation extrinsèque grâce à l'analyse des dépendances. Le code source est publié sur https://github.com/ufal/multilexnorm2021 et les modèles affinés sur https://huggingface.co/ufal.</abstract_fr>
      <abstract_es>Presentamos la entrada ganadora de la tarea compartida de Normalización Léxica Multilingüe (MultilexNorm) en W-NUT 2021 (van der Goot et al., 2021a), que evalúa los sistemas de normalización léxica en 12 conjuntos de datos de redes sociales en 11 idiomas. Basamos nuestra solución en un modelo de lenguaje a nivel de bytes previamente entrenado, ByT5 (Xue et al., 2021a), que entrenamos previamente con datos sintéticos y luego ajustamos con precisión los datos de normalización auténticos. Nuestro sistema logra el mejor rendimiento por un amplio margen en la evaluación intrínseca, y también el mejor rendimiento en la evaluación extrínseca mediante el análisis de dependencias. El código fuente se publica en https://github.com/ufal/multilexnorm2021 y los modelos ajustados en https://huggingface.co/ufal.</abstract_es>
      <abstract_ar>نقدم الإدخال الفائز إلى مهمة التطبيع المعجمي متعدد اللغات (MultiLexNorm) المشتركة في W-NUT 2021 (van der Goot et al. ، 2021a) ، والتي تقيم أنظمة التطبيع المعجمي في 12 مجموعة بيانات للوسائط الاجتماعية بـ 11 لغة. نحن نبني حلنا على نموذج لغة على مستوى البايت تم تدريبه مسبقًا ، ByT5 (Xue وآخرون ، 2021 أ) ، والذي نقوم بتدريبه مسبقًا على البيانات التركيبية ثم ضبطه على بيانات التطبيع الأصلية. يحقق نظامنا أفضل أداء بهامش واسع في التقييم الداخلي ، وأيضًا أفضل أداء في التقييم الخارجي من خلال تحليل التبعية. يتم تحرير كود المصدر على https://github.com/ufal/multilexnorm2021 والنماذج الدقيقة على https://huggingface.co/ufal.</abstract_ar>
      <abstract_ja>W - NUT 2021 （ van der Goot et al., 2021 a ）での多言語Lexical Normalization （ MultiLexNorm ）共有タスクの優勝エントリを紹介します。これは、11言語の12のソーシャルメディアデータセット上の語彙正規化システムを評価します。私たちは、事前にトレーニングされたバイトレベルの言語モデルであるByT 5 （ Xue et al., 2021 a ）に基づいてソリューションを作成します。これにより、合成データの事前トレーニングをさらに進め、真正な正規化データを微調整します。当社のシステムは、固有評価で広い余裕を持つことで最高のパフォーマンスを実現し、また、依存関係解析を通じて外部評価で最高のパフォーマンスを実現します。ソースコードはhttps://github.com/ufal/multilexnorm2021でリリースされ、モデルはhttps://huggingface.co/ufalで微調整されています。</abstract_ja>
      <abstract_zh>臣等W-NUT 2021(van der Goot et al.,2021a)上展多言词汇规范化(MultiLexNorm)共享之获奖作品,当质11种语者12社交媒体据集上词汇规范化系统。 吾解决方案基于豫练字节语言模ByT5(Xue et al.,2021a),合数预训练之,然后微于真规范化。 吾统内得其性,而恃其解析而外得其性。 源代码发于 https://github.com/ufal/multilexnorm2021 ,微发于 https://huggingface.co/ufal 。</abstract_zh>
      <abstract_ru>Мы представляем выигрышную запись в общей задаче многоязычной лексической нормализации (MultiLexNorm) на W-NUT 2021 (van der Goot et al., 2021a), которая оценивает системы лексической нормализации на 12 наборах данных социальных сетей на 11 языках. Мы основываем наше решение на предварительно обученной языковой модели байтового уровня ByT5 (Xue et al., 2021a), которую мы дополнительно предварительно обучаем синтетическим данным, а затем тонко настраиваем на аутентичные данные нормализации. Наша система достигает наилучшей производительности благодаря большому запасу внутренней оценки, а также наилучшей производительности внешней оценки за счет анализа зависимостей. Исходный код выпускается по адресу https://github.com/ufal/multilexnorm2021, а тонко настроенные модели - по адресу https://huggingface.co/ufal.</abstract_ru>
      <abstract_hi>हम W-NUT 2021 (van der Goot et al., 2021a) में बहुभाषी लेक्सिकल सामान्यीकरण (MultiLexNorm) साझा कार्य के लिए विजेता प्रविष्टि प्रस्तुत करते हैं, जो 11 भाषाओं में 12 सोशल मीडिया डेटासेट पर लेक्सिकल-सामान्यीकरण प्रणालियों का मूल्यांकन करता है। हम अपने समाधान को एक पूर्व-प्रशिक्षित बाइट-स्तर के भाषा मॉडल, ByT5 (Xue et al., 2021a) पर आधारित करते हैं, जिसे हम सिंथेटिक डेटा पर आगे प्री-ट्रेन करते हैं और फिर प्रामाणिक सामान्यीकरण डेटा पर ठीक करते हैं। हमारी प्रणाली आंतरिक मूल्यांकन में एक व्यापक मार्जिन से सबसे अच्छा प्रदर्शन प्राप्त करती है, और निर्भरता पार्सिंग के माध्यम से बाहरी मूल्यांकन में सबसे अच्छा प्रदर्शन भी करती है। स्रोत कोड https://github.com/ufal/multilexnorm2021 पर जारी किया जाता है और https://huggingface.co/ufal पर ठीक-ठाक मॉडल।</abstract_hi>
      <abstract_ga>Cuirimid i láthair an iontráil bhuaiteach don tasc roinnte um Normalú Foclaíochta Ilteangach (MultiLexNorm) ag W-NUT 2021 (van der Goot et al., 2021a), a dhéanann meastóireacht ar chórais normalaithe foclóireachta ar 12 thacar sonraí meán sóisialta i 11 theanga. Bunaimid ár réiteach ar mhúnla teanga leibhéal beart réamh-oilte, ByT5 (Xue et al., 2021a), a ndéanaimid tuilleadh oiliúna ar shonraí sintéiseacha agus ansin mionchoigeartú a dhéanamh ar shonraí barántúla normalaithe. Baineann ár gcóras an fheidhmíocht is fearr amach le corrlach leathan sa mheastóireacht intreach, agus freisin an fheidhmíocht is fearr i meastóireacht eistreach trí pharsáil spleáchais. Eisítear an cód foinse ag https://github.com/ufal/multilexnorm2021 agus na samhlacha mionchoigeartaithe ag https://huggingface.co/ufal.</abstract_ga>
      <abstract_ka>ჩვენ მრავალენგური ლექსიკალური ნორმალიზაციის (MultiLexNorm) სხვადასხვა რაოდენობა W-NUT 2021 (van der Goot et al., 2021a), რომელიც 12 სოციალური მედიატის მონაცემების განსაზღვრებული ლექსიკალური ნორმალიზაციის სისტემებში 11 ჩვენ განვითარებას წინასწარმოადგენებული ბაიტის ენის მოდელზე, ByT5 (Xue et al., 2021a), რომელიც ჩვენ უფრო მეტი სინტეტიკური მონაცემებზე გავაგრძნოთ და შემდეგ ავტონტიკური ნორმალიზაციის მონაცემებზე და ჩვენი სისტემა უკეთესი გამოსახულებას უფრო მნიშვნელოვანია ინტერნექტური განსახულებაში, და ასევე უკეთესი გამოსახულებას ექსტრინული განსახულებაში გამოსახულებ მხოლოდ კოდის გახსნა https://github.com/ufal/multilexnorm2021 და მარტივი მოდელები https://huggingface.co/ufal.</abstract_ka>
      <abstract_hu>Bemutatjuk a többnyelvű lexikai normalizáció (MultiLexNorm) megosztott feladat nyertes nevét a W-NUT 2021 (van der Goot et al., 2021a), amely 12 közösségi média adatkészleten 11 nyelven értékeli a lexikai normalizációs rendszert. Megoldásunkat egy előre képzett bájtszintű nyelvi modellre alapozzuk, a ByT5-re (Xue et al., 2021a), amelyet tovább képzünk szintetikus adatokra, majd finomhangolunk hiteles normalizációs adatokra. Rendszerünk a legjobb teljesítményt a belső értékelésben széles margin mellett, valamint a legjobb teljesítményt a külső értékelésben a függőség elemzésével. A forráskód a következő címen kerül kiadásra: https://github.com/ufal/multilexnorm2021 és a finomhangolt modellek https://huggingface.co/ufal.</abstract_hu>
      <abstract_el>Παρουσιάζουμε την επιτυχημένη συμμετοχή στην κοινή εργασία Πολυγλωσσικής Λεξικής Κανονικής Κανονικής (Πολυγλωσσικής Κανονικής Κανονικής Κανονικής) στο το οποίο αξιολογεί συστήματα Λεξικής-Κανονικής Κανονικής σε 12σύνολα δεδομένων κοινωνικών μέσων σε 11 γλώσσες. Βασίζουμε τη λύση μας σε ένα προ-εκπαιδευμένο γλωσσικό μοντέλο σε επίπεδο byte, το οποίο προπληρώνουμε περαιτέρω σε συνθετικά δεδομένα και στη συνέχεια συντονίζουμε με αυθεντικά δεδομένα ομαλοποίησης. Το σύστημά μας επιτυγχάνει την καλύτερη απόδοση με ένα ευρύ περιθώριο στην εσωτερική αξιολόγηση, καθώς και την καλύτερη απόδοση στην εξωτερική αξιολόγηση μέσω ανάλυσης εξάρτησης. Ο πηγαίος κώδικας δημοσιεύεται στο https://github.com/ufal/multilexnorm2021 και τα εκλεπτυσμένα μοντέλα στο https://huggingface.co/ufal.</abstract_el>
      <abstract_it>Presentiamo la partecipazione vincente al compito condiviso Multilingual Lexical Normalization (MultiLexNorm) a W-NUT 2021 (van der Goot et al., 2021a), che valuta i sistemi di normalizzazione lessicale su 12 set di dati social media in 11 lingue. Basamo la nostra soluzione su un modello di linguaggio pre-addestrato a livello byte, ByT5 (Xue et al., 2021a), che pre-addestrato ulteriormente su dati sintetici e poi perfezionato su dati di normalizzazione autentici. Il nostro sistema raggiunge le migliori prestazioni con un ampio margine nella valutazione intrinseca, e anche le migliori prestazioni nella valutazione estrinseca attraverso l'analisi delle dipendenze. Il codice sorgente è rilasciato a https://github.com/ufal/multilexnorm2021 e i modelli perfezionati a https://huggingface.co/ufal.</abstract_it>
      <abstract_kk>Біз көп тілді лексикалық нормализация (MultiLexNorm) W-NUT 2021 (van der Goot et al., 2021a) ортақ тапсырмасына жеткізген жазуды, ол 12 социаллық медиа деректерінде 11 тілде лексикалық нормализациялау жүйелерін бағалады. Біз өзіміздің шешімімізді алдын- ала оқылған байт деңгейіндегі тіл үлгісіне, ByT5 (Xue et al., 2021a) негіздеп, синтетикалық деректерді алдын- ала тұрып, автентикалық нормализациялау деректеріне жақсы түзе Біздің жүйеіміз ішкі оқиғалардың ең жақсы жылдамдығын, сондай-ақ тәуелдік талдау арқылы ekstrinsic оқиғалардың ең жақсы жылдамдығын жеткізеді. Бастапқы код тасталған https://github.com/ufal/multilexnorm2021 және дұрыс келтірілген үлгілер https://huggingface.co/ufal.</abstract_kk>
      <abstract_lt>Pateikiame laimingą įrašą į dalijamąjį darbą „Multilingual Lexical Normalization“ (MultiLexNorm) W-NUT 2021 (van der Goot et al., 2021a), kuriame vertinamos 12 socialinių žiniasklaidos duomenų rinkinių tekstinės normalizacijos sistemos 11 kalbų. Mūsų sprendimas grindžiamas iš anksto parengtu baitų lygio kalbos modeliu ByT5 (Xue et al., 2021a), kuris toliau rengiamas sintetiniais duomenimis, o vėliau patobulinamas autentiškais normalizavimo duomenimis. Mūsų sistema, atlikdama priklausomybės analizę, pasiekia geriausius rezultatus, pasitelkdama didelę vidinio vertinimo maržą, taip pat geriausius išorinio vertinimo rezultatus. The source code is released at  https://github.com/ufal/multilexnorm2021 - ir patobulinti modeliai https://huggingface.co/ufal.</abstract_lt>
      <abstract_mk>Ние го претставуваме победничкиот влез во Мултијанговната лексикална нормализација (МултилексНорм) заедничката задача на W-NUT 2021 (ван дер Гут и ал., 2021а), која ги проценува лексикалните нормализациски системи на 12 социјални медиумски податоци на 11 јазици. Ние го базираме нашето решение на предобучен јазички модел на бајт ниво, ByT5 (Xue et al., 2021a), кој понатаму го предобучуваме на синтетичките податоци и потоа финетизираме на автентичните податоци за нормализација. Нашиот систем ја постигнува најдобрата резултат со широка маргина во внатрешната проценка, како и најдобрата резултат во надворешната проценка преку анализирање на зависноста. Изворниот код е објавен на https://github.com/ufal/multilexnorm2021 И моделите на https://huggingface.co/ufal.</abstract_mk>
      <abstract_ms>Kami memperkenalkan masukan yang menang kepada Normalisasi Leksikal Berbahasa (MultiLexNorm) tugas berkongsi di W-NUT 2021 (van der Goot et al., 2021a), yang meneliti sistem normalisasi leksikal pada 12 set data media sosial dalam 11 bahasa. Kita mengasaskan penyelesaian kita pada model bahasa tahap bait yang dilatih-dilatih, ByT5 (Xue et al., 2021a), yang mana kita melanjutkan melatih-melatih pada data sintetik dan kemudian tune-fine pada data normalisasi sah. Sistem kita mencapai prestasi terbaik dengan margin luas dalam penilaian dalaman, dan juga prestasi terbaik dalam penilaian luar melalui penghuraian dependensi. Kod sumber dibebaskan pada https://github.com/ufal/multilexnorm2021 - dan model-tuned di https://huggingface.co/ufal.</abstract_ms>
      <abstract_ml>ഞങ്ങള്‍ വിജയിക്കുന്നത് പല ഭാഷ ലെക്സിക്കാല്‍ നോര്‍മാലിയഷനിലേക്ക് (MultiLexNorm) വിജയിക്കുന്ന ജോലിയാണ് (വാന്‍ ഡെര്‍ ഗൂട്ട് അല്‍ , 2021a), 12 സോഷ്യല്‍ മീഡിയ ഡാറ്റാസറേറ്റു നമ്മുടെ പരിശീലനത്തിനു മുമ്പ് പരിശീലനം നല്‍കപ്പെട്ട ബൈറ്റ് നില ഭാഷ മോഡലിന്‍റെ മേല്‍ നമ്മുടെ പരിഹരിക്കുന്നത് ബൈട്ടി5 (ജൂ et, 2021a), അതിന്‍റെ സിന്‍റെറ്റ നമ്മുടെ സിസ്റ്റത്തില്‍ വിശാലമായ ഒരു പ്രകടനം നേടുന്നത് ആവേകത്തിലെ വിശ്വാസത്തിലും, ആശ്രയിച്ച പാര്‍ജിങ്ങിലൂടെ ഉത്തമമായ പ് ഉറവിട കോഡ് വിടുന്നു https://github.com/ufal/multilexnorm2021 പിന്നെ നല്ല മോഡലുകള്‍ https://huggingface.co/ufal.</abstract_ml>
      <abstract_mt>Aħna nippreżentaw id-dħul rebbieħ għall-kompitu kondiviż tan-Normalizzazzjoni Lessika Multilingwi (MultiLexNorm) fil-W-NUT 2021 (van der Goot et al., 2021a), li jevalwa s-sistemi ta’ normalizzazzjoni lexikali fuq 12-il sett ta’ dejta tal-midja soċjali fi 11-il lingwa. Aħna nibbażaw is-soluzzjoni tagħna fuq mudell lingwistiku ta’ livell ta’ byte imħarreġ minn qabel, ByT5 (Xue et al., 2021a), li a ħna nħarrġu aktar minn qabel fuq dejta sintetika u mbagħad nirranġaw fuq dejta ta’ normalizzazzjoni awtentika. Is-sistema tagħna tikseb l-a ħjar prestazzjoni b’marġini wiesa’ fl-evalwazzjoni intrinsika, kif ukoll l-aħjar prestazzjoni fl-evalwazzjoni esterna permezz tal-analiżi tad-dipendenza. Il-kodiċi tas-sors jiġi rilaxxat fuq https://github.com/ufal/multilexnorm2021 ) u l-mudelli rranġati f’ https://huggingface.co/ufal.</abstract_mt>
      <abstract_no>Vi viser det vinnende oppføringa til den fleirspråksnormaliseringen (MultiLexNorm) delte oppgåva på W-NUT 2021 (van der Goot et al., 2021a), som evaluerer leksiske normaliseringssystemet på 12 sosiale medietata i 11 språk. Vi baserer løsningen vårt på eit føretrained byte-nivåspråk-modell, ByT5 (Xue et al., 2021a), som vi framleis føretreng på syntetiske data og så finn opp på autentiske normaliseringsdata. Sistemet vårt gjer det beste utviklinga med ein brei margin i innhaldet evalueringa, og også den beste utviklinga i ekstrinske evalueringa gjennom tolking av avhengighet. Kjeldekode vert sletta på https://github.com/ufal/multilexnorm2021 og dei finnstillingsmodelane på https://huggingface.co/ufal.</abstract_no>
      <abstract_pl>Prezentujemy zwycięski wpis do wspólnego zadania Wielojęzyczna Lexikalna Normalizacja (MultiLexNorm) podczas W-NUT 2021 (van der Goot et al., 2021a), który ocenia systemy leksykalno-normalizacyjne na 12-ciu zbiorach danych mediów społecznościowych w 11-językach. Nasze rozwiązanie opiera się na wstępnie przeszkolonym modelu języka bajtowego ByT5 (Xue et al., 2021a), który następnie wstępnie trenujemy na danych syntetycznych, a następnie dostosowujemy na autentycznych danych normalizacyjnych. Nasz system osiąga najlepszą wydajność o szeroki margines w ocenie wewnętrznej, a także najlepszą wydajność w ocenie zewnętrznej poprzez parsowanie zależności. Kod źródłowy jest publikowany pod adresem: https://github.com/ufal/multilexnorm2021 i dopracowane modele na https://huggingface.co/ufal.</abstract_pl>
      <abstract_mn>Бид олон хэлний лексикийн нормализацийг (MultiLexNorm) W-NUT 2021 (van der Goot et al., 2021a) дээр хуваалцах үйл ажиллагааг илтгэдэг. Энэ нь 12 нийгмийн медиа өгөгдлийн санг 11 хэлний 12 хэлний хэлний лексикийн нормализацийн системийг үнэлдэг. Бид өөрсдийн шийдлийг урд сургалтын байт хэл загвар дээр суурилуулж, ByT5 (Xue et al., 2021a) гэсэн үг. Бид үүнийг синтетик өгөгдлийг илүү урд суурилуулж, дараа нь зөв хэмжээст өгөгдлийг сайжруулдаг. Бидний систем дотоод үнэлгээнд хамгийн шилдэг үйл ажиллагааг, мөн хамааралтай ажиллагааны хуваалцаанд хамгийн шилдэг үйл ажиллагааг гаргадаг. Гэхдээ эх үүсвэрийн код https://github.com/ufal/multilexnorm2021 Мөн загвар нь https://huggingface.co/ufal.</abstract_mn>
      <abstract_ro>Vă prezentăm intrarea câștigătoare la sarcina partajată Multilingv Lexical Normalization (MultiLexNorm) la W-NUT 2021 (van der Goot et al., 2021a), care evaluează sistemele de normalizare lexicală pe 12 seturi de date de social media în 11 limbi. Ne bazăm soluția pe un model de limbaj pre-instruit la nivel de octeți, ByT5 (Xue et al., 2021a), pe care îl pregătim în continuare pe date sintetice și apoi reglăm fin pe date autentice de normalizare. Sistemul nostru obține cea mai bună performanță printr-o marjă largă în evaluarea intrinsecă, precum și cea mai bună performanță în evaluarea extrinsică prin analizarea dependenței. Codul sursă este lansat la https://github.com/ufal/multilexnorm2021 şi modelele reglate fin la https://huggingface.co/ufal.</abstract_ro>
      <abstract_sr>Predstavljamo dobitni ulaz na višejezičku leksičku normalizaciju (MultiLexNorm) zajedničku zadatak na W-NUT 2021 (van der Goot et al., 2021a), koji procjenjuje sisteme leksičke normalizacije na 12 socijalnih medijskih podataka na 11 jezika. Mi baziramo naše rješenje na predobučenom jezičkom modelu na nivou bajtova, ByT5 (Xue et al., 2021a), koji smo dalje predobučavali sintetičke podatke, a zatim potpuno srediti autentične normalizacije podataka. Naš sistem postiže najbolju izvršnost širom marginom u unutrašnjoj procjeni, kao i najbolju izvršnost ekstrinske procjene kroz analizu zavisnosti. Izvorni kod je objavljen na https://github.com/ufal/multilexnorm2021 i dobre modele u https://huggingface.co/ufal.</abstract_sr>
      <abstract_si>අපි ජයග්‍රාවක් ඇතුළට පෙන්වන්නේ වැඩි භාෂාවක් ලෙක්සිකාල් සාමාජික සංවේදනය (MultiLexNorm) වෙනුවෙන් වැඩි වැඩක් W-NuT 2021 (van der Goot et al., 2021a), මෙයා ලෙක්සික අපි අපේ විස්තරය ප්‍රීක්ෂණා කරපු බායිට් ස්තූතිය භාෂාවක් නිර්මාණයෙන්, ByT5 (Xue et al., 2021a), ඒක අපි තව ප්‍රීක්ෂණා කරපු විස්තර දත්ත සඳහා ප අපේ පද්ධතිය හොඳම ක්‍රියාත්මක විශේෂයෙන් විශාල ප්‍රමාණයක් වෙනුවෙන් හොඳම ක්‍රියාත්මක විශේෂ කරනවා, සහ ප්‍රමාණ මූල කෝඩ් නිදහස් කරලා තියෙනවා https://github.com/ufal/multilexnorm2021 ඒ වගේම හොඳ සැලසුම් විදියට https://huggingface.co/ufal.</abstract_si>
      <abstract_so>Waxaannu u soo bandhignaynaa guuleynta guulaysashada Luqadaha badan ee Leksikal Normalization (MultiLexNorm) oo lagu qaybsaday shaqada W-NUT 2021 (van der Goot et al., 2021a), kaas oo qiimeynaya nidaamka lexical-normalization ee 12 macluumaadka bulshada ah oo ku qoran 11 luqadood. Xaruntanada waxaynu ku saleynnaa model afka hore oo lagu tababaray barashada, ByT5 (Xue et, 2021a), kaas oo aynu horay ugu sii bandhignaynaa macluumaadka heshiiska, kadibna si fiican ugu qornaa macluumaadka rasmiga ah. nidaamkayagu wuxuu gaadhaa sameynta ugu wanaagsan baaritaanka baaritaanka gudaha ah iyo sidoo kale qiimeynta ugu wanaagsan baaritaanka dibadda ee ku saabsan baaritaanka ku xiran. Kaarka asalka ayaa lagu furaa https://github.com/ufal/multilexnorm2021 iyo modelalka qurxoonaa https://huggingface.co/ufal.</abstract_so>
      <abstract_sv>Vi presenterar det vinnande bidraget till den flerspråkiga Lexical Normalization (MultiLexNorm) delade uppgiften vid W-NUT 2021 (van der Goot et al., 2021a), som utvärderar lexikala normaliseringssystem på 12 sociala mediedataset på 11 språk. Vi baserar vår lösning på en förintränad byte-nivå språkmodell, ByT5 (Xue et al., 2021a), som vi vidareutbildar på syntetiska data och sedan finjusterar på autentiska normaliseringsdata. Vårt system uppnår den bästa prestandan med en bred marginal i intern utvärdering, och även den bästa prestandan i extrinsk utvärdering genom beroendetolkning. Källkoden släpps på https://github.com/ufal/multilexnorm2021 och de finjusterade modellerna vid https://huggingface.co/ufal.</abstract_sv>
      <abstract_ta>நாங்கள் வெற்றி நுழைவை பல மொழி லெக்சியல் இயல்பானத்திற்கு (பல லெக்சியல் Normalization) பங்கிடப்பட்ட பணி நாம் முன் பயிற்சி செய்யப்பட்ட பைட்- நிலை மொழி மாதிரி மாதிரியில் தீர்வை அடிப்படையிடுகிறோம், ByT5 (ஜூ et., 2021a), அதை நாம் மேலும் தொடர்ந்து கொள்ள ம நம்முடைய அமைப்பு சிறந்த செயல்பாடு பெறுகிறது உள்ளார்ந்த மதிப்பில், மற்றும் சார்ந்த பாடல் மூலம் சார்ந்த சார்ந்த மதிப்பில் ச மூல குறியீடு வெளியிடப்பட்டது https://github.com/ufal/multilexnorm2021 மேலும் சிறந்த மாதிரிகளில் https://huggingface.co/ufal.</abstract_ta>
      <abstract_ur>ہم نے بہت سی زبان کی لکسیکل Normalization (MultiLexNorm) کو W-NUT 2021 (van der Goot et al., 2021a) میں مشترک کام کے ذریعے پیغام پہنچا دیتے ہیں جو 12 سوسیل میڈیا ڈیٹسٹ میں لکسیکل-عامل سیستموں کا ارزش کرتا ہے۔ ہم نے اپنے حل کو ایک پیش آموزش کے بائیٹ سطح کی زبان موڈل پر بنیاد رکھا ہے ByT5 (Xue et al., 2021a) جسے ہم اس سے پہلے سینٹیٹیک ڈیٹے پر ترین کریں اور پھر سچائی نارمولیزی ڈیٹے پر اچھا ترین کریں۔ ہماری سیستم ایک گھیری مقدار کے ذریعہ سے بہترین عمل پہنچاتا ہے، اور نیک ارزش کے ذریعہ بھی بہترین عمل کرتا ہے. سورس کوڈ اس میں منتشر کیا گیا ہے https://github.com/ufal/multilexnorm2021 اور بہترین نمونے https://huggingface.co/ufal.</abstract_ur>
      <abstract_vi>Chúng tôi giới thiệu mục đích thắng cuộc cho hệ thống ngôn ngữ tự kỉ (đa LexNorm) chia sẻ nhiệm vụ ở W-Giờ 2021 (van der Goot et al., 2021), đánh giá hệ thống quy phục văn học trên 12 bộ dữ liệu mạng xã hội bằng ngôn ngữ 11. Căn cứ giải pháp này dựa trên mô hình ngôn ngữ byte đã được đào tạo sẵn, Byzantium (Xu et al., 2021), chúng tôi sẽ tiến hành trước nghiên cứu thông tin tổng hợp và chỉnh sửa bằng dữ liệu bình thường đích thực. Hệ thống của chúng ta đạt được hiệu quả tốt nhất nhờ một khoảng cách rộng lớn trong việc đánh giá nội bộ, cũng như khả năng cao nhất trong việc đánh giá phụ thuộc qua cách phân tích. Nguồn mã được phát ra tại https://github.com/ufal/multilexnorm2021 và các mô hình chỉnh sửa tại https://huggingface.co/ufal.</abstract_vi>
      <abstract_uz>Biz bir necha tillar Leksikal Normalizatsiya (MultiLexNorm) vazifasi W-NUT 2021 (van der Goot et al., 2021a) bilan birlashtirilgan vazifani hozir qilamiz. Bu 11 tillarda leksikal- normalization tizimini qiymatga ega. Biz oldin o'rganilgan bayt darajasi modeli ByT5 (Xue et, 2021a) bilan o'qitumiz. Biz bunday bir nechta bir tizim haqiqiqiy taʼminlovchi maʼlumot haqida o'rganamiz. Bizning tizimmiz ichki qiymatda juda yaxshi narsa topadi, va tashqi qiymatda ishlab chiqarishni tasavvur qiladi. Manba kodi https://github.com/ufal/multilexnorm2021  and the fine-tuned models at  https://huggingface.co/ufal.</abstract_uz>
      <abstract_bg>Представяме победителя в споделената задача за многоезична лексикална нормализация (която оценява лексикално-нормализиращи системи на 12 набора от данни в социалните медии на 11 езика. Основаваме решението си на предварително обучен езиков модел на ниво байт, който допълнително предварително обучаваме на синтетични данни и след това фино настройваме на автентични данни за нормализация. Нашата система постига най-доброто представяне чрез широк марж в вътрешната оценка, както и най-доброто представяне в външната оценка чрез анализ на зависимостта. Изходният код се издава на https://github.com/ufal/multilexnorm2021 и фино настроените модели на https://huggingface.co/ufal.</abstract_bg>
      <abstract_hr>Predstavljamo pobjednički ulaz na višejezičku leksičku normalizaciju (MultiLexNorm) zajednički zadatak na W-NUT 2021 (van der Goot et al., 2021a), koji procjenjuje sisteme leksičke normalizacije na 12 podataka socijalnih medija na 11 jezika. Mi baziramo naše rješenje na predobučenom jezičkom modelu na nivou bajtova ByT5 (Xue et al., 2021a), kojim smo dalje predobučili sintetičke podatke, a zatim potpuno srediti autentične normalizacije podataka. Naš sustav postiže najbolji učinkovit širom marginom u unutrašnjoj procjeni, kao i najbolji učinkoviti u vanjskoj procjeni kroz analizu zavisnosti. Izvorni kod je objavljen na https://github.com/ufal/multilexnorm2021 i dobri modeli https://huggingface.co/ufal.</abstract_hr>
      <abstract_nl>We presenteren de winnende inzending voor de gedeelde taak Multilingual Lexical Normalization (MultiLexNorm) op W-NUT 2021 (van der Goot et al., 2021a), die lexicaal-normalisatiesystemen evalueert op 12 social media datasets in elf talen. We baseren onze oplossing op een vooraf getraind byte-level taalmodel, ByT5 (Xue et al., 2021a), dat we verder trainen op synthetische data en vervolgens finetunen op authentieke normalisatiegegevens. Ons systeem bereikt de beste prestaties met een brede marge in intrinsieke evaluatie, en ook de beste prestaties in extrinsische evaluatie door afhankelijkheidsparsing. De broncode wordt vrijgegeven op: https://github.com/ufal/multilexnorm2021 en de verfijnde modellen op https://huggingface.co/ufal.</abstract_nl>
      <abstract_da>Vi præsenterer vinderen til den flersprogede Lexical Normalization (MultiLexNorm) delte opgave på W-NUT 2021 (van der Goot et al., 2021a), som evaluerer leksikalsnormaliseringssystemer på 12 sociale medier datasæt på 11 sprog. Vi baserer vores løsning på en prætrænet byte-niveau sprogmodel, ByT5 (Xue et al., 2021a), som vi yderligere forudtræner på syntetiske data og derefter finjusterer på autentiske normaliseringsdata. Vores system opnår den bedste ydeevne ved en bred margin i iboende evaluering, og også den bedste ydeevne i ekstern evaluering gennem afhængighedsparsing. Kildekoden udgives på https://github.com/ufal/multilexnorm2021 og de finjusterede modeller på https://huggingface.co/ufal.</abstract_da>
      <abstract_de>Wir präsentieren den Siegerbeitrag zur gemeinsamen Aufgabe Multilingual Lexical Normalization (MultiLexNorm) auf der W-NUT 2021 (van der Goot et al., 2021a), die lexikalisch-normalisierende Systeme auf 12 Social Media Datensätzen in 11-Sprachen evaluiert. Unsere Lösung basiert auf einem vortrainierten Byte-Level-Sprachmodell, ByT5 (Xue et al., 2021a), das wir auf synthetischen Daten vortrainieren und anschließend auf authentischen Normalisierungsdaten verfeinern. Unser System erreicht die beste Leistung bei der intrinsischen Evaluation mit einem breiten Spielraum, und auch die beste Leistung bei der extrinsischen Evaluation durch Dependency Parsing. Der Quellcode wird veröffentlicht unter https://github.com/ufal/multilexnorm2021 und die fein abgestimmten Modelle bei https://huggingface.co/ufal.</abstract_de>
      <abstract_id>Kami mempersembahkan masukan yang menang ke Multilingual Lexical Normalization (MultiLexNorm) tugas berbagi di W-NUT 2021 (van der Goot et al., 2021a), yang mengevaluasi sistem lexical-normalization pada 12 set data media sosial dalam 11 bahasa. Kami mendasarkan solusi kami pada model bahasa tahap byte yang dilatih-dilatih, ByT5 (Xue et al., 2021a), yang kami melanjutkan melatih-melatih pada data sintetis dan kemudian fine-tune pada data normalisasi autentik. Sistem kita mencapai prestasi terbaik dengan margin lebar dalam evaluasi intrinsik, dan juga prestasi terbaik dalam evaluasi extrinsic melalui pemeriksaan dependensi. Kode sumber dibebaskan di https://github.com/ufal/multilexnorm2021 Dan model yang disesuaikan di https://huggingface.co/ufal.</abstract_id>
      <abstract_ko>우리는 W-NUT 2021(van der Goot et al., 2021a)에서 11개 언어의 12개 소셜미디어 데이터 세트의 어휘 규범화 시스템을 평가한 다국어 어휘 규범화(MultiLex Norm) 공유 임무의 수상작을 선보였다.우리의 해결 방안은 사전에 훈련된 바이트급 언어 모델인 ByT5(Xue 등, 2021a)를 바탕으로 합성 데이터에 대해 예비 훈련을 한 다음에 실제 규범화된 데이터를 미세하게 조정한다.우리 시스템은 어느 정도에 최상의 내재적 평가 성능을 실현했고 해석에 의존하여 최상의 외재적 평가 성능을 실현했다.소스 코드 게시https://github.com/ufal/multilexnorm2021그리고https://huggingface.co/ufal.</abstract_ko>
      <abstract_sw>We present the winning entry to the Multilingual Lexical Normalization (MultiLexNorm) shared task at W-NUT 2021 (van der Goot et al., 2021a), which evaluates lexical-normalization systems on 12 social media datasets in 11 languages.  Tunaweza kuweka suluhisho letu juu ya modeli ya lugha ya lugha iliyoendeshwa kabla, ByT5 (Xue et, 2021a), ambazo tunaendelea treni zaidi kuhusu takwimu za ufuatiliaji na kisha tuweke vizuri juu ya taarifa za uhalisia. Mfumo wetu unafanikiwa ufanisi mzuri zaidi kwa kiasi kikubwa katika uchunguzi wa ndani, na pia utendaji bora zaidi katika uchunguzi wa nje kwa kupitia wimbo wa kutegemea. Kodi la chanzo limetolewa kwenye https://github.com/ufal/multilexnorm2021 na mifano nzuri katika https://huggingface.co/ufal.</abstract_sw>
      <abstract_fa>ما وارد پیروزی را به وظیفه‌ی تعداد‌های متعدد زبان‌ها (MultiLexNorm) در W-NUT 2021 (van der Goot et al., 2021a) نشان می‌دهیم که سیستم‌های تعداد‌های داده‌های اجتماعی در ۱۱ زبان ارزش می‌دهد. ما راه حل خود را بر یک مدل زبان سایت‌سطح پیش آموزش داده‌ایم ByT5 (Xue et al., 2021a) که پیش از آن روی داده‌های سناتیک آموزش می‌دهیم و بعد از آن روی داده‌های سناتیک تحریک می‌کنیم. سیستم ما بهترین عملکرد را با یک مرز گسترده در ارزیابی داخلی می رساند، و همچنین بهترین عملکرد در ارزیابی خارجی از طریق بررسی بستگی. کد منبع در https://github.com/ufal/multilexnorm2021 و مدل‌های نیکویی https://huggingface.co/ufal.</abstract_fa>
      <abstract_tr>Biz MultiLexNorm'yň (MultiLexNorm) W-NUT 2021 (van der Goot et al., 2021a) ýeňiji çykyş sistemalaryny 11 dilde çykyş edip, beýleki düzenlemek sistemalaryny çykarýarys. Biz özümiziň çözümüzü öňünden eğlenen baýt düzeden bir nusga görýäris, ByT5 (Xue et al., 2021a) we bu nusga syntetik maglumaty üstünde öňünden geçirip, soňra awtentifik normalizasyon maglumaty üstine süýtgedik. Bizim sistemimiz iç değerlendirmede geniş bir gabat tarafından iň gowy etkinlik başarýar we daşarylyk değerlendirmede en gowy etkinlik başarýar. %s-iň üstine bellenilýär. https://github.com/ufal/multilexnorm2021 Hassalary bilen düzelenýän nusgalar https://huggingface.co/ufal.</abstract_tr>
      <abstract_af>Ons stel die vinnige inskrywing aan die Multilingual Lexical Normalisation (MultiLexNorm) gedeelde taak by W-NUT 2021 (van der Goot et al., 2021a), wat evalueer lexical-normalisation stelsels op 12 sosiale media datastelle in 11 tale. Ons basiseer ons oplossing op 'n vooraf-opgelei byte-vlak taal model ByT5 (Xue et al., 2021a), wat ons verder vooraf-trein op sintetiese data en dan fin-tune op outentiese normaliseringsdata. Ons stelsel bereik die beste prestasie deur 'n wyde marjin in intrinsiese evaluering, en ook die beste prestasie in ekstrinsiese evaluering deur afhanklikheidsverking. Die bronkode is verlos by https://github.com/ufal/multilexnorm2021 en die fine-tuned modele https://huggingface.co/ufal.</abstract_af>
      <abstract_am>በ12 ማኅበራዊ አውታር ሚዲያዎች ዳታዎችን በአሥራ 11 ቋንቋዎች ላይ በሚያስተካክሉ ሌክሲካል-normalization ስርዓት እናሳውቃለን፡፡ ለቀድሞ ተማሪ የልዩ ደረጃ ቋንቋ ምሳሌ ByT5 (Xue et., 2021a) እናገራለን፡፡ Our system achieves the best performance by a wide margin in intrinsic evaluation, and also the best performance in extrinsic evaluation through dependency parsing.  ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s https://github.com/ufal/multilexnorm2021 እናም መልካሞቹ ሞዴላዎች https://huggingface.co/ufal.</abstract_am>
      <abstract_hy>Մենք ներկայացնում ենք բազլեզու Լեքսիկալ Նորմալիզացիայի (ՄուլիլեքսՆորմ) հաղթանակի հաղթանակը W-NOT 2021-ում (van der Goot et al., 2021a), որը գնահատում է լեքսիկալ-նորմալիզացիայի համակարգերը 12 սոցիալական լրատվամիջոցների տվյալների համակարգերի 11 լեզուներ Մենք հիմնում ենք մեր լուծումը նախապատրաստված բայթի մակարդակի լեզվի մոդելի վրա, ԲիՏ5 (Xgue և այլն., 2021a), որը մենք նախապատրաստում ենք սինթետիկ տվյալների վրա և հետո բարձրացնում ենք ինքնատիվ նորմալիզացիայի տվյալների վրա: Մեր համակարգը հասնում է լավագույն արդյունքներին ներքին գնահատման մեջ, ինչպես նաև արտաքին գնահատման մեջ լավագույն արդյունքներին կախվածության վերլուծության միջոցով: Առաջին կոդը հրապարակում է https://github.com/ufal/multilexnorm2021 - և բարձրացված մոդելները https://huggingface.co/ufal.</abstract_hy>
      <abstract_sq>Ne paraqesim hyrjen fituese në detyrën e përbashkët Multilingual Lexical Normalization (MultiLexNorm) në W-NUT 2021 (van der Goot et al., 2021a), e cila vlerëson sistemet e normalizimit lexik në 12 datasets të medias sociale në 11 gjuhë. Ne bazojmë zgjidhjen tonë në një model gjuhësh të paratrajnuar në nivel byte, ByT5 (Xue et al., 2021a), të cilin e paratrajnojmë më tej në të dhënat sintetike dhe pastaj e përshtasim në të dhënat e normalizimit autentik. Sistemi ynë arrin performancën më të mirë me një margen të gjerë në vlerësimin e brendshëm dhe gjithashtu performancën më të mirë në vlerësimin e jashtëm nëpërmjet analizimit të varësisë. Kodi burimi është lëshuar në https://github.com/ufal/multilexnorm2021 Dhe modelet e rregulluara në https://huggingface.co/ufal.</abstract_sq>
      <abstract_bn>আমরা মাল্টিভুয়াল লেক্সিকাল লেক্সিক্যাল স্বাভাবিক স্বাভাবিক ভাষায় বিজয়ী প্রবেশের সামনে উপস্থিত করছি ডি-এনউট ২০২১ (ভান দের গুট এল, ২০২১), যা ১২ ভাষায় লেক্সিক্ আমরা পূর্ব প্রশিক্ষিত বাইট-স্তরের ভাষার মডেলের উপর আমাদের সমাধান নির্ধারণ করি, বাইটি৫ (জুe et al., 2021a), যা আমরা সিন্টেটিক ডাটা সম্পর্কে আরো ট্রেনে যাই এবং তারপর সত্ Our system achieves the best performance by a wide margin in intrinsic evaluation, and also the best performance in extrinsic evaluation through dependency parsing.  সোর্স কোড মুক্ত করা হয়েছে https://github.com/ufal/multilexnorm2021 এবং সুন্দর মডেল https://huggingface.co/ufal.</abstract_bn>
      <abstract_ca>Presentam la entrada guanyadora a la tasca compartida Multilingual Lexical Normalization (MultiLexNorm) a W-NUT 2021 (van der Goot et al., 2021a), que evalua els sistemes de normalització lexical en 12 conjunts de dades dels mitjans socials en 11 llengües. We base our solution on a pre-trained byte-level language model, ByT5 (Xue et al., 2021a), which we further pre-train on synthetic data and then fine-tune on authentic normalization data.  El nostre sistema aconsegueix el millor rendiment amb un gran marge en l'evaluació intrínseca, i també el millor rendiment en l'evaluació extrínsica mitjançant l'analisi de la dependencia. El codi fonts s'allibera a https://github.com/ufal/multilexnorm2021 i els models millorats https://huggingface.co/ufal.</abstract_ca>
      <abstract_cs>Představujeme vítězný příspěvek k sdílenému úkolu Multilingual Lexical Normalization (MultiLexNorm) na W-NUT 2021 (van der Goot et al., 2021a), který hodnotí lexikálně-normalizační systémy na 12 datových sadách sociálních médií v 11 jazycích. Naše řešení vychází z předškoleného jazykového modelu ByT5 (Xue et al., 2021a), který dále předškolíme na syntetických datech a následně doladíme na autentických normalizačních datech. Náš systém dosahuje nejlepšího výkonu širokým rozpětím při vnitřním hodnocení a také nejlepšího výkonu v extrinsickém hodnocení prostřednictvím analýzy závislostí. Zdrojový kód je uvolněn na adrese https://github.com/ufal/multilexnorm2021 a jemně vyladěné modely na https://huggingface.co/ufal.</abstract_cs>
      <abstract_et>Esitleme võidutööd mitmekeelse leksikaalse normaliseerimise (MultiLexNorm) jagatud ülesandes W-NUT 2021 (van der Goot et al., 2021a), mis hindab leksikaalse normaliseerimise süsteeme 12 sotsiaalmeedia andmekogumil 11 keeles. Meie lahendus tugineb eelkoolitud baiditaseme keelemudelile ByT5 (Xue et al., 2021a), mida edaspidi eelkoolitame sünteetilistel andmetel ja seejärel täpsustame autentseid normaliseerimisandmeid. Meie süsteem saavutab parima jõudluse laia marginaaliga sisemises hindamises ja ka parima jõudluse välises hindamises sõltuvuse parsimise kaudu. Lähtekood avaldatakse aadressil https://github.com/ufal/multilexnorm2021 ja täpselt häälestatud mudelid https://huggingface.co/ufal.</abstract_et>
      <abstract_fi>Esittelemme voittaneen teoksen Multilingual Lexical Normalization (MultiLexNorm) -yhteiseen teht瓣v瓣瓣n W-NUT 2021 (van der Goot et al., 2021a), jossa arvioidaan sanastonormalisointij瓣rjestelmi瓣 12 sosiaalisen median aineistossa 11 kielell瓣. Perustamme ratkaisumme esikoulutettuun tavutason kielimalliin ByT5 (Xue et al., 2021a), jota edelleen esikoulutamme synteettiseen dataan ja hienos瓣瓣d瓣mme autenttisiin normalisointitietoihin. J瓣rjestelm瓣mme saavuttaa parhaan suorituskyvyn laajalla marginaalilla sis瓣isess瓣 arvioinnissa sek瓣 parhaan suorituskyvyn ulkoisessa arvioinnissa riippuvuuden j瓣sent瓣misen avulla. L瓣hdekoodi julkaistaan osoitteessa https://github.com/ufal/multilexnorm2021 ja hienos瓣瓣detyt mallit https://huggingface.co/ufal.</abstract_fi>
      <abstract_bs>Predstavljamo pobjednički ulaz na višejezičku leksičku normalizaciju (MultiLexNorm) zajednički zadatak na W-NUT 2021 (van der Goot et al., 2021a), koji procjenjuje sisteme leksičke normalizacije na 12 dataseta socijalnih medija na 11 jezika. Mi baziramo naše rješenje na predobučenom jezičkom modelu na nivou bajtova ByT5 (Xue et al., 2021a), koji smo dalje predobučili sintetičke podatke, a zatim potpuno srediti autentične normalizacije podataka. Naš sistem postigne najbolje izvršenje širom marginom unutrašnje procjene, kao i najbolje izvršenje ekstrinske procjene kroz analizu zavisnosti. Izvorni kod je objavljen na https://github.com/ufal/multilexnorm2021 I dobre modele u https://huggingface.co/ufal.</abstract_bs>
      <abstract_az>Biz çoxlu dilli Lexical Normalization (MultiLexNorm) W-NUT 2021 (van der Goot et al., 2021a) paylaşıb paylaşın işi göstəririk ki, 12 sosyal mediya veri qurularında leksik-normalizasyon sistemlərini 11 dildə değerlendirir. Biz çözümüzü öyrəndiyimiz bajt səviyyəsi dili modeli, ByT5 (Xue et al., 2021a) ilə təyin edirik. Biz sintetik məlumatlarını daha öncə təyin edirik və sonra həqiqət normalizasyon məlumatlarını təyin edirik. Sistemimiz ən yaxşı performansımızı içəri çətinliklərdə çox çətinliklərlə, həmçin in bağımlılıq analizi vasitəsilə extrinsic değerlendirmədə ən yaxşı performansımızı başa çatdırır. Kaynak kodu açılır https://github.com/ufal/multilexnorm2021 və düzəldilmiş modellər https://huggingface.co/ufal.</abstract_az>
      <abstract_sk>Predstavljamo zmagovalni vpis v skupno nalogo MultiLexNorm (MultiLexNorm) na W-NUT 2021 (van der Goot et al., 2021a), ki ocenjuje leksikalno-normalizacijske sisteme na 12 naborih podatkov družbenih omrežij v 11 jezikih. Našo rešitev temelji na vnaprej usposobljenem bajtnem jezikovnem modelu ByT5 (Xue et al., 2021a), ki ga nadalje predtreniramo na sintetičnih podatkih in nato natančno nastavimo na pristnih normalizacijskih podatkih. Naš sistem dosega najboljšo učinkovitost s širokim robom v notranjem vrednotenju, pa tudi najboljšo učinkovitost pri zunanjem vrednotenju z razčlenitvijo odvisnosti. Izvorna koda se objavi na https://github.com/ufal/multilexnorm2021 in natančno nastavljene modele na https://huggingface.co/ufal.</abstract_sk>
      <abstract_ha>Tuna halatar da ta rinjãya zuwa masu multi-linguin Leksalization (multi-LexNorthm) mai raba aiki a W-NUT 2021 (van der Got et al., 2021a), wanda ke ƙaddara tsarin leksikal-normal a kan 12-tsaro na zane-zane cikin zane 11. Mu ƙayyade suluyinmu a kan wata misãlin-zaman mai bayt-daraja, ByT5 (Hue et, 2021a), wanda Muke ƙara gaba-togi kan data na synthetic, sa'an nan kuma ka sami mai kyau kan data na daidaita. TsarinMu ya sami mafiya kyakkyawan aiki da ke cikin muhimmi guda, kuma da mafi kyaun aikin muhimmada a kan muhimmada a bakin bayani. Ana sakar da kodi na source https://github.com/ufal/multilexnorm2021 da misãlai mai kyau a kan https://huggingface.co/ufal.</abstract_ha>
      <abstract_he>אנחנו מציגים את הכניסה המנצחת לנורמליזציה לקסיקנית רבולוגית (MultiLexNorm) המשימה המשותפת ב-W-NUT 2021 (van der Goot et al., 2021a), אשר מעריכה מערכות נורמליזציה לקסיקנית ב-12 קבוצות נתונים של מדיה חברתית ב-11 שפות. אנחנו מבססים את הפתרון שלנו על מודל שפת רמת בייט מאומן מראש, ByT5 (Xue et al., 2021a), שאנחנו ממשיכים להתאמן מראש על נתונים סינטטיים ואז להתאים על נתונים נורמליזציה אוטוטיים. המערכת שלנו משיגה את ההופעה הטובה ביותר על ידי גבול רחב בערכה פנימית, וגם את ההופעה הטובה ביותר בערכה פנימית דרך בדיקת תלויות. קוד המקור משוחרר ב https://github.com/ufal/multilexnorm2021 והדוגמנים המתאימים https://huggingface.co/ufal.</abstract_he>
      <abstract_jv>Awak dhéwé nggawe barang pengguna nggawe Multilanguage Leksial Normalizer We basa dhéwé kaluwargane ning model sing preransferéng banter, bajil (Xu et al, 2020 1a), dadi sing wis mulai banter, podête sistem sistem sing wis ana, sak sistêm nggunaké mulai, dadi sing diranggunaké etik tau. Sistem dhéwé iso nggawe akeh sing luwih dumadhi iki, nik akeh lanjut cara-lanjut sing gak dhéwé. Sistem dhéwé iso nggawe akeh lanjut cara-lanjut iso nggawe lanjut cara-lanjut sing paling dhéwé. Sumber kode mbukak ing kene https://github.com/ufal/multilexnorm2021 Jejaring https://huggingface.co/ufal.</abstract_jv>
      <abstract_bo>We present the winning entry to the Multilingual Lexical Normalization (MultiLexNorm) shared task at W-NUT 2021 (van der Goot et al., 2021a), which evaluates lexical-normalization systems on 12 social media datasets in 11 languages. ང་ཚོའི་ཐབས་ཤེས་འདོད་དག་གི་སྔོན་སྒྲིག་འཛུགས་པའི་བྱ་ཚིག་གི་དཔེ་གཞི་(Xue et al., 2021a)ཡིན། ང་ཚོའི་མ་ལག ཐོག་མའི་ཨང་རིས་འདིའི་ནང་དུ་ཉར་ཚར་བ https://github.com/ufal/multilexnorm2021 fine-tuned models at http://www.google.com/search?ie=UTF-8oe=UTF-8 https://huggingface.co/ufal.</abstract_bo>
      </paper>
    </volume>
</collection>