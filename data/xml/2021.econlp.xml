<collection id="2021.econlp">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Economics and Natural Language Processing</booktitle>
      <editor><first>Udo</first><last>Hahn</last></editor>
      <editor><first>Veronique</first><last>Hoste</last></editor>
      <editor><first>Amanda</first><last>Stent</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="4e91a557">2021.econlp-1.0</url>
      <bibkey>econlp-2021-economics</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Fine-Grained Annotated Corpus for Target-Based Opinion Analysis of Economic and Financial Narratives</title>
      <author><first>Jiahui</first><last>Hu</last></author>
      <author><first>Patrick</first><last>Paroubek</last></author>
      <pages>1&#8211;12</pages>
      <abstract>In this paper about aspect-based sentiment analysis (ABSA), we present the first version of a fine-grained annotated corpus for target-based opinion analysis (TBOA) to analyze economic activities or financial markets. We have annotated, at an intra-sentential level, a corpus of sentences extracted from documents representative of financial analysts&#8217; most-read materials by considering how financial actors communicate about the evolution of event trends and analyze related publications (news, official communications, etc.). Since we focus on identifying the expressions of opinions related to the economy and financial markets, we annotated the sentences that contain at least one subjective expression about a domain-specific term. Candidate sentences for annotations were randomly chosen from texts of specialized press and professional information channels over a period ranging from 1986 to 2021. Our annotation scheme relies on various linguistic markers like domain-specific vocabulary, syntactic structures, and rhetorical relations to explicitly describe the author&#8217;s subjective stance. We investigated and evaluated the recourse to automatic pre-annotation with existing natural language processing technologies to alleviate the annotation workload. Our aim is to propose a corpus usable on the one hand as training material for the automatic detection of the opinions expressed on an extensive range of domain-specific aspects and on the other hand as a gold standard for evaluation TBOA. In this paper, we present our pre-annotation models and evaluations of their performance, introduce our annotation scheme and report on the main characteristics of our corpus.</abstract>
      <url hash="06570a64">2021.econlp-1.1</url>
      <bibkey>hu-paroubek-2021-fine</bibkey>
      <doi>10.18653/v1/2021.econlp-1.1</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="2">
      <title><fixed-case>EDGAR</fixed-case>-<fixed-case>CORPUS</fixed-case>: Billions of Tokens Make The World Go Round</title>
      <author><first>Lefteris</first><last>Loukas</last></author>
      <author><first>Manos</first><last>Fergadiotis</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <pages>13&#8211;18</pages>
      <abstract>We release EDGAR-CORPUS, a novel corpus comprising annual reports from all the publicly traded companies in the US spanning a period of more than 25 years. To the best of our knowledge, EDGAR-CORPUS is the largest financial NLP corpus available to date. All the reports are downloaded, split into their corresponding items (sections), and provided in a clean, easy-to-use JSON format. We use EDGAR-CORPUS to train and release EDGAR-W2V, which are WORD2VEC embeddings for the financial domain. We employ these embeddings in a battery of financial NLP tasks and showcase their superiority over generic GloVe embeddings and other existing financial word embeddings. We also open-source EDGAR-CRAWLER, a toolkit that facilitates downloading and extracting future annual reports.</abstract>
      <url hash="7cc0391b">2021.econlp-1.2</url>
      <bibkey>loukas-etal-2021-edgar</bibkey>
      <doi>10.18653/v1/2021.econlp-1.2</doi>
      <pwccode url="https://github.com/nlpaueb/edgar-crawler" additional="false">nlpaueb/edgar-crawler</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/edgar-corpus">EDGAR-CORPUS</pwcdataset>
    </paper>
    <paper id="3">
      <title>The Global Banking Standards <fixed-case>QA</fixed-case> Dataset (<fixed-case>GBS</fixed-case>-<fixed-case>QA</fixed-case>)</title>
      <author><first>Kyunghwan</first><last>Sohn</last></author>
      <author><first>Sunjae</first><last>Kwon</last></author>
      <author><first>Jaesik</first><last>Choi</last></author>
      <pages>19&#8211;25</pages>
      <abstract>A domain specific question answering (QA) dataset dramatically improves the machine comprehension performance. This paper presents a new Global Banking Standards QA dataset (GBS-QA) in the banking regulation domain. The GBS-QA has three values. First, it contains actual questions from market players and answers from global rule setter, the Basel Committee on Banking Supervision (BCBS) in the middle of creating and revising banking regulations. Second, financial regulation experts analyze and verify pairs of questions and answers in the annotation process. Lastly, the GBS-QA is a totally different dataset with existing datasets in finance and is applicable to stimulate transfer learning research in the banking regulation domain.</abstract>
      <url hash="cc80d688">2021.econlp-1.3</url>
      <bibkey>sohn-etal-2021-global</bibkey>
      <doi>10.18653/v1/2021.econlp-1.3</doi>
    </paper>
    <paper id="4">
      <title>Corporate Bankruptcy Prediction with Domain-Adapted <fixed-case>BERT</fixed-case></title>
      <author><first>Alex Gunwoo</first><last>Kim</last></author>
      <author><first>Sangwon</first><last>Yoon</last></author>
      <pages>26&#8211;36</pages>
      <abstract>This study performs BERT-based analysis, which is a representative contextualized language model, on corporate disclosure data to predict impending bankruptcies. Prior literature on bankruptcy prediction mainly focuses on developing more sophisticated prediction methodologies with financial variables. However, in our study, we focus on improving the quality of input dataset. Specifically, we employ BERT model to perform sentiment analysis on MD&amp;A disclosures. We show that BERT outperforms dictionary-based predictions and Word2Vec-based predictions in terms of adjusted R-square in logistic regression, k-nearest neighbor (kNN-5), and linear kernel support vector machine (SVM). Further, instead of pre-training the BERT model from scratch, we apply self-learning with confidence-based filtering to corporate disclosure data (10-K). We achieve the accuracy rate of 91.56% and demonstrate that the domain adaptation procedure brings a significant improvement in prediction accuracy.</abstract>
      <url hash="570b9d58">2021.econlp-1.4</url>
      <bibkey>kim-yoon-2021-corporate</bibkey>
      <doi>10.18653/v1/2021.econlp-1.4</doi>
    </paper>
    <paper id="9">
      <title>To What Extent Can <fixed-case>E</fixed-case>nglish-as-a-Second Language Learners Read Economic News Texts?</title>
      <author><first>Yo</first><last>Ehara</last></author>
      <pages>62&#8211;68</pages>
      <abstract>In decision making in the economic field, an especially important requirement is to rapidly understand news to absorb ever-changing economic situations. Given that most economic news is written in English, the ability to read such information without waiting for a translation is particularly valuable in economics in contrast to other fields. In consideration of this issue, this research investigated the extent to which non-native English speakers are able to read economic news to make decisions accordingly &#8211; an issue that has been rarely addressed in previous studies. Using an existing standard dataset as training data, we created a classifier that automatically evaluates the readability of text with high accuracy for English learners. Our assessment of the readability of an economic news corpus revealed that most news texts can be read by intermediate English learners. We also found that in some cases, readability varies considerably depending on the knowledge of certain words specific to the economic field.</abstract>
      <url hash="fd7d735f">2021.econlp-1.9</url>
      <bibkey>ehara-2021-extent</bibkey>
      <doi>10.18653/v1/2021.econlp-1.9</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
    </paper>
    </volume>
</collection>