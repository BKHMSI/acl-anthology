<collection id="2020.semeval">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Fourteenth Workshop on Semantic Evaluation</booktitle>
      <editor><first>Aurelie</first><last>Herbelot</last></editor>
      <editor><first>Xiaodan</first><last>Zhu</last></editor>
      <editor><first>Alexis</first><last>Palmer</last></editor>
      <editor><first>Nathan</first><last>Schneider</last></editor>
      <editor><first>Jonathan</first><last>May</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <publisher>International Committee for Computational Linguistics</publisher>
      <address>Barcelona (online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="d141a7a7">2020.semeval-1.0</url>
      <bibkey>semeval-2020-semantic</bibkey>
    </frontmatter>
    <paper id="6">
      <title>Discovery Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: Context-sensitive Embeddings Not Always Better than Static for Semantic Change Detection</title>
      <author><first>Matej</first><last>Martinc</last></author>
      <author><first>Syrielle</first><last>Montariol</last></author>
      <author><first>Elaine</first><last>Zosa</last></author>
      <author><first>Lidia</first><last>Pivovarova</last></author>
      <pages>67&#8211;73</pages>
      <abstract>This paper describes the approaches used by the Discovery Team to solve SemEval-2020 Task 1 - Unsupervised Lexical Semantic Change Detection. The proposed method is based on clustering of BERT contextual embeddings, followed by a comparison of cluster distributions across time. The best results were obtained by an ensemble of this method and static Word2Vec embeddings. According to the official results, our approach proved the best for Latin in Subtask 2.</abstract>
      <url hash="083ea248">2020.semeval-1.6</url>
      <bibkey>martinc-etal-2020-discovery</bibkey>
      <doi>10.18653/v1/2020.semeval-1.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>GM</fixed-case>-<fixed-case>CTSC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: <fixed-case>G</fixed-case>aussian Mixtures Cross Temporal Similarity Clustering</title>
      <author><first>Pierluigi</first><last>Cassotti</last></author>
      <author><first>Annalina</first><last>Caputo</last></author>
      <author><first>Marco</first><last>Polignano</last></author>
      <author><first>Pierpaolo</first><last>Basile</last></author>
      <pages>74&#8211;80</pages>
      <abstract>This paper describes the system proposed by the Random team for SemEval-2020 Task 1: Unsupervised Lexical Semantic Change Detection. We focus our approach on the detection problem. Given the semantics of words captured by temporal word embeddings in different time periods, we investigate the use of unsupervised methods to detect when the target word has gained or lost senses. To this end, we define a new algorithm based on Gaussian Mixture Models to cluster the target similarities computed over the two periods. We compare the proposed approach with a number of similarity-based thresholds. We found that, although the performance of the detection methods varies across the word embedding algorithms, the combination of Gaussian Mixture with Temporal Referencing resulted in our best system.</abstract>
      <url hash="51866b0c">2020.semeval-1.7</url>
      <bibkey>cassotti-etal-2020-gm</bibkey>
      <doi>10.18653/v1/2020.semeval-1.7</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>RIJP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: <fixed-case>G</fixed-case>aussian-based Embeddings for Semantic Change Detection</title>
      <author><first>Ran</first><last>Iwamoto</last></author>
      <author><first>Masahiro</first><last>Yukawa</last></author>
      <pages>98&#8211;104</pages>
      <abstract>This paper describes the model proposed and submitted by our RIJP team to SemEval 2020 Task1: Unsupervised Lexical Semantic Change Detection. In the model, words are represented by Gaussian distributions. For Subtask 1, the model achieved average scores of 0.51 and 0.70 in the evaluation and post-evaluation processes, respectively. The higher score in the post-evaluation process than that in the evaluation process was achieved owing to appropriate parameter tuning. The results indicate that the proposed Gaussian-based embedding model is able to express semantic shifts while having a low computational</abstract>
      <url hash="23708d8a">2020.semeval-1.10</url>
      <bibkey>iwamoto-yukawa-2020-rijp</bibkey>
      <doi>10.18653/v1/2020.semeval-1.10</doi>
    </paper>
    <paper id="14">
      <title><fixed-case>U</fixed-case>i<fixed-case>O</fixed-case>-<fixed-case>U</fixed-case>v<fixed-case>A</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: Contextualised Embeddings for Lexical Semantic Change Detection</title>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <author><first>Mario</first><last>Giulianelli</last></author>
      <pages>126&#8211;134</pages>
      <abstract>We apply contextualised word embeddings to lexical semantic change detection in the SemEval-2020 Shared Task 1. This paper focuses on Subtask 2, ranking words by the degree of their semantic drift over time. We analyse the performance of two contextualising architectures (BERT and ELMo) and three change detection algorithms. We find that the most effective algorithms rely on the cosine similarity between averaged token embeddings and the pairwise distances between token embeddings. They outperform strong baselines by a large margin (in the post-evaluation phase, we have the best Subtask 2 submission for SemEval-2020 Task 1), but interestingly, the choice of a particular algorithm depends on the distribution of gold scores in the test set.</abstract>
      <url hash="6f8c0547">2020.semeval-1.14</url>
      <bibkey>kutuzov-giulianelli-2020-uio</bibkey>
      <doi>10.18653/v1/2020.semeval-1.14</doi>
      <pwccode url="https://github.com/akutuzov/semeval2020" additional="false">akutuzov/semeval2020</pwccode>
    </paper>
    <paper id="15">
      <title><fixed-case>BMEAUT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 2: Lexical Entailment with Semantic Graphs</title>
      <author><first>&#193;d&#225;m</first><last>Kov&#225;cs</last></author>
      <author><first>Kinga</first><last>G&#233;mes</last></author>
      <author><first>Andras</first><last>Kornai</last></author>
      <author><first>G&#225;bor</first><last>Recski</last></author>
      <pages>135&#8211;141</pages>
      <abstract>In this paper we present a novel rule-based, language independent method for determining lexical entailment relations using semantic representations built from Wiktionary definitions. Combined with a simple WordNet-based method our system achieves top scores on the English and Italian datasets of the Semeval-2020 task &#8220;Predicting Multilingual and Cross-lingual (graded) Lexical Entailment&#8221; (Glava&#353; et al., 2020). A detailed error analysis of our output uncovers future di- rections for improving both the semantic parsing method and the inference process on semantic graphs.</abstract>
      <url hash="002844d9">2020.semeval-1.15</url>
      <bibkey>kovacs-etal-2020-bmeaut</bibkey>
      <doi>10.18653/v1/2020.semeval-1.15</doi>
    </paper>
    <paper id="16">
      <title><fixed-case>BRUMS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 3: Contextualised Embeddings for Predicting the (Graded) Effect of Context in Word Similarity</title>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <pages>142&#8211;149</pages>
      <abstract>This paper presents the team BRUMS submission to SemEval-2020 Task 3: Graded Word Similarity in Context. The system utilises state-of-the-art contextualised word embeddings, which have some task-specific adaptations, including stacked embeddings and average embeddings. Overall, the approach achieves good evaluation scores across all the languages, while maintaining simplicity. Following the final rankings, our approach is ranked within the top 5 solutions of each language while preserving the 1st position of Finnish subtask 2.</abstract>
      <url hash="3b0c34a9">2020.semeval-1.16</url>
      <bibkey>hettiarachchi-ranasinghe-2020-brums</bibkey>
      <doi>10.18653/v1/2020.semeval-1.16</doi>
      <pwccode url="https://github.com/HHansi/Semeval-2020-Task3" additional="false">HHansi/Semeval-2020-Task3</pwccode>
    </paper>
    <paper id="19">
      <title><fixed-case>UZH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 3: Combining <fixed-case>BERT</fixed-case> with <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Sense Embeddings to Predict Graded Word Similarity Changes</title>
      <author><first>Li</first><last>Tang</last></author>
      <pages>166&#8211;170</pages>
      <abstract>CoSimLex is a dataset that can be used to evaluate the ability of context-dependent word embed- dings for modeling subtle, graded changes of meaning, as perceived by humans during reading. At SemEval-2020, task 3, subtask 1 is about &#8221;predicting the (graded) effect of context in word similarity&#8221;, using CoSimLex to quantify such a change of similarity for a pair of words, from one context to another. Here, a meaning shift is composed of two aspects, a) discrete changes observed between different word senses, and b) more subtle changes of meaning representation that are not captured in those discrete changes. Therefore, this SemEval task was designed to allow the evaluation of systems that can deal with a mix of both situations of semantic shift, as they occur in the human perception of meaning. The described system was developed to improve the BERT baseline provided with the task, by reducing distortions in the BERT semantic space, compared to the human semantic space. To this end, complementarity between 768- and 1024-dimensional BERT embeddings, and average word sense vectors were used. With this system, after some fine-tuning, the baseline performance of 0.705 (uncentered Pearson correlation with human semantic shift data from 27 annotators) was enhanced by more than 6%, to 0.7645. We hope that this work can make a contribution to further our understanding of the semantic vector space of human perception, as it can be modeled with context-dependent word embeddings in natural language processing systems.</abstract>
      <url hash="f01314b6">2020.semeval-1.19</url>
      <bibkey>tang-2020-uzh</bibkey>
      <doi>10.18653/v1/2020.semeval-1.19</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>DCC</fixed-case>-Uchile at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: Temporal Referencing Word Embeddings</title>
      <author><first>Frank D.</first><last>Zamora-Reina</last></author>
      <author><first>Felipe</first><last>Bravo-Marquez</last></author>
      <pages>194&#8211;200</pages>
      <abstract>We present a system for the task of unsupervised lexical change detection: given a target word and two corpora spanning different periods of time, automatically detects whether the word has lost or gained senses from one corpus to another. Our system employs the temporal referencing method to obtain compatible representations of target words in different periods of time. This is done by concatenating corpora of different periods and performing a temporal referencing of target words i.e., treating occurrences of target words in different periods as two independent tokens. Afterwards, we train word embeddings on the joint corpus and compare the referenced vectors of each target word using cosine similarity. Our submission was ranked 7th among 34 teams for subtask 1, obtaining an average accuracy of 0.637, only 0.050 points behind the first ranked system.</abstract>
      <url hash="7b1c00b5">2020.semeval-1.23</url>
      <bibkey>zamora-reina-bravo-marquez-2020-dcc</bibkey>
      <doi>10.18653/v1/2020.semeval-1.23</doi>
    </paper>
    <paper id="26">
      <title><fixed-case>SST</fixed-case>-<fixed-case>BERT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: Semantic Shift Tracing by Clustering in <fixed-case>BERT</fixed-case>-based Embedding Spaces</title>
      <author><first>Vani</first><last>Kanjirangat</last></author>
      <author><first>Sandra</first><last>Mitrovic</last></author>
      <author><first>Alessandro</first><last>Antonucci</last></author>
      <author><first>Fabio</first><last>Rinaldi</last></author>
      <pages>214&#8211;221</pages>
      <abstract>Lexical semantic change detection (also known as semantic shift tracing) is a task of identifying words that have changed their meaning over time. Unsupervised semantic shift tracing, focal point of SemEval2020, is particularly challenging. Given the unsupervised setup, in this work, we propose to identify clusters among different occurrences of each target word, considering these as representatives of different word meanings. As such, disagreements in obtained clusters naturally allow to quantify the level of semantic shift per each target word in four target languages. To leverage this idea, clustering is performed on contextualized (BERT-based) embeddings of word occurrences. The obtained results show that our approach performs well both measured separately (per language) and overall, where we surpass all provided SemEval baselines.</abstract>
      <url hash="f4371019">2020.semeval-1.26</url>
      <bibkey>kanjirangat-etal-2020-sst</bibkey>
      <doi>10.18653/v1/2020.semeval-1.26</doi>
      <pwccode url="https://github.com/vanikanjirangat/SST_BERT-SEMEVAL_TASK1" additional="true">vanikanjirangat/SST_BERT-SEMEVAL_TASK1</pwccode>
    </paper>
    <paper id="27">
      <title><fixed-case>T</fixed-case>emporal<fixed-case>T</fixed-case>eller at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 1: Unsupervised Lexical Semantic Change Detection with Temporal Referencing</title>
      <author><first>Jinan</first><last>Zhou</last></author>
      <author><first>Jiaxin</first><last>Li</last></author>
      <pages>222&#8211;231</pages>
      <abstract>This paper describes our TemporalTeller system for SemEval Task 1: Unsupervised Lexical Semantic Change Detection. We develop a unified framework for the common semantic change detection pipelines including preprocessing, learning word embeddings, calculating vector distances and determining threshold. We also propose Gamma Quantile Threshold to distinguish between changed and stable words. Based on our system, we conduct a comprehensive comparison among BERT, Skip-gram, Temporal Referencing and alignment-based methods. Evaluation results show that Skip-gram with Temporal Referencing achieves the best performance of 66.5% classification accuracy and 51.8% Spearman&#8217;s Ranking Correlation.</abstract>
      <url hash="0eeca120">2020.semeval-1.27</url>
      <bibkey>zhou-li-2020-temporalteller</bibkey>
      <doi>10.18653/v1/2020.semeval-1.27</doi>
    </paper>
    <paper id="35">
      <title>Ferryman at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 3: Bert with <fixed-case>TFIDF</fixed-case>-Weighting for Predicting the Effect of Context in Word Similarity</title>
      <author><first>Weilong</first><last>Chen</last></author>
      <author><first>Xin</first><last>Yuan</last></author>
      <author><first>Sai</first><last>Zhang</last></author>
      <author><first>Jiehui</first><last>Wu</last></author>
      <author><first>Yanru</first><last>Zhang</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <pages>281&#8211;285</pages>
      <abstract>Word similarity is widely used in machine learning applications like searching engine and recommendation. Measuring the changing meaning of the same word between two different sentences is not only a way to handle complex features in word usage (such as sentence syntax and semantics), but also an important method for different word polysemy modeling. In this paper, we present the methodology proposed by team Ferryman. Our system is based on the Bidirectional Encoder Representations from Transformers (BERT) model combined with term frequency-inverse document frequency (TF-IDF), applying the method on the provided datasets called CoSimLex, which covers four different languages including English, Croatian, Slovene, and Finnish. Our team Ferryman wins the the first position for English task and the second position for Finnish in the subtask 1.</abstract>
      <url hash="a09a8129">2020.semeval-1.35</url>
      <bibkey>chen-etal-2020-ferryman</bibkey>
      <doi>10.18653/v1/2020.semeval-1.35</doi>
    </paper>
    <paper id="37">
      <title><fixed-case>JUSTM</fixed-case>asters at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 3: Multilingual Deep Learning Model to Predict the Effect of Context in Word Similarity</title>
      <author><first>Nour</first><last>Al-khdour</last></author>
      <author><first>Mutaz</first><last>Bni Younes</last></author>
      <author><first>Malak</first><last>Abdullah</last></author>
      <author><first>Mohammad</first><last>AL-Smadi</last></author>
      <pages>292&#8211;300</pages>
      <abstract>There is a growing research interest in studying word similarity. Without a doubt, two similar words in a context may considered different in another context. Therefore, this paper investigates the effect of the context in word similarity. The SemEval-2020 workshop has provided a shared task (Task 3: Predicting the (Graded) Effect of Context in Word Similarity). In this task, the organizers provided unlabeled datasets for four languages, English, Croatian, Finnish and Slovenian. Our team, JUSTMasters, has participated in this competition in the two subtasks: A and B. Our approach has used a weighted average ensembling method for different pretrained embeddings techniques for each of the four languages. Our proposed model outperformed the baseline models in both subtasks and acheived the best result for subtask 2 in English and Finnish, with score 0.725 and 0.68 respectively. We have been ranked the sixth for subtask 1, with scores for English, Croatian, Finnish, and Slovenian as follows: 0.738, 0.44, 0.546, 0.512.</abstract>
      <url hash="0b3f7007">2020.semeval-1.37</url>
      <bibkey>al-khdour-etal-2020-justmasters</bibkey>
      <doi>10.18653/v1/2020.semeval-1.37</doi>
    </paper>
    <paper id="38">
      <title><fixed-case>W</fixed-case>ill_<fixed-case>G</fixed-case>o at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 3: An Accurate Model for Predicting the (Graded) Effect of Context in Word Similarity Based on <fixed-case>BERT</fixed-case></title>
      <author><first>Wei</first><last>Bao</last></author>
      <author><first>Hongshu</first><last>Che</last></author>
      <author><first>Jiandong</first><last>Zhang</last></author>
      <pages>301&#8211;306</pages>
      <abstract>Natural Language Processing (NLP) has been widely used in the semantic analysis in recent years. Our paper mainly discusses a methodology to analyze the effect that context has on human perception of similar words, which is the third task of SemEval 2020. We apply several methods in calculating the distance between two embedding vector generated by Bidirectional Encoder Representation from Transformer (BERT). Our team will go won the 1st place in Finnish language track of subtask1, the second place in English track of subtask1.</abstract>
      <url hash="2cf85893">2020.semeval-1.38</url>
      <bibkey>bao-etal-2020-will</bibkey>
      <doi>10.18653/v1/2020.semeval-1.38</doi>
    </paper>
    <paper id="41">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 6: Definition Extraction from Free Text with the <fixed-case>DEFT</fixed-case> Corpus</title>
      <author><first>Sasha</first><last>Spala</last></author>
      <author><first>Nicholas</first><last>Miller</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Carl</first><last>Dockhorn</last></author>
      <pages>336&#8211;345</pages>
      <abstract>Research on definition extraction has been conducted for well over a decade, largely with significant constraints on the type of definitions considered. In this work, we present DeftEval, a SemEval shared task in which participants must extract definitions from free text using a term-definition pair corpus that reflects the complex reality of definitions in natural language. Definitions and glosses in free text often appear without explicit indicators, across sentences boundaries, or in an otherwise complex linguistic manner. DeftEval involved 3 distinct subtasks: 1) Sentence classification, 2) sequence labeling, and 3) relation extraction.</abstract>
      <url hash="fb203f3c">2020.semeval-1.41</url>
      <bibkey>spala-etal-2020-semeval</bibkey>
      <doi>10.18653/v1/2020.semeval-1.41</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/deft-corpus">DEFT Corpus</pwcdataset>
    </paper>
    <paper id="42">
      <title><fixed-case>IIE</fixed-case>-<fixed-case>NLP</fixed-case>-<fixed-case>NUT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Guiding <fixed-case>PLM</fixed-case> with Prompt Template Reconstruction Strategy for <fixed-case>C</fixed-case>om<fixed-case>VE</fixed-case></title>
      <author><first>Luxi</first><last>Xing</last></author>
      <author><first>Yuqiang</first><last>Xie</last></author>
      <author><first>Yue</first><last>Hu</last></author>
      <author><first>Wei</first><last>Peng</last></author>
      <pages>346&#8211;353</pages>
      <abstract>This paper introduces our systems for the first two subtasks of SemEval Task4: Commonsense Validation and Explanation. To clarify the intention for judgment and inject contrastive information for selection, we propose the input reconstruction strategy with prompt templates. Specifically, we formalize the subtasks into the multiple-choice question answering format and construct the input with the prompt templates, then, the final prediction of question answering is considered as the result of subtasks. Experimental results show that our approaches achieve significant performance compared with the baseline systems. Our approaches secure the third rank on both official test sets of the first two subtasks with an accuracy of 96.4 and an accuracy of 94.3 respectively.</abstract>
      <url hash="e64ce198">2020.semeval-1.42</url>
      <bibkey>xing-etal-2020-iie</bibkey>
      <doi>10.18653/v1/2020.semeval-1.42</doi>
    </paper>
    <paper id="46">
      <title><fixed-case>BUT</fixed-case>-<fixed-case>FIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Multilingual Commonsense</title>
      <author><first>Josef</first><last>Jon</last></author>
      <author><first>Martin</first><last>Fajcik</last></author>
      <author><first>Martin</first><last>Docekal</last></author>
      <author><first>Pavel</first><last>Smrz</last></author>
      <pages>374&#8211;390</pages>
      <abstract>We participated in all three subtasks. In subtasks A and B, our submissions are based on pretrained language representation models (namely ALBERT) and data augmentation. We experimented with solving the task for another language, Czech, by means of multilingual models and machine translated dataset, or translated model inputs. We show that with a strong machine translation system, our system can be used in another language with a small accuracy loss. In subtask C, our submission, which is based on pretrained sequence-to-sequence model (BART), ranked 1st in BLEU score ranking, however, we show that the correlation between BLEU and human evaluation, in which our submission ended up 4th, is low. We analyse the metrics used in the evaluation and we propose an additional score based on model from subtask B, which correlates well with our manual ranking, as well as reranking method based on the same principle. We performed an error and dataset analysis for all subtasks and we present our findings.</abstract>
      <url hash="ab673fcf">2020.semeval-1.46</url>
      <bibkey>jon-etal-2020-fit</bibkey>
      <doi>10.18653/v1/2020.semeval-1.46</doi>
      <pwccode url="https://github.com/cepin19/semeval2020_task4" additional="false">cepin19/semeval2020_task4</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
    </paper>
    <paper id="49">
      <title>Masked Reasoner at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Fine-Tuning <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Commonsense Reasoning</title>
      <author><first>Daming</first><last>Lu</last></author>
      <pages>411&#8211;414</pages>
      <abstract>This paper describes the masked reasoner system that participated in SemEval-2020 Task 4: Commonsense Validation and Explanation. The system participated in the subtask B.We proposes a novel method to fine-tune RoBERTa by masking the most important word in the statement. We believe that the confidence of the system in recovering that word is positively correlated to the score the masked language model gives to the current statement-explanation pair. We evaluate the importance of each word using InferSent and do the masked fine-tuning on RoBERTa. Then we use the fine-tuned model to predict the most plausible explanation. Our system is fast in training and achieved 73.5% accuracy.</abstract>
      <url hash="eb1a8361">2020.semeval-1.49</url>
      <bibkey>lu-2020-masked</bibkey>
      <doi>10.18653/v1/2020.semeval-1.49</doi>
    </paper>
    <paper id="52">
      <title><fixed-case>U</fixed-case>o<fixed-case>R</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Pre-trained Sentence Transformer Models for Commonsense Validation and Explanation</title>
      <author><first>Thanet</first><last>Markchom</last></author>
      <author><first>Bhuvana</first><last>Dhruva</last></author>
      <author><first>Chandresh</first><last>Pravin</last></author>
      <author><first>Huizhi</first><last>Liang</last></author>
      <pages>430&#8211;436</pages>
      <abstract>SemEval Task 4 Commonsense Validation and Explanation Challenge is to validate whether a system can differentiate natural language statements that make sense from those that do not make sense. Two subtasks, A and B, are focused in this work, i.e., detecting against-common-sense statements and selecting explanations of why they are false from the given options. Intuitively, commonsense validation requires additional knowledge beyond the given statements. Therefore, we propose a system utilising pre-trained sentence transformer models based on BERT, RoBERTa and DistillBERT architectures to embed the statements before classification. According to the results, these embeddings can improve the performance of the typical MLP and LSTM classifiers as downstream models of both subtasks compared to regular tokenised statements. These embedded statements are shown to comprise additional information from external resources which help validate common sense in natural language.</abstract>
      <url hash="4da66650">2020.semeval-1.52</url>
      <bibkey>markchom-etal-2020-uor</bibkey>
      <doi>10.18653/v1/2020.semeval-1.52</doi>
    </paper>
    <paper id="53">
      <title><fixed-case>BUT</fixed-case>-<fixed-case>FIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: Automatic Detection of Counterfactual Statements with Deep Pre-trained Language Representation Models</title>
      <author><first>Martin</first><last>Fajcik</last></author>
      <author><first>Josef</first><last>Jon</last></author>
      <author><first>Martin</first><last>Docekal</last></author>
      <author><first>Pavel</first><last>Smrz</last></author>
      <pages>437&#8211;444</pages>
      <abstract>This paper describes BUT-FIT&#8217;s submission at SemEval-2020 Task 5: Modelling Causal Reasoning in Language: Detecting Counterfactuals. The challenge focused on detecting whether a given statement contains a counterfactual (Subtask 1) and extracting both antecedent and consequent parts of the counterfactual from the text (Subtask 2). We experimented with various state-of-the-art language representation models (LRMs). We found RoBERTa LRM to perform the best in both subtasks. We achieved the first place in both exact match and F1 for Subtask 2 and ranked second for Subtask 1.</abstract>
      <url hash="cf93293d">2020.semeval-1.53</url>
      <bibkey>fajcik-etal-2020-fit</bibkey>
      <doi>10.18653/v1/2020.semeval-1.53</doi>
      <pwccode url="https://github.com/MFajcik/SemEval_2020_Task-5" additional="false">MFajcik/SemEval_2020_Task-5</pwccode>
    </paper>
    <paper id="58">
      <title><fixed-case>ACNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 6: A Supervised Approach for Definition Extraction</title>
      <author><first>Fabien</first><last>Caspani</last></author>
      <author><first>Pirashanth</first><last>Ratnamogan</last></author>
      <author><first>Mathis</first><last>Linger</last></author>
      <author><first>Mhamed</first><last>Hajaiej</last></author>
      <pages>479&#8211;486</pages>
      <abstract>We describe our contribution to two of the subtasks of SemEval 2020 Task 6, DeftEval: Extracting term-definition pairs in free text. The system for Subtask 1: Sentence Classification is based on a transformer architecture where we use transfer learning to fine-tune a pretrained model on the downstream task, and the one for Subtask 3: Relation Classification uses a Random Forest classifier with handcrafted dedicated features. Our systems respectively achieve 0.830 and 0.994 F1-scores on the official test set, and we believe that the insights derived from our study are potentially relevant to help advance the research on definition extraction.</abstract>
      <url hash="371695b1">2020.semeval-1.58</url>
      <bibkey>caspani-etal-2020-acnlp</bibkey>
      <doi>10.18653/v1/2020.semeval-1.58</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/deft-corpus">DEFT Corpus</pwcdataset>
    </paper>
    <paper id="60">
      <title><fixed-case>CN</fixed-case>-<fixed-case>HIT</fixed-case>-<fixed-case>IT</fixed-case>.<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Enhanced Language Representation with Multiple Knowledge Triples</title>
      <author><first>Yice</first><last>Zhang</last></author>
      <author><first>Jiaxuan</first><last>Lin</last></author>
      <author><first>Yang</first><last>Fan</last></author>
      <author><first>Peng</first><last>Jin</last></author>
      <author><first>Yuanchao</first><last>Liu</last></author>
      <author><first>Bingquan</first><last>Liu</last></author>
      <pages>494&#8211;500</pages>
      <abstract>This paper describes our system that participated in the SemEval-2020 task 4: Commonsense Validation and Explanation. For this task, it is obvious that external knowledge, such as Knowledge graph, can help the model understand commonsense in natural language statements. But how to select the right triples for statements remains unsolved, so how to reduce the interference of irrelevant triples on model performance is a research focus. This paper adopt a modified K-BERT as the language encoder, to enhance language representation through triples from knowledge graphs. Experiments show that our method is better than models without external knowledge, and is slightly better than the original K-BERT. We got an accuracy score of 0.97 in subtaskA, ranking 1/45, and got an accuracy score of 0.948, ranking 2/35.</abstract>
      <url hash="c18d8eff">2020.semeval-1.60</url>
      <bibkey>zhang-etal-2020-cn</bibkey>
      <doi>10.18653/v1/2020.semeval-1.60</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="62">
      <title><fixed-case>CS</fixed-case>-<fixed-case>NLP</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Evaluation of State-of-the-art <fixed-case>NLP</fixed-case> Deep Learning Architectures on Commonsense Reasoning Task</title>
      <author><first>Sirwe</first><last>Saeedi</last></author>
      <author><first>Aliakbar</first><last>Panahi</last></author>
      <author><first>Seyran</first><last>Saeedi</last></author>
      <author><first>Alvis</first><last>C Fong</last></author>
      <pages>507&#8211;515</pages>
      <abstract>In this paper, we investigate a commonsense inference task that unifies natural language understanding and commonsense reasoning. We describe our attempt at SemEval-2020 Task 4 competition: Commonsense Validation and Explanation (ComVE) challenge. We discuss several state-of-the-art deep learning architectures for this challenge. Our system uses prepared labeled textual datasets that were manually curated for three different natural language inference subtasks. The goal of the first subtask is to test whether a model can distinguish between natural language statements that make sense and those that do not make sense. We compare the performance of several language models and fine-tuned classifiers. Then, we propose a method inspired by question/answering tasks to treat a classification problem as a multiple choice question task to boost the performance of our experimental results (96.06%), which is significantly better than the baseline. For the second subtask, which is to select the reason why a statement does not make sense, we stand within the first six teams (93.7%) among 27 participants with very competitive results. Our result for last subtask of generating reason against the nonsense statement shows many potentials for future researches as we applied the most powerful generative model of language (GPT-2) with 6.1732 BLEU score among first four teams. .</abstract>
      <url hash="51abcbf9">2020.semeval-1.62</url>
      <bibkey>saeedi-etal-2020-cs</bibkey>
      <doi>10.18653/v1/2020.semeval-1.62</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
    </paper>
    <paper id="65">
      <title><fixed-case>JBNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: <fixed-case>BERT</fixed-case> and <fixed-case>U</fixed-case>ni<fixed-case>LM</fixed-case> for Commonsense Validation and Explanation</title>
      <author><first>Seung-Hoon</first><last>Na</last></author>
      <author><first>Jong-Hyeon</first><last>Lee</last></author>
      <pages>527&#8211;534</pages>
      <abstract>This paper presents our contributions to the SemEval-2020 Task 4 Commonsense Validation and Explanation (ComVE) and includes the experimental results of the two Subtasks B and C of the SemEval-2020 Task 4. Our systems rely on pre-trained language models, i.e., BERT (including its variants) and UniLM, and rank 10th and 7th among 27 and 17 systems on Subtasks B and C, respectively. We analyze the commonsense ability of the existing pretrained language models by testing them on the SemEval-2020 Task 4 ComVE dataset, specifically for Subtasks B and C, the explanation subtasks with multi-choice and sentence generation, respectively.</abstract>
      <url hash="d61d668f">2020.semeval-1.65</url>
      <bibkey>na-lee-2020-jbnu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.65</doi>
    </paper>
    <paper id="67">
      <title><fixed-case>K</fixed-case>a<fixed-case>LM</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Knowledge-aware Language Models for Comprehension and Generation</title>
      <author><first>Jiajing</first><last>Wan</last></author>
      <author><first>Xinting</first><last>Huang</last></author>
      <pages>543&#8211;550</pages>
      <abstract>This paper presents our strategies in SemEval 2020 Task 4: Commonsense Validation and Explanation. We propose a novel way to search for evidence and choose the different large-scale pre-trained models as the backbone for three subtasks. The results show that our evidence-searching approach improves model performance on commonsense explanation task. Our team ranks 2nd in subtask C according to human evaluation score.</abstract>
      <url hash="9c03f3cc">2020.semeval-1.67</url>
      <bibkey>wan-huang-2020-kalm</bibkey>
      <doi>10.18653/v1/2020.semeval-1.67</doi>
      <pwccode url="https://github.com/huangxt39/KaLM" additional="false">huangxt39/KaLM</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/commonsenseqa">CommonsenseQA</pwcdataset>
    </paper>
    <paper id="70">
      <title><fixed-case>LMVE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Commonsense Validation and Explanation Using Pretraining Language Model</title>
      <author><first>Shilei</first><last>Liu</last></author>
      <author><first>Yu</first><last>Guo</last></author>
      <author><first>BoChao</first><last>Li</last></author>
      <author><first>Feiliang</first><last>Ren</last></author>
      <pages>562&#8211;568</pages>
      <abstract>This paper introduces our system for commonsense validation and explanation. For Sen-Making task, we use a novel pretraining language model based architecture to pick out one of the two given statements that is againstcommon sense. For Explanation task, we use a hint sentence mechanism to improve the performance greatly. In addition, we propose a subtask level transfer learning to share information between subtasks.</abstract>
      <url hash="07b413d2">2020.semeval-1.70</url>
      <bibkey>liu-etal-2020-lmve</bibkey>
      <doi>10.18653/v1/2020.semeval-1.70</doi>
    </paper>
    <paper id="73">
      <title><fixed-case>SSN</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Text Classification and Generation on Common Sense Context Using Neural Networks</title>
      <author><first>Rishivardhan</first><last>K.</last></author>
      <author><first>Kayalvizhi</first><last>S</last></author>
      <author><first>Thenmozhi</first><last>D.</last></author>
      <author><first>Raghav</first><last>R.</last></author>
      <author><first>Kshitij</first><last>Sharma</last></author>
      <pages>580&#8211;584</pages>
      <abstract>Common sense validation deals with testing whether a system can differentiate natural language statements that make sense from those that do not make sense. This paper describes the our approach to solve this challenge. For common sense validation with multi choice, we propose a stacking based approach to classify sentences that are more favourable in terms of common sense to the particular statement. We have used majority voting classifier methodology amongst three models such as Bidirectional Encoder Representations from Transformers (BERT), Micro Text Classification (Micro TC) and XLNet. For sentence generation, we used Neural Machine Translation (NMT) model to generate explanatory sentences.</abstract>
      <url hash="19903604">2020.semeval-1.73</url>
      <bibkey>k-etal-2020-ssn</bibkey>
      <doi>10.18653/v1/2020.semeval-1.73</doi>
    </paper>
    <paper id="77">
      <title><fixed-case>UAICS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: Using a Bidirectional Transformer for Task a</title>
      <author><first>Ciprian-Gabriel</first><last>Cusmuliuc</last></author>
      <author><first>Lucia-Georgiana</first><last>Coca</last></author>
      <author><first>Adrian</first><last>Iftene</last></author>
      <pages>609&#8211;613</pages>
      <abstract>Commonsense Validation and Explanation has been a difficult task for machines since the dawn of computing. Although very trivial to humans it poses a high complexity for machines due to the necessity of inference over a pre-existing knowledge base. In order to try and solve this problem the SemEval 2020 Task 4 - &#8221;Commonsense Validation and Explanation (ComVE)&#8221; aims to evaluate systems capable of multiple stages of ComVE. The challenge includes 3 tasks (A, B and C), each with it&#8217;s own requirements. Our team participated only in task A which required selecting the statement that made the least sense. We choose to use a bidirectional transformer in order to solve the challenge, this paper presents the details of our method, runs and result.</abstract>
      <url hash="fc98e437">2020.semeval-1.77</url>
      <bibkey>cusmuliuc-etal-2020-uaics</bibkey>
      <doi>10.18653/v1/2020.semeval-1.77</doi>
    </paper>
    <paper id="79">
      <title>Warren at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 4: <fixed-case>ALBERT</fixed-case> and Multi-Task Learning for Commonsense Validation</title>
      <author><first>Yuhang</first><last>Wu</last></author>
      <author><first>Hao</first><last>Wu</last></author>
      <pages>620&#8211;625</pages>
      <abstract>This paper describes our system in subtask A of SemEval 2020 Shared Task 4. We propose a reinforcement learning model based on MTL(Multi-Task Learning) to enhance the prediction ability of commonsense validation. The experimental results demonstrate that our system outperforms the single-task text classification model. We combine MTL and ALBERT pretrain model to achieve an accuracy of 0.904 and our model is ranked 16th on the final leader board of the competition among the 45 teams.</abstract>
      <url hash="334d7cf7">2020.semeval-1.79</url>
      <bibkey>wu-wu-2020-warren</bibkey>
      <doi>10.18653/v1/2020.semeval-1.79</doi>
    </paper>
    <paper id="83">
      <title><fixed-case>ETHAN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: Modelling Causal Reasoning in Language Using Neuro-symbolic Cloud Computing</title>
      <author><first>Len</first><last>Yabloko</last></author>
      <pages>645&#8211;652</pages>
      <abstract>I present ETHAN: Experimental Testing of Hybrid AI Node implemented entirely on free cloud computing infrastructure. The ultimate goal of this research is to create modular reusable hybrid neuro-symbolic architecture for Artificial Intelligence. As a test case I model natural language comprehension of causal relations from open domain text corpus that combines semi-supervised language model (Huggingface Transformers) with constituency and dependency parsers (Allen Institute for Artificial Intelligence.)</abstract>
      <url hash="e284d87b">2020.semeval-1.83</url>
      <bibkey>yabloko-2020-ethan</bibkey>
      <doi>10.18653/v1/2020.semeval-1.83</doi>
    </paper>
    <paper id="84">
      <title>Ferryman as <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: Optimized <fixed-case>BERT</fixed-case> for Detecting Counterfactuals</title>
      <author><first>Weilong</first><last>Chen</last></author>
      <author><first>Yan</first><last>Zhuang</last></author>
      <author><first>Peng</first><last>Wang</last></author>
      <author><first>Feng</first><last>Hong</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Yanru</first><last>Zhang</last></author>
      <pages>653&#8211;657</pages>
      <abstract>The main purpose of this article is to state the effect of using different methods and models for counterfactual determination and detection of causal knowledge. Nowadays, counterfactual reasoning has been widely used in various fields. In the realm of natural language process(NLP), counterfactual reasoning has huge potential to improve the correctness of a sentence. In the shared Task 5 of detecting counterfactual in SemEval 2020, we pre-process the officially given dataset according to case conversion, extract stem and abbreviation replacement. We use last-5 bidirectional encoder representation from bidirectional encoder representation from transformer (BERT)and term frequency&#8211;inverse document frequency (TF-IDF) vectorizer for counterfactual detection. Meanwhile, multi-sample dropout and cross validation are used to improve versatility and prevent problems such as poor generosity caused by overfitting. Finally, our team Ferryman ranked the 8th place in the sub-task 1 of this competition.</abstract>
      <url hash="989b7417">2020.semeval-1.84</url>
      <bibkey>chen-etal-2020-ferryman-semeval</bibkey>
      <doi>10.18653/v1/2020.semeval-1.84</doi>
    </paper>
    <paper id="86">
      <title>Lee at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: <fixed-case>ALBERT</fixed-case> Model Based on the Maximum Ensemble Strategy and Different Data Sampling Methods for Detecting Counterfactual Statements</title>
      <author><first>Junyi</first><last>Li</last></author>
      <author><first>Yuhang</first><last>Wu</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <author><first>Haiyan</first><last>Ding</last></author>
      <pages>664&#8211;669</pages>
      <abstract>This article describes the system submitted to SemEval 2020 Task 5: Modelling Causal Reasoning in Language: Detecting Counterfactuals. In this task, we only participate in the subtask A which is detecting counterfactual statements. In order to solve this sub-task, first of all, because of the problem of data balance, we use the undersampling and oversampling methods to process the data set. Second, we used the ALBERT model and the maximum ensemble method based on the ALBERT model. Our methods achieved a F1 score of 0.85 in subtask A.</abstract>
      <url hash="b887af8a">2020.semeval-1.86</url>
      <bibkey>li-etal-2020-lee</bibkey>
      <doi>10.18653/v1/2020.semeval-1.86</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="87">
      <title><fixed-case>NLU</fixed-case>-Co at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: <fixed-case>NLU</fixed-case>/<fixed-case>SVM</fixed-case> Based Model Apply Tocharacterise and Extract Counterfactual Items on Raw Data</title>
      <author><first>Elvis</first><last>Mboning Tchiaze</last></author>
      <author><first>Damien</first><last>Nouvel</last></author>
      <pages>670&#8211;676</pages>
      <abstract>In this article, we try to solve the problem of classification of counterfactual statements and extraction of antecedents/consequences in raw data, by mobilizing on one hand Support vector machine (SVMs) and on the other hand Natural Language Understanding (NLU) infrastructures available on the market for conversational agents. Our experiments allowed us to test different pipelines of two known platforms (Snips NLU and Rasa NLU). The results obtained show that a Rasa NLU pipeline, built with a well-preprocessed dataset and tuned algorithms, allows to model accurately the structure of a counterfactual event, in order to facilitate the identification and the extraction of its components.</abstract>
      <url hash="47fdd5e0">2020.semeval-1.87</url>
      <bibkey>mboning-tchiaze-nouvel-2020-nlu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.87</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/snips">SNIPS</pwcdataset>
    </paper>
    <paper id="89">
      <title><fixed-case>YNU</fixed-case>-oxz at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 5: Detecting Counterfactuals Based on Ordered Neurons <fixed-case>LSTM</fixed-case> and Hierarchical Attention Network</title>
      <author><first>Xiaozhi</first><last>Ou</last></author>
      <author><first>Shengyan</first><last>Liu</last></author>
      <author><first>Hongling</first><last>Li</last></author>
      <pages>683&#8211;689</pages>
      <abstract>This paper describes the system and results of our team&#8217;s participation in SemEval-2020 Task5: Modelling Causal Reasoning in Language: Detecting Counterfactuals, which aims to simulate counterfactual semantics and reasoning in natural language. This task contains two subtasks: Subtask1&#8211;Detecting counterfactual statements and Subtask2&#8211;Detecting antecedent and consequence. We only participated in Subtask1, aiming to determine whether a given sentence is counterfactual. In order to solve this task, we proposed a system based on Ordered Neurons LSTM (ON-LSTM) with Hierarchical Attention Network (HAN) and used Pooling operation for dimensionality reduction. Finally, we used the K-fold approach as the ensemble method. Our model achieved an F1 score of 0.7040 in Subtask1 (Ranked 16/27).</abstract>
      <url hash="bbe53f67">2020.semeval-1.89</url>
      <bibkey>ou-etal-2020-ynu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.89</doi>
    </paper>
    <paper id="90">
      <title><fixed-case>BERT</fixed-case>at<fixed-case>DE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 6: Extracting Term-definition Pairs in Free Text Using Pre-trained Model</title>
      <author><first>Huihui</first><last>Zhang</last></author>
      <author><first>Feiliang</first><last>Ren</last></author>
      <pages>690&#8211;696</pages>
      <abstract>Definition extraction is an important task in Nature Language Processing, and it is used to identify the terms and definitions related to terms. The task contains sentence classification task (i.e., classify whether it contains definition) and sequence labeling task (i.e., find the boundary of terms and definitions). The paper describes our system BERTatDE1 in sentence classification task (subtask 1) and sequence labeling task (subtask 2) in the definition extraction (SemEval-2020 Task 6). We use BERT to solve the multi-domain problems including the uncertainty of term boundary that is, different areas have different ways to definite the domain related terms. We use BERT, BiLSTM and attention in subtask 1 and our best result achieved 79.71% in F1 and the eighteenth place in subtask 1. For the subtask 2, we use BERT, BiLSTM and CRF to sequence labeling, and achieve 40.73% in Macro-averaged F1.</abstract>
      <url hash="ced65874">2020.semeval-1.90</url>
      <bibkey>zhang-ren-2020-bertatde</bibkey>
      <doi>10.18653/v1/2020.semeval-1.90</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/deft-corpus">DEFT Corpus</pwcdataset>
    </paper>
    <paper id="92">
      <title>Defx at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 6: Joint Extraction of Concepts and Relations for Definition Extraction</title>
      <author><first>Marc</first><last>H&#252;bner</last></author>
      <author><first>Christoph</first><last>Alt</last></author>
      <author><first>Robert</first><last>Schwarzenberg</last></author>
      <author><first>Leonhard</first><last>Hennig</last></author>
      <pages>704&#8211;709</pages>
      <abstract>Definition Extraction systems are a valuable knowledge source for both humans and algorithms. In this paper we describe our submissions to the DeftEval shared task (SemEval-2020 Task 6), which is evaluated on an English textbook corpus. We provide a detailed explanation of our system for the joint extraction of definition concepts and the relations among them. Furthermore we provide an ablation study of our model variations and describe the results of an error analysis.</abstract>
      <url hash="14648690">2020.semeval-1.92</url>
      <bibkey>hubner-etal-2020-defx</bibkey>
      <doi>10.18653/v1/2020.semeval-1.92</doi>
      <pwccode url="https://github.com/DFKI-NLP/defx" additional="false">DFKI-NLP/defx</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/deft-corpus">DEFT Corpus</pwcdataset>
    </paper>
    <paper id="97">
      <title><fixed-case>UPB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 6: Pretrained Language Models for Definition Extraction</title>
      <author><first>Andrei-Marius</first><last>Avram</last></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last></author>
      <author><first>Costin</first><last>Chiru</last></author>
      <pages>737&#8211;745</pages>
      <abstract>This work presents our contribution in the context of the 6th task of SemEval-2020: Extracting Definitions from Free Text in Textbooks (DeftEval). This competition consists of three subtasks with different levels of granularity: (1) classification of sentences as definitional or non-definitional, (2) labeling of definitional sentences, and (3) relation classification. We use various pretrained language models (i.e., BERT, XLNet, RoBERTa, SciBERT, and ALBERT) to solve each of the three subtasks of the competition. Specifically, for each language model variant, we experiment by both freezing its weights and fine-tuning them. We also explore a multi-task architecture that was trained to jointly predict the outputs for the second and the third subtasks. Our best performing model evaluated on the DeftEval dataset obtains the 32nd place for the first subtask and the 37th place for the second subtask. The code is available for further research at: <url>https://github.com/avramandrei/DeftEval</url>
      </abstract>
      <url hash="43d211d7">2020.semeval-1.97</url>
      <bibkey>avram-etal-2020-upb</bibkey>
      <doi>10.18653/v1/2020.semeval-1.97</doi>
      <pwccode url="https://github.com/avramandrei/DeftEval" additional="true">avramandrei/DeftEval</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/deft-corpus">DEFT Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
    </paper>
    <paper id="104">
      <title>Buhscitu at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Assessing Humour in Edited News Headlines Using Hand-Crafted Features and Online Knowledge Bases</title>
      <author><first>Kristian N&#248;rgaard</first><last>Jensen</last></author>
      <author><first>Nicolaj Filrup</first><last>Rasmussen</last></author>
      <author><first>Thai</first><last>Wang</last></author>
      <author><first>Marco</first><last>Placenti</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>824&#8211;832</pages>
      <abstract>This paper describes a system that aims at assessing humour intensity in edited news headlines as part of the 7th task of SemEval-2020 on &#8220;Humor, Emphasis and Sentiment&#8221;. Various factors need to be accounted for in order to assess the funniness of an edited headline. We propose an architecture that uses hand-crafted features, knowledge bases and a language model to understand humour, and combines them in a regression model. Our system outperforms two baselines. In general, automatic humour assessment remains a difficult task.</abstract>
      <url hash="8e995fbd">2020.semeval-1.104</url>
      <bibkey>jensen-etal-2020-buhscitu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.104</doi>
    </paper>
    <paper id="105">
      <title>Hasyarasa at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Quantifying Humor as Departure from Expectedness</title>
      <author><first>Ravi Theja</first><last>Desetty</last></author>
      <author><first>Ranit</first><last>Chatterjee</last></author>
      <author><first>Smita</first><last>Ghaisas</last></author>
      <pages>833&#8211;842</pages>
      <abstract>This paper describes our system submission Hasyarasa for the SemEval-2020 Task-7: Assessing Humor in Edited News Headlines. This task has two subtasks. The goal of Subtask 1 is to predict the mean funniness of the edited headline given the original and the edited headline. In Subtask 2, given two edits on the original headline, the goal is to predict the funnier of the two. We observed that the departure from expected state/ actions of situations/ individuals is the cause of humor in the edited headlines. We propose two novel features: Contextual Semantic Distance and Contextual Neighborhood Distance to estimate this departure and thus capture the contextual absurdity and hence the humor in the edited headlines. We have used these features together with a Bi-LSTM Attention based model and have achieved 0.53310 RMSE for Subtask 1 and 60.19% accuracy for Subtask 2.</abstract>
      <url hash="956d6e35">2020.semeval-1.105</url>
      <bibkey>desetty-etal-2020-hasyarasa</bibkey>
      <doi>10.18653/v1/2020.semeval-1.105</doi>
    </paper>
    <paper id="110">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Using an Ensemble <fixed-case>B</fixed-case>i<fixed-case>GRU</fixed-case> Model to Evaluate the Humor of Edited News Titles</title>
      <author><first>Joseph</first><last>Tomasulo</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>871&#8211;875</pages>
      <abstract>This paper describes an ensemble model designed for Semeval-2020 Task 7. The task is based on the Humicroedit dataset that is comprised of news titles and one-word substitutions designed to make them humorous. We use BERT, FastText, Elmo, and Word2Vec to encode these titles then pass them to a bidirectional gated recurrent unit (BiGRU) with attention. Finally, we used XGBoost on the concatenation of the results of the different models to make predictions.</abstract>
      <url hash="a6a02927">2020.semeval-1.110</url>
      <bibkey>tomasulo-etal-2020-ynu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.110</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/humicroedit">Humicroedit</pwcdataset>
    </paper>
    <paper id="113">
      <title><fixed-case>NLP</fixed-case>_<fixed-case>UIOWA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: You&#8217;re Not the Only One Cursed with Knowledge - Multi Branch Model Memotion Analysis</title>
      <author><first>Ingroj</first><last>Shrestha</last></author>
      <author><first>Jonathan</first><last>Rusert</last></author>
      <pages>891&#8211;900</pages>
      <abstract>We propose hybrid models (HybridE and HybridW) for meme analysis (SemEval 2020 Task 8), which involves sentiment classification (Subtask A), humor classification (Subtask B), and scale of semantic classes (Subtask C). The hybrid model consists of BLSTM and CNN for text and image processing respectively. HybridE provides equal weight to BLSTM and CNN performance, while HybridW provides weightage based on the performance of BLSTM and CNN on a validation set. The performances (macro F1) of our hybrid model on Subtask A are 0.329 (HybridE), 0.328 (HybridW), on Subtask B are 0.507 (HybridE), 0.512 (HybridW), and on Subtask C are 0.309 (HybridE), 0.311 (HybridW).</abstract>
      <url hash="78e353cb">2020.semeval-1.113</url>
      <bibkey>shrestha-rusert-2020-nlp</bibkey>
      <doi>10.18653/v1/2020.semeval-1.113</doi>
    </paper>
    <paper id="117">
      <title><fixed-case>CS</fixed-case>-Embed at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: The Effectiveness of Code-switched Word Embeddings for Sentiment Analysis</title>
      <author><first>Frances Adriana</first><last>Laureano De Leon</last></author>
      <author><first>Florimond</first><last>Gu&#233;niat</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <pages>922&#8211;927</pages>
      <abstract>The growing popularity and applications of sentiment analysis of social media posts has naturally led to sentiment analysis of posts written in multiple languages, a practice known as code-switching. While recent research into code-switched posts has focused on the use of multilingual word embeddings, these embeddings were not trained on code-switched data. In this work, we present word-embeddings trained on code-switched tweets, specifically those that make use of Spanish and English, known as Spanglish. We explore the embedding space to discover how they capture the meanings of words in both languages. We test the effectiveness of these embeddings by participating in SemEval 2020 Task 9: <i>Sentiment Analysis on Code-Mixed Social Media Text</i>. We utilised them to train a sentiment classifier that achieves an F-1 score of 0.722. This is higher than the baseline for the competition of 0.656, with our team (codalab username francesita) ranking 14 out of 29 participating teams, beating the baseline.</abstract>
      <url hash="5aa787f3">2020.semeval-1.117</url>
      <bibkey>laureano-de-leon-etal-2020-cs</bibkey>
      <doi>10.18653/v1/2020.semeval-1.117</doi>
      <pwccode url="https://github.com/francesita/CS-Embed-SemEval2020" additional="false">francesita/CS-Embed-SemEval2020</pwccode>
    </paper>
    <paper id="118">
      <title><fixed-case>FII</fixed-case>-<fixed-case>UAIC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Sentiment Analysis for Code-Mixed Social Media Text Using <fixed-case>CNN</fixed-case></title>
      <author><first>Lavinia</first><last>Aparaschivei</last></author>
      <author><first>Andrei</first><last>Palihovici</last></author>
      <author><first>Daniela</first><last>G&#238;fu</last></author>
      <pages>928&#8211;933</pages>
      <abstract>The &#8220;Sentiment Analysis for Code-Mixed Social Media Text&#8221; task at the SemEval 2020 competition focuses on sentiment analysis in code-mixed social media text , specifically, on the combination of English with Spanish (Spanglish) and Hindi (Hinglish). In this paper, we present a system able to classify tweets, from Spanish and English languages, into positive, negative and neutral. Firstly, we built a classifier able to provide corresponding sentiment labels. Besides the sentiment labels, we provide the language labels at the word level. Secondly, we generate a word-level representation, using Convolutional Neural Network (CNN) architecture. Our solution indicates promising results for the Sentimix Spanglish-English task (0.744), the team, Lavinia_Ap, occupied the 9th place. However, for the Sentimix Hindi-English task (0.324) the results have to be improved.</abstract>
      <url hash="5bc816a5">2020.semeval-1.118</url>
      <bibkey>aparaschivei-etal-2020-fii</bibkey>
      <doi>10.18653/v1/2020.semeval-1.118</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/sentimix">SentiMix</pwcdataset>
    </paper>
    <paper id="123">
      <title><fixed-case>NLP</fixed-case>-<fixed-case>CIC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Analysing Sentiment in Code-switching Language Using a Simple Deep-learning Classifier</title>
      <author><first>Jason</first><last>Angel</last></author>
      <author><first>Segun Taofeek</first><last>Aroyehun</last></author>
      <author><first>Antonio</first><last>Tamayo</last></author>
      <author><first>Alexander</first><last>Gelbukh</last></author>
      <pages>957&#8211;962</pages>
      <abstract>Code-switching is a phenomenon in which two or more languages are used in the same message. Nowadays, it is quite common to find messages with languages mixed in social media. This phenomenon presents a challenge for sentiment analysis. In this paper, we use a standard convolutional neural network model to predict the sentiment of tweets in a blend of Spanish and English languages. Our simple approach achieved a F1-score of 0:71 on test set on the competition. We analyze our best model capabilities and perform error analysis to expose important difficulties for classifying sentiment in a code-switching setting.</abstract>
      <url hash="de54a9f8">2020.semeval-1.123</url>
      <bibkey>angel-etal-2020-nlp</bibkey>
      <doi>10.18653/v1/2020.semeval-1.123</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/sentimix">SentiMix</pwcdataset>
    </paper>
    <paper id="124">
      <title>Palomino-Ochoa at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Robust System Based on Transformer for Code-Mixed Sentiment Classification</title>
      <author><first>Daniel</first><last>Palomino</last></author>
      <author><first>Jos&#233;</first><last>Ochoa-Luna</last></author>
      <pages>963&#8211;967</pages>
      <abstract>We present a transfer learning system to perform a mixed Spanish-English sentiment classification task. Our proposal uses the state-of-the-art language model BERT and embed it within a ULMFiT transfer learning pipeline. This combination allows us to predict the polarity detection of code-mixed (English-Spanish) tweets. Thus, among 29 submitted systems, our approach (referred to as dplominop) is ranked 4th on the Sentimix Spanglish test set of SemEval 2020 Task 9. In fact, our system yields the weighted-F1 score value of 0.755 which can be easily reproduced &#8212; the source code and implementation details are made available.</abstract>
      <url hash="aff7d188">2020.semeval-1.124</url>
      <bibkey>palomino-ochoa-luna-2020-palomino</bibkey>
      <doi>10.18653/v1/2020.semeval-1.124</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/sentimix">SentiMix</pwcdataset>
    </paper>
    <paper id="125">
      <title><fixed-case>ULD</fixed-case>@<fixed-case>NUIG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Generative Morphemes with an Attention Model for Sentiment Analysis in Code-Mixed Text</title>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Priya</first><last>Rani</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Theodorus</first><last>Fransen</last></author>
      <author><first>John P.</first><last>McCrae</last></author>
      <pages>968&#8211;974</pages>
      <abstract>Code mixing is a common phenomena in multilingual societies where people switch from one language to another for various reasons. Recent advances in public communication over different social media sites have led to an increase in the frequency of code-mixed usage in written language. In this paper, we present the Generative Morphemes with Attention (GenMA) Model sentiment analysis system contributed to SemEval 2020 Task 9 SentiMix. The system aims to predict the sentiments of the given English-Hindi code-mixed tweets without using word-level language tags instead inferring this automatically using a morphological model. The system is based on a novel deep neural network (DNN) architecture, which has outperformed the baseline F1-score on the test data-set as well as the validation data-set. Our results can be found under the user name &#8220;koustava&#8221; on the &#8220;Sentimix Hindi English&#8221; page.</abstract>
      <url hash="caa55042">2020.semeval-1.125</url>
      <bibkey>goswami-etal-2020-uld</bibkey>
      <doi>10.18653/v1/2020.semeval-1.125</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/sentimix">SentiMix</pwcdataset>
    </paper>
    <paper id="129">
      <title><fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Assessing Humor in Edited News Headlines Using <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> with Attention</title>
      <author><first>Tiantian</first><last>Zhang</last></author>
      <author><first>Zhixuan</first><last>Chen</last></author>
      <author><first>Man</first><last>Lan</last></author>
      <pages>995&#8211;1000</pages>
      <abstract>In this paper we describe our system submitted to SemEval 2020 Task 7: &#8220;Assessing Humor in Edited News Headlines&#8221;. We participated in all subtasks, in which the main goal is to predict the mean funniness of the edited headline given the original and the edited headline. Our system involves two similar sub-networks, which generate vector representations for the original and edited headlines respectively. And then we do a subtract operation of the outputs from two sub-networks to predict the funniness of the edited headline.</abstract>
      <url hash="7cdd3cbb">2020.semeval-1.129</url>
      <bibkey>zhang-etal-2020-ecnu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.129</doi>
    </paper>
    <paper id="130">
      <title><fixed-case>ELM</fixed-case>o-<fixed-case>NB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Assessing Sense of Humor in <fixed-case>E</fixed-case>dited<fixed-case>N</fixed-case>ews Headlines Using <fixed-case>ELM</fixed-case>o and <fixed-case>NB</fixed-case></title>
      <author><first>Enas</first><last>Khwaileh</last></author>
      <author><first>Muntaha A.</first><last>Al-As&#8217;ad</last></author>
      <pages>1001&#8211;1007</pages>
      <abstract>Our approach is constructed to improve on a couple of aspects; preprocessing with an emphasis on humor sense detection, using embeddings from state-of-the-art language model(Elmo), and ensembling the results came up with using machine learning model Na &#776;&#305;ve Bayes(NB) with a deep learning pre-trained models. Elmo-NB participation has scored (0.5642) on the competition leader board, where results were measured by Root Mean Squared Error (RMSE).</abstract>
      <url hash="578f4d22">2020.semeval-1.130</url>
      <bibkey>khwaileh-al-asad-2020-elmo</bibkey>
      <doi>10.18653/v1/2020.semeval-1.130</doi>
    </paper>
    <paper id="131">
      <title>Ferryman at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Ensemble Model for Assessing Humor in Edited News Headlines</title>
      <author><first>Weilong</first><last>Chen</last></author>
      <author><first>Jipeng</first><last>Li</last></author>
      <author><first>Chenghao</first><last>Huang</last></author>
      <author><first>Wei</first><last>Bai</last></author>
      <author><first>Yanru</first><last>Zhang</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <pages>1008&#8211;1012</pages>
      <abstract>Natural language processing (NLP) has been applied to various fields including text classification and sentiment analysis. In the shared task of assessing the funniness of edited news headlines, which is a part of the SemEval 2020 competition, we preprocess datasets by replacing abbreviation, stemming words, then merge three models including Light Gradient Boosting Machine (LightGBM), Long Short-Term Memory (LSTM), and Bidirectional Encoder Representation from Transformer (BERT) by taking the average to perform the best. Our team Ferryman wins the 9th place in Sub-task 1 of Task 7 - Regression.</abstract>
      <url hash="15f8aaba">2020.semeval-1.131</url>
      <bibkey>chen-etal-2020-ferryman-semeval-2020</bibkey>
      <doi>10.18653/v1/2020.semeval-1.131</doi>
    </paper>
    <paper id="132">
      <title>Funny3 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Humor Detection of Edited Headlines with <fixed-case>LSTM</fixed-case> and <fixed-case>TFIDF</fixed-case> Neural Network System</title>
      <author><first>Xuefeng</first><last>Luo</last></author>
      <author><first>Kuan</first><last>Tang</last></author>
      <pages>1013&#8211;1018</pages>
      <abstract>This paper presents a neural network system where we participate in the first task of SemEval-2020 shared task 7 &#8220;Assessing the Funniness of Edited News Headlines&#8221;. Our target is to create to neural network model that can predict the funniness of edited headlines. We build our model using a combination of LSTM and TF-IDF, then a feed-forward neural network. The system manages to slightly improve RSME scores regarding our mean score baseline.</abstract>
      <url hash="e6fd220b">2020.semeval-1.132</url>
      <bibkey>luo-tang-2020-funny3</bibkey>
      <doi>10.18653/v1/2020.semeval-1.132</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/humicroedit">Humicroedit</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sarc">SARC</pwcdataset>
    </paper>
    <paper id="133">
      <title><fixed-case>H</fixed-case>umor<fixed-case>AAC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Assessing the Funniness of Edited News Headlines through Regression and Trump Mentions</title>
      <author><first>Anna-Katharina</first><last>Dick</last></author>
      <author><first>Charlotte</first><last>Weirich</last></author>
      <author><first>Alla</first><last>Kutkina</last></author>
      <pages>1019&#8211;1025</pages>
      <abstract>In this paper we describe our contribution to the Semeval-2020 Humor Assessment task. We essentially use three different features that are passed into a ridge regression to determine a funniness score for an edited news headline: statistical, count-based features, semantic features and contextual information. For deciding which one of two given edited headlines is funnier, we additionally use scoring information and logistic regression. Our work was mostly concentrated on investigating features, rather than improving prediction based on pre-trained language models. The resulting system is task-specific, lightweight and performs above the majority baseline. Our experiments indicate that features related to socio-cultural context, in our case mentions of Donald Trump, generally perform better than context-independent features like headline length.</abstract>
      <url hash="d2378d58">2020.semeval-1.133</url>
      <bibkey>dick-etal-2020-humoraac</bibkey>
      <doi>10.18653/v1/2020.semeval-1.133</doi>
    </paper>
    <paper id="136">
      <title><fixed-case>MLE</fixed-case>ngineer at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: <fixed-case>BERT</fixed-case>-Flair Based Humor Detection Model (<fixed-case>BFH</fixed-case>umor)</title>
      <author><first>Fara</first><last>Shatnawi</last></author>
      <author><first>Malak</first><last>Abdullah</last></author>
      <author><first>Mahmoud</first><last>Hammad</last></author>
      <pages>1041&#8211;1048</pages>
      <abstract>Task 7, Assessing the Funniness of Edited News Headlines, in the International Workshop SemEval2020 introduces two sub-tasks to predict the funniness values of edited news headlines from the Reddit website. This paper proposes the BFHumor model of the MLEngineer team that participates in both sub-tasks in this competition. The BFHumor&#8217;s model is defined as a BERT-Flair based humor detection model that is a combination of different pre-trained models with various Natural Language Processing (NLP) techniques. The Bidirectional Encoder Representations from Transformers (BERT) regressor is considered the primary pre-trained model in our approach, whereas Flair is the main NLP library. It is worth mentioning that the BFHumor model has been ranked 4th in sub-task1 with a root mean square error (RMSE) value of 0.51966, and it is 0.02 away from the first ranked model. Also, the team is ranked 12th in the sub-task2 with an accuracy of 0.62291, which is 0.05 away from the top-ranked model. Our results indicate that the BFHumor model is one of the top models for detecting humor in the text.</abstract>
      <url hash="6e3f087b">2020.semeval-1.136</url>
      <bibkey>shatnawi-etal-2020-mlengineer</bibkey>
      <doi>10.18653/v1/2020.semeval-1.136</doi>
    </paper>
    <paper id="140">
      <title><fixed-case>UTFPR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Using Co-occurrence Frequencies to Capture Unexpectedness</title>
      <author><first>Gustavo Henrique</first><last>Paetzold</last></author>
      <pages>1066&#8211;1070</pages>
      <abstract>We describe the UTFPR system for SemEval-2020&#8217;s Task 7: Assessing Humor in Edited News Headlines. Ours is a minimalist unsupervised system that uses word co-occurrence frequencies from large corpora to capture unexpectedness as a mean to capture funniness. Our system placed 22nd on the shared task&#8217;s Task 2. We found that our approach requires more text than we used to perform reliably, and that unexpectedness alone is not sufficient to gauge funniness for humorous content that targets a diverse target audience.</abstract>
      <url hash="b9487b83">2020.semeval-1.140</url>
      <bibkey>paetzold-2020-utfpr</bibkey>
      <doi>10.18653/v1/2020.semeval-1.140</doi>
    </paper>
    <paper id="141">
      <title><fixed-case>WUY</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 7: Combining <fixed-case>BERT</fixed-case> and Naive <fixed-case>B</fixed-case>ayes-<fixed-case>SVM</fixed-case> for Humor Assessment in Edited News Headlines</title>
      <author><first>Cheng</first><last>Zhang</last></author>
      <author><first>Hayato</first><last>Yamana</last></author>
      <pages>1071&#8211;1076</pages>
      <abstract>This paper describes our participation in SemEval 2020 Task 7 on assessment of humor in edited news headlines, which includes two subtasks, estimating the humor of micro-editd news headlines (subtask A) and predicting the more humorous of the two edited headlines (subtask B). To address these tasks, we propose two systems. The first system adopts a regression-based fine-tuned single-sequence bidirectional encoder representations from transformers (BERT) model with easy data augmentation (EDA), called &#8220;BERT+EDA&#8221;. The second system adopts a hybrid of a regression-based fine-tuned sequence-pair BERT model and a combined Naive Bayes and support vector machine (SVM) model estimated on term frequency&#8211;inverse document frequency (TFIDF) features, called &#8220;BERT+NB-SVM&#8221;. In this case, no additional training datasets were used, and the BERT+NB-SVM model outperformed BERT+EDA. The official root-mean-square deviation (RMSE) score for subtask A is 0.57369 and ranks 31st out of 48, whereas the best RMSE of BERT+NB-SVM is 0.52429, ranking 7th. For subtask B, we simply use a sequence-pair BERT model, the official accuracy of which is 0.53196 and ranks 25th out of 32.</abstract>
      <url hash="96d21553">2020.semeval-1.141</url>
      <bibkey>zhang-yamana-2020-wuy</bibkey>
      <doi>10.18653/v1/2020.semeval-1.141</doi>
    </paper>
    <paper id="144">
      <title><fixed-case>BERT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: Using <fixed-case>BERT</fixed-case> to Analyse Meme Emotions</title>
      <author><first>Adithya</first><last>Avvaru</last></author>
      <author><first>Sanath</first><last>Vobilisetty</last></author>
      <pages>1094&#8211;1099</pages>
      <abstract>Sentiment analysis, being one of the most sought after research problems within Natural Language Processing (NLP) researchers. The range of problems being addressed by sentiment analysis is increasing. Till now, most of the research focuses on predicting sentiment, or sentiment categories like sarcasm, humor, offense and motivation on text data. But, there is very limited research that is focusing on predicting or analyzing the sentiment of internet memes. We try to address this problem as part of &#8220;Task 8 of SemEval 2020: Memotion Analysis&#8221;. We have participated in all the three tasks under Memotion Analysis. Our system built using state-of-the-art Transformer-based pre-trained Bidirectional Encoder Representations from Transformers (BERT) performed better compared to baseline models for the two tasks A and C and performed close to the baseline model for task B. In this paper, we present the data used, steps used by us for data cleaning and preparation, the fine-tuning process for BERT based model and finally predict the sentiment or sentiment categories. We found that the sequence models like Long Short Term Memory(LSTM) and its variants performed below par in predicting the sentiments. We also performed a comparative analysis with other Transformer based models like DistilBERT and XLNet.</abstract>
      <url hash="f49a3216">2020.semeval-1.144</url>
      <bibkey>avvaru-vobilisetty-2020-bert</bibkey>
      <doi>10.18653/v1/2020.semeval-1.144</doi>
    </paper>
    <paper id="146">
      <title><fixed-case>CSECU</fixed-case>_<fixed-case>KDE</fixed-case>_<fixed-case>MA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: A Neural Attention Model for Memotion Analysis</title>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <author><first>Umme Aymun</first><last>Siddiqua</last></author>
      <author><first>Masaki</first><last>Aono</last></author>
      <pages>1106&#8211;1111</pages>
      <abstract>A meme is a pictorial representation of an idea or theme. In the age of emerging volume of social media platforms, memes are spreading rapidly from person to person and becoming a trending ways of opinion expression. However, due to the multimodal characteristics of meme contents, detecting and analyzing the underlying emotion of a meme is a formidable task. In this paper, we present our approach for detecting the emotion of a meme defined in the SemEval-2020 Task 8. Our team CSECU_KDE_MA employs an attention-based neural network model to tackle the problem. Upon extracting the text contents from a meme using an optical character reader (OCR), we represent it using the distributed representation of words. Next, we perform the convolution based on multiple kernel sizes to obtain the higher-level feature sequences. The feature sequences are then fed into the attentive time-distributed bidirectional LSTM model to learn the long-term dependencies effectively. Experimental results show that our proposed neural model obtained competitive performance among the participants&#8217; systems.</abstract>
      <url hash="78ff8d8a">2020.semeval-1.146</url>
      <bibkey>chy-etal-2020-csecu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.146</doi>
    </paper>
    <paper id="149">
      <title>Hitachi at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: Simple but Effective Modality Ensemble for Meme Emotion Recognition</title>
      <author><first>Terufumi</first><last>Morishita</last></author>
      <author><first>Gaku</first><last>Morio</last></author>
      <author><first>Shota</first><last>Horiguchi</last></author>
      <author><first>Hiroaki</first><last>Ozaki</last></author>
      <author><first>Toshinori</first><last>Miyoshi</last></author>
      <pages>1126&#8211;1134</pages>
      <abstract>Users of social networking services often share their emotions via multi-modal content, usually images paired with text embedded in them. SemEval-2020 task 8, Memotion Analysis, aims at automatically recognizing these emotions of so-called internet memes. In this paper, we propose a simple but effective Modality Ensemble that incorporates visual and textual deep-learning models, which are independently trained, rather than providing a single multi-modal joint network. To this end, we first fine-tune four pre-trained visual models (i.e., Inception-ResNet, PolyNet, SENet, and PNASNet) and four textual models (i.e., BERT, GPT-2, Transformer-XL, and XLNet). Then, we fuse their predictions with ensemble methods to effectively capture cross-modal correlations. The experiments performed on dev-set show that both visual and textual features aided each other, especially in subtask-C, and consequently, our system ranked 2nd on subtask-C.</abstract>
      <url hash="10d22014">2020.semeval-1.149</url>
      <bibkey>morishita-etal-2020-hitachi-semeval-2020</bibkey>
      <doi>10.18653/v1/2020.semeval-1.149</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="154">
      <title>Memebusters at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: Feature Fusion Model for Sentiment Analysis on Memes Using Transfer Learning</title>
      <author><first>Mayukh</first><last>Sharma</last></author>
      <author><first>Ilanthenral</first><last>Kandasamy</last></author>
      <author><first>W.b.</first><last>Vasantha</last></author>
      <pages>1163&#8211;1171</pages>
      <abstract>In this paper, we describe our deep learning system used for SemEval 2020 Task 8: Memotion analysis. We participated in all the subtasks i.e Subtask A: Sentiment classification, Subtask B: Humor classification, and Subtask C: Scales of semantic classes. Similar multimodal architecture was used for each subtask. The proposed architecture makes use of transfer learning for images and text feature extraction. The extracted features are then fused together using stacked bidirectional Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU) model with attention mechanism for final predictions. We also propose a single model for predicting semantic classes (Subtask B) as well as their scales (Subtask C) by branching the final output of the post LSTM dense layers. Our model was ranked 5 in Subtask B and ranked 8 in Subtask C and performed nicely in Subtask A on the leader board. Our system makes use of transfer learning for feature extraction and fusion of image and text features for predictions.</abstract>
      <url hash="a2867821">2020.semeval-1.154</url>
      <bibkey>sharma-etal-2020-memebusters</bibkey>
      <doi>10.18653/v1/2020.semeval-1.154</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/memotion-analysis">Memotion Analysis</pwcdataset>
    </paper>
    <paper id="157">
      <title><fixed-case>SIS</fixed-case>@<fixed-case>IIITH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: An Overview of Simple Text Classification Methods for Meme Analysis</title>
      <author><first>Sravani</first><last>Boinepelli</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>1190&#8211;1194</pages>
      <abstract>Memes are steadily taking over the feeds of the public on social media. There is always the threat of malicious users on the internet posting offensive content, even through memes. Hence, the automatic detection of offensive images/memes is imperative along with detection of offensive text. However, this is a much more complex task as it involves both visual cues as well as language understanding and cultural/context knowledge. This paper describes our approach to the task of SemEval-2020 Task 8: Memotion Analysis. We chose to participate only in Task A which dealt with Sentiment Classification, which we formulated as a text classification problem. Through our experiments, we explored multiple training models to evaluate the performance of simple text classification algorithms on the raw text obtained after running OCR on meme images. Our submitted model achieved an accuracy of 72.69% and exceeded the existing baseline&#8217;s Macro F1 score by 8% on the official test dataset. Apart from describing our official submission, we shall elucidate how different classification models respond to this task.</abstract>
      <url hash="ad908cd7">2020.semeval-1.157</url>
      <bibkey>boinepelli-etal-2020-sis</bibkey>
      <doi>10.18653/v1/2020.semeval-1.157</doi>
    </paper>
    <paper id="159">
      <title><fixed-case>U</fixed-case>o<fixed-case>R</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 8: <fixed-case>G</fixed-case>aussian Mixture Modelling (<fixed-case>GMM</fixed-case>) Based Sampling Approach for Multi-modal Memotion Analysis</title>
      <author><first>Zehao</first><last>Liu</last></author>
      <author><first>Emmanuel</first><last>Osei-Brefo</last></author>
      <author><first>Siyuan</first><last>Chen</last></author>
      <author><first>Huizhi</first><last>Liang</last></author>
      <pages>1201&#8211;1207</pages>
      <abstract>Memes are widely used on social media. They usually contain multi-modal information such as images and texts, serving as valuable data sources to analyse opinions and sentiment orientations of online communities. The provided memes data often face an imbalanced data problem, that is, some classes or labelled sentiment categories significantly outnumber other classes. This often results in difficulty in applying machine learning techniques where balanced labelled input data are required. In this paper, a Gaussian Mixture Model sampling method is proposed to tackle the problem of class imbalance for the memes sentiment classification task. To utilise both text and image data, a multi-modal CNN-LSTM model is proposed to jointly learn latent features for positive, negative and neutral category predictions. The experiments show that the re-sampling model can slightly improve the accuracy on the trial data of sub-task A of Task 8. The multi-modal CNN-LSTM model can achieve macro F1 score 0.329 on the test set.</abstract>
      <url hash="13b03497">2020.semeval-1.159</url>
      <bibkey>liu-etal-2020-uor</bibkey>
      <doi>10.18653/v1/2020.semeval-1.159</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/memotion-analysis">Memotion Analysis</pwcdataset>
    </paper>
    <paper id="162">
      <title><fixed-case>BAKSA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Bolstering <fixed-case>CNN</fixed-case> with Self-Attention for Sentiment Analysis of Code Mixed Text</title>
      <author><first>Ayush</first><last>Kumar</last></author>
      <author><first>Harsh</first><last>Agarwal</last></author>
      <author><first>Keshav</first><last>Bansal</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>1221&#8211;1226</pages>
      <abstract>Sentiment Analysis of code-mixed text has diversified applications in opinion mining ranging from tagging user reviews to identifying social or political sentiments of a sub-population. In this paper, we present an ensemble architecture of convolutional neural net (CNN) and self-attention based LSTM for sentiment analysis of code-mixed tweets. While the CNN component helps in the classification of positive and negative tweets, the self-attention based LSTM, helps in the classification of neutral tweets, because of its ability to identify correct sentiment among multiple sentiment bearing units. We achieved F1 scores of 0.707 (ranked 5th) and 0.725 (ranked 13th) on Hindi-English (Hinglish) and Spanish-English (Spanglish) datasets, respectively. The submissions for Hinglish and Spanglish tasks were made under the usernames ayushk and harsh_6 respectively.</abstract>
      <url hash="c7d202b1">2020.semeval-1.162</url>
      <bibkey>kumar-etal-2020-baksa</bibkey>
      <doi>10.18653/v1/2020.semeval-1.162</doi>
      <pwccode url="https://github.com/keshav22bansal/BAKSA_IITK" additional="false">keshav22bansal/BAKSA_IITK</pwccode>
    </paper>
    <paper id="164">
      <title>Deep Learning Brasil - <fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Sentiment Analysis of Code-Mixed Tweets Using Ensemble of Language Models</title>
      <author><first>Manoel</first><last>Ver&#237;ssimo dos Santos Neto</last></author>
      <author><first>Ayrton</first><last>Amaral</last></author>
      <author><first>N&#225;dia</first><last>Silva</last></author>
      <author><first>Anderson</first><last>da Silva Soares</last></author>
      <pages>1233&#8211;1238</pages>
      <abstract>In this paper, we describe a methodology to predict sentiment in code-mixed tweets (hindi-english). Our team called verissimo.manoel in CodaLab developed an approach based on an ensemble of four models (MultiFiT, BERT, ALBERT, and XLNET). The final classification algorithm was an ensemble of some predictions of all softmax values from these four models. This architecture was used and evaluated in the context of the SemEval 2020 challenge (task 9), and our system got 72.7% on the F1 score.</abstract>
      <url hash="b0bac4b5">2020.semeval-1.164</url>
      <bibkey>verissimo-dos-santos-neto-etal-2020-deep</bibkey>
      <doi>10.18653/v1/2020.semeval-1.164</doi>
    </paper>
    <paper id="170">
      <title><fixed-case>IUST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Sentiment Analysis for Code-Mixed Social Media Text Using Deep Neural Networks and Linear Baselines</title>
      <author><first>Soroush</first><last>Javdan</last></author>
      <author><first>Taha</first><last>Shangipour ataei</last></author>
      <author><first>Behrouz</first><last>Minaei-Bidgoli</last></author>
      <pages>1270&#8211;1275</pages>
      <abstract>Sentiment Analysis is a well-studied field of Natural Language Processing. However, the rapid growth of social media and noisy content within them poses significant challenges in addressing this problem with well-established methods and tools. One of these challenges is code-mixing, which means using different languages to convey thoughts in social media texts. Our group, with the name of IUST(username: TAHA), participated at the SemEval-2020 shared task 9 on Sentiment Analysis for Code-Mixed Social Media Text, and we have attempted to develop a system to predict the sentiment of a given code-mixed tweet. We used different preprocessing techniques and proposed to use different methods that vary from NBSVM to more complicated deep neural network models. Our best performing method obtains an F1 score of 0.751 for the Spanish-English sub-task and 0.706 over the Hindi-English sub-task.</abstract>
      <url hash="94093d17">2020.semeval-1.170</url>
      <bibkey>javdan-etal-2020-iust</bibkey>
      <doi>10.18653/v1/2020.semeval-1.170</doi>
    </paper>
    <paper id="174">
      <title><fixed-case>M</fixed-case>eister<fixed-case>M</fixed-case>orxrc at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Fine-Tune Bert and Multitask Learning for Sentiment Analysis of Code-Mixed Tweets</title>
      <author><first>Qi</first><last>Wu</last></author>
      <author><first>Peng</first><last>Wang</last></author>
      <author><first>Chenghao</first><last>Huang</last></author>
      <pages>1294&#8211;1297</pages>
      <abstract>Natural language processing (NLP) has been applied to various fields including text classification and sentiment analysis. In the shared task of sentiment analysis of code-mixed tweets, which is a part of the SemEval-2020 competition, we preprocess datasets by replacing emoji and deleting uncommon characters and so on, and then fine-tune the Bidirectional Encoder Representation from Transformers(BERT) to perform the best. After exhausting top3 submissions, Our team MeisterMorxrc achieves an averaged F1 score of 0.730 in this task, and and our codalab username is MeisterMorxrc</abstract>
      <url hash="fadd8bba">2020.semeval-1.174</url>
      <bibkey>wu-etal-2020-meistermorxrc</bibkey>
      <doi>10.18653/v1/2020.semeval-1.174</doi>
    </paper>
    <paper id="181">
      <title><fixed-case>WESSA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Code-Mixed Sentiment Analysis Using Transformers</title>
      <author><first>Ahmed</first><last>Sultan</last></author>
      <author><first>Mahmoud</first><last>Salim</last></author>
      <author><first>Amina</first><last>Gaber</last></author>
      <author><first>Islam</first><last>El Hosary</last></author>
      <pages>1342&#8211;1347</pages>
      <abstract>In this paper, we describe our system submitted for SemEval 2020 Task 9, Sentiment Analysis for Code-Mixed Social Media Text alongside other experiments. Our best performing system is a Transfer Learning-based model that fine-tunes XLM-RoBERTa, a transformer-based multilingual masked language model, on monolingual English and Spanish data and Spanish-English code-mixed data. Our system outperforms the official task baseline by achieving a 70.1% average F1-Score on the official leaderboard using the test set. For later submissions, our system manages to achieve a 75.9% average F1-Score on the test set using CodaLab username &#8220;ahmed0sultan&#8221;.</abstract>
      <url hash="093170e3">2020.semeval-1.181</url>
      <bibkey>sultan-etal-2020-wessa</bibkey>
      <doi>10.18653/v1/2020.semeval-1.181</doi>
    </paper>
    <paper id="183">
      <title>Zyy1510 Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 9: Sentiment Analysis for Code-Mixed Social Media Text with Sub-word Level Representations</title>
      <author><first>Yueying</first><last>Zhu</last></author>
      <author><first>Xiaobing</first><last>Zhou</last></author>
      <author><first>Hongling</first><last>Li</last></author>
      <author><first>Kunjie</first><last>Dong</last></author>
      <pages>1354&#8211;1359</pages>
      <abstract>This paper reports the zyy1510 team&#8217;s work in the International Workshop on Semantic Evaluation (SemEval-2020) shared task on Sentiment analysis for Code-Mixed (Hindi-English, English-Spanish) Social Media Text. The purpose of this task is to determine the polarity of the text, dividing it into one of the three labels positive, negative and neutral. To achieve this goal, we propose an ensemble model of word n-grams-based Multinomial Naive Bayes (MNB) and sub-word level representations in LSTM (Sub-word LSTM) to identify the sentiments of code-mixed data of Hindi-English and English-Spanish. This ensemble model combines the advantage of rich sequential patterns and the intermediate features after convolution from the LSTM model, and the polarity of keywords from the MNB model to obtain the final sentiment score. We have tested our system on Hindi-English and English-Spanish code-mixed social media data sets released for the task. Our model achieves the F1 score of 0.647 in the Hindi-English task and 0.682 in the English-Spanish task, respectively.</abstract>
      <url hash="fc22ac55">2020.semeval-1.183</url>
      <bibkey>zhu-etal-2020-zyy1510</bibkey>
      <doi>10.18653/v1/2020.semeval-1.183</doi>
    </paper>
    <paper id="188">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Multilingual Offensive Language Identification in Social Media (<fixed-case>O</fixed-case>ffens<fixed-case>E</fixed-case>val 2020)</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Sara</first><last>Rosenthal</last></author>
      <author><first>Pepa</first><last>Atanasova</last></author>
      <author><first>Georgi</first><last>Karadzhov</last></author>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Leon</first><last>Derczynski</last></author>
      <author><first>Zeses</first><last>Pitenis</last></author>
      <author><first>&#199;a&#287;r&#305;</first><last>&#199;&#246;ltekin</last></author>
      <pages>1425&#8211;1447</pages>
      <abstract>We present the results and the main findings of SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval-2020). The task included three subtasks corresponding to the hierarchical taxonomy of the OLID schema from OffensEval-2019, and it was offered in five languages: Arabic, Danish, English, Greek, and Turkish. OffensEval-2020 was one of the most popular tasks at SemEval-2020, attracting a large number of participants across all subtasks and languages: a total of 528 teams signed up to participate in the task, 145 teams submitted official runs on the test data, and 70 teams submitted system description papers.</abstract>
      <url hash="7c06d352">2020.semeval-1.188</url>
      <bibkey>zampieri-etal-2020-semeval</bibkey>
      <doi>10.18653/v1/2020.semeval-1.188</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/dkhate">DKhate</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="189">
      <title>Galileo at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Multi-lingual Learning for Offensive Language Identification Using Pre-trained Language Models</title>
      <author><first>Shuohuan</first><last>Wang</last></author>
      <author><first>Jiaxiang</first><last>Liu</last></author>
      <author><first>Xuan</first><last>Ouyang</last></author>
      <author><first>Yu</first><last>Sun</last></author>
      <pages>1448&#8211;1455</pages>
      <abstract>This paper describes Galileo&#8217;s performance in SemEval-2020 Task 12 on detecting and categorizing offensive language in social media. For Offensive Language Identification, we proposed a multi-lingual method using Pre-trained Language Models, ERNIE and XLM-R. For offensive language categorization, we proposed a knowledge distillation method trained on soft labels generated by several supervised models. Our team participated in all three sub-tasks. In Sub-task A - Offensive Language Identification, we ranked first in terms of average F1 scores in all languages. We are also the only team which ranked among the top three across all languages. We also took the first place in Sub-task B - Automatic Categorization of Offense Types and Sub-task C - Offence Target Identification.</abstract>
      <url hash="fd7b4056">2020.semeval-1.189</url>
      <bibkey>wang-etal-2020-galileo</bibkey>
      <doi>10.18653/v1/2020.semeval-1.189</doi>
    </paper>
    <paper id="191">
      <title>Aschern at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: It Takes Three to Tango: <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a, <fixed-case>CRF</fixed-case>, and Transfer Learning</title>
      <author><first>Anton</first><last>Chernyavskiy</last></author>
      <author><first>Dmitry</first><last>Ilvovsky</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>1462&#8211;1468</pages>
      <abstract>We describe our system for SemEval-2020 Task 11 on Detection of Propaganda Techniques in News Articles. We developed ensemble models using RoBERTa-based neural architectures, additional CRF layers, transfer learning between the two subtasks, and advanced post-processing to handle the multi-label nature of the task, the consistency between nested spans, repetitions, and labels from similar spans in training. We achieved sizable improvements over baseline fine-tuned RoBERTa models, and the official evaluation ranked our system 3rd (almost tied with the 2nd) out of 36 teams on the span identification subtask with an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams on the technique classification subtask with an F1 score of 0.62.</abstract>
      <url hash="a197e0fd">2020.semeval-1.191</url>
      <bibkey>chernyavskiy-etal-2020-aschern</bibkey>
      <doi>10.18653/v1/2020.semeval-1.191</doi>
      <pwccode url="https://github.com/aschern/semeval2020_task11" additional="false">aschern/semeval2020_task11</pwccode>
    </paper>
    <paper id="198">
      <title><fixed-case>A</fixed-case>delaide<fixed-case>C</fixed-case>y<fixed-case>C</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Ensemble of Classifiers for Offensive Language Detection in Social Media</title>
      <author><first>Mahen</first><last>Herath</last></author>
      <author><first>Thushari</first><last>Atapattu</last></author>
      <author><first>Hoang Anh</first><last>Dung</last></author>
      <author><first>Christoph</first><last>Treude</last></author>
      <author><first>Katrina</first><last>Falkner</last></author>
      <pages>1516&#8211;1523</pages>
      <abstract>This paper describes the systems our team (AdelaideCyC) has developed for SemEval Task 12 (OffensEval 2020) to detect offensive language in social media. The challenge focuses on three subtasks &#8211; offensive language identification (subtask A), offense type identification (subtask B), and offense target identification (subtask C). Our team has participated in all the three subtasks. We have developed machine learning and deep learning-based ensembles of models. We have achieved F1-scores of 0.906, 0.552, and 0.623 in subtask A, B, and C respectively. While our performance scores are promising for subtask A, the results demonstrate that subtask B and C still remain challenging to classify.</abstract>
      <url hash="929044de">2020.semeval-1.198</url>
      <bibkey>herath-etal-2020-adelaidecyc</bibkey>
      <doi>10.18653/v1/2020.semeval-1.198</doi>
    </paper>
    <paper id="202">
      <title><fixed-case>G</fixed-case>ru<fixed-case>P</fixed-case>a<fixed-case>T</fixed-case>o at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Retraining m<fixed-case>BERT</fixed-case> on Social Media and Fine-tuned Offensive Language Models</title>
      <author><first>Davide</first><last>Colla</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <author><first>Valerio</first><last>Basile</last></author>
      <author><first>Jelena</first><last>Mitrovi&#263;</last></author>
      <author><first>Michael</first><last>Granitzer</last></author>
      <pages>1546&#8211;1554</pages>
      <abstract>We introduce an approach to multilingual Offensive Language Detection based on the mBERT transformer model. We download extra training data from Twitter in English, Danish, and Turkish, and use it to re-train the model. We then fine-tuned the model on the provided training data and, in some configurations, implement transfer learning approach exploiting the typological relatedness between English and Danish. Our systems obtained good results across the three languages (.9036 for EN, .7619 for DA, and .7789 for TR).</abstract>
      <url hash="09931e41">2020.semeval-1.202</url>
      <bibkey>colla-etal-2020-grupato</bibkey>
      <doi>10.18653/v1/2020.semeval-1.202</doi>
    </paper>
    <paper id="203">
      <title><fixed-case>GUIR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Domain-Tuned Contextualized Models for Offensive Language Detection</title>
      <author><first>Sajad</first><last>Sotudeh</last></author>
      <author><first>Tong</first><last>Xiang</last></author>
      <author><first>Hao-Ren</first><last>Yao</last></author>
      <author><first>Sean</first><last>MacAvaney</last></author>
      <author><first>Eugene</first><last>Yang</last></author>
      <author><first>Nazli</first><last>Goharian</last></author>
      <author><first>Ophir</first><last>Frieder</last></author>
      <pages>1555&#8211;1561</pages>
      <abstract>Offensive language detection is an important and challenging task in natural language processing. We present our submissions to the OffensEval 2020 shared task, which includes three English sub-tasks: identifying the presence of offensive language (Sub-task A), identifying the presence of target in offensive language (Sub-task B), and identifying the categories of the target (Sub-task C). Our experiments explore using a domain-tuned contextualized language model (namely, BERT) for this task. We also experiment with different components and configurations (e.g., a multi-view SVM) stacked upon BERT models for specific sub-tasks. Our submissions achieve F1 scores of 91.7% in Sub-task A, 66.5% in Sub-task B, and 63.2% in Sub-task C. We perform an ablation study which reveals that domain tuning considerably improves the classification performance. Furthermore, error analysis shows common misclassification errors made by our model and outlines research directions for future.</abstract>
      <url hash="f32d0e10">2020.semeval-1.203</url>
      <bibkey>sotudeh-etal-2020-guir</bibkey>
      <doi>10.18653/v1/2020.semeval-1.203</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="204">
      <title><fixed-case>IIITG</fixed-case>-<fixed-case>ADBU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Comparison of <fixed-case>BERT</fixed-case> and <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> in Detecting Offensive Language</title>
      <author><first>Arup</first><last>Baruah</last></author>
      <author><first>Kaushik</first><last>Das</last></author>
      <author><first>Ferdous</first><last>Barbhuiya</last></author>
      <author><first>Kuntal</first><last>Dey</last></author>
      <pages>1562&#8211;1568</pages>
      <abstract>Task 12 of SemEval 2020 consisted of 3 subtasks, namely offensive language identification (Subtask A), categorization of offense type (Subtask B), and offense target identification (Subtask C). This paper presents the results our classifiers obtained for the English language in the 3 subtasks. The classifiers used by us were BERT and BiLSTM. On the test set, our BERT classifier obtained macro F1 score of 0.90707 for subtask A, and 0.65279 for subtask B. The BiLSTM classifier obtained macro F1 score of 0.57565 for subtask C. The paper also performs an analysis of the errors made by our classifiers. We conjecture that the presence of few misleading instances in the dataset is affecting the performance of the classifiers. Our analysis also discusses the need of temporal context and world knowledge to determine the offensiveness of few comments.</abstract>
      <url hash="64833cb4">2020.semeval-1.204</url>
      <bibkey>baruah-etal-2020-iiitg-adbu-semeval</bibkey>
      <doi>10.18653/v1/2020.semeval-1.204</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech-and-offensive-language">Hate Speech and Offensive Language</pwcdataset>
    </paper>
    <paper id="208">
      <title><fixed-case>NUIG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Pseudo Labelling for Offensive Content Classification</title>
      <author><first>Shardul</first><last>Suryawanshi</last></author>
      <author><first>Mihael</first><last>Arcan</last></author>
      <author><first>Paul</first><last>Buitelaar</last></author>
      <pages>1598&#8211;1604</pages>
      <abstract>This work addresses the classification problem defined by sub-task A (English only) of the OffensEval 2020 challenge. We used a semi-supervised approach to classify given tweets into an offensive (OFF) or not-offensive (NOT) class. As the OffensEval 2020 dataset is loosely labelled with confidence scores given by unsupervised models, we used last year&#8217;s offensive language identification dataset (OLID) to label the OffensEval 2020 dataset. Our approach uses a pseudo-labelling method to annotate the current dataset. We trained four text classifiers on the OLID dataset and the classifier with the highest macro-averaged F1-score has been used to pseudo label the OffensEval 2020 dataset. The same model which performed best amongst four text classifiers on OLID dataset has been trained on the combined dataset of OLID and pseudo labelled OffensEval 2020. We evaluated the classifiers with precision, recall and macro-averaged F1-score as the primary evaluation metric on the OLID and OffensEval 2020 datasets. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Licence details: <url>http://creativecommons.org/licenses/by/4.0/</url>.</abstract>
      <url hash="d796fa3e">2020.semeval-1.208</url>
      <bibkey>suryawanshi-etal-2020-nuig</bibkey>
      <doi>10.18653/v1/2020.semeval-1.208</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="213">
      <title><fixed-case>UHH</fixed-case>-<fixed-case>LT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Fine-Tuning of Pre-Trained Transformer Networks for Offensive Language Detection</title>
      <author><first>Gregor</first><last>Wiedemann</last></author>
      <author><first>Seid Muhie</first><last>Yimam</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>1638&#8211;1644</pages>
      <abstract>Fine-tuning of pre-trained transformer networks such as BERT yield state-of-the-art results for text classification tasks. Typically, fine-tuning is performed on task-specific training datasets in a supervised manner. One can also fine-tune in unsupervised manner beforehand by further pre-training the masked language modeling (MLM) task. Hereby, in-domain data for unsupervised MLM resembling the actual classification target dataset allows for domain adaptation of the model. In this paper, we compare current pre-trained transformer networks with and without MLM fine-tuning on their performance for offensive language detection. Our MLM fine-tuned RoBERTa-based classifier officially ranks 1st in the SemEval 2020 Shared Task 12 for the English language. Further experiments with the ALBERT model even surpass this result.</abstract>
      <url hash="aeb6b4e3">2020.semeval-1.213</url>
      <bibkey>wiedemann-etal-2020-uhh</bibkey>
      <doi>10.18653/v1/2020.semeval-1.213</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="214">
      <title><fixed-case>EL</fixed-case>-<fixed-case>BERT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 10: A Multi-Embedding Ensemble Based Approach for Emphasis Selection in Visual Media</title>
      <author><first>Chandresh</first><last>Kanani</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>1645&#8211;1651</pages>
      <abstract>In visual media, text emphasis is the strengthening of words in a text to convey the intent of the author. Text emphasis in visual media is generally done by using different colors, backgrounds, or font for the text; it helps in conveying the actual meaning of the message to the readers. Emphasis selection is the task of choosing candidate words for emphasis, it helps in automatically designing posters and other media contents with written text. If we consider only the text and do not know the intent, then there can be multiple valid emphasis selections. We propose the use of ensembles for emphasis selection to improve over single emphasis selection models. We show that the use of multi-embedding helps in enhancing the results for base models. To show the efficacy of proposed approach we have also done a comparison of our results with state-of-the-art models.</abstract>
      <url hash="a4c4fdbc">2020.semeval-1.214</url>
      <bibkey>kanani-etal-2020-el</bibkey>
      <doi>10.18653/v1/2020.semeval-1.214</doi>
    </paper>
    <paper id="218">
      <title><fixed-case>LAST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 10: Finding Tokens to Emphasise in Short Written Texts with Precomputed Embedding Models and <fixed-case>L</fixed-case>ight<fixed-case>GBM</fixed-case></title>
      <author><first>Yves</first><last>Bestgen</last></author>
      <pages>1671&#8211;1677</pages>
      <abstract>To select tokens to be emphasised in short texts, a system mainly based on precomputed embedding models, such as BERT and ELMo, and LightGBM is proposed. Its performance is low. Additional analyzes suggest that its effectiveness is poor at predicting the highest emphasis scores while they are the most important for the challenge and that it is very sensitive to the specific instances provided during learning.</abstract>
      <url hash="f6a1f955">2020.semeval-1.218</url>
      <bibkey>bestgen-2020-last</bibkey>
      <doi>10.18653/v1/2020.semeval-1.218</doi>
    </paper>
    <paper id="220">
      <title>Randomseed19 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 10: Emphasis Selection for Written Text in Visual Media</title>
      <author><first>Aleksandr</first><last>Shatilov</last></author>
      <author><first>Denis</first><last>Gordeev</last></author>
      <author><first>Alexey</first><last>Rey</last></author>
      <pages>1685&#8211;1690</pages>
      <abstract>This paper describes our approach to emphasis selection for written text in visual media as a solution for SemEval 2020 Task 10. We used an ensemble of several different Transformer-based models and cast the task as a sequence labeling problem with two tags: &#8216;I&#8217; as &#8216;emphasized&#8217; and &#8216;O&#8217; as &#8216;non-emphasized&#8217; for each token in the text.</abstract>
      <url hash="aab27287">2020.semeval-1.220</url>
      <bibkey>shatilov-etal-2020-randomseed19</bibkey>
      <doi>10.18653/v1/2020.semeval-1.220</doi>
    </paper>
    <paper id="224">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 10: Using a Multi-granularity Ordinal Classification of the <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Model for Emphasis Selection</title>
      <author><first>Dawei</first><last>Liao</last></author>
      <author><first>Jin</first><last>Wang</last></author>
      <author><first>Xuejie</first><last>Zhang</last></author>
      <pages>1710&#8211;1715</pages>
      <abstract>In this study, we propose a multi-granularity ordinal classification method to address the problem of emphasis selection. In detail, the word embedding is learned from Embeddings from Language Model (ELMO) to extract feature vector representation. Then, the ordinal classifica-tions are implemented on four different multi-granularities to approximate the continuous em-phasize values. Comparative experiments were conducted to compare the model with baseline in which the problem is transformed to label distribution problem.</abstract>
      <url hash="daa59896">2020.semeval-1.224</url>
      <bibkey>liao-etal-2020-ynu</bibkey>
      <doi>10.18653/v1/2020.semeval-1.224</doi>
    </paper>
    <paper id="229">
      <title><fixed-case>JUST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Detecting Propaganda Techniques Using <fixed-case>BERT</fixed-case> Pre-trained Model</title>
      <author><first>Ola</first><last>Altiti</last></author>
      <author><first>Malak</first><last>Abdullah</last></author>
      <author><first>Rasha</first><last>Obiedat</last></author>
      <pages>1749&#8211;1755</pages>
      <abstract>This paper presents the submission to semeval-2020 task 11, Detection of Propaganda Techniques in News Articles. Knowing that there are two subtasks in this competition, we have participated in the Technique Classification subtask (TC), which aims to identify the propaganda techniques used in a specific propaganda span. We have used and implemented various models to detect propaganda. Our proposed model is based on BERT uncased pre-trained language model as it has achieved state-of-the-art performance on multiple NLP benchmarks. The performance results of our proposed model have scored 0.55307 F1-Score, which outperforms the baseline model provided by the organizers with 0.2519 F1-Score, and our model is 0.07 away from the best performing team. Compared to other participating systems, our submission is ranked 15th out of 31 participants.</abstract>
      <url hash="bdfcdc1e">2020.semeval-1.229</url>
      <bibkey>altiti-etal-2020-just</bibkey>
      <doi>10.18653/v1/2020.semeval-1.229</doi>
    </paper>
    <paper id="232">
      <title><fixed-case>NLFIIT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Neural Network Architectures for Detection of Propaganda Techniques in News Articles</title>
      <author><first>Matej</first><last>Martinkovic</last></author>
      <author><first>Samuel</first><last>Pecar</last></author>
      <author><first>Marian</first><last>Simko</last></author>
      <pages>1771&#8211;1778</pages>
      <abstract>Since propaganda became more common technique in news, it is very important to look for possibilities of its automatic detection. In this paper, we present neural model architecture submitted to the SemEval-2020 Task 11 competition: &#8220;Detection of Propaganda Techniques in News Articles&#8221;. We participated in both subtasks, propaganda span identification and propaganda technique classification. Our model utilizes recurrent Bi-LSTM layers with pre-trained word representations and also takes advantage of self-attention mechanism. Our model managed to achieve score 0.405 F1 for subtask 1 and 0.553 F1 for subtask 2 on test set resulting in 17th and 16th place in subtask 1 and subtask 2, respectively.</abstract>
      <url hash="a6ad55e6">2020.semeval-1.232</url>
      <bibkey>martinkovic-etal-2020-nlfiit</bibkey>
      <doi>10.18653/v1/2020.semeval-1.232</doi>
    </paper>
    <paper id="233">
      <title><fixed-case>P</fixed-case>suedo<fixed-case>P</fixed-case>rop at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Propaganda Span Detection Using <fixed-case>BERT</fixed-case>-<fixed-case>CRF</fixed-case> and Ensemble Sentence Level Classifier</title>
      <author><first>Aniruddha</first><last>Chauhan</last></author>
      <author><first>Harshita</first><last>Diddee</last></author>
      <pages>1779&#8211;1785</pages>
      <abstract>This paper explains our teams&#8217; submission to the Shared Task of Fine-Grained Propaganda Detection in which we propose a sequential BERT-CRF based Span Identification model where the fine-grained detection is carried out only on the articles that are flagged as containing propaganda by an ensemble SLC model. We propose this setup bearing in mind the practicality of this approach in identifying propaganda spans in the exponentially increasing content base where the fine-tuned analysis of the entire data repository may not be the optimal choice due to its massive computational resource requirements. We present our analysis on different voting ensembles for the SLC model. Our system ranks 14th on the test set and 22nd on the development set and with an F1 score of 0.41 and 0.39 respectively.</abstract>
      <url hash="f8778a6e">2020.semeval-1.233</url>
      <bibkey>chauhan-diddee-2020-psuedoprop</bibkey>
      <doi>10.18653/v1/2020.semeval-1.233</doi>
    </paper>
    <paper id="234">
      <title><fixed-case>S</fixed-case>koltech<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Exploring Unsupervised Text Augmentation for Propaganda Detection</title>
      <author><first>Daryna</first><last>Dementieva</last></author>
      <author><first>Igor</first><last>Markov</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>1786&#8211;1792</pages>
      <abstract>This paper presents a solution for the Span Identification (SI) task in the &#8220;Detection of Propaganda Techniques in News Articles&#8221; competition at SemEval-2020. The goal of the SI task is to identify specific fragments of each article which contain the use of at least one propaganda technique. This is a binary sequence tagging task. We tested several approaches finally selecting a fine-tuned BERT model as our baseline model. Our main contribution is an investigation of several unsupervised data augmentation techniques based on distributional semantics expanding the original small training dataset as applied to this BERT-based sequence tagger. We explore various expansion strategies and show that they can substantially shift the balance between precision and recall, while maintaining comparable levels of the F1 score.</abstract>
      <url hash="852acda9">2020.semeval-1.234</url>
      <bibkey>dementieva-etal-2020-skoltechnlp</bibkey>
      <doi>10.18653/v1/2020.semeval-1.234</doi>
    </paper>
    <paper id="237">
      <title>syrapropa at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: <fixed-case>BERT</fixed-case>-based Models Design for Propagandistic Technique and Span Detection</title>
      <author><first>Jinfen</first><last>Li</last></author>
      <author><first>Lu</first><last>Xiao</last></author>
      <pages>1808&#8211;1816</pages>
      <abstract>This paper describes the BERT-based models proposed for two subtasks in SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles. We first build the model for Span Identification (SI) based on SpanBERT, and facilitate the detection by a deeper model and a sentence-level representation. We then develop a hybrid model for the Technique Classification (TC). The hybrid model is composed of three submodels including two BERT models with different training methods, and a feature-based Logistic Regression model. We endeavor to deal with imbalanced dataset by adjusting cost function. We are in the seventh place in SI subtask (0.4711 of F1-measure), and in the third place in TC subtask (0.6783 of F1-measure) on the development set.</abstract>
      <url hash="4cbddd57">2020.semeval-1.237</url>
      <bibkey>li-xiao-2020-syrapropa</bibkey>
      <doi>10.18653/v1/2020.semeval-1.237</doi>
    </paper>
    <paper id="238">
      <title>Team <fixed-case>D</fixed-case>i<fixed-case>S</fixed-case>aster at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Combining <fixed-case>BERT</fixed-case> and Hand-crafted Features for Identifying Propaganda Techniques in News</title>
      <author><first>Anders</first><last>Kaas</last></author>
      <author><first>Viktor Torp</first><last>Thomsen</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>1817&#8211;1822</pages>
      <abstract>The identification of communication techniques in news articles such as propaganda is important, as such techniques can influence the opinions of large numbers of people. Most work so far focused on the identification at the news article level. Recently, a new dataset and shared task has been proposed for the identification of propaganda techniques at the finer-grained span level. This paper describes our system submission to the subtask of technique classification (TC) for the SemEval 2020 shared task on detection of propaganda techniques in news articles. We propose a method of combining neural BERT representations with hand-crafted features via stacked generalization. Our model has the added advantage that it combines the power of contextual representations from BERT with simple span-based and article-based global features. We present an ablation study which shows that even though BERT representations are very powerful also for this task, BERT still benefits from being combined with carefully designed task-specific features.</abstract>
      <url hash="753aa8ba">2020.semeval-1.238</url>
      <bibkey>kaas-etal-2020-team</bibkey>
      <doi>10.18653/v1/2020.semeval-1.238</doi>
    </paper>
    <paper id="240">
      <title><fixed-case>TTUI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Propaganda Detection with Transfer Learning and Ensembles</title>
      <author><first>Moonsung</first><last>Kim</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>1829&#8211;1834</pages>
      <abstract>In this paper, we describe our approaches and systems for the SemEval-2020 Task 11 on propaganda technique detection. We fine-tuned BERT and RoBERTa pre-trained models then merged them with an average ensemble. We conducted several experiments for input representations dealing with long texts and preserving context as well as for the imbalanced class problem. Our system ranked 20th out of 36 teams with 0.398 F1 in the SI task and 14th out of 31 teams with 0.556 F1 in the TC task.</abstract>
      <url hash="78cb2802">2020.semeval-1.240</url>
      <bibkey>kim-bethard-2020-ttui</bibkey>
      <doi>10.18653/v1/2020.semeval-1.240</doi>
    </paper>
    <paper id="241">
      <title><fixed-case>UAIC</fixed-case>1860 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Detection of Propaganda Techniques in News Articles</title>
      <author><first>Vlad</first><last>Ermurachi</last></author>
      <author><first>Daniela</first><last>Gifu</last></author>
      <pages>1835&#8211;1840</pages>
      <abstract>The &#8220;Detection of Propaganda Techniques in News Articles&#8221; task at the SemEval 2020 competition focuses on detecting and classifying propaganda, pervasive in news article. In this paper, we present a system able to evaluate on sentence level, three traditional text representation techniques for these study goals, using: tf*idf, word and character n-grams. Firstly, we built a binary classifier able to provide corresponding propaganda labels, propaganda or non-propaganda. Secondly, we build a multilabel multiclass model to identify applied propaganda.</abstract>
      <url hash="38229a7c">2020.semeval-1.241</url>
      <bibkey>ermurachi-gifu-2020-uaic1860</bibkey>
      <doi>10.18653/v1/2020.semeval-1.241</doi>
    </paper>
    <paper id="242">
      <title><fixed-case>UMSIF</fixed-case>oreseer at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Propaganda Detection by Fine-Tuning <fixed-case>BERT</fixed-case> with Resampling and Ensemble Learning</title>
      <author><first>Yunzhe</first><last>Jiang</last></author>
      <author><first>Cristina</first><last>Garbacea</last></author>
      <author><first>Qiaozhu</first><last>Mei</last></author>
      <pages>1841&#8211;1846</pages>
      <abstract>We describe our participation at the SemEval 2020 &#8220;Detection of Propaganda Techniques in News Articles&#8221; - Techniques Classification (TC) task, designed to categorize textual fragments into one of the 14 given propaganda techniques. Our solution leverages pre-trained BERT models. We present our model implementations, evaluation results and analysis of these results. We also investigate the potential of combining language models with resampling and ensemble learning methods to deal with data imbalance and improve performance.</abstract>
      <url hash="95d18f74">2020.semeval-1.242</url>
      <bibkey>jiang-etal-2020-umsiforeseer</bibkey>
      <doi>10.18653/v1/2020.semeval-1.242</doi>
    </paper>
    <paper id="243">
      <title><fixed-case>UNTL</fixed-case>ing at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 11: Detection of Propaganda Techniques in <fixed-case>E</fixed-case>nglish News Articles</title>
      <author><first>Maia</first><last>Petee</last></author>
      <author><first>Alexis</first><last>Palmer</last></author>
      <pages>1847&#8211;1852</pages>
      <abstract>Our system for the PropEval task explores the ability of semantic features to detect and label propagandistic rhetorical techniques in English news articles. For Subtask 2, labeling identified propagandistic fragments with one of fourteen technique labels, our system attains a micro-averaged F1 of 0.40; in this paper, we take a detailed look at the fourteen labels and how well our semantically-focused model detects each of them. We also propose strategies to fill the gaps.</abstract>
      <url hash="6bdf11e1">2020.semeval-1.243</url>
      <bibkey>petee-palmer-2020-untling</bibkey>
      <doi>10.18653/v1/2020.semeval-1.243</doi>
    </paper>
    <paper id="250">
      <title>Amsqr at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Offensive Language Detection Using Neural Networks and Anti-adversarial Features</title>
      <author><first>Alejandro</first><last>Mosquera</last></author>
      <pages>1898&#8211;1905</pages>
      <abstract>This paper describes a method and system to solve the problem of detecting offensive language in social media using anti-adversarial features. Our submission to the SemEval-2020 task 12 challenge was generated by an stacked ensemble of neural networks fine-tuned on the OLID dataset and additional external sources. For Task-A (English), text normalisation filters were applied at both graphical and lexical level. The normalisation step effectively mitigates not only the natural presence of lexical variants but also intentional attempts to bypass moderation by introducing out of vocabulary words. Our approach provides strong F1 scores for both 2020 (0.9134) and 2019 (0.8258) challenges.</abstract>
      <url hash="3950af80">2020.semeval-1.250</url>
      <bibkey>mosquera-2020-amsqr</bibkey>
      <doi>10.18653/v1/2020.semeval-1.250</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="258">
      <title>Hitachi at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Offensive Language Identification with Noisy Labels Using Statistical Sampling and Post-Processing</title>
      <author><first>Manikandan</first><last>Ravikiran</last></author>
      <author><first>Amin Ekant</first><last>Muljibhai</last></author>
      <author><first>Toshinori</first><last>Miyoshi</last></author>
      <author><first>Hiroaki</first><last>Ozaki</last></author>
      <author><first>Yuta</first><last>Koreeda</last></author>
      <author><first>Sakata</first><last>Masayuki</last></author>
      <pages>1961&#8211;1967</pages>
      <abstract>In this paper, we present our participation in SemEval-2020 Task-12 Subtask-A (English Language) which focuses on offensive language identification from noisy labels. To this end, we developed a hybrid system with the BERT classifier trained with tweets selected using Statistical Sampling Algorithm (SA) and Post-Processed (PP) using an offensive wordlist. Our developed system achieved 34th position with Macro-averaged F1-score (Macro-F1) of 0.90913 over both offensive and non-offensive classes. We further show comprehensive results and error analysis to assist future research in offensive language identification with noisy labels.</abstract>
      <url hash="0a6cca3d">2020.semeval-1.258</url>
      <bibkey>ravikiran-etal-2020-hitachi</bibkey>
      <doi>10.18653/v1/2020.semeval-1.258</doi>
    </paper>
    <paper id="263">
      <title><fixed-case>IR</fixed-case>3218-<fixed-case>UI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Emoji Effects on Offensive Language <fixed-case>I</fixed-case>dentifi<fixed-case>C</fixed-case>ation</title>
      <author><first>Sandy</first><last>Kurniawan</last></author>
      <author><first>Indra</first><last>Budi</last></author>
      <author><first>Muhammad Okky</first><last>Ibrohim</last></author>
      <pages>1998&#8211;2005</pages>
      <abstract>In this paper, we present our approach and the results of our participation in OffensEval 2020. There are three sub-tasks in OffensEval 2020 namely offensive language identification (sub-task A), automatic categorization of offense types (sub-task B), and offense target identification (sub-task C). We participated in sub-task A of English OffensEval 2020. Our approach emphasizes on how the emoji affects offensive language identification. Our model used LSTM combined with GloVe pre-trained word vectors to identify offensive language on social media. The best model obtained macro F1-score of 0.88428.</abstract>
      <url hash="faa9f188">2020.semeval-1.263</url>
      <bibkey>kurniawan-etal-2020-ir3218</bibkey>
      <doi>10.18653/v1/2020.semeval-1.263</doi>
    </paper>
    <paper id="266">
      <title><fixed-case>JCT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Offensive Language Detection in Tweets Using Preprocessing Methods, Character and Word N-grams</title>
      <author><first>Moshe</first><last>Uzan</last></author>
      <author><first>Yaakov</first><last>HaCohen-Kerner</last></author>
      <pages>2017&#8211;2022</pages>
      <abstract>In this paper, we describe our submissions to SemEval-2020 contest. We tackled subtask 12 - &#8220;Multilingual Offensive Language Identification in Social Media&#8221;. We developed different models for four languages: Arabic, Danish, Greek, and Turkish. We applied three supervised machine learning methods using various combinations of character and word n-gram features. In addition, we applied various combinations of basic preprocessing methods. Our best submission was a model we built for offensive language identification in Danish using Random Forest. This model was ranked at the 6 position out of 39 submissions. Our result is lower by only 0.0025 than the result of the team that won the 4 place using entirely non-neural methods. Our experiments indicate that char ngram features are more helpful than word ngram features. This phenomenon probably occurs because tweets are more characterized by characters than by words, tweets are short, and contain various special sequences of characters, e.g., hashtags, shortcuts, slang words, and typos.</abstract>
      <url hash="7c457f64">2020.semeval-1.266</url>
      <bibkey>uzan-hacohen-kerner-2020-jct</bibkey>
      <doi>10.18653/v1/2020.semeval-1.266</doi>
    </paper>
    <paper id="273">
      <title>Lee at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: A <fixed-case>BERT</fixed-case> Model Based on the Maximum Self-ensemble Strategy for Identifying Offensive Language</title>
      <author><first>Junyi</first><last>Li</last></author>
      <author><first>Xiaobing</first><last>Zhou</last></author>
      <author><first>Zichen</first><last>Zhang</last></author>
      <pages>2067&#8211;2072</pages>
      <abstract>This article describes the system submitted to SemEval 2020 Task 12: OffensEval 2020. This task aims to identify and classify offensive languages in different languages on social media. We only participate in the English part of subtask A, which aims to identify offensive languages in English. To solve this task, we propose a BERT model system based on the transform mechanism, and use the maximum self-ensemble to improve model performance. Our model achieved a macro F1 score of 0.913(ranked 13/82) in subtask A.</abstract>
      <url hash="30f9cbdf">2020.semeval-1.273</url>
      <bibkey>li-etal-2020-lee-semeval</bibkey>
      <doi>10.18653/v1/2020.semeval-1.273</doi>
    </paper>
    <paper id="274">
      <title><fixed-case>LIIR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: A Cross-Lingual Augmentation Approach for Multilingual Offensive Language Identification</title>
      <author><first>Erfan</first><last>Ghadery</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>2073&#8211;2079</pages>
      <abstract>This paper presents our system entitled &#8216;LIIR&#8217; for SemEval-2020 Task 12 on Multilingual Offensive Language Identification in Social Media (OffensEval 2). We have participated in sub-task A for English, Danish, Greek, Arabic, and Turkish languages. We adapt and fine-tune the BERT and Multilingual Bert models made available by Google AI for English and non-English languages respectively. For the English language, we use a combination of two fine-tuned BERT models. For other languages we propose a cross-lingual augmentation approach in order to enrich training data and we use Multilingual BERT to obtain sentence representations.</abstract>
      <url hash="2541f3e5">2020.semeval-1.274</url>
      <bibkey>ghadery-moens-2020-liir</bibkey>
      <doi>10.18653/v1/2020.semeval-1.274</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="283">
      <title><fixed-case>S</fixed-case>alam<fixed-case>NET</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Deep Learning Approach for <fixed-case>A</fixed-case>rabic Offensive Language Detection</title>
      <author><first>Fatemah</first><last>Husain</last></author>
      <author><first>Jooyeon</first><last>Lee</last></author>
      <author><first>Sam</first><last>Henry</last></author>
      <author><first>Ozlem</first><last>Uzuner</last></author>
      <pages>2133&#8211;2139</pages>
      <abstract>This paper describes SalamNET, an Arabic offensive language detection system that has been submitted to SemEval 2020 shared task 12: Multilingual Offensive Language Identification in Social Media. Our approach focuses on applying multiple deep learning models and conducting in depth error analysis of results to provide system implications for future development considerations. To pursue our goal, a Recurrent Neural Network (RNN), a Gated Recurrent Unit (GRU), and Long-Short Term Memory (LSTM) models with different design architectures have been developed and evaluated. The SalamNET, a Bi-directional Gated Recurrent Unit (Bi-GRU) based model, reports a macro-F1 score of 0.83%</abstract>
      <url hash="af3d59f6">2020.semeval-1.283</url>
      <bibkey>husain-etal-2020-salamnet</bibkey>
      <doi>10.18653/v1/2020.semeval-1.283</doi>
    </paper>
    <paper id="285">
      <title>Sonal.kumari at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Social Media Multilingual Offensive Text Identification and Categorization Using Neural Network Models</title>
      <author><first>Sonal</first><last>Kumari</last></author>
      <pages>2146&#8211;2154</pages>
      <abstract>In this paper, we present our approaches and results for SemEval-2020 Task 12, Multilingual Offensive Language Identification in Social Media (OffensEval 2020). The OffensEval 2020 had three subtasks: A) Identifying the tweets to be offensive (OFF) or non-offensive (NOT) for Arabic, Danish, English, Greek, and Turkish languages, B) Detecting if the offensive tweet is targeted (TIN) or untargeted (UNT) for the English language, and C) Categorizing the offensive targeted tweets into three classes, namely: individual (IND), Group (GRP), or Other (OTH) for the English language. We participate in all the subtasks A, B, and C. In our solution, first we use the pre-trained BERT model for all subtasks, A, B, and C and then we apply the BiLSTM model with attention mechanism (Attn-BiLSTM) for the same. Our result demonstrates that the pre-trained model is not giving good results for all types of languages and is compute and memory intensive whereas the Attn-BiLSTM model is fast and gives good accuracy with fewer resources. The Attn-BiLSTM model is giving better accuracy for Arabic and Greek where the pre-trained model is not able to capture the complete context of these languages due to lower vocab-size.</abstract>
      <url hash="c5930894">2020.semeval-1.285</url>
      <bibkey>kumari-2020-sonal</bibkey>
      <doi>10.18653/v1/2020.semeval-1.285</doi>
    </paper>
    <paper id="287">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>NLP</fixed-case>_<fixed-case>MLRG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Offensive Language Identification in <fixed-case>E</fixed-case>nglish, <fixed-case>D</fixed-case>anish, <fixed-case>G</fixed-case>reek Using <fixed-case>BERT</fixed-case> and Machine Learning Approach</title>
      <author><first>A</first><last>Kalaivani</last></author>
      <author><first>Thenmozhi</first><last>D.</last></author>
      <pages>2161&#8211;2170</pages>
      <abstract>Offensive language identification is to detect the hurtful tweets, derogatory comments, swear words on social media. As an emerging growth of social media communication, offensive language detection has received more attention in the last years; we focus to perform the task on English, Danish and Greek. We have investigated which can be effect more on pre-trained models BERT (Bidirectional Encoder Representation from Transformer) and Machine Learning Approaches. Our investigation shows the difference performance between the three languages and to identify the best performance is evaluated by the classification algorithms. In the shared task SemEval-2020, our team SSN_NLP_MLRG submitted for three languages that are Subtasks A, B, C in English, Subtask A in Danish and Subtask A in Greek. Our team SSN_NLP_MLRG obtained the F1 Scores as 0.90, 0.61, 0.52 for the Subtasks A, B, C in English, 0.56 for the Subtask A in Danish and 0.67 for the Subtask A in Greek respectively.</abstract>
      <url hash="d7f35faf">2020.semeval-1.287</url>
      <bibkey>kalaivani-d-2020-ssn</bibkey>
      <doi>10.18653/v1/2020.semeval-1.287</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="289">
      <title><fixed-case>TAC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Ensembling Approach for Multilingual Offensive Language Identification in Social Media</title>
      <author><first>Talha</first><last>Anwar</last></author>
      <author><first>Omer</first><last>Baig</last></author>
      <pages>2177&#8211;2182</pages>
      <abstract>Usage of offensive language on social media is getting more common these days, and there is a need of a mechanism to detect it and control it. This paper deals with offensive language detection in five different languages; English, Arabic, Danish, Greek and Turkish. We presented an almost similar ensemble pipeline comprised of machine learning and deep learning models for all five languages. Three machine learning and four deep learning models were used in the ensemble. In the OffensEval-2020 competition our model achieved F1-score of 0.85, 0.74, 0.68, 0.81, and 0.9 for Arabic, Turkish, Danish, Greek and English language tasks respectively.</abstract>
      <url hash="9b3b6acd">2020.semeval-1.289</url>
      <bibkey>anwar-baig-2020-tac</bibkey>
      <doi>10.18653/v1/2020.semeval-1.289</doi>
      <pwccode url="https://github.com/talhaanwarch/offenseeval2020" additional="false">talhaanwarch/offenseeval2020</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="295">
      <title><fixed-case>U</fixed-case>o<fixed-case>B</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2020 Task 12: Boosting <fixed-case>BERT</fixed-case> with Corpus Level Information</title>
      <author><first>Wah Meng</first><last>Lim</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <pages>2216&#8211;2221</pages>
      <abstract>Pre-trained language model word representation, such as BERT, have been extremely successful in several Natural Language Processing tasks significantly improving on the state-of-the-art. This can largely be attributed to their ability to better capture semantic information contained within a sentence. Several tasks, however, can benefit from information available at a corpus level, such as Term Frequency-Inverse Document Frequency (TF-IDF). In this work we test the effectiveness of integrating this information with BERT on the task of identifying abuse on social media and show that integrating this information with BERT does indeed significantly improve performance. We participate in Sub-Task A (abuse detection) wherein we achieve a score within two points of the top performing team and in Sub-Task B (target detection) wherein we are ranked 4 of the 44 participating teams.</abstract>
      <url hash="709f5882">2020.semeval-1.295</url>
      <bibkey>lim-tayyar-madabushi-2020-uob</bibkey>
      <doi>10.18653/v1/2020.semeval-1.295</doi>
    </paper>
    </volume>
</collection>