<collection id="2021.unimplicit">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language</booktitle>
      <editor><first>Michael</first><last>Roth</last></editor>
      <editor><first>Reut</first><last>Tsarfaty</last></editor>
      <editor><first>Yoav</first><last>Goldberg</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="2f1d2093">2021.unimplicit-1</url>
    </meta>
    <frontmatter>
      <url hash="ef56eece">2021.unimplicit-1.0</url>
      <bibkey>unimplicit-2021-understanding</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Evaluation Guidelines to Deal with Implicit Phenomena to Assess Factuality in Data-to-Text Generation</title>
      <author><first>Roy</first><last>Eisenstadt</last></author>
      <author><first>Michael</first><last>Elhadad</last></author>
      <pages>20&#8211;27</pages>
      <abstract>Data-to-text generation systems are trained on large datasets, such as WebNLG, Ro-toWire, E2E or DART. Beyond traditional token-overlap evaluation metrics (BLEU or METEOR), a key concern faced by recent generators is to control the factuality of the generated text with respect to the input data specification. We report on our experience when developing an automatic factuality evaluation system for data-to-text generation that we are testing on WebNLG and E2E data. We aim to prepare gold data annotated manually to identify cases where the text communicates more information than is warranted based on the in-put data (extra) or fails to communicate data that is part of the input (missing). While analyzing reference (data, text) samples, we encountered a range of systematic uncertainties that are related to cases on implicit phenomena in text, and the nature of non-linguistic knowledge we expect to be involved when assessing factuality. We derive from our experience a set of evaluation guidelines to reach high inter-annotator agreement on such cases.</abstract>
      <url hash="56cda1bd">2021.unimplicit-1.3</url>
      <doi>10.18653/v1/2021.unimplicit-1.3</doi>
      <bibkey>eisenstadt-elhadad-2021-evaluation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rotowire">RotoWire</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikibio">WikiBio</pwcdataset>
    </paper>
    <paper id="4">
      <title><fixed-case>U</fixed-case>n<fixed-case>I</fixed-case>mplicit Shared Task Report: Detecting Clarification Requirements in Instructional Text</title>
      <author><first>Michael</first><last>Roth</last></author>
      <author><first>Talita</first><last>Anthonio</last></author>
      <pages>28&#8211;32</pages>
      <abstract>This paper describes the data, task setup, and results of the shared task at the First Workshop on Understanding Implicit and Underspecified Language (UnImplicit). The task requires computational models to predict whether a sentence contains aspects of meaning that are contextually unspecified and thus require clarification. Two teams participated and the best scoring system achieved an accuracy of 68%.</abstract>
      <url hash="e7673810">2021.unimplicit-1.4</url>
      <doi>10.18653/v1/2021.unimplicit-1.4</doi>
      <bibkey>roth-anthonio-2021-unimplicit</bibkey>
    </paper>
    <paper id="6">
      <title>Human-Model Divergence in the Handling of Vagueness</title>
      <author><first>Elias</first><last>Stengel-Eskin</last></author>
      <author><first>Jimena</first><last>Guallar-Blasco</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>43&#8211;57</pages>
      <abstract>While aggregate performance metrics can generate valuable insights at a large scale, their dominance means more complex and nuanced language phenomena, such as vagueness, may be overlooked. Focusing on vague terms (e.g. sunny, cloudy, young, etc.) we inspect the behavior of visually grounded and text-only models, finding systematic divergences from human judgments even when a model&#8217;s overall performance is high. To help explain this disparity, we identify two assumptions made by the datasets and models examined and, guided by the philosophy of vagueness, isolate cases where they do not hold.</abstract>
      <url hash="c34ab4ad">2021.unimplicit-1.6</url>
      <doi>10.18653/v1/2021.unimplicit-1.6</doi>
      <bibkey>stengel-eskin-etal-2021-human</bibkey>
    </paper>
    </volume>
</collection>