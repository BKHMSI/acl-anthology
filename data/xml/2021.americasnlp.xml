<collection id="2021.americasnlp">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</booktitle>
      <editor><first>Manuel</first><last>Mager</last></editor>
      <editor><first>Arturo</first><last>Oncevay</last></editor>
      <editor><first>Annette</first><last>Rios</last></editor>
      <editor><first>Ivan Vladimir Meza</first><last>Ruiz</last></editor>
      <editor><first>Alexis</first><last>Palmer</last></editor>
      <editor><first>Graham</first><last>Neubig</last></editor>
      <editor><first>Katharina</first><last>Kann</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.americasnlp-1</url>
    </meta>
    <frontmatter>
      <url hash="beb9eed7">2021.americasnlp-1.0</url>
      <bibkey>americasnlp-2021-natural</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Investigating variation in written forms of <fixed-case>N</fixed-case>ahuatl using character-based language models</title>
      <author><first>Robert</first><last>Pugh</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <pages>21&#8211;27</pages>
      <abstract>We describe experiments with character-based language modeling for written variants of Nahuatl. Using a standard LSTM model and publicly available Bible translations, we explore how character language models can be applied to the tasks of estimating mutual intelligibility, identifying genetic similarity, and distinguishing written variants. We demonstrate that these simple language models are able to capture similarities and differences that have been described in the linguistic literature.</abstract>
      <url hash="ba4bb55f">2021.americasnlp-1.3</url>
      <doi>10.18653/v1/2021.americasnlp-1.3</doi>
      <bibkey>pugh-tyers-2021-investigating</bibkey>
      <pwccode url="https://github.com/lguyogiro/nahuatl-variant-charlms-americasnlp" additional="false">lguyogiro/nahuatl-variant-charlms-americasnlp</pwccode>
    </paper>
    <paper id="10">
      <title>Morphological Segmentation for <fixed-case>S</fixed-case>eneca</title>
      <author><first>Zoey</first><last>Liu</last></author>
      <author><first>Robert</first><last>Jimerson</last></author>
      <author><first>Emily</first><last>Prud&#8217;hommeaux</last></author>
      <pages>90&#8211;101</pages>
      <abstract>This study takes up the task of low-resource morphological segmentation for Seneca, a critically endangered and morphologically complex Native American language primarily spoken in what is now New York State and Ontario. The labeled data in our experiments comes from two sources: one digitized from a publicly available grammar book and the other collected from informal sources. We treat these two sources as distinct domains and investigate different evaluation designs for model selection. The first design abides by standard practices and evaluate models with the in-domain development set, while the second one carries out evaluation using a development domain, or the out-of-domain development set. Across a series of monolingual and crosslinguistic training settings, our results demonstrate the utility of neural encoder-decoder architecture when coupled with multi-task learning.</abstract>
      <url hash="371b8485">2021.americasnlp-1.10</url>
      <doi>10.18653/v1/2021.americasnlp-1.10</doi>
      <bibkey>liu-etal-2021-morphological</bibkey>
      <pwccode url="https://github.com/zoeyliu18/seneca" additional="false">zoeyliu18/seneca</pwccode>
    </paper>
    <paper id="11">
      <title>Representation of <fixed-case>Y</fixed-case>ine [<fixed-case>A</fixed-case>rawak] Morphology by Finite State Transducer Formalism</title>
      <author><first>Adriano</first><last>Ingunza Torres</last></author>
      <author><first>John</first><last>Miller</last></author>
      <author><first>Arturo</first><last>Oncevay</last></author>
      <author><first>Roberto</first><last>Zariquiey Biondi</last></author>
      <pages>102&#8211;112</pages>
      <abstract>We represent the complexity of Yine (Arawak) morphology with a finite state transducer (FST) based morphological analyzer. Yine is a low-resource indigenous polysynthetic Peruvian language spoken by approximately 3,000 people and is classified as &#8216;definitely endangered&#8217; by UNESCO. We review Yine morphology focusing on morphophonology, possessive constructions and verbal predicates. Then we develop FSTs to model these components proposing techniques to solve challenging problems such as complex patterns of incorporating open and closed category arguments. This is a work in progress and we still have more to do in the development and verification of our analyzer. Our analyzer will serve both as a tool to better document the Yine language and as a component of natural language processing (NLP) applications such as spell checking and correction.</abstract>
      <url hash="fa1d4d59">2021.americasnlp-1.11</url>
      <attachment type="OptionalSupplementaryCode" hash="3b960847">2021.americasnlp-1.11.OptionalSupplementaryCode.zip</attachment>
      <doi>10.18653/v1/2021.americasnlp-1.11</doi>
      <bibkey>ingunza-torres-etal-2021-representation</bibkey>
    </paper>
    <paper id="14">
      <title>Expanding <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for Polysynthetic Languages: A Case of <fixed-case>S</fixed-case>t. <fixed-case>L</fixed-case>awrence <fixed-case>I</fixed-case>sland <fixed-case>Y</fixed-case>upik</title>
      <author><first>Hyunji Hayley</first><last>Park</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <pages>131&#8211;142</pages>
      <abstract>This paper describes the development of the first Universal Dependencies (UD) treebank for St. Lawrence Island Yupik, an endangered language spoken in the Bering Strait region. While the UD guidelines provided a general framework for our annotations, language-specific decisions were made necessary by the rich morphology of the polysynthetic language. Most notably, we annotated a corpus at the morpheme level as well as the word level. The morpheme level annotation was conducted using an existing morphological analyzer and manual disambiguation. By comparing the two resulting annotation schemes, we argue that morpheme-level annotation is essential for polysynthetic languages like St. Lawrence Island Yupik. Word-level annotation results in degenerate trees for some Yupik sentences and often fails to capture syntactic relations that can be manifested at the morpheme level. Dependency parsing experiments provide further support for morpheme-level annotation. Implications for UD annotation of other polysynthetic languages are discussed.</abstract>
      <url hash="49a8ac83">2021.americasnlp-1.14</url>
      <doi>10.18653/v1/2021.americasnlp-1.14</doi>
      <bibkey>park-etal-2021-expanding</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="23">
      <title>Findings of the <fixed-case>A</fixed-case>mericas<fixed-case>NLP</fixed-case> 2021 Shared Task on Open Machine Translation for Indigenous Languages of the <fixed-case>A</fixed-case>mericas</title>
      <author><first>Manuel</first><last>Mager</last></author>
      <author><first>Arturo</first><last>Oncevay</last></author>
      <author><first>Abteen</first><last>Ebrahimi</last></author>
      <author><first>John</first><last>Ortega</last></author>
      <author><first>Annette</first><last>Rios</last></author>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Ximena</first><last>Gutierrez-Vasques</last></author>
      <author><first>Luis</first><last>Chiruzzo</last></author>
      <author><first>Gustavo</first><last>Gim&#233;nez-Lugo</last></author>
      <author><first>Ricardo</first><last>Ramos</last></author>
      <author><first>Ivan Vladimir</first><last>Meza Ruiz</last></author>
      <author><first>Rolando</first><last>Coto-Solano</last></author>
      <author><first>Alexis</first><last>Palmer</last></author>
      <author><first>Elisabeth</first><last>Mager-Hois</last></author>
      <author><first>Vishrav</first><last>Chaudhary</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <pages>202&#8211;217</pages>
      <abstract>This paper presents the results of the 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas. The shared task featured two independent tracks, and participants submitted machine translation systems for up to 10 indigenous languages. Overall, 8 teams participated with a total of 214 submissions. We provided training sets consisting of data collected from various sources, as well as manually translated sentences for the development and test sets. An official baseline trained on this data was also provided. Team submissions featured a variety of architectures, including both statistical and neural models, and for the majority of languages, many teams were able to considerably improve over the baseline. The best performing systems achieved 12.97 ChrF higher than baseline, when averaged across languages.</abstract>
      <url hash="ac069c84">2021.americasnlp-1.23</url>
      <doi>10.18653/v1/2021.americasnlp-1.23</doi>
      <bibkey>mager-etal-2021-findings</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flores">FLoRes</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/xnli">XNLI</pwcdataset>
    </paper>
    <paper id="27">
      <title>The <fixed-case>REPU</fixed-case> <fixed-case>CS</fixed-case>&#8217; <fixed-case>S</fixed-case>panish&#8211;<fixed-case>Q</fixed-case>uechua Submission to the <fixed-case>A</fixed-case>mericas<fixed-case>NLP</fixed-case> 2021 Shared Task on Open Machine Translation</title>
      <author><first>Oscar</first><last>Moreno</last></author>
      <pages>241&#8211;247</pages>
      <abstract>We present the submission of REPUcs to the AmericasNLP machine translation shared task for the low resource language pair Spanish&#8211;Quechua. Our neural machine translation system ranked first in Track two (development set not used for training) and third in Track one (training includes development data). Our contribution is focused on: (i) the collection of new parallel data from different web sources (poems, lyrics, lexicons, handbooks), and (ii) using large Spanish&#8211;English data for pre-training and then fine-tuning the Spanish&#8211;Quechua system. This paper describes the new parallel corpora and our approach in detail.</abstract>
      <url hash="0d16c89a">2021.americasnlp-1.27</url>
      <doi>10.18653/v1/2021.americasnlp-1.27</doi>
      <bibkey>moreno-2021-repu</bibkey>
    </paper>
    <paper id="29">
      <title>The <fixed-case>H</fixed-case>elsinki submission to the <fixed-case>A</fixed-case>mericas<fixed-case>NLP</fixed-case> shared task</title>
      <author><first>Ra&#250;l</first><last>V&#225;zquez</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Sami</first><last>Virpioja</last></author>
      <author><first>J&#246;rg</first><last>Tiedemann</last></author>
      <pages>255&#8211;264</pages>
      <abstract>The University of Helsinki participated in the AmericasNLP shared task for all ten language pairs. Our multilingual NMT models reached the first rank on all language pairs in track 1, and first rank on nine out of ten language pairs in track 2. We focused our efforts on three aspects: (1) the collection of additional data from various sources such as Bibles and political constitutions, (2) the cleaning and filtering of training data with the OpusFilter toolkit, and (3) different multilingual training techniques enabled by the latest version of the OpenNMT-py toolkit to make the most efficient use of the scarce data. This paper describes our efforts in detail.</abstract>
      <url hash="c92b8108">2021.americasnlp-1.29</url>
      <doi>10.18653/v1/2021.americasnlp-1.29</doi>
      <bibkey>vazquez-etal-2021-helsinki</bibkey>
    </paper>
    </volume>
</collection>