<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.maiworkshop">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Multimodal Artificial Intelligence</booktitle>
      <editor><first>Amir</first><last>Zadeh</last></editor>
      <editor><first>Louis-Philippe</first><last>Morency</last></editor>
      <editor><first>Paul Pu</first><last>Liang</last></editor>
      <editor><first>Candace</first><last>Ross</last></editor>
      <editor><first>Ruslan</first><last>Salakhutdinov</last></editor>
      <editor><first>Soujanya</first><last>Poria</last></editor>
      <editor><first>Erik</first><last>Cambria</last></editor>
      <editor><first>Kelly</first><last>Shi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Mexico City, Mexico</address>
      <month>June</month>
      <year>2021</year>
      <url hash="f2f0aab4">2021.maiworkshop-1</url>
    </meta>
    <frontmatter>
      <url hash="46cec279">2021.maiworkshop-1.0</url>
      <bibkey>maiworkshop-2021-multimodal</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Multi Task Learning based Framework for Multimodal Classification</title>
      <author><first>Danting</first><last>Zeng</last></author>
      <pages>30–35</pages>
      <abstract>Large-scale multi-modal classification aim to distinguish between different multi-modal data, and it has drawn dramatically attentions since last decade. In this paper, we propose a multi-task learning-based framework for the multimodal classification task, which consists of two branches : multi-modal autoencoder branch and attention-based multi-modal modeling branch. Multi-modal autoencoder can receive multi-modal features and obtain the interactive information which called multi-modal encoder feature, and use this feature to reconstitute all the input data. Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task). As for attention-based multimodal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multi-modal encoder feature to enrich the input information, achieve a better performance. We conduct extensive experiments on different dataset, the results demonstrate the effectiveness of proposed <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>.</abstract>
      <url hash="e12103f7">2021.maiworkshop-1.5</url>
      <doi>10.18653/v1/2021.maiworkshop-1.5</doi>
      <bibkey>zeng-2021-multi</bibkey>
    <title_es>Marco basado en el aprendizaje multitarea para la clasificación multimodal</title_es>
      <title_ar>إطار عمل قائم على التعلم متعدد المهام للتصنيف متعدد الوسائط</title_ar>
      <title_fr>Cadre basé sur l'apprentissage multitâche pour la classification multimodale</title_fr>
      <title_ja>マルチモーダル分類のためのマルチタスク学習ベースのフレームワーク</title_ja>
      <title_ru>Система мультизадачного обучения для мультимодальной классификации</title_ru>
      <title_pt>Estrutura baseada em Aprendizado de Tarefas Múltiplas para Classificação Multimodal</title_pt>
      <title_zh>盖多任务学之多模类框架</title_zh>
      <title_hi>मल्टी मोडल वर्गीकरण के लिए मल्टी टास्क लर्निंग आधारित फ्रेमवर्क</title_hi>
      <title_ga>Creat Il-Tasc Foghlama don Aicmiú Ilmhódach</title_ga>
      <title_ukr>База багатозадачного навчання для мультимодальної класифікації</title_ukr>
      <title_isl>Margfeldismeðaltal fyrir fjölfeldismeðal</title_isl>
      <title_ka>Multimodal Classification</title_ka>
      <title_el>Πλαίσιο εκμάθησης πολλαπλών εργασιών για την πολυμερή ταξινόμηση</title_el>
      <title_hu>Multimodális osztályozás többfeladatú tanuláson alapuló keretrendszere</title_hu>
      <title_lt>Multi Task Learning based Framework for Multimodal Classification</title_lt>
      <title_it>Quadro basato sull'apprendimento multi-task per la classificazione multimodale</title_it>
      <title_kk>Көптеген тапсырмаларды білім беру негіздеген фреймді</title_kk>
      <title_ms>Name</title_ms>
      <title_mn>Multimodal Classification</title_mn>
      <title_ml>Multimodal Classification</title_ml>
      <title_mt>Qafas ibbażat fuq it-Tagħlim Multimodali għall-Klassifikazzjoni Multimodali</title_mt>
      <title_pl>Wielozadaniowe ramy dla klasyfikacji multimodalnej oparte na uczeniu się</title_pl>
      <title_ro>Cadrul de învățare bazat pe mai multe sarcini pentru clasificarea multimodală</title_ro>
      <title_mk>Рамка за мултимодална класификација базирана на мултимодално учење на задачи</title_mk>
      <title_sr>Višestruko učenje zadataka bazirano na okviru multimodalne klasifikacije</title_sr>
      <title_sv>Multi Task Learning based Framework for Multimodal Classification</title_sv>
      <title_si>Multi-mode Classication</title_si>
      <title_so>Shaqooyin badan oo ku saleysan waxbarasho shaqo</title_so>
      <title_ur>Multimodal Classification</title_ur>
      <title_no>Fleire oppgåver-læring basert rammeverk for multimodal klassifikasjon</title_no>
      <title_ta>பல வகுப்புகளுக்கு அடிப்படையான செயல் கற்றுக்கொடுப்பு சட்டம்</title_ta>
      <title_uz>Name</title_uz>
      <title_vi>Mô hình tổ hợp nghề nghiệp về giáo dục đa phương</title_vi>
      <title_bg>Рамка за мултимодална класификация, базирана на множество задачи</title_bg>
      <title_da>Multi Task Learning Based Framework for Multimodal Classification</title_da>
      <title_de>Multi Task Learning basiertes Framework für multimodale Klassifikation</title_de>
      <title_id>Multi Task Learning Based Framework for Multimodal Classification</title_id>
      <title_ko>다중 임무 학습 기반의 다중모드 분류 프레임워크</title_ko>
      <title_hr>Naučenje višestrukih zadataka bazirano na okviru multimodalne klasifikacije</title_hr>
      <title_nl>Multi Task Learning gebaseerd Framework voor multimodale classificatie</title_nl>
      <title_fa>چشمه‌سازی بنیاد یادگیری دنده‌های زیادی برای کلاس‌سازی چندmodal</title_fa>
      <title_af>Veelvuldige taak leer gebaseerde Raamwerk vir Multimodaal Klassifikasie</title_af>
      <title_sw>Miundombi ya Kujifunza kazi nyingi kwa ajili ya Kufunguliwa</title_sw>
      <title_tr>Çoklumodal klasifikasyon üçin köp zady öwrenmek</title_tr>
      <title_hy>Մոլորմոդալ դասակարգման բազմախնդիրներ սովորելու հիմնված շրջանակը</title_hy>
      <title_az>Multimodal Klasifikat 칲칞칲n 칞oxlu Task 칐yr톛nm톛si</title_az>
      <title_bn>বহুমোডাল ক্লাসিফেশনের জন্য ভিত্তিক কাজ শিক্ষা</title_bn>
      <title_sq>Korniza për klasifikimin multimodal bazuar në mësimin e shumë detyrave</title_sq>
      <title_ca>Quadro de classificació multimodal basat en l'aprenentatge multitasca</title_ca>
      <title_am>መግለጫ</title_am>
      <title_cs>Multi Task Learning založený rámec pro multimodální klasifikaci</title_cs>
      <title_et>Mitme ülesandega õppimisel põhinev mitmeliigilise liigituse raamistik</title_et>
      <title_fi>Multi Task Learning based Framework for Multimodal Classification</title_fi>
      <title_bs>Multimodalna klasifikacija</title_bs>
      <title_jv>Multimodal</title_jv>
      <title_sk>Okvir za večmodalno klasifikacijo, ki temelji na učenju z več nalogami</title_sk>
      <title_ha>Frame for multi-modal Classification</title_ha>
      <title_he>מסגרת למידת משימות רבות מבוססת על שיעור רבים</title_he>
      <title_bo>Multimodal Classification ཡི་ལ་སྤྱོད་པའི་སྲོལ་སྒྲིག་བཀོད་གཞི་རྟེན་ནས་ཤེས་ཀྱི་བྱ་བ་ཆ་བོ</title_bo>
      <title_fil>Multimodal Classification</title_fil>
      <abstract_pt>A classificação multimodal em larga escala visa distinguir entre diferentes dados multimodais, e tem atraído dramaticamente a atenção desde a última década. Neste artigo, propomos uma estrutura baseada em aprendizado multitarefa para a tarefa de classificação multimodal, que consiste em duas ramificações: ramificação de autoencoder multimodal e ramificação de modelagem multimodal baseada em atenção. O autoencoder multimodal pode receber recursos multimodais e obter as informações interativas que chamam de recurso de codificador multimodal e usar esse recurso para reconstituir todos os dados de entrada. Além disso, o recurso de codificador multimodal pode ser usado para enriquecer o conjunto de dados brutos e melhorar o desempenho de tarefas downstream (como tarefa de classificação). Quanto ao ramo de modelagem multimodal baseado em atenção, primeiro empregamos o mecanismo de atenção para tornar o modelo focado em recursos importantes, depois usamos o recurso de codificador multimodal para enriquecer as informações de entrada, obter um melhor desempenho. Realizamos extensos experimentos em diferentes conjuntos de dados, os resultados demonstram a eficácia do framework proposto.</abstract_pt>
      <abstract_fr>La classification multimodale à grande échelle vise à distinguer les différentes données multimodales, et elle a attiré l'attention de façon spectaculaire depuis la dernière décennie. Dans cet article, nous proposons un cadre basé sur l'apprentissage multitâche pour la tâche de classification multimodale, qui se compose de deux branches : une branche d'encodeur automatique multimodale et une branche de modélisation multimodale basée sur l'attention. L'encodeur automatique multimodal peut recevoir des caractéristiques multimodales et obtenir les informations interactives appelées fonction de codeur multimodal, et utiliser cette fonctionnalité pour reconstituer toutes les données d'entrée. En outre, la fonction d'encodeur multimodal peut être utilisée pour enrichir le jeu de données brut et améliorer les performances des tâches en aval (telles que les tâches de classification). En ce qui concerne la branche de modélisation multimodale basée sur l'attention, nous utilisons d'abord un mécanisme d'attention pour concentrer le modèle sur des caractéristiques importantes, puis nous utilisons la fonction de codeur multimodal pour enrichir les informations d'entrée et obtenir de meilleures performances. Nous menons des expériences approfondies sur différents ensembles de données, les résultats démontrent l'efficacité du cadre proposé.</abstract_fr>
      <abstract_ja>大規模なマルチモーダル分類は、異なるマルチモーダルデータを区別することを目的としており、過去10年から劇的に注目を集めています。 本稿では、マルチモーダルオートエンコーダ分岐とアテンションベースマルチモーダルモデリング分岐の2つの分岐からなる、マルチモーダル分類タスクのためのマルチタスク学習ベースのフレームワークを提案する。 マルチモーダルオートエンコーダは、マルチモーダル機能を受信し、マルチモーダルエンコーダ機能と呼ばれるインタラクティブな情報を取得し、この機能を使用してすべての入力データを再構成することができます。 さらに、マルチモーダルエンコーダ機能を使用して、生データセットを充実させ、ダウンストリームタスク（分類タスクなど）のパフォーマンスを向上させることができます。 注目度ベースのマルチモーダルモデリング分岐については、まず注目度メカニズムを採用して重要な機能に焦点を当て、次にマルチモーダルエンコーダ機能を採用して入力情報を充実させ、より良いパフォーマンスを実現します。 さまざまなデータセットについて広範な実験を行い、その結果は提案されたフレームワークの有効性を示しています。</abstract_ja>
      <abstract_ar>يهدف التصنيف متعدد الوسائط على نطاق واسع إلى التمييز بين البيانات متعددة الوسائط المختلفة ، وقد جذب الانتباه بشكل كبير منذ العقد الماضي. في هذه الورقة ، نقترح إطارًا قائمًا على التعلم متعدد المهام لمهمة التصنيف متعدد الوسائط ، والذي يتكون من فرعين: فرع التشفير التلقائي متعدد الوسائط وفرع النمذجة متعدد الوسائط القائم على الانتباه. يمكن لجهاز التشفير التلقائي متعدد الوسائط تلقي ميزات متعددة الوسائط والحصول على المعلومات التفاعلية التي تسمى ميزة التشفير متعدد الوسائط ، واستخدام هذه الميزة لإعادة تكوين جميع بيانات الإدخال. إلى جانب ذلك ، يمكن استخدام ميزة التشفير متعدد الوسائط لإثراء مجموعة البيانات الأولية ، وتحسين أداء المهام النهائية (مثل مهمة التصنيف). بالنسبة لفرع النمذجة متعددة الوسائط القائمة على الانتباه ، فإننا نستخدم أولاً آلية الانتباه لجعل النموذج يركز على الميزات المهمة ، ثم نستخدم ميزة التشفير متعدد الوسائط لإثراء معلومات الإدخال ، وتحقيق أداء أفضل. نجري تجارب مكثفة على مجموعة بيانات مختلفة ، تظهر النتائج فعالية الإطار المقترح.</abstract_ar>
      <abstract_es>La clasificación multimodal a gran escala tiene como objetivo distinguir entre diferentes datos multimodales, y ha llamado la atención de manera espectacular desde la última década. En este artículo, proponemos un marco basado en el aprendizaje multitarea para la tarea de clasificación multimodal, que consta de dos ramas: rama de autocodificador multimodal y rama de modelado multimodal basado en la atención. El autocodificador multimodal puede recibir características multimodales y obtener la información interactiva que se llama función de codificador multimodal, y usar esta función para reconstituir todos los datos de entrada. Además, la función de codificador multimodal se puede utilizar para enriquecer el conjunto de datos sin procesar y mejorar el rendimiento de las tareas posteriores (como la tarea de clasificación). En cuanto a la rama de modelado multimodal basado en la atención, primero empleamos el mecanismo de atención para hacer que el modelo se centre en características importantes, luego utilizamos la función de codificador multimodal para enriquecer la información de entrada y lograr un mejor rendimiento. Llevamos a cabo experimentos exhaustivos en diferentes conjuntos de datos, los resultados demuestran la eficacia del marco propuesto.</abstract_es>
      <abstract_ru>Крупномасштабная мультимодальная классификация направлена на проведение различия между различными мультимодальными данными, и с прошлого десятилетия она привлекла к себе значительное внимание. В данной работе мы предлагаем многозадачный обучающий фреймворк для задачи мультимодальной классификации, который состоит из двух ветвей: ветви мультимодального автокодирования и ветви мультимодального моделирования на основе внимания. Мультимодальный автокодер может принимать мультимодальные функции и получать интерактивную информацию, называемую мультимодальной функцией кодера, и использовать эту функцию для восстановления всех входных данных. Кроме того, мультимодальная функция кодировщика может использоваться для обогащения необработанного набора данных и улучшения выполнения последующих задач (таких как задача классификации). Что касается отрасли мультимодального моделирования, основанной на внимании, мы сначала используем механизм внимания, чтобы сделать модель сфокусированной на важных функциях, затем мы используем функцию мультимодального кодера для обогащения входной информации, достижения лучшей производительности. Мы проводим обширные эксперименты на разных массивах данных, результаты демонстрируют эффективность предлагаемой структуры.</abstract_ru>
      <abstract_ukr>Масштабна мультимодальна класифікація має на меті розрізнити різні мультимодальні дані, і вона різко привернула увагу з останнього десятиліття. У цій роботі ми пропонуємо багатозадачний навчальний фреймворк для мультимодального класифікаційного завдання, який складається з двох гілок: мультимодальної гілки автокодування та уважної гілки мультимодального моделювання. Мультимодальний автокодер може отримувати мультимодальні функції та отримувати інтерактивну інформацію, яку називають мультимодальною функцією кодера, і використовувати цю функцію для відновлення всіх вхідних даних. Крім того, мультимодальна функція кодувальника може бути використана для збагачення сирого набору даних та покращення виконання нижчих завдань (таких як завдання класифікації). Що стосується галузі мультимодального моделювання на основі уваги, ми спочатку використовуємо механізм уваги, щоб зробити модель зосередженою на важливих функціях, потім ми використовуємо мультимодальний кодер для збагачення вхідної інформації, досягнення кращої продуктивності. Проводимо широкі експерименти на різних наборах даних, результати демонструють ефективність запропонованої структури.</abstract_ukr>
      <abstract_ga>Tá sé mar aidhm ag aicmiú ilmhódúil ar scála mór idirdhealú a dhéanamh idir sonraí ilmhódacha éagsúla, agus tá aird mhór tarraingthe air le deich mbliana anuas. Sa pháipéar seo, molaimid creat il-tasc bunaithe ar fhoghlaim don tasc aicmithe ilmhódach, atá comhdhéanta de dhá bhrainse: brainse uath-ionchódóra ilmhódaigh agus brainse samhaltú ilmhódúil bunaithe ar aird. Is féidir le uath-ionchódóir ilmhódúil gnéithe ilmhódacha a fháil agus an fhaisnéis idirghníomhach ar a dtugtar gné ionchódóra ilmhódaigh a fháil, agus an ghné seo a úsáid chun na sonraí ionchuir go léir a athdhéanamh. Thairis sin, is féidir gné ionchódóra ilmhódúil a úsáid chun an tacar sonraí amh a shaibhriú, agus feabhas a chur ar fheidhmíocht tascanna iartheachtacha (cosúil le tasc aicmithe). Maidir le brainse samhaltú ilmhódúil atá bunaithe ar aird, bainimid úsáid as meicníocht aird ar dtús chun an tsamhail a dhíriú ar ghnéithe tábhachtacha, ansin úsáidimid an ghné ionchódóra ilmhódaigh chun an fhaisnéis ionchuir a shaibhriú, feidhmíocht níos fearr a bhaint amach. Déanaimid turgnaimh fhairsing ar thacar sonraí éagsúla, léiríonn na torthaí éifeachtacht an chreata atá beartaithe.</abstract_ga>
      <abstract_hi>बड़े पैमाने पर बहु-मोडल वर्गीकरण का उद्देश्य विभिन्न बहु-मोडल डेटा के बीच अंतर करना है, और इसने पिछले दशक से नाटकीय रूप से ध्यान आकर्षित किया है। इस पेपर में, हम मल्टीमॉडल वर्गीकरण कार्य के लिए एक बहु-कार्य सीखने-आधारित ढांचे का प्रस्ताव करते हैं, जिसमें दो शाखाएं शामिल हैं: मल्टी-मोडल ऑटोएनकोडर शाखा और ध्यान-आधारित मल्टी-मोडल मॉडलिंग शाखा। मल्टी-मोडल ऑटोएनकोडर मल्टी-मोडल सुविधाओं को प्राप्त कर सकता है और इंटरैक्टिव जानकारी प्राप्त कर सकता है जिसे मल्टी-मोडल एनकोडर फीचर कहा जाता है, और सभी इनपुट डेटा को पुनर्गठित करने के लिए इस सुविधा का उपयोग करें। इसके अलावा, बहु-मोडल एन्कोडर सुविधा का उपयोग कच्चे डेटासेट को समृद्ध करने और डाउनस्ट्रीम कार्यों (जैसे वर्गीकरण कार्य) के प्रदर्शन में सुधार करने के लिए किया जा सकता है। ध्यान-आधारित मल्टीमॉडल मॉडलिंग शाखा के लिए, हम पहले मॉडल को महत्वपूर्ण विशेषताओं पर केंद्रित करने के लिए ध्यान तंत्र को नियोजित करते हैं, फिर हम इनपुट जानकारी को समृद्ध करने, बेहतर प्रदर्शन प्राप्त करने के लिए बहु-मोडल एनकोडर सुविधा का उपयोग करते हैं। हम विभिन्न डेटासेट पर व्यापक प्रयोग करते हैं, परिणाम प्रस्तावित ढांचे की प्रभावशीलता को प्रदर्शित करते हैं।</abstract_hi>
      <abstract_zh>大多模式分类旨在区别不同的多模式数据,自去十年以来大起关注。 本文举一于多任务学之多模态分类之任框架,当框架两支:多模态自编码器支与注意者多模态建模支。 多模态自编码器受多模态取曰多模态编码器交互信息,因其重建输数。 又多模态编码器功可以丰原始数据集,而崇下流之务(类)之性也。 若夫注意者多模态建模支,吾先注意机而专于要,然后因多模态编码器而丰输信息,以致其善。 博实验异数集上证其框架有效性。</abstract_zh>
      <abstract_el>Η ευρείας κλίμακας πολυμορφική ταξινόμηση αποσκοπεί στη διάκριση μεταξύ διαφορετικών πολυμορφικών δεδομένων, και έχει προσελκύσει δραματικά προσοχή από την τελευταία δεκαετία. Στην παρούσα εργασία, προτείνουμε ένα πλαίσιο εκμάθησης πολλαπλών εργασιών για την εργασία πολυπροπικής ταξινόμησης, το οποίο αποτελείται από δύο κλάδους: τον κλάδο πολυπροπικού αυτόματου κωδικοποιητή και τον κλάδο πολυπροπικής μοντελοποίησης με βάση την προσοχή. Ο πολυτροπικός αυτόματος κωδικοποιητής μπορεί να λάβει τα πολυτροπικά χαρακτηριστικά γνωρίσματα και να λάβει τις διαδραστικές πληροφορίες που καλούν το πολυτροπικό χαρακτηριστικό κωδικοποιητή, και να χρησιμοποιήσει αυτό το χαρακτηριστικό γνώρισμα για να ανασυσταθεί όλα τα δεδομένα εισαγωγής. Εκτός αυτού, το χαρακτηριστικό πολλαπλών τρόπων κωδικοποιητή μπορεί να χρησιμοποιηθεί για να εμπλουτίσει το ακατέργαστο σύνολο δεδομένων, και να βελτιώσει την απόδοση των μεταγενέστερων εργασιών (όπως η εργασία ταξινόμησης). Όσο για τον τομέα μοντελοποίησης βασισμένο στην προσοχή, χρησιμοποιούμε πρώτα μηχανισμό προσοχής για να κάνουμε το μοντέλο επικεντρωμένο σε σημαντικά χαρακτηριστικά γνωρίσματα, στη συνέχεια χρησιμοποιούμε το χαρακτηριστικό γνώρισμα κωδικοποιητή για να εμπλουτίσουμε τις πληροφορίες εισαγωγής, να επιτύχουμε μια καλύτερη απόδοση. Διεξάγουμε εκτεταμένα πειράματα σε διαφορετικά σύνολα δεδομένων, τα αποτελέσματα αποδεικνύουν την αποτελεσματικότητα του προτεινόμενου πλαισίου.</abstract_el>
      <abstract_hu>A nagyméretű multimodális osztályozás célja a különböző multimodális adatok közötti különbség megkülönböztetése, és ez az elmúlt évtized óta drámaian felhívta a figyelmet. Jelen tanulmányban egy multimodális osztályozási feladat multimodális tanulási alapú keretrendszerét javasoljuk, amely két ágból áll: multimodális autoencoder ágból és figyelem-alapú multimodális modellezési ágból. A multimodális autoencoder képes multimodális funkciókat fogadni és megszerezni az interaktív információt, amelyet multimodális encoder funkciónak neveznek, és ezt a funkciót használja az összes beviteli adat rekonstruálására. Emellett a multimodális kódoló funkció használható a nyers adatkészlet gazdagítására és a downstream feladatok teljesítményének javítására (mint például osztályozási feladat). Ami a figyelem alapú multimodális modellezési ágazatot illeti, először figyelem mechanizmust alkalmazunk arra, hogy a modell fontos funkciókra összpontosítson, majd a multimodális kódoló funkciót használjuk a bemeneti információk gazdagítására, jobb teljesítmény elérésére. Széleskörű kísérleteket végzünk különböző adatkészleteken, az eredmények bizonyítják a javasolt keretrendszer hatékonyságát.</abstract_hu>
      <abstract_ka>დიდი მრავალური მოდიალური კლასიფიკაციის მიზეზი განსხვავება განსხვავებული მრავალური მოდიალური მონაცემების განსხვავებას და მისი ბოლო ათეულის შემდეგ დირამატური მონაცემები გა ამ დომენტში ჩვენ მრავალური დავისწავლა მრავალური დავალების ფრამეტრი მრავალური კლასიფიკაციის რაოდენობისთვის, რომელიც ორი სახელიდან იყოს: მრავალური მოდიალური ავტოკოდერის სახელი და მრავალური მოდელის მოდე მრავალური მოდიალური ავტოკოდერები შეიძლება მრავალური მოდიალური ფუნქციების მიღება და ინტერრაქტიური ინფორმაციის მიღება, რომელიც მრავალური მოდიალური კოდერების ფუნქცია, და ამ ფუნქციის დამატებით, მრავალური მოდიალური კოდირების ფუნქცია შეიძლება გამოყენება მხარეს მონაცემების სეტატის შესაბამისთვის და შესაბამისთვის შესაბამისთვის (როგორც კლასიფიკა მალტიმოდიალური მოდელური სახელის შესახებ, ჩვენ პირველად აყენებთ მოდელს მნიშვნელოვანი ფუნქციებისთვის, შემდეგ ჩვენ გამოყენებთ მრავალური მოდელური კოდელური ფუნქციის შესახებ ინფორმაციის შესახე ჩვენ განსხვავებული მონაცემების კონპერიმენტებზე გავაკეთებთ განსხვავებული ექსპერიმენტები, რომელიც გამოჩვენებულია პროგრამის ეფექტიურობ</abstract_ka>
      <abstract_kk>Үлкен масштабы көп модалдық классификациялау мақсатында бірнеше көп модалдық деректер арасында айыру үшін, соңғы он жылдан кейін драматикалық қатынасы көрсетті. Бұл қағазда біз көп тапсырманың оқыту негізінде көп тапсырманың бірнеше бағдарламасын ұсынамыз. Бұл екі бөлшектен құрылады: көп модалдық автокодер бөлшегі және қарау негізінде көп модалдық модель модель бөлше Көп модалдық автокодері көп модалдық мүмкіндіктерді алып, көп модалдық кодер функциясы деп аталатын интерактивті мәліметті алуға болады. Бұл мүмкіндікті барлық келтіру деректерін қайта құру ү Көп модалдық кодер мүмкіндігін қолдану үшін сызық деректер жиынын бағалау және төменгі тапсырмалардың істеуін жақсарту үшін қолданылады. Біріншіден бірнеше модельді модельді бағалау үшін, үлгісін маңызды мүмкіндіктерге назар ауыстыру механизмін қолданамыз, содан кейін бірнеше модельді кодерлеу мүмкіндігін қолданамыз, келтіру мәліметін бағалау үші Біз басқа деректер қорларында кеңейтілген тәжірибелерді жасаймыз. Нәтижелер қолданылатын қорларының эффективнігін көрсетеді.</abstract_kk>
      <abstract_it>La classificazione multimodale su larga scala mira a distinguere tra diversi dati multimodali e ha attirato drammaticamente l'attenzione dall'ultimo decennio. In questo articolo, proponiamo un framework basato sull'apprendimento multi-task per il compito di classificazione multimodale, che consiste in due rami: ramo autoencoder multimodale e ramo di modellazione multimodale basato sull'attenzione. L'autoencoder multimodale può ricevere funzioni multimodali e ottenere le informazioni interattive chiamate funzione encoder multimodale e utilizzare questa funzione per ricostituire tutti i dati in ingresso. Inoltre, la funzione di encoder multimodale può essere utilizzata per arricchire il set di dati grezzi e migliorare le prestazioni delle attività a valle (come attività di classificazione). Per quanto riguarda il ramo della modellazione multimodale basata sull'attenzione, impieghiamo prima il meccanismo di attenzione per rendere il modello focalizzato su caratteristiche importanti, poi usiamo la funzione dell'encoder multimodale per arricchire le informazioni di input, ottenere una migliore prestazione. Conduciamo esperimenti approfonditi su diversi set di dati, i risultati dimostrano l'efficacia del framework proposto.</abstract_it>
      <abstract_mk>Големата мултимодилна класификација има за цел разлика помеѓу различните мултимодилни податоци и драматично привлече внимание од минатата деценија. Во овој документ, предложуваме рамка базирана на мултимодално учење за мултимодалната класификациска задача, која се состои од две гранки: мултимодалното автокодерско гранко и мултимодалното моделирање базирано на внимание. Мултимодален автокодер може да добие мултимодални карактеристики и да ја добие интерактивната информација која се нарекува мултимодален кодер карактеристика, и да ја искористи оваа карактеристика за реконституција на сите внесени податоци. Покрај тоа, можно е да се користи мултимодален кодер за богатство на суровите податоци и подобрување на извршувањето на понатамошните задачи (како што е класификациската задача). Што се однесува до финансиската финансија за мултимодилно моделирање базирана на внимание, прво користиме механизам за внимание за моделот да се фокусира на важни карактеристики, потоа ја користиме финансијата за мултимодилниот кодер за да ги збогатиме информациите за внесување Правиме експерименти на различни податоци, резултатите ја покажуваат ефикасноста на предложената рамка.</abstract_mk>
      <abstract_lt>Didelio masto daugiarūšio transporto rūšių klasifikavimo tikslas – atskirti skirtingus daugiarūšio transporto rūšių duomenis, o pastarąjį dešimtmetį jis labai atkreipė dėmesį. Šiame dokumente siūlome daugiafunkcinę mokymosi sistemą daugiarūšio klasifikavimo užduotims, kurią sudaro du filialai: daugiarūšio autokodavimo filialas ir dėmesio daugiarūšio modeliavimo filialas. Multi-modal autoencoder can receive multi-modal features and obtain the interactive information which called multi-modal encoder feature, and use this feature to reconstitute all the input data.  Be to, daugiarūšio kodavimo funkcija gali būti naudojama žaliaviniam duomenų rinkiniui praturtinti ir tolesnių užduočių (pvz., klasifikavimo užduočių) vykdymui gerinti. Kalbant apie dėmesiu grindžiamą daugiarūšio modeliavimo sektorių, pirmiausia naudojame dėmesio mechanizmą, kad modelis būtų sutelktas į svarbias savybes, o vėliau naudojame daugiarūšio modeliavimo funkciją, kad praturtintume įvestą informaciją ir pasiektume geresnius rezultatus. Atliekame išsamius įvairių duomenų rinkinių eksperimentus, rezultatai rodo siūlomos sistemos veiksmingumą.</abstract_lt>
      <abstract_ml>പല്ലിമോഡല്‍ ഡേറ്റാകള്‍ക്കിടയില്‍ വേര്‍തിരിച്ച് വേര്‍തിരിക്കാനുള്ള വലിയ വലിയ മോഡിമോഡല്‍ ക്ലാസ്ഫിക്ഷന്‍ ലക്ഷ്യമാണ്, കഴിഞ്ഞ ഈ പേപ്പറില്‍, ഞങ്ങള്‍ പല പണിയില്‍ പഠിക്കുന്നതിന്റെ അടിസ്ഥാനമായ ഒരു ഫ്രെയിമെയില്‍ പ്രായണം ചെയ്യുന്നു. അത് രണ്ടു ശാഖകളില്‍ ഉള്ളതാണ്: പല മോഡിയല്‍ സ്വയമായ Multi- modal autocoder can receive multi- modal features and get the interactive information that calls multi- modal encoder features, and use this feature to reconstitute all input data. ഇതിനു പുറമെ പല-മോഡല്‍ കോഡെര്‍ വിശേഷങ്ങള്‍ കൊണ്ട് ചുരുക്കിയ ഡാറ്റാസെറ്റിനെ സമ്പാദിപ്പിക്കാന്‍ ഉപയോഗിക്കുകയും നദിയിലെ ജോല മോഡല്‍ പ്രധാനപ്പെട്ട വിഭാഗങ്ങളില്‍ ശ്രദ്ധിക്കുന്നതിനാല്‍ നമ്മള്‍ ആദ്യം ശ്രദ്ധ കാണിക്കുന്നു. പിന്നീട് നമ്മള്‍ മോഡലിനെ ശ്രദ്ധിക്കുന്നതിനായി ശ്രദ്ധി വ്യത്യസ്ത ഡാറ്റാസറ്റില്‍ നാം വിശാലമായ പരീക്ഷണങ്ങള്‍ നടത്തുന്നു. പ്രൊദേശിച്ച ഫ്രെയിമ്പിന്റെ പ്രവർ</abstract_ml>
      <abstract_isl>Large-scale multi-modal classification aim to distinguish between different multi-modal data, and it has drawn dramatically attentions since last decade.  In this paper, we propose a multi-task learning-based framework for the multimodal classification task, which consists of two branches: multi-modal autoencoder branch and attention-based multi-modal modeling branch.  Fjölmögulegur sjálfvirkur kóðari getur fengið fjölmöguleg einkenni og fengið milliverkandi upplýsingar sem kallast fjölmögulegur kóðari einkenni og notað þetta einkenni til að endurbúa öll inntaksgögn. Auk þess er hægt að nota fjölmóða kóðunareiginleika til að auðvelda grunngögn og bæta framkvæmd eftirfarandi verkefna (svo sem flokkunarverkefni). As for attention-based multimodal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multi-modal encoder feature to enrich the input information, achieve a better performance.  Við framkvæmum umtalsverðar tilraunir á mismunandi gögnum, niðurstöður sýna virkni framlagðra ramma.</abstract_isl>
      <abstract_ms>Klasifikasi multi modal skala besar bertujuan untuk membezakan antara data multimodal berbeza, dan ia telah menarik perhatian secara dramatis sejak dekad lepas. Dalam kertas ini, kami cadangan pembelajaran berasaskan-tugas berbilang untuk tugas klasifikasi multi modal, yang terdiri dari dua cabang: cabang auto-pengekod multimodal dan cabang pemodelan multimodal berasaskan perhatian. Autopengekod berbilang-modal boleh menerima ciri-ciri berbilang-modal dan mendapatkan maklumat interaktif yang dipanggil ciri-ciri pengekod berbilang-modal, dan guna ciri-ciri ini untuk mengembalikan semula semua data input. Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task).  Adapun cabang pemodelan multi modal berdasarkan perhatian, kita pertama-tama menggunakan mekanisme perhatian untuk membuat model fokus pada ciri-ciri penting, kemudian kita menggunakan ciri pengekod multimodal untuk memperkaya maklumat input, mencapai prestasi yang lebih baik. Kami melakukan eksperimen luas pada set data yang berbeza, hasilnya menunjukkan keefektivitas kerangka yang diusulkan.</abstract_ms>
      <abstract_mt>Il-klassifikazzjoni multimodali fuq skala kbira għandha l-għan li tiddistingwi bejn dejta multimodali differenti, u ġibdet attenzjoni drammatika minn dawn l-aħħar għaxar snin. In this paper, we propose a multi-task learning-based framework for the multimodal classification task, which consists of two branches: multi-modal autoencoder branch and attention-based multi-modal modeling branch.  L-awtokoder multimodali jista’ jirċievi karatteristiċi multimodali u jikseb l-informazzjoni interattiva li tissejjaħ karatteristika tal-kodifikatur multimodali, u juża din il-karatteristika biex tirrikostitwixxi d-dejta kollha tal-input. Barra minn hekk, il-karatteristika tal-kodifikatur multimodali tista’ tintuża biex issaħħaħ is-sett tad-dejta mhux ipproċessat, u ttejjeb il-prestazzjoni ta’ kompiti downstream (bħall-kompitu ta’ klassifikazzjoni). Fir-rigward tal-fergħa tal-immudellar multimodali bbażata fuq l-attenzjoni, l-ewwel a ħna nużaw mekkaniżmu ta’ attenzjoni biex il-mudell ikun iffukat fuq karatteristiċi importanti, imbagħad aħna nużaw il-karatteristika tal-kodifikatur multimodali biex isaħħu l-informazzjoni tal-input, niksbu prestazzjoni aħjar. Aħna nagħmlu esperimenti estensivi fuq sett ta’ dejta differenti, ir-riżultati juru l-effettività tal-qafas propost.</abstract_mt>
      <abstract_no>Stor skala fleire modaleklassifikasjonar mål å skilja mellom ulike fleire modaler data, og det har teikna dramatiske oppmerkingar sidan siste tiåret. I denne papiret foreslår vi eit fleire oppgåver-læringsbasert rammeverk for multi modal klassifikasjon-oppgåva, som inneheld av to grene: multimodal autokodingsgrene og multimodal modellingsgrene med oppmerksomhet. Multi modal autokoding kan motta fleire modal funksjonar og henta interaktive informasjon som kalla fleire modal koderingsfunksjonar, og bruka denne funksjonen for å gjenoppretta alle inndata. I tillegg kan fleire modal koderingsfunksjonar brukast for å rykke rådatasettet og forbetra utviklinga av nedstrekkoppgåver (som klassifikasjonsverkt). I tillegg til merksomhetsbasert multi modal modelleringsgrenn, bruker vi først merksomhetsmekanismekanismen for å få modellen fokusert på viktige funksjonar, og så bruker vi fleire modal koderingsfunksjonen for å rykke inndatainformasjonen og oppnå ei betre utvikling. Vi gjer utvida eksperimenter på ulike datasett, og resultatene viser effektiviteten til foreslått rammeverk.</abstract_no>
      <abstract_mn>Ихэнх хэмжээний олон моделийн хуваарилалт нь өөр олон моделийн өгөгдлийн хоорондоо ялгаа хийх зорилго юм. Энэ нь сүүлийн 10-аас хойш маш их анхаарал татаж байна. Энэ цаасан дээр бид олон ажлын суралцах суралцах суралцах сургалтын үндсэн хэлбэрийг санал болгож байна. Энэ нь хоёр хэлбэрээс бүрддэг: олон моделын автомоделийн автомоделийн загвар, анхаарлын үндсэн олон моделийн моделийн загвар. Олон-модал автомодал автомодал маш олон модал чанарыг авч, олон-модал кодчууд гэдэг интерактив мэдээллийг авч, бүх өгөгдлийн мэдээллийг дахин шинэчлэхэд ашиглаж болно. Үүнээс гадна олон модаль кодчуудын шинжлэх ухаан нь баян өгөгдлийн санг багасгаж, багасгах үйл ажиллагааны үйл ажиллагааг сайжруулах боломжтой. Анхаарлын үндсэн олон моделийн моделийн загварын тухай бид анхаарлын анхаарлын механизмийг хэрэглэж, загварыг чухал чанар дээр анхаарлаа хандуулахын тулд, дараа нь олон моделийн коддогч чанарыг ашиглаж, орлуулах мэдээллийг баялгаж, илүү сайн Бид өөр өгөгдлийн сан дээр маш их туршилт хийдэг. Үүний үр дүнд санал өгсөн хэлбэрийн үр дүнг үзүүлдэг.</abstract_mn>
      <abstract_pl>Wielkoskalowa klasyfikacja multimodalna ma na celu rozróżnienie różnych danych multimodalnych i od ostatniej dekady przyciąga dramatyczną uwagę. W niniejszym artykule proponujemy wielozadaniowe ramy oparte na uczeniu się dla zadania klasyfikacji multimodalnej, które składa się z dwóch gałęzi: gałęzi multimodalnego autokodera i gałęzi modelowania multimodalnego opartego na uwadze. Multi-modalny autokoder może otrzymywać funkcje multimodalne i uzyskać interaktywne informacje, które nazywają funkcją multimodalnego kodera i używać tej funkcji do odtworzenia wszystkich danych wejściowych. Ponadto funkcja multimodalnego kodera może być wykorzystana do wzbogacenia surowego zbioru danych i poprawy wydajności zadań kolejnych (takich jak zadanie klasyfikacji). Jeśli chodzi o branżę modelowania multimodalnego opartą na uwadze, najpierw stosujemy mechanizm uwagi, aby model skoncentrował się na ważnych cechach, a następnie używamy funkcji kodera multimodalnego, aby wzbogacić informacje wejściowe, osiągnąć lepszą wydajność. Przeprowadzamy obszerne eksperymenty na różnych zbiorach danych, wyniki pokazują skuteczność proponowanych ram.</abstract_pl>
      <abstract_si>විශාල විශාල විශාල විශාල විශාල විශාල දත්ත අතර වෙනස් විශාල දත්ත අතර විශාල කරන්න, ඒ වගේම ඒක අන්තිම දහස් පස්සේ  මේ පැත්තේ, අපි ගොඩක් වැඩි වැඩක් ඉගෙන ඉගෙන ගන්න අධාරිත වැඩක් වෙනුවෙන් ගොඩක් වැඩක් ප්‍රයෝජනය කරන්න ප්‍රයෝජනය කරනවා, ඒකෙන් වැඩි දෙකක් තියෙ ගොඩක් මෝඩාල් ස්වයංකේතකයෙන් ගොඩක් මෝඩාල් අවශ්‍යතාවක් ලැබෙන්න පුළුවන් සහ ගොඩක් මෝඩාල් කෝඩාර් අවශ්‍යතාවක් කියලා ස ඒ වගේම, බොහෝ මොඩාල් කෝඩාර් අවශ්‍ය භාවිතා කරන්න පුළුවන් වර්ණ දත්ත සෙට් විශ්වාස කරන්න, සහ බොහෝ ක්‍රියාත්මක වැ අවධානය අධ්‍යාත්මක විශේෂ විශේෂ විශේෂ විශේෂ වලට අපි පළමු අවධානය අධ්‍යාත්මක විධානය කරනවා, ඊට පස්සේ අපි විශේෂ විශේෂ වලට අපි වෙනස් දත්ත සැට් එකේ විශාල ප්‍රයෝජනය කරනවා, ප්‍රතිචාරය ප්‍රයෝජනය කරනවා ප්‍රයෝජනය කරපු ප්‍</abstract_si>
      <abstract_sr>Velika skala multimodalne klasifikacije je cilj da se razlikuje između različitih multimodalnih podataka, i od prošle decenije je izrazila dramatično pažnju. U ovom papiru predlažemo okvir za multimodalnu klasifikaciju, koji se sastoji od dve grane: multimodalna autokoderska grana i multimodalna modelingska grana na pažnji. Multimodalni autokoder može primiti multimodalne funkcije i dobiti interaktivne informacije koje se zovu multimodalna kodera funkcija, i koristiti ovu funkciju da bi rekonstituirali sve podatke o ulazu. Osim toga, multimodalna kodera funkcija može se koristiti za bogatstvo sirovog seta podataka i poboljšavanje učinka ležanih zadataka (poput klasifikacijskog zadataka). Što se tiče multimodalne modelne grane na pažnji, prvo upotrebimo mehanizam pažnje da se model usredotoči na važne karakteristike, a onda koristimo multimodalnu kodersku funkciju kako bi obogatili informacije o ulazu, postigli bolju funkciju. Mi vodimo široke eksperimente na različitim podacima, rezultati pokazuju učinkovitost predloženog okvira.</abstract_sr>
      <abstract_ro>Clasificarea multimodală la scară largă urmărește să facă distincția între diferitele date multimodale și a atras atenții dramatice din ultimul deceniu. În această lucrare, propunem un cadru de învățare bazat pe mai multe sarcini pentru activitatea de clasificare multimodală, care constă din două ramuri: ramura autoencoder multimodal și ramura modelare multimodală bazată pe atenție. Autoencoder multimodal poate primi caracteristici multimodale și poate obține informațiile interactive care numesc caracteristica encoder multimodal și poate utiliza această caracteristică pentru a reconstitui toate datele de intrare. În plus, caracteristica encoder multimodal poate fi utilizată pentru a îmbogăți setul de date brute și pentru a îmbunătăți performanța sarcinilor din aval (cum ar fi sarcina de clasificare). În ceea ce privește ramura modelării multimodale bazată pe atenție, folosim mai întâi mecanismul de atenție pentru a face modelul concentrat pe caracteristici importante, apoi folosim caracteristica encoder multimodal pentru a îmbogăți informațiile de intrare, pentru a obține o performanță mai bună. Realizăm experimente extinse pe diferite seturi de date, rezultatele demonstrează eficacitatea cadrului propus.</abstract_ro>
      <abstract_so>Takhasuska kala duduwan oo kala duduwan oo kala duduwan, waxayna leedahay taxadar aad u dhaqdhaqaaq ah tan iyo tobankii hore. Qoraalkan waxaan ka soo jeedaynaa koorasyo waxbarasho oo ku saleysan shaqaalaha kala duduwan, kaas oo ka mid ah laba laamood: laamaha bilowga ah oo kala duduwan iyo laamaha sameynta qaabilsan oo kala duduwan. Qodbixiyuhu wuxuu heli karaa noocyo badan oo kala duduwan, wuxuuna heli karaa macluumaad faa’iido ah oo la yidhaahdo xog badan oo noocyo badan, waxaadna isticmaali kartaa qaababkan si uu u cusboonaysiiyo macluumaadka input oo dhan. Intaas waxaa dheer oo loo isticmaali karaa qalabka koowaad oo kala duduwan si uu u hodanayo sawirada cusub, wuxuuna hagaajin karaa sameynta shaqooyinka hoose (tusaale ahaan shaqo fasax). Inta loo jeedo laamaha tusaale ahaan oo kala duduwan, marka hore waxaynu shaqaynayaa meymisyo dhaqdhaqaaq ah si aan modellka uga dhigno tayo muhiim ah, kadibna waxaynu isticmaalnaa qalabka kooxeedka kala duduwan si aan u hodanno macluumaadka soo gelinta, si aan u helno wax ka wanaagsan. Waxaan sameynaa imtixaamo dheeraad ah oo ku saabsan kooxda macluumaadka kala duduwan, dhamaadyadana waxay muujiyaan waxyaabaha lagu talo galay firaaqa.</abstract_so>
      <abstract_ta>பெரிய அளவு பல- மாதிரி வகுப்பு வகுப்புகளுக்கு வேறு பல- மாதிரி தரவுகளுக்கு இடையே வேறுபடுத்தல் செயல்படுகிறது, மற்றும் அது கடந்த பத்தாவது  இந்த காகிதத்தில், பல வகுப்பு வகுப்பு செயலுக்கான பல்வேலை கற்றல் அடிப்படையான சட்டத்தை நாம் பரிந்துரைக்கிறோம். அது இரண்டு கிளைகளில் உள்ளது: பல மாதிரி தானியங் பல- மாற்று தன்னியக்க குறியீட்டாளர் பல- மாற்று தன்னியக்க குறியீட்டை பெற முடியும் மற்றும் பல- மாற்று குறியீட்டு குறியீட்டு கூறும் இட Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task).  முக்கியமான தன்மைகள் மீது கவனம் செலுத்த முறைமையை நாம் முதலில் கவனம் முறைமையை பயன்படுத்துகிறோம், பின்னர் நாம் முக்கியமான குறியீட்டு குறியீட்டு குறியீட நாம் வேறு தரவுத்தளத்தில் விரிவான சோதனைகளை செய்கிறோம், முடிவுகள் பரிந்துரைக்கப்பட்ட சட்டத்தின் விளை</abstract_ta>
      <abstract_sv>Den storskaliga multimodala klassificeringen syftar till att skilja mellan olika multimodala data, och den har uppmärksammats dramatiskt sedan det senaste decenniet. I denna uppsats föreslår vi ett multi-task learning-baserat ramverk för multimodal klassificering uppgift, som består av två grenar: multimodal autoencoder gren och uppmärksamhetsbaserad multimodal modellering gren. Multi-modal autoencoder kan ta emot multimodala funktioner och få den interaktiva information som kallas multimodal encoder funktion, och använda denna funktion för att rekonstituera alla indata data. Dessutom kan multi-modal encoder funktion användas för att berika rådatauppsättningen och förbättra prestanda för nedströms uppgifter (såsom klassificering uppgift). När det gäller uppmärksamhetsbaserad multimodal modellering gren använder vi först uppmärksamhetsmekanism för att göra modellen fokuserad på viktiga funktioner, sedan använder vi den multimodala kodningsfunktionen för att berika indatadsinformationen, uppnå en bättre prestanda. Vi genomför omfattande experiment på olika datauppsättningar, resultaten visar hur effektivt det föreslagna ramverket är.</abstract_sv>
      <abstract_ur>بہت بڑی مزید مڈیل کلاسیفوں کا ارادہ ہے کہ مختلف متعدد موڈیل ڈیٹے کے درمیان اختلاف کریں، اور اس نے اگلے دس سال کے بعد بہت بڑی توجه کی ہے. ہم اس کاغذ میں ایک multi modal classification task کے لئے multimodal classification task کی تعلیم کی بنیاد پر بہت سے کام کا فرم پیشنهاد کرتے ہیں، جو دو شاخہ میں ہے: multimodal autoencoder branch اور attention-based multimodal modeling branch. Multi modal autoencoder can receive multimodal features and obtain the interactive information that called multimodal encoder feature, and use this feature to reconstitute all input data. اس کے علاوہ، بہت سی موڈال اینکوڈر فوکتوری استعمال کی جاتی ہے کہ رئو ڈاٹ سٹ کو ثابت قدم کرے، اور لائونٹریم ٹاکسوں کی عملکرد (جیسے کلاسپیٹ ٹاکس) بہتر کر سکے۔ لیکن توجه کی بنیادی ملتی موڈل موڈلینگ شاخہ کے لئے ہم پہلی بار توجه کی مکانیزمن کو استعمال کرتے ہیں کہ موڈل کو اہم شخصیت پر تمرکز کریں، پھر ہم multi modal encoder فرصت کو استعمال کرتے ہیں کہ ان کے سوال معلومات کو ثروت کرنے کے لئے، بہترین فعالیت حاصل کریں. ہم مختلف ڈاٹ سٹ پر وسیع آزمائش کرتے ہیں، نتیجے پیشنهاد فرمود کے فعالیت دکھاتے ہیں.</abstract_ur>
      <abstract_vi>Các phân loại đa phương rộng lớn nhằm phân biệt các dữ liệu đa phương khác nhau, và nó đã gây chú ý đột ngột từ thập kỷ qua. Trong tờ giấy này, chúng tôi đề xuất một cơ sở nghiên cứu đa nhiệm vụ phân loại đa phương, gồm hai chi nhánh: ngành mã hóa tự động nhiều chiều, và chi nhánh tạo mẫu nhiều phương thần chú ý. Hộp mã tự động đa phương có thể nhận các tính năng đa phương và thu thập các thông tin tương ứng gọi là tính năng mã hóa đa phương, và dùng tính năng này để phục hồi dữ liệu nhập. Thêm vào đó, tính năng mã hóa đa phương có thể được dùng để cải thiện bộ dữ liệu thô, và cải thiện khả năng thực hiện các công việc xuôi dòng (như nhiệm vụ phân loại). Còn về chi nhánh tạo mẫu nhiều phương tiện chú ý, chúng tôi trước tiên sử dụng cơ chế tập trung vào những tính năng quan trọng, rồi sử dụng tính năng mã hóa đa phương để làm giàu thông tin nhập, để đạt hiệu suất tốt hơn. Chúng tôi tiến hành thí nghiệm đầy đủ trên các bộ dữ liệu khác nhau, kết quả chứng minh hiệu quả của dự án.</abstract_vi>
      <abstract_uz>Bir necha modal tarkibini ajratish uchun katta shaklga ko'plab-modal darajasi, har xil modal maʼlumotlar orasidan ajratish mumkin, va bu oxirgi yil yildan avtomatik taʼminlovchilar chiqaradi. Bu qogʻozda, biz bir necha vazifa o'rganish vazifasi uchun multi modal darajalashtirish vazifasi boshqaruvchimiz, bu ikkita darajadagi ikkita darajaga ega bo'ladi: ko'plab modal kodlash chegarasi va ko'plab modal modeling qismi. Koʻproq modal avtomatik kodlash usulini bir necha modal imkoniyatlarni qabul qiladi va multi- modal kodlash imkoniyatini olish mumkin va hamma kiritish maʼlumotini qayta yuklash uchun ushbu imkoniyatlarni ishlatish mumkin. Kodlash usuli Ko'pchilik asosida multi modal model boshqa qismiga, biz birinchi marta modelni muhim xususiyatlarni qo'yish uchun foydalanamiz. Keyin biz bir necha moda kodlash imkoniyatini ishlatamiz, kiritish maʼlumotini yozish uchun yaxshi bajarish imkoniyatini bajaramiz. Biz boshqa maʼlumotlar sahifadagi kengaytirish imtiyozni bajaramiz, natijalari talab qilingan freymning effektini ko'rsatadi.</abstract_uz>
      <abstract_bg>Широкомащабната мултимодална класификация цели да разграничи различните мултимодални данни и от последното десетилетие тя привлече драстично внимание. В настоящата статия предлагаме мултимодална рамка, базирана на обучение, за задачата за мултимодална класификация, която се състои от два клона: мултимодален автокодер клон и мултимодален моделиране клон, базиран на вниманието. Мултимодалният автокодер може да получава мултимодални функции и да получи интерактивната информация, която нарича мултимодален кодер функция, и да използва тази функция, за да възстанови всички входни данни. Освен това, функцията за мултимодален кодер може да се използва за обогатяване на необработения набор от данни и подобряване на изпълнението на задачите надолу по веригата (като задача за класификация). Що се отнася до мултимодалното моделиране, базирано на вниманието клон, първо използваме механизъм за внимание, за да направим модела фокусиран върху важни характеристики, след това използваме мултимодалната функция за кодиране, за да обогатим входната информация, да постигнем по-добра производителност. Провеждаме обширни експерименти върху различни набори от данни, резултатите демонстрират ефективността на предложената рамка.</abstract_bg>
      <abstract_nl>Grootschalige multimodale classificatie beoogt onderscheid te maken tussen verschillende multimodale gegevens en heeft sinds het afgelopen decennium dramatische aandacht getrokken. In dit artikel stellen we een multi-task learning-based framework voor de multimodale classificatietaak voor, dat bestaat uit twee takken: multi-modale autoencoder tak en aandacht-gebaseerde multimodale modellering tak. De multimodale autoencoder kan multimodale kenmerken ontvangen en de interactieve informatie verkrijgen die multimodale encoderfunctie genoemd wordt, en deze functie gebruiken om alle invoergegevens te reconstitueren. Bovendien kan de multimodale encoderfunctie worden gebruikt om de ruwe dataset te verrijken en de prestaties van downstreamtaken (zoals classificatietaak) te verbeteren. Wat betreft aandacht-gebaseerde multimodale modelleringstak, gebruiken we eerst aandachtsmechanisme om het model gericht te maken op belangrijke kenmerken, dan gebruiken we de multimodale encoderfunctie om de invoerinformatie te verrijken, een betere prestaties te bereiken. We voeren uitgebreide experimenten uit op verschillende datasets, de resultaten tonen de effectiviteit van het voorgestelde framework aan.</abstract_nl>
      <abstract_hr>Velika velika multimodalna klasifikacija cilja je da se razlikuje između različitih multimodalnih podataka i od prošle decenije dramatično pažnje. U ovom papiru predlažemo brojni okvir na osnovu učenja za multimodalnu klasifikaciju, koji se sastoji od dvije grane: multimodalna autokoderska grana i multimodalna modeliranja grana na osnovu pažnje. Multimodalni autokoder može primiti multimodalne funkcije i dobiti interaktivne informacije koje se zovu multimodalna kodera funkcija, te koristiti ovu funkciju kako bi rekonstituirali sve podatke o ulazu. Osim toga, mogu se koristiti multimodalna kodera za obogaćanje sirovog seta podataka i poboljšati učinkovitost nizovog zadataka (poput klasifikacijskog zadataka). Što se tiče multimodalne modelne grane na pažnji, prvo upotrebimo mehanizam pažnje da se model usredotoči na važne karakteristike, a zatim koristimo multimodalnu kodersku funkciju kako bi obogatili informacije o ulazu, postigli bolju učinku. Mi provodimo široke eksperimente na različitim podacima, rezultati pokazuju učinkovitost predloženog okvira.</abstract_hr>
      <abstract_da>Den store multimodale klassifikation har til formål at skelne mellem forskellige multimodale data, og den har været dramatisk opmærksom siden sidste årti. I denne artikel foreslår vi en multi-task learning-baseret ramme for den multimodale klassifikationsopgave, som består af to grene: multimodal autoencoder gren og opmærksomhedsbaseret multimodal modellering gren. Multi-modal autoencoder kan modtage multimodale funktioner og få den interaktive information, som kaldes multimodal encoder funktion, og bruge denne funktion til at rekonstituere alle input data. Desuden kan multi-modal encoder funktion bruges til at berige det rå datasæt og forbedre ydeevnen af downstream opgaver (såsom klassificering opgave). Hvad angår opmærksomhedsbaseret multimodal modellering gren, anvender vi først opmærksomhedsmekanisme til at gøre modellen fokuseret på vigtige funktioner, derefter bruger vi den multimodale encoder funktion til at berige input information, opnå en bedre ydeevne. Vi gennemfører omfattende eksperimenter på forskellige datasæt, resultaterne viser effektiviteten af de foreslåede rammer.</abstract_da>
      <abstract_de>Die großräumige multimodale Klassifizierung zielt darauf ab, zwischen verschiedenen multimodalen Daten zu unterscheiden, und sie hat seit dem letzten Jahrzehnt dramatische Aufmerksamkeit auf sich gezogen. In diesem Beitrag schlagen wir ein multitasking lernbasiertes Framework für die multimodale Klassifikationsaufgabe vor, das aus zwei Zweigen besteht: multimodaler Autoencoder-Zweig und aufmerksamkeitsbasierter multimodaler Modellierungszweig. Multimodaler Autoencoder kann multimodale Funktionen empfangen und die interaktiven Informationen erhalten, die multimodale Encoder-Funktion genannt werden, und diese Funktion verwenden, um alle Eingabedaten wiederherzustellen. Außerdem kann die multimodale Encoder-Funktion verwendet werden, um den Rohdatensatz anzureichern und die Leistung von nachgelagerten Aufgaben (wie Klassifizierungsaufgaben) zu verbessern. Was den aufmerksamkeitsbasierten multimodalen Modellierungszweig betrifft, verwenden wir zuerst Aufmerksamkeitsmechanismus, um das Modell auf wichtige Funktionen zu konzentrieren, dann verwenden wir die multimodale Encoder-Funktion, um die Eingabeinformationen zu bereichern und eine bessere Leistung zu erzielen. Wir führen umfangreiche Experimente an verschiedenen Datensätzen durch, die Ergebnisse zeigen die Wirksamkeit des vorgeschlagenen Frameworks.</abstract_de>
      <abstract_id>Klasifikasi multi modal skala besar bertujuan untuk membedakan antara data multimodal yang berbeda, dan telah menarik perhatian dramatis sejak dekade lalu. Dalam kertas ini, kami mengusulkan rangka pembelajaran berbasis multi-tugas untuk tugas klasifikasi multi modal, yang terdiri dari dua cabang: cabang autokoder multimodal dan cabang modeling multimodal berbasis perhatian. Autokoder multi modal dapat menerima fitur multimodal dan mendapatkan informasi interaktif yang disebut fitur pengekoder multimodal, dan menggunakan fitur ini untuk rekonstitusi semua data input. Selain itu, fitur pengkode multi modal dapat digunakan untuk memperkaya dataset raw, dan meningkatkan prestasi tugas downstream (seperti tugas klasifikasi). Bagi cabang modeling multi modal berdasarkan perhatian, kita pertama-tama menggunakan mekanisme perhatian untuk membuat model fokus pada fitur penting, kemudian kita menggunakan fitur koder multimodal untuk memperkaya informasi input, mencapai prestasi yang lebih baik. Kami melakukan eksperimen ekstensif pada set data yang berbeda, hasilnya menunjukkan efektivitas dari cadangan yang diusulkan.</abstract_id>
      <abstract_fa>مقیاس بسیار زیادی از دسته گذشته به عنوان تفاوت بین داده های متعدد مدال متفاوت نشان می دهد و از دهه گذشته به شدت توجه به شدت کشیده است. در این کاغذ، ما پیشنهاد می کنیم یک چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهار رمز‌دهنده‌های زیادی مدال می‌تواند ویژگی‌های زیادی مدال را دریافت کند و اطلاعات interactive را دریافت کند که به عنوان ویژگی رمز‌دهنده‌های زیادی مدال نامیده می‌شود، و از این ویژگی برای بازسازی تمام داده‌های ورودی استفاده کند. علاوه بر این، ویژگی‌های رمدوندۀ چندین مدال می‌تواند برای ثروت کردن مجموعه داده‌های خالی استفاده شود و فعالیت کارهای پایین‌ترین (مثل وظیفه‌ی شناسایی) را بهبود دهد. به عنوان شاخه‌ی مدل‌سازی بسیاری از توجه، اول از مکانیسم توجه را استفاده می‌کنیم تا مدل را روی ویژه‌های مهم تمرکز کنیم، سپس از ویژه‌های متعدد مدل‌سازی استفاده می‌کنیم تا اطلاعات ورودی را ثروتمندی کنیم، و یک عملکرد بهت ما آزمایشات زیادی روی مجموعه داده‌های مختلف انجام می‌دهیم، نتیجه‌ها فعالیت چهارچوب پیشنهاد را نشان می‌دهند.</abstract_fa>
      <abstract_sw>Utawala mkubwa wa aina mbalimbali unalenga kutofautisha kati ya takwimu tofauti za matumizi, na imevuta uangalizi mkubwa tangu muongo uliopita. Katika karatasi hii, tunapendekeza mfumo wa kujifunza kwa kazi mbalimbali kwa ajili ya kazi ya kutangaza viwili, ambazo ni pamoja na matawi mawili: mfumo wa kujiandikisha kwa njia mbalimbali na mfumo wa mifano wa mitindo. Kodi la kujitegemea kwa njia nyingi inaweza kupata vipengele vya aina mbalimbali na kupata taarifa zinazohusiana na kinachoitwa tayari za kodi kwa njia mbalimbali, na kutumia kipengele hiki ili kurekebisha taarifa zote za input. Zaidi ya hayo, utaratibu wa kodi za aina mbalimbali unaweza kutumika kutajiri seti ya data chafu, na kuboresha ufanisi wa kazi za mito chini (kama vile kazi ya usambazaji). Kuhusu mfumo wa mifano mbalimbali, tunatumia mfumo wa mwanzo wa kutoa hisia ili kutengeneza mifano yenye muhimu, kisha tunatumia utambulisho wa aina mbalimbali ili kutajirisha taarifa za input, kupata ufanisi bora. Tunafanya majaribio makubwa katika seti ya data tofauti, matokeo yanaonyesha ufanisi wa mfumo wa pendekezo.</abstract_sw>
      <abstract_tr>Ullakan görnöş modal klasifikasyon beýleki modal maglumatlar arasynda tapawutlandyrmak amaçlary we bu iň soňky on bäri gaty üns çekdi. Bu kagyzda, multi modal klasifikasyon uzyny üçin köp-täblik öwrenmesi tabanly bir çerçew teklip edip görýäris. Bu iki sany: multimodal otokodeçi ramy we üns tabanly multimodal modal modelleme bagy. Çoklu modal otoködler multimodal özellikleri alap biler we multimodal ködler özelliklerini alap biler, we bu özelliği tüm giriş maglumatyny ýene döremek üçin ullanyň. Munuň ýagdaýda, köp-modal ködleme hatlary baglanmak üçin ullanyla bilýär we aşağıdaki zadlaryň eserini gowlaşdyrmak üçin ullanyla bilýär. Diňleşen multi modal modelleşdirmek üçin, biz ilkinji gezek modelleri möhüm karakterlere üns bermek üçin üns mekanizmasyny ulanýarys, soňra biz multimodal kodeýar özelligini girdi maglumatyny baýlamak üçin ullanýarys, gowy bir etkinlik ýerine ýetirýäris. Biz dürli veri setirinde örän köp deneyler çykýarys, netijeler teklip edilen çerçewçilikiň etkinliýetini görkez.</abstract_tr>
      <abstract_af>Groot- skaal multimodale klasifikasie doel om tussen verskillende multimodale data te skiedenis, en dit het dramatiese aandag van die laaste dekade getrek. In hierdie papier, voorstel ons 'n multi-taak leer-gebaseerde raamwerk vir die multimodaal klasifikasie taak, wat bestaan van twee takke: multimodaal outokoder takk en aandag-gebaseerde multimodaal modeling takk. Multi modal outokoder kan multimodale funksies ontvang en die interaktiewe inligting wat multimodale enkoder funksie genoem word, en gebruik hierdie funksie om alle invoerdataataatae herstel te word. Buitend, multimodale enkoder funksie kan gebruik word om die raai datastel te ryk en die prestasie van onderstreem opdragte (soos klasifikasie opdrag) te verbeter. As vir aandag-gebaseerde multimodaal modellering takk, gebruik ons eerste aandag mekanisme om die model op belangrike funksies te maak, dan gebruik ons die multimodaal enkoder funksie om die invoer inligting te ryk, en 'n beter prestasie te bereik. Ons doen uitbreidige eksperimente op verskillende datastel, die resultate wys die effektiviteit van voorgestelde raamwerk.</abstract_af>
      <abstract_sq>Klasifikimi i madh multi modal ka për qëllim të dallojë midis të dhënave të ndryshme multimodale dhe ka tërhequr vëmendje dramatike që nga dekada e kaluar. Në këtë letër, propozojmë një kuadër të bazuar në mësim shumë-detyrash për detyrën e klasifikimit multi modal, e cila përbëhet nga dy degë: degë multimodale autokoduese dhe degë multimodale modelimi bazuar në vëmendje. Autokoduesi multi modal mund të marrë funksione multimodale dhe të marrë informacionin interaktiv që quhet funksion multimodal koduesi dhe të përdorë këtë funksion për të rindërtuar të gjitha të dhënat e hyrjes. Përveç kësaj, funksioni i koduesit multi modal mund të përdoret për të pasuruar grupin e të dhënave të papërpunuara dhe për të përmirësuar performancën e detyrave të poshtme (të tilla si detyra klasifikuese). Sa për degën e modelimit multi modal bazuar në vëmendje, ne së pari përdorim mekanizmin e vëmendjes për të bërë modelin të përqëndruar në karakteristika të rëndësishme, pastaj përdorim karakteristikën e koduesit multimodal për të pasuruar informacionin e hyrjes, për të arritur një performancë më të mirë. Ne kryejmë eksperimente të gjerë në grupe të dhënash të ndryshme, rezultatet demonstrojnë efektshmërinë e kuadrit të propozuar.</abstract_sq>
      <abstract_ko>대규모 다중모드 분류는 서로 다른 다중모드 데이터를 구분하기 위해 최근 10년 동안 광범위한 관심을 받았다.본고는 다중 임무 학습을 바탕으로 하는 다중모드 분류 임무 구조를 제시했다. 이 구조는 두 가지 부분으로 구성되어 있는데 그것이 바로 다중모드 자동 인코딩 지점과 주의를 바탕으로 하는 다중모드 모델링 지점이다.다중모드 자동 인코더는 다중모드 특징을 수신하고 상호작용 정보를 얻을 수 있는데 이를 다중모드 인코더 특징이라고 하고 이 특징을 이용하여 모든 입력 데이터를 재구성한다.그 밖에 다중모드 인코더 특성은 원시 데이터 집합을 풍부하게 하고 하위 작업(예를 들어 분류 작업)의 성능을 향상시킬 수 있다.주의를 바탕으로 하는 다중모드 모델링 지점에 대해 우리는 먼저 주의 메커니즘을 이용하여 모델을 중요한 특징에 초점을 맞추고 다중모드 인코더의 특징을 이용하여 정보를 풍부하게 입력하여 더욱 좋은 성능을 얻는다.우리는 서로 다른 데이터 집합에서 대량의 실험을 진행하였는데, 결과는 이 구조의 유효성을 증명하였다.</abstract_ko>
      <abstract_am>በተለየ ብዙዎች-modal data መካከል ለመለየት የሚችል ትልቅ ምርጫዎች በሙሉ አሥር ዓመታት ጀምሮ በጥያቄ ተጨማሪ ነው፡፡ በዚህ ፕሮግራም፣ ለሁለት ቅርንጫፎች የሁለት ቅርንጫፎች የሚቆጠሩ የብዙዎች ትምህርት ሥርዓት መሠረት እና በብዙ-ዓይነቶች የሞዴል ቅርንጫፎች ቅርንጫፎች እና በብዙ ዓይነቶች የሚቆጠሩ ቅርንጫፎችን አቅራቢያ እናደርጋለን፡፡ የፊደል ቅርጽ ምርጫዎች በተጨማሪም የፊደል ቅርጽ አቀማመጥ ማድረጊያውን ለመጠቀም እና የወንዝ ስራዎችን ማድረግ ማድረግ ለመጠቀም ይችላል (እንደ መግለጫ አድራሻ). ለመጠየቅ የብዙኃላዊ ሞዴል ቅርንጫፍ፣ መጀመሪያ ሞዴላውን በአስቸጋሪ ምርጫዎች ላይ ለማምጣት እናስገድዳለን፣ ከዚያም የጥያቄውን መረጃ ለማጠቀም እናስጠጋለን፡፡ በተለየ የዳታ ጽሑፎች ላይ ብዙ ፈተናዎችን እናደርጋለን፤ ፍሬዎቹም የተዘጋጀውን የፍሬም ውጤት እናሳያል፡፡</abstract_am>
      <abstract_az>Büyük ölçüdə çoxlu modal klasifikasiya müxtəlif çoxlu modal verilər arasında ayırmaq məqsədilə niyyət edir, və bu son on ildən bu yana dərin dikkatini çəkir. Bu kağızda, çoxlu işin öyrənməsi üçün çoxlu modal klasifikasyon işindən olan bir çerçive təklif edirik, bu iki dəstədən oluşan: çoxlu modal autokoder dəstəsi və çoxlu modal modellik dəstəsi. Çoxlu modal avtomatik kodlayıcı çoxlu modal xüsusiyyətləri alır və çoxlu modal kodlayıcı xüsusiyyətləri adlandıran interaktif məlumatları alır və bütün girdi məlumatlarını yenidən konfigurasiya etmək üçün bu xüsusiyyəti istifadə edir. Əksinə, çoxlu modal kodlayıcı özellikləri həmçinin həmçinin verilən qutusu zenginlənmək üçün istifadə edilə bilər və aşağı-aşağı işlərin performansını (klasifikasyon işləri kimi) yaxşılaşdıra bilər. Dikkatimizi çoxlu modal modelləşdirmək dəyişinə görə, ilk dəyişiklik mehānismini mövcud fərqlərə təsirləndirmək üçün istifadə edirik, sonra çoxlu modal kodlayıcı fərqliyini istifadə edirik, girdi məlumatlarını çoxluğa çatdırmaq üçün, daha yaxşı performansı başa düşərik. Biz müxtəlif verilən qurğuda geniş eksperimentlər etdik, sonuçlar təklif edilmiş qurğunun etkinliğini göstərir.</abstract_az>
      <abstract_bs>Velika velika multimodalna klasifikacija je cilj da se razlikuje između različitih multimodalnih podataka, a od prošle decenije je izrazila dramatično pažnju. U ovom papiru predlažemo brojni okvir na osnovu učenja za multimodalnu klasifikaciju, koji se sastoji od dva grana: multimodalna autokoderska grana i multimodalna grana modeliranja na pažnji. Multimodalni autokoder može primiti multimodalne funkcije i dobiti interaktivne informacije koje se zovu multimodalna kodera funkcija, i koristiti ovu funkciju za rekonstituiranje svih podataka o ulazu. Osim toga, mogu se koristiti multimodalna kodera za obogaćanje sirovog seta podataka i poboljšati učinkovitost nizovog zadataka (poput klasifikacijskog zadataka). Što se tiče multimodalne modelne grane na pažnji, prvo upotrebimo mehanizam pažnje da se model usredotoči na važne karakteristike, a zatim koristimo multimodalnu kodersku funkciju kako bi obogatili informacije o ulazu, postigli bolju funkciju. Mi provodimo široke eksperimente na različitim podacima, rezultati pokazuju učinkovitost predloženog okvira.</abstract_bs>
      <abstract_cs>Rozsáhlá multimodální klasifikace má za cíl rozlišovat mezi různými multimodálními daty a od posledního desetiletí přitahuje dramatickou pozornost. V tomto článku navrhujeme multi-úlohový učební rámec pro multimodální klasifikační úlohu, který se skládá ze dvou větví: multimodální autokodérové větve a multimodální modelovací větve založené na pozornosti. Multimodální autokodér může přijímat multimodální funkce a získat interaktivní informace, které nazývají multimodální snímač funkce, a použít tuto funkci k rekonstituci všech vstupních dat. Kromě toho, multimodální snímač funkce může být použit k obohacení surové datové sady a zlepšení výkonu následných úloh (jako je klasifikační úloha). Pokud jde o multimodální modelování založenou na pozornosti, nejprve používáme mechanismus pozornosti, aby se model zaměřil na důležité vlastnosti, pak používáme funkci multimodálního snímače k obohacení vstupních informací, dosažení lepšího výkonu. Provádíme rozsáhlé experimenty na různých datových sadách, výsledky ukazují efektivitu navrženého rámce.</abstract_cs>
      <abstract_hy>Մեծ մասշտաբով բազմամոդային դասակարգման նպատակն է տարբեր բազմամոդային տվյալների միջև տարբերվել, և այն վերջին տասնամյակից շատ ուշադրություն է դարձրել: Այս թղթի մեջ մենք առաջարկում ենք բազմախնդիրների ուսումնասիրության հիմնված շրջանակ բազմամոդական դասակարգման խնդրի համար, որը կազմված է երկու ճյուղերից' բազմամոդական ավտոկոդերի ճյուղերից և ուշադրության հիմնված բազմամոդական մոդելների ճյուղերից Բազմամոդալ ավտոկոդերը կարող է ստանալ բազմամոդալ հատկանիշներ և ստանալ ինտերակտիվ տեղեկատվությունը, որը կոչվում է բազմամոդալ կոդեր հատկանիշ, և օգտագործել այս հատկանիշը վերականգնելու համար բոլոր մուտքագրված տվյալները: Ավելին, բազմամոդային կոդավորման հատկությունը կարող է օգտագործվել աղբ տվյալների համակարգի հարստացնելու և հետագա խնդիրների (ինչպիսիք են դասակարգման խնդիրները) արտադրողության բարելավման համար: As for attention-based multimodal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multi-modal encoder feature to enrich the input information, achieve a better performance.  Մենք տարբեր տվյալների համակարգերի վրա էքսպենսիվ փորձեր ենք կատարում, արդյունքները ցույց են տալիս առաջարկած շրջանակի արդյունավետությունը:</abstract_hy>
      <abstract_et>Laiaulatusliku mitmeliigilise liigituse eesmärk on eristada erinevaid mitmeliigilisi andmeid ning see on juhtinud märkimisväärset tähelepanu alates viimasest kümnendist. Käesolevas töös pakume välja mitmeliigilise klassifitseerimisülesande mitmeliigilise õppepõhise raamistiku, mis koosneb kahest harust: mitmeliigilise autokodeeri harust ja tähelepanupõhisest mitmeliigilise modelleerimise harust. Multimodaalne automaatkodeerija võib vastu võtta multimodaalseid funktsioone ja saada interaktiivset teavet, mida nimetatakse multimodaalseks kodeerijaks funktsiooniks, ning kasutada seda funktsiooni kõigi sisendandmete taastamiseks. Lisaks saab mitmeliigilist kodeerijat kasutada toorandmekogumi rikastamiseks ja järgnevate ülesannete (nt klassifitseerimisülesannete) tulemuslikkuse parandamiseks. Mis puudutab tähelepanupõhist multimodaalset modelleerimist, siis kasutame esmalt tähelepanumehhanismi, et muuta mudel keskendunud olulistele omadustele, seejärel kasutame multimodaalset kodeerijat sisendteabe rikastamiseks, parema jõudluse saavutamiseks. Teostame ulatuslikke eksperimente erinevate andmekogumitega, tulemused näitavad kavandatud raamistiku efektiivsust.</abstract_et>
      <abstract_fi>Laajamittaisella multimodaaliluokituksella pyritään erottamaan toisistaan eri multimodaalitiedot, ja se on herättänyt dramaattista huomiota viime vuosikymmenestä lähtien. Tässä työssä ehdotamme multimodaalisen luokittelutehtävän monitehtäväoppimiseen perustuvaa viitekehystä, joka koostuu kahdesta haarasta: multimodaalisesta automaattikooderin haarasta ja huomiopohjaisesta multimodaalisesta mallinnushaarasta. Multimodaalinen automaattikooderi voi vastaanottaa multimodaalisia ominaisuuksia ja saada interaktiivista tietoa, jota kutsutaan multimodaaliseksi kooderiominaisuudeksi, ja käyttää tätä ominaisuutta kaikkien syöttötietojen palauttamiseen. Lisäksi multimodaalista kooderiominaisuutta voidaan käyttää raaka-aineiston rikastamiseen ja jatkojalostustehtävien (kuten luokitustehtävän) suorituskyvyn parantamiseen. Huomioon perustuvassa multimodaalisessa mallinnushaarassa käytämme ensin huomiomekanismia, jotta malli keskittyisi tärkeisiin ominaisuuksiin, sitten käytämme multimodaalista kooderiominaisuutta rikastamaan syöttötietoja, saavuttamaan paremman suorituskyvyn. Teemme laajoja kokeiluja eri aineistoilla, tulokset osoittavat ehdotetun viitekehyksen tehokkuuden.</abstract_fi>
      <abstract_bn>ব্যাপক মোডাল ক্লাসাফেশনের লক্ষ্য হচ্ছে বিভিন্ন বহুমোডাল ডাটার মধ্যে বিচ্ছিন্ন করার, আর গত দশকের পর থেকে এটি ন্যায়ামিকভাবে মনোয এই কাগজটিতে আমরা মাল্টিমোডাল ক্লাস্ফিকেশন কাজের জন্য একটি বহুক্ত কাজ শিক্ষা ভিত্তিক কাঠামো প্রস্তাব করি, যা দুটি শাখার মধ্যে রয়েছে: বহুমোডাল স্বয়ং বহুমোডাল স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয় এনকোডার পাওয়া যাবে বহুমোডাল-মোডাল বৈশিষ্ট্য প্রাপ্ত এবং ইন্টার্ভিক তথ্য পাওয়া যাবে যার না এছাড়াও, ভূল ডাটাসেট সমৃদ্ধ করার জন্য বহুমোডাল এনকোডারের বৈশিষ্ট্য ব্যবহার করা যাবে এবং নীচের কাজের প্রভাব উন্নত করা যাবে (যেমন ক্লা মাল্টিমোডাল মডেলিং শ্র্যাঙ্কের দৃষ্টিভঙ্গিতে আমরা প্রথমে মডেলের প্রতি মনোযোগ আকর্ষণ করি গুরুত্বপূর্ণ বৈশিষ্ট্যের উপর, তারপর আমরা বহুমোডাল এনকোডারের বৈ আমরা বিভিন্ন ডাটাসেটে বিস্তারিত পরীক্ষা করি, ফলাফল প্রস্তাবিত ফ্রেমের কার্যক্রম প্রদর্শন করে।</abstract_bn>
      <abstract_ca>La classificació multi modal a gran escala té l'objectiu de distingir entre diferents dades multimodals, i ha atraït molta atenció des de la darrera dècada. En aquest paper, proposem un marc d'aprenentatge multitascat per la tasca de classificació multi modal, que consisteix en dues ramificacions: ramificació multimodal d'autocodificació i ramificació multimodal d'atenció. L'autocodificador multi modal pot rebre característiques multimodals i obtenir la informació interactiva que es diu característica multimodal, i utilitzar aquesta característica per reconstruir totes les dades d'entrada. A més, es pot utilitzar una característica multi modal de codificador per enriquecer el conjunt de dades bruts i millorar el rendiment de tasques avall (com ara tasca de classificació). Quant a la rama de modelació multi modal basada en l'atenció, primer fem servir mecanisme d'atenció per centrar-nos en característiques importants, després fem servir la característica del codificador multimodal per enriquecer la informació d'entrada, aconseguir un millor rendiment. Fem experiments extensos en diversos conjunts de dades, els resultats demostren l'eficacia del marc proposat.</abstract_ca>
      <abstract_jv>string" in "context_BAR_stringLink Nang pentung iki, kita supoyo sistem multi-task Learn-basa kanggo kelas multi modal, sing dumadhi karo ramu ramu: multi-modal autokoder ramu lan ateng-basa multimodal modelining ramu. Multi modal autokoder can find multi-modal parameters and find the interactive information that cries multi-modal koder option, and use this option to decostitute all the input data. politenessoffpolite"), and when there is a change ("assertivepoliteness Tanggal kanggo diangkat-diangkat sistem multi modal, kita ngubah perusahaan winih kanggo nggawe modal sing nyimpen ingkang diangkat ingkang cara sing dikarepok, kita ngubah dhéwé sistem multimodal karo pakek nggawe informasi layar, iso nggawe akeh lanjut cara sing luwih dumadhi. Awak dhéwé éntuk éntuk akèh akeh operasi ning dataset sing mengko, dadi sing ngomong nik nggawe efekat kanggo nyenggawe barang nggawe</abstract_jv>
      <abstract_ha>Tsarawa masu girma na ƙayyade multi-modal don ya yi amfani da yin rarraba tsakanin data masu daban-modal, kuma ya goyi taƙaitori masu taƙaita kanan kwanan wata shekara ta shida. Daga wannan takardan, Munã buɗa wani firam mai yawan aikin da aka sanar da shi a kan aikin multiodal, wanda ke haɗi na biyu-rasa: rubutun farat-kwamfyuta masu amfani da mai nuna wa masu motsi masu yawa. Koda farat-kwamfyuta mai yawa zai iya motsa wasu tsari masu motsi masu yawa kuma ya sami information masu husũma wanda ke kiran tsarin kode-multi-moda, kuma ka yi amfani da wannan feature don ya canza tsarin tsarin da za'a sake sake tsari duk data na shigar. Bayan haka, za'a yi amfani da tsarin kode-multi-moda don ya wadãtar da tsarin maɓallin raw, kuma ya kyautata aikin aikin aiki na ƙarƙashin (kamar misãlin aikin classified). As for attention-based multimodal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multi-modal encoder feature to enrich the input information, achieve a better performance.  Munã samun jarrabo masu yawa a kan danne-danne-daban, matsalan za'a nuna aikin firam wanda aka buƙata.</abstract_ha>
      <abstract_sk>Cilj obsežne multimodalne klasifikacije je razlikovanje med različnimi multimodalnimi podatki, od zadnjega desetletja pa je pritegnila veliko pozornosti. V prispevku predlagamo večopravilni učni okvir za nalogo multimodalne klasifikacije, ki je sestavljen iz dveh vej: veje multimodalnega avtokodikatorja in veje multimodalnega modeliranja, ki temelji na pozornosti. Multimodalni samokodirnik lahko sprejema multimodalne funkcije in pridobi interaktivne informacije, ki jih imenuje funkcija multimodalnega kodirnika, in uporablja to funkcijo za rekonstitucijo vseh vhodnih podatkov. Poleg tega se lahko funkcija multimodalnega kodirnika uporablja za obogatitev surovega nabora podatkov in izboljšanje uspešnosti nadaljnjih nalog (kot je opravilo klasifikacije). Kar zadeva večmodalno modeliranje, ki temelji na pozornosti, najprej uporabimo mehanizem pozornosti, da bi model osredotočil na pomembne značilnosti, nato pa uporabimo funkcijo multimodalnega kodirnika za obogatitev vhodnih informacij, doseganje boljše zmogljivosti. Izvajamo obsežne eksperimente na različnih podatkovnih naborih, rezultati pa kažejo učinkovitost predlaganega okvira.</abstract_sk>
      <abstract_fil>Ang malaking kalagayan ng maraming modal na klasifikasyon ay ibig ang pagpakaiba sa pagitan ng iba't iba't ibang multimodal na data, at ito'y gumawa ng dramatic attention mula nang huling dekada. Sa papiro na ito, inihahandog namin ang isang multi-task-learning-based framework para sa multi modal classification task, na may dalawang sanga: multimodal autoencoder branch at multimodal modeling branch. Maraming modal autoencoder ay makatatanggap ng maraming modal na feature at makakuha ng interactive na impormasyon na tinatawag na multimodal encoder feature, at gamitin ang feature na ito upang reconstruction ang lahat ng data ng input. Bukod dito, ang multi modal encoder feature ay maaaring gamitin upang mayaman ang raw dataset, at pabago ang performance ng downstream tasks (tulad ng task ng klasifikasyon). Tungkol sa multi modal modeling branch na nagbabago ng attention, ginagamit namin muna ang pag-iingat na mekanismo upang gawin ang model na focused sa mga mahalagang karakter, pagkatapos ginagamit namin ang multimodal encoder feature upang magmayaman ng impormasyong input, magtataglay ng mas mabuti na performance. Ginagawa namin ng malaking eksperimento sa ibang dataset, ang mga resulta ay nagpapakita ng effectiveness ng proposed framework.</abstract_fil>
      <abstract_bo>དབྱེ་སྟངས་འདྲ་བ་མང་ཆེ་བའི་དབྱེ་རིགས་ལ་དམིགས་ཡུལ་ནི་དབྱེ་སྟངས་ཀྱི་ཐབས་ལམ་འདྲ་བ་དང་འདིས་འདས་པའི་ལོ་བཅུ་ལྷག་ལས་འགྱུར་བ་རེད། ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་འདྲ་བྱུང་བའི་ལྟ་བུའི་རྒྱུ་དངོས་ཡིག་ཆ་རྩལ་བ་གཞི་རྟེན་ནས་སྣ་མཐུན་གྱི་གནད་སྡུད་ཅིག་བཤད་ཀྱི་ཡོད། Multi-modal autoencoder can receive multi-modal features and obtain the interactive information which called multi-modal encoder feature, and use this feature to reconstitute all the input data. Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task). As for attention-based multi modal modeling branch, we first employ attention mechanism to make the model focused on important features, then we use the multimodal encoder feature to enrich the input information, achieve a better performance. ང་ཚོས་གནས་སྟངས་སྒྲིག་ཆ་མ་འདྲ་བ་ལ་བརྟག་ཞིབ་བྱེད་པའི་གྲུབ་འབྲས་བ་དེ་གིས་ཉེན་ཁ་ཡོད་པའི་ལྟ་བུ</abstract_bo>
      <abstract_he>מסגרת מסוג רב-מודלית גדולה מכוונה להבדיל בין נתונים רב-מודליים שונים, והיא משיכה תשומת לב דרמטית מאז עשור שעבר. בעיתון הזה, אנו מציעים מסגרת למידה רבה-משימות מבוססת למשימה רבה-מודלית למשימה רבה-מודלית, אשר מורכבת משני ענפים: ענף מודלית אוטומודלית רבה-מודלית ומבוססת תשומת לב ענף מודלית רבה-מודלית. Multi-modal autoencoder can receive multi-modal features and obtain the interactive information which called multi-modal encoder feature, and use this feature to reconstitute all the input data.  Besides, multi-modal encoder feature can be used to enrich the raw dataset, and improve the performance of downstream tasks (such as classification task).  בנוגע לענף הדוגמניות המולטימודלית המבוססת על תשומת לב, אנו קודם משתמשים במנגנון תשומת לב כדי לגרום לדוגמא להתמקד על תכונות חשובות, ואז אנו משתמשים בתוכנית המקוד המולטימודלית כדי לעשיר את מידע הכניסה, להשיג ביצוע טוב יותר. We conduct extensive experiments on different dataset, the results demonstrate the effectiveness of proposed framework.</abstract_he>
      </paper>
    <paper id="10">
      <title>A Package for Learning on Tabular and Text Data with Transformers</title>
      <author><first>Ken</first><last>Gu</last></author>
      <author><first>Akshay</first><last>Budhkar</last></author>
      <pages>69–73</pages>
      <abstract>Recent progress in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> has led to Transformer architectures becoming the predominant model used for natural language tasks. However, in many real- world datasets, additional modalities are included which the <a href="https://en.wikipedia.org/wiki/Transformer">Transformer</a> does not directly leverage. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face’s existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract>
      <url hash="2665785e">2021.maiworkshop-1.10</url>
      <doi>10.18653/v1/2021.maiworkshop-1.10</doi>
      <bibkey>gu-budhkar-2021-package</bibkey>
    <title_pt>Um pacote para aprendizado em dados tabulares e de texto com transformadores</title_pt>
      <title_ar>حزمة للتعلم على البيانات الجدولية والنصية باستخدام المحولات</title_ar>
      <title_fr>Un package pour l'apprentissage des données tabulaires et textuelles avec Transformers</title_fr>
      <title_es>Un paquete para aprender datos tabulares y de texto con Transformers</title_es>
      <title_ja>変圧器を使用した表形式およびテキストデータの学習パッケージ</title_ja>
      <title_zh>用转换器学表格及文本数软件包</title_zh>
      <title_hi>ट्रांसफॉर्मर के साथ सारणीबद्ध और पाठ डेटा पर सीखने के लिए एक पैकेज</title_hi>
      <title_ru>Пакет для обучения табличным и текстовым данным с трансформаторами</title_ru>
      <title_ukr>Пакет для навчання табличним та текстовим даним за допомогою трансформаторів</title_ukr>
      <title_ga>Pacáiste le haghaidh Foghlama ar Shonraí Tábla agus Téacs le Claochladáin</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>Táblázatos és szöveges adatok tanulására szolgáló csomag transzformátorokkal</title_hu>
      <title_it>Un pacchetto per imparare sui dati tabulari e di testo con i trasformatori</title_it>
      <title_el>Ένα πακέτο για τη μάθηση σε δεδομένα πίνακα και κειμένου με μετασχηματιστές</title_el>
      <title_kk>Қойындық мен мәтін деректерінің оқыту дестесіName</title_kk>
      <title_lt>A Package for Learning on Tabular and Text Data with Transformers</title_lt>
      <title_ms>A Package for Learning on Tabular and Text Data with Transformers</title_ms>
      <title_ml>Name</title_ml>
      <title_mk>Пакет за учење на таблички и текстови податоци со трансформирачиName</title_mk>
      <title_isl>Pakkning til að læra á töflu- og textagögnum með umbreytingum</title_isl>
      <title_mn>Хүснэгт болон Текст өгөгдлийн тухай сурах багц</title_mn>
      <title_no>Name</title_no>
      <title_ro>Un pachet pentru învățarea datelor tabulare și text cu transformatoare</title_ro>
      <title_mt>Pakkett għat-Tagħlim fuq Dejta Tabulari u tat-Test bi Trasformaturi</title_mt>
      <title_sr>Paket za učenje na tabularnim i tekstskim podacima sa transformatorima</title_sr>
      <title_si>Name</title_si>
      <title_sv>Ett paket för att lära sig om tabeller och textdata med transformatorer</title_sv>
      <title_so>A package for Learning on Table and Text Data with Transformers</title_so>
      <title_ta>Name</title_ta>
      <title_ur>Name</title_ur>
      <title_pl>Pakiet do nauki o danych tabelarnych i tekstowych z transformatorami</title_pl>
      <title_uz>Name</title_uz>
      <title_vi>Một gói tin để học trên các hình ảnh và các dữ liệu văn bản có biến hình</title_vi>
      <title_bg>Пакет за обучение на таблици и текстови данни с трансформатори</title_bg>
      <title_nl>Een pakket voor leren over tabelvormige en tekstgegevens met transformers</title_nl>
      <title_da>En pakke til læring om tabel- og tekstdata med transformatorer</title_da>
      <title_hr>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</title_hr>
      <title_de>Ein Paket zum Lernen von Tabellen- und Textdaten mit Transformatoren</title_de>
      <title_id>Pakej untuk Belajar di Data Tabular dan Teks dengan Transformer</title_id>
      <title_ko>Transformers 학습 표 및 텍스트 데이터를 사용하는 패키지</title_ko>
      <title_fa>Name</title_fa>
      <title_sw>Mpaka wa kujifunza kwenye Taarifa za Tabili na Matandao yenye Wasafiri</title_sw>
      <title_tr>Täbler we Metin Maglumaty Üýtgetmek üçin bir Paket</title_tr>
      <title_hy>Comment</title_hy>
      <title_af>Name</title_af>
      <title_am>Table and Text Data with Transformers</title_am>
      <title_sq>Një paketë për mësim në të dhënat tabelore dhe tekstore me transformues</title_sq>
      <title_bn>Name</title_bn>
      <title_bs>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</title_bs>
      <title_az>T톛rc칲m톛 v톛 Metin Veril톛ri il톛 칐yr톛nm톛k 칲칞칲n Paket</title_az>
      <title_ca>Un paquet d'aprenentatge a les dades tabulars i textuals amb transformadors</title_ca>
      <title_et>Pakett tabel- ja tekstiandmete õppimiseks transformaatoritega</title_et>
      <title_fi>Paketti taulukkotietojen ja tekstitietojen oppimiseen muuntajien avulla</title_fi>
      <title_cs>Balíček pro výuku tabulkových a textových dat s transformátory</title_cs>
      <title_jv>Name</title_jv>
      <title_ha>A Package for Learning on Tabular and Text Data with Transformers</title_ha>
      <title_he>חבילה ללמוד על מידע טקסט ולשולחן עם מעצבים</title_he>
      <title_sk>Paket za učenje tabelarnih in besedilnih podatkov s transformatorji</title_sk>
      <title_fil>Name</title_fil>
      <title_bo>ཤོག་བྱང་དང་ཡི་གེའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་བསུབ་པའི་སྒྲིག་སྟངས</title_bo>
      <abstract_fr>Les récents progrès dans le traitement du langage naturel ont conduit les architectures Transformer à devenir le modèle prédominant utilisé pour les tâches en langage naturel. Cependant, dans de nombreux ensembles de données du monde réel, des modalités supplémentaires sont incluses que le Transformer n'exploite pas directement. Nous présentons Multimodal-Toolkit, un package Python open source permettant d'intégrer du texte et des données tabulaires (catégoriques et numériques) avec Transformers pour les applications en aval. Notre boîte à outils s'intègre parfaitement à l'API existante de Hugging Face, telle que la tokenisation et le hub de modèles, qui permet de télécharger facilement différents modèles pré-entraînés.</abstract_fr>
      <abstract_ar>أدى التقدم الأخير في معالجة اللغة الطبيعية إلى أن تصبح معماريات Transformer هي النموذج السائد المستخدم في مهام اللغة الطبيعية. ومع ذلك ، في العديد من مجموعات البيانات في العالم الحقيقي ، يتم تضمين طرائق إضافية لا يستفيد منها المحول بشكل مباشر. نقدم مجموعة الأدوات متعددة الوسائط ، وهي حزمة Python مفتوحة المصدر لدمج البيانات النصية والجداول (الفئوية والرقمية) مع المحولات للتطبيقات النهائية. تتكامل مجموعة الأدوات الخاصة بنا بشكل جيد مع واجهة برمجة التطبيقات الحالية لـ Hugging Face مثل الرمز المميز ومحور النموذج الذي يسمح بتنزيل نماذج مختلفة مُدربة مسبقًا بسهولة.</abstract_ar>
      <abstract_es>El progreso reciente en el procesamiento del lenguaje natural ha llevado a que las arquitecturas Transformer se conviertan en el modelo predominante utilizado para las tareas del lenguaje natural. Sin embargo, en muchos conjuntos de datos del mundo real, se incluyen modalidades adicionales que el Transformer no aprovecha directamente. Presentamos Multimodal- Toolkit, un paquete Python de código abierto para incorporar texto y datos tabulares (categóricos y numéricos) con Transformers para aplicaciones posteriores. Nuestro kit de herramientas se integra bien con la API existente de Hugging Face, como la tokenización y el centro de modelos, que permite descargar fácilmente diferentes modelos previamente entrenados.</abstract_es>
      <abstract_pt>O progresso recente no processamento de linguagem natural fez com que as arquiteturas Transformer se tornassem o modelo predominante usado para tarefas de linguagem natural. No entanto, em muitos conjuntos de dados do mundo real, são incluídas modalidades adicionais que o Transformer não aproveita diretamente. Apresentamos o Multimodal- Toolkit, um pacote Python de código aberto para incorporar texto e dados tabulares (categóricos e numéricos) com Transformers para aplicativos downstream. Nosso kit de ferramentas se integra bem com a API existente do Hugging Face, como tokenização e o hub de modelos, que permite o download fácil de diferentes modelos pré-treinados.</abstract_pt>
      <abstract_ja>自然言語処理の最近の進歩により、Transformerアーキテクチャは自然言語タスクに使用される主なモデルになりました。しかし、多くの現実世界のデータセットでは、トランスフォーマーが直接レバレッジしない追加のモダリティが含まれています。マルチモーダルツールキットは、オープンソースのPythonパッケージで、下流アプリケーションのためのTransformersとのテキストおよび表形式（カテゴリおよび数値）データを組み込むことができます。当社のツールキットは、トークン化やモデルハブなど、Hugging Faceの既存のAPIとうまく統合されており、さまざまな事前にトレーニングを受けたモデルを簡単にダウンロードできます。</abstract_ja>
      <abstract_hi>प्राकृतिक भाषा प्रसंस्करण में हाल की प्रगति ने ट्रांसफॉर्मर आर्किटेक्चर को प्राकृतिक भाषा कार्यों के लिए उपयोग किया जाने वाला प्रमुख मॉडल बनने के लिए प्रेरित किया है। हालांकि, कई वास्तविक दुनिया के डेटासेट में, अतिरिक्त तौर-तरीकों को शामिल किया गया है जो ट्रांसफॉर्मर सीधे लाभ नहीं उठाता है। हम मल्टीमॉडल-टूलकिट, डाउनस्ट्रीम अनुप्रयोगों के लिए ट्रांसफॉर्मर के साथ पाठ और सारणीबद्ध (स्पष्ट और संख्यात्मक) डेटा को शामिल करने के लिए एक ओपन-सोर्स पायथन पैकेज प्रस्तुत करते हैं। हमारा टूलकिट फेस के मौजूदा एपीआई जैसे टोकनाइजेशन और मॉडल हब को गले लगाने के साथ अच्छी तरह से एकीकृत करता है जो विभिन्न पूर्व-प्रशिक्षित मॉडलों के आसान डाउनलोड की अनुमति देता है।</abstract_hi>
      <abstract_zh>自然语言理之最新进展Transformer架构为自然语言务大体。 然世界数集,变形金刚无径用者模态。 余言Multimodal-Toolkit,此一开源Python包也,以合文本与表格(数)数与Transformers并为下流应用程序。 吾工具包与Hugging Face之见API善相聚,若标化与中心,可以轻下载异者。</abstract_zh>
      <abstract_ru>Недавний прогресс в обработке естественного языка привел к тому, что архитектуры трансформаторов стали преобладающей моделью, используемой для задач естественного языка. Тем не менее, во многих наборах данных реального мира включены дополнительные модальности, которые Трансформер напрямую не использует. Мы представляем Multimodal- Toolkit, пакет Python с открытым исходным кодом для интеграции текстовых и табличных (категориальных и числовых) данных с Трансформаторами для последующего применения. Наш инструментарий хорошо интегрируется с существующим API Hugging Face, таким как токенизация и концентратор моделей, который позволяет легко загружать различные предварительно обученные модели.</abstract_ru>
      <abstract_ukr>Нещодавній прогрес в обробці природної мови призвів до того, що архітектури Трансформерів стали переважною моделлю, що використовується для завдань природної мови. Однак, у багатьох реальних наборах даних включені додаткові модальності, які Трансформер безпосередньо не використовує. Ми представляємо Multimodal- Toolkit, пакет Python з відкритим вихідним кодом для інтеграції текстових та табличних (категорійних та числових) даних з Transformers для подальших застосувань. Наш інструментарій добре інтегрується з існуючим API Hugging Face, таким як токенізація та концентратор моделей, що дозволяє легко завантажувати різні попередньо навчені моделі.</abstract_ukr>
      <abstract_ga>Mar gheall ar an dul chun cinn a rinneadh le déanaí i bpróiseáil teanga nádúrtha is í ailtireacht Claochladáin an príomh-mhúnla a úsáidtear do thascanna nádúrtha teanga. Mar sin féin, i go leor tacar sonraí den fhíorshaol, cuirtear módúlachtaí breise san áireamh nach ndéanann an Trasfhoirmeoir giaráil díreach orthu. Cuirimid i láthair Multimodal- Toolkit, pacáiste foinse oscailte Python chun téacs agus sonraí tábla (catagóireacha agus uimhriúla) a ionchorprú le Transformers le haghaidh feidhmchláir iartheachtacha. Comhtháthaíonn ár bhfoireann uirlisí go maith leis an API atá ann cheana féin Hugging Face ar nós tokenization agus an mol múnla a cheadaíonn samhlacha réamhoilte éagsúla a íoslódáil go héasca.</abstract_ga>
      <abstract_ka>მიმდინარე პროგრესი თავისუფალური ენის პროცესის შესახებ ტრანფორმეტრის აქტიქტიქტურების შესახებ, რომელიც თავისუფალური ენის დავალებებისთვის გამ მაგრამ, ბევრი რეალური მსოფლიოს მონაცემების კონფიგურაციაში, დამატებული მოდილიტები ჩვენებულია, რომლებიც ტრანფიგურაციატორი არ ექსტურ ჩვენ მრავალმედიალური ხელსაწყობილობის კონფიგურაცია, გახსნილი Python ფოკეტის პაკეტი, რომელიც ტექსტის და ტაბულური (კატეგორიალური და ციფრიური) მონაცემების შეყვარე ჩვენი ხელსაწყოთა კიტი ძალიან ინტერგურაცია, როგორც ტოკენიზაცია და მოდელური ჰუბი, რომელიც განსხვავებული პრე-განსწავლებული მოდელების განმავლობაში ადვილი გადატანა.</abstract_ka>
      <abstract_el>Η πρόσφατη πρόοδος στην επεξεργασία φυσικής γλώσσας έχει οδηγήσει στις αρχιτεκτονικές μετασχηματιστών να γίνουν το κυρίαρχο μοντέλο που χρησιμοποιείται για εργασίες φυσικής γλώσσας. Ωστόσο, σε πολλά σύνολα δεδομένων πραγματικού κόσμου, περιλαμβάνονται πρόσθετες λεπτομέρειες τις οποίες ο μετασχηματιστής δεν αξιοποιεί άμεσα. Παρουσιάζουμε ένα πακέτο ανοιχτού κώδικα για την ενσωμάτωση κειμένου και πινάκων (κατηγορηματικών και αριθμητικών) δεδομένων με μετασχηματιστές για μεταγενέστερες εφαρμογές. Η εργαλειοθήκη μας ενσωματώνεται καλά με το υπάρχον όπως η επισήμανση και ο κόμβος μοντέλου που επιτρέπει την εύκολη λήψη διαφορετικών προ-εκπαιδευμένων μοντέλων.</abstract_el>
      <abstract_hu>A természetes nyelv feldolgozásának közelmúltbeli fejlődése miatt a Transformer architektúrák a természetes nyelvi feladatok meghatározó modelljévé váltak. Számos valós adatkészletben azonban további módszereket is tartalmaznak, amelyeket a Transzformátor nem használ közvetlenül. Bemutatjuk a Multimodális- Toolkit-et, egy nyílt forráskódú Python csomagot, amely szöveget és táblázatos (kategorikus és numerikus) adatokat foglal magába a transzformátorokkal downstream alkalmazásokhoz. Eszközkészletünk jól integrálódik a Hugging Face meglévő API-jával, mint például a tokenizáció és a modell hub, amely lehetővé teszi a különböző előre képzett modellek egyszerű letöltését.</abstract_hu>
      <abstract_kk>Табиғи тіл процессінің жаңа жағдайда архитектураларды түрлендіру үшін табиғи тіл тапсырмалар үшін қолданылатын үлгі болады. Бірақ көптеген шын әлемдегі деректер қорларында Трансформациясы тікелей тәртіпке жеткізбейтін қосымша әдістер қосылады. Мәтін мен кестелер (сандар мен сандар) деректерін төменгі қолданбалар үшін Трансформациялау құралдарының көшірмесі Python бағдарламасының көшірмесі. Біздің құралдар панеліміз Hugging Face- дің барлық API мен бірге біріктіреді, мысалы, токенизациялау мен өзгертілген алдындағы моделдерді оңай жүктеуге мүмкіндік беретін моделдерді.</abstract_kk>
      <abstract_lt>Pastaruoju metu gamtinės kalbos apdorojimo pažanga lėmė, kad transformuotojų architektūros tapo vyraujančiu gamtinės kalbos užduotims naudojamu modeliu. However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage.  Mes pristatome Multimodal- Toolkit, atviro kodo Python paketą, kuriame bus įtraukti teksto ir lentelių (kategorijinių ir skaitmeninių) duomenys su Transformers tolesnėms programoms. Mūs ų įrankių rinkinys gerai integruojamas su esama Hugging Face API, pvz., tokenizacija ir modelio centras, kuris leidžia lengvai parsisiųsti įvairius iš anksto parengtus modelius.</abstract_lt>
      <abstract_mk>Неодамнешниот напредок во природното обработување на јазиците доведе до трансформарните архитектури да станат претежниот модел кој се користи за природните јазични задачи. Сепак, во многу податоци од реалниот свет се вклучени дополнителни модијали кои Трансформерот не ги влијае директно. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_mk>
      <abstract_it>I recenti progressi nell'elaborazione del linguaggio naturale hanno portato le architetture Transformer a diventare il modello predominante utilizzato per le attività di linguaggio naturale. Tuttavia, in molti dataset del mondo reale, sono incluse modalità aggiuntive che il Transformer non sfrutta direttamente. Vi presentiamo Multimodal- Toolkit, un pacchetto Python open source per incorporare testo e dati tabulari (categorici e numerici) con Transformers per applicazioni downstream. Il nostro toolkit si integra bene con l'API esistente di Hugging Face come la tokenizzazione e l'hub del modello che consente di scaricare facilmente diversi modelli pre-addestrati.</abstract_it>
      <abstract_ms>Kemajuan baru-baru ini dalam pemprosesan bahasa alami telah menyebabkan arkitektur Transformer menjadi model utama yang digunakan untuk tugas bahasa alami. Bagaimanapun, dalam banyak set data dunia nyata, modaliti tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami perkenalkan Multimodal- Toolkit, pakej Python sumber terbuka untuk menggabungkan teks dan data tabular (kategori dan nombor) dengan Transformers untuk aplikasi turun. Kit alat kami menyertai dengan baik dengan API yang wujud Hugging Face seperti tokenization dan hub model yang membolehkan muat turun mudah bagi model yang berlainan yang dilatih.</abstract_ms>
      <abstract_isl>Nýlega hefur framfarið í náttúrulegum tungumálameðhöndlun leitt til þess að Umbreyttar arkitektur verði yfirvaldandi líkan sem notað er í náttúrulegum tungumálaverkum. However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage.  Við kynnum fjölmóða- tækjasett, opinn Python pakki sem inniheldur texta og töflugögn (flokkaðar og tölulegar) með Transformers fyrir neðan forrit. Verkfæri okkar tengist vel við aðgerð Hugging Face sem er til staðar eins og tokenization og líkanhnútur sem leyfir auðvelt að hlaða niður mismunandi forþjálfaðar líkanir.</abstract_isl>
      <abstract_mn>Байгалийн хэл үйлдвэрлэлийн саяхан хөгжлийн үр дүнд байгалийн хэл үйлдвэрлэлд хэрэглэгддэг архитектурууд Трансфер архитектурууд болж ирсэн. Гэхдээ маш олон бодит ертөнцийн өгөгдлийн санд Трансформатор шууд хэрэглэхгүй нэмэлт арга замыг нэмэгдүүлдэг. Бид олон моделийн хэрэгсэл бөгөөд, нээлттэй эх үүсвэртэй Python багцлагыг өгөгдлийг доорх хэрэглэмжүүдийн Трансформ болон таблицын (категорийн болон тоон) өгөгдлийг нэгтгэх болно. Бидний хэрэгслийн суурь нь Hugging Face-ийн суурилсан API-тэй сайн нэгтгэдэг. Яг л тодорхойлолт, загварын холбоотой. Энэ нь өөр олон сургалтын өмнө сургалтын загваруудыг хялбар авах боломжтой бол</abstract_mn>
      <abstract_ml>സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷയുടെ അടുത്തുള്ള പുരോഗതി സ്വാഭാവിക ഭാഷയുടെ ജോലികള്‍ക്കായി ഉപയോഗിക്കുന്ന പ്രകൃ എന്നാലും, പലതും യഥാര്‍ത്ഥ ലോക ഡാറ്റാസറ്റുകളില്‍, കൂടുതല്‍ മാറ്റങ്ങള്‍ നേരിട്ട് ട്രാന്‍സ്ഫോര്‍മാര്‍ നേരിട്ട്  ടെക്സ്റ്റും ടാബുളും (categorical and numerical) ഡേറ്ററുകളുമായി ട്രാന്‍സ്ട്രീമില്‍ പ്രയോഗങ്ങള്‍ക്ക് വേണ്ടി ട്രാന്‍സ്ഫോര്‍മാരുമായി ഒരു തുറന്ന സോ ഞങ്ങളുടെ ഉപകരണക്കിടം ഹുഗിംഗ് മുഖം നിലവിലുള്ള ഏപിഐ പോലെ ഒരുമിച്ചിരിക്കുന്നു. ടോണിക്ഷനേഷനും മോഡല്‍ ഹുബും പോലെ വ്യത്യസ്ത പരിശീ</abstract_ml>
      <abstract_pl>Ostatnie postępy w przetwarzaniu języka naturalnego doprowadziły do tego, że architektury Transformera stały się dominującym modelem stosowanym do zadań języka naturalnego. Jednak w wielu zbiorach danych świata rzeczywistego zawiera się dodatkowe modalności, których Transformer nie wykorzystuje bezpośrednio. Przedstawiamy Multimodal- Toolkit, open-source pakiet Pythona, który umożliwia włączenie danych tekstowych i tabelarnych (kategorycznych i numerycznych) z Transformerami do dalszych aplikacji. Nasz zestaw narzędzi dobrze integruje się z istniejącym interfejsem API Hugging Face, takim jak tokenizacja i centrum modelu, który umożliwia łatwe pobieranie różnych wstępnie przeszkolonych modeli.</abstract_pl>
      <abstract_sr>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu predominantni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim stvarnim svijetskim podacima, uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket otvorenog izvora Python za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformacijama za programe koji se nalaze niz stranu. Naš toolkit se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</abstract_sr>
      <abstract_ro>Progresele recente în procesarea limbajului natural au condus la arhitecturile Transformer devenind modelul predominant utilizat pentru sarcinile de limbaj natural. Cu toate acestea, în multe seturi de date din lumea reală, sunt incluse modalități suplimentare pe care Transformerul nu le utilizează direct. Vă prezentăm Multimodal- Toolkit, un pachet Python open-source pentru a încorpora text și date tabulare (categorice și numerice) cu Transformers pentru aplicații din aval. Setul nostru de instrumente se integrează bine cu API-ul existent al Hugging Face, cum ar fi tokenizarea și hub-ul modelului, care permite descărcarea ușoară a diferitelor modele pre-instruite.</abstract_ro>
      <abstract_no>Nyleg framgang i naturspråkshandtering har ført til å transformera arkitektur bli den viktigste modellen brukt for naturspråksoppgåver. I mange verdsetata er imidlertid tilleggsmodular som Transformeren ikkje direkte leverer. Vi presenterer multimodal verktøykassett, eit opna kjeldepakke for Python som inkluderer tekst og tabulatordata (kategorisk og numerisk) med Transformerer for nedstrekkprogram. Vårt verktøykassett integrerer godt med den eksisterande API til Hugging Face som tokenisering og modellhuben som tillater enkelt nedlasting av ulike føretrengde modeller.</abstract_no>
      <abstract_so>Horumarinta ugu dambeysa ee baaraandegista luqada dabiicadda ah wuxuu u keenay dhismaha wareejinta oo ay noqdaan modelkii ugu horeeya ee loo isticmaalay shaqooyinka afka dabiicadda ah. Si kastaba ha ahaatee, waxaa ku jira habab dheeraad ah oo uu turjubaanku si toos ah u isticmaalayo. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Qorigayada qalabka ayaa si wanaagsan u qabsada afka Hugging ee uu heysto API, tusaale ahaan calaamad iyo muusikada, kaas oo sahlan soo dejin kara modello kala duduwan oo horay loo tababaray.</abstract_so>
      <abstract_ta>சமீபத்தில் இயல்பான மொழி செயல்படுத்தலின் முன்னேற்றம் இயல்பான மொழி பணிகளுக்கு பயன்படுத்தப்பட்ட முக்கிய மாதிரியான ம ஆனால், பல உண்மையான- உலக தரவுத்தளங்களில், மாற்றி நேரடியாக ஒப்புக்கொள்ளாத கூடுதல் வகைகள் உள்ளன. நாங்கள் பல மூலக் கருவிப்புக்கூட்டு, ஒரு திறந்த மூலத்தின் பைதான் தொகுப்பு, உரையை மற்றும் அட்டவணை (வகையான மற்றும் எண்ணிக்கை) தகவல்களை கூட்டு எங்கள் கருவிப்பெட்டி ஹங்கிங் முகத்தில் இருக்கும் API போன்ற ஒருங்கிணைக்கும், அது வேறு முன் பயிற்சிக்கப்பட்ட மாதிரிகளின் எளிதாக</abstract_ta>
      <abstract_sv>De senaste framstegen inom bearbetningen av naturligt språk har lett till att Transformer-arkitekturer blivit den dominerande modellen som används för naturliga språkuppgifter. Men i många verkliga datauppsättningar ingår ytterligare metoder som Transformern inte direkt utnyttjar. Vi presenterar Multimodal- Toolkit, ett Python-paket med öppen källkod för att införliva text och tabelldata (kategoriska och numeriska) med Transformers för nedströms applikationer. Vår verktygslåda integreras väl med Hugging Faces befintliga API såsom tokenisering och modellhubben som gör det enkelt att ladda ner olika förintränade modeller.</abstract_sv>
      <abstract_ur>طبیعی زبان پردازی میں اچھی پیشرفت کی وجہ سے تغییر معماری بنانے کے لئے طبیعی زبان کے کاموں کے لئے استعمال کیا جاتا ہے۔ However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage. ہم ملٹی موڈال- تولکیٹ کو پیش کریں گے، ایک کھولی- سورس پیٹون پاکس کے لئے پاکستان اور ٹاکلور (کاٹی اور شماری) ڈائٹ ڈونسٹریم کاربریوں کے ساتھ تغییرات کرنے والوں کے ساتھ شامل کریں گے۔ ہماری تولیک کیٹ ہیونگ فیس کے موجود API کے ساتھ اچھی طرح تفسیر کرتی ہے جیسے ٹوکنیزی اور موڈل ہب جو مختلف پیش آموزش کی موڈلیوں کے آسان ڈونلوڈ کی اجازت دیتا ہے.</abstract_ur>
      <abstract_mt>Recent progress in natural language processing has led to Transformer architectures becoming the predominant model used for natural language tasks.  However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage.  We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications.  Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_mt>
      <abstract_si>ස්වාභාවික භාෂාව ප්‍රක්‍රියාපනයේ අන්තිම ප්‍රභාවිත විද්‍යාපනය විද්‍යාපනය කරනවා ස්වාභික භාෂා නමුත්, ඇත්ත- ලෝකයේ දත්ත සෙට් වලින්, තවත් මොඩියුල් සම්බන්ධ වෙලා තියෙන්නේ මොඩියුල් තියෙන්නේ ම Name අපේ උපකරණ කිට් හොඳටම හුගින් ෆේස්ගේ තියෙන ඉන්න API වලින් ටොකෙනිස් සහ මොඩේල් හුබ් වලින් සමහර විවිධ ප්‍රධානය කරපු</abstract_si>
      <abstract_uz>@ info: whatsthis Ammo, ko'pchilik dunyo maʼlumotlar tarkibida, Transfer toʻgʻri ishlatilmagan qoʻshimcha usullar bor. @ info: whatsthis Bizning asboblar kitoblarimiz Hugging Faceb mavjud API bilan birga birlashtiriladi. Bu model hub boshqa taʼminlovchi modellarni yozib olish imkoniyatini yordam beradi.</abstract_uz>
      <abstract_vi>Sự tiến bộ gần đây trong việc xử lý ngôn ngữ tự nhiên đã khiến các kiến trúc biến hình thành mô hình nổi bật sử dụng cho các nhiệm vụ ngôn ngữ tự nhiên. Tuy nhiên, trong nhiều bộ dữ liệu thế giới thực, có thêm phương thức mà Transformer không trực tiếp hoạt động. Chúng tôi giới thiệu các tập cụ đa phương, một gói Python mở nguồn để cung cấp các dữ liệu cấu hình (và số) dứt điểm với các biến hình cho các ứng dụng xuôi dòng. Bộ hỗ trợ của chúng ta hòa hợp tốt với API hiện có của Huging Face như tokenition và mô hình trung tâm cho phép tải tải xuống dễ dàng các mẫu đã được huấn luyện.</abstract_vi>
      <abstract_bg>Последният напредък в обработката на естествения език доведе до превръщането на архитектурите на трансформаторите в преобладаващия модел, използван за задачи с естествен език. Въпреки това, в много реални набори от данни са включени допълнителни модификации, които трансформаторът не използва пряко. Представяме Мултимодален инструментариум, пакет с отворен код за включване на текстови и таблични (категорични и цифрови) данни с трансформатори за приложения надолу по веригата. Нашият инструментариум се интегрира добре със съществуващия API като токенизация и моделния хъб, който позволява лесно изтегляне на различни предварително обучени модели.</abstract_bg>
      <abstract_hr>Nedavno napredak prirodnog obrazovanja jezika doveo je do arhitekture transformera postajući predsjednik koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne primjenjuje direktno. Predstavljamo Multimodalni Toolkit, otvoreni Python paket za uključivanje teksta i tabularnih (kategorijskih i brojnih) podataka s transformacijama za prijave za dolje. Naš alat se dobro uključuje s postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako preuzimanje različitih predobučenih modela.</abstract_hr>
      <abstract_nl>Recente vooruitgang in de verwerking van natuurlijke taal heeft ertoe geleid dat Transformer architecturen het dominante model zijn geworden voor natuurlijke taaltaken. In veel real-world datasets zijn echter aanvullende modaliteiten opgenomen die de Transformer niet direct benut. We presenteren Multimodal-Toolkit, een open-source Python pakket om tekst en tabulaire (categorische en numerieke) gegevens te integreren met Transformers voor downstream toepassingen. Onze toolkit integreert goed met Hugging Face's bestaande API, zoals tokenization en de model hub, waardoor verschillende voorgetrainde modellen eenvoudig kunnen worden gedownload.</abstract_nl>
      <abstract_da>Nylige fremskridt inden for behandling af naturligt sprog har ført til, at Transformer-arkitekturer er blevet den dominerende model, der anvendes til opgaver med naturligt sprog. Men i mange datasæt i den virkelige verden, er yderligere modaliteter inkluderet, som Transformeren ikke direkte udnytter. Vi præsenterer Multimodal-Toolkit, en open source Python pakke til at indarbejde tekst og tabel (kategoriske og numeriske) data med Transformers til downstream applikationer. Vores værktøjssæt integrerer godt med Hugging Face's eksisterende API såsom tokenisering og model hub, som gør det nemt at downloade forskellige præ-trænede modeller.</abstract_da>
      <abstract_id>Kemajuan baru-baru ini dalam proses bahasa alam telah menyebabkan arsitektur Transformer menjadi model dominan yang digunakan untuk tugas bahasa alam. Namun, dalam banyak set data dunia nyata, modalitas tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami mempersembahkan Multimodal- Toolkit, sebuah paket Python sumber terbuka untuk memasukkan teks dan data tabular (kategori dan numerik) dengan Transformers untuk aplikasi turun. Paket alat kita terintegrasi dengan API yang ada Hugging Face seperti tokenization dan model hub yang memungkinkan muat turun mudah dari model yang berlatih.</abstract_id>
      <abstract_de>Die jüngsten Fortschritte in der Verarbeitung natürlicher Sprache haben dazu geführt, dass Transformer-Architekturen das vorherrschende Modell für Aufgaben natürlicher Sprache geworden sind. In vielen realen Datensätzen sind jedoch zusätzliche Modalitäten enthalten, die der Transformer nicht direkt nutzt. Wir präsentieren Multimodal-Toolkit, ein Open-Source Python-Paket, das Text und tabellarische (kategorische und numerische) Daten mit Transformern für nachgelagerte Anwendungen integriert. Unser Toolkit lässt sich gut mit Hugging Face's bestehender API wie Tokenisierung und dem Model Hub integrieren, der einen einfachen Download verschiedener vortrainierter Modelle ermöglicht.</abstract_de>
      <abstract_sw>Maendeleo ya hivi karibuni katika upasuaji wa lugha za asili yamesababisha majengo ya Kupitisha kuwa modeli muhimu inayotumiwa kwa ajili ya kazi za lugha za asili. Hata hivyo, katika seti nyingi za taarifa za dunia halisi, mbinu za ziada zinajumuisha ambazo WaTransfer hawatumii moja kwa moja. Tunaweza kuweka kituo cha Kifaa cha Multimodal-Tool, kitengele cha Python kilicho wazi kwa ajili ya kuingiza taarifa za maandishi na tabia (makundi na tarakimu) kwa ajili ya matumizi ya mitandao ya chini. Vifaa vyetu vinaunganisha vizuri na API iliyopo Hugging Face kama vile uthibitisho na kituo cha modeli ambacho kinaruhusu kupandisha mifano tofauti ya mafunzo ya awali.</abstract_sw>
      <abstract_tr>Doýal diller işlemeginiň öňki täzelikleri tebigy diller üçin ullanýan arhitekturlary üýtgedir. Ýöne, birnäçe sanat dünýäde maglumat setirlerinde, esasy modlerde terjime etmeýän modlerde dahil edildi. Biz Multimodal-Esbap zolaky, Açyk-çeşme Python paketi metin we täblikler (kategoriýal we sayyk) maglumaty aşaky uygulamalar üçin terjime etmek üçin bir paketi görkeýäris Biziň alet çykyşlarymyz Hugging Face'iň bar API bilen gowy birleştirilýär. Öňünden öňünden bilinmiş modelleriň ýeňil ýüklemegine mümkin edýän nusgalary.</abstract_tr>
      <abstract_ko>자연 언어 처리의 최신 진전은 변환기 구조를 자연 언어 임무의 주요 모델로 만들었다.그러나 많은 실제 세계의 데이터가 집중되어 변압기가 직접적으로 이용하지 않는 다른 모델을 포함하고 있다.우리는 텍스트와 표 (분류, 디지털) 데이터를 변환기와 결합시켜 하위 응용 프로그램에 사용하는Multimodal-Toolkit을 보여 줍니다.Google 패키지는 Hugging Face의 기존 API(예를 들어 표기화)와 모델 센터(model hub)와 잘 통합되어 서로 다른 예비 트레이닝 모델을 쉽게 다운로드할 수 있습니다.</abstract_ko>
      <abstract_fa>پیشرفت اخیرا در پردازش زبان طبیعی به معماری تغییر دهنده به عنوان مدل پیشوایی که برای کار زبان طبیعی استفاده می‌شود تبدیل می‌شود. با این حال، در بسیاری از مجموعه‌های داده‌های واقعی دنیا، modalities additional include which the Transformer does not directly leverage. ما کیت multimodal- Toolkit را نشان می‌دهیم، یک بسته Python منبع باز برای شامل کردن متن و اطلاعات تبلیک (kategorical and numerical) با تغییردهندگان برای کاربردهای پایین سیستم. وسیله‌های ما با API موجود Hugging Face مثل توکین کردن و مدل‌هایی که اجازه می‌دهد آسان دانلود از مدل‌های پیش آموزش متفاوت را فراهم کند.</abstract_fa>
      <abstract_sq>Përparimi i fundit në procesimin natyror të gjuhës ka shpjerë në arkitekturat Transformer të bëhen modeli mbizotërues i përdorur për detyrat natyrore të gjuhës. Megjithatë, në shumë grupe të dhënash të botës reale, janë përfshirë modalitete shtesë që Transformuesi nuk përfshin drejtpërdrejt. Ne paraqesim Multimodal- Toolkit, një paketë Python me burim të hapur për të përfshirë tekst dhe të dhëna tabulare (kategorike dhe numerike) me Transformers për aplikimet e poshtme. Paketa jonë mjete integrohet mirë me API ekzistuese të Hugging Face si tokenization dhe model hub që lejon shkarkimin e lehtë të modeleve të ndryshme të paratrajnuara.</abstract_sq>
      <abstract_am>አዲስ የፍጥረት ቋንቋ ማቀናጃ ውስጥ የሚደረግ ግንኙነትን ለፍጥረት ቋንቋ ስራ የሚጠቀሙት መሠረት መሆኑን አቀረበ፡፡ ምንም እንኳን፣ በብዙ እውነተኛ- ዓለም ዳታዎች ውስጥ፣ በተጨማሪው ድርጅቶች በተጨማሪው ድርጅቶች ውስጥ የተገቡ ናቸው፡፡ Multimodal-Toolkit, open-source Python ጥቅል እና tabular (categorical and numerical) data with Transformers for downstream applications ለማግባት ነው፡፡ የመልኮታችን መሣሪያዎች የHugging ፊታችንን እንደምሳሌ ማስታወቂያ እና የሞዴል ክፍል በተለየ የፊደል ሞዴላዎችን ማውረድ የሚያስቀላል ነው፡፡</abstract_am>
      <abstract_af>Onlangse vordering in natuurlike taal-prosessering het gelei na Transformer-arkitekturke wat die voordekende model gebruik word vir natuurlike taal-taak. Alhoewel, in baie reël- wêreld datastelle, is addisionele modaliteite ingesluit wat die Transformer nie direk verwyder nie. Ons voorsien Multimodal- Nutsbalk, 'n oop- bron Python pakket om teks en tabulêer (kategoriese en numeriese) data te inkorpreer met Transformers vir onderstreem toepassings. Ons nutsbalkit integreer goed met Hugging Face se bestaande API soos tokenisasie en die model hub wat maklik laat af van verskillende voorafoerende modele toe.</abstract_af>
      <abstract_az>Təbiətli dil işləməsində son tədbir tədbir edilməsi təbiətli dil işləri üçün istifadə edilən təbiətli modellərə çevrildi. Ancaq bir çox real dünya verilən qurğularında, Transformer'in düzgün istifadə etmədiyi papildu modüllər daxil edilir. Biz çoxlu-modal-araç çubuğunu, aşağı-aşağı proqramlar üçün Transformers üçün metin və tabular (kategorik və numerik) məlumatları birləşdirmək üçün açıq-kaynak Python paketini göstəririk. Bizim vasitələrimiz Hugging Face'in mövcuddur API ilə yaxşı birləşdirir, çünki tokenizasyon və modeli hub kimi, farklı əvvəlcə təhsil edilmiş modellərin asanlıqlarını indirməyə imkan verir.</abstract_az>
      <abstract_hy>Վերջերս բնական լեզուների վերաբերյալ զարգացումը հանգեցրեց, որ տրանսֆերմերի ճարտարապետությունները դառնան բնական լեզուների խնդիրների համար օգտագործվող գլխավոր մոդելը: Այնուամենայնիվ, շատ իրական աշխարհի տվյալների համակարգերում ներառված են ավելացյալ մեթոդներ, որոնք Transforme-ը անմիջապես չի ազդում: Մենք ներկայացնում ենք Բազմամոդալ-Գործիքների համակարգ, բաց աղբյուր Պիթոն փաթեթ, որը ներառում է տեքստի և տախտային (կատեգորիկական և թվային) տվյալներ Transforme-ների հետ հետագա ծրագրերի համար: Մեր գործիքների շարքը լավ ինտեգրվում է Հուգինգ Ֆեյսի գոյություն ունեցող API-ի հետ, ինչպիսիք են թոկենիզացիան և մոդելի կենտրոնը, որը հնարավորություն է տալիս հեշտ ներբեռնել տարբեր նախապատրաստված մոդելներ:</abstract_hy>
      <abstract_bn>প্রাকৃতিক ভাষা প্রক্রিয়ায় সাম্প্রতিক অগ্রগতি প্রাকৃতিক ভাষার কাজের জন্য ব্যবহৃত প্রাকৃতিক ভাষার কাজের জন্য তবে অনেক বাস্তব-বিশ্বের তথ্য সেটে, যার মধ্যে অন্তর্ভুক্ত বৈষম্য রয়েছে যার মধ্যে ট্রান্সফার্নার নির্দেশ দেয় টেক্সট এবং ট্যাবুল (ক্যাটারেক্টারিক্যাল এবং সংখ্যা) ডাটার অন্তর্ভুক্ত করার জন্য আমরা মাল্টিমোডাল- টুলিকিট, একটি খোলা সোর্স পাইথন আমাদের টুলিকিট হুগিং মুখের বিদ্যমান এপিআই-এর সাথে ভালোভাবে একত্রিত করেছে, যেমন চিহ্নিত বিভিন্ন প্রশিক্ষিত মডেলের সহজে ডাউনলোড</abstract_bn>
      <abstract_bs>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu glavni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket Python otvorenog izvora za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformatorima za programe za snimke. Naš alat se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</abstract_bs>
      <abstract_ca>El progrés recent en el processament natural de llenguatges ha portat a que les arquitectures Transformer es converteixin en el model predominant utilitzat per a tasques de llenguatges naturals. No obstant això, en molts conjunts de dades del món real, s'inclouen modalitats adicionals que el Transformer no utilitza directament. Presentam Multimodal-Toolkit, un paquet de Python de codi obert per incorporar text i dades tabulars (categóriques i numèriques) amb Transformers per aplicacions avall. El nostre conjunt d'eines s'integra bé amb l'API existent d'Hugging Face, com la tocenització i el centre model que permet descarregar fàcilment diferents models pré-entrenats.</abstract_ca>
      <abstract_cs>Nedávný pokrok ve zpracování přirozeného jazyka vedl k tomu, že architektury Transformer se staly dominantním modelem používaným pro úlohy přirozeného jazyka. Nicméně v mnoha skutečných datových sadách jsou zahrnuty další modality, které Transformer přímo nevyužívá. Představujeme Multimodal- Toolkit, open-source Python balíček pro začlenění textových a tabulkových (kategorických a číselných) dat s transformátory pro následné aplikace. Náš nástroj se dobře integruje s existujícím API Hugging Face, jako je tokenizace a modelový hub, který umožňuje snadné stahování různých předškolených modelů.</abstract_cs>
      <abstract_et>Hiljutised edusammud looduskeele töötlemisel on viinud Transformeri arhitektuuride muutumiseni peamiseks mudeliks, mida kasutatakse looduskeele ülesannetes. Paljudes reaalmaailma andmekogumites on siiski lisatud täiendavad meetodid, mida Transformer otseselt ei kasuta. Esitleme Multimodal- Toolkit, avatud lähtekoodiga Pythoni paketti, mis sisaldab teksti- ja tabeliandmeid (kategoorialised ja numbrilised) Transformeritega alljärgnevate rakenduste jaoks. Meie tööriistakomplekt integreerub hästi Hugging Face olemasoleva API-ga, nagu tokeniseerimine ja mudeli hub, mis võimaldab lihtsalt alla laadida erinevaid eeltreenitud mudeleid.</abstract_et>
      <abstract_fi>Luonnonkielen käsittelyn viimeaikainen kehitys on johtanut siihen, että Transformer-arkkitehtuurista on tullut luonnollisissa kielitehtävissä vallitseva malli. Moniin reaalimaailman datakokonaisuuksiin sisältyy kuitenkin muita menetelmiä, joita muuntaja ei suoraan hyödynnä. Esittelemme Multimodal- Toolkit, avoimen lähdekoodin Python-paketin, joka sisältää teksti- ja taulukkotietoja (kategorinen ja numeerinen) Transformers-ohjelmistojen kanssa jatko-sovelluksiin. Työkalupakkimme integroituu hyvin Hugging Facen olemassa olevaan API-rajapintaan, kuten tokenisointiin ja mallikeskukseen, joka mahdollistaa erilaisten esikoulutettujen mallien helpon lataamisen.</abstract_fi>
      <abstract_sk>Nedavni napredek pri obdelavi naravnega jezika je pripeljal do tega, da so arhitekture transformatorjev postale prevladujoči model, ki se uporablja za naloge naravnega jezika. Vendar pa so v številnih resničnih zbirkah podatkov vključene dodatne načine, ki jih transformator ne uporablja neposredno. Predstavljamo Multimodal- Toolkit, odprtokodni paket Python, ki vključuje besedilo in tabularne (kategorične in numerične) podatke s transformatorji za nadaljnje aplikacije. Naš komplet orodij se dobro integrira z obstoječim API-jem Hugging Face, kot sta žetonizacija in vozlišče modela, ki omogoča enostaven prenos različnih predhodno usposobljenih modelov.</abstract_sk>
      <abstract_jv>FindOK politenessoffpolite"), and when there is a change ("assertivepoliteness We present Multimodal- Tool lkit, an open-source Arkit-tool sing ditambah gambaran karo Api yang saben nggawe, lagi tokenizer karo model</abstract_jv>
      <abstract_ha>@ info: whatsthis Amma, cikin masu yawa na danna-duniya masu gaske, akwai wasu shiryoyin dabam da Transformer bã ya gaurar da hanya. Tuna halatar da Shirin Ayuka na Kwamfyuta Tsarin kayan aiki na sami da shirin Hugging Face na da ke gaba kamar shirin ayuka da kwamfyutan ayuka da ke yarda da download masu motsi na daban-danne.</abstract_ha>
      <abstract_fil>Ang mga bagong progreso sa natural language processing ay nagdala ng mga Transformer architectures na naging pangunahing model na ginagamit para sa natural language tasks. Gayon ma'y sa maraming talagang datasets ng mundo, ang mga bagong modalitate ay nagkakasama na hindi direktang leverage ng Transformer. Nagbibigay kami ng Multimodal-Toolkit, isang open-source Python package upang magkasama ng text at tabular (kategorical at numerical) data na may Transformers para sa downstream applications. Ang toolkit namin ay nagkakasama ng mabuti sa mga API na nagkakaroon ng Hugging Face, tulad sa tokenization at ang model hub na nagpapahintulot ng magandang download ng ibang pre-trained model s.</abstract_fil>
      <abstract_bo>རང་བཞིན་གྱི་སྐད་རིགས་ལས་སྦྱོར་བའི་འཕེལ་རིམ་དེ་ནི་བཟོ་བཅོས་ཁང་གཟུགས་རིས་ལ་མཐུན་ནུས་མེད་པའི་རྣམ་གྲངས་སྤ ཡིན་ནའང་། ངོ་མ་འཛམ་གླིང་ཡོད་པའི་གནས་ཚུལ་སྒྲིག་འགོད་མང་པོ་ཞིག་ལ་བཟོ་བཅོས་བྱེད་སྣང་བའི་ཐབས་ལམ་ཁྱབ་སྤྱོད་ We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</abstract_bo>
      <abstract_he>התקדמות האחרונה בעבודת שפת טבעית הובילה לארכיטקטורות טרנספורטר להפוך למודל הכי גדול שמשתמש למשימות שפת טבעיות. בכל אופן, במערכות נתונים רבות בעולם האמיתי, מודליות נוספות כוללות שהטרנספורטר לא משתמש באופן ישיר. אנחנו מציגים ערכת כלים מורכבת, חבילה Python מקור פתוח כדי לכלול טקסט ומידע טבלה (קטגורית ומספרית) עם Transformers לתוכניות מתחתיות. חבילת הכלים שלנו משתלבת היטב עם API הקיום של Hugging Face כמו tokenization והמרכז המודל שמאפשר להוריד בקלות של דוגמנים מאומנים מראש.</abstract_he>
      </paper>
    <paper id="13">
      <title>Learning to Select Question-Relevant Relations for Visual Question Answering</title>
      <author><first>Jaewoong</first><last>Lee</last></author>
      <author><first>Heejoon</first><last>Lee</last></author>
      <author><first>Hwanhee</first><last>Lee</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>87–96</pages>
      <abstract>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations. However, studies that use GNNs typically ignore the importance of each relation and simply concatenate outputs from multiple relation encoders. In this paper, we propose a novel layer architecture that fuses multiple visual relations through an attention mechanism to address this issue. Specifically, we develop a model that uses question embedding and joint embedding of the encoders to obtain dynamic attention weights with regard to the type of questions. Using the learnable attention weights, the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can efficiently use the necessary visual relation features for a given question. Experimental results on the VQA 2.0 dataset demonstrate that the proposed model outperforms existing graph attention network-based architectures. Additionally, we visualize the attention weight and show that the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> assigns a higher weight to relations that are more relevant to the question.</abstract>
      <url hash="e2e33677">2021.maiworkshop-1.13</url>
      <doi>10.18653/v1/2021.maiworkshop-1.13</doi>
      <bibkey>lee-etal-2021-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering-v2-0">Visual Question Answering v2.0</pwcdataset>
    <title_ar>تعلم تحديد العلاقات ذات الصلة بالسؤال للإجابة المرئية على الأسئلة</title_ar>
      <title_es>Aprender a seleccionar relaciones relevantes para las preguntas para la respuesta visual a las preguntas</title_es>
      <title_pt>Aprendendo a selecionar relações relevantes para perguntas para respostas visuais a perguntas</title_pt>
      <title_fr>Apprendre à sélectionner les relations pertinentes aux questions pour répondre visuellement aux questions</title_fr>
      <title_ja>視覚的な質問への回答のための質問関連の関係を選択する方法を学ぶ</title_ja>
      <title_hi>दृश्य प्रश्न उत्तर देने के लिए प्रश्न-प्रासंगिक संबंधों का चयन करना सीखना</title_hi>
      <title_zh>学者,所以视问也</title_zh>
      <title_ru>Учимся выбирать отношения, имеющие отношение к вопросу, для визуального ответа на вопрос</title_ru>
      <title_ukr>Навчання вибору відповідних відносин для візуальної відповіді на запитання</title_ukr>
      <title_ga>Ag Foghlaim conas Ceist-Caidreamh Ábhartha a Roghnú le hAmharc-Fhreagar Ceist</title_ga>
      <title_ka>ვიზუალური კითხვის პასუხისთვის შესაბამისათვის კითხვის შესაბამისათვის შესაბამისათვის</title_ka>
      <title_hu>Kérdések-releváns kapcsolatok kiválasztásának tanulása vizuális kérdések megválaszolásához</title_hu>
      <title_el>Μάθετε να επιλέγετε σχετικές σχέσεις ερωτήσεων για οπτική απάντηση ερωτήσεων</title_el>
      <title_isl>Að læra að velja spurningalega tengsl við sjónsvörun</title_isl>
      <title_it>Imparare a selezionare le relazioni rilevanti per la risposta visiva alle domande</title_it>
      <title_kk>Көрінетін сұрақтар жауап беру үшін сұрақтардың қатынасын таңдау үйрену</title_kk>
      <title_lt>Mokymasis pasirinkti klausimus atitinkančius santykius atsakant į vizualius klausimus</title_lt>
      <title_ms>Belajar untuk Pilih Hubungan Berkaitan soalan untuk Jawapan soalan Visual</title_ms>
      <title_mk>Научи да избереш врски поврзани со прашањата за одговор на визуелни прашања</title_mk>
      <title_mt>Tagħlim biex jintgħażel Relazzjonijiet Relevanti għall-Mistoqsijiet għat-tweġibiet għall-Mistoqsijiet Viżwali</title_mt>
      <title_ml>കാഴ്ചയുള്ള ചോദ്യം ഉത്തരം നല്‍കുന്നതിനുള്ള ചോദ്യങ്ങള്‍ തെരഞ്ഞെടുക്കാന്‍ പഠിക്കുന്നു</title_ml>
      <title_ro>Învățarea de a selecta relațiile relevante pentru întrebări vizuale</title_ro>
      <title_mn>Хариулт асуултын хариултын тулд асуулт-хамааралтай харилцаа сонгох суралцах</title_mn>
      <title_no>Læring å velja spørsmålsrelasjonar for visuelle spørsmålssvar</title_no>
      <title_pl>Nauka wybierania relacji związanych z pytaniami do wizualnego odpowiadania na pytania</title_pl>
      <title_si>ප්‍රශ්න- සම්බන්ධ සම්බන්ධතාවක් තෝරාගන්න ඉගෙනගන්න</title_si>
      <title_sr>Naučenje izabrati veze sa pitanjem za odgovor na vizuelno pitanje</title_sr>
      <title_so>Waxbarashada doorashada su'aalaha la xiriira su'aalaha aragtida</title_so>
      <title_sv>Lär dig att välja frågerelevanta relationer för visuell frågebesvarande</title_sv>
      <title_ta>காட்சி கேள்வி பதில் கேள்வி தொடர்புகளை தேர்ந்தெடுக்கவும்</title_ta>
      <title_ur>سؤال-رابطہ انتخاب کرنے کے لئے سیکھنا</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Học cách đặt câu hỏi liên quan tới câu hỏi ảo</title_vi>
      <title_hr>Naučenje izabrati veze s pitanjem za odgovor na vizuelno pitanje</title_hr>
      <title_nl>Leren vraagrelevante relaties te selecteren voor visueel antwoord op vragen</title_nl>
      <title_id>Belajar untuk memilih hubungan Relevan Pertanyaan untuk Jawaban Pertanyaan Visual</title_id>
      <title_ko>학습 선택과 문제와 관련된 관계를 가시화 문답으로 진행하다</title_ko>
      <title_da>Lære at vælge spørgsmål-relevante relationer til visuel spørgsmål besvarelse</title_da>
      <title_bg>Научете се да избирате релевантни отношения за визуално отговаряне на въпроси</title_bg>
      <title_fa>یاد گرفتن برای انتخاب رابطه‌های مربوط به سوال‌ها برای جواب سوال‌های بینایی</title_fa>
      <title_de>Lernen, Fragen-relevante Beziehungen für die visuelle Beantwortung von Fragen auszuwählen</title_de>
      <title_sw>Kujifunza kuchagua mahusiano yanayohusiana na swali la Visual Answering</title_sw>
      <title_tr>Görsel soragy jogaplamak üçin soraglary seçmek üçin öwrenmek</title_tr>
      <title_af>Leer na Kies Fraag- Relevant Relasies vir Visuele Fraag Antwoord</title_af>
      <title_hy>Սովորել ընտրել հարցերի հարաբերություններ տեսողական հարցերի պատասխանելու համար</title_hy>
      <title_sq>Mësimi për të zgjedhur marrëdhëniet lidhur me pyetjet për përgjigjet vizuale të pyetjeve</title_sq>
      <title_az>Görünül sual cavabı üçün sual-bağlı ilişkileri seçmək öyrənmək</title_az>
      <title_bn>দৃশ্যমান প্রশ্নের উত্তরের জন্য প্রশ্ন- সম্পর্ক নির্বাচন করতে শিখা হচ্ছে</title_bn>
      <title_am>ምርጫ</title_am>
      <title_ca>Aprendre a seleccionar relacions relacionades amb preguntes per respondre a preguntes visuals</title_ca>
      <title_cs>Naučení se vybrat vztahy relevantní pro otázky pro vizuální zodpovězení otázek</title_cs>
      <title_fi>Oppiminen valitsemaan kysymyksiä koskevat suhteet visuaaliseen kysymykseen vastaamiseen</title_fi>
      <title_et>Õppimine valida küsimustele vastavad suhted visuaalsetele küsimustele vastamiseks</title_et>
      <title_bs>Naučenje izabrati veze s pitanjem za odgovor na vizuelno pitanje</title_bs>
      <title_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness</title_jv>
      <title_sk>Učenje izbire odnosov na vprašanja za vizualno odgovarjanje na vprašanja</title_sk>
      <title_he>Learning to Select Question-Relevant Relations for Visual Question Answering</title_he>
      <title_fil>Nagtuturo ng pagpili ng mga relasyon sa tanong-Relevant para sa pagsagot ng visual Question</title_fil>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>མཐོང་ནུས་གནས་ཚུལ་ལ་མཐུན་དང་གདོང་ལེན་པའི་དྲི་ཚུལ་དང་འབྲེལ་བ་འདེམས་པ</title_bo>
      <abstract_ar>عادةً ما تستخدم أنظمة الإجابة على الأسئلة المرئية (VQA) الموجودة سابقًا الشبكات العصبية للرسم البياني (GNNs) لاستخراج العلاقات المرئية مثل العلاقات الدلالية أو العلاقات المكانية. ومع ذلك ، فإن الدراسات التي تستخدم GNNs تتجاهل عادةً أهمية كل علاقة وتقوم ببساطة بتسلسل المخرجات من ترميز علاقات متعددة. في هذه الورقة ، نقترح بنية طبقة جديدة تدمج العلاقات المرئية المتعددة من خلال آلية الانتباه لمعالجة هذه المشكلة. على وجه التحديد ، نقوم بتطوير نموذج يستخدم تضمين الأسئلة والتضمين المشترك للمشفرات للحصول على أوزان انتباه ديناميكية فيما يتعلق بنوع الأسئلة. باستخدام أوزان الانتباه القابلة للتعلم ، يمكن للنموذج المقترح استخدام ميزات العلاقة المرئية اللازمة لسؤال معين بكفاءة. توضح النتائج التجريبية على مجموعة بيانات VQA 2.0 أن النموذج المقترح يتفوق في الأداء على البنى القائمة على الشبكة القائمة على الاهتمام بالرسم البياني. بالإضافة إلى ذلك ، فإننا نتخيل وزن الانتباه ونبين أن النموذج المقترح يعطي وزناً أكبر للعلاقات الأكثر صلة بالسؤال.</abstract_ar>
      <abstract_fr>Les anciens systèmes de réponse visuelle aux questions (VQA) existants utilisent couramment des réseaux de neurones graphiques (GNN) pour extraire des relations visuelles telles que des relations sémantiques ou des relations spatiales. Cependant, les études qui utilisent des GNN ignorent généralement l'importance de chaque relation et concaténent simplement les sorties de plusieurs codeurs de relations. Dans cet article, nous proposons une nouvelle architecture de couches qui fusionne de multiples relations visuelles grâce à un mécanisme d'attention pour résoudre ce problème. Plus précisément, nous développons un modèle qui utilise l'intégration de questions et l'intégration conjointe des codeurs pour obtenir des poids d'attention dynamiques en fonction du type de questions. En utilisant les pondérations d'attention apprises, le modèle proposé peut utiliser efficacement les caractéristiques de relation visuelle nécessaires pour une question donnée. Les résultats expérimentaux sur l'ensemble de données VQA 2.0 démontrent que le modèle proposé surpasse les architectures basées sur le réseau d'attention graphique existantes. De plus, nous visualisons le poids de l'attention et montrons que le modèle proposé attribue un poids plus élevé aux relations plus pertinentes par rapport à la question.</abstract_fr>
      <abstract_es>Los sistemas de respuesta visual a preguntas (VQA) existentes anteriormente comúnmente utilizan redes neuronales gráficas (GNN) para extraer relaciones visuales, como relaciones semánticas o relaciones espaciales. Sin embargo, los estudios que utilizan GNN normalmente ignoran la importancia de cada relación y simplemente concatenan las salidas de múltiples codificadores de relación. En este artículo, proponemos una arquitectura de capas novedosa que fusiona múltiples relaciones visuales a través de un mecanismo de atención para abordar este problema. Específicamente, desarrollamos un modelo que utiliza la incrustación de preguntas y la incrustación conjunta de los codificadores para obtener pesos de atención dinámicos con respecto al tipo de preguntas. Al usar los pesos de atención aprendibles, el modelo propuesto puede usar de manera eficiente las características de relación visual necesarias para una pregunta determinada. Los resultados experimentales en el conjunto de datos de VQA 2.0 demuestran que el modelo propuesto supera a las arquitecturas existentes basadas en redes de atención gráfica. Además, visualizamos el peso de la atención y mostramos que el modelo propuesto asigna un mayor peso a las relaciones que son más relevantes para la pregunta.</abstract_es>
      <abstract_pt>Os sistemas de resposta visual a perguntas (VQA) existentes anteriormente geralmente usam redes neurais gráficas (GNNs) para extrair relações visuais, como relações semânticas ou relações espaciais. No entanto, estudos que usam GNNs normalmente ignoram a importância de cada relação e simplesmente concatenam saídas de vários codificadores de relação. Neste artigo, propomos uma nova arquitetura de camadas que funde múltiplas relações visuais por meio de um mecanismo de atenção para resolver esse problema. Especificamente, desenvolvemos um modelo que usa a incorporação de perguntas e a incorporação conjunta dos codificadores para obter pesos dinâmicos de atenção em relação ao tipo de perguntas. Usando os pesos de atenção apreensíveis, o modelo proposto pode usar eficientemente os recursos de relação visual necessários para uma determinada questão. Resultados experimentais no conjunto de dados VQA 2.0 demonstram que o modelo proposto supera as arquiteturas baseadas em rede de atenção de grafos existentes. Além disso, visualizamos o peso da atenção e mostramos que o modelo proposto atribui um peso maior às relações mais relevantes para a questão.</abstract_pt>
      <abstract_ja>以前の既存の視覚的質問応答（ ＶＱＡ ）システムは、意味関係または空間関係などの視覚的関係を抽出するためにグラフニューラルネットワーク（ ＧＮＮ ）を一般的に使用する。 しかしながら、GNNを使用する研究は、通常、各関係の重要性を無視し、単に複数の関係エンコーダからの出力を連結する。 本稿では、この問題に対処するための注意メカニズムを通じて、複数の視覚的関係を融合させた新規の層アーキテクチャを提案する。 具体的には、質問の種類に関する動的な注意重みを得るために、質問の埋め込みとエンコーダの関節の埋め込みを使用するモデルを開発します。 学習可能な注意重みを使用して、提案されたモデルは、与えられた質問に必要な視覚的関係機能を効率的に使用することができる。 VQA 2.0データセットの実験結果は、提案されたモデルが既存のグラフ注意ネットワークベースのアーキテクチャよりも優れていることを示しています。 さらに、注意の重みを視覚化し、提案されたモデルが質問に関連する関係により高い重みを割り当てることを示します。</abstract_ja>
      <abstract_zh>旧见视问答(VQA)系统常用图神经网络(GNN)以取视觉,如语义空间。 然用GNN之论,率忽于重要,而连络编码器输。 于本文中,发新架构,以意机融合为解。 具体来说发一模,嵌编码器以得其权。 用可学之权重,立形之用给定视之大者也。 VQA 2.0数集之实验结果表明,宜优于今之网络架构。 此外可视化注意权重,明分轻重也。</abstract_zh>
      <abstract_ru>Предыдущие существующие системы ответов на визуальные вопросы (VQA) обычно используют нейронные сети графов (GNN) для извлечения визуальных отношений, таких как семантические отношения или пространственные отношения. Тем не менее, исследования, в которых используются GNN, обычно игнорируют важность каждого отношения и просто объединяют выходы нескольких кодеров отношений. В этой статье мы предлагаем новую архитектуру слоя, которая объединяет несколько визуальных отношений через механизм внимания для решения этой проблемы. В частности, мы разрабатываем модель, которая использует встраивание вопросов и совместное встраивание кодеров для получения динамических весов внимания в отношении типа вопросов. Используя изучаемые веса внимания, предлагаемая модель может эффективно использовать необходимые визуальные признаки отношения для заданного вопроса. Экспериментальные результаты по набору данных VQA 2.0 показывают, что предлагаемая модель превосходит существующие сетевые архитектуры на основе графа внимания. Кроме того, мы визуализируем вес внимания и показываем, что предлагаемая модель придает больший вес отношениям, которые более актуальны для вопроса.</abstract_ru>
      <abstract_hi>पिछले मौजूदा दृश्य प्रश्न उत्तर (वीक्यूए) सिस्टम आमतौर पर ग्राफ न्यूरल नेटवर्क (जीएनएन) का उपयोग दृश्य संबंधों जैसे शब्दार्थ संबंधों या स्थानिक संबंधों को निकालने के लिए करते हैं। हालांकि, जीएनएन का उपयोग करने वाले अध्ययन आमतौर पर प्रत्येक संबंध के महत्व को अनदेखा करते हैं और बस कई संबंध एनकोडर से आउटपुट को संयोजित करते हैं। इस पेपर में, हम एक उपन्यास परत वास्तुकला का प्रस्ताव करते हैं जो इस मुद्दे को संबोधित करने के लिए एक ध्यान तंत्र के माध्यम से कई दृश्य संबंधों को फ्यूज करता है। विशेष रूप से, हम एक मॉडल विकसित करते हैं जो प्रश्नों के प्रकार के संबंध में गतिशील ध्यान वजन प्राप्त करने के लिए एनकोडर के प्रश्न एम्बेडिंग और संयुक्त एम्बेडिंग का उपयोग करता है। सीखने योग्य ध्यान वजन का उपयोग करते हुए, प्रस्तावित मॉडल किसी दिए गए प्रश्न के लिए आवश्यक दृश्य संबंध सुविधाओं का कुशलतापूर्वक उपयोग कर सकता है। VQA 2.0 डेटासेट पर प्रयोगात्मक परिणाम प्रदर्शित करते हैं कि प्रस्तावित मॉडल मौजूदा ग्राफ़ ध्यान नेटवर्क-आधारित आर्किटेक्चर को बेहतर बनाता है। इसके अतिरिक्त, हम ध्यान वजन की कल्पना करते हैं और दिखाते हैं कि प्रस्तावित मॉडल उन संबंधों को उच्च वजन प्रदान करता है जो प्रश्न के लिए अधिक प्रासंगिक हैं।</abstract_hi>
      <abstract_ukr>Попередні існуючі системи відповідей на візуальні запитання (VQA) зазвичай використовують графічні нейронні мережі(GNN) для добування візуальних зв 'язків, таких як семантичні зв' язки або просторові зв 'язки. Однак дослідження, які використовують GNN, зазвичай ігнорують важливість кожного відношення і просто об 'єднують виходи з декількох кодерів відношень. У цій роботі ми пропонуємо нову архітектуру шарів, яка поєднує кілька візуальних зв 'язків через механізм уваги для вирішення цієї проблеми. Зокрема, ми розробляємо модель, яка використовує вбудовування питань та спільне вбудовування кодувальників для отримання динамічних ваг уваги щодо типу питань. Використовуючи вивчені ваги уваги, запропонована модель може ефективно використовувати необхідні особливості візуального відношення для даного питання. Експериментальні результати на наборі даних VQA 2.0 демонструють, що запропонована модель перевершує існуючі мережеві архітектури з графічною увагою. Крім того, ми візуалізуємо вагу уваги та показуємо, що запропонована модель надає більшої ваги відносинам, які є більш релевантними до питання.</abstract_ukr>
      <abstract_ga>Úsáideann córais físfhreagartha ceisteanna (VQA) a bhí ann roimhe seo go minic líonraí néaracha graif (GNNanna) chun gaolmhaireachtaí amhairc a bhaint amach mar chaidreamh séimeantach nó caidreamh spásúil. Mar sin féin, tugann staidéir a úsáideann GNNanna neamhaird ar thábhacht gach gaolta agus ní dhéanann siad ach aschuir ó ionchódóirí caidrimh iolracha a chomhcheangal. Sa pháipéar seo, molaimid ailtireacht ciseal nua a chomhcheanglaíonn caidreamh ilamhairc trí mheicníocht aird chun aghaidh a thabhairt ar an tsaincheist seo. Go sonrach, forbraímid samhail a úsáideann leabú ceisteanna agus leabú comhpháirteach na n-ionchódóirí chun meáchain aird dinimiciúil a fháil maidir leis na cineálacha ceisteanna. Trí úsáid a bhaint as na meáchain aird infhoghlama, is féidir leis an tsamhail mholta na gnéithe coibhneasa amhairc is gá do cheist ar leith a úsáid go héifeachtach. Léiríonn torthaí turgnamhacha ar thacar sonraí VQA 2.0 go sáraíonn an tsamhail atá beartaithe na hailtireachtaí líonra-bhunaithe aird ghraif atá ann cheana féin. Ina theannta sin, léirímid an aird-mheáchan agus léirímid go sannann an tsamhail mholta meáchan níos airde do chaidreamh atá níos ábhartha don cheist.</abstract_ga>
      <abstract_ka>პირველი ვიზუალური კითხვების პასუხი (VQA) სისტემები უბრალოდ გამოყენება გრაფის ნეიროლური ქსელები (GNNs) ვიზუალური პირობები, როგორც სმენტიკური პირობები ან სისტე მაგრამ, კვლევები, რომლებიც GNN გამოყენებენ, ყოველ კავშირების მნიშვნელობას და მხოლოდ მნიშვნელობის შემდეგი შემდეგი შემდეგი შემდეგი შემდეგი კოდერებ ამ დომენტში, ჩვენ ახალგაზრდებით ახალგაზრუქტური აქტიქტურა, რომელიც მრავალ ვიზუალური შესახებების გამოყენება ამ პრობლემენტის შესახებ. განსაკუთრებით, ჩვენ განვითარებთ მოდელი, რომელიც კითხვების შეყვარება და კოდერების ერთადერთი შეყვარება გამოყენება, რომ დავიღოთ დინამიკური ინტერფექციის სიმაღლე, რომელი შესწავლებელი ინტერქციის სიმაღლეების გამოყენება მოდელეც შეუძლია ეფექტიურად გამოიყენოთ საჭირო ვიზუალური დაკავშირების სიმაღლეები. VQA 2.0 მონაცემების მონაცემების გამოცემების შედეგი გამოჩვენება, რომ მონაცემები მოდელედ არსებობს მიმდინარე გრაფიკური მონაცემები ქსელის აკტერქ დამატებით, ჩვენ ვიუზუალურებთ ინტერნეციის სიმაღლე და ჩვენ აჩვენებთ, რომ მოდელის მოდელის უფრო მეტი სიმაღლე კითხვაზე უფრო მნიშვნელოვანია.</abstract_ka>
      <abstract_hu>A korábbi vizuális kérdésre válaszoló (VQA) rendszerek általában gráf neurális hálózatokat (GNN-eket) használnak vizuális kapcsolatok kivonására, mint például szemantikai kapcsolatok vagy térbeli kapcsolatok. A GNN-eket használó tanulmányok azonban általában figyelmen kívül hagyják az egyes kapcsolatok fontosságát, és egyszerűen összekapcsolják a többféle kapcsolatú kódolók kimeneteit. Ebben a tanulmányban egy új rétegarchitektúrát javasolunk, amely egy figyelemmechanizmus segítségével ötvözi a többféle vizuális kapcsolatokat a probléma megoldására. Konkrétan olyan modellt fejlesztünk ki, amely kérdésbeágyazást és közös beágyazást használ a kódolók dinamikus figyelem súlyához a kérdések típusát illetően. A tanulható figyelemsúlyok felhasználásával a javasolt modell hatékonyan használhatja az adott kérdéshez szükséges vizuális kapcsolat funkciókat. A VQA 2.0 adatkészleten végzett kísérleti eredmények azt mutatják, hogy a javasolt modell felülmúlja a meglévő grafikonfigyelem hálózati architektúrákat. Továbbá vizualizáljuk a figyelem súlyát, és megmutatjuk, hogy a javasolt modell nagyobb súlyt tulajdonít a kérdés szempontjából relevánsabb kapcsolatoknak.</abstract_hu>
      <abstract_isl>Fyrri sjónsvörunarkerfi (VQA) sem eru til staðar eru algengt að nota graftaugakerfi (graph neural network(GNNs)) til að draga úr sjóntengslum svo sem sjóntengslum eða geimstengslum. Hins vegar hafa rannsóknir sem nota GNN venjulega hunsað mikilvægi hvers sambands og einfaldlega sameina útganga úr mörgum sambandskóðum. Í ūessu pappíri leggjum viđ fram nũja lagaarkitektur sem tengir mörg sjķnvarpstengsl gegnum athyglisbúnađ til a đ ræđa ūetta mál. Sérstaklega þróum við líkani sem notar spurningar og samsett innsetningu kóðanna til a ð fá hreyfilega athyglisþyngd hvað varðar tegund spurninga. Með því a ð nota athyglisþyngd sem hægt er að læra getur fyrirhuguð líkani notað nauðsynlegar sjónsambandseiginleikar fyrir ákveðina spurningu. Rannsóknarniðurstöður á VQA 2.0 gagnagrunni sýna að fyrirhuguð líkani er meiri en fyrirhuguð gerð sem byggir á gróðum athygli netsins. Auk þess sýnum við athyglisþyngd og sýnum a ð fyrirhuguð líkani gefur meiri þyngd tengslum sem skipta meira máli við spurninguna.</abstract_isl>
      <abstract_it>I precedenti sistemi di risposta visiva alle domande (VQA) utilizzano comunemente reti neurali grafiche (GNN) per estrarre relazioni visive come relazioni semantiche o relazioni spaziali. Tuttavia, gli studi che utilizzano GNN in genere ignorano l'importanza di ogni relazione e concatenano semplicemente le uscite da encoder di relazione multipla. In questo articolo, proponiamo una nuova architettura di layer che fonde molteplici relazioni visive attraverso un meccanismo di attenzione per affrontare questo problema. Nello specifico, sviluppiamo un modello che utilizza l'embedding delle domande e l'embedding congiunto degli encoder per ottenere pesi di attenzione dinamici rispetto al tipo di domande. Utilizzando i pesi di attenzione imparabili, il modello proposto può utilizzare in modo efficiente le caratteristiche di relazione visiva necessarie per una data domanda. I risultati sperimentali sul set di dati VQA 2.0 dimostrano che il modello proposto supera le architetture basate sulla rete di attenzione dei grafici esistenti. Inoltre, visualizziamo il peso dell'attenzione e mostriamo che il modello proposto assegna un peso maggiore alle relazioni che sono più rilevanti per la domanda.</abstract_it>
      <abstract_el>Τα προηγούμενα υπάρχοντα συστήματα οπτικής απάντησης ερωτήσεων χρησιμοποιούν συνήθως νευρωνικά δίκτυα γραφήματος (GNN) για την εξαγωγή οπτικών σχέσεων όπως σημασιολογικές σχέσεις ή χωρικές σχέσεις. Ωστόσο, μελέτες που χρησιμοποιούν συνήθως αγνοούν τη σημασία της κάθε σχέσης και απλά ενώνουν τις εξόδους από πολλαπλούς κωδικοποιητές σχέσεων. Στην παρούσα εργασία, προτείνουμε μια νέα αρχιτεκτονική στρώματος που ενώνει πολλαπλές οπτικές σχέσεις μέσω ενός μηχανισμού προσοχής για την αντιμετώπιση αυτού του ζητήματος. Συγκεκριμένα, αναπτύσσουμε ένα μοντέλο που χρησιμοποιεί την ενσωμάτωση ερωτήσεων και την κοινή ενσωμάτωση των κωδικοποιητών για την απόκτηση δυναμικών βαρών προσοχής σε σχέση με τον τύπο των ερωτήσεων. Χρησιμοποιώντας τα μαθησιακά βάρη προσοχής, το προτεινόμενο μοντέλο μπορεί να χρησιμοποιήσει αποτελεσματικά τα απαραίτητα χαρακτηριστικά οπτικής σχέσης για μια συγκεκριμένη ερώτηση. Τα πειραματικά αποτελέσματα στο σύνολο δεδομένων καταδεικνύουν ότι το προτεινόμενο μοντέλο ξεπερνά τις υπάρχουσες αρχιτεκτονικές προσοχής γραφικών δικτύων. Επιπλέον, οπτικοποιούμε το βάρος προσοχής και δείχνουμε ότι το προτεινόμενο μοντέλο αποδίδει μεγαλύτερο βάρος σε σχέσεις που είναι πιο σχετικές με το ερώτημα.</abstract_el>
      <abstract_lt>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations.  Tačiau tyrimai, kuriuose naudojami GNN, paprastai ignoruoja kiekvieno santykio svarbą ir paprasčiausiai sutrumpina kelių santykių koduotojų rezultatus. Šiame dokumente siūlome naują sluoksnio architektūrą, kuri sujungia daugelį vizualinių santykių per dėmesio mechanizmą šiam klausimui spręsti. Konkrečiai mes parengiame model į, kuriame naudojamas klausimų įtraukimas ir bendras koduotojų įtraukimas siekiant gauti dinamišką dėmesio svorį klausimų rūšies atžvilgiu. Pasiūlytas modelis, naudodamas mokomąjį dėmesį, gali veiksmingai naudoti tam tikram klausimui reikalingas vizualinio ryšio charakteristikas. Eksperimentiniai VQA 2.0 duomenų rinkinio rezultatai rodo, kad siūlomas modelis atitinka esamas grafinio dėmesio tinklo architektūras. Be to, matome dėmesio svorį ir rodome, kad siūlomame modelyje daugiau dėmesio skiriama santykiams, kurie yra svarbesni šiam klausimui.</abstract_lt>
      <abstract_mk>Претходните постоечки системи за одговори на визуелни прашања (VQA) обично користат графски нервни мрежи (GNNs) за извлекување визуелни односи како што се семантичните односи или просторските односи. However, studies that use GNNs typically ignore the importance of each relation and simply concatenate outputs from multiple relation encoders.  Во овој весник предложуваме нова архитектура на слој која ги спои повеќето визуелни односи преку механизам на внимание за решавање на ова прашање. Специфично, развиваме модел кој користи вградување на прашања и заедничко вградување на кодерите за да добие динамични тегови на внимание во врска со типот на прашања. Using the learnable attention weights, the proposed model can efficiently use the necessary visual relation features for a given question.  Експерименталните резултати на датотеката VQA 2.0 покажуваат дека предложениот модел ги надминува постојните архитектури на мрежата за внимание на графот. Покрај тоа, ја визуелизираме тежината на вниманието и покажуваме дека предложениот модел додава повисока тежина на односите кои се поврзани со прашањето.</abstract_mk>
      <abstract_ms>Sistem yang terdahulu menjawab soalan visual (VQA) biasanya menggunakan rangkaian saraf graf (GNNs) untuk mengekstrak hubungan visual seperti hubungan semantik atau hubungan ruang. Namun, kajian yang menggunakan GNN biasanya mengabaikan penting setiap hubungan dan hanya menyatukan output dari pengekod hubungan berbilang. Dalam kertas ini, kami cadangkan arkitektur lapisan baru yang menyatukan hubungan visual berbilang melalui mekanisme perhatian untuk mengatasi isu ini. Secara khusus, kita mengembangkan model yang menggunakan penyembedding soalan dan penyembedding bersama pengekod untuk mendapatkan berat perhatian dinamik terhadap jenis soalan. Menggunakan berat perhatian yang boleh dipelajari, model yang direncanakan boleh menggunakan secara efisien ciri-ciri hubungan visual yang diperlukan untuk soalan tertentu. Keputusan percubaan pada set data VQA 2.0 menunjukkan bahawa model yang diusulkan melebihi arkitektur berdasarkan rangkaian perhatian graf yang wujud. Lagipun, kita memahami berat perhatian dan menunjukkan bahawa model yang direncanakan memberikan berat lebih tinggi kepada hubungan yang lebih berkaitan dengan soalan.</abstract_ms>
      <abstract_ml>മുമ്പുണ്ടായിരുന്ന നിലവിലുള്ള കാഴ്ച ചോദ്യങ്ങളുടെ ഉത്തരം (VQA) സിസ്റ്റമുകള്‍ സാധാരണ ഗ്രാഫ് ന്യൂറല്‍ നെറുല്‍ നെറുല്‍ നെറ്റര്‍ നെറ്റ എങ്കിലും GNNs ഉപയോഗിക്കുന്ന പഠനങ്ങള്‍ സാധാരണയായി എല്ലാ ബന്ധത്തിന്റെയും പ്രധാനപ്പെട്ടത് അവഗണിക്കുകയും പല ബന്ധപ്പെട്ട കോ ഈ പത്രത്തില്‍, നമ്മള്‍ ഒരു നോവല്‍ ലേറ്റ് ആര്‍ക്ടിക്കറ്റിക്കേറ്റര്‍ പ്രൊദ്ദേശിപ്പിക്കുന്നു. അത് ഒരു ശ്രദ്ധ കാണാനുള്ള ഒരു  Specifically, we develop a model that uses question embedding and joint embedding of the encoders to obtain dynamic attention weights with regard to the type of questions.  പഠിക്കാന്‍ കഴിവുള്ള ശ്രദ്ധ തൂക്കങ്ങള്‍ ഉപയോഗിച്ച്, പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്‍ ഒരു ചോദ്യത്തിന് ആവശ്യമുള്ള കാഴ് VQA 2. 0 ഡാറ്റാസറ്റിന്റെ പരീക്ഷണ ഫലങ്ങള്‍ നിലവിലുള്ള ഗ്രാഫ് ശ്രദ്ധ നെറ്റ്‌വര്‍ക്കെറ്റിന്റെ അടിസ്ഥാനമായ ആര്‍ക്കിട്ടുകള കൂടാതെ, നമ്മള്‍ ശ്രദ്ധിക്കുന്ന ഭാരം കാണിക്കുകയും പ്രൊദ്ദേശിക്കപ്പെട്ട മോഡല്‍ കാണിക്കുകയും ചോദ്യത്തിന് കൂടുതല്‍ ബന്ധ</abstract_ml>
      <abstract_kk>Алдыңғы көрінетін сұрақтар жауап беру (VQA) жүйелері көпшілік графикалық невралдық желі (GNN) симпатикалық қатынастарды не бос қатынастарды тарқату үшін көрінетін қатынастарды қолданады. Бірақ GNN қолданылатын зерттеулері әдетте әрбір қатынастың маңыздылығын елемейді және бірнеше қатынастың кодерінің шығысын тек бірнеше қатынастың кодерінің маңыздылығын бірдей қа Бұл қағазда, біз бұл мәселеді шешу үшін бірнеше визуалдық қатынастарды біріктіретін жаңа қабат архитектурасын ұсынамыз. Сұрақтар түріне қатынау үшін, кодерлерді ендіру және біріктіру үшін қолданатын модель жасаймыз. Оқылмайтын қызықтың теңдігін қолдану үлгісі келтірілген сұрақ үшін қажетті көрініс қатынасын қолданады. VQA 2. 0 деректер жиынының эксперименталдық нәтижелері бар графикалық назардағы желінің архитектураларын көрсетеді. Қосымша, бұл үлгі қатынасын көрсетуге болады. Бұл үлгі сұрақтың қатынасына көп қатынасына көп қатынасын көрсетуге болады.</abstract_kk>
      <abstract_mn>Өмнөх хариултын асуулт хариулт (VQA) системүүд ихэвчлэн график мэдрэлийн сүлжээг (GNNs) ашигладаг. Жишээлбэл тэмдгийн харилцаа эсвэл огторгуйн харилцаа зэрэг харилцаа гаргаж байдаг. Гэхдээ ГНН хэрэглэдэг судалгаанууд харилцааны чухал чухал байдлыг эсэргүүцдэг, олон харилцааны кодчуудын үр дүнг тодорхойлох боломжтой. Энэ цаасан дээр бид энэ асуудлыг зохицуулахын тулд олон төрлийн харилцааны холбоотой шинэ давхар архитектурыг санал болгож байна. Тодорхой хэлбэл, бид асуултуудын төрлийн талаар хөгжүүлэх, холбоотой асуулт ашигладаг загварыг хөгжүүлдэг. Сургуулсан анхаарлын хэмжээг ашиглан, санал өгсөн загвар нь тодорхой асуултын тулд хэрэгтэй харилцаа холбоотой байдлыг ашиглаж болно. VQA 2.0 өгөгдлийн сан дээрх туршилтын үр дүн нь суурилсан загвар нь суурилсан график анхаарлын сүлжээнд суурилсан архитектуруудыг илтгэдэг. Мөн бид анхаарлын жингийг харуулж, санал өгсөн загвар асуултын тухай илүү холбоотой харилцаанд илүү өндөр жинг өгдөг гэдгийг харуулж байна.</abstract_mn>
      <abstract_no>Førre visuelle spørsmålsystemet som svarar på spørsmål (VQA) brukar vanlegvis grafennettverk (GNN) for å pakka ut visuelle forhold som semantiske forhold eller mellomromforhold. Men studier som brukar GNN ignorerer vanlegvis viktigheten for kvar relasjon og enkelt samanlikn utdata frå fleire relasjonskode. I denne papiret foreslår vi eit nytt lagarkitektur som får fleire visuelle forhold gjennom ein oppmerksmekanisme for å handtera dette problemet. Spesielt utviklar vi eit modell som brukar spørsmål innebygging og kopla innbygging av koderane for å få dynamiske oppmerksvekt med gjennom type spørsmål. Bruk dei lærbare oppmerksvektene kan den foreslåde modellen bruka dei nødvendige visualrelasjonsfunksjonane for eit oppgjeven spørsmål. Eksperimentale resultat på datasettet VQA 2.0 viser at den foreslåde modellen utfører eksisterande arkitekturar som er basert på nettverksoppmerksomhet i grafen. I tillegg visualiserer vi oppmerksvekten og viser at den foreslåde modellen tilbyr høgare vekt til forholdet som er meir relevant til spørsmålet.</abstract_no>
      <abstract_mt>Sistemi ta’ tweġiba għall-mistoqsijiet viżwali eżistenti preċedenti (VQA) jużaw b’mod komuni netwerks newrali tal-graff (GNNs) biex jestraġu relazzjonijiet viżwali bħal relazzjonijiet semantiċi jew relazzjonijiet ġeografiċi. Madankollu, studji li jużaw GNNs tipikament jinjoraw l-importanza ta’ kull relazzjoni u sempliċement jikkonċentraw ir-riżultati minn kodifikaturi ta’ relazzjonijiet multipli. F’dan id-dokument, qed nipproponu arkitettura ġdida tas-saff li tgħaqqad relazzjonijiet viżivi multipli permezz ta’ mekkaniżmu ta’ attenzjoni biex tiġi indirizzata din il-kwistjoni. B’mod speċifiku, qed niżviluppaw mudell li juża l-inkorporazzjoni ta’ mistoqsijiet u l-inkorporazzjoni konġunta tal-kodifikaturi biex jinkisbu piżijiet dinamiċi ta’ attenzjoni fir-rigward tat-tip ta’ mistoqsijiet. Bl-użu tal-piżijiet ta’ attenzjoni li jistgħu jitgħallmu, il-mudell propost jista’ juża b’mod effiċjenti l-karatteristiċi ta’ relazzjoni viżwali meħtieġa għal kwistjoni partikolari. Experimental results on the VQA 2.0 dataset demonstrate that the proposed model outperforms existing graph attention network-based architectures.  Barra minn hekk, niviżwalizzaw il-piż tal-attenzjoni u nuru li l-mudell propost jassenja piż ogħla għar-relazzjonijiet li huma aktar rilevanti għall-kwistjoni.</abstract_mt>
      <abstract_pl>Dotychczasowe istniejące systemy odpowiedzi na wizualne pytania (VQA) powszechnie wykorzystują wykresowe sieci neuronowe (GNN) do wyodrębniania relacji wizualnych, takich jak relacje semantyczne lub relacje przestrzenne. Jednak badania używające GNN zwykle ignorują znaczenie każdej relacji i po prostu łączą wyjścia z wielu koderów relacji. W niniejszym artykule proponujemy nowatorską architekturę warstwową, która łączy wiele relacji wizualnych poprzez mechanizm uwagi, aby rozwiązać ten problem. W szczególności opracowujemy model, który wykorzystuje osadzanie pytań i wspólne osadzenie koderów do uzyskania dynamicznych wag uwagi w odniesieniu do rodzaju pytań. Wykorzystując nauczalne wagi uwagi, proponowany model może skutecznie wykorzystać niezbędne cechy relacji wizualnych dla danego pytania. Wyniki eksperymentalne na zbiorze danych VQA 2.0 pokazują, że proponowany model przewyższa istniejące architektury oparte na sieci uwagi grafu. Dodatkowo wizualizujemy wagę uwagi i pokazujemy, że proponowany model przypisuje większą wagę relacjom, które są bardziej istotne dla danego pytania.</abstract_pl>
      <abstract_ro>Sistemele anterioare de răspuns vizual la întrebări (VQA) utilizează în mod obișnuit rețelele neurale grafice (GNN) pentru a extrage relații vizuale, cum ar fi relațiile semantice sau relațiile spațiale. Cu toate acestea, studiile care utilizează GNN ignoră de obicei importanța fiecărei relații și pur și simplu concatenează ieșirile de la codificatoarele de relații multiple. În această lucrare, propunem o arhitectură nouă de straturi care fuzionează relații vizuale multiple printr-un mecanism de atenție pentru a aborda această problemă. În mod specific, dezvoltăm un model care utilizează încorporarea întrebărilor și încorporarea comună a encoderelor pentru a obține greutăți dinamice de atenție în ceea ce privește tipul de întrebări. Folosind greutățile atenției care pot fi învățate, modelul propus poate utiliza eficient caracteristicile de relație vizuală necesare pentru o anumită întrebare. Rezultatele experimentale ale setului de date VQA 2.0 demonstrează că modelul propus depășește arhitecturile existente bazate pe rețea de atenție grafică. În plus, vizualizăm greutatea atenției și arătăm că modelul propus atribuie o greutate mai mare relațiilor care sunt mai relevante pentru întrebare.</abstract_ro>
      <abstract_si>මුලින් ප්‍රශ්න ප්‍රශ්න ප්‍රශ්නය (VQA) පද්ධතිය සාමාන්‍යයෙන්ම ග්‍රාෆ් න්‍යූරාල ජාලය (GnNs) භාවිත කරන්න ප්‍රශ්නය සම නමුත්, අධ්‍යානය සමහර විශේෂයෙන් සම්බන්ධ වෙනුවෙන් ප්‍රයෝජනය කරන්නේ හැම සම්බන්ධයේ වැදගත්ත වැදගත්තා සමහ මේ පත්තරේ අපි ප්‍රශ්නයක් කරනවා මේ ප්‍රශ්නයක් ගැන බලන්න අවධානයක් සම්බන්ධ කරනවා. විශේෂයෙන්, අපි ප්‍රශ්නයක් සම්බන්ධ කරන්න සහ සම්බන්ධ ප්‍රශ්නයක් භාවිත කරන්න ප්‍රශ්නයක් ප්‍රශ්නයක් ලැබෙන්න ස ඉගෙන ගන්න පුළුවන් අවධානයක් භාවිත කරන්න, ප්‍රශ්නයක් ලැබෙන්න පුළුවන් ප්‍රශ්නයක් වෙනුවෙන් අවශ්‍ VQA 2.0 දත්ත සැටේ පරීක්ෂණ ප්‍රතික්‍රියාත්මක විදිහට ප්‍රතික්‍රියා කරනවා කියලා ප්‍රතික්‍රියාත්මක විදිහට අනුවෙන් අපි අවධානය ගැන බලන්න පෙන්වන්නේ ඒ වගේම ප්‍රශ්නය වෙනුවෙන් ප්‍රශ්නය වෙනුවෙන් වඩා වඩා බලයක් ති</abstract_si>
      <abstract_sr>Prethodni sistemi odgovora na vizualno pitanje (VQA) često koriste grafičke neuralne mreže (GNN) kako bi izvukli vizuelne veze kao što su semantički odnosi ili prostorni odnosi. Međutim, ispitivanja koje koriste GNN obično ignoriraju važnost svakog odnosa i jednostavno potvrđuju ishod od od višestrukih kodera veza. U ovom papiru predlažemo novu arhitekturu slojeva koja spaja višestruke vizualne odnose kroz mehanizam pažnje za rješavanje ovog pitanja. Posebno, razvijamo model koji koristi integraciju pitanja i zajedničku integraciju kodera kako bi dobili dinamičnu težinu pažnje u odnosu na vrste pitanja. Koristeći težine pažnje, predloženi model može efikasno koristiti potrebne vizualne veze za određeno pitanje. Eksperimentalni rezultati na setu podataka VQA 2.0 pokazuju da predloženi model iznosi postojeće arhitekture na mreži pažnje na grafiku. Osim toga, mi vizualiziramo težinu pažnje i pokazujemo da predloženi model dodaje veću težinu odnosima koje su važnije za pitanje.</abstract_sr>
      <abstract_so>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations.  Si kastaba ha ahaatee, waxbarashada GNNs sida caadiga ah u jeeda muhiimka xiriir kasta ah, islamarkaasna waxay keliyahoo ka soo bandhigaan soo bixinta kooxda xiriirka kala duduwan. Warqaddan waxaynu ka soo jeedaynaa dhismo sawir ah oo kordhiya xiriir kala duduwan oo arag la’a an ah, si aan u baaraandegayo arimahan. Si gaar ah, waxaynu horumarinaa model, kaas oo isticmaalaya su'aalo ku saabsan iyo wadajir ka mid ah codsiga, si aan u helno miisaanka dareemaha dabiiqada ee su'aalaha nooca ah. Isku isticmaalidda daryeelka caqliga ah waxaa si fiican u isticmaali kara xiriirka aragga ee loo baahan yahay su'aal la siiyo. Imtixaanka ku saabsan VQA 2.0 dataset waxay muujiyaan in modelkii la soo jeeday uu soo saaraa taariikhda warbixinta shabakadda ee ku qoran ee jimicsiga. Sidoo kale waxaynu fiirinnaa miisaanka, waxaana muujinnaa in qaababka la soo jeeday ay ay miisaan ka sarreeyaan xiriirka ay ka muhiimsan yihiin su'aalka.</abstract_so>
      <abstract_sv>Tidigare existerande visuella frågesvarssystem (VQA) använder ofta grafneurala nätverk (GNN) för att extrahera visuella relationer såsom semantiska relationer eller rumsliga relationer. Studier som använder GNN ignorerar dock vanligtvis vikten av varje relation och sammanfogar helt enkelt utgångar från flera relationskoder. I denna uppsats föreslår vi en ny lagerarkitektur som förenar flera visuella relationer genom en uppmärksamhetsmekanism för att ta itu med denna fråga. Specifikt utvecklar vi en modell som använder frågeinbäddning och gemensam inbäddning av kodarna för att få dynamiska uppmärksamhetsvikter med avseende på typen av frågor. Med hjälp av de inlärbara uppmärksamhetsvikten kan den föreslagna modellen effektivt använda nödvändiga visuella relationsfunktioner för en viss fråga. Experimentella resultat på datauppsättningen VQA 2.0 visar att den föreslagna modellen överträffar befintliga nätverksbaserade arkitekturer. Dessutom visualiserar vi uppmärksamhetsvikten och visar att den föreslagna modellen lägger högre vikt på relationer som är mer relevanta för frågan.</abstract_sv>
      <abstract_ur>پہلے موجود visual question replying (VQA) systems commonly use graph neural networks (GNNs) to extract visual relationships such as semantic relations or spatial relations. However, studies that use GNN typically ignore the importance of each relation and simply concatenate outputs from multiple relation encoders. اس کاغذ میں ہم ایک نئی لائر معماری پیشنهاد کرتے ہیں جو اس مسئلہ کے بارے میں مشورہ کرنے کے لئے بہت سی نظر والی رابطہ کے ذریعہ مکانیسم کے ذریعہ مکانیسم کے ذریعہ مکانیسم سے متصل خاص طور پر، ہم ایک موڈل ایجاد کرتے ہیں جو سوال کی طرح کے بارے میں ڈینمانیک توجه حاصل کرنے کے لئے سوال کے مطابق سؤال کے مطابق سوال کے مطابق استعمال کرتا ہے۔ سکھانے والی توجه کے مطابق، پیشنهاد کی موڈل ایک سوال کے لئے ضروری تصویر نسبت کا فائدہ استعمال کر سکتا ہے. VQA 2.0 ڈاٹ سٹ پر تجربہ کا نتیجہ دکھاتا ہے کہ پیشنهاد کی مدل موجود ہونے والی گراف توجه نیٹ ورک کی بنیادی معماری سے کام کرتا ہے۔ اور اضافہ، ہم توجه وزن کو دکھاتے ہیں اور دکھاتے ہیں کہ پیش کیا گیا موڈل ایک بلند وزن رابطہ کے لئے مقرر کرتا ہے جو سوال کے زیادہ اضافہ ہیں.</abstract_ur>
      <abstract_ta>முந்தைய இருக்கும் பார்வை கேள்வி பதில் (VQA) அமைப்புகள் பொதுவாக வரைபடத்தின் நெயுரல் வலைப்பின்னல்களை பயன்படுத்தி பார்வையில் உள்ள இணைப்ப எனினும், ஒவ்வொரு தொடர்புகளின் முக்கியத்தை புறக்கணிக்கும் படிப்புகளும் பல தொடர்பு குறியீடு இந்த காகிதத்தில், நாம் ஒரு புதிய அடுக்கு உருவாக்கத்தை பரிந்துரைக்கிறோம். அது பல பார்வையுடைய உறவுகளை பிரச்சனைப்படுத் குறிப்பிட்டு, நாம் ஒரு மாதிரி உருவாக்குகிறோம் கேள்வி உள்ளடக்கம் மற்றும் குறியீடுகளின் இணைய குறியீடுகளை சேர்க்கும் மாதி படிக்கக்கூடிய கவனம் எடைகளை பயன்படுத்தி, பரிந்துரைக்கப்பட்ட மாதிரி கொடுக்கப்பட்ட கேள்வி Name கூடுதலாக, நாம் கவனத்தை பார்க்கிறோம் மற்றும் பரிந்துரைக்கப்பட்ட மாதிரி கேள்விக்கு மிகவும் தொடர்புகளுக்கு உயர்ந்த எட</abstract_ta>
      <abstract_vi>Các hệ thống phản ứng hình ảnh trước đây (VQA) thường sử dụng các mạng thần kinh đồ thị (GNNs) để chiết xuất các mối quan hệ hình ảnh như giao tiếp/ Tuy nhiên, các nghiên cứu sử dụng GNN thường phớt lờ tầm quan trọng của mỗi mối quan hệ và đơn giản chỉ kết nối kết xuất từ các mã hóa liên quan nhiều. Trong tờ giấy này, chúng tôi đề nghị một kiến trúc lớp mới kết hợp nhiều quan hệ hình ảnh qua một cơ chế để chú ý giải quyết vấn đề này. Cụ thể, chúng tôi phát triển một mô hình dùng việc lắp ghép các câu hỏi và ghép ghép ghép các bộ mã hóa để có thể nhận được trọng lượng sự chú ý động trong các loại câu hỏi. Sử dụng các trọng lượng gây chú ý dễ thấm thấm thoát, kiểu mẫu đề nghị có thể sử dụng hiệu quả các tính năng quan hệ thị giác cần thiết cho một câu hỏi. Các kết quả thử nghiệm trên tập tin VQA 2.0 đã chứng minh rằng mô hình đã đề ra ngoài thực hiện các kiến trúc dựa trên mạng chú ý đồ thị. Thêm nữa, chúng tôi hình dung trọng lượng chú ý và cho thấy rằng mô hình đề xuất đặt trọng lượng cao hơn vào các mối quan hệ có liên quan hơn với câu hỏi.</abstract_vi>
      <abstract_uz>@ info Lekin, GNNs' dan foydalanuvchilar odatda har bir munosabatlarning muhimligini eslab qoladi va bir necha bogʻ'lama kodlardan aniqlash mumkin. In this paper, we propose a novel layer architecture that fuses multiple visual relations through an attention mechanism to address this issue.  Kodlash usulini foydalanish mumkin, bu muammolar turli soʻrov va kodlash usulini birlashtirish uchun foydalanadi. Koʻrsatilgan foydalanuvchi modeli foydalanishi mumkin. Koʻrsatilgan savol uchun kerak visual aloqaning xususiyatlarini foydalanishi mumkin. Name Ko'pchilik, biz murakkablikni tasavvur qilamiz va taʼminlovchi modeli savol bilan juda bog'liq munosabatlarni ko'rsatumiz.</abstract_uz>
      <abstract_sw>Mfumo wa zamani unaoendelea kujibu maswali ya kuona (VQA) mara nyingi hutumia mitandao ya picha ya neura(GNNs) kuondoa mahusiano ya kuonekana kama vile mahusiano ya kimapenzi au mahusiano ya spania. Hata hivyo, utafiti ambao hutumia GNN kwa kawaida hupuuza umuhimu wa kila mahusiano na wanatengeneza matokeo yanayotokana na kodi nyingi za mahusiano. Katika gazeti hili, tunapendekeza ujenzi wa kiwango cha riwaya unaosababisha mahusiano kadhaa ya kuona kwa njia ya mfumo wa kutangaza suala hili. Kwa ujumla, tunatengeneza muundo unaotumia maswali yanayoingia pamoja na kuingiza jumla ya idadi hiyo ili kupata mizani ya msimamo mkali kuhusu aina ya maswali. Kwa kutumia mizani ya kusikiliza, muundo wa pendekezo unaweza kutumia vifaa muhimu vya mahusiano ya kuona kwa swali fulani. Matokeo ya majaribio yanayotokana na seti ya taarifa za VQA 2.0 yanaonyesha kuwa modeli iliypendekezwa inaonyesha majengo yanayotokana na mitandao ya uchunguzi wa picha. Zaidi ya hayo, tunaonyesha uzito wa kusikiliza na kuonyesha kuwa muundo wa pendekezo unaweka uzito mkubwa wa mahusiano yanayohusiana na swali hilo.</abstract_sw>
      <abstract_fa>سیستم‌های جواب سؤال دیده‌ای پیش از آن (VQA) معمولاً شبکه‌های عصبی (GNN) را برای خروج رابطه‌های دیده‌ای مثل رابطه‌های semantic یا رابطه‌های فضایی استفاده می‌کنند. ولی مطالعه‌ها که از GNN استفاده می‌کنند معمولاً اهمیت هر رابطه را نادیده می‌گیرند و نتیجه‌های متعدد از کودهای متعدد رابطه را نادیده می‌گیرند. در این کاغذ، ما یک معماری جدید لایه پیشنهاد می کنیم که با یک مکانیسم توجه برای حل این مسئله تعداد زیادی رابطه‌های بینایی را جمع می‌کند. به طور خاصی، ما یک مدل توسعه می‌کنیم که از مشترک سوال استفاده می‌کند که از مشترک و مشترک پیوند‌گیری از کودکان‌ها استفاده می‌کند تا وزن توجه‌های دینامیک را درباره نوع سوال‌ها دریافت کند. با استفاده از وزن توجه یادآوری، مدل پیشنهاد می‌تواند از ویژه‌های ارتباط دیده‌ای لازم برای یک سوال معلوم استفاده کند. نتیجه‌های تجربه روی مجموعه داده‌های VQA 2.0 نشان می‌دهد که مدل پیشنهاد توجه به شبکه‌های توجه گرافی موجود بیشتر از آن انجام می‌دهد. اضافه این، ما وزن توجه را تصور می‌کنیم و نشان می‌دهیم که مدل پیشنهاد وزن بیشتری برای رابطه‌هایی که با این سوال ارتباط بیشتری دارند، مقرر می‌کند.</abstract_fa>
      <abstract_id>Sistem yang sebelumnya menjawab pertanyaan visual (VQA) biasanya menggunakan jaringan saraf grafik (GNN) untuk mengekstrak hubungan visual seperti hubungan semantis atau hubungan ruang. Namun, penelitian yang menggunakan GNN biasanya mengabaikan penting setiap hubungan dan hanya menyatukan output dari koder hubungan berbilang. Dalam kertas ini, kami mengusulkan arsitektur lapisan baru yang menggabungkan hubungan visual berbilang melalui mekanisme perhatian untuk mengatasi masalah ini. Secara spesifik, kita mengembangkan model yang menggunakan penyembedding pertanyaan dan penyembedding kongsi koder untuk mendapatkan berat perhatian dinamik dalam hal jenis pertanyaan. Menggunakan berat perhatian yang dapat dipelajari, model yang diusulkan dapat menggunakan secara efisien fitur hubungan visual yang diperlukan untuk pertanyaan tertentu. Hasil eksperimental pada set data VQA 2.0 menunjukkan bahwa model yang diusulkan lebih berharga dari arsitektur jaringan perhatian grafik yang ada. Selain itu, kita membayangkan berat perhatian dan menunjukkan bahwa model yang diusulkan mengarahkan berat badan yang lebih tinggi kepada hubungan yang lebih relevan untuk pertanyaan.</abstract_id>
      <abstract_bg>Предишни съществуващи системи за визуално отговаряне на въпроси (VQA) обикновено използват графични невронни мрежи (GNN) за извличане на визуални взаимоотношения като семантични взаимоотношения или пространствени взаимоотношения. Въпреки това, проучванията, които използват GNN обикновено игнорират значението на всяка връзка и просто конкатенират изходите от множество релационни кодери. В настоящата статия предлагаме нова архитектура на слоя, която слива множество визуални отношения чрез механизъм за внимание за решаване на този проблем. По-конкретно, разработваме модел, който използва вграждане на въпроси и съвместно вграждане на кодерите за получаване на динамични тежести на вниманието по отношение на вида на въпросите. Използвайки усвояемите тежести на вниманието, предложеният модел може ефективно да използва необходимите визуални взаимоотношения функции за даден въпрос. Експерименталните резултати на набора от данни показват, че предложеният модел превъзхожда съществуващите мрежови архитектури за внимание на графиките. Освен това визуализираме тежестта на вниманието и показваме, че предложеният модел придава по-голяма тежест на отношенията, които са по-подходящи за въпроса.</abstract_bg>
      <abstract_cs>Předchozí existující systémy zodpovězení vizuálních otázek (VQA) běžně používají grafové neuronové sítě (GNN) k extrakci vizuálních vztahů, jako jsou sémantické vztahy nebo prostorové vztahy. Studie, které používají GNN, však obvykle ignorují důležitost každé relace a jednoduše řetězí výstupy z více relačních kodérů. V tomto článku navrhujeme novou vrstvu architektury, která spojuje více vizuálních vztahů prostřednictvím mechanismu pozornosti k řešení tohoto problému. Konkrétně vyvíjíme model, který využívá vložení otázek a společné vložení snímačů k získání dynamické pozornostní hmotnosti s ohledem na typ otázek. Pomocí naučitelných závaží pozornosti může navržený model efektivně využít potřebné vizuální vztahy pro danou otázku. Experimentální výsledky na datové sadě VQA 2.0 ukazují, že navržený model překonává stávající architektury grafové pozornosti založené na síti. Navíc vizualizujeme váhu pozornosti a ukazujeme, že navržený model přiřazuje vyšší váhu vztahům, které jsou relevantnější pro otázku.</abstract_cs>
      <abstract_az>Əvvəlki görsel sual cevapları (VQA) sistemləri, semantik əlaqələr və uzay əlaqələr kimi görsel əlaqələri çıxartmaq üçün grafik nöral ağları(GNN) kullanır. Ancaq GNN istifadə edən təhsil olaraq hər bir bağlantının vacibətini və çoxlu bağlantı kodlayıcılarından istifadə edirlər. Bu kağızda, bu meseleyi çəkmək üçün çoxlu görsel ilişkileri birləşdirən yeni bir layer arhitektura təklif edirik. Özellikle, biz bir modeli inşa edirik ki, kodlayıcıların birləşdirilməsi üçün dinamik dikkati a ğırlığını soruşmaq üçün sual çəkir. Öyrənə bilən təsirlərin a ğırlığını istifadə edərək, təklif edilən modeli müəyyən bir sual üçün ehtiyacı görünüş əlaqələrini faydalanır. VQA 2.0 veri qutusundakı təcrübə sonuçları, qurduğu modellərin mevcut grafik məlumatı şəbəkə tabanlı arhitektarlarından üstün olduğunu göstərir. Əksinə, biz məlumatların a ğırlığını görürük və təklif etdiyimiz modellərin suala daha çox bağlı olan ilişkilərə yüksək ağırlığı verir.</abstract_az>
      <abstract_de>Bisherige Systeme zur visuellen Beantwortung von Fragen (VQA) verwenden üblicherweise Graph Neuronal Networks (GNNs), um visuelle Beziehungen wie semantische Beziehungen oder räumliche Beziehungen zu extrahieren. Studien, die GNNs verwenden, ignorieren jedoch typischerweise die Bedeutung jeder Beziehung und verketten einfach Ausgänge von mehreren Relationencodern. In diesem Beitrag schlagen wir eine neuartige Schichtarchitektur vor, die mehrere visuelle Beziehungen durch einen Aufmerksamkeitsmechanismus verbindet, um dieses Problem anzugehen. Konkret entwickeln wir ein Modell, das mittels Frageinbedding und Joint Embedding der Encoder dynamische Aufmerksamkeitsgewichte hinsichtlich der Art der Fragen erhält. Mit den erlernbaren Aufmerksamkeitsgewichten kann das vorgeschlagene Modell effizient die notwendigen visuellen Beziehungsmerkmale für eine bestimmte Frage nutzen. Experimentelle Ergebnisse des VQA 2.0 Datensatzes zeigen, dass das vorgeschlagene Modell bestehende Graphenaufmerksamkeitsnetzwerkarchitekturen übertrifft. Zusätzlich visualisieren wir das Aufmerksamkeitsgewicht und zeigen, dass das vorgeschlagene Modell Beziehungen, die für die Frage relevanter sind, ein höheres Gewicht zuweist.</abstract_de>
      <abstract_ko>기존의 시각 퀴즈 시스템은 일반적으로 의미 관계나 공간 관계와 같은 시각 관계를 추출하기 위해 도형 신경 네트워크(GNN)를 사용한다.그러나 GNN을 이용한 연구는 일반적으로 모든 관계의 중요성을 무시하고 여러 개의 관계 인코더의 출력만 연결한다.본고에서 우리는 새로운 차원 구조를 제시했고 주의 메커니즘을 통해 다양한 시각 관계를 융합시켜 이 문제를 해결했다.구체적으로 말하자면, 우리는 문제 삽입과 인코더의 결합 삽입을 사용하여 문제 유형에 대한 동적 주의권을 얻는 모델을 개발했다.학습 가능한 주의권을 사용함으로써 이 모델은 주어진 문제에 필요한 시각 관계 특징을 효과적으로 활용할 수 있다.VQA 2.0 데이터 세트에서의 실험 결과에 따르면 이 모델은 기존의 도형 주의 네트워크 기반의 체계 구조보다 우수하다.그 밖에 우리는 주의력의 중요성을 가시화하고 제시한 모델이 문제와 더욱 관련된 관계에 더욱 높은 중요성을 부여했음을 나타낸다.</abstract_ko>
      <abstract_af>Vorige bestaande visuele vraag antwoord (VQA) stelsels gewoonlik gebruik graaf neurale netwerke (GNN) om visuele verwantings te uitpak soos semantiese verwantings of spasiele verwantings. Maar studies wat GNN gebruik word, het tipes die belangrikheid van elke verwanting geignoreer en eenvoudig die uitvoerdes van veelvuldige verwanting enkoderes. In hierdie papier, voorstel ons 'n nuwe laag-arkitektuur wat veelvuldige visuele verwante verbind deur 'n aandagmekanisme om hierdie probleem te adres. Spesifieke, ons ontwikkel 'n model wat gebruik vraag inbêring en joint inbêring van die enkodere om dinamiese aandagsverke te kry met betrekking tot die tipe vraagte. Gebruik van die leerbare aandagsvegte, kan die voorgestelde model effektief die nodige visuele verwanting funksies vir 'n gegewe vraag gebruik. Eksperimentale resultate op die VQA 2. 0 datastel vertoon dat die voorgestelde model uitvoer bestaande graaf aandag netwerk-gebaseerde architecture. In addition, we visualiseer the attention weight and show that the proposed model assigns a higher weight to relations that are more relevant to the question.</abstract_af>
      <abstract_hy>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations.  Այնուամենայնիվ, այն ուսումնասիրությունները, որոնք օգտագործում են GNN-ները, սովորաբար անտեսում են յուրաքանչյուր հարաբերության կարևորությունը և պարզապես համընդհանուր արտադրանքները բազմաթիվ հարաբերությունների կոդերների Այս թղթի մեջ մենք առաջարկում ենք նոր շերտի ճարտարապետություն, որը միացնում է բազմաթիվ տեսողական հարաբերությունները ուշադրության մեխանիզմի միջոցով այս խնդիրը լուծելու համար: Հատկապես, մենք ստեղծում ենք մի մոդել, որը օգտագործում է հարցերի ներառումը և կոդերների միասին ներառումը, որպեսզի ստանանք դինամիկ ուշադրության կշիռներ հարցերի տեսակի նկատմամբ: Օգտագործելով սովորելի ուշադրության կշիռը, առաջարկված մոդելը կարող է արդյունավետ օգտագործել որոշ հարցերի համար անհրաժեշտ տեսողական հարաբերությունները: VQA 2.0 տվյալների համակարգի փորձարկման արդյունքները ցույց են տալիս, որ առաջարկված մոդելը արտադրում է գոյություն ունեցող գծագրային ուշադրության ցանցի կառուցվածքներ: Ավելին, մենք տեսնում ենք ուշադրության կշիռը և ցույց ենք տալիս, որ առաջարկած մոդելը ավելի բարձր կշիռ է տալիս հարաբերություններին, որոնք ավելի կարևոր են հարցին:</abstract_hy>
      <abstract_sq>Sistemet e mëparshëm që përgjigjen pyetjeve vizuale (VQA) përdorin zakonisht rrjetet nervore grafike (GNNs) për të nxjerrë marrëdhënie vizuale të tilla si marrëdhëniet semantike apo marrëdhëniet hapësirore. Megjithatë, studimet që përdorin GNN zakonisht injorojnë rëndësinë e çdo marrëdhënie dhe thjesht bashkëkuptojnë daljet nga koduesit e lidhjeve të shumta. Në këtë letër, propozojmë një arkitekturë të re shtrese që bashkon marrëdhënie të shumta vizuale nëpërmjet një mekanizmi vëmendjeje për të trajtuar këtë çështje. Veçanërisht, ne zhvillojmë një model që përdor përfshirjen e çështjeve dhe përfshirjen e përbashkët të koduesve për të marrë pesha dinamike vëmendjeje lidhur me llojin e pyetjeve. Using the learnable attention weights, the proposed model can efficiently use the necessary visual relation features for a given question.  Rezultatet eksperimentale në grupin e të dhënave VQA 2.0 demonstrojnë se modeli i propozuar ekziston arkitektura ekzistuese bazuar në rrjetin e vëmendjes grafike. Përveç kësaj, ne vizualizojmë peshën e vëmendjes dhe tregojmë se modeli i propozuar i cakton një peshë më të lartë marrëdhënieve që janë më të rëndësishme për këtë çështje.</abstract_sq>
      <abstract_nl>Eerder bestaande systemen voor visual question responsing (VQA) gebruiken meestal grafiekneurale netwerken (GNN's) om visuele relaties zoals semantische relaties of ruimtelijke relaties te extraheren. Studies die GNN's gebruiken negeren echter meestal het belang van elke relatie en verbinden eenvoudig outputs van meerdere relatiecoders. In dit artikel stellen we een nieuwe laagarchitectuur voor die meerdere visuele relaties fuseert door middel van een aandachtsmechanisme om dit probleem aan te pakken. Specifiek ontwikkelen we een model dat gebruikmaakt van vraag embedding en joint embedding van de encoders om dynamische aandachtsgewichten te verkrijgen met betrekking tot het type vragen. Met behulp van de leerbare aandachtsgewichten kan het voorgestelde model efficiënt gebruik maken van de benodigde visuele relatiefuncties voor een bepaalde vraag. Experimentele resultaten op de VQA 2.0 dataset tonen aan dat het voorgestelde model beter presteert dan bestaande grafiekaandachtsnetwerk-gebaseerde architecturen. Daarnaast visualiseren we het aandachtsgewicht en laten we zien dat het voorgestelde model een hoger gewicht toekent aan relaties die relevanter zijn voor de vraag.</abstract_nl>
      <abstract_hr>Prije postojećih sustava odgovora na vizualno pitanje (VQA) obično koriste grafičke neuralne mreže (GNN) za izvlačenje vizuelnih odnosa poput semantičkih odnosa ili prostornih odnosa. Međutim, ispitivanja koje koriste GNN obično ignoriraju važnost svakog odnosa i jednostavno potvrđuju ishod od od višestrukih kodera odnosa. U ovom papiru predlažemo novu arhitekturu slojeva koja spaja višestruke vizualne odnose kroz mehanizam pažnje za rješavanje ovog pitanja. Posebno, razvijamo model koji koristi pitanje uključujući i zajedničku uključenje kodera kako bi dobili dinamičnu težinu pažnje u vezi vrsta pitanja. Koristeći težine učenja pažnje, predloženi model može učinkovito koristiti potrebne vizualne veze za određeno pitanje. Eksperimentalni rezultati na setu podataka VQA 2.0 pokazuju da predloženi model iznosi postojeće arhitekture na temelju mreže pažnje na grafiku. Osim toga, vizualiziramo težinu pažnje i pokazujemo da predloženi model dodaje veću težinu odnosima koje su važnije pitanju.</abstract_hr>
      <abstract_da>Tidligere eksisterende visuelle spørgsmålsbesvarelsessystemer (VQA) bruger almindeligvis grafneurale netværk (GNN'er) til at udtrække visuelle relationer såsom semantiske relationer eller rumlige relationer. Men undersøgelser, der bruger GNN'er, ignorerer typisk vigtigheden af hver relation og blot sammenkobler output fra flere relationskodere. I denne artikel foreslår vi en ny lagarkitektur, der smelter flere visuelle relationer gennem en opmærksomhedsmekanisme for at løse dette problem. Specielt udvikler vi en model, der bruger spørgsmålsindlejring og fælles indlejring af encoderne til at opnå dynamiske opmærksomhedsvægte i forhold til typen af spørgsmål. Ved hjælp af de lærbare opmærksomhedsvægte kan den foreslåede model effektivt bruge de nødvendige visuelle relationsfunktioner til et givet spørgsmål. Eksperimentelle resultater på VQA 2.0 datasættet viser, at den foreslåede model overgår eksisterende grafopmærksomhedsnetværksbaserede arkitekturer. Derudover visualiserer vi opmærksomhedsvægten og viser, at den foreslåede model tildeler en højere vægt til relationer, der er mere relevante for spørgsmålet.</abstract_da>
      <abstract_tr>Öň bar görsel soraglaryň jogapy (VQA) sistemleri hemişe grafik näyral şebekleri(GNNs) semantik baglaýyşlary ýa-da sowal baglaýyşlary açmak üçin ullanýarlar. Ýöne GNN ullanýan öwrenmeler adatça her baglaýyşyň wajyplygyny görmeýän we birnäçe baglaýyşyň kodelerinden netijesini takyklaýarlar. Bu kagyzda, biz bu meseleyi çözmek üçin birnäçe görsel baglaşyklary bilen örän gaty bir gaty arhitektura teklip edýäris. Adatça, soraglaryň içine bir nusgasyny ullanýan we birleşik kodeýçlerin içine dinamik derejesi bar. Edilen üns çyzgyny ullanýar, teklip eden nusga berilen sorag üçin gerekli görnöş baglaýyşlary ulanyp biler. VQA 2 Hemmäçe, biz üns çekmegini görsek we teklip eden nusgyň soragyna has baglaşyklaryň ýokary uly derejä gurlaýandygyny görkez.</abstract_tr>
      <abstract_bn>পূর্ববর্তী দৃশ্যমান প্রশ্নের উত্তর (ভিকিউএ) সিস্টেম সাধারণত গ্রাফ নিউরেল নেটওয়ার্ক ব্যবহার করে যেমন সেমেন্টিক সম্পর্ক অথবা স্পেশিয়াল সম্পর তবে গবেষণা যা GNNs ব্যবহার করে সাধারণত প্রতিটি সম্পর্কের গুরুত্বপূর্ণ গুরুত্ব উপেক্ষা করে এবং শুধুমাত্র বিভিন্ন সম্পর্কের এই কাগজটিতে আমরা একটি উপন্যাস স্তরের আর্কিকেট প্রস্তাব করছি যা এই বিষয়টি নিয়ে আলোচনা করার জন্য বেশ কিছু দৃষ্টিভঙ্গি সম্পর্কের ব বিশেষ করে, আমরা একটি মডেল তৈরি করি যা প্রশ্ন ব্যবহার করে এনকোডারের বিভিন্ন প্রশ্ন ব্যবহার করে যোগাযোগ করে প্রশ্নের ব্যাপারে প্রশ্নের প্রশ শিখতে পারার প্রস্তাবিত মডেল ব্যবহার করে একটি প্রশ্নের জন্য প্রয়োজনীয় দৃশ্য সম্পর্ক বৈশিষ্ট্য ব্যবহার করতে পারে। ভিকিউএ ২. ০ ডাটাসেটের পরীক্ষার ফলাফল প্রদর্শন করেছে যে প্রস্তাবিত মডেল বিদ্যমান গ্রাফ মনোযোগ নেটওয়ার্ক ভিত্তিক কাঠামো প্রদর তাছাড়াও, আমরা মনোযোগ দেখি এবং দেখাই যে প্রস্তাবিত মডেল এই প্রশ্নের প্রতি আরো গুরুত্বপূর্ণ সম্পর্কের ব্যাপারে আরো বেশী গুর</abstract_bn>
      <abstract_am>የቀድሞው የነበረው የራእይ ጥያቄ መልስ ነገር ግን የኖን አካባቢ ጥያቄ የሁሉንም ግንኙነት ማድረግ ትርጉም እና ከብዙ ግንኙነት አካባቢዎች ውጤቶችን ማሳየት ብቻ ነው፡፡ በዚህ ገጽ፣ ይህ ጉዳይ ለመጠቀም በብዙ የዓይነት ግንኙነትን የሚያሳውቅ የአንባቢ ደረጃ መሠረት እናሳልቃለን፡፡ በተለይም፣ የጥያቄን ጥያቄ እና የኮድ አካባቢዎችን በመጠቀም እና በመጠቀም የጥያቄ ሚዛኖችን በመጠቀም እናደርጋለን፡፡ በተማረ ትኩረት ሚዛን በመጠቀም፣ በተዘጋጀው ሞዴል የተፈቃደውን የግንኙነት ግንኙነት ለጥያቄ ጥያቄ እንዲጠቀም ይችላል፡፡ የVQA 2.0 ዳታ setup ፈተና ውጤቶች የተዘጋጀው ሞዴል የአሁኑን የግራፍ ትኩረት የመረጃ መሠረት ማድረጊያዎችን እንዲያሳየው ያሳያል፡፡ በተጨማሪም፣ ማስታወቂያውን እናሳየዋለን፣ የተዘጋጀውም ሞዴል ለጥያቄው በተጠቃሚ ግንኙነት ላይ ከፍተኛ ሚዛንን እናሳየዋለን፡፡</abstract_am>
      <abstract_ca>Previous existing visual question answering (VQA) systems commonly use graph neural networks(GNNs) to extract visual relationships such as semantic relations or spatial relations.  However, studies that use GNNs typically ignore the importance of each relation and simply concatenate outputs from multiple relation encoders.  En aquest article proposem una nova arquitectura de capa que fusiona múltiples relacions visuals a través d'un mecanisme d'atenció per abordar aquest tema. Concretament, desenvolupem un model que utilitza l'incorporació de preguntes i l'incorporació conjunta dels codificadors per obtenir pes dinàmics d'atenció en relació amb el tipus de preguntes. Utilitzant els pes d'atenció aprendibles, el model proposat pot utilitzar eficientment les característiques de relació visual necessàries per una pregunta dada. Els resultats experimentals del conjunt de dades VQA 2.0 demostren que el model proposat supera les arquitectures existents basades en la xarxa d'atenció gràfica. A més, visualitzem el pes de l'atenció i demostrem que el model proposat afegeix un pes més gran a les relacions més rellevants a la pregunta.</abstract_ca>
      <abstract_fi>Aiemmat visuaaliset kysymyksenvastausj瓣rjestelm瓣t k瓣ytt瓣v瓣t yleisesti graafisia neuroverkkoja (GNN) visuaalisten suhteiden, kuten semanttisten suhteiden tai spatiaalisten suhteiden, poimimiseen. Kuitenkin GNN:it瓣 k瓣ytt瓣v瓣t tutkimukset yleens瓣 sivuuttavat kunkin suhteen merkityksen ja yksinkertaisesti yhdist瓣v瓣t tuotokset useista relaatiokoodereista. T瓣ss瓣 ty繹ss瓣 ehdotamme uudenlaista kerrosarkkitehtuuria, joka yhdist瓣瓣 useita visuaalisia suhteita huomiomekanismin avulla ongelman ratkaisemiseksi. Erityisesti kehit瓣mme mallin, joka k瓣ytt瓣瓣 koodereiden kysymysupotusta ja yhteisupotusta saadaksemme dynaamisia huomiopainoja kysymystyyppiin n瓣hden. Oppitavissa olevien huomiopainojen avulla ehdotettu malli pystyy tehokkaasti k瓣ytt瓣m瓣瓣n tiettyyn kysymykseen tarvittavia visuaalisia suhdeominaisuuksia. Kokeelliset tulokset VQA 2.0 -aineistosta osoittavat, ett瓣 ehdotettu malli on parempi kuin olemassa olevat graafisen huomion verkkopohjaiset arkkitehtuurit. Lis瓣ksi visualisoimme huomion painoarvon ja osoitamme, ett瓣 ehdotettu malli antaa suuremman painoarvon suhteessa, joka on merkityksellisempi kysymykseen.</abstract_fi>
      <abstract_bs>Prethodni sustavi odgovora na vizualno pitanje (VQA) obično koriste grafičke neuralne mreže (GNN) za izvlačenje vizuelnih odnosa poput semantičkih odnosa ili prostornih odnosa. Međutim, ispitivanja koje koriste GNN obično ignoriraju važnost svakog odnosa i jednostavno potvrđuju ishod od od višestrukih kodera veza. U ovom papiru predlažemo novu arhitekturu slojeva koja spaja višestruke vizualne odnose kroz mehanizam pažnje za rješavanje ovog pitanja. Posebno, razvijamo model koji koristi integraciju pitanja i zajedničku integraciju kodera kako bi dobili dinamičnu težinu pažnje u odnosu na vrste pitanja. Koristeći težine učenja pažnje, predloženi model može učinkovito koristiti potrebne vizualne veze za određeno pitanje. Eksperimentalni rezultati na setu podataka VQA 2.0 pokazuju da predloženi model iznosi postojeće arhitekture na mreži pod pažnjom grafika. Osim toga, mi vizualiziramo težinu pažnje i pokazujemo da predloženi model dodaje veću težinu odnosima koje su važnije za pitanje.</abstract_bs>
      <abstract_et>Varasemad olemasolevad visuaalsed küsimustele vastamise süsteemid kasutavad tavaliselt graafiliste närvivõrkude (GNN) ekstraheerimiseks visuaalseid suhteid, näiteks semantilisi suhteid või ruumilisi suhteid. Kuid GNN-sid kasutavad uuringud eiravad tavaliselt iga seose tähtsust ja lihtsalt siduvad väljundid mitmest seoskodeerijast. Käesolevas töös pakume välja uudse kihi arhitektuuri, mis ühendab mitmed visuaalsed suhted läbi tähelepanumehhanismi selle probleemi lahendamiseks. Täpsemalt töötame välja mudeli, mis kasutab kodeerijate küsimuste manustamist ja ühist manustamist, et saada dünaamilist tähelepanu kaalu küsimuste tüübile. Kasutades õppitavaid tähelepanukaalusid, saab kavandatud mudel tõhusalt kasutada konkreetse küsimuse jaoks vajalikke visuaalse suhte funktsioone. VQA 2.0 andmekogumi eksperimentaalsed tulemused näitavad, et kavandatud mudel ületab olemasolevaid graafilise tähelepanu võrgupõhiseid arhitektuure. Lisaks visualiseerime tähelepanu kaalu ja näitame, et kavandatud mudel annab suurema kaalu suhetele, mis on küsimusele olulisemad.</abstract_et>
      <abstract_he>מערכות שעובדות על שאלות חזותיות (VQA) קיימות קודמות משתמשות בדרך כלל ברשתות עצביות גרף (GNNs) כדי לחלץ מערכות יחסים חזותיות כמו מערכות יחסים סמנטיות או יחסים חלליים. למרות זאת, מחקרים שמשתמשים ב-GNN בדרך כלל מתעלמים מהחשיבות של כל מערכת יחסים ופשוט משתמשים בתוצאות ממקודדים יחסים רבים. בעיתון הזה, אנו מציעים ארכיטקטורה שכבה חדשה שמרכיבת יחסים חזותיים רבים דרך מנגנון תשומת לב כדי להתמודד עם הנושא הזה. במיוחד, אנחנו מפתחים מודל שמשתמש בתכנית שאלות ותכנית משותפת של הקודנים כדי להשיג משקלי תשומת לב דינמיים בנוגע לסוג השאלות. בשימוש במשקל תשומת לב ללמוד, המודל המוצע יכול להשתמש באופן יעיל בתוכניות יחסים ויזואליים הנדרשים לשאלה מסוימת. תוצאות ניסיוניות על קבוצת נתונים VQA 2.0 מראות שהמודל המוצע עולה על ארכיטקטורות רשת תשומת לב גרף קיימת. בנוסף, אנו מדמיינים את משקל תשומת לב ולהראות שהמודל המוצע מצביע משקל גבוה יותר ליחסים שיהיו יותר רלוונטיים לשאלה.</abstract_he>
      <abstract_jv>Rasané sing gawe personan gambar ngganti (VqA) sistem sing dikenalke Jejaring (GNNs) nggawe barang nggambar barang nggambar barang nggambar barang kering Nanging, akeh basa sing paling nggambar GNNs kuwi bagian nggawe gerakan luwih dumateng kanggo nggawe barang nggawe barang seneng bongkar nggawe Nang pebuk iki, kita supoyata architecture sing nyebatasan kanggo ngilanggar aturan anyar tentang karo iso nggawe barang nggawe aturan tapi kanggo nganggo kuwi kesempatan iki. Alang-alang, kita ngubah model sing bisa ngubah ingkang inset lan ijol-ijolan koder Jejaring Perintah sing paling nggambar VqA 2.0 dataset kuwi bisalahan nggawe model sing supoyo nggawe barang nggawe aturan sing paling nggambar maneh. Nanging tambah, awak dhéwé ngerasakno ateng lan wong-wong kuwi model sing apik gedhéwé nggawe barang sing luwih apik kanggo wong liya sing dikarepaké awak dhéwé.</abstract_jv>
      <abstract_ha>@ info A lokacin da aka yi amfani da GNNs, ana ƙyale muhimmin haɗi duk kuma ana ƙayyade masu fitarwa daga kodkodi masu yawa. Ga wannan takardan, Munã buɗa wani matsayin bangon nowaya wanda ke ƙara masu haɗi da gannai masu yawa, a kan wani matsayin muhalli da za'a yi masa magana ga wannan masu husũma. A ƙayyade, munã buɗe wani motel wanda ke amfani da tambayar ta cikin shirin kode da ke haɗa shi dõmin ka sami nau'i masu nau'i ga nau'in zũciya da nau'in tambayar. Yi amfani da masu nauyi da za'a sanar da shi, shirin da aka buƙata, yana iya amfani da fasahan tsarin haɗi na gane wa wani tambayi wanda aka ƙayyade. Experimental results on the VQA 2.0 dataset demonstrate that the proposed model outperforms existing graph attention network-based architectures.  Ina ƙaranci, za mu gani masu nauyi kuma mu nuna cewa misalin da aka buƙata shi yana da nauyi mafi girma ga danganta waɗand a ke da mafiya amfani ga tambayar.</abstract_ha>
      <abstract_sk>Prejšnji obstoječi sistemi za vizualno odgovarjanje na vprašanja (VQA) običajno uporabljajo grafska nevronska omrežja (GNN) za izvlečevanje vizualnih odnosov, kot so semantične odnose ali prostorske odnose. Vendar pa študije, ki uporabljajo GNN, običajno ignorirajo pomen vsake relacije in preprosto povezujejo izhode iz več relacijskih kodirnikov. V prispevku predlagamo novo slojno arhitekturo, ki združuje več vizualnih odnosov skozi mehanizem pozornosti za reševanje tega vprašanja. Natančneje smo razvili model, ki uporablja vgradnjo vprašanj in skupno vgradnjo kodirnikov za pridobivanje dinamičnih uteži pozornosti glede na vrsto vprašanj. S pomočjo učnih uteži pozornosti lahko predlagani model učinkovito uporablja potrebne značilnosti vizualnega odnosa za določeno vprašanje. Eksperimentalni rezultati podatkovnega nabora VQA 2.0 kažejo, da predlagani model presega obstoječe arhitekture, ki temeljijo na omrežju. Poleg tega vizualiziramo težo pozornosti in pokažemo, da predlagani model pripisuje večjo težo odnosom, ki so bolj pomembni za vprašanje.</abstract_sk>
      <abstract_fil>Ang mga kasalukuyang pagsagot ng visual question (VQA) na mga sistema ay karaniwang gamitin ang graph neural networks(GNNs) upang kumuha ng visual relationships tulad ng semantic relations o spatial relations. Gayon ma'y ang mga pag-aaral na gumagamit ng GNN ay walang kabuluhan ang mahalaga ng bawa't relasyon at ang mga outputs mula sa multiple relation encoders. Sa papiro na ito, iniuutos namin ang isang bagong layer architecture na nagbibigay ng maraming visual relationships sa pamamagitan ng attention mechanism upang makausap ng problemang ito. Sa takdang paraan, kami ay naglalabas ng model na gumagamit ng tanong na embedding at joint embedding ng mga encoder upang makakuha ng dinamikang pakinabang tungkol sa uri ng tanong. Sa paggamit ng mga timbang ng pagtutunan ng pag-aaral, maaaring magagamit ang pangangailangan ng mga karakterístikang visual relation para sa isang tanong na ibinigay. Ang mga resulta ng eksperimento sa VQA 2.0 dataset ay nagpapakita na ang proponeso na modelo ay hindi nagbibigay ng mga arkitektura na nagbabasid sa mga kasalukuyang pagbabantay ng graph attention. Dahil dito, nakikita namin ang bigat ng pakikita at ipinakikita namin na ang proponeso na model ay nagbibigay ng lalong mataas na timbang sa mga relasyon na mas mahalaga sa tanong.</abstract_fil>
      <abstract_bo>སྔོན་མ་ཡོད་པའི་མཐོང་བའི་འདྲི་ཚིག་ལ་ལན་གསལ་བ(VQA)མ་ལག ཡིན་ནའང་། གནད་དོན་རིས་སྤྱོད་པའི་ལྟ་བུ་དག་ནི་འབྲེལ་བ་སོ་སོའི་གལ་ཆེ་བ་སྣང འུ་ཅག་གིས་ཤོག་བུ་འདིའི་ནང་དུ་ལྟ་བུའི་མཐོང་སྣང་དང་མཐོང་ནུས་མཐུན་སྒྲིག་ཆ་གསར་པ་ཞིག་སྤྲོད་ཀྱི་ཡོད། ང་ཚོས་དབྱིབས་གསལ་བཤད་ཀྱི་རྣམ་པ་ཞིག་གསར་འཛུགས་བྱས་ནས་འདྲི་ཚིག ཤོག་བྱེད་རུང་བའི་བསམ་བློ་གཏོང་ཚད་སྤྱོད་སྤྱད་ནས་འཆར་ཡོད་པའི་མིག་ཆས་དེ་དམིགས་འཛུགས་ཀྱི་རྣམ་པ VQA 2 འོན་ཀྱང་། ང་ཚོས་བློ་གཏོང་གི་ཆེ་ལ་ལྟ་བུ་འཇུག</abstract_bo>
      </paper>
  </volume>
</collection>