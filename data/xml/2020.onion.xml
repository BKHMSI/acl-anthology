<collection id="2020.onion">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of LREC2020 Workshop "People in language, vision and the mind" (ONION2020)</booktitle>
      <editor><first>Patrizia</first><last>Paggio</last></editor>
      <editor><first>Albert</first><last>Gatt</last></editor>
      <editor><first>Roman</first><last>Klinger</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-70-2</isbn>
    </meta>
    <frontmatter>
      <url hash="d9186cde">2020.onion-1.0</url>
      <bibkey>onion-2020-lrec2020</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Analysis of Body Behaviours in Human-Human and Human-Robot Interactions</title>
      <author><first>Taiga</first><last>Mori</last></author>
      <author><first>Kristiina</first><last>Jokinen</last></author>
      <author><first>Yasuharu</first><last>Den</last></author>
      <pages>7&#8211;14</pages>
      <abstract>We conducted preliminary comparison of human-robot (HR) interaction with human-human (HH) interaction conducted in English and in Japanese. As the result, body gestures increased in HR, while hand and head gestures decreased in HR. Concerning hand gesture, they were composed of more diverse and complex forms, trajectories and functions in HH than in HR. Moreover, English speakers produced 6 times more hand gestures than Japanese speakers in HH. Regarding head gesture, even though there was no difference in the frequency of head gestures between English speakers and Japanese speakers in HH, Japanese speakers produced slightly more nodding during the robot&#8217;s speaking than English speakers in HR. Furthermore, positions of nod were different depending on the language. Concerning body gesture, participants produced body gestures mostly to regulate appropriate distance with the robot in HR. Additionally, English speakers produced slightly more body gestures than Japanese speakers.</abstract>
      <url hash="29b6f4db">2020.onion-1.2</url>
      <language>eng</language>
      <bibkey>mori-etal-2020-analysis</bibkey>
    </paper>
    <paper id="5">
      <title>Improving Sentiment Analysis with Biofeedback Data</title>
      <author><first>Daniel</first><last>Schl&#246;r</last></author>
      <author><first>Albin</first><last>Zehe</last></author>
      <author><first>Konstantin</first><last>Kobs</last></author>
      <author><first>Blerta</first><last>Veseli</last></author>
      <author><first>Franziska</first><last>Westermeier</last></author>
      <author><first>Larissa</first><last>Br&#252;bach</last></author>
      <author><first>Daniel</first><last>Roth</last></author>
      <author><first>Marc Erich</first><last>Latoschik</last></author>
      <author><first>Andreas</first><last>Hotho</last></author>
      <pages>28&#8211;33</pages>
      <abstract>Humans frequently are able to read and interpret emotions of others by directly taking verbal and non-verbal signals in human-to-human communication into account or to infer or even experience emotions from mediated stories. For computers, however, emotion recognition is a complex problem: Thoughts and feelings are the roots of many behavioural responses and they are deeply entangled with neurophysiological changes within humans. As such, emotions are very subjective, often are expressed in a subtle manner, and are highly depending on context. For example, machine learning approaches for text-based sentiment analysis often rely on incorporating sentiment lexicons or language models to capture the contextual meaning. This paper explores if and how we further can enhance sentiment analysis using biofeedback of humans which are experiencing emotions while reading texts. Specifically, we record the heart rate and brain waves of readers that are presented with short texts which have been annotated with the emotions they induce. We use these physiological signals to improve the performance of a lexicon-based sentiment classifier. We find that the combination of several biosignals can improve the ability of a text-based classifier to detect the presence of a sentiment in a text on a per-sentence level.</abstract>
      <url hash="1b303c6b">2020.onion-1.5</url>
      <language>eng</language>
      <bibkey>schlor-etal-2020-improving</bibkey>
    </paper>
  </volume>
</collection>