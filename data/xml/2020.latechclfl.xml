<collection id="2020.latechclfl">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the The 4th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</booktitle>
      <editor><first>Stefania</first><last>DeGaetano</last></editor>
      <editor><first>Anna</first><last>Kazantseva</last></editor>
      <editor><first>Nils</first><last>Reiter</last></editor>
      <editor><first>Stan</first><last>Szpakowicz</last></editor>
      <publisher>International Committee on Computational Linguistics</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="3b16801f">2020.latechclfl-1.0</url>
      <bibkey>latechclfl-2020-joint</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Automatic Topological Field Identification in (Historical) <fixed-case>G</fixed-case>erman Texts</title>
      <author><first>Katrin</first><last>Ortmann</last></author>
      <pages>10&#8211;18</pages>
      <abstract>For the study of certain linguistic phenomena and their development over time, large amounts of textual data must be enriched with relevant annotations. Since the manual creation of such annotations requires a lot of effort, automating the process with NLP methods would be convenient. But the required amounts of training data are usually not available for non-standard or historical language. The present study investigates whether models trained on modern newspaper text can be used to automatically identify topological fields, i.e. syntactic structures, in different modern and historical German texts. The evaluation shows that, in general, it is possible to transfer a parser model to other registers or time periods with overall F1-scores &gt;92%. However, an error analysis makes clear that additional rules and domain-specific training data would be beneficial if sentence structures differ significantly from the training data, e.g. in the case of Early New High German.</abstract>
      <url hash="199e90f9">2020.latechclfl-1.2</url>
      <bibkey>ortmann-2020-automatic</bibkey>
      <pwccode url="https://github.com/rubcompling/latech2020" additional="false">rubcompling/latech2020</pwccode>
    </paper>
    <paper id="5">
      <title>Neural Machine Translation of Artwork Titles Using Iconclass Codes</title>
      <author><first>Nikolay</first><last>Banar</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <author><first>Mike</first><last>Kestemont</last></author>
      <pages>42&#8211;51</pages>
      <abstract>We investigate the use of Iconclass in the context of neural machine translation for NL&lt;-&gt;EN artwork titles. Iconclass is a widely used iconographic classification system used in the cultural heritage domain to describe and retrieve subjects represented in the visual arts. The resource contains keywords and definitions to encode the presence of objects, people, events and ideas depicted in artworks, such as paintings. We propose a simple concatenation approach that improves the quality of automatically generated title translations for artworks, by leveraging textual information extracted from Iconclass. Our results demonstrate that a neural machine translation system is able to exploit this metadata to boost the translation performance of artwork titles. This technology enables interesting applications of machine learning in resource-scarce domains in the cultural sector.</abstract>
      <url hash="f06236e9">2020.latechclfl-1.5</url>
      <bibkey>banar-etal-2020-neural</bibkey>
    </paper>
    <paper id="8">
      <title>Vital Records: Uncover the past from historical handwritten records</title>
      <author><first>Herve</first><last>Dejean</last></author>
      <author><first>Jean-Luc</first><last>Meunier</last></author>
      <pages>69&#8211;73</pages>
      <abstract>We present Vital Records, a demonstrator based on deep-learning approaches to handwritten-text recognition, table processing and information extraction, which enables data from century-old documents to be parsed and analysed, making it possible to explore death records in space and time. This demonstrator provides a user interface for browsing and visualising data extracted from 80,000 handwritten pages of tabular data.</abstract>
      <url hash="f55170c3">2020.latechclfl-1.8</url>
      <bibkey>dejean-meunier-2020-vital</bibkey>
    </paper>
    <paper id="11">
      <title>Life still goes on: Analysing <fixed-case>A</fixed-case>ustralian <fixed-case>WW</fixed-case>1 Diaries through Distant Reading</title>
      <author><first>Ashley</first><last>Dennis-Henderson</last></author>
      <author><first>Matthew</first><last>Roughan</last></author>
      <author><first>Lewis</first><last>Mitchell</last></author>
      <author><first>Jonathan</first><last>Tuke</last></author>
      <pages>90&#8211;104</pages>
      <abstract>An increasing amount of historic data is now available in digital (text) formats. This gives quantitative researchers an opportunity to use distant reading techniques, as opposed to traditional close reading, in order to analyse larger quantities of historic data. Distant reading allows researchers to view overall patterns within the data and reduce researcher bias. One such data set that has recently been transcribed is a collection of over 500 Australian World War I (WW1) diaries held by the State Library of New South Wales. Here we apply distant reading techniques to this corpus to understand what soldiers wrote about and how they felt over the course of the war. Extracting dates accurately is important as it allows us to perform our analysis over time, however, it is very challenging due to the variety of date formats and abbreviations diarists use. But with that data, topic modelling and sentiment analysis can then be applied to show trends, for instance, that despite the horrors of war, Australians in WW1 primarily wrote about their everyday routines and experiences. Our results detail some of the challenges likely to be encountered by quantitative researchers intending to analyse historical texts, and provide some approaches to these issues.</abstract>
      <url hash="0213c97c">2020.latechclfl-1.11</url>
      <bibkey>dennis-henderson-etal-2020-life</bibkey>
    </paper>
    <paper id="14">
      <title>Results of a Single Blind Literary Taste Test with Short Anonymized Novel Fragments</title>
      <author><first>Andreas</first><last>van Cranenburgh</last></author>
      <author><first>Corina</first><last>Koolen</last></author>
      <pages>121&#8211;126</pages>
      <abstract>It is an open question to what extent perceptions of literary quality are derived from text-intrinsic versus social factors. While supervised models can predict literary quality ratings from textual factors quite successfully, as shown in the Riddle of Literary Quality project (Koolen et al., 2020), this does not prove that social factors are not important, nor can we assume that readers make judgments on literary quality in the same way and based on the same information as machine learning models. We report the results of a pilot study to gauge the effect of textual features on literary ratings of Dutch-language novels by participants in a controlled experiment with 48 participants. In an exploratory analysis, we compare the ratings to those from the large reader survey of the Riddle in which social factors were not excluded, and to machine learning predictions of those literary ratings. We find moderate to strong correlations of questionnaire ratings with the survey ratings, but the predictions are closer to the survey ratings. Code and data: https://github.com/andreasvc/litquest</abstract>
      <url hash="dfc08e87">2020.latechclfl-1.14</url>
      <bibkey>van-cranenburgh-koolen-2020-results</bibkey>
      <pwccode url="https://github.com/andreasvc/litquest" additional="false">andreasvc/litquest</pwccode>
    </paper>
    <paper id="17">
      <title>Interpretation of Sentiment Analysis in Aeschylus&#8217;s <fixed-case>G</fixed-case>reek Tragedy</title>
      <author><first>Vijaya Kumari</first><last>Yeruva</last></author>
      <author><first>Mayanka</first><last>ChandraShekar</last></author>
      <author><first>Yugyung</first><last>Lee</last></author>
      <author><first>Jeff</first><last>Rydberg-Cox</last></author>
      <author><first>Virginia</first><last>Blanton</last></author>
      <author><first>Nathan A</first><last>Oyler</last></author>
      <pages>138&#8211;146</pages>
      <abstract>Recent advancements in NLP and machine learning have created unique challenges and opportunities for digital humanities research. In particular, there are ample opportunities for NLP and machine learning researchers to analyze data from literary texts and to broaden our understanding of human sentiment in classical Greek tragedy. In this paper, we will explore the challenges and benefits from the human and machine collaboration for sentiment analysis in Greek tragedy and address some open questions related to the collaborative annotation for the sentiments in literary texts. We focus primarily on (i) an analysis of the challenges in sentiment analysis tasks for humans and machines, and (ii) whether consistent annotation results are generated from the multiple human annotators and multiple machine annotators. For human annotators, we have used a survey-based approach with about 60 college students. We have selected three popular sentiment analysis tools for machine annotators, including VADER, CoreNLP&#8217;s sentiment annotator, and TextBlob. We have conducted a qualitative and quantitative evaluation and confirmed our observations on sentiments in Greek tragedy.</abstract>
      <url hash="c980bd19">2020.latechclfl-1.17</url>
      <bibkey>yeruva-etal-2020-interpretation</bibkey>
    </paper>
    <paper id="19">
      <title>Finding and Generating a Missing Part for Story Completion</title>
      <author><first>Yusuke</first><last>Mori</last></author>
      <author><first>Hiroaki</first><last>Yamane</last></author>
      <author><first>Yusuke</first><last>Mukuta</last></author>
      <author><first>Tatsuya</first><last>Harada</last></author>
      <pages>156&#8211;166</pages>
      <abstract>Creating a story is difficult. Professional writers often experience a writer&#8217;s block. Thus, providing automatic support to writers is crucial but also challenging. Recently, in the field of generating and understanding stories, story completion (SC) has been proposed as a method for generating missing parts of an incomplete story. Despite this method&#8217;s usefulness in providing creative support, its applicability is currently limited because it requires the user to have prior knowledge of the missing part of a story. Writers do not always know which part of their writing is flawed. To overcome this problem, we propose a novel approach called &#8220;missing position prediction (MPP).&#8221; Given an incomplete story, we aim to predict the position of the missing part. We also propose a novel method for MPP and SC. We first conduct an experiment focusing on MPP, and our analysis shows that highly accurate predictions can be obtained when the missing part of a story is the beginning or the end. This suggests that if a story has a specific beginning or end, they play significant roles. We conduct an experiment on SC using MPP, and our proposed method demonstrates promising results.</abstract>
      <url hash="76cbf0ef">2020.latechclfl-1.19</url>
      <bibkey>mori-etal-2020-finding</bibkey>
      <pwccode url="https://github.com/mil-tokyo/missing-position-prediction" additional="false">mil-tokyo/missing-position-prediction</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rocstories">ROCStories</pwcdataset>
    </paper>
    </volume>
</collection>