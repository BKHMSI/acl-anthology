<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.sigdial">
  <volume id="1" ingest-date="2021-08-12">
    <meta>
      <booktitle>Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue</booktitle>
      <editor><first>Haizhou</first><last>Li</last></editor>
      <editor><first>Gina-Anne</first><last>Levow</last></editor>
      <editor><first>Zhou</first><last>Yu</last></editor>
      <editor><first>Chitralekha</first><last>Gupta</last></editor>
      <editor><first>Berrak</first><last>Sisman</last></editor>
      <editor><first>Siqi</first><last>Cai</last></editor>
      <editor><first>David</first><last>Vandyke</last></editor>
      <editor><first>Nina</first><last>Dethlefs</last></editor>
      <editor><first>Yan</first><last>Wu</last></editor>
      <editor><first>Junyi Jessy</first><last>Li</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore and Online</address>
      <month>July</month>
      <year>2021</year>
      <url hash="605ef8f6">2021.sigdial-1</url>
    </meta>
    <frontmatter>
      <url hash="c6cff5ff">2021.sigdial-1.0</url>
      <bibkey>sigdial-2021-special</bibkey>
    </frontmatter>
    <paper id="4">
      <title>Individual Interaction Styles : Evidence from a Spoken Chat Corpus</title>
      <author><first>Nigel</first><last>Ward</last></author>
      <pages>27–31</pages>
      <abstract>here is increasing interest in modeling style choices in <a href="https://en.wikipedia.org/wiki/Dialogue">dialog</a>, for example for enabling <a href="https://en.wikipedia.org/wiki/Dialogue">dialog systems</a> to adapt to their users. It is commonly assumed that each user has his or her own stable characteristics, but for interaction style the truth of this assumption has not been well examined. I investigated using a vector-space model of interaction styles, derived from the Switchboard corpus of telephone conversations and a broad set of prosodic-behavior features. While most individuals exhibited interaction style tendencies, these were generally far from stable, with a <a href="https://en.wikipedia.org/wiki/Predictive_modelling">predictive model</a> based on individual tendencies outperforming a speaker-independent model by only 3.6 %. The tendencies were somewhat stronger for some speakers, including generally males, and for some dimensions of variation.</abstract>
      <url hash="269878c8">2021.sigdial-1.4</url>
      <bibkey>ward-2021-individual</bibkey>
      <video href="https://www.youtube.com/watch?v=cSNGdDL-MVY" />
    </paper>
    <paper id="6">
      <title>Improving Named Entity Recognition in Spoken Dialog Systems by Context and Speech Pattern Modeling</title>
      <author><first>Minh</first><last>Nguyen</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>45–55</pages>
      <abstract>While named entity recognition (NER) from <a href="https://en.wikipedia.org/wiki/Speech">speech</a> has been around as long as NER from written text has, the accuracy of NER from <a href="https://en.wikipedia.org/wiki/Speech">speech</a> has generally been much lower than that of NER from <a href="https://en.wikipedia.org/wiki/Written_language">text</a>. The rise in popularity of spoken dialog systems such as <a href="https://en.wikipedia.org/wiki/Siri">Siri</a> or <a href="https://en.wikipedia.org/wiki/Amazon_Alexa">Alexa</a> highlights the need for more accurate <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">NER</a> from speech because <a href="https://en.wikipedia.org/wiki/Natural_language_understanding">NER</a> is a core component for understanding what users said in dialogs. Deployed spoken dialog systems receive user input in the form of automatic speech recognition (ASR) transcripts, and simply applying NER model trained on written text to ASR transcripts often leads to low accuracy because compared to written text, ASR transcripts lack important cues such as <a href="https://en.wikipedia.org/wiki/Punctuation">punctuation</a> and <a href="https://en.wikipedia.org/wiki/Capitalization">capitalization</a>. Besides, errors in ASR transcripts also make <a href="https://en.wikipedia.org/wiki/Near-infrared_spectroscopy">NER</a> from <a href="https://en.wikipedia.org/wiki/Speech">speech</a> challenging. We propose two models that exploit dialog context and speech pattern clues to extract named entities more accurately from open-domain dialogs in spoken dialog systems. Our results show the benefit of modeling dialog context and speech patterns in two settings : a standard setting with random partition of data and a more realistic but also more difficult setting where many named entities encountered during deployment are unseen during training.</abstract>
      <url hash="ab415bae">2021.sigdial-1.6</url>
      <bibkey>nguyen-yu-2021-improving</bibkey>
      <video href="https://www.youtube.com/watch?v=JIGvcylPvPI" />
    </paper>
    <paper id="7">
      <title>SoDA : On-device Conversational Slot Extraction<fixed-case>S</fixed-case>o<fixed-case>DA</fixed-case>: On-device Conversational Slot Extraction</title>
      <author><first>Sujith</first><last>Ravi</last></author>
      <author><first>Zornitsa</first><last>Kozareva</last></author>
      <pages>56–65</pages>
      <abstract>We propose a novel on-device neural sequence labeling model which uses embedding-free projections and character information to construct compact word representations to learn a sequence model using a combination of bidirectional LSTM with self-attention and CRF. Unlike typical dialog models that rely on huge, complex neural network architectures and large-scale pre-trained Transformers to achieve state-of-the-art results, our method achieves comparable results to BERT and even outperforms its smaller variant DistilBERT on conversational slot extraction tasks. Our method is faster than BERT models while achieving significant model size reductionour model requires 135x and 81x fewer model parameters than BERT and DistilBERT, respectively. We conduct experiments on multiple conversational datasets and show significant improvements over existing methods including recent on-device models. Experimental results and ablation studies also show that our neural models preserve tiny memory footprint necessary to operate on smart devices, while still maintaining high performance.</abstract>
      <url hash="6d8b59c4">2021.sigdial-1.7</url>
      <bibkey>ravi-kozareva-2021-soda</bibkey>
      <video href="https://www.youtube.com/watch?v=0hDaafkctwI" />
    </paper>
    <paper id="9">
      <title>ARTA : Collection and Classification of Ambiguous Requests and Thoughtful Actions<fixed-case>ARTA</fixed-case>: Collection and Classification of Ambiguous Requests and Thoughtful Actions</title>
      <author><first>Shohei</first><last>Tanaka</last></author>
      <author><first>Koichiro</first><last>Yoshino</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <pages>77–88</pages>
      <abstract>Human-assisting systems such as dialogue systems must take thoughtful, appropriate actions not only for clear and unambiguous user requests, but also for ambiguous user requests, even if the users themselves are not aware of their potential requirements. To construct such a dialogue agent, we collected a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and developed a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> that classifies ambiguous user requests into corresponding system actions. In order to collect a high-quality corpus, we asked workers to input antecedent user requests whose pre-defined actions could be regarded as thoughtful. Although multiple actions could be identified as thoughtful for a single <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">user request</a>, annotating all combinations of <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">user requests</a> and <a href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">system actions</a> is impractical. For this reason, we fully annotated only the test data and left the annotation of the training data incomplete. In order to train the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification model</a> on such training data, we applied the positive / unlabeled (PU) learning method, which assumes that only a part of the data is labeled with positive examples. The experimental results show that the PU learning method achieved better performance than the general positive / negative (PN) learning method to classify thoughtful actions given an ambiguous user request.</abstract>
      <url hash="8119cb08">2021.sigdial-1.9</url>
      <bibkey>tanaka-etal-2021-arta</bibkey>
      <video href="https://www.youtube.com/watch?v=Y4OAaQzoIhA" />
      <pwccode url="https://github.com/ahclab/arta_corpus" additional="false">ahclab/arta_corpus</pwccode>
    </paper>
    <paper id="14">
      <title>Velocidapter : Task-oriented Dialogue Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title>
      <author><first>Ibrahim Taha</first><last>Aksu</last></author>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>133–143</pages>
      <abstract>We introduce a synthetic dialogue generation framework, Velocidapter, which addresses the corpus availability problem for dialogue comprehension. Velocidapter augments datasets by simulating synthetic conversations for a task-oriented dialogue domain, requiring a small amount of bootstrapping work for each new domain. We evaluate the efficacy of our framework on a task-oriented dialogue comprehension dataset, MRCWOZ, which we curate by annotating questions for slots in the restaurant, taxi, and hotel domains of the MultiWOZ 2.2 dataset (Zang et al., 2020). We run experiments within a low-resource setting, where we pretrain a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on SQuAD, fine-tuning it on either a small original data or on the synthetic data generated by our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a>. Velocidapter shows significant improvements using both the transformer-based BERTBase and BiDAF as base models. We further show that the <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> is easy to use by novice users and conclude that Velocidapter can greatly help training over task-oriented dialogues, especially for low-resourced emerging domains.</abstract>
      <url hash="88cab37f">2021.sigdial-1.14</url>
      <bibkey>aksu-etal-2021-velocidapter</bibkey>
      <video href="https://www.youtube.com/watch?v=2BkbrFFGTFA" />
      <pwccode url="https://github.com/cuthalionn/velocidapter" additional="false">cuthalionn/velocidapter</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
    <title_ar>Velocidapter: النمذجة الحوارية الموجهة نحو المهام المقترنة بإنشاء نص اصطناعي مع تكييف المجال</title_ar>
      <title_pt>Velocidapter: Modelagem de Compreensão de Diálogo Orientado a Tarefas Emparelhando Geração de Texto Sintético com Adaptação de Domínio</title_pt>
      <title_es>Velocidapter: modelado de comprensión de diálogo orientado a tareas que empareja la generación de texto sintético con la adaptación de dominios</title_es>
      <title_ja>Velocidapter ：タスク指向のダイアログ理解モデリング合成テキスト生成とドメイン適応</title_ja>
      <title_zh>Velocidapter曰:向言建模将合文成与域应配对</title_zh>
      <title_hi>Velocidapter: कार्य उन्मुख संवाद समझ मॉडलिंग डोमेन अनुकूलन के साथ सिंथेटिक पाठ पीढ़ी युग्मन</title_hi>
      <title_ga>Velocidapter: Samhaltú Tuisceana Comhphlé Tasc-dhírithe Ag Péireáil Giniúint Téacs Sintéiseach le hoiriúnú Fearainn</title_ga>
      <title_el>Βελοκωδικοποιητής: Η κατανόηση διαλόγου προσανατολισμένη στην εργασία μοντελοποίηση ζευγαρώνοντας τη δημιουργία συνθετικού κειμένου με την προσαρμογή τομέα</title_el>
      <title_hu>Velocidapter: feladatorientált párbeszéd átfogó modellezés Szintetikus szöveggenerálás párosítása tartomány adaptációval</title_hu>
      <title_ka>სინტეტიკური სინტეტიკური ტექსტის შექმნა დიალოგის კომპრენზიცია</title_ka>
      <title_it>Velocidapter: Modellazione di comprensione del dialogo orientata alle attività Associare la generazione di testo sintetico con l'adattamento del dominio</title_it>
      <title_lt>Greitasis adaptatorius: į užduotis orientuotas dialogas Komprensinis modeliavimas poravimo sintetinio teksto generavimas su domeno pritaikymu</title_lt>
      <title_mk>Велоцидаптер: Ориентиран на задачите дијалог со компромензија Моделирање на парење синтетички текст генерација со адаптација на домен</title_mk>
      <title_kk>Жылдамдығы: Тапсырмалар бағытталған диалогты қисықтау үлгісі Тіркеу синтетикалық мәтін домен адаптациясы</title_kk>
      <title_ml>വെലോക്കോഡിപ്റ്റര്‍: ജോലി തിരിച്ചറിയപ്പെടുത്തിയ ഡയലോഗ് പുതുക്കുന്നതിനുള്ള മോഡില്‍ പെയിര്‍ സിനിറ്റിക് പദാ</title_ml>
      <title_ms>Velocidapter: Dialog Berorientasi-Tugas Pemahaman Modelan Perpasangan Jenerasi Teks Sintetik dengan Penyesuaian Domain</title_ms>
      <title_mn>Velocidapter: Task-oriented Dialog Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_mn>
      <title_mt>Veloċidaptur: Djalogu orjentat lejn ix-xogħol Komprensjoni Immudellar tal-Immudellar tat-Tekst Sintetiku tat-Tqabbil bl-Adattament tad-Domain</title_mt>
      <title_pl>Velocidapter: zorientowane na zadania dialogowe zrozumiałe modelowanie modeli syntetycznego generowania tekstu z adaptacją domeny</title_pl>
      <title_si>Velocidapter: වැඩ- ප්‍රමාණය සංවාදය සම්පූර්ණය සංවාදය සංවිධානය සමග සංවිධානය සංවිධානය</title_si>
      <title_no>Snøggtast: Oppgåveorientert dialogkomprehensingsmodellering av samarbeidsintetisk tekstgenerering med domeneadaptasjon</title_no>
      <title_ro>Velocidapter: Modelare de înțelegere a dialogului orientată spre activități Asocierea generarii textului sintetic cu adaptarea domeniului</title_ro>
      <title_sr>Velocidapter: Uređen na zadatke dijalog za komprenziju modela parenja sintetičkog teksta sa adaptacijom domena</title_sr>
      <title_so>Velocidapter: Digital Composition Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_so>
      <title_ta>வெல்லோகிடேப்டர்: பணி திருத்தப்பட்ட உரையாடல் முடிவு மாற்றுதல் ஒத்திசைப்படுத்தல் உரை உருவாக்கத்துடன் களம் மாற்றுதல்</title_ta>
      <title_ur>Velocidapter: Task-oriented Dialog Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_ur>
      <title_sv>Velocidapter: Uppgiftsorienterad dialog Förståelsemodellering Parning av syntetisk textgenerering med domänanpassning</title_sv>
      <title_vi>Name=ra tay Comment=Trình quản lý Name=Trình quản lý Name=Plugin ảnhName Comment</title_vi>
      <title_uz>Comment</title_uz>
      <title_bg>Създаване на синтетичен текст с адаптация на домейна</title_bg>
      <title_da>Velocidapter: Opgaveorienteret dialogforståelsesmodellering Parring af syntetisk tekstgenerering med domænetilpasning</title_da>
      <title_nl>Velocidapter: Taakgericht dialoogbegrip modelleren Koppeling synthetische tekstgeneratie met domeinaanpassing</title_nl>
      <title_hr>Velocidapter: modeliranje kompresije dijaloga na zadatku s prikladom domena</title_hr>
      <title_de>Velocidapter: Aufgabenorientierte DialogverstĂ¤ndnismodellierung Kopplung synthetischer Textgenerierung mit DomĂ¤nenanpassung</title_de>
      <title_id>Velocidapter: Dialog Berorientasi Tugas Memodeling Modeling Pairing Synthetic Text Generation dengan Adaptasi Domain</title_id>
      <title_ko>Velocidapter: 작업에 대한 대화 이해 모델링 - 합성 텍스트 생성과 영역 적응</title_ko>
      <title_fa>Velocidapter: نمونه‌سازی نمونه‌های متن سینتاتیک جفت با تغییر دامنه‌</title_fa>
      <title_sw>Velocidapter: Mpango wa Mpango wa Mpango wa Mpango wa Mpango wa Mpango wa Mpango wa Mipango na Uwekezaji wa Domain</title_sw>
      <title_tr>Çaltylık:Task-oriented Dialog Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_tr>
      <title_af>Velocidapter: Opdrag- orienteerde dialoog Komprimensie Modelering Pairing Sintetiese Teks Generasie met Domein Aanpassering</title_af>
      <title_sq>Velocidapter: Dialogu i orientuar ndaj detyrave Modelimi i modelimit të palëzimit të tekstit sintetik me adaptimin e domenit</title_sq>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_bn>ভেলোকিডাপ্টার: কাজের প্রতিষ্ঠিত ডায়ালগ সম্পাদন মোডেলিং সিনিটিক টেক্সট প্রজন্ম ডোমেইন অ্যাডাপ্যাটেশন সহ</title_bn>
      <title_az>Velocidapter: Task-oriented Dialog Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_az>
      <title_hy>Comment</title_hy>
      <title_bs>Velocidapter: modeliranje komprencije dijaloga orientiranog na zadatke za parenje sintetičkog teksta sa adaptacijom domena</title_bs>
      <title_ca>Velocidapter: Diàleg orientat a les tasques Comprension Modelling Pairing Synthetic Text Generation with Domain Adaptation</title_ca>
      <title_cs>Velociapter: Úlohově orientované dialogové pochopení modelů Párování syntetického textu s adaptací domény</title_cs>
      <title_et>Velocidapter: ülesannetele orienteeritud dialoogi läbimõistmise modelleerimine Sünteetilise teksti genereerimise sidumine domeeni kohandamisega</title_et>
      <title_fi>Velocidapter: Tehtävälähtöinen dialogin ymmärtämisen mallinnus Synteettisen tekstin luomisen parittaminen verkkotunnuksen mukauttamiseen</title_fi>
      <title_he>המהירות: דיאלוג ממוקד למשימות גילוי מודל ציור טקסט סינטטי של זוגות</title_he>
      <title_sk>Velocidapter: Modeliranje razumevanja dialoga, usmerjenega v opravila, združevanje ustvarjanja sintetičnega besedila s prilagajanjem domene</title_sk>
      <title_jv>Speed</title_jv>
      <title_ha>@ action</title_ha>
      <title_bo>Velocidapter: Task-oriented Dialogue Comprehension Modeling Pairing Synthetic Text Generation with Domain Adaptation</title_bo>
      <abstract_ar>نقدم إطار عمل إنشاء حوار تركيبي ، Velocidapter ، والذي يعالج مشكلة توفر المجموعة لفهم الحوار. يعمل Velocidapter على زيادة مجموعات البيانات عن طريق محاكاة المحادثات التركيبية لمجال حوار موجه نحو المهام ، مما يتطلب قدرًا صغيرًا من أعمال التمهيد لكل مجال جديد. نقوم بتقييم فعالية إطار العمل الخاص بنا في مجموعة بيانات فهم الحوار الموجه نحو المهام ، MRCWOZ ، والتي نقوم بتنسيقها من خلال التعليق على الأسئلة الخاصة بالفتحات في مجالات المطاعم وسيارات الأجرة والفنادق لمجموعة بيانات MultiWOZ 2.2 (Zang et al. ، 2020). نجري تجارب في بيئة منخفضة الموارد ، حيث نقوم بإجراء اختبار مسبق لنموذج على SQuAD ، ونقوم بضبطه إما على بيانات أصلية صغيرة أو على البيانات التركيبية التي تم إنشاؤها بواسطة إطار عملنا. يُظهر Velocidapter تحسينات كبيرة باستخدام كل من BERTBase القائم على المحولات و BiDAF كنماذج أساسية. نظهر كذلك أن إطار العمل سهل الاستخدام من قبل المستخدمين المبتدئين وخلصنا إلى أن Velocidapter يمكن أن يساعد بشكل كبير في التدريب على الحوارات الموجهة نحو المهام ، خاصةً للمجالات الناشئة منخفضة الموارد.</abstract_ar>
      <abstract_pt>Apresentamos um framework sintético de geração de diálogos, Velocidapter, que aborda o problema de disponibilidade de corpus para a compreensão do diálogo. O Velocidapter aumenta os conjuntos de dados simulando conversas sintéticas para um domínio de diálogo orientado a tarefas, exigindo uma pequena quantidade de trabalho de inicialização para cada novo domínio. Avaliamos a eficácia de nossa estrutura em um conjunto de dados de compreensão de diálogo orientado a tarefas, MRCWOZ, que selecionamos anotando perguntas para slots nos domínios de restaurante, táxi e hotel do conjunto de dados MultiWOZ 2.2 (Zang et al., 2020). Executamos experimentos em uma configuração de poucos recursos, onde pré-treinamos um modelo no SQuAD, ajustando-o em pequenos dados originais ou nos dados sintéticos gerados por nossa estrutura. O Velocidapter mostra melhorias significativas usando o BERTBase baseado em transformador e o BiDAF como modelos básicos. Mostramos ainda que a estrutura é fácil de usar por usuários iniciantes e concluímos que o Velocidapter pode ajudar muito no treinamento em diálogos orientados a tarefas, especialmente para domínios emergentes com poucos recursos.</abstract_pt>
      <abstract_es>Presentamos un marco de generación de diálogos sintéticos, Velocidapter, que aborda el problema de la disponibilidad de corpus para la comprensión del diálogo. Velocidapter aumenta los conjuntos de datos simulando conversaciones sintéticas para un dominio de diálogo orientado a tareas, lo que requiere una pequeña cantidad de trabajo de arranque para cada nuevo dominio. Evaluamos la eficacia de nuestro marco en un conjunto de datos de comprensión del diálogo orientado a tareas, MRCWOZ, que seleccionamos mediante la anotación de preguntas para espacios en los dominios de restaurantes, taxis y hoteles del conjunto de datos MultiWoz 2.2 (Zang et al., 2020). Realizamos experimentos en un entorno de pocos recursos, en el que preentrenamos un modelo en sQuad, ajustándolo en pequeños datos originales o en los datos sintéticos generados por nuestro marco. Velocidapter muestra mejoras significativas utilizando como modelos base tanto BertBase como BidAF basados en transformadores. Además, demostramos que el marco es fácil de usar para los usuarios novatos y concluimos que Velocidapter puede ayudar mucho a la capacitación sobre diálogos orientados a tareas, especialmente para dominios emergentes de bajos recursos.</abstract_es>
      <abstract_ja>対話の理解のためのコーパス可用性問題に取り組む合成対話生成フレームワーク、Velocidapterを導入しました。 Velocidapterは、タスク指向のダイアログドメインの合成会話をシミュレートすることでデータセットを拡張し、新しいドメインごとに少量のブートストラップ作業を必要とします。 私たちは、MultiWOZ 2.2データセット（ Zang et al., 2020 ）のレストラン、タクシー、およびホテルのドメイン内のスロットに関する質問に注釈を付けることによってキュレーションする、タスク指向の対話理解データセットMRCWOZのフレームワークの有効性を評価します。 私たちは、SQuADでモデルを事前にトレーニングし、小さなオリジナルデータまたはフレームワークによって生成された合成データのいずれかでモデルを微調整し、低リソース設定内で実験を実行します。 Velocidapterは、トランスベースのBERTBaseとBiDAFの両方をベースモデルとして使用して、大幅な改善を示しています。 さらに、このフレームワークは初心者のユーザーが簡単に使用できることを示し、Velocidapterは、特にリソースの少ない新興ドメインのために、タスク指向のダイアログでのトレーニングを大いに助けることができると結論づけています。</abstract_ja>
      <abstract_hi>हम एक सिंथेटिक संवाद पीढ़ी के ढांचे, Velocidapter, जो संवाद समझ के लिए कॉर्पस उपलब्धता समस्या को संबोधित करता है पेश करते हैं। Velocidapter एक कार्य उन्मुख संवाद डोमेन के लिए सिंथेटिक वार्तालापों का अनुकरण करके डेटासेट को बढ़ाता है, जिसमें प्रत्येक नए डोमेन के लिए बूटस्ट्रैपिंग कार्य की एक छोटी राशि की आवश्यकता होती है। हम एक कार्य-उन्मुख संवाद समझ डेटासेट, MRCWOZ पर हमारे ढांचे की प्रभावकारिता का मूल्यांकन करते हैं, जिसे हम मल्टीडब्ल्यूओजेड 2.2 डेटासेट (ज़ांग एट अल। हम एक कम संसाधन सेटिंग के भीतर प्रयोग चलाते हैं, जहां हम SQuAD पर एक मॉडल को प्रीट्रेन करते हैं, इसे या तो एक छोटे से मूल डेटा पर या हमारे ढांचे द्वारा उत्पन्न सिंथेटिक डेटा पर ठीक-ट्यूनिंग करते हैं। Velocidapter आधार मॉडल के रूप में दोनों ट्रांसफार्मर-आधारित BERTBase और BiDAF का उपयोग करके महत्वपूर्ण सुधार दिखाता है। हम आगे दिखाते हैं कि नौसिखिए उपयोगकर्ताओं द्वारा ढांचे का उपयोग करना आसान है और निष्कर्ष निकाला गया है कि वेलोसिडैप्टर कार्य-उन्मुख संवादों पर प्रशिक्षण में बहुत मदद कर सकता है, विशेष रूप से कम संसाधन वाले उभरते डोमेन के लिए।</abstract_hi>
      <abstract_zh>引入一合,框架Velocidapter解语料库可用性。 Velocidapter以拟言域之合而增数据集,每新域皆须少导。 对数集MRCWOZ估吾框架之有效性,注MultiWOZ 2.2数集之餐厅,出租车与酒垆领域之位以谋(Zang等,2020)。 行实验于低资源,练形于SQuAD上预,因小原始数据、框架成之数而微之。 Velocidapter用基变压器BERTBase与BiDAF为本体显改。 宜框架易新手用户用,Velocidapter可大助培训面任之对,特于资源匮乏之新兴领域。</abstract_zh>
      <abstract_ga>Tugaimid isteach creat giniúna comhphlé sintéiseach, Velocidapter, a thugann aghaidh ar fhadhb infhaighteachta an chorpais chun idirphlé a thuiscint. Méadaíonn Velocidapter tacair shonraí trí chomhráite sintéiseacha a insamhlú le haghaidh fearann comhphlé tasc-dhírithe, rud a éilíonn méid beag oibre tosaithe do gach fearann nua. Déanaimid meastóireacht ar éifeachtúlacht ár gcreat ar thacar sonraí tuisceana idirphlé tasc-dhírithe, MRCWOZ, a choinnímid trí cheisteanna do shliotáin i bhfearainn na mbialann, na dtacsaithe agus na n-óstán de thacar sonraí MultiWOZ 2.2 a anó (Zang et al., 2020). Reáchtálaimid turgnaimh laistigh de shuíomh acmhainní ísle, áit a ndéanaimid réamhthraenáil ar shamhail ar SQuAD, á mionchoigeartú ar bhunshonraí beaga nó ar na sonraí sintéiseacha a ghineann ár gcreat. Léiríonn Velocidapter feabhsuithe suntasacha ag baint úsáide as an gclaochladán-bhunaithe BERTBase agus BiDAF mar mhúnlaí bonn. Léirímid freisin go bhfuil an creat éasca le húsáid ag úsáideoirí nua-aimseartha agus tá sé de thátal againn gur féidir le Velocidapter cuidiú go mór le hoiliúint a dhéanamh ar idirphlé tasc-dhírithe, go háirithe i bhfearainn éiritheacha a bhfuil acmhainní ísle acu.</abstract_ga>
      <abstract_el>Παρουσιάζουμε ένα συνθετικό πλαίσιο δημιουργίας διαλόγου, το οποίο αντιμετωπίζει το πρόβλημα διαθεσιμότητας σώματος για την κατανόηση του διαλόγου. Το διευρύνει τα σύνολα δεδομένων προσομοιώνοντας συνθετικές συνομιλίες για έναν τομέα διαλόγου προσανατολισμένο στις εργασίες, απαιτώντας ένα μικρό ποσό εργασίας εκκίνησης για κάθε νέο τομέα. Αξιολογούμε την αποτελεσματικότητα του πλαισίου μας σε ένα σύνολο δεδομένων κατανόησης διαλόγου προσανατολισμένο στην εργασία, το οποίο επιμελούμε σχολιάζοντας ερωτήσεις για κουλοχέρηδες στους τομείς εστιατορίων, ταξί και ξενοδοχείων του συνόλου δεδομένων (κ.α., 2020). Πραγματοποιούμε πειράματα σε ένα περιβάλλον χαμηλών πόρων, όπου προετοιμάζουμε ένα μοντέλο στο SQuAD, βελτιώνοντάς το είτε σε μικρά πρωτότυπα δεδομένα είτε στα συνθετικά δεδομένα που παράγονται από το πλαίσιο μας. Το Velocidapter παρουσιάζει σημαντικές βελτιώσεις χρησιμοποιώντας τόσο τη βάση του μετασχηματιστή BERTBase όσο και BiDAF ως βασικά μοντέλα. Αποδεικνύουμε επίσης ότι το πλαίσιο είναι εύκολο στη χρήση από αρχάριους χρήστες και καταλήγουμε στο συμπέρασμα ότι το Velocidapter μπορεί να βοηθήσει σημαντικά στην εκπαίδευση πάνω από διαλόγους προσανατολισμένους σε εργασίες, ειδικά για αναδυόμενους τομείς με χαμηλούς πόρους.</abstract_el>
      <abstract_ka>ჩვენ შევცვალოთ სინტეტიკური დიალოგის დავიწყება, Velocidapter, რომელიც კოპუსს მისამართლობა პრობლემას დიალოგის გაგრძელება. სინტეტიკური პარამეტრების დიალოგის დიალოგის დიალოგის დიალოგის სიმუშაციაში სინტეტიკური პარამეტრების შექმნა, რომელიც ყველა ახალი დიალოგიისთვის პატარა მნიშვნელოვანი სა ჩვენ ვამუშაობთ ჩვენი პარამეტრების ეფექტიურობა მონაცემების დიალოგის შესახებ მონაცემების შესახებ, MRCWOZ, რომელიც ჩვენ მონაცემებით რესტორანში, რაქსიში და ჰოტელური მონაცემების მონაცემების მონაცემების კითხვების შესახებ ( ჩვენ ექსპერიმენტები გავაკეთებთ ცოტა რესურსების შესახებ, სადაც ჩვენ SQuAD-ზე მოდელის შესახებ გავაკეთებთ, რომელიც ჩვენი პატარა ორიგინალური მონაცემებზე ან სინტეტიკური მო Velocidapter გამოყენებს მნიშვნელოვანი უფლებები, რომლის გამოყენება ორივე ტრანფორმეტრის ბაზი BERTBase და BiDAF როგორც ბაზი მოდელები. ჩვენ დავაჩვენებთ, რომ ფრამეტრის გამოყენება ახალი მომხმარებელი და დავაკეთებთ, რომ Velocidapter შეუძლია ძალიან დახმარება განათლებას დამუშავებელი საქმედების დიალოგიებზე, განსაკუთრებით მაღალი რე</abstract_ka>
      <abstract_hu>Bevezetünk egy szintetikus párbeszédgenerációs keretet, a Velocidaptert, amely a párbeszéd megértéséhez szükséges korpusz-rendelkezésre állási problémát foglalkozik. A Velocidapter bővíti az adatkészleteket azáltal, hogy szintetikus beszélgetéseket szimulál egy feladatorientált párbeszédtartományhoz, ami minden új tartományhoz kis mennyiségű rendszerindítási munkát igényel. Keretrendszerünk hatékonyságát értékeljük egy feladatorientált párbeszédértési adatkészleten, az MRCWOZ-en, amelyet a MultiWOZ 2.2 adatkészlet éttermi, taxi és szállodai tartományaiban található résidőkre vonatkozó kérdések jegyzetelésével kezelünk (Zang et al., 2020). Alacsony erőforrásokkal rendelkező környezetben végzünk kísérleteket, ahol előkészítünk egy modellt az SQUAD-en, finomhangoljuk azt egy kis eredeti adatokra vagy a keretrendszerünk által generált szintetikus adatokra. A Velocidapter jelentős javulást mutat mind a transzformátor alapú BERTBase, mind a BiDAF alapmodellek használatával. Megmutatjuk továbbá, hogy a keretrendszer kezdő felhasználók számára könnyen használható, és arra a következtetésre jutunk, hogy a Velocidapter nagymértékben segíthet a feladatorientált párbeszédek képzésében, különösen az alacsony forrással rendelkező feltörekvő területek esetében.</abstract_hu>
      <abstract_it>Introducemo un framework sintetico di generazione del dialogo, Velocidapter, che affronta il problema della disponibilità del corpus per la comprensione del dialogo. Velocidapter aumenta i set di dati simulando conversazioni sintetiche per un dominio di dialogo orientato alle attività, richiedendo una piccola quantità di lavoro di avvio per ogni nuovo dominio. Valutiamo l'efficacia del nostro framework su un dataset di comprensione del dialogo orientato al compito, MRCWOZ, che curiamo annotando domande per slot nei domini ristorante, taxi e hotel del dataset MultiWOZ 2.2 (Zang et al., 2020). Eseguiamo esperimenti all'interno di un ambiente a basso contenuto di risorse, dove prevediamo un modello su SQUAD, regolandolo su un piccolo dato originale o sui dati sintetici generati dal nostro framework. Velocidapter mostra miglioramenti significativi utilizzando sia il trasformatore basato su BERTBase che BiDAF come modelli base. Dimostriamo inoltre che il framework è facile da usare dagli utenti principianti e concludiamo che Velocidapter può aiutare notevolmente la formazione sui dialoghi orientati alle attività, soprattutto per i domini emergenti a basso contenuto di risorse.</abstract_it>
      <abstract_lt>Įdiegiame sintetinio dialogo kūrimo sistemą Velocidapter, kurioje sprendžiama prieinamumo korpuso problem a dialogui suprasti. Velocidapter augments datasets by simulating synthetic conversations for a task-oriented dialogue domain, requiring a small amount of bootstrapping work for each new domain.  Vertiname savo sistemos, skirtos užduotims orientuotam dialogui, supratimo duomenų rinkiniui MRCWOZ, veiksmingumą, kurį tvarkome, užrašydami klausimus dėl laiko tarpsnių MultiWOZ 2.2 duomenų rinkinio (Zang et al., 2020 m.). Eksperimentuojame mažai išteklių turinčioje aplinkoje, kur iš anksto parengiame SQuAD model į, patobulindami jį arba mažais originaliais duomenimis, arba sintetiniais duomenimis, gautais pagal mūsų sistemą. Velocidapter rodo reikšmingus patobulinimus, naudojant transformatoriumi pagrįstą BERTBase ir BiDAF kaip bazinius modelius. Be to, mes parodome, kad sistemą lengva naudoti naujiems naudotojams ir darome išvadą, kad Velocidapter gali labai padėti mokymui užduotims orientuotuose dialoguose, ypač mažai išteklių turinčiose naujose srityse.</abstract_lt>
      <abstract_mk>Ние воведуваме рамка за генерација на синтетички дијалог, Велоцидаптер, која го решава проблемот со пристапноста на корпусот за разбирање на дијалогот. Velocidapter ги зголемува датотеките со симулирање на синтетичките разговори за домен на дијалог ориентиран на задачите, што бара мала количина на работа на bootstrapping за секој нов домен. Ја проценуваме ефикасноста на нашата рамка на датотеката за разбирање на дијалогот ориентиран на задачите, МРЦВОЗ, која ја курираме со анотација на прашањата за слотови во ресторанот, таксито и хотелските домени на податоците МултиВОЗ 2.2 (Zang et al., 2020). Ние спроведуваме експерименти во ниско ресурсно поставување, каде што предпредупредуваме модел на SQuAD, прилагодувајќи го или на мали оригинални податоци или на синтетичките податоци генерирани од нашата рамка. Велоцидаптерот покажува значителни подобрувања со користење на BERTBase и BiDAF бази на трансформатори. Понатаму покажуваме дека рамката е лесна за користење од новите корисници и заклучуваме дека Велоцидаптер може да помогне во голема мера во обуката во врска со дијалози ориентирани на задачите, особено за новите домени со ниски ресурси.</abstract_mk>
      <abstract_kk>Біз синтетикалық диалог құрылғысын, Velocidapter, диалогтың түсініктері үшін корпус мүмкіндіктерінің мәселесін түсіндіреді. Тапсырма диалог доменінің синтетикалық сөйлесуді біртіндеп, жылдамдық ауыстыру деректер жиындары, әрбір жаңа доменге кішкентай жүктеу жұмысын талап етеді. Біз тапсырманың бағытталған диалогтың деректерді түсініп, MRCWOZ бағытталған қоршауымыздың эффектілігін бағалаймыз. Біз ресторант, такси және MultiWOZ 2.2 деректер жиынының (Zang et al., 2020) лоттардың сұрақтарының сұрақтарын жаңарту арқылы жазы Біз эксперименттерді төмен ресурстар баптауында орындаймыз. SQuAD үлгісін өзгертеміз. Біз оны кішкентай бастапқы деректерге немесе қоршауымыздың құрылған синтетикалық деректеріне тұрады. Жылдамдығы BERTBase және BiDAF негізгі үлгілер ретінде түрлендіру үлгілерін қолдану үшін маңызды жақсартуларын көрсетеді. Біз жаңа пайдаланушылардың қолдануы оңай болып, Velocidapter тапсырмалар бағытталған диалогтардың оқытуына көмектесе алады деп ойлаймыз, осы түсінікте көмектесетін домендер үшін.</abstract_kk>
      <abstract_ms>Kami memperkenalkan kerangka generasi dialog sintetik, Velocidapter, yang mengatasi masalah kebebasan corpus untuk pemahaman dialog. Pemantau pantas menambah set data dengan simulasi perbualan sintetik untuk domain dialog orientasi tugas, memerlukan sejumlah kecil kerja bootstrapping bagi setiap domain baru. Kami menilai kegagalan kerangka kami pada set data pemahaman dialog bertujuan-tugas, MRCWOZ, yang kami mengukur dengan menandakan soalan untuk slot di restoran, taksi, dan domain hotel set data MultiWOZ 2.2 (Zang et al., 2020). Kami menjalankan eksperimen dalam tetapan sumber rendah, di mana kami mempelajari model pada SQuAD, memperbaikinya sama ada pada data asal kecil atau pada data sintetik yang dijana oleh kerangka kami. Velocidapter menunjukkan peningkatan yang signifikan menggunakan BERTBase dan BiDAF berdasarkan pengubah sebagai model as as. Kami juga menunjukkan bahawa kerangka mudah digunakan oleh pengguna awal dan kesimpulan bahawa Velocidapter boleh membantu banyak latihan melalui dialog-arah tugas, terutama untuk domain yang muncul dengan sumber rendah.</abstract_ms>
      <abstract_mt>Aħna nintroduċu qafas ta’ ġenerazzjoni ta’ djalogu sintetiku, Velocidapter, li jindirizza l-problem a tad-disponibbiltà korpus għall-komprensjoni tad-djalogu. Il-veloċidapter iżid is-settijiet tad-dejta billi jissimula konverżjonijiet sintetiċi għal dominju ta’ djalogu orjentat lejn ix-xogħol, li jeħtieġ ammont żgħir ta’ xogħol ta’ bootstrapping għal kull dominju ġdid. Aħna jevalwaw l-effikaċja tal-qafas tagħna fuq sett ta’ dejta dwar il-komprensjoni tad-djalogu orjentat lejn ix-xogħol, MRCWOZ, li nikuraw billi ninnutaw mistoqsijiet għal slots fir-ristorant, it-taxi, u d-dominji tal-lukandi tas-sett ta’ dejta MultiWOZ 2.2 (Zang et al., 2020). Aħna nagħmlu esperimenti f’ambjent ta’ riżorsi baxxi, fejn a ħna nħarrġu minn qabel mudell fuq SQuAD, u nħarrġu mill-ġdid jew fuq dejta oriġinali żgħira jew fuq dejta sintetika ġġenerata mill-qafas tagħna. Velocidapter juri titjib sinifikanti bl-użu kemm tal-BERTBase ibbażat fuq it-trasformatur kif ukoll tal-BiDAF bħala mudelli bażi. Aħna nuru wkoll li l-qafas huwa faċli biex jintuża mill-utenti ġodda u nikkonkludu li Velocidapter jista' jgħin ħafna fit-taħriġ fuq djalogi orjentati lejn ix-xogħol, speċjalment għal oqsma emerġenti b'riżorsi baxxi.</abstract_mt>
      <abstract_mn>Бид синтетик диалог бүтээлч системийг танилцуулж, Velocidapter, диалогын ойлголтын тухай ярианы асуудлыг ярилцдаг. Шинэ холбоотой бүрт жижиг хэмжээний bootstrapping ажлыг шаардаж байгаа нь шинэ холбоотой диалог холбоотой синтетик ярилцлагуудыг шинэчлэхээр Velocidapter өсөлтийн өгөгдлийн сангуудыг нэмэгдүүлдэг. Бид ажил дээрх диалогын өгөгдлийн санг ойлгох, MRCWOZ-ын хөрөнгө оруулалтын үр дүнг үнэлдэг. Энэ нь бид хоолны ресторан, такси, олон WOZ 2.2 өгөгдлийн сангийн сургуульд асуултыг анзаарч байгаа. Бид бага боловсролын төвшинд туршилт хийдэг. SQuAD дээрх загварыг тодорхойлж, жижиг эхний өгөгдлийг эсвэл бидний хэлбэрээр гаргасан синтетик өгөгдлийн талаар тодорхойлж байна. Velocidapter transformer-based BERTBase болон BiDAF-г суурь загвар болгон ашиглан чухал сайжруулалтыг харуулдаг. Дараа нь бид шинэ хэрэглэгчид ашиглах хөрөнгө оруулалт амархан гэдгийг харуулж, Velocidapter нь ажил дээр ориентирогдсон диалог дээр сургалтын тусламжтайгаар туслах боломжтой болсон, ялангуяа бага байгальтай шинэ ор</abstract_mn>
      <abstract_ml>സംസാരിക്കുന്ന ഒരു സംസാര തലമുറന്ന ഡയലോഗ് ഫ്രെയിമാര്‍ക്ക് ഞങ്ങള്‍ പരിചയപ്പെടുത്തുന്നു, വെലോക്കിഡിപ്റ്റര്‍, അത് ഡയലോഗ്  ഓരോ പുതിയ ഡൊമൈനിനും വേണ്ടി ബുട്ട്സ്ട്രാപ്പിങ്ങ് ജോലി ആവശ്യപ്പെടുന്ന വെലോക്കോഡിപ്റ്റര്‍ ഡേറ്റാസ്റ്റിക് സിമിലേറ്റിക്ക നമ്മുടെ ഫ്രെയിമെയിലുകളുടെ പ്രഭാവം നമ്മള്‍ വിലയിച്ചുകൊടുക്കുന്നു. മെര്‍സിവുവോസ്, റെസ്റ്റോറന്റ്, ടാക്സിയിലെ സ്ലോട്ടുകള്‍ക്കുള്ള ചോദ്യങ്ങള്‍ വിശദീകരിക്കുന്നു. മിട്ടിട കുറഞ്ഞ വിഭവങ്ങളുടെ ക്രമീകരണത്തില്‍ ഞങ്ങള്‍ പരീക്ഷണങ്ങള്‍ പ്രവര്‍ത്തിക്കുന്നു. അവിടെ സ്ക്വാഡില്‍ ഒരു മോഡല്‍ പെയ്യുന്നു. അത് ചെറിയ മൂല വിവരങ്ങള വെലോക്കോഡിപ്റ്റര്‍ മാറ്റങ്ങളുടെ അടിസ്ഥാനത്തിലുള്ള ബെര്‍ടിബേസും ബിഡിഎഫും ബേസ് മോഡലുകളായി ഉപയോഗിച്ച് വളരെ മു നോവീസ് ഉപയോക്താക്കള്‍ ഉപയോഗിക്കാന്‍ ഈ ഫ്രെയിമെക്ക് എളുപ്പമാണെന്നും തീരുമാനിക്കുന്നത് വെലോക്കിഡിപ്റ്റര്‍ ജോലിയിലേക്കുള്ള ഡയലോഗ</abstract_ml>
      <abstract_no>Vi introduserer eit syntetisk dialogopprettingsrammeverk, Velocidapter, som adresserer problemet med tilgjengeleg korpus for å forstå dialogvindauget. Velocidapter øker datasett ved å simulera syntetiske samtaler for eit oppgåveorientert dialogdomene, som krev ein liten mengde oppgåveverk for kvar ny domene. Vi evaluerer effektiviteten av rammeverket vårt på eit oppgåveorientert dialogvindauge for å forstå datasett, MRCWOZ, som vi kurrer ved å merke spørsmål om plasser i restauranten, taksi og hoteldomene i datasettet MultiWOZ 2.2 (Zang et al., 2020). Vi køyrer eksperimenter i eit låg ressursinnstilling, der vi prøver eit modell på SQuAD, og finn det på anten ein liten original data eller på syntetiske data laga av rammeverket vår. Velocidapter viser signifikante forbedringar ved å bruka både BERTBase og BiDAF som basemodeller på transformeringa. Vi viser meir at rammeverket er lett å bruka av nye brukarar og avsluttar at Velocidapter kan hjelpa mykje opplæring over oppgåveorienterte dialogar, særlig for låg ressursar oppgåande domene.</abstract_no>
      <abstract_pl>Wprowadzamy syntetyczny framework generowania dialogów, Velocidapter, który rozwiązuje problem dostępności korpusów dla zrozumienia dialogu. Velocidapter rozszerza zbiory danych symulując syntetyczne konwersacje dla domeny dialogowej zorientowanej na zadania, wymagając niewielkiej ilości pracy bootstrapping dla każdej nowej domeny. Oceniamy skuteczność naszego frameworku na zadaniowym zbiorze danych rozumienia dialogu MRCWOZ, który kuracjonujemy poprzez adnotację pytań dotyczących slotów w domenach restauracji, taxi i hotelu zestawu danych MultiWOZ 2.2 (Zang et al., 2020). Przeprowadzamy eksperymenty w warunkach niskich zasobów, gdzie wstępnie trenujemy model na SQuAD, dostosowując go albo na małych oryginalnych danych, albo na syntetycznych danych generowanych przez nasz framework. Velocidapter wykazuje znaczące ulepszenia wykorzystując zarówno modele bazowe BERTBase, jak i BiDAF oparte na transformatorach. Pokazujemy również, że framework jest łatwy w użyciu przez początkujących użytkowników i wnioskujemy, że Velocidapter może znacznie pomóc w szkoleniu dialogów zorientowanych na zadania, zwłaszcza w przypadku powstających domen o niskich zasobach.</abstract_pl>
      <abstract_ro>Introducem un cadru sintetic de generare a dialogului, Velocidapter, care abordează problema disponibilității corpurilor pentru înțelegerea dialogului. Velocidapter mărește seturile de date simulând conversații sintetice pentru un domeniu de dialog orientat spre sarcini, necesitând o cantitate mică de lucru de bootstrapping pentru fiecare domeniu nou. Evaluăm eficacitatea cadrului nostru asupra unui set de date de înțelegere a dialogului orientat spre sarcini, MRCWOZ, pe care îl curățăm prin adnotarea întrebărilor pentru sloturi în domeniile restaurantului, taxiului și hotelului din setul de date MultiWOZ 2.2 (Zang et al., 2020). Executăm experimente într-un cadru cu resurse reduse, unde pregătim un model pe SQUAD, reglându-l fin fie pe o mică dată originală, fie pe datele sintetice generate de cadrul nostru. Velocidapter prezintă îmbunătățiri semnificative utilizând atât BERTBase bazate pe transformator, cât și BiDAF ca modele de bază. De asemenea, demonstrăm că cadrul este ușor de utilizat de utilizatorii începători și concluzionăm că Velocidapter poate ajuta foarte mult la formarea în dialogurile orientate spre sarcini, în special pentru domeniile emergente cu resurse reduse.</abstract_ro>
      <abstract_sr>Predstavljamo okvir generacije sintetičkog dijaloga, Velocidapter, koji rješava problem dostupnosti korpusa za razumijevanje dijaloga. Povećavanje podataka za brzinu podataka simulirajući sintetičke razgovore za domenu dijaloga orijentiranu na zadatke, zahtevajući mala količina posla za svaku novu domenu. Procjenjujemo učinkovitost našeg okvira na setu podataka o razumijevanju na zadatku orijentiranog dijaloga, MRCWOZ, kojeg smo iznosili annotacijom pitanja za slobode u restoranu, taksi i hotelskim domenama MultiWOZ 2.2 dataset (Zang et al., 2020). Pokrenuli smo eksperimente unutar nizakvih resursa, gde pretvaramo model na SQuAD, kako ga dobro sredimo na malim originalnim podacima ili na sintetičkim podacima koje je stvorio naš okvir. Velocidapter pokazuje značajne poboljšanje koristeći i BERTBase i BiDAF na transformaciji kao bazne modele. Dalje pokazujemo da je okvir lako iskoristiti novi korisnici i zaključujemo da Velocidapter može veliko pomoći u obuci na dijalogovima orijentiranim na zadatke, posebno za manje resurse u novim domenama.</abstract_sr>
      <abstract_sv>Vi introducerar ett syntetiskt dialoggenereringsramverk, Velocidapter, som tar itu med korpustillg채nglighetsproblemet f철r dialogf철rst책else. Velocidapter ut철kar dataupps채ttningar genom att simulera syntetiska konversationer f철r en uppgiftsorienterad dialogdom채n, vilket kr채ver en liten m채ngd uppstartsarbete f철r varje ny dom채n. Vi utv채rderar effektiviteten av v책rt ramverk p책 ett uppgiftsorienterat dataset f철r dialogf철rst책else, MRCWOZ, som vi kurerar genom att kommentera fr책gor f철r slots i restaurang-, taxi- och hotelldom채nerna i MultiWOZ 2.2 dataset (Zang et al., 2020). Vi k철r experiment inom en l책gresursmilj철, d채r vi f철rbereder en modell p책 SQUAD, finjusterar den antingen p책 en liten originaldata eller p책 syntetiska data som genereras av v책rt ramverk. Velocidapter visar betydande f철rb채ttringar med b책de transformatorbaserade BERTBase och BiDAF som basmodeller. Vi visar vidare att ramverket 채r l채tt att anv채nda av nyb철rjare och drar slutsatsen att Velocidapter i h철g grad kan hj채lpa till att utbilda sig 철ver uppgiftsorienterade dialoger, s채rskilt f철r l책gresurserade framv채xande dom채ner.</abstract_sv>
      <abstract_si>අපි සංවිධානය සංවාදයක් පරීක්ෂණය කරනවා, Velocidapter, ඒ කොර්පස් ප්‍රශ්නයක් තේරුම් ගන්න සංවාදය සඳහා ප්‍රශ්න Velocidapter විශාලනයේ දත්ත සැකසුම් විදිහට සංවාදය සඳහා කාර්යය සඳහා සංවාදය සඳහා සංවාදය සඳහා සංවාදය සඳහා සංවාදය සඳ අපි ක්‍රියාත්මක සංවාදයේ ප්‍රශ්නයක් විශ්වාස කරනවා, MRCWOZ, මේ ප්‍රශ්නයක් අපි ප්‍රශ්නයක් විශ්වාස කරනවා, ටැක්සි සහ හ හෝටල් ඩොමේන්ස් 2.2 දත්ත සැට (Zang et al., 2020යි අපි පරීක්ෂණයක් අඩුම සම්පූර්ණ සැකසුම් වලට පරීක්ෂණය කරනවා, SQuAD වලට මොඩේල් එකක් ප්‍රතික්ෂණය කරනවා, ඒක පුංචි ප්‍රතිකාර දත Velocidapter පෙන්වන්නේ වෙනස් පරිවර්තනය සහ BiDAF පරිවර්තනය වෙනුවෙන් විශේෂ ප්‍රමාණය ප්‍රයෝජනය කරන්න. අපි තවත් පෙන්වන්නේ මේ ප්‍රකාරයක් ප්‍රයෝජනය කරන්න ලේසියි කියලා, වෙලෝසිඩාප්ටර් වෙලෝසිඩාප්ටර් ප්‍රයෝජනය කරන්න පුළුවන් වැඩ</abstract_si>
      <abstract_so>Waxaynu soo bandhignaynaa qoraal-muuqasho ah, Velocidapter, kaas oo looga baaraandegayo dhibaatada helitaanka qoyska ee sameynta dialogue. Soo sawiraadka macluumaadka ee Velocidapter waxay ku similanayaan hadalka synthetic oo lagu qorayo guriga diyaarinta shaqada, waxayna u baahan yihiin shaqo yar oo boostada boostada ah oo ku jira domain kasta oo cusub. Waxaynu qiimeynaynaa saameynta sameynta qoraalka hoose-dhigista ee shaqaalaha, MRCWOZ, kaas oo aynu ku qiimeynaynaa su'aalo ku saabsan jabsamada restauranteeda, taxiga iyo goobaha hoteelka ee MultiWOZ 2.2 (Zang et, 2020). Imtixaan baaritaanka hoose-resource ah, halkaas oo aynu ku soo dayno model SQuAD, si fiican ugu sameyno macluumaad yar ama danbiyo rasmi ah oo uu ka soo dhashay qoraalkayaga. Velocidapter wuxuu muujiyaa hagaajinta aad u weyn oo ku isticmaalaya wareejinta BERTBase iyo BiDAF sida modello aasaasi ah. Sidoo kale waxaynu tusnaynaa in shirkadu fudud yahay isticmaalka dadka noqooyiga ah iyo in Velocidapter uu aad ugu caawinayo waxbarashada ku saabsan dialogueoyinka shaqada, khusuusan goobaha soo baxa ee noocyada yar.</abstract_so>
      <abstract_ta>நாம் ஒரு கூட்டிணைப்பு உரையாடல் உரையாடல் உரையாடல் சட்டத்தை குறிப்பிடுகிறோம், வெல்லோகிடேப்டர், அது உரையாடல் சூழ்ந்து உரைய வெல்லோகிடேப்டர் கூட்டுதல் தகவல் அமைப்புகள் செயல்பாடு திட்டத்தில் உள்ள உரையாடல் களத்திற்கான தொடர்புகளை பாவனைசெய்து, ஒவ்வொரு புதிய தளத நாங்கள் செயல்பாடு திசைக்கப்பட்ட உரையாடல் சூழ்நிலை தகவல் அமைப்பின் விளைவை மதிப்பிடுகிறோம். இதை நாம் மாற்றியமைப்பு, டாக்சி, மற்றும் மிக பல்WOZ 2. 2 தகவல் அமைப்புகளின் விளக்கம் செய் We run experiments within a low-resource setting, where we pretrain a model on SQuAD, fine-tuning it on either a small original data or on the synthetic data generated by our framework.  மாற்று அடிப்படையில் இருந்து BERTBase மற்றும் பிடிஏப் மாதிரிகளாக முக்கியமான முன்னேற்றங்களை காட்டுகிறது. நாம் மேலும் காண்பிக்கிறோம் நோவியன் பயனர்களால் பயன்படுத்தும் சட்டம் எளிதாக இருக்கும் மற்றும் முடிவு செய்தால் வெல்லோகிடேடர் செயல் முறை</abstract_ta>
      <abstract_ur>ہم ایک سینٹٹیسی ڈیلوگر نسل فرم، Velocidapter کو معرفی کرتے ہیں، جسے ڈیلوگر سمجھنے کے لئے کورپوس کے موجود موجود مسئلہ کے بارے میں مشکل کرتا ہے. Velocidapter augments datasets by simulating synthetic conversations for a task-oriented dialog domain, requiring a small amount of bootstrapping work for each new domain. ہم نے اپنے فرمود کے فعالیت کو ایک ٹاکس کی طرف متوجہ ہونے والی ڈیٹ سٹ، MRCWOZ کے ذریعے مطابق کا ارزش کیا ہے، جسے ہم نے رستوران، تاکسی، اور MultiWOZ 2.2 ڈیٹ سٹ (Zang et al., 2020) میں سوالوں کے لئے سوالوں کے ذریعے آگاہ کر دیا ہے۔ ہم ایک کم منطقی سٹینٹ میں آزمائش کریں گے جہاں ہم SQuAD پر ایک موڈل کو پہنچاتے ہیں، اسے چھوٹی اصلی ڈاٹی پر یا ہمارے فرم کے ذریعہ سے پیدا کیا گیا سینٹیسی ڈاٹی پر سینٹیسی ڈاٹی پر ٹھیک ٹونٹ کر Velocidapter دکھاتا ہے کہ تبدیل کرنے والی BERTBase اور BiDAF کو بنسٹ موڈل کے طور پر ضروری اضافہ کرتا ہے. ہم اس سے زیادہ دکھاتے ہیں کہ فرم نویس کارساز کے ذریعے استعمال کرنے کے لئے آسان ہے اور اس کے نتیجے میں یہ ہے کہ Velocidapter بہت زیادہ کارساز کی تعلیم کی مدد کر سکتا ہے، مخصوصاً کم سرمایہ دار پیدا ہونے والی دامنین کے لئے۔</abstract_ur>
      <abstract_uz>Biz muloqat tizimi yaratish muvaffaqiyatlarini tahlil qilamiz. Bu oyna tuzuvchi tizimga qoʻllaniladi. Name We evaluate the efficacy of our framework on a task-oriented dialogue comprehension dataset, MRCWOZ, which we curate by annotating questions for slots in the restaurant, taxi, and hotel domains of the MultiWOZ 2.2 dataset (Zang et al., 2020).  Biz kichkina resource moslamada tajribalarni bajaramiz. Bu yerda SQuAD modelini tahrirlashimiz mumkin, uni kichkina asl maʼlumotga yoki chegara yaratilgan bir nechta maʼlumot haqida bajaramiz. Name Biz yana ko'rayapmiz, bu freym novice foydalanuvchilar uchun oddiy foydalanish mumkin va va Velocidapter vazifa bilan boshqarish dialoglari bilan moslash uchun juda ham yordam beradi, hususan kichkina murakkab bo'lgan domenalar uchun.</abstract_uz>
      <abstract_vi>Chúng tôi giới thiệu một hệ thống sản xuất cuộc đối thoại tổng hợp, Velocidapter, Ủy ban giải quyết vấn đề về khả năng của tập thể để hiểu rộng. Trình nâng cao dữ liệu của Velocidapter bằng cách mô phỏng các cuộc đối thoại tổng hợp cho một miền thoại hướng nhiệm vụ, yêu cầu một ít công việc khởi động cho mỗi miền mới. Chúng tôi đánh giá hiệu quả của cơ thể chúng tôi về một bộ dữ liệu quy định về cuộc đối thoại hướng nhiệm vụ, MRCWOZ, mà chúng tôi quản lý bằng cách ghi chú những câu hỏi cho các máy đánh bạc ở nhà hàng, taxi, và khu vực của đa dịch 2.2 (Zang et al., 2020). Chúng tôi tiến hành thí nghiệm trong một môi trường ít nguồn, nơi chúng tôi ngụy trang một mô hình về SQurAD, sửa chữa nó bằng một dữ liệu gốc nhỏ hoặc các dữ liệu nhân tạo từ cơ sở của chúng tôi. Loài Velocidapter cho thấy một sự tổn tại quan trọng bằng cả hai một khẩu pháp chuyển được chuyển ra. Chúng tôi cho thấy những khung hình này rất dễ sử dụng cho người mới và kết luận rằng Velocidapter có thể giúp huấn luyện về các ca- trình dựa trên các nhiệm vụ, đặc biệt là với những lĩnh vực mới có nguồn ít.</abstract_vi>
      <abstract_bg>Въвеждаме синтетична рамка за генериране на диалог, която разглежда проблема с наличието на корпус за разбиране на диалога. Увеличава наборите от данни чрез симулиране на синтетични разговори за ориентиран към задачите диалогов домейн, изискващ малко количество работа за стартиране на всеки нов домейн. Оценяваме ефикасността на нашата рамка върху набор от данни за разбиране на диалога, ориентиран към задачите, който курираме чрез анотиране на въпроси за слотове в ресторантите, такситата и хотелските домейни на набор от данни (Занг и др., 2020). Ние провеждаме експерименти в рамките на нискоресурсна настройка, където предварително подготвяме модел на SQuAD, фино настройвайки го или върху малки оригинални данни, или върху синтетичните данни, генерирани от нашата рамка. Велоцидаптер показва значителни подобрения, използвайки както трансформаторно базираните BERTBase, така и BiDAF като базови модели. Освен това показваме, че рамката е лесна за използване от начинаещи потребители и заключаваме, че може значително да помогне на обучението за ориентирани към задачите диалози, особено за нововъзникващи домейни с нисък ресурс.</abstract_bg>
      <abstract_da>Vi introducerer en syntetisk dialoggenereringsramme, Velocidapter, som løser problemet med korpustilgængelighed for dialog forståelse. Velocidapter forøger datasæt ved at simulere syntetiske samtaler for et opgaveorienteret dialogdomæne, hvilket kræver en lille mængde opstartsarbejde for hvert nyt domæne. Vi evaluerer effektiviteten af vores rammer på et opgaveorienteret dialogforståelsesdatasæt, MRCWOZ, som vi kurerer ved at kommentere spørgsmål til slots i restaurant, taxa og hotel domæner i MultiWOZ 2.2 datasættet (Zang et al., 2020). Vi kører eksperimenter inden for en lav ressource-indstilling, hvor vi forbereder en model på SQUAD, finjusterer den enten på en lille original data eller på de syntetiske data genereret af vores framework. Velocidapter viser betydelige forbedringer ved hjælp af både transformerbaserede BERTBase og BiDAF som grundmodeller. Vi viser endvidere, at rammerne er nemme at bruge af nybegyndere og konkluderer, at Velocidapter i høj grad kan hjælpe med at træne i opgaveorienterede dialoger, især for nye domæner med lav ressource.</abstract_da>
      <abstract_hr>Predstavljamo okvir generacije sintetičkog dijaloga, Velocidapter, koji rješava problem dostupnosti korpusa za razumijevanje dijaloga. Povećavanje podataka za brzinu povećavanja podataka simulirajući sintetičke razgovore za domenu dijaloga orientiranog na zadatke, zahtijevajući mala količina rada za svaku novu domenu. Procjenjujemo učinkovitost našeg okvira na kompletu podataka o razumijevanju dijaloga usmjerenog na zadatke, MRCWOZ, kojeg smo riješili annotacijom pitanja za slobode u restoranu, taksi i hotelskim domenama MultiWOZ 2.2 podataka (Zang et al., 2020). Pokrenuli smo eksperimenti unutar nastave niskog resursa, gdje pretvaramo model na SQuAD-u, ispravljamo ga na malim originalnim podacima ili na sintetičkim podacima koje je stvorio naš okvir. Velocidapter pokazuje značajne poboljšanje koristeći i BERTBase i BiDAF na transformaciji kao bazne modele. Dalje pokazujemo da je okvir lako koristiti novi korisnici i zaključujemo da Velocidapter može veliko pomoći obuci na dijalogovima orijentiranim na zadatke, posebno za manje resurse u novim domenama.</abstract_hr>
      <abstract_nl>We introduceren een synthetisch dialoog generatie framework, Velocidapter, dat het corpus beschikbaarheid probleem voor dialoog begrip aanpakt. Velocidapter breidt datasets uit door synthetische conversaties te simuleren voor een taakgericht dialoogdomein, wat een kleine hoeveelheid bootstrapping werk vereist voor elk nieuw domein. We evalueren de effectiviteit van ons framework op basis van een taakgerichte dialogbegrip dataset, MRCWOZ, die we cureren door vragen te annoteren voor slots in het restaurant-, taxi- en hoteldomein van de MultiWOZ 2.2 dataset (Zang et al., 2020). We voeren experimenten uit binnen een low-resource setting, waarbij we een model vooraf trainen op SQuAD, het verfijnen op ofwel een kleine originele data of op de synthetische data gegenereerd door ons framework. Velocidapter vertoont aanzienlijke verbeteringen met zowel de transformatorgebaseerde BERTBase als BiDAF als basismodellen. We tonen verder aan dat het framework gemakkelijk te gebruiken is door beginnende gebruikers en concluderen dat Velocidapter enorm kan helpen bij het trainen van taakgerichte dialogen, vooral voor opkomende domeinen met lage resources.</abstract_nl>
      <abstract_id>Kami memperkenalkan sistem generasi dialog sintetis, Velocidapter, yang mengatasi masalah kebebasan corpus untuk pemahaman dialog. Velocidapter meningkatkan set data dengan simulasi konversasi sintetis untuk domain dialog orientasi tugas, membutuhkan jumlah kecil kerja bootstrapping untuk setiap domain baru. Kami mengevaluasi efektivitas dari kerangka kami pada set data pemahaman dialog yang orient tugas, MRCWOZ, yang kami curasi dengan mengantar pertanyaan untuk slot di restoran, taksi, dan domain hotel MultiWOZ 2.2 dataset (Zang et al., 2020). Kami menjalankan eksperimen dalam pengaturan sumber daya rendah, di mana kami mempelajari model pada SQuAD, memperbaikinya pada data asli kecil atau pada data sintetis yang dihasilkan oleh kerangka kami. Velocidapter menunjukkan perbaikan yang signifikan menggunakan BERTBase dan BiDAF berdasarkan transformer sebagai model dasar. Kami lebih lanjut menunjukkan bahwa kerangka mudah digunakan oleh pengguna awal dan menyimpulkan bahwa Velocidapter dapat sangat membantu latihan melalui dialog orientasi tugas, terutama untuk domain yang muncul dengan sumber daya rendah.</abstract_id>
      <abstract_de>Wir führen ein synthetisches Dialoggenerierungsframework Velocidapter ein, das das Problem der Korpusverfügbarkeit für das Dialogverständnis adressiert. Velocidapter erweitert Datensätze, indem synthetische Konversationen für eine aufgabenorientierte Dialogdomäne simuliert werden, was für jede neue Domäne einen geringen Aufwand an Bootstrapping erfordert. Wir evaluieren die Wirksamkeit unseres Frameworks auf einem aufgabenorientierten Dialogverständnisdatensatz MRCWOZ, den wir kuratieren, indem wir Fragen für Slots in den Bereichen Restaurant, Taxi und Hotel des MultiWOZ 2.2 Datensatzes kommentieren (Zang et al., 2020). Wir führen Experimente in einer ressourcenarmen Umgebung durch, wo wir ein Modell auf SQuAD vortrainieren und es entweder auf kleinen Originaldaten oder auf den synthetischen Daten, die von unserem Framework generiert werden, verfeinern. Velocidapter zeigt deutliche Verbesserungen mit der transformatorbasierten BERTBase und BiDAF als Basismodelle. Wir zeigen weiter, dass das Framework für Anfänger einfach zu bedienen ist und kommen zu dem Schluss, dass Velocidapter das Training über aufgabenorientierte Dialoge erheblich unterstützen kann, insbesondere für aufkommende Domänen mit geringen Ressourcen.</abstract_de>
      <abstract_ko>우리는 대화 이해 중인 자료 라이브러리의 가용성 문제를 해결하는 종합적인 대화 생성 프레임워크인 Velocidapter를 소개했다.Velocidapter는 작업을 위한 대화 영역의 합성 대화를 시뮬레이션하여 데이터 집합을 확장합니다. 새로운 영역마다 소량의 안내 작업이 필요합니다.우리는 임무를 위한 대화 이해 데이터 집합인 MRCWOZ에서 우리의 틀의 유효성을 평가했고, MultiWOZ 2.2 데이터 집합(Zang 등, 2020)의 식당, 택시와 호텔 분야의 주석 문제를 통해 이 데이터 집합을 기획했다.우리는 낮은 자원 환경에서 실험을 실행하고 팀에서 예비 훈련 모델을 사용하며 작은 원시 데이터나 우리 프레임워크에서 생성된 합성 데이터에 마이크로 조정 모델을 사용한다.Velocidapter는 변압기 기반의 BERTBase와 BiDAF를 기초 모델로 삼아 현저한 개선을 보였다.우리는 이 프레임워크가 초보자들에게 사용하기 쉽다는 것을 증명했고, Velocidapter는 임무를 위한 대화 교육, 특히 자원 부족의 신흥 분야에 큰 도움을 줄 수 있다는 결론을 내렸다.</abstract_ko>
      <abstract_fa>ما یک چهارچوب نسل گفتگوی سنتئاتیک را معرفی می کنیم، Velocidapter، که مشکل موجودات کورپوس را برای فهمیدن گفتگو درباره‌ی مشکل دسترسی می‌کند. تنظیم داده‌های Velocidapter با شبیه‌سازی مجموعه‌های سینتیک برای یک دامنۀ محاورۀ محاورۀ مشارکت به کار، نیاز به اندازه‌ای کوچک از کارهای پرتاب‌کننده برای هر دامنۀ جدید است. ما موثرت چهارچوب ما را در یک مجموعه داده‌های متوجه شدن در مورد یک مشارکت مشاهده می‌کنیم MRCWOZ که با مشاهده کردن سوالات برای نقطه‌ها در رستوران، تاکسی و دومین‌های هتل‌های مجموعه‌ی داده‌های MultiWOZ 2.2 (Zang et al., 2020) تحقیق می‌کنیم. ما آزمایش‌ها را در یک تنظیم منابع کم انجام می‌دهیم، جایی که یک مدل روی SQuAD را پیشنهاد می‌کنیم، یا روی داده‌های اصلی کوچک یا روی داده‌های سینتاتیک که توسط چهارچوب ما تولید می‌شود، درست می‌کنیم. Velocidapter با استفاده از BERTBase و BiDAF به عنوان مدل‌های پایه بهترین شدید را نشان می‌دهد. ما نشان می دهیم که چهارچوب برای استفاده از کاربران جدید آسان است و نتیجه می دهیم که Velocidapter می تواند بسیار کمک کند به تمرین کردن در گفتگوهای مستقیم به کار، مخصوصا برای دامنه های پیشرفته کمتر.</abstract_fa>
      <abstract_af>Ons introduseer 'n sintetiese dialoog generasie raamwerk, Velocidapter, wat die korpus beskikbaarheid probleem vir dialoog verstaan. Velocidapter versterking datastelle deur sintetiese gesprekke vir 'n taak- orienteerde dialoog domein te simuleer, wat 'n klein hoeveelheid opstarting werk vir elke nuwe domein benodig. Ons evalueer die effektiviteit van ons raamwerk op 'n taak-orienteerde dialoog verstaan datastel, MRCWOZ, wat ons uitgevoer deur vrae vir slots in die restaurant, taksi en hoteldomene van die MultiWOZ 2.2 datastel (Zang et al., 2020). Ons hardloop eksperimente binne 'n lae- hulpbron instelling, waar ons 'n model op SQuAD trek, fin- tuning dit op óf 'n klein oorspronklike data of op die sintetiese data genereer deur ons raamwerk. Velocidapter wys betekende verbeteringe met gebruik van beide die transformeerder-gebaseerde BERTBase en BiDAF as basis modele. Ons wys verder dat die raamwerk maklik is om deur nuwe gebruikers te gebruik en te sluit dat Velocidapter baie kan hulp onderwerp oor taak-orienteerde dialoog, spesiaal vir lae-hulpbronne uiteindelike domeine.</abstract_af>
      <abstract_sw>Tunaweza kutengeneza mfumo wa mazungumzo ya pamoja, Velocidapter, ambalo linahusu tatizo la upatikanaji wa mazungumzo kwa ufahamu wa mazungumzo. Tovuti za taarifa za maendeleo ya Velocidapter kwa kuelezea mazungumzo ya pamoja kwa ajili ya eneo la mazungumzo yenye malengo ya kazi, zinahitaji kiasi kidogo cha kazi za boot kwa kila domain mpya. Tutathmini ufanisi wa mfumo wetu wa mazungumzo kwenye seti ya kompyuta ya mazungumzo yenye malengo ya kazi, MRCWOZ, ambayo tunafundisha kwa kutangaza maswali ya mistari ya mgahawa, taxi na vituo vya hoteli vya takwimu za MultiWOZ 2.2 (Zang et, 2020). Tunaendesha majaribio katika mazingira ya rasilimali yenye chini, ambapo tunajieleza mifano kwenye SQuAD, tunaweka vizuri kwenye takwimu ndogo za asili au kwenye taarifa za pamoja zilizotengenezwa na mfumo wetu. Velocidapter anaonyesha maboresho makubwa kwa kutumia mabadiliko yenye msingi wa BERTBase na BiDAF kama mifano ya msingi. Tunaonyesha zaidi kuwa mfumo huu ni rahisi kutumia watumiaji wa mtandao wa intaneti na anahitimisha kuwa Velocidapter anaweza kusaidia mafunzo mengi ya mazungumzo yanayoongozwa na kazi, hususani kwa ajili ya maeneo yanayotokana na rasmi ndogo.</abstract_sw>
      <abstract_sq>Ne prezantojmë një kuadër të gjenerimit të dialogut sintetik, Velocidapter, i cili trajton problemet e disponueshmërisë së korpusit për kuptimin e dialogut. Velocidapter rrit grupet e të dhënave duke simuluar bisedimet sintetike për një domeni dialog të orientuar ndaj detyrave, duke kërkuar një sasi të vogël pune bootstrapping për çdo domeni të ri. Ne vlerësojmë efektshmërinë e kuadrit tonë në një set të dhënash të kuptimit të dialogut të orientuar ndaj detyrave, MRCWOZ, të cilin e kurojmë duke vënë në dukje pyetje për slots në restorant, taksi dhe domenat e hotelit të MultiWOZ 2.2 dataset (Zang et al., 2020). Ne bëjmë eksperimente brenda një përcaktimi me burime të ulëta, ku paraqesim një model në SQuAD, duke e rregulluar atë ose në një të dhënë të vogël origjinale ose në të dhënat sintetike të gjeneruara nga kuadri ynë. Velocidapter tregon përmirësime të rëndësishme duke përdorur si BERTBase me bazë në transformues, ashtu edhe BiDAF si modele bazë. Ne tregojmë më tej se kuadri është i lehtë për të përdorur nga përdoruesit e filluesve dhe përfundojmë se Velocidapter mund të ndihmojë në mënyrë të madhe trainimin lidhur me dialogun e orientuar ndaj detyrave, veçanërisht për fusha të zhvilluara me burime të ulta.</abstract_sq>
      <abstract_tr>Biz bir sintetik dialog döredilmesi çerçevesini, Velocidapter'i, dijalogyň düşünmesi üçin korpus ulaşabilmesi meselesini çözýäris. Velocidapter öňlikler veri setirleri bir täze domeny üçin syntetik sohbetleri simulatýar Biz öz çerçewçimiziň etkinliýetimizi, MRCWOZ, restoran, taksi we multiWOZ 2.2 veri setiriniň (Zang et al., 2020) sahypalarynyň halkara çykyşlygynda çykýardyk. Biz SQuAD'da bir nusga örän düşürip ýagdaýynda çykyş edip, muny ýagdaýymyzda kiçi bir başlangyç maglumatyň ýa-da sistemimiziň tarapyndan üretilen sintetik maglumatyň üstine süýtgedik. Velocidapter BERTBase ve BiDAF tabanlı modeller olarak kullanarak önemli gelişmeleri gösterir. Biz indi täze ulananlar tarapyndan ulanmak aňsat däldigini we çykarjak bolýarys. Velocidapter işe görkezilen dialoglarda okuwçylyga örän kömek edip biler, ýöne-de aşak resurslar üçin.</abstract_tr>
      <abstract_az>Biz sintetik dialoq nəticəsi framework ünü təşkil edirik, Velocidapter, korpus faydalanması problemini anlamaq üçün çəkirir. Hər yeni domena üçün kiçik dəyişiklik başlatma işləri istəyir. Biz qurğumuzun etkinliğini çəkirik, MRCWOZ veri qurğularını anlamaq üçün çəkirik. Bu çoxlu WOZ 2.2 veri qurduğu yerlərin restoranda, taksi və hotel sahələrindəki sualları məlumatlarının istifadə edərək. Biz düşük ressurs qurğusu içində təcrübələr işlədirik, SQuAD üzerində modeli təcrübə edirik, onu ya kiçik orijinal verilər, ya da fotogramımızdan yaratdığı sintetik verilər barəsində təcrübə edirik. Velocidapter hər ikisini transformer-based BERTBase və BiDAF-nin baz modelləri kimi istifadə edərək möhkəm düzəltmələri göstərir. Biz daha da göstəririk ki, qurğun yeni istifadəçilər tərəfindən istifadə edilməsi kolaydır və Velocidapter iş tərəfindən təhsil edilən dialogların təhsil edilməsinə çox kömək edə bilər, özellikle də zəif ressurslı yeni domenalar üçün.</abstract_az>
      <abstract_am>የኮርፓስ ስብስብ ጉዳይ ለጥያቄ አካባቢ ጥያቄን እናስጠጋለን፡፡ አዲስ ዶሴ ፍጠር የሥርዓት አዳራሽ ዳታዎችን ማህበረሰብ እናስተውላለን፡፡ ከታናሽ resource ማህበረሰብ ውስጥ ፈተናዎችን እንሮጣለን፤ በSQuAD ላይ ምሳሌን እናሳድራለን፤ ወይም ትንሽ አዲስ አዋጅ ወይም በፍሬማችን የተፈጠረውን የስንተርቲካዊ ዳታዎችን እናሳውቃለን፡፡ Velolocidapter በመለወጥ BERTBase እና BiDAF በመሠረት ሞዴላዎችን በመጠቀም የበለጠ ክፍተቶችን ያሳያል፡፡ ደግሞም የሥርዓት ፍሬማት በኖዌዊ ተጠቃሚዎች የሚጠቀም ቀላል ነው እና ዋሎኪዳpter ለስራ አቀናኝነት በተደረገ ማኅበረሰብ ላይ፣ በተለይ ለታናሽ ድምፅ በሚወስደው ድምፅ ላይ ማስተምር እንዲችል ይችላል፡፡</abstract_am>
      <abstract_bs>Predstavljamo okvir generacije sintetičkog dijaloga, Velocidapter, koji rješava problem dostupnosti korpusa za razumijevanje dijaloga. Povećavanje podataka za brzinu povećavanja podataka simulirajući sintetičke razgovore za domenu dijaloga orijentiranu na zadatke, zahtijevajući mala količina radova za svaku novu domenu. Procjenjujemo učinkovitost našeg okvira na setu podataka o razumijevanju na cilju zadataka, MRCWOZ, kojom smo riješili annotacijom pitanja za slobode u restoranu, taksi i hotelskim domenama MultiWOZ 2.2 dataset (Zang et al., 2020). Pokrenuli smo eksperimenti unutar nizakvih resursa, gdje pretvaramo model na SQuAD-u, finaliziramo ga na malim originalnim podacima ili na sintetičkim podacima koje je stvorio naš okvir. Velocidapter pokazuje značajne poboljšanje koristeći i BERTBase i BiDAF na transformaciji kao bazne modele. Dalje pokazujemo da je okvir lako iskoristiti novi korisnici i zaključujemo da Velocidapter može veliko pomoći u obuci na dijalogovima orijentiranim na zadatke, posebno za manje resurse u novim domenama.</abstract_bs>
      <abstract_ca>Introduïm un marc de generació de diàleg sintètic, Velocidapter, que aborda el problem a de disponibilitat del cos per a la comprensió del diàleg. El Velocidapter augmenta els conjunts de dades simulant converses sintètiques per a un domini de diàleg orientat a les tasques, necessitant una petita quantitat de treball de bootstrapping per cada nou domini. Evaluam l'eficacia del nostre marc en un conjunt de dades de comprensió de diàleg orientat a les tasques, MRCWOZ, que creem anotant preguntes per les estacions d'espai en el restaurant, taxi i dominis d'hotel del conjunt de dades MultiWOZ 2.2 (Zang et al., 2020). Fem experiments dins un entorn de baix recursos, on premenem un model a SQuAD, finant-lo en una petita data original o en les dades sintètiques generades pel nostre marc. Velocidapter mostra millores significatives utilitzant tant BERTBase com BiDAF com models de base. Ens mostren que el marc és fàcil d'utilitzar pels usuaris nous i concluim que Velocidapter pot ajudar molt a formar-se sobre diàlegs orientats a les tasques, especialment en dominis emergents amb baixos recursos.</abstract_ca>
      <abstract_hy>Մենք ներկայացնում ենք սինթետիկ խոսակցության ստեղծման շրջանակ, Վելոսիդապեր, որը լուծում է մարմնի հասանելիության խնդիրը խոսակցության ընկալում: Վիլեոդիպտերը բարձրացնում է տվյալների համակարգերը՝ սիմուլյացնում է սինթետիկ հաղորդակցությունները խնդիրների ուղղությամբ խոսակցության ոլորտի համար, որոնց համար յուրաքանչյուր նոր ոլորտի համար անհրաժեշտ է մի փոքր քանակութ Մենք գնահատում ենք մեր կառուցվածքի արդյունավետությունը առաջադրանքների ուղղությամբ խոսակցության ընկալումների տվյալների համակարգի, MRCwoz-ի վրա, որը մենք վարժեցնում ենք նշորելով հարցերը ռեստորանի, տաքսի և հյուրանոցային բնագավառների համար, որոնք ներկայացնում են Մոթի-ՈւՕԶ Մենք փորձարկումներ ենք կատարում ցածր ռեսուրսների միջոցով, որտեղ մենք նախապատրաստում ենք SQUADի մոդելը, բարելավելով այն կամ փոքր սկզբնական տվյալների վրա, կամ մեր շրջանակի միջոցով ստեղծված սինթետիկ տվյալների վրա: Velocidapter shows significant improvements using both the transformer-based BERTBase and BiDAF as base models.  Մենք նաև ցույց ենք տալիս, որ շրջանակը հեշտ է օգտագործել նորից օգտագործողների կողմից և եզրակացում ենք, որ Վելոսիդապտերը կարող է մեծ օգնությամբ ուսումնասիրել խնդիրների վրա ուղղությամբ խոսակցություններ, հատկապես ցածր ռեսուրս</abstract_hy>
      <abstract_bn>আমরা একটি সিন্টেটিক ডায়ালগ প্রজন্মের ফ্রেমের সাথে পরিচয় করিয়ে দিচ্ছি ভেলোকিডাপ্টার, যা ডায়ালগ সম্পূর্ণ বিভাগের জন্য কোর্ ভেলোকিডাপ্টার অ্যাগ্রাগমেন্ট প্রত্যেক নতুন ডোমেইনের জন্য বুটস্ট্র্যাপিং কাজের প্রয়োজনীয় সামান্য পরিমাণ বুটস্ট্র্যাপিং করা আমাদের কার্যক্রমের কার্যক্রমের মূল্যায়ন করা হচ্ছে একটি কাজের মুখোমুখি ডায়ালগ সম্পূর্ণ ডায়ালগ সেট, এমআরসিওয়াজ, যা আমরা রেস্টোরেন্ট, ট্যাক্সি এবং মাল্টিউডওজ ২. ২ ডাটাসেট (জাং এন্ আমরা একটি নিম্নলিখিত রিসোর্স সেটের মধ্যে পরীক্ষা চালাই, যেখানে আমরা স্কুয়াডে একটি মডেল পাঠাই, যেখানে এটা সামান্য মূল তথ্যের উপর ভালোভাবে প Velocidapter shows significant improvements using both the transformer-based BERTBase and BiDAF as base models.  আমরা আরো দেখাচ্ছি যে নোভিক ব্যবহারকারীদের ব্যবহার করার কার্যক্রম সহজ এবং উপসংহার প্রদান করেছি যে ভেলোকিডাপ্টার কাজের মুখোমুখি আলোচনার উপর প্রশিক্ষণ প</abstract_bn>
      <abstract_cs>Představujeme syntetický framework pro generování dialogů Velocidapter, který řeší problém dostupnosti korpusu pro porozumění dialogům. Velocidapter rozšiřuje datové sady simulací syntetických konverzací pro dialogovou doménu orientovanou na úkoly, což vyžaduje malé množství bootstrapping práce pro každou novou doménu. Hodnotíme efektivitu našeho rámce na úlohově orientovaném datovém souboru porozumění dialogu MRCWOZ, který kurátorujeme anotováním otázek pro sloty v doméně restaurací, taxi a hotelů datové sady MultiWOZ 2.2 (Zang et al., 2020). Provádíme experimenty v rámci nízkých zdrojů, kde předtřídíme model na SQuAD, jemně ho vyladíme buď na malých originálních datech, nebo na syntetických datech generovaných naším frameworkem. Velocidapter vykazuje významné zlepšení použití jak transformátorových modelů BERTBase, tak BiDAF jako základních modelů. Dále ukazujeme, že framework je snadno použitelný pro začínající uživatele a dospěli jsme k závěru, že Velocidapter může výrazně pomoci školení dialogů orientovaných na úkoly, zejména pro vznikající domény s nízkými zdroji.</abstract_cs>
      <abstract_fi>Esittelemme synteettisen dialogin luomisen viitekehyksen, Velocidapterin, joka käsittelee korpusten saatavuuden ongelmaa dialogin ymmärtämiseksi. Velocidapter lisää datajoukkoja simuloimalla synteettisiä keskusteluja tehtävälähtöiselle dialogialueelle, mikä vaatii pienen määrän käynnistystyötä jokaiselle uudelle toimialueelle. Arvioimme viitekehyksemme tehokkuutta tehtäväkeskeisessä dialogin ymmärtämisen tietoaineistossa MRCWOZ, jonka kuratoimme kirjoittamalla kysymyksiä MultiWOZ 2.2 -aineiston ravintola-, taksi- ja hotellitoimialueille (Zang et al., 2020). Suoritamme kokeiluja vähävaraisessa ympäristössä, jossa esikäsittelemme mallin SQuAD:llä hienosäätäen sitä joko pienelle alkuperäiselle datalle tai kehyksemme tuottamalle synteettiselle datalle. Velocidapterin perusmalleina käytetään sekä muuntajapohjaista BERTBase- että BiDAF-mallia. Osoitamme lisäksi, että aloittelevien käyttäjien on helppo käyttää kehystä, ja päättelemme, että Velocidapter voi auttaa huomattavasti tehtävälähtöisten vuoropuhelujen harjoittelussa, erityisesti pieniresurssisilla kehittyvillä aloilla.</abstract_fi>
      <abstract_et>Tutvustame sünteetilise dialoogi loomise raamistiku Velocidapteri, mis käsitleb korpuse kättesaadavuse probleemi dialoogi mõistmiseks. Velocidapter täiendab andmekogumeid, simuleerides sünteetilisi vestlusi ülesandepõhise dialoogidomeeni jaoks, mis nõuab iga uue domeeni jaoks väikest alglaadimistööd. Hindame raamistiku efektiivsust ülesannetele orienteeritud dialoogi mõistmise andmekogumil MRCWOZ, mida kureerime MultiWOZ 2.2 andmekogumi restorani-, takso- ja hotellidomeenide teenindusaegade kohta (Zang et al., 2020). Me teeme katseid madala ressursiga seadistuses, kus me eeltreenime mudeli SQuAD-il, täpsustades seda kas väikeste originaalsete andmete või meie raamistiku loodud sünteetiliste andmete põhjal. Velocidapter näitab olulisi edusamme, kasutades baasmudelitena nii trafopõhist BERTBase kui ka BiDAF-i. Lisaks näitame, et raamistikku on algajatele lihtne kasutada ja järeldame, et Velocidapter võib oluliselt aidata koolitada ülesannetele orienteeritud dialoogide üle, eriti vähese ressursiga tekkivate valdkondade puhul.</abstract_et>
      <abstract_ha>Tuna fara wani firam na zauren akwatin zauren akwatin bayani na haɗi, mai lokaliidator, wanda ke yi amfani da matabbatar da kornau'in da za'a samu ga zauren akwatin bayani. Ƙara masu amfani da shiryoyin ayuka na lolokaliidator, ana ƙayyade mazaɓa na haɗi da shiryayyu wa zauren akwatin bayani na masu shirya wa aikin ayuka, da kuma yana ƙayyade kiman goyi mai ƙara wa duk wuri na daban. Kana ƙayyade aikin kafaffiyarmu a kan zauren akwatin bayani masu cikin aikin da aka yi fari da shi, MRCWOZ, wanda Muke zartar da su kafaffiyar masu sakan cikin restaurant, tax, da hotel guda na multi-WOZ 2.2 (Zag et al, 2020). We run experiments within a low-resource setting, where we pretrain a model on SQuAD, fine-tuning it on either a small original data or on the synthetic data generated by our framework.  @ info: whatsthis Tuna ƙara nuna cewa, firam mai sauƙi ne da za'a yi amfani da shi na masu amfani da mataimaki na nowaya kuma ana ƙarfafa cewa, lolocidator yana iya ƙaranci taimako da mafarin wa zauren akwatin bayani masu fara-danganta, da haske dõmin masu buƙata masu ƙaranci.</abstract_ha>
      <abstract_he>אנחנו מציגים מסגרת דור דיאלוג סינטטית, Velocidapter, שמטפלת בבעיה הזמינות של הקורפוס להבינה דיאלוג. המהירות מגדילה קבוצות נתונים על ידי סימולציה של שיחות סינטטיות לתחום דיאלוג ממוקד למשימות, שדורש כמות קטנה של עבודת התחילה עבור כל תחום חדש. אנו מעריכים את היעילות של המסגרת שלנו על קבוצת נתונים להבנה של דיאלוג ממוקד למשימות, MRCWOZ, שאנחנו מעריכים על ידי הערות שאלות למסעדות במסעדה, מונית ומלון בתחומים של קבוצת נתונים MultiWOZ 2.2 (Zang et al., 2020). אנחנו מנהלים ניסויים בתוך מסגרת משאבים נמוכה, שבו אנו מחדש מתאמנים מודל על SQuAD, מתאימים אותו על מידע מקורי קטן או על מידע הסינטטי שנוצר על ידי המסגרת שלנו. Velocidapter shows significant improvements using both the transformer-based BERTBase and BiDAF as base models.  אנו נוספים מראים כי המסגרת קלה להשתמש על ידי משתמשים חדשים ומסקנה כי Velocidapter יכול לעזור באופן גדול לאימונים על דיאלוגים ממוקדים למשימות, במיוחד עבור תחומות מתפתחות נמוכות משאבים.</abstract_he>
      <abstract_bo>ང་ཚོས་རང་ཉིད་ཀྱི་དབང་རྩལ་གྱི་སྒྲ་ཚུལ་གྱི་རྩོམ་པ་ཞིག་གསལ་བཀོད་བྱེད་ཀྱི་ཡོད། Velocidapter augments datasets by simulating synthetic conversations for a task-oriented dialog domain, requiring a small amount of bootstrapping work for each new domain. We evaluate the efficacy of our framework on a task-oriented dialog comprehension dataset, MRCWOZ, which we curate by annotating questions for slots in the restaurant, taxi, and hotel domains of the MultiWOZ 2.2 dataset (Zang et al., 2020). We run experiments within a low-resource setting, where we pretrain a model on SQuAD, fine-tuning it on either a small original data or on the synthetic data generated by our framework. Velocidapter нь transformer-based BERTBase་དང་། BiDAF རྨང་གཞི་མིག་དཔེ་བར་སྤྱོད་བཞིན་པའི་ཆེས་ཉུང་བའི་ཡར་རྒྱས་གཏོང་བྱེད་ཀྱི་ཡོད། ང་ཚོས་བྱ་རིམ་འདི་གསར་འགོད་པའི་སྤྱོད་མཁན་གྱི་ལག་ལེན་པ་ཚོ་ལས་སྤྱོད་ཐབས་མེད་པར་ལས་ཀར་ཆེ།</abstract_bo>
      <abstract_jv>Awak dhéwé nggawe sistem sing paling senetik dialog, velocidapter, sing dumalakno perusahaan kanggo ngerasakno dialog Speed Awak dhéwé nggunakake efekasi kanggo nggawe sistem sing rumangsa nyebuturan dataset, MRWOZ, sing nyimpek dhéwé nggawe ngulinakake perusahaan kanggo kalagayet kanggo ngilangno dolanan lokal restoran, tausi n' lan lokal sing gawe dataset MultiWOZ 2.2 (Sadang et al, 2020). Awak dhéwé mulai éntuk éntuk sistem sing wis ana dadi sing paling-pernik, ingkang awak dhéwé nggawe model sing nyebutaké speed Awak dhéwé nglanggar wigatining sistem akeh gampang kanggo nggambar aturan winih lan nganggep iki, speed</abstract_jv>
      <abstract_sk>Predstavljamo sintetični okvir za generiranje dialoga Velocidapter, ki obravnava problem razpoložljivosti korpusa za razumevanje dialoga. Velocidapter povečuje nabore podatkov s simuliranjem sintetičnih pogovorov za domeno dialoga, usmerjeno v opravila, kar zahteva majhno količino dela zagonskega dela za vsako novo domeno. Učinkovitost našega okvira ocenjujemo na nalogo usmerjenem naboru podatkov o razumevanju dialoga MRCWOZ, ki ga kuriramo z označevanjem vprašanj za reže v restavracijah, taksijih in hotelskih domenah nabora podatkov MultiWOZ 2.2 (Zang et al., 2020). Izvajamo poskuse znotraj nastavitve nizkih virov, kjer predpredvajamo model na SQuAD in ga natančno nastavimo bodisi na majhnih originalnih podatkih bodisi na sintetičnih podatkih, ki jih ustvari naš okvir. Velocidapter kaže znatne izboljšave z uporabo transformatorskega BERTBase in BiDAF kot osnovnega modela. Poleg tega pokažemo, da je okvir enostaven za uporabo začetnih uporabnikov, in ugotavljamo, da lahko Velocidapter v veliki meri pomaga pri usposabljanju v okviru dialogov, usmerjenih v naloge, zlasti pri nastajajočih področjih z nizkimi viri.</abstract_sk>
      </paper>
    <paper id="16">
      <title>A Simple yet Effective Method for Sentence Ordering</title>
      <author><first>Aili</first><last>Shen</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>154–160</pages>
      <abstract>Sentence ordering is the task of arranging a given bag of sentences so as to maximise the coherence of the overall text. In this work, we propose a simple yet effective <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training method</a> that improves the capacity of models to capture overall text coherence based on training over pairs of sentences / segments. Experimental results show the superiority of our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> in in- and cross-domain settings. The utility of our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> is also verified over a multi-document summarisation task.</abstract>
      <url hash="e2aab5e3">2021.sigdial-1.16</url>
      <bibkey>shen-baldwin-2021-simple</bibkey>
      <video href="https://www.youtube.com/watch?v=HcurPPqHcrY" />
    </paper>
    <paper id="18">
      <title>Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair Coherence Scoring</title>
      <author><first>Linzi</first><last>Xing</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>167–177</pages>
      <abstract>Dialogue topic segmentation is critical in several dialogue modeling problems. However, popular <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised approaches</a> only exploit surface features in assessing topical coherence among utterances. In this work, we address this limitation by leveraging supervisory signals from the utterance-pair coherence scoring task. First, we present a simple yet effective strategy to generate a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training corpus</a> for utterance-pair coherence scoring. Then, we train a BERT-based neural utterance-pair coherence model with the obtained <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training corpus</a>. Finally, such <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is used to measure the topical relevance between utterances, acting as the basis of the segmentation inference. Experiments on three public datasets in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> demonstrate that our proposal outperforms the state-of-the-art baselines.</abstract>
      <url hash="284d742f">2021.sigdial-1.18</url>
      <bibkey>xing-carenini-2021-improving</bibkey>
      <video href="https://www.youtube.com/watch?v=04Urc5LRBlk" />
      <pwccode url="https://github.com/lxing532/Dialogue-Topic-Segmenter" additional="false">lxing532/Dialogue-Topic-Segmenter</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/doc2dial-1">Doc2Dial</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/doc2dial">doc2dial</pwcdataset>
    </paper>
    <paper id="21">
      <title>Contrastive Response Pairs for Automatic Evaluation of Non-task-oriented Neural Conversational Models</title>
      <author><first>Koshiro</first><last>Okano</last></author>
      <author><first>Yu</first><last>Suzuki</last></author>
      <author><first>Masaya</first><last>Kawamura</last></author>
      <author><first>Tsuneo</first><last>Kato</last></author>
      <author><first>Akihiro</first><last>Tamura</last></author>
      <author><first>Jianming</first><last>Wu</last></author>
      <pages>202–207</pages>
      <abstract>Responses generated by neural conversational models (NCMs) for non-task-oriented systems are difficult to evaluate. We propose contrastive response pairs (CRPs) for automatically evaluating responses from non-task-oriented NCMs. We conducted an error analysis on responses generated by an encoder-decoder recurrent neural network (RNN) type NCM and created three types of CRPs corresponding to the three most frequent errors found in the analysis. Three NCMs of different response quality were objectively evaluated with the CRPs and compared to a subjective assessment. The correctness obtained by the three types of CRPs were consistent with the results of the subjective assessment.</abstract>
      <url hash="6ccd3ce7">2021.sigdial-1.21</url>
      <bibkey>okano-etal-2021-contrastive</bibkey>
      <video href="https://www.youtube.com/watch?v=Wtma3lm9AMc" />
    </paper>
    <paper id="25">
      <title>Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems : A Survey</title>
      <author><first>Vevake</first><last>Balaraman</last></author>
      <author><first>Seyedmostafa</first><last>Sheikhalishahi</last></author>
      <author><first>Bernardo</first><last>Magnini</last></author>
      <pages>239–251</pages>
      <abstract>This paper aims at providing a comprehensive overview of recent developments in dialogue state tracking (DST) for task-oriented conversational systems. We introduce the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, the main <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> that have been exploited as well as their evaluation metrics, and we analyze several proposed approaches. We distinguish between static ontology DST models, which predict a fixed set of dialogue states, and dynamic ontology models, which can predict dialogue states even when the <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a> changes. We also discuss the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s ability to track either single or multiple domains and to scale to new domains, both in terms of <a href="https://en.wikipedia.org/wiki/Knowledge_transfer">knowledge transfer</a> and zero-shot learning. We cover a period from 2013 to 2020, showing a significant increase of multiple domain methods, most of them utilizing pre-trained language models.</abstract>
      <url hash="6722fe65">2021.sigdial-1.25</url>
      <bibkey>balaraman-etal-2021-recent</bibkey>
      <video href="https://www.youtube.com/watch?v=zQuaI9czmJk" />
      <pwcdataset url="https://paperswithcode.com/dataset/multiwoz">MultiWOZ</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sgd">SGD</pwcdataset>
    </paper>
    <paper id="26">
      <title>Scikit-talk : A toolkit for processing real-world conversational speech data<fixed-case>S</fixed-case>cikit-talk: A toolkit for processing real-world conversational speech data</title>
      <author><first>Andreas</first><last>Liesenfeld</last></author>
      <author><first>Gabor</first><last>Parti</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <pages>252–256</pages>
      <abstract>We present Scikit-talk, an open-source toolkit for processing collections of real-world conversational speech in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python</a>. First of its kind, the <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a> equips those interested in studying or modeling conversations with an easy-to-use interface to build and explore large collections of transcriptions and annotations of talk-in-interaction. Designed for applications in <a href="https://en.wikipedia.org/wiki/Speech_processing">speech processing</a> and Conversational AI, Scikit-talk provides tools to custom-build datasets for tasks such as intent prototyping, dialog flow testing, and conversation design. Its preprocessor module comes with several pre-built interfaces for common transcription formats, which aim to make working across multiple data sources more accessible. The explorer module provides a collection of tools to explore and analyse this data type via <a href="https://en.wikipedia.org/wiki/String_matching">string matching</a> and unsupervised machine learning techniques. Scikit-talk serves as a platform to collect and connect different transcription formats and representations of talk, enabling the user to quickly build multilingual datasets of varying detail and granularity. Thus, the toolkit aims to make working with authentic conversational speech data in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python</a> more accessible and to provide the user with comprehensive options to work with representations of talk in appropriate detail for any downstream task. For the latest updates and information on currently supported languages and language resources, please refer to : https://pypi.org/project/scikit-talk/<i>preprocessor</i> module comes with several pre-built interfaces for common transcription formats, which aim to make working across multiple data sources more accessible. The <i>explorer</i> module provides a collection of tools to explore and analyse this data type via string matching and unsupervised machine learning techniques. Scikit-talk serves as a platform to collect and connect different transcription formats and representations of talk, enabling the user to quickly build multilingual datasets of varying detail and granularity. Thus, the toolkit aims to make working with authentic conversational speech data in Python more accessible and to provide the user with comprehensive options to work with representations of talk in appropriate detail for any downstream task. For the latest updates and information on currently supported languages and language resources, please refer to: https://pypi.org/project/scikit-talk/</abstract>
      <url hash="c9f37c38">2021.sigdial-1.26</url>
      <bibkey>liesenfeld-etal-2021-scikit</bibkey>
      <video href="https://www.youtube.com/watch?v=yNtYLKCo3xI" />
    </paper>
    <paper id="31">
      <title>Summarizing Behavioral Change Goals from SMS Exchanges to Support Health Coaches<fixed-case>SMS</fixed-case> Exchanges to Support Health Coaches</title>
      <author><first>Itika</first><last>Gupta</last></author>
      <author><first>Barbara</first><last>Di Eugenio</last></author>
      <author><first>Brian D.</first><last>Ziebart</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Ben S.</first><last>Gerber</last></author>
      <author><first>Lisa K.</first><last>Sharp</last></author>
      <pages>276–289</pages>
      <abstract>Regular physical activity is associated with a reduced risk of chronic diseases such as type 2 diabetes and improved <a href="https://en.wikipedia.org/wiki/Mental_health">mental well-being</a>. Yet, more than half of the US population is insufficiently active. Health coaching has been successful in promoting healthy behaviors. In this paper, we present our work towards assisting <a href="https://en.wikipedia.org/wiki/Coaching">health coaches</a> by extracting the physical activity goal the user and coach negotiate via <a href="https://en.wikipedia.org/wiki/Text_messaging">text messages</a>. We show that information captured by dialogue acts can help to improve the goal extraction results. We employ both traditional and transformer-based machine learning models for dialogue acts prediction and find them statistically indistinguishable in performance on our health coaching dataset. Moreover, we discuss the feedback provided by the health coaches when evaluating the correctness of the extracted goal summaries. This work is a step towards building a virtual assistant health coach to promote a healthy lifestyle.</abstract>
      <url hash="99e5467b">2021.sigdial-1.31</url>
      <bibkey>gupta-etal-2021-summarizing</bibkey>
      <video href="https://www.youtube.com/watch?v=0FxAJvs93WA" />
    </paper>
    <paper id="33">
      <title>CIDER : Commonsense Inference for Dialogue Explanation and Reasoning<fixed-case>CIDER</fixed-case>: Commonsense Inference for Dialogue Explanation and Reasoning</title>
      <author><first>Deepanway</first><last>Ghosal</last></author>
      <author><first>Pengfei</first><last>Hong</last></author>
      <author><first>Siqi</first><last>Shen</last></author>
      <author><first>Navonil</first><last>Majumder</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <pages>301–313</pages>
      <abstract>Commonsense inference to understand and explain <a href="https://en.wikipedia.org/wiki/Human_language">human language</a> is a fundamental research problem in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Explaining human conversations poses a great challenge as it requires contextual understanding, planning, <a href="https://en.wikipedia.org/wiki/Inference">inference</a>, and several aspects of <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a> including causal, temporal, and commonsense reasoning. In this work, we introduce CIDER   a manually curated dataset that contains dyadic dialogue explanations in the form of implicit and explicit knowledge triplets inferred using contextual commonsense inference. Extracting such rich explanations from <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> can be conducive to improving several downstream <a href="https://en.wikipedia.org/wiki/Application_software">applications</a>. The annotated triplets are categorized by the type of <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">commonsense knowledge</a> present (e.g., causal, conditional, temporal). We set up three different tasks conditioned on the annotated dataset : Dialogue-level Natural Language Inference, Span Extraction, and Multi-choice Span Selection. Baseline results obtained with transformer-based models reveal that the tasks are difficult, paving the way for promising future research. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and the baseline implementations are publicly available at https://github.com/declare-lab/CIDER.</abstract>
      <url hash="ec76dd0d">2021.sigdial-1.33</url>
      <bibkey>ghosal-etal-2021-cider</bibkey>
      <video href="https://www.youtube.com/watch?v=vSNq0OOGRc0" />
      <pwccode url="https://github.com/declare-lab/CIDER" additional="false">declare-lab/CIDER</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dream">DREAM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glucose">GLUCOSE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mutual">MuTual</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/swag">SWAG</pwcdataset>
    </paper>
    <paper id="37">
      <title>How Should Agents Ask Questions For <a href="https://en.wikipedia.org/wiki/Situated_learning">Situated Learning</a>? An Annotated Dialogue Corpus</title>
      <author><first>Felix</first><last>Gervits</last></author>
      <author><first>Antonio</first><last>Roque</last></author>
      <author><first>Gordon</first><last>Briggs</last></author>
      <author><first>Matthias</first><last>Scheutz</last></author>
      <author><first>Matthew</first><last>Marge</last></author>
      <pages>353–359</pages>
      <abstract>Intelligent agents that are confronted with novel concepts in situated environments will need to ask their human teammates questions to learn about the <a href="https://en.wikipedia.org/wiki/Universe">physical world</a>. To better understand this problem, we need data about asking questions in situated task-based interactions. To this end, we present the Human-Robot Dialogue Learning (HuRDL) Corpus-a novel dialogue corpus collected in an online interactive virtual environment in which human participants play the role of a robot performing a collaborative tool-organization task. We describe the <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpus data</a> and a corresponding <a href="https://en.wikipedia.org/wiki/Annotation">annotation scheme</a> to offer insight into the form and content of questions that humans ask to facilitate learning in a situated environment. We provide the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> as an empirically-grounded resource for improving question generation in situated intelligent agents.</abstract>
      <url hash="c1163e34">2021.sigdial-1.37</url>
      <bibkey>gervits-etal-2021-agents</bibkey>
      <video href="https://www.youtube.com/watch?v=9IAwjDa0Wp0" />
      <pwccode url="https://github.com/USArmyResearchLab/ARL-HuRDL" additional="false">USArmyResearchLab/ARL-HuRDL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hurdl">HuRDL</pwcdataset>
    </paper>
    <paper id="40">
      <title>What to Fact-Check : Guiding Check-Worthy Information Detection in News Articles through Argumentative Discourse Structure</title>
      <author><first>Tariq</first><last>Alhindi</last></author>
      <author><first>Brennan</first><last>McManus</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <pages>380–391</pages>
      <abstract>Most existing <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> for automatic fact-checking start with a precompiled list of claims to verify. We investigate the understudied problem of determining what statements in <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> are worthy to fact-check. We annotate the <a href="https://en.wikipedia.org/wiki/Argument_structure">argument structure</a> of 95 <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a> in the <a href="https://en.wikipedia.org/wiki/Global_warming">climate change domain</a> that are fact-checked by climate scientists at climatefeedback.org. We release the first multi-layer annotated corpus for both argumentative discourse structure (argument types and relations) and for fact-checked statements in news articles. We discuss the connection between <a href="https://en.wikipedia.org/wiki/Argument_structure">argument structure</a> and check-worthy statements and develop several baseline models for detecting check-worthy statements in the <a href="https://en.wikipedia.org/wiki/Climate_change_modeling">climate change domain</a>. Our preliminary results show that using information about argumentative discourse structure shows slight but statistically significant improvement over a baseline of local discourse structure.</abstract>
      <url hash="c1a4cf3d">2021.sigdial-1.40</url>
      <bibkey>alhindi-etal-2021-fact</bibkey>
      <video href="https://www.youtube.com/watch?v=oBT795ipFFM" />
    </paper>
    <paper id="41">
      <title>How open are the conversations with open-domain chatbots? A proposal for Speech Event based evaluation</title>
      <author><first>A. Seza</first><last>Doğruöz</last></author>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <pages>392–402</pages>
      <abstract>Open-domain chatbots are supposed to converse freely with humans without being restricted to a topic, task or domain. However, the boundaries and/or contents of open-domain conversations are not clear. To clarify the boundaries of openness, we conduct two studies : First, we classify the types of <a href="https://en.wikipedia.org/wiki/Speech">speech events</a> encountered in a chatbot evaluation data set (i.e., Meena by Google) and find that these conversations mainly cover the small talk category and exclude the other speech event categories encountered in real life human-human communication. Second, we conduct a small-scale pilot study to generate <a href="https://en.wikipedia.org/wiki/Online_chat">online conversations</a> covering a wider range of <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech event categories</a> between two humans vs. a human and a state-of-the-art <a href="https://en.wikipedia.org/wiki/Chatbot">chatbot</a> (i.e., Blender by Facebook). A human evaluation of these generated <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> indicates a preference for human-human conversations, since the human-chatbot conversations lack coherence in most speech event categories. Based on these results, we suggest (a) using the term <a href="https://en.wikipedia.org/wiki/Small_talk">small talk</a> instead of <a href="https://en.wikipedia.org/wiki/Open_domain">open-domain</a> for the current <a href="https://en.wikipedia.org/wiki/Chatbot">chatbots</a> which are not that open in terms of conversational abilities yet, and (b) revising the evaluation methods to test the chatbot conversations against other speech events.</abstract>
      <url hash="aa2871ba">2021.sigdial-1.41</url>
      <bibkey>dogruoz-skantze-2021-open</bibkey>
      <video href="https://www.youtube.com/watch?v=bYXcZg_VWiE" />
    </paper>
    <paper id="44">
      <title>DTAFA : Decoupled Training Architecture for Efficient FAQ Retrieval<fixed-case>DTAFA</fixed-case>: Decoupled Training Architecture for Efficient <fixed-case>FAQ</fixed-case> Retrieval</title>
      <author><first>Haytham</first><last>Assem</last></author>
      <author><first>Sourav</first><last>Dutta</last></author>
      <author><first>Edward</first><last>Burgin</last></author>
      <pages>423–430</pages>
      <abstract>Automated Frequently Asked Question (FAQ) retrieval provides an effective procedure to provide prompt responses to natural language based queries, providing an efficient platform for large-scale service-providing companies for presenting readily available information pertaining to customers’ questions. We propose DTAFA, a novel multi-lingual FAQ retrieval system that aims at improving the top-1 retrieval accuracy with the least number of parameters. We propose two decoupled deep learning architectures trained for (i) candidate generation via text classification for a user question, and (ii) learning fine-grained semantic similarity between user questions and the FAQ repository for candidate refinement. We validate our <a href="https://en.wikipedia.org/wiki/System">system</a> using real-life enterprise data as well as <a href="https://en.wikipedia.org/wiki/Open-source_data">open source dataset</a>. Empirically we show that DTAFA achieves better <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> compared to existing <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> while requiring nearly 30 lesser number of <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training parameters</a>.</abstract>
      <url hash="ff972d8c">2021.sigdial-1.44</url>
      <bibkey>assem-etal-2021-dtafa</bibkey>
      <video href="https://www.youtube.com/watch?v=_tJhKdtu8EM" />
    </paper>
    <paper id="45">
      <title>Projection of Turn Completion in Incremental Spoken Dialogue Systems</title>
      <author><first>Erik</first><last>Ekstedt</last></author>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <pages>431–437</pages>
      <abstract>The ability to take turns in a fluent way (i.e., without long response delays or frequent interruptions) is a fundamental aspect of any spoken dialog system. However, practical speech recognition services typically induce a long response delay, as it takes time before the processing of the user’s utterance is complete. There is a considerable amount of research indicating that humans achieve fast response times by projecting what the interlocutor will say and estimating upcoming turn completions. In this work, we implement this mechanism in an incremental spoken dialog system, by using a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> that generates possible futures to project upcoming completion points. In theory, this could make the <a href="https://en.wikipedia.org/wiki/System">system</a> more responsive, while still having access to <a href="https://en.wikipedia.org/wiki/Semantics">semantic information</a> not yet processed by the <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognizer</a>. We conduct a small study which indicates that this is a viable approach for practical dialog systems, and that this is a promising direction for future research.</abstract>
      <url hash="cbe97965">2021.sigdial-1.45</url>
      <bibkey>ekstedt-skantze-2021-projection</bibkey>
      <video href="https://www.youtube.com/watch?v=jfB1gE1wP6Y" />
    </paper>
    <paper id="50">
      <title>Do Encoder Representations of Generative Dialogue Models have sufficient summary of the Information about the task?</title>
      <author><first>Prasanna</first><last>Parthasarathi</last></author>
      <author><first>Joelle</first><last>Pineau</last></author>
      <author><first>Sarath</first><last>Chandar</last></author>
      <pages>477–488</pages>
      <abstract>Predicting the next utterance in dialogue is contingent on encoding of users’ input text to generate appropriate and relevant response in data-driven approaches. Although the semantic and syntactic quality of the language generated is evaluated, more often than not, the encoded representation of input is not evaluated. As the representation of the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> is essential for predicting the appropriate response, evaluation of <a href="https://en.wikipedia.org/wiki/Encoder">encoder representation</a> is a challenging yet important problem. In this work, we showcase evaluating the text generated through human or automatic metrics is not sufficient to appropriately evaluate soundness of the language understanding of dialogue models and, to that end, propose a set of probe tasks to evaluate encoder representation of different <a href="https://en.wikipedia.org/wiki/Encoder">language encoders</a> commonly used in dialogue models. From experiments, we observe that some of the probe tasks are easier and some are harder for even sophisticated model architectures to learn. And, through experiments we observe that RNN based architectures have lower performance on automatic metrics on text generation than transformer model but perform better than the transformer model on the probe tasks indicating that RNNs might preserve task information better than the Transformers.</abstract>
      <url hash="582efccf">2021.sigdial-1.50</url>
      <bibkey>parthasarathi-etal-2021-encoder</bibkey>
      <video href="https://www.youtube.com/watch?v=AwHuUPEpJFA" />
      <pwccode url="https://github.com/ppartha03/Dialogue-Probe-Tasks-Public" additional="false">ppartha03/Dialogue-Probe-Tasks-Public</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/persona-chat-1">PERSONA-CHAT</pwcdataset>
    </paper>
    <paper id="52">
      <title>Schema-Guided Paradigm for Zero-Shot Dialog</title>
      <author><first>Shikib</first><last>Mehri</last></author>
      <author><first>Maxine</first><last>Eskenazi</last></author>
      <pages>499–508</pages>
      <abstract>Developing mechanisms that flexibly adapt dialog systems to unseen tasks and domains is a major challenge in dialog research. Neural models implicitly memorize task-specific dialog policies from the training data. We posit that this implicit memorization has precluded zero-shot transfer learning. To this end, we leverage the schema-guided paradigm, wherein the task-specific dialog policy is explicitly provided to the model. We introduce the Schema Attention Model (SAM) and improved schema representations for the STAR corpus. SAM obtains significant improvement in zero-shot settings, with a +22 F1 score improvement over prior work. These results validate the feasibility of zero-shot generalizability in <a href="https://en.wikipedia.org/wiki/Dialogue">dialog</a>. Ablation experiments are also presented to demonstrate the efficacy of <a href="https://en.wikipedia.org/wiki/Samarium_selenide">SAM</a>.</abstract>
      <url hash="e42940e6">2021.sigdial-1.52</url>
      <bibkey>mehri-eskenazi-2021-schema</bibkey>
      <video href="https://www.youtube.com/watch?v=usZQulwdOZs" />
      <pwccode url="https://github.com/Shikib/schema_attention_model" additional="false">Shikib/schema_attention_model</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/star">STAR</pwcdataset>
    </paper>
    <paper id="53">
      <title>Coreference-Aware Dialogue Summarization</title>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Ke</first><last>Shi</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>509–519</pages>
      <abstract>Summarizing conversations via neural approaches has been gaining research traction lately, yet it is still challenging to obtain practical solutions. Examples of such challenges include unstructured information exchange in dialogues, informal interactions between speakers, and dynamic role changes of speakers as the dialogue evolves. Many of such challenges result in complex coreference links. Therefore, in this work, we investigate different approaches to explicitly incorporate coreference information in neural abstractive dialogue summarization models to tackle the aforementioned challenges. Experimental results show that the proposed approaches achieve state-of-the-art performance, implying it is useful to utilize coreference information in dialogue summarization. Evaluation results on factual correctness suggest such coreference-aware models are better at tracing the information flow among interlocutors and associating accurate status / actions with the corresponding <a href="https://en.wikipedia.org/wiki/Interlocutor_(linguistics)">interlocutors</a> and person mentions.</abstract>
      <url hash="9be8ac79">2021.sigdial-1.53</url>
      <bibkey>liu-etal-2021-coreference</bibkey>
      <revision id="1" href="2021.sigdial-1.53v1" hash="a9c373ea" />
      <revision id="2" href="2021.sigdial-1.53v2" hash="9be8ac79" date="2022-01-24">Fixed typos in Section 3 and updated Table 3.</revision>
      <video href="https://www.youtube.com/watch?v=XNiUdhaW6LI" />
      <pwccode url="https://github.com/seq-to-mind/coref_dial_summ" additional="false">seq-to-mind/coref_dial_summ</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/samsum-corpus">SAMSum Corpus</pwcdataset>
    </paper>
    <paper id="54">
      <title>Weakly Supervised Extractive Summarization with Attention</title>
      <author><first>Yingying</first><last>Zhuang</last></author>
      <author><first>Yichao</first><last>Lu</last></author>
      <author><first>Simi</first><last>Wang</last></author>
      <pages>520–529</pages>
      <abstract>Automatic summarization aims to extract important information from large amounts of <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">textual data</a> in order to create a shorter version of the original texts while preserving its information. Training traditional extractive summarization models relies heavily on human-engineered labels such as sentence-level annotations of summary-worthiness. However, in many use cases, such human-engineered labels do not exist and manually annotating thousands of documents for the purpose of training models may not be feasible. On the other hand, indirect signals for summarization are often available, such as agent actions for customer service dialogues, headlines for news articles, <a href="https://en.wikipedia.org/wiki/Diagnosis">diagnosis</a> for <a href="https://en.wikipedia.org/wiki/Electronic_health_record">Electronic Health Records</a>, etc. In this paper, we develop a general framework that generates extractive summarization as a byproduct of <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning tasks</a> for indirect signals via the help of attention mechanism. We test our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on customer service dialogues and experimental results demonstrated that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> can reliably select informative sentences and words for <a href="https://en.wikipedia.org/wiki/Automatic_summarization">automatic summarization</a>.</abstract>
      <url hash="96373a53">2021.sigdial-1.54</url>
      <bibkey>zhuang-etal-2021-weakly</bibkey>
      <video href="https://www.youtube.com/watch?v=0xiQe0OPwBA" />
    </paper>
    <paper id="55">
      <title>Incremental temporal summarization in multi-party meetings</title>
      <author><first>Ramesh</first><last>Manuvinakurike</last></author>
      <author><first>Saurav</first><last>Sahay</last></author>
      <author><first>Wenda</first><last>Chen</last></author>
      <author><first>Lama</first><last>Nachman</last></author>
      <pages>530–541</pages>
      <abstract>In this work, we develop a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for incremental temporal summarization in a multiparty dialogue. We use crowd-sourcing paradigm with a model-in-loop approach for collecting the summaries and compare the data with the expert summaries. We leverage the question generation paradigm to automatically generate questions from the <a href="https://en.wikipedia.org/wiki/Dialogue">dialogue</a>, which can be used to validate the <a href="https://en.wikipedia.org/wiki/Participation_(decision_making)">user participation</a> and potentially also draw attention of the user towards the contents then need to summarize. We then develop several <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for abstractive summary generation in the Incremental temporal scenario. We perform a detailed analysis of the results and show that including the past context into the summary generation yields better summaries.</abstract>
      <url hash="484cf7ac">2021.sigdial-1.55</url>
      <bibkey>manuvinakurike-etal-2021-incremental</bibkey>
      <video href="https://www.youtube.com/watch?v=CnHqotO89jQ" />
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="58">
      <title>Large-Scale Quantitative Evaluation of Dialogue Agents’ Response Strategies against Offensive Users</title>
      <author><first>Haojun</first><last>Li</last></author>
      <author><first>Dilara</first><last>Soylu</last></author>
      <author><first>Christopher</first><last>Manning</last></author>
      <pages>556–561</pages>
      <abstract>As voice assistants and dialogue agents grow in popularity, so does the abuse they receive. We conducted a large-scale quantitative evaluation of the effectiveness of 4 response types (avoidance, why, empathetic, and counter), and 2 additional factors (using a redirect or a voluntarily provided name) that have not been tested by prior work. We measured their direct effectiveness on real users in-the-wild by the re-offense ratio, length of conversation after the initial response, and number of turns until the next re-offense. Our experiments confirm prior lab studies in showing that <a href="https://en.wikipedia.org/wiki/Empathy">empathetic responses</a> perform better than generic avoidance responses as well as counter responses. We show that dialogue agents should almost always guide offensive users to a new topic through the use of redirects and use the user’s name if provided. As compared to a baseline avoidance strategy employed by commercial agents, our best <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a> is able to reduce the re-offense ratio from 92 % to 43 %.</abstract>
      <url hash="8fd5350b">2021.sigdial-1.58</url>
      <bibkey>li-etal-2021-large</bibkey>
      <video href="https://www.youtube.com/watch?v=FLsqwyGx4zM" />
      <pwccode url="https://github.com/lithiumh/offensive" additional="false">lithiumh/offensive</pwccode>
    </paper>
  </volume>
</collection>