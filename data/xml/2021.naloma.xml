<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.naloma">
  <volume id="1" ingest-date="2021-10-27">
    <meta>
      <booktitle>Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA)</booktitle>
      <editor><first>Aikaterini-Lida</first><last>Kalouli</last></editor>
      <editor><first>Lawrence S.</first><last>Moss</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Groningen, the Netherlands (online)</address>
      <month>June</month>
      <year>2021</year>
      <url hash="68bf91c3">2021.naloma-1</url>
    </meta>
    <frontmatter>
      <url hash="b8097cd2">2021.naloma-1.0</url>
      <bibkey>naloma-2021-workshops</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Attentive Tree-structured Network for Monotonicity Reasoning</title>
      <author><first>Zeming</first><last>Chen</last></author>
      <pages>12–21</pages>
      <abstract>Many state-of-art neural models designed for monotonicity reasoning perform poorly on downward inference. To address this shortcoming, we developed an attentive tree-structured neural network. It consists of a tree-based long-short-term-memory network (Tree-LSTM) with soft attention. It is designed to model the syntactic parse tree information from the sentence pair of a reasoning task. A self-attentive aggregator is used for aligning the representations of the premise and the hypothesis. We present our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> and evaluate it using the Monotonicity Entailment Dataset (MED). We show and attempt to explain that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms existing <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on MED.</abstract>
      <url hash="cfbaf3f9">2021.naloma-1.3</url>
      <bibkey>chen-2021-attentive</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/help">HELP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/med">MED</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    <title_ar>شبكة شجرية اليقظة لاستدلال الرتابة</title_ar>
      <title_fr>Réseau structuré en arbre attentif pour le raisonnement sur la monotonicité</title_fr>
      <title_es>Red atenta estructurada en árbol para el razonamiento de la monotonicidad</title_es>
      <title_pt>Rede Atenta Estruturada em Árvore para Raciocínio de Monotonicidade</title_pt>
      <title_ja>単調性推論のための注意深いツリー構造ネットワーク</title_ja>
      <title_ru>Внимательная деревянная сеть для рассуждения о монотонности</title_ru>
      <title_zh>单调推理细心树结构网络</title_zh>
      <title_hi>Monotonicity Reasoning के लिए चौकस ट्री-संरचित नेटवर्क</title_hi>
      <title_ga>Líonra Aireach Crann-struchtúrtha le haghaidh Réasúnaíochta Monatonachta</title_ga>
      <title_el>Προσεκτικό Δίκτυο Δομημένης Δέντρου για την Λογιστική Μονοτονίας</title_el>
      <title_ka>მონოტონისტის მიზეზებისთვის აღმოჩენებული ქსტრუქტურაციული ქსელი</title_ka>
      <title_it>Rete attenta strutturata ad albero per la ragione della monotonia</title_it>
      <title_hu>Figyelmes, fa-strukturált hálózat a monotonitás érvelésére</title_hu>
      <title_lt>Pagrindinis medžių struktūrinis monotoniškumo pagrindimo tinklas</title_lt>
      <title_ms>Name</title_ms>
      <title_kk>Монотикалық себебі үшін нақты ағаш құрылған желі</title_kk>
      <title_mk>Name</title_mk>
      <title_ml>മോണോണിനിറ്റി വായിക്കുന്നതിനുള്ള വൃക്ഷത്തിനുള്ള ശൃംഖലം</title_ml>
      <title_no>Gjennomsiktig tråstrukturert nettverk for monotoniske grunnlag</title_no>
      <title_ro>Rețea atentă structurată în arbori pentru raționarea monotonicității</title_ro>
      <title_pl>Uważna sieć oparta na drzewie dla rozumowania monotoniczności</title_pl>
      <title_sr>Pažnja mreža strukturirana drvetom za razloge monotoniciteta</title_sr>
      <title_so>Shabakadda geedka la dhisay ee sababo banaaninimada</title_so>
      <title_sv>Uppmärksamma trädstrukturerade nätverk för monotonitetsresonemang</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>موتونیٹی راس کے لئے اچھی طرح کے درخت ساختہ نیٹورک</title_ur>
      <title_si>මොනෝටෝනිකිටි හේතුවක් වෙනුවෙන් අවධානය වෘක්ෂ සංවිධාන ජාලය</title_si>
      <title_mn>Хэрэглэгч Мод бүтээгдэхүүний шалтгааныг сонирхолтой сүлжээ</title_mn>
      <title_mt>Netwerk Attenziv Strutturat mis-Siġar għar-Raġunar tal-Monotonità</title_mt>
      <title_uz>Name</title_uz>
      <title_vi>Mạng trang thiên văn học</title_vi>
      <title_bg>Внимателна дървесна структурирана мрежа за монотонност</title_bg>
      <title_hr>Pažnja mreža strukturirana drvetom za razloge monotoniciteta</title_hr>
      <title_da>Opmærksomme træstrukturerede netværk for monotonitets begrundelse</title_da>
      <title_nl>Aandacht Boomstructureerd Netwerk voor Monotoniciteit Redenen</title_nl>
      <title_de>Aufmerksames Tree-strukturiertes Netzwerk für Monotonizität Reasoning</title_de>
      <title_ko>단조로운 추리에 사용되는 주의 트리 구조 네트워크</title_ko>
      <title_sw>Mtandao wa Mti ulioanzishwa kwa ajili ya Kusoma Uchaguzi</title_sw>
      <title_tr>Monotonik Reaksyony üçin agaç-düzümlenmiş Aç</title_tr>
      <title_id>Rangkaian Struktur Pohon Menarik untuk Membuat Perasaan Monotonitas</title_id>
      <title_fa>شبکه ساخته شده از درخت مواظب واسه دلایل مواظب خودخواهی</title_fa>
      <title_af>Aangaande boom- structured Netwerk vir Monotonisiteit Redigering</title_af>
      <title_az>Monotonitik Reasonu üçün dikkatli Ağac-qurulmuş Ağ</title_az>
      <title_am>ምርጫዎች</title_am>
      <title_hy>Attentive Tree-structured Network for Monotonicity Reasoning</title_hy>
      <title_bs>Pažnja mreža strukturirana drvetom za razloge monotoniciteta</title_bs>
      <title_sq>Attentive Tree-structured Network for Monotonicity Reasoning</title_sq>
      <title_bn>মনোটোনিটিকি প্রাপ্তির জন্য গাছ-তৈরি নেটওয়ার্ক</title_bn>
      <title_ca>Rede atentiva per a la raonació de la monotonitat estructurada en arbres</title_ca>
      <title_et>Tähelepanev puustruktureeritud monotoonsuse mõistmise võrgustik</title_et>
      <title_cs>Pozornost stromově strukturovaná síť pro odůvodnění monotonity</title_cs>
      <title_fi>Tarkka puiden jäsennelty verkko monotonisuuden päättelyyn</title_fi>
      <title_jv>Attentive Jarob-structural Network for Monotonity Regioning</title_jv>
      <title_he>Name</title_he>
      <title_ha>Attentive Tree-structured Network for Monotonicity Reasoning</title_ha>
      <title_sk>Pozorno drevesno strukturirano omrežje za razumevanje monotoničnosti</title_sk>
      <title_bo>སྒེར་ལ་དང་ལྟ་བུའི་དབྱིབས་དབྱིབས་བཟོས་ཡོད་པའི་དྲ་བ</title_bo>
      <abstract_ar>تعمل العديد من النماذج العصبية الحديثة المصممة لاستدلال الرتابة بشكل سيئ على الاستدلال التنازلي. لمعالجة هذا القصور ، قمنا بتطوير شبكة عصبية مهيكلة على شكل شجرة. وهو يتألف من شبكة ذاكرة طويلة المدى تعتمد على الأشجار (Tree-LSTM) باهتمام ناعم. إنه مصمم لنمذجة معلومات شجرة التحليل النحوية من زوج الجملة لمهمة التفكير. يتم استخدام المُجمِّع الذاتي الانتباه لمحاذاة تمثيلات الافتراض والفرضية. نقدم نموذجنا ونقوم بتقييمه باستخدام مجموعة بيانات Entailment Monotonicity (MED). نظهر ونحاول أن نشرح أن نموذجنا يتفوق على النماذج الحالية في MED.</abstract_ar>
      <abstract_fr>De nombreux modèles neuronaux de pointe conçus pour le raisonnement de monotonie donnent de mauvais résultats sur l'inférence descendante. Pour pallier cette lacune, nous avons développé un réseau neuronal à structure arborescente attentive. Il se compose d'un réseau de mémoire à long et court terme basé sur un arbre (Tree-LSTM) avec une attention douce. Il est conçu pour modéliser les informations de l'arbre d'analyse syntaxique à partir de la paire de phrases d'une tâche de raisonnement. Un agrégateur auto-attentif est utilisé pour aligner les représentations de la prémisse et de l'hypothèse. Nous présentons notre modèle et l'évaluons à l'aide de l'ensemble de données d'implication de monotonicité (MED). Nous montrons et tentons d'expliquer que notre modèle surpasse les modèles existants sur MED.</abstract_fr>
      <abstract_es>Muchos modelos neuronales de última generación diseñados para el razonamiento de monotonicidad funcionan mal en la inferencia descendente. Para abordar esta deficiencia, desarrollamos una red neuronal atenta estructurada en árbol. Consiste en una red de memoria a corto plazo larga basada en árboles (Tree-LSTM) con una atención suave. Está diseñado para modelar la información del árbol de análisis sintáctico a partir del par de oraciones de una tarea de razonamiento. Se utiliza un agregador autoatento para alinear las representaciones de la premisa y la hipótesis. Presentamos nuestro modelo y lo evaluamos utilizando el Conjunto de Datos de Implicación de la Monotonicidad (MED). Demostramos e intentamos explicar que nuestro modelo supera a los modelos existentes en MED.</abstract_es>
      <abstract_pt>Muitos modelos neurais de última geração projetados para o raciocínio de monotonicidade têm um desempenho ruim na inferência descendente. Para resolver essa deficiência, desenvolvemos uma rede neural estruturada em árvore atenta. Consiste em uma rede de memória de longo prazo baseada em árvore (Tree-LSTM) com atenção suave. Ele é projetado para modelar as informações da árvore sintática de análise do par de frases de uma tarefa de raciocínio. Um agregador auto-atencioso é usado para alinhar as representações da premissa e da hipótese. Apresentamos nosso modelo e o avaliamos usando o Monotonicity Entailment Dataset (MED). Mostramos e tentamos explicar que nosso modelo supera os modelos existentes no MED.</abstract_pt>
      <abstract_ja>単調性推論のために設計された多くの最先端のニューラルモデルは、下向き推論では性能が悪い。この欠点に対処するために、注意深い木構造ニューラルネットワークを開発しました。それは、柔らかい注意を払って木ベースの長期記憶ネットワーク（ Tree - LSTM ）で構成されています。これは、推論タスクの文ペアから構文解析ツリー情報をモデル化するように設計されています。自己注意的集計器は、前提と仮説の表現を整列させるために使用される。モデルを提示し、単調性エンテイメントデータセット（ MED ）を使用して評価します。私たちは、MEDのモデルが既存のモデルよりも優れていることを示し、説明しようとしています。</abstract_ja>
      <abstract_zh>诸为单调性推理最先进者神经形于下推理。 为解此病,细心结神经网络。 一树长期记忆网络(Tree-LSTM)成,有软注意力。 其旨在句语法解析树信建模。 自注之聚合器,施于齐前及假设也。 展我模样,单调性蕴涵数(MED)评。 我们展示并试图解释我们的模形优于MED上的现在模样。</abstract_zh>
      <abstract_ru>Многие современные нейронные модели, разработанные для рассуждений о монотонности, плохо работают при нисходящем выводе. Для устранения этого недостатка мы разработали внимательную древовидную нейронную сеть. Он состоит из дерева на основе долгосрочной краткосрочной сети памяти (Tree-LSTM) с мягким вниманием. Он предназначен для моделирования информации синтаксического дерева синтаксического анализа из пары предложений задачи рассуждения. Для выравнивания представлений предпосылки и гипотезы используется самовнимательный агрегатор. Мы представляем нашу модель и оцениваем ее с помощью набора данных о монотонности (MED). Мы показываем и пытаемся объяснить, что наша модель превосходит существующие модели на MED.</abstract_ru>
      <abstract_hi>मोनोटोनिकता तर्क के लिए डिज़ाइन किए गए कई अत्याधुनिक तंत्रिका मॉडल नीचे की ओर अनुमान पर खराब प्रदर्शन करते हैं। इस कमी को दूर करने के लिए, हमने एक चौकस पेड़-संरचित तंत्रिका नेटवर्क विकसित किया। इसमें नरम ध्यान के साथ एक पेड़-आधारित दीर्घकालिक-अल्पकालिक-मेमोरी नेटवर्क (ट्री-एलएसटीएम) शामिल है। यह एक तर्क कार्य की वाक्य जोड़ी से वाक्यात्मक पार्स पेड़ की जानकारी को मॉडल करने के लिए डिज़ाइन किया गया है। एक आत्म-चौकस एग्रीगेटर का उपयोग आधार और परिकल्पना के प्रतिनिधित्व को संरेखित करने के लिए किया जाता है। हम अपने मॉडल को प्रस्तुत करते हैं और Monotonicity Entailment Dataset (MED) का उपयोग करके इसका मूल्यांकन करते हैं। हम दिखाते हैं और समझाने का प्रयास करते हैं कि हमारा मॉडल MED पर मौजूदा मॉडलों को मात देता है।</abstract_hi>
      <abstract_ga>Feidhmíonn go leor samhlacha néaracha úrscothacha atá deartha le haghaidh réasúnaíocht aontonachta go dona ar thátal anuas. Chun aghaidh a thabhairt ar an easnamh seo, d'fhorbraíomar gréasán néarach crann-struchtúrtha aireach. Is éard atá ann ná líonra cuimhne fadtéarmach crann-bhunaithe (Tree-LSTM) le haird bhog. Tá sé deartha chun an t-eolas crann parsála comhréire a shamhaltú ón bpéire abairte de thasc réasúnaíochta. Baintear úsáid as comhbhailitheoir féin-aireach chun léiriúcháin na mbonn agus na hipitéise a ailíniú. Cuirimid ár samhail i láthair agus déanaimid é a mheas ag baint úsáide as Tacar Sonraí Monatónachachta (MED). Léirímid agus déanaimid iarracht a mhíniú go sáraíonn ár samhail na samhlacha atá ann cheana féin ar MED.</abstract_ga>
      <abstract_ka>ბევრი წარმოდგენების ნეიროლური მოდელები, რომელიც მონოტონონიტების პარამენციებისთვის დამუშაობაში გავაკეთებენ. ამ ბოლოს მისაღებისთვის, ჩვენ განვითარებეთ ატრუქტურებული ხე სტრუქტურაციული ნეიროლური ქსელი. ეს შექმნა ძალიან სიმართლე-სიმართლე-მეხსიერების ქსელი (Tree-LSTM) რომელიც სიმართლე გურნავს. სინტაქტიკური პარასის ინფორმაციის მოდელეცია, რომელიც არსებობს რაოდენობის მხარედან. თავისუფალური ადგრეგტორი გამოყენება პრომენტის და ჰიპოტეზის გამოყენებას. ჩვენ ჩვენი მოდელს გაჩვენებთ და გავამუშაოთ მას მონოტონონიკური მონაცემების მონაცემების გამოყენებით (MED). ჩვენ ჩვენ ჩვენ ჩვენი მოდელის შესაძლებლობად დავიწყვით, რომ ჩვენი მოდელის შესაძლებლობა MED-ზე მუშაობს მოდელის შესაძლებლობა.</abstract_ka>
      <abstract_kk>Монотониялық сезім үшін құрылған көп күй- жай невралдық моделдері төмендету кезінде жаман істейді. Бұл қысқарту үшін біз ағаш құрылған невралдық желі құрылдық. Бұл ағаш негіздеген қысқа уақыт жады желінен (Tree- LSTM) болады. Бұл синтактикалық талдау ағаш мәліметін келтіру тапсырманың екіншісінен үлгілеу үшін құрылған. Өзіңіздің таңдау агрегаторы премизасының мен гипотезиясының түрлендіру үшін қолданылады. Біз өзіміздің үлгімізді келтіріп, оны монотикалық толық деректер бағдарламасын (MED) қолдану арқылы бағалаймыз. Біз моделіміздің MED үлгілерінде болатын үлгілерді таңдау және түсіндіру әрекетін көрсетедік.</abstract_kk>
      <abstract_hu>Számos korszerű neurális modell, amelyeket monotonitási érvelésre terveztek, rosszul teljesít a lefelé irányuló következtetésben. Ennek a hiányosságnak a kezelésére egy figyelmes, fa strukturált neurális hálózatot fejlesztettünk ki. Ez egy fa alapú hosszú-rövid távú memória hálózatból áll (Tree-LSTM), puha figyelemmel. Úgy tervezték, hogy modellezze a szintaktikus elemzési fa információkat egy érvelési feladat mondatpárjából. A feltételezés és a hipotézis reprezentációinak összehangolására önfigyelmes aggregátort használunk. Modellünket bemutatjuk és értékeljük a Monotonicity Entailment Dataset (MED) segítségével. Megmutatjuk és megpróbáljuk elmagyarázni, hogy modellünk felülmúlja a meglévő MED modelleket.</abstract_hu>
      <abstract_lt>Daugelis modernių nervų modelių, sukurtų monotoniškumui pagrįsti, blogai daro mažesnę išvadą. Siekdami pašalinti šį trūkumą, sukūrėme atidų medžio struktūrizuotą nervų tinklą. It consists of a tree-based long-short-term-memory network (Tree-LSTM) with soft attention.  Ji skirta modeliuoti sintaksinę analizavimo medžio informaciją iš motyvavimo užduoties sakinių poros. A self-attentive aggregator is used for aligning the representations of the premise and the hypothesis.  We present our model and evaluate it using the Monotonicity Entailment Dataset (MED).  Mes parodome ir bandome paaiškinti, kad mūsų modelis yra didesnis už esamus modelius MED srityje.</abstract_lt>
      <abstract_mk>Многу современи нервни модели дизајнирани за монотонични размислувања лошо работат на конференција надолу. За да го решиме ова недостаток, развивме внимателна структурирана нервна мрежа со дрво. Се состои од мрежа на долгорочна меморија на дрво (Tree-LSTM) со меко внимание. Тој е дизајниран за моделирање на информациите за синтактичката анализа на дрвото од парот на реченици на задача за размислување. Самовнимателен агрегатор се користи за израмнување на претставувањата на претпоставката и хипотезата. Ние го претставуваме нашиот модел и го оценуваме со помош на податоците за монотонитет на болести (MED). Ние покажуваме и се обидуваме да објасниме дека нашиот модел ги надминува постојните модели на MED.</abstract_mk>
      <abstract_el>Πολλά σύγχρονα νευρωνικά μοντέλα σχεδιασμένα για λόγους μονοτονίας αποδίδουν άσχημα σε συμπεράσματα προς τα κάτω. Για να αντιμετωπιστεί αυτό το έλλειμμα, αναπτύξαμε ένα προσεκτικό νευρικό δίκτυο δομημένο από δέντρα. Αποτελείται από ένα δίκτυο μακροχρόνιας βραχυπρόθεσμης μνήμης (Tree-LSTM) με απαλή προσοχή. Έχει σχεδιαστεί για να μοντελοποιήσει τις συντακτικές πληροφορίες δέντρου ανάλυσης από το ζεύγος προτάσεων μιας εργασίας συλλογισμού. Ένας αυτοεξυπηρετικός συγκεντρωτής χρησιμοποιείται για την ευθυγράμμιση των αναπαραστάσεων της υπόθεσης και της υπόθεσης. Παρουσιάζουμε το μοντέλο μας και το αξιολογούμε χρησιμοποιώντας το σύνολο δεδομένων μονοτονίας (MED). Δείχνουμε και προσπαθούμε να εξηγήσουμε ότι το μοντέλο μας ξεπερνά τα υπάρχοντα μοντέλα στο MED.</abstract_el>
      <abstract_ms>Banyak model saraf state-of-the-art yang direka untuk alasan monotoniti melakukan tidak baik pada kesimpulan turun. Untuk mengatasi kekurangan ini, kami mengembangkan rangkaian saraf struktur pokok yang perhatian. Ia terdiri dari rangkaian ingatan jangka-pendek-panjang berdasarkan pokok (Tree-LSTM) dengan perhatian lembut. It is designed to model the syntactic parse tree information from the sentence pair of a reasoning task.  Aggregator perhatian diri digunakan untuk menyesuaikan perwakilan premis dan hipotesis. We present our model and evaluate it using the Monotonicity Entailment Dataset (MED).  We show and attempt to explain that our model outperforms existing models on MED.</abstract_ms>
      <abstract_it>Molti modelli neurali all'avanguardia progettati per il ragionamento monotonico funzionano male sull'inferenza verso il basso. Per ovviare a questa lacuna, abbiamo sviluppato una rete neurale attenta strutturata ad albero. Si compone di una rete di memoria a lungo-breve termine basata su albero (Tree-LSTM) con attenzione morbida. È progettato per modellare le informazioni sintattiche dell'albero di analisi dalla coppia di frasi di un'attività di ragionamento. Un aggregatore auto-attento viene utilizzato per allineare le rappresentazioni della premessa e dell'ipotesi. Presentiamo il nostro modello e lo valutiamo utilizzando il Monotonicity Entailment Dataset (MED). Mostriamo e cerchiamo di spiegare che il nostro modello supera i modelli esistenti su MED.</abstract_it>
      <abstract_ml>ഒരുപാട് രാജ്യത്തിലെ ന്യൂറല്‍ മോഡലുകള്‍ക്കായി സൃഷ്ടിക്കപ്പെട്ടിരിക്കുന്നു. മോണോണിനിറ്റിയില്‍ നിന്ന ഈ കുറുക്കുവഴിയെ വിശദീകരിക്കാന്‍ ഞങ്ങള്‍ ഒരു ആശ്വാസപൂര്‍ണ്ണവൃക്ഷത്തില്‍ നിര്‍മ്മിച്ച നെയുറല്‍ നെ ഒരു മരത്തിന്‍റെ അടിസ്ഥാനത്തുള്ള നീണ്ട-നീണ്ട മെമ്മറി നെറ്റ്‌വര്‍ക്കിലുള്ള ഒരു വൃക്ഷത്തില്‍ ഉണ്ടാക്കുന്നു.  വാക്കിന്റെ രണ്ട് ജോലിയില്‍ നിന്നും സിന്റാക്റ്റിക്ക് പാര്‍സ് വിവരങ്ങള്‍ നിര്‍മ്മിക്കുന്നതാണിത്. സ്വയം ശ്രദ്ധിക്കുന്ന ഒരു ആത്മാര്‍ത്ഥിക്കുന്നവന്‍ ഉപയോഗിക്കുന്നു പ്രസ്താവിന്റെയും ഹൈപ്പിയറ്റിസിന്റെ ഞങ്ങള്‍ നമ്മുടെ മോഡല്‍ കൊണ്ടുവന്നു അതിനെ മോണോട്ടോണിക്റ്റി ഇന്‍റെയില്‍മെന്‍റ് ഡാറ്റാസറ്റ് ഉപയോഗിച്ച ഞങ്ങള്‍ കാണിക്കുകയും വിശദീകരിക്കാന്‍ ശ്രമിക്കുകയും ചെയ്യുന്നു, നമ്മുടെ മോഡല്‍ മെഡില്‍ നിലവിലുള്ള മോ</abstract_ml>
      <abstract_mt>Ħafna mudelli newrali moderni ddisinjati għar-raġunament tal-monotoniċità jwettqu prestazzjoni ħażina fuq inferenza 'l isfel. Biex nindirizzaw dan in-nuqqas, żviluppajna netwerk newrali attent strutturat mis-siġar. Din tikkonsisti f’netwerk ta’ memorja fuq medda twila ta’ żmien qasira bbażat fuq is-siġar (Tree-LSTM) b’attenzjoni dgħajfa. Hija ddisinjata biex timmudella l-informazzjoni sinrattika tas-siġra tal-analizzazzjoni mill-par tas-sentenza ta’ kompitu ta’ raġunament. Aggregatur li jagħti attenzjoni lilu nnifsu jintuża biex jiġu allinjati r-rappreżentazzjonijiet tal-premessa u l-ipoteżi. Aħna nippreżentaw il-mudell tagħna u nilvalutawh permezz tad-Dataset dwar il-Mard Monotoniku (MED). Aħna nuru u nippruvaw nispjegaw li l-mudell tagħna huwa akbar mill-mudelli eżistenti dwar il-MED.</abstract_mt>
      <abstract_no>Mange neuralmodeller i kunsttilstanden utvikla for monotoniske rasjonar gjer slik dårlig ved nedtrekksmessighet. For å handtera denne kortvaringa, utvikla vi ein attentiv trestrukturert neuralnettverk. Det inneheld ein tråbasert langsiktig minnetverk (Tree-LSTM) med mykt oppmerksomhet. Det er designert for å modellere syntaksiske tolkingsinformasjonen frå setningsprogrammet av eit redefinert oppgåve. Eit selvmerksomsiktig aggregator vert brukt for å justera representasjonane av premisen og hypotesien. Vi presenterer modellen vårt og evaluerer det med databasen for monotoniske kompleksjon (MED). Vi viser og prøver å forklare at modellen vårt utfører eksisterande modeller på MED.</abstract_no>
      <abstract_mn>Ихэнх урлагийн сэтгэл хөдлөлийн загварууд нь монотон загварын шалтгааныг багасгаж буй халдвартай байдаг. Энэ тохиолдолд бид анхаарлын модны бүтээгдэхүүнтэй мэдрэлийн сүлжээг бүтээсэн. Энэ мод дээр богино хугацааны санамжийн сүлжээнд (Tree-LSTM) бага анхаарал хангалттай байдаг. Энэ нь шинжлэх ухааны хоёр даалгаварын шинжлэх ухааны мэдээллийг загварчлахын тулд зохион байгуулагдсан. Өөрийгөө анхаарлын агрегатор нь анхны төлөвлөгөө болон таамаглалын төлөвлөгөөг зэрэгцүүлэхэд хэрэглэгддэг. Бид загварыг тайлбарлаж, үүнийг монотоницийн бүтээлтийн өгөгдлийн сан (MED) ашиглан үнэлэх болно. Бид загварын загвар MED дээр оршиж байгаа загваруудыг тайлбарлах гэж хичээдэг.</abstract_mn>
      <abstract_sr>Mnogi neuralni modeli iz stanja umjetnosti dizajnirani za monotoničnu razumnost loše izvode na infekciji dole. Da bi se riješili ovog nedostatka, razvili smo pažljivo strukturiranu nervnu mrežu. To se sastoji od dugoročne sjećanske mreže na drvetu sa mekom pažnjom. To je dizajnirano da modeluje informacije o sintaktičkom analizu drveta iz parova rečenice razumnog zadatka. Samoopazljiv aggregator se koristi za usklađivanje predstavljanja premise i hipoteze. Predstavljamo naš model i procjenjujemo ga koristeći datoteku za kompletnost monotonnosti (MED). Pokazujemo i pokušavamo objasniti da naš model iznosi postojeće modele na MED-u.</abstract_sr>
      <abstract_ro>Multe modele neurale de ultimă generație concepute pentru raționamentul monotonic funcționează slab la inferența descendentă. Pentru a aborda această deficiență, am dezvoltat o rețea neuronală atentă structurată în copaci. Acesta constă dintr-o rețea de memorie pe termen lung-scurt bazată pe arbori (Tree-LSTM) cu atenție ușoară. Este conceput pentru a modela informațiile sintactice ale arborelui de parsare din perechea de propoziții a unei sarcini de raționament. Un agregator auto-atent este folosit pentru alinierea reprezentărilor premisei și ipotezei. Prezentăm modelul nostru și îl evaluăm folosind Monotonicity Entailment Dataset (MED). Aratăm și încercăm să explicăm că modelul nostru depășește modelele existente pe MED.</abstract_ro>
      <abstract_sv>Många state-of-art neurala modeller utformade för monotonitetsresonemang presterar dåligt på nedåtgående inferens. För att åtgärda denna brist utvecklade vi ett uppmärksamt trädstrukturerat neuralt nätverk. Den består av ett trädbaserat nätverk för långtidsminne (Tree-LSTM) med mjuk uppmärksamhet. Den är utformad för att modellera den syntaktiska tolkningsträdinformationen från meningsparet i en resonemang uppgift. En självuppmärksam aggregator används för att anpassa representationerna av premissen och hypotesen. Vi presenterar vår modell och utvärderar den med hjälp av Monotonicity Entailment Dataset (MED). Vi visar och försöker förklara att vår modell överträffar befintliga modeller på MED.</abstract_sv>
      <abstract_ta>நிறைய மாநிலை புதிய மாதிரிகள் வடிவமைக்கப்பட்டுள்ளது பாதுகாப்பு காரணத்திற்காக வடிவமைக்கப்பட்டுள்ளது கீழே ந இந்த குறுக்குவழியை முகவரிப்பதற்கு, நாங்கள் ஒரு கவனமான மரத்தை அமைத்த புதிய பிணையத்தை உருவாக்கினோம். It consists of a tree-based long-short-term-memory network (Tree-LSTM) with soft attention.  It is designed to model the syntactic parse tree information from the sentence pair of a reasoning task.  முன்னோக்கு மற்றும் hypothesis குறிப்புகளை ஒழுங்குபடுத்த பயன்படுத்தப்படுகிறது. நாம் எங்கள் மாதிரியை காண்பிக்கிறோம் மற்றும் அதை தானோட்டோனிசி தகவல் அமைப்பை பயன்படுத்தி மதிப்பிடுகிற நாங்கள் முயற்சி காட்டுகிறோம் மற்றும் விளக்க முயற்சிக்கிறோம் எங்கள் மாதிரி நடப்பு மாதிரிகளை மேம</abstract_ta>
      <abstract_so>Tusaale badan oo asalka neurada ah oo loo qoray qofka dhallinyarada ah sababtoo ah waxay si xun u sameeyaan cudurada hoose. Si aan ugu sheekeyno soo gaaban, waxaan horumarinnay shabakad aad u adag geed-dhisan neurada. Waxaa ka mid ah shabakadda geed-ku saleysan oo waqti dheer oo xasuusta (Tree-LSTM) iyadoo aad u dhaqdhaqaaqsan tahay. It is designed to model the syntactic parse tree information from the sentence pair of a reasoning task.  Qofka iskaasha isku qiimeeya waxaa loo isticmaalaa in la isbedelo aragtida hore iyo fikrada. Tusaalkayaga waxan ku qiimeynaynaa isticmaalka macluumaadka macluumaadka ka soo saarashada Monotonicity (MED). Waxaynu tusnaynaa oo isku dayaynaa in qaababkayagu uu ka muujiyo modelalka joogta ee MED.</abstract_so>
      <abstract_ur>بہت سی موقعیت کی نئورل موڈل جو ایک ٹیٹونیٹی منظورت کے لئے طراحی کی گئی ہے نیچے نیچے نئورل موڈل کے ذریعہ برابر عمل کرتے ہیں. ہم نے اس کوتاہی کے لئے ایک اچھی درخت کی ساختار نیورال نیٹ ورک کی تولید کی۔ یہ ایک درخت کی بنیاد میں لہروں کی توجه کے ساتھ ہے۔ یہ ایک منطقی کام کے جوڑے سے سینٹکتیک پیرس درخت کی معلومات کی مدل کرنے کے لئے طراحی کی گئی ہے. ایک اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا ہم اپنے مدل کو پیش کرتے ہیں اور اسے موتونیٹی Entailment Dataset (MED) کے مطابق ارزش کرتے ہیں۔ ہم دکھاتے ہیں اور سعی کرتے ہیں کہ ہماری مدل MED پر موجود موجود موجود موجود موجود موجود موجود ہیں۔</abstract_ur>
      <abstract_si>ගොඩක් ස්ථානයේ ක්‍රියාත්මක න්‍යූරාල් මොඩේල් සැලසුම් කරලා මොනෝටෝනිසිටි හේතුව සඳහා සැලසුම් ක අපි මේ අවස්ථාවක් විදිහට අවස්ථාවක් කරලා තියෙනවා. ඒක සම්පූර්ණ අවධානයක් තියෙන්නේ ගස් අධාරිත ලොකු කාලකාල මතක ජාලය (Tree-LSTM) වලින්. ඒක සැකසුම් කරලා තියෙන්නේ වාක්ෂික විශ්ලේෂණ කකුළු තොරතුරු මොඩල් කරන්න. ස්වයංග්‍රහයක් අවධානය සම්බන්ධයක් ප්‍රමාණය සහ හිතාව සම්බන්ධ කරන්න පාවිච්චි කරනවා. අපි අපේ මොඩේල් එක පෙනුම් කරනවා ඒක විශ්වාස කරනවා මොනෝටෝනිකිටි අන්තිම දත්ත (MED) එක්ක. අපි පෙන්වන්න හා උත්සාහ කරනවා අපේ මොඩල් එක MED එකේ ඉතින් මොඩල් එකක් නිර්මාණය කරනවා කියලා.</abstract_si>
      <abstract_pl>Wiele najnowocześniejszych modeli neuronowych zaprojektowanych do rozumowania monotonicznego słabo działa w przypadku wniosków spadkowych. Aby rozwiązać tę niedociągnięcie, opracowaliśmy uważną sieć neuronową o strukturze drzewa. Składa się z drzewnej sieci pamięci długoterminowej (Tree-LSTM) z miękką uwagą. Jest on zaprojektowany do modelowania składniowego drzewa parsowania informacji z pary zdań zadania rozumowania. Do dostosowania reprezentacji założenia i hipotezy używany jest samoobsługowy agregator. Prezentujemy nasz model i oceniamy go za pomocą zestawu danych dotyczących monotonicity Entailment Dataset (MED). Pokazujemy i staramy się wyjaśnić, że nasz model przewyższa istniejące modele na MED.</abstract_pl>
      <abstract_uz>Oddiy sabablar uchun qo'shimcha neyron modellari ko'pchilik davlat qo'l modellari eng yuqori kasalliklarni bajaradi. Ushbu kutilgan narsa uchun biz juda muhim daraxt tuzilgan neyrol tarmoqni yaratdik. Name Name Ikkinchi shaxsiy kattalashtiruvchi prefik va hypothesis tashkilotlarini aniqlash uchun ishlatiladi. Biz modelimizni hozir qilamiz va uni Monotonikity Elementlar maʼlumoti (MED) bilan qiymatmiz. Biz modelmiz MED'da mavjud modellarni bajaradi.</abstract_uz>
      <abstract_vi>Nhiều mô hình thần kinh tiên tiến được thiết kế cho việc căn cứ đơn điệu không tốt khi đi xuống. Để giải quyết thiếu sót này, chúng tôi đã phát triển một mạng lưới thần kinh chu đáo. Nó gồm một mạng nhớ dài hạn (Tree-LSTM) với mềm tập trung. Nó được thiết kế để mô tả thông tin về cây theo cấu tạo từ một công việc lập trình. Một tổng hợp chu đáo được dùng để chỉnh lại các biểu tượng của tiền đề và giả thuyết. Chúng tôi giới thiệu mô hình của chúng tôi và đánh giá nó bằng đơn vị dữ liệu cấu trúc. Chúng tôi thể hiện và cố giải thích rằng mẫu của chúng tôi hoàn thiện các mô hình có trên tên Md.</abstract_vi>
      <abstract_bg>Много от най-съвременните невронни модели, предназначени за монотонно разсъждение, се представят зле при низходящо заключение. За да се справим с този недостатък, разработихме внимателна дървесна нервна мрежа. Състои се от дърво базирана дългосрочна краткосрочна памет мрежа (Tree-LSTM) с меко внимание. Тя е предназначена да моделира синтактичната информация за дървото от двойката изречения на задача за разсъждение. За привеждане в съответствие на представите на предпоставката и хипотезата се използва самовнимателен агрегатор. Представяме нашия модел и го оценяваме с помощта на набор от данни за монотонност (МЕД). Показваме и се опитваме да обясним, че нашият модел надминава съществуващите модели на МЕД.</abstract_bg>
      <abstract_nl>Veel state-of-art neurale modellen ontworpen voor monotoniciteit redeneren presteren slecht op neerwaartse inferentie. Om deze tekortkoming aan te pakken, ontwikkelden we een attent boomgestructureerd neuraal netwerk. Het bestaat uit een boomgebaseerd long-short-term-memory netwerk (Tree-LSTM) met zachte aandacht. Het is ontworpen om de syntactische parse boominformatie te modelleren van het zinspaar van een redeneringstaak. Een zelfattente aggregator wordt gebruikt om de representaties van het uitgangspunt en de hypothese op één lijn te brengen. We presenteren ons model en evalueren het met behulp van de Monotonicity Entailment Dataset (MED). We laten zien en proberen uit te leggen dat ons model beter presteert dan bestaande modellen op MED.</abstract_nl>
      <abstract_hr>Mnogi state-of-art neuralni modeli dizajnirani za monotoničnu razumnost loše izvode na infekciji dolje. Da bi se riješili ovog nedostatka, razvili smo pažljivu strukturiranu nervnu mrežu. To se sastoji od dugoročne sjećanske mreže na drvetu (Tree-LSTM) s mekom pažnjom. To je dizajnirano da modelira informacije o sintaktičkom analizu drveta iz parova rečenice razumnog zadatka. Samoopazljiv aggregator se koristi za usklađivanje predstavljanja premise i hipoteze. Predstavljamo naš model i procjenjujemo ga koristeći datoteku za kompletnost monotonnosti (MED). Pokazujemo i pokušavamo objasniti da naš model iznosi postojeće modele na MED-u.</abstract_hr>
      <abstract_da>Mange state-of-art neurale modeller designet til monotonicity ræsonnement fungerer dårligt på nedadgående inference. For at imødegå denne mangel udviklede vi et opmærksomt træstruktureret neuralt netværk. Den består af et træbaseret langtidshukommelsesnetværk (Tree-LSTM) med blød opmærksomhed. Det er designet til at modellere den syntaktiske parse træ information fra sætningsparet af en ræsonnement opgave. En selvopmærksom aggregator bruges til at justere repræsentationerne af præmisen og hypotesen. Vi præsenterer vores model og evaluerer den ved hjælp af Monotonicity Entailment Dataset (MED). Vi viser og forsøger at forklare, at vores model overgår eksisterende modeller på MED.</abstract_da>
      <abstract_de>Viele hochmoderne neuronale Modelle, die für Monotonizitätsargumente entwickelt wurden, funktionieren bei Abwärtsinferenzen schlecht. Um diesen Mangel zu beheben, haben wir ein aufmerksames, baumstrukturiertes neuronales Netzwerk entwickelt. Es besteht aus einem Baum-basierten Long-Short-Term-Memory Netzwerk (Tree-LSTM) mit weicher Aufmerksamkeit. Es wurde entwickelt, um die syntaktischen Parse-Bauminformationen aus dem Satzpaar einer Argumentationsaufgabe zu modellieren. Ein selbstaufmerksamer Aggregator wird verwendet, um die Repräsentationen der Prämisse und der Hypothese auszurichten. Wir stellen unser Modell vor und bewerten es anhand des Monotonicity Entailment Datasets (MED). Wir zeigen und versuchen zu erklären, dass unser Modell bestehende Modelle auf MED übertrifft.</abstract_de>
      <abstract_ko>단조로운 추리를 위해 설계된 많은 선진 신경 모형들이 아래로 추리하는 데 좋지 않다.이 단점을 해결하기 위해 우리는 세심한 나무 구조 신경 네트워크를 개발했다.그것은 트리 기반의 긴 단기 기억 네트워크 (tree-LSTM) 와 부드러운 주의로 구성되어 있다.그것의 목적은 추리 임무의 문장에서 모형 문법으로 트리 정보를 분석하는 것이다.자기 관심 집합기는 전제와 가설을 맞추는 데 쓰인다.우리는 우리의 모델을 제시하고 단조로운 함축 데이터 집합(MED)을 사용하여 이를 평가했다.MED에서 기존 모델보다 우수한 모델을 보여 주고 설명하려고 합니다.</abstract_ko>
      <abstract_id>Banyak model saraf terbaik yang direncanakan untuk alasan monotonisitas bekerja buruk pada kesimpulan turun. Untuk mengatasi kekurangan ini, kami mengembangkan jaringan saraf struktur pohon yang perhatian. Ini terdiri dari jaringan memori panjang jangka pendek berdasarkan pohon (Tree-LSTM) dengan perhatian lembut. Ini direncanakan untuk model informasi sintaksi pemeriksaan pohon dari pasangan kalimat tugas alasan. Sebuah agregator yang memperhatikan diri digunakan untuk menyesuaikan perwakilan dari premis dan hipotesis. Kami memperkenalkan model kami dan mengevaluasinya menggunakan Monotonicity Entailment Dataset (MED). Kami menunjukkan dan mencoba untuk menjelaskan bahwa model kami melebihi model yang ada di MED.</abstract_id>
      <abstract_af>Baie state-of-art neural models ontwerp vir monotonisiteit redening verkeerd uitvoer op onderkant inferensie. Om hierdie kortpad te adres, ontwikkel ons 'n aandaglike boom-struktureerde neuralnetwerk. Dit bestaan van 'n boom- gebaseerde lang- term- geheue netwerk (Boom- LSTM) met sagte aandag. Dit is ontwerp om die sintaktieke verwerking boom inligting te model van die sentence pair van 'n redekende taak. 'n Sel-aandagbare aggregator word gebruik vir die voorstellings van die premise en die hipotees te aligneer. Ons voorsien ons model en evalueer dit met die gebruik van die Monotonisiteit Entailment Dataset (MED). Ons wys en probeer om te verduidelik dat ons model uitvoer bestaande modele op MED.</abstract_af>
      <abstract_sw>Mifano mingi ya taratibu za kisasa zilizotengenezwa kwa sababu za upumbavu wanafanya vibaya kutokana na maambukizi ya chini. Ili kuzungumzia muda huu, tulitengeneza mtandao wa neura uliotengenezwa na mti. Inajumuisha Mtandao wa Kumbukumbu kwa muda mrefu wa muda mrefu wa mti (mti-LSTM) yenye mwangalizi mzuri. Ni lengo la kutengeneza taarifa za mti wa pamoja kutoka kwenye hukumu hiyo wawili wa kazi yenye maana. Mtengenezaji wa kujitegemea anatumiwa kwa kutangaza maoni ya mtazamo na nadharia. Tunatoa mfano wetu na kutathmini kwa kutumia seti ya Ujumbe wa Uchaguzi (MED). Tunaonyesha na jaribio la kuelezea kwamba mifano yetu inaonyesha mifano iliyopo kwenye MED.</abstract_sw>
      <abstract_fa>بسیاری از مدل‌های عصبی‌های ایالت‌هنری که برای دلیل‌های منطقه‌ای واحدی طراحی شده‌اند، به بدی در آلودگی پایین انجام می‌دهند. برای حل این کوتاهی، ما یک شبکه عصبی با درخت ساخته شده توجه کردیم. از شبکه‌ی حافظه‌ی طولانی‌زمانی (Tree-LSTM) بر روی درخت با توجه نرم است. این طراحی شده است تا اطلاعات جدا کردن درخت را از جفت جمله یک کار منطقی مدل کند. یک گروهبان خودمواظب برای تعیین نمایش‌های پیشنهاد و فرضیه استفاده می‌شود. ما مدل خود را نشان می دهیم و آن را با استفاده از Databases Entailment Monotonicity (MED) ارزش می دهیم. ما نشان می دهیم و سعی می کنیم توضیح دهیم که مدل ما از مدل موجود موجود در MED بیشتر انجام می دهد.</abstract_fa>
      <abstract_tr>Monotonetik seb채bi tasarlan첵an k철p m철h체m nural modelleri a힊a휓캇 d체힊체rmek 체챌in 첵ok edip 첵철re첵채r. Bu gysga 챌ykmak 체챌in aga챌 첵aly strukturly첵an neural 힊ebekesini geli힊tirdik. A휓a 챌-dan da힊ary gi챌-wagt 첵agtylyk netijesinden (aga챌-LSTM) 첵umu힊 체ns beril첵채r. Bu sentaktik analyz aga챌 maglumatyny seb채pli bir zady흫 챌ift bolmagyndan nusgala etmek 체챌in tasarlan첵ar. Kendi dikkatli bir toplant캇c캇, asal ve tahmin ifadelerini 챌izeltmek i챌in kullan캇l캇r. Biz modelimizi g철rkezip we muny Monotonicity Entailment Dataset (MED) bilen 챌yk첵arys. Bizi흫 nusgymyzy흫 me흫 bar nusgalarymyzy흫 MED'de 첵ok nusgalaryny흫 bardygyny we d체힊체ndirm채ge synany힊첵arys.</abstract_tr>
      <abstract_am>ብዙዎች የሀገር አካባቢ አካባቢ አካባቢ አካባቢ የነጥብ ዓይነቶች ከታችኞቹ ጉዳይ የጎደለኛ ነው፡፡ ይህንን አነስተኛ ግንኙነት ለመግለጽ፣ የዛፍ የተመሠረተውን የናቡር መረብ አካባቢ አደረግን፡፡ በዛፍ ላይ የረጅም ዘመን-ቆራጭ የማስታወሻ መረብ (ዛፍ-LSTM) ጥብቅ ተጠቃሚ ነው፡፡ ከክፍሉ ሁለት ዓይነቶች ከታዋቂው ስራ የሚደረገውን የSyntactic ፓርስ መረጃዎችን መግለጫ ነው፡፡ የራሱ አዳማሚ የፊደል እና የንፍቅናውን መልዕክት በማሳመር ተጠቃሚ ነው፡፡ ሞዴልናችንን እናሳየዋለን እና በሞቶኒካዊነት የኢንተርኔት ዳታ (MED) የተጠቃሚ ነው፡፡ We show and attempt to explain that our model outperforms existing models on MED.</abstract_am>
      <abstract_sq>Shumë modele neurale moderne të dizajnuara për arsyetimin e monotonitetit funksionojnë keq në inferencën poshtë. Për të trajtuar këtë mungesë, kemi zhvilluar një rrjet nervor të vëmendshëm të strukturuar nga pemët. Përbëhet nga një rrjet kujtese afat-shkurtër me bazë në pemë (Tree-LSTM) me vëmendje të butë. Është dizajnuar për të modeluar informacionin sintaktik të pemës së analizimit nga çifti i fjalëve të një detyre arsyetimi. Një agregator vetëvëmendje përdoret për të renditur përfaqësimet e premtesës dhe hipotezës. Ne paraqesim modelin tonë dhe e vlerësojmë duke përdorur bazën e të dhënave për sëmundjet monotonike (MED). Ne tregojmë dhe përpiqemi të shpjegojmë se modeli ynë ekziston më shumë se modelet ekzistuese në MED.</abstract_sq>
      <abstract_hy>Շատ նորաձևակայական նյարդային մոդելներ, որոնք նախագծված են մոնոտոնիկ մտածելու համար, վատ են աշխատում ներքև եզրակացության վրա: Այս թերությունը լուծելու համար մենք զարգացրեցինք ուշադիր ծառի կառուցվածքով նյարդային ցանց: Այն կազմված է ծառի վրա հիմնված երկար-կարճ-տերմինային հիշողության ցանցից (ծառ-LSMT), որն ունի թեթև ուշադրություն: Այն նախագծված է, որպեսզի մոդելավորի սինտակտիկ վերլուծման ծառի տեղեկատվությունը մտածողական խնդիրների երկու նախադասություններից: Ինքնաուշադրություն դարձնող ագրեգատորը օգտագործվում է ենթադրության և հիպոթեզի նկարագրությունները հավասարեցնելու համար: Մենք ներկայացնում ենք մեր մոդելը և գնահատում ենք այն օգտագործելով Մոնոտոնիզմի հիվանդության տվյալների համակարգը (ՄԵԴ). Մենք ցույց ենք տալիս և փորձում ենք բացատրել, որ մեր մոդելը գերազանցում է գոյություն ունեցող մոդելները ՄԻԱՎ-ում:</abstract_hy>
      <abstract_az>Bir çox sanat nöral modelləri, monotonik razılığı üçün hazırlanmışdır. Aşağı aşağı infeksiyonda pis davranır. Bu xəstəliyi çəkmək üçün, dikkatli ağac-strukturlı nöral ağ təhsil etdik. Bu a ğac tabanlı uzun-müddətli hafıza ağından (ağac-LSTM) yumuşaq bir məlumatdır. Bu sintaktik ayırma a ğacının məlumatını dəyişdirmək üçün müəyyən edilmişdir. Öz-özünə dikkat edən bir aggregator əvvəlkilərin və hipotezin tərzlərini düzəltmək üçün istifadə edilir. Biz modelimizi göstərir və onu Monotonicity Entailment Dataset (MED) vasitəsilə değerləşdiririk. Biz modellərimizin MED-də mövcuddur modellərin istifadə etməsini göstərir və təfsilat etmək üçün çalışırıq.</abstract_az>
      <abstract_bn>অনেক রাষ্ট্র-শিল্পের নিউরেল মডেল নির্মাণ করা হয়েছে যেখানে দুর্ভোগের জন্য নির্মাণ করা হয়েছে। এই সংক্ষিপ্ত বিষয়টি ঠিকানা করার জন্য, আমরা একটি প্রত্যাশিত গাছ-স্থাপনিত নিউরেল নেটওয়ার্ক উন্নয়ন করেছি। এটি একটি গাছের ভিত্তিক দীর্ঘমেয়াদ-মেমরি নেটওয়ার্ক (গাছ-এলস্টিএম) যেখানে সঠিক মনোযোগ রয়েছে। এটি একটি যুক্তিশীল কাজ থেকে সিন্ট্যাক্টিক পার্স গাছের তথ্য মডেল করার জন্য ডিজাইন করা হয়েছে। একজন আত্মসমর্থিত বিষয়ক ব্যবহার করা হয়েছে এই বিষয়টির প্রতিনিধির প্রতিনিধিত্ব এবং হিসেবে তুলে ধরার জন্য। আমরা আমাদের মডেল উপস্থাপন করি এবং এটাকে মূল্যায়ন করি মনোটোনিকিটি এন্টেলেমেন্ট ডাটাসেট (এমডি)। আমরা ব্যাখ্যা করার চেষ্টা করছি এবং ব্যাখ্যা করার চেষ্টা করছি যে আমাদের মডেল এমডিতে বিদ্যমান মডেল পালন করছে।</abstract_bn>
      <abstract_cs>Mnoho nejmodernějších neuronových modelů navržených pro monotonické uvažování funguje špatně při inferenci směrem dolů. Abychom tento nedostatek vyřešili, vyvinuli jsme pozornou stromově strukturovanou neuronovou síť. Skládá se ze stromové sítě dlouhodobé paměti (Tree-LSTM) s měkkou pozorností. Je navržen tak, aby modeloval syntaktické informace o stromu parse z páru vět úlohy uvažování. Sebevědomý agregátor se používá pro sladění reprezentací předpokladu a hypotézy. Představujeme náš model a vyhodnocujeme jej pomocí Monotonicity Entailment Dataset (MED). Ukazujeme a snažíme se vysvětlit, že náš model překonává existující modely na MED.</abstract_cs>
      <abstract_bs>Mnogi state-of-art neuralni modeli dizajnirani za monotoničnu razumnost loše izvode na infekciji dolje. Da bi se riješili ovog nedostatka, razvili smo pažljivu strukturiranu nervnu mrežu. To se sastoji od dugoročne sjećanske mreže na drvetu s mekom pažnjom. To je dizajnirano da modeluje informacije o sintaktičkom analizu drveta iz parova rečenice razumnog zadatka. Samoopazljiv aggregator se koristi za usklađivanje predstava premise i hipoteze. Predstavljamo naš model i procjenjujemo ga koristeći datoteku za kompletnost monotonnosti (MED). Pokazujemo i pokušavamo objasniti da naš model iznosi postojeće modele na MED-u.</abstract_bs>
      <abstract_fi>Monet monotonisuuspäättelyyn suunnitellut neuromallit toimivat huonosti alaspäin suuntautuvassa päättelyssä. Tämän puutteen korjaamiseksi kehitimme tarkkaavaisen puurakenteisen neuroverkon. Se koostuu puupohjaisesta pitkän aikavälin muistiverkosta (Tree-LSTM), jossa on pehmeää huomiota. Se on suunniteltu mallintamaan päättelytehtävän lauseparin syntaktista jäsennyspuuinformaatiota. Itsetarkkaavaista aggregaattoria käytetään lähtökohtan ja hypoteesin esitysten yhdenmukaistamiseen. Esittelemme mallimme ja arvioimme sitä Monotonicity Entailment Datasetin (MED) avulla. Osoitamme ja yritämme selittää, että mallimme suoriutuu MED:n nykyisistä malleista.</abstract_fi>
      <abstract_ca>Molts models neurals d'última edat dissenyats per a raonar la monotonicitat es produeixen malament en inferència cap a baix. Per abordar aquest problema, vam desenvolupar una atenta xarxa neural estructurada amb arbres. Composa d'una xarxa de memòria a llarg i curt termini basada en arbres (Tree-LSTM) amb atenció suau. Està dissenyat per modelar la informació sinàctica sobre l'arbre d'analització a partir del parell de frases d'una tasca de raonament. A self-attentive aggregator is used for aligning the representations of the premise and the hypothesis.  We present our model and evaluate it using the Monotonicity Entailment Dataset (MED).  Mostrem i intentem explicar que el nostre model supera els models existents en MED.</abstract_ca>
      <abstract_et>Paljud moodsad neuromudelid, mis on mõeldud monotoonsuse mõtlemiseks, toimivad halvasti allapoole järeldustel. Selle puuduse lahendamiseks töötasime välja tähelepaneliku puustruktureeritud närvivõrgu. See koosneb puupõhisest pikaajalisest mäluvõrgust (Tree-LSTM) pehme tähelepanuga. See on mõeldud mõtlemisülesande lausepaari süntaktilise parsimise puu info modelleerimiseks. Enesetähelepanelikku agregaatorit kasutatakse eelduse ja hüpoteesi esituste ühtlustamiseks. Esitleme oma mudelit ja hindame seda Monotonicity Entailment Dataset (MED) abil. Näitame ja püüame selgitada, et meie mudel ületab MED-i olemasolevaid mudeleid.</abstract_et>
      <abstract_sk>Veliko najsodobnejših nevronskih modelov, zasnovanih za monotonično razmišljanje, slabo deluje pri sklepanju navzdol. Da bi odpravili to pomanjkljivost, smo razvili pozorno drevesno strukturirano nevronsko omrežje. Sestavljen je iz drevesnega dolgoročnega pomnilniškega omrežja (Tree-LSTM) z mehko pozornostjo. Zasnovan je za modeliranje sintaktičnega razčlenitve drevesa informacij iz stavkovnega para opravila razmišljanja. Za uskladitev predstavitev premisa in hipoteze se uporablja samopozoren agregator. Naš model predstavljamo in ga ocenimo z uporabo nabora podatkov o monotoničnosti (MED). Pokažemo in poskušamo pojasniti, da naš model presega obstoječe modele na MED.</abstract_sk>
      <abstract_jv>Ana multi-etong-karcis model sing dibenalke kanggo sampek Monotoniyen Nyong ngomong mbut iki, awake dhewe nyulung sistem sing sampek maning. Jaring sembaran nganggo punika, ditambah-perkorontah uwong-uwong (Jaring-SLT M) nganggo ngatah sawar. Layout Yuta nesaturan atit-awat arka mbutuhake nggawe Ngubah gambar aturan tapi iki ngono nggawe Awak dhéwé éntuk model nyebuté karo nggawe kuwi nggawe Monotonity Entayment dataacet (MED). Awak dhéwé éntuk lan saiki ngejaraké awak dhéwé model sing bisa model sing ngomong nik MED</abstract_jv>
      <abstract_bo>སྣང་ཚུལ་གྱི་གནས་སྟངས་ལ་མང་པོ་ཞིག་ཡིན་པས་རྐྱེན་ཚད་ལྡན་པ་གསལ་བསམ་བློ་གཏོང་ན་སྐྱུར་བརྗོད་དང་། འོན་ཀྱང་། སྔོན་མ་འོང་བའི་ཐབས་ལམ་འདི་ལ་ང་ཚོས་རང་ཉིད་ཀྱི་རྩ་འབྲེལ་བ་ཞིག་གསར་བསྐྲུན་བྱས། It consists of a tree based long-term-memory network (Tree-LSTM) with soft attention. འདི་ལ་སྒྲུབ་ཀྱི་ཚིག་རྩལ་བ་ཁང་གི་དབྱེ་སྟངས་ལ་བཅས་ཀྱི་ཆ་ཚིག་དང་མཐུན་སྒྲིག་འགོད་བྱས་པ་རེད། རང་ཉིད་རྟོན་པའི་བསྡུར་མཁན་གྱི་གཙོ་རིམ་དང་གྲངས་སུ་ཚུར་མཚུངས་པའི་རྣམ་པ་སྒྲིག་ཐབས་བེད། ང་ཚོའི་མ་དབྱིབས་གཟུགས་རིས་འདི་ལ་རང་ཉིད་ཀྱི་རྣམ་པ་དང་ཚད་ལྟར་བྱེད་ཀྱི་ཡོད་པ་སྤྱོད་ཀྱི་ཡོད། ང་ཚོས་མིག་གཟུགས་རིས་MED ནང་གི་མིག་དཔེ་དབྱེ་བ་དེ་ལས་འགྲེལ་བཤད་བྱེད་དགོས་བྱས་པ་ཡིན།</abstract_bo>
      <abstract_ha>Wasu'a na-halin neural da aka designed for monotonicity argument to do poorly on shida ƙasan. To, don mu shiryu wannan shortcut, mun buɗe wani zane na'urar-na'urar da aka samar da shi na jarraba. Yana ƙunsa da wani zanen aikin memory mai zaman kure na itãce (Tree-LSM) mai sauƙin haɗi. An designe shi dõmin ka motsa information na parse itãcen syntactic daga aikin aiki biyu na halarce. An yi amfani da jigon kansa dõmin ya sami misãlai na gabatar da kai. Tuna gabatar da misalinmu kuma munã iya ƙayyade shi da ake amfani da data na Entertainci na Monotonicity (MED). Tuna nũna kuma Muke jarraba ka bayyana misalinmu yana samar da misalin da ke cikin MED.</abstract_ha>
      <abstract_he>המודלים העצביים המוקדמים רבים שנועדו להסבירת מונוטוניות מבצעים רע במסקנה למטה. כדי להתמודד עם הקצר הזה, פיתחנו רשת עצים מובנת תשומת לב. It consists of a tree-based long-short-term-memory network (Tree-LSTM) with soft attention.  הוא מעוצב כדי לדוגמא את מידע העץ המחקר הסינטקטי מזוג המשפטים של משימה הגיונית. אגרגרגרטור בעצמו משתמש בהתאם ביצועים של הנושא וההיפותזיה. אנחנו מציגים את המודל שלנו ולעריך אותו באמצעות קבוצת נתונים של מחלות מונוטוניות (MED). We show and attempt to explain that our model outperforms existing models on MED.</abstract_he>
      </paper>
    <paper id="4">
      <title>Transferring Representations of Logical Connectives</title>
      <author><first>Aaron</first><last>Traylor</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <author><first>Roman</first><last>Feiman</last></author>
      <pages>22–25</pages>
      <abstract>In modern natural language processing pipelines, it is common practice to pretrain a generative language model on a large corpus of text, and then to finetune the created representations by continuing to train them on a discriminative textual inference task. However, it is not immediately clear whether the <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">logical meaning</a> necessary to model <a href="https://en.wikipedia.org/wiki/Logical_consequence">logical entailment</a> is captured by <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> in this <a href="https://en.wikipedia.org/wiki/Paradigm">paradigm</a>. We examine this pretrain-finetune recipe with language models trained on a synthetic propositional language entailment task, and present results on test sets probing models’ knowledge of axioms of first order logic.</abstract>
      <url hash="8ba0ccc2">2021.naloma-1.4</url>
      <bibkey>traylor-etal-2021-transferring</bibkey>
    <title_ar>نقل تمثيلات الروابط المنطقية</title_ar>
      <title_es>Transferencia de representaciones de conectivas lógicas</title_es>
      <title_fr>Transfert de représentations de connectives logiques</title_fr>
      <title_pt>Transferindo Representações de Conectivos Lógicos</title_pt>
      <title_ja>論理接続の表現の転送</title_ja>
      <title_zh>传输逻辑连接词之</title_zh>
      <title_hi>तार्किक संयोजी के अभ्यावेदन को स्थानांतरित करना</title_hi>
      <title_ru>Передача представлений логических соединений</title_ru>
      <title_ga>Léirithe Nascthasc Loighciúil a Aistriú</title_ga>
      <title_ka>ლოგიკური კავშირების გამოსახულება</title_ka>
      <title_hu>Logikai kapcsolatok reprezentációinak átvitele</title_hu>
      <title_el>Μεταφορά αναπαραστάσεων λογικών συνδέσεων</title_el>
      <title_it>Trasferimento delle rappresentazioni di connessioni logiche</title_it>
      <title_kk>Логикалық қосылымдарды таңдау</title_kk>
      <title_lt>Transferring Representations of Logical Connectives</title_lt>
      <title_mk>Пренос на презентации на логични поврзувања</title_mk>
      <title_ms>Memindahkan Perwakilan Sambungan Logik</title_ms>
      <title_mt>Trasferiment ta’ Rappreżentazzjonijiet ta’ Konnettivi Loġiċi</title_mt>
      <title_ml>ലോഗിക്കല്‍ ബന്ധങ്ങളുടെ പ്രതിനിധികള്‍ മാറ്റുന്നു</title_ml>
      <title_mn>Логикийн холбоонуудын төлөөлөлт шилжүүлж байна</title_mn>
      <title_no>Overfører representasjonar av logiske tilkoplingar</title_no>
      <title_ro>Transferul reprezentărilor conexiunilor logice</title_ro>
      <title_pl>Przenoszenie reprezentacji połączeń logicznych</title_pl>
      <title_sr>Prebacuju predstave logičkih konektiva</title_sr>
      <title_si>තාර්කික සම්බන්ධයේ ප්‍රතිස්ථාපනය</title_si>
      <title_so>Ku wareejinta xiriirka Logical</title_so>
      <title_sv>Överföra representationer av logiska anslutningar</title_sv>
      <title_ta>தொடர்புகளின் மாற்றப்படுகிறது</title_ta>
      <title_ur>لوجیک اتصال کی روشنی</title_ur>
      <title_uz>Comment</title_uz>
      <title_vi>Truyền ảnh các kết nối logic</title_vi>
      <title_bg>Прехвърляне на представителства на логически връзки</title_bg>
      <title_hr>Prebacuju predstave logičkih konektiva</title_hr>
      <title_nl>Vertegenwoordigingen van logische verbindingen overbrengen</title_nl>
      <title_ko>논리적 연결어의 변환 표현</title_ko>
      <title_de>Übertragung von Repräsentationen von logischen Verbindungen</title_de>
      <title_sw>Kubadilisha maoni ya Mawasiliano ya KiLogical</title_sw>
      <title_id>Memindahkan Perwakilan Konektif Logik</title_id>
      <title_fa>Transferring Representations of Logical Connectives</title_fa>
      <title_da>Overførsel af repræsentationer af logiske forbindelser</title_da>
      <title_af>Oordrag Voorstellings van Logiese Verbindings</title_af>
      <title_am>Transferring Representations of Logical Connectives</title_am>
      <title_sq>Duke transferuar përfaqësimet e lidhjeve logjike</title_sq>
      <title_tr>Logyk Baglaýyşlaryň Görkezilmeleri Taýşart</title_tr>
      <title_hy>Լոգիկական կապերի ներկայացումների փոխանցումը</title_hy>
      <title_bn>লোগিকেল সংযোগের প্রতিনিধি পরিবর্তন করা হচ্ছে</title_bn>
      <title_cs>Přenos reprezentací logických spojů</title_cs>
      <title_az>Lojik Baƒülantƒ±larƒ±n ƒ∞fad…ôl…ôrini da≈üƒ±nƒ±r</title_az>
      <title_fi>Loogisten yhteyksien edustustojen siirtäminen</title_fi>
      <title_ca>Transferent Representations of Logical Connectives</title_ca>
      <title_bs>Prebacuju predstave logičkih konektiva</title_bs>
      <title_et>Loogiliste ühenduste esinduste edastamine</title_et>
      <title_jv>Ngubah Gambar Ketokani</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>העברת מייצגים של קשרים לוגיים</title_he>
      <title_sk>Prenos predstavitev logičnih povezav</title_sk>
      <title_bo>ནང་དོན་འབྲེལ་མཐུད་ཀྱི་རྣམ་པ་སྤོར་བཞིན་</title_bo>
      <abstract_ar>في خطوط أنابيب معالجة اللغة الطبيعية الحديثة ، من الممارسات الشائعة "التدريب المسبق" لنموذج اللغة التوليدية على مجموعة كبيرة من النص ، ثم "صقل" التمثيلات التي تم إنشاؤها من خلال الاستمرار في تدريبهم على مهمة استدلال نصي تمييزي. ومع ذلك ، ليس من الواضح على الفور ما إذا كان المعنى المنطقي الضروري لنمذجة الاستلزام المنطقي قد تم التقاطه بواسطة نماذج اللغة في هذا النموذج. ندرس هذه الوصفة الدقيقة قبل التمرين باستخدام نماذج لغوية مدربة على مهمة تستلزم لغة افتراضية تركيبية ، ونقدم نتائج على مجموعات الاختبار التي تستقصي معرفة النماذج عن البديهيات لمنطق الدرجة الأولى.</abstract_ar>
      <abstract_pt>Nos pipelines modernos de processamento de linguagem natural, é prática comum “pré-treinar” um modelo de linguagem generativa em um grande corpus de texto e, em seguida, “ajustar” as representações criadas continuando a treiná-las em uma tarefa de inferência textual discriminativa. No entanto, não está imediatamente claro se o significado lógico necessário para modelar a implicação lógica é capturado pelos modelos de linguagem neste paradigma. Examinamos esta receita de pré-treinamento com modelos de linguagem treinados em uma tarefa de vinculação de linguagem proposicional sintética e apresentamos resultados em conjuntos de testes que investigam o conhecimento dos modelos de axiomas da lógica de primeira ordem.</abstract_pt>
      <abstract_es>En los procesos modernos de procesamiento del lenguaje natural, es una práctica común «preentrenar» un modelo de lenguaje generativo en un gran corpus de texto, y luego «afinar» las representaciones creadas al continuar entrenándolas en una tarea de inferencia textual discriminativa. Sin embargo, no está claro de inmediato si el significado lógico necesario para modelar la implicación lógica es capturado por los modelos de lenguaje en este paradigma. Examinamos esta receta de ajuste previo al entrenamiento con modelos de lenguaje entrenados en una tarea de implicación de lenguaje proposicional sintético, y presentamos los resultados en conjuntos de pruebas que sondean el conocimiento de los modelos de axiomas de la lógica de primer orden.</abstract_es>
      <abstract_fr>Dans les pipelines modernes de traitement du langage naturel, il est courant de « pré-entraîner » un modèle de langage génératif sur un grand corpus de texte, puis de « peaufiner » les représentations créées en continuant à les entraîner sur une tâche d'inférence textuelle discriminatoire. Cependant, il n'est pas immédiatement clair si le sens logique nécessaire pour modéliser l'implication logique est saisi par les modèles linguistiques dans ce paradigme. Nous examinons cette recette de pré-apprentissage et de mise au point avec des modèles de langage formés sur une tâche d'implication de langage propositionnel synthétique, et présentons les résultats sur des ensembles de tests qui sondent la connaissance des modèles des axiomes de la logique de premier ordre.</abstract_fr>
      <abstract_ja>現代の自然言語処理パイプラインでは、テキストの大規模なコーパスに生成言語モデルを「事前訓練」し、その後、差別的なテキスト推論タスクでそれらを訓練し続けることによって、作成された表現を「微調整」するのが一般的である。しかし、論理的帰結をモデル化するために必要な論理的意味が、このパラダイムの言語モデルによって捉えられるかどうかは、すぐには明らかではない。我々は、合成命題言語関連タスクで訓練された言語モデルを用いて、この訓練前のレシピを検討し、一階論理の公理に関するモデルの知識を探索するテストセットの結果を提示する。</abstract_ja>
      <abstract_hi>आधुनिक प्राकृतिक भाषा प्रसंस्करण पाइपलाइनों में, पाठ के एक बड़े कॉर्पस पर एक उत्पादक भाषा मॉडल को "प्रीट्रेन" करना आम बात है, और फिर उन्हें भेदभावपूर्ण पाठ्य अनुमान कार्य पर प्रशिक्षित करना जारी रखकर बनाए गए अभ्यावेदनों को "फाइनट्यून" करने के लिए। हालांकि, यह तुरंत स्पष्ट नहीं है कि क्या तार्किक तात्पर्य को मॉडल करने के लिए आवश्यक तार्किक अर्थ इस प्रतिमान में भाषा मॉडल द्वारा कब्जा कर लिया गया है। हम एक सिंथेटिक प्रस्तावात्मक भाषा पर प्रशिक्षित भाषा मॉडल के साथ इस pretrain-finetune नुस्खा की जांच करते हैं, और पहले आदेश तर्क के स्वयंसिद्धों के मॉडल के ज्ञान की जांच करने वाले परीक्षण सेटों पर परिणाम प्रस्तुत करते हैं।</abstract_hi>
      <abstract_zh>今世自然语言治管,常以"预"为语料库,然后以"微调"为辞。 然未详其范式,语言得建模逻辑蕴涵所需逻辑之义。 合命题之言蕴涵以练言语,以验其方,以展其集上,以探其辩。</abstract_zh>
      <abstract_ru>В современных конвейерах обработки естественного языка общепринятой практикой является «предварительная подготовка» генеративной языковой модели на большом корпусе текста, а затем «тонкая настройка» созданных представлений, продолжая обучать их дискриминирующей текстовой задаче вывода. Однако не сразу ясно, отражено ли в этой парадигме логическое значение, необходимое для моделирования логического влечения, языковыми моделями. Мы изучаем этот предрецепт с языковыми моделями, обученными на синтетической предлагаемой языковой задаче, и представляем результаты по знанию моделей зондирования тестовых наборов аксиом логики первого порядка.</abstract_ru>
      <abstract_ga>Sna píblínte próiseála teanga nádúrtha nua-aimseartha, is gnáthchleachtas é “réamhoiliúint” a dhéanamh ar mhúnla ginte teanga ar chorpas mór téacs, agus ansin na huiríll cruthaithe a “mhionneodhú” trí leanúint dá n-oiliúint ar thasc tátal idirdhealaitheach téacsúil. Mar sin féin, níl sé soiléir láithreach an bhfuil an bhrí loighciúil atá riachtanach chun eiseamláiriú loighciúil a shamhaltú ag samhlacha teanga sa pharaidím seo. Scrúdóimid an t-oideas réamhthraenála-mhíntiún seo le múnlaí teanga atá oilte ar thasc tairscríofa teanga sintéiseach, agus cuirimid torthaí i láthair ar thacair thástálacha ag fiosrú eolas samhlacha ar aicsiomaí den loighic den chéad scoth.</abstract_ga>
      <abstract_ka>მოდინარებული ენერგიის პროცესირების პერსექსირებაში, ეს საერთო პროცესია "pretrain" ენერგიის მოდელის დიდი ტექსტის კორპუსში და შემდეგ "finetune" შექმნილი რესპექსირებების გამოყენება, რომლებიც ისინი დარწყება დისკ მაგრამ არ არის წარმოადგილად, თუ ლოგიკური მნიშვნელობა, რომელიც ამ პარადიგმაში მჭირდება, რომ ლოგიკური მნიშვნელობა მოდელისთვის მოდგენა. ჩვენ შევხედავთ ეს პრეტერეინ-ფინტუნის რესპექტი ენის მოდელებით, რომლებიც სინტეტიკური პროგრამეტური ენის შესაძლებლობის მომუშაობაში განსწავლია, და შესაძლებლობები ტესტის შესაძლებლობის მოდელების</abstract_ka>
      <abstract_hu>A modern természetes nyelvfeldolgozó csővezetékekben általános gyakorlat egy generációs nyelvi modellt "előkészíteni" egy nagy szövegkorpuszon, majd "finomhangolni" a létrehozott reprezentációkat azáltal, hogy tovább tanítják őket egy diszkriminatív szöveges következtetési feladatra. Azonban nem egyértelmű, hogy a logikai vonatkozás modellezéséhez szükséges logikai jelentést ebben a paradigmában megragadják-e. Ezt az előzetes finomhangolás receptet szintetikus propozicionális nyelvi vonatkozási feladatra képzett nyelvi modellekkel vizsgáljuk, és bemutatjuk az eredményeket az elsőrendű logika axiómáinak vizsgálatára.</abstract_hu>
      <abstract_el>Στους σύγχρονους αγωγούς επεξεργασίας φυσικής γλώσσας, είναι κοινή πρακτική να "προετοιμάζουμε" ένα μοντέλο γενεαλογικής γλώσσας σε ένα μεγάλο σώμα κειμένου και στη συνέχεια να "τελειοποιούμε" τις δημιουργημένες αναπαραστάσεις συνεχίζοντας να τις εκπαιδεύουμε σε μια εργασία διακριτών κειμενικών συμπερασμάτων. Ωστόσο, δεν είναι αμέσως σαφές αν η λογική έννοια που είναι απαραίτητη για το μοντέλο της λογικής εμπλοκής αποτυπώνεται από γλωσσικά μοντέλα σε αυτό το παράδειγμα. Εξετάζουμε αυτή τη συνταγή με γλωσσικά μοντέλα εκπαιδευμένα σε μια εργασία συνθετικής πρότασης γλώσσας και παρουσιάζουμε αποτελέσματα σε δοκιμαστικά σύνολα που διερευνούν τη γνώση των μοντέλων για αξιώματα λογικής πρώτης τάξης.</abstract_el>
      <abstract_it>Nelle moderne pipeline di elaborazione del linguaggio naturale, è prassi comune "preparare" un modello di linguaggio generativo su un grande corpus di testo, e poi "perfezionare" le rappresentazioni create continuando ad addestrarle su un compito discriminante di inferenza testuale. Tuttavia, non è immediatamente chiaro se il significato logico necessario per modellare il coinvolgimento logico sia catturato dai modelli linguistici in questo paradigma. Esaminiamo questa ricetta pretrain-finetune con modelli linguistici addestrati su un compito di implicazione del linguaggio proposizionale sintetico, e presentiamo i risultati su set di test sondando la conoscenza dei modelli degli assiomi della logica del primo ordine.</abstract_it>
      <abstract_kk>Қазіргі табиғи тілдерді өңдеу үлгілі мәтіннің үлкен корпус үшін "pretrain" деген көпшілік тіл үлгісін өзгерту әрекеті болады. Содан кейін оларды дискриминациялық мәтіннің бағыттау тапсырмасын "finetune" дегенге Бірақ, логикалық үлгілерді үлгілеу үшін логикалық мәліметі бұл парадигмінің тіл үлгілері арқылы түсірілгені түсінбейді. Біз тіл үлгілерін синтетикалық тілді қолдану тапсырмасына ұқсас етілген пререйн- финетун рецепті тексеріп, сынақтағы нәтижелері бірінші рет логикалық асиомдардың мәліметін тексеру үлгілерінің білімін</abstract_kk>
      <abstract_lt>Šiuolaikinėse gamtinėse kalbų apdorojimo vamzdynuose įprasta praktika „iš anksto“ parengti kartotinį kalbos model į ant didelio teksto korpuso, o vėliau „patobulinti“ sukurtus atstovus ir toliau mokyti juos diskriminuojant tekstinę išvadą. Tačiau nedelsiant neaišku, ar logiška reikšmė, reikalinga loginiam įtraukimui modeliuoti, yra pagrįsta kalbų modeliais šioje paradigmoje. Mes išnagrinėjame šį ankstyvuoju būdu patobulintą receptą su kalbų modeliais, mokomais atlikti sintetinę siūlomą kalbos įtraukimo užduotį, ir pateikiame rezultatus bandymų rinkiniuose, kuriuose ištiriamos modelių žinios apie pirmosios eilės logikos aksioms.</abstract_lt>
      <abstract_mk>Во модерните нафтоводи за процес на природен јазик, често е да се „претренира“ генеративен јазик модел на голем корпус текст, а потоа да се „финетизира“ создадените претставувања со продолжување на обуката за дискриминативна текстуална инференција. Сепак, не е веднаш јасно дали логичното значење потребно за моделот на логичното вмешање е зафатено од јазичките модели во овој парадигм. Ние го испитуваме овој рецепт од предожд со јазички модели обучени на синтетичка предложна задача за антилација на јазик, и ги претставуваме резултатите на тестовите кои ги испитуваат знањата на моделите за аксиомите од прва логика.</abstract_mk>
      <abstract_ms>Dalam saluran paip pemprosesan bahasa semulajadi modern, ia adalah praktek biasa untuk "pretraining" model bahasa generatif pada korpus besar teks, dan kemudian untuk "finetune" perwakilan yang dicipta dengan terus melatih mereka pada tugas kesimpulan teks diskriminatif. Namun, tidak jelas secara segera sama ada makna logik yang diperlukan untuk model penyelesaian logik ditangkap oleh model bahasa dalam paradigma ini. Kami memeriksa resep pre-rain-finetune ini dengan model bahasa dilatih pada tugas sintetik bahasa propositional entailment, dan memperkenalkan keputusan pada set ujian menguji pengetahuan model aksiom logik tertib pertama.</abstract_ms>
      <abstract_ml>ആധുനിക ഭാഷ പ്രാവൃത്തിക ഭാഷയുടെ പ്രക്രിയശ്ചിത്രത്തില്‍, ഒരു ജനറല്‍ ഭാഷയുടെ മോഡലില്‍ "പ്രസ്താവീകരിക്കുക" എന്നതാണ് സാധാരണ പ്രവര്‍ത്തനങ്ങള്‍, പിന്നെ ഒരു വലിയ വാക്കുകള എന്നാലും ഈ പ്രദര്‍ശനത്തിലെ ഭാഷ മോഡലുകള്‍ പിടികൂടുന്നതിനാല്‍ ലോഗിക്കല്‍ അര്‍ത്ഥം മാത്രമാണോ എന്ന് വ്യക്തമാക്കുന്നില്ല നമ്മള്‍ ഭാഷ മോഡലുകള്‍ പരിശീലിക്കുന്നത് ഭാഷ മാതൃകങ്ങള്‍ പരിശീലിക്കുന്നു. ഒരു സിന്റെറ്റിക്കല്‍ പരിശോധിക്കുന്ന ഭാഷ മാതൃകങ്ങളില്‍ പരിശോധിക്കുന്</abstract_ml>
      <abstract_mt>Fil-pajpijiet moderni tal-ipproċessar tal-lingwi naturali, huwa prattika komuni li “jiġi mħarreġ minn qabel” mudell ta’ lingwa ġenerattiva fuq korpus kbir ta’ test, u mbagħad li “jiġu ffinalizzati” r-rappreżentazzjonijiet maħluqa billi jkomplu jitħarrġuhom fuq kompitu ta’ inferenza testwali diskriminatorja. Madankollu, mhux ċar immedjatament jekk it-tifsira loġika meħtieġa għall-mudell ta’ involviment loġiku tinqabad minn mudelli lingwistiċi f’dan il-paradigma. Aħna jeżaminaw din ir-riċetta ta’ qabel it-tixrid finat b’mudelli lingwistiċi mħarrġa fuq kompitu sintetiku ta’ involviment lingwistiku propostiv, u nippreżentaw riżultati fuq settijiet ta’ testijiet li jsawru l-għarfien tal-mudelli tal-assiomi tal-loġika tal-ewwel ordni.</abstract_mt>
      <abstract_mn>Орчин үеийн байгалийн хэл дамжуулагч хоолойн шугамын тусламжтайгаар "pretrain" хэл загварын нэг томоохон хэл загварын тулд ерөнхий дасгал хөдөлгөөн байдаг. Тэгээд "finetune" хэлбэрийн тусламжтайгаар бүтээгдэхүүний тусламжтайгаар тэдн Гэвч энэ парадигмд хэл загвараар барьж байгаа логикийн утгыг загварчлах хэрэгтэй эсэхийг шууд тодорхойлж чадахгүй. Бид хэл загвараар сургалтын шинжлэх ухааны ажил дээр сургалтын анхны хэл дээр сургалтын сургалтын арга загварыг шалгаж, шалгалтын үр дүнг нь анхны дараагийн логикийн тэнхлэгийн арга загварын мэдлэгийг шалгаж байна.</abstract_mn>
      <abstract_no>I moderne naturspråk-behandlingslinjer er det vanlege praksis for «pretrain» ein generert språk-modell på ein stor tekstkorpus, og deretter for «finetune» dei lagane representasjonane ved å fortsette å trena dei på ein diskriminasjonalt tekstinfeksjonsverkt. Det er imidlertid ikkje klart om det logiske betydninga som er nødvendig for å modellera logisk innhald vert henta av språk-modeller i denne paradigmen. Vi undersøker denne pretrain-finetune-recepten med språk-modeller som trengte på eit syntetisk foreslådgivning av språk, og første resultat på testen setter opp forsøkmodellerens kunnskap om aksiom av første rekkefølgje logikk.</abstract_no>
      <abstract_pl>We współczesnych rurociągach przetwarzania języka naturalnego powszechną praktyką jest "pretrening" generatywnego modelu języka na dużym korpusie tekstu, a następnie "finetuning" tworzonych reprezentacji, kontynuując ich trening w zakresie dyskryminacyjnego zadania wnioskowania tekstowego. Nie jest jednak od razu jasne, czy logiczne znaczenie niezbędne do modelowania logicznego implikacji jest uchwycone przez modele językowe w tym paradygmacie. Badamy tę recepturę pretreningową-finetuningową z modelami językowymi przeszkolonymi na zadaniu syntetycznego języka propozycyjnego oraz prezentujemy wyniki zestawów testowych badających wiedzę modeli o aksiomach logiki pierwszego rzędu.</abstract_pl>
      <abstract_ro>În conductele moderne de procesare a limbajului natural, este o practică obișnuită să se "pregătească" un model de limbaj generativ pe un corpus mare de text, și apoi să "finuțească" reprezentările create continuând să le antreneze pe o sarcină de deducere textuală discriminatorie. Cu toate acestea, nu este imediat clar dacă semnificația logică necesară modelării implicației logice este capturată de modelele lingvistice din această paradigmă. Examinăm această rețetă pretrain-finetune cu modele lingvistice instruite pe o sarcină de implicare a limbajului propozițional sintetic și prezentăm rezultatele seturilor de testare care sondează cunoștințele modelelor despre axiomele logicii de prim ordin.</abstract_ro>
      <abstract_sr>U modernom prirodnom jeziku obrađivanje cijevi, to je zajednička praksa „pretkivanje“ generičnim jezičkim modelom na velikom korpusu teksta, a zatim „finetune“ stvorenim predstavljanjima nastavljajući ih obučavati na diskriminacijskom tekstualnom zadatku infekcije. Međutim, nije odmah jasno da li je logičko značenje potrebno za modelu logičke namjere uhvaćeno jezičkim modelima u ovoj paradigmi. Ispitujemo ovaj recept pretrain-finetune sa jezičkim modelima obučenim na zadatak za integraciju sintetičkog predloženog jezika, i predstavljamo rezultate test a postavljaju znanje modela istraživanja aksioma prvog reda logike.</abstract_sr>
      <abstract_so>Dhagaxa baaritaanka afka asalka ah waa hab caadi ah in lagu sameeyo “pretrain” model afka general ah oo ku qoran qoraal aad u weyn, dabadeedna in lagu sameeyo “finetune” lagu tababariyo shaqada ku saabsan cudurka qoriga ah. Si kastaba ha ahaatee markiiba ma caddayno in loo baahan yahay in loo sameynayo tusaale ahaan qofka cilmiga la xiriira looga baahdo. Waxaan imtixaamaynaa samooyinkaas afka lagu tababariyey oo lagu baro shaqo la barto afka hore oo la soo jeedo, waxaana la soo bandhigayaa resultooyin imtixaanka lagu tijaabiyo tusaalaha aqoonta sawirada safarka hore.</abstract_so>
      <abstract_sv>I moderna naturliga språkbehandlingspipelines är det vanligt att "förbeställa" en generativ språkmodell på en stor textkorpus, och sedan "finjustera" de skapade representationerna genom att fortsätta träna dem på en diskriminerande textdeduktionsuppgift. Det är dock inte omedelbart klart om den logiska innebörden som krävs för att modellera logisk involvering fångas upp av språkmodeller i detta paradigm. Vi undersöker detta preliminära-finjusterade recept med språkmodeller utbildade på en syntetisk propositionsspråklig innebördesuppgift, och presenterar resultat på testset som undersöker modellernas kunskap om axiomer av första ordningens logik.</abstract_sv>
      <abstract_si>අධ්‍යාත්මක භාෂාව පායිප්ලින්ස් පරීක්ෂණා කරනවා, ඒක "ප්‍රීට්‍රින්" භාෂාව ප්‍රමාණයක් විශාල භාෂාව පිළිබඳ භාෂාව පිළිබඳ පිළ නමුත්, ඒක ඉක්මනින් පැහැදිලි නැහැ මේ පැරැඩිග්ම් වල භාෂාව මොඩල් වලින් අල්ලගන්න ඕනි ලෝජික අදහස් අ අපි මේ ප්‍රීට්‍රින්-ෆින්ටුන් රිසිපිට් එක්ක භාෂා මොඩේල් එක්ක ප්‍රශ්නයක් කරලා තියෙන්නේ සංවේදනය භාෂාවක් අන්තිම වැඩේ සඳහා පර</abstract_si>
      <abstract_ur>آسانی طبیعی زبان کی پردازی پائیپلین میں، یہ ایک بڑے ٹیکسٹ کے کرپوس پر ایک جوڑی زبان کی موڈل کی تعلیم ہے، اور اس کے بعد پیدا کئے ہوئے نمائش "finetune" کے ذریعہ سے ان کی تعلیم کے ساتھ پردازی کرنا ادامه کرنا چاہتا ہے. However, it is not immediately clear whether the logical meaning necessary to model logical intention is captured by language models in this paradigm. ہم اس پرٹرین-فینٹون رسیپ کی تحقیق کرتے ہیں جو زبان مدل کے ذریعے ایک سینٹیسی پیشنهاد زبان کی تعلیم کی کوشش پر آموزش کی گئی ہے، اور آزمائش کے نتیجے میں پہلی اوردن لاجیک کی آکسیوم کے معاملہ میں تحقیق مدل کے معاملہ میں رکھتے ہیں.</abstract_ur>
      <abstract_ta>தற்போதைய இயற்கையான மொழி செயல்பாடுகளில் ஒரு பொதுவான பயிற்சி உரையின் பெரிய மொழி மாதிரி மாதிரி மாதிரியாகும், பின்னர் "ஃபின்டுயூன்" என்று உருவாக்கப்பட்ட பின்த ஆயினும், உடனடியாக தெளிவாக இல்லை நாம் இந்த மொழி மாதிரியில் பயிற்சி செய்யப்பட்ட மொழியில் இந்த மாதிரி பின்னுட்டுவைப்பை பரிசோதிக்கிறோம். முதல் வரிசை நுழைவுகளின் அறிவு மாதி</abstract_ta>
      <abstract_uz>Name However, it is not immediately clear whether the logical meaning necessary to model logical entailment is captured by language models in this paradigm.  Biz bu prerain-finetun tizimini o'rganish tili modellari bilan o'rganishni o'rganishni o'rganamiz, va bu natijalarni birinchi takror logikasini o'rganish modellarni o'rganamiz.</abstract_uz>
      <abstract_vi>Trong những đường ống xử lý ngôn ngữ tự nhiên hiện đại, đây là thói quen chung với những đường ống 82;pretirain*8221; một mô hình ngôn ngữ tạo hóa trên một tập lớn của văn bản, và sau đó là*82201; tinh vi được tạo ra bằng cách tiếp tục huấn luyện chúng theo một công việc nhận kết cấu phân biệt độc tính. Tuy nhiên, không phải lúc nào cũng rõ rằng ý nghĩa logic cần thiết để mô hình tỷ lệ tỷ lệ logic được nắm giữ bởi các mô hình ngôn ngữ trong mô hình này. Chúng tôi nghiên cứu công thức tinh tế này với các mô hình ngôn ngữ được đào tạo trên một nhiệm vụ cung cấp ngôn ngữ văn bản tổng hợp, và có kết quả về các bộ thử nghiệm thăm dò kiến thức của các mô- đun về các trục của logic thứ nhất.</abstract_vi>
      <abstract_hr>U modernom prirodnom jeziku obrađivanje cijevi, to je obična praksa "pretrain" generičnim jezičkim modelom na velikom korpusu teksta, a zatim "finetune" stvorenim predstavljanjima nastavljajući ih obučavati na diskriminativnom tekstualnom infekciju zadatku. Međutim, nije odmah jasno da li je logičko značenje potrebno za modelu logičke namjere uhvaćeno jezičkim modelima u ovoj paradigmi. Ispitujemo ovaj recept pretrain-finetune sa jezičkim modelima obučenim na zadatku o integraciji sintetičkog prijedloga jezika, i predstavljamo rezultate test a postavljaju znanje modela istraživanja aksioma prvog reda logike.</abstract_hr>
      <abstract_nl>In moderne natuurlijke taalverwerkingspipelines is het gebruikelijk om een generatief taalmodel vooraf te 'trainen' op een groot corpus tekst, en vervolgens de gecreëerde representaties te 'finetunen' door ze te blijven trainen op een discriminerende tekstuele inferentietaak. Het is echter niet meteen duidelijk of de logische betekenis die nodig is om logische implicatie te modelleren, wordt vastgelegd door taalmodellen in dit paradigma. We onderzoeken dit pretrain-finetune recept met taalmodellen die zijn getraind op een synthetische propositionele taal implicatietaak, en presenteren resultaten op testsets die de kennis van modellen van axioma's van eerste orde logica onderzoeken.</abstract_nl>
      <abstract_bg>В съвременните тръбопроводи за обработка на естествени езици е обичайна практика да се "подготви" генеративен езиков модел върху голям корпус от текст, а след това да се "финизират" създадените изображения, като продължават да се обучават върху дискриминативна задача за текстово заключение. Не е ясно обаче веднага дали логическото значение, необходимо за моделиране на логическото обвързване, е уловено от езиковите модели в тази парадигма. Разглеждаме тази рецепта с езикови модели, обучени по задача за синтетично обвързване на пропорционалния език, и представяме резултати от тестови комплекти, изследващи познанията на моделите за аксиоми от логика от първи ред.</abstract_bg>
      <abstract_de>In modernen Pipelines zur Verarbeitung natürlicher Sprache ist es üblich, ein generatives Sprachmodell auf einem großen Textkorpus vorzutrainieren und dann die erstellten Repräsentationen zu "verfeinern", indem sie weiter an einer diskriminierenden Textinferenz-Aufgabe trainiert werden. Es ist jedoch nicht sofort klar, ob in diesem Paradigma die logische Bedeutung, die für die Modellierung logischer Implikationen notwendig ist, von Sprachmodellen erfasst wird. Wir untersuchen dieses Pretrain-Finetune-Rezept mit Sprachmodellen, die auf einer synthetischen Satzsprache-Implementierungsaufgabe trainiert wurden, und präsentieren Ergebnisse an Testsätzen, die das Wissen von Modellen über Axiome erster Ordnung untersuchen.</abstract_de>
      <abstract_da>I moderne natursprogbehandlingsrørledninger er det almindelig praksis at 'forudsætte' en generativ sprogmodel på et stort tekstkorpus og derefter 'finjustere' de skabte repræsentationer ved at fortsætte med at træne dem i en diskriminerende tekstbaseret slutopgave. Det er imidlertid ikke umiddelbart klart, om den logiske betydning, der er nødvendig for at modellere logisk involvering, fanges af sprogmodeller i dette paradigme. Vi undersøger denne præ-finetune opskrift med sprogmodeller trænet i en syntetisk propositional sproginvolveringsopgave, og præsenterer resultater på testsæt, der sonderer modellernes viden om aksiomer af førsteordens logik.</abstract_da>
      <abstract_ko>현대 자연 언어 처리 파이프라인에서 일반적인 방법은 대량의 텍스트에서'예훈련'을 통해 언어 모델을 생성한 다음에 서로 다른 텍스트 추리 임무를 계속 훈련함으로써'미조정'을 통해 만들어진 표현을 하는 것이다.그러나 이런 모델 중의 언어 모델이 모델링 논리에 필요한 논리적 의미를 포착했는지는 아직 분명하지 않다.우리는 종합 명제 언어의 내포된 임무에 대해 훈련된 언어 모델로 이pretrain의 세부적인 설계도를 검증하고 탐색 모델이 1단계 논리적 공리에 대한 지식에 대한 테스트집에서 결과를 제시한다.</abstract_ko>
      <abstract_sw>Katika mistari ya upasuaji wa lugha za asili za kisasa, ni utaratibu wa kawaida wa 'pretrain' wa mtindo wa lugha ya kizalendo kwenye makampuni makubwa ya maandishi, na kisha 'finetune' ulioanzishwa kwa kuwafundisha kazi ya kutokuwepo na ugonjwa wa kimsingi. Hata hivyo, haijaeleweka wazi ikiwa maana ya kimaadili yanahitajika kuelezea mtoto wa kitaaluma inakamatwa na mifano ya lugha katika upande huu. Tunatachunguza kipindi hiki kinachotumiwa na mifano ya lugha inayofundishwa kwa kazi ya lugha inayopendekezwa kwa ushirikiano, na matokeo yanayotokea kwenye majaribio yanatengeneza maarifa ya mifano ya mantiki ya kwanza ya mfumo.</abstract_sw>
      <abstract_id>Dalam pipa proses bahasa alam modern, praktek umum untuk 'pretrain' model bahasa generatif pada tubuh besar teks, dan kemudian untuk 'finetune' representation yang diciptakan dengan terus melatih mereka pada tugas diskriminatif kesimpulan teks. However, it is not immediately clear whether the logical meaning necessary to model logical entailment is captured by language models in this paradigm.  We examine this pretrain-finetune recipe with language models trained on a synthetic propositional language entailment task, and present results on test sets probing models' knowledge of axioms of first order logic.</abstract_id>
      <abstract_fa>در مجموعه‌های پردازش لوله‌های طبیعی مدرن، این تمرین معمولی برای "pretrain" یک مدل زبان ژنراتی روی یک کورپوس بزرگ از متن است، و سپس برای "finetune" نمایش‌های ساخته‌شده با ادامه دادن آنها را روی یک کار آلوده‌ی متن جدا می‌گیرد. با این حال، فوراً واضح نیست که آیا معنی منطقی که لازم است برای مدل ارائه منطقی توسط مدل زبانی در این پارادیگ گرفته شود. ما این فرصت پیشرین-فینتون را با مدل زبان آموزش داده‌ایم که روی یک وظیفه پیشنهاد زبان ساخته می‌شود تحقیق می‌کنیم، و نتیجه‌های آزمایش در آزمایش دانش مدل‌های آکسیوم اولین فرصت منطقی را تعلیم می‌دهیم.</abstract_fa>
      <abstract_am>በአዲስ አዲስ የፍጥረት ቋንቋ ማቀናቀል፣ በ ትልቅ የጽሑፍ አካባቢ የቋንቋ ሞዴል “pretrain” (ፍትሪን) በመጠቀም፣ ከዚያም በኋላ “ፍንቲን” የተፈጠረውን መልዕክቶች በተለያዩ የጽሑፍ ውጤታዊ ስራ በማስተማር ላይ ማሳየት ይደረጋሉ፡፡ ምንም እንኳን፣ የግንኙነት ማህበረሰብ የቋንቋ ምሳሌዎች በዚህ አካባቢ ውስጥ መያዣ እንዲያስፈልገው የግለጹ ማህተት አይገልጽም፡፡ ይህንን የፊርrain-ፊንቱናን recipe በቋንቋ ምሳሌዎች በተጠቃሚ የቋንቋ ቋንቋ ማወቅ በሚያስተምርበት እናፈትናለን፤ ፍሬቶችንም የፊተኛውን ክፍተት የግንኙነት ማወቂያ ማውቀትን እናደርጋለን፡፡</abstract_am>
      <abstract_af>In moderne natuurlike taal verwerking pyplyn is dit gemeenskaplike praksie om 'pretrain' n genereerdere taal model op 'n groot korpus van teks, en dan na 'finetune' die geskepe voorstellings deur voortgaan om hulle te trei op 'n diskriminasieële teksverdigheidsel taak. Maar dit is nie dadelik duidelik of die logiese betekening wat nodig is om logiese aanhouding te model word deur taal modele in hierdie paradigme gevang word nie. Ons ondersoek hierdie pretrain-finetune recepte met taal modele wat op 'n sintetiese voorstellings taal aanhou opdrag is, en voorstel resultate op toets stel probeer modele se kennis van aksies van eerste volgorde logiek.</abstract_af>
      <abstract_tr>Modern tebigat dilinde pipelinikler işlemek üçin 'pretrain' dilinde örän uly tekst corpusynda döredilen praktika, soňra olary diskriminýa tekst a şyk täsirinde öwrenmäge dowam edýärler. Ýöne şu paradigmda logik maglumatyň nusgasyna görä almalydygyny düşünmez. Biz bu önümçilik-finetun reçetesini syntetik teklip taýýarlanan dil nusgalarynda barlaýarys we netijesi testiň modelleriniň ilkinji terjime logiki aksynyň bilgisini çykýarlar.</abstract_tr>
      <abstract_az>HazńĪrkńĪ t…ôbi…ôtli dild…ô pipe √ßizg…ôl…ôri iŇül…ôdir…ôk, b√∂y√ľk bir m…ôtn korpusu √ľzerind…ô 'pretrain' dil modeli olaraq, sonra da 'finetune' vasit…ôl…ôri yaratdńĪńüńĪ t…ôrzd…ô onlarńĪ diskriminat textual inference iŇül…ôrind…ô √∂yr…ôtm…ôk √ľ√ß√ľn istifad…ô edir. Lakin, bu paradigmd…ô dil modell…ôri tarafńĪndan alńĪnmńĪŇü logik anlamńĪnńĪn m…ôs…ôli olmasńĪ d…ôrhal a√ßńĪq deyil. Biz bu pretrain-finetune recepsini sintetik t…ôklif dill…ôrind…ô t…ôhsil edil…ôn dil modell…ôri il…ô t…ôhsil edirik v…ô sńĪnama sonu√ßlarńĪ ilk sńĪra logik aksiyonlarńĪn bilgisini t…ôhsil edirik.</abstract_az>
      <abstract_sq>In modern natural language processing pipelines, it is common practice to 'pretrain' a generative language model on a large corpus of text, and then to 'finetune' the created representations by continuing to train them on a discriminative textual inference task.  However, it is not immediately clear whether the logical meaning necessary to model logical entailment is captured by language models in this paradigm.  Ne e shqyrtojmë këtë recetë paraprake-finetune me modele gjuhësh të stërvitur në një detyrë sintetike propozicionale për përfshirjen e gjuhës dhe paraqesim rezultate në grupet e testimeve që hetojnë njohurinë e modeleve për aksiomet e logjikës së rendit të parë.</abstract_sq>
      <abstract_bn>আধুনিক ভাষার প্রাকৃতিক প্রক্রিয়ার পাইপেলাইনে একটি জেনারেটিভ ভাষার মডেলের জন্য সাধারণ প্রযুক্তি হচ্ছে, যা একটি বিশাল কোর্পাসে প্রযুক্তি প্রদান করে, আর তারপর ‘ফিন কিন্তু সাথে পরিষ্কার করা যায় না যে এই প্যারাডিমের ভাষার মডেলে মডেল করার জন্য যুক্তিগত অর্থ প্রয়োজন কিনা। আমরা ভাষার মডেলের সাথে প্রশিক্ষণ প্রদান করেছি একটি সিন্টেটিক ভাষার প্রস্তাবিত কাজের উপর এবং বর্তমানে পরীক্ষার ফলাফল প্রথম অর্ডারের লোগিকের মেডেলের জ্</abstract_bn>
      <abstract_bs>U modernom prirodnom jeziku obrađuje cijevi, to je zajednička praksa za 'pretrain' generični jezički model na velikom korpusu teksta, a zatim za 'finetune' stvorene predstave nastavljajući ih obučavati na diskriminacijskom zadatku tekstualnog infekcije. Međutim, nije odmah jasno da li je logičko značenje potrebno za modelu logičke namjere uhvaćeno jezičkim modelima u ovoj paradigmi. Ispitujemo ovaj recept pretrain-finetune sa jezičkim modelima obučenim na zadatak za integraciju sintetičkog predloženog jezika, i predstavljamo rezultate test a postavljaju znanje modela istraživanja aksioma prvog reda logike.</abstract_bs>
      <abstract_ca>En els tubs moderns de processament natural de llenguatges, és pràctica comú "pré-treinar" un model de llenguatge generador en un gran cos de text, i després "finar" les representacions creades continuant treinant-les en una tasca discriminativa de inferència textual. No obstant això, no és clar immediatament si el significat lògic necessari per modelar l'involucració lògica és capturat pels models lingüístics en aquest paradigma. Examinem aquesta receta de pré-estimulació amb models de llenguatge entrenats en una tasca sintètica d'involucració de llenguatge proposional, i presentem resultats en conjunts de proves que estudien el coneixement dels models dels axiomes de la lògica de primer ordre.</abstract_ca>
      <abstract_hy>Այսօրվա բնական լեզվի վերամշակման խողովակաշարերում սովորական գործընթաց է նախադառնալ սերունդային լեզվի մոդել տեքստի մեծ կորպոսի վրա, հետո "փոքրացնել" ստեղծված ներկայացումները շարունակելով ուսուցանել նրանց խտրականող տեքստային հետևանքների վրա Այնուամենայնիվ, անմիջապես պարզ չէ, թե արդյոք տրամաբանական իմաստը, որը անհրաժեշտ է տրամաբանական ներգրավման մոդելների համար, ընկած է այս պարադիգմայում գտնվող լեզվային մոդելների միջոցով Մենք ուսումնասիրում ենք այս նախօրինակ բաղադրատոմը լեզվի մոդելների հետ, որոնք վարժեցվել են սինթետիկ առաջարկած լեզվի ներգրավման խնդրի վրա, և ներկայացնում ենք փորձարկումների համակարգերի արդյունքները, որոնք ուսումնասիրում են մոդելների գիտելիք</abstract_hy>
      <abstract_et>Kaasaegsete looduskeelte töötlemise torujuhtmete puhul on tavaline "eeltreenida" generatiivne keelemudel suurele tekstikorpusele ja seejärel "täpsustada" loodud representatsioone, jätkates nende koolitamist diskrimineeriva tekstijärelduse ülesandeks. Siiski ei ole kohe selge, kas loogilise kaasamise modelleerimiseks vajalik loogiline tähendus on selles paradigmas keelemudelitega seotud. Uurime seda eeltreeni-peenestamise retsepti keelemudelitega, mis on koolitatud sünteetilise propositsiooni keele kaasamise ülesandeks, ning esitame tulemusi testikogumitest, mis proovivad mudelite teadmisi esimese astme loogika aksioomidest.</abstract_et>
      <abstract_cs>V moderních pipelines pro zpracování přírodního jazyka je běžnou praxí "předtrénovat" generativní jazykový model na velkém korpusu textu a poté "doladit" vytvořené reprezentace tím, že je pokračuje trénovat na diskriminačním textovém úkolu inference. Není však okamžitě jasné, zda je logický význam potřebný k modelování logické implikace zachycen jazykovými modely v tomto paradigmatu. Tento recept předběžného vyladění zkoumáme pomocí jazykových modelů trénovaných na úkolu syntetického výrokového jazyka a prezentujeme výsledky testovacích sad zkoumajících znalosti modelů o axiomech logiky prvního řádu.</abstract_cs>
      <abstract_fi>Nykyaikaisissa luonnollisen kielen käsittelyputkissa on yleistä "esikäsitellä" generatiivinen kielimalli suurelle tekstikorpuselle ja sitten "hienosäätää" luotuja representaatioita kouluttamalla niitä edelleen syrjivään tekstipäättelytehtävään. Heti ei kuitenkaan ole selvää, vangitsevatko kielimallit logisen osallisuuden mallintamiseen tarvittavan loogisen merkityksen tässä paradigmassa. Tutkimme tätä esihienosäätöreseptiä synteettiseen propositionaaliseen kielenkäyttötehtävään koulutetuilla kielimalleilla ja esitämme tuloksia testisarjoista, jotka tutkivat mallien tietämystä ensimmäisen asteen logiikan aksioomista.</abstract_fi>
      <abstract_jv>Nang modèr, nglanga-perusahaan ngeralakno dumadhi, kuwi nggawe pratike kuwi 'prekrén' ing modèl kuwi nggolok bantuan textual, lan sampek iso nggawe 'Finetune' sing ngewehke mulai nggawe ngubah iso nggawe ngubah ujaran cara-ujaran petandelah sing berarti. Nanging, ora dadi kapan dadi sing paling-kapan nganggo akeh logik dipunasaben nggawe modek kuwi alam-alam kuwi model model sing ngendalikne ning ngendalikne kuwi. Awak dhéwé éntuk gadhah pregunter-Finetune kuwi nggambar model sing luwih cara nggawe barang sistem sing rumangsa banjur kuwi nggagal sistem, lan bukane dadi nggawe ujian sistem kuwi nggawe model sing paling dhéwé kuwi " axiOm " sing berarti sistem tualke "</abstract_jv>
      <abstract_sk>V sodobnih cevovodih za obdelavo naravnih jezikov je običajna praksa, da se generativni jezikovni model "predvaja" na velikem korpusu besedila, nato pa se ustvarjene reprezentacije "finizirajo" tako, da se nadaljujejo z usposabljanjem za diskriminativno besedilno sklepanje. Vendar pa ni takoj jasno, ali logični pomen, potreben za modeliranje logične posledice, ujamejo jezikovni modeli v tej paradigmi. Ta recept predtren-fine tune preučujemo z jezikovnimi modeli, usposobljenimi za nalogo sintetičnega proposicijskega jezika, in predstavimo rezultate testnih nizov, ki prodirajo znanje modelov o aksiomih logike prvega reda.</abstract_sk>
      <abstract_ha>A cikin masu amfani da harshen na farko, yana da amfani da 'preraine' a cikin wata misalin littãfi mai girma, kuma a sa'an nan zuwa 'finatune' an halitta su da ana ƙara su a kan wani aikin wanda ya yi wa'azi na fasihi. Amma, ba za'a buƙata ba yanzu yanzu, ko ma'anar logiki na da amfani da wanda za'a yi amfani da shi a cikin wannan paradigm. Kana jarraba wannan misalin-fintune da misalin harshe wanda aka yi wa wa aikin da aka sani na littafin da ɗakiya, kuma a yanzu matsalan jarraba yana sami-sami'in motsi da aka sanar da shiryoyin ayuka na kwanza.</abstract_ha>
      <abstract_bo>In modern natural language processing pipelines, it is common practice to 'pretrain' a generative language model on a large corpus of text, and then to 'finetune' the created representations by continuing to train them on a discriminatory textual inference task. ཡིན་ནའང་། སྔོན་ལྟར་སྟོན་པར་ནི་གྲངས་རིག་གིས་དཔེ་གཏོང་དགོས་མིན་ཡང་ན། We examine this pretrain-finetune recipe with language models trained on a synthetic propositional language entailment task, and present results on test sets probing models' knowledge of axioms of first order logic.</abstract_bo>
      <abstract_he>בתוך צינורות עיבוד שפת טבעית מודרניים, זה מעשה נפוץ לשחק מודל שפת יוצר על גוף גדול של טקסט, ואז לשחק את היצירות שנוצרו על ידי המשיכה לאמן אותן על משימה מסורת טקסטית מדברית. בכל אופן, לא ברור מיד אם המשמעות הגיונית הנדרשת למודל התערבות הגיונית נתפסת על ידי דוגמני שפה בפרדיגמה הזאת. אנו בודקים את המתכון הזה לפני גשם עם דוגמנים שפות מאומנים על משימה סינטטית של השפה הציעה, ומציגים תוצאות על קבוצות מבחנים חוקרים ידע של דוגמנים על אקסיומים של הגיון של הסדר הראשון.</abstract_he>
      </paper>
    <paper id="5">
      <title>Monotonic Inference for Underspecified Episodic Logic</title>
      <author><first>Gene</first><last>Kim</last></author>
      <author><first>Mandar</first><last>Juvekar</last></author>
      <author><first>Lenhart</first><last>Schubert</last></author>
      <pages>26–40</pages>
      <abstract>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic. We establish a correspondence between inference rules of scope resolved Episodic Logic and the natural logic treatment by Snchez Valencia (1991a), and hence demonstrate the ability to handle foundational natural logic inferences from prior literature as well as more general nested monotonicity inferences.</abstract>
      <url hash="7d7fd64d">2021.naloma-1.5</url>
      <bibkey>kim-etal-2021-monotonic</bibkey>
    <title_pt>Inferência monotônica para lógica episódica subespecificada</title_pt>
      <title_es>Inferencia monótona para lógica episódica infravalorada</title_es>
      <title_ar>الاستدلال الأحادي للمنطق العرضي غير محدد</title_ar>
      <title_fr>Inférence monotone pour une logique épisodique sous-spécifiée</title_fr>
      <title_zh>未指定情理</title_zh>
      <title_hi>अनिर्दिष्ट एपिसोडिक तर्क के लिए मोनोटोनिक अनुमान</title_hi>
      <title_ru>Монотонный вывод для неопределенной эпизодической логики</title_ru>
      <title_ja>特定されていないエピソード論理の単調推論</title_ja>
      <title_ga>Tátal Monotónach maidir le Loighic Eipeasóid Neamhshonraithe</title_ga>
      <title_el>Μονοτονικό συμπέρασμα για την υποκαθορισμένη επισκοπική λογική</title_el>
      <title_hu>Monotóniás fertőzés alul meghatározott episzodikus logikához</title_hu>
      <title_it>Inferenza monotonica per logica episodica sottospecificata</title_it>
      <title_ka>მონოტონიკური ინფერენცია ჩემი განსაზღვრებული ეპიციოდიური ლოგიკისთვის</title_ka>
      <title_kk>Төменгі келтірілген эписодикалық логикалық монотониялық инференциясы</title_kk>
      <title_lt>Monotoninė Inferencija nepakankamai apibrėžtai epizodiniai logikai</title_lt>
      <title_ms>Inferensi Monotonik untuk Logik Episodi Tertidak Dinyatakan</title_ms>
      <title_ml>എപ്പിസോഡിക് ലോഗിക്കിനുള്ള ആന്‍ഡോണിക് ഇന്‍ഫെരെന്‍ഷന്‍സ്</title_ml>
      <title_mk>Монотонска инференција за недопределена епизодична логика</title_mk>
      <title_mt>Inferenza Monotonika għal Loġika Epiżodika Mhux Speċifikata biżżejjed</title_mt>
      <title_no>Monotonisk innstilling for underspesifisert episodisk logikk</title_no>
      <title_mn>Гурван тодорхойлогдсон эпиsodic Logic-ын Monotonic Inference</title_mn>
      <title_pl>Monotoniczny wniosek dla nieokreślonej logiki epizodycznej</title_pl>
      <title_ro>Inferenţă monotonică pentru logica episodică subspecificată</title_ro>
      <title_sr>Monotonska infekcija za pododređenu episodsku logiku</title_sr>
      <title_si>අඩිතිරික්ෂිත Episodic Logic සඳහා මොනෝටෝනික විශේෂය</title_si>
      <title_so>Dhibaatooyinka maandooriyaha</title_so>
      <title_sv>Monotonisk inferens för underspecificerad episodisk logik</title_sv>
      <title_ta>குறிப்பிட்ட குறிப்பிட்ட தொனோட்டிக் புகுநிரல்</title_ta>
      <title_ur>نیچے مطابق مطابق اپیسوڈیک لاجیک کے لئے مونوٹنیک افارنس</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Truyền liên kết đơn sắc cho Dịch phụ Tiểu động</title_vi>
      <title_bg>Монотоничен извод за недостатъчна епизодична логика</title_bg>
      <title_nl>Monotone conclusie voor ondergespecificeerde episodische logica</title_nl>
      <title_da>Monotonisk inferens for underspecificeret episodisk logik</title_da>
      <title_hr>Monotonska poremećaj za podspecificiranu episodijsku logiku</title_hr>
      <title_de>Monotone Schlussfolgerung für eine unterspezifierte episodische Logik</title_de>
      <title_id>Monotonic Inference for Underspecified Episodic Logic</title_id>
      <title_sw>Kuzungumzwa kwa Kimonotoniki kwa ajili ya Nembo ya Kipisode</title_sw>
      <title_fa>تأثیر منطقه‌ای برای منطقه‌ای زیر مشخص شده</title_fa>
      <title_ko>줄거리 논리가 정해지지 않은 단조로운 추리</title_ko>
      <title_af>Monotoniese Inferensie vir onderspesifiseerde episodiese logiek</title_af>
      <title_sq>Monotonic Inference for Underspecified Episodic Logic</title_sq>
      <title_tr>Asty takyklanylan episodik maglumaty üçin monotonik faýllar</title_tr>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_bn>Monotonic Inference for Underspecified Episodic Logic</title_bn>
      <title_az>Alt belirtilən episodik lojik üçün monotonik Inference</title_az>
      <title_bs>Monotonska infekcija za pododređenu episodsku logiku</title_bs>
      <title_hy>Մոնոտոնիկ ինֆերենսը թերբնորոշված էպիզոդիկ տրամաբանության համար</title_hy>
      <title_ca>Inferència monotònica per la Lògica Episòdica Subespecificada</title_ca>
      <title_cs>Monotonický závěr pro nespecifikovanou epizodickou logiku</title_cs>
      <title_et>Monotooniline järeldus alatäpsustatud episoodilise loogika jaoks</title_et>
      <title_fi>Monotoninen inferenssi alimääritellylle episodiselle logiikalle</title_fi>
      <title_jv>Monotonik Keterangan kanggo langgambar Episotik</title_jv>
      <title_ha>@ info: whatsthis</title_ha>
      <title_sk>Monotonična sklepanja za nedoločeno episodično logiko</title_sk>
      <title_he>Inference מונטונית ללוגית Episodic לא מוגדרת</title_he>
      <title_bo>འོག་གྲངས་དམིགས་འཛུགས་ཀྱི་ཕྱིར་གཏོང་ནུས་ཚོད་ལ་རང་ཉིད་སྒྲིག་འགོད་པ</title_bo>
      <abstract_es>Presentamos un método para hacer inferencias de lógica natural a partir de la forma lógica sin alcance de la lógica episódica. Establecemos una correspondencia entre las reglas de inferencia de la lógica episódica resuelta de alcance y el tratamiento de lógica natural de Sänchez Valencia (1991a), y por lo tanto demostramos la capacidad de manejar inferencias fundamentales de lógica natural de la literatura anterior, así como inferencias de monotonicidad anidadas más generales.</abstract_es>
      <abstract_ar>نقدم طريقة لعمل استدلالات المنطق الطبيعي من الشكل المنطقي غير المنضبط للمنطق العرضي. نحن نؤسس المراسلات بين قواعد الاستدلال الخاصة بالنطاق المنطق العرضي الذي تم حله والمعالجة المنطقية الطبيعية بواسطة Sänchez Valencia (1991a) ، وبالتالي نثبت القدرة على التعامل مع استنتاجات المنطق الطبيعي التأسيسي من الأدبيات السابقة بالإضافة إلى استنتاجات رتابة متداخلة أكثر عمومية.</abstract_ar>
      <abstract_fr>Nous présentons une méthode pour faire des inférences de logique naturelle à partir de la forme logique non scopée de la logique épisodique. Nous établissons une correspondance entre les règles d'inférence de la logique épisodique résolue par la portée et le traitement de logique naturelle de Sänchez Valencia (1991a), et démontrons ainsi la capacité de traiter les inférences fondamentales de logique naturelle tirées de la littérature antérieure ainsi que des inférences de monotonicité imbriquées plus générales.</abstract_fr>
      <abstract_pt>Apresentamos um método de fazer inferências lógicas naturais a partir da Forma Lógica Sem Escopo da Lógica Episódica. Estabelecemos uma correspondência entre as regras de inferência da Lógica Episódica resolvida de escopo e o tratamento da lógica natural por Sänchez Valencia (1991a), e, portanto, demonstramos a capacidade de lidar com inferências de lógica natural fundacional da literatura anterior, bem como inferências de monotonicidade aninhadas mais gerais.</abstract_pt>
      <abstract_ja>エピソード論理の非スコープ論理形式から自然論理推論を行う方法を提示する。我々は、解決されたエピソード論理の範囲の推論規則とSänchez Valencia （ 1991 a ）による自然論理処理との間の対応関係を確立し、従って、以前の文献からの基礎的な自然論理推論と、より一般的な入れ子の単調性推論を扱う能力を実証する。</abstract_ja>
      <abstract_zh>我们有一种从情节逻辑的无方逻辑自然逻辑推断的方法。 吾于已解之情节逻辑之理,与Sänchez Valencia(1991a)之自然逻辑立应,以证前文自然逻辑推断及更嵌套单调性推理之能。</abstract_zh>
      <abstract_hi>हम एपिसोडिक लॉजिक के अनस्कोप्ड लॉजिकल फॉर्म से प्राकृतिक तर्क अनुमान लगाने की एक विधि प्रस्तुत करते हैं। हम स्कोप के अनुमान नियमों के बीच एक पत्राचार स्थापित करते हैं जो एपिसोडिक लॉजिक और सैनचेज़ वालेंसिया (1991ए) द्वारा प्राकृतिक तर्क उपचार को हल करते हैं, और इसलिए पूर्व साहित्य से मूलभूत प्राकृतिक तर्क अनुमानों के साथ-साथ अधिक सामान्य नेस्टेड मोनोटोनिकिटी अनुमानों को संभालने की क्षमता का प्रदर्शन करते हैं।</abstract_hi>
      <abstract_ru>Предложен метод вывода естественной логики из нескопированной логической формы эпизодической логики. Мы устанавливаем соответствие между правилами вывода объема разрешенной эпизодической логики и естественным логическим режимом Sänchez Valencia (1991a) и, следовательно, демонстрируем способность обрабатывать фундаментальные естественные логические выводы из предшествующей литературы, а также более общие вложенные выводы о монотонности.</abstract_ru>
      <abstract_ga>Cuirimid i láthair modh chun tátail nádúrtha loighic a dhéanamh ó Fhoirm Loighciúil Neamhscóip na Loighic Eipeasóidigh. Bunóimid comhfhreagras idir rialacha tátail scóip Réitigh Eipeasóid Loighic agus an chóireáil loighic nádúrtha le Sänchez Valencia (1991a), agus mar sin léiriú ar an gcumas chun déileáil le tátail bhunúsacha loighic nádúrtha ón litríocht roimh ré chomh maith le tátail monotonicity neadaithe níos ginearálta.</abstract_ga>
      <abstract_ka>ჩვენ ჩვენ აჩვენებთ ნაირადი ლოგიკური ინფრენციების გამოყენება, რომელიც ეპიციოდიკური ლოგიკური ფორმიდან არ შექმნა. ჩვენ განვიყენებთ კოსპერენციის კოსპერენციის კოსპერენციის კოსპორენცია, რომელიც წარმოდგენა ეპიციოდიური ლოგიკა და სანფეზი გალენციაზე (1991a) მიერ ნახვა ლოგიკური კოსპერენცია, და ამიტომ გამოჩვენება უფრო სხვა მონოტონი</abstract_ka>
      <abstract_el>Παρουσιάζουμε μια μέθοδο για την εξαγωγή φυσικών λογικών συμπερασμάτων από την Ακατέργαστη Λογική Μορφή της Επισκοπής Λογικής. Διαπιστώνουμε μια αντιστοιχία μεταξύ των κανόνων συμπερασμάτων της επίλυσης της Επισκοπής Λογικής και της φυσικής λογικής επεξεργασίας από τον Σάντσεζ Βαλένθια (1991α), αποδεικνύοντας έτσι την ικανότητα χειρισμού θεμελιωδών συμπερασμάτων φυσικής λογικής από προηγούμενη βιβλιογραφία καθώς και γενικότερων συμπερασμάτων ένθετης μονοτονίας.</abstract_el>
      <abstract_hu>Bemutatjuk a természetes logikai következtetéseket az episzodikus logika nem fedett logikai formájából. Megállapítjuk a megoldott epizódikus logika következtetési szabályai és Sanchez Valencia természetes logikai kezelése (1991a) közötti megfelelést, és ezáltal bemutatjuk, hogy képes kezelni a korábbi irodalomból származó alapvető természetes logikai következtetéseket, valamint általánosabb beágyazott monotonitás következtetéseket.</abstract_hu>
      <abstract_it>Presentiamo un metodo per fare inferenze logiche naturali dalla Forma Logica Inscopata della Logica Episodica. Stabiliamo una corrispondenza tra regole di inferenza della logica episodica risolta e il trattamento logico naturale di Sanchez Valencia (1991a), e quindi dimostriamo la capacità di gestire inferenze logiche naturali fondamentali dalla letteratura precedente e inferenze monotoniche più generali annidate.</abstract_it>
      <abstract_kk>Біз еписодикалық логикалық логикалық түрінен табиғи логикалық инференцияларын жасау әдісін таңдаймыз. Біз сәйкестік тәртіпсіздік тәртіпсіздік тәртіпсіздігін эписодикалық логика және Санчес Валенсия (1991а) негізінде тәртіпсіздік тәртіпсіздік тәртіпсіздігін жасадық. Сондықтан бұрынғы литературасының негізінде ж</abstract_kk>
      <abstract_lt>Pateikiame metodą, kaip daryti gamtines logines išvadas iš neskopinės loginės epizodinės logikos formos. Nustatome korespondenciją tarp išvadų taikymo srities taisyklių, išspręstų Epizodinė logika, ir natūralaus logiško gydymo Sanchez Valencia (1991a), ir taip įrodome gebėjimą tvarkyti pagrindines natūralias išvadas iš ankstesnės literatūros, taip pat bendresnes nested monotonicity išvadas.</abstract_lt>
      <abstract_mk>Презентираме метод за создавање на природни логични инференции од Нескопирана логична форма на епизодична логика. Ние воспоставуваме кореспонденција помеѓу правилата за инференција на опфат решени Епизодична логика и природниот логичен третман од Санчез Валенсија (1991а), и со тоа ја демонстрираме способноста да се справат со основните природни логични инференции од претходната литература, како и поопштите инференции за</abstract_mk>
      <abstract_ml>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  സാന്‍ചെസ് വാലെന്‍സിയ (1991a) നിര്‍മ്മിക്കുന്ന ഏപിസോഡിക് ലോഗിക്കും സ്വാഭാവികമായ ലോക്കിക്കും തമ്മില്‍ നിയമങ്ങള്‍ക്കുമിടയില്‍ നമ്മള്‍ ഒരു പ്രധാനപ്പെടുത്തുന്നു. അതിനാല്‍ സ</abstract_ml>
      <abstract_ms>Kami memperkenalkan kaedah untuk membuat kesimpulan logik alami dari Bentuk Logik Tidak Diskopi Logik Episodi. Kami menetapkan persamaan antara peraturan kesimpulan skop menyelesaikan Episodic Logic dan rawatan logik alami oleh Sanchez Valencia (1991a), dan oleh itu menunjukkan kemampuan untuk menangani kesimpulan logik alami as as dari literatur terdahulu serta kesimpulan monotoniti yang lebih umum.</abstract_ms>
      <abstract_mt>Aħna nippreżentaw metodu biex nagħmlu inferenzi loġiċi naturali minn Formola Loġika Mhux Skopjata ta’ Loġika Episodika. Aħna nistabbilixxu korrispondenza bejn ir-regoli ta’ inferenza ta’ kamp ta’ applikazzjoni solvuti l-Loġika Episodika u t-trattament loġiku naturali minn Sanchez Valencia (1991a), u għalhekk nippruvaw il-ħila li nindirizzaw inferenzi loġiki naturali fundamentali mil-letteratura preċedenti kif ukoll inferenzi monotoniċi mniżżla aktar ġenerali.</abstract_mt>
      <abstract_mn>Бид байгалийн логик халдварыг эпиsodic Logic-ын логик хэлбэрээс гаргаж чадна. Бид эписодик логик болон байгалийн логик эмчилгээ (1991a) болон Санчез Валенсия (1991a) хоорондын халдварын дүрэм хоорондын харилцааны харилцааны байгалийн логик халдвар болон өмнөх уран зохиолын үүсгэлтэй байгалийн логик халдварын тухай харуулж чаддаг.</abstract_mn>
      <abstract_no>Vi presenterer ein metode for å laga naturlege logiske inferenssar frå ikkje kopla logisk form av episodisk logikk. Vi oppretter eit korrespondensjon mellom infeksjonsregular av området som er løyst av episodisk logisk og naturlig logisk behandling av Sanchez Valencia (1991a), og derfor viser det muligheten til å handtera grunnleggjande naturlege logiske infeksjonar frå førre literatur og meir generelle nesterte monotoniske infeksjonar.</abstract_no>
      <abstract_pl>Przedstawiamy metodę wykonywania wniosków logicznych naturalnych z Nieskopionej Formy Logicznej Logiki Epizodycznej. Ustalamy korespondencję między regułami zakresu rozwiązanej logiki epizodycznej a naturalnym leczeniem logiki Sancheza Walencji (1991a), a tym samym wykazujemy zdolność obsługi fundamentalnych wniosków logiki naturalnej z poprzedniej literatury oraz bardziej ogólnych wniosków monotonicznych.</abstract_pl>
      <abstract_sr>Predstavljamo metodu prirodne logičke inferencije iz neoskupljene logičke oblike episodske logike. Postavljamo dopisnost između pravila infekcije područja rešila je episodijsku logiku i prirodnu logiku liječenje Sanchez Valencijom (1991a), i zato pokazujemo sposobnost da se bavi osnovanim prirodnim logičkim infekcijama iz prethodne literature, kao i generalnim gnjezidnim monotoničnim infekcijama.</abstract_sr>
      <abstract_ro>Vă prezentăm o metodă de a face deduceri logice naturale din Forma Logică Nescoperată a Logicii Episodice. Stabilim o corespondență între regulile de inferență ale logicii episodice rezolvate și tratamentul logic natural realizat de Sanchez Valencia (1991a), demonstrând astfel capacitatea de a gestiona inferențele logicii naturale fundamentale din literatura de specialitate anterioară, precum și inferențele monotonice cuibărite mai generale.</abstract_ro>
      <abstract_si>අපි පිළිගන්නවා ප්‍රාකෘතික තාක්ෂික විද්‍යාවක් නැති විද්‍යාවක් නිර්මාණය කරන්න. අපි ස්ථාපනය කරන්න ප්‍රතිචාරයක් අතර ප්‍රතිචාරයක් අතර ප්‍රතිචාරයක් ප්‍රතිචාර කරලා Episodic Logic සහ සැන්චෙස් වැලෙන්සියා වලින් ස්වාභාවික ලොකිසික ප්‍රතිචාර</abstract_si>
      <abstract_so>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  Waxaannu dhisnaa isku xiriir u dhexeeya sharciyada cudurada dhimirka ee Episodik Logic iyo daryeelka dabiicadda ee Sanchez Valencia (1991a), kadibna waxan tusinaynaa awoodda u qabsashada cudurada asalka ah ee qoraalka hore iyo cudurada dhaqdhaqaalaha ee dhaqdhaqaaqa ah.</abstract_so>
      <abstract_ur>ہم ایک طریقہ پیش کریں گے کہ اپیسوڈیک لاجیک کی غیر اسکوپیڈ لاجیک فرم سے طبیعی لاجیک ایفارنس بنا سکیں۔ ہم نے اسکوپ کے منطقی قانون کے درمیان ایک تعلق مقرر کیا ہے جو اپی سوڈیک لاجیک اور سانچز والنسیا (1991a) کے ذریعہ منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی منطقی اور اس کے بعد</abstract_ur>
      <abstract_sv>Vi presenterar en metod för att göra naturliga logiska slutsatser från Oskopad logisk form av episodisk logik. Vi etablerar en korrespondens mellan inferensregler för räckvidd löst episodisk logik och den naturliga logikbehandlingen av Sanchez Valencia (1991a), och demonstrerar därmed förmågan att hantera grundläggande naturliga logiska slutsatser från tidigare litteratur samt mer allmänna kapslade monotonicitetsslutsatser.</abstract_sv>
      <abstract_ta>நாங்கள் இயற்கையான பாதிப்புகளை உருவாக்க ஒரு முறையை காண்பிக்கிறோம் முறைமை நாம் சான்செஸ் வாலென்சியால் தீர்மானித்துள்ள ஆயுத்த விதிகளுக்கும் இடையே ஒரு செய்தியை ஏற்படுத்துகிறோம். முன்னால் கல்வியிலிருந்து அடிப்படையான இயற்கையான நோய் நோய்</abstract_ta>
      <abstract_uz>Biz asosiy Logik formatidagi tabiiy logik kasalliklarni yaratish usulini hosil qilamiz. Biz Skopning cheksiz qoidalari va Sanchez Valencia (1991) orqali tabiiy bog'liq boshqaruvchisi bilan bir xil qoidani qo'llamiz va bizda oldingi littatlardan asosiy logik kasalliklarni boshqarish imkoniyatlarini va ko'proq umumiy qo'llangan monotonikiy kasalliklarni ko'rsatdik.</abstract_uz>
      <abstract_vi>Chúng tôi giới thiệu một phương pháp để tạo ra những suy luận logic tự nhiên từ mẫu luân lýStencils không riêng của Episodic Logic. Chúng tôi thiết lập tương ứng giữa các quy tắc hiếm có giải quyết Logic Episodic và logic tự nhiên của Sanchez Valencia (1991a) và hiển thị khả năng xử lý luận logic tự nhiên đúc từ các loại học giả cũng như ngụ ý độc tính chung.</abstract_vi>
      <abstract_bg>Представяме метод за правене на естествени логически изводи от Нескопирана логическа форма на епизодичната логика. Установяваме кореспонденция между правилата за заключения от обхвата на разрешената епизодична логика и естественото логическо третиране от Санчес Валенсия (1991а), като по този начин демонстрираме способността за справяне с фундаментални природни логически изводи от предишна литература, както и по-общи гнездени заключения за монотонност.</abstract_bg>
      <abstract_hr>Predstavljamo metodu prirodne logičke inferencije iz neoskupljene logičke oblike episodske logike. Mi smo uspostavili dopisnost između pravila infekcije područja riješena episodska logika i prirodna logička liječenja Sanchez Valencia (1991a), i stoga pokazuju sposobnost da se postigne osnovane prirodne logičke infekcije iz prethodne literature, kao i opće gnjezdane monotonične infekcije.</abstract_hr>
      <abstract_nl>We presenteren een methode voor het maken van natuurlijke logica conclusies uit Ongecopte Logische Vorm van Episodische Logica. We stellen een correspondentie vast tussen inferentieregels van scope opgeloste episodische logica en de natuurlijke logica behandeling door Sanchez Valencia (1991a), en demonstreren daarmee het vermogen om fundamentele natuurlijke logica conclusies uit eerdere literatuur en meer algemene geneste monotoniciteitsconclusies te verwerken.</abstract_nl>
      <abstract_da>Vi præsenterer en metode til at gøre naturlige logiske konklusioner fra Unskoped Logical Form of Episodic Logic. Vi etablerer en korrespondance mellem inference regler for omfang løst episodisk logik og naturlig logik behandling af Sanchez Valencia (1991a), og demonstrerer dermed evnen til at håndtere grundlæggende naturlogiske logiske konklusioner fra tidligere litteratur såvel som mere generelle indlejrede monotonicity konklusioner.</abstract_da>
      <abstract_de>Wir stellen eine Methode vor, natürliche logische Schlussfolgerungen aus der Unscoped Logical Form of Episodic Logic zu ziehen. Wir stellen eine Korrespondenz zwischen Inferenzregeln der scope aufgelösten Episodischen Logik und der natürlichen Logik Behandlung von Sanchez Valencia (1991a) her und demonstrieren damit die Fähigkeit, grundlegende naturlogische Schlussfolgerungen aus vorheriger Literatur sowie allgemeinere verschachtelte Monotonizitätsinferenzen zu handhaben.</abstract_de>
      <abstract_ko>우리는 줄거리 논리의 비범위 논리 형식에서 자연 논리 추리를 하는 방법을 제시했다.우리는 줄거리 논리를 범위적으로 분별하는 추리 규칙과 Sanchez Valencia(1991a)의 자연 논리 처리 간의 대응 관계를 구축하여 이전 문헌에서 기본적인 자연 논리 추리와 더욱 일반적인 단조로운 추리를 처리하는 능력을 증명했다.</abstract_ko>
      <abstract_id>Kami mempersembahkan metode untuk membuat kesimpulan logika alam dari bentuk logika Episodiks tanpa skop. Kami menetapkan korespondensi antara aturan inferensi dari skop memecahkan Episodic Logic dan perawatan logika alami oleh Sanchez Valencia (1991a), dan oleh itu menunjukkan kemampuan untuk menangani inferensi logika alami dasar dari literatur sebelumnya serta inferensi monotonisme yang lebih umum.</abstract_id>
      <abstract_fa>ما روش ساختن تفاوت منطقی طبیعی از شکل منطقی غیر قابل تفاوت منطقی منطقی را پیشنهاد می کنیم. ما یک ارتباط بین قوانین آلودگی منطقی و درمان منطقی طبیعی توسط سانچز والنسیا (۱۹۱a) مقرر کردیم، و به همین دلیل توانایی تحمل آلودگی منطقی طبیعی بنیادی از ادبیات قبلی و آلودگی منطقی بیشتری را نشان می دهیم.</abstract_fa>
      <abstract_sw>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  Tunaweza kuanzisha mawasiliano kati ya kanuni za uchunguzi wa vifaa vya Episodic na matibabu ya kimasilia ya Sanchez Valencia (1991a), na kwa hiyo tunaonyesha uwezo wa kukabiliana na magonjwa ya asili ya asili kutoka katika fasihi ya kabla na magonjwa ya kimapenzi yaliyosababishwa.</abstract_sw>
      <abstract_af>Ons stel 'n metode om natuurlike logiese inferensies te maak van Onkopeerde Logiese Form van Episodiese Logika. Ons stel 'n ooreenkomstigheid tussen inferensiereëls van omvang wat Episodiese Logik en die natuurlike logiese behandeling deur Sanchez Valencia (1991a) opgelos het, en daarom wys die moontlikheid om fondasionale natuurlike logiese inferensies te hanteer van voorree literaat en meer algemene gebeste monotonisiteit inferensies.</abstract_af>
      <abstract_tr>Episodiýanyň täbiň lojik hasaplaryny çykarmak üçin bir yöntemi görkezýäris. Biz sowgadyň a şyk düzgünleriniň arasynda Episodik Logik we Sanchez Valencia (1991a) tarapyndan çözüldik we munuň üçin öňki edebiýatyndan döredilmiş, tebigat lojik aşyklaryny we daşary ynsanlaryň üstüne çykyp biljekdigini görkezip tutdyk.</abstract_tr>
      <abstract_sq>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  Ne vendosim një korrespondencë midis rregullave të përfundimit të fushës zgjidhur Logike Episodike dhe trajtimit logjik natyror nga Sançez Valencia (1991a) dhe kështu demonstrojmë aftësinë për të trajtuar përfundimet themelore logjike natyrore nga letratura e mëparshme si dhe përfundimet më të përgjithshme të monotonitetit.</abstract_sq>
      <abstract_am>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  የቀድሞው ጽሑፍ፣ የኢፊስዶክን ሎጂክ እና የፍጥረታዊ ሎጂ treatment (1991) መካከል ግንኙነት እና በሳንchez Valencia (1991) እና ከዚህ በኋላ የመሠረታዊ የፍጥረታዊ የሎጂ ድካም እና አብዛኛውን የፖስቲካዊ ድካም መቆጣጠርን እና የተጨማሪውን የሞቶኒክነት ድካም ማቀናጃ እናሳየዋለን፡፡</abstract_am>
      <abstract_hy>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  Մենք ստեղծում ենք համեմատություն վերջնական գծի կանոնների միջև, որոնք լուծեցին Էպիզոդիկ Լոգիկան և բնական տրամաբանական բուժումը Սանչես Վալենսիայի (1991a) կողմից, և այսպես ցույց են տալիս, թե ինչպես կարելի է վերաբերվել նախորդ գրականության հիմնարար բնական տրամաբանական հետևանքներին,</abstract_hy>
      <abstract_bn>আমরা আনস্কোপের লজিক্যাল ফর্ম থেকে প্রাকৃতিক লোগিক আক্রান্ত বানানোর একটি পদ্ধতি উপস্থাপন করি। সাঞ্চেজ ভ্যালেন্সিয়া (১৯৯১)-এর মাধ্যমে স্কোপের অসুস্থ নিয়মের মধ্যে আমরা একটি সংবাদ প্রতিষ্ঠান স্থাপন করেছি যা পূর্বের সাহিত্য থেকে প্রাকৃতিক লোগিক আক্রান্ত এবং আরো বেশী</abstract_bn>
      <abstract_bs>Predstavljamo metodu prirodne logičke inferencije iz neoskupljene logičke oblike episodske logike. Mi smo uspostavili dopisnost između pravila infekcije područja rešili episodijsku logiku i prirodnu logiku liječenje Sanchez Valencia (1991a), i zato pokazuju sposobnost da se bavi osnovanim prirodnim logičkim inferencijama iz ranije literature, kao i općem gnjezdanim monotoničnim inferencijama.</abstract_bs>
      <abstract_ca>We present a method of making natural logic inferences from Unscoped Logical Form of Episodic Logic.  Establecem una corresponència entre les regles de inferència d'ambit resoldíem la Lògica Episòdica i el tractament lògic natural de Sanchez Valencia (1991a), i per tant demostrem l'habilitat de gestionar les inferències lògices naturals fonamentals de la literatura anterior i les inferències monotòniques més generals.</abstract_ca>
      <abstract_cs>Představujeme metodu vytváření přirozených logických závěrů z Neskopované logické formy epizodické logiky. Zjišťujeme korespondenci mezi inferenčními pravidly rozsahu řešenými epizodickou logikou a přirozenou logickou léčbou Sancheze Valencie (1991a), a proto demonstrujeme schopnost zvládnout základní přírodní logické inference z předchozí literatury a obecnější vnořené monotonické inference.</abstract_cs>
      <abstract_et>Tutvustame loogiliste järelduste tegemise meetodit episoodilise loogika koopiata loogilisest vormist. Loome vastavuse ulatuses lahendatud episoodilise loogika järeldusreeglite ja Sanchez Valencia (1991a) loogilise loogika käsitluse vahel ning näitame seega võimet käsitleda varasematest kirjandustest pärit loogilise loogika alusjäreldusi ning üldisemaid pesastatud monotoonsuse järeldusi.</abstract_et>
      <abstract_fi>Esitämme menetelmän, jolla tehdään luonnollisia logiikkajohtopäätöksiä episodisen logiikan skooppimattomasta loogisesta muodosta. Toteamme vastaavuuden episodisen logiikan ja Sanchez Valencian (1991a) luonnollisen logiikan päättelyn välillä ja siten osoitamme kykyä käsitellä aikaisemmasta kirjallisuudesta saatuja perustavanlaatuisia luonnollisia logiikkajohtopäätöksiä sekä yleisempiä sisäkkäisiä monotonisuusjohtopäätöksiä.</abstract_fi>
      <abstract_az>Biz t…ôbi…ôtli lojik inferensi Episodik lojik ≈ü…ôkilind…ôn yaratmaq ΟΦΟßΟΦn bir yolu gΟΕst…ôririk. Biz s…ôviyy…ônin episodik lojik v…ô Sanchez Valencia (1991a) t…ôbi…ôtli lojik t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôsirl…ôrinin v…ô daha genel t…ôhsil t…ôhsil t…ôhsil t…ôhsil t…ôsirl…ôrinin t…ôhsil edilm…ôsini gΟΕst…ôrdik.</abstract_az>
      <abstract_jv>Awak dhéwé éntuk sistem kanggo nggawe barang nggambar luwih apik kebuturan cara nggawe sistem logik gak nggawe barang Episotik. Awak dhéwé éntuk kesempatan ning èwèké diuwisan pangan ning aram sing beraksi Episok logik lan alam sing dohaké dhéwé basa SanChez Galentia (1997), lan kaya ngono iso nggawe nguasai kapan kuwi wis nguasai nggawe dolanan logik sing apik dhéwé, suku kedaulatan susahé awak dhéwé basa sing berarti ngono kuwi ngêwong jut perintahaa</abstract_jv>
      <abstract_ha>Tuna halatar da wata hanyoyi wa ka sami kasar da halin lojiki daga Sharin Logic na Unskopted. Tuna saɓa a tsakanin Rubuwan Nazara na Epiodic Logic da wata matsayin taratibu na Sanchez WalEncia (1991a), kuma ko da wannan, za'a nũna abincin ya yi mataimaki ga manyan mala'a na asalin tarayya daga gaban littãfi da waɗanan da aka yi ƙaranci da mala'a na kwanza.</abstract_ha>
      <abstract_sk>Predstavljamo metodo naravnih logičnih sklepov iz neoskopirane logične oblike episodične logike. Ugotavljamo korespondenco med sklepnimi pravili obsega rešene episodične logike in naravno logično obravnavo Sancheza Valencia (1991a), s čimer dokazujemo sposobnost obravnavanja temeljnih naravnih logičnih sklepov iz predhodne literature in splošnejših sklepov monotoničnosti.</abstract_sk>
      <abstract_bo>ང་ཚོས་ཕྱིར་མཐོང We establish a correspondence between inference rules of scope resolved Episodic Logic and the natural logic treatment by Sanchez Valencia (1991a), and hence demonstrate the ability to handle foundational natural logic inferences from prior literature as well as more general nested monotonicity inferences.</abstract_bo>
      <abstract_he>אנחנו מציגים שיטה להוציא תוצאות הגיונית הטבעיות מהצורה הגיונית ללא סקופ של הגיונית Episodic. אנחנו מקבלים התאמה בין חוקי ההנחה של הסקופ פתרו לוגיקה Episodic וטיפול הגיוני הטבעי על ידי סאנצ'ז ולנסיה (1991a), ולכן להוכיח את היכולת להתמודד עם ההנחות הגיוניות הטבעית הבסיסית מהספרות קודמות כמו גם ההנחות מונוטוניות קבורות יותר כלליות.</abstract_he>
      </paper>
    <paper id="7">
      <title>Bayesian Classification and Inference in a Probabilistic Type Theory with Records<fixed-case>B</fixed-case>ayesian Classification and Inference in a Probabilistic Type Theory with Records</title>
      <author><first>Staffan</first><last>Larsson</last></author>
      <author><first>Robin</first><last>Cooper</last></author>
      <pages>51–59</pages>
      <abstract>We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. We suggest probabilistic type theoretic formulations of <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes Classifiers</a> and <a href="https://en.wikipedia.org/wiki/Bayesian_network">Bayesian Networks</a>. A central element of these constructions is a type-theoretic version of a <a href="https://en.wikipedia.org/wiki/Random_variable">random variable</a>. We illustrate this account with a simple <a href="https://en.wikipedia.org/wiki/Language_game">language game</a> combining probabilistic classification of perceptual input with probabilistic (semantic) inference.</abstract>
      <url hash="6d329532">2021.naloma-1.7</url>
      <bibkey>larsson-cooper-2021-bayesian</bibkey>
    <title_ar>التصنيف والاستدلال البايزي في نظرية النوع الاحتمالي مع السجلات</title_ar>
      <title_pt>Classificação Bayesiana e Inferência em uma Teoria Probabilística de Tipos com Registros</title_pt>
      <title_fr>Classification bayésienne et inférence dans une théorie probabiliste des types avec enregistrements</title_fr>
      <title_es>Clasificación e inferencia bayesiana en una teoría de tipos probabilística con registros</title_es>
      <title_ja>記録を持つ確率的型理論におけるベイズ分類と推論</title_ja>
      <title_zh>所记概率类贝叶斯类推理</title_zh>
      <title_hi>Bayesian वर्गीकरण और अभिलेखों के साथ एक संभाव्य प्रकार सिद्धांत में अनुमान</title_hi>
      <title_ru>Байесовская классификация и вывод в вероятностной теории типа с записями</title_ru>
      <title_ga>Aicmiú agus Tátal Bayesian i dTeoiric Chineál Dóchúil le Taifid</title_ga>
      <title_ka>Name</title_ka>
      <title_el>Μπαγιεζική ταξινόμηση και συμπέρασμα σε μια πιθανή θεωρία τύπων με αρχεία</title_el>
      <title_hu>Bajeáziai osztályozás és inferencia egy valószínűsíthető típuselméletben rekordokkal</title_hu>
      <title_it>Classificazione bayesiana e inferenza in una teoria del tipo probabilistico con record</title_it>
      <title_kk>Байезия классификациясы мен маңызды түрінің теориясы</title_kk>
      <title_mk>Bayesian Classification and Inference in a Probabilistic Type Theory with Records</title_mk>
      <title_lt>Bayesian Classification and Inference in Probabilistic Type Theory with Records</title_lt>
      <title_ms>Klasifikasi dan Inferensi Bayesian dalam Teori Jenis Kemungkinan dengan Rekod</title_ms>
      <title_ml>ഒരു സാധ്യതരത്തിലുള്ള തരത്തിലുള്ള ബെയിസിയന്‍ ക്ലാസ്സിഷനും പ്രഭുവും റെക്കോര്‍ഡുകളുമായുള്ള പ്രമേയം</title_ml>
      <title_mt>Klassifikazzjoni u Inferenza Bayesian a f’Teorija tat-Tip Probabilistiku b’Rekords</title_mt>
      <title_mn>Байзийн классификаци болон хамгийн чухал төрлийн теори дээр</title_mn>
      <title_no>Name</title_no>
      <title_pl>Klasyfikacja Bayesowska i wniosek w prawdopodobnej teorii typu z rekordami</title_pl>
      <title_si>Name</title_si>
      <title_ro>Clasificarea bayeziană și inferența într-o teorie de tip probabilistic cu înregistrări</title_ro>
      <title_sr>Bayesijska klasifikacija i infekcija u verovatnoj teoriji tipa sa rekordima</title_sr>
      <title_so>Bayesian Classification and Inference in a Tiyaar Type of Probability with Records</title_so>
      <title_sv>Bayesian Klassificering och inferens i en sannolik typteori med register</title_sv>
      <title_ta>Name</title_ta>
      <title_ur>بائئسئي کلاسيفٹ اور انفارنس راکورڈ کے ساتھ شائستہ طرح تئوري میں</title_ur>
      <title_vi>KCharselect unicode block name của một số bệnh dịch</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Байезийска класификация и заключение в вероятна теория на типа с записи</title_bg>
      <title_hr>Bayesijska klasifikacija i infekcija u vjerojatnoj teoriji tipa s rekordima</title_hr>
      <title_de>Bayessche Klassifikation und Schlussfolgerung in einer probabilistischen Typentheorie mit Datensätzen</title_de>
      <title_nl>Bayesiaanse Classificatie en Inferentie in een Probabilistische Type Theorie met Records</title_nl>
      <title_da>Bayesian klassificering og inferens i en sandsynlig typeteori med poster</title_da>
      <title_id>Klasifikasi dan Inferensi Bayesian dalam Teori Tipe Kemungkinan Dengan Rekaman</title_id>
      <title_fa>تئوری نوع احتمالی با ثبت‌ها</title_fa>
      <title_ko>확률 유형 이론 중의 베일스의 분류와 추리를 기록하고 있다</title_ko>
      <title_sw>Makala na Kuingiliwa kwa Bayesia katika Tamko la a in a inayowezekana na Takwimu</title_sw>
      <title_af>Name</title_af>
      <title_tr>Kaynaklar bilen Beýezi Taýpi we Taýpi Taýpi</title_tr>
      <title_sq>Klasifikimi dhe Inferenca Bayesian në një Teori të Tipit Probabilist me Rekorde</title_sq>
      <title_am>ፋይል sን መክፈት አልቻለም፦ %s፦ %s</title_am>
      <title_hy>Բեյզիացի դասակարգումը և ինֆերենսը հավանական տեսակի տեսության մեջ</title_hy>
      <title_az>B톛diyal캼 Klasifikat v톛 캻nf톛renci Q톛rcl톛yici T칲r칲 Teoriyas캼nda</title_az>
      <title_bn>সম্ভাব্য ধরনের থিওরিতে বেয়েসিয়ান ক্লাসিকেশন এবং ইনফারেন্স</title_bn>
      <title_bs>Bayesijska klasifikacija i infekcija u teoriji mogućnosti tipa sa rekordima</title_bs>
      <title_ca>Bayesian Classification and Inference in a Probabilistic Type Theory with Records</title_ca>
      <title_cs>Bayesovská klasifikace a inference v pravděpodobné typové teorii se záznamy</title_cs>
      <title_et>Bayesi klassifikatsioon ja järeldus tõenäolise tüübi teoorias kirjetega</title_et>
      <title_fi>Bayesian luokitus ja päätelmä todennäköisessä tyyppiteoriassa tietueilla</title_fi>
      <title_jv>bayesi</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>שיעור בייזי ונפרנס בתאוריה של סוג סביר עם רשומות</title_he>
      <title_sk>Bayezijska klasifikacija in sklepanje v verjetni teoriji tipa z zapisi</title_sk>
      <title_bo>Bayesian Classification and Inference in a Probabilistic Type Theory with Records</title_bo>
      <abstract_ar>نقترح حسابًا احتماليًا للاستدلال الدلالي والتصنيف المصاغ من حيث نظرية النوع الاحتمالي مع السجلات ، بناءً على Cooper et. آل. (2014) و Cooper et. آل. (2015). نقترح الصيغ النظرية من النوع الاحتمالي لمصنفات Naive Bayes وشبكات Bayesian. العنصر المركزي في هذه التركيبات هو نسخة من النوع النظري لمتغير عشوائي. نوضح هذا الحساب بلعبة لغوية بسيطة تجمع بين التصنيف الاحتمالي للمدخلات الحسية والاستدلال الاحتمالي (الدلالي).</abstract_ar>
      <abstract_pt>Propomos uma explicação probabilística de inferência semântica e classificação formulada em termos de teoria de tipos probabilísticos com registros, com base em Cooper et. al. (2014) e Cooper et. al. (2015). Sugerimos formulações teóricas do tipo probabilísticas de Classificadores Naive Bayes e Redes Bayesianas. Um elemento central dessas construções é uma versão teórica de tipo de uma variável aleatória. Ilustramos esse relato com um jogo de linguagem simples que combina classificação probabilística de entrada perceptiva com inferência probabilística (semântica).</abstract_pt>
      <abstract_fr>Nous proposons un compte rendu probabiliste de l'inférence sémantique et de la classification formulés en termes de théorie probabiliste des types avec des enregistrements, en s'appuyant sur Cooper et al. (2014) et Cooper et al. (2015). Nous suggérons des formulations probabilistes de théorie des types de classificateurs bayésiens naïfs et de réseaux bayésiens. Un élément central de ces constructions est une version théorique de type d'une variable aléatoire. Nous illustrons ce récit par un jeu de langage simple combinant une classification probabiliste de l'entrée perceptuelle avec une inférence probabiliste (sémantique).</abstract_fr>
      <abstract_es>Proponemos un relato probabilístico de la inferencia semántica y la clasificación formulado en términos de teoría probabilística de tipos con registros, basándose en Cooper et. al. (2014) y Cooper et. al. (2015). Sugerimos formulaciones teóricas de tipo probabilístico de Naive Bayes Classifiers y Bayesian Networks. Un elemento central de estas construcciones es una versión teórica de tipos de una variable aleatoria. Ilustramos este relato con un juego de lenguaje simple que combina la clasificación probabilística de la entrada perceptual con la inferencia probabilística (semántica).</abstract_es>
      <abstract_ja>クーパーら（ 2014 ）とクーパーら（ 2015 ）に基づいて、記録を伴う確率論的型理論の観点から定式化された意味推論と分類の確率論的記述を提案する。Naive Bayes ClassifiersとBayesian Networksの確率論的型理論的定式化を提案します。これらの構築の中心的な要素は、ランダム変数の型理論的なバージョンである。我々は、知覚入力の確率的分類と確率的（意味的）推論を組み合わせた単純な言語ゲームでこの説明を例示する。</abstract_ja>
      <abstract_zh>立Cooper et之语义,推类之概率,以概率为基。 (2014)与Cooper等。 （2015）. 吾侪建素贝叶斯器贝叶斯网络之概率论公式。 其构心元素,随机变量类论版本也。 以一简言戏言之,该游戏合感知所输概率类概率(语义)推理。</abstract_zh>
      <abstract_hi>हम रिकॉर्ड के साथ संभाव्य प्रकार के सिद्धांत के संदर्भ में तैयार किए गए शब्दार्थ अनुमान और वर्गीकरण के एक संभाव्य खाते का प्रस्ताव करते हैं, जो कूपर एट पर निर्माण करता है। al. (2014) और कूपर एट। अल (2015)। हम भोले Bayes क्लासिफायर्स और Bayesian नेटवर्क के संभाव्य प्रकार सैद्धांतिक योगों का सुझाव देते हैं। इन निर्माणों का एक केंद्रीय तत्व एक यादृच्छिक चर का एक प्रकार-सैद्धांतिक संस्करण है। हम इस खाते को एक सरल भाषा खेल के साथ चित्रित करते हैं जो संभावित (शब्दार्थ) अनुमान के साथ अवधारणात्मक इनपुट के संभावित वर्गीकरण के संयोजन के साथ होता है।</abstract_hi>
      <abstract_ru>Предложен вероятностный учет семантического вывода и классификации, сформулированных в терминах вероятностной теории типов с записями, на основе Cooper et. al. (2014) и Cooper et. al. (2015). Мы предлагаем теоретические формулировки наивных классификаторов Байеса и байесовских сетей вероятностного типа. Центральным элементом этих построений является тип-теоретическая версия случайной переменной. Мы иллюстрируем этот счет простой языковой игрой, объединяющей вероятностную классификацию входного восприятия с вероятностным (семантическим) выводом.</abstract_ru>
      <abstract_ga>Molaimid cuntas dóchúlachtach ar thátal shéimeantach agus ar aicmiú arna fhoirmiú i dtéarmaí teoiric cineáil dóchúlachta le taifid, ag tógáil ar Cooper et. al. (2014) agus Cooper et. al. (2015). Molaimid foirmithe teoiriciúla de chineál probabilistic de Aicmitheoirí Naive Bayes agus Líonraí Bayesian. Gné lárnach de na tógálacha seo is ea leagan cineál-teoiriciúil d'athróg randamach. Léirímid an cuntas seo le cluiche simplí teanga a chomhcheanglaíonn aicmiú dóchúlachta an ionchuir aireachtála le tátal dóchúil (shéimeantach).</abstract_ga>
      <abstract_ka>ჩვენ გვეძლევა სემონტიკური ინფრენციის და კლასიფიკაციის შესახებ პრობილისტიკური ტიპის თეორიის შესახებ, რომელიც წიგნის შესახებ, Cooper et. al. (2014) და Cooper et. al. (2015). ჩვენ გვეყველას შესაბამისი ტიპი ტეორეტიკური ფორმაციები Naive Bayes კლასიფერების და Bayesian Networks. ამ კონფიგურაციების ცენტრალური ელემენტი არის კონფიგურაციის ტიპის ტეორეტიკური ვერსია. ჩვენ ამ წიგნის გამოსახულებას ერთადერთი ენის თამაში გამოყენებთ, რომელიც შესაბამისი კლასიფიკაციის შესაბამისი შესაბამისი შესაბამისი (semantic) ინფრენცია.</abstract_ka>
      <abstract_hu>A szemantikai következtetés és osztályozás valószínűségi beszámolóját javasoljuk, amelyet a valószínűségi típuselmélet szempontjából megfogalmaztunk rekordokkal, Cooper et al. (2014) és Cooper et al. (2015) alapján. Javasoljuk Naive Bayes Classifiers és Bayesian Networks valószínűsíthető típusú elméleti formuláit. Ezeknek a konstrukcióknak a központi eleme egy véletlenszerű változó típuselméleti változata. Ezt a beszámolót egy egyszerű nyelvi játékkal illusztráljuk, amely ötvözi az észlelési bemenet valószínűségi osztályozását és a valószínűségi (szemantikai) következtetéssel.</abstract_hu>
      <abstract_el>Προτείνουμε μια πιθανολογική καταγραφή σημασιολογικών συμπερασμάτων και ταξινόμησης που διατυπώνεται με βάση την πιθανολογική θεωρία τύπων με αρχεία, στηριζόμενη στην Κούπερ κ.α. (2014) και Κούπερ κ.α. (2015). Προτείνουμε πιθανολογικές θεωρητικές διατυπώσεις των αφελών ταξινομητών Μπάγιες και των δικτύων Μπάγιες. Κεντρικό στοιχείο αυτών των κατασκευών είναι η τυποθεωρητική έκδοση μιας τυχαίας μεταβλητής. Παρουσιάζουμε αυτή την αφήγηση με ένα απλό γλωσσικό παιχνίδι που συνδυάζει πιθανή ταξινόμηση της αντιληπτικής εισόδου με πιθανή (σημασιολογική) συμπέρασμα.</abstract_el>
      <abstract_it>Proponiamo un resoconto probabilistico dell'inferenza semantica e della classificazione formulata in termini di teoria del tipo probabilistico con record, basandosi su Cooper et. al. (2014) e Cooper et. al. (2015). Suggeriamo formulazioni teoriche di tipo probabilistico di Classificatori Naive Bayes e Reti Bayesiane. Un elemento centrale di queste costruzioni è una versione teorica del tipo di una variabile casuale. Illustriamo questo racconto con un semplice gioco linguistico che combina classificazione probabilistica dell'input percettivo con inferenza probabilistica (semantica).</abstract_it>
      <abstract_lt>We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. (2015).  Siūlome tikėtiną teorinę Naive Bayes klasifikatorių ir Bayesian tinklų formą. A central element of these constructions is a type-theoretic version of a random variable.  Mes iliustruojame šią sąskaitą paprastu kalbų žaidimu, derinančiu perceptualinio įvedimo probabilistinį klasifikavimą su probabilistine (semantine) išvada.</abstract_lt>
      <abstract_mk>We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. (2015).  Предлагаме веројатни теоретски формулации на Naive Bayes Classifiers и Bayesian Networks. Централен елемент на овие конструкции е тип-теоретска верзија на случајна променлива. We illustrate this account with a simple language game combining probabilistic classification of perceptual input with probabilistic (semantic) inference.</abstract_mk>
      <abstract_kk>Біз симантикалық инфиденциялық және классификациялық тіркелгісін жазып, Cooper т. д. (2014) және Cooper т. д. (2015). Біз Naive Bayes классификаторлары және Bayesian желінің теоретикалық түрлерінің формулацияларын ұсынамыз. Бұл құрылымдардың орталық элементі - кездейсоқ айнымалының түрі теориялық нұсқасы. Біз бұл тіркелгіні қарапайым тіл ойынымен көрсетедік. Бұл тіркелгіні қарапайым (semantic) деңгейіндегі ықтималдық келтіру үшін біріктіріп тұрады.</abstract_kk>
      <abstract_ms>Kami cadangkan akaun kemungkinan dari kesimpulan semantik dan kelasukan yang dibentuk dalam terma teori jenis kemungkinan dengan rekod, berdiri pada Cooper et al. (2014) dan Cooper et al. (2015). Kami cadangkan bentuk teori jenis kebarangkalian dari Pengarah Naive Bayes dan Rangkaian Bayesian. Unsur pusat konstruksi ini adalah versi-teori jenis pembolehubah rawak. Kami memperlihatkan akaun ini dengan permainan bahasa sederhana yang menggabungkan kelasukan kemungkinan input peraptual dengan kesimpulan kemungkinan (semantik).</abstract_ms>
      <abstract_ml>നമ്മള്‍ ഒരു സാധ്യതകള്‍ പ്രായശ്ചിത്രത്തില്‍ നിര്‍മ്മിക്കപ്പെട്ടിരിക്കുന്ന സെമാന്റിക് അപകടത്തിന്റെയും ക്ലാസ്ഫിക്കേഷനുമുള്ള അക്കൌണ്ട് പ് നമ്മള്‍ നാവ് ബെയ്സ് ക്ലാസിഫയര്‍സിന്റെയും ബെയിസ്യന്‍ നെറ്റ്വര്‍ക്കുകളുടെയും തരത്തിലുള്ള തിയോറിറ്റിക് രൂപങ് ഈ നിര്‍മ്മാണങ്ങളുടെ മദ്ധ്യ മൂലകങ്ങള്‍ ഒരു കുറിച്ചില്ലാത്ത മാറിയുള്ള തരത്തിലെ തിയോറിക്ക് പതിപ്പാ നമ്മള്‍ ഈ അക്കൗണ്ടിനെ വിശദീകരിക്കുന്നത് സാധ്യതയുള്ള (semantic) അപകടത്തോടൊപ്പം സാധ്യതയുള്ള ക്ലാസ്ഫിക്കല്‍ കൂട്ടിച്ചേര്‍ക്</abstract_ml>
      <abstract_mt>Aħna nipproponu kont probabilistiku ta’ inferenza semantika u klassifikazzjoni fformulati f’termini ta’ teorija tat-tip probabilistiku b’rekords, li jibnu fuq Cooper et. al. (2014) u Cooper et. al. (2015). Aħna ssuġġerixxu formulazzjonijiet teoretiċi tat-tip probabilistiku tal-Klassifikaturi Naive Bayes u n-Netwerks Bayesiani. Element ċentrali ta’ dawn il-kostruzzjonijiet huwa verżjoni teoretika tat-tip ta’ varjabbli aleatorja. Illustraw dan il-kont b’logħob sempliċi tal-lingwa li jgħaqqad il-klassifikazzjoni probabilistika tal-input perċettwali ma’ inferenza probabilistika (semantika).</abstract_mt>
      <abstract_mn>Бид магадлалтай төрлийн онолын хувьд бүтээгдэхүүний магадлал халдвар болон хуваарилалтын тооны санал дэвшүүлж байна. Cooper et.al. (2014) болон Cooper et.al. (2015). Бид Naive Bayes Classifiers болон Bayesian Networks-ийн магадлал төрлийн теоретикийн томъёонуудыг санал дэвшүүлнэ. Эдгээр бүтээлүүдийн төв элемент нь санамсаргүй хувьсалын төрлийн теоретик хувилбар юм. Бид энэ тоонуудыг энгийн хэл тоглоомоор харуулж, магадгүй (semantic) халдвартай ойлголтын хөрөнгө оруулалтын магадлалтай хуваалцааны хуваалцаа болгодог.</abstract_mn>
      <abstract_no>Vi foreslår eit sannsynlig konto på semantisk infeksjon og klassifikasjon formert i forhold til sannsynlige type-teorie med opptak, bygging på Cooper et. al. (2014) og Cooper et. al. (2015). Vi foreslår sannsynlige type teoretiske formlar av Naive Bayes- klassifiserar og Bayesian- nettverk. Ein sentralelement av desse konstruksjonane er ein type teoretisk versjon av ein tilfeldig variabel. Vi illustrerer denne kontoen med ein enkel språksspel som kombinerer sannsynlig klassifikasjon av oppfattig inndata med sannsynlig (semantisk) infeksjon.</abstract_no>
      <abstract_pl>Proponujemy rachunek prawdopodobieństwa wniosków semantycznych i klasyfikacji sformułowany pod kątem teorii typu probabilistycznego z zapisami, w oparciu o Cooper et. al. (2014) i Cooper et. al. (2015). Proponujemy formuły teoretyczne typu probabilistycznego Naive Bayesa Classifiers i Bayesa Networks. Centralnym elementem tych konstrukcji jest teoretyczna wersja zmiennej losowej. Ilustrujemy tę relację prostą grą językową łączącą prawdopodobną klasyfikację wejścia perceptualnego z prawdopodobnym (semantycznym) wnioskiem.</abstract_pl>
      <abstract_ro>Propunem o relatare probabilistică a inferenței semantice și clasificării formulate în termeni de teoria tipului probabilistic cu înregistrări, bazându-se pe Cooper et. al. (2014) și Cooper et. al. (2015). Sugerăm formulări teoretice de tip probabilistic ale clasificatoarelor naive Bayes și rețelelor bayesiane. Un element central al acestor construcții este o versiune teoretică de tip a unei variabile aleatorii. Ilustrăm acest cont cu un simplu joc lingvistic care combină clasificarea probabilistică a intrării perceptuale cu inferența probabilistică (semantică).</abstract_ro>
      <abstract_sr>Predlažemo verovatan račun semantičke infekcije i klasifikacije formulisanog u smislu teorije verovatnih tipa sa dosijeima, izgradnjom na Cooperu i tako dalje. (2014) i Cooperu i tako dalje. (2015). Predlažemo verovatnoj teorijskoj formaciji Naive Bayes klasifikatora i Bayesianskih mreža. Centralni element ove konstrukcije je teorijska verzija nasumične varijante tipa. Ilustriramo ovaj račun jednostavnom jezičkom igrom koja kombinuje verovatnu klasifikaciju perceptualnog ulaska sa verovatnošću (semantičnom) infekcijom.</abstract_sr>
      <abstract_so>Waxaynu soo bandhignaynaa xisaab suurtagal ah oo ku qoran kooper et. al. (2014) iyo Cooper et. al. (2015). Waxan soo jeedaynaa noocyo teoretic ah oo Naive Bayes Classifiers iyo Bayesian Network. Qaybta dhexe ee dhismahan waa nooc-theoretical version of a random variable. Waxaynu sameynaa akawnkan oo ku qoran ciyaar fudud oo ku qoran fasaxa aragtida oo suurtagal ah oo ku jirta cawinaad (semantic).</abstract_so>
      <abstract_sv>Vi föreslår en probabilistisk redogörelse för semantisk inferens och klassificering formulerad i termer av probabilistisk typteori med register, baserat på Cooper et. al. (2014) och Cooper et. al. (2015). Vi föreslår sannolikhetsteoretiska formuleringar av Naive Bayes Classifiers och Bayesian Networks. Ett centralt element i dessa konstruktioner är en typteoretisk version av en slumpvariabel. Vi illustrerar detta med ett enkelt språkspel som kombinerar sannolik klassificering av perceptuell input med sannolik (semantisk) inferens.</abstract_sv>
      <abstract_ta>நாம் ஒரு சாத்தியமான கணக்கை நினைவூட்டுகிறோம் மற்றும் வகைப்படுத்தப்பட்டுள்ளது சாத்தியமான வகையான திடீரியோவில் பதிவுகள், Cooper et. al. கட்டுதல் கூப்பர் et.  நாம் நேவ் பேய் சிறப்பாளர்கள் மற்றும் பேயிசியன் வலைப்பின்னல்களின் தியூரியல் வடிவமைப்பை பரிந்துரைக்கிறோம். இந்த கட்டமைப்பின் மையம் உறுப்பு ஒரு குறிப்பில்லாத மாறியின் வகை தியூரிக் பதிப்பு. நாம் இந்த கணக்கை எளிய மொழி விளையாட்டுடன் வெளிப்படுத்துகிறோம். பார்வையில் உள்ளீட்டின் வகைப்பாட்டை சேர்க்கும் போதும்</abstract_ta>
      <abstract_ur>ہم ایک شانس حساب کی پیشنهاد کریں گے کہ شانس طرح تئوری کے مطابق کوپر اٹ. ال. (2014) اور کوپر اٹ. ال. (2015) کی تصویر کی تصویر کی۔ ہم نے Naive Bayes Classifiers اور Bayesian Networks کے احتمالی طرح تئوریٹی فرمول کو پیش کرتا ہے. ان ساختاروں کی مرکزی عنصر ایک طرح-نظریہ ویرائل کی ایک نسخہ ہے. ہم اس حساب کو ایک ساده زبان کھیل کے ساتھ نمایش دیتے ہیں جس میں احساساتی (semantic) کفار کے ساتھ احساساتی اینپیٹ کا کلاسپیٹ کرتا ہے۔</abstract_ur>
      <abstract_si>අපි ප්‍රශ්නයක් කරනවා සැමැන්ටික් පරීක්ෂණය සහ පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා ප්‍රශ්නයක් ප්‍රශ්නයක් ප්‍රශ්නයක් තියෙනවා, කූපර් ට.  අපි කියන්නේ නේව් බේස් ක්ලාසිෆාර්ස් සහ බේසියාන් ජාලවාර්ක්ස් ගැන සාමාන්‍ය විද්‍යාත්මක විද්‍යාවය. මේ නිර්මාණයේ මධ්‍යම අවශ්‍ය තත්වයක් තර්ගයක් වෙනස් වෙනස් වර්ගයක්. අපි මේ ගිණුම සාමාන්‍ය භාෂාවක් සෙල්ලම් කරනවා සම්බන්ධ භාෂාවක් සෙල්ලම් කරනවා සම්බන්ධ විශ්වාසික විශ්වාස</abstract_si>
      <abstract_uz>Biz muvaffaqiyatli narsalar, Cooper et. al (2014) va Cooper et. al (2015) bilan birlashtirilgan semantik kasalliklarning hisobotini tahrirlash mumkin. Biz Naiv Bayes klassifierlari va Bayesiya tarmoqlari uchun teoretik turlarini talab qilamiz. Ushbu buyruqlarning markaziy element - Tasodifiy oʻzgaruvchining turi teoretik versiyasi. Biz bu hisobni oddiy tilning oʻyinlari bilan tasavvur qilamiz, ammo o o'ylab ko'rinish (semantik) o'smirligini birlashtirish mumkin.</abstract_uz>
      <abstract_vi>Chúng tôi đề nghị giải thích rõ ràng về ngụ ý và phân tích theo mức độ xác định theo lý thuyết kiểu di chúc với các hồ sơ, dựa trên Cooper et. al. (bây giờ) và Cooper et. Chúng tôi đề nghị các mô tả thuyết học về kiểu thể của Naive Bayes ngã giá và Bayisian Networks. Một yếu tố trung tâm của những công trình này là một phiên bản định lí kiểu của một biến số ngẫu nhiên. Chúng tôi mô tả tài khoản này với một trò chơi ngôn ngữ đơn giản kết hợp mức độ nhận thức theo cách chấp nhận cùng với ngụ ý xác thực.</abstract_vi>
      <abstract_bg>Предлагаме вероятностен разказ на семантичното заключение и класификация, формулиран от гледна точка на вероятностната теория на типа с записи, базиран на Купър и др. (2014) и Купър и др. (2015). Предлагаме вероятностни типови теоретични формулировки на Нейви Байс Класификатори и Байсийски мрежи. Централен елемент на тези конструкции е типова теоретична версия на случайна променлива. Ние илюстрираме този разказ с проста езикова игра, съчетаваща вероятностна класификация на възприятието вход с вероятностно (семантично) заключение.</abstract_bg>
      <abstract_nl>We stellen een probabilistisch verslag voor van semantische inferentie en classificatie geformuleerd in termen van probabilistische typetheorie met records, voortbouwend op Cooper et.al. (2014) en Cooper et.al. (2015). We stellen probabilistische type theoretische formuleringen voor van naïeve Bayes classifiers en Bayesian Networks. Een centraal element van deze constructies is een typetheoretische versie van een willekeurige variabele. We illustreren dit verhaal met een eenvoudig taalspel dat probabilistische classificatie van perceptuele input combineert met probabilistische (semantische) inferentie.</abstract_nl>
      <abstract_da>Vi foreslår en probabilistisk redegørelse for semantisk inferens og klassifikation formuleret i form af probabilistisk typeteori med optegnelser, baseret på Cooper et al. (2014) og Cooper et al. (2015). Vi foreslår probabilistiske type teoretiske formuleringer af Naive Bayes Classifiers og Bayesian Networks. Et centralt element i disse konstruktioner er en typeteoretisk version af en tilfældig variabel. Vi illustrerer denne beretning med et simpelt sprogspil, der kombinerer probabilistisk klassificering af perceptuel input med probabilistisk (semantisk) inferens.</abstract_da>
      <abstract_hr>Predlažemo vjerojatni račun semantičke infekcije i klasifikacije formuliranog u smislu teorije vjerojatnosti tipa s dosijeima, izgrađenim na Cooper et. al. (2014) i Cooper et. al. (2015). Predlažemo vjerojatnost teorijske formulacije Naive Bayes klasifikatora i Bayesianskih mreža. Centralni element ove konstrukcije je teorijska verzija tipa nasumične promjene. Ilustriramo ovaj račun jednostavnom jezičkom igrom kombinirajući vjerojatno klasifikaciju perceptualnog ulaska sa vjerojatnom (semantičnom) infekcijom.</abstract_hr>
      <abstract_de>Wir schlagen eine probabilistische Darstellung der semantischen Inferenz und Klassifizierung vor, die in Bezug auf probabilistische Typentheorie mit Datensätzen formuliert wird, basierend auf Cooper et. al. (2014) und Cooper et. al. (2015). Wir schlagen probabilistische typtheoretische Formulierungen von Naiven Bayes-Klassifizierern und Bayes-Netzwerken vor. Ein zentrales Element dieser Konstruktionen ist eine typtheoretische Version einer Zufallsvariablen. Wir illustrieren diesen Bericht mit einem einfachen Sprachspiel, das probabilistische Klassifizierung von perzeptuellen Eingaben mit probabilistischer (semantischer) Inferenz kombiniert.</abstract_de>
      <abstract_id>Kami mengusulkan sebuah rekening probabilis dari kesimpulan semantis dan klasifikasi terbentuk dalam terma teori tipe probabilis dengan catatan, berdiri pada Cooper et al. (2014) dan Cooper et al. (2015). Kami sarankan formulasi teori tipe probabilis dari Klasifikasi Naive Bayes dan Rangkaian Bayesian. Elemen pusat dari konstruksi ini adalah versi tipe-teori dari variabel acak. Kami menggambarkan rekening ini dengan permainan bahasa sederhana yang menggabungkan klasifikasi probabilis dari input persepsi dengan inferensi probabilis (semantis).</abstract_id>
      <abstract_ko>우리는 쿠퍼 등(2014)과 쿠퍼 등(2015)을 토대로 확률 유형 이론과 기록을 바탕으로 하는 의미 추리와 분류의 확률 해석을 제시했다.우리는 소박한 베일러 분류기와 베일러 네트워크의 확률 유형 이론 공식을 제시했다.이런 구조의 중심 요소는 무작위 변수의 유형 이론 버전이다.우리는 간단한 언어 게임으로 이 점을 설명한다. 이 게임은 감지 입력의 확률 분류와 확률(의미) 추리를 결합시킨다.</abstract_ko>
      <abstract_fa>ما یک حساب احتمالی از آلودگی‌های semantic و classification را پیشنهاد می‌کنیم که در نظریه‌های نوع احتمالی با ثبت‌ها، بر روی کوپر و آل. (۲۰۱۴) و کوپر و آل. (۲۰۱۵). ما پیشنهاد می‌کنیم فرمول‌های نظریه‌ی نوع احتمالاتی از کلاس‌های نایو بیز و شبکه‌های بایزی‌ها. یک عنصر مرکزی از این ساختمان نسخه‌ی نظریه‌ای از یک متغیر تصادفی است. ما این حساب را با بازی زبان ساده نمایش می‌دهیم که شامل تفریق احتمالات ورودی مشاهده می‌کند با احتمالات تفاوت (semantic) تفاوت.</abstract_fa>
      <abstract_sw>We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. (2015).  Tunapendekeza aina inayowezekana ya aina ya nadharia ya michoro ya wataalamu wa Bayes na mitandao ya Bayesia. Kitu cha katikati cha majengo haya ni toleo la aina ya nadharia ya mabadiliko yasiyo na uhakika. Tunaelezea akaunti hii kwa mchezo rahisi wa lugha ukiunganisha usambazaji wa uwezekano wa kuandika kwa mtazamo na uwezekano wa kupunguza (semantic).</abstract_sw>
      <abstract_af>Ons voorstel 'n waarskynlike rekening van semantiese inferensie en klasifikasie geformeer in terms of waarskynlike tipe teorie met opneem, bou op Cooper et. al. (2014) en Cooper et. al. (2015). Ons voorstel waarskynlik tipe teorieese formulasies van Naive Bayes Classifiers en Bayesian Netwerke. 'n Sentraal element van hierdie konstruksies is 'n tipe- teorieese weergawe van' n willekeurige veranderlike. Ons illustreer hierdie rekening met 'n eenvoudige taal speletjie wat waarskynlik klasifikasie van perceptual invoer met waarskynlik (semantiese) inferensie kombinerer.</abstract_af>
      <abstract_tr>Biz semantik hasaplanjaň we klasifikasyýanyň muhtemelen hili teoriýa ýazylýan, Cooper etkinleşeni we Cooper etkinleşeni maslahat berýäris. (2014) we Cooper etkinleşeni. Najve Bayes klassiferi we Bayesian Networks'in muhtemelen tipi teoretik formüllerini teklif ediyoruz. Bu yapıların merkezi elementi, tesadüf bir çeşitli tür teoretik sürümidir. Biz bu hasaby (semantik) senedi bir dil oýunlary bilen görkez.</abstract_tr>
      <abstract_sq>Ne propozojmë një llogari probabiliste të inferencës semantike dhe klasifikimit të formuluar në terma të teorisë së tipit probabilist me regjistrime, duke ndërtuar në Cooper et al. (2014) dhe Cooper et al. (2015). Ne sugjerojmë formulime teorike të llojit probabilist të klasifikuesve Naive Bayes dhe rrjeteve Bayesian. Një element qendror i këtyre ndërtimeve është një version lloj-teoretik i një ndryshuese të rastësishme. Ne e ilustrojmë këtë llogari me një lojë të thjeshtë gjuhësh që kombinon klasifikimin probabilistik të hyrjes perceptuale me inferencën probabilistike (semantike).</abstract_sq>
      <abstract_am>በኮፕር et. al. እና Cooper et. የነዌብ ባይስ ክላሲያዎችን እና የባይስያ ኔትርክ አካባቢዎችን እና የጥያቄ አካባቢዎችን መግለጫ እናስባለን፡፡ የእነዚህ አካባቢዎች መካከለኛ አካል - ዓይነት-theoretical version of a random variable. ይህንን አካባቢ በቋንቋ ጨዋታ እናሳውቃለን፡፡</abstract_am>
      <abstract_hy>Մենք առաջարկում ենք սեմանտիկ հետևանքների և դասակարգումների հավանական հաշվարկը, որը ձևավորված է հավանական տեսակի տեսության առումով ձայնագրությունների հետ, հիմնված Cooper et al. (2014) և Cooper et al. (2015). Մենք առաջարկում ենք հավանական տեսական տեսակի կառուցվածքներ Նայվ Բեյզ դասավորողների և Բեյզիական ցանցերի համար: Այս կառուցվածքների կենտրոնական տարրերը պատահական փոփոխականների տեսակի տեսակի տարբերակն է: Մենք ներկայացնում ենք այս հաշիվը մի պարզ լեզվային խաղով, որը համադրում է ընկալումների հավանական դասակարգումը հավանական (սեմանտիկ) եզրակացության հետ:</abstract_hy>
      <abstract_az>Biz semantik infeksiyonun və klasifikasiyanın imkansızlıq hesabını təklif edirik, mümkünlük növ teorisi ilə, Cooper et. al. (2014) və Cooper et. al. (2015). Biz Naive Bayes Klasifikləri və Bayesian Sənələrinin mümkün olaraq teorik formüllərini təbliğ edirik. Bu inşalların mərkəzi elementi rastgele variablanın türü teoriki versiyasıdır. Biz bu hesabı çox basit dil oyunu ilə göstəririk ki, bu hesabı mümkün olaraq (semantik) infeksiyonla imkansızlıq girişinin müvəffəqiyyəti ilə birləşdirir.</abstract_az>
      <abstract_bn>We propose a probabilistic account of semantic inference and classification formulated in terms of probabilistic type theory with records, building on Cooper et. al. (2014) and Cooper et. al. (2015).  আমরা প্রস্তাব করছি নাইভ বেইস ক্লাসিফার এবং বেয়েশিয়ান নেটওয়ার্কের সম্ভাব্য ধরনের ততিত্বের বৈশিষ্ট্য। এই নির্মাণের কেন্দ্রীয় উপাদান হচ্ছে একটি অদ্ভুত ভেরিয়েলের ধরনের থিওরিক সংস্করণ। আমরা এই অ্যাকাউন্টের বর্ণনা করি সাধারণ ভাষার খেলার মাধ্যমে যা দৃষ্টিভঙ্গিকার ইনপুটের সাথে সম্ভাব্য (সেমেন্টিক) অসুসংক্রা</abstract_bn>
      <abstract_bs>Predlažemo vjerojatni račun semantičke infekcije i klasifikacije formuliranog u smislu teorije mogućnosti tipa sa dosijeima, izgrađenim na Cooper et. al. (2014) i Cooper et. al. (2015). Predlažemo verovatnoj teorijskoj formaciji Naive Bayes klasifikatora i Bayesianskih mreža. Centralni element ove konstrukcije je tipovna teorijska verzija nasumične varijante. Ilustriramo ovaj račun jednostavnom jezičkom igrom koja kombinuje verovatnu klasifikaciju perceptualnog ulaska sa verovatnošću (semantičnom) infekcijom.</abstract_bs>
      <abstract_ca>Proposem un compte probabilístic de la inferència semàntica i la classificació formulat en termes de teoria del tipus probabilístic amb registres, basant-se en Cooper et al. (2014) i Cooper et al. (2015). We suggest probabilistic type theoretic formulations of Naive Bayes Classifiers and Bayesian Networks.  Un element central d'aquestes construccions és una versió teòrica del tipus d'una variable aleatòria. Illustrem aquest compte amb un joc de llenguatge senzill que combina la classificació probabilista de la entrada perceptual amb la inferència probabilista (semàntica).</abstract_ca>
      <abstract_cs>Navrhujeme pravděpodobnostní popis sémantické inference a klasifikace formulovaný z hlediska teorie pravděpodobnostních typů se záznamy, stavějící na Cooperovi et. al. (2014) a Cooperovi et. al. (2015). Navrhujeme pravděpodobnostní teoretické formulace naivních Bayesových klasifikátorů a Bayesovských sítí. Ústředním prvkem těchto konstrukcí je typově teoretická verze náhodné proměnné. Tento účet ilustrujeme jednoduchou jazykovou hrou kombinující pravděpodobnostní klasifikaci perceptuálního vstupu s pravděpodobnostní (sémantickou) inferencí.</abstract_cs>
      <abstract_et>Pakume välja tõenäolise konto semantilisest järeldusest ja klassifikatsioonist, mis on sõnastatud tõenäosusliku tüübi teoorias kirjetega, tuginedes Cooper et al. (2014) ja Cooper et. al. (2015). Me soovitame tõenäoliselt tüüpi teoreetilisi vorme Naive Bayes Classifiers ja Bayesian Networks. Nende konstruktsioonide keskseks elemendiks on juhusliku muutuja tüübi teoreetiline versioon. Me illustreerime seda kontot lihtsa keelemänguga, mis ühendab tajusisendi tõenäosusliku klassifikatsiooni tõenäosusliku (semantilise) järeldusega.</abstract_et>
      <abstract_fi>Ehdotamme todennäköistä selvitystä semanttisesta päättelystä ja luokittelusta, joka on muotoiltu probabilistisen tyyppiteorian ja tietueiden perusteella Cooper et. al. (2014) ja Cooper et. al. (2015). Ehdotamme todennäköisiä tyyppiteoreettisia formulaatioita Naive Bayes Classifiers ja Bayesian Networks. Näiden rakennelmien keskeinen elementti on satunnaismuuttujan tyyppiteoreettinen versio. Kuvaamme tätä kertomusta yksinkertaisella kielipelillä, jossa yhdistyvät havainnollisen syötteen todennäköisyysluokitus todennäköisyyteen (semanttiseen) päättelyyn.</abstract_fi>
      <abstract_jv>Awak dhéwé ngerasakno perbudalistik kuwi semanti luhuran karo kelompok nggawe barang kelompok sing ngewehke nggawe Tipe sanalistik karo akeh kayimit, gagale nggawe Mungkin et. al (2013) lan colla et. al (2013). Awak dhéwé ngerasakno perbudhakan ngerasakno perbudhakan ngerasakno anu Mbeje Baye Laptop" and "Desktop Awak dhéwé éntuk éntuk nggawe barang kelangan seneng luwih, yen nggawe barang nggawe barang seneng pisan seneng pisan praksistik (semanti)</abstract_jv>
      <abstract_he>אנו מציעים חשבון סימניסטי של ההנחה הסמנטית והקליפורציה התוכננות במונחים של תיאוריה סוג סימניסטי עם רשומות, בניין על Cooper et. al. (2014) ו Cooper et. al. (2015). We suggest probabilistic type theoretic formulations of Naive Bayes Classifiers and Bayesian Networks.  A central element of these constructions is a type-theoretic version of a random variable.  אנו מציגים את החשבון הזה עם משחק שפה פשוט שילוב סיפור סיפורי של הכניסה התפיסה עם ההנחה סיפוריסטית (סמנטית).</abstract_he>
      <abstract_ha>Munã goyyar da wani akan kafin na kasar mutane da aka samu da fasarin da aka samu da takardar littafin mai yiwuwa da aka samu karatun karãtun littafin, na ginar kan Cooper et. al. (2014) da Cooper et. al. (2015). Tuna ƙayyade probabilistic typi theoretic formulas of Naive Bayes Classifiers and Bayesian Networks. Wata ƙanshi na tsakiya daga wannan salon, shi ne wata nau'in-teoretic version of an variable da randa. Tuna bayyana wannan akan da wani game da harshe na sauƙi, mai sambawa da fassarar mai yiwuwa da ke samu'a cikin shirin ayuka na gane da mai yiwuwa (semantic) ƙaranci.</abstract_ha>
      <abstract_sk>Predlagamo verjetnostni račun semantične sklepe in klasifikacije, formuliran v smislu teorije verjetnostnih tipov z zapisi, ki temelji na Cooper et. al. (2014) in Cooper et. al. (2015). Predlagamo verjetnostne tipske teoretične formulacije Naive Bayes Classifiers in Bayesian Networks. Osrednji element teh konstrukcij je tipskoteoretična verzija naključne spremenljivke. Ta račun ponazarjamo s preprosto jezikovno igro, ki združuje verjetnostno klasifikacijo zaznavnega vnosa s verjetnostno (semantično) sklepanje.</abstract_sk>
      <abstract_bo>ང་ཚོས་semantic inference་དང་དབྱེ་རིགས་ཀྱི་རྒྱུ་རྐྱེན་གྱི་ཐོག་ལས་བྱུང་བ་སྐྱེན་གྱི་རྩིས་ཐོག་ཅིག་བཤད་ཀྱི་ཡོད། ང་ཚོས་Naive Bayes Classifiers དང་Bayesian Networks ཚོའི་ཆོས་ཉིད་ཀྱི་དབྱེ་རིགས་ལུགས་སྔོན་བསམ་བློ་གཏོང་། A central element of these constructions is a type-theoretic version of a random variable. ང་ཚོས་རྩིས་ཐོ་འདི་ལ་སྟབས་བདེ་བའི་སྐད་རིགས་ཞིག་གིས་མཐུན་རྐྱེན་བྱས་ཆོས་མཉམ་དུ་གཏོང་བ།</abstract_bo>
      </paper>
    </volume>
</collection>