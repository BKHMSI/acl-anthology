<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.textgraphs">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)</booktitle>
      <editor><first>Dmitry</first><last>Ustalov</last></editor>
      <editor><first>Swapna</first><last>Somasundaran</last></editor>
      <editor><first>Alexander</first><last>Panchenko</last></editor>
      <editor><first>Fragkiskos D.</first><last>Malliaros</last></editor>
      <editor><first>Ioana</first><last>Hulpuș</last></editor>
      <editor><first>Peter</first><last>Jansen</last></editor>
      <editor><first>Abhik</first><last>Jana</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="00d04105">2020.textgraphs-1.0</url>
      <bibkey>textgraphs-2020-graph</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A survey of embedding models of entities and relationships for knowledge graph completion</title>
      <author><first>Dat Quoc</first><last>Nguyen</last></author>
      <pages>1–14</pages>
      <abstract>Knowledge graphs (KGs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a> are typically incomplete, it is useful to perform knowledge graph completion or link prediction, i.e. predict whether a relationship not in the <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a> is likely to be true. This paper serves as a comprehensive survey of embedding models of entities and relationships for knowledge graph completion, summarizing up-to-date experimental results on standard benchmark datasets and pointing out potential future research directions.</abstract>
      <url hash="645a9fe7">2020.textgraphs-1.1</url>
      <attachment type="OptionalSupplementaryMaterial" hash="c48b2a8f">2020.textgraphs-1.1.OptionalSupplementaryMaterial.pdf</attachment>
      <bibkey>nguyen-2020-survey</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.1</doi>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k-237">FB15k-237</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nell">NELL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18rr">WN18RR</pwcdataset>
    </paper>
    <paper id="5">
      <title>Contextual BERT : Conditioning the <a href="https://en.wikipedia.org/wiki/Language_model">Language Model</a> Using a Global State<fixed-case>BERT</fixed-case>: Conditioning the Language Model Using a Global State</title>
      <author><first>Timo I.</first><last>Denk</last></author>
      <author><first>Ana</first><last>Peleteiro Ramallo</last></author>
      <pages>46–50</pages>
      <abstract>BERT is a popular <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> whose main pre-training task is to fill in the blank, i.e., predicting a word that was masked out of a sentence, based on the remaining words. In some applications, however, having an additional context can help the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> make the right prediction, e.g., by taking the domain or the time of writing into account. This motivates us to advance the BERT architecture by adding a <a href="https://en.wikipedia.org/wiki/State_(computer_science)">global state</a> for conditioning on a fixed-sized context. We present our two novel approaches and apply them to an industry use-case, where we complete fashion outfits with missing articles, conditioned on a specific customer. An experimental comparison to other <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> from the literature shows that our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> improve <a href="https://en.wikipedia.org/wiki/Personalization">personalization</a> significantly.</abstract>
      <url hash="20609025">2020.textgraphs-1.5</url>
      <bibkey>denk-peleteiro-ramallo-2020-contextual</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.5</doi>
    </paper>
    <paper id="13">
      <title>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base<fixed-case>ILP</fixed-case> Inference over Knowledge Base</title>
      <author><first>Aayushee</first><last>Gupta</last></author>
      <author><first>Gopalakrishnan</first><last>Srinivasaraghavan</last></author>
      <pages>109–114</pages>
      <abstract>Textgraphs 2020 Workshop organized a shared task on ‘Explanation Regeneration’ that required reconstructing gold explanations for elementary science questions. This work describes our submission to the task which is based on multiple components : a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. Our <a href="https://en.wikipedia.org/wiki/System">system</a> achieved a Mean Average Precision score of 0.3659.</abstract>
      <url hash="41fbef76">2020.textgraphs-1.13</url>
      <attachment type="OptionalSupplementaryMaterial" hash="20936250">2020.textgraphs-1.13.OptionalSupplementaryMaterial.pdf</attachment>
      <bibkey>gupta-srinivasaraghavan-2020-explanation</bibkey>
      <doi>10.18653/v1/2020.textgraphs-1.13</doi>
    <title_ar>تجديد التفسير عبر استدلال متعدد المراحل لـ ILP عبر قاعدة المعرفة</title_ar>
      <title_es>Explicación Regeneración mediante Inferencia de ILP de múltiples saltos sobre la base de conocimientos</title_es>
      <title_pt>Explicação Regeneração via Inferência ILP Multi-Hop sobre Base de Conhecimento</title_pt>
      <title_fr>Régénération des explications via l'inférence ILP multi-sauts via la base de connaissances</title_fr>
      <title_ja>ナレッジベース上のマルチホップILP推論による説明の再生</title_ja>
      <title_zh>因知识库多跳跃 ILP 推理复生成</title_zh>
      <title_hi>नॉलेज बेस पर मल्टी-हॉप आईएलपी अनुमान के माध्यम से स्पष्टीकरण पुनर्जनन</title_hi>
      <title_ru>Регенерация объяснения с помощью многохопового вывода ILP по сравнению с базой знаний</title_ru>
      <title_ga>Míniú Athghiniúint trí Il-Hop ILP Tátail ar Bhonn Eolais</title_ga>
      <title_ka>განახსნა რეგენერაცია Multi-Hop ILP ინფერაცია მეცნიერების ბაზაზე</title_ka>
      <title_el>Εξήγηση Αναγέννηση μέσω Συμπερασμάτων πολλαπλών Hop μέσω της Γνώσης Βάση</title_el>
      <title_hu>Magyarázat Regeneráció Multi-Hop ILP fertőzéssel a Tudásbázison keresztül</title_hu>
      <title_kk>Білім негізінен көп- хоп ILP инференциясы арқылы түсініктемелер</title_kk>
      <title_lt>Paaiškinimas Regeneracija naudojant daugiapakopę ILP informaciją apie žinias</title_lt>
      <title_it>Rigenerazione tramite inferenza ILP multi-hop su Knowledge Base</title_it>
      <title_mk>Објаснување на регенерацијата преку Мулти-Hop ILP инференција преку базата на знаење</title_mk>
      <title_ml>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base</title_ml>
      <title_ms>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base</title_ms>
      <title_mt>Spjegazzjoni Riġenerazzjoni permezz ta’ Inferenza ILP Multi-Hop fuq il-Bażi tal-Għarfien</title_mt>
      <title_mn>Мэдлэг суурь дээрх олон-Hop ILP нэр төрлийн тодорхойлолтыг дахин сэргээх</title_mn>
      <title_no>Uttrykk regenerasjon via fleirhopp ILP-inferens over kunnskapsbasen</title_no>
      <title_pl>Wyjaśnienie Regeneracja za pomocą Multi-Hop ILP Inference w bazie wiedzy</title_pl>
      <title_sr>Reģeneracija objašnjenja preko multiHop ILP Inferencije nad bazom znanja</title_sr>
      <title_ro>Explicație Regenerare prin infecția ILP Multi-Hop peste baza de cunoștințe</title_ro>
      <title_si>Multi-Hop ILP ප්‍රශ්නයක් දැනගන්න ප්‍රශ්නය</title_si>
      <title_so>Regeneration of Explanation via Multi-Hop ILP Inference over Knowledge Base</title_so>
      <title_sv>Förklaring Regenerering via Multi-Hop ILP Inferens över kunskapsbasen</title_sv>
      <title_ta>அறிவிப்பு அடிப்படையின் மேல் பல- ஹாப் ILP புகுதித்தல் மூலம் வெளியீட்டு மேலேற்றம்</title_ta>
      <title_ur>Multi-Hop ILP Inference over Knowledge Base through Explanation Regeneration</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Giải thích cấu trúc qua nhiều ngành truyền thông qua Nhà tri thức</title_vi>
      <title_hr>Objašnjenje objašnjenja putem multiHop ILP Inferencije nad bazom znanja</title_hr>
      <title_nl>Verklaring Regeneratie via Multi-Hop ILP Inference over Knowledge Base</title_nl>
      <title_da>Forklaring Regeneration via Multi-Hop ILP Inference over Knowledge Base</title_da>
      <title_bg>Обяснение Регенерация чрез мулти-хоп заключение на ILP над базата знания</title_bg>
      <title_id>Penjelasan Regenerasi melalui Multi-Hop ILP Inference over Knowledge Base</title_id>
      <title_de>Erklärung Regeneration mittels Multi-Hop ILP Inference über Knowledge Base</title_de>
      <title_tr>Multi-Hop ILP Bilim Basesynda düşündirim</title_tr>
      <title_ko>지식 라이브러리 기반의 멀티플렉스 ILP 추리의 해석 재생</title_ko>
      <title_sw>Kupitia Udhibiti wa Maelezo kupitia Udhibiti wa ILP katika Ufahamu</title_sw>
      <title_fa>توضيح بازسازي از طريق بيشتر هوپ ILP تأثير بر پايگاه دانش</title_fa>
      <title_af>Verduideling Regenerasie deur Multi-Hop ILP Inferensie oor kennis Basis</title_af>
      <title_sq>Shpjegimi Rigjenerimi nëpërmjet Inferencës Multi-Hop ILP mbi Bazën e njohurive</title_sq>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_bs>Rejeneracija objašnjenja putem multiHop ILP Inferencije nad bazom znanja</title_bs>
      <title_az>Multi-Hop ILP Inference over Knowledge Base</title_az>
      <title_hy>Հիմացության հիմքի միջոցով բազմահույս ILP ինֆերանսը բացատրելու համար</title_hy>
      <title_cs>Vysvětlení Regenerace pomocí Multi-Hop ILP Inference přes znalostní bázi</title_cs>
      <title_et>Selgitus Regeneratsioon Multi-Hop ILP järelduse kaudu teabebaasi üle</title_et>
      <title_bn>জ্ঞানের ভিত্তিতে বহুহোপ আইএলপি ইনফারেন্সের মাধ্যমে এক্সপ্লেনেশন রিজেনেশন</title_bn>
      <title_ca>La regeneració de l'explicació a través de la multiHop ILP Inferència sobre la Base de Conèixements</title_ca>
      <title_fi>Selitys Regeneraatio Multi-Hop ILP inference over Knowledge Base</title_fi>
      <title_jv>layer-mode-effects</title_jv>
      <title_sk>Razlaga Regeneracija prek Multi-Hop ILP sklepanja nad bazo znanja</title_sk>
      <title_bo>Multi-Hop ILP Inference over Knowledge Base</title_bo>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_he>מחדש ההסבר באמצעות אינפרנציה ILP Multi-Hop על בסיס ידע</title_he>
      <abstract_ar>نظمت ورشة عمل Textgraphs 2020 مهمة مشتركة حول "Explanation Regeneration" الذي تطلب إعادة بناء تفسيرات الذهب لأسئلة العلوم الأولية. يصف هذا العمل تقديمنا للمهمة التي تستند إلى مكونات متعددة: تصنيف BERT الأساسي ، وإعادة التصنيف المستند إلى البرنامج الخطي الصحيح (ILP) ونموذج الانحدار لإعادة ترتيب حقائق التفسير. حقق نظامنا متوسط درجات الدقة 0.3659.</abstract_ar>
      <abstract_es>El taller Textgraphs 2020 organizó una tarea compartida sobre «Regeneración de explicaciones» que requirió la reconstrucción de explicaciones de oro para preguntas de ciencia elemental. Este trabajo describe nuestra sumisión a la tarea, que se basa en múltiples componentes: una clasificación de referencia BERT, una nueva calificación basada en el Programa Lineal de Enteros (ILP) y un modelo de regresión para volver a clasificar los hechos explicativos. Nuestro sistema obtuvo una puntuación de Precisión Media Media de 0.3659.</abstract_es>
      <abstract_fr>L'atelier Textgraphs 2020 a organisé une tâche partagée sur la « régénération des explications » qui nécessitait de reconstruire des explications en or pour des questions de sciences élémentaires. Ce travail décrit notre soumission à la tâche qui est basée sur plusieurs composantes : un classement de base BERT, un re-scoring basé sur un programme linéaire entier (ILP) et un modèle de régression pour reclasser les faits explicatifs. Notre système a obtenu un score de précision moyenne moyenne de 0,3659.</abstract_fr>
      <abstract_pt>O Workshop Textgraphs 2020 organizou uma tarefa compartilhada sobre 'Regeneração de Explicações' que exigia a reconstrução de explicações de ouro para questões científicas elementares. Este trabalho descreve nossa submissão à tarefa que é baseada em múltiplos componentes: um ranking de linha de base do BERT, um rescoring baseado em ILP (Programa Linear Inteiro) e um modelo de regressão para reordenar os fatos explicativos. Nosso sistema alcançou uma pontuação de Precisão Média Média de 0,3659.</abstract_pt>
      <abstract_ja>テキストグラフ2020ワークショップでは、基礎科学の質問に対する金の説明の再構築を必要とする「説明の再生」に関する共有タスクを開催しました。この研究では、BERTベースラインランキング、整数線形プログラム（ ILP ）ベースの再スコアリング、および説明事実を再ランク付けするための回帰モデルという複数のコンポーネントに基づいたタスクへの提出について説明します。当社のシステムは、平均精度スコア0.3659を達成しました。</abstract_ja>
      <abstract_zh>Textgraphs 2020研讨会说再生之共同任务,重建科学金之说。 其言我于数组件之任:BERT基线之排名,基于整数线性规画(ILP)之重评分及以重名说事者归之。 统之均精,分为0.3659。</abstract_zh>
      <abstract_hi>टेक्स्टग्राफ 2020 कार्यशाला ने 'स्पष्टीकरण पुनर्जनन' पर एक साझा कार्य का आयोजन किया, जिसके लिए प्राथमिक विज्ञान के प्रश्नों के लिए सोने के स्पष्टीकरण के पुनर्निर्माण की आवश्यकता थी। यह काम उस कार्य के लिए हमारे सबमिशन का वर्णन करता है जो कई घटकों पर आधारित है: एक BERT बेसलाइन रैंकिंग, एक पूर्णांक रैखिक कार्यक्रम (ILP) आधारित पुन: स्कोरिंग और स्पष्टीकरण तथ्यों को फिर से रैंकिंग करने के लिए एक प्रतिगमन मॉडल। हमारे सिस्टम ने 0.3659 का एक औसत औसत परिशुद्धता स्कोर हासिल किया।</abstract_hi>
      <abstract_ru>Семинар Textgraphs 2020 организовал совместную задачу по «регенерации объяснений», которая потребовала реконструировать объяснения золота для вопросов элементарной науки. Эта работа описывает наше участие в задаче, которая основана на нескольких компонентах: ранжирование базовой линии BERT, пересчет на основе целочисленной линейной программы (ILP) и регрессионная модель для пересчета объясняющих фактов. Наша система достигла среднего балла прецизионности 0,3659.</abstract_ru>
      <abstract_ga>D’eagraigh Ceardlann Textgraphs 2020 tasc roinnte ar ‘Athghiniúint Mínithe’ a d’éiligh míniúcháin óir a athchruthú do cheisteanna bunúsacha eolaíochta. Déanann an obair seo cur síos ar ár n-aighneacht don tasc atá bunaithe ar ilchodanna: rangú bonnlíne BERT, athscóráil bunaithe ar Chlár Líneach Slánuimhir (ILP) agus samhail aischéimnithe chun na fíricí mínithe a athrangú. Bhain ár gcóras Meánscór beachtais de 0.3659.</abstract_ga>
      <abstract_ka>Textgraphs 2020 Workshop organised a shared task on `Explanation Regeneration' that required reconstruction of gold explanations for elementary science questions. ეს სამუშაო აღწერს ჩვენი დამუშაობა რაოდენტის დაბაზეული მრავალ კომპონტენტებზე: BERT ბაზილური რენექციის რენექცია, მუშაობელი რენექციის პროგრამი (ILP) დაბაზეული რესკორცია და რეგრესიის ნაქარა ჟთჟრვმა ეჲჟრигნალა ჟპვენარა ჟპვენარა ოპვეგთე ნა 0,3659.</abstract_ka>
      <abstract_el>Το εργαστήριο οργάνωσε ένα κοινό έργο με θέμα "Εξήγηση Αναγέννησης" που απαιτούσε την ανακατασκευή χρυσών εξηγήσεων για θέματα στοιχειώδους επιστήμης. Αυτή η εργασία περιγράφει την υποβολή μας στην εργασία η οποία βασίζεται σε πολλαπλά συστατικά: μια κατάταξη βάσης BERT, ένα ακέραιο γραμμικό πρόγραμμα (ILP) βασισμένο σε επαναβαθμολόγηση και ένα μοντέλο παλινδρόμησης για την επανακατάταξη των γεγονότων επεξήγησης. Το σύστημά μας πέτυχε μια μέση βαθμολογία ακρίβειας 0.3659.</abstract_el>
      <abstract_hu>Textgraphs 2020 Workshop egy közös feladatot szervezett "Magyarázat regeneráció" címmel, amely az alapvető tudományos kérdések arany magyarázatainak rekonstruálására volt szükség. Ez a munka több összetevőn alapuló feladatnak való benyújtásunkat ismerteti: BERT alapszint rangsorolás, ILP alapú újraértékelés és regressziós modell a magyarázat tényeinek újraértékelésére. Rendszerünk 0,3659-es átlagos pontszámot ért el.</abstract_hu>
      <abstract_it>Textgraphs 2020 Workshop ha organizzato un compito condiviso su `Spiegazione Rigenerazione' che richiedeva la ricostruzione di spiegazioni d'oro per questioni scientifiche elementari. Questo lavoro descrive la nostra sottomissione al compito che si basa su più componenti: una classifica di base BERT, un re-scoring basato su un programma lineare intero (ILP) e un modello di regressione per ri-ranking dei fatti di spiegazione. Il nostro sistema ha ottenuto un punteggio medio di precisione di 0,3659.</abstract_it>
      <abstract_kk>Текстграфикалық 2020 жұмыс істемесі бағдарламалық ғылым сұрақтарының алтын түсініктемелерін қайта құру керек 'Түсініктемелер регенерациясы' деген ортақ тапсырманы орындады. Бұл жұмыс бірнеше компоненттерге негізделген тапсырмаға жіберімізді анықтайды: BERT негізгі жолдар, толық сызық бағдарламасы (ILP) негізделген қайта сұрау мен түсініктерді қайта реттеу үшін регрессия моделі. Біздің жүйеміз 0,3659 деген орташа дәрежес нәтижесін жетті.</abstract_kk>
      <abstract_lt>„Textgraphs 2020“ seminare buvo surengta bendra užduotis „Paaiškinimo regeneracija“, pagal kurią reikėjo atkurti aukso paaiškinimus pagrindiniams mokslo klausimams. Šiame darbe apibūdinamas mūsų pristatymas uždaviniui, kuris grindžiamas keliomis sudedamosiomis dalimis: BERT pradiniu reitingu, Integralios linijinės programos (ILP) pakartotiniu reitingu ir regresijos modeliu, skirtu pakartotiniam paaiškinimo faktų reitingui. Mūsų sistema pasiekė vidutinį tikslumą 0,3659.</abstract_lt>
      <abstract_mk>Workshop Textgraphs 2020 организираше заедничка задача за „Регенерација на објаснувањето“ која бараше реконструкција на златни објаснувања за прашањата на основната наука. Оваа работа ја опишува нашата поднесувачка на задачата која се базира на повеќе компоненти: рангирање на база на БЕРТ, рерангирање на целосната линијарна програма (ИЛП) и регресен модел за рерангирање на фактите за објаснување. Нашиот систем постигна просечна точност од 0,3659.</abstract_mk>
      <abstract_ms>Kerja kerja Textgraphs 2020 mengatur tugas berkongsi pada `Explanation Regeneration' yang memerlukan pembangunan semula penjelasan emas untuk soalan sains asas. Kerja ini menggambarkan penghantaran kami ke tugas yang berdasarkan komponen berbilang: rangkaian dasar BERT, rangkaian semula berdasarkan Program Linar Integer (ILP) dan model regresi untuk rangkaian semula fakta penjelasan. Our system achieved a Mean Average Precision score of 0.3659.</abstract_ms>
      <abstract_mt>Il-Workshop tat-Teksti 2020 organizza kompitu komuni dwar “Riġenerazzjoni ta’ Spjegazzjoni” li kien jeħtieġ ir-rikostruzzjoni ta’ spjegazzjonijiet tad-deheb għal kwistjonijiet ta’ xjenza elementari. Dan ix-xogħol jiddeskrivi s-sottomissjoni tagħna għall-kompitu li huwa bbażat fuq komponenti multipli: klassifikazzjoni tal-linja bażi BERT, klassifikazzjoni mill-ġdid ibbażata fuq Programm Linjari Integri (ILP) u mudell ta’ rigressjoni għall-klassifikazzjoni mill-ġdid tal-fatti ta’ spjegazzjoni. Is-sistema tagħna kisbet punteġġ Medju ta’ Preċiżjoni ta’ 0.3659.</abstract_mt>
      <abstract_ml>എക്സ്പ്ലാനേഷന്‍ റിജെനെഷനേഷനില്‍ പങ്കാളിയുള്ള ഒരു ജോലി ഒരുക്കിവെച്ചിരിക്കുന്നു. ആദ്യത്തിലെ ശാസ്ത്ര ശാസ്ത്ര ചോദ്യങ This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts.  നമ്മുടെ സിസ്റ്റത്തിന്റെ മേനസ്ഥാനം 0.3659 പ്രിസിഷന്‍ സ്കോര്‍ എത്തി.</abstract_ml>
      <abstract_no>Textgraphs 2020 Workshop organisert ei delt oppgåve på « Explanation Regeneration », som krevst å gjenoppretta gull-forklaringar for elementære vitenskapsførsmål. Dette arbeidet beskriver vår tilføring til oppgåva som er basert på fleire komponentar: ein BERT baselinjer, ein heiltal linjerprogram (ILP) basert på omskoring og ein regresjonsmodul for å gjenoppretta utklaringsfakta. Sistemet vårt oppnådd ein gjennomsnittlig gjennomsnittlig presisjonskort på 0,3659.</abstract_no>
      <abstract_mn>Textgraphs 2020 Workshop нь үндсэн шинжлэх ухааны асуултуудад алт тайлбарыг дахин бүтээх шаардлагатай "Тодорхойлолт дахин сэргээх" талаар хуваалцааг зохион байгуулсан. Энэ ажил бидний олон компонент дээр суурилсан даалгаврыг тайлбарладаг: BERT үндсэн шугам, бүтэн шугам хөтөлбөр (ILP) дээр суурилсан дахин сүлжээ болон тайлбарлалтын үндсэн талаар дахин сүлжээний загвар. Бидний систем 0.3659 дундаж дундаж дундаж тодорхойлолт гарсан.</abstract_mn>
      <abstract_ro>Atelierul de lucru 2020 a organizat o sarcină comună privind "Regenerarea explicațiilor", care a necesitat reconstruirea explicațiilor de aur pentru întrebările științifice elementare. Această lucrare descrie prezentarea noastră la sarcina care se bazează pe mai multe componente: un clasament BERT de bază, un program liniar întreg (ILP) bazat pe re-scoring și un model de regresie pentru re-rangarea faptelor explicative. Sistemul nostru a obținut un scor de precizie medie medie de 0,3659.</abstract_ro>
      <abstract_pl>Warsztaty Textgraphs 2020 zorganizowały wspólne zadanie "Regeneracja wyjaśnień", które wymagało rekonstrukcji złotych wyjaśnień dla podstawowych pytań naukowych. W niniejszej pracy opisano naszą zgłoszenie się do zadania, które opiera się na wielu składnikach: rankingu bazowego BERT, całkowitego programu liniowego (ILP) oraz modelu regresji do ponownego rankingu faktów wyjaśniających. Nasz system osiągnął średnią średnią precyzję wyniku 0.3659.</abstract_pl>
      <abstract_sr>Textgraphs 2020 Workshop je organizovao zajednički zadatak o «Reģeneraciji objašnjenja» koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna naučna pitanja. Ovaj rad opisuje našu predanost zadatku koji je baziran na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranoj ponovno izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sistem je postigao srednju srednju tačnost od 0,3659.</abstract_sr>
      <abstract_si>textGraphs 2020වැඩසටහන් විශ්වාස ප්‍රශ්නය සඳහා සාමාන්‍ය වැඩසටහන් සැකසුම් කරලා තියෙනවා. මේ වැඩේ අපේ ප්‍රතිචාරය විස්තර කරනවා වගේම විශේෂ අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අං අපේ පද්ධතිය පරීක්ෂණය 0.3659 වෙනුවෙන් සාමාන්‍ය විශ්වාසයක් ලැබුනා.</abstract_si>
      <abstract_so>Textgraphs 2020 Workshop wuxuu qabanqaabiyey shuqul la qayb ah oo ku saabsan `Explanation Regeneration' oo u baahan yahay in loo dhiso fasirada dahab ah si ay u dhisto su'aalaha cilmiga hoose. Shaqadan wuxuu ku qoran yahay dhiigga shaqada oo ku saleysan qeybaha kala duduwan: saqafka baseline ee BERT, barnaamijka caadiga Linear (ILP) oo ku saleysan cusboonaysiinta iyo modelka dib u dhigista oo u beddelaysa arrimaha fasaxa. Systemkanagu wuxuu gaadhay qiimaha darajada hore ee 0.3659.</abstract_so>
      <abstract_sv>Textgrafer 2020 Workshop organiserade en gemensam uppgift om "Förklaring Regeneration" som krävde rekonstruktion av guldförklaringar för grundläggande vetenskapliga frågor. Detta arbete beskriver vår inlämning till uppgiften som baseras på flera komponenter: en BERT baslinje ranking, en heltalslinjär program (ILP) baserad omräkning och en regressionsmodell för omräkning av förklaringsfakta. Vårt system uppnådde en genomsnittlig precision poäng på 0,3659.</abstract_sv>
      <abstract_ta>'Explanation Regeneration' மீது ஒரு பகிர்ந்த பணியை அமைத்தது பொருள் அறிவியல் கேள்விகளுக்கான தங்கக் விளக்கங்களை மீண்டும் அமைக்க வேண்டும். இந்த வேலை பல பொருள்களை அடிப்படையில் எங்கள் பணிக்கு ஏற்றுமதி குறிப்பிடுகிறது. BERT அடிப்படைக்கோடு வரிசையில், ஒரு முழு கோடு நிரல் (ILP) அடிப்படையில் மீண்டும் மத எங்கள் அமைப்பு 0.3659 சராசரி மதிப்பு மதிப்பெண்ணை அடைந்தது.</abstract_ta>
      <abstract_ur>Textgraphs 2020 Workshop نے `Explanation Regeneration' کے بارے میں ایک مشترک کام کا سامان کیا تھا جس کے لئے سونے کی توضیح اولی سائنس سؤال کے لئے دوبارہ ساخت کرنے کی ضرورت تھی. یہ کام ہماری اطلاعات کو بہت سی قسمتوں پر بنیاد رکھتا ہے: BERT بنیاد لین رینگ، Integer Linear پروگرام (ILP) بنیاد رکھتا ہے کہ دوبارہ اسکورینگ اور واضح حقیقتوں کو دوبارہ رینگ کرنے کے لئے ریگرس موڈل ہے. ہماری سیستم نے 0.3659 کی میانہ میانہ مضبوط سطح کا امتیاز پہنچا۔</abstract_ur>
      <abstract_uz>2020 Ish stoli `Explanation Regeneration' haqida bir qanday ishni tayyorlaydi. Ilmiy savollari uchun gullni qayta o'rnatish kerak. Bu ishni bir necha komponentlar asosida yaratilgan vazifaning imkoniyatini anglatadi: BERT asosiy satr chegarasi, IP asosida qayta qiymatni qaytadan qo'yish dasturi va faqatlarni qaytadan boshlash uchun boshqarish modeli. Our system achieved a Mean Average Precision score of 0.3659.</abstract_uz>
      <abstract_vi>Văn bản 2020 Workshop đã tổ chức một nhiệm vụ chia sẻ về "Giải thích cấu trúc" cần làm lại giải thích vàng cho các câu hỏi khoa học cơ bản. Công việc này mô tả sự phục tùng của chúng ta cho nhiệm vụ dựa trên nhiều thành phần: ưu thế hoàn to àn của BERT, một chương trình dây chằng Integer (ILP) dựa vào điểm đánh giá lại và một mô hình hồi quy để xếp lại các dữ liệu giải thích. Hệ thống của chúng tôi đạt được điểm chính xác trung bình</abstract_vi>
      <abstract_bg>Текстове 2020 Семинарът организира споделена задача на тема "Обяснение за възстановяване", която изисква реконструкция на златни обяснения за елементарните научни въпроси. Тази работа описва нашето подчинение на задачата, която се основава на множество компоненти: базово класиране на базата на Цяла линейна програма (ИЛП) и регресионен модел за повторно класиране на обяснителните факти. Нашата система постигна средна прецизност от 0,3659.</abstract_bg>
      <abstract_da>Tekstgrafer 2020 Workshop organiserede en fælles opgave om `Forklaring Regeneration', der krævede rekonstruktion af guld forklaringer til elementære videnskabelige spørgsmål. Dette arbejde beskriver vores indlæg til opgaven, som er baseret på flere komponenter: en BERT-baseline ranking, en Integer Linear Program (ILP) baseret re-scoring og en regressionsmodel til re-rangering af forklaringsfakta. Vores system opnåede en gennemsnitlig præcision score på 0,3659.</abstract_da>
      <abstract_nl>Textgraphs 2020 Workshop organiseerde een gezamenlijke taak over 'Verklaring Regeneratie' die gold verklaringen voor elementaire wetenschappelijke vragen moest reconstrueren. Dit werk beschrijft onze inzending aan de taak die is gebaseerd op meerdere componenten: een BERT baseline ranking, een Integer Linear Program (ILP) gebaseerde re-score en een regressiemodel voor het opnieuw rangschikken van de verklaringsfeiten. Ons systeem behaalde een gemiddelde gemiddelde precisiescore van 0.3659.</abstract_nl>
      <abstract_hr>Textgraphs 2020 Workshop organizirao je zajednički zadatak o "Regeneraciji objašnjenja" koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna znanstvena pitanja. Ovaj rad opisuje naše podatke na zadatku koji se temelji na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranom ponovnom izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sustav je postigao srednji prosječni rezultat točnosti od 0,3659.</abstract_hr>
      <abstract_de>Textgraphs 2020 Workshop organisierte eine gemeinsame Aufgabe zum Thema "Erklärung Regeneration", die die Rekonstruktion goldener Erklärungen für elementarwissenschaftliche Fragen erforderte. Diese Arbeit beschreibt unsere Einreichung zu der Aufgabe, die auf mehreren Komponenten basiert: einem BERT Baseline Ranking, einem Integer Linear Program (ILP) basierenden Re-Scoring und einem Regressionsmodell zum Re-Ranking der Erklärungsfaktoren. Unser System erreichte eine mittlere durchschnittliche Präzision Punktzahl von 0.3659.</abstract_de>
      <abstract_id>Workshop Textgraphs 2020 mengatur tugas berbagi pada `Explanation Regeneration' yang membutuhkan rekonstruksi penjelasan emas untuk pertanyaan ilmu dasar. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts.  Sistem kita mencapai nilai Precision Utara 0,3659.</abstract_id>
      <abstract_ko>Textgraphs 2020 세미나는'해석 재생'에 대한 공유 임무를 조직해 기초 과학 문제의 황금 해석을 재건할 것을 요구했다.이 작업은 우리가 임무에 대한 제출을 묘사했다. 이 임무는 여러 가지 구성 부분을 바탕으로 한다. 하나는 버트 기선 랭킹, 하나는 정수선형 계획 (ILP) 을 바탕으로 하는 재평가, 그리고 하나는 사실을 재배열하고 해석하는 데 사용되는 회귀 모델이다.우리 시스템의 평균 정밀도는 0.3659로 나뉜다.</abstract_ko>
      <abstract_fa>کارگاه Textgraphs 2020 یک کار مشترک در مورد «توضیح بازسازی» که نیاز به بازسازی توضیح طلا برای سوالات علمی ابتدایی داشت. این کار تسلیم کردن ما به کار که بر پایه بسیاری از بخش‌های متعدد است توصیف می‌کند: صفحه پایین‌خط BERT، برنامه‌ی کلی خط‌شناسی (ILP) بر پایه‌ی بازگرداندن و مدل بازگرداندن برای بازگرداندن حقیقت توضیح‌ها. سیستم ما به یک امتیاز دقیق متوسط 0.3659 رسید.</abstract_fa>
      <abstract_sw>Warsha ya Teknolojia 2020 iliandaa kazi ya ushirikiano juu ya “Ujenzi wa Utafiti wa Maelezo” ambayo ilihitaji kujenga maelezo ya dhahabu kwa maswali ya msingi ya sayansi. Kazi hii inaelezea ujumbe wetu wa kazi inayohusiana na vipengele kadhaa: Mpango wa Ujumbe wa BERT unaoandaliwa, Mpango wa Ujumbe wa Linear (ILP) unaoanzishwa kwa upya upya na modeli wa kandamizi kwa ajili ya kutafuta ukweli wa maelezo. Mfumo wetu ulipata kiwango cha wastani cha Uheshima cha 0.3659.</abstract_sw>
      <abstract_tr>Textgraphs 2020 Workshop, elementary bilim soraglary üçin altyn düşündirimlerini täzeden guruldy. Bu işe biziň gönderişimizi birnäçe komponentlere daýan ýan zada tassyklaýar: BERT baseline derejesi, bir Integer Linear Program (ILP) ýene-küýtgetmek we düşündirilmek üçin regresije modeli. Biziň sistemamyz orta orta karanlyk 0.3659 netijesinde çykdy.</abstract_tr>
      <abstract_af>Textgraphs 2020 Workshop het 'n gedeelde taak op 'Verklaring Regenerasie' organiseer wat goud verklaring nodig het vir elementeerde wetenskap vrae herstruiker. Hierdie werk beskryf ons onderskrywing na die taak wat gebaseer is op veelvuldige komponente: 'n BERT baselyn rangering, 'n Heelgetalle Linear Program (ILP) gebaseer herskoring en 'n regresie model vir herrangering van die uitduidelingsfakte. Ons stelsel het 'n Gemiddelde Gemiddelde Gemiddelde Presisie Skaal van 0.3659 bereik.</abstract_af>
      <abstract_sq>Workshop Textgraphs 2020 organizoi një detyrë të përbashkët mbi `Shpjegimin Rigjenerim' që kërkonte rindërtimin e shpjegimeve të artë për çështjet e shkencës elementare. Ky punë përshkruan paraqitjen tonë ndaj detyrës që është bazuar në komponente të shumta: një renditje bazë BERT, një renditje bazë Integer Linear Program (ILP) dhe një model regresioni për renditjen e fakteve të shpjegimit. Sistemi ynë arriti një rezultat mesatar të saktësisë 0.3659.</abstract_sq>
      <abstract_am>የጽሑፍ ግንኙነት 2020 ሰርቨርስቲ ለጥያቄ ሳይንቀሳዊ ጥያቄዎች የወርቅ ትርጓሜዎችን በመሠረት ያስፈልጋል፡፡ ይህ ሥራ በብዛት ክፍሎች ላይ ወደሚገኘው ስራታችንን የሚያሳውቃት ነው፤ BERT መቀመጫው ደረጃ፣ የኢሌም ጉዳይ ፕሮግራም (ILP) የተመሳሳይ የኢትዮጵያ መቆጣጠር እና የግልፅ ውርይይቶችን ለመመለስ እንደተደረገ አስተካክል ሞዴል ነው፡፡ ስርዓታችን የ0.3659 ጥያቄ ነጥብ አግኝቷል፡፡</abstract_am>
      <abstract_hy>Տեքստգրաֆ 2020-ի աշխատասենյակը կազմակերպեց «Պատասխանատվության վերականգնումը» ընդհանուր խնդիր, որը պահանջեց վերականգնել ոսկու բացատրությունները տարրական գիտության հարցերի համար: Այս աշխատանքը նկարագրում է մեր ներկայացումը հանձնարարության վրա, որը հիմնված է բազմաթիվ բաղադրիչների վրա. BER-ի հիմնական դասակարգում, Ամբողջ գծային ծրագիր (ILP) հիմնված վերադասակարգում և վերադասակարգում մոդել բացատրության փաստերի վերադասակարգում: Մեր համակարգը հասավ միջին ճշգրտության 0.3659 գնահատականի:</abstract_hy>
      <abstract_az>Textgraphs 2020 Workshop, ilk elmi sualları üçün altın a çıqlamalarını yenidən inşa etmək lazım olan 'Explanation Regeneration' haqqında paylaşılan bir işi təyin etdi. Bu işlər çoxlu komponentlərə dayanan işlərə təklif etdiyimizi təsdiqləyir: BERT səviyyəsi səviyyəsi, tamamlama Linear Program ı (ILP) təkrar-scoring və a çıq-aydın faktlarını yenidən dəyişdirmək üçün regresiya modeli təsdiqləyir. Sistemimiz orta ədaləti 0.3659 dərəcəsini qəbul etdi.</abstract_az>
      <abstract_bn>টেক্সট্রাফ ২০২০ ওয়ার্ক কর্মশালা 'এক্সপ্ল্যানেশন রিজেনারেশন' নিয়ে একটি শেয়ার কর্মসূচী আয়োজন করেছে, যা পুনরায় সোনার ব্যাখ্যা প্ এই কাজ আমাদের কাজের প্রতি আমাদের আত্মসমর্পণ বর্ণনা করা হয়েছে যা বেশ কয়েকটি উপাদানের ভিত্তিতে ভিত্তিক: বিবেরেট বেসালাইন রেঙ্কিং, একটি গ্রেটার লাইনার প্রোগ আমাদের সিস্টেম মেয়াদ সংখ্যার স্কোর অর্জন করেছে ০. ৩৬৫৯।</abstract_bn>
      <abstract_bs>Textgraphs 2020 Workshop organizirao je zajednički zadatak o "Regeneraciji objašnjenja", koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna naučna pitanja. Ovaj rad opisuje naše podatke na zadatku koji se temelji na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranoj ponovno izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sistem je postigao srednju srednju tačnost od 0,3659.</abstract_bs>
      <abstract_cs>Textgraphs 2020 Workshop uspořádal společný úkol na "Vysvětlení regenerace", který vyžadoval rekonstrukci zlatých vysvětlení pro základní vědecké otázky. Tato práce popisuje naše podání k úkolu, který je založen na několika komponentách: BERT základním hodnocení, integer lineárním programu (ILP) a regresním modelu pro přehodnocení vysvětlení faktů. Náš systém dosáhl skóre střední průměrné přesnosti 0.3659.</abstract_cs>
      <abstract_ca>El taller Textgraphs 2020 va organitzar una tasca compartida sobre "Regeneració de l'Explicació" que necessitava reconstruir explicacions d'or per a preguntes de ciència elementar. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts.  El nostre sistema va aconseguir una puntuació mitjana de precisió de 0,3659.</abstract_ca>
      <abstract_et>Tekstid 2020 Töötuba korraldas ühise ülesande teemal "Selgituse taastumine", mis nõudis kuldsete selgituste rekonstrueerimist elementaarteaduse küsimustele. Käesolevas töös kirjeldatakse meie alluvust ülesandele, mis põhineb mitmel komponendil: BERT algtaseme järjestusel, täieliku lineaarse programmi (ILP) alusel põhineval ümberhindamisel ja regressioonimudel selgitavate faktide ümberhindamiseks. Meie süsteem saavutas keskmise täpsuse skoori 0,3659.</abstract_et>
      <abstract_fi>Tekstikuviot 2020 Workshop järjesti yhteisen tehtävän `Selityksen regeneroinnista', joka vaati kultaisten selitysten rekonstruointia alkeistieteellisiin kysymyksiin. Tässä työssä kuvataan tehtävään sitoutumista, joka perustuu useisiin komponentteihin: BERT-perusluokitukseen, kokonaislineaariseen ohjelmaan (ILP) perustuvaan uudelleenpisteytykseen ja regressiomalliin selittävien faktojen uudelleensijoitukseen. Järjestelmämme saavutti keskimääräisen tarkkuuden pisteen 0,3659.</abstract_fi>
      <abstract_jv>textgraphs 2020 Workspace 1 Sistem dhéwé éntuk tanggal sing perusahaan kanggo 0.246</abstract_jv>
      <abstract_sk>Besedila 2020 Delavnica je organizirala skupno nalogo ‚Razlaganje regeneracije', ki je zahtevala rekonstrukcijo zlatih razlag za osnovna znanstvena vprašanja. To delo opisuje našo predložitev nalogi, ki temelji na več komponentah: osnovni razvrstitvi BERT, ponovni oceni celotnega linearnega programa (ILP) in regresijskem modelu za ponovno razvrstitev pojasnjevalnih dejstev. Naš sistem je dosegel rezultat povprečne natančnosti 0,3659.</abstract_sk>
      <abstract_ha>Textgraphs 2020 Wannan aikin yana bayyana mĩƙa zuwa aikin da aka ƙaddara shi a kan wasu composhi: ranning basin BERT, Shirin Ayuka na Inter Linke (ILP) da aka asa shi a kan re-score kuma wata motel na haramtar da za'a sake ranar da gaskiyar fassarar. Babu'ananmu ya sami wani nau'in Narayi na gaba 0.3659.</abstract_ha>
      <abstract_he>Workshop Textgraphs 2020 ארגן משימה משותפת על "ההסבר מחדש" שדורש שיחזור ביצוע הסברים זהב לשאלות מדע יסודיים. העבודה הזו מתארת את ההעברה שלנו למשימה שמבוססת על מרובות מרכיבים: דירה בסיסית BERT, תוכנית לינרית שלמה (Integer Linear Program, ILP) מבוססת על דירה מחדש ומודל regression כדי לשדרג את העובדות ההסבר. המערכת שלנו השיגה נקודת מדויקת ממוצעת 0.3659.</abstract_he>
      <abstract_bo>Textgraphs 2020 Workshop organized a shared task on `Explanation Regeneration' that required reconstructing gold explanations for elementary science questions. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. ང་ཚོའི་མ་ལག་གིས་རྒྱ་མཚུངས་གྱི་ཚད་རྟགས་པར་ཐག་ཚད་0.3659 ཡིན།</abstract_bo>
      </paper>
    </volume>
</collection>