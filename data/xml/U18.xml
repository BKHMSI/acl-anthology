<collection id="U18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Australasian Language Technology Association Workshop 2018</booktitle>
      <url hash="d16bf8c3">U18-1</url>
      <editor><first>Sunghwan Mac</first><last>Kim</last></editor>
      <editor><first>Xiuzhen (Jenny)</first><last>Zhang</last></editor>
      <address>Dunedin, New Zealand</address>
      <month>December</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="5802d99e">U18-1000</url>
      <bibkey>alta-2018-australasian</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Improved Neural Machine Translation using Side Information</title>
      <author><first>Cong Duy Vu</first><last>Hoang</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>6&#8211;16</pages>
      <url hash="46593160">U18-1001</url>
      <abstract>In this work, we investigate whether side information is helpful in neural machine translation (NMT). We study various kinds of side information, including topical information, personal trait, then propose different ways of incorporating them into the existing NMT models. Our experimental results show the benefits of side information in improving the NMT models.</abstract>
      <bibkey>hoang-etal-2018-improved</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/pattr">PatTR</pwcdataset>
    </paper>
    <paper id="3">
      <title>Development of Natural Language Processing Tools for <fixed-case>C</fixed-case>ook <fixed-case>I</fixed-case>slands <fixed-case>M</fixed-case>&#257;ori</title>
      <author><first>Rolando Coto</first><last>Solano</last></author>
      <author><first>Sally Akevai</first><last>Nicholas</last></author>
      <author><first>Samantha</first><last>Wray</last></author>
      <pages>26&#8211;33</pages>
      <url hash="f4845959">U18-1003</url>
      <abstract>This paper presents three ongoing projects for NLP in Cook Islands Maori: Untrained Forced Alignment (approx. 9% error when detecting the center of words), speech-to-text (37% WER in the best trained models) and POS tagging (92% accuracy for the best performing model). Included as part of these projects are new resources filling in a gap in Australasian languages, including gold standard POS-tagged written corpora, transcribed speech corpora, time-aligned corpora down to the level of phonemes. These are part of efforts to accelerate the documentation of Cook Islands Maori and to increase its vitality amongst its users.</abstract>
      <bibkey>solano-etal-2018-development</bibkey>
    </paper>
    <paper id="5">
      <title>Specifying Conceptual Models Using Restricted Natural Language</title>
      <author><first>Bayzid Ashik</first><last>Hossain</last></author>
      <author><first>Rolf</first><last>Schwitter</last></author>
      <pages>44&#8211;52</pages>
      <url hash="5269a4f3">U18-1005</url>
      <abstract>The key activity to design an information system is conceptual modelling which brings out and describes the general knowledge that is required to build a system. In this paper we propose a novel approach to conceptual modelling where the domain experts will be able to specify and construct a model using a restricted form of natural language. A restricted natural language is a subset of a natural language that has well-defined computational properties and therefore can be translated unambiguously into a formal notation. We will argue that a restricted natural language is suitable for writing precise and consistent specifications that lead to executable conceptual models. Using a restricted natural language will allow the domain experts to describe a scenario in the terminology of the application domain without the need to formally encode this scenario. The resulting textual specification can then be automatically translated into the language of the desired conceptual modelling framework.</abstract>
      <bibkey>hossain-schwitter-2018-specifying</bibkey>
    </paper>
    <paper id="8">
      <title>Cluster Labeling by Word Embeddings and <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et's Hypernymy</title>
      <author><first>Hanieh</first><last>Poostchi</last></author>
      <author><first>Massimo</first><last>Piccardi</last></author>
      <pages>66&#8211;70</pages>
      <url hash="e98a71c5">U18-1008</url>
      <abstract>Cluster labeling is the assignment of representative labels to clusters obtained from the organization of a document collection. Once assigned, the labels can play an important role in applications such as navigation, search and document classification. However, finding appropriately descriptive labels is still a challenging task. In this paper, we propose various approaches for assigning labels to word clusters by leveraging word embeddings and the synonymity and hypernymy relations in the WordNet lexical ontology. Experiments carried out using the WebAP document dataset have shown that one of the approaches stand out in the comparison and is capable of selecting labels that are reasonably aligned with those chosen by a pool of four human annotators.</abstract>
      <bibkey>poostchi-piccardi-2018-cluster</bibkey>
    </paper>
    <paper id="9">
      <title>A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions</title>
      <author><first>Navnita</first><last>Nandakumar</last></author>
      <author><first>Bahar</first><last>Salehi</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>71&#8211;76</pages>
      <url hash="3d7aad37">U18-1009</url>
      <abstract>In this paper, we perform a comparative evaluation of off-the-shelf embedding models over the task of compositionality prediction of multiword expressions("MWEs"). Our experimental results suggest that character- and document-level models capture knowledge of MWE compositionality and are effective in modelling varying levels of compositionality, with the advantage over word-level models that they do not require token-level identification of MWEs in the training corpus.</abstract>
      <bibkey>nandakumar-etal-2018-comparative</bibkey>
    </paper>
    <paper id="11">
      <title>Overview of the 2018 <fixed-case>ALTA</fixed-case> Shared Task: Classifying Patent Applications</title>
      <author><first>Diego</first><last>Moll&#225;</last></author>
      <author><first>Dilesha</first><last>Seneviratne</last></author>
      <pages>84&#8211;88</pages>
      <url hash="b16206b8">U18-1011</url>
      <abstract>We present an overview of the 2018 ALTA shared task. This is the 9th of the series of shared tasks organised by ALTA since 2010. The task was to classify Australian patent classifications following the sections defined by the International Patient Classification (IPC), using data made available by IP Australia. We introduce the task, describe the data and present the results of the participating teams. Some of the participating teams outperformed state of the art.</abstract>
      <bibkey>molla-seneviratne-2018-overview</bibkey>
    </paper>
    <paper id="12">
      <title>Classifying Patent Applications with Ensemble Methods</title>
      <author><first>Fernando</first><last>Benites</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>89&#8211;92</pages>
      <url hash="fe24ec3a">U18-1012</url>
      <abstract>We present methods for the automatic classification of patent applications using an annotated dataset provided by the organizers of the ALTA 2018 shared task - Classifying Patent Applications. The goal of the task is to use computational methods to categorize patent applications according to a coarse-grained taxonomy of eight classes based on the International Patent Classification (IPC). We tested a variety of approaches for this task and the best results, 0.778 micro-averaged F1-Score, were achieved by SVM ensembles using a combination of words and characters as features. Our team, BMZ, was ranked first among 14 teams in the competition.</abstract>
      <bibkey>benites-etal-2018-classifying</bibkey>
    </paper>
    <paper id="13">
      <title>Universal Language Model Fine-tuning for Patent Classification</title>
      <author><first>Jason</first><last>Hepburn</last></author>
      <pages>93&#8211;96</pages>
      <url hash="5e044eeb">U18-1013</url>
      <abstract>This paper describes the methods used for the 2018 ALTA Shared Task. The task this year was to automatically classify Australian patents into their main International Patent Classification section. Our final submission used a Support Vector Machine (SVM) and Universal Language Model with Fine-tuning (ULMFiT). Our system achieved the best results in the student category.</abstract>
      <bibkey>hepburn-2018-universal</bibkey>
    </paper>
  </volume>
</collection>