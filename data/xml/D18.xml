<?xml version='1.0' encoding='utf-8'?>
<collection id="D18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</booktitle>
      <url hash="469db651">D18-1</url>
      <editor><first>Ellen</first><last>Riloff</last></editor>
      <editor><first>David</first><last>Chiang</last></editor>
      <editor><first>Julia</first><last>Hockenmaier</last></editor>
      <editor><first>Jun’ichi</first><last>Tsujii</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Brussels, Belgium</address>
      <month>October-November</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="cd02d92c">D18-1000</url>
      <bibkey>emnlp-2018-2018</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Adversarial Removal of Demographic Attributes from Text Data</title>
      <author><first>Yanai</first><last>Elazar</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>11–21</pages>
      <url hash="e1b6c149">D18-1002</url>
      <attachment type="attachment" hash="db553d71">D18-1002.Attachment.pdf</attachment>
      <abstract>Recent advances in <a href="https://en.wikipedia.org/wiki/Representation_learning">Representation Learning</a> and Adversarial Training seem to succeed in removing unwanted features from the learned <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a>. We show that <a href="https://en.wikipedia.org/wiki/Demography">demographic information</a> of authors is encoded inand can be recovered fromthe <a href="https://en.wikipedia.org/wiki/Intermediate_representation">intermediate representations</a> learned by text-based neural classifiers. The implication is that decisions of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> trained on textual data are not agnostic toand likely condition ondemographic attributes. When attempting to remove such demographic information using adversarial training, we find that while the adversarial component achieves chance-level development-set accuracy during training, a post-hoc classifier, trained on the encoded sentences from the first part, still manages to reach substantially higher classification accuracies on the same data. This behavior is consistent across several <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, <a href="https://en.wikipedia.org/wiki/Demography">demographic properties</a> and datasets. We explore several techniques to improve the effectiveness of the adversarial component. Our main conclusion is a cautionary one : do not rely on the adversarial training to achieve invariant representation to sensitive features.</abstract>
      <video href="https://vimeo.com/305203150" />
      <doi>10.18653/v1/D18-1002</doi>
      <bibkey>elazar-goldberg-2018-adversarial</bibkey>
      <pwccode url="https://github.com/yanaiela/demog-text-removal" additional="false">yanaiela/demog-text-removal</pwccode>
    </paper>
    <paper id="3">
      <title>DeClarE : Debunking Fake News and False Claims using Evidence-Aware Deep Learning<fixed-case>D</fixed-case>e<fixed-case>C</fixed-case>lar<fixed-case>E</fixed-case>: Debunking Fake News and False Claims using Evidence-Aware Deep Learning</title>
      <author><first>Kashyap</first><last>Popat</last></author>
      <author><first>Subhabrata</first><last>Mukherjee</last></author>
      <author><first>Andrew</first><last>Yates</last></author>
      <author><first>Gerhard</first><last>Weikum</last></author>
      <pages>22–32</pages>
      <url hash="3f9b060d">D18-1003</url>
      <abstract>Misinformation such as <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> is one of the big challenges of our society. Research on automated fact-checking has proposed methods based on <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deficit by considering <a href="https://en.wikipedia.org/wiki/Source_text">external sources</a> related to a claim. However, these <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> require substantial <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">feature modeling</a> and rich lexicons. This paper overcomes these limitations of prior work with an end-to-end model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Experiments with four datasets and ablation studies show the strength of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a>.</abstract>
      <video href="https://vimeo.com/305203523" />
      <doi>10.18653/v1/D18-1003</doi>
      <bibkey>popat-etal-2018-declare</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="5">
      <title>Detecting Gang-Involved Escalation on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> Using Context</title>
      <author><first>Serina</first><last>Chang</last></author>
      <author><first>Ruiqi</first><last>Zhong</last></author>
      <author><first>Ethan</first><last>Adams</last></author>
      <author><first>Fei-Tzin</first><last>Lee</last></author>
      <author><first>Siddharth</first><last>Varia</last></author>
      <author><first>Desmond</first><last>Patton</last></author>
      <author><first>William</first><last>Frey</last></author>
      <author><first>Chris</first><last>Kedzie</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>46–56</pages>
      <url hash="d9a88bc9">D18-1005</url>
      <attachment type="attachment" hash="75559092">D18-1005.Attachment.zip</attachment>
      <abstract>Gang-involved youth in cities such as Chicago have increasingly turned to <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> to post about their experiences and intents online. In some situations, when they experience the loss of a loved one, their online expression of emotion may evolve into aggression towards rival gangs and ultimately into real-world violence. In this paper, we present a novel <a href="https://en.wikipedia.org/wiki/System">system</a> for detecting Aggression and Loss in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. Our system features the use of domain-specific resources automatically derived from a large unlabeled corpus, and contextual representations of the emotional and semantic content of the user’s recent tweets as well as their interactions with other users. Incorporating <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> in our Convolutional Neural Network (CNN) leads to a significant improvement.</abstract>
      <video href="https://vimeo.com/305204297" />
      <doi>10.18653/v1/D18-1005</doi>
      <bibkey>chang-etal-2018-detecting</bibkey>
      <pwccode url="https://github.com/serinachang5/contextifier" additional="false">serinachang5/contextifier</pwccode>
    </paper>
    <paper id="6">
      <title>Reasoning about Actions and State Changes by Injecting Commonsense Knowledge</title>
      <author><first>Niket</first><last>Tandon</last></author>
      <author><first>Bhavana</first><last>Dalvi</last></author>
      <author><first>Joel</first><last>Grus</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Antoine</first><last>Bosselut</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <pages>57–66</pages>
      <url hash="62106735">D18-1006</url>
      <abstract>Comprehending procedural text, e.g., a paragraph describing photosynthesis, requires modeling actions and the state changes they produce, so that questions about entities at different timepoints can be answered. Although several recent systems have shown impressive progress in this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, their predictions can be globally inconsistent or highly improbable. In this paper, we show how the predicted effects of actions in the context of a paragraph can be improved in two ways : (1) by incorporating global, commonsense constraints (e.g., a non-existent entity can not be destroyed), and (2) by biasing reading with preferences from large-scale corpora (e.g., trees rarely move). Unlike earlier methods, we treat the problem as a neural structured prediction task, allowing <a href="https://en.wikipedia.org/wiki/Constraint_(mathematics)">hard and soft constraints</a> to steer the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> away from unlikely predictions. We show that the new model significantly outperforms earlier <a href="https://en.wikipedia.org/wiki/System">systems</a> on a benchmark dataset for procedural text comprehension (+8 % relative gain), and that it also avoids some of the nonsensical predictions that earlier systems make.</abstract>
      <video href="https://vimeo.com/305193585" />
      <doi>10.18653/v1/D18-1006</doi>
      <bibkey>tandon-etal-2018-reasoning</bibkey>
      <pwccode url="https://github.com/allenai/propara" additional="false">allenai/propara</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/propara">ProPara</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="7">
      <title>Collecting Diverse Natural Language Inference Problems for Sentence Representation Evaluation</title>
      <author><first>Adam</first><last>Poliak</last></author>
      <author><first>Aparajita</first><last>Haldar</last></author>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <author><first>J. Edward</first><last>Hu</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <author><first>Aaron Steven</first><last>White</last></author>
      <author><first>Benjamin</first><last>Van Durme</last></author>
      <pages>67–81</pages>
      <url hash="d3fb53d6">D18-1007</url>
      <abstract>We present a large-scale collection of diverse natural language inference (NLI) datasets that help provide insight into how well a sentence representation captures distinct types of <a href="https://en.wikipedia.org/wiki/Reason">reasoning</a>. The collection results from recasting 13 existing datasets from 7 semantic phenomena into a common NLI structure, resulting in over half a million labeled context-hypothesis pairs in total. We refer to our <a href="https://en.wikipedia.org/wiki/Collection_(artwork)">collection</a> as the DNC : Diverse Natural Language Inference Collection. The DNC is available online at, and will grow over time as additional resources are recast and added from novel sources.<url>https://www.decomp.net</url>, and will grow over time as additional resources are recast and added from novel sources.</abstract>
      <video href="https://vimeo.com/305194062" />
      <doi>10.18653/v1/D18-1007</doi>
      <bibkey>poliak-etal-2018-collecting</bibkey>
    </paper>
    <paper id="9">
      <title>SWAG : A Large-Scale Adversarial Dataset for Grounded Commonsense Inference<fixed-case>SWAG</fixed-case>: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference</title>
      <author><first>Rowan</first><last>Zellers</last></author>
      <author><first>Yonatan</first><last>Bisk</last></author>
      <author><first>Roy</first><last>Schwartz</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>93–104</pages>
      <url hash="79779610">D18-1009</url>
      <attachment type="attachment" hash="4222a586">D18-1009.Attachment.zip</attachment>
      <abstract>Given a partial description like she opened the hood of the car, humans can reason about the situation and anticipate what might come next (then, she examined the engine). In this paper, we introduce the task of grounded commonsense inference, unifying <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language inference</a> and <a href="https://en.wikipedia.org/wiki/Commonsense_reasoning">commonsense reasoning</a>. We present SWAG, a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-the-art language models to massively oversample a diverse set of potential <a href="https://en.wikipedia.org/wiki/Counterfactual_conditional">counterfactuals</a>. Empirical results demonstrate that while humans can solve the resulting inference problems with high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> (88 %), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.</abstract>
      <video href="https://vimeo.com/305195438" />
      <doi>10.18653/v1/D18-1009</doi>
      <bibkey>zellers-etal-2018-swag</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/swag">SWAG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/activitynet">ActivityNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/activitynet-captions">ActivityNet Captions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/copa">COPA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-madlibs">Visual Madlibs</pwcdataset>
    </paper>
    <paper id="11">
      <title>Associative Multichannel Autoencoder for Multimodal Word Representation</title>
      <author><first>Shaonan</first><last>Wang</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>115–124</pages>
      <url hash="0dbd5914">D18-1011</url>
      <abstract>In this paper we address the problem of learning multimodal word representations by integrating textual, visual and auditory inputs. Inspired by the re-constructive and associative nature of human memory, we propose a novel associative multichannel autoencoder (AMA). Our model first learns the associations between textual and perceptual modalities, so as to predict the missing perceptual information of concepts. Then the textual and predicted perceptual representations are fused through reconstructing their original and associated embeddings. Using a gating mechanism our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> assigns different weights to each modality according to the different concepts. Results on six benchmark concept similarity tests show that the proposed method significantly outperforms strong unimodal baselines and state-of-the-art multimodal models.</abstract>
      <video href="https://vimeo.com/305209813" />
      <doi>10.18653/v1/D18-1011</doi>
      <bibkey>wang-etal-2018-associative</bibkey>
      <pwccode url="https://github.com/wangshaonan/Associative-multichannel-autoencoder" additional="false">wangshaonan/Associative-multichannel-autoencoder</pwccode>
    </paper>
    <paper id="14">
      <title>Multimodal Language Analysis with Recurrent Multistage Fusion</title>
      <author><first>Paul Pu</first><last>Liang</last></author>
      <author><first>Ziyin</first><last>Liu</last></author>
      <author><first>AmirAli</first><last>Bagher Zadeh</last></author>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <pages>150–161</pages>
      <url hash="390fc1c4">D18-1014</url>
      <attachment type="attachment" hash="62c92e38">D18-1014.Attachment.zip</attachment>
      <abstract>Computational modeling of human multimodal language is an emerging research area in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> spanning the <a href="https://en.wikipedia.org/wiki/Language">language</a>, visual and acoustic modalities. Comprehending multimodal language requires modeling not only the interactions within each modality (intra-modal interactions) but more importantly the interactions between modalities (cross-modal interactions). In this paper, we propose the Recurrent Multistage Fusion Network (RMFN) which decomposes the fusion problem into multiple stages, each of them focused on a subset of multimodal signals for specialized, effective fusion. Cross-modal interactions are modeled using this multistage fusion approach which builds upon intermediate representations of previous stages. Temporal and intra-modal interactions are modeled by integrating our proposed fusion approach with a system of recurrent neural networks. The RMFN displays state-of-the-art performance in modeling human multimodal language across three public datasets relating to multimodal sentiment analysis, <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition</a>, and speaker traits recognition. We provide visualizations to show that each stage of fusion focuses on a different subset of multimodal signals, learning increasingly discriminative multimodal representations.</abstract>
      <video href="https://vimeo.com/305210831" />
      <doi>10.18653/v1/D18-1014</doi>
      <bibkey>liang-etal-2018-multimodal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
    </paper>
    <paper id="16">
      <title>PreCo : A Large-scale Dataset in Preschool Vocabulary for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">Coreference Resolution</a><fixed-case>P</fixed-case>re<fixed-case>C</fixed-case>o: A Large-scale Dataset in Preschool Vocabulary for Coreference Resolution</title>
      <author><first>Hong</first><last>Chen</last></author>
      <author><first>Zhenhua</first><last>Fan</last></author>
      <author><first>Hao</first><last>Lu</last></author>
      <author><first>Alan</first><last>Yuille</last></author>
      <author><first>Shu</first><last>Rong</last></author>
      <pages>172–181</pages>
      <url hash="87cd619d">D18-1016</url>
      <abstract>We introduce PreCo, a large-scale English dataset for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>. The dataset is designed to embody the core challenges in <a href="https://en.wikipedia.org/wiki/Coreference">coreference</a>, such as <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity representation</a>, by alleviating the challenge of low overlap between training and test sets and enabling separated analysis of mention detection and mention clustering. To strengthen the training-test overlap, we collect a large corpus of 38 K documents and 12.5 M words which are mostly from the vocabulary of English-speaking preschoolers. Experiments show that with higher training-test overlap, error analysis on PreCo is more efficient than the one on OntoNotes, a popular existing dataset. Furthermore, we annotate singleton mentions making it possible for the first time to quantify the influence that a mention detector makes on <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a> performance. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> is freely available at.<url>https://preschool-lab.github.io/PreCo/</url>.</abstract>
      <video href="https://vimeo.com/306353798" />
      <doi>10.18653/v1/D18-1016</doi>
      <bibkey>chen-etal-2018-preco</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/preco">PreCo</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="17">
      <title>Adversarial Transfer Learning for Chinese Named Entity Recognition with Self-Attention Mechanism<fixed-case>C</fixed-case>hinese Named Entity Recognition with Self-Attention Mechanism</title>
      <author><first>Pengfei</first><last>Cao</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Shengping</first><last>Liu</last></author>
      <pages>182–192</pages>
      <url hash="ed3cfde0">D18-1017</url>
      <abstract>Named entity recognition (NER) is an important task in natural language processing area, which needs to determine entities boundaries and classify them into pre-defined categories. For Chinese NER task, there is only a very small amount of annotated data available. Chinese NER task and Chinese word segmentation (CWS) task have many similar word boundaries. There are also specificities in each <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. However, existing methods for Chinese NER either do not exploit word boundary information from CWS or can not filter the specific information of CWS. In this paper, we propose a novel adversarial transfer learning framework to make full use of task-shared boundaries information and prevent the task-specific features of CWS. Besides, since arbitrary character can provide important cues when predicting entity type, we exploit self-attention to explicitly capture long range dependencies between two tokens. Experimental results on two different widely used datasets show that our proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly and consistently outperforms other state-of-the-art methods.</abstract>
      <video href="https://vimeo.com/306354811" />
      <doi>10.18653/v1/D18-1017</doi>
      <bibkey>cao-etal-2018-adversarial</bibkey>
      <pwccode url="https://github.com/CPF-NLPR/AT4ChineseNER" additional="false">CPF-NLPR/AT4ChineseNER</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/weibo-ner">Weibo NER</pwcdataset>
    </paper>
    <paper id="18">
      <title>Using <a href="https://en.wikipedia.org/wiki/Linguistic_feature">Linguistic Features</a> to Improve the Generalization Capability of Neural Coreference Resolvers</title>
      <author><first>Nafise Sadat</first><last>Moosavi</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>193–203</pages>
      <url hash="06e1286a">D18-1018</url>
      <attachment type="attachment" hash="5c53b62c">D18-1018.Attachment.pdf</attachment>
      <abstract>Coreference resolution is an intermediate step for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">text understanding</a>. It is used in tasks and domains for which we do not necessarily have coreference annotated corpora. Therefore, <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> is of special importance for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>. However, while recent coreference resolvers have notable improvements on the CoNLL dataset, they struggle to generalize properly to new domains or datasets. In this paper, we investigate the role of <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a> in building more generalizable coreference resolvers. We show that <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> improves only slightly by merely using a set of additional <a href="https://en.wikipedia.org/wiki/Feature_(linguistics)">linguistic features</a>. However, employing <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> and subsets of their values that are informative for <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>, considerably improves <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a>. Thanks to better <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a>, our <a href="https://en.wikipedia.org/wiki/System">system</a> achieves state-of-the-art results in out-of-domain evaluations, e.g., on WikiCoref, our <a href="https://en.wikipedia.org/wiki/System">system</a>, which is trained on CoNLL, achieves on-par performance with a <a href="https://en.wikipedia.org/wiki/System">system</a> designed for this dataset.</abstract>
      <video href="https://vimeo.com/306355512" />
      <doi>10.18653/v1/D18-1018</doi>
      <bibkey>moosavi-strube-2018-using</bibkey>
      <pwccode url="https://github.com/ns-moosavi/epm" additional="false">ns-moosavi/epm</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikicoref">WikiCoref</pwcdataset>
    </paper>
    <paper id="21">
      <title>Joint Representation Learning of Cross-lingual Words and Entities via Attentive Distant Supervision</title>
      <author><first>Yixin</first><last>Cao</last></author>
      <author><first>Lei</first><last>Hou</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Chengjiang</first><last>Li</last></author>
      <author><first>Xu</first><last>Chen</last></author>
      <author><first>Tiansi</first><last>Dong</last></author>
      <pages>227–237</pages>
      <url hash="d84ed3fd">D18-1021</url>
      <abstract>Jointly representation learning of words and entities benefits many NLP tasks, but has not been well explored in cross-lingual settings. In this paper, we propose a novel method for joint representation learning of cross-lingual words and entities. It captures mutually complementary knowledge, and enables cross-lingual inferences among <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge bases</a> and texts. Our method does not require <a href="https://en.wikipedia.org/wiki/Parallel_corpus">parallel corpus</a>, and automatically generates comparable data via distant supervision using <a href="https://en.wikipedia.org/wiki/Multilingualism">multi-lingual knowledge bases</a>. We utilize two types of regularizers to align cross-lingual words and entities, and design knowledge attention and cross-lingual attention to further reduce noises. We conducted a series of experiments on three tasks : <a href="https://en.wikipedia.org/wiki/Translation">word translation</a>, <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity relatedness</a>, and cross-lingual entity linking. The results, both qualitative and quantitative, demonstrate the significance of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a>.</abstract>
      <doi>10.18653/v1/D18-1021</doi>
      <bibkey>cao-etal-2018-joint</bibkey>
    </paper>
    <paper id="23">
      <title>Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding</title>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Boliang</first><last>Zhang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Kevin</first><last>Knight</last></author>
      <pages>250–260</pages>
      <url hash="ba74292b">D18-1023</url>
      <abstract>We construct a multilingual common semantic space based on <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a>, where words from multiple languages are projected into a shared space via which all available resources and knowledge can be shared across multiple languages. Beyond <a href="https://en.wikipedia.org/wiki/Word_alignment">word alignment</a>, we introduce multiple cluster-level alignments and enforce the word clusters to be consistently distributed across multiple languages. We exploit three signals for clustering : (1) neighbor words in the monolingual word embedding space ; (2) character-level information ; and (3) <a href="https://en.wikipedia.org/wiki/Semantic_property">linguistic properties</a> (e.g., <a href="https://en.wikipedia.org/wiki/Apposition">apposition</a>, locative suffix) derived from linguistic structure knowledge bases available for thousands of languages. We introduce a new cluster-consistent correlational neural network to construct the common semantic space by aligning words as well as <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clusters</a>. Intrinsic evaluation on monolingual and multilingual QVEC tasks shows our approach achieves significantly higher correlation with linguistic features which are extracted from manually crafted lexical resources than state-of-the-art multi-lingual embedding learning methods do. Using low-resource language name tagging as a case study for extrinsic evaluation, our <a href="https://en.wikipedia.org/wiki/Methodology">approach</a> achieves up to 14.6 % absolute F-score gain over the state of the art on cross-lingual direct transfer. Our approach is also shown to be robust even when the size of <a href="https://en.wikipedia.org/wiki/Bilingual_dictionary">bilingual dictionary</a> is small.</abstract>
      <doi>10.18653/v1/D18-1023</doi>
      <bibkey>huang-etal-2018-multi</bibkey>
    </paper>
    <paper id="24">
      <title>Unsupervised Multilingual Word Embeddings</title>
      <author><first>Xilun</first><last>Chen</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>261–270</pages>
      <url hash="484da67d">D18-1024</url>
      <abstract>Multilingual Word Embeddings (MWEs) represent words from multiple languages in a single distributional vector space. Unsupervised MWE (UMWE) methods acquire multilingual embeddings without cross-lingual supervision, which is a significant advantage over traditional supervised approaches and opens many new possibilities for low-resource languages. Prior art for learning UMWEs, however, merely relies on a number of independently trained Unsupervised Bilingual Word Embeddings (UBWEs) to obtain multilingual embeddings. These <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> fail to leverage the interdependencies that exist among many languages. To address this shortcoming, we propose a fully unsupervised framework for learning MWEs that directly exploits the relations between all language pairs. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> substantially outperforms previous approaches in the experiments on multilingual word translation and cross-lingual word similarity. In addition, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> even beats <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised approaches</a> trained with cross-lingual resources.</abstract>
      <doi>10.18653/v1/D18-1024</doi>
      <bibkey>chen-cardie-2018-unsupervised</bibkey>
      <pwccode url="https://github.com/ccsasuke/umwe" additional="true">ccsasuke/umwe</pwccode>
    </paper>
    <paper id="26">
      <title>Adversarial Propagation and Zero-Shot Cross-Lingual Transfer of Word Vector Specialization</title>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Nikola</first><last>Mrkšić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>282–293</pages>
      <url hash="cb2bb29c">D18-1026</url>
      <abstract>Semantic specialization is a process of fine-tuning pre-trained <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional word vectors</a> using <a href="https://en.wikipedia.org/wiki/Lexical_analysis">external lexical knowledge</a> (e.g., WordNet) to accentuate a particular <a href="https://en.wikipedia.org/wiki/Semantic_relation">semantic relation</a> in the specialized vector space. While post-processing specialization methods are applicable to arbitrary distributional vectors, they are limited to updating only the vectors of words occurring in external lexicons (i.e., seen words), leaving the vectors of all other words unchanged. We propose a novel <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> to specializing the full distributional vocabulary. Our adversarial post-specialization method propagates the external lexical knowledge to the full distributional space. We exploit words seen in the resources as training examples for learning a global specialization function. This function is learned by combining a standard L2-distance loss with a adversarial loss : the adversarial component produces more realistic output vectors. We show the effectiveness and robustness of the proposed method across three languages and on three tasks : <a href="https://en.wikipedia.org/wiki/Similarity_measure">word similarity</a>, dialog state tracking, and lexical simplification. We report consistent improvements over distributional word vectors and vectors specialized by other state-of-the-art specialization frameworks. Finally, we also propose a cross-lingual transfer method for zero-shot specialization which successfully specializes a full target distributional space without any lexical knowledge in the target language and without any bilingual data.</abstract>
      <doi>10.18653/v1/D18-1026</doi>
      <bibkey>ponti-etal-2018-adversarial</bibkey>
      <pwccode url="https://github.com/cambridgeltl/adversarial-postspec" additional="false">cambridgeltl/adversarial-postspec</pwccode>
    </paper>
    <paper id="31">
      <title>Personalized Microblog Sentiment Classification via Adversarial Cross-lingual Multi-task Learning</title>
      <author><first>Weichao</first><last>Wang</last></author>
      <author><first>Shi</first><last>Feng</last></author>
      <author><first>Wei</first><last>Gao</last></author>
      <author><first>Daling</first><last>Wang</last></author>
      <author><first>Yifei</first><last>Zhang</last></author>
      <pages>338–348</pages>
      <url hash="cb546142">D18-1031</url>
      <abstract>Sentiment expression in microblog posts can be affected by user’s personal character, <a href="https://en.wikipedia.org/wiki/Opinion">opinion bias</a>, <a href="https://en.wikipedia.org/wiki/Politics">political stance</a> and so on. Most of existing personalized microblog sentiment classification methods suffer from the insufficiency of discriminative tweets for personalization learning. We observed that <a href="https://en.wikipedia.org/wiki/Microblogging">microblog users</a> have consistent individuality and opinion bias in different languages. Based on this observation, in this paper we propose a novel user-attention-based Convolutional Neural Network (CNN) model with adversarial cross-lingual learning framework. The user attention mechanism is leveraged in CNN model to capture user’s language-specific individuality from the posts. Then the attention-based CNN model is incorporated into a novel adversarial cross-lingual learning framework, in which with the help of user properties as bridge between languages, we can extract the language-specific features and language-independent features to enrich the user post representation so as to alleviate the data insufficiency problem. Results on English and Chinese microblog datasets confirm that our method outperforms state-of-the-art baseline algorithms with large margins.</abstract>
      <doi>10.18653/v1/D18-1031</doi>
      <bibkey>wang-etal-2018-personalized</bibkey>
    </paper>
    <paper id="33">
      <title>Cross-lingual Lexical Sememe Prediction</title>
      <author><first>Fanchao</first><last>Qi</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Hao</first><last>Zhu</last></author>
      <author><first>Ruobing</first><last>Xie</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <pages>358–368</pages>
      <url hash="2b054c66">D18-1033</url>
      <abstract>Sememes are defined as the minimum semantic units of human languages. As important knowledge sources, sememe-based linguistic knowledge bases have been widely used in many <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP tasks</a>. However, most languages still do not have sememe-based linguistic knowledge bases. Thus we present a task of cross-lingual lexical sememe prediction, aiming to automatically predict <a href="https://en.wikipedia.org/wiki/Sememe">sememes</a> for words in other languages. We propose a novel framework to model correlations between <a href="https://en.wikipedia.org/wiki/Sememe">sememes</a> and multi-lingual words in low-dimensional semantic space for sememe prediction. Experimental results on real-world datasets show that our proposed model achieves consistent and significant improvements as compared to baseline methods in cross-lingual sememe prediction. The codes and data of this paper are available at.<url>https://github.com/thunlp/CL-SP</url>.</abstract>
      <doi>10.18653/v1/D18-1033</doi>
      <bibkey>qi-etal-2018-cross</bibkey>
      <pwccode url="https://github.com/thunlp/CL-SP" additional="false">thunlp/CL-SP</pwccode>
    </paper>
    <paper id="35">
      <title>A Stable and Effective Learning Strategy for Trainable Greedy Decoding</title>
      <author><first>Yun</first><last>Chen</last></author>
      <author><first>Victor O.K.</first><last>Li</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Samuel</first><last>Bowman</last></author>
      <pages>380–390</pages>
      <url hash="ddee07be">D18-1035</url>
      <abstract>Beam search is a widely used approximate search strategy for neural network decoders, and it generally outperforms simple <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy decoding</a> on tasks like <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. However, this improvement comes at substantial computational cost. In this paper, we propose a flexible new method that allows us to reap nearly the full benefits of <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> with nearly no additional computational cost. The method revolves around a small neural network actor that is trained to observe and manipulate the hidden state of a previously-trained decoder. To train this actor network, we introduce the use of a pseudo-parallel corpus built using the output of <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> on a base model, ranked by a target quality metric like BLEU. Our method is inspired by earlier work on this problem, but requires no <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>, and can be trained reliably on a range of <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. Experiments on three parallel corpora and three architectures show that the method yields substantial improvements in translation quality and speed over each base system.</abstract>
      <doi>10.18653/v1/D18-1035</doi>
      <bibkey>chen-etal-2018-stable</bibkey>
    </paper>
    <paper id="36">
      <title>Addressing Troublesome Words in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Zhongjun</first><last>He</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <author><first>Hua</first><last>Wu</last></author>
      <pages>391–400</pages>
      <url hash="d31a1c9d">D18-1036</url>
      <abstract>One of the weaknesses of Neural Machine Translation (NMT) is in handling lowfrequency and ambiguous words, which we refer as troublesome words. To address this problem, we propose a novel memoryenhanced NMT method. First, we investigate different <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> to define and detect the troublesome words. Then, a contextual memory is constructed to memorize which target words should be produced in what situations. Finally, we design a hybrid model to dynamically access the contextual memory so as to correctly translate the troublesome words. The extensive experiments on Chinese-to-English and English-to-German translation tasks demonstrate that our method significantly outperforms the strong baseline models in translation quality, especially in handling troublesome words.</abstract>
      <doi>10.18653/v1/D18-1036</doi>
      <bibkey>zhao-etal-2018-addressing</bibkey>
    </paper>
    <paper id="38">
      <title>XL-NBT : A Cross-lingual Neural Belief Tracking Framework<fixed-case>XL</fixed-case>-<fixed-case>NBT</fixed-case>: A Cross-lingual Neural Belief Tracking Framework</title>
      <author><first>Wenhu</first><last>Chen</last></author>
      <author><first>Jianshu</first><last>Chen</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Dong</first><last>Yu</last></author>
      <author><first>Xifeng</first><last>Yan</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>414–424</pages>
      <url hash="93c3d7b5">D18-1038</url>
      <attachment type="attachment" hash="7ed0cb4f">D18-1038.Attachment.pdf</attachment>
      <abstract>Task-oriented dialog systems are becoming pervasive, and many companies heavily rely on them to complement <a href="https://en.wikipedia.org/wiki/Intelligent_agent">human agents</a> for customer service in call centers. With globalization, the need for providing cross-lingual customer support becomes more urgent than ever. However, cross-lingual support poses great challengesit requires a large amount of additional annotated data from <a href="https://en.wikipedia.org/wiki/First_language">native speakers</a>. In order to bypass the expensive human annotation and achieve the first step towards the ultimate goal of building a universal dialog system, we set out to build a cross-lingual state tracking framework. Specifically, we assume that there exists a source language with dialog belief tracking annotations while the target languages have no annotated dialog data of any form. Then, we pre-train a state tracker for the source language as a teacher, which is able to exploit easy-to-access parallel data. We then distill and transfer its own knowledge to the student state tracker in target languages. We specifically discuss two types of common parallel resources : <a href="https://en.wikipedia.org/wiki/Bilingual_corpus">bilingual corpus</a> and <a href="https://en.wikipedia.org/wiki/Bilingual_dictionary">bilingual dictionary</a>, and design different transfer learning strategies accordingly. Experimentally, we successfully use English state tracker as the teacher to transfer its knowledge to both Italian and German trackers and achieve promising results.</abstract>
      <doi>10.18653/v1/D18-1038</doi>
      <bibkey>chen-etal-2018-xl</bibkey>
      <pwccode url="https://github.com/wenhuchen/Cross-Lingual-NBT" additional="false">wenhuchen/Cross-Lingual-NBT</pwccode>
    </paper>
    <paper id="40">
      <title>Back-Translation Sampling by Targeting Difficult Words in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Marzieh</first><last>Fadaee</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>436–446</pages>
      <url hash="2c5c12ed">D18-1040</url>
      <abstract>Neural Machine Translation has achieved state-of-the-art performance for several language pairs using a combination of parallel and synthetic data. Synthetic data is often generated by back-translating sentences randomly sampled from monolingual data using a reverse translation model. While <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> has been shown to be very effective in many cases, it is not entirely clear why. In this work, we explore different aspects of <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a>, and show that words with high prediction loss during training benefit most from the addition of <a href="https://en.wikipedia.org/wiki/Synthetic_data">synthetic data</a>. We introduce several variations of <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">sampling strategies</a> targeting difficult-to-predict words using prediction losses and frequencies of words. In addition, we also target the contexts of difficult words and sample sentences that are similar in context. Experimental results for the WMT news translation task show that our method improves translation quality by up to 1.7 and 1.2 Bleu points over <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> using <a href="https://en.wikipedia.org/wiki/Simple_random_sample">random sampling</a> for German-English and English-German, respectively.</abstract>
      <doi>10.18653/v1/D18-1040</doi>
      <bibkey>fadaee-monz-2018-back</bibkey>
    </paper>
    <paper id="42">
      <title>A Discriminative Latent-Variable Model for Bilingual Lexicon Induction</title>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Yova</first><last>Kementchedjhieva</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>458–468</pages>
      <url hash="d3490b13">D18-1042</url>
      <abstract>We introduce a novel discriminative latent-variable model for the task of bilingual lexicon induction. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> combines the bipartite matching dictionary prior of Haghighi et al. (2008) with a state-of-the-art embedding-based approach. To train the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, we derive an efficient Viterbi EM algorithm. We provide empirical improvements on six language pairs under two metrics and show that the prior theoretically and empirically helps to mitigate the hubness problem. We also demonstrate how previous work may be viewed as a similarly fashioned latent-variable model, albeit with a different prior.</abstract>
      <doi>10.18653/v1/D18-1042</doi>
      <bibkey>ruder-etal-2018-discriminative</bibkey>
      <pwccode url="https://github.com/sebastianruder/latent-variable-vecmap" additional="false">sebastianruder/latent-variable-vecmap</pwccode>
    </paper>
    <paper id="43">
      <title>Non-Adversarial Unsupervised Word Translation</title>
      <author><first>Yedid</first><last>Hoshen</last></author>
      <author><first>Lior</first><last>Wolf</last></author>
      <pages>469–478</pages>
      <url hash="8ac2df29">D18-1043</url>
      <abstract>Unsupervised word translation from non-parallel inter-lingual corpora has attracted much research interest. Very recently, <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural network methods</a> trained with adversarial loss functions achieved high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. Despite the impressive success of the recent techniques, they suffer from the typical drawbacks of generative adversarial models : sensitivity to <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyper-parameters</a>, long training time and lack of <a href="https://en.wikipedia.org/wiki/Interpretability">interpretability</a>. In this paper, we make the observation that two sufficiently similar distributions can be aligned correctly with iterative matching methods. We present a novel method that first aligns the second moment of the word distributions of the two languages and then iteratively refines the alignment. Extensive experiments on word translation of European and Non-European languages show that our method achieves better performance than recent state-of-the-art deep adversarial approaches and is competitive with the supervised baseline. It is also efficient, easy to parallelize on CPU and interpretable.</abstract>
      <doi>10.18653/v1/D18-1043</doi>
      <bibkey>hoshen-wolf-2018-non</bibkey>
      <pwccode url="https://github.com/facebookresearch/MUSE" additional="true">facebookresearch/MUSE</pwccode>
    </paper>
    <paper id="44">
      <title>Semi-Autoregressive Neural Machine Translation</title>
      <author><first>Chunqi</first><last>Wang</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <author><first>Haiqing</first><last>Chen</last></author>
      <pages>479–488</pages>
      <url hash="404bea16">D18-1044</url>
      <abstract>Existing approaches to <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> are typically <a href="https://en.wikipedia.org/wiki/Autoregressive_model">autoregressive models</a>. While these models attain state-of-the-art translation quality, they are suffering from low <a href="https://en.wikipedia.org/wiki/Parallelizability">parallelizability</a> and thus slow at decoding long sequences. In this paper, we propose a novel <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for fast sequence generation   the semi-autoregressive Transformer (SAT). The SAT keeps the autoregressive property in global but relieves in local and thus are able to produce multiple successive words in parallel at each time step. Experiments conducted on English-German and Chinese-English translation tasks show that the SAT achieves a good balance between translation quality and decoding speed. On WMT’14 English-German translation, the SAT achieves 5.58 speedup while maintaining 88 % translation quality, significantly better than the previous non-autoregressive methods. When produces two words at each time step, the SAT is almost lossless (only 1 % degeneration in BLEU score).</abstract>
      <doi>10.18653/v1/D18-1044</doi>
      <bibkey>wang-etal-2018-semi-autoregressive</bibkey>
      <pwccode url="https://github.com/chqiwang/sa-nmt" additional="false">chqiwang/sa-nmt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="45">
      <title>Understanding Back-Translation at Scale</title>
      <author><first>Sergey</first><last>Edunov</last></author>
      <author><first>Myle</first><last>Ott</last></author>
      <author><first>Michael</first><last>Auli</last></author>
      <author><first>David</first><last>Grangier</last></author>
      <pages>489–500</pages>
      <url hash="10188c11">D18-1045</url>
      <abstract>An effective method to improve <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> with monolingual data is to augment the parallel training corpus with back-translations of target language sentences. This work broadens the understanding of <a href="https://en.wikipedia.org/wiki/Back-translation">back-translation</a> and investigates a number of methods to generate synthetic source sentences. We find that in all but resource poor settings <a href="https://en.wikipedia.org/wiki/Back_translation">back-translations</a> obtained via <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">sampling</a> or noised beam outputs are most effective. Our analysis shows that sampling or noisy synthetic data gives a much stronger training signal than <a href="https://en.wikipedia.org/wiki/Data">data</a> generated by beam or greedy search. We also compare how synthetic data compares to genuine bitext and study various domain effects. Finally, we scale to hundreds of millions of monolingual sentences and achieve a new state of the art of 35 BLEU on the WMT’14 English-German test set.</abstract>
      <doi>10.18653/v1/D18-1045</doi>
      <bibkey>edunov-etal-2018-understanding</bibkey>
      <pwccode url="https://github.com/pytorch/fairseq" additional="true">pytorch/fairseq</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="46">
      <title>Bootstrapping Transliteration with Constrained Discovery for Low-Resource Languages</title>
      <author><first>Shyam</first><last>Upadhyay</last></author>
      <author><first>Jordan</first><last>Kodner</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>501–511</pages>
      <url hash="489ccb93">D18-1046</url>
      <abstract>Generating the English transliteration of a name written in a foreign script is an important and challenging step in multilingual knowledge acquisition and <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>. Existing approaches to transliteration generation require a large (5000) number of training examples. This difficulty contrasts with <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration discovery</a>, a somewhat easier task that involves picking a plausible <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a> from a given list. In this work, we present a <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrapping algorithm</a> that uses constrained discovery to improve generation, and can be used with as few as 500 training examples, which we show can be sourced from annotators in a matter of hours. This opens the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> to languages for which large number of training examples are unavailable. We evaluate transliteration generation performance itself, as well the improvement it brings to cross-lingual candidate generation for <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity linking</a>, a typical downstream task. We present a comprehensive evaluation of our approach on nine languages, each written in a unique script.</abstract>
      <doi>10.18653/v1/D18-1046</doi>
      <bibkey>upadhyay-etal-2018-bootstrapping</bibkey>
    </paper>
    <paper id="48">
      <title>Adaptive Multi-pass Decoder for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Xinwei</first><last>Geng</last></author>
      <author><first>Xiaocheng</first><last>Feng</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>523–532</pages>
      <url hash="7ae098cf">D18-1048</url>
      <abstract>Although end-to-end neural machine translation (NMT) has achieved remarkable progress in the recent years, the idea of adopting multi-pass decoding mechanism into conventional NMT is not well explored. In this paper, we propose a novel architecture called adaptive multi-pass decoder, which introduces a flexible multi-pass polishing mechanism to extend the capacity of NMT via <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>. More specifically, we adopt an extra policy network to automatically choose a suitable and effective number of decoding passes, according to the <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a> of source sentences and the <a href="https://en.wikipedia.org/wiki/Quality_(business)">quality</a> of the generated translations. Extensive experiments on Chinese-English translation demonstrate the effectiveness of our proposed adaptive multi-pass decoder upon the conventional <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a> with a significant improvement about 1.55 BLEU.</abstract>
      <doi>10.18653/v1/D18-1048</doi>
      <bibkey>geng-etal-2018-adaptive</bibkey>
    </paper>
    <paper id="51">
      <title>SimpleQuestions Nearly Solved : A New Upperbound and Baseline Approach<fixed-case>S</fixed-case>imple<fixed-case>Q</fixed-case>uestions Nearly Solved: A New Upperbound and Baseline Approach</title>
      <author><first>Michael</first><last>Petrochuk</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>554–558</pages>
      <url hash="5dcb4b79">D18-1051</url>
      <abstract>The SimpleQuestions dataset is one of the most commonly used benchmarks for studying single-relation factoid questions. In this paper, we present new evidence that this <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark</a> can be nearly solved by standard methods. First, we show that ambiguity in the data bounds performance at 83.4 % ; many questions have more than one equally plausible interpretation. Second, we introduce a <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> that sets a new state-of-the-art performance level at 78.1 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, despite using standard <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a>. Finally, we report an empirical analysis showing that the <a href="https://en.wikipedia.org/wiki/Upper_and_lower_bounds">upperbound</a> is loose ; roughly a quarter of the remaining errors are also not resolvable from the <a href="https://en.wikipedia.org/wiki/Signal_(IPC)">linguistic signal</a>. Together, these results suggest that the SimpleQuestions dataset is nearly solved.</abstract>
      <video href="https://vimeo.com/305204813" />
      <doi>10.18653/v1/D18-1051</doi>
      <bibkey>petrochuk-zettlemoyer-2018-simplequestions</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/simplequestions">SimpleQuestions</pwcdataset>
    </paper>
    <paper id="52">
      <title>Phrase-Indexed Question Answering : A New Challenge for Scalable Document Comprehension</title>
      <author><first>Minjoon</first><last>Seo</last></author>
      <author><first>Tom</first><last>Kwiatkowski</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <author><first>Ali</first><last>Farhadi</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <pages>559–564</pages>
      <url hash="a04d933f">D18-1052</url>
      <abstract>We formalize a new modular variant of current question answering tasks by enforcing complete independence of the document encoder from the question encoder. This formulation addresses a key challenge in machine comprehension by building a standalone representation of the document discourse. It additionally leads to a significant scalability advantage since the encoding of the answer candidate phrases in the document can be pre-computed and indexed offline for efficient retrieval. We experiment with baseline models for the new task, which achieve a reasonable accuracy but significantly underperform unconstrained QA models. We invite the QA research community to engage in Phrase-Indexed Question Answering (PIQA, pika) for closing the gap. The leaderboard is at :<url>nlp.cs.washington.edu/piqa</url>
      </abstract>
      <video href="https://vimeo.com/305205055" />
      <doi>10.18653/v1/D18-1052</doi>
      <bibkey>seo-etal-2018-phrase</bibkey>
      <pwccode url="https://github.com/uwnlp/piqa" additional="false">uwnlp/piqa</pwccode>
    </paper>
    <paper id="54">
      <title>Cut to the Chase : A Context Zoom-in Network for Reading Comprehension</title>
      <author><first>Sathish Reddy</first><last>Indurthi</last></author>
      <author><first>Seunghak</first><last>Yu</last></author>
      <author><first>Seohyun</first><last>Back</last></author>
      <author><first>Heriberto</first><last>Cuayáhuitl</last></author>
      <pages>570–575</pages>
      <url hash="01165d8d">D18-1054</url>
      <attachment type="attachment" hash="90e5d4b3">D18-1054.Attachment.zip</attachment>
      <abstract>In recent years many <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> have been proposed to solve Reading Comprehension (RC) tasks. Most of these models suffer from reasoning over long documents and do not trivially generalize to cases where the answer is not present as a span in a given document. We present a novel neural-based architecture that is capable of extracting relevant regions based on a given question-document pair and generating a well-formed answer. To show the effectiveness of our architecture, we conducted several experiments on the recently proposed and challenging RC dataset ‘NarrativeQA’. The proposed <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a> outperforms state-of-the-art results by 12.62 % (ROUGE-L) relative improvement.</abstract>
      <video href="https://vimeo.com/305205548" />
      <doi>10.18653/v1/D18-1054</doi>
      <bibkey>indurthi-etal-2018-cut</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/narrativeqa">NarrativeQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="55">
      <title>Adaptive Document Retrieval for Deep Question Answering</title>
      <author><first>Bernhard</first><last>Kratzwald</last></author>
      <author><first>Stefan</first><last>Feuerriegel</last></author>
      <pages>576–581</pages>
      <url hash="cc6188ab">D18-1055</url>
      <abstract>State-of-the-art systems in deep question answering proceed as follows : (1)an initial <a href="https://en.wikipedia.org/wiki/Document_retrieval">document retrieval</a> selects relevant documents, which (2) are then processed by a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> in order to extract the final answer. Yet the exact interplay between both components is poorly understood, especially concerning the number of candidate documents that should be retrieved. We show that choosing a static number of documents-as used in prior research-suffers from a noise-information trade-off and yields suboptimal results. As a remedy, we propose an adaptive document retrieval model. This learns the optimal candidate number for <a href="https://en.wikipedia.org/wiki/Document_retrieval">document retrieval</a>, conditional on the size of the corpus and the query. We report extensive experimental results showing that our adaptive approach outperforms state-of-the-art methods on multiple benchmark datasets, as well as in the context of corpora with variable sizes.</abstract>
      <video href="https://vimeo.com/305205847" />
      <doi>10.18653/v1/D18-1055</doi>
      <bibkey>kratzwald-feuerriegel-2018-adaptive</bibkey>
      <pwccode url="https://github.com/bernhard2202/adaptive-ir-for-qa" additional="false">bernhard2202/adaptive-ir-for-qa</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimovies">WikiMovies</pwcdataset>
    </paper>
    <paper id="56">
      <title>Why is unsupervised alignment of English embeddings from different algorithms so hard?<fixed-case>E</fixed-case>nglish embeddings from different algorithms so hard?</title>
      <author><first>Mareike</first><last>Hartmann</last></author>
      <author><first>Yova</first><last>Kementchedjhieva</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>582–586</pages>
      <url hash="b30f4eb4">D18-1056</url>
      <abstract>This paper presents a challenge to the community : Generative adversarial networks (GANs) can perfectly align independent English word embeddings induced using the same <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>, based on distributional information alone ; but fails to do so, for two different embeddings algorithms. Why is that? We believe understanding why, is key to understand both modern word embedding algorithms and the limitations and instability dynamics of GANs. This paper shows that (a) in all these cases, where alignment fails, there exists a linear transform between the two embeddings (so algorithm biases do not lead to non-linear differences), and (b) similar effects can not easily be obtained by varying hyper-parameters. One plausible suggestion based on our initial experiments is that the differences in the inductive biases of the embedding algorithms lead to an optimization landscape that is riddled with <a href="https://en.wikipedia.org/wiki/Local_optimum">local optima</a>, leading to a very small basin of convergence, but we present this more as a challenge paper than a technical contribution.</abstract>
      <video href="https://vimeo.com/305196498" />
      <doi>10.18653/v1/D18-1056</doi>
      <bibkey>hartmann-etal-2018-unsupervised</bibkey>
    </paper>
    <paper id="57">
      <title>Quantifying Context Overlap for Training Word Embeddings</title>
      <author><first>Yimeng</first><last>Zhuang</last></author>
      <author><first>Jinghui</first><last>Xie</last></author>
      <author><first>Yinhe</first><last>Zheng</last></author>
      <author><first>Xuan</first><last>Zhu</last></author>
      <pages>587–593</pages>
      <url hash="2d5632cf">D18-1057</url>
      <abstract>Most <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for learning <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> are trained based on the context information of words, more precisely first order co-occurrence relations. In this paper, a <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> is designed to estimate second order co-occurrence relations based on context overlap. The estimated values are further used as the augmented data to enhance the learning of word embeddings by joint training with existing neural word embedding models. Experimental results show that better word vectors can be obtained for word similarity tasks and some downstream NLP tasks by the enhanced approach.</abstract>
      <video href="https://vimeo.com/305196755" />
      <doi>10.18653/v1/D18-1057</doi>
      <bibkey>zhuang-etal-2018-quantifying</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="58">
      <title>Neural Latent Relational Analysis to Capture Lexical Semantic Relations in a Vector Space</title>
      <author><first>Koki</first><last>Washio</last></author>
      <author><first>Tsuneaki</first><last>Kato</last></author>
      <pages>594–600</pages>
      <url hash="a2ac2107">D18-1058</url>
      <abstract>Capturing the semantic relations of words in a <a href="https://en.wikipedia.org/wiki/Vector_space">vector space</a> contributes to many natural language processing tasks. One promising approach exploits lexico-syntactic patterns as features of word pairs. In this paper, we propose a novel <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> of this pattern-based approach, neural latent relational analysis (NLRA). NLRA can generalize co-occurrences of word pairs and lexico-syntactic patterns, and obtain embeddings of the word pairs that do not co-occur. This overcomes the critical data sparseness problem encountered in previous pattern-based models. Our experimental results on measuring relational similarity demonstrate that NLRA outperforms the previous pattern-based models. In addition, when combined with a vector offset model, NLRA achieves a performance comparable to that of the state-of-the-art <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> that exploits additional semantic relational data.</abstract>
      <video href="https://vimeo.com/305197006" />
      <doi>10.18653/v1/D18-1058</doi>
      <bibkey>washio-kato-2018-neural</bibkey>
    </paper>
    <paper id="59">
      <title>Generalizing Word Embeddings using Bag of Subwords</title>
      <author><first>Jinman</first><last>Zhao</last></author>
      <author><first>Sidharth</first><last>Mudgal</last></author>
      <author><first>Yingyu</first><last>Liang</last></author>
      <pages>601–606</pages>
      <url hash="ed341fa5">D18-1059</url>
      <abstract>We approach the problem of generalizing pre-trained word embeddings beyond fixed-size vocabularies without using additional <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a>. We propose a subword-level word vector generation model that views <a href="https://en.wikipedia.org/wiki/Word_(computer_science)">words</a> as bags of character n-grams. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is simple, fast to train and provides good vectors for rare or unseen words. Experiments show that our model achieves state-of-the-art performances in English word similarity task and in joint prediction of part-of-speech tag and morphosyntactic attributes in 23 languages, suggesting our model’s ability in capturing the relationship between words’ textual representations and their embeddings.<tex-math>n</tex-math>-grams. The model is simple, fast to train and provides good vectors for rare or unseen words. Experiments show that our model achieves state-of-the-art performances in English word similarity task and in joint prediction of part-of-speech tag and morphosyntactic attributes in 23 languages, suggesting our model’s ability in capturing the relationship between words’ textual representations and their embeddings.</abstract>
      <video href="https://vimeo.com/305197257" />
      <doi>10.18653/v1/D18-1059</doi>
      <bibkey>zhao-etal-2018-generalizing</bibkey>
      <pwccode url="https://github.com/jmzhao/bag-of-substring-embedder" additional="false">jmzhao/bag-of-substring-embedder</pwccode>
    </paper>
    <paper id="60">
      <title>Neural Metaphor Detection in Context</title>
      <author><first>Ge</first><last>Gao</last></author>
      <author><first>Eunsol</first><last>Choi</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>607–613</pages>
      <url hash="f3e54110">D18-1060</url>
      <abstract>We present end-to-end neural models for detecting metaphorical word use in context. We show that relatively standard BiLSTM models which operate on complete sentences work well in this setting, in comparison to previous work that used more restricted forms of linguistic context. These models establish a new state-of-the-art on existing verb metaphor detection benchmarks, and show strong performance on jointly predicting the <a href="https://en.wikipedia.org/wiki/Metaphor">metaphoricity</a> of all words in a running text.</abstract>
      <video href="https://vimeo.com/305197464" />
      <doi>10.18653/v1/D18-1060</doi>
      <bibkey>gao-etal-2018-neural</bibkey>
      <pwccode url="https://github.com/gao-g/metaphor-in-context" additional="false">gao-g/metaphor-in-context</pwccode>
    </paper>
    <paper id="61">
      <title>Distant Supervision from Disparate Sources for Low-Resource Part-of-Speech Tagging</title>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Željko</first><last>Agić</last></author>
      <pages>614–620</pages>
      <url hash="be94bece">D18-1061</url>
      <abstract>a cross-lingual neural part-of-speech tagger that learns from disparate sources of distant supervision, and realistically scales to hundreds of low-resource languages. The model exploits annotation projection, <a href="https://en.wikipedia.org/wiki/Instance_selection">instance selection</a>, tag dictionaries, morphological lexicons, and <a href="https://en.wikipedia.org/wiki/Distributed_representation">distributed representations</a>, all in a uniform framework. The approach is simple, yet surprisingly effective, resulting in a new state of the art without access to any gold annotated data.</abstract>
      <video href="https://vimeo.com/305211701" />
      <doi>10.18653/v1/D18-1061</doi>
      <bibkey>plank-agic-2018-distant</bibkey>
      <pwccode url="https://github.com/bplank/bilstm-aux" additional="false">bplank/bilstm-aux</pwccode>
    </paper>
    <paper id="64">
      <title>Adversarial Training for Multi-task and Multi-lingual Joint Modeling of Utterance Intent Classification</title>
      <author><first>Ryo</first><last>Masumura</last></author>
      <author><first>Yusuke</first><last>Shinohara</last></author>
      <author><first>Ryuichiro</first><last>Higashinaka</last></author>
      <author><first>Yushi</first><last>Aono</last></author>
      <pages>633–639</pages>
      <url hash="a7297bf3">D18-1064</url>
      <abstract>This paper proposes an adversarial training method for the multi-task and multi-lingual joint modeling needed for utterance intent classification. In joint modeling, <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a> can be efficiently utilized among multiple tasks or multiple languages. This is achieved by introducing both language-specific networks shared among different tasks and task-specific networks shared among different languages. However, the shared networks are often specialized in majority tasks or languages, so performance degradation must be expected for some minor data sets. In order to improve the invariance of shared networks, the proposed method introduces both language-specific task adversarial networks and task-specific language adversarial networks ; both are leveraged for purging the task or language dependencies of the shared networks. The effectiveness of the adversarial training proposal is demonstrated using Japanese and English data sets for three different utterance intent classification tasks.</abstract>
      <video href="https://vimeo.com/305212477" />
      <doi>10.18653/v1/D18-1064</doi>
      <bibkey>masumura-etal-2018-adversarial</bibkey>
    </paper>
    <paper id="69">
      <title>Hybrid Neural Attention for Agreement / Disagreement Inference in Online Debates</title>
      <author><first>Di</first><last>Chen</last></author>
      <author><first>Jiachen</first><last>Du</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>665–670</pages>
      <url hash="b16150c1">D18-1069</url>
      <abstract>Inferring the agreement / disagreement relation in <a href="https://en.wikipedia.org/wiki/Debate">debates</a>, especially in online debates, is one of the fundamental tasks in argumentation mining. The expressions of agreement / disagreement usually rely on argumentative expressions in text as well as interactions between participants in debates. Previous works usually lack the capability of jointly modeling these two factors. To alleviate this problem, this paper proposes a hybrid neural attention model which combines self and cross attention mechanism to locate salient part from textual context and interaction between users. Experimental results on three (dis)agreement inference datasets show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the state-of-the-art models.</abstract>
      <video href="https://vimeo.com/306360792" />
      <doi>10.18653/v1/D18-1069</doi>
      <bibkey>chen-etal-2018-hybrid</bibkey>
    </paper>
    <paper id="71">
      <title>A Syntactically Constrained Bidirectional-Asynchronous Approach for Emotional Conversation Generation</title>
      <author><first>Jingyuan</first><last>Li</last></author>
      <author><first>Xiao</first><last>Sun</last></author>
      <pages>678–683</pages>
      <url hash="8a6fa04b">D18-1071</url>
      <abstract>Traditional neural language models tend to generate generic replies with poor logic and no <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>. In this paper, a syntactically constrained bidirectional-asynchronous approach for emotional conversation generation (E-SCBA) is proposed to address this issue. In our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>, pre-generated emotion keywords and topic keywords are asynchronously introduced into the process of decoding. It is much different from most existing <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> which generate replies from the first word to the last. Through experiments, the results indicate that our approach not only improves the diversity of replies, but gains a boost on both <a href="https://en.wikipedia.org/wiki/Logic">logic</a> and emotion compared with <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>.</abstract>
      <doi>10.18653/v1/D18-1071</doi>
      <bibkey>li-sun-2018-syntactically</bibkey>
    </paper>
    <paper id="72">
      <title>Auto-Dialabel : Labeling Dialogue Data with <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">Unsupervised Learning</a></title>
      <author><first>Chen</first><last>Shi</last></author>
      <author><first>Qi</first><last>Chen</last></author>
      <author><first>Lei</first><last>Sha</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <author><first>Houfeng</first><last>Wang</last></author>
      <author><first>Lintao</first><last>Zhang</last></author>
      <pages>684–689</pages>
      <url hash="ed7f79ec">D18-1072</url>
      <abstract>The lack of <a href="https://en.wikipedia.org/wiki/Data_(computing)">labeled data</a> is one of the main challenges when building a task-oriented dialogue system. Existing dialogue datasets usually rely on human labeling, which is expensive, limited in size, and in low coverage. In this paper, we instead propose our framework auto-dialabel to automatically cluster the dialogue intents and slots. In this framework, we collect a set of context features, leverage an <a href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</a> for feature assembly, and adapt a dynamic hierarchical clustering method for intent and slot labeling. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> can promote human labeling cost to a great extent, achieve good intent clustering accuracy (84.1 %), and provide reasonable and instructive slot labeling results.</abstract>
      <doi>10.18653/v1/D18-1072</doi>
      <bibkey>shi-etal-2018-auto</bibkey>
    </paper>
    <paper id="73">
      <title>Extending Neural Generative Conversational Model using External Knowledge Sources</title>
      <author><first>Prasanna</first><last>Parthasarathi</last></author>
      <author><first>Joelle</first><last>Pineau</last></author>
      <pages>690–695</pages>
      <url hash="ef3197a8">D18-1073</url>
      <abstract>The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence</a> and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> when leveraging <a href="https://en.wikipedia.org/wiki/Knowledge">external knowledge</a>.</abstract>
      <doi>10.18653/v1/D18-1073</doi>
      <bibkey>parthasarathi-pineau-2018-extending</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/nell">NELL</pwcdataset>
    </paper>
    <paper id="75">
      <title>An Auto-Encoder Matching Model for Learning Utterance-Level Semantic Dependency in Dialogue Generation</title>
      <author><first>Liangchen</first><last>Luo</last></author>
      <author><first>Jingjing</first><last>Xu</last></author>
      <author><first>Junyang</first><last>Lin</last></author>
      <author><first>Qi</first><last>Zeng</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>702–707</pages>
      <url hash="04e8a53b">D18-1075</url>
      <abstract>Generating semantically coherent responses is still a major challenge in dialogue generation. Different from conventional text generation tasks, the mapping between inputs and responses in conversations is more complicated, which highly demands the understanding of utterance-level semantic dependency, a relation between the whole meanings of inputs and outputs. To address this problem, we propose an Auto-Encoder Matching (AEM) model to learn such dependency. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> contains two <a href="https://en.wikipedia.org/wiki/Auto-encoder">auto-encoders</a> and one mapping module. The auto-encoders learn the semantic representations of inputs and responses, and the mapping module learns to connect the utterance-level representations. Experimental results from automatic and human evaluations demonstrate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is capable of generating responses of high coherence and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a> compared to baseline models.</abstract>
      <doi>10.18653/v1/D18-1075</doi>
      <bibkey>luo-etal-2018-auto</bibkey>
      <pwccode url="https://github.com/lancopku/AMM" additional="false">lancopku/AMM</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dailydialog">DailyDialog</pwcdataset>
    </paper>
    <paper id="76">
      <title>A Dataset for Document Grounded Conversations</title>
      <author><first>Kangyan</first><last>Zhou</last></author>
      <author><first>Shrimai</first><last>Prabhumoye</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <pages>708–713</pages>
      <url hash="14f70050">D18-1076</url>
      <attachment type="attachment" hash="30c71711">D18-1076.Attachment.zip</attachment>
      <abstract>This paper introduces a document grounded dataset for <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a>. We define Document Grounded Conversations as conversations that are about the contents of a specified document. In this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> the specified documents were Wikipedia articles about popular movies. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> contains 4112 conversations with an average of 21.43 turns per conversation. This positions this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> to not only provide a relevant chat history while generating responses but also provide a source of information that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> could use. We describe two neural architectures that provide benchmark performance on the task of generating the next response. We also evaluate our models for <a href="https://en.wikipedia.org/wiki/Engagement">engagement</a> and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>, and find that the information from the document helps in generating more engaging and fluent responses.</abstract>
      <doi>10.18653/v1/D18-1076</doi>
      <bibkey>zhou-etal-2018-dataset</bibkey>
      <pwccode url="https://github.com/festvox/datasets-CMU_DoG" additional="true">festvox/datasets-CMU_DoG</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cmu-dog">CMU DoG</pwcdataset>
    </paper>
    <paper id="79">
      <title>Using active learning to expand training data for implicit discourse relation recognition</title>
      <author><first>Yang</first><last>Xu</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Huibin</first><last>Ruan</last></author>
      <author><first>Jianmin</first><last>Yao</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>725–731</pages>
      <url hash="afe49e15">D18-1079</url>
      <abstract>We tackle discourse-level relation recognition, a problem of determining semantic relations between text spans. Implicit relation recognition is challenging due to the lack of explicit relational clues. The increasingly popular <a href="https://en.wikipedia.org/wiki/Neural_network">neural network techniques</a> have been proven effective for semantic encoding, whereby widely employed to boost semantic relation discrimination. However, learning to predict semantic relations at a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep level</a> heavily relies on a great deal of training data, but the scale of the publicly available data in this field is limited. In this paper, we follow Rutherford and Xue (2015) to expand the training data set using the corpus of explicitly-related arguments, by arbitrarily dropping the overtly presented discourse connectives. On the basis, we carry out an experiment of <a href="https://en.wikipedia.org/wiki/Sampling_(statistics)">sampling</a>, in which a simple active learning approach is used, so as to take the informative instances for data expansion. The goal is to verify whether the selective use of external data not only reduces the time consumption of <a href="https://en.wikipedia.org/wiki/Retraining">retraining</a> but also ensures a better <a href="https://en.wikipedia.org/wiki/System">system</a> performance. Using the expanded training data, we retrain a convolutional neural network (CNN) based classifer which is a simplified version of Qin et al. (2016)’s stacking gated relation recognizer. Experimental results show that expanding the training set with small-scale carefully-selected external data yields substantial performance gain, with the improvements of about 4 % for <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and 3.6 % for <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>. This allows a <a href="https://en.wikipedia.org/wiki/Weak_classifier">weak classifier</a> to achieve a comparable performance against the state-of-the-art systems.</abstract>
      <doi>10.18653/v1/D18-1079</doi>
      <bibkey>xu-etal-2018-using</bibkey>
      <pwccode url="https://github.com/AndreaXu0401/ALIDRC" additional="false">AndreaXu0401/ALIDRC</pwccode>
    </paper>
    <paper id="81">
      <title>BLEU is Not Suitable for the Evaluation of Text Simplification<fixed-case>BLEU</fixed-case> is Not Suitable for the Evaluation of Text Simplification</title>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <author><first>Ari</first><last>Rappoport</last></author>
      <pages>738–744</pages>
      <url hash="0e496fe7">D18-1081</url>
      <attachment type="attachment" hash="3d9ea42f">D18-1081.Attachment.zip</attachment>
      <abstract>BLEU is widely considered to be an informative metric for text-to-text generation, including Text Simplification (TS). TS includes both lexical and structural aspects. In this paper we show that <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> is not suitable for the evaluation of sentence splitting, the major structural simplification operation. We manually compiled a sentence splitting gold standard corpus containing multiple structural paraphrases, and performed a correlation analysis with human judgments. We find low or no correlation between <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> and the grammaticality and meaning preservation parameters where sentence splitting is involved. Moreover, <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> often negatively correlates with <a href="https://en.wikipedia.org/wiki/Simplicity">simplicity</a>, essentially penalizing simpler sentences.</abstract>
      <doi>10.18653/v1/D18-1081</doi>
      <bibkey>sulem-etal-2018-bleu</bibkey>
      <pwccode url="https://github.com/eliorsulem/HSplit-corpus" additional="false">eliorsulem/HSplit-corpus</pwccode>
    </paper>
    <paper id="82">
      <title>S2SPMN : A Simple and Effective Framework for Response Generation with Relevant Information<fixed-case>S</fixed-case>2<fixed-case>SPMN</fixed-case>: A Simple and Effective Framework for Response Generation with Relevant Information</title>
      <author><first>Jiaxin</first><last>Pei</last></author>
      <author><first>Chenliang</first><last>Li</last></author>
      <pages>745–750</pages>
      <url hash="4b27ba24">D18-1082</url>
      <abstract>How to generate relevant and informative responses is one of the core topics in response generation area. Following the task formulation of <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, previous works mainly consider response generation task as a mapping from a source sentence to a target sentence. To realize this mapping, existing works tend to design intuitive but complex models. However, the relevant information existed in large dialogue corpus is mainly overlooked. In this paper, we propose Sequence to Sequence with Prototype Memory Network (S2SPMN) to exploit the relevant information provided by the large dialogue corpus to enhance response generation. Specifically, we devise two simple approaches in S2SPMN to select the relevant information (named prototypes) from the dialogue corpus. These <a href="https://en.wikipedia.org/wiki/Prototype">prototypes</a> are then saved into prototype memory network (PMN). Furthermore, a hierarchical attention mechanism is devised to extract the semantic information from the PMN to assist the response generation process. Empirical studies reveal the advantage of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> over several classical and strong baselines.</abstract>
      <doi>10.18653/v1/D18-1082</doi>
      <bibkey>pei-li-2018-s2spmn</bibkey>
    </paper>
    <paper id="83">
      <title>Improving Reinforcement Learning Based Image Captioning with Natural Language Prior</title>
      <author><first>Tszhang</first><last>Guo</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Kun</first><last>Bai</last></author>
      <pages>751–756</pages>
      <url hash="3ef74295">D18-1083</url>
      <attachment type="attachment" hash="13c8e34a">D18-1083.Attachment.zip</attachment>
      <abstract>Recently, Reinforcement Learning (RL) approaches have demonstrated advanced performance in image captioning by directly optimizing the <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> used for testing. However, this shaped reward introduces <a href="https://en.wikipedia.org/wiki/Learning_bias">learning biases</a>, which reduces the readability of generated text. In addition, the large sample space makes training unstable and slow. To alleviate these issues, we propose a simple coherent solution that constrains the action space using an n-gram language prior. Quantitative and qualitative evaluations on <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmarks</a> show that RL with the simple add-on module performs favorably against its counterpart in terms of both <a href="https://en.wikipedia.org/wiki/Readability">readability</a> and <a href="https://en.wikipedia.org/wiki/Speed_of_convergence">speed of convergence</a>. Human evaluation results show that our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is more human readable and graceful. The <a href="https://en.wikipedia.org/wiki/Implementation">implementation</a> will become publicly available upon the acceptance of the paper.</abstract>
      <doi>10.18653/v1/D18-1083</doi>
      <bibkey>guo-etal-2018-improving</bibkey>
      <pwccode url="https://github.com/tgGuo15/PriorImageCaption" additional="false">tgGuo15/PriorImageCaption</pwccode>
    </paper>
    <paper id="84">
      <title>Training for Diversity in Image Paragraph Captioning</title>
      <author><first>Luke</first><last>Melas-Kyriazi</last></author>
      <author><first>Alexander</first><last>Rush</last></author>
      <author><first>George</first><last>Han</last></author>
      <pages>757–761</pages>
      <url hash="e0c3ab82">D18-1084</url>
      <abstract>Image paragraph captioning models aim to produce detailed descriptions of a source image. These <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> use similar techniques as standard image captioning models, but they have encountered issues in text generation, notably a lack of diversity between sentences, that have limited their effectiveness. In this work, we consider applying sequence-level training for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We find that standard self-critical training produces poor results, but when combined with an integrated penalty on trigram repetition produces much more diverse paragraphs. This simple training approach improves on the best result on the Visual Genome paragraph captioning dataset from 16.9 to 30.6 CIDEr, with gains on <a href="https://en.wikipedia.org/wiki/METEOR">METEOR</a> and <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> as well, without requiring any architectural changes.</abstract>
      <doi>10.18653/v1/D18-1084</doi>
      <bibkey>melas-kyriazi-etal-2018-training</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/image-paragraph-captioning">Image Paragraph Captioning</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="88">
      <title>Neural Latent Extractive Document Summarization</title>
      <author><first>Xingxing</first><last>Zhang</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>779–784</pages>
      <url hash="c5341430">D18-1088</url>
      <abstract>Extractive summarization models need sentence level labels, which are usually created with rule-based methods since most summarization datasets only have document summary pairs. These labels might be suboptimal. We propose a latent variable extractive model, where sentences are viewed as <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variables</a> and sentences with activated variables are used to infer gold summaries. During <a href="https://en.wikipedia.org/wiki/Training">training</a>, the loss can come directly from gold summaries. Experiments on CNN / Dailymail dataset show our latent extractive model outperforms a strong extractive baseline trained on rule-based labels and also performs competitively with several recent models.</abstract>
      <doi>10.18653/v1/D18-1088</doi>
      <bibkey>zhang-etal-2018-neural</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="89">
      <title>On the Abstractiveness of Neural Document Summarization</title>
      <author><first>Fangfang</first><last>Zhang</last></author>
      <author><first>Jin-ge</first><last>Yao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>785–790</pages>
      <url hash="4ef0e3fa">D18-1089</url>
      <abstract>Many modern neural document summarization systems based on encoder-decoder networks are designed to produce abstractive summaries. We attempted to verify the degree of abstractiveness of modern neural abstractive summarization systems by calculating overlaps in terms of various types of units. Upon the observation that many abstractive systems tend to be near-extractive in practice, we also implemented a pure copy system, which achieved comparable results as abstractive summarizers while being far more computationally efficient. These findings suggest the possibility for future efforts towards more efficient <a href="https://en.wikipedia.org/wiki/System">systems</a> that could better utilize the vocabulary in the original document.</abstract>
      <doi>10.18653/v1/D18-1089</doi>
      <bibkey>zhang-etal-2018-abstractiveness</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="90">
      <title>Automatic Essay Scoring Incorporating Rating Schema via <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a></title>
      <author><first>Yucheng</first><last>Wang</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Yaqian</first><last>Zhou</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>791–797</pages>
      <url hash="cb77fb65">D18-1090</url>
      <abstract>Automatic essay scoring (AES) is the task of assigning grades to essays without <a href="https://en.wikipedia.org/wiki/Interference_(communication)">human interference</a>. Existing systems for AES are typically trained to predict the score of each single essay at a time without considering the rating schema. In order to address this issue, we propose a reinforcement learning framework for essay scoring that incorporates quadratic weighted kappa as guidance to optimize the scoring system. Experiment results on benchmark datasets show the effectiveness of our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a>.</abstract>
      <doi>10.18653/v1/D18-1090</doi>
      <bibkey>wang-etal-2018-automatic</bibkey>
    </paper>
    <paper id="91">
      <title>Identifying Well-formed Natural Language Questions</title>
      <author><first>Manaal</first><last>Faruqui</last></author>
      <author><first>Dipanjan</first><last>Das</last></author>
      <pages>798–803</pages>
      <url hash="dd734fae">D18-1091</url>
      <abstract>Understanding search queries is a hard problem as it involves dealing with word salad text ubiquitously issued by users. However, if a query resembles a well-formed question, a natural language processing pipeline is able to perform more accurate interpretation, thus reducing downstream compounding errors. Hence, identifying whether or not a query is well formed can enhance <a href="https://en.wikipedia.org/wiki/Query_understanding">query understanding</a>. Here, we introduce a new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> of identifying a well-formed natural language question. We construct and release a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of 25,100 publicly available questions classified into <a href="https://en.wikipedia.org/wiki/Well-formedness">well-formed and non-wellformed categories</a> and report an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 70.7 % on the test set. We also show that our <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> can be used to improve the performance of neural sequence-to-sequence models for generating questions for <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>.</abstract>
      <doi>10.18653/v1/D18-1091</doi>
      <bibkey>faruqui-das-2018-identifying</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/paralex">Paralex</pwcdataset>
    </paper>
    <paper id="92">
      <title>Self-Governing Neural Networks for On-Device Short Text Classification</title>
      <author><first>Sujith</first><last>Ravi</last></author>
      <author><first>Zornitsa</first><last>Kozareva</last></author>
      <pages>804–810</pages>
      <url hash="677e8056">D18-1092</url>
      <abstract>Deep neural networks reach state-of-the-art performance for wide range of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a> and speech applications. Yet, one of the biggest challenges is running these complex networks on devices such as <a href="https://en.wikipedia.org/wiki/Mobile_phone">mobile phones</a> or <a href="https://en.wikipedia.org/wiki/Smartwatch">smart watches</a> with tiny memory footprint and low computational capacity. We propose on-device Self-Governing Neural Networks (SGNNs), which learn compact projection vectors with local sensitive hashing. The key advantage of SGNNs over existing work is that they surmount the need for pre-trained word embeddings and <a href="https://en.wikipedia.org/wiki/Complex_network">complex networks</a> with huge parameters. We conduct extensive evaluation on dialog act classification and show significant improvement over state-of-the-art results. Our findings show that SGNNs are effective at capturing low-dimensional semantic text representations, while maintaining high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <video href="https://vimeo.com/305197775" />
      <doi>10.18653/v1/D18-1092</doi>
      <bibkey>ravi-kozareva-2018-self</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mrda">MRDA</pwcdataset>
    </paper>
    <paper id="93">
      <title>HFT-CNN : Learning Hierarchical Category Structure for Multi-label Short Text Categorization<fixed-case>HFT</fixed-case>-<fixed-case>CNN</fixed-case>: Learning Hierarchical Category Structure for Multi-label Short Text Categorization</title>
      <author><first>Kazuya</first><last>Shimura</last></author>
      <author><first>Jiyi</first><last>Li</last></author>
      <author><first>Fumiyo</first><last>Fukumoto</last></author>
      <pages>811–816</pages>
      <url hash="3455ee66">D18-1093</url>
      <attachment type="attachment" hash="243d2479">D18-1093.Attachment.zip</attachment>
      <abstract>We focus on the multi-label categorization task for short texts and explore the use of a hierarchical structure (HS) of categories. In contrast to the existing work using non-hierarchical flat model, the method leverages the <a href="https://en.wikipedia.org/wiki/Hierarchy">hierarchical relations</a> between the pre-defined categories to tackle the data sparsity problem. The lower the HS level, the less the <a href="https://en.wikipedia.org/wiki/Categorization">categorization</a> performance. Because the number of training data per category in a lower level is much smaller than that in an upper level. We propose an approach which can effectively utilize the data in the upper levels to contribute the <a href="https://en.wikipedia.org/wiki/Categorization">categorization</a> in the lower levels by applying the Convolutional Neural Network (CNN) with a fine-tuning technique. The results using two benchmark datasets show that proposed method, Hierarchical Fine-Tuning based CNN (HFT-CNN) is competitive with the state-of-the-art CNN based methods.</abstract>
      <doi>10.18653/v1/D18-1093</doi>
      <bibkey>shimura-etal-2018-hft</bibkey>
      <pwccode url="https://github.com/ShimShim46/HFT-CNN" additional="false">ShimShim46/HFT-CNN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rcv1">RCV1</pwcdataset>
    </paper>
    <paper id="94">
      <title>A Hierarchical Neural Attention-based Text Classifier</title>
      <author><first>Koustuv</first><last>Sinha</last></author>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <author><first>Derek</first><last>Ruths</last></author>
      <pages>817–823</pages>
      <url hash="e819e4c5">D18-1094</url>
      <attachment type="attachment" hash="ddb0a619">D18-1094.Attachment.zip</attachment>
      <abstract>Deep neural networks have been displaying superior performance over traditional <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised classifiers</a> in <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a>. They learn to extract useful <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> automatically when sufficient amount of data is presented. However, along with the growth in the number of documents comes the increase in the number of categories, which often results in poor performance of the multiclass classifiers. In this work, we use external knowledge in the form of topic category taxonomies to aide the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> by introducing a deep hierarchical neural attention-based classifier. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs better than or comparable to state-of-the-art hierarchical models at significantly lower <a href="https://en.wikipedia.org/wiki/Computational_cost">computational cost</a> while maintaining high <a href="https://en.wikipedia.org/wiki/Interpretability">interpretability</a>.</abstract>
      <doi>10.18653/v1/D18-1094</doi>
      <bibkey>sinha-etal-2018-hierarchical</bibkey>
      <pwccode url="https://github.com/koustuvsinha/hier-class" additional="false">koustuvsinha/hier-class</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/web-of-science-dataset">WOS</pwcdataset>
    </paper>
    <paper id="96">
      <title>Coherence-Aware Neural Topic Modeling</title>
      <author><first>Ran</first><last>Ding</last></author>
      <author><first>Ramesh</first><last>Nallapati</last></author>
      <author><first>Bing</first><last>Xiang</last></author>
      <pages>830–836</pages>
      <url hash="e8f88d86">D18-1096</url>
      <abstract>Topic models are evaluated based on their ability to describe documents well (i.e. low perplexity) and to produce topics that carry coherent semantic meaning. In <a href="https://en.wikipedia.org/wiki/Topic_modeling">topic modeling</a> so far, <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> is a direct optimization target. However, topic coherence, owing to its challenging computation, is not optimized for and is only evaluated after training. In this work, under a neural variational inference framework, we propose methods to incorporate a topic coherence objective into the training process. We demonstrate that such a coherence-aware topic model exhibits a similar level of <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a> as baseline models but achieves substantially higher topic coherence.</abstract>
      <doi>10.18653/v1/D18-1096</doi>
      <bibkey>ding-etal-2018-coherence</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="97">
      <title>Utilizing Character and Word Embeddings for Text Normalization with Sequence-to-Sequence Models</title>
      <author><first>Daniel</first><last>Watson</last></author>
      <author><first>Nasser</first><last>Zalmout</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>837–843</pages>
      <url hash="7b1b96d0">D18-1097</url>
      <abstract>Text normalization is an important enabling technology for several NLP tasks. Recently, neural-network-based approaches have outperformed well-established <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> in this task. However, in languages other than English, there has been little exploration in this direction. Both the scarcity of annotated data and the complexity of the language increase the difficulty of the problem. To address these challenges, we use a sequence-to-sequence model with character-based attention, which in addition to its self-learned character embeddings, uses word embeddings pre-trained with an approach that also models subword information. This provides the neural model with access to more linguistic information especially suitable for <a href="https://en.wikipedia.org/wiki/Text_normalization">text normalization</a>, without large parallel corpora. We show that providing the model with word-level features bridges the gap for the neural network approach to achieve a state-of-the-art F1 score on a standard Arabic language correction shared task dataset.</abstract>
      <doi>10.18653/v1/D18-1097</doi>
      <bibkey>watson-etal-2018-utilizing</bibkey>
    </paper>
    <paper id="99">
      <title>Supervised and Unsupervised Methods for Robust Separation of Section Titles and Prose Text in Web Documents</title>
      <author><first>Abhijith Athreya</first><last>Mysore Gopinath</last></author>
      <author><first>Shomir</first><last>Wilson</last></author>
      <author><first>Norman</first><last>Sadeh</last></author>
      <pages>850–855</pages>
      <url hash="de1d6e17">D18-1099</url>
      <abstract>The text in many web documents is organized into a hierarchy of section titles and corresponding prose content, a structure which provides potentially exploitable information on discourse structure and <a href="https://en.wikipedia.org/wiki/Topicality">topicality</a>. However, this <a href="https://en.wikipedia.org/wiki/Organization">organization</a> is generally discarded during text collection, and collecting it is not straightforward : the same visual organization can be implemented in a myriad of different ways in the underlying <a href="https://en.wikipedia.org/wiki/HTML">HTML</a>. To remedy this, we present a flexible system for automatically extracting the hierarchical section titles and prose organization of web documents irrespective of differences in HTML representation. This system uses features from <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a>, <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>, <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a> and <a href="https://en.wikipedia.org/wiki/Markup_language">markup</a> to build two models which classify HTML text into section titles and prose text. When tested on three different domains of web text, our domain-independent system achieves an overall <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)">precision</a> of 0.82 and a recall of 0.98. The domain-dependent variation produces very high <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">precision</a> (0.99) at the expense of <a href="https://en.wikipedia.org/wiki/Precision_(statistics)">recall</a> (0.75). These results exhibit a robust level of <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> suitable for enhancing <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>, <a href="https://en.wikipedia.org/wiki/Information_extraction">information extraction</a>, and <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>.</abstract>
      <doi>10.18653/v1/D18-1099</doi>
      <bibkey>mysore-gopinath-etal-2018-supervised</bibkey>
    </paper>
    <paper id="100">
      <title>SwitchOut : an Efficient Data Augmentation Algorithm for <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a><fixed-case>S</fixed-case>witch<fixed-case>O</fixed-case>ut: an Efficient Data Augmentation Algorithm for Neural Machine Translation</title>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>Hieu</first><last>Pham</last></author>
      <author><first>Zihang</first><last>Dai</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>856–861</pages>
      <url hash="f03185d2">D18-1100</url>
      <attachment type="attachment" hash="30560394">D18-1100.Attachment.pdf</attachment>
      <abstract>In this work, we examine methods for <a href="https://en.wikipedia.org/wiki/Data_augmentation">data augmentation</a> for <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">text-based tasks</a> such as <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation (NMT)</a>. We formulate the design of a data augmentation policy with desirable properties as an <a href="https://en.wikipedia.org/wiki/Optimization_problem">optimization problem</a>, and derive a generic analytic solution. This solution not only subsumes some existing augmentation schemes, but also leads to an extremely simple data augmentation strategy for NMT : randomly replacing words in both the source sentence and the target sentence with other random words from their corresponding vocabularies. We name this method SwitchOut. Experiments on three translation datasets of different scales show that SwitchOut yields consistent improvements of about 0.5 BLEU, achieving better or comparable performances to strong alternatives such as word dropout (Sennrich et al., 2016a). Code to implement this <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> is included in the appendix.</abstract>
      <video href="https://vimeo.com/305206127" />
      <doi>10.18653/v1/D18-1100</doi>
      <bibkey>wang-etal-2018-switchout</bibkey>
    </paper>
    <paper id="102">
      <title>Decipherment of Substitution Ciphers with Neural Language Models</title>
      <author><first>Nishant</first><last>Kambhatla</last></author>
      <author><first>Anahita</first><last>Mansouri Bigvand</last></author>
      <author><first>Anoop</first><last>Sarkar</last></author>
      <pages>869–874</pages>
      <url hash="a4fd2bea">D18-1102</url>
      <abstract>Decipherment of homophonic substitution ciphers using <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> is a well-studied task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. Previous work in this topic scores short local spans of possible plaintext decipherments using n-gram language models. The most widely used technique is the use of <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> with n-gram language models proposed by Nuhn et al.(2013). We propose a beam search algorithm that scores the entire candidate plaintext at each step of the <a href="https://en.wikipedia.org/wiki/Decipherment">decipherment</a> using a neural language model. We augment <a href="https://en.wikipedia.org/wiki/Beam_search">beam search</a> with a novel rest cost estimation that exploits the prediction power of a neural language model. We compare against the state of the art n-gram based methods on many different decipherment tasks. On challenging <a href="https://en.wikipedia.org/wiki/Cipher">ciphers</a> such as the <a href="https://en.wikipedia.org/wiki/Beale_cipher">Beale cipher</a> we provide significantly better error rates with much smaller beam sizes.</abstract>
      <video href="https://vimeo.com/305206655" />
      <doi>10.18653/v1/D18-1102</doi>
      <bibkey>kambhatla-etal-2018-decipherment</bibkey>
    </paper>
    <paper id="103">
      <title>Rapid Adaptation of <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> to New Languages</title>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Junjie</first><last>Hu</last></author>
      <pages>875–880</pages>
      <url hash="a4d997dc">D18-1103</url>
      <abstract>This paper examines the problem of adapting neural machine translation systems to new, low-resourced languages (LRLs) as effectively and rapidly as possible. We propose methods based on starting with massively multilingual seed models, which can be trained ahead-of-time, and then continuing training on data related to the LRL. We contrast a number of strategies, leading to a novel, simple, yet effective method of similar-language regularization, where we jointly train on both a LRL of interest and a similar high-resourced language to prevent over-fitting to small LRL data. Experiments demonstrate that massively multilingual models, even without any explicit adaptation, are surprisingly effective, achieving <a href="https://en.wikipedia.org/wiki/BLEU">BLEU scores</a> of up to 15.5 with no data from the LRL, and that the proposed similar-language regularization method improves over other adaptation methods by 1.7 BLEU points average over 4 LRL settings.</abstract>
      <video href="https://vimeo.com/305207187" />
      <doi>10.18653/v1/D18-1103</doi>
      <bibkey>neubig-hu-2018-rapid</bibkey>
      <pwccode url="https://github.com/neubig/rapid-adaptation" additional="false">neubig/rapid-adaptation</pwccode>
    </paper>
    <paper id="104">
      <title>Compact Personalized Models for Neural Machine Translation</title>
      <author><first>Joern</first><last>Wuebker</last></author>
      <author><first>Patrick</first><last>Simianer</last></author>
      <author><first>John</first><last>DeNero</last></author>
      <pages>881–886</pages>
      <url hash="e2cc58a0">D18-1104</url>
      <abstract>We propose and compare methods for gradient-based domain adaptation of self-attentive neural machine translation models. We demonstrate that a large proportion of model parameters can be frozen during adaptation with minimal or no reduction in translation quality by encouraging structured sparsity in the set of offset tensors during <a href="https://en.wikipedia.org/wiki/Machine_learning">learning</a> via group lasso regularization. We evaluate this technique for both batch and incremental adaptation across multiple data sets and language pairs. Our system architecturecombining a state-of-the-art self-attentive model with compact domain adaptationprovides high quality personalized machine translation that is both space and time efficient.</abstract>
      <video href="https://vimeo.com/305207608" />
      <doi>10.18653/v1/D18-1104</doi>
      <bibkey>wuebker-etal-2018-compact</bibkey>
    </paper>
    <paper id="105">
      <title>Self-Governing Neural Networks for On-Device Short Text Classification</title>
      <author><first>Sujith</first><last>Ravi</last></author>
      <author><first>Zornitsa</first><last>Kozareva</last></author>
      <pages>887–893</pages>
      <url hash="a7a3bfc5">D18-1105</url>
      <abstract>Deep neural networks reach state-of-the-art performance for wide range of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision</a> and speech applications. Yet, one of the biggest challenges is running these complex networks on devices such as <a href="https://en.wikipedia.org/wiki/Mobile_phone">mobile phones</a> or <a href="https://en.wikipedia.org/wiki/Smartwatch">smart watches</a> with tiny memory footprint and low computational capacity. We propose on-device Self-Governing Neural Networks (SGNNs), which learn compact projection vectors with local sensitive hashing. The key advantage of SGNNs over existing work is that they surmount the need for pre-trained word embeddings and <a href="https://en.wikipedia.org/wiki/Complex_network">complex networks</a> with huge parameters. We conduct extensive evaluation on dialog act classification and show significant improvement over state-of-the-art results. Our findings show that SGNNs are effective at capturing low-dimensional semantic text representations, while maintaining high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>.</abstract>
      <video href="https://vimeo.com/305197775" />
      <doi>10.18653/v1/D18-1105</doi>
      <bibkey>ravi-kozareva-2018-self-governing</bibkey>
    </paper>
    <paper id="106">
      <title>Supervised Domain Enablement Attention for Personalized Domain Classification</title>
      <author><first>Joo-Kyung</first><last>Kim</last></author>
      <author><first>Young-Bum</first><last>Kim</last></author>
      <pages>894–899</pages>
      <url hash="2d9bc102">D18-1106</url>
      <abstract>In large-scale domain classification for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a>, leveraging each user’s domain enablement information, which refers to the preferred or authenticated domains by the user, with attention mechanism has been shown to improve the overall domain classification performance. In this paper, we propose a supervised enablement attention mechanism, which utilizes sigmoid activation for the <a href="https://en.wikipedia.org/wiki/Attention">attention weighting</a> so that the <a href="https://en.wikipedia.org/wiki/Attention">attention</a> can be computed with more expressive power without the weight sum constraint of softmax attention. The attention weights are explicitly encouraged to be similar to the corresponding elements of the output one-hot vector, and self-distillation is used to leverage the attention information of the other enabled domains. By evaluating on the actual utterances from a large-scale IPDA, we show that our approach significantly improves domain classification performance</abstract>
      <video href="https://vimeo.com/305198062" />
      <doi>10.18653/v1/D18-1106</doi>
      <bibkey>kim-kim-2018-supervised</bibkey>
    </paper>
    <paper id="108">
      <title>Towards Dynamic Computation Graphs via Sparse Latent Structure</title>
      <author><first>Vlad</first><last>Niculae</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>905–911</pages>
      <url hash="488270fa">D18-1108</url>
      <attachment type="attachment" hash="d92b09c3">D18-1108.Attachment.zip</attachment>
      <abstract>Deep NLP models benefit from underlying structures in the datae.g., parse treestypically extracted using off-the-shelf <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>. Recent attempts to jointly learn the latent structure encounter a tradeoff : either make factorization assumptions that limit expressiveness, or sacrifice end-to-end differentiability. Using the recently proposed SparseMAP inference, which retrieves a sparse distribution over latent structures, we propose a novel approach for end-to-end learning of latent structure predictors jointly with a downstream predictor. To the best of our knowledge, our method is the first to enable unrestricted dynamic computation graph construction from the global latent structure, while maintaining <a href="https://en.wikipedia.org/wiki/Derivative">differentiability</a>.</abstract>
      <video href="https://vimeo.com/305198410" />
      <doi>10.18653/v1/D18-1108</doi>
      <bibkey>niculae-etal-2018-towards</bibkey>
      <pwccode url="https://github.com/vene/sparsemap" additional="false">vene/sparsemap</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="109">
      <title>Convolutional Neural Networks with Recurrent Neural Filters</title>
      <author><first>Yi</first><last>Yang</last></author>
      <pages>912–917</pages>
      <url hash="e0766eac">D18-1109</url>
      <abstract>We introduce a class of <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks (CNNs)</a> that utilize <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks (RNNs)</a> as convolution filters. A convolution filter is typically implemented as a linear affine transformation followed by a <a href="https://en.wikipedia.org/wiki/Nonlinear_system">non-linear function</a>, which fails to account for language compositionality. As a result, it limits the use of high-order filters that are often warranted for natural language processing tasks. In this work, we model convolution filters with <a href="https://en.wikipedia.org/wiki/Random-access_memory">RNNs</a> that naturally capture compositionality and long-term dependencies in language. We show that simple CNN architectures equipped with recurrent neural filters (RNFs) achieve results that are on par with the best published ones on the Stanford Sentiment Treebank and two answer sentence selection datasets.</abstract>
      <video href="https://vimeo.com/305198501" />
      <doi>10.18653/v1/D18-1109</doi>
      <bibkey>yang-2018-convolutional</bibkey>
      <pwccode url="https://github.com/bloomberg/cnn-rnf" additional="true">bloomberg/cnn-rnf</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="111">
      <title>Retrieval-Based Neural Code Generation</title>
      <author><first>Shirley Anugrah</first><last>Hayati</last></author>
      <author><first>Raphael</first><last>Olivier</last></author>
      <author><first>Pravalika</first><last>Avvaru</last></author>
      <author><first>Pengcheng</first><last>Yin</last></author>
      <author><first>Anthony</first><last>Tomasic</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>925–930</pages>
      <url hash="71fde365">D18-1111</url>
      <abstract>In models to generate program source code from <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>, representing this <a href="https://en.wikipedia.org/wiki/Source_code">code</a> in a <a href="https://en.wikipedia.org/wiki/Tree_structure">tree structure</a> has been a common approach. However, existing <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> often fail to generate complex code correctly due to a lack of ability to memorize large and complex structures. We introduce RECODE, a method based on subtree retrieval that makes it possible to explicitly reference existing code examples within a neural code generation model. First, we retrieve sentences that are similar to input sentences using a dynamic-programming-based sentence similarity scoring method. Next, we extract n-grams of action sequences that build the associated <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">abstract syntax tree</a>. Finally, we increase the probability of actions that cause the retrieved n-gram action subtree to be in the predicted code. We show that our <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">approach</a> improves the performance on two <a href="https://en.wikipedia.org/wiki/Code_generation_(compiler)">code generation tasks</a> by up to +2.6 BLEU.</abstract>
      <video href="https://vimeo.com/305213468" />
      <doi>10.18653/v1/D18-1111</doi>
      <bibkey>hayati-etal-2018-retrieval</bibkey>
      <pwccode url="https://github.com/sweetpeach/ReCode" additional="false">sweetpeach/ReCode</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/django">Django</pwcdataset>
    </paper>
    <paper id="112">
      <title>SQL-to-Text Generation with Graph-to-Sequence Model<fixed-case>SQL</fixed-case>-to-Text Generation with Graph-to-Sequence Model</title>
      <author><first>Kun</first><last>Xu</last></author>
      <author><first>Lingfei</first><last>Wu</last></author>
      <author><first>Zhiguo</first><last>Wang</last></author>
      <author><first>Yansong</first><last>Feng</last></author>
      <author><first>Vadim</first><last>Sheinin</last></author>
      <pages>931–936</pages>
      <url hash="ce3506d5">D18-1112</url>
      <abstract>Previous work approaches the SQL-to-text generation task using vanilla Seq2Seq models, which may not fully capture the inherent <a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">graph-structured information</a> in <a href="https://en.wikipedia.org/wiki/SQL">SQL query</a>. In this paper, we propose a graph-to-sequence model to encode the global structure information into node embeddings. This <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> can effectively learn the correlation between the SQL query pattern and its interpretation. Experimental results on the WikiSQL dataset and Stackoverflow dataset show that our model outperforms the Seq2Seq and Tree2Seq baselines, achieving the state-of-the-art performance.</abstract>
      <video href="https://vimeo.com/305213739" />
      <doi>10.18653/v1/D18-1112</doi>
      <bibkey>xu-etal-2018-sql</bibkey>
      <pwccode url="https://github.com/IBM/SQL-to-Text" additional="false">IBM/SQL-to-Text</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="113">
      <title>Generating Syntactic Paraphrases</title>
      <author><first>Emilie</first><last>Colin</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>937–943</pages>
      <url hash="944ec103">D18-1113</url>
      <abstract>We study the automatic generation of syntactic paraphrases using four different models for generation : data-to-text generation, text-to-text generation, text reduction and text expansion, We derive training data for each of these tasks from the WebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input.</abstract>
      <video href="https://vimeo.com/305214075" />
      <doi>10.18653/v1/D18-1113</doi>
      <bibkey>colin-gardent-2018-generating</bibkey>
    </paper>
    <paper id="116">
      <title>Toward Fast and Accurate Neural Discourse Segmentation</title>
      <author><first>Yizhong</first><last>Wang</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <author><first>Jingfeng</first><last>Yang</last></author>
      <pages>962–967</pages>
      <url hash="4c119a3c">D18-1116</url>
      <abstract>Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse analysis</a>. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance.</abstract>
      <video href="https://vimeo.com/306361340" />
      <doi>10.18653/v1/D18-1116</doi>
      <bibkey>wang-etal-2018-toward</bibkey>
    </paper>
    <paper id="118">
      <title>Cascaded Mutual Modulation for Visual Reasoning</title>
      <author><first>Yiqun</first><last>Yao</last></author>
      <author><first>Jiaming</first><last>Xu</last></author>
      <author><first>Feng</first><last>Wang</last></author>
      <author><first>Bo</first><last>Xu</last></author>
      <pages>975–980</pages>
      <url hash="bbd2295a">D18-1118</url>
      <attachment type="attachment" hash="00000000">D18-1118.Attachment.zip</attachment>
      <abstract>Visual reasoning is a special visual question answering problem that is multi-step and compositional by nature, and also requires intensive text-vision interactions. We propose CMM : Cascaded Mutual Modulation as a novel end-to-end visual reasoning model. CMM includes a <a href="https://en.wikipedia.org/wiki/Comprehension_(logic)">multi-step comprehension process</a> for both question and image. In each step, we use a Feature-wise Linear Modulation (FiLM) technique to enable textual / visual pipeline to mutually control each other. Experiments show that CMM significantly outperforms most related models, and reach state-of-the-arts on two visual reasoning benchmarks : CLEVR and NLVR, collected from both synthetic and natural languages. Ablation studies confirm the effectiveness of CMM to comprehend <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language logics</a> under the guidence of images. Our code is available at.<url>https://github.com/FlamingHorizon/CMM-VR</url>.</abstract>
      <video href="https://vimeo.com/306362249" />
      <doi>10.18653/v1/D18-1118</doi>
      <bibkey>yao-etal-2018-cascaded</bibkey>
      <pwccode url="https://github.com/FlamingHorizon/CMM-VR" additional="false">FlamingHorizon/CMM-VR</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nlvr">NLVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="119">
      <title>How agents see things : On visual representations in an emergent language game</title>
      <author><first>Diane</first><last>Bouchacourt</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>981–985</pages>
      <url hash="01f6cbbc">D18-1119</url>
      <abstract>There is growing interest in the <a href="https://en.wikipedia.org/wiki/Language">language</a> developed by agents interacting in emergent-communication settings. Earlier studies have focused on the agents’ symbol usage, rather than on their <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representation of visual input</a>. In this paper, we consider the referential games of Lazaridou et al. (2017), and investigate the representations the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> develop during their evolving interaction. We find that the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> establish successful communication by inducing visual representations that almost perfectly align with each other, but, surprisingly, do not capture the conceptual properties of the objects depicted in the input images. We conclude that, if we care about developing language-like communication systems, we must pay more attention to the visual semantics agents associate to the symbols they use.</abstract>
      <video href="https://vimeo.com/306362292" />
      <doi>10.18653/v1/D18-1119</doi>
      <bibkey>bouchacourt-baroni-2018-agents</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="121">
      <title>Put It Back : Entity Typing with Language Model Enhancement</title>
      <author><first>Ji</first><last>Xin</last></author>
      <author><first>Hao</first><last>Zhu</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>993–998</pages>
      <url hash="36405925">D18-1121</url>
      <abstract>Entity typing aims to classify semantic types of an entity mention in a specific context. Most existing <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> obtain training data using distant supervision, and inevitably suffer from the problem of noisy labels. To address this issue, we propose <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity typing</a> with language model enhancement. It utilizes a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> to measure the compatibility between context sentences and labels, and thereby automatically focuses more on context-dependent labels. Experiments on benchmark datasets demonstrate that our method is capable of enhancing the entity typing model with information from the language model, and significantly outperforms the state-of-the-art baseline. Code and data for this paper can be found from.<url>https://github.com/thunlp/LME</url>.</abstract>
      <doi>10.18653/v1/D18-1121</doi>
      <bibkey>xin-etal-2018-put</bibkey>
      <pwccode url="https://github.com/thunlp/LME" additional="false">thunlp/LME</pwccode>
    </paper>
    <paper id="123">
      <title>PubSE : A Hierarchical Model for Publication Extraction from Academic Homepages<fixed-case>P</fixed-case>ub<fixed-case>SE</fixed-case>: A Hierarchical Model for Publication Extraction from Academic Homepages</title>
      <author><first>Yiqing</first><last>Zhang</last></author>
      <author><first>Jianzhong</first><last>Qi</last></author>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Chuandong</first><last>Yin</last></author>
      <pages>1005–1010</pages>
      <url hash="47bb1605">D18-1123</url>
      <attachment type="attachment" hash="f6a85969">D18-1123.Attachment.pdf</attachment>
      <abstract>Publication information in a researcher’s academic homepage provides insights about the researcher’s expertise, research interests, and collaboration networks. We aim to extract all the <a href="https://en.wikipedia.org/wiki/Article_(publishing)">publication strings</a> from a given academic homepage. This is a challenging task because the publication strings in different academic homepages may be located at different positions with different structures. To capture the positional and structural diversity, we propose an end-to-end hierarchical model named PubSE based on Bi-LSTM-CRF. We further propose an alternating training method for training the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Experiments on real data show that PubSE outperforms the state-of-the-art <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> by up to 11.8 % in <a href="https://en.wikipedia.org/wiki/F-number">F1-score</a>.</abstract>
      <doi>10.18653/v1/D18-1123</doi>
      <bibkey>zhang-etal-2018-pubse</bibkey>
    </paper>
    <paper id="126">
      <title>Effective Use of <a href="https://en.wikipedia.org/wiki/Context_(computing)">Context</a> in Noisy Entity Linking</title>
      <author><first>David</first><last>Mueller</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>1024–1029</pages>
      <url hash="afddd0a6">D18-1126</url>
      <abstract>To disambiguate between closely related concepts, entity linking systems need to effectively distill cues from their context, which may be quite noisy. We investigate several techniques for using these <a href="https://en.wikipedia.org/wiki/Sensory_cue">cues</a> in the context of noisy entity linking on <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">short texts</a>. Our starting point is a state-of-the-art attention-based model from prior work ; while this model’s attention typically identifies context that is topically relevant, it fails to identify some of the most indicative surface strings, especially those exhibiting lexical overlap with the true title. Augmenting the model with convolutional networks over characters still leaves it largely unable to pick up on these cues compared to sparse features that target them directly, indicating that automatically learning how to identify relevant character-level context features is a hard problem. Our final system outperforms past work on the WikilinksNED test set by 2.8 % absolute.</abstract>
      <doi>10.18653/v1/D18-1126</doi>
      <bibkey>mueller-durrett-2018-effective</bibkey>
      <pwccode url="https://github.com/davidandym/wikilinks-ned" additional="false">davidandym/wikilinks-ned</pwccode>
    </paper>
    <paper id="127">
      <title>Exploiting Contextual Information via Dynamic Memory Network for Event Detection</title>
      <author><first>Shaobo</first><last>Liu</last></author>
      <author><first>Rui</first><last>Cheng</last></author>
      <author><first>Xiaoming</first><last>Yu</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <pages>1030–1035</pages>
      <url hash="49430900">D18-1127</url>
      <abstract>The task of event detection involves identifying and categorizing event triggers. Contextual information has been shown effective on the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. However, existing <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> which utilize <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> only process the context once. We argue that the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context</a> can be better exploited by processing the context multiple times, allowing the model to perform complex reasoning and to generate better <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context representation</a>, thus improving the overall performance. Meanwhile, dynamic memory network (DMN) has demonstrated promising capability in capturing <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> and has been applied successfully to various <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a>. In light of the multi-hop mechanism of the DMN to model the context, we propose the trigger detection dynamic memory network (TD-DMN) to tackle the event detection problem. We performed a five-fold cross-validation on the ACE-2005 dataset and experimental results show that the multi-hop mechanism does improve the performance and the proposed model achieves best F1 score compared to the state-of-the-art methods.</abstract>
      <doi>10.18653/v1/D18-1127</doi>
      <bibkey>liu-etal-2018-exploiting-contextual</bibkey>
      <pwccode url="https://github.com/AveryLiu/TD-DMN" additional="false">AveryLiu/TD-DMN</pwccode>
    </paper>
    <paper id="128">
      <title>Do explanations make VQA models more predictable to a human?<fixed-case>VQA</fixed-case> models more predictable to a human?</title>
      <author><first>Arjun</first><last>Chandrasekaran</last></author>
      <author><first>Viraj</first><last>Prabhu</last></author>
      <author><first>Deshraj</first><last>Yadav</last></author>
      <author><first>Prithvijit</first><last>Chattopadhyay</last></author>
      <author><first>Devi</first><last>Parikh</last></author>
      <pages>1036–1042</pages>
      <url hash="1b271ee5">D18-1128</url>
      <attachment type="attachment" hash="d2770a11">D18-1128.Attachment.zip</attachment>
      <abstract>A rich line of research attempts to make <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> more transparent by generating human-interpretable ‘explanations’ of their <a href="https://en.wikipedia.org/wiki/Decision-making">decision process</a>, especially for interactive tasks like Visual Question Answering (VQA). In this work, we analyze if existing explanations indeed make a VQA model   its responses as well as failures   more predictable to a human. Surprisingly, we find that they do not. On the other hand, we find that human-in-the-loop approaches that treat the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> as a black-box do.</abstract>
      <doi>10.18653/v1/D18-1128</doi>
      <bibkey>chandrasekaran-etal-2018-explanations</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="132">
      <title>Translating a Math Word Problem to a <a href="https://en.wikipedia.org/wiki/Expression_tree">Expression Tree</a></title>
      <author><first>Lei</first><last>Wang</last></author>
      <author><first>Yan</first><last>Wang</last></author>
      <author><first>Deng</first><last>Cai</last></author>
      <author><first>Dongxiang</first><last>Zhang</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <pages>1064–1069</pages>
      <url hash="396f7a7a">D18-1132</url>
      <abstract>Sequence-to-sequence (SEQ2SEQ) models have been successfully applied to automatic math word problem solving. Despite its simplicity, a drawback still remains : a math word problem can be correctly solved by more than one equations. This non-deterministic transduction harms the performance of <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation</a>. In this paper, by considering the uniqueness of <a href="https://en.wikipedia.org/wiki/Expression_tree">expression tree</a>, we propose an equation normalization method to normalize the duplicated equations. Moreover, we analyze the performance of three popular SEQ2SEQ models on the math word problem solving. We find that each <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has its own specialty in solving problems, consequently an ensemble model is then proposed to combine their advantages. Experiments on dataset Math23 K show that the <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble model</a> with equation normalization significantly outperforms the previous state-of-the-art methods.</abstract>
      <doi>10.18653/v1/D18-1132</doi>
      <bibkey>wang-etal-2018-translating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/math23k">Math23K</pwcdataset>
    </paper>
    <paper id="133">
      <title>Semantic Linking in <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> for Answer Sentence Selection</title>
      <author><first>Massimo</first><last>Nicosia</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>1070–1076</pages>
      <url hash="64ec19de">D18-1133</url>
      <attachment type="attachment" hash="046392e8">D18-1133.Attachment.zip</attachment>
      <abstract>State-of-the-art <a href="https://en.wikipedia.org/wiki/Social_network">networks</a> that model relations between two pieces of text often use complex architectures and <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. In this paper, instead of focusing on architecture engineering, we take advantage of small amounts of labelled data that model semantic phenomena in text to encode matching features directly in the word representations. This greatly boosts the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of our reference network, while keeping the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> simple and fast to train. Our approach also beats a tree kernel model that uses similar input encodings, and neural models which use advanced attention and compare-aggregate mechanisms.</abstract>
      <doi>10.18653/v1/D18-1133</doi>
      <bibkey>nicosia-moschitti-2018-semantic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/trecqa">TrecQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="135">
      <title>Improving the results of string kernels in <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and Arabic dialect identification by adapting them to your test set<fixed-case>A</fixed-case>rabic dialect identification by adapting them to your test set</title>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <author><first>Andrei M.</first><last>Butnaru</last></author>
      <pages>1084–1090</pages>
      <url hash="a2b9d13d">D18-1135</url>
      <abstract>Recently, <a href="https://en.wikipedia.org/wiki/String_kernel">string kernels</a> have obtained state-of-the-art results in various text classification tasks such as Arabic dialect identification or native language identification. In this paper, we apply two simple yet effective transductive learning approaches to further improve the results of <a href="https://en.wikipedia.org/wiki/String_kernel">string kernels</a>. The first approach is based on interpreting the pairwise string kernel similarities between samples in the training set and samples in the test set as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a>. Our second approach is a simple self-training method based on two learning iterations. In the first <a href="https://en.wikipedia.org/wiki/Iteration">iteration</a>, a <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> is trained on the training set and tested on the test set, as usual. In the second iteration, a number of test samples (to which the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> associated higher confidence scores) are added to the training set for another round of training. However, the ground-truth labels of the added test samples are not necessary. Instead, we use the labels predicted by the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> in the first training iteration. By adapting <a href="https://en.wikipedia.org/wiki/String_kernel">string kernels</a> to the <a href="https://en.wikipedia.org/wiki/Test_set">test set</a>, we report significantly better accuracy rates in English polarity classification and Arabic dialect identification.</abstract>
      <doi>10.18653/v1/D18-1135</doi>
      <bibkey>ionescu-butnaru-2018-improving</bibkey>
    </paper>
    <paper id="137">
      <title>Improving Multi-label Emotion Classification via Sentiment Classification with Dual Attention Transfer Network</title>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Luís</first><last>Marujo</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <author><first>Pradeep</first><last>Karuturi</last></author>
      <author><first>William</first><last>Brendel</last></author>
      <pages>1097–1102</pages>
      <url hash="bee0d17b">D18-1137</url>
      <abstract>In this paper, we target at improving the performance of multi-label emotion classification with the help of sentiment classification. Specifically, we propose a new transfer learning architecture to divide the sentence representation into two different feature spaces, which are expected to respectively capture the general sentiment words and the other important emotion-specific words via a dual attention mechanism. Experimental results on two <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmark datasets</a> demonstrate the effectiveness of our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>.</abstract>
      <doi>10.18653/v1/D18-1137</doi>
      <bibkey>yu-etal-2018-improving</bibkey>
    </paper>
    <paper id="139">
      <title>Joint Aspect and Polarity Classification for Aspect-based Sentiment Analysis with End-to-End Neural Networks</title>
      <author><first>Martin</first><last>Schmitt</last></author>
      <author><first>Simon</first><last>Steinheber</last></author>
      <author><first>Konrad</first><last>Schreiber</last></author>
      <author><first>Benjamin</first><last>Roth</last></author>
      <pages>1109–1114</pages>
      <url hash="472dd5c3">D18-1139</url>
      <abstract>In this work, we propose a new <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for aspect-based sentiment analysis. In contrast to previous approaches, we jointly model the <a href="https://en.wikipedia.org/wiki/Detection_theory">detection of aspects</a> and the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification of their polarity</a> in an end-to-end trainable neural network. We conduct experiments with different neural architectures and word representations on the recent GermEval 2017 dataset. We were able to show considerable performance gains by using the joint modeling approach in all settings compared to pipeline approaches. The combination of a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> and fasttext embeddings outperformed the best submission of the shared task in 2017, establishing a new state of the art.</abstract>
      <doi>10.18653/v1/D18-1139</doi>
      <bibkey>schmitt-etal-2018-joint</bibkey>
    </paper>
    <paper id="140">
      <title>Representing Social Media Users for Sarcasm Detection</title>
      <author><first>Y. Alex</first><last>Kolchinski</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <pages>1115–1121</pages>
      <url hash="f275c53d">D18-1140</url>
      <attachment type="attachment" hash="c43aa221">D18-1140.Attachment.tgz</attachment>
      <abstract>We explore two methods for representing <a href="https://en.wikipedia.org/wiki/Author">authors</a> in the context of textual sarcasm detection : a Bayesian approach that directly represents authors’ propensities to be sarcastic, and a dense embedding approach that can learn interactions between the author and the text. Using the SARC dataset of Reddit comments, we show that augmenting a bidirectional RNN with these representations improves performance ; the Bayesian approach suffices in homogeneous contexts, whereas the added power of the dense embeddings proves valuable in more diverse ones.</abstract>
      <doi>10.18653/v1/D18-1140</doi>
      <bibkey>kolchinski-potts-2018-representing</bibkey>
      <pwccode url="https://github.com/kolchinski/reddit-sarc" additional="false">kolchinski/reddit-sarc</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sarc">SARC</pwcdataset>
    </paper>
    <paper id="141">
      <title>Syntactical Analysis of the Weaknesses of Sentiment Analyzers</title>
      <author><first>Rohil</first><last>Verma</last></author>
      <author><first>Samuel</first><last>Kim</last></author>
      <author><first>David</first><last>Walter</last></author>
      <pages>1122–1127</pages>
      <url hash="b7ef5ba0">D18-1141</url>
      <attachment type="attachment" hash="838d7a43">D18-1141.Attachment.zip</attachment>
      <abstract>We carry out a syntactic analysis of two state-of-the-art sentiment analyzers, Google Cloud Natural Language and Stanford CoreNLP, to assess their classification accuracy on sentences with negative polarity items. We were motivated by the absence of studies investigating <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analyzer</a> performance on sentences with polarity items, a common construct in <a href="https://en.wikipedia.org/wiki/Human_language">human language</a>. Our analysis focuses on two sentential structures : <a href="https://en.wikipedia.org/wiki/Downward_entailment">downward entailment</a> and non-monotone quantifiers ; and demonstrates weaknesses of Google Natural Language and CoreNLP in capturing polarity item information. We describe the particular syntactic phenomenon that these analyzers fail to understand that any ideal <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analyzer</a> must. We also provide a set of 150 test sentences that any ideal <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analyzer</a> must be able to understand.</abstract>
      <doi>10.18653/v1/D18-1141</doi>
      <bibkey>verma-etal-2018-syntactical</bibkey>
    </paper>
    <paper id="142">
      <title>Is Nike female? Exploring the role of <a href="https://en.wikipedia.org/wiki/Sound_symbolism">sound symbolism</a> in predicting brand name gender<fixed-case>N</fixed-case>ike female? Exploring the role of sound symbolism in predicting brand name gender</title>
      <author><first>Sridhar</first><last>Moorthy</last></author>
      <author><first>Ruth</first><last>Pogacar</last></author>
      <author><first>Samin</first><last>Khan</last></author>
      <author><first>Yang</first><last>Xu</last></author>
      <pages>1128–1132</pages>
      <url hash="aae5b8d4">D18-1142</url>
      <attachment type="attachment" hash="c973e33a">D18-1142.Attachment.zip</attachment>
      <abstract>Are <a href="https://en.wikipedia.org/wiki/Brand">brand names</a> such as Nike female or male? Previous research suggests that the sound of a person’s first name is associated with the person’s gender, but no research has tried to use this knowledge to assess the gender of brand names. We present a simple computational approach that uses <a href="https://en.wikipedia.org/wiki/Sound_symbolism">sound symbolism</a> to address this open issue. Consistent with previous research, a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on various linguistic features of name endings predicts human gender with high <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>. Applying this model to a data set of over a thousand commercially-traded brands in 17 product categories, our results reveal an overall bias toward male names, cutting across both male-oriented product categories as well as female-oriented categories. In addition, we find variation within categories, suggesting that firms might be seeking to imbue their brands with differentiating characteristics as part of their competitive strategy.</abstract>
      <doi>10.18653/v1/D18-1142</doi>
      <bibkey>moorthy-etal-2018-nike</bibkey>
    </paper>
    <paper id="143">
      <title>Improving Large-Scale Fact-Checking using Decomposable Attention Models and Lexical Tagging</title>
      <author><first>Nayeon</first><last>Lee</last></author>
      <author><first>Chien-Sheng</first><last>Wu</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>1133–1138</pages>
      <url hash="4954a69a">D18-1143</url>
      <abstract>Fact-checking of textual sources needs to effectively extract relevant information from large knowledge bases. In this paper, we extend an existing pipeline approach to better tackle this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>. We propose a neural ranker using a decomposable attention model that dynamically selects sentences to achieve promising improvement in evidence retrieval F1 by 38.80 %, with (x65) speedup compared to a TF-IDF method. Moreover, we incorporate lexical tagging methods into our pipeline framework to simplify the tasks and render the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> more generalizable. As a result, our <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> achieves promising performance on a large-scale fact extraction and verification dataset with speedup.</abstract>
      <doi>10.18653/v1/D18-1143</doi>
      <bibkey>lee-etal-2018-improving</bibkey>
    </paper>
    <paper id="146">
      <title>Somm : Into the Model<fixed-case>S</fixed-case>omm: Into the Model</title>
      <author><first>Shengli</first><last>Hu</last></author>
      <pages>1153–1159</pages>
      <url hash="ac716190">D18-1146</url>
      <abstract>To what extent could the <a href="https://en.wikipedia.org/wiki/Sommelier">sommelier profession</a>, or wine stewardship, be displaced by <a href="https://en.wikipedia.org/wiki/Algorithm">machine leaning algorithms</a>? There are at least three essential skills that make a qualified <a href="https://en.wikipedia.org/wiki/Sommelier">sommelier</a> : wine theory, blind tasting, and beverage service, as exemplified in the rigorous certification processes of certified sommeliers and above (advanced and master) with the most authoritative body in the industry, the Court of Master Sommelier (hereafter CMS). We propose and train corresponding machine learning models that match these skills, and compare algorithmic results with real data collected from a large group of wine professionals. We find that our machine learning models outperform human sommeliers on most tasks   most notably in the section of blind tasting, where hierarchically supervised Latent Dirichlet Allocation outperforms <a href="https://en.wikipedia.org/wiki/Sommelier">sommeliers’ judgment calls</a> by over 6 % in terms of F1-score ; and in the section of beverage service, especially wine and food pairing, a modified Siamese neural network based on BiLSTM achieves better results than <a href="https://en.wikipedia.org/wiki/Sommelier">sommeliers</a> by 2 %. This demonstrates, contrary to popular opinion in the industry, that the sommelier profession is at least to some extent automatable, barring economic (Kleinberg et al., 2017) and psychological (Dietvorst et al., 2015) complications.</abstract>
      <doi>10.18653/v1/D18-1146</doi>
      <bibkey>hu-2018-somm</bibkey>
    </paper>
    <paper id="148">
      <title>The Remarkable Benefit of User-Level Aggregation for Lexical-based Population-Level Predictions</title>
      <author><first>Salvatore</first><last>Giorgi</last></author>
      <author><first>Daniel</first><last>Preoţiuc-Pietro</last></author>
      <author><first>Anneke</first><last>Buffone</last></author>
      <author><first>Daniel</first><last>Rieman</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>1167–1172</pages>
      <url hash="85e049d6">D18-1148</url>
      <attachment type="attachment" hash="2ef58675">D18-1148.Attachment.zip</attachment>
      <abstract>Nowcasting based on social media text promises to provide unobtrusive and near real-time predictions of community-level outcomes. These outcomes are typically regarding people, but the data is often aggregated without regard to users in the Twitter populations of each community. This paper describes a simple yet effective method for building community-level models using Twitter language aggregated by user. Results on four different U.S. county-level tasks, spanning demographic, health, and psychological outcomes show large and consistent improvements in prediction accuracies (e.g. from Pearson r=.73 to.82 for median income prediction or r=.37 to.47 for life satisfaction prediction) over the standard approach of aggregating all tweets. We make our aggregated and anonymized community-level data, derived from 37 billion tweets   over 1 billion of which were mapped to counties, available for research.</abstract>
      <doi>10.18653/v1/D18-1148</doi>
      <bibkey>giorgi-etal-2018-remarkable</bibkey>
    </paper>
    <paper id="149">
      <title>Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement</title>
      <author><first>Jason</first><last>Lee</last></author>
      <author><first>Elman</first><last>Mansimov</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>1173–1182</pages>
      <url hash="0c7dc425">D18-1149</url>
      <attachment type="attachment" hash="7a8a72e4">D18-1149.Attachment.pdf</attachment>
      <abstract>We propose a conditional non-autoregressive neural sequence model based on <a href="https://en.wikipedia.org/wiki/Iterative_refinement">iterative refinement</a>. The proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is designed based on the principles of <a href="https://en.wikipedia.org/wiki/Latent_variable_model">latent variable models</a> and denoising autoencoders, and is generally applicable to any sequence generation task. We extensively evaluate the proposed model on machine translation (En-De and En-Ro) and image caption generation, and observe that it significantly speeds up decoding while maintaining the generation quality comparable to the autoregressive counterpart.</abstract>
      <video href="https://vimeo.com/305207923" />
      <doi>10.18653/v1/D18-1149</doi>
      <bibkey>lee-etal-2018-deterministic</bibkey>
      <pwccode url="https://github.com/nyu-dl/dl4mt-nonauto" additional="true">nyu-dl/dl4mt-nonauto</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016-news">WMT 2016 News</pwcdataset>
    </paper>
    <paper id="151">
      <title>Targeted Syntactic Evaluation of <a href="https://en.wikipedia.org/wiki/Language_model">Language Models</a></title>
      <author><first>Rebecca</first><last>Marvin</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>1192–1202</pages>
      <url hash="bd8a459e">D18-1151</url>
      <attachment type="attachment" hash="708dbc34">D18-1151.Attachment.pdf</attachment>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Data_set">data set</a> for evaluating the <a href="https://en.wikipedia.org/wiki/Grammaticality">grammaticality</a> of the predictions of a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>. We automatically construct a large number of minimally different pairs of <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">English sentences</a>, each consisting of a grammatical and an ungrammatical sentence. The sentence pairs represent different variations of structure-sensitive phenomena : <a href="https://en.wikipedia.org/wiki/Agreement_(linguistics)">subject-verb agreement</a>, reflexive anaphora and negative polarity items. We expect a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> to assign a higher probability to the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">grammatical sentence</a> than the ungrammatical one. In an experiment using this <a href="https://en.wikipedia.org/wiki/Data_set">data set</a>, an LSTM language model performed poorly on many of the constructions. Multi-task training with a syntactic objective (CCG supertagging) improved the LSTM’s accuracy, but a large gap remained between its performance and the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of human participants recruited online. This suggests that there is considerable room for improvement over LSTMs in capturing <a href="https://en.wikipedia.org/wiki/Syntax_(programming_languages)">syntax</a> in a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>.</abstract>
      <video href="https://vimeo.com/305208737" />
      <doi>10.18653/v1/D18-1151</doi>
      <bibkey>marvin-linzen-2018-targeted</bibkey>
      <pwccode url="https://github.com/BeckyMarvin/LM_syneval" additional="true">BeckyMarvin/LM_syneval</pwccode>
    </paper>
    <paper id="153">
      <title>Efficient Contextualized Representation : Language Model Pruning for Sequence Labeling</title>
      <author><first>Liyuan</first><last>Liu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Jingbo</first><last>Shang</last></author>
      <author><first>Xiaotao</first><last>Gu</last></author>
      <author><first>Jian</first><last>Peng</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>1215–1225</pages>
      <url hash="f336b424">D18-1153</url>
      <abstract>Many efforts have been made to facilitate natural language processing tasks with pre-trained language models (LMs), and brought significant improvements to various applications. To fully leverage the nearly unlimited corpora and capture linguistic information of multifarious levels, large-size LMs are required ; but for a specific task, only parts of these information are useful. Such large-sized LMs, even in the inference stage, may cause heavy computation workloads, making them too time-consuming for large-scale applications. Here we propose to compress bulky LMs while preserving useful information with regard to a specific <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. As different layers of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> keep different information, we develop a layer selection method for <a href="https://en.wikipedia.org/wiki/Mathematical_model">model pruning</a> using sparsity-inducing regularization. By introducing the dense connectivity, we can detach any layer without affecting others, and stretch shallow and wide LMs to be deep and narrow. In <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">model training</a>, LMs are learned with layer-wise dropouts for better robustness. Experiments on two benchmark datasets demonstrate the effectiveness of our <a href="https://en.wikipedia.org/wiki/Methodology">method</a>.</abstract>
      <video href="https://vimeo.com/305209444" />
      <doi>10.18653/v1/D18-1153</doi>
      <bibkey>liu-etal-2018-efficient</bibkey>
      <pwccode url="https://github.com/LiyuanLucasLiu/LD-Net" additional="false">LiyuanLucasLiu/LD-Net</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="154">
      <title>Automatic Event Salience Identification</title>
      <author><first>Zhengzhong</first><last>Liu</last></author>
      <author><first>Chenyan</first><last>Xiong</last></author>
      <author><first>Teruko</first><last>Mitamura</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>1226–1236</pages>
      <url hash="33b77f88">D18-1154</url>
      <abstract>Identifying the salience (i.e. importance) of discourse units is an important task in <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding</a>. While <a href="https://en.wikipedia.org/wiki/Event_(probability_theory)">events</a> play important roles in <a href="https://en.wikipedia.org/wiki/Text_corpus">text documents</a>, little research exists on analyzing their saliency status. This paper empirically studies Event Salience and proposes two salience detection models based on <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>. The <a href="https://en.wikipedia.org/wiki/First_law_of_thermodynamics">first</a> is a feature based salience model that incorporates cohesion among <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse units</a>. The second is a neural model that captures more complex interactions between <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse units</a>. In our new large-scale event salience corpus, both methods significantly outperform the strong frequency baseline, while our neural model further improves the feature based one by a large margin. Our analyses demonstrate that our neural model captures interesting connections between <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">salience</a> and discourse unit relations (e.g., <a href="https://en.wikipedia.org/wiki/Scripting_language">scripts</a> and frame structures).</abstract>
      <video href="https://vimeo.com/305198570" />
      <doi>10.18653/v1/D18-1154</doi>
      <bibkey>liu-etal-2018-automatic</bibkey>
      <pwccode url="https://github.com/hunterhector/EventSalience" additional="false">hunterhector/EventSalience</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/new-york-times-annotated-corpus">New York Times Annotated Corpus</pwcdataset>
    </paper>
    <paper id="158">
      <title>Collective Event Detection via a Hierarchical and Bias Tagging Networks with Gated Multi-level Attention Mechanisms</title>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Hang</first><last>Yang</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Yantao</first><last>Jia</last></author>
      <pages>1267–1276</pages>
      <url hash="b65cbc81">D18-1158</url>
      <abstract>Traditional approaches to the task of ACE event detection primarily regard multiple events in one sentence as independent ones and recognize them separately by using sentence-level information. However, events in one sentence are usually interdependent and sentence-level information is often insufficient to resolve <a href="https://en.wikipedia.org/wiki/Ambiguity">ambiguities</a> for some types of events. This paper proposes a novel framework dubbed as Hierarchical and Bias Tagging Networks with Gated Multi-level Attention Mechanisms (HBTNGMA) to solve the two problems simultaneously. Firstly, we propose a hierachical and bias tagging networks to detect multiple events in one sentence collectively. Then, we devise a gated multi-level attention to automatically extract and dynamically fuse the sentence-level and document-level information. The experimental results on the widely used ACE 2005 dataset show that our approach significantly outperforms other state-of-the-art methods.</abstract>
      <video href="https://vimeo.com/305199664" />
      <doi>10.18653/v1/D18-1158</doi>
      <bibkey>chen-etal-2018-collective</bibkey>
      <pwccode url="https://github.com/yubochen/NBTNGMA4ED" additional="false">yubochen/NBTNGMA4ED</pwccode>
    </paper>
    <paper id="159">
      <title>Valency-Augmented Dependency Parsing</title>
      <author><first>Tianze</first><last>Shi</last></author>
      <author><first>Lillian</first><last>Lee</last></author>
      <pages>1277–1291</pages>
      <url hash="fa6c273e">D18-1159</url>
      <attachment type="attachment" hash="b8920385">D18-1159.Attachment.zip</attachment>
      <abstract>We present a complete, automated, and efficient approach for utilizing valency analysis in making dependency parsing decisions. It includes extraction of valency patterns, a probabilistic model for tagging these patterns, and a joint decoding process that explicitly considers the number and types of each token’s syntactic dependents. On 53 treebanks representing 41 languages in the Universal Dependencies data, we find that incorporating valency information yields higher precision and F1 scores on the core arguments (subjects and complements) and functional relations (e.g., auxiliaries) that we employ for <a href="https://en.wikipedia.org/wiki/Valency_(linguistics)">valency analysis</a>. Precision on core arguments improves from 80.87 to 85.43. We further show that our approach can be applied to an ostensibly different formalism and dataset, Tree Adjoining Grammar as extracted from the Penn Treebank ; there, we outperform the previous state-of-the-art labeled attachment score by 0.7. Finally, we explore the potential of extending valency patterns beyond their traditional domain by confirming their helpfulness in improving PP attachment decisions.</abstract>
      <video href="https://vimeo.com/305214708" />
      <doi>10.18653/v1/D18-1159</doi>
      <bibkey>shi-lee-2018-valency</bibkey>
      <pwccode url="https://github.com/tzshi/valency-parser-emnlp18" additional="false">tzshi/valency-parser-emnlp18</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="160">
      <title>Unsupervised Learning of Syntactic Structure with Invertible Neural Projections</title>
      <author><first>Junxian</first><last>He</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <pages>1292–1302</pages>
      <url hash="85a93b57">D18-1160</url>
      <abstract>Unsupervised learning of syntactic structure is typically performed using <a href="https://en.wikipedia.org/wiki/Generative_model">generative models</a> with <a href="https://en.wikipedia.org/wiki/Latent_variable">discrete latent variables</a> and <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial parameters</a>. In most cases, these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have not leveraged continuous word representations. In this work, we propose a novel <a href="https://en.wikipedia.org/wiki/Generative_model">generative model</a> that jointly learns discrete syntactic structure and continuous word representations in an unsupervised fashion by cascading an invertible neural network with a structured generative prior. We show that the invertibility condition allows for efficient <a href="https://en.wikipedia.org/wiki/Exact_inference">exact inference</a> and marginal likelihood computation in our model so long as the <a href="https://en.wikipedia.org/wiki/Prior_probability">prior</a> is well-behaved. In experiments we instantiate our approach with both Markov and tree-structured priors, evaluating on two tasks : part-of-speech (POS) induction, and unsupervised dependency parsing without gold POS annotation. On the <a href="https://en.wikipedia.org/wiki/Penn_Treebank">Penn Treebank</a>, our <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov-structured model</a> surpasses state-of-the-art results on POS induction. Similarly, we find that our tree-structured model achieves state-of-the-art performance on unsupervised dependency parsing for the difficult training condition where neither gold POS annotation nor punctuation-based constraints are available.</abstract>
      <video href="https://vimeo.com/305215139" />
      <doi>10.18653/v1/D18-1160</doi>
      <bibkey>he-etal-2018-unsupervised</bibkey>
      <pwccode url="https://github.com/jxhe/struct-learning-with-flow" additional="false">jxhe/struct-learning-with-flow</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="164">
      <title>Tell-and-Answer : Towards Explainable Visual Question Answering using Attributes and Captions</title>
      <author><first>Qing</first><last>Li</last></author>
      <author><first>Jianlong</first><last>Fu</last></author>
      <author><first>Dongfei</first><last>Yu</last></author>
      <author><first>Tao</first><last>Mei</last></author>
      <author><first>Jiebo</first><last>Luo</last></author>
      <pages>1338–1346</pages>
      <url hash="b3360843">D18-1164</url>
      <abstract>In Visual Question Answering, most existing approaches adopt the <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">pipeline</a> of representing an image via pre-trained CNNs, and then using the uninterpretable CNN features in conjunction with the question to predict the answer. Although such end-to-end models might report promising performance, they rarely provide any insight, apart from the answer, into the VQA process. In this work, we propose to break up the end-to-end VQA into two steps : explaining and reasoning, in an attempt towards a more explainable VQA by shedding light on the intermediate results between these two steps. To that end, we first extract <a href="https://en.wikipedia.org/wiki/Attribute_(computing)">attributes</a> and generate descriptions as explanations for an image. Next, a reasoning module utilizes these explanations in place of the image to infer an answer. The advantages of such a breakdown include : (1) the attributes and captions can reflect what the system extracts from the image, thus can provide some insights for the predicted answer ; (2) these intermediate results can help identify the inabilities of the image understanding or the answer inference part when the predicted answer is wrong. We conduct extensive experiments on a popular VQA dataset and our system achieves comparable performance with the baselines, yet with added benefits of explanability and the inherent ability to further improve with higher quality explanations.</abstract>
      <video href="https://vimeo.com/306362344" />
      <doi>10.18653/v1/D18-1164</doi>
      <bibkey>li-etal-2018-tell</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco-captions">COCO Captions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="165">
      <title>Learning a Policy for Opportunistic Active Learning</title>
      <author><first>Aishwarya</first><last>Padmakumar</last></author>
      <author><first>Peter</first><last>Stone</last></author>
      <author><first>Raymond</first><last>Mooney</last></author>
      <pages>1347–1357</pages>
      <url hash="209e24b5">D18-1165</url>
      <attachment type="attachment" hash="f2a2aee7">D18-1165.Attachment.tgz</attachment>
      <abstract>Active learning identifies data points to label that are expected to be the most useful in improving a <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised model</a>. Opportunistic active learning incorporates <a href="https://en.wikipedia.org/wiki/Active_learning">active learning</a> into <a href="https://en.wikipedia.org/wiki/Interactive_learning">interactive tasks</a> that constrain possible queries during interactions. Prior work has shown that opportunistic active learning can be used to improve grounding of <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language descriptions</a> in an interactive object retrieval task. In this work, we use <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> for such an object retrieval task, to learn a policy that effectively trades off task completion with model improvement that would benefit future tasks.</abstract>
      <video href="https://vimeo.com/306362379" />
      <doi>10.18653/v1/D18-1165</doi>
      <bibkey>padmakumar-etal-2018-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="166">
      <title>RecipeQA : A Challenge Dataset for Multimodal Comprehension of Cooking Recipes<fixed-case>R</fixed-case>ecipe<fixed-case>QA</fixed-case>: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes</title>
      <author><first>Semih</first><last>Yagcioglu</last></author>
      <author><first>Aykut</first><last>Erdem</last></author>
      <author><first>Erkut</first><last>Erdem</last></author>
      <author><first>Nazli</first><last>Ikizler-Cinbis</last></author>
      <pages>1358–1368</pages>
      <url hash="a65f6bef">D18-1166</url>
      <attachment type="attachment" hash="fb0aa293">D18-1166.Attachment.pdf</attachment>
      <abstract>Understanding and reasoning about cooking recipes is a fruitful research direction towards enabling machines to interpret procedural text. In this work, we introduce RecipeQA, a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for multimodal comprehension of cooking recipes. It comprises of approximately 20 K instructional recipes with multiple modalities such as titles, descriptions and aligned set of <a href="https://en.wikipedia.org/wiki/Image">images</a>. With over 36 K automatically generated question-answer pairs, we design a set of comprehension and reasoning tasks that require joint understanding of images and text, capturing the temporal flow of events and making sense of <a href="https://en.wikipedia.org/wiki/Procedural_knowledge">procedural knowledge</a>. Our preliminary results indicate that RecipeQA will serve as a challenging test bed and an ideal benchmark for evaluating machine comprehension systems. The data and leaderboard are available at.<url>http://hucvl.github.io/recipeqa</url>.</abstract>
      <video href="https://vimeo.com/306363701" />
      <doi>10.18653/v1/D18-1166</doi>
      <bibkey>yagcioglu-etal-2018-recipeqa</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/recipeqa">RecipeQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/figureqa">FigureQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/movieqa">MovieQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tqa">TQA</pwcdataset>
    </paper>
    <paper id="168">
      <title>Localizing Moments in Video with Temporal Language</title>
      <author><first>Lisa Anne</first><last>Hendricks</last></author>
      <author><first>Oliver</first><last>Wang</last></author>
      <author><first>Eli</first><last>Shechtman</last></author>
      <author><first>Josef</first><last>Sivic</last></author>
      <author><first>Trevor</first><last>Darrell</last></author>
      <author><first>Bryan</first><last>Russell</last></author>
      <pages>1380–1390</pages>
      <url hash="b510601b">D18-1168</url>
      <attachment type="attachment" hash="f1d762de">D18-1168.Attachment.pdf</attachment>
      <abstract>Localizing moments in a longer video via <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language queries</a> is a new, challenging task at the intersection of language and video understanding. Though moment localization with <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> is similar to other language and vision tasks like <a href="https://en.wikipedia.org/wiki/Natural_language">natural language object retrieval</a> in images, moment localization offers an interesting opportunity to model temporal dependencies and reasoning in text. We propose a new model that explicitly reasons about different temporal segments in a video, and shows that temporal context is important for localizing phrases which include temporal language. To benchmark whether our model, and other recent video localization models, can effectively reason about temporal language, we collect the novel TEMPOral reasoning in video and language (TEMPO) dataset. Our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> consists of two parts : a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> with real videos and template sentences (TEMPO-Template Language) which allows for controlled studies on temporal language, and a human language dataset which consists of temporal sentences annotated by humans (TEMPO-Human Language).</abstract>
      <video href="https://vimeo.com/306365884" />
      <doi>10.18653/v1/D18-1168</doi>
      <bibkey>hendricks-etal-2018-localizing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/tempo">TEMPO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/clevr">CLEVR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/charades">Charades</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/didemo">DiDeMo</pwcdataset>
    </paper>
    <paper id="171">
      <title>Weeding out Conventionalized Metaphors : A Corpus of Novel Metaphor Annotations</title>
      <author><first>Erik-Lân</first><last>Do Dinh</last></author>
      <author><first>Hannah</first><last>Wieland</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>1412–1424</pages>
      <url hash="c90a74bd">D18-1171</url>
      <abstract>We encounter <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a> every day, but only a few jump out on us and make us stumble. However, little effort has been devoted to investigating more novel metaphors in comparison to general metaphor detection efforts. We attribute this gap primarily to the lack of larger datasets that distinguish between conventionalized, i.e., very common, and novel metaphors. The goal of this paper is to alleviate this situation by introducing a crowdsourced novel metaphor annotation layer for an existing metaphor corpus. Further, we analyze our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and investigate correlations between novelty and features that are typically used in metaphor detection, such as concreteness ratings and more semantic features like the Potential for <a href="https://en.wikipedia.org/wiki/Metaphor">Metaphoricity</a>. Finally, we present a <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline approach</a> to assess novelty in metaphors based on our <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>.</abstract>
      <doi>10.18653/v1/D18-1171</doi>
      <bibkey>do-dinh-etal-2018-weeding</bibkey>
      <pwccode url="https://github.com/UKPLab/emnlp2018-novel-metaphors" additional="false">UKPLab/emnlp2018-novel-metaphors</pwccode>
    </paper>
    <paper id="174">
      <title>Disambiguated skip-gram model</title>
      <author><first>Karol</first><last>Grzegorczyk</last></author>
      <author><first>Marcin</first><last>Kurdziel</last></author>
      <pages>1445–1454</pages>
      <url hash="cd823406">D18-1174</url>
      <attachment type="attachment" hash="c6b953e6">D18-1174.Attachment.zip</attachment>
      <abstract>We present disambiguated skip-gram : a neural-probabilistic model for learning multi-sense distributed representations of words. Disambiguated skip-gram jointly estimates a skip-gram-like context word prediction model and a <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation model</a>. Unlike previous probabilistic models for learning multi-sense word embeddings, disambiguated skip-gram is end-to-end differentiable and can be interpreted as a simple feed-forward neural network. We also introduce an effective pruning strategy for the <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> learned by disambiguated skip-gram. This allows us to control the granularity of representations learned by our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. In experimental evaluation disambiguated skip-gram improves state-of-the are results in several word sense induction benchmarks.</abstract>
      <doi>10.18653/v1/D18-1174</doi>
      <bibkey>grzegorczyk-kurdziel-2018-disambiguated</bibkey>
    </paper>
    <paper id="175">
      <title>Picking Apart Story Salads</title>
      <author><first>Su</first><last>Wang</last></author>
      <author><first>Eric</first><last>Holgate</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <author><first>Katrin</first><last>Erk</last></author>
      <pages>1455–1465</pages>
      <url hash="d59c0dd3">D18-1175</url>
      <abstract>During <a href="https://en.wikipedia.org/wiki/Natural_disaster">natural disasters</a> and conflicts, information about what happened is often confusing and messy, and distributed across many sources. We would like to be able to automatically identify relevant information and assemble it into coherent narratives of what happened. To make this task accessible to neural models, we introduce Story Salads, mixtures of multiple documents that can be generated at scale. By exploiting the <a href="https://en.wikipedia.org/wiki/Wikipedia_hierarchy">Wikipedia hierarchy</a>, we can generate <a href="https://en.wikipedia.org/wiki/Salad_(disambiguation)">salads</a> that exhibit challenging inference problems. Story salads give rise to a novel, challenging clustering task, where the objective is to group sentences from the same narratives. We demonstrate that simple bag-of-words similarity clustering falls short on this task, and that it is necessary to take into account global context and <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherence</a>.<i>Story Salads</i>, mixtures of multiple documents that can be generated at scale. By exploiting the Wikipedia hierarchy, we can generate salads that exhibit challenging inference problems. Story salads give rise to a novel, challenging clustering task, where the objective is to group sentences from the same narratives. We demonstrate that simple bag-of-words similarity clustering falls short on this task, and that it is necessary to take into account global context and coherence.</abstract>
      <doi>10.18653/v1/D18-1175</doi>
      <bibkey>wang-etal-2018-picking</bibkey>
    </paper>
    <paper id="176">
      <title>Dynamic Meta-Embeddings for Improved Sentence Representations</title>
      <author><first>Douwe</first><last>Kiela</last></author>
      <author><first>Changhan</first><last>Wang</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>1466–1477</pages>
      <url hash="68b7cde5">D18-1176</url>
      <abstract>While one of the first steps in many NLP systems is selecting what pre-trained word embeddings to use, we argue that such a step is better left for <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> to figure out by themselves. To that end, we introduce dynamic meta-embeddings, a simple yet effective method for the supervised learning of embedding ensembles, which leads to state-of-the-art performance within the same model class on a variety of tasks. We subsequently show how the technique can be used to shed new light on the usage of <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP systems</a>.</abstract>
      <doi>10.18653/v1/D18-1176</doi>
      <bibkey>kiela-etal-2018-dynamic</bibkey>
      <pwccode url="https://github.com/facebookresearch/DME" additional="true">facebookresearch/DME</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="177">
      <title>A Probabilistic Model for Joint Learning of Word Embeddings from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">Texts</a> and Images</title>
      <author><first>Melissa</first><last>Ailem</last></author>
      <author><first>Bowen</first><last>Zhang</last></author>
      <author><first>Aurelien</first><last>Bellet</last></author>
      <author><first>Pascal</first><last>Denis</last></author>
      <author><first>Fei</first><last>Sha</last></author>
      <pages>1478–1487</pages>
      <url hash="49a6a579">D18-1177</url>
      <abstract>Several recent studies have shown the benefits of combining language and perception to infer <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. These <a href="https://en.wikipedia.org/wiki/Multimodal_interaction">multimodal approaches</a> either simply combine pre-trained textual and visual representations (e.g. features extracted from convolutional neural networks), or use the latter to bias the learning of textual word embeddings. In this work, we propose a novel probabilistic model to formalize how linguistic and perceptual inputs can work in concert to explain the observed word-context pairs in a <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a>. Our approach learns textual and visual representations jointly : latent visual factors couple together a skip-gram model for co-occurrence in linguistic data and a generative latent variable model for visual data. Extensive experimental studies validate the proposed <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Concretely, on the tasks of assessing pairwise word similarity and image / caption retrieval, our approach attains equally competitive or stronger results when compared to other state-of-the-art multimodal models.</abstract>
      <doi>10.18653/v1/D18-1177</doi>
      <bibkey>ailem-etal-2018-probabilistic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="178">
      <title>Transfer and Multi-Task Learning for NounNoun Compound Interpretation</title>
      <author><first>Murhaf</first><last>Fares</last></author>
      <author><first>Stephan</first><last>Oepen</last></author>
      <author><first>Erik</first><last>Velldal</last></author>
      <pages>1488–1498</pages>
      <url hash="819f59f5">D18-1178</url>
      <abstract>In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task : semantic interpretation of nounnoun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> via parameter initialization and <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.</abstract>
      <doi>10.18653/v1/D18-1178</doi>
      <bibkey>fares-etal-2018-transfer</bibkey>
    </paper>
    <paper id="180">
      <title>Preposition Sense Disambiguation and Representation</title>
      <author><first>Hongyu</first><last>Gong</last></author>
      <author><first>Jiaqi</first><last>Mu</last></author>
      <author><first>Suma</first><last>Bhat</last></author>
      <author><first>Pramod</first><last>Viswanath</last></author>
      <pages>1510–1521</pages>
      <url hash="d685248a">D18-1180</url>
      <attachment type="attachment" hash="a7a7eff2">D18-1180.Attachment.zip</attachment>
      <abstract>Prepositions are highly polysemous, and their variegated senses encode significant semantic information. In this paper we match each preposition’s left- and right context, and their interplay to the geometry of the word vectors to the left and right of the <a href="https://en.wikipedia.org/wiki/Preposition_and_postposition">preposition</a>. Extracting these <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> from a large corpus and using them with <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> makes for an efficient preposition sense disambiguation (PSD) algorithm, which is comparable to and better than <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> on two benchmark datasets. Our reliance on no linguistic tool allows us to scale the PSD algorithm to a large corpus and learn sense-specific preposition representations. The crucial abstraction of <a href="https://en.wikipedia.org/wiki/Preposition_and_postposition">preposition senses</a> as word representations permits their use in downstream applicationsphrasal verb paraphrasing and preposition selectionwith new state-of-the-art results.</abstract>
      <doi>10.18653/v1/D18-1180</doi>
      <bibkey>gong-etal-2018-preposition</bibkey>
      <pwccode url="https://github.com/HongyuGong/PrepositionSenseDisambiguation" additional="false">HongyuGong/PrepositionSenseDisambiguation</pwccode>
    </paper>
    <paper id="181">
      <title>Auto-Encoding Dictionary Definitions into Consistent Word Embeddings</title>
      <author><first>Tom</first><last>Bosc</last></author>
      <author><first>Pascal</first><last>Vincent</last></author>
      <pages>1522–1532</pages>
      <url hash="7531d4f3">D18-1181</url>
      <attachment type="attachment" hash="1a681327">D18-1181.Attachment.zip</attachment>
      <abstract>Monolingual dictionaries are widespread and semantically rich resources. This paper presents a simple <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that learns to compute <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> by processing <a href="https://en.wikipedia.org/wiki/Dictionary_definition">dictionary definitions</a> and trying to reconstruct them. It exploits the inherent recursivity of dictionaries by encouraging consistency between the representations it uses as inputs and the representations it produces as outputs. The resulting <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> are shown to capture <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> better than regular distributional methods and other dictionary-based methods. In addition, our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> shows strong performance when trained exclusively on <a href="https://en.wikipedia.org/wiki/Dictionary">dictionary data</a> and generalizes in one shot.</abstract>
      <doi>10.18653/v1/D18-1181</doi>
      <bibkey>bosc-vincent-2018-auto</bibkey>
      <pwccode url="https://github.com/tombosc/cpae" additional="true">tombosc/cpae</pwccode>
    </paper>
    <paper id="183">
      <title>Neural Multitask Learning for Simile Recognition</title>
      <author><first>Lizhen</first><last>Liu</last></author>
      <author><first>Xiao</first><last>Hu</last></author>
      <author><first>Wei</first><last>Song</last></author>
      <author><first>Ruiji</first><last>Fu</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Guoping</first><last>Hu</last></author>
      <pages>1543–1553</pages>
      <url hash="a4238f16">D18-1183</url>
      <abstract>Simile is a special type of <a href="https://en.wikipedia.org/wiki/Metaphor">metaphor</a>, where comparators such as like and as are used to compare two objects. Simile recognition is to recognize <a href="https://en.wikipedia.org/wiki/Simile">simile sentences</a> and extract simile components, i.e., the tenor and the vehicle. This paper presents a study of simile recognition in <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>. We construct an annotated corpus for this research, which consists of 11.3k sentences that contain a <a href="https://en.wikipedia.org/wiki/Comparator">comparator</a>. We propose a neural network framework for jointly optimizing three tasks : simile sentence classification, simile component extraction and <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a>. The experimental results show that the neural network based approaches can outperform all rule-based and feature-based baselines. Both simile sentence classification and simile component extraction can benefit from <a href="https://en.wikipedia.org/wiki/Multitask_learning">multitask learning</a>. The <a href="https://en.wikipedia.org/wiki/Conjecture">former</a> can be solved very well, while the <a href="https://en.wikipedia.org/wiki/Conjecture">latter</a> is more difficult.</abstract>
      <doi>10.18653/v1/D18-1183</doi>
      <bibkey>liu-etal-2018-neural</bibkey>
    </paper>
    <paper id="188">
      <title>Question Generation from SQL Queries Improves Neural Semantic Parsing<fixed-case>SQL</fixed-case> Queries Improves Neural Semantic Parsing</title>
      <author><first>Daya</first><last>Guo</last></author>
      <author><first>Yibo</first><last>Sun</last></author>
      <author><first>Duyu</first><last>Tang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Jian</first><last>Yin</last></author>
      <author><first>Hong</first><last>Chi</last></author>
      <author><first>James</first><last>Cao</last></author>
      <author><first>Peng</first><last>Chen</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>1597–1607</pages>
      <url hash="4e760e30">D18-1188</url>
      <abstract>In this paper, we study how to learn a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> of state-of-the-art <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> with less supervised training data. We conduct our study on WikiSQL, the largest hand-annotated semantic parsing dataset to date. First, we demonstrate that question generation is an effective method that empowers us to learn a state-of-the-art neural network based semantic parser with thirty percent of the supervised training data. Second, we show that applying question generation to the full supervised training data further improves the state-of-the-art model. In addition, we observe that there is a logarithmic relationship between the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> and the amount of training data.</abstract>
      <doi>10.18653/v1/D18-1188</doi>
      <bibkey>guo-etal-2018-question</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitablequestions">WikiTableQuestions</pwcdataset>
    </paper>
    <paper id="189">
      <title>SemRegex : A Semantics-Based Approach for Generating <a href="https://en.wikipedia.org/wiki/Regular_expression">Regular Expressions</a> from Natural Language Specifications<fixed-case>S</fixed-case>em<fixed-case>R</fixed-case>egex: A Semantics-Based Approach for Generating Regular Expressions from Natural Language Specifications</title>
      <author><first>Zexuan</first><last>Zhong</last></author>
      <author><first>Jiaqi</first><last>Guo</last></author>
      <author><first>Wei</first><last>Yang</last></author>
      <author><first>Jian</first><last>Peng</last></author>
      <author><first>Tao</first><last>Xie</last></author>
      <author><first>Jian-Guang</first><last>Lou</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Dongmei</first><last>Zhang</last></author>
      <pages>1608–1618</pages>
      <url hash="00857a00">D18-1189</url>
      <abstract>Recent research proposes syntax-based approaches to address the problem of <a href="https://en.wikipedia.org/wiki/Computer_programming">generating programs</a> from <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language specifications</a>. These approaches typically train a sequence-to-sequence learning model using a syntax-based objective : <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximum likelihood estimation (MLE)</a>. Such syntax-based approaches do not effectively address the goal of generating semantically correct programs, because these approaches fail to handle Program Aliasing, i.e., semantically equivalent programs may have many syntactically different forms. To address this issue, in this paper, we propose a semantics-based approach named SemRegex. SemRegex provides solutions for a subtask of the program-synthesis problem : generating <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a> from <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. Different from the existing syntax-based approaches, SemRegex trains the model by maximizing the expected semantic correctness of the generated <a href="https://en.wikipedia.org/wiki/Regular_expression">regular expressions</a>. The semantic correctness is measured using the DFA-equivalence oracle, random test cases, and distinguishing test cases. The experiments on three public datasets demonstrate the superiority of SemRegex over the existing state-of-the-art approaches.</abstract>
      <doi>10.18653/v1/D18-1189</doi>
      <bibkey>zhong-etal-2018-semregex</bibkey>
    </paper>
    <paper id="190">
      <title>Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing</title>
      <author><first>Jonathan</first><last>Herzig</last></author>
      <author><first>Jonathan</first><last>Berant</last></author>
      <pages>1619–1629</pages>
      <url hash="f125fa89">D18-1190</url>
      <abstract>Building a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> quickly in a new domain is a fundamental challenge for conversational interfaces, as current semantic parsers require expensive supervision and lack the ability to generalize to new domains. In this paper, we introduce a zero-shot approach to <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> that can parse utterances in unseen domains while only being trained on examples in other source domains. First, we map an utterance to an abstract, domain independent, logical form that represents the structure of the logical form, but contains slots instead of KB constants. Then, we replace slots with KB constants via lexical alignment scores and global inference. Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> reaches an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">average accuracy</a> of 53.4 % on 7 domains in the OVERNIGHT dataset, substantially better than other zero-shot baselines, and performs as good as a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> trained on over 30 % of the target domain examples.</abstract>
      <doi>10.18653/v1/D18-1190</doi>
      <bibkey>herzig-berant-2018-decoupling</bibkey>
      <pwccode url="https://github.com/jonathanherzig/zero-shot-semantic-parsing" additional="false">jonathanherzig/zero-shot-semantic-parsing</pwccode>
    </paper>
    <paper id="192">
      <title>Mapping Language to Code in Programmatic Context</title>
      <author><first>Srinivasan</first><last>Iyer</last></author>
      <author><first>Ioannis</first><last>Konstas</last></author>
      <author><first>Alvin</first><last>Cheung</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <pages>1643–1652</pages>
      <url hash="e14d9fb6">D18-1192</url>
      <abstract>Source code is rarely written in isolation. It depends significantly on the <a href="https://en.wikipedia.org/wiki/Context_(computing)">programmatic context</a>, such as the class that the code would reside in. To study this phenomenon, we introduce the task of generating class member functions given English documentation and the programmatic context provided by the rest of the class. This task is challenging because the desired code can vary greatly depending on the functionality the class provides (e.g., a sort function may or may not be available when we are asked to return the smallest element in a particular member variable list). We introduce CONCODE, a new large dataset with over 100,000 examples consisting of Java classes from online code repositories, and develop a new encoder-decoder architecture that models the interaction between the method documentation and the class environment. We also present a detailed error analysis suggesting that there is significant room for future work on this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <doi>10.18653/v1/D18-1192</doi>
      <bibkey>iyer-etal-2018-mapping</bibkey>
      <pwccode url="https://github.com/sriniiyer/concode" additional="false">sriniiyer/concode</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/concode">CONCODE</pwcdataset>
    </paper>
    <paper id="193">
      <title>SyntaxSQLNet : Syntax Tree Networks for Complex and Cross-Domain Text-to-SQL Task<fixed-case>S</fixed-case>yntax<fixed-case>SQLN</fixed-case>et: Syntax Tree Networks for Complex and Cross-Domain Text-to-<fixed-case>SQL</fixed-case> Task</title>
      <author><first>Tao</first><last>Yu</last></author>
      <author><first>Michihiro</first><last>Yasunaga</last></author>
      <author><first>Kai</first><last>Yang</last></author>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Dongxu</first><last>Wang</last></author>
      <author><first>Zifan</first><last>Li</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>1653–1663</pages>
      <url hash="466eef9d">D18-1193</url>
      <abstract>Most existing studies in text-to-SQL tasks do not require generating complex SQL queries with multiple clauses or sub-queries, and generalizing to new, unseen databases. In this paper we propose SyntaxSQLNet, a syntax tree network to address the complex and cross-domain text-to-SQL generation task. SyntaxSQLNet employs a SQL specific syntax tree-based decoder with SQL generation path history and table-aware column attention encoders. We evaluate SyntaxSQLNet on a new large-scale text-to-SQL corpus containing databases with multiple tables and complex SQL queries containing multiple SQL clauses and nested queries. We use a database split setting where databases in the test set are unseen during training. Experimental results show that SyntaxSQLNet can handle a significantly greater number of complex SQL examples than prior work, outperforming the previous state-of-the-art <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> by 9.5 % in exact matching accuracy. To our knowledge, we are the first to study this complex text-to-SQL task. Our <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a> and models with the latest updates are available at.<url>https://yale-lily.github.io/seq2sql/spider</url>.</abstract>
      <doi>10.18653/v1/D18-1193</doi>
      <bibkey>yu-etal-2018-syntaxsqlnet</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="195">
      <title>Learning to Learn Semantic Parsers from Natural Language Supervision</title>
      <author><first>Igor</first><last>Labutov</last></author>
      <author><first>Bishan</first><last>Yang</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>1676–1690</pages>
      <url hash="e1ff0fbb">D18-1195</url>
      <abstract>As humans, we often rely on <a href="https://en.wikipedia.org/wiki/Language">language</a> to learn <a href="https://en.wikipedia.org/wiki/Language">language</a>. For example, when corrected in a conversation, we may learn from that correction, over time improving our <a href="https://en.wikipedia.org/wiki/Fluency">language fluency</a>. Inspired by this observation, we propose a <a href="https://en.wikipedia.org/wiki/Machine_learning">learning algorithm</a> for training semantic parsers from supervision (feedback) expressed in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>. Our <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> learns a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> from users’ corrections such as no, what I really meant was before his job, not after, by also simultaneously learning to parse this natural language feedback in order to leverage it as a form of <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a>. Unlike <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> with gold-standard logical forms, our method does not require the user to be familiar with the underlying logical formalism, and unlike <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> from <a href="https://en.wikipedia.org/wiki/Denotation">denotation</a>, it does not require the user to know the correct answer to their query. This makes our learning algorithm naturally scalable in settings where existing conversational logs are available and can be leveraged as training data. We construct a novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language feedback</a> in a conversational setting, and show that our method is effective at learning a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> from such <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language supervision</a>.</abstract>
      <doi>10.18653/v1/D18-1195</doi>
      <bibkey>labutov-etal-2018-learning</bibkey>
    </paper>
    <paper id="197">
      <title>What It Takes to Achieve 100 % Condition Accuracy on WikiSQL<fixed-case>W</fixed-case>iki<fixed-case>SQL</fixed-case></title>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Izzeddin</first><last>Gur</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Xifeng</first><last>Yan</last></author>
      <pages>1702–1711</pages>
      <url hash="5b13f70f">D18-1197</url>
      <abstract>WikiSQL is a newly released dataset for studying the <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language sequence</a> to SQL translation problem. The SQL queries in WikiSQL are simple : Each involves one relation and does not have any <a href="https://en.wikipedia.org/wiki/Join_(SQL)">join operation</a>. Despite of its simplicity, none of the publicly reported structured query generation models can achieve an <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> beyond 62 %, which is still far from enough for practical use. In this paper, we ask two questions, Why is the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> still low for such simple <a href="https://en.wikipedia.org/wiki/Information_retrieval">queries</a>? and What does it take to achieve 100 % accuracy on WikiSQL? To limit the scope of our study, we focus on the WHERE clause in <a href="https://en.wikipedia.org/wiki/SQL">SQL</a>. The answers will help us gain insights about the directions we should explore in order to further improve the translation accuracy. We will then investigate alternative solutions to realize the potential ceiling performance on WikiSQL. Our proposed <a href="https://en.wikipedia.org/wiki/Solution">solution</a> can reach up to 88.6 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">condition accuracy</a> on the WikiSQL dataset.</abstract>
      <doi>10.18653/v1/D18-1197</doi>
      <bibkey>yavuz-etal-2018-takes</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisql">WikiSQL</pwcdataset>
    </paper>
    <paper id="199">
      <title>Heuristically Informed Unsupervised Idiom Usage Recognition</title>
      <author><first>Changsheng</first><last>Liu</last></author>
      <author><first>Rebecca</first><last>Hwa</last></author>
      <pages>1723–1731</pages>
      <url hash="a6d4996d">D18-1199</url>
      <abstract>Many <a href="https://en.wikipedia.org/wiki/Idiom_(language_structure)">idiomatic expressions</a> can be interpreted figuratively or literally depending on their contexts. This paper proposes an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised learning method</a> for recognizing the intended usages of <a href="https://en.wikipedia.org/wiki/Idiom">idioms</a>. We treat the usages as a <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a> in <a href="https://en.wikipedia.org/wiki/Statistical_model">probabilistic models</a> and train them in a linguistically motivated feature space. Crucially, we show that <a href="https://en.wikipedia.org/wiki/Distributional_semantics">distributional semantics</a> is a helpful heuristic for distinguishing the literal usage of idioms, giving us a way to formulate a literal usage metric to estimate the likelihood that the <a href="https://en.wikipedia.org/wiki/Idiom">idiom</a> is intended literally. This information then serves as a form of distant supervision to guide the unsupervised training process for the <a href="https://en.wikipedia.org/wiki/Statistical_model">probabilistic models</a>. Experiments show that our overall model performs competitively against <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised methods</a>.</abstract>
      <video href="https://vimeo.com/305931117" />
      <doi>10.18653/v1/D18-1199</doi>
      <bibkey>liu-hwa-2018-heuristically</bibkey>
    <title_ar>التعرف على استخدام المصطلح غير الخاضع للإشراف علم وإرشادي</title_ar>
      <title_fr>Reconnaissance d'utilisation d'idiomes non supervisée éclairée de manière heuristique</title_fr>
      <title_pt>Reconhecimento de uso de idioma não supervisionado informado heuristicamente</title_pt>
      <title_es>Reconocimiento de uso de modismos no supervisados con información heurística</title_es>
      <title_zh>启发式谕无监督习语以法识之</title_zh>
      <title_ru>Эвристически информированное неконтролируемое распознавание использования идиомы</title_ru>
      <title_ja>ヒューリスティックインフォメーション非監督のイディオム用法認識</title_ja>
      <title_hi>Heuristically सूचित असुरक्षित मुहावरा उपयोग मान्यता</title_hi>
      <title_ga>Aitheantas Úsáide Idiom Gan Maoirseacht Heuristically Informed</title_ga>
      <title_ka>Heuristically Informed Unsupervised Idiom Usage Recognition</title_ka>
      <title_el>Αναγνώριση χρήσης ηλίθιου χωρίς επιτήρηση με ευρηματική ενημέρωση</title_el>
      <title_hu>Heurisztikailag tájékoztatott, felügyeletlen idióma használat felismerése</title_hu>
      <title_it>Riconoscimento dell'uso di idiomi non sorvegliati con informazioni euristiche</title_it>
      <title_kk>Жергілікті мәлімет берілмеген идиом пайдалануын анықтау</title_kk>
      <title_mk>Хеуристички информирано препознавање на ненадгледувано користење идиоми</title_mk>
      <title_ms>Pengenalan Penggunaan Idiom Tidak Dikawal Bermaklumat Secara Heuristik</title_ms>
      <title_lt>Heuristiniu būdu informuotas nenorėtas idiomų naudojimo pripažinimas</title_lt>
      <title_ml>നിരീക്ഷിക്കപ്പെടാത്ത ഐഡിയോ ഉപയോഗം തിരിച്ചറിയുക</title_ml>
      <title_mt>Ir-Rikonoxximent tal-Użu tal-Idjom Mhux Sorveljat b’Informazzjoni Ewristika</title_mt>
      <title_mn>Хуристикийн мэдээллээр дэмжигдэхгүй идэвхтэй хэрэглээ танилцуулах</title_mn>
      <title_no>Heuristisk informasjon utan oppretta bruk av språk</title_no>
      <title_pl>Rozpoznawanie nienadzorowanego użycia idiomów poinformowanych heurystycznie</title_pl>
      <title_sr>Heuristički informativno nepotrebno prepoznavanje korištenja idiota</title_sr>
      <title_ro>Recunoașterea utilizării idiomului nesupravegheat informată euristic</title_ro>
      <title_si>හෙයුරිස්ටිකින් තොරතුරු නැති අභාවිත භාවිතා අඳුරගන්න</title_si>
      <title_so>Heuristically Informed Unsupervised Idiom Usage Recognition</title_so>
      <title_sv>Heuristiskt informerad icke övervakad idiom användningsegenkänning</title_sv>
      <title_ta>கண்காணிக்கப்படாத அடையாளத்தின் பயன்பாடு அறிவிப்பு</title_ta>
      <title_ur>ہوریستیکی معلوم غیر محافظت دیوانے استعمال پتچانی</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_bg>Хеуристично информирано разпознаване на употребата на идиоми без надзор</title_bg>
      <title_da>Heuristisk informeret Uovervåget Idiom Brugsgenkendelse</title_da>
      <title_hr>Heuristički obaviješteno nepotrebno prepoznavanje primjene idiota</title_hr>
      <title_nl>Heuristisch geïnformeerde onbewakte idiomgebruiksherkenning</title_nl>
      <title_de>Heuristisch informierte nicht überwachte Idiom Usage Recognition</title_de>
      <title_id>Pengetahuan Penggunaan Idiom Tak Tersupervisi Diinformasikan Secara Heuristik</title_id>
      <title_ko>계발식 비감독 성어 용법 식별</title_ko>
      <title_fa>شناسایی استفاده از زبان‌های غیرقابل حیاتی</title_fa>
      <title_sw>Heuristically Informed Unsupervised Idiom Usage Recognition</title_sw>
      <title_sq>Njohja e përdorimit të Idiomit të Informuar Heuristikisht</title_sq>
      <title_af>Heuristies inligtig Onondersteunde Idiomgebruik herken</title_af>
      <title_tr>Gürjyksuz Maglumaty Jakyp Ullanmaky Tanamak</title_tr>
      <title_am>Unsupervised Idiom Usage Recognition</title_am>
      <title_hy>Heuristically Informed Unsupervised Idiom Usage Recognition</title_hy>
      <title_az>Heuristik m…ôlumatlarƒ± Qeyd edilm…ômi≈ü Dil Qullanƒ±mƒ± Tanƒ±ma</title_az>
      <title_bn>হিউরিস্টিক্যালিক তথ্য প্রদান করা অনভার করা আইডিয়াম ব্যবহার পরিচিতি</title_bn>
      <title_bs>Heuristički informativno nepotrebno prepoznavanje upotrebe idiota</title_bs>
      <title_ca>Reconosciment d'Us d'Idioms Sense Supervisió Informat Heuristicament</title_ca>
      <title_cs>Heuristicky informované nerezervované rozpoznávání použití idiomů</title_cs>
      <title_fi>Heuristisesti informoitu valvomaton idiomin käyttötunnistus</title_fi>
      <title_et>Heuristiliselt informeeritud järelevalveta idioomi kasutamise tuvastamine</title_et>
      <title_jv>Heuristik Info Gak Cocok Ati Lisanjut Panjenengan</title_jv>
      <title_he>Heuristically Informed Unsupervised Idiom Usage Recognition</title_he>
      <title_ha>Uncontrolled user ID Recognition</title_ha>
      <title_sk>Heuristično obveščeno prepoznavanje uporabe neustreznega idioma</title_sk>
      <title_bo>Heuristically Informed Unsupervised Idiom Usage Recognition</title_bo>
      <abstract_es>Muchas expresiones idiomáticas pueden interpretarse en sentido figurado o literal en función de sus contextos. Este artículo propone un método de aprendizaje no supervisado para reconocer los usos previstos de los modismos. Tratamos los usos como una variable latente en los modelos probabilísticos y los entrenamos en un espacio de características con motivación lingüística. Fundamentalmente, mostramos que la semántica distribucional es una heurística útil para distinguir el uso literal de los modismos, lo que nos da una forma de formular una métrica de uso literal para estimar la probabilidad de que el idioma esté destinado literalmente. Esta información sirve entonces como una forma de supervisión a distancia para guiar el proceso de entrenamiento no supervisado para los modelos probabilísticos. Los experimentos muestran que nuestro modelo general funciona de manera competitiva en comparación con los métodos supervisados.</abstract_es>
      <abstract_ar>يمكن تفسير العديد من التعبيرات الاصطلاحية مجازيًا أو حرفيًا اعتمادًا على سياقاتها. تقترح هذه الورقة طريقة تعلم غير خاضعة للإشراف للتعرف على الاستخدامات المقصودة للمصطلحات. نتعامل مع الاستخدامات كمتغير كامن في النماذج الاحتمالية وندربها في مساحة ميزة ذات دوافع لغوية. بشكل حاسم ، نظهر أن دلالات التوزيع هي دليل مفيد للتمييز بين الاستخدام الحرفي للمصطلحات ، مما يمنحنا طريقة لصياغة مقياس استخدام حرفي لتقدير احتمالية أن يكون المصطلح مقصودًا حرفيًا. تعمل هذه المعلومات بعد ذلك كشكل من أشكال الإشراف عن بعد لتوجيه عملية التدريب غير الخاضعة للإشراف للنماذج الاحتمالية. تظهر التجارب أن نموذجنا العام يؤدي بشكل تنافسي ضد الأساليب الخاضعة للإشراف.</abstract_ar>
      <abstract_pt>Muitas expressões idiomáticas podem ser interpretadas figurativamente ou literalmente, dependendo de seus contextos. Este artigo propõe um método de aprendizado não supervisionado para reconhecer os usos pretendidos de expressões idiomáticas. Tratamos os usos como uma variável latente em modelos probabilísticos e os treinamos em um espaço de traços lingüisticamente motivado. Crucialmente, mostramos que a semântica distribucional é uma heurística útil para distinguir o uso literal de expressões idiomáticas, dando-nos uma maneira de formular uma métrica de uso literal para estimar a probabilidade de que a expressão idiomática se destina literalmente. Essas informações servem então como uma forma de supervisão à distância para orientar o processo de treinamento não supervisionado para os modelos probabilísticos. Experimentos mostram que nosso modelo geral tem um desempenho competitivo em relação aos métodos supervisionados.</abstract_pt>
      <abstract_fr>De nombreuses expressions idiomatiques peuvent être interprétées au sens figuré ou littéral en fonction de leur contexte. Cet article propose une méthode d'apprentissage non supervisée pour reconnaître les usages prévus des expressions idiomatiques. Nous traitons les usages comme une variable latente dans les modèles probabilistes et les formons dans un espace de fonctionnalités motivé par la langue. Surtout, nous montrons que la sémantique distributionnelle est une heuristique utile pour distinguer l'usage littéral des idiomes, ce qui nous permet de formuler une métrique d'utilisation littérale pour estimer la probabilité que l'idiome soit conçu littéralement. Ces informations servent ensuite de forme de supervision à distance pour guider le processus de formation non supervisée pour les modèles probabilistes. Les expériences montrent que notre modèle global est compétitif par rapport aux méthodes supervisées.</abstract_fr>
      <abstract_ja>多くの成語表現は、その文脈に応じて、比喩的または文字通りに解釈することができる。本論文では、成語の意図された用法を認識するための無指導学習法を提案している。確率モデルにおける潜在変数として扱い、言語的に動機づけられた特徴空間で訓練する。重要なことに、分布セマンティクスは、成語の文字通りの使用法を区別するのに役立つヒューリスティックであることを示し、成語が文字通り意図されている可能性を推定するための文字通りの使用法指標を定式化する方法を提供します。この情報は、確率モデルのための監督されていないトレーニングプロセスを導くための遠隔監督の一形態として機能します。実験によると、当社の全体的なモデルは、監督された方法に対して競争的にパフォーマンスを発揮することが示されています。</abstract_ja>
      <abstract_hi>कई मुहावरेदार अभिव्यक्तियों को उनके संदर्भों के आधार पर आलंकारिक रूप से या शाब्दिक रूप से व्याख्या की जा सकती है। यह पेपर मुहावरों के इच्छित उपयोगों को पहचानने के लिए एक असुरक्षित सीखने की विधि का प्रस्ताव करता है। हम संभावित मॉडल में एक अव्यक्त चर के रूप में उपयोगों का इलाज करते हैं और उन्हें भाषाई रूप से प्रेरित सुविधा स्थान में प्रशिक्षित करते हैं। महत्वपूर्ण रूप से, हम दिखाते हैं कि वितरण ता्मक शब्दार्थ मुहावरों के शाब्दिक उपयोग को अलग करने के लिए एक सहायक हेरिस्टिक है, जिससे हमें इस संभावना का अनुमान लगाने के लिए एक शाब्दिक उपयोग मीट्रिक तैयार करने का एक तरीका मिलता है कि मुहावरे का शाब्दिक इरादा शाब्दिक रूप से है। यह जानकारी तब संभावित मॉडल के लिए असुरक्षित प्रशिक्षण प्रक्रिया का मार्गदर्शन करने के लिए दूर के पर्यवेक्षण के एक रूप के रूप में कार्य करती है। प्रयोगों से पता चलता है कि हमारा समग्र मॉडल पर्यवेक्षित तरीकों के खिलाफ प्रतिस्पर्धात्मक रूप से प्रदर्शन करता है।</abstract_hi>
      <abstract_zh>众习语可随其上下文喻字面解。 本文有无督学之法,以识习语之期。 吾以此法为概率形之潜变量,而练之于言语动机之间。 至要者,明布语义为分别成语文字用法有用启发式法,为我供一制文用指标之法,以度成语从字面上意之可能也。 然后以为远程监之文,以导概率之无监也。 实验明,吾体与监督有竞争力。</abstract_zh>
      <abstract_ru>Многие идиоматические выражения могут быть интерпретированы образно или буквально в зависимости от их контекста. В данной работе предлагается метод неконтролируемого обучения для распознавания предполагаемого использования идиомы. Мы рассматриваем использование как скрытую переменную в вероятностных моделях и обучаем их в лингвистически мотивированном пространстве признаков. Важно, что мы показываем, что семантика распределения является полезной эвристикой для различения буквального использования идиомы, давая нам способ сформулировать буквальную метрику использования для оценки вероятности того, что идиома предназначена буквально. Затем эта информация служит в качестве формы дистанционного наблюдения для руководства процессом самостоятельной подготовки вероятностных моделей. Эксперименты показывают, что наша общая модель конкурирует с контролируемыми методами.</abstract_ru>
      <abstract_ga>Is féidir go leor nathanna cainte a léirmhíniú go figiúrach nó go litriúil ag brath ar a gcomhthéacsanna. Molann an páipéar seo modh foghlama gan mhaoirseacht chun na húsáidí atá beartaithe do nathanna cainte a aithint. Déileálaimid leis na húsáidí mar athróg fholaigh i múnlaí dóchúlachta agus cuirimid oiliúint orthu i spás gné spreagtha ag teanga. Go ríthábhachtach, léirímid gur heoraíoch cabhrach é an tséimeantaic dáileacháin chun idirdhealú a dhéanamh ar úsáid liteartha na bhfocal, rud a thugann bealach dúinn chun méadrach úsáide litriúil a cheapadh chun meastachán a dhéanamh ar an dóchúlacht go bhfuil an idiom beartaithe go litriúil. Feidhmíonn an t-eolas seo ansin mar chineál de chianmhaoirseacht chun an próiseas oiliúna gan mhaoirseacht do na samhlacha dóchúlachta a threorú. Léiríonn turgnaimh go bhfeidhmíonn ár múnla foriomlán go hiomaíoch i gcoinne modhanna maoirsithe.</abstract_ga>
      <abstract_el>Πολλές ιδιοματικές εκφράσεις μπορούν να ερμηνευθούν μεταφορικά ή κυριολεκτικά ανάλογα με το πλαίσιο τους. Η παρούσα εργασία προτείνει μια μέθοδο μάθησης χωρίς επίβλεψη για την αναγνώριση των προβλεπόμενων χρήσεων των ιδιωμάτων. Αντιμετωπίζουμε τις χρήσεις ως λανθάνουσα μεταβλητή στα πιθανολογικά μοντέλα και τις εκπαιδεύουμε σε έναν γλωσσικά υποκινούμενο χώρο χαρακτηριστικών. Σημαντικά, δείχνουμε ότι η σημασιολογία κατανομής είναι ένας χρήσιμος heuristik για τη διάκριση της κυριολεκτικής χρήσης των ιδιωμάτων, δίνοντάς μας έναν τρόπο να διαμορφώσουμε μια μετρική κυριολεκτικής χρήσης για να εκτιμήσουμε την πιθανότητα ότι το ιδίωμα προορίζεται κυριολεκτικά. Οι πληροφορίες αυτές χρησιμεύουν στη συνέχεια ως μια μορφή μακρινής επίβλεψης για να καθοδηγήσουν τη διαδικασία εκπαίδευσης χωρίς επίβλεψη για τα πιθανολογικά μοντέλα. Τα πειράματα δείχνουν ότι το συνολικό μοντέλο μας λειτουργεί ανταγωνιστικά έναντι των εποπτευόμενων μεθόδων.</abstract_el>
      <abstract_it>Molte espressioni idiomatiche possono essere interpretate figurativamente o letteralmente a seconda del loro contesto. Questo articolo propone un metodo di apprendimento non supervisionato per riconoscere gli usi previsti degli idiomi. Trattiamo gli usi come una variabile latente nei modelli probabilistici e li addestriamo in uno spazio di funzionalità motivato linguisticamente. Fondamentalmente, mostriamo che la semantica distributiva è un euristica utile per distinguere l'uso letterale degli idiomi, dandoci un modo per formulare una metrica di uso letterale per stimare la probabilità che l'idioma sia inteso letteralmente. Queste informazioni servono poi come una forma di supervisione a distanza per guidare il processo di formazione non supervisionato per i modelli probabilistici. Gli esperimenti dimostrano che il nostro modello globale funziona in modo competitivo rispetto ai metodi supervisionati.</abstract_it>
      <abstract_ka>ბევრი იდიომატიური გამოსახულებები შეიძლება ფიგურატიურად ან ბულტურად განსახულებელია მათი კონტექსტზე. ეს დოკუმენტი იდეომების მისამართებელი გამოყენება განაცნობისთვის უარყოფილი სწავლების მეტი. ჩვენ გამოყენებას როგორც ცვლილება შესაბამისი მოდელში და გამოყენებთ ისინი ლენგურისტიკურად მოტივირული ფუნქციების სივრცეში. მნიშვნელოვანია, ჩვენ ჩვენ აჩვენებთ, რომ დისტრიბუციონალური სემენტიკი არის საჭირო ჰერისტიკი იდეომების ლიტრალური გამოყენება განსხვავებას, რომელიც გვეძლევს გზა, რომელიც ბოლობური გამოყენება მეტრიკის ფ ეს ინფორმაცია შემდეგ იმუშაობს, როგორც ძალიან განმავლობის ფორმა, რომ გადაწყენოთ უარყოფილი განმავლობა პროცესის პროცესი პროცესი პროცესი პრობლე ექსპერიმენტები გამოჩვენება, რომ ჩვენი ყველა მოდელი კონპექტიურად კონპექტიურად გამოყენებს შენახვედული მეტისებზე.</abstract_ka>
      <abstract_hu>Számos idiomatikus kifejezés értelmezhető képletesen vagy szó szerint a kontextusoktól függően. Ez a tanulmány egy felügyelet nélküli tanulási módszert javasol a kifejezések tervezett használatának felismerésére. A felhasználásokat látens változóként kezeljük valószínűségi modellekben, és nyelvileg motivált funkciótérben tanítjuk. Lényegében megmutatjuk, hogy a disztribúciós szemantika hasznos heurisztikát jelent a kifejezések szó szerinti használatának megkülönböztetésére, lehetővé téve szó szerinti használati metrika megfogalmazását, hogy becsüljük annak valószínűségét, hogy a kifejezést szó szerint szánták. Ezek az információk ezután a távoli felügyelet formáját szolgálják, amely irányítja a felügyelet nélküli képzési folyamatot a valószínűségi modellek esetében. A kísérletek azt mutatják, hogy az általános modellünk versenyképes a felügyelt módszerekkel szemben.</abstract_hu>
      <abstract_kk>Көп идеоматикалық өрнектерді пішімді немесе әдімгі мәтіндеріне тәуелді түсіндіре алады. Бұл қағаз идиомдардың қолданбаларын анықтау үшін қолданбаған үйрену әдісін ұсынады. Біз пайдалануларды ықтималдық үлгілерде кейінгі айнымалыс ретінде тұрып, оларды лингвистикалық мотивациялық мүмкіндіктер бойынша үйренеміз. Біз үлестіріміздің семантикалық семантикалық идиомдардың әдімгі пайдалануын таңдау үшін көмектесілі геуристік деп көрсетедік. Бізге әдімгі метрикалық пайдалану мүмкіндігін түсіндіру үшін мәліметті оқу үші Содан кейін бұл мәлімет мүмкіндік үлгілер үшін қашықтағы қашықтағы бақылау процесін бақылау үшін қашықтағы қашықтағы қашықтағы бақылау түрі болады. Тәжірибелер біздің жалпы моделіміздің бақылау әдістерімізге қарсы тәжірибелерімізді көрсетеді.</abstract_kk>
      <abstract_ms>Banyak ungkapan idiomatik boleh ditafsirkan secara figuratif atau secara literal bergantung pada konteks mereka. Kertas ini mencadangkan kaedah pembelajaran tidak diawasi untuk mengenali penggunaan idiom yang ditentukan. Kami memperlakukan penggunaan sebagai pembolehubah tersembunyi dalam model kemungkinan dan melatih mereka dalam ruang ciri-ciri yang bermotif secara bahasa. Yang penting, kita menunjukkan bahawa semantik distribusi adalah heuristik yang berguna untuk membedakan penggunaan huruf-hara idiom, memberi kita cara untuk membentuk penggunaan huruf-hara metrik untuk menghargai kemungkinan bahawa idiom adalah bermaksud huruf-hara. Maklumat ini kemudian berkhidmat sebagai bentuk pengawasan jauh untuk memimpin proses latihan tidak diawasi untuk model kemungkinan. Eksperimen menunjukkan bahawa model keseluruhan kita berkompetitif melawan kaedah yang diawasi.</abstract_ms>
      <abstract_ml>ഒരുപാട് വിഡ്ഢിത്ത വാക്കുകള്‍ക്ക് വ്യാഖ്യാനം ചെയ്യാന്‍ കഴിയും, അല്ലെങ്കില്‍ അവരുടെ പ്രഭാതത്തിനെ ആശ്രയി ഈ പത്രത്തില്‍ നിര്‍ണ്ണയിക്കപ്പെട്ട വിഡ്ഢികളുടെ ഉപയോഗം തിരിച്ചറിയാനുള്ള ഒരു സൂക്ഷ്മമായ പഠിപ്പി നമ്മള്‍ ഉപയോഗിക്കുന്നത് സാധ്യതയുള്ള മാതൃകങ്ങളില്‍ പുതിയ മാറ്റങ്ങളായി നോക്കുന്നു. ഭാഷക്കാരില്‍ നിന്നും പ്രചോദപ നമ്മള്‍ കാണിക്കുന്നത് വിതരണ സെമാന്റിക്സ് ഒരു പ്രയോജനകരമാണെന്ന്, വിഡ്ഢികളുടെ സാക്ഷ്യ ഉപയോഗം വേര്‍തിരിച്ചറിയാന്‍ സഹായിക്കുന്നത്, ഒരു സാധാരണ ഉപയോഗം മെട്രിക്ക പിന്നീട് ഈ വിവരങ്ങള്‍ സംരക്ഷിക്കാത്ത പരിശീല പ്രക്രിയയ്ക്ക് മാതൃകങ്ങള്‍ക്ക് വഴികാട്ടാന്‍ ദൂരെ നിരീക്ഷിക്കു പരീക്ഷണങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ മൊത്തം മോഡല്‍ നിരീക്ഷിക്കപ്പെട്ട രീതികള്‍ക്ക</abstract_ml>
      <abstract_lt>Daugelis idiomatinių išraiškų gali būti aiškinamos vaizdiškai arba literaliai priklausomai nuo jų konteksto. Šiame dokumente siūlomas nepastebimas mokymosi metodas, kuriuo pripažįstamas numatomas idiomų naudojimas. Mes vertiname naudojimą kaip latent in į kintamąjį probabilistiniuose modeliuose ir mokome juos kalbiniu būdu motyvuotoje savybės erdvėje. Svarbiausia, mes rodome, kad paskirstymo semantika yra naudinga heuristika skiriant literal ų idiom ų naudojimą, suteikiant mums būdą suformuluoti literalų naudojimo metriką siekiant įvertinti tikimybę, kad idiomas yra skirtas literaliai. Tada ši informacija naudojama kaip nuotolinės priežiūros form a, kuria vadovaujamasi nepastebimam probabilistinių modelių mokymo procesui. Eksperimentai rodo, kad mūsų bendras modelis veikia konkurencingai, palyginti su prižiūrimais metodais.</abstract_lt>
      <abstract_mk>Многу идиоматски изрази можат да се интерпретираат фигуративно или буквално во зависност од нивните контексти. Овој весник предлага ненадгледуван метод на учење за препознавање на наменетите употреби на идиомите. We treat the usages as a latent variable in probabilistic models and train them in a linguistically motivated feature space.  Основно, покажуваме дека дистрибуционалната семантика е корисна хеористика за разликување на буквалната употреба на идиомите, што ни дава начин да формулираме буквална метрика за употреба за проценка на веројатноста дека идиомот е буквално наменет. Оваа информација потоа служи како форма на далечен надзор за да го води ненадгледуваниот процес на обука за веројатностите на моделите. Експериментите покажуваат дека нашиот целокупен модел функционира конкурентно против надгледуваните методи.</abstract_mk>
      <abstract_no>Mange idiomatiske uttrykk kan tolkast figurativt eller bokstavleg avhengig av kontekstane sine. Denne papiret foreslår ein ukjend læringsmetode for å gjenkjenna dei gjeldande bruka av idioma. Vi behandler brukane som ein latent variabel i sannsynlige modeller og treng dei i eit språk motivert funksjonsplass. Dette viser vi at distribusjonssemantikk er ein hjelp heuristisk for å distisera bokstaven bruk av idiom a, og gir oss ein måte å formera ein bokstav bruk metrisk for å estimere sannsynligheten at idioma er rett. Denne informasjonen gjev derfor ein form av distant oversikt for å hjelpa opplæringsprosessen som ikkje er oppretta for sannsynlige modeller. Eksperimentar viser at vår overalt modell utfører konkurransa mot oversikte metodar.</abstract_no>
      <abstract_mt>Ħafna espressjonijiet idjomatiċi jistgħu jiġu interpretati b’mod figurattiv jew letterali skont il-kuntesti tagħhom. Dan id-dokument jipproponi metodu ta’ tagħlim mhux sorveljat għar-rikonoxximent tal-użu maħsub tal-idjomi. Intrattaw l-użu bħala varjabbli moħbija fil-mudelli probabilistiċi u nħarrġuhom fi spazju ta’ karatteristiċi motivati lingwistikament. Crucially, we show that distribution semantics is a helpful heuristic for distinguishing the literal use of idioms, giving us a way to formulate a literal use metric to estimate the likelihood that the idiom is intended literally. Din l-informazzjoni mbagħad isservi bħala form a ta’ superviżjoni mill-bogħod biex tiggwida l-proċess ta’ taħriġ mhux sorveljat għall-mudelli probabilistiċi. L-esperimenti juru li l-mudell globali tagħna jwettaq prestazzjoni kompetittiva kontra metodi sorveljati.</abstract_mt>
      <abstract_ro>Multe expresii idiomatice pot fi interpretate figurat sau literalmente în funcție de contextul lor. Această lucrare propune o metodă de învățare nesupravegheată pentru recunoașterea utilizărilor propuse ale expresiilor. Tratăm utilizările ca pe o variabilă latentă în modelele probabilistice și le antrenăm într-un spațiu de caracteristici motivat lingvistic. În mod esențial, arătăm că semantica distribuțională este o euristică utilă pentru distingerea utilizării literale a idiomelor, oferindu-ne o modalitate de a formula o metrică de utilizare literală pentru a estima probabilitatea ca idiomul să fie intenționat literalmente. Aceste informații servesc apoi ca o formă de supraveghere la distanță pentru a ghida procesul de formare nesupravegheat pentru modelele probabilistice. Experimentele arată că modelul nostru general funcționează competitiv împotriva metodelor supravegheate.</abstract_ro>
      <abstract_pl>Wiele idiomatycznych wyrażeń może być interpretowanych przenośnie lub dosłownie w zależności od ich kontekstu. W artykule zaproponowano metodę uczenia się bez nadzoru służącą rozpoznawaniu zamierzonych zastosowań idiomów. Zastosowania traktujemy jako skrytą zmienną w modelach probabilistycznych i trenujemy je w językowo motywowanej przestrzeni cech. Co istotne, pokazujemy, że semantyka dystrybucyjna jest pomocną heurystyką do rozróżnienia dosłownego użycia idiomów, dając nam sposób sformułowania dosłownej metryki użycia, aby oszacować prawdopodobieństwo, że idiom jest zamierzony dosłownie. Informacje te służą następnie jako forma nadzoru na odległość, aby kierować procesem szkolenia bez nadzoru dla modeli probabilistycznych. Eksperymenty pokazują, że nasz ogólny model działa konkurencyjnie wobec metod nadzorowanych.</abstract_pl>
      <abstract_mn>Ихэнх идиоматик илэрхийллүүд өөрсдийн нөхцөл байдлаас хамаарч болох юм. Энэ цаас нь идэвхтэй хэрэглэгдэхийг хүлээн зөвшөөрөх боломжгүй суралцах аргыг сануулдаг. Бид үүнийг магадлалын загвар дээр хамгийн сүүлийн хувьсагч болгож, хэлний урам зориулсан зайд суралцах болно. Хамгийн чухал нь бид хуваарилцааны семантик нь тэмцээний бичиг хэрэглэгийг тодорхойлох тусламжтай гэдгийг харуулж, тэмцээний магадлалыг тодорхойлох арга өгдөг. Тэгээд энэ мэдээлэл магадлал загварын дасгал хөдөлгөөний үйл ажиллагааг удирдах хол даяарлын хэлбэрээр ажилладаг. Эмчилгээний туршилт бидний нийт загвар удирдлагын арга замыг эсрэг өрсөлдөг гэдгийг харуулдаг.</abstract_mn>
      <abstract_sv>Många idiomatiska uttryck kan tolkas bildligt eller bokstavligt beroende på deras sammanhang. Denna uppsats föreslår en oövervakad inlärningsmetod för att erkänna de avsedda användningen av idiom. Vi behandlar användningarna som en latent variabel i sannolikhetsmodeller och tränar dem i ett språkligt motiverat funktionsutrymme. Viktigt är att vi visar att distributionssig semantik är en användbar heuristik för att skilja den bokstavliga användningen av idiom, vilket ger oss ett sätt att formulera en bokstavlig användning metrik för att uppskatta sannolikheten för att idiomet är avsett bokstavligt. Denna information fungerar sedan som en form av fjärrövervakning för att vägleda den oövervakade träningsprocessen för de sannolika modellerna. Experiment visar att vår övergripande modell presterar konkurrenskraftigt mot övervakade metoder.</abstract_sv>
      <abstract_so>Waxyaabo badan oo idioti ah waxaa lagu turjumi karaa si fasax ah ama si rasmi ah waxay ku xiran karaan xaaladahooda. Kanu wuxuu soo jeedaa qaab waxbarasho oo aan la ilaalinayn oo lagu aqoonsado isticmaalka lagu talo galay idimyada. Isticmaalka waxaan ugu dhaqdhaqaaqnaa isbedelka muuqashada suurtagalka ah, waxaana ku tababarinnaa goob luqad ah oo la hago. Sida xaqiiqada ah, waxaynu muujinnaa in seminiyada kala qaybsan ay tahay mid caawinaya si ay u kala soocdo isticmaalka asalka ah ee idimyada, waxayna na siiyaa jid aan u sameyno isticmaalka qoraalka ah si aan ugu qiimeyno suurtagalka loogu talagalay dumarka. Markaas macluumaadkaas waxaa loola adeegaa qaab ilaaliyo fog oo lagu hago samooyinka suurtagalka ah oo lagu sameynayo koorasyada waxbarashada aan la ilaalinayn. Imtixaanka waxaa muuqda in qaababkayaga guud uu si iskutar ah u sameeyo qaababka la ilaaliyo.</abstract_so>
      <abstract_sr>Mnogi idiomatski izrazi mogu da se interpretiraju figurativno ili bukvalno ovisno o svojim kontekstima. Ovaj papir predlaže neodređenu metodu učenja za prepoznavanje namernog korištenja idiota. Tretiramo korištenje kao latentnu promjenu u verovatnim modelima i treniramo ih u jezički motiviranom prostoru. U suštini, pokazujemo da je distribucijska semantika korisna heuristička za razliku bukvalnog korištenja idiom a, dajući nam način da formulišemo bukvalno korištenje metrika kako bi procenili mogućnost da je idiom doslovno nameravan. Ove informacije onda služe kao oblik dalekog nadzora da vodi neodređeni proces obuke za verovatnih modela. Eksperimenti pokazuju da naš ukupni model izvodi konkurentno protiv nadzornih metoda.</abstract_sr>
      <abstract_si>ගොඩක් මෝඩයාත්මක ප්‍රශ්නයක් ප්‍රශ්නයක් වෙන්න පුළුවන් නැහැ නැත්නම් ප්‍රශ්නයක් ඔවුන්ගේ ස මේ පැත්තේ ප්‍රශ්නයක් ප්‍රශ්නයක් කරනවා මෝඩයෝගේ අනුමුත්ත භාවිතාවක් අඳින්න. අපි පාවිච්චි වෙනස් වෙනුවෙන් ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් වෙනුවෙන් භාෂාවික විශේෂ විදිහට පත විශේෂයෙන්, අපි පෙන්වන්නේ විදුලිය සෙමැන්ටික්ස් එක ප්‍රයෝජනයක් වෙනුවෙන් මෝඩයෝගේ ප්‍රයෝජනය වෙනුවෙන් ප්‍රයෝජනයක් වෙනුවෙන් ප්‍රයෝජනයක මේ තොරතුරු පස්සේ දුරස්ථ ප්‍රධානයක් වෙනුවෙන් ප්‍රධානය කරන්න පුළුවන් ප්‍රධානය සඳහා ප්‍රධානය නැති ප්‍ පරීක්ෂණය පෙන්වන්නේ අපේ සාමාන්‍ය මොඩේල් එක්ක පරීක්ෂණය විරුද්ධ විරුද්ධ වෙනුවෙන් සාධ</abstract_si>
      <abstract_ur>بہت سی زبان مثالیں ان کی موقعیت پر نابستہ ہو سکتے ہیں جو انجیل کے طور پر تعبیر کر سکتے ہیں یا بالکل ان کی موقعیت پر نابستہ ہو سکتے ہیں. یہ کاغذ ایک غیرقابل تعلیم طریقہ پیش کرتا ہے جو احمقوں کے مطابق استعمال کرنا ہے۔ ہم ان استعمال کو احتمالات ماڈل میں لاٹینٹ ویرئیٹ کے طور پر چلتے ہیں اور انہیں زبان کے ذریعہ منصفات کی جگہ میں تربیت کرتے ہیں. ہم دکھاتے ہیں کہ تقسیم سیمانٹیک ایک مہربانی ہے کہ دیوونوں کے ذریعہ استعمال کو تفریق کرنے کے لئے، ہمیں ایک طریقہ دیتا ہے کہ ایک صحیح استعمال متریک کا فرمول کریں کہ اس احتمال کا اندازہ کریں کہ دیوونوں کا ذریعہ صحیح طور پر مقرر کیا گیا ہے. اس کے بعد یہ معلومات دور کی نظارت کی شکل کے طور پر موجود ہے کہ امکانات مدل کے لئے غیر قابل تعلیم پروسس کی راہ دکھائے۔ تجربے دکھاتے ہیں کہ ہمارے سارے موڈل نظارت کی طریقے سے مسابقه کرتا ہے.</abstract_ur>
      <abstract_ta>பெரும்பாலான முட்டாளிக் கூற்றுகளை வடிவமைப்பாக விளக்க முடியும் இந்த காகிதத்தில் முட்டாள்களின் நிர்ணயிக்கப்பட்ட பயன்பாடு நாம் பயன்பாடுகளை ஒரு சமீபத்தில் மாறிகளாக பயன்படுத்துகிறோம் சாத்தியமான மாதிரிகளில் மற்றும் மொழியில் ஊக்கும் தன்மைக் முட்டாள்களின் பயன்பாட்டை வேறுபடுத்துவதற்கு ஒரு உதவியுள்ளது என்பதை நாம் காண்பிக்கிறோம். முட்டாள் என்று நிர்ணயிக்கும் வித்தியாசமான உபயோகிப்பு மெட்ரிக்கு  @ info கண்காணிக்கப்பட்ட முறைகளுக்கு எதிராக எங்கள் மொத்த மாதிரி தோற்றம் செய்கிறது என்று தெரியும்.</abstract_ta>
      <abstract_uz>Ko'pchilik idiotik ifodalarni tasavvur qilishi mumkin yoki o'z taxminan holatlarga ishlatishi mumkin. Bu qogʻoz ishlatilgan odamlarni aniqlash uchun xavfsiz qilmagan o'rganish usulini anglatadi. We treat the usages as a latent variable in probabilistic models and train them in a linguistically motivated feature space.  Biz o'xshasiz, tarqatish semantika o'zaro ishlatishga yordam beruvchi heuristik, bizga o'xshash imkoniyatlarni o'zgartirish imkoniyatlariga yordam beramiz, bizga o'xshagan foydalanish metrikini aniqlash imkoniyatini o'rganish mumkin. Name Tajribalar umumiy modelimiz taʼminlovchi usullarni ishlab chiqaradi.</abstract_uz>
      <abstract_vi>Nhiều biểu tượng có thể được giải thích theo nghĩa bóng hoặc nghĩa đen tùy thuộc vào ngữ cảnh. Tờ giấy này đề xuất một phương pháp học không giám sát để nhận ra cách sử dụng ngôn ngữ được sắp đặt. Chúng tôi xem phương pháp này như biến tiềm ẩn trong các mô hình xác suất và huấn luyện chúng trong một khoảng trống do ngôn ngữ. Điều cốt yếu là, chúng ta cho thấy rằng phân phát ngữ nghĩa là một giúp đỡ đỡ đỡ để phân biệt chữ thường sử dụng các thành ngữ, cho chúng ta một cách để phát âm một cách tổng quát để ước lượng khả năng rằng thành ngữ được sắp đặt theo nghĩa đen. Thông tin này là một hình thức giám sát xa xôi để hướng dẫn tiến trình huấn luyện không giám sát cho các mô hình xác suất. Thí nghiệm cho thấy mẫu vật của chúng ta có thể cạnh tranh với các phương pháp được giám sát.</abstract_vi>
      <abstract_nl>Veel idiomatische uitdrukkingen kunnen figuurlijk of letterlijk geïnterpreteerd worden, afhankelijk van hun context. Dit artikel stelt een methode voor om de beoogde toepassingen van idiomen te herkennen zonder toezicht. We behandelen de toepassingen als een latente variabele in probabilistische modellen en trainen ze in een taalkundig gemotiveerde feature space. Belangrijk is dat we laten zien dat distributionele semantiek een nuttige heuristiek is voor het onderscheiden van het letterlijke gebruik van idiomen, waardoor we een manier krijgen om een letterlijke gebruiksmetriek te formuleren om de waarschijnlijkheid te schatten dat het idioom letterlijk bedoeld is. Deze informatie dient dan als een vorm van toezicht op afstand om het trainingsproces zonder toezicht voor de probabilistische modellen te begeleiden. Experimenten tonen aan dat ons algehele model concurrerend presteert ten opzichte van begeleide methoden.</abstract_nl>
      <abstract_bg>Много идиоматични изрази могат да бъдат интерпретирани фигуративно или буквално в зависимост от контекста им. Настоящата статия предлага метод на обучение без надзор за разпознаване на предназначените употреби на идиоми. Ние третираме употребите като латентна променлива в вероятностните модели и ги обучаваме в лингвистично мотивирано пространство. От решаващо значение е, че дистрибуционната семантика е полезна евристика за разграничаване на буквалното използване на идиоми, което ни дава начин да формулираме буквален метрик за използване, за да оценим вероятността идиомът да бъде предназначен буквално. След това тази информация служи като форма на дистанционен надзор, който да ръководи процеса на обучение без надзор за вероятностните модели. Експериментите показват, че нашият цялостен модел работи конкурентно срещу надзорните методи.</abstract_bg>
      <abstract_hr>Mnoge idiomatske izraze mogu se interpretirati figurativno ili bukvalno ovisno o svojim kontekstima. Ovaj papir predlaže neodređenu metodu učenja za prepoznavanje namjerenih korištenja idiota. Tretiramo korištenje kao latentnu promjenu u vjerojatnim modelima i obučavamo ih u jezički motiviranom prostoru. U suštini, pokazujemo da je distribucijska semantika korisna heuristička za razliku bukvalnog korištenja idiom a, dajući nam način da formuliramo bukvalno korištenje metrika kako bi procijenili vjerojatnost da je idiom namjerena bukvalno. Tada se ova informacija služi kao oblik dalekog nadzora kako bi vodio neodređeni proces obuke za vjerojatni modeli. Eksperimenti pokazuju da naš ukupni model izvodi konkurentno protiv nadzornih metoda.</abstract_hr>
      <abstract_da>Mange idiomatiske udtryk kan fortolkes billedligt eller bogstaveligt afhængigt af deres sammenhænge. Denne artikel foreslår en uautoriseret læringsmetode til anerkendelse af de påtænkte anvendelser af idiomer. Vi behandler brugerne som en latent variabel i sandsynlighedsmodeller og træner dem i et sprogligt motiveret funktionsrum. Afgørende er, at vi viser, at distributions semantik er en nyttig heuristik til at skelne den bogstavelige brug af idiomer, hvilket giver os en måde at formulere en bogstavelig brugsmetric for at estimere sandsynligheden for, at idiomet er tænkt bogstaveligt. Disse oplysninger tjener derefter som en form for fjernvejledning til at lede den uautoriserede træningsproces for de sandsynlige modeller. Eksperimenter viser, at vores overordnede model præsterer konkurrencedygtigt mod overvågede metoder.</abstract_da>
      <abstract_de>Viele idiomatische Ausdrücke können je nach Kontext bildlich oder wörtlich interpretiert werden. Diese Arbeit schlägt eine Methode vor, um die beabsichtigten Verwendungen von Idiomen zu erkennen. Wir behandeln die Verwendungen als latente Variable in probabilistischen Modellen und trainieren sie in einem linguistisch motivierten Feature Space. Entscheidend ist, dass Verteilungssemmeantik eine hilfreiche Heuristik für die Unterscheidung der wörtlichen Verwendung von Idiomen ist, was uns eine Möglichkeit gibt, eine wörtliche Nutzungsmetrik zu formulieren, um die Wahrscheinlichkeit zu schätzen, dass das Idiom wörtlich gemeint ist. Diese Informationen dienen dann als Fernüberwachung, um den unbeaufsichtigten Trainingsprozess für probabilistische Modelle zu leiten. Experimente zeigen, dass unser Gesamtmodell gegenüber überwachten Methoden wettbewerbsfähig ist.</abstract_de>
      <abstract_id>Banyak ekspresi idiomatis dapat diterjemahkan secara figuratif atau secara harfiah bergantung pada konteks mereka. Kertas ini mengusulkan metode belajar yang tidak diawasi untuk mengenali penggunaan idiom yang direncanakan. Kami memperlakukan penggunaan sebagai variabel latent dalam model probabilis dan melatihnya dalam ruang karakteristik yang bermotivasi bahasa. Yang paling penting, kita menunjukkan bahwa semantik distribusi adalah heuristik yang berguna untuk membedakan penggunaan secara harfiah idiom, memberikan kita cara untuk menyiformulasi penggunaan secara harfiah metrik untuk memperkirakan kemungkinan bahwa idiom itu berarti secara harfiah. Informasi ini kemudian melayani sebagai bentuk pengawasan jauh untuk memimpin proses latihan tidak diawasi untuk model probabilis. Eksperimen menunjukkan bahwa model keseluruhan kita berkompetitif melawan metode yang diawasi.</abstract_id>
      <abstract_sw>Maelezo mengi ya upumbavu yanaweza kutafsiriwa kwa kiasi cha kinachotegemea mikutano yao. Makala hii inapendekeza njia ya kujifunza isiyo na uhakika kwa kutambua matumizi yaliyolengwa na ujinga. Tunatumia matumizi kama mabadiliko ya hivi karibuni katika mifano inayowezekana na kuwafundisha katika nafasi inayohamasishwa kwa lugha. Kwa hakika, tunaonyesha kuwa semantika za usambazaji ni utaratibu wa kusaidia kutofautisha matumizi ya kijinga, na kutupa njia ya kutengeneza mbinu za usambazaji wa kisasa ili kadiria uwezekano wa upumbavu uliopo kwa kiasi kikubwa. Taarifa hizi baadae inatumia kama namna ya kufuatiliwa mbali ili kuongoza mchakato wa mafunzo usioendelea kwa mifano inayowezekana. Experiments show that our overall model performs competitively against supervised methods.</abstract_sw>
      <abstract_fa>بسیاری از واژه‌های احمقانه‌ای می‌توانند به صورت‌سازی یا literally بستگی به موقعیت‌هایشان تفسیر کنند. این کاغذ یک روش آموزش غیرقابل تحقیق برای شناسایی استفاده از احمقان پیشنهاد می‌کند. ما استفاده ها را به عنوان تغییر latent در مدل احتمالات درمان می کنیم و آنها را در فضای انگیزه‌های انگیز زبان آموزش می‌دهیم. به طور خاص، ما نشان می دهیم که سیمانتیک‌های تقسیم‌پذیری برای تفاوت استفاده از احمقان کمک است، و به ما راهی می‌دهد که یک متریک استفاده‌پذیری را فرمول کنیم تا حدس بزنیم احتمال این احمق را به طور واقعی هدف می‌دهد. این اطلاعات بعدش به عنوان شکل نظارت دور برای هدایت فرایند آموزش غیرقابل توجه برای مدل احتمالات است. تجربه‌ها نشان می‌دهند که کل مدل ما در مقابل روش‌های نظارت مسابقه‌ای انجام می‌دهد.</abstract_fa>
      <abstract_ko>많은 습어는 상하문에 근거하여 비유하거나 서면으로 해석할 수 있다.본고는 습어를 식별하기 위한 무감독 학습 방법을 제시했다.우리는 용법을 확률모델의 잠재적인 변수로 보고 언어의 특징을 바탕으로 하는 공간에서 이를 훈련할 것이다.관건은 분포어의학이 습어를 구분하는 서면용법에 대해 유익한 계발이라는 것을 증명했고 이것은 우리에게 서면용법의 도량을 제정하여 습어의 서면용법의 가능성을 평가하는 방법을 제공했다.그리고 이런 정보는 원격 감독의 한 형식으로서 확률모델의 무감독 훈련 과정을 지도하는 데 사용된다.실험에 의하면 우리의 전체 모델은 감독 방법에 비해 경쟁력이 있다.</abstract_ko>
      <abstract_tr>Köp dilli ifade surat şeklinde ýa-da düzgünlerine garaşyp biler. Bu kagyz dilleriň maksady ulanylaryny tanamak üçin garaşylmadyk öwrenmek yöntemi teklip edýär. Biz kullanılmaları muhtemelen modellerde geçen bir değişiklik olarak tedavi edip, oları bir dil motivasyonat özelliklerinde eğitiriz. Adatça, döwlet semantikleri saýlawlaryň ýüzelini tapawutlamak üçin faydaly bir heuristik diýip görünýärdik. Bize sammynyň hakyky bir şekilde meýilleşdirilen mümkinçiligi takmynamak üçin bir ýoly berýäris. Soňra bu maglumat möhüm modalary üçin janlaşdyrylmadyk eğitim prosesini yönetmek üçin uzak supervisiň bir şekli bolup geçirýär. Denminatlar biziň hemme nusgamyzyň gözleýän yönlerimize garşy ýakynlaşykly etýändigini görkezýär.</abstract_tr>
      <abstract_sq>Many idiomatic expressions can be interpreted figuratively or literally depending on their contexts.  Ky dokument propozon një metodë mësimi të pazgjidhur për njohjen e përdorimit të synuar të idiomave. We treat the usages as a latent variable in probabilistic models and train them in a linguistically motivated feature space.  Pjesëmarrësisht, ne tregojmë se semantika shpërndarëse është një heuristik e dobishme për të dalluar përdorimin literal të idiomave, duke na dhënë një mënyrë për të formuluar një përdorim literal metrik për të vlerësuar mundësinë që idiomi është qëllim literalisht. Kjo informacion më pas shërben si një form ë mbikqyrjeje të largët për të udhëzuar procesin e trainimit të pazgjidhur për modelet probabiliste. Eksperimentet tregojnë se modeli ynë i përgjithshëm funksionon konkurruesisht kundër metodave të mbikqyrura.</abstract_sq>
      <abstract_hy>Շատ իդոմատիկ արտահայտություններ կարելի է մեկնաբանել ֆիզիկապես կամ բառացիորեն կախված իրենց կոնտեքստից: Այս հոդվածը առաջարկում է անվերահսկված ուսումնական մեթոդ, որպեսզի ճանաչենք լեզուների մտածված օգտագործումը: Մենք վերաբերում ենք օգտագործումը որպես թաքնված փոփոխական հավանական մոդելների մեջ և վարժեցնում ենք նրանց լեզվաբանական մոտիվացված հատկանիշների տարածքում: Հետաքրքիրն այն է, որ մենք ցույց ենք տալիս, որ բաշխման սեմանտիկան օգտակար հորիստիկ է, որպեսզի տարբերակենք իբյոմների բառացիորեն օգտագործվող օգտագործումը, մեզ հնարավորություն է տալիս բառացիորեն օգտագործվող մետրիկ ձևավորել, որպեսզի հաշվարկենք այն հավանականությունը, որ Այս տեղեկատվությունը հետո ծառայում է որպես հեռավոր վերահսկողության ձև, որպեսզի ուղղորդի հավանական մոդելների անվերահսկված ուսուցման գործընթացը: Փորձարկումները ցույց են տալիս, որ մեր ընդհանուր մոդելը մրցակցություն ունի վերահսկվող մեթոդների դեմ:</abstract_hy>
      <abstract_af>Baie idiomatiese uitdrukkings kan figuratief of literatief afhang van hulle kontekste. Hierdie papier voorstel 'n onverondersteunde leermeetode vir herken die bedoelde gebruik van idioms. Ons behandel die gebruikte as 'n latente veranderlike in waarskynlike modele en trein hulle in 'n lingwisies motiveer funksie spasie. In kruistelik, ons wys dat verspreidingssemantieke 'n hulp heuristiese is om die leeterale gebruik van idioms te verkies en ons 'n manier om 'n leeterale gebruik metriek te formeer om die waarskynlik dat die idiom leeteraal beteken is. Hierdie inligting dien dan as 'n vorm van afgeleë supervisie om die ononderwerpende onderwerp proses te lei vir die waarskynlike modele. Eksperimente wys dat ons heeltemal model teen ondersoekte metodes rekenaar.</abstract_af>
      <abstract_bs>Mnoge idiomatske izraze mogu se interpretirati figurativno ili bukvalno ovisno o svojim kontekstima. Ovaj papir predlaže neodređenu metodu učenja za prepoznavanje namjerenih korištenja idiota. Tretiramo korištenje kao latentnu promjenu u vjerojatnim modelima i treniramo ih u jezički motiviranom prostoru. U suštini, pokazujemo da je distribucijska semantika korisna heuristička za razliku bukvalnog korištenja idiom a, dajući nam način da formuliramo bukvalno korištenje metrika da procijenimo vjerojatnost da je idiom doslovno namjeren. Tada se ova informacija služi kao oblik dalekog nadzora kako bi vodio neodređeni proces treninga za vjerovatne modele. Eksperimenti pokazuju da naš ukupni model izvodi konkurentno protiv nadzornih metoda.</abstract_bs>
      <abstract_ca>Moltes expressions idiomàtiques es poden interpretar figurativament o literalment segons els seus contextos. Aquest paper propon un mètode d'aprenentatge no supervisat per reconèixer els usos intencionats dels idiomes. Tratem els usos com una variable latent en models probabilistes i els entrenem en un espai de característiques motivats lingüísticament. El més important és que demostrem que la semàntica distribucional és una heurística útil per distingir l'ús literal dels idiomes, donant-nos una manera de formular un ús literal mètric per estimar la probabilitat que el idiome està intencionat literalment. Aquesta informació serveix llavors com una form a de supervisió remota per guiar el procés d'entrenament sense supervisió dels models probabilistes. Els experiments demostren que el nostre model general es produeix competitivament en comparació amb els mètodes supervisats.</abstract_ca>
      <abstract_cs>Mnoho idiomatických výrazů lze interpretovat obrazně nebo doslova v závislosti na jejich kontextu. Tento článek navrhuje metodu učení bez dozoru pro rozpoznání zamýšlených použití idiomů. Použití považujeme za latentní proměnnou v pravděpodobnostních modelech a trénujeme je v lingvisticky motivovaném funkčním prostoru. Klíčové je, že distribuční sémantika je užitečná heuristika pro rozlišení doslovného použití idiomů, což nám dává způsob, jak formulovat doslovnou metriku použití k odhadu pravděpodobnosti, že idiom je zamýšlen doslova. Tyto informace pak slouží jako forma vzdáleného dohledu, který vede proces tréninku bez dohledu pro pravděpodobnostní modely. Experimenty ukazují, že náš celkový model funguje konkurenčně proti kontrolovaným metodám.</abstract_cs>
      <abstract_am>ብዙዎች የሞኝነት ንግግር በሥርዓት ወይም በአካባቢነት በሥርዓታቸው ላይ የሚታመሙ ሊተረጉም ይችላል፡፡ ይህ ፕሮግራም የተሰበሰቡትን የሞኝነት ተጠቃሚዎችን ለማወቅ የማይጠበቀውን ትምህርት ማድረግ ያስባል፡፡ በቋንቋው በተመሳሳይ የፊደል ስፍራን እናስተማራቸዋለን፡፡ በብርቱ፣ የግንኙነት ስሜንቲክ የኢትዮጵያዊ ጥያቄን ለመለየት የሚረዳ ሀሪክኛ ነው፡፡ የዚህ መረጃ በኋላ የሩቅ ማኅበረሰብ የስህተት ትምህርት ፕሮግራሙን ለመመራት ይጠቅማል፡፡ ፈተናዎች በሙሉ ሞዴላዎቻችን በተቃዋሚ ሥርዓት ላይ እንዲያደርጉ ያሳያል፡፡</abstract_am>
      <abstract_bn>অনেক বোকামী প্রকাশের ব্যাখ্যা গতভাবে বা সত্যিকারে তাদের প্রতিযোগিতার উপর নির্ভর করতে পারে। এই পত্রিকাটি বোকামীদের ব্যবহার স্বীকার করার জন্য অরক্ষিত শিক্ষার পদ্ধতি প্রস্তাব করেছে। আমরা এই ব্যবহারকারীদের সম্ভাব্য মডেলের সাম্প্রতিক পরিবর্তন হিসেবে ব্যবহার করি এবং ভাষাগত উদ্দেশ্যের বৈশিষ্ট্যের স্থানে তা ক্রিয়াশিক্রমে, আমরা দেখাচ্ছি যে বিতরণের সেমান্টিক্স একটি সাহায্য হারিস্টিক যা বিচ্ছিন্ন করার জন্য, যা আমাদের একটি সাহিত্যিক ব্যবহারের মেট্রিক তৈরি করার উপায় দিয় এই তথ্য তারপর দূরবর্তী পর্যবেক্ষণ হিসেবে সার্ভিস্ট মোডেলের জন্য সংরক্ষিত প্রশিক্ষণ প্রক্রিয়াকে হেদায়েত করার জন্য সা পরীক্ষাগুলো দেখাচ্ছে যে আমাদের সাধারণ মডেল পর্যবেক্ষণীয় পদ্ধতির বিরুদ্ধে প্রতিযোগিতায় প্রতিযোগি</abstract_bn>
      <abstract_et>Paljusid idiomaatilisi väljendeid saab tõlgendada kujunduslikult või sõna otseses mõttes sõltuvalt nende kontekstist. Käesolev töö pakub välja järelevalveta õppemeetod, et tuvastada kavandatud kasutusviise idioomid. Tõenäosusmudelites käsitleme kasutusviise latentse muutujana ja koolitame neid keeleliselt motiveeritud funktsiooniruumis. Oluliselt näitame, et distributsioonisemantika on kasulik heuristika idioomide sõnasõnalise kasutamise eristamiseks, andes meile võimaluse sõnasõnalise kasutusmeetri sõnasõnalise kasutamise mõõdiku hindamiseks tõenäosust, et idioom on mõeldud sõna otseses mõttes. See teave on seejärel kaugjärelevalve vorm, mis juhib tõenäosusmudelite järelevalveta koolitusprotsessi. Katsed näitavad, et meie üldine mudel toimib konkurentsivõimeliselt kontrollitud meetoditega.</abstract_et>
      <abstract_az>Birçox idiomatik ifadələr şəkildə və ya yazılı olaraq onların məsələlərinə bağlı olar. Bu kağıt idilərin müəyyən edilmiş istifadələrini tanıtmaq üçün müəyyən edilməmiş öyrənmə metodumu təklif edir. Biz bu işləri mümkünlük modellərdə latent dəyişiklik olaraq təhsil edirik və dil olaraq motivatlı fərqli alanda təhsil edirik. Əslində, biz dağıtıcı semantik idimlərin faydalı istifadəsini ayırmaq üçün faydalı bir heuristik olduğunu göstərdik, idimlərin qismi olaraq məqsədilə müəyyən ediləcəyi mümkünlüyü təmin etmək üçün bizə yazılı istifadə etmə metrik yolu göstərdik. Sonra bu məlumat, mümkün olaraq modellərin təhsil edilməmiş təhsil sürətini doğru yola yönəltmək üçün uzaq bir supervizyon formu olar. Həqiqətən, təcrübələrimiz bütün modellərimiz gözləmə metodlarına qarşı müqayisədə çalışır.</abstract_az>
      <abstract_fi>Monia idiomaattisia ilmaisuja voidaan tulkita kuvaannollisesti tai kirjaimellisesti niiden kontekstista riippuen. Tässä työssä ehdotetaan valvomatonta oppimismenetelmää idiomien käyttötarkoitusten tunnistamiseksi. Käsittelemme käyttötapoja piilevänä muuttujana todennäköisyysmalleissa ja koulutamme niitä kielellisesti motivoituneessa ominaisuustilassa. Tärkeintä on osoittaa, että jakelusemantiikka on hyödyllinen heuristikko erottaa kielenkäyttö kirjaimellisesti, mikä antaa meille tavan muotoilla kirjaimellinen käyttömetriikka arvioimaan todennäköisyyttä, että kielenkäyttö on kirjaimellisesti tarkoitettu. Tämä tieto toimii etäohjauksena, joka ohjaa todennäköisyysmallien valvomatonta koulutusprosessia. Kokeet osoittavat, että kokonaismallimme toimii kilpailullisesti valvottuja menetelmiä vastaan.</abstract_fi>
      <abstract_jv>politenessoffpolite"), and when there is a change ("assertivepoliteness Perintah iki supoya sistem sing paling nggawe ora nesaturan pertama kanggo ngerasah dumadhi iki dadi. Awak dhéwé éntuk nggambar aturan sing perusahaan ning model sing berarti ngono nggawe ngulinggo perusahaan Awak dhéwé, kéné ngerasakno ngono hal-bawih éntuk ning heuristik nyebutiné kanggo nggawe gambar alik dhéwé, nggawe awak dhéwé ngerasakno ngono nggawe sistem sing berartik dhéwé, sing paling dhéwé. Awakdhéwé iki dadi mbugu perbudhakan sampeyan anyar tentang kanggo ngubah perusahaan cara sing gak nggawe modèl. Isopo sing ngomong nik akeh model sing paling-alih dumadhi iki banget supoyo maneh sing nguasai.</abstract_jv>
      <abstract_ha>Babu da wasu bakarãrar jãhilci kan an fassara su da fassaraki ko da littafi, sunã daidai a kan muhimmanci. Wannan karatun na buƙata wata metode da ba'a tsare ta ba don ya gane amfani da ake yi wa amfani da dumbuwa. Kana yarda da amfani da masu iya ƙara cikin misãlai masu yiwuwa kuma Muke sanar da su a cikin wani fili wanda aka yi kashi da harshen. Ina bayan haka, munã nuna cema masu diffaniki ne mai amfani ga rarraba amfani da littãfin na'asar idima, kuma yana bã mu wani hani ga za'a samo wani amfani da littafi na littafi ko kuma za'a ƙaddara a kan muhimmin da za'a yi amfani da idima. This information then serves as a form of distant supervision to guide the unsupervised training process for the probabilistic models.  Tajarakin na nuna cewa misalinmu a jumla, yana aiki daidai a kangara a kan tsari.</abstract_ha>
      <abstract_sk>Veliko idiomatskih izrazov je mogoče interpretirati figurativno ali dobesedno glede na njihov kontekst. V prispevku je predlagana metoda nenadzorovanega učenja za prepoznavanje predvidenih uporab jezikov. Uporabe obravnavamo kot latentno spremenljivko v verjetnostnih modelih in jih usposabljamo v jezikovno motiviranem funkcijskem prostoru. Ključnega pomena je, da je distribucijska semantika koristna heuristika pri razlikovanju dobesedne uporabe idiomov, kar nam daje način, da formuliramo dobesedno metriko uporabe za oceno verjetnosti, da je idiom namenjen dobesedno. Te informacije nato služijo kot oblika nadzora na daljavo, ki vodi proces nenadzorovanega usposabljanja za verjetnostne modele. Eksperimenti kažejo, da naš celotni model deluje konkurenčno proti nadzorovanim metodam.</abstract_sk>
      <abstract_he>ביטויים אידיומטיים רבים יכולים להתפרש בצורה ציונית או מילולית תלוי בקשר שלהם. העבודה הזו מציעה שיטת לימוד ללא השגחה לזהות את השימושים המתכוונים של אידיומים. We treat the usages as a latent variable in probabilistic models and train them in a linguistically motivated feature space.  במיוחד, אנו מראים שסמנטיקה פיצועית היא היוריסטית מועילה להבחין את השימוש המילותי של אידיומים, נותנת לנו דרך ליצור מטריקה להשתמש המילותי כדי להעריך את הסיכוי שהאידיום מתכוון באופן מילולי. המידע הזה משמש כצורה של פיקוח מרוחק כדי להדריך את תהליך האימונים הלא משומר למודלים הפרוביליסטיים. ניסויים מראים שהמודל הכללי שלנו מתפקד בתחרות נגד שיטות מפקחות.</abstract_he>
      <abstract_bo>སྐད་ཡིག་གི་གསལ་བརྗོད་མང་པོ་ཞིག་ལ་གཟུགས་རིས་རང་གི་གནས་ཚུལ་དང་གཞི་རྟེན་ཏུ་འགྲེལ་བཤད་ཐུབ། ཤོག་བྱང་འདིས་སྔོན་ཡོད་པའི་ལྟ་བུའི་ལག་ལེན་འཐབ་རྩིས་མེད་ལག་ལེན་བྱེད་སྟངས་དང་། We treat the uses as a latent variable in probabilistic models and train them in a linguistically motivated feature space. Crucially, we show that distributional semantics is a helpful heuristic for distinguishing the literal usage of idioms, giving us a way to formulate a literal usage metric to estimate the likelihood that the idiom is intended literally. དེ་ནས་ཆ་འཕྲིན་དེ་ནི་བར་ཐག་རིང་ལྟ་བུའི་རྣམ་པ་ཞིག་གིས་བདེ་སྐྱོང་བ་མེད་པའི་གོ་སྐབས་ཀྱི་ལས་རིམ་སྟོན་གྱི་ཡོད། ལག་ལེན་བྱེད་དགོས་བྱས་ན་ང་ཚོའི་མ་དབྱིབས་ཡོད་ཚད་ལྟ་རྟོག་པའི་ཐབས་ལམ་ལུགས་སྡོབ་བྱེད་མི་འདུག</abstract_bo>
      </paper>
    <paper id="204">
      <title>Neural Related Work Summarization with a Joint Context-driven Attention Mechanism</title>
      <author><first>Yongzhen</first><last>Wang</last></author>
      <author><first>Xiaozhong</first><last>Liu</last></author>
      <author><first>Zheng</first><last>Gao</last></author>
      <pages>1776–1786</pages>
      <url hash="444eaa5f">D18-1204</url>
      <abstract>Conventional solutions to automatic related work summarization rely heavily on human-engineered features. In this paper, we develop a neural data-driven summarizer by leveraging the seq2seq paradigm, in which a joint context-driven attention mechanism is proposed to measure the contextual relevance within full texts and a heterogeneous bibliography graph simultaneously. Our motivation is to maintain the topic coherency between a related work section and its target document, where both the textual and graphic contexts play a big role in characterizing the relationship among <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific publications</a> accurately. Experimental results on a large dataset show that our approach achieves a considerable improvement over a typical seq2seq summarizer and five classical summarization baselines.</abstract>
      <video href="https://vimeo.com/305686976" />
      <doi>10.18653/v1/D18-1204</doi>
      <bibkey>wang-etal-2018-neural-related</bibkey>
      <pwccode url="https://github.com/kuadmu/2018EMNLP" additional="false">kuadmu/2018EMNLP</pwccode>
    </paper>
    <paper id="205">
      <title>Improving Neural Abstractive Document Summarization with Explicit Information Selection Modeling</title>
      <author><first>Wei</first><last>Li</last></author>
      <author><first>Xinyan</first><last>Xiao</last></author>
      <author><first>Yajuan</first><last>Lyu</last></author>
      <author><first>Yuanzhuo</first><last>Wang</last></author>
      <pages>1787–1796</pages>
      <url hash="0e94c89c">D18-1205</url>
      <attachment type="attachment" hash="b0eecca5">D18-1205.Attachment.pdf</attachment>
      <abstract>Information selection is the most important component in document summarization task. In this paper, we propose to extend the basic neural encoding-decoding framework with an information selection layer to explicitly model and optimize the information selection process in abstractive document summarization. Specifically, our information selection layer consists of two parts : gated global information filtering and local sentence selection. Unnecessary information in the original document is first globally filtered, then salient sentences are selected locally while generating each summary sentence sequentially. To optimize the information selection process directly, distantly-supervised training guided by the golden summary is also imported. Experimental results demonstrate that the explicit modeling and optimizing of the information selection process improves document summarization performance significantly, which enables our model to generate more informative and concise summaries, and thus significantly outperform state-of-the-art neural abstractive methods.</abstract>
      <video href="https://vimeo.com/305885506" />
      <doi>10.18653/v1/D18-1205</doi>
      <bibkey>li-etal-2018-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="207">
      <title>Improving Abstraction in Text Summarization</title>
      <author><first>Wojciech</first><last>Kryściński</last></author>
      <author><first>Romain</first><last>Paulus</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <author><first>Richard</first><last>Socher</last></author>
      <pages>1808–1817</pages>
      <url hash="68a480d7">D18-1207</url>
      <abstract>Abstractive text summarization aims to shorten long text documents into a human readable form that contains the most important facts from the original document. However, the level of actual abstraction as measured by novel phrases that do not appear in the source document remains low in existing approaches. We propose two techniques to improve the level of abstraction of generated summaries. First, we decompose the decoder into a contextual network that retrieves relevant parts of the source document, and a pretrained language model that incorporates prior knowledge about language generation. Second, we propose a novelty metric that is optimized directly through <a href="https://en.wikipedia.org/wiki/Policy_learning">policy learning</a> to encourage the generation of novel phrases. Our model achieves results comparable to state-of-the-art models, as determined by ROUGE scores and human evaluations, while achieving a significantly higher level of abstraction as measured by n-gram overlap with the source document.</abstract>
      <video href="https://vimeo.com/305886179" />
      <doi>10.18653/v1/D18-1207</doi>
      <bibkey>kryscinski-etal-2018-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="208">
      <title>Content Selection in Deep Learning Models of Summarization</title>
      <author><first>Chris</first><last>Kedzie</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <author><first>Hal</first><last>Daumé III</last></author>
      <pages>1818–1828</pages>
      <url hash="ec38c396">D18-1208</url>
      <revision id="1" href="D18-1208v1" hash="6f8f065b" />
      <revision id="2" href="D18-1208v2" hash="ec38c396">No description of the changes were recorded.</revision>
      <attachment type="attachment" hash="67a8078d">D18-1208.Attachment.pdf</attachment>
      <abstract>We carry out experiments with deep learning models of <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a> across the domains of <a href="https://en.wikipedia.org/wiki/News">news</a>, personal stories, meetings, and <a href="https://en.wikipedia.org/wiki/Medicine">medical articles</a> in order to understand how content selection is performed. We find that many sophisticated <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> of state of the art extractive summarizers do not improve performance over simpler <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. These results suggest that it is easier to create a <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarizer</a> for a new domain than previous work suggests and bring into question the benefit of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> for <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a> for those domains that do have <a href="https://en.wikipedia.org/wiki/Big_data">massive datasets</a> (i.e., news). At the same time, they suggest important questions for new research in summarization ; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the sumarization task.</abstract>
      <video href="https://vimeo.com/305886331" />
      <doi>10.18653/v1/D18-1208</doi>
      <bibkey>kedzie-etal-2018-content</bibkey>
      <pwccode url="https://github.com/kedz/nnsum" additional="true">kedz/nnsum</pwccode>
    </paper>
    <paper id="209">
      <title>Improved Semantic-Aware Network Embedding with Fine-Grained Word Alignment</title>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Xinyuan</first><last>Zhang</last></author>
      <author><first>Ricardo</first><last>Henao</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>1829–1838</pages>
      <url hash="059cbc00">D18-1209</url>
      <abstract>Network embeddings, which learns low-dimensional representations for each <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">vertex</a> in a large-scale network, have received considerable attention in recent years. For a wide range of applications, <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">vertices</a> in a <a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">network</a> are typically accompanied by rich textual information such as user profiles, paper abstracts, etc. In this paper, we propose to incorporate semantic features into <a href="https://en.wikipedia.org/wiki/Graph_embedding">network embeddings</a> by matching important words between text sequences for all pairs of <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">vertices</a>. We introduce an word-by-word alignment framework that measures the compatibility of embeddings between word pairs, and then adaptively accumulates these alignment features with a simple yet effective aggregation function. In experiments, we evaluate the proposed framework on three real-world benchmarks for downstream tasks, including link prediction and multi-label vertex classification. The experimental results demonstrate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state-of-the-art network embedding methods by a large margin.</abstract>
      <video href="https://vimeo.com/306030030" />
      <doi>10.18653/v1/D18-1209</doi>
      <bibkey>shen-etal-2018-improved</bibkey>
    </paper>
    <paper id="210">
      <title>Learning Context-Sensitive Convolutional Filters for <a href="https://en.wikipedia.org/wiki/Text_processing">Text Processing</a></title>
      <author><first>Dinghan</first><last>Shen</last></author>
      <author><first>Martin Renqiang</first><last>Min</last></author>
      <author><first>Yitong</first><last>Li</last></author>
      <author><first>Lawrence</first><last>Carin</last></author>
      <pages>1839–1848</pages>
      <url hash="3f2360b2">D18-1210</url>
      <abstract>Convolutional neural networks (CNNs) have recently emerged as a popular building block for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing (NLP)</a>. Despite their success, most existing CNN models employed in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> share the same learned (and static) set of <a href="https://en.wikipedia.org/wiki/Filter_(signal_processing)">filters</a> for all input sentences. In this paper, we consider an approach of using a small meta network to learn context-sensitive convolutional filters for <a href="https://en.wikipedia.org/wiki/Text_processing">text processing</a>. The role of meta network is to abstract the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> of a sentence or document into a set of input-sensitive filters. We further generalize this framework to model sentence pairs, where a bidirectional filter generation mechanism is introduced to encapsulate co-dependent sentence representations. In our benchmarks on four different tasks, including ontology classification, sentiment analysis, answer sentence selection, and paraphrase identification, our proposed model, a modified CNN with context-sensitive filters, consistently outperforms the standard CNN and attention-based CNN baselines. By visualizing the learned context-sensitive filters, we further validate and rationalize the effectiveness of proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a>.</abstract>
      <video href="https://vimeo.com/306040551" />
      <doi>10.18653/v1/D18-1210</doi>
      <bibkey>shen-etal-2018-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="211">
      <title>Deep Relevance Ranking Using Enhanced Document-Query Interactions</title>
      <author><first>Ryan</first><last>McDonald</last></author>
      <author><first>George</first><last>Brokos</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>1849–1860</pages>
      <url hash="0a1a4e29">D18-1211</url>
      <attachment type="attachment" hash="f72f8e9d">D18-1211.Attachment.zip</attachment>
      <abstract>We explore several new models for document relevance ranking, building upon the Deep Relevance Matching Model (DRMM) of Guo et al. Unlike DRMM, which uses context-insensitive encodings of terms and query-document term interactions, we inject rich context-sensitive encodings throughout our models, inspired by PACRR’s (Hui et al., 2017) convolutional n-gram matching features, but extended in several ways including multiple views of query and document inputs. We test our models on datasets from the BIOASQ question answering challenge (Tsatsaronis et al., 2015) and TREC ROBUST 2004 (Voorhees, 2005), showing they outperform BM25-based baselines, DRMM, and PACRR.</abstract>
      <video href="https://vimeo.com/306041612" />
      <doi>10.18653/v1/D18-1211</doi>
      <bibkey>mcdonald-etal-2018-deep</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/bioasq">BioASQ</pwcdataset>
    </paper>
    <paper id="213">
      <title>AD3 : Attentive Deep Document Dater<fixed-case>AD</fixed-case>3: Attentive Deep Document Dater</title>
      <author><first>Swayambhu Nath</first><last>Ray</last></author>
      <author><first>Shib Sankar</first><last>Dasgupta</last></author>
      <author><first>Partha</first><last>Talukdar</last></author>
      <pages>1871–1880</pages>
      <url hash="7cbf3f83">D18-1213</url>
      <abstract>Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc. Unfortunately, for most of the documents on the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">Web</a>, the time-stamp metadata is either missing or ca n’t be trusted. Thus, predicting creation time from document content itself is an important task. In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner. We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines.</abstract>
      <video href="https://vimeo.com/306043956" />
      <doi>10.18653/v1/D18-1213</doi>
      <bibkey>ray-etal-2018-ad3</bibkey>
      <pwccode url="https://github.com/malllabiisc/AD3" additional="false">malllabiisc/AD3</pwccode>
    </paper>
    <paper id="216">
      <title>Deriving Machine Attention from Human Rationales</title>
      <author><first>Yujia</first><last>Bao</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <pages>1903–1913</pages>
      <url hash="f9133bec">D18-1216</url>
      <attachment type="attachment" hash="d585d4e2">D18-1216.Attachment.zip</attachment>
      <abstract>Attention-based models are successful when trained on large amounts of data. In this paper, we demonstrate that even in the low-resource scenario, <a href="https://en.wikipedia.org/wiki/Attention">attention</a> can be learned effectively. To this end, we start with discrete human-annotated rationales and map them into continuous attention. Our central hypothesis is that this <a href="https://en.wikipedia.org/wiki/Map_(mathematics)">mapping</a> is general across domains, and thus can be transferred from resource-rich domains to low-resource ones. Our model jointly learns a domain-invariant representation and induces the desired mapping between rationales and <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. Our empirical results validate this hypothesis and show that our approach delivers significant gains over state-of-the-art baselines, yielding over 15 % average error reduction on benchmark datasets.</abstract>
      <video href="https://vimeo.com/305661928" />
      <doi>10.18653/v1/D18-1216</doi>
      <bibkey>bao-etal-2018-deriving</bibkey>
      <pwccode url="https://github.com/YujiaBao/R2A" additional="true">YujiaBao/R2A</pwccode>
    </paper>
    <paper id="219">
      <title>A Deterministic Algorithm for Bridging Anaphora Resolution</title>
      <author><first>Yufang</first><last>Hou</last></author>
      <pages>1938–1948</pages>
      <url hash="ef4dd097">D18-1219</url>
      <abstract>Previous work on bridging anaphora resolution (Poesio et al., 2004 ; Hou et al., 2013) use syntactic preposition patterns to calculate word relatedness. However, such patterns only consider <a href="https://en.wikipedia.org/wiki/Noun_phrase">NPs’ head nouns</a> and hence do not fully capture the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of <a href="https://en.wikipedia.org/wiki/Noun_phrase">NPs</a>. Recently, Hou (2018) created word embeddings (embeddings_PP) to capture associative similarity (i.e., relatedness) between <a href="https://en.wikipedia.org/wiki/Noun">nouns</a> by exploring the syntactic structure of noun phrases. But embeddings_PP only contains <a href="https://en.wikipedia.org/wiki/Word_formation">word representations</a> for <a href="https://en.wikipedia.org/wiki/Noun">nouns</a>. In this paper, we create new word vectors by combining embeddings_PP with <a href="https://en.wikipedia.org/wiki/GloVe">GloVe</a>. This new word embeddings (embeddings_bridging) are a more general lexical knowledge resource for bridging and allow us to represent the meaning of an NP beyond its head easily. We therefore develop a deterministic approach for bridging anaphora resolution, which represents the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of an <a href="https://en.wikipedia.org/wiki/NP_(complexity)">NP</a> based on its head noun and modifications. We show that this simple approach achieves the competitive results compared to the best <a href="https://en.wikipedia.org/wiki/System">system</a> in Hou et al. (2013) which explores <a href="https://en.wikipedia.org/wiki/Markov_logic_network">Markov Logic Networks</a> to model the <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>. Additionally, we further improve the results for bridging anaphora resolution reported in Hou (2018) by combining our simple deterministic approach with Hou et al. (2013)’s best system MLN II.</abstract>
      <doi>10.18653/v1/D18-1219</doi>
      <bibkey>hou-2018-deterministic</bibkey>
    </paper>
    <paper id="221">
      <title>Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs<fixed-case>LSTM</fixed-case>s</title>
      <author><first>Dimitri</first><last>Kartsaklis</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <author><first>Nigel</first><last>Collier</last></author>
      <pages>1959–1970</pages>
      <url hash="695c1177">D18-1221</url>
      <abstract>This paper addresses the problem of mapping <a href="https://en.wikipedia.org/wiki/Natural_language">natural language text</a> to knowledge base entities. The mapping process is approached as a composition of a phrase or a sentence into a point in a multi-dimensional entity space obtained from a <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graph</a>. The compositional model is an LSTM equipped with a dynamic disambiguation mechanism on the input word embeddings (a Multi-Sense LSTM), addressing polysemy issues. Further, the knowledge base space is prepared by collecting random walks from a <a href="https://en.wikipedia.org/wiki/Graph_(abstract_data_type)">graph</a> enhanced with textual features, which act as a set of semantic bridges between text and knowledge base entities. The ideas of this work are demonstrated on large-scale text-to-entity mapping and entity classification tasks, with state of the art results.</abstract>
      <doi>10.18653/v1/D18-1221</doi>
      <bibkey>kartsaklis-etal-2018-mapping</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cora">Cora</pwcdataset>
    </paper>
    <paper id="223">
      <title>One-Shot Relational Learning for Knowledge Graphs</title>
      <author><first>Wenhan</first><last>Xiong</last></author>
      <author><first>Mo</first><last>Yu</last></author>
      <author><first>Shiyu</first><last>Chang</last></author>
      <author><first>Xiaoxiao</first><last>Guo</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>1980–1990</pages>
      <url hash="ebc9bc6b">D18-1223</url>
      <attachment type="attachment" hash="b19a1428">D18-1223.Attachment.pdf</attachment>
      <abstract>Knowledge graphs (KG) are the key components of various <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing applications</a>. To further expand KGs’ coverage, previous studies on knowledge graph completion usually require a large number of positive examples for each relation. However, we observe long-tail relations are actually more common in KGs and those newly added relations often do not have many known triples for training. In this work, we aim at predicting new facts under a challenging setting where only one training instance is available. We propose a one-shot relational learning framework, which utilizes the knowledge distilled by embedding models and learns a matching metric by considering both the learned embeddings and one-hop graph structures. Empirically, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> yields considerable performance improvements over existing <a href="https://en.wikipedia.org/wiki/Embedding">embedding models</a>, and also eliminates the need of re-training the <a href="https://en.wikipedia.org/wiki/Embedding">embedding models</a> when dealing with newly added relations.</abstract>
      <doi>10.18653/v1/D18-1223</doi>
      <bibkey>xiong-etal-2018-one</bibkey>
      <pwccode url="https://github.com/xwhan/One-shot-Relational-Learning" additional="false">xwhan/One-shot-Relational-Learning</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wiki-one">Wiki-One</pwcdataset>
    </paper>
    <paper id="224">
      <title>Regular Expression Guided Entity Mention Mining from Noisy Web Data</title>
      <author><first>Shanshan</first><last>Zhang</last></author>
      <author><first>Lihong</first><last>He</last></author>
      <author><first>Slobodan</first><last>Vucetic</last></author>
      <author><first>Eduard</first><last>Dragut</last></author>
      <pages>1991–2000</pages>
      <url hash="c962b288">D18-1224</url>
      <attachment type="attachment" hash="c311a89e">D18-1224.Attachment.zip</attachment>
      <abstract>Many important entity types in web documents, such as dates, times, email addresses, and course numbers, follow or closely resemble patterns that can be described by Regular Expressions (REs). Due to a vast diversity of web documents and ways in which they are being generated, even seemingly straightforward tasks such as identifying mentions of date in a document become very challenging. It is reasonable to claim that it is impossible to create a RE that is capable of identifying such entities from <a href="https://en.wikipedia.org/wiki/Web_page">web documents</a> with perfect <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">precision</a> and <a href="https://en.wikipedia.org/wiki/Recall_(memory)">recall</a>. Rather than abandoning REs as a go-to approach for <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity detection</a>, this paper explores ways to combine the expressive power of REs, ability of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> to learn from large data, and human-in-the loop approach into a new integrated framework for <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity identification</a> from web data. The <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> starts by creating or collecting the existing REs for a particular type of an entity. Those REs are then used over a large document corpus to collect weak labels for the entity mentions and a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> is trained to predict those RE-generated weak labels. Finally, a human expert is asked to label a small set of documents and the <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> is fine tuned on those documents. The experimental evaluation on several entity identification problems shows that the proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> achieves impressive <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, while requiring very modest human effort.</abstract>
      <doi>10.18653/v1/D18-1224</doi>
      <bibkey>zhang-etal-2018-regular</bibkey>
    </paper>
    <paper id="226">
      <title>Neural Adaptation Layers for Cross-domain Named Entity Recognition</title>
      <author><first>Bill Yuchen</first><last>Lin</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <pages>2012–2022</pages>
      <url hash="b063c080">D18-1226</url>
      <abstract>Recent research efforts have shown that neural architectures can be effective in conventional information extraction tasks such as <a href="https://en.wikipedia.org/wiki/Named-entity_recognition">named entity recognition</a>, yielding state-of-the-art results on standard newswire datasets. However, despite significant resources required for training such models, the performance of a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on one domain typically degrades dramatically when applied to a different domain, yet extracting entities from new emerging domains such as <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> can be of significant interest. In this paper, we empirically investigate effective methods for conveniently adapting an existing, well-trained neural NER model for a new domain. Unlike existing approaches, we propose lightweight yet effective <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> for performing <a href="https://en.wikipedia.org/wiki/Domain_adaptation">domain adaptation</a> for neural models. Specifically, we introduce adaptation layers on top of existing neural architectures, where no re-training using the source domain data is required. We conduct extensive empirical studies and show that our approach significantly outperforms state-of-the-art methods.</abstract>
      <doi>10.18653/v1/D18-1226</doi>
      <bibkey>lin-lu-2018-neural</bibkey>
    </paper>
    <paper id="228">
      <title>Annotation of a Large Clinical Entity Corpus</title>
      <author><first>Pinal</first><last>Patel</last></author>
      <author><first>Disha</first><last>Davey</last></author>
      <author><first>Vishal</first><last>Panchal</last></author>
      <author><first>Parth</first><last>Pathak</last></author>
      <pages>2033–2042</pages>
      <url hash="3fad55fb">D18-1228</url>
      <abstract>Having an entity annotated corpus of the clinical domain is one of the basic requirements for detection of clinical entities using <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning (ML) approaches</a>. Past researches have shown the superiority of statistical / ML approaches over the rule based approaches. But in order to take full advantage of the ML approaches, an accurately annotated corpus becomes an essential requirement. Though there are a few annotated corpora available either on a small data set, or covering a narrower domain (like cancer patients records, lab reports), <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> of a large data set representing the entire clinical domain has not been created yet. In this paper, we have described in detail the annotation guidelines, annotation process and our approaches in creating a CER (clinical entity recognition) corpus of 5,160 clinical documents from forty different clinical specialities. The clinical entities range across various types such as diseases, <a href="https://en.wikipedia.org/wiki/Medical_procedure">procedures</a>, <a href="https://en.wikipedia.org/wiki/Medication">medications</a>, <a href="https://en.wikipedia.org/wiki/Medical_device">medical devices</a> and so on. We have classified them into eleven categories for <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>. Our <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a> also reflects the relations among the group of entities that constitute larger concepts altogether.</abstract>
      <doi>10.18653/v1/D18-1228</doi>
      <bibkey>patel-etal-2018-annotation</bibkey>
    </paper>
    <paper id="230">
      <title>Learning Named Entity Tagger using Domain-Specific Dictionary</title>
      <author><first>Jingbo</first><last>Shang</last></author>
      <author><first>Liyuan</first><last>Liu</last></author>
      <author><first>Xiaotao</first><last>Gu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Teng</first><last>Ren</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <pages>2054–2064</pages>
      <url hash="752a2c30">D18-1230</url>
      <abstract>Recent advances in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural models</a> allow us to build reliable named entity recognition (NER) systems without handcrafting features. However, such <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> require large amounts of manually-labeled training data. There have been efforts on replacing human annotations with distant supervision (in conjunction with external dictionaries), but the generated noisy labels pose significant challenges on learning effective neural models. Here we propose two neural models to suit noisy distant supervision from the dictionary. First, under the traditional sequence labeling framework, we propose a revised fuzzy CRF layer to handle tokens with multiple possible labels. After identifying the nature of noisy labels in distant supervision, we go beyond the traditional framework and propose a novel, more effective neural model AutoNER with a new Tie or Break scheme. In addition, we discuss how to refine distant supervision for better NER performance. Extensive experiments on three benchmark datasets demonstrate that AutoNER achieves the best performance when only using dictionaries with no additional human effort, and delivers competitive results with state-of-the-art supervised benchmarks.</abstract>
      <doi>10.18653/v1/D18-1230</doi>
      <bibkey>shang-etal-2018-learning</bibkey>
      <pwccode url="https://github.com/shangjingbo1226/AutoNER" additional="false">shangjingbo1226/AutoNER</pwccode>
    </paper>
    <paper id="233">
      <title>Interpretation of Natural Language Rules in Conversational Machine Reading</title>
      <author><first>Marzieh</first><last>Saeidi</last></author>
      <author><first>Max</first><last>Bartolo</last></author>
      <author><first>Patrick</first><last>Lewis</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <author><first>Tim</first><last>Rocktäschel</last></author>
      <author><first>Mike</first><last>Sheldon</last></author>
      <author><first>Guillaume</first><last>Bouchard</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <pages>2087–2097</pages>
      <url hash="e538c291">D18-1233</url>
      <attachment type="attachment" hash="9e0af49f">D18-1233.Attachment.zip</attachment>
      <abstract>Most work in <a href="https://en.wikipedia.org/wiki/Machine_reading">machine reading</a> focuses on question answering problems where the answer is directly expressed in the text to read. However, many real-world question answering problems require the reading of text not because it contains the literal answer, but because it contains a recipe to derive an answer together with the reader’s background knowledge. One example is the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> of interpreting regulations to answer Can I...? or Do I have to...? questions such as I am working in Canada. Do I have to carry on paying UK National Insurance? after reading a UK government website about this topic. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> requires both the interpretation of rules and the application of background knowledge. It is further complicated due to the fact that, in practice, most questions are underspecified, and a human assistant will regularly have to ask clarification questions such as How long have you been working abroad? when the answer can not be directly derived from the question and text. In this paper, we formalise this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and develop a crowd-sourcing strategy to collect 37k <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task instances</a> based on real-world rules and crowd-generated questions and scenarios. We analyse the challenges of this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and assess its difficulty by evaluating the performance of rule-based and machine-learning baselines. We observe promising results when no background knowledge is necessary, and substantial room for improvement whenever background knowledge is needed.</abstract>
      <doi>10.18653/v1/D18-1233</doi>
      <bibkey>saeidi-etal-2018-interpretation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sharc">ShARC</pwcdataset>
    </paper>
    <paper id="234">
      <title>A State-transition Framework to Answer Complex Questions over Knowledge Base</title>
      <author><first>Sen</first><last>Hu</last></author>
      <author><first>Lei</first><last>Zou</last></author>
      <author><first>Xinbo</first><last>Zhang</last></author>
      <pages>2098–2108</pages>
      <url hash="61247a23">D18-1234</url>
      <attachment type="attachment" hash="17492234">D18-1234.Attachment.pdf</attachment>
      <abstract>Although natural language question answering over <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a> have been studied in the literature, existing methods have some limitations in answering complex questions. To address that, in this paper, we propose a State Transition-based approach to translate a complex natural language question N to a semantic query graph (SQG), which is used to match the underlying knowledge graph to find the answers to question N. In order to generate SQG, we propose four primitive operations (expand, fold, connect and merge) and a learning-based state transition approach. Extensive experiments on several benchmarks (such as QALD, WebQuestions and ComplexQuestions) with two knowledge bases (DBpedia and Freebase) confirm the superiority of our approach compared with state-of-the-arts.</abstract>
      <doi>10.18653/v1/D18-1234</doi>
      <bibkey>hu-etal-2018-state</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="236">
      <title>Logician and Orator : Learning from the Duality between Language and Knowledge in Open Domain</title>
      <author><first>Mingming</first><last>Sun</last></author>
      <author><first>Xu</first><last>Li</last></author>
      <author><first>Ping</first><last>Li</last></author>
      <pages>2119–2130</pages>
      <url hash="318e7a04">D18-1236</url>
      <abstract>We propose the task of Open-Domain Information Narration (OIN) as the reverse task of Open Information Extraction (OIE), to implement the dual structure between language and knowledge in the open domain. Then, we develop an agent, called Orator, to accomplish the OIN task, and assemble the Orator and the recently proposed OIE agent   Logician into a dual system to utilize the duality structure with a reinforcement learning paradigm. Experimental results reveal the dual structure between OIE and OIN tasks helps to build better both OIE agents and OIN agents.</abstract>
      <doi>10.18653/v1/D18-1236</doi>
      <bibkey>sun-etal-2018-logician</bibkey>
    </paper>
    <paper id="237">
      <title>MemoReader : Large-Scale Reading Comprehension through Neural Memory Controller<fixed-case>M</fixed-case>emo<fixed-case>R</fixed-case>eader: Large-Scale Reading Comprehension through Neural Memory Controller</title>
      <author><first>Seohyun</first><last>Back</last></author>
      <author><first>Seunghak</first><last>Yu</last></author>
      <author><first>Sathish Reddy</first><last>Indurthi</last></author>
      <author><first>Jihie</first><last>Kim</last></author>
      <author><first>Jaegul</first><last>Choo</last></author>
      <pages>2131–2140</pages>
      <url hash="dde161f9">D18-1237</url>
      <attachment type="attachment" hash="b28c6a9b">D18-1237.Attachment.pdf</attachment>
      <abstract>Machine reading comprehension helps machines learn to utilize most of the human knowledge written in the form of text. Existing approaches made a significant progress comparable to human-level performance, but they are still limited in understanding, up to a few paragraphs, failing to properly comprehend lengthy document. In this paper, we propose a novel deep neural network architecture to handle a <a href="https://en.wikipedia.org/wiki/Long-range_dependency">long-range dependency</a> in RC tasks. In detail, our method has two novel aspects : (1) an advanced memory-augmented architecture and (2) an expanded gated recurrent unit with dense connections that mitigate potential information distortion occurring in the <a href="https://en.wikipedia.org/wiki/Memory">memory</a>. Our proposed <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a> is widely applicable to other <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>. We have performed extensive experiments with well-known benchmark datasets such as TriviaQA, QUASAR-T, and SQuAD. The experimental results demonstrate that the proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a> outperforms existing <a href="https://en.wikipedia.org/wiki/Methodology">methods</a>, especially for lengthy documents.</abstract>
      <doi>10.18653/v1/D18-1237</doi>
      <bibkey>back-etal-2018-memoreader</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
    </paper>
    <paper id="238">
      <title>Multi-Granular Sequence Encoding via Dilated Compositional Units for Reading Comprehension</title>
      <author><first>Yi</first><last>Tay</last></author>
      <author><first>Anh Tuan</first><last>Luu</last></author>
      <author><first>Siu Cheung</first><last>Hui</last></author>
      <pages>2141–2151</pages>
      <url hash="528fcad8">D18-1238</url>
      <abstract>Sequence encoders are crucial components in many neural architectures for learning to read and comprehend. This paper presents a new compositional encoder for reading comprehension (RC). Our proposed <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> is not only aimed at being fast but also expressive. Specifically, the key novelty behind our <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> is that it explicitly models across multiple granularities using a new dilated composition mechanism. In our approach, gating functions are learned by modeling relationships and reasoning over multi-granular sequence information, enabling compositional learning that is aware of both long and short term information. We conduct experiments on three RC datasets, showing that our proposed <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> demonstrates very promising results both as a standalone encoder as well as a complementary building block. Empirical results show that simple Bi-Attentive architectures augmented with our proposed <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> not only achieves state-of-the-art / highly competitive results but is also considerably faster than other published works.</abstract>
      <doi>10.18653/v1/D18-1238</doi>
      <bibkey>tay-etal-2018-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/narrativeqa">NarrativeQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/searchqa">SearchQA</pwcdataset>
    </paper>
    <paper id="239">
      <title>Neural Compositional Denotational Semantics for Question Answering</title>
      <author><first>Nitish</first><last>Gupta</last></author>
      <author><first>Mike</first><last>Lewis</last></author>
      <pages>2152–2161</pages>
      <url hash="2262c0d3">D18-1239</url>
      <attachment type="attachment" hash="c5256ade">D18-1239.Attachment.pdf</attachment>
      <abstract>Answering compositional questions requiring multi-step reasoning is challenging. We introduce an end-to-end differentiable model for interpreting questions about a knowledge graph (KG), which is inspired by formal approaches to <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a>. Each span of text is represented by a denotation in a KG and a <a href="https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)">vector</a> that captures ungrounded aspects of meaning. Learned composition modules recursively combine constituent spans, culminating in a grounding for the complete sentence which answers the question. For example, to interpret not green, the model represents <a href="https://en.wikipedia.org/wiki/Green">green</a> as a set of KG entities and not as a trainable ungrounded vectorand then uses this vector to parameterize a <a href="https://en.wikipedia.org/wiki/Function_composition">composition function</a> that performs a <a href="https://en.wikipedia.org/wiki/Complement_(set_theory)">complement operation</a>. For each sentence, we build a parse chart subsuming all possible <a href="https://en.wikipedia.org/wiki/Parsing">parses</a>, allowing the model to jointly learn both the composition operators and output structure by <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> from end-task supervision. The model learns a variety of challenging semantic operators, such as <a href="https://en.wikipedia.org/wiki/Quantifier_(linguistics)">quantifiers</a>, <a href="https://en.wikipedia.org/wiki/Logical_disjunction">disjunctions</a> and composed relations, and infers latent syntactic structure. It also generalizes well to longer questions than seen in its training data, in contrast to RNN, its tree-based variants, and semantic parsing baselines.</abstract>
      <doi>10.18653/v1/D18-1239</doi>
      <bibkey>gupta-lewis-2018-neural</bibkey>
    </paper>
    <paper id="240">
      <title>Cross-Pair Text Representations for Answer Sentence Selection</title>
      <author><first>Kateryna</first><last>Tymoshenko</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>2162–2173</pages>
      <url hash="761c6a1d">D18-1240</url>
      <abstract>High-level semantics tasks, e.g., paraphrasing, textual entailment or question answering, involve modeling of text pairs. Before the emergence of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>, this has been mostly performed using intra-pair features, which incorporate similarity scores or rewrite rules computed between the members within the same pair. In this paper, we compute scalar products between vectors representing similarity between members of different pairs, in place of simply using a single vector for each pair. This allows us to obtain a representation specific to any pair of pairs, which delivers the state of the art in answer sentence selection. Most importantly, our approach can outperform much more complex <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> based on <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>.</abstract>
      <doi>10.18653/v1/D18-1240</doi>
      <bibkey>tymoshenko-moschitti-2018-cross</bibkey>
      <pwccode url="https://github.com/iKernels/RelTextRank" additional="false">iKernels/RelTextRank</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="242">
      <title>Knowledge Base Question Answering via Encoding of Complex Query Graphs</title>
      <author><first>Kangqi</first><last>Luo</last></author>
      <author><first>Fengli</first><last>Lin</last></author>
      <author><first>Xusheng</first><last>Luo</last></author>
      <author><first>Kenny</first><last>Zhu</last></author>
      <pages>2185–2194</pages>
      <url hash="f7829f8d">D18-1242</url>
      <abstract>Answering complex questions that involve multiple entities and multiple relations using a standard <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> is an open and challenging task. Most existing KBQA approaches focus on simpler questions and do not work very well on complex questions because they were not able to simultaneously represent the question and the corresponding complex query structure. In this work, we encode such complex query structure into a uniform vector representation, and thus successfully capture the interactions between individual semantic components within a complex question. This approach consistently outperforms existing methods on <a href="https://en.wikipedia.org/wiki/Complex_question">complex questions</a> while staying competitive on simple questions.</abstract>
      <doi>10.18653/v1/D18-1242</doi>
      <bibkey>luo-etal-2018-knowledge</bibkey>
      <pwccode url="https://github.com/lkq1992yeah/CompQA" additional="false">lkq1992yeah/CompQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/simplequestions">SimpleQuestions</pwcdataset>
    </paper>
    <paper id="244">
      <title>Graph Convolution over Pruned Dependency Trees Improves Relation Extraction</title>
      <author><first>Yuhao</first><last>Zhang</last></author>
      <author><first>Peng</first><last>Qi</last></author>
      <author><first>Christopher D.</first><last>Manning</last></author>
      <pages>2205–2215</pages>
      <url hash="67edbf50">D18-1244</url>
      <attachment type="attachment" hash="20aa4f04">D18-1244.Attachment.pdf</attachment>
      <abstract>Dependency trees help relation extraction models capture long-range relations between words. However, existing dependency-based models either neglect crucial information (e.g., negation) by pruning the dependency trees too aggressively, or are computationally inefficient because it is difficult to parallelize over different <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree structures</a>. We propose an extension of graph convolutional networks that is tailored for <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>, which pools information over arbitrary dependency structures efficiently in parallel. To incorporate relevant information while maximally removing irrelevant content, we further apply a novel pruning strategy to the input <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">trees</a> by keeping words immediately around the shortest path between the two entities among which a relation might hold. The resulting <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves state-of-the-art performance on the large-scale TACRED dataset, outperforming existing sequence and dependency-based neural models. We also show through detailed analysis that this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> has complementary strengths to sequence models, and combining them further improves the state of the art.</abstract>
      <doi>10.18653/v1/D18-1244</doi>
      <bibkey>zhang-etal-2018-graph</bibkey>
      <pwccode url="https://github.com/qipeng/gcn-over-pruned-trees" additional="false">qipeng/gcn-over-pruned-trees</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/re-tacred">Re-TACRED</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tacred">TACRED</pwcdataset>
    </paper>
    <paper id="245">
      <title>Multi-Level Structured Self-Attentions for Distantly Supervised Relation Extraction</title>
      <author><first>Jinhua</first><last>Du</last></author>
      <author><first>Jingguang</first><last>Han</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <author><first>Dadong</first><last>Wan</last></author>
      <pages>2216–2225</pages>
      <url hash="272e7312">D18-1245</url>
      <abstract>Attention mechanism is often used in <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a> for distantly supervised relation extraction (DS-RE) to distinguish valid from noisy instances. However, traditional 1-D vector attention model is insufficient for learning of different contexts in the selection of valid instances to predict the relationship for an entity pair. To alleviate this issue, we propose a novel multi-level structured (2-D matrix) self-attention mechanism for DS-RE in a multi-instance learning (MIL) framework using bidirectional recurrent neural networks (BiRNN). In the proposed method, a structured word-level self-attention learns a <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">2-D matrix</a> where each row vector represents a <a href="https://en.wikipedia.org/wiki/Weight_distribution">weight distribution</a> for different aspects of an instance regarding two entities. Targeting the MIL issue, the structured sentence-level attention learns a <a href="https://en.wikipedia.org/wiki/Matrix_(mathematics)">2-D matrix</a> where each row vector represents a <a href="https://en.wikipedia.org/wiki/Weight_distribution">weight distribution</a> on selection of different valid instances. Experiments conducted on two publicly available DS-RE datasets show that the proposed framework with multi-level structured self-attention mechanism significantly outperform baselines in terms of PR curves, P@N and F1 measures.</abstract>
      <doi>10.18653/v1/D18-1245</doi>
      <bibkey>du-etal-2018-multi</bibkey>
    </paper>
    <paper id="248">
      <title>Label-Free Distant Supervision for Relation Extraction via Knowledge Graph Embedding</title>
      <author><first>Guanying</first><last>Wang</last></author>
      <author><first>Wen</first><last>Zhang</last></author>
      <author><first>Ruoxu</first><last>Wang</last></author>
      <author><first>Yalin</first><last>Zhou</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Hai</first><last>Zhu</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <pages>2246–2255</pages>
      <url hash="cb6dcc77">D18-1248</url>
      <abstract>Distant supervision is an effective method to generate large scale labeled data for <a href="https://en.wikipedia.org/wiki/Relation_extraction">relation extraction</a>, which assumes that if a pair of entities appears in some relation of a Knowledge Graph (KG), all sentences containing those entities in a large unlabeled corpus are then labeled with that relation to train a relation classifier. However, when the pair of entities has multiple relationships in the <a href="https://en.wikipedia.org/wiki/Kinetic_theory_of_gases">KG</a>, this assumption may produce noisy relation labels. This paper proposes a label-free distant supervision method, which makes no use of the relation labels under this inadequate assumption, but only uses the prior knowledge derived from the KG to supervise the learning of the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier</a> directly and softly. Specifically, we make use of the type information and the translation law derived from typical KG embedding model to learn <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> for certain sentence patterns. As the supervision signal is only determined by the two aligned entities, neither hard relation labels nor extra noise-reduction model for the bag of sentences is needed in this way. The experiments show that the <a href="https://en.wikipedia.org/wiki/Design_of_experiments">approach</a> performs well in current distant supervision dataset.</abstract>
      <doi>10.18653/v1/D18-1248</doi>
      <bibkey>wang-etal-2018-label</bibkey>
    </paper>
    <paper id="251">
      <title>Possessors Change Over Time : A Case Study with <a href="https://en.wikipedia.org/wiki/Work_of_art">Artworks</a></title>
      <author><first>Dhivya</first><last>Chinnappa</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <pages>2278–2287</pages>
      <url hash="b74c5481">D18-1251</url>
      <abstract>This paper presents a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> and experimental results to extract possession relations over time. We work with Wikipedia articles about artworks, and extract possession relations along with temporal information indicating when these <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a> are true. The annotation scheme yields many possessors over time for a given artwork, and experimental results show that an LSTM ensemble can automate the task.</abstract>
      <doi>10.18653/v1/D18-1251</doi>
      <bibkey>chinnappa-blanco-2018-possessors</bibkey>
    </paper>
    <paper id="252">
      <title>Using Lexical Alignment and Referring Ability to Address Data Sparsity in Situated Dialog Reference Resolution</title>
      <author><first>Todd</first><last>Shore</last></author>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <pages>2288–2297</pages>
      <url hash="132d768a">D18-1252</url>
      <attachment type="attachment" hash="69165eed">D18-1252.Attachment.pdf</attachment>
      <abstract>Referring to entities in situated dialog is a collaborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so. Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated. In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways : First, we trained a words-as-classifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog. We then used these semantic models to learn the general referring ability of each word, which is independent of referent features. These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data.</abstract>
      <video href="https://vimeo.com/305936322" />
      <doi>10.18653/v1/D18-1252</doi>
      <bibkey>shore-skantze-2018-using</bibkey>
    </paper>
    <paper id="253">
      <title>Subgoal Discovery for Hierarchical Dialogue Policy Learning</title>
      <author><first>Da</first><last>Tang</last></author>
      <author><first>Xiujun</first><last>Li</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <author><first>Chong</first><last>Wang</last></author>
      <author><first>Lihong</first><last>Li</last></author>
      <author><first>Tony</first><last>Jebara</last></author>
      <pages>2298–2309</pages>
      <url hash="bbf379c4">D18-1253</url>
      <abstract>Developing <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agents</a> to engage in complex goal-oriented dialogues is challenging partly because the main learning signals are very sparse in long conversations. In this paper, we propose a divide-and-conquer approach that discovers and exploits the hidden structure of the task to enable efficient <a href="https://en.wikipedia.org/wiki/Policy_learning">policy learning</a>. First, given successful example dialogues, we propose the Subgoal Discovery Network (SDN) to divide a complex goal-oriented task into a set of simpler subgoals in an unsupervised fashion. We then use these <a href="https://en.wikipedia.org/wiki/Goal">subgoals</a> to learn a multi-level policy by hierarchical reinforcement learning. We demonstrate our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> by building a dialogue agent for the composite task of travel planning. Experiments with simulated and real users show that our approach performs competitively against a state-of-the-art method that requires human-defined subgoals. Moreover, we show that the learned <a href="https://en.wikipedia.org/wiki/Goal">subgoals</a> are often human comprehensible.</abstract>
      <video href="https://vimeo.com/305937184" />
      <doi>10.18653/v1/D18-1253</doi>
      <bibkey>tang-etal-2018-subgoal</bibkey>
    </paper>
    <paper id="254">
      <title>Supervised Clustering of Questions into Intents for Dialog System Applications</title>
      <author><first>Iryna</first><last>Haponchyk</last></author>
      <author><first>Antonio</first><last>Uva</last></author>
      <author><first>Seunghak</first><last>Yu</last></author>
      <author><first>Olga</first><last>Uryupina</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>2310–2321</pages>
      <url hash="3a5ded43">D18-1254</url>
      <abstract>Modern automated dialog systems require complex dialog managers able to deal with <a href="https://en.wikipedia.org/wiki/User_intent">user intent</a> triggered by high-level semantic questions. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for automatically clustering questions into <a href="https://en.wikipedia.org/wiki/User_intent">user intents</a> to help the design tasks. Since questions are short texts, uncovering their <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> to group them together can be very challenging. We approach the problem by using powerful semantic classifiers from question duplicate / matching research along with a novel idea of supervised clustering methods based on structured output. We test our approach on two intent clustering corpora, showing an impressive improvement over previous methods for two languages / domains.</abstract>
      <video href="https://vimeo.com/305938531" />
      <doi>10.18653/v1/D18-1254</doi>
      <bibkey>haponchyk-etal-2018-supervised</bibkey>
    </paper>
    <paper id="255">
      <title>Towards Exploiting Background Knowledge for Building Conversation Systems</title>
      <author><first>Nikita</first><last>Moghe</last></author>
      <author><first>Siddhartha</first><last>Arora</last></author>
      <author><first>Suman</first><last>Banerjee</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <pages>2322–2332</pages>
      <url hash="902e095f">D18-1255</url>
      <attachment type="attachment" hash="d648b72e">D18-1255.Attachment.zip</attachment>
      <abstract>Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> which treat <a href="https://en.wikipedia.org/wiki/Conversation">conversation</a> as a sequence-to-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90 K utterances from 9 K conversations) using three different models : (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.</abstract>
      <video href="https://vimeo.com/305939688" />
      <doi>10.18653/v1/D18-1255</doi>
      <bibkey>moghe-etal-2018-towards</bibkey>
      <pwccode url="https://github.com/nikitacs16/Holl-E" additional="false">nikitacs16/Holl-E</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/holl-e">Holl-E</pwcdataset>
    </paper>
    <paper id="256">
      <title>Decoupling Strategy and Generation in Negotiation Dialogues</title>
      <author><first>He</first><last>He</last></author>
      <author><first>Derek</first><last>Chen</last></author>
      <author><first>Anusha</first><last>Balakrishnan</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <pages>2333–2343</pages>
      <url hash="10d6227f">D18-1256</url>
      <attachment type="attachment" hash="2de951fa">D18-1256.Attachment.pdf</attachment>
      <abstract>We consider negotiation settings in which two agents use <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a> to bargain on goods. Agents need to decide on both high-level strategy (e.g., proposing $ 50) and the execution of that strategy (e.g., generating The bike is brand new. Selling for just $ 50 !). Recent work on <a href="https://en.wikipedia.org/wiki/Negotiation">negotiation</a> trains neural models, but their end-to-end nature makes it hard to control their <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a>, and <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> tends to lead to degenerate solutions. In this paper, we propose a <a href="https://en.wikipedia.org/wiki/Modular_programming">modular approach</a> based on coarse dialogue acts (e.g., propose(price=50)) that decouples <a href="https://en.wikipedia.org/wiki/Strategy_(game_theory)">strategy</a> and generation. We show that we can flexibly set the strategy using <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a>, or domain-specific knowledge without degeneracy, while our retrieval-based generation can maintain context-awareness and produce diverse utterances. We test our approach on the recently proposed DEALORNODEAL game, and we also collect a richer dataset based on real items on <a href="https://en.wikipedia.org/wiki/Craigslist">Craigslist</a>. Human evaluation shows that our <a href="https://en.wikipedia.org/wiki/System">systems</a> achieve higher task success rate and more human-like negotiation behavior than previous approaches.</abstract>
      <video href="https://vimeo.com/305940786" />
      <doi>10.18653/v1/D18-1256</doi>
      <bibkey>he-etal-2018-decoupling</bibkey>
      <pwccode url="https://worksheets.codalab.org/worksheets/0x453913e76b65495d8b9730d41c7e0a0c" additional="true">worksheets/0x453913e7</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/craigslistbargains">CraigslistBargains</pwcdataset>
    </paper>
    <paper id="257">
      <title>Large-scale Cloze Test Dataset Created by Teachers</title>
      <author><first>Qizhe</first><last>Xie</last></author>
      <author><first>Guokun</first><last>Lai</last></author>
      <author><first>Zihang</first><last>Dai</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>2344–2356</pages>
      <url hash="c7b294be">D18-1257</url>
      <abstract>Cloze tests are widely adopted in <a href="https://en.wikipedia.org/wiki/Test_(assessment)">language exams</a> to evaluate students’ language proficiency. In this paper, we propose the first large-scale human-created cloze test dataset CLOTH, containing questions used in middle-school and high-school language exams. With missing blanks carefully created by teachers and candidate choices purposely designed to be nuanced, CLOTH requires a deeper language understanding and a wider <a href="https://en.wikipedia.org/wiki/Attention_span">attention span</a> than previously automatically-generated cloze datasets. We test the performance of dedicatedly designed baseline models including a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> trained on the One Billion Word Corpus and show humans outperform them by a significant margin. We investigate the source of the performance gap, trace model deficiencies to some distinct properties of CLOTH, and identify the limited ability of comprehending the long-term context to be the key bottleneck.</abstract>
      <video href="https://vimeo.com/305886563" />
      <doi>10.18653/v1/D18-1257</doi>
      <bibkey>xie-etal-2018-large</bibkey>
      <pwccode url="https://github.com/qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers" additional="true">qizhex/Large-scale-Cloze-Test-Dataset-Designed-by-Teachers</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cloth">CLOTH</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/bookcorpus">BookCorpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/lambada">LAMBADA</pwcdataset>
    </paper>
    <paper id="258">
      <title>emrQA : A Large Corpus for <a href="https://en.wikipedia.org/wiki/Question_answering">Question Answering</a> on Electronic Medical Records<fixed-case>QA</fixed-case>: A Large Corpus for Question Answering on Electronic Medical Records</title>
      <author><first>Anusri</first><last>Pampari</last></author>
      <author><first>Preethi</first><last>Raghavan</last></author>
      <author><first>Jennifer</first><last>Liang</last></author>
      <author><first>Jian</first><last>Peng</last></author>
      <pages>2357–2368</pages>
      <url hash="f8802c93">D18-1258</url>
      <abstract>We propose a novel <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> to generate domain-specific large-scale question answering (QA) datasets by re-purposing existing <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> for other NLP tasks. We demonstrate an instance of this methodology in generating a large-scale QA dataset for electronic medical records by leveraging existing expert annotations on clinical notes for various NLP tasks from the community shared i2b2 datasets. The resulting corpus (emrQA) has 1 million questions-logical form and 400,000 + question-answer evidence pairs. We characterize the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and explore its learning potential by training baseline models for question to logical form and question to answer mapping.</abstract>
      <video href="https://vimeo.com/305887077" />
      <doi>10.18653/v1/D18-1258</doi>
      <bibkey>pampari-etal-2018-emrqa</bibkey>
      <pwccode url="https://github.com/panushri25/emrQA" additional="true">panushri25/emrQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/emrqa">emrQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="263">
      <title>Semantics as a Foreign Language</title>
      <author><first>Gabriel</first><last>Stanovsky</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>2412–2421</pages>
      <url hash="5b9fae30">D18-1263</url>
      <abstract>We propose a novel approach to semantic dependency parsing (SDP) by casting the task as an instance of multi-lingual machine translation, where each semantic representation is a different foreign dialect. To that end, we first generalize syntactic linearization techniques to account for the richer semantic dependency graph structure. Following, we design a neural sequence-to-sequence framework which can effectively recover our graph linearizations, performing almost on-par with previous SDP state-of-the-art while requiring less parallel training annotations. Beyond SDP, our linearization technique opens the door to integration of graph-based semantic representations as <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> in neural models for downstream applications.</abstract>
      <video href="https://vimeo.com/306045906" />
      <doi>10.18653/v1/D18-1263</doi>
      <bibkey>stanovsky-dagan-2018-semantics</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="264">
      <title>An AMR Aligner Tuned by Transition-based Parser<fixed-case>AMR</fixed-case> Aligner Tuned by Transition-based Parser</title>
      <author><first>Yijia</first><last>Liu</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <author><first>Bo</first><last>Zheng</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>2422–2430</pages>
      <url hash="5dd59fed">D18-1264</url>
      <abstract>In this paper, we propose a new rich resource enhanced AMR aligner which produces multiple alignments and a new transition system for AMR parsing along with its oracle parser. Our aligner is further tuned by our <a href="https://en.wikipedia.org/wiki/Oracle_machine">oracle parser</a> via picking the alignment that leads to the highest-scored achievable AMR graph. Experimental results show that our aligner outperforms the rule-based aligner in previous work by achieving higher alignment F1 score and consistently improving two open-sourced AMR parsers. Based on our aligner and transition system, we develop a transition-based AMR parser that parses a sentence into its AMR graph directly. An ensemble of our <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a> with only words and POS tags as input leads to 68.4 Smatch F1 score, which outperforms the current state-of-the-art parser.</abstract>
      <video href="https://vimeo.com/306049123" />
      <doi>10.18653/v1/D18-1264</doi>
      <bibkey>liu-etal-2018-amr</bibkey>
      <pwccode url="https://github.com/Oneplus/tamr" additional="false">Oneplus/tamr</pwccode>
    </paper>
    <paper id="265">
      <title>Dependency-based Hybrid Trees for Semantic Parsing</title>
      <author><first>Zhanming</first><last>Jie</last></author>
      <author><first>Wei</first><last>Lu</last></author>
      <pages>2431–2441</pages>
      <url hash="fec90ce6">D18-1265</url>
      <attachment type="attachment" hash="6eddf9c1">D18-1265.Attachment.zip</attachment>
      <abstract>We propose a novel dependency-based hybrid tree model for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>, which converts natural language utterance into machine interpretable meaning representations. Unlike previous state-of-the-art models, the semantic information is interpreted as the latent dependency between the natural language words in our joint representation. Such dependency information can capture the interactions between the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> and <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language words</a>. We integrate a neural component into our model and propose an efficient dynamic-programming algorithm to perform tractable inference. Through extensive experiments on the standard multilingual GeoQuery dataset with eight languages, we demonstrate that our proposed approach is able to achieve state-of-the-art performance across several languages. Analysis also justifies the effectiveness of using our new dependency-based representation.</abstract>
      <video href="https://vimeo.com/306052219" />
      <doi>10.18653/v1/D18-1265</doi>
      <bibkey>jie-lu-2018-dependency</bibkey>
    </paper>
    <paper id="267">
      <title>Sentence Compression for Arbitrary Languages via Multilingual Pivoting</title>
      <author><first>Jonathan</first><last>Mallinson</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <pages>2453–2464</pages>
      <url hash="1a3aaddf">D18-1267</url>
      <attachment type="attachment" hash="587f38b7">D18-1267.Attachment.zip</attachment>
      <abstract>In this paper we advocate the use of bilingual corpora which are abundantly available for training sentence compression models. Our approach borrows much of its machinery from <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> and leverages bilingual pivoting : compressions are obtained by translating a source string into a foreign language and then back-translating it into the source while controlling the translation length. Our model can be trained for any language as long as a bilingual corpus is available and performs arbitrary rewrites without access to compression specific data. We release. Moss, a new parallel Multilingual Compression dataset for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, and <a href="https://en.wikipedia.org/wiki/French_language">French</a> which can be used to evaluate compression models across languages and genres.</abstract>
      <video href="https://vimeo.com/305663630" />
      <doi>10.18653/v1/D18-1267</doi>
      <bibkey>mallinson-etal-2018-sentence</bibkey>
      <pwccode url="https://github.com/Jmallins/MOSS" additional="false">Jmallins/MOSS</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sentence-compression">Sentence Compression</pwcdataset>
    </paper>
    <paper id="269">
      <title>XNLI : Evaluating Cross-lingual Sentence Representations<fixed-case>XNLI</fixed-case>: Evaluating Cross-lingual Sentence Representations</title>
      <author><first>Alexis</first><last>Conneau</last></author>
      <author><first>Ruty</first><last>Rinott</last></author>
      <author><first>Guillaume</first><last>Lample</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Samuel</first><last>Bowman</last></author>
      <author><first>Holger</first><last>Schwenk</last></author>
      <author><first>Veselin</first><last>Stoyanov</last></author>
      <pages>2475–2485</pages>
      <url hash="c3ce7082">D18-1269</url>
      <abstract>State-of-the-art <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing systems</a> rely on <a href="https://en.wikipedia.org/wiki/Supervisor">supervision</a> in the form of <a href="https://en.wikipedia.org/wiki/Annotation">annotated data</a> to learn competent <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a>. These <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> are generally trained on data in a single language (usually English), and can not be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 14 languages, including low-resource languages such as <a href="https://en.wikipedia.org/wiki/Swahili_language">Swahili</a> and <a href="https://en.wikipedia.org/wiki/Urdu">Urdu</a>. We hope that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that XNLI represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>.</abstract>
      <video href="https://vimeo.com/305665271" />
      <doi>10.18653/v1/D18-1269</doi>
      <bibkey>conneau-etal-2018-xnli</bibkey>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/xnli">XNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    </paper>
    <paper id="273">
      <title>A Hybrid Approach to Automatic Corpus Generation for Chinese Spelling Check<fixed-case>C</fixed-case>hinese Spelling Check</title>
      <author><first>Dingmin</first><last>Wang</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Jialong</first><last>Han</last></author>
      <author><first>Haisong</first><last>Zhang</last></author>
      <pages>2517–2527</pages>
      <url hash="1afb6a31">D18-1273</url>
      <abstract>Chinese spelling check (CSC) is a challenging yet meaningful task, which not only serves as a preprocessing in many natural language processing(NLP) applications, but also facilitates reading and understanding of running texts in peoples’ daily lives. However, to utilize data-driven approaches for CSC, there is one major limitation that annotated corpora are not enough in applying <a href="https://en.wikipedia.org/wiki/Algorithm">algorithms</a> and building <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>. In this paper, we propose a novel approach of constructing CSC corpus with automatically generated spelling errors, which are either visually or phonologically resembled characters, corresponding to the OCR- and ASR-based methods, respectively. Upon the constructed corpus, different <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> are trained and evaluated for CSC with respect to three standard test sets. Experimental results demonstrate the effectiveness of the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, therefore confirm the validity of our approach.</abstract>
      <doi>10.18653/v1/D18-1273</doi>
      <bibkey>wang-etal-2018-hybrid</bibkey>
      <pwccode url="https://github.com/wdimmy/Automatic-Corpus-Generation" additional="false">wdimmy/Automatic-Corpus-Generation</pwccode>
    </paper>
    <paper id="274">
      <title>Neural Quality Estimation of Grammatical Error Correction</title>
      <author><first>Shamil</first><last>Chollampatt</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <pages>2528–2539</pages>
      <url hash="e2f2c56e">D18-1274</url>
      <abstract>Grammatical error correction (GEC) systems deployed in language learning environments are expected to accurately correct errors in learners’ writing. However, in practice, they often produce spurious corrections and fail to correct many errors, thereby misleading learners. This necessitates the estimation of the quality of output sentences produced by GEC systems so that instructors can selectively intervene and re-correct the sentences which are poorly corrected by the <a href="https://en.wikipedia.org/wiki/System">system</a> and ensure that learners get accurate feedback. We propose the first neural approach to automatic quality estimation of GEC output sentences that does not employ any hand-crafted features. Our <a href="https://en.wikipedia.org/wiki/System">system</a> is trained in a supervised manner on learner sentences and corresponding GEC system outputs with quality score labels computed using human-annotated references. Our neural quality estimation models for GEC show significant improvements over a strong feature-based baseline. We also show that a state-of-the-art GEC system can be improved when quality scores are used as features for re-ranking the N-best candidates.</abstract>
      <doi>10.18653/v1/D18-1274</doi>
      <bibkey>chollampatt-ng-2018-neural</bibkey>
      <pwccode url="https://github.com/nusnlp/neuqe" additional="false">nusnlp/neuqe</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error">CoNLL-2014 Shared Task: Grammatical Error Correction</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/jfleg">JFLEG</pwcdataset>
    </paper>
    <paper id="275">
      <title>Transferring from Formal Newswire Domain with Hypernet for Twitter POS Tagging<fixed-case>T</fixed-case>witter <fixed-case>POS</fixed-case> Tagging</title>
      <author><first>Tao</first><last>Gui</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Jingjing</first><last>Gong</last></author>
      <author><first>Minlong</first><last>Peng</last></author>
      <author><first>Di</first><last>Liang</last></author>
      <author><first>Keyu</first><last>Ding</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>2540–2549</pages>
      <url hash="bf54447d">D18-1275</url>
      <abstract>Part-of-Speech (POS) tagging for <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> has received considerable attention in recent years. Because most POS tagging methods are based on <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised models</a>, they usually require a large amount of labeled data for training. However, the existing labeled datasets for <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a> are much smaller than those for newswire text. Hence, to help POS tagging for <a href="https://en.wikipedia.org/wiki/Twitter">Twitter</a>, most domain adaptation methods try to leverage newswire datasets by learning the shared features between the two domains. However, from a linguistic perspective, Twitter users not only tend to mimic the formal expressions of traditional media, like <a href="https://en.wikipedia.org/wiki/News">news</a>, but they also appear to be developing linguistically informal styles. Therefore, <a href="https://en.wikipedia.org/wiki/POS_tagging">POS tagging</a> for the formal Twitter context can be learned together with the newswire dataset, while <a href="https://en.wikipedia.org/wiki/POS_tagging">POS tagging</a> for the informal Twitter context should be learned separately. To achieve this task, in this work, we propose a hypernetwork-based method to generate different parameters to separately model contexts with different expression styles. Experimental results on three different datasets show that our approach achieves better performance than state-of-the-art methods in most cases.</abstract>
      <doi>10.18653/v1/D18-1275</doi>
      <bibkey>gui-etal-2018-transferring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="276">
      <title>Free as in Free Word Order : An Energy Based Model for Word Segmentation and Morphological Tagging in <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a><fixed-case>S</fixed-case>anskrit</title>
      <author><first>Amrith</first><last>Krishna</last></author>
      <author><first>Bishal</first><last>Santra</last></author>
      <author><first>Sasi Prasanth</first><last>Bandaru</last></author>
      <author><first>Gaurav</first><last>Sahu</last></author>
      <author><first>Vishnu Dutt</first><last>Sharma</last></author>
      <author><first>Pavankumar</first><last>Satuluri</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>2550–2561</pages>
      <url hash="7bb868b7">D18-1276</url>
      <attachment type="attachment" hash="8119b05a">D18-1276.Attachment.zip</attachment>
      <abstract>The configurational information in sentences of a free word order language such as <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a> is of limited use. Thus, the context of the entire sentence will be desirable even for basic processing tasks such as <a href="https://en.wikipedia.org/wiki/Word_segmentation">word segmentation</a>. We propose a structured prediction framework that jointly solves the word segmentation and morphological tagging tasks in <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>. We build an energy based model where we adopt approaches generally employed in graph based parsing techniques (McDonald et al., 2005a ; Carreras, 2007). Our <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> outperforms the state of the art with an F-Score of 96.92 (percentage improvement of 7.06 %) while using less than one tenth of the task-specific training data. We find that the use of a <a href="https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)">graph based approach</a> instead of a traditional lattice-based sequential labelling approach leads to a percentage gain of 12.6 % in F-Score for the segmentation task.</abstract>
      <doi>10.18653/v1/D18-1276</doi>
      <bibkey>krishna-etal-2018-free</bibkey>
    </paper>
    <paper id="278">
      <title>What do character-level models learn about <a href="https://en.wikipedia.org/wiki/Morphology_(biology)">morphology</a>? The case of dependency parsing</title>
      <author><first>Clara</first><last>Vania</last></author>
      <author><first>Andreas</first><last>Grivas</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <pages>2573–2583</pages>
      <url hash="a6bbbc40">D18-1278</url>
      <attachment type="attachment" hash="2b39c730">D18-1278.Attachment.zip</attachment>
      <abstract>When parsing morphologically-rich languages with neural models, it is beneficial to model input at the character level, and it has been claimed that this is because character-level models learn <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a>. We test these claims by comparing character-level models to an oracle with access to explicit morphological analysis on twelve languages with varying <a href="https://en.wikipedia.org/wiki/Morphological_typology">morphological typologies</a>. Our results highlight many strengths of character-level models, but also show that they are poor at disambiguating some words, particularly in the face of case syncretism. We then demonstrate that explicitly modeling morphological case improves our best model, showing that character-level models can benefit from targeted forms of explicit morphological modeling.</abstract>
      <doi>10.18653/v1/D18-1278</doi>
      <bibkey>vania-etal-2018-character</bibkey>
    </paper>
    <paper id="280">
      <title>ICON : Interactive Conversational Memory Network for Multimodal Emotion Detection<fixed-case>ICON</fixed-case>: Interactive Conversational Memory Network for Multimodal Emotion Detection</title>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Soujanya</first><last>Poria</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <author><first>Roger</first><last>Zimmermann</last></author>
      <pages>2594–2604</pages>
      <url hash="7a5e747d">D18-1280</url>
      <abstract>Emotion recognition in <a href="https://en.wikipedia.org/wiki/Conversation">conversations</a> is crucial for building empathetic machines. Present works in this domain do not explicitly consider the inter-personal influences that thrive in the emotional dynamics of dialogues. To this end, we propose Interactive COnversational memory Network (ICON), a multimodal emotion detection framework that extracts multimodal features from conversational videos and hierarchically models the self- and inter-speaker emotional influences into global memories. Such <a href="https://en.wikipedia.org/wiki/Memory">memories</a> generate contextual summaries which aid in predicting the emotional orientation of utterance-videos. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state-of-the-art networks on multiple classification and regression tasks in two benchmark datasets.</abstract>
      <doi>10.18653/v1/D18-1280</doi>
      <bibkey>hazarika-etal-2018-icon</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/iemocap">IEMOCAP</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/semaine">SEMAINE</pwcdataset>
    </paper>
    <paper id="281">
      <title>Discriminative Learning of Open-Vocabulary Object Retrieval and Localization by Negative Phrase Augmentation</title>
      <author><first>Ryota</first><last>Hinami</last></author>
      <author><first>Shin’ichi</first><last>Satoh</last></author>
      <pages>2605–2615</pages>
      <url hash="513cc9ef">D18-1281</url>
      <attachment type="attachment" hash="87c103a7">D18-1281.Attachment.pdf</attachment>
      <abstract>Thanks to the success of object detection technology, we can retrieve objects of the specified classes even from huge image collections. However, the current state-of-the-art object detectors (such as Faster R-CNN) can only handle pre-specified classes. In addition, large amounts of positive and negative visual samples are required for training. In this paper, we address the problem of open-vocabulary object retrieval and localization, where the target object is specified by a textual query (e.g., a word or phrase). We first propose Query-Adaptive R-CNN, a simple extension of Faster R-CNN adapted to open-vocabulary queries, by transforming the text embedding vector into an object classifier and localization regressor. Then, for discriminative training, we then propose negative phrase augmentation (NPA) to mine hard negative samples which are visually similar to the query and at the same time semantically mutually exclusive of the query. The proposed <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> can retrieve and localize objects specified by a <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">textual query</a> from one million images in only 0.5 seconds with high precision.</abstract>
      <doi>10.18653/v1/D18-1281</doi>
      <bibkey>hinami-satoh-2018-discriminative</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k-entities">Flickr30K Entities</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="282">
      <title>Grounding Semantic Roles in Images</title>
      <author><first>Carina</first><last>Silberer</last></author>
      <author><first>Manfred</first><last>Pinkal</last></author>
      <pages>2616–2626</pages>
      <url hash="ad2081f0">D18-1282</url>
      <abstract>We address the task of visual semantic role labeling (vSRL), the identification of the participants of a situation or event in a visual scene, and their labeling with their semantic relations to the event or situation. We render candidate participants as image regions of objects, and train a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> which learns to ground roles in the regions which depict the corresponding participant. Experimental results demonstrate that we can train a vSRL model without reliance on prohibitive image-based role annotations, by utilizing noisy data which we extract automatically from image captions using a linguistic SRL system. Furthermore, our model induces framesemantic visual representations, and their comparison to previous work on supervised visual verb sense disambiguation yields overall better results.</abstract>
      <doi>10.18653/v1/D18-1282</doi>
      <bibkey>silberer-pinkal-2018-grounding</bibkey>
    </paper>
    <paper id="283">
      <title>Commonsense Justification for Action Explanation</title>
      <author><first>Shaohua</first><last>Yang</last></author>
      <author><first>Qiaozi</first><last>Gao</last></author>
      <author><first>Sari</first><last>Sadiya</last></author>
      <author><first>Joyce</first><last>Chai</last></author>
      <pages>2627–2637</pages>
      <url hash="4c4df699">D18-1283</url>
      <abstract>To enable collaboration and communication between humans and agents, this paper investigates learning to acquire commonsense evidence for action justification. In particular, we have developed an approach based on the generative Conditional Variational Autoencoder(CVAE) that models object relations / attributes of the world as latent variables and jointly learns a performer that predicts actions and an explainer that gathers commonsense evidence to justify the action. Our empirical results have shown that, compared to a typical attention-based model, CVAE achieves significantly higher performance in both action prediction and <a href="https://en.wikipedia.org/wiki/Theory_of_justification">justification</a>. A human subject study further shows that the commonsense evidence gathered by CVAE can be communicated to humans to achieve a significantly higher common ground between humans and agents.</abstract>
      <doi>10.18653/v1/D18-1283</doi>
      <bibkey>yang-etal-2018-commonsense</bibkey>
      <pwccode url="https://github.com/yangshao/Commonsense4Action" additional="false">yangshao/Commonsense4Action</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-genome">Visual Genome</pwcdataset>
    </paper>
    <paper id="285">
      <title>Grounding <a href="https://en.wikipedia.org/wiki/Language_acquisition">language acquisition</a> by training semantic parsers using captioned videos</title>
      <author><first>Candace</first><last>Ross</last></author>
      <author><first>Andrei</first><last>Barbu</last></author>
      <author><first>Yevgeni</first><last>Berzak</last></author>
      <author><first>Battushig</first><last>Myanganbayar</last></author>
      <author><first>Boris</first><last>Katz</last></author>
      <pages>2647–2656</pages>
      <url hash="a024ba54">D18-1285</url>
      <abstract>We develop a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> that is trained in a grounded setting using pairs of videos captioned with sentences. This setting is both data-efficient, requiring little <a href="https://en.wikipedia.org/wiki/Annotation">annotation</a>, and similar to the experience of children where they observe their environment and listen to speakers. The <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a> recovers the meaning of English sentences despite not having access to any annotated sentences. It does so despite the ambiguity inherent in vision where a sentence may refer to any combination of objects, object properties, relations or actions taken by any agent in a video. For this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we collected a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for grounded language acquisition. Learning a grounded semantic parser   turning sentences into logical forms using captioned videos   can significantly expand the range of data that parsers can be trained on, lower the effort of training a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a>, and ultimately lead to a better understanding of child language acquisition.</abstract>
      <doi>10.18653/v1/D18-1285</doi>
      <bibkey>ross-etal-2018-grounding</bibkey>
    </paper>
    <paper id="286">
      <title>Translating Navigation Instructions in Natural Language to a High-Level Plan for Behavioral Robot Navigation</title>
      <author><first>Xiaoxue</first><last>Zang</last></author>
      <author><first>Ashwini</first><last>Pokle</last></author>
      <author><first>Marynel</first><last>Vázquez</last></author>
      <author><first>Kevin</first><last>Chen</last></author>
      <author><first>Juan Carlos</first><last>Niebles</last></author>
      <author><first>Alvaro</first><last>Soto</last></author>
      <author><first>Silvio</first><last>Savarese</last></author>
      <pages>2657–2666</pages>
      <url hash="86d04a58">D18-1286</url>
      <attachment type="attachment" hash="b9e66a09">D18-1286.Attachment.zip</attachment>
      <abstract>We propose an end-to-end deep learning model for translating free-form natural language instructions to a high-level plan for behavioral robot navigation. We use attention models to connect information from both the <a href="https://en.wikipedia.org/wiki/User_interface">user instructions</a> and a topological representation of the environment. We evaluate our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s performance on a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> containing 10,050 pairs of navigation instructions. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly outperforms baseline approaches. Furthermore, our results suggest that it is possible to leverage the <a href="https://en.wikipedia.org/wiki/Environment_map">environment map</a> as a relevant knowledge base to facilitate the translation of free-form navigational instruction.</abstract>
      <doi>10.18653/v1/D18-1286</doi>
      <bibkey>zang-etal-2018-translating</bibkey>
    </paper>
    <paper id="288">
      <title>Deconvolutional Time Series Regression : A Technique for Modeling Temporally Diffuse Effects</title>
      <author><first>Cory</first><last>Shain</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <pages>2679–2689</pages>
      <url hash="09f176c5">D18-1288</url>
      <abstract>Researchers in computational psycholinguistics frequently use <a href="https://en.wikipedia.org/wiki/Linear_model">linear models</a> to study <a href="https://en.wikipedia.org/wiki/Time_series">time series data</a> generated by human subjects. However, <a href="https://en.wikipedia.org/wiki/Time_series">time series</a> may violate the assumptions of these models through temporal diffusion, where stimulus presentation has a lingering influence on the response as the rest of the experiment unfolds. This paper proposes a new <a href="https://en.wikipedia.org/wiki/Statistical_model">statistical model</a> that borrows from <a href="https://en.wikipedia.org/wiki/Digital_signal_processing">digital signal processing</a> by recasting the predictors and response as convolutionally-related signals, using recent advances in <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> to fit latent impulse response functions (IRFs) of arbitrary shape. A synthetic experiment shows successful recovery of true latent IRFs, and psycholinguistic experiments reveal plausible, replicable, and fine-grained estimates of latent temporal dynamics, with comparable or improved prediction quality to widely-used alternatives.</abstract>
      <doi>10.18653/v1/D18-1288</doi>
      <bibkey>shain-schuler-2018-deconvolutional</bibkey>
      <pwccode url="https://github.com/coryshain/dtsr" additional="false">coryshain/dtsr</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/natural-stories">Natural Stories</pwcdataset>
    </paper>
    <paper id="292">
      <title>Depth-bounding is effective : Improvements and evaluation of unsupervised PCFG induction<fixed-case>PCFG</fixed-case> induction</title>
      <author><first>Lifeng</first><last>Jin</last></author>
      <author><first>Finale</first><last>Doshi-Velez</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <pages>2721–2731</pages>
      <url hash="2bbc2212">D18-1292</url>
      <abstract>There have been several recent attempts to improve the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of grammar induction systems by bounding the recursive complexity of the <a href="https://en.wikipedia.org/wiki/Mathematical_induction">induction model</a>. Modern depth-bounded grammar inducers have been shown to be more accurate than early unbounded PCFG inducers, but this technique has never been compared against unbounded induction within the same system, in part because most previous depth-bounding models are built around sequence models, the complexity of which grows exponentially with the maximum allowed depth. The present work instead applies depth bounds within a chart-based Bayesian PCFG inducer, where <a href="https://en.wikipedia.org/wiki/Upper_and_lower_bounds">bounding</a> can be switched on and off, and then samples trees with or without <a href="https://en.wikipedia.org/wiki/Upper_and_lower_bounds">bounding</a>. Results show that depth-bounding is indeed significantly effective in limiting the <a href="https://en.wikipedia.org/wiki/Feasible_region">search space</a> of the inducer and thereby increasing accuracy of resulting parsing model, independent of the contribution of modern Bayesian induction techniques. Moreover, parsing results on <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> and <a href="https://en.wikipedia.org/wiki/German_language">German</a> show that this bounded model is able to produce parse trees more accurately than or competitively with state-of-the-art constituency grammar induction models.</abstract>
      <doi>10.18653/v1/D18-1292</doi>
      <bibkey>jin-etal-2018-depth</bibkey>
      <pwccode url="https://github.com/lifengjin/dimi_emnlp18" additional="false">lifengjin/dimi_emnlp18</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="293">
      <title>Incremental Computation of Infix Probabilities for Probabilistic Finite Automata</title>
      <author><first>Marco</first><last>Cognetta</last></author>
      <author><first>Yo-Sub</first><last>Han</last></author>
      <author><first>Soon Chan</first><last>Kwon</last></author>
      <pages>2732–2741</pages>
      <url hash="789f5da2">D18-1293</url>
      <attachment type="attachment" hash="2dca39cf">D18-1293.Attachment.zip</attachment>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, a common task is to compute the probability of a phrase appearing in a document or to calculate the probability of all phrases matching a given pattern. For instance, one computes affix (prefix, <a href="https://en.wikipedia.org/wiki/Suffix">suffix</a>, <a href="https://en.wikipedia.org/wiki/Infix">infix</a>, etc.) probabilities of a string or a set of strings with respect to a probability distribution of patterns. The problem of computing infix probabilities of strings when the pattern distribution is given by a <a href="https://en.wikipedia.org/wiki/Probabilistic_context-free_grammar">probabilistic context-free grammar</a> or by a <a href="https://en.wikipedia.org/wiki/Probabilistic_finite_automaton">probabilistic finite automaton</a> is already solved, yet it was open to compute the infix probabilities in an incremental manner. The <a href="https://en.wikipedia.org/wiki/Incremental_computation">incremental computation</a> is crucial when a new query is built from a previous query. We tackle this problem and suggest a method that computes infix probabilities incrementally for <a href="https://en.wikipedia.org/wiki/Probabilistic_finite_automaton">probabilistic finite automata</a> by representing all the probabilities of matching strings as a series of transition matrix calculations. We show that the proposed approach is theoretically faster than the previous method and, using real world data, demonstrate that our approach has vastly better performance in practice.</abstract>
      <doi>10.18653/v1/D18-1293</doi>
      <bibkey>cognetta-etal-2018-incremental</bibkey>
    </paper>
    <paper id="294">
      <title>Syntax Encoding with Application in Authorship Attribution</title>
      <author><first>Richong</first><last>Zhang</last></author>
      <author><first>Zhiyuan</first><last>Hu</last></author>
      <author><first>Hongyu</first><last>Guo</last></author>
      <author><first>Yongyi</first><last>Mao</last></author>
      <pages>2742–2753</pages>
      <url hash="32d742ef">D18-1294</url>
      <abstract>We propose a novel strategy to encode the syntax parse tree of sentence into a learnable distributed representation. The proposed syntax encoding scheme is provably information-lossless. In specific, an <a href="https://en.wikipedia.org/wiki/Embedding">embedding vector</a> is constructed for each word in the sentence, encoding the path in the <a href="https://en.wikipedia.org/wiki/Syntax_tree">syntax tree</a> corresponding to the word. The one-to-one correspondence between these syntax-embedding vectors and the words (hence their embedding vectors) in the sentence makes it easy to integrate such a representation with all word-level NLP models. We empirically show the benefits of the syntax embeddings on the Authorship Attribution domain, where our approach improves upon the prior art and achieves new performance records on five benchmarking data sets.</abstract>
      <doi>10.18653/v1/D18-1294</doi>
      <bibkey>zhang-etal-2018-syntax</bibkey>
    </paper>
    <paper id="295">
      <title>Sanskrit Word Segmentation Using Character-level Recurrent and Convolutional Neural Networks<fixed-case>S</fixed-case>anskrit Word Segmentation Using Character-level Recurrent and Convolutional Neural Networks</title>
      <author><first>Oliver</first><last>Hellwig</last></author>
      <author><first>Sebastian</first><last>Nehrdich</last></author>
      <pages>2754–2763</pages>
      <url hash="f39b7d83">D18-1295</url>
      <abstract>The paper introduces end-to-end neural network models that tokenize <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a> by jointly splitting compounds and resolving phonetic merges (Sandhi). Tokenization of <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a> depends on local phonetic and distant semantic features that are incorporated using convolutional and recurrent elements. Contrary to most previous systems, our models do not require <a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a> or extern linguistic resources, but operate solely on parallel versions of raw and segmented text. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> discussed in this paper clearly improve over previous <a href="https://en.wikipedia.org/wiki/Conceptual_model">approaches</a> to Sanskrit word segmentation. As they are language agnostic, we will demonstrate that they also outperform the state of the art for the related task of German compound splitting.</abstract>
      <doi>10.18653/v1/D18-1295</doi>
      <bibkey>hellwig-nehrdich-2018-sanskrit</bibkey>
    </paper>
    <paper id="296">
      <title>Session-level Language Modeling for Conversational Speech</title>
      <author><first>Wayne</first><last>Xiong</last></author>
      <author><first>Lingfeng</first><last>Wu</last></author>
      <author><first>Jun</first><last>Zhang</last></author>
      <author><first>Andreas</first><last>Stolcke</last></author>
      <pages>2764–2768</pages>
      <url hash="1b61603c">D18-1296</url>
      <abstract>We propose to generalize language models for conversational speech recognition to allow them to operate across utterance boundaries and speaker changes, thereby capturing conversation-level phenomena such as <a href="https://en.wikipedia.org/wiki/Adjacency_pairs">adjacency pairs</a>, <a href="https://en.wikipedia.org/wiki/Lexical_entrainment">lexical entrainment</a>, and topical coherence. The model consists of a long-short-term memory (LSTM) recurrent network that reads the entire word-level history of a conversation, as well as information about turn taking and speaker overlap, in order to predict each next word. The <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is applied in a rescoring framework, where the word history prior to the current utterance is approximated with preliminary recognition results. In experiments in the conversational telephone speech domain (Switchboard) we find that such a model gives substantial perplexity reductions over a standard LSTM-LM with utterance scope, as well as improvements in word error rate.</abstract>
      <video href="https://vimeo.com/305942129" />
      <doi>10.18653/v1/D18-1296</doi>
      <bibkey>xiong-etal-2018-session</bibkey>
    </paper>
    <paper id="297">
      <title>Towards Less Generic Responses in Neural Conversation Models : A Statistical Re-weighting Method</title>
      <author><first>Yahui</first><last>Liu</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Jun</first><last>Gao</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <author><first>Jian</first><last>Yao</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <pages>2769–2774</pages>
      <url hash="2adebab4">D18-1297</url>
      <abstract>Sequence-to-sequence neural generation models have achieved promising performance on short text conversation tasks. However, they tend to generate generic / dull responses, leading to unsatisfying dialogue experience. We observe that in the conversation tasks, each query could have multiple responses, which forms a 1-to-n or m-to-n relationship in the view of the total corpus. The <a href="https://en.wikipedia.org/wiki/Loss_function">objective function</a> used in standard sequence-to-sequence models will be dominated by loss terms with generic patterns. Inspired by this observation, we introduce a statistical re-weighting method that assigns different weights for the multiple responses of the same query, and trains the common neural generation model with the weights. Experimental results on a large Chinese dialogue corpus show that our method improves the acceptance rate of generated responses compared with several baseline models and significantly reduces the number of generated generic responses.</abstract>
      <video href="https://vimeo.com/305942945" />
      <doi>10.18653/v1/D18-1297</doi>
      <bibkey>liu-etal-2018-towards-less</bibkey>
      <pwccode url="https://github.com/yhlleo/Reweighting" additional="false">yhlleo/Reweighting</pwccode>
    </paper>
    <paper id="298">
      <title>Training Millions of Personalized Dialogue Agents</title>
      <author><first>Pierre-Emmanuel</first><last>Mazaré</last></author>
      <author><first>Samuel</first><last>Humeau</last></author>
      <author><first>Martin</first><last>Raison</last></author>
      <author><first>Antoine</first><last>Bordes</last></author>
      <pages>2775–2779</pages>
      <url hash="aeef3315">D18-1298</url>
      <abstract>Current dialogue systems fail at being engaging for users, especially when trained end-to-end without relying on proactive reengaging scripted strategies. Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model. However, the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> used in Zhang et al. (2018) is synthetic and only contains around 1k different <a href="https://en.wikipedia.org/wiki/Persona">personas</a>. In this paper we introduce a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> providing 5 million <a href="https://en.wikipedia.org/wiki/Persona">personas</a> and 700 million persona-based dialogues. Our experiments show that, at this scale, training using <a href="https://en.wikipedia.org/wiki/Persona">personas</a> still improves the performance of <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end systems</a>. In addition, we show that other tasks benefit from the wide coverage of our <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> by fine-tuning our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the data from Zhang et al. (2018) and achieving state-of-the-art results.</abstract>
      <video href="https://vimeo.com/305943582" />
      <doi>10.18653/v1/D18-1298</doi>
      <bibkey>mazare-etal-2018-training</bibkey>
    </paper>
    <paper id="299">
      <title>Towards Universal Dialogue State Tracking</title>
      <author><first>Liliang</first><last>Ren</last></author>
      <author><first>Kaige</first><last>Xie</last></author>
      <author><first>Lu</first><last>Chen</last></author>
      <author><first>Kai</first><last>Yu</last></author>
      <pages>2780–2786</pages>
      <url hash="7b1aec94">D18-1299</url>
      <abstract>Dialogue state tracker is the core part of a <a href="https://en.wikipedia.org/wiki/Spoken_dialogue_system">spoken dialogue system</a>. It estimates the beliefs of possible user’s goals at every dialogue turn. However, for most current approaches, it’s difficult to scale to large dialogue domains. They have one or more of following limitations : (a) Some <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> do n’t work in the situation where slot values in ontology changes dynamically ; (b) The number of model parameters is proportional to the number of slots ; (c) Some <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.</abstract>
      <video href="https://vimeo.com/305944406" />
      <doi>10.18653/v1/D18-1299</doi>
      <bibkey>ren-etal-2018-towards</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dialogue-state-tracking-challenge">Dialogue State Tracking Challenge</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wizard-of-oz">Wizard-of-Oz</pwcdataset>
    </paper>
    <paper id="302">
      <title>Reducing Gender Bias in Abusive Language Detection</title>
      <author><first>Ji Ho</first><last>Park</last></author>
      <author><first>Jamin</first><last>Shin</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>2799–2804</pages>
      <url hash="41f18a73">D18-1302</url>
      <abstract>Abusive language detection models tend to have a problem of being biased toward identity words of a certain group of people because of imbalanced training datasets. For example, You are a good woman was considered sexist when trained on an existing <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>. Such model bias is an obstacle for <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> to be robust enough for practical use. In this work, we measure them on <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained with different <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>, while analyzing the effect of different pre-trained word embeddings and model architectures. We also experiment with three mitigation methods : (1) debiased word embeddings, (2) gender swap data augmentation, and (3) fine-tuning with a larger corpus. These methods can effectively reduce model bias by 90-98 % and can be extended to correct model bias in other scenarios.</abstract>
      <video href="https://vimeo.com/305891047" />
      <doi>10.18653/v1/D18-1302</doi>
      <bibkey>park-etal-2018-reducing</bibkey>
    </paper>
    <paper id="305">
      <title>WikiConv : A Corpus of the Complete Conversational History of a Large Online Collaborative Community<fixed-case>W</fixed-case>iki<fixed-case>C</fixed-case>onv: A Corpus of the Complete Conversational History of a Large Online Collaborative Community</title>
      <author><first>Yiqing</first><last>Hua</last></author>
      <author><first>Cristian</first><last>Danescu-Niculescu-Mizil</last></author>
      <author><first>Dario</first><last>Taraborelli</last></author>
      <author><first>Nithum</first><last>Thain</last></author>
      <author><first>Jeffery</first><last>Sorensen</last></author>
      <author><first>Lucas</first><last>Dixon</last></author>
      <pages>2818–2823</pages>
      <url hash="43f79dfd">D18-1305</url>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> that encompasses the complete history of conversations between contributors to <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>, one of the largest online collaborative communities. By recording the intermediate states of conversations-including not only comments and replies, but also their modifications, deletions and restorations-this <a href="https://en.wikipedia.org/wiki/Data">data</a> offers an unprecedented view of online conversation. Our framework is designed to be language agnostic, and we show that it extracts high quality data in both <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> and <a href="https://en.wikipedia.org/wiki/English_language">English</a>. This level of detail supports new research questions pertaining to the process (and challenges) of large-scale online collaboration. We illustrate the <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>’ potential with two case studies on <a href="https://en.wikipedia.org/wiki/English_Wikipedia">English Wikipedia</a> that highlight new perspectives on earlier work. First, we explore how a person’s conversational behavior depends on how they relate to the discussion’s venue. Second, we show that community moderation of toxic behavior happens at a higher rate than previously estimated.</abstract>
      <video href="https://vimeo.com/305892676" />
      <doi>10.18653/v1/D18-1305</doi>
      <bibkey>hua-etal-2018-wikiconv</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiconv">WikiConv</pwcdataset>
    </paper>
    <paper id="306">
      <title>Marginal Likelihood Training of BiLSTM-CRF for Biomedical Named Entity Recognition from Disjoint Label Sets<fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-<fixed-case>CRF</fixed-case> for Biomedical Named Entity Recognition from Disjoint Label Sets</title>
      <author><first>Nathan</first><last>Greenberg</last></author>
      <author><first>Trapit</first><last>Bansal</last></author>
      <author><first>Patrick</first><last>Verga</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>2824–2829</pages>
      <url hash="eef7ff7d">D18-1306</url>
      <attachment type="attachment" hash="5d06608d">D18-1306.Attachment.pdf</attachment>
      <abstract>Extracting typed entity mentions from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a> is a fundamental component to <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">language understanding and reasoning</a>. While there exist substantial labeled text datasets for multiple subsets of biomedical entity typessuch as genes and proteins, or chemicals and diseasesit is rare to find large labeled datasets containing labels for all desired entity types together. This paper presents a method for training a single CRF extractor from multiple <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> with disjoint or partially overlapping sets of entity types. Our approach employs marginal likelihood training to insist on labels that are present in the data, while filling in missing labels. This allows us to leverage all the available data within a single <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. In experimental results on the Biocreative V CDR (chemicals / diseases), Biocreative VI ChemProt (chemicals / proteins) and MedMentions (19 entity types) datasets, we show that joint training on multiple datasets improves NER F1 over training in isolation, and our methods achieve state-of-the-art results.</abstract>
      <video href="https://vimeo.com/306054703" />
      <doi>10.18653/v1/D18-1306</doi>
      <bibkey>greenberg-etal-2018-marginal</bibkey>
    </paper>
    <paper id="308">
      <title>Structured Multi-Label Biomedical Text Tagging via Attentive Neural Tree Decoding</title>
      <author><first>Gaurav</first><last>Singh</last></author>
      <author><first>James</first><last>Thomas</last></author>
      <author><first>Iain</first><last>Marshall</last></author>
      <author><first>John</first><last>Shawe-Taylor</last></author>
      <author><first>Byron C.</first><last>Wallace</last></author>
      <pages>2837–2842</pages>
      <url hash="6fcb378d">D18-1308</url>
      <attachment type="attachment" hash="20327ddf">D18-1308.Attachment.pdf</attachment>
      <abstract>We propose a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for tagging <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured texts</a> with an arbitrary number of terms drawn from a <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree-structured vocabulary</a> (i.e., an <a href="https://en.wikipedia.org/wiki/Ontology_(information_science)">ontology</a>). We treat this as a special case of sequence-to-sequence learning in which the decoder begins at the root node of an ontological tree and recursively elects to expand child nodes as a function of the input text, the current node, and the latent decoder state. We demonstrate that this method yields state-of-the-art results on the important task of assigning <a href="https://en.wikipedia.org/wiki/Medical_Subject_Headings">MeSH terms</a> to biomedical abstracts.</abstract>
      <video href="https://vimeo.com/306056257" />
      <doi>10.18653/v1/D18-1308</doi>
      <bibkey>singh-etal-2018-structured</bibkey>
      <pwccode url="https://github.com/gauravsc/NTD" additional="false">gauravsc/NTD</pwccode>
    </paper>
    <paper id="309">
      <title>Deep Exhaustive Model for Nested Named Entity Recognition</title>
      <author><first>Mohammad Golam</first><last>Sohrab</last></author>
      <author><first>Makoto</first><last>Miwa</last></author>
      <pages>2843–2849</pages>
      <url hash="e108b492">D18-1309</url>
      <abstract>We propose a simple <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural model</a> for nested named entity recognition (NER). Most NER models focused on flat entities and ignored nested entities, which failed to fully capture underlying semantic information in texts. The key idea of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is to enumerate all possible regions or spans as potential entity mentions and classify them with <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks</a>. To reduce the computational costs and capture the information of the contexts around the regions, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> represents the regions using the outputs of shared underlying bidirectional long short-term memory. We evaluate our exhaustive <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> on the GENIA and JNLPBA corpora in biomedical domain, and the results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state-of-the-art models on nested and flat NER, achieving 77.1 % and 78.4 % respectively in terms of <a href="https://en.wikipedia.org/wiki/F-score">F-score</a>, without any external knowledge resources.</abstract>
      <video href="https://vimeo.com/306057139" />
      <doi>10.18653/v1/D18-1309</doi>
      <bibkey>sohrab-miwa-2018-deep</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
    </paper>
    <paper id="310">
      <title>Evaluating the Utility of <a href="https://en.wikipedia.org/wiki/Handicraft">Hand-crafted Features</a> in Sequence Labelling</title>
      <author><first>Minghao</first><last>Wu</last></author>
      <author id="fei-liu-unimelb"><first>Fei</first><last>Liu</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>2850–2856</pages>
      <url hash="02f9b953">D18-1310</url>
      <abstract>Conventional wisdom is that hand-crafted features are redundant for deep learning models, as they already learn adequate representations of text automatically from corpora. In this work, we test this claim by proposing a new method for exploiting handcrafted features as part of a novel hybrid learning approach, incorporating a feature auto-encoder loss component. We evaluate on the task of named entity recognition (NER), where we show that including manual features for part-of-speech, word shapes and gazetteers can improve the performance of a neural CRF model. We obtain a F 1 of 91.89 for the CoNLL-2003 English shared task, which significantly outperforms a collection of highly competitive baseline models. We also present an ablation study showing the importance of auto-encoding, over using features as either inputs or outputs alone, and moreover, show including the autoencoder components reduces training requirements to 60 %, while retaining the same predictive accuracy.</abstract>
      <video href="https://vimeo.com/306112516" />
      <doi>10.18653/v1/D18-1310</doi>
      <bibkey>wu-etal-2018-evaluating</bibkey>
      <pwccode url="https://github.com/minghao-wu/CRF-AE" additional="false">minghao-wu/CRF-AE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="311">
      <title>Improved Dependency Parsing using Implicit Word Connections Learned from Unlabeled Data</title>
      <author><first>Wenhui</first><last>Wang</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Mairgup</first><last>Mansur</last></author>
      <pages>2857–2863</pages>
      <url hash="0fa11117">D18-1311</url>
      <abstract>Pre-trained word embeddings and <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> have been shown useful in a lot of tasks. However, both of them can not directly capture word connections in a sentence, which is important for dependency parsing given its goal is to establish dependency relations between words. In this paper, we propose to implicitly capture word connections from unlabeled data by a word ordering model with self-attention mechanism. Experiments show that these implicit word connections do improve our parsing model. Furthermore, by combining with a pre-trained language model, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> gets state-of-the-art performance on the English PTB dataset, achieving 96.35 % UAS and 95.25 % LAS.</abstract>
      <video href="https://vimeo.com/305667813" />
      <doi>10.18653/v1/D18-1311</doi>
      <bibkey>wang-etal-2018-improved</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="312">
      <title>A Framework for Understanding the Role of <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">Morphology</a> in Universal Dependency Parsing<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Parsing</title>
      <author><first>Mathieu</first><last>Dehouck</last></author>
      <author><first>Pascal</first><last>Denis</last></author>
      <pages>2864–2870</pages>
      <url hash="a3720304">D18-1312</url>
      <attachment type="attachment" hash="70ebc2d4">D18-1312.Attachment.pdf</attachment>
      <abstract>This paper presents a simple <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> for characterizing <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological complexity</a> and how it encodes <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a>. In particular, we propose a new measure of morpho-syntactic complexity in terms of governor-dependent preferential attachment that explains <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> performance. Through experiments on dependency parsing with data from Universal Dependencies (UD), we show that representations derived from morphological attributes deliver important parsing performance improvements over standard word form embeddings when trained on the same datasets. We also show that the new morpho-syntactic complexity measure is predictive of the gains provided by using morphological attributes over plain forms on parsing scores, making it a tool to distinguish languages using <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> as a syntactic marker from others.</abstract>
      <video href="https://vimeo.com/305925065" />
      <doi>10.18653/v1/D18-1312</doi>
      <bibkey>dehouck-denis-2018-framework</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="314">
      <title>Imitation Learning for Neural Morphological String Transduction</title>
      <author><first>Peter</first><last>Makarov</last></author>
      <author><first>Simon</first><last>Clematide</last></author>
      <pages>2877–2882</pages>
      <url hash="4daa33f8">D18-1314</url>
      <abstract>We employ imitation learning to train a neural transition-based string transducer for morphological tasks such as <a href="https://en.wikipedia.org/wiki/Inflection">inflection generation</a> and <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a>. Previous approaches to training this type of <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> either rely on an external character aligner for the production of gold action sequences, which results in a suboptimal <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> due to the unwarranted dependence on a single gold action sequence despite spurious ambiguity, or require warm starting with an MLE model. Our approach only requires a simple expert policy, eliminating the need for a character aligner or <a href="https://en.wikipedia.org/wiki/Warm_start">warm start</a>. It also addresses familiar MLE training biases and leads to strong and state-of-the-art performance on several <a href="https://en.wikipedia.org/wiki/Benchmark_(computing)">benchmarks</a>.</abstract>
      <video href="https://vimeo.com/305671668" />
      <doi>10.18653/v1/D18-1314</doi>
      <bibkey>makarov-clematide-2018-imitation</bibkey>
      <pwccode url="https://github.com/ZurichNLP/emnlp2018-imitation-learning-for-neural-morphology" additional="false">ZurichNLP/emnlp2018-imitation-learning-for-neural-morphology</pwccode>
    </paper>
    <paper id="315">
      <title>An Encoder-Decoder Approach to the Paradigm Cell Filling Problem</title>
      <author><first>Miikka</first><last>Silfverberg</last></author>
      <author><first>Mans</first><last>Hulden</last></author>
      <pages>2883–2889</pages>
      <url hash="6ac95f40">D18-1315</url>
      <abstract>The Paradigm Cell Filling Problem in <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> asks to complete word inflection tables from partial ones. We implement novel neural models for this task, evaluating them on 18 data sets in 8 languages, showing performance that is comparable with previous work with far less training data. We also publish a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> and code implementing the <a href="https://en.wikipedia.org/wiki/System">system</a> described in this paper.</abstract>
      <video href="https://vimeo.com/305674091" />
      <doi>10.18653/v1/D18-1315</doi>
      <bibkey>silfverberg-hulden-2018-encoder</bibkey>
      <pwccode url="https://github.com/mpsilfve/pcfp-data" additional="false">mpsilfve/pcfp-data</pwccode>
    </paper>
    <paper id="317">
      <title>Multi-Head Attention with Disagreement Regularization</title>
      <author><first>Jian</first><last>Li</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Michael R.</first><last>Lyu</last></author>
      <author><first>Tong</first><last>Zhang</last></author>
      <pages>2897–2903</pages>
      <url hash="055ab3ce">D18-1317</url>
      <abstract>Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization, which respectively encourage the <a href="https://en.wikipedia.org/wiki/Linear_subspace">subspace</a>, the attended positions, and the output representation associated with each attention head to be different from other heads. Experimental results on widely-used WMT14 English-German and WMT17 Chinese-English translation tasks demonstrate the effectiveness and universality of the proposed approach.</abstract>
      <doi>10.18653/v1/D18-1317</doi>
      <bibkey>li-etal-2018-multi-head</bibkey>
    </paper>
    <paper id="318">
      <title>Deep Bayesian Active Learning for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a> : Results of a Large-Scale Empirical Study<fixed-case>B</fixed-case>ayesian Active Learning for Natural Language Processing: Results of a Large-Scale Empirical Study</title>
      <author><first>Aditya</first><last>Siddhant</last></author>
      <author><first>Zachary C.</first><last>Lipton</last></author>
      <pages>2904–2909</pages>
      <url hash="9718d321">D18-1318</url>
      <abstract>Several recent papers investigate Active Learning (AL) for mitigating the <a href="https://en.wikipedia.org/wiki/Data_dependence">data dependence</a> of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. However, the applicability of AL to real-world problems remains an open question. While in <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>, practitioners can try many different methods, evaluating each against a validation set before selecting a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>, AL affords no such luxury. Over the course of one AL run, an agent annotates its dataset exhausting its labeling budget. Thus, given a new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we have no opportunity to compare <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> and acquisition functions. This paper provides a large-scale empirical study of deep active learning, addressing multiple tasks and, for each, multiple datasets, multiple models, and a full suite of acquisition functions. We find that across all settings, Bayesian active learning by disagreement, using uncertainty estimates provided either by Dropout or <a href="https://en.wikipedia.org/wiki/Bayes’_rule">Bayes-by-Backprop</a> significantly improves over i.i.d. baselines and usually outperforms classic uncertainty sampling.</abstract>
      <doi>10.18653/v1/D18-1318</doi>
      <bibkey>siddhant-lipton-2018-deep</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="319">
      <title>Bayesian Compression for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a><fixed-case>B</fixed-case>ayesian Compression for Natural Language Processing</title>
      <author><first>Nadezhda</first><last>Chirkova</last></author>
      <author><first>Ekaterina</first><last>Lobacheva</last></author>
      <author><first>Dmitry</first><last>Vetrov</last></author>
      <pages>2910–2915</pages>
      <url hash="0096dec4">D18-1319</url>
      <attachment type="attachment" hash="57a3e550">D18-1319.Attachment.zip</attachment>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>, a lot of the tasks are successfully solved with <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural networks</a>, but such <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> have a huge number of parameters. The majority of these parameters are often concentrated in the <a href="https://en.wikipedia.org/wiki/Embedding">embedding layer</a>, which size grows proportionally to the vocabulary length. We propose a Bayesian sparsification technique for RNNs which allows compressing the RNN dozens or hundreds of times without time-consuming hyperparameters tuning. We also generalize the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> for vocabulary sparsification to filter out unnecessary words and compress the RNN even further. We show that the choice of the kept words is interpretable.</abstract>
      <doi>10.18653/v1/D18-1319</doi>
      <bibkey>chirkova-etal-2018-bayesian</bibkey>
      <pwccode url="https://github.com/tipt0p/SparseBayesianRNN" additional="true">tipt0p/SparseBayesianRNN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="321">
      <title>Chinese Pinyin Aided IME, Input What You Have Not Keystroked Yet<fixed-case>C</fixed-case>hinese <fixed-case>P</fixed-case>inyin Aided <fixed-case>IME</fixed-case>, Input What You Have Not Keystroked Yet</title>
      <author><first>Yafang</first><last>Huang</last></author>
      <author><first>Hai</first><last>Zhao</last></author>
      <pages>2923–2929</pages>
      <url hash="28f2e0f3">D18-1321</url>
      <abstract>Chinese pinyin input method engine (IME) converts pinyin into character so that <a href="https://en.wikipedia.org/wiki/Chinese_characters">Chinese characters</a> can be conveniently inputted into computer through common keyboard. IMEs work relying on its core component, pinyin-to-character conversion (P2C). Usually Chinese IMEs simply predict a list of character sequences for user choice only according to user pinyin input at each turn. However, Chinese inputting is a multi-turn online procedure, which can be supposed to be exploited for further user experience promoting. This paper thus for the first time introduces a sequence-to-sequence model with gated-attention mechanism for the core task in <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture">IMEs</a>. The proposed neural P2C model is learned by encoding previous input utterance as extra context to enable our IME capable of predicting character sequence with incomplete pinyin input. Our model is evaluated in different benchmark datasets showing great user experience improvement compared to traditional models, which demonstrates the first engineering practice of building Chinese aided IME.</abstract>
      <doi>10.18653/v1/D18-1321</doi>
      <bibkey>huang-zhao-2018-chinese</bibkey>
      <pwccode url="https://github.com/YvonneHuang/gaIME" additional="false">YvonneHuang/gaIME</pwccode>
    </paper>
    <paper id="322">
      <title>Estimating Marginal Probabilities of n-grams for Recurrent Neural Language Models</title>
      <author><first>Thanapon</first><last>Noraset</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <pages>2930–2935</pages>
      <url hash="664e26b7">D18-1322</url>
      <abstract>Recurrent neural network language models (RNNLMs) are the current standard-bearer for statistical language modeling. However, RNNLMs only estimate probabilities for complete sequences of text, whereas some applications require context-independent phrase probabilities instead. In this paper, we study how to compute an RNNLM’s em marginal probability : the probability that the model assigns to a short sequence of text when the preceding context is not known. We introduce a simple method of altering the RNNLM training to make the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> more accurate at marginal estimation. Our experiments demonstrate that the technique is effective compared to baselines including the traditional RNNLM probability and an importance sampling approach. Finally, we show how we can use the marginal estimation to improve an RNNLM by training the <a href="https://en.wikipedia.org/wiki/Marginal_distribution">marginals</a> to match n-gram probabilities from a larger corpus.</abstract>
      <doi>10.18653/v1/D18-1322</doi>
      <bibkey>noraset-etal-2018-estimating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-103">WikiText-103</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-2">WikiText-2</pwcdataset>
    </paper>
    <paper id="323">
      <title>How to represent a word and predict it, too : Improving tied architectures for language modelling</title>
      <author><first>Kristina</first><last>Gulordava</last></author>
      <author><first>Laura</first><last>Aina</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <pages>2936–2941</pages>
      <url hash="9536bb47">D18-1323</url>
      <attachment type="attachment" hash="7f751dbf">D18-1323.Attachment.pdf</attachment>
      <abstract>Recent state-of-the-art neural language models share the representations of words given by the input and output mappings. We propose a simple modification to these <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a> that decouples the hidden state from the word embedding prediction. Our architecture leads to comparable or better results compared to previous tied models and <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> without tying, with a much smaller number of parameters. We also extend our proposal to word2vec models, showing that tying is appropriate for general word prediction tasks.</abstract>
      <doi>10.18653/v1/D18-1323</doi>
      <bibkey>gulordava-etal-2018-represent</bibkey>
    </paper>
    <paper id="324">
      <title>The Importance of Generation Order in Language Modeling</title>
      <author><first>Nicolas</first><last>Ford</last></author>
      <author><first>Daniel</first><last>Duckworth</last></author>
      <author><first>Mohammad</first><last>Norouzi</last></author>
      <author><first>George</first><last>Dahl</last></author>
      <pages>2942–2946</pages>
      <url hash="28afca9e">D18-1324</url>
      <abstract>Neural language models are a critical component of state-of-the-art systems for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>, <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">audio transcription</a>, and other tasks. These language models are almost universally autoregressive in nature, generating sentences one token at a time from left to right. This paper studies the influence of token generation order on model quality via a novel two-pass language model that produces partially-filled sentence templates and then fills in missing tokens. We compare various <a href="https://en.wikipedia.org/wiki/Strategy_(game_theory)">strategies</a> for structuring these two passes and observe a surprisingly large variation in model quality. We find the most effective <a href="https://en.wikipedia.org/wiki/Strategy">strategy</a> generates <a href="https://en.wikipedia.org/wiki/Function_word">function words</a> in the first pass followed by <a href="https://en.wikipedia.org/wiki/Content_word">content words</a> in the second. We believe these experimental results justify a more extensive investigation of the generation order for neural language models.</abstract>
      <doi>10.18653/v1/D18-1324</doi>
      <bibkey>ford-etal-2018-importance</bibkey>
    </paper>
    <paper id="326">
      <title>Three Strategies to Improve One-to-Many Multilingual Translation</title>
      <author><first>Yining</first><last>Wang</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Feifei</first><last>Zhai</last></author>
      <author><first>Jingfang</first><last>Xu</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>2955–2960</pages>
      <url hash="e6e1e760">D18-1326</url>
      <abstract>Due to the benefits of model compactness, multilingual translation (including many-to-one, many-to-many and one-to-many) based on a universal encoder-decoder architecture attracts more and more attention. However, previous studies show that one-to-many translation based on this <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a> can not perform on par with the individually trained models. In this work, we introduce three <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> to improve one-to-many multilingual translation by balancing the shared and unique features. Within the architecture of one <a href="https://en.wikipedia.org/wiki/Codec">decoder</a> for all target languages, we first exploit the use of unique initial states for different target languages. Then, we employ language-dependent positional embeddings. Finally and especially, we propose to divide the hidden cells of the <a href="https://en.wikipedia.org/wiki/Code">decoder</a> into shared and language-dependent ones. The extensive experiments demonstrate that our proposed methods can obtain remarkable improvements over the strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a>. Moreover, our <a href="https://en.wikipedia.org/wiki/Strategy">strategies</a> can achieve comparable or even better performance than the individually trained <a href="https://en.wikipedia.org/wiki/Translation_(biology)">translation models</a>.</abstract>
      <doi>10.18653/v1/D18-1326</doi>
      <bibkey>wang-etal-2018-three</bibkey>
    </paper>
    <paper id="327">
      <title>Multi-Source Syntactic Neural Machine Translation</title>
      <author><first>Anna</first><last>Currey</last></author>
      <author><first>Kenneth</first><last>Heafield</last></author>
      <pages>2961–2966</pages>
      <url hash="0b16219d">D18-1327</url>
      <abstract>We introduce a novel multi-source technique for incorporating <a href="https://en.wikipedia.org/wiki/Syntax_(programming_languages)">source syntax</a> into <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> using linearized parses. This is achieved by employing separate <a href="https://en.wikipedia.org/wiki/Encoder">encoders</a> for the sequential and parsed versions of the same source sentence ; the resulting representations are then combined using a hierarchical attention mechanism. The proposed model improves over both seq2seq and parsed baselines by over 1 BLEU on the WMT17 English-German task. Further analysis shows that our multi-source syntactic model is able to translate successfully without any parsed input, unlike standard parsed methods. In addition, performance does not deteriorate as much on long sentences as for the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">baselines</a>.</abstract>
      <doi>10.18653/v1/D18-1327</doi>
      <bibkey>currey-heafield-2018-multi</bibkey>
    </paper>
    <paper id="328">
      <title>Fixing Translation Divergences in Parallel Corpora for Neural MT<fixed-case>MT</fixed-case></title>
      <author><first>MinhQuang</first><last>Pham</last></author>
      <author><first>Josep</first><last>Crego</last></author>
      <author><first>Jean</first><last>Senellart</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>2967–2973</pages>
      <url hash="899063d9">D18-1328</url>
      <abstract>Corpus-based approaches to <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> rely on the availability of clean parallel corpora. Such resources are scarce, and because of the automatic processes involved in their preparation, they are often noisy. This paper describes an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised method</a> for detecting translation divergences in parallel sentences. We rely on a <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> that computes cross-lingual sentence similarity scores, which are then used to effectively filter out divergent translations. Furthermore, similarity scores predicted by the <a href="https://en.wikipedia.org/wiki/Flow_network">network</a> are used to identify and fix some partial divergences, yielding additional parallel segments. We evaluate these methods for English-French and English-German machine translation tasks, and show that using filtered / corrected corpora actually improves MT performance.</abstract>
      <doi>10.18653/v1/D18-1328</doi>
      <bibkey>pham-etal-2018-fixing</bibkey>
      <pwccode url="https://github.com/jmcrego/similarity" additional="false">jmcrego/similarity</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/opensubtitles">OpenSubtitles</pwcdataset>
    </paper>
    <paper id="330">
      <title>Loss in Translation : Learning Bilingual Word Mapping with a Retrieval Criterion</title>
      <author><first>Armand</first><last>Joulin</last></author>
      <author><first>Piotr</first><last>Bojanowski</last></author>
      <author><first>Tomas</first><last>Mikolov</last></author>
      <author><first>Hervé</first><last>Jégou</last></author>
      <author><first>Edouard</first><last>Grave</last></author>
      <pages>2979–2984</pages>
      <url hash="6ceba9b0">D18-1330</url>
      <attachment type="attachment" hash="c4209512">D18-1330.Attachment.zip</attachment>
      <abstract>Continuous word representations learned separately on distinct languages can be aligned so that their words become comparable in a common space. Existing works typically solve a quadratic problem to learn a <a href="https://en.wikipedia.org/wiki/Orthogonal_matrix">orthogonal matrix</a> aligning a <a href="https://en.wikipedia.org/wiki/Bilingual_lexicon">bilingual lexicon</a>, and use a retrieval criterion for <a href="https://en.wikipedia.org/wiki/Statistical_inference">inference</a>. In this paper, we propose an unified formulation that directly optimizes a retrieval criterion in an end-to-end fashion. Our experiments on standard <a href="https://en.wikipedia.org/wiki/Benchmarking">benchmarks</a> show that our approach outperforms the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state of the art</a> on word translation, with the biggest improvements observed for distant language pairs such as <a href="https://en.wikipedia.org/wiki/Standard_Chinese">English-Chinese</a>.</abstract>
      <doi>10.18653/v1/D18-1330</doi>
      <bibkey>joulin-etal-2018-loss</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="334">
      <title>Getting Gender Right in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Eva</first><last>Vanmassenhove</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>3003–3008</pages>
      <url hash="e3e7af19">D18-1334</url>
      <abstract>Speakers of different languages must attend to and encode strikingly different aspects of the world in order to use their language correctly (Sapir, 1921 ; Slobin, 1996). One such difference is related to the way gender is expressed in a language. Saying I am happy in English, does not encode any additional knowledge of the speaker that uttered the sentence. However, many other languages do have <a href="https://en.wikipedia.org/wiki/Grammatical_gender">grammatical gender systems</a> and so such knowledge would be encoded. In order to correctly translate such a sentence into, say, <a href="https://en.wikipedia.org/wiki/French_language">French</a>, the inherent gender information needs to be retained / recovered. The same sentence would become either Je suis heureux, for a male speaker or Je suis heureuse for a female one. Apart from <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological agreement</a>, <a href="https://en.wikipedia.org/wiki/Demography">demographic factors</a> (gender, age, etc.) also influence our use of language in terms of word choices or syntactic constructions (Tannen, 1991 ; Pennebaker et al., 2003). We integrate <a href="https://en.wikipedia.org/wiki/Gender">gender information</a> into <a href="https://en.wikipedia.org/wiki/Network_topology">NMT systems</a>. Our contribution is two-fold : (1) the compilation of large datasets with speaker information for 20 language pairs, and (2) a simple set of experiments that incorporate gender information into NMT for multiple language pairs. Our experiments show that adding a gender feature to an NMT system significantly improves the translation quality for some language pairs.</abstract>
      <doi>10.18653/v1/D18-1334</doi>
      <bibkey>vanmassenhove-etal-2018-getting</bibkey>
    </paper>
    <paper id="338">
      <title>Training Deeper Neural Machine Translation Models with Transparent Attention</title>
      <author><first>Ankur</first><last>Bapna</last></author>
      <author><first>Mia</first><last>Chen</last></author>
      <author><first>Orhan</first><last>Firat</last></author>
      <author><first>Yuan</first><last>Cao</last></author>
      <author><first>Yonghui</first><last>Wu</last></author>
      <pages>3028–3033</pages>
      <url hash="2645d840">D18-1338</url>
      <abstract>While current state-of-the-art NMT models, such as RNN seq2seq and Transformers, possess a large number of parameters, they are still shallow in comparison to convolutional models used for both text and vision applications. In this work we attempt to train significantly (2-3x) deeper Transformer and Bi-RNN encoders for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. We propose a simple modification to the attention mechanism that eases the optimization of deeper models, and results in consistent gains of 0.7-1.1 BLEU on the benchmark WMT’14 English-German and WMT’15 Czech-English tasks for both <a href="https://en.wikipedia.org/wiki/Computer_architecture">architectures</a>.</abstract>
      <doi>10.18653/v1/D18-1338</doi>
      <bibkey>bapna-etal-2018-training</bibkey>
    </paper>
    <paper id="339">
      <title>Context and Copying in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a></title>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>3034–3041</pages>
      <url hash="83c75623">D18-1339</url>
      <abstract>Neural machine translation systems with subword vocabularies are capable of <a href="https://en.wikipedia.org/wiki/Translation">translating</a> or copying unknown words. In this work, we show that they learn to copy words based on both the context in which the words appear as well as features of the words themselves. In contexts that are particularly copy-prone, they even copy words that they have already learned they should translate. We examine the influence of <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context and subword features</a> on this and other types of <a href="https://en.wikipedia.org/wiki/Copying">copying behavior</a>.</abstract>
      <doi>10.18653/v1/D18-1339</doi>
      <bibkey>knowles-koehn-2018-context</bibkey>
    </paper>
    <paper id="342">
      <title>Breaking the Beam Search Curse : A Study of (Re-)Scoring Methods and Stopping Criteria for Neural Machine Translation</title>
      <author><first>Yilin</first><last>Yang</last></author>
      <author><first>Liang</first><last>Huang</last></author>
      <author><first>Mingbo</first><last>Ma</last></author>
      <pages>3054–3059</pages>
      <url hash="6923c029">D18-1342</url>
      <abstract>Beam search is widely used in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>, and usually improves translation quality compared to <a href="https://en.wikipedia.org/wiki/Greedy_search">greedy search</a>. It has been widely observed that, however, beam sizes larger than 5 hurt translation quality. We explain why this happens, and propose several <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> to address this problem. Furthermore, we discuss the optimal stopping criteria for these methods. Results show that our hyperparameter-free methods outperform the widely-used hyperparameter-free heuristic of length normalization by +2.0 BLEU, and achieve the best results among all methods on Chinese-to-English translation.</abstract>
      <doi>10.18653/v1/D18-1342</doi>
      <bibkey>yang-etal-2018-breaking</bibkey>
    </paper>
    <paper id="343">
      <title>Multi-Multi-View Learning : Multilingual and Multi-Representation Entity Typing</title>
      <author><first>Yadollah</first><last>Yaghoobzadeh</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>3060–3066</pages>
      <url hash="2b3df4de">D18-1343</url>
      <attachment type="attachment" hash="ced6de9c">D18-1343.Attachment.zip</attachment>
      <abstract>Accurate and complete knowledge bases (KBs) are paramount in <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a>. We employ mul-itiview learning for increasing the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and coverage of entity type information in <a href="https://en.wikipedia.org/wiki/Knowledge_base">KBs</a>. We rely on two <a href="https://en.wikipedia.org/wiki/Metafiction">metaviews</a> : language and representation. For <a href="https://en.wikipedia.org/wiki/Language">language</a>, we consider high-resource and low-resource languages from <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>. For <a href="https://en.wikipedia.org/wiki/Representation_(mathematics)">representation</a>, we consider representations based on the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">context distribution</a> of the entity (i.e., on its embedding), on the entity’s name (i.e., on its surface form) and on its description in <a href="https://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a>. The two metaviews language and representation can be freely combined : each pair of <a href="https://en.wikipedia.org/wiki/Language_(computer_science)">language</a> and representation (e.g., German embedding, English description, Spanish name) is a distinct view. Our experiments on entity typing with fine-grained classes demonstrate the effectiveness of multiview learning. We release MVET, a large multiview   and, in particular, multilingual   entity typing dataset we created. Mono- and multilingual fine-grained entity typing systems can be evaluated on this dataset.</abstract>
      <doi>10.18653/v1/D18-1343</doi>
      <bibkey>yaghoobzadeh-schutze-2018-multi</bibkey>
      <pwccode url="https://github.com/yyaghoobzadeh/MVET" additional="false">yyaghoobzadeh/MVET</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/figer">FIGER</pwcdataset>
    </paper>
    <paper id="344">
      <title>Word Embeddings for Code-Mixed Language Processing</title>
      <author><first>Adithya</first><last>Pratapa</last></author>
      <author><first>Monojit</first><last>Choudhury</last></author>
      <author><first>Sunayana</first><last>Sitaram</last></author>
      <pages>3067–3072</pages>
      <url hash="16c91e7e">D18-1344</url>
      <abstract>We compare three existing bilingual word embedding approaches, and a novel approach of training skip-grams on synthetic code-mixed text generated through linguistic models of code-mixing, on two tasks-sentiment analysis and POS tagging for code-mixed text. Our results show that while CVM and CCA based embeddings perform as well as the proposed embedding technique on semantic and syntactic tasks respectively, the proposed approach provides the best performance for both tasks overall. Thus, this study demonstrates that existing bilingual embedding techniques are not ideal for code-mixed text processing and there is a need for learning multilingual word embedding from the code-mixed text.</abstract>
      <doi>10.18653/v1/D18-1344</doi>
      <bibkey>pratapa-etal-2018-word</bibkey>
    </paper>
    <paper id="346">
      <title>Code-switched Language Models Using Dual RNNs and Same-Source Pretraining<fixed-case>RNN</fixed-case>s and Same-Source Pretraining</title>
      <author><first>Saurabh</first><last>Garg</last></author>
      <author><first>Tanmay</first><last>Parekh</last></author>
      <author><first>Preethi</first><last>Jyothi</last></author>
      <pages>3078–3083</pages>
      <url hash="55cfaaa6">D18-1346</url>
      <abstract>This work focuses on building language models (LMs) for code-switched text. We propose two techniques that significantly improve these LMs : 1) A novel recurrent neural network unit with dual components that focus on each language in the code-switched text separately 2) Pretraining the LM using synthetic text from a generative model estimated using the training data. We demonstrate the effectiveness of our proposed techniques by reporting perplexities on a Mandarin-English task and derive significant reductions in <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a>.</abstract>
      <doi>10.18653/v1/D18-1346</doi>
      <bibkey>garg-etal-2018-code</bibkey>
    </paper>
    <paper id="347">
      <title>Part-of-Speech Tagging for Code-Switched, Transliterated Texts without Explicit Language Identification</title>
      <author><first>Kelsey</first><last>Ball</last></author>
      <author><first>Dan</first><last>Garrette</last></author>
      <pages>3084–3089</pages>
      <url hash="0416ff31">D18-1347</url>
      <abstract>Code-switching, the use of more than one language within a single utterance, is ubiquitous in much of the world, but remains a challenge for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> largely due to the lack of representative data for training models. In this paper, we present a novel model architecture that is trained exclusively on <a href="https://en.wikipedia.org/wiki/Monolingualism">monolingual resources</a>, but can be applied to unseen code-switched text at inference time. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> accomplishes this by jointly maintaining separate word representations for each of the possible languages, or <a href="https://en.wikipedia.org/wiki/Writing_system">scripts</a> in the case of <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a>, allowing each to contribute to inferences without forcing the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> to commit to a language. Experiments on Hindi-English part-of-speech tagging demonstrate that our approach outperforms standard models when training on monolingual text without <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration</a>, and testing on code-switched text with alternate scripts.</abstract>
      <doi>10.18653/v1/D18-1347</doi>
      <bibkey>ball-garrette-2018-part</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="349">
      <title>Hierarchical Neural Networks for Sequential Sentence Classification in Medical Scientific Abstracts</title>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Peter</first><last>Szolovits</last></author>
      <pages>3100–3109</pages>
      <url hash="d506d1ab">D18-1349</url>
      <abstract>Prevalent models based on artificial neural network (ANN) for sentence classification often classify sentences in isolation without considering the context in which sentences appear. This hampers the traditional sentence classification approaches to the problem of sequential sentence classification, where <a href="https://en.wikipedia.org/wiki/Structured_prediction">structured prediction</a> is needed for better overall classification performance. In this work, we present a hierarchical sequential labeling network to make use of the <a href="https://en.wikipedia.org/wiki/Context_(language_use)">contextual information</a> within surrounding sentences to help classify the current sentence. Our model outperforms the state-of-the-art results by 2%-3 % on two benchmarking datasets for sequential sentence classification in medical scientific abstracts.</abstract>
      <video href="https://vimeo.com/305946571" />
      <doi>10.18653/v1/D18-1349</doi>
      <bibkey>jin-szolovits-2018-hierarchical</bibkey>
      <pwccode url="https://github.com/jind11/HSLN-Joint-Sentence-Classification" additional="false">jind11/HSLN-Joint-Sentence-Classification</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/pubmed-rct">PubMed RCT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/pubmed">Pubmed</pwcdataset>
    </paper>
    <paper id="350">
      <title>Investigating Capsule Networks with <a href="https://en.wikipedia.org/wiki/Dynamic_routing">Dynamic Routing</a> for Text Classification</title>
      <author><first>Wei</first><last>Zhao</last></author>
      <author><first>Jianbo</first><last>Ye</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Zeyang</first><last>Lei</last></author>
      <author><first>Suofei</first><last>Zhang</last></author>
      <author><first>Zhou</first><last>Zhao</last></author>
      <pages>3110–3119</pages>
      <url hash="ac9b806b">D18-1350</url>
      <abstract>In this study, we explore capsule networks with <a href="https://en.wikipedia.org/wiki/Dynamic_routing">dynamic routing</a> for <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a>. We propose three strategies to stabilize the dynamic routing process to alleviate the disturbance of some noise capsules which may contain background information or have not been successfully trained. A series of experiments are conducted with capsule networks on six text classification benchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets, which shows the effectiveness of capsule networks for <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a>. We additionally show that capsule networks exhibit significant improvement when transfer single-label to multi-label text classification over strong baseline methods. To the best of our knowledge, this is the first work that capsule networks have been empirically investigated for text modeling.</abstract>
      <video href="https://vimeo.com/305947408" />
      <doi>10.18653/v1/D18-1350</doi>
      <bibkey>zhao-etal-2018-investigating</bibkey>
      <pwccode url="https://github.com/andyweizhao/capsule_text_classification" additional="true">andyweizhao/capsule_text_classification</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mr">MR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/subj">SUBJ</pwcdataset>
    </paper>
    <paper id="352">
      <title>Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces</title>
      <author><first>Anthony</first><last>Rios</last></author>
      <author><first>Ramakanth</first><last>Kavuluru</last></author>
      <pages>3132–3142</pages>
      <url hash="1a16abad">D18-1352</url>
      <abstract>Large multi-label datasets contain labels that occur thousands of times (frequent group), those that occur only a few times (few-shot group), and labels that never appear in the training dataset (zero-shot group). Multi-label few- and zero-shot label prediction is mostly unexplored on datasets with large label spaces, especially for text classification. In this paper, we perform a fine-grained evaluation to understand how state-of-the-art methods perform on infrequent labels. Furthermore, we develop few- and zero-shot methods for multi-label text classification when there is a known structure over the label space, and evaluate them on two publicly available medical text datasets : MIMIC II and MIMIC III. For few-shot labels we achieve improvements of 6.2 % and 4.8 % in <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R@10</a> for MIMIC II and MIMIC III, respectively, over prior efforts ; the corresponding <a href="https://en.wikipedia.org/wiki/R_(programming_language)">R@10</a> improvements for zero-shot labels are 17.3 % and 19 %.</abstract>
      <video href="https://vimeo.com/305948835" />
      <doi>10.18653/v1/D18-1352</doi>
      <bibkey>rios-kavuluru-2018-shot</bibkey>
      <pwccode url="https://github.com/bionlproc/multi-label-zero-shot" additional="false">bionlproc/multi-label-zero-shot</pwccode>
    </paper>
    <paper id="355">
      <title>Integrating Transformer and Paraphrase Rules for Sentence Simplification</title>
      <author><first>Sanqiang</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Meng</last></author>
      <author><first>Daqing</first><last>He</last></author>
      <author><first>Andi</first><last>Saptono</last></author>
      <author><first>Bambang</first><last>Parmanto</last></author>
      <pages>3164–3173</pages>
      <url hash="914b3b9a">D18-1355</url>
      <abstract>Sentence simplification aims to reduce the <a href="https://en.wikipedia.org/wiki/Complexity">complexity</a> of a sentence while retaining its original meaning. Current models for <a href="https://en.wikipedia.org/wiki/Sentence_simplification">sentence simplification</a> adopted ideas from machine translation studies and implicitly learned simplification mapping rules from normal-simple sentence pairs. In this paper, we explore a novel model based on a multi-layer and multi-head attention architecture and we propose two innovative approaches to integrate the Simple PPDB (A Paraphrase Database for Simplification), an external paraphrase knowledge base for simplification that covers a wide range of real-world simplification rules. The experiments show that the integration provides two major benefits : (1) the integrated model outperforms multiple state-of-the-art baseline models for <a href="https://en.wikipedia.org/wiki/Sentence_simplification">sentence simplification</a> in the literature (2) through analysis of the rule utilization, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> seeks to select more accurate simplification rules. The code and models used in the paper are available at.<url>https://github.com/Sanqiang/text_simplification</url>.</abstract>
      <video href="https://vimeo.com/305927122" />
      <doi>10.18653/v1/D18-1355</doi>
      <bibkey>zhao-etal-2018-integrating</bibkey>
      <pwccode url="https://github.com/Sanqiang/text_simplification" additional="false">Sanqiang/text_simplification</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/asset">ASSET</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/turkcorpus">TurkCorpus</pwcdataset>
    </paper>
    <paper id="357">
      <title>Multi-Reference Training with Pseudo-References for Neural Translation and Text Generation</title>
      <author><first>Renjie</first><last>Zheng</last></author>
      <author><first>Mingbo</first><last>Ma</last></author>
      <author><first>Liang</first><last>Huang</last></author>
      <pages>3188–3197</pages>
      <url hash="198df929">D18-1357</url>
      <abstract>Neural text generation, including <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>, image captioning, and <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a>, has been quite successful recently. However, during training time, typically only one reference is considered for each example, even though there are often multiple references available, e.g., 4 references in <a href="https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST MT evaluations</a>, and 5 references in image captioning data. We first investigate several different ways of utilizing multiple human references during training. But more importantly, we then propose an <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> to generate exponentially many pseudo-references by first compressing existing human references into <a href="https://en.wikipedia.org/wiki/Lattice_(group)">lattices</a> and then traversing them to generate new pseudo-references. These approaches lead to substantial improvements over strong <a href="https://en.wikipedia.org/wiki/Baseline_(typography)">baselines</a> in both <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> (+1.5 BLEU) and image captioning (+3.1 BLEU / +11.7 CIDEr).</abstract>
      <video href="https://vimeo.com/305929800" />
      <doi>10.18653/v1/D18-1357</doi>
      <bibkey>zheng-etal-2018-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="364">
      <title>Implicational Universals in Stochastic Constraint-Based Phonology</title>
      <author><first>Giorgio</first><last>Magri</last></author>
      <pages>3265–3274</pages>
      <url hash="497d3f7a">D18-1364</url>
      <abstract>This paper focuses on the most basic implicational universals in <a href="https://en.wikipedia.org/wiki/Phonology">phonological theory</a>, called T-orders after Anttila and Andrus (2006). It shows that the T-orders predicted by stochastic (and partial order) Optimality Theory coincide with those predicted by categorical OT. Analogously, the T-orders predicted by stochastic Harmonic Grammar coincide with those predicted by categorical HG. In other words, these stochastic constraint-based frameworks do not tamper with the <a href="https://en.wikipedia.org/wiki/Typology_(linguistics)">typological structure</a> induced by the original <a href="https://en.wikipedia.org/wiki/Categorical_variable">categorical frameworks</a>.</abstract>
      <video href="https://vimeo.com/305679809" />
      <doi>10.18653/v1/D18-1364</doi>
      <bibkey>magri-2018-implicational</bibkey>
    </paper>
    <paper id="365">
      <title>Explaining Character-Aware Neural Networks for Word-Level Prediction : Do They Discover Linguistic Rules?</title>
      <author><first>Fréderic</first><last>Godin</last></author>
      <author><first>Kris</first><last>Demuynck</last></author>
      <author><first>Joni</first><last>Dambre</last></author>
      <author><first>Wesley</first><last>De Neve</last></author>
      <author><first>Thomas</first><last>Demeester</last></author>
      <pages>3275–3284</pages>
      <url hash="1b160136">D18-1365</url>
      <attachment type="attachment" hash="f4753a11">D18-1365.Attachment.zip</attachment>
      <abstract>Character-level features are currently used in different neural network-based natural language processing algorithms. However, little is known about the character-level patterns those <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> learn. Moreover, <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are often compared only quantitatively while a qualitative analysis is missing. In this paper, we investigate which character-level patterns neural networks learn and if those <a href="https://en.wikipedia.org/wiki/Pattern">patterns</a> coincide with manually-defined word segmentations and <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>. To that end, we extend the contextual decomposition technique (Murdoch et al. 2018) to <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> which allows us to compare <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural networks</a> and bidirectional long short-term memory networks. We evaluate and compare these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> for the task of morphological tagging on three morphologically different languages and show that these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> implicitly discover understandable linguistic rules.</abstract>
      <video href="https://vimeo.com/305681577" />
      <doi>10.18653/v1/D18-1365</doi>
      <bibkey>godin-etal-2018-explaining</bibkey>
      <pwccode url="https://github.com/FredericGodin/ContextualDecomposition-NLP" additional="false">FredericGodin/ContextualDecomposition-NLP</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="367">
      <title>A Computational Exploration of Exaggeration</title>
      <author><first>Enrica</first><last>Troiano</last></author>
      <author><first>Carlo</first><last>Strapparava</last></author>
      <author><first>Gözde</first><last>Özbal</last></author>
      <author><first>Serra Sinem</first><last>Tekiroğlu</last></author>
      <pages>3296–3304</pages>
      <url hash="7d00d8e6">D18-1367</url>
      <abstract>Several NLP studies address the problem of <a href="https://en.wikipedia.org/wiki/Figurative_language">figurative language</a>, but among non-literal phenomena, they have neglected <a href="https://en.wikipedia.org/wiki/Exaggeration">exaggeration</a>. This paper presents a first <a href="https://en.wikipedia.org/wiki/Computational_linguistics">computational approach</a> to this <a href="https://en.wikipedia.org/wiki/Figure_of_speech">figure of speech</a>. We explore the possibility to automatically detect <a href="https://en.wikipedia.org/wiki/Exaggeration">exaggerated sentences</a>. First, we introduce HYPO, a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> containing overstatements (or hyperboles) collected on the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a> and validated via <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a>. Then, we evaluate a number of <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained on HYPO, and bring evidence that the task of hyperbole identification can be successfully performed based on a small set of <a href="https://en.wikipedia.org/wiki/Semantic_feature">semantic features</a>.</abstract>
      <doi>10.18653/v1/D18-1367</doi>
      <bibkey>troiano-etal-2018-computational</bibkey>
    </paper>
    <paper id="368">
      <title>Building Context-aware Clause Representations for Situation Entity Type Classification</title>
      <author><first>Zeyu</first><last>Dai</last></author>
      <author><first>Ruihong</first><last>Huang</last></author>
      <pages>3305–3315</pages>
      <url hash="b72ed19f">D18-1368</url>
      <abstract>Capabilities to categorize a clause based on the type of situation entity (e.g., <a href="https://en.wikipedia.org/wiki/Event_(philosophy)">events</a>, states and generic statements) the clause introduces to the <a href="https://en.wikipedia.org/wiki/Discourse">discourse</a> can benefit many <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP applications</a>. Observing that the situation entity type of a clause depends on discourse functions the clause plays in a paragraph and the interpretation of discourse functions depends heavily on paragraph-wide contexts, we propose to build context-aware clause representations for predicting situation entity types of clauses. Specifically, we propose a hierarchical recurrent neural network model to read a whole paragraph at a time and jointly learn representations for all the clauses in the paragraph by extensively modeling context influences and inter-dependencies of clauses. Experimental results show that our model achieves the state-of-the-art performance for clause-level situation entity classification on the genre-rich MASC+Wiki corpus, which approaches human-level performance.</abstract>
      <doi>10.18653/v1/D18-1368</doi>
      <bibkey>dai-huang-2018-building</bibkey>
    </paper>
    <paper id="370">
      <title>Investigating the Role of <a href="https://en.wikipedia.org/wiki/Argumentation_theory">Argumentation</a> in the <a href="https://en.wikipedia.org/wiki/Rhetorical_analysis">Rhetorical Analysis</a> of <a href="https://en.wikipedia.org/wiki/Scientific_literature">Scientific Publications</a> with Neural Multi-Task Learning Models</title>
      <author><first>Anne</first><last>Lauscher</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Simone Paolo</first><last>Ponzetto</last></author>
      <author><first>Kai</first><last>Eckert</last></author>
      <pages>3326–3338</pages>
      <url hash="0f6c5c91">D18-1370</url>
      <attachment type="attachment" hash="46c78007">D18-1370.Attachment.zip</attachment>
      <abstract>Exponential growth in the number of <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific publications</a> yields the need for effective automatic analysis of rhetorical aspects of scientific writing. Acknowledging the argumentative nature of <a href="https://en.wikipedia.org/wiki/Scientific_literature">scientific text</a>, in this work we investigate the link between the argumentative structure of scientific publications and rhetorical aspects such as discourse categories or <a href="https://en.wikipedia.org/wiki/Citation">citation contexts</a>. To this end, we (1) augment a corpus of scientific publications annotated with four layers of rhetoric annotations with argumentation annotations and (2) investigate neural multi-task learning architectures combining argument extraction with a set of rhetorical classification tasks. By coupling rhetorical classifiers with the extraction of argumentative components in a joint multi-task learning setting, we obtain significant performance gains for different rhetorical analysis tasks.</abstract>
      <doi>10.18653/v1/D18-1370</doi>
      <bibkey>lauscher-etal-2018-investigating</bibkey>
    </paper>
    <paper id="371">
      <title>Neural Ranking Models for Temporal Dependency Structure Parsing</title>
      <author><first>Yuchen</first><last>Zhang</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>3339–3349</pages>
      <url hash="b0b17f70">D18-1371</url>
      <abstract>We design and build the first neural temporal dependency parser. It utilizes a neural ranking model with minimal feature engineering, and parses time expressions and events in a text into a temporal dependency tree structure. We evaluate our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on two domains : <a href="https://en.wikipedia.org/wiki/News">news reports</a> and <a href="https://en.wikipedia.org/wiki/Narrative">narrative stories</a>. In a parsing-only evaluation setup where gold time expressions and <a href="https://en.wikipedia.org/wiki/Event_(computing)">events</a> are provided, our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> reaches 0.81 and 0.70 <a href="https://en.wikipedia.org/wiki/F-score">f-score</a> on unlabeled and labeled parsing respectively, a result that is very competitive against alternative approaches. In an end-to-end evaluation setup where time expressions and events are automatically recognized, our <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> beats two strong <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> on both data domains. Our experimental results and discussions shed light on the nature of temporal dependency structures in different domains and provide insights that we believe will be valuable to future research in this area.</abstract>
      <doi>10.18653/v1/D18-1371</doi>
      <bibkey>zhang-xue-2018-neural</bibkey>
      <pwccode url="https://github.com/yuchenz/tdp_ranking" additional="true">yuchenz/tdp_ranking</pwccode>
    </paper>
    <paper id="372">
      <title>Causal Explanation Analysis on <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></title>
      <author><first>Youngseo</first><last>Son</last></author>
      <author><first>Nipun</first><last>Bayas</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>3350–3359</pages>
      <url hash="30b2cdee">D18-1372</url>
      <attachment type="attachment" hash="01a94c37">D18-1372.Attachment.zip</attachment>
      <abstract>Understanding causal explanations-reasons given for happenings in one’s life-has been found to be an important psychological factor linked to physical and mental health. Causal explanations are often studied through manual identification of phrases over limited samples of personal writing. Automatic identification of causal explanations in <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>, while challenging in relying on contextual and sequential cues, offers a larger-scale alternative to expensive manual ratings and opens the door for new applications (e.g. studying prevailing beliefs about causes, such as climate change). Here, we explore automating causal explanation analysis, building on discourse parsing, and presenting two novel subtasks : causality detection (determining whether a causal explanation exists at all) and causal explanation identification (identifying the specific phrase that is the explanation). We achieve strong accuracies for both tasks but find different approaches best : an SVM for causality prediction (F1 = 0.791) and a hierarchy of Bidirectional LSTMs for causal explanation identification (F1 = 0.853). Finally, we explore applications of our complete pipeline (F1 = 0.868), showing demographic differences in mentions of causal explanation and that the association between a word and sentiment can change when it is used within a <a href="https://en.wikipedia.org/wiki/Causality">causal explanation</a>.</abstract>
      <doi>10.18653/v1/D18-1372</doi>
      <bibkey>son-etal-2018-causal</bibkey>
    </paper>
    <paper id="374">
      <title>Content Explorer : Recommending Novel Entities for a Document Writer</title>
      <author><first>Michal</first><last>Lukasik</last></author>
      <author><first>Richard</first><last>Zens</last></author>
      <pages>3371–3380</pages>
      <url hash="ac8d3bc8">D18-1374</url>
      <attachment type="attachment" hash="ab43bc31">D18-1374.Attachment.tgz</attachment>
      <abstract>Background research is an essential part of document writing. Search engines are great for retrieving information once we know what to look for. However, the bigger challenge is often identifying topics for further research. Automated tools could help significantly in this discovery process and increase the productivity of the writer. In this paper, we formulate the problem of recommending topics to a writer. We consider this as a supervised learning problem and run a <a href="https://en.wikipedia.org/wiki/User_study">user study</a> to validate this approach. We propose an evaluation metric and perform an empirical comparison of state-of-the-art models for extreme multi-label classification on a large data set. We demonstrate how a simple modification of the cross-entropy loss function leads to improved results of the <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a>.</abstract>
      <doi>10.18653/v1/D18-1374</doi>
      <bibkey>lukasik-zens-2018-content</bibkey>
    </paper>
    <paper id="375">
      <title>A Genre-Aware Attention Model to Improve the Likability Prediction of Books</title>
      <author><first>Suraj</first><last>Maharjan</last></author>
      <author><first>Manuel</first><last>Montes</last></author>
      <author><first>Fabio A.</first><last>González</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>3381–3391</pages>
      <url hash="63bc6e39">D18-1375</url>
      <abstract>Likability prediction of books has many uses. Readers, writers, as well as the publishing industry, can all benefit from automatic book likability prediction systems. In order to make reliable decisions, these <a href="https://en.wikipedia.org/wiki/System">systems</a> need to assimilate information from different aspects of a book in a sensible way. We propose a novel multimodal neural architecture that incorporates genre supervision to assign weights to individual feature types. Our proposed method is capable of dynamically tailoring weights given to feature types based on the characteristics of each book. Our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> achieves competitive results and even outperforms <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> for this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>.</abstract>
      <doi>10.18653/v1/D18-1375</doi>
      <bibkey>maharjan-etal-2018-genre</bibkey>
      <pwccode url="https://github.com/sjmaharjan/genre_aware_attention" additional="false">sjmaharjan/genre_aware_attention</pwccode>
    </paper>
    <paper id="376">
      <title>Thread Popularity Prediction and Tracking with a Permutation-invariant Model</title>
      <author><first>Hou Pong</first><last>Chan</last></author>
      <author><first>Irwin</first><last>King</last></author>
      <pages>3392–3401</pages>
      <url hash="e6138c36">D18-1376</url>
      <attachment type="attachment" hash="6beec136">D18-1376.Attachment.zip</attachment>
      <abstract>The task of thread popularity prediction and tracking aims to recommend a few popular comments to subscribed users when a batch of new comments arrive in a <a href="https://en.wikipedia.org/wiki/Conversation_threading">discussion thread</a>. This task has been formulated as a reinforcement learning problem, in which the reward of the agent is the sum of positive responses received by the recommended comments. In this work, we propose a novel <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">approach</a> to tackle this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>. First, we propose a deep neural network architecture to model the expected cumulative reward (Q-value) of a recommendation (action). Unlike the state-of-the-art approach, which treats an action as a sequence, our model uses an attention mechanism to integrate information from a set of comments. Thus, the prediction of Q-value is invariant to the permutation of the comments, which leads to a more consistent agent behavior. Second, we employ a <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy procedure</a> to approximate the action that maximizes the predicted Q-value from a combinatorial action space. Different from the state-of-the-art approach, this procedure does not require an additional pre-trained model to generate candidate actions. Experiments on five real-world datasets show that our approach outperforms the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a>.</abstract>
      <doi>10.18653/v1/D18-1376</doi>
      <bibkey>chan-king-2018-thread</bibkey>
    </paper>
    <paper id="378">
      <title>Limbic : Author-Based Sentiment Aspect Modeling Regularized with Word Embeddings and Discourse Relations<fixed-case>L</fixed-case>imbic: Author-Based Sentiment Aspect Modeling Regularized with Word Embeddings and Discourse Relations</title>
      <author><first>Zhe</first><last>Zhang</last></author>
      <author><first>Munindar</first><last>Singh</last></author>
      <pages>3412–3422</pages>
      <url hash="e91e489f">D18-1378</url>
      <abstract>We propose <a href="https://en.wikipedia.org/wiki/Limbic">Limbic</a>, an <a href="https://en.wikipedia.org/wiki/Unsupervised_learning">unsupervised probabilistic model</a> that addresses the problem of discovering aspects and sentiments and associating them with authors of opinionated texts. Limbic combines three ideas, incorporating <a href="https://en.wikipedia.org/wiki/Author">authors</a>, <a href="https://en.wikipedia.org/wiki/Discourse_analysis">discourse relations</a>, and <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>. For discourse relations, <a href="https://en.wikipedia.org/wiki/Limbic">Limbic</a> adopts a generative process regularized by a <a href="https://en.wikipedia.org/wiki/Markov_random_field">Markov Random Field</a>. To promote words with high <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a> into the same topic, <a href="https://en.wikipedia.org/wiki/Limbic">Limbic</a> captures semantic regularities from <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> via a generalized Plya Urn process. We demonstrate that Limbic (1) discovers aspects associated with sentiments with high <a href="https://en.wikipedia.org/wiki/Lexical_diversity">lexical diversity</a> ; (2) outperforms state-of-the-art models by a substantial margin in topic cohesion and sentiment classification.</abstract>
      <doi>10.18653/v1/D18-1378</doi>
      <bibkey>zhang-singh-2018-limbic</bibkey>
    </paper>
    <paper id="379">
      <title>An Interpretable Neural Network with Topical Information for Relevant Emotion Ranking</title>
      <author><first>Yang</first><last>Yang</last></author>
      <author><first>Deyu</first><last>Zhou</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>3423–3432</pages>
      <url hash="10eb669b">D18-1379</url>
      <abstract>Text might express or evoke multiple emotions with varying intensities. As such, it is crucial to predict and rank multiple relevant emotions by their intensities. Moreover, as <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> might be evoked by hidden topics, it is important to unveil and incorporate such topical information to understand how the <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> are evoked. We proposed a novel interpretable neural network approach for relevant emotion ranking. Specifically, motivated by <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>, the <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> is initialized to make the hidden layer approximate the behavior of <a href="https://en.wikipedia.org/wiki/Topic_model">topic models</a>. Moreover, a novel <a href="https://en.wikipedia.org/wiki/Error_detection_and_correction">error function</a> is defined to optimize the whole <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> for relevant emotion ranking. Experimental results on three real-world corpora show that the proposed approach performs remarkably better than the state-of-the-art emotion detection approaches and multi-label learning methods. Moreover, the extracted emotion-associated topic words indeed represent <a href="https://en.wikipedia.org/wiki/Emotion">emotion-evoking events</a> and are in line with our <a href="https://en.wikipedia.org/wiki/Common_sense">common-sense knowledge</a>.</abstract>
      <doi>10.18653/v1/D18-1379</doi>
      <bibkey>yang-etal-2018-interpretable</bibkey>
    </paper>
    <paper id="381">
      <title>Attentive Gated Lexicon Reader with Contrastive Contextual Co-Attention for Sentiment Classification</title>
      <author><first>Yi</first><last>Tay</last></author>
      <author><first>Anh Tuan</first><last>Luu</last></author>
      <author><first>Siu Cheung</first><last>Hui</last></author>
      <author><first>Jian</first><last>Su</last></author>
      <pages>3443–3453</pages>
      <url hash="e1d004ef">D18-1381</url>
      <abstract>This paper proposes a new neural architecture that exploits readily available sentiment lexicon resources. The key idea is that that incorporating a word-level prior can aid in the representation learning process, eventually improving <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performance. To this end, our model employs two distinctly unique components, i.e., (1) we introduce a lexicon-driven contextual attention mechanism to imbue lexicon words with long-range contextual information and (2), we introduce a contrastive co-attention mechanism that models contrasting polarities between all positive and negative words in a sentence. Via extensive experiments, we show that our approach outperforms many other neural baselines on sentiment classification tasks on multiple benchmark datasets.</abstract>
      <doi>10.18653/v1/D18-1381</doi>
      <bibkey>tay-etal-2018-attentive</bibkey>
    </paper>
    <paper id="385">
      <title>Cross-Lingual Cross-Platform Rumor Verification Pivoting on Multimedia Content</title>
      <author><first>Weiming</first><last>Wen</last></author>
      <author><first>Songwen</first><last>Su</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>3487–3496</pages>
      <url hash="7360654d">D18-1385</url>
      <abstract>With the increasing popularity of <a href="https://en.wikipedia.org/wiki/Smart_device">smart devices</a>, <a href="https://en.wikipedia.org/wiki/Rumor">rumors</a> with <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia content</a> become more and more common on <a href="https://en.wikipedia.org/wiki/List_of_social_networking_websites">social networks</a>. The <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia information</a> usually makes <a href="https://en.wikipedia.org/wiki/Rumor">rumors</a> look more convincing. Therefore, finding an automatic approach to verify <a href="https://en.wikipedia.org/wiki/Rumor">rumors</a> with <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia content</a> is a pressing task. Previous rumor verification research only utilizes <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia</a> as input features. We propose not to use the <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia content</a> but to find <a href="https://en.wikipedia.org/wiki/Infographic">external information</a> in other <a href="https://en.wikipedia.org/wiki/Online_newspaper">news platforms</a> pivoting on it. We introduce a new features set, cross-lingual cross-platform features that leverage the semantic similarity between the rumors and the external information. When implemented, <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning methods</a> utilizing such <a href="https://en.wikipedia.org/wiki/Feature_(machine_learning)">features</a> achieved the state-of-the-art rumor verification results.</abstract>
      <doi>10.18653/v1/D18-1385</doi>
      <bibkey>wen-etal-2018-cross</bibkey>
      <pwccode url="https://github.com/WeimingWen/CCRV" additional="true">WeimingWen/CCRV</pwccode>
    </paper>
    <paper id="386">
      <title>Extractive Adversarial Networks : High-Recall Explanations for Identifying Personal Attacks in Social Media Posts</title>
      <author><first>Samuel</first><last>Carton</last></author>
      <author><first>Qiaozhu</first><last>Mei</last></author>
      <author><first>Paul</first><last>Resnick</last></author>
      <pages>3497–3507</pages>
      <url hash="162b9140">D18-1386</url>
      <abstract>We introduce an <a href="https://en.wikipedia.org/wiki/Adversarial_system">adversarial method</a> for producing high-recall explanations of neural text classifier decisions. Building on an existing architecture for extractive explanations via hard attention, we add an adversarial layer which scans the residual of the <a href="https://en.wikipedia.org/wiki/Attention">attention</a> for remaining predictive signal. Motivated by the important domain of detecting personal attacks in social media comments, we additionally demonstrate the importance of manually setting a semantically appropriate default behavior for the model by explicitly manipulating its bias term. We develop a validation set of human-annotated personal attacks to evaluate the impact of these changes.</abstract>
      <doi>10.18653/v1/D18-1386</doi>
      <bibkey>carton-etal-2018-extractive</bibkey>
    </paper>
    <paper id="387">
      <title>Automatic Detection of Vague Words and Sentences in Privacy Policies</title>
      <author><first>Logan</first><last>Lebanoff</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>3508–3517</pages>
      <url hash="e677813f">D18-1387</url>
      <abstract>Website privacy policies represent the single most important source of information for users to gauge how their personal data are collected, used and shared by companies. However, <a href="https://en.wikipedia.org/wiki/Privacy_policy">privacy policies</a> are often vague and people struggle to understand the content. Their opaqueness poses a significant challenge to both users and policy regulators. In this paper, we seek to identify vague content in <a href="https://en.wikipedia.org/wiki/Privacy_policy">privacy policies</a>. We construct the first <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of human-annotated vague words and sentences and present empirical studies on automatic vagueness detection. In particular, we investigate context-aware and context-agnostic models for predicting vague words, and explore auxiliary-classifier generative adversarial networks for characterizing sentence vagueness. Our experimental results demonstrate the effectiveness of proposed approaches. Finally, we provide suggestions for resolving <a href="https://en.wikipedia.org/wiki/Vagueness">vagueness</a> and improving the usability of <a href="https://en.wikipedia.org/wiki/Privacy_policy">privacy policies</a>.</abstract>
      <doi>10.18653/v1/D18-1387</doi>
      <bibkey>lebanoff-liu-2018-automatic</bibkey>
    </paper>
    <paper id="388">
      <title>Multi-view Models for Political Ideology Detection of News Articles</title>
      <author><first>Vivek</first><last>Kulkarni</last></author>
      <author><first>Junting</first><last>Ye</last></author>
      <author><first>Steve</first><last>Skiena</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <pages>3518–3527</pages>
      <url hash="0c9a6481">D18-1388</url>
      <abstract>A news article’s title, content and link structure often reveal its <a href="https://en.wikipedia.org/wiki/Ideology">political ideology</a>. However, most existing works on automatic political ideology detection only leverage textual cues. Drawing inspiration from recent advances in neural inference, we propose a novel attention based multi-view model to leverage cues from all of the above views to identify the <a href="https://en.wikipedia.org/wiki/Ideology">ideology</a> evinced by a <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news article</a>. Our model draws on advances in representation learning in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> and <a href="https://en.wikipedia.org/wiki/Network_science">network science</a> to capture cues from both textual content and the network structure of <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>. We empirically evaluate our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> against a battery of baselines and show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms state of the art by 10 percentage points F1 score.</abstract>
      <doi>10.18653/v1/D18-1388</doi>
      <bibkey>kulkarni-etal-2018-multi</bibkey>
    </paper>
    <paper id="389">
      <title>Predicting Factuality of Reporting and Bias of News Media Sources</title>
      <author><first>Ramy</first><last>Baly</last></author>
      <author><first>Georgi</first><last>Karadzhov</last></author>
      <author><first>Dimitar</first><last>Alexandrov</last></author>
      <author><first>James</first><last>Glass</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>3528–3539</pages>
      <url hash="b654b880">D18-1389</url>
      <abstract>We present a study on predicting the factuality of reporting and bias of <a href="https://en.wikipedia.org/wiki/News_media">news media</a>. While previous work has focused on studying the veracity of claims or documents, here we are interested in characterizing entire <a href="https://en.wikipedia.org/wiki/News_media">news media</a>. This is an under-studied, but arguably important research problem, both in its own right and as a prior for <a href="https://en.wikipedia.org/wiki/Fact-checking">fact-checking systems</a>. We experiment with a large list of news websites and with a rich set of features derived from (i) a sample of articles from the target <a href="https://en.wikipedia.org/wiki/News_media">news media</a>, (ii) its Wikipedia page, (iii) its Twitter account, (iv) the structure of its URL, and (v) information about the Web traffic it attracts. The experimental results show sizable performance gains over the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a>, and reveal the importance of each feature type.</abstract>
      <doi>10.18653/v1/D18-1389</doi>
      <bibkey>baly-etal-2018-predicting</bibkey>
      <pwccode url="https://github.com/ramybaly/News-Media-Reliability" additional="true">ramybaly/News-Media-Reliability</pwccode>
    </paper>
    <paper id="390">
      <title>Legal Judgment Prediction via Topological Learning</title>
      <author><first>Haoxi</first><last>Zhong</last></author>
      <author><first>Zhipeng</first><last>Guo</last></author>
      <author><first>Cunchao</first><last>Tu</last></author>
      <author><first>Chaojun</first><last>Xiao</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>3540–3549</pages>
      <url hash="a9a610ee">D18-1390</url>
      <abstract>Legal Judgment Prediction (LJP) aims to predict the judgment result based on the facts of a case and becomes a promising application of artificial intelligence techniques in the <a href="https://en.wikipedia.org/wiki/Law">legal field</a>. In real-world scenarios, <a href="https://en.wikipedia.org/wiki/Legal_judgment">legal judgment</a> usually consists of multiple subtasks, such as the decisions of applicable law articles, <a href="https://en.wikipedia.org/wiki/Criminal_charge">charges</a>, <a href="https://en.wikipedia.org/wiki/Fine_(penalty)">fines</a>, and the term of penalty. Moreover, there exist topological dependencies among these subtasks. While most existing works only focus on a specific subtask of judgment prediction and ignore the dependencies among subtasks, we formalize the dependencies among subtasks as a Directed Acyclic Graph (DAG) and propose a topological multi-task learning framework, TopJudge, which incorporates multiple subtasks and DAG dependencies into judgment prediction. We conduct experiments on several real-world large-scale datasets of criminal cases in the <a href="https://en.wikipedia.org/wiki/Civil_law_(legal_system)">civil law system</a>. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves consistent and significant improvements over baselines on all judgment prediction tasks. The source code can be obtained from.<url>https://github.com/thunlp/TopJudge</url>.</abstract>
      <doi>10.18653/v1/D18-1390</doi>
      <bibkey>zhong-etal-2018-legal</bibkey>
      <pwccode url="https://github.com/thunlp/TopJudge" additional="false">thunlp/TopJudge</pwccode>
    </paper>
    <paper id="393">
      <title>Framing and Agenda-setting in Russian News : a Computational Analysis of Intricate Political Strategies<fixed-case>R</fixed-case>ussian News: a Computational Analysis of Intricate Political Strategies</title>
      <author><first>Anjalie</first><last>Field</last></author>
      <author><first>Doron</first><last>Kliger</last></author>
      <author><first>Shuly</first><last>Wintner</last></author>
      <author><first>Jennifer</first><last>Pan</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>3570–3580</pages>
      <url hash="76ca3a63">D18-1393</url>
      <attachment type="attachment" hash="75a82b13">D18-1393.Attachment.pdf</attachment>
      <abstract>Amidst growing concern over <a href="https://en.wikipedia.org/wiki/Media_manipulation">media manipulation</a>, NLP attention has focused on overt strategies like <a href="https://en.wikipedia.org/wiki/Censorship">censorship</a> and <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a>. Here, we draw on two concepts from political science literature to explore subtler strategies for government media manipulation : <a href="https://en.wikipedia.org/wiki/Agenda-setting_theory">agenda-setting</a> (selecting what topics to cover) and <a href="https://en.wikipedia.org/wiki/Framing_(social_sciences)">framing</a> (deciding how topics are covered). We analyze 13 years (100 K articles) of the <a href="https://en.wikipedia.org/wiki/List_of_newspapers_in_Russia">Russian newspaper</a> Izvestia and identify a strategy of distraction : articles mention the U.S. more frequently in the month directly following an economic downturn in Russia. We introduce embedding-based methods for cross-lingually projecting English frames to <a href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>, and discover that these articles emphasize U.S. moral failings and threats to the U.S. Our work offers new ways to identify subtle media manipulation strategies at the intersection of agenda-setting and framing.</abstract>
      <doi>10.18653/v1/D18-1393</doi>
      <bibkey>field-etal-2018-framing</bibkey>
    </paper>
    <paper id="396">
      <title>Beyond Error Propagation in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> : Characteristics of Language Also Matter</title>
      <author><first>Lijun</first><last>Wu</last></author>
      <author><first>Xu</first><last>Tan</last></author>
      <author><first>Di</first><last>He</last></author>
      <author><first>Fei</first><last>Tian</last></author>
      <author><first>Tao</first><last>Qin</last></author>
      <author><first>Jianhuang</first><last>Lai</last></author>
      <author><first>Tie-Yan</first><last>Liu</last></author>
      <pages>3602–3611</pages>
      <url hash="6ca0dc1b">D18-1396</url>
      <attachment type="attachment" hash="7d7eec46">D18-1396.Attachment.pdf</attachment>
      <abstract>Neural machine translation usually adopts autoregressive models and suffers from <a href="https://en.wikipedia.org/wiki/Exposure_bias">exposure bias</a> as well as the consequent error propagation problem. Many previous works have discussed the relationship between error propagation and the accuracy drop (i.e., the left part of the translated sentence is often better than its right part in left-to-right decoding models) problem. In this paper, we conduct a series of analyses to deeply understand this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> and get several interesting findings. (1) The role of <a href="https://en.wikipedia.org/wiki/Error_propagation">error propagation</a> on accuracy drop is overstated in the literature, although it indeed contributes to the accuracy drop problem. (2) Characteristics of a language play a more important role in causing the accuracy drop : the left part of the translation result in a <a href="https://en.wikipedia.org/wiki/Branching_(linguistics)">right-branching language</a> (e.g., English) is more likely to be more accurate than its right part, while the right part is more accurate for a <a href="https://en.wikipedia.org/wiki/Branching_(linguistics)">left-branching language</a> (e.g., Japanese). Our discoveries are confirmed on different model structures including Transformer and <a href="https://en.wikipedia.org/wiki/Radio-frequency_identification">RNN</a>, and in other sequence generation tasks such as <a href="https://en.wikipedia.org/wiki/Automatic_summarization">text summarization</a>.<i>accuracy drop</i> (i.e., the left part of the translated sentence is often better than its right part in left-to-right decoding models) problem. In this paper, we conduct a series of analyses to deeply understand this problem and get several interesting findings. (1) The role of error propagation on accuracy drop is overstated in the literature, although it indeed contributes to the accuracy drop problem. (2) Characteristics of a language play a more important role in causing the accuracy drop: the left part of the translation result in a right-branching language (e.g., English) is more likely to be more accurate than its right part, while the right part is more accurate for a left-branching language (e.g., Japanese). Our discoveries are confirmed on different model structures including Transformer and RNN, and in other sequence generation tasks such as text summarization.</abstract>
      <video href="https://vimeo.com/306146050" />
      <doi>10.18653/v1/D18-1396</doi>
      <bibkey>wu-etal-2018-beyond</bibkey>
    </paper>
    <paper id="398">
      <title>Meta-Learning for Low-Resource Neural Machine Translation</title>
      <author><first>Jiatao</first><last>Gu</last></author>
      <author><first>Yong</first><last>Wang</last></author>
      <author><first>Yun</first><last>Chen</last></author>
      <author><first>Victor O. K.</first><last>Li</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>3622–3631</pages>
      <url hash="d89d9237">D18-1398</url>
      <abstract>In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML, Finn, et al., 2017) for low-resource neural machine translation (NMT). We frame low-resource translation as a meta-learning problem where we learn to adapt to low-resource languages based on multilingual high-resource language tasks. We use the universal lexical representation (Gu et al., 2018b) to overcome the input-output mismatch across different languages. We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro, Lv, Fi, Tr and Ko) as target tasks. We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach (Zoph et al., 2016) and enables us to train a competitive NMT system with only a fraction of training examples. For instance, the proposed approach can achieve as high as 22.04 <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> on Romanian-English WMT’16 by seeing only 16,000 translated words (~600 parallel sentences)</abstract>
      <video href="https://vimeo.com/306147573" />
      <doi>10.18653/v1/D18-1398</doi>
      <bibkey>gu-etal-2018-meta</bibkey>
    </paper>
    <paper id="400">
      <title>A Visual Attention Grounding Neural Model for Multimodal Machine Translation</title>
      <author><first>Mingyang</first><last>Zhou</last></author>
      <author><first>Runxiang</first><last>Cheng</last></author>
      <author><first>Yong Jae</first><last>Lee</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>3643–3653</pages>
      <url hash="fd10c087">D18-1400</url>
      <attachment type="attachment" hash="12f0f17f">D18-1400.Attachment.zip</attachment>
      <abstract>We introduce a novel multimodal machine translation model that utilizes parallel visual and textual information. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> jointly optimizes the learning of a shared visual-language embedding and a <a href="https://en.wikipedia.org/wiki/Translation">translator</a>. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> leverages a visual attention grounding mechanism that links the visual semantics with the corresponding textual semantics. Our approach achieves competitive state-of-the-art results on the Multi30 K and the Ambiguous COCO datasets. We also collected a new multilingual multimodal product description dataset to simulate a real-world international online shopping scenario. On this <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>, our visual attention grounding model outperforms other <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> by a large margin.</abstract>
      <video href="https://vimeo.com/306149028" />
      <doi>10.18653/v1/D18-1400</doi>
      <bibkey>zhou-etal-2018-visual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="404">
      <title>CARER : Contextualized Affect Representations for Emotion Recognition<fixed-case>CARER</fixed-case>: Contextualized Affect Representations for Emotion Recognition</title>
      <author><first>Elvis</first><last>Saravia</last></author>
      <author><first>Hsien-Chi Toby</first><last>Liu</last></author>
      <author><first>Yen-Hao</first><last>Huang</last></author>
      <author><first>Junlin</first><last>Wu</last></author>
      <author><first>Yi-Shin</first><last>Chen</last></author>
      <pages>3687–3697</pages>
      <url hash="0ccb3f31">D18-1404</url>
      <attachment type="attachment" hash="0e3c611d">D18-1404.Attachment.zip</attachment>
      <abstract>Emotions are expressed in nuanced ways, which varies by collective or individual experiences, knowledge, and beliefs. Therefore, to understand <a href="https://en.wikipedia.org/wiki/Emotion">emotion</a>, as conveyed through text, a robust mechanism capable of capturing and modeling different linguistic nuances and phenomena is needed. We propose a semi-supervised, graph-based algorithm to produce rich structural descriptors which serve as the building blocks for constructing contextualized affect representations from text. The <a href="https://en.wikipedia.org/wiki/Pattern_recognition">pattern-based representations</a> are further enriched with <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> and evaluated through several <a href="https://en.wikipedia.org/wiki/Emotion_recognition">emotion recognition tasks</a>. Our experimental results demonstrate that the proposed method outperforms state-of-the-art techniques on emotion recognition tasks.</abstract>
      <video href="https://vimeo.com/306129121" />
      <doi>10.18653/v1/D18-1404</doi>
      <bibkey>saravia-etal-2018-carer</bibkey>
      <pwccode url="https://github.com/dair-ai/emotion_dataset" additional="false">dair-ai/emotion_dataset</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/emotion">CARER</pwcdataset>
    </paper>
    <paper id="405">
      <title>Noise Contrastive Estimation and Negative Sampling for Conditional Models : Consistency and Statistical Efficiency</title>
      <author><first>Zhuang</first><last>Ma</last></author>
      <author><first>Michael</first><last>Collins</last></author>
      <pages>3698–3707</pages>
      <url hash="dfabf192">D18-1405</url>
      <attachment type="attachment" hash="4f84098c">D18-1405.Attachment.pdf</attachment>
      <abstract>Noise Contrastive Estimation (NCE) is a powerful parameter estimation method for log-linear models, which avoids calculation of the partition function or its derivatives at each training step, a computationally demanding step in many cases. It is closely related to negative sampling methods, now widely used in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. This paper considers NCE-based estimation of conditional models. Conditional models are frequently encountered in practice ; however there has not been a rigorous theoretical analysis of NCE in this setting, and we will argue there are subtle but important questions when generalizing NCE to the conditional case. In particular, we analyze two variants of NCE for conditional models : one based on a <a href="https://en.wikipedia.org/wiki/Loss_function">classification objective</a>, the other based on a <a href="https://en.wikipedia.org/wiki/Loss_function">ranking objective</a>. We show that the ranking-based variant of NCE gives consistent parameter estimates under weaker assumptions than the classification-based method ; we analyze the statistical efficiency of the ranking-based and classification-based variants of NCE ; finally we describe experiments on synthetic data and language modeling showing the effectiveness and tradeoffs of both methods.</abstract>
      <video href="https://vimeo.com/306156327" />
      <doi>10.18653/v1/D18-1405</doi>
      <bibkey>ma-collins-2018-noise</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="406">
      <title>CaLcs : Continuously Approximating Longest Common Subsequence for Sequence Level Optimization<fixed-case>C</fixed-case>a<fixed-case>L</fixed-case>cs: Continuously Approximating Longest Common Subsequence for Sequence Level Optimization</title>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Chung-Cheng</first><last>Chiu</last></author>
      <author><first>Patrick</first><last>Nguyen</last></author>
      <author><first>Yonghui</first><last>Wu</last></author>
      <pages>3708–3718</pages>
      <url hash="ff8921a6">D18-1406</url>
      <abstract>Maximum-likelihood estimation (MLE) is one of the most widely used approaches for training structured prediction models for text-generation based natural language processing applications. However, besides <a href="https://en.wikipedia.org/wiki/Exposure_bias">exposure bias</a>, models trained with MLE suffer from wrong objective problem where they are trained to maximize the word-level correct next step prediction, but are evaluated with respect to sequence-level discrete metrics such as ROUGE and <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>. Several variants of policy-gradient methods address some of these problems by optimizing for final discrete evaluation metrics and showing improvements over MLE training for downstream tasks like <a href="https://en.wikipedia.org/wiki/Automatic_summarization">text summarization</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. However, policy-gradient methods suffers from high <a href="https://en.wikipedia.org/wiki/Variance">sample variance</a>, making the <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training process</a> very difficult and unstable. In this paper, we present an alternative direction towards mitigating this problem by introducing a new objective (CaLcs) based on a differentiable surrogate of longest common subsequence (LCS) measure that captures sequence-level structure similarity. Experimental results on abstractive summarization and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> validate the effectiveness of the proposed approach.</abstract>
      <video href="https://vimeo.com/306157322" />
      <doi>10.18653/v1/D18-1406</doi>
      <bibkey>yavuz-etal-2018-calcs</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="408">
      <title>Phrase-level Self-Attention Networks for Universal Sentence Encoding</title>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Houfeng</first><last>Wang</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Shuming</first><last>Ma</last></author>
      <pages>3729–3738</pages>
      <url hash="70e81b7d">D18-1408</url>
      <abstract>Universal sentence encoding is a hot topic in recent <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP research</a>. Attention mechanism has been an integral part in many sentence encoding models, allowing the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> to capture context dependencies regardless of the distance between the elements in the sequence. Fully attention-based models have recently attracted enormous interest due to their highly <a href="https://en.wikipedia.org/wiki/Parallel_computing">parallelizable computation</a> and significantly less <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">training time</a>. However, the <a href="https://en.wikipedia.org/wiki/Memory">memory consumption</a> of their models grows quadratically with the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence length</a>, and the <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a> is neglected. To this end, we propose Phrase-level Self-Attention Networks (PSAN) that perform self-attention across words inside a phrase to capture context dependencies at the phrase level, and use the gated memory updating mechanism to refine each word’s representation hierarchically with longer-term context dependencies captured in a larger phrase. As a result, the memory consumption can be reduced because the self-attention is performed at the <a href="https://en.wikipedia.org/wiki/Phrase">phrase level</a> instead of the <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence level</a>. At the same time, <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a> can be easily integrated in the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. Experiment results show that PSAN can achieve the state-of-the-art performance across a plethora of NLP tasks including binary and multi-class classification, natural language inference and sentence similarity.</abstract>
      <video href="https://vimeo.com/306159624" />
      <doi>10.18653/v1/D18-1408</doi>
      <bibkey>wu-etal-2018-phrase</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="409">
      <title>BanditSum : Extractive Summarization as a Contextual Bandit<fixed-case>B</fixed-case>andit<fixed-case>S</fixed-case>um: Extractive Summarization as a Contextual Bandit</title>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Yikang</first><last>Shen</last></author>
      <author><first>Eric</first><last>Crawford</last></author>
      <author><first>Herke</first><last>van Hoof</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>3739–3748</pages>
      <url hash="8201e19d">D18-1409</url>
      <attachment type="attachment" hash="190e9519">D18-1409.Attachment.pdf</attachment>
      <abstract>In this work, we propose a novel method for training <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> to perform single-document extractive summarization without heuristically-generated extractive labels. We call our approach BanditSum as it treats extractive summarization as a contextual bandit (CB) problem, where the model receives a document to summarize (the context), and chooses a sequence of sentences to include in the summary (the action). A policy gradient reinforcement learning algorithm is used to train the model to select sequences of sentences that maximize ROUGE score. We perform a series of experiments demonstrating that BanditSum is able to achieve ROUGE scores that are better than or comparable to the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art</a> for extractive summarization, and converges using significantly fewer update steps than competing approaches. In addition, we show empirically that BanditSum performs significantly better than competing approaches when good summary sentences appear late in the source document.</abstract>
      <video href="https://vimeo.com/306160623" />
      <doi>10.18653/v1/D18-1409</doi>
      <bibkey>dong-etal-2018-banditsum</bibkey>
      <pwccode url="https://github.com/yuedongP/BanditSum" additional="false">yuedongP/BanditSum</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="410">
      <title>A Word-Complexity Lexicon and A Neural Readability Ranking Model for Lexical Simplification</title>
      <author><first>Mounica</first><last>Maddela</last></author>
      <author><first>Wei</first><last>Xu</last></author>
      <pages>3749–3760</pages>
      <url hash="67f62b0c">D18-1410</url>
      <abstract>Current lexical simplification approaches rely heavily on <a href="https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making">heuristics</a> and corpus level features that do not always align with <a href="https://en.wikipedia.org/wiki/Judgement">human judgment</a>. We create a human-rated word-complexity lexicon of 15,000 English words and propose a novel neural readability ranking model with a Gaussian-based feature vectorization layer that utilizes these human ratings to measure the complexity of any given word or phrase. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs better than the state-of-the-art systems for different lexical simplification tasks and evaluation datasets. Additionally, we also produce SimplePPDB++, a lexical resource of over 10 million simplifying paraphrase rules, by applying our model to the Paraphrase Database (PPDB).</abstract>
      <video href="https://vimeo.com/306116474" />
      <doi>10.18653/v1/D18-1410</doi>
      <bibkey>maddela-xu-2018-word</bibkey>
      <pwccode url="https://github.com/mounicam/lexical_simplification" additional="false">mounicam/lexical_simplification</pwccode>
    </paper>
    <paper id="412">
      <title>Syntactic Scaffolds for Semantic Structures</title>
      <author><first>Swabha</first><last>Swayamdipta</last></author>
      <author><first>Sam</first><last>Thomson</last></author>
      <author><first>Kenton</first><last>Lee</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Chris</first><last>Dyer</last></author>
      <author><first>Noah A.</first><last>Smith</last></author>
      <pages>3772–3782</pages>
      <url hash="f1038a53">D18-1412</url>
      <attachment type="attachment" hash="a8278c60">D18-1412.Attachment.zip</attachment>
      <abstract>We introduce the syntactic scaffold, an approach to incorporating <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a> into <a href="https://en.wikipedia.org/wiki/Semantics">semantic tasks</a>. Syntactic scaffolds avoid expensive syntactic processing at runtime, only making use of a <a href="https://en.wikipedia.org/wiki/Treebank">treebank</a> during training, through a multitask objective. We improve over strong baselines on PropBank semantics, frame semantics, and <a href="https://en.wikipedia.org/wiki/Coreference_resolution">coreference resolution</a>, achieving competitive performance on all three tasks.</abstract>
      <video href="https://vimeo.com/306118515" />
      <doi>10.18653/v1/D18-1412</doi>
      <bibkey>swayamdipta-etal-2018-syntactic</bibkey>
      <pwccode url="https://github.com/swabhs/scaffolding" additional="false">swabhs/scaffolding</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="414">
      <title>Semantic Role Labeling for Learner Chinese : the Importance of Syntactic Parsing and L2-L1 Parallel Data<fixed-case>C</fixed-case>hinese: the Importance of Syntactic Parsing and <fixed-case>L</fixed-case>2-<fixed-case>L</fixed-case>1 Parallel Data</title>
      <author><first>Zi</first><last>Lin</last></author>
      <author><first>Yuguang</first><last>Duan</last></author>
      <author><first>Yuanyuan</first><last>Zhao</last></author>
      <author><first>Weiwei</first><last>Sun</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>3793–3802</pages>
      <url hash="c4999b6a">D18-1414</url>
      <abstract>This paper studies <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> for interlanguage (L2), taking semantic role labeling (SRL) as a case task and learner Chinese as a case language. We first manually annotate the semantic roles for a set of learner texts to derive a gold standard for automatic SRL. Based on the new data, we then evaluate three off-the-shelf SRL systems, i.e., the PCFGLA-parser-based, neural-parser-based and neural-syntax-agnostic systems, to gauge how successful SRL for learner Chinese can be. We find two non-obvious facts : 1) the L1-sentence-trained systems performs rather badly on the L2 data ; 2) the performance drop from the L1 data to the L2 data of the two parser-based systems is much smaller, indicating the importance of syntactic parsing in SRL for interlanguages. Finally, the paper introduces a new agreement-based model to explore the semantic coherency information in the large-scale L2-L1 parallel data. We then show such information is very effective to enhance SRL for learner texts. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves an <a href="https://en.wikipedia.org/wiki/F-score">F-score</a> of 72.06, which is a 2.02 point improvement over the best <a href="https://en.wikipedia.org/wiki/Baseline_(medicine)">baseline</a>.</abstract>
      <video href="https://vimeo.com/306119942" />
      <doi>10.18653/v1/D18-1414</doi>
      <bibkey>lin-etal-2018-semantic</bibkey>
      <pwccode url="https://github.com/pkucoli/srl4il" additional="false">pkucoli/srl4il</pwccode>
    </paper>
    <paper id="417">
      <title>A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding</title>
      <author><first>Changliang</first><last>Li</last></author>
      <author><first>Liang</first><last>Li</last></author>
      <author><first>Ji</first><last>Qi</last></author>
      <pages>3824–3833</pages>
      <url hash="d9fbc855">D18-1417</url>
      <abstract>Spoken Language Understanding (SLU), which typically involves intent determination and slot filling, is a core component of spoken dialogue systems. Joint learning has shown to be effective in SLU given that slot tags and intents are supposed to share knowledge with each other. However, most existing joint learning methods only consider joint learning by sharing parameters on surface level rather than semantic level. In this work, we propose a novel self-attentive model with gate mechanism to fully utilize the semantic correlation between slot and <a href="https://en.wikipedia.org/wiki/Intention">intent</a>. Our model first obtains intent-augmented embeddings based on <a href="https://en.wikipedia.org/wiki/Neural_network">neural network</a> with self-attention mechanism. And then the intent semantic representation is utilized as the gate for labelling slot tags. The objectives of both <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> are optimized simultaneously via joint learning in an end-to-end way. We conduct experiment on popular benchmark ATIS. The results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieves state-of-the-art and outperforms other popular methods by a large margin in terms of both intent detection error rate and slot filling F1-score. This paper gives a new perspective for research on SLU.</abstract>
      <doi>10.18653/v1/D18-1417</doi>
      <bibkey>li-etal-2018-self</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/atis">ATIS</pwcdataset>
    </paper>
    <paper id="418">
      <title>Learning End-to-End Goal-Oriented Dialog with Multiple Answers</title>
      <author><first>Janarthanan</first><last>Rajendran</last></author>
      <author><first>Jatin</first><last>Ganhotra</last></author>
      <author><first>Satinder</first><last>Singh</last></author>
      <author><first>Lazaros</first><last>Polymenakos</last></author>
      <pages>3834–3843</pages>
      <url hash="9d6b3da9">D18-1418</url>
      <abstract>In a <a href="https://en.wikipedia.org/wiki/Dialogue">dialog</a>, there could be multiple valid next utterances at any point. The present end-to-end neural methods for <a href="https://en.wikipedia.org/wiki/Dialog_(software)">dialog</a> do not take this into account. They learn with the assumption that at any time there is only one correct next utterance. In this work, we focus on this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a> in the goal-oriented dialog setting where there are different paths to reach a goal. We propose a new method, that uses a combination of supervised learning and reinforcement learning approaches to address this issue. We also propose a new and more effective <a href="https://en.wikipedia.org/wiki/Testbed">testbed</a>, permuted-bAbI dialog tasks, by introducing multiple valid next utterances to the original-bAbI dialog tasks, which allows evaluation of end-to-end goal-oriented dialog systems in a more realistic setting. We show that there is a significant drop in performance of existing <a href="https://en.wikipedia.org/wiki/End-to-end_principle">end-to-end neural methods</a> from 81.5 % per-dialog accuracy on original-bAbI dialog tasks to 30.3 % on permuted-bAbI dialog tasks. We also show that our proposed <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">method</a> improves the performance and achieves 47.3 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">per-dialog accuracy</a> on permuted-bAbI dialog tasks. We also release permuted-bAbI dialog tasks, our proposed testbed, to the community for evaluating dialog systems in a goal-oriented setting.</abstract>
      <doi>10.18653/v1/D18-1418</doi>
      <bibkey>rajendran-etal-2018-learning</bibkey>
      <pwccode url="https://github.com/IBM/permuted-bAbI-dialog-tasks" additional="false">IBM/permuted-bAbI-dialog-tasks</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/permuted-babi-dialog-task">Permuted bAbI dialog task</pwcdataset>
    </paper>
    <paper id="420">
      <title>QuaSE : Sequence Editing under Quantifiable Guidance<fixed-case>Q</fixed-case>ua<fixed-case>SE</fixed-case>: Sequence Editing under Quantifiable Guidance</title>
      <author><first>Yi</first><last>Liao</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Piji</first><last>Li</last></author>
      <author><first>Shuming</first><last>Shi</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <author><first>Tong</first><last>Zhang</last></author>
      <pages>3855–3864</pages>
      <url hash="af754825">D18-1420</url>
      <abstract>We propose the task of Quantifiable Sequence Editing (QuaSE): editing an input sequence to generate an output sequence that satisfies a given numerical outcome value measuring a certain property of the sequence, with the requirement of keeping the main content of the input sequence. For example, an input sequence could be a word sequence, such as review sentence and <a href="https://en.wikipedia.org/wiki/Advertising">advertisement text</a>. For a review sentence, the outcome could be the review rating ; for an <a href="https://en.wikipedia.org/wiki/Advertising">advertisement</a>, the outcome could be the <a href="https://en.wikipedia.org/wiki/Click-through_rate">click-through rate</a>. The major challenge in performing QuaSE is how to perceive the outcome-related wordings, and only edit them to change the outcome. In this paper, the proposed framework contains two latent factors, namely, outcome factor and content factor, disentangled from the input sentence to allow convenient editing to change the outcome and keep the content. Our framework explores the pseudo-parallel sentences by modeling their content similarity and outcome differences to enable a better disentanglement of the latent factors, which allows generating an output to better satisfy the desired outcome and keep the content. The dual reconstruction structure further enhances the capability of generating expected output by exploiting the couplings of latent factors of pseudo-parallel sentences. For evaluation, we prepared a dataset of Yelp review sentences with the ratings as outcome. Extensive experimental results are reported and discussed to elaborate the peculiarities of our <a href="https://en.wikipedia.org/wiki/Conceptual_framework">framework</a>.</abstract>
      <doi>10.18653/v1/D18-1420</doi>
      <bibkey>liao-etal-2018-quase</bibkey>
      <pwccode url="https://bitbucket.org/leoeaton/quase" additional="false">leoeaton/quase</pwccode>
    </paper>
    <paper id="421">
      <title>Paraphrase Generation with Deep Reinforcement Learning</title>
      <author><first>Zichao</first><last>Li</last></author>
      <author><first>Xin</first><last>Jiang</last></author>
      <author><first>Lifeng</first><last>Shang</last></author>
      <author><first>Hang</first><last>Li</last></author>
      <pages>3865–3878</pages>
      <url hash="3e04ac6a">D18-1421</url>
      <abstract>Automatic generation of paraphrases from a given sentence is an important yet challenging task in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing (NLP)</a>. In this paper, we present a deep reinforcement learning approach to <a href="https://en.wikipedia.org/wiki/Paraphrase_generation">paraphrase generation</a>. Specifically, we propose a new <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for the <a href="https://en.wikipedia.org/wiki/Task_(computing)">task</a>, which consists of a <a href="https://en.wikipedia.org/wiki/Generator_(computer_programming)">generator</a> and an evaluator, both of which are learned from data. The <a href="https://en.wikipedia.org/wiki/Generator_(mathematics)">generator</a>, built as a sequence-to-sequence learning model, can produce <a href="https://en.wikipedia.org/wiki/Paraphrase">paraphrases</a> given a sentence. The evaluator, constructed as a deep matching model, can judge whether two sentences are paraphrases of each other. The generator is first trained by <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> and then further fine-tuned by <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">reinforcement learning</a> in which the reward is given by the evaluator. For the learning of the evaluator, we propose two methods based on <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a> and <a href="https://en.wikipedia.org/wiki/Inverse_reinforcement_learning">inverse reinforcement learning</a> respectively, depending on the type of available training data. Experimental results on two datasets demonstrate the proposed models (the generators) can produce more accurate paraphrases and outperform the state-of-the-art methods in <a href="https://en.wikipedia.org/wiki/Paraphrase_generation">paraphrase generation</a> in both automatic evaluation and human evaluation.</abstract>
      <doi>10.18653/v1/D18-1421</doi>
      <bibkey>li-etal-2018-paraphrase</bibkey>
    </paper>
    <paper id="422">
      <title>Operation-guided Neural Networks for High Fidelity Data-To-Text Generation</title>
      <author><first>Feng</first><last>Nie</last></author>
      <author><first>Jinpeng</first><last>Wang</last></author>
      <author><first>Jin-Ge</first><last>Yao</last></author>
      <author><first>Rong</first><last>Pan</last></author>
      <author><first>Chin-Yew</first><last>Lin</last></author>
      <pages>3879–3889</pages>
      <url hash="94f588fb">D18-1422</url>
      <abstract>Recent neural models for data-to-text generation are mostly based on data-driven end-to-end training over encoder-decoder networks. Even though the generated texts are mostly fluent and informative, they often generate descriptions that are not consistent with the input structured data. This is a critical issue especially in domains that require <a href="https://en.wikipedia.org/wiki/Inference">inference</a> or calculations over <a href="https://en.wikipedia.org/wiki/Raw_data">raw data</a>. In this paper, we attempt to improve the <a href="https://en.wikipedia.org/wiki/Fidelity">fidelity</a> of neural data-to-text generation by utilizing pre-executed symbolic operations. We propose a framework called Operation-guided Attention-based sequence-to-sequence network (OpAtt), with a specifically designed gating mechanism as well as a quantization module for operation results to utilize information from pre-executed operations. Experiments on two sports datasets show our proposed method clearly improves the <a href="https://en.wikipedia.org/wiki/Fidelity">fidelity</a> of the generated texts to the input structured data.</abstract>
      <doi>10.18653/v1/D18-1422</doi>
      <bibkey>nie-etal-2018-operation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rotowire">RotoWire</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikibio">WikiBio</pwcdataset>
    </paper>
    <paper id="424">
      <title>Paragraph-level Neural Question Generation with Maxout Pointer and Gated Self-attention Networks</title>
      <author><first>Yao</first><last>Zhao</last></author>
      <author><first>Xiaochuan</first><last>Ni</last></author>
      <author><first>Yuanyuan</first><last>Ding</last></author>
      <author><first>Qifa</first><last>Ke</last></author>
      <pages>3901–3910</pages>
      <url hash="ef604f38">D18-1424</url>
      <abstract>Question generation, the task of automatically creating questions that can be answered by a certain span of text within a given passage, is important for question-answering and conversational systems in digital assistants such as <a href="https://en.wikipedia.org/wiki/Amazon_Alexa">Alexa</a>, <a href="https://en.wikipedia.org/wiki/Cortana">Cortana</a>, <a href="https://en.wikipedia.org/wiki/Google_Assistant">Google Assistant</a> and <a href="https://en.wikipedia.org/wiki/Siri">Siri</a>. Recent sequence to sequence neural models have outperformed previous <a href="https://en.wikipedia.org/wiki/Rule-based_system">rule-based systems</a>. Existing <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> mainly focused on using one or two sentences as the input. Long text has posed challenges for sequence to sequence neural models in question generation   worse performances were reported if using the whole paragraph (with multiple sentences) as the input. In reality, however, it often requires the whole paragraph as context in order to generate high quality questions. In this paper, we propose a maxout pointer mechanism with gated self-attention encoder to address the challenges of processing long text inputs for question generation. With sentence-level inputs, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms previous approaches with either sentence-level or paragraph-level inputs. Furthermore, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can effectively utilize paragraphs as inputs, pushing the state-of-the-art result from 13.9 to 16.3 (BLEU_4).</abstract>
      <doi>10.18653/v1/D18-1424</doi>
      <bibkey>zhao-etal-2018-paragraph</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="426">
      <title>Unsupervised Natural Language Generation with Denoising Autoencoders</title>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>Scott</first><last>Roy</last></author>
      <pages>3922–3929</pages>
      <url hash="cace9b7c">D18-1426</url>
      <abstract>Generating text from <a href="https://en.wikipedia.org/wiki/Structured_data">structured data</a> is important for various tasks such as <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a> and dialog systems. We show that in at least one domain, without any supervision and only based on unlabeled text, we are able to build a Natural Language Generation (NLG) system with higher performance than supervised approaches. In our approach, we interpret the structured data as a corrupt representation of the desired output and use a denoising auto-encoder to reconstruct the sentence. We show how to introduce <a href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> into training examples that do not contain <a href="https://en.wikipedia.org/wiki/Structured_data">structured data</a>, and that the resulting denoising auto-encoder generalizes to generate correct sentences when given <a href="https://en.wikipedia.org/wiki/Structured_data">structured data</a>.</abstract>
      <doi>10.18653/v1/D18-1426</doi>
      <bibkey>freitag-roy-2018-unsupervised</bibkey>
    </paper>
    <paper id="427">
      <title>Answer-focused and Position-aware Neural Question Generation</title>
      <author><first>Xingwu</first><last>Sun</last></author>
      <author><first>Jing</first><last>Liu</last></author>
      <author><first>Yajuan</first><last>Lyu</last></author>
      <author><first>Wei</first><last>He</last></author>
      <author><first>Yanjun</first><last>Ma</last></author>
      <author><first>Shi</first><last>Wang</last></author>
      <pages>3930–3939</pages>
      <url hash="a5cb6721">D18-1427</url>
      <attachment type="attachment" hash="e95b15cc">D18-1427.Attachment.zip</attachment>
      <abstract>In this paper, we focus on the problem of question generation (QG). Recent neural network-based approaches employ the sequence-to-sequence model which takes an answer and its context as input and generates a relevant question as output. However, we observe two major issues with these approaches : (1) The generated interrogative words (or question words) do not match the answer type. (2) The model copies the context words that are far from and irrelevant to the answer, instead of the words that are close and relevant to the answer. To address these two issues, we propose an answer-focused and position-aware neural question generation model. (1) By answer-focused, we mean that we explicitly model question word generation by incorporating the answer embedding, which can help generate an interrogative word matching the answer type. (2) By position-aware, we mean that we model the relative distance between the context words and the answer. Hence the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can be aware of the position of the context words when copying them to generate a question. We conduct extensive experiments to examine the effectiveness of our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>. The experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> significantly improves the <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baseline</a> and outperforms the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-the-art system</a>.</abstract>
      <doi>10.18653/v1/D18-1427</doi>
      <bibkey>sun-etal-2018-answer</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="429">
      <title>Towards a Better Metric for Evaluating Question Generation Systems</title>
      <author><first>Preksha</first><last>Nema</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <pages>3950–3959</pages>
      <url hash="927b3062">D18-1429</url>
      <abstract>There has always been criticism for using n-gram based similarity metrics, such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, <a href="https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology">NIST</a>, etc, for evaluating the performance of NLG systems. However, these <a href="https://en.wikipedia.org/wiki/Performance_metric">metrics</a> continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from <a href="https://en.wikipedia.org/wiki/Document">documents</a>, <a href="https://en.wikipedia.org/wiki/Knowledge_graph">knowledge graphs</a>, <a href="https://en.wikipedia.org/wiki/Image">images</a>, etc. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on answerability of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, etc. In this work, we show that current automatic evaluation metrics based on n-gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability and show that when this scoring function is integrated with existing <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a>, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available.<tex-math>n</tex-math>-gram based similarity metrics, such as BLEU, NIST, <i>etc</i>, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, <i>etc</i>. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on <i>answerability</i> of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, <i>etc</i>. In this work, we show that current automatic evaluation metrics based on <tex-math>n</tex-math>-gram similarity do not always correlate well with human judgments about <i>answerability</i> of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture <i>answerability</i> and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available.</abstract>
      <doi>10.18653/v1/D18-1429</doi>
      <bibkey>nema-khapra-2018-towards</bibkey>
      <pwccode url="https://github.com/PrekshaNema25/Answerability-Metric" additional="false">PrekshaNema25/Answerability-Metric</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikimovies">WikiMovies</pwcdataset>
    </paper>
    <paper id="430">
      <title>Stylistic Chinese Poetry Generation via Unsupervised Style Disentanglement<fixed-case>C</fixed-case>hinese Poetry Generation via Unsupervised Style Disentanglement</title>
      <author><first>Cheng</first><last>Yang</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Xiaoyuan</first><last>Yi</last></author>
      <author><first>Wenhao</first><last>Li</last></author>
      <pages>3960–3969</pages>
      <url hash="984e84cf">D18-1430</url>
      <attachment type="attachment" hash="4fdb6e89">D18-1430.Attachment.txt</attachment>
      <abstract>The ability to write diverse poems in different styles under the same poetic imagery is an important characteristic of human poetry writing. Most previous works on automatic Chinese poetry generation focused on improving the coherency among lines. Some work explored <a href="https://en.wikipedia.org/wiki/Style_(visual_arts)">style transfer</a> but suffered from expensive expert labeling of poem styles. In this paper, we target on stylistic poetry generation in a fully unsupervised manner for the first time. We propose a novel model which requires no supervised style labeling by incorporating <a href="https://en.wikipedia.org/wiki/Mutual_information">mutual information</a>, a concept in <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a>, into modeling. Experimental results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is able to generate stylistic poems without losing fluency and <a href="https://en.wikipedia.org/wiki/Coherence_(linguistics)">coherency</a>.</abstract>
      <doi>10.18653/v1/D18-1430</doi>
      <bibkey>yang-etal-2018-stylistic</bibkey>
    </paper>
    <paper id="431">
      <title>Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints</title>
      <author><first>Ashutosh</first><last>Baheti</last></author>
      <author><first>Alan</first><last>Ritter</last></author>
      <author><first>Jiwei</first><last>Li</last></author>
      <author><first>Bill</first><last>Dolan</last></author>
      <pages>3970–3980</pages>
      <url hash="e53a61f6">D18-1431</url>
      <abstract>Neural conversation models tend to generate safe, generic responses for most inputs. This is due to the limitations of likelihood-based decoding objectives in generation tasks with diverse outputs, such as <a href="https://en.wikipedia.org/wiki/Conversation">conversation</a>. To address this challenge, we propose a simple yet effective approach for incorporating side information in the form of <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">distributional constraints</a> over the generated responses. We propose two constraints that help generate more content rich responses that are based on a model of syntax and topics (Griffiths et al., 2005) and semantic similarity (Arora et al., 2016). We evaluate our approach against a variety of competitive baselines, using both automatic metrics and human judgments, showing that our proposed approach generates responses that are much less generic without sacrificing plausibility. A working demo of our code can be found at.<url>https://github.com/abaheti95/DC-NeuralConversation</url>.</abstract>
      <doi>10.18653/v1/D18-1431</doi>
      <bibkey>baheti-etal-2018-generating</bibkey>
      <pwccode url="https://github.com/abaheti95/DC-NeuralConversation" additional="true">abaheti95/DC-NeuralConversation</pwccode>
    </paper>
    <paper id="434">
      <title>Multimodal Differential Network for Visual Question Generation</title>
      <author><first>Badri Narayana</first><last>Patro</last></author>
      <author><first>Sandeep</first><last>Kumar</last></author>
      <author><first>Vinod Kumar</first><last>Kurmi</last></author>
      <author><first>Vinay</first><last>Namboodiri</last></author>
      <pages>4002–4012</pages>
      <url hash="41ae8bed">D18-1434</url>
      <attachment type="attachment" hash="40a8ed9b">D18-1434.Attachment.zip</attachment>
      <abstract>Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely <a href="https://en.wikipedia.org/wiki/Location">places</a>, <a href="https://en.wikipedia.org/wiki/Photo_caption">captions</a>, and <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">tags</a>. In this paper, we propose the use of <a href="https://en.wikipedia.org/wiki/Exemplar_(textual_criticism)">exemplars</a> for obtaining the relevant context. We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU, <a href="https://en.wikipedia.org/wiki/METEOR">METEOR</a>, ROUGE, and CIDEr).</abstract>
      <doi>10.18653/v1/D18-1434</doi>
      <bibkey>patro-etal-2018-multimodal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/vqg">VQG</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/visual-question-answering">Visual Question Answering</pwcdataset>
    </paper>
    <paper id="435">
      <title>Entity-aware Image Caption Generation</title>
      <author><first>Di</first><last>Lu</last></author>
      <author><first>Spencer</first><last>Whitehead</last></author>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Shih-Fu</first><last>Chang</last></author>
      <pages>4013–4023</pages>
      <url hash="7d35d96a">D18-1435</url>
      <abstract>Current image captioning approaches generate descriptions which lack specific information, such as <a href="https://en.wikipedia.org/wiki/Named_entity">named entities</a> that are involved in the <a href="https://en.wikipedia.org/wiki/Image">images</a>. In this paper we propose a new task which aims to generate informative image captions, given <a href="https://en.wikipedia.org/wiki/Image">images</a> and <a href="https://en.wikipedia.org/wiki/Hashtag">hashtags</a> as input. We propose a simple but effective <a href="https://en.wikipedia.org/wiki/Scientific_method">approach</a> to tackle this <a href="https://en.wikipedia.org/wiki/Problem_solving">problem</a>. We first train a convolutional neural networks-long short term memory networks (CNN-LSTM) model to generate a template caption based on the input image. Then we use a knowledge graph based collective inference algorithm to fill in the template with specific named entities retrieved via the hashtags. Experiments on a new benchmark dataset collected from <a href="https://en.wikipedia.org/wiki/Flickr">Flickr</a> show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> generates news-style image descriptions with much richer information. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms <a href="https://en.wikipedia.org/wiki/Unimodality">unimodal baselines</a> significantly with various evaluation metrics.</abstract>
      <doi>10.18653/v1/D18-1435</doi>
      <bibkey>lu-etal-2018-entity</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
    </paper>
    <paper id="436">
      <title>Learning to Describe Differences Between Pairs of Similar Images</title>
      <author><first>Harsh</first><last>Jhamtani</last></author>
      <author><first>Taylor</first><last>Berg-Kirkpatrick</last></author>
      <pages>4024–4034</pages>
      <url hash="47740e34">D18-1436</url>
      <abstract>In this paper, we introduce the task of automatically generating text to describe the differences between two similar images. We collect a new <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> by crowd-sourcing difference descriptions for pairs of <a href="https://en.wikipedia.org/wiki/Film_frame">image frames</a> extracted from <a href="https://en.wikipedia.org/wiki/Closed-circuit_television">video-surveillance footage</a>. Annotators were asked to succinctly describe all the differences in a short paragraph. As a result, our novel <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> provides an opportunity to explore <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that align language and <a href="https://en.wikipedia.org/wiki/Visual_perception">vision</a>, and capture <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">visual salience</a>. The <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> may also be a useful benchmark for coherent multi-sentence generation. We perform a first-pass visual analysis that exposes clusters of differing pixels as a proxy for object-level differences. We propose a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that captures visual salience by using a <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a> to align clusters of differing pixels with output sentences. We find that, for both single-sentence generation and as well as multi-sentence generation, the proposed model outperforms the models that use <a href="https://en.wikipedia.org/wiki/Attention">attention</a> alone.</abstract>
      <doi>10.18653/v1/D18-1436</doi>
      <bibkey>jhamtani-berg-kirkpatrick-2018-learning</bibkey>
      <pwccode url="https://github.com/harsh19/spot-the-diff" additional="false">harsh19/spot-the-diff</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/spot-the-diff">Spot-the-diff</pwcdataset>
    </paper>
    <paper id="438">
      <title>Abstractive Text-Image Summarization Using Multi-Modal Attentional Hierarchical RNN<fixed-case>RNN</fixed-case></title>
      <author><first>Jingqiang</first><last>Chen</last></author>
      <author><first>Hai</first><last>Zhuge</last></author>
      <pages>4046–4056</pages>
      <url hash="796e274f">D18-1438</url>
      <abstract>Rapid growth of multi-modal documents on the <a href="https://en.wikipedia.org/wiki/Internet">Internet</a> makes multi-modal summarization research necessary. Most previous research summarizes texts or images separately. Recent neural summarization research shows the strength of the Encoder-Decoder model in <a href="https://en.wikipedia.org/wiki/Automatic_summarization">text summarization</a>. This paper proposes an abstractive text-image summarization model using the attentional hierarchical Encoder-Decoder model to summarize a text document and its accompanying images simultaneously, and then to align the sentences and images in summaries. A multi-modal attentional mechanism is proposed to attend original sentences, images, and captions when decoding. The DailyMail dataset is extended by collecting <a href="https://en.wikipedia.org/wiki/Image">images</a> and captions from the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">Web</a>. Experiments show our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms the neural abstractive and extractive text summarization methods that do not consider <a href="https://en.wikipedia.org/wiki/Digital_image">images</a>. In addition, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can generate informative summaries of images.</abstract>
      <doi>10.18653/v1/D18-1438</doi>
      <bibkey>chen-zhuge-2018-abstractive</bibkey>
    </paper>
    <paper id="440">
      <title>Closed-Book Training to Improve Summarization Encoder Memory</title>
      <author><first>Yichen</first><last>Jiang</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>4067–4077</pages>
      <url hash="1c3aa128">D18-1440</url>
      <attachment type="attachment" hash="96dc21c9">D18-1440.Attachment.pdf</attachment>
      <abstract>A good neural sequence-to-sequence summarization model should have a strong <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> that can distill and memorize the important information from long input texts so that the decoder can generate salient summaries based on the <a href="https://en.wikipedia.org/wiki/Encoder">encoder’s memory</a>. In this paper, we aim to improve the memorization capabilities of the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> of a pointer-generator model by adding an additional ‘closed-book’ decoder without attention and pointer mechanisms. Such a <a href="https://en.wikipedia.org/wiki/Code">decoder</a> forces the <a href="https://en.wikipedia.org/wiki/Encoder">encoder</a> to be more selective in the information encoded in its memory state because the <a href="https://en.wikipedia.org/wiki/Code">decoder</a> ca n’t rely on the extra information provided by the <a href="https://en.wikipedia.org/wiki/Attention">attention</a> and possibly copy modules, and hence improves the entire model. On the CNN / Daily Mail dataset, our 2-decoder model outperforms the baseline significantly in terms of ROUGE and METEOR metrics, for both cross-entropy and reinforced setups (and on human evaluation). Moreover, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> also achieves higher scores in a test-only DUC-2002 generalizability setup. We further present a memory ability test, two saliency metrics, as well as several sanity-check ablations (based on fixed-encoder, gradient-flow cut, and model capacity) to prove that the encoder of our 2-decoder model does in fact learn stronger memory representations than the baseline encoder.</abstract>
      <doi>10.18653/v1/D18-1440</doi>
      <bibkey>jiang-bansal-2018-closed</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="442">
      <title>Iterative Document Representation Learning Towards <a href="https://en.wikipedia.org/wiki/Summarization">Summarization</a> with Polishing</title>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>Shen</first><last>Gao</last></author>
      <author><first>Chongyang</first><last>Tao</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>4088–4097</pages>
      <url hash="ef874038">D18-1442</url>
      <attachment type="attachment" hash="8512f4a6">D18-1442.Attachment.pdf</attachment>
      <abstract>In this paper, we introduce Iterative Text Summarization (ITS), an iteration-based model for supervised extractive text summarization, inspired by the observation that it is often necessary for a human to read an article multiple times in order to fully understand and summarize its contents. Current summarization approaches read through a document only once to generate a document representation, resulting in a sub-optimal representation. To address this issue we introduce a <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> which iteratively polishes the document representation on many passes through the document. As part of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, we also introduce a selective reading mechanism that decides more accurately the extent to which each sentence in the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> should be updated. Experimental results on the CNN / DailyMail and DUC2002 datasets demonstrate that our model significantly outperforms state-of-the-art extractive systems when evaluated by machines and by humans.</abstract>
      <doi>10.18653/v1/D18-1442</doi>
      <bibkey>chen-etal-2018-iterative</bibkey>
      <pwccode url="https://github.com/yingtaomj/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing" additional="false">yingtaomj/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
    <paper id="444">
      <title>Controlling Length in Abstractive Summarization Using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a></title>
      <author><first>Yizhu</first><last>Liu</last></author>
      <author><first>Zhiyi</first><last>Luo</last></author>
      <author><first>Kenny</first><last>Zhu</last></author>
      <pages>4110–4119</pages>
      <url hash="39d26cd6">D18-1444</url>
      <abstract>Convolutional neural networks (CNNs) have met great success in abstractive summarization, but they can not effectively generate summaries of desired lengths. Because generated summaries are used in difference scenarios which may have space or length constraints, the ability to control the summary length in abstractive summarization is an important problem. In this paper, we propose an approach to constrain the summary length by extending a convolutional sequence to sequence model. The results show that this approach generates high-quality summaries with user defined length, and outperforms the baselines consistently in terms of ROUGE score, length variations and <a href="https://en.wikipedia.org/wiki/Semantic_similarity">semantic similarity</a>.</abstract>
      <doi>10.18653/v1/D18-1444</doi>
      <bibkey>liu-etal-2018-controlling</bibkey>
      <pwccode url="https://github.com/YizhuLiu/sumlen" additional="false">YizhuLiu/sumlen</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dmqa">DMQA</pwcdataset>
    </paper>
    <paper id="446">
      <title>Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization</title>
      <author><first>Logan</first><last>Lebanoff</last></author>
      <author><first>Kaiqiang</first><last>Song</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>4131–4141</pages>
      <url hash="33f7318f">D18-1446</url>
      <abstract>Generating a text abstract from a set of documents remains a challenging task. The neural encoder-decoder framework has recently been exploited to summarize single documents, but its success can in part be attributed to the availability of large parallel data automatically acquired from the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">Web</a>. In contrast, parallel data for <a href="https://en.wikipedia.org/wiki/Multi-document_summarization">multi-document summarization</a> are scarce and costly to obtain. There is a pressing need to adapt an encoder-decoder model trained on single-document summarization data to work with multiple-document input. In this paper, we present an initial investigation into a novel adaptation method. It exploits the maximal marginal relevance method to select representative sentences from multi-document input, and leverages an abstractive encoder-decoder model to fuse disparate sentences to an abstractive summary. The adaptation method is robust and itself requires no training data. Our system compares favorably to state-of-the-art extractive and abstractive approaches judged by automatic metrics and human assessors.</abstract>
      <doi>10.18653/v1/D18-1446</doi>
      <bibkey>lebanoff-etal-2018-adapting</bibkey>
      <pwccode url="https://github.com/ucfnlp/multidoc_summarization" additional="false">ucfnlp/multidoc_summarization</pwccode>
    </paper>
    <paper id="447">
      <title>Semi-Supervised Learning for Neural Keyphrase Generation</title>
      <author><first>Hai</first><last>Ye</last></author>
      <author><first>Lu</first><last>Wang</last></author>
      <pages>4142–4153</pages>
      <url hash="b9be5123">D18-1447</url>
      <abstract>We study the problem of generating keyphrases that summarize the key points for a given document. While sequence-to-sequence (seq2seq) models have achieved remarkable performance on this task (Meng et al., 2017), model training often relies on large amounts of labeled data, which is only applicable to resource-rich domains. In this paper, we propose semi-supervised keyphrase generation methods by leveraging both labeled data and large-scale unlabeled samples for <a href="https://en.wikipedia.org/wiki/Machine_learning">learning</a>. Two strategies are proposed. First, unlabeled documents are first tagged with synthetic keyphrases obtained from unsupervised keyphrase extraction methods or a self-learning algorithm, and then combined with labeled samples for training. Furthermore, we investigate a multi-task learning framework to jointly learn to generate keyphrases as well as the titles of the articles. Experimental results show that our semi-supervised learning-based methods outperform a state-of-the-art model trained with labeled data only.</abstract>
      <doi>10.18653/v1/D18-1447</doi>
      <bibkey>ye-wang-2018-semi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/kp20k">KP20k</pwcdataset>
    </paper>
    <paper id="448">
      <title>MSMO : Multimodal Summarization with Multimodal Output<fixed-case>MSMO</fixed-case>: Multimodal Summarization with Multimodal Output</title>
      <author><first>Junnan</first><last>Zhu</last></author>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Tianshang</first><last>Liu</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>4154–4164</pages>
      <url hash="5448f81f">D18-1448</url>
      <attachment type="attachment" hash="add3e5f4">D18-1448.Attachment.zip</attachment>
      <abstract>Multimodal summarization has drawn much attention due to the rapid growth of <a href="https://en.wikipedia.org/wiki/Multimedia">multimedia data</a>. The output of the current multimodal summarization systems is usually represented in texts. However, we have found through experiments that multimodal output can significantly improve user satisfaction for informativeness of summaries. In this paper, we propose a novel task, multimodal summarization with multimodal output (MSMO). To handle this <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>, we first collect a <a href="https://en.wikipedia.org/wiki/Data_set">large-scale dataset</a> for MSMO research. We then propose a multimodal attention model to jointly generate text and select the most relevant image from the multimodal input. Finally, to evaluate multimodal outputs, we construct a novel multimodal automatic evaluation (MMAE) method which considers both intra-modality salience and inter-modality relevance. The experimental results show the effectiveness of <a href="https://en.wikipedia.org/wiki/MMAE">MMAE</a>.</abstract>
      <doi>10.18653/v1/D18-1448</doi>
      <bibkey>zhu-etal-2018-msmo</bibkey>
    </paper>
    <paper id="449">
      <title>Frustratingly Easy Model Ensemble for Abstractive Summarization</title>
      <author><first>Hayato</first><last>Kobayashi</last></author>
      <pages>4165–4176</pages>
      <url hash="9fa37c30">D18-1449</url>
      <attachment type="attachment" hash="3f8fdfb0">D18-1449.Attachment.pdf</attachment>
      <abstract>Ensemble methods, which combine multiple models at decoding time, are now widely known to be effective for text-generation tasks. However, they generally increase computational costs, and thus, there have been many studies on compressing or distilling ensemble models. In this paper, we propose an alternative, simple but effective unsupervised ensemble method, post-ensemble, that combines multiple models by selecting a majority-like output in post-processing. We theoretically prove that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is closely related to <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a> based on the von Mises-Fisher kernel. Experimental results on a news-headline-generation task show that the proposed method performs better than the current <a href="https://en.wikipedia.org/wiki/Ensemble_learning">ensemble methods</a>.<i>post-ensemble</i>, that combines multiple models by selecting a majority-like output in post-processing. We theoretically prove that our method is closely related to kernel density estimation based on the von Mises-Fisher kernel. Experimental results on a news-headline-generation task show that the proposed method performs better than the current ensemble methods.</abstract>
      <doi>10.18653/v1/D18-1449</doi>
      <attachment type="poster" hash="7d264a73">D18-1449.Poster.pdf</attachment>
      <bibkey>kobayashi-2018-frustratingly</bibkey>
    </paper>
    <paper id="450">
      <title>Automatic Pyramid Evaluation Exploiting EDU-based Extractive Reference Summaries<fixed-case>EDU</fixed-case>-based Extractive Reference Summaries</title>
      <author><first>Tsutomu</first><last>Hirao</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <pages>4177–4186</pages>
      <url hash="131c8104">D18-1450</url>
      <abstract>This paper tackles automation of the pyramid method, a reliable manual evaluation framework. To construct a pyramid, we transform human-made reference summaries into extractive reference summaries that consist of Elementary Discourse Units (EDUs) obtained from source documents and then weight every EDU by counting the number of extractive reference summaries that contain the EDU. A summary is scored by the correspondences between EDUs in the summary and those in the pyramid. Experiments on DUC and TAC data sets show that our methods strongly correlate with various manual evaluations.</abstract>
      <doi>10.18653/v1/D18-1450</doi>
      <bibkey>hirao-etal-2018-automatic</bibkey>
    </paper>
    <paper id="451">
      <title>Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks</title>
      <author><first>Yaushian</first><last>Wang</last></author>
      <author><first>Hung-Yi</first><last>Lee</last></author>
      <pages>4187–4195</pages>
      <url hash="69b228e3">D18-1451</url>
      <attachment type="attachment" hash="fd404bce">D18-1451.Attachment.pdf</attachment>
      <abstract>Auto-encoders compress input data into a latent-space representation and reconstruct the original data from the <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representation</a>. This latent representation is not easily interpreted by humans. In this paper, we propose training an auto-encoder that encodes input text into human-readable sentences, and unpaired abstractive summarization is thereby achieved. The <a href="https://en.wikipedia.org/wiki/Auto-encoder">auto-encoder</a> is composed of a <a href="https://en.wikipedia.org/wiki/Generator_(computer_programming)">generator</a> and a <a href="https://en.wikipedia.org/wiki/Reconstructor">reconstructor</a>. The <a href="https://en.wikipedia.org/wiki/Generator_(mathematics)">generator</a> encodes the input text into a shorter word sequence, and the reconstructor recovers the <a href="https://en.wikipedia.org/wiki/Generator_(mathematics)">generator input</a> from the <a href="https://en.wikipedia.org/wiki/Generator_(mathematics)">generator output</a>. To make the generator output human-readable, a <a href="https://en.wikipedia.org/wiki/Discriminator">discriminator</a> restricts the output of the <a href="https://en.wikipedia.org/wiki/Generator_(mathematics)">generator</a> to resemble human-written sentences. By taking the generator output as the summary of the input text, abstractive summarization is achieved without document-summary pairs as training data. Promising results are shown on both English and Chinese corpora.</abstract>
      <doi>10.18653/v1/D18-1451</doi>
      <bibkey>wang-lee-2018-learning</bibkey>
    </paper>
    <paper id="452">
      <title>Joint Multitask Learning for Community Question Answering Using Task-Specific Embeddings</title>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Lluís</first><last>Màrquez</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>4196–4207</pages>
      <url hash="91af0c00">D18-1452</url>
      <abstract>We address jointly two important tasks for Question Answering in community forums : given a new question, (i) find related existing questions, and (ii) find relevant answers to this new question. We further use an auxiliary task to complement the previous two, i.e., (iii) find good answers with respect to the thread question in a question-comment thread. We use deep neural networks (DNNs) to learn meaningful task-specific embeddings, which we then incorporate into a conditional random field (CRF) model for the multitask setting, performing joint learning over a complex graph structure. While <a href="https://en.wikipedia.org/wiki/Deep_learning">DNNs</a> alone achieve competitive results when trained to produce the embeddings, the CRF, which makes use of the embeddings and the dependencies between the tasks, improves the results significantly and consistently across a variety of evaluation metrics, thus showing the complementarity of <a href="https://en.wikipedia.org/wiki/Deep_learning">DNNs</a> and <a href="https://en.wikipedia.org/wiki/Structured_learning">structured learning</a>.</abstract>
      <video href="https://vimeo.com/306149753" />
      <doi>10.18653/v1/D18-1452</doi>
      <bibkey>joty-etal-2018-joint</bibkey>
    </paper>
    <paper id="453">
      <title>What Makes Reading Comprehension Questions Easier?</title>
      <author><first>Saku</first><last>Sugawara</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <author><first>Satoshi</first><last>Sekine</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>4208–4219</pages>
      <url hash="e164a29c">D18-1453</url>
      <abstract>A challenge in creating a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> for machine reading comprehension (MRC) is to collect questions that require a sophisticated understanding of language to answer beyond using superficial cues. In this work, we investigate what makes questions easier across recent 12 MRC datasets with three question styles (answer extraction, description, and multiple choice). We propose to employ simple <a href="https://en.wikipedia.org/wiki/Heuristic">heuristics</a> to split each <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> into easy and hard subsets and examine the performance of two baseline models for each of the <a href="https://en.wikipedia.org/wiki/Subset">subsets</a>. We then manually annotate questions sampled from each <a href="https://en.wikipedia.org/wiki/Subset">subset</a> with both validity and requisite reasoning skills to investigate which skills explain the difference between easy and hard questions. From this study, we observed that (i) the baseline performances for the hard subsets remarkably degrade compared to those of entire datasets, (ii) hard questions require knowledge inference and multiple-sentence reasoning in comparison with easy questions, and (iii) multiple-choice questions tend to require a broader range of reasoning skills than answer extraction and description questions. These results suggest that one might overestimate recent advances in <a href="https://en.wikipedia.org/wiki/Microscopic_scale">MRC</a>.</abstract>
      <video href="https://vimeo.com/306150555" />
      <doi>10.18653/v1/D18-1453</doi>
      <bibkey>sugawara-etal-2018-makes</bibkey>
      <pwccode url="https://github.com/Alab-NII/mrc-heuristics" additional="false">Alab-NII/mrc-heuristics</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/arc">ARC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ms-marco">MS MARCO</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/who-did-what">Who-did-What</pwcdataset>
    </paper>
    <paper id="454">
      <title>Commonsense for Generative Multi-Hop Question Answering Tasks</title>
      <author><first>Lisa</first><last>Bauer</last></author>
      <author><first>Yicheng</first><last>Wang</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>4220–4230</pages>
      <url hash="89645650">D18-1454</url>
      <attachment type="attachment" hash="a4283c3f">D18-1454.Attachment.pdf</attachment>
      <abstract>Reading comprehension QA tasks have seen a recent surge in popularity, yet most works have focused on fact-finding extractive QA. We instead focus on a more challenging multi-hop generative task (NarrativeQA), which requires the model to reason, gather, and synthesize disjoint pieces of information within the context to generate an answer. This type of multi-step reasoning also often requires understanding implicit relations, which humans resolve via external, background commonsense knowledge. We first present a strong generative baseline that uses a multi-attention mechanism to perform multiple hops of reasoning and a pointer-generator decoder to synthesize the answer. This <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs substantially better than previous generative models, and is competitive with current state-of-the-art span prediction models. We next introduce a novel system for selecting grounded multi-hop relational commonsense information from <a href="https://en.wikipedia.org/wiki/ConceptNet">ConceptNet</a> via a pointwise mutual information and term-frequency based scoring function. Finally, we effectively use this extracted commonsense information to fill in gaps of reasoning between context hops, using a selectively-gated attention mechanism. This boosts the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s performance significantly (also verified via human evaluation), establishing a new state-of-the-art for the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a>. We also show that our background knowledge enhancements are generalizable and improve performance on QAngaroo-WikiHop, another multi-hop reasoning dataset.</abstract>
      <video href="https://vimeo.com/306151626" />
      <doi>10.18653/v1/D18-1454</doi>
      <bibkey>bauer-etal-2018-commonsense</bibkey>
      <pwccode url="https://github.com/yicheng-w/CommonSenseMultiHopQA" additional="true">yicheng-w/CommonSenseMultiHopQA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/narrativeqa">NarrativeQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikihop">WikiHop</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="456">
      <title>A Nil-Aware Answer Extraction Framework for <a href="https://en.wikipedia.org/wiki/Question_answering">Question Answering</a></title>
      <author><first>Souvik</first><last>Kundu</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <pages>4243–4252</pages>
      <url hash="d08cbb85">D18-1456</url>
      <abstract>Recently, there has been a surge of interest in reading comprehension-based (RC) question answering (QA). However, current approaches suffer from an impractical assumption that every question has a valid answer in the associated passage. A practical QA system must possess the ability to determine whether a valid answer exists in a given text passage. In this paper, we focus on developing QA systems that can extract an answer for a question if and only if the associated passage contains an answer. If the associated passage does not contain any valid answer, the QA system will correctly return Nil. We propose a novel nil-aware answer span extraction framework that is capable of returning Nil or a text span from the associated passage as an answer in a single step. We show that our proposed <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> can be easily integrated with several recently proposed QA models developed for <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> and can be trained in an end-to-end fashion. Our proposed nil-aware answer extraction neural network decomposes pieces of evidence into relevant and irrelevant parts and then combines them to infer the existence of any answer. Experiments on the NewsQA dataset show that the integration of our proposed framework significantly outperforms several strong baseline systems that use pipeline or threshold-based approaches.</abstract>
      <video href="https://vimeo.com/306152896" />
      <doi>10.18653/v1/D18-1456</doi>
      <bibkey>kundu-ng-2018-nil</bibkey>
      <pwccode url="https://github.com/nusnlp/namanda" additional="false">nusnlp/namanda</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="458">
      <title>Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures</title>
      <author><first>Gongbo</first><last>Tang</last></author>
      <author><first>Mathias</first><last>Müller</last></author>
      <author><first>Annette</first><last>Rios</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <pages>4263–4272</pages>
      <url hash="fe1f9b90">D18-1458</url>
      <abstract>Recently, non-recurrent architectures (convolutional, self-attentional) have outperformed RNNs in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>. CNNs and self-attentional networks can connect distant words via shorter network paths than RNNs, and it has been speculated that this improves their ability to model long-range dependencies. However, this theoretical argument has not been tested empirically, nor have alternative explanations for their strong performance been explored in-depth. We hypothesize that the strong performance of CNNs and self-attentional networks could also be due to their ability to extract semantic features from the source text, and we evaluate RNNs, CNNs and self-attention networks on two tasks : subject-verb agreement (where capturing long-range dependencies is required) and word sense disambiguation (where semantic feature extraction is required). Our experimental results show that : 1) self-attentional networks and CNNs do not outperform RNNs in modeling subject-verb agreement over long distances ; 2) self-attentional networks perform distinctly better than RNNs and CNNs on <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">word sense disambiguation</a>.</abstract>
      <video href="https://vimeo.com/306131741" />
      <doi>10.18653/v1/D18-1458</doi>
      <bibkey>tang-etal-2018-self</bibkey>
      <pwccode url="https://github.com/awslabs/sockeye" additional="false">awslabs/sockeye</pwccode>
    </paper>
    <paper id="459">
      <title>Simplifying <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a> with Addition-Subtraction Twin-Gated Recurrent Networks</title>
      <author><first>Biao</first><last>Zhang</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Jinsong</first><last>Su</last></author>
      <author><first>Qian</first><last>Lin</last></author>
      <author><first>Huiji</first><last>Zhang</last></author>
      <pages>4273–4283</pages>
      <url hash="6f4ac157">D18-1459</url>
      <attachment type="attachment" hash="04c1ce06">D18-1459.Attachment.zip</attachment>
      <abstract>In this paper, we propose an additionsubtraction twin-gated recurrent network (ATR) to simplify <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a>. The recurrent units of ATR are heavily simplified to have the smallest number of weight matrices among units of all existing gated RNNs. With the simple addition and subtraction operation, we introduce a twin-gated mechanism to build input and forget gates which are highly correlated. Despite this simplification, the essential <a href="https://en.wikipedia.org/wiki/Nonlinear_system">non-linearities</a> and capability of modeling long-distance dependencies are preserved. Additionally, the proposed <a href="https://en.wikipedia.org/wiki/Atchison,_Topeka_and_Santa_Fe_Railway">ATR</a> is more transparent than LSTM / GRU due to the simplification. Forward self-attention can be easily established in ATR, which makes the proposed <a href="https://en.wikipedia.org/wiki/Telecommunications_network">network</a> interpretable. Experiments on WMT14 translation tasks demonstrate that ATR-based neural machine translation can yield competitive performance on English-German and English-French language pairs in terms of both translation quality and speed. Further experiments on NIST Chinese-English translation, natural language inference and Chinese word segmentation verify the generality and applicability of ATR on different natural language processing tasks.</abstract>
      <video href="https://vimeo.com/306132998" />
      <doi>10.18653/v1/D18-1459</doi>
      <bibkey>zhang-etal-2018-simplifying</bibkey>
      <pwccode url="https://github.com/bzhangGo/zero" additional="true">bzhangGo/zero</pwccode>
    </paper>
    <paper id="460">
      <title>Speeding Up Neural Machine Translation Decoding by Cube Pruning</title>
      <author><first>Wen</first><last>Zhang</last></author>
      <author><first>Liang</first><last>Huang</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Lei</first><last>Shen</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <pages>4284–4294</pages>
      <url hash="7c2c9392">D18-1460</url>
      <abstract>Although <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> has achieved promising results, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> suffers from slow translation speed. The direct consequence is that a trade-off has to be made between translation quality and speed, thus its performance can not come into full play. We apply cube pruning, a popular technique to speed up <a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>, into <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> to speed up the <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. To construct the <a href="https://en.wikipedia.org/wiki/Equivalence_class">equivalence class</a>, similar target hidden states are combined, leading to less RNN expansion operations on the target side and less softmax operations over the large target vocabulary. The experiments show that, at the same or even better translation quality, our method can translate faster compared with naive beam search by 3.3x on <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPUs</a> and 3.5x on <a href="https://en.wikipedia.org/wiki/Central_processing_unit">CPUs</a>.</abstract>
      <video href="https://vimeo.com/306134160" />
      <doi>10.18653/v1/D18-1460</doi>
      <bibkey>zhang-etal-2018-speeding</bibkey>
    </paper>
    <paper id="464">
      <title>A Neural Local Coherence Model for Text Quality Assessment</title>
      <author><first>Mohsen</first><last>Mesgar</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>4328–4339</pages>
      <url hash="8affc39e">D18-1464</url>
      <attachment type="attachment" hash="6b10f25e">D18-1464.Attachment.pdf</attachment>
      <abstract>We propose a local coherence model that captures the flow of what semantically connects adjacent sentences in a text. We represent the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of a sentence by a <a href="https://en.wikipedia.org/wiki/Euclidean_vector">vector</a> and capture its state at each word of the sentence. We model what relates two adjacent sentences based on the two most similar semantic states, each of which is in one of the sentences. We encode the perceived coherence of a text by a <a href="https://en.wikipedia.org/wiki/Euclidean_vector">vector</a>, which represents patterns of changes in salient information that relates adjacent sentences. Our experiments demonstrate that our approach is beneficial for two downstream tasks : Readability assessment, in which our model achieves new state-of-the-art results ; and essay scoring, in which the combination of our coherence vectors and other task-dependent features significantly improves the performance of a strong essay scorer.</abstract>
      <video href="https://vimeo.com/306164201" />
      <doi>10.18653/v1/D18-1464</doi>
      <bibkey>mesgar-strube-2018-neural</bibkey>
    </paper>
    <paper id="466">
      <title>Getting to Hearer-old : Charting Referring Expressions Across Time</title>
      <author><first>Ieva</first><last>Staliūnaitė</last></author>
      <author><first>Hannah</first><last>Rohde</last></author>
      <author><first>Bonnie</first><last>Webber</last></author>
      <author><first>Annie</first><last>Louis</last></author>
      <pages>4350–4359</pages>
      <url hash="bc342646">D18-1466</url>
      <abstract>When a reader is first introduced to an entity, its <a href="https://en.wikipedia.org/wiki/Referring_expression">referring expression</a> must describe the entity. For entities that are widely known, a single word or phrase often suffices. This paper presents the first study of how <a href="https://en.wikipedia.org/wiki/Expression_(mathematics)">expressions</a> that refer to the same entity develop over time. We track thousands of person and organization entities over 20 years of New York Times (NYT). As entities move from hearer-new (first introduction to the NYT audience) to hearer-old (common knowledge) status, we show empirically that the referring expressions along this trajectory depend on the type of the entity, and exhibit linguistic properties related to becoming common knowledge (e.g., shorter length, less use of appositives, more definiteness). These properties can also be used to build a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to predict how long it will take for an entity to reach hearer-old status. Our results reach 10-30 % absolute improvement over a majority-class baseline.</abstract>
      <video href="https://vimeo.com/306166016" />
      <doi>10.18653/v1/D18-1466</doi>
      <bibkey>staliunaite-etal-2018-getting</bibkey>
    </paper>
    <paper id="467">
      <title>Making fetch happen : The influence of social and linguistic context on nonstandard word growth and decline</title>
      <author><first>Ian</first><last>Stewart</last></author>
      <author><first>Jacob</first><last>Eisenstein</last></author>
      <pages>4360–4370</pages>
      <url hash="5d60253b">D18-1467</url>
      <abstract>In an <a href="https://en.wikipedia.org/wiki/Online_community">online community</a>, new words come and go : today’s haha may be replaced by tomorrow’s lol. Changes in online writing are usually studied as a social process, with innovations diffusing through a network of individuals in a <a href="https://en.wikipedia.org/wiki/Speech_community">speech community</a>. But unlike other types of <a href="https://en.wikipedia.org/wiki/Innovation">innovation</a>, <a href="https://en.wikipedia.org/wiki/Language_change">language change</a> is shaped and constrained by the <a href="https://en.wikipedia.org/wiki/Grammar">grammatical system</a> in which it takes part. To investigate the role of social and structural factors in <a href="https://en.wikipedia.org/wiki/Language_change">language change</a>, we undertake a large-scale analysis of the frequencies of <a href="https://en.wikipedia.org/wiki/Nonstandard_dialect">non-standard words</a> in <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>. Dissemination across many linguistic contexts is a predictor of success : words that appear in more linguistic contexts grow faster and survive longer. Furthermore, social dissemination plays a less important role in explaining word growth and decline than previously hypothesized.</abstract>
      <video href="https://vimeo.com/306120421" />
      <doi>10.18653/v1/D18-1467</doi>
      <bibkey>stewart-eisenstein-2018-making</bibkey>
    </paper>
    <paper id="468">
      <title>Analyzing Correlated Evolution of Multiple Features Using Latent Representations</title>
      <author><first>Yugo</first><last>Murawaki</last></author>
      <pages>4371–4382</pages>
      <url hash="4a4ba889">D18-1468</url>
      <attachment type="attachment" hash="b75d6a11">D18-1468.Attachment.pdf</attachment>
      <abstract>Statistical phylogenetic models have allowed the quantitative analysis of the evolution of a single categorical feature and a pair of binary features, but correlated evolution involving multiple discrete features is yet to be explored. Here we propose latent representation-based analysis in which (1) a sequence of discrete surface features is projected to a sequence of <a href="https://en.wikipedia.org/wiki/Independence_(probability_theory)">independent binary variables</a> and (2) <a href="https://en.wikipedia.org/wiki/Phylogenetic_inference">phylogenetic inference</a> is performed on the latent space. In the experiments, we analyze the features of <a href="https://en.wikipedia.org/wiki/Linguistic_typology">linguistic typology</a>, with a special focus on the order of subject, object and verb. Our analysis suggests that <a href="https://en.wikipedia.org/wiki/Language">languages</a> sharing the same <a href="https://en.wikipedia.org/wiki/Word_order">word order</a> are not necessarily a coherent group but exhibit varying degrees of diachronic stability depending on other features.</abstract>
      <video href="https://vimeo.com/306121200" />
      <doi>10.18653/v1/D18-1468</doi>
      <bibkey>murawaki-2018-analyzing</bibkey>
      <pwccode url="https://github.com/murawaki/lattyp" additional="false">murawaki/lattyp</pwccode>
    </paper>
    <paper id="469">
      <title>Capturing <a href="https://en.wikipedia.org/wiki/Regional_variation">Regional Variation</a> with Distributed Place Representations and Geographic Retrofitting</title>
      <author><first>Dirk</first><last>Hovy</last></author>
      <author><first>Christoph</first><last>Purschke</last></author>
      <pages>4383–4394</pages>
      <url hash="1fd6b6ce">D18-1469</url>
      <abstract>Dialects are one of the main drivers of <a href="https://en.wikipedia.org/wiki/Variation_(linguistics)">language variation</a>, a major challenge for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing tools</a>. In most languages, <a href="https://en.wikipedia.org/wiki/Dialect">dialects</a> exist along a continuum, and are commonly discretized by combining the extent of several preselected linguistic variables. However, the selection of these <a href="https://en.wikipedia.org/wiki/Variable_(mathematics)">variables</a> is theory-driven and itself insensitive to change. We use Doc2Vec on a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus of 16.8 M anonymous online posts</a> in the <a href="https://en.wikipedia.org/wiki/List_of_territorial_entities_where_German_is_an_official_language">German-speaking area</a> to learn continuous document representations of cities. These <a href="https://en.wikipedia.org/wiki/Representation_(arts)">representations</a> capture continuous regional linguistic distinctions, and can serve as input to downstream NLP tasks sensitive to <a href="https://en.wikipedia.org/wiki/Regional_variation">regional variation</a>. By incorporating geographic information via <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting</a> and <a href="https://en.wikipedia.org/wiki/Agglomerative_clustering">agglomerative clustering</a> with <a href="https://en.wikipedia.org/wiki/Structure">structure</a>, we recover dialect areas at various levels of <a href="https://en.wikipedia.org/wiki/Granularity">granularity</a>. Evaluating these <a href="https://en.wikipedia.org/wiki/Cluster_analysis">clusters</a> against an existing dialect map, we achieve a match of up to 0.77 V-score (harmonic mean of cluster completeness and homogeneity). Our results show that representation learning with <a href="https://en.wikipedia.org/wiki/Retrofitting">retrofitting</a> offers a robust general method to automatically expose dialectal differences and regional variation at a finer granularity than was previously possible.</abstract>
      <video href="https://vimeo.com/306121832" />
      <doi>10.18653/v1/D18-1469</doi>
      <bibkey>hovy-purschke-2018-capturing</bibkey>
    </paper>
    <paper id="472">
      <title>Is it Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks<fixed-case>NLP</fixed-case> tasks</title>
      <author><first>Steffen</first><last>Eger</last></author>
      <author><first>Paul</first><last>Youssef</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>4415–4424</pages>
      <url hash="b8bda569">D18-1472</url>
      <attachment type="attachment" hash="7237425a">D18-1472.Attachment.zip</attachment>
      <abstract>Activation functions play a crucial role in <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> because they are the <a href="https://en.wikipedia.org/wiki/Nonlinear_system">nonlinearities</a> which have been attributed to the success story of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>. One of the currently most popular activation functions is <a href="https://en.wikipedia.org/wiki/ReLU">ReLU</a>, but several competitors have recently been proposed or ‘discovered’, including LReLU functions and swish. While most works compare newly proposed <a href="https://en.wikipedia.org/wiki/Activation_function">activation functions</a> on few tasks (usually from image classification) and against few competitors (usually ReLU), we perform the first largescale comparison of 21 <a href="https://en.wikipedia.org/wiki/Activation_function">activation functions</a> across eight different NLP tasks. We find that a largely unknown activation function performs most stably across all tasks, the so-called penalized tanh function. We also show that it can successfully replace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage point (pp) improvement over the standard choices on a challenging NLP task.</abstract>
      <doi>10.18653/v1/D18-1472</doi>
      <bibkey>eger-etal-2018-time</bibkey>
      <pwccode url="https://github.com/UKPLab/emnlp2018-activation-functions" additional="false">UKPLab/emnlp2018-activation-functions</pwccode>
    </paper>
    <paper id="473">
      <title>Hard Non-Monotonic Attention for Character-Level Transduction</title>
      <author><first>Shijie</first><last>Wu</last></author>
      <author><first>Pamela</first><last>Shapiro</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <pages>4425–4438</pages>
      <url hash="35cb2663">D18-1473</url>
      <abstract>Character-level string-to-string transduction is an important component of various NLP tasks. The goal is to map an input string to an output string, where the strings may be of different lengths and have characters taken from different alphabets. Recent approaches have used sequence-to-sequence models with an attention mechanism to learn which parts of the input string the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> should focus on during the generation of the output string. Both soft attention and hard monotonic attention have been used, but hard non-monotonic attention has only been used in other sequence modeling tasks and has required a stochastic approximation to compute the <a href="https://en.wikipedia.org/wiki/Gradient">gradient</a>. In this work, we introduce an exact, polynomial-time algorithm for marginalizing over the exponential number of non-monotonic alignments between two strings, showing that hard attention models can be viewed as neural reparameterizations of the classical IBM Model 1. We compare soft and hard non-monotonic attention experimentally and find that the exact <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> significantly improves performance over the <a href="https://en.wikipedia.org/wiki/Stochastic_approximation">stochastic approximation</a> and outperforms soft attention.</abstract>
      <doi>10.18653/v1/D18-1473</doi>
      <bibkey>wu-etal-2018-hard</bibkey>
      <pwccode url="https://github.com/shijie-wu/neural-transducer" additional="true">shijie-wu/neural-transducer</pwccode>
    </paper>
    <paper id="477">
      <title>Simple Recurrent Units for Highly Parallelizable Recurrence</title>
      <author><first>Tao</first><last>Lei</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Sida I.</first><last>Wang</last></author>
      <author><first>Hui</first><last>Dai</last></author>
      <author><first>Yoav</first><last>Artzi</last></author>
      <pages>4470–4481</pages>
      <url hash="04b47c81">D18-1477</url>
      <attachment type="attachment" hash="679ec9b0">D18-1477.Attachment.pdf</attachment>
      <abstract>Common <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">recurrent neural architectures</a> scale poorly due to the intrinsic difficulty in parallelizing their state computations. In this work, we propose the Simple Recurrent Unit (SRU), a light recurrent unit that balances model capacity and <a href="https://en.wikipedia.org/wiki/Scalability">scalability</a>. SRU is designed to provide expressive recurrence, enable highly parallelized implementation, and comes with careful initialization to facilitate training of <a href="https://en.wikipedia.org/wiki/Deep_learning">deep models</a>. We demonstrate the effectiveness of SRU on multiple NLP tasks. SRU achieves 59x speed-up over cuDNN-optimized LSTM on classification and question answering datasets, and delivers stronger results than LSTM and convolutional models. We also obtain an average of 0.7 BLEU improvement over the Transformer model (Vaswani et al., 2017) on <a href="https://en.wikipedia.org/wiki/Translation_(geometry)">translation</a> by incorporating SRU into the <a href="https://en.wikipedia.org/wiki/Computer_architecture">architecture</a>.</abstract>
      <doi>10.18653/v1/D18-1477</doi>
      <bibkey>lei-etal-2018-simple</bibkey>
      <pwccode url="https://github.com/asappresearch/sru" additional="true">asappresearch/sru</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mpqa-opinion-corpus">MPQA Opinion Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2014">WMT 2014</pwcdataset>
    </paper>
    <paper id="479">
      <title>Co-Stack Residual Affinity Networks with Multi-level Attention Refinement for Matching Text Sequences</title>
      <author><first>Yi</first><last>Tay</last></author>
      <author><first>Anh Tuan</first><last>Luu</last></author>
      <author><first>Siu Cheung</first><last>Hui</last></author>
      <pages>4492–4502</pages>
      <url hash="21bf2e3c">D18-1479</url>
      <abstract>Learning a <a href="https://en.wikipedia.org/wiki/Matching_function">matching function</a> between two text sequences is a long standing problem in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP research</a>. This <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> enables many potential <a href="https://en.wikipedia.org/wiki/Application_software">applications</a> such as <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a> and paraphrase identification. This paper proposes Co-Stack Residual Affinity Networks (CSRAN), a new and universal neural architecture for this problem. CSRAN is a deep architecture, involving stacked (multi-layered) recurrent encoders. Stacked / Deep architectures are traditionally difficult to train, due to the inherent weaknesses such as difficulty with feature propagation and <a href="https://en.wikipedia.org/wiki/Vanishing_gradient">vanishing gradients</a>. CSRAN incorporates two novel <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">components</a> to take advantage of the stacked architecture. Firstly, it introduces a new bidirectional alignment mechanism that learns <a href="https://en.wikipedia.org/wiki/Ligand_(biochemistry)">affinity weights</a> by fusing sequence pairs across stacked hierarchies. Secondly, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> leverages a multi-level attention refinement component between stacked recurrent layers. The key intuition is that, by leveraging information across all <a href="https://en.wikipedia.org/wiki/Hierarchy">network hierarchies</a>, we can not only improve <a href="https://en.wikipedia.org/wiki/Gradient_flow">gradient flow</a> but also improve overall performance. We conduct extensive experiments on six well-studied text sequence matching datasets, achieving state-of-the-art performance on all.</abstract>
      <doi>10.18653/v1/D18-1479</doi>
      <bibkey>tay-etal-2018-co</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="480">
      <title>Spherical Latent Spaces for Stable Variational Autoencoders</title>
      <author><first>Jiacheng</first><last>Xu</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>4503–4513</pages>
      <url hash="0d416bfa">D18-1480</url>
      <abstract>A hallmark of variational autoencoders (VAEs) for <a href="https://en.wikipedia.org/wiki/Text_processing">text processing</a> is their combination of powerful encoder-decoder models, such as LSTMs, with simple latent distributions, typically multivariate Gaussians. These models pose a difficult optimization problem : there is an especially bad local optimum where the variational posterior always equals the prior and the model does not use the <a href="https://en.wikipedia.org/wiki/Latent_variable">latent variable</a> at all, a kind of collapse which is encouraged by the KL divergence term of the objective. In this work, we experiment with another choice of latent distribution, namely the von Mises-Fisher (vMF) distribution, which places mass on the surface of the <a href="https://en.wikipedia.org/wiki/Unit_hypersphere">unit hypersphere</a>. With this choice of prior and posterior, the KL divergence term now only depends on the variance of the vMF distribution, giving us the ability to treat it as a fixed hyperparameter. We show that doing so not only averts the KL collapse, but consistently gives better likelihoods than <a href="https://en.wikipedia.org/wiki/List_of_things_named_after_Carl_Friedrich_Gauss">Gaussians</a> across a range of modeling conditions, including recurrent language modeling and bag-of-words document modeling. An analysis of the properties of our vMF representations shows that they learn richer and more nuanced structures in their latent representations than their Gaussian counterparts.</abstract>
      <doi>10.18653/v1/D18-1480</doi>
      <bibkey>xu-durrett-2018-spherical</bibkey>
      <pwccode url="https://github.com/jiacheng-xu/vmf_vae_nlp" additional="false">jiacheng-xu/vmf_vae_nlp</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="482">
      <title>Word Mover’s Embedding : From Word2Vec to Document Embedding<fixed-case>W</fixed-case>ord2<fixed-case>V</fixed-case>ec to Document Embedding</title>
      <author><first>Lingfei</first><last>Wu</last></author>
      <author><first>Ian En-Hsu</first><last>Yen</last></author>
      <author><first>Kun</first><last>Xu</last></author>
      <author><first>Fangli</first><last>Xu</last></author>
      <author><first>Avinash</first><last>Balakrishnan</last></author>
      <author><first>Pin-Yu</first><last>Chen</last></author>
      <author><first>Pradeep</first><last>Ravikumar</last></author>
      <author><first>Michael J.</first><last>Witbrock</last></author>
      <pages>4524–4534</pages>
      <url hash="ca029237">D18-1482</url>
      <attachment type="attachment" hash="82f8fe42">D18-1482.Attachment.zip</attachment>
      <abstract>While the celebrated Word2Vec technique yields semantically rich representations for individual words, there has been relatively less success in extending to generate unsupervised sentences or documents embeddings. Recent work has demonstrated that a distance measure between documents called Word Mover’s Distance (WMD) that aligns semantically similar words, yields unprecedented KNN classification accuracy. However, WMD is expensive to compute, and it is hard to extend its use beyond a KNN classifier. In this paper, we propose the Word Mover’s Embedding (WME), a novel approach to building an unsupervised document (sentence) embedding from pre-trained word embeddings. In our experiments on 9 benchmark text classification datasets and 22 textual similarity tasks, the proposed technique consistently matches or outperforms state-of-the-art techniques, with significantly higher accuracy on problems of short length.</abstract>
      <doi>10.18653/v1/D18-1482</doi>
      <bibkey>wu-etal-2018-word</bibkey>
      <pwccode url="https://github.com/IBM/WordMoversEmbeddings" additional="false">IBM/WordMoversEmbeddings</pwccode>
    </paper>
    <paper id="484">
      <title>Multi-Task Label Embedding for Text Classification</title>
      <author><first>Honglun</first><last>Zhang</last></author>
      <author><first>Liqiang</first><last>Xiao</last></author>
      <author><first>Wenqing</first><last>Chen</last></author>
      <author><first>Yongkun</first><last>Wang</last></author>
      <author><first>Yaohui</first><last>Jin</last></author>
      <pages>4545–4553</pages>
      <url hash="dc675dc5">D18-1484</url>
      <abstract>Multi-task learning in <a href="https://en.wikipedia.org/wiki/Text_classification">text classification</a> leverages implicit correlations among related tasks to extract common features and yield performance gains. However, a large body of previous work treats labels of each task as independent and meaningless one-hot vectors, which cause a loss of potential label information. In this paper, we propose Multi-Task Label Embedding to convert labels in text classification into semantic vectors, thereby turning the original <a href="https://en.wikipedia.org/wiki/Task_(computing)">tasks</a> into vector matching tasks. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> utilizes semantic correlations among tasks and makes it convenient to scale or transfer when new tasks are involved. Extensive experiments on five benchmark datasets for text classification show that our model can effectively improve the performances of related tasks with semantic representations of labels and additional information from each other.</abstract>
      <doi>10.18653/v1/D18-1484</doi>
      <bibkey>zhang-etal-2018-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="487">
      <title>Uncertainty-aware generative models for inferring document class prevalence</title>
      <author><first>Katherine</first><last>Keith</last></author>
      <author><first>Brendan</first><last>O’Connor</last></author>
      <pages>4575–4585</pages>
      <url hash="910c7c53">D18-1487</url>
      <abstract>Prevalence estimation is the task of inferring the relative frequency of classes of unlabeled examples in a groupfor example, the proportion of a document collection with positive sentiment. Previous work has focused on aggregating and adjusting discriminative individual classifiers to obtain prevalence point estimates. But imperfect classifier accuracy ought to be reflected in uncertainty over the predicted prevalence for scientifically valid inference. In this work, we present (1) a generative probabilistic modeling approach to prevalence estimation, and (2) the construction and evaluation of prevalence confidence intervals ; in particular, we demonstrate that an off-the-shelf discriminative classifier can be given a generative re-interpretation, by backing out an implicit individual-level likelihood function, which can be used to conduct fast and simple group-level Bayesian inference. Empirically, we demonstrate our approach provides better confidence interval coverage than an alternative, and is dramatically more robust to shifts in the class prior between training and testing.</abstract>
      <doi>10.18653/v1/D18-1487</doi>
      <bibkey>keith-oconnor-2018-uncertainty</bibkey>
      <pwccode url="https://github.com/slanglab/doc_prevalence" additional="false">slanglab/doc_prevalence</pwccode>
    </paper>
    <paper id="490">
      <title>Disfluency Detection using Auto-Correlational Neural Networks</title>
      <author><first>Paria</first><last>Jamshid Lou</last></author>
      <author><first>Peter</first><last>Anderson</last></author>
      <author><first>Mark</first><last>Johnson</last></author>
      <pages>4610–4619</pages>
      <url hash="6cbe1636">D18-1490</url>
      <abstract>In recent years, the natural language processing community has moved away from task-specific feature engineering, i.e., researchers discovering ad-hoc feature representations for various tasks, in favor of <a href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units">general-purpose methods</a> that learn the input representation by themselves. However, state-of-the-art approaches to disfluency detection in spontaneous speech transcripts currently still depend on an array of hand-crafted features, and other representations derived from the output of pre-existing systems such as <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> or dependency parsers. As an alternative, this paper proposes a simple yet effective <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> for automatic disfluency detection, called an auto-correlational neural network (ACNN). The model uses a convolutional neural network (CNN) and augments it with a new auto-correlation operator at the lowest layer that can capture the kinds of rough copy dependencies that are characteristic of repair disfluencies in speech. In experiments, the ACNN model outperforms the baseline CNN on a disfluency detection task with a 5 % increase in <a href="https://en.wikipedia.org/wiki/F-score">f-score</a>, which is close to the previous best result on this task.</abstract>
      <doi>10.18653/v1/D18-1490</doi>
      <bibkey>jamshid-lou-etal-2018-disfluency</bibkey>
      <pwccode url="https://github.com/pariajm/deep-disfluency-detector" additional="true">pariajm/deep-disfluency-detector</pwccode>
    </paper>
    <paper id="492">
      <title>On Tree-Based Neural Sentence Modeling</title>
      <author><first>Haoyue</first><last>Shi</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Jiaze</first><last>Chen</last></author>
      <author><first>Lei</first><last>Li</last></author>
      <pages>4631–4641</pages>
      <url hash="5e10b91f">D18-1492</url>
      <attachment type="attachment" hash="5aea7c87">D18-1492.Attachment.zip</attachment>
      <abstract>Neural networks with tree-based sentence encoders have shown better results on many <a href="https://en.wikipedia.org/wiki/Downstream_(networking)">downstream tasks</a>. Most of existing tree-based encoders adopt syntactic parsing trees as the explicit structure prior. To study the effectiveness of different <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">tree structures</a>, we replace the parsing trees with <a href="https://en.wikipedia.org/wiki/Tree_(data_structure)">trivial trees</a> (i.e., binary balanced tree, left-branching tree and right-branching tree) in the <a href="https://en.wikipedia.org/wiki/Encoder">encoders</a>. Though trivial trees contain no <a href="https://en.wikipedia.org/wiki/Syntax">syntactic information</a>, those <a href="https://en.wikipedia.org/wiki/Encoder">encoders</a> get competitive or even better results on all of the ten <a href="https://en.wikipedia.org/wiki/Downstream_(networking)">downstream tasks</a> we investigated. This surprising result indicates that explicit syntax guidance may not be the main contributor to the superior performances of tree-based neural sentence modeling. Further analysis show that <a href="https://en.wikipedia.org/wiki/Tree_model">tree modeling</a> gives better results when crucial words are closer to the final representation. Additional experiments give more clues on how to design an effective tree-based encoder. Our code is open-source and available at.<url>https://github.com/ExplorerFreda/TreeEnc</url>.</abstract>
      <doi>10.18653/v1/D18-1492</doi>
      <bibkey>shi-etal-2018-tree</bibkey>
      <pwccode url="https://github.com/ExplorerFreda/TreeEnc" additional="false">ExplorerFreda/TreeEnc</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/ag-news">AG News</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="494">
      <title>Siamese Network-Based Supervised Topic Modeling<fixed-case>S</fixed-case>iamese Network-Based Supervised Topic Modeling</title>
      <author><first>Minghui</first><last>Huang</last></author>
      <author><first>Yanghui</first><last>Rao</last></author>
      <author><first>Yuwei</first><last>Liu</last></author>
      <author><first>Haoran</first><last>Xie</last></author>
      <author><first>Fu Lee</first><last>Wang</last></author>
      <pages>4652–4662</pages>
      <url hash="fbe23cdc">D18-1494</url>
      <abstract>Label-specific topics can be widely used for supporting <a href="https://en.wikipedia.org/wiki/Personality_psychology">personality psychology</a>, aspect-level sentiment analysis, and cross-domain sentiment classification. To generate label-specific topics, several supervised topic models which adopt likelihood-driven objective functions have been proposed. However, it is hard for them to get a precise estimation on both topic discovery and <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>. In this study, we propose a supervised topic model based on the <a href="https://en.wikipedia.org/wiki/Siamese_network">Siamese network</a>, which can trade off label-specific word distributions with document-specific label distributions in a uniform framework. Experiments on real-world datasets validate that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> performs competitive in topic discovery quantitatively and qualitatively. Furthermore, the proposed model can effectively predict categorical or real-valued labels for new documents by generating word embeddings from a label-specific topical space.</abstract>
      <doi>10.18653/v1/D18-1494</doi>
      <bibkey>huang-etal-2018-siamese</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/isear">ISEAR</pwcdataset>
    </paper>
    <paper id="497">
      <title>Learning Disentangled Representations of Texts with Application to Biomedical Abstracts</title>
      <author><first>Sarthak</first><last>Jain</last></author>
      <author><first>Edward</first><last>Banner</last></author>
      <author><first>Jan-Willem</first><last>van de Meent</last></author>
      <author><first>Iain J.</first><last>Marshall</last></author>
      <author><first>Byron C.</first><last>Wallace</last></author>
      <pages>4683–4693</pages>
      <url hash="7116b988">D18-1497</url>
      <attachment type="attachment" hash="96ed59f2">D18-1497.Attachment.pdf</attachment>
      <abstract>We propose a method for learning disentangled representations of texts that code for distinct and complementary aspects, with the aim of affording efficient model transfer and <a href="https://en.wikipedia.org/wiki/Interpretability">interpretability</a>. To induce disentangled embeddings, we propose an adversarial objective based on the (dis)similarity between triplets of documents with respect to specific aspects. Our motivating application is embedding biomedical abstracts describing <a href="https://en.wikipedia.org/wiki/Clinical_trial">clinical trials</a> in a manner that disentangles the populations, interventions, and outcomes in a given trial. We show that our method learns <a href="https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning">representations</a> that encode these clinically salient aspects, and that these can be effectively used to perform aspect-specific retrieval. We demonstrate that the approach generalizes beyond our motivating application in experiments on two multi-aspect review corpora.</abstract>
      <doi>10.18653/v1/D18-1497</doi>
      <bibkey>jain-etal-2018-learning</bibkey>
      <pwccode url="https://github.com/successar/neural-nlp" additional="false">successar/neural-nlp</pwccode>
    </paper>
    <paper id="498">
      <title>Multi-Source Domain Adaptation with Mixture of Experts</title>
      <author><first>Jiang</first><last>Guo</last></author>
      <author><first>Darsh</first><last>Shah</last></author>
      <author><first>Regina</first><last>Barzilay</last></author>
      <pages>4694–4703</pages>
      <url hash="e0382e9b">D18-1498</url>
      <abstract>We propose a mixture-of-experts approach for unsupervised domain adaptation from multiple sources. The key idea is to explicitly capture the relationship between a target example and different source domains. This relationship, expressed by a <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">point-to-set metric</a>, determines how to combine predictors trained on various domains. The <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metric</a> is learned in an unsupervised fashion using meta-training. Experimental results on <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a> demonstrate that our approach consistently outperforms multiple baselines and can robustly handle negative transfer.</abstract>
      <doi>10.18653/v1/D18-1498</doi>
      <bibkey>guo-etal-2018-multi</bibkey>
      <pwccode url="https://github.com/jiangfeng1124/transfer" additional="false">jiangfeng1124/transfer</pwccode>
    </paper>
    <paper id="505">
      <title>Revisiting the Importance of Encoding Logic Rules in Sentiment Classification</title>
      <author><first>Kalpesh</first><last>Krishna</last></author>
      <author><first>Preethi</first><last>Jyothi</last></author>
      <author><first>Mohit</first><last>Iyyer</last></author>
      <pages>4743–4751</pages>
      <url hash="35510b1d">D18-1505</url>
      <attachment type="attachment" hash="8f972a28">D18-1505.Attachment.zip</attachment>
      <abstract>We analyze the performance of different sentiment classification models on syntactically complex inputs like <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">A-but-B sentences</a>. The first contribution of this analysis addresses reproducible research : to meaningfully compare different <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>, their accuracies must be averaged over far more random seeds than what has traditionally been reported. With proper averaging in place, we notice that the distillation model described in Hu et al. (2016), which incorporates explicit logic rules for sentiment classification, is ineffective. In contrast, using contextualized ELMo embeddings (Peters et al., 2018a) instead of logic rules yields significantly better performance. Additionally, we provide analysis and visualizations that demonstrate ELMo’s ability to implicitly learn <a href="https://en.wikipedia.org/wiki/Rule_of_inference">logic rules</a>. Finally, a <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourced analysis</a> reveals how ELMo outperforms baseline models even on sentences with ambiguous sentiment labels.</abstract>
      <video href="https://vimeo.com/306136412" />
      <doi>10.18653/v1/D18-1505</doi>
      <bibkey>krishna-etal-2018-revisiting</bibkey>
      <pwccode url="https://github.com/martiansideofthemoon/logic-rules-sentiment" additional="false">martiansideofthemoon/logic-rules-sentiment</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="506">
      <title>A Co-Attention Neural Network Model for Emotion Cause Analysis with Emotional Context Awareness</title>
      <author><first>Xiangju</first><last>Li</last></author>
      <author><first>Kaisong</first><last>Song</last></author>
      <author><first>Shi</first><last>Feng</last></author>
      <author><first>Daling</first><last>Wang</last></author>
      <author><first>Yifei</first><last>Zhang</last></author>
      <pages>4752–4757</pages>
      <url hash="cbc97f60">D18-1506</url>
      <abstract>Emotion cause analysis has been a key topic in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a>. Existing methods ignore the contexts around the emotion word which can provide an emotion cause clue. Meanwhile, the clauses in a document play different roles on stimulating a certain emotion, depending on their content relevance. Therefore, we propose a co-attention neural network model for emotion cause analysis with emotional context awareness. The method encodes the clauses with a co-attention based bi-directional long short-term memory into high-level input representations, which are further fed into a convolutional layer for emotion cause analysis. Experimental results show that our approach outperforms the state-of-the-art baseline methods.</abstract>
      <video href="https://vimeo.com/306136988" />
      <doi>10.18653/v1/D18-1506</doi>
      <bibkey>li-etal-2018-co</bibkey>
    </paper>
    <paper id="507">
      <title>Modeling Empathy and Distress in Reaction to News Stories</title>
      <author><first>Sven</first><last>Buechel</last></author>
      <author><first>Anneke</first><last>Buffone</last></author>
      <author><first>Barry</first><last>Slaff</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <pages>4758–4765</pages>
      <url hash="b84d8729">D18-1507</url>
      <abstract>Computational detection and understanding of empathy is an important factor in advancing <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-computer interaction</a>. Yet to date, text-based empathy prediction has the following major limitations : It underestimates the psychological complexity of the phenomenon, adheres to a weak notion of ground truth where empathic states are ascribed by third parties, and lacks a shared corpus. In contrast, this contribution presents the first publicly available gold standard for empathy prediction. It is constructed using a novel annotation methodology which reliably captures empathy assessments by the writer of a statement using <a href="https://en.wikipedia.org/wiki/Scale_(social_sciences)">multi-item scales</a>. This is also the first computational work distinguishing between multiple forms of <a href="https://en.wikipedia.org/wiki/Empathy">empathy</a>, <a href="https://en.wikipedia.org/wiki/Empathic_concern">empathic concern</a>, and <a href="https://en.wikipedia.org/wiki/Distress_(medicine)">personal distress</a>, as recognized throughout <a href="https://en.wikipedia.org/wiki/Psychology">psychology</a>. Finally, we present experimental results for three different <a href="https://en.wikipedia.org/wiki/Predictive_modelling">predictive models</a>, of which a CNN performs the best.</abstract>
      <video href="https://vimeo.com/306137544" />
      <doi>10.18653/v1/D18-1507</doi>
      <bibkey>buechel-etal-2018-modeling</bibkey>
      <pwccode url="https://github.com/wwbp/empathic_reactions" additional="false">wwbp/empathic_reactions</pwccode>
    </paper>
    <paper id="509">
      <title>A Tree-based Decoder for Neural Machine Translation</title>
      <author><first>Xinyi</first><last>Wang</last></author>
      <author><first>Hieu</first><last>Pham</last></author>
      <author><first>Pengcheng</first><last>Yin</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <pages>4772–4777</pages>
      <url hash="5825b6ca">D18-1509</url>
      <attachment type="attachment" hash="6e656174">D18-1509.Attachment.pdf</attachment>
      <abstract>Recent advances in Neural Machine Translation (NMT) show that adding syntactic information to NMT systems can improve the quality of their translations. Most existing work utilizes some specific types of linguistically-inspired tree structures, like <a href="https://en.wikipedia.org/wiki/Constituent_(linguistics)">constituency</a> and dependency parse trees. This is often done via a standard RNN decoder that operates on a linearized target tree structure. However, it is an open question of what specific linguistic formalism, if any, is the best structural representation for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NMT</a>. In this paper, we (1) propose an NMT model that can naturally generate the <a href="https://en.wikipedia.org/wiki/Topology">topology</a> of an arbitrary <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">tree structure</a> on the target side, and (2) experiment with various target tree structures. Our experiments show the surprising result that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> delivers the best improvements with balanced binary trees constructed without any linguistic knowledge ; this <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> outperforms standard seq2seq models by up to 2.1 BLEU points, and other methods for incorporating target-side syntax by up to 0.7 BLEU.</abstract>
      <video href="https://vimeo.com/306166768" />
      <doi>10.18653/v1/D18-1509</doi>
      <bibkey>wang-etal-2018-tree</bibkey>
      <pwccode url="https://github.com/cindyxinyiwang/TrDec_pytorch" additional="false">cindyxinyiwang/TrDec_pytorch</pwccode>
    </paper>
    <paper id="512">
      <title>Has <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a> Achieved Human Parity? A Case for Document-level Evaluation</title>
      <author><first>Samuel</first><last>Läubli</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Martin</first><last>Volk</last></author>
      <pages>4791–4796</pages>
      <url hash="1d38a97f">D18-1512</url>
      <attachment type="attachment" hash="04d6f185">D18-1512.Attachment.pdf</attachment>
      <abstract>Recent research suggests that <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> achieves parity with <a href="https://en.wikipedia.org/wiki/Translation">professional human translation</a> on the WMT ChineseEnglish news translation task. We empirically test this claim with alternative evaluation protocols, contrasting the evaluation of single sentences and entire documents. In a pairwise ranking experiment, <a href="https://en.wikipedia.org/wiki/Human">human raters</a> assessing adequacy and fluency show a stronger preference for <a href="https://en.wikipedia.org/wiki/Human">human</a> over <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> when evaluating documents as compared to isolated sentences. Our findings emphasise the need to shift towards document-level evaluation as <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> improves to the degree that errors which are hard or impossible to spot at the sentence-level become decisive in discriminating quality of different translation outputs.</abstract>
      <video href="https://vimeo.com/306169001" />
      <doi>10.18653/v1/D18-1512</doi>
      <bibkey>laubli-etal-2018-machine</bibkey>
      <pwccode url="https://github.com/laeubli/parity" additional="false">laeubli/parity</pwccode>
    </paper>
    <paper id="518">
      <title>Learning Word Representations with Cross-Sentence Dependency for End-to-End Co-reference Resolution</title>
      <author><first>Hongyin</first><last>Luo</last></author>
      <author><first>Jim</first><last>Glass</last></author>
      <pages>4829–4833</pages>
      <url hash="2c5f2793">D18-1518</url>
      <abstract>In this work, we present a word embedding model that learns cross-sentence dependency for improving end-to-end co-reference resolution (E2E-CR). While the traditional E2E-CR model generates word representations by running long short-term memory (LSTM) recurrent neural networks on each sentence of an input article or conversation separately, we propose linear sentence linking and attentional sentence linking models to learn cross-sentence dependency. Both sentence linking strategies enable the LSTMs to make use of valuable information from context sentences while calculating the representation of the current input word. With this approach, the LSTMs learn <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> considering knowledge not only from the current sentence but also from the entire input document. Experiments show that learning cross-sentence dependency enriches information contained by the word representations, and improves the performance of the co-reference resolution model compared with our baseline.</abstract>
      <video href="https://vimeo.com/306126460" />
      <doi>10.18653/v1/D18-1518</doi>
      <bibkey>luo-glass-2018-learning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/ontonotes-5-0">OntoNotes 5.0</pwcdataset>
    </paper>
    <paper id="523">
      <title>Word Sense Induction with Neural biLM and Symmetric Patterns<fixed-case>LM</fixed-case> and Symmetric Patterns</title>
      <author><first>Asaf</first><last>Amrami</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>4860–4867</pages>
      <url hash="15cfcf0f">D18-1523</url>
      <abstract>An established method for Word Sense Induction (WSI) uses a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> to predict probable substitutes for target words, and induces senses by clustering these resulting substitute vectors. We replace the ngram-based language model (LM) with a recurrent one. Beyond being more accurate, the use of the recurrent LM allows us to effectively query it in a creative way, using what we call dynamic symmetric patterns. The combination of the RNN-LM and the dynamic symmetric patterns results in strong substitute vectors for WSI, allowing to surpass the current state-of-the-art on the SemEval 2013 WSI shared task by a large margin.</abstract>
      <doi>10.18653/v1/D18-1523</doi>
      <bibkey>amrami-goldberg-2018-word</bibkey>
      <pwccode url="https://github.com/asafamr/SymPatternWSI" additional="false">asafamr/SymPatternWSI</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2013">SemEval 2013</pwcdataset>
    </paper>
    <paper id="525">
      <title>Similarity-Based Reconstruction Loss for Meaning Representation</title>
      <author><first>Olga</first><last>Kovaleva</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <author><first>Alexey</first><last>Romanov</last></author>
      <pages>4875–4880</pages>
      <url hash="bf87a5de">D18-1525</url>
      <abstract>This paper addresses the problem of <a href="https://en.wikipedia.org/wiki/Representation_learning">representation learning</a>. Using an autoencoder framework, we propose and evaluate several <a href="https://en.wikipedia.org/wiki/Loss_function">loss functions</a> that can be used as an alternative to the commonly used cross-entropy reconstruction loss. The proposed <a href="https://en.wikipedia.org/wiki/Loss_function">loss functions</a> use similarities between words in the <a href="https://en.wikipedia.org/wiki/Glossary_of_computer_graphics">embedding space</a>, and can be used to train any neural model for <a href="https://en.wikipedia.org/wiki/Text_generator">text generation</a>. We show that the introduced <a href="https://en.wikipedia.org/wiki/Loss_function">loss functions</a> amplify semantic diversity of reconstructed sentences, while preserving the original meaning of the input. We test the derived autoencoder-generated representations on paraphrase detection and language inference tasks and demonstrate performance improvement compared to the traditional cross-entropy loss.</abstract>
      <doi>10.18653/v1/D18-1525</doi>
      <bibkey>kovaleva-etal-2018-similarity</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="526">
      <title>What can we learn from Semantic Tagging?</title>
      <author><first>Mostafa</first><last>Abdou</last></author>
      <author><first>Artur</first><last>Kulmizev</last></author>
      <author><first>Vinit</first><last>Ravishankar</last></author>
      <author><first>Lasha</first><last>Abzianidze</last></author>
      <author><first>Johan</first><last>Bos</last></author>
      <pages>4881–4889</pages>
      <url hash="a191683a">D18-1526</url>
      <attachment type="attachment" hash="c03d6312">D18-1526.Attachment.pdf</attachment>
      <abstract>We investigate the effects of <a href="https://en.wikipedia.org/wiki/Multi-task_learning">multi-task learning</a> using the recently introduced task of <a href="https://en.wikipedia.org/wiki/Tag_(metadata)">semantic tagging</a>. We employ semantic tagging as an auxiliary task for three different NLP tasks : <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>, Universal Dependency parsing, and <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">Natural Language Inference</a>. We compare full neural network sharing, partial neural network sharing, and what we term the learning what to share setting where negative transfer between tasks is less likely. Our findings show considerable improvements for all <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, particularly in the learning what to share setting which shows consistent gains across all tasks.</abstract>
      <doi>10.18653/v1/D18-1526</doi>
      <bibkey>abdou-etal-2018-learn</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="527">
      <title>Conditional Word Embedding and <a href="https://en.wikipedia.org/wiki/Hypothesis_testing">Hypothesis Testing</a> via Bayes-by-Backprop<fixed-case>B</fixed-case>ayes-by-Backprop</title>
      <author><first>Rujun</first><last>Han</last></author>
      <author><first>Michael</first><last>Gill</last></author>
      <author><first>Arthur</first><last>Spirling</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>4890–4895</pages>
      <url hash="6a19eec9">D18-1527</url>
      <attachment type="attachment" hash="3943bcdc">D18-1527.Attachment.pdf</attachment>
      <abstract>Conventional word embedding models do not leverage information from document meta-data, and they do not model <a href="https://en.wikipedia.org/wiki/Uncertainty">uncertainty</a>. We address these concerns with a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> that incorporates document covariates to estimate conditional word embedding distributions. Our model allows for (a) hypothesis tests about the meanings of terms, (b) assessments as to whether a word is near or far from another conditioned on different covariate values, and (c) assessments as to whether estimated differences are statistically significant.</abstract>
      <doi>10.18653/v1/D18-1527</doi>
      <bibkey>han-etal-2018-conditional</bibkey>
    </paper>
    <paper id="530">
      <title>Sanskrit Sandhi Splitting using seq2(seq)2<fixed-case>S</fixed-case>anskrit Sandhi Splitting using seq2(seq)2</title>
      <author><first>Rahul</first><last>Aralikatte</last></author>
      <author><first>Neelamadhav</first><last>Gantayat</last></author>
      <author><first>Naveen</first><last>Panwar</last></author>
      <author><first>Anush</first><last>Sankaran</last></author>
      <author><first>Senthil</first><last>Mani</last></author>
      <pages>4909–4914</pages>
      <url hash="e1fab2bd">D18-1530</url>
      <attachment type="attachment" hash="d99b3443">D18-1530.Attachment.zip</attachment>
      <abstract>In <a href="https://en.wikipedia.org/wiki/Sanskrit">Sanskrit</a>, small words (morphemes) are combined to form <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">compound words</a> through a process known as <a href="https://en.wikipedia.org/wiki/Sandhi">Sandhi</a>. Sandhi splitting is the process of splitting a given <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">compound word</a> into its constituent morphemes. Although <a href="https://en.wikipedia.org/wiki/Linguistic_prescription">rules</a> governing <a href="https://en.wikipedia.org/wiki/Word_splitting">word splitting</a> exists in the language, it is highly challenging to identify the location of the splits in a <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">compound word</a>. Though existing Sandhi splitting systems incorporate these pre-defined splitting rules, they have a low <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> as the same <a href="https://en.wikipedia.org/wiki/Compound_(linguistics)">compound word</a> might be broken down in multiple ways to provide syntactically correct splits. In this research, we propose a novel deep learning architecture called Double Decoder RNN (DD-RNN), which (i) predicts the location of the split(s) with 95 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, and (ii) predicts the constituent words (learning the Sandhi splitting rules) with 79.5 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, outperforming the <a href="https://en.wikipedia.org/wiki/State_of_the_art">state-of-art</a> by 20 %. Additionally, we show the generalization capability of our deep learning model, by showing competitive results in the problem of Chinese word segmentation, as well.</abstract>
      <doi>10.18653/v1/D18-1530</doi>
      <bibkey>aralikatte-etal-2018-sanskrit</bibkey>
    </paper>
    <paper id="531">
      <title>Unsupervised Neural Word Segmentation for <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a> via Segmental Language Modeling<fixed-case>C</fixed-case>hinese via Segmental Language Modeling</title>
      <author><first>Zhiqing</first><last>Sun</last></author>
      <author><first>Zhi-Hong</first><last>Deng</last></author>
      <pages>4915–4920</pages>
      <url hash="8dbd5a45">D18-1531</url>
      <abstract>Previous traditional approaches to unsupervised Chinese word segmentation (CWS) can be roughly classified into discriminative and generative models. The former uses the carefully designed goodness measures for candidate segmentation, while the latter focuses on finding the optimal segmentation of the highest generative probability. However, while there exists a trivial way to extend the <a href="https://en.wikipedia.org/wiki/Discriminative_model">discriminative models</a> into neural version by using neural language models, those of <a href="https://en.wikipedia.org/wiki/Generative_model">generative ones</a> are non-trivial. In this paper, we propose the segmental language models (SLMs) for CWS. Our approach explicitly focuses on the segmental nature of <a href="https://en.wikipedia.org/wiki/Chinese_language">Chinese</a>, as well as preserves several properties of <a href="https://en.wikipedia.org/wiki/Language_model">language models</a>. In SLMs, a context encoder encodes the previous context and a segment decoder generates each segment incrementally. As far as we know, we are the first to propose a neural model for unsupervised CWS and achieve competitive performance to the state-of-the-art statistical models on four different datasets from SIGHAN 2005 bakeoff.</abstract>
      <doi>10.18653/v1/D18-1531</doi>
      <bibkey>sun-deng-2018-unsupervised</bibkey>
      <pwccode url="https://github.com/Edward-Sun/SLM" additional="false">Edward-Sun/SLM</pwccode>
    </paper>
    <paper id="532">
      <title>LemmaTag : Jointly Tagging and <a href="https://en.wikipedia.org/wiki/Lemmatization">Lemmatizing</a> for Morphologically Rich Languages with BRNNs<fixed-case>L</fixed-case>emma<fixed-case>T</fixed-case>ag: Jointly Tagging and Lemmatizing for Morphologically Rich Languages with <fixed-case>BRNN</fixed-case>s</title>
      <author><first>Daniel</first><last>Kondratyuk</last></author>
      <author><first>Tomáš</first><last>Gavenčiak</last></author>
      <author><first>Milan</first><last>Straka</last></author>
      <author><first>Jan</first><last>Hajič</last></author>
      <pages>4921–4928</pages>
      <url hash="09483f27">D18-1532</url>
      <attachment type="attachment" hash="741ad562">D18-1532.Attachment.zip</attachment>
      <abstract>We present LemmaTag, a featureless neural network architecture that jointly generates part-of-speech tags and lemmas for sentences by using bidirectional RNNs with character-level and word-level embeddings. We demonstrate that both tasks benefit from sharing the encoding part of the <a href="https://en.wikipedia.org/wiki/Flow_network">network</a>, predicting tag subcategories, and using the tagger output as an input to the <a href="https://en.wikipedia.org/wiki/Lemmatizer">lemmatizer</a>. We evaluate our model across several languages with complex morphology, which surpasses state-of-the-art accuracy in both <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a> and <a href="https://en.wikipedia.org/wiki/Lemmatization">lemmatization</a> in <a href="https://en.wikipedia.org/wiki/Czech_language">Czech</a>, <a href="https://en.wikipedia.org/wiki/German_language">German</a>, and <a href="https://en.wikipedia.org/wiki/Arabic">Arabic</a>.</abstract>
      <doi>10.18653/v1/D18-1532</doi>
      <bibkey>kondratyuk-etal-2018-lemmatag</bibkey>
      <pwccode url="https://github.com/hyperparticle/LemmaTag" additional="false">hyperparticle/LemmaTag</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="533">
      <title>Recovering Missing Characters in Old Hawaiian Writing<fixed-case>H</fixed-case>awaiian Writing</title>
      <author><first>Brendan</first><last>Shillingford</last></author>
      <author><first>Oiwi</first><last>Parker Jones</last></author>
      <pages>4929–4934</pages>
      <url hash="ee1f402b">D18-1533</url>
      <attachment type="attachment" hash="1ae36c24">D18-1533.Attachment.pdf</attachment>
      <abstract>In contrast to the older writing system of the 19th century, modern Hawaiian orthography employs characters for <a href="https://en.wikipedia.org/wiki/Vowel_length">long vowels</a> and <a href="https://en.wikipedia.org/wiki/Glottal_stop">glottal stops</a>. These extra characters account for about one-third of the <a href="https://en.wikipedia.org/wiki/Phoneme">phonemes</a> in <a href="https://en.wikipedia.org/wiki/Hawaiian_language">Hawaiian</a>, so including them makes a big difference to <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a> and <a href="https://en.wikipedia.org/wiki/Pronunciation">pronunciation</a>. However, <a href="https://en.wikipedia.org/wiki/Transliteration">transliterating</a> between older and newer texts is a laborious task when performed manually. We introduce two related methods to help solve this <a href="https://en.wikipedia.org/wiki/Transliteration">transliteration problem</a> automatically. One approach is implemented, end-to-end, using finite state transducers (FSTs). The other is a hybrid deep learning approach, which approximately composes an FST with a recurrent neural network language model.</abstract>
      <doi>10.18653/v1/D18-1533</doi>
      <bibkey>shillingford-parker-jones-2018-recovering</bibkey>
    </paper>
    <paper id="535">
      <title>Bridging Knowledge Gaps in Neural Entailment via Symbolic Models</title>
      <author><first>Dongyeop</first><last>Kang</last></author>
      <author><first>Tushar</first><last>Khot</last></author>
      <author><first>Ashish</first><last>Sabharwal</last></author>
      <author><first>Peter</first><last>Clark</last></author>
      <pages>4940–4945</pages>
      <url hash="37634c4b">D18-1535</url>
      <attachment type="attachment" hash="b3701c4f">D18-1535.Attachment.pdf</attachment>
      <abstract>Most textual entailment models focus on lexical gaps between the premise text and the hypothesis, but rarely on knowledge gaps. We focus on filling these knowledge gaps in the Science Entailment task, by leveraging an external structured knowledge base (KB) of science facts. Our new <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> combines standard neural entailment models with a knowledge lookup module. To facilitate this lookup, we propose a fact-level decomposition of the hypothesis, and verifying the resulting sub-facts against both the textual premise and the structured KB. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, NSNet, learns to aggregate predictions from these heterogeneous data formats. On the SciTail dataset, NSNet outperforms a simpler combination of the two predictions by 3 % and the base entailment model by 5 %.</abstract>
      <doi>10.18653/v1/D18-1535</doi>
      <bibkey>kang-etal-2018-bridging</bibkey>
    </paper>
    <paper id="536">
      <title>The BQ Corpus : A Large-scale Domain-specific Chinese Corpus For Sentence Semantic Equivalence Identification<fixed-case>BQ</fixed-case> Corpus: A Large-scale Domain-specific <fixed-case>C</fixed-case>hinese Corpus For Sentence Semantic Equivalence Identification</title>
      <author><first>Jing</first><last>Chen</last></author>
      <author><first>Qingcai</first><last>Chen</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Haijun</first><last>Yang</last></author>
      <author><first>Daohe</first><last>Lu</last></author>
      <author><first>Buzhou</first><last>Tang</last></author>
      <pages>4946–4951</pages>
      <url hash="dd29a2df">D18-1536</url>
      <abstract>This paper introduces the Bank Question (BQ) corpus, a Chinese corpus for sentence semantic equivalence identification (SSEI). The BQ corpus contains 120,000 question pairs from 1-year online bank custom service logs. To efficiently process and annotate questions from such a large scale of logs, this paper proposes a clustering based annotation method to achieve questions with the same intent. First, the deduplicated questions with the same answer are clustered into stacks by the Word Mover’s Distance (WMD) based Affinity Propagation (AP) algorithm. Then, the annotators are asked to assign the clustered questions into different intent categories. Finally, the positive and negative question pairs for SSEI are selected in the same intent category and between different intent categories respectively. We also present six SSEI benchmark performance on our <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a>, including state-of-the-art algorithms. As the largest manually annotated public Chinese SSEI corpus in the bank domain, the BQ corpus is not only useful for Chinese question semantic matching research, but also a significant resource for cross-lingual and cross-domain SSEI research. The <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">corpus</a> is available in public.</abstract>
      <doi>10.18653/v1/D18-1536</doi>
      <bibkey>chen-etal-2018-bq</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/pit">PIT</pwcdataset>
    </paper>
    <paper id="537">
      <title>Interpreting Recurrent and Attention-Based Neural Models : a Case Study on Natural Language Inference</title>
      <author><first>Reza</first><last>Ghaeini</last></author>
      <author><first>Xiaoli</first><last>Fern</last></author>
      <author><first>Prasad</first><last>Tadepalli</last></author>
      <pages>4952–4957</pages>
      <url hash="f9ed715b">D18-1537</url>
      <attachment type="attachment" hash="67549907">D18-1537.Attachment.zip</attachment>
      <abstract>Deep learning models have achieved remarkable success in natural language inference (NLI) tasks. While these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> are widely explored, they are hard to interpret and it is often unclear how and why they actually work. In this paper, we take a step toward explaining such deep learning based models through a case study on a popular neural model for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLI</a>. In particular, we propose to interpret the intermediate layers of NLI models by visualizing the <a href="https://en.wikipedia.org/wiki/Salience_(neuroscience)">saliency of attention</a> and LSTM gating signals. We present several examples for which our methods are able to reveal interesting insights and identify the critical information contributing to the model decisions.</abstract>
      <doi>10.18653/v1/D18-1537</doi>
      <bibkey>ghaeini-etal-2018-interpreting</bibkey>
    </paper>
    <paper id="539">
      <title>Identifying Domain Adjacent Instances for Semantic Parsers</title>
      <author><first>James</first><last>Ferguson</last></author>
      <author><first>Janara</first><last>Christensen</last></author>
      <author><first>Edward</first><last>Li</last></author>
      <author><first>Edgar</first><last>Gonzàlez</last></author>
      <pages>4964–4969</pages>
      <url hash="c8df40e0">D18-1539</url>
      <abstract>When the <a href="https://en.wikipedia.org/wiki/Semantics">semantics</a> of a sentence are not representable in a <a href="https://en.wikipedia.org/wiki/Semantic_parser">semantic parser</a>’s output schema, <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> will inevitably fail. Detection of these instances is commonly treated as an out-of-domain classification problem. However, there is also a more subtle scenario in which the test data is drawn from the same domain. In addition to formalizing this problem of domain-adjacency, we present a comparison of various baselines that could be used to solve it. We also propose a new simple <a href="https://en.wikipedia.org/wiki/Sentence_(linguistics)">sentence representation</a> that emphasizes words which are unexpected. This approach improves the performance of a downstream semantic parser run on in-domain and domain-adjacent instances.</abstract>
      <doi>10.18653/v1/D18-1539</doi>
      <bibkey>ferguson-etal-2018-identifying</bibkey>
    </paper>
    <paper id="540">
      <title>Mapping <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language commands</a> to web elements</title>
      <author><first>Panupong</first><last>Pasupat</last></author>
      <author><first>Tian-Shun</first><last>Jiang</last></author>
      <author><first>Evan</first><last>Liu</last></author>
      <author><first>Kelvin</first><last>Guu</last></author>
      <author><first>Percy</first><last>Liang</last></author>
      <pages>4970–4976</pages>
      <url hash="3b714abd">D18-1540</url>
      <abstract>The <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a> provides a rich, open-domain environment with textual, structural, and spatial properties. We propose a new <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> for grounding language in this environment : given a natural language command (e.g., click on the second article), choose the correct element on the web page (e.g., a hyperlink or text box). We collected a <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> of over 50,000 <a href="https://en.wikipedia.org/wiki/Command_(computing)">commands</a> that capture various phenomena such as functional references (e.g. find who made this site), relational reasoning (e.g. article by john), and <a href="https://en.wikipedia.org/wiki/Visual_reasoning">visual reasoning</a> (e.g. top-most article). We also implemented and analyzed three baseline models that capture different phenomena present in the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a>.</abstract>
      <doi>10.18653/v1/D18-1540</doi>
      <bibkey>pasupat-etal-2018-mapping</bibkey>
      <pwccode url="https://github.com/stanfordnlp/phrasenode" additional="true">stanfordnlp/phrasenode</pwccode>
    </paper>
    <paper id="541">
      <title>Wronging a Right : Generating Better Errors to Improve Grammatical Error Detection</title>
      <author><first>Sudhanshu</first><last>Kasewa</last></author>
      <author><first>Pontus</first><last>Stenetorp</last></author>
      <author><first>Sebastian</first><last>Riedel</last></author>
      <pages>4977–4983</pages>
      <url hash="95100892">D18-1541</url>
      <abstract>Grammatical error correction, like other machine learning tasks, greatly benefits from large quantities of high quality training data, which is typically expensive to produce. While writing a program to automatically generate realistic <a href="https://en.wikipedia.org/wiki/Grammatical_error">grammatical errors</a> would be difficult, one could learn the distribution of naturally-occurring errors and attempt to introduce them into other <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. Initial work on inducing errors in this way using <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation">statistical machine translation</a> has shown promise ; we investigate cheaply constructing synthetic samples, given a small corpus of human-annotated data, using an off-the-rack attentive sequence-to-sequence model and a straight-forward post-processing procedure. Our approach yields error-filled artificial data that helps a vanilla bi-directional LSTM to outperform the previous state of the art at grammatical error detection, and a previously introduced model to gain further improvements of over 5 % F0.5 score. When attempting to determine if a given sentence is synthetic, a human annotator at best achieves 39.39 F1 score, indicating that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> generates mostly <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-like instances</a>.</abstract>
      <doi>10.18653/v1/D18-1541</doi>
      <bibkey>kasewa-etal-2018-wronging</bibkey>
      <pwccode url="https://github.com/skasewa/wronging" additional="false">skasewa/wronging</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fce">FCE</pwcdataset>
    </paper>
    <paper id="542">
      <title>Modeling Input Uncertainty in Neural Network Dependency Parsing</title>
      <author><first>Rob</first><last>van der Goot</last></author>
      <author><first>Gertjan</first><last>van Noord</last></author>
      <pages>4984–4991</pages>
      <url hash="3fba5307">D18-1542</url>
      <attachment type="attachment" hash="426c1a8b">D18-1542.Attachment.pdf</attachment>
      <abstract>Recently introduced neural network parsers allow for new approaches to circumvent data sparsity issues by modeling character level information and by exploiting raw data in a semi-supervised setting. Data sparsity is especially prevailing when transferring to <a href="https://en.wikipedia.org/wiki/Standardization">non-standard domains</a>. In this setting, lexical normalization has often been used in the past to circumvent data sparsity. In this paper, we investigate whether these new neural approaches provide similar functionality as lexical normalization, or whether they are complementary. We provide experimental results which show that a separate normalization component improves performance of a neural network parser even if it has access to character level information as well as external word embeddings. Further improvements are obtained by a straightforward but novel approach in which the top-N best candidates provided by the <a href="https://en.wikipedia.org/wiki/Parsing">normalization component</a> are available to the <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>.</abstract>
      <doi>10.18653/v1/D18-1542</doi>
      <bibkey>van-der-goot-van-noord-2018-modeling</bibkey>
      <pwccode url="https://bitbucket.org/robvanderg/normpar" additional="false">robvanderg/normpar</pwccode>
    </paper>
    <paper id="543">
      <title>Parameter sharing between dependency parsers for related languages</title>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Johannes</first><last>Bjerva</last></author>
      <author><first>Isabelle</first><last>Augenstein</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>4992–4997</pages>
      <url hash="acc741c2">D18-1543</url>
      <attachment type="attachment" hash="3aa1858a">D18-1543.Attachment.pdf</attachment>
      <abstract>Previous work has suggested that parameter sharing between transition-based neural dependency parsers for related languages can lead to better performance, but there is no consensus on what parameters to share. We present an evaluation of 27 different parameter sharing strategies across 10 languages, representing five pairs of related languages, each pair from a different <a href="https://en.wikipedia.org/wiki/Language_family">language family</a>. We find that sharing transition classifier parameters always helps, whereas the usefulness of sharing word and/or character LSTM parameters varies. Based on this result, we propose an architecture where the transition classifier is shared, and the sharing of word and character parameters is controlled by a parameter that can be tuned on validation data. This <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> is linguistically motivated and obtains significant improvements over a monolingually trained baseline. We also find that sharing transition classifier parameters helps when training a <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> on unrelated language pairs, but we find that, in the case of unrelated languages, sharing too many parameters does not help.</abstract>
      <attachment type="poster" hash="7d484185">D18-1543.Poster.pdf</attachment>
      <doi>10.18653/v1/D18-1543</doi>
      <bibkey>de-lhoneux-etal-2018-parameter</bibkey>
      <pwccode url="https://github.com/coastalcph/uuparser" additional="false">coastalcph/uuparser</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="544">
      <title>Grammar Induction with Neural Language Models : An Unusual Replication</title>
      <author><first>Phu Mon</first><last>Htut</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Samuel</first><last>Bowman</last></author>
      <pages>4998–5003</pages>
      <url hash="c3ef8822">D18-1544</url>
      <attachment type="attachment" hash="7fc47f98">D18-1544.Attachment.zip</attachment>
      <abstract>A substantial thread of recent work on latent tree learning has attempted to develop neural network models with parse-valued latent variables and train them on non-parsing tasks, in the hope of having them discover interpretable tree structure. In a recent paper, Shen et al. (2018) introduce such a model and report near-state-of-the-art results on the target task of <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a>, and the first strong latent tree learning result on constituency parsing. In an attempt to reproduce these results, we discover issues that make the original results hard to trust, including tuning and even training on what is effectively the test set. Here, we attempt to reproduce these results in a fair experiment and to extend them to two new datasets. We find that the results of this work are robust : All variants of the model under study outperform all latent tree learning baselines, and perform competitively with symbolic grammar induction systems. We find that this model represents the first empirical success for latent tree learning, and that neural network language modeling warrants further study as a setting for <a href="https://en.wikipedia.org/wiki/Grammar_induction">grammar induction</a>.</abstract>
      <doi>10.18653/v1/D18-1544</doi>
      <bibkey>htut-etal-2018-grammar</bibkey>
    </paper>
    <paper id="545">
      <title>Data Augmentation via Dependency Tree Morphing for Low-Resource Languages</title>
      <author><first>Gözde Gül</first><last>Şahin</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>5004–5009</pages>
      <url hash="26b9ff10">D18-1545</url>
      <abstract>Neural NLP systems achieve high scores in the presence of sizable training dataset. Lack of such <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a> leads to poor <a href="https://en.wikipedia.org/wiki/System">system</a> performances in the case low-resource languages. We present two simple text augmentation techniques using dependency trees, inspired from <a href="https://en.wikipedia.org/wiki/Digital_image_processing">image processing</a>. We crop sentences by removing dependency links, and we rotate sentences by moving the tree fragments around the root. We apply these techniques to augment the training sets of low-resource languages in Universal Dependencies project. We implement a character-level sequence tagging model and evaluate the augmented datasets on part-of-speech tagging task. We show that <a href="https://en.wikipedia.org/wiki/Crop_factor">crop</a> and rotate provides improvements over the <a href="https://en.wikipedia.org/wiki/Statistical_model">models</a> trained with non-augmented data for majority of the languages, especially for languages with rich case marking systems.</abstract>
      <doi>10.18653/v1/D18-1545</doi>
      <bibkey>sahin-steedman-2018-data</bibkey>
      <pwccode url="https://github.com/gozdesahin/crop-rotate-augment" additional="true">gozdesahin/crop-rotate-augment</pwccode>
    </paper>
    <paper id="546">
      <title>How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks</title>
      <author><first>Divyansh</first><last>Kaushik</last></author>
      <author><first>Zachary C.</first><last>Lipton</last></author>
      <pages>5010–5015</pages>
      <url hash="b37e408a">D18-1546</url>
      <abstract>Many recent papers address <a href="https://en.wikipedia.org/wiki/Reading_comprehension">reading comprehension</a>, where examples consist of (question, passage, answer) tuples. Presumably, a <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> must combine information from both questions and passages to predict corresponding answers. However, despite intense interest in the topic, with hundreds of published papers vying for leaderboard dominance, basic questions about the difficulty of many popular benchmarks remain unanswered. In this paper, we establish sensible baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding that question- and passage-only models often perform surprisingly well. On 14 out of 20 bAbI tasks, passage-only models achieve greater than 50 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a>, sometimes matching the full <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>. Interestingly, while <a href="https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy">CBT</a> provides 20-sentence passages, only the last is needed for accurate prediction. By comparison, SQuAD and <a href="https://en.wikipedia.org/wiki/CNN">CNN</a> appear better-constructed.</abstract>
      <video href="https://vimeo.com/306140720" />
      <doi>10.18653/v1/D18-1546</doi>
      <bibkey>kaushik-lipton-2018-much</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cbt">CBT</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/who-did-what">Who-did-What</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="547">
      <title>MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling<fixed-case>M</fixed-case>ulti<fixed-case>WOZ</fixed-case> - A Large-Scale Multi-Domain <fixed-case>W</fixed-case>izard-of-<fixed-case>O</fixed-case>z Dataset for Task-Oriented Dialogue Modelling</title>
      <author><first>Paweł</first><last>Budzianowski</last></author>
      <author><first>Tsung-Hsien</first><last>Wen</last></author>
      <author><first>Bo-Hsiang</first><last>Tseng</last></author>
      <author><first>Iñigo</first><last>Casanueva</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Osman</first><last>Ramadan</last></author>
      <author><first>Milica</first><last>Gašić</last></author>
      <pages>5016–5026</pages>
      <url hash="22a4ee89">D18-1547</url>
      <attachment type="attachment" hash="ab7f5f03">D18-1547.Attachment.pdf</attachment>
      <abstract>Even though <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning</a> has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available. To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The contribution of this work apart from the open-sourced dataset is two-fold : firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowd-sourcing</a> without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.</abstract>
      <video href="https://vimeo.com/306141298" />
      <doi>10.18653/v1/D18-1547</doi>
      <bibkey>budzianowski-etal-2018-multiwoz</bibkey>
      <pwccode url="https://github.com/budzianowski/multiwoz" additional="false">budzianowski/multiwoz</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/dialogue-state-tracking-challenge">Dialogue State Tracking Challenge</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wizard-of-oz">Wizard-of-Oz</pwcdataset>
    </paper>
    <paper id="548">
      <title>Linguistically-Informed Self-Attention for Semantic Role Labeling</title>
      <author><first>Emma</first><last>Strubell</last></author>
      <author><first>Patrick</first><last>Verga</last></author>
      <author><first>Daniel</first><last>Andor</last></author>
      <author><first>David</first><last>Weiss</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>5027–5038</pages>
      <url hash="162cbf0a">D18-1548</url>
      <attachment type="attachment" hash="8f61ab5a">D18-1548.Attachment.pdf</attachment>
      <abstract>Current state-of-the-art semantic role labeling (SRL) uses a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural network</a> with no explicit linguistic features. However, prior work has shown that gold syntax trees can dramatically improve SRL decoding, suggesting the possibility of increased accuracy from explicit modeling of syntax. In this work, we present linguistically-informed self-attention (LISA): a neural network model that combines multi-head self-attention with multi-task learning across dependency parsing, <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tagging</a>, predicate detection and <a href="https://en.wikipedia.org/wiki/Speech_recognition">SRL</a>. Unlike previous models which require significant pre-processing to prepare linguistic features, LISA can incorporate <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> using merely raw tokens as input, encoding the sequence only once to simultaneously perform <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a>, predicate detection and role labeling for all predicates. Syntax is incorporated by training one <a href="https://en.wikipedia.org/wiki/Head_(linguistics)">attention head</a> to attend to syntactic parents for each token. Moreover, if a high-quality syntactic parse is already available, it can be beneficially injected at test time without re-training our SRL model. In experiments on CoNLL-2005 SRL, LISA achieves new state-of-the-art performance for a model using predicted predicates and standard <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, attaining 2.5 F1 absolute higher than the previous state-of-the-art on <a href="https://en.wikipedia.org/wiki/News_agency">newswire</a> and more than 3.5 F1 on out-of-domain data, nearly 10 % reduction in error. On ConLL-2012 English SRL we also show an improvement of more than 2.5 F1.</abstract>
      <video href="https://vimeo.com/306141078" />
      <doi>10.18653/v1/D18-1548</doi>
      <bibkey>strubell-etal-2018-linguistically</bibkey>
      <pwccode url="https://github.com/strubell/LISA" additional="false">strubell/LISA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2012-1">CoNLL-2012</pwcdataset>
    </paper>
    </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</booktitle>
      <url hash="2f1b5b55">D18-2</url>
      <editor><first>Eduardo</first><last>Blanco</last></editor>
      <editor><first>Wei</first><last>Lu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Brussels, Belgium</address>
      <month>November</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="2fa595ab">D18-2000</url>
      <bibkey>emnlp-2018-2018-empirical</bibkey>
    </frontmatter>
    <paper id="1">
      <title>SyntaViz : Visualizing Voice Queries through a Syntax-Driven Hierarchical Ontology<fixed-case>S</fixed-case>ynta<fixed-case>V</fixed-case>iz: Visualizing Voice Queries through a Syntax-Driven Hierarchical Ontology</title>
      <author><first>Md Iftekhar</first><last>Tanveer</last></author>
      <author><first>Ferhan</first><last>Ture</last></author>
      <pages>1–6</pages>
      <url hash="dd7e0e3f">D18-2001</url>
      <abstract>This paper describes SyntaViz, a visualization interface specifically designed for analyzing natural-language queries that were created by users of a voice-enabled product. SyntaViz provides a platform for browsing the ontology of user queries from a syntax-driven perspective, providing quick access to high-impact failure points of the existing intent understanding system and evidence for data-driven decisions in the development cycle. A case study on Xfinity X1 (a voice-enabled entertainment platform from Comcast) reveals that SyntaViz helps developers identify multiple action items in a short amount of time without any special training. SyntaViz has been open-sourced for the benefit of the community.</abstract>
      <doi>10.18653/v1/D18-2001</doi>
      <bibkey>tanveer-ture-2018-syntaviz</bibkey>
      <pwccode url="https://github.com/Comcast/SyntaViz" additional="false">Comcast/SyntaViz</pwccode>
    </paper>
    <paper id="5">
      <title>MorAz : an Open-source Morphological Analyzer for Azerbaijani Turkish<fixed-case>M</fixed-case>or<fixed-case>A</fixed-case>z: an Open-source Morphological Analyzer for <fixed-case>A</fixed-case>zerbaijani <fixed-case>T</fixed-case>urkish</title>
      <author><first>Berke</first><last>Özenç</last></author>
      <author><first>Razieh</first><last>Ehsani</last></author>
      <author><first>Ercan</first><last>Solak</last></author>
      <pages>25–29</pages>
      <url hash="4fcedcb9">D18-2005</url>
      <revision id="1" href="D18-2005v1" hash="0ed3d732" />
      <revision id="2" href="D18-2005v2" hash="4fcedcb9">No description of the changes were recorded.</revision>
      <abstract>MorAz is an open-source <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological analyzer</a> for <a href="https://en.wikipedia.org/wiki/Azerbaijani_language">Azerbaijani Turkish</a>. The analyzer is available through both as a website for interactive exploration and as a <a href="https://en.wikipedia.org/wiki/Representational_state_transfer">RESTful web service</a> for integration into a <a href="https://en.wikipedia.org/wiki/Pipeline_(software)">natural language processing pipeline</a>. MorAz implements the <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphology</a> of <a href="https://en.wikipedia.org/wiki/Azerbaijani_language">Azerbaijani Turkish</a> in two-level using Helsinki finite-state transducer and wraps the analyzer with python scripts in a Django instance.</abstract>
      <doi>10.18653/v1/D18-2005</doi>
      <bibkey>ozenc-etal-2018-moraz</bibkey>
    </paper>
    <paper id="7">
      <title>Visual Interrogation of Attention-Based Models for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">Natural Language Inference</a> and Machine Comprehension</title>
      <author><first>Shusen</first><last>Liu</last></author>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Zhimin</first><last>Li</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <author><first>Valerio</first><last>Pascucci</last></author>
      <author><first>Peer-Timo</first><last>Bremer</last></author>
      <pages>36–41</pages>
      <url hash="6551e668">D18-2007</url>
      <abstract>Neural networks models have gained unprecedented popularity in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> due to their state-of-the-art performance and the flexible end-to-end training scheme. Despite their advantages, the lack of interpretability hinders the deployment and refinement of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>. In this work, we present a flexible visualization library for creating customized visual analytic environments, in which the user can investigate and interrogate the relationships among the input, the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model internals</a> (i.e., <a href="https://en.wikipedia.org/wiki/Attentional_control">attention</a>), and the output predictions, which in turn shed light on the <a href="https://en.wikipedia.org/wiki/Decision-making_software">model decision-making process</a>.</abstract>
      <doi>10.18653/v1/D18-2007</doi>
      <bibkey>liu-etal-2018-visual</bibkey>
    </paper>
    <paper id="8">
      <title>DERE : A Task and Domain-Independent Slot Filling Framework for Declarative Relation Extraction<fixed-case>DERE</fixed-case>: A Task and Domain-Independent Slot Filling Framework for Declarative Relation Extraction</title>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Laura Ana Maria</first><last>Bostan</last></author>
      <author><first>Sean</first><last>Papay</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>42–47</pages>
      <url hash="711cb4bb">D18-2008</url>
      <abstract>Most <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning systems</a> for <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> are tailored to specific tasks. As a result, comparability of <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> across tasks is missing and their applicability to new tasks is limited. This affects end users without machine learning experience as well as model developers. To address these limitations, we present DERE, a novel <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for declarative specification and compilation of template-based information extraction. It uses a generic <a href="https://en.wikipedia.org/wiki/Specification_language">specification language</a> for the task and for data annotations in terms of spans and <a href="https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)">frames</a>. This formalism enables the representation of a large variety of natural language processing challenges. The <a href="https://en.wikipedia.org/wiki/Front_and_back_ends">backend</a> can be instantiated by different <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>, following different paradigms. The clear separation of frame specification and <a href="https://en.wikipedia.org/wiki/Modeling_language">model backend</a> will ease the implementation of new <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> and the evaluation of different <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> across different tasks. Furthermore, it simplifies <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a>, joint learning across tasks and/or domains as well as the assessment of model generalizability. DERE is available as open-source software.</abstract>
      <doi>10.18653/v1/D18-2008</doi>
      <bibkey>adel-etal-2018-dere</bibkey>
    </paper>
    <paper id="9">
      <title>Demonstrating Par4Sem-A Semantic Writing Aid with Adaptive Paraphrasing<fixed-case>P</fixed-case>ar4<fixed-case>S</fixed-case>em - A Semantic Writing Aid with Adaptive Paraphrasing</title>
      <author><first>Seid Muhie</first><last>Yimam</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>48–53</pages>
      <url hash="c81ea894">D18-2009</url>
      <abstract>In this paper, we present Par4Sem, a semantic writing aid tool based on adaptive paraphrasing. Unlike many annotation tools that are primarily used to collect training examples, Par4Sem is integrated into a real word application, in this case a writing aid tool, in order to collect training examples from usage data. Par4Sem is a tool, which supports an adaptive, iterative, and interactive process where the underlying <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> are updated for each iteration using new training examples from usage data. After motivating the use of ever-learning tools in NLP applications, we evaluate Par4Sem by adopting it to a text simplification task through mere usage.</abstract>
      <doi>10.18653/v1/D18-2009</doi>
      <bibkey>yimam-biemann-2018-demonstrating</bibkey>
    </paper>
    <paper id="10">
      <title>Juman++ : A Morphological Analysis Toolkit for Scriptio Continua<fixed-case>J</fixed-case>uman++: A Morphological Analysis Toolkit for Scriptio Continua</title>
      <author><first>Arseny</first><last>Tolmachev</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>54–59</pages>
      <url hash="8a150617">D18-2010</url>
      <abstract>We present a three-part toolkit for developing <a href="https://en.wikipedia.org/wiki/Morphology_(linguistics)">morphological analyzers</a> for languages without natural word boundaries. The first part is a C++11/14 lattice-based morphological analysis library that uses a combination of linear and recurrent neural net language models for analysis. The other parts are a tool for exposing problems in the trained <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> and a partial annotation tool. Our morphological analyzer of <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a> achieves new SOTA on Jumandic-based corpora while being 250 times faster than the previous one. We also perform a small experiment and quantitive analysis and experience of using <a href="https://en.wikipedia.org/wiki/Programming_tool">development tools</a>. All <a href="https://en.wikipedia.org/wiki/Component-based_software_engineering">components</a> of the <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a> is open source and available under a permissive Apache 2 License.</abstract>
      <doi>10.18653/v1/D18-2010</doi>
      <bibkey>tolmachev-etal-2018-juman</bibkey>
      <pwccode url="https://github.com/ku-nlp/jumanpp" additional="false">ku-nlp/jumanpp</pwccode>
    </paper>
    <paper id="12">
      <title>SentencePiece : A simple and language independent subword tokenizer and detokenizer for Neural Text Processing<fixed-case>S</fixed-case>entence<fixed-case>P</fixed-case>iece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</title>
      <author><first>Taku</first><last>Kudo</last></author>
      <author><first>John</first><last>Richardson</last></author>
      <pages>66–71</pages>
      <url hash="df57cd89">D18-2012</url>
      <abstract>This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">Neural Machine Translation</a>. It provides open-source <a href="https://en.wikipedia.org/wiki/C++">C++</a> and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and find that it is possible to achieve comparable <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various configurations. SentencePiece is available under the Apache 2 license at.<url>https://github.com/google/sentencepiece</url>.</abstract>
      <doi>10.18653/v1/D18-2012</doi>
      <bibkey>kudo-richardson-2018-sentencepiece</bibkey>
    </paper>
    <paper id="13">
      <title>CogCompTime : A Tool for Understanding Time in <a href="https://en.wikipedia.org/wiki/Natural_language">Natural Language</a><fixed-case>C</fixed-case>og<fixed-case>C</fixed-case>omp<fixed-case>T</fixed-case>ime: A Tool for Understanding Time in Natural Language</title>
      <author><first>Qiang</first><last>Ning</last></author>
      <author><first>Ben</first><last>Zhou</last></author>
      <author><first>Zhili</first><last>Feng</last></author>
      <author><first>Haoruo</first><last>Peng</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>72–77</pages>
      <url hash="59570264">D18-2013</url>
      <abstract>Automatic extraction of temporal information is important for <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language understanding</a>. It involves two basic <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> : (1) Understanding time expressions that are mentioned explicitly in text (e.g., February 27, 1998 or tomorrow), and (2) Understanding <a href="https://en.wikipedia.org/wiki/Time">temporal information</a> that is conveyed implicitly via <a href="https://en.wikipedia.org/wiki/Binary_relation">relations</a>. This paper introduces CogCompTime, a <a href="https://en.wikipedia.org/wiki/System">system</a> that has these two important functionalities. It incorporates the most recent progress, achieves state-of-the-art performance, and is publicly available at.<url>http://cogcomp.org/page/publication_view/844</url>.</abstract>
      <doi>10.18653/v1/D18-2013</doi>
      <bibkey>ning-etal-2018-cogcomptime</bibkey>
    </paper>
    <paper id="14">
      <title>A Multilingual Information Extraction Pipeline for Investigative Journalism</title>
      <author><first>Gregor</first><last>Wiedemann</last></author>
      <author><first>Seid Muhie</first><last>Yimam</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>78–83</pages>
      <url hash="a2b3d191">D18-2014</url>
      <abstract>We introduce an advanced information extraction pipeline to automatically process very large collections of <a href="https://en.wikipedia.org/wiki/Unstructured_data">unstructured textual data</a> for the purpose of <a href="https://en.wikipedia.org/wiki/Investigative_journalism">investigative journalism</a>. The <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a> serves as a new input processor for the upcoming major release of our New / s / leak 2.0 software, which we develop in cooperation with a large German news organization. The use case is that journalists receive a large collection of files up to several Gigabytes containing unknown contents. Collections may originate either from official disclosures of documents, e.g. Freedom of Information Act requests, or unofficial data leaks.</abstract>
      <doi>10.18653/v1/D18-2014</doi>
      <bibkey>wiedemann-etal-2018-multilingual</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/polyglot-ner">Polyglot-NER</pwcdataset>
    </paper>
    <paper id="16">
      <title>KT-Speech-Crawler : Automatic Dataset Construction for <a href="https://en.wikipedia.org/wiki/Speech_recognition">Speech Recognition</a> from YouTube Videos<fixed-case>KT</fixed-case>-Speech-Crawler: Automatic Dataset Construction for Speech Recognition from <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Videos</title>
      <author><first>Egor</first><last>Lakomkin</last></author>
      <author><first>Sven</first><last>Magg</last></author>
      <author><first>Cornelius</first><last>Weber</last></author>
      <author><first>Stefan</first><last>Wermter</last></author>
      <pages>90–95</pages>
      <url hash="32ab2e78">D18-2016</url>
      <abstract>We describe KT-Speech-Crawler : an approach for automatic dataset construction for <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> by crawling <a href="https://en.wikipedia.org/wiki/YouTube">YouTube videos</a>. We outline several filtering and post-processing steps, which extract samples that can be used for training end-to-end neural speech recognition systems. In our experiments, we demonstrate that a single-core version of the <a href="https://en.wikipedia.org/wiki/Web_crawler">crawler</a> can obtain around 150 hours of <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">transcribed speech</a> within a day, containing an estimated 3.5 % <a href="https://en.wikipedia.org/wiki/Word_error_rate">word error rate</a> in the <a href="https://en.wikipedia.org/wiki/Transcription_(linguistics)">transcriptions</a>. Automatically collected samples contain reading and spontaneous speech recorded in various conditions including background noise and music, distant microphone recordings, and a variety of <a href="https://en.wikipedia.org/wiki/Accent_(sociolinguistics)">accents</a> and <a href="https://en.wikipedia.org/wiki/Reverberation">reverberation</a>. When training a <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural network</a> on <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a>, we observed around 40 % word error rate reduction on the Wall Street Journal dataset by integrating 200 hours of the collected samples into the training set.</abstract>
      <doi>10.18653/v1/D18-2016</doi>
      <bibkey>lakomkin-etal-2018-kt</bibkey>
      <pwccode url="https://github.com/EgorLakomkin/KTSpeechCrawler" additional="false">EgorLakomkin/KTSpeechCrawler</pwccode>
    </paper>
    <paper id="18">
      <title>An Interface for Annotating Science Questions</title>
      <author><first>Michael</first><last>Boratko</last></author>
      <author><first>Harshit</first><last>Padigela</last></author>
      <author><first>Divyendra</first><last>Mikkilineni</last></author>
      <author><first>Pritish</first><last>Yuvraj</last></author>
      <author><first>Rajarshi</first><last>Das</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <author><first>Maria</first><last>Chang</last></author>
      <author><first>Achille</first><last>Fokoue</last></author>
      <author><first>Pavan</first><last>Kapanipathi</last></author>
      <author><first>Nicholas</first><last>Mattei</last></author>
      <author><first>Ryan</first><last>Musa</last></author>
      <author><first>Kartik</first><last>Talamadupula</last></author>
      <author><first>Michael</first><last>Witbrock</last></author>
      <pages>102–107</pages>
      <url hash="68fea77f">D18-2018</url>
      <abstract>Recent work introduces the AI2 Reasoning Challenge (ARC) and the associated ARC dataset that partitions open domain, complex science questions into an Easy Set and a Challenge Set. That work includes an analysis of 100 questions with respect to the types of knowledge and reasoning required to answer them. However, it does not include clear definitions of these types, nor does it offer information about the quality of the labels or the annotation process used. In this paper, we introduce a novel interface for human annotation of science question-answer pairs with their respective knowledge and reasoning types, in order that the classification of new questions may be improved. We build on the classification schema proposed by prior work on the ARC dataset, and evaluate the effectiveness of our interface with a preliminary study involving 10 participants.</abstract>
      <doi>10.18653/v1/D18-2018</doi>
      <bibkey>boratko-etal-2018-interface</bibkey>
    </paper>
    <paper id="19">
      <title>APLenty : annotation tool for creating high-quality datasets using active and proactive learning<fixed-case>APL</fixed-case>enty: annotation tool for creating high-quality datasets using active and proactive learning</title>
      <author><first>Minh-Quoc</first><last>Nghiem</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>108–113</pages>
      <url hash="74309ae7">D18-2019</url>
      <abstract>In this paper, we present APLenty, an annotation tool for creating high-quality sequence labeling datasets using active and proactive learning. A major innovation of our tool is the integration of automatic annotation with <a href="https://en.wikipedia.org/wiki/Active_learning">active learning</a> and <a href="https://en.wikipedia.org/wiki/Proactive_learning">proactive learning</a>. This makes the task of creating labeled datasets easier, less time-consuming and requiring less human effort. APLenty is highly flexible and can be adapted to various other <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>.</abstract>
      <doi>10.18653/v1/D18-2019</doi>
      <bibkey>nghiem-ananiadou-2018-aplenty</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="20">
      <title>Interactive Instance-based Evaluation of Knowledge Base Question Answering</title>
      <author><first>Daniil</first><last>Sorokin</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>114–119</pages>
      <url hash="0391b6e8">D18-2020</url>
      <abstract>Most approaches to Knowledge Base Question Answering are based on <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a>. In this paper, we present a tool that aids in debugging of question answering systems that construct a structured semantic representation for the input question. Previous work has largely focused on building <a href="https://en.wikipedia.org/wiki/Question_answering">question answering interfaces</a> or evaluation frameworks that unify multiple data sets. The primary objective of our <a href="https://en.wikipedia.org/wiki/System">system</a> is to enable interactive debugging of model predictions on individual instances (questions) and to simplify manual error analysis. Our interactive interface helps researchers to understand the shortcomings of a particular <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>, qualitatively analyze the complete <a href="https://en.wikipedia.org/wiki/Pipeline_transport">pipeline</a> and compare different <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a>. A set of sit-by sessions was used to validate our <a href="https://en.wikipedia.org/wiki/User_interface_design">interface design</a>.</abstract>
      <doi>10.18653/v1/D18-2020</doi>
      <bibkey>sorokin-gurevych-2018-interactive</bibkey>
      <pwccode url="https://github.com/UKPLab/emnlp2018-question-answering-interface" additional="false">UKPLab/emnlp2018-question-answering-interface</pwccode>
    </paper>
    <paper id="21">
      <title>Magnitude : A Fast, Efficient Universal Vector Embedding Utility Package<fixed-case>M</fixed-case>agnitude: A Fast, Efficient Universal Vector Embedding Utility Package</title>
      <author><first>Ajay</first><last>Patel</last></author>
      <author><first>Alexander</first><last>Sands</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Marianna</first><last>Apidianaki</last></author>
      <pages>120–126</pages>
      <url hash="f239bac1">D18-2021</url>
      <abstract>Vector space embedding models like <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a>, <a href="https://en.wikipedia.org/wiki/GloVe_(machine_learning)">GloVe</a>, and <a href="https://en.wikipedia.org/wiki/FastText">fastText</a> are extremely popular representations in natural language processing (NLP) applications. We present Magnitude, a fast, lightweight tool for utilizing and processing <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. Magnitude is an open source <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python package</a> with a compact vector storage file format that allows for efficient manipulation of huge numbers of <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>. Magnitude performs common <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture">operations</a> up to 60 to 6,000 times faster than <a href="https://en.wikipedia.org/wiki/Gensim">Gensim</a>. Magnitude introduces several novel <a href="https://en.wikipedia.org/wiki/Software_feature">features</a> for improved <a href="https://en.wikipedia.org/wiki/Robustness_(computer_science)">robustness</a> like out-of-vocabulary lookups.</abstract>
      <doi>10.18653/v1/D18-2021</doi>
      <bibkey>patel-etal-2018-magnitude</bibkey>
      <pwccode url="https://github.com/plasticityai/magnitude" additional="false">plasticityai/magnitude</pwccode>
    </paper>
    <paper id="22">
      <title>Integrating Knowledge-Supported Search into the INCEpTION Annotation Platform<fixed-case>INCE</fixed-case>p<fixed-case>TION</fixed-case> Annotation Platform</title>
      <author><first>Beto</first><last>Boullosa</last></author>
      <author><first>Richard</first><last>Eckart de Castilho</last></author>
      <author><first>Naveen</first><last>Kumar</last></author>
      <author><first>Jan-Christoph</first><last>Klie</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>127–132</pages>
      <url hash="7e5d254f">D18-2022</url>
      <abstract>Annotating entity mentions and linking them to a knowledge resource are essential tasks in many domains. It disambiguates mentions, introduces cross-document coreferences, and the resources contribute extra information, e.g. taxonomic relations. Such tasks benefit from <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text annotation tools</a> that integrate a <a href="https://en.wikipedia.org/wiki/Search_engine_technology">search</a> which covers the <a href="https://en.wikipedia.org/wiki/Text_(literary_theory)">text</a>, the <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a>, as well as the knowledge resource. However, to the best of our knowledge, no current tools integrate knowledge-supported search as well as entity linking support. We address this gap by introducing knowledge-supported search functionality into the INCEpTION text annotation platform. In our approach, cross-document references are created by linking entity mentions to a <a href="https://en.wikipedia.org/wiki/Knowledge_base">knowledge base</a> in the form of a structured hierarchical vocabulary. The resulting <a href="https://en.wikipedia.org/wiki/Annotation">annotations</a> are then indexed to enable fast and yet complex <a href="https://en.wikipedia.org/wiki/Information_retrieval">queries</a> taking into account the text, the annotations, and the vocabulary structure.</abstract>
      <doi>10.18653/v1/D18-2022</doi>
      <bibkey>boullosa-etal-2018-integrating</bibkey>
    </paper>
    <paper id="23">
      <title>CytonMT : an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++<fixed-case>C</fixed-case>yton<fixed-case>MT</fixed-case>: an Efficient Neural Machine Translation Open-source Toolkit Implemented in <fixed-case>C</fixed-case>++</title>
      <author><first>Xiaolin</first><last>Wang</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>133–138</pages>
      <url hash="d8acb7c6">D18-2023</url>
      <abstract>This paper presents an open-source neural machine translation toolkit named CytonMT. The <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a> is built from scratch only using <a href="https://en.wikipedia.org/wiki/C++">C++</a> and NVIDIA’s GPU-accelerated libraries. The <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a> features training efficiency, code simplicity and translation quality. Benchmarks show that cytonMT accelerates the training speed by 64.5 % to 110.8 % on <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> of various sizes, and achieves competitive translation quality.</abstract>
      <doi>10.18653/v1/D18-2023</doi>
      <bibkey>wang-etal-2018-cytonmt</bibkey>
      <pwccode url="https://github.com/arthurxlw/cytonMt" additional="false">arthurxlw/cytonMt</pwccode>
    </paper>
    <paper id="24">
      <title>OpenKE : An Open Toolkit for Knowledge Embedding<fixed-case>O</fixed-case>pen<fixed-case>KE</fixed-case>: An Open Toolkit for Knowledge Embedding</title>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Shulin</first><last>Cao</last></author>
      <author><first>Xin</first><last>Lv</last></author>
      <author><first>Yankai</first><last>Lin</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <author><first>Juanzi</first><last>Li</last></author>
      <pages>139–144</pages>
      <url hash="9bcedcb9">D18-2024</url>
      <abstract>We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes <a href="https://en.wikipedia.org/wiki/Operational_efficiency">operational efficiency</a> to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibility to easily incorporate new <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> into the <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a>. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval</a>, personalized recommendation and <a href="https://en.wikipedia.org/wiki/Question_answering">question answering</a>. The <a href="https://en.wikipedia.org/wiki/List_of_toolkits">toolkit</a>, documentation, and pre-trained embeddings are all released on.<url>http://openke.thunlp.org/</url>.</abstract>
      <doi>10.18653/v1/D18-2024</doi>
      <bibkey>han-etal-2018-openke</bibkey>
      <pwccode url="https://github.com/thunlp/OpenKE" additional="false">thunlp/OpenKE</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fb15k">FB15k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wn18">WN18</pwcdataset>
    </paper>
    <paper id="25">
      <title>LIA : A Natural Language Programmable Personal Assistant<fixed-case>LIA</fixed-case>: A Natural Language Programmable Personal Assistant</title>
      <author><first>Igor</first><last>Labutov</last></author>
      <author><first>Shashank</first><last>Srivastava</last></author>
      <author><first>Tom</first><last>Mitchell</last></author>
      <pages>145–150</pages>
      <url hash="ae61e82a">D18-2025</url>
      <abstract>We present LIA, an intelligent personal assistant that can be programmed using <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language</a>. Our <a href="https://en.wikipedia.org/wiki/System">system</a> demonstrates multiple competencies towards learning from <a href="https://en.wikipedia.org/wiki/Human–computer_interaction">human-like interactions</a>. These include the ability to be taught reusable conditional procedures, the ability to be taught new knowledge about the world (concepts in an ontology) and the ability to be taught how to ground that knowledge in a set of <a href="https://en.wikipedia.org/wiki/Sensor">sensors</a> and effectors. Building such a system highlights design questions regarding the overall architecture that such an <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> should have, as well as questions about <a href="https://en.wikipedia.org/wiki/Parsing">parsing</a> and grounding language in situational contexts. We outline key properties of this <a href="https://en.wikipedia.org/wiki/Architecture">architecture</a>, and demonstrate a <a href="https://en.wikipedia.org/wiki/Prototype">prototype</a> that embodies them in the form of a <a href="https://en.wikipedia.org/wiki/Personal_assistant">personal assistant</a> on an <a href="https://en.wikipedia.org/wiki/Android_(operating_system)">Android device</a>.</abstract>
      <doi>10.18653/v1/D18-2025</doi>
      <bibkey>labutov-etal-2018-lia</bibkey>
    </paper>
    <paper id="26">
      <title>PizzaPal : Conversational Pizza Ordering using a High-Density Conversational AI Platform<fixed-case>P</fixed-case>izza<fixed-case>P</fixed-case>al: Conversational Pizza Ordering using a High-Density Conversational <fixed-case>AI</fixed-case> Platform</title>
      <author><first>Antoine</first><last>Raux</last></author>
      <author><first>Yi</first><last>Ma</last></author>
      <author><first>Paul</first><last>Yang</last></author>
      <author><first>Felicia</first><last>Wong</last></author>
      <pages>151–156</pages>
      <url hash="62ec9159">D18-2026</url>
      <abstract>This paper describes PizzaPal, a voice-only agent for ordering pizza, as well as the Conversational AI architecture built at b4.ai. Based on the principles of high-density conversational AI, it supports natural and flexible interactions through neural conversational language understanding, robust dialog state tracking, and hierarchical task decomposition.</abstract>
      <doi>10.18653/v1/D18-2026</doi>
      <bibkey>raux-etal-2018-pizzapal</bibkey>
    </paper>
    <paper id="27">
      <title>Developing Production-Level Conversational Interfaces with Shallow Semantic Parsing</title>
      <author><first>Arushi</first><last>Raghuvanshi</last></author>
      <author><first>Lucien</first><last>Carroll</last></author>
      <author><first>Karthik</first><last>Raghunathan</last></author>
      <pages>157–162</pages>
      <url hash="f14d4fb4">D18-2027</url>
      <abstract>We demonstrate an end-to-end approach for building conversational interfaces from prototype to production that has proven to work well for a number of applications across diverse verticals. Our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> improves on the standard domain-intent-entity classification hierarchy and dialogue management architecture by leveraging shallow semantic parsing. We observe that NLU systems for industry applications often require more structured representations of entity relations than provided by the standard <a href="https://en.wikipedia.org/wiki/Hierarchy">hierarchy</a>, yet without requiring full semantic parses which are often inaccurate on real-world conversational data. We distinguish two kinds of semantic properties that can be provided through shallow semantic parsing : <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity groups</a> and <a href="https://en.wikipedia.org/wiki/Entity–relationship_model">entity roles</a>. We also provide live demos of conversational apps built for two different <a href="https://en.wikipedia.org/wiki/Use_case">use cases</a> : <a href="https://en.wikipedia.org/wiki/Online_food_ordering">food ordering</a> and meeting control.</abstract>
      <doi>10.18653/v1/D18-2027</doi>
      <bibkey>raghuvanshi-etal-2018-developing</bibkey>
    </paper>
    <paper id="28">
      <title>When <a href="https://en.wikipedia.org/wiki/Science_journalism">science journalism</a> meets <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</a> : An interactive demonstration</title>
      <author><first>Raghuram</first><last>Vadapalli</last></author>
      <author><first>Bakhtiyar</first><last>Syed</last></author>
      <author><first>Nishant</first><last>Prabhu</last></author>
      <author><first>Balaji Vasan</first><last>Srinivasan</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>163–168</pages>
      <url hash="b2de0732">D18-2028</url>
      <abstract>We present an online interactive tool that generates titles of blog titles and thus take the first step toward automating <a href="https://en.wikipedia.org/wiki/Science_journalism">science journalism</a>. Science journalism aims to transform jargon-laden scientific articles into a form that the common reader can comprehend while ensuring that the underlying meaning of the article is retained. In this work, we present a tool, which, given the title and abstract of a research paper will generate a blog title by mimicking a human science journalist. The tool makes use of a <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a> trained on a <a href="https://en.wikipedia.org/wiki/Text_corpus">corpus</a> of 87,328 pairs of research papers and their corresponding <a href="https://en.wikipedia.org/wiki/Blog">blogs</a>, built from two <a href="https://en.wikipedia.org/wiki/News_aggregator">science news aggregators</a>. The architecture of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> is a two-stage mechanism which generates <a href="https://en.wikipedia.org/wiki/Blog">blog titles</a>. Evaluation using standard <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> indicate the viability of the proposed <a href="https://en.wikipedia.org/wiki/System">system</a>.</abstract>
      <doi>10.18653/v1/D18-2028</doi>
      <bibkey>vadapalli-etal-2018-science</bibkey>
    </paper>
    <paper id="29">
      <title>Universal Sentence Encoder for English<fixed-case>E</fixed-case>nglish</title>
      <author><first>Daniel</first><last>Cer</last></author>
      <author><first>Yinfei</first><last>Yang</last></author>
      <author><first>Sheng-yi</first><last>Kong</last></author>
      <author><first>Nan</first><last>Hua</last></author>
      <author><first>Nicole</first><last>Limtiaco</last></author>
      <author><first>Rhomni</first><last>St. John</last></author>
      <author><first>Noah</first><last>Constant</last></author>
      <author><first>Mario</first><last>Guajardo-Cespedes</last></author>
      <author><first>Steve</first><last>Yuan</last></author>
      <author><first>Chris</first><last>Tar</last></author>
      <author><first>Brian</first><last>Strope</last></author>
      <author><first>Ray</first><last>Kurzweil</last></author>
      <pages>169–174</pages>
      <url hash="3916f650">D18-2029</url>
      <abstract>We present easy-to-use TensorFlow Hub sentence embedding models having good task transfer performance. Model variants allow for trade-offs between <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> and <a href="https://en.wikipedia.org/wiki/Computational_resource">compute resources</a>. We report the relationship between model complexity, <a href="https://en.wikipedia.org/wiki/Resource_(computer_science)">resources</a>, and transfer performance. Comparisons are made with <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> without <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> and to <a href="https://en.wikipedia.org/wiki/Baseline_(configuration_management)">baselines</a> that incorporate word-level transfer. Transfer learning using sentence-level embeddings is shown to outperform models without <a href="https://en.wikipedia.org/wiki/Transfer_learning">transfer learning</a> and often those that use only word-level transfer. We show good transfer task performance with minimal training data and obtain encouraging results on word embedding association tests (WEAT) of model bias.</abstract>
      <doi>10.18653/v1/D18-2029</doi>
      <bibkey>cer-etal-2018-universal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mpqa-opinion-corpus">MPQA Opinion Corpus</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
  </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</booktitle>
      <editor><first /><last>Mausam</last></editor>
      <editor><first>Lu</first><last>Wang</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Melbourne, Australia</address>
      <month>October-November</month>
      <year>2018</year>
    </meta>
    <paper id="1">
      <title>Joint models for <fixed-case>NLP</fixed-case></title>
      <author><first>Yue</first><last>Zhang</last></author>
      <abstract>Joint models have received much research attention in NLP, allowing relevant tasks to share common information while avoiding error propagation in multi-stage pepelines. Several main approaches have been taken by statistical joint modeling, while neural models allow parameter sharing and adversarial training. This tutorial reviews main approaches to joint modeling for both statistical and neural methods.</abstract>
      <bibkey>zhang-2018-joint</bibkey>
    </paper>
    <paper id="2">
      <title>Graph Formalisms for Meaning Representations</title>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Sorcha</first><last>Gilroy</last></author>
      <abstract>In this tutorial we will focus on Hyperedge Replacement Languages (HRL; Drewes et al. 1997), a context-free graph rewriting system. HRL are one of the most popular graph formalisms to be studied in NLP (Chiang et al., 2013; Peng et al., 2015; Bauer and Rambow, 2016). We will discuss HRL by formally defining them, studying several examples, discussing their properties, and providing exercises for the tutorial. While HRL have been used in NLP in the past, there is some speculation that they are more expressive than is necessary for graphs representing natural language (Drewes, 2017). Part of our own research has been exploring what restrictions of HRL could yield languages that are more useful for NLP and also those that have desirable properties for NLP models, such as being closed under intersection. With that in mind, we also plan to discuss Regular Graph Languages (RGL; Courcelle 1991), a subfamily of HRL which are closed under intersection. The definition of RGL is relatively simple after being introduced to HRL. We do not plan on discussing any proofs of why RGL are also a subfamily of MSOL, as described in Gilroy et al. (2017b). We will briefly mention the other formalisms shown in Figure 1 such as MSOL and DAGAL but this will focus on their properties rather than any formal definitions.</abstract>
      <bibkey>lopez-gilroy-2018-graph</bibkey>
    </paper>
    <paper id="3">
      <title>Writing Code for <fixed-case>NLP</fixed-case> Research</title>
      <author><first>Matt</first><last>Gardner</last></author>
      <author><first>Mark</first><last>Neumann</last></author>
      <author><first>Joel</first><last>Grus</last></author>
      <author><first>Nicholas</first><last>Lourie</last></author>
      <abstract>Doing modern NLP research requires writing code. Good code enables fast prototyping, easy debugging, controlled experiments, and accessible visualizations that help researchers understand what a model is doing. Bad code leads to research that is at best hard to reproduce and extend, and at worst simply incorrect. Indeed, there is a growing recognition of the importance of having good tools to assist good research in our field, as the upcoming workshop on open source software for NLP demonstrates. This tutorial aims to share best practices for writing code for NLP research, drawing on the instructors' experience designing the recently-released AllenNLP toolkit, a PyTorch-based library for deep learning NLP research. We will explain how a library with the right abstractions and components enables better code and better science, using models implemented in AllenNLP as examples. Participants will learn how to write research code in a way that facilitates good science and easy experimentation, regardless of what framework they use.</abstract>
      <bibkey>gardner-etal-2018-writing</bibkey>
    </paper>
    <paper id="4">
      <title>Deep Latent Variable Models of Natural Language</title>
      <author><first>Alexander</first><last>Rush</last></author>
      <author><first>Yoon</first><last>Kim</last></author>
      <author><first>Sam</first><last>Wiseman</last></author>
      <abstract>The proposed tutorial will cover deep latent variable models both in the case where exact inference over the latent variables is tractable and when it is not. The former case includes neural extensions of unsupervised tagging and parsing models. Our discussion of the latter case, where inference cannot be performed tractably, will restrict itself to continuous latent variables. In particular, we will discuss recent developments both in neural variational inference (e.g., relating to Variational Auto-encoders) and in implicit density modeling (e.g., relating to Generative Adversarial Networks). We will highlight the challenges of applying these families of methods to NLP problems, and discuss recent successes and best practices.</abstract>
      <bibkey>rush-etal-2018-deep</bibkey>
    </paper>
    <paper id="5">
      <title>Standardized Tests as benchmarks for Artificial Intelligence</title>
      <author><first>Mrinmaya</first><last>Sachan</last></author>
      <author><first>Minjoon</first><last>Seo</last></author>
      <author><first>Hannaneh</first><last>Hajishirzi</last></author>
      <author><first>Eric</first><last>Xing</last></author>
      <abstract>Standardized tests have recently been proposed as replacements to the Turing test as a driver for progress in AI (Clark, 2015). These include tests on understanding passages and stories and answering questions about them (Richardson et al., 2013; Rajpurkar et al., 2016a, inter alia), science question answering (Schoenick et al., 2016, inter alia), algebra word problems (Kushman et al., 2014, inter alia), geometry problems (Seo et al., 2015; Sachan et al., 2016), visual question answering (Antol et al., 2015), etc. Many of these tests require sophisticated understanding of the world, aiming to push the boundaries of AI. For this tutorial, we broadly categorize these tests into two categories: open domain tests such as reading comprehensions and elementary school tests where the goal is to find the support for an answer from the student curriculum, and closed domain tests such as intermediate level math and science tests (algebra, geometry, Newtonian physics problems, etc.). Unlike open domain tests, closed domain tests require the system to have significant domain knowledge and reasoning capabilities. For example, geometry questions typically involve a number of geometry primitives (lines, quadrilaterals, circles, etc) and require students to use axioms and theorems of geometry (Pythagoras theorem, alternating angles, etc) to solve them. These closed domains often have a formal logical basis and the question can be mapped to a formal language by semantic parsing. The formal question representation can then provided as an input to an expert system to solve the question.</abstract>
      <bibkey>sachan-etal-2018-standardized</bibkey>
    </paper>
    <paper id="6">
      <title>Deep Chit-Chat: Deep Learning for <fixed-case>C</fixed-case>hat<fixed-case>B</fixed-case>ots</title>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <abstract>The tutorial is based on the long-term efforts on building conversational models with deep learning approaches for chatbots. We will summarize the fundamental challenges in modeling open domain dialogues, clarify the difference from modeling goal-oriented dialogues, and give an overview of state-of-the-art methods for open domain conversation including both retrieval-based methods and generation-based methods. In addition to these, our tutorial will also cover some new trends of research of chatbots, such as how to design a reasonable evaluation system and how to "control" conversations from a chatbot with some specific information such as personas, styles, and emotions, etc.</abstract>
      <bibkey>wu-yan-2018-deep</bibkey>
    </paper>
  </volume>
</collection>