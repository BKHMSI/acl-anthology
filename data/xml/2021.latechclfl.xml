<collection id="2021.latechclfl">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</booktitle>
      <editor><first>Stefania</first><last>Degaetano-Ortlieb</last></editor>
      <editor><first>Anna</first><last>Kazantseva</last></editor>
      <editor><first>Nils</first><last>Reiter</last></editor>
      <editor><first>Stan</first><last>Szpakowicz</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic (online)</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="3e1699e7">2021.latechclfl-1.0</url>
      <bibkey>latechclfl-2021-joint</bibkey>
    </frontmatter>
    <paper id="2">
      <title><fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et-like Annotation of Olfactory Information in Texts</title>
      <author><first>Sara</first><last>Tonelli</last></author>
      <author><first>Stefano</first><last>Menini</last></author>
      <pages>11&#8211;20</pages>
      <abstract>Although olfactory references play a crucial role in our cultural memory, only few works in NLP have tried to capture them from a computational perspective. Currently, the main challenge is not much the development of technological components for olfactory information extraction, given recent advances in semantic processing and natural language understanding, but rather the lack of a theoretical framework to capture this information from a linguistic point of view, as a preliminary step towards the development of automated systems. Therefore, in this work we present the annotation guidelines, developed with the help of history scholars and domain experts, aimed at capturing all the relevant elements involved in olfactory situations or events described in texts. These guidelines have been inspired by FrameNet annotation, but underwent some adaptations, which are detailed in this paper. Furthermore, we present a case study concerning the annotation of olfactory situations in English historical travel writings describing trips to Italy. An analysis of the most frequent role fillers show that olfactory descriptions pertain to some typical domains such as religion, food, nature, ancient past, poor sanitation, all supporting the creation of a stereotypical imagery related to Italy. On the other hand, positive feelings triggered by smells are prevalent, and contribute to framing travels to Italy as an exciting experience involving all senses.</abstract>
      <url hash="09467409">2021.latechclfl-1.2</url>
      <bibkey>tonelli-menini-2021-framenet</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.2</doi>
    </paper>
    <paper id="3">
      <title>Batavia asked for advice. Pretrained language models for Named Entity Recognition in historical texts.</title>
      <author><first>Sophie I.</first><last>Arnoult</last></author>
      <author><first>Lodewijk</first><last>Petram</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>21&#8211;30</pages>
      <abstract>Pretrained language models like BERT have advanced the state of the art for many NLP tasks. For resource-rich languages, one has the choice between a number of language-specific models, while multilingual models are also worth considering. These models are well known for their crosslingual performance, but have also shown competitive in-language performance on some tasks. We consider monolingual and multilingual models from the perspective of historical texts, and in particular for texts enriched with editorial notes: how do language models deal with the historical and editorial content in these texts? We present a new Named Entity Recognition dataset for Dutch based on 17th and 18th century United East India Company (VOC) reports extended with modern editorial notes. Our experiments with multilingual and Dutch pretrained language models confirm the crosslingual abilities of multilingual models while showing that all language models can leverage mixed-variant data. In particular, language models successfully incorporate notes for the prediction of entities in historical texts. We also find that multilingual models outperform monolingual models on our data, but that this superiority is linked to the task at hand: multilingual models lose their advantage when confronted with more semantical tasks.</abstract>
      <url hash="469f2a04">2021.latechclfl-1.3</url>
      <bibkey>arnoult-etal-2021-batavia</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.3</doi>
    </paper>
    <paper id="8">
      <title>Emotion Classification in <fixed-case>G</fixed-case>erman Plays with Transformer-based Language Models Pretrained on Historical and Contemporary Language</title>
      <author><first>Thomas</first><last>Schmidt</last></author>
      <author><first>Katrin</first><last>Dennerlein</last></author>
      <author><first>Christian</first><last>Wolff</last></author>
      <pages>67&#8211;79</pages>
      <abstract>We present results of a project on emotion classification on historical German plays of Enlightenment, Storm and Stress, and German Classicism. We have developed a hierarchical annotation scheme consisting of 13 sub-emotions like suffering, love and joy that sum up to 6 main and 2 polarity classes (positive/negative). We have conducted textual annotations on 11 German plays and have acquired over 13,000 emotion annotations by two annotators per play. We have evaluated multiple traditional machine learning approaches as well as transformer-based models pretrained on historical and contemporary language for a single-label text sequence emotion classification for the different emotion categories. The evaluation is carried out on three different instances of the corpus: (1) taking all annotations, (2) filtering overlapping annotations by annotators, (3) applying a heuristic for speech-based analysis. Best results are achieved on the filtered corpus with the best models being large transformer-based models pretrained on contemporary German language. For the polarity classification accuracies of up to 90% are achieved. The accuracies become lower for settings with a higher number of classes, achieving 66% for 13 sub-emotions. Further pretraining of a historical model with a corpus of dramatic texts led to no improvements.</abstract>
      <url hash="8f74a762">2021.latechclfl-1.8</url>
      <bibkey>schmidt-etal-2021-emotion</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.8</doi>
    </paper>
    <paper id="9">
      <title>Automating the Detection of Poetic Features: The Limerick as Model Organism</title>
      <author><first>Almas</first><last>Abdibayev</last></author>
      <author><first>Yohei</first><last>Igarashi</last></author>
      <author><first>Allen</first><last>Riddell</last></author>
      <author><first>Daniel</first><last>Rockmore</last></author>
      <pages>80&#8211;90</pages>
      <abstract>In this paper we take up the problem of &#8220;limerick detection&#8221; and describe a system to identify five-line poems as limericks or not. This turns out to be a surprisingly difficult challenge with many subtleties. More precisely, we produce an algorithm which focuses on the structural aspects of the limerick &#8211; rhyme scheme and rhythm (i.e., stress patterns) &#8211; and when tested on a a culled data set of 98,454 publicly available limericks, our &#8220;limerick filter&#8221; accepts 67% as limericks. The primary failure of our filter is on the detection of &#8220;non-standard&#8221; rhymes, which we highlight as an outstanding challenge in computational poetics. Our accent detection algorithm proves to be very robust. Our main contributions are (1) a novel rhyme detection algorithm that works on English words including rare proper nouns and made-up words (and thus, words not in the widely used CMUDict database); (2) a novel rhythm-identifying heuristic that is robust to language noise at moderate levels and comparable in accuracy to state-of-the-art scansion algorithms. As a third significant contribution (3) we make publicly available a large corpus of limericks that includes tags of &#8220;limerick&#8221; or &#8220;not-limerick&#8221; as determined by our identification software, thereby providing a benchmark for the community. The poetic tasks that we have identified as challenges for machines suggest that the limerick is a useful &#8220;model organism&#8221; for the study of machine capabilities in poetry and more broadly literature and language. We include a list of open challenges as well. Generally, we anticipate that this work will provide useful material and benchmarks for future explorations in the field.</abstract>
      <url hash="d4fe781d">2021.latechclfl-1.9</url>
      <bibkey>abdibayev-etal-2021-automating</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.9</doi>
    </paper>
    <paper id="12">
      <title>Translationese in <fixed-case>R</fixed-case>ussian Literary Texts</title>
      <author><first>Maria</first><last>Kunilovskaya</last></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <pages>101&#8211;112</pages>
      <abstract>The paper reports the results of a translationese study of literary texts based on translated and non-translated Russian. We aim to find out if translations deviate from non-translated literary texts, and if the established differences can be attributed to typological relations between source and target languages. We expect that literary translations from typologically distant languages should exhibit more translationese, and the fingerprints of individual source languages (and their families) are traceable in translations. We explore linguistic properties that distinguish non-translated Russian literature from translations into Russian. Our results show that non-translated fiction is different from translations to the degree that these two language varieties can be automatically classified. As expected, language typology is reflected in translations of literary texts. We identified features that point to linguistic specificity of Russian non-translated literature and to shining-through effects. Some of translationese features cut across all language pairs, while others are characteristic of literary translations from languages belonging to specific language families.</abstract>
      <url hash="b3e4c2f2">2021.latechclfl-1.12</url>
      <bibkey>kunilovskaya-etal-2021-translationese</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.12</doi>
    </paper>
    <paper id="15">
      <title>A Pilot Study for <fixed-case>BERT</fixed-case> Language Modelling and Morphological Analysis for Ancient and Medieval <fixed-case>G</fixed-case>reek</title>
      <author><first>Pranaydeep</first><last>Singh</last></author>
      <author><first>Gorik</first><last>Rutten</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>128&#8211;137</pages>
      <abstract>This paper presents a pilot study to automatic linguistic preprocessing of Ancient and Byzantine Greek, and morphological analysis more specifically. To this end, a novel subword-based BERT language model was trained on the basis of a varied corpus of Modern, Ancient and Post-classical Greek texts. Consequently, the obtained BERT embeddings were incorporated to train a fine-grained Part-of-Speech tagger for Ancient and Byzantine Greek. In addition, a corpus of Greek Epigrams was manually annotated and the resulting gold standard was used to evaluate the performance of the morphological analyser on Byzantine Greek. The experimental results show very good perplexity scores (4.9) for the BERT language model and state-of-the-art performance for the fine-grained Part-of-Speech tagger for in-domain data (treebanks containing a mixture of Classical and Medieval Greek), as well as for the newly created Byzantine Greek gold standard data set. The language models and associated code are made available for use at https://github.com/pranaydeeps/Ancient-Greek-BERT</abstract>
      <url hash="864c05aa">2021.latechclfl-1.15</url>
      <bibkey>singh-etal-2021-pilot</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.15</doi>
      <pwccode url="https://github.com/pranaydeeps/ancient-greek-bert" additional="false">pranaydeeps/ancient-greek-bert</pwccode>
    </paper>
    <paper id="16">
      <title>Zero-Shot Information Extraction to Enhance a Knowledge Graph Describing Silk Textiles</title>
      <author><first>Thomas</first><last>Schleider</last></author>
      <author><first>Raphael</first><last>Troncy</last></author>
      <pages>138&#8211;146</pages>
      <abstract>The knowledge of the European silk textile production is a typical case for which the information collected is heterogeneous, spread across many museums and sparse since rarely complete. Knowledge Graphs for this cultural heritage domain, when being developed with appropriate ontologies and vocabularies, enable to integrate and reconcile this diverse information. However, many of these original museum records still have some metadata gaps. In this paper, we present a zero-shot learning approach that leverages the ConceptNet common sense knowledge graph to predict categorical metadata informing about the silk objects production. We compared the performance of our approach with traditional supervised deep learning-based methods that do require training data. We demonstrate promising and competitive performance for similar datasets and circumstances and the ability to predict sometimes more fine-grained information. Our results can be reproduced using the code and datasets published at https://github.com/silknow/ZSL-KG-silk.</abstract>
      <url hash="603bc3b6">2021.latechclfl-1.16</url>
      <bibkey>schleider-troncy-2021-zero</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.16</doi>
      <pwccode url="https://github.com/silknow/zsl-kg-silk" additional="false">silknow/zsl-kg-silk</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="19">
      <title>Period Classification in <fixed-case>C</fixed-case>hinese Historical Texts</title>
      <author><first>Zuoyu</first><last>Tian</last></author>
      <author><first>Sandra</first><last>K&#252;bler</last></author>
      <pages>168&#8211;177</pages>
      <abstract>In this study, we study language change in Chinese Biji by using a classification task: classifying Ancient Chinese texts by time periods. Specifically, we focus on a unique genre in classical Chinese literature: Biji (literally &#8220;notebook&#8221; or &#8220;brush notes&#8221;), i.e., collections of anecdotes, quotations, etc., anything authors consider noteworthy, Biji span hundreds of years across many dynasties and conserve informal language in written form. For these reasons, they are regarded as a good resource for investigating language change in Chinese (Fang, 2010). In this paper, we create a new dataset of 108 Biji across four dynasties. Based on the dataset, we first introduce a time period classification task for Chinese. Then we investigate different feature representation methods for classification. The results show that models using contextualized embeddings perform best. An analysis of the top features chosen by the word n-gram model (after bleaching proper nouns) confirms that these features are informative and correspond to observations and assumptions made by historical linguists.</abstract>
      <url hash="b030a9f1">2021.latechclfl-1.19</url>
      <bibkey>tian-kubler-2021-period</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.19</doi>
    </paper>
    <paper id="21">
      <title>Stylometric Literariness Classification: the Case of Stephen King</title>
      <author><first>Andreas</first><last>van Cranenburgh</last></author>
      <author><first>Erik</first><last>Ketzan</last></author>
      <pages>189&#8211;197</pages>
      <abstract>This paper applies stylometry to quantify the literariness of 73 novels and novellas by American author Stephen King, chosen as an extraordinary case of a writer who has been dubbed both &#8220;high&#8221; and &#8220;low&#8221; in literariness in critical reception. We operationalize literariness using a measure of stylistic distance (Cosine Delta) based on the 1000 most frequent words in two bespoke comparison corpora used as proxies for literariness: one of popular genre fiction, another of National Book Award-winning authors. We report that a supervised model is highly effective in distinguishing the two categories, with 94.6% macro average in a binary classification. We define two subsets of texts by King&#8212;&#8220;high&#8221; and &#8220;low&#8221; literariness works as suggested by critics and ourselves&#8212;and find that a predictive model does identify King&#8217;s Dark Tower series and novels such as Dolores Claiborne as among his most &#8220;literary&#8221; texts, consistent with critical reception, which has also ascribed postmodern qualities to the Dark Tower novels. Our results demonstrate the efficacy of Cosine Delta-based stylometry in quantifying the literariness of texts, while also highlighting the methodological challenges of literariness, especially in the case of Stephen King. The code and data to reproduce our results are available at https://github.com/andreasvc/kinglit</abstract>
      <url hash="7b93ab8a">2021.latechclfl-1.21</url>
      <bibkey>van-cranenburgh-ketzan-2021-stylometric</bibkey>
      <doi>10.18653/v1/2021.latechclfl-1.21</doi>
      <pwccode url="https://github.com/andreasvc/kinglit" additional="false">andreasvc/kinglit</pwccode>
    </paper>
  </volume>
</collection>