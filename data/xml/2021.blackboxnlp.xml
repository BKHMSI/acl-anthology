<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.blackboxnlp">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</booktitle>
      <editor><first>Jasmijn</first><last>Bastings</last></editor>
      <editor><first>Yonatan</first><last>Belinkov</last></editor>
      <editor><first>Emmanuel</first><last>Dupoux</last></editor>
      <editor><first>Mario</first><last>Giulianelli</last></editor>
      <editor><first>Dieuwke</first><last>Hupkes</last></editor>
      <editor><first>Yuval</first><last>Pinter</last></editor>
      <editor><first>Hassan</first><last>Sajjad</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="913b864b">2021.blackboxnlp-1.0</url>
      <bibkey>blackboxnlp-2021-blackboxnlp</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Does <a href="https://en.wikipedia.org/wiki/Knowledge">External Knowledge</a> Help Explainable <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">Natural Language Inference</a>? Automatic Evaluation vs. Human Ratings</title>
      <author><first>Hendrik</first><last>Schuff</last></author>
      <author><first>Hsiu-Yu</first><last>Yang</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>26–41</pages>
      <abstract>Natural language inference (NLI) requires models to learn and apply commonsense knowledge. These reasoning abilities are particularly important for explainable NLI systems that generate a <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language explanation</a> in addition to their label prediction. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities. For this, we investigate different sources of external knowledge and evaluate the performance of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. We find that different sources of knowledge have a different effect on reasoning abilities, for example, <a href="https://en.wikipedia.org/wiki/Implicit_knowledge">implicit knowledge</a> stored in language models can hinder reasoning on numbers and <a href="https://en.wikipedia.org/wiki/Negation">negations</a>. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date. It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor <a href="https://en.wikipedia.org/wiki/Grammar">grammar correctness</a>.</abstract>
      <url hash="30bfd8a2">2021.blackboxnlp-1.3</url>
      <bibkey>schuff-etal-2021-external</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.3</doi>
      <pwccode url="https://github.com/boschresearch/external-knowledge-explainable-nli" additional="false">boschresearch/external-knowledge-explainable-nli</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/e-snli">e-SNLI</pwcdataset>
    <title_ar>هل المعرفة الخارجية تساعد في تفسير استدلال اللغة الطبيعية؟ التقييم التلقائي مقابل التقييمات البشرية</title_ar>
      <title_pt>O conhecimento externo ajuda a inferência de linguagem natural explicável? Avaliação automática versus classificações humanas</title_pt>
      <title_es>¿El conocimiento externo ayuda a la inferencia explicable del lenguaje natural? Evaluación automática frente a calificaciones humanas</title_es>
      <title_ja>外部知識は説明可能な自然言語推論に役立ちますか？自動評価と人間評価</title_ja>
      <title_hi>क्या बाहरी ज्ञान प्राकृतिक भाषा अनुमान को समझाने में मदद करता है? स्वचालित मूल्यांकन बनाम मानव रेटिंग</title_hi>
      <title_zh>外知有助于可解者自然语言理乎? 自料与人工评级</title_zh>
      <title_ga>An Cuidíonn Eolas Seachtrach Tátail Inmhínithe Teanga Nádúrtha? Meastóireacht Uathoibríoch vs. Rátálacha Daonna</title_ga>
      <title_ka>გარეშე ცნობიერების დახმარება გამოსახულებელი თავისუფლიო ენაზე? ადამიანის რეტინგის ავტომატური განსაზღვრება</title_ka>
      <title_hu>Segít a külső tudás megmagyarázni a természetes nyelvi fertőzést? Automatikus értékelés vs. humán minősítések</title_hu>
      <title_el>Βοηθά η εξωτερική γνώση στην εξήγηση της φυσικής γλώσσας; Αυτόματη αξιολόγηση έναντι των ανθρώπινων βαθμολογιών</title_el>
      <title_it>La conoscenza esterna aiuta a spiegare l'inferenza del linguaggio naturale? Valutazione automatica contro valutazioni umane</title_it>
      <title_kk>Сыртқы білім көмегімен түсініктіретін табиғи тілдер қатынасы бар ма? Адам бағалауына қарсы автоматты түрде оқу</title_kk>
      <title_lt>Ar išorinės žinios padeda paaiškinti gamtinės kalbos trūkumą? Automatinis vertinimas, palyginti su žmogaus vertinimais</title_lt>
      <title_mk>Дали надворешното знаење помага да се објасни природната инференција на јазикот? Automatic Evaluation vs. Human Ratings</title_mk>
      <title_ms>Adakah Pengetahuan Luar Bantu Dijelaskan Bahasa Bahasa Alami? Evaluasi Automatik vs. Nilai Manusia</title_ms>
      <title_mn>Байгалийн мэдлэг нь тайлбарлах байгалийн хэл хамааралтай туслах уу? Хүн төрөлхтний тооны эсрэг автоматтын үнэлгээ</title_mn>
      <title_ml>പുറത്തുള്ള അറിവ് സ്വാഭാവികമായ ഭാഷ വിശദീകരിക്കാന്‍ സഹായിക്കുന്നുണ്ടോ? മനുഷ്യരുടെ റേറ്റിങ്ങുകള്‍</title_ml>
      <title_mt>L-Għarfien Estern jgħin fl-Inferenza tal-Lingwi Naturali Spjegabbli? Evalwazzjoni Awtomatika vs. Klassifikazzjonijiet tal-Bniedem</title_mt>
      <title_no>Er eksterne kunnskap hjelp for utforskar naturspråk? Automatisk evaluering mot menneske verdiar</title_no>
      <title_sr>Da li vanjska znanja pomaže da objasni prirodni jezik? Automatic Evaluation vs. Human Ratings</title_sr>
      <title_pl>Czy wiedza zewnętrzna pomaga wyjaśnić wniosek języka naturalnego? Automatyczna ocena w porównaniu z oceną ludzką</title_pl>
      <title_ro>Cunoștințele externe ajută la explicarea inferenței limbajului natural? Evaluare automată comparativ cu evaluările umane</title_ro>
      <title_si>පුරුද්ගලික දැනගන්න උදව් කරන්න පුරුද්ගලික භාෂාව ප්‍රශ්නය කරන්න පුළුවන්ද? ස්වයංක්‍රියාත්මක විශ්වාස කරන්න</title_si>
      <title_sv>Hjälper extern kunskap till att förklara naturliga språkinfektioner? Automatisk utvärdering jämfört med mänskliga värderingar</title_sv>
      <title_so>Ma cawinaada aqoonta dibadda ah oo la caddeyn karo afka asalka ah? Qedemeynta bilowga</title_so>
      <title_ta>வெளி அறிவு இயல்பான மொழி புதுப்பிக்க உதவுகிறதா? தானியங்கி மதிப்பீடு</title_ta>
      <title_ur>کیا خارجی علم کی تعریف قابل توسطی زبان کی نسبت مدد کرتی ہے؟ اٹوٹوکیٹ ارتفاع انسانی راٹینگ</title_ur>
      <title_uz>Tashqi maò¥lumot Natalik tilni aniqlashni istaysizmi? Avto- toò£gò£rilash</title_uz>
      <title_vi>Hỗ trợ hiểu biết đối diện Giải thích ngôn ngữ tự nhiên? Đánh giá tự động tương ứng con người</title_vi>
      <title_bg>Външното знание помага ли за обяснимото природно езиково заключение? Автоматична оценка спрямо човешките рейтинги</title_bg>
      <title_nl>Helpt Externe Kennis Verklaarbare Natuurlijke Taal Inferentie? Automatische evaluatie versus menselijke ratings</title_nl>
      <title_hr>Da li vanjska znanja pomaže objašnjivim prirodnim jezikom? Automatska procjena protiv ljudskih ocjena</title_hr>
      <title_da>Hjælper ekstern viden med at forklare naturlige sproginfektioner? Automatisk evaluering i forhold til menneskelige vurderinger</title_da>
      <title_id>Apakah Pengetahuan Luar membantu Penjelasan Bahasa Alami Inferensi? Evaluasi Otomatis vs. Rating Manusia</title_id>
      <title_de>Hilft externes Wissen bei erklärbaren Schlussfolgerungen natürlicher Sprache? Automatische Bewertung vs. Human Ratings</title_de>
      <title_ko>외부 지식은 자연 언어의 추리를 해석하는 데 도움이 됩니까?자동 평가와 인공 평가</title_ko>
      <title_fa>آیا دانش خارجی کمک می کند تفاوت زبان طبیعی توضیح داده شود؟ ارزیابی خودکار با ارزیابی انسان</title_fa>
      <title_sw>Je, maarifa ya nje inasaidia kuingilia lugha ya asili? Uchunguzi wa kujitegemea dhidi ya mabomu ya binadamu</title_sw>
      <title_tr>Daşarydaky Bilim Tebiýaly Dili Aňlamakda Kömek edip bilýärmi? Otomatik Taýýarlama</title_tr>
      <title_af>Het eksterne kennis hulp verduidelik Natuurlike Taal Inferensie? Outomatiese evaluering teen menslike waardelings</title_af>
      <title_sq>A ndihmon njohuria e jashtme të shpjegohet për gjuhën natyrore? Vlerësim automatik kundër vlerësimeve njerëzore</title_sq>
      <title_am>የውጭ እውቀት የባሕላዊ ቋንቋ መግለጫ ይችላልን? ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_az>External Knowledge Yard캼m edir M톛xluqat Dili Inference? 캻nsan qiym톛tl톛ri</title_az>
      <title_hy>Does External Knowledge Help Explainable Natural Language Inference?  Comment</title_hy>
      <title_bn>বাইরের জ্ঞান কি স্বাভাবিক ভাষা ব্যাখ্যা করতে সাহায্য করে? স্বয়ংক্রিয়ভাবে মানুষের রেটিং</title_bn>
      <title_bs>Da li vanjska znanja pomaže objašnjavajući prirodni jezik? Automatska procjena protiv ljudskih ocjena</title_bs>
      <title_ca>El coneixement extern ajuda a explicar la llengua natural? Evaluació automàtica contra valoracions humanes</title_ca>
      <title_cs>Pomáhají externí znalosti vysvětlitelnému závěru přirozeného jazyka? Automatické hodnocení vs. lidské hodnocení</title_cs>
      <title_et>Kas välised teadmised aitavad selgitada loodusliku keele järeldust? Automaatne hindamine vs inimhinnangud</title_et>
      <title_fi>Auttaako ulkoinen tietämys selittäviä luonnollisen kielen päätelmiä? Automaattinen arviointi verrattuna ihmisten luokituksiin</title_fi>
      <title_jv>Opo kowe paling Panjenengan langkung popolahan apik ? drawable-action</title_jv>
      <title_he>האם הידע החיצוני עוזר להסביר שפת טבעית חולה? Automatic Evaluation vs. Human Ratings</title_he>
      <title_ha>Shin, Aiki na Bayan Cilmi na Bayan Aiki na Bayan Taurar da za'a bayyana Infez da Lugha na Natural? @ action</title_ha>
      <title_sk>Ali zunanje znanje pomaga pojasniti sklepanje naravnega jezika? Avtomatsko ocenjevanje v primerjavi z oceno ljudi</title_sk>
      <title_bo>ཕྱི་རིང་གི་ཤེས་པའི་རོགས་རམ་བསླབ་བཏུབ་པའི་རང་བཞིན་སྐད་ཀྱི་ཆ་གཤིས་ཡིན་ནམ། རང་འགུལ་གྱིས་མིའི་རིམ་པ</title_bo>
      <abstract_ar>يتطلب الاستدلال اللغوي الطبيعي (NLI) نماذج للتعلم وتطبيق المعرفة المنطقية. تعتبر قدرات التفكير هذه مهمة بشكل خاص لأنظمة NLI القابلة للتفسير والتي تولد تفسيرًا للغة الطبيعية بالإضافة إلى تنبؤ التسمية الخاصة بهم. لقد ثبت أن تكامل المعرفة الخارجية يحسن أنظمة NLI ، وهنا نتحرى ما إذا كان بإمكانه أيضًا تحسين قدرات التفسير الخاصة بها. لهذا ، نحن نبحث في مصادر مختلفة للمعرفة الخارجية ونقيم أداء نماذجنا على بيانات المجال وكذلك على مجموعات بيانات النقل الخاصة المصممة لتقييم قدرات التفكير الدقيقة. نجد أن مصادر المعرفة المختلفة لها تأثير مختلف على قدرات التفكير ، على سبيل المثال ، المعرفة الضمنية المخزنة في نماذج اللغة يمكن أن تعيق التفكير في الأرقام والنفي. أخيرًا ، نجري أكبر دراسة تعهيد جماعي قابلة للتفسير وأكثرها دقة حتى الآن. ويكشف أنه حتى الاختلافات الكبيرة في درجات الأداء التلقائية لا تنعكس في التصنيفات البشرية للتسمية والتفسير والمنطق ولا صحة القواعد.</abstract_ar>
      <abstract_es>La inferencia de lenguaje natural (NLI) requiere modelos para aprender y aplicar el conocimiento de sentido común. Estas habilidades de razonamiento son particularmente importantes para los sistemas de NLI explicables que generan una explicación en lenguaje natural además de la predicción de su etiqueta. Se ha demostrado que la integración del conocimiento externo mejora los sistemas de NLI, aquí investigamos si también puede mejorar sus capacidades de explicación. Para ello, investigamos diferentes fuentes de conocimiento externo y evaluamos el rendimiento de nuestros modelos en datos de dominio, así como en conjuntos de datos de transferencia especiales que están diseñados para evaluar capacidades de razonamiento minuciosas. Encontramos que las diferentes fuentes de conocimiento tienen un efecto diferente en las habilidades de razonamiento, por ejemplo, el conocimiento implícito almacenado en los modelos de lenguaje puede dificultar el razonamiento sobre números y negaciones. Finalmente, llevamos a cabo el mayor y más detallado estudio de crowdsourcing explicable de NLI hasta la fecha. Revela que incluso las grandes diferencias en las puntuaciones automáticas de rendimiento no se reflejan en las calificaciones humanas de etiqueta, explicación, sentido común ni corrección gramatical.</abstract_es>
      <abstract_pt>A inferência de linguagem natural (NLI) requer modelos para aprender e aplicar o conhecimento do senso comum. Essas habilidades de raciocínio são particularmente importantes para sistemas NLI explicáveis que geram uma explicação em linguagem natural além de sua previsão de rótulo. A integração do conhecimento externo mostrou melhorar os sistemas NLI, aqui investigamos se também pode melhorar suas capacidades de explicação. Para isso, investigamos diferentes fontes de conhecimento externo e avaliamos o desempenho de nossos modelos em dados no domínio, bem como em conjuntos de dados de transferência especiais projetados para avaliar recursos de raciocínio refinado. Descobrimos que diferentes fontes de conhecimento têm um efeito diferente nas habilidades de raciocínio, por exemplo, o conhecimento implícito armazenado em modelos de linguagem pode dificultar o raciocínio sobre números e negações. Por fim, realizamos o maior e mais detalhado estudo de crowdsourcing NLI explicável até o momento. Ele revela que mesmo grandes diferenças nas pontuações de desempenho automático não refletem nas classificações humanas de rótulo, explicação, senso comum ou correção gramatical.</abstract_pt>
      <abstract_ja>自然言語推論（ NLI ）では、モデルが常識的な知識を学び、適用する必要がある。 これらの推論能力は、ラベル予測に加えて自然言語の説明を生成する説明可能なNLIシステムにとって特に重要です。 外部知識の統合はNLIシステムを改善することが示されており、ここではそれらの説明能力を向上させることができるかどうかを調査します。 このため、外部知識のさまざまなソースを調査し、ドメイン内データおよび細かい推論能力を評価するように設計された特別な転送データセットでのモデルのパフォーマンスを評価します。 異なる知識源は、例えば、言語モデルに保存された暗黙の知識が、数値や否定に関する推論を妨げる可能性があるなど、推論能力に異なる影響を及ぼすことがわかっている。 最後に、これまでで最大かつ最も細かく説明可能なNLIクラウドソーシング研究を行います。 自動パフォーマンススコアの大きな違いでさえ、ラベル、説明、常識、文法の正しさの人間的評価に反映されないことが明らかになりました。</abstract_ja>
      <abstract_zh>自然语言推理(NLI)求模形学用常识。 其于可解者NLI统尤要,非生成之外,犹生自然语言解。 外知之整合,已验可以改善NLI统,于此论其可以益其说。 故论外知之本,而论域内之数,及指评细粒度理能之殊传输数据集上。 臣等见异端,有异于推理,如言语模形隐性则碍数否之理。 最后迄今为止规模最大,最细粒度者可解NLI众包究。 明虽性能分数差异,不能见于人,说,常识语法正确性之评级也。</abstract_zh>
      <abstract_hi>प्राकृतिक भाषा अनुमान (एनएलआई) को सामान्य ज्ञान ज्ञान को सीखने और लागू करने के लिए मॉडल की आवश्यकता होती है। ये तर्क क्षमताएं विशेष रूप से स्पष्ट एनएलआई प्रणालियों के लिए महत्वपूर्ण हैं जो उनके लेबल की भविष्यवाणी के अलावा एक प्राकृतिक भाषा स्पष्टीकरण उत्पन्न करती हैं। बाहरी ज्ञान के एकीकरण को एनएलआई प्रणालियों में सुधार करने के लिए दिखाया गया है, यहां हम जांच करते हैं कि क्या यह उनकी स्पष्टीकरण क्षमताओं में भी सुधार कर सकता है। इसके लिए, हम बाहरी ज्ञान के विभिन्न स्रोतों की जांच करते हैं और इन-डोमेन डेटा के साथ-साथ विशेष हस्तांतरण डेटासेट पर हमारे मॉडल के प्रदर्शन का मूल्यांकन करते हैं जो ठीक-ठाक तर्क क्षमताओं का आकलन करने के लिए डिज़ाइन किए गए हैं। हम पाते हैं कि ज्ञान के विभिन्न स्रोतों का तर्क क्षमताओं पर एक अलग प्रभाव पड़ता है, उदाहरण के लिए, भाषा मॉडल में संग्रहीत अंतर्निहित ज्ञान संख्याओं और नकारों पर तर्क में बाधा डाल सकता है। अंत में, हम आज तक के सबसे बड़े और सबसे ठीक-ठाक स्पष्ट एनएलआई क्राउडसोर्सिंग अध्ययन का संचालन करते हैं। यह पता चलता है कि स्वचालित प्रदर्शन स्कोर में भी बड़े अंतर न तो लेबल, स्पष्टीकरण, कॉमनसेंस और न ही व्याकरण शुद्धता की मानव रेटिंग में प्रतिबिंबित होते हैं।</abstract_hi>
      <abstract_ga>Teastaíonn samhlacha ó thátal nádúrtha teanga (NLI) chun eolas ciallmhar a fhoghlaim agus a chur i bhfeidhm. Tá na cumais réasúnaíochta seo thar a bheith tábhachtach do chórais NLI inmhínithe a ghineann míniúchán teanga nádúrtha i dteannta lena dtuar lipéid. Léiríodh go bhfeabhsaítear córais LNÉ trí chomhtháthú an eolais sheachtraigh, agus anseo fiosraimid an féidir leis a gcumas míniúcháin a fheabhsú freisin. Chuige sin, déanaimid imscrúdú ar fhoinsí éagsúla eolais sheachtraigh agus déanaimid meastóireacht ar fheidhmíocht ár samhlacha ar shonraí in-fhearainn agus ar thacair sonraí aistrithe speisialta atá deartha chun cumais réasúnaíochta mhínínithe a mheas. Faighimid amach go mbíonn tionchar difriúil ag foinsí éagsúla eolais ar chumais réasúnaíochta, mar shampla, is féidir le heolas intuigthe atá stóráilte i múnlaí teanga bac a chur ar réasúnaíocht ar uimhreacha agus ar dhiúltaí. Ar deireadh, déanaimid an staidéar sluafhoinsithe de chuid LNÉ is mó agus is míne inmhínithe go dtí seo. Léiríonn sé nach léiríonn fiú difríochtaí móra sna scóir feidhmíochta uathoibríocha sna rátálacha daonna maidir le lipéad, míniú, tuiscint choitianta ná cruinneas gramadaí.</abstract_ga>
      <abstract_hu>A természetes nyelvi következtetés (NLI) modelleket igényel a közértelmes ismeretek tanulásához és alkalmazásához. Ezek az érvelési képességek különösen fontosak a megmagyarázható NLI rendszerek esetében, amelyek természetes nyelvi magyarázatot generálnak a címke előrejelzése mellett. A külső tudás integrációja bizonyítottan javítja az NLI rendszereket, itt azt vizsgáljuk, hogy képes-e javítani a magyarázat képességeit is. Ennek érdekében a külső ismeretek különböző forrásait vizsgáljuk, és értékeljük modelleink teljesítményét a tartományon belüli adatokon, valamint speciális átviteli adatkészleteken, amelyek a finomszemcsés érvelési képességek felmérésére szolgálnak. Megállapítjuk, hogy a különböző tudásforrások eltérő hatással vannak az érvelési képességekre, például a nyelvi modellekben tárolt implicit tudás akadályozhatja a számok és tagadások érvelését. Végül végezzük el az eddigi legnagyobb és legfinomabb magyarázható NLI crowdsourcing tanulmányt. Feltárja, hogy még az automatikus teljesítmény pontszámok közötti nagy különbségek sem tükröznek az emberi értékelésekben a címke, magyarázat, közérzet vagy nyelvtani helyesség.</abstract_hu>
      <abstract_el>Το συμπέρασμα φυσικής γλώσσας απαιτεί μοντέλα για να μάθουν και να εφαρμόσουν γνώση κοινής λογικής. Αυτές οι ικανότητες συλλογισμού είναι ιδιαίτερα σημαντικές για τα εξηγητά συστήματα που παράγουν μια φυσική εξήγηση γλώσσας εκτός από την πρόβλεψη ετικετών τους. Η ενσωμάτωση εξωτερικών γνώσεων έχει αποδειχθεί ότι βελτιώνει τα συστήματα Εδώ ερευνούμε αν μπορεί επίσης να βελτιώσει τις δυνατότητες εξήγησης τους. Για το σκοπό αυτό, διερευνούμε διαφορετικές πηγές εξωτερικής γνώσης και αξιολογούμε την απόδοση των μοντέλων μας σε δεδομένα εντός του τομέα καθώς και σε ειδικά σύνολα δεδομένων μεταφοράς που έχουν σχεδιαστεί για την αξιολόγηση των δυνατοτήτων λεπτού συλλογισμού. Διαπιστώνουμε ότι διαφορετικές πηγές γνώσης έχουν διαφορετική επίδραση στις ικανότητες συλλογισμού, για παράδειγμα, η σιωπηρή γνώση που αποθηκεύεται σε γλωσσικά μοντέλα μπορεί να εμποδίσει τη συλλογιστική αριθμών και αρνήσεων. Τέλος, διεξάγουμε τη μεγαλύτερη και πιο λεπτόκοκκη επεξηγητή μελέτη μέχρι σήμερα. Αποκαλύπτει ότι ακόμη και μεγάλες διαφορές στις αυτόματες βαθμολογίες απόδοσης δεν αντικατοπτρίζονται στις ανθρώπινες αξιολογήσεις της ετικέτας, της επεξήγησης, της κοινής λογικής ή της γραμματικής ορθότητας.</abstract_el>
      <abstract_ka>ნაირადი ენის ინფრენცია (NLI) უნდა მოდელების შესწავლება და გამოყენება საერთო სიცოცხლე. ეს პარამენტიური შესაძლებლობა განსაზღვრებელი NLI სისტემებისთვის მნიშვნელოვანია, რომელიც თავის ლაბეტის წარმოდგენის დამატებით ნახვა ენის გახსნა. გარეშე ცნობილების ინტერგურაცია გამოჩვენებულია, რომ NLI სისტემების უფრო მეტირებად, აქ ჩვენ ვაკეთებთ თუ ეს შეუძლია ასევე უფრო მეტირება შესაძლებლობა. ამისთვის, ჩვენ განსხვავებული გარეშე ცნობილების განსხვავებული გამოყენება და ჩვენი მოდელების გამოყენება დემომინის მონაცემებზე და სპეციალური გარეშე მონაცემების შესახებ, რომლებიც განაზღვრებულია ჩვენ ვიფიქრობთ, რომ განსხვავებული მეცნიერების გამოსახულების განსხვავებული ეფექტი არსებობს რაოდენობის შესაძლებლობაზე, მაგალითად, ენის მოდელში მუშაობული მეცნიერების შესაძლებელია რაო საბოლოოდ, ჩვენ გავაკეთებთ უფრო დიდი და უკეთესი განახსენებელი NLI მუშაობის სწავლა. ეს აღმოჩნდება, რომ კიდევ დიდი განსხვავებები ავტომატური განსხვავებაში არ განსხვავებენ ადამიანის რეტენტირებში, განსხვავებაში, საშუალოდ განსხვავებაში არ განსხვავებენ,</abstract_ka>
      <abstract_it>L'inferenza del linguaggio naturale (NLI) richiede modelli per imparare e applicare conoscenze di senso comune. Queste capacità di ragionamento sono particolarmente importanti per i sistemi NLI spiegabili che generano una spiegazione del linguaggio naturale in aggiunta alla loro previsione dell'etichetta. L'integrazione delle conoscenze esterne ha dimostrato di migliorare i sistemi NLI, qui si studia se può anche migliorare le loro capacità di spiegazione. Per questo, esaminiamo diverse fonti di conoscenza esterna e valutiamo le prestazioni dei nostri modelli su dati in-domain e su set di dati speciali di trasferimento progettati per valutare capacità di ragionamento a grana fine. Troviamo che diverse fonti di conoscenza hanno un effetto diverso sulle capacità di ragionamento, ad esempio, le conoscenze implicite memorizzate nei modelli linguistici possono ostacolare il ragionamento su numeri e negazioni. Infine, conduciamo lo studio di crowdsourcing NLI più ampio e spiegabile fino ad oggi. Essa rivela che anche le grandi differenze nei punteggi delle prestazioni automatiche non riflettono nelle valutazioni umane di etichetta, spiegazione, senso comune o correttezza grammaticale.</abstract_it>
      <abstract_lt>Natural language inference (NLI) requires models to learn and apply commonsense knowledge.  Šie pagrįstieji gebėjimai ypač svarbūs aiškioms NLI sistemoms, kurios, be etiketės prognozės, sukuria natūralų kalbos paaiškinimą. Įrodyta, kad išorės žinių integracija pagerina NLI sistemas, čia mes tiriame, ar ji taip pat gali pagerinti jų paaiškinimo gebėjimus. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  Nustatome, kad skirtingi žinių šaltiniai turi skirtingą poveikį pagrįstiesiems gebėjimams, pavyzdžiui, netiesioginės kalbų modeliuose saugomos žinios gali trukdyti pagrįsti skaičių ir neigiamus gebėjimus. Galiausiai iki šiol atliekame didžiausią ir geriausiai paaiškinamą NLI visuomenės išteklių tyrimą. Iš jo matyti, kad net dideli automatinių veikimo rezultatų skirtumai neatspindi nei žmogaus etiketės, paaiškinimo, bendro pobūdžio, nei gramatinio tikslumo vertinimų.</abstract_lt>
      <abstract_kk>Табиғлық тіл инференциясы (NLI) үлгілерін үйрену және көпшілік мәліметтерді қолдану үшін керек. Бұл сезімдік мүмкіндіктері өзінің белгілерін таңдау үшін түсініктіретін NLI жүйелері үшін өте маңызды. Сыртқы білімдердің интеграциясы NLI жүйелерін жақсарту үшін көрсетілді. Бұл жерде біз оның түсіндіру мүмкіндіктерін де жақсартуға болады. Бұл үшін біз сыртқы білім көзін зерттеп, домен деректерінің үлгілеріміздің және арнайы аудару деректер жиындарын оқу үшін құрылған. Мысалы, тіл үлгілерінде сақталған мәліметтердің түрлі мәліметтерінің басқа нәтижелері сандар мен негативтер үшін тұратын мәліметтердің әртүрлі нәтижелері бар. Соңында, біз NLI көпшілік көпшіліктерінің ең үлкен және ең жақсы түсінікті зерттеуді жасадық. Бұл автоматты істеу нәтижесінің үлкен түрлері адамдардың белгілері, түсініктемелері, көпшілікті және грамматикалық дұрыстығын көрсетпейді.</abstract_kk>
      <abstract_mk>Природната инференција на јазикот (NLI) бара модели за учење и примена на заедничко знаење. Овие размислувачки способности се особено важни за објаснливите системи на НЛИ кои генерираат природно објаснување на јазикот покрај нивните предвидувања на етикетата. Интеграцијата на надворешното знаење покажа дека ќе ги подобри системите на НЛИ, тука истражуваме дали тоа може, исто така, да ги подобри нивните објаснувачки способности. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  Најдовме дека различните извори на знаење имаат различен ефект на размислувачките способности, на пример, имплицитното знаење складирано во јазичките модели може да го попречи размислувањето на броевите и негативите. Конечно, досега ја спроведуваме најголемата и најубавата објаснлива студија на НЛИ за пулсорсирање. Истата открива дека дури и големите разлики во автоматските резултати не одразуваат ниту во човечките рејтинзи на етикетата, објаснувањето, заедничката ниту граматичната коректност.</abstract_mk>
      <abstract_ms>Keputusan bahasa semulajadi (NLI) memerlukan model untuk belajar dan melaksanakan pengetahuan umum. These reasoning abilities are particularly important for explainable NLI systems that generate a natural language explanation in addition to their label prediction.  Penyempurnaan pengetahuan luaran telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki sama ada ia juga boleh meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luaran yang berbeza dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data pemindahan khas yang direka untuk mengevaluasi kemampuan pemakaian yang sempurna. Kami mendapati bahawa sumber pengetahuan berbeza mempunyai kesan yang berbeza pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa boleh menghalang reasoning pada nombor dan negatif. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling baik yang boleh dijelaskan sehingga kini. Ia mengungkapkan bahawa walaupun perbezaan besar dalam skor prestasi automatik tidak mencerminkan dalam nilai manusia label, penjelasan, umum atau kebijaksanaan grammar.</abstract_ms>
      <abstract_ml>സ്വാഭാവികമായ ഭാഷ അപരിഹാരം ആവശ്യപ്പെടുന്നു. കമോണ്‍സണ്‍സെന്‍സ് അറിവ് പഠിക്കുകയും പ്രയോഗിക്കുകയും ചെയ്യാ ഈ കാരണങ്ങളുടെ കഴിവുകള്‍ വ്യക്തമാക്കാന്‍ കഴിയുന്ന NLI സിസ്റ്റമുകള്‍ക്ക് പ്രധാനപ്പെട്ടതാണ്. അവയുടെ ലേബിള്‍ പ്രവചനങ്ങള്‍ക് പുറത്തുള്ള അറിവുകളുടെ കൂട്ടത്തില്‍ NLI സിസ്റ്റം മെച്ചപ്പെടുത്തുന്നതിനായി കാണിച്ചിരിക്കുന്നു. ഇവിടെ നമ്മള്‍ അന് ഇതിനുവേണ്ടി ഞങ്ങള്‍ പുറത്തുള്ള അറിവുകളുടെ വ്യത്യസ്ത സ്രോതസ്സുകള്‍ അന്വേഷിക്കുകയും, നമ്മുടെ മോഡലുകളുടെ പ്രഭാവം ഡോമെയിന്‍ ഡേറ്റാകളുടെ പ്രഭാവം വി വ്യത്യസ്ത അറിവുകളുടെ സ്രോതസ്സുകള്‍ക്ക് വ്യത്യസ്ത പ്രഭാവം ഉണ്ടെന്ന് ഞങ്ങള്‍ കണ്ടെത്തുന്നു. ഉദാഹരണത്തിനായി ഭാഷ മോഡലില്‍ സൂക്ഷ അവസാനം, നമ്മള്‍ ഏറ്റവും വലിയ കിട്ടിയിട്ടുള്ള ഏറ്റവും സുന്ദരിയായിട്ടുള്ള ഏറ്റവും നല്ല കാര്യങ്ങള്‍ പ്രവര്‍ത്തിക്കുന സ്വയം പ്രവര്‍ത്തിപ്പിക്കുന്ന സ്കോര്‍സില്‍ വലിയ വ്യത്യാസങ്ങള്‍ പോലും മനുഷ്യരുടെ ലേബ്ലെറ്റിന്‍റെയും വിശദീകരണങ്ങള്‍, കമോണ്‍സണ</abstract_ml>
      <abstract_mt>L-inferenza lingwistika naturali (NLI) teħtieġ mudelli biex jitgħallmu u japplikaw għarfien komuni. Dawn l-abbiltajiet ta’ raġunament huma partikolarment importanti għal sistemi NLI li jistgħu jiġu spjegati li jiġġeneraw spjegazzjoni tal-lingwa naturali minbarra t-tbassir tat-tikketta tagħhom. Intwera li l-integrazzjoni tal-għarfien estern ittejjeb is-sistemi NLI, hawnhekk ninvestigaw jekk tistax ittejjeb ukoll il-kapaċitajiet ta’ spjegazzjoni tagħhom. Għal dan, ninvestigaw sorsi differenti ta’ għarfien estern u ninvestigaw il-prestazzjoni tal-mudelli tagħna fuq id-dejta fid-dominju kif ukoll fuq settijiet ta’ dejta speċjali ta’ trasferiment li huma mfassla biex jivvalutaw il-kapaċitajiet ta’ raġunament imfassla fin. Issibu li sorsi differenti ta’ għarfien għandhom effett differenti fuq il-ħiliet ta’ raġunament, pereżempju, għarfien impliċitu maħżun fil-mudelli lingwistiċi jista’ jfixkel ir-raġunament fuq in-numri u n-negazzjonijiet. Fl-aħħar nett, sal-lum qed nagħmlu l-akbar u l-aktar studju spjegabbli tal-crowdsourcing NLI. Jiżvela li anki differenzi kbar fil-punteġġi awtomatiċi tal-prestazzjoni la jirriflettu fil-klassifikazzjonijiet umani tat-tikketta, l-ispjegazzjoni, il-kunsens komuni u lanqas il-korrettezza grammarja.</abstract_mt>
      <abstract_mn>Байгалийн хэл халдвар (NLI) нь ерөнхий мэдрэмжтэй мэдлэг сурах, ашиглах загваруудыг шаарддаг. Эдгээр ойлголтын чадварууд нь ихэвчлэн хамгийн чухал NLI системүүдэд байгалийн хэл тодорхойлолт бий болгодог. Гадаан мэдлэгийн нэгтгэл нь NLI системийг сайжруулахын тулд харагдсан. Энд бид түүний тайлбарлалтын чадварыг сайжруулж чадах эсэхийг судалж байна. Үүний тулд бид гадаад мэдлэгийн өөр өөр эх үүсвэрүүдийг судалж, дотоод өгөгдлийн загварын үйл ажиллагааг үнэлэх боломжтой. Мөн өөр өөр шилжүүлэлтийн өгөгдлийн сангуудыг үнэлэх зорилготой. Бид өөр өөр мэдлэгийн эх үүсвэрүүд нь ойлголтын чадвар дээр өөр нөлөөтэй, жишээ нь хэл загваруудад хадгалагдсан үндсэн мэдлэг нь тоо болон сөрөг талаар бодохыг зогсоож чадна. Эцэст нь бид НЛИ-ын олон нийтийн хүмүүсийн асуудлын судалгааг хүртэл хамгийн том, хамгийн сайхан тарианы судалгаа хийсэн. Энэ нь автоматик үйлдвэрлэлийн оноо дээр маш их ялгаа ч хүн төрөлхтний загвар, тодорхойлолт, ерөнхий ойлголт, грамматик зөв байдлыг харуулж чадахгүй.</abstract_mn>
      <abstract_no>Naturspråk-infeksjon (NLI) krev modeller for å læra og bruka vanleg kunnskap. Desse grunnleggjande kapasitetene er spesielt viktige for forklarbare NLI-systemer som lagar eit naturleg språk-forklaring i tillegg til merkelappen sin forhåndsvising. Integreringen av eksterne kunnskap er vist for å forbetra NLI-systemet. Her er vi undersøk om det også kan forbetra utklaringskapasiteten sine. For dette, vi undersøker ulike kjelde for eksterne kunnskap og evaluerer utviklinga av våre modeller på interne domenedata, og på spesielle overføringsdata som er utforma for å vurdere fin-kornerte redensingskapasiteten. Vi finn at forskjellige kjelde av kunnskap har ein annan effekt på rasjonskobilitetar, for eksempel, implisitt kunnskap lagra i språk-modeller kan hindra rasjon på tall og negasjon. Etter slutt, vi gjer den største og mest fyrste forklarbare NLI crowdsourcing studien til dag. Det viser at sjølv store forskjeller i automatiske funksjonspoeng ikkje reflekterer i menneskelige retningar av etikett, forklaring, fellesskap eller gramatisk rettighet.</abstract_no>
      <abstract_pl>Inferencja języka naturalnego (NLI) wymaga modeli do nauki i stosowania wiedzy zdrowego rozsądku. Te zdolności rozumowania są szczególnie ważne dla wyjaśnionych systemów NLI, które generują wyjaśnienie języka naturalnego oprócz przewidywania etykiety. Wykazano, że integracja wiedzy zewnętrznej poprawia systemy NLI, tutaj badamy, czy może ona również poprawić ich możliwości wyjaśniania. W tym celu badamy różne źródła wiedzy zewnętrznej i oceniamy wydajność naszych modeli na danych wewnątrz domeny, jak również na specjalnych zbiorach danych transferowych, które mają na celu ocenę możliwości precyzyjnego rozumowania. Odkrywamy, że różne źródła wiedzy mają różny wpływ na zdolności rozumowania, na przykład wiedza domniemana przechowywana w modelach językowych może utrudniać rozumowanie liczb i negacji. Wreszcie prowadzimy do tej pory największe i najbardziej precyzyjne badanie crowdsourcingu NLI. Ujawnia ona, że nawet duże różnice w automatycznych wynikach wydajności nie odzwierciedlają ludzkiej oceny etykiety, wyjaśnienia, zdrowego rozsądku czy poprawności gramatycznej.</abstract_pl>
      <abstract_sr>Prirodna jezička infekcija (NLI) zahteva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja je pokazala kako bi poboljšala NLI sisteme, ovde istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskog znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne sete podataka koji su dizajnirani za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit uticaj na razumne sposobnosti, na primer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumljivanje na brojeve i negacije. Konačno, provedem najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. To otkriva da čak i velike razlike u automatskim rezultatima uspeha ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, čestitosti niti gramatičke ispravnosti.</abstract_sr>
      <abstract_ro>Inferența limbajului natural (NLI) necesită modele pentru a învăța și aplica cunoștințele de bun simț. Aceste abilități de raționament sunt deosebit de importante pentru sistemele NLI explicabile care generează o explicație de limbaj natural în plus față de predicția etichetei lor. Integrarea cunoștințelor externe a demonstrat că îmbunătățește sistemele NLI, aici investigăm dacă poate îmbunătăți și capacitățile lor de explicare. În acest scop, investigăm diferite surse de cunoștințe externe și evaluăm performanța modelelor noastre pe date în domeniu, precum și pe seturi de date speciale de transfer, concepute pentru a evalua capacitățile de raționament fină. Considerăm că diferitele surse de cunoaștere au un efect diferit asupra abilităților de raționament, de exemplu, cunoștințele implicite stocate în modele lingvistice pot împiedica raționamentul asupra numerelor și negațiilor. În cele din urmă, efectuăm cel mai mare și cel mai fin studiu de crowdsourcing explicabil NLI până în prezent. Aceasta dezvăluie că chiar și diferențele mari în scorurile automate de performanță nu reflectă în evaluările umane de etichetă, explicație, sens comun sau corectitudine gramaticală.</abstract_ro>
      <abstract_si>ස්වභාවික භාෂාව ප්‍රමාණය (NLI) අවශ්‍ය වෙනවා සාමාන්‍ය භාෂාවික දැනගන්න සහ අවශ්‍ය වෙන් මේ හේතුවක් ප්‍රශ්නයක් විශේෂයෙන් වැදගත් NLI පද්ධතියක් විස්තර කරන්න පුළුවන් විදිහට වැදගත් වෙනවා ඔවුන් පුරුද්ගලික දන්නවගේ සම්බන්ධයක් පෙන්වන්න පුළුවන් NLI පද්ධතිය වැඩ කරන්න, මෙතන අපි පරීක්ෂණය කරන්න පුළුවන් ක මේක සඳහා අපි ප්‍රතිශේෂ විවිධ දැනයේ වෙනස් ප්‍රතිශ්නයක් පරීක්ෂා කරනවා සහ අපේ මොඩේල්ස් ගැන ප්‍රතිශේෂ දත්ත සඳහා විශේෂ සං අපිට හොයාගන්න පුළුවන් වෙනස් දැනගන්න ප්‍රශ්නයක් තියෙනවා කියලා, උදාහරණයෙන්, භාෂා මොඩල් වල සංකේතයෙන් තියෙන අ අන්තිමේදි, අපි ලොකුම සහ හොඳම ප්‍රශ්නයක් කරනවා නිලි ජාතික විස්තර කරන්න පුළුවන් ප්‍රශ්නයක් තියෙන ඒක ප්‍රකාශ කරන්නේ ස්වයංක්‍රියාත්මක ක්‍රියාත්මක ක්‍රියාත්මක වෙනස් වගේම මිනිස්සුන්ගේ රේටින්ස් වලින් ප්‍රතිකා</abstract_si>
      <abstract_so>Cudurka afka asalka ah (NLI) wuxuu u baahan yahay qaabab barashada iyo codsashada aqoonta shirkadda. Aqooyinkan sababta ah si gaar ah waa muhiim u ah nidaamka NLI ee aan la caddeyn karin, taas oo soo saara fasirada afka dabiicadda ah, iyadoo aan laguu sii sheegin calaamada. La-qabsashada aqoonta dibadda waxaa lagu muujiyey in la kordhiyo nidaamka NLI, halkan waxaynu baaraynaa inay kordhin karto awoodooda turjumista. Taas darteed waxaynu baaraynaa noocyo kala duduwan aqoonta dibadda ah iyo waxaynu qiimeynaynaa sameynta sameynta modellka macluumaadka gudaha iyo sawirada macluumaadka gaarka ah oo loo qoray si aan u qiimeyno awoodaha garashada. Waxaynu aragnaa in noocyada aqoonta kala duduwan ay saameyn u leeyihiin waxyaabo kala duduwan, tusaale ahaan aqoonta ku saabsan noocyada luuqada lagu kaydiyey waxay ka hor mari karaan arrimaha ku saabsan lambarada iyo waxyaabaha la naco. Ugu dambaysta, waxaynu sameynaa waxbarashada kooxaha dadka NLI ee ugu waaweyn ee ugu fiican. Waxay muuqataa in xittaa kala duwanaanshaha badan oo ay iskuulaadka farsamada iskuulka ah ku jiraan kuma fikiraan qiyaastii dadka, fasax, faqan ama hagaajinta qofka.</abstract_so>
      <abstract_ur>طبیعی زبان ایفارنس (NLI) کی مدل کی ضرورت ہے کہ معمولی علم کی تعلیم اور استعمال کریں۔ یہ منطقی قابلیت ان کے لیبل پیش بینی کے علاوہ ایک طبیعی زبان کی توضیح پیدا کرتی ہیں۔ بیرونی علم کی تعلیم NLI سیستموں کو بہتر کرنے کے لئے دکھائی گئی ہے، یہاں ہم تحقیق کرتے ہیں کہ یہ ان کی توضیح کے قابلیت بھی بہتر کر سکتا ہے. اس کے لئے ہم باہر علم کے مختلف سراسروں کی تحقیق کرتے ہیں اور ہمارے مدلکوں کے عملکرد کو دامین میں ڈیٹے پر مطالعہ کرتے ہیں اور ویسی ترنسیٹ ڈیٹ سٹ پر بھی مطالعہ کئے جاتے ہیں جو مطالعہ اندازے کے قابلیت کی آزمائش کے لئے طراحی ک ہمیں معلوم ہے کہ علم کے مختلف سرمالوں کے باعث منطقی قابلیت پر مختلف اثر ہے، مثال، زبان مدلکوں میں ذخیره ہوئی معلومات کی تعداد اور منطقی کے باعث منطقی کرسکتی ہے. آخر میں ہم نے سب سے بڑے اور بہترین دانے کا مفصل کر لیا ہے۔ یہ ظاہر کرتا ہے کہ اٹوٹیٹ کروٹ سکونٹوں میں بھی بہت بڑی اختلاف بھی نہیں کرتی لیبل، توضیح، معمولی اور گرامی اصلاح میں.</abstract_ur>
      <abstract_sv>Naturligt språk inferens (NLI) kräver modeller för att lära sig och tillämpa allmännyttig kunskap. Dessa resonemang förmågor är särskilt viktiga för förklaringsbara NLI-system som genererar en naturlig språkförklaring utöver deras etikettprediktion. Integrationen av extern kunskap har visat sig förbättra NLI-system, här undersöker vi om det också kan förbättra deras förklaringsförmåga. För detta undersöker vi olika källor till extern kunskap och utvärderar prestandan hos våra modeller på domändata samt på speciella överföringsdatauppsättningar som är utformade för att bedöma finkorniga resonemang. Vi finner att olika kunskapskällor har en annan effekt på resonemang förmågor, till exempel implicit kunskap lagrad i språkmodeller kan hindra resonemang om siffror och negationer. Slutligen genomför vi den största och mest finkorniga förklaringsbara NLI crowdsourcingsstudien hittills. Det avslöjar att även stora skillnader i automatiska prestationspoäng varken återspeglar mänskliga bedömningar av etikett, förklaring, allmänst eller grammatik korrekthet.</abstract_sv>
      <abstract_ta>இயல்பான மொழி குறைவு (NLI) தொழில்நுட்ப அறிவை கற்று பயன்படுத்த மாதிரிகள் தேவைப்படுகிறது. இந்த காரணங்கள் விளக்கமுடியாத NLI அமைப்புகளுக்கு குறிப்பாக முக்கியமானது. அது ஒரு இயல்பான மொழி விளக்கம் உருவாக்குகிறது  வெளி அறிவின் ஒன்றிணைப்பு NLI முறைமைகளை மேம்படுத்துவதற்கு காண்பிக்கப்பட்டுள்ளது, இது அவர்களுடைய விளக்கங்களின் இயல்புகளை  இதுக்கு, நாம் வெளி அறிவின் மூலங்களை ஆராய்ச்சி மற்றும் எங்கள் மாதிரிகளின் செயல்பாட்டை கண்டறிக்கிறோம் மற்றும் சிறப்பு மாற்றும் தகவல் அமைப்புகளில மொழி மாதிரிகளில் சேமிக்கப்பட்ட அறிவு மூலம் எண்கள் மற்றும் எதிர்மங்கள் பற்றி குறித்துக் கொள்ள வேறு விளைவுகள் இருக்கும் என்பதை நா இறுதியில், நாங்கள் பெரிய மற்றும் மிகவும் நல்ல பிரச்சனையான NLI மக்கள் மூல வளைவு பட்டியலை நடத்துகிறோம். அது தானியங்கி செய்யும் புள்ளிகளில் பெரிய வேறுபாடுகளுக்கு கூட தெளிவுபடுத்துகிறது விளக்கத்தின் விளக்கங்கள், விளக்கம</abstract_ta>
      <abstract_uz>Natalik til infeksiyati (NLI) modellarni o'rganish va qoʻllash uchun kerak. Bu sabablar qobiliyatlari ularning yorliq oldini oldinga oddiy tilning forklarini yaratadigan NLI tizimlariga muhim. Tashqi ta'limning birlashtirish NLI tizimlarini yaxshi ko'rsatadi. Bu yerda biz ularning fikrlarining imkoniyatlarini bajarishi mumkin deb o'rganamiz. Bu uchun, biz tashqi ta'limning boshqa manbalarini qidirib, domen maʼlumotidagi modellarimizning natijasini qiymatimiz, va xavfsiz tarkib maʼlumotlar tarkibida o'zgartirish qoidalarini qidirish uchun qo'llanmalar mumkin. Biz o'ylaymiz, boshqa ta'lim manbaslari haqida ma'lumotga ega bo'ladi. Masalan, tildagi modellarda saqlangan ilmo'zi sonlar va negativ haqida g'oyalarni o'zgartiradi. Endi biz hozirda eng katta va eng yaxshi ajoyib bo'lgan NLI jamoatlarni o'rganamiz. U avtomatik foydalanuvchi darajadagi katta ўзгаришларни ko'rsatadi, odamning qismlarini, faqat fasirlash, murakkab va grammatik toʻgʻri haqida o'ylamaydi.</abstract_uz>
      <abstract_vi>Kết quả ngôn ngữ tự nhiên (NLI) đòi hỏi các mẫu học hỏi và áp dụng các kiến thức thông thường. Những khả năng lập luận này rất quan trọng với hệ thống NIL có thể giải thích ngôn ngữ tự nhiên, cùng với dự đoán nhãn hiệu của chúng. Sự hợp nhất của kiến thức bên ngoài đã được cho thấy nhằm cải thiện hệ thống NIL, tại đây chúng tôi đang tìm hiểu liệu nó có thể cải thiện khả năng giải thích của chúng. Chúng tôi nghiên cứu các nguồn kiến thức bên ngoài khác nhau và đánh giá khả năng làm việc của các mẫu trên dữ liệu nội bộ, cũng như các tập tin giao dịch đặc biệt được thiết kế để đánh giá các khả năng lập luận ổn định. Chúng tôi thấy những nguồn kiến thức khác nhau có ảnh hưởng khác nhau đến khả năng lập luận, ví dụ, kiến thức ngầm được cất giữ trong mô hình ngôn ngữ có thể gây trở ngại việc lập luận về con số và âm bản. Cuối cùng, chúng tôi tiến hành nghiên cứu tài nguyên cao nhất và được giải thích cao nhất. Nó tiết lộ rằng thậm chí sự khác nhau lớn trong tỉ số hiệu suất tự động cũng không phản ánh các đánh giá của nhân loại về nhãn hiệu, cách giải thích, lẽ thường hay sửa ngữ pháp.</abstract_vi>
      <abstract_bg>Природните езикови изводи (НЛИ) изискват модели за учене и прилагане на разумни знания. Тези способности за разсъждаване са особено важни за обясними системи, които генерират естествено езиково обяснение в допълнение към прогнозирането на етикета. Доказано е, че интегрирането на външни знания подобрява системите на НЛИ, тук изследваме дали може да подобри и техните обяснителни възможности. За тази цел ние изследваме различни източници на външни знания и оценяваме ефективността на нашите модели върху вътрешни данни, както и върху специални набори от данни за трансфер, които са предназначени да оценят фините възможности за разсъждаване. Откриваме, че различните източници на знания имат различен ефект върху способностите за разсъждаване, например имплицитното знание, съхранявано в езиковите модели, може да възпрепятства разсъждаването на числа и отрицания. И накрая, ние провеждаме най-голямото и най-фино обяснимо проучване на НЛИ crowdsourcing досега. Тя разкрива, че дори големите разлики в автоматичните резултати не отразяват нито в оценките на етикета, обяснението, благоразумието, нито граматическата коректност.</abstract_bg>
      <abstract_nl>Natural language inference (NLI) vereist modellen om gezond verstand te leren en toe te passen. Deze redeneringsvaardigheden zijn vooral belangrijk voor uitlegbare NLI-systemen die naast hun labelvoorspelling ook een natuurlijke taalverklaring genereren. De integratie van externe kennis is aangetoond om NLI-systemen te verbeteren, hier onderzoeken we of het ook hun verklaringsmogelijkheden kan verbeteren. Hiervoor onderzoeken we verschillende bronnen van externe kennis en evalueren we de prestaties van onze modellen op in-domain data en op speciale transfer datasets die zijn ontworpen om fijngranige redeneermogelijkheden te beoordelen. We vinden dat verschillende bronnen van kennis een ander effect hebben op redeneringsvermogen, bijvoorbeeld impliciete kennis opgeslagen in taalmodellen kan redeneren over getallen en ontkenningen belemmeren. Tot slot voeren we de grootste en meest fijngranige uitlegbare NLI crowdsourcing studie uit tot nu toe. Het toont aan dat zelfs grote verschillen in automatische prestatiescores geen weerspiegeling zijn in menselijke beoordelingen van label, uitleg, gezond verstand of grammatica correctheid.</abstract_nl>
      <abstract_de>Natural Language Inference (NLI) erfordert Modelle, um gesundes Wissen zu lernen und anzuwenden. Diese Argumentationsfﾃ､higkeiten sind besonders wichtig fﾃｼr erklﾃ､rbare NLI-Systeme, die zusﾃ､tzlich zu ihrer Label-Vorhersage eine natﾃｼrliche Spracherklﾃ､rung generieren. Die Integration von externem Wissen hat gezeigt, dass NLI-Systeme verbessert werden, hier untersuchen wir, ob es auch deren Erklﾃ､rungsfﾃ､higkeit verbessern kann. Dazu untersuchen wir verschiedene Quellen externer Erkenntnisse und bewerten die Performance unserer Modelle sowohl auf In-Domain-Daten als auch auf speziellen Transferdatensﾃ､tzen, die zur Beurteilung feingranularer Denkfﾃ､higkeiten konzipiert sind. Wir stellen fest, dass unterschiedliche Wissensquellen unterschiedliche Auswirkungen auf die Denkfﾃ､higkeit haben. Beispielsweise kann implizites Wissen, das in Sprachmodellen gespeichert ist, das Argumentieren von Zahlen und Negationen behindern. Schlieﾃ殕ich fﾃｼhren wir die bisher grﾃｶﾃ殳e und feinkﾃｶrnigste erklﾃ､rbare NLI Crowdsourcing-Studie durch. Es zeigt sich, dass sich selbst groﾃ歹 Unterschiede in den automatischen Leistungswerten weder in der menschlichen Bewertung von Label, Erklﾃ､rung, gesundem Menschenverstand noch grammatikalischer Korrektheit widerspiegeln.</abstract_de>
      <abstract_da>Naturligt sprog inference (NLI) kræver modeller til at lære og anvende almindelig viden. Disse ræsonnement evner er særligt vigtige for forklarelige NLI-systemer, der genererer en naturlig sprogforklaring ud over deres etiket forudsigelse. Integrationen af ekstern viden har vist sig at forbedre NLI systemer, her undersøger vi, om det også kan forbedre deres forklaringsmuligheder. Til dette undersøger vi forskellige kilder til ekstern viden og evaluerer ydeevnen af vores modeller på domænedata såvel som på særlige overførselsdatasæt, der er designet til at vurdere finkornede ræsonnementsfunktioner. Vi finder ud af, at forskellige kilder til viden har en anden effekt på ræsonnement evner, for eksempel kan implicit viden lagret i sprogmodeller hindre ræsonnement om tal og negationer. Endelig gennemfører vi den største og mest finkornede forklarelige NLI crowdsourcing undersøgelse hidtil. Det afslører, at selv store forskelle i automatiske resultater hverken afspejler i menneskelige vurderinger af etiket, forklaring, almindelighed eller grammatik korrekthed.</abstract_da>
      <abstract_hr>Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja običnog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sustave koji stvaraju prirodno objašnjenje jezika u dodatnoj predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sustave, ovdje istražujemo može li i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne prijenosne podatke koje su dizajnirane za procjenu potpunih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit učinak na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumjevanje brojeva i negacija. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI crowdsourcing do sada. Otkriva se da čak i velike razlike u automatskim rezultatima učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti ispravnosti gramatike.</abstract_hr>
      <abstract_fa>آلودگی زبان طبیعی (NLI) نیاز به مدل‌های یادگیری و استفاده از دانش معمولی است. این توانایی منطقی برای سیستم های NLI قابل توضیح و توضیح زبان طبیعی در addition to their label prediction مهم است. جمع علم خارجی نشون داده شده تا سیستم‌های NLI را بهتر کند، اینجا تحقیق کنیم که آیا می‌تواند توانایی توضیح‌شان را بهتر کند. برای این، ما منبع های مختلف دانش خارجی را تحقیق می کنیم و عملکرد مدل های ما را در اطلاعات دامنی‌های خاص و در مجموعه‌های انتقال داده‌های خاصی که طراحی شده‌اند برای ارزیابی توانایی‌های منطقی‌کننده‌های پاکیزه‌ی دانه‌های خارجی ارزی ما متوجه شدیم که منابع مختلف علم تأثیر متفاوتی بر توانایی منطقی دارند، برای مثال، دانش معمولی که در مدلهای زبانی ذخیره شده است، می تواند منطقی در شماره و منطقی را متوقف کند. بالاخره، ما بزرگترین و بهترین دانه‌های توضیح قابل توضیح عمومی NLI را تا حالا انجام می‌دهیم. این نشان می دهد که حتی تفاوت های بزرگ در امتیاز عملکرد خودکار در امتیاز های نقاشی، توضیح، معمولی و درستی نقاشی انسان تفکیر نمی کنند.</abstract_fa>
      <abstract_id>Keputusan bahasa alam (NLI) membutuhkan model untuk belajar dan menerapkan pengetahuan umum. Kemampuan alasan ini sangat penting untuk sistem NLI yang dapat dijelaskan yang menghasilkan penjelasan bahasa alami selain prediksi label mereka. Integrasi pengetahuan luar telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki apakah itu juga dapat meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luar yang berbeda dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data transfer khusus yang direncanakan untuk mengevaluasi kemampuan pemikiran yang baik. Kami menemukan bahwa sumber pengetahuan yang berbeda memiliki efek yang berbeda pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa dapat menghalangi reasoning pada angka dan negati. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling bagus yang bisa dijelaskan sampai saat ini. Hal ini mengungkapkan bahkan perbedaan besar dalam skor prestasi otomatis tidak merefleksikan dalam nilai manusia label, penjelasan, umum atau persis grammar.</abstract_id>
      <abstract_sw>Upunguzo wa lugha ya asili (NLI) unahitaji mifano ya kujifunza na kutumia maarifa ya umma. Tamko hizi zinazoelezea ni muhimu kwa mfumo wa NLI unaotengeneza maelezo ya lugha asili zaidi ya utabiri wao wa alama. Ushirikiano wa maarifa ya nje umeonyesha kuboresha mifumo ya NLI, hapa tunachunguza kama inaweza pia kuboresha uwezo wa maelezo yao. Kwa hili, tunachunguza vyanzo tofauti vya ufahamu wa nje na kutathmini ufanisi wa mifano yetu kwenye data za ndani pamoja na kwenye seti maalum za usafirishaji ambazo zinalengwa kutathmini uwezo wa kufikiriwa vizuri. Tunapata kwamba vyanzo tofauti vya maarifa vina athari tofauti juu ya uwezo wa kuzingatia, kwa mfano, maarifa yaliyohifadhiwa katika mifano ya lugha yanaweza kuzuia mawazo kuhusu idadi na hasi. Mwisho, tunafanya utafiti mkubwa zaidi na wenye ufafanuzi mkubwa zaidi wa vyama vya habari vya NLI mpaka sasa. Inaonyesha kwamba hata tofauti kubwa katika vipimo vya utendaji vya kujitegemea hazitafakari katika viwango vya kibinadamu vya alama, maelezo, makubaliano wala sahihi.</abstract_sw>
      <abstract_ko>자연 언어 추리(NLI)는 상식 지식을 모형 학습하고 응용해야 한다.이러한 추리력은 해석 가능한 NLI 시스템에 특히 중요하다. 이런 시스템은 라벨 예측 외에 자연 언어 해석도 생성한다.외부 지식의 통합이 NLI 시스템을 개선할 수 있다는 것이 증명되었는데, 여기서 우리는 그것이 그들의 해석 능력을 향상시킬 수 있는지를 연구한다.이를 위해 우리는 외부 지식의 서로 다른 출처를 조사하고 우리의 모델이 역내 데이터와 세립도 추리 능력을 평가하는 특수 전송 데이터 집합의 성능을 평가했다.우리는 서로 다른 지식의 출처가 추리 능력에 서로 다른 영향을 미친다는 것을 발견했다. 예를 들어 언어 모델에 저장된 숨은 지식은 숫자와 부정에 대한 추리를 방해할 수 있다.마지막으로 우리는 지금까지 규모가 가장 크고 입도가 가장 가는 NLI 클러스터 연구를 진행했다.연구에 따르면 자동 성적의 큰 차이도 라벨, 해석, 상식과 문법의 정확성에 대한 인류의 평점에 반영되지 않는다.</abstract_ko>
      <abstract_tr>Tebiýal dil azalyşyk (NLI) duýdury bilgi öwrenmek we uygulamak üçin nusgalary gerek. Bu razylyk başaryşlary etiket öňünden boşluşyk bilen tebigy dili düşündirjek NLI sistemalary üçin has möhüm. Daşarydaky bilim üýtgetmegi NLI sistemalaryny geliştirmek üçin görkezildi. Şu ýerde biz munuň olaryň düşündirişi başarylygyny geliştirmegi mümkin edýändigini soradyk. Bu üçin biz daşarydaky bilim sistemleriniň farklı çeşmelerini inceleýäris we domençe maglumatlarymyzda modellerimiziň eserini deňleýäris we gowy gabat etmek üçin tasarlanýan aýratyn transfers veri setirlerini deňleýäris Bilim sistemleriniň farklı kaynaklarynyň düşünüp ukyplaryna üýtgeşik bar, meselâ, dil modellerinde gaýd edilen bilim sistemleri rakamlar we bölümlerde düşünüpden çykaryp biler. Soňunda biz iň uly we iň gowy görnümli NLI köpüşiklik isleýän ylgamy ýerine ýetirdik. Muny otomatik netijesinde hatda näçe üýtgeşmeler etiket, düşündirim, jemgyýetçilik we gramatik dogrylygynda täsirleýändirler.</abstract_tr>
      <abstract_sq>Përfundimi natyror i gjuhës (NLI) kërkon modele për të mësuar dhe aplikuar njohuri të përbashkët. Këto aftësi arsyetimi janë veçanërisht të rëndësishme për sistemet e shpjeguara të NLI që gjenerojnë një shpjegim natyror gjuhës përveç parashikimit të etiketës së tyre. Integrimi i njohurive të jashtme është treguar për të përmirësuar sistemet NLI, këtu ne hetojmë nëse mund të përmirësojë gjithashtu aftësitë e tyre të shpjegimit. Për këtë, ne hetojmë burime të ndryshme të njohurive të jashtme dhe vlerësojmë performancën e modeleve tona në të dhënat në domeni si dhe në grupe të dhënash të posaçme transferimi që janë dizajnuar për të vlerësuar aftësitë e arsyetimit të hollësishëm. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations.  Më në fund, ne kryejmë studimin më të madh dhe më të hollë të shpjeguar të NLI crowdsourcing deri tani. Ajo zbulon se edhe dallime të mëdha në rezultatet e performancës automatike nuk pasqyrojnë as në vlerësimet njerëzore të etiketës, shpjegimit, të zakonshme as korrektësisë gramatike.</abstract_sq>
      <abstract_af>Natuurlike taal inferensie (NLI) benodig modele om gemeenskaplike kennis te leer en toewend. Hierdie redelike moontlikhede is besonderlik belangrik vir verduidelike NLI stelsels wat 'n natuurlike taal uitduidelik genereer in addition to their label prediction. Die integrasie van eksterne kennis is vertoon om NLI stelsels te verbeter, hier ondersoek ons of dit ook hulle uitduidelingskapasiteite kan verbeter. Vir hierdie, ons ondersoek verskillende bronne van eksterne kennis en evalueer die effektiviteit van ons modele op in-domein data as ook op spesiale oordrag datastelle wat ontwerp word om fin-kornerede redekening kapasiteite te asseer. Ons vind dat verskillende bronne van kennis 'n ander effek het op redekende kapasiteite, byvoorbeeld, inplisite kennis wat in taal modele gestoor is, kan hinder redensie op getalle en negasies. Eindelik, ons doen die grootste en mees fyn-korne verduidelik NLI skakering studie tot nou. Dit openbaar dat selfs groot verskil in outomatiese prestasie punte geen reflekteer in menslike reetings van etiket, uitduidelikheid, gewoonlik of grammatiese regverdigheid.</abstract_af>
      <abstract_hy>Բնական լեզվի եզրակացությունը պահանջում է մոդելներ սովորելու և կիրառելու համար ընդհանուր գիտելիքներ: Այս մտածողական հնարավորությունները հատկապես կարևոր են ՀՆԱ-ի բացատրելի համակարգերի համար, որոնք ստեղծում են բնական լեզվի բացատրություն, բացի իրենց պիտակների կանխատեսումից: Պարզվել է, որ արտաքին գիտելիքների ինտեգրացիան բարելավում է ՆԼԻ համակարգերը, այստեղ մենք ուսումնասիրում ենք, արդյոք այն կարող է նաև բարելավել իրենց բացատրական ունակությունները: Այս դեպքում մենք ուսումնասիրում ենք արտաքին գիտելիքների տարբեր աղբյուրներ և գնահատում ենք մեր մոդելների արտադրողականությունը բնագավառի տվյալների, ինչպես նաև հատուկ տեղափոխման տվյալների համակարգերի վրա, որոնք նախագծված են նրբագեղ մտածողականության հ Մենք հայտնաբերում ենք, որ տարբեր գիտելիքների աղբյուրները տարբեր ազդեցություններ ունեն մտածողական ունակությունների վրա, օրինակ, լեզվի մոդելներում պահպանված ենթարկված գիտելիքները կարող են խոչընդոտել մտածողությունը թվերի և բացասական Վերջապես, մենք կատարում ենք մինչ այժմ ամենամեծ և ամենագեղեցիկ բացատրելի ՆԼԻ-ի ժողովրդավարման ուսումնասիրությունը: It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor grammar correctness.</abstract_hy>
      <abstract_bs>Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sisteme, ovdje istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela o podacima u domenu, kao i o specijalnim prijenosnim podacima koje su dizajnirane za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različite utjecaje na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razgovor na brojeve i negacije. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. Ono otkriva da čak i velike razlike u rezultatima automatskih učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti gramatske ispravnosti.</abstract_bs>
      <abstract_am>Natural language inference (NLI) requires models to learn and apply commonsense knowledge.  እነዚህ የሚያስተባብሉ ስልጣናት ይልቅ ለማይታወቅ የNLI ስርዓቶች ፍጥረታዊ ቋንቋን ለመፍጠር የሚችሉ ናቸው፡፡ የውጭ እውቀት ማጠናቀል NLI ስርዓቶች ማሻሻል ታይቷል፡፡ በዚህ ደግሞ መፍረጃቸውን ማሻሻል ይችላልን፡፡ ለዚህ ምክንያት የውጭ እውቀት መልዕክቶችን እናሳውቃለን እና የዶሜን ዳታዎችን እና የተመሳሳይ አእምሮዎችን ማረጋገጥ በተለየ የተለየ የዳታ መስኮት ላይ እናስተውላለን፡፡ የልዩ የእውቀት ምንጮች ለልዩ አካባቢዎች በቋንቋ ምሳሌዎች የተደብቀው እውቀት የቁጥር እና ውቀትን የሚከለክል ነው ብለን እናገኛለን፡፡ በመጨረሻም፣ ከሁሉ የበለጠ እና የበለጠ የNLI የድብፅ ጉዳይ ትምህርት እናደርጋለን፡፡ በራሱ አካባቢ ትልቅ ልውጤቶች ቢሆን በአካባቢው ስርዓት፣ ትርጓሜ፣ ትርጓሜ እና ትክክለኛ ትክክል በሚገልጽ አይመለከትም፡፡</abstract_am>
      <abstract_az>Təbiətli dil infeksiyonu (NLI) öyrənmək və müxtəlif bilikləri istifadə etmək üçün modellər lazımdır. Bu müzakirə qabiliyyətlər özlərinin etiketlərinin öngörünüşünü artıran təbiətli dil a çıqlaması yaradan NLI sistemlərinə münasibdir. Dərzində bilgi integrasiyası NLI sistemlərini yaxşılaşdırmaq üçün göstərildi. Burada onların açıqlama kapasitələrini də yaxşılaşdırmaq mümkündür. Buna görə, biz dış bilgisinin müxtəlif mənbələrini incidirik və modellərimizin əməllərini domain verilənlərin və müxtəlif təkrar verilənlərin qurğularını müəyyən etmək üçün tasarlanmışdır. Biz bilirik ki, müxtəlif bilimin mənbələrinin razılıq qabiliyyətlərinə, məsələn dil modellerində qoyulan imkanlı bilgi sayılar və negasyonlar barəsində müzakirə edə bilər. Sonunda biz NLI crowdsourcing təhsil edilən ən ən böyük və ən gözəl taxıl təhsil etdik. Bu göstərir ki, otomatik performans nöqtələrində hətta böyük fərqli etiketlərin, açıq-aydınlıqların, yayınlıqların və gramatik düzgünlüklərində olmaz.</abstract_az>
      <abstract_bn>স্বাভাবিক ভাষার আক্রান্ত (NLI) কমন্সেন্সের জ্ঞান শিক্ষা ও প্রয়োগ করার জন্য মডেল প্রয়োজন। এনলিআই সিস্টেমের জন্য এই কারণের ক্ষমতা বিশেষ গুরুত্বপূর্ণ যা তাদের লেবেলের ভবিষ্যতের ছাড়াও প্রাকৃতিক ভাষার ব্য এনলিআই সিস্টেম উন্নত করার জন্য বাইরের জ্ঞানের একত্রিত করা হয়েছে, এখানে আমরা তদন্ত করছি এটা তাদের ব্যাখ্যা ক্ষমতা উন্নত কিনা। এর জন্য আমরা বাইরের জ্ঞানের বিভিন্ন সূত্র তদন্ত করি এবং ডোমেইনের তথ্যে আমাদের মডেলের প্রভাবের বিষয়টি মূল্য করি এবং সাথে বিশেষ পরিবহনের তথ্যের বিষয়ে যা ভ আমরা খুঁজে পাচ্ছি যে বিভিন্ন জ্ঞানের উৎস বিভিন্ন ক্ষমতার প্রভাব রয়েছে, যেমন, ভাষার মডেলে সংরক্ষিত জ্ঞানের বিষয়টি সংরক্ষিত করা  অবশেষে, আমরা এখন পর্যন্ত সবচেয়ে বৃহত্তম এবং সবচেয়ে ভালোভাবে কাজ করি এনলি জনসোর্সিং গবেষণা। এটি প্রকাশ করে যে স্বয়ংক্রিয়ভাবে প্রদর্শনের স্কোরে বিশাল পার্থক্য তারা লেবেল, ব্যাখ্যা, কমান্সেন্স এবং গ্রামের সঠিক ম</abstract_bn>
      <abstract_ca>La inferència de llenguatges naturals (NLI) requereix models per aprendre i aplicar coneixements comuns. Aquestes habilitats de raonament són particularment importants per a sistemes explicables de l'INN que generen una explicació natural de llenguatge a més de la seva predicció d'etiqueta. La integració del coneixement extern ha demostrat millorar els sistemes de l'INN, aquí investigam si també pot millorar les seves capacitats d'explicació. Per això, investigam diferents fonts de coneixement extern i evaluem el rendiment dels nostres models en dades internes i en conjunts de dades especials de transfer ència dissenyats per avaluar capacitats de raonament fins. Trobem que diferents fonts de coneixement tenen un efecte diferent en les habilitats de raonament, per exemple, el coneixement implícit emmagatzemat en models lingüístics pot impedir el raonament en números i negatius. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date.  revela que fins i tot les grans diferències en les puntuacions automàtiques de rendiment no reflecteixen ni en les puntuacions humanes d'etiqueta, explicació, comú ni correcció gramàtica.</abstract_ca>
      <abstract_et>Looduskeele järeldus (NLI) nõuab mudeleid, et õppida ja rakendada üldse mõistlikke teadmisi. Need arutlusvõimed on eriti olulised seletatavate NLI süsteemide puhul, mis loovad lisaks oma märgise prognoosile looduskeelse selgituse. Välisteadmiste integreerimine on näidanud NLI süsteemide parandamist, siin uurime, kas see võib parandada ka nende selgitusvõimet. Selleks uurime erinevaid välisteadmiste allikaid ja hindame oma mudelite jõudlust nii domeenisiseste andmete kui ka spetsiaalsete edastamisandmekogumite puhul, mis on mõeldud hindama peenete arutlusvõimeid. Leiame, et erinevatel teadmisteallikatel on erinev mõju mõtlemisvõimele, näiteks keelemudelites salvestatud kaudsed teadmised võivad takistada arvude ja negatsioonide arutlemist. Lõpuks viime läbi seni suurima ja kõige peenema selgitatava NLI ühishankimise uuringu. See näitab, et isegi suured erinevused automaatsete tulemuste skoorides ei kajasta inimeste hinnanguid sildi, selgituse, mõistuse ega grammatika õigsuse kohta.</abstract_et>
      <abstract_cs>Inference přirozeného jazyka (NLI) vyžaduje modely k učení se a aplikaci znalostí zdravého rozumu. Tyto schopnosti uvažování jsou obzvláště důležité pro vysvětlitelné NLI systémy, které vedle predikce etiket generují vysvětlení přirozeného jazyka. Bylo prokázáno, že integrace externích znalostí zlepšuje NLI systémy, zde zkoumáme, zda může také zlepšit jejich vysvětlovací schopnosti. Za tímto účelem zkoumáme různé zdroje externích znalostí a vyhodnocujeme výkonnost našich modelů na doménových datech i na speciálních datových sadách přenosu, které jsou navrženy k posouzení jemně zraněných možností uvažování. Zjišťujeme, že různé zdroje znalostí mají různý vliv na schopnosti uvažování, například implicitní znalosti uložené v jazykových modelech mohou bránit uvažování o číslech a negacích. Nakonec provádíme největší a nejjemnější vysvětlitelnou NLI crowdsourcingovou studii dosud. Odhaluje, že ani velké rozdíly v automatickém skórování výkonu se neodrážejí v lidském hodnocení označení, vysvětlení, zdravého rozumu ani gramatické správnosti.</abstract_cs>
      <abstract_fi>Luonnonkielen päättely (NLI) edellyttää malleja, joilla voidaan oppia ja soveltaa järjetöntä tietoa. Nämä päättelytaidot ovat erityisen tärkeitä selitettävissä oleville NLI-järjestelmille, jotka tuottavat etikettiennusteen lisäksi luonnollisen kielen selityksen. Ulkoisen tiedon integroinnin on osoitettu parantavan NLI-järjestelmiä, tässä selvitämme, voiko se myös parantaa niiden selityskykyä. Tätä varten tutkimme erilaisia ulkoisen tiedon lähteitä ja arvioimme malliemme suorituskykyä sekä sisäisissä tiedoissa että erityisissä siirtotietoaineistoissa, jotka on suunniteltu arvioimaan hienojakoisia päättelykykyjä. Havaitsemme, että eri tietolähteillä on erilainen vaikutus päättelykykyyn, esimerkiksi kielimalleihin tallennettu implisiittinen tieto voi haitata lukujen ja kiistojen päättelyä. Lopuksi toteutamme tähän mennessä suurimman ja hienorakeisen selitettävän NLI-joukkohankintatutkimuksen. Se paljastaa, että jopa suuret erot automaattisissa suorituspisteissä eivät heijastu ihmisten luokituksia etiketistä, selityksestä, järkevyydestä tai kieliopin oikeellisuudesta.</abstract_fi>
      <abstract_jv>Nari kesalahan kelas (NLI) butakon model kanggo sampek karo aplikasi kesalahan ingkang dipun. Awarti punika dipunanggé kuwi nggawe barang akeh luwih apik kanggo ngerasakno NLI iki dadi kapan tanggal sing dirambut kanggo ngerasakno tambah kanggo ngerasakno ning etiket. Entekan wong liyane ing rak segala sing nyerampun kanggo nggawe sistem NLI, kene awak dhéwé ujian sisaan kaya ngono iso nggawe akeh perusahaan kapasituran kanggo mbanjurakno. Saiki iki, we istrage diwurune buktuan samihan kelas barang nggawe barang nggawe model karo data-domain lan karo perusahaan dataset sing dibenaanye nggawe kanggo assess Awak dhéwé éntuk sistem sing dipun ajeng-sistem dadi kapan kuwi tindang yen manut karo nggawe barang, bisa ngono kuwi tindang kuwi tindang kejahatan Nyong-ngopo, kita praksi sing paling awak dhéwé anu nggawe gerakan oleh dumadhi NLI sing susahe nggawe ujak. Punika-punika sing ngerasakno akeh luwih akeh gak bener</abstract_jv>
      <abstract_he>תוצאת שפת טבעית (NLI) דורשת דוגמנים ללמוד ולהשתמש בידע משותף. היכולות ההיגיון הללו חשובות במיוחד למערכות NLI מסבירות שמוצרות הסבר טבעי לשפה בנוסף לחזות התווית שלהם. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities.  For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities.  אנו מוצאים שלמקורות שונים של ידע יש השפעה שונה על יכולות ההיגיון, לדוגמא, ידע מרושע שמחסן בדוגמנים לשפה יכול לעצור ההיגיון על מספרים ושלילות. סוף סוף, אנו מבצעים את המחקר הגדול ביותר והמוסבר ביותר במקורי קהל NLI עד היום. הוא מגלה שאפילו הבדלים גדולים בתוצאות ביצועים אוטומטיים לא משקפים בכישורים אנושיים של תווית, הסבר, משמעותי או תקנות גרמטיקה.</abstract_he>
      <abstract_sk>Sklepanje naravnega jezika (NLI) zahteva modele za učenje in uporabo splošnega smisla znanja. Te sposobnosti razmišljanja so še posebej pomembne za pojasnljive sisteme NLI, ki poleg napovedi oznake ustvarjajo razlago naravnega jezika. Pokazalo se je, da integracija zunanjega znanja izboljšuje sisteme NLI, tukaj pa raziskujemo, ali lahko izboljša tudi njihove razlage. V ta namen raziskujemo različne vire zunanjega znanja in ocenjujemo učinkovitost naših modelov na domenskih podatkih in na posebnih naborih prenosov podatkov, ki so zasnovani za ocenjevanje drobnozrnatih sposobnosti razmišljanja. Ugotavljamo, da različni viri znanja različno vplivajo na sposobnosti razmišljanja, npr. implicitno znanje, shranjeno v jezikovnih modelih, lahko ovira razmišljanje o številih in zanikah. Na koncu izvajamo največjo in najbolj natančno razložljivo študijo množičnega nabora NLI doslej. Razkriva, da tudi velike razlike v avtomatskih ocenah uspešnosti ne odražajo niti v ocenah oznake, razlage, splošnega smisla niti slovnične pravilnosti.</abstract_sk>
      <abstract_ha>@ info: whatsthis Ga wannan abinci masu inganci ne mafiya muhimu ga system-NLI waɗanda bã da an bayyana shi ba, ta ƙãga fassarar harshen kawaici da kuma ba da gabanin littafan su ba. An nuna integratewa da ilmi na baka don ya ƙara tsarin NLI, a nan, Munã tambaya ko za ta ƙara da abincin fassararsu. Daga wannan, Munã tambayi sourcen sanyin baka da kuma munã ƙaddara game da aikin misãlai masu cikin-danne da kuma kan data masu shige da aka ƙaddara don a ƙaddara abincin da aka naƙasa. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations.  Haƙĩƙa, Munã tafiyar da mafi girma da mafi kyaun karatun na NLI da ake bayyana wa maɓallin sourcer zuwa yanzu. Yana bayyana cewa, kõ dã sãɓa masu girma cikin score na-performance farat ɗaya ba su yi tunãni ba a cikin rabo-rayin mutum, fassarar, farin ciki, kuma kuma kuma daman shiryarwa.</abstract_ha>
      <abstract_bo>སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ཕལ་ཆེ་བ(NLI)ལ་མིག་གཟུགས་རིས་དཔེ་གཏོང་དང་མཉམ་དུ་མཐུན རྟོགས་བསམ་ནུས་པ་འདི་དག་གི་ཁྱད་པར་གལ་ཆེན་ཡིན་པའི་NLI་རིགས ཕྱི་ལ་གྱི་ཤེས་ཡོད་ཚད་ཀྱི་ཆ་ཁ་ཤས་གཅིག་སྟོན་ཡོད་པས་NLI་རིམ་པ་ལ་ཡར་རྒྱས་གཏོང་ན། དེ་ནས་ང་ཚོའི་ནང་དུ་འོས་ཡོད For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. ང་ཚོར་ཤེས་པའི་ཐོག་ཁུངས་མི་འདྲ་བ་ལ་རྟོགས་བསམ་བློ་གཏོང་ནུས་པའི་དབང་རྩལ་དང་། དཔེར་ན། སྐད་ཡིག མཐའ་མར་དུ་འུ་ཅག་གིས་གནད་དོན་ཕལ་ཆེ་ཤོས་དང་ཆེ་བའི་ལྕགས་རིས་མང་ཤོས་ཀྱི་ཉེན་བརྗོད་བྱེད་ཀྱི་ཡོད། It reveals that even large differences in automatic performance scores do not reflect in human ratings of label, explanation, commonsense nor grammar correctness.</abstract_bo>
      </paper>
    <paper id="5">
      <title>On the Limits of <a href="https://en.wikipedia.org/wiki/Minimal_pairs">Minimal Pairs</a> in Contrastive Evaluation</title>
      <author><first>Jannis</first><last>Vamvas</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <pages>58–68</pages>
      <abstract>Minimal sentence pairs are frequently used to analyze the behavior of <a href="https://en.wikipedia.org/wiki/Language_model">language models</a>. It is often assumed that model behavior on contrastive pairs is predictive of <a href="https://en.wikipedia.org/wiki/Behavioral_model">model behavior</a> at large. We argue that two conditions are necessary for this assumption to hold : First, a tested hypothesis should be well-motivated, since experiments show that contrastive evaluation can lead to false positives. Secondly, test data should be chosen such as to minimize distributional discrepancy between evaluation time and deployment time. For a good approximation of deployment-time decoding, we recommend that <a href="https://en.wikipedia.org/wiki/Minimal_pairs">minimal pairs</a> are created based on machine-generated text, as opposed to human-written references. We present a contrastive evaluation suite for EnglishGerman MT that implements this recommendation.</abstract>
      <url hash="5459accb">2021.blackboxnlp-1.5</url>
      <bibkey>vamvas-sennrich-2021-limits</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.5</doi>
      <pwccode url="https://github.com/zurichnlp/distil-lingeval" additional="false">zurichnlp/distil-lingeval</pwccode>
    </paper>
    <paper id="6">
      <title>What Models Know About Their Attackers : Deriving Attacker Information From Latent Representations</title>
      <author><first>Zhouhang</first><last>Xie</last></author>
      <author><first>Jonathan</first><last>Brophy</last></author>
      <author><first>Adam</first><last>Noack</last></author>
      <author><first>Wencong</first><last>You</last></author>
      <author><first>Kalyani</first><last>Asthana</last></author>
      <author><first>Carter</first><last>Perkins</last></author>
      <author><first>Sabrina</first><last>Reis</last></author>
      <author><first>Zayd</first><last>Hammoudeh</last></author>
      <author><first>Daniel</first><last>Lowd</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <pages>69–78</pages>
      <abstract>Adversarial attacks curated against NLP models are increasingly becoming practical threats. Although various methods have been developed to detect adversarial attacks, securing learning-based NLP systems in practice would require more than identifying and evading perturbed instances. To address these issues, we propose a new set of adversary identification tasks, Attacker Attribute Classification via Textual Analysis (AACTA), that attempts to obtain more detailed information about the attackers from adversarial texts. Specifically, given a piece of adversarial text, we hope to accomplish tasks such as localizing perturbed tokens, identifying the attacker’s access level to the target model, determining the evasion mechanism imposed, and specifying the perturbation type employed by the attacking algorithm. Our contributions are as follows : we formalize the task of classifying attacker attributes, and create a benchmark on various target models from sentiment classification and abuse detection domains. We show that signals from BERT models and target models can be used to train <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> that reveal the properties of the attacking algorithms. We demonstrate that adversarial attacks leave interpretable traces in both feature spaces of pre-trained language models and target models, making AACTA a promising direction towards more trustworthy NLP systems.</abstract>
      <url hash="ff4cd161">2021.blackboxnlp-1.6</url>
      <bibkey>xie-etal-2021-models</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.6</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="8">
      <title>ProSPer : Probing Human and Neural Network Language Model Understanding of Spatial Perspective<fixed-case>P</fixed-case>ro<fixed-case>SP</fixed-case>er: Probing Human and Neural Network Language Model Understanding of Spatial Perspective</title>
      <author><first>Tessa</first><last>Masis</last></author>
      <author><first>Carolyn</first><last>Anderson</last></author>
      <pages>95–135</pages>
      <abstract>Understanding perspectival language is important for applications like <a href="https://en.wikipedia.org/wiki/Dialogue_system">dialogue systems</a> and <a href="https://en.wikipedia.org/wiki/Human–robot_interaction">human-robot interaction</a>. We propose a probe task that explores how well <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> understand <a href="https://en.wikipedia.org/wiki/Perspective_(graphical)">spatial perspective</a>. We present a dataset for evaluating perspective inference in <a href="https://en.wikipedia.org/wiki/English_language">English</a>, ProSPer, and use it to explore how humans and Transformer-based language models infer perspective. Although the best bidirectional model performs similarly to humans, they display different strengths : <a href="https://en.wikipedia.org/wiki/Human">humans</a> outperform <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a> in conversational contexts, while RoBERTa excels at written genres.</abstract>
      <url hash="ff6104a9">2021.blackboxnlp-1.8</url>
      <bibkey>masis-anderson-2021-prosper</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.8</doi>
      <pwccode url="https://github.com/canders1/prosper" additional="false">canders1/prosper</pwccode>
    </paper>
    <paper id="10">
      <title>Transferring Knowledge from Vision to Language : How to Achieve it and how to Measure it?</title>
      <author><first>Tobias</first><last>Norlund</last></author>
      <author><first>Lovisa</first><last>Hagström</last></author>
      <author><first>Richard</first><last>Johansson</last></author>
      <pages>149–162</pages>
      <abstract>Large language models are known to suffer from the hallucination problem in that they are prone to output statements that are false or inconsistent, indicating a lack of knowledge. A proposed solution to this is to provide the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> with additional data modalities that complements the knowledge obtained through text. We investigate the use of visual data to complement the knowledge of large language models by proposing a method for evaluating visual knowledge transfer to text for uni- or multimodal language models. The <a href="https://en.wikipedia.org/wiki/Methodology">method</a> is based on two steps, 1) a novel <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> querying for <a href="https://en.wikipedia.org/wiki/Memory_color">knowledge of memory colors</a>, i.e. typical colors of well-known objects, and 2) filtering of model training data to clearly separate knowledge contributions. Additionally, we introduce a <a href="https://en.wikipedia.org/wiki/Modeling_language">model architecture</a> that involves a visual imagination step and evaluate it with our proposed <a href="https://en.wikipedia.org/wiki/Methodology">method</a>. We find that our method can successfully be used to measure visual knowledge transfer capabilities in models and that our novel model architecture shows promising results for leveraging multimodal knowledge in a unimodal setting.</abstract>
      <url hash="e57c76c7">2021.blackboxnlp-1.10</url>
      <bibkey>norlund-etal-2021-transferring</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.10</doi>
    </paper>
    <paper id="13">
      <title>A howling success or a working sea? Testing what BERT knows about metaphors<fixed-case>BERT</fixed-case> knows about metaphors</title>
      <author><first>Paolo</first><last>Pedinotti</last></author>
      <author><first>Eliana</first><last>Di Palma</last></author>
      <author><first>Ludovica</first><last>Cerini</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>192–204</pages>
      <abstract>Metaphor is a widespread linguistic and cognitive phenomenon that is ruled by mechanisms which have received attention in the literature. Transformer Language Models such as BERT have brought improvements in metaphor-related tasks. However, they have been used only in application contexts, while their knowledge of the phenomenon has not been analyzed. To test what BERT knows about <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a>, we challenge it on a new dataset that we designed to test various aspects of this phenomenon such as variations in linguistic structure, variations in <a href="https://en.wikipedia.org/wiki/Convention_(norm)">conventionality</a>, the boundaries of the plausibility of a metaphor and the interpretations that we attribute to metaphoric expressions. Results bring out some tendencies that suggest that the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can reproduce some human intuitions about <a href="https://en.wikipedia.org/wiki/Metaphor">metaphors</a>.</abstract>
      <url hash="f9f860ff">2021.blackboxnlp-1.13</url>
      <bibkey>pedinotti-etal-2021-howling</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.13</doi>
    </paper>
    <paper id="14">
      <title>How Length Prediction Influence the Performance of Non-Autoregressive Translation?</title>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Guo</first><last>Jiaxin</last></author>
      <author><first>Yuxia</first><last>Wang</last></author>
      <author><first>Yimeng</first><last>Chen</last></author>
      <author><first>Su</first><last>Chang</last></author>
      <author><first>Hengchao</first><last>Shang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Shimin</first><last>Tao</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <pages>205–213</pages>
      <abstract>Length prediction is a special task in a series of NAT models where target length has to be determined before generation. However, the performance of length prediction and its influence on translation quality has seldom been discussed. In this paper, we present comprehensive analyses on length prediction task of NAT, aiming to find the factors that influence performance, as well as how it associates with translation quality. We mainly perform experiments based on Conditional Masked Language Model (CMLM) (Ghazvininejad et al., 2019), a representative NAT model, and evaluate it on two language pairs, En-De and En-Ro. We draw two conclusions : 1) The performance of length prediction is mainly influenced by properties of language pairs such as alignment pattern, <a href="https://en.wikipedia.org/wiki/Word_order">word order</a> or intrinsic length ratio, and is also affected by the usage of knowledge distilled data. 2) There is a positive correlation between the performance of the length prediction and the BLEU score.</abstract>
      <url hash="28706094">2021.blackboxnlp-1.14</url>
      <bibkey>wang-etal-2021-length</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.14</doi>
    </paper>
    <paper id="15">
      <title>On the Language-specificity of Multilingual BERT and the Impact of <a href="https://en.wikipedia.org/wiki/Fine-tuning">Fine-tuning</a><fixed-case>BERT</fixed-case> and the Impact of Fine-tuning</title>
      <author><first>Marc</first><last>Tanti</last></author>
      <author><first>Lonneke</first><last>van der Plas</last></author>
      <author><first>Claudia</first><last>Borg</last></author>
      <author><first>Albert</first><last>Gatt</last></author>
      <pages>214–227</pages>
      <abstract>Recent work has shown evidence that the <a href="https://en.wikipedia.org/wiki/Knowledge">knowledge</a> acquired by multilingual BERT (mBERT) has two components : a language-specific and a language-neutral one. This paper analyses the relationship between them, in the context of fine-tuning on two tasks   POS tagging and natural language inference   which require the model to bring to bear different degrees of language-specific knowledge. Visualisations reveal that mBERT loses the ability to cluster representations by language after <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>, a result that is supported by evidence from <a href="https://en.wikipedia.org/wiki/Language_identification">language identification</a> experiments. However, further experiments on ‘unlearning’ language-specific representations using gradient reversal and iterative adversarial learning are shown not to add further improvement to the language-independent component over and above the effect of <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>. The results presented here suggest that the process of <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a> causes a reorganisation of the <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a>’s limited representational capacity, enhancing language-independent representations at the expense of language-specific ones.</abstract>
      <url hash="aaf3284f">2021.blackboxnlp-1.15</url>
      <bibkey>tanti-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.15</doi>
      <pwccode url="https://github.com/mtanti/mbert-language-specificity" additional="false">mtanti/mbert-language-specificity</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/xnli">XNLI</pwcdataset>
    </paper>
    <paper id="18">
      <title>Variation and generality in encoding of syntactic anomaly information in sentence embeddings</title>
      <author><first>Qinxuan</first><last>Wu</last></author>
      <author><first>Allyson</first><last>Ettinger</last></author>
      <pages>250–264</pages>
      <abstract>While sentence anomalies have been applied periodically for testing in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, we have yet to establish a picture of the precise status of anomaly information in representations from <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP models</a>. In this paper we aim to fill two primary gaps, focusing on the domain of syntactic anomalies. First, we explore fine-grained differences in anomaly encoding by designing probing tasks that vary the hierarchical level at which anomalies occur in a sentence. Second, we test not only models’ ability to detect a given <a href="https://en.wikipedia.org/wiki/Anomaly_(physics)">anomaly</a>, but also the generality of the detected anomaly signal, by examining transfer between distinct anomaly types. Results suggest that all <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> encode some information supporting <a href="https://en.wikipedia.org/wiki/Anomaly_detection">anomaly detection</a>, but detection performance varies between anomalies, and only representations from more re- cent transformer models show signs of generalized knowledge of anomalies. Follow-up analyses support the notion that these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> pick up on a legitimate, general notion of sentence oddity, while coarser-grained word position information is likely also a contributor to the observed <a href="https://en.wikipedia.org/wiki/Anomaly_detection">anomaly detection</a>.</abstract>
      <url hash="77a20cdc">2021.blackboxnlp-1.18</url>
      <bibkey>wu-ettinger-2021-variation</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.18</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/cola">CoLA</pwcdataset>
    </paper>
    <paper id="19">
      <title>Enhancing Interpretable Clauses Semantically using Pretrained Word Representation</title>
      <author><first>Rohan Kumar</first><last>Yadav</last></author>
      <author><first>Lei</first><last>Jiao</last></author>
      <author><first>Ole-Christoffer</first><last>Granmo</last></author>
      <author><first>Morten</first><last>Goodwin</last></author>
      <pages>265–274</pages>
      <abstract>Tsetlin Machine (TM) is an interpretable pattern recognition algorithm based on <a href="https://en.wikipedia.org/wiki/Propositional_calculus">propositional logic</a>, which has demonstrated competitive performance in many Natural Language Processing (NLP) tasks, including <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>, text classification, and <a href="https://en.wikipedia.org/wiki/Word-sense_disambiguation">Word Sense Disambiguation</a>. To obtain human-level interpretability, legacy TM employs Boolean input features such as bag-of-words (BOW). However, the BOW representation makes it difficult to use any pre-trained information, for instance, <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> and GloVe word representations. This restriction has constrained the performance of TM compared to deep neural networks (DNNs) in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>. To reduce the performance gap, in this paper, we propose a novel way of using pre-trained word representations for TM. The approach significantly enhances the performance and interpretability of TM. We achieve this by extracting semantically related words from pre-trained word representations as input features to the TM. Our experiments show that the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of the proposed approach is significantly higher than the previous BOW-based TM, reaching the level of DNN-based models.</abstract>
      <url hash="e5714f89">2021.blackboxnlp-1.19</url>
      <bibkey>yadav-etal-2021-enhancing</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.19</doi>
      <pwccode url="" additional="true" />
      <pwcdataset url="https://paperswithcode.com/dataset/mr">MR</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/reuters-21578">Reuters-21578</pwcdataset>
    </paper>
    <paper id="21">
      <title>An in-depth look at Euclidean disk embeddings for structure preserving parsing<fixed-case>E</fixed-case>uclidean disk embeddings for structure preserving parsing</title>
      <author><first>Federico</first><last>Fancellu</last></author>
      <author><first>Lan</first><last>Xiao</last></author>
      <author><first>Allan</first><last>Jepson</last></author>
      <author><first>Afsaneh</first><last>Fazly</last></author>
      <pages>283–295</pages>
      <abstract>Preserving the structural properties of trees or graphs when embedding them into a <a href="https://en.wikipedia.org/wiki/Metric_space">metric space</a> allows for a high degree of <a href="https://en.wikipedia.org/wiki/Interpretability">interpretability</a>, and has been shown beneficial for <a href="https://en.wikipedia.org/wiki/Downstream_(computer_science)">downstream tasks</a> (e.g., hypernym detection, natural language inference, multimodal retrieval). However, whereas the majority of prior work looks at using structure-preserving embeddings when encoding a <a href="https://en.wikipedia.org/wiki/Structure">structure</a> given as input, e.g., <a href="https://en.wikipedia.org/wiki/WordNet">WordNet</a> (Fellbaum, 1998), there is little exploration on how to use such <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a> when predicting one. We address this gap for two structure generation tasks, namely dependency and semantic parsing. We test the applicability of disk embeddings (Suzuki et al., 2019) that has been proposed for embedding Directed Acyclic Graphs (DAGs) but has not been tested on tasks that generate such structures. Our experimental results show that for both tasks the original disk embedding formulation leads to much worse performance when compared to non-structure-preserving baselines. We propose enhancements to this formulation and show that they almost close the performance gap for dependency parsing. However, the gap still remains notable for <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> due to the complexity of meaning representation graphs, suggesting a challenge for generating interpretable semantic parse representations.</abstract>
      <url hash="f6178fb4">2021.blackboxnlp-1.21</url>
      <bibkey>fancellu-etal-2021-depth</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.21</doi>
    </paper>
    <paper id="26">
      <title>Assessing the Generalization Capacity of Pre-trained Language Models through Japanese Adversarial Natural Language Inference<fixed-case>J</fixed-case>apanese Adversarial Natural Language Inference</title>
      <author><first>Hitomi</first><last>Yanaka</last></author>
      <author><first>Koji</first><last>Mineshima</last></author>
      <pages>337–349</pages>
      <abstract>Despite the success of multilingual pre-trained language models, it remains unclear to what extent these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> have human-like generalization capacity across languages. The aim of this study is to investigate the out-of-distribution generalization of pre-trained language models through Natural Language Inference (NLI) in <a href="https://en.wikipedia.org/wiki/Japanese_language">Japanese</a>, the typological properties of which are different from those of <a href="https://en.wikipedia.org/wiki/English_language">English</a>. We introduce a synthetically generated Japanese NLI dataset, called the Japanese Adversarial NLI (JaNLI) dataset, which is inspired by the English HANS dataset and is designed to require understanding of Japanese linguistic phenomena and illuminate the vulnerabilities of models. Through a series of experiments to evaluate the <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> performance of both Japanese and multilingual BERT models, we demonstrate that there is much room to improve current <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> trained on Japanese NLI tasks. Furthermore, a comparison of human performance and model performance on the different types of garden-path sentences in the JaNLI dataset shows that structural phenomena that ease interpretation of garden-path sentences for human readers do not help <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> in the same way, highlighting a difference between human readers and the <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>.</abstract>
      <url hash="9cb8672a">2021.blackboxnlp-1.26</url>
      <bibkey>yanaka-mineshima-2021-assessing</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.26</doi>
      <pwccode url="https://github.com/verypluming/janli" additional="false">verypluming/janli</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/janli">JaNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="27">
      <title>Investigating Negation in Pre-trained Vision-and-language Models</title>
      <author><first>Radina</first><last>Dobreva</last></author>
      <author><first>Frank</first><last>Keller</last></author>
      <pages>350–362</pages>
      <abstract>Pre-trained vision-and-language models have achieved impressive results on a variety of tasks, including ones that require complex reasoning beyond <a href="https://en.wikipedia.org/wiki/Outline_of_object_recognition">object recognition</a>. However, little is known about how they achieve these results or what their limitations are. In this paper, we focus on a particular linguistic capability, namely the understanding of negation. We borrow techniques from the analysis of language models to investigate the ability of pre-trained vision-and-language models to handle <a href="https://en.wikipedia.org/wiki/Negation">negation</a>. We find that these <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> severely underperform in the presence of <a href="https://en.wikipedia.org/wiki/Negation">negation</a>.</abstract>
      <url hash="6f38e673">2021.blackboxnlp-1.27</url>
      <bibkey>dobreva-keller-2021-investigating</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.27</doi>
      <pwccode url="https://github.com/radidd/vision-and-language-negation" additional="false">radidd/vision-and-language-negation</pwccode>
    </paper>
    <paper id="30">
      <title>Learning Mathematical Properties of Integers</title>
      <author><first>Maria</first><last>Ryskina</last></author>
      <author><first>Kevin</first><last>Knight</last></author>
      <pages>389–395</pages>
      <abstract>Embedding words in <a href="https://en.wikipedia.org/wiki/High-dimensional_space">high-dimensional vector spaces</a> has proven valuable in many <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language applications</a>. In this work, we investigate whether similarly-trained embeddings of integers can capture concepts that are useful for <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">mathematical applications</a>. We probe the integer embeddings for mathematical knowledge, apply them to a set of numerical reasoning tasks, and show that by learning the representations from mathematical sequence data, we can substantially improve over number embeddings learned from English text corpora.</abstract>
      <url hash="4d129f93">2021.blackboxnlp-1.30</url>
      <bibkey>ryskina-knight-2021-learning</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.30</doi>
      <pwccode url="https://github.com/ryskina/integer-embedding-tests" additional="true">ryskina/integer-embedding-tests</pwccode>
    </paper>
    <paper id="34">
      <title>An Investigation of Language Model Interpretability via Sentence Editing</title>
      <author><first>Samuel</first><last>Stevens</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <pages>435–446</pages>
      <abstract>Pre-trained language models (PLMs) like BERT are being used for almost all language-related tasks, but interpreting their behavior still remains a significant challenge and many important questions remain largely unanswered. In this work, we re-purpose a sentence editing dataset, where faithful high-quality human rationales can be automatically extracted and compared with extracted model rationales, as a new testbed for interpretability. This enables us to conduct a systematic investigation on an array of questions regarding PLMs’ interpretability, including the role of pre-training procedure, comparison of rationale extraction methods, and different layers in the PLM. The investigation generates new insights, for example, contrary to the common understanding, we find that attention weights correlate well with <a href="https://en.wikipedia.org/wiki/Rationality">human rationales</a> and work better than gradient-based saliency in extracting model rationales. Both the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> and code will be released to facilitate future interpretability research.</abstract>
      <url hash="731f7921">2021.blackboxnlp-1.34</url>
      <bibkey>stevens-su-2021-investigation</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.34</doi>
      <pwccode url="https://github.com/samuelstevens/bert-edits" additional="true">samuelstevens/bert-edits</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/100doh">100DOH</pwcdataset>
    </paper>
    <paper id="37">
      <title>Controlled tasks for model analysis : Retrieving discrete information from sequences</title>
      <author><first>Ionut-Teodor</first><last>Sorodoc</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <author><first>Marco</first><last>Baroni</last></author>
      <pages>468–478</pages>
      <abstract>In recent years, the NLP community has shown increasing interest in analysing how <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> work. Given that large models trained on complex <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> are difficult to inspect, some of this work has focused on controlled tasks that emulate specific aspects of <a href="https://en.wikipedia.org/wiki/Language">language</a>. We propose a new set of such controlled tasks to explore a crucial aspect of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">natural language processing</a> that has not received enough attention : the need to retrieve discrete information from sequences. We also study model behavior on the tasks with simple instantiations of <a href="https://en.wikipedia.org/wiki/Transformers_(toy_line)">Transformers</a> and <a href="https://en.wikipedia.org/wiki/Light-emitting_diode">LSTMs</a>. Our results highlight the beneficial role of decoder attention and its sometimes unexpected interaction with other components. Moreover, we show that, for most of the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a>, these simple models still show significant difficulties. We hope that the community will take up the analysis possibilities that our tasks afford, and that a clearer understanding of model behavior on the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">tasks</a> will lead to better and more transparent models.</abstract>
      <url hash="ae95a9a1">2021.blackboxnlp-1.37</url>
      <bibkey>sorodoc-etal-2021-controlled</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.37</doi>
      <pwccode url="https://github.com/sorodoc/discreteseq" additional="false">sorodoc/discreteseq</pwccode>
    </paper>
    <paper id="40">
      <title>Do <a href="https://en.wikipedia.org/wiki/Language_model">Language Models</a> Know the Way to Rome?<fixed-case>R</fixed-case>ome?</title>
      <author><first>Bastien</first><last>Liétard</last></author>
      <author><first>Mostafa</first><last>Abdou</last></author>
      <author><first>Anders</first><last>Søgaard</last></author>
      <pages>510–517</pages>
      <abstract>The <a href="https://en.wikipedia.org/wiki/Global_geometry">global geometry</a> of <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> is important for a range of applications, but language model probes tend to evaluate rather local relations, for which ground truths are easily obtained. In this paper we exploit the fact that in <a href="https://en.wikipedia.org/wiki/Geography">geography</a>, ground truths are available beyond local relations. In a series of experiments, we evaluate the extent to which <a href="https://en.wikipedia.org/wiki/Language_model">language model representations</a> of city and country names are isomorphic to real-world geography, e.g., if you tell a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> where <a href="https://en.wikipedia.org/wiki/Paris">Paris</a> and <a href="https://en.wikipedia.org/wiki/Berlin">Berlin</a> are, does it know the way to Rome? We find that language models generally encode limited geographic information, but with larger <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> performing the best, suggesting that geographic knowledge can be induced from higher-order co-occurrence statistics.<i>can</i> be induced from higher-order co-occurrence statistics.</abstract>
      <url hash="abdabe9b">2021.blackboxnlp-1.40</url>
      <bibkey>lietard-etal-2021-language</bibkey>
      <doi>10.18653/v1/2021.blackboxnlp-1.40</doi>
    </paper>
    </volume>
</collection>