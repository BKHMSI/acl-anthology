<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.gebnlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Gender Bias in Natural Language Processing</booktitle>
      <editor><first>Marta</first><last>Costa-jussa</last></editor>
      <editor><first>Hila</first><last>Gonen</last></editor>
      <editor><first>Christian</first><last>Hardmeier</last></editor>
      <editor><first>Kellie</first><last>Webster</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="38ae9296">2021.gebnlp-1</url>
    </meta>
    <frontmatter>
      <url hash="9df1219b">2021.gebnlp-1.0</url>
      <bibkey>gebnlp-2021-gender</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Gender Bias Hidden Behind Chinese Word Embeddings : The Case of Chinese Adjectives<fixed-case>C</fixed-case>hinese Word Embeddings: The Case of <fixed-case>C</fixed-case>hinese Adjectives</title>
      <author><first>Meichun</first><last>Jiao</last></author>
      <author><first>Ziyang</first><last>Luo</last></author>
      <pages>8–15</pages>
      <abstract>Gender bias in word embeddings gradually becomes a vivid research field in recent years. Most studies in this field aim at measurement and debiasing methods with <a href="https://en.wikipedia.org/wiki/English_language">English</a> as the target language. This paper investigates <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> in static word embeddings from a unique perspective, <a href="https://en.wikipedia.org/wiki/Chinese_adjectives">Chinese adjectives</a>. By training word representations with different <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a>, the <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> behind the vectors of adjectives is assessed. Through a comparison between the produced results and a human scored data set, we demonstrate how gender bias encoded in word embeddings differentiates from people’s attitudes.</abstract>
      <url hash="509ba7f6">2021.gebnlp-1.2</url>
      <doi>10.18653/v1/2021.gebnlp-1.2</doi>
      <bibkey>jiao-luo-2021-gender</bibkey>
    <title_ar>التحيز الجنساني المخفي وراء زخارف الكلمات الصينية: حالة الصفات الصينية</title_ar>
      <title_es>El sesgo de género oculto detrás de la inserción de palabras chinas: el caso de los adjetivos chinos</title_es>
      <title_fr>Les préjugés sexistes cachés derrière les intégrations de mots chinois : le cas des adjectifs chinois</title_fr>
      <title_pt>Preconceito de gênero escondido por trás das incorporações de palavras chinesas: o caso dos adjetivos chineses</title_pt>
      <title_zh>隐于汉语词嵌背性别偏见:汉语形容词例</title_zh>
      <title_ja>中国語の単語埋め込みの背後に隠されたジェンダーバイアス：中国語の形容詞のケース</title_ja>
      <title_ru>Гендерные предрассудки, скрытые за вложениями китайского слова: пример китайских прилагательных</title_ru>
      <title_hi>लिंग पूर्वाग्रह चीनी शब्द एम्बेडिंग के पीछे छिपा हुआ है: चीनी विशेषणों का मामला</title_hi>
      <title_ga>Claonadh Inscne Ar Folaithe Taobh thiar de Leabú Focal Síneach: Cás na nAidiachtaí Síneacha</title_ga>
      <title_ukr>Гендерна упередженість, прихована за вбудованими китайськими словами: випадок китайських прикметників</title_ukr>
      <title_el>Η προκατάληψη των φύλων κρυμμένη πίσω από τις κινεζικές λέξεις ενσωμάτωσης: Η περίπτωση των κινεζικών επίθετων</title_el>
      <title_isl>Kynþættir felnar fyrir aftan kínverskt orð: Fall kínverskra viðtaka</title_isl>
      <title_ka>ჩინეთის სიტყვების შემდეგ ჩინეთი სიტყვების გარეშე: The Case of Chinese Adjectives</title_ka>
      <title_hu>A kínai szóbeágyazások mögött rejtőzött gender bias: A kínai mellékletek esete</title_hu>
      <title_it>Bias di genere nascosto dietro l'embedding di parole cinesi: il caso degli aggettivi cinesi</title_it>
      <title_ms>Bias Gender Tersembunyi Di Belakang Penampilan Kata Cina: Kasus Adjektif Cina</title_ms>
      <title_kk>Қытай сөз ендірулерінің артында жасырылған гендер биасы: The Case of Chinese Adjectives</title_kk>
      <title_lt>Lyčių skirtumas paslėptas už Kinijos žodžių įterpimo: Kinijos subjektų atvejis</title_lt>
      <title_mk>Генерална промена скриена позади вклопувањето на кинеските зборови: случајот на кинеските адективи</title_mk>
      <title_mn>Хятад үгийн хамтдаа нуугдсан гендер Биас: The Case of Chinese Adjectives</title_mn>
      <title_ml>ചൈനീസ് വാക്കുകളുടെ പിന്നില്‍ മറഞ്ഞിരിക്കുന്ന പെണ്ണ് ബിയാസ്: ചൈനീസ് സജ്ജമാക്കളുടെ കേസ്.</title_ml>
      <title_pl>Uprzedzenia o płci ukryte za chińskimi słowami: przypadek chińskich adjektiwów</title_pl>
      <title_mt>Diversità bejn is-sessi moħbija wara l-inkorporazzjoni tal-kliem Ċiniż: Il-Każ tal-Addettivi Ċiniżi</title_mt>
      <title_si>ජෙන්ඩර් බියාස් චීනි වචන ඇම්බෙඩින්ස් පස්සේ හැංගිලා තියෙන්නේ: The case of China Adpectives</title_si>
      <title_so>Xaaladaha Shiino</title_so>
      <title_no>The Case of Chinese Adjectives</title_no>
      <title_sv>Könsbias dold bakom kinesiska ord inbäddade: fallet med kinesiska adjektiv</title_sv>
      <title_sr>Gender Bias sakriven iza kineskih reči: Case of Chinese Adjectives</title_sr>
      <title_ta>Name</title_ta>
      <title_ur>جنس بیس چینی کلمات کے پیچھے چھپائی جاتی ہے: The Case of Chinese Adjectives</title_ur>
      <title_ro>Bias gen ascuns în spatele încorporărilor cuvintelor chinezești: cazul adjectivelor chinezești</title_ro>
      <title_uz>Name</title_uz>
      <title_vi>Giới tính đằng sau những lời khai của Trung Quốc:</title_vi>
      <title_bg>Джендър предразсъдъци, скрити зад китайските слова: случаят с китайските приспособления</title_bg>
      <title_da>Kønsfordi skjult bag kinesiske ordindlejringer: Tilfældet med kinesiske adjektiver</title_da>
      <title_nl>Gendervooroordelen verborgen achter Chinese woord embeddings: het geval van Chinese bijvoeglijke naamwoorden</title_nl>
      <title_hr>Gender Bias sakriven iza kineske riječi: Case of Chinese Adjectives</title_hr>
      <title_de>Gender Bias versteckt hinter chinesischen Wort Einbettungen: Der Fall chinesischer Adjektive</title_de>
      <title_id>Gender Bias Tersembunyi Di Belakang Penampilan Kata Cina: Kasus Adjektif Cina</title_id>
      <title_fa>جنس بیس پشت کلمه چینی پنهان شده: The Case of Chinese Adjectives</title_fa>
      <title_ko>중국어 어휘 뒤에 숨겨진 성별 편견 - 중국어 형용사를 예로 들다</title_ko>
      <title_sw>Bias za jinsia zilizofichikana nyuma ya Hadithi ya China: Mashtaka ya Washindi</title_sw>
      <title_af>Gender Bias weggesteekte agter Sjinese Woord Inbetering: The Case of Chinese Adjectives</title_af>
      <title_tr>Çinçe sözleriniň arkasynda Ýenç Biýasy: The Case of Chinese Adjectives</title_tr>
      <title_sq>Ndryshimi gjinorë i fshehur pas përfshirjes së fjalëve kineze: rasti i objektivave kineze</title_sq>
      <title_am>የቻይና ቃላት አቀማመጥ</title_am>
      <title_hy>Սկնդային տարբերակները թաքնված չինական բառերի ներգրավման ետևում. Չինական ադիկտիվների դեպքը</title_hy>
      <title_az>쎇楮⁓쎶穬즙物湩渠慲擄녮摡渠杩穬즙湭槅鼠䝥湤敲⁂楡猺⁔桥⁃慳攠潦⁃桩湥獥⁁摪散瑩癥猊</title_az>
      <title_bn>চীনা শব্দের অভিবেদনের পেছনে লুকানো লিঙ্গ বিয়াস: চীনা অভিবাসীদের মামলা</title_bn>
      <title_bs>Gender Bias sakriven iza kineske riječi: Case of Chinese Adjectives</title_bs>
      <title_ca>El problema de gènere amagat darrere d'incorporacions de paraules xineses: el cas dels objectius xinesos</title_ca>
      <title_cs>Genderové předsudky skryté za čínskými slovy vloženími: Případ čínských adjektivů</title_cs>
      <title_et>Hiina sõnade põimimise taga peidetud soolised kallakud: Hiina adjektiivide juhtum</title_et>
      <title_fi>Sukupuolten taipumus piilotettuna kiinalaisten sanaupotusten taakse: Kiinan adjektiivien tapaus</title_fi>
      <title_ha>@ item Text character set</title_ha>
      <title_sk>Spolna pristranskost skrita za kitajskimi besedami: primer kitajskih pripomočkov</title_sk>
      <title_he>Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese Adjectives</title_he>
      <title_bo>རྒྱ་ནག་གི་ཐ་སྙད་ནང་ལ་སྦྱར་བའི་ལྟ་བུའི་ནང་དུ་ཡིན་མིན་པའི་ཚིག</title_bo>
      <title_jv>Gender Bias nang ambalanjur Kemerdekaan Winih: The Case of Chinese Adjectivers</title_jv>
      <title_fil>Gender Bias Hidden Behind Chinese Word Embeddings: The Case of Chinese Adjectives</title_fil>
      <abstract_ar>أصبح التحيز الجنساني في حفلات الزفاف تدريجيًا مجالًا بحثيًا حيويًا في السنوات الأخيرة. تهدف معظم الدراسات في هذا المجال إلى طرق القياس وإزالة الحيز مع اللغة الإنجليزية كلغة مستهدفة. تبحث هذه الورقة في التحيز الجنساني في حفلات الزفاف الثابتة من منظور فريد ، الصفات الصينية. من خلال تدريب تمثيل الكلمات بنماذج مختلفة ، يتم تقييم التحيز الجنساني وراء نواقل الصفات. من خلال مقارنة بين النتائج التي تم الحصول عليها ومجموعة البيانات التي سجلها الإنسان ، نوضح كيف يميز التحيز الجنساني المشفر في الزخارف بالكلمات عن مواقف الناس.</abstract_ar>
      <abstract_es>El sesgo de género en la inserción de palabras se convierte gradualmente en un campo de investigación vívido en los últimos años La mayoría de los estudios en este campo apuntan a métodos de medición y desviación con el inglés como idioma de destino. Este artículo investiga el sesgo de género en la incrustación de palabras estáticas desde una perspectiva única, los adjetivos chinos. Al entrenar las representaciones de palabras con diferentes modelos, se evalúa el sesgo de género detrás de los vectores de los adjetivos. A través de una comparación entre los resultados obtenidos y un conjunto de datos puntuados por humanos, demostramos cómo el sesgo de género codificado en la inserción de palabras se diferencia de las actitudes de las personas.</abstract_es>
      <abstract_fr>Les préjugés sexistes dans les intégrations de mots sont progressivement devenus un domaine de recherche très actif au cours des dernières années. La plupart des études dans ce domaine visent des méthodes de mesure et de débiaisement avec l'anglais comme langue cible. Cet article examine les préjugés sexistes dans les intégrations de mots statiques d'un point de vue unique, les adjectifs chinois. En formant des représentations de mots avec différents modèles, on évalue le biais sexiste qui sous-tend les vecteurs des adjectifs. Grâce à une comparaison entre les résultats produits et un ensemble de données humaines, nous démontrons comment les préjugés sexistes codés dans les intégrations de mots se différencient des attitudes des personnes.</abstract_fr>
      <abstract_pt>O viés de gênero na incorporação de palavras gradualmente se torna um campo de pesquisa vívido nos últimos anos. A maioria dos estudos neste campo visa métodos de medição e desvirtuamento com o inglês como língua-alvo. Este artigo investiga o viés de gênero em incorporações de palavras estáticas a partir de uma perspectiva única, os adjetivos chineses. Ao treinar representações de palavras com diferentes modelos, avalia-se o viés de gênero por trás dos vetores de adjetivos. Através de uma comparação entre os resultados produzidos e um conjunto de dados de pontuação humana, demonstramos como o preconceito de gênero codificado em incorporações de palavras se diferencia das atitudes das pessoas.</abstract_pt>
      <abstract_ja>埋め込みにおけるジェンダーバイアスは、近年徐々に鮮やかな研究分野となっている。この分野のほとんどの研究は、英語をターゲット言語とした測定とデビアシングの方法を目指しています。本論文では、中国語の形容詞という独自の視点から、静的な単語埋め込みにおけるジェンダーバイアスを調査する。異なるモデルで単語表現をトレーニングすることにより、形容詞のベクターの背後にある性別バイアスが評価される。生成された結果と人間のスコアデータセットとの比較を通じて、私たちは、単語埋め込みにエンコードされたジェンダーバイアスが人々の態度とどのように差別化するかを示します。</abstract_ja>
      <abstract_zh>近年以来,词中性别偏见渐成一个生动的研究领域。 其域多以英语为的言语,测消偏倚之法。 本文从特角(中国形容词)究静词嵌中性别偏见。 以形教单词,评估形容词向量背之偏见。 以生人评分数集,示嵌入词中编码性别分别。</abstract_zh>
      <abstract_hi>शब्द एम्बेडिंग में लिंग पूर्वाग्रह धीरे-धीरे हाल के वर्षों में एक ज्वलंत अनुसंधान क्षेत्र बन जाता है। इस क्षेत्र में अधिकांश अध्ययनों का उद्देश्य लक्ष्य भाषा के रूप में अंग्रेजी के साथ माप और debiasing विधियों को मापना और debiasing करना है। यह पेपर एक अद्वितीय परिप्रेक्ष्य, चीनी विशेषणों से स्थिर शब्द एम्बेडिंग में लिंग पूर्वाग्रह की जांच करता है। विभिन्न मॉडलों के साथ शब्द प्रतिनिधित्व को प्रशिक्षित करके, विशेषणों के वैक्टर के पीछे लिंग पूर्वाग्रह का आकलन किया जाता है। उत्पादित परिणामों और मानव स्कोर किए गए डेटा सेट के बीच तुलना के माध्यम से, हम प्रदर्शित करते हैं कि शब्द एम्बेडिंग में एन्कोडेड लिंग पूर्वाग्रह लोगों के दृष्टिकोण से कैसे अलग होता है।</abstract_hi>
      <abstract_ru>Гендерная предвзятость в словах постепенно становится яркой областью исследований в последние годы. Большинство исследований в этой области направлены на методы измерения и дебирования с использованием английского языка в качестве целевого языка. В этой статье изучается гендерная предвзятость в статических вложениях слов с уникальной точки зрения - китайских прилагательных. Путем обучения словопредставлений с различными моделями оценивается гендерная предвзятость векторов прилагательных. Путем сравнения полученных результатов с оцененным человеком набором данных мы демонстрируем, как гендерная предвзятость, закодированная в словарных вложениях, отличается от отношения людей.</abstract_ru>
      <abstract_ukr>Гендерна упередженість у вбудовуваннях слів поступово стає яскравою галуззю дослідження в останні роки. Більшість досліджень у цій галузі спрямовані на методи вимірювання та дебіасифікації з англійською мовою як цільовою мовою. Ця робота досліджує гендерне упередження в статичних вставках слів з унікальної точки зору, китайських прикметників. Навчаючи представлення слів з різними моделями, оцінюється гендерна упередженість за векторами прикметників. Завдяки порівнянню отриманих результатів та набору даних, оцінених людиною, ми демонструємо, як гендерне упередження, закодоване у вбудованих словах, відрізняється від ставлення людей.</abstract_ukr>
      <abstract_ga>De réir a chéile déantar réimse beoga taighde de chlaonadh inscne i neadú focal le blianta beaga anuas. Tá sé d’aidhm ag formhór na staidéar sa réimse seo modhanna tomhais agus díchlaonta a dhéanamh leis an mBéarla mar sprioctheanga. Déanann an páipéar seo imscrúdú ar chlaonadh inscne i neadú focal statach ó pheirspictíocht uathúil, aidiachtaí Síneacha. Trí léiriú focal a oiliúint le múnlaí éagsúla, déantar measúnú ar an gclaonadh inscne atá taobh thiar de veicteoirí na n-aidiachtaí. Trí chomparáid a dhéanamh idir na torthaí a tháirgtear agus tacar sonraí scóráilte daonna, léirímid conas a dhéanann an claonadh inscne atá ionchódaithe i bhfocal leabaithe idirdhealú idir dearcadh daoine.</abstract_ga>
      <abstract_isl>Kynnsleg tilhneiging í orðsamsetningu verður smám saman ljós rannsóknarsvæði á síðustu árum. Most studies in this field aim at measurement and debiasing methods with English as the target language.  Þessi pappír rannsakar kynhneigð í stöðugum orðum innsetningu frá einstökum sjónarmiði, kínverskum viðbótum. Með því að þjálfa orðmyndir með mismunandi líkönum er hægt að meta kynhneigð bak við vekjur viðbótar. Með samanburði á niðurstöðum úr rannsókninni og gögnum með skori úr mönnum s ýnum við hvernig kynskilyrði kóða ð í orðum breytist við aðstæður fólks.</abstract_isl>
      <abstract_it>Il pregiudizio di genere nelle incorporazioni di parole diventa gradualmente un campo di ricerca vivido negli ultimi anni. La maggior parte degli studi in questo campo mira a metodi di misurazione e debiasing con l'inglese come lingua di destinazione. Questo articolo indaga il pregiudizio di genere in incorporazioni statiche di parole da una prospettiva unica, aggettivi cinesi. Allenando rappresentazioni di parole con modelli diversi, viene valutato il pregiudizio di genere dietro i vettori degli aggettivi. Attraverso un confronto tra i risultati prodotti e un set di dati di punteggio umano, dimostriamo come il bias di genere codificato nelle incorporazioni di parole si differenzia dagli atteggiamenti delle persone.</abstract_it>
      <abstract_el>Η προκατάληψη φύλου στην ενσωμάτωση λέξεων σταδιακά γίνεται ένα ζωντανό ερευνητικό πεδίο τα τελευταία χρόνια. Οι περισσότερες μελέτες στον τομέα αυτό στοχεύουν στη μέτρηση και την απομάκρυνση μεθόδων με την αγγλική ως γλώσσα-στόχο. Η παρούσα εργασία διερευνά την προκατάληψη φύλου σε στατικές ενσωμάτωση λέξεων από μια μοναδική προοπτική, τα κινεζικά επίθετα. Με την εκπαίδευση των αναπαραστάσεων λέξεων με διαφορετικά μοντέλα, αξιολογείται η προκατάληψη φύλου πίσω από τους φορείς των επίθετων. Μέσω μιας σύγκρισης μεταξύ των παραγόμενων αποτελεσμάτων και ενός ανθρώπινου συνόλου δεδομένων, καταδεικνύουμε πώς η προκατάληψη φύλου που κωδικοποιείται στις ενσωμάτωση λέξεων διαφοροποιείται από τη στάση των ανθρώπων.</abstract_el>
      <abstract_kk>Соңғы жылдарда жалғыз зерттеу өрісі болады. Бұл өрістегінің көпшілігі ағылшынша тілінің өлшемі және дебияциялау әдістерін мақсат тілі ретінде мақсат етеді. Бұл қағаз Статикалық сөздерді бірнеше перспективадан ендіру үшін гендерлік тәжірибесін зерттейді. Қытайша көмектесетін. Басқа үлгілерден сөздерді бақылау арқылы, бөлшектердің артындағы бөлшектердің секс қарсы оқылған. Жасалған нәтижелер мен адамдардың нәтижелері арасындағы салыстырылып, адамдардың қасиеттерінен қалай айырмашылығын көрсетеді.</abstract_kk>
      <abstract_ka>წინ წლის შემდეგ წარმოდგენების წარმოდგენების წარმოდგენების წარმოდგენების წარმოდგენებია. ბევრი კვლევები ამ ფერის მიზეზიან ანგლისური სიტყვის განზემილების და დებიზაციის მეტოვების მიზეზი. ეს დოკუმენტი სტატიკური სიტყვებით სუნიკალური პერვიკუმენტიდან, ჩინეთის აექექტივებით განსხვავებულია. განსხვავებული მოდელთან განსხვავებული სიტყვების გამოყენებით, ექექექტივების გექსენტრის გარეშე განსხვავებულია. გამოყენებული წარმოდგენების და ადამიანის მონაცემების კონფიგურაციის შემდეგ ჩვენ გამოჩვენებთ, როგორ გენექტური წარმოდგენების კონფიგურაცია სიტყვებით გამოყენებული სიტყვებით</abstract_ka>
      <abstract_hu>A nemi elfogultság a szóbeágyazásokban fokozatosan élénk kutatási területté válik az elmúlt években. A legtöbb tanulmány ezen a területen az angol célnyelvű mérési és lebontási módszerekre irányul. A tanulmány statikus szóbeágyazásokban a nemi elfogultságot vizsgálja egyedi perspektívából, kínai melléknevekből. A különböző modellekkel történő szóreprezentációk képzésével értékeljük a melléknévek vektorai mögötti nemi elfogultságot. Az előállított eredmények és az emberi pontszámok adatkészlet összehasonlításával bemutatjuk, hogy a szóbeágyazásokban kódolt nemi elfogultság hogyan különbözik meg az emberek attitűdjétől.</abstract_hu>
      <abstract_ml>അടുത്ത കൊല്ലങ്ങളില്‍ വാക്കുകളില്‍ സ്വതന്ത്രമായി നിരീക്ഷിക്കുന്ന സ്വഭാവികമായി വാക്കുകളില്‍ പെരു ഈ പ്രദേശത്തിലെ പലതും പഠനങ്ങള്‍ക്ക് ലക്ഷ്യഭാഷയായി ഇംഗ്ലീഷില്‍ അളക്കുന്നതും തെറ്റിക്കുന്ന രീതികള്‍ക് ഈ പേപ്പറില്‍ സ്റ്റാറ്റിക്ക് വാക്കില്‍ സ്റ്റാക്കിക് വാക്കുകളില്‍ നിന്നും സ്ഥാപിക്കുന്നത് ചൈനീസ് കാഴ് വ്യത്യസ്ത മോഡലുകളുമായി വാക്കുകള്‍ പ്രതിനിധികളായി പഠിപ്പിക്കുന്നത് കൊണ്ട്, വെക്ടിക്റ്റീവുകളുടെ പി നിര്‍മ്മിക്കപ്പെട്ട ഫലങ്ങള്‍ക്കും ഒരു മനുഷ്യന്‍റെ സ്കോര്‍ട്ട് ഡേറ്റാ സെറ്റുകള്‍ക്കും തമ്മിലുള്ള ഒരു താല്‍പ്പര്യത്തിലൂടെ ഞങ്ങള്‍ കാണിച്</abstract_ml>
      <abstract_lt>Pastaraisiais metais lyčių pusiausvyra žodžių įtraukimo srityje palaipsniui tampa gyva mokslinių tyrimų sritimi. Daugumos šios srities tyrimų tikslas – matuoti ir mažinti anglų kalbą kaip tikslinę kalbą. Šiame dokumente nagrinėjama lyčių pusiausvyra statinėse žodžių įtraukose unikaliu požiūriu, Kinijos priedėliuose. Mokant žodžių atstovavimą įvairiais modeliais, vertinama lyčių pusiausvyra už priedėlių vektorių. Palygindami gautus rezultatus su žmogaus rezultatų rinkiniu, parodome, kaip lyčių pusiausvyra, koduota žodžių įtraukose, skiriasi nuo žmonių požiūrio.</abstract_lt>
      <abstract_mk>Порасната предрасуда во зборовите постепено станува живо истражувачко поле во последните години. Повеќето студии во ова поле имаат за цел методи за мерење и дебизација со англискиот јазик како цел. Овој весник ја истражува генералната пристрасност во статичките зборови вклучени од уникатна перспектива, кинеските приклучоци. Со обуката на претставувањата на зборовите со различни модели, се проценува половината на предрасудата зад векторите на приклучувањата. Со споредба помеѓу произведените резултати и човековите податоци, ние демонстрираме како генералните предрасуди кодирани во зборовите се разликуваат од однесувањата на луѓето.</abstract_mk>
      <abstract_mn>Сүүлийн жилийн дотор гендер байдал гэдэг үгийг нэмэгдүүлэхэд бага зэрэг судалгааны талбар болдог. Энэ талбарын ихэнх судалгаанууд Англи хэлний хэл болгон хэмжээгээр хэмжээгээр хэмжээгээр хэмжээгээр дүгнэх аргыг зориулдаг. Энэ цаас Хятад тусгаарлагддаг хүн төрөлхтний эсрэг байдлыг судалдаг. Өөр төрлийн загвартай илэрхийллийг суралцах үед, adjectives-ын ард гендерийн загварыг тооцоолж байна. Ингээд бүтээгдэхүүний үр дүн болон хүн төрөлхтний мэдээллийн багц хоорондын харьцуулахад бид хүмүүсийн хандлагаас хэрхэн ялгаатай гэдгийг харуулж байна.</abstract_mn>
      <abstract_pl>Uprzedzenia płci w osadzeniach słów stopniowo stają się żywą dziedziną badawczą w ostatnich latach. Większość badań w tej dziedzinie ma na celu pomiar i debiacing metod z językiem angielskim jako docelowym. Niniejszy artykuł bada uprzedzenia płci w statycznych osadzeniach słów z unikalnej perspektywy, chińskich przymiotników. Przez trening reprezentacji słów z różnymi modelami ocenia się uprzedzenia płci stojące za wektorami przymiotników. Poprzez porównanie uzyskanych wyników z zestawem danych ocenianych przez człowieka pokazujemy, w jaki sposób uprzedzenia dotyczące płci zakodowane w osadzeniach słów różnią się od postaw ludzi.</abstract_pl>
      <abstract_ro>Prejudecățile de gen în încorporarea cuvintelor devin treptat un domeniu viu de cercetare în ultimii ani. Majoritatea studiilor din acest domeniu vizează metodele de măsurare și debiasing cu limba engleză ca limbă țintă. Această lucrare investighează părtinirea genului în încorporarea statică a cuvintelor dintr-o perspectivă unică, adjectivele chinezești. Prin instruirea reprezentărilor cuvintelor cu diferite modele, se evaluează părtinirea genului din spatele vectorilor adjectivelor. Printr-o comparație între rezultatele obținute și un set de date cu scoruri umane, demonstrăm modul în care părtinirea de gen codificată în încorporarea cuvintelor diferențiază de atitudinea oamenilor.</abstract_ro>
      <abstract_no>Gender bias i ordinnbygging blir gradvis ein vivid forskningsfelt i siste år. Dei fleste studiane i dette feltet måtar å måle og debiasere metodar med engelsk som målspråket. Denne papiret undersøker seks-forsikt i statiske ordinnbygging frå ein unikt perspektiv, kinesisk adjektiv. Ved opplæring av ordrepresentasjonar med ulike modeller er seks-forskyvinga bak vektorane av adjektiv vurdert. Gjennom samanlikning mellom produserte resultatet og eit menneskelige datasett, viser vi korleis følgjande følgje kodert i ordinnbygging forskjeller frå menneskelige tilstandar.</abstract_no>
      <abstract_si>පස්සේ අවුරුදු වලින් ජීවිත විශ්වාසයෙන් පරීක්ෂණ ක්‍ෂේත්රයක් වෙනවා. මේ ක්ෂේත්රයේ ගොඩක් අධ්‍යානයක් ඉංග්‍රීසි වල ඉලක්ක භාෂා වලින් ඉංග්‍රීසි වලින් මාපනය මේ පත්තර පරීක්ෂණය කරනවා ස්ථිර වචනයෙන් ස්ථිර වචනයක් සංවිධානය කරනවා, චීනියාව අයිතිකාරයෙන්  වෙනස් මොඩල් එක්ක ප්‍රධාන වචන වචන ප්‍රතිනිශ්නය කරලා, වෙක්ටර් වලින් වෙක්ටර් වලින් සිද්ධ විශේෂ මිනිස්සුන්ගේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රති</abstract_si>
      <abstract_mt>Il-preġudizzju bejn is-sessi fl-inkorporazzjoni tal-kliem gradwalment isir qasam ta’ riċerka qawwi f’dawn l-a ħħar snin. Il-biċċa l-kbira tal-istudji f’dan il-qasam għandhom l-għan li jkejlu u jnaqqsu l-metodi bl-Ingliż bħala l-lingwa fil-mira. This paper investigates gender bias in static word embeddings from a unique perspective, Chinese adjectives.  By training word representations with different models, the gender bias behind the vectors of adjectives is assessed.  Permezz ta’ paragun bejn ir-riżultati prodotti u sett ta’ dejta b’punteġġi umani, nagħmlu xhieda ta’ kif il-preġudizzju bejn is-sessi kkodifikat fl-inkorporazzjoni tal-kliem jiddifferenzja mill-attitudnijiet tan-nies.</abstract_mt>
      <abstract_sr>Ženska predrasuda u rečima ugrađenja postupno postaje živo istraživanje polje u poslednjih godina. Većina studija na ovom polju je cilj mjerenja i debijacije metoda sa engleskim jezikom kao ciljni jezik. Ovaj papir istražuje spolne predrasude u statičnim rečima, uključujući se iz jedinstvene perspektive, kineske adjektive. Predstavljanjem reèi sa različitim modelima, procjenjuje se spolna predrasuda iza vektora adjektiva. Kroz usporedbu između proizvodnjih rezultata i grupe podataka koji su dobili ljudski rezultat, pokazujemo kako spolna predrasuda kodirana rečima ugrađenja razlikuje od stavova ljudi.</abstract_sr>
      <abstract_sv>Genusbias i ordinbäddningar blir gradvis ett levande forskningsområde under de senaste åren. De flesta studier inom detta område syftar till mätning och debiasing metoder med engelska som målspråk. Denna uppsats undersöker könsbias i statiska ordinbäddningar ur ett unikt perspektiv, kinesiska adjektiv. Genom att träna ordrepresentationer med olika modeller bedöms könsfördelningen bakom adjektivens vektorer. Genom en jämförelse mellan de producerade resultaten och en mänsklig poänguppsättning visar vi hur könsbias kodad i ordinbäddningar skiljer sig från människors attityder.</abstract_sv>
      <abstract_so>Galbeedka jinsiga ee hadalka ku dhex yaala si taxadar ah ayuu ugu dhaqdhaqaaqa u noqdaa beerta baaritaanka dhaqdhaqaaqa ee sanadkii ugu dambeeyey. Waxbarashada badankood ee duurkan waxaa loogu talagalay qiyaasta iyo qalbiyada afka Ingiriiska sida luqada goalka ah. Warqaddaas wuxuu ka baaraandegaa rabshadda jinsiga oo ku qoran hadal static ah oo ka soo baxa aragtida gaarka ah ee Shiinaha. Waxbarashada hadalka oo ku qoran tusaalooyin kala duduwan waxaa lagu qiimeeyaa qofka galmada ka dambeeya wadeenka isbedelka. Isbarbardhig u dhexeeya midhaha soo saaray iyo sawirada dadka la koobay, waxaynu muujinnaa siduu ku kooban yahay dabiicadda jinsiga ee hadalka ka ka duwan yahay aragtida dadka.</abstract_so>
      <abstract_ms>Kebiasaan jenis dalam penyelesaian perkataan secara perlahan-lahan menjadi bidang kajian yang nyata dalam tahun-tahun terakhir. Most studies in this field aim at measurement and debiasing methods with English as the target language.  Kertas ini menyelidiki bias jenis dalam penyambungan perkataan statik dari perspektif unik, adjektif Cina. By training word representations with different models, the gender bias behind the vectors of adjectives is assessed.  Through a comparison between the produced results and a human scored data set, we demonstrate how gender bias encoded in word embeddings differentiates from people's attitudes.</abstract_ms>
      <abstract_ta>சமீபத்திய ஆண்டுகளில் வார்த்தையில் பொருத்தும் பிரிவுகளில் பெண்கள் செவிரகாசமாக ஒரு விரைவான ஆராய் இந்த புலத்தில் பெரும்பாலான படிப்பாடுகள் இலக்கு மொழியாக அளவு மற்றும் பிழை நீக்கும் முறைகளை அளக்குக இந்த காகிதத்தில் புள்ளிய வார்த்தைகளில் புள்ளியியல் பிரச்சினைகளை தேடுகிறது தனிப்பட்ட புலங்களில் இருந்து,  வேறு மாதிரிகளுடன் பயிற்சி வார்த்தைகளின் பங்கீடுகளை பயிற்சி செய்து, செலுத்துவோரின் நெறிகளுக்கு பி உருவாக்கப்பட்ட முடிவுகள் மற்றும் ஒரு மனித மதிப்புள்ள தகவல் அமைப்புக்கும் இடையே ஒப்பிடுவதால், நாம் வார்த்தையில் குறியீடு பிரச்சனை</abstract_ta>
      <abstract_ur>کلمات میں جنسی بغیر بغیر اگلے سالوں میں آسان تحقیق کا فیلڈ ہو جاتا ہے۔ اس کھیتی میں اکثر مطالعہ کی مطالعہ انگلیسی کے مطالعہ سے اندازے اور ڈبیس کرنے کے مطالعہ ہیں۔ This paper investigates gender bias in static word embedding from a unique perspective, Chinese adjectives. کلمات کی تعلیم کے ذریعہ مختلف نمڈلوں کے ساتھ جنس کی تعلیم کی تعلیم کے ذریعہ، تقسیم کے ویکتروں کے پیچھے جنس کی تعلیم کا انتظام کیا جاتا ہے. پیدا کئے ہوئے نتیجے اور انسان کے ذریعہ سے ڈیٹ سٹ کے درمیان ایک مقایسہ کے ذریعہ سے، ہم نشان دیتے ہیں کہ کس طرح جنس کی مخالفت لکھی جاتی ہے جو کلمات میں ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ ڈیٹ</abstract_ur>
      <abstract_uz>Keyingi yil ichida so'zlar tajribasini tajriba qilishni o'zgartiradi. Bu maydondagi ko'pchilik o'qituvchilar ingliz tilida o'zgartirish va deb aytish usullarini anglatadi. Bu qogʻoz esa, xitoycha adjektlaridan bir unik shaklga so'zlarda jinsiyalarni o'rganadi. Bu so'zlar boshqa modellar bilan taʼminlovchi so'zlar yordamida, juksektiv vektorining qiymatiga kiritiladi. Natijalar va inson qiymatlari tarkibi maʼlumotlar tarkibida o'xshash paytlarida, biz jinsiyalar tizimi odamning fikrlaridan ajratilgan so'zlar qanday o'zgarishni ko'rganamiz.</abstract_uz>
      <abstract_vi>Giới tính giữa giới tính trong sự ghép nối từ ngữ dần trở thành một lĩnh vực nghiên cứu sống động trong những năm gần đây. Hầu hết các nghiên cứu trong lĩnh vực này nhằm mục đích đo lường và thao túng phương pháp bằng tiếng Anh. Tờ giấy này nghiên cứu tính thiên vị giới tính trong sự gắn kết từ tĩnh từ một cách độc đáo, tính từ Trung Quốc. Dựa trên các mô tả từ ngữ huấn luyện với các mô hình khác nhau, khả năng giới tính nam đằng sau các véc- tơ của tính từ được đánh giá. Bằng cách so s ánh giữa kết quả và một nhóm dữ liệu ghi điểm, chúng tôi chứng minh tính phân biệt giới tính trong sự gắn liền từ ngữ phân biệt với thái độ của con người.</abstract_vi>
      <abstract_nl>Gender bias in woord embeddings wordt de laatste jaren geleidelijk een levendig onderzoeksveld. De meeste studies op dit gebied zijn gericht op meet- en debiasing methoden met Engels als doeltaal. Deze paper onderzoekt gender bias in statische woordinbeddingen vanuit een uniek perspectief, Chinese bijvoeglijke naamwoorden. Door woordrepresentaties met verschillende modellen te trainen, wordt de gender bias achter de vectoren van bijvoeglijke naamwoorden beoordeeld. Door een vergelijking tussen de geproduceerde resultaten en een door mensen gescoorde dataset, laten we zien hoe gender bias gecodeerd in woord embeddings onderscheidt van de attitudes van mensen.</abstract_nl>
      <abstract_da>Kønsfordele i ordindlejringer bliver gradvist et levende forskningsfelt i de seneste år. De fleste undersøgelser på dette område sigter mod måling og debiasing metoder med engelsk som målsprog. Denne artikel undersøger kønsbias i statiske ord indlejringer fra et unikt perspektiv, kinesiske adjektiver. Ved at træne ordrepræsentationer med forskellige modeller vurderes kønsfordelene bag adjektivernes vektorer. Gennem en sammenligning mellem de producerede resultater og et menneskeligt scoret datasæt viser vi, hvordan kønsbias kodet i ordindlejringer adskiller sig fra folks holdninger.</abstract_da>
      <abstract_bg>Половите пристрастия в вграждането на думи постепенно се превръщат в ярка изследователска област през последните години. Повечето изследвания в тази област имат за цел измерване и дебиазиране методи с английски език като целеви език. Настоящата статия изследва половите пристрастия в статичните слова от уникална гледна точка, китайските прилагателни. Чрез обучение на думи с различни модели се оценява половото пристрастие зад векторите на прилагателните. Чрез сравнение между получените резултати и набора от данни с оценка от човека, ние демонстрираме как половите пристрастия, кодирани в вграждането на думи, се различават от нагласите на хората.</abstract_bg>
      <abstract_hr>Ženska predrasuda u riječima ugrađenja postupno postaje živo istraživanje polje u posljednjih godina. Većina ispitivanja na ovom polju cilja je mjerenja i debijaža metoda s engleskim jezikom kao ciljni jezik. Ovaj papir istražuje spolnu pristrasnost u statičnim riječima, uključujući se iz jedinstvene perspektive, kineske adjektive. Predstavljajući obrazovanje riječi s različitim modelima, procjenjuje se spolna predrasuda iza vektora adjektiva. Kroz usporedbu između proizvodnjih rezultata i skupa podataka koji su dobili ljudski rezultat, pokazujemo kako se spolna predrasuda kodirana u riječima ugrađenja razlikuje od stavova ljudi.</abstract_hr>
      <abstract_de>Gender Bias in Wort Einbettungen wird in den letzten Jahren allmählich zu einem lebendigen Forschungsfeld. Die meisten Studien in diesem Bereich zielen auf Mess- und Debiasing-Methoden mit Englisch als Zielsprache ab. Dieser Beitrag untersucht Gender Bias in statischen Worteinbettungen aus einer einzigartigen Perspektive, chinesischen Adjektiven. Durch Training von Wortrepräsentationen mit verschiedenen Modellen wird der Gender Bias hinter den Vektoren von Adjektiven bewertet. Durch einen Vergleich der gewonnenen Ergebnisse mit einem human scored Datensatz zeigen wir, wie Gender Bias kodiert in Wort Einbettungen sich von den Einstellungen der Menschen unterscheidet.</abstract_de>
      <abstract_id>Kebiasaan jenis dalam pembangunan kata secara perlahan-lahan menjadi bidang penelitian yang nyata selama bertahun-tahun terakhir. Kebanyakan studi di lapangan ini bertujuan pada metode pengukuran dan debiasing dengan bahasa Inggris sebagai bahasa sasaran. Kertas ini menyelidiki bias jenis dalam pembangunan kata statis dari perspektif unik, adjektif Cina. Dengan melatih represensi kata dengan model yang berbeda, bias jenis di belakang vektor adjektif dipastikan. Melalui perbandingan antara hasil yang dihasilkan dan set data skor manusia, kita menunjukkan bagaimana bias jenis yang dikodifikasikan dalam bentuk kata berbeda dari sikap orang.</abstract_id>
      <abstract_fa>در سال های اخیر، تحقیقات جنسیت در کلمه‌های استفاده به تدریج یک منطقه تحقیقات زنده می‌شود. بیشتر مطالعه‌ها در این زمینه هدف می‌گیرند که روش‌های اندازه‌گیری و نابودی با انگلیسی به عنوان زبان هدف باشد. این کاغذ تحقیق عادلانه جنسی در کلمه استاستیکی که از یک دیدگاه متفاوتی است، شرکت چینی را تحقیق می کند. با آموزش کلمه نمایش‌های متفاوت با مدل‌های متفاوت، پیشرفت جنسی پشت ویکتور‌های متفاوت ارزیابی می‌شود. از طریق مقایسه بین نتیجه‌های تولید شده و یک مجموعه داده‌های ثبت شده انسان، نشان می‌دهیم که چگونه پیشرفت جنسی که در کلمه‌های تولید شده‌اند، از وضعیت مردم متفاوت می‌شود.</abstract_fa>
      <abstract_sw>Ukosefu wa jinsia katika maneno yanayoingia taratibu hugeuka kuwa mtafiti wa vizuri katika miaka ya hivi karibuni. Utafiti wengi katika uwanja huu unalenga kupima na njia za kudanganya kwa Kiingereza kama lugha ya lengo. Makala hii inachunguza upendeleo wa kijinsia katika maneno ya takwimu yanayotokana na mtazamo wa kipekee, wa-China. Kwa mafunzo ya maneno yanayohusiana na mifano tofauti, upendeleo wa jinsia nyuma ya vectors za mabadiliko unavutiwa. Kwa kulinganisha kati ya matokeo yaliyozaliwa na seti ya taarifa zilizotolewa kwa binadamu, tunaonyesha jinsi upendeleo wa kijinsia ulivyokuwa umetofautiana na mitazamo ya watu.</abstract_sw>
      <abstract_ko>최근 몇 년 동안 단어에 박힌 성별 편견은 점차 활발한 연구 분야가 되었다.이 분야의 대다수 연구는 영어를 목표로 하는 언어의 측정과 감축 방법이다.본고는 중국어 형용사라는 독특한 시각에서 정태어가 박힌 성별 편견을 연구하고자 한다.서로 다른 모델을 이용하여 단어 표징을 훈련시켜 형용사 벡터 뒤에 있는 성별 편견을 평가했다.생성된 결과를 인간의 평점 데이터 집합과 비교함으로써 우리는 단어에 인코딩된 성별 편견과 사람들의 태도의 차이를 보여 주었다.</abstract_ko>
      <abstract_tr>Soňky ýyllar içinde jentiller alçaklarda ýa şamly araştyrma sahypasyna gelir. Bu sahada köp öwrenmeler iňlisçe bilen maksady dil diýip ölçüp we çykmak üçin amaçlarýar. Bu kagyzyň jentiller biasyny beýleki perspektivden daşary edilen statik sözlerde çykýar, Çin çe adjektivler. Farklı modellerle ifadeleri eğiterek, eksiktiflerin arkasındaki cinsel önlemleri değerlendirildir. Yapılan netijeler ve insan noktalary arasynda bir karşılaştırma vasitəsinde, adamlaryň durumlardan nähili cins biasyny kodlaýandygyny görkez.</abstract_tr>
      <abstract_sq>Përparësia gjinore në përfshirjen e fjalëve gradualisht bëhet një fushë kërkimi i gjallë në vitet e fundit. Shumica e studimeve në këtë fushë synojnë metodat e matjes dhe debizimit me anglishtin si gjuhën objektive. Kjo artikull heton paragjykimin e gjinisë në përfshirjen e fjalëve statike nga një perspektivë unike, adjektive kineze. Duke trajnuar përfaqësimet e fjalëve me modele të ndryshme, vlerësohet paragjykimi gjinore pas vektorëve të adjektivëve. Nëpërmjet një krahasimi midis rezultateve të prodhuara dhe një grupi të dhënash me rezultate njerëzore, ne demonstrojmë se si paragjykimi gjinore i koduar në përfshirjet e fjalëve ndryshon nga qëndrimet e njerëzve.</abstract_sq>
      <abstract_am>የዝሙት ውይይት በአሁኑ ዓመታት የቋንቋ ጥያቄ መሆኑን ቀላል ይደረጋል፡፡ በዚህ መሬት ውስጥ ብዙ ትምህርት የእንግሊዝኛ ቋንቋ እንዲመስል እና የሚያሳፍር ሥርዓት ነው፡፡ ይህ ገጽ የሴሰኝነትን ውጤቶች ከቻይና ውጤቶች በተለየ የቻይና ውይይት በሚያሳየው የቋንቋ ቃላት ይፈርዳል፡፡ በተለያዩ ምሳሌዎች ላይ የሴት ውይይት በአካባቢዎች በኋላ ነው፡፡ ፍሬዎችን እና የሰው አካባቢ ዳታዎችን በመካከለኛ በተስተያየት፣ የሴት ውጤቶች ከሕዝብ አካባቢ እንዴት እንደተለየ ቃላትን እናሳየዋለን፡፡</abstract_am>
      <abstract_af>Gender bias in woord inbettings gradief word 'n lewendige ondersoek veld in onlangse jaar. Die meeste studie in hierdie veld doel om te maak en debiasing metodes met Engels as die doel taal. Hierdie papier ondersoek geneemde bias in statiese woord inbêring van 'n unieke perspektief, Sjinese adjektives. Deur die onderwerp van woord verteenwoordes met verskillende modele, word die geneemvoorbeeld agter die vekteurs van adjektives oorgeasseer. Deur 'n vergelyking tussen die geproduseerde resultate en 'n menslike gegee data stel, wys ons hoe gemeenskap bias gekodeer in woord inbettings verskillig word van mense se aangesig.</abstract_af>
      <abstract_hy>Սկնդի կողմնականությունը բառերի ներգրավման մեջ դառնում է վերջին տարիների ընթացքում կենդանի հետազոտության ոլորտ: Այս ոլորտում ուսումնասիրությունների մեծամասնությունը նպատակում է չափել և նվազեցնել անգլերենի միջոցները որպես նպատակային լեզու: Այս հոդվածը ուսումնասիրում է գենդերային կողմնականությունը առանձնահատուկ տեսանկյունից ստատիկ բառերի ներդրման մեջ, չինական ադրեկտիվ: Օգտագործելով բառերի ներկայացումներ տարբեր մոդելներով, գնահատվում է սեռի կողմնականությունը աճեկտիվ գործիչների ետևում: Համեմատության միջոցով արտադրված արդյունքների և մարդկային գնահատված տվյալների համակարգի միջև մենք ցույց ենք տալիս, թե ինչպես գենդերային կողմնականությունը, կոդավորված բառերի ներառման մեջ, տարբերվում է մարդկանց դիրքերից:</abstract_hy>
      <abstract_az>Sözlərdə dövlətli tədbirlər son il içində yaşayan bir araştırma sahəsi olar. Bu sahədə çox öyrənmək məqsədilə İngilizce dili ilə ölçmək və debiyasing metodlarını məqsədilə məcbur edir. Bu kağıt statik sözlərdə cins bias ını təşkil edir ki, ünsiyyətli bir perspektivdən, Çincə təşkil edir. Müxtəlif modellərlə təhsil edilən sözləri təhsil edirək, adjektivlərin vektorların arxasında cins bias ı təhsil edilir. Yapılmış sonuçlar və insan məlumatlarının dəyişdirilməsi ilə insanların davranışlarından necə fərqli olduğunu göstərdik.</abstract_az>
      <abstract_bs>Ženska predrasuda u riječima ugrađenja postupno postaje živo istraživanje polje u posljednjih godina. Većina studija na ovom polju cilja je mjerenja i debijaža metoda s engleskim kao ciljanim jezikom. Ovaj papir istražuje spolne predrasude u statičnim riječima, uključujući se iz jedinstvene perspektive, kineske adjektive. Predstavljajući obrazovanje riječi sa različitim modelima, procjenjuje se spolna predrasuda iza vektora adjektiva. Kroz usporedbu između proizvodnjih rezultata i grupe podataka koji su dobili ljudski rezultat, pokazujemo kako se seksualna predrasuda kodirana u riječima ugrađenja razlikuje od stavova ljudi.</abstract_bs>
      <abstract_ca>El bias de gènere en l'incorporació de paraules es converteix gradualment en un camp de investigació viu en els últims anys. La majoria dels estudis d'aquest camp busquen mètodes de mesura i debilitació amb l'anglès com a llenguatge d'objectiu. Aquest article investiga el bias de gènere en les integracions estatiques de paraules d'una perspectiva única, els adjectius xinesos. Treinant representacions de paraules amb diferents models, es valora el bias de gènere darrere dels vectors d'adjectius. A través d'una comparació entre els resultats produïts i un conjunt de dades puntuades per humans, demostram com el bias de gènere codificat en les integracions de paraules diferencia de les actituds de la gent.</abstract_ca>
      <abstract_bn>সাম্প্রতিক বছরগুলোতে শব্দের বিভিন্ন ভিডিও গবেষণা ক্ষেত্রে লিঙ্গের বিরুদ্ধে ধীরে পরিণত হয়। এই ক্ষেত্রে বেশীরভাগ গবেষণার লক্ষ্য হচ্ছে গ্রেফতার ভাষা হিসেবে ইংরেজি দ্বারা মাপ এবং বিভ্রান্তিকর এই পত্রিকাটি একটি বিশেষ দৃষ্টিভঙ্গি থেকে বিভিন্ন দৃষ্টিভঙ্গিতে লিঙ্গের বিরুদ্ধে তদন্ত করেছে। প্রশিক্ষণের মাধ্যমে ভিন্ন মডেলের প্রতিনিধিত্বের মাধ্যমে প্রশিক্ষণের মাধ্যমে সংযুক্ত ভেক্টরের পেছনে যৌ উৎপাদনের ফলাফল এবং মানুষের স্কোরের তথ্য সেটের মধ্যে তুলনায় আমরা প্রদর্শন করি কিভাবে লিঙ্গের বিরুদ্ধে শব্দের বিভিন্ন ভিন্ন ভিন্ন ভিন্</abstract_bn>
      <abstract_cs>Genderová zaujatost ve slovních vloženích se v posledních letech postupně stává živým výzkumným oborem. Většina studií v této oblasti se zaměřuje na metody měření a debiacingu s angličtinou jako cílovým jazykem. Tento článek zkoumá genderové zaujatosti v statických slovních vloženích z unikátní perspektivy, čínská přídavná jména. Trénováním reprezentace slov s různými modely je posouzena genderová zaujatost za vektory přídavných jmen. Prostřednictvím srovnání mezi získanými výsledky a datovou sadou hodnocených lidí ukazujeme, jak se genderová zaujatost kódovaná ve slovních vloženích liší od postojů lidí.</abstract_cs>
      <abstract_et>Sooline eelarvamus sõnade manustamisel muutub viimastel aastatel järk-järgult elavaks uurimisvaldkonnaks. Enamik uuringuid selles valdkonnas on suunatud mõõtmis- ja debiasimismeetoditele, mille sihtkeeleks on inglise keel. Käesolevas artiklis uuritakse sooliseid eelarvamusi staatilistes sõnades ainulaadsest vaatenurgast, hiina omadussõnadest. Erinevate mudelitega sõnarepresentatsioonide koolitamisel hinnatakse omadussõnade vektorite sooliseid eelarvamusi. Toodetud tulemuste ja inimese hinnatud andmekogumi võrdlemise kaudu näitame, kuidas sõnades kodeeritud soolised eelarvamused eristuvad inimeste hoiakutest.</abstract_et>
      <abstract_fi>Sukupuolinen puolueellisuus sanan upottamisessa muuttuu vähitellen eloisaksi tutkimuskentäksi viime vuosina. Suurin osa alan tutkimuksista tähtää mittaus- ja debiasointimenetelmiin, joiden kohdekielenä on englanti. Tämä artikkeli tutkii sukupuoliharhaa staattisissa sanaupotuksissa ainutlaatuisesta näkökulmasta, kiinalaisista adjektiiveista. Harjoittamalla sanaesityksiä eri malleilla arvioidaan adjektiivien vektorien taustalla olevaa sukupuolivääristymää. Vertailemalla tuotettuja tuloksia ja ihmispisteytettyä aineistoa osoitamme, miten sanaupotuksiin koodattu sukupuoliharha eroaa ihmisten asenteista.</abstract_fi>
      <abstract_jv>Wis Piye graning ing ing dipunangé karo kapan iki, suku piye measurement lan debianing method karo Inggris barang kelangan bangsa. Awakdhéwé iki dadi nyong nglanggar bias-bias kanggo mbanjurakan kelas kuwi panggayatan, nik nggambar barang basa sing wis mungkin nggo nggambar uwis. Genjer-Genjer Dheweke ngomong karo perusahaan langgar dadi nggawe lan mulalaman dino sing perusahaan, awak dhéwé ngerasakno piye cara-piye sing ngerasakno ning awak dhéwé ngerasakno uwong sing ngerasakno uwong.</abstract_jv>
      <abstract_he>ההתמחות הגברית במילים בהדרגה הופכת לשדה מחקר חי בשנים האחרונות. רוב המחקרים בשטח הזה מכוונים למדידה ושיטות השמידה עם אנגלית כשפת המטרה. העיתון הזה חוקר את ההתמחות מינית במילים סטטיות ממבט ייחודי, תוספות סיניות. על ידי אימון מילים מייצגות עם דוגמנים שונים, ההתמונות של מין מאחורי הוקטורים של תוספים מוערכת. Through a comparison between the produced results and a human scored data set, we demonstrate how gender bias encoded in word embeddings differentiates from people's attitudes.</abstract_he>
      <abstract_fil>Ang Gender bias sa salitang embedding ay nagiging mabuhay na research field noong mga nakaraang taon. Ang karamihan ng mga pag-aaral sa parang na ito ay ibinibigay sa pagsukat at debiasing ng mga paraan na may Ingles bilang target language. Ang paper na ito ay sumusunod ng gender bias sa static word embedding from a unique perspective, Chinese adjectives. Sa pagtuturo ng mga salitang representasyon na may ibang mga modelo, ang gender bias sa likuran ng mga vectors ng adjectives ay inihasis. Sa pamamagitan ng komparasyon s a mga resultado at sa isang data set ng tao, nagpapakita kami kung paano ang gender bias encoded sa salitang embeddings ay nagkakaiba sa mga pakikipagkailangan ng mga tao.</abstract_fil>
      <abstract_sk>Spolna pristranskost pri vključevanju besed v zadnjih letih postopoma postaja živahno raziskovalno področje. Večina študij na tem področju je usmerjenih v metode merjenja in debiasiranja z angleščino kot ciljnim jezikom. V prispevku raziskujemo spolno pristranskost v statičnih besedah z edinstvenega vidika, kitajskih pridevnikov. Z usposabljanjem besednih reprezentacij z različnimi modeli se oceni spolna pristranskost za vektorji pridevnikov. S primerjavo doseženih rezultatov in nabora podatkov s človeško oceno prikazujemo, kako spolna pristranskost, kodirana v besedah, razlikuje od odnosov ljudi.</abstract_sk>
      <abstract_ha>Mataimakin jini da ke cikin maganar da aka shigar ta taƙaitacce ta zama field na fassarar research a cikin shekara na farko. Babu abu da ake amfani da akan wannan field yana ƙayyade metodin yin haƙƙin da yin gaugãwa da Ingiriya kamar harshen wanda aka ƙayyade. Wannan karatun yana tambayar suriyar jini cikin kalma na tababar da ke cikin wata na'ani na dabam'a, China. Ina ƙidãya game da tsarin maganar masu da misãlai daban, ana ƙayyade jinsi bakin shiryoyin juyi. Ina samfani a tsakanin da aka samar da fassaran mutane da aka score data, za mu nuna jinin yadda biyar jinni ya kodi a cikin maganar ta rarrabe masu daga misãlai ga mutane.</abstract_ha>
      <abstract_bo>གནས་ཚུལ་ནང་གི་སྐྱེས་ཆེན་དག་རྣམས་གནས་སྟངས་འདི་ལྟར་བཅས་ཀྱི་འཚོལ་ཞིབ་ཚབ་ཤིག་ཏུ་འགྱུར་སྲིད། སྒེར་གྱི་ནང་དུ་ཡོད་ཚད་མང་ཆེ་ཤོས་ཡིན་པའི་དབྱིན་ཡིག་གི་ལམ་ལུགས་ཚད་དང་རྫུན་བཟོ་བྱེད་ཀྱི་ཡོད། ཤོག་བྱང་འདིས་གསལ་བཤད་པའི་ནང་དུ་འཛམ་གླིང་སྐྱེས་པའི་གནད་དོན་རིགས་ལ་བཙལ་ཞིབ་ཏེ། དབྱེ་རིམ་དང་མི་འདྲ་བའི་གྲངས་སྒྲིག་ཐད་ནས་སྡོད་པའི་གནས་ཚུལ་གྱི་རྗེས་ཀྱི་གཏོང་བ་དེ་རྟོགས་ཡོད། དཔལ་འབྲས་བ་དང་མིའི་རྣམ་གྲངས་ཀྱི་ཚད་རྩིས་ཡོད་པའི་བརྡ་སྐོར་ལས་</abstract_bo>
      </paper>
    <paper id="3">
      <title>Evaluating Gender Bias in Hindi-English Machine Translation<fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Machine Translation</title>
      <author><first>Krithika</first><last>Ramesh</last></author>
      <author><first>Gauri</first><last>Gupta</last></author>
      <author><first>Sanjay</first><last>Singh</last></author>
      <pages>16–23</pages>
      <abstract>With <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs. The word embedding representations of these <a href="https://en.wikipedia.org/wiki/Language_model">language models</a> often implicitly draw unwanted associations that form a social bias within the model. The nature of gendered languages like <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject. Additionally, there is sparse work done in the realm of measuring and debiasing systems for <a href="https://en.wikipedia.org/wiki/Indo-Aryan_languages">Indic languages</a>. In our work, we attempt to evaluate and quantify the <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> within a Hindi-English machine translation system. We implement a modified version of the existing TGBI metric based on the grammatical considerations for <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>. We also compare and contrast the resulting bias measurements across multiple <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> for pre-trained embeddings and the ones learned by our machine translation model.</abstract>
      <url hash="899b8bf2">2021.gebnlp-1.3</url>
      <attachment type="OptionalSupplementaryMaterial" hash="5b68eee7">2021.gebnlp-1.3.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.gebnlp-1.3</doi>
      <bibkey>ramesh-etal-2021-evaluating</bibkey>
    <title_ar>تقييم التحيز بين الجنسين في الترجمة الآلية الهندية الإنجليزية</title_ar>
      <title_pt>Avaliando o preconceito de gênero na tradução automática hindi-inglês</title_pt>
      <title_fr>Évaluation des préjugés sexistes dans la traduction automatique hindi-anglais</title_fr>
      <title_es>Evaluación del sesgo de género en la traducción automática hindi-inglés</title_es>
      <title_zh>评估印地语- 英语机器翻译中性别偏见</title_zh>
      <title_ja>ヒンディー語-英語機械翻訳におけるジェンダーバイアスの評価</title_ja>
      <title_ukr>Оцінка гендерної упередженості в машинному перекладі гінді-англійською мовою</title_ukr>
      <title_hi>हिंदी-अंग्रेजी मशीन अनुवाद में लिंग पूर्वाग्रह का मूल्यांकन</title_hi>
      <title_ga>Ag Measúnú Laofachta Inscne san Aistriúchán Meaisín Hiondúis-Béarla</title_ga>
      <title_ru>Оценка гендерной предвзятости в машинном переводе на хинди и английском языке</title_ru>
      <title_ka>Name</title_ka>
      <title_el>Αξιολόγηση της προκατάλειψης των φύλων στα Χίντι-Αγγλικά Μηχανική μετάφραση</title_el>
      <title_it>Valutazione dei bias di genere nella traduzione automatica hindi-inglese</title_it>
      <title_hu>A nemek közötti eltérések értékelése hindi-angol gépi fordításban</title_hu>
      <title_kk>Хинд- ағылшын тіліндегі машинаның аудармасында гендер биасын оқу</title_kk>
      <title_isl>Mat á kynlegum breytingum í hindísk-ensku vélþýðingu</title_isl>
      <title_mk>Evaluating Gender Bias in Hindi-English Machine Translation</title_mk>
      <title_lt>Lyčių nelaimių vertinimas vertant anglų kalba anglų kalba</title_lt>
      <title_mt>Evalwazzjoni tad-Differenzi bejn is-Sessi fit-Traduzzjoni tal-Makkinarju Indjan-Ingliż</title_mt>
      <title_ms>Menilai Bias Gender dalam Terjemahan Mesin Hindi-Inggeris</title_ms>
      <title_ml>ഹിന്ദി- ഇംഗ്ലീഷ്- മെഷീന്‍ പരിഭാഷപ്പെടുത്തുന്നതിനുള്ള ലീന്‍ഡ് ബിയാസ്</title_ml>
      <title_no>Evaluerer sjølvbyar i hindisk- engelsk maskinsomsetjing</title_no>
      <title_mn>Хинди-Англи хэлний машины хөгжлийн биасыг үнэлэх</title_mn>
      <title_pl>Ocena uprzedzeń płci w tłumaczeniu maszynowym hindi-angielskim</title_pl>
      <title_ro>Evaluarea Bias de gen în traducerea automată hindi-engleză</title_ro>
      <title_sv>Utvärdering av könsfördelning i hindi-engelska maskinöversättning</title_sv>
      <title_so>Qiimeynta qoraalka jinsiga ee lagu turjumayo mashiinka Ingiriis-Ingiriis</title_so>
      <title_ur>ہندی-انگلیسی ماشین ترجمہ میں جنس بیس کا ارزش کیا گیا ہے</title_ur>
      <title_si>Name</title_si>
      <title_sr>Procjenjivanje Gender Bias u Hindi-engleskom mašinskom prevodu</title_sr>
      <title_ta>Hindi- ஆங்கிலம் இயந்திரம் மொழிபெயர்ப்பில் இனம் பியாஸ்களை மதிப்பிடுகிறது</title_ta>
      <title_vi>Đánh giá giới tính bằng tiếng Hindi?</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Оценка на половите наклонности в хинди-английски машинен превод</title_bg>
      <title_da>Evaluering af kønsfordele i hindi-engelsk maskinoversættelse</title_da>
      <title_nl>Het beoordelen van gender bias in het Hindi-Engels Machine Translation</title_nl>
      <title_hr>Procjenjivanje Gender Bias u Hindi-engleskom prevodu strojeva</title_hr>
      <title_de>Bewertung von Gender Bias in Hindi-Englisch Maschinelle Übersetzung</title_de>
      <title_id>Mengevaluasi Kesusahan Gender dalam Translation Machine Hindi-Inggris</title_id>
      <title_fa>ارزیابی بیس جنسی در ترجمه ماشین هندی-انگلیسی</title_fa>
      <title_ko>인디언-영어 번역 중인 성별 편견 평가</title_ko>
      <title_sw>Kupima Biashara ya jinsia katika Tafsiri ya Kiingereza</title_sw>
      <title_tr>Hindi-Iňlisçe Maşynyň terjimesinde jentiller Biýasyny Taýýarlamak</title_tr>
      <title_am>የgender Bias በማድረግ ላይ በHindi-እንግሊዘኛ Machine መግለጫ</title_am>
      <title_af>Evalueer Gender Bias in Hindi- Engels Masjien Vertaling</title_af>
      <title_sq>Vlerësimi i ngatërresave gjinore në përkthimin e makinave Hindi-English</title_sq>
      <title_az>Hindi-캻ngiliz톛 Makinel톛rin T톛rc칲m톛sind톛 Gender Bias qiym톛ti</title_az>
      <title_bn>হিন্দি- ইংরেজী মেশিন অনুবাদের লিঙ্গ বিয়াস পরিমাপ করা হচ্ছে</title_bn>
      <title_hy>Հինդի-անգլերեն մեքենայի թարգմանման գենդերային հակամարտությունների գնահատումը</title_hy>
      <title_ca>Evaluation Gender Bias in Hindi-English Machine Translation</title_ca>
      <title_bs>Procjenjivanje Gender Bias u Hindi-English Machine Translation</title_bs>
      <title_cs>Hodnocení genderových předpokladů v hindštině-angličtině Strojový překlad</title_cs>
      <title_et>Soolise eelarvamuse hindamine hindi-inglise masintõlkes</title_et>
      <title_fi>Sukupuolten ennakkoluulojen arviointi hindi-englanti Konekäännös</title_fi>
      <title_jv>Ngawe Perintah Gender Bias nang Terjamahan Inggris-Inggris</title_jv>
      <title_sk>Ocenjevanje spolnih pristranskosti v hindujsko-angleškem strojnem prevajanju</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_fil>Inaalaga ang Gender Bias sa Hindi-English Machine Translation</title_fil>
      <title_bo>རྒྱ་ནག་ཡིག་གི་མིང་ཚོའི་དབྱིན་ཡིག་ཆས་ལ་འགྲེལ་བཤད་ཀྱི་དབྱེ་རིགས་ཤིག་བྱ་རིམ་དང་།</title_bo>
      <title_he>הערכה של סבלנות מיני בתרגום מכונות הינדי-אנגלית</title_he>
      <abstract_pt>Com os modelos de linguagem sendo implantados cada vez mais no mundo real, é essencial abordar a questão da justiça de suas saídas. A palavra que incorpora representações desses modelos de linguagem muitas vezes atrai implicitamente associações indesejadas que formam um viés social dentro do modelo. A natureza das línguas de gênero, como o hindi, coloca um problema adicional à quantificação e mitigação do viés, devido à mudança na forma das palavras na frase, com base no gênero do sujeito. Além disso, há um trabalho esparso feito no domínio dos sistemas de medição e desbalanceamento para as línguas índicas. Em nosso trabalho, tentamos avaliar e quantificar o preconceito de gênero dentro de um sistema de tradução automática Hindi-Inglês. Implementamos uma versão modificada da métrica TGBI existente com base nas considerações gramaticais para o hindi. Também comparamos e contrastamos as medições de viés resultantes em várias métricas para incorporações pré-treinadas e aquelas aprendidas pelo nosso modelo de tradução automática.</abstract_pt>
      <abstract_ar>مع انتشار النماذج اللغوية بشكل متزايد في العالم الحقيقي ، من الضروري معالجة مسألة عدالة مخرجاتها. غالبًا ما تؤدي كلمة تضمين تمثيلات نماذج اللغة هذه إلى جذب ارتباطات غير مرغوب فيها تشكل تحيزًا اجتماعيًا داخل النموذج. تطرح طبيعة اللغات الجنسانية مثل الهندية مشكلة إضافية لتقدير التحيز وتخفيفه ، بسبب التغيير في شكل الكلمات في الجملة ، بناءً على جنس الموضوع. بالإضافة إلى ذلك ، هناك القليل من العمل المنجز في مجال أنظمة القياس وإزالة الحواف للغات الهندية. في عملنا ، نحاول تقييم وقياس التحيز بين الجنسين في نظام الترجمة الآلية الهندية الإنجليزية. نقوم بتنفيذ نسخة معدلة من مقياس TGBI الحالي بناءً على الاعتبارات النحوية للغة الهندية. نقوم أيضًا بمقارنة ومقارنة قياسات التحيز الناتجة عبر مقاييس متعددة لحفلات الزفاف المدربة مسبقًا وتلك التي تم تعلمها من خلال نموذج الترجمة الآلية لدينا.</abstract_ar>
      <abstract_es>Con los modelos lingüísticos cada vez más desplegados en el mundo real, es esencial abordar la cuestión de la imparcialidad de sus productos. La palabra que incorpora representaciones de estos modelos de lenguaje a menudo dibuja implícitamente asociaciones no deseadas que forman un sesgo social dentro del modelo. La naturaleza de los idiomas de género, como el hindi, plantea un problema adicional para la cuantificación y mitigación del sesgo, debido al cambio en la forma de las palabras de la oración, en función del género del sujeto. Además, hay poco trabajo realizado en el ámbito de los sistemas de medición y desvío para las lenguas índicas. En nuestro trabajo, intentamos evaluar y cuantificar el sesgo de género dentro de un sistema de traducción automática hindi-inglés. Implementamos una versión modificada de la métrica TGBI existente basada en las consideraciones gramaticales del hindi. También comparamos y contrastamos las mediciones de sesgo resultantes en múltiples métricas para incorporaciones previamente entrenadas y las aprendidas por nuestro modelo de traducción automática.</abstract_es>
      <abstract_fr>Les modèles linguistiques étant de plus en plus utilisés dans le monde réel, il est essentiel d'aborder la question de l'équité de leurs résultats. Le mot incorporant des représentations de ces modèles linguistiques crée souvent implicitement des associations indésirables qui forment un biais social au sein du modèle. La nature des langues sexospécifiques, comme l'hindi, pose un problème supplémentaire à la quantification et à l'atténuation des biais, en raison du changement de forme des mots dans la phrase, en fonction du sexe du sujet. En outre, peu de travail est fait dans le domaine des systèmes de mesure et de débiaisement pour les langues indiennes. Dans notre travail, nous tentons d'évaluer et de quantifier les préjugés sexistes au sein d'un système de traduction automatique hindi-anglais. Nous implémentons une version modifiée de la métrique TGBI existante basée sur les considérations grammaticales pour l'hindi. Nous comparons et comparons également les mesures de biais résultantes entre plusieurs mesures pour les intégrations pré-entraînées et celles apprises par notre modèle de traduction automatique.</abstract_fr>
      <abstract_zh>随言模转多,决输公平性至重。 其言模形之词,隐式画不须之关,以成偏见。 印地语性别量化轻,句单词因主而变也。 此外,印度语之度去偏度统域亦少事也。 试评量化印地语 - 英语机器翻译系统性偏见。 据印地语语法注意事项成 TGBI 指标修改版本。 较之先练嵌机器翻译多指标差测量值。</abstract_zh>
      <abstract_hi>भाषा मॉडल के साथ वास्तविक दुनिया में तेजी से तैनात किया जा रहा है, यह उनके outputs की निष्पक्षता के मुद्दे को संबोधित करने के लिए आवश्यक है। इन भाषा मॉडलों के प्रतिनिधित्व को एम्बेड करने वाला शब्द अक्सर अंतर्निहित रूप से अवांछित संघों को आकर्षित करता है जो मॉडल के भीतर एक सामाजिक पूर्वाग्रह बनाते हैं। हिंदी जैसी लैंगिक भाषाओं की प्रकृति, विषय के लिंग के आधार पर वाक्य में शब्दों के रूप में परिवर्तन के कारण पूर्वाग्रह के परिमाणीकरण और शमन के लिए एक अतिरिक्त समस्या पैदा करती है। इसके अतिरिक्त, भारतीय भाषाओं के लिए प्रणालियों को मापने और डिबियासिंग के दायरे में विरल कार्य किया जाता है। हमारे काम में, हम एक हिंदी-अंग्रेजी मशीन अनुवाद प्रणाली के भीतर लिंग पूर्वाग्रह का मूल्यांकन और मात्रा निर्धारित करने का प्रयास करते हैं। हम हिंदी के लिए व्याकरणिक विचारों के आधार पर मौजूदा TGBI मीट्रिक के एक संशोधित संस्करण को लागू करते हैं। हम पूर्व-प्रशिक्षित एम्बेडिंग के लिए कई मीट्रिक में परिणामी पूर्वाग्रह मापों की तुलना और इसके विपरीत भी करते हैं और हमारे मशीन अनुवाद मॉडल द्वारा सीखे गए हैं।</abstract_hi>
      <abstract_ja>言語モデルが現実世界でますます展開されているため、そのアウトプットの公平性の問題に取り組むことが不可欠です。 これらの言語モデルの単語埋め込み表現は、多くの場合、モデル内に社会的バイアスを形成する望ましくない関連を暗黙的に描きます。 ヒンディー語のような性別言語の性質は、対象の性別に基づいて文の単語の形式が変化したため、偏見の定量化と緩和にさらなる問題をもたらします。 さらに、Indic言語の測定およびデバイアスシステムの領域では、ほとんど作業が行われていません。 私たちの研究では、ヒンディー語-英語機械翻訳システム内のジェンダーバイアスを評価し、定量化しようとしています。 ヒンディー語の文法的考察に基づいて、既存のTGBIメトリックの修正版を実装しています。 また、事前にトレーニングされた埋め込みのための複数の指標と、機械翻訳モデルで学んだ指標を比較し、対比します。</abstract_ja>
      <abstract_ru>Поскольку языковые модели все шире используются в реальном мире, крайне важно решить вопрос о справедливости их результатов. Представления этих языковых моделей, содержащие слово, часто подразумевают нежелательные ассоциации, которые формируют социальную предвзятость в рамках модели. Гендерный характер таких языков, как хинди, создает дополнительную проблему для количественной оценки и смягчения предвзятости в связи с изменением формы слов в предложении в зависимости от пола субъекта. Кроме того, в области систем измерения и дебиасинга для языков индикаторов проделана скудная работа. В своей работе мы пытаемся оценить и количественно оценить гендерную предвзятость в системе машинного перевода хинди-английского языка. Мы внедряем модифицированную версию существующей метрики TGBI на основе грамматических соображений для хинди. Мы также сравниваем и сравниваем полученные в результате измерения смещения по нескольким показателям для предварительно обученных вложений и тех, которые были изучены с помощью нашей модели машинного перевода.</abstract_ru>
      <abstract_ga>Agus múnlaí teanga á n-úsáid níos mó agus níos mó sa saol fíor, tá sé riachtanach aghaidh a thabhairt ar cheist chothroime a n-aschur. Is minic go dtarraingíonn an focal leabú léirithe ar na múnlaí teanga seo cumainn nach dteastaíonn uathu a chruthaíonn laofacht shóisialta laistigh den mhúnla. Cruthaíonn nádúr na dteangacha inscne cosúil le Hiondúis fadhb bhreise maidir le cainníochtú agus maolú na laofachta, mar gheall ar an athrú ar fhoirm na bhfocal san abairt, bunaithe ar inscne an ábhair. Ina theannta sin, is tearc obair a dhéantar i réimse na gcóras tomhais agus díchlaonta do theangacha Indeacha. Inár gcuid oibre, déanaimid iarracht an claonadh inscne laistigh de chóras aistriúcháin meaisín Hiondúis-Béarla a mheas agus a chainníochtú. Cuirimid leagan modhnaithe de mhéadrach TGBI reatha i bhfeidhm bunaithe ar na gnéithe gramadaí don Hiondúis. Déanaimid comparáid agus codarsnacht freisin idir na tomhais laofachta a bhíonn mar thoradh air sin trasna méadracht iolrach do leabú réamhoilte agus na cinn a d’fhoghlaim ár múnla aistriúcháin meaisín.</abstract_ga>
      <abstract_ukr>Оскільки мовні моделі все частіше розгортаються в реальному світі, важливо вирішити питання справедливості їх результатів. Репрезентації вбудовування слів цих мовних моделей часто мимоволі малюють небажані асоціації, які утворюють соціальне упередження всередині моделі. Природа гендерних мов, таких як гінді, становить додаткову проблему для кількісного визначення та пом 'якшення упередженості, через зміну форми слів у реченні, засновану на статі суб' єкта. Крім того, існує невелика робота, виконана в області вимірювання та дебіасизації систем для мов індикаторів. У своїй роботі ми намагаємося оцінити та кількісно оцінити гендерну упередженість в системі машинного перекладу гінді-англійською мовою. Ми впроваджуємо модифіковану версію існуючої метрики TGBI на основі граматичних міркувань щодо гінді. Ми також порівнюємо та порівнюємо отримані вимірювання похибки для декількох показників для попередньо навчених вбудов та тих, що вивчені нашою моделлю машинного перекладу.</abstract_ukr>
      <abstract_isl>Með því að tungumyndir eru allt meira í raunverulegum heimi er nauðsynlegt að ræða málið um réttlæti úttaka þeirra. Orðið sem inniheldur myndir þessara tungumynda dregur oft óæskilega óæskilegar tengsl sem mynda samfélagsleg tilhneiging innan líkamans. Náttúru kynlegra tungumál eins og indíána veldur auknum vandamálum við kvarðað og auðveldara tilhneigingu vegna breytinga á formi orða í setningunni, byggt á kyni efnisins. Auk þess er lítið verk gert á svæði mælingar- og þrýstingskerfa fyrir indíska tungumál. Í vinnunni okkar reynum viđ a đ meta og kvarđa kynhneigđ innan hindíska-ensku tölvuskerfisins. Við framkvæmum breytta útgáfu af núverandi TGBI mæli byggt á grammatical considerations fyrir Hindi. Við borum einnig saman og breytum saman niðurstöðum niðurstöðunarmælinga á mörgum mælingum fyrir fyrirþjálfaðar innsetningar og þær sem þekkt er af tölvulegum þýðingarlíkani okkar.</abstract_isl>
      <abstract_ka>ენების მოდელები, რომლებიც რეალური მსოფლიოში უფრო მეტი გამოყენებულია, უფრო მნიშვნელოვანია, რომ მათი გავაკეთებების სამართლობას გასაკეთება. სიტყვა, რომელიც ამ ენის მოდელების გამოყენებულებების გამოყენება, ზოგიერთად გამოყენებულია, რომელიც მოდელში სოციალური წინასწორება. გენდრებულ ენების სახელი, როგორც ჰინდი, დამატებული პრობლემა კვანტაქტიფიკაციის და მიმცირების კონტაქტიფიკაციის და მიმცირების განმავლობაზე, რადგან სიტყვების ფორმის ცვლილება, რადგან მისი სახე დამატებით, ინდოეთიური ენებისთვის სისტემების მარტირება და დებიზაციის სამყაროში აკეთებულია. ჩვენი სამუშაოში, ჩვენ ვცდილობთ განსაზღვრება და კვანტაქტირება გენდრების წინასწორება ჰინდი-ანგლისური მანქანის განსაგულისხმების სისტემაში. ჩვენ მივიყენებთ გადასრულებული TGBI მეტრიკის შეცვლელი ვერსია, რომელიც ჰინდის გრამიკალური აღმოჩენებისთვის. ჩვენ ასევე შემწყვებით და კონტრონტრებით შემდეგ მრავალური მეტრიკის განზომილებები, რომლებიც წინასწყვებით განზომილებული ინბიდნენებისთვის და ჩვენი მაქინის გან</abstract_ka>
      <abstract_el>Καθώς τα γλωσσικά μοντέλα αναπτύσσονται όλο και περισσότερο στον πραγματικό κόσμο, είναι σημαντικό να αντιμετωπιστεί το ζήτημα της δικαιοσύνης των αποτελεσμάτων τους. Η λέξη που ενσωματώνει αναπαραστάσεις αυτών των γλωσσικών μοντέλων συχνά συνεπάγεται ανεπιθύμητες συσχετίσεις που σχηματίζουν μια κοινωνική προκατάληψη μέσα στο μοντέλο. Η φύση των φυλετικών γλωσσών όπως τα Χίντι, θέτει ένα πρόσθετο πρόβλημα στον ποσοτικό προσδιορισμό και τον μετριασμό της προκατάληψης, λόγω της αλλαγής της μορφής των λέξεων στην πρόταση, με βάση το φύλο του υποκειμένου. Επιπροσθέτως, γίνεται σπάνια εργασία στον τομέα της μέτρησης και της απομάκρυνσης των συστημάτων για τις ινδικές γλώσσες. Στην εργασία μας, προσπαθούμε να αξιολογήσουμε και να ποσοτικοποιήσουμε την προκατάληψη φύλου μέσα σε ένα σύστημα μηχανικής μετάφρασης Χίντι-Αγγλικά. Εφαρμόζουμε μια τροποποιημένη έκδοση της υπάρχουσας μετρικής βασισμένη στις γραμματικές εκτιμήσεις για τα Χίντι. Επίσης, συγκρίνουμε και συγκρίνουμε τις μετρήσεις προκατάλειψης που προκύπτουν σε πολλαπλές μετρήσεις για προ-εκπαιδευμένες ενσωματώσεις και αυτές που μαθαίνουμε από το μοντέλο μηχανικής μετάφρασης.</abstract_el>
      <abstract_hu>Mivel a nyelvi modelleket egyre inkább alkalmazzák a valós világban, alapvető fontosságú, hogy foglalkozzunk az eredmények méltányosságával. Ezeknek a nyelvi modelleknek a beágyazása szó gyakran implicit módon vonzza le a nem kívánt asszociációkat, amelyek társadalmi elfogultságot alkotnak a modellben. A nemi nyelvek jellege, mint a hindi, további problémát jelent az elfogultság számszerűsítése és enyhítése szempontjából, mivel a mondatban szereplő szavak formájának változása, a téma neme alapján. Ezen túlmenően ritka munka folyik az indikus nyelvek mérési és lejátszási rendszereinek területén. Munkánk során megpróbáljuk értékelni és számszerűsíteni a nemi elfogultságot egy hindi-angol gépi fordító rendszerben. A meglévő TGBI metrika módosított verzióját a hindi nyelvtani megfontolások alapján hajtjuk végre. Ezenkívül összehasonlítjuk és ellensúlyozzuk az előre képzett beágyazások és a gépi fordítási modellünk által tanultak méréseket.</abstract_hu>
      <abstract_it>Dato che i modelli linguistici sono sempre più diffusi nel mondo reale, è essenziale affrontare la questione dell'equità dei loro risultati. La parola incorporare rappresentazioni di questi modelli linguistici spesso disegna implicitamente associazioni indesiderate che formano un pregiudizio sociale all'interno del modello. La natura delle lingue di genere come l'hindi, pone un ulteriore problema alla quantificazione e mitigazione dei pregiudizi, a causa del cambiamento nella forma delle parole nella frase, in base al genere del soggetto. Inoltre, c'è poco lavoro fatto nel campo dei sistemi di misurazione e debiasing per le lingue indiche. Nel nostro lavoro, cerchiamo di valutare e quantificare il pregiudizio di genere all'interno di un sistema di traduzione automatica hindi-inglese. Implementiamo una versione modificata della metrica TGBI esistente basata sulle considerazioni grammaticali per Hindi. Confrontiamo e confrontiamo anche le misurazioni di bias risultanti attraverso più metriche per incorporazioni pre-addestrate e quelle apprese dal nostro modello di traduzione automatica.</abstract_it>
      <abstract_lt>Kadangi kalbų modeliai vis labiau naudojami realiame pasaulyje, labai svarbu spręsti jų rezultatų teisingumo klausimą. Šių kalbų modelių įtraukimo žodis dažnai netiesiogiai apibūdina nepageidaujamas asociacijas, kurios modelyje sudaro socialinę pusiausvyrą. Lyčių kalbų, kaip antai Hindi, pobūdis kelia papildomą problem ą kiekybiškai įvertinant ir mažinant pusiausvyrą dėl to, kad pasikeitė sakinyje esančių žodžių forma, atsižvelgiant į temos lytį. Be to, nedidelis darbas atliekamas Indijos kalbų matavimo ir debisavimo sistemų srityje. Mūsų darbe bandome įvertinti ir kiekybiškai įvertinti lyčių pusiausvyrą Hindi ir anglų vertimo mašinomis sistemoje. Įgyvendiname modifikuotą esamos TGBI metrijos versiją, pagrįstą gramatiniais Hindi svarstymais. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</abstract_lt>
      <abstract_kk>Тіл үлгілері дұрыс әлемдегі өзгертілген болса, олардың шығаруларының дұрыстығын өзгерту үшін маңызды. Бұл тіл үлгілерін ендіру сөзі үлгісінің ішінде әлеуметтік тәртіпсіздігін көрсетеді. Хинди секілді гендер тілдерінің қасиеті, тақырыбының гендеріне негізделген сөздерді өзгерту үшін көбірек мәселелерді көшірмелеу және көшірмелеу үшін қосымша мәселе береді. Қосымша, индикалық тілдер үшін өлшемі және дебияциялау жүйелерінде көп жұмыс істейді. Біздің жұмысымызда, хиндық-ағылшын тілінің аудару жүйесінде гендердің қарсылығын бағалау және есептеп көреміз. Біз Хинди үшін грамматикалық түсініктеріне негізделген TGBI метрикалық нұсқасының өзгертілген нұсқасын іске асырамыз. Мұндай-ақ біз бірнеше метрикалық мөлшерлерді алдын- ала оқылған ендіру үшін және компьютердің аудару үлгісімен үйренгендерді салыстырып қарсыз.</abstract_kk>
      <abstract_ms>Dengan model bahasa digunakan semakin banyak di dunia nyata, penting untuk mengatasi isu keadilan output mereka. Perkataan menggabungkan perwakilan bagi model bahasa ini sering secara implicit melukis asosiasi tidak diinginkan yang membentuk bias sosial dalam model. Sifat bahasa jenis seperti Hindi, menghasilkan masalah tambahan untuk kuantifikasi dan mengurangi bias, disebabkan perubahan dalam bentuk perkataan dalam kalimat, berdasarkan jenis subjek. Additionally, there is sparse work done in the realm of measuring and debiasing systems for Indic languages.  Dalam kerja kami, kami cuba untuk menilai dan kuantifikasi bias jenis dalam sistem terjemahan mesin Hindi-Inggeris. Kami melaksanakan versi diubahsuai metrik TGBI yang wujud berdasarkan pertimbangan grammatik untuk Hindi. Kita juga membandingkan dan mengembangkan pengukuran bias yang berkaitan melalui metrik berbilang untuk embedding yang dilatih-dilatih dan yang dipelajari oleh model terjemahan mesin kita.</abstract_ms>
      <abstract_mk>With language models being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs.  Зборот кој ги вклучува претставувањата на овие јазички модели честопати имплицитно црта нежелни асоцијации кои формираат социјална предрасуда во рамките на моделот. Природата на половите јазици како Хинди претставува дополнителен проблем во квантификацијата и намалувањето на предрасудите, поради промената на формата на зборовите во реченицата, базирана на полот на темата. Покрај тоа, има ретка работа во областа на системите за мерење и дебизација на индиските јазици. Во нашата работа, се обидуваме да ја процениме и квантификуваме гендерската пристрасност во системот на хинди-англиски машински превод. Ние имплементираме модифицирана верзија на постојната метрика TGBI базирана на граматичките размислувања за Хинди. Ние, исто така, ги споредуваме и контрастираме резултатите на мерките на предрасудените предрасудени медиуми и оние што ги научивме од нашиот модел на машински превод.</abstract_mk>
      <abstract_no>Med språk-modeller som vert utført økt i verden, er det nødvendig å handtere problemet om rettigheten av utdata sine. Ordet som innebygger representasjonar av desse språk-modelane, ofte teiknar ugyldige tilknytingar som formar ein sosialt forsikt i modellen. Naturen av følgjande språk som Hindi, legger eit ekstra problem til kvantifikasjonen og minning av følgjande, ved grunn av endringen i form av ord i setninga, basert på seksen på emnet. I tillegg er det sparke arbeid gjort i området av målsystemet og debiasing for indiske språk. I arbeidet vårt prøver vi å evaluera og kvantifika seks-forsikta i eit hindisk-engelsk maskinsomsetjingssystem. Vi implementerer ein endra versjon av den eksisterande TGBI-metriske, basert på dei grammatiske uttrykkene for Hindi. Vi sammenliknar også og kontrast resultatet forskyvingsmålingane over fleire metrikar for føretrainerte innbygging og dei som lærte av maskineoversettelsmodellen vår.</abstract_no>
      <abstract_mn>Үнэндээ хэл загваруудыг бодит ертөнцөд нэмэгдүүлж байгаагаар тэдний үр дүнтэй байдлын асуудлыг асуух нь чухал. Эдгээр хэл загваруудын илтгэлүүдийг бий болгодог үг нь загварын дотор нийгмийн алдартай байдлыг бий болгодоггүй холбоотой. Хинди шиг гендер хэлнүүдийн байр сургуулийн гендер гэдэг үгийг өөрчлөхөд, сэдвийн гендер дээр үндсэн гэсэн үгийг хэмжээгээр тооцоолж, багасгах боломжтой асуудал болгодог. Түүнчлэн Индийн хэлний хэлний хэлний хэмжээсүүдийн хэмжээсүүд болон хэмжээсүүдийг хэмжээсүүд дээр ажилладаг. Бид ажлын хувьд Хинди-Англи хэлний хөрөнгө оруулах системээс гендерийн тухай тооцоолох, тооцоолох гэж оролдож байна. Бид Хиндийн грамматикийн санаанд суурилсан TGBI метрийн өөрчлөгдсөн хувилбарыг хийдэг. Мөн бид машин орчуулах загвараар сурсан хүмүүсийг олон метр дахь ойлголтын хэмжээсүүдийг харьцуулж, эсрэг харьцуулж байна.</abstract_mn>
      <abstract_mt>Billi l-mudelli lingwistiċi qed jintużaw dejjem aktar fid-dinja reali, huwa essenzjali li tiġi indirizzata l-kwistjoni tal-ġustizzja tar-riżultati tagħhom. Il-kelma li tinkludi rappreżentazzjonijiet ta’ dawn il-mudelli lingwistiċi ta’ spiss b’mod impliċitu tiġbor assoċjazzjonijiet mhux mixtieqa li jiffurmaw preġudizzju soċjali fi ħdan il-mudell. In-natura tal-lingwi sesswali bħall-Indjan, to ħloq problema addizzjonali għall-kwantifikazzjoni u l-mitigazzjoni tal-preġudizzju, minħabba l-bidla fil-forma tal-kliem fis-sentenza, ibbażata fuq is-sess tas-suġġett. Barra minn hekk, hemm ftit xogħol li jsir fil-qasam tas-sistemi tal-kejl u d-debizzar għall-lingwi Indjani. Fil-ħidma tagħna, nippruvaw jivvalutaw u nikkwantifikaw il-preġudizzju bejn is-sessi fi ħdan sistema ta’ traduzzjoni tal-magni Indjan-Ingliż. Aħna nimplimentaw verżjoni modifikata tal-metrika eżistenti tat-TGBI bbażata fuq il-kunsiderazzjonijiet grammatiċi għall-Indjan. Aħna nqabblu u nikkuntrastaw ukoll il-kejl tal-pre ġudizzju li jirriżulta minn diversi metriċi għall-inkorporazzjonijiet imħarrġa minn qabel u dawk imgħallma mill-mudell tagħna tat-traduzzjoni bil-magna.</abstract_mt>
      <abstract_pl>Ponieważ modele językowe są coraz częściej wdrażane w świecie rzeczywistym, konieczne jest zajęcie się kwestią sprawiedliwości ich wyników. Słowo osadzające reprezentacje tych modeli językowych często domyślnie rysuje niechciane skojarzenia, które tworzą uprzedzenia społeczne w modelu. Charakter języków płciowych, takich jak hindi, stanowi dodatkowy problem do ilościowego określenia i łagodzenia uprzedzeń, ze względu na zmianę formy słów w zdaniu, w oparciu o płeć podmiotu. Dodatkowo wykonywana jest rzadka praca w zakresie systemów pomiaru i debiating dla języków indyjskich. W naszej pracy staramy się ocenić i kwantyfikować uprzedzenia płci w ramach hindi-angielskiego systemu tłumaczenia maszynowego. Wdrażamy zmodyfikowaną wersję istniejącej metryki TGBI w oparciu o rozważania gramatyczne dla hindi. Porównujemy również i kontrastujemy wynikowe pomiary biasu w wielu wskaźnikach dla wstępnie przeszkolonych osadzeń i tych, których nauczyliśmy się w naszym modelu tłumaczenia maszynowego.</abstract_pl>
      <abstract_ml>യഥാര്‍ത്ഥ ലോകത്തില്‍ ഭാഷ മോഡലുകള്‍ കൂടുതല്‍ പ്രസ്താവിക്കപ്പെടുന്നത് കൊണ്ട്, അവരുടെ പുറത്തുള്ള നീതിയുടെ കാര്യത്തെപ ഈ ഭാഷ മോഡലുകളുടെ പ്രതിനിധികള്‍ ഉള്‍പ്പെടുത്തുന്ന വാക്ക് മാതൃകയില്‍ ഒരു സാമൂഹ്യത്തിന്റെ പ്രതിനിധികള്‍ ഉണ്ടാക്ക ഹിന്ദിയെപ്പോലെയുള്ള ഭാഷകളുടെ സ്വഭാവം കൂടുതല്‍ കൂടുതല്‍ പ്രശ്നമാണ്, വിഷയത്തിന്റെ വാക്കുകളുടെ രീതിയില്‍ മാറ്റം വരുത്തിയതിനാല്‍, വിഷയത്തിന കൂടാതെ, ഇന്ത്യഭാഷകള്‍ക്ക് അളക്കുന്നതിനും ഡിബിയസിസ്റ്റം സിസ്റ്റമുണ്ടാക്കുന്നതിന്റെ രാജ്യത്തില്‍ ചെറു ഞങ്ങളുടെ ജോലിയില്‍, ഞങ്ങള്‍ ഹിന്ദി-ഇംഗ്ലീഷ് യന്ത്രത്തിന്റെ പരിഭാഷണ സിസ്റ്റത്തില്‍ പെണ്‍കുട്ടികളുടെ കൂട്ടത്തെ  നിലവിലുള്ള ടിജിബിഐ മെറ്റിക്കിന്റെ ഒരു മാറ്റം നാം പ്രവര്‍ത്തിപ്പിക്കുന്നു. നമ്മള്‍ ഒരുപാട് മെറ്റിക്കുകള്‍ക്ക് മുമ്പ് പരിശീലിക്കപ്പെടുന്ന അളവുകള്‍ക്ക് വേണ്ടിയും, നമ്മുടെ യന്ത്രത്തിന്‍റെ പരിഭാഷണമായ മ</abstract_ml>
      <abstract_sr>Kada se jezički modeli uvećavaju u stvarnom svijetu, važno je riješiti pitanje poštenosti njihovih ishoda. Riječ uključujući predstave ovih jezičkih model a često implicitno crtaju neoželjene asocijacije koje formiraju društvenu predrasude unutar modela. Priroda spolnih jezika kao što su Hindi, predstavlja dodatni problem kvantifikaciji i smanjenju pristrasnosti, zbog promjene reči u obliku reči rečenice, na osnovu spola teme. Osim toga, u regiji mjerenja i debijacije sistema indijskih jezika radi rezervni rad. U našem poslu pokušavamo procijeniti i kvantificirati spolne predrasude u sistemu prevođenja hindskih-engleskih mašina. Mi implementiramo modificiranu verziju postojeće TGBI metrike na osnovu gramatičnih razmišljanja za hinde. Takođe uspoređujemo i kontrastiramo rezultate mjerenja predrasude preko višestruke metrike za predobučene integracije i one koje su naučili naš model prevoda mašine.</abstract_sr>
      <abstract_ro>Având în vedere că modelele lingvistice sunt implementate din ce în ce mai mult în lumea reală, este esențial să se abordeze problema corectitudinii rezultatelor acestora. Cuvântul încorporare reprezentări ale acestor modele lingvistice deseori desenează implicit asociații nedorite care formează o părtinire socială în cadrul modelului. Natura limbilor de gen precum hindi, reprezintă o problemă suplimentară la cuantificarea și atenuarea prejudecăților, datorită schimbării formei cuvintelor din propoziție, în funcție de genul subiectului. În plus, există o muncă rară făcută în domeniul sistemelor de măsurare și debiasing pentru limbile indice. În activitatea noastră, încercăm să evaluăm și să cuantificăm părtinirea genului într-un sistem de traducere automată hindi-engleză. Implementăm o versiune modificată a metricei TGBI existente pe baza considerațiilor gramaticale pentru hindi. De asemenea, comparăm și contrastăm măsurătorile de părtinire rezultate în mai multe măsurători pentru încorporările pre-instruite și cele învățate de modelul nostru de traducere automată.</abstract_ro>
      <abstract_si>භාෂාව මොඩේල් එක්ක ඇත්ත ලෝකයේ වැඩියෙන් වැඩියි, ඒක අවශ්‍ය වෙනවා ඔවුන්ගේ ප්‍රතිචාර ප්‍රශ්නය ගැන ප්‍රශ මේ භාෂා මෝඩේල්ගේ සංවිධානයක් සාමාජික සංවිධානයක් සංවිධානය කරනවා නැති අවශ්‍ය සම්බන්ධයක්  හින්දි වගේ ස්වභාවිතයේ ස්වභාවිතය, ප්‍රශ්නයක් තියෙනවා ක්වාන්තිකාරණය සහ ප්‍රශ්නයක්, වචනයේ වර්තනයේ වෙනස් වෙනුවෙන්, විදියට තවත් ඉන්දික භාෂාවලට පද්ධතිය පද්ධතියක් විශේෂ කරලා තියෙනවා. අපේ වැඩේ අපි උත්සාහ කරනවා හින්දී ඉංග්‍රීසි යන්ත්‍ර පද්ධතියේ ජීවිත විශ්වාස ස්ථානයක් ගැන විශ්වාස අපි හින්දි වෙනුවෙන් තියෙන්න තියෙන්න තියෙන්නෙ TGBI මෙට්‍රික් එකේ වෙනස් වෙනුවෙන් සංවිධානයක් අව අපි ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් වෙනුවෙන් ප්‍රශ්නයක් වෙනුව</abstract_si>
      <abstract_ta>With language models being deployed increasingly in the real world, it is essential to address the issue of the fairness of their outputs.  இந்த மொழி மாதிரிகளின் குறிப்பிட்ட சொல்லை பெரும்பாலும் தேவையில்லாத இணைப்புகளை வரையும் மாதிரியில் ஒரு சமூக Hindi போன்ற இனந்திர மொழிகளின் இயல்பு, பொருளின் இனம் அடிப்படையிலான வார்த்தைகளின் வடிவமைப்பு மாற்றத்திற்காக கூடுதல் பிரச்சனைக்கு கொடுக்கு கூடுதலாக, சிந்திக் மொழிகளுக்கான அளவு மற்றும் பிழைதாக்கும் அமைப்புகளில் சிறிய வேலை செய்யப்பட்டுள்ளது. எங்கள் வேலையில், நாங்கள் ஒரு ஹின்டி- ஆங்கிலத்தின் மொழிபெயர்ப்பு அமைப்பில் பெண்கள் குறிப்பிட முயற்சி மற்றும் அளவ நாம் நடப்பு TGBI மெட்ரிக்கின் மாற்றப்பட்ட பதிப்பை செயல்படுத்துகிறோம் இந்தியின் வரைப்படை கருத்துகளை அடிப்படையி முன் பயிற்சி மொழிபெயர்ப்பு முறைமையால் கற்றுக் கொண்டிருக்கும் பல மெட்ரிக்குகள் மூலம் முடிவுகளை ஒப்பிடுக்க மற்றும் ம</abstract_ta>
      <abstract_so>Dunida runta ah waxaa muhiim ah in la sheekeysto arimaha caddaaladda soo baxa. Ereyga ku yaala noocyada luuqadahan inta badan waxay u soo dhashaan ururo aan loo baahnayn, kaas oo sameynaya qaababka bulshada. Luqadaha jinsiga ah sida Hindi waxay leedahay dhibaato dheer oo ku saabsan qiyaasta iyo qiyaasta galmada, sababtoo ah beddelka qaabka erayada ku qoran hadalka, iyadoo ku saleysan jinsiga mada. Sidoo kale waxaa boqortooyada ku jira shaqo yar oo ku saabsan qiyaasta iyo cadaadinta nidaamka afka Indiga ah. Shaqadeena waxaan isku daynaa inaannu qiimeynayno oo qiimeynaynaa hababka jinsiga ee ku jira nidaamka turjumista machine-Ingiriis. Waxaynu sameeynaa warqad beddelan oo ku qoran TGBI oo ku saleysan fiirsashada grammatika ee Hindi. Sidoo kale waxaynu isbarbardhignaa oo kala duwan nahay qiyaastii waxyaabaha ka soo baxay oo kala duduwan metriciyada, taasoo lagu bartay qaababka turjumista machineenna.</abstract_so>
      <abstract_ur>زبان مدلکوں کے ساتھ حقیقی دنیا میں زیادہ اضافہ کئے جاتے ہیں، ان کے نتائج عدالت کے مسئلہ کے بارے میں ضرورت ہے. یہ زبان مدلکوں کے معاملات میں داخل ہونے والی لکھی ہوئی لکھی ہے کہ اکثر غیر خواہشوں کی اتحادیوں کو ڈھانک رہی ہیں جو مدل کے اندر ایک سوسیال اتحادیہ بناتے ہیں۔ ہندی کی طرح جنس کی زبانوں کی تعریف، اس کے جنس پر زیادہ مسئلہ ہے کہ کلمات کی صورت بدلنے کی وجہ سے، کلمات کی تعریف اور ذلت کے ذریعہ، اس کے جنس پر بنیاد ہے. اور اضافہ بھی، انڈی زبانوں کے لئے اندازے اور ڈبی سیستموں کے ملک میں کم کام کیا جاتا ہے۔ ہمارے کام میں، ہم ایک ہندی-انگلیسی ماشین ترجمہ سیسٹم کے اندر جنس کی مخالفت کا ارزش اور مقدار کرنے کی کوشش کرتے ہیں. ہم ہندی کے لئے گراماتیکی نظریات پر بنیاد رکھتے ہیں جو موجود TGBI متریک کی ایک بدل ہوئی نسخہ پر قائم کرتے ہیں. ہم نے اس کے نتیجے کے اندازے کئی متریک کے درمیان ایک دوسرے کی مطابق مقایسہ کر دیے ہیں اور ان کا مقایسہ کر دیا ہے جو ہمارے ماشین ترجمہ موڈل سے سکھائے گئے ہیں۔</abstract_ur>
      <abstract_sv>Eftersom språkmodeller används alltmer i verkligheten är det viktigt att ta itu med frågan om rättvisa resultat. Ordet inbäddande representationer av dessa språkmodeller drar ofta implicit oönskade associationer som bildar en social bias inom modellen. Arten av könade språk som hindi utgör ytterligare ett problem vid kvantifiering och begränsning av bias, på grund av förändringen i formen av orden i meningen, baserat på ämnets kön. Dessutom görs det glest arbete inom mät- och debiasing-system för indiska språk. I vårt arbete försöker vi utvärdera och kvantifiera könsfördelningen inom ett hindi-engelskt maskinöversättningssystem. Vi implementerar en modifierad version av det befintliga TGBI-mätvärdet baserat på grammatiska överväganden för hindi. Vi jämför och kontrasterar också de resulterande bias mätningarna över flera mätvärden för förinställda inbäddningar och de som lärts av vår maskinöversättningsmodell.</abstract_sv>
      <abstract_vi>Khi các mô hình ngôn ngữ được triển khai ngày càng nhiều trong thế giới thực, cần phải giải quyết vấn đề về sự công bằng kết xuất chúng. Từ chứa các biểu tượng của các mô hình ngôn ngữ này thường ngấm ngầm thu hút các liên quan không mong muốn tạo thành thiên hướng xã hội trong mô hình. Tính chất của ngôn ngữ giới tính như Hindi, tạo thêm rắc rối cho việc phân tích và giảm bớt khuynh hướng, do sự thay đổi hình dạng từ trong câu, dựa trên giới tính của chủ đề. Thêm vào đó, có rất ít việc làm trong lĩnh vực đo lường và thao túng hệ thống ngôn ngữ Ấn Độ. Trong công việc của chúng tôi, chúng tôi cố gắng đánh giá và xác định khuynh hướng giới tính trong hệ thống dịch chuyển máy tiếng Ấn. Chúng tôi áp dụng một phiên bản đã sửa đổi về định dạng TGBI hiện tại dựa trên tính toán theo tiếng Hindi. Chúng tôi cũng so sánh và chống lại những tất cả số đó bằng đại âm lượng cho sự giảm cấp được chuẩn bị trước và những cái mà được biết được từ cá</abstract_vi>
      <abstract_uz>Tilning modellari dunyoda ko'proq o'zlashtirilganligi bilan, ularning natijalarining haqida murakkablarini ajratish muhim. Ushbu tillar modellarining representarini ko'paytirish so'z modelidagi jamiyatlarni o'zgartirish imkoniyatlarni o'zgartiradi. The nature of gendered languages like Hindi, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject.  Ko'pchilik, Hindik tillarining o'lchamini oʻzgartirish va deb hisoblash tizimi davrida ishlaydi. Biz ishimizda, Hindi- Ingliz mashina tarjima tizimida jinsiyalarni qiymatlashni va qiymatlashni harakat qilamiz. Biz Hindi uchun grammatikal qiymatlar asosida mavjud TGBI metrik versiyasini bajaramiz. Biz bir necha metrik orqali bir necha o'rganishdan o'xshash va biz mashinamiz tarjima modeli bilan o'rganishlar bilan bir necha metriklarga kamaytirish va bir necha metriklarga qisqaramiz.</abstract_uz>
      <abstract_bg>Тъй като езиковите модели се използват все по-често в реалния свят, от съществено значение е въпросът за справедливостта на техните резултати. Думата, включваща изображения на тези езикови модели, често имплицитно привлича нежелани асоциации, които формират социално пристрастие в модела. Естеството на половите езици като хинди, поставя допълнителен проблем за количественото определяне и смекчаване на пристрастията, поради промяната във формата на думите в изречението, въз основа на пола на субекта. Освен това има рядка работа в областта на измервателните и дебиазиращите системи за индийски езици. В нашата работа се опитваме да оценим и количествено предразсъдъка между половете в хинди-английската система за машинен превод. Ние внедряваме модифицирана версия на съществуващата метрика базирана на граматическите съображения за хинди. Също така сравняваме и контрастираме получените измервания на отклонения в множество показатели за предварително обучени вграждания и тези, научени от нашия модел за машинен превод.</abstract_bg>
      <abstract_hr>Pošto se jezički modeli uvećavaju u stvarnom svijetu, važno je riješiti pitanje pravednosti njihovih ishoda. Riječ uključujući predstavljanja ovih jezičkih model a često implicitno crtaju neočekivane asocijacije koje formiraju društvene predrasude unutar modela. Priroda spolnih jezika poput Hindija predstavlja dodatni problem kvantifikaciji i smanjenju pristrasnosti, zbog promjene u obliku riječi u rečenici, temeljene na spolu teme. Osim toga, u regiji mjerenja i debijacije sustava indijskih jezika radi rezervni rad. U našem poslu pokušavamo procijeniti i kvantificirati spolne predrasude u sustavu prevoda hindskih-engleskih strojeva. Mi provodimo modificiranu verziju postojeće metričke TGBI-e na temelju gramatičkih razmišljanja za hinde. Također uspoređujemo i suprotstavljamo rezultate mjerenja pristrasnosti preko višestruke metrike za predobučene integracije i one koje su naučili našim modelom prevoda stroja.</abstract_hr>
      <abstract_nl>Nu taalmodellen steeds vaker worden ingezet in de echte wereld, is het van essentieel belang dat de kwestie van de eerlijkheid van hun output wordt aangepakt. Het woord inbeddende representaties van deze taalmodellen trekken vaak impliciet ongewenste associaties die een sociale vooroordeel vormen binnen het model. De aard van geslachtstalen, zoals Hindi, vormt een extra probleem voor de kwantificering en beperking van vooroordelen, als gevolg van de verandering in de vorm van de woorden in de zin, gebaseerd op het geslacht van het onderwerp. Daarnaast wordt er weinig werk gedaan op het gebied van het meten en debiaseren van systemen voor Indische talen. In ons werk proberen we de gender bias binnen een Hindi-Engels machinevertaalsysteem te evalueren en kwantificeren. We implementeren een aangepaste versie van de bestaande TGBI metric gebaseerd op de grammaticale overwegingen voor Hindi. We vergelijken en contrasteren ook de resulterende bias metingen met meerdere metrics voor vooraf getrainde embeddings en die welke door ons machine translation model zijn geleerd.</abstract_nl>
      <abstract_da>I takt med, at sprogmodeller i stigende grad anvendes i den virkelige verden, er det vigtigt at tage fat på spørgsmålet om retfærdigheden af deres resultater. Ordet integrering repræsentationer af disse sprogmodeller tegner ofte implicit uønskede associationer, der danner en social bias inden for modellen. Karakteren af kønssprog som hindi, udgør et yderligere problem til kvantificering og afbødning af bias, på grund af ændringen i form af ordene i sætningen, baseret på emnets køn. Derudover er der sparsomt arbejde udført inden for måling og debiasing systemer til indiske sprog. I vores arbejde forsøger vi at evaluere og kvantificere kønsfordelene i et hindi-engelsk maskinoversættelsessystem. Vi implementerer en modificeret version af den eksisterende TGBI metric baseret på grammatiske overvejelser for hindi. Vi sammenligner og kontrasterer også de resulterende bias målinger på tværs af flere målinger for præ-trænede indlejringer og dem, der læres af vores maskinoversættelsesmodel.</abstract_da>
      <abstract_id>Dengan model bahasa yang semakin dieksploitasi di dunia nyata, penting untuk mengatasi masalah keadilan dari hasil mereka. Kata yang menggabungkan representation dari model bahasa ini sering secara implicit menggambar asosiasi tidak diinginkan yang membentuk bias sosial dalam model. Alam bahasa jenis seperti Hindi, menghasilkan masalah tambahan untuk kuantifikasi dan mengurangi bias, karena perubahan dalam bentuk kata-kata dalam kalimat, berdasarkan jenis subjek. Selain itu, ada sedikit pekerjaan yang dilakukan dalam bidang pengukuran dan debiasing sistem untuk bahasa India. Dalam pekerjaan kami, kami mencoba untuk mengevaluasi dan kuantifikasi bias jenis dalam sistem terjemahan mesin Hindi-Inggris. Kami menerapkan versi modifikasi dari metrik TGBI yang ada berdasarkan pertimbangan grammatik untuk Hindi. Kami juga membandingkan dan mengembangkan pengukuran bias yang berasal dari berbagai metrik untuk embedding-embedding terlatih-terlatih dan yang belajar dari model terjemahan mesin kami.</abstract_id>
      <abstract_ko>언어 모델이 현실 세계에서 점점 더 많이 응용됨에 따라 수출의 공평성 문제를 해결하는 것이 매우 중요하다.이러한 언어 모델의 단어 삽입은 일반적으로 불필요한 연상을 내포하여 모델에 사회적 편견을 형성한다는 것을 나타낸다.인디언과 같은 성별 언어의 성질은 편견의 양적화와 완화에 또 다른 문제를 가져왔다. 문장의 단어 형식은 주제의 성별에 따라 달라지기 때문이다.이 밖에 인도어의 측량과 차용 시스템 분야에서 이런 일을 한 사람은 드물다.우리의 업무에서, 우리는 인디언 - 영어 기계 번역 시스템의 성별 편견을 평가하고 계량화하려고 한다.인디언의 문법적 고려를 바탕으로 우리는 기존 TGBI 도량의 수정 버전을 실현하였다.우리는 또한 예비훈련 삽입과 기계번역모델 학습의 여러 지표의 편차 측정 결과를 비교하고 비교했다.</abstract_ko>
      <abstract_de>Da Sprachmodelle zunehmend in der realen Welt eingesetzt werden, ist es unerlässlich, das Problem der Fairness ihrer Ergebnisse anzugehen. Das Wort Einbettung von Repräsentationen dieser Sprachmodelle zieht oft implizit unerwünschte Assoziationen, die eine soziale Voreingenommenheit innerhalb des Modells bilden. Die Natur geschlechtsspezifischer Sprachen wie Hindi stellt ein zusätzliches Problem zur Quantifizierung und Minderung von Voreingenommenheiten dar, da sich die Wörter im Satz aufgrund des Geschlechts des Subjekts ändern. Darüber hinaus gibt es wenig Arbeit im Bereich der Mess- und Debiasing-Systeme für indische Sprachen. In unserer Arbeit versuchen wir, den Gender Bias innerhalb eines Hindi-Englischen maschinellen Übersetzungssystems zu bewerten und zu quantifizieren. Wir implementieren eine modifizierte Version der bestehenden TGBI-Metrik basierend auf den grammatischen Überlegungen für Hindi. Wir vergleichen und kontrastieren auch die resultierenden Bias-Messungen über mehrere Metriken für vorgetrainierte Einbettungen und diejenigen, die von unserem maschinellen Übersetzungsmodell gelernt wurden.</abstract_de>
      <abstract_fa>با مدلهای زبانی که در دنیای واقعی بیشتر از حد افزایش می‌شود، مسئله عدالت نتیجه‌هایشان را حل کردن ضروری است. کلمه‌ای که نمایش‌های این مدل‌های زبان‌ها را جمع می‌کند، اغلب به طور اغلب شرکت‌های ناخواسته‌ای را می‌کشند که در مدل یک طبق اجتماعی وجود دارند. طبیعت زبانهای جنسی مانند هندی، مشکل اضافی برای تعیین و کاهش کردن تعادل را به دلیل تغییر شکل کلمات در جمله، بر اساس جنسی موضوع قرار می دهد. به اضافه، کار کمی در سلطنتی از سیستم اندازه‌گیری و اندازه‌گیری برای زبانهای هندی انجام می‌شود. در کار ما، تلاش می کنیم که در یک سیستم ترجمه ماشین هندی-انگلیسی ارزیابی و تعداد جنسی را ارزیابی کنیم. ما یک نسخه تغییر داده شده از متریک TGBI موجود را بر اساس توجه گراماتیک برای هندی انجام می دهیم. ما همچنین اندازه‌هایی که نتیجه داده می‌شود را در متریک‌های چندین مقایسه می‌کنیم و تفاوت می‌کنیم برای اندازه‌هایی که پیش آموزش داده شده‌اند و آنها که توسط مدل ترجمه ماشین یاد گرفته‌اند.</abstract_fa>
      <abstract_sw>Kwa kutumia mifano ya lugha inayotumiwa kwa kiasi kikubwa katika dunia halisi, ni muhimu kukabiliana na suala la haki za matokeo yao. Neno linalohusisha maonesho ya mifano ya lugha hizi mara nyingi huvuta mashirika yasiyotarajiwa yanayotengeneza upendeleo wa kijamii ndani ya mtindo huo. Utawala wa lugha za kijinsia kama Hindi, unaleta tatizo la ziada la kutambua na kuchunguzwa kwa upendeleo, kwa sababu ya mabadiliko ya namna ya maneno katika hukumu hiyo, kwa kutumia jinsia ya mada. Kwa nyongeza, kuna kazi kidogo inayofanya katika ufalme wa kupima na kuharibu mifumo ya lugha za Kihindi. Katika kazi yetu, tunajaribu kutathmini na kuhakikisha upendeleo wa kijinsia katika mfumo wa kutafsiri mashine ya Kiingereza. Tunatumia toleo lililobadilishwa kwa mtiririko wa TGBI ulioendelea kwa kutumia mtazamo wa takwimu wa Kihindi. Pia tunalinganisha na tofauti na hatua za upendeleo zinazotokana na mifano mbalimbali kwa ajili ya vifaa vya mafunzo vilivyojifunza na mifano ya kutafsiri mashine yetu.</abstract_sw>
      <abstract_sq>Me modelet gjuhësore që janë vendosur gjithnjë e më shumë në botën reale, është thelbësore të trajtohet çështja e drejtësisë së rezultateve të tyre. Fjala që përfaqëson përfaqësimet e këtyre modeleve gjuhësore shpesh përfshirë shoqata të padëshiruara që formojnë një paragjykim shoqëror brenda modelit. Natyra e gjuhëve gjinore si Hindi, paraqet një problem shtesë për kuantifikimin dhe lehtësimin e paragjykimit, për shkak të ndryshimit në form ën e fjalëve në fjalë, bazuar në gjinin e subjektit. Përveç kësaj, është bërë punë e paktë në fushën e sistemeve të matjes dhe debizimit për gjuhët indike. Në punën tonë, ne përpiqemi të vlerësojmë dhe kuantifikojmë paragjykimin e gjinisë brenda një sistemi përkthimi makineri Hindi-Anglisht. Ne zbatojmë një version të modifikuar të metrikës ekzistuese TGBI bazuar në konsideratat grammatike për Hindi. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</abstract_sq>
      <abstract_af>Met die taal modele wat in die werklike wêreld vergroot word, is dit noodsaaklik om die probleem van die regverdigheid van hulle uitvoerdes te raak. Die woord wat ingesluit verteenwoordes van hierdie taal modele dikwels inplisite onverwagte asosiasies teken wat 'n sosiale voorbeeld in die model vorm. Die natuur van geneemde tale soos Hindi, stel 'n addisionele probleem aan die kvantifikasie en vermindering van voorspoedige, omdat die verandering in die vorm van die woorde in die seting gebaseer is, op die geneem van die onderwerp. In addition, there is sparse work done in the realm of measuring and debiasing systems for Indic languages. In ons werk probeer ons om die seunsbias binne 'n Hindi-Engels masjien vertaling stelsel te evalueer en quantifiseer. Ons implementeer 'n veranderde weergawe van die bestaande TGBI metriese gebaseer op die grammatiese oordelings vir Hindi. Ons vergelyk en kontras die resultateerde bias-measurements deur veelvuldige metries vir voorafgevorderde inbêdings en die wat deur ons masjien-vertaling model geleer het.</abstract_af>
      <abstract_tr>Dil nusgalary hakyky d체n첵채de k철p b철l체n첵채n 첵agda첵da, netijelerini흫 adalatlygyny 챌철zmek gerek. Bu dil nusgalaryny흫 i챌inde k철p체r채k isleme첵채n guramlary nusgalary nusgasynda 챌ykar첵ar. Hindi 첵aly jens dillerini흫 tebigaty, s철zleri흫 jentillerine da첵an 첵an s철zlerini흫 체첵tgediligine g철r채 bir mesele bar. Di흫e indiki diller 체챌in 철l챌체leme we 챌철zg체leme sistemlerinde k체챌체k i힊 bar. Bizi흫 i힊imizde, jentiller guralygyny Hindi-i흫lis챌e ma힊yny흫 terjime sistemasynda de흫lemek we 챌ykarmak synany힊첵arys. Biz Hindiler 체챌in gramatik pikirlerine dayanan bolan TGBI metriklerinin 체첵tgedilmi힊 bir wersi첵any implement etdik. Ayr캇ca, bu sonu챌 철n체nde e휓lenen i챌eri ve makinelerimizin 챌evirilmesi modellerinden 철휓rendikleri bias 철l챌체mlerini 챌oklu metrik aras캇nda kar힊캇la힊t캇r캇p kar힊캇la힊t캇r캇yoruz.</abstract_tr>
      <abstract_az>Dil modelləri həqiqi dünyada daha çox yayılan kimi, çətinliklərinin ədalətini çəkmək məqsədilə vacibdir. Bu dil modellərin göstərilmələri çox sıxıntılı olaraq istəməmiş bağlantıları modellərin içində sosyal tərzlərini yaradan şəkildə çizdirirlər. Hindi kimi cinsel dillərin təbiəti, məsələnin cinsi üzərində olan sözlərin dəyişikliklərinə görə, küçük-küçük və azaltmasına görə daha çox problemi var. Əksinə, Indik dillərin ölçü və debiasing sistemlərinin səltənətində çox az işlər var. Bizim işimizdə, Hindi-İngilizce maşına çeviriş sistemində cins bias ını değerləşdirmək və quantifik etmək istəyirik. Biz Hindistan üçün gramatik düşüncələrinə dayanan TGBI metriklərinin dəyişdirilmiş bir versiyonu təyin edirik. Biz həmçinin müxtəlif metriklərdən öyrənib öyrəndiyimiz məlumatları və maşın çevirim modeli ilə öyrəndiyimiz məlumatları ilə birləşdiririk.</abstract_az>
      <abstract_am>የቋንቋ ምሳሌዎች በመጀመሪያው ዓለምን ላይ የሚወስዱ ሲሆኑ የውጤታቸውን የውጤት ውጤት ለመቀበል ያስፈልጋል፡፡ The word embedding representations of these language models often implicitly draw unwanted associations that form a social bias within the model.  የዓይነ ቋንቋዎች ምሳሌ እንደ ኪንዲ፣ የውይይት ቋንቋዎች በሥርዓት ውይይት የተደረገ የውይይት ግንኙነትን በማሰናከል እና ማሰናከል ነው፡፡ በተጨማሪም፣ የህንድ ቋንቋዎች ስብስብስብና የሚያሳፍር ስርዓቶች በመንግሥት ውስጥ ጥቂት ሥራ ይሠራል፡፡ በሥራችን የሴቶችን ብሔራዊ ግንኙነት በHindi-እንግሊዝኛ መተርጓሜ ስርዓት ውስጥ ለማስተካከል እናሳውቃለን፡፡ የአሁኑ የTGBI ሜትሪክ በHindi ላይ የግራማዊ አስተያየት በመሠረት ላይ የተለወጠውን ክፍል እናደርጋለን፡፡ እና የፍጥረቱን የውጤት መስኮት በብዙ ሜትሪኮች ላይ እናስተካከላለን እናተካክላታለን እና የመሳኪያውን ትርጉም ሞዴል የተማሩትን እናተካክላለን፡፡</abstract_am>
      <abstract_hy>Երբ լեզվի մոդելները ավելի ու ավելի են օգտագործվում իրական աշխարհում, կարևոր է լուծել նրանց արտադրանքների արդարության խնդիրը: Այս լեզվի մոդելների ներառման բառը հաճախ միանգամայն նկարում է անցանկանալի կապեր, որոնք մոդելի մեջ սոցիալական կողմնականություն են կազմում: Հինդիայի նման սեռական լեզուների բնույթը հանդիսանում է առանձնահատուկ խնդիր կողմնականության քանակությամբ և նվազեցման համար, քանի որ նախադասության բառերի ձևի փոփոխությունը հիմնված է թեմայի սեռի վրա: Ավելին, հազվադեպ աշխատանք կատարվում է ինդիական լեզուների չափման և նվազեցման համակարգերի ոլորտում: Մեր աշխատանքում մենք փորձում ենք գնահատել և չափել գենդերային կողմնականությունը Հինդի-անգլերեն մեքենայի թարգմանման համակարգում: Մենք կիրառում ենք գոյություն ունեցող ԹԳԲԻ մետրիկայի փոփոխված տարբերակը հիմնված Հինդի գրամատիկական հաշվարկների վրա: Մենք նաև համեմատում ենք և հակադրում ենք արդյունքում ստացված կողմնակի չափումները նախապատրաստված ներդրումների և մեքենայի թարգմանման մոդելի միջոցով սովորված չափումների միջև:</abstract_hy>
      <abstract_bs>S obzirom da se jezički modeli uvećavaju u stvarnom svijetu, važno je riješiti pitanje pravednosti njihovih ishoda. Riječ uključujući predstave ovih jezičkih model a često implicitno crtaju neoželjene asocijacije koje formiraju socijalnu predrasude unutar modela. Priroda spolnih jezika kao što su Hindi, predstavlja dodatni problem kvantifikaciji i smanjenju pristrasnosti, zbog promjene u obliku riječi u rečenici, na temelju spola teme. Osim toga, u regiji mjerenja i debijacije sustava indijskih jezika radi rezervni rad. U našem poslu pokušavamo procijeniti i kvantificirati spolne predrasude u sistemu prevoda Hindi-engleskog mašine. Mi implementiramo modificiranu verziju postojeće metričke TGBI na temelju gramatičkih razmišljanja za hinde. Također uspoređujemo i kontrastiramo rezultate mjerenja predrasude preko višestruke metrike za predobučene integracije i one koje su naučili naš model prevoda mašine.</abstract_bs>
      <abstract_bn>পৃথিবীতে ভাষার মডেল বাড়তে থাকার মাধ্যমে তাদের আউটপুটের ন্যায়বিচারের ব্যাপারে কথা বলা গুরুত্বপূর্ণ। এই ভাষার মডেলের প্রতিনিধিত্বের শব্দ প্রায়শই অসন্তুষ্ট সংগঠনের প্রতিনিধিত্ব করে যা মডেলের মধ্যে একটি সামাজিক ব The nature of gendered languages like Hindi, poses an additional problem to the quantification and mitigation of bias, owing to the change in the form of the words in the sentence, based on the gender of the subject.  এছাড়াও ইন্ডিক ভাষার জন্য মাপ এবং বিভ্রান্ত সিস্টেম পরিমাপ এবং বিভ্রান্ত করার সামান্য কাজ করা হয়েছে। আমাদের কাজে আমরা হিন্দি-ইংরেজি মেশিন অনুবাদ ব্যবস্থার মধ্যে যৌন বিভাগের মূল্য এবং পরিমাণের চেষ্টা করছি। আমরা বিদ্যমান টিজিবিআই মেট্রিকের একটি পরিবর্তন সংস্করণ ব্যবস্থা করি হিন্দির জন্য গ্রামাটিক বিবেচনার ভিত্তিতে। আমরা পূর্ব প্রশিক্ষিত প্রবেশের জন্য বিভিন্ন মেট্রিক জুড়ে যাওয়ার ফলাফলের বিরুদ্ধে তুলনা করি এবং তারা আমাদের মেশিন অনুবাদ মডেল দ্</abstract_bn>
      <abstract_ca>Amb que els models de llenguatge es desplegan cada cop més al món real, és essencial abordar el tema de la justesa dels seus productes. La paraula incorporant representacions d'aquests models de llenguatge sovint dibuixa implícitament associacions no desitjades que formen un bias social dins el model. La naturalesa de les llengües de gènere com el Hindi, representa un problema adicional a la quantificació i mitigació del bias, degut al canvi de forma de paraules de la frase, basat en el gènere del tema. A més, hi ha poca feina feta en el sector dels sistemes de mesura i debilitació de les llengües índiques. En la nostra feina intentem evaluar i quantificar el bias de gènere dins un sistema de traducció de màquina hindo-anglès. Implementam una versió modificada de la mètrica TGBI existent basada en les consideracions gramàtiques del Hindi. També comparem i contrastem les mesures de bias resultants a través de múltiples mètriques per incorporacions pré-entrenades i les que aprenem amb el nostre model de traducció màquina.</abstract_ca>
      <abstract_cs>Vzhledem k tomu, že jazykové modely jsou ve stále více využívány v reálném světě, je nezbytné řešit otázku spravedlivosti jejich výstupů. Slovo vkládající reprezentace těchto jazykových modelů často implicitně kreslí nežádoucí asociace, které tvoří sociální zaujatost v modelu. Povaha genderových jazyků, jako je hindština, představuje další problém k kvantifikaci a zmírnění zaujatosti, vzhledem ke změně formy slov ve větě, založené na pohlaví subjektu. Kromě toho existuje řídká práce v oblasti měření a odstraňování systémů indických jazyků. V naší práci se snažíme vyhodnotit a kvantifikovat genderovou předpojatost v rámci hindsky-anglického strojového překladu systému. Implementujeme modifikovanou verzi stávající metriky TGBI na základě gramatických úvah pro hindštinu. Rovněž porovnáváme a kontrolujeme výsledná měření biasu napříč několika metrikami pro předškolené vložení a měření zjištěná naším modelem strojového překladu.</abstract_cs>
      <abstract_fi>Koska kielimalleja otetaan yhﾃ､ enemmﾃ､n kﾃ､yttﾃｶﾃｶn reaalimaailmassa, on olennaisen tﾃ､rkeﾃ､ﾃ､ puuttua niiden tulosten oikeudenmukaisuuteen. Nﾃ､itﾃ､ kielimalleja kuvaava sana vetﾃ､ﾃ､ usein implisiittisesti esiin ei-toivottuja assosiaatioita, jotka muodostavat mallin sosiaalisen puolueen. Sukupuolisten kielten, kuten hindin, luonne aiheuttaa lisﾃ､ongelman puolueellisuuden kvantifioinnille ja lieventﾃ､miselle, koska lauseen sanat muuttuvat sukupuoleen perustuen. Lisﾃ､ksi intialaisten kielten mittaus- ja debiasointijﾃ､rjestelmien alalla on tehty niukasti tyﾃｶtﾃ､. Tyﾃｶssﾃ､mme pyrimme arvioimaan ja kvantifioimaan sukupuolijakaumaa hindi-englantilaisessa konekﾃ､ﾃ､nnﾃｶsjﾃ､rjestelmﾃ､ssﾃ､. Toteutamme muutetun version olemassa olevasta TGBI-metriikasta, joka perustuu hindin kieliopillisiin huomioihin. Vertaamme ja vertaamme tuloksena saatuja harhamittauksia useiden mittausten vﾃ､lillﾃ､ esikoulutettujen upotusten ja konekﾃ､ﾃ､nnﾃｶsmallimme avulla opittujen mittausten vﾃ､lillﾃ､.</abstract_fi>
      <abstract_et>Kuna keelemudeleid kasutatakse reaalses maailmas üha enam, on oluline käsitleda nende väljundite õigluse küsimust. Neid keelemudeleid sisaldav sõna juhib sageli kaudselt soovimatuid seoseid, mis moodustavad mudelis sotsiaalse eelarvamuse. Sooliste keelte, nagu hindi, olemus tekitab täiendava probleemi eelarvamuste kvantifitseerimisel ja leevendamisel, kuna lauses olevate sõnade vormi muutused põhinevad subjekti sool. Lisaks on india keelte mõõtmis- ja debiaseerimissüsteemide valdkonnas vähe tööd tehtud. Oma töös püüame hindi-inglise masintõlke süsteemis hinnata ja kvantifitseerida soolist eelarvamust. Rakendame olemasoleva TGBI meetriku muudetud versiooni, mis põhineb hindi grammatilistel kaalutlustel. Samuti võrdleme ja kontrasteerime tulemusena saadud kalduvusmõõtmisi eelkoolitud manustamise mitme mõõdiku ja meie masintõlke mudeli abil õppitud mõõdikute vahel.</abstract_et>
      <abstract_sk>Ker se jezikovni modeli vedno bolj uporabljajo v realnem svetu, je bistveno, da se obravnava vprašanje pravičnosti njihovih rezultatov. Beseda, ki vsebuje predstavitve teh jezikovnih modelov, pogosto implicitno nariše neželene asociacije, ki tvorijo socialno pristranskost znotraj modela. Narava spolnih jezikov, kot je hindujščina, predstavlja dodaten problem za kvantifikacijo in ublažitev pristranskosti zaradi spremembe oblike besed v stavku, ki temelji na spolu subjekta. Poleg tega je na področju merilnih in debiasnih sistemov za indijske jezike opravljeno redko delo. V našem delu poskušamo oceniti in kvantificirati spolno pristranskost znotraj sistema strojnega prevajanja hindijsko-angleščine. Izvajamo spremenjeno različico obstoječe meritve TGBI, ki temelji na slovničnih premislekih za hindijščino. Prav tako primerjamo in primerjamo rezultate meritev pristranskosti pri več meritvah za vnaprej usposobljene vdelave in meritvah, ki jih je naučil naš model strojnega prevajanja.</abstract_sk>
      <abstract_ha>Ga da misãlai da aka saka su a cikin duniya halinsa, yana da muhimu a yi magana ga masu daidaita matsayinsu. Kalmar da ke ƙunsa da masu tsarin waɗannan misalin harshe, ko da yawa, za'a ƙunsa da uruki waɗanda ba'a so ba, wanda ya sami wani sura cikin misali. Tsarin harshen jinsi kamar Hindi, yana da wata mataimaki mai ƙaranci zuwa tsarin da ake yi wa haske, saboda haka da musanyi cikin tsarin maganar da aka faɗa, a kan jinin da aka sani. Da haka, there za ta sami aikin kaɗan a cikin mulkin akwatin da ake ƙaddara da yin ɓarna wa harshen Indic. Daga aikinmu, Munã jarraba yin hakar da jinni a cikin tsarin tarjibu na Ingiriya. Tuna samar da wani version na da aka riga TGBI a kan kwamfyutan kalma na Hindu. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</abstract_ha>
      <abstract_he>עם מודלים שפות מתפקדים יותר ויותר בעולם האמיתי, זה חיוני להתמודד עם הנושא של הוגנות התוצאות שלהם. המילה שמכילה מייצגים של דוגמני שפה אלה לעתים קרובות מציירים באופן לא רצוי ארגונים שמייצרים חיזוק חברתי בתוך המודל. הטבע של שפות גזעיות כמו הינדי, יוצר בעיה נוספת לכוונתית והקלה של היחידות, בגלל השינוי בצורת המילים במשפט, מבוסס על מין הנושא. בנוסף, יש עבודה נדירה שעושה בתחום של מערכות מדידות ומעטפות לשפות אינדיות. In our work, we attempt to evaluate and quantify the gender bias within a Hindi-English machine translation system.  אנחנו מפעילים גרסה משוננת של מטריקה TGBI קיימת מבוססת על השקולות גרמטיות בהינדי. אנחנו משוותים וגם משוותים את המדידות הנוצאות במטריקות רבות למערכות מאומנות מראש ואלה שנלמדו על ידי מודל התרגום המכונית שלנו.</abstract_he>
      <abstract_bo>སྐད་ཡིག་ཐབས་ལམ་འདི་དངོས་ཡོད་ཚད་དངོས་ཡོད་བཞིན་པའི་འཛམ་གླིང་ནང་དུ་གཏོང་བར་གལ་ཆེན་ཡོད། ཐ་སྙད་འདི་དག་གི་སྐད་རིགས་མིག་དཔེ་གཞི་འདིའི་ནང་དུ་སྤྱི་ཚོགས་དབྱིབས་ཀྱི་མཐུད་སྤྱི་ཚོགས་དང་མཉམ་དུ་འབྲི་ན། རྒྱ་ནག་དང་མི་འདྲ་བརྗོད་པའི་སྐད་ཡིག་ཚོའི་རང་བཞིན་གྱི་རྒྱུན་རིགས་ཀྱི་དབྱེ་བ་དེ་ལྟར་ཡན་ལག་གདོང་ལེན་འཐབ་རྒྱུ་དང་། འོན་ཀྱང་། ཨིན་ཌི་ཡིས་སྐད་ཀྱི་རྒྱལ་ཁབ་ལ་ཚད་དང་རྫུན་ཆས་པ་ཚོགས་ཀྱི་ལས་ཀ་རྟོགས་པ་ཞིག་ཡོད། ང་ཚོའི་ལས་ཀ་ལྟའི་ནང་དུ་ང་ཚོས་རྒྱ་གར་གྱི་མ་ལག We implement a modified version of the existing TGBI metric based on the grammatical considerations for Hindi. We also compare and contrast the resulting bias measurements across multiple metrics for pre-trained embeddings and the ones learned by our machine translation model.</abstract_bo>
      <abstract_fil>Dil modelleri gerçek dünyada daha yüksek dağıtılırken, çözümlerinin adaletliğin in sorunu çözmek gerekir. Ang salitang nagbibigay ng mga representasyon ng mga wikang models na ito ay madalas ay nagbibigay ng di-kailangang asosyasyon na naglalagay ng social bias sa loob ng modelo. Ang kalikasan ng mga wikang nagngangalang tulad sa Hindi, ay nagbibigay ng ibang problema sa quantification at pagbabago ng bias, dahil sa pagbabago ng anyo ng mga salita sa sentencia, na basahin sa lahi ng subjekto. Dahil dito, may maliit na gawa sa kaharian ng pagsusukat at debiasing systems para sa mga wika ng Indic. Sa ating trabaho, pinagsisikapan nating evaluwasyon at pagkakainting ang gender bias sa isang sistema ng paglilikas ng makina Hindi-Ingles. Naglalagay kami ng isang pagbago na bersyon ng mayroong TGBI metric na ayon sa mga grammatical consideration para sa Hindi. Pinagpigaralan din namin at nakikipagkasundo ang resulting bias measurements sa multiple metrics para sa pre-trained embeddings at sa mga natutunan ng aming model ng paglilikat sa makina.</abstract_fil>
      <abstract_jv>Suara model sing ngaweh luwih dumadhi iki, akeh dumadhi kanggo kuwi nggawe barang langkung wih apik sing bakal dumadhi iki banget. Wurung metungin Rayong NdSudakya kelas barang kelas banget nganggo barang hendhis, iso nggawe perbudhakan langkung dadi apik lan nggawe biasa, dadi mbukakipun banjur kuwi tindah kuwi kerdusé winih, dadi sing ngesir uwong. Mungkin, wis kelas barang nggawe barang nggawe barang nggawe sistem maning lan nggawe barang tarjamahan kanggo langkung endik. Nang barêng-barêng, kéné saiki ngênggunaké beraksi lan kuwi nggawe gerakan kanggo kuwi bias a kanggo ngilangno ning sistem sing itolekaké Inggris. Awak dhéwé ngewehke perusahaan anyari kabèh durung tanggal PGBI iki dadi, dadi supoyo barang nggawe barang kelangan kanggo barang barang barang kelangan Laptop" and "Desktop</abstract_jv>
      </paper>
    <paper id="4">
      <title>Alexa, Google, Siri : What are Your Pronouns? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants<fixed-case>A</fixed-case>lexa, <fixed-case>G</fixed-case>oogle, <fixed-case>S</fixed-case>iri: What are Your Pronouns? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title>
      <author><first>Gavin</first><last>Abercrombie</last></author>
      <author><first>Amanda</first><last>Cercas Curry</last></author>
      <author><first>Mugdha</first><last>Pandya</last></author>
      <author><first>Verena</first><last>Rieser</last></author>
      <pages>24–33</pages>
      <abstract>Technology companies have produced varied responses to concerns about the effects of the design of their conversational AI systems. Some have claimed that their voice assistants are in fact not gendered or human-likedespite design features suggesting the contrary. We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants. We also examine systems’ responses and the extent to which they generate output which is gendered and anthropomorphic. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true. In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract>
      <url hash="37fbde43">2021.gebnlp-1.4</url>
      <doi>10.18653/v1/2021.gebnlp-1.4</doi>
      <bibkey>abercrombie-etal-2021-alexa</bibkey>
      <pwccode url="https://github.com/GavinAbercrombie/GeBNLP2021" additional="false">GavinAbercrombie/GeBNLP2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/persona-chat-1">PERSONA-CHAT</pwcdataset>
    <title_ar>أليكسا ، جوجل ، سيري: ما هي الضمائر الخاصة بك؟ الجنس والأنثروبومورفيسم في تصميم وتصور مساعدي المحادثة</title_ar>
      <title_ja>Alexa、Google、Siri:あなたの代名詞は何ですか？会話アシスタントのデザインと知覚における性別と擬人化</title_ja>
      <title_es>Alexa, Google, Siri: ¿Cuáles son tus pronombres? Género y antropomorfismo en el diseño y la percepción de los asistentes conversacionales</title_es>
      <title_fr>Alexa, Google, Siri : quels sont tes pronoms ? Genre et anthropomorphisme dans la conception et la perception des assistants conversationnels</title_fr>
      <title_pt>Alexa, Google, Siri: Quais são seus pronomes? Gênero e Antropomorfismo no Design e Percepção de Assistentes Conversacionais</title_pt>
      <title_zh>Alexa,Google,Siri:子何代词? 会话佐计、感知别拟人化</title_zh>
      <title_ukr>Alexa, Google, Siri: Які ваші займенники? Гендер та антропоморфізм у дизайні та сприйнятті розмовних асистентів</title_ukr>
      <title_hi>एलेक्सा, Google, सिरी: आपके सर्वनाम क्या हैं? संवादी सहायकों के डिजाइन और धारणा में लिंग और एंथ्रोपोमोर्फिज्म</title_hi>
      <title_ga>Alexa, Google, Siri: Cad iad na Forainmneacha atá agat? Inscne agus Antrapamorphism i nDearadh agus Dearcadh Cúntóirí Comhrá</title_ga>
      <title_ru>Alexa, Google, Siri: Каковы ваши местоимения? Гендерный и антропоморфизм в дизайне и восприятии разговорных помощников</title_ru>
      <title_hu>Alexa, Google, Siri: Mik a névmások? Nemek és antropomorfizmus a beszélgetési asszisztensek tervezésében és érzékelésében</title_hu>
      <title_isl>Alexa, Google, Siri: Hvað eru nafnið þitt? Kyn og kynhvöt í hönnun og skilningu samræmsaðstoðara</title_isl>
      <title_ka>ალექსია, Google, Siri: რა არის თქვენი პროგრამები? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_ka>
      <title_el>Ποια είναι τα προφωνήματά σας; Φύλο και ανθρωπομορφισμός στο σχεδιασμό και την αντίληψη των βοηθών συνομιλίας</title_el>
      <title_it>Alexa, Google, Siri: Quali sono i tuoi pronomi? Genere e antropomorfo nella progettazione e nella percezione degli assistenti di conversazione</title_it>
      <title_kk>Алекса, Гугл, Сири: Сіздің протендеріңіз не? Жалғыз және антропоморфизм қатынау көмекшілердің дизайны және қарсы</title_kk>
      <title_lt>Aleksa, Google, Siri: Kokie jūsų vardai? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_lt>
      <title_ms>Alexa, Google, Siri: Apa nama anda? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_ms>
      <title_mk>Алекса, Гугл, Сири: Кои се твоите презими? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_mk>
      <title_ml>അലെക്സാ, ഗൂഗിള്‍, സിരി: നിങ്ങളുടെ പ്രോപ്നോണ്‍സ് എന്താണ്? സംസാരിക്കുന്ന സഹായികളുടെ ഡിസൈനും പെര്‍സിപ്ഷനുമായ സ്ത്രോപോമോര്‍ഫിസിസ്</title_ml>
      <title_mt>Alexa, Google, Siri: X’inhuma l-Ismijiet tiegħek? Sess u antropomorfismu fid-Disinn u l-Perċezzjoni ta’ Assistenti Konversazzjonali</title_mt>
      <title_mn>Алекса, Google, Сири: Чиний нэр дэвшигчид юу вэ? Хоролцооны тусламжтайгаар дизайнд гендер болон антропоморфизм</title_mn>
      <title_pl>Alexa, Google, Siri: Jakie są Twoje zaimki? Płeć i antropomorfizm w projektowaniu i postrzeganiu asystentów konwersacyjnych</title_pl>
      <title_no>Alexa, Google, Siri: Kva er din uttaler? Gender og Anthropomorphism i Design and Perception of Conversational Assistants</title_no>
      <title_ro>Alexa, Google, Siri: Care sunt pronumele tale? Genul și antropomorfismul în proiectarea și percepția asistenților de conversație</title_ro>
      <title_si>ඇලෙක්සා, ගුගුල්, සිරි: ඔයාගේ ප්‍රදේශය මොකද්ද? ජෙන්ඩර් සහ ඇන්ට්‍රොපොමොර්ෆිස්ම් විද්‍යාපනය සහ ප්‍රශ්නයක් විද්‍යාපනය සහ ප්‍රශ්නය</title_si>
      <title_sr>Алекса, Гугле, Сири: Шта су Твоји прогнози? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_sr>
      <title_so>Alexa, Google, Siri: Muxuu yahay Koriintaada? Jinni iyo Anthropomorfism in Design and Perception of Talobixinta</title_so>
      <title_sv>Alexa, Google, Siri: Vilka är dina pronomen? Genus och antropomorfi i design och uppfattning av samtalsassistenter</title_sv>
      <title_ta>அலெக்சா, கூகுல், சிரி: உங்கள் பிரயோன்ஸ் என்ன? பேச்சு உதவிகளின் வடிவமைப்பு மற்றும் பரிசோதனை</title_ta>
      <title_ur>الکسا، گوگل، سیری: تیرے معاملات کیا ہیں؟ جنس اور انٹروپورفیسم کی طراحی اور تصور کی</title_ur>
      <title_uz>Alexa, Google, Siri: Siz nima? Name</title_uz>
      <title_vi>Alexa, Google, Siri: Các danh từ của cô là gì? Giới tính và Nhân loại trong sự thiết kế và nhận thức của các trợ lý đối thoại</title_vi>
      <title_bg>Алекса, Гугъл, Сири: Какви са вашите местоимения? Пол и антропоморфизъм в проектирането и възприемането на разговорните асистенти</title_bg>
      <title_da>Alexa, Google, Siri: Hvad er dine udtaler? Køn og antropomorfi i design og opfattelse af samtalsassistenter</title_da>
      <title_nl>Alexa, Google, Siri: Wat zijn je voornaamwoorden? Gender en antropomorfisme in het ontwerp en perceptie van gespreksassistenten</title_nl>
      <title_hr>Alexa, Google, Siri: Koji su vaši proglašeni? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_hr>
      <title_id>Alexa, Google, Siri: Apa nama Anda? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_id>
      <title_de>Alexa, Google, Siri: Was sind deine Pronomen? Gender und Anthropomorphismus in der Gestaltung und Wahrnehmung von Gesprächssistenten</title_de>
      <title_ko>Alexa, Google, Siri: 당신의 대명사는 무엇입니까?회화 보조 설계와 감지에서의 성별과 의인화</title_ko>
      <title_fa>الکسا، گوگل، سیری: معروف شما چیست؟ جنس و آنتروپروپورفیسم در طراحی و تصور کمک‌کنندگان گفتگو</title_fa>
      <title_sw>Alexa, Google, Siri: Maonyesho yako ni nini? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_sw>
      <title_tr>Alexa, Google, Siri: Seniň tasarlamalaryň näme? Jender we Antropomorphism Gezgini we Düzenleme Mümkinçilerinde</title_tr>
      <title_af>Alexa, Google, Siri: Wat is u voorneemde? Gender en Anthropomorphism in die Ontwerp en Perseptie van Gespraaksassistente</title_af>
      <title_sq>Alexa, Google, Siri: What are Your Pronouns?  Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_sq>
      <title_am>አሌክሳይ፣ ጎግል፣ ሲሪ፤ ፕሮጀንስ ምንድር ነው? ሴት እና Anthropomorphism በdesign and Perception of Conversational Assistants</title_am>
      <title_hy>Ալեքսա, Գուգլ, Սիրին. Ո՞րն են ձեր նախաանունները: Խոսակցության օգնականների դիզայնի և ընկալումների մեջ գենդերն ու անտրոպոմորֆիզմը</title_hy>
      <title_az>Alexa, Google, Siri: Sizin proqramlar캼n캼z n톛dir? C톛nn톛t v톛 Antropomorphism M칲톛llif Yard캼mc캼lar캼n캼n tasar캼m캼 v톛 perspektivi</title_az>
      <title_bn>অ্যালেক্সা, গুগল, সিরি: তোমাদের প্রজন্ম কি? আলোচনার সহকারীদের ডিজাইন এবং পার্সিপেশনের লিঙ্গ এবং অ্যান্ট্রোপোর্ফিজম</title_bn>
      <title_ca>Alexa, Google, Siri: What are Your Pronouns?  Gènere i antropomorfisme en el disseny i percepció d'assistents conversacionals</title_ca>
      <title_cs>Alexa, Google, Siri: Jaká jsou vaše zájmena? Gender a antropomorfismus v designu a vnímání konverzačních asistentů</title_cs>
      <title_et>Alexa, Google, Siri: Millised on teie pronounid? Sugu ja antropomorfism vestlusassistentide disainimisel ja tajumisel</title_et>
      <title_fi>Alexa, Google, Siri: Mitkä ovat pronominisi? Sukupuoli ja antropomorfismi keskusteluavustajien suunnittelussa ja havaitsemisessa</title_fi>
      <title_bs>Alexa, Google, Siri: Koji su tvoji proglašeni? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_bs>
      <title_sk>Alexa, Google, Siri: Katera so vaša imena? Spol in antropomorfizem pri oblikovanju in zaznavanju pogovornih asistentov</title_sk>
      <title_fil>Alexa, Google, Siri: Ano ang iyong mga Pronouns? Gender and Anthropomorphism sa Design and Perception of Conversational Assistants</title_fil>
      <title_bo>Alexa, Google, Siri: ཁྱོད་ཀྱི་རྗེས་ཐོག་ཅི་རེད། Gender and Anthropomorphism in the Design and Perception of Conversational Assistant</title_bo>
      <title_ha>Aleca, Google, Siri: @ item Text character set</title_ha>
      <title_he>אלכסא, גוגל, סירי: מה השם שלכם? Gender and Anthropomorphism in the Design and Perception of Conversational Assistants</title_he>
      <title_jv>Alaka, Google, Simi: Ngopo sing paling apa ? Genjer karo antahrohelp</title_jv>
      <abstract_pt>As empresas de tecnologia produziram respostas variadas às preocupações sobre os efeitos do design de seus sistemas de IA conversacionais. Alguns alegaram que seus assistentes de voz na verdade não são de gênero ou humanos - apesar dos recursos de design sugerirem o contrário. Comparamos essas afirmações com as percepções dos usuários analisando os pronomes que eles usam quando se referem a assistentes de IA. Também examinamos as respostas dos sistemas e até que ponto eles geram saídas de gênero e antropomórficas. Descobrimos que, embora algumas empresas pareçam estar abordando as preocupações éticas levantadas, em alguns casos, suas alegações não parecem verdadeiras. Em particular, nossos resultados mostram que as saídas do sistema são ambíguas quanto à humanidade dos sistemas, e que os usuários tendem a personificá-los e classificá-los como resultado.</abstract_pt>
      <abstract_ar>أنتجت شركات التكنولوجيا استجابات متنوعة للمخاوف المتعلقة بتأثيرات تصميم أنظمة الذكاء الاصطناعي الخاصة بالمحادثة. ادعى البعض أن مساعدي الصوت في الواقع ليسوا من النوع الاجتماعي أو يشبهون البشر - على الرغم من ميزات التصميم التي تشير إلى عكس ذلك. نقارن هذه الادعاءات بتصورات المستخدم من خلال تحليل الضمائر التي يستخدمونها عند الإشارة إلى مساعدي الذكاء الاصطناعي. نقوم أيضًا بفحص استجابات الأنظمة ومدى إنتاجها لمخرجات متجانسة ومتجسدة. وجدنا أنه في حين يبدو أن بعض الشركات تتعامل مع المخاوف الأخلاقية التي أثيرت ، في بعض الحالات ، لا يبدو أن ادعاءاتهم صحيحة. على وجه الخصوص ، تُظهر نتائجنا أن مخرجات النظام غامضة فيما يتعلق بإنسانية الأنظمة ، وأن المستخدمين يميلون إلى تجسيدها ونوعها نتيجة لذلك.</abstract_ar>
      <abstract_fr>Les entreprises technologiques ont produit des réponses variées aux préoccupations concernant les effets de la conception de leurs systèmes d'IA conversationnelle. Certains ont affirmé que leurs assistants vocaux ne sont en fait pas sexistes ou humains, malgré les caractéristiques de conception suggérant le contraire. Nous comparons ces affirmations aux perceptions des utilisateurs en analysant les pronoms qu'ils utilisent lorsqu'ils font référence aux assistants IA. Nous examinons également les réponses des systèmes et la mesure dans laquelle ils génèrent une production sexospécifique et anthropomorphique. Nous constatons que, même si certaines entreprises semblent répondre aux préoccupations éthiques soulevées, dans certains cas, leurs affirmations ne semblent pas être fondées. En particulier, nos résultats montrent que les résultats du système sont ambigus quant à l'humanité des systèmes, et que les utilisateurs ont tendance à les personnifier et à les différencier en fonction de leur sexe.</abstract_fr>
      <abstract_es>Las empresas de tecnología han producido respuestas variadas a las preocupaciones sobre los efectos del diseño de sus sistemas de IA conversacional. Algunos han afirmado que sus asistentes de voz en realidad no tienen género ni son similares a los humanos, a pesar de las características de diseño que sugieren lo contrario. Comparamos estas afirmaciones con las percepciones de los usuarios analizando los pronombres que utilizan cuando nos referimos a los asistentes de IA. También examinamos las respuestas de los sistemas y la medida en que generan resultados antropomórficos y de género. Descubrimos que, si bien algunas empresas parecen estar abordando las preocupaciones éticas planteadas, en algunos casos, sus afirmaciones no parecen ser ciertas. En particular, nuestros resultados muestran que los resultados del sistema son ambiguos en cuanto a la humanidad de los sistemas y que, como resultado, los usuarios tienden a personificarlos y darles género.</abstract_es>
      <abstract_ja>テクノロジー企業は、会話型AIシステムの設計の影響に関する懸念に対してさまざまな反応を生み出してきました。一部の人々は、彼らの声のアシスタントは実際には性別や人間のようなデザインの特徴ではないと主張しており、それとは逆のことを示唆しています。AIアシスタントを参照する際に使用する代名詞を分析することで、これらの主張をユーザーの認識と比較します。また、システムの応答と、それらがジェンダー化され、擬人化された出力を生成する程度を検討します。提起された倫理的な懸念に対処していると思われる企業もありますが、場合によってはその主張が当てはまらないこともあります。特に、私たちの結果は、システムのアウトプットがシステムの人間性に関して曖昧であり、その結果、ユーザーがそれらを人格化し、性別化する傾向があることを示しています。</abstract_ja>
      <abstract_zh>科技公司已对其对式AI系统计效之忧有异应矣。 或称其语音助手实无性别及人类者 - 虽设意特征表明反。 论用户AI之代词,比之用户知。 又论系统之反应,其生性别化,拟人化所输如此。 虽公司似有道德,其说似不成立。 特是,我们的结果表明,系统输出对系统的人性是模棱两可的,所以用户倾向他们拟人化和性别化。</abstract_zh>
      <abstract_hi>प्रौद्योगिकी कंपनियों ने अपने संवादी एआई सिस्टम के डिजाइन के प्रभावों के बारे में चिंताओं के लिए विभिन्न प्रतिक्रियाओं का उत्पादन किया है। कुछ ने दावा किया है कि उनके आवाज सहायक वास्तव में लिंग या मानव की तरह नहीं हैं- इसके विपरीत सुझाव देने वाली डिजाइन सुविधाओं के बावजूद। हम एआई सहायकों का उल्लेख करते समय उपयोग किए जाने वाले सर्वनामों का विश्लेषण करके उपयोगकर्ता धारणाओं से इन दावों की तुलना करते हैं। हम सिस्टम की प्रतिक्रियाओं की भी जांच करते हैं और जिस हद तक वे आउटपुट उत्पन्न करते हैं जो लिंग और एंथ्रोपोमोर्फिक है। हम पाते हैं कि, जबकि कुछ कंपनियां उठाई गई नैतिक चिंताओं को संबोधित करती हैं, कुछ मामलों में, उनके दावे सच नहीं लगते हैं। विशेष रूप से, हमारे परिणामों से पता चलता है कि सिस्टम आउटपुट सिस्टम की मानवीयता के रूप में अस्पष्ट हैं, और यह कि उपयोगकर्ता परिणामस्वरूप उन्हें व्यक्तित्व और लिंग करते हैं।</abstract_hi>
      <abstract_ru>Технологические компании подготовили различные ответы на опасения по поводу последствий разработки их систем ИИ для общения. Некоторые утверждают, что их голосовые помощники на самом деле не являются гендерными или человекоподобными особенностями дизайна, предполагающими обратное. Мы сравниваем эти утверждения с восприятием пользователей, анализируя местоимения, которые они используют при обращении к помощникам ИИ. Мы также изучаем реакцию систем и степень, в которой они генерируют результаты, которые являются гендерными и антропоморфными. Мы считаем, что, хотя некоторые компании, как представляется, решают этические проблемы, в некоторых случаях их утверждения, как представляется, не соответствуют действительности. В частности, наши результаты показывают, что результаты работы системы неоднозначны в том, что касается гуманности систем, и что пользователи, как правило, олицетворяют их и, как следствие, учитывают их гендерные аспекты.</abstract_ru>
      <abstract_ukr>Технологічні компанії дали різні відповіді на занепокоєння щодо наслідків проектування їхніх розмовних систем ШІ. Деякі стверджують, що їхні голосові помічники насправді не є гендерними або людиноподібними особливостями дизайну, що свідчить про протилежне. Ми порівнюємо ці твердження зі сприйняттям користувача, аналізуючи займенники, які вони використовують, посилаючись на помічників ШІ. Ми також вивчаємо реакції систем та ступінь, в якій вони генерують результати, які є ґендерними та антропоморфними. Ми виявляємо, що, хоча деякі компанії, здається, вирішують етичні проблеми, в деяких випадках їхні претензії, здається, не відповідають дійсності. Зокрема, наші результати показують, що результати системи є неоднозначними щодо гуманності систем, і що користувачі, як правило, уособлюють їх і, як наслідок, стають ними.</abstract_ukr>
      <abstract_ga>Tá freagraí éagsúla curtha ar fáil ag cuideachtaí teicneolaíochta ar imní faoi éifeachtaí dearadh a gcórais chomhrá AI. Mhaígh roinnt daoine nach bhfuil a gcuid cúntóirí gutha inscne nó cosúil le daoine – in ainneoin gnéithe dearaidh a thugann a mhalairt le tuiscint. Déanaimid comparáid idir na héilimh seo agus dearcadh úsáideoirí trí anailís a dhéanamh ar na forainmneacha a úsáideann siad agus iad ag tagairt do chúntóirí AI. Scrúdaímid freisin freagairtí na gcóras agus an méid a ghineann siad aschur atá inscne agus antrapamorfach. Faighimid amach, cé go ndealraíonn sé go bhfuil roinnt cuideachtaí ag dul i ngleic leis na hábhair imní eiticiúla a ardaíodh, i gcásanna áirithe, ní cosúil go bhfuil a gcuid éileamh fíor. Léiríonn ár dtorthaí go háirithe go bhfuil aschuir an chórais débhríoch maidir le daonnacht na gcóras, agus go mbíonn claonadh ag úsáideoirí iad a phearsanú agus a inscne dá bharr.</abstract_ga>
      <abstract_ka>ტექნოლოგიური კომპონიაციები განსხვავებულ პასუხების შესახებ საინტერესო სისტემის განსაზღვრების შესახებ. ზოგიერთი აღმოჩნეთ, რომ მათი სიტყვას აზიანტები ფაქტიურად არიან გენექცირებული ან ადამიანური განსხვავებული განსხვავებების განსხვავებას. ჩვენ გამოყენებთ ეს წინასწორებების მომხმარებელი აღმოჩენების შესახებ, რომლებიც გამოყენებენ აღმოჩენების შესახებ. ჩვენ ასევე შევხედავთ სისტემის პასუხები და განსაზღვრება, რომლებიც ისინი წარმოიქმნენ, რომელიც გენესური და ანტროპომოპფიკური. ჩვენ ვფიქრობთ, რომ, როცა ზოგიერთი კომპანიაციები აღწევენ ეტიკური დარწმუნება, რამდენიმე შემთხვევაში, მათი წყვეტილება არ იქნება მართლად. განსაკუთრებით, ჩვენი შედეგები აჩვენებენ, რომ სისტემის შედეგები არსებულია სისტემის ადამიანიერობას, და რომ მომხმარებელი მათი პროგრამების განსაკუთრება და გენექცია შედეგებით</abstract_ka>
      <abstract_isl>Tæknifyrirtæki hafa sýnt ýmsar svörun við áhyggjum vegna áhrifa hannunar samtalstæknikerfa þeirra. Sumir hafa sagt að röddumönnunaraðilar þeirra séu reyndar ekki kynslíkir eða mannslíkir þrátt fyrir hönnunaratriði sem benda til öfugs. Við borum saman þessi ákvörðun við notandaskilningu með því að greina nafn sem þeir nota þegar um aðstoðarmann við AI. Við skoðum einnig svörun kerfisins og hversu mikið þeir mynda útgáfu sem er kynlegt og mannfæðilegt. Við finnum að þótt sumir fyrirtæki virðist hafa verið að meðhöndla siðfræðilegar áhyggjur sem komu fram, virðist í sumum tilvikum ekki vera satt. Sérstaklega sýna niðurstöður okkar a ð kerfisútsetningar eru tveggja hvað varðar mannkyni kerfisins og að notendur hafa tilhneigingu til að persónuleggja og kynlíf þau sem afleiðing.</abstract_isl>
      <abstract_hu>A technológiai vállalatok különböző válaszokat adtak a beszélgető mesterséges intelligencia-rendszereik kialakításának hatásaival kapcsolatos aggályokra. Néhányan azt állították, hogy a hangasszisztenseik valójában nemek vagy emberi jellegűek – annak ellenére, hogy a tervezési jellemzők az ellenkezőjét sugallják. Ezeket az állításokat a felhasználói érzékelésekkel hasonlítjuk össze, elemzve azokat a névmásokat, amelyeket az AI asszisztensekre utalnak. Vizsgáljuk továbbá a rendszerek válaszait, valamint azt is, hogy milyen mértékben generálnak nemi és antropomorf termelést. Úgy találjuk, hogy bár egyes vállalatok úgy tűnik, hogy kezelik a felmerült etikai aggályokat, bizonyos esetekben állításaik nem tűnnek igaznak. Eredményeink különösen azt mutatják, hogy a rendszer kimenetei kétértelműek a rendszerek emberségét illetően, és ennek eredményeképpen a felhasználók hajlamosak megszemélyesíteni és nemezni őket.</abstract_hu>
      <abstract_el>Οι εταιρείες τεχνολογίας έχουν παρουσιάσει ποικίλες απαντήσεις στις ανησυχίες σχετικά με τις επιπτώσεις του σχεδιασμού των επικοινωνιακών συστημάτων τεχνητής νοημοσύνης τους. Ορισμένοι ισχυρίστηκαν ότι οι φωνητικοί βοηθοί τους στην πραγματικότητα δεν είναι φυλετικοί ή ανθρώπινοι-παρά τα σχεδιαστικά χαρακτηριστικά που υποδηλώνουν το αντίθετο. Συγκρίνουμε αυτούς τους ισχυρισμούς με τις αντιλήψεις των χρηστών αναλύοντας τις αντωνυμίες που χρησιμοποιούν όταν αναφέρονται σε βοηθούς τεχνητής νοημοσύνης. Εξετάζουμε επίσης τις αντιδράσεις των συστημάτων και τον βαθμό στον οποίο παράγουν παραγωγή που είναι φυλετική και ανθρωπομορφική. Διαπιστώνουμε ότι, ενώ ορισμένες εταιρείες φαίνεται να αντιμετωπίζουν τις ηθικές ανησυχίες που εγείρονται, σε ορισμένες περιπτώσεις, οι ισχυρισμοί τους δεν φαίνεται να ισχύουν. Ειδικότερα, τα αποτελέσματά μας δείχνουν ότι τα αποτελέσματα του συστήματος είναι διφορούμενα ως προς την ανθρωπιά των συστημάτων, και ότι οι χρήστες τείνουν να τα προσωποποιούν και να τα φύλουν ως αποτέλεσμα.</abstract_el>
      <abstract_it>Le aziende tecnologiche hanno prodotto risposte diverse alle preoccupazioni circa gli effetti della progettazione dei loro sistemi di intelligenza artificiale conversazionale. Alcuni hanno affermato che i loro assistenti vocali in realtà non sono di genere o umano, nonostante le caratteristiche progettuali suggeriscano il contrario. Confrontiamo queste affermazioni con le percezioni degli utenti analizzando i pronomi che usano quando si riferiscono agli assistenti AI. Esaminiamo anche le risposte dei sistemi e la misura in cui generano un output di genere e antropomorfo. Riteniamo che, mentre alcune aziende sembrano affrontare le preoccupazioni etiche sollevate, in alcuni casi le loro affermazioni non sembrano essere vere. In particolare, i nostri risultati mostrano che i risultati del sistema sono ambigui in merito all'umanità dei sistemi, e che gli utenti tendono a personificarli e gender come risultato.</abstract_it>
      <abstract_kk>Технологиялық компаниялардың қатынасыз AI жүйелерінің құрылымының қасиеттері туралы айырмашылық жауаптарды жасады. Кейбірінің дауыс көмекшілері қарсы дегенді көрсетуге қарамастан, гендерлік не адамға ұқсас емес деп айтты. Біз бұл жағдайларды пайдаланушылардың түсініктеріне салыстырып, AI көмекшілеріне салыстырып қолданылатын сөздерді анализ етіп салыстырамыз. Біз жүйелердің жауаптарын және олар гендерлік және антропоморфикалық шығарудың шегін тексереміз. Біз, кейбір компаниялардың этикалық қатынастарын өзгерту үшін, кейбір жағдайда, олардың жағдайлары дұрыс емес сияқты. Біздің нәтижелеріміз жүйелік нәтижелеріміз жүйелердің адамзаттылығы және пайдаланушылардың нәтижесі болып жатқан адамзаттылығын көрсетеді.</abstract_kk>
      <abstract_mk>Технолошките претпријатија произведоа различни одговори на загриженоста во врска со ефектите на дизајнот на нивните конверзационални системи на ИИ. Некои тврдат дека нивните гласовни асистенти всушност не се генерални или човечки слични на дизајнски карактеристики кои наведуваат спротивно. Ги споредуваме овие тврдења со перцепциите на корисниците со анализирање на изговорите кои ги користат кога се однесуваат на асистентите на AI. Ние, исто така, ги испитуваме одговорите на системите и степенот во кој тие генерираат излез кој е генериран и антропорфски. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true.  In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract_mk>
      <abstract_lt>Technology companies have produced varied responses to concerns about the effects of the design of their conversational AI systems.  Kai kurie teigė, kad jų balso padėjėjai iš tikrųjų nėra lyties ar panašūs į žmogų, nepaisant projekto požymių, rodančių priešingą. We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants.  Mes taip pat nagrinėjame sistemų atsakus ir kiek jie sukuria lytinę ir antropomorfinę produkciją. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true.  In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract_lt>
      <abstract_ms>Perusahaan teknologi telah menghasilkan balasan berbagai-bagai kepada risau mengenai kesan desain sistem AI perbualan mereka. Some have claimed that their voice assistants are in fact not gendered or human-like-despite design features suggesting the contrary.  We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants.  Kami juga memeriksa tindak balas sistem dan ke mana mereka menghasilkan output yang jenis dan antropomorfik. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true.  In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract_ms>
      <abstract_ml>ടെക്നോളജി കമ്പനികള്‍ വ്യത്യസ്ത പ്രതികരണങ്ങള്‍ ഉണ്ടാക്കിയിരിക്കുന്നു. അവരുടെ സംസാരിക്കുന്ന AI സിസ്റ്റത്തിന്റെ സം ചിലര്‍ അവരുടെ ശബ്ദത്തിന്‍റെ സഹായികള്‍ യഥാര്‍ത്ഥത്തില്‍ ഭിന്നിക്കപ്പെട്ടവരല്ലെന്നോ മനുഷ്യര്‍ക്ക് തുല്യമായ പ്രതിഫല AI സഹായികളെ വിശദീകരിക്കുമ്പോള്‍ ഉപയോക്താവിന്റെ കാര്യങ്ങള്‍ പരിശോധിക്കുന്നതിനാല്‍ നമ്മള്‍ ഈ വാക്കുകളെ താല്‍ സിസ്റ്റത്തിന്റെ ഉത്തരം നമ്മളും പരിശോധിക്കുന്നു. അതിന്റെ പ്രതികരണങ്ങള്‍ക്കുള്ള പരിശോധിക്കുന്നു. അതിന്റെ പ്രഭാ ഞങ്ങള്‍ കണ്ടെത്തുന്നു, കുറച്ചു കമ്പനികള്‍ സാമാന്യമായ കാര്യങ്ങളെക്കുറിച്ച് വിചാരിക്കുമ്പോള്‍, ചില കാര്യങ്ങളില്‍ അവരുടെ വ പ്രത്യേകിച്ച്, നമ്മുടെ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു സിസ്റ്റത്തിന്റെ പുറത്തുള്ള പ്രശ്നങ്ങള്‍ സിസ്റ്റത്തിന്റെ മനുഷ്</abstract_ml>
      <abstract_mn>Технологийн компаниуд харилцааны AI системийн загварын үр дүний тухай сэтгэл санаанд өөр өөр хариулт гаргасан. Зарим хүмүүс дуу хоолойн тусламжтайгаа гендер эсвэл хүн төрөлхтний төстэй биш гэдгийг хэлэхдээ эсрэг хэлбэртэй. Бид эдгээрийг хэрэглэгчдийн ойлголтын тухай харьцуулж, AI-ын тусламжтайгаар ашиглах үед хэрэглэгчдийн утгыг шинжилдэг. Мөн бид системийн хариултыг шалгаж байна. Тэд гендер болон антропоморфик бүтээгдэхүүний үр дүнг гаргадаг. Зарим компаниуд эдийн засгийн сэтгэл хөдлөлийг зохицуулж байгаа ч зарим тохиолдолд тэдний утга нь үнэн биш юм шиг харагдаж байна. Ялангуяа бидний үр дүнд системийн үр дүнг системийн хүн төрөлхтний хувьд хэцүү гэдгийг харуулж байна. Хэрэглэгчид үүнийг хүн төрөлхтний үр дүнд хүн төрөлхтний тулд хүн төрөлхтний тулд хүн төрөл</abstract_mn>
      <abstract_mt>Il-kumpaniji tat-teknoloġija pproduċew tweġibiet varji għat-tħassib dwar l-effetti tad-disinn tas-sistemi tal-AI ta’ konverżjoni tagħhom. Xi wħud iddikjaraw li l-assistenti tal-vuċi tagħhom fil-fatt mhumiex ġeneri jew simili għall-bniedem minkejja karatteristiċi ta’ disinn li jissuġġerixxu l-kuntrarju. Aħna nqabblu dawn id-dikjarazzjonijiet mal-perċezzjonijiet tal-utenti billi ninalwaw il-pronomi li jużaw meta nirreferu għall-assistenti tal-AI. Aħna teżamina wkoll ir-reazzjonijiet tas-sistemi u l-punt sa fejn jiġġeneraw produzzjoni li hija ġenerata u antropomorfika. Aħna nsibu li, filwaqt li xi kumpaniji jidhru li qed jindirizzaw it-tħassib etiku mqajjem, f’xi każijiet, it-talbiet tagħhom ma jidhrux li huma vera. In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract_mt>
      <abstract_no>Teknologiske selskapar har produsert varierte svar på bekymringar om effekten av utforminga av dei samtale AI-systemene sine. Noen har tvrd at stemmeassistenten sine er faktisk ikkje generert eller menneskelig, selv om design-funksjonar foreslår motsatt. Vi sammenliknar desse førespurnadene til brukaren ved å analysera uttalene dei brukar når du refererer til AI-assistentar. Vi undersøker også systemsvar og storleiken dei genererar utdata som er generelt og antropomorfisk. Vi finn at, mens nokre selskaper ser ut til å handtere dei etiske bekymringane som er oppretta, i nokre tilfelle, så ser det ikkje ut til at tiltak sine er sann. I særskilt viser resultatet våre at systemutgåver er utgåver avhengig av systemet, og at brukarar tenderer å personifisera og følgja dei som resultat.</abstract_no>
      <abstract_pl>Firmy technologiczne przygotowały różnorodne odpowiedzi na obawy dotyczące efektów projektowania swoich systemów rozmowy AI. Niektórzy twierdzili, że ich asystenci głosowi w rzeczywistości nie mają charakteru płciowego ani ludzkiego, pomimo cech konstrukcyjnych sugerujących przeciwność. Porównujemy te twierdzenia do postrzegania użytkowników, analizując zaimki, których używają w odniesieniu do asystentów AI. Badamy również odpowiedzi systemów oraz stopień, w jakim generują one produkcję płciową i antropomorficzną. Uważamy, że chociaż niektóre przedsiębiorstwa wydają się rozwiązywać problemy etyczne, w niektórych przypadkach ich twierdzenia nie są prawdziwe. W szczególności nasze wyniki pokazują, że wyniki systemu są niejednoznaczne co do ludzkości systemów, a w rezultacie użytkownicy mają tendencję do uosobienia i płci ich.</abstract_pl>
      <abstract_ro>Companiile tehnologice au produs răspunsuri variate la preocupările legate de efectele proiectării sistemelor lor conversaționale AI. Unii au susținut că asistenții lor de voce nu sunt de fapt sexați sau asemănători oamenilor, în ciuda caracteristicilor de design sugerează contrariul. Comparăm aceste afirmații cu percepțiile utilizatorilor analizând pronumele pe care le folosesc atunci când se referă la asistenții AI. De asemenea, examinăm răspunsurile sistemelor și măsura în care acestea generează producție care este gender și antropomorf. Considerăm că, în timp ce unele companii par să abordeze preocupările etice ridicate, în unele cazuri, afirmațiile lor nu par să fie adevărate. În special, rezultatele noastre arată că rezultatele sistemului sunt ambigue în ceea ce privește umanitatea sistemelor și că utilizatorii tind să le personifice și să le sexeze ca rezultat.</abstract_ro>
      <abstract_so>Shirkadaha Teknolojiyadu waxay samaysteen jawaabo kala duduwan si ay uga fikiraan saamaynta ku saabsan sawirada nidaamka AI-ka-hadalka. Qaar ka mid ah waxay sheegeen in caawiyayaashooda codkoodu aysan ahayn jinsi ama dad la mid ah, in kastoo ay ka muuqato fikrada si ka duwan. Waxaannu isbarbardhignaa aragtidan isticmaalayaasha, baaritaanka ay isticmaalayaan marka loo sheegayo caawiyayaasha AI. Sidoo kale waxaynu baaraynaa jawaabaha nidaamka iyo sida ay u dhashaan midhaha ay ku dhashaan jinsiga iyo jinsiyada. Waxaynu ognahay in marka shirkadaha qaarkood ay u muuqanayaan inay ka sheekeystaan fikrada rasmiga ah, xaaladaha qaarkood ay dacwadeen ma ahan mid run ah. Si gaar ah, resultimahayagu waxay muuqataa in soo baxa nidaamka ay u xiisoodaan biniamka nidaamka, isticmaalayaashuna waxay u baahan yihiin inay si gaar ah u dhigaan oo ay u jinsiyeeyaan.</abstract_so>
      <abstract_sv>Teknikföretag har tagit fram olika svar på farhågor om effekterna av utformningen av sina konversations AI-system. Vissa har hävdat att deras röstassistenter i själva verket inte är könade eller människoliknande, trots att designfunktioner tyder på motsatsen. Vi jämför dessa påståenden med användaruppfattningar genom att analysera pronomen de använder när de hänvisar till AI-assistenter. Vi undersöker också systemens respons och i vilken utsträckning de genererar en produktion som är genusad och antropomorf. Vi konstaterar att även om vissa företag verkar ta itu med de etiska frågor som väckts, verkar deras påståenden i vissa fall inte stämma. Framför allt visar våra resultat att systemresultat är tvetydiga när det gäller systemens humanitet, och att användare tenderar att personifiera och genusföra dem som ett resultat.</abstract_sv>
      <abstract_ta>தொழில்நுட்பம் நிறுவனங்கள் வேறு விளைவுகளை உருவாக்கினார்கள் அவர்கள் உரையாடல் AI முறைமைகளின் வடிவமைப்பு விளைவுகளை பற்ற Some have claimed that their voice assistants are in fact not gendered or human-like-despite design features suggesting the contrary.  AI உதவியாளர்களை குறிப்பிடும் போது அவர்கள் பயன்படுத்தும் விவரங்களை ஆராய்ந்து இந்த கூறுகளை நாம் உதாரணமாக ஒப்பிடு நாம் அமைப்புகளின் பதில்களையும் சோதிக்க வேண்டும் மற்றும் இனம் மற்றும் குறிப்பிட்ட வெளியீட்டை உருவாக்கும் அளவ நாங்கள் கண்டுபிடிக்கிறோம், சில நிறுவனங்கள் உண்மையாக இருக்கும் போது அவர்கள் கூறுகிறார்கள். குறிப்பிட்டு, எங்கள் முடிவுகள் காண்பிக்கிறது அமைப்பு வெளியீடுகள் கணினிகளின் மனிதனுக்கு தேவையானது, மற்றும் பயனர்கள் அதை தனிப்படுத்</abstract_ta>
      <abstract_ur>ٹیکنالوجی کمپنیوں نے اپنے مکالمانی AI سیستموں کی طراحی کے اثرات کے بارے میں نگرانی کے بارے میں مختلف جواب دیں۔ بعض لوگ یہ کہتے ہیں کہ ان کی آواز مددگار حقیقت میں جنس یا انسان جیسا نہیں ہیں اگرچہ ان کی طرح کی مخالفت کی نشانیاں پیش کرتے ہیں. ہم ان معاوضوں کو استعمال کرنے والوں کے مطابق استعمال کرنے کے ذریعے ان معاوضوں کے مطابق استعمال کرتے ہیں. ہم نے بھی سیستموں کی جواب اور کثرت کی تحقیق کرلیا ہے جس طرح انہوں نے اگلوٹ پیدا کیا ہے جو جنسی اور انسانی موروفیک ہے۔ ہم دیکھتے ہیں کہ جب بعض کمپنیوں کو اٹھایا گیا ہے تو بعض موقع میں ان کی تعلیمات سچ نہیں لگتی۔ خاص طور پر، ہمارے نتیجے دکھاتے ہیں کہ سیسٹم کے نتیجے سیسٹم کی بشریت کے معاملہ میں مشکل ہیں، اور یہ کہ کارساز ان کے نتیجے کے طور پر شخصی اور جنس کرنے کی کوشش رکھتے ہیں.</abstract_ur>
      <abstract_sr>Tehnološke kompanije su proizveli različite odgovore na zabrinutost na učinak dizajna njihovih razgovornih AI sistema. Neki su tvrdili da njihovi glasovni asistenti zapravo nisu spolni ili ljudski, uprkos dizajnskim karakteristikama koji predlažu suprotno. Uspoređujemo te tvrdnje sa percepcijama korisnika analizirajući izraze koje koriste kada se odnose na pomoćnike AI-a. Takoðe pregledavamo odgovore sistema i razinu u kojoj stvaraju izlaz koji je spolno i antropomorfski. Mi smatramo da, iako se neki kompaniji čine da se rješavaju etičkim zabrinutostima, u nekim slučajevima, njihova tvrdnja ne čini istinskom. Posebno, naši rezultati pokazuju da su rezultati sistema dvosmisleni za ljudskost sustava, i da korisnici tendiraju da ih osobiziraju i spoluju kao rezultat toga.</abstract_sr>
      <abstract_si>ටෙක්නොක්ලෝජානික සම්පූර්ණයෙන් වෙනස් ප්‍රතික්‍රියාත්මක ප්‍රතික්‍රියාත්මක කරලා තියෙනවා එයාලගේ  සමහර දෙනෙක් කිව්වා ඔවුන්ගේ ශබ්ද උදව්වක් ඇත්තටම ජීවත් වෙන්නේ නැහැ නැහැ නැහැ නැහැ මිනිස් වගේ වි අපි මේ ප්‍රශ්නයක් පාවිච්චි බලන්න ප්‍රශ්නයක් විශ්ලේෂනය කරන්නේ AI උදව්වකයන්ට ප්‍රශ්නයක් කරන්න. අපි පද්ධතියේ ප්‍රතික්‍රියාව සහ ප්‍රතික්‍රියාව පරීක්ෂා කරනවා ඒ වගේම ඔවුන් ප්‍රතික්‍රියාත්මක විදියට ප්‍රත අපිට හොයාගන්න පුළුවන් විදියට, සමහර සමාගම් සමාගම් වලින් විශ්වාස කරනවා කියලා, සමහර විදියට, ඔවුන්ගේ අවශ විශේෂයෙන්, අපේ ප්‍රතිචාරය පෙන්වන්නේ පද්ධතිය ප්‍රතිචාරය ප්‍රතිචාරයක් පද්ධතියේ මානසිකත්වය ගැන, ඒ වගේම ප්‍රයෝ</abstract_si>
      <abstract_uz>Teknolojiy kompaniyalar ularning chaqaloqlar AI tizimlarining dizayning effektlarini haqida ishlash uchun har xil javoblar beradi. Ba'zilari dizayning xususiyatlarini aytib berishi haqida tovush yordamchilari o'ylab ko'rinishi mumkin. Biz buni foydalanuvchilarga tasavvur qilamiz, SI yordamchilarini tasavvur qilayotganda foydalanuvchilarga aniqlash mumkin. Biz tizimning javoblarini ko'rib o'rganamiz. Ular geng'ri va anthropomorfik natijasi yaratish darajasini o'rganamiz. We find that, while some companies appear to be addressing the ethical concerns raised, in some cases, their claims do not seem to hold true.  Bizning natijalarimiz tizimning natijalari tizimning insonligiga qiyin tugadi, va foydalanuvchilar ularni shaxsiy va ijodkorga qaramadi.</abstract_uz>
      <abstract_vi>Công ty công nghệ đã tạo ra nhiều phản ứng khác nhau với những lo ngại về tác động của thiết kế cấu trúc của hệ thống AI đối thoại. Một số người khẳng định rằng các trợ lý giọng nói của họ không phải là nhân tạo hay con người mặc dù thiết kế khác. Chúng ta so sánh những yêu cầu này với nhận thức của người dùng bằng cách phân tích các đại từ sử dụng khi gọi là nhân viên AI. Chúng tôi cũng nghiên cứu các phản ứng của hệ thống và kích thước chúng tạo ra sản phẩm được hình thành từ nhân loại và nhân vật. Chúng tôi thấy rằng, trong khi một số công ty có vẻ đang giải quyết các vấn đề đạo đức được đưa ra, thì trong một số trường hợp, các yêu cầu của họ dường như không đúng. Đặc biệt, kết quả của chúng ta cho thấy kết quả hệ thống là mơ hồ về sự nhân tính của hệ thống, và người dùng có xu hướng nhân cách và làm họ giống nhau.</abstract_vi>
      <abstract_bg>Технологичните компании дават разнообразни отговори на притесненията относно ефектите от проектирането на техните разговорни системи с изкуствен интелект. Някои твърдят, че техните гласови асистенти всъщност не са полови или човешки, въпреки че дизайнерските характеристики предполагат обратното. Сравняваме тези твърдения с възприятията на потребителите, като анализираме местоименията, които използват при позоваване на асистенти по изкуствен интелект. Също така изследваме реакциите на системите и степента, до която те генерират продукция, която е полово и антропоморфна. Установяваме, че макар някои дружества да разглеждат повдигнатите етични опасения, в някои случаи техните твърдения изглежда не са верни. По-конкретно, нашите резултати показват, че системните изходи са двусмислени по отношение на хуманността на системите и че потребителите са склонни да ги олицетворяват и правят полов пол в резултат на това.</abstract_bg>
      <abstract_hr>Tehnologijske kompanije su proizveli različite odgovore na brige o učinama dizajna njihovih razgovornih AI sustava. Neki su tvrdili da njihovi glasovni asistenti zapravo nisu spolni ili ljudi slični uprkos dizajnskim karakteristikama koji sugeriraju suprotno. Uspoređujemo te tvrdnje sa percepcijama korisnika analizirajući izraze koje koriste kada se odnose na pomoćnike AI-a. Također pregledamo odgovore sustava i mjeru u kojoj proizvode proizvodnju spola i antropomorfa. Mi smatramo da, iako se neki kompaniji čini da se rješavaju etičkim zabrinutostima, u nekim slučajevima, njihova tvrdnja čini se da nisu istina. Posebno, naši rezultati pokazuju da su rezultati sustava dvosmisleni za ljudskost sustava, i da korisnici tendiraju da ih osobiziraju i spoluju kao rezultat toga.</abstract_hr>
      <abstract_nl>Technologiebedrijven hebben gevarieerde antwoorden gegeven op bezorgdheid over de effecten van het ontwerp van hun conversationele AI-systemen. Sommigen beweren dat hun stemassistenten in feite niet geslachtsgebonden of menselijk zijn, ondanks ontwerpkenmerken die het tegendeel suggereren. We vergelijken deze claims met de percepties van gebruikers door de voornaamwoorden te analyseren die ze gebruiken wanneer ze verwijzen naar AI-assistenten. We onderzoeken ook de reacties van systemen en de mate waarin ze gendergerelateerde en antropomorfe output genereren. Hoewel sommige bedrijven de ethische bezwaren lijken aan te pakken, blijkt dat hun beweringen in sommige gevallen niet waar lijken te zijn. Onze resultaten tonen met name aan dat systeemoutputs dubbelzinnig zijn over de menselijkheid van de systemen, en dat gebruikers de neiging hebben om ze te personifiëren en te genderen als gevolg daarvan.</abstract_nl>
      <abstract_da>Teknologiske virksomheder har givet forskellige svar på bekymringer over virkningerne af designet af deres samtale AI-systemer. Nogle har hævdet, at deres stemmeassistenter i virkeligheden ikke er kønnede eller menneskelige-lignende – trods designfunktioner tyder på det modsatte. Vi sammenligner disse påstande med brugernes opfattelse ved at analysere de stedord, de bruger, når de refererer til AI-assistenter. Vi undersøger også systemernes reaktioner og i hvilket omfang de genererer kønsbaseret og menneskeligt output. Vi finder, at selv om nogle virksomheder ser ud til at tage fat på de etiske bekymringer, der er rejst, synes deres påstande i nogle tilfælde ikke at være sande. Vores resultater viser især, at systemoutput er tvetydige med hensyn til systemernes menneskelighed, og at brugerne har tendens til at personificere og kønne dem som følge heraf.</abstract_da>
      <abstract_de>Technologieunternehmen haben vielfältige Antworten auf Bedenken hinsichtlich der Auswirkungen des Designs ihrer konversativen KI-Systeme abgegeben. Einige behaupten, dass ihre Sprachassistenten tatsächlich nicht geschlechtsspezifisch oder menschenähnlich sind – obwohl Designmerkmale das Gegenteil nahelegen. Wir vergleichen diese Behauptungen mit Nutzerwahrnehmungen, indem wir die Pronomen analysieren, die sie beim Bezug auf KI-Assistenten verwenden. Wir untersuchen auch die Reaktionen von Systemen und das Ausmaß, in dem sie geschlechtsspezifische und anthropomorphe Outputs erzeugen. Wir stellen fest, dass, obwohl einige Unternehmen die aufgeworfenen ethischen Bedenken zu adressieren scheinen, ihre Behauptungen in einigen Fällen nicht wahr zu sein scheinen. Insbesondere zeigen unsere Ergebnisse, dass Systemergebnisse in Bezug auf die Menschlichkeit der Systeme mehrdeutig sind und dass Nutzer dazu neigen, sie zu personifizieren und zu gendern.</abstract_de>
      <abstract_id>Perusahaan teknologi telah menghasilkan respons berbagai macam terhadap kekhawatiran tentang efek desain sistem AI konversasi mereka. Some have claimed that their voice assistants are in fact not gendered or human-like-despite design features suggesting the contrary.  We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants.  Kami juga memeriksa respon sistem dan jangkauan mereka menghasilkan output yang jenis dan antropomorfik. Kami menemukan bahwa, sementara beberapa perusahaan tampaknya sedang mengatasi kekhawatiran etik yang diberikan, dalam beberapa kasus, klaim mereka tampaknya tidak benar. Terutama, hasil kita menunjukkan bahwa hasil sistem adalah ambigus tentang kemanusiaan sistem, dan bahwa pengguna cenderung untuk personifikasi dan jenis mereka sebagai hasil.</abstract_id>
      <abstract_ko>과학기술회사들은 대화 인공지능 시스템 설계의 영향에 대한 우려에 대해 다른 반응을 보였다.일부 사람들은 그들의 음성 조수가 사실상 성별이나 인성화되지 않았다고 주장한다. 비록 디자인 특징이 이와 상반되지만.우리는 사용자가 인공지능 조수를 언급할 때 사용하는 대명사를 분석함으로써 이러한 견해를 사용자의 인지와 비교한다.우리는 또 체계적인 반응과 그것들이 성별화와 의인화 수출을 일으키는 정도를 연구했다.우리는 비록 일부 회사들이 제기한 도덕적 문제를 해결하고 있는 것 같지만, 어떤 상황에서는 그들의 견해가 정확하지 않은 것 같다는 것을 발견했다.특히 우리의 결과에 따르면 시스템 출력은 시스템의 인성화에 대해 명확하지 않기 때문에 사용자들은 이를 인격화하고 성별화하는 경향이 있다.</abstract_ko>
      <abstract_fa>شرکتهای تکنولوژی جواب های متفاوتی برای نگرانی در مورد تاثیرات طراحی سیستم های AI مکالمانی آنها تولید کرده اند. بعضی از مردم ادعا کردند که دستیاران صداشون در حقیقت جنسی و انسانی نیستند، با وجود طراحی ویژه های مخالفت را پیشنهاد می کنند. ما این ادعا را با احساسات کاربر با تحلیل کردن ادعای استفاده می‌کنند در حالی که به دستیاران AI ارتباط می‌دهند مقایسه می‌کنیم. ما همچنین پاسخ های سیستم‌ها و اندازه‌ای که آنها نتیجه‌های جنسی و انسان‌پورفیک را تولید می‌کنند را تحقیق می‌کنیم. ما فهمیدیم که، در حالی که بعضی از شرکتها به نظر می رسد که درباره نگرانی اخلاقی که در بعضی مواقع بالا اومده اند، ادعایشان به نظر نمی رسد که حقیقت ندارند. در خصوص، نتیجه‌های ما نشان می‌دهند که نتیجه‌های سیستم در مورد انسانی سیستم‌ها مشغول است، و کاربران به عنوان نتیجه آنها را به شخصی و جنسی می‌رسانند.</abstract_fa>
      <abstract_tr>Tehnologiýa kompaniýalary öz taryşma AI sistemalarynyň netijesi barada çykyp jogaplary üretdiler. Käbirleri sesli kömekçileriniň cins ýaly däldigini aýtdylar. Gerçekten däldigine garamazdan hem adam ýaly bir şekilde garşy maslahat bermeýändigini aýtdylar. Biz bu hasaplaryny AI kömekçilerine görä ulanylaryň nämelerini analyz edip brûkalaryň pikirlerine karşılaştyrýarys. Biz sistemlerin cevaplarını ve cinsel ve antropomorfik şeklinde çykarýan çözümlerini inceledik. Biziň pikirimçe, käbir kompaniýalaryň etik aladalaryny çykyp görünýän bolanynda, käbir wagtda olaryň iddialarynyň dogry ýaly görünmeýär. Şeýleki netijelerimiz sistemanyň netijesi sistemalaryň ynsanlygyna görä a ýratyn bolandygyny görkezýäris we onuň netijesi bolan adamlary tanyşdyryp, adamlary tanyşdyryp bilýändigini görkezýäris.</abstract_tr>
      <abstract_sw>Makampuni ya teknolojia yametengeneza majibu mbalimbali ya wasiwasi kuhusu madhara ya ubunifu wa mifumo ya UKI ya mazungumzo yao. Baadhi ya watu wamedai kwamba wasaidizi wao wa sauti ni ukweli hawana jinsia au wale wa binadamu pamoja na utoaji wa ubunifu unaoonyesha kinyume chake. Tunawalinganisha madai haya kwa mtazamo wa watumiaji kwa uchambuzi wa kauli wanazotumia pale tunawaelezea wasaidizi wa AI. Pia tunachunguza majibu ya mifumo na kwa kiwango ambacho wanatengeneza matokeo yanayozaliwa na maarufu. Tunafikiri kwamba, wakati makampuni mengine yanaonekana kuwa yanazungumzia wasiwasi wa kimaadili, katika baadhi ya matukio hayo, madai yao hayaonekana kuwa kweli. Kwa hakika, matokeo yetu yanaonyesha kwamba matokeo ya mfumo yanakuwa na hamasa ya kibinadamu wa mifumo, na kwamba watumiaji huenda kuwaweka binafsi na kuzingatia matokeo yake.</abstract_sw>
      <abstract_sq>Kompanitë e teknologjisë kanë prodhuar përgjigje të ndryshme ndaj shqetësimeve rreth efekteve të dizajnit të sistemeve të tyre AI konversuese. Some have claimed that their voice assistants are in fact not gendered or human-like-despite design features suggesting the contrary.  We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants.  Ne gjithashtu shqyrtojmë përgjigjet e sistemeve dhe shkallën në të cilën ato gjenerojnë dalje që është gjenerale dhe antropomorfike. Ne gjejmë se ndërsa disa kompani duket se po trajtojnë shqetësimet etike të ngritura, në disa raste pretendimet e tyre nuk duken të vërteta. Në veçanti, rezultatet tona tregojnë se rezultatet e sistemit janë të qarta në lidhje me njerëzimin e sistemeve dhe se përdoruesit kanë tendencë t'i personifikojnë dhe gjinorojnë si rezultat.</abstract_sq>
      <abstract_af>Teknologiese maatskappye het verskillende antwoordes aan bekommerde aangaande die effekte van die ontwerp van hul omskakelike AI-stelsels produseer. Sommige het aanbeveel dat hulle stem assistente is in werklikheid nie gegend of menslike-onderwerp van ontwerp funksies wat die teenstemming voorstel nie. Ons vergelyk hierdie aansoek met gebruiker aansoek deur die uitsoek wat hulle gebruik word wanneer hulle verwys na AI assistente. Ons ondersoek ook die antwoordes van stelsels en die uitbreiding waarmee hulle uitvoer genereer het wat genereer is en antropomorpie. Ons vind dat, terwyl sommige maatskappye verskyn om die etiese bekommerings te besluit, in sommige gevalle, hulle aansoek lyk nie waar te hou nie. In besonderhede, ons resultate wys dat stelsel uitvoerdes onveranderlike is as die menslike van die stelsels, en dat gebruikers hulle as gevolg persoonlike en geneem het.</abstract_af>
      <abstract_am>የቴክኖሎጂ ኮምፒዩተርናዎች በተለያዩ መልስ አካሄዱን የኢ ሲስተም አካባቢ ግንኙነታቸውን የሚያስከትሩ ናቸው፡፡ አንዳንዶቹ የድምፅ ረዳቶቻቸው በተቃወመ ጥናት ምንም እንኳ እንደሆነ፣ gender ወይም በሰው የሚመስሉ ናቸው ብለው ተናግረዋል፡፡ እነዚህንም አካባቢዎች ወደ AI ተሟጋቾች ሲጠይቁ በሚጠይቁት ድረ ገጽ በማስተካከል እናሳያታለን፡፡ የስርዓት መልስ እና የውጤት ውጤት መፍጠርን እናደርጋለን፡፡ አንዳንዶች ኮምፒውተሮች የኢትዮጵያውያን አዋቂዎች ለመቀላቀል ሲመስሉ፣ አንዳንድ ጉዳይ እውነተኛ መሆኑን አይመስልም፡፡ በተለይም ፍሬዎቻችን የሲስተም ውጤቶች የስብተኞቹን አካባቢ እና ተጠቃሚዎች ይደነግጡታል፡፡</abstract_am>
      <abstract_hy>Տեխնոլոգիական ընկերությունները արտադրել են բազմազան պատասխաններ մտահոգվածություններին իրենց խոսակցական ԱԲ համակարգերի կառուցվածքի ազդեցության մասին: Some have claimed that their voice assistants are in fact not gendered or human-like-despite design features suggesting the contrary.  Մենք համեմատում ենք այս փաստարկները օգտագործողների ընկալումների հետ վերլուծելով արտահայտությունները, որոնք նրանք օգտագործում են ԱԲ-ի օգնականներին խոսելիս: Մենք նաև ուսումնասիրում ենք համակարգերի արձագանքները և այն, թե որքան են դրանք ստեղծում գենդերային և անտրոպոմորֆիկ արդյունք: Մենք հայտնաբերում ենք, որ մինչ որոշ ընկերություններ, թվում է, լուծում են բարոյական խնդիրները, որոշ դեպքերում, նրանց փաստարկները ճշմարիտ չեն թվում: In particular, our results show that system outputs are ambiguous as to the humanness of the systems, and that users tend to personify and gender them as a result.</abstract_hy>
      <abstract_bs>Tehnološke kompanije su proizveli različite odgovore na zabrinutost na učinak dizajna njihovih razgovornih AI sustava. Neki su tvrdili da njihovi glasovni asistenti zapravo nisu spolni ili ljudi slični uprkos dizajnskim karakteristikama koji sugeriraju suprotno. Uspoređujemo te tvrdnje sa percepcijama korisnika analizirajući izraze koje koriste kada se odnose na pomoćnike AI-a. Također pregledavamo odgovore sistema i mjeru u kojoj proizvode izlaz koji je spolno i antropomorfski. Mi smatramo da, iako se neki kompaniji čini da se rješavaju etičkim zabrinutostima, u nekim slučajevima, njihova tvrdnja čini se da nisu istina. Posebno, naši rezultati pokazuju da su rezultati sustava dvosmisleni za ljudskost sustava, i da korisnici tendiraju da ih osobiziraju i spoluju kao rezultat toga.</abstract_bs>
      <abstract_az>Teknolojik kompaniyaları öz müzakirçi AI sistemlərinin dizaynının təsirlərinə görə dəyişiklik cavab vermişdir. Bazıları dedilər ki, səs köməkçiləri həqiqətən cins və insan kimi deyildir. Biz bu iddiaları istifadəçilərin fikirlərinə qarşılaşdırırıq, AI köməkçiləri ilə istifadə edirlər. Biz də sistemlərin cavablarını və cinsel və antropomorphic ürəklərinin nəticəsini çəkirik. Bazı şirketlər etik baxışlarına baxmayaraq, bəzi vaxtlarda onların iddiaları do ğru deyil. Özellikle, sistem sonuçlarımızın sistemlərin insanlığı barəsində müxtəlif olduğunu göstərir, və istifadəçilərin sonuçlarına görə onları təhsil edir və cins edirlər.</abstract_az>
      <abstract_bn>প্রযুক্তিগত কোম্পানিগুলো বিভিন্ন প্রতিক্রিয়া তৈরি করেছে যাতে তারা আলোচনাকারী AI সিস্টেমের ডিজাইনের প্রভাব নি কেউ কেউ দাবি করেছেন যে তাদের কণ্ঠস্বর সহকারীরা আসলে লিঙ্গ অথবা মানুষের মতো কোন ধরনের ডিজাইনের বৈশিষ্ট্য প্রদান করেছ আমরা এই দাবি ব্যবহারকারীর দৃষ্টিভঙ্গি ব্যবহারকারীদের তুলনা করি এইআই সাহায্যকারীদের উল্লেখ করার সময় তারা ব্যবহার করে য আমরা সিস্টেমের প্রতিক্রিয়া পরীক্ষা করি এবং তারা যে পর্যায়ে আউটপুট তৈরি করে তা যা লিঙ্গ এবং মানুষের প্রতিক্রিয়া। আমরা খুঁজে পাচ্ছি যে, কিছু কোম্পানিগুলো নৈতিক উদ্বেগের বিষয় নিয়ে কথা বলছে, কিছু ক্ষেত্রে তাদের দাবি সত্য মনে হচ্ছে না। বিশেষ করে আমাদের ফলাফল দেখাচ্ছে যে সিস্টেমের মানবাধিকারের ব্যাপারে সিস্টেমের আউটপুটগুলো বিবেচনা করে এবং এর ফলে ব্যবহারকারীরা তা</abstract_bn>
      <abstract_cs>Technologické společnosti vytvořily různé reakce na obavy ohledně dopadů návrhu svých konverzačních systémů AI. Někteří tvrdí, že jejich hlasové asistenty ve skutečnosti nejsou pohlavní nebo lidské – navzdory designovým prvkům naznačujícím opak. Tyto tvrzení porovnáváme s vnímáním uživatelů analýzou zájmen, která používají při odkazu na asistenty AI. Dále zkoumáme reakce systémů a do jaké míry generují genderový a antropomorfní výstup. Zjišťujeme, že i když se zdá, že některé společnosti řeší vznesené etické obavy, v některých případech se jejich tvrzení zdá být pravdivé. Konkrétně naše výsledky ukazují, že systémové výstupy jsou nejednoznačné, pokud jde o lidskost systémů, a že uživatelé mají tendenci je zosobňovat a pohlaví v důsledku toho.</abstract_cs>
      <abstract_ca>Les empreses tecnològiques han produït diverses respostes a les preocupacions sobre els efectes del disseny dels seus sistemes d'AI conversacionals. Alguns han afirmat que els seus assistents de veu no són de fet de gènere ni de tipus humà malgrat el disseny que suggereix el contrari. We compare these claims to user perceptions by analysing the pronouns they use when referring to AI assistants.  També examinem les respostes dels sistemes i la mesura en què generen producció que és general i antropomòrfic. Trobem que, mentre que algunes empreses semblen estar abordant les preocupacions ètiques planteades, en alguns casos, les seves afirmacions no semblen ser certes. En particular, els nostres resultats mostren que els resultats del sistema són ambiguos en relació a la humanitat dels sistemes, i que els usuaris tendeixen a personificar-los i fer-los gènere com a resultat.</abstract_ca>
      <abstract_et>Tehnoloogiaettevõtted on andnud erinevaid vastuseid muredele nende vestluslike AI süsteemide projekteerimise mõju pärast. Mõned on väitnud, et nende hääleabistajad ei ole tegelikult soolised ega inimlikud, vaatamata disaini omadustele, mis viitavad vastupidisele. Me võrdleme neid väiteid kasutajate arusaamadega, analüüsides nende poolt AI assistentidele viitamisel kasutatavaid asenimesid. Samuti uurime süsteemide reaktsioone ja seda, mil määral need tekitavad soolist ja antropomorfset väljundit. Leiame, et kuigi mõned ettevõtted näivad käsitlevad tõstatatud eetilisi probleeme, ei paista mõnel juhul nende väited tõesed olevat. Eelkõige näitavad meie tulemused, et süsteemi väljundid on süsteemide inimlikkuse osas ebaselged ning et kasutajad kipuvad neid seetõttu isiksustama ja sooliselt sooliselt sooliselt sooliselt sooliselt.</abstract_et>
      <abstract_fi>Teknologiayritykset ovat tuottaneet erilaisia vastauksia keskusteluiden tekoälyjärjestelmien suunnittelun vaikutuksiin. Jotkut ovat väittäneet, että heidän puheavustajansa eivät itse asiassa ole sukupuolisia tai inhimillisiä, vaikka suunnitteluominaisuudet viittaavat päinvastaiseen. Vertailemme näitä väitteitä käyttäjien käsityksiin analysoimalla pronomineja, joita he käyttävät viitatessaan tekoälyavustajiin. Tutkimme myös järjestelmien vasteita ja sitä, missä määrin ne tuottavat sukupuoleen perustuvaa ja antropomorfista tuotosta. Olemme havainneet, että vaikka jotkin yritykset näyttävät tarttuvan esiin tuotuihin eettisiin huolenaiheisiin, joissakin tapauksissa niiden väitteet eivät näytä pitävän paikkansa. Erityisesti tulokset osoittavat, että järjestelmän tuotokset ovat epäselviä järjestelmien inhimillisyyden suhteen ja että käyttäjät pyrkivät hahmottamaan ja sukupuolistamaan niitä.</abstract_fi>
      <abstract_ha>Umarni na Technical sun ƙãga masu karɓar dabam-dabam domin su yi wasiyya ga aikin designi na'urar AI da ake yi musu magana. Babu daga cikinsu, sun ce cewa mataimakarsu da sautinsu ba su zama jinsiga ba, kuma kõ da yaushe wasu misãlai da ke son mutum, sun faɗa da kinyume. Munã buga misãlai da waɗannan suna misãlai ga misãlai ga misãlai da za'a yi amfani da su idan sun faɗa mataimaki na AI. Kayya, Munã jarraba majibu na'urar system da gwargwadon da za su zata fitarwa wanda za'a zafi da mutane. Muna gane cewa, a lokacin da wasu makampuni na kamfata su yi addu'a ga matsayin da aka haife su, da wasu kashfiya, daidai ba ta zace gaskiya ba. Kayyai, matsalayinmu na nũna cewa matsalar na'urar na'urar na'urar na'urar na'ura, kuma misãlai za'a zafi su mutane su da jini matsayi.</abstract_ha>
      <abstract_sk>Tehnološka podjetja so ustvarila različne odzive na pomisleke glede učinkov oblikovanja njihovih pogovornih sistemov AI. Nekateri so trdili, da njihovi glasovni pomočniki dejansko niso spolni ali človeški podobni – kljub oblikovalskim značilnostim kažejo nasprotno. Te trditve primerjamo z dojemanjem uporabnikov z analizo zaimkov, ki jih uporabljajo pri sklicevanju na pomočnike umetne inteligence. Preučujemo tudi odzive sistemov in obseg, v katerem ustvarjajo spolno in antropomorfno produkcijo. Ugotavljamo, da čeprav nekatera podjetja obravnavajo izražene etične pomisleke, se zdi, da njihove trditve v nekaterih primerih ne držijo resnične. Naši rezultati kažejo zlasti, da so rezultati sistema dvoumni glede človeškosti sistemov in da jih uporabniki posledično poosebljajo in spolno spolno spolno spolno spolnost.</abstract_sk>
      <abstract_he>חברות טכנולוגיה יצרו תשובות שונות לדאגה על השפעות של עיצוב מערכות השיחה שלהם AI. חלקם טענו שעוזרים הקול שלהם למעשה אינם מיני או דמות בני אדם למרות תכנונים שמצייעים את ההפך. אנחנו משוותים את הטענות האלה לתפיסה של משתמשים על ידי ניתוח את המילים שהם משתמשים כאשר מתייחסים לעוזרים AI. אנחנו גם בודקים את התגובות של המערכות, ואת המידה שבה הם יוצרים תוצאה שהיא מינית ואנטרופומורפית. אנו מוצאים כי, בעוד כמה חברות נראות מתמודדות עם הדאגה האתית שגורמת, במקרים מסוימים, הטענות שלהם לא נכונות. במיוחד, התוצאות שלנו מראות כי יציאות המערכת הן ספורות בנוגע לאנושות המערכות, ושמשתמשים נוטים לאדם ולגזע אותם כתוצאה מכך.</abstract_he>
      <abstract_fil>Mga teknolojiya ay nagsigawa ng ibang sagot sa mga pakialam tungkol sa mga effekto ng disenyo ng kanilang conversational AI systems. Ang ilan ay nagsisipagsabi na ang kanilang voice assistant ay hindi gaya ng lahi o gaya ng tao, kahit ang mga pagsasanggalang ay nagbibigay ng pagbabagsak. Ito ang mga pangangailangan namin ay pinakikipagtibay sa mga pangangailangan ng gamit sa pamamagitan ng pag-analisay ng mga pangangailangan na ginagamit sa pagbibigay sa mga assistente ng AI. Tinutunaw din namin ang mga sagot ng mga sistema at ang kadahilanan ng kanilang ginagawa ng output na nagnganak at anthropomorphic. Nasusumpungan natin na, samantalang ang ilan ng mga kompaniya ay nagtataglay ng mga kabagabagan ng etika, sa ilang mga paraan, ang kanilang mga pangangailangan ay walang katotohanan. Katotohanan, ang aming mga result a ay nagpapakita na ang mga outputs ng sistema ay walang kabuluhan tungkol sa pagkatao ng mga sistema, at ang mga gamit ay nagtataglay sa pagkatao at nagkakaanak sa kanila dahil sa resulta.</abstract_fil>
      <abstract_bo>ལག་རྩལ་གྱི་སྡོམ་འབྲེལ་གྱི་དབང་རྩལ་ཆ་སྤྱི་ཚོགས་ཀྱི་གནོད་འགྱུར་བ་དང་བརྗོད་མ་འདྲ་བྱས་ཡོད། ལ་ཅིག་ཁོང་ཚོའི་སྐད་བརྡ་གྲོགས་རམ་བྱེད་མཁན་གྱི་རྣམ་པ་དང་མི་འདྲ་བ་གཉིས་ཀྱི་ལས་འགུལ་གྱི་ཁྱད་ཆོས་ལ་བསྟུན་ནས་ ང་ཚོས་ལག་ལེན་པའི་བསམ་ཚུལ་འདི་དག་གི་རྟོགས་པ་ཚོར་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡོད་པ་དང་མཉམ་བསྡུར་བྱེད་ཀྱི་ཡོད། ང་ཚོས་མ་ལག་གི་ལན་གསལ་བཤད་དང་གཟའ་རིམ་ལ་ཞིབ་དཔྱད་ཀྱི་ཡོད། ང་ཚོའི་ནང་དུ་ཚོང་འབྲེལ་མཐུད་གཞན་ཞིག་ཀྱང་དཀའ་རིགས་ཀྱི་ཞལ དམིགས་བསལ་ན། ང་ཚོའི་འབྲས་འབྲས་བ་ནི་མ་ལག་གི་ཆེད་མཁན་གྱི་མི་མང་པོ་ཞིག་ཡིན་ཏེ།</abstract_bo>
      <abstract_jv>empresi teknêlogi wis arep bantayan gambarang nggawe barang nggawe barang nggawe nguasar sistem AI conversations barang. Genjer-genjer paling kelas sing paling kelas kuwi, kuwi mau ngomong nik pakan kelas liyan karo perbudhakan maneh. Awak dhéwé nggawe perusahaan karo perusahaan langgar sapa-perusahaan neng dadi pangrungu sing isiné nang sampek kang AI. Awak dhéwé éntuk éntukne gambarang sistem lan padha mengko perusahaan sing nggawe winih sing katêpakan karo perusahaan bantêr. Awak dhéwé ngerti, nganggep nek alam sing paling nggawe perusahaan etik iki, ning kelambah sing apik, sawetara sak durung ono ora iso nggawe tenan. Mangkane, awak dhéwé dipontong ing sistem sing dikarepaké awak dhéwé ning barang-barang iki dadi sing luwih apik, lan uwong-alam kuwi kesempatan kanggo ngerasah karo hal-salang iki dadi.</abstract_jv>
      </paper>
    <paper id="5">
      <title>Gender Bias in Text : Origin, Taxonomy, and Implications</title>
      <author><first>Jad</first><last>Doughman</last></author>
      <author><first>Wael</first><last>Khreich</last></author>
      <author><first>Maya</first><last>El Gharib</last></author>
      <author><first>Maha</first><last>Wiss</last></author>
      <author><first>Zahraa</first><last>Berjawi</last></author>
      <pages>34–44</pages>
      <abstract>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions. Applications powered by Artificial Intelligence (AI) are increasingly being used in the real world to provide critical decisions about who is going to be hired, granted a loan, admitted to college, etc. However, the main pillars of <a href="https://en.wikipedia.org/wiki/Artificial_intelligence">AI</a>, <a href="https://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing (NLP)</a> and <a href="https://en.wikipedia.org/wiki/Machine_learning">Machine Learning (ML)</a> have been shown to reflect and even amplify <a href="https://en.wikipedia.org/wiki/Gender_bias">gender biases</a> and stereotypes, which are mainly inherited from historical training data. In an effort to facilitate the identification and mitigation of <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> in English text, we develop a comprehensive taxonomy that relies on the following <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias types</a> : Generic Pronouns, <a href="https://en.wikipedia.org/wiki/Sexism">Sexism</a>, Occupational Bias, Exclusionary Bias, and <a href="https://en.wikipedia.org/wiki/Semantics">Semantics</a>. We also provide a bottom-up overview of <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a>, from its societal origin to its spillover onto language. Finally, we link the societal implications of <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> to their corresponding type(s) in the proposed <a href="https://en.wikipedia.org/wiki/Taxonomy_(biology)">taxonomy</a>. The underlying motivation of our work is to help enable the technical community to identify and mitigate relevant biases from training corpora for improved fairness in NLP systems.</abstract>
      <url hash="8a6bc4f6">2021.gebnlp-1.5</url>
      <doi>10.18653/v1/2021.gebnlp-1.5</doi>
      <bibkey>doughman-etal-2021-gender</bibkey>
    <title_fr>Préjugés sexistes dans le texte : origine, taxonomie et implications</title_fr>
      <title_ar>التحيز الجنساني في النص: الأصل ، التصنيف ، والآثار</title_ar>
      <title_pt>Preconceito de gênero no texto: origem, taxonomia e implicações</title_pt>
      <title_es>El sesgo de género en el texto: origen, taxonomía e implicaciones</title_es>
      <title_ja>テキストにおけるジェンダーバイアス：起源、分類、および含意</title_ja>
      <title_zh>文本性别偏见:起源、分类、义义</title_zh>
      <title_ru>Гендерная предвзятость в тексте: происхождение, таксономия и последствия</title_ru>
      <title_ga>Laofacht Inscne sa Téacs: Bunús, Tacsanomaíocht agus Impleachtaí</title_ga>
      <title_hi>पाठ में लिंग पूर्वाग्रह: मूल, वर्गीकरण, और निहितार्थ</title_hi>
      <title_ukr>Гендерна упередженість у тексті: походження, таксономія та наслідки</title_ukr>
      <title_el>Διαταραχές φύλου στο κείμενο: Προέλευση, Ταξινομία και Επιπτώσεις</title_el>
      <title_isl>Kynlíf í texta: Upprun, skattfræði og áhrif</title_isl>
      <title_hu>A nemek közötti eltérések a szövegben: eredet, taxonómia és következmények</title_hu>
      <title_it>Bias di genere nel testo: origine, tassonomia e implicazioni</title_it>
      <title_ka>ტექსტში გენერი ბიაი: წარმოდგენა, რაკონომია და ამომპლექციები</title_ka>
      <title_kk>Мәтінде гендер биасы: Бастапқы, Таксония, және Импликациялар</title_kk>
      <title_mk>Порасни поени во текстот: потекло, таксономија и импликации</title_mk>
      <title_lt>Lyčių skirtumai tekste: kilmė, taksonomija ir pasekmės</title_lt>
      <title_mt>Gender Bias in Text: Origin, Taxonomy, and Implications</title_mt>
      <title_no>Gender Bias i tekst: Original, taksonomie og implementasjonar</title_no>
      <title_ms>Gender Bias in Text: Origin, Taxonomy, and Implications</title_ms>
      <title_ro>Bias gen în text: origine, taxonomie și implicații</title_ro>
      <title_mn>Текст дахь гендер Биас: эх үүсвэр, Таксономийн болон Амжилт</title_mn>
      <title_ml>പദാവലിയിലെ പെണ്ണ് ബിയാസ്: Origin, Taxonomy, and Implications</title_ml>
      <title_so>Sida uu ku qoro qoraal: Origin, Taxonomy, Implications</title_so>
      <title_sr>Gender Bias u tekstu: porijeklo, taksonomija i Implicije</title_sr>
      <title_si>පාළුවේ ජෙන්ඩර් බියාස්: ප්‍රභාව, ටැක්සොනෝමි, සහ ප්‍රභාවිතය</title_si>
      <title_ta>உரையில் பெண் பியாஸ்: Origin, Taxonomy and Implications</title_ta>
      <title_pl>Uprzedzenia płci w tekście: pochodzenie, taksonomia i konsekwencje</title_pl>
      <title_sv>Genus Bias i text: Ursprung, taxonomi och konsekvenser</title_sv>
      <title_ur>پیغام میں جنس بیس: اصل، تاکسونمی، اور عملومات</title_ur>
      <title_uz>Origin, Taxonomy and Implications</title_uz>
      <title_vi>Giới tính Âm thanhName</title_vi>
      <title_bg>Полови предразсъдъци в текста: произход, таксономия и последици</title_bg>
      <title_nl>Gender Bias in Tekst: Oorsprong, Taxonomie en Implicaties</title_nl>
      <title_hr>Gender Bias u tekstu: Original, taksonomija i Implicije</title_hr>
      <title_da>Kønsfordele i tekst: Oprindelse, taksonomi og konsekvenser</title_da>
      <title_id>Gender Bias in Text: Origin, Taxonomy, and Implications</title_id>
      <title_de>Gender Bias in Text: Herkunft, Taxonomie und Implikationen</title_de>
      <title_ko>텍스트의 성별 편견: 기원, 분류와 의미</title_ko>
      <title_fa>جنسی بیس در متن: اصلی، تاکسونمی، و عملیات</title_fa>
      <title_tr>Metin içinde soňra Biýasy: Origin, Taxonomy, and Implications</title_tr>
      <title_af>Gender Bias in Teks: Oorspronklik, Taxonomie en Implikasie</title_af>
      <title_sw>Gender Bias in Text: Origin, Taxonomy, and Implications</title_sw>
      <title_sq>Gender Bias in Text: Origin, Taxonomy, and Implications</title_sq>
      <title_am>Origin, Taxonomy and Implications</title_am>
      <title_hy>Տեքստում գտնվող գենդերային հարաբերությունները՝ ծագումը, տաքսոնամիան և հետևանքները</title_hy>
      <title_ca>Gender Bias in Text: Origin, Taxonomy, and Implications</title_ca>
      <title_bn>লেখায় লিঙ্গ বিয়াস: প্রথম, ট্যাক্সোনোমি এবং ইম্পিলিকেশন</title_bn>
      <title_bs>Gender Bias u tekstu: Original, taksonomija i Implicije</title_bs>
      <title_az>M…ôtnd…ô Gender Bias: M…ôxluq, Taksonomiya v…ô ńįplikasyon</title_az>
      <title_fi>Sukupuolten bias tekstissä: alkuperä, taksonomia ja vaikutukset</title_fi>
      <title_et>Sooline kalduvus tekstis: päritolu, taksonoomia ja tagajärjed</title_et>
      <title_cs>Gender Bias v textu: původ, taxonomie a důsledky</title_cs>
      <title_jv>Kemerdekaan Bias nang Teks: Orijin, Taksino, lan Gambaran</title_jv>
      <title_ha>@ item Text character set</title_ha>
      <title_sk>Spolne pristranskosti v besedilu: izvor, taksonomija in posledice</title_sk>
      <title_fil>Gender Bias sa Text: Origin, Taxonomy, at Implications</title_fil>
      <title_bo>ཚིག་ཡིག་གི་ནང་དུ་ཚོང་མོ་རྣམ་པ། སྔོན་ལྗོད་དང་ཐུག་སྒྲིལ་ནང་དུ་ཡོད་པ།</title_bo>
      <title_he>Gender Bias in Text: Origin, Taxonomy, and Implications</title_he>
      <abstract_pt>A desigualdade de gênero representa uma perda considerável do potencial humano e perpetua uma cultura de violência, maiores disparidades salariais de gênero e falta de representação das mulheres em cargos de chefia e liderança. Aplicativos alimentados por Inteligência Artificial (IA) estão sendo cada vez mais usados no mundo real para fornecer decisões críticas sobre quem será contratado, concedido um empréstimo, admitido na faculdade etc. No entanto, os principais pilares da IA, Processamento de Linguagem Natural ( NLP) e Machine Learning (ML) demonstraram refletir e até ampliar preconceitos e estereótipos de gênero, que são herdados principalmente de dados históricos de treinamento. Em um esforço para facilitar a identificação e mitigação do preconceito de gênero no texto em inglês, desenvolvemos uma taxonomia abrangente que se baseia nos seguintes tipos de preconceito de gênero: pronomes genéricos, sexismo, preconceito ocupacional, preconceito de exclusão e semântica. Também fornecemos uma visão geral de baixo para cima do preconceito de gênero, desde sua origem social até seu transbordamento para a linguagem. Finalmente, vinculamos as implicações sociais do viés de gênero ao(s) tipo(s) correspondente(s) na taxonomia proposta. A motivação subjacente do nosso trabalho é ajudar a comunidade técnica a identificar e mitigar vieses relevantes de corpora de treinamento para melhorar a justiça nos sistemas de PNL.</abstract_pt>
      <abstract_ar>يمثل عدم المساواة بين الجنسين خسارة كبيرة في الإمكانات البشرية ويؤدي إلى استمرار ثقافة العنف ، وزيادة فجوات الأجور بين الجنسين ، ونقص تمثيل المرأة في المناصب العليا والقيادية. يتم استخدام التطبيقات المدعومة بالذكاء الاصطناعي (AI) بشكل متزايد في العالم الحقيقي لتقديم قرارات حاسمة حول من سيتم تعيينه ، ومنح قرض ، وقبول في الكلية ، وما إلى ذلك. ومع ذلك ، فإن الركائز الأساسية للذكاء الاصطناعي ، ومعالجة اللغة الطبيعية ( لقد ثبت أن البرمجة اللغوية العصبية (NLP) والتعلم الآلي (ML) تعكس وحتى تضخيم التحيزات والقوالب النمطية بين الجنسين ، والتي يتم توريثها بشكل أساسي من بيانات التدريب التاريخية. في محاولة لتسهيل تحديد وتخفيف التحيز بين الجنسين في النص الإنجليزي ، نقوم بتطوير تصنيف شامل يعتمد على أنواع التحيز الجنساني التالية: الضمائر العامة ، والتمييز على أساس الجنس ، والتحيز المهني ، والتحيز الإقصائي ، والدلالات. نقدم أيضًا نظرة عامة من أسفل إلى أعلى عن التحيز الجنساني ، من أصله المجتمعي إلى امتداده إلى اللغة. أخيرًا ، نربط الآثار المجتمعية للتحيز الجنساني بالنوع (الأنواع) المقابل في التصنيف المقترح. الدافع الأساسي لعملنا هو المساعدة في تمكين المجتمع التقني من تحديد وتخفيف التحيزات ذات الصلة من هيئة التدريب لتحسين الإنصاف في أنظمة البرمجة اللغوية العصبية.</abstract_ar>
      <abstract_fr>L'inégalité entre les sexes représente une perte considérable de potentiel humain et perpétue une culture de violence, des écarts salariaux plus élevés entre les sexes et un manque de représentation des femmes aux postes supérieurs et de direction. Les applications basées sur l'intelligence artificielle (IA) sont de plus en plus utilisées dans le monde réel pour prendre des décisions critiques quant à savoir qui va être embauché, accordé un prêt, admis à l'université, etc. Cependant, il a été démontré que les principaux piliers de l'IA, du traitement du langage naturel (NLP) et de l'apprentissage automatique (ML) reflètent et amplifient même les préjugés et stéréotypes sexistes, qui sont principalement hérités des données historiques sur la formation. Afin de faciliter l'identification et l'atténuation des préjugés sexistes dans le texte anglais, nous développons une taxonomie complète qui repose sur les types de préjugés sexistes suivants : pronoms génériques, sexisme, biais professionnel, biais d'exclusion et sémantique. Nous fournissons également une vue d'ensemble ascendante des préjugés sexistes, depuis leur origine sociétale jusqu'à leurs répercussions sur la langue. Enfin, nous établissons un lien entre les implications sociétales des préjugés sexistes et leur (s) type (s) correspondant (s) dans la taxonomie proposée. La motivation sous-jacente de notre travail est d'aider la communauté technique à identifier et à atténuer les biais pertinents des corpus de formation pour une meilleure équité dans les systèmes de PNL.</abstract_fr>
      <abstract_es>La desigualdad de género representa una pérdida considerable de potencial humano y perpetúa una cultura de violencia, mayores brechas salariales de género y falta de representación de las mujeres en puestos superiores y de liderazgo. Las aplicaciones impulsadas por Inteligencia Artificial (IA) se utilizan cada vez más en el mundo real para tomar decisiones críticas sobre quién va a ser contratado, conceder un préstamo, admitirse en la universidad, etc. Sin embargo, se ha demostrado que los pilares principales de la IA, el procesamiento del lenguaje natural (NLP) y el aprendizaje automático (ML) reflejar e incluso amplificar los prejuicios y estereotipos de género, que se heredan principalmente de los datos históricos de formación. En un esfuerzo por facilitar la identificación y mitigación del sesgo de género en el texto en inglés, desarrollamos una taxonomía integral que se basa en los siguientes tipos de sesgo de género: pronombres genéricos, sexismo, sesgo ocupacional, sesgo excluyente y semántica. También ofrecemos una visión general de abajo hacia arriba de los prejuicios de género, desde su origen social hasta su repercusión en el idioma. Finalmente, vinculamos las implicaciones sociales del sesgo de género con su (s) tipo (s) correspondiente (s) en la taxonomía propuesta. La motivación subyacente de nuestro trabajo es ayudar a permitir que la comunidad técnica identifique y mitigue los sesgos relevantes de los cuerpos de capacitación para mejorar la equidad en los sistemas de PNL.</abstract_es>
      <abstract_ja>男女格差は、人間の潜在能力のかなりの損失を表し、暴力の文化、より高い男女間の賃金格差、および高い地位とリーダーシップの地位における女性の代表の欠如を永続化します。 人工知能（ AI ）を搭載したアプリケーションは、誰が雇用され、誰がローンを付与され、誰が大学に入学するかなどの重要な決定を提供するために、現実世界でますます使用されています。 しかし、AI、自然言語処理（ NLP ）、機械学習（ ML ）の主な柱は、主に歴史的なトレーニングデータから受け継がれる性別の偏見や固定観念を反映し、さらには増幅することが示されている。 英語のテキストにおけるジェンダーバイアスの識別と軽減を促進するために、私たちは次のジェンダーバイアスの種類に依存する包括的な分類法を開発します：一般代名詞、性差別、職業バイアス、排他的バイアス、および意味論。 また、社会起源から言語への波及まで、ジェンダーバイアスのボトムアップの概要も提供します。 最後に、私たちは、ジェンダーバイアスの社会的影響を提案された分類法における対応するタイプ（複数可）に結びつけます。 当社の仕事の基本的な動機は、NLPシステムの公平性を向上させるために、トレーニングコーポラから関連するバイアスを特定し、軽減することを技術コミュニティが可能にすることです。</abstract_ja>
      <abstract_zh>性别不等,使人力多失,使暴力文化,高者工资差距及妇人在高位上乏代表性者久矣。 由人工智能(AI)供应用程序益多于世界,以给雇用,得贷,取等要策。 然人工智能、自然语言治(NLP)、机器学(ML)大柱已证可见,至于放性偏见、刻板印象,偏见、刻板印象,主承史数。 进知缓英语文本偏见,开一全分类法,分类法依下偏见:通用代词,性别歧视,业偏见,排他性偏见语义学。 资性别之偏概述,起世间之溢语。 最后,我们将性别偏见的世间影响与拟议分类法中的相应。 吾曹潜机助术社区识轻培训语料库,以崇NLP统之公平性。</abstract_zh>
      <abstract_hi>लिंग असमानता मानव क्षमता के काफी नुकसान का प्रतिनिधित्व करती है और हिंसा की संस्कृति, उच्च लिंग मजदूरी अंतराल, और उच्च और नेतृत्व की स्थिति में महिलाओं के प्रतिनिधित्व की कमी को कायम रखती है। आर्टिफिशियल इंटेलिजेंस (एआई) द्वारा संचालित अनुप्रयोगों का उपयोग वास्तविक दुनिया में तेजी से किया जा रहा है ताकि इस बारे में महत्वपूर्ण निर्णय प्रदान किए जा सकें कि किसे काम पर रखा जा रहा है, ऋण दिया जा रहा है, कॉलेज में भर्ती कराया जा रहा है, आदि। हालांकि, एआई, प्राकृतिक भाषा प्रसंस्करण (एनएलपी) और मशीन लर्निंग (एमएल) के मुख्य स्तंभों को लिंग पूर्वाग्रहों और रूढ़ियों को प्रतिबिंबित करने और यहां तक कि बढ़ाने के लिए दिखाया गया है, जो मुख्य रूप से ऐतिहासिक प्रशिक्षण डेटा से विरासत में मिले हैं। अंग्रेजी पाठ में लिंग पूर्वाग्रह की पहचान और शमन को सुविधाजनक बनाने के प्रयास में, हम एक व्यापक वर्गीकरण विकसित करते हैं जो निम्नलिखित लिंग पूर्वाग्रह प्रकारों पर निर्भर करता है: जेनेरिक सर्वनाम, लिंगवाद, व्यावसायिक पूर्वाग्रह, बहिष्करण पूर्वाग्रह, और शब्दार्थ। हम लिंग पूर्वाग्रह का एक बॉटम-अप अवलोकन भी प्रदान करते हैं, इसकी सामाजिक उत्पत्ति से लेकर भाषा पर इसके स्पिलओवर तक। अंत में, हम प्रस्तावित वर्गीकरण में लिंग पूर्वाग्रह के सामाजिक निहितार्थों को उनके संबंधित प्रकार (ओं) से जोड़ते हैं। हमारे काम की अंतर्निहित प्रेरणा तकनीकी समुदाय को एनएलपी प्रणालियों में बेहतर निष्पक्षता के लिए प्रशिक्षण निगम से प्रासंगिक पूर्वाग्रहों की पहचान करने और कम करने में सक्षम बनाने में मदद करना है।</abstract_hi>
      <abstract_ru>Гендерное неравенство представляет собой значительную потерю человеческого потенциала и увековечивает культуру насилия, увеличивает разрыв в оплате труда мужчин и женщин и недостаточную представленность женщин на более высоких и руководящих должностях. Приложения, основанные на искусственном интеллекте (ИИ), все чаще используются в реальном мире для принятия критических решений о том, кто будет принят на работу, кому будет предоставлен кредит, кого допустят в колледж и т. д. Однако было показано, что основные принципы ИИ, обработки естественного языка (НЯЯ) и машинного обучения (МП) отражают и даже усиливают гендерные предрассудки и стереотипы, которые в основном унаследованы от исторических данных о профессиональной подготовке. Стремясь облегчить выявление и смягчение гендерных предрассудков в английском тексте, мы разрабатываем комплексную таксономию, которая опирается на следующие типы гендерных предрассудков: общие местоимения, сексизм, профессиональные предрассудки, предрассудки, связанные с исключением, и семантика. Мы также представляем обзор гендерной предвзятости снизу вверх, начиная с ее социального происхождения и заканчивая ее распространением на язык. Наконец, мы связываем социальные последствия гендерной предвзятости с их соответствующим типом(типами) в предлагаемой таксономии. Основная мотивация нашей работы заключается в том, чтобы помочь техническому сообществу выявить и смягчить соответствующие предубеждения от обучающих корпусов для улучшения справедливости в системах NLP.</abstract_ru>
      <abstract_ukr>Гендерна нерівність являє собою значну втрату людського потенціалу та увічнює культуру насильства, більш високі гендерні розриви в оплаті праці та відсутність представництва жінок на вищих та керівних посадах. Програми, що працюють на штучному інтелекті (ШІ), все частіше використовуються в реальному світі для забезпечення критичних рішень про те, хто буде найнятий, кому надано кредит, кого допущено до коледжу тощо. Однак, було показано, що основні основи ШІ, обробки природної мови (NLP) та машинного навчання (ML) відображають і навіть посилюють гендерні упередження та стереотипи, які в основному успадковані від історичних навчальних даних. Намагаючись сприяти ідентифікації та пом 'якшенню гендерної упередженості в англійському тексті, ми розробляємо комплексну таксономію, яка спирається на такі типи гендерної упередженості: Загальні займенники, Сексизм, Професійна упередженість, Виключна упередженість та Семантика. Ми також надаємо висхідний огляд гендерної упередженості, від її суспільного походження до поширення на мову. Нарешті, ми пов 'язуємо суспільні наслідки гендерної упередженості з їх відповідним типом(типами) у запропонованій таксономії. Основна мотивація нашої роботи полягає в тому, щоб допомогти технічній спільноті визначити та пом 'якшити відповідні упередження від навчальних корпусів для покращення справедливості в системах NLP.</abstract_ukr>
      <abstract_ga>Is ionann éagothroime inscne agus caillteanas suntasach d’acmhainneacht an duine agus buanaíonn sé cultúr foréigin, bearnaí pá níos airde inscne, agus easpa ionadaíochta ban i bpoist níos airde agus ceannaireachta. Tá iarratais atá faoi thiomáint ag Intleacht Shaorga (AI) á n-úsáid níos mó sa saol fíor chun cinntí ríthábhachtacha a sholáthar maidir le cé atá le fostú, le hiasacht a dheonú, le ligean isteach sa choláiste, etc. Mar sin féin, is iad príomhcholúin AI, Próiseáil Teanga Nádúrtha ( Léiríodh go léiríonn NLP) agus Machine Learning (ML) laofachtaí inscne agus steiréitíopaí, agus fiú iad a mhéadú, a fhaightear go príomha ó shonraí oiliúna stairiúla. Mar iarracht chun an claonadh inscne a aithint agus a mhaolú i dtéacs Béarla, forbraímid tacsanomaíocht chuimsitheach a bhraitheann ar na cineálacha seo a leanas de chlaonadh inscne: Forainmneacha Cineálacha, Gnéasachta, Laofachta Ceirde, Claonadh Eisiach, agus Séimeantaic. Cuirimid freisin forbhreathnú ón mbun aníos ar an gclaonadh inscne, ón mbunús sochaíoch go dtí an t-athrú ar an teanga. Ar deireadh, nascaimid na himpleachtaí sochaíocha a bhaineann le claonadh inscne lena gcineál/cineálacha comhfhreagracha sa tacsanomaíocht atá beartaithe. Is é bunspreagadh ár gcuid oibre cabhrú leis an bpobal teicniúil a chumasú chun laofachtaí ábhartha ón gcorpas oiliúna a aithint agus a mhaolú ar mhaithe le cothroime feabhsaithe i gcórais NLP.</abstract_ga>
      <abstract_ka>Gender inequalities represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions. არტიფიკალური ინტელექცია (AI) გამოყენებული პროგრამები მსოფლიოში უფრო მეტი გამოიყენება, რომ კრიტიკური განსაზღვრებების შესახებ ვინ იქნება, ვინ იქნება დაიყენება, კოლექცია, კოლექციაში მიიღება, ანუ. მაგრამ, ინტელექტიკური ენის პროცესი (NLP) და მაქ რომლებიც ძირითად ისტორიური განათლების მონაცემებით მივიღეთ. ჩვენ ინგლისური ტექსტში გენექტური წარმოდგენების განსაზღვრება და მიმცირება სხვადასხვა რაკონომია განვითარებით, რომელიც განვითარებულია შემდეგი გენექტური წარმოდგენების ტიპები: გენერიკური წარმოდგენები, სექსიმი,  ჩვენ ასევე უფრო ნაკლები გენექტური წარმოდგენისთვის, საზოგადოებო წარმოდგენისთვის, საზოგადოებო წარმოდგენისთვის მისი წარმოდგენისთ საბოლოოდ, ჩვენ სოციალური ინფლექციების გენექტური წარმოდგენების შესაბამისი ტიპი(ები) დაკავშირებთ საკუთარი ტექსონომიში. ჩვენი სამუშაო მოტივაცია არის დახმარება ტექნონიკური საზოგადოებას, რომ განვიცნოს და შემცირებას შესაძლებელი წარმოდგენების შესაბამისი კოპორაციის შესაბამისი სამართლო</abstract_ka>
      <abstract_hu>A nemek közötti egyenlőtlenség az emberi potenciál jelentős csökkenését jelenti, és fenntartja az erőszak kultúráját, a nemek közötti bérkülönbségeket, valamint a nők magasabb és vezető pozíciókban való képviseletének hiányát. A mesterséges intelligencia (AI) által működtetett alkalmazásokat egyre inkább használják a való világban, hogy kritikus döntéseket hozzanak arról, hogy ki fog felvenni, ki kap kölcsönt, felvételt a főiskolára stb. Azonban a mesterséges intelligencia, a természetes nyelvfeldolgozás (NLP) és a gépi tanulás (ML) fő pillérei tükrözik, sőt erősítik a nemi előítéleteket és sztereotípiákat, amelyeket elsősorban a korábbi képzési adatokból örököltek. Annak érdekében, hogy megkönnyítsük a nemi elfogultság azonosítását és enyhítését angol szövegben, átfogó taxonómiát dolgozunk ki, amely a következő nemi elfogultság típusokra támaszkodik: Általános névmások, Szexizmus, Foglalkozási Bias, Exkluzív Bias és Szemantika. Alulról felfelé irányuló áttekintést is nyújtunk a nemek közötti elfogultságról, a társadalmi eredetétől a nyelvre való átterjedéséig. Végezetül összekapcsoljuk a nemi elfogultság társadalmi következményeit a javasolt taxonómia megfelelő típusához. Munkánk alapvető motivációja, hogy segítsünk a technikai közösségnek azonosítani és enyhíteni tudjuk a vállalatok képzéséből származó releváns előítéleteket az NLP rendszerek méltányosságának javítása érdekében.</abstract_hu>
      <abstract_isl>Ójafnvægi á kyni leiðir til mikilvægrar minnkunar á möguleika manna og heldur áfram a ð ræða ofbeldi, hærri lönubilun á kyni og skorts á fulltrúa konum í hærri stöðu og stjórnarstöðu. Umsóknir sem starfa eru af listrænum upplýsingum (AI) eru allt meira a ð nota í raunverulegum heimi til að veita ákvarðandi ákvörðun um hvern á að vera ráðið, gefið lán, komið inn í háskóla o.s.frv. Hins vegar hefur verið sýnt fram á að aðalpillurnar AI, náttúrulegra tungumyndunar (NLP) og vélbúnaðar (ML) endurspegla og jafnvel auka kynslíkar fyrirsætningar og stereótýpur, - sem eru aðallega arfgengir úr sögulegum þjálfunargögnum. Í tilraun til a ð auðvelda greiningu og minnkun kynhneigða í ensku texti þróum við umtalsverða skattafræði sem byggist á eftirfarandi kynhneigðategundir: Almenn nafn, kynlíf, atvinnuleg breyting, einstök breyting og fræðileg breyting. Við gefum einnig yfirlit niður í upphaf á kynþáttum, frá samfélagslegum uppruna hennar til spillovers hennar á tungumál. Finally, we link the societal implications of gender bias to their corresponding type(s) in the proposed taxonomy.  The underlying motivation of our work is to help enable the technical community to identify and mitigate relevant biases from training corpora for improved fairness in NLP systems.</abstract_isl>
      <abstract_el>Η ανισότητα των φύλων αντιπροσωπεύει σημαντική απώλεια ανθρώπινου δυναμικού και διαιωνίζει μια κουλτούρα βίας, υψηλότερα μισθολογικά χάσματα μεταξύ των φύλων και έλλειψη εκπροσώπησης γυναικών σε ανώτερες θέσεις και ηγετικές θέσεις. Οι εφαρμογές που τροφοδοτούνται από τεχνητή νοημοσύνη (τεχνητή νοημοσύνη) χρησιμοποιούνται όλο και περισσότερο στον πραγματικό κόσμο για να παρέχουν κρίσιμες αποφάσεις σχετικά με το ποιος πρόκειται να προσληφθεί, να χορηγηθεί δάνειο, να εισαχθεί στο κολέγιο, κ.λπ. Ωστόσο, οι κύριοι πυλώνες της τεχνητής νοημοσύνης, της επεξεργασίας φυσικής γλώσσας και της μηχανικής μάθησης (έχουν αποδειχθεί ότι αντικατοπτρίζουν και ακόμη ενισχύουν τις προκαταλήψεις και τα στερεότυπα των φύλων, τα οποία κληρονομούνται κυρίως από ιστορικά δεδομένα κατάρτισης. Σε μια προσπάθεια να διευκολυνθεί ο εντοπισμός και ο μετριασμός της προκατάληψης φύλου στο αγγλικό κείμενο, αναπτύσσουμε μια ολοκληρωμένη ταξινομία που βασίζεται στους ακόλουθους τύπους προκατάληψης φύλου: Γενικές Προφωνήσεις, Σεξισμός, Επαγγελματική προκατάληψη, Αποκλειστική προκατάληψη και Σημαντική. Παρέχουμε επίσης μια από τα κάτω προς τα πάνω επισκόπηση της προκατάληψης των φύλων, από την κοινωνική προέλευσή της μέχρι την εξάπλωσή της στη γλώσσα. Τέλος, συσχετίζουμε τις κοινωνικές επιπτώσεις της προκατάλειψης του φύλου με τον αντίστοιχο τύπο τους στην προτεινόμενη ταξινομία. Το υποκείμενο κίνητρο της εργασίας μας είναι να βοηθήσουμε την τεχνική κοινότητα να εντοπίσει και να μετριάσει τις σχετικές προκαταλήψεις από τα εκπαιδευτικά σώματα για βελτιωμένη δικαιοσύνη στα συστήματα NLP.</abstract_el>
      <abstract_it>La disuguaglianza di genere rappresenta una notevole perdita di potenziale umano e perpetua una cultura della violenza, maggiori disparità salariali di genere e una mancanza di rappresentanza delle donne in posizioni superiori e di leadership. Le applicazioni basate sull'Intelligenza Artificiale (AI) sono sempre più utilizzate nel mondo reale per fornire decisioni critiche su chi sta per essere assunto, concesso un prestito, ammesso al college, ecc. Tuttavia, i pilastri principali dell'AI, Natural Language Processing (NLP) e Machine Learning (ML) hanno dimostrato di riflettere e persino amplificare pregiudizi e stereotipi di genere, che sono ereditate principalmente dai dati storici di formazione. Nel tentativo di facilitare l'identificazione e la mitigazione dei pregiudizi di genere nel testo inglese, sviluppiamo una tassonomia completa che si basa sui seguenti tipi di pregiudizi di genere: Pronomi generici, Sessualismo, Bias occupazionale, Bias esclusionary e Semantics. Forniamo anche una panoramica bottom-up dei pregiudizi di genere, dalla sua origine sociale alla sua diffusione sulla lingua. Infine, colleghiamo le implicazioni sociali del pregiudizio di genere ai loro tipi corrispondenti nella tassonomia proposta. La motivazione alla base del nostro lavoro è quella di aiutare la comunità tecnica a identificare e mitigare i pregiudizi rilevanti da parte dei corpi di formazione per migliorare l'equità nei sistemi NLP.</abstract_it>
      <abstract_kk>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and the lack of representation of women in higher and leadership positions. Бұл бағдарламалар Ақпараттық Интеллектер (МП) қолданылатын қолданбалар көбірек әлемдеге кімге қатынау, колледжіне қатынау, жұмыс беру және т.б. қатынау үшін көбірек шешімдерді беру үшін қолданылады. Бірақ, AI, Natural Language Processing (NLP) және Machine Learning (ML) негізгі бағдарламалар гендер Таригиялық оқыту деректерінен негізінде орындалады. Ағылшынша мәтінде гендерді анықтау және азайту әрекетіне көмектесу үшін біз келесі гендердің қарсылық түрлеріне тәуелді толық таксономиясын жасаймыз: генералық қарсылықтар, сексизм, жұмыс істеу қарсылықтары, бөліктердің қарсылықтары ж Мұндай-ақ, әлемдік түрінен тілдерге көтеріп жатқан гендердің қарсылығының төмендегі көрінісін қараймыз. Соңғы сәтте, біз гендерлік қарсылықтарының әлемді таксономиялық түріне қосымыз. Жұмыстың негізгі мотивациясы - NLP жүйелерінде оқиғаларды жақсарту үшін корпораға үйрену жүйелерінде қасиеттерді анықтауға және көмектесуға көмектесу.</abstract_kk>
      <abstract_ms>Keketidaksamaan jenis mewakili kehilangan potensi manusia yang besar dan mengembangkan budaya kekerasan, perbezaan gaji jenis yang lebih tinggi, dan kekurangan mewakili wanita dalam kedudukan yang lebih tinggi dan pemimpin. Aplikasi yang diberi kuasa oleh Intelligence Artificial (AI) semakin digunakan di dunia nyata untuk menyediakan keputusan kritik tentang siapa yang akan disewa, diberi pinjaman, diterima ke kolej, dll. Namun, pilar utama AI, Proses Bahasa Semulajadi (NLP) dan Pembelajaran Mesin (ML) telah menunjukkan untuk mencerminkan dan memperkuat biases dan stereotip jenis jenis, - yang paling mewarisi dari data latihan sejarah. Dalam usaha untuk memudahkan pengenalan dan perlengkapan bias jenis dalam teks Inggeris, kami mengembangkan taksonomi komprensif yang bergantung pada jenis bias jenis jenis jenis jenis berikut: Pronouns Generic, Sexism, Bias Occupational, Exclusionary Bias, and Semantics. Kami juga menyediakan pandangan rendah-rendah bias jenis, dari asal masyarakatnya hingga spillover ke bahasa. Akhirnya, kita paut implikasi masyarakat bias jenis yang sepadan dengan jenis-jenis mereka dalam taksonomi yang diusulkan. Motivasi dasar kerja kita adalah untuk membantu masyarakat teknikal untuk mengenalpasti dan mengurangi biases yang relevan dari pelatihan corpora untuk memperbaiki keadilan dalam sistem NLP.</abstract_ms>
      <abstract_mt>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions.  L-applikazzjonijiet imħaddma mill-Intelliġenza Artifikali (AI) qed jintużaw dejjem aktar fid-dinja reali biex jipprovdu deċiżjonijiet kritiċi dwar min se jiġi impjegat, mogħti self, ammess fil-kulleġġ, eċċ. Madankollu, intwera li l-pilastri ewlenin tal-AI, l-Ipproċessar tal-Lingwi Naturali (NLP) u t-Tagħlim tal-Magni (ML) jirriflettu u saħansitra amplifikaw il-preġudizzji u l-isterjotipi bejn is-sessi, ) li huma prinċipalment erediti minn dejta storika ta’ taħriġ. Fi sforz biex tiġi ffaċilitata l-identifikazzjoni u l-mitigazzjoni tal-preġudizzju bejn is-sessi fit-test Ingliż, a ħna niżviluppaw tassonomija komprensiva li tiddependi fuq it-tipi ta’ preġudizzju bejn is-sessi li ġejjin: Pronomi Ġeneriċi, Sessiżmu, Bias tax-Xogħol, Bias Esklużjonarji, u Semanti. Aħna nipprovdu wkoll ħarsa ġenerali minn isfel għal fuq tal-preġudizzju bejn is-sessi, mill-oriġini tas-soċjetà tagħha sal-konsegwenza tagħha fuq il-lingwa. Fl-aħħar nett, aħna nillegaw l-implikazzjonijiet soċjetali tal-preġudizzju bejn is-sessi mat-tip(i) korrispondenti tagħhom fit-tassonomija proposta. Il-motivazzjoni sottostanti tax-xogħol tagħna hija li tgħin lill-komunità teknika tidentifika u tnaqqas il-preġudizzji rilevanti minn korpora ta’ taħriġ għal ġustizzja mtejba fis-sistemi NLP.</abstract_mt>
      <abstract_mk>Нееднаквоста помеѓу половите претставува значителна загуба на човечкиот потенцијал и ја продолжува културата на насилство, повисоките разлики во платите помеѓу половите и недостатокот на претставување на жените на повисоките позиции и на водечките места Апликациите поттикнати од уметничката интелигенција (AI) се сé повеќе се користат во реалниот свет за да обезбедат критични одлуки за тоа кој ќе биде вработен, доделен заем, применет на колеџ итн. Сепак, се покажа дека главните столбови на AI, природното јазичко процесирање (NLP) и машинско учење (ML) одразуваат и дури и ги зголемуваат полските предрасуди и сте  which are mainly inherited from historical training data.  In an effort to facilitate the identification and mitigation of gender bias in English text, we develop a comprehensive taxonomy that relies on the following gender bias types: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics.  Ние, исто така, обезбедуваме преглед од дното нагоре на генералната пристрасност, од нејзиното општествено потекло до нејзиното пренесување на јазикот. Конечно, ги поврзуваме општествените импликации на генералната пристрасност со нивниот или нивните соодветни типови во предложената таксономија. Основната мотивација на нашата работа е да й се помогне на техничката заедница да ги идентификува и намали релевантните предрасуди од обуката на корпората за подобрена фер во системите на НЛП.</abstract_mk>
      <abstract_lt>Lyčių nelygybė žymiai praranda žmogaus potencialą ir išlieka smurto kultūra, didesni lyčių darbo užmokesčio skirtumai ir moterų atstovavimo aukštesnėse ir vadovaujančiose pareigose stoka. Dirbtinės žvalgybos (AI) teikiamos paraiškos vis dažniau naudojamos realiame pasaulyje priimant kritinius sprendimus dėl to, kas bus įdarbintas, suteiktas paskolas, priimamas į koledžą ir t. t. Tačiau buvo įrodyta, kad pagrindiniai AI, gamtinės kalbos apdorojimo (NLP) ir mašininio mokymosi (ML) ramsčiai atspindi ir net sustiprina lyčių pusiausvyrą ir stereotipus, - kurie daugiausia paveldimi istoriniais mokymo duomenimis. In an effort to facilitate the identification and mitigation of gender bias in English text, we develop a comprehensive taxonomy that relies on the following gender bias types: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics.  Taip pat teikiame iš apačios į viršų apžvalgą apie lyčių pusiausvyrą nuo jos visuomenės kilmės iki jos išplitimo į kalbą. Galiausiai mes susiejame lyčių pusiausvyros poveikį visuomenei su atitinkamu (-ais) jų tipu (-ais) siūlomoje taksonomijoje. Pagrindinė mūsų darbo motyvacija yra padėti techninei bendruomenei nustatyti ir sušvelninti atitinkamus mokymo korporacijos iškraipymus siekiant geresnio teisingumo NLP sistemose.</abstract_lt>
      <abstract_ml>പെണ്‍കുട്ടികളുടെ സാധ്യത മനുഷ്യന്റെ നഷ്ടത്തിന്റെ പ്രതിനിധിക്കുന്നത് മനുഷ്യരുടെ നഷ്ടത്തിനാണ്. കൂടുതല്‍ സംസ്കാരം, കൂടുതല്‍ പ്രതിഫല വേ ആരാണ് കൂലിയാക്കുവാന്‍ പോകുന്നത്, കോളേജിലേക്ക് സമ്മതിക്കുവാന്‍ പോകുന്നത് എന്നിട്ടും ആര്‍ട്ടിഫിക്കല്‍ ഇന്‍റലിജെന്‍സില്‍ ശക്തിയുള്ള പ്രയോഗങ്ങള്‍ കൂടുതല്‍ ഉപയോഗിക്കുന്നു. എന്നാല്‍ പ്രധാനപ്പെട്ട ഐ, സ്വാഭാവിക ഭാഷയ പ്രധാനപ്പെട്ട ചരിത്ര പരിശീലന വിവരങ്ങളില്‍ നിന്നും അവകാശികളാണ്. ഇംഗ്ലീഷ് ടെക്സ്റ്റില്‍ നിരീക്ഷിക്കുന്നതിനും പ്രധാനപ്പെടുത്തുവാനും ഞങ്ങള്‍ ഒരു പൂര്‍ണ്ണമായ ടാക്സോനോമിയാണ് നിര്‍മ്മിക്കുന്നത്: സാധാരണ പ്രോണോണിന്‍സ്, സെക്സിക്സം,  We also provide a bottom-up overview of gender bias, from its societal origin to its spillover onto language.  അവസാനം, നമ്മള്‍ പ്രൊത്തപ്പെട്ട ട ടാക്സോനോമിയില്‍ അവരുടെ പൊരുത്തപ്പെടുന്ന തരത്തില്‍ സാമൂഹ്യത്തിലെ പ്രശ്നങ്ങളെ ബന നമ്മുടെ ജോലിയുടെ അടിസ്ഥാനത്തെ പ്രഭോഷണം എന്‍എല്‍പി സിസ്റ്റത്തിലെ നീതി മെച്ചപ്പെടുത്തുന്നതിന് വേണ്ടി സാങ്കേതിക സമൂഹത്തെ പരിശ</abstract_ml>
      <abstract_no>Gender ulikhet representerer ein betydelig tap av menneskelige potensial og perpetuaterer ein kultur av vold, høgare gjennomslag, og ein mangling av representasjon av kvinner i høgare og ledersplasseringar. Programmer som er påkravde av kunstige intelligens (AI) blir større brukt i verda for å gjera kritiske beslutningar om kva som skal lånast, tilgjengeleg ein lån, tilgjengeleg til universitet osv. Dei hovudpillarane av AI, naturspråk-prosessering (NLP) og maskinelæring (ML) er imidlertid viste for å refleksera og til og til og med forstørra seks-forsikt og stereotypar, Dette er hovudsakelig hered frå historiske treningsdata. I eit forsøk for å gjere enkelt identifikasjon og reduksjon av seksusjonsformen i engelsk tekst, utviklar vi ein komplett taksonomie som relier på desse seksusjonertypene: Generiske forebygging, seksisme, profesjonelt byar, ekskluseringsbyar og semiantikk. Vi tilbyr også ein oversikt over gjennomgang av seks, frå sosiale opprinnelsen til språk. Til slutt, vi lenkjer samfunnsmessige implikasjonane av seks-forholdet til dei tilsvarande type(ane) i den foreslåde taksonomien. Det underliggende motivasjonen av arbeidet vårt er å hjelpa på å gjera det tekniske fellesskapet til å identifisera og minne relevante forskjeller frå opplæring av korpora for forbetra rettighet i NLP-systemet.</abstract_no>
      <abstract_pl>Równość płci oznacza znaczną utratę potencjału ludzkiego i utrwalają kulturę przemocy, większe różnice w wynagrodzeniach płci oraz brak reprezentacji kobiet na wyższych stanowiskach i stanowiskach kierowniczych. Aplikacje oparte na sztucznej inteligencji (AI) są coraz częściej wykorzystywane w świecie rzeczywistym do podejmowania krytycznych decyzji o tym, kto zostanie zatrudniony, udzielony pożyczki, przyjęty na studia itp. Jednak wykazano, że główne filary AI, przetwarzania języka naturalnego (NLP) i uczenia maszynowego (ML) odzwierciedlają, a nawet wzmacniają uprzedzenia i stereotypy płci, które są głównie dziedziczone na podstawie historycznych danych treningowych. W celu ułatwienia identyfikacji i łagodzenia uprzedzeń płciowych w tekście angielskim opracowujemy kompleksową taksonomię, która opiera się na następujących typach uprzedzeń płciowych: zaimki generyczne, seksizm, uprzedzenia zawodowe, uprzedzenia wyłączne i semantyka. Zapewniamy również oddolny przegląd uprzedzeń dotyczących płci, począwszy od pochodzenia społecznego do przenoszenia się na język. Wreszcie, w proponowanej taksonomii łączymy społeczne implikacje uprzedzeń płci z ich odpowiednimi typami. Podstawową motywacją naszej pracy jest umożliwienie środowisku technicznemu identyfikacji i łagodzenia istotnych uprzedzeń korpusów szkoleniowych w celu poprawy uczciwości w systemach NLP.</abstract_pl>
      <abstract_mn>Эсвэл төрөлхтний тэгш байдал нь хүн төрөлхтний потенциалаас маш их алдагддаг ба хүчирхийллийн соёл, гендерийн цалингийн ялгаа, эмэгтэйчүүдийн илэрхийлэл өндөр, удирдагчийн байр суурь байрлалд байдаг. Урлаг ухаан ухааны (AI) хүчтэй програм нь хэн ажиллах, сургуульд зөвшөөрөгдсөн бөгөөд хэн ажиллах боломжтой гэсэн чухал шийдвэр гаргахын тулд бодит ертөнц дээр ихэвчлэн хэрэглэгддэг. Гэхдээ AI, Байгалийн хэл Процессор (NLP) болон Машин Сургууль (ML) нь гендерийн тухай ойлголт, эсрэг хэлб Эдгээр нь түүхэн дасгал өгөгдлийн мэдээллээс үндсэн. Англи хэлний бичлэг дээрх гендерийн өрөөсгөлийг тодорхойлох болон багасгах зорилгоор бид дараагийн гендерийн өрөөсгөл байдлын төрлүүд дээр хамаарч байгаа бүрэн татварын оном үүсгэдэг. Бид мөн гендерийн өрөөсгөл байдал, нийгмийн эх үүсвэрээс хэл руу шингээгч хүртэл дамжуулдаг. Эцэст нь бид гендерийн эсрэг харилцааны нийгмийн нөлөөлөлийг санал өгсөн татекономикийн харилцааны харилцааны төрлийг холбож байна. Бидний ажлын үндсэн урам зорилго нь NLP системийн шударга байдлыг сайжруулахын тулд техник нийгмийн нийгмийн тусламжтай байдлыг багасгах боломжтой болгох юм.</abstract_mn>
      <abstract_ro>Inegalitatea de gen reprezintă o pierdere considerabilă a potențialului uman și perpetuează o cultură a violenței, diferențele salariale mai mari între femei și bărbați și lipsa reprezentării femeilor în poziții superioare și de conducere. Aplicațiile alimentate de inteligență artificială (AI) sunt utilizate din ce în ce mai mult în lumea reală pentru a furniza decizii critice cu privire la cine urmează să fie angajat, acordat un împrumut, admis la colegiu etc. Cu toate acestea, principalii piloni ai AI, Natural Language Processing (PNL) și Machine Learning (ML) au fost demonstrate că reflectă și chiar amplifică prejudecățile și stereotipurile de gen, care sunt moștenite în principal din datele istorice de formare. În efortul de a facilita identificarea și atenuarea prejudecăților de gen în textul englez, dezvoltăm o taxonomie cuprinzătoare care se bazează pe următoarele tipuri de prejudecăți de gen: Pronume generice, Sexism, Bias ocupațional, Bias exclusiv și Semantică. De asemenea, oferim o imagine de ansamblu de jos în sus asupra prejudecăților de gen, de la originea sa societală până la revendicarea sa asupra limbii. În cele din urmă, legăm implicațiile societale ale prejudecății de gen cu tipul (tipurile) corespunzătoare din taxonomia propusă. Motivația fundamentală a activității noastre este de a ajuta comunitatea tehnică să identifice și să atenueze prejudecățile relevante ale corporațiilor de formare pentru îmbunătățirea echității în sistemele PNL.</abstract_ro>
      <abstract_so>Sinnaanta galmada waxaa ka mid ah khasaaro aad u weyn oo awoodda dadku ku jirto, wuxuuna sii wadaa dhaqanka dagaalka, kala bixinta mushahaarada jinsiga, iyo baahida la’aanta sharciga dumarka meelaha sare iyo hogaamiya. Dalbooyinka cilmiga farshaxanka ah (AI) waxaa si badan looga isticmaalaa caalamka ah si ay u fidiyaan go'aanka muhiimka ah oo ku saabsan qofka la kiraysto, amaahda la siiyo, iskuulka lagu kireeyo, tusaale ahaan tiirarka asalka ah ee AI, Processing afka asalka ah (NLP) iyo Waxbarashada mashiinka (ML) si loo fiiriyo iyo weliba kordhiyo caymiska jinsiga ah iyo stereotypes, taasoo ugu horeyn dhaxal ka helay macluumaadka waxbarashada taariikhda. In an effort to facilitate the identification and mitigation of gender bias in English text, we develop a comprehensive taxonomy that relies on the following gender bias types: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics.  Sidoo kale waxaynu fidinnaa muuqasho hoose ah oo ku qoran dabeecada jinsiga, tan iyo asalkiisa bulshada iyo ilaa luqadiisa hore. Ugu dambaysta, waxaynu ku xidhiidhinnaa arimaha bulshada ee rabshadda jinsiga oo la mid ah noocyadooda la mid dhigay canshuuraha la soo jeeday. Dhaqaalaha hoose ee shaqadeenna waa in ay caawiyaan bulshada teknolojiga si ay u aqoonsadaan oo ay u isticmaalaan tababarida shirkadda la xiriira si ay ugu hagaajiyaan caddaaladda nidaamka NLP.</abstract_so>
      <abstract_ta>பெண்களின் சமம் மனித சாத்தியங்களின் இழப்பு மிகவும் குறைந்துள்ளது மற்றும் ஒரு வன்முறையின் கலாச்சாரத்தை தொடர்ந்து செல்கிறது, அதிகமாக இனம்  கலைஞர் அறிவிப்பு (AI) ஆற்றலுள்ள பயன்பாடுகள் உண்மையில் பயன்படுத்தப்படுகிறது யார் வேலை செய்யப்படுவார்கள் என்பதை பற்றி முக்கியமான தீர்மானிப்புகளை வழங்கும், கல்லூரிக்கு ஏற்றுக்கொள்ள முடியும் என்றாலும் AI, இயற்கையான அது முக்கியமாக வரலாற்று பயிற்சி தரவிலிருந்து வாரிசுகளாக இருக்கிறது. ஆங்கிலம் உரையில் பெண்களை அடையாளம் மற்றும் சுருக்க முயற்சியில், நாம் ஒரு முழுமையான வரிசையை உருவாக்குகிறோம், கீழ் வரும் இம்மைகளை நம்புகிறார் நாம் ஒரு கீழ் மேலே பெண் பிரிவுகளை கொடுக்கிறோம், அதன் சமூகத்திலிருந்து அதன் மொழியில் சுழற்றும் மொழியில் இருந இறுதியில், நாம் பிரிந்திக்கப்பட்ட வரிசையில் பெண்கள் பிரச்சினைகளின் சமூகத்தின் பாக்கியங்களை இணைக்கிறோம். எங்கள் வேலையின் அடிப்படையான ஊக்கம் என்னவென்றால் தொழில்நுட்பம் சமூகத்தை கண்டுபிடிக்க மற்றும் சுருக்கும் பொருத்தமான பிரச்சனைகள</abstract_ta>
      <abstract_sr>Neravnoteža žena predstavlja značajan gubitak ljudskog potencijala i zauvijek održava kulturu nasilja, veće praznine plaće u spolu, i nedostatak zastupanja žena na višim i vodstvenim položajima. Aplikacije koje su moćne umetničkom inteligencijom (AI) uvećavaju se u stvarnom svijetu koriste za pružanje kritičnih odluka o tome ko će biti angažovan, određen kredit, priznat na koledž, itd. Međutim, pokazuju se da su glavni stupovi AI, prirodnog procesa jezika (NLP) i mašinskog učenja (ML) odražavali i čak pojačavali spolne predrasude i stereotipe, koje se uglavnom naslijeđuju iz istorijskih podataka obuke. U naporima za olakšanje identifikacije i smanjenje spolnih pristrasnosti na engleskom tekstu, razvijamo kompletnu taksonomiju koja se oslanja na sljedeće tipove spolnih pristrasnosti: generalne proglaske, seksizm, profesionalne bije, ekskluzivne bije i semantike. Takođe pružamo pregled spolnih predrasude, od socijalnog porekla do prolivača na jezik. Konačno povezujemo socijalne implikacije spolnih predrasuda sa njihovim odgovarajućim tipom(ima) u predloženoj taksonomiji. Na temelju motivacije našeg rada je da pomognemo tehničkoj zajednici da identifikuje i smanji relevantne predrasude od treninga korporacije za poboljšanje pravednosti u NLP-ovim sistemima.</abstract_sr>
      <abstract_sv>Jämställdhet mellan könen innebär en avsevärd förlust av mänsklig potential och upprätthåller en våldskultur, högre löneskillnader mellan könen och bristen på representation av kvinnor i högre positioner och ledande befattningar. Tillämpningar som drivs av artificiell intelligens (AI) används alltmer i verkligheten för att ge kritiska beslut om vem som ska anställas, beviljas lån, antagits till college osv. Men huvudpelarna i AI, Natural Language Processing (NLP) och Machine Learning (ML) har visat sig återspegla och till och med förstärka könsfördomar och stereotyper. som huvudsakligen ärvts från historiska träningsdata. För att underlätta identifiering och begränsning av könsbias i engelsk text utvecklar vi en omfattande taxonomi som bygger på följande typer av könsbias: Generiska pronomen, Sexism, Yrkesbias, Exklusiv Bias och Semantics. Vi ger också en nedifrån och upp översikt över könsbias, från dess samhälleliga ursprung till dess spridning på språk. Slutligen kopplar vi de samhälleliga konsekvenserna av könsbias till motsvarande typ(er) i den föreslagna taxonomin. Den underliggande motivationen för vårt arbete är att hjälpa den tekniska gemenskapen att identifiera och mildra relevanta fördomar från träningsföretag för förbättrad rättvisa i NLP-system.</abstract_sv>
      <abstract_ur>جنس کی عداوت انسان کی امکانات کا بہت اچھا خسارہ ہے اور ہتھیار کی فرهنگی، بلند جنس کی اجرت فاصلہ، اور عورتوں کی زیادہ اور رئیڈرسی کی موقعیت میں کمی ہے. مجموعہ اطلاعات (AI) کے ذریعے طاقت رکھے ہوئے अनुप्रयोग واقعی دنیا میں اضافہ ہوتے ہیں کہ کس کے بارے میں ضروری فیصلہ کرنے کے لئے استعمال کئے جائیں گے، کس کو قرض دیا جائے گا، کالج میں اعتراف کئے جائیں گے، اور اضافہ کئے جائیں گے، اضافہ کئے جائیں گے، طبیعی زبان پردازی (NLP) اور ماشین سکھانے (ML) کی اصلی ستونروں کو د جو اکثر تاریخی تعلیم دادہ سے وارث ہوتے ہیں۔ انگلیسی ٹیکسٹ میں جنس کی مخالفت کی شناسایی اور ذلت کے ذریعہ آسانی کرنے کی کوشش میں ہم ایک کامل تاکسونوم کی تخلیق کریں جو نیچے جنس کی مخالفت پر اعتماد کرتی ہے: جنسی قوانین، جنسی قوانین، کارسازی بیس، اسکلیزونی بیس، اور سیمانٹیکس. ہم نے جنس کی مخالفت کے بارے میں نیچے بالا نظر بھی پیش کیا ہے، اس کی اجتماعی اصل سے اس کی زبان پر چڑھنے والے تک۔ آخر میں، ہم جنس کی مخالفت کی اجتماعی اثرات کو ان کی مخالف طرح(وں) سے متصل کر رہے ہیں۔ ہمارے کام کی بنیاد دلیل یہ ہے کہ ٹیکنیکی کمونٹی کو NLP سیسٹموں میں بہترین عدالت کی تدبیر اور کمزور کرنے کی مدد کریں۔</abstract_ur>
      <abstract_si>ජෙන්ඩර් නිර්මාණය ප්‍රතිනිශ්ණය ප්‍රතිනිශ්ණයෙන් මිනිස්සු ප්‍රතිශ්ණතාවක් ගොඩක් නැතිවෙන්න පුළුවන් වෙනුවෙන් ඉන්නේ,  විශ්වාසික බුද්ධිමත්වය (AI) වලින් ප්‍රයෝජනය විශ්වාසයෙන් ප්‍රයෝජනය කරනවා ඇත්ත ලෝකයේ විශ්වාසික විශ්වාස කරන්න විශ්වාසික තීරණය සඳහා කවුද කියලා, බුද්ධිමත්, කොලේජ් වලින් ව ඉතිහාසික ප්‍රීක්ෂණා දත්තෙන් පිළිගන්න පුළුවන්. In an empowerment to assist the ID and Mitigation of Genr Bias in English text, we develop a comprehersive TaxNomy that Departs on the Next Genr Bias types: geneic ProNouns, sex isms, Threshold Bias, Exludary Bias, and semantics. අපි සමහර විශේෂ ප්‍රදේශයක් සමහර විශේෂ කරනවා, සමාජික ප්‍රදේශයෙන් එයාගේ භාෂාවෙන් විශේෂ කරනවා. අන්තිමේදී, අපි සමාජිකව සම්බන්ධ විශ්වාස කරනවා ජීවිත සාමාජිකව සම්බන්ධ විශ්වාසිකයෙන් ඔවුන්ගේ  අපේ වැඩේ ප්‍රමාණයක් තමයි තාක්ෂණික සමාජයට උදව් කරන්නේ NLP පද්ධතියේදී සාමාන්‍ය විශ්වාස කරන්න සම්බන්ධ විශ්වාස කරන්</abstract_si>
      <abstract_uz>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions.  Аслида, AI, tabiiy tillar jarayonligi (NLP) va Mashine ta'lim o'qituvchilari (ML) haqida jinsiyalarni ko'paytirish va stereotyplarni ko'rsatish va ko'paytirish uchun juda muhim muammolar yordamida ishlatiladi. hozir tarixi taʼminlovchi maʼlumotdan arzon bo'lgan. Eng ingliz matnning jinsiyalarni aniqlash va tahrirlashga yordam berish uchun biz quyidagi jinsiyalar turlariga ishlatadigan katta taxonomni yaratib boramiz: Umumiy Pronouns, Seksizm, Xitoy Bia, Exclusionary Bia va Semantiklar. Biz buning jamiyatlarning asl aslidan o'zgarishni o'zgartiradik. Endi, biz taxonomdagi ijtimoiy harakatlarni o'zgartirish turi(lar) bilan bog'liqchimiz. Bizning ishimizning asosiy motivati, texnologiya jamiyatlarni NLP tizimlarida o'zgartirish uchun muhim qismlarni aniqlash va o'zgartirishni yordam berish va yordam berish uchun.</abstract_uz>
      <abstract_vi>Sự bất đồng giới tính là một mất mát đáng kể của tiềm năng con người và duy trì một nền văn hóa bạo lực, mức lương cao hơn giới tính, và sự thiếu sự đại diện của phụ nữ ở vị trí lãnh đạo cao hơn. Ứng dụng có năng lực từ trí thông minh nhân tạo (AI) được sử dụng ngày càng nhiều trong thế giới thực để đưa ra quyết định quan trọng về ai sẽ được thuê, cho vay mượn, được cho vào đại học, v.v. Tuy nhiên, các trụ cột chính của AI, Bảo quản chế ngôn ngữ tự nhiên (NLP) và Machine Learning (ML) đã được cho thấy phản xạ và thậm chí tăng cường tính đa số và rập khuôn, mà chủ yếu được thừa kế từ dữ liệu về lịch sử. Để dễ nhận dạng và giảm thiểu khuynh hướng giới tính trong văn bản Anh, chúng tôi phát triển một loại taxonomy to àn cầu nhờ có các kiểu thiên vị giới tính: Generic Prodains, Sexism, occupieal Bians, exclusive Bians, và Semantics. Chúng tôi cũng cung cấp một thông tin từ tầng trên về khuynh hướng giới tính, từ nguồn gốc xã hội cho đến việc tiết lộ ngôn ngữ. Cuối cùng, chúng ta kết nối các tác động xã hội của khuynh hướng giới tính với chủng loại tương ứng trong tổng phân loại dự kiến. Nền động cơ của chúng ta là giúp cho cộng đồng kỹ thuật xác định và giảm thiểu các thói quen thuộc từ giáo sư để làm cho công bằng hơn trong hệ thống NLP.</abstract_vi>
      <abstract_bg>Неравенството между половете представлява значителна загуба на човешкия потенциал и поддържа култура на насилие, по-високи разлики в заплатите между половете и липсата на представителство на жените на висши и ръководни позиции. Приложенията, захранвани от изкуствен интелект (ИИ), все повече се използват в реалния свят, за да се предоставят критични решения за това кой ще бъде нает, отпуснат заем, приет в колеж и т.н. Въпреки това, основните стълбове на ИИ, Обработката на естествения език (НЛП) и Машинното обучение (МЛ) са показани, че отразяват и дори усилват половите пристрастия и стереотипите, които са наследени главно от исторически данни за обучение. В стремежа си да улесним идентифицирането и смекчаването на половите пристрастия в английския текст, ние разработваме цялостна таксономия, която разчита на следните видове пристрастия към пола: Генерални местоимения, Сексизъм, Професионални пристрастия, Изключителни пристрастия и Семантика. Ние също така предоставяме преглед отдолу нагоре на предразсъдъците, свързани с пола, от обществения му произход до разпространението му върху езика. Накрая, ние свързваме обществените последици от половото пристрастие с техния(ите) тип(и) в предложената таксономия. Основната мотивация на нашата работа е да помогнем на техническата общност да идентифицира и смекчи съответните предразсъдъци от обучителните корпуси за подобряване на справедливостта в системите за НЛП.</abstract_bg>
      <abstract_da>Ligestilling mellem kønnene udgør et betydeligt tab af menneskeligt potentiale og opretholder en voldskultur, større lønforskelle mellem kønnene og manglende repræsentation af kvinder i højere stillinger og ledende stillinger. Applikationer drevet af kunstig intelligens (AI) bliver i stigende grad brugt i den virkelige verden til at træffe kritiske beslutninger om, hvem der skal ansættes, ydes et lån, optages på college osv. Men de vigtigste søjler i AI, Natural Language Processing (NLP) og Machine Learning (ML) har vist sig at afspejle og endda forstærke kønsfordomme og stereotyper, som hovedsagelig er arvet fra historiske træningsdata. I et forsøg på at gøre det lettere at identificere og afbøde kønsbias i engelsk tekst, udvikler vi en omfattende taksonomi, der er baseret på følgende kønsbias typer: Generiske udtaler, Sexisme, Erhvervsmæssig bias, Eksklusiv bias og Semantics. Vi giver også et bottom-up overblik over kønsfordele, fra dens samfundsmæssige oprindelse til dens spredning på sproget. Endelig forbinder vi de samfundsmæssige konsekvenser af kønsfordele med deres tilsvarende type(r) i den foreslåede taksonomi. Den underliggende motivation i vores arbejde er at hjælpe det tekniske fællesskab med at identificere og afbøde relevante fordomme fra træning corpora for forbedret retfærdighed i NLP systemer.</abstract_da>
      <abstract_nl>Genderongelijkheid betekent een aanzienlijk verlies van menselijk potentieel en bestendigt een cultuur van geweld, hogere loonverschillen tussen mannen en vrouwen en een gebrek aan vertegenwoordiging van vrouwen in hogere en leidinggevende posities. Toepassingen die worden aangedreven door kunstmatige intelligentie (AI) worden steeds vaker gebruikt in de echte wereld om kritische beslissingen te nemen over wie gaat worden aangenomen, een lening wordt toegekend, toegelaten tot de universiteit, enz. De belangrijkste pijlers van AI, Natural Language Processing (NLP) en Machine Learning (ML) zijn echter aangetoond dat ze gendervoorraden en stereotypen weerspiegelen en zelfs versterken. die hoofdzakelijk geërfd zijn van historische opleidingsgegevens. In een poging om de identificatie en beperking van gender bias in Engelse tekst te vergemakkelijken, ontwikkelen we een uitgebreide taxonomie die gebaseerd is op de volgende gender bias types: generieke voornaamwoorden, seksisme, beroepsvooroordelen, exclusionary bias en semantics. We bieden ook een bottom-up overzicht van gender bias, van de maatschappelijke oorsprong tot de spillover op taal. Tot slot koppelen we de maatschappelijke implicaties van gender bias aan hun overeenkomstige type(en) in de voorgestelde taxonomie. De onderliggende motivatie van ons werk is om de technische gemeenschap in staat te stellen relevante vooroordelen van trainingscorpora's te identificeren en te verminderen voor een betere eerlijkheid in NLP-systemen.</abstract_nl>
      <abstract_de>Geschlechterungleichheit bedeutet einen erheblichen Verlust an menschlichem Potenzial und hält eine Kultur der Gewalt, höhere geschlechtsspezifische Lohnunterschiede und eine mangelnde Vertretung von Frauen in höheren und Führungspositionen aufrecht. Anwendungen, die auf künstlicher Intelligenz (KI) basieren, werden zunehmend in der realen Welt verwendet, um kritische Entscheidungen darüber zu treffen, wer eingestellt, ein Darlehen gewährt, zum College zugelassen wird, usw. Jedoch haben sich gezeigt, dass die Hauptsäulen von KI, Natural Language Processing (NLP) und Machine Learning (ML) geschlechtsspezifische Vorurteile und Stereotypen reflektieren und sogar verstärken. die hauptsächlich aus historischen Trainingsdaten stammen. Um die Identifizierung und Verminderung von Gender Bias im englischen Text zu erleichtern, entwickeln wir eine umfassende Taxonomie, die auf den folgenden Gender Bias Typen basiert: Generische Pronomen, Sexismus, Berufliche Bias, Ausschließliche Bias und Semantik. Wir bieten auch einen Bottom-up-Überblick über geschlechtsspezifische Vorurteile, von ihrer gesellschaftlichen Herkunft bis zu ihrem Spillover auf Sprache. Schließlich verknüpfen wir die gesellschaftlichen Implikationen von Gender Bias mit ihren entsprechenden Typen in der vorgeschlagenen Taxonomie. Die zugrunde liegende Motivation unserer Arbeit besteht darin, der technischen Gemeinschaft zu helfen, relevante Vorurteile aus Trainingskorpora zu identifizieren und zu mindern, um die Fairness in NLP-Systemen zu verbessern.</abstract_de>
      <abstract_hr>Gender inequality predstavlja značajan gubitak ljudskog potencijala i zauvijek održava kulturu nasilja, veće praznine plaće za spol i nedostatak zastupanja žena na višim i vodećim položajima. U stvarnom svijetu se sve više koriste aplikacije pod nadzorom umjetne obavještajne informacije (AI) kako bi pružili kritične odluke o tome tko će biti angažovan, posuditi kredit, priznat na fakultet itd. Međutim, pokazali su glavni stupovi AI, procesa prirodnog jezika (NLP) i učenja strojeva (ML) koji odražavaju i čak pojačavaju spolne predrasude i stereotipe, koje se uglavnom naslijeđuju iz istorijskih podataka o obuci. U pokušaju olakšanja identifikacije i smanjenja spolnih pristrasnosti na engleskom tekstu, razvijamo sveobuhvatnu taksonomiju koja se oslanja na sljedeće tipove spolnih pristrasnosti: generalne proglaske, seksizm, profesionalne bije, ekskluzivne bije i semiantike. Također pružamo donji pregled spolnog pristrasnosti, od njegovog društvenog porijekla do njegovog prolivača na jezik. Konačno povezujemo socijalne implikacije spolnih pristrasnosti s njihovim odgovarajućim tipom(ima) u predloženoj taksonomiji. Na temelju motivacije našeg rada je pomoć omogućiti tehničkoj zajednici da identificira i smanji relevantne predrasude od obuke tijela za poboljšanje pravednosti u sustavima NLP-a.</abstract_hr>
      <abstract_id>Ketidapatan jenis mewakili kehilangan potensi manusia yang konsiderel dan mengembangkan budaya kekerasan, perbedaan gaji jenis yang lebih tinggi, dan kekurangan perwakilan wanita di posisi yang lebih tinggi dan pemimpin. Aplikasi yang dipakai oleh Intelijen Seni (AI) semakin digunakan di dunia nyata untuk menyediakan keputusan kritis tentang siapa yang akan disewa, diberikan pinjaman, diterima di kuliah, dll. Namun, pilar utama AI, Proses Bahasa Alami (NLP) dan Pempelajaran Mesin (ML) telah menunjukkan untuk merefleksikan dan bahkan memperkuat biases dan stereotipe jenis, Yang paling mewarisi dari data latihan sejarah. Dalam usaha untuk memudahkan identifikasi dan perlengkapan bias jenis dalam teks Inggris, kami mengembangkan taksonomi komprensif yang bergantung pada tipe bias jenis jenis jenis berikut: Pronouns Generic, Sexism, Occupational Bias, Exclusionary Bias, dan Semantics. We also provide a bottom-up overview of gender bias, from its societal origin to its spillover onto language.  Akhirnya, kita menghubungkan implikasi masyarakat dari bias jenis dengan tipe(jenis) mereka yang cocok dalam taksonomi yang diusulkan. Motivasi dasar dari pekerjaan kita adalah untuk membantu masyarakat teknik untuk mengidentifikasi dan mengurangi bias relevan dari pelatihan korpora untuk memperbaiki keadilan dalam sistem NLP.</abstract_id>
      <abstract_fa>نابرابری جنسی یک خسارت بزرگی از پتانسیل انسان را معرفی می‌کند و فرهنگ خسارت را جاودانه می‌کند، فاصله‌های پرداخت جنسی بالاتر و ناتوانی نمایش زنان در موقعیت های بالاتر و رهبری. برنامه‌هایی که توسط اطلاعات مصنوعی (AI) قدرت می‌دهند، بیشتر در دنیای واقعی استفاده می‌شوند تا تصمیم‌های مهمی در مورد کسانی که استخدام می‌شوند، قرض داده می‌شوند، به دانشگاه اجازه داده می‌شوند و غیر از آن می‌شوند. با این حال، ستون‌های اصلی AI، پرداخت زبان طبیعی (NLP) و یادگیری ماشین (ML) نشان داده شده‌اند که که در اصل از داده های آموزش تاریخی وارث می شوند. در تلاش برای آسان شناسایی و کاهش تعادل جنسی در متن انگلیسی، ما یک تاکسونوم کامل را توسعه می‌کنیم که بر این نوع تعادل جنسی بستگی دارد: نژادهای ژنرالی، سکسیسم، بیس‌های شغلی، بیس‌های خارجی و سیمانتیک. ما همچنین یک نگاهی پایین بالا از نحوه جنسی، از اصل اجتماعی آن تا نحوه‌اش به زبان می‌رسانیم. بالاخره، ما اثرات اجتماعی جنسیت را به نوع(ها) متعلق به تاکسونوم پیشنهاد ارتباط می‌دهیم. انگیزه‌های بنیادی کار ما این است که کمک به اجتماعی تکنیکی را اجازه دهیم تا جامعه‌های ارتباطی را شناسایی و کاهش دهند و از شرکت آموزش دادن برای بهتر عدالت در سیستم‌های NLP.</abstract_fa>
      <abstract_sw>Ukosefu wa kijinsia unawakilisha hasara kubwa ya uwezekano wa binadamu na unaendelea na utamaduni wa ghasia, mapambano ya kijinsia, na ukosefu wa uwakilishi wa wanawake katika nafasi za juu na uongozi. Matumizi yanayowezekana na Intelliti ya Kisanaa (AI) yanatumiwa kwa kiasi kikubwa duniani ili kutoa maamuzi muhimu kuhusu nani ataajiriwa, kupata deni, kukabiliwa chuo, etc. Hata hivyo, nguzo kuu za AI, Utendaji wa Lugha za Kiasili (NLP) na Ufunzi wa Mashiniki (ML) zimeonyeshwa kutafakari na kuimarisha upendeleo wa kijinsia na vibaya, ambazo zinarithishwa kwa takwimu za mafunzo ya kihistoria. Katika jitihada za kusaidia kutambua na kutengeneza upendeleo wa kijinsia kwa lugha ya Kiingereza, tunaendelea koksnoma ya kina inayotegemea a in a zifuatazo za kijinsia: Maandamano ya ujumla, jinsia, Bia za Kiajira, Bias na Semantics. Pia tunatoa mtazamo wa chini juu wa upendeleo wa kijinsia, kutoka asili yake ya kijamii mpaka kwenye lugha yake. Mwisho, tunaunganisha matatizo ya kijamii ya upinzani wa kijinsia na aina(s) inayolinganisha katika utamaduni unapendekezwa. Lengo la msingi la kazi zetu ni kusaidia jamii ya teknolojia kutambua na kupunguza upendeleo unaohusika kutoka kwa mafunzo ya kampuni ya usawa katika mfumo wa NLP.</abstract_sw>
      <abstract_af>Gender inekwaliteit verteenwoordig 'n betekende verlies van menslike potensiele en verwag 'n kultuur van geweld, hoëre geneemde vergelde gapes en 'n mankaak van verteenwoordigheid van vroue in hoër en leiersposisies. Toepassinge wat deur Kunstenaar Inteligence (AI) krag is, word vermeerder gebruik word in die reël wêreld om kritiese besluite te verskaf oor wie gaan ontvang word, toegelaat 'n loan, aangeneem na kolleks, ens. Maar, die hoofpilare van AI, Natuurlike Taal Prosessering (NLP) en Masjien Leer (ML) is vertoon om te reflekteer en selfs versterk seuns biases en stereotipes, wat hoofsaaklik van historiese onderwerp data erfdeel word. In 'n versoek om die identifikasie en gemeindiging van gemeenskappe in Engelske teks te maak, ontwikkel ons 'n komplettende taksonomie wat op die volgende geneemde bias tipes aflyk: Generies Pronouns, Sexism, Occupational Bias, Exclusionary Bias en Semantics. Ons verskaf ook 'n ondersteunde oorskou van geneemgeweld, van sy gemeenskap oorspronklik tot sy spelonder na taal. Eindelik, ons skakel die samelewing inplikasies van gemeenskap aan hul ooreenstemmende tipe(s) in die voorgestelde taksonomie. Die onderstelde motivasie van ons werk is om die tegniese gemeenskap te help om relevant biases te identifiseer en verminder van die onderwerp van die korpora vir verbeterde regverdigheid in NLP stelsels.</abstract_af>
      <abstract_ko>성별 불평등은 인류 잠재력의 막대한 손실을 의미하고 폭력 문화를 영구화하며 성별 임금 격차가 커지고 여성이 더 높고 리더십에 있어서의 대표성이 부족하다는 것을 의미한다.인공지능(AI)이 지원하는 앱은 현실 세계에서 누가 고용될 것인지, 대출을 받을 것인지, 대학에 진학할 것인지 등에 대한 관건적인 의사결정을 제공하는 데 점점 더 많이 사용되고 있다. 그러나 인공지능, 자연언어처리(NLP)와 머신러닝(ML)의 주요 기둥은 성별 편견과 판에 박힌 인상을 반영하고 있음을 증명하고 있다.주로 역사 훈련 데이터에서 물려받은 것이다.영어 텍스트의 성 편견을 식별하고 완화시키는 데 도움을 주기 위해 우리는 전면적인 분류법을 개발했다. 이 분류법은 다음과 같은 성 편견 유형인 통용 대명사, 성 차별, 직업 편견, 배타적 편견과 의미에 의존한다.우리는 또한 사회의 기원부터 언어에 대한 과잉에 이르기까지 아래에서 위로의 성별 편견에 대한 개술도 제공했다.마지막으로 우리는 성별 편견의 사회적 영향과 의안 분류법의 상응하는 유형을 연결시킨다.우리가 일하는 근본적인 동기는 기술계가 교육 자료 라이브러리의 관련 편견을 식별하고 완화시켜 NLP 시스템의 공평성을 높이는 데 도움을 주는 것이다.</abstract_ko>
      <abstract_sq>Pabarazia gjinore përfaqëson një humbje të konsiderueshme të potencialit njerëzor dhe vazhdon një kulturë dhune, dallime më të larta pagash gjinore dhe një mungesë përfaqësimi i grave në pozita më të larta dhe udhëheqëse. Aplikatat e fuqizuara nga Inteligjenca Artifike (AI) po përdoren gjithnjë e më tepër në botën reale për të ofruar vendime kritike rreth kë do të punësohet, do të jepet një hua, do të pranohet në kolegj, etj. Megjithatë, shtyllat kryesore të AI, Procesimit të Gjuhave Natyrore (NLP) dhe Mësimit të Makinës (ML) janë treguar që reflektojnë dhe madje amplifikojnë paragjykimet dhe stereotipet e gjinisë, - që janë trashëguar kryesisht nga të dhënat historike të trainimit. Në një përpjekje për të lehtësuar identifikimin dhe lehtësimin e paragjykimit të gjinisë në tekstin anglez, ne zhvillojmë një taksonomie të përgjithshme që mbështetet në tipet e paragjykimit të gjinisë të ardhshëm: pronimet gjenerike, seksizmi, paragjykimi profesional, paragjykimi ekskluziv dhe Semantika. Ne ofrojmë gjithashtu një përmbledhje poshtë lart të paragjykimit të gjinisë, nga origjina e saj shoqërore deri në shpërndarjen e saj në gjuhë. Më në fund, ne lidhim pasojat shoqërore të paragjykimit të gjinisë me llojin e tyre të përshtatshëm në taksonominë e propozuar. The underlying motivation of our work is to help enable the technical community to identify and mitigate relevant biases from training corpora for improved fairness in NLP systems.</abstract_sq>
      <abstract_am>የሴት ንቅናቄ የሰው ስልጣናዊ ጉዳይ እና የዓመፅ ግንኙነት፣ ከፍተኛ የሴት ዋጋ ክፍል እና ከፍተኛ እና የመራመሪያ ቦታዎች ላይ የሴቶችን ቁጥር ማሳየት አይጎድልበትም፡፡ በአርስቲካዊ Intelligence (AI) የሚችሉትን ፕሮግራሞች ለማን እንዲቀጠሩ፣ ለማን እንዲቀጠሩ፣ ለኮሌጅ እንዲገባ፣ ለማድረግ የሚችሉትን አዋቂዎች እና የመኪን ትምህርት መሠረት እና ማሳየት (ML) ለማስተዋልት እና ለማድረግ፣ የሴቶችን ድጋፍ እና ድጋፍ እና ተሳታፊዎችን ለማድረግ ይታያል፡፡ ታሪክ ትምህርት ማህበረሰብ ዳታ ወረሱ፡፡ በንግግሊዝኛ ጽሑፍ ውስጥ የሴቶችን ብሔራዎችን ለማግኘት እና ለማቀናቀል ለመቻል፣ በሚከተሉት የሴቶችን ብሔራዊ ጥያቄ እናደርጋለን፡፡ We also provide a bottom-up overview of gender bias, from its societal origin to its spillover onto language.  በመጨረሻም የሴት ብሔራዊ ጥያቄዎችን በተዘጋጀው ጥያቄ ውስጥ እናስገራለን፡፡ የሥራችን ውስጥነት የቴክኖክቲካዊ ማኅበረሰብ ከNLP ስርዓቶች ውስጥ ትክክለኛነትን ለማሻለል እና ማቅረብ ማቅረብ ነው፡፡</abstract_am>
      <abstract_tr>Jenkörlük değersizliğin insan potansiyelinin ýitilmesini ve şiddet kültürünü sürdürür, cinsel işi boşluklarının yüksek ve liderlik pozisyonlarında kadınlaryň temsilcisi yoktur. Halk inteligensiýa (AI) tarapyndan güýçli Uygulamalar Gerçek dünýäde özüne işe alan, bermäge borç berilen, fakultede kabul edilen we bölegi barada kritik kararlar bermek üçin ulanýarlar. Ýöne-de, AI'niň esasy sütunlary, Natural Language Processing (NLP) we Maşynyň öwrenmesi (ML) diýip görünýär we hatta cinsiýa biaslaryny we stereotiplerini bejermek üçin üýtgeden Olar taryhy eğitim maglumatyndan ilkinji gezek bolýar. Iňlis dilinde jentiller bias ını tanamak we küçülemek üçin gurlap çykyşymyz üçin, biz diňe bir topar arzanlaşyk bilen täsirli bir taxonomiýa düşürip çykýarys: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics (Täze Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics). Biz hem jentil täsirlerini, jemgyýetiň başlangyşyndan çykyşynyň diline çenli bir nusgasyny berýäris. Soňunda biz jentiller täsirleriniň jemgyýetiň täsirlerini teklip eden taksionomiýada baglaýarys. Biziň işimiziň esasy motivasy NLP sistemalarynda adalatlygyny gelişmek üçin korporadyň ukyplaryny tanamak we azaltmak üçin teknik toplumyna kömek etmekdir.</abstract_tr>
      <abstract_hy>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions.  Արվեստական ինտելեկտության (ԱԲ) կողմից օգտագործվող ծրագրերը ավելի ու ավելի են օգտագործվում իրական աշխարհում, որպեսզի կարևոր որոշումներ տրամադրեն այն մասին, թե ով է վարձվում, վարկ տալիս, ընդունվում է համալսարան, և այլն: Սակայն, ԱԲ-ի, Բնական լեզվի վերլուծության (ՆԼՊ) և Մեքենայի ուսումնասիրության (ՄԼ) հիմնական աստիճանները արտաց - որոնք հիմնականում ժառանգում են պատմական ուսուցման տվյալներից: Փորձելով հասարակել գենդերային կողմնականության հայտնաբերումը և նվազեցնելը անգլերենի տեքստում, մենք զարգանում ենք ընդհանուր դասակարգչային համակարգ, որը հիմնված է հետևյալ գենդերային կողմնականության տեսակների վրա՝ գենդերական կողմնականությունների, սեքսիզմի, մասնագիտական կողմնակ Մենք նաև գենդերային կողմնականության ներքև վերևում գտնվող գենդերային կողմնականության վերաբերյալ ենք տրամադրում, հասարակական ծագումից մինչև լեզվի տարածումը: Վերջապես, մենք կապում ենք գենդերային կողմնականության հասարակական հետևանքները նրանց համապատասխան տեսակի հետ առաջարկած դասակարգության մեջ: Մեր աշխատանքի հիմնական դրդապատճառն այն է, որ օգնենք տեխնիկական համայնքին բացահայտել և նվազեցնել նշանակալի կողմնականություններ, որոնք կատարվում են ՆԼՊ համակարգերում բարելավված արդարության համար:</abstract_hy>
      <abstract_bs>Gender inequality predstavlja značajan gubitak ljudskog potencijala i zauvijek održava kulturu nasilja, veće praznine plaće za spol i nedostatak zastupanja žena na višim i vodstvenim položajima. U stvarnom svijetu se sve više koriste aplikacije pod nadzorom umjetne obavještajne informacije (AI) kako bi pružili kritične odluke o tome ko će biti angažovan, posuditi kredit, priznat na fakultet itd. Međutim, pokazali su glavni stupovi AI, procesa prirodnog jezika (NLP) i učenja mašine (ML) koji odražavaju i čak pojačavaju spolne predrasude i stereotipe, koje se uglavnom naslijeđuju iz istorijskih podataka o obuci. U naporima za olakšanje identifikacije i smanjenje spolnih pristrasnosti na engleskom tekstu, razvijamo kompletnu taksonomiju koja se oslanja na sljedeće tipove spolnih pristrasnosti: generalne prognoze, seksizm, profesionalne bije, ekskluzivne bije i semiantike. Također pružamo donji pregled spolnih predrasuda, od njegovog društvenog porijekla do njegovog prolivača na jezik. Konačno povezujemo socijalne implikacije spolnih predrasuda sa njihovim odgovarajućim tipom(ima) u predloženoj taksonomiji. Na temelju motivacije našeg rada je da pomognemo tehničkoj zajednici da identifikuje i smanji relevantne predrasude od obuke korporacije za poboljšanje pravednosti u NLP-ovim sistemima.</abstract_bs>
      <abstract_ca>La desigualtat de gènere representa una pèrdua considerable del potencial humà i perpetua una cultura de violència, més grans diferències salariales de gènere i la falta de representació de dones en posicions superiors i de lideratge. Les aplicacions alimentades per la Inteligència Artificial (AI) s'utilitzen cada vegada més en el món real per proporcionar decisions crítiques sobre qui serà contratat, donat un préstec, admitit a la universitat, etc. Tot i així, els pilars principals de l'AI, el Procesament de Llingua Natural (NLP) i l'Aprendiment Màquin (ML) han demostrat reflexionar i fins i tot amplificar les tendències i estereotips de gènere, que es hereten principalment de dades històriques d'entrenament. En un esforç per facilitar l'identificació i la mitigació del bias de gènere en el text anglès, desenvolupem una taxonomia completa que es basa en els següents tipus de bias de gènere: Pronom genèric, Sexisme, Bias Occupacionals, Bias Exclusionaris i Semàtics. També proporcionem una visió general de baix a dalt del bias de gènere, des del seu origen social fins al seu diferència al llenguatge. Finalment, enllacem les implicacions socials del bias de gènere amb els seus tipus correspondents en la taxonomia proposada. La motivació subjacente de la nostra feina és ajudar a permetre a la comunitat tècnica identificar i mitigar les tendències pertinents de la formació corporal per millorar la justesa en els sistemes NLP.</abstract_ca>
      <abstract_cs>Nerovnost pohlaví představuje značnou ztrátu lidského potenciálu a udržuje kulturu násilí, vyšší rozdíly mezd žen a mužů a nedostatek zastoupení žen ve vyšších a vedoucích pozicích. Aplikace poháněné umělou inteligencí (AI) se v reálném světě stále častěji používají k poskytování kritických rozhodnutí o tom, kdo bude přijat, kdo bude půjčen, přijat na vysokou školu atd. Nicméně, hlavní pilíře AI, zpracování přírodního jazyka (NLP) a strojového učení (ML) odrážejí a dokonce zesilují genderové zaujatosti a stereotypy, které jsou převážně zděděny z historických výcvikových dat. Ve snaze usnadnit identifikaci a zmírnění genderové zaujatosti v anglickém textu vytváříme komplexní taxonomii, která se opírá o následující typy genderových zaujatostí: obecná zájmena, sexismus, profesní zaujatost, exkluzivní zaujatost a sémantika. Poskytujeme také zdola nahoru přehled genderové zaujatosti, od jejího společenského původu až po její překlad na jazyk. Nakonec propojujeme společenské důsledky genderové předsudků s jejich odpovídajícími typy v navrhované taxonomii. Základní motivací naší práce je umožnit technické komunitě identifikovat a zmírnit relevantní zaujatosti ze vzdělávacích korpusů pro zlepšení spravedlivosti v NLP systémech.</abstract_cs>
      <abstract_et>Sooline ebavõrdsus kaotab märkimisväärselt inimpotentsiaali ning säilitab vägivallakultuuri, suuremaid soolisi palgalõhesid ning naiste esindatuse puudumist kõrgematel ja juhtivatel ametikohtadel. Tehisintellekti (AI) rakendusi kasutatakse reaalses maailmas üha enam kriitiliste otsuste tegemiseks selle kohta, kes palkatakse, kes antakse laenu, võetakse vastu kolledžisse jne. Siiski on näidatud, et tehisintellekti, looduskeelte töötlemise (NLP) ja masinõppe (ML) peamised sambad peegeldavad ja isegi võimendavad soolisi eelarvamusi ja stereotüüpe, mis pärinevad peamiselt varasematest koolitusandmetest. Selleks et hõlbustada soolise eelarvamuse tuvastamist ja leevendamist ingliskeelses tekstis, töötame välja tervikliku taksonoomia, mis tugineb järgmistele soolise eelarvamuse tüüpidele: üldised pronounid, seksism, ametialane eelarvamus, eksklusiivne eelarvamus ja semantika. Samuti anname alt üles ülevaate soolisest eelarvamusest alates selle ühiskondlikust päritolust kuni selle ülekandumiseni keelele. Lõpuks seostame soolise eelarvamuse ühiskondlikud mõjud nende vastavate tüüpidega kavandatud taksonoomias. Meie töö aluseks on aidata tehnilistel kogukondadel tuvastada ja leevendada koolituskorporate asjakohaseid eelarvamusi, et parandada õiglust uue õppekava süsteemides.</abstract_et>
      <abstract_az>Cinlər ədalətsizliyi insan potensialinin böyük bir zərəri göstərir və şiddətli kültürünü sürəkləyir, cins mükafatlarını daha yüksək və liderlik məqamlarında qadınların representasiyonu yoxdur. Yaxşı Bilgi (AI) tarafından güclü proqramlar kimin istifadə ediləcəyini, kimin istifadə ediləcəyini, kimin qənimət verəcəyini, kollekəyə qəbul ediləcəyini və bu cür qərar vermək üçün gerçek dünyada daha çox istifadə edilirlər. Ancaq AI, Təbiətli Dil Proqramının (NLP) və Makin Öyrənməsi (ML) ən böyük sütunları düşünüb, hətta cins tərzlərini və stereotiplərini daha çox Həqiqətən, tarihi təhsil məlumatlarından varis edilir. İngilis metinlərində cins təsirlərini tanıtmaq və küçük etmək üçün, biz bu cins təsirlərinə bağlı olan bütün taxonomiya düzəltdik: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias və Semantics. Biz həmçinin cins tərəfindən, sosyal tərəfindən dilinə çevrilməsinə qədər tərəfindən a şağı tərəfindən bir nümunə veririk. Sonunda, biz cins təsirlərinin müqayisəsi tərzlərinə təklif edilmiş taxonomiyada əlavə edilən tərzlərinə bağlamışıq. Bizim işimizin əsl motivasiyonu NLP sistemlərində ədaləti daha yaxşılaşdırmaq üçün korpora təhsil etməkdən və düzəltməkdən əlaqəli təsirləri tanıma və düzəltməyə kömək etməkdir.</abstract_az>
      <abstract_bn>লিঙ্গের বৈষম্যের প্রতিনিধিত্ব হচ্ছে মানুষের সম্ভাবনার বেশী ক্ষতিগ্রস্ত এবং সহিংসতার সংস্কৃতি, উচ্চতর লিঙ্গ বেতনের বিভাগ এবং উচ্চতর এবং  আর্টিফিকেল ইন্টেলিজেন্স (এআই) দ্বারা ক্ষমতাশীল অ্যাপলিকেশন বেশী ব্যবহার করে যাচ্ছে যে কারা ভাড়া করবে, কার জন্য গুরুত্বপূর্ণ সিদ্ধান্ত প্রদান করা হবে, যাতে কলেজে স্বীকৃতি প্রদান করা হবে। তবে এআই, প্রাকৃতিক ভাষার প্রক্ যা মূলত ঐতিহাসিক প্রশিক্ষণের তথ্য থেকে উত্তরাধিকারী। ইংরেজী টেক্সটে লিঙ্গের বৈষম্য পরিচিতি এবং অপসারণের জন্য আমরা একটি সম্পূর্ণ ট্যাক্সোনোমি উন্নয়ন করি যা নিম্নলিখিত লিঙ্গের বৈষম্যের উপর নির্ভর করে: সাধারণ প্রোনোনোন, যৌন, কাজ, কা আমরা তাদের সামাজিক প্রজন্ম থেকে তাদের ভাষায় উল্লেখযোগ্য ভাষা থেকে। Finally, we link the societal implications of gender bias to their corresponding type(s) in the proposed taxonomy.  আমাদের কাজের মূল উদ্দেশ্য হচ্ছে প্রযুক্তিগত সম্প্রদায়কে সাহায্য করার জন্য এনএলপি সিস্টেমে ন্যায়বিচারের জন্য প্রশিক্ষণ করা কোর্প</abstract_bn>
      <abstract_fi>Sukupuolten eriarvoisuus merkitsee huomattavaa inhimillisen potentiaalin menetystä ja ylläpitää väkivallan kulttuuria, korkeampia sukupuolten palkkaeroja ja naisten edustuston puutetta ylemmissä ja johtotehtävissä. Tekoälyn (AI) tukemia sovelluksia käytetään yhä enemmän todellisessa maailmassa kriittisten päätösten tekemiseen siitä, ketä palkataan, myönnetään lainaa, hyväksytään collegeen jne. Kuitenkin tekoälyn, luonnollisen kielen käsittelyn (NLP) ja koneoppimisen (ML) pääpilarien on osoitettu heijastavan ja jopa vahvistavan sukupuolivääristymiä ja stereotypioita, jotka periytyvät pääasiassa aikaisemmista koulutustiedoista. Pyrimme helpottamaan sukupuoliharhan tunnistamista ja lieventämistä englanninkielisessä tekstissä, ja kehitämme kattavan taksonomian, joka perustuu seuraaviin sukupuoliharhatyyppeihin: Generic Pronomins, Sexism, Occupational Bias, Exclusionary Bias ja Semantics. Tarjoamme myös alhaalta ylöspäin suuntautuvan yleiskatsauksen sukupuolijakauman yhteiskunnallisesta alkuperästä kieleen siirtymiseen. Lopuksi yhdistämme sukupuolen vääristymisen yhteiskunnalliset vaikutukset ehdotettuun taksonomiaan vastaaviin tyyppeihin. Työn taustalla oleva motivaatio on auttaa teknistä yhteisöä tunnistamaan ja lieventämään koulutuskorpusten aiheuttamia ennakkoluuloja, jotka parantavat oikeudenmukaisuutta NLP-järjestelmissä.</abstract_fi>
      <abstract_ha>Sinai da jini yana halartar hasara mai girma ga mataimaki ya mutane kuma yana daɗa wata kultur na tunkuɗe, gaurar musahar jinsi da kuma bã da hasãra ga mataimaka a cikin wurãren nan sarki da shiryuwar. Shiryoyin ayukan da aka yi na amfani da Shirin Intifar (AI) ana ƙara amfani da su a cikin duniya halinsa dõmin a bãyar da hukuncin muhimma masu iya muhimma wa wanda zai yi kirada, aka bai wa kodi, aka shigar da shi a cikin dufai, etc. Amma, an nuna muhimmin taskõkin AI, Jalalar Ayuka na Natural (NLP) da Learnin Machine (ML) zuwa a yi tunãni da kuma za'a ƙarfafa saurin jinni da maras, @ info: whatsthis Ko cikin aikin ka sauƙa ƙara ganin da za'a sauƙaƙara wa misalin mutane a cikin littãfin Ingiriya, za'a develope wani taxnomi mai jumla wanda ke dõgara nauyin jinsi da ke biyar: Kayya, Munã samar da wani misalin sauri daga zayenta zuwa harshensa. Na ƙarama, Munã haɗe da masu aikin jamii da za'a sami zuwa irin mutane da ke daidai a cikin taksomin da aka faɗa. Bayan kashi na aikinmu yana taimakon jamii na technical su gane da kuma su cire gaura masu muhimmi daga shirin makampuni don ya improve ãdalci a cikin tsarin NLP.</abstract_ha>
      <abstract_sk>neenakost med spoloma pomeni precejšnjo izgubo človeškega potenciala in ohranja kulturo nasilja, višje razlike v plačah med spoloma ter pomanjkanje zastopanosti žensk na višjih in vodilnih položajih. Aplikacije, ki jih poganja umetna inteligenca (AI), se v resničnem svetu vse bolj uporabljajo za zagotavljanje kritičnih odločitev o tem, kdo bo najet, odobren posojilo, sprejet na kolidž itd. Vendar se je pokazalo, da glavni stebri umetne inteligence, obdelave naravnega jezika (NLP) in strojnega učenja (ML) odražajo in celo povečujejo pristranskosti spolov in stereotipe, ki so večinoma podedovani iz preteklih podatkov o usposabljanju. V prizadevanjih za lažje prepoznavanje in ublažitev spolnih pristranskosti v angleškem besedilu razvijamo celovito taksonomijo, ki temelji na naslednjih vrstah spolnih pristranskosti: generična imena, seksizem, poklicna pristranskost, izključevalna pristranskost in semantika. Zagotavljamo tudi pregled pristranskosti med spoloma od spodaj navzgor, od njenega družbenega izvora do prelivanja na jezik. Nazadnje povezujemo družbene posledice pristranskosti med spoloma z ustreznimi tipi v predlagani taksonomiji. Osnovna motivacija našega dela je pomagati tehnični skupnosti prepoznati in ublažiti ustrezne pristranske korpusov usposabljanja za izboljšanje pravičnosti v sistemih NLP.</abstract_sk>
      <abstract_jv>Genjer Aplikasi sing ditambah ning Artidical AI (AI sumulai Sing jewis nggawe sistem sing nyimpen nggunakake karo hal-jewis karo nganggep kanggo ngilangno iki, awake dhéwé wis entekaké karo aturan sing gawe nguasai perusahaan karo hal-jewisan iki: Generc Pronoons, sextalism, Jobal Bias, Inclusary Bias, lan semanti. Awakdhéwé nganggo nggawe barang-barang kanggo ngerasakno babagan barang, suku tanggal barang komunitas nang ingkang ambabarang. Lha wih-wih, awak dhéwé nyukaké perusahaan soko-perusahaan iki dadi iki dadi, nik awak dhéwé nggawe Tipe(s) sing berarti tambah nêmên. Awak dhéwé éntuk aksi perbudhakan kanggo nglanggar ngéwé komunitas teknik kanggo nambah lan ujian sing beraksi kanggo nggawe barang-ujaran kanggo nggawe barang tambah kanggo ngilanggar aturan sing luwih dumadhi kanggo ngilanggar aturan NLP.</abstract_jv>
      <abstract_fil>Ang kaligayahan ng Gender ay nagtataglay ng malaking pagkawala ng mga kapangyarihan ng tao at nagtataglay ng kultura ng pangdadahas, mataas na mga gapas ng pangangasiwa ng lahi, at ng kulang ng pangangasiwa ng mga babae sa mataas at pangulo. Ang mga aplikasyon na may kapangyarihan ng Artificial Intelligence (AI) ay lumalaki na ginagamit sa totoong mundo upang magbigay ng mga critical decisions tungkol sa kanino inaupahan, magbibigay ng utang, inaasahan sa kolehiya, etc. Gayon ma'y ang mga pangulong haligi ng AI, Natural Language Processing (NLP) at Machine Learning Na pinamamana sa mga datos ng pag-aaral ng kasaysayan. Sa pinagsisikapan upang maganap ang pagtatanggap at pagbabagabag ng mga Gentil bias sa teksto ng Ingles, kami ay naglalabas ng buong taxonomy na umaasa sa mga sumusunod na uri ng Gentil bias: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, at Semantics. Nagbibigay din naman kami ng pagbabago ng mga pangangailangan ng lahi, mula sa kanyang mga sangkap hanggang sa kanyang pangangailangan sa wika. Sa katapusan, iniligtas namin ang societal implications ng gender bias sa kanilang corresponding type(s) sa inilagay na taxonomy. Ang ilalim na motivasyon ng ating trabaho ay tulungan ang teknik komunasyon upang makita at mitigasyon ang relevant bias sa pag-aaral ng korporasyon para maayong katuwiran sa mga sistema ng NLP.</abstract_fil>
      <abstract_he>אי שוויון מין מייצג אובדן משמעותי של פוטנציאל אנושי וממשיך לתרבות של אלימות, פערי שכר גבוהים יותר, וחסר מייצג של נשים בעמדות גבוהות יותר ומנהיגות. היישומים המכוננים על ידי המודיעין האמנתי (AI) משתמשים יותר ויותר בעולם האמיתי כדי לספק החלטות קריטיות לגבי מי הולך להיות שכר, נותן הלוואה, מוכר לקולג', וכו. שמורשת בעיקר ממידע האימונים היסטורי. במאמץ להקל את זיהוי והקלה של ההתמחות של מין בטקסט אנגלי, אנחנו מפתחים טקסונומיה כוללת שמבוססת על סוגי ההתמחות המיניים הבאים: אנחנו גם מספקים תצוגה מלמטה למעלה של ההתמחות מינית, ממקור החברתי שלה עד השפך שלה לשפה. סוף סוף, אנו קושרים את השלכות החברתיות של ההתמחות מינית לסוג(ים) המתאים שלהם במקסינומיה המוצעת. המוטיבציה המרכזית של העבודה שלנו היא לעזור לקהילה הטכנית לזהות ולקל את ההתמחות הרלוונטיות מהאימון של גופורה לשיפור הוגנות במערכות NLP.</abstract_he>
      <abstract_bo>Gender inequality represents a considerable loss of human potential and perpetuates a culture of violence, higher gender wage gaps, and a lack of representation of women in higher and leadership positions. རྒྱུ་དངོས་ཡོད་པའི་ཆེད་དུ་དང་ཐོག་ལས་དཀའ་ངལ་ཆེན་པོ་གཉིས་ཀྱིས་ལག་ལེན་འཐབ་དུ་འཇུག འདི་དག་ལོ་རྒྱུས་ལོ་རྒྱུས་ཀྱི་དབྱིབས་ཆོས་ཡོད་པའི་ཆོས་ཉིད་ཅིག་རེད། In an effort to facilitate the identification and mitigation of gender bias in English text, we develop a comprehensive taxonomy that relies on the following gender bias types: Generic Pronouns, Sexism, Occupational Bias, Exclusionary Bias, and Semantics. ང་ཚོས་རང་ཚོའི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དང་མི་འདྲ་བར་མཐོང་ཁག་ཅིག་ལ་རྒྱལ་ཁབ་ཅིག་གི་མཐོང་སྣང་བྱེད་ཀྱི་ཡོད། མཐའ་མར་དུ། ང་ཚོས་སྤྱི་ཚོགས་ཀྱི་དབུལ་གྱི་གནོད་འཚོལ་བ་ནི་ཁོང་ཚོའི་དབུལ་གྱི་རིགས་དང་མཐུན་སྒྲིག་འཇུག་ཆས་འདོ NLP མ་ལག་གི་བདེ་འཇགས་རིགས་དང་མཐུན་རྐྱེན་ཡར་རྒྱས་གཏོང་བའི་ཆེད་སྤྱི་ཚོགས་ལ་རོགས་མཐུན་དང་།</abstract_bo>
      </paper>
    <paper id="6">
      <title>Sexism in the Judiciary : The Importance of Bias Definition in <a href="https://en.wikipedia.org/wiki/Neuro-linguistic_programming">NLP</a> and In Our Courts<fixed-case>NLP</fixed-case> and In Our Courts</title>
      <author><first>Noa</first><last>Baker Gillis</last></author>
      <pages>45–54</pages>
      <abstract>We analyze 6.7 million case law documents to determine the presence of <a href="https://en.wikipedia.org/wiki/Gender_bias">gender bias</a> within our <a href="https://en.wikipedia.org/wiki/Judiciary">judicial system</a>. We find that current bias detection methods in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a> are insufficient to determine gender bias in our case law database and propose an alternative approach. We show that existing algorithms’ inconsistent results are consequences of prior research’s inconsistent definitions of biases themselves. Bias detection algorithms rely on groups of words to represent <a href="https://en.wikipedia.org/wiki/Bias">bias</a> (e.g., ‘salary,’ ‘job,’ and ‘boss’ to represent <a href="https://en.wikipedia.org/wiki/Employment">employment</a> as a potentially biased theme against women in text). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers’ own intuitions. We suggest two new methods of automating the creation of word lists to represent <a href="https://en.wikipedia.org/wiki/Bias">biases</a>. We find that our <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> outperform current NLP bias detection methods. Our research improves the capabilities of <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP technology</a> to detect <a href="https://en.wikipedia.org/wiki/Bias">bias</a> and highlights <a href="https://en.wikipedia.org/wiki/Sexism">gender biases</a> present in influential case law. In order to test our NLP bias detection method’s performance, we regress our results of bias in case law against <a href="https://en.wikipedia.org/wiki/United_States_Census">U.S census data</a> of women’s participation in the workforce in the last 100 years.</abstract>
      <url hash="0cc4e192">2021.gebnlp-1.6</url>
      <doi>10.18653/v1/2021.gebnlp-1.6</doi>
      <bibkey>baker-gillis-2021-sexism</bibkey>
    <title_es>Sexismo en el poder judicial: la importancia de la definición de sesgo en la PNL y en nuestros tribunales</title_es>
      <title_ar>التحيز الجنسي في القضاء: أهمية تعريف التحيز في البرمجة اللغوية العصبية وفي محاكمنا</title_ar>
      <title_pt>Sexismo no Judiciário: a importância da definição de preconceito na PNL e em nossos tribunais</title_pt>
      <title_fr>Le sexisme dans le système judiciaire : l'importance de la définition des préjugés dans la PNL et dans nos tribunaux</title_fr>
      <title_ja>司法における性差別： NLPおよび裁判所におけるバイアスの定義の重要性</title_ja>
      <title_zh>法司性别歧视:NLP、法院偏见定义之要</title_zh>
      <title_hi>न्यायपालिका में लिंगवाद: एनएलपी और हमारे न्यायालयों में पूर्वाग्रह परिभाषा का महत्व</title_hi>
      <title_ru>Сексизм в судебной системе: важность определения предвзятости в НЛП и в наших судах</title_ru>
      <title_ukr>Сексизм у судовій системі: важливість визначення упередженості в НЛП та в наших судах</title_ukr>
      <title_ga>Gnéis sa Bhreithiúnacht: Tábhacht na Laofachta Sainmhíniú in NLP agus inár gCúirteanna</title_ga>
      <title_ka>ჟვკჟთჱმყრ ნა ეზსეთუთწრა: გაზნჲჟრრა ნა ბწჟ ევტთნთუთწრა გ NLP თ გ ნაქთრვ ჟყეთ.</title_ka>
      <title_el>Σεξισμός στη δικαιοσύνη: Η σημασία του ορισμού προκατάληψης στο ΝΛΠ και στα Δικαστήριά μας</title_el>
      <title_hu>Szexizmus az igazságszolgáltatásban: Az elkötelezettség definíciójának fontossága az NLP-ben és a bíróságokban</title_hu>
      <title_isl>Kynlíf í réttarhöldum: Mikilvægi skilgreiningar skaðleika í NLP og í réttum okkar</title_isl>
      <title_it>Il sessismo nella magistratura: l'importanza della definizione di Bias nel PNL e nelle nostre corti</title_it>
      <title_kk>Суджердегі сексизм: NLP және Суджердегі Bias анықтамасының маңыздылығы</title_kk>
      <title_ms>Sexism di Judiciary: Kepentingan Definisi Bias di NLP dan di Mahkamah Kami</title_ms>
      <title_ml>ജഡിസ്റ്ററിയില്‍ സെക്സിമി: NLP-ലും നമ്മുടെ കോടതികളിലും ബിയാസിന്റെ വിവരണത്തിന്റെ പ്രധാനപ്പെട്ടത്</title_ml>
      <title_mt>Is-sessiżmu fil-Ġudikatura: L-Importanza tad-Definizzjoni ta’ Bias fil-NLP u fil-Qrati tagħna</title_mt>
      <title_mn>Шүүхийн сексуализм: NLP болон шүүхийн тухай Биасын тодорхойлолтын чухал</title_mn>
      <title_mk>Сексизмот во судството: Важноста на дефиницијата на навредата во НЛП и во нашите судови</title_mk>
      <title_pl>Seksizm w sądownictwie: znaczenie definicji uprzedzeń w NLP i w naszych sądach</title_pl>
      <title_no>Seksismen i Judiciary: Viktigheten av Bias-definisjon i NLP og i Courts våre</title_no>
      <title_lt>Seksinis procesas teisme: Bias apibrėžimo svarba NLP ir Mūsų teismuose</title_lt>
      <title_ro>Sexismul în justiție: Importanța definiției Bias în PNL și în instanțele noastre</title_ro>
      <title_sr>Seksizam u sudnici: Važnost definicije Bias u NLP-u i u našim sudovima</title_sr>
      <title_si>ජූඩිසියරියේ සෙක්සිමය: The vitance of Bias definition in NLP and in our corts</title_si>
      <title_so>Sexism in the Judiciary: The Importance of Bias Definition in NLP and In Court</title_so>
      <title_sv>Sexism i rättsväsendet: betydelsen av bias definition i NLP och i våra domstolar</title_sv>
      <title_ta>தீவிரவாதியில் செக்சியம்: NLP மற்றும் எங்கள் கோடுகளில் முக்கியமான பையாஸ் வரையறையின் முக்கியம்</title_ta>
      <title_ur>جنسیسم جنسی: NLP اور ہماری کورتوں میں بیس کی تعریف کا اہم</title_ur>
      <title_uz>Hujjatda seksimonima: NLP va Mahakamlar davomida Bias ajratish muhim</title_uz>
      <title_vi>Quan hệ dâm dục trong ngành tư pháp: Điều quan trọng của lời nói trong ngôn ngữ NIchọc và trong phiên tòa của chúng tôi</title_vi>
      <title_bg>Сексизмът в съдебната власт: значението на дефиницията на предразсъдъци в НЛП и в нашите съдилища</title_bg>
      <title_nl>Sexisme in de rechterlijke macht: het belang van vooroordelen definitie in NLP en in onze rechtbanken</title_nl>
      <title_hr>Seksizam u sudnici: Važnost definicije Bias u NLP-u i u našim sudovima</title_hr>
      <title_da>Sexisme i retsvæsenet: Betydningen af bias definition i NLP og i vores domstole</title_da>
      <title_de>Sexismus in der Justiz: Die Bedeutung der Bias Definition in NLP und in unseren Gerichten</title_de>
      <title_id>Seksisme di pengadilan: Kepentingan Definisi Bias di NLP dan di pengadilan kami</title_id>
      <title_ko>사법에서의 성차별: NLP와 법원에서의 편견 정의의 중요성</title_ko>
      <title_fa>سکسیسم در دادگاه: مهم تعریف بیا در NLP و در دادگاه ما</title_fa>
      <title_sw>Ubaguzi katika Mahakama: Umuhimu wa uamuzi wa Bias katika NLP na Katika Mahakama yetu</title_sw>
      <title_af>Sexisme in die Judisie: Die belangrikheid van Bias definisie in NLP en in ons howe</title_af>
      <title_tr>Adalat Respublikasy: The Importance of Bias Definition in NLP and In Our Courts</title_tr>
      <title_sq>Seksimi në gjyqësor: rëndësia e përcaktimit të dëmtimeve në NLP dhe në gjykatat tona</title_sq>
      <title_am>በአዳጅ ውስጥ የቢas ውጤት: በNLP እና በፍርድ ውስጥ የቢas ውጤት ግንኙነት</title_am>
      <title_hy>Սեքսիզմը դատարանի մեջ. ՆԼՊ-ում և մեր դատարաններում աղետի սահմանման կարևորությունը</title_hy>
      <title_bn>বিচার বিভাগে: এনএলপি এবং আমাদের আদালতে বায়াস সংজ্ঞার গুরুত্বপূর্ণ</title_bn>
      <title_az>H칬kmd톛ki seksizm: NLP v톛 Qardlar캼m캼zda</title_az>
      <title_bs>Seksizam u sudnici: Važnost definicije Bias u NLP-u i u našim sudovima</title_bs>
      <title_ca>Sexisme a la judiciaria: La importància de la definició de biais en NLP i als nostres tribunals</title_ca>
      <title_cs>Sexismus v soudnictví: význam definice zaujatosti v NLP a u našich soudů</title_cs>
      <title_et>Seksism kohtutes: kallakute määratluse tähtsus uues õppekavas ja meie kohtutes</title_et>
      <title_fi>Seksismi oikeuslaitoksessa: Bias-määritelmän merkitys NLP:ssä ja tuomioistuimissa</title_fi>
      <title_he>סקסיזם בבית המשפט: חשיבות ההגדרה של ביאס ב-NLP ובבית המשפטים שלנו</title_he>
      <title_jv>Seksi kanggo kelas Yudhis: The Importance of Bias Defining in NLP and In We Curts</title_jv>
      <title_bo>Judiciary's Sexism: The Importance of Bias Definition in NLP and In Our Courts (Courts)</title_bo>
      <title_sk>Seksizem v sodstvu: pomen opredelitve pristranskosti v NLP in na naših sodiščih</title_sk>
      <title_ha>Sexem in the Domestic: The important of Bias Definition in NLP and In Mu court</title_ha>
      <title_fil>Sexism in the Judiciary: The Importance of Bias Definition in NLP and In Our Courts</title_fil>
      <abstract_ar>نقوم بتحليل 6.7 مليون وثيقة سوابق قضائية لتحديد وجود التحيز الجنساني داخل نظامنا القضائي. وجدنا أن الطرق الحالية لاكتشاف التحيز في البرمجة اللغوية العصبية غير كافية لتحديد التحيز الجنساني في قاعدة بيانات السوابق القضائية لدينا واقتراح نهج بديل. نظهر أن النتائج غير المتسقة للخوارزميات الحالية هي عواقب لتعريفات البحث السابق غير المتسقة للتحيزات نفسها. تعتمد خوارزميات الكشف عن التحيز على مجموعات من الكلمات لتمثيل التحيز (على سبيل المثال ، "الراتب" و "الوظيفة" و "الرئيس" لتمثيل التوظيف كموضوع متحيز محتمل ضد النساء في النص). ومع ذلك ، فإن طرق بناء هذه المجموعات من الكلمات لها العديد من نقاط الضعف ، في المقام الأول أن قوائم الكلمات تستند إلى حدس الباحثين. نقترح طريقتين جديدتين لأتمتة إنشاء قوائم الكلمات لتمثيل التحيزات. وجدنا أن أساليبنا تتفوق في الأداء على طرق الكشف عن التحيز في البرمجة اللغوية العصبية. يعمل بحثنا على تحسين قدرات تقنية البرمجة اللغوية العصبية لاكتشاف التحيز ويسلط الضوء على التحيزات بين الجنسين الموجودة في السوابق القضائية المؤثرة. من أجل اختبار أداء طريقة اكتشاف التحيز في البرمجة اللغوية العصبية لدينا ، فإننا نتراجع عن نتائجنا الخاصة بالتحيز في السوابق القضائية ضد بيانات التعداد السكاني في الولايات المتحدة لمشاركة المرأة في القوى العاملة في المائة عام الماضية.</abstract_ar>
      <abstract_es>Analizamos 6,7 millones de documentos de jurisprudencia para determinar la presencia de prejuicios de género en nuestro sistema judicial. Encontramos que los métodos actuales de detección de sesgos en PNL son insuficientes para determinar el sesgo de género en nuestra base de datos de jurisprudencia y proponer un enfoque alternativo. Mostramos que los resultados inconsistentes de los algoritmos existentes son consecuencia de las definiciones inconsistentes de los sesgos en sí mismos de investigaciones anteriores. Los algoritmos de detección de sesgos se basan en grupos de palabras para representar el sesgo (por ejemplo, «salario», «trabajo» y «jefe» para representar el empleo como un tema potencialmente sesgado contra las mujeres en el texto). Sin embargo, los métodos para construir estos grupos de palabras tienen varias debilidades, principalmente porque las listas de palabras se basan en las intuiciones de los propios investigadores. Sugerimos dos nuevos métodos para automatizar la creación de listas de palabras para representar sesgos. Descubrimos que nuestros métodos superan a los métodos actuales de detección de sesgos de PNL. Nuestra investigación mejora las capacidades de la tecnología de PNL para detectar sesgos y destaca los sesgos de género presentes en la jurisprudencia influyente. Con el fin de probar el rendimiento de nuestro método de detección de sesgos de PNL, retrocedemos nuestros resultados de sesgo en la jurisprudencia contra los datos del censo de EE. UU. sobre la participación de las mujeres en la fuerza laboral en los últimos 100 años.</abstract_es>
      <abstract_fr>Nous analysons 6,7 millions de documents de jurisprudence afin de déterminer la présence de préjugés sexistes au sein de notre système judiciaire. Nous constatons que les méthodes actuelles de détection des biais en PNL sont insuffisantes pour déterminer les préjugés sexistes dans notre base de données de jurisprudence et proposer une approche alternative. Nous montrons que les résultats incohérents des algorithmes existants sont la conséquence des définitions incohérentes des biais eux-mêmes dans les recherches antérieures. Les algorithmes de détection de biais s'appuient sur des groupes de mots pour représenter un biais (par exemple, « salaire », « emploi » et « patron » pour représenter l'emploi comme un thème potentiellement biaisé à l'égard des femmes dans le texte). Cependant, les méthodes utilisées pour construire ces groupes de mots présentent plusieurs faiblesses, principalement parce que les listes de mots sont basées sur les intuitions des chercheurs. Nous proposons deux nouvelles méthodes pour automatiser la création de listes de mots afin de représenter les biais. Nous constatons que nos méthodes surpassent les méthodes actuelles de détection de biais PNL. Notre recherche améliore les capacités de la technologie de la PNL à détecter les biais et met en évidence les préjugés sexistes présents dans la jurisprudence influente. Afin de tester les performances de notre méthode de détection des biais de la PNL, nous réévaluons nos résultats de biais dans la jurisprudence par rapport aux données du recensement américain sur la participation des femmes au marché du travail au cours des 100 dernières années.</abstract_fr>
      <abstract_pt>Analisamos 6,7 milhões de documentos de jurisprudência para determinar a presença de preconceito de gênero em nosso sistema judicial. Achamos que os métodos atuais de detecção de viés na PNL são insuficientes para determinar o viés de gênero em nosso banco de dados de jurisprudência e propomos uma abordagem alternativa. Mostramos que os resultados inconsistentes dos algoritmos existentes são consequências das próprias definições inconsistentes dos vieses de pesquisas anteriores. Os algoritmos de detecção de viés dependem de grupos de palavras para representar o viés (por exemplo, 'salário', 'emprego' e 'chefe' para representar emprego como um tema potencialmente tendencioso contra mulheres no texto). No entanto, os métodos para construir esses grupos de palavras apresentam vários pontos fracos, principalmente que as listas de palavras são baseadas nas próprias intuições dos pesquisadores. Sugerimos dois novos métodos para automatizar a criação de listas de palavras para representar vieses. Descobrimos que nossos métodos superam os métodos atuais de detecção de viés de PNL. Nossa pesquisa melhora as capacidades da tecnologia de PNL para detectar preconceitos e destaca os preconceitos de gênero presentes na jurisprudência influente. Para testar o desempenho do nosso método de detecção de viés de PNL, regredimos nossos resultados de viés na jurisprudência contra os dados do censo dos EUA sobre a participação das mulheres na força de trabalho nos últimos 100 anos.</abstract_pt>
      <abstract_ja>670万の判例文書を分析して、司法システム内でのジェンダーバイアスの有無を判断します。 NLPにおける現在のバイアス検出方法は、当社の判例データベースにおけるジェンダーバイアスを決定し、代替アプローチを提案するには不十分であることがわかります。 既存のアルゴリズムの一貫性のない結果は、先行研究のバイアスの定義自体の一貫性のない結果であることを示しています。 バイアス検出アルゴリズムは、バイアスを表すために単語のグループに依存している（例えば、「給与」、「仕事」、「上司」は、テキストで女性に対する潜在的なバイアスのあるテーマとして雇用を表す）。 しかし、これらの単語群を構築する方法にはいくつかの弱点があり、主に単語リストは研究者自身の直観に基づいている。 偏見を表すために、単語リストの作成を自動化する2つの新しい方法を提案します。 私たちの方法は、現在のNLPバイアス検出方法よりも優れていることがわかります。 私たちの研究は、偏見を検出するNLPテクノロジーの能力を向上させ、影響力のある判例法に存在する性別偏見を強調します。 NLPバイアス検出方法のパフォーマンスをテストするために、過去100年間の労働力への女性の参加に関する米国の国勢調査データに対する判例法のバイアスの結果を回帰させます。</abstract_ja>
      <abstract_zh>论670万份判例法文,以定性别。 NLP中偏见检测之法,不足以定性别于吾判例法数据库,而建一代之法。 我们明白,现在算法的不一样是先前研究偏见偏见本身不一的定义。 偏差检测算法依词组以示偏差(如薪水、工作、老板,即业为文本有潜见之主题)。 然构此单词组,其术数短,盖单词列表,盖究人自直觉也。 建二自创单词列表以示偏法。 吾见吾法优于今NLP偏差检测之法。 吾道增NLP术检偏见,而有影响力之判例法偏见。 试我NLP偏见检测之性,据美国人口普查数,倒退判例法中100中女性与力数中。</abstract_zh>
      <abstract_hi>हम अपनी न्यायिक प्रणाली के भीतर लिंग पूर्वाग्रह की उपस्थिति निर्धारित करने के लिए 6.7 मिलियन मामले कानून दस्तावेजों का विश्लेषण करते हैं। हम पाते हैं कि एनएलपी में वर्तमान पूर्वाग्रह का पता लगाने के तरीके हमारे मामले के कानून डेटाबेस में लिंग पूर्वाग्रह निर्धारित करने और एक वैकल्पिक दृष्टिकोण का प्रस्ताव करने के लिए अपर्याप्त हैं। हम दिखाते हैं कि मौजूदा एल्गोरिदम के असंगत परिणाम पूर्वाग्रहों की पूर्व अनुसंधान की असंगत परिभाषाओं के परिणाम हैं। पूर्वाग्रह का पता लगाने वाले एल्गोरिदम पूर्वाग्रह का प्रतिनिधित्व करने के लिए शब्दों के समूहों पर भरोसा करते हैं (उदाहरण के लिए, 'वेतन,' 'नौकरी', और 'बॉस' पाठ में महिलाओं के खिलाफ संभावित पक्षपाती विषय के रूप में रोजगार का प्रतिनिधित्व करने के लिए)। हालांकि, शब्दों के इन समूहों को बनाने के तरीकों में कई कमजोरियां हैं, मुख्य रूप से शब्द सूचियां शोधकर्ताओं के अपने अंतर्ज्ञान पर आधारित हैं। हम पूर्वाग्रहों का प्रतिनिधित्व करने के लिए शब्द सूचियों के निर्माण को स्वचालित करने के दो नए तरीकों का सुझाव देते हैं। हम पाते हैं कि हमारे तरीके वर्तमान एनएलपी पूर्वाग्रह का पता लगाने के तरीकों से बेहतर प्रदर्शन करते हैं। हमारा शोध पूर्वाग्रह का पता लगाने के लिए एनएलपी प्रौद्योगिकी की क्षमताओं में सुधार करता है और प्रभावशाली मामले कानून में मौजूद लिंग पूर्वाग्रहों पर प्रकाश डालता है। हमारे एनएलपी पूर्वाग्रह का पता लगाने की विधि के प्रदर्शन का परीक्षण करने के लिए, हम पिछले 100 वर्षों में कार्यबल में महिलाओं की भागीदारी के अमेरिकी जनगणना के आंकड़ों के खिलाफ मामले में पूर्वाग्रह के हमारे परिणामों को वापस करते हैं।</abstract_hi>
      <abstract_ru>Мы анализируем 6,7 млн. документов прецедентного права, чтобы определить наличие гендерной предвзятости в нашей судебной системе. Мы считаем, что нынешние методы выявления предвзятости в НЛП недостаточны для определения гендерной предвзятости в нашей базе данных по прецедентному праву, и предлагаем альтернативный подход. Мы показываем, что несогласованные результаты существующих алгоритмов являются следствием самих несогласованных определений смещений, полученных в ходе предыдущих исследований. Алгоритмы обнаружения предвзятости опираются на группы слов для представления предвзятости (например, «зарплата», «работа» и «начальник» для представления занятости как потенциально предвзятой темы в отношении женщин в тексте). Однако методы построения этих групп слов имеют несколько слабых мест, прежде всего то, что списки слов основаны на собственных интуициях исследователей. Мы предлагаем два новых метода автоматизации создания списков слов для представления смещений. Мы обнаружили, что наши методы превосходят текущие методы обнаружения смещения NLP. Наше исследование улучшает возможности технологии NLP для обнаружения предвзятости и подчеркивает гендерные предрассудки, присутствующие во влиятельном прецедентном праве. Для того чтобы проверить эффективность используемого нами метода выявления систематических отклонений, мы регрессируем результаты систематических отклонений в прецедентном праве в сравнении с данными переписи населения США, касающимися участия женщин в рабочей силе за последние 100 лет.</abstract_ru>
      <abstract_ukr>Ми проаналізували 6,7 млн документів прецедентного права, щоб визначити наявність гендерних упереджень у нашій судовій системі. Ми вважаємо, що поточних методів виявлення упереджень в НЛП недостатньо для визначення гендерної упередженості в нашій базі даних прецедентного права і пропонуємо альтернативний підхід. Ми показуємо, що неузгоджені результати існуючих алгоритмів є наслідками неузгоджених визначень самих упереджень попередніх досліджень. Алгоритми виявлення упереджень покладаються на групи слів для представлення упередженості (наприклад, "зарплата", "робота" та "начальник" для представлення зайнятості як потенційно упередженої теми проти жінок у тексті). Однак методи побудови цих груп слів мають кілька слабких місць, в першу чергу те, що списки слів базуються на власних інтуїціях дослідників. Пропонуємо два нових способи автоматизації створення списків слів для представлення упереджень. Ми виявили, що наші методи перевершують поточні методи виявлення упереджень NLP. Наше дослідження покращує можливості технології NLP для виявлення упереджень та висвітлює гендерні упередження, присутні у впливовому прецедентному праві. Для того, щоб перевірити ефективність нашого методу виявлення упереджень NLP, ми регресуємо наші результати упереджень у прецедентному праві щодо даних перепису населення США про участь жінок у робочій силі за останні 100 років.</abstract_ukr>
      <abstract_ga>Déanaimid anailís ar 6.7 milliún doiciméad cásdlí chun a chinneadh an bhfuil claonadh inscne laistigh dár gcóras breithiúnach. Faighimid amach nach leor na modhanna braite laofachta reatha in NLP chun laofacht inscne a chinneadh inár mbunachar sonraí cásdlí agus molaimid cur chuige eile. Léirímid go bhfuil torthaí neamh-chomhsheasmhacha na n-algartam atá ann cheana féin ina n-iarmhairtí ar shainmhínithe neamh-chomhsheasmhacha taighde roimhe seo ar laofachtaí iad féin. Braitheann algartaim braite laofachta ar ghrúpaí focal chun laofacht a léiriú (m.sh., `tuarastal,' `post,' agus `boss' chun fostaíocht a léiriú mar théama a d'fhéadfadh a bheith claonta i gcoinne na mban sa téacs). Mar sin féin, tá roinnt laigí ag baint leis na modhanna chun na grúpaí focal seo a thógáil, go príomha go bhfuil na liostaí focal bunaithe ar intuition na dtaighdeoirí féin. Molaimid dhá mhodh nua chun cruthú liostaí focal a uathoibriú chun laofachtaí a léiriú. Faighimid amach go sáraíonn ár modhanna modhanna braite laofachta NLP faoi láthair. Feabhsaítear ár dtaighde ar chumas na teicneolaíochta NLP chun laofacht a bhrath agus leagann sé béim ar laofachtaí inscne i gcásdlí a bhfuil tionchar acu. D’fhonn feidhmíocht ár modh braite claonta NLP a thástáil, aisiompaimid ár dtorthaí ar chlaonadh sa chásdlí i gcoinne sonraí daonáirimh na SA maidir le rannpháirtíocht na mban san fhórsa saothair le 100 bliain anuas.</abstract_ga>
      <abstract_ka>6.7 მილიონი კონკუმენტების კონკუმენტების ანალიზაცია, რომ ჩვენი სექსიტური სისტემაში გენექტური კონკუმენტები განსაზღვრება. ჩვენ ვფიქრობთ, რომ NLP-ში მიმდინარე წარმოადგენების განსაზღვრების მეტოვები არ არის მსგავსი, რომ ჩვენი საკუთარი საკუთარი საკუთარი ბაზატური ბაზატურში გენექტურ ჩვენ ჩვენ აჩვენებთ, რომ არსებობს ალგორიტემის შემდეგი შემდეგი არსებობს წინასწარმატების განსაზღვრებების შემდეგი. ორი განახლება ალგორიტიმები იყენება სიტყვების ჯგუფებზე, რომელიც გამოსახულებელია (მაგალითად, `დავალება,''სამუშაო'' და `ბოსტი') სამუშაო სამუშაო როგორც პოტენციალურად გა მაგრამ ამ სიტყვების ჯგუფის შექმნა მეტი აქვს რამდენიმე სიტყვების სიტყვების სიტყვების ინტეუციების დაბაზეული. ჩვენ შეგიძლიათ ორი ახალი მეთოდი სიტყვების სიტყვების შექმნის ავტომატიკურად გამოყენება. ჩვენ ვფიქრობთ, რომ ჩვენი მეტები მიმდინარე NLP წარმოადგენების მეტებით გავაკეთებთ. ჩვენი შესწავლობა NLP ტექნოლოგიის შესაძლებლობას გაუქმედება, რომელიც წარმოადგენს წარმოადგენების წარმოადგენების წარმოადგენების წარმოადგენების შესაძლებლობა. რომ ჩვენი NLP წარმოდგენების გამოყენება მეტის განახლების შესაძლებლობად, ჩვენ განახლებით ჩვენი წარმოდგენების წარმოდგენების წარმოდგენების შესაძლებლობად ამერიკის წარმოდგენების მონაცემების მონაცე</abstract_ka>
      <abstract_hu>6,7 millió ítélkezési gyakorlatot elemezünk annak megállapítására, hogy igazságszolgáltatási rendszerünkön belül milyen a nemi elfogultság. Úgy találjuk, hogy a jelenlegi elfogultság-felismerési módszerek az NLP-ben nem elegendőek az ítélkezési gyakorlati adatbázisunkban, és alternatív megközelítést javasolunk. Megmutatjuk, hogy a meglévő algoritmusok következetlen eredményei a korábbi kutatások következetlen definícióinak következményei maguknak az előítéleteknek. A Bias detektálási algoritmusok a szavak csoportjaira támaszkodnak, hogy képviseljék az elfogultságot (pl. "fizetés", "munka", és "főnök", hogy a foglalkoztatást, mint potenciálisan elfogult téma a nőkkel szemben a szövegben). A szócsoportok felépítésének módszerei azonban számos gyengesége van, elsősorban azt jelenti, hogy a szólisták a kutatók saját megérzésein alapulnak. Két új módszert javasolunk a szólisták létrehozásának automatizálására az elfogultságok megjelenítésére. Úgy találjuk, hogy módszereink felülmúlják a jelenlegi NLP-torzítás felismerési módszereket. Kutatásunk javítja az NLP technológia képességeit az elfogultságok felismerésére, és kiemeli a befolyásos ítélkezési gyakorlatban jelen lévő nemi elfogultságokat. Annak érdekében, hogy teszteljük NLP elfogultság felismerési módszerünk teljesítményét, az ítélkezési gyakorlatban előforduló elfogultság eredményeit az elmúlt 100 évben a nők munkaerőben való részvételéről szóló amerikai népszámlálási adatokkal szemben.</abstract_hu>
      <abstract_el>Αναλύουμε 6.7 εκατομμύρια έγγραφα νομολογίας για να προσδιορίσουμε την παρουσία προκατάλειψης φύλου στο δικαστικό μας σύστημα. Διαπιστώνουμε ότι οι τρέχουσες μέθοδοι ανίχνευσης μεροληψίας στο ΝΛΠ δεν επαρκούν για να προσδιορίσουν την προκατάληψη φύλου στη βάση δεδομένων νομολογίας μας και να προτείνουν μια εναλλακτική προσέγγιση. Αποδεικνύουμε ότι τα ασυνεπή αποτελέσματα των υφιστάμενων αλγορίθμων είναι συνέπειες των ασυνεπών ορισμών των προκατάληψης από προηγούμενες έρευνες. Οι αλγόριθμοι ανίχνευσης προκατάλειψης βασίζονται σε ομάδες λέξεων για να αντιπροσωπεύουν προκατάληψη (π.χ. "μισθός", "εργασία" και "αφεντικό" για να αντιπροσωπεύουν την απασχόληση ως δυνητικά προκατάληψη θέματος κατά των γυναικών στο κείμενο). Ωστόσο, οι μέθοδοι για την κατασκευή αυτών των ομάδων λέξεων έχουν αρκετές αδυναμίες, κυρίως ότι οι λίστες λέξεων βασίζονται στη διαίσθηση των ερευνητών. Προτείνουμε δύο νέες μεθόδους αυτοματοποίησης της δημιουργίας καταλόγων λέξεων για την αναπαράσταση προκαταλήψεων. Διαπιστώνουμε ότι οι μέθοδοι μας ξεπερνούν τις τρέχουσες μεθόδους ανίχνευσης μεροληψίας. Η έρευνά μας βελτιώνει τις δυνατότητες της τεχνολογίας να ανιχνεύει προκατάληψη και να αναδεικνύει τις προκαταλήψεις των φύλων που υπάρχουν στη σημαντική νομολογία. Για να ελέγξουμε την απόδοση της μεθόδου ανίχνευσης προκατάληψης, επαναπροσδιορίζουμε τα αποτελέσματα της προκατάληψης στη νομολογία ενάντια στα δεδομένα απογραφής των ΗΠΑ για τη συμμετοχή των γυναικών στο εργατικό δυναμικό τα τελευταία 100 χρόνια.</abstract_el>
      <abstract_lt>Analizuojame 6,7 mln. teismų praktikos dokumentų, siekiant nustatyti lyčių pusiausvyrą teisminėje sistemoje. Mes manome, kad dabartiniai šališkumo nustatymo metodai NLP yra nepakankami siekiant nustatyti lyčių pusiausvyrą mūsų teismų praktikos duomenų bazėje ir pasiūlyti alternatyvų metodą. Mes rodome, kad esamų algoritmų nenuoseklūs rezultatai yra anksčiau atliktų nenuoseklių s ąvokų apibrėžimų pasekmės. Sužalojimo nustatymo algoritmai grindžiami žodžių grupėmis, kurios rodo sąžiningumą (pvz., darbo užmokestis, „darbas“ ir „bosas“, kad tekste užimtumas būtų potencialiai sąžininga tema prieš moteris). Tačiau šių žodžių grupių kūrimo metodai turi keletą trūkumų, visų pirma tai, kad žodžių sąrašai grindžiami mokslininkų intuicijomis. Siūlome du naujus žodžių sąrašų kūrimo automatizavimo metodus, kad būtų galima atspindėti pusiausvyras. Matome, kad mūsų metodai viršija dabartinius NLP išankstinio nustatymo metodus. Mūsų moksliniai tyrimai pagerina NLP technologijos gebėjimus nustatyti pusiausvyrą ir pabrėžia įtakingoje teismų praktikoje esančias lyčių pusiausvyras. Siekdami išbandyti mūs ų NLP sąžiningumo nustatymo metodo veiksmingumą, mes grąžiname savo sąžiningumo teismų praktikoje rezultatus, palyginti su JAV surašymo duomenimis apie moterų dalyvavimą darbo jėgoje per pastaruosius 100 metų.</abstract_lt>
      <abstract_it>Analizziamo 6,7 milioni di documenti di giurisprudenza per determinare la presenza di pregiudizi di genere all'interno del nostro sistema giudiziario. Troviamo che gli attuali metodi di rilevamento dei pregiudizi nel PNL non sono sufficienti per determinare i pregiudizi di genere nel nostro database di giurisprudenza e proponiamo un approccio alternativo. Mostriamo che i risultati incoerenti degli algoritmi esistenti sono conseguenze delle definizioni incoerenti dei pregiudizi stessi da parte di ricerche precedenti. Gli algoritmi di rilevamento dei bias si basano su gruppi di parole per rappresentare i bias (ad esempio, 'stipendio,' 'lavoro,' e 'capo' per rappresentare l'occupazione come un tema potenzialmente pregiudizievole contro le donne nel testo). Tuttavia, i metodi per costruire questi gruppi di parole hanno diversi punti deboli, principalmente che le liste di parole sono basate sulle intuizioni dei ricercatori. Suggeriamo due nuovi metodi per automatizzare la creazione di elenchi di parole per rappresentare i pregiudizi. Troviamo che i nostri metodi superano gli attuali metodi di rilevamento dei bias NLP. La nostra ricerca migliora le capacità della tecnologia NLP per rilevare i pregiudizi di genere presenti nella giurisprudenza influente. Al fine di testare le prestazioni del nostro metodo di rilevamento dei bias NLP, regrediamo i nostri risultati di bias nella giurisprudenza contro i dati del censimento statunitense sulla partecipazione delle donne nella forza lavoro negli ultimi 100 anni.</abstract_it>
      <abstract_kk>Біз 6,7 миллион жағдай құжаттарын оқу жүйемізде гендерлік қатынасын анықтау үшін анализ етеміз. Біз NLP-де қазіргі қазіргі қазіргі қазіргі қазіргі тәртіптерді анықтау әдістерімізде гендерлік қазірлерін анықтау үшін жеткілікті емес және қазіргі қазір Біз алгоритмдердің қайсыз нәтижелерін көрсетедік, алдыңғы зерттеулердің қайсыз анықтамасының нәтижелері. Биос анықтау алгоритмдері әйелдердің мәтіндегі әйелдерге қарсы жұмыс істеу үшін сөздер топтарына тәуелді (мысалы, «жасау,» «жұмыс,» және «бос» деп аталады). Бірақ бұл сөздер топтарын құру әдістері бірнеше қауіпсіздігі бар, негізінде сөздер тізімі зерттеушілердің өзінің түсініктеріне негізделген. Біз сөз тізімдерін автоматты түрде құру үшін екі жаңа әдістерді таңдаймыз. Біз әдістеріміздің NLP қазіргі тәртіптерімізді анықтау әдістерінен арналған. Біздің зерттеулеріміз NLP технологиясының көңіл түсініктерін анықтау және гендердің көңіл жағдайда болатын жағдайды жасайды. NLP бақылау тәсілдерімізді тексеру үшін, соңғы 100 жыл бойы әйелдердің жұмыс күшінде қатысу үшін АҚШ бақылау мәліметіміздің нәтижесін қайта қайта қалдырып тұрмыз.</abstract_kk>
      <abstract_ml>ഞങ്ങള്‍ 6.7 മില്ല്യന്‍ കേസ് നിയമങ്ങളുടെ രേഖകള്‍ അന്വേഷിക്കുന്നു. നമ്മുടെ ന്യായാധിക വ്യവസ്ഥയിലുള്ള സ്ഥിതി നമ്മുടെ കേസ് നിയമത്തിന്റെ ഡാറ്റാബേസില്‍ സംബന്ധിച്ച് വേറൊരു മാര്‍ഗവും നിരീക്ഷിക്കാന്‍ ഇപ്പോഴത്തെ ബിയാസ് കണ്ടെത്തു നിലവിലുള്ള ആല്‍ഗോരിത്മുകളുടെ അസാധ്യതയില്ലാത്ത ഫലങ്ങള്‍ തന്നെയാണ് നോക്കുന്നത് നേരത്തെ പരിശോധിക്കുന്നതിന്റെ അന് Bias detection algorithms rely on groups of words to represent bias (e.g., `salary,' `job,' and `boss' to represent employment as a potentially biased theme against women in text).  എന്നാലും ഈ വാക്കുകള്‍ പണിയാനുള്ള രീതികള്‍ക്ക് കുറച്ച് ദുര്‍ബലങ്ങളുണ്ട്, പ്രധാനപ്പെട്ട വാക്കുകളുടെ ലിസ്റ്റുകള്‍ ശ് വാക്കുകളുടെ ലിസ്റ്റുകളുടെ സൃഷ്ടിക്കാന്‍ രണ്ടു പുതിയ രീതികള്‍ നാം നിര്‍ദേശിക്കുന്നു. ഇപ്പോഴത്തെ NLP ബിയസ് കണ്ടെത്തുന്ന രീതികളില്‍ നിന്നും നമ്മുടെ രീതികള്‍ കണ്ടെത്തുന്നു. നമ്മുടെ ഗവേഷണം എംഎല്‍പി സാങ്കേതികവിദ്യയെ കണ്ടുപിടിക്കുന്നതിന്റെ കഴിവുകള്‍ മെച്ചപ്പെടുത്തുന്നു. പ്രധാനപൂ നമ്മുടെ NLP ബിയസ് കണ്ടുപിടിക്കുന്ന രീതിയിലെ പ്രവര്‍ത്തനം പരീക്ഷിക്കാന്‍ വേണ്ടി, കഴിഞ്ഞ 100 വര്‍ഷങ്ങളില്‍ സ്ത്രീകളുടെ പങ്കെടുക്കുന്നതിനെതിര</abstract_ml>
      <abstract_isl>Við greinum 6,7 milljón réttarfræðileg skjöl til að ákvarða að kynþáttur séu til staðar í réttarkerfinu okkar. Við finnum að núverandi aðferðir til að greina hlutleysi í NLP eru ófullnægjandi til að ákvarða kynhlutleysi í gagnagrunni okkar og leggja fram aðra aðferð. Við s ýnum að ósamræmi niðurstöður núverandi algoritma eru afleiðingar af ósamræmi skilgreiningu fyrri rannsķknir á sjálfum sér. Aðgreiningaraðgerðir á a ð byggjast á hópum orða til að sýna fyrirskipun (t.d. 'laun,' 'starf' og 'stjórn' til að sýna fyrirskipun sem hugsanlega fyrirskipt þema gegn konum í texta). Hins vegar eru aðferðirnar til að byggja þessi hóp orða nokkrar veikindir, aðallega að orðalistar byggjast á eigin innsæi rannsakanda. Við leggjum fram tvær nýjar aðferðir til að sjálfvirkja búningu á orðalistum til að sýna fyrirsæti. Við finnum að aðferðir okkar eru stærri en núverandi aðferðir til að greina NLP. Rannsókn okkar bætir hæfni NLP tækni til að greina tilhneigingu og bendir til kynslíkra tilhneiginga sem eru í áhrifaríkri réttarhöndlun. Til ađ prķfa framkvæmd NLP-greiningaraðferðarinnar skrúfum við niðurstöður okkar af tilhneigingu í málaráætlun gegn upplýsingum um þátttöku konur í starfsemi Bandaríkjanna á s íðustu 100 árum.</abstract_isl>
      <abstract_ms>Kami menganalisis 6.7 juta dokumen hukum untuk menentukan kehadiran bias jenis dalam sistem hukum kami. Kami mendapati bahawa kaedah pengesan bias semasa dalam NLP tidak cukup untuk menentukan bias jenis dalam pangkalan data hukum kami dan melamar pendekatan alternatif. Kami menunjukkan hasil yang tidak konsisten algoritma yang wujud adalah konsekuensi dari penelitian sebelumnya definisi tidak konsisten biases mereka sendiri. Algoritma pengesan bias bergantung pada kumpulan perkataan untuk mewakili bias (contohnya, `gaji,' 'kerja,' dan `bos' untuk mewakili pekerjaan sebagai tema yang berpotensi bias terhadap wanita dalam teks). Namun, kaedah untuk membina kumpulan perkataan ini mempunyai beberapa kelemahan, terutama bahawa senarai perkataan berdasarkan intuisi penyelidik sendiri. Kami cadangkan dua kaedah baru untuk automatikan penciptaan senarai perkataan untuk mewakili biases. Kami mendapati bahawa kaedah kami melampaui kaedah pengesan bias NLP semasa. kajian kami meningkatkan kemampuan teknologi NLP untuk mengesan bias dan menentukan bias jenis yang ada dalam kaedah yang mempengaruhi. Untuk menguji prestasi kaedah pengesan bias NLP kami, kami mengembalikan hasil bias kami dalam kaedah hukum melawan data census Amerika Syarikat tentang pesertaan wanita dalam kuasa kerja dalam 100 tahun terakhir.</abstract_ms>
      <abstract_no>Vi analyserer 6,7 millioner tilfelle-lovsdokumenter for å bestemme eksisterende tilfelle i rettssystemet vår. Vi finn at gjeldande metodar for oppdaging av bias i NLP er ikkje tilstrekkelig for å bestemme seks-bias i databasen vår for tilfelle og foreslå eit alternativ tilnærming. Vi viser at inkonsistente resultat av eksisterande algoritme er konsekvensar av førre forskningsinkonsistente definisjonar av forskning selv. Algoritme for oppdaging av bias er på grupper av ord som representerer bias (f.eks. « lønn, « jobb » og « boss » for å representera arbeid som eit potensielt forvirra tema mot kvinner i tekst). Metodane for å bygge desse ordgruppene har fleire tyrke, hovudsakelig at ordlista er basert på forskere eige intuitjonar. Vi foreslår to nye metodar for å automatisera opprettinga av ordlister for å representera forsiktigheter. Vi finn at metodane våre utfører gjeldande NLP-forsikningsmetoder. Våre forskning forbedrar kapasiteten for NLP-teknologi for å finna forsiktighet og markerer seks-forsiktigheter som finst i påvirkande tilfelle. For å prøve utviklinga av NLP-metoden vårt for å oppdaga bias-oppdaginga, regreserer vi våre resultat av bias i tilfelle mot USA-census data om kvinner delta i arbeidsforska i løpet av siste 100 år.</abstract_no>
      <abstract_mt>We analyze 6.7 million case law documents to determine the presence of gender bias within our judicial system.  Aħna nsibu li l-metodi attwali ta’ identifikazzjoni ta’ preġudizzji fil-NLP mhumiex biżżejjed biex jiddeterminaw il-preġudizzju bejn is-sessi fid-database tal-każistika tagħna u jipproponu approċċ alternattiv. Aħna nuru li r-riżultati inkonsistenti tal-algoritmi eżistenti huma konsegwenzi tad-definizzjonijiet inkonsistenti tal-preċedenti tar-riċerka dwar il-preġudizzji nfushom. L-algoritmi tal-identifikazzjoni tal-ħsara jiddependu fuq gruppi ta’ kliem biex jirrappreżentaw il-ħsara (pereżempju, `salarju,' 'impjieg,' u `boss' biex jirrappreżentaw l-impjieg bħala tema potenzjalment biased kontra n-nisa fit-test). Madankollu, il-metodi għall-bini ta’ dawn il-gruppi ta’ kliem għandhom diversi dgħufijiet, primarjament li l-listi tal-kliem huma bbażati fuq l-intwizzjonijiet tar-riċerkaturi stess. Aħna ssuġġerixxu żewġ metodi ġodda ta' awtomatizzazzjoni tal-ħolqien ta' listi ta' kliem biex jirrappreżentaw preġudizzji. Aħna nsibu li l-metodi tagħna jaqbżu l-metodi attwali ta’ identifikazzjoni tal-preġudizzji tal-NLP. Ir-riċerka tagħna ttejjeb il-kapaċitajiet tat-teknoloġija NLP biex tinstab preġudizzju u tenfasizza l-preġudizzji bejn is-sessi preżenti fil-każistika influwenti. Sabiex jittestjaw il-prestazzjoni tal-metodu tagħna ta’ identifikazzjoni ta’ preġudizzji tal-NLP, irringressaw ir-riżultati tagħna ta’ preġudizzju fil-każistika kontra d-dejta taċ-ċensiment tal-Istati Uniti dwar il-parteċipazzjoni tan-nisa fil-forza tax-xogħol fl-aħħar 100 sena.</abstract_mt>
      <abstract_mk>Ние анализираме 6,7 милиони документи од судската практика за да го утврдиме присуството на половина предрасуда во нашиот судски систем. Најдовме дека сегашните методи за детекција на предрасуди во НЛП не се доволни за да се одреди полова предрасуда во нашата база на податоци за случаи и да се предложи алтернативен пристап. Ние покажуваме дека постоечките алгоритми несогласни резултати се последици од претходните истражувања несогласни дефиниции на самите предрасуди. Алгоритмите за детекција на навреда се потпираат на групи зборови кои претставуваат навреда (на пример, „плата“, „работа“ и „шефот“ кои претставуваат вработување како потенцијално навредена тема против жените во текстот). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions.  Предлагаме два нови методи за автоматизација на создавањето на листи на зборови за претставување на предрасуди. Најдовме дека нашите методи ги надминуваат актуелните методи за детекција на предрасуди на НЛП. Нашите истражувања ги подобруваат способностите на технологијата НЛП за откривање на предрасуди и ги истакнуваат полските предрасуди кои се присутни во влијателната судска практика. За да го тестираме изведувањето на нашиот метод за детекција на предрасуди на НЛП, ги регресираме нашите резултати на предрасудите во судската практика против податоците од пописот на САД за учеството на жените во работната сила во изминатите 100 години.</abstract_mk>
      <abstract_mn>Бид 6.7 сая хууль хууль баримтуудыг шүүхийн системийн дотор гендер эсрэг байдлыг тогтоохын тулд шинжилгээ хийдэг. Бид NLP-д орчин үеийн өрөөсгөл ойлголтын аргыг олох нь бидний хуулийн өгөгдлийн сан дээр гендерийн өрөөсгөл байдлыг тодорхойлж, өөр арга замыг санал болгож чадахгүй байна. Бид алгоритмын эсрэг үр дүн нь өмнө судалгааны эсрэг тодорхойлолтуудын үр дүн юм. Биеийн мэдэх алгоритмын алгоритм нь бусдыг илэрхийлдэг хэсэг үгсийг тодорхойлж байдаг (жишээ нь, цалинг, ажил, бас "босс" гэдэг нь эмэгтэйчүүдийн текст дээрх эмэгтэйчүүдийн эсрэг ажиллагааг илэрхийлдэг загвар Гэвч эдгээр хэсэгт үг бүтээх арга нь олон хүчтэй байдаг. Ялангуяа судлаачидын зөвшөөрөл дээр үг жагсаалтын түвшинд байдаг. Бид үгийн жагсаалтыг автоматжуулахын тулд хоёр шинэ арга зам зааж байна. Бид өөрсдийн арга нь одоогийн NLP-ын алдаа алдаа байдлыг олох арга хэрэгтэй. Бидний судалгаагаа NLP технологийн чадварыг сайжруулж, нөлөөлдөг үйл явдлын хуульд байгаа гендер эсрэг нөлөөлдөг байдлыг тодорхойлох боломжтой болгодог. NLP-ын алдартай байдлыг олох арга замыг шалгахын тулд бид сүүлийн 100 жилд эмэгтэйчүүдийн ажиллах хүчний оролцооны тоо баримтын үр дүнг АНУ-ын хууль хууль зөвшөөрөл байдлын үр дүнг буцааж байна.</abstract_mn>
      <abstract_pl>Analizujemy 6,7 miliony dokumentów orzecznictwa w celu określenia obecności uprzedzeń płci w naszym systemie sądownictwa. Stwierdzamy, że obecne metody wykrywania stronniczości w NLP są niewystarczające do określenia stronniczości płci w naszej bazie orzecznictwa i zaproponowania alternatywnego podejścia. Pokazujemy, że niespójne wyniki istniejących algorytmów są konsekwencją niespójnych definicji wcześniejszych badań samych uprzedzeń. Algorytmy wykrywania uprzedzeń opierają się na grupach słów, aby reprezentować uprzedzenia (np. "wynagrodzenie", "praca" i "szef", aby reprezentować zatrudnienie jako potencjalnie stronniczy temat wobec kobiet w tekście). Jednak metody budowania tych grup słów mają kilka słabości, przede wszystkim to, że listy słów opierają się na własnych intuicjach naukowców. Proponujemy dwie nowe metody automatyzacji tworzenia list słów reprezentujących uprzedzenia. Stwierdzamy, że nasze metody przewyższają obecne metody wykrywania biasów NLP. Nasze badania poprawiają możliwości technologii NLP do wykrywania stronniczości i podkreślają uprzedzenia płci obecne w wpływowym orzecznictwie. Aby sprawdzić skuteczność naszej metody wykrywania stronniczości NLP, regresujemy nasze wyniki stronniczości w orzecznictwie przeciwko amerykańskim danym spisowym dotyczącym udziału kobiet w pracy w ciągu ostatnich stuleci lat.</abstract_pl>
      <abstract_ro>Analizăm 6,7 milioane de documente de jurisprudență pentru a determina prezența prejudecății de gen în sistemul nostru judiciar. Considerăm că metodele actuale de detectare a prejudiciilor în PNL sunt insuficiente pentru a determina prejudiciile de gen în baza noastră de date jurisprudență și propune o abordare alternativă. Arătăm că rezultatele inconsecvente ale algoritmilor existenți sunt consecințele definițiilor inconsecvente ale prejudecăților efectuate de cercetările anterioare. Algoritmii de detectare a bias se bazează pe grupuri de cuvinte pentru a reprezenta prejudecăți (de exemplu, "salariu", "job" și "șef" pentru a reprezenta ocuparea forței de muncă ca o temă potențial părtinitoare împotriva femeilor în text). Cu toate acestea, metodele de construire a acestor grupuri de cuvinte au mai multe slăbiciuni, în primul rând faptul că listele de cuvinte se bazează pe intuițiile proprii ale cercetătorilor. Sugerăm două metode noi de automatizare a creării listelor de cuvinte pentru a reprezenta prejudecăți. Considerăm că metodele noastre depășesc metodele actuale de detectare a distorsiunii PNL. Cercetarea noastră îmbunătățește capacitățile tehnologiei PNL de a detecta prejudecățile și evidențiază prejudecățile de gen prezente în jurisprudența influentă. Pentru a testa performanța metodei noastre de detectare a părtinirii PNL, regresăm rezultatele prejudiciare în jurisprudență față de datele recensământului SUA privind participarea femeilor la forța de muncă în ultimii 100 de ani.</abstract_ro>
      <abstract_so>Ana baaraynaa qoraalka sharciga xaaladaha 6,7 milyan oo sharciga ah si aan u go’aanno baahida jinsiga nidaamka xukunka ah gudaheeda. Waxaynu ognahay in hababka ALP-ka ee sasa ay ku filan yihiin in aan go’aanka galmada ku cadaynayo danbiyada sharcigayada iyo in uu soo jeedo qaab kale ah. Waxaynu muujinnaa in arimaha aan dhamaaneyn ay jiraan ay sabab u yihiin arimaha baaritaanka hore ee cilmiga khiyaanada isbedelka ah. Aqoonsashada Bias waxay ku xiran yihiin koox hadal ah oo ay ka mid yihiin bias (tusaale ahaan mushaar, `mushaar', `shaqo', iyo `boshqar' inay u representaan shaqo si ay ugu dhaqso midab la khilaafay dumarka qoraalka ku qoran). Si kastaba ha ahaatee qaababka dhismaha kooxaha erayadan waxay leeyihiin taageero badan, marka ugu horeysa waxaa lagu saleeyaa qoraalka ay ku saleysan fikrada baaritaanka. Waxaynu soo jeedaynaa laba qaab oo cusub oo aan automatino abuuridda qoraalka si ay u representaan tababaro. Waxaynu helnaa in qaababkayaga ay ka samaystaan hababka baaritaanka ee NLP. Baaritaankeennu wuxuu kordhiyaa awoodda Teknolojiyada NLP si ay u ogaato tababaro iyo sidoo kale wuxuu ku muujiyaa tababarada jinsiga ee sharciga saameyn ku leh. Si aan u imtixaano sameynta qaababka baaritaanka ee NLP, waxaynu dib u celinaynaa resultiyada khiyaanada sharciga ka geesta ah macluumaadka dadka dumarka ka qayb galay shaqada 100 sano ee ugu dambeeyey.</abstract_so>
      <abstract_sv>Vi analyserar 6,7 miljoner rättspraxis för att fastställa förekomsten av könsbias inom vårt rättssystem. Vi finner att nuvarande metoder för att upptäcka bias i NLP är otillräckliga för att fastställa könsbias i vår rättspraxis databas och föreslår ett alternativt tillvägagångssätt. Vi visar att existerande algoritmers inkonsekventa resultat är konsekvenser av tidigare forsknings inkonsekventa definitioner av partis själva. Algoritmer för diagnosedetektering förlitar sig på ordgrupper för att representera bias (t.ex. "lön", "jobb" och "chef" för att representera sysselsättning som ett potentiellt partiskt tema mot kvinnor i text). Metoderna att bygga upp dessa ordgrupper har dock flera svagheter, främst att ordlistorna baseras på forskarnas egna intuitioner. Vi föreslår två nya metoder för att automatisera skapandet av ordlistor för att representera fördomar. Vi finner att våra metoder överträffar nuvarande NLP bias detection metoder. Vår forskning förbättrar NLP-teknologins förmåga att upptäcka bias och belyser könsfördomar som förekommer i inflytelserik rättspraxis. För att testa vår NLP bias detection metods prestanda, regreserar vi våra resultat av bias i rättspraxis mot amerikanska folkräkningsdata om kvinnors deltagande i arbetskraften under de senaste 100 åren.</abstract_sv>
      <abstract_sr>Analiziramo 6,7 miliona slučajnih dokumenta kako bi utvrdili prisustvo spolnih predrasuda u našem sudskom sistemu. Nalazimo da trenutne metode otkrivanja pristrasnosti u NLP-u nisu dovoljne za određivanje spolnih pristrasnosti u našoj bazi podataka zakona i predložimo alternativni pristup. Pokazujemo da su rezultati postojećih algoritma nepristojni posledici samih nepristojnih definicija prethodnih istraživanja. Algoritmi za otkrivanje biologije oslanjaju se na grupe reèi koje predstavljaju predrasude (npr. „plaæanje“, „posao“, „šef“) da predstavljaju zapošljavanje kao potencijalno predrasuden tema protiv žena u tekstu). Međutim, metode za izgradnju tih grupa reèi imaju nekoliko slabosti, glavno da su listi reèi zasnovani na sopstvenim intuicijama istraživača. Predlažemo dve nove metode automatizacije stvaranja listi reèi kako bi predstavljali predrasude. Naše metode iznose trenutne metode otkrivanja pristrasnosti NLP-a. Naše istraživanje poboljšava sposobnost tehnologije NLP-a da otkrije predrasude i naglašava spolne predrasude koje postoje u uticajnom zakonu o slučaju. Da bismo testirali izvršnost metode detektacije predrasude NLP-a, regresirali smo rezultate predrasude u slučaju zakona protiv podataka o popisu američkih podataka o sudjelovanju žena u radnoj snazi u poslednjih 100 godina.</abstract_sr>
      <abstract_ur>ہم نے 6.7 میلیون کیس قانون سند کی تحقیق کی کہ ہمارے قانون سیسٹم میں جنس کی مخالفت کا موقع مقرر کریں۔ ہم دیکھتے ہیں کہ NLP میں موجود بغیر بغیر بغیر بغیر بغیر بغیر بغیر بغیر بغیر طریقہ کا مقرر کرنے کے لئے نہیں ہے۔ ہم دکھاتے ہیں کہ موجود الگوریتم کے ناپاکیزہ نتیجے پہلے تحقیق کی ناپاکیزہ تعریف کے نتیجے ہیں۔ دوسری آلگوریٹم کی وجہ سے کلمات کے گروہوں پر اعتماد رکھتے ہیں جن کی تعبیر کی تعبیر کرتی ہے (مثال „salary,“ job,“ اور „boss“) کی تعبیر کے لئے استعمال کی تعبیر کرتی ہے۔ However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions. ہم نے دو نو طریقے پیش کریں کہ کلمات لکھوں کی پیدائش کو آٹوٹی سے پیدا کریں۔ ہمیں معلوم ہے کہ ہمارے طریقے موجود NLP پیدا کرنے کے طریقے سے کام لیتے ہیں۔ ہماری تحقیقات NLP ٹیکنالوجی کے قابل تغییرات کو اضافہ کرتا ہے کہ ان کی مخالفت کو پہچان سکیں اور جنس کی مخالفت کو اضافہ کرتا ہے کہ ان کے قانون میں موجود ہیں۔ ہمارے NLP منطقی شناسایی طریقے کے کام کی آزمائش کے لئے، ہم اگلوں 100 سالوں میں عورتوں کی مشارکت کے ذریعے امریکا سگنس کے مقابلہ میں اپنے منطقی کا نتیجہ دوبارہ دفع کرتے ہیں.</abstract_ur>
      <abstract_ta>நாம் 6.7 மில்லியன் வழக்க விதிகள் ஆவணங்களை ஆய்வு செய்கிறோம் எங்கள் நியாயத்திற்கு உள்ளிருக்கும் பெண் பிர நாம் கண்டுபிடிக்கும் தற்போதைய பியா கண்டுபிடிப்பு முறைமைகள் என்று கண்டுபிடிக்க போதுமானது எங்கள் விஷயத்தின் சட்டத்தின நாங்கள் காண்பிக்கிறோம் ஏற்கனவே இருக்கும் ஆல்பரிட்டத்தின் முழுமையான முடிவுகள் முன்னால் ஆராய்ச்சியின் முழும பியாஸ் கண்டுபிடிப்பு பட்டியல் பியாஸ் குழுக்களை குறிப்பிட வார்த்தைகளின் மீது நம்பிக்கை கொண்டிருக்கிறது (உதாரணமாக, `வரிசை, `வேலை, மற்றும் `ம However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions.  வார்த்தை பட்டியலின் பட்டியலை தானாகவே உருவாக்கும் இரண்டு புதிய முறைகளை நாம் பரிந்துரைக்கிறோம். இப்போதைய NLP பியாஸ் கண்டுபிடிப்பு முறைகளை விட எங்கள் முறைகளை கண்டுபிடிக்கிறது. எங்கள் ஆராய்ச்சி NLP தொழில்நுட்பத்தின் தொழில்நுட்பத்தை மேம்படுத்துகிறது பியேஸ் கண்டுபிடிக்க மற்றும் பாதிப எங்கள் NLP பியாஸ் கண்டுபிடிப்பு முறைமையின் செயல்பாட்டை சோதிக்க, கடந்த 100 ஆண்டுகளில் பெண்களின் பகிர்ந்து பெண்களுக்கு எதிராக நாம் விதியாசம</abstract_ta>
      <abstract_si>අපි 6.7 මිලියන් විශ්ලේෂණය කරනවා කේස් නීතිය ලිපින්තුවක් අපේ නීතිය පද්ධතියේ සිද්ධ විශ්ලේෂණය කරන් අපිට හොයාගන්න පුළුවන් ප්‍රස්තූතිය ප්‍රවෘත්තිය NLP වල ලැබුණු ප්‍රවෘත්තිය හොයාගන්න ප්‍රවෘත්තිය නිර්ධ අපි පෙන්වන්නේ ඉතින් ඇල්ගෝරිත්මස්ගේ නිර්මාණ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ර Bias පරීක්ෂණ ඇල්ගෝරිතම් වචන ස්ථානයක් විශ්වාස කරන්න පුළුවන් වචන ස්ථානය (උදාහරණයෙන්, `Salary,' `job', සහ `Boss' විශ්වාස කරන්න ප්‍රතිකාර නමුත්, මේ වචන් කණ්ඩායම් නිර්මාණය කරන්න විදියට වචන අවශ්‍ය විදියට වචන ලැයිස්තුවක් පරීක්ෂකයන්ගේ පුළුවන් අවශ අපි අලුත් විද්‍යාවක් දෙකක් ස්වයංක්‍රීය විදිහට වචන ලැයිස්තුව නිර්මාණය කරන්න පුළුවන්. අපිට හොයාගන්න පුළුවන් අපේ පද්ධතිය NLP ප්‍රතිස්ථානය හොයාගන්න ප්‍රතිස්ථානය නිර්මාණ අපේ පරීක්ෂණය NLP තාක්ෂණයේ සක්ෂමතාවක් වැඩි කරනවා ප්‍රශ්නයක් හොයාගන්න සහ ප්‍රශ්නයක් නීතියෙන් ඉන්න ජීවිත අපේ NLP බයිස් හොයාගන්න විදියට පරීක්ෂා කරන්න, අපි අන්තිම අවුරුදු 100ක් වෙනුවෙන් අපේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රති</abstract_si>
      <abstract_uz>Biz juda tizimdagi jinsiyalar tizimdagi bo'lganligini aniqlash uchun 6.7 million kishi ҳужжатlarini analyzemiz. Biz NLP'ning joriy bias qidirish usullarini o'rganish qoidamizda jinsiyalar bazasini aniqlashga yetarli emas va boshqa usulni boshqarish imkoniyatini anglatadi. Biz hozir mavjud algoritlar muvaffaqiyatli natijalari o'zida o'z o'z o'z o'z o'z o'z o'z o'z o'z o'z o'z o'zini o'zgartirib o'zgarishlar natijalarining natijalaridir. Bias qidirish algoritlari bir guruhga bis (масалан `musiqa, `vazifa', `boshqaruv' va `boshqaruv' ishni matn bilan qiziqarli mavzuga e g a bo'lishi mumkin). Lekin, bu so'zlar guruhlarini yaratish usullari bir necha sodda bo'ladi, aslida so'zlar roʻyxati o'qituvchilarga o'zgarishlarga asoslangan. Biz bir necha xizmatlarni tahrirlash uchun so'zlar roʻyxatini avtomatik yaratish uchun ikkita yangi usullarni talab qilamiz. Biz hozirgi NLP biz qidirish usullarini bajarayotganimiz mumkin. Bizning taʼminlovchimiz NLP texnologiyani aniqlash imkoniyatini oshirish va ta'sirlik sharciga ega bo'lgan jinsiyalarni ko'paytirish imkoniyatini oshirish mumkin. Biz NLP bizning qidirish usulini tekshirish uchun, biz 100 yil ichida ishlab chiqarishga AQSdan foydalanuvchi ayollarning qismiga qayta ishlash haqida qayta ishlash natijalarimizni qaytadi.</abstract_uz>
      <abstract_vi>Chúng tôi phân tích 6.7 triệu tập tài liệu pháp lý để xác định sự có khuynh hướng giới tính trong hệ thống xét xử. Chúng tôi thấy rằng các phương pháp phát hiện khuynh hướng tại đài NLP không đủ để xác định khuynh hướng giới tính trong cơ sở dữ liệu trường hợp và đề xuất phương pháp khác. Chúng tôi cho thấy hiệu quả mâu thuẫn của thuật toán hiện tại là hậu quả của việc nghiên cứu trước đó mâu thuẫn định nghĩa giả lập. Thuật to án thám tử Bis dựa vào các nhóm chữ để đại diện cho thiên vị (v.d., lương, và'sếp'để đại diện cho việc làm, như một sắc thái thiên vị đối với phụ nữ trong văn bản). Tuy nhiên, phương pháp xây dựng những nhóm chữ này có nhiều điểm yếu, chủ yếu là danh sách từ đó dựa trên linh cảm của các nhà nghiên cứu. Chúng tôi đề xuất hai phương pháp mới để tự động hoá lập danh sách các từ để đại diện cho giả sử. Chúng tôi thấy các phương pháp vượt trội các phương pháp phát hiện khuynh hướng độc lập. Nghiên cứu của chúng tôi cải thiện khả năng của công nghệ Njala để phát hiện khuynh hướng và đánh dấu sai lệch giới tính có trong các trường hợp có ảnh hưởng. Để kiểm tra khả năng phát hiện thiên vị độc lập của phương pháp lập lập lập lập NLP, Chúng tôi thụt lùi kết quả của khuynh hướng trong trường hợp pháp chống lại dữ liệu thống kê của phụ nữ vào nhân công trong hàng trăm năm qua.</abstract_vi>
      <abstract_bg>Анализираме 6,7 милиона документа от съдебната практика, за да определим наличието на полово пристрастие в съдебната система. Намираме, че настоящите методи за откриване на пристрастия в НЛП са недостатъчни, за да се определи пристрастието към пола в нашата база данни от съдебната практика и да се предложи алтернативен подход. Показваме, че несъответствителните резултати на съществуващите алгоритми са последици от непоследователните дефиниции на предишните изследвания на самите пристрастия. Алгоритмите за откриване на пристрастия разчитат на групи думи, за да представят пристрастия (напр. "заплата", "работа" и "шеф", за да представят заетостта като потенциално пристрастна тема срещу жените в текста). Методите за изграждане на тези групи от думи обаче имат няколко слабости, най-вече, че списъците с думи се основават на собствените интуиции на изследователите. Предлагаме два нови метода за автоматизиране на създаването на списъци с думи за представяне на пристрастия. Откриваме, че нашите методи превъзхождат настоящите методи за откриване на пристрастия. Нашите изследвания подобряват възможностите на технологията за откриване на пристрастия и подчертават пристрастията на пола, присъстващи във влиятелната съдебна практика. За да тестваме ефективността на метода ни за откриване на пристрастия в НЛП, ние регресираме нашите резултати от пристрастия в съдебната практика спрямо данните от преброяването на участието на жените в работната сила в САЩ през последните 100 години.</abstract_bg>
      <abstract_nl>We analyseren 6,7 miljoen jurisprudentiedocumenten om de aanwezigheid van gender bias binnen ons rechtssysteem te bepalen. We vinden dat de huidige bias detectie methoden in NLP onvoldoende zijn om gender bias in onze jurisprudentie database te bepalen en een alternatieve aanpak voor te stellen. We tonen aan dat de inconsistente resultaten van bestaande algoritmes gevolgen zijn van de inconsistente definities van vooroordelen zelf. Algorithmen voor bias detectie zijn gebaseerd op groepen woorden om bias te vertegenwoordigen (bijvoorbeeld, 'salaris', 'baan' en 'baas' om werkgelegenheid als potentieel bevooroordeeld thema tegen vrouwen in tekst te vertegenwoordigen). De methoden om deze groepen woorden te bouwen hebben echter verschillende zwakke punten, vooral dat de woordenlijsten gebaseerd zijn op de eigen intuïtie van de onderzoekers. We stellen twee nieuwe methoden voor om het maken van woordlijsten te automatiseren om vooroordelen weer te geven. We vinden dat onze methoden beter presteren dan de huidige NLP bias detectie methoden. Ons onderzoek verbetert de mogelijkheden van NLP-technologie om bias op te sporen en benadrukt gender biases aanwezig in invloedrijke jurisprudentie. Om de prestaties van onze NLP bias detectie methode te testen, regresseren we onze resultaten van bias in jurisprudentie tegen Amerikaanse census data van de deelname van vrouwen in het arbeidsproces in de afgelopen 100 jaar.</abstract_nl>
      <abstract_da>Vi analyserer 6,7 millioner retspraksis dokumenter for at fastslå tilstedeværelsen af kønsfordele i vores retssystem. Vi finder, at nuværende bias detection metoder i NLP er utilstrækkelige til at bestemme kønsbias i vores retspraksis database og foreslå en alternativ tilgang. Vi viser, at eksisterende algoritmers inkonsekvente resultater er konsekvenser af tidligere forsknings inkonsekvente definitioner af fordomme selv. Diagnosedetekteringsalgoritmer er baseret på grupper af ord til at repræsentere bias (f.eks. "løn", "job" og "chef" til at repræsentere beskæftigelse som et potentielt partisk tema mod kvinder i tekst). Metoderne til at opbygge disse ordgrupper har dog flere svagheder, primært at ordlisterne er baseret på forskernes egne intuitioner. Vi foreslår to nye metoder til automatisering af oprettelsen af ordlister til at repræsentere fordomme. Vi finder ud af, at vores metoder overgår nuværende NLP bias detektion metoder. Vores forskning forbedrer NLP-teknologiens evner til at detektere bias og fremhæver kønsfordomme, der er til stede i indflydelsesrig retspraksis. For at teste vores NLP bias detection metodes ydeevne, regrederer vi vores resultater af bias i retspraksis mod amerikanske folketællingsdata om kvinders deltagelse i arbejdsstyrken i de sidste 100 år.</abstract_da>
      <abstract_hr>Analiziramo 6,7 milijuna slučajnih dokumenta kako bi utvrdili prisutnost spolnih predrasuda u našem sudskom sustavu. Nalazimo da trenutne metode otkrivanja pristrasnosti u NLP-u nisu dovoljne za određivanje spolnih pristrasnosti u našoj bazi podataka zakona i predložiti alternativni pristup. Pokazujemo da su rezultati postojećih algoritma nepristojni posljedici samih nepristojnih definicija prethodnih istraživanja. Algoritmi za otkrivanje Bias oslanjaju se na grupe riječi koje predstavljaju predrasude (npr. „plaća, „posao“, i „šef“) kako bi predstavljali zapošljavanje kao potencijalno predrasudenu temu protiv žena u tekstu). Međutim, metode za izgradnju tih grupa riječi imaju nekoliko slabosti, glavno da su popis riječi temeljeni na vlastitoj intuiciji istraživača. Predlažemo dvije nove metode automatizacije stvaranja listova riječi kako bi predstavljali predrasude. Naše metode nadmađuju trenutne metode otkrivanja pristrasnosti NLP-a. Naše istraživanje poboljšava mogućnosti NLP tehnologije za otkrivanje predrasude i naglašava spolne predrasude koje postoje u utjecajnom zakonu o slučaju. Da bismo testirali učinkovitost metode otkrivanja pristrasnosti našeg NLP-a, regresirali smo rezultate pristrasnosti u slučaju zakona protiv podataka o popisu američkih podataka o sudjelovanju žena u radnoj snazi u posljednjih 100 godina.</abstract_hr>
      <abstract_de>Wir analysieren 6,7 Millionen Rechtsprechungsdokumente, um das Vorhandensein von Gender Bias in unserem Justizsystem festzustellen. Wir finden, dass die derzeitigen Bias-Detektionsmethoden in NLP nicht ausreichen, um Gender Bias in unserer Rechtsprechungsdatenbank zu bestimmen und einen alternativen Ansatz vorzuschlagen. Wir zeigen, dass die inkonsistenten Ergebnisse bestehender Algorithmen Konsequenzen der inkonsistenten Definitionen von Vorurteilen selbst sind. Algorithmen zur Bias-Erkennung stützen sich auf Wortgruppen, um Bias darzustellen (z.B. "Gehalt", "Job" und "Chef", um Beschäftigung als potenziell voreingenommenes Thema gegen Frauen im Text darzustellen). Die Methoden zum Aufbau dieser Wortgruppen weisen jedoch mehrere Schwächen auf, vor allem, dass die Wortlisten auf den eigenen Intuitionen der Forscher basieren. Wir schlagen zwei neue Methoden vor, um die Erstellung von Wortlisten zu automatisieren, um Verzerrungen darzustellen. Wir stellen fest, dass unsere Methoden die aktuellen NLP Bias Detection Methoden übertreffen. Unsere Forschung verbessert die Fähigkeiten der NLP-Technologie zur Erkennung von Bias und hebt geschlechtsspezifische Bias hervor, die in einflussreicher Rechtsprechung vorhanden sind. Um die Leistungsfähigkeit unserer NLP Bias Detection Methode zu testen, regressieren wir unsere Ergebnisse der Bias in der Rechtsprechung gegen US-Zensusdaten zur Erwerbsbeteiligung von Frauen in den letzten 100 Jahren.</abstract_de>
      <abstract_id>Kami menganalisis 6,7 juta dokumen hukum untuk menentukan kehadiran bias jenis dalam sistem hukum kami. Kami menemukan bahwa metode deteksi bias saat ini di NLP tidak cukup untuk menentukan bias jenis dalam pangkalan data hukum kami dan mengusulkan pendekatan alternatif. Kami menunjukkan bahwa hasil yang tidak konsisten algoritma yang ada adalah konsekuensi dari penelitian sebelumnya definisi tidak konsisten biases mereka sendiri. Algoritma deteksi bias bergantung pada kelompok kata untuk mewakili bias (contohnya, `gaji,' 'pekerjaan,' dan `bos' untuk mewakili pekerjaan sebagai tema yang berpotensi bias terhadap wanita dalam teks). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions.  Kami menyarankan dua metode baru untuk otomatisasi penciptaan daftar kata untuk mewakili biases. Kami menemukan bahwa metode kita melebihi metode deteksi bias NLP saat ini. Penelitian kami meningkatkan kemampuan teknologi NLP untuk mendeteksi bias dan menyatakan bias jenis yang ada dalam kasus yang mempengaruhi. Untuk menguji prestasi metode deteksi bias NLP kami, kami mengubah hasil bias kami dalam kasus hukum melawan data census AS tentang pesertaan wanita dalam pasukan kerja dalam 100 tahun terakhir.</abstract_id>
      <abstract_ko>우리는 사법 시스템에 성별 편견이 있는지 확인하기 위해 670만 개의 판례 문건을 분석했다.우리는 현재 NLP의 편견 검출 방법이 판례법 데이터베이스에서의 성별 편견을 확정하기에 부족하다는 것을 발견하고 대체 방법을 제시했다.우리는 기존 알고리즘의 불일치 결과는 이전에 연구한 편차 자체에 대한 정의가 불일치한 결과라는 것을 보여준다.편견 검출 알고리즘은 하나의 단어에 의존하여 편견을 나타낸다(예를 들어'salary','job','boss'는 취업이 텍스트에서 여성에 대한 잠재적인 편견 주제임을 나타낸다).그러나 이러한 어구를 구축하는 방법은 몇 가지 단점이 있는데 주로 어표는 연구원들의 직감을 바탕으로 하는 것이다.우리는 편견을 표시하기 위해 두 가지 새로운 방법을 사용해서 자동으로 단어 목록을 만드는 것을 권장합니다.우리는 우리의 방법이 현재의 NLP 편차 측정 방법보다 우수하다는 것을 발견했다.우리 연구는 NLP 기술로 편견을 감지하는 능력을 높이고, 영향력 있는 판례법에 존재하는 성 편견을 강조했다.우리의 NLP 편차 측정 방법의 성능을 시험하기 위해 판례법의 편차 결과는 지난 100년 동안 미국 인구센서스에서 여성이 노동력에 참여한 데이터와 회귀할 것이다.</abstract_ko>
      <abstract_sw>Tunafahamu nyaraka za sheria milioni 6.7 za kesi ili kuamua kuwepo kwa upendeleo wa kijinsia ndani ya mfumo wetu wa mahakama. Tunapata kwamba mbinu za kutambua upendeleo wa sasa katika NLP hazina kutosha kuamua upendeleo wa kijinsia katika database ya sheria yetu na pendekeza njia mbadala. Tunaonyesha kwamba matokeo yasiyo na ukweli wa algorithi yaliyopo ni matokeo ya utafiti yaliyotokea kutokuwepo kwa utafiti wenyewe. Mfululizo wa utambuzi wa Bias wanategemea makundi ya maneno yanayowakilisha upendeleo (kwa mfano, 'mshahara,' 'kazi', na 'bosi' wakiwakilisha ajira kama mada yenye uwezekano wa upinzani dhidi ya wanawake kwa maandishi). Hata hivyo, mbinu za kujenga makundi haya ya maneno yana udhaifu kadhaa, hasa kwamba orodha ya maneno ni ya msingi na mitazamo ya watafiti wenyewe. Tunazipendekeza njia mbili mpya za kutengeneza orodha ya maneno ili kuwakilisha upendeleo. Tunaona kuwa njia zetu za kutekeleza njia za uchunguzi wa sasa za NLP. Utafiti wetu unaboresha uwezo wa teknolojia ya NLP kutambua upendeleo na kuonyesha upendeleo wa kijinsia unaoendelea katika sheria ya kesi yenye ushawishi. Ili kujaribu kuchunguza mbinu yetu ya kutambua upendeleo wa NLP, tunarudisha matokeo yetu ya upendeleo katika kesi ya sheria dhidi ya taarifa za kufuatilia sensa za wanawake kushiriki katika vikosi vya kazi katika miaka 100 iliyopita.</abstract_sw>
      <abstract_fa>ما 6.7 میلیون دلیل قانون پرونده را تحلیل می کنیم تا تعیین وجود جنسی در سیستم دادگاهی ما باشد. ما متوجه می‌شویم که روش شناسایی جاری در NLP برای تعیین کنار جنسی در داده‌های داده‌های قانونی ما کافی نیستند و یک روش دیگری پیشنهاد می‌دهند. ما نشان می دهیم که نتایج ناپایدار الگوریتم موجود نتیجه‌های ناپایدار تحقیقات قبلی از تعریف ناپایدار خودشان هستند. الگوریتم‌های شناسایی بین‌ها بر گروهی از کلمات وابسته می‌شوند که نشان داده شوند (به عنوان «salary,» «job» و «boss» برای نشان دادن کاری به عنوان یک عنوان مسئله‌ای که ممکن است بر علیه زنان در متن است). ولی روش‌هایی برای ساختن این گروه‌های کلمه‌ها چندین ضعیف دارند، در اصل لیست‌های کلمه‌ها بر روی نظریه‌های خود تحقیقات کننده‌اند. ما دو روش جدید را پیشنهاد می‌کنیم که آفرینش لیست‌های کلمه‌ها را برای نشان دادن توجه‌ها خودکار کنیم. ما متوجه می‌شویم که روش‌هایمان از روش‌های شناسایی پیشرفت NLP فعلی بیشتر انجام می‌دهند. تحقیقات ما توانایی تکنولوژی NLP را بهبود می‌دهد تا پیشرفت را شناسایی کند و در قانون پرونده‌های تاثیر نشان دهد. برای آزمایش تحقیقات روش شناسایی پیشرفت NLP ما، نتیجه‌هایمان را در مورد قانون در مقابل داده‌های عدد زنان آمریکا در نیروی کار در ۱۰۰ سال گذشته باز می‌گردانیم.</abstract_fa>
      <abstract_tr>Biz 6.7 milliýon gadyr kanunlaryň kanunlaryny jussa sistemamyzda tanyşdyrmak üçin çözýäris. NLP'da häzirki faýllaryň sözlerimizde nähili faýllaryň tanyşyk metodlarynyň jentiller baýramyzda ýeterlik däldir we başga bir nusga teklip etmegi üçin ýeterlik däldir. Biz bar algoritmalaryň nädogry netijesi öňki araştyrmanyň özleriniň hem-de durmaýan tanyşlarynyň netijesi diýip görkeýäris. Iki sany tanyşdyrma algoritmalar bias-täsirini temel etmek üçin sözler toparyna ynanýarlar (meselâ, `salary,' `iş,' we `boss') metin içindeki a ýallara garşy edilen işi temel etmek üçin işleýän temasyna ynanýarlar. Ýöne bu sözlerin toparyny gurmak üçin ýüregimizde birnäçe zaçyrlyk bar, özellikle sözlerin sözleriniň öz düşünjelerine daýanýar. Biz söz listlerini üýtgetmek üçin iki täze yöntemi üýtgetmek üçin teklip edip görýäris. Biziň yönlerimiziň häzirki NLP faýllaryň deteksi yöntemlerinden çykyp ýok. Biziň araşdyrymyz NLP tehnologiýasynyň biasy detek etmek we seňler kanunlarynyň etkisi kanunlarynda tapawutlamak üçin üýtgedýär. NLP bias detection yöntemimizi test etmek üçin, ABD kanunlaryň son 100 ýylda işgärler gücüne katılmasynyň netijesini boýun gaýtalamak üçin netijesimizi yzarlamak üçin.</abstract_tr>
      <abstract_sq>Ne analizojmë 6.7 milion dokumente të rastit për të përcaktuar praninë e paragjykimit të gjinisë brenda sistemit tonë gjyqësor. Ne zbulojmë se metodat aktuale të zbulimit të paragjykimeve në NLP nuk janë të mjaftueshme për të përcaktuar paragjykimet gjinore në bazën e dhënave tona të rastit dhe për të propozuar një qasje alternative. Ne tregojmë se rezultatet jo konsistente të algoritmeve ekzistuese janë pasojat e përcaktimit jo konsistent të kërkimeve të mëparshme të paragjykimeve vetë. Algoritmet e zbulimit të dëmtimeve mbështeten në grupe fjalësh për të përfaqësuar paragjykimin (për shembull, `paga,' 'punë,' dhe `shef' për të përfaqësuar punësimin si një temë potencialisht të paragjykimit ndaj grave në tekst). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions.  Ne sugjerojmë dy metoda të reja për automatizimin e krijimit të listave të fjalëve për të përfaqësuar paragjykimet. Ne zbulojmë se metodat tona kalojnë metodat e tanishme të zbulimit të paragjykimeve të NLP-së. Kërkimi ynë përmirëson aftësitë e teknologjisë NLP për të zbuluar paragjykimet dhe thekson paragjykimet gjinore të pranishme në rastligjin ndikues. Me qëllim që të testojmë performancën e metodës sonë të zbulimit të paragjykimeve të NLP-s ë, ne regresojmë rezultatet tona të paragjykimeve në rastligjin kundër të dhënave të rregjistrimit të SHBA për pjesëmarrjen e grave në forcën e punës në 100 vitet e fundit.</abstract_sq>
      <abstract_af>Ons analiseer 6.7 miljoen kaswet dokumente om die voorsiening van geneemde bias in ons regstelsel te bepaal. Ons vind dat huidige bias-opdekking metodes in NLP is onvoldoende om genaamde bias in ons geval wet databasis te bepaal en 'n alternatiewe toegang te voorstel. Ons wys dat bestaande algoritme se inkonsistente resultate is sekvens van vooraf ondersoek se inkonsistente definisies van biases self. Bias-opdekking algoritme vertrou op groepe woorde om bias te verteenwoordig (bv. `salary,' `job,' en `bos' om arbeid te verteenwoordig as 'n potensieel biased tema teen vroue in teks). Maar die metodes om hierdie groepe van woorde te bou het verskeie swakhede, voorskynlik dat die woorde lyste gebaseer is op die eie intuisies van die ondersoekers. Ons voorstel twee nuwe metodes om die skepping van woorde lyste outomatiese te stel om voorspoedings te stel. Ons vind dat ons metodes uitvoer huidige NLP bias-ontdekking metodes. Ons ondersoek verbeter die moontlikhede van NLP-teknologie om bias te ontdek en verlig seuns voorspoedige wat in influensielike kaswet is. Om ons NLP-bias-opdekking metode se prestasie te probeer, word ons ons resultate van bias in geval wet teen U.S. census data van vroue se deelnadering in die werkskrap in die laaste 100 jaar herstel.</abstract_af>
      <abstract_hy>Մենք վերլուծում ենք 6.7 միլիոն իրավաբանական փաստաթղթեր, որպեսզի որոշենք գենդերային կողմնականությունը մեր իրավաբանական համակարգում: Մենք հայտնաբերում ենք, որ ՆԼՊ-ի ներկայիս կողմնականության հայտնաբերման մեթոդները բավարար չեն գենդերային կողմնականության որոշումների համար մեր իրավաբանական տվյալներում և առաջարկում են այլ մոտեցում: Մենք ցույց ենք տալիս, որ գոյություն ունեցող ալգորիթմների անհամապատասխան արդյունքները նախորդ հետազոտության անհամապատասխան սահմանումների հետևանքներ են: Ալգորիթմները կախված են բառերի խմբերից, որպեսզի ներկայացնեն կողմնականությունը (օրինակ, `աշխատավարձը,', 'աշխատանքը' և `ղեկավարը' որպեսզի ներկայացնեն աշխատանքը որպես պոտենցիալ կողմնակի թեմա կանանց դեմ տեքստում): Այնուամենայնիվ, բառերի այս խմբերի կառուցման մեթոդները մի քանի թույլ ունեն, հիմնականում այն, որ բառերի ցուցակները հիմնված են հետազոտողների սեփական ինտուիցիաների վրա: Մենք առաջարկում ենք երկու նոր մեթոդ բառերի ցուցակների ստեղծման ավտոմատիզացման համար, որպեսզի ներկայացնենք կողմնականություններ: Մենք հայտնաբերում ենք, որ մեր մեթոդները գերազանցում են ներկայիս ՆԼՊ-ի կողմնականության հայտնաբերման մեթոդները: Մեր հետազոտությունները բարելավում են ՆԼՊ տեխնոլոգիայի հնարավորությունները բացահայտելու կողմնականությունը և շեշտում են գենդերային կողմնականությունները, որոնք գոյություն ունեն ազդեցիկ իրավաբանության մեջ: Որպեսզի ստուգենք մեր ՆԼՊ-ի կողմնակի հայտնաբերման մեթոդի արտադրությունը, մենք վերադառնում ենք դատաստանի մեջ մեր կողմնականության արդյունքները ԱՄՆ-ի հանձնարարության տվյալների հետ կապված կանանց մասնակցության աշխատաշուկայում վերջին 100 տարիների ըն</abstract_hy>
      <abstract_am>6.7 ሚሊዮን የሥርዓት ሕግ ውስጥ የሴሰኝነት ጥያቄን በሕግ ስርዓታችን ውስጥ ለመግኘት እናስተምር፡፡ የአሁኑ የውይይት ግንኙነት በNLP ውስጥ የሴሰኝነትን ቅድሚያ በሥርዓታችን ህግ ዳታቤታችን መፍጠር አይበቃንም የተለወጠውንም ጉዳይ ለመፍጠር እና ለመለወጥ ጉዳይ ማቅረብ እናደርጋለን፡፡ እናሳያቸዋለን፣ የአልጎርጂም ውጤቶች የባይኖረው ውጤቶች ለራሳቸው የማይቃወም የጥያቄ ግንኙነት ነው፡፡ ቢያዝ አሌጎርጂም በክፍለ ጉዳዮች ላይ ብያሽን (ምሳሌ ‹ደመወዝ፣’ ‘ሥራ›› እና ‹boss› ስራ በጽሑፍ ላይ በተቃራኒ ተቃውሞ የሴቶችን ጉዳይ መሆኑን ለማስተካከል ነው፡፡ ምንም እንኳን፣ እነዚህን ቃሎች መሠረት ሥርዓት ብዙዎች ደካሞች አሉ፡፡ የቃላት ዝርዝሮች መፍጠርን ለመፍጠር ሁለት አዲስ ልማድ እናስባለን፡፡ We find that our methods outperform current NLP bias detection methods.  ትምህርታችን የNLP ቴክሎጂ መፍታትን ማግኘት እና በጥያቄ ሥርዓት ውስጥ ያሉትን የሴሰኝነት ሁኔታዎችን ማሳየት ይሻላል፡፡ የNLP የውይይት ግንኙነታችንን ለመፈትነው፣ ባለፉት 100 ዓመታት ውስጥ የሴቶችን ተግባር ማግባት በሚቃወም በአሜሪካ ሰንሰናዊ ዳታ ላይ የጥያቄን ፍሬታችንን መለስን፡፡</abstract_am>
      <abstract_az>Biz 6.7 milyon vəziyyətdə qanunu belə analiz edirik ki, qanunlarımızda cins bias olmasını təsdiqləyirik. NLP içindəki hökmdür bias keşif metodlarının cins tərzini təyin etmək və alternatif tərzini təbliğ etmək üçün kifayət deyildir. Biz həmin algoritmin müəyyən sonuçlarını göstəririk ki, əvvəlki araştırmaların müəyyən olmayan tərzlərin tərzlərinin sonuçlarıdır. İki keşif algoritmi təsirlərini g östərmək üçün sözlərin qruplarına təvəkkül edir (məsələn, "maaş", "iş" və "boss" yazılmış qadınlara qarşı mümkün olaraq təsirli tema olaraq istifadə etmək üçün istifadə edir). Lakin bu sözlərin qruplarını inşa etmək üçün metodların çoxlu zəiflikləri vardır, ilk dəfə sözlərin məlumatı araştıranların öz düşüncələrinə dayandırılır. Biz söz listelərinin yaradılışını təşkil etmək üçün iki yeni metod təşkil edirik. Bizim metodlarımız ağımdaki NLP bias keçmə metodlarından üstün olduğunu görürük. Bizim araştırmalarımız NLP teknolojisinin tərzini keşfetmək və təsirli davalar qanunlarında olan cins tərzlərini təşkil edir. NLP bias detection metodumunun performansını s ınamaq üçün, son 100 il ərzində qadınların istifadə etməsi üçün U.S. qadınların istifadə etməsi məlumatlarının sonuçlarını yenidən dəyişdiririk.</abstract_az>
      <abstract_bn>আমরা ৬.৭ মিলিয়ন মামলা আইনের তথ্য বিশ্লেষণ করি আমাদের বিচার ব্যবস্থার মধ্যে লিঙ্গ বিভ্রান্তির উপস্থিতি নির আমরা খুঁজে পাচ্ছি যে এনএলপিতে বর্তমান বিভিন্ন বিভিন্ন বিভিন্ন উপায় নির্ধারণ করা যথেষ্ট নয় এবং বিকল্প উপায় প্রস্তাব করা। আমরা দেখাচ্ছি যে বিদ্যমান অ্যালগরিদমের অস্থিরতার ফলাফল পূর্বে গবেষণার বিষয়বস্তু নিজেদের নিজেদের বিভ্রান্তিকর সংজ্ বিয়াস আবিষ্কার করা আলগরিদম বিয়াদের প্রতিনিধিত্ব করে (উদাহরণস্বরূপ, বেতন, 'চাকরি' এবং 'বস' নারীদের বিরুদ্ধে সম্ভাব্য বিভিন্ন বিষয় হিসেবে চাকুরীর প্ তবে এই শব্দগুলোর বানানোর পদ্ধতি বেশ কয়েকটি দুর্বলতা আছে, প্রধানভাবে এই শব্দগুলোর তালিকা গবেষকদের নিজেদের অনুভূতির উপর ভিত আমরা স্বয়ংক্রিয়ভাবে শব্দ তালিকার তৈরি করার দুটি নতুন পদ্ধতি পরামর্শ দিচ্ছি যাতে তারা বিভিন্ন বিভি আমরা খুঁজে পাচ্ছি যে বর্তমান এনএলপি বিয়াস আবিষ্কারের পদ্ধতিতে আমাদের পদ্ধতি। আমাদের গবেষণা এনএলপি প্রযুক্তির ক্ষমতা উন্নত করে প্রভাবিত কেসের আইনে উপস্থিত লিঙ্গের বৈষম্য সনাক্ত করতে এবং লিঙ্গের বির আমাদের এনএলপি বিয়াস আবিষ্কার করার পদ্ধতি পরীক্ষা করার জন্য, গত ১০০ বছরে আমেরিকার সেন্সরসের তথ্যের বিরুদ্ধে নারীদের কাজে অংশগ্রহণের বিরুদ্ধে আইন</abstract_bn>
      <abstract_ca>Analitzem 6,7 milions de documents de jurisprudencia per determinar la presença de bias de gènere dins el nostre sistema judicial. Trobem que els mètodes actuals de detecció de bias en NLP no són suficients per determinar bias de gènere en la nostra base de dades de jurisprudencia i proposar un enfocament alternativ. Mostrem que els resultats inconsistent s dels algoritmes existents s ón conseqüències de les definicions inconsistents de biases de la recerca anterior. Els algoritmes de detecció del bias es basan en grups de paraules que representen el bias (per exemple, `salary,' `job,' i `boss' per representar l'ocupació com un tema potencialment bias contra les dones en text). Però els mètodes per construir aquests grups de paraules tenen diverses debilitats, principalment que les llistes de paraules estan basades en les intuïcions dels investigadors. Sugirem dos nous mètodes d'automatització de la creació de llistes de paraules per representar biases. Trobem que els nostres mètodes superen els mètodes actuals de detecció de bias de la NLP. La nostra investigació millora les capacitats de la tecnologia NLP per detectar bias i destaca les bias de gènere presents en influent jurisprudencia. In order to test our NLP bias detection method's performance, we regress our results of bias in case law against U.S census data of women's participation in the workforce in the last 100 years.</abstract_ca>
      <abstract_cs>Analyzujeme 6,7 milionů judikaturních dokumentů, abychom zjistili přítomnost genderové zaujatosti v našem soudním systému. Zjišťujeme, že současné metody detekce bias v NLP nejsou dostatečné k určení genderové bias v naší judikaturní databázi a navrhnout alternativní přístup. Ukazujeme, že nekonzistentní výsledky existujících algoritmů jsou důsledky nekonzistentních definicí samotných předsudků předchozího výzkumu. Algoritmy detekce zaujatosti spoléhají na skupiny slov, které reprezentují zaujatost (např. "plat", "práce" a "šéf", aby reprezentovaly zaměstnání jako potenciálně zaujaté téma vůči ženám v textu). Metody sestavení těchto skupin slov však mají několik slabých stránek, především to, že seznamy slov jsou založeny na vlastních intuicích vědců. Navrhujeme dvě nové metody automatizace tvorby seznamů slov pro reprezentaci zaujatostí. Zjišťujeme, že naše metody překonávají současné metody detekce bias NLP. Náš výzkum zlepšuje schopnosti technologie NLP detekovat zaujatosti a upozorňuje na genderové zaujatosti přítomné v vlivné judikaturě. Za účelem testování výkonnosti naší metody detekce předběžnosti NLP provádíme regresi výsledků předběžnosti v judikaturě proti americkým sčítáním údajů o účasti žen na pracovní síle za posledních sto let.</abstract_cs>
      <abstract_et>Analüüsime 6,7 miljonit kohtupraktika dokumenti, et teha kindlaks soolise eelarvamuse esinemine meie kohtusüsteemis. Leiame, et praegused eelarvamuste tuvastamise meetodid NLP-s ei ole piisavad soolise eelarvamuse tuvastamiseks meie kohtupraktika andmebaasis ja alternatiivse lähenemisviisi pakkumiseks. Näitame, et olemasolevate algoritmide ebaühtlased tulemused on varasemate uuringute ebaühtlase määratluse tagajärjed. Eelarvamuste tuvastamise algoritmid tuginevad eelarvamuste kujutamiseks sõnarühmadele (nt "palk", "töö" ja "boss", et kujutada tööd potentsiaalselt erapooletu teemana naiste suhtes tekstis). Kuid nende sõnarühmade ehitamise meetoditel on mitmeid nõrkusi, eelkõige see, et sõnaraamatud nimekirjad põhinevad teadlaste enda intuitsioonil. Pakume välja kaks uut meetodit sõnaloendite loomise automatiseerimiseks, et esindada eelarvamusi. Leiame, et meie meetodid ületavad praeguseid NLP kallakute tuvastamise meetodeid. Meie uuringud parandavad NLP tehnoloogia võimekust tuvastada eelarvamusi ja toovad esile soolised eelarvamused, mis esinevad mõjukas kohtupraktikas. Selleks et testida meie NLP-i eelarvamuste tuvastamise meetodi tulemuslikkust, taandame kohtupraktika eelarvamuste tulemused USA loendusandmetega naiste osalemise kohta tööjõus viimase 100 aasta jooksul.</abstract_et>
      <abstract_bs>Analiziramo 6,7 miliona slučajnih dokumenta kako bi utvrdili prisutnost spolnih predrasuda u našem sudskom sustavu. Nalazimo da su trenutne metode otkrivanja pristrasnosti u NLP-u nedovoljne za određivanje spolnih pristrasnosti u našoj bazi podataka zakona i predložili alternativni pristup. Pokazujemo da su rezultati postojećih algoritma neskladni rezultati posljedica neskladnih definicija prethodnih istraživanja samih predrasuda. Algoritmi za otkrivanje biologije oslanjaju se na grupe riječi koje predstavljaju predrasude (npr. „plaća, „posao“, i `šef“, kako bi predstavljali zapošljavanje kao potencijalno predrasuden tema protiv žena u tekstu). Međutim, metode za izgradnju tih grupa riječi imaju nekoliko slabosti, glavno da su listi riječi zasnovani na vlastitoj intuiciji istraživača. Predlažemo dvije nove metode automatizacije stvaranja listi riječi kako bi predstavljali predrasude. Naše metode nadmađuju trenutne metode otkrivanja pristrasnosti NLP-a. Naše istraživanje poboljšava mogućnosti NLP tehnologije za otkrivanje predrasude i naglašava spolne predrasude koje postoje u uticajnom pravu na slučaj. Da bismo testirali učinkovitost metode otkrivanja pristrasnosti našeg NLP-a, regresiramo rezultate pristrasnosti u slučaju zakona protiv podataka o popisu američkih podataka o sudjelovanju žena u radnoj snazi u posljednjih 100 godina.</abstract_bs>
      <abstract_fi>Analysoimme 6,7 miljoonaa oikeuskﾃ､ytﾃ､ntﾃｶasiakirjaa selvittﾃ､ﾃ､ksemme sukupuolijakauman olemassaolon oikeusjﾃ､rjestelmﾃ､ssﾃ､mme. Havaitsemme, ettﾃ､ nykyiset ennakkoluulojen havaitsemismenetelmﾃ､t NLP:ssﾃ､ eivﾃ､t riitﾃ､ mﾃ､ﾃ､rittﾃ､mﾃ､ﾃ､n sukupuolen ennakkoluuloa oikeuskﾃ､ytﾃ､ntﾃｶtietokannassamme ja ehdottamaan vaihtoehtoista lﾃ､hestymistapaa. Osoitamme, ettﾃ､ olemassa olevien algoritmien epﾃ､johdonmukaiset tulokset ovat seurausta aiemmissa tutkimuksissa tehdyistﾃ､ epﾃ､johdonmukaisista harhamﾃ､ﾃ､rityksistﾃ､. Bias detection algoritmit perustuvat sanaryhmiin edustamaan puolueellisuutta (esim. "palkka", "tyﾃｶ" ja "pomo" edustamaan tyﾃｶllisyyttﾃ､ mahdollisesti puolueellisena teemana naisia vastaan tekstissﾃ､). Nﾃ､iden sanaryhmien rakentamismenetelmissﾃ､ on kuitenkin useita heikkouksia, ensisijaisesti se, ettﾃ､ sanaluettelot perustuvat tutkijoiden omiin intuitioihin. Ehdotamme kahta uutta tapaa automatisoida sanalistojen luominen edustamaan ennakkoluuloja. Havaitsemme, ettﾃ､ menetelmﾃ､mme ovat parempia kuin nykyiset NLP-viuhojen havaitsemismenetelmﾃ､t. Tutkimuksemme parantaa NLP-teknologian kykyﾃ､ havaita ennakkoluuloja ja korostaa vaikutusvaltaisessa oikeuskﾃ､ytﾃ､nnﾃｶssﾃ､ esiintyviﾃ､ sukupuoliennakkoluuloja. Testataksemme NLP-puolueen havaitsemismenetelmﾃ､mme suorituskykyﾃ､ regressoimme oikeuskﾃ､ytﾃ､nnﾃｶn puolueellisuuden tuloksia Yhdysvaltojen vﾃ､estﾃｶnlaskennan tietoihin naisten osallistumisesta tyﾃｶvoimaan viimeisen sadan vuoden aikana.</abstract_fi>
      <abstract_ha>Tuna anayya da takardar kisa 6.7 milliardu a cikin jurisdictiyarmu. Tun gane cewa hanyoyin gano na yanzu a cikin NLP ba za'a ba wanda ya buƙata ƙarya ga jinsi a cikin danne-danganta sharciyarmu, kuma yana buƙata wata hanyor musanya. Tuna nũna cewa matsala na algorituman da ba'a da ba da taƙaita ba ta kasance matsayi na zaman fassarar da bakwai na bakwai. Algorituman Bias na dõgara g a jama'a na kalmõmi su nuna abis (misali, "musahar", "aikin", da 'boss' dõmin su nuna wani jiyi mai yiwuwa ya yi karya a kan mata cikin rubutun). Haƙĩƙa, hanyoyinin da za'a samar da waɗannan jama'a-jama'a, yana da maras ƙaranci, mainli, a kan jerin maganar nan, aka ƙayyade a kan fikan masu fitin. Tuna shawarar da hanyõyi biyu biyu masu iya faratarwa wa halin jerin maganar da za'a nuna taƙaitãwa. Tuna gane cewa hanyoyinmu na sami hanyoyin zafi na NLP yanzu. LakeyinMu yana ƙara awon technical NLP ga gane haske da kuma yana sarrafa saurin da ke cikin sharci masu shagala. Dõmin ya jarraba aikin na NLP 'yar'awi na aikin aikin ƙwarai, za mu s ãka matsalar da maras a cikin kashfa da sharci ya yi kashẽwa a kan mutane na rayin mutane na rayin aiki a cikin shekarar 100 na shida.</abstract_ha>
      <abstract_sk>Analiziramo 6,7 milijona dokumentov sodne prakse, da ugotovimo prisotnost spolne pristranskosti v našem pravosodnem sistemu. Ugotavljamo, da sedanje metode odkrivanja pristranskosti v NLP ne zadostujejo za ugotavljanje pristranskosti med spoloma v naši bazi sodne prakse in predlaganje alternativnega pristopa. Pokazali smo, da so nedosledni rezultati obstoječih algoritmov posledice nedoslednih definicij pristranskosti, ki jih je opravila predhodna raziskava. Algoritmi za odkrivanje pristranskosti se zanašajo na skupine besed, ki predstavljajo pristranskost (npr. "plača", "delo" in "šef", da predstavljajo zaposlitev kot potencialno pristransko temo proti ženskam v besedilu). Vendar pa imajo metode za gradnjo teh skupin besed več slabosti, predvsem da besedni seznami temeljijo na lastnih intuicijah raziskovalcev. Predlagamo dve novi metodi avtomatizacije ustvarjanja besednih seznamov, ki predstavljajo pristranskosti. Ugotavljamo, da naše metode presegajo trenutne metode odkrivanja pristranskosti NLP. Naše raziskave izboljšujejo zmožnosti tehnologije NLP za odkrivanje pristranskosti in poudarjajo pristranskosti med spoloma, prisotne v vplivni sodni praksi. Da bi preizkusili uspešnost naše metode odkrivanja pristranskosti NLP, naše rezultate pristranskosti v sodni praksi regresiramo glede na podatke iz popisa ameriških popisov o udeležbi žensk v delovni sili v zadnjih 100 letih.</abstract_sk>
      <abstract_he>אנו מנתחים 6.7 מיליון מסמכי משפט כדי לקבוע את נוכחות ההתמחות מינית בתוך מערכת המשפט שלנו. אנו מוצאים ששיטות גילוי היחידות הנוכחיות ב-NLP אינן מספיקות כדי לקבוע היחידות מיני במסד הנתונים של המקרים שלנו ולהציע גישה אלטרנטיבית. אנחנו מראים שהתוצאות לא תואמות של האלגוריתמים קיימים הן השלכות של הגדרות לא תואמות של מחקר קודם אלגוריתמים של גילוי הבריאות תלויים בקבוצות מילים כדי לייצג הבריאות (למשל, "משכורת", "עבודה", "עבודה" ו "בוס" כדי לייצג את העבודה כנושא פוטנציאלי מועמד נגד נשים בטקסט). However, the methods to build these groups of words have several weaknesses, primarily that the word lists are based on the researchers' own intuitions.  אנו מציעים שתי שיטות חדשות לאוטומטיזציה של יצירת רשימות מילים כדי לייצג חיונים. אנו מוצאים שהשיטות שלנו מעליפות את שיטות גילוי ההתמחות הנוכחיות של NLP. המחקר שלנו משפר את היכולות של טכנולוגיה NLP לגלות ההתמחות ומדגיש את ההתמחות מיני הנוכחות במקרה משפיע. In order to test our NLP bias detection method's performance, we regress our results of bias in case law against U.S census data of women's participation in the workforce in the last 100 years.</abstract_he>
      <abstract_bo>ང་ཚོས་རང་ཉིད་ཀྱི་དུས་ཡུལ་ལྡན་པའི་ཡིག་ཆ་༦.༧་ཙམ་ཞིབ་དཔྱད་ནས་དབུལ We find that current bias detection methods in NLP are insufficient to determine gender bias in our case law database and propose an alternative approach. ང་ཚོས་གནས་ཡུལ་གྱི་སྐྱེས་རྩལ་བ་དག་གི་རྐྱེན་འབྲས་མེད་པའི་གནད་སྡུད་རྐྱེན་བྱས་མེད་པའི་གནད་སྡུད་མེད་པའི་དབྱ Bias detection algorithms rely on words to represent bias (e.g., `salary,' `job,' and `boss'to represent employment as a potentially biased theme against women in text). ཡིན་ནའང་། གནད་དོན་གྱི་ཚོགས་ཁང་འདི་དག་བཟོ་བར་བཟོ་བ་ཀྱི་ཐབས་ལམ་ལ་ཆ་ཁ་ཤས་ཀྱི་ཉེན་ཁ་ཤས་ཡོད། ང་ཚོས་ཐོ་འགོད་པ་དེ་རང་འགུལ་གྱིས་ཐབས་ལམ་གསར་པ་གཉིས་བསམ་འཆར་ཡོད། ང་ཚོས་ད་ལྟའི་ཐབས་ལམ་དེ་ནས་ད་ལྟའི་NLP གནད་སྡུད་དབྱེ་རྟགས་ཐབས་ལམ་ལ་ཕན་ཐོག ང་ཚོའི་འཚོལ་ཞིབ་ཀྱང་ནི་NLP(technology)གི་ཆ་རྐྱེན་དང་རང་ཉིད་ཀྱི་ཕྱོགས་རྣམས་མཐོང་སྣང་དང་གསལ་བཤད་ཀྱི་ཡོད། To test our NLP bias detection method's performance, we regress our bias resulting in law against U.S census of women's participation in the workforce in the last 100 years.</abstract_bo>
      <abstract_jv>Awak dhéwé énglek 6.7 milion dolan kanggo nggawe aturan Kasal kanggo nggawe barang-barang kanggo ngilangno kuwi mau Awak dhéwé ngêkaké ngerasakno karo hal-hal ingkang NLP kuwi ora sufisik kanggo nggawe barang kanggo nggawe barang kanggo kebebasané perusahaan kanggo kebebasané hukum sing gawe lan nyimpen maneh sing wis ana. Awak dhéwé ngerasakno karo hal-hal gak perusahaan Algorithm kuwi kapan kanggo nguasai perusahaan winih sing gak perusahaan karo perusahaan Algorithm Awak dhéwé, sira lak nggawe nggawe kelompok iki dadi luwih-luwih hayo perusahaan, nik awak dhéwé kuwi tindakan kelompok sing bisa basa Perusahaan winih Monday Awak dhéwé ngerti cara-cara sing paling nggawe NLP bukane. Awakdhéwé éntuk perbudhakan kanggo ngerasakno kapanan NLP teknôlogi kanggo kebonan biasa lan ngregani biasa kuwi mau sing gawe nguasakno uwong. Mbok bisa ngubah winih kanggo ngilangno bias NLP iki, awak dhéwé iso nglanggar tarjamahan kanggo bias-bias kuwi dianggap kanggo Kemerdekaan kanggo Kemerdekaan kanggo Kemerdekaan Winih sing bisa ngubah dhéwé sing paling nggawe barang hun tau.</abstract_jv>
      <abstract_fil>Inaalisa namin ang 6.7 milyong kautusan na dokumento para ipagtibay ang harapan ng pagdadala ng lahi sa ating sistema ng judisyal. Nasusumpungan natin na ang kasalukuyang paraan ng pag-detection ng bias sa NLP ay hindi sapat na magtakda ng gender bias sa ating case law database at magbigay ng alternatiyong paraan. Pinapakita natin na ang mga walang pagsalang resulta ng mga algoritmo ay mga consequences ng mga walang pagsalang definiciyon ng unang reserbasyon ng mga bias sa kanilang sarili. Ang mga algoritmo ng pag-detection ay nagsisiitiwala sa mga grupo ng mga salita upang mag-represent ng bias (halimbawa, `salary,' `job,' at `boss' upang mag-represent ng pangangasiwa bilang isang posibilidad na tema laban sa mga babae sa teksto). Gayon ma'y ang mga paraan ng pagtatayo ng mga grupong ito ng mga salita ay may maraming kahinaan, na una'y ang mga salitang listahan ay nagiisip sa sariling pagiisip ng mga manggagawa. Nagbibigay kami ng dalawang bagong paraan ng paglikha ng mga salitang listahan upang ipaghanda ang mga bias. Nasusumpungan natin na ang aming mga paraan ay hindi nakagawa sa mga paraan ng pag-detection ng NLP. Ang aming pagsasangguni ay nagpapalago ng kapangyarihan ng teknolojiya ng NLP upang makasumpong ng bias at magliliwanag ng mga bias ng lahi na nasa kautusan ng influential case. Upang subukan ang gawain ng metodo ng pag-detection ng NLP bias, kami ay nagbabalik ng mga resulta ng bias sa kautusan laban sa mga datos ng census ng U.S. ng pagdadalhin ng mga babae sa trabaho noong huling 100 taon.</abstract_fil>
      </paper>
    <paper id="10">
      <title>Investigating the Impact of <a href="https://en.wikipedia.org/wiki/Gender_representation">Gender Representation</a> in ASR Training Data : a Case Study on Librispeech<fixed-case>ASR</fixed-case> Training Data: a Case Study on Librispeech</title>
      <author><first>Mahault</first><last>Garnerin</last></author>
      <author><first>Solange</first><last>Rossato</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>86–92</pages>
      <abstract>In this paper we question the impact of <a href="https://en.wikipedia.org/wiki/Gender_representation">gender representation</a> in training data on the performance of an end-to-end ASR system. We create an experiment based on the Librispeech corpus and build 3 different training corpora varying only the proportion of data produced by each gender category. We observe that if our system is overall robust to the gender balance or imbalance in training data, it is nonetheless dependant of the adequacy between the individuals present in the training and testing sets.</abstract>
      <url hash="d224b621">2021.gebnlp-1.10</url>
      <doi>10.18653/v1/2021.gebnlp-1.10</doi>
      <bibkey>garnerin-etal-2021-investigating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/librispeech">LibriSpeech</pwcdataset>
    <title_es>Investigación del impacto de la representación de género en los datos de capacitación de ASR: un estudio de caso sobre Librispeech</title_es>
      <title_fr>Étude de l'impact de la représentation hommes-femmes dans les données de formation ASR : une étude de cas sur Librispeech</title_fr>
      <title_ar>التحقيق في تأثير التمثيل الجنساني في بيانات التدريب على ASR: دراسة حالة على Librispeech</title_ar>
      <title_zh>案ASR培训数代表性:其Librispeech例究之</title_zh>
      <title_ja>ASRトレーニングデータにおける性別表現の影響の調査： Librispeechに対するケーススタディ</title_ja>
      <title_pt>Investigando o impacto da representação de gênero nos dados de treinamento em ASR: um estudo de caso sobre librispeech</title_pt>
      <title_ru>Изучение влияния гендерного представительства в данных обучения ASR: тематическое исследование Librispeech</title_ru>
      <title_hi>एएसआर प्रशिक्षण डेटा में लिंग प्रतिनिधित्व के प्रभाव की जांच: लिब्रिसपीच पर एक केस स्टडी</title_hi>
      <title_ga>Tionchar Ionadaíocht Inscne i Sonraí Oiliúna ASR a Imscrúdú: Cás-Staidéar ar Librispeich</title_ga>
      <title_ukr>Дослідження впливу гендерної репрезентації в навчальних даних ASR: тематичне дослідження Librispeech</title_ukr>
      <title_isl>Rannsókn á áhrifum kynþáttar í ASR þjálfunargögnum: tilviksrannsókn á Librispeech</title_isl>
      <title_hu>A nemek közötti reprezentáció hatásának vizsgálata az ASR képzési adatokban: esettanulmány a Librispeech-ről</title_hu>
      <title_el>Η διερεύνηση των επιπτώσεων της εκπροσώπησης των φύλων στα δεδομένα κατάρτισης ASR: μια μελέτη περίπτωσης για τη βιβλιογραφία</title_el>
      <title_ka>ASR განსწავლების მონაცემების ინტექტირება: Librispeech მონაცემების ინტექტირება</title_ka>
      <title_kk>ASR оқыту деректерінде гендерді таңдау нәтижесін зерттеу: a Case Study on Librispeech</title_kk>
      <title_lt>Lyčių atstovavimo poveikio ASR mokymo duomenise tyrimas: Bibliotekos bylų tyrimas</title_lt>
      <title_mk>Истрага на влијанието на полската претстава во податоците за обука на АСР: случајна студија на Librispeech</title_mk>
      <title_it>Indagine sull'impatto della rappresentazione di genere nei dati di formazione ASR: un caso di studio su Librispeech</title_it>
      <title_ml>ASR പരിശീലനത്തിന്റെ ഡേറ്റായില്‍ സ്ത്രീന്‍ പ്രതിനിധികളുടെ പ്രഭാവം അന്വേഷിക്കുന്നു: ലിബ്രിസ്പീചിലെ ഒരു കേസ</title_ml>
      <title_no>Investigerer effekten av generelt representasjon i ASR- treningsdata: ein tilfeldig undersøking om Librispeech</title_no>
      <title_ms>Menyelidiki Kesan Perwakilan Gender dalam Data Latihan ASR: kajian kes pada Librispeech</title_ms>
      <title_pl>Badanie wpływu reprezentacji płci w danych szkoleniowych ASR: studium przypadku Librispeech</title_pl>
      <title_ro>Investigarea impactului reprezentanței de gen în datele de formare ASR: un studiu de caz pe Librispeech</title_ro>
      <title_mt>Investigazzjoni tal-Impatt tar-Rappreżentanza tas-Sessi fid-Dejta dwar it-Taħriġ ASR: Studju ta’ Każ dwar Librispeech</title_mt>
      <title_sr>Istraživanje utjecaja predstavljanja žena u podacima obuke ASR: studija slučajeva o Librispeech</title_sr>
      <title_mn>ASR Training Data: a Case Study on Librispeech</title_mn>
      <title_so>Investigation the Impact of gender Representation in ASR Data Training: a Case Study on Librispeech</title_so>
      <title_si>ASR ප්‍රේෂණික දත්තේ ජෙන්ඩර් ප්‍රතිනිධානයේ පරීක්ෂණය: ප්‍රතිනිධානය සඳහා කේස් පරීක්ෂණය</title_si>
      <title_ta>ASR பயிற்சி தரவில் பெண் பிரதிநிதியின் விளைவு ஆய்வு செய்யப்படுகிறது</title_ta>
      <title_sv>Undersökning av genusrepresentationens effekter i ASR-utbildningsdata: en fallstudie på Librispeech</title_sv>
      <title_ur>ASR ٹرینینگ ڈاٹ میں جنس ریسپانسیٹ کے اثر کا تحقیق کرتا ہے: ایک کیس تحقیق لیبراریسپیچ پر</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Điều tra về ảnh hưởng của quan điểm giới tính trong dữ liệu đào tạo ASR: a Case study on Librispeech</title_vi>
      <title_hr>Istraživanje utjecaja predstavljanja žena u podacima obuke ASR: istraživanje slučaja o Librispeech</title_hr>
      <title_da>Undersøgelse af virkningen af kønsrepræsentation i ASR-uddannelsesdata: et casestudie om Librispeech</title_da>
      <title_bg>Изследване на въздействието на представителството на половете в обучението за АСР данни: казус за Либриспейх</title_bg>
      <title_nl>Onderzoek naar de impact van gendervertegenwoordiging in ASR-opleidingsgegevens: een casestudy op Librispeech</title_nl>
      <title_de>Untersuchung der Auswirkungen der Geschlechtervertretung in ASR-Trainingsdaten: eine Fallstudie zu Librispeech</title_de>
      <title_id>Investigating the Impact of Gender Representation in ASR Training Data: a Case Study on Librispeech</title_id>
      <title_fa>تحقیق اثر نماینده جنسی در اطلاعات آموزش ASR: یک مطالعه پرونده در Librispeech</title_fa>
      <title_ko>ASR 교육 데이터에서 성별의 대표적인 영향에 대한 조사: Librispeech 사례 연구</title_ko>
      <title_sw>Kuchunguza madhara ya kuhakikisha jinsia katika mafunzo ya data ya ASR: Utafiti wa kesi kuhusu Librispeech</title_sw>
      <title_tr>ASR eğitim Maglumatynda Genjer Representationisiň etkisini barlamak: a Case Study on Librispeech</title_tr>
      <title_sq>Hetimi i ndikimit të përfaqësimit të gjinëve në të dhënat e trajnimit të ASR: një studim rasti mbi Librispeech</title_sq>
      <title_am>በASR ትምህርት ዳታ ውስጥ የgender Representation Impact investigating: a Case Study on Librispeech</title_am>
      <title_hy>Սկնդի ներկայացման ազդեցության ուսումնասիրելը ASR-ի ուսումնասիրության տվյալներում. գրադարանի դեպքերի ուսումնասիրություն</title_hy>
      <title_af>Inligting van die Impact van Gender Representation in ASR Oefening Data: 芒聙聶n Kas Studie op Librispeech</title_af>
      <title_bn>আসার প্রশিক্ষণ তথ্যে লিঙ্গ প্রতিনিধির প্রভাব অনুসন্ধান করা হচ্ছে: লিবিস্পেচের একটি কেস স্টিডি</title_bn>
      <title_az>ASR t톛hsil veril톛nl톛rind톛 Gen칞 Representation Impact Investigating in ASR Training Data: a Case Study on Librispeech</title_az>
      <title_bs>Istraživanje utjecaja predstavljanja žena u podacima obuke ASR: istraživanje slučaja o Librispeech</title_bs>
      <title_ca>Investigar l'impacte de la representació de gènere en les dades d'capacitació ASR: un estudi de cas sobre Librispeech</title_ca>
      <title_et>Soolise esindatuse mõju uurimine ASR koolituse andmetes: juhtumiuuring Librispeechi kohta</title_et>
      <title_cs>Vyšetřování vlivu reprezentace pohlaví v ASR tréninkových datech: případová studie na Librispeech</title_cs>
      <title_fi>Sukupuolten edustuksen vaikutusten tutkiminen ASR-koulutuksessa: tapaustutkimus Librispeechistä</title_fi>
      <title_he>חקירת השפעה של מייצג מין בנתונים האימונים של ASR: מחקר מקרים על Librispeech</title_he>
      <title_jv>istraging the Effect of Gender representation in ASR Learning data: a Case Learning on Library</title_jv>
      <title_ha>Inspecting the Effect of gender Reposition in ATR Training Data: a case Research on Librispech</title_ha>
      <title_sk>Preiskava vpliva zastopanosti spolov v podatkih o usposabljanju ASR: študija primera Librispeech</title_sk>
      <title_fil>Investigating the Impact of Gender Representation in ASR Training Data: a Case Study on Librispeech</title_fil>
      <title_bo>Investigating the Impact of Gender Representation in ASR Training Data: a Case Study on Librispeech</title_bo>
      <abstract_ar>في هذه الورقة ، نشكك في تأثير تمثيل النوع الاجتماعي في بيانات التدريب على أداء نظام ASR الشامل. نقوم بإنشاء تجربة بناءً على مجموعة Librispeech ونبني 3 هيئات تدريب مختلفة تختلف فقط في نسبة البيانات التي تنتجها كل فئة جنس. نلاحظ أنه إذا كان نظامنا قويًا بشكل عام للتوازن بين الجنسين أو عدم التوازن في بيانات التدريب ، فإنه مع ذلك يعتمد على الكفاية بين الأفراد الموجودين في مجموعات التدريب والاختبار.</abstract_ar>
      <abstract_es>En este artículo, cuestionamos el impacto de la representación de género en los datos de capacitación sobre el rendimiento de un sistema ASR integral. Creamos un experimento basado en el corpus de Librispeech y construimos 3 cuerpos de entrenamiento diferentes que varían solo la proporción de datos producidos por cada categoría de género. Observamos que si nuestro sistema es en general sólido para el equilibrio de género o el desequilibrio en los datos de capacitación, depende de la adecuación entre las personas presentes en los conjuntos de capacitación y pruebas.</abstract_es>
      <abstract_pt>Neste artigo, questionamos o impacto da representação de gênero nos dados de treinamento no desempenho de um sistema ASR de ponta a ponta. Criamos um experimento baseado no corpus Librispeech e construímos 3 corpora de treinamento diferentes variando apenas a proporção de dados produzidos por cada categoria de gênero. Observamos que, se nosso sistema é globalmente robusto ao equilíbrio de gênero ou desequilíbrio nos dados de treinamento, ele é, no entanto, dependente da adequação entre os indivíduos presentes nos conjuntos de treinamento e teste.</abstract_pt>
      <abstract_ja>本稿では，エンドツーエンドのASRシステムのパフォーマンスに対するトレーニングデータにおけるジェンダー表現の影響について疑問を呈する．私たちはLibrispeechコーパスに基づいて実験を作成し、それぞれの性別カテゴリによって生成されたデータの割合のみを変化させる3つの異なるトレーニングコーパスを構築します。私たちは、私たちのシステムがトレーニングデータのジェンダーバランスまたはアンバランスに対して全体的に堅牢である場合でも、トレーニングとテストセットに存在する個人間の妥当性に依存していることを観察します。</abstract_ja>
      <abstract_hi>इस पेपर में हम एक एंड-टू-एंड एएसआर सिस्टम के प्रदर्शन पर प्रशिक्षण डेटा में लिंग प्रतिनिधित्व के प्रभाव पर सवाल उठाते हैं। हम लिब्रिसपीच कॉर्पस के आधार पर एक प्रयोग बनाते हैं और प्रत्येक लिंग श्रेणी द्वारा उत्पादित डेटा के अनुपात में केवल 3 अलग-अलग प्रशिक्षण निगम का निर्माण करते हैं। हम देखते हैं कि यदि हमारी प्रणाली प्रशिक्षण डेटा में लिंग संतुलन या असंतुलन के लिए समग्र रूप से मजबूत है, तो यह फिर भी प्रशिक्षण और परीक्षण सेट में मौजूद व्यक्तियों के बीच पर्याप्तता पर निर्भर है।</abstract_hi>
      <abstract_ru>В настоящем документе мы ставим вопрос о влиянии представленности мужчин и женщин в данных о профессиональной подготовке на эффективность комплексной системы ASR. Мы создаем эксперимент на основе корпуса Librispeech и строим 3 различных обучающих корпуса, варьируя только долю данных, полученных по каждой гендерной категории. Мы отмечаем, что, если наша система в целом устойчива к гендерному балансу или дисбалансу в данных о профессиональной подготовке, она, тем не менее, зависит от адекватности между лицами, присутствующими в наборах для профессиональной подготовки и тестирования.</abstract_ru>
      <abstract_ukr>У цій роботі ми ставимо під сумнів вплив гендерної репрезентації в навчальних даних на ефективність системи ASR. Ми створюємо експеримент на основі корпусу Librispeech і будуємо 3 різні навчальні корпуси, варіюючи лише частку даних, отриманих кожною гендерною категорією. Ми спостерігаємо, що якщо наша система є загалом надійною щодо гендерної рівноваги або дисбалансу в навчальних даних, вона, тим не менш, залежить від адекватності між особами, присутніми в навчальних та тестових наборах.</abstract_ukr>
      <abstract_fr>Dans cet article, nous nous interrogeons sur l'impact de la représentation des sexes dans les données de formation sur la performance d'un système ASR de bout en bout. Nous créons une expérience basée sur le corpus Librispeech et construisons 3 corpus d'entraînement différents ne variant que la proportion de données produites par chaque catégorie de genre. Nous observons que si notre système est globalement robuste par rapport à l'équilibre entre les sexes ou au déséquilibre des données de formation, il dépend néanmoins de l'adéquation entre les personnes présentes dans les ensembles de formation et de test.</abstract_fr>
      <abstract_ga>Sa pháipéar seo ceistímid an tionchar atá ag ionadaíocht inscne i sonraí oiliúna ar fheidhmíocht an chórais ASR ceann go ceann. Cruthaímid turgnamh bunaithe ar chorpas Librispeech agus tógaimid 3 chorparáid oiliúna dhifriúla nach n-athraítear ach céatadán na sonraí a tháirgeann gach catagóir inscne. Tugaimid faoi deara má tá ár gcóras láidir ar an iomlán don chothromaíocht inscne nó don éagothroime i sonraí oiliúna, go mbraitheann sé mar sin féin ar leordhóthanacht na ndaoine aonair atá i láthair sna tacair oiliúna agus tástála.</abstract_ga>
      <abstract_zh>本文质疑培训数中性别代表性对端至端ASR系统性能。 盖Librispeech语料库创一实验,构3异教语料库,性类不同。 吾观之,若吾系统对练数之性,与不平之体,犹决于教试集个体之充分性。</abstract_zh>
      <abstract_el>Στην παρούσα εργασία εξετάζουμε τον αντίκτυπο της εκπροσώπησης των φύλων στα δεδομένα κατάρτισης στην απόδοση ενός ολοκληρωμένου συστήματος ΑΣR. Δημιουργούμε ένα πείραμα βασισμένο στο σώμα και κατασκευάζουμε τρία διαφορετικά σώματα εκπαίδευσης που διαφοροποιούν μόνο το ποσοστό των δεδομένων που παράγονται από κάθε κατηγορία φύλου. Παρατηρούμε ότι αν το σύστημά μας είναι γενικά ανθεκτικό στην ισορροπία των φύλων ή στην ανισορροπία στα δεδομένα κατάρτισης, εξαρτάται ωστόσο από την επάρκεια μεταξύ των ατόμων που βρίσκονται στα σύνολα κατάρτισης και δοκιμών.</abstract_el>
      <abstract_hu>Jelen tanulmányban megkérdőjelezzük, hogy a nemek közötti reprezentáció milyen hatással van a képzési adatokban egy end-to-end ASR rendszer teljesítményére. Kísérletet hozunk létre a Librispeech corpus alapján, és 3 különböző edzőtestületet építünk, amelyek csak az egyes nemkategóriák szerinti adatok arányát változtatják. Megfigyeljük, hogy ha rendszerünk általánosságban megbízható a nemek közötti egyensúlyhoz vagy a képzési adatok egyensúlyhiányához, akkor azonban attól függ, hogy a képzési és tesztkészletekben részt vevő egyének megfelelő-e.</abstract_hu>
      <abstract_isl>Í þessu pappíri efast við áhrifum kynþáttar í þjálfunargögnum um framkvæmd ASR kerfisins loka til loka. Við búum til tilraun sem byggist á Librispeech corpus og byggjum þrjú mismunandi þjálfunarhóp sem breytist aðeins hlutfalli gagna sem framleitt er eftir hverjum kynflokki. We observe that if our system is overall robust to the gender balance or imbalance in training data, it is nonetheless dependant of the adequacy between the individuals present in the training and testing sets.</abstract_isl>
      <abstract_ka>ამ დოკუნეში ჩვენ ვაკითხებთ გენდერის გამოსახულების მონაცემების შესახებ ASR სისტემის გაკეთებაზე. ჩვენ ვქმნით ექსპერიმენტი, რომელიც Librispeech corpus-ზე დაბაზიან და 3 განსხვავებული განსწავლების კოპორაცია განსხვავებულია მხოლოდ ყოველ გენდრის კატეგორიაში გამოიყ ჩვენ დავხედავთ, რომ თუ ჩვენი სისტემა ძალიან ძალიან გენექტური ბალანზაციას ან განმავლობას განმავლობაში მონაცემების განმავლობაში, მაგრამ ეს იყოს განმავლობაზე, რომელიც განმავლობაში და ტესტის</abstract_ka>
      <abstract_lt>Šiame dokumente mes abejojame lyčių atstovavimo mokymo duomenise poveikiu baigiamosios ASR sistemos veikimui. Mes sukuriame eksperimentą, pagrįstą Librispeech korpusu, ir sukuriame 3 skirtingus mokymo korpusus, kurie skiriasi tik pagal kiekvieną lyties kategoriją gautų duomenų dalis. Mes pastebime, kad jei mūsų sistema apskritai yra patikima siekiant lyčių pusiausvyros ar mokymo duomenų disbalanso, ji vis dėlto priklauso nuo mokymo ir bandymų rinkiniuose dalyvaujančių asmenų tinkamumo.</abstract_lt>
      <abstract_kk>Бұл қағазда біз ASR жүйесінің соңғы-соңғы жұмыс істеу үшін гендерлік деңгейінің нәтижесін сұрақ береміз. Біз Librispeech корпус негізінде тәжірибе құрып, 3 түрлі оқыту корпорасын құрып, тек әрбір гендер санаттарының деректерінің бөлшегін өзгертіп тұрмыз. Біз, егер жүйеміздің гендер балансы немесе оқыту деректерінің балансы немесе дисбалансы тәжірибесіне қатысты болса, бұл оқыту және сынақтар жиындарының арасындағы адамдардың адамдарының адамдығына тәуелді</abstract_kk>
      <abstract_ms>Dalam kertas ini kita mempersoalkan kesan perwakilan jenis dalam data latihan mengenai prestasi sistem ASR akhir-akhir. Kami mencipta eksperimen berdasarkan Librispeech corpus dan membina 3 corpora latihan yang berbeza hanya berbeza proporsi data yang dihasilkan oleh setiap kategori jenis. Kami memperhatikan bahawa jika sistem kita secara keseluruhan kuat untuk keseimbangan jenis atau ketidakseimbangan dalam data latihan, ia tetap bergantung kepada keperluan antara individu yang hadir dalam set latihan dan ujian.</abstract_ms>
      <abstract_it>In questo articolo ci interroghiamo sull'impatto della rappresentazione di genere nei dati di formazione sulle prestazioni di un sistema end-to-end ASR. Creiamo un esperimento basato sul corpus Librispeech e costruiamo 3 diversi corpi di allenamento variabili solo la proporzione di dati prodotti da ogni categoria di genere. Osserviamo che se il nostro sistema è complessivamente solido all'equilibrio di genere o allo squilibrio dei dati di formazione, dipende comunque dall'adeguatezza tra le persone presenti nei set di formazione e di test.</abstract_it>
      <abstract_ml>ഈ പത്രത്തില്‍ ഞങ്ങള്‍ പ്രദര്‍ശിപ്പിക്കുന്നത് ആസ്ആര്‍ സിസ്റ്റത്തിന്റെ അവസാനത്തേക്കുള്ള പ്രകടനത്തെപ്പറ്റിയാണ്. ഞങ്ങള്‍ ലിബ്രിസ്പീച് കോര്‍പ്പുസിനെ അടിസ്ഥാനമാക്കി 3 വ്യത്യസ്ത പരീക്ഷണങ്ങള്‍ ഉണ്ടാക്കുകയും, എല്ലാ ലിബ്രിസ്പീച് വിഭാഗത്തില നമ്മുടെ സിസ്റ്റത്തിന്റെ സംവിധാനത്തെ പൊതുവാക്കുകയോ പരിശീലനത്തിന്റെയും പരിശീലനത്തിന്റെയും ഇടയിലുള്ള വ്യക്തികള്‍ക്കും തമ്മിലുള്ള വ്</abstract_ml>
      <abstract_mt>F’dan id-dokument qed nitdubitaw l-impatt tar-rappreżentanza tas-sessi fid-dejta tat-taħriġ dwar il-prestazzjoni ta’ sistema ASR minn tarf sa tarf. Aħna nħolqu esperiment ibbażat fuq il-Librispeech corpus u nibnu 3 korpi differenti ta’ taħriġ li jvarjaw biss il-proporzjon ta’ dejta prodotta minn kull kategorija ta’ sessi. Aħna ninnota li jekk is-sistema tagħna tkun b’mod ġenerali soda għall-bilanċ bejn is-sessi jew l-iżbilanċ fid-dejta tat-taħriġ, hija madankollu dipendenti mill-adegwatezza bejn l-individwi preżenti fis-settijiet tat-taħriġ u l-ittestjar.</abstract_mt>
      <abstract_mn>Энэ цаасан дээр бид гендер илтгэлийн нөлөөг асууж байна. АСР системийн төгсгөл болон төгсгөл болох өгөгдлийн талаар суралцах өгөгдлийн талаар. Бид Librispeech корпус дээр суурилсан туршилт бий болгож, 3 өөр сургалтын корпора бүтээж, зөвхөн гендер хэлбэрээр бүтээсэн өгөгдлийн хувьд өөрчлөгдөж байна. Хэрэв бидний систем суралцах өгөгдлийн талаар гендерийн тэнцвэрт эсвэл тэнцвэртэй байвал энэ нь суралцах болон шалгах хэмжээнд байгаа хүмүүсийн адилхан байдлын хамааралтай гэдгийг бид анзаарсан.</abstract_mn>
      <abstract_pl>W artykule zastanawiamy się nad wpływem reprezentacji płci w danych szkoleniowych na wydajność kompleksowego systemu ASR. Tworzymy eksperyment oparty na korpusie Librispeech i budujemy trzy różne korpusy treningowe zmieniające jedynie proporcję danych produkowanych przez każdą kategorię płci. Zauważamy, że jeśli nasz system jest ogólnie solidny w odniesieniu do równowagi płci lub zaburzeń równowagi w danych szkoleniowych, jest on jednak zależny od adekwatności pomiędzy osobami obecnymi w zestawach szkoleniowych i testowych.</abstract_pl>
      <abstract_ro>În această lucrare punem la îndoială impactul reprezentării de gen în datele de formare asupra performanței unui sistem end-to-end ASR. Creăm un experiment bazat pe corpul Librispeech și construim 3 corpuri de formare diferite variind doar proporția de date produse de fiecare categorie de gen. Observăm că, dacă sistemul nostru este, în general, robust în raport cu echilibrul de gen sau dezechilibrul datelor privind formarea, depinde totuși de caracterul adecvat al persoanelor prezente în seturile de formare și testare.</abstract_ro>
      <abstract_mk>Во овој документ се сомневаме во влијанието на претставувањето на половите во податоците за обуката на изведувањето на системот од крај до крај на АСР. Ние создаваме експеримент базиран на Librispeech корпус и изградуваме 3 различни тренинг корпуси кои разликуваат само процентот на податоци произведени од секоја полова категорија. Ние забележуваме дека ако нашиот систем е целосно силен во однос на полова баланс или небаланс во податоците за обука, сепак зависи од соодветноста помеѓу поединците присутни во обуката и тестирањето.</abstract_mk>
      <abstract_sr>U ovom papiru sumnjamo na utjecaj predstavljanja spola u podacima o obuci na provedbu sustava ASR-a do kraja. Mi stvorimo eksperiment baziran na Librispeech korpusu i izgradimo 3 različite trening korporacije, razlikujući se samo proporcija podataka proizvođenih od svake kategorije spola. Primećujemo da ako je naš sistem ukupno roban prema spolnoj ravnoteži ili nelagodnosti podataka o obuci, ipak je ovisan o adekvatnosti između pojedinaca koji su prisutni u obuci i testiranju.</abstract_sr>
      <abstract_no>I denne papiret spør vi etterspørselen av følgjande representasjon i opplæringsdata om utviklinga av ein ASR- system for slutten til slutten. Vi oppretter ein eksperiment basert på Librispeech corpus og bygger 3 ulike opplæringskorpora som bare varierer proporsjonen av data produserte av kvar sekskategori. Vi observerer at dersom systemet vårt er overalt sterkt til seksbalansen eller ulikheten i opplæringsdata, er det likevel avhengig av adekviteten mellom personene som finst i opplæring og testsettet.</abstract_no>
      <abstract_so>Warqadan waxaynu ka waydiinnaa saamaynta sharciga dadka jinsiga looga dhigo waxbarashada ku saabsan sameynta nidaamka ASR dhammaadka ugu dambaysta. Waxaan sameynaa imtixaan ku saleysan qabriga Librispeech, waxaana dhisnaa shirkado 3 oo kala duduwan oo kala duduwan oo kala duduwan kala duduwan oo kala duduwan kooxo macluumaadka la soo saaray jinsi kasta. Waxaynu fiirinaynaa in haddii nidaamkayagu uu si wada jir ah u geysto balaanshaha jinsiga ama aan la simnaaneyn karo macluumaadka waxbarashada, waxay ku xiran tahay qiimo ku filan dhexdooda dadka ku jira kooxaha waxbarashada iyo imtixaanka.</abstract_so>
      <abstract_si>මේ පත්තරේ අපි ප්‍රශ්නයක් කරනවා ජෙන්ඩර් ප්‍රතිනිධානයගේ ප්‍රශ්නයක් අවසාන ASR පද්ධතියේ ප්‍රශ්නයක් ග අපි ලිබ්රිස්පයිච් කොර්පුස් එක අධාරිත පරීක්ෂණයක් නිර්මාණය කරනවා සහ වෙනස් පරීක්ෂණ කොර්පෝරා තුනක් නිර්ම අපි බලාපොරොත්තු කරනවා අපේ පද්ධතිය සාමාන්‍ය විශ්වාස කරනවා නමුත් අපේ පද්ධතිය සාමාන්‍ය විශ්වාස කරනවා නමුත් ප්‍රශ්නය සහ පරීක්ෂණ ස</abstract_si>
      <abstract_sv>I denna uppsats ifrågasätter vi hur könsrepresentation i utbildningsdata påverkar resultatet av ett heltäckande ASR-system. Vi skapar ett experiment baserat på Librispeech-korpusen och bygger 3 olika träningskorpus som endast varierar andelen data som produceras av varje genuskategori. Vi konstaterar att om vårt system generellt sett är robust mot könsbalansen eller obalansen i utbildningsdata, är det ändå beroende av lämpligheten mellan de individer som deltar i utbildnings- och testuppsättningarna.</abstract_sv>
      <abstract_ta>இந்த காகிதத்தில் நாம் பெண் பிரதிநிதியின் விளைவுகளை பயிற்சி தகவலில் கேள்வி கேட்கிறோம் ASR முடிவில் முடிவ நாம் லிப்ரிசிக் கூட்டத்தை அடிப்படையில் ஒரு சோதனையை உருவாக்கி ஒவ்வொரு பெண்ணின் வகையில் உருவாக்கும் தரவு வித்தியாசம் மட் We observe that if our system is overall robust to the gender balance or imbalance in training data, it is nonetheless dependant of the adequacy between the individuals present in the training and testing sets.</abstract_ta>
      <abstract_ur>ہم اس کاغذ میں سؤال کرتے ہیں کہ جنس کی تعلیم کے ذریعہ ایک آخر-پایان آس آر سیسٹم کے کامیابی پر ڈیٹوں کی تدریس کرتی ہے۔ ہم ایک آزمائش بناتے ہیں لیبریسپیچ کورپوس پر اور تین مختلف ترینس کورپور بناتے ہیں جو صرف ہر جنس کاٹی کے ذریعے پیدا کئے ہوئے ڈاکٹوں کے اندازے متفاوت ہیں. ہم دیکھتے ہیں کہ اگر ہمارا سیستم جنس تعلیم یا غیر قابل تعلیم دیٹوں میں سکھایا گیا ہے تو یہ تعلیم اور آزمائش سٹ میں موجود ہونے والوں کے درمیان مناسب تعلیم کا اعتبار ہے۔</abstract_ur>
      <abstract_uz>Bu qogʻozdagi biz ASR tizimning oxiriga oxirigi tizimning bajarishi haqida jinsiy representiyasining effekti haqida savol qilamiz. Biz Librispeek kompyuterga asoslangan bir tajribani yaramiz va 3 boshqa ta'lim kompaniyalarini yaratishmiz va faqat har bir jinsiya kategoriga yaratilgan maʼlumot tarkibini o'zgartiradi. Biz tasavvur qilamiz, agar bizning tizimmiz jamiyat jinsiyalar balandligiga yoki taʼminlovchi maʼlumotga o'xshasha bo'lsa, bu ta'lim va sinov satrlarida mavjud odamlarga yetarli bo'lsa.</abstract_uz>
      <abstract_vi>Trong tờ giấy này, chúng tôi đặt câu hỏi về tác động của sự phân phối giới tính trong dữ liệu đào tạo về hiệu quả của hệ thống ASR cuối cùng. Chúng tôi tạo ra một thí nghiệm dựa trên Kinh tế Librispeech và xây dựng ba cơ thể huấn luyện khác nhau chỉ khác với số lượng dữ liệu được sản xuất bởi mỗi loại giới tính. Chúng tôi quan sát rằng nếu hệ thống của chúng tôi hoàn to àn vững chắc về cân bằng giữa giới tính hay mất cân bằng trong dữ liệu về huấn luyện, nó không ảnh hưởng đến sự phù hợp giữa cá nhân có mặt trong các bộ huấn luyện và thử nghiệm.</abstract_vi>
      <abstract_nl>In dit artikel onderzoeken we de impact van gender representatie in opleidingsgegevens op de prestaties van een end-to-end ASR systeem. We maken een experiment gebaseerd op het Librispeech corpus en bouwen drie verschillende trainingscorpora's die alleen variëren van het aandeel van de gegevens geproduceerd door elke gendercategorie. Wij constateren dat als ons systeem over het algemeen robuust is tegen het evenwicht tussen mannen en vrouwen of onevenwichtigheid in trainingsgegevens, het desondanks afhankelijk is van de adequaatheid tussen de personen die aanwezig zijn in de trainings- en testsets.</abstract_nl>
      <abstract_hr>U ovom papiru sumnjamo na učinak predstavljanja spola u podacima obuke o učinkovitosti sustava ASR-a do kraja. Napravili smo eksperiment na temelju Librispeech korpusa i izgradili 3 različite vježbanje korporacije koje se razlikuju samo dio podataka proizvođenih od svake kategorije spola. Primjećujemo da ako je naš sustav ukupno jak prema spolnoj ravnoteži ili ravnoteži u podacima obuke, ipak je ovisan o adekvatnosti između pojedinaca koji su prisutni u obuci i testiranju.</abstract_hr>
      <abstract_de>In diesem Beitrag wird der Einfluss der Geschlechtervertretung in Trainingsdaten auf die Leistungsfähigkeit eines End-to-End ASR-Systems untersucht. Wir erstellen ein Experiment basierend auf dem Librispeech-Korpus und bauen drei verschiedene Trainingskorpora auf, die nur den Anteil der Daten variieren, die von jeder Geschlechterkategorie produziert werden. Wir stellen fest, dass unser System, wenn es insgesamt robust gegen das Gleichgewicht der Geschlechter oder Ungleichgewichte in den Trainingsdaten ist, dennoch von der Angemessenheit zwischen den in den Trainings- und Testsets anwesenden Personen abhängt.</abstract_de>
      <abstract_id>Dalam kertas ini kita mempertanyakan dampak dari persembahan jenis dalam data latihan tentang prestasi sistem ASR dari akhir ke akhir. Kami menciptakan eksperimen berdasarkan Librispeech corpus dan membangun 3 korpora latihan berbeda yang hanya berbeda proporsi data yang diproduksi oleh setiap kategori jenis. Kita memperhatikan bahwa jika sistem kita secara umum kuat untuk keseimbangan jenis atau ketidakseimbangan dalam data pelatihan, hal itu tetap tergantung dari keperluan antara individu yang hadir dalam set pelatihan dan tes.</abstract_id>
      <abstract_ko>본고에서 우리는 교육 데이터의 성별 대표성이 전체 ASR 시스템 성능에 미치는 영향에 대해 의문을 제기했다.우리는 Librispeech 자료 라이브러리를 토대로 하나의 실험을 만들었고 3개의 서로 다른 훈련 자료 라이브러리를 구축하여 각 성별 유형에 따라 발생하는 데이터 비율만 바꾸었다.만약에 우리 시스템이 교육 데이터 중의 성별 균형이나 불균형에 대해 전체적으로 안정적이라면, 그것은 여전히 교육과 테스트가 집중된 개체 간의 충분성에 달려 있다.</abstract_ko>
      <abstract_fa>در این کاغذ ما تحت تاثیر نمایش جنسی در داده های آموزش روی انجام یک سیستم ASR پایان و پایان سوال می کنیم. ما یک آزمایش را بر اساس کورپوس لیبریسپیچ ایجاد می کنیم و سه شرکت آموزش متفاوت را ساختیم که تنها نسبت داده های توسط هر گروه جنسی تغییر می دهند. ما مشاهده می کنیم که اگر سیستم ما در کل با تعادل جنسی یا نابرابری در داده های آموزش، بستگی به مناسب بین فردی که در مجموعه آموزش و آزمایش وجود دارند بستگی دارد.</abstract_fa>
      <abstract_da>I denne artikel sætter vi spørgsmålstegn ved virkningen af kønsrepræsentation i uddannelsesdata på resultaterne af et end-to-end ASR-system. Vi skaber et eksperiment baseret på Librispeech-korpuset og bygger 3 forskellige træningskorpuser, der kun varierer andelen af data produceret af hver kønskategori. Vi bemærker, at hvis vores system generelt er robust i forhold til kønsbalancen eller uligevægten i uddannelsesdata, er det ikke desto mindre afhængigt af tilstrækkeligheden mellem de personer, der deltager i uddannelses- og testsættet.</abstract_da>
      <abstract_bg>В настоящата статия се поставя под въпрос въздействието на представителството на половете в данните за обучението върху ефективността на цялостна система за АСР. Създаваме експеримент на базата на корпуса и изграждаме 3 различни корпуса за обучение, вариращи само пропорцията на данните, произведени от всяка полова категория. Наблюдаваме, че ако нашата система е като цяло здрава за баланса между половете или дисбаланса в данните за обучение, тя все пак зависи от адекватността между лицата, присъстващи в комплектите за обучение и тестване.</abstract_bg>
      <abstract_af>In hierdie papier vra ons die vloek van seuns voorstelling in onderwerp data op die prestasie van 'n einde-tot-einde ASR stelsel. Ons skep 'n eksperiment gebaseer op die Librispeech corpus en bou 3 verskillende onderwerp korpora wat net die proporsie van data wat deur elke seunskategorie geproduseer is. Ons aanhou dat as ons stelsel heeltemal kragtig is tot die seunsbalanse of onbalanse in onderwerp data, is dit tog afhanklik van die adekuasie tussen die individuele wat in die onderwerp en toets is.</abstract_af>
      <abstract_sw>Katika karatasi hii tunahoji athari ya uwakilishi wa jinsia katika mafunzo ya data kuhusu utendaji wa mfumo wa ASR wa mwisho wa mwisho. Tunaitengeneza jaribio linalohusu makampuni ya Librispeech na kujenga kampuni tatu tofauti ya mafunzo yanatofautiana tu kwa kiwango cha data kilichotengenezwa na kila aina ya jinsia. Tunaona kwamba kama mfumo wetu umekuwa umevurugwa kwa usawa wa jinsia au ukosefu wa usawa katika data za mafunzo, hata hivyo ni kutegemea usawa kati ya watu waliopo katika seti za mafunzo na majaribio.</abstract_sw>
      <abstract_tr>Bu kagyzda biz jentiller täsirini ASR sistemasynyň soňky we soňky sistemasynyň üstünliklerine görkezmelerinde soraglaýarys. Librispeech korpusyna daýan ýan bir deney bejerdik we 3 dürli okuwçy korpoýasyny diňe her jens kategoriýasy tarapyndan üretilen berýän maglumatyň döwletlerini üýtgedik. Eğer sistemamyz gelişme bergilerinde jentiller dengisligine ýa-da eşitmänligine ýok bolsa, bu durum okuwçylygda we synagda bulunan adamlaryň arasyndaky ýerlikhedigine baglanýar.</abstract_tr>
      <abstract_hy>In this paper we question the impact of gender representation in training data on the performance of an end-to-end ASR system.  Մենք ստեղծում ենք մի փորձ, որը հիմնված է գրադարանի կորպոսի վրա և կառուցում ենք 3 տարբեր ուսուցման կորպոռներ, որոնք տարբերվում են միայն յուրաքանչյուր սեռի կատեգորիայի կողմից ստացված տվյալ Մենք նկատում ենք, որ եթե մեր համակարգը ընդհանուր առմամբ ուժեղ է գենդերային հավասարակշռության կամ կրթության տվյալների անհավասարակշռության համար, այն այնուամենայնիվ կախված է կրթության և փորձարկումների համակարգերի միջև գտնվող անհա</abstract_hy>
      <abstract_az>Bu kańüńĪtda, ASR sisteminin sonuna q…ôd…ôr t…ôhsil edilm…ôsi bar…ôsind…ô cins g√∂st…ôricisinin t…ôsiri bar…ôsind…ô sorńüu-sual edirik. Librispeech korpusuna dayanan bir eksperiment yaradńĪrńĪq v…ô 3 m√ľxt…ôlif t…ôhsil korporasńĪ yaradńĪrńĪq, yalnńĪz h…ôr cins kategoriyasńĪndan √ľr…ôkl…ôn…ôn m…ôlumatlarńĪn proporsiyasńĪnńĪ d…ôyiŇüdirir. ∆Źg…ôr sistemimiz t…ôhsil m…ôlumatlarńĪnda cins balanńĪna v…ô ya m√ľqabiliyy…ôtin…ô istinad edirs…ô, bu t…ôhsil v…ô sńĪnama qurmaqlarńĪnda olan kiŇüil…ôr arasńĪndakńĪ adeqlńĪńüa bańülńĪ olar.</abstract_az>
      <abstract_sq>Në këtë letër ne dyshojmë në ndikimin e përfaqësimit të gjinisë në trajnimin e të dhënave mbi performancën e një sistemi ASR nga fundi në fund. Ne krijojmë një eksperiment bazuar në Librispeech corpus dhe ndërtojmë 3 korpra të ndryshme trajnimi që ndryshojnë vetëm proporcionin e të dhënave të prodhuara nga çdo kategori gjinore. Ne vëzhgojmë se në qoftë se sistemi ynë është përgjithësisht i fortë ndaj ekuilibrit gjinorë apo disbalancit në të dhënat e trainimit, ai megjithatë varet nga përshtatja midis individëve të pranishëm në grupet e trainimit dhe testimit.</abstract_sq>
      <abstract_am>በዚህ ካላት ውስጥ የሴት መልዕክት የሥርዓት አካባቢ ዳታዎችን ለመግለጥ የASR ስርዓት መጨረሻ ውጤት ማድረግ ጠይቃለን፡፡ የሊብሪስpeክ ኮፕስስ በመሠረት ላይ ፈተናን እናደርጋለን፣ የሥርዓት ክፍል የሚደረገውን የዳታ ክፍል ብቻ ይለያያሉ፡፡ ሲስተማርነታችን በሙያዊ ሚዛን ወይም በማስተካከል በማስተካከል ቢሆን፣ ነገር ግን በትምህርት እና በመፈተና ማሰናከል በሚገኙት ሰዎች መካከል በኩል የታመነ ነው፡፡</abstract_am>
      <abstract_bn>এই কাগজটিতে আমরা লিঙ্গ প্রতিনিধিত্বের প্রভাবের প্রশিক্ষণের তথ্য প্রশিক্ষণের প্রশিক্ষা করছি যে শেষ পর্যন্ত এসার সিস আমরা লিব্রিস্পেচ কোর্পাসের উপর ভিত্তি করে একটি পরীক্ষা তৈরি করি এবং তিনটি ভিন্ন প্রশিক্ষণ কোর্পোরা তৈরি করে প্রত্যেক লিঙ্গ বিভি আমরা দেখছি যে যদি আমাদের সিস্টেম প্রশিক্ষণের তথ্যে লিঙ্গ ব্যবস্থা বা বৈষম্য নিয়ে যায়, তবে প্রশিক্ষণ ও পরীক্ষা সেটে উপস্থিত ব্যক্তিদের মধ্যে</abstract_bn>
      <abstract_bs>U ovom papiru sumnjamo na učinak predstavljanja spola u podacima obuke o učinkovitosti sustava ASR-a do kraja. Napravili smo eksperiment baziran na Librispeech korpusu i izgradili 3 različite trening korporacije koje se razlikuju samo proporcija podataka proizvođenih od svake kategorije spola. Primijetimo da, ako je naš sistem ukupno jak na ravnotežu spola ili neravnotežan u podacima obuke, ipak je ovisan o adekvatnosti između pojedinaca prisutnih u obuci i testiranju.</abstract_bs>
      <abstract_ca>En aquest paper qüestionem l'impacte de la representació de gènere en les dades d'entrenament sobre el rendiment d'un sistema ASR de final a final. Creem un experiment basat en el Librispeech corpus i construim 3 corpores de formació diferents que només varian la proporció de dades produïdes per cada categoria de gènere. Observem que si el nostre sistema és en general robust per al equilibri de gènere o desequilibri en les dades d'entrenament, depèn encara de l'adequació entre els individus presents en els grups d'entrenament i prova.</abstract_ca>
      <abstract_cs>V tomto článku se zabýváme vlivem reprezentace žen a mužů v údajích o vzdělávání na výkonnost end-to-end ASR systému. Vytvoříme experiment založený na korpusu Librispeech a vytvoříme tři různé tréninkové korpusy, které se liší pouze podílem dat produkovaných každou genderovou kategorií. Pozorujeme, že pokud je náš systém celkově robustní vůči rovnováze žen a mužů nebo nerovnováze v údajích o tréninku, je nicméně závislý na přiměřenosti mezi jednotlivci přítomnými ve výcvikových a testovacích sadách.</abstract_cs>
      <abstract_fi>Tässä artikkelissa pohdimme sukupuolten edustuksen vaikutusta koulutustiedoissa kokonaisvaltaisen ASR-järjestelmän suorituskykyyn. Luomme Librispeech-korpuseen perustuvan kokeilun ja rakennamme kolme erilaista koulutuskorpusta, jotka vaihtelevat vain kunkin sukupuolen tuottaman tiedon osuutta. Havaitsemme, että jos järjestelmämme on yleisesti ottaen vankka sukupuolten tasapainon tai koulutustietojen epätasapainon suhteen, se on kuitenkin riippuvainen koulutus- ja testaussarjoissa olevien henkilöiden riittävyydestä.</abstract_fi>
      <abstract_et>Käesolevas dokumendis küsitakse soolise esindatuse mõju koolitusandmetes täieliku ASR-süsteemi tulemuslikkusele. Loome Librispeechi korpusel põhineva eksperimendi ja ehitame kolm erinevat koolituskorporat, mis varieerivad ainult iga sookategooria andmete osakaalu. Me täheldame, et kui meie süsteem on üldiselt tugev soolise tasakaalu või koolitusandmete tasakaalustamatuse suhtes, sõltub see siiski koolitus- ja katsekomplektides osalevate isikute piisavusest.</abstract_et>
      <abstract_jv>Nang kuwi iki, awake awake dhéwé ngejane perusahaan langkung werak-wong liya neng data nggawe barang nggawe sistem ASR murah berlakkat sabanjuré. Awak dhéwé nggawe éntuk mulai perbudhakan podho suku kelompok Library Awak dhéwé ngerti, nek sistem awak dhéwé nggawe sistem iki luwih nggawe gerakan kanggo nik nglanggar kuwi duluran, kuwi mau, mengko iso nguasai perusahaan langgar-sistem sing gak nggawe gerakan sak kudu, nik nggawe nguasai perusahaan wong-wong iki dadi susahe sak</abstract_jv>
      <abstract_sk>V prispevku postavljamo vprašanje o vplivu zastopanosti spolov v podatkih o usposabljanju na uspešnost celovitega sistema ASR. Ustvarimo eksperiment na osnovi korpusa Librispeech in zgradimo tri različne korpuse usposabljanja, ki spreminjajo le delež podatkov, ki jih proizvaja posamezna spolna kategorija. Ugotavljamo, da je naš sistem na splošno trden za uravnoteženost spolov ali neravnovesje v podatkih o usposabljanju, kljub temu odvisen od ustreznosti posameznikov, prisotnih v sklopih usposabljanja in testiranja.</abstract_sk>
      <abstract_ha>Ga wannan takardan da Muke tambayar ta wajen muhallin jini cikin shirin data a kan aikin aikin tsarin na ƙari-zuwa-ƙari. Munã sami jarrabo a kan karatun Librispech kuma Muke samar da firma 3 dabam-dabam na dabam-tarakin data da aka samar da kõwace category. Muna gani cewa, idan na sami tsarinmu zuwa balancin jini ko kuma ba da balanci a cikin data na tattalin, sai yana dõgara da adadi a tsakanin mutane da ke cikin shirin da ke jarraba.</abstract_ha>
      <abstract_he>בעיתון הזה אנו מפקפקים בהשפעה של ייצוג מין במידע האימוני על ההופעה של מערכת ASR סוף-סוף. אנו יוצרים ניסוי מבוסס על הקורפוס של Librispeech ולבנות 3 גופות אימונים שונות שונות רק את המספר של נתונים שנוצרים על ידי כל קטגוריה מינית. אנו שומרים על כך שאם המערכת שלנו חזקה באופן כללי לאיזון מין או אי-איזון בנתונים האימונים, היא עדיין תלויה בהתאם בין האדם הנוכחים במערכות האימונים ובניסויים.</abstract_he>
      <abstract_fil>Sa papiro na ito ay aming tinatanong ang impaktuo ng pang-aral na reprezentasyon sa pananalita ng data sa pag-aaral sa gawain ng sistema ng end-to-end ASR. Naglalagay kami ng isang eksperimento na basag sa Librispeech corpus at nagtayo ng 3 ibang training corpora na nagkakaiba lamang ng proporsyon ng data na ginagawa ng bawat kategoriya ng lahi. Tinatanggap natin na kung ang ating sistema ay totoong matibay sa balanse ng lahi o imbalans sa mga datos ng pag-aaral, gayon ma'y ito'y dependant sa adequacy sa mga tao na nakaharap sa pag-aaral at pag-aaral.</abstract_fil>
      <abstract_bo>ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་གི་ཡིག་ཆའི་ནང་དུ་གུས་མེད་འཚོལ་བ་སྐྱེན་ཚོའི་གནོད་འཚོལ་གསུམ་སྟོན་པའི་གནས་སྟངས ང་ཚོས་Librispeech སྒེར་གྱི་གཙོ་སྟངས་དང་སྒྲིག་འཛུགས་གྱི་ཚད་རྩིས་ཐོག་ལས་བརྟན་དཔྱད་བྱས་པའི་སྒེར་གྱི་ཚད་རྐྱེན་སྒྲིག་མཁན་གསུམ་ ང་ཚོའི་མ་ལག་གི་རྐྱེན་ཚད་ལྡན་སྒྲིག་ཐད་ཀར་བ་ཡིན་ན་མིན་ཐད་ཡོད་པས། གལ་སྲིད་རང་གི་མ་ལག་གི་རྐྱེན་ཚད་དང་བརྟག་དཔྱད་ནང་གི་ཚད་རྐྱེན་ཚད་</abstract_bo>
      </paper>
    <paper id="11">
      <title>Generating Gender Augmented Data for NLP<fixed-case>NLP</fixed-case></title>
      <author><first>Nishtha</first><last>Jain</last></author>
      <author><first>Maja</first><last>Popović</last></author>
      <author><first>Declan</first><last>Groves</last></author>
      <author><first>Eva</first><last>Vanmassenhove</last></author>
      <pages>93–102</pages>
      <abstract>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages. Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also due to unbalanced grammatical gender frequencies of inflected words. This type of <a href="https://en.wikipedia.org/wiki/Bias">bias</a> becomes more evident in generating conversational utterances where gender is not specified within the sentence, because most current NLP applications still work on a sentence-level context. As a step towards more inclusive NLP, this paper proposes an automatic and generalisable re-writing approach for short conversational sentences. The <a href="https://en.wikipedia.org/wiki/Rewriting">rewriting method</a> can be applied to sentences that, without <a href="https://en.wikipedia.org/wiki/Context_(language_use)">extra-sentential context</a>, have multiple equivalent alternatives in terms of gender. The method can be applied both for creating gender balanced outputs as well as for creating gender balanced training data. The proposed approach is based on a neural machine translation system trained to ‘translate’ from one gender alternative to another. Both the automatic and manual analysis of the approach show promising results with respect to the automatic generation of gender alternatives for conversational sentences in Spanish.</abstract>
      <url hash="552391e1">2021.gebnlp-1.11</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2de0cc30">2021.gebnlp-1.11.OptionalSupplementaryMaterial.pdf</attachment>
      <doi>10.18653/v1/2021.gebnlp-1.11</doi>
      <bibkey>jain-etal-2021-generating</bibkey>
      <pwccode url="https://github.com/awslabs/sockeye" additional="false">awslabs/sockeye</pwccode>
    <title_ar>توليد البيانات المعززة حسب الجنس من أجل البرمجة اللغوية العصبية</title_ar>
      <title_fr>Générer des données augmentées sur le genre pour la PNL</title_fr>
      <title_pt>Gerando dados de gênero aumentado para PNL</title_pt>
      <title_es>Generación de datos aumentados por género para la PNL</title_es>
      <title_ja>NLPのジェンダー拡張データの生成</title_ja>
      <title_ru>Формирование гендерных дополненных данных для NLP</title_ru>
      <title_ukr>Створення гендерно доповнених даних для NLP</title_ukr>
      <title_ga>Sonraí Méadaithe Inscne a Ghiniúint do NLP</title_ga>
      <title_zh>为 NLP 生性别增数</title_zh>
      <title_hi>एनएलपी के लिए लिंग संवर्धित डेटा जनरेट करना</title_hi>
      <title_ka>Name</title_ka>
      <title_el>Δημιουργία δεδομένων ενισχυμένων φύλων για τη NLP</title_el>
      <title_hu>Nemek közötti kiterjesztett adatok generálása az NLP számára</title_hu>
      <title_it>Generare dati aumentati di genere per PNL</title_it>
      <title_kk>NLP үшін жалғыз шектелген деректер құрылуда</title_kk>
      <title_lt>Lyčių ir moterų padidintų NLP duomenų kūrimas</title_lt>
      <title_ms>Menjana Data Ditambah Gender untuk NLP</title_ms>
      <title_isl>Búa til kynaukna gögn fyrir NLP</title_isl>
      <title_mk>Генерирање на податоци зголемени за полот за NLP</title_mk>
      <title_no>Lagar generell augmentert data for NLP</title_no>
      <title_ml>NLP-നുള്ള ജെന്റര്‍ ആഗ്മെന്റ് ഡേറ്റാ ഉണ്ടാക്കുന്നു</title_ml>
      <title_mt>Il-Ġenerazzjoni ta’ Dejta miżjuda dwar is-Sessi għall-NLP</title_mt>
      <title_ro>Generarea datelor extinse de gen pentru PNL</title_ro>
      <title_pl>Generowanie danych zwiększonych płci dla NLP</title_pl>
      <title_sv>Generera könsutökade data för NLP</title_sv>
      <title_si>Name</title_si>
      <title_ta>NLP க்கான பெண் ஒதுக்கப்பட்ட தரவை உருவாக்குகிறது</title_ta>
      <title_sr>Generirajući povećane podatke za NLP</title_sr>
      <title_ur>Name</title_ur>
      <title_so>Generating data of gender Augmented data for NLP</title_so>
      <title_mn>NLP-ийн Gender Augmented Data-г үүсгэх</title_mn>
      <title_uz>Name</title_uz>
      <title_vi>Tạo dữ liệu tăng cường Gondor cho Njala.</title_vi>
      <title_hr>Generiranje povećanih podataka za NLP</title_hr>
      <title_bg>Генериране на увеличени данни за пола за НЛП</title_bg>
      <title_nl>Gender Augmented Data genereren voor NLP</title_nl>
      <title_da>Generering af kønsforøgede data for NLP</title_da>
      <title_ko>NLP에 대한 성별 강화 데이터 생성</title_ko>
      <title_id>Membuat Data Ditambah Gender untuk NLP</title_id>
      <title_fa>ایجاد داده‌های افزایش جنسی برای NLP</title_fa>
      <title_sw>Kutengeneza data kwa NLP</title_sw>
      <title_de>Generierung geschlechtsspezifischer Daten für NLP</title_de>
      <title_sq>Gjenerimi i të dhënave të rritura për gjirin për NLP</title_sq>
      <title_am>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</title_am>
      <title_az>NLP üçün Gender Augmented Data icat edilir</title_az>
      <title_tr>NLP üçin Genjer Aýtget Maglumaty Dönülýär</title_tr>
      <title_af>Genereer Gender Augmented Data vir NLP</title_af>
      <title_bn>NLP এর জন্য লেন্ডার অগমেন্ট ডাটা তৈরি করা হচ্ছে</title_bn>
      <title_ca>Generating Gender Augmented Data for NLP</title_ca>
      <title_cs>Generování dat rozšířených pohlavím pro NLP</title_cs>
      <title_et>Soolise võrdõiguslikkuse suurendatud andmete loomine uue tööprogrammi jaoks</title_et>
      <title_hy>ՆԼՊ-ի համար ստեղծված գենդերային աճված տվյալներ</title_hy>
      <title_fi>Sukupuolten lisätyn tiedon luominen uutta ohjelmaa varten</title_fi>
      <title_bs>Generiranje povećanih podataka za NLP</title_bs>
      <title_sk>Ustvarjanje povečanih podatkov o spolu za NLP</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>NLP ལ་སྤྱོད་ཀྱི་Gender Augmented Data་གསར་བཟོ་བཞིན་པ</title_bo>
      <title_fil>Naglalagay ng Gender Augmented Data para sa NLP</title_fil>
      <title_he>Generating Gender Augmented Data for NLP</title_he>
      <title_jv>print operation status</title_jv>
      <abstract_ar>التحيز بين الجنسين أمر شائع الحدوث في التطبيقات القائمة على البرمجة اللغوية العصبية ، خاصة في اللغات المتأثرة بالجنس. يمكن أن يظهر التحيز من خلال ارتباطات بعض الصفات والأسماء الحية مع الجنس الطبيعي للمراجع ، ولكن أيضًا بسبب الترددات النحوية غير المتوازنة بين الجنسين للكلمات المنحرفة. يصبح هذا النوع من التحيز أكثر وضوحًا في توليد أقوال محادثة حيث لا يتم تحديد الجنس في الجملة ، لأن معظم تطبيقات البرمجة اللغوية العصبية الحالية لا تزال تعمل على سياق مستوى الجملة. كخطوة نحو البرمجة اللغوية العصبية الأكثر شمولاً ، تقترح هذه الورقة نهج إعادة الكتابة التلقائي والقابل للتعميم لجمل المحادثة القصيرة. يمكن تطبيق طريقة إعادة الكتابة على الجمل التي تحتوي على بدائل متعددة مكافئة من حيث الجنس ، بدون سياق أكثر حساسية. يمكن تطبيق الطريقة لإنشاء مخرجات متوازنة بين الجنسين وكذلك لإنشاء بيانات تدريب متوازنة بين الجنسين. يعتمد النهج المقترح على نظام ترجمة آلي عصبي مدرب على "الترجمة" من بديل جنساني إلى آخر. يُظهر كل من التحليل الآلي واليدوي للنهج نتائج واعدة فيما يتعلق بالإنشاء التلقائي للبدائل الجنسانية لجمل المحادثة باللغة الإسبانية.</abstract_ar>
      <abstract_fr>Les préjugés sexistes sont fréquents dans les applications basées sur la PNL, particulièrement dans les langues influencées par le genre. Les biais peuvent apparaître par l'association de certains adjectifs et noms animés avec le genre naturel des référents, mais aussi par des fréquences grammaticales de genre déséquilibrées des mots fléchis. Ce type de biais devient plus évident dans la génération d'énoncés conversationnels où le sexe n'est pas précisé dans la phrase, car la plupart des applications de PNL actuelles fonctionnent toujours dans un contexte au niveau de la phrase. Comme étape vers une PNL plus inclusive, cet article propose une approche de réécriture automatique et généralisable pour les phrases conversationnelles courtes. La méthode de réécriture peut être appliquée à des phrases qui, sans contexte extra-sententiel, ont de multiples alternatives équivalentes en termes de genre. La méthode peut être appliquée à la fois pour créer des résultats équilibrés entre les sexes ainsi que pour créer des données de formation équilibrées entre les sexes. L'approche proposée est basée sur un système de traduction automatique neuronale formé pour « traduire » d'une alternative sexuelle à une autre. L'analyse automatique et manuelle de l'approche montre des résultats prometteurs en ce qui concerne la génération automatique d'alternatives de genre pour les phrases conversationnelles en espagnol.</abstract_fr>
      <abstract_ja>ジェンダーバイアスは、特にジェンダーに影響された言語で顕著な、NLPベースのアプリケーションで頻繁に発生します。 偏見は、特定の形容詞とアニメーション名詞と参照の自然な性別との関連を介して現れることがありますが、それはまた、屈折した単語の不均衡な文法的性別の頻度に起因します。 現在のほとんどのNLPアプリケーションはまだ文レベルのコンテキストで動作しているため、このタイプのバイアスは、文内で性別が指定されていない会話の発話を生成する上でより明らかになります。 より包括的なNLPへの一歩として、この論文は、短い会話文のための自動的で一般化可能な書き換えアプローチを提案している。 この書き換え方法は、超文脈なしで、性別に関して複数の同等の代替案を有する文章に適用することができる。 この方法は、ジェンダーバランスのアウトプットを作成するためと、ジェンダーバランスのトレーニングデータを作成するための両方に適用できます。 提案されたアプローチは、ある性別の代替案から別の性別への「翻訳」を行うように訓練されたニューラル機械翻訳システムに基づいている。 アプローチの自動分析と手動分析の両方で、スペイン語の会話文のための性別代替案の自動生成に関して有望な結果が示されています。</abstract_ja>
      <abstract_pt>O viés de gênero é uma ocorrência frequente em aplicativos baseados em PNL, especialmente pronunciado em idiomas com flexão de gênero. O viés pode aparecer por meio de associações de certos adjetivos e substantivos animados com o gênero natural dos referentes, mas também devido a frequências de gênero gramatical desequilibradas de palavras flexionadas. Esse tipo de viés se torna mais evidente na geração de enunciados conversacionais em que o gênero não é especificado na frase, porque a maioria dos aplicativos de PNL atuais ainda funcionam em um contexto de nível de frase. Como um passo em direção à PNL mais inclusiva, este artigo propõe uma abordagem de reescrita automática e generalizável para frases curtas de conversação. O método de reescrita pode ser aplicado a sentenças que, sem contexto extra-sentencial, possuem múltiplas alternativas equivalentes em termos de gênero. O método pode ser aplicado tanto para criar resultados com equilíbrio de gênero quanto para criar dados de treinamento com equilíbrio de gênero. A abordagem proposta é baseada em um sistema de tradução automática neural treinado para 'traduzir' de uma alternativa de gênero para outra. Tanto a análise automática quanto a manual da abordagem mostram resultados promissores no que diz respeito à geração automática de alternativas de gênero para frases de conversação em espanhol.</abstract_pt>
      <abstract_es>El sesgo de género es frecuente en las solicitudes basadas en PNL, especialmente pronunciado en los idiomas con inflexión de género. El sesgo puede aparecer a través de asociaciones de ciertos adjetivos y sustantivos animados con el género natural de los referentes, pero también debido a las frecuencias gramaticales de género desequilibradas de las palabras flexionadas. Este tipo de sesgo se hace más evidente al generar expresiones conversacionales donde el género no se especifica dentro de la oración, porque la mayoría de las aplicaciones actuales de PNL todavía funcionan en un contexto a nivel de oración. Como un paso hacia una PNL más inclusiva, este artículo propone un enfoque de reescritura automático y generalizable para frases conversacionales cortas. El método de reescritura se puede aplicar a oraciones que, sin contexto extrasensencial, tienen múltiples alternativas equivalentes en términos de género. El método se puede aplicar tanto para crear productos equilibrados de género como para crear datos de capacitación equilibrados entre hombres y mujeres. El enfoque propuesto se basa en un sistema de traducción automática neuronal capacitado para «traducir» de una alternativa de género a otra. Tanto el análisis automático como el manual del enfoque muestran resultados prometedores con respecto a la generación automática de alternativas de género para frases conversacionales en español.</abstract_es>
      <abstract_ru>Гендерная предвзятость является частым явлением в приложениях на основе NLP, особенно выраженным в языках, учитывающих гендерные аспекты. Предвзятость может проявляться через ассоциации определенных прилагательных и анимированных существительных с естественным родом референтов, а также из-за несбалансированных грамматических гендерных частот переливающихся слов. Этот тип предвзятости становится более очевидным при генерации разговорных высказываний, где пол не указан в предложении, потому что большинство современных приложений NLP все еще работают на уровне предложения. В качестве шага в направлении более инклюзивного NLP, в этой статье предлагается автоматический и обобщаемый подход к переписыванию коротких разговорных предложений. Метод переписывания может быть применен к предложениям, которые без внесудебного контекста имеют несколько эквивалентных альтернатив с точки зрения пола. Этот метод может применяться как для подготовки сбалансированных с гендерной точки зрения материалов, так и для подготовки сбалансированных с гендерной точки зрения данных о профессиональной подготовке. Предлагаемый подход основан на нейронной системе машинного перевода, обученной «переводить» с одной гендерной альтернативы на другую. Как автоматический, так и ручной анализ подхода показывает многообещающие результаты в отношении автоматического генерирования гендерных альтернатив для разговорных предложений на испанском языке.</abstract_ru>
      <abstract_ukr>Гендерна упередженість є частим явищем у програмах на основі НЛП, особливо вираженим у мовах, що враховують гендерні аспекти. Упередження може з 'являтися через асоціації певних прикметників та анімаційних іменників з природною статтю референтів, а також через незбалансовані граматичні гендерні частоти ввігнутих слів. Цей тип упередження стає більш очевидним при генеруванні розмовних висловлювань, де стать не вказана в реченні, оскільки більшість сучасних програм NLP все ще працюють на контексті на рівні речення. Як крок до більш інклюзивного NLP, цей документ пропонує автоматичний та узагальнений підхід до переписування коротких розмовних речень. Метод переписування може бути застосований до речень, які без екстрасенсного контексту мають кілька еквівалентних альтернатив з точки зору статі. Метод може застосовуватися як для створення ґендерно збалансованих результатів, так і для створення ґендерно збалансованих навчальних даних. Запропонований підхід базується на нейронній системі машинного перекладу, навченій «перекладати» з однієї гендерної альтернативи на іншу. Як автоматичний, так і ручний аналіз підходу показує перспективні результати щодо автоматичної генерації гендерних альтернатив для розмовних речень іспанською мовою.</abstract_ukr>
      <abstract_ga>Is minic a tharlaíonn laofacht inscne i bhfeidhmchláir atá bunaithe ar NLP, go háirithe i dteangacha inscne-inscne. Is féidir le claonadh a bheith le feiceáil trí aidiachtaí áirithe a chomhcheangal agus ainmfhocail a bheochan le hinscne nádúrtha na dtagairtí, ach freisin de bharr minicíochtaí inscne neamhchothromaithe gramadaí na bhfocal infhillte. Éiríonn an cineál seo claonta níos soiléire maidir le cainteanna comhrá a ghiniúint nuair nach bhfuil inscne sonraithe san abairt, toisc go n-oibríonn formhór na bhfeidhmchlár NLP reatha fós ar chomhthéacs leibhéal na habairte. Mar chéim i dtreo NLP níos cuimsithí, molann an páipéar seo cur chuige uathoibríoch agus inghinearálta athscríobh le haghaidh abairtí gearra comhrá. Is féidir an modh athscríobh a chur i bhfeidhm ar abairtí a bhfuil roghanna iolracha coibhéiseacha acu i dtéarmaí inscne, gan comhthéacs seachbhreithe. Is féidir an modh a chur i bhfeidhm chun aschuir chothromaithe inscne a chruthú chomh maith le sonraí oiliúna cothrom inscne a chruthú. Tá an cur chuige atá beartaithe bunaithe ar chóras néar-aistriúcháin meaisín atá oilte chun `aistriú' ó mhalairt inscne amháin go ceann eile. Léiríonn an anailís uathoibríoch agus láimhe ar an gcur chuige araon torthaí gealltanais maidir le giniúint uathoibríoch roghanna inscne d’abairtí comhrá sa Spáinnis.</abstract_ga>
      <abstract_zh>性别偏见于NLP应用程序之中,尤在变化之言明矣。 偏见形容词之关联,动画名词之自然性别,亦或屈折不平语法性别频率。 偏见句中未指定语言明白,多NLP应用程序犹在句上下文中。 向更具包容性NLP出一步,本文发一种自广的重写法,用于简短的会话句。 重写法可施于无外感性上下文之句,此句于性别多等效代方案。 其法既可以建性别平衡之产,亦可以建性别平衡之培训数。 所立之法,盖一神经机器翻译系统,当系统训练,可以一性别代方案"译"至一性别代方案。 自与手动析,皆见于西班牙语会言自生性别代项者也。</abstract_zh>
      <abstract_hi>लिंग पूर्वाग्रह एनएलपी-आधारित अनुप्रयोगों में एक लगातार घटना है, विशेष रूप से लिंग-inflected भाषाओं में स्पष्ट है। पूर्वाग्रह कुछ विशेषणों के संघों के माध्यम से दिखाई दे सकता है और संदर्भों के प्राकृतिक लिंग के साथ एनिमेट संज्ञाएं, लेकिन अंतर्निहित शब्दों की असंतुलित व्याकरणिक लिंग आवृत्तियों के कारण भी। इस प्रकार का पूर्वाग्रह संवादात्मक कथन उत्पन्न करने में अधिक स्पष्ट हो जाता है जहां लिंग वाक्य के भीतर निर्दिष्ट नहीं किया जाता है, क्योंकि अधिकांश वर्तमान एनएलपी एप्लिकेशन अभी भी वाक्य-स्तर के संदर्भ पर काम करते हैं। अधिक समावेशी एनएलपी की ओर एक कदम के रूप में, यह पेपर छोटे संवादी वाक्यों के लिए एक स्वचालित और सामान्यीकृत पुन: लेखन दृष्टिकोण का प्रस्ताव करता है। पुनर्लेखन विधि को उन वाक्यों पर लागू किया जा सकता है, जो अतिरिक्त-संवेदनशील संदर्भ के बिना, लिंग के संदर्भ में कई समकक्ष विकल्प हैं। विधि को लिंग संतुलित आउटपुट बनाने के साथ-साथ लिंग संतुलित प्रशिक्षण डेटा बनाने के लिए दोनों के लिए लागू किया जा सकता है। प्रस्तावित दृष्टिकोण एक तंत्रिका मशीन अनुवाद प्रणाली पर आधारित है जो एक लिंग विकल्प से दूसरे लिंग विकल्प से 'अनुवाद' करने के लिए प्रशिक्षित है। दृष्टिकोण के स्वचालित और मैनुअल विश्लेषण दोनों स्पेनिश में संवादी वाक्यों के लिए लिंग विकल्पों की स्वचालित पीढ़ी के संबंध में आशाजनक परिणाम दिखाते हैं।</abstract_hi>
      <abstract_el>Η προκατάληψη του φύλου είναι συχνή εμφάνιση σε εφαρμογές βασισμένες σε ΝΛΠ, ιδιαίτερα έντονη σε γλώσσες με τάση φύλου. Η προκατάληψη μπορεί να εμφανιστεί μέσω συσχετισμών ορισμένων επίθετων και ζωντανών ουσιαστικών με το φυσικό φύλο των αναφερθέντων, αλλά και λόγω ανισορροπημένων γραμματικών συχνοτήτων φύλου των διεστραμμένων λέξεων. Αυτός ο τύπος προκατάληψης γίνεται πιο εμφανής στη δημιουργία προφορών συνομιλίας όπου το φύλο δεν καθορίζεται μέσα στην πρόταση, επειδή οι περισσότερες τρέχουσες εφαρμογές εξακολουθούν να λειτουργούν σε ένα πλαίσιο σε επίπεδο πρότασης. Ως βήμα προς την κατεύθυνση της πιο περιεκτικής NLP, η παρούσα εργασία προτείνει μια αυτόματη και γενικευμένη προσέγγιση επαναγραφής για σύντομες προτάσεις συζήτησης. Η μέθοδος επαναγραφής μπορεί να εφαρμοστεί σε προτάσεις που, χωρίς εξωγήινο πλαίσιο, έχουν πολλαπλές ισοδύναμες εναλλακτικές από άποψη φύλου. Η μέθοδος μπορεί να εφαρμοστεί τόσο για τη δημιουργία ισορροπημένων αποτελεσμάτων μεταξύ των φύλων όσο και για τη δημιουργία ισορροπημένων δεδομένων κατάρτισης μεταξύ των φύλων. Η προτεινόμενη προσέγγιση βασίζεται σε ένα νευρωνικό σύστημα μηχανικής μετάφρασης εκπαιδευμένο να "μεταφράσει" από το ένα φύλο εναλλακτική σε το άλλο. Τόσο η αυτόματη όσο και η χειρωνακτική ανάλυση της προσέγγισης δείχνουν ελπιδοφόρα αποτελέσματα όσον αφορά την αυτόματη δημιουργία εναλλακτικών λύσεων φύλου για συζητήσεις στα ισπανικά.</abstract_el>
      <abstract_hu>A nemi elfogultság gyakori előfordulás az NLP alapú alkalmazásokban, különösen a nemi befolyással rendelkező nyelveken. A kötések bizonyos melléknévek asszociációjával és főneveket animálhatnak a referenciák természetes nemével, de az inflektált szavak kiegyensúlyozatlan nyelvtani nemi frekvenciájának köszönhetően is. Ez a fajta elfogultság egyre nyilvánvalóbbá válik a beszélgetési kimondások kialakításában, ahol a nemet nem határozzák meg a mondatban, mivel a legtöbb jelenlegi NLP alkalmazás még mindig mondatszintű kontextusban működik. Az inkluzívabb NLP felé vezető lépésként ez a tanulmány egy automatikus és általánosítható újraírási megközelítést javasol rövid beszélgetési mondatokhoz. Az újraírási módszer alkalmazható olyan mondatokra, amelyek érzékenységen kívüli kontextus nélkül több egyenértékű alternatívával rendelkeznek a nemek szempontjából. A módszer alkalmazható mind a nemek közötti kiegyensúlyozott eredmények létrehozására, mind a nemek közötti kiegyensúlyozott képzési adatok létrehozására. A javasolt megközelítés egy neurális gépi fordítási rendszeren alapul, amely képzett arra, hogy "fordítsa" az egyik nemi alternatívából a másikba. A megközelítés automatikus és manuális elemzése ígéretes eredményeket mutat a spanyol nyelvű nemi alternatívák automatikus generálása tekintetében.</abstract_hu>
      <abstract_isl>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages.  Bias getur komið fram með tengslum ákveðinna viðbótarlyfja og hreyft nefn við náttúrulegt kyn viðbótarlyfja, en einnig vegna ójafnvægilegrar tíðni kynþáttar orða. Þessi tegund tilhneigingar verður augljósari við a ð búa til samtalstjórnir þar sem kyn er ekki tilgreind í setningunni, þar sem flestar núverandi NLP umsóknir vinna enn á tengslum við setningastærð. Sem skref í átt a ð fullnægjandi NLP leggur þessi pappír fram sjálfvirka og almenna endurskriftafræði fyrir stutta samtalssetningar. Aðferð við endurskrift er hægt að nota á setningar sem, án viðbótarsetninga, hafa margar jafngildar aðferðir hvað varðar kyn. Aðferðina er hægt að nota bæði til að búa til jafnvægi útganga á kyni og til að búa til jafnvægi upplýsinga um þjálfun á kyni. The proposed approach is based on a neural machine translation system trained to `translate' from one gender alternative to another.  Bæði sjálfvirk og handvirk greining á aðferðinni sýnir loforðandi niðurstöður með tilliti til sjálfvirkrar myndunar kynslíkra valkosta fyrir samræmssetningar á spænsku.</abstract_isl>
      <abstract_it>Il pregiudizio di genere è un fenomeno frequente nelle applicazioni basate sulla PNL, particolarmente pronunciato nelle lingue influenzate dal genere. I bias possono comparire attraverso associazioni di alcuni aggettivi e animare sostantivi con il genere naturale dei referenti, ma anche a causa di frequenze grammaticali sbilanciate di genere delle parole flesse. Questo tipo di bias diventa più evidente nel generare espressioni conversazionali dove il genere non è specificato all'interno della frase, perché la maggior parte delle applicazioni NLP attuali funzionano ancora su un contesto a livello di frase. Come passo verso un PNL più inclusivo, questo articolo propone un approccio automatico e generalizzato di riscrittura per brevi frasi conversazionali. Il metodo di riscrittura può essere applicato a frasi che, senza contesto extra-sentimentale, hanno molteplici alternative equivalenti in termini di genere. Il metodo può essere applicato sia per creare risultati equilibrati tra i sessi sia per creare dati di formazione equilibrati tra i sessi. L'approccio proposto si basa su un sistema di traduzione automatica neurale addestrato a "tradurre" da un'alternativa di genere all'altra. Sia l'analisi automatica che manuale dell'approccio mostrano risultati promettenti rispetto alla generazione automatica di alternative di genere per frasi conversazionali in spagnolo.</abstract_it>
      <abstract_lt>Lyčių pusiausvyra dažnai pasireiškia taikant NLP, ypač dėl lyties kylančiomis kalbomis. Sužalojimas gali atsirasti asociacijomis tam tikrų priedų ir animacinių vardinių dalių su natūralia referentų lytimi, bet taip pat dėl nesubalansuoto gramatinio lyties dažnio sukeltų žodžių. Toks pusiausvyros pobūdis tampa akivaizdesnis sukuriant pokalbių išraiškas, kai lytis nenurodyta sakinyje, nes dauguma dabartinių NLP taikomųjų nuostatų vis dar veikia atsižvelgiant į sakinių lygį. Šiame dokumente siūlomas automatinis ir generalizuojamas trumpų pokalbių sakinių perskaičiavimo metodas, kaip žingsnis siekiant įtraukesnio NLP. Perrašymo metodas gali būti taikomas sakiniams, kurie be papildomų sakinių neturi daugelio lygiaverčių lyčių alternatyvų. Metodas gali būti taikomas sukuriant lyčių pusiausvyrą užtikrinančius rezultatus ir sukuriant lyčių pusiausvyrą užtikrinančius mokymo duomenis. Siūlomas metodas grindžiamas neurologiniu mašinų vertimo sistema, parengta „vertti“ iš vienos lyties alternatyvos į kitą. Automatinė ir rankinė metodo analizė rodo perspektyvius rezultatus, susijusius su automatine lyčių alternatyvų, skirtų kalbiniams sakiniams, kūrimu ispanų kalba.</abstract_lt>
      <abstract_mk>Порасната предрасуда е често појава во апликациите базирани на НЛП, особено изразени на јазиците предизвикани од полот. Бјас може да се појави преку асоцијации на одредени приклучоци и да се анімира имената со природниот пол на референтите, но исто така поради небалансираните граматички гендерски фреквенции на привлечени зборови. Овој тип на пристрасност станува поочигледен во генерирањето на разговорни изрази каде полот не е специфициран во реченицата, бидејќи повеќето актуелни апликации на НЛП сé уште работат на контекст на ниво на реченици. Како чекор кон повклучителна НЛП, овој весник предложува автоматски и генерализирачки пристап на повторно пишување за кратки разговорни реченици. Методот на препишување може да се примени на речениците кои, без екстра-реченцијален контекст, имаат повеќе еквивалентни алтернативи во поглед на полот. Методот може да се примени и за создавање на гендерски балансирани резултати, како и за создавање на гендерски балансирани податоци за обука. Предложениот пристап се базира на нервен машински преведувачки систем обучен за „ преведување “ од една полова алтернатива на друга. Автоматска и рачната анализа на пристапот покажува ветувачки резултати во однос на автоматската генерација на полски алтернативи за разговорни реченици на шпански.</abstract_mk>
      <abstract_ml>നെഎല്‍പി അടിസ്ഥാനമായ പ്രയോഗങ്ങളില്‍ സംഭവിക്കുന്ന സംഭവം, പ്രത്യേകിച്ച് പ്രസ്താവിക്കുന്ന ഭാഷകളില്‍ പ്രസ്താവിക ബിയാസുകള്‍ക്ക് സ്വാഭാവികമായ വാക്കുകളുടെ സ്വാഭാവികമായ സ്വഭാവികമായ വേദങ്ങളുടെ സ്വഭാവികമായ വേദങ്ങളുടെ സ്വഭാവികമായ സംഘത്തിലൂട വാക്കിനുള്ളില്‍ സംസാരിക്കാത്ത വാക്കുകള്‍ സൃഷ്ടിക്കുന്നതില്‍ ഈ തരം പിയാസ് വ്യക്തമായി തെളിയിക്കുന്നു. കാരണം ഇപ്പോഴത്തെ NLP പ എംഎല്‍പിയിലേക്ക് കൂടുതല്‍ ചേര്‍ന്നുകൊണ്ടിരിക്കുന്ന ഒരു പടിയായി ഈ പത്രത്തില്‍ സ്വയം സംസാരിക്കുന്ന വാക്കുകള്‍ക് വീണ്ടും എഴുതുന്ന രീതി പ്രയോഗിക്കുവാന്‍ സാധ്യതയുള്ള പുറത്തുകള്‍ സൃഷ്ടിക്കുന്നതിനും പ്രയോഗിക്കുന്ന രീതിയില്‍ പ്രയോഗിക്കുക പ്രൊദ്ദേശിക്കപ്പെട്ട നിര്‍ദ്ദേശിക്കപ്പെട്ട ഒരു ന്യൂറല്‍ യന്ത്രത്തിന്റെ പരിഭാഷ സിസ്റ്റം അടിസ്ഥാനത്താണു് സ്പാനിഷിലെ സംസാരിക്കുന്ന വാക്കുകള്‍ക്കുള്ള സ്വയം തലമുറയുടെ സ്വാതന്ത്ര്യത്തില്‍ സ്വാനിഷ്യന്‍ വാക്കുകളുടെ സ്വാതന്ത്ര</abstract_ml>
      <abstract_ms>Kebiasaan jenis adalah kejadian yang sering didalam aplikasi berasaskan NLP, terutama terdengar dalam bahasa yang disebabkan oleh jenis. Bias boleh muncul melalui persatuan beberapa adjektif dan animasikan nama dengan jenis alami referens, tetapi juga disebabkan frekuensi jenis grammatik yang tidak seimbang perkataan yang disebabkan. Jenis bias ini menjadi lebih jelas dalam menghasilkan ungkapan perbualan di mana jenis tidak dinyatakan dalam kalimat, kerana kebanyakan aplikasi NLP semasa masih bekerja pada konteks aras kalimat. Sebagai langkah menuju NLP yang lebih inklusif, kertas ini mencadangkan pendekatan tulisan semula secara automatik dan boleh diperlukan untuk kalimat percakapan pendek. Kaedah tulisan semula boleh dilaksanakan kepada kalimat yang, tanpa konteks kalimat tambahan, mempunyai alternatif yang sama dalam terma jenis. Kaedah ini boleh dilaksanakan untuk mencipta output seimbang jenis dan untuk mencipta data latihan seimbang jenis. The proposed approach is based on a neural machine translation system trained to `translate' from one gender alternative to another.  Both the automatic and manual analysis of the approach show promising results with respect to the automatic generation of gender alternatives for conversational sentences in Spanish.</abstract_ms>
      <abstract_mt>Il-preġudizzju bejn is-sessi huwa okkorrenza frekwenti fl-applikazzjonijiet ibbażati fuq il-NLP, speċjalment espress fil-lingwi kkawżati mis-sessi. Il-biża’ tista’ tidher permezz ta’ assoċjazzjonijiet ta’ ċerti aġġettivi u anima n-nomi mas-sess naturali tar-referenti, iżda wkoll minħabba frekwenzi grammatiċi mhux bilanċjati tas-sess ta’ kliem influtt. Dan it-tip ta’ preġudizzju jsir aktar evidenti fil-ġenerazzjoni ta’ dikjarazzjonijiet ta’ konverżjoni fejn is-sess mhuwiex speċifikat fis-sentenza, minħabba li l-biċċa l-kbira tal-applikazzjonijiet attwali tal-NLP għadhom jaħdmu fuq kuntest fil-livell tas-sentenza. Bħala pass lejn NLP aktar inklużiv, dan id-dokument jipproponi approċċ awtomatiku u ġeneralizzabbli ta’ kitba mill-ġdid għal sentenzi ta’ konverżjoni qosra. Il-metodu tal-kitba mill-ġdid jista’ jiġi applikat għal sentenzi li, mingħajr kuntest extra-sentenzjali, għandhom diversi alternattivi ekwivalenti f’termini ta’ sess. Il-metodu jista’ jiġi applikat kemm għall-ħolqien ta’ riżultati bilanċjati bejn is-sessi kif ukoll għall-ħolqien ta’ dejta ta’ taħriġ bilanċjat bejn is-sessi. L-approċċ propost huwa bbażat fuq sistema ta’ traduzzjoni tal-magni newrali mħarrġa biex “tittraduċi” minn alternattiva bejn is-sessi għal oħra. Kemm l-analiżi awtomatika kif ukoll manwali tal-approċċ juru riżultati promettenti fir-rigward tal-ġenerazzjoni awtomatika ta’ alternattivi tas-sessi għal sentenzi ta’ konverżjoni bl-Ispanjol.</abstract_mt>
      <abstract_no>Gender bias er ein ofte forekomst i NLP-baserte program, spesielt uttalet i seks-influserte språk. Bias kan visast gjennom tilknytingar av nokre adjektiv og animater namn med den naturlege seksen av referanser, men også på grunn av ubebalanserte grammatiske seksfrekvenser av inflektiv ord. Denne typen følgjande blir meir synleg i å laga samtaletaler der seks ikkje er spesifisert i setninga, fordi dei fleste gjeldande NLP-program fungerer fortsatt på eit setningsnivåkontekst. Som steg mot meir inkludert NLP, foreslår denne papiret ein automatisk og generelt omskrivbar tilnærming for korte konvertasjonssteikn. Omskrivingsmetoden kan brukast til setningar som, utan ekstra sentensiell kontekst, har fleire ekvivalente alternativ i vilkåra av seks. Metoden kan brukast både for å laga seksbalanserte utgåver og for å laga seksbalanserte øvingsdata. Førehandsvis tilnærming er basert på eit neuralmaskinsomsetjingssystem som treng til « translate » frå ein generell alternativ til ein annan. Både automatisk og manuelt analysen av tilnærminga viser alvorleg resultat med hensyn til automatisk generering av seks-alternativ for samtalesetningar i spansk.</abstract_no>
      <abstract_mn>НЛП-д суурилсан хэрэглээнд гендер эсрэг байдал ихэвчлэн ихэвчлэн явагддаг, ялангуяа гендер нөлөөлдөг хэл дээр илэрхийлэгддэг. Биас зарим adjectives, animated nouns нь байгалийн гендер сэтгэл хөдлөлтэй холбоотой боловч мөн нөлөөлдөг үгнүүдийн грамматикийн гендер хэмжээсүүдийн үр дүнд баланслагүй боловч харагдаж болно. Яагаад гэвэл ихэнх орчин үеийн NLP програмууд үеийн түвшинд ажилладаг. Энэ цаас нь богино ярилцлагын өгүүлбэрт автоматически, ерөнхийлөгч дахин бичиж чадах арга зам болгоно. Дахин бичих арга нь нэмэлт өгүүлбэрээс илүү ижил өөрчлөлтийг гендерийн хувьд харьцуулж чадна. Эдгээр арга нь гендерийн балансийн үр дүнг бүтээх болон гендерийн балансийн дасгал өгөгдлийг бүтээх боломжтой. Тайлбарлалтын арга нь сэтгэл хөдлөлийн нэг гендерийн альтернативээс өөр нэгэнд "translate" болох мэдрэлийн машин орчуулалтын системээс сургалтын байдаг. Энэ арга баримтын автоматик болон гарын шинжилгээс хоёулаа нь Испанийн ярилцлагын өгүүлбэрийн автоматик хүйсийн өөрчлөлтүүдийн үр дүнг харуулдаг.</abstract_mn>
      <abstract_pl>Białość płci jest często występująca w aplikacjach opartych na NLP, szczególnie wyraźna w językach o napięciu płci. Bias może pojawiać się poprzez skojarzenia niektórych przymiotników i rzeczowników animowanych z naturalną płcią referentów, ale także ze względu na niezrównoważoną gramatyczną częstotliwość płci przekształconych słów. Ten rodzaj uprzedzeń staje się bardziej widoczny w generowaniu wypowiedzi konwersacyjnych, w których płeć nie jest określona w zdaniu, ponieważ większość obecnych aplikacji NLP nadal działa w kontekście na poziomie zdania. Jako krok w kierunku bardziej integracyjnego NLP, niniejszy artykuł proponuje automatyczne i ogólne podejście do przepisywania krótkich zdań konwersacyjnych. Metodę przepisywania można zastosować do zdań, które bez kontekstu pozasensownego mają wiele równoważnych alternatyw pod względem płci. Metoda ta może być stosowana zarówno do tworzenia wyników zrównoważonych płci, jak i do tworzenia danych dotyczących szkoleń zrównoważonych płci. Proponowane podejście opiera się na neuronowym systemie tłumaczenia maszynowego przeszkolonym do "tłumaczenia" z jednej alternatywy płci na drugą. Zarówno automatyczna, jak i ręczna analiza podejścia pokazuje obiecujące rezultaty w zakresie automatycznego generowania alternatyw płci dla zdań konwersacyjnych w języku hiszpańskim.</abstract_pl>
      <abstract_sr>Ženska pristrasnost je često pojavljivanje aplikacija na temelju NLP-a, posebno proglašena na spolnim jezicima. Bias se može pojaviti kroz udruženje određenih adjektiva i animirati imena sa prirodnim spolom referenta, ali takođe zbog nepravednosti gramatične spolne frekvencije utjecaja reči. Ova vrsta predrasude postaje oèiglednije u stvaranju razgovornih reèi gde se spol ne određuje u rečenici, jer veæin a trenutnih aplikacija NLP još uvijek radi na kontekstu razine rečenica. Kao korak ka uključivanju NLP-a, ovaj papir predlaže automatski i generalni ponovno pisani pristup kratkim razgovornim re čenicama. Metod prepisanja se može primijeniti na rečenice koje bez ekstra-sentencijalnog konteksta imaju višestruke ekvivalentne alternative u smislu spola. Metod se može primjenjivati i za stvaranje spolnih balanciranih ishoda, kao i za stvaranje podataka o balanciranoj obuci spola. Predloženi pristup je baziran na sistemu neurološkog prevoda obučenom na "prevod" od jedne alternative spola drugoj. I automatska i ručna analiza pristupa pokazuju obećavajuće rezultate u pogledu automatske generacije spolnih alternativa za razgovorne rečenice na španjolskom.</abstract_sr>
      <abstract_si>ජෙන්ඩර් බායිස් තමයි NLP-අධාරිත භාවිතාවයේ සාමාන්‍ය විදිහක් වෙන්නේ, විශේෂයෙන් ජෙන්ඩර් ප්‍රතික Bias can be seen by Association of Certe Adectives and anite Nuns with the Native Genr of References, but too Due to unscaled Gramatical Genr Frequexes of Infected Words. මේ ප්‍රකාරයේ ප්‍රකාරය ප්‍රවේශනයක් වෙන්න පුළුවන් වෙනවා වාර්තාවක් සම්බන්ධ වාර්තාවක් සිද්ධ වෙන්න, ජෙන්ඩර් වාර්තාව මේ පැත්තේ ස්වයංක්‍රියාත්මක සහ සාමාන්‍ය වාර්තාවක් සමාන්‍ය වාර්තාවක් වෙනුවෙන් නැවත ලියන්න පුළුවන් ප්‍රවේශ ප්‍රතිලිපණ විධානය ප්‍රයෝජනය කරන්න පුළුවන් විදිහට වචනයක් විතරයි, විතරක් වචනයක් නැති විදිහට සමාන්‍ය විකල විධානය ප්‍රයෝජනය කරන්න පුළුවන් ජෙන්ඩර් සැලසුම් ප්‍රයෝජනය සහ ජෙන්ඩර් සැලසුම් ප්‍රයෝජනය දත් ප්‍රශ්නයක් තියෙන්නේ න්‍යූරාල් මැෂින් වාර්ථාව පද්ධතියක් පද්ධතියෙන් අධාරිත වෙන්නේ, `trans' එක ස්වයංක්‍රියාත්මක විශ්ලේෂණයේ ස්වයංක්‍රියාත්මක විශ්ලේෂණය දෙන්නම් ප්‍රතිචාර ප්‍රතිචාර ප්‍රතිචාර ප්‍ර</abstract_si>
      <abstract_ro>Prejudecățile de gen sunt frecvente în aplicațiile bazate pe PNL, mai ales pronunțate în limbile inflectate de gen. Bias-urile pot apărea prin asocierea anumitor adjective și animarea substantivelor cu genul natural al referenților, dar și datorită frecvențelor de gen gramatical dezechilibrate ale cuvintelor inflectate. Acest tip de părtinire devine mai evident în generarea pronunțărilor conversaționale în care sexul nu este specificat în propoziție, deoarece majoritatea aplicațiilor actuale PNL funcționează încă într-un context la nivel de propoziție. Ca un pas spre PNL mai incluziv, această lucrare propune o abordare automată și generalizabilă de rescriere a propozițiilor conversaționale scurte. Metoda de rescriere poate fi aplicată propozițiilor care, fără context extra-sentimental, au multiple alternative echivalente în ceea ce privește sexul. Metoda poate fi aplicată atât pentru crearea de rezultate echilibrate între femei și bărbați, cât și pentru crearea de date privind formarea echilibrată între femei și bărbați. Abordarea propusă se bazează pe un sistem neuronal de traducere automată instruit să "traducă" de la o alternativă de gen la alta. Atât analiza automată, cât și cea manuală a abordării arată rezultate promițătoare în ceea ce privește generarea automată de alternative de gen pentru propozițiile conversaționale în limba spaniolă.</abstract_ro>
      <abstract_ka>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages. Bias შეიძლება გამოჩვენება განსაკუთრებული აექექტიგების აპორციაციებით და ანიმეტრების აპორციალური გენექტის აპორციაციებით, მაგრამ განსაკუთრებული გენექტიური სიტყვების განსაკუთრებით. ამ ტიპის წარმოდგენები უფრო დაახლოებით, რომელიც კონტაქციო სიტყვების შექმნა, სადაც გენდერი არ განსაზღვრულია სიტყვებში, რადგან მეტი მიმდინარე NLP პროგრამები უკვე როგორც უფრო კონტაქტიური NLP-ის გარეშე, ეს დონტაქტი აჩვენებს ავტომატიური და გენერალური გარეშე წერილების მიღება კონტაქტიური კონტაქტიური სიტყვილებისთ გადაწერის მეტი შეიძლება გამოყენება სიტყვებისთვის, რომლებიც ექსტრენციალური კონტექსტური გარეშე არსებობს განსხვავებული ალტენტიფიკაციები გენდერის შესახებ პროცემი შეიძლება გამოყენება გენექსური ბალანსური გამოსვლების შექმნა და გენექსური ბალანსური განათლების მონაცემების შექმნა. პროგრამის მიღება ნეიროლური მანქანის გადაწყვეტილების სისტემის დაბაზია, რომელიც `translate' უნდა ერთი გენერის ალტენტიფიკატისგან სხვა. აвтоматичесკი და მანძილური ანალიზაცია პროგრამის შესახებ გამოიყენება, რომელიც საკუთარი წარმოდგენების შესახებ გენდრის ალტენტიფიკაციის ავტომატიკური წარმოდგენის</abstract_ka>
      <abstract_sv>Könsbias är en frekvent förekomst i NLP-baserade tillämpningar, särskilt uttalad på könsinfluerade språk. Bias kan uppstå genom associationer av vissa adjektiv och animera substantiv med referenternas naturliga kön, men också på grund av obalanserade grammatiska könsfrekvenser av böjda ord. Denna typ av bias blir tydligare i att generera konversationsuttal där kön inte specificeras i meningen, eftersom de flesta nuvarande NLP-applikationer fortfarande fungerar på en meningsnivå kontext. Som ett steg mot en mer inkluderande NLP föreslår denna uppsats en automatisk och generell omskrivning av korta konversationssymboler. Omskrivningsmetoden kan tillämpas på meningar som, utan extra-sentimental kontext, har flera likvärdiga alternativ när det gäller kön. Metoden kan användas både för att skapa könsbalanserade resultat och för att skapa könsbalanserade utbildningsdata. Det föreslagna tillvägagångssättet bygger på ett neuralt maskinöversättningssystem som utbildats för att "översätta" från ett könsalternativ till ett annat. Både den automatiska och manuella analysen av tillvägagångssättet visar lovande resultat med avseende på automatisk generering av genusalternativ för konversations meningar på spanska.</abstract_sv>
      <abstract_kk>Gender bias - NLP негіздеген қолданбаларда көптеген, әсіресе гендердің тілдерінде көптеген. Bias кейбір бөлшектердің бірнеше бөлшектерінің бөлшектері мен сілтемелердің табиғи гендеріне анимациялау мүмкін, бірақ сондай-ақ балансияланбаған грамматикалық гендер жиілігінің көмегімен. Бұл тәртібі сұлбаның көпшілігі сұлбаның көпшілігі сұлбаның көпшілігінде жұмыс істемеген мәліметтерді құру үшін болады, себебі қазіргі NLP қолданбалары ә Бұл қағаз көбірек NLP қатынасына қадам ретінде қысқа аудармалы сөйлемелер үшін автоматты және жалпы қайта жазу әдісін ұсынады. Қайта жазу әдісі гендердің қасиетінде бірнеше тең альтернативтері бар сөздерге қолданылады. Бұл әдіс гендердің балансировалған шығысын құру үшін және гендердің балансировалған оқыту деректерін құру үшін қолданылады. Келтірілген тәсілі невралдық компьютердің аудару жүйесіне негізделген бір гендердің альтернативінен басқаша 'translate' дегенге аудару жүйесіне негізделген. Қолданыстың автоматты түрде және қолмен анализ екеуі есептеу сөйлемелерінің автоматты түрде жасау альтернативтерінің нәтижелерін көрсетеді.</abstract_kk>
      <abstract_so>Dhinacyada jinsigu waa mid inta badan ku dhaca codsiga ku saleysan NLP, khusuusan lagu sheego luuqadaha jinsiga la xiriiray. Bias waxay ka muuqan karaan ururada isbedelka qaarkood iyo jinsiyada dabiicadda ah, laakiin waxaa kaloo looga muujin karaa dhibaatooyinka jinsiga oo aan la siman karin hadalka saameysan. Nooca caynkan ah waxey ka muuqataa si ka muuqata hadallada iskala hadla, meesha aan jinsigu ku qornayn qoraalka gudaheeda, sababtoo ah xiliga codsiga NLP waxay weli ka shaqeeyaan qoraal-heer. Qoraalkan warqaddaas wuxuu u soo jeedaa qaabab automatic oo general ah oo u qori karo hadal gaaban. The rewriting method can be applied to sentences that, without extra-sentential context, have multiple equivalent alternatives in terms of gender.  Sidoo kale waxaa lagu codsan karaa qaababka abuurista soo bixinta jinsiga oo la siman yahay iyo abuurista macluumaadka waxbarashada jinsiga oo la siman yahay. Dhaqdhaqaaqa la soo jeedo waxay ku saleysan tahay nidaamka turjumidda neural machine tarjumidda ee loo baray `turjuma' oo ka mid ah jinsi bedel kale. Analyska rasmi ah iyo manual ah ee qaababka soo qaabilsan waxay muuqataa resulto ballanqaadsan oo ku saabsan farshaha bilowga ah oo ka bedela qaabilaada jinsiga ee hadalka Isbanish ku qoran.</abstract_so>
      <abstract_ta>NLP- அடிப்படையிலான பயன்பாடு பையாஸ் சில துண்டுக்கள் மற்றும் அசைவூட்டத்திற்கு மூலம் பார்க்கலாம் மற்றும் இயல்பான குறிப்புக்குறிப்புகளின் இனம் உடன், ஆனால் நிறைய வாக்கியத்திற்குள் இனம் குறிப்பிடப்படவில்லை என்ற பேச்சு வார்த்தைகளை உருவாக்கும் போது இந்த பியாஸ் தெளிவாக தெரியும், ஏனெனில்  மேலும் NLP சேர்க்கப்பட்ட ஒரு படி என்றால், இந்த தாள் சிறிய பேச்சு வாக்குகளுக்கு தானியங்கிய மற்றும் பொதுவாக எழுதும்  மீண்டும் எழுதும் முறைமையை செயல்படுத்த முடியும், அதிக உணர்வு சூழல் இல்லாமல், பெண்களுக்கு பல சமமான மாற்றுகள் இருக்கும். பெண்களின் நிலையான வெளியீடுகளை உருவாக்குவதற்கும் மற்றும் பெண்களின் நிலையான பயிற்சி தரவை உருவாக்குவதற்காக முற பரிந்துரைக்கப்பட்ட முறைமை ஒரு புதிய இயந்திர மொழிபெயர்ப்பு அமைப்பின் அடிப்படையிலாக உள்ளது 'மொழிபெயர்ப்பு' ஒரு  தானாகவே மற்றும் கைமுறை ஆராய்ச்சியில் இருந்தும் வாக்களிக்கப்பட்ட முடிவுகளை காட்டும் தானாகவே பேசும் வாக்குகளுக்கு தானா</abstract_ta>
      <abstract_ur>جنس کی بحث NLP بنیادی کاربریوں میں بہت زیادہ اتفاق ہے، مخصوصاً جنس کی تحت تاثیر کی زبانوں میں پڑھی جاتی ہے. Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also because of unbalanced grammatical gender frequencies of influenced words. یہ قسم کی بحث زیادہ واضح ہو جاتی ہے، جہاں جنس کی تعریف میں نہیں دی جاتی، کیونکہ اکثر موجود NLP اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اس کاغذ نے بہت شامل NLP کی طرف ایک قدم بنایا ہے، یہ کاغذ چھوٹی گفتگو جماعتوں کے لئے آٹوٹی اور عمومی طریقے کی پیشنهاد کرتا ہے. دوبارہ نوشتنے کا طریقہ جماعتوں پر لازم کر سکتا ہے جو جنس کے اندر بہت سی برابر اختیار رکھتے ہیں۔ یہ طریقہ دونوں کو جنس کی تعلیم برالینگ نتائج بنانے کے لئے بھی لازم کر سکتا ہے اور جنس کی تعلیم دادہ بنانے کے لئے بھی۔ پیشنهاد کی تقریبا ایک نئورل ماشین ترجمہ سیستم پر بنیاد ہے جسے ایک جنس الٹی سے دوسرے کے لئے ترجمہ کیا گیا ہے۔ اس طریقے کی آٹوٹی اور مہمانی تحلیل دونوں میں سپانیایی جماعتوں کے لئے جنس کی آٹوٹی پیدائش کے بارے میں وعدہ دینے والی نتیجے دکھاتے ہیں.</abstract_ur>
      <abstract_uz>Jin bias - NLP asosiy dasturlarda oddiy bo'lgan holatdir, hususan jinsiyalar bilan qo'llangan tillarda. Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also due to unbalanced grammatical gender frequencies of inflected words.  @ info: whatsthis Koʻproq NLP orqali bir qadam sifatida, bu hujjat chaqaloqlar soʻzlari uchun avtomatik va generaliz ravishda qayta yozib qoʻllaniladi. @ info: whatsthis Name Name Name</abstract_uz>
      <abstract_vi>Sự thiên vị giới tính là thường thấy trong các ứng dụng dựa vào ngôn ngữ ngụcl, đặc biệt được phát hiện. Âm học có thể xuất hiện qua các liên quan của tính từ và danh từ động vật với giới tính tự nhiên của các từ, nhưng cũng là do tần số giới tính sai lệch của các từ ngữ nhập. Kiểu khuynh hướng này trở nên rõ ràng hơn trong việc tạo ra những từ đối thoại nơi giới tính không được xác định trong câu, vì hầu hết các ứng dụng NLP vẫn còn hoạt động trong ngữ cảnh cấp độ Câu. Như một bước tiến tới một tiêu biểu khôn khéo hơn, tờ giấy đề xuất một phương pháp viết lại tự động và tổng quát cho các câu ngắn. Cách viết lại có thể áp dụng vào các câu mà không có trường hợp ngoại lệ, có nhiều lựa chọn tương đương về giới tính. Phương pháp này có thể được áp dụng cho việc tạo ra kết quả cân bằng giới tính, cũng như để tạo dữ liệu giáo dục cân bằng. Cách tiếp cận được đề nghị dựa trên một hệ thống dịch chuyển máy thần kinh được đào tạo để "dịch" từ giới tính thay thế giới khác. Cả bản phân tích tự động và tay về phương pháp này đều cho thấy kết quả hứa hẹn về việc sản xuất các thay đổi giới tính tự động cho câu đối thoại ở Tây Ban Nha.</abstract_vi>
      <abstract_bg>Половите пристрастия са често срещани в приложенията, базирани на НЛП, особено изразени в езици, свързани с пола. Приклоненията могат да се появят чрез асоциации на определени прилагателни и анимирани съществителни с естествения пол на референтите, но също така и поради небалансирани граматически полови честоти на наклонените думи. Този тип пристрастие става по-очевидно при генерирането на разговорни изказвания, където пол не е определен в изречението, тъй като повечето съвременни приложения за НЛП все още работят на ниво изречение контекст. Като стъпка към по-приобщаваща НЛП, настоящата статия предлага автоматичен и обобщен подход за пренаписване на кратки разговорни изречения. Методът за пренаписване може да се прилага за изречения, които без извънреден контекст имат множество еквивалентни алтернативи по отношение на пола. Методът може да се приложи както за създаване на балансирани резултати между половете, така и за създаване на балансирани данни за обучение между половете. Предложеният подход се основава на невронна система за машинен превод, обучена да "превежда" от един пол алтернатива на друг. Както автоматичният, така и ръчният анализ на подхода показват обещаващи резултати по отношение на автоматичното генериране на полови алтернативи за разговорни изречения на испански език.</abstract_bg>
      <abstract_da>Kønsbias er en hyppig forekomst i NLP-baserede applikationer, især udtalt i kønsbaserede sprog. Bias kan forekomme gennem associationer af visse adjektiver og animere substantiver med referenternes naturlige køn, men også på grund af ubalancerede grammatiske kønsfrekvenser af bøjede ord. Denne type bias bliver mere tydelig ved at generere samtaleudgifter, hvor køn ikke er specificeret i sætningen, fordi de fleste nuværende NLP-applikationer stadig fungerer på en sætningsniveau kontekst. Som et skridt mod mere inklusiv NLP foreslår denne artikel en automatisk og generel omskrivning tilgang til korte samtalesætninger. Omskrivningsmetoden kan anvendes på sætninger, der uden ekstra-sentimental kontekst har flere tilsvarende alternativer med hensyn til køn. Metoden kan anvendes både til at skabe kønsafbalancerede resultater og til at skabe kønsafbalancerede uddannelsesdata. Den foreslåede tilgang er baseret på et neuralt maskinoversættelsessystem, der er uddannet til at oversætte fra et kønsalternativ til et andet. Både den automatiske og manuelle analyse af tilgangen viser lovende resultater med hensyn til automatisk generering af kønsalternativer til samtalesætninger på spansk.</abstract_da>
      <abstract_id>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages.  Bias dapat muncul melalui asosiasi beberapa adjektif dan animasi nama dengan jenis alami referens, tetapi juga karena frekuensi kelamin grammatik yang tidak seimbang dari kata-kata yang disebabkan. Jenis bias ini menjadi lebih jelas dalam menghasilkan ucapan konversasi di mana jenis tidak dinyatakan dalam kalimat, karena kebanyakan aplikasi NLP saat ini masih bekerja pada konteks tahap kalimat. Sebagai langkah menuju NLP yang lebih inklusif, kertas ini mengusulkan pendekatan menulis ulang secara otomatis dan umum untuk kalimat percakapan pendek. Metode tulisan ulang dapat diterapkan pada kalimat yang, tanpa konteks ekstra kalimat, memiliki banyak alternatif yang sama dalam terma jenis. Metode ini dapat diterapkan untuk menciptakan output yang seimbang jenis dan untuk menciptakan data pelatihan yang seimbang jenis. pendekatan yang diusulkan berdasarkan sistem terjemahan mesin saraf dilatih untuk `terjemahan' dari satu alternatif jenis ke yang lain. Both the automatic and manual analysis of the approach show promising results with respect to the automatic generation of gender alternatives for conversational sentences in Spanish.</abstract_id>
      <abstract_de>Gender Bias ist ein häufiges Auftreten in NLP-basierten Anwendungen, besonders ausgeprägt in geschlechterbedingten Sprachen. Bias kann durch Assoziationen bestimmter Adjektive und animierter Substantive mit dem natürlichen Geschlecht der Referenten auftreten, aber auch durch unausgewogene grammatische Geschlechterfrequenzen von gebeugten Wörtern. Diese Art von Verzerrung wird deutlicher, wenn Konversationsäußerungen erzeugt werden, bei denen das Geschlecht nicht innerhalb des Satzes angegeben ist, da die meisten aktuellen NLP-Anwendungen immer noch auf einem Kontext auf Satzebene arbeiten. Als Schritt hin zu inklusiveren NLP schlägt dieses Papier einen automatischen und verallgemeinerbaren Umschreibungsansatz für kurze Konversationssätze vor. Die Umschreibungsmethode kann auf Sätze angewendet werden, die ohne extrasentiellen Kontext mehrere gleichwertige Alternativen in Bezug auf das Geschlecht haben. Die Methode kann sowohl zur Erstellung geschlechtsspezifischer Outputs als auch zur Erstellung geschlechtsspezifischer Trainingsdaten angewendet werden. Der vorgeschlagene Ansatz basiert auf einem neuronalen maschinellen Übersetzungssystem, das darauf trainiert ist, von einer Geschlechtsalternative zu einer anderen zu "übersetzen". Sowohl die automatische als auch die manuelle Analyse des Ansatzes zeigen vielversprechende Ergebnisse hinsichtlich der automatischen Generierung von Geschlechteralternativen für Konversationssätze auf Spanisch.</abstract_de>
      <abstract_ko>성별 편견은 NLP 기반 응용 프로그램에서, 특히 성별의 영향을 받는 언어에서 자주 발생한다.편견은 일부 형용사와 생동감 있고 활발한 명사와 가리키는 대상의 자연성별 간의 관련을 통해 나타날 수 있지만 굴절사의 문법적 성별 빈도 불균형으로 인한 것일 수도 있다.이런 유형의 편견은 문장에서 성별을 지정하지 않은 세션에서 더욱 뚜렷해졌다. 왜냐하면 현재 대부분의 NLP 응용 프로그램이 문장 단계의 상하문에서 일하고 있기 때문이다.더욱 포용적인 자연 언어 처리를 위한 한 걸음으로 본고는 자동적이고 통용되는 짧은 문장 개작 방법을 제시했다.이런 개작 방법은 문장의 외국어 경계가 없고 성별에 있어서 여러 개의 대등한 선택이 있는 문장에 응용할 수 있다.이 방법은 성별 균형의 생산을 만드는 데도 사용될 뿐만 아니라 성별 균형의 교육 데이터를 만드는 데도 사용될 수 있다.제시된 방법은 훈련을 받은 신경기계 번역 시스템을 바탕으로 이 시스템은 한 성별에서 다른 성별로 선택할 수 있다.이 방법의 자동과 수동 분석에 따르면 스페인어 회화 문장을 자동으로 생성하는 성별 선택에 있어 만족스러운 결과를 얻었다.</abstract_ko>
      <abstract_nl>Gender bias komt vaak voor in NLP-gebaseerde toepassingen, vooral uitgesproken in gender-geïnfecteerde talen. Bias kan ontstaan door associaties van bepaalde bijvoeglijke naamwoorden en geanimeerde zelfstandige naamwoorden met het natuurlijke geslacht van referenten, maar ook door onevenwichtige grammaticale geslachtsfrequenties van gebogen woorden. Dit type bias wordt duidelijker bij het genereren van conversationele uitingen waarbij gender niet is gespecificeerd binnen de zin, omdat de meeste huidige NLP-toepassingen nog steeds werken op een zin-niveau context. Als stap naar inclusievere NLP stelt dit artikel een automatische en algemene herschrijvingsaanpak voor voor korte gesprekszinnen. De herschrijvingsmethode kan worden toegepast op zinnen die, zonder extra-sententiële context, meerdere gelijkwaardige alternatieven hebben qua geslacht. De methode kan zowel worden toegepast voor het creëren van gendergebalanceerde outputs als voor het creëren van gendergebalanceerde opleidingsgegevens. De voorgestelde aanpak is gebaseerd op een neuraal machine translation systeem dat getraind is om te 'vertalen' van het ene gender alternatief naar het andere. Zowel de automatische als de handmatige analyse van de aanpak laten veelbelovende resultaten zien met betrekking tot de automatische generatie van gender alternatieven voor conversatieszinnen in het Spaans.</abstract_nl>
      <abstract_hr>Ženska pristrasnost je često pojavljivanje primjena na temelju NLP-a, posebno proglašena na spolnim jezicima. Bias se može pojaviti kroz udruženje određenih adjektiva i animirati imena prirodnim spolom referenta, ali također zbog nepravednosti gramatične spolne frekvencije utjecaja riječi. Ova vrsta predrasude postaje očiglednije u stvaranju razgovornih govora gdje se spol ne određuje unutar rečenice, jer većin a trenutnih aplikacija NLP-a još uvijek radi na kontekstu razine rečenica. Kao korak ka uključujući NLP, ovaj papir predlaže automatski i generalni ponovno pisani pristup kratkim razgovornim re čenicama. Metod prepisanja se može primjenjivati na rečenice koje bez dodatnog konteksta imaju višestruke ekvivalentne alternative u smislu spola. Metod se može primjenjivati i za stvaranje balanciranih ishoda spola, kao i za stvaranje podataka o balanciranoj obuci spola. Predloženi pristup se temelji na sustavu prevoda neuroloških strojeva obučenom na 'prevod' od jedne alternative spola drugoj. I automatska i ručna analiza pristupa pokazuju obećavajuće rezultate u pogledu automatske generacije spolnih alternativa za razgovorne rečenice na španjolskom.</abstract_hr>
      <abstract_af>Gender bias is 'n dikwels voorkoms in NLP-gebaseerde toepassings, veral uitgepronklik in gender-inflekke tale. Bias kan verskyn deur assosiasies van sekere adjektiewe en animeer noume met die natuurlike geneem van verwysing, maar ook vanweë onbalanseerde grammatiese geneemfrekwensies van inflekke woorde. Hierdie tipe bias word meer duidelik in die genereer van konversasionale uitspraak waar genereer is nie gespesifiseer binne die seting nie, omdat die meeste huidige NLP toepassings nog werk op 'n setvlak konteks. As 'n stap na meer inkluisiewe NLP, voorstel hierdie papier 'n outomatiese en generaliseerbare reerskryfbaar toegang vir kort gesprekslyn setinge. Die herskryfmetode kan aanwend word na setnings wat, sonder ekstra-sentensiele konteks, veelvuldige gelykende alternatiewe het ingevolge geneem. Die metode kan gebruik word beide vir skep van gemengsbalanseerde uitvoerdes as ook vir skep van gemengsbalanseerde onderwerking data. Die voorgestelde toegang is gebaseer op 'n neurale masjien vertaling stelsel wat onderwerp word na `translate' van een seunsalternatief na 'n ander. Beid die outomatiese en manuale analisie van die toegang vertoon die beloftende resultate met betrekking tot die outomatiese generasie van seunsalternatiewe vir konversasionale setings in Spaanse.</abstract_af>
      <abstract_fa>نسبت به جنسی یک اتفاق اغلب در کاربردهای بنیاد NLP است، مخصوصاً در زبان های جنسی تأثیر داده شده است. Bias می تواند از طریق اتصال‌هایی از قسمت متوسط و اسم‌های طبیعی با جنس طبیعی نسبت‌ها ظاهر شود، ولی همچنین به خاطر فرکانس‌های گراماتیک جنس‌های متوسط کلمات تأثیر داده شود. این نوع تغییرات در تولید سخنرانی مکالمه‌ای که جنسی در جمله مشخص نشده است، بیشتر کاربردهای NLP فعلی هنوز در یک محیط سطح جمله کار می‌کنند. به عنوان یک قدم به طرف NLP شامل بیشتری، این کاغذ برای جمله‌های مکالمه کوتاه یک دستور دوباره نوشتن خودکار و عمومی پیشنهاد می‌کند. روش نوشتن دوباره می‌تواند به جمله‌ها کاربرد شود که بدون محتوای اضافه‌ای از جمله‌های جنسی چندین تفاوت برابر دارند. این روش می‌تواند برای ایجاد نتیجه‌های تطبیعی جنسی و برای ایجاد داده‌های تطبیعی جنسی در هر دو استفاده شود. این دستور پیشنهاد بر اساس یک سیستم ترجمه ماشین عصبی آموزش داده شده تا «ترجمه» از یک جایگزینه جنسی به دیگر باشد. هر دو تحلیل خودکار و دستی از دستور این دستور نتیجه‌های قول‌دهنده را در مورد نسل‌های جایگزین جنسی برای جمله‌های مکالمه‌ای در اسپانیایی نشان می‌دهد.</abstract_fa>
      <abstract_sw>Ubaguzi wa jinsia unatokea mara kwa mara katika matumizi yanayotokana na NLP, hususani kutangazwa kwa lugha za jinsia zinazohusiana na jinsia. Bias inaweza kuonekana kupitia makundi ya baadhi ya waboreshaji na viungo vinavyozaliwa na jinsia asilia ya maoni, lakini pia kwa sababu ya kuongezeka kwa kiwango cha kijinsia cha maneno yanayoathirika. a in a hii ya upendeleo inaonekana kuwa wazi zaidi katika kutengeneza hotuba za mazungumzo ambapo jinsia haijaelewekwa ndani ya hukumu, kwa sababu matumizi mengi ya NLP bado yanafanya kazi katika muktadha wa hukumu. As a step towards more inclusive NLP, this paper proposes an automatic and generalisable re-writing approach for short conversational sentences.  Utawala wa kuandika upya unaweza kutumika kwa hukumu kwamba, bila muktadha wa kuongeza hisia, wana mabadiliko mengi yanayofanana na jinsia. Utawala unaweza kutumika kwa ajili ya kutengeneza matokeo yenye usawa wa jinsia pamoja na kutengeneza taarifa za mafunzo ya kijinsia. Mtandao huu unapendekezwa umejikita na mfumo wa kutafsiri mashine ya ubongo ulioelekezwa kwa `tafsiri' kutoka mbadala ya kijinsia na nyingine. Uchambuzi wa kibinafsi na manufaa wa mbinu hizo unaonyesha matokeo yanayoahidi kuheshimu kizazi cha kujitegemea mabadiliko ya kijinsia kwa ajili ya hukumu za mazungumzo ya lugha ya Kihispania.</abstract_sw>
      <abstract_sq>Paragjyqësia e gjinit është një ndodhie e shpeshtë në aplikimet me bazë në NLP, veçanërisht e shprehur në gjuhët e shkaktuara nga gjini. Bias mund të shfaqet nëpërmjet shoqatave të disa adjektive dhe të animacioneve emra me gjinin natyror të referentëve, por gjithashtu për shkak të frekuencave të paekuilibruara të gjinisë gramatike të fjalëve të ardhura. Ky lloj paragjykimi bëhet më i qartë në krijimin e shprehjeve bisedimore ku gjini nuk është specifikuar brenda dënimit, sepse shumica e aplikimeve aktuale të NLP ende punojnë në një kontekst të nivelit të dënimeve. Si një hap drejt NLP më përfshirëse, ky dokument propozon një qasje automatike dhe të gjeneralizueshme të rishkrimit për fjalime të shkurtra bisedimesh. Metoda e rishkrimit mund të aplikohet në fraza që, pa kontekst ekstra-dënimi, kanë alternativa të shumta ekvivalente lidhur me gjininë. Metoda mund të aplikohet si për krijimin e rezultateve të ekuilibruara gjinore si dhe për krijimin e të dhënave të ekuilibruara gjinore të trainimit. Përqasja e propozuar bazohet në një sistem përkthimi nervor makineri të trajnuar për `përkthimin' nga një alternativë gjinore në tjetrën. Analiza automatike dhe manuale e qasjes tregon rezultate premtuese lidhur me gjeneratën automatike të alternativave gjinore për fjalimet bisedore në spanjoll.</abstract_sq>
      <abstract_tr>NLP-da görkezilen uygulamalarda soňra näçe görnüşler bolýar, ýöne cins etmän dillerde sözleşir. Bias birnäçe adjektivler bilen birleşişip, tebigy jentiller bilen animatýan adlary bilen görünýär, ýöne bu şekilde etkileşimli sözlerin gramatik jentiller arasynda täsirleýän döwletlere seredendir. Bu hili sowgatlar sözleriň içinde jentiller takyklanmaýan sözleri döretmäge köp üns berilýär, sebäbi häzirki NLP programleri heniz hem sözleriň derejesinde işleýärler. NLP hem daşary bir ädim bolsa, bu kagyz gysga sözleriň üçin awtomatik we umumy ýene-de ýazmak ýazjagyny teklip edip bilýär. Täzeden ýazma yöntemi cinsiýa duşuşyksyz bolan sözlere uygulanabilir. Genç çözümleri çözümlendirmek üçin we jentiller çözümlendirmek üçin hem çözümlendirilebilir. Mazmunlar üçin nuýral maşynyň terjime sistemasyna daýanýar. Bu ýagdaýyň otomatik we el analizi hem çykyş sözleri üçin sözleşmek üçin jentiller guralýan netijelerini görkezýär.</abstract_tr>
      <abstract_hy>Սկնդի կողմնականությունը հաճախ է տեղի ունենում ՆԼՊ-ի հիմնված ծրագրերում, հատկապես արտահայտվում է գենդերային լեզուներում: Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also due to unbalanced grammatical gender frequencies of inflected words.  Այս տեսակի կողմնականությունը ավելի ակնհայտ է դառնում խոսակցական արտահայտությունների ստեղծման մեջ, որտեղ գենդերն արտահայտվում են նախադասության մեջ, քանի որ ներկայիս ՆԼՊ ծրագրերի մեծ մասը դեռ աշխատում է նախադասության մակարդակի կո Որպես քայլ դեպի ավելի ներառող ՆԼՊ, այս թղթին առաջարկում է ավտոմատիկ և ընդհանուր վերագրելու մոտեցում կարճ հաղորդակցման նախադասությունների համար: Կարող է վերագրելու մեթոդը կիրառվել նախադասությունների համար, որոնք առանց ավելին նախադասությունների կոնտեքստի ունեն բազմաթիվ հավասար այլընտրանքներ գենդերային առումով: Մեթոդը կարող է կիրառվել սեռի հավասարակշռություն ունեցող արտադրությունների ստեղծման համար, ինչպես նաև սեռի հավասարակշռություն ունեցող ուսուցման տվյալների ստեղծման համար: Պատրաստված մոտեցումը հիմնված է նյարդային մեքենայի թարգմանման համակարգի վրա, որը պատրաստված է մեկ գենդերային այլընտրանքային թարգմանելու համար: Մոցակցության ավտոմատիկ և ձեռքի վերլուծությունները ցույց են տալիս խոստովանում արդյունքներ սեռի այլընտրանքային տարբերակների ավտոմատիկ սերնդի վերաբերյալ իսպաներեն խոսակցական նախադասությունների համար:</abstract_hy>
      <abstract_bn>এনএলপি-ভিত্তিক অ্যাপ্লিকেশনে লিঙ্গ বিয়াস প্রায়শ ঘটছে, বিশেষ করে লিঙ্গ-প্রভাবিত ভাষায় উল্লেখ করা হয়েছে। বিয়াস নির্দিষ্ট সংস্থার মাধ্যমে বিভিন্ন সংস্থার মাধ্যমে প্রকৃত প্রাকৃতিক লিঙ্গের মাধ্যমে দেখতে পারে, কিন্তু প্রভাবিত শব্দের অ এই ধরনের বিভিন্ন কথোপকথন বাক্য তৈরি করার জন্য বেশী পরিষ্কার হয়ে যায় যেখানে লিঙ্গ নির্দিষ্ট বাক্য নেই, কারণ বর্তমান এনএলপি অ্যাপলি এনএলপির মধ্যে আরো বেশী যোগাযোগের প্রতি একটি পদক্ষেপ হিসেবে এই পাতাটি স্বয়ংক্রিয় এবং সাধারণ আলোচনার বাক্যের জন্য পুনরা পুনঃলেখার পদ্ধতি প্রয়োগ করতে পারে যে লিঙ্গের ব্যাপারে বেশিরভাগ বিকল্প রয়েছে। এই পদ্ধতি প্রয়োগ করা যাবে যে লিঙ্গের মানসিক আউটপুট তৈরি করার জন্য এবং যৌন সম্পূর্ণ প্রশিক্ষণের তথ্য তৈরি করার জন্য। The proposed approach is based on a neural machine translation system trained to `translate' from one gender alternative to another.  এই প্রযুক্তির বিশ্লেষণের স্বয়ংক্রিয়ভাবে এবং হাতিয়াল বিশ্লেষণ উভয় স্প্যানিশ ভাষায় কথোপকথনীয় বাক্যের জন্য স্বয়ং</abstract_bn>
      <abstract_az>NLP-ə dayanan uyğulamalarda cins təsiri olaraq, əlbəttə cins təsiri dillərdə təsirli olaraq cürbəcür təsirlərdir. Bias bəzi adjektivlərin birlikləri ilə görünər və təbiətli cinslərin təbiəti ilə ismlərini animat edə bilər, lakin həmçinin təsirli sözlərin gramatik cinslərin frekvencilərinin də səbəbi olar. Bu cümlənin içində cins belirtilmədiyi müzakirə sözlərini yaratmaq üçün bu cümlənin çoxu NLP proqramları hələ də cümlənin səviyyəsində çalışır. Daha çox inklusiv NLP tərəfindən bir adım olaraq, bu kağıt qısa sözlər üçün avtomatik və general yeni yazılı tərəfindən təklif edir. Yenidən yazma metodumu cinsi olaraq çoxlu eynil alternatifi olmayan cümlələrə istifadə edilə bilər. Bu metod cins balançılıqları yaratmaq üçün və cins balançılıqları təhsil məlumatları yaratmaq üçün də istifadə edilə bilər. Bu təklif təklif, bir cins alternatifi ilə "tercümə" təhsil edilən nöral maşın tercümə sisteminə dayanılır. Bu tərzimin otomatik və manual analizi də İspanyol sözlərində müzakirə edən cins alternatifi olaraq təşkil edən nəticələri göstərir.</abstract_az>
      <abstract_am>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages.  ቢያዎች በአካባቢው የሥልጣዊ ውይይት እና የአፍሪካዊ የሥርዓት ውይይት ጋር ሊታይ ይችላል፣ ነገር ግን በተለያዩ የግራማቲካዊ የውይይት ቁጥጥር በጥያቄ ቃላት ነው፡፡ የሥርዓት ግንኙነት ውስጥ ያልታወቀ የውይይት ንግግር በመፍጠር ይታያል፡፡ ምክንያቱም አሁን ብዙዎቹ የNLP ፕሮግራሞች ገና በክፍለ-ደረጃ ውስጥ ይሠራሉ፡፡ የNLP አካባቢ ደረጃ እንዲሆን፣ ይህ ገጽ ለጥቂት የአካባቢ ንግግር ቃላት የራሳቸውን እና የዘላለም የጽሑፍ ሥርዓት ለመቀበል ያሳያል፡፡ የፊደል ጽሑፍ ሥርዓት፣ በጨዋታው አስተያየት ሳይኖር፣ በሴት ማሰናከል የተለያዩ ምርጫዎች አለባቸው፡፡ የሥርዓት ደረጃዎችን ለመፍጠር እና የሴቶችን ትክክል ማህበረሰብ ዳታ ለመፍጠር ይችላል፡፡ የተዘጋጀው ሥርዓት `ትርጉም' ከአንድ ጀምሮ ወደ ሌላ መተላለፊያ በሚያስተማርበት የናውሬው መሣሪያ ትርጉም ስርዓት በመሠረት ነው፡፡ የሥርዓት ትውልድ ለስፓኒስዊ ቃላት የተለየ የሴት ትውልድ መመለስ በሚያሳየው ውጤቶች እና በሐሳብ አስተያየት ነው፡፡</abstract_am>
      <abstract_ca>El bias de gènere és una ocorrència freqüent en aplicacions basades en NLP, especialment en llengües influïdes en gènere. Bias can appear through associations of certain adjectives and animate nouns with the natural gender of referents, but also due to unbalanced grammatical gender frequencies of inflected words.  Aquest tipus de bias esdevé més evident en generar expressions conversacionals on el gènere no es especifica dins la frase, perquè la majoria de les aplicacions actuals del NLP encara treballen en un context de nivell de frases. Com un pas cap a un NLP més inclusiu, aquest paper propon un enfocament automàtic i generalitzable de reescriptura per a frases de conversació curtes. El mètode de reescriptura es pot aplicar a frases que, sense contexte extra-sentencial, tenen múltiples alternatives equivalents en termes de gènere. El mètode es pot aplicar tant per crear productes equilibrats de gènere com per crear dades de formació equilibrades de gènere. L'enfocament proposat està basat en un sistema neuromàtic de traducció format per traduir d'una alternativa de gènere a l'altra. Tant l'anàlisi automàtica com manual de l'enfocament mostra resultats prometedors en relació a la generació automàtica d'alternatives de gènere per a frases conversacionals en espanyol.</abstract_ca>
      <abstract_cs>Gender bias je častý výskyt v aplikacích založených na NLP, zvláště výrazný v jazycích s vlivem pohlaví. Předsudek se může objevit prostřednictvím asociací určitých přídavných jmen a animovaných podstatných jmen s přirozeným pohlavím referentů, ale také kvůli nevyvážené gramatické genderové frekvenci zkloněných slov. Tento typ zaujatosti se stává zřetelnější při generování konverzačních projevů, kde pohlaví není specifikováno ve větě, protože většina současných aplikací NLP stále funguje na úrovni věty. Jako krok směrem k inkluzivnějšímu NLP, tento článek navrhuje automatický a obecně přepisovatelný přístup pro krátké konverzační věty. Metodu přepisu lze aplikovat na věty, které bez mimořádného kontextu mají více ekvivalentních alternativ z hlediska pohlaví. Metoda může být aplikována jak pro vytváření genderově vyvážených výstupů, tak pro vytváření genderově vyvážených údajů o odborném vzdělávání. Navržený přístup je založen na neuronovém strojovém překladu vycvičeném k "překladu" z jedné genderové alternativy do druhé. Automatická i manuální analýza přístupu ukazuje slibné výsledky s ohledem na automatické generování genderových alternativ pro konverzační věty ve španělštině.</abstract_cs>
      <abstract_bs>Ženska pristrasnost je često pojavljivanje aplikacija na temelju NLP-a, posebno proglašena na spolnim jezicima. Bias se može pojaviti kroz udruženje određenih adjektiva i animirati imena sa prirodnim spolom referenta, ali i zbog nepravednosti gramatične spolne frekvencije utjecaja riječi. Ova vrsta predrasude postaje očiglednije u stvaranju razgovornih govora gdje se spol ne određuje u rečenici, jer većin a trenutnih aplikacija NLP još uvijek radi na kontekstu razine rečenica. Kao korak ka uključujući NLP, ovaj papir predlaže automatski i generalni ponovno pisani pristup kratkim razgovornim re čenicama. Metod prepisanja se može primjenjivati na rečenice koje bez ekstra-sentencijalnog konteksta imaju višestruke ekvivalentne alternative u smislu spola. Metod se može primjenjivati i za stvaranje balanciranih ishoda spola, kao i za stvaranje podataka o balanciranoj obuci spola. Predloženi pristup se temelji na sustavu prevoda neuronskih strojeva obučenom na "prevod" od jedne alternative spola drugoj. I automatska i ručna analiza pristupa pokazuju obećavajuće rezultate u odnosu na automatsku generaciju alternativa spola za razgovorne rečenice na španjolskom.</abstract_bs>
      <abstract_et>Soolised eelarvamused esinevad sageli uue õppekava rakendustes, eriti väljenduvad sooliselt mõjutatud keeltes. Eelarvamused võivad tekkida teatud omadussõnade ja animaalsete nimisõnade seoste kaudu viidete loomuliku sooga, kuid ka paindlike sõnade grammatiliste soosageduste tasakaalustamata tõttu. Seda tüüpi eelarvamus muutub ilmsemaks vestlussõnade loomisel, kus soo lauses ei ole määratletud, sest enamik praegusi NLP rakendusi töötavad endiselt lausetasemel. Käesolevas dokumendis pakutakse sammuna kaasava uue õppekava suunas välja automaatne ja üldistatav ümberkirjutamine lühikeste vestluslausete jaoks. Ümberkirjutamise meetodit saab rakendada lausetele, millel ilma tundevälise kontekstita on sooliselt mitu samaväärset alternatiivi. Meetodit saab rakendada nii soolise tasakaalustatud väljundite loomiseks kui ka soolise tasakaalustatud koolitusandmete loomiseks. Kavandatud lähenemisviis põhineb masintõlkesüsteemil, mis on koolitatud tõlkima ühest soost teisele. Nii lähenemisviisi automaatne kui käsitsi analüüs näitab paljutõotavaid tulemusi seoses sooalternatiivide automaatse loomisega vestluslausete jaoks hispaaniakeelses keeles.</abstract_et>
      <abstract_fi>Sukupuolinen puolueellisuus esiintyy usein NLP-pohjaisissa sovelluksissa, erityisesti sukupuoleen vaikuttavilla kielillä. Bias voi ilmetä tiettyjen adjektiivien ja animaattien substantiivien yhteyksien kautta viittausten luonnolliseen sukupuoleen, mutta myös taivutettujen sanojen epäsymmetristen kielioppisten sukupuolitaajuuksien vuoksi. Tämäntyyppinen ennakkoluulo tulee näkyvämmäksi keskustelussa, jossa sukupuolta ei ole määritelty lauseessa, koska useimmat nykyiset NLP-sovellukset toimivat edelleen lausetason kontekstissa. Tässä asiakirjassa ehdotetaan automaattista ja yleistettävää uudelleenkirjoittamista lyhyille keskustelulauseille askel kohti osallistavampaa uutta oppimista. Uudelleenkirjoittamismenetelmää voidaan soveltaa lauseisiin, joilla ilman ylimääräistä tunnekontekstia on useita vastaavia vaihtoehtoja sukupuolen suhteen. Menetelmää voidaan soveltaa sekä sukupuolten tasapainoisten tulosten luomiseen että sukupuolten tasapainoisen koulutustiedon luomiseen. Ehdotettu lähestymistapa perustuu neurokonekäännösjärjestelmään, joka on koulutettu kääntämään sukupuolesta toiseen. Lähestymistavan automaattinen ja manuaalinen analyysi osoittavat lupaavia tuloksia espanjankielisten keskustelulauseiden automaattisessa generoinnissa.</abstract_fi>
      <abstract_jv>Gender bias mengko karo aplikasi NLP, supoyo urip kuwi kapan-kapan banget. Bias iso ngomong nek as챗n챗m챗n langgar-as챗n챗m챗n karo ndelok sing ng챗dol iki, nik as챗n챗m챗n langgar-as챗n챗m챗n karo perusahaan langgar y챗n챗m챗n. Tipe karo bias iki dadi kapan langkung rawuh akeh dumateng kapan pangan conversatif Tanggal kelompok liyane NLP luwih akeh, basa iki tentang tanggal nggawe gerakan tarjamahan karo perusahaan langkung nggawe gerakan akeh tarjamahan. Ngubah gambar nggambar kelas Metoh iso nggawe nggo yen nggawe Perintah Panjenengan langgar sami nggawe dadi nggawe Perintah Panjenengan Ndoleh sing supoyo nggunakake ing sistem tarjamahan, ingkang Neral, sing dikoleh kanggo 'translation' ning sampeyan Alternate kanggo saben. Bocah automatik lan manuk yang dipunaksi kanggo nganggo akeh langgar nganggo akeh sing nguasai gampang kanggo ngerayakno Manuk kanggo ngerayakno Manuk kanggo Kemerdekaan kanggo Kemerdekaan Winih</abstract_jv>
      <abstract_ha>@ info: whatsthis Bias can appeare through associations of some jurisdictive and animati with the natural genre of Reference, but also owa to an inganci of non-balanced grammatisk genre rates of genre-affirmative words. Wannan nau'in ɓangare ya fi bayyanawa a cikin mai ƙiƙiro magana na da za'a ƙayyade jinsi a cikin cewa, kwani da masu yawa na shiryoyin ayuka na NLP yanzu yi aiki a kan mazaɓa-daraja. Kama wata ƙõfa zuwa ga mafi ƙaranci da ke haɗa na NLP, wannan takardar na ƙayyade wata hanyor da farat ɗaya da mai iya iya rubũtãwa wa rubũtarwa kafin magana. @ action: button @ action: inmenu @ action: button Ana yi amfani da farat ɗaya da manual na nuna matsayin da ake yi wa'adi da matsala masu yi wa'adi game da zaɓen zaɓen mutane na farat ɗaya wa da aka yi masa magana cikin Isbanish.</abstract_ha>
      <abstract_sk>Spolna pristranskost se pogosto pojavlja pri aplikacijah, ki temeljijo na NLP, zlasti izrazito v jezikih, ki vplivajo na spol. Prizadevanja se lahko pojavijo preko asociacij določenih pridevnikov in animiranih samostalnikov z naravnim spolom referenc, pa tudi zaradi neuravnoteženih slovničnih spolnih frekvenc upognjenih besed. Ta vrsta pristranskosti postane bolj očitna pri ustvarjanju pogovornih izgovorov, kjer spol ni določen v stavku, saj večina trenutnih aplikacij NLP še vedno deluje na ravni stavka. Ta prispevek kot korak k bolj vključujočemu NLP predlaga avtomatičen in splošljiv pristop ponovnega pisanja za kratke govorne stavke. Metoda ponovnega pisanja se lahko uporablja za stavke, ki imajo brez zunanjega konteksta več enakovrednih alternativ glede na spol. Metoda se lahko uporablja tako za ustvarjanje uravnoteženih rezultatov med spoloma kot tudi za ustvarjanje uravnoteženih podatkov o usposabljanju med spoloma. Predlagani pristop temelji na nevronskem strojnem prevajalskem sistemu, usposobljenem za `prevajanje' iz enega spola v drugo. Tako avtomatična kot ročna analiza pristopa kaže obetavne rezultate glede avtomatične generacije spolnih alternativ za pogovorne stavke v španščini.</abstract_sk>
      <abstract_fil>Ang Gender bias ay madalas na nangyayari sa mga aplikasyon na nagbabago sa NLP, lalong lalo'y pronounced sa mga wikang pang-sex. Bias ay makapakita sa pamamagitan ng mga asosyasyon ng ilang adjectives at mga pangalan ng animo sa natural gender of referents, nguni't dahil din sa hindi balanse na grammatical gender frequencies ng mga salitang inflective. Itong uri ng bias ay lalong maliwanag sa paggawa ng mga salitang conversational kung saan ang género ay hindi inilagay sa loob ng sentence, sapagka't ang karamihan ng mga kasalukuyang applications ng NLP ay nagsisigawa pa sa isang konteksyon ng talaksang sentence-level. Parang step sa lalong inclusive NLP, ang paper na ito ay nagbibigay ng automatic at generalised re-writing approach para sa maliit na mga salitang conversational. Ang paraan ng pagsusulat ay maaaring isasagawa sa mga sentencial na walang extra-sentencial context, may maraming iba't iba't iba't iba't iba't iba't iba't iba't iba't iba't iba't iba. Ang paraan ay maaaring gamitin para sa paglikha ng mga balanse na outputs ng sexus at para sa paglikha ng mga datos ng pag-aaral ng sexus. Ang inilagay na paglapit ay based sa isang sistema ng paglilikat ng neural machine na natuturo sa `translate' mula sa isang alternatibo ng lahi sa iba. Ang automatik at manual analysis ng paglapit ay nagpapakita ng mga pangako na resulta tungkol sa automatik na generasyon ng mga alternatibo ng sexus para sa mga salitang salita sa Espaniol.</abstract_fil>
      <abstract_he>Gender bias is a frequent occurrence in NLP-based applications, especially pronounced in gender-inflected languages.  ביאס יכול להופיע באמצעות איגודים של אדיקטיבים מסויימים ואנימוסים שמות עם מין טבעי של רפורנטים, אבל גם בגלל תדירות גרמטיות לא מאוזנות של מילים שגורמות. This type of bias becomes more evident in generating conversational utterances where gender is not specified within the sentence, because most current NLP applications still work on a sentence-level context.  כצעד לכיוון NLP יותר כולל, העיתון הזה מציע גישה אוטומטית וגנרליזבית לכתיבה מחדש למשפטים שיחה קצרים. The rewriting method can be applied to sentences that, without extra-sentential context, have multiple equivalent alternatives in terms of gender.  השיטה יכולה להשתמש בין לייצור תוצאות מאוזנות מין וגם לייצור נתונים מאוזנים מין. הגישה המוצעת מבוססת על מערכת תרגום מכונת עצבית מאומנת לתרגם מאחר מין לאחר. הניתוח האוטומטי והידני של הגישה מראה תוצאות מבטיחות בנוגע לדור האוטומטי של אלטרנטיביות מין למשפטים שיחה בספרדית.</abstract_he>
      <abstract_bo>NLP ནང་དུ་Gender bias་ནི་ཆེས་སུ་འབྱུང་བར་ཆེ་བའི་ཉེར་སྤྱོད་རིགས་དང་ཁྱད་པར་ནས་སྐྱེས་པའི་སྐད་རིགས་ནང་གསལ་བཤད་ཡོད། དམིགས་བསལ་ཀྱི་སྤྱི་ཚོགས་དང་སྤྱི་ཚོགས་ཀྱི་ཆ་ཤས་ཀྱི་ཚོགས་རྣམས་མཐོང་ཐུབ་པས། འདི་ལྟ་བུ NLP ནང་དུ་ཡོད་པའི་ཤོག་བྱང་ཞིག་ལ་གྲངས་སུ་ཤོག་བྱང་འདིས་རང་འགུལ་གྱིས་དང་སྤྱིར་བཏང་བའི་བསྐྱར་འབྲི་ཐབས་ལམ་སྤྲོད་ཡོད།  བསྐྱར་འབྲི་བ་ཐབས་ལམ་དེ་ཚོར་བ་སྤྱོད་ཐུབ་པའི་ཚིག་རྟགས་གཞན་མེད་པའི་སྐབས་ཡུལ་ལ་འཇུག་སྤྱོད་ཐུབ་པ། ཐབས་ལམ་དེ་གཉིས་ཀྱིས་སྐྱེས་བ་དང་ཅུང་ཕྱོགས་གཉིས་ཀྱིས་བྱ་རིམ་བཟོ་བྱེད་སྟངས། འདི་ལྟ་བུ གནད་སྤྲོད་ཀྱི་རང་འགུལ་གྱིས་དང་ལག་བཟོས་ཐོག་གི་དབྱེ་ཞིབ་གཉིས་ཀྱིས་མཐུན་རྐྱེན་སྟངས་ལ་རང་འགུལ་གྱིས་མི་སྐྱེན་འདྲེན་གྱི་ར</abstract_bo>
      </paper>
    <paper id="12">
      <title>Second Order WinoBias (SoWinoBias) Test Set for Latent Gender Bias Detection in Coreference Resolution<fixed-case>W</fixed-case>ino<fixed-case>B</fixed-case>ias (<fixed-case>S</fixed-case>o<fixed-case>W</fixed-case>ino<fixed-case>B</fixed-case>ias) Test Set for Latent Gender Bias Detection in Coreference Resolution</title>
      <author><first>Hillary</first><last>Dawkins</last></author>
      <pages>103–111</pages>
      <abstract>We observe an instance of gender-induced bias in a downstream application, despite the absence of explicit gender words in the test cases. We provide a test set, SoWinoBias, for the purpose of measuring such latent gender bias in coreference resolution systems. We evaluate the performance of current debiasing methods on the SoWinoBias test set, especially in reference to the method’s design and altered embedding space properties. See https://github.com/hillary-dawkins/SoWinoBias.</abstract>
      <url hash="4a3028b8">2021.gebnlp-1.12</url>
      <doi>10.18653/v1/2021.gebnlp-1.12</doi>
      <bibkey>dawkins-2021-second</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/winobias">WinoBias</pwcdataset>
    <title_ar>مجموعة اختبار WinoBias (SoWinoBias) من الدرجة الثانية للكشف عن التحيز الكامن بين الجنسين في حل Coreference</title_ar>
      <title_es>Conjunto de pruebas WinObias de segundo orden (SoWiNobias) para la detección de sesgos de género latentes en la resolución de correferencia</title_es>
      <title_fr>Ensemble de tests WinObias de second ordre (SoWiNobias) pour la détection de biais de genre latent dans la résolution de coréférence</title_fr>
      <title_pt>Conjunto de teste WinoBias de segunda ordem (SoWinoBias) para detecção de viés de gênero latente na resolução de correferência</title_pt>
      <title_ja>コアリファレンス分解能における潜在的な性別バイアス検出のためのセカンドオーダーWinoBias (SoWinoBias)テストセット</title_ja>
      <title_zh>二阶 WinoBias (SoWinoBias) 试集,用于共推理解析中检测性别偏差</title_zh>
      <title_ru>Набор тестов WinoBias (SoWinoBias) второго порядка для обнаружения скрытой гендерной предвзятости в разрешении ядра</title_ru>
      <title_hi>दूसरा आदेश WinoBias (SoWinoBias) परीक्षण Coreference संकल्प में अव्यक्त लिंग पूर्वाग्रह का पता लगाने के लिए सेट</title_hi>
      <title_ukr>Набір тестів WinoBias другого порядку (SoWinoBias) для виявлення латентної гендерної упередженості в роздільної здатності ядра</title_ukr>
      <title_ga>Tacar Tástála WinoBias (SoWinoBias) den Dara hOrdú chun Laofacht Inscne Folaigh a Bhrath i Rún Croíthagartha</title_ga>
      <title_ka>მეორე წერტილი WinoBias (SoWinoBias) შემდეგ გენერი ბიოს განსაკუთრებისთვის ტესტის შესაძლებლობა</title_ka>
      <title_el>Σετ δοκιμής δεύτερης τάξης για την ανίχνευση λανθάνουσας προκατάλειψης φύλων στην επίλυση</title_el>
      <title_hu>Másodrendű WinoBias (SoWinoBias) tesztkészlet a későbbi nemi Bias felismeréséhez Coreferencia felbontásban</title_hu>
      <title_isl>VinoBias (SoWinoBias) prófssett í annarri röð til að greina síðustu kynbreytingar í samræmi</title_isl>
      <title_it>Set di prova WinoBias (SoWinoBias) di secondo ordine per la rilevazione latente di Bias di genere nella risoluzione di Coreference</title_it>
      <title_kk>Екінші рет WinoBias (SoWinoBias) сынақтары Кейінгі жалғыз екі реттік табу үшін Қосымшалық Айырымдылығында</title_kk>
      <title_mk>Тестот на втор ред Винобијас (SoWinoBias) за откривање подоцна на половина во резолуцијата на кореференција</title_mk>
      <title_lt>Antrosios eilės WinoBias (SoWinoBias) bandymų rinkinys, skirtas vėlesniam lyties pažeidimų nustatymui koreferencinėje rezoliucijoje</title_lt>
      <title_ms>Set Ujian WinoBias (SoWinoBias) Order Kedua untuk Pengesanan Bias Gender Latent dalam Resolusi Kesuaian</title_ms>
      <title_ml>രണ്ടാമത്തെ ഓര്‍ഡര്‍ വിനോബിയാസ് (സോവിനോബിയാസ്) പരീക്ഷണത്തിനായി കോര്‍ഫെന്‍സ് റിപ്പോര്‍ഷനിലെ അടുത്ത ജെന്‍റ് ബിയാസ്</title_ml>
      <title_mn>Хоёр дахь дараагийн дараагийн WinoBias (SoWinoBias) Сүүлчийн Сүүлчийн Дөрвөлжингийн Дөрвөлжингийн Шүүмжлэл дээр шалгалт</title_mn>
      <title_mt>Sett tat-Test tal-WinoBias tat-Tieni Ordni (SoWinoBias) għad-Detezzjoni Latent Gender Bias fir-Riżoluzzjoni tal-Koreferenza</title_mt>
      <title_pl>Zestaw testowy WinoBias drugiego rzędu (SoWinoBias) dla wykrywania uprzedzeń płciowych w rozdzielczości Coreference</title_pl>
      <title_no>Dette andre rekkefølgje WinoBias (SoWinoBias) testsett for seinare gjennomsikt i kjerneoppløysing</title_no>
      <title_ro>Setul de testare WinoBias (SoWinoBias) de ordin al doilea pentru detectarea biasului latent de gen în rezoluția corefenței</title_ro>
      <title_sr>Drugi red WinoBias (SoWinoBias) testiranje za kasno detektivno detektivno biće u rezoluciji korisnosti</title_sr>
      <title_so>Imtixaanka labaad ee WinoBias (SoWinoBias) Istixaanka ugu dambeeya jinsiga Bias Detection in Coreference Resolution</title_so>
      <title_ta>இரண்டாம் வரிசைப்படுத்தல் வினோபியாஸ் (சோவினோபியாஸ்) சோதனை செய்யவும் முறைமை திருத்தியில் தற்போதைய இனம் பியாவை கண்ட</title_ta>
      <title_ur>دوسری اوردر WinoBias (SoWinoBias) آزمائش سٹ کے لئے اچھی جنس دوئس آزمائش کے لئے</title_ur>
      <title_sv>Andra ordningen WinoBias (SoWinoBias) Test Set för Latent Kön Bias Detection i Coreference upplösning</title_sv>
      <title_si>දෙවෙනි පරීක්ෂණය WinoBias (SoWinoBias) පරීක්ෂණය සඳහා පරීක්ෂණය සඳහා පරීක්ෂණය</title_si>
      <title_uz>Comment</title_uz>
      <title_vi>Xét nghiệm A Lí Tiệc Thế Thứ hai cho phép xác định Giới thượng số trong giải quyết</title_vi>
      <title_da>Anden orden WinoBias (SoWinoBias) Test sæt til Latent Køn Bias detektion i Coreference opløsning</title_da>
      <title_bg>Тестов комплект от втори ред за откриване на латентни полови наклонности в резолюцията на кореференцията</title_bg>
      <title_hr>Drugi red WinoBias (SoWinoBias) testiranje postavljeno za kasno otkrivanje spolnih bića u rezoluciji korisnosti</title_hr>
      <title_nl>Tweede orde WinoBias (SoWinoBias) Test Set voor Latente Gender Bias Detectie in Coreference Resolutie</title_nl>
      <title_de>Second Order WinoBias (SoWinoBias) Test Set für latente Gender Bias Erkennung in Coreferenz Auflösung</title_de>
      <title_ko>모두 소해 중 잠재적 성별 편차 검측을 가리키는 2 단계 WinoBias(SoWinoBias) 테스트 세트</title_ko>
      <title_id>Set ujian WinoBias (SoWinoBias) Order Kedua untuk Deteksi Bias Gender Latent dalam Resolusi Koreference</title_id>
      <title_fa>تنظیم آزمایش دوم دستور WinoBias (SoWinoBias) برای آزمایش دوباره جنسی در راه حل پیشنهاد</title_fa>
      <title_sw>Tatizo la pili WinoBias</title_sw>
      <title_tr>Ikinji tertibine WinoBias (SoWinoBias) Soňky Jaňky Bias Taýýarlama Setirini Coreference Çözümleşdiriň</title_tr>
      <title_sq>Grupi i testit WinoBias (SoWinoBias) i rendit të dytë për zbulimin e mërzitjeve të gjinisë në zgjidhjen e korreferencës</title_sq>
      <title_af>Tweede Volgorde WinoBias (SoWinoBias) Toetsstel vir Latent Gender Bias Opdekking in Hoofferensresolusie</title_af>
      <title_am>የፊደል ቅርጽ ምርጫዎች</title_am>
      <title_hy>Կորեֆերնսի լուծումներում</title_hy>
      <title_bn>দ্বিতীয় ক্ষেত্র উইনোবিয়াস (সোউইনোবিয়াস) পরীক্ষা নির্ধারণ করুন কোরেফেন্সেন্স রিলিউশনের সাম্প্রতিক লিঙ্গ বিয়া</title_bn>
      <title_bs>Drugi red WinoBias (SoWinoBias) test postavljen za kasno otkrivanje spolnih bića u rezoluciji korisnosti</title_bs>
      <title_az>쒰歩湣椠卥祩爠坩湯䉩慳 卯坩湯䉩慳⤠卯湲慫쒱⁃즙湮즙琠쒰歩湣椠쒰歩湣椠쒰歩湣椠쒰歩湣椠쒰歩湣椠쒰歩湣椠쒰얟泉駅齤楲淉饫⁓敹楲椊</title_az>
      <title_ca>Enseny de segona ordre WinoBias (SoWinoBias) per a la detecció tardiva de bias de gènere en la resolució de coreferència</title_ca>
      <title_cs>Testovací sada WinoBias druhého řádu (SoWinoBias) pro detekci latentních genderových biasů v rozlišení Coreference</title_cs>
      <title_fi>Toisen asteen WinoBias (SoWinoBias) -testisarja latenttien sukupuolivääristymien havaitsemiseen Coreference-tarkkuudessa</title_fi>
      <title_et>Teise astme WinoBias (SoWinoBias) testkomplekt latentse soolise kalduvuse tuvastamiseks Coreference Resolutsioonis</title_et>
      <title_jv>Second order Wino Bias (SoWino Bias) Test Set for Last Gender Bias detection in corefern Resolution</title_jv>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_sk>Drugi red WinoBias (SoWinoBias) test set za zaznavanje latentne spolne pristranskosti v ločljivosti Coreference</title_sk>
      <title_fil>Pangalawang Order WinoBias (SoWinoBias) Test Set para sa Latest Gender Bias Detection sa Coreference Resolution</title_fil>
      <title_bo>Second Order WinoBias (SoWinoBias) Test Set for Latent Gender Bias Detection in Coreference Resolution</title_bo>
      <title_he>קבוצת מבחן WinoBias (SoWinoBias) של סדר שני לגלות סדר סדר סדר מאוחר</title_he>
      <abstract_pt>Observamos uma instância de viés induzido por gênero em uma aplicação a jusante, apesar da ausência de palavras de gênero explícitas nos casos de teste. Fornecemos um conjunto de teste, SoWinoBias, com o objetivo de medir esse viés de gênero latente em sistemas de resolução de correferência. Avaliamos o desempenho dos métodos atuais de despolarização no conjunto de testes SoWinoBias, especialmente em referência ao design do método e propriedades alteradas do espaço de incorporação. Veja https://github.com/hillary-dawkins/SoWinoBias.</abstract_pt>
      <abstract_ar>نلاحظ حالة من التحيز الناجم عن الجنس في تطبيق المصب ، على الرغم من عدم وجود كلمات صريحة تتعلق بالجنس في حالات الاختبار. نحن نقدم مجموعة اختبار ، SoWinoBias ، لغرض قياس مثل هذا التحيز الكامن بين الجنسين في أنظمة دقة المرجع. نقوم بتقييم أداء طرق إزالة الحواف الحالية على مجموعة اختبار SoWinoBias ، لا سيما فيما يتعلق بتصميم الطريقة وخصائص مساحة التضمين المعدلة. راجع https://github.com/hillary-dawkins/SoWinoBias.</abstract_ar>
      <abstract_es>Observamos un caso de sesgo inducido por género en una solicitud posterior, a pesar de la ausencia de palabras de género explícitas en los casos de prueba. Proporcionamos un conjunto de pruebas, SowInobias, con el fin de medir este sesgo de género latente en los sistemas de resolución de correferencias. Evaluamos el rendimiento de los métodos de debiasing actuales en el conjunto de pruebas SoWiNobias, especialmente en referencia al diseño del método y a las propiedades alteradas del espacio de incrustación. Consulte https://github.com/hillary-dawkins/SoWinoBias.</abstract_es>
      <abstract_fr>Nous observons un cas de biais sexiste dans une application en aval, malgré l'absence de mots sexistes explicites dans les cas de test. Nous fournissons un ensemble de tests, SoWinobias, dans le but de mesurer ce biais sexiste latent dans les systèmes de résolution de coréférence. Nous évaluons les performances des méthodes actuelles de dépolarisation sur l'ensemble de tests SowiNobias, en particulier en référence à la conception de la méthode et aux propriétés modifiées de l'espace d'enrobage. Voir https://github.com/hillary-dawkins/SoWinoBias.</abstract_fr>
      <abstract_ja>私たちは、テストケースに明示的なジェンダー単語がないにもかかわらず、下流のアプリケーションでジェンダー誘発バイアスの例を観察します。当社は、コアリファレンス解決システムにおける潜在的な性別バイアスを測定するためのテストセット、SoWinoBiasを提供しています。SoWinoBiasテストセット上の現在のデビアシングメソッドのパフォーマンスを評価します。特に、メソッドの設計と変更された埋め込みスペースのプロパティを参照してください。https://github.com/hillary-dawkins/SoWinoBiasを参照してください。</abstract_ja>
      <abstract_zh>余于下流应用程序中得偏见实例,虽试用例无明性别词。 供一试集,SoWinoBias以测共推理系统之偏见也。 估今去偏振法于SoWinoBias试集上性能,特参以意变者为性。 请参阅 https://github.com/hillary-dawkins/SoWinoBias。</abstract_zh>
      <abstract_hi>हम परीक्षण के मामलों में स्पष्ट लिंग शब्दों की अनुपस्थिति के बावजूद, डाउनस्ट्रीम एप्लिकेशन में लिंग-प्रेरित पूर्वाग्रह का एक उदाहरण देखते हैं। हम एक परीक्षण सेट, SoWinoBias प्रदान करते हैं, coreference संकल्प प्रणालियों में इस तरह के अव्यक्त लिंग पूर्वाग्रह को मापने के उद्देश्य से। हम SoWinoBias परीक्षण सेट पर वर्तमान debiasing विधियों के प्रदर्शन का मूल्यांकन करते हैं, विशेष रूप से विधि के डिजाइन और परिवर्तित एम्बेडिंग स्पेस गुणों के संदर्भ में। https://github.com/hillary-dawkins/SoWinoBias देखें।</abstract_hi>
      <abstract_ru>Мы наблюдаем случай гендерной предвзятости в последующем приложении, несмотря на отсутствие явных гендерных слов в тестовых случаях. Мы предоставляем тестовый набор, SoWinoBias, для измерения такой скрытой гендерной предвзятости в системах разрешения ядра. Мы оцениваем производительность текущих методов дебирования на тестовом наборе SoWinoBias, особенно в отношении дизайна метода и измененных свойств пространства вложений. См. https://github.com/hillary-dawkins/SoWinoBias.</abstract_ru>
      <abstract_ukr>Ми спостерігаємо випадок гендерно-індукованої упередженості в подальшому застосуванні, незважаючи на відсутність явних гендерних слів у тестових випадках. Ми надаємо тестовий набір SoWinoBias з метою вимірювання такої прихованої гендерної упередженості в системах роздільної здатності ядра. Ми оцінюємо продуктивність поточних методів зневадження на наборі тестів SoWinoBias, особливо стосовно дизайну методу та змінених властивостей простору вбудовування. Див. https://github.com/hillary-dawkins/SoWinoBias.</abstract_ukr>
      <abstract_ga>Breathnaímid ar chás de chlaonadh inscne-spreagtha i bhfeidhmchlár iartheachtacha, in ainneoin easpa focail inscne follasacha sna cásanna tástála. Cuirimid foireann tástála, SoWinoBias, ar fáil chun an claonadh folaigh sin inscne a thomhas i gcórais réitigh croíchomhdhála. Déanaimid measúnú ar fheidhmíocht na modhanna díchlaonta reatha ar thacar tástála SoWinoBias, go háirithe maidir le dearadh an mhodha agus airíonna spás leabaithe athraithe. Féach https://github.com/hillary-dawkins/SoWinoBias.</abstract_ga>
      <abstract_ka>ჩვენ შევხედავთ გენდრების ინდისტაციას, რომელიც შემდეგ გამოყენებული პროგრამებში, მაგრამ განსხვავებული გენდრების სიტყვების არსებობა ტესტის შემთხვევაში. ჩვენ შევცვალობთ, SoWinoBias-ს, რაც უნდა ამოზადოთ სენექტური გენექტური წარმოდგენების სისტემებში. ჩვენ მიმდინარე დებიზაციის გამოყენება SoWinoBias ტესტის შესახებ, განსაკუთრებით შესახებ მეთოდის განაზღვრება და შეცვლა სივრცე განსაზღვრება. ხედავთ https://github.com/hillary-dawkins/SoWinoBias.</abstract_ka>
      <abstract_el>Παρατηρούμε μια περίπτωση προκατάλειψης λόγω φύλου σε μεταγενέστερη εφαρμογή, παρά την απουσία ρητών λέξεων φύλου στις δοκιμαστικές περιπτώσεις. Παρέχουμε ένα σετ δοκιμών, SoWinoBias, με σκοπό τη μέτρηση αυτής της λανθάνουσας προκατάλειψης φύλου σε συστήματα ανάλυσης αλληλοδιαφορών. Αξιολογούμε την απόδοση των σημερινών μεθόδων απομάκρυνσης στο σετ δοκιμών ειδικά σε σχέση με το σχεδιασμό της μεθόδου και τις αλλοιωμένες ιδιότητες του χώρου ενσωμάτωσης. Δείτε https://github.com/hillary-dawkins/SoWinoBias.</abstract_el>
      <abstract_hu>Egy downstream alkalmazásban megfigyeljük a nemek által indukált elfogultság példáját, annak ellenére, hogy a tesztesetekben nincs explicit nemi szavak. Egy tesztkészletet, a SoWinoBias-t biztosítunk az ilyen látens nemi elfogultság mérésére a coreferencia felbontási rendszerekben. A SoWinoBias tesztkészleten értékeljük a jelenlegi debiasing módszerek teljesítményét, különös tekintettel a módszer kialakítására és megváltoztatott beágyazási tér tulajdonságaira. Lásd https://github.com/hillary-dawkins/SoWinoBias.</abstract_hu>
      <abstract_isl>Við sjáum tilvik af kynhvörfum tilhneigingu í eftirfarandi umsókn þrátt fyrir a ð ekki séu nákvæm kynorð í prófstilvikum. Við veitum prófssett, SoWinoBias, til þess a ð mæla slíkt leynilegt kynhneigð í samræmi upplausnarkerfi. Við meta framkvæmd núverandi dreifingaraðferða á SoWinoBias prófssettinu, s érstaklega með tilliti til hannunar aðferðarinnar og breyttra eiginleika innbyggingarhús s. Sjá https://github.com/hillary-dawkins/SoWinoBias.</abstract_isl>
      <abstract_it>Osserviamo un caso di bias indotto dal genere in un'applicazione a valle, nonostante l'assenza di parole esplicite di genere nei casi di test. Forniamo un set di test, SoWinoBias, allo scopo di misurare tali pregiudizi latenti di genere nei sistemi di risoluzione della coreferenza. Valutiamo le prestazioni degli attuali metodi di debiasing sul set di test SoWinoBias, in particolare in riferimento al design del metodo e alle proprietà alterate dello spazio di embedding. Vedi https://github.com/hillary-dawkins/SoWinoBias.</abstract_it>
      <abstract_lt>Atliekant tolesnę programą, nepaisant to, kad bandomosiose bylose nėra aiškių lyčių žodžių, pastebime lyčių sukeltos pusiausvyros atvejį. Pateikiame bandymų rinkinį, SoWinoBias, siekiant išmatuoti tokį latent in į lyčių pusiausvyrą koreferencijos pertvarkymo sistemose. Vertiname dabartinių debisavimo metodų veikimą SoWinoBias bandymų rinkinyje, ypač atsižvelgiant į metodo projektą ir pakeistas įdėjimo erdvės savybes. See  https://github.com/hillary-dawkins/SoWinoBias.</abstract_lt>
      <abstract_ms>Kami mengamati contoh bias disebabkan oleh jenis dalam aplikasi turun, walaupun tidak ada kata-kata seksual eksplicit dalam kes ujian. Kami menyediakan set ujian, SoWinoBias, untuk tujuan mengukur bias jenis tersembunyi dalam sistem resolusi persamaan. Kami menilai prestasi kaedah debiasing semasa pada set ujian SoWinoBias, terutama dalam rujukan kepada rancangan kaedah dan ciri-ciri ruang embedding yang diubah. Lihat https://github.com/hillary-dawkins/SoWinoBias.</abstract_ms>
      <abstract_kk>Біз гендердің көпшілігін бақылау бағдарламасында, сынақтарда таңдаған гендердің сөздері жоқ екенін қараймыз. Біз SoWinoBias сынақтарын таңдаймыз. Бұл жалғыз гендердің қарсылығын мөлдіру үшін, қарсылық шешу жүйелерінде. SoWinoBias сынақтағы кезіндегі дебияциялау әдістерін бағалаймыз, әсіресе әдісінің дизайны және ендіру бос орын қасиеттерін өзгерту үшін. Көру https://github.com/hillary-dawkins/SoWinoBias.</abstract_kk>
      <abstract_ml>പ്രത്യക്ഷപ്പെടുത്തുന്ന വാക്കുകള്‍ പരീക്ഷ കേസുകളില്‍ പ്രത്യക്ഷപ്പെടുത്തുന്നില്ലെങ്കിലും ഞങ്ങള്‍ ഒരു പ്രയോഗത്തില്‍ പെണ സോവിനോബിയാസ്, നമ്മള്‍ ഒരു പരീക്ഷണസെറ്റ് നല്‍കുന്നു, കോര്‍ഫനെന്‍സ് റിസ്റ്റല്‍ സിസ്റ്റമില്‍ നിന്നും സാമ്പത്തിലുള്ള സോവിനോബിയാസിന്റെ പരീക്ഷണത്തിന്റെ സെറ്റില്‍ നിലവിലുള്ള ഡിബബസിങ്ങ് രീതിയുടെ പ്രകടനത്തെ ഞങ്ങള്‍ വിലയിച്ചു കൊണ്ടിരിക്കുന് നോക്കുക https://github.com/hillary-dawkins/SoWinoBias.</abstract_ml>
      <abstract_mk>Набљудуваме пример на предрасуди предизвикани од полот во понатамошна апликација, и покрај отсуството на експлицитни зборови за полот во тестовите случаи. Ние обезбедуваме тест сет, СоВиноБиас, со цел да се мери ваква лајна полова пристрасност во системите за резолуција на современост. Ги проценуваме изведувањата на актуелните методи на дебизација на тестот СоWinoBias, особено во врска со дизајнот на методот и променетите вселенски сопствености. See  https://github.com/hillary-dawkins/SoWinoBias.</abstract_mk>
      <abstract_mn>Бид гендер сэтгэл хөдлөлтэй өрөөсгөл байдлыг шалгалтын тухайд тодорхой гендер үг байхгүй ч гэсэн бага зэрэг үздэг. Бид, SoWinoBias-ын шалгалтын комплексийг зөвшөөрөл шийдвэрлэлтийн системд ийм эсрэг гендерийн тухай хэмжээний зорилго хангадаг. Бид SoWinoBias-ын тест хэмжээнд орчин үеийн дебиазын үйл ажиллагааны үйл ажиллагааг үнэлдэг. Ялангуяа арга загварын загварын болон орон зайн өөрчлөлтийг өөрчилж чаддаг. Харах https://github.com/hillary-dawkins/SoWinoBias.</abstract_mn>
      <abstract_ro>Observăm un exemplu de părtinire indusă de gen într-o aplicație din aval, în ciuda absenței explicite de cuvinte de gen în cazurile de testare. Oferim un set de test, SoWinoBias, în scopul măsurării unei astfel de părtiniri latente de gen în sistemele de rezoluție a coreferenței. Evaluăm performanța metodelor actuale de debiasing pe setul de testare SoWinoBias, în special în ceea ce privește designul metodei și proprietățile modificate ale spațiului de încorporare. Vezi https://github.com/hillary-dawkins/SoWinoBias.</abstract_ro>
      <abstract_no>Vi observerer ein eksempel av seks-indusert forvirkning i eit nedtrekksprogram, selv om det ikkje finst eksplisitt seks-ord i testtilfellene. Vi tilbyr eit testsett, SoWinoBias, for å måle slike latent seks-forsikt i koreferansen-oppløysingssystemet. Vi evaluerer utviklinga av gjeldande debiasing- metodar på SoWinoBias- testen, spesielt i referanse til metodens design og endra innbyggingseigenskapar. Sjå https://github.com/hillary-dawkins/SoWinoBias.</abstract_no>
      <abstract_mt>Aħna ninservaw eżempju ta’ preġudizzju kkawżat mis-sessi f’applikazzjoni downstream, minkejja n-nuqqas ta’ kliem espliċitu dwar is-sessi fil-każijiet tat-test. Aħna nipprovdu sett tat-test, SoWinoBias, għall-fini tal-kejl ta’ tali preġudizzju latenti bejn is-sessi fis-sistemi ta’ riżoluzzjoni tal-koreferenza. Aħna jevalwaw il-prestazzjoni tal-metodi attwali ta’ debizzar fuq is-sett tat-test SoWinoBias, speċjalment b’referenza għad-disinn tal-metodu u l-proprjetajiet tal-ispazju ta’ inkorporazzjoni mibdula. Ara https://github.com/hillary-dawkins/SoWinoBias.</abstract_mt>
      <abstract_si>අපි පරීක්ෂණාවට ප්‍රශ්නයක් නැති විදියට පරීක්ෂණාවට ප්‍රශ්නයක් නැති විදියට පරීක්ෂණාවට පරීක්ෂණය කරනවා කි අපි පරීක්ෂණ සෙට් එකක් සොවිනෝබියාස් වෙනුවෙන්, අරමුණ වෙනුවෙන් එහෙම ලේටින් ජෙන්ඩර් ක්‍රියාත්මක විශේ අපි දැන් විදියට විදියට පරීක්ෂණය සඳහා විශේෂ විදියට විශේෂය කරන්නේ සොවිනෝබියාස් පරීක්ෂණයේ විදියට, විශේෂයෙ බලන්න https://github.com/hillary-dawkins/SoWinoBias.</abstract_si>
      <abstract_pl>Obserwujemy przypadek uprzedzeń związanych z płcią w dalszym zastosowaniu, pomimo braku wyraźnych słów płci w przypadkach testowych. Dostarczamy zestaw testowy, SoWinoBias, do celów pomiaru takich utajonych tendencji płci w systemach rozdzielczości współdzielczej. Oceniamy wydajność obecnych metod debiacingu na zestawie testowym SoWinoBias, w szczególności w odniesieniu do projektu metody i zmienionych właściwości przestrzeni osadzania. Zobacz https://github.com/hillary-dawkins/SoWinoBias.</abstract_pl>
      <abstract_so>Waxaynu fiirinaynaa tusaale ahaan baayacsiga jinsiga lagu sameeyo codsiga biyaha hoose, inkastoo a an la’a an in hadal cad oo jinsiga ah marka lagu imtixaamo. SoWinoBias, waxaynu sameynaa heer imtixaan, si aan u qiyaasno nidaamka qaybsiga hoose ee jinsiga. Waxaynu qiimeynaynaa muuqashada qaababka sasa ee baaritaanka ee SoWinoBias, khusuusan ku saabsan sawirada qaababka iyo waxyaabaha bedbeddelan ee goobta shaqada. Fiiri https://github.com/hillary-dawkins/SoWinoBias.</abstract_so>
      <abstract_sr>Primjetili smo primjer predrasude iz spola u nedavnom primjenu, uprkos nedostatku eksplicitih spolnih reči u testovima. Mi pružamo test set, SoWinoBias, za svrhu mjerenja takvih latentnih predrasuda spola u sistemima rješavanja pristojnosti. Procjenjujemo učinkovitost trenutnih metoda debijacije na setu SoWinoBias testa, posebno u odnosu na dizajn metode i promjenu svemirske vlasništva. Vidiš? https://github.com/hillary-dawkins/SoWinoBias.</abstract_sr>
      <abstract_ur>ہم آزمائش کاسٹوں میں صریح جنسی لفظ کے بغیر جنسی کی ایک مثال دیکھتے ہیں۔ ہم ایک امتحان مجموعہ بناتے ہیں، SoWinoBias، اس طرح لٹینٹ جنس کی مخالفت مطابق کرنا کے مطابق مطابق کریں گے. ہم نے SoWinoBias آزمائش سٹ پر موجود دبیزانگ طریقوں کی عملکرد کا ارزش کیا ہے، مخصوصاً طریقے کی طریقے کے ذریعہ اور تبدیل کئے گئے جگہ فضائی کے خاصات کے ذریعہ۔ دیکھو https://github.com/hillary-dawkins/SoWinoBias.</abstract_ur>
      <abstract_sv>Vi observerar ett exempel på könsinducerad bias i en efterföljande tillämpning, trots avsaknad av explicita könsord i testfallen. Vi tillhandahåller en testuppsättning, SoWinoBias, för att mäta sådan latent könsbias i coreference resolution system. Vi utvärderar prestandan hos nuvarande debiasing metoder på SoWinoBias testset, särskilt med hänvisning till metodens design och ändrade inbäddningsutrymmesegenskaper. Se https://github.com/hillary-dawkins/SoWinoBias.</abstract_sv>
      <abstract_ta>நாங்கள் ஒரு எடுத்துக்காட்டை பார்க்கிறோம் பெண்கள் சோதனைகளில் வெளிப்படையான பெண் வார்த்தைகள் இல்லையென்றாலும். சோவினோபியாஸ், நாம் ஒரு சோதனை அமைப்பை வழங்குகிறோம், சமீபத்திய பெண்ணியல் குறிப்பு தெளிவுத்திறன் அமைப்பில் அளக்க சோவினோபியாஸ் சோவினோபியாவின் சோதனையின் செயல்பாட்டின் செயல்பாட்டை நாம் மதிப்பிடுகிறோம், குறிப்பாக முறைமையின் வடிவமைப் பார் https://github.com/hillary-dawkins/SoWinoBias.</abstract_ta>
      <abstract_vi>Chúng tôi quan sát một ví dụ về khuynh hướng giới tính trong một ứng dụng xuôi dòng, mặc dù không có từ giới tính rõ ràng trong các vụ thử nghiệm. Chúng tôi cung cấp một bộ thử nghiệm, Soho Bians, để đo lường khuynh hướng giới tính tiềm ẩn trong hệ thống giải quyết hồng cầu. Chúng tôi đánh giá khả năng hiệu suất của phương pháp thao túng hiện thời trên bộ thử nghiệm Soho Bians, đặc biệt là dựa trên thiết kế của phương pháp và thay đổi tính chất xây dựng không gian. Xem. https://github.com/hillary-dawkins/SoWinoBias.</abstract_vi>
      <abstract_uz>Biz sinov holatlarida tajriba so'zlar mavjud emas bo'lganligini ko'rib turamiz. Biz soWinoBias, yangi jinsiyalar tizimini o'ylash uchun sinov tizimini o'ylaymiz. We evaluate the performance of current debiasing methods on the SoWinoBias test set, especially in reference to the method's design and altered embedding space properties.  Koʻrib chiqish https://github.com/hillary-dawkins/SoWinoBias.</abstract_uz>
      <abstract_bg>Наблюдаваме случай на индуцирано от пола пристрастие в приложение надолу по веригата, въпреки липсата на изрични полови думи в тестовите случаи. Ние предоставяме тестов комплект, за целите на измерването на такива латентни полови отклонения в системите за резолюция на кореференцията. Оценяваме ефективността на текущите методи за дебиазиране на тестовия комплект, особено по отношение на проектирането на метода и променените вградни пространствени свойства. Виж https://github.com/hillary-dawkins/SoWinoBias.</abstract_bg>
      <abstract_hr>Primjećujemo primjer predrasude iz spola u nedavnom primjenu, uprkos nedostatku jasnih spolnih riječi u testovima. Mi pružamo test set, SoWinoBias, za svrhu mjerenja takvih latentnih spolnih pristrasnosti u sustavima rješavanja pristojnosti. Procjenjujemo učinkovitost trenutnih metoda debijacije na setu SoWinoBias testa, posebno u odnosu na dizajn metode i izmjenu osvajanja svemirskih vlasništva. Vidiš? https://github.com/hillary-dawkins/SoWinoBias.</abstract_hr>
      <abstract_nl>We observeren een geval van gender-geïnduceerde bias in een downstream applicatie, ondanks de afwezigheid van expliciete genderwoorden in de testcases. We leveren een testset, SoWinoBias, om dergelijke latente gender bias in coreferentie resolutiesystemen te meten. We evalueren de prestaties van huidige debiasing methoden op de SoWinoBias test set, met name in verband met het ontwerp van de methode en gewijzigde embedding ruimte eigenschappen. Zie https://github.com/hillary-dawkins/SoWinoBias.</abstract_nl>
      <abstract_da>Vi observerer et eksempel på kønsinduceret bias i en downstream applikation, på trods af manglen på eksplicitte kønsord i testcasene. Vi leverer et testsæt, SoWinoBias, med det formål at måle sådanne latente kønsbias i coreferenceopløsningssystemer. Vi evaluerer ydeevnen af nuværende debiasing metoder på SoWinoBias testsættet, især med hensyn til metodens design og ændrede indlejringsrum egenskaber. Se https://github.com/hillary-dawkins/SoWinoBias.</abstract_da>
      <abstract_de>Wir beobachten einen Fall von geschlechtsinduzierter Verzerrung in einer nachgeschalteten Anwendung, obwohl in den Testfällen keine expliziten Geschlechterwörter vorhanden sind. Wir stellen einen Testsatz, SoWinoBias, zur Messung solcher latenten Gender Bias in Coreferenz-Auflösungssystemen zur Verfügung. Wir bewerten die Performance aktueller Debiasing-Methoden am SoWinoBias-Testsatz, insbesondere im Hinblick auf das Design der Methode und veränderte Einbettungsraumeigenschaften. Siehe https://github.com/hillary-dawkins/SoWinoBias.</abstract_de>
      <abstract_ko>우리는 테스트 용례에 명확한 성별어가 없지만 하위 응용 프로그램에서 성별이 편견을 유도하는 예를 관찰했다.Google은 시스템에 잠재되어 있는 성별 편견을 측정하는 테스트 세트 SoWinoBias를 제공합니다.우리는 SoWinoBias 테스트 세트에서 현재 debiasing 방법의 성능을 평가했는데 특히 이 방법의 디자인과 변경된 삽입 공간 속성에 대해 평가했다.보이다https://github.com/hillary-dawkins/SoWinoBias.</abstract_ko>
      <abstract_id>Kami mengamati contoh bias disebabkan oleh jenis dalam aplikasi turun, meskipun tidak ada kata-kata eksplicit jenis dalam kasus tes. Kami menyediakan set tes, SoWinoBias, untuk tujuan mengukur bias jenis tersembunyi dalam sistem resolusi koreferensi. Kami mengevaluasi prestasi dari metode debiasing saat ini pada set tes SoWinoBias, terutama dalam referensi pada desain metode dan perubahan properti ruang embedding. Lihat https://github.com/hillary-dawkins/SoWinoBias.</abstract_id>
      <abstract_fa>ما در یک کاربرد پایین، با وجود absence of explicit gender words in the test cases, یک نمونه از طبق طبق طبق طبق طبق جنسیت را مشاهده می کنیم. ما یک مجموعه آزمایش را برای اندازه اندازه‌گیری چنین قطعه جنسی در سیستم‌های حل‌سازی رضایت می‌کنیم، SoWinoBias. ما عملکرد روش‌های debiasing فعلی را در مجموعه آزمایش SoWinoBias ارزیابی می‌کنیم، مخصوصا در مورد طراحی روش و ویژگی‌های جامعه‌ای تغییر داده می‌شویم. ببين https://github.com/hillary-dawkins/SoWinoBias.</abstract_fa>
      <abstract_sw>Tunaona mfano wa upendeleo wa kijinsia katika matumizi ya mito ya chini, pamoja na kutokuwepo kwa maneno ya wazi ya kijinsia katika kesi za jaribio. Tunatoa seti ya majaribio, SoWinoBias, kwa lengo la kupima upendeleo wa kijinsia wa hivi karibuni katika mfumo wa utatuzi. Tunatathmini utendaji wa njia za sasa za mabadiliko katika kipimo cha jaribio la SoWinoBias, hasa kwa kuelekea ubunifu wa mbinu na mabadiliko ya utaalam wa anga. Tazama https://github.com/hillary-dawkins/SoWinoBias.</abstract_sw>
      <abstract_af>Ons aanhou 'n voorbeeld van geneem-induseerde voorbeeld in 'n onderstreem toepassing, ten ag van die absence van eksplisiese geneemwoorde in die toets gevalle. Ons verskaf 'n toets stel, SoWinoBias, vir die doel van die maat van sodanige latente gender bias in koreferensie oplossing stelsels. Ons evalueer die prestasie van huidige debiasing metodes op die SoWinoBias toets stel, veral in verwysing na die metode se ontwerp en verander inbêring spasieeienskappe. Kyk https://github.com/hillary-dawkins/SoWinoBias.</abstract_af>
      <abstract_sq>Ne vëzhgojmë një shembull të paragjykimit të shkaktuar nga gjini në një aplikim poshtë, pavarësisht nga mungesa e fjalëve të shprehura të gjinit në rastet e testit. Ne ofrojmë një grup testesh, SoWinoBias, për qëllim të matjes së një paragjykimi të tillë të fshehtë të gjinisë në sistemet e zgjidhjes së korreferencës. Ne vlerësojmë performancën e metodave aktuale të debizimit në grupin e testit SoWinoBias, veçanërisht në lidhje me dizajnin e metodës dhe të ndryshuarat pronësitë e hapësirës s ë përfshirjes. Shiko. https://github.com/hillary-dawkins/SoWinoBias.</abstract_sq>
      <abstract_am>በፈተናው ጉዳዮች ውስጥ ግልጾች የሴት ቃላት ምንም እንኳ ሳይኖር የሴት ውይይት የተደረገውን ብጤት እናደርጋለን፡፡ ሶዊንቦቢas፣ የቅርብ የውንዶች የሴሰኝነትን የግንኙነት አካባቢ ሲሞክር እናደርጋለን፡፡ የአሁኑን የስሕተት አካባቢዎችን በSoWinoBias ፈተና ላይ እናስተዋልታለን፣ በተለይም የሥርዓት ጥናት እና የተለወጠውን የስፋት ምርጫዎች በመጠየቅ ነው፡፡ ተመልከት https://github.com/hillary-dawkins/SoWinoBias.</abstract_am>
      <abstract_hy>Մենք դիտում ենք գենդերային կողմնականության օրինակ հետագա ծրագրում, չնայած արտահայտված գենդերային բառերի բացակայությունը թեստի դեպքերում: Մենք տրամադրում ենք փորձարկումներ, ՍոՎինոբիան, որպեսզի չափենք այդպիսի թաքնված գենդերային կողմնականությունը կորեֆերանսի լուծման համակարգերում: Մենք գնահատում ենք սովինոբիայի փորձարկումների ընթացքում ներկայիս թեքսիզացիայի մեթոդների արտադրողությունը, հատկապես վերաբերյալ մեթոդի դիզայնին և փոխված տիեզերքի հատկություններին: Տեսեք https://github.com/hillary-dawkins/SoWinoBias.</abstract_hy>
      <abstract_tr>Biz jentiller täsirli durmuşynyň bir nusgasyna seredýäris, diýmek durumlarda tans sözleri ýok bolsaňyz. SoWinoBias, diňe çözümleme sistemalarynda döwürmek üçin bir test setini temin edýäris. SoWinoBias testi düzeninde häzirki debiasing metodlaryň etkinleşigini çykarýarys, ýöne taýýarlamanyň dizaynynyň we içine girişim hasaplarynyň üstine çykarýarys. Gör https://github.com/hillary-dawkins/SoWinoBias.</abstract_tr>
      <abstract_bs>Primjetili smo primjer predrasude iz spola u nedovoljnom primjenu, uprkos nedostatku eksplicitih spolnih riječi u testovima. Mi pružamo test set, SoWinoBias, za cilj mjerenja takvih latentnih pristrasnosti spola u sistemima rješavanja pristojnosti. Procjenjujemo učinkovitost trenutnih metoda debijacije na setu SoWinoBias testa, posebno u odnosu na dizajn metode i promjenu osvajanja svemirskih vlasništva. Vidiš? https://github.com/hillary-dawkins/SoWinoBias.</abstract_bs>
      <abstract_bn>We observe an instance of gender-induced bias in a downstream application, despite the absence of explicit gender words in the test cases.  সোউইনোবিয়াস, আমরা একটি পরীক্ষা সেট প্রদান করি, যার উদ্দেশ্যে সাম্প্রতিক লিঙ্গের প্রতিক্রিয়া সিস্টেমে যুক্ত করা হয়। আমরা সোউইনোবিয়াস পরীক্ষায় বর্তমান বিভ্রান্ত পদ্ধতির কার্যক্রমের বিষয়টি মূল্যায়ন করি, বিশেষ করে এই পদ্ধতির ডিজাইন এবং বিভিন্ন স্থানের ব দেখুন https://github.com/hillary-dawkins/SoWinoBias.</abstract_bn>
      <abstract_az>Biz cins-induced bias örneğini sınamaq məqsədilə a çıq cins sözlərinin yoxduğu halda, aşağılıq bir uyğulamada görürük. Biz, SoWinoBias, bu cürbəcür cins bias ölçmək məqsədilə, bir test seti təyin edirik. SoWinoBias s ınama qutusunda ağımdaki debiasing metodların performansını değerləşdiririk, özellikle metodun dizaynı və uzay özelliklərini dəyişdiririk. Görün https://github.com/hillary-dawkins/SoWinoBias.</abstract_az>
      <abstract_ca>Observem un exemple de bias induït pel gènere en una aplicació avall, malgrat l'absència de paraules explícites de gènere en els casos de prova. Ens proporcionem un conjunt d'exàmens, SoWinoBias, per mesurar aquestes tendències latents de gènere en els sistemes de resolució de coreferencia. Evaluam el rendiment dels mètodes de debització actuals en el conjunt de proves SoWinoBias, especialment en relació al disseny del mètode i les propietats alterades d'espai d'incorporació. Veieu https://github.com/hillary-dawkins/SoWinoBias.</abstract_ca>
      <abstract_cs>V následující aplikaci pozorujeme případ pohlaví indukovaného zaujatosti, navzdory absenci explicitních genderových slov v testovacích případech. Poskytujeme testovací sadu SoWinoBias pro účely měření latentního genderového biasu v systémech koreferenčního rozlišení. Hodnotíme výkonnost současných metod debiazování na testovací sadě SoWinoBias, zejména s ohledem na návrh metody a pozměněné vlastnosti vloženého prostoru. Vidíte https://github.com/hillary-dawkins/SoWinoBias.</abstract_cs>
      <abstract_fi>Havaitsemme sukupuolen aiheuttaman puolueellisuuden tapauksen loppupään sovelluksessa, vaikka testitapauksissa ei ollut eksplisiittisiä sukupuolisanoja. Tarjoamme SoWinoBias-testisarjan tällaisen piilevän sukupuolivääristymän mittaamiseen koreferenssiresoluutiojärjestelmissä. Arvioimme SoWinoBias-testisarjan nykyisten debiaasimenetelmien suorituskykyä erityisesti menetelmän suunnittelun ja muokattujen upotustilaominaisuuksien osalta. Katso https://github.com/hillary-dawkins/SoWinoBias.</abstract_fi>
      <abstract_et>Vaatamata sellele, et testijuhtudel puuduvad selgesõnalised soolised sõnad, täheldame soost tingitud eelarvamuse juhtumit. Pakume testikomplekti SoWinoBias, mille eesmärk on mõõta sellist latentset soolise kalduvuse mõõtmist kortereferentsi resolutsioonisüsteemides. Hindame SoWinoBias katsekomplekti praeguste debiasimise meetodite toimivust, eriti lähtudes meetodi konstruktsioonist ja muudetud manustamisruumi omadustest. Vaata https://github.com/hillary-dawkins/SoWinoBias.</abstract_et>
      <abstract_jv>Awak dhéwé ngerasahan perbudhakan langgar-langgar wigatining nan aplikasi padha, nganggep kuwi kaluluh sing nyimpen kelas nang cukup. Awak dhéwé ngewehke pernik, SoWino Bias, nggo nggawe geraksi kanggo ngilangno sewis bias a kanggo ngilangno sistem sing nggawe gerakan. Awak dhéwé nggunian cara nggawe sistem debiansing wis nggawe SoWino Bias test nambah, supoyo nggawe tarjamahan karo design lan cage dipharrambaran space wis dipunangé. Delok https://github.com/hillary-dawkins/SoWinoBias.</abstract_jv>
      <abstract_he>אנו צופים במקרה של היחידות שנגרמו מהמין בתוכנית למטה, למרות העדר מילים מיניים ברורות במקרים המבחנים. We provide a test set, SoWinoBias, for the purpose of measuring such latent gender bias in coreference resolution systems.  אנו מעריכים את ההפעלה של שיטות השפלה הנוכחיות על קבוצת המבחנים של סווינוביאס, במיוחד בהקשר לעיצוב של השיטה ושינוי תכונות חלל. רואה? https://github.com/hillary-dawkins/SoWinoBias.</abstract_he>
      <abstract_ha>Kana ganin wani misali wanda aka yi wa sauri da jini a cikin shirin ayuka na ƙarami, kuma ingawa ba da wasu magana bayyananne na jinni cikin jarrabai. Tuna samar da jarrabi, SoWinoBias, don ka ƙayyade haske na sauri na mutane a cikin tsarin mafarata. Tuna ƙaddara game da shirin ayuka masu yin ɓarna a yanzu a kan jarraba-SoWinoBias, hasa'a, dõmin a bincike wa shirin ayuka da aka canza tsarin tsarin fili da aka shigar da shi. @ action https://github.com/hillary-dawkins/SoWinoBias.</abstract_ha>
      <abstract_sk>Pri nadaljnji aplikaciji opažamo primer pristranskosti zaradi spola, kljub odsotnosti eksplicitnih spolnih besed v testnih primerih. Nudimo testni komplet SoWinoBias za merjenje takšne latentne pristranskosti spola v sistemih ločljivosti koreference. Ocenjujemo učinkovitost trenutnih metod debiasiranja na testnem nizu SoWinoBias, zlasti glede na konstrukcijo metode in spremenjene lastnosti vgradnega prostora. Glej https://github.com/hillary-dawkins/SoWinoBias.</abstract_sk>
      <abstract_fil>Tinatanggap namin ang isang halimbawa ng pagbibigay ng lahi sa pagbibigay ng lahi, kahit walang explicit na salita ng lahi sa mga test cases. Nagbibigay kami ng isang test set, SoWinoBias, para sa panukala ng pagsukat ng ganyang latent na gender bias sa mga sistema ng resolusion ng coreference. Inabawasayan natin ang gawain ng kasalukuyang mga paraan ng debiasing sa SoWinoBias test set, lalong lalo na tungkol sa design ng paraan at baguhin ang mga propeta ng lugar na embedding. Tingnan mo... https://github.com/hillary-dawkins/SoWinoBias.</abstract_fil>
      <abstract_bo>ང་ཚོས་ཉེར་སྤྱོད་ཐོག་ཏུ་རང་ཉིད་ཀྱི་དབྱེ་རིམ་གྱི་དཔེར་བརྗོད་པ་ཞིག་ལྟ་རྟོགས། ང་ཚོས་གཞུང་ལ་བརྟག་དཔྱད་ཞིག་བྱས་པ་ཡིན། SoWinoBias་ནི་དམིགས་ཡུལ་འདི་དག་གི་རྐྱེན་མེད་སྟངས་གཟུགས་རིས་མེད་པའི་ཚོ We evaluate the performance of current debiasing method s on the SoWinoBias test set, especially in reference to the method's design and altered embedding space properties. ལྟ་ཀློག https://github.com/hillary-dawkins/SoWinoBias.</abstract_bo>
      </paper>
  </volume>
</collection>