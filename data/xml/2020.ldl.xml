<collection id="2020.ldl">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)</booktitle>
      <editor><first>Maxim</first><last>Ionov</last></editor>
      <editor><first>John P.</first><last>McCrae</last></editor>
      <editor><first>Christian</first><last>Chiarcos</last></editor>
      <editor><first>Thierry</first><last>Declerck</last></editor>
      <editor><first>Julia</first><last>Bosque-Gil</last></editor>
      <editor><first>Jorge</first><last>Gracia</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-36-8</isbn>
    </meta>
    <frontmatter>
      <url hash="f15e978d">2020.ldl-1.0</url>
      <bibkey>ldl-2020-linked</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Transforming the Cologne Digital <fixed-case>S</fixed-case>anskrit Dictionaries into <fixed-case>O</fixed-case>nto<fixed-case>L</fixed-case>ex-Lemon</title>
      <author><first>Francisco</first><last>Mondaca</last></author>
      <author><first>Felix</first><last>Rau</last></author>
      <pages>11&#8211;14</pages>
      <abstract>The Cologne Digital Sanskrit Dictionaries (CDSD) is a large collection of complex digitized Sanskrit dictionaries, consisting of over thirty-five works, and is the most prominent collection of Sanskrit dictionaries worldwide. In this paper we evaluate two methods for transforming the CDSD into Ontolex-Lemon based on a modelling exercise. The first method that we evaluate consists of applying RDFa to the existent TEI-P5 files. The second method consists of transforming the TEI-encoded dictionaries into new files containing RDF triples modelled in OntoLex-Lemon. As a result of the modelling exercise we choose the second method: to transform TEI-encoded lexical data into Ontolex-Lemon by creating new files containing exclusively RDF triples.</abstract>
      <url hash="7bb4408c">2020.ldl-1.2</url>
      <language>eng</language>
      <bibkey>mondaca-rau-2020-transforming</bibkey>
    </paper>
    <paper id="7">
      <title>Challenges of Word Sense Alignment: <fixed-case>P</fixed-case>ortuguese Language Resources</title>
      <author><first>Ana</first><last>Salgado</last></author>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <author><first>Alberto</first><last>Sim&#245;es</last></author>
      <author><first>John Philip</first><last>McCrae</last></author>
      <author><first>Rute</first><last>Costa</last></author>
      <pages>45&#8211;51</pages>
      <abstract>This paper reports on an ongoing task of monolingual word sense alignment in which a comparative study between the Portuguese Academy of Sciences Dictionary and the Dicion&#225;rio Aberto is carried out in the context of the ELEXIS (European Lexicographic Infrastructure) project. Word sense alignment involves searching for matching senses within dictionary entries of different lexical resources and linking them, which poses significant challenges. The lexicographic criteria are not always entirely consistent within individual dictionaries and even less so across different projects where different options may have been assumed in terms of structure and especially wording techniques of lexicographic glosses. This hinders the task of matching senses. We aim to present our annotation workflow in Portuguese using the Semantic Web technologies. The results obtained are useful for the discussion within the community.</abstract>
      <url hash="71ecc019">2020.ldl-1.7</url>
      <language>eng</language>
      <bibkey>salgado-etal-2020-challenges</bibkey>
    </paper>
    <paper id="12">
      <title>Lexemes in <fixed-case>W</fixed-case>ikidata: 2020 status</title>
      <author><first>Finn</first><last>Nielsen</last></author>
      <pages>82&#8211;86</pages>
      <abstract>Wikidata now records data about lexemes, senses and lexical forms and exposes them as Linguistic Linked Open Data. Since lexemes in Wikidata was first established in 2018, this data has grown considerable in size. Links between lexemes in different languages can be made, e.g., through a derivation property or senses. We present some descriptive statistics about the lexemes of Wikidata, focusing on the multilingual aspects and show that there are still relatively few multilingual links.</abstract>
      <url hash="0d0fdd66">2020.ldl-1.12</url>
      <language>eng</language>
      <bibkey>nielsen-2020-lexemes</bibkey>
    </paper>
  </volume>
</collection>