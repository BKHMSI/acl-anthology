<collection id="J19">
  <volume id="1">
    <meta>
      <booktitle>Computational Linguistics, Volume 45, Issue 1 - March 2019</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>March</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <bibkey>cl-2019-linguistics</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Parsing <fixed-case>C</fixed-case>hinese Sentences with Grammatical Relations</title>
      <author><first>Weiwei</first><last>Sun</last></author>
      <author><first>Yufei</first><last>Chen</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <author><first>Meichun</first><last>Liu</last></author>
      <doi>10.1162/coli_a_00343</doi>
      <abstract>We report our work on building linguistic resources and data-driven parsers in the grammatical relation (GR) analysis for Mandarin Chinese. Chinese, as an analytic language, encodes grammatical information in a highly configurational rather than morphological way. Accordingly, it is possible and reasonable to represent almost all grammatical relations as bilexical dependencies. In this work, we propose to represent grammatical information using general directed dependency graphs. Both only-local and rich long-distance dependencies are explicitly represented. To create high-quality annotations, we take advantage of an existing TreeBank, namely, Chinese TreeBank (CTB), which is grounded on the Government and Binding theory. We define a set of linguistic rules to explore CTB&#8217;s implicit phrase structural information and build deep dependency graphs. The reliability of this linguistically motivated GR extraction procedure is highlighted by manual evaluation. Based on the converted corpus, data-driven, including graph- and transition-based, models are explored for Chinese GR parsing. For graph-based parsing, a new perspective, graph merging, is proposed for building flexible dependency graphs: constructing complex graphs via constructing simple subgraphs. Two key problems are discussed in this perspective: (1) how to decompose a complex graph into simple subgraphs, and (2) how to combine subgraphs into a coherent complex graph. For transition-based parsing, we introduce a neural parser based on a list-based transition system. We also discuss several other key problems, including dynamic oracle and beam search for neural transition-based parsing. Evaluation gauges how successful GR parsing for Chinese can be by applying data-driven models. The empirical analysis suggests several directions for future study.</abstract>
      <pages>95&#8211;136</pages>
      <url hash="673f5e48">J19-1003</url>
      <bibkey>sun-etal-2019-parsing</bibkey>
    </paper>
    <paper id="4">
      <title>Automatic Inference of Sound Correspondence Patterns across Multiple Languages</title>
      <author><first>Johann-Mattis</first><last>List</last></author>
      <doi>10.1162/coli_a_00344</doi>
      <abstract>Sound correspondence patterns play a crucial role for linguistic reconstruction. Linguists use them to prove language relationship, to reconstruct proto-forms, and for classical phylogenetic reconstruction based on shared innovations. Cognate words that fail to conform with expected patterns can further point to various kinds of exceptions in sound change, such as analogy or assimilation of frequent words. Here I present an automatic method for the inference of sound correspondence patterns across multiple languages based on a network approach. The core idea is to represent all columns in aligned cognate sets as nodes in a network with edges representing the degree of compatibility between the nodes. The task of inferring all compatible correspondence sets can then be handled as the well-known minimum clique cover problem in graph theory, which essentially seeks to split the graph into the smallest number of cliques in which each node is represented by exactly one clique. The resulting partitions represent all correspondence patterns that can be inferred for a given data set. By excluding those patterns that occur in only a few cognate sets, the core of regularly recurring sound correspondences can be inferred. Based on this idea, the article presents a method for automatic correspondence pattern recognition, which is implemented as part of a Python library which supplements the article. To illustrate the usefulness of the method, I present how the inferred patterns can be used to predict words that have not been observed before.</abstract>
      <pages>137&#8211;161</pages>
      <url hash="22f63a92">J19-1004</url>
      <bibkey>list-2019-automatic</bibkey>
      <pwccode url="https://github.com/lingpy/lingrex" additional="true">lingpy/lingrex</pwccode>
    </paper>
    <paper id="5">
      <title>A Sequential Matching Framework for Multi-Turn Response Selection in Retrieval-Based Chatbots</title>
      <author><first>Yu</first><last>Wu</last></author>
      <author><first>Wei</first><last>Wu</last></author>
      <author><first>Chen</first><last>Xing</last></author>
      <author><first>Can</first><last>Xu</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <doi>10.1162/coli_a_00345</doi>
      <abstract>We study the problem of response selection for multi-turn conversation in retrieval-based chatbots. The task involves matching a response candidate with a conversation context, the challenges for which include how to recognize important parts of the context, and how to model the relationships among utterances in the context. Existing matching methods may lose important information in contexts as we can interpret them with a unified framework in which contexts are transformed to fixed-length vectors without any interaction with responses before matching. This motivates us to propose a new matching framework that can sufficiently carry important information in contexts to matching and model relationships among utterances at the same time. The new framework, which we call a sequential matching framework (SMF), lets each utterance in a context interact with a response candidate at the first step and transforms the pair to a matching vector. The matching vectors are then accumulated following the order of the utterances in the context with a recurrent neural network (RNN) that models relationships among utterances. Context-response matching is then calculated with the hidden states of the RNN. Under SMF, we propose a sequential convolutional network and sequential attention network and conduct experiments on two public data sets to test their performance. Experiment results show that both models can significantly outperform state-of-the-art matching methods. We also show that the models are interpretable with visualizations that provide us insights on how they capture and leverage important information in contexts for matching.</abstract>
      <pages>163&#8211;197</pages>
      <url hash="1a517ee4">J19-1005</url>
      <bibkey>wu-etal-2019-sequential</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/douban">Douban</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/douban-conversation-corpus">Douban Conversation Corpus</pwcdataset>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Computational Linguistics, Volume 45, Issue 2 - June 2019</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    </volume>
  <volume id="3">
    <meta>
      <booktitle>Computational Linguistics, Volume 45, Issue 3 - September 2019</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>September</month>
      <year>2019</year>
    </meta>
    </volume>
  <volume id="4">
    <meta>
      <booktitle>Computational Linguistics, Volume 45, Issue 4 - December 2019</booktitle>
      <publisher>MIT Press</publisher>
      <address>Cambridge, MA</address>
      <month>December</month>
      <year>2019</year>
    </meta>
    </volume>
</collection>