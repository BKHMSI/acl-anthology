<collection id="2021.law">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of The Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop</booktitle>
      <editor><first>Claire</first><last>Bonial</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="45004721">2021.law-1.0</url>
      <bibkey>law-2021-joint</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Representing Implicit Positive Meaning of Negated Statements in <fixed-case>AMR</fixed-case></title>
      <author><first>Katharina</first><last>Stein</last></author>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <pages>23&#8211;35</pages>
      <abstract>Abstract Meaning Representation (AMR) has become popular for representing the meaning of natural language in graph structures. However, AMR does not represent scope information, posing a problem for its overall expressivity and specifically for drawing inferences from negated statements. This is the case with so-called &#8220;positive interpretations&#8221; of negated statements, in which implicit positive meaning is identified by inferring the opposite of the negation&#8217;s focus. In this work, we investigate how potential positive interpretations (PPIs) can be represented in AMR. We propose a logically motivated AMR structure for PPIs that makes the focus of negation explicit and sketch an initial proposal for a systematic methodology to generate this more expressive structure.</abstract>
      <url hash="375da95b">2021.law-1.3</url>
      <bibkey>stein-donatelli-2021-representing</bibkey>
      <doi>10.18653/v1/2021.law-1.3</doi>
    </paper>
    <paper id="5">
      <title>Can predicate-argument relationships be extracted from <fixed-case>UD</fixed-case> trees?</title>
      <author><first>Adam</first><last>Ek</last></author>
      <author><first>Jean-Philippe</first><last>Bernardy</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <pages>46&#8211;55</pages>
      <abstract>In this paper we investigate the possibility of extracting predicate-argument relations from UD trees (and enhanced UD graphs). Con- cretely, we apply UD parsers on an En- glish question answering/semantic-role label- ing data set (FitzGerald et al., 2018) and check if the annotations reflect the relations in the resulting parse trees, using a small number of rules to extract this information. We find that 79.1% of the argument-predicate pairs can be found in this way, on the basis of Ud- ify (Kondratyuk and Straka, 2019). Error anal- ysis reveals that half of the error cases are at- tributable to shortcomings in the dataset. The remaining errors are mostly due to predicate- argument relations not being extractible algo- rithmically from the UD trees (requiring se- mantic reasoning to be resolved). The parser itself is only responsible for a small portion of errors. Our analysis suggests a number of improvements to the UD annotation schema: we propose to enhance the schema in four ways, in order to capture argument-predicate relations. Additionally, we propose improve- ments regarding data collection for question answering/semantic-role labeling data.</abstract>
      <url hash="37166656">2021.law-1.5</url>
      <bibkey>ek-etal-2021-predicate</bibkey>
      <doi>10.18653/v1/2021.law-1.5</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>Classifying Divergences in Cross-lingual <fixed-case>AMR</fixed-case> Pairs</title>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>56&#8211;65</pages>
      <abstract>Translation divergences are varied and widespread, challenging approaches that rely on parallel text. To annotate translation divergences, we propose a schema grounded in the Abstract Meaning Representation (AMR), a sentence-level semantic framework instantiated for a number of languages. By comparing parallel AMR graphs, we can identify specific points of divergence. Each divergence is labeled with both a type and a cause. We release a small corpus of annotated English-Spanish data, and analyze the annotations in our corpus.</abstract>
      <url hash="375d34f8">2021.law-1.6</url>
      <bibkey>wein-schneider-2021-classifying</bibkey>
      <doi>10.18653/v1/2021.law-1.6</doi>
      <pwccode url="https://github.com/shirawein/spanish-english-amr-corpus" additional="false">shirawein/spanish-english-amr-corpus</pwccode>
    </paper>
    <paper id="10">
      <title>Subcategorizing Adverbials in <fixed-case>U</fixed-case>niversal <fixed-case>C</fixed-case>onceptual <fixed-case>C</fixed-case>ognitive <fixed-case>A</fixed-case>nnotation</title>
      <author><first>Zhuxin</first><last>Wang</last></author>
      <author><first>Jakob</first><last>Prange</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>96&#8211;105</pages>
      <abstract>Universal Conceptual Cognitive Annotation (UCCA) is a semantic annotation scheme that organizes texts into coarse predicate-argument structure, offering broad coverage of semantic phenomena. At the same time, there is still need for a finer-grained treatment of many of the categories. The Adverbial category is of special interest, as it covers a wide range of fundamentally different meanings such as negation, causation, aspect, and event quantification. In this paper we introduce a refinement annotation scheme for UCCA&#8217;s Adverbial category, showing that UCCA Adverbials can indeed be subcategorized into at least 7 semantic types, and doing so can help clarify and disambiguate the otherwise coarse-grained labels. We provide a preliminary set of annotation guidelines, as well as pilot annotation experiments with high inter-annotator agreement, confirming the validity of the scheme.</abstract>
      <url hash="b9971d4a">2021.law-1.10</url>
      <bibkey>wang-etal-2021-subcategorizing</bibkey>
      <doi>10.18653/v1/2021.law-1.10</doi>
    </paper>
    <paper id="18">
      <title><fixed-case>W</fixed-case>iki<fixed-case>GUM</fixed-case>: Exhaustive Entity Linking for Wikification in 12 Genres</title>
      <author><first>Jessica</first><last>Lin</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>170&#8211;175</pages>
      <abstract>Previous work on Entity Linking has focused on resources targeting non-nested proper named entity mentions, often in data from Wikipedia, i.e. Wikification. In this paper, we present and evaluate WikiGUM, a fully wikified dataset, covering all mentions of named entities, including their non-named and pronominal mentions, as well as mentions nested within other mentions. The dataset covers a broad range of 12 written and spoken genres, most of which have not been included in Entity Linking efforts to date, leading to poor performance by a pretrained SOTA system in our evaluation. The availability of a variety of other annotations for the same data also enables further research on entities in context.</abstract>
      <url hash="a46c418a">2021.law-1.18</url>
      <bibkey>lin-zeldes-2021-wikigum</bibkey>
      <doi>10.18653/v1/2021.law-1.18</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/gum">GUM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nne">NNE</pwcdataset>
    </paper>
  </volume>
</collection>