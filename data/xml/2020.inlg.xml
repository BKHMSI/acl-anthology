<collection id="2020.inlg">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Natural Language Generation</booktitle>
      <editor><first>Brian</first><last>Davis</last></editor>
      <editor><first>Yvette</first><last>Graham</last></editor>
      <editor><first>John</first><last>Kelleher</last></editor>
      <editor><first>Yaji</first><last>Sripada</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dublin, Ireland</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="c03367d5">2020.inlg-1.0</url>
      <revision id="1" href="2020.inlg-1.0v1" hash="0cd95e3d" />
      <revision id="2" href="2020.inlg-1.0v2" hash="c03367d5" date="2021-04-26">Added missing sponsor and made changes to the organizational committee.</revision>
      <bibkey>inlg-2020-international</bibkey>
    </frontmatter>
    <paper id="8">
      <title>Assessing Discourse Relations in Language Generation from <fixed-case>GPT</fixed-case>-2</title>
      <author><first>Wei-Jen</first><last>Ko</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <pages>52&#8211;59</pages>
      <abstract>Recent advances in NLP have been attributed to the emergence of large-scale pre-trained language models. GPT-2, in particular, is suited for generation tasks given its left-to-right language modeling objective, yet the linguistic quality of its generated text has largely remain unexplored. Our work takes a step in understanding GPT-2&#8217;s outputs in terms of discourse coherence. We perform a comprehensive study on the validity of explicit discourse relations in GPT-2&#8217;s outputs under both organic generation and fine-tuned scenarios. Results show GPT-2 does not always generate text containing valid discourse relations; nevertheless, its text is more aligned with human expectation in the fine-tuned scenario. We propose a decoupled strategy to mitigate these problems and highlight the importance of explicitly modeling discourse information.</abstract>
      <url hash="de60e57f">2020.inlg-1.8</url>
      <bibkey>ko-li-2020-assessing</bibkey>
    </paper>
    <paper id="10">
      <title>The <fixed-case>CACAPO</fixed-case> Dataset: A Multilingual, Multi-Domain Dataset for Neural Pipeline and End-to-End Data-to-Text Generation</title>
      <author><first>Chris</first><last>van der Lee</last></author>
      <author><first>Chris</first><last>Emmery</last></author>
      <author><first>Sander</first><last>Wubben</last></author>
      <author><first>Emiel</first><last>Krahmer</last></author>
      <pages>68&#8211;79</pages>
      <abstract>This paper describes the CACAPO dataset, built for training both neural pipeline and end-to-end data-to-text language generation systems. The dataset is multilingual (Dutch and English), and contains almost 10,000 sentences from human-written news texts in the sports, weather, stocks, and incidents domain, together with aligned attribute-value paired data. The dataset is unique in that the linguistic variation and indirect ways of expressing data in these texts reflect the challenges of real world NLG tasks.</abstract>
      <url hash="6218b1e2">2020.inlg-1.10</url>
      <attachment type="Supplementary_Attachment" hash="e55d25a7">2020.inlg-1.10.Supplementary_Attachment.pdf</attachment>
      <bibkey>van-der-lee-etal-2020-cacapo</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/rotowire">RotoWire</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/webnlg">WebNLG</pwcdataset>
    </paper>
    <paper id="15">
      <title><fixed-case>D</fixed-case>a<fixed-case>M</fixed-case>ata: A Robot-Journalist Covering the <fixed-case>B</fixed-case>razilian <fixed-case>A</fixed-case>mazon Deforestation</title>
      <author><first>Andr&#233; Luiz</first><last>Rosa Teixeira</last></author>
      <author><first>Jo&#227;o</first><last>Campos</last></author>
      <author><first>Rossana</first><last>Cunha</last></author>
      <author><first>Thiago</first><last>Castro Ferreira</last></author>
      <author><first>Adriana</first><last>Pagano</last></author>
      <author><first>Fabio</first><last>Cozman</last></author>
      <pages>103&#8211;106</pages>
      <abstract>This demo paper introduces DaMata, a robot-journalist covering deforestation in the Brazilian Amazon. The robot-journalist is based on a pipeline architecture of Natural Language Generation, which yields multilingual daily and monthly reports based on the public data provided by DETER, a real-time deforestation satellite monitor developed and maintained by the Brazilian National Institute for Space Research (INPE). DaMata automatically generates reports in Brazilian Portuguese and English and publishes them on the Twitter platform. Corpus and code are publicly available.</abstract>
      <url hash="2aee9bfe">2020.inlg-1.15</url>
      <bibkey>rosa-teixeira-etal-2020-damata</bibkey>
      <pwccode url="https://github.com/botsdobem/demo_inpe_covid" additional="false">botsdobem/demo_inpe_covid</pwccode>
    </paper>
    <paper id="18">
      <title><fixed-case>PARENT</fixed-case>ing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation</title>
      <author><first>Clement</first><last>Rebuffel</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <author><first>Geoffrey</first><last>Scoutheeten</last></author>
      <author><first>Patrick</first><last>Gallinari</last></author>
      <pages>120&#8211;130</pages>
      <abstract>In language generation models conditioned by structured data, the classical training via maximum likelihood almost always leads models to pick up on dataset divergence (i.e., hallucinations or omissions), and to incorporate them erroneously in their own generations at inference. In this work, we build on top of previous Reinforcement Learning based approaches and show that a model-agnostic framework relying on the recently introduced PARENT metric is efficient at reducing both hallucinations and omissions. Evaluations on the widely used WikiBIO and WebNLG benchmarks demonstrate the effectiveness of this framework compared to state-of-the-art models.</abstract>
      <url hash="5dfd3607">2020.inlg-1.18</url>
      <bibkey>rebuffel-etal-2020-parenting</bibkey>
      <pwccode url="https://github.com/KaijuML/PARENTing-rl" additional="false">KaijuML/PARENTing-rl</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikibio">WikiBio</pwcdataset>
    </paper>
    <paper id="20">
      <title>Chart-to-Text: Generating Natural Language Descriptions for Charts by Adapting the Transformer Model</title>
      <author><first>Jason</first><last>Obeid</last></author>
      <author><first>Enamul</first><last>Hoque</last></author>
      <pages>138&#8211;147</pages>
      <abstract>Information visualizations such as bar charts and line charts are very popular for exploring data and communicating insights. Interpreting and making sense of such visualizations can be challenging for some people, such as those who are visually impaired or have low visualization literacy. In this work, we introduce a new dataset and present a neural model for automatically generating natural language summaries for charts. The generated summaries provide an interpretation of the chart and convey the key insights found within that chart. Our neural model is developed by extending the state-of-the-art model for the data-to-text generation task, which utilizes a transformer-based encoder-decoder architecture. We found that our approach outperforms the base model on a content selection metric by a wide margin (55.42% vs. 8.49%) and generates more informative, concise, and coherent summaries.</abstract>
      <url hash="b06fec26">2020.inlg-1.20</url>
      <bibkey>obeid-hoque-2020-chart</bibkey>
      <pwccode url="https://github.com/JasonObeid/Chart2Text" additional="false">JasonObeid/Chart2Text</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/chart2text">Chart2Text</pwcdataset>
    </paper>
    <paper id="24">
      <title>Disentangling the Properties of Human Evaluation Methods: A Classification System to Support Comparability, Meta-Evaluation and Reproducibility Testing</title>
      <author><first>Anya</first><last>Belz</last></author>
      <author><first>Simon</first><last>Mille</last></author>
      <author><first>David M.</first><last>Howcroft</last></author>
      <pages>183&#8211;194</pages>
      <abstract>Current standards for designing and reporting human evaluations in NLP mean it is generally unclear which evaluations are comparable and can be expected to yield similar results when applied to the same system outputs. This has serious implications for reproducibility testing and meta-evaluation, in particular given that human evaluation is considered the gold standard against which the trustworthiness of automatic metrics is gauged. %and merging others, as well as deciding which evaluations should be able to reproduce each other&#8217;s results. Using examples from NLG, we propose a classification system for evaluations based on disentangling (i) what is being evaluated (which aspect of quality), and (ii) how it is evaluated in specific (a) evaluation modes and (b) experimental designs. We show that this approach provides a basis for determining comparability, hence for comparison of evaluations across papers, meta-evaluation experiments, reproducibility testing.</abstract>
      <url hash="08a92927">2020.inlg-1.24</url>
      <revision id="1" href="2020.inlg-1.24v1" hash="b11eeb47" />
      <revision id="2" href="2020.inlg-1.24v2" hash="08a92927" date="2021-04-16">Extended the Acknowledgments section.</revision>
      <bibkey>belz-etal-2020-disentangling</bibkey>
    </paper>
    <paper id="26">
      <title>Listener&#8217;s Social Identity Matters in Personalised Response Generation</title>
      <author><first>Guanyi</first><last>Chen</last></author>
      <author><first>Yinhe</first><last>Zheng</last></author>
      <author><first>Yupei</first><last>Du</last></author>
      <pages>205&#8211;215</pages>
      <abstract>Personalised response generation enables generating human-like responses by means of assigning the generator a social identity. However, pragmatics theory suggests that human beings adjust the way of speaking based on not only who they are but also whom they are talking to. In other words, when modelling personalised dialogues, it might be favourable if we also take the listener&#8217;s social identity into consideration. To validate this idea, we use gender as a typical example of a social variable to investigate how the listener&#8217;s identity influences the language used in Chinese dialogues on social media. Also, we build personalised generators. The experiment results demonstrate that the listener&#8217;s identity indeed matters in the language use of responses and that the response generator can capture such differences in language use. More interestingly, by additionally modelling the listener&#8217;s identity, the personalised response generator performs better in its own identity.</abstract>
      <url hash="fd4cd4ad">2020.inlg-1.26</url>
      <bibkey>chen-etal-2020-listeners</bibkey>
    </paper>
    <paper id="35">
      <title>Schema-Guided Natural Language Generation</title>
      <author><first>Yuheng</first><last>Du</last></author>
      <author><first>Shereen</first><last>Oraby</last></author>
      <author><first>Vittorio</first><last>Perera</last></author>
      <author><first>Minmin</first><last>Shen</last></author>
      <author><first>Anjali</first><last>Narayan-Chen</last></author>
      <author><first>Tagyoung</first><last>Chung</last></author>
      <author><first>Anushree</first><last>Venkatesh</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>283&#8211;295</pages>
      <abstract>Neural network based approaches to data-to-text natural language generation (NLG) have gained popularity in recent years, with the goal of generating a natural language prompt that accurately realizes an input meaning representation. To facilitate the training of neural network models, researchers created large datasets of paired utterances and their meaning representations. However, the creation of such datasets is an arduous task and they mostly consist of simple meaning representations composed of slot and value tokens to be realized. These representations do not include any contextual information that an NLG system can use when trying to generalize, such as domain information and descriptions of slots and values. In this paper, we present the novel task of Schema-Guided Natural Language Generation (SG-NLG). Here, the goal is still to generate a natural language prompt, but in SG-NLG, the input MRs are paired with rich schemata providing contextual information. To generate a dataset for SG-NLG we re-purpose an existing dataset for another task: dialog state tracking, which includes a large and rich schema spanning multiple different attributes, including information about the domain, user intent, and slot descriptions. We train different state-of-the-art models for neural natural language generation on this dataset and show that in many cases, including rich schema information allows our models to produce higher quality outputs both in terms of semantics and diversity. We also conduct experiments comparing model performance on seen versus unseen domains, and present a human evaluation demonstrating high ratings for overall output quality.</abstract>
      <url hash="ab06674d">2020.inlg-1.35</url>
      <bibkey>du-etal-2020-schema</bibkey>
      <pwccode url="https://github.com/alexa/schema-guided-nlg" additional="false">alexa/schema-guided-nlg</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sg-nlg">SG-NLG</pwcdataset>
    </paper>
    <paper id="37">
      <title>Neural <fixed-case>NLG</fixed-case> for Methodius: From <fixed-case>RST</fixed-case> Meaning Representations to Texts</title>
      <author><first>Symon</first><last>Stevens-Guille</last></author>
      <author><first>Aleksandre</first><last>Maskharashvili</last></author>
      <author><first>Amy</first><last>Isard</last></author>
      <author><first>Xintong</first><last>Li</last></author>
      <author><first>Michael</first><last>White</last></author>
      <pages>306&#8211;315</pages>
      <abstract>While classic NLG systems typically made use of hierarchically structured content plans that included discourse relations as central components, more recent neural approaches have mostly mapped simple, flat inputs to texts without representing discourse relations explicitly. In this paper, we investigate whether it is beneficial to include discourse relations in the input to neural data-to-text generators for texts where discourse relations play an important role. To do so, we reimplement the sentence planning and realization components of a classic NLG system, Methodius, using LSTM sequence-to-sequence (seq2seq) models. We find that although seq2seq models can learn to generate fluent and grammatical texts remarkably well with sufficiently representative Methodius training data, they cannot learn to correctly express Methodius&#8217;s similarity and contrast comparisons unless the corresponding RST relations are included in the inputs. Additionally, we experiment with using self-training and reverse model reranking to better handle train/test data mismatches, and find that while these methods help reduce content errors, it remains essential to include discourse relations in the input to obtain optimal performance.</abstract>
      <url hash="59008881">2020.inlg-1.37</url>
      <attachment type="Supplementary_Attachment" hash="3a84b37b">2020.inlg-1.37.Supplementary_Attachment.pdf</attachment>
      <bibkey>stevens-guille-etal-2020-neural</bibkey>
      <pwccode url="https://github.com/methodius-project/neural-methodius" additional="false">methodius-project/neural-methodius</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/webnlg">WebNLG</pwcdataset>
    </paper>
    <paper id="38">
      <title>From &#8220;Before&#8221; to &#8220;After&#8221;: Generating Natural Language Instructions from Image Pairs in a Simple Visual Domain</title>
      <author><first>Robin</first><last>Rojowiec</last></author>
      <author><first>Jana</first><last>G&#246;tze</last></author>
      <author><first>Philipp</first><last>Sadler</last></author>
      <author><first>Henrik</first><last>Voigt</last></author>
      <author><first>Sina</first><last>Zarrie&#223;</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>316&#8211;326</pages>
      <abstract>While certain types of instructions can be com-pactly expressed via images, there are situations where one might want to verbalise them, for example when directing someone. We investigate the task of Instruction Generation from Before/After Image Pairs which is to derive from images an instruction for effecting the implied change. For this, we make use of prior work on instruction following in a visual environment. We take an existing dataset, the BLOCKS data collected by Bisk et al. (2016) and investigate whether it is suitable for training an instruction generator as well. We find that it is, and investigate several simple baselines, taking these from the related task of image captioning. Through a series of experiments that simplify the task (by making image processing easier or completely side-stepping it; and by creating template-based targeted instructions), we investigate areas for improvement. We find that captioning models get some way towards solving the task, but have some difficulty with it, and future improvements must lie in the way the change is detected in the instruction.</abstract>
      <url hash="e0f2a2a8">2020.inlg-1.38</url>
      <attachment type="Supplementary_Attachment" hash="02f65016">2020.inlg-1.38.Supplementary_Attachment.pdf</attachment>
      <revision id="1" href="2020.inlg-1.38v1" hash="0d842728" />
      <revision id="2" href="2020.inlg-1.38v2" hash="e0f2a2a8" date="2021-01-01">References to appendix were corrected as they were broken (e.g. pages 318, 319 "...Appendix ??" changed to "...Appendix [A,B,...]")</revision>
      <bibkey>rojowiec-etal-2020-generating</bibkey>
    </paper>
    <paper id="42">
      <title>Rapformer: Conditional Rap Lyrics Generation with Denoising Autoencoders</title>
      <author><first>Nikola I.</first><last>Nikolov</last></author>
      <author><first>Eric</first><last>Malmi</last></author>
      <author><first>Curtis</first><last>Northcutt</last></author>
      <author><first>Loreto</first><last>Parisi</last></author>
      <pages>360&#8211;373</pages>
      <abstract>The ability to combine symbols to generate language is a defining characteristic of human intelligence, particularly in the context of artistic story-telling through lyrics. We develop a method for synthesizing a rap verse based on the content of any text (e.g., a news article), or for augmenting pre-existing rap lyrics. Our method, called Rapformer, is based on training a Transformer-based denoising autoencoder to reconstruct rap lyrics from content words extracted from the lyrics, trying to preserve the essential meaning, while matching the target style. Rapformer features a novel BERT-based paraphrasing scheme for rhyme enhancement which increases the average rhyme density of output lyrics by 10%. Experimental results on three diverse input domains show that Rapformer is capable of generating technically fluent verses that offer a good trade-off between content preservation and style transfer. Furthermore, a Turing-test-like experiment reveals that Rapformer fools human lyrics experts 25% of the time.</abstract>
      <url hash="966d1de8">2020.inlg-1.42</url>
      <attachment type="Supplementary_Attachment" hash="315249f7">2020.inlg-1.42.Supplementary_Attachment.zip</attachment>
      <bibkey>nikolov-etal-2020-rapformer</bibkey>
    </paper>
    <paper id="46">
      <title>Policy-Driven Neural Response Generation for Knowledge-Grounded Dialog Systems</title>
      <author><first>Behnam</first><last>Hedayatnia</last></author>
      <author><first>Karthik</first><last>Gopalakrishnan</last></author>
      <author><first>Seokhwan</first><last>Kim</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Mihail</first><last>Eric</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>412&#8211;421</pages>
      <abstract>Open-domain dialog systems aim to generate relevant, informative and engaging responses. In this paper, we propose using a dialog policy to plan the content and style of target, open domain responses in the form of an action plan, which includes knowledge sentences related to the dialog context, targeted dialog acts, topic information, etc. For training, the attributes within the action plan are obtained by automatically annotating the publicly released Topical-Chat dataset. We condition neural response generators on the action plan which is then realized as target utterances at the turn and sentence levels. We also investigate different dialog policy models to predict an action plan given the dialog context. Through automated and human evaluation, we measure the appropriateness of the generated responses and check if the generation models indeed learn to realize the given action plans. We demonstrate that a basic dialog policy that operates at the sentence level generates better responses in comparison to turn level generation as well as baseline models with no action plan. Additionally the basic dialog policy has the added benefit of controllability.</abstract>
      <url hash="009b2e1d">2020.inlg-1.46</url>
      <bibkey>hedayatnia-etal-2020-policy</bibkey>
    </paper>
  </volume>
</collection>