<collection id="S18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of The 12th International Workshop on Semantic Evaluation</booktitle>
      <url hash="aca7e30c">S18-1</url>
      <editor><first>Marianna</first> <last>Apidianaki</last></editor>
      <editor><first>Saif M.</first> <last>Mohammad</last></editor>
      <editor><first>Jonathan</first> <last>May</last></editor>
      <editor><first>Ekaterina</first> <last>Shutova</last></editor>
      <editor><first>Steven</first> <last>Bethard</last></editor>
      <editor><first>Marine</first> <last>Carpuat</last></editor>
      <doi>10.18653/v1/S18-1</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>New Orleans, Louisiana</address>
      <month>June</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="2d27ee37">S18-1000</url>
      <bibkey>semeval-2018-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Affect in Tweets</title>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Felipe</first> <last>Bravo-Marquez</last></author>
      <author><first>Mohammad</first> <last>Salameh</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <pages>1&#8211;17</pages>
      <abstract>We present the SemEval-2018 Task 1: Affect in Tweets, which includes an array of subtasks on inferring the affectual state of a person from their tweet. For each task, we created labeled data from English, Arabic, and Spanish tweets. The individual tasks are: 1. emotion intensity regression, 2. emotion intensity ordinal classification, 3. valence (sentiment) regression, 4. valence ordinal classification, and 5. emotion classification. Seventy-five teams (about 200 team members) participated in the shared task. We summarize the methods, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful. We also analyze systems for consistent bias towards a particular race or gender. The data is made freely available to further improve our understanding of how people convey emotions through language.</abstract>
      <attachment type="note" hash="b776485c">S18-1001.Notes.pdf</attachment>
      <url hash="95040a83">S18-1001</url>
      <doi>10.18653/v1/S18-1001</doi>
      <bibkey>mohammad-etal-2018-semeval</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>S</fixed-case>eer<fixed-case>N</fixed-case>et at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Domain Adaptation for Affect in Tweets</title>
      <author><first>Venkatesh</first> <last>Duppada</last></author>
      <author><first>Royal</first> <last>Jain</last></author>
      <author><first>Sushant</first> <last>Hiray</last></author>
      <pages>18&#8211;23</pages>
      <abstract>The paper describes the best performing system for the SemEval-2018 Affect in Tweets(English) sub-tasks. The system focuses on the ordinal classification and regression sub-tasks for valence and emotion. For ordinal classification valence is classified into 7 different classes ranging from -3 to 3 whereas emotion is classified into 4 different classes 0 to 3 separately for each emotion namely anger, fear, joy and sadness. The regression sub-tasks estimate the intensity of valence and each emotion. The system performs domain adaptation of 4 different models and creates an ensemble to give the final prediction. The proposed system achieved 1stposition out of 75 teams which participated in the fore-mentioned sub-tasks. We outperform the baseline model by margins ranging from 49.2% to 76.4 %, thus, pushing the state-of-the-art significantly.</abstract>
      <url hash="8dc38e23">S18-1002</url>
      <doi>10.18653/v1/S18-1002</doi>
      <bibkey>duppada-etal-2018-seernet</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2018 Task 2: Multilingual Emoji Prediction</title>
      <author><first>Francesco</first> <last>Barbieri</last></author>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Francesco</first> <last>Ronzano</last></author>
      <author><first>Luis</first> <last>Espinosa-Anke</last></author>
      <author><first>Miguel</first> <last>Ballesteros</last></author>
      <author><first>Valerio</first> <last>Basile</last></author>
      <author><first>Viviana</first> <last>Patti</last></author>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <pages>24&#8211;33</pages>
      <abstract>This paper describes the results of the first Shared Task on Multilingual Emoji Prediction, organized as part of SemEval 2018. Given the text of a tweet, the task consists of predicting the most likely emoji to be used along such tweet. Two subtasks were proposed, one for English and one for Spanish, and participants were allowed to submit a system run to one or both subtasks. In total, 49 teams participated to the English subtask and 22 teams submitted a system run to the Spanish subtask. Evaluation was carried out emoji-wise, and the final ranking was based on macro F-Score. Data and further information about this task can be found at <url>https://competitions.codalab.org/competitions/17344</url>.
    </abstract>
      <url hash="cb4c9b23">S18-1003</url>
      <doi>10.18653/v1/S18-1003</doi>
      <bibkey>barbieri-etal-2018-semeval</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>T</fixed-case>&#252;bingen-<fixed-case>O</fixed-case>slo at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>SVM</fixed-case>s perform better than <fixed-case>RNN</fixed-case>s in Emoji Prediction</title>
      <author><first>&#199;a&#287;r&#305;</first> <last>&#199;&#246;ltekin</last></author>
      <author><first>Taraka</first> <last>Rama</last></author>
      <pages>34&#8211;38</pages>
      <abstract>This paper describes our participation in the SemEval-2018 task Multilingual Emoji Prediction. We participated in both English and Spanish subtasks, experimenting with support vector machines (SVMs) and recurrent neural networks. Our SVM classifier obtained the top rank in both subtasks with macro-averaged F1-measures of 35.99% for English and 22.36% for Spanish data sets. Similar to a few earlier attempts, the results with neural networks were not on par with linear SVMs.</abstract>
      <url hash="5ba5771a">S18-1004</url>
      <doi>10.18653/v1/S18-1004</doi>
      <bibkey>coltekin-rama-2018-tubingen</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony Detection in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Cynthia</first> <last>Van Hee</last></author>
      <author><first>Els</first> <last>Lefever</last></author>
      <author><first>V&#233;ronique</first> <last>Hoste</last></author>
      <pages>39&#8211;50</pages>
      <abstract>This paper presents the first shared task on irony detection: given a tweet, automatic natural language processing systems should determine whether the tweet is ironic (Task A) and which type of irony (if any) is expressed (Task B). The ironic tweets were collected using irony-related hashtags (i.e. #irony, #sarcasm, #not) and were subsequently manually annotated to minimise the amount of noise in the corpus. Prior to distributing the data, hashtags that were used to collect the tweets were removed from the corpus. For both tasks, a training corpus of 3,834 tweets was provided, as well as a test set containing 784 tweets. Our shared tasks received submissions from 43 teams for the binary classification Task A and from 31 teams for the multiclass Task B. The highest classification scores obtained for both subtasks are respectively F1= 0.71 and F1= 0.51 and demonstrate that fine-grained irony classification is much more challenging than binary irony detection.</abstract>
      <url hash="922bb73b">S18-1005</url>
      <doi>10.18653/v1/S18-1005</doi>
      <bibkey>van-hee-etal-2018-semeval</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Tweet Irony Detection with Densely connected <fixed-case>LSTM</fixed-case> and Multi-task Learning</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>51&#8211;56</pages>
      <abstract>Detecting irony is an important task to mine fine-grained information from social web messages. Therefore, the Semeval-2018 task 3 is aimed to detect the ironic tweets (subtask A) and their ironic types (subtask B). In order to address this task, we propose a system based on a densely connected LSTM network with multi-task learning strategy. In our dense LSTM model, each layer will take all outputs from previous layers as input. The last LSTM layer will output the hidden representations of texts, and they will be used in three classification task. In addition, we incorporate several types of features to improve the model performance. Our model achieved an F-score of 70.54 (ranked 2/43) in the subtask A and 49.47 (ranked 3/29) in the subtask B. The experimental results validate the effectiveness of our system.</abstract>
      <url hash="ee790bcf">S18-1006</url>
      <doi>10.18653/v1/S18-1006</doi>
      <bibkey>wu-etal-2018-thu</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val 2018 Task 4: Character Identification on Multiparty Dialogues</title>
      <author><first>Jinho D.</first> <last>Choi</last></author>
      <author><first>Henry Y.</first> <last>Chen</last></author>
      <pages>57&#8211;64</pages>
      <abstract>Character identification is a task of entity linking that finds the global entity of each personal mention in multiparty dialogue. For this task, the first two seasons of the popular TV show Friends are annotated, comprising a total of 448 dialogues, 15,709 mentions, and 401 entities. The personal mentions are detected from nominals referring to certain characters in the show, and the entities are collected from the list of all characters in those two seasons of the show. This task is challenging because it requires the identification of characters that are mentioned but may not be active during the conversation. Among 90+ participants, four of them submitted their system outputs and showed strengths in different aspects about the task. Thorough analyses of the distributed datasets, system outputs, and comparative studies are also provided. To facilitate the momentum, we create an open-source project for this task and publicly release a larger and cleaner dataset, hoping to support researchers for more enhanced modeling.</abstract>
      <url hash="31495e3b">S18-1007</url>
      <doi>10.18653/v1/S18-1007</doi>
      <bibkey>choi-chen-2018-semeval</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>AMORE</fixed-case>-<fixed-case>UPF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 4: <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> with Entity Library</title>
      <author><first>Laura</first> <last>Aina</last></author>
      <author><first>Carina</first> <last>Silberer</last></author>
      <author><first>Ionut-Teodor</first> <last>Sorodoc</last></author>
      <author><first>Matthijs</first> <last>Westera</last></author>
      <author><first>Gemma</first> <last>Boleda</last></author>
      <pages>65&#8211;69</pages>
      <abstract>This paper describes our winning contribution to SemEval 2018 Task 4: Character Identification on Multiparty Dialogues. It is a simple, standard model with one key innovation, an entity library. Our results show that this innovation greatly facilitates the identification of infrequent characters. Because of the generic nature of our model, this finding is potentially relevant to any task that requires the effective learning from sparse or imbalanced data.</abstract>
      <url hash="4ffebdd6">S18-1008</url>
      <doi>10.18653/v1/S18-1008</doi>
      <bibkey>aina-etal-2018-amore</bibkey>
      <pwccode url="https://github.com/amore-upf/semeval2018-task4" additional="false">amore-upf/semeval2018-task4</pwccode>
    </paper>
    <paper id="10">
      <title><fixed-case>KOI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 5: Building Knowledge Graph of Incidents</title>
      <author><first>Paramita</first> <last>Mirza</last></author>
      <author><first>Fariz</first> <last>Darari</last></author>
      <author><first>Rahmad</first> <last>Mahendra</last></author>
      <pages>81&#8211;87</pages>
      <abstract>We present KOI (Knowledge of Incidents), a system that given news articles as input, builds a knowledge graph (KOI-KG) of incidental events. KOI-KG can then be used to efficiently answer questions such &#8220;How many killing incidents happened in 2017 that involve Sean?&#8221; The required steps in building the KG include: (i) document preprocessing involving word sense disambiguation, named-entity recognition, temporal expression recognition and normalization, and semantic role labeling; (ii) incidental event extraction and coreference resolution via document clustering; and (iii) KG construction and population.</abstract>
      <url hash="1b927609">S18-1010</url>
      <doi>10.18653/v1/S18-1010</doi>
      <bibkey>mirza-etal-2018-koi</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>NEUROSENT</fixed-case>-<fixed-case>PDI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text</title>
      <author><first>Mauro</first> <last>Dragoni</last></author>
      <pages>102&#8211;108</pages>
      <abstract>This paper describes the NeuroSent system that participated in SemEval 2018 Task 1. Our system takes a supervised approach that builds on neural networks and word embeddings. Word embeddings were built by starting from a repository of user generated reviews. Thus, they are specific for sentiment analysis tasks. Then, tweets are converted in the corresponding vector representation and given as input to the neural network with the aim of learning the different semantics contained in each emotion taken into account by the SemEval task. The output layer has been adapted based on the characteristics of each subtask. Preliminary results obtained on the provided training set are encouraging for pursuing the investigation into this direction.</abstract>
      <url hash="338b38ae">S18-1013</url>
      <doi>10.18653/v1/S18-1013</doi>
      <bibkey>dragoni-2018-neurosent</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>FOI</fixed-case> <fixed-case>DSS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Combining <fixed-case>LSTM</fixed-case> States, Embeddings, and Lexical Features for Affect Analysis</title>
      <author><first>Maja</first> <last>Karasalo</last></author>
      <author><first>Mattias</first> <last>Nilsson</last></author>
      <author><first>Magnus</first> <last>Rosell</last></author>
      <author><first>Ulrika</first> <last>Wickenberg Bolin</last></author>
      <pages>109&#8211;115</pages>
      <abstract>This paper describes the system used and results obtained for team FOI DSS at SemEval-2018 Task 1: Affect In Tweets. The team participated in all English language subtasks, with a method utilizing transfer learning from LSTM nets trained on large sentiment datasets combined with embeddings and lexical features. For four out of five subtasks, the system performed in the range of 92-95% of the winning systems, in terms of the competition metrics. Analysis of the results suggests that improved pre-processing and addition of more lexical features may further elevate performance.</abstract>
      <url hash="f973a54b">S18-1014</url>
      <doi>10.18653/v1/S18-1014</doi>
      <bibkey>karasalo-etal-2018-foi</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>NLPZZX</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Using Ensemble Method for Emotion and Sentiment Intensity Determination</title>
      <author><first>Zhengxin</first> <last>Zhang</last></author>
      <author><first>Qimin</first> <last>Zhou</last></author>
      <author><first>Hao</first> <last>Wu</last></author>
      <pages>116&#8211;122</pages>
      <abstract>In this paper, we put forward a system that competed at SemEval-2018 Task 1: &#8220;Affect in Tweets&#8221;. Our system uses a simple yet effective ensemble method which combines several neural network components. We participate in two subtasks for English tweets: EI-reg and V-reg. For two subtasks, different combinations of neural components are examined. For EI-reg, our system achieves an accuracy of 0.727 in Pearson Correlation Coefficient (all instances) and an accuracy of 0.555 in Pearson Correlation Coefficient (0.5-1). For V-reg, the achieved accuracy scores are respectively 0.835 and 0.670</abstract>
      <url hash="615972b3">S18-1015</url>
      <doi>10.18653/v1/S18-1015</doi>
      <bibkey>zhang-etal-2018-nlpzzx</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>LT</fixed-case>3 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: A classifier chain to detect emotions in tweets</title>
      <author><first>Luna</first> <last>De Bruyne</last></author>
      <author><first>Orph&#233;e</first> <last>De Clercq</last></author>
      <author><first>V&#233;ronique</first> <last>Hoste</last></author>
      <pages>123&#8211;127</pages>
      <abstract>This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, subtask 5: Detecting Emotions. The system combines lexicon, n-gram, style, syntactic and semantic features. For this multi-class multi-label problem, we created a classifier chain. This is an ensemble of eleven binary classifiers, one for each possible emotion category, where each model gets the predictions of the preceding models as additional features. The predicted labels are combined to get a multi-label representation of the predictions. Our system was ranked eleventh among thirty five participating teams, with a Jaccard accuracy of 52.0% and macro- and micro-average F1-scores of 49.3% and 64.0%, respectively.</abstract>
      <url hash="bd71f42a">S18-1016</url>
      <doi>10.18653/v1/S18-1016</doi>
      <bibkey>de-bruyne-etal-2018-lt3</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>SINAI</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Recognition in Tweets</title>
      <author><first>Flor Miriam</first> <last>Plaza-del-Arco</last></author>
      <author><first>Salud Mar&#237;a</first> <last>Jim&#233;nez-Zafra</last></author>
      <author><first>Maite</first> <last>Martin</last></author>
      <author><first>L. Alfonso</first> <last>Ure&#241;a-L&#243;pez</last></author>
      <pages>128&#8211;132</pages>
      <abstract>Emotion classification is a new task that combines several disciplines including Artificial Intelligence and Psychology, although Natural Language Processing is perhaps the most challenging area. In this paper, we describe our participation in SemEval-2018 Task1: Affect in Tweets. In particular, we have participated in EI-oc, EI-reg and E-c subtasks for English and Spanish languages.</abstract>
      <url hash="4aaffdc7">S18-1017</url>
      <doi>10.18653/v1/S18-1017</doi>
      <bibkey>plaza-del-arco-etal-2018-sinai</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>INGEOTEC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>E</fixed-case>vo<fixed-case>MSA</fixed-case> and &#956;<fixed-case>TC</fixed-case> for Sentiment Analysis</title>
      <author><first>Mario</first> <last>Graff</last></author>
      <author><first>Sabino</first> <last>Miranda-Jim&#233;nez</last></author>
      <author><first>Eric S.</first> <last>Tellez</last></author>
      <author><first>Daniela</first> <last>Moctezuma</last></author>
      <pages>146&#8211;150</pages>
      <abstract>This paper describes our participation in Affective Tweets task for emotional intensity and sentiment intensity subtasks for English, Spanish, and Arabic languages. We used two approaches, &#956;TC and EvoMSA. The first one is a generic text categorization and regression system; and the second one, a two-stage architecture for Sentiment Analysis. Both approaches are multilingual and domain independent.</abstract>
      <url hash="553aebf3">S18-1020</url>
      <doi>10.18653/v1/S18-1020</doi>
      <bibkey>graff-etal-2018-ingeotec</bibkey>
    </paper>
    <paper id="24">
      <title>Tw-<fixed-case>S</fixed-case>t<fixed-case>AR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Preprocessing Impact on Multi-label Emotion Classification</title>
      <author><first>Hala</first> <last>Mulki</last></author>
      <author><first>Chedi</first> <last>Bechikh Ali</last></author>
      <author><first>Hatem</first> <last>Haddad</last></author>
      <author><first>Ismail</first> <last>Babao&#287;lu</last></author>
      <pages>167&#8211;171</pages>
      <abstract>In this paper, we describe our contribution in SemEval-2018 contest. We tackled task 1 &#8220;Affect in Tweets&#8221;, subtask E-c &#8220;Detecting Emotions (multi-label classification)&#8221;. A multilabel classification system Tw-StAR was developed to recognize the emotions embedded in Arabic, English and Spanish tweets. To handle the multi-label classification problem via traditional classifiers, we employed the binary relevance transformation strategy while a TF-IDF scheme was used to generate the tweets&#8217; features. We investigated using single and combinations of several preprocessing tasks to further improve the performance. The results showed that specific combinations of preprocessing tasks could significantly improve the evaluation measures. This has been later emphasized by the official results as our system ranked 3rd for both Arabic and Spanish datasets and 14th for the English dataset.</abstract>
      <url hash="d276e67c">S18-1024</url>
      <doi>10.18653/v1/S18-1024</doi>
      <bibkey>mulki-etal-2018-tw</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>E</fixed-case>mo<fixed-case>I</fixed-case>ntens Tracker at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotional Intensity Levels in #Tweets</title>
      <author><first>Ramona-Andreea</first> <last>Turcu</last></author>
      <author><first>Sandra Maria</first> <last>Amarandei</last></author>
      <author><first>Iuliana-Alexandra</first> <last>Flescan-Lovin-Arseni</last></author>
      <author><first>Daniela</first> <last>Gifu</last></author>
      <author><first>Diana</first> <last>Trandabat</last></author>
      <pages>177&#8211;180</pages>
      <abstract>The &#8222;Affect in Tweets&#8221; task is centered on emotions categorization and evaluation matrix using multi-language tweets (English and Spanish). In this research, SemEval Affect dataset was preprocessed, categorized, and evaluated accordingly (precision, recall, and accuracy). The system described in this paper is based on the implementation of supervised machine learning (Naive Bayes, KNN and SVM), deep learning (NN Tensor Flow model), and decision trees algorithms.</abstract>
      <url hash="6e41d05b">S18-1026</url>
      <doi>10.18653/v1/S18-1026</doi>
      <bibkey>turcu-etal-2018-emointens</bibkey>
    </paper>
    <paper id="28">
      <title><fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Fine-grained Tweet Sentiment Intensity Analysis with Attention <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case></title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>186&#8211;192</pages>
      <abstract>Traditional sentiment analysis approaches mainly focus on classifying the sentiment polarities or emotion categories of texts. However, they can&#8217;t exploit the sentiment intensity information. Therefore, the SemEval-2018 Task 1 is aimed to automatically determine the intensity of emotions or sentiment of tweets to mine fine-grained sentiment information. In order to address this task, we propose a system based on an attention CNN-LSTM model. In our model, LSTM is used to extract the long-term contextual information from texts. We apply attention techniques to selecting this information. A CNN layer with different size of kernels is used to extract local features. The dense layers take the pooled CNN feature maps and predict the intensity scores. Our system reaches average Pearson correlation score of 0.722 (ranked 12/48) in emotion intensity regression task, and 0.810 in valence regression task (ranked 15/38). It indicates that our system can be further extended.</abstract>
      <url hash="efa50a03">S18-1028</url>
      <doi>10.18653/v1/S18-1028</doi>
      <bibkey>wu-etal-2018-thu-ngn</bibkey>
    </paper>
    <paper id="29">
      <title><fixed-case>E</fixed-case>i<fixed-case>TAKA</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: An Ensemble of N-Channels <fixed-case>C</fixed-case>onv<fixed-case>N</fixed-case>et and <fixed-case>XG</fixed-case>boost Regressors for Emotion Analysis of Tweets</title>
      <author><first>Mohammed</first> <last>Jabreel</last></author>
      <author id="antonio-moreno-ribas"><first>Antonio</first> <last>Moreno</last></author>
      <pages>193&#8211;199</pages>
      <abstract>This paper describes our system that has been used in Task1 Affect in Tweets. We combine two different approaches. The first one called N-Stream ConvNets, which is a deep learning approach where the second one is XGboost regressor based on a set of embedding and lexicons based features. Our system was evaluated on the testing sets of the tasks outperforming all other approaches for the Arabic version of valence intensity regression task and valence ordinal classification task.</abstract>
      <url hash="d018ae55">S18-1029</url>
      <doi>10.18653/v1/S18-1029</doi>
      <bibkey>jabreel-moreno-2018-eitaka</bibkey>
    </paper>
    <paper id="30">
      <title><fixed-case>CENTEMENT</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Classification of Tweets using Multiple Thresholds with Self-correction and Weighted Conditional Probabilities</title>
      <author><first>Tariq</first> <last>Ahmad</last></author>
      <author><first>Allan</first> <last>Ramsay</last></author>
      <author><first>Hanady</first> <last>Ahmed</last></author>
      <pages>200&#8211;204</pages>
      <abstract>In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emotions of Arabic and English tweets. We attempted &#8220;Affect in Tweets&#8221;, specifically Task E-c: Detecting Emotions (multi-label classification). Our method is based on preprocessing the tweets and creating word vectors combined with a self correction step to remove noise. We also make use of emotion specific thresholds. The final submission was selected upon the best performance achieved, selected when using a range of thresholds. Our system was evaluated on the Arabic and English datasets provided for the task by the competition organisers, where it ranked 2nd for the Arabic dataset (out of 14 entries) and 12th for the English dataset (out of 35 entries).</abstract>
      <url hash="569e10b4">S18-1030</url>
      <doi>10.18653/v1/S18-1030</doi>
      <bibkey>ahmad-etal-2018-centement</bibkey>
    </paper>
    <paper id="31">
      <title>Yuan at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network</title>
      <author><first>Min</first> <last>Wang</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>205&#8211;209</pages>
      <abstract>We perform the LSTM and BiLSTM model for the emotion intensity prediction. We only join the third subtask in Task 1:Affect in Tweets. Our system rank 6th among all the teams.</abstract>
      <url hash="2c32ddc4">S18-1031</url>
      <doi>10.18653/v1/S18-1031</doi>
      <bibkey>wang-zhou-2018-yuan</bibkey>
    </paper>
    <paper id="33">
      <title><fixed-case>A</fixed-case>mobee at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>GRU</fixed-case> Neural Network with a <fixed-case>CNN</fixed-case> Attention Mechanism for Sentiment Classification</title>
      <author><first>Alon</first> <last>Rozental</last></author>
      <author><first>Daniel</first> <last>Fleischer</last></author>
      <pages>218&#8211;225</pages>
      <abstract>This paper describes the participation of Amobee in the shared sentiment analysis task at SemEval 2018. We participated in all the English sub-tasks and the Spanish valence tasks. Our system consists of three parts: training task-specific word embeddings, training a model consisting of gated-recurrent-units (GRU) with a convolution neural network (CNN) attention mechanism and training stacking-based ensembles for each of the sub-tasks. Our algorithm reached the 3rd and 1st places in the valence ordinal classification sub-tasks in English and Spanish, respectively.</abstract>
      <url hash="52cebc84">S18-1033</url>
      <doi>10.18653/v1/S18-1033</doi>
      <bibkey>rozental-fleischer-2018-amobee</bibkey>
    </paper>
    <paper id="35">
      <title><fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models</title>
      <author><first>Huimin</first> <last>Xu</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>231&#8211;235</pages>
      <abstract>This paper describes our submissions to SemEval 2018 task 1. The task is affect intensity prediction in tweets, including five subtasks. We participated in all subtasks of English tweets. We extracted several traditional NLP, sentiment lexicon, emotion lexicon and domain specific features from tweets, adopted supervised machine learning algorithms to perform emotion intensity prediction.</abstract>
      <url hash="ebf5b535">S18-1035</url>
      <doi>10.18653/v1/S18-1035</doi>
      <bibkey>xu-etal-2018-ecnu</bibkey>
    </paper>
    <paper id="37">
      <title><fixed-case>NTUA</fixed-case>-<fixed-case>SLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive <fixed-case>RNN</fixed-case>s and Transfer Learning</title>
      <author><first>Christos</first> <last>Baziotis</last></author>
      <author><first>Athanasiou</first> <last>Nikolaos</last></author>
      <author><first>Alexandra</first> <last>Chronopoulou</last></author>
      <author><first>Athanasia</first> <last>Kolovou</last></author>
      <author><first>Georgios</first> <last>Paraskevopoulos</last></author>
      <author><first>Nikolaos</first> <last>Ellinas</last></author>
      <author><first>Shrikanth</first> <last>Narayanan</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>245&#8211;255</pages>
      <abstract>In this paper we present deep-learning models that submitted to the SemEval-2018 Task 1 competition: &#8220;Affect in Tweets&#8221;. We participated in all subtasks for English tweets. We propose a Bi-LSTM architecture equipped with a multi-layer self attention mechanism. The attention mechanism improves the model performance and allows us to identify salient words in tweets, as well as gain insight into the models making them more interpretable. Our model utilizes a set of word2vec word embeddings trained on a large collection of 550 million Twitter messages, augmented by a set of word affective features. Due to the limited amount of task-specific training data, we opted for a transfer learning approach by pretraining the Bi-LSTMs on the dataset of Semeval 2017, Task 4A. The proposed approach ranked 1st in Subtask E &#8220;Multi-Label Emotion Classification&#8221;, 2nd in Subtask A &#8220;Emotion Intensity Regression&#8221; and achieved competitive results in other subtasks.</abstract>
      <url hash="e2322e38">S18-1037</url>
      <doi>10.18653/v1/S18-1037</doi>
      <bibkey>baziotis-etal-2018-ntua</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="38">
      <title><fixed-case>C</fixed-case>rystal<fixed-case>F</fixed-case>eel at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Understanding and Detecting Emotion Intensity using Affective Lexicons</title>
      <author><first>Raj Kumar</first> <last>Gupta</last></author>
      <author><first>Yinping</first> <last>Yang</last></author>
      <pages>256&#8211;263</pages>
      <abstract>While sentiment and emotion analysis has received a considerable amount of research attention, the notion of understanding and detecting the intensity of emotions is relatively less explored. This paper describes a system developed for predicting emotion intensity in tweets. Given a Twitter message, CrystalFeel uses features derived from parts-of-speech, n-grams, word embedding, and multiple affective lexicons including Opinion Lexicon, SentiStrength, AFFIN, NRC Emotion &amp; Hash Emotion, and our in-house developed EI Lexicons to predict the degree of the intensity associated with fear, anger, sadness, and joy in the tweet. We found that including the affective lexicons-based features allowed the system to obtain strong prediction performance, while revealing interesting emotion word-level and message-level associations. On gold test data, CrystalFeel obtained Pearson correlations of 0.717 on average emotion intensity and of 0.816 on sentiment intensity.</abstract>
      <url hash="14e01a62">S18-1038</url>
      <doi>10.18653/v1/S18-1038</doi>
      <bibkey>gupta-yang-2018-crystalfeel</bibkey>
    </paper>
    <paper id="39">
      <title><fixed-case>P</fixed-case>lus<fixed-case>E</fixed-case>mo2<fixed-case>V</fixed-case>ec at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Exploiting emotion knowledge from emoji and #hashtags</title>
      <author><first>Ji Ho</first> <last>Park</last></author>
      <author><first>Peng</first> <last>Xu</last></author>
      <author><first>Pascale</first> <last>Fung</last></author>
      <pages>264&#8211;272</pages>
      <abstract>This paper describes our system that has been submitted to SemEval-2018 Task 1: Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both sentence and word level representations of emotion inside texts through large distantly labeled corpora with emojis and hashtags. We transfer the emotional knowledge by exploiting neural network models as feature extractors and use these representations for traditional machine learning models such as support vector regression (SVR) and logistic regression to solve the competition tasks. Our system is placed among the Top3 for all subtasks we participated.</abstract>
      <url hash="3610cc5a">S18-1039</url>
      <doi>10.18653/v1/S18-1039</doi>
      <bibkey>park-etal-2018-plusemo2vec</bibkey>
    </paper>
    <paper id="40">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> with Attention based Sentiment Analysis for Affect in Tweets</title>
      <author><first>You</first> <last>Zhang</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>273&#8211;278</pages>
      <abstract>We implemented the sentiment system in all five subtasks for English and Spanish. All subtasks involve emotion or sentiment intensity prediction (regression and ordinal classification) and emotions determining (multi-labels classification). The useful BiLSTM (Bidirectional Long-Short Term Memory) model with attention mechanism was mainly applied for our system. We use BiLSTM in order to get word information extracted from both directions. The attention mechanism was used to find the contribution of each word for improving the scores. Furthermore, based on BiLSTMATT (BiLSTM with attention mechanism) a few deep-learning algorithms were employed for different subtasks. For regression and ordinal classification tasks we used domain adaptation and ensemble learning methods to leverage base model. While a single base model was used for multi-labels task.</abstract>
      <url hash="ab404bc9">S18-1040</url>
      <doi>10.18653/v1/S18-1040</doi>
      <bibkey>zhang-etal-2018-ynu</bibkey>
    </paper>
    <paper id="41">
      <title><fixed-case>UG</fixed-case>18 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Generating Additional Training Data for Predicting Emotion Intensity in <fixed-case>S</fixed-case>panish</title>
      <author><first>Marloes</first> <last>Kuijper</last></author>
      <author><first>Mike</first> <last>van Lenthe</last></author>
      <author><first>Rik</first> <last>van Noord</last></author>
      <pages>279&#8211;285</pages>
      <abstract>The present study describes our submission to SemEval 2018 Task 1: Affect in Tweets. Our Spanish-only approach aimed to demonstrate that it is beneficial to automatically generate additional training data by (i) translating training data from other languages and (ii) applying a semi-supervised learning method. We find strong support for both approaches, with those models outperforming our regular models in all subtasks. However, creating a stepwise ensemble of different models as opposed to simply averaging did not result in an increase in performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc) in the four Spanish subtasks we participated in.</abstract>
      <url hash="611ce3e7">S18-1041</url>
      <doi>10.18653/v1/S18-1041</doi>
      <bibkey>kuijper-etal-2018-ug18</bibkey>
    </paper>
    <paper id="42">
      <title><fixed-case>ISCLAB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: <fixed-case>UIR</fixed-case>-Miner for Affect in Tweets</title>
      <author><first>Meng</first> <last>Li</last></author>
      <author><first>Zhenyuan</first> <last>Dong</last></author>
      <author><first>Zhihao</first> <last>Fan</last></author>
      <author><first>Kongming</first> <last>Meng</last></author>
      <author><first>Jinghua</first> <last>Cao</last></author>
      <author><first>Guanqi</first> <last>Ding</last></author>
      <author><first>Yuhan</first> <last>Liu</last></author>
      <author><first>Jiawei</first> <last>Shan</last></author>
      <author><first>Binyang</first> <last>Li</last></author>
      <pages>286&#8211;290</pages>
      <abstract>This paper presents a UIR-Miner system for emotion and sentiment analysis evaluation in Twitter in SemEval 2018. Our system consists of three main modules: preprocessing module, stacking module to solve the intensity prediction of emotion and sentiment, LSTM network module to solve multi-label classification, and the hierarchical attention network module for solving emotion and sentiment classification problem. According to the metrics of SemEval 2018, our system gets the final scores of 0.636, 0.531, 0.731, 0.708, and 0.408 on 5 subtasks, respectively.</abstract>
      <url hash="bf56840d">S18-1042</url>
      <doi>10.18653/v1/S18-1042</doi>
      <bibkey>li-etal-2018-isclab</bibkey>
    </paper>
    <paper id="43">
      <title><fixed-case>TCS</fixed-case> Research at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Learning Robust Representations using Multi-Attention Architecture</title>
      <author><first>Hardik</first> <last>Meisheri</last></author>
      <author><first>Lipika</first> <last>Dey</last></author>
      <pages>291&#8211;299</pages>
      <abstract>This paper presents system description of our submission to the SemEval-2018 task-1: Affect in tweets for the English language. We combine three different features generated using deep learning models and traditional methods in support vector machines to create a unified ensemble system. A robust representation of a tweet is learned using a multi-attention based architecture which uses a mixture of different pre-trained embeddings. In addition to this analysis of different features is also presented. Our system ranked 2nd, 5th, and 7th in different subtasks among 75 teams.</abstract>
      <url hash="c7e740da">S18-1043</url>
      <doi>10.18653/v1/S18-1043</doi>
      <bibkey>meisheri-dey-2018-tcs</bibkey>
    </paper>
    <paper id="44">
      <title><fixed-case>DMCB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Transfer Learning of Sentiment Classification Using Group <fixed-case>LSTM</fixed-case> for Emotion Intensity prediction</title>
      <author><first>Youngmin</first> <last>Kim</last></author>
      <author><first>Hyunju</first> <last>Lee</last></author>
      <pages>300&#8211;304</pages>
      <abstract>This paper describes a system attended in the SemEval-2018 Task 1 &#8220;Affect in tweets&#8221; that predicts emotional intensities. We use Group LSTM with an attention model and transfer learning with sentiment classification data as a source data (SemEval 2017 Task 4a). A transfer model structure consists of a source domain and a target domain. Additionally, we try a new dropout that is applied to LSTMs in the Group LSTM. Our system ranked 8th at the subtask 1a (emotion intensity regression). We also show various results with different architectures in the source, target and transfer models.</abstract>
      <url hash="76078495">S18-1044</url>
      <doi>10.18653/v1/S18-1044</doi>
      <bibkey>kim-lee-2018-dmcb</bibkey>
    </paper>
    <paper id="45">
      <title><fixed-case>D</fixed-case>eep<fixed-case>M</fixed-case>iner at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Emotion Intensity Recognition Using Deep Representation Learning</title>
      <author><first>Habibeh</first> <last>Naderi</last></author>
      <author><first>Behrouz</first> <last>Haji Soleimani</last></author>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <author><first>Stan</first> <last>Matwin</last></author>
      <pages>305&#8211;312</pages>
      <abstract>In this paper, we propose a regression system to infer the emotion intensity of a tweet. We develop a multi-aspect feature learning mechanism to capture the most discriminative semantic features of a tweet as well as the emotion information conveyed by each word in it. We combine six types of feature groups: (1) a tweet representation learned by an LSTM deep neural network on the training data, (2) a tweet representation learned by an LSTM network on a large corpus of tweets that contain emotion words (a distant supervision corpus), (3) word embeddings trained on the distant supervision corpus and averaged over all words in a tweet, (4) word and character n-grams, (5) features derived from various sentiment and emotion lexicons, and (6) other hand-crafted features. As part of the word embedding training, we also learn the distributed representations of multi-word expressions (MWEs) and negated forms of words. An SVR regressor is then trained over the full set of features. We evaluate the effectiveness of our ensemble feature sets on the SemEval-2018 Task 1 datasets and achieve a Pearson correlation of 72% on the task of tweet emotion intensity prediction.</abstract>
      <url hash="9df5a176">S18-1045</url>
      <doi>10.18653/v1/S18-1045</doi>
      <bibkey>naderi-etal-2018-deepminer</bibkey>
    </paper>
    <paper id="46">
      <title>Zewen at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: An Ensemble Model for Affect Prediction in Tweets</title>
      <author><first>Zewen</first> <last>Chi</last></author>
      <author><first>Heyan</first> <last>Huang</last></author>
      <author><first>Jiangui</first> <last>Chen</last></author>
      <author><first>Hao</first> <last>Wu</last></author>
      <author><first>Ran</first> <last>Wei</last></author>
      <pages>313&#8211;318</pages>
      <abstract>This paper presents a method for Affect in Tweets, which is the task to automatically determine the intensity of emotions and intensity of sentiment of tweets. The term affect refers to emotion-related categories such as anger, fear, etc. Intensity of emo-tions need to be quantified into a real valued score in [0, 1]. We propose an en-semble system including four different deep learning methods which are CNN, Bidirectional LSTM (BLSTM), LSTM-CNN and a CNN-based Attention model (CA). Our system gets an average Pearson correlation score of 0.682 in the subtask EI-reg and an average Pearson correlation score of 0.784 in subtask V-reg, which ranks 17th among 48 systems in EI-reg and 19th among 38 systems in V-reg.</abstract>
      <url hash="1a0e2b7e">S18-1046</url>
      <doi>10.18653/v1/S18-1046</doi>
      <bibkey>chi-etal-2018-zewen</bibkey>
    </paper>
    <paper id="55">
      <title><fixed-case>ARB</fixed-case>-<fixed-case>SEN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task1: A New Set of Features for Enhancing the Sentiment Intensity Prediction in <fixed-case>A</fixed-case>rabic Tweets</title>
      <author><first>El Moatez Billah</first> <last>Nagoudi</last></author>
      <pages>364&#8211;368</pages>
      <abstract>This article describes our proposed Arabic Sentiment Analysis system named ARB-SEN. This system is designed for the International Workshop on Semantic Evaluation 2018 (SemEval-2018), Task1: Affect in Tweets. ARB-SEN proposes two supervised models to estimate the sentiment intensity in Arabic tweets. Both models use a set of features including sentiment lexicon, negation, word embedding and emotion symbols features. Our system combines these features to assist the sentiment analysis task. ARB-SEN system achieves a correlation score of 0.720, ranking 6th among all participants in the valence intensity regression (V-reg) for the Arabic sub-task organized within the SemEval 2018 evaluation campaign.</abstract>
      <url hash="8e1f8e04">S18-1055</url>
      <doi>10.18653/v1/S18-1055</doi>
      <bibkey>nagoudi-2018-arb</bibkey>
    </paper>
    <paper id="56">
      <title>psy<fixed-case>ML</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Transfer Learning for Sentiment and Emotion Analysis</title>
      <author><first>Grace</first> <last>Gee</last></author>
      <author><first>Eugene</first> <last>Wang</last></author>
      <pages>369&#8211;376</pages>
      <abstract>In this paper, we describe the first attempt to perform transfer learning from sentiment to emotions. Our system employs Long Short-Term Memory (LSTM) networks, including bidirectional LSTM (biLSTM) and LSTM with attention mechanism. We perform transfer learning by first pre-training the LSTM networks on sentiment data before concatenating the penultimate layers of these networks into a single vector as input to new dense layers. For the E-c subtask, we utilize a novel approach to train models for correlated emotion classes. Our system performs 4/48, 3/39, 8/38, 4/37, 4/35 on all English subtasks EI-reg, EI-oc, V-reg, V-oc, E-c of SemEval 2018 Task 1: Affect in Tweets.</abstract>
      <url hash="30d57bd8">S18-1056</url>
      <doi>10.18653/v1/S18-1056</doi>
      <bibkey>gee-wang-2018-psyml</bibkey>
    </paper>
    <paper id="57">
      <title><fixed-case>UIUC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Recognizing Affect with Ensemble Models</title>
      <author><first>Abhishek Avinash</first> <last>Narwekar</last></author>
      <author><first>Roxana</first> <last>Girju</last></author>
      <pages>377&#8211;384</pages>
      <abstract>Our submission to the SemEval-2018 Task1: Affect in Tweets shared task competition is a supervised learning model relying on standard lexicon features coupled with word embedding features. We used an ensemble of diverse models, including random forests, gradient boosted trees, and linear models, corrected for training-development set mismatch. We submitted the system&#8217;s output for subtasks 1 (emotion intensity prediction), 2 (emotion ordinal classification), 3 (valence intensity regression) and 4 (valence ordinal classification), for English tweets. We placed 25th, 19th, 24th and 15th in the four subtasks respectively. The baseline considered was an SVM (Support Vector Machines) model with linear kernel on the lexicon and embedding based features. Our system&#8217;s final performance measured in Pearson correlation scores outperformed the baseline by a margin of 2.2% to 14.6% across all tasks.</abstract>
      <url hash="2dc5f5ad">S18-1057</url>
      <doi>10.18653/v1/S18-1057</doi>
      <bibkey>narwekar-girju-2018-uiuc</bibkey>
    </paper>
    <paper id="58">
      <title><fixed-case>KU</fixed-case>-<fixed-case>MTL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 1: Multi-task Identification of Affect in Tweets</title>
      <author><first>Thomas</first> <last>Nyegaard-Signori</last></author>
      <author><first>Casper Veistrup</first> <last>Helms</last></author>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <author><first>Isabelle</first> <last>Augenstein</last></author>
      <pages>385&#8211;389</pages>
      <abstract>We take a multi-task learning approach to the shared Task 1 at SemEval-2018. The general idea concerning the model structure is to use as little external data as possible in order to preserve the task relatedness and reduce complexity. We employ multi-task learning with hard parameter sharing to exploit the relatedness between sub-tasks. As a base model, we use a standard recurrent neural network for both the classification and regression subtasks. Our system ranks 32nd out of 48 participants with a Pearson score of 0.557 in the first subtask, and 20th out of 35 in the fifth subtask with an accuracy score of 0.464.</abstract>
      <url hash="3caf8855">S18-1058</url>
      <doi>10.18653/v1/S18-1058</doi>
      <bibkey>nyegaard-signori-etal-2018-ku</bibkey>
    </paper>
    <paper id="59">
      <title><fixed-case>E</fixed-case>mo<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>E</fixed-case>nglish Emoji Prediction with Gradient Boosting Regression Tree Method and Bidirectional <fixed-case>LSTM</fixed-case></title>
      <author><first>Man</first> <last>Liu</last></author>
      <pages>390&#8211;394</pages>
      <abstract>This paper describes our system used in the English Emoji Prediction Task 2 at the SemEval-2018. Our system is based on two supervised machine learning algorithms: Gradient Boosting Regression Tree Method (GBM) and Bidirectional Long Short-term Memory Network (BLSTM). Besides the common features, we extract various lexicon and syntactic features from external resources. After comparing the results of two algorithms, GBM is chosen for the final evaluation.</abstract>
      <url hash="8cb13ca1">S18-1059</url>
      <doi>10.18653/v1/S18-1059</doi>
      <bibkey>liu-2018-emonlp</bibkey>
    </paper>
    <paper id="60">
      <title><fixed-case>UMDS</fixed-case>ub at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding</title>
      <author><first>Zhenduo</first> <last>Wang</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>395&#8211;399</pages>
      <abstract>This paper describes the UMDSub system that participated in Task 2 of SemEval-2018. We developed a system that predicts an emoji given the raw text in a English tweet. The system is a Multi-channel Convolutional Neural Network based on subword embeddings for the representation of tweets. This model improves on character or word based methods by about 2%. Our system placed 21st of 48 participating systems in the official evaluation.</abstract>
      <url hash="21b93b9e">S18-1060</url>
      <doi>10.18653/v1/S18-1060</doi>
      <bibkey>wang-pedersen-2018-umdsub</bibkey>
    </paper>
    <paper id="61">
      <title><fixed-case>UMD</fixed-case>uluth-<fixed-case>CS</fixed-case>8761 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emojis: Too many Choices?</title>
      <author><first>Jonathan</first> <last>Beaulieu</last></author>
      <author><first>Dennis</first> <last>Asamoah Owusu</last></author>
      <pages>400&#8211;404</pages>
      <abstract>In this paper, we present our system for assigning an emoji to a tweet based on the text. Each tweet was originally posted with an emoji which the task providers removed. Our task was to decide out of 20 emojis, which originally came with the tweet. Two datasets were provided - one in English and the other in Spanish. We treated the task as a standard classification task with the emojis as our classes and the tweets as our documents. Our best performing system used a Bag of Words model with a Linear Support Vector Machine as its&#8217; classifier. We achieved a macro F1 score of 32.73% for the English data and 17.98% for the Spanish data.</abstract>
      <url hash="eba2d25e">S18-1061</url>
      <doi>10.18653/v1/S18-1061</doi>
      <bibkey>beaulieu-asamoah-owusu-2018-umduluth</bibkey>
    </paper>
    <paper id="63">
      <title><fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Residual <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> Network with Attention for <fixed-case>E</fixed-case>nglish Emoji Prediction</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Junxin</first> <last>Liu</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>410&#8211;414</pages>
      <abstract>Emojis are widely used by social media and social network users when posting their messages. It is important to study the relationships between messages and emojis. Thus, in SemEval-2018 Task 2 an interesting and challenging task is proposed, i.e., predicting which emojis are evoked by text-based tweets. We propose a residual CNN-LSTM with attention (<b>RCLA</b>) model
      for this task. Our model combines CNN and LSTM layers to capture
      both local and long-range contextual information for tweet
      representation.  In addition, attention mechanism is used to
      select important components.  Besides, residual connection is
      applied to CNN layers to facilitate the training of neural
      networks. We also incorporated additional features such as POS
      tags and sentiment features extracted from lexicons. Our model
      achieved 30.25% macro-averaged F-score in the first subtask
      (i.e., emoji prediction in English), ranking 7th out of 48
      participants.
    </abstract>
      <url hash="cbf6e073">S18-1063</url>
      <doi>10.18653/v1/S18-1063</doi>
      <bibkey>wu-etal-2018-thu-ngn-semeval</bibkey>
    </paper>
    <paper id="64">
      <title>#<fixed-case>T</fixed-case>eam<fixed-case>INF</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction in Tweets</title>
      <author><first>Alison</first> <last>Ribeiro</last></author>
      <author><first>N&#225;dia</first> <last>Silva</last></author>
      <pages>415&#8211;418</pages>
      <abstract>In this paper, we describe a methodology to predict emoji in tweets. Our approach is based on the classic bag-of-words model in conjunction with word embeddings. The used classification algorithm was Logistic Regression. This architecture was used and evaluated in the context of the SemEval 2018 challenge (task 2, subtask 1).</abstract>
      <url hash="715b9c04">S18-1064</url>
      <doi>10.18653/v1/S18-1064</doi>
      <bibkey>ribeiro-silva-2018-teaminf</bibkey>
    </paper>
    <paper id="65">
      <title><fixed-case>EICA</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Semantic and Metadata-based Features for Multilingual Emoji Prediction</title>
      <author><first>Yufei</first> <last>Xie</last></author>
      <author><first>Qingqing</first> <last>Song</last></author>
      <pages>419&#8211;422</pages>
      <abstract>The advent of social media has brought along a novel way of communication where meaning is composed by combining short text messages and visual enhancements, the so-called emojis. We describe our system for participating in SemEval-2018 Task 2 on Multilingual Emoji Prediction. Our approach relies on combining a rich set of various types of features: semantic and metadata. The most important types turned out to be the metadata feature. In subtask 1: Emoji Prediction in English, our primary submission obtain a MAP of 16.45, Precision of 31.557, Recall of 16.771 and Accuracy of 30.992.</abstract>
      <url hash="413e29f5">S18-1065</url>
      <doi>10.18653/v1/S18-1065</doi>
      <bibkey>xie-song-2018-eica</bibkey>
    </paper>
    <paper id="66">
      <title><fixed-case>E</fixed-case>moji<fixed-case>I</fixed-case>t at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words</title>
      <author><last>Chen</last> <first>Shiyun</first></author>
      <author><last>Wang</last> <first>Maoquan</first></author>
      <author><last>He</last> <first>Liang</first></author>
      <pages>423&#8211;427</pages>
      <abstract>This paper presents our single model to Subtask 1 of SemEval 2018 Task 2: Emoji Prediction in English. In order to predict the emoji that may be contained in a tweet, the basic model we use is an attention-based recurrent neural network which has achieved satisfactory performs in Natural Language processing. Considering the text comes from social media, it contains many discrepant abbreviations and online terms, we also combine word-level and character-level word vector embedding to better handling the words not appear in the vocabulary. Our single model1 achieved 29.50% Macro F-score in test data and ranks 9th among 48 teams.</abstract>
      <url hash="6439765e">S18-1066</url>
      <attachment type="note" hash="ef33e4cb">S18-1066.Notes.pdf</attachment>
      <doi>10.18653/v1/S18-1066</doi>
      <bibkey>chen-etal-2018-emojiit</bibkey>
    </paper>
    <paper id="67">
      <title>Peperomia at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Vector Similarity Based Approach for Emoji Prediction</title>
      <author><first>Jing</first> <last>Chen</last></author>
      <author><first>Dechuan</first> <last>Yang</last></author>
      <author><first>Xilian</first> <last>Li</last></author>
      <author><first>Wei</first> <last>Chen</last></author>
      <author><first>Tengjiao</first> <last>Wang</last></author>
      <pages>428&#8211;432</pages>
      <abstract>This paper describes our participation in SemEval 2018 Task 2: Multilingual Emoji Prediction, in which participants are asked to predict a tweet&#8217;s most associated emoji from 20 emojis. Instead of regarding it as a 20-class classification problem we regard it as a text similarity problem. We propose a vector similarity based approach for this task. First the distributed representation (tweet vector) for each tweet is generated, then the similarity between this tweet vector and each emoji&#8217;s embedding is evaluated. The most similar emoji is chosen as the predicted label. Experimental results show that our approach performs comparably with the classification approach and shows its advantage in classifying emojis with similar semantic meaning.</abstract>
      <url hash="dbf16eb8">S18-1067</url>
      <doi>10.18653/v1/S18-1067</doi>
      <bibkey>chen-etal-2018-peperomia</bibkey>
    </paper>
    <paper id="69">
      <title><fixed-case>NTUA</fixed-case>-<fixed-case>SLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Predicting Emojis using <fixed-case>RNN</fixed-case>s with Context-aware Attention</title>
      <author><first>Christos</first> <last>Baziotis</last></author>
      <author><first>Athanasiou</first> <last>Nikolaos</last></author>
      <author><first>Athanasia</first> <last>Kolovou</last></author>
      <author><first>Georgios</first> <last>Paraskevopoulos</last></author>
      <author><first>Nikolaos</first> <last>Ellinas</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>438&#8211;444</pages>
      <abstract>In this paper we present a deep-learning model that competed at SemEval-2018 Task 2 &#8220;Multilingual Emoji Prediction&#8221;. We participated in subtask A, in which we are called to predict the most likely associated emoji in English tweets. The proposed architecture relies on a Long Short-Term Memory network, augmented with an attention mechanism, that conditions the weight of each word, on a &#8220;context vector&#8221; which is taken as the aggregation of a tweet&#8217;s meaning. Moreover, we initialize the embedding layer of our model, with word2vec word embeddings, pretrained on a dataset of 550 million English tweets. Finally, our model does not rely on hand-crafted features or lexicons and is trained end-to-end with back-propagation. We ranked 2nd out of 48 teams.</abstract>
      <url hash="ba7b9f90">S18-1069</url>
      <doi>10.18653/v1/S18-1069</doi>
      <bibkey>baziotis-etal-2018-ntua-slp</bibkey>
      <pwccode url="" additional="true" />
    </paper>
    <paper id="70">
      <title>Hatching Chick at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction</title>
      <author><first>Jo&#235;l</first> <last>Coster</last></author>
      <author><first>Reinder Gerard</first> <last>van Dalen</last></author>
      <author><first>Nathalie Adri&#235;nne Jacqueline</first> <last>Stierman</last></author>
      <pages>445&#8211;448</pages>
      <abstract>As part of a SemEval 2018 shared task an attempt was made to build a system capable of predicting the occurence of a language&#8217;s most frequently used emoji in Tweets. Specifically, models for English and Spanish data were created and trained on 500.000 and 100.000 tweets respectively. In order to create these models, first a logistic regressor, a sequential LSTM, a random forest regressor and a SVM were tested. The latter was found to perform best and therefore optimized individually for both languages. During developmet f1-scores of 61 and 82 were obtained for English and Spanish data respectively, in comparison, f1-scores on the official evaluation data were 21 and 18. The significant decrease in performance during evaluation might be explained by overfitting during development and might therefore have partially be prevented by using cross-validation. Over all, emoji which occur in a very specific context such as a Christmas tree were found to be most predictable.</abstract>
      <url hash="15b1565b">S18-1070</url>
      <doi>10.18653/v1/S18-1070</doi>
      <bibkey>coster-etal-2018-hatching</bibkey>
    </paper>
    <paper id="71">
      <title><fixed-case>EPUTION</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction with User Adaption</title>
      <author><first>Liyuan</first> <last>Zhou</last></author>
      <author><first>Qiongkai</first> <last>Xu</last></author>
      <author><first>Hanna</first> <last>Suominen</last></author>
      <author><first>Tom</first> <last>Gedeon</last></author>
      <pages>449&#8211;453</pages>
      <abstract>This paper describes our approach, called EPUTION, for the open trial of the SemEval- 2018 Task 2, Multilingual Emoji Prediction. The task relates to using social media &#8212; more precisely, Twitter &#8212; with its aim to predict the most likely associated emoji of a tweet. Our solution for this text classification problem explores the idea of transfer learning for adapting the classifier based on users&#8217; tweeting history. Our experiments show that our user-adaption method improves classification results by more than 6 per cent on the macro-averaged F1. Thus, our paper provides evidence for the rationality of enriching the original corpus longitudinally with user behaviors and transferring the lessons learned from corresponding users to specific instances.</abstract>
      <attachment type="note" hash="1ad2c50c">S18-1071.Notes.pdf</attachment>
      <url hash="17734302">S18-1071</url>
      <doi>10.18653/v1/S18-1071</doi>
      <bibkey>zhou-etal-2018-epution</bibkey>
    </paper>
    <paper id="72">
      <title><fixed-case>P</fixed-case>ickle<fixed-case>T</fixed-case>eam! at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: <fixed-case>E</fixed-case>nglish and <fixed-case>S</fixed-case>panish Emoji Prediction from Tweets</title>
      <author><first>Daphne</first> <last>Groot</last></author>
      <author><first>R&#233;mon</first> <last>Kruizinga</last></author>
      <author><first>Hennie</first> <last>Veldthuis</last></author>
      <author><first>Simon</first> <last>de Wit</last></author>
      <author><first>Hessel</first> <last>Haagsma</last></author>
      <pages>454&#8211;458</pages>
      <abstract>We present a system for emoji prediction on English and Spanish tweets, prepared for the SemEval-2018 task on Multilingual Emoji Prediction. We compared the performance of an SVM, LSTM and an ensemble of these two. We found the SVM performed best on our development set with an accuracy of 61.3% for English and 83% for Spanish. The features used for the SVM are lowercased word n-grams in the range of 1 to 20, tokenised by a TweetTokenizer and stripped of stop words. On the test set, our model achieved an accuracy of 34% on English, with a slightly lower score of 29.7% accuracy on Spanish.</abstract>
      <url hash="8a9c12ee">S18-1072</url>
      <doi>10.18653/v1/S18-1072</doi>
      <bibkey>groot-etal-2018-pickleteam</bibkey>
    </paper>
    <paper id="73">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multi-ensemble <fixed-case>B</fixed-case>i-<fixed-case>GRU</fixed-case> Model with Attention Mechanism for Multilingual Emoji Prediction</title>
      <author><first>Nan</first> <last>Wang</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>459&#8211;465</pages>
      <abstract>This paper describes our approach to SemEval-2018 Task 2, which aims to predict the most likely associated emoji, given a tweet in English or Spanish. We normalized text-based tweets during pre-processing, following which we utilized a bi-directional gated recurrent unit with an attention mechanism to build our base model. Multi-models with or without class weights were trained for the ensemble methods. We boosted models without class weights, and only strong boost classifiers were identified. In our system, not only was a boosting method used, but we also took advantage of the voting ensemble method to enhance our final system result. Our method demonstrated an obvious improvement of approximately 3% of the macro F1 score in English and 2% in Spanish.</abstract>
      <url hash="ef8d95d1">S18-1073</url>
      <doi>10.18653/v1/S18-1073</doi>
      <bibkey>wang-etal-2018-ynu</bibkey>
    </paper>
    <paper id="74">
      <title><fixed-case>DUTH</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Emoji Prediction in Tweets</title>
      <author><first>Dimitrios</first> <last>Effrosynidis</last></author>
      <author><first>Georgios</first> <last>Peikos</last></author>
      <author><first>Symeon</first> <last>Symeonidis</last></author>
      <author><first>Avi</first> <last>Arampatzis</last></author>
      <pages>466&#8211;469</pages>
      <abstract>This paper describes the approach that was developed for SemEval 2018 Task 2 (Multilingual Emoji Prediction) by the DUTH Team. First, we employed a combination of pre-processing techniques to reduce the noise of tweets and produce a number of features. Then, we built several N-grams, to represent the combination of word and emojis. Finally, we trained our system with a tuned LinearSVC classifier. Our approach in the leaderboard ranked 18th amongst 48 teams.</abstract>
      <url hash="efccb393">S18-1074</url>
      <doi>10.18653/v1/S18-1074</doi>
      <bibkey>effrosynidis-etal-2018-duth</bibkey>
    </paper>
    <paper id="77">
      <title><fixed-case>D</fixed-case>uluth <fixed-case>UROP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Multilingual Emoji Prediction with Ensemble Learning and Oversampling</title>
      <author><first>Shuning</first> <last>Jin</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>482&#8211;485</pages>
      <abstract>This paper describes the Duluth UROP systems that participated in SemEval&#8211;2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers using Naive Bayes, Logistic Regression, and Random Forests. We used unigram and bigram features and tried to offset the skewness of the data through the use of oversampling. Our task evaluation results place us 19th of 48 systems in the English evaluation, and 5th of 21 in the Spanish. After the evaluation we realized that some simple changes to our pre-processing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the English evaluation, and second in the Spanish.</abstract>
      <url hash="242988f8">S18-1077</url>
      <doi>10.18653/v1/S18-1077</doi>
      <bibkey>jin-pedersen-2018-duluth</bibkey>
      <pwccode url="https://github.com/shuningjin/SemEval2018-Task2-EmojiDetection" additional="false">shuningjin/SemEval2018-Task2-EmojiDetection</pwccode>
    </paper>
    <paper id="78">
      <title><fixed-case>CENNLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation</title>
      <author><first>Naveen</first> <last>J R</last></author>
      <author><first>Hariharan</first> <last>V</last></author>
      <author><first>Barathi</first> <last>Ganesh H. B.</last></author>
      <author><first>Anand</first> <last>Kumar M</last></author>
      <author><first>Soman</first> <last>K P</last></author>
      <pages>486&#8211;490</pages>
      <abstract>Emoji is one of the &#8220;fastest growing language &#8221; in pop-culture, especially in social media and it is very unlikely for its usage to decrease. These are generally used to bring an extra level of meaning to the texts, posted on social media platforms. Providing such an added info, gives more insights to the plain text, arising to hidden interpretation within the text. This paper explains our analysis on Task 2, &#8221; Multilingual Emoji Prediction&#8221; sharedtask conducted by Semeval-2018. In the task, a predicted emoji based on a piece of Twitter text are labelled under 20 different classes (most commonly used emojis) where these classes are learnt and further predicted are made for unseen Twitter text. In this work, we have experimented and analysed emojis predicted based on Twitter text, as a classification problem where the entailing emoji is considered as a label for every individual text data. We have implemented this using distributed representation of text through fastText. Also, we have made an effort to demonstrate how fastText framework can be useful in case of emoji prediction. This task is divide into two subtask, they are based on dataset presented in two different languages English and Spanish.</abstract>
      <url hash="d2d95ccc">S18-1078</url>
      <doi>10.18653/v1/S18-1078</doi>
      <bibkey>j-r-etal-2018-cennlp-semeval</bibkey>
    </paper>
    <paper id="81">
      <title><fixed-case>LIS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 2: Mixing Word Embeddings and Bag of Features for Multilingual Emoji Prediction</title>
      <author><first>Ga&#235;l</first> <last>Guibon</last></author>
      <author><first>Magalie</first> <last>Ochs</last></author>
      <author><first>Patrice</first> <last>Bellot</last></author>
      <pages>502&#8211;506</pages>
      <abstract>In this paper we present the system submitted to the SemEval2018 task2 : Multilingual Emoji Prediction. Our system approaches both languages as being equal by first; considering word embeddings associated to automatically computed features of different types, then by applying bagging algorithm RandomForest to predict the emoji of a tweet.</abstract>
      <url hash="1598ca93">S18-1081</url>
      <doi>10.18653/v1/S18-1081</doi>
      <bibkey>guibon-etal-2018-lis</bibkey>
    </paper>
    <paper id="82">
      <title><fixed-case>ALANIS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Feature Engineering Approach to Irony Detection in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Kevin</first> <last>Swanberg</last></author>
      <author><first>Madiha</first> <last>Mirza</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <author><first>Zhenduo</first> <last>Wang</last></author>
      <pages>507&#8211;511</pages>
      <abstract>This paper describes the ALANIS system that participated in Task 3 of SemEval-2018. We develop a system for detection of irony, as well as the detection of three types of irony: verbal polar irony, other verbal irony, and situational irony. The system uses a logistic regression model in subtask A and a voted classifier system with manually developed features to identify ironic tweets. This model improves on a naive bayes baseline by about 8 percent on training set.</abstract>
      <url hash="aa3f5e45">S18-1082</url>
      <doi>10.18653/v1/S18-1082</doi>
      <bibkey>swanberg-etal-2018-alanis</bibkey>
    </paper>
    <paper id="84">
      <title><fixed-case>UWB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony detection in <fixed-case>E</fixed-case>nglish tweets</title>
      <author><first>Tom&#225;&#353;</first> <last>Hercig</last></author>
      <pages>520&#8211;524</pages>
      <abstract>This paper describes our system created for the SemEval-2018 Task 3: Irony detection in English tweets. Our strongly constrained system uses only the provided training data without any additional external resources. Our system is based on Maximum Entropy classifier and various features using parse tree, POS tags, and morphological features. Even without additional lexicons and word embeddings we achieved fourth place in Subtask A and seventh in Subtask B in terms of accuracy.</abstract>
      <url hash="badd8b53">S18-1084</url>
      <doi>10.18653/v1/S18-1084</doi>
      <bibkey>hercig-2018-uwb</bibkey>
    </paper>
    <paper id="85">
      <title><fixed-case>NIHRIO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Simple and Accurate Neural Network Model for Irony Detection in <fixed-case>T</fixed-case>witter</title>
      <author><first>Thanh</first> <last>Vu</last></author>
      <author><first>Dat Quoc</first> <last>Nguyen</last></author>
      <author><first>Xuan-Son</first> <last>Vu</last></author>
      <author><first>Dai Quoc</first> <last>Nguyen</last></author>
      <author><first>Michael</first> <last>Catt</last></author>
      <author><first>Michael</first> <last>Trenell</last></author>
      <pages>525&#8211;530</pages>
      <abstract>This paper describes our NIHRIO system for SemEval-2018 Task 3 &#8220;Irony detection in English tweets.&#8221; We propose to use a simple neural network architecture of Multilayer Perceptron with various types of input features including: lexical, syntactic, semantic and polarity features. Our system achieves very high performance in both subtasks of binary and multi-class irony detection in tweets. In particular, we rank at least fourth using the accuracy metric and sixth using the F1 metric. Our code is available at: <url>https://github.com/NIHRIO/IronyDetectionInTwitter</url>
      </abstract>
      <url hash="2b0db811">S18-1085</url>
      <doi>10.18653/v1/S18-1085</doi>
      <bibkey>vu-etal-2018-nihrio</bibkey>
      <pwccode url="https://github.com/NIHRIO/IronyDetectionInTwitter" additional="false">NIHRIO/IronyDetectionInTwitter</pwccode>
    </paper>
    <paper id="86">
      <title><fixed-case>LDR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Low Dimensional Text Representation for Irony Detection</title>
      <author><first>Bilal</first> <last>Ghanem</last></author>
      <author><first>Francisco</first> <last>Rangel</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>531&#8211;536</pages>
      <abstract>In this paper we describe our participation in the SemEval-2018 task 3 Shared Task on Irony Detection. We have approached the task with our low dimensionality representation method (LDR), which exploits low dimensional features extracted from text on the basis of the occurrence probability of the words depending on each class. Our intuition is that words in ironic texts have different probability of occurrence than in non-ironic ones. Our approach obtained acceptable results in both subtasks A and B. We have performed an error analysis that shows the difference on correct and incorrect classified tweets.</abstract>
      <url hash="ca8a046e">S18-1086</url>
      <doi>10.18653/v1/S18-1086</doi>
      <bibkey>ghanem-etal-2018-ldr</bibkey>
    </paper>
    <paper id="88">
      <title><fixed-case>P</fixed-case>un<fixed-case>F</fixed-case>ields at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Detecting Irony by Tools of Humor Analysis</title>
      <author><first>Elena</first> <last>Mikhalkova</last></author>
      <author><first>Yuri</first> <last>Karyakin</last></author>
      <author><first>Alexander</first> <last>Voronov</last></author>
      <author><first>Dmitry</first> <last>Grigoriev</last></author>
      <author><first>Artem</first> <last>Leoznov</last></author>
      <pages>541&#8211;545</pages>
      <abstract>The paper describes our search for a universal algorithm of detecting intentional lexical ambiguity in different forms of creative language. At SemEval-2018 Task 3, we used PunFields, the system of automatic analysis of English puns that we introduced at SemEval-2017, to detect irony in tweets. Preliminary tests showed that it can reach the score of F1=0.596. However, at the competition, its result was F1=0.549.</abstract>
      <url hash="a7bafdcd">S18-1088</url>
      <doi>10.18653/v1/S18-1088</doi>
      <bibkey>mikhalkova-etal-2018-punfields</bibkey>
    </paper>
    <paper id="89">
      <title><fixed-case>H</fixed-case>ash<fixed-case>C</fixed-case>ount at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Concatenative Featurization of Tweet and Hashtags for Irony Detection</title>
      <author><first>Won Ik</first> <last>Cho</last></author>
      <author><first>Woo Hyun</first> <last>Kang</last></author>
      <author><first>Nam Soo</first> <last>Kim</last></author>
      <pages>546&#8211;552</pages>
      <abstract>This paper proposes a novel feature extraction process for SemEval task 3: Irony detection in English tweets. The proposed system incorporates a concatenative featurization of tweet and hashtags, which helps distinguishing between the irony-related and the other components. The system embeds tweets into a vector sequence with widely used pretrained word vectors, partially using a character embedding for the words that are out of vocabulary. Identification was performed with BiLSTM and CNN classifiers, achieving F1 score of 0.5939 (23/42) and 0.3925 (10/28) each for the binary and the multi-class case, respectively. The reliability of the proposed scheme was verified by analyzing the Gold test data, which demonstrates how hashtags can be taken into account when identifying various types of irony.</abstract>
      <url hash="0830d953">S18-1089</url>
      <doi>10.18653/v1/S18-1089</doi>
      <bibkey>cho-etal-2018-hashcount</bibkey>
    </paper>
    <paper id="90">
      <title><fixed-case>WLV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Dissecting Tweets in Search of Irony</title>
      <author><first>Omid</first> <last>Rohanian</last></author>
      <author><first>Shiva</first> <last>Taslimipoor</last></author>
      <author><first>Richard</first> <last>Evans</last></author>
      <author><first>Ruslan</first> <last>Mitkov</last></author>
      <pages>553&#8211;559</pages>
      <abstract>This paper describes the systems submitted to SemEval 2018 Task 3 &#8220;Irony detection in English tweets&#8221; for both subtasks A and B. The first system leveraging a combination of sentiment, distributional semantic, and text surface features is ranked third among 44 teams according to the official leaderboard of the subtask A. The second system with slightly different representation of the features ranked ninth in subtask B. We present a method that entails decomposing tweets into separate parts. Searching for contrast within the constituents of a tweet is an integral part of our system. We embrace an extensive definition of contrast which leads to a vast coverage in detecting ironic content.</abstract>
      <url hash="13a80ed7">S18-1090</url>
      <doi>10.18653/v1/S18-1090</doi>
      <bibkey>rohanian-etal-2018-wlv</bibkey>
    </paper>
    <paper id="95">
      <title>Irony Detector at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Irony Detection in <fixed-case>E</fixed-case>nglish Tweets using Word Graph</title>
      <author><first>Usman</first> <last>Ahmed</last></author>
      <author><first>Lubna</first> <last>Zafar</last></author>
      <author><first>Faiza</first> <last>Qayyum</last></author>
      <author><first>Muhammad</first> <last>Arshad Islam</last></author>
      <pages>581&#8211;586</pages>
      <abstract>This paper describes the Irony detection system that participates in SemEval-2018 Task 3: Irony detection in English tweets. The system participated in the subtasks A and B. This paper discusses the results of our system in the development, evaluation and post evaluation. Each class in the dataset is represented as directed unweighted graphs. Then, the comparison is carried out with each class graph which results in a vector. This vector is used as features by machine learning algorithm. The model is evaluated on a hold on strategy. The organizers randomly split 80% (3,833 instances) training set (provided to the participant in training their system) and testing set 20%(958 instances). The test set is reserved to evaluate the performance of participants systems. During the evaluation, our system ranked 23 in the Coda Lab result of the subtask A (binary class problem). The binary class system achieves accuracy 0.6135, precision 0.5091, recall 0.7170 and F measure 0.5955. The subtask B (multi-class problem) system is ranked 22 in Coda Lab results. The multiclass model achieves the accuracy 0.4158, precision 0.4055, recall 0.3526 and f measure 0.3101.</abstract>
      <url hash="09677fa1">S18-1095</url>
      <doi>10.18653/v1/S18-1095</doi>
      <bibkey>ahmed-etal-2018-irony</bibkey>
    </paper>
    <paper id="96">
      <title><fixed-case>L</fixed-case>ancaster at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Investigating Ironic Features in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Edward</first> <last>Dearden</last></author>
      <author><first>Alistair</first> <last>Baron</last></author>
      <pages>587&#8211;593</pages>
      <abstract>This paper describes the system we submitted to SemEval-2018 Task 3. The aim of the system is to distinguish between irony and non-irony in English tweets. We create a targeted feature set and analyse how different features are useful in the task of irony detection, achieving an F1-score of 0.5914. The analysis of individual features provides insight that may be useful in future attempts at detecting irony in tweets.</abstract>
      <url hash="28cd350b">S18-1096</url>
      <doi>10.18653/v1/S18-1096</doi>
      <bibkey>dearden-baron-2018-lancaster</bibkey>
    </paper>
    <paper id="97">
      <title><fixed-case>INAOE</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: An Ensemble Approach for Irony Detection in <fixed-case>T</fixed-case>witter</title>
      <author><first>Delia Iraz&#250;</first> <last>Hern&#225;ndez Far&#237;as</last></author>
      <author><first>Fernando</first> <last>S&#225;nchez-Vega</last></author>
      <author><first>Manuel</first> <last>Montes-y-G&#243;mez</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>594&#8211;599</pages>
      <abstract>This paper describes an ensemble approach to the SemEval-2018 Task 3. The proposed method is composed of two renowned methods in text classification together with a novel approach for capturing ironic content by exploiting a tailored lexicon for irony detection. We experimented with different ensemble settings. The obtained results show that our method has a good performance for detecting the presence of ironic content in Twitter.</abstract>
      <url hash="f15111f7">S18-1097</url>
      <doi>10.18653/v1/S18-1097</doi>
      <bibkey>hernandez-farias-etal-2018-inaoe</bibkey>
    </paper>
    <paper id="99">
      <title><fixed-case>KLUE</fixed-case>nicorn at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: A Naive Approach to Irony Detection</title>
      <author><first>Luise</first> <last>D&#252;rlich</last></author>
      <pages>607&#8211;612</pages>
      <abstract>This paper describes the KLUEnicorn system submitted to the SemEval-2018 task on &#8220;Irony detection in English tweets&#8221;. The proposed system uses a naive Bayes classifier to exploit rather simple lexical, pragmatical and semantical features as well as sentiment. It further takes a closer look at different adverb categories and named entities and factors in word-embedding information.</abstract>
      <url hash="90c27989">S18-1099</url>
      <doi>10.18653/v1/S18-1099</doi>
      <bibkey>durlich-2018-kluenicorn</bibkey>
    </paper>
    <paper id="101">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Ensemble Neural Network Models for Irony Detection on <fixed-case>T</fixed-case>witter</title>
      <author><first>Bo</first> <last>Peng</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>622&#8211;627</pages>
      <abstract>This paper describe the system we proposed to participate the first year of Irony detection in English tweets competition. Previous works demonstrate that LSTMs models have achieved remarkable performance in natural language processing; besides, combining multiple classification from various individual classifiers in general is more powerful than a single classification. In order to obtain more precision classification of irony detection, our system trained several individual neural network classifiers and combined their results according to the ensemble-learning algorithm.</abstract>
      <url hash="254099e5">S18-1101</url>
      <doi>10.18653/v1/S18-1101</doi>
      <bibkey>peng-etal-2018-ynu</bibkey>
    </paper>
    <paper id="102">
      <title>Binarizer at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Parsing dependency and deep learning for irony detection</title>
      <author><first>Nishant</first> <last>Nikhil</last></author>
      <author><first>Muktabh</first> <last>Mayank Srivastava</last></author>
      <pages>628&#8211;632</pages>
      <abstract>In this paper, we describe the system submitted for the SemEval 2018 Task 3 (Irony detection in English tweets) Subtask A by the team Binarizer. Irony detection is a key task for many natural language processing works. Our method treats ironical tweets to consist of smaller parts containing different emotions. We break down tweets into separate phrases using a dependency parser. We then embed those phrases using an LSTM-based neural network model which is pre-trained to predict emoticons for tweets. Finally, we train a fully-connected network to achieve classification.</abstract>
      <url hash="856feebe">S18-1102</url>
      <doi>10.18653/v1/S18-1102</doi>
      <bibkey>nikhil-mayank-srivastava-2018-binarizer</bibkey>
    </paper>
    <paper id="105">
      <title><fixed-case>V</fixed-case>alen<fixed-case>TO</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 3: Exploring the Role of Affective Content for Detecting Irony in <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Delia Iraz&#250;</first> <last>Hern&#225;ndez Far&#237;as</last></author>
      <author><first>Viviana</first> <last>Patti</last></author>
      <author><first>Paolo</first> <last>Rosso</last></author>
      <pages>643&#8211;648</pages>
      <abstract>In this paper we describe the system used by the ValenTO team in the shared task on Irony Detection in English Tweets at SemEval 2018. The system takes as starting point emotIDM, an irony detection model that explores the use of affective features based on a wide range of lexical resources available for English, reflecting different facets of affect. We experimented with different settings, by exploiting different classifiers and features, and participated both to the binary irony detection task and to the task devoted to distinguish among different types of irony. We report on the results obtained by our system both in a constrained setting and unconstrained setting, where we explored the impact of using additional data in the training phase, such as corpora annotated for the presence of irony or sarcasm from the state of the art. Overall, the performance of our system seems to validate the important role that affective information has for identifying ironic content in Twitter.</abstract>
      <url hash="0bfedaa3">S18-1105</url>
      <doi>10.18653/v1/S18-1105</doi>
      <bibkey>hernandez-farias-etal-2018-valento</bibkey>
    </paper>
    <paper id="108">
      <title><fixed-case>N</fixed-case>ews<fixed-case>R</fixed-case>eader at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 5: Counting events by reasoning over event-centric-knowledge-graphs</title>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>660&#8211;666</pages>
      <abstract>In this paper, we describe the participation of the NewsReader system in the SemEval-2018 Task 5 on Counting Events and Participants in the Long Tail. NewsReader is a generic unsupervised text processing system that detects events with participants, time and place to generate Event Centric Knowledge Graphs (ECKGs). We minimally adapted these ECKGs to establish a baseline performance for the task. We first use the ECKGs to establish which documents report on the same incident and what event mentions are coreferential. Next, we aggregate ECKGs across coreferential mentions and use the aggregated knowledge to answer the questions of the task. Our participation tests the quality of NewsReader to create ECKGs, as well as the potential of ECKGs to establish event identity and reason over the result to answer the task queries.</abstract>
      <url hash="0de7ff68">S18-1108</url>
      <doi>10.18653/v1/S18-1108</doi>
      <bibkey>vossen-2018-newsreader</bibkey>
    </paper>
    <paper id="113">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Semantic Extraction from <fixed-case>C</fixed-case>ybersec<fixed-case>U</fixed-case>rity <fixed-case>RE</fixed-case>ports using Natural Language Processing (<fixed-case>S</fixed-case>ecure<fixed-case>NLP</fixed-case>)</title>
      <author><first>Peter</first> <last>Phandi</last></author>
      <author><first>Amila</first> <last>Silva</last></author>
      <author><first>Wei</first> <last>Lu</last></author>
      <pages>697&#8211;706</pages>
      <abstract>This paper describes the SemEval 2018 shared task on semantic extraction from cybersecurity reports, which is introduced for the first time as a shared task on SemEval. This task comprises four SubTasks done incrementally to predict the characteristics of a specific malware using cybersecurity reports. To the best of our knowledge, we introduce the world&#8217;s largest publicly available dataset of annotated malware reports in this task. This task received in total 18 submissions from 9 participating teams.</abstract>
      <url hash="8bd299c0">S18-1113</url>
      <doi>10.18653/v1/S18-1113</doi>
      <bibkey>phandi-etal-2018-semeval</bibkey>
    </paper>
    <paper id="114">
      <title><fixed-case>DM</fixed-case>_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: neural sequence labeling with linguistic features</title>
      <author><first>Chunping</first> <last>Ma</last></author>
      <author><first>Huafei</first> <last>Zheng</last></author>
      <author><first>Pengjun</first> <last>Xie</last></author>
      <author><first>Chen</first> <last>Li</last></author>
      <author><first>Linlin</first> <last>Li</last></author>
      <author><first>Luo</first> <last>Si</last></author>
      <pages>707&#8211;711</pages>
      <abstract>This paper describes our submissions for SemEval-2018 Task 8: Semantic Extraction from CybersecUrity REports using NLP. The DM_NLP participated in two subtasks: SubTask 1 classifies if a sentence is useful for inferring malware actions and capabilities, and SubTask 2 predicts token labels (&#8220;Action&#8221;, &#8220;Entity&#8221;, &#8220;Modifier&#8221; and &#8220;Others&#8221;) for a given malware-related sentence. Since we leverage results of Subtask 2 directly to infer the result of Subtask 1, the paper focus on the system solving Subtask 2. By taking Subtask 2 as a sequence labeling task, our system relies on a recurrent neural network named BiLSTM-CNN-CRF with rich linguistic features, such as POS tags, dependency parsing labels, chunking labels, NER labels, Brown clustering. Our system achieved the highest F1 score in both token level and phrase level.</abstract>
      <url hash="fa6627a9">S18-1114</url>
      <doi>10.18653/v1/S18-1114</doi>
      <bibkey>ma-etal-2018-dm</bibkey>
    </paper>
    <paper id="115">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: Hypernym Discovery</title>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Claudio</first> <last>Delli Bovi</last></author>
      <author><first>Luis</first> <last>Espinosa-Anke</last></author>
      <author><first>Sergio</first> <last>Oramas</last></author>
      <author><first>Tommaso</first> <last>Pasini</last></author>
      <author><first>Enrico</first> <last>Santus</last></author>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <author><first>Roberto</first> <last>Navigli</last></author>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <pages>712&#8211;724</pages>
      <abstract>This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling hypernymy, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows: given an input term, retrieve (or discover) its suitable hypernyms from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the subtasks. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the task can be found at <url>https://competitions.codalab.org/competitions/17119</url>.
    </abstract>
      <url hash="c1cf581f">S18-1115</url>
      <doi>10.18653/v1/S18-1115</doi>
      <bibkey>camacho-collados-etal-2018-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="117">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes</title>
      <author><first>Alicia</first> <last>Krebs</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <author><first>Denis</first> <last>Paperno</last></author>
      <pages>732&#8211;740</pages>
      <abstract>This paper describes the SemEval 2018 Task 10 on Capturing Discriminative Attributes. Participants were asked to identify whether an attribute could help discriminate between two concepts. For example, a successful system should determine that &#8216;urine&#8217; is a discriminating feature in the word pair &#8216;kidney&#8217;, &#8216;bone&#8217;. The aim of the task is to better evaluate the capabilities of state of the art semantic models, beyond pure semantic similarity. The task attracted submissions from 21 teams, and the best system achieved a 0.75 F1 score.</abstract>
      <url hash="34de5cec">S18-1117</url>
      <doi>10.18653/v1/S18-1117</doi>
      <bibkey>krebs-etal-2018-semeval</bibkey>
    </paper>
    <paper id="119">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension Using Commonsense Knowledge</title>
      <author><first>Simon</first> <last>Ostermann</last></author>
      <author><first>Michael</first> <last>Roth</last></author>
      <author><first>Ashutosh</first> <last>Modi</last></author>
      <author><first>Stefan</first> <last>Thater</last></author>
      <author><first>Manfred</first> <last>Pinkal</last></author>
      <pages>747&#8211;757</pages>
      <abstract>This report summarizes the results of the SemEval 2018 task on machine comprehension using commonsense knowledge. For this machine comprehension task, we created a new corpus, MCScript. It contains a high number of questions that require commonsense knowledge for finding the correct answer. 11 teams from 4 different countries participated in this shared task, most of them used neural approaches. The best performing system achieves an accuracy of 83.95%, outperforming the baselines by a large margin, but still far from the human upper bound, which was found to be at 98%.</abstract>
      <url hash="19e9ab5a">S18-1119</url>
      <doi>10.18653/v1/S18-1119</doi>
      <bibkey>ostermann-etal-2018-semeval</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mcscript">MCScript</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/mctest">MCTest</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/newsqa">NewsQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/triviaqa">TriviaQA</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/babi-1">bAbI</pwcdataset>
    </paper>
    <paper id="120">
      <title>Yuanfudao at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension</title>
      <author><first>Liang</first> <last>Wang</last></author>
      <author><first>Meng</first> <last>Sun</last></author>
      <author><first>Wei</first> <last>Zhao</last></author>
      <author><first>Kewei</first> <last>Shen</last></author>
      <author><first>Jingming</first> <last>Liu</last></author>
      <pages>758&#8211;762</pages>
      <abstract>This paper describes our system for SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. We use Three-way Attentive Networks (TriAN) to model interactions between the passage, question and answers. To incorporate commonsense knowledge, we augment the input with relation embedding from the graph of general knowledge ConceptNet. As a result, our system achieves state-of-the-art performance with 83.95% accuracy on the official test data. Code is publicly available at <url>https://github.com/intfloat/commonsense-rc</url>.
    </abstract>
      <url hash="7a23223b">S18-1120</url>
      <doi>10.18653/v1/S18-1120</doi>
      <bibkey>wang-etal-2018-yuanfudao</bibkey>
      <pwccode url="https://github.com/intfloat/commonsense-rc" additional="true">intfloat/commonsense-rc</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/race">RACE</pwcdataset>
    </paper>
    <paper id="121">
      <title><fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: The Argument Reasoning Comprehension Task</title>
      <author><first>Ivan</first> <last>Habernal</last></author>
      <author><first>Henning</first> <last>Wachsmuth</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <author><first>Benno</first> <last>Stein</last></author>
      <pages>763&#8211;772</pages>
      <abstract>A natural language argument is composed of a claim as well as reasons given as premises for the claim. The warrant explaining the reasoning is usually left implicit, as it is clear from the context and common sense. This makes a comprehension of arguments easy for humans but hard for machines. This paper summarizes the first shared task on argument reasoning comprehension. Given a premise and a claim along with some topic information, the goal was to automatically identify the correct warrant among two candidates that are plausible and lexically close, but in fact imply opposite claims. We describe the dataset with 1970 instances that we built for the task, and we outline the 21 computational approaches that participated, most of which used neural networks. The results reveal the complexity of the task, with many approaches hardly improving over the random accuracy of about 0.5. Still, the best observed accuracy (0.712) underlines the principle feasibility of identifying warrants. Our analysis indicates that an inclusion of external knowledge is key to reasoning comprehension.</abstract>
      <url hash="6ae6ad14">S18-1121</url>
      <doi>10.18653/v1/S18-1121</doi>
      <bibkey>habernal-etal-2018-semeval</bibkey>
    </paper>
    <paper id="122">
      <title><fixed-case>GIST</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: A network transferring inference knowledge to Argument Reasoning Comprehension task</title>
      <author><first>HongSeok</first> <last>Choi</last></author>
      <author><first>Hyunju</first> <last>Lee</last></author>
      <pages>773&#8211;777</pages>
      <abstract>This paper describes our GIST team system that participated in SemEval-2018 Argument Reasoning Comprehension task (Task 12). Here, we address two challenging factors: unstated common senses and two lexically close warrants that lead to contradicting claims. A key idea for our system is full use of transfer learning from the Natural Language Inference (NLI) task to this task. We used Enhanced Sequential Inference Model (ESIM) to learn the NLI dataset. We describe how to use ESIM for transfer learning to choose correct warrant through a proposed system. We show comparable results through ablation experiments. Our system ranked 1st among 22 systems, outperforming all the systems more than 10%.</abstract>
      <url hash="18861404">S18-1122</url>
      <doi>10.18653/v1/S18-1122</doi>
      <bibkey>choi-lee-2018-gist</bibkey>
      <pwccode url="https://github.com/hongking9/SemEval-2018-task12" additional="false">hongking9/SemEval-2018-task12</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="123">
      <title><fixed-case>L</fixed-case>ight<fixed-case>R</fixed-case>el at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Lightweight and Fast Relation Classification</title>
      <author><first>Tyler</first> <last>Renslow</last></author>
      <author><first>G&#252;nter</first> <last>Neumann</last></author>
      <pages>778&#8211;782</pages>
      <abstract>We present LightRel, a lightweight and fast relation classifier. Our goal is to develop a high baseline for different relation extraction tasks. By defining only very few data-internal, word-level features and external knowledge sources in the form of word clusters and word embeddings, we train a fast and simple linear classifier</abstract>
      <url hash="4e9b5b4a">S18-1123</url>
      <doi>10.18653/v1/S18-1123</doi>
      <bibkey>renslow-neumann-2018-lightrel</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2010-task-8">SemEval-2010 Task 8</pwcdataset>
    </paper>
    <paper id="124">
      <title><fixed-case>O</fixed-case>hio<fixed-case>S</fixed-case>tate at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Exploiting Data Augmentation for Relation Classification in Scientific Papers Using Piecewise Convolutional Neural Networks</title>
      <author><first>Dushyanta</first> <last>Dhyani</last></author>
      <pages>783&#8211;787</pages>
      <abstract>We describe our system for SemEval-2018 Shared Task on Semantic Relation Extraction and Classification in Scientific Papers where we focus on the Classification task. Our simple piecewise convolution neural encoder performs decently in an end to end manner. A simple inter-task data augmentation significantly boosts the performance of the model. Our best-performing systems stood 8th out of 20 teams on the classification task on noisy data and 12th out of 28 teams on the classification task on clean data.</abstract>
      <url hash="c58346d4">S18-1124</url>
      <doi>10.18653/v1/S18-1124</doi>
      <bibkey>dhyani-2018-ohiostate</bibkey>
    </paper>
    <paper id="126">
      <title><fixed-case>UC</fixed-case>3<fixed-case>M</fixed-case>-<fixed-case>NII</fixed-case> Team at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Classification in Scientific Papers via Convolutional Neural Network</title>
      <author><first>V&#237;ctor</first> <last>Su&#225;rez-Paniagua</last></author>
      <author><first>Isabel</first> <last>Segura-Bedmar</last></author>
      <author><first>Akiko</first> <last>Aizawa</last></author>
      <pages>793&#8211;797</pages>
      <abstract>This paper reports our participation for SemEval-2018 Task 7 on extraction and classification of relationships between entities in scientific papers. Our approach is based on the use of a Convolutional Neural Network (CNN) trained on350 abstract with manually annotated entities and relations. Our hypothesis is that this deep learning model can be applied to extract and classify relations between entities for scientific papers at the same time. We use the Part-of-Speech and the distances to the target entities as part of the embedding for each word and we blind all the entities by marker names. In addition, we use sampling techniques to overcome the imbalance issues of this dataset. Our architecture obtained an F1-score of 35.4% for the relation extraction task and 18.5% for the relation classification task with a basic configuration of the one step CNN.</abstract>
      <url hash="aac62a4a">S18-1126</url>
      <doi>10.18653/v1/S18-1126</doi>
      <bibkey>suarez-paniagua-etal-2018-uc3m</bibkey>
    </paper>
    <paper id="127">
      <title><fixed-case>MIT</fixed-case>-<fixed-case>MEDG</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Classification via Convolution Neural Network</title>
      <author><first>Di</first> <last>Jin</last></author>
      <author><first>Franck</first> <last>Dernoncourt</last></author>
      <author><first>Elena</first> <last>Sergeeva</last></author>
      <author><first>Matthew</first> <last>McDermott</last></author>
      <author><first>Geeticka</first> <last>Chauhan</last></author>
      <pages>798&#8211;804</pages>
      <abstract>SemEval 2018 Task 7 tasked participants to build a system to classify two entities within a sentence into one of the 6 possible relation types. We tested 3 classes of models: Linear classifiers, Long Short-Term Memory (LSTM) models, and Convolutional Neural Network (CNN) models. Ultimately, the CNN model class proved most performant, so we specialized to this model for our final submissions. We improved performance beyond a vanilla CNN by including a variant of negative sampling, using custom word embeddings learned over a corpus of ACL articles, training over corpora of both tasks 1.1 and 1.2, using reversed feature, using part of context words beyond the entity pairs and using ensemble methods to improve our final predictions. We also tested attention based pooling, up-sampling, and data augmentation, but none improved performance. Our model achieved rank 6 out of 28 (macro-averaged F1-score: 72.7) in subtask 1.1, and rank 4 out of 20 (macro F1: 80.6) in subtask 1.2.</abstract>
      <url hash="432eddf1">S18-1127</url>
      <doi>10.18653/v1/S18-1127</doi>
      <bibkey>jin-etal-2018-mit</bibkey>
    </paper>
    <paper id="128">
      <title><fixed-case>SIRIUS</fixed-case>-<fixed-case>LTG</fixed-case>-<fixed-case>U</fixed-case>i<fixed-case>O</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers</title>
      <author><first>Farhad</first> <last>Nooralahzadeh</last></author>
      <author><first>Lilja</first> <last>&#216;vrelid</last></author>
      <author><first>Jan Tore</first> <last>L&#248;nning</last></author>
      <pages>805&#8211;810</pages>
      <abstract>This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path (sdp) between two entities, then we introduce a convolutional neural network (CNN) which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for relation classification on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on clean data, it obtained F1 scores of 37.4 and 33.6 for each phase. Our system ranks 3rd in all three sub-tasks of the shared task.</abstract>
      <url hash="a926772d">S18-1128</url>
      <doi>10.18653/v1/S18-1128</doi>
      <bibkey>nooralahzadeh-etal-2018-sirius</bibkey>
    </paper>
    <paper id="131">
      <title>Texterra at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Exploiting Syntactic Information for Relation Extraction and Classification in Scientific Papers</title>
      <author><first>Andrey</first> <last>Sysoev</last></author>
      <author><first>Vladimir</first> <last>Mayorov</last></author>
      <pages>821&#8211;825</pages>
      <abstract>In this work we evaluate applicability of entity pair models and neural network architectures for relation extraction and classification in scientific papers at SemEval-2018. We carry out experiments with representing entity pairs through sentence tokens and through shortest path in dependency tree, comparing approaches based on convolutional and recurrent neural networks. With convolutional network applied to shortest path in dependency tree we managed to be ranked eighth in subtask 1.1 (&#8220;clean data&#8221;), ninth in 1.2 (&#8220;noisy data&#8221;). Similar model applied to separate parts of the shortest path was mounted to ninth (extraction track) and seventh (classification track) positions in subtask 2 ranking.</abstract>
      <url hash="3023bc3e">S18-1131</url>
      <doi>10.18653/v1/S18-1131</doi>
      <bibkey>sysoev-mayorov-2018-texterra</bibkey>
    </paper>
    <paper id="132">
      <title><fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>a at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Semantic Relation Extraction and Classification from Scientific Publications</title>
      <author><first>Thorsten</first> <last>Keiper</last></author>
      <author><first>Zhonghao</first> <last>Lyu</last></author>
      <author><first>Sara</first> <last>Pooladzadeh</last></author>
      <author><first>Yuan</first> <last>Xu</last></author>
      <author><first>Jingyi</first> <last>Zhang</last></author>
      <author><first>Anne</first> <last>Lauscher</last></author>
      <author><first>Simone Paolo</first> <last>Ponzetto</last></author>
      <pages>826&#8211;830</pages>
      <abstract>Large repositories of scientific literature call for the development of robust methods to extract information from scholarly papers. This problem is addressed by the SemEval 2018 Task 7 on extracting and classifying relations found within scientific publications. In this paper, we present a feature-based and a deep learning-based approach to the task and discuss the results of the system runs that we submitted for evaluation.</abstract>
      <url hash="235910cb">S18-1132</url>
      <doi>10.18653/v1/S18-1132</doi>
      <bibkey>keiper-etal-2018-unima</bibkey>
    </paper>
    <paper id="134">
      <title><fixed-case>C</fixed-case>lai<fixed-case>RE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Classification of Relations using Embeddings</title>
      <author><first>Lena</first> <last>Hettinger</last></author>
      <author><first>Alexander</first> <last>Dallmann</last></author>
      <author><first>Albin</first> <last>Zehe</last></author>
      <author><first>Thomas</first> <last>Niebler</last></author>
      <author><first>Andreas</first> <last>Hotho</last></author>
      <pages>836&#8211;841</pages>
      <abstract>In this paper we describe our system for SemEval-2018 Task 7 on classification of semantic relations in scientific literature for clean (subtask 1.1) and noisy data (subtask 1.2). We compare two models for classification, a C-LSTM which utilizes only word embeddings and an SVM that also takes handcrafted features into account. To adapt to the domain of science we train word embeddings on scientific papers collected from arXiv.org. The hand-crafted features consist of lexical features to model the semantic relations as well as the entities between which the relation holds. Classification of Relations using Embeddings (ClaiRE) achieved an F1 score of 74.89% for the first subtask and 78.39% for the second.</abstract>
      <url hash="5bfbefc2">S18-1134</url>
      <doi>10.18653/v1/S18-1134</doi>
      <bibkey>hettinger-etal-2018-claire</bibkey>
    </paper>
    <paper id="138">
      <title><fixed-case>NTNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Classifier Ensembling for Semantic Relation Identification and Classification in Scientific Papers</title>
      <author><first>Biswanath</first> <last>Barik</last></author>
      <author><first>Utpal Kumar</first> <last>Sikdar</last></author>
      <author><first>Bj&#246;rn</first> <last>Gamb&#228;ck</last></author>
      <pages>858&#8211;862</pages>
      <abstract>The paper presents NTNU&#8217;s contribution to SemEval-2018 Task 7 on relation identification and classification. The class weights and parameters of five alternative supervised classifiers were optimized through grid search and cross-validation. The outputs of the classifiers were combined through voting for the final prediction. A wide variety of features were explored, with the most informative identified by feature selection. The best setting achieved F1 scores of 47.4% and 66.0% in the relation classification subtasks 1.1 and 1.2. For relation identification and classification in subtask 2, it achieved F1 scores of 33.9% and 17.0%,</abstract>
      <url hash="414c121d">S18-1138</url>
      <doi>10.18653/v1/S18-1138</doi>
      <bibkey>barik-etal-2018-ntnu</bibkey>
    </paper>
    <paper id="139">
      <title>Talla at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 7: Hybrid Loss Optimization for Relation Classification using Convolutional Neural Networks</title>
      <author><first>Bhanu</first> <last>Pratap</last></author>
      <author><first>Daniel</first> <last>Shank</last></author>
      <author><first>Oladipo</first> <last>Ositelu</last></author>
      <author><first>Byron</first> <last>Galbraith</last></author>
      <pages>863&#8211;867</pages>
      <abstract>This paper describes our approach to SemEval-2018 Task 7 &#8211; given an entity-tagged text from the ACL Anthology corpus, identify and classify pairs of entities that have one of six possible semantic relationships. Our model consists of a convolutional neural network leveraging pre-trained word embeddings, unlabeled ACL-abstracts, and multiple window sizes to automatically learn useful features from entity-tagged sentences. We also experiment with a hybrid loss function, a combination of cross-entropy loss and ranking loss, to boost the separation in classification scores. Lastly, we include WordNet-based features to further improve the performance of our model. Our best model achieves an F1(macro) score of 74.2 and 84.8 on subtasks 1.1 and 1.2, respectively.</abstract>
      <url hash="f905abb9">S18-1139</url>
      <doi>10.18653/v1/S18-1139</doi>
      <bibkey>pratap-etal-2018-talla</bibkey>
    </paper>
    <paper id="140">
      <title><fixed-case>T</fixed-case>eam<fixed-case>DL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Cybersecurity Text Analysis using Convolutional Neural Network and Conditional Random Fields</title>
      <author><first>Manikandan</first> <last>R</last></author>
      <author><first>Krishna</first> <last>Madgula</last></author>
      <author><first>Snehanshu</first> <last>Saha</last></author>
      <pages>868&#8211;873</pages>
      <abstract>In this work we present our participation to SemEval-2018 Task 8 subtasks 1 &amp; 2 respectively. We developed Convolution Neural Network system for malware sentence classification (subtask 1) and Conditional Random Fields system for malware token label prediction (subtask 2). We experimented with couple of word embedding strategies, feature sets and achieved competitive performance across the two subtasks. For subtask 1 We experimented with two category of word embeddings namely native embeddings and task specific embedding using Word2vec and Glove algorithms. 1. Native Embeddings: All words including the unknown ones that are randomly initialized use embeddings from original Word2vec/Glove models. 2. Task specific : The embeddings are generated by training Word2vec/Glove algorithms on sentences from MalwareTextDB We found that glove outperforms rest of embeddings for subtask 1. For subtask 2, we used N-grams of size 6, previous, next tokens and labels, features giving disjunctions of words anywhere in the left or right, word shape features, word lemma of current, previous and next words, word-tag pair features, POS tags, prefix and suffixes.</abstract>
      <url hash="aed91bba">S18-1140</url>
      <doi>10.18653/v1/S18-1140</doi>
      <bibkey>r-etal-2018-teamdl</bibkey>
    </paper>
    <paper id="141">
      <title><fixed-case>HCCL</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: An End-to-End System for Sequence Labeling from Cybersecurity Reports</title>
      <author><first>Mingming</first> <last>Fu</last></author>
      <author><first>Xuemin</first> <last>Zhao</last></author>
      <author><first>Yonghong</first> <last>Yan</last></author>
      <pages>874&#8211;877</pages>
      <abstract>This paper describes HCCL team systems that participated in SemEval 2018 Task 8: SecureNLP (Semantic Extraction from cybersecurity reports using NLP). To solve the problem, our team applied a neural network architecture that benefits from both word and character level representaions automatically, by using combination of Bi-directional LSTM, CNN and CRF (Ma and Hovy, 2016). Our system is truly end-to-end, requiring no feature engineering or data preprocessing, and we ranked 4th in the subtask 1, 7th in the subtask2 and 3rd in the SubTask2-relaxed.</abstract>
      <url hash="c5f5ff5a">S18-1141</url>
      <doi>10.18653/v1/S18-1141</doi>
      <bibkey>fu-etal-2018-hccl</bibkey>
    </paper>
    <paper id="142">
      <title><fixed-case>UMBC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Understanding Text about Malware</title>
      <author><first>Ankur</first> <last>Padia</last></author>
      <author><first>Arpita</first> <last>Roy</last></author>
      <author><first>Taneeya</first> <last>Satyapanich</last></author>
      <author><first>Francis</first> <last>Ferraro</last></author>
      <author><first>Shimei</first> <last>Pan</last></author>
      <author><first>Youngja</first> <last>Park</last></author>
      <author><first>Anupam</first> <last>Joshi</last></author>
      <author><first>Tim</first> <last>Finin</last></author>
      <pages>878&#8211;884</pages>
      <abstract>We describe the systems developed by the UMBC team for 2018 SemEval Task 8, SecureNLP (Semantic Extraction from CybersecUrity REports using Natural Language Processing). We participated in three of the sub-tasks: (1) classifying sentences as being relevant or irrelevant to malware, (2) predicting token labels for sentences, and (4) predicting attribute labels from the Malware Attribute Enumeration and Characterization vocabulary for defining malware characteristics. We achieve F1 score of 50.34/18.0 (dev/test), 22.23 (test-data), and 31.98 (test-data) for Task1, Task2 and Task2 respectively. We also make our cybersecurity embeddings publicly available at <url>http://bit.ly/cyber2vec</url>.
    </abstract>
      <url hash="d5cba936">S18-1142</url>
      <doi>10.18653/v1/S18-1142</doi>
      <bibkey>padia-etal-2018-umbc</bibkey>
    </paper>
    <paper id="143">
      <title>Villani at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Semantic Extraction from Cybersecurity Reports using Representation Learning</title>
      <author><first>Pablo</first> <last>Loyola</last></author>
      <author><first>Kugamoorthy</first> <last>Gajananan</last></author>
      <author><first>Yuji</first> <last>Watanabe</last></author>
      <author><first>Fumiko</first> <last>Satoh</last></author>
      <pages>885&#8211;889</pages>
      <abstract>In this paper, we describe our proposal for the task of Semantic Extraction from Cybersecurity Reports. The goal is to explore if natural language processing methods can provide relevant and actionable knowledge to contribute to better understand malicious behavior. Our method consists of an attention-based Bi-LSTM which achieved competitive performance of 0.57 for the Subtask 1. In the due process we also present ablation studies across multiple embeddings and their level of representation and also report the strategies we used to mitigate the extreme imbalance between classes.</abstract>
      <url hash="c0d6214b">S18-1143</url>
      <doi>10.18653/v1/S18-1143</doi>
      <bibkey>loyola-etal-2018-villani</bibkey>
    </paper>
    <paper id="145">
      <title>Digital Operatives at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 8: Using dependency features for malware <fixed-case>NLP</fixed-case></title>
      <author><first>Chris</first> <last>Brew</last></author>
      <pages>894&#8211;897</pages>
      <abstract>The four sub-tasks of SecureNLP build towards a capability for quickly highlighting critical information from malware reports, such as the specific actions taken by a malware sample. Digital Operatives (DO) submitted to sub-tasks 1 and 2, using standard text analysis technology (text classification for sub-task 1, and a CRF for sub-task 2). Performance is broadly competitive with other submitted systems on sub-task 1 and weak on sub-task 2. The annotation guidelines for the intermediate sub-tasks create a linkage to the final task, which is both an annotation challenge and a potentially useful feature of the task. The methods that DO chose do not attempt to make use of this linkage, which may be a missed opportunity. This motivates a post-hoc error analysis. It appears that the annotation task is very hard, and that in some cases both deep conceptual knowledge and substantial surrounding context are needed in order to correctly classify sentences.</abstract>
      <url hash="5f711ab7">S18-1145</url>
      <doi>10.18653/v1/S18-1145</doi>
      <bibkey>brew-2018-digital</bibkey>
    </paper>
    <paper id="147">
      <title><fixed-case>SJTU</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: Neural Hypernym Discovery with Term Embeddings</title>
      <author><first>Zhuosheng</first> <last>Zhang</last></author>
      <author><first>Jiangtong</first> <last>Li</last></author>
      <author><first>Hai</first> <last>Zhao</last></author>
      <author><first>Bingjie</first> <last>Tang</last></author>
      <pages>903&#8211;908</pages>
      <abstract>This paper describes a hypernym discovery system for our participation in the SemEval-2018 Task 9, which aims to discover the best (set of) candidate hypernyms for input concepts or entities, given the search space of a pre-defined vocabulary. We introduce a neural network architecture for the concerned task and empirically study various neural network models to build the representations in latent space for words and phrases. The evaluated models include convolutional neural network, long-short term memory network, gated recurrent unit and recurrent convolutional neural network. We also explore different embedding methods, including word embedding and sense embedding for better performance.</abstract>
      <url hash="01e746eb">S18-1147</url>
      <doi>10.18653/v1/S18-1147</doi>
      <bibkey>zhang-etal-2018-sjtu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="148">
      <title><fixed-case>NLP</fixed-case>_<fixed-case>HZ</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: a Nearest Neighbor Approach</title>
      <author><first>Wei</first> <last>Qiu</last></author>
      <author><first>Mosha</first> <last>Chen</last></author>
      <author><first>Linlin</first> <last>Li</last></author>
      <author><first>Luo</first> <last>Si</last></author>
      <pages>909&#8211;913</pages>
      <abstract>Hypernym discovery aims to discover the hypernym word sets given a hyponym word and proper corpus. This paper proposes a simple but effective method for the discovery of hypernym sets based on word embedding, which can be used to measure the contextual similarities between words. Given a test hyponym word, we get its hypernym lists by computing the similarities between the hyponym word and words in the training data, and fill the test word&#8217;s hypernym lists with the hypernym list in the training set of the nearest similarity distance to the test word. In SemEval 2018 task9, our results, achieve 1st on Spanish, 2nd on Italian, 6th on English in the metric of MAP.</abstract>
      <url hash="f5a08a25">S18-1148</url>
      <doi>10.18653/v1/S18-1148</doi>
      <bibkey>qiu-etal-2018-nlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="149">
      <title><fixed-case>UMD</fixed-case>uluth-<fixed-case>CS</fixed-case>8761 at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task9: Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings</title>
      <author><first>Arshia Zernab</first> <last>Hassan</last></author>
      <author><first>Manikya Swathi</first> <last>Vallabhajosyula</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>914&#8211;918</pages>
      <abstract>Hypernym Discovery is the task of identifying potential hypernyms for a given term. A hypernym is a more generalized word that is super-ordinate to more specific words. This paper explores several approaches that rely on co-occurrence frequencies of word pairs, Hearst Patterns based on regular expressions, and word embeddings created from the UMBC corpus. Our system Babbage participated in Subtask 1A for English and placed 6th of 19 systems when identifying concept hypernyms, and 12th of 18 systems for entity hypernyms.</abstract>
      <url hash="948705cf">S18-1149</url>
      <doi>10.18653/v1/S18-1149</doi>
      <bibkey>hassan-etal-2018-umduluth</bibkey>
    </paper>
    <paper id="150">
      <title><fixed-case>EXPR</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 9: A Combined Approach for Hypernym Discovery</title>
      <author><first>Ahmad</first> <last>Issa Alaa Aldine</last></author>
      <author><first>Mounira</first> <last>Harzallah</last></author>
      <author><first>Giuseppe</first> <last>Berio</last></author>
      <author><first>Nicolas</first> <last>B&#233;chet</last></author>
      <author><first>Ahmad</first> <last>Faour</last></author>
      <pages>919&#8211;923</pages>
      <abstract>In this paper, we present our proposed system (EXPR) to participate in the hypernym discovery task of SemEval 2018. The task addresses the challenge of discovering hypernym relations from a text corpus. Our proposal is a combined approach of path-based technique and distributional technique. We use dependency parser on a corpus to extract candidate hypernyms and represent their dependency paths as a feature vector. The feature vector is concatenated with a feature vector obtained using Wikipedia pre-trained term embedding model. The concatenated feature vector fits a supervised machine learning method to learn a classifier model. This model is able to classify new candidate hypernyms as hypernym or not. Our system performs well to discover new hypernyms not defined in gold hypernyms.</abstract>
      <url hash="c396abd8">S18-1150</url>
      <doi>10.18653/v1/S18-1150</doi>
      <bibkey>issa-alaa-aldine-etal-2018-expr</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/semeval-2018-task-9-hypernym-discovery">SemEval-2018 Task 9: Hypernym Discovery</pwcdataset>
    </paper>
    <paper id="154">
      <title>Meaning_space at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Combining explicitly encoded knowledge with information extracted from word embeddings</title>
      <author><first>Pia</first> <last>Sommerauer</last></author>
      <author><first>Antske</first> <last>Fokkens</last></author>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>940&#8211;946</pages>
      <abstract>This paper presents the two systems submitted by the meaning space team in Task 10 of the SemEval competition 2018 entitled Capturing discriminative attributes. The systems consist of combinations of approaches exploiting explicitly encoded knowledge about concepts in WordNet and information encoded in distributional semantic vectors. Rather than aiming for high performance, we explore which kind of semantic knowledge is best captured by different methods. The results indicate that WordNet glosses on different levels of the hierarchy capture many attributes relevant for this task. In combination with exploiting word embedding similarities, this source of information yielded our best results. Our best performing system ranked 5th out of 13 final ranks. Our analysis yields insights into the different kinds of attributes represented by different sources of knowledge.</abstract>
      <url hash="2c9c2249">S18-1154</url>
      <doi>10.18653/v1/S18-1154</doi>
      <bibkey>sommerauer-etal-2018-meaning</bibkey>
    </paper>
    <paper id="156">
      <title><fixed-case>C</fixed-case>itius<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes</title>
      <author><first>Pablo</first> <last>Gamallo</last></author>
      <pages>953&#8211;957</pages>
      <abstract>This article describes the unsupervised strategy submitted by the CitiusNLP team to the SemEval 2018 Task 10, a task which consists of predict whether a word is a discriminative attribute between two other words. Our strategy relies on the correspondence between discriminative attributes and relevant contexts of a word. More precisely, the method uses transparent distributional models to extract salient contexts of words which are identified as discriminative attributes. The system performance reaches about 70% accuracy when it is applied on the development dataset, but its accuracy goes down (63%) on the official test dataset.</abstract>
      <url hash="b755760b">S18-1156</url>
      <doi>10.18653/v1/S18-1156</doi>
      <bibkey>gamallo-2018-citiusnlp</bibkey>
    </paper>
    <paper id="157">
      <title><fixed-case>THU</fixed-case>_<fixed-case>NGN</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes with <fixed-case>MLP</fixed-case>-<fixed-case>CNN</fixed-case> model</title>
      <author><first>Chuhan</first> <last>Wu</last></author>
      <author><first>Fangzhao</first> <last>Wu</last></author>
      <author><first>Sixing</first> <last>Wu</last></author>
      <author><first>Zhigang</first> <last>Yuan</last></author>
      <author><first>Yongfeng</first> <last>Huang</last></author>
      <pages>958&#8211;962</pages>
      <abstract>Existing semantic models are capable of identifying the semantic similarity of words. However, it&#8217;s hard for these models to discriminate between a word and another similar word. Thus, the aim of SemEval-2018 Task 10 is to predict whether a word is a discriminative attribute between two concepts. In this task, we apply a multilayer perceptron (MLP)-convolutional neural network (CNN) model to identify whether an attribute is discriminative. The CNNs are used to extract low-level features from the inputs. The MLP takes both the flatten CNN maps and inputs to predict the labels. The evaluation F-score of our system on the test set is 0.629 (ranked 15th), which indicates that our system still needs to be improved. However, the behaviours of our system in our experiments provide useful information, which can help to improve the collective understanding of this novel task.</abstract>
      <url hash="810b24ea">S18-1157</url>
      <doi>10.18653/v1/S18-1157</doi>
      <bibkey>wu-etal-2018-thu-ngn-semeval-2018</bibkey>
    </paper>
    <paper id="158">
      <title><fixed-case>ALB</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: A System for Capturing Discriminative Attributes</title>
      <author><first>Bogdan</first> <last>Dumitru</last></author>
      <author><first>Alina Maria</first> <last>Ciobanu</last></author>
      <author><first>Liviu P.</first> <last>Dinu</last></author>
      <pages>963&#8211;967</pages>
      <abstract>Semantic difference detection attempts to capture whether a word is a discriminative attribute between two other words. For example, the discriminative feature red characterizes the first word from the (apple, banana) pair, but not the second. Modeling semantic difference is essential for language understanding systems, as it provides useful information for identifying particular aspects of word senses. This paper describes our system implementation (the ALB system of the NLP@Unibuc team) for the 10th task of the SemEval 2018 workshop, &#8220;Capturing Discriminative Attributes&#8221;. We propose a method for semantic difference detection that uses an SVM classifier with features based on co-occurrence counts and shallow semantic parsing, achieving 0.63 F1 score in the competition.</abstract>
      <url hash="c70ae7bc">S18-1158</url>
      <doi>10.18653/v1/S18-1158</doi>
      <bibkey>dumitru-etal-2018-alb</bibkey>
    </paper>
    <paper id="159">
      <title><fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing Discriminative Attributes with Knowledge Graphs and <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Jos&#233;-&#193;ngel</first> <last>Gonz&#225;lez</last></author>
      <author><first>Llu&#237;s-F.</first> <last>Hurtado</last></author>
      <author><first>Encarna</first> <last>Segarra</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <pages>968&#8211;971</pages>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 10, Capturing Discriminative Attributes, of SemEval-2018. Our best approach consists of using ConceptNet, Wikipedia and NumberBatch embeddings in order to stablish relationships between concepts and attributes. Furthermore, this system achieves competitive results in the official evaluation.</abstract>
      <url hash="84ff5880">S18-1159</url>
      <doi>10.18653/v1/S18-1159</doi>
      <bibkey>gonzalez-etal-2018-elirf-upv</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="160">
      <title>Wolves at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Semantic Discrimination based on Knowledge and Association</title>
      <author><first>Shiva</first> <last>Taslimipoor</last></author>
      <author><first>Omid</first> <last>Rohanian</last></author>
      <author><first>Le An</first> <last>Ha</last></author>
      <author><first>Gloria</first> <last>Corpas Pastor</last></author>
      <author><first>Ruslan</first> <last>Mitkov</last></author>
      <pages>972&#8211;976</pages>
      <abstract>This paper describes the system submitted to SemEval 2018 shared task 10 &#8216;Capturing Dicriminative Attributes&#8217;. We use a combination of knowledge-based and co-occurrence features to capture the semantic difference between two words in relation to an attribute. We define scores based on association measures, ngram counts, word similarity, and ConceptNet relations. The system is ranked 4th (joint) on the official leaderboard of the task.</abstract>
      <url hash="f9067449">S18-1160</url>
      <doi>10.18653/v1/S18-1160</doi>
      <bibkey>taslimipoor-etal-2018-wolves</bibkey>
    </paper>
    <paper id="162">
      <title><fixed-case>L</fixed-case>uminoso at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Distinguishing Attributes Using Text Corpora and Relational Knowledge</title>
      <author><first>Robyn</first> <last>Speer</last></author>
      <author><first>Joanna</first> <last>Lowry-Duda</last></author>
      <pages>985&#8211;989</pages>
      <abstract>Luminoso participated in the SemEval 2018 task on &#8220;Capturing Discriminative Attributes&#8221; with a system based on ConceptNet, an open knowledge graph focused on general knowledge. In this paper, we describe how we trained a linear classifier on a small number of semantically-informed features to achieve an F1 score of 0.7368 on the task, close to the task&#8217;s high score of 0.75.</abstract>
      <url hash="aade300c">S18-1162</url>
      <doi>10.18653/v1/S18-1162</doi>
      <revision id="1" href="S18-1162v1" hash="8b47f741" />
      <revision id="2" href="S18-1162v2" hash="aade300c">No description of the changes were recorded.</revision>
      <bibkey>speer-lowry-duda-2018-luminoso</bibkey>
      <pwccode url="https://github.com/LuminosoInsight/semeval-discriminatt" additional="false">LuminosoInsight/semeval-discriminatt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
    </paper>
    <paper id="163">
      <title><fixed-case>B</fixed-case>om<fixed-case>J</fixed-case>i at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes</title>
      <author><first>Enrico</first> <last>Santus</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <author><first>Emmanuele</first> <last>Chersoni</last></author>
      <pages>990&#8211;994</pages>
      <abstract>This paper describes BomJi, a supervised system for capturing discriminative attributes in word pairs (e.g. yellow as discriminative for banana over watermelon). The system relies on an XGB classifier trained on carefully engineered graph-, pattern- and word embedding-based features. It participated in the SemEval-2018 Task 10 on Capturing Discriminative Attributes, achieving an F1 score of 0.73 and ranking 2nd out of 26 participant systems.</abstract>
      <url hash="a817b805">S18-1163</url>
      <doi>10.18653/v1/S18-1163</doi>
      <bibkey>santus-etal-2018-bomji</bibkey>
    </paper>
    <paper id="164">
      <title>Igevorse at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Exploring an Impact of Word Embeddings Concatenation for Capturing Discriminative Attributes</title>
      <author><first>Maxim</first> <last>Grishin</last></author>
      <pages>995&#8211;998</pages>
      <abstract>This paper presents a comparison of several approaches for capturing discriminative attributes and considers an impact of concatenation of several word embeddings of different nature on the classification performance. A similarity-based method is proposed and compared with classical machine learning approaches. It is shown that this method outperforms others on all the considered word vector models and there is a performance increase when concatenated datasets are used.</abstract>
      <url hash="e0d86f6d">S18-1164</url>
      <doi>10.18653/v1/S18-1164</doi>
      <bibkey>grishin-2018-igevorse</bibkey>
    </paper>
    <paper id="166">
      <title><fixed-case>A</fixed-case>mrita<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Capturing discriminative attributes using convolution neural network over global vector representation.</title>
      <author><first>Vivek</first> <last>Vinayan</last></author>
      <author><first>Anand</first> <last>Kumar M</last></author>
      <author><first>Soman</first> <last>K P</last></author>
      <pages>1003&#8211;1007</pages>
      <abstract>The &#8220;Capturing Discriminative Attributes&#8221; sharedtask is the tenth task, conjoint with SemEval2018. The task is to predict if a word can capture distinguishing attributes of one word from another. We use GloVe word embedding, pre-trained on openly sourced corpus for this task. A base representation is initially established over varied dimensions. These representations are evaluated based on validation scores over two models, first on an SVM based classifier and second on a one dimension CNN model. The scores are used to further develop the representation with vector combinations, by considering various distance measures. These measures correspond to offset vectors which are concatenated as features, mainly to improve upon the F1score, with the best accuracy. The features are then further tuned on the validation scores, to achieve highest F1score. Our evaluation narrowed down to two representations, classified on CNN models, having a total dimension length of 1204 &amp; 1203 for the final submissions. Of the two, the latter feature representation delivered our best F1score of 0.658024 (as per result).</abstract>
      <url hash="59281a54">S18-1166</url>
      <doi>10.18653/v1/S18-1166</doi>
      <bibkey>vinayan-etal-2018-amritanlp</bibkey>
    </paper>
    <paper id="167">
      <title>Discriminator at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Minimally Supervised Discrimination</title>
      <author><first>Artur</first> <last>Kulmizev</last></author>
      <author><first>Mostafa</first> <last>Abdou</last></author>
      <author><first>Vinit</first> <last>Ravishankar</last></author>
      <author><first>Malvina</first> <last>Nissim</last></author>
      <pages>1008&#8211;1012</pages>
      <abstract>We participated to the SemEval-2018 shared task on capturing discriminative attributes (Task 10) with a simple system that ranked 8th amongst the 26 teams that took part in the evaluation. Our final score was 0.67, which is competitive with the winning score of 0.75, particularly given that our system is a zero-shot system that requires no training and minimal parameter optimisation. In addition to describing the submitted system, and discussing the implications of the relative success of such a system on this task, we also report on other, more complex models we experimented with.</abstract>
      <url hash="fd6187fe">S18-1167</url>
      <doi>10.18653/v1/S18-1167</doi>
      <bibkey>kulmizev-etal-2018-discriminator</bibkey>
    </paper>
    <paper id="170">
      <title><fixed-case>UMD</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Can Word Embeddings Capture Discriminative Attributes?</title>
      <author><first>Alexander</first> <last>Zhang</last></author>
      <author><first>Marine</first> <last>Carpuat</last></author>
      <pages>1022&#8211;1026</pages>
      <abstract>We describe the University of Maryland&#8217;s submission to SemEval-018 Task 10, &#8220;Capturing Discriminative Attributes&#8221;: given word triples (w1, w2, d), the goal is to determine whether d is a discriminating attribute belonging to w1 but not w2. Our study aims to determine whether word embeddings can address this challenging task. Our submission casts this problem as supervised binary classification using only word embedding features. Using a gaussian SVM model trained only on validation data results in an F-score of 60%. We also show that cosine similarity features are more effective, both in unsupervised systems (F-score of 65%) and supervised systems (F-score of 67%).</abstract>
      <url hash="39c3d201">S18-1170</url>
      <doi>10.18653/v1/S18-1170</doi>
      <bibkey>zhang-carpuat-2018-umd</bibkey>
    </paper>
    <paper id="171">
      <title><fixed-case>NTU</fixed-case> <fixed-case>NLP</fixed-case> Lab System at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 10: Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge</title>
      <author><first>Yow-Ting</first> <last>Shiue</last></author>
      <author><first>Hen-Hsen</first> <last>Huang</last></author>
      <author><first>Hsin-Hsi</first> <last>Chen</last></author>
      <pages>1027&#8211;1033</pages>
      <abstract>This paper presents the NTU NLP Lab system for the SemEval-2018 Capturing Discriminative Attributes task. Word embeddings, pointwise mutual information (PMI), ConceptNet edges and shortest path lengths are utilized as input features to build binary classifiers to tell whether an attribute is discriminative for a pair of concepts. Our neural network model reaches about 73% F1 score on the test set and ranks the 3rd in the task. Though the attributes to deal with in this task are all visual, our models are not provided with any image data. The results indicate that visual information can be derived from textual data.</abstract>
      <url hash="2b673176">S18-1171</url>
      <doi>10.18653/v1/S18-1171</doi>
      <bibkey>shiue-etal-2018-ntu</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/imagenet">ImageNet</pwcdataset>
    </paper>
    <paper id="172">
      <title><fixed-case>EL</fixed-case>i<fixed-case>RF</fixed-case>-<fixed-case>UPV</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension using Commonsense Knowledge</title>
      <author><first>Jos&#233;-&#193;ngel</first> <last>Gonz&#225;lez</last></author>
      <author><first>Llu&#237;s-F.</first> <last>Hurtado</last></author>
      <author><first>Encarna</first> <last>Segarra</last></author>
      <author><first>Ferran</first> <last>Pla</last></author>
      <pages>1034&#8211;1037</pages>
      <abstract>This paper describes the participation of ELiRF-UPV team at task 11, Machine Comprehension using Commonsense Knowledge, of SemEval-2018. Our approach is based on the use of word embeddings, NumberBatch Embeddings, and a Deep Learning architecture to find the best answer for the multiple-choice questions based on the narrative text. The results obtained are in line with those obtained by the other participants and they encourage us to continue working on this problem.</abstract>
      <url hash="3c998991">S18-1172</url>
      <doi>10.18653/v1/S18-1172</doi>
      <bibkey>gonzalez-etal-2018-elirf-upv-semeval</bibkey>
    </paper>
    <paper id="174">
      <title><fixed-case>YNU</fixed-case>_<fixed-case>D</fixed-case>eep at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: An Ensemble of Attention-based <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Models for Machine Comprehension</title>
      <author><first>Peng</first> <last>Ding</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1043&#8211;1047</pages>
      <abstract>We firstly use GloVe to learn the distributed representations automatically from the instance, question and answer triples. Then an attentionbased Bidirectional LSTM (BiLSTM) model is used to encode the triples. We also perform a simple ensemble method to improve the effectiveness of our model. The system we developed obtains an encouraging result on this task. It achieves the accuracy 0.7472 on the test set. We rank 5th according to the official ranking.</abstract>
      <url hash="b0592a20">S18-1174</url>
      <doi>10.18653/v1/S18-1174</doi>
      <bibkey>ding-zhou-2018-ynu</bibkey>
    </paper>
    <paper id="176">
      <title><fixed-case>CSR</fixed-case>eader at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Multiple Choice Question Answering as Textual Entailment</title>
      <author><first>Zhengping</first> <last>Jiang</last></author>
      <author><first>Qi</first> <last>Sun</last></author>
      <pages>1053&#8211;1057</pages>
      <abstract>In this document we present an end-to-end machine reading comprehension system that solves multiple choice questions with a textual entailment perspective. Since some of the knowledge required is not explicitly mentioned in the text, we try to exploit commonsense knowledge by using pretrained word embeddings during contextual embeddings and by dynamically generating a weighted representation of related script knowledge. In the model two kinds of prediction structure are ensembled, and the final accuracy of our system is 10 percent higher than the naiive baseline.</abstract>
      <url hash="59357af1">S18-1176</url>
      <doi>10.18653/v1/S18-1176</doi>
      <bibkey>jiang-sun-2018-csreader</bibkey>
    </paper>
    <paper id="177">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>S</fixed-case>emeval-2018 Task 11: Using an Attention-based <fixed-case>CNN</fixed-case>-<fixed-case>LSTM</fixed-case> for Machine Comprehension using Commonsense Knowledge</title>
      <author><first>Hang</first> <last>Yuan</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>1058&#8211;1062</pages>
      <abstract>This shared task is a typical question answering task. Compared with the normal question and answer system, it needs to give the answer to the question based on the text provided. The essence of the problem is actually reading comprehension. Typically, there are several questions for each text that correspond to it. And for each question, there are two candidate answers (and only one of them is correct). To solve this problem, the usual approach is to use convolutional neural networks (CNN) and recurrent neural network (RNN) or their improved models (such as long short-term memory (LSTM)). In this paper, an attention-based CNN-LSTM model is proposed for this task. By adding an attention mechanism and combining the two models, this experimental result has been significantly improved.</abstract>
      <url hash="06f64a25">S18-1177</url>
      <doi>10.18653/v1/S18-1177</doi>
      <bibkey>yuan-etal-2018-ynu</bibkey>
    </paper>
    <paper id="178">
      <title>Jiangnan at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Deep Neural Network with Attention Method for Machine Comprehension Task</title>
      <author><first>Jiangnan</first> <last>Xia</last></author>
      <pages>1063&#8211;1067</pages>
      <abstract>This paper describes our submission for the International Workshop on Semantic Evaluation (SemEval-2018) shared task 11&#8211; Machine Comprehension using Commonsense Knowledge (Ostermann et al., 2018b). We use a deep neural network model to choose the correct answer from the candidate answers pair when the document and question are given. The interactions between document, question and answers are modeled by attention mechanism and a variety of manual features are used to improve model performance. We also use CoVe (McCann et al., 2017) as an external source of knowledge which is not mentioned in the document. As a result, our system achieves 80.91% accuracy on the test data, which is on the third place of the leaderboard.</abstract>
      <url hash="c226ed6c">S18-1178</url>
      <doi>10.18653/v1/S18-1178</doi>
      <bibkey>xia-2018-jiangnan</bibkey>
    </paper>
    <paper id="180">
      <title>Lyb3b at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Machine Comprehension Task using Deep Learning Models</title>
      <author><first>Yongbin</first> <last>Li</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1073&#8211;1077</pages>
      <abstract>Machine Comprehension of text is a typical Natural Language Processing task which remains an elusive challenge. This paper is to solve the task 11 of SemEval-2018, Machine Comprehension using Commonsense Knowledge task. We use deep learning model to solve the problem. We build distributed word embedding of text, question and answering respectively instead of manually extracting features by linguistic tools. Meanwhile, we use a series of frameworks such as CNN model, LSTM model, LSTM with attention model and biLSTM with attention model for processing word vector. Experiments demonstrate the superior performance of biLSTM with attention framework compared to other models. We also delete high frequency words and combine word vector and data augmentation methods, achieved a certain effect. The approach we proposed rank 6th in official results, with accuracy rate of 0.7437 in test dataset.</abstract>
      <url hash="5488f63e">S18-1180</url>
      <doi>10.18653/v1/S18-1180</doi>
      <bibkey>li-zhou-2018-lyb3b</bibkey>
    </paper>
    <paper id="181">
      <title><fixed-case>MITRE</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 11: Commonsense Reasoning without Commonsense Knowledge</title>
      <author><first>Elizabeth</first> <last>Merkhofer</last></author>
      <author><first>John</first> <last>Henderson</last></author>
      <author><first>David</first> <last>Bloom</last></author>
      <author><first>Laura</first> <last>Strickhart</last></author>
      <author><first>Guido</first> <last>Zarrella</last></author>
      <pages>1078&#8211;1082</pages>
      <abstract>This paper describes MITRE&#8217;s participation in SemEval-2018 Task 11: Machine Comprehension using Commonsense Knowledge. The techniques explored range from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Logistic regression ties the systems together into an ensemble submitted for evaluation. The resulting system answers reading comprehension questions with 82.27% accuracy.</abstract>
      <url hash="8a899252">S18-1181</url>
      <doi>10.18653/v1/S18-1181</doi>
      <bibkey>merkhofer-etal-2018-mitre</bibkey>
    </paper>
    <paper id="182">
      <title><fixed-case>SNU</fixed-case>_<fixed-case>IDS</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension</title>
      <author><first>Taeuk</first> <last>Kim</last></author>
      <author><first>Jihun</first> <last>Choi</last></author>
      <author><first>Sang-goo</first> <last>Lee</last></author>
      <pages>1083&#8211;1088</pages>
      <abstract>We present a novel neural architecture for the Argument Reasoning Comprehension task of SemEval 2018. It is a simple neural network consisting of three parts, collectively judging whether the logic built on a set of given sentences (a claim, reason, and warrant) is plausible or not. The model utilizes contextualized word vectors pre-trained on large machine translation (MT) datasets as a form of transfer learning, which can help to mitigate the lack of training data. Quantitative analysis shows that simply leveraging LSTMs trained on MT datasets outperforms several baselines and non-transferred models, achieving accuracies of about 70% on the development set and about 60% on the test set.</abstract>
      <url hash="158aea38">S18-1182</url>
      <doi>10.18653/v1/S18-1182</doi>
      <bibkey>kim-etal-2018-snu</bibkey>
      <pwccode url="https://github.com/galsang/SemEval2018-task12" additional="false">galsang/SemEval2018-task12</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="183">
      <title><fixed-case>ITNLP</fixed-case>-<fixed-case>ARC</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Argument Reasoning Comprehension with Attention</title>
      <author><first>Wenjie</first> <last>Liu</last></author>
      <author><first>Chengjie</first> <last>Sun</last></author>
      <author><first>Lei</first> <last>Lin</last></author>
      <author><first>Bingquan</first> <last>Liu</last></author>
      <pages>1089&#8211;1093</pages>
      <abstract>Reasoning is a very important topic and has many important applications in the field of natural language processing. Semantic Evaluation (SemEval) 2018 Task 12 &#8220;The Argument Reasoning Comprehension&#8221; committed to research natural language reasoning. In this task, we proposed a novel argument reasoning comprehension system, ITNLP-ARC, which use Neural Networks technology to solve this problem. In our system, the LSTM model is involved to encode both the premise sentences and the warrant sentences. The attention model is used to merge the two premise sentence vectors. Through comparing the similarity between the attention vector and each of the two warrant vectors, we choose the one with higher similarity as our system&#8217;s final answer.</abstract>
      <url hash="6b4476fe">S18-1183</url>
      <doi>10.18653/v1/S18-1183</doi>
      <bibkey>liu-etal-2018-itnlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="184">
      <title><fixed-case>ECNU</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task</title>
      <author><first>Junfeng</first> <last>Tian</last></author>
      <author><first>Man</first> <last>Lan</last></author>
      <author><first>Yuanbin</first> <last>Wu</last></author>
      <pages>1094&#8211;1098</pages>
      <abstract>This paper presents our submissions to SemEval 2018 Task 12: the Argument Reasoning Comprehension Task. We investigate an end-to-end attention-based neural network to represent the two lexically close candidate warrants. On the one hand, we extract their different parts as attention vectors to obtain distinguishable representations. On the other hand, we use their surrounds (i.e., claim, reason, debate context) as another attention vectors to get contextual representations, which work as final clues to select the correct warrant. Our model achieves 60.4% accuracy and ranks 3rd among 22 participating systems.</abstract>
      <url hash="77ac67cd">S18-1184</url>
      <doi>10.18653/v1/S18-1184</doi>
      <bibkey>tian-etal-2018-ecnu</bibkey>
    </paper>
    <paper id="185">
      <title><fixed-case>NLIT</fixed-case>rans at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension</title>
      <author><first>Timothy</first> <last>Niven</last></author>
      <author><first>Hung-Yu</first> <last>Kao</last></author>
      <pages>1099&#8211;1103</pages>
      <abstract>The Argument Reasoning Comprehension Task is a difficult challenge requiring significant language understanding and complex reasoning over world knowledge. We focus on transfer of a sentence encoder to bootstrap more complicated architectures given the small size of the dataset. Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching. This model achieves mean test set accuracy of 61.31%. Encoder transfer yields a significant gain to our best model over random initialization. Sharing parameters for independent warrant evaluation provides regularization and effectively doubles the size of the dataset. We demonstrate that regularization comes from ignoring statistical correlations between warrant positions. We also report an experiment with our best model that only matches warrants to reasons, ignoring claims. Performance is still competitive, suggesting that our model is not necessarily learning the intended task.</abstract>
      <url hash="4441c9ce">S18-1185</url>
      <doi>10.18653/v1/S18-1185</doi>
      <bibkey>niven-kao-2018-nlitrans</bibkey>
      <pwccode url="https://github.com/IKMLab/arct" additional="false">IKMLab/arct</pwccode>
    </paper>
    <paper id="186">
      <title><fixed-case>BLCU</fixed-case>_<fixed-case>NLP</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: An Ensemble Model for Argument Reasoning Based on Hierarchical Attention</title>
      <author><first>Meiqian</first> <last>Zhao</last></author>
      <author><first>Chunhua</first> <last>Liu</last></author>
      <author><first>Lu</first> <last>Liu</last></author>
      <author><first>Yan</first> <last>Zhao</last></author>
      <author><first>Dong</first> <last>Yu</last></author>
      <pages>1104&#8211;1108</pages>
      <abstract>To comprehend an argument and fill the gap between claims and reasons, it is vital to find the implicit supporting warrants behind. In this paper, we propose a hierarchical attention model to identify the right warrant which explains why the reason stands for the claim. Our model focuses not only on the similar part between warrants and other information but also on the contradictory part between two opposing warrants. In addition, we use the ensemble method for different models. Our model achieves an accuracy of 61%, ranking second in this task. Experimental results demonstrate that our model is effective to make correct choices.</abstract>
      <url hash="c14de464">S18-1186</url>
      <doi>10.18653/v1/S18-1186</doi>
      <bibkey>zhao-etal-2018-blcu</bibkey>
    </paper>
    <paper id="189">
      <title><fixed-case>YNU</fixed-case> Deep at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: A <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Model with Neural Attention for Argument Reasoning Comprehension</title>
      <author><first>Peng</first> <last>Ding</last></author>
      <author><first>Xiaobing</first> <last>Zhou</last></author>
      <pages>1120&#8211;1123</pages>
      <abstract>This paper describes the system submitted to SemEval-2018 Task 12 (The Argument Reasoning Comprehension Task). Enabling a computer to understand a text so that it can answer comprehension questions is still a challenging goal of NLP. We propose a Bidirectional LSTM (BiLSTM) model that reads two sentences separated by a delimiter to determine which warrant is correct. We extend this model with a neural attention mechanism that encourages the model to make reasoning over the given claims and reasons. Officially released results show that our system ranks 6th among 22 submissions to this task.</abstract>
      <url hash="60c8cf31">S18-1189</url>
      <doi>10.18653/v1/S18-1189</doi>
      <bibkey>ding-zhou-2018-ynu-deep</bibkey>
    </paper>
    <paper id="190">
      <title><fixed-case>U</fixed-case>ni<fixed-case>M</fixed-case>elb at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Generative Implication using <fixed-case>LSTM</fixed-case>s, <fixed-case>S</fixed-case>iamese Networks and Semantic Representations with Synonym Fuzzing</title>
      <author><first>Anirudh</first> <last>Joshi</last></author>
      <author><first>Tim</first> <last>Baldwin</last></author>
      <author><first>Richard O.</first> <last>Sinnott</last></author>
      <author><first>Cecile</first> <last>Paris</last></author>
      <pages>1124&#8211;1128</pages>
      <abstract>This paper describes a warrant classification system for SemEval 2018 Task 12, that attempts to learn semantic representations of reasons, claims and warrants. The system consists of 3 stacked LSTMs: one for the reason, one for the claim, and one shared Siamese Network for the 2 candidate warrants. Our main contribution is to force the embeddings into a shared feature space using vector operations, semantic similarity classification, Siamese networks, and multi-task learning. In doing so, we learn a form of generative implication, in encoding implication interrelationships between reasons, claims, and the associated correct and incorrect warrants. We augment the limited data in the task further by utilizing WordNet synonym &#8220;fuzzing&#8221;. When applied to SemEval 2018 Task 12, our system performs well on the development data, and officially ranked 8th among 21 teams.</abstract>
      <url hash="a382f263">S18-1190</url>
      <doi>10.18653/v1/S18-1190</doi>
      <bibkey>joshi-etal-2018-unimelb</bibkey>
    </paper>
    <paper id="191">
      <title>Joker at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: The Argument Reasoning Comprehension with Neural Attention</title>
      <author><last>Sui</last> <first>Guobin</first></author>
      <author><last>Chao</last> <first>Wenhan</first></author>
      <author><last>Luo</last> <first>Zhunchen</first></author>
      <pages>1129&#8211;1132</pages>
      <abstract>This paper describes a classification system that participated in the SemEval-2018 Task 12: The Argument Reasoning Comprehension Task. Briefly the task can be described as that a natural language &#8220;argument&#8221; is what we have, with reason, claim, and correct and incorrect warrants, and we need to choose the correct warrant. In order to make fully understand of the semantic information of the sentences, we proposed a neural network architecture with attention mechanism to achieve this goal. Besides we try to introduce keywords into the model to improve accuracy. Finally the proposed system achieved 5th place among 22 participating systems</abstract>
      <url hash="2464d0ae">S18-1191</url>
      <doi>10.18653/v1/S18-1191</doi>
      <bibkey>sui-etal-2018-joker</bibkey>
    </paper>
    <paper id="194">
      <title><fixed-case>TRANSRW</fixed-case> at <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val-2018 Task 12: Transforming Semantic Representations for Argument Reasoning Comprehension</title>
      <author><first>Zhimin</first> <last>Chen</last></author>
      <author><first>Wei</first> <last>Song</last></author>
      <author><first>Lizhen</first> <last>Liu</last></author>
      <pages>1142&#8211;1145</pages>
      <abstract>This paper describes our system in SemEval-2018 task 12: Argument Reasoning Comprehension. The task is to select the correct warrant that explains reasoning of a particular argument consisting of a claim and a reason. The main idea of our methods is based on the assumption that the semantic composition of the reason and the warrant should be close to the semantic representation of the corresponding claim. We propose two neural network models. The first one considers two warrant candidates simultaneously, while the second one processes each candidate separately and then chooses the best one. We also incorporate sentiment polarity by assuming that there are kinds of sentiment associations between the reason, the warrant and the claim. The experiments show that the first framework is more effective and sentiment polarity is useful.</abstract>
      <url hash="b28328b3">S18-1194</url>
      <doi>10.18653/v1/S18-1194</doi>
      <bibkey>chen-etal-2018-transrw</bibkey>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</booktitle>
      <url hash="78ba5d5e">S18-2</url>
      <editor><first>Malvina</first> <last>Nissim</last></editor>
      <editor><first>Jonathan</first> <last>Berant</last></editor>
      <editor><first>Alessandro</first> <last>Lenci</last></editor>
      <doi>10.18653/v1/S18-2</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>New Orleans, Louisiana</address>
      <month>June</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="25e979dc">S18-2000</url>
      <bibkey>semeval-2018-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Resolving Event Coreference with Supervised Representation Learning and Clustering-Oriented Regularization</title>
      <author><first>Kian</first> <last>Kenyon-Dean</last></author>
      <author><first>Jackie Chi Kit</first> <last>Cheung</last></author>
      <author><first>Doina</first> <last>Precup</last></author>
      <pages>1&#8211;10</pages>
      <abstract>We present an approach to event coreference resolution by developing a general framework for clustering that uses supervised representation learning. We propose a neural network architecture with novel Clustering-Oriented Regularization (CORE) terms in the objective function. These terms encourage the model to create embeddings of event mentions that are amenable to clustering. We then use agglomerative clustering on these embeddings to build event coreference chains. For both within- and cross-document coreference on the ECB+ corpus, our model obtains better results than models that require significantly more pre-annotated information. This work provides insight and motivating results for a new general approach to solving coreference and clustering problems with representation learning.</abstract>
      <url hash="9eacb95e">S18-2001</url>
      <doi>10.18653/v1/S18-2001</doi>
      <bibkey>kenyon-dean-etal-2018-resolving</bibkey>
      <pwccode url="https://github.com/kiankd/events" additional="false">kiankd/events</pwccode>
    </paper>
    <paper id="2">
      <title>Learning distributed event representations with a multi-task approach</title>
      <author><first>Xudong</first> <last>Hong</last></author>
      <author><first>Asad</first> <last>Sayeed</last></author>
      <author><first>Vera</first> <last>Demberg</last></author>
      <pages>11&#8211;21</pages>
      <abstract>Human world knowledge contains information about prototypical events and their participants and locations. In this paper, we train the first models using multi-task learning that can both predict missing event participants and also perform semantic role classification based on semantic plausibility. Our best-performing model is an improvement over the previous state-of-the-art on thematic fit modelling tasks. The event embeddings learned by the model can additionally be used effectively in an event similarity task, also outperforming the state-of-the-art.</abstract>
      <url hash="f61e3151">S18-2002</url>
      <doi>10.18653/v1/S18-2002</doi>
      <bibkey>hong-etal-2018-learning</bibkey>
    </paper>
    <paper id="3">
      <title>Assessing Meaning Components in <fixed-case>G</fixed-case>erman Complex Verbs: A Collection of Source-Target Domains and Directionality</title>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <author><first>Maximilian</first> <last>K&#246;per</last></author>
      <author><first>Sylvia</first> <last>Springorum</last></author>
      <pages>22&#8211;32</pages>
      <abstract>This paper presents a collection to assess meaning components in German complex verbs, which frequently undergo meaning shifts. We use a novel strategy to obtain source and target domain characterisations via sentence generation rather than sentence annotation. A selection of arrows adds spatial directional information to the generated contexts. We provide a broad qualitative description of the dataset, and a series of standard classification experiments verifies the quantitative reliability of the presented resource. The setup for collecting the meaning components is applicable also to other languages, regarding complex verbs as well as other language-specific targets that involve meaning shifts.</abstract>
      <url hash="7b804ed2">S18-2003</url>
      <doi>10.18653/v1/S18-2003</doi>
      <bibkey>schulte-im-walde-etal-2018-assessing</bibkey>
    </paper>
    <paper id="7">
      <title>Mixing Context Granularities for Improved Entity Linking on Question Answering Data across Entity Categories</title>
      <author><first>Daniil</first> <last>Sorokin</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>65&#8211;75</pages>
      <abstract>The first stage of every knowledge base question answering approach is to link entities in the input question. We investigate entity linking in the context of question answering task and present a jointly optimized neural architecture for entity mention detection and entity disambiguation that models the surrounding context on different levels of granularity. We use the Wikidata knowledge base and available question answering datasets to create benchmarks for entity linking on question answering data. Our approach outperforms the previous state-of-the-art system on this data, resulting in an average 8% improvement of the final score. We further demonstrate that our model delivers a strong performance across different entity categories.</abstract>
      <url hash="4864b567">S18-2007</url>
      <doi>10.18653/v1/S18-2007</doi>
      <bibkey>sorokin-gurevych-2018-mixing</bibkey>
      <pwccode url="https://github.com/UKPLab/starsem2018-entity-linking" additional="false">UKPLab/starsem2018-entity-linking</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/webquestions">WebQuestions</pwcdataset>
    </paper>
    <paper id="8">
      <title>Quantitative Semantic Variation in the Contexts of Concrete and Abstract Words</title>
      <author><first>Daniela</first> <last>Naumann</last></author>
      <author><first>Diego</first> <last>Frassinelli</last></author>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <pages>76&#8211;85</pages>
      <abstract>Across disciplines, researchers are eager to gain insight into empirical features of abstract vs. concrete concepts. In this work, we provide a detailed characterisation of the distributional nature of abstract and concrete words across 16,620 English nouns, verbs and adjectives. Specifically, we investigate the following questions: (1) What is the distribution of concreteness in the contexts of concrete and abstract target words? (2) What are the differences between concrete and abstract words in terms of contextual semantic diversity? (3) How does the entropy of concrete and abstract word contexts differ? Overall, our studies show consistent differences in the distributional representation of concrete and abstract words, thus challenging existing theories of cognition and providing a more fine-grained description of their nature.</abstract>
      <url hash="907c91aa">S18-2008</url>
      <doi>10.18653/v1/S18-2008</doi>
      <bibkey>naumann-etal-2018-quantitative</bibkey>
    </paper>
    <paper id="10">
      <title>The Limitations of Cross-language Word Embeddings Evaluation</title>
      <author><first>Amir</first> <last>Bakarov</last></author>
      <author><first>Roman</first> <last>Suvorov</last></author>
      <author><first>Ilya</first> <last>Sochenkov</last></author>
      <pages>94&#8211;100</pages>
      <abstract>The aim of this work is to explore the possible limitations of existing methods of cross-language word embeddings evaluation, addressing the lack of correlation between intrinsic and extrinsic cross-language evaluation methods. To prove this hypothesis, we construct English-Russian datasets for extrinsic and intrinsic evaluation tasks and compare performances of 5 different cross-language models on them. The results say that the scores even on different intrinsic benchmarks do not correlate to each other. We can conclude that the use of human references as ground truth for cross-language word embeddings is not proper unless one does not understand how do native speakers process semantics in their cognition.</abstract>
      <url hash="b5b95a20">S18-2010</url>
      <doi>10.18653/v1/S18-2010</doi>
      <bibkey>bakarov-etal-2018-limitations</bibkey>
      <pwccode url="https://github.com/bakarov/cross-lang-embeddings" additional="false">bakarov/cross-lang-embeddings</pwccode>
    </paper>
    <paper id="11">
      <title>How Gender and Skin Tone Modifiers Affect Emoji Semantics in <fixed-case>T</fixed-case>witter</title>
      <author><first>Francesco</first> <last>Barbieri</last></author>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <pages>101&#8211;106</pages>
      <abstract>In this paper we analyze the use of emojis in social media with respect to gender and skin tone. By gathering a dataset of over twenty two million tweets from United States some findings are clearly highlighted after performing a simple frequency-based analysis. Moreover, we carry out a semantic analysis on the usage of emojis and their modifiers (e.g. gender and skin tone) by embedding all words, emojis and modifiers into the same vector space. Our analyses reveal that some stereotypes related to the skin color and gender seem to be reflected on the use of these modifiers. For example, emojis representing hand gestures are more widely utilized with lighter skin tones, and the usage across skin tones differs significantly. At the same time, the vector corresponding to the male modifier tends to be semantically close to emojis related to business or technology, whereas their female counterparts appear closer to emojis about love or makeup.</abstract>
      <url hash="327e0759">S18-2011</url>
      <doi>10.18653/v1/S18-2011</doi>
      <bibkey>barbieri-camacho-collados-2018-gender</bibkey>
      <pwccode url="https://github.com/fvancesco/emoji_modifiers" additional="false">fvancesco/emoji_modifiers</pwccode>
    </paper>
    <paper id="14">
      <title>Learning Patient Representations from Text</title>
      <author><first>Dmitriy</first> <last>Dligach</last></author>
      <author><first>Timothy</first> <last>Miller</last></author>
      <pages>119&#8211;123</pages>
      <abstract>Mining electronic health records for patients who satisfy a set of predefined criteria is known in medical informatics as phenotyping. Phenotyping has numerous applications such as outcome prediction, clinical trial recruitment, and retrospective studies. Supervised machine learning for phenotyping typically relies on sparse patient representations such as bag-of-words. We consider an alternative that involves learning patient representations. We develop a neural network model for learning patient representations and show that the learned representations are general enough to obtain state-of-the-art performance on a standard comorbidity detection task.</abstract>
      <url hash="2d079f55">S18-2014</url>
      <doi>10.18653/v1/S18-2014</doi>
      <bibkey>dligach-miller-2018-learning</bibkey>
      <pwccode url="https://github.com/dmitriydligach/starsem2018-patient-representations" additional="false">dmitriydligach/starsem2018-patient-representations</pwccode>
    </paper>
    <paper id="15">
      <title>Polarity Computations in Flexible Categorial Grammar</title>
      <author><first>Hai</first> <last>Hu</last></author>
      <author><first>Larry</first> <last>Moss</last></author>
      <pages>124&#8211;129</pages>
      <abstract>This paper shows how to take parse trees in CCG and algorithmically find the polarities of all the constituents. Our work uses the well-known polarization principle corresponding to function application, and we have extended this with principles for type raising and composition. We provide an algorithm, extending the polarity marking algorithm of van Benthem. We discuss how our system works in practice, taking input from the C&amp;C parser.</abstract>
      <url hash="8c345d0c">S18-2015</url>
      <doi>10.18653/v1/S18-2015</doi>
      <bibkey>hu-moss-2018-polarity</bibkey>
      <pwccode url="https://github.com/huhailinguist/ccg2mono" additional="false">huhailinguist/ccg2mono</pwccode>
    </paper>
    <paper id="17">
      <title><fixed-case>H</fixed-case>alo: Learning Semantics-Aware Representations for Cross-Lingual Information Extraction</title>
      <author><first>Hongyuan</first> <last>Mei</last></author>
      <author><first>Sheng</first> <last>Zhang</last></author>
      <author><first>Kevin</first> <last>Duh</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>142&#8211;147</pages>
      <abstract>Cross-lingual information extraction (CLIE) is an important and challenging task, especially in low resource scenarios. To tackle this challenge, we propose a training method, called <i>Halo</i>, which enforces the local region of each hidden state of a neural model
      to only generate target tokens with the same semantic structure tag. This
      simple but powerful technique enables a neural model to learn
      semantics-aware representations that are robust to noise, without
      introducing any extra parameter, thus yielding better generalization in
      both high and low resource settings.
    </abstract>
      <url hash="11aa2329">S18-2017</url>
      <doi>10.18653/v1/S18-2017</doi>
      <bibkey>mei-etal-2018-halo</bibkey>
    </paper>
    <paper id="19">
      <title>Predicting Word Embeddings Variability</title>
      <author><first>B&#233;n&#233;dicte</first> <last>Pierrejean</last></author>
      <author><first>Ludovic</first> <last>Tanguy</last></author>
      <pages>154&#8211;159</pages>
      <abstract>Neural word embeddings models (such as those built with word2vec) are known to have stability problems: when retraining a model with the exact same hyperparameters, words neighborhoods may change. We propose a method to estimate such variation, based on the overlap of neighbors of a given word in two models trained with identical hyperparameters. We show that this inherent variation is not negligible, and that it does not affect every word in the same way. We examine the influence of several features that are intrinsic to a word, corpus or embedding model and provide a methodology that can predict the variability (and as such, reliability) of a word representation in a semantic vector space.</abstract>
      <url hash="366bbcdd">S18-2019</url>
      <doi>10.18653/v1/S18-2019</doi>
      <bibkey>pierrejean-tanguy-2018-predicting</bibkey>
    </paper>
    <paper id="20">
      <title>Integrating Multiplicative Features into Supervised Distributional Methods for Lexical Entailment</title>
      <author><first>Tu</first> <last>Vu</last></author>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <pages>160&#8211;166</pages>
      <abstract>Supervised distributional methods are applied successfully in lexical entailment, but recent work questioned whether these methods actually learn a relation between two words. Specifically, Levy et al. (2015) claimed that linear classifiers learn only separate properties of each word. We suggest a cheap and easy way to boost the performance of these methods by integrating multiplicative features into commonly used representations. We provide an extensive evaluation with different classifiers and evaluation setups, and suggest a suitable evaluation setup for the task, eliminating biases existing in previous ones.</abstract>
      <url hash="c68397a4">S18-2020</url>
      <doi>10.18653/v1/S18-2020</doi>
      <bibkey>vu-shwartz-2018-integrating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
    </paper>
    <paper id="21">
      <title>Deep Affix Features Improve Neural Named Entity Recognizers</title>
      <author><first>Vikas</first> <last>Yadav</last></author>
      <author><first>Rebecca</first> <last>Sharp</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <pages>167&#8211;172</pages>
      <abstract>We propose a practical model for named entity recognition (NER) that combines word and character-level information with a specific learned representation of the prefixes and suffixes of the word. We apply this approach to multilingual and multi-domain NER and show that it achieves state of the art results on the CoNLL 2002 Spanish and Dutch and CoNLL 2003 German NER datasets, consistently achieving 1.5-2.3 percent over the state of the art without relying on any dictionary features. Additionally, we show improvement on SemEval 2013 task 9.1 DrugNER, achieving state of the art results on the MedLine dataset and the second best results overall (-1.3% from state of the art). We also establish a new benchmark on the I2B2 2010 Clinical NER dataset with 84.70 F-score.</abstract>
      <url hash="c0fc9cd8">S18-2021</url>
      <doi>10.18653/v1/S18-2021</doi>
      <bibkey>yadav-etal-2018-deep</bibkey>
      <pwccode url="https://github.com/vikas95/Pref_Suff_Span_NN" additional="false">vikas95/Pref_Suff_Span_NN</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2002">CoNLL 2002</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
    </paper>
    <paper id="23">
      <title>Hypothesis Only Baselines in Natural Language Inference</title>
      <author><first>Adam</first> <last>Poliak</last></author>
      <author><first>Jason</first> <last>Naradowsky</last></author>
      <author><first>Aparajita</first> <last>Haldar</last></author>
      <author><first>Rachel</first> <last>Rudinger</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>180&#8211;191</pages>
      <abstract>We propose a hypothesis only baseline for diagnosing Natural Language Inference (NLI). Especially when an NLI dataset assumes inference is occurring based purely on the relationship between a context and a hypothesis, it follows that assessing entailment relations while ignoring the provided context is a degenerate solution. Yet, through experiments on 10 distinct NLI datasets, we find that this approach, which we refer to as a hypothesis-only model, is able to significantly outperform a majority-class baseline across a number of NLI datasets. Our analysis suggests that statistical irregularities may allow a model to perform NLI in some datasets beyond what should be achievable without access to the context.</abstract>
      <url hash="d2c72451">S18-2023</url>
      <doi>10.18653/v1/S18-2023</doi>
      <bibkey>poliak-etal-2018-hypothesis</bibkey>
      <pwccode url="https://github.com/azpoliak/hypothesis-only-NLI" additional="false">azpoliak/hypothesis-only-NLI</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/flickr30k">Flickr30k</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sick">SICK</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="25">
      <title>Term Definitions Help Hypernymy Detection</title>
      <author><first>Wenpeng</first> <last>Yin</last></author>
      <author><first>Dan</first> <last>Roth</last></author>
      <pages>203&#8211;213</pages>
      <abstract>Existing methods of hypernymy detection mainly rely on statistics over a big corpus, either mining some co-occurring patterns like &#8220;animals such as cats&#8221; or embedding words of interest into context-aware vectors. These approaches are therefore limited by the availability of a large enough corpus that can cover all terms of interest and provide sufficient contextual information to represent their meaning. In this work, we propose a new paradigm, HyperDef, for hypernymy detection &#8211; expressing word meaning by encoding word definitions, along with context driven representation. This has two main benefits: (i) Definitional sentences express (sense-specific) corpus-independent meanings of words, hence definition-driven approaches enable strong generalization &#8211; once trained, the model is expected to work well in open-domain testbeds; (ii) Global context from a large corpus and definitions provide complementary information for words. Consequently, our model, HyperDef, once trained on task-agnostic data, gets state-of-the-art results in multiple benchmarks</abstract>
      <url hash="8d7e76f0">S18-2025</url>
      <doi>10.18653/v1/S18-2025</doi>
      <bibkey>yin-roth-2018-term</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/evalution">EVALution</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/yago">YAGO</pwcdataset>
    </paper>
    <paper id="26">
      <title>Agree or Disagree: Predicting Judgments on Nuanced Assertions</title>
      <author><first>Michael</first> <last>Wojatzki</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <pages>214&#8211;224</pages>
      <abstract>Being able to predict whether people agree or disagree with an assertion (i.e. an explicit, self-contained statement) has several applications ranging from predicting how many people will like or dislike a social media post to classifying posts based on whether they are in accordance with a particular point of view. We formalize this as two NLP tasks: predicting judgments of (i) individuals and (ii) groups based on the text of the assertion and previous judgments. We evaluate a wide range of approaches on a crowdsourced data set containing over 100,000 judgments on over 2,000 assertions. We find that predicting individual judgments is a hard task with our best results only slightly exceeding a majority baseline, but that judgments of groups can be more reliably predicted using a Siamese neural network, which outperforms all other approaches by a wide margin.</abstract>
      <url hash="b2e59d87">S18-2026</url>
      <doi>10.18653/v1/S18-2026</doi>
      <bibkey>wojatzki-etal-2018-agree</bibkey>
      <pwccode url="https://github.com/muchafel/judgmentPrediction" additional="false">muchafel/judgmentPrediction</pwccode>
    </paper>
    <paper id="29">
      <title>Measuring Frame Instance Relatedness</title>
      <author><first>Valerio</first> <last>Basile</last></author>
      <author><first>Roque</first> <last>Lopez Condori</last></author>
      <author><first>Elena</first> <last>Cabrio</last></author>
      <pages>245&#8211;254</pages>
      <abstract>Frame semantics is a well-established framework to represent the meaning of natural language in computational terms. In this work, we aim to propose a quantitative measure of relatedness between pairs of frame instances. We test our method on a dataset of sentence pairs, highlighting the correlation between our metric and human judgments of semantic similarity. Furthermore, we propose an application of our measure for clustering frame instances to extract prototypical knowledge from natural language.</abstract>
      <url hash="11f1e222">S18-2029</url>
      <doi>10.18653/v1/S18-2029</doi>
      <bibkey>basile-etal-2018-measuring</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/framenet">FrameNet</pwcdataset>
    </paper>
    <paper id="30">
      <title>Solving Feature Sparseness in Text Classification using Core-Periphery Decomposition</title>
      <author><first>Xia</first> <last>Cui</last></author>
      <author><first>Sadamori</first> <last>Kojaku</last></author>
      <author><first>Naoki</first> <last>Masuda</last></author>
      <author><first>Danushka</first> <last>Bollegala</last></author>
      <pages>255&#8211;264</pages>
      <abstract>Feature sparseness is a problem common to cross-domain and short-text classification tasks. To overcome this feature sparseness problem, we propose a novel method based on graph decomposition to find candidate features for expanding feature vectors. Specifically, we first create a feature-relatedness graph, which is subsequently decomposed into core-periphery (CP) pairs and use the peripheries as the expansion candidates of the cores. We expand both training and test instances using the computed related features and use them to train a text classifier. We observe that prioritising features that are common to both training and test instances as cores during the CP decomposition to further improve the accuracy of text classification. We evaluate the proposed CP-decomposition-based feature expansion method on benchmark datasets for cross-domain sentiment classification and short-text classification. Our experimental results show that the proposed method consistently outperforms all baselines on short-text classification tasks, and perform competitively with pivot-based cross-domain sentiment classification methods.</abstract>
      <url hash="e55eee70">S18-2030</url>
      <doi>10.18653/v1/S18-2030</doi>
      <bibkey>cui-etal-2018-solving</bibkey>
    </paper>
    </volume>
</collection>