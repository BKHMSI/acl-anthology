<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.eval4nlp">
  <volume id="1" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems</booktitle>
      <editor><first>Steffen</first><last>Eger</last></editor>
      <editor><first>Yang</first><last>Gao</last></editor>
      <editor><first>Maxime</first><last>Peyrard</last></editor>
      <editor><first>Wei</first><last>Zhao</last></editor>
      <editor><first>Eduard</first><last>Hovy</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>November</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="f2f7d694">2020.eval4nlp-1.0</url>
      <bibkey>eval4nlp-2020-evaluation</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Item Response Theory for Efficient Human Evaluation of Chatbots</title>
      <author><first>João</first><last>Sedoc</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <pages>21–33</pages>
      <abstract>Conversational agent quality is currently assessed using human evaluation, and often requires an exorbitant number of comparisons to achieve <a href="https://en.wikipedia.org/wiki/Statistical_significance">statistical significance</a>. In this paper, we introduce Item Response Theory (IRT) for chatbot evaluation, using a paired comparison in which annotators judge which system responds better to the next turn of a conversation. IRT is widely used in educational testing for simultaneously assessing the ability of test takers and the quality of test questions. It is similarly well suited for chatbot evaluation since <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> allows the assessment of both <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> and the prompts used to evaluate them. We use IRT to efficiently assess <a href="https://en.wikipedia.org/wiki/Chatbot">chatbots</a>, and show that different examples from the evaluation set are better suited for comparing high-quality (nearer to human performance) than low-quality systems. Finally, we use IRT to reduce the number of evaluation examples assessed by human annotators while retaining discriminative power.</abstract>
      <url hash="a90a3c48">2020.eval4nlp-1.3</url>
      <attachment type="OptionalSupplementaryMaterial" hash="d2341742">2020.eval4nlp-1.3.OptionalSupplementaryMaterial.pdf</attachment>
      <doi>10.18653/v1/2020.eval4nlp-1.3</doi>
      <video href="https://slideslive.com/38939718" />
      <bibkey>sedoc-ungar-2020-item</bibkey>
    </paper>
    <paper id="4">
      <title>ViLBERTScore : Evaluating Image Caption Using Vision-and-Language BERT<fixed-case>V</fixed-case>i<fixed-case>LBERTS</fixed-case>core: Evaluating Image Caption Using Vision-and-Language <fixed-case>BERT</fixed-case></title>
      <author><first>Hwanhee</first><last>Lee</last></author>
      <author><first>Seunghyun</first><last>Yoon</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Doo Soon</first><last>Kim</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Kyomin</first><last>Jung</last></author>
      <pages>34–39</pages>
      <abstract>In this paper, we propose an evaluation metric for image captioning systems using both image and text information. Unlike the previous methods that rely on textual representations in evaluating the caption, our approach uses visiolinguistic representations. The proposed method generates image-conditioned embeddings for each token using ViLBERT from both generated and reference texts. Then, these contextual embeddings from each of the two sentence-pair are compared to compute the <a href="https://en.wikipedia.org/wiki/Similarity_score">similarity score</a>. Experimental results on three benchmark datasets show that our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> correlates significantly better with human judgments than all existing <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a>.</abstract>
      <url hash="fa4d3c89">2020.eval4nlp-1.4</url>
      <doi>10.18653/v1/2020.eval4nlp-1.4</doi>
      <video href="https://slideslive.com/38939719" />
      <bibkey>lee-etal-2020-vilbertscore</bibkey>
      <pwccode url="https://github.com/hwanheelee1993/vilbertscore" additional="false">hwanheelee1993/vilbertscore</pwccode>
    </paper>
    <paper id="5">
      <title>BLEU Neighbors : A Reference-less Approach to Automatic Evaluation<fixed-case>BLEU</fixed-case> Neighbors: A Reference-less Approach to Automatic Evaluation</title>
      <author><first>Kawin</first><last>Ethayarajh</last></author>
      <author><first>Dorsa</first><last>Sadigh</last></author>
      <pages>40–50</pages>
      <abstract>Evaluation is a bottleneck in the development of natural language generation (NLG) models. Automatic metrics such as <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> rely on references, but for tasks such as open-ended generation, there are no references to draw upon. Although <a href="https://en.wikipedia.org/wiki/Language">language diversity</a> can be estimated using statistical measures such as <a href="https://en.wikipedia.org/wiki/Perplexity">perplexity</a>, measuring language quality requires <a href="https://en.wikipedia.org/wiki/Evaluation">human evaluation</a>. However, because human evaluation at scale is slow and expensive, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is used sparingly ; <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> can not be used to rapidly iterate on NLG models, in the way <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a> is used for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. To this end, we propose BLEU Neighbors, a nearest neighbors model for estimating language quality by using the BLEU score as a <a href="https://en.wikipedia.org/wiki/Positive-definite_kernel">kernel function</a>. On existing datasets for chitchat dialogue and open-ended sentence generation, we find that   on average   the quality estimation from a BLEU Neighbors model has a lower <a href="https://en.wikipedia.org/wiki/Mean_squared_error">mean squared error</a> and higher <a href="https://en.wikipedia.org/wiki/Spearman_correlation">Spearman correlation</a> with the ground truth than individual human annotators. Despite its simplicity, BLEU Neighbors even outperforms state-of-the-art <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> on automatically grading essays, including <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> that have access to a gold-standard reference essay.</abstract>
      <url hash="0e857069">2020.eval4nlp-1.5</url>
      <doi>10.18653/v1/2020.eval4nlp-1.5</doi>
      <video href="https://slideslive.com/38939709" />
      <bibkey>ethayarajh-sadigh-2020-bleu</bibkey>
    </paper>
    <paper id="8">
      <title>Artemis : A Novel Annotation Methodology for Indicative Single Document Summarization</title>
      <author><first>Rahul</first><last>Jha</last></author>
      <author><first>Keping</first><last>Bi</last></author>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Mahdi</first><last>Pakdaman</last></author>
      <author><first>Asli</first><last>Celikyilmaz</last></author>
      <author><first>Ivan</first><last>Zhiboedov</last></author>
      <author><first>Kieran</first><last>McDonald</last></author>
      <pages>69–78</pages>
      <abstract>We describe Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), a novel hierarchical annotation process that produces indicative summaries for documents from multiple domains. Current summarization evaluation datasets are single-domain and focused on a few domains for which naturally occurring summaries can be easily found, such as news and scientific articles. These are not sufficient for training and evaluation of summarization models for use in <a href="https://en.wikipedia.org/wiki/Document_management_system">document management</a> and <a href="https://en.wikipedia.org/wiki/Information_retrieval">information retrieval systems</a>, which need to deal with documents from multiple domains. Compared to other annotation methods such as Relative Utility and Pyramid, Artemis is more tractable because judges do n’t need to look at all the sentences in a document when making an importance judgment for one of the sentences, while providing similarly rich sentence importance annotations. We describe the annotation process in detail and compare <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> with other similar evaluation systems. We also present analysis and experimental results over a sample set of 532 annotated documents.</abstract>
      <url hash="e8d1d984">2020.eval4nlp-1.8</url>
      <doi>10.18653/v1/2020.eval4nlp-1.8</doi>
      <video href="https://slideslive.com/38939707" />
      <bibkey>jha-etal-2020-artemis</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    <title_ar>أرتميس: منهج جديد للتعليق التوضيحي للتلخيص الإرشادي للوثيقة الفردية</title_ar>
      <title_es>Artemis: una nueva metodología de anotación para el resumen indicativo de un solo documento</title_es>
      <title_pt>Artemis: Uma Nova Metodologia de Anotação para Sumarização Indicativa de Documento Único</title_pt>
      <title_ja>アルテミス：単一文書の要約を示すための新規の注釈方法論</title_ja>
      <title_zh>Artemis曰:一以指示性单文档摘要新注法</title_zh>
      <title_hi>आर्टेमिस: संकेतक एकल दस्तावेज़ सारांशीकरण के लिए एक उपन्यास एनोटेशन पद्धति</title_hi>
      <title_ga>Artemis: Modheolaíocht Anótála Úrscéalta le haghaidh Achoimre ar Dhoiciméad Aonair Táscach</title_ga>
      <title_ka>Comment</title_ka>
      <title_hu>Artemisz: Új megjegyzési módszertan az indikatív egységes dokumentumok összefoglalásához</title_hu>
      <title_el>Άρτεμις: Μια νέα μεθοδολογία σχολιασμού για την Ενδεικτική Σύνοψη Ενιαίου Έγγραφου</title_el>
      <title_it>Artemis: una nuova metodologia di annotazione per la sintesi indicativa del documento unico</title_it>
      <title_mk>Артемис: Нова методологија на анотација за индикативна резултатација на еден документ</title_mk>
      <title_kk>Artemis: Индикативалық бір құжат тұжырымдамасының жаңа жазбалар методологиясы</title_kk>
      <title_lt>Artemis: Naujoji orientacinės bendrojo dokumento santraukos annotacijos metodika</title_lt>
      <title_ms>Artemis: Metodologi Annotasi Baru untuk Penapisan Dokumen tunggal Indikatif</title_ms>
      <title_ml>ആർട്ടിമിസ്: സിദ്ധീകരിക്കുന്ന ഏക രേഖയുടെ ചുരുക്കം</title_ml>
      <title_mt>Artemis: Metodoloġija Ġdida ta’ Annotazzjoni għas-Sommarju Indikattiv tad-Dokument Uniku</title_mt>
      <title_mn>Artemis: Нэг баримт нийлүүлэх шинэ анзаарлын методологи</title_mn>
      <title_no>Artemis: A Novel Annotation Methodology for Indicative Single Document Summarization</title_no>
      <title_pl>Artemis: Nowa metodologia adnotacji dla orientacyjnego podsumowania pojedynczego dokumentu</title_pl>
      <title_sr>Artemis: Novi metodologija Annotacije za pokazivanje indikativnog jedinstvenog dokumenta</title_sr>
      <title_ro>Artemis: O nouă metodologie de adnotare pentru rezumarea indicativă a documentului unic</title_ro>
      <title_si>ArtEm: නෝවෙල් නෝටේෂන් විද්‍යාව ප්‍රමාණ විද්‍යාව සංඥානය සඳහා ප්‍රමාණ විද්‍යාව</title_si>
      <title_so>Artemis: A Novel Annotation Methodology for Indicative single document summarization</title_so>
      <title_sv>Artemis: En ny metod för notering för vägledande sammanfattning av ett enda dokument</title_sv>
      <title_ta>ஆர்டிமிஸ்: ஒரு நிலை அறிவிப்பு முறைமை</title_ta>
      <title_ur>آرٹیمیز: ایک نوئل نوٹیشن منڈولوژی نشانی واحد دفتر جمع کرنا کے لئے ایک نوئل نوٹیشن منڈولوژی</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Tác giả: Một tiểu thuyết chú thích cho mô tả chỉ một tài liệu tổng hợp</title_vi>
      <title_bg>Артемида: Нова анотационна методология за обобщаване на индикативния единен документ</title_bg>
      <title_nl>Artemis: Een nieuwe annotatiemethodologie voor indicatieve samenvatting van één document</title_nl>
      <title_da>Artemis: En ny anmærkningsmetode til vejledende sammenfatning af enkeltdokument</title_da>
      <title_hr>Artemis: Novi metodologija oznake za pokazivanje indikativnog jedinstvenog dokumenta</title_hr>
      <title_de>Artemis: Eine neuartige Annotationsmethode zur indikativen Zusammenfassung einzelner Dokumente</title_de>
      <title_id>Artemis: A Novel Annotation Methodology for Indicative Single Document Summarization</title_id>
      <title_ko>Artemis: 새로운 지시 단일 문서 요약 메모 방법</title_ko>
      <title_fa>Artemis: یک روش اظهار نول برای جمع کردن سند واحد نشان دهنده</title_fa>
      <title_tr>Artemis: A Novel Annotation Methodology for Indicative Single Document Summarization</title_tr>
      <title_sw>Artemis: Utawala wa Tamko la Eneo kwa Ujumbe wa Kanuni moja</title_sw>
      <title_af>Artemis: ' n Novel Annotation Methodology for Indicative Single Document Summarization</title_af>
      <title_sq>Artemis: Një metodologi e re e anotacionit për përmbledhjen Indikative të Dokumentit të Vetëm</title_sq>
      <title_am>አርጤምስ: A Novel Annotation Methodology for Indicative One Document Summary</title_am>
      <title_hy>Արտեմիս. Նոր նատորական մեթոդոլոգիա, որն օգտագործում է մեկ փաստաթղթի ցուցադրական համառոտագրությունը</title_hy>
      <title_bn>শিল্প: ইন্ডিয়েক্টিয়েটিভ একক নথির সামার্মিজেশনের জন্য একটি মোডোলজি</title_bn>
      <title_az>Artemis</title_az>
      <title_ca>Artemis: Una nova metodologia d'anotació per a una resumensió indicativa del document únic</title_ca>
      <title_cs>Artemis: Nová metodika anotace pro orientační shrnutí jednoho dokumentu</title_cs>
      <title_bs>Artemis: Novi metodologija Annotacije za pokazivanje indikativnog jedinstvenog dokumenta</title_bs>
      <title_et>Artemis: Uus annotatsioonimetoodika indikatiivse ühtse dokumendi kokkuvõtte jaoks</title_et>
      <title_fi>Artemis: Uusi merkintämenetelmä ohjeellisen yhden asiakirjan yhteenvetoon</title_fi>
      <title_ha>Artemis: A Novel Annotation Methodology for Indicative Single Document Summarization</title_ha>
      <title_sk>Artemis: Nove metode opombe za indikativno povzetek enotnega dokumenta</title_sk>
      <title_he>ארטמיס: Metodology of New Annotation for Indicative Single Document Summarization</title_he>
      <title_jv>artemu:</title_jv>
      <title_bo>Artemis:A Novel Annotation Methodology for Indicative Single Document Summarization</title_bo>
      <abstract_ar>نحن نصف Artemis (منهجية التعليق التوضيحي للتلخيص الثري ، القابل للتتبع ، الاستخراجي ، متعدد المجالات ، التلخيص الإرشادي) ، وهي عملية تعليق توضيحي هرمية جديدة تنتج ملخصات إرشادية للمستندات من مجالات متعددة. مجموعات بيانات تقييم التلخيص الحالية هي مجال واحد وتركز على عدد قليل من المجالات التي يمكن العثور على الملخصات التي تحدث بشكل طبيعي بسهولة ، مثل الأخبار والمقالات العلمية. هذه ليست كافية للتدريب وتقييم نماذج التلخيص لاستخدامها في إدارة الوثائق وأنظمة استرجاع المعلومات ، والتي تحتاج إلى التعامل مع الوثائق من مجالات متعددة. مقارنة بأساليب التعليقات التوضيحية الأخرى مثل المنفعة النسبية والهرم ، فإن Artemis أكثر قابلية للتتبع لأن القضاة لا يحتاجون إلى إلقاء نظرة على جميع الجمل في المستند عند إصدار حكم مهم لإحدى الجمل ، مع توفير تعليقات توضيحية ذات أهمية جمل غنية بالمثل. نصف عملية التعليق التوضيحي بالتفصيل ونقارنها بأنظمة التقييم الأخرى المماثلة. نقدم أيضًا نتائج تحليلية وتجريبية على مجموعة عينات مكونة من 532 مستندًا مشروحًا.</abstract_ar>
      <abstract_es>Describimos Artemis (metodología de anotación para sumarización rica, tratable, extractiva, multidominio e indicativa), un novedoso proceso de anotación jerárquica que produce resúmenes indicativos para documentos de múltiples dominios. Los conjuntos de datos de evaluación de resúmenes actuales son de dominio único y se centran en unos pocos dominios para los que se pueden encontrar fácilmente resúmenes naturales, como noticias y artículos científicos. Estos no son suficientes para la capacitación y evaluación de modelos de resumen para su uso en sistemas de gestión de documentos y recuperación de información, que deben tratar documentos de múltiples dominios. En comparación con otros métodos de anotación como Relative Utility y Pyramid, Artemis es más manejable porque los jueces no necesitan mirar todas las oraciones de un documento al hacer un juicio de importancia para una de las oraciones, mientras que proporcionan anotaciones de importancia de oraciones igualmente ricas. Describimos el proceso de anotación en detalle y lo comparamos con otros sistemas de evaluación similares. También presentamos análisis y resultados experimentales en un conjunto de muestras de 532 documentos anotados.</abstract_es>
      <abstract_pt>Descrevemos Artemis (Metodologia de anotação para Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), um novo processo de anotação hierárquica que produz resumos indicativos para documentos de vários domínios. Os conjuntos de dados de avaliação de sumarização atuais são de domínio único e focados em alguns domínios para os quais os resumos de ocorrência natural podem ser facilmente encontrados, como notícias e artigos científicos. Estes não são suficientes para treinamento e avaliação de modelos de sumarização para uso em gerenciamento de documentos e sistemas de recuperação de informações, que precisam lidar com documentos de vários domínios. Comparado a outros métodos de anotação, como Utilidade Relativa e Pirâmide, o Artemis é mais tratável porque os juízes não precisam examinar todas as sentenças em um documento ao fazer um julgamento de importância para uma das sentenças, enquanto fornecem anotações de importância de sentenças igualmente ricas. Descrevemos o processo de anotação em detalhes e o comparamos com outros sistemas de avaliação semelhantes. Também apresentamos análises e resultados experimentais sobre um conjunto amostral de 532 documentos anotados.</abstract_pt>
      <abstract_ja>ARTEMIS （豊富、抽出可能、抽出可能、マルチドメイン、指標要約のためのアノテーション方法論）について説明します。これは、複数のドメインから文書の指標要約を生成する新規の階層的アノテーションプロセスです。 現在の要約評価データセットは、単一ドメインであり、ニュースや科学的記事など、自然発生の要約が容易に見つかるいくつかのドメインに焦点を当てています。 これらは、複数のドメインからの文書を扱う必要がある文書管理および情報検索システムで使用するための要約モデルのトレーニングおよび評価には不十分です。 相対的効用やピラミッドなどの他の注釈方法と比較して、ARTEMISは、文の重要性の判断を行う際に、審査員が文書内のすべての文を見る必要がなく、同様に豊富な文の重要性の注釈を提供するため、より分かりやすくなっています。 注釈プロセスを詳細に説明し、他の同様の評価システムと比較します。 我々はまた、532の注釈付き文書のサンプルセットにわたって分析および実験結果を提示する。</abstract_ja>
      <abstract_zh>述Artemis(丰赡,可处可多域,指性摘要注法),此新颖之分注,可为数域文档生指性摘要。 今之摘要估数集是单域,侧重于可以轻寻自然之摘要数域,如新闻科学文章。 不足以训估文档治信息检索之摘要,数域之文档也。 比之金字塔注,Artemis易处也,以法官重要不须检文档中所有句,兼资重注也。 臣等详细描述注,比之评估。 又于532带注文样本剖析实验实。</abstract_zh>
      <abstract_hi>हम आर्टेमिस (रिच, ट्रैकेबल, एक्सट्रैक्टिव, मल्टी-डोमेन, इंडिक्टिक सारांशके लिए एनोटेशन पद्धति) का वर्णन करते हैं, एक उपन्यास पदानुक्रमित एनोटेशन प्रक्रिया जो कई डोमेन से दस्तावेजों के लिए संकेतक सारांश का उत्पादन करती है। वर्तमान सारांश मूल्यांकन डेटासेट एकल-डोमेन हैं और कुछ डोमेन पर केंद्रित हैं जिनके लिए स्वाभाविक रूप से होने वाले सारांश आसानी से पाए जा सकते हैं, जैसे समाचार और वैज्ञानिक लेख। ये दस्तावेज़ प्रबंधन और सूचना पुनर्प्राप्ति प्रणालियों में उपयोग के लिए सारांश मॉडल के प्रशिक्षण और मूल्यांकन के लिए पर्याप्त नहीं हैं, जिन्हें कई डोमेन से दस्तावेजों से निपटने की आवश्यकता है। अन्य एनोटेशन विधियों जैसे सापेक्ष उपयोगिता और पिरामिड की तुलना में, आर्टेमिस अधिक असभ्य है क्योंकि न्यायाधीशों को वाक्यों में से एक के लिए एक महत्वपूर्ण निर्णय लेते समय दस्तावेज़ में सभी वाक्यों को देखने की आवश्यकता नहीं होती है, जबकि समान रूप से समृद्ध वाक्य महत्व एनोटेशन प्रदान करते हैं। हम एनोटेशन प्रक्रिया का विस्तार से वर्णन करते हैं और इसकी तुलना अन्य समान मूल्यांकन प्रणालियों के साथ करते हैं। हम 532 एनोटेट किए गए दस्तावेजों के एक नमूना सेट पर विश्लेषण और प्रयोगात्मक परिणाम भी प्रस्तुत करते हैं।</abstract_hi>
      <abstract_ga>Déanaimid cur síos ar Artemis (Modheolaíocht anótála le haghaidh Saibhreas, Inrianaithe, Eastóscach, Ilfhearainn, Achoimriú Táscach), próiseas anótála ordlathach nua a tháirgeann achoimrí táscacha do dhoiciméid ó ilfhearainn. Réimse aonair atá i dtacar sonraí meastóireachta achoimrithe reatha agus dírítear ar roinnt réimsí ar féidir achoimrí nádúrtha a aimsiú go héasca orthu, amhail nuacht agus ailt eolaíocha. Ní leor iad seo chun samhlacha achoimrithe a oiliúint agus a mheasúnú le húsáid i gcórais bhainistíochta doiciméad agus aisghabhála faisnéise, ar gá dóibh déileáil le doiciméid ó réimsí iolracha. I gcomparáid le modhanna nótaí eile ar nós Relative Utility and Pyramid, tá Artemis níos inrianaithe mar ní gá do bhreithiúna breathnú ar na habairtí go léir i ndoiciméad agus breithiúnas tábhachta á dhéanamh acu do cheann amháin de na habairtí, agus nótaí tábhachta na habairte saibhir céanna á gcur ar fáil acu. Déanaimid cur síos mion ar an bpróiseas anótála agus cuirimid i gcomparáid é le córais mheastóireachta eile dá samhail. Cuirimid anailís agus torthaí turgnamhacha i láthair freisin thar thacar samplach de 532 doiciméad anótáilte.</abstract_ga>
      <abstract_el>Περιγράφουμε μια νέα ιεραρχική διαδικασία σχολιασμού που παράγει ενδεικτικές περιλήψεις για έγγραφα από πολλαπλούς τομείς. Τα τρέχοντα σύνολα δεδομένων αξιολόγησης συνοψίας είναι μεμονωμένα και επικεντρώνονται σε λίγους τομείς για τους οποίους μπορούν εύκολα να βρεθούν φυσικά περιλήψεις, όπως ειδήσεις και επιστημονικά άρθρα. Αυτά δεν επαρκούν για την εκπαίδευση και την αξιολόγηση μοντέλων σύνοψης για χρήση σε συστήματα διαχείρισης εγγράφων και ανάκτησης πληροφοριών, τα οποία πρέπει να ασχολούνται με έγγραφα από πολλούς τομείς. Σε σύγκριση με άλλες μεθόδους σχολιασμού όπως η σχετική χρησιμότητα και η πυραμίδα, η Άρτεμις είναι πιο ελκυστική επειδή οι δικαστές δεν χρειάζεται να εξετάζουν όλες τις προτάσεις σε ένα έγγραφο όταν κάνουν μια κρίση σπουδαιότητας για μια από τις προτάσεις, ενώ παρέχουν παρόμοια πλούσια σχολιασμούς σπουδαιότητας προτάσεων. Περιγράφουμε λεπτομερώς τη διαδικασία σχολιασμού και τη συγκρίνουμε με άλλα παρόμοια συστήματα αξιολόγησης. Παρουσιάζουμε επίσης ανάλυση και πειραματικά αποτελέσματα σε ένα δείγμα από 532 σχολιασμένα έγγραφα.</abstract_el>
      <abstract_hu>Leírjuk az Artemist (Megjegyzési módszertan Rich, Tractable, Extractive, Multi-domain, Indikatív Összefoglaláshoz), egy új hierarchikus megjegyzési folyamatot, amely indikatív összefoglalókat készít több domain dokumentumaihoz. A jelenlegi összefoglaló értékelési adatkészletek egy-dományba tartoznak, és néhány olyan területre összpontosítanak, amelyek természetesen előforduló összefoglalók könnyen megtalálhatók, mint például hírek és tudományos cikkek. Ezek nem elegendőek a dokumentumkezelő és információvisszakereső rendszerekben használt összefoglaló modellek képzéséhez és értékeléséhez, amelyeknek több területről származó dokumentumokkal kell foglalkozniuk. Más megjegyzési módszerekkel összehasonlítva, mint például a Relative Utility és Pyramid, Artemisz sokkal kezelhetőbb, mivel a bíróknak nem kell megvizsgálniuk a dokumentum összes mondatát, amikor fontos ítéletet hoznak az egyik mondat esetében, miközben hasonlóan gazdag mondat fontosságú megjegyzéseket adnak. Részletesen leírjuk a jegyzetelési folyamatot és összehasonlítjuk más hasonló értékelési rendszerekkel. Az elemzési és kísérleti eredményeket 532 jegyzetelt dokumentumból álló mintahalmazon is bemutatjuk.</abstract_hu>
      <abstract_ka>ჩვენ აღწერეთ Artemis (ბეჭდვი, Tractable, ექსტრაქტური, მრავალემენი, ინდექტიური კომპანიზაცია) პროცესი ჰიერაქტიური ანოტაციის პროცესი, რომელიც მრავალედ დიომენტების კომპუნეტე მიმდინარე რეზიუმიზაციის მონაცემების შესაბამისი მონაცემები ერთი დიომენია და დაყენებულია რამდენიმე დიომენზე, რომლებიც ნართვის შესაბამისი რეზიუმენტები ადვილედ იქნებ ეს არ არის მნიშვნელოვანი კოსუმენტის მოდელების განათლებისთვის და გამოყენებისთვის დოკუმენტის მენეჯეროში და ინფორმაციის მიღებისთვის, რომლებიც უნდა გამოყენება დოკუმე სხვა ამოცანების მეტოვებით, როგორც Relative Utility და Pyramid, Artemis უფრო მეტად მონაცემულია, რადგან მსგავსი ამოცანები არ უნდა დაახედოთ ყველა ამოცანების შესახებ დოკუმენტში, როდესაც ერთი წესების გასანიშვნელოვან ჩვენ აღწერეთ მონიტოციის პროცესი დეტალურად და ამას სხვა მსგავსი განსაზღვრების სისტემისთან შედგენებთ. ჩვენ ასევე ანალიზი და ექსპერიმენტიური შედეგი 532 მონიშნული დოკუმენტების მონაცემების შესახებ.</abstract_ka>
      <abstract_it>Descriviamo Artemis (Metodologia di annotazione per Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), un nuovo processo di annotazione gerarchica che produce riassunti indicativi per documenti provenienti da più domini. Gli attuali set di dati di valutazione di sintesi sono monodominio e si concentrano su alcuni domini per i quali si possono facilmente trovare riassunti naturali, come notizie e articoli scientifici. Questi non sono sufficienti per la formazione e la valutazione dei modelli di sintesi da utilizzare nei sistemi di gestione dei documenti e di recupero delle informazioni, che devono trattare documenti provenienti da più domini. Rispetto ad altri metodi di annotazione come Relative Utility e Pyramid, Artemis è più trattabile perché i giudici non hanno bisogno di guardare tutte le frasi in un documento quando fanno un giudizio importante per una delle frasi, fornendo allo stesso tempo annotazioni altrettanto ricche di importanza delle frasi. Descriviamo il processo di annotazione in dettaglio e lo confrontiamo con altri sistemi di valutazione simili. Presentiamo anche analisi e risultati sperimentali su un campione di 532 documenti annotati.</abstract_it>
      <abstract_lt>Mes apibūdiname Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summary), naują hierarchical annotation process, kuriame pateikiamos orientacinės santraukos dokumentams iš įvairių sričių. Dabartiniai santraukų vertinimo duomenų rinkiniai yra vienos srities ir daugiausia dėmesio skiria kelioms sritims, kurioms paprasčiausiai galima rasti natūralių santraukų, pavyzdžiui, naujienų ir mokslinių straipsnių. Tai nepakanka rengiant ir vertinant santraukų modelius, naudojamus dokumentų valdymo ir informacijos gavimo sistemose, kuriose turi būti nagrinėjami įvairių sričių dokumentai. Palyginti su kitais anotacijos metodais, pavyzdžiui, Relative Utility ir Pyramid, Artemis yra labiau traktuojamas, nes teisėjai neturi žiūrėti į visus dokumente esančius sakinius priimant svarbų sprendimą dėl vieno iš sakinių, tuo pat metu pateikiant panašiai turtingus sakinių svarbos anotacijas. Išsamiai apibūdiname anotacijos procesą ir palyginame jį su kitomis panašiomis vertinimo sistemomis. Taip pat pateikiame analizę ir eksperimentinius rezultatus 532 anotuotų dokumentų rinkiniui.</abstract_lt>
      <abstract_kk>Біз Artemis (Rich, Tractable, Extractive, Multi-domain, Indicative Summarization) методологиясын таңдаймыз. Бірнеше доменден құжаттар үшін көрсетілетін жазбаларды жасайтын романдық иерархиялық жазбалар процесі. Қолданыстағы тұжырымдамасын бағалау деректер жиындары бір домен болып, бірнеше доменге назар ауыстырылады. Бұл жаңалықтар мен ғылыми мақалалар секілді жаңалықтар мен жаңалықтар. Бұл құжаттарды басқару жүйелерінде және мәліметті алу жүйелерінде қолдану үшін құжаттарды бақылау мен оқу үлгілерінде жеткілікті емес. Бұл құжаттарды бірнеше доменден Сәйкестік утилиялық және пирамид секілді басқа жазбалардың әдістеріне салыстырылып, Artemis қадамдастырылып тұрады, себебі жазбалардың бір сөздерге маңызды мәлімет бергенде құжаттың барлық сөздерін қарау керек емес, сондай-а Біз жазбалардың процесін егжей- тегжейлі түсіндіріп, оны басқа ұқсас оқиғалардың жүйелерімен салыстырып көрдік. Мұндай-ақ 532 жазылған құжаттар үшін анализ және тәжірибелі нәтижелерін көрсетедік.</abstract_kk>
      <abstract_ms>Kami menggambarkan Artemis (Metodologi Annotasi untuk Rich, Tractable, Extractive, Multi-domain, Ringkasan Indikatif), proses annotasi hierarkis baru yang menghasilkan ringkasan indikatif untuk dokumen dari domain berbilang. Set data penilaian ringkasan semasa adalah domain tunggal dan fokus pada beberapa domain yang mana ringkasan yang berlaku secara alami boleh mudah ditemui, seperti berita dan artikel saintifik. Ini tidak cukup untuk latihan dan penilaian model ringkasan untuk digunakan dalam pengurusan dokumen dan sistem pemulihan maklumat, yang perlu berurusan dengan dokumen dari domain berbilang. Compared to other annotation methods such as Relative Utility and Pyramid, Artemis is more tractable because judges don't need to look at all the sentences in a document when making an importance judgment for one of the sentences, while providing similarly rich sentence importance annotations. Kami menggambarkan proses anotasi secara terperinci dan membandingkannya dengan sistem penilaian yang sama lain. Kami juga memperkenalkan analisis dan hasil percubaan melalui set sampel 532 dokumen yang dicatat.</abstract_ms>
      <abstract_mk>Ние го опишуваме Артемис (методологија на анотација за богати, трактивни, екстрактивни, мултидомени, индикативни резултати), нов хиерархички процес на анотација кој произведува индикативни резултати за документите од повеќе домени. Сегашните датотеки за проценка на резултатите се еднодомени и фокусирани на неколку домени за кои природно се наоѓаат резултати, како што се вестите и научните статии. Овие не се доволни за обука и евалуација на моделите за резултат за употреба во менаџментот на документите и системите за преземање информации, кои мора да се справат со документите од повеќе домени. Во споредба со другите методи на анотација како што се Relative Utility и Pyramid, Артемис е попривлечен бидејќи судиите не мора да ги погледнат сите реченици во документот кога прават важна пресуда за една од речениците, истовремено обезбедувајќи слично богати реченици важни анотации. Го опишуваме процесот на анотација во детали и го споредуваме со други слични системи на оценка. Исто така, ги претставуваме анализите и експерименталните резултати во врска со примерок од 532 анотирани документи.</abstract_mk>
      <abstract_ml>നമ്മള്‍ ആര്‍ട്ടെമിസിനെ വിശദീകരിക്കുന്നു (സമ്പത്ത്, ട്രാക്ട്രാക്ടിക്കേള്‍ക്കാവുന്ന രീതിയില്‍ നിന്നും പുറപ്പെടുത്താനുള്ള രേഖകള്‍ക്ക് വ്യക്തമാക്കുന് നിലവിലുള്ള സംസ്കാരം വിലാസപൂര്‍ണ്ണമായ ഡാറ്റാസറിന്റെ വിലാസങ്ങള്‍ ഒറ്റയ്ക്കാണ്. സ്വാഭാവികമായി സംഭവിക്കുന്ന കുറച്ചു ഡൊമെയിന രേഖകളുടെ മാനേജന്റ് മാനേജ്മെന്റിലും വിവരങ്ങള്‍ തിരിച്ചറിയുന്ന സിസ്റ്റത്തിലും ഉപയോഗിക്കുന്നതിനും പരിശീലനത്തിനും വിലയിക്കു വാക്കുകളില്‍ ഒരു പ്രധാനപ്പെട്ട വിധിയുണ്ടാക്കുമ്പോള്‍ ഒരു വാക്കുകളില്‍ ഒരു പ്രധാനപ്പെട്ട വിധിയുണ്ടാക്കുമ്പോള്‍ ഒരു വാക്കുകളിലെ വാക്കുകളൊക്കെയും നോക്കേണ നമ്മള്‍ വിശദീകരിക്കുന്ന പ്രക്രിയയെ വിശദീകരിക്കുകയും അതിനെ മറ്റു പോലുള്ള വിലാസപ്രക്രിയകളോട് താല 532 രേഖകളുടെ മാതൃകയ്ക്കുള്ള ഒരു രേഖയില്‍ ഞങ്ങള്‍ അന്വേഷണവും പരീക്ഷണത്തിന്റെ ഫലവും കാണിക്കുന്നു.</abstract_ml>
      <abstract_mt>Aħna niddeskrivu Artemis (Metodoloġija ta’ annotazzjoni għal Rich, Tractable, Extractive, Multi-domain, Sommarju Indikattiv), proċess ġdid ta’ annotazzjoni ġerarkika li jipproduċi sommarji indikattivi għal dokumenti minn diversi domains. Is-settijiet tad-dejta attwali tal-evalwazzjoni tas-sommarju huma ta’ dominju wieħed u ffukati fuq ftit oqsma li għalihom jistgħu jinstabu sommarji li jseħħu b’mod naturali faċilment, bħall-a ħbarijiet u l-artikoli xjentifiċi. Dawn mhumiex biżżejjed għat-taħriġ u l-evalwazzjoni ta’ mudelli ta’ sommarju għall-użu fil-ġestjoni tad-dokumenti u s-sistemi ta’ ġbir tal-informazzjoni, li jeħtieġu jittrattaw dokumenti minn diversi oqsma. Meta mqabbel ma’ metodi oħra t a’ annotazzjoni bħall-Utilità Relattiva u l-Piramida, l-Artemis huwa aktar attraenti minħabba li l-imħallfin ma għandhomx għalfejn iħarsu lejn is-sentenzi kollha f’dokument meta jagħmlu sentenza ta’ importanza għal waħda mis-sentenzi, filwaqt li jipprovdu annotazzjonijiet ta’ importanza ta’ sentenza rikka simili. Aħna niddeskrivu l-proċess ta’ annotazzjoni fid-dettall u nqabblu ma’ sistemi oħra ta’ evalwazzjoni simili. Aħna nippreżentaw ukoll analiżi u riżultati sperimentali fuq sett ta’ kampjuni ta’ 532 dokument annotat.</abstract_mt>
      <abstract_pl>Opisujemy Artemis (metodologię Annotation for Rich, Tractable, Extractive, Multi-Domain, Indicative Summarization), nowy hierarchiczny proces annotacji, który tworzy orientacyjne podsumowania dokumentów z wielu domen. Aktualne zbiory danych dotyczące oceny podsumowań są pojedynczej domeny i koncentrują się na kilku dziedzinach, dla których naturalnie występujące podsumowania można łatwo znaleźć, takie jak wiadomości i artykuły naukowe. Nie są one wystarczające do szkolenia i oceny modeli podsumowania stosowanych w systemach zarządzania dokumentami i pozyskiwania informacji, które muszą zajmować się dokumentami z wielu dziedzin. W porównaniu z innymi metodami adnotacji, takimi jak Relative Utility i Piramida, Artemis jest bardziej przyciągająca, ponieważ sędziowie nie muszą patrzeć na wszystkie zdania w dokumencie podczas dokonywania oceny ważności jednego ze zdań, zapewniając jednocześnie podobnie bogate adnotacje ważności zdań. Szczegółowo opisujemy proces adnotacji i porównujemy go z innymi podobnymi systemami oceny. Przedstawiamy również wyniki analizy i eksperymentalne na przykładowym zestawie dokumentów notatowanych 532.</abstract_pl>
      <abstract_mn>Бид Artemis-г тайлбарлаж байна (Баян, Трэйстабл, Экстрактив, Мөн хэлбэрээр, Индикатив Холбоо), олон хэлбэрээс баримт бичсэн дүрсийг бий болгодог шинэ шинэ дүрсийн үзүүлэлтийн процесс. Одоогийн жинхэнэ дүгнэлтийн өгөгдлийн сангууд нь нэг-холбоотой бөгөөд хэд хэдэн хэсэгт анхаарлаа хангалттай байдаг. Яг л мэдээлэл, шинжлэх ухааны баримтууд. Эдгээр нь баримт удирдах, мэдээлэл авах системд ашиглах хэмжээсүүдийн дасгал болон дүгнэлтийн загваруудыг багшлах болон үнэлэхэд хангалттай биш. Харин харьцангуй хэрэглээ болон Пирамид гэх мэт бусад хэлбэртэй харьцуулахад, Артемис илүү давтагддаг. Учир нь шүүгчид баримт өгүүлбэрүүдийн нэгэнд чухал шүүмжлээ хийх үед бүх өгүүлбэрүүдийг харах хэрэггүй. Бид тэмдэглэх үйл явцыг нарийвчлан тайлбарлаж бусад төстэй үнэлгээ системтэй харьцуулж байна. Бид мөн шинжилгээ, туршилтын үр дүнг 532 анзаарсан баримт дээр харуулж байна.</abstract_mn>
      <abstract_no>Vi beskriver Artemis (annotasjonsmetodulogi for Rich, Tractable, Extractive, Multi-domene, Indicative Summarization), eit nytt hierarkisk annotasjonsprosess som produserer indikative samandrag for dokument frå fleire domene. Noverande datasett for sammendraging er enkelt domene og fokuserte på noen domene som naturleg oppstår sammendragar kan enkelt finnast, slik som nyhetar og vitenskapelige artiklar. Dette er ikkje nok for å trenga og evaluera sammendragsmodular for bruk i dokumenthandtering og informasjonshendingssystemet, som må handsama dokument frå fleire domene. Sammenlignet med andre merkingsmetoder som Relativ verktøy og piramidt, er Artemis mer sporbar fordi sprøytane ikkje treng å sjå på alle setningane i eit dokument når du gjer eit viktig sprøym for ein av setningane, medan du gjer tilsvarande rike setningsverktøy. Vi beskriver annotasjonsprosessen i detaljar og sammenliknar det med andre liknande evalueringssystemer. Vi presenterer også analyse og eksperimentell resultat over eit prøvesett av 532 markerte dokument.</abstract_no>
      <abstract_ro>Descriem Artemis (Metodologie de adnotare pentru bogată, trasabilă, extractivă, multidomeniu, sumarizare indicativă), un nou proces de adnotare ierarhică care produce rezumate orientative pentru documente din mai multe domenii. Seturile de date actuale de evaluare a rezumatelor sunt unice și se concentrează pe câteva domenii pentru care rezumatele naturale pot fi găsite cu ușurință, cum ar fi știri și articole științifice. Acestea nu sunt suficiente pentru formarea și evaluarea modelelor de sinteză utilizate în sistemele de gestionare a documentelor și de recuperare a informațiilor, care trebuie să se ocupe de documente din mai multe domenii. Comparativ cu alte metode de adnotare, cum ar fi Utilitatea relativă și Piramida, Artemis este mai tratabil deoarece judecătorii nu trebuie să se uite la toate propozițiile dintr-un document atunci când fac o judecată importantă pentru una dintre propoziții, oferind în același timp adnotări similare bogate pentru importanța propozițiilor. Descriem în detaliu procesul de adnotare și îl comparăm cu alte sisteme similare de evaluare. De asemenea, prezentăm analize și rezultatele experimentale pe un set de eșantioane de 532 de documente adnotate.</abstract_ro>
      <abstract_sr>Mi opisujemo Artemis (metodologija Annotacije za bogate, Tractable, Ekstraktivne, Višedomene, indikativne sažetke), nov hijerarhički annotacijski proces koji proizvodi indikativne sažetke za dokumente iz višestrukih domena. Trenutne skupine procjene podataka za procjenu sažetke su jedinstvena domena i fokusirane na nekoliko domena za koje se prirodno dogaðaju sažetke mogu lako naći, poput vesti i naučnih članaka. To nije dovoljno za obuku i procjenu modela sažetanja za upotrebu u upravljanju dokumentima i sustavima prikupljanja informacija, koji moraju da se bave dokumentima iz višestrukih domena. U usporedbi sa drugim metodama annotacije poput Relativne korisnosti i piramide, Artemis je praćeniji jer suci ne moraju da gledaju sve rečenice u dokumentu kada donose važnu presudu za jednu od rečenica, dok pružaju is to bogate oznake. Opišemo proces annotacije detaljno i uspoređujemo ga sa drugim sličnim sistemima procjene. Takođe predstavljamo analizu i eksperimentalne rezultate iznad uzoraka sa 532 annotiranih dokumenta.</abstract_sr>
      <abstract_so>Waxaan qoraynaa Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summariisation), kaas oo soo saara jardiino hierarchic annotations ah oo soo saara summaris oo muuqata dukumentiyada kala duduwan. Xafiisyada qiimeynta lagu qiimeeyo ee joogtada ah waa hal meelood oo kaliya, wuxuuna ku kalsoonaaday dhawr meelood oo si fudud u soo socda, sida warqadaha iyo sayniska. Waxyaabahaas kuma filna waxbarashada iyo qiimeynta samooyinka summarinta ee lagu isticmaali karo maamulka dukumentiga iyo nidaamka helitaanka macluumaadka, taas oo u baahan inay ka shaqeeyaan dukumentiyada meelaha kala duduwan. Isbarbardhigta qalabka kale ee la xiriira, tusaale ahaan xiriirka isticmaalka iyo Pyramid, Artemis waa mid ka sii suurtagal, sababtoo ah xaakinnadu uma baahna inay fiiriyaan dhammaan erayada dukumenti ku qoran marka ay muhiim u sameeyaan xukunka mid ka mid ah, isla markaasna ay bixiyaan ogeysiiska muhiimka ah ee xafiiska la xiriiro. Waxaannu si gaar ah u qoraynaa baaraandegista baaraandegista, waxaynu isbarbardhignaa nidaamka kale ee qiimeynta. Waxaynu sidoo kale keennaa baaritaanka iyo arimaha imtixaanka tusaale ahaan 532 dukumentiyada la wareejiyey.</abstract_so>
      <abstract_sv>Vi beskriver Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-Domain, Indikativ Summarization), en ny hierarkisk annotationsprocess som producerar vägledande sammanfattningar för dokument från flera domäner. Aktuella sammanfattningsutvärderingsdata är en domän och fokuserar på några områden där naturligt förekommande sammanfattningar lätt kan hittas, såsom nyheter och vetenskapliga artiklar. Dessa är inte tillräckliga för utbildning och utvärdering av sammanfattningsmodeller för användning i dokumenthanterings- och informationsinsamlingssystem, som behöver hantera dokument från flera domäner. Jämfört med andra anmärkningsmetoder som Relative Utility och Pyramid är Artemis mer lätthanterlig eftersom domare inte behöver titta på alla meningar i ett dokument när de gör en viktig bedömning för en av meningarna, samtidigt som de tillhandahåller liknande rika meningsintresser. Vi beskriver anteckningsprocessen i detalj och jämför den med andra liknande utvärderingssystem. Vi presenterar även analyser och experimentella resultat över ett urval av 532 kommenterade dokument.</abstract_sv>
      <abstract_ta>நாம் ஆர்டிமிஸ்களை விவரிக்கிறோம் (Rich, Tractable, Extractive, Multi- domain, Indicative சுருக்கம், சுருக்கம், சுழற்சி செய்யும் அறிவிப்பு முறைமை தற்போதைய சுருக்கம் மதிப்பீடு தகவல் அமைப்பு ஆவண மேலாண்மை மற்றும் தகவல் மீட்டும் அமைப்பில் பயன்படுத்துவதற்கான சுருக்க மாதிரிகளை பயிற்சி மற்றும் மதிப்பிட இது போதுமானதாக இல்ல தொடர்பு பயன்பாடு மற்றும் பிரைமிட் போன்ற மற்ற வேறு அறிவிப்பு முறைகளுடன் ஒப்பிட்டால், ஆர்டிமிஸ் மிகவும் அடிச்சுவடாகும். ஏனென்றால் வாக்கியங்களில் ஒரு முக்கியமான வி நாம் அறிவிப்பு செயலை விவரமாக விவரிக்கிறோம் மற்றொரு போன்ற மதிப்பினை முறைமைகளை ஒப்பிடுகிறோம். 532 குறிப்பிடப்பட்ட ஆவணங்களின் மீது நாம் ஆராய்ச்சி மற்றும் சோதனையின் முடிவுகளை காண்பிக்கிறோம்.</abstract_ta>
      <abstract_si>අපි ArtEm විස්තර කරනවා (රිච්, ස්ට්‍රේක්ටෙබ්, ඉක්ෂ්‍යාක්ෂිත, Multi-domain, ඉන්දික්ෂිත සාමාර්ථක පරීක්ෂණයක්), විස්තර සාමාර්ථක පරීක්ෂණයක් ව ප්‍රස්තූතිය සංශ්‍යාපනය දත්ත සැකසුම් තරම් ඩොමේන් කිහිපයක් වෙනුවෙන් ප්‍රස්තූතියෙන් සංශ්‍යාපනය සහ විද්‍යාපණ මේවා ලේඛන ප්‍රධානය සහ තොරතුරු ගන්න පද්ධතියේ භාවිතා කරන්න සඳහා සාමාවික පද්ධතිය සඳහා ප්‍රධානය සහ අවශ්‍ය විශ්වා සම්බන්ධ උපයෝජනය සහ පිරාමිඩ් වගේ අනිත් කිරීම් විදියට සම්බන්ධ විදියට සම්බන්ධ විදියට, ArtEm විශේෂ විදියටත් විශේෂ විදියට පරික්ෂා වෙන්න අපි විස්තර විස්තරයෙන් ප්‍රවේශනය විස්තර කරනවා ඒක අනිත් වගේ විස්තර පද්ධතියෙන් විස්තර කරනවා. අපි විශ්ලේෂණය සහ පරීක්ෂණ ප්‍රතිචාර ප්‍රතිචාර ප්‍රතිචාරයක් තියෙනවා 532 නිර්දේශ කරපු ලි</abstract_si>
      <abstract_ur>ہم آرتمیسی (ریچ، تراکٹیبل، اخلاقی، Multi-domain، اخلاقی) کے لئے آرتمیسی کا مطابق بیان کرتے ہیں، ایک نئی آرتمیسی اظہار پیدائش پرسس جو بہت سی دامنوں سے سند کے لئے دکھانے والی مطابق پیدائش کرتا ہے۔ اوروں کی نسبت ارزیابی ڈاٹ سٹ ایک ڈومین ہیں اور چند ڈومین پر تمرکز کیا جاتا ہے جن کے لئے طبیعی طور پر آسانی طرح حاصل ہوتے ہیں، جیسے اخبار اور سائنس لیکن لکھے جاتے ہیں. یہ تعلیم اور ارزیابی موڈل کے لئے کافی نہیں ہیں کہ دکھانے کی مدیریت اور معلومات پھیرنے کی سیستموں میں استعمال کریں، جو بہت سی ڈومین سے دکھانے کے لئے لازم ہے. اور دوسری یادہانی طریقوں کے مقابلہ میں، جیسے Relative Utility اور Pyramid، آرتمیسی زیادہ تراکٹبل ہے کیونکہ فیصلہ کرنے والوں کے لئے ایک جماعت کے لئے اہم فیصلہ کرنے کی ضرورت نہیں ہے جب ایک جماعت کے لئے ایک اہم فیصلہ کرتا ہے، اور اس طرح ثروت جماعت کے اہم علامتوں کو پیش کرتا ہے. ہم مفصل کے مطابق مفصل کے مطابق توصیح کرتے ہیں اور اس کو دوسرے مطابق مطابق مطابق نظام کے مطابق مقایسہ کرتے ہیں۔ ہم نے بھی تحلیل اور آزمائش نتیجے 532 دفتروں کی نمونہ سٹ پر پیش کیے ہیں.</abstract_ur>
      <abstract_uz>Biz Artemis (Tahrirlash, Traktable, Extraktable, Multi-Domen, Xitoy hisoblanish uchun taʼminlovchi metodini tahlil qilamiz), bir nechta domen hujjatlardan aniqlash uchun yangi hierarchik taʼminlovchi jarayoni yaratadi. @ info @ info Name Biz taqdimot jarayonini aniqlash va uni boshqa qiymatni boshqa tizimga kamaytirish. Biz 532 yordamchi hujjatlar bir misol uchun analyzer va tajriba natijalarini hozir qilamiz.</abstract_uz>
      <abstract_vi>Chúng tôi mô tả Artemis (Chú giải thích về Rich, TracBàn, tháo gỡ, đa miền, Mô tả Hồi âm), một tiến trình ghi chú cấp bậc mới tạo ra các bản tóm tắt về các tài liệu từ đa miền. Các tập tin đánh giá tổng quát hiện thời chỉ có một lĩnh vực và tập trung vào một vài lĩnh vực mà những bản tóm tắt tự nhiên có thể dễ tìm thấy, như tin tức và các công cụ khoa học. Những thứ này không đủ để đào tạo và đánh giá các mô hình tóm tắt để sử dụng trong hệ thống thu thập tài liệu và thông tin, mà cần phải xử lý các tài liệu từ nhiều lĩnh vực. So với các phương pháp ghi chú khác như Sử dụng t ương đối và Kim Tự Tháp, Artemis là người dễ thương hơn vì các thẩm phán không cần phải xem xét tất cả các câu trong một tài liệu khi đưa ra một phán quyết quan trọng cho một trong những câu án, trong khi cung cấp chú thích về mức án cực quan trọng tương tự. Chúng tôi mô tả chi tiết tiến trình ghi chú và so sánh nó với các hệ thống đánh giá tương tự. Chúng tôi cũng đưa ra kết quả phân tích và thí nghiệm trên một mẫu tài liệu ghi chú của cô 312.</abstract_vi>
      <abstract_da>Vi beskriver Artemis (Anmærkningsmetode for Rich, Tractable, Extractive, Multi-Domain, Vejledende Summarization), en ny hierarkisk anmærkningsproces, der producerer vejledende resuméer for dokumenter fra flere domæner. Nuværende sammenfattende evalueringsdatasæt er enkeltdatamæssige og fokuserer på nogle få domæner, hvor naturligt forekommende resuméer let kan findes, såsom nyheder og videnskabelige artikler. Disse er ikke tilstrækkelige til uddannelse og evaluering af sammenfatningsmodeller til brug i dokumenthåndterings- og informationssøgningssystemer, som skal beskæftige sig med dokumenter fra flere domæner. Sammenlignet med andre noteringsmetoder som Relative Utility og Pyramide, Artemis er mere traktabel, fordi dommere ikke behøver at se på alle sætninger i et dokument, når de foretager en vigtig bedømmelse for en af sætningerne, samtidig med at de giver tilsvarende rige sætninger vigtighed annotationer. Vi beskriver annoteringsprocessen i detaljer og sammenligner den med andre lignende evalueringssystemer. Vi præsenterer også analyser og eksperimentelle resultater over et prøvesæt af 532 kommenterede dokumenter.</abstract_da>
      <abstract_bg>Описваме Артемис (методология за анотация за богато, проследимо, екстрактивно, многодомейнно, индикативно обобщаване), нов йерархичен процес на анотация, който произвежда индикативни резюмета за документи от множество домейни. Настоящите набори от данни за оценка на обобщението са еднодомейнни и са фокусирани върху няколко области, за които лесно могат да бъдат намерени естествени обобщения, като новини и научни статии. Те не са достатъчни за обучение и оценка на модели за обобщаване за използване в системи за управление на документи и извличане на информация, които трябва да се справят с документи от множество области. В сравнение с други методи за анотация, като относителна полезност и пирамида, Артемида е по-проследим, тъй като съдиите не трябва да разглеждат всички изречения в документ, когато правят преценка по важност за едно от изреченията, като същевременно предоставят еднакво богати анотации по важност на изречението. Описваме подробно процеса на анотация и го сравняваме с други подобни системи за оценка. Представяме и анализи и експериментални резултати върху извадков набор от 532 анотирани документа.</abstract_bg>
      <abstract_nl>We beschrijven Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-Domain, Indicative Summarization), een nieuw hiërarchisch annotatieproces dat indicatieve samenvattingen produceert voor documenten uit meerdere domeinen. Huidige samenvattingsevaluatie datasets zijn single-domain en gericht op een paar domeinen waarvoor natuurlijk voorkomende samenvattingen gemakkelijk te vinden zijn, zoals nieuws en wetenschappelijke artikelen. Deze zijn niet voldoende voor het trainen en evalueren van samenvattingsmodellen voor gebruik in documentmanagement- en information retrieval-systemen, die moeten omgaan met documenten uit meerdere domeinen. Vergeleken met andere annotatiemethoden zoals Relative Utility en Piramide, is Artemis aantrekkelijker omdat rechters niet alle zinnen in een document hoeven te bekijken wanneer ze een belangrijk oordeel maken voor een van de zinnen, terwijl ze vergelijkbare rijke annotaties voor het belang van de zinnen verstrekken. We beschrijven het annotatieproces in detail en vergelijken het met andere vergelijkbare evaluatiesystemen. We presenteren ook analyse en experimentele resultaten over een steekproefset van 532 geannoteerde documenten.</abstract_nl>
      <abstract_de>Wir beschreiben Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-Domain, Indicative Summarization), einen neuartigen hierarchischen Annotationsprozess, der indikative Zusammenfassungen für Dokumente aus mehreren Domänen erzeugt. Aktuelle Zusammenfassungsevaluationsdatensätze sind Single-Domain und fokussieren sich auf einige Bereiche, für die natürlich vorkommende Zusammenfassungen leicht gefunden werden können, wie Nachrichten und wissenschaftliche Artikel. Diese reichen nicht aus, um Zusammenfassungsmodelle für den Einsatz in Dokumentenmanagement- und Informationsabrufsystemen zu trainieren und auszuwerten, die sich mit Dokumenten aus mehreren Domänen befassen müssen. Im Vergleich zu anderen Annotationsmethoden wie Relative Utility und Pyramid ist Artemis zugänglicher, da Richter nicht alle Sätze in einem Dokument betrachten müssen, wenn sie eine Bedeutung für einen der Sätze beurteilen, während sie ähnlich reichhaltige Anmerkungen zur Bedeutung des Satzes bereitstellen. Wir beschreiben den Annotationsprozess im Detail und vergleichen ihn mit anderen ähnlichen Auswertungssystemen. Wir präsentieren auch Analyse- und experimentelle Ergebnisse über einen Mustersatz von 532 kommentierten Dokumenten.</abstract_de>
      <abstract_hr>Mi opisujemo Artemis (metodologija Annotacije za bogate, Tractable, Extractive, Multi-domene, Indicative Summarization), nov proces hijerarhičke annotacije koji proizvodi indikativne sažetke za dokumente iz višestrukih domena. Trenutne skupine procjene podataka o procjenama sažetka su jednodomena i fokusirane na nekoliko domena za koje se prirodno događaju sažetke mogu lako naći, poput vijesti i znanstvenih članaka. To nije dovoljno za obuku i procjenu modela sažetanja za upotrebu u sustavima upravljanja dokumentima i prikupljanja informacija, koje moraju riješiti dokumente iz višestrukih domena. U usporedbi s drugim metodama oznake poput Relativne korisnosti i piramide, Artemis je praćeniji jer suci ne moraju gledati sve rečenice u dokumentu kada donose važnu presudu za jednu od rečenica, dok pružaju istovremeno bogate oznake za važnu kaznu. Opišemo proces oznake detaljno i uspoređujemo ga s drugim sličnim sustavima ocjene. Također predstavljamo analizu i eksperimentalne rezultate iznad uzoraka od 532 annotiranih dokumenta.</abstract_hr>
      <abstract_id>Kami menggambarkan Artemis (metodologi anotasi untuk Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), proses anotasi hierarkis baru yang menghasilkan ringkasan indikasif untuk dokumen dari berbagai domain. Current summarization evaluation datasets are single-domain and focused on a few domains for which naturally occurring summaries can be easily found, such as news and scientific articles.  Ini tidak cukup untuk latihan dan evaluasi model ringkasan untuk digunakan dalam manajemen dokumen dan sistem penemuan informasi, yang perlu berurusan dengan dokumen dari berbagai domain. dibandingkan dengan metode anotasi lain seperti Utilitas Relatif dan Piramid, Artemis lebih menarik karena hakim tidak perlu melihat semua kalimat dalam dokumen ketika membuat penghakiman penting untuk salah satu kalimat, sementara menyediakan annotasi penting kalimat yang sama kaya. Kami menjelaskan proses anotasi secara rinci dan membandingkannya dengan sistem evaluasi yang sama lainnya. Kami juga mempersembahkan analisis dan hasil percobaan melalui set sampel dari 532 dokumen yang dicatat.</abstract_id>
      <abstract_ko>Artemis(풍부하고 처리 가능하며 추출 가능하며 여러 영역, 지시적 요약의 주석 방법)를 설명했습니다. 이것은 여러 영역에서 온 문서에 지시적 요약을 생성하는 새로운 층별 주석 과정입니다.현재의 요약 평가 데이터 집합은 단일 분야로 주로 뉴스와 과학 문장 등 자연 요약을 찾기 쉬운 몇 가지 분야에 집중되어 있다.문서 관리와 정보 검색 시스템에서 사용하는 요약 모델의 교육과 평가에 있어 이런 것들은 모두 부족하다. 왜냐하면 이런 시스템은 여러 분야에서 온 문서를 처리해야 하기 때문이다.상대적 효용과 피라미드 등 다른 주석 방법에 비해 아르테미스는 처리하기 쉽다. 법관이 그 중 한 문장에 대해 중요한 판단을 할 때 문서의 모든 문장을 볼 필요가 없고 풍부한 문장의 중요성 주석을 제공하기 때문이다.우리는 주석 과정을 상세하게 묘사하고 이를 다른 유사한 평가 시스템과 비교했다.우리는 또한 주석이 달린 문서 샘플집 532개의 분석과 실험 결과를 제공했다.</abstract_ko>
      <abstract_sw>Tunaelezea Artemis (mbinu za kutangaza za utajiri, Utafiki, Utafiti, Ujumbe wa Mambo ya Miili, Ujumbe wa Kihindi), mchakato wa matangazo ya kihistoria unaotengeneza muhtasari wa nyaraka kutoka maeneo mbalimbali. Taarifa za taarifa za muhtasari za sasa ni moja kwa moja na zinajikita kwenye maeneo machache ambayo kwa uhalisia yanaweza kupatikana kwa urahisi, kama vile makala za habari na sayansi. Hizi hazina tosha ya mafunzo na kutathmini mifano ya muhtasari kwa ajili ya kutumia katika utawala wa nyaraka na mfumo wa upatikanaji wa taarifa, ambao unahitaji kukabiliana na nyaraka kutoka kwenye maeneo mbalimbali. Kulinganishwa na mbinu nyingine za kutoa taarifa kama vile Utumiaji wa Kuhusiana na Pyramid, Artemis ni jambo linaloendelea zaidi kwa sababu mahakimu hawahitaji kuangalia hukumu zote katika nyaraka wakati wakifanya uamuzi wa muhimu kwa moja ya hukumu hizo, wakati wakitoa matangazo ya umuhimu wa hukumu hiyo. Tunaelezea mchakato wa kutangaza kwa kina na kulinganisha na mifumo mingine kama hizo za uchunguzi. Pia tunaweka uchambuzi na matokeo ya majaribio kwa mfululizo wa nyaraka 532 zilizotajwa.</abstract_sw>
      <abstract_sq>Ne përshkruajmë Artemis (metodologji e anotacionit për të pasurit, të ndjeshëm, ekstraktiv, Multi-domain, Summarization Indicative), një proces i ri i anotacionit hierarkik që prodhon përmbledhje treguese për dokumentet nga shumë domaine. Të dhënat aktuale të vlerësimit të përmbledhjes janë një domeni dhe përqëndruan në disa domena për të cilat përmbledhjet që ndodhin natyralisht mund të gjenden lehtë, të tilla si lajmet dhe artikujt shkencore. Këto nuk janë të mjaftueshme për trajnimin dhe vlerësimin e modeleve të përmbledhjes për përdorimin në menaxhimin e dokumenteve dhe sistemet e marrjes së informacionit, që duhet të trajtojnë dokumentet nga fusha të shumta. Krahasuar me metodat e tjera t ë anotacionit të tilla si Utiliteti Relativ dhe Piramida, Artemis është më i trajtueshëm sepse gjyqtarët nuk kanë nevojë të shohin të gjitha fjalët në një dokument kur bëjnë një gjykim të rëndësishëm për një nga fjalët, ndërsa ofrojnë anotacione të rëndësishme të fjalëve të pasura në mënyrë të ngjashme. Ne e përshkruajmë procesin e anotacionit në hollësi dhe e krahasojmë me sisteme të tjera të ngjashme vlerësimi. Ne gjithashtu paraqesim analiza dhe rezultate eksperimentale mbi një sërë mostrash prej 532 dokumentesh të anotuara.</abstract_sq>
      <abstract_am>አርጤምስን (ለሀብታም፣ ለሀብታም፣ ለመውጣት፣ ለብዙኛ ዶሜን፣ ማሳየት ማቀናጃ፣ የአርጤክስል ማስታወቂያ ፕሮጀክት እናሳውቃለን፡፡ የአሁኑ ማቀናጃ ማሳተሚያ የዳታዎችን ማሳየት አንድ ዶሜን ናቸው፡፡ እነዚህ የሰነድ ማቀናጃ እና የመረጃ ማቀናጃ ሲስተካከል የሚጠቀሙት ሰነዶች ከሁለት ዶሜኖች ማነሻ ያስፈልጋሉ፡፡ Compared to other annotation methods such as Relative Utility and Pyramid, Artemis is more tractable because judges don't need to look at all the sentences in a document when making an importance judgment for one of the sentences, while providing similarly rich sentence importance annotations.  እናሳውቃለን፡፡ በ532 ሰነዶች ላይ የተጠቃነ ምሳሌ እናደርጋለን፡፡</abstract_am>
      <abstract_hy>Մենք նկարագրում ենք Արտեմիսը (Անտորակային մեթոդոլոգիան հարուստ, հետաքրքիր, արտադրողական, բազմաբնագավառների, Անտորակային համառոտագրման համար), նոր հիերարխիկ նատորակային գործընթաց, որը ստեղծում է բազմաբնագավառների փաստաթղթերի ինդիկտիվ համառոտա Ներկայական համառոտագրման գնահատման տվյալների համակարգերը միաբնագավառ են և կենտրոնացված մի քանի բնագավառերի վրա, որոնց համար բնական համառոտագրություններ հեշտությամբ կարող են գտնել, ինչպիսիք են նորությունները և գիտական հոդվածները: Սրանք բավարար չեն փաստաթղթերի կառավարման և տեղեկատվության վերադարձման համակարգերում օգտագործվող համառոտագրման մոդելների ուսումնասիրության և գնահատման համար, որոնք պետք է վերաբերվեն բազմաթիվ բնագավառների փաստաթղթերի հետ Համեմատելով այլ annoտացիոն մեթոդների հետ, ինչպիսիք են հարաբերական օգտակարությունը և փիրամիդը, Արտեմիսը ավելի գրավիչ է, որովհետև դատավորները կարիք չունեն նայել փաստաթղթի բոլոր նախադասություններին, երբ դատավորություններից մեկի կարևոր դատողություն են կատարում, միաժամանակ նման հարուստ նախա Մենք մանրամասն նկարագրում ենք annoտացիայի գործընթացը և համեմատում ենք այն այլ նման գնահատման համակարգերի հետ: Մենք նաև ներկայացնում ենք վերլուծություններ և փորձարկման արդյունքներ 532 annoted փաստաթղթերի նմուշների վրա:</abstract_hy>
      <abstract_fa>ما آرتامیز را توصیف می‌کنیم (روش توصیف برای ثروت، ردیابی، خارج‌کننده، چندین دامنه، جمع‌آوری مشخص‌کننده) یک روش توصیف‌کننده‌ی دامنه‌های دامنه‌ای که جمع‌آوری مشخص‌کننده برای سند‌ها از دامنه‌های چندین تولید مجموعه‌های ارزیابی داده‌های فعلی یک دامنی هستند و روی چند دامنی تمرکز می‌شوند که جمع‌های طبیعی اتفاق می‌افتد به آسانی پیدا می‌شوند، مثل اخبار و مقاله‌های علمی. اینها برای آموزش و ارزیابی مدل‌های جمع‌آوری برای استفاده در مدیریت سند و سیستم‌های بازیابی اطلاعات کافی نیستند که باید با سند‌ها از مدل‌های متعدد استفاده کند. در مقایسه با روش‌های دیگر نوشته‌ها مثل استفاده‌های مرتبط و پیرامید، آرتامیز بیشتر ردیابی است، زیرا قاضیان نیاز به همه‌ی جمله‌ها در یک سند در حالی که تصمیم مهم برای یکی از جمله‌ها انجام می‌دهند، در حالی که نوشته‌های مهم‌ترین جمله‌های ثروتمند به طور مشابه می‌دهند. ما فرایند آگاهی را در جزئیات توصیف می‌کنیم و با سیستم‌های ارزیابی مشابه مقایسه می‌کنیم. ما همچنین نتیجه‌های تحلیل و آزمایش را بر روی یک مجموعه نمونه‌ای از 532 مدارک آشکار می‌کنیم.</abstract_fa>
      <abstract_tr>Biz Artemis Häzirki jemgyýet çykyş maglumatlary ýeke-domain we bellenen birnäçe sahypa üstine üns berilip bilýär. Täzelikler we bilim makalary ýaly däl. Bu sened yönetiminde ullanýan we hasaplanja nusgalarynyň bilim alma sistemalarynda ýeterlik däl. Olar birnäçe sahypadan sened bilen çözmeli. Artemis, Relativ Utilitet we Pyramid ýaly başga sözleşme yöntemlere görä görä çözümlidir, sebäbi hökmürler sözleriň birine nähili möhüm sözleriň t äsirlerini berýän wagtlaryna seretmeli däldir. Biz duyurma prosesini detaylarda tanımlarız ve diğer benzer değerlendirme sistemleri ile karşılaştırıyoruz. Biz hem çözümleme we experimental netijesi 532 ýazylan täze senediň örneklerinden çykýarys.</abstract_tr>
      <abstract_bn>আমরা আর্টেমিস (ধনী, ট্র্যাক্টেক্টিক্টিভার, বহুডোমেইন, সংক্রান্ত সংক্রান্ত সংক্রান্ত প্রক্রিয়া) বর্ণনা করি, যা বেশ কয়েকটি ডোমেন থেকে নির্দেশিত তথ্যের বর্তমান সংক্ষিপ্ত তথ্য মূল্যের মূল্য এক ডোমেইন এবং কয়েকটি ডোমেনের উপর মনোযোগ দিয়েছে যেখানে স্বাভাবিক সংক্রান্ত সংক্ষেপ প পাওয়া যাবে, য ডকুমেন্ট ম্যানেজেন্ট এবং তথ্য পুনরুদ্ধার সিস্টেমে ব্যবহারের জন্য প্রশিক্ষণ ও মূল্যায়নের জন্য এগুলো যথেষ্ট নয়, যা বেশ কয়েকটি ডো আর্টেমিস আর্ট্রাক্টিবিশেষ বিষয়বস্তু এবং পিরামিডের মতো অন্যান্য বিবেচনার পদ্ধতির তুলনায়, কারণ বিচারকেরা একটি বাক্যের জন্য গুরুত্বপূর্ণ বিচার করার সময় একটি নথিতে কোন বা আমরা বিস্তারিত প্রক্রিয়া বিস্তারিত বর্ণনা করি আর অন্যান্য একই ধরনের মূল্যায়ন ব্যবস্থার সাথে তুলনা করি। এছাড়াও আমরা বিশ্লেষণ এবং পরীক্ষার ফলাফলের উপস্থাপন করছি একটি নমুনা সেটের মাধ্যমে ৫২ টি বিরক্তিকর নথিপত্র।</abstract_bn>
      <abstract_af>Ons beskrywe Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), ân novel hierarchical annotation process wat aanduidelike opsommings vir dokumente uit veelvuldige domeine produseer. Huidige opsomming evaluering datastel is enkel- domein en fokus op 'n paar domeine waarvan natuurlik opsomming voorgekom kan maklik gevind word, soos nuus en wetenskaplike aktikels. Hierdie is nie genoeg vir onderwerp en evaluering van opsommingsmodele vir gebruik in dokumentbestuurder en inligting ontvangingsstelsels nie, wat nodig om met dokumente te behandel van veelvuldige domeine. Vergelyk met ander annotasie metodes soos Relatiewe nuttigheid en Pyramid, is Artemis meer tractabel omdat regters nie nodig om na al die setinge in 'n dokument te kyk wanneer 'n belangrike oordeel vir een van die setinge gemaak word, terwyl gelyk ryk setinge belangrike annotasies verskaf word nie. Ons beskrywe die annotasie proses in detail en vergelyk dit met ander gelykbare evaluasie stelsels. Ons het ook analiseer en eksperimentale resultate voorgestel oor 'n voorbeeld stel van 532 opgemerkte dokumente.</abstract_af>
      <abstract_bs>Mi opisujemo Artemis (metodologija Annotacije za bogate, Tractable, Extractive, Multi-domene, indikativne sažetke), nov proces hijerarhijske annotacije koji proizvodi indikativne sažetke za dokumente iz višestrukih domena. Trenutne skupine procjene podataka za procjenu rezimezacije su jednodomena i fokusirane na nekoliko domena za koje se prirodno događaju sažetke mogu lako naći, poput vijesti i naučnih članaka. To nije dovoljno za obuku i procjenu modela sažetanja za upotrebu u sustavima upravljanja dokumentima i prikupljanja informacija, koje moraju riješiti dokumente iz višestrukih domena. U usporedbi s drugim metodama annotacije poput Relativne korisnosti i piramide, Artemis je praćeniji jer suci ne moraju gledati sve rečenice u dokumentu kada donose važnu presudu za jednu od rečenica, dok pružaju istovremeno bogate oznake kazne. Opišemo proces annotacije detaljno i uspoređujemo je sa drugim sličnim sistemima procjene. Također predstavljamo analizu i eksperimentalne rezultate iznad uzoraka sa 532 annotiranih dokumenta.</abstract_bs>
      <abstract_ca>Descrivem Artemis (metodologia d'anotació per Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), un nou procés d'anotació jeràrquica que produeix resumes indicatius per documents de múltiples dominis. Els conjunts de dades actuals d'evaluació de resumes són de domini únic i centrats en alguns dominis en els quals es poden trobar fàcilment resumes naturals, com les notícies i els articles científics. Aquestes no són suficients per formar i evaluar els models de resum que s'utilitzen en sistemes de gestió de documents i recuperació d'informació, que han de tractar amb documents de múltiples dominis. Comparat amb altres mètodes d'anotació com l'Utilitat Relativa i la Piramida, l'Artemis és més tractable perquè els jutges no han de mirar totes les frases d'un document quan fan un judici d'importància per una de les frases, mentre proporcionen anotacions d'importància de frases igualment ricas. Descrivem el procés d'anotació en detall i el comparem amb altres sistemes d'evaluació similars. També presentem anàlisis i resultats experimentals sobre un conjunt de mostres de 532 documents anotats.</abstract_ca>
      <abstract_cs>Popisujeme Artemis (metodika anotace pro Rich, Tractable, Extractive, Multi-Domain, Indicative Summarization), nový hierarchický anotace proces, který vytváří orientační shrnutí dokumentů z více domén. Současné soubory hodnocení souhrnných dat jsou jednotlivé domény a zaměřeny na několik domén, pro které lze snadno nalézt přirozeně se vyskytující souhrny, jako jsou zprávy a vědecké články. Ty nejsou dostačující pro školení a hodnocení souhrnných modelů pro použití v systémech správy dokumentů a vyhledávání informací, které potřebují řešit dokumenty z více oblastí. Ve srovnání s jinými metodami anotace, jako jsou Relative Utility a Pyramid, je Artemis více přitažlivá, protože soudci se nemusí dívat na všechny věty v dokumentu při posuzování důležitosti jedné z vět, přičemž poskytují podobně bohaté anotace důležitosti věty. Podrobně popisujeme proces anotace a porovnáváme ho s jinými podobnými systémy hodnocení. Dále prezentujeme analýzu a experimentální výsledky na vzorkové sadě 532 anotovaných dokumentů.</abstract_cs>
      <abstract_et>Kirjeldame Artemist (Rich, Tractable, Extractive, Multi-domain, Indicative Summarization) uudset hierarhilist annotatsiooniprotsessi, mis koostab soovituslikke kokkuvõtteid dokumentidele mitmest valdkonnast. Praegused kokkuvõtliku hindamise andmekogumid on ühe valdkonnaga ja keskenduvad mõnele valdkonnale, mille kohta on lihtne leida looduslikke kokkuvõtteid, näiteks uudiseid ja teadusartikleid. Need ei ole piisavad dokumendihaldus- ja infootsingusüsteemides kasutatavate kokkuvõtlusmudelite koolitamiseks ja hindamiseks, mis peavad tegelema mitme valdkonna dokumentidega. Võrreldes teiste märgistusmeetoditega, nagu suhteline kasulikkus ja püramiid, on Artemis rohkem kirjutatav, sest kohtunikud ei pea vaatama kõiki dokumendi lauseid, kui nad teevad olulise otsuse ühe lause jaoks, pakkudes samas sarnaselt rikkalikke lause tähtsuse märgistusi. Kirjeldame anoteerimisprotsessi üksikasjalikult ja võrdleme seda teiste sarnaste hindamissüsteemidega. Samuti esitame analüüsi- ja katsetulemusi 532 anoteeritud dokumendist koosneva näidiskomplekti põhjal.</abstract_et>
      <abstract_fi>Kuvaamme Artemisia (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), uutta hierarkkista huomautusprosessia, joka tuottaa ohjeellisia yhteenvetoja dokumenteille useilta toimialoilta. Nykyiset tiivistelmäarviointiaineistot ovat yhden toimialueen aineistoja ja keskittyvät muutamiin aloihin, joista luonnossa esiintyvät tiivistelmät löytyvät helposti, kuten uutisiin ja tieteellisiin artikkeleihin. Nämä eivät riitä asiakirjojen hallinta- ja tiedonhakujärjestelmissä käytettävien yhteenvetomallien kouluttamiseen ja arviointiin, sillä niiden on käsiteltävä asiakirjoja useilta toimialoilta. Verrattuna muihin huomautusmenetelmiin, kuten suhteelliseen hyödyllisyyteen ja pyramidiin, Artemis on helpompi jäljittää, koska tuomarien ei tarvitse tarkastella kaikkia asiakirjan lauseita tehdessään tärkeysjärjestystä yhdelle lauseelle, samalla kun he tarjoavat yhtä rikkaita lauseen tärkeysjärjestyksiä. Kuvaamme merkintäprosessia yksityiskohtaisesti ja vertaamme sitä muihin vastaaviin arviointijärjestelmiin. Esitämme myös analyysi- ja kokeellisia tuloksia 532 merkinnällä varustettua asiakirjaa sisältävän otoksen pohjalta.</abstract_fi>
      <abstract_az>Biz Artemisi (Zəngin, Tractable, Extractive, Multi-domain, Indicative Summarization üçün Annotation Methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), bir yeni hiyerarşik annotation process, ki, çoxlu domeinlərdən beləliklə məlumatlar yaradır. Hazırkı qurğulama verilən verilən qurğuları tək-domena və bir neçə domena fokus edilir ki, bəzisi və bilimsel məktublar kimi, doğal olaraq görünən qurğumlar asanlıqla tapılır. Bunlar belə bir çox domeindən belgeler ilə çəkilmək lazımdır. Artemis, əlaqəsiz Utilik və Piramid kimi başqa məlumatlar metodlarına qarşılaşdırılmış, çünki yargıcılar belə cümlələrdən birinə möhkəm hökm vermək üçün belə cümlələrdən birinin möhkəm hökmünü t əsdiqlədiyi zaman bütün cümlələrə baxmaq lazımdır. Biz annotasyon prosesini detaylı təsdiqləyirik və onu başqa bənzər değerlendirmə sistemləri ilə qarşılaşdırırıq. Biz də analizi və təcrübə sonuçlarını 532 belə yazılmış dökümlər üzərində göstəririk.</abstract_az>
      <abstract_jv>We describ artemu current sumification assertion dataset are single-domain and centered on a little domain for that priessly recurring digesters can be readly detected, like new and Sayensical Artiles. Iki ora cukup kanggo nglanggar nggawe lan assempen ning model resumen kanggo nggunakaé ning stiftar dokumen lan sistem kebebasan informasi, sing kudu nggawe dokumen sak oleh domain sing apik. Dijaraké karo pertualangan liyane sing wis ngerasakno, lagi Attribute lan Piramid, artEMS mengko bukane saiki di antara awak dhéwé kuwi jenis hukum gak dhéwé kanggo langgar sapa mulasar winih sing wis nggawe gerakan kanggo kebebasan unalah winih kanggo sawar winih, sampeyan kawit mengko akeh pertualangan. Awakdhéwé nggawe Perintah kanggo nyelarakno lan nggawe gerarané karo sistem sing larang sing it éparan. Awak dhéwé éntuk karo hal dadi karo akeh operasi lan banjur ngewehke sampur karo dokumen sing wis ngaturaken, kawula neng singakake toralah</abstract_jv>
      <abstract_he>We describe Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), a novel hierarchical annotation process that produces indicative summaries for documents from multiple domains.  קבוצות מידע הערכה הנוכחיות של הסיוריזציה הן תחום אחד ומוקדמות על מספר תחומות שאפשר למצוא בסיוריות מתרחשות באופן טבעי בקלות, כמו חדשות ומאמרים מדעיים. אלה לא מספיקים לאימונים ולהערכה של דוגמנים של סאמריזציה לשימוש בניהול מסמכים ומערכות השיגת מידע, שצריכות להתמודד עם מסמכים ממשפחות רבות. בהשוואה לשיטות ציונים אחרות כמו שימוש יחסי ופירמידה, ארטמיס יותר מושכת כי השופטים לא צריכים להסתכל על כל המשפטים במסמך כשעושים שיפוט חשוב לאחד המשפטים, בזמן שסיפקו ציונים חשובים משפטים עשירים באותה מידה. אנחנו מתארים את תהליך ההערכה בפרטים ולהשוות אותה עם מערכות עריכה דומות אחרות. אנחנו גם מציגים ניתוחים ותוצאות ניסויים על סדר דגימות של 532 מסמכים מצוינים.</abstract_he>
      <abstract_sk>Opisujemo Artemis (metodologija za opombe za bogat, poizvedljiv, ekstraktiven, večdomenski, indikativni povzetek), nov hierarhični postopek opombe, ki ustvarja okvirne povzetke za dokumente iz več domen. Trenutni nabori podatkov o vrednotenju povzetkov so enodomenski in se osredotočajo na nekaj področij, za katere je mogoče zlahka najti naravne povzetke, kot so novice in znanstveni članki. Ti ne zadostujejo za usposabljanje in vrednotenje modelov povzetkov za uporabo v sistemih upravljanja dokumentov in pridobivanja informacij, ki morajo obravnavati dokumente z več področij. V primerjavi z drugimi metodami označevanja, kot sta relativna uporabnost in piramida, je Artemis bolj prilagodljiv, saj sodnikom ni treba gledati vseh stavkov v dokumentu, ko opravljajo pomembno presojo za enega od stavkov, hkrati pa zagotavljajo podobno bogate označbe o pomembnosti stavka. Postopek označevanja podrobno opišemo in ga primerjamo z drugimi podobnimi sistemi ocenjevanja. Predstavljamo tudi analize in eksperimentalne rezultate na vzorčnem nizu 532 dokumentov z oznakami.</abstract_sk>
      <abstract_bo>We describe Artemis (Annotation methodology for Rich, Tractable, Extractive, Multi-domain, Indicative Summarization), a novel hierarchical annotation process that produces indicative summaries for documents from multiple domains. Name Current summarization evaluation datasets are single-domain and focused on a few domains for which naturally occurring summaries can be easily found, such as news and scientific articles. These are not sufficient for training and evaluation of summarization models for use in document management and information retrieval systems, which need to deal with documents from multiple domains. ཚོར་བ་སྤྱོད་ཐབས་ལམ་གཞན་དང་མཉམ་དུ་མཐུན་རྐྱེན་ཐབས་ལམ་གཞན་དང་Pyramid ། Artemis་ནི་རྗེས་སུ་འབྱུང་བའི་རྒྱུ་མཚན་ནི་ཉེན་རྟོགས་པ་ཚོས་ཡིག་ཆ་ཚང་མཉམ་དུ་བལྟ་དགོས་མེད། འུ་ཅག་གིས་གསལ་བཤད་ཀྱི་ལས་སྦྱོར་ལ་གསལ་བཤད་བྱས་པ་དང་འདི་ལྟ་བུའི་དབྱེ་ཞིབ་གཞན་དང་མཉམ་དུ་བསྡུར་ ང་ཚོས་ཀྱང་དབྱེ་ཞིབ་དང་བརྟག་དཔྱད་ཡིག་གེ། དཔེ་དབྱེ་ཞིབ་བྱེད་ཀྱི་ཡིག་ཆ་རྣམས་532 དཔེ་བརྗོད་ཀྱི་སྒྲི</abstract_bo>
      <abstract_ha>Tuna bayyana Sura'ar sanatarwa (Ana Shirin Hanyar, Tractable, Extracti, multi-Domen, Mai Gani, Jummariɗawa), wani jarrabi na sanarwa na yanzu hiera da ke ƙara muhimmada wa takardun duk biyu. QXml Hawa ba su isa ga wa mai amfani da wa misãlai masu ƙararin da za'a yi amfani da shi cikin manajan takardar, da kuma tsarin masu motsari da information, wanda ya kamata ya yi amfani da takardun duk masu cikin guda masu yawa. Ana sami da wasu hanyoyin zarzartarwa kamar shirin Relative Aiki da Pymido, artemis ne mafi tracable, dõmin bã ya kasancẽwa ga majakin su dũba duk maganar a cikin takarda idan ya sanya wani muhimu ga zartar da ɗayan maganar, a lokacin da za'a bãyar da sunayen muhimu ga kalma mai girma. We describe the annotation process in detail and compare it with other similar evaluation systems.  Tuna halatar da rabon da matsalan jarrabãwa a samun takardar 532 da aka sanar.</abstract_ha>
      </paper>
    <paper id="9">
      <title>Probabilistic Extension of Precision, <a href="https://en.wikipedia.org/wiki/Recall_(memory)">Recall</a>, and <a href="https://en.wikipedia.org/wiki/F-number">F1 Score</a> for More Thorough Evaluation of Classification Models</title>
      <author><first>Reda</first><last>Yacouby</last></author>
      <author><first>Dustin</first><last>Axman</last></author>
      <pages>79–91</pages>
      <abstract>In pursuit of the perfect supervised NLP classifier, razor thin margins and low-resource test sets can make modeling decisions difficult. Popular metrics such as <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Accuracy</a>, <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">Precision</a>, and Recall are often insufficient as they fail to give a complete picture of the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a>’s behavior. We present a probabilistic extension of Precision, Recall, and F1 score, which we refer to as confidence-Precision (cPrecision), confidence-Recall (cRecall), and confidence-F1 (cF1) respectively. The proposed <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> address some of the challenges faced when evaluating large-scale NLP systems, specifically when the model’s confidence score assignments have an impact on the system’s behavior. We describe four key benefits of our proposed <a href="https://en.wikipedia.org/wiki/Metric_(mathematics)">metrics</a> as compared to their threshold-based counterparts. Two of these benefits, which we refer to as robustness to missing values and sensitivity to model confidence score assignments are self-evident from the metrics’ definitions ; the remaining benefits, generalization, and functional consistency are demonstrated empirically.</abstract>
      <url hash="7a0e6c99">2020.eval4nlp-1.9</url>
      <doi>10.18653/v1/2020.eval4nlp-1.9</doi>
      <video href="https://slideslive.com/38939710" />
      <bibkey>yacouby-axman-2020-probabilistic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="14">
      <title>On Aligning OpenIE Extractions with Knowledge Bases : A Case Study<fixed-case>O</fixed-case>pen<fixed-case>IE</fixed-case> Extractions with Knowledge Bases: A Case Study</title>
      <author><first>Kiril</first><last>Gashteovski</last></author>
      <author><first>Rainer</first><last>Gemulla</last></author>
      <author><first>Bhushan</first><last>Kotnis</last></author>
      <author><first>Sven</first><last>Hertling</last></author>
      <author><first>Christian</first><last>Meilicke</last></author>
      <pages>143–154</pages>
      <abstract>Open information extraction (OIE) is the task of extracting relations and their corresponding arguments from a natural language text in un- supervised manner. Outputs of such systems are used for downstream tasks such as <a href="https://en.wikipedia.org/wiki/Question_answering">ques- tion answering</a> and automatic knowledge base (KB) construction. Many of these downstream tasks rely on aligning OIE triples with refer- ence KBs. Such alignments are usually eval- uated w.r.t. a specific downstream task and, to date, no direct manual evaluation of such alignments has been performed. In this paper, we directly evaluate how OIE triples from the OPIEC corpus are related to the DBpedia KB w.r.t. information content. First, we investigate OPIEC triples and <a href="https://en.wikipedia.org/wiki/DBpedia">DBpedia facts</a> having the same arguments by comparing the information on the OIE surface relation with the KB rela- tion. Second, we evaluate the expressibility of general OPIEC triples in <a href="https://en.wikipedia.org/wiki/DBpedia">DBpedia</a>. We in- vestigate whetherand, if so, howa given OIE triple can be mapped to a single KB fact. We found that such mappings are not always possible because the information in the OIE triples tends to be more specific. Our evalua- tion suggests, however, that significant part of OIE triples can be expressed by means of KB formulas instead of individual facts.</abstract>
      <url hash="b2d4d5b3">2020.eval4nlp-1.14</url>
      <doi>10.18653/v1/2020.eval4nlp-1.14</doi>
      <video href="https://slideslive.com/38939720" />
      <bibkey>gashteovski-etal-2020-aligning</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dbpedia">DBpedia</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/opiec">OPIEC</pwcdataset>
    </paper>
    <paper id="15">
      <title>ClusterDataSplit : Exploring Challenging Clustering-Based Data Splits for Model Performance Evaluation<fixed-case>C</fixed-case>luster<fixed-case>D</fixed-case>ata<fixed-case>S</fixed-case>plit: Exploring Challenging Clustering-Based Data Splits for Model Performance Evaluation</title>
      <author><first>Hanna</first><last>Wecker</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <pages>155–163</pages>
      <abstract>This paper adds to the ongoing discussion in the natural language processing community on how to choose a good development set. Motivated by the real-life necessity of applying <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning models</a> to different <a href="https://en.wikipedia.org/wiki/Distribution_(mathematics)">data distributions</a>, we propose a clustering-based data splitting algorithm. It creates development (or test) sets which are lexically different from the training data while ensuring similar label distributions. Hence, we are able to create challenging cross-validation evaluation setups while abstracting away from performance differences resulting from label distribution shifts between training and test data. In addition, we present a <a href="https://en.wikipedia.org/wiki/Python_(programming_language)">Python-based tool</a> for analyzing and visualizing data split characteristics and model performance. We illustrate the workings and results of our approach using a <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a> and a patent classification task.</abstract>
      <url hash="784206c5">2020.eval4nlp-1.15</url>
      <doi>10.18653/v1/2020.eval4nlp-1.15</doi>
      <video href="https://slideslive.com/38939708" />
      <bibkey>wecker-etal-2020-clusterdatasplit</bibkey>
      <pwccode url="https://github.com/boschresearch/clusterdatasplit_eval4nlp-2020" additional="false">boschresearch/clusterdatasplit_eval4nlp-2020</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="16">
      <title>Best Practices for Crowd-based Evaluation of German Summarization : Comparing Crowd, Expert and Automatic Evaluation<fixed-case>G</fixed-case>erman Summarization: Comparing Crowd, Expert and Automatic Evaluation</title>
      <author><first>Neslihan</first><last>Iskender</last></author>
      <author><first>Tim</first><last>Polzehl</last></author>
      <author><first>Sebastian</first><last>Möller</last></author>
      <pages>164–175</pages>
      <abstract>One of the main challenges in the development of <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization tools</a> is <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization quality evaluation</a>. On the one hand, the human assessment of summarization quality conducted by <a href="https://en.wikipedia.org/wiki/Linguistics">linguistic experts</a> is slow, expensive, and still not a standardized procedure. On the other hand, the automatic assessment metrics are reported not to correlate high enough with <a href="https://en.wikipedia.org/wiki/Human_factors_and_ergonomics">human quality ratings</a>. As a solution, we propose <a href="https://en.wikipedia.org/wiki/Crowdsourcing">crowdsourcing</a> as a fast, scalable, and cost-effective alternative to expert evaluations to assess the intrinsic and extrinsic quality of <a href="https://en.wikipedia.org/wiki/Automatic_summarization">summarization</a> by comparing crowd ratings with expert ratings and automatic metrics such as ROUGE, <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>, or BertScore on a German summarization data set. Our results provide a basis for best practices for crowd-based summarization evaluation regarding major influential factors such as the best annotation aggregation method, the influence of readability and reading effort on summarization evaluation, and the optimal number of crowd workers to achieve comparable results to experts, especially when determining factors such as overall quality, grammaticality, referential clarity, focus, structure &amp; coherence, summary usefulness, and summary informativeness.</abstract>
      <url hash="8e2697a5">2020.eval4nlp-1.16</url>
      <doi>10.18653/v1/2020.eval4nlp-1.16</doi>
      <video href="https://slideslive.com/38939713" />
      <bibkey>iskender-etal-2020-best</bibkey>
    </paper>
    <paper id="17">
      <title>Evaluating Word Embeddings on Low-Resource Languages</title>
      <author><first>Nathan</first><last>Stringham</last></author>
      <author><first>Mike</first><last>Izbicki</last></author>
      <pages>176–186</pages>
      <abstract>The analogy task introduced by Mikolov et al. (2013) has become the standard metric for tuning the hyperparameters of word embedding models. In this paper, however, we argue that the analogy task is unsuitable for low-resource languages for two reasons : (1) it requires that <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> be trained on large amounts of text, and (2) analogies may not be well-defined in some low-resource settings. We solve these problems by introducing the OddOneOut and Topk tasks, which are specifically designed for <a href="https://en.wikipedia.org/wiki/Model_selection">model selection</a> in the low-resource setting. We use these metrics to successfully tune hyperparameters for a low-resource emoji embedding task and word embeddings on 16 extinct languages. The largest of these languages (Ancient Hebrew) has a 41 million token dataset, and the smallest (Old Gujarati) has only a 1813 token dataset.</abstract>
      <url hash="015e5edb">2020.eval4nlp-1.17</url>
      <doi>10.18653/v1/2020.eval4nlp-1.17</doi>
      <video href="https://slideslive.com/38939712" />
      <bibkey>stringham-izbicki-2020-evaluating</bibkey>
    </paper>
  </volume>
</collection>