<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.internlp">
  <volume id="1" ingest-date="2021-07-25">
    <meta>
      <booktitle>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</booktitle>
      <editor><first>Kianté</first><last>Brantley</last></editor>
      <editor><first>Soham</first><last>Dan</last></editor>
      <editor><first>Iryna</first><last>Gurevych</last></editor>
      <editor><first>Ji-Ung</first><last>Lee</last></editor>
      <editor><first>Filip</first><last>Radlinski</last></editor>
      <editor><first>Hinrich</first><last>Schütze</last></editor>
      <editor><first>Edwin</first><last>Simpson</last></editor>
      <editor><first>Lili</first><last>Yu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>August</month>
      <year>2021</year>
      <url hash="245ab163">2021.internlp-1</url>
    </meta>
    <frontmatter>
      <url hash="15b91d30">2021.internlp-1.0</url>
      <bibkey>internlp-2021-interactive</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Apple Core-dination : Linguistic Feedback and Learning in a Speech-to-Action Shared World Game</title>
      <author><first>Susann</first><last>Boy</last></author>
      <author><first>AriaRay</first><last>Brown</last></author>
      <author><first>Morgan</first><last>Wixted</last></author>
      <pages>7–15</pages>
      <abstract>We investigate the question of how adaptive feedback from a <a href="https://en.wikipedia.org/wiki/Virtual_agent">virtual agent</a> impacts the linguistic input of the user in a shared world game environment. To do so, we carry out an exploratory pilot study to observe how individualized linguistic feedback affects the user’s speech input. We introduce a speech-controlled game, Apple Core-dination, in which an agent learns complex tasks using a base knowledge of simple actions. The <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> is equipped with a <a href="https://en.wikipedia.org/wiki/Machine_learning">learning mechanism</a> for mapping new commands to sequences of simple actions, as well as the ability to incorporate <a href="https://en.wikipedia.org/wiki/User_(computing)">user input</a> into written responses. The <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> repeatedly shares its internal knowledge state by responding to what it knows and does not know about <a href="https://en.wikipedia.org/wiki/Meaning_(linguistics)">language meaning</a> and the shared environment. Our paper focuses on the linguistic feedback loop in order to analyze the nature of <a href="https://en.wikipedia.org/wiki/Input_(computer_science)">user input</a>. Feedback from the <a href="https://en.wikipedia.org/wiki/Intelligent_agent">agent</a> is provided in the form of <a href="https://en.wikipedia.org/wiki/Motion">visual movement</a> and <a href="https://en.wikipedia.org/wiki/Writing">written linguistic responses</a>. Particular attention is given to incorporating user input into agent responses and updating the speech-to-action mappings based on commands provided by the user. Through our pilot study, we analyze task success and compare the <a href="https://en.wikipedia.org/wiki/Lexicon">lexical features</a> of user input. Results show variation in input length and <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">lexical variety</a> across users, suggesting a correlation between the two that can be studied further.</abstract>
      <url hash="6eeb0843">2021.internlp-1.2</url>
      <doi>10.18653/v1/2021.internlp-1.2</doi>
      <bibkey>boy-etal-2021-apple</bibkey>
    </paper>
    <paper id="4">
      <title>A Proposal : Interactively Learning to Summarise Timelines by <a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement Learning</a></title>
      <author><first>Yuxuan</first><last>Ye</last></author>
      <author><first>Edwin</first><last>Simpson</last></author>
      <pages>25–31</pages>
      <abstract>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as <a href="https://en.wikipedia.org/wiki/Article_(publishing)">news articles</a>. However, current <a href="https://en.wikipedia.org/wiki/System">systems</a> do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users’ demands and the generated <a href="https://en.wikipedia.org/wiki/Timeline">timeline</a>. The other sub-reward functions contribute to topical coherence and linguistic fluency. We plan experiments to evaluate whether our approach could generate accurate and precise <a href="https://en.wikipedia.org/wiki/Timeline">timelines</a> tailored for each user.</abstract>
      <url hash="21f50786">2021.internlp-1.4</url>
      <doi>10.18653/v1/2021.internlp-1.4</doi>
      <bibkey>ye-simpson-2021-proposal</bibkey>
    <title_ar>اقتراح: التعلم التفاعلي لتلخيص الجداول الزمنية من خلال التعلم المعزز</title_ar>
      <title_es>Una propuesta: aprender de forma interactiva a resumir los plazos mediante el aprendizaje por refuerzo</title_es>
      <title_pt>Uma Proposta: Aprendizagem Interativa para Resumir Cronogramas por Aprendizagem por Reforço</title_pt>
      <title_fr>Une proposition : Apprentissage interactif pour résumer les délais par l'apprentissage par renforcement</title_fr>
      <title_ja>提案：強化学習によるタイムラインを要約するためのインタラクティブな学習</title_ja>
      <title_zh>建言:交互式学以强化结时间表</title_zh>
      <title_ru>Предложение: Интерактивное обучение для обобщения временных рамок посредством обучения подкреплению</title_ru>
      <title_hi>एक प्रस्ताव: इंटरैक्टिव रूप से सुदृढीकरण सीखने द्वारा समयरेखा को संक्षेप में प्रस्तुत करने के लिए सीखना</title_hi>
      <title_ga>Togra: Foghlaim go hIdirghníomhach chun Amlínte a Achoimriú trí Fhoghlaim Atreisithe</title_ga>
      <title_hu>Javaslat: Interaktív tanulás az idővonalak összefoglalására a tanulás megerősítésével</title_hu>
      <title_el>Μια πρόταση: Αλληλέγγυα μάθηση να συνοψίζει χρονοδιαγράμματα με την ενίσχυση της μάθησης</title_el>
      <title_ka>პროცესი: ინტერქექტიური სწავლება თარიღის ხაზების შესაძლებლობით</title_ka>
      <title_it>Una proposta: Imparare interattivamente per riassumere le tempistiche attraverso il rafforzamento dell'apprendimento</title_it>
      <title_kk>Мәлімет: Тұжырымдық уақыт жолдарын күшейту оқыту арқылы интерактивті оқыту</title_kk>
      <title_lt>Pasiūlymas: tarpusavyje mokytis apibendrinti mokymosi sustiprinimu tvarkaraščius</title_lt>
      <title_ms>A Proposal: Interactively Learning to Summary Timelines by Reinforcement Learning</title_ms>
      <title_mk>Предлог: Интерактивно учење да ги сумира временските линии со зајакнување на учењето</title_mk>
      <title_ml>ഒരു പ്രൊഫോസല്‍: വീണ്ടും പഠിപ്പിക്കുന്നതിനാല്‍ കുരുക്കം നേരിടുന്ന സമയത്തിലേക്ക് പഠിക്കുന്നതിനു</title_ml>
      <title_mn>Өдөр дэвшүүлэл: Хүчирхийллийн суралцлагаар нэмэгдүүлэх цаг хугацааны зураг</title_mn>
      <title_mt>Proposta: Tagħlim Interattiv biex jinġabru fil-qosor il-Linji taż-Żmien bit-Tagħlim tat-Tisħiħ</title_mt>
      <title_pl>Wniosek: Interaktywne uczenie się podsumowywania linii czasowych poprzez uczenie się wzmacniające</title_pl>
      <title_ro>O propunere: Învățarea interactivă pentru a rezuma termenele prin consolidarea învățării</title_ro>
      <title_sr>Prijedlog: Interaktivno učenje za skupljanje vremenskih linija pojačanjem učenja</title_sr>
      <title_si>ප්‍රශ්නයක්: සම්බන්ධ වෙලාව සම්බන්ධ වෙලාවට ඉගෙන ගන්න</title_si>
      <title_so>A Proposal: Interactively Learning to Summary Updates by Reinforcement Learning</title_so>
      <title_ta>ஒரு குணங்கள்:</title_ta>
      <title_ur>ایک پیشنهاد: ہمیشہ استعمال کی تعلیم کے ذریعہ تایمیلین کو جمع کرنے کے لئے اثرات سے سیکھنا</title_ur>
      <title_no>Eit førespurnad: Interaktiv læring for samansering av tidslinjer ved å styrke læring</title_no>
      <title_sv>Ett förslag: Interaktivt lärande för att sammanfatta tidslinjer genom förstärkt lärande</title_sv>
      <title_uz>Name</title_uz>
      <title_vi>Một đề nghị: học tương tác để tổng hợp dòng thời gian bằng cách tăng cường học hành</title_vi>
      <title_bg>Предложение: Взаимно обучение за обобщаване на времевите линии чрез засилване на обучението</title_bg>
      <title_nl>Een voorstel: Interactief Leren Tijdlijnen samenvatten door Reinforcement Learning</title_nl>
      <title_da>Et forslag: Interaktivt læring til at opsummere tidslinjer ved at styrke læring</title_da>
      <title_hr>Prijedlog: Interaktivno učenje prikupljanja vremenskih linija pojačanjem učenja</title_hr>
      <title_de>Ein Vorschlag: Interaktives Lernen, Zeitrahmen durch Reinforcement Learning zusammenzufassen</title_de>
      <title_ko>건의: 학습 상호작용 강화를 통해 학습 총결산 시간표</title_ko>
      <title_fa>یک پیشنهاد: یادگیری با فعالیت برای جمع کردن خطوط زمانی با یادگیری بیشتری</title_fa>
      <title_id>Sebuah cadangan: Belajar secara interaktif untuk mempersingkatkan Jadual Waktu Dengan Penolakan Penyukuran</title_id>
      <title_af>'n Voorskou: Interaktiewe leer na opsomming tydline deur versterking leer</title_af>
      <title_sq>Një propozim: Mësimi interaktiv për të përmbledhur afatet kohore nga forcimi i Mësimit</title_sq>
      <title_am>A Proposal: Interactive Learn to Summary Timelines by Reinforcement Learn</title_am>
      <title_tr>Mazmunlar: Öğrenmek üçin Taýratma Hatlary Taýratma Hatlary öwrenmek</title_tr>
      <title_sw>Tamko: Kujifunza kwa njia za muhtasari na Kufundisha Maendeleo</title_sw>
      <title_hy>A Proposal: Interactively Learning to Summarise Timelines by Reinforcement Learning</title_hy>
      <title_az>Bir t…ôbliΡü: Ο•yr…ônm…ôk Ο•yr…ônm…ôsi il…ô Ο•yr…ônm…ôk</title_az>
      <title_bn>একটি বৈশিষ্ট্য: সামার্মিজের সময়ের শিক্ষা পুনরায় শিক্ষার্থী</title_bn>
      <title_bs>Prijedlog: Interaktivno učenje za skupljanje vremenskih linija pojačanjem učenja</title_bs>
      <title_ca>Una proposta: Aprendre interactivament a resumir les línies de temps per reforçar l'aprenentatge</title_ca>
      <title_cs>Návrh: Interaktivní učení shrnout časové osy pomocí posilovacího učení</title_cs>
      <title_et>Ettepanek: Ajakavade kokkuvõtmise vastastikune õppimine õppimise tugevdamise abil</title_et>
      <title_fi>Ehdotus: Vuorovaikutteinen oppiminen kokoamaan aikajanoja vahvistamalla oppimista</title_fi>
      <title_he>הצעה: ללמוד באופן אינטראקטיבי לסכם את קווי הזמנים</title_he>
      <title_sk>Predlog: Interaktivno učenje povzemanja časovnih okvirov z okrepitvijo učenja</title_sk>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>ང་ཚོས་བྱ་ཚུལ། སྤྱིར་གཏོང་ཚབ་ལྟར་དུས་ཚོད་དང་བསྟུན་ནས་ཕར་རྒྱས་གཏོང་ཐབས་ཤིག་བྱ།</title_bo>
      <title_jv>Suasal: Tulung gambar Daftar Taani</title_jv>
      <abstract_ar>يهدف تلخيص الجدول الزمني (TLS) إلى إنشاء قائمة موجزة ومرتبة زمنيًا للأحداث الموضحة في المصادر مثل المقالات الإخبارية. ومع ذلك ، لا توفر الأنظمة الحالية طريقة مناسبة للتكيف مع المجالات الجديدة ولا للتركيز على الجوانب التي تهم مستخدم معين. لذلك ، نقترح طريقة للتعلم التفاعلي لطبقة النقل الآمنة التجريدية باستخدام التعلم المعزز (RL). نحدد وظيفة المكافأة المركبة ونستخدم RL لضبط نموذج تلخيص متعدد المستندات (MDS) ، والذي يتجنب الحاجة إلى التدريب باستخدام الملخصات المرجعية. سيتم تعلم إحدى وظائف المكافآت الفرعية بشكل تفاعلي من ملاحظات المستخدم لضمان الاتساق بين طلبات المستخدمين والجدول الزمني الذي تم إنشاؤه. تساهم وظائف المكافآت الفرعية الأخرى في التماسك الموضعي والطلاقة اللغوية. نحن نخطط لإجراء تجارب لتقييم ما إذا كان نهجنا يمكن أن يولد جداول زمنية دقيقة ودقيقة مصممة لكل مستخدم.</abstract_ar>
      <abstract_es>Timeline Summarisation (TLS) tiene como objetivo generar una lista concisa y ordenada en el tiempo de los eventos descritos en fuentes como artículos de noticias. Sin embargo, los sistemas actuales no proporcionan una forma adecuada de adaptarse a nuevos dominios ni de centrarse en los aspectos de interés para un usuario en particular. Por lo tanto, proponemos un método para el aprendizaje interactivo de TLS abstractivo mediante el aprendizaje por refuerzo (RL). Definimos una función de recompensa compuesta y utilizamos RL para ajustar un modelo abstractivo de resumen de documentos múltiples (MDS), que evita la necesidad de entrenar con resúmenes de referencia. Una de las funciones de sub-recompensa se aprenderá de forma interactiva a partir de los comentarios de los usuarios para garantizar la coherencia entre las demandas de los usuarios y el cronograma generado. Las otras funciones de sub-recompensa contribuyen a la coherencia temática y la fluidez lingüística. Planificamos experimentos para evaluar si nuestro enfoque podría generar plazos precisos y precisos adaptados a cada usuario.</abstract_es>
      <abstract_pt>A sumarização da linha do tempo (TLS) visa gerar uma lista concisa e ordenada de eventos descritos em fontes como artigos de notícias. No entanto, os sistemas atuais não fornecem uma maneira adequada de se adaptar a novos domínios nem de se concentrar nos aspectos de interesse de um determinado usuário. Portanto, propomos um método para aprender interativamente TLS abstrativo usando Reinforcement Learning (RL). Definimos uma função de recompensa composta e usamos RL para ajustar um modelo abstrativo de sumarização de vários documentos (MDS), o que evita a necessidade de treinar usando resumos de referência. Uma das funções de sub-recompensa será aprendida interativamente a partir do feedback do usuário para garantir a consistência entre as demandas dos usuários e o cronograma gerado. As outras funções de sub-recompensa contribuem para a coerência tópica e a fluência linguística. Planejamos experimentos para avaliar se nossa abordagem pode gerar cronogramas precisos e precisos sob medida para cada usuário.</abstract_pt>
      <abstract_fr>Timeline Summarisation (TLS) vise à générer une liste concise et ordonnée d'événements décrits dans des sources telles que des articles de presse. Cependant, les systèmes actuels ne fournissent pas un moyen adéquat de s'adapter à de nouveaux domaines ni de se concentrer sur les aspects présentant un intérêt pour un utilisateur particulier. C'est pourquoi nous proposons une méthode d'apprentissage interactif du TLS abstrait à l'aide de l'apprentissage par renforcement (RL). Nous définissons une fonction de récompense composée et utilisons RL pour affiner un modèle abstrait de synthèse multi-documents (MDS), ce qui évite d'avoir à former à l'aide de résumés de référence. L'une des fonctions secondaires sera apprise de manière interactive à partir des commentaires des utilisateurs afin d'assurer la cohérence entre les demandes des utilisateurs et le calendrier généré. Les autres fonctions de sous-récompense contribuent à la cohérence thématique et à la maîtrise linguistique. Nous planifions des expériences afin d'évaluer si notre approche peut générer des délais précis et adaptés à chaque utilisateur.</abstract_fr>
      <abstract_ja>タイムラインサマリゼーション（ TLS ）は、ニュース記事などのソースで説明されているイベントの簡潔で時系列のリストを生成することを目的としています。しかしながら、現在のシステムは、新しいドメインに適応するための適切な方法、または特定のユーザーに関心のある態様に焦点を当てるための適切な方法を提供しない。そこで，強化学習（ Reinforcement Learning, RL ）を用いて抽象的なTLSをインタラクティブに学習する方法を提案する．複合報酬関数を定義し、RLを使用して抽象的なマルチドキュメント要約（ MDS ）モデルを微調整します。これにより、参照要約を使用してトレーニングする必要がなくなります。サブリワード機能の1つは、ユーザーの要求と生成されたタイムラインとの間の一貫性を確保するために、ユーザーのフィードバックから対話的に学習されます。他の副次的な機能は、話題の一貫性と言語の流暢性に寄与します。私たちは、私たちのアプローチが各ユーザーに合わせた正確で正確なタイムラインを生成できるかどうかを評価するための実験を計画しています。</abstract_ja>
      <abstract_ru>Сводка временной шкалы (TLS) направлена на создание краткого, упорядоченного по времени списка событий, описанных в таких источниках, как новостные статьи. Однако нынешние системы не обеспечивают адекватного способа адаптации к новым областям или сосредоточения внимания на аспектах, представляющих интерес для конкретного пользователя. Поэтому мы предлагаем метод интерактивного обучения абстрактному TLS с использованием обучения подкреплению (RL). Мы определяем сложную функцию вознаграждения и используем RL для тонкой настройки абстрактной модели суммирования нескольких документов (MDS), которая позволяет избежать необходимости тренировки с использованием справочных сводок. Одна из функций субпоощрения будет изучаться в интерактивном режиме на основе обратной связи с пользователями, с тем чтобы обеспечить согласованность между запросами пользователей и составленными сроками. Другие функции суб-награды способствуют тематической согласованности и лингвистической беглости. Мы планируем эксперименты, чтобы оценить, может ли наш подход генерировать точные и точные временные рамки, адаптированные для каждого пользователя.</abstract_ru>
      <abstract_zh>时间轴摘要(TLS)旨在生成新闻文章等事简明,以时序列。 然目前之统,未有适特定用户之宜也。 故吾言强化学(RL)交学抽象TLS之道也。 吾义了一复合奖函数,并用 RL 微抽象之多文档摘要 (MDS) 模样,以免参考摘要训练之用。 其一奖励功能,将以交互方式学于用户反馈,以保用户成之时间表一致性。 其他次级奖功有助于主题连贯性语言流利性。 吾计实验之,以估吾法为用户量身定确之时间表。</abstract_zh>
      <abstract_hi>टाइमलाइन सारांशीकरण (टीएलएस) का उद्देश्य समाचार लेख जैसे स्रोतों में वर्णित घटनाओं की एक संक्षिप्त, समय-क्रमबद्ध सूची उत्पन्न करना है। हालांकि, वर्तमान सिस्टम नए डोमेन के अनुकूल होने का पर्याप्त तरीका प्रदान नहीं करते हैं और न ही किसी विशेष उपयोगकर्ता के लिए रुचि के पहलुओं पर ध्यान केंद्रित करते हैं। इसलिए, हम सुदृढीकरण सीखने (आरएल) का उपयोग करके इंटरैक्टिव रूप से अमूर्त टीएलएस सीखने के लिए एक विधि का प्रस्ताव करते हैं। हम एक यौगिक इनाम समारोह को परिभाषित करते हैं और एक अमूर्त बहु-दस्तावेज़ सारांशीकरण (एमडीएस) मॉडल को ठीक करने के लिए आरएल का उपयोग करते हैं, जो संदर्भ सारांश का उपयोग करके प्रशिक्षित करने की आवश्यकता से बचता है। उप-इनाम कार्यों में से एक को उपयोगकर्ताओं की मांगों और उत्पन्न समयरेखा के बीच स्थिरता सुनिश्चित करने के लिए उपयोगकर्ता प्रतिक्रिया से इंटरैक्टिव रूप से सीखा जाएगा। अन्य उप-इनाम कार्य सामयिक सुसंगतता और भाषाई प्रवाह में योगदान करते हैं। हम यह मूल्यांकन करने के लिए प्रयोगों की योजना बनाते हैं कि क्या हमारा दृष्टिकोण प्रत्येक उपयोगकर्ता के लिए सटीक और सटीक समयरेखा उत्पन्न कर सकता है।</abstract_hi>
      <abstract_ga>Tá sé mar aidhm ag Achoimriú Amlíne (TLS) liosta gonta, am-ordaithe a chruthú d’imeachtaí a gcuirtear síos orthu i bhfoinsí ar nós ailt nuachta. Mar sin féin, ní sholáthraíonn na córais reatha bealach imleor chun oiriúnú d’fhearainn nua ná chun díriú ar ghnéithe ar díol spéise iad d’úsáideoir áirithe. Mar sin, molaimid modh chun TLS teibí a fhoghlaim go hidirghníomhach ag baint úsáide as Foghlaim Neartú (RL). Sainmhínímid feidhm luach saothair iolrach agus úsáidimid RL chun mionchoigeartú a dhéanamh ar shamhail Achoimrithe Ildhoiciméid (MDS) teibí, a sheachnaíonn an gá le hoiliúint a úsáid le hachoimrí tagartha. Foghlaimeofar ceann de na feidhmeanna fo-luaíochta go hidirghníomhach ó aiseolas ó úsáideoirí chun comhsheasmhacht idir éilimh na n-úsáideoirí agus an t-amlíne ginte a chinntiú. Cuireann na feidhmeanna fo-luaíochta eile le comhleanúnachas tráthúla agus líofacht teanga. Déanaimid turgnaimh a phleanáil chun a mheas an bhféadfadh ár gcur chuige amlínte cruinne beachta a chur in oiriúint do gach úsáideoir.</abstract_ga>
      <abstract_el>Η Σύνοψη Χρονικής Γραμμής έχει ως στόχο να δημιουργήσει μια συνοπτική λίστα γεγονότων που περιγράφονται σε πηγές όπως άρθρα ειδήσεων. Ωστόσο, τα σημερινά συστήματα δεν παρέχουν επαρκή τρόπο προσαρμογής σε νέους τομείς ούτε εστίασης στις πτυχές που ενδιαφέρουν έναν συγκεκριμένο χρήστη. Ως εκ τούτου, προτείνουμε μια μέθοδο για διαδραστική εκμάθηση αφηρημένου με τη χρήση της Ενίσχυσης Μάθησης (RL). Καθορίζουμε μια σύνθετη συνάρτηση ανταμοιβής και χρησιμοποιούμε για να τελειοποιήσουμε ένα αφηρημένο μοντέλο Περίληψης πολλαπλών εγγράφων (το οποίο αποφεύγει την ανάγκη κατάρτισης χρησιμοποιώντας περιλήψεις αναφοράς. Μια από τις λειτουργίες υποτροφίας θα διδαχθεί αλληλεπιδραστικά από τα σχόλια των χρηστών για να εξασφαλιστεί η συνέπεια μεταξύ των απαιτήσεων των χρηστών και του παραγόμενου χρονοδιαγράμματος. Οι άλλες λειτουργίες υποτιμίας συμβάλλουν στην τοπική συνοχή και γλωσσική ευχέρεια. Σχεδιάζουμε πειράματα για να αξιολογήσουμε αν η προσέγγισή μας θα μπορούσε να δημιουργήσει ακριβή και ακριβή χρονοδιαγράμματα προσαρμοσμένα για κάθε χρήστη.</abstract_el>
      <abstract_ka>დრო ხაზის კონფიგურაცია (TLS) მიზეზია, რომ წარმოიდგინოთ, დროს დაწყენებული მოვლენების სია, როგორც ახალგაზონის статьები. მაგრამ, მიმდინარე სისტემები არ ახალ დიომენთან აეპტიფიკაციის შესაძლებელი გზა, არა ინტერესტის აპექტიკურება განსაკუთრებული მომხმარებისთვის. ამიტომ, ჩვენ მინდა ინტერექტიგურად აბსტრაქტიგური TLS სწავლისთვის, რომელიც გამოყენებული აბსტრაქტიგური სწავლისთვის (RL). ჩვენ განსაზღვრებით შეცდომების ფუნქცია და გამოყენებით RL, რომ აბსტრაქტიური მრავალე დოკუმენტის კომპერაციაცია (MDS) მოდელს, რომელიც გამოცდილობს რეფერაციის კომპერ ერთი სამუშაო ფუნქციებიდან ინტერექტიგურად მომხმარებლის გადასწავლა, რომ მომხმარებლის მოთხოვრების და შექმნილი სამუშაო ხაზის განმავლობას დასწავლათ. სხვა სამუშაო ფუნქციები მიიღებენ ტემატიური კონექერენციას და ენგურისტიური ფუნქციას. ჩვენ ვფიქრობთ ექსპერიმენტები, რომელიც განსაზღვრება თუ ჩვენი პროგრამა შეიძლება წარმოიქმნა მარტივი და წარმოადგილი დრო ხაზები, რომელიც ყო</abstract_ka>
      <abstract_hu>A Timeline Summarisation (TLS) célja, hogy tömör, időrendezett listát készítsen a forrásokban, például a hírekben leírt eseményekről. A jelenlegi rendszerek azonban nem biztosítanak megfelelő módot az új területekhez való alkalmazkodásra, sem pedig arra, hogy egy adott felhasználó érdeklődésének szempontjaira összpontosítsanak. Ezért javasoljuk az absztraktív TLS interaktív tanulásának módszerét a Reinforcement Learning (RL) segítségével. Meghatározunk egy összetett jutalomfüggvényt, és RL segítségével finomhangoljuk az absztraktív Multi-Document Summarisation (MDS) modellt, amely elkerüli a referenciaösszefoglalók használatával történő képzés szükségességét. Az egyik részjutalom funkció interaktív módon megtanulható a felhasználói visszajelzésekből, hogy biztosítsa a felhasználók igényei és a generált idővonal közötti összhangot. A többi aljutalom funkció hozzájárul a aktuális koherenciához és a nyelvi folyékonysághoz. Kísérleteket tervezünk annak értékelésére, hogy megközelítésünk képes-e pontos és pontos idővonalakat generálni az egyes felhasználók számára.</abstract_hu>
      <abstract_kk>Уақыт жолының тұжырымдамасы (TLS) жаңалық мақалалар секілді көзінде таңдалған оқиғалар тізімін құру мақсаты болады. Бірақ назардағы жүйелер жаңа доменге адаптау үшін және осы пайдаланушыға қызықтық аспектеріне көңіл бермейді. Сондықтан, біз интерактивті түрде абстрактивті TLS оқыту әдісін қолданамыз (RL). Біз компоненттің жоғары функциясын анықтап, RL дегенді абстрактивті көптеген құжаттардың тұжырымдамасын (MDS) баптау үшін қолданамыз. Бұл сілтемелер тұжырымдамасын қолдану керектігін шектеп Пайдаланушылардың талаптарының және құрылған уақыт жолының тәуелсіздігін тексеру үшін қолданушылардың қайтару арқылы интерактивті түрде үйреніледі. Басқа төмендеу функциялары нақышты согластық және лингвистикалық жылдамдығына көмектеседі. Біз әрбір пайдаланушыға дұрыс және дұрыс уақыт жолдарын құрастыру үшін тәжірибелерді бағалау үшін тәжірибелерді жоспарлаймыз.</abstract_kk>
      <abstract_it>Timeline Summarisation (TLS) mira a generare un elenco conciso e cronologico di eventi descritti in fonti come articoli di notizie. Tuttavia, i sistemi attuali non forniscono un modo adeguato per adattarsi a nuovi domini né per concentrarsi sugli aspetti di interesse per un determinato utente. Pertanto, proponiamo un metodo per imparare interattivamente TLS astratto utilizzando Reinforcement Learning (RL). Definiamo una funzione di ricompensa composta e utilizziamo RL per ottimizzare un modello astratto di Summarisation Multi-Document (MDS), evitando la necessità di allenarsi utilizzando riassunti di riferimento. Una delle funzioni di sub-ricompensa sarà imparata interattivamente dal feedback degli utenti per garantire la coerenza tra le richieste degli utenti e la timeline generata. Le altre funzioni di sub-ricompensa contribuiscono alla coerenza topica e alla fluidità linguistica. Progettiamo esperimenti per valutare se il nostro approccio possa generare tempistiche accurate e precise su misura per ogni utente.</abstract_it>
      <abstract_ml>വാര്‍ത്തകള്‍ പോലെ വിവരിച്ചിരിക്കുന്ന സംഭവങ്ങളുടെ നിര്‍ദ്ദേശങ്ങളുടെ പട്ടിക ഉണ്ടാക്കുവാന്‍ ടൈമെലിന്‍ ചുരുക്കം(TLS)  എന്നാലും ഇപ്പോഴത്തെ സിസ്റ്റത്തില്‍ പുതിയ ഡൊമെന്‍സിലേക്ക് ചേര്‍ക്കാനും പ്രത്യേകിച്ചുള്ള ഉപയോക്താവിന് താല്പര്യ അതുകൊണ്ട്, നമ്മള്‍ വീണ്ടും പ്രവര്‍ത്തിപ്പിക്കുന്ന വിദ്യാഭ്യാസ പഠിക്കുന്നതിനുള്ള ഒരു രീതിയെടുക്കുന്നു. ഞങ്ങള്‍ ഒരു കൂട്ടത്തിലെ പ്രതിഫല ഫങ്ഷന്‍ നിര്‍ണ്ണയിക്കുന്നു. RL ഉപയോഗിക്കുന്നത് ഒരു അസാധ്യതയില്ലാത്ത പല രേഖയുടെ ചുരുക്കം മോഡലിലേക്ക് ഉപയ ഉപയോക്താവിന്റെ ആവശ്യങ്ങള്‍ക്കും സൃഷ്ടിക്കുന്ന സമയലൈനുമിടയിലുള്ള അവസ്ഥ ഉറപ്പുവരുത്തുന്നതിനും ഉപയോക്താവിന്റെ ഫിബിബിബാക മറ്റുള്ള ഉപപ്രതിഫല പ്രവര്‍ത്തനങ്ങള്‍ പ്രധാനപൂര്‍ണ്ണമായ സഹജയത്തിലും ഭാഷക്കാരുടെ ഫ്ലൈന്‍സിക്കും സഹായിക് നമ്മുടെ പരീക്ഷണങ്ങള്‍ പരിശോധിക്കുന്നത് ഓരോ ഉപയോക്താവിനും വേണ്ടി നിര്‍ണ്ണയിക്കപ്പെട്ട സമയത്തിന്റെയും കൃത്യമ</abstract_ml>
      <abstract_mt>Is-Sommarju taż-Żmien (TLS) għandu l-għan li jiġġenera list a konċiża u ordnata skont iż-żmien ta’ avvenimenti deskritti f’sorsi bħal artikoli tal-a ħbarijiet. Madankollu, is-sistemi attwali ma jipprovdux mod adegwat biex jadattaw għal dominji ġodda u lanqas biex jiffokaw fuq l-aspetti ta’ interess għal utent partikolari. Għalhekk, qed nipproponu metodu għat-tagħlim interattiv tat-TLS astrattiv bl-użu tat-Tagħlim ta’ Rinforzament (RL). Aħna niddefinixxu funzjoni komposta ta’ premju u nużaw RL biex nidfinaw mudell astrattiv ta’ Sommarju Multi-Dokumenti (MDS), li jevita l-ħtieġa li nħarrġu bl-użu ta’ sommarji ta’ referenza. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users' demands and the generated timeline.  Il-funzjonijiet l-oħra ta’ sottopremju jikkontribwixxu għal koerenza topika u fluwenza lingwistika. Aħna ppjanaw esperimenti biex jivvalutaw jekk l-approċċ tagħna jistax jiġġenera skedi ta’ żmien preċiżi u preċiżi mfassla għal kull utent.</abstract_mt>
      <abstract_mn>Цаг хугацааны уулзалт (TLS) нь мэдээллийн баримтууд шиг эх үүсвэрт тайлбарлан тодорхой, цаг хугацааны дарааллын жагсаалтыг бүтээх зорилго юм. Гэхдээ одоогийн системүүд шинэ хэсэгт адилтгах боломжтой арга замаар хангадаггүй, эсвэл тодорхой хэрэглэгчид сонирхолтой асуудлыг анхаарлаа хангадаггүй. Тиймээс бид интерактив суралцах арга замыг нэмэгдүүлэх (RL) суралцах арга зам өгдөг. Бид холбоотой шагналын функцийг тодорхойлож, RL-г ашиглаж, харьцангуй олон баримт нийлүүлэлтийн (MDS) загварыг сайжруулахын тулд ашигладаг. Энэ нь хариултын нийлүүлэлтийг ашиглан суралцах хэрэгтэй. Хэрэглэгчдийн хэрэглэгчдийн талаар болон үүсгэсэн цаг хугацааны хоорондын харилцааны харилцааны харилцааны нэг нь интерактив байдлаар суралцагдана. Бусад шагналын функцүүд сэдэв хамааралтай, хэлний шингэнд тусалдаг. Бид туршилтуудыг хэрэглэгчид бүрт тодорхой, тодорхой цаг хугацааны шугам бий болгож чадах эсэхийг тодорхойлдохын тулд төлөвлөгдөг.</abstract_mn>
      <abstract_mk>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as news articles.  However, current systems do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user.  Затоа предложуваме метод за интерактивно учење апстрактивен ТЛС користејќи го Научувањето на зајакнување (РЛ). Ние дефинираме комплексна функција на награда и користиме RL за финетизирање на апстрактивен модел на Мултидокументарна резултатација (МДС), кој ја избегнува потребата за обука користејќи референтни резултати. Една од функциите на поднаградата ќе биде научена интерактивно од корисничките реакции за да се осигури константноста помеѓу барањата на корисниците и генерираната временска линија. Другите функции на поднаграда придонесуваат за точната кохеренција и јазичната течност. Планираме експерименти за да процениме дали нашиот пристап може да генерира точни и прецизни временски линии соодветни за секој корисник.</abstract_mk>
      <abstract_ms>Penapisan Garis Masa (TLS) bermaksud untuk menghasilkan senarai peristiwa yang tersusun dan tersusun-masa yang diterangkan dalam sumber seperti artikel berita. However, current systems do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user.  Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL).  Kami takrifkan fungsi hadiah gabungan dan gunakan RL untuk menyesuaikan model Penapisan Berberapa Dokumen (MDS) abstraktif, yang mengelakkan perlukan latihan menggunakan ringkasan rujukan. Salah satu fungsi sub-hadiah akan belajar secara interaktif dari balas balik pengguna untuk memastikan konsistensi antara permintaan pengguna dan garis masa yang dijana. Fungsi sub-hadiah lain berkontribusi kepada ketepatan topik dan ketepatan bahasa. Kami merancang eksperimen untuk menilai sama ada pendekatan kita boleh menghasilkan garis masa yang tepat dan tepat yang disesuaikan untuk setiap pengguna.</abstract_ms>
      <abstract_no>Tidlinjesamandringa (TLS) måtar å laga ei konklus, tidsredigt liste over hendingar som er beskriven i kjelder som nyhetsarklar. Det gjeldande systemet gjev imidlertid ikkje noko passande måte å tilpassa nye domene eller fokusera på aspektane av interesse til ein bestemt brukar. Derfor fører vi ein metode for interaktivt læring av abstraktive TLS ved hjelp av reinforcementlæring (RL). Vi definerer ein komponent rentefunksjon og bruker RL for å finne opp ein abstraktiv multidokumentsamandrag (MDS) modell, som unngår behov for å trenja med referanssamandrag. Ein av underløpsfunksjonane vil bli lært interaktivt frå tilbakemeldinga til brukaren for å sikra at konsistens mellom brukaren krev og den genererte tidslinja. Den andre underløpsfunksjonane bidrar til temaske koherens og språkstiske fluktens. Vi planlegger eksperimenter for å evaluera om tilnærminga vårt kan laga nøyaktig og nøyaktig tidslinjer som er tilpassa for kvar brukar.</abstract_no>
      <abstract_pl>Podsumowanie linii czasu (TLS) ma na celu stworzenie zwięzłej, uporządkowanej w czasie listy zdarzeń opisanych w źródłach, takich jak artykuły wiadomościowe. Obecne systemy nie zapewniają jednak odpowiedniego sposobu dostosowania się do nowych domen ani skupienia się na aspektach interesujących konkretnego użytkownika. Dlatego proponujemy metodę interaktywnego uczenia się abstrakcyjnego TLS z wykorzystaniem Reinforcement Learning (RL). Definiujemy złożoną funkcję nagrody i używamy RL do dostrojenia abstrakcyjnego modelu podsumowania wielu dokumentów (MDS), co unika konieczności treningu za pomocą podsumowań referencyjnych. Jedna z funkcji sub-nagrody zostanie nauczona interaktywnie z opinii użytkowników, aby zapewnić spójność między wymaganiami użytkowników a generowaną linią czasu. Inne funkcje sub-nagrody przyczyniają się do aktualnej spójności i płynności językowej. Planujemy eksperymenty, aby ocenić, czy nasze podejście może generować dokładne i precyzyjne linie czasu dostosowane do każdego użytkownika.</abstract_pl>
      <abstract_ro>Timeline Summarisation (TLS) își propune să genereze o listă concisă, ordonată în timp, a evenimentelor descrise în surse precum articole de știri. Cu toate acestea, sistemele actuale nu oferă o modalitate adecvată de adaptare la noile domenii și nici de concentrare asupra aspectelor de interes pentru un anumit utilizator. Prin urmare, propunem o metodă de învățare interactivă a TLS abstractivă folosind Reinforcement Learning (RL). Definim o funcție de recompensă compusă și folosim RL pentru a regla fin un model abstractiv Multi-Document Summarisation (MDS), care evită nevoia de a instrui folosind rezumate de referință. Una dintre funcțiile de subrecompensă va fi învățată interactiv din feedback-ul utilizatorilor pentru a asigura coerența între cerințele utilizatorilor și calendarul generat. Celelalte funcții sub-recompensare contribuie la coerența actuală și fluența lingvistică. Planificăm experimente pentru a evalua dacă abordarea noastră ar putea genera cronologii precise și precise adaptate fiecărui utilizator.</abstract_ro>
      <abstract_sr>Vremenska sažetka (TLS) je cilj da stvori konkretnu, vremenski naređenu listu događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sistemi ne pružaju odgovarajući način da se prilagodi novim domenama niti da se fokusiraju na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju kompleksnog nagrade i koristimo RL za finaliziranje apstraktivnog model a rezervacije mnogih dokumenta (MDS), koji izbjegava potrebu treniranja korištenjem referentnih sažetaka. Jedna od funkcija podnagrade biće učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahteva korisnika i proizvedenih vremenskih linija. Druge podnagrade doprinose temalnoj koherenciji i jezičkoj tekućini. Planiramo eksperimente da procenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije ispravljene za svakog korisnika.</abstract_sr>
      <abstract_si>වෙලාව සම්පූර්ණය (TLS) අදහස් කරනවා සම්පූර්ණය, වෙලාව සම්පූර්ණය සඳහා වාර්තාවක් ලැයිස්තුවක් නිර්මාණය කරන නමුත්, ප්‍රස්ථාන පද්ධතිය අළුත් ඩෝමේන් වලට සම්බන්ධ වෙන්න හැබැයි විශේෂ ප්‍රයෝජකයෙක්ට ප්‍රශ්නයක්  ඉතින්, අපි ප්‍රයෝජනය කරන්නේ ප්‍රයෝජනයක් ප්‍රයෝජනය කරන්නේ ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳ අපි සම්පූර්ණ ප්‍රයෝජනයක් විශ්වාස කරන්න සහ RL විශ්වාස කරන්න සම්පූර්ණ විශ්වාස කරන්න සම්පූර්ණ විශ්වාස (MDS) මොඩේල් එක පාවිච්චි ප්‍රයෝජනය සහ නිර්මාණය වෙනුවෙන් ප්‍රයෝජනය ප්‍රයෝජනයෙන් ප්‍රයෝජනයෙන් ප්‍රයෝජනයෙන් ප්‍රයෝ අනිත් ප්‍රතිචාර ප්‍රයෝජනය සහ භාෂාත්මක ප්‍රයෝජනය සම්බන්ධ වෙන්න පුළුවන්. අපි පරීක්ෂණය සැලසුම් කරනවා අපේ පරීක්ෂණය සිද්ධ වෙන්න පුළුවන් කියලා හැම පාවිච්චිකරුවෙක්ම සැකස</abstract_si>
      <abstract_sv>Timeline Summarisation (TLS) syftar till att skapa en kortfattad, tidsordnad lista över händelser som beskrivs i källor som nyhetsartiklar. Nuvarande system ger dock inte ett lämpligt sätt att anpassa sig till nya domäner eller att fokusera på aspekter av intresse för en viss användare. Därför föreslår vi en metod för interaktivt lärande av abstrakt TLS med hjälp av Reinforcement Learning (RL). Vi definierar en sammansatt belöningsfunktion och använder RL för att finjustera en abstraktiv MDS-modell (Multi-Document Summarisation), vilket undviker behovet av att träna med referenssammanfattningar. En av delbelöningsfunktionerna kommer att läras interaktivt från användarfeedback för att säkerställa samstämmigheten mellan användarnas krav och den genererade tidslinjen. De andra delbelöningsfunktionerna bidrar till aktuell samstämmighet och språklig flytning. Vi planerar experiment för att utvärdera om vårt tillvägagångssätt kan generera exakta och exakta tidslinjer anpassade för varje användare.</abstract_sv>
      <abstract_so>Summariska waqtiga (TLS) waxaa loola jeedaa inuu sameeyo liiska dhacdooyinka oo lagu qoray sida warqadaha habari. Si kastaba ha ahaatee nidaamka joogtada ah ma bixiyaan hab ku filan in lagu beddelo deegaanka cusub ama uu ku kalsoonaado arrimaha xiisaha ee isticmaalaha gaar ah. Sidaas darteed waxaynu soo jeedaynaa qaab aan si iskuul ah u barano TLS oo la isticmaalayo waxbarashada Reinforcement (RL). Waxaynu u qoraynaa shaqo mushaar ah oo ka mid ah RL si a an u sameyno sameyn sameynta dhamaadka qoraalka kala duduwan (MDS), kaasoo diida in loo baahdo waxbarashada isticmaalka summarinta reference. Mid ka mid ah waxqabadka sub-mushaarka waxaa si firfircoon looga bartaa feedbacka isticmaalaha si uu u xaqiijiyo isku xiriirka u dhexeeya baahida isticmaalayaasha iyo xilliga la soo saaray. Shaqooyinka kale ee sub-mushaarku waxay ku caawinaysaa isku xiriir iyo luqada. Waxaan qorsheynaa baaritaanka si aan u qiimeynayno in qaababkayagu uu u sameyn karo saxda iyo saxda xilliyada ee loo qoray isticmaalaha kasta.</abstract_so>
      <abstract_ur>Timeline Summarisation (TLS) کا ارادہ یہ ہے کہ سورجوں میں واضح ہونے والی حادثوں کی ایک قطعہ، زمان سفارش کی لکھ پیدا کرے۔ لیکن موجود سیستموں نے نئی ڈومین کے ساتھ اچھی طرح نہیں دی ہے اور نہ کسی خاص کاربر کے علاقے پر تمرکز کرنا ہے. لہٰذا، ہم ایک طریقہ پیشنهاد کرتے ہیں کہ آب تراکٹیو TLS کی استعمال کریں (RL) کے مطابق ایک طریقہ سکھائیں۔ ہم ایک متصلہ اجرت کا فرقہ مقرر کرتے ہیں اور RL کو استعمال کرتے ہیں کہ ایک مثبت multi-document Summarisation (MDS) موڈل (مثبت) کو مثبت کر سکیں، جو مرتبہ جمع کے مطابق تطالب کرنے کی ضرورت سے روکتی ہے۔ سوب-پاداش کا ایک فنکٹ یوسف یوسف فیڈبک سے پیدا کیا جائے گا تاکہ کارساز کی خواہشوں اور پیدا کیے ہوئے تایملین کے درمیان اتصال کرے۔ اور دوسری کمائی کے فناوروں نے ٹوپائیل کی ملکیت اور زبان کی ملکیت میں اضافہ کیا ہے۔ ہم آزمائش کی تدبیروں کی تدبیر کریں گے کہ ہمارا طریقہ دقیق اور دقیق تایملین پیدا کرے جو ہر کاربر کے لئے تدبیر کی گئی ہے۔</abstract_ur>
      <abstract_lt>Laikotarpio santraukos tikslas – sudaryti trumpą, laiku tvarkomą įvykių, aprašytų šaltiniuose, pavyzdžiui, naujienų straipsniuose, sąrašą. Tačiau dabartinės sistemos nesuteikia tinkamo būdo prisitaikyti prie naujų sričių ir sutelkti dėmesio į konkrečiam vartotojui svarbius aspektus. Todėl siūlome metodą interaktyviai mokytis abstraktyvios TLS naudojant sustiprintą mokymąsi. We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries.  Viena iš papildomo atlyginimo funkcijų bus interaktyviai mokoma iš vartotojų atsiliepimų, kad būtų užtikrintas vartotojų poreikių ir sukauptų terminų nuoseklumas. Kitos subatlyginimo funkcijos prisideda prie aktualios nuoseklumo ir kalbų lankstumo. Planuojame eksperimentus, kad įvertintume, ar mūsų metodas galėtų sukurti tikslias ir tikslias kiekvienam naudotojui pritaikytas grafikas.</abstract_lt>
      <abstract_ta>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as news articles.  ஆயினும், தற்போதைய கணினிகள் புதிய களங்களுக்கு ஒப்பிட போதுமான வழியைக் கொடுக்கவில்லை அல்லது குறிப்பிட்ட பயனருக்கு த ஆகையால், நாம் ஒரு முறையை திரும்பச் செயல்படுத்த வேண்டிய TLS கற்றுக்கொள்ள ஒரு முறையை பரிந்துரைக்கிறோம். நாம் ஒரு கூட்டு கூலி செயல்கூறை வரையறுக்கிறோம் மற்றும் RL பயன்படுத்தி ஒரு செயல்படுத்தப்பட்ட பல்ஆவண சுருக்கம் (MDS) மாதிரியை பயன்படுத்துகிறோம், அது  துணை பூர்த்தி செயல்பாடுகளில் ஒன்று பயனர் செயல்பாடுகளின் செயல்பாடுகளிலிருந்து செயல்படுத்தப்படும் பயனர் தேவைகள் மற்றும் உருவா மற்ற துணை பூர்த்தி செயல்பாடுகள் தலைப்பு ஒன்றிணைப்புகளுக்கும் மொழியில் தெளிவான விளைவுகளுக்கும்  ஒவ்வொரு பயனருக்கும் சரியான மற்றும் சரியான நேர வரிகளை உருவாக்க முடியுமா என்று பரிசோதிப்போம்.</abstract_ta>
      <abstract_uz>@ info: whatsthis Lekin, joriy tizim yangi domen bilan moslash uchun yetarli usulni koʻrsatilmaydi va foydalanuvchiga foydalanuvchi qiymatlariga foydalanish uchun foydalanuvchini foydalanishi mumkin. Shunday qilib, biz Reinforcement o'rganish (RL) yordamida avto'g'ri bo'lgan TLS o'rganish usulini tahlil qilamiz. Biz bir kompyuterning muvaffaqiyatlarni aniqlash va RL'ni ajratish uchun katta hujjat hisobotini (MDS) modeliga foydalanamiz. Bu muammolar hisobotidan foydalanish kerak emas. Name Boshqa sub-payt funksiyalari mavjud birlashtirish va tillarda foydalanadi. Biz bir foydalanuvchiga tayyorlangan taymaviy va taymaviy vaqtlarni yaratish uchun imtiyozlarni qiymatga qaramamiz.</abstract_uz>
      <abstract_vi>Lát nữa sẽ có buổi khai đại (TLS) nhằm tạo ra một danh sách các sự kiện ngắn gọn, được đặt ra theo thời gian diễn tả trong các nguồn tin như bản tin. Tuy nhiên, hệ thống hiện tại không cung cấp một cách thích hợp để thích nghi với lĩnh vực mới hay tập trung vào các khía cạnh quan tâm đối với một người dùng cụ thể. Do đó, chúng tôi đề xuất phương pháp học tập trừu tượng TLS bằng cách tiếp cận học tủy sống (RL). Chúng tôi xác định một hàm phần thưởng phức tạp và dùng RL để chỉnh sửa một kiểu tổ chức đa tài liệu trừu tượng (MDS) để tránh việc huấn luyện bằng các bản tóm tắt tham khảo. Một trong các chức năng phần thưởng sẽ được học tương tác từ phản hồi của người dùng để đảm bảo sự đồng nhất giữa yêu cầu của người dùng và dòng thời gian đã tạo ra. Các chức năng tiền thưởng khác đóng góp cho sự đồng bộ thời sự kiên trì. Chúng tôi lên kế hoạch thử nghiệm để xem phương pháp của chúng ta có thể tạo ra dòng thời gian chính xác cho mỗi người dùng không.</abstract_vi>
      <abstract_bg>Целта на обобщението на времевата линия е да генерира кратък, подреден във времето списък на събитията, описани в източници като новинарски статии. Настоящите системи обаче не осигуряват адекватен начин за адаптиране към нови домейни, нито за фокусиране върху аспектите, които представляват интерес за конкретен потребител. Затова предлагаме метод за интерактивно изучаване на абстрактни ТУС с помощта на подсилващо обучение (РС). Определяме комбинирана функция за възнаграждение и използваме за фина настройка на абстрактен модел за обобщаване на множество документи (МДС), което избягва необходимостта от обучение с помощта на справочни резюмета. Една от функциите за подвъзнаграждение ще се научи интерактивно от обратната връзка на потребителите, за да се гарантира съгласуваността между исканията на потребителите и генерирания времеви график. Другите подвъзнаграждение функции допринасят за актуална съгласуваност и езиково владеене. Планираме експерименти, за да оценим дали нашият подход може да генерира точни и точни времеви линии, съобразени с всеки потребител.</abstract_bg>
      <abstract_da>Timeline Summarisation (TLS) har til formål at generere en kortfattet, tidsordnet liste over begivenheder beskrevet i kilder såsom nyhedsartikler. De nuværende systemer giver imidlertid ikke en passende måde at tilpasse sig nye områder på eller fokusere på aspekter af interesse for en bestemt bruger. Derfor foreslår vi en metode til interaktivt at lære abstrakt TLS ved hjælp af Reinforcement Learning (RL). Vi definerer en sammensat belønningsfunktion og bruger RL til at finjustere en abstraktiv MDS-model (Multi-Document Summarisation), hvilket undgår behovet for at træne ved hjælp af referenceresuméer. En af subbelønningsfunktionerne vil blive lært interaktivt fra brugerfeedback for at sikre konsistensen mellem brugernes krav og den genererede tidslinje. De øvrige subbelønningsfunktioner bidrager til aktuel sammenhæng og sproglig flydende. Vi planlægger eksperimenter for at vurdere, om vores tilgang kunne generere nøjagtige og præcise tidslinjer skræddersyet til hver bruger.</abstract_da>
      <abstract_hr>Vremenska sažetka (TLS) je cilj proizvesti konkretni, vremenski raspoređeni popis događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sustavi ne pružaju odgovarajući način prilagođenja novim domenama niti fokusirati se na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju nagrade kombinacije i koristimo RL kako bi upravljali abstraktivni model rezervacije mnogih dokumenta (MDS), koji izbjegava potrebu trenirati s referentnim sažetkama. Jedna od funkcija podnagrade bit će učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahtjeva korisnika i proizvedene vremenske linije. Druge podnagrade doprinose temeljnoj konsekvenciji i jezičkoj tekućini. Planiramo eksperimente da procijenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije prilagođene svakom korisniku.</abstract_hr>
      <abstract_id>Penapisan Garis Waktu (TLS) bermaksud untuk menghasilkan daftar peristiwa singkat, tertib-waktu yang ditetapkan dalam sumber seperti artikel berita. Namun, sistem saat ini tidak menyediakan cara yang tepat untuk beradaptasi ke domain baru atau untuk fokus pada aspek kepentingan bagi pengguna tertentu. Oleh karena itu, kami mengusulkan metode untuk mempelajari secara interaktif TLS abstraktif menggunakan Penjelasan Penyukuran (RL). Kami mendefinisikan fungsi penghargaan komponen dan menggunakan RL untuk memperbaiki model abstraktif Multi-Document Summarization (MDS), yang menghindari kebutuhan untuk berlatih menggunakan ringkasan referensi. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users' demands and the generated timeline.  Fungsi sub-hadiah lainnya berkontribusi ke koerensi topik dan keterlaluan bahasa. Kami merencanakan eksperimen untuk mengevaluasi apakah pendekatan kita dapat menghasilkan garis waktu yang tepat dan tepat disesuaikan untuk setiap pengguna.</abstract_id>
      <abstract_de>Timeline Summarisation (TLS) zielt darauf ab, eine kurze, zeitlich geordnete Liste von Ereignissen zu erstellen, die in Quellen wie Nachrichtenartikeln beschrieben werden. Die derzeitigen Systeme bieten jedoch keine adäquate Möglichkeit, sich an neue Domänen anzupassen oder sich auf die Aspekte zu konzentrieren, die für einen bestimmten Benutzer von Interesse sind. Daher schlagen wir eine Methode vor, um abstraktives TLS interaktiv mit Reinforcement Learning (RL) zu lernen. Wir definieren eine zusammengesetzte Belohnungsfunktion und verwenden RL zur Feinabstimmung eines abstraktiven MDS-Modells (Multi-Document Summarisation). Eine der Unterbelohnungsfunktionen wird interaktiv aus Benutzerfeedback gelernt, um die Konsistenz zwischen den Anforderungen der Benutzer und der generierten Zeitleiste zu gewährleisten. Die anderen Sub-Belohnungsfunktionen tragen zur aktuellen Kohärenz und Sprachflüssigkeit bei. Wir planen Experimente, um zu evaluieren, ob unser Ansatz genaue und präzise Zeitpläne generieren kann, die auf jeden Benutzer zugeschnitten sind.</abstract_de>
      <abstract_sw>Uhitimisho wa muda mfupi (TLS) unalenga kutengeneza orodha ya matukio yanayoamrishwa kwa muda unaoandikwa katika vyanzo kama vile makala za habari. Hata hivyo, mifumo ya sasa hazina njia ya kutosha ya kubadilishana na maeneo mapya wala kuyatazama masuala ya maslahi kwa mtumiaji fulani. Kwa hiyo, tunapendekeza njia ya kujifunza kwa njia za kujitegemea TLS zenye ubora kwa kutumia mafunzo ya Maendeleo (RL). Tunaweza kufafanua kazi ya malipo ya pamoja na kutumia RL kwa ajili ya kuunganisha mfumo wa Mkutano wa nyaraka kadhaa (MDS), ambao unajitenga na haja ya kufundisha kwa kutumia muhtasari wa maandishi. Moja ya kazi za malipo ya subira itajifunza kwa namna moja kwa moja kutokana na mwitikio wa mtumiaji ili kuhakikisha umuhimu kati ya mahitaji ya watumiaji na simu zilizotengenezwa. Shughuli nyingine za malipo ya subira zinachangia ushirikiano wa mada na ufanisi wa lugha. We plan experiments to evaluate whether our approach could generate accurate and precise timelines tailored for each user.</abstract_sw>
      <abstract_nl>Timeline Summarisation (TLS) heeft als doel een beknopte, tijdgeordende lijst te genereren van gebeurtenissen beschreven in bronnen zoals nieuwsberichten. De huidige systemen bieden echter geen adequate manier om zich aan te passen aan nieuwe domeinen of om te focussen op de aspecten die voor een bepaalde gebruiker interessant zijn. Daarom stellen we een methode voor om interactief abstractief TLS te leren met behulp van Reinforcement Learning (RL). We definiëren een samengestelde beloningsfunctie en gebruiken RL om een abstractief MDS-model (Multi-Document Summarisation) te finetunen, waardoor het niet nodig is om te trainen met behulp van referentiesamenvattingen. Een van de sub-beloningsfuncties wordt interactief geleerd van gebruikersfeedback om de consistentie tussen de eisen van gebruikers en de gegenereerde tijdlijn te verzekeren. De andere sub-beloningsfuncties dragen bij aan actuele samenhang en taalbeheersing. We plannen experimenten om te evalueren of onze aanpak nauwkeurige en nauwkeurige tijdlijnen kan genereren op maat van elke gebruiker.</abstract_nl>
      <abstract_fa>جمع کردن خط زمانی (TLS) هدف می‌گیرد که یک فهرست دقیق، سفارشی زمانی از اتفاقات توصیف شده در منابع مانند مقاله‌های خبری را ایجاد کند. ولی سیستم‌های فعلی راهی مناسب برای adapting to new domains و برای تمرکز روی نقطه‌های علاقه به یک کاربر خاص نمی‌دهند. بنابراین، ما یک روش برای یادگیری TLS abstractive با استفاده از یادگیری افزایش (RL) را پیشنهاد می‌کنیم. ما یک عملکرد پاداش متصل را تعریف می‌کنیم و از RL استفاده می‌کنیم تا یک مدل جمع‌آوری Multi-Document (MDS) را پاداش دهیم که از نیازی استفاده از جمع‌آوری‌های متصل آموزش فرار می‌کند. یکی از عملکرد‌های زیر پاداش از بازگشت کاربر به طور متفاوتی یاد می‌گیرد تا مطمئن شود که هماهنگی بین درخواست‌های کاربر و خط زمانی تولید شده است. کارهای زیر پاداش دیگر به هماهنگی و فعالیت زبان کمک می کنند. ما برنامه‌های آزمایشات را برای ارزیابی که آیا دستور ما می‌تواند خط زمان دقیق و دقیق را برای هر کاربر تغییر داده شود.</abstract_fa>
      <abstract_ko>타임라인 요약(TLS)은 뉴스 기사와 같은 출처에서 기술한 이벤트의 간단명료하고 시간순으로 목록을 만들기 위한 것이다.그러나 현재의 시스템은 새로운 분야에 적응하는 적당한 방식을 제공하지 않고 특정 사용자가 흥미를 느끼는 부분에 중점을 두지 않는다.따라서 우리는 강화학습(RL)을 사용하여 추상적인 TLS를 상호작용으로 학습하는 방법을 제시했다.우리는 복합 보상 함수를 정의하고 RL을 사용하여 추상적인 다중 문서 요약(MDS) 모델을 미세하게 조정하여 참고 요약을 사용하여 교육을 진행하는 수요를 피했다.그 중 하나의 차급 보상 기능은 사용자의 피드백에서 상호작용을 통해 사용자의 수요와 생성된 시간선 간의 일치성을 확보할 것이다.기타 하위 보상 기능은 주제의 일관성과 언어의 유창성에 도움이 된다.우리는 우리의 방법이 모든 사용자에게 정확한 시간선을 생성할 수 있는지를 평가하기 위해 실험을 진행할 계획이다.</abstract_ko>
      <abstract_am>የአሁኑን ፋይል አስቀምጥ ምንም እንኳን፣ የአሁኑ ስርዓቶች አዲስ ዶሜኖችን ለመቀበል እና የተጠቃሚ ተጠቃሚ ጉዳዮችን ለመጠቀም አይጠቅሙም፡፡ ስለዚህም፣ በሥርዓት ትምህርት (RL) የተጠቃሚ ትምህርት (TLS) ለመማር የሚችሉትን ተቃውሞ እናስፈልጋለን፡፡ የዋጋውን ዋጋ ማድረግ እና RL በመጠቀም እናስቀምጣለን፡፡ ጥያቄ ሌሎቹ የዋጋ ደመወዝ ስርዓቶች ለባሕላዊ ስብስብ እና ለቋንቋዊ ውጤት ያጣቅማሉ፡፡ ሁኔታ ለሁሉም ተጠቃሚዎች የተፈጸመ እና የጊዜውን መስመር መፍጠር እንዲችል ተፈተና እናደርጋለን፡፡</abstract_am>
      <abstract_af>Tydline Opsomming (TLS) doel doen om 'n sameslys, tydporteerde lys van gebeurtenis in bronne beskrywe soos nuusartikels te genereer. Maar huidige stelsels verskaf nie 'n adequate manier om na nuwe domeine te pas nie of om op die aspekte van belang te fokus a an 'n bepaalde gebruiker te verskaf nie. Daarom, ons voorstel 'n metode vir interaktief abstraktiewe TLS te leer met die gebruik van Versterking Leer (RL). Ons definieer 'n komponente vergelde funksie en gebruik RL om 'n abstraktiewe Multi- dokument Opsomming (MDS) model te fin- tune, wat veroorsaak die benodig om te trein met verwysing opsommings te gebruik. Een van die sub- reward funksies sal interaktief leer word van gebruiker terugkeer om die konsistensie tussen gebruikers se vraagte en die genereerde tydline te verseker. Die ander subvergelde funksies bydra tot onderwerp koherens en lingwisiese fluiditeit. Ons plan eksperimente om te evalueer of ons toegang kan spesifieke en presies tydline vir elke gebruiker genereer.</abstract_af>
      <abstract_tr>Zaman hatlary Toplaýyşy Ýöne häzirki sistemler täze sahypa üýtgetmek üçin ýeterli ýoly saýlamaýarlar, we munyň wajyp ullanyşyň nähili gyzyklanmagyny üçin üns bermeýärler. Şol sebäpli, abstraktiwny TLS öwrenmegi üçin bir täze teklip edip görýäris. Biz birleşik täsirli fonksiýany tanyşdyrýarys we soňra bir çoklu-sened jemgyýeti düzenlemek üçin RL'i ulanýarys we bu şekilde çykyş sumlaryny ulanmakdan uzaklaşdyrylýar. Ullançylaryň talaplarynyň we üretilen wagtlyk hatlaryň barlygyny garaşdyrmak üçin alt-täsirli fonksiýalarynyň biri aktiw olara öwrenip biler. Başga üýtgetmeli işlemler meýdança bir ýerleşmeligine we dil ýerleşmeligine kömekleýär. Biz özümiziň ýaryşymyzyň dogry we dogry zamanlyk çykarylyklaryň her Ulaşçy üçin üýtgedilýändigini çözmek üçin deneyleri planlaýarys.</abstract_tr>
      <abstract_hy>Ժամանակի համառոտագրությունը (TLS) նպատակով է ստեղծել համընդհանուր, ժամանակի համակարգված ցուցակ իրադարձությունների, որոնք նկարագրվում են այնպիսի աղբյուրներում, ինչպիսիք են նորությունների հոդվածները: Այնուամենայնիվ, ներկայիս համակարգերը բավարար միջոց չեն տրամադրում նոր ոլորտներին հարմարվելու կամ կենտրոնանալ որոշակի օգտագործողի հետաքրքրության ասպեկտների վրա: Այդ պատճառով, մենք առաջարկում ենք ինտերակտիվ ուսումնասիրելու աբստրակտիվ ԹԼՍ-ը օգտագործելով ուժեղացման ուսումնասիրությունը (ՌԼ): Մենք սահմանում ենք համադրված վարձի ֆունկցիան և օգտագործում ենք RL-ը վերաստեղծելու համար բազմաթիվ փաստաթղթերի համառոտագրման (MDS) մոդելը, որը խուսափում է հարցումների համառոտագրման կարիքից: Օգտագործողների արձագանքներից մեկը ինտերակտիվ կսովորվի օգտագործողների պահանջների և ստեղծված ժամանակային գծերի միջև հատուկ լինելու համար: Մյուս ենթավարձի ֆունկցիաները ներդրում են թեմական համապատասխանությունը և լեզվաբանական ճկունությունը: Մենք փորձեր ենք պլանավորում, որպեսզի գնահատենք, արդյոք մեր մոտեցումը կարող է ստեղծել ճշգրիտ և ճշգրիտ ժամանակահատվածներ, որոնք պատրաստված են յուրաքանչյուր օգտագործողի համար:</abstract_hy>
      <abstract_sq>Përshkrimi i afatit të kohës (TLS) synon të gjenerojë një list ë të shkurtër dhe të caktuar me kohë të ngjarjeve të përshkruara në burime të tilla si artikujt e lajmeve. Megjithatë, sistemet aktuale nuk ofrojnë një mënyrë të përshtatshme për t'u përshtatur në fusha të reja dhe as për t'u përqëndruar në aspektet e interesit për një përdorues të veçantë. Prandaj, ne propozojmë një metodë për të mësuar interaktivisht TLS abstraktiv duke përdorur Mësimin e Përforcimit (RL). Ne përcaktojmë një funksion shpërblimi të përbashkët dhe përdorim RL për të përshtatur një model abstraktiv të Summarization Multi-Document (MDS), i cili shmanget nevojës për trajnimin duke përdorur përmbledhjet e referimit. Një nga funksionet e nënshpërblimit do të mësohet interaktivisht nga përgjigjet e përdoruesve për të siguruar konsistencën midis kërkesave e përdoruesve dhe vijës kohore të gjeneruar. Funksionet e tjera të nënshpërblimit kontribuojnë për koherencën aktuale dhe fluencën gjuhësore. Ne planifikojmë eksperimente për të vlerësuar nëse qasja jonë mund të gjenerojë vija kohore të sakta dhe të sakta të përshtatshme për çdo përdorues.</abstract_sq>
      <abstract_az>Zaman səhifəsi Toplaşdırma (TLS) haqqı məktublar kimi məktublar içində tanımlanmış vaxt sıralanmış vaxt listesini yaratmaq istəyir. Halbuki, a ğımdaki sistemlər yeni domenalara uyğunlaşdırmaq üçün yeterli bir yol verməz və ya müəyyən istifadəçilərə maraqlıq aspektlərinə odaqlanmaq üçün. Buna görə də bizim abstraktiv TLS öyrənmək üçün bir metod təklif edirik. Biz birləşdirilmiş mükafat funksiyasını təyin edirik və RL'i abstraktiv Multi-document Summarisation (MDS) modelini təyin etmək üçün istifadə edirik ki, bu dəyişiklik toplamlarını istifadə etməyə ehtiyacı yoxdur. Üstödüllü funksiyalardan biri istifadəçilərin istəkləri və ürəklənmiş vaxt səhifəsi arasında müəyyən edilməsini təsdiqləmək üçün istifadəçilərin reaksiyasından interaktif olaraq öyrənəcəkdir. Diğer dəyişiklik funksiyaları məsələlərin birləşməsinə və dillərin fəaliyyətinə kömək edir. Biz təcrübələrimizin hər istifadəçi üçün müəyyən edilmiş və müəyyən edilmiş vaxt səhifələrini təşkil etmək üçün təcrübələrimizi təşkil edirik.</abstract_az>
      <abstract_bn>টাইমেলিন সামার্মিস (টিএলএস) এর লক্ষ্য হচ্ছে সংবাদ প্রবন্ধের মতো সংবাদ প্রবন্ধের মতো বর্ণনা করা হয়েছে একটি সূত্র, সময়-নির্দেশি তবে বর্তমান সিস্টেম নতুন ডোমেইনের সাথে মেনে নেওয়ার জন্য যথেষ্ট উপায় প্রদান করে না এবং কোন বিশেষ ব্যবহারকারীর প্রতি আগ্রহের প্রত তাই আমরা প্রস্তাব করি একটি উপায় যাতে প্রতিষ্ঠান শিক্ষা ব্যবহার করে অস্বাভাবিক টিএলএস শিখতে পারি। আমরা একটি কম্পোনেন্ড পুরস্কারের ফাংশন নির্ধারণ করি এবং RL ব্যবহার করি একটি অস্বাভাবিক মাল্টিক ডকুমেন্ট সামার্সিং মডেল (এমডিএস), যা রেফারেন্স সারিম ব্যবহারকারীদের দাবি এবং উৎপাদন করা সময় লাইনের মধ্যে সাবপুরস্কারের একটি ফাংশন সক্রিয় করে ব্যবহারকারীর ফিডব্যাক থেকে শিখা হবে। অন্যান্য সাব-পুরস্কারের ফাংশন বিষয়বস্তুর সাথে এবং ভাষার ভাষার প্রভাবে অবদান করে। আমরা পরীক্ষার পরীক্ষার পরিকল্পনা করছি যাতে আমাদের প্রতিটি ব্যবহারকারীর জন্য সঠিক এবং পরিমাপের সময় লাইন তৈরি করা যায় কিনা।</abstract_bn>
      <abstract_ca>El resum del calendari (TLS) té l'objectiu de generar una llista concisa i ordenada del temps d'esdeveniments descrits en fonts com els articles de notícies. No obstant això, els sistemes actuals no proporcionen una manera adequada d'adaptar-se a nous dominis ni centrar-se en els aspectes d'interès d'un usuari particular. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL).  Defineixem una funció de recompensa compuesta i utilitzem RL per ajustar un model abstracte de Resume Multidocumental (MDS), que evita la necessitat d'entrenar fent servir resumes de referència. Una de les funcions de subrecompensa es aprendrà interactivament a partir del feedback dels usuaris per assegurar la consistencia entre les exigències dels usuaris i la línia de temps generada. Les altres funcions de subrecompensa contribueixen a la coherencia topical i la fluència lingüística. Planem experiments per avaluar si el nostre enfocament podria generar línies de temps exactes i precisas adaptades a cada usuari.</abstract_ca>
      <abstract_cs>Shrnutí časové osy (TLS) si klade za cíl vytvořit stručný, časově uspořádaný seznam událostí popsaných ve zdrojích, jako jsou například zpravodajské články. Stávající systémy však neposkytují adekvátní způsob, jak se přizpůsobit novým doménám ani jak se zaměřit na aspekty zájmu konkrétního uživatele. Proto navrhujeme metodu interaktivního učení abstraktivního TLS pomocí Reinforcement Learning (RL). Definujeme složenou funkci odměny a používáme RL k jemnému ladění abstraktivního MDS modelu (Multi-Document Sumlarisation), který se vyhýbá nutnosti trénovat pomocí referenčních souhrnů. Jedna z funkcí sub-odměny se interaktivně naučí ze zpětné vazby uživatelů, aby byla zajištěna konzistence mezi požadavky uživatelů a generovanou časovou osou. Další funkce pododměny přispívají k aktuální soudržnosti a jazykové plynulosti. Plánujeme experimenty, abychom vyhodnotili, zda by náš přístup mohl generovat přesné a přesné časové osy přizpůsobené každému uživateli.</abstract_cs>
      <abstract_et>Timeline Summarisation (TLS) eesmärk on luua lühike ja ajaliselt järjestatud nimekiri sündmustest, mida kirjeldatakse allikates, näiteks uudisteartiklites. Praegused süsteemid ei paku siiski piisavat võimalust kohaneda uute valdkondadega ega keskenduda konkreetsele kasutajale huvi pakkuvatele aspektidele. Seetõttu pakume välja meetodi abstraktse TLS interaktiivseks õppimiseks tugevdusõppe abil. Määratleme komplektfunktsiooni ja kasutame RL-i abstraktse mitme dokumendi kokkuvõtte (MDS) mudeli täpsustamiseks, mis väldib vajadust treenida viitekokkuvõtete abil. Ühte allpreemiafunktsiooni õpitakse interaktiivselt kasutajate tagasisidest, et tagada kasutajate nõudmiste ja loodud ajakava vaheline sidusus. Teised allpreemiafunktsioonid aitavad kaasa aktuaalsele sidususele ja keelelisele sujuvusele. Kavandame katseid, et hinnata, kas meie lähenemisviis suudab luua täpseid ja täpseid ajajooni, mis on kohandatud iga kasutaja jaoks.</abstract_et>
      <abstract_bs>Vremenska sažetka (TLS) cilja je da stvori konkretnu, vremenski naređenu listu događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sistemi ne pružaju odgovarajući način da se prilagodi novim domenama niti da se fokusiraju na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju nagrade u kombinaciji i koristimo RL kako bi ispravili abstraktivni model rezervacije višestrukih dokumenta (MDS), koji izbjegava potrebu trenirati s referentnim sažetkama. Jedna od funkcija podnagrade bit će učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahtjeva korisnika i proizvedene vremenske linije. Druge podnagrade doprinose temeljnoj saskašnosti i jezičkoj tekućini. Planiramo eksperimente da procijenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije prilagođene svakom korisniku.</abstract_bs>
      <abstract_fi>Timeline Summarisation (TLS) tavoitteena on luoda tiivis, ajoitettu luettelo tapahtumista, joita kuvataan lähteissä, kuten uutisartikkeleissa. Nykyiset järjestelmät eivät kuitenkaan tarjoa riittävää tapaa sopeutua uusiin toimialoihin eivätkä keskittyä tiettyä käyttäjää kiinnostaviin näkökohtiin. Tämän vuoksi ehdotamme menetelmää abstraktisen TLS:n oppimiseen vuorovaikutteisesti käyttäen Reinforcement Learning (RL) -menetelmää. Määrittelemme yhdistelmäpalkitsemistoiminnon ja hienosäädämme RL:n avulla abstraktiivista Multi-document Summarisation (MDS) -mallia, jolloin ei tarvitse harjoitella viiteyhteenvedoilla. Yksi osapalkkiotoiminnoista opitaan vuorovaikutteisesti käyttäjien palautteesta, jotta varmistetaan käyttäjien vaatimusten ja luotujen aikajanojen välinen johdonmukaisuus. Muut palkitsemistoiminnot edistävät ajankohtaista johdonmukaisuutta ja kielellistä sujuvuutta. Suunnittelemme kokeiluja arvioidaksemme, voisiko lähestymistapamme tuottaa tarkkoja ja tarkkoja aikajanoja kullekin käyttäjälle.</abstract_fi>
      <abstract_jv>Ukuntaha Tarjamahan (TIL) kang disimpen nggawe sampek, aku-disimpen oleh dadi pawaran kanggo nggawe tarjamahan karo penjelongkapan kanggo Artis Perintah politenessoffpolite"), and when there is a change ("assertivepoliteness Kaya, kéné gunakake sistem kanggo nggambar aksi tarjamahan kanggo nggambar RL kuwi nggawe Rayforcement Learning (RL). Awakdhéwé Define 1 Omah sing mbubuti Layaran Pangan Sub-Rayakno sing mengko perusahaan nganggep bantuan kanggo sabên bakal terusahan karo pawaran ingkang. Awak dhéwé éntukno éntukang nggawe baléné, mengko iso nggawe layang kanggo ngono nggawe layang kanggo nggawe Perintah kanggo nguasai nggo sabên pengguna.</abstract_jv>
      <abstract_he>סדרת קו הזמן (TLS) מתכוונת ליצור רשימה קצרה ומסדרת בזמן של אירועים מתארות במקורים כמו מאמרים חדשות. בכל אופן, מערכות הנוכחיות לא מספקות דרך מתאימה להתאים לתחומים חדשים ולא להתמקד באינטרסים למשתמש מסוים. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL).  אנחנו מגדירים פונקציה של פרס מורכב ושימושים RL כדי לתקן מודל מסמכים רבים אסטרקטיבי (MDS), שממנע את הצורך לאימון באמצעות סדרות התייחסות. אחת התפקידים של הפרס התחתון תלמד באופן אינטראקטיבי ממחזור המשתמש כדי להבטיח את התקבילות בין הדרישות של המשתמשים לקו הזמן הנוצר. התפקידים האחרים של הפרס התחתון תורמים לקשורות נופעית ושלווה שפתית. אנחנו מתכננים ניסויים כדי להעריך אם הגישה שלנו יכולה ליצור קווי זמנים מדויקים ודויקים מתאימים לכל משתמש.</abstract_he>
      <abstract_sk>Cilj povzetka časovne linije (TLS) je ustvariti jedrnat, časovno urejen seznam dogodkov, opisanih v virih, kot so novinarski članki. Vendar sedanji sistemi ne zagotavljajo ustreznega načina prilagajanja novim področjem niti osredotočanja na vidike, ki zanimajo določenega uporabnika. Zato predlagamo metodo interaktivnega učenja abstraktivnega TLS z uporabo ojačevalnega učenja (RL). Določimo sestavljeno funkcijo nagrajevanja in uporabljamo RL za natančno nastavitev abstraktivnega modela večdokumentnega povzetka (MDS), s čimer se izognemo treningu z uporabo referenčnih povzetkov. Ena od funkcij podnagrade se bo interaktivno naučila iz povratnih informacij uporabnikov, da se zagotovi skladnost med zahtevami uporabnikov in ustvarjenim časovnim okvirom. Druge funkcije podnagrade prispevajo k aktualni skladnosti in jezikovni tekočosti. Načrtujemo poskuse, s katerimi ocenimo, ali lahko naš pristop ustvari natančne in natančne časovne linije, prilagojene vsakemu uporabniku.</abstract_sk>
      <abstract_bo>དུས་ཡོད་པའི་ཆ་འཕྲིན་འབྲེལ་བ(TLS)ལ་དམིགས་ཡུལ་ནི་འབྱུང་ཁུངས་ནང་གསལ་བཤད་ཀྱི་དུས་ཚོད་ལྟར་བཤད་ཀྱི་ཐོ་ཡིག་སྐྱེལ་བ ཡིན་ནའང་ད་ལྟོའི་མ་ལག་གི་སྤྱོད་མཁན་པ་ཞིག་ལས་དུས་ཡོད་པའི་འཆར་གཞུང་གིས་དུས་མཐུན་གྱི་ཐབས་ལམ་ལ་དང་མཐུན་སྒྲིག དེར་བརྟེན། ང་ཚོས་རྗེས་སུ་འབྱུང་བའི་TLS ལ་ལམ་ལུགས་གཅིག་གི་སྤྲོད་བྱེད་ཀྱི་ཡོད། We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. Name Sub-reward ལས་ཕན་འབྲས་ཀྱི་ལས་ཀ་གཅིག་ནི་སྤྱོད་མཁན་གྱི་ངོས་ལངས་ཀྱི་ནང་དུ་སྤྱིར་བཏང་བ་དང་གསར་བསྐྲུན་ཡོད་པའི་དུས Sub-reward་གཞན་པ་འདིས་གནད་དོན་དག་གི་མཉམ་སྦྲགས་དང་སྐད་རིགས་ཀྱི་མཚུངས་སྐོར་དང་། ང་ཚོས་ལག་ལེན་པ་རེ་རེ་བ་མི་དང་འགྲོ་བརྟན་པར་མཐུན་འགྲོ་བ་ཡིན་མིན་ན།</abstract_bo>
      <abstract_ha>@ action: button A lokacin da, na'urar da ake kai yanzu ba za'a ƙudura hanya mai daidai wa da za'a haɗi koda, kuma bã ya zura ido kan masu da amfani da wani mai ƙayyade. Saboda haka, Munã buɗa wata usur da za'a sanar da mutane ta kanrakati TLS da amfani da Shirin LUTI (RL). Mu ƙayyade wani aikin ijãrar da aka ƙunsa da kuma Mu yi amfani da RL zuwa a gyare-tun wata misali na takardar mulki-dokuman aiki (MDS), wanda ya ƙẽtare umarni da ke amfani da fassarar tsari. Babu wani abu na ƙara-sakamakon za'a sanar da shi farat ɗaya daga baka mai amfani da mai amfani da, dõmin ya yi yaƙĩni da wata daidaita tsakanin tambayar mai amfani da kuma tare da aka ƙãga wani lokaci. Suna da wasu functionin sub-ijãra yana ƙara wa fassarar samuraci da linguistic. We plan experiments to evaluate whether our approach could generate accurate and precise timelines tailored for each user.</abstract_ha>
      </paper>
    <paper id="5">
      <title>Dynamic Facet Selection by Maximizing Graded Relevance</title>
      <author><first>Michael</first><last>Glass</last></author>
      <author><first>Md Faisal Mahbub</first><last>Chowdhury</last></author>
      <author><first>Yu</first><last>Deng</last></author>
      <author><first>Ruchi</first><last>Mahindru</last></author>
      <author><first>Nicolas Rodolfo</first><last>Fauceglia</last></author>
      <author><first>Alfio</first><last>Gliozzo</last></author>
      <author><first>Nandana</first><last>Mihindukulasooriya</last></author>
      <pages>32–39</pages>
      <abstract>Dynamic faceted search (DFS), an interactive query refinement technique, is a form of Humancomputer information retrieval (HCIR) approach. It allows users to narrow down search results through facets, where the facets-documents mapping is determined at runtime based on the context of user query instead of pre-indexing the facets statically. In this paper, we propose a new unsupervised approach for dynamic facet generation, namely optimistic facets, which attempts to generate the best possible subset of facets, hence maximizing expected Discounted Cumulative Gain (DCG), a measure of ranking quality that uses a graded relevance scale. We also release code to generate a new evaluation dataset. Through empirical results on two datasets, we show that the proposed DFS approach considerably improves the document ranking in the search results.</abstract>
      <url hash="8c786b65">2021.internlp-1.5</url>
      <doi>10.18653/v1/2021.internlp-1.5</doi>
      <bibkey>glass-etal-2021-dynamic</bibkey>
      <pwccode url="https://github.com/ibm/stackoverflow-technotes-dataset" additional="false">ibm/stackoverflow-technotes-dataset</pwccode>
    </paper>
    <paper id="6">
      <title>Active Curriculum Learning</title>
      <author><first>Borna</first><last>Jafarpour</last></author>
      <author><first>Dawn</first><last>Sepehr</last></author>
      <author><first>Nick</first><last>Pogrebnyakov</last></author>
      <pages>40–45</pages>
      <abstract>This paper investigates and reveals the relationship between two closely related machine learning disciplines, namely Active Learning (AL) and Curriculum Learning (CL), from the lens of several novel <a href="https://en.wikipedia.org/wiki/Curriculum">curricula</a>. This paper also introduces Active Curriculum Learning (ACL) which improves AL by combining AL with CL to benefit from the dynamic nature of the AL informativeness concept as well as the human insights used in the design of the curriculum heuristics. Comparison of the performance of ACL and AL on two public datasets for the Named Entity Recognition (NER) task shows the effectiveness of combining AL and CL using our proposed framework.</abstract>
      <url hash="f1741a5b">2021.internlp-1.6</url>
      <doi>10.18653/v1/2021.internlp-1.6</doi>
      <bibkey>jafarpour-etal-2021-active</bibkey>
    </paper>
    <paper id="7">
      <title>Tackling Fake News Detection by Interactively Learning Representations using Graph Neural Networks</title>
      <author><first>Nikhil</first><last>Mehta</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>46–53</pages>
      <abstract>Easy access, variety of content, and fast widespread interactions are some of the reasons that have made <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> increasingly popular in today’s society. However, this has also enabled the widespread propagation of fake news, text that is published with an intent to spread <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> and sway beliefs. Detecting fake news is important to prevent <a href="https://en.wikipedia.org/wiki/Misinformation">misinformation</a> and maintain a healthy society. While prior works have tackled this problem by building <a href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning systems</a>, automatedly modeling the social media landscape that enables the spread of <a href="https://en.wikipedia.org/wiki/Fake_news">fake news</a> is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.<i>interactively</i>, where human insight can be continually combined with an automated system, enabling better social media representation quality. Our experiments show performance improvements in this setting.</abstract>
      <url hash="d1fc0b98">2021.internlp-1.7</url>
      <doi>10.18653/v1/2021.internlp-1.7</doi>
      <bibkey>mehta-goldwasser-2021-tackling</bibkey>
    </paper>
  </volume>
</collection>