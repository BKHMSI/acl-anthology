<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.vardial">
  <volume id="1" ingest-date="2021-04-19">
    <meta>
      <booktitle>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</booktitle>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Nikola</first><last>Ljubešić</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Yves</first><last>Scherrer</last></editor>
      <editor><first>Tommi</first><last>Jauhiainen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Kiyv, Ukraine</address>
      <month>April</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="5dcc52a6">2021.vardial-1.0</url>
      <bibkey>vardial-2021-nlp</bibkey>
    </frontmatter>
    <paper id="2">
      <title>Hierarchical Transformer for Multilingual Machine Translation</title>
      <author><first>Albina</first><last>Khusainova</last></author>
      <author><first>Adil</first><last>Khan</last></author>
      <author><first>Adín Ramírez</first><last>Rivera</last></author>
      <author><first>Vitaly</first><last>Romanov</last></author>
      <pages>12–20</pages>
      <abstract>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally <a href="https://en.wikipedia.org/wiki/Parameter_space">parameter space</a> is used and hence, directly influences ultimate translation quality. Inspired by <a href="https://en.wikipedia.org/wiki/Tree_(graph_theory)">linguistic trees</a> that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. The main idea is to use these expert language hierarchies as a basis for multilingual architecture : the closer two languages are, the more parameters they share. In this work, we test this idea using the Transformer architecture and show that despite the success in previous work there are problems inherent to training such hierarchical models. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</abstract>
      <url hash="9548e505">2021.vardial-1.2</url>
      <bibkey>khusainova-etal-2021-hierarchical</bibkey>
    <title_ar>محول هرمي للترجمة الآلية متعددة اللغات</title_ar>
      <title_es>Transformador jerárquico para traducción automática multilingüe</title_es>
      <title_pt>Transformador hierárquico para tradução automática multilíngue</title_pt>
      <title_zh>多言机器翻译者转换器</title_zh>
      <title_ja>多言語機械翻訳のための階層トランスフォーマー</title_ja>
      <title_hi>बहुभाषी मशीन अनुवाद के लिए पदानुक्रमित ट्रांसफार्मर</title_hi>
      <title_ga>Claochladán Ordlathach le haghaidh Aistriúchán Meaisín Ilteangach</title_ga>
      <title_el>Ιεραρχικός μετασχηματιστής για πολυγλωσσική μηχανική μετάφραση</title_el>
      <title_hu>Hierarchikus transzformátor a többnyelvű gépi fordításhoz</title_hu>
      <title_ka>Name</title_ka>
      <title_lt>Hierarchinis daugiakalbio mašinų vertimo transformatorius</title_lt>
      <title_kk>Көп тілдік машинаны аудару үшін хиерархикалық түрлендірушіName</title_kk>
      <title_it>Trasformatore gerarchico per traduzione automatica multilingue</title_it>
      <title_ms>Penukar Hierarkik untuk Penerjemahan Mesin Berbahasa</title_ms>
      <title_mt>Trasferiment Erarkiku għat-Traduzzjoni Multilingwi tal-Magni</title_mt>
      <title_mk>Hierarchical Transformer for Multilingual Machine Translation</title_mk>
      <title_no>Hierarisk transformer for fleirspråk maskinsomsetjing</title_no>
      <title_ml>Multilingual Mashine Translation</title_ml>
      <title_mn>Ихэнх хэлний машин орчуулахын тулд гиерархик шилжүүлэгч</title_mn>
      <title_pl>Transformator hierarchiczny do wielojęzycznego tłumaczenia maszynowego</title_pl>
      <title_ro>Transformator ierarhic pentru traducere automată multilingvă</title_ro>
      <title_sr>Hijerarhički transformator za multijezički prevod mašine</title_sr>
      <title_si>ගොඩක් භාෂාවක් මැෂින් පරිවර්තනය වෙනුවෙන් හියාර්චිකල් ප්‍රවර්තනය</title_si>
      <title_ta>பல்மொழி இயந்திரத்திற்கான மொழிமாற்றியமைப்பு</title_ta>
      <title_so>Turjumista hierarchical for multiluqado badan</title_so>
      <title_ur>Multilingual Machine Translation for Hierarchical Transformer</title_ur>
      <title_sv>Hierarkisk transformator för flerspråkig maskinöversättning</title_sv>
      <title_vi>KCharselect unicode block name</title_vi>
      <title_uz>Name</title_uz>
      <title_bg>Йерархичен трансформатор за многоезичен машинен превод</title_bg>
      <title_nl>Hiërarchische transformator voor meertalige machinevertaling</title_nl>
      <title_da>Hierarkisk transformator til flersproget maskinoversættelse</title_da>
      <title_hr>Hierarični transformator za multijezički prevod strojeva</title_hr>
      <title_de>Hierarchischer Transformator für mehrsprachige maschinelle Übersetzung</title_de>
      <title_ko>다국어 기계 번역에 사용되는 차원 변환기</title_ko>
      <title_tr>Çoklu dilli maşynyň terjimesine üçin iýerarhiýal terjimeçi</title_tr>
      <title_fa>Name</title_fa>
      <title_id>Transformer Hierarkis untuk Translation Multilingual Machine</title_id>
      <title_af>Hierariese Transformeerder vir Veelvuldige Masjien Vertaling</title_af>
      <title_sw>Tafsiri ya Kiingereza kwa Tafsiri ya Mashine ya Kilugha</title_sw>
      <title_am>ትርጉም</title_am>
      <title_az>Çoxlu dilli Makin Çeviri üçün hiyerarşik transformatörü</title_az>
      <title_bs>Hijerarhički transformator za multijezički prevod mašine</title_bs>
      <title_sq>Hierarchical Transformer for Multilingual Machine Translation</title_sq>
      <title_bn>বহুভাষী মেশিন অনুবাদের জন্য হিরেরাক্কিল ট্রান্সফার্নার</title_bn>
      <title_hy>Բազլեզու մեքենայի թարգմանման գերախիկ վերածիչը</title_hy>
      <title_ca>Transformador Hierarquic per traducció multilingüe de màquines</title_ca>
      <title_fi>Hierarkkinen muuntaja monikieliseen konekäännökseen</title_fi>
      <title_cs>Hierarchický transformátor pro vícejazyčný strojový překlad</title_cs>
      <title_et>Hierarhiline muundur mitmekeelse masintõlke jaoks</title_et>
      <title_ha>@ item Text character set</title_ha>
      <title_sk>Hierarhični transformator za večjezični strojni prevod</title_sk>
      <title_he>התמרת הייררכית לתרגום מכונות רבות שפתיים</title_he>
      <title_jv>Piranti Pilihan Transformer kanggo Terjamahan Karo Multilanggar</title_jv>
      <title_bo>སྐད་རིགས་འདྲ་མིའི་ནང་གི་སྒྲིག་དབྱིབས་བསྒྱུར་བཅོས་བྱེད་པ</title_bo>
      <abstract_es>La elección de la estrategia de uso compartido de parámetros en los modelos de traducción automática multilingüe determina el uso óptimo del espacio de parámetros y, por lo tanto, influye directamente en la calidad de la traducción Inspirado en los árboles lingüísticos que muestran el grado de relación entre los diferentes idiomas, recientemente se sugirió el nuevo enfoque general para compartir parámetros en la traducción automática multilingüe. La idea principal es utilizar estas jerarquías lingüísticas expertas como base para una arquitectura multilingüe: cuanto más cerca estén dos idiomas, más parámetros comparten. En este trabajo, probamos esta idea utilizando la arquitectura Transformer y demostramos que, a pesar del éxito obtenido en trabajos anteriores, existen problemas inherentes al entrenamiento de tales modelos jerárquicos. Demostramos que, en el caso de una estrategia de capacitación cuidadosamente elegida, la arquitectura jerárquica puede superar a los modelos bilingües y multilingües con un intercambio completo de parámetros.</abstract_es>
      <abstract_ar>يحدد اختيار استراتيجية مشاركة المعلمات في نماذج الترجمة الآلية متعددة اللغات كيفية استخدام مساحة المعلمة على النحو الأمثل ، وبالتالي ، يؤثر بشكل مباشر على جودة الترجمة النهائية. مستوحى من الأشجار اللغوية التي تظهر درجة الارتباط بين اللغات المختلفة ، تم اقتراح النهج العام الجديد لمشاركة المعلمات في الترجمة الآلية متعددة اللغات مؤخرًا. الفكرة الرئيسية هي استخدام هذه التسلسلات الهرمية اللغوية المتخصصة كأساس للعمارة متعددة اللغات: كلما اقتربت لغتان ، زاد عدد المعلمات المشتركة بينهما. في هذا العمل ، نختبر هذه الفكرة باستخدام بنية Transformer ونوضح أنه على الرغم من النجاح في العمل السابق ، هناك مشاكل متأصلة في تدريب مثل هذه النماذج الهرمية. نوضح أنه في حالة استراتيجية التدريب المختارة بعناية ، يمكن للهندسة الهرمية أن تتفوق على النماذج ثنائية اللغة والنماذج متعددة اللغات مع مشاركة كاملة للمعلمات.</abstract_ar>
      <abstract_ja>多言語機械翻訳モデルにおけるパラメータ共有戦略の選択は、パラメータ空間がどのように最適に使用されるかを決定し、したがって、究極の翻訳品質に直接影響を与えます。異なる言語間の関連性の程度を示す言語ツリーに触発されて、多言語機械翻訳におけるパラメータ共有の新しい一般的なアプローチが最近提案された。主なアイデアは、これらのエキスパート言語の階層を多言語アーキテクチャの基礎として使用することです。2つの言語が近いほど、パラメータがより共有されます。この作業では、トランスフォーマーのアーキテクチャを使用してこのアイデアをテストし、以前の作業で成功したにもかかわらず、そのような階層モデルをトレーニングするには固有の問題があることを示します。慎重に選択されたトレーニング戦略の場合、階層的アーキテクチャは、完全なパラメータ共有でバイリンガルモデルや多言語モデルを上回ることができることを実証します。</abstract_ja>
      <abstract_pt>A escolha da estratégia de compartilhamento de parâmetros em modelos de tradução automática multilíngue determina como o espaço de parâmetros é usado de maneira ideal e, portanto, influencia diretamente a qualidade final da tradução. Inspirada em árvores linguísticas que mostram o grau de parentesco entre diferentes idiomas, a nova abordagem geral para compartilhamento de parâmetros na tradução automática multilíngue foi sugerida recentemente. A ideia principal é usar essas hierarquias de linguagens especializadas como base para a arquitetura multilíngue: quanto mais próximas duas linguagens estiverem, mais parâmetros eles compartilham. Neste trabalho, testamos essa ideia usando a arquitetura Transformer e mostramos que apesar do sucesso em trabalhos anteriores existem problemas inerentes ao treinamento de tais modelos hierárquicos. Demonstramos que, no caso de uma estratégia de treinamento cuidadosamente escolhida, a arquitetura hierárquica pode superar modelos bilíngues e modelos multilíngues com compartilhamento completo de parâmetros.</abstract_pt>
      <abstract_zh>多言机器翻译模形参数共策定参数空中最佳,直染终译。 受示异语言树之启,近多言机器翻译中参数共享新通用之法。 凡心用其言层次结构以为多言架构基:两言愈近,其参数愈多。 以此观之,Transformer架构试之,明虽成功于前,而练之以固也。 吾证精择训练之策,架构胜双语模形与全参数共多言模。</abstract_zh>
      <abstract_hi>बहुभाषी मशीन अनुवाद मॉडल में पैरामीटर साझा करण रणनीति का विकल्प यह निर्धारित करता है कि पैरामीटर स्थान का उपयोग कैसे किया जाता है और इसलिए, सीधे अंतिम अनुवाद गुणवत्ता को प्रभावित करता है। भाषाई पेड़ों से प्रेरित होकर जो विभिन्न भाषाओं के बीच संबंधितता की डिग्री दिखाते हैं, बहुभाषी मशीन अनुवाद में पैरामीटर साझा करने के लिए नए सामान्य दृष्टिकोण का सुझाव हाल ही में दिया गया था। मुख्य विचार बहुभाषी वास्तुकला के लिए एक आधार के रूप में इन विशेषज्ञ भाषा पदानुक्रमों का उपयोग करना है: दो भाषाएं जितनी करीब होंगी, वे उतने ही अधिक पैरामीटर साझा करते हैं। इस काम में, हम ट्रांसफॉर्मर आर्किटेक्चर का उपयोग करके इस विचार का परीक्षण करते हैं और दिखाते हैं कि पिछले काम में सफलता के बावजूद ऐसे पदानुक्रमित मॉडल को प्रशिक्षित करने के लिए अंतर्निहित समस्याएं हैं। हम प्रदर्शित करते हैं कि सावधानीपूर्वक चुनी गई प्रशिक्षण रणनीति के मामले में पदानुक्रमित वास्तुकला पूर्ण पैरामीटर साझाकरण के साथ द्विभाषी मॉडल और बहुभाषी मॉडल को मात दे सकती है।</abstract_hi>
      <abstract_ga>Cinneann rogha na straitéise comhroinnte paraiméadar i múnlaí aistriúcháin meaisín ilteangacha cé chomh optamach a úsáidtear spás paraiméadar agus mar sin bíonn tionchar díreach aige ar cháilíocht an aistriúcháin deiridh. Arna spreagadh ag crainn theangeolaíocha a thaispeánann an ghaolmhaireacht atá idir teangacha éagsúla, moladh le déanaí an cur chuige ginearálta nua maidir le paraiméadar a chomhroinnt san aistriúchán meaisín ilteangach. Is é an príomh-smaoineamh ná úsáid a bhaint as na sainordlathas teanga seo mar bhunús don ailtireacht ilteangach: dá gaire an dá theanga is ea is mó paraiméadair a roinneann siad. San obair seo, déanaimid tástáil ar an smaoineamh seo ag baint úsáide as ailtireacht an Trasfhoirmeora agus taispeánann sé go bhfuil fadhbanna bunúsacha ag baint le hoiliúint a chur ar mhúnlaí ordlathacha den sórt sin in ainneoin an rath a bhí ar obair roimhe seo. Léirímid, i gcás straitéise oiliúna a roghnaítear go cúramach, gur féidir leis an ailtireacht ordlathach sárobair a dhéanamh ar mhúnlaí dátheangacha agus ar mhúnlaí ilteangacha le comhroinnt iomlán na bparaiméadar.</abstract_ga>
      <abstract_hu>A többnyelvű gépi fordítási modellek paramétermegosztási stratégiájának megválasztása határozza meg, hogy a paraméterek optimális felhasználását hogyan használják, és így közvetlenül befolyásolja a végső fordítási minőséget. A különböző nyelvek közötti kapcsolat mértékét mutató nyelvi fák inspirálták a közelmúltban a többnyelvű gépi fordítás paramétereinek megosztására vonatkozó új általános megközelítést javasolták. A fő ötlet az, hogy ezeket a szakértői nyelvi hierarchiákat használjuk a többnyelvű architektúra alapjaként: minél közelebb van a két nyelv, annál több paramétert osztanak meg. Ebben a munkában ezt az ötletet a Transformer architektúrával teszteljük, és megmutatjuk, hogy a korábbi munkák sikere ellenére az ilyen hierarchikus modellek képzésének problémái vannak. Bemutatjuk, hogy gondosan megválasztott képzési stratégia esetén a hierarchikus architektúra teljes paraméterek megosztásával felülmúlhatja a kétnyelvű modelleket és a többnyelvű modelleket.</abstract_hu>
      <abstract_el>Η επιλογή της στρατηγικής κοινής χρήσης παραμέτρων σε πολυγλωσσικά μοντέλα μηχανικής μετάφρασης καθορίζει τον βέλτιστο τρόπο χρήσης του χώρου παραμέτρων και ως εκ τούτου επηρεάζει άμεσα την τελική ποιότητα μετάφρασης. Εμπνευσμένη από γλωσσικά δέντρα που δείχνουν τον βαθμό συσχέτισης μεταξύ διαφορετικών γλωσσών, προτείνεται πρόσφατα η νέα γενική προσέγγιση για την κοινή χρήση παραμέτρων στην πολυγλωσσική μηχανική μετάφραση. Η κύρια ιδέα είναι να χρησιμοποιηθούν αυτές οι εξειδικευμένες γλωσσικές ιεραρχίες ως βάση για την πολυγλωσσική αρχιτεκτονική: όσο πιο κοντά είναι οι δύο γλώσσες, τόσο περισσότερες παράμετροι μοιράζονται. Σε αυτή την εργασία, δοκιμάζουμε αυτή την ιδέα χρησιμοποιώντας την αρχιτεκτονική και δείχνουν ότι παρά την επιτυχία σε προηγούμενες εργασίες υπάρχουν προβλήματα εγγενή στην εκπαίδευση τέτοιων ιεραρχικών μοντέλων. Αποδεικνύουμε ότι σε περίπτωση προσεκτικά επιλεγμένης στρατηγικής εκπαίδευσης η ιεραρχική αρχιτεκτονική μπορεί να ξεπεράσει τα δίγλωσσα μοντέλα και τα πολύγλωσσα μοντέλα με πλήρη κοινή χρήση παραμέτρων.</abstract_el>
      <abstract_ka>პარამეტრის გაყოფილი სტრატიგიის არჩევა მრავალენგური მანქანის გაგრძელების მოდელში განსაზღვრავს თუ როგორ ოპრამეტრის სივრცე გამოიყენება და ამიტომ, Direktively გამოიყენ ლენგურისტიკური ხეები, რომლებიც განსხვავებული ენების განმავლობაში დაკავშირებულების დონე, ახალი საერთო პროგრამის გაყოფილი პარამეტრების განმავლობაში მრავალენგური მაქინის განმავლ მნიშვნელოვანი იდეა, რომ ამ ექსპერტის ენის ჰიერაქტის გამოყენება მნიშვნელოვანი აქტიქტიქტიკის ბაზი: ორი ენები უფრო კიდევ, რაც უფრო მეტი პარამეტრები იყო ამ სამუშაოში, ჩვენ შევცვალოთ ეს იდეა ტრანფორმეტრის აქტიქტიქტურის გამოყენებით და ჩვენ ჩვენებთ, რომ წინა სამუშაო სამუშაო მუშაოდ არსებობს პრობლემები ჩვენ ევმონსტრაცით, რომ აღმოჩნეთ სტრატიფიკალური სტრატიფიკალური სტრატიქტიკალური მოდელები და მრავალენგური მოდელები შეუძლიათ გავაკეთოთ სრულ პარამეტრის გაყო</abstract_ka>
      <abstract_kk>Көптеген тілдік ортақтастыру стратегиясын бірнеше тілдік компьютер аудару үлгілерінде параметрлерді ортақтастыру стратегиясының таңдауы керек параметрлердің ортасын қалай қолданылатын аны Басқа тілдер арасындағы лингвистикалық ағаштардың қатынасын көрсетеді. Жаңа параметрлерді бірнеше тілдер аудармасында ортақтастыру үшін жаңа жалпы қатынасы жуырда ұсынылды. Негізгі идея - бұл эксперт тіл иерархиясын көптілік архитектурасының негізінде қолдану: екі тіл жақын, олардың ортақ параметрлері көп. Бұл жұмыс ішінде, біз бұл идеяны түрлендіруші архитектурасын қолданып, алдыңғы жұмыстың сәттілігіне қарамастан, бұл иерархиялық моделдерді оқыту үшін мәселелер бар. Біз тәжірибе таңдалған оқыту стратегиясы болса, иерархиялық архитектура екі тіл үлгілерін және көп тіл үлгілерін толық параметрлерді ортақтастыруға болады.</abstract_kk>
      <abstract_lt>Pasirinkus parametrų pasidalijimo strategiją daugiakalbėse mašin ų vertimo modeliuose nustatoma, kaip optimaliai naudojama parametrų erdvė, taigi tiesiogiai daroma įtaka galutinei vertimo kokybei. Neseniai pasiūlytas naujas bendras požiūris į dalijimąsi parametrais daugiakalbio vertimo mašinomis metodu, įkvėptas kalbiniais medžiais, kurie rodo skirtingų kalbų ryšį. Pagrindinė idėja – naudoti šias ekspertų kalbų hierarchijas kaip daugiakalbės architektūros pagrindą: kuo artimesnės dvi kalbos, tuo daugiau parametrų jos dalijasi. Šiame darbe išbandome šią idėją naudojant Transformer architektūrą ir parodysime, kad nepaisant ankstesnio darbo sėkmės kyla problemų, susijusių su tokių hierarchinių modelių mokymu. Mes įrodome, kad kruopščiai pasirinktos mokymo strategijos atveju hierarchinė architektūra gali būti didesnė už dvikalbius modelius ir daugiakalbius modelius, visiškai dalijantis parametrais.</abstract_lt>
      <abstract_it>La scelta della strategia di condivisione dei parametri nei modelli di traduzione automatica multilingue determina l'utilizzo ottimale dello spazio dei parametri e quindi influenza direttamente la qualità della traduzione finale. Ispirato da alberi linguistici che mostrano il grado di relazione tra le diverse lingue, è stato recentemente suggerito il nuovo approccio generale alla condivisione dei parametri nella traduzione automatica multilingue. L'idea principale è quella di utilizzare queste gerarchie linguistiche esperte come base per l'architettura multilingue: più sono vicine due lingue, più parametri condividono. In questo lavoro, testiamo questa idea utilizzando l'architettura Transformer e mostriamo che nonostante il successo nel lavoro precedente ci sono problemi inerenti alla formazione di tali modelli gerarchici. Dimostriamo che in caso di strategia formativa accuratamente scelta l'architettura gerarchica può superare modelli bilingui e modelli multilingue con condivisione completa dei parametri.</abstract_it>
      <abstract_mk>Изборот на стратегија за поделба на параметри во мултијазичните машински модели за превод одредува како се користи оптимално параметралниот простор и, со тоа, директно влијае врз апсолутниот квалитет на превод. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently.  The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share.  Во оваа работа, ја тестираме оваа идеја користејќи ја трансформираната архитектура и покажуваме дека и покрај успехот во претходната работа постојат проблеми поврзани со обуката на вакви хиерархички модели. Демонстрираме дека во случај на внимателно избрана стратегија за обука хиерархиската архитектура може да ги надмине двојјазичните модели и мултијазичните модели со целосно споделување на параметрите.</abstract_mk>
      <abstract_ml>പലില്ലാത്ത മെഷിന്‍ പരാമീറ്റര്‍ പങ്കെടുക്കുന്ന സ്ട്രാറ്റിജിയില്‍ പങ്കെടുക്കുന്നതിന്റെ തിരഞ്ഞെടുക്കുക, എങ്ങനെയാണ് പാ വ്യത്യസ്ത ഭാഷകള്‍ക്കിടയിലുള്ള ബന്ധം കാണിക്കുന്ന ഭാഷ്ട്രീകളാല്‍ ഭാഷയിലുള്ള വൃക്ഷങ്ങള്‍ നിര്‍ദ്ദേശിക്കുന്നു. അടുത്തുതന്നെ പല പ്രധാനപ്പെട്ട ഐഡിയയാണ് ഈ വിശേഷ ഭാഷയുടെ ഹിയേരാര്‍ക്കികള്‍ പല ഭാഷകളുടെ സ്ഥാനത്തിന്റെ അടിസ്ഥാനമായി ഉപയോഗിക്കുന്നത്: അടുത ഈ ജോലിയില്‍, നമ്മള്‍ ഈ ഐഡിയ പരീക്ഷിക്കുന്നു, ട്രാന്‍സ്ഫോര്‍മാന്‍ ആര്‍ക്കിക്കറ്റര്‍ ഉപയോഗിച്ച് കാണിക്കുന്നു. മുമ്പ് ജോലിയി സൂക്ഷ്മമായി തിരഞ്ഞെടുത്ത പരിശീലനത്തിന്റെ ട്രെയിനിജ്ജിയുടെ കാര്യത്തില്‍ ഹിയെരാര്‍ക്കിക്കല്‍ ആര്‍ക്ടിക്കറ്റിക്കാര്‍ക്ക</abstract_ml>
      <abstract_ms>Pilihan strategi berkongsi parameter dalam model terjemahan mesin berbilang bahasa menentukan bagaimana ruang parameter optimal digunakan dan oleh itu, secara langsung mempengaruhi kualiti terjemahan terbaik. Diinspirasi oleh pokok bahasa yang menunjukkan darjah hubungan antara bahasa berbeza, pendekatan umum baru untuk berkongsi parameter dalam terjemahan mesin berbilang bahasa telah disarankan baru-baru ini. Idea utama ialah menggunakan hierarki bahasa ahli ini sebagai dasar untuk arkitektur berbilang bahasa: semakin dekat dua bahasa, semakin banyak parameter yang mereka berkongsi. Dalam kerja ini, kami menguji idea ini menggunakan arkitektur Transformer dan menunjukkan bahawa walaupun sukses dalam kerja sebelumnya terdapat masalah yang berkaitan dengan latihan model hierarkis seperti itu. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</abstract_ms>
      <abstract_mn>Олон хэлний машины орчуулах загварын параметр хуваалцах стратегийн сонголт нь хэрхэн эерэг параметр орон зай хэрхэн ашигладгийг тодорхойлдог бөгөөд энэ нь шууд орчуулах чадварыг нөлөөлдөг. Өөр хэл хоорондын харилцааны түвшинд харилцааны хэлний модонуудын гайхалтай санагдаж, олон хэл хэлний машины хөрөнгө хуваалцааны шинэ ерөнхий арга зам нь саяхан санал болсон. Хамгийн гол санаа нь эдгээр мэргэжлийн хэл төрлийн архитектуруудыг олон хэл бүтээгдэхүүний суурь болгон ашиглах юм: хамгийн ойрхон хоёр хэл нь, тэдний хуваалцах илүү параметр юм. Энэ ажлын тулд бид энэ санааг Трансформфер архитектурыг ашиглан шалгаж, өмнөх ажлын амжилтын үр дүнд ч ийм төрлийн загваруудыг суралцах асуудлууд байдаг. Бид анхаархан сонгогдсон сургалтын стратегийг харуулж байна. Иерархик архитектур нь хоёр хэл загвар болон олон хэл загваруудыг бүрэн параметр хуваалцаж чадна.</abstract_mn>
      <abstract_no>Valet til å dele strategi for parametrar i fleirspråk maskineomsetjingsmodular bestemmer korleis optimalt parametrarom vert brukt og derfor direkte påvirkar endringskvalitet for omsetjingar. I løpet av lingviske trær som viser kor mykje relatede mellom ulike språk, vart nyleg foreslått den nye generelle tilnærming til å dele parametrar i fleirspråksomsetjinga. Hovudsideen er å bruka disse ekspertspråkehierarkitene som grunnlag for fleirspråk arkitektur: dei nærmere to språke er, dei fleire parametra dei deler. I denne arbeida testerer vi denne ideen ved å bruka Transformeringsarkitekturen og vise at selv om suksessen i tidlegare arbeid er det problema som er tilhøyrande å lære slike hierarkiske modeller. Vi demonstrerer at i tilfelle med forsiktig valt treingingsstrategi kan hierarkiske arkitekturen utføre bilinguelmodeller og fleirspråk modeller med fullstendig deling av parametrar.</abstract_no>
      <abstract_pl>Wybór strategii udostępniania parametrów w wielojęzycznych modelach tłumaczeń maszynowych określa optymalne wykorzystanie przestrzeni parametrów, a tym samym bezpośrednio wpływa na najwyższą jakość tłumaczenia. Zainspirowane drzewami językowymi, które pokazują stopień powiązania między różnymi językami, zaproponowano ostatnio nowe ogólne podejście do współdzielenia parametrów w wielojęzycznym tłumaczeniu maszynowym. Główną ideą jest wykorzystanie tych specjalistycznych hierarchii językowych jako podstawy architektury wielojęzycznej: im bliżej są dwa języki, tym więcej parametrów mają wspólne. W niniejszej pracy testujemy ten pomysł przy użyciu architektury Transformera i pokazujemy, że pomimo sukcesu w poprzednich pracach istnieją problemy nieodłączne z szkoleniem takich hierarchicznych modeli. Pokazujemy, że w przypadku starannie dobranej strategii szkoleniowej architektura hierarchiczna może przewyższyć modele dwujęzyczne i modele wielojęzyczne z pełnym współdzieleniem parametrów.</abstract_pl>
      <abstract_mt>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality.  Sperit minn siġar lingwistiċi li juru l-grad ta’ rabta bejn ilsna differenti, dan l-aħħar ġie ssuġġerit approċċ ġenerali ġdid għall-qsim tal-parametri fit-traduzzjoni tal-magni multilingwi. L-idea ewlenija hija li jintużaw dawn il-ġerarkiji tal-lingwi esperti bħala bażi għall-arkitettura multilingwi: aktar ikunu eqreb iż-żewġ lingwi, aktar parametri jaqsmu. F’dan ix-xogħol, nistestjaw din l-idea bl-użu tal-arkitettura Transformer u nuru li minkejja s-suċċess fix-xogħol preċedenti hemm problemi inerenti għat-taħriġ ta’ mudelli ġerarkiċi bħal dawn. Aħna nuru li fil-każ ta’ strateġija ta’ taħriġ magħżula bir-reqqa l-arkitettura ġerarkika tista’ taqbeż il-mudelli bilingwi u mudelli multilingwi b’kondiviżjoni sħiħa tal-parametri.</abstract_mt>
      <abstract_sr>Izbor strategije za dijeljenje parametara u modelima prevođenja multijezičkih mašina određuje kako se optimalno koristi prostor parametara, i stoga direktno utiče na kvalitet prevođenja. Inspirirali su jezički drveći koji pokazuju stepen odnosa između različitih jezika, nedavno je predložen novi opći pristup delivanju parametara u multijezičkom prevodu mašine. Glavna ideja je da koristimo ove hijerarhije stručnih jezika kao osnova za multijezičku arhitekturu: što je bliže dve jezike, što više parametra podijele. U ovom poslu, testiramo ovu ideju koristeći arhitekturu transformera i pokažemo da, uprkos uspjehu prethodnog posla, postoje problema koji su uključeni obuku takvih hijerarhijskih modela. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</abstract_sr>
      <abstract_ro>Alegerea strategiei de partajare a parametrilor în modelele de traducere automată multilingvă determină modul în care este utilizat optim spațiul parametrilor și, prin urmare, influențează direct calitatea finală a traducerii. Inspirată de arbori lingvistici care arată gradul de relație dintre diferitele limbi, noua abordare generală a partajării parametrilor în traducerea automată multilingvă a fost sugerată recent. Ideea principală este de a utiliza aceste ierarhii lingvistice experți ca bază pentru arhitectura multilingvă: cu cât sunt mai apropiate două limbi, cu atât împărtășesc mai mulți parametri. În această lucrare, testăm această idee folosind arhitectura Transformer și arătăm că, în ciuda succesului în lucrările anterioare, există probleme inerente formării unor astfel de modele ierarhice. Demonstrăm că în cazul strategiei de formare alese cu atenție arhitectura ierarhică poate depăși modelele bilingve și multilingve cu partajarea completă a parametrilor.</abstract_ro>
      <abstract_sv>Valet av parameterdelningsstrategi i flersprﾃ･kiga maskinﾃｶversﾃ､ttningsmodeller avgﾃｶr hur optimalt parameterutrymme anvﾃ､nds och pﾃ･verkar dﾃ､rmed den ultimata ﾃｶversﾃ､ttningskvaliteten direkt. Inspirerad av sprﾃ･kliga trﾃ､d som visar graden av samband mellan olika sprﾃ･k, fﾃｶreslogs nyligen en ny allmﾃ､n strategi fﾃｶr parameterdelning i flersprﾃ･kig maskinﾃｶversﾃ､ttning. Huvudidﾃｩn ﾃ､r att anvﾃ､nda dessa expertsprﾃ･khierarkier som grund fﾃｶr flersprﾃ･kig arkitektur: ju nﾃ､rmare tvﾃ･ sprﾃ･k ﾃ､r, desto fler parametrar delar de. I detta arbete testar vi denna idﾃｩ med hjﾃ､lp av Transformer-arkitekturen och visar att trots framgﾃ･ngarna i tidigare arbete finns problem inneboende med att utbilda sﾃ･dana hierarkiska modeller. Vi visar att vid noggrant vald utbildningsstrategi kan den hierarkiska arkitekturen ﾃｶvertrﾃ､ffa tvﾃ･sprﾃ･kiga modeller och flersprﾃ･kiga modeller med fullstﾃ､ndig parameterdelning.</abstract_sv>
      <abstract_so>Doorashada qayb-qaybinta parameter ee noocyada turjumaadda luuqadaha kala duduwan ayaa go’aan ku saameysanaya sida loo isticmaalayo goobta parameter, taas darteed wuxuu toos u saameyn ku yeelanayaa qiimaha ugu danbeeya turjumaadda. Waxaa la soo dhiibay geedaha luuqadaha ku qoran oo muujiya shahaadada xiriirka luuqadaha kala duduwan, ugu dhowaad waxaa la soo jeeday qaababka cusub ee ku saabsan parameter ku saabsan turjumidda machine luuqadaha kala duduwan. Fikirada ugu horeysa waa in lagu isticmaalaa hierarkii luuqada khaaska ah sida aasaasi ah dhismaha luuqadaha kala duduwan: labada luqadood ee ugu dhow waa, si kamid ah oo ay u qeybiyaan. Markaas waxan, waxaynu tijaabinaynaa fikradan isticmaalka dhismaha turjumista iyo waxaynu tusaynaa in despite guulaysta shaqada hore dhibaatooyin ku jirta waxbarashada tusaalaha hierarkiisa ah. Waxaynu muujinnaa in marka qoraalka waxbarashada si taxadar leh loo doortay, dhismaha hierarkiis wuxuu sameyn karaa tusaalooyin labaad oo kala duduwan iyo tusaalooyin kala duduwan oo kala duduwan oo wada qaybsan parameter.</abstract_so>
      <abstract_ta>பல மொழி மொழி மொழிமாற்றி மாதிரிகளில் அளபுரு பகிர்ந்து தேர்வு தேர்ந்தெடுக்கப்பட்டுள்ளது எவ்வாறு தேர்வு அளபுரு இடத்தை பயன்படுத் மொழி மொழிகளுக்கு இடையே தொடர்புகளின் degree காட்டும் மொழிகளால் வழங்கப்பட்டுள்ளது, அளபுருவை பகிர்ந்து புதிய முறைமை சமீபத்தில் பல மொழ முக்கிய ய யோசனை பல மொழி கட்டுப்பாட்டுக்கான அடிப்படையாக பயன்படுத்த வேண்டும். நெருங்கிய இரு மொழிகள், அதிக அளவுருக்கள் அவர்கள் பகிர் இந்த வேலையில், நாம் இந்த கருத்தை பரிசோதிக்கிறோம் மாற்று உருவாக்கத்தை பயன்படுத்தி காட்டுகிறோம் முந்தைய வேலையில் வெற்றி நாம் கவனமாக தேர்ந்தெடுக்கப்பட்ட பயிற்சி திட்டத்திற்கு காண்பிக்கிறோம் என்றால் முழு அளபுரு பகிர்ந்து இரு மொழி மாதிரிகள் மற்ற</abstract_ta>
      <abstract_si>ගොඩක් භාෂාවක් පද්ධතිය පද්ධතිය පද්ධතිය අනුවාර්ථ විශේෂයෙන් ප්‍රතිභාවිතයේ තෝරණය තෝරණය නිර්ධාරණය කර වෙනස් භාෂාවල් අතර සම්බන්ධතාවක් පෙන්වන්න භාෂාවල් වලින් ප්‍රශ්නයක් තියෙන්නේ, අලුත් සාමාන්‍ය ප්‍රශ්නයක්  ප්‍රධාන අදහසය තමයි මේ විශ්වාසික භාෂාව අයිරිෂ්ටියව භාවිතා කරන්න බොහොම භාෂාව සංවිධානයක් විදිහට: වඩ මේ වැඩේ අපි මේ අදහසක් පරීක්ෂා කරනවා මේ අදහසක් ප්‍රවේශකයේ ස්ථාපනය කරන්න සහ පෙන්වන්නේ, මුලින් වැඩේ වැඩේ සාර්ථක වැඩේ  අපි පැහැදිලි කරනවා කියලා පරික්ෂා විදිහට තෝරාගන්න පුළුවන් පුළුවන් විදිහට පරික්ෂා විදිහට පරික්ෂා විදිහ</abstract_si>
      <abstract_ur>پارامیٹر شریک استراتژی کا انتخاب multilingual machine translation models میں مقرر کرتا ہے کہ کس طرح optimal parameter space استعمال کیا جاتا ہے اور اسی طرح، بالکل ترجمہ کیفیت پر مستقیم تأثیر دیتا ہے. زبان کے درختوں کے ذریعہ جو مختلف زبانوں کے درمیان رابطہ کا درجہ دکھاتے ہیں، بہت سی زبان کے ماشین کی ترجمہ میں تقسیم کرنے کے لئے نئی عمومی طریقہ کی نصیحت کی گئی ہے. اصلی نظر یہ ہے کہ ان مخصوص زبان آئرکریٹیوں کو بہت سی زبان آئرکریٹ کے لئے بنیاد بنانا ہے: دو زبانوں سے زیادہ قریب تر ہے، جسے زیادہ پارامتر وہ شریک کرتے ہیں۔ اس کام میں ہم نے اس ایڈیوں کو تغییر پھیلانے والے معماری کے مطابق آزمایا اور دکھائی کہ اگلے کاموں کے موفقیت کے بغیر اس طرح کی آزمائش کی مسائل ہیں۔ ہم دکھاتے ہیں کہ اچھے طریقے سے انتخاب کئے گئے ترین استراتژی کے مطابق حکومت کی معماری دو زبان کی مدل اور بہت سی زبان کی مدل کو پورا پارامتر شریک کرنے کے ساتھ کامل کر سکتا ہے.</abstract_ur>
      <abstract_uz>@ info: whatsthis Yaqinda bir necha tilda bir xil mashina tarjima qiladigan parametrlar darajasini koʻrsatish uchun lingʻlik darajasi bilan imzolangan. Bu oddiy g'oya bir necha tillar arxituvchisi asosiy bo'lishi mumkin: ikkita tillar soni ko'proq parametrlar bo'lishi mumkin. Bu ishda biz bu g'oyani Transformer architektorlar bilan sinab ko'raymiz va oldingi ishda muvaffaqiyatlarni ko'rsatganimizda bunday hierarchik modellarini o'rganish uchun muammolar bor. Biz tajriba o'rganish strategiga qaramaymiz, hierarchik arxituvchisi bilan ikkita tillar modellari va bir necha tildagi modellarni butun parametr boʻlishi mumkin.</abstract_uz>
      <abstract_vi>Lựa chọn chiến lược chia sẻ Tham số trong các mô hình dịch máy đa dạng, quyết định cách sử dụng các khu vực tham số tốt và do đó, ảnh hưởng trực tiếp đến chất lượng dịch thuật. Nguồn cảm hứng từ cây ngôn ngữ cho thấy độ liên quan giữa các ngôn ngữ khác nhau, bạn đã đề nghị gần đây một phương pháp chung chung mới về chia sẻ các tham số trong phiên dịch máy đa dạng. Chủ đề chính là sử dụng những cấp dưới ngôn ngữ chuyên môn này làm nền tảng cho kiến trúc đa dạng. Hai ngôn ngữ càng gần thì càng chia sẻ nhiều tham số. Trong công trình này, chúng ta thử nghiệm ý tưởng này qua kiến trúc biến áp và cho thấy mặc dù thành công trong công việc trước kia có vấn đề gì trong việc đào tạo các mô hình cấp bậc này. Chúng tôi chứng minh rằng trong trường hợp được chọn kỹ thuật huấn luyện cẩn thận cấu trúc thứ tự có thể đạt giới hạn cách làm ăn nhanh hơn các mô- đun và các mô-đun đa dạng.</abstract_vi>
      <abstract_hr>Izbor strategije dijeljenja parametara u multijezičkim modelima prevoda uređaja određuje kako se optimalno koristi prostor parametara, i stoga izravno utječe na konačnu kvalitet prevoda. Nedavno je predloženo novi opći pristup dijeljenju parametara u multijezičkom prevodu strojeva. Glavna ideja je koristiti ove hijerarhije stručnih jezika kao temelj za multijezičku arhitekturu: što je bliže dvije jezike, što više parametara dijele. U ovom poslu testiramo ovu ideju koristeći arhitekturu transformera i pokazujemo da, uprkos uspjehu prethodnog posla, postoje problema koji su uključujući obuku takvih hijerarhijskih modela. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</abstract_hr>
      <abstract_bg>Изборът на стратегия за споделяне на параметри в многоезичните модели за машинен превод определя как оптимално се използва пространството на параметрите и следователно пряко влияе върху върховното качество на превода. Вдъхновен от езиковите дървета, които показват степента на свързаност между различните езици, наскоро беше предложен нов общ подход към споделянето на параметри в многоезичния машинен превод. Основната идея е да се използват тези експертни езикови йерархии като основа за многоезична архитектура: колкото по-близки са двата езика, толкова повече параметри споделят. В тази работа тестваме тази идея с помощта на архитектурата на трансформатора и показваме, че въпреки успеха в предишната работа съществуват проблеми, присъщи на обучението на такива йерархични модели. Ние демонстрираме, че при внимателно подбрана стратегия за обучение йерархичната архитектура може да надмине двуезичните модели и многоезичните модели с пълно споделяне на параметри.</abstract_bg>
      <abstract_nl>De keuze van de strategie voor het delen van parameters in meertalige machinevertaalmodellen bepaalt hoe optimaal de parameterruimte wordt gebruikt en beïnvloedt daarmee direct de uiteindelijke vertaalkwaliteit. Geïnspireerd door taalbomen die de mate van verwantschap tussen verschillende talen tonen, werd onlangs de nieuwe algemene benadering voor het delen van parameters in meertalige machinevertaling voorgesteld. Het belangrijkste idee is om deze deskundige taalhiërarchieën te gebruiken als basis voor meertalige architectuur: hoe dichter de twee talen zijn, hoe meer parameters ze delen. In dit werk testen we dit idee met behulp van de Transformer architectuur en laten we zien dat ondanks het succes in eerdere werken er problemen inherent zijn aan het trainen van dergelijke hiërarchische modellen. We tonen aan dat in geval van zorgvuldig gekozen trainingsstrategie de hiërarchische architectuur tweetalige modellen en meertalige modellen met volledige parameterdeling kan overtreffen.</abstract_nl>
      <abstract_da>Valget af parameterdelingsstrategi i flersprogede maskinoversættelsesmodeller bestemmer, hvor optimalt parameterpladsen anvendes, og påvirker dermed den ultimative oversættelseskvalitet direkte. Inspireret af sproglige træer, der viser graden af relaterethed mellem forskellige sprog, blev den nye generelle tilgang til parameterdeling i flersproget maskinoversættelse foreslået for nylig. Hovedideen er at bruge disse ekspertssproghierarkier som grundlag for flersproget arkitektur: Jo tættere to sprog er, jo flere parametre deler de. I dette arbejde tester vi denne idé ved hjælp af Transformer-arkitekturen og viser, at trods succesen i tidligere arbejde er der problemer forbundet med at træne sådanne hierarkiske modeller. Vi demonstrerer, at i tilfælde af nøje valgt træningsstrategi kan den hierarkiske arkitektur overgå tosprogede modeller og flersprogede modeller med fuld parameterdeling.</abstract_da>
      <abstract_fa>انتخاب استراتژی تقسیم پارامتر در مدل ترجمه‌های ماشین‌های زیادی زبان تعریف می‌کند که چگونه فضای پارامتر optimally استفاده می‌شود و بنابراین، مستقیماً کیفیت ترجمه را تأثیر می‌دهد. توسط درختان زبان‌شناسی که درجه ارتباط بین زبان‌های مختلف را نشان می‌دهند، دستور جدید عمومی برای تقسیم پارامتر در ترجمه ماشین‌های زیادی زبان اخیرا پیشنهاد داده شد. ایده اصلی این است که از این مجموعه‌های زبان متخصص به عنوان بنیادی برای معماری بسیاری زبان استفاده کنیم: هر دو زبان نزدیک تر از آن است، هر پارامتری بیشتری که آنها را تقسیم می‌کنند. در این کار، ما این ایده را با استفاده از معماری تغییر دهنده آزمایش می‌کنیم و نشان می‌دهیم که با وجود موفقیت در کار قبلی مشکل‌هایی وجود دارد که برای آموزش چنین مدل‌های معماری هستند. ما نشان می دهیم که در مورد استراتژی آموزش با دقت انتخاب شده، معماری معماری الهی می تواند مدل های دو زبانی و مدل های متعدد زبانی را با مشترک پارامتر کامل انجام دهد.</abstract_fa>
      <abstract_de>Die Wahl der Parametersharing-Strategie in mehrsprachigen maschinellen Übersetzungsmodellen bestimmt, wie der Parameterraum optimal genutzt wird und beeinflusst somit direkt die ultimative Übersetzungsqualität. Inspiriert von linguistischen Bäumen, die den Grad der Verwandtschaft zwischen verschiedenen Sprachen zeigen, wurde kürzlich der neue allgemeine Ansatz für die gemeinsame Nutzung von Parametern in mehrsprachigen maschinellen Übersetzungen vorgeschlagen. Die Grundidee ist, diese fachkundigen Sprachhierarchien als Grundlage für mehrsprachige Architektur zu nutzen: Je näher zwei Sprachen sind, desto mehr Parameter teilen sie sich. In dieser Arbeit testen wir diese Idee mit Hilfe der Transformer Architektur und zeigen, dass trotz des Erfolgs in früheren Arbeiten Probleme beim Training solcher hierarchischen Modelle bestehen. Wir zeigen, dass die hierarchische Architektur im Falle einer sorgfältig gewählten Trainingsstrategie zweisprachige Modelle und mehrsprachige Modelle mit vollständiger Parameterfreigabe übertreffen kann.</abstract_de>
      <abstract_ko>다중 언어 기계 번역 모델에서 매개 변수 공유 전략의 선택은 매개 변수 공간의 가장 좋은 사용을 결정하고 최종 번역의 질에 직접적인 영향을 미친다.서로 다른 언어 간의 연관성을 나타내는 언어 트리의 계발을 받아 최근 새로운 통용 다언어 기계 번역 파라미터 공유 방법을 제시했다.그 주요 사상은 이런 전문가들의 언어 차원 구조를 다중 언어 체계 구조의 기초로 사용하는 것이다. 두 언어가 가까울수록 그들이 공유하는 파라미터가 많아진다.이 작업에서 우리는 Transformer 구조를 이용하여 이 생각을 테스트했고 이전의 작업에서 성공을 거두었지만 이런 차원 모델을 훈련할 때 여전히 고유한 문제가 존재한다는 것을 나타냈다.우리는 정성스럽게 선택한 훈련 전략의 상황에서 층 구조가 이중 언어 모델과 완전한 파라미터가 공유하는 다중 언어 모델보다 우수하다는 것을 증명했다.</abstract_ko>
      <abstract_id>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality.  Terinspirasi oleh pohon bahasa yang menunjukkan tingkat hubungan antara bahasa yang berbeda, pendekatan umum baru untuk berbagi parameter dalam terjemahan mesin berbilang bahasa baru-baru ini disarankan. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share.  Dalam pekerjaan ini, kami menguji ide ini menggunakan arsitektur Transformer dan menunjukkan bahwa meskipun sukses dalam pekerjaan sebelumnya ada masalah yang tergantung pada pelatihan model hierarkis seperti itu. Kami menunjukkan bahwa dalam kasus strategi latihan yang dipilih dengan hati-hati arsitektur hierarkis dapat melebihi model dua bahasa dan model berbilang bahasa dengan berbagi parameter penuh.</abstract_id>
      <abstract_sw>Uchaguzi wa kushirikiana mpango wa kutumia mbinu za kutafsiri kwa lugha mbalimbali unaamua namna ambavyo nafasi ya parameter inavyotumiwa na hivyo, unaathiri moja kwa moja kiwango cha tafsiri cha mwisho. Imetumiwa na miti ya lugha inayoonyesha kiwango cha uhusiano kati ya lugha tofauti, mbinu mpya ya kushirikiana kwa vifaa vya lugha mbalimbali ilipendekezwa hivi karibuni. Wazo kuu ni kutumia hifadhi hizi za lugha za wataalam kama msingi wa ujenzi wa lugha mbalimbali: lugha mbili karibu zaidi ni, kipimo ambacho wanaweza kushirikiana. Katika kazi hii, tunajaribu wazo hili kwa kutumia ujenzi wa zamani na kuonyesha kwamba pamoja na mafanikio katika kazi zilizopita, kuna matatizo yanayohusiana na kufundisha mifano kama haya ya kihierarchical. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</abstract_sw>
      <abstract_tr>Çoklu dilli maşynyň terjime nusgalarynda parameterler paylaşdyrma stratejiýasynyň saýlawy nähili optimiz seleňler ullanylýar we şonuň üçin iň üstüne terjime kwalitesini täsirleýär. Diller arasyndaky baglaýyşlar tarapyndan nähili bir baglaýyşyň barlygyny görkezýär, täze uly diller maşynyň terjimesinde paýlaşmak üçin täze ýagdaý maslahat edildi. Esasy ideýa şu uzmanly dil hijerarhiýasyny multi dil arhitektura üýtgetmekdir: iki diliň ýakyn bolsa, olaryň paylaşyklarynyň has köp parameterleri. Bu işde, biz bu ideýany Transformer arhitekturyny ulanyp barýarys we öňki işiň başarnygynyň ýöne şol ýaly iýerarhiýa nusgalary öwrenmek üçin kynçylyklary bar diýip görkezip bileris. Biz iýerarhiýa arhitekturyň iki dil nusgalaryny we multidil nusgalaryny doly parmaýa bilen dykkatly saýlandygyny görkez.</abstract_tr>
      <abstract_af>Die keuse van parameter deel strategie in multilingual masjien vertaling modele bepaal hoe optimale parameter spasie gebruik word en daarom, direk influens die ultimate vertaling kwaliteit. Inspirasie deur lingvisse bome wat die grad van verwantigheid tussen verskillende tale vertoon het, het die nuwe algemene toegang tot parameter deel in multilingse masjien vertaling onlangs voorgestel. Die hoof idee is om hierdie ekspertiese taal hierarkies as 'n basis vir multilinglike arkitektuur te gebruik: die nader twee tale is, die meer parameters wat hulle deel. In hierdie werk, ons probeer hierdie idee deur die Transformer-arkitektuur te gebruik en wys dat, alhoewel die sukses in die vorige werk, daar is probleme wat onderwerp is om sodanige hierarkiese modele te onderwerp. Ons wys dat in geval van versigtig gekose onderwerp strategie kan die hierarkiese arkitektuur twee tale modele en multitaal modele uitvoer met volle parameter deel.</abstract_af>
      <abstract_sq>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality.  Inspiruar nga pemët gjuhësore që tregojnë shkallën e lidhjes midis gjuhëve të ndryshme, u sugjerua kohët e fundit metoda e re e përgjithshme për ndarjen e parametrave në përkthimin shumëgjuhës të makinave. Ideja kryesore është të përdorim këto hierarki gjuhësh eksperte si bazë për arkitekturën shumëgjuhëse: sa më afër janë dy gjuhët, aq më shumë parametra ndajnë. Në këtë punë, ne e testojmë këtë ide duke përdorur arkitekturën Transformer dhe tregojmë se pavarësisht nga suksesi në punën e mëparshme ka probleme inerente në trajnimin e modeleve të tilla hierarkike. Ne demonstrojmë se në rast të strategjisë së trajnimit të zgjedhur me kujdes arkitektura hierarkike mund të kalojë modelet dygjuhëse dhe modelet shumëgjuhëse me ndarjen e plotë të parametrave.</abstract_sq>
      <abstract_az>Çoxlu dilli maşın çevirim modellərində parametru paylaşım stratejisinin seçimi necə optimallı parametru alanı istifadə edir və buna görə də sonrakı çevirim keyfiyyətinə təsir edir. Müxtəlif dillər arasındakı bağlılıq dərəcəsini göstərən dil ağacları tarafından təşkil edildi, çoxlu dil makinelərin tercüməsində paylaşılması üçün yeni genel yol göstərildi. Ən böyük fikir, bu müxtəlif dil hiyerarhiyatlarını çoxlu dil arhitektarının əsası kimi istifadə etməkdir: ən yaxın iki dildir, daha çox parametrləri paylaşırlar. Bu işdə, biz bu ideyanı Transformer arhitektürünün vasitəsilə imtahana çəkirik və göstəririk ki, əvvəlki işin başarısızlığına baxmayaraq böyük hiyerarşik modellərini təhsil etmək üçün problemlər var. Biz göstəririk ki, təhsil müəyyən edilmiş təhsil strateji olaraq hiyerarşik arhitektura iki dil modellərini və çoxlu dil modellərini tam parametrləri paylaşdırması ilə daha üstün edə bilər.</abstract_az>
      <abstract_am>በ多ልቋንቋ ቋንቋ ማተርጓም ሞዴዎች ውስጥ የፓርላማ ማጋራጨት ትርጉም ምረጡ እንዴት እንደሚጠቀሙ እና ከዚህ በኋላ በአዲስ መጨረሻ ትርጉም ጥሩ እንዲያስቀምጥ ይፈጥራል። በልዩ ቋንቋዎች መካከል ግንኙነት የሚያሳየው የቋንቋ ዛፎች በቋንቋዎች ላይ የሚታየው አዲስ የጠቅላላ አካባቢ ግንኙነት በብልልቋንቋ ቋንቋ መሳሳይ ትርጉም በመጠቀም ተግሳጽቷል፡፡ የዋነኛው አሳብ ይህ የቋንቋ አዳራሲ ቋንቋዎች መሠረታዊ መሠረት መሆኑን ለመጠቀም ነው፤ በጣም የቀረበ ሁለት ቋንቋዎች ናቸው፣ ይልቁንም ይጨማራሉ፡፡ በዚህ ሥራ፣ ይህንን አእምሮን የTransformer የመሠረተ ሥርዓት በመጠቀም እናሳያቸዋለን፣ የቀድሞው ስርዓት ምንም እንኳ እንደሆነ እንደዚህ ያለ hierarchical models ለማስተማር መከራዎች አሉ፡፡ በጥንቃቄ የተመረጠውን ትምህርት ማሰናከል፣ የሐራርካዊ መሠረተ ሥርዓት በሁለት ቋንቋዎች እና በብዙ ቋንቋዎች ዓይነቶች በሙሉ ተማሪዎች ማሳየት ይችላል፡፡</abstract_am>
      <abstract_hy>Բազլեզու մեքենայի թարգմանման մոդելների պարամետրերի կիսման ռազմավարության ընտրությունը որոշում է, թե ինչպես է օպտիմալ պարամետրերի տարածքը օգտագործվում և հետևաբար, անմիջապես ազդում է վերջնական թարգմանման որակին: Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently.  Հիմնական գաղափարն այն է, որ այս մասնագետների լեզվի հիերարխիաները օգտագործենք որպես բազլեզու ճարտարապետության հիմք. որքան ավելի մոտ են երկու լեզուները, այնքան ավելի շատ պարամետրեր են նրանք կիսում: Այս աշխատանքի ընթացքում մենք փորձում ենք այս գաղափարը օգտագործելով Թանֆերմերների ճարտարապետությունը և ցույց ենք տալիս, որ չնայած նախորդ աշխատանքի հաջողության, կան խնդիրներ, որոնք բնորոշ են նման հիերարխիկ մոդելների Մենք ցույց ենք տալիս, որ ուշադիր ընտրված ուսումնասիրության ռազմավարության դեպքում հիերարխիկ ճարտարապետությունը կարող է գերազանցել երկլեզու մոդելները և բազլեզու մոդելները՝ ամբողջ պարամետրերի կիսվելով:</abstract_hy>
      <abstract_bs>Izbor strategije dijeljenja parametara u multijezičkim modelima prevođenja mašina određuje kako se optimalno koristi prostor parametara i stoga direktno utiče na kvalitet prevođenja. Nedavno je predloženo novi generalni pristup dijeljenju parametara u multijezičkom prevodu strojeva. Glavna ideja je da koristimo ove hijerarhije stručnih jezika kao osnova za multijezičku arhitekturu: što je bliže dvije jezike, što više parametara dijele. U ovom poslu testiramo ovu ideju koristeći arhitekturu Transformera i pokazujemo da, uprkos uspjehu prethodnog posla, postoje problema koji su obučeni takvim hijerarhijskim modelima. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</abstract_bs>
      <abstract_et>Parameetrite jagamise strateegia valik mitmekeelsetes masintõlkemudelites määrab, kuidas parameetrite ruumi optimaalselt kasutatakse, ning mõjutab seega otseselt ülimat tõlkekvaliteeti. Hiljuti pakuti välja uus üldine lähenemisviis parameetrite jagamisele mitmekeelses masintõlkes, inspireerituna keelepuudest, mis näitavad erinevate keelte vahelist seost. Põhieesmärk on kasutada neid ekspertkeele hierarhiaid mitmekeelse arhitektuuri alusena: mida lähemal kaks keelt on, seda rohkem parameetreid nad jagavad. Selles töös katsetame seda ideed Transformeri arhitektuuri abil ja näitame, et vaatamata varasemate tööde edule on selliste hierarhiliste mudelite koolitamisega seotud probleeme. Näitame, et hoolikalt valitud koolitusstrateegia korral suudab hierarhiline arhitektuur ületada kakskeelseid mudeleid ja mitmekeelseid mudeleid täieliku parameetrite jagamisega.</abstract_et>
      <abstract_cs>Volba strategie sdílení parametrů ve vícejazyčných modelech strojového překladu určuje, jak je optimálně využíván parametrový prostor, a tím přímo ovlivňuje maximální kvalitu překladu. Inspirován jazykovými stromy, které ukazují stupeň souvislosti mezi různými jazyky, byl v poslední době navržen nový obecný přístup ke sdílení parametrů ve vícejazyčném strojovém překladu. Hlavní myšlenkou je využít tyto odborné jazykové hierarchie jako základ pro vícejazyčnou architekturu: čím blíže jsou dva jazyky, tím více parametrů sdílejí. V této práci tuto myšlenku testujeme s využitím architektury Transformeru a ukážeme, že i přes úspěch v předchozí práci existují problémy s tréninkem těchto hierarchických modelů. Ukazujeme, že v případě pečlivě zvolené tréninkové strategie hierarchická architektura může překonat dvojjazyčné modely a vícejazyčné modely s plným sdílením parametrů.</abstract_cs>
      <abstract_bn>মাল্টিভাল মেশিন অনুবাদ মডেলে প্যারামিটার শেয়ার করার কৌশলের বেছে নির্ধারণ করা যায় কিভাবে অপ্রায় পরামিটারের স্থান ব্যবহার করা হয় ভাষাভাষী গাছ দ্বারা অনুপ্রাণিত হয়েছে যা ভিন্ন ভাষার মধ্যে যুক্তি প্রদর্শন করে, সম্প্রতি মাল্টিভাষার মেশিন অনুবাদে প্যারামিটার শ প্রধান ধারণা হচ্ছে এই বিশেষজ্ঞ ভাষার হিয়ারার্কি ব্যবহার করা মাল্টিভাষা ভাষার প্রতিষ্ঠানের জন্য ভিত্তিক হিসেবে: দুই ভাষা এই কাজে আমরা এই চিন্তা পরীক্ষা করি ট্রান্সফার্ন আর্কিকেট ব্যবহার করে এবং দেখাচ্ছি যে আগের কাজের সফল সত্ত্বেও এই ধরনের হিরেরার্কিকাল আমরা দেখাচ্ছি যে সাবধানে প্রশিক্ষণ কৌশলের ক্ষেত্রে হিয়ারেক্যাল কাঠামো দুই ভাষার মডেল এবং বহুভাষায় মডেল প্রদর্শন করতে পারে পুরো প</abstract_bn>
      <abstract_ca>L'elecció de l'estratègia de compartir paràmetres en models multilingües de traducció de màquines determina com s'utilitza l'espai de paràmetres de manera optima i, per tant, influeix directament en la qualitat final de traducció. Inspirat pels arbres lingüístics que mostran el grau de relació entre les diferents llengües, fa poc va suggerir un nou enfocament general al compartir paràmetres en la traducció multilingüe de màquines. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share.  En aquesta feina, provem aquesta idea utilitzant l'arquitectura Transformer i demostrem que malgrat l'èxit de la feina anterior hi ha problemes inherents a l'entrenament d'aquests models jeràrquics. Demonstrem que en el cas d'una estratègia de formació escollida amb cura l'arquitectura jeràrquica pot superar els models bilingües i multilingües amb un compartiment complet de paràmetres.</abstract_ca>
      <abstract_fi>Monikielisten konekäännösmallien parametrinjakostrategian valinta määrittää, miten optimaalisesti parametritilaa käytetään ja siten vaikuttaa suoraan käännöksen lopulliseen laatuun. Äskettäin ehdotettiin uutta yleistä lähestymistapaa parametrien jakamiseen monikielisessä konekäännöksessä, joka perustuu kielipuihin, jotka osoittavat eri kielten keskinäisen yhteyden. Pääajatuksena on käyttää näitä asiantuntijakielihierarkioita monikielisen arkkitehtuurin perustana: mitä lähempänä kaksi kieltä ovat, sitä enemmän parametreja ne jakavat. Tässä työssä testaamme tätä ajatusta Transformer-arkkitehtuurin avulla ja osoitamme, että huolimatta aiemman työn onnistumisesta tällaisten hierarkkisten mallien kouluttamiseen liittyy ongelmia. Osoitamme, että huolellisesti valitun koulutusstrategian tapauksessa hierarkkinen arkkitehtuuri voi suoriutua kaksikielisistä malleista ja monikielisistä malleista täydellä parametrien jakamisella.</abstract_fi>
      <abstract_jv>translation Ngubah bener Piyambak luwih apik lan gambar aturan kanggo nggawe luwih apik karo akeh basa kanggo arquitur multilanggar: akeh langgar sampeyan sing luwih apik, akeh sabên langgar sapa nyimpen. Nang barêng-barêng iki, kéné ujian akeh iki ning gambar architecture Transformer sampeyan ngono kuwi bagian sing perbudhakan kanggo nggawe barang nggawe barang kelas kuwi kudu nggawe sistem sing berarti kuwi mau. Awak dhéwé éntuk éntuk ngono cah akeh nggawe aturan sing paling berarti maneh karo akeh perusahaan winih lan model multilanggar sampek ndelak dhéwé karo perusahaan parameter.</abstract_jv>
      <abstract_sk>Izbira strategije delitve parametrov v večjezičnih modelih strojnega prevajanja določa, kako optimalno se uporablja prostor parametrov in s tem neposredno vpliva na končno kakovost prevajanja. Na podlagi jezikovnih dreves, ki kažejo stopnjo povezanosti med različnimi jeziki, je bil pred kratkim predlagan nov splošni pristop k delitvi parametrov v večjezičnem strojnem prevajanju. Glavna ideja je uporaba teh strokovnih jezikovnih hierarhij kot osnove za večjezično arhitekturo: bližje kot sta dva jezika, več parametrov si delita. V tem delu preizkušamo to idejo s pomočjo arhitekture transformatorjev in pokažemo, da kljub uspehu pri prejšnjem delu obstajajo težave pri usposabljanju takšnih hierarhičnih modelov. Pokazali smo, da lahko v primeru skrbno izbrane strategije usposabljanja hierarhična arhitektura presega dvojezične modele in večjezične modele s popolno delitvijo parametrov.</abstract_sk>
      <abstract_ha>Zaɓi shirin shari da parameter cikin misãlai masu fassarar masu cikin birai na ƙidãya, yana bayyana yadda ake amfani da filin parameteri da kuma, a bayan haka, yana yi amfani da tsarin fassarar ta ƙarami. An Inspire shi da itãce na linguistic waɗanda ke nũna daraja na haɗuwa a tsakanin harshen daban, an buƙata wata hanyor zuwa sharing da parameter cikin fassarar masu multilingu na ƙarani. Maɓancin yana amfani da waɗannan hiera masu cikin harshen masu fitarwa kamar bango wa matsayin mulki-lingui: don harshen biyu masu kusantar, ko da takarda zasu share. Daga wannan aikin, Munã jarraba wannan idãnar da Muke amfani da ¦arkin Transformer kuma Muke nũna cewa, kõ da yaushe an sami cin nasara a gabanin aikin na farko, there za'a sami masu tsari misãlai masu hiera. Tuna nũna cewa, idan an ƙididdige tayari masu amfani da taƙaitacce, an iya samar da matsayin na'asar da misãlai biyu masu cikin lugha da cikakken parameteri.</abstract_ha>
      <abstract_he>הבחירה של אסטרטגיה לחלוק פרמטרים בדוגמאות תרגום מכונות רבות שפויות קובעת איך אופטימית השתמש בחלל פרמטרים ולכן, ישירות משפיעה על איכות תרגום אולטימטיבית. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently.  הרעיון העיקרי הוא להשתמש בהיררכיות השפה המומחיות האלה כבסיס לארכיטקטורה רבת-שפתית: ככל שתי שפות קרובות יותר, כך הם חולקים יותר פרמטרים. בעבודה הזו, אנו מבחנים את הרעיון הזה באמצעות הארכיטקטורה הטרנספורטרית ולהראות שלמרות הצלחה בעבודה הקודמת יש בעיות הנכונות לאימון דוגמנים היררכיים כאלה. אנחנו מראים כי במקרה של אסטרטגיה אימונים שנבחרה בזהירות הארכיטקטורה היררכית יכולה להתגבר על דוגמנים שתיים-שפתיים ומדוגמנים רבות-שפתיים עם חלקת פרמטרים מלאה.</abstract_he>
      <abstract_bo>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share. འོན་ཀྱང་། ང་ཚོས་གནས་སྟངས་འདི་ལྟ་བུའི་ནང་དུ་བཟོ་བཅོས་མཁན་གྱི་སྒྲིག་བརྩལ་བ་སྤྱོད་བཞིན་པའི་ལྟ་བུའི་ནང་དུ་གྲུབ་སྐྱོར་བ་རྒྱུན་ལྡ We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</abstract_bo>
      </paper>
    <paper id="4">
      <title>Representations of Language Varieties Are Reliable Given Corpus Similarity Measures</title>
      <author><first>Jonathan</first><last>Dunn</last></author>
      <pages>28–38</pages>
      <abstract>This paper measures <a href="https://en.wikipedia.org/wiki/Similarity_measure">similarity</a> both within and between 84 <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language varieties</a> across nine languages. These <a href="https://en.wikipedia.org/wiki/Corpus_linguistics">corpora</a> are drawn from digital sources (the <a href="https://en.wikipedia.org/wiki/World_Wide_Web">web</a> and tweets), allowing us to evaluate whether such geo-referenced corpora are reliable for modelling linguistic variation. The basic idea is that, if each source adequately represents a single underlying <a href="https://en.wikipedia.org/wiki/Variety_(linguistics)">language variety</a>, then the similarity between these sources should be stable across all languages and countries. The paper shows that there is a consistent agreement between these <a href="https://en.wikipedia.org/wiki/Source_text">sources</a> using frequency-based corpus similarity measures. This provides further evidence that digital geo-referenced corpora consistently represent <a href="https://en.wikipedia.org/wiki/Dialect">local language varieties</a>.</abstract>
      <url hash="b64e4e4d">2021.vardial-1.4</url>
      <bibkey>dunn-2021-representations</bibkey>
    </paper>
    <paper id="5">
      <title>Whit’s the Richt Pairt o Speech : PoS tagging for Scots<fixed-case>P</fixed-case>o<fixed-case>S</fixed-case> tagging for <fixed-case>S</fixed-case>cots</title>
      <author><first>Harm</first><last>Lameris</last></author>
      <author><first>Sara</first><last>Stymne</last></author>
      <pages>39–48</pages>
      <abstract>In this paper we explore PoS tagging for the <a href="https://en.wikipedia.org/wiki/Scots_language">Scots language</a>. Scots is spoken in <a href="https://en.wikipedia.org/wiki/Scotland">Scotland</a> and Northern Ireland, and is closely related to <a href="https://en.wikipedia.org/wiki/English_language">English</a>. As no linguistically annotated Scots data were available, we manually PoS tagged a small set that is used for evaluation and training. We use <a href="https://en.wikipedia.org/wiki/English_language">English</a> as a transfer language to examine zero-shot transfer and transfer learning methods. We find that training on a very small amount of Scots data was superior to zero-shot transfer from <a href="https://en.wikipedia.org/wiki/English_language">English</a>. Combining the Scots and English data led to further improvements, with a <a href="https://en.wikipedia.org/wiki/Concatenation">concatenation method</a> giving the best results. We also compared the use of two different English treebanks and found that a treebank containing web data was superior in the zero-shot setting, while it was outperformed by a <a href="https://en.wikipedia.org/wiki/Treebank">treebank</a> containing a mix of genres when combined with Scots data.</abstract>
      <url hash="ce78f7c0">2021.vardial-1.5</url>
      <bibkey>lameris-stymne-2021-whits</bibkey>
    </paper>
    <paper id="8">
      <title>Discriminating Between Similar Nordic Languages</title>
      <author><first>René</first><last>Haas</last></author>
      <author><first>Leon</first><last>Derczynski</last></author>
      <pages>67–75</pages>
      <abstract>Automatic language identification is a challenging problem. Discriminating between closely related languages is especially difficult. This paper presents a machine learning approach for <a href="https://en.wikipedia.org/wiki/Automatic_language_identification">automatic language identification</a> for the <a href="https://en.wikipedia.org/wiki/North_Germanic_languages">Nordic languages</a>, which often suffer <a href="https://en.wikipedia.org/wiki/Miscategorization">miscategorisation</a> by existing state-of-the-art tools. Concretely we will focus on discrimination between six Nordic languages : <a href="https://en.wikipedia.org/wiki/Danish_language">Danish</a>, <a href="https://en.wikipedia.org/wiki/Swedish_language">Swedish</a>, Norwegian (Nynorsk), Norwegian (Bokml), <a href="https://en.wikipedia.org/wiki/Faroese_language">Faroese</a> and <a href="https://en.wikipedia.org/wiki/Icelandic_language">Icelandic</a>.</abstract>
      <url hash="19384313">2021.vardial-1.8</url>
      <bibkey>haas-derczynski-2021-discriminating</bibkey>
      <pwccode url="https://github.com/StrombergNLP/NordicDSL" additional="true">StrombergNLP/NordicDSL</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/nordic-langid">nordic_langid</pwcdataset>
    </paper>
    <paper id="11">
      <title>Optimizing a Supervised Classifier for a Difficult Language Identification Problem</title>
      <author><first>Yves</first><last>Bestgen</last></author>
      <pages>96–101</pages>
      <abstract>This paper describes the system developed by the Laboratoire d’analyse statistique des textes for the Dravidian Language Identification (DLI) shared task of VarDial 2021. This task is particularly difficult because the materials consists of short YouTube comments, written in <a href="https://en.wikipedia.org/wiki/Latin_script">Roman script</a>, from three closely related <a href="https://en.wikipedia.org/wiki/Dravidian_languages">Dravidian languages</a>, and a fourth category consisting of several other languages in varying proportions, all mixed with English. The proposed system is made up of a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression model</a> which uses as only features n-grams of characters with a maximum length of 5. After its optimization both in terms of the feature weighting and the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifier parameters</a>, <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> ranked first in the challenge. The additional analyses carried out underline the importance of <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">optimization</a>, especially when the measure of effectiveness is the Macro-F1.</abstract>
      <url hash="2f5da910">2021.vardial-1.11</url>
      <bibkey>bestgen-2021-optimizing</bibkey>
    </paper>
    <paper id="14">
      <title>Comparing <a href="https://en.wikipedia.org/wiki/Dialectic">Approaches</a> to Dravidian Language Identification<fixed-case>D</fixed-case>ravidian Language Identification</title>
      <author><first>Tommi</first><last>Jauhiainen</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>120–127</pages>
      <abstract>This paper describes the submissions by team HWR to the Dravidian Language Identification (DLI) shared task organized at VarDial 2021 workshop. The DLI training set includes 16,674 YouTube comments written in Roman script containing code-mixed text with English and one of the three South Dravidian languages : <a href="https://en.wikipedia.org/wiki/Kannada">Kannada</a>, <a href="https://en.wikipedia.org/wiki/Malayalam">Malayalam</a>, and <a href="https://en.wikipedia.org/wiki/Tamil_language">Tamil</a>. We submitted results generated using two models, a <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Naive Bayes classifier</a> with adaptive language models, which has shown to obtain competitive performance in many language and dialect identification tasks, and a transformer-based model which is widely regarded as the state-of-the-art in a number of NLP tasks. Our first submission was sent in the closed submission track using only the training set provided by the shared task organisers, whereas the second submission is considered to be open as it used a pretrained model trained with external data. Our team attained shared second position in the shared task with the submission based on Naive Bayes. Our results reinforce the idea that deep learning methods are not as competitive in language identification related tasks as they are in many other text classification tasks.</abstract>
      <url hash="19975f07">2021.vardial-1.14</url>
      <bibkey>jauhiainen-etal-2021-comparing</bibkey>
    </paper>
    </volume>
</collection>