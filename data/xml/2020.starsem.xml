<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.starsem">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics</booktitle>
      <editor><first>Iryna</first><last>Gurevych</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Manaal</first><last>Faruqui</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="cb1bed58">2020.starsem-1.0</url>
      <bibkey>sem-2020-joint</bibkey>
    </frontmatter>
    <paper id="6">
      <title>Semantic Structural Decomposition for Neural Machine Translation</title>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <author><first>Ari</first><last>Rappoport</last></author>
      <pages>50–57</pages>
      <abstract>Building on recent advances in <a href="https://en.wikipedia.org/wiki/Semantic_parsing">semantic parsing</a> and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a>. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments. Results show a significant increase in <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a> on long sentences on an English-to- French setting with a training corpus of 5 M sentence pairs, while retaining comparable <a href="https://en.wikipedia.org/wiki/Adequality">adequacy</a>. We also perform a manual analysis which explores the tradeoff between adequacy and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a> in the case where all sentence lengths are considered.</abstract>
      <url hash="e26db7a4">2020.starsem-1.6</url>
      <bibkey>sulem-etal-2020-semantic</bibkey>
      <pwccode url="https://github.com/eliorsulem/semantic-structural-decomposition-for-nmt" additional="false">eliorsulem/semantic-structural-decomposition-for-nmt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisplit">WikiSplit</pwcdataset>
    <title_ar>التحلل الهيكلي الدلالي لترجمة الآلة العصبية</title_ar>
      <title_fr>Décomposition structurale sémantique pour la traduction automatique neuronale</title_fr>
      <title_es>Descomposición estructural semántica para la traducción automática neuronal</title_es>
      <title_pt>Decomposição Estrutural Semântica para Tradução Automática Neural</title_pt>
      <title_ja>神経機械翻訳のための意味論的構造分解</title_ja>
      <title_hi>तंत्रिका मशीन अनुवाद के लिए शब्दार्थ संरचनात्मक अपघटन</title_hi>
      <title_ru>Семантическое структурное разложение для нейронного машинного перевода</title_ru>
      <title_zh>用于神经机器翻译者语义结构分解</title_zh>
      <title_ga>Dianscaoileadh Séimeantach Struchtúrtha le haghaidh Aistriúchán Meaisín Néarach</title_ga>
      <title_ka>Name</title_ka>
      <title_hu>Szemantikus strukturális bontás a neurális gépi fordításhoz</title_hu>
      <title_el>Σημαντική δομική αποσύνθεση για τη νευρωνική μηχανική μετάφραση</title_el>
      <title_it>Decomposizione strutturale semantica per la traduzione automatica neurale</title_it>
      <title_lt>Semantinis struktūrinis sklaidos sklaida, skirta neurologiniam mašinų vertimui</title_lt>
      <title_kk>Нейрондық машинаның аудармасының семантикалық структуралық декомпозициясы</title_kk>
      <title_mk>Семантичка структурна декомпозиција за превод на неврални машини</title_mk>
      <title_ms>Semantic Structural Decomposition for Neural Machine Translation</title_ms>
      <title_ml>നെയുറല്‍ മെഷീന്‍ പരിഭാഷക്കുള്ള സെമാന്റിക് സ്ട്രാക്ട്രോക്ടറില്‍ ഡെക്കോമ്പോസ്റ്റ്</title_ml>
      <title_mt>Dekompożizzjoni Strutturali Semantika għat-Traduzzjoni tal-Magna Newrali</title_mt>
      <title_mn>Цөмийн машины хөгжлийн Semantic Structureural Decomposition for Neural Machine Translation</title_mn>
      <title_no>Name</title_no>
      <title_pl>Semantyczny rozkład strukturalny dla neuronowego tłumaczenia maszynowego</title_pl>
      <title_ro>Decompoziție structurală semantică pentru traducerea automată neurală</title_ro>
      <title_sr>Semantička strukturalna dekompozicija za neurološki prevod mašine</title_sr>
      <title_si>සෙමැන්ටික් සංවිධානය සංවිධානය නිර්මාණය සඳහා</title_si>
      <title_so>Semantic structural Decomposition for Neural machine Translation</title_so>
      <title_sv>Semantisk strukturell nedbrytning för neural maskinöversättning</title_sv>
      <title_ta>புதிய இயந்திரம் மொழிபெயர்ப்புக்கான செமான்டிக் கட்டுப்பாட்டு குறைப்பு</title_ta>
      <title_ur>نیورال ماشین ترجمہ کے لئے سیمنٹی ساخترال ناکامپوسٹ</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Phân chia thành phần mềm cho máy móc thần kinh</title_vi>
      <title_bg>Семантично структурно разлагане за неврален машинен превод</title_bg>
      <title_da>Semantisk strukturel nedbrydning til neural maskinoversættelse</title_da>
      <title_nl>Semantische structurele decompositie voor neurale machinevertaling</title_nl>
      <title_hr>Semantička strukturna dekompozicija za neuronski prevod strojeva</title_hr>
      <title_de>Semantische strukturelle Dekomposition für neuronale maschinelle Übersetzung</title_de>
      <title_id>Semantic Structural Decomposition for Neural Machine Translation</title_id>
      <title_ko>신경 기계 번역 중의 의미 구조 분해</title_ko>
      <title_sw>Udhibiti wa Miundombinu kwa Tafsiri ya Mashine ya Nguvu</title_sw>
      <title_tr>Neural Maşynyň terjimesine görkezilen çykyş</title_tr>
      <title_af>Name</title_af>
      <title_fa>تعادل ساختار ساختاری سیماتیک برای ترجمه ماشین عصبی</title_fa>
      <title_am>position for neural machine translation</title_am>
      <title_hy>Semantic Structural Decomposition for Neural Machine Translation</title_hy>
      <title_az>Nöral Makin Çeviri üçün Semantik Struktural Dekompozisyon</title_az>
      <title_bs>Semantička strukturna dekompozicija za neuronski prevod mašine</title_bs>
      <title_bn>নিউরাল মেশিন অনুবাদের জন্য সেম্যান্টিক ক্ষেত্রের ডিমোম্পোস্ট</title_bn>
      <title_cs>Sémantická strukturní dekompozice pro neuronový strojový překlad</title_cs>
      <title_et>Semantiline struktuuriline lagunemine neuroaalse masintõlke jaoks</title_et>
      <title_fi>Semanttinen rakenteellinen hajoaminen hermojen konekääntämiseen</title_fi>
      <title_sq>Dekompozicioni strukturor Semantik për Translation Neural Machine</title_sq>
      <title_ca>Semantic Structural Decomposition for Neural Machine Translation</title_ca>
      <title_jv>Ngucap Samantar</title_jv>
      <title_ha>position for translation</title_ha>
      <title_sk>Semantna strukturna razgradnja za strojno prevajanje nevronov</title_sk>
      <title_bo>སྤྱིར་བཏང་བའི་དབྱིབས་རྩིས་གཞུང་གི་མཐའ་འཁོར་བརྗོད་ཀྱི་</title_bo>
      <title_he>התפרצות מבנה סמנטית לתרגום מכונות נוירות</title_he>
      <abstract_fr>En nous appuyant sur les récents progrès en matière d'analyse sémantique et de simplification de texte, nous étudions l'utilisation de la division sémantique de la phrase source comme prétraitement pour la traduction automatique. Nous expérimentons un modèle Transformer et l'évaluons à l'aide d'expériences de crowdsourcing à grande échelle. Les résultats montrent une augmentation significative de la fluidité des phrases longues dans un contexte anglo-français avec un corpus d'entraînement de 5 millions de paires de phrases, tout en conservant une adéquation comparable. Nous effectuons également une analyse manuelle qui explore le compromis entre adéquation et fluidité dans le cas où toutes les longueurs de phrase sont prises en compte.</abstract_fr>
      <abstract_ar>بناءً على التطورات الحديثة في التحليل الدلالي وتبسيط النص ، فإننا نتحرى عن استخدام التقسيم الدلالي للجملة المصدر كتجهيز مسبق للترجمة الآلية. نقوم بتجربة نموذج Transformer وتقييمه باستخدام تجارب التعهيد الجماعي واسعة النطاق. تظهر النتائج زيادة ملحوظة في الطلاقة في الجمل الطويلة في بيئة من الإنجليزية إلى الفرنسية مع مجموعة تدريب مكونة من 5 ملايين أزواج من الجمل ، مع الحفاظ على كفاية مماثلة. نقوم أيضًا بإجراء تحليل يدوي يستكشف المفاضلة بين الكفاية والطلاقة في الحالة التي يتم فيها أخذ جميع أطوال الجملة في الاعتبار.</abstract_ar>
      <abstract_pt>Com base nos avanços recentes na análise semântica e simplificação de texto, investigamos o uso da divisão semântica da frase fonte como pré-processamento para tradução automática. Experimentamos um modelo Transformer e avaliamos usando experimentos de crowdsourcing em larga escala. Os resultados mostram um aumento significativo na fluência em frases longas em um ambiente de inglês para francês com um corpus de treinamento de 5 milhões de pares de frases, mantendo uma adequação comparável. Também realizamos uma análise manual que explora o tradeoff entre adequação e fluência no caso em que todos os comprimentos das frases são considerados.</abstract_pt>
      <abstract_es>Sobre la base de los avances recientes en el análisis semántico y la simplificación del texto, investigamos el uso de la división semántica de la oración fuente como preprocesamiento para la traducción automática. Experimentamos con un modelo Transformer y evaluamos mediante experimentos de crowdsourcing a gran escala. Los resultados muestran un aumento significativo de la fluidez en frases largas en un entorno de inglés a francés con un corpus de entrenamiento de 5 millones de pares de oraciones, manteniendo una adecuación comparable. También realizamos un análisis manual que explora el equilibrio entre la adecuación y la fluidez en el caso de que se tengan en cuenta todas las longitudes de oración.</abstract_es>
      <abstract_ja>セマンティック構文解析とテキスト簡略化の最近の進歩に基づいて、機械翻訳の前処理としてのソース文のセマンティック分割の使用を調査します。トランスフォーマーモデルを実験し、大規模なクラウドソーシング実験を使用して評価します。結果は、同等の妥当性を維持しながら、5 Mの文章ペアのトレーニングコーパスを持つ英語からフランス語の設定で、長文の流暢性が大幅に向上したことを示しています。また、すべての文の長さを考慮した場合の妥当性と流暢性のトレードオフを探る手動分析も行います。</abstract_ja>
      <abstract_zh>盖语义解析文简化之最新进展,研用源句之语义,分为机器翻译预处理。 Transformer以实验,大众包实验以质。 结果显示在英语法语中,长句流利,教语料库为5M句,兼保比充分性。 执手动析之,穷思句端,充分性流畅性之权衡。</abstract_zh>
      <abstract_hi>शब्दार्थ पार्सिंग और पाठ सरलीकरण में हाल की प्रगति पर निर्माण, हम मशीन अनुवाद के लिए preprocessing के रूप में स्रोत वाक्य के शब्दार्थ विभाजन के उपयोग की जांच करते हैं। हम एक ट्रांसफॉर्मर मॉडल के साथ प्रयोग करते हैं और बड़े पैमाने पर भीड़-सोर्सिंग प्रयोगों का उपयोग करके मूल्यांकन करते हैं। परिणाम 5M वाक्य जोड़े के प्रशिक्षण कॉर्पस के साथ एक अंग्रेजी-से-फ्रांसीसी सेटिंग पर लंबे वाक्यों पर प्रवाह में महत्वपूर्ण वृद्धि दिखाते हैं, जबकि तुलनीय पर्याप्तता को बनाए रखते हैं। हम एक मैनुअल विश्लेषण भी करते हैं जो उस मामले में पर्याप्तता और प्रवाह के बीच ट्रेडऑफ की पड़ताल करता है जहां सभी वाक्य लंबाई पर विचार किया जाता है।</abstract_hi>
      <abstract_ru>Основываясь на последних достижениях в семантическом разборе и упрощении текста, мы исследуем использование семантического разделения исходного предложения в качестве предварительной обработки для машинного перевода. Экспериментируем с трансформаторной моделью и оцениваем с помощью крупномасштабных краудсорсинговых экспериментов. Результаты показывают значительное увеличение беглости в длинных предложениях в англо-французской среде с обучающим корпусом из 5 пар предложений при сохранении сопоставимой адекватности. Мы также проводим ручной анализ, который исследует компромисс между адекватностью и беглостью в случае, когда учитываются все длины предложений.</abstract_ru>
      <abstract_ga>Ag tógáil ar an dul chun cinn a rinneadh le déanaí i bparsáil shéimeantach agus i simpliú téacs, déanaimid imscrúdú ar úsáid scoilteadh shéimeantach na habairte foinse mar réamhphróiseáil d’aistriúchán meaisín. Déanaimid turgnamh le samhail Trasfhoirmeoir agus déanaimid meastóireacht ag baint úsáide as turgnaimh slua-fhoinsithe ar scála mór. Léiríonn torthaí méadú suntasach ar líofacht ar abairtí fada ar shuíomh Béarla-go-Fraincis le corpas oiliúna de phéirí abairtí 5M, agus leordhóthanacht inchomparáide á choinneáil ag an am céanna. Déanaimid anailís láimhe freisin a dhéanann iniúchadh ar an gcomhbhabhtáil idir leordhóthanacht agus líofacht sa chás go ndéantar gach abairt a mheas.</abstract_ga>
      <abstract_hu>A szemantikai elemzés és a szövegegyszerűsítés legutóbbi előrehaladásaira építve vizsgáljuk a forráskód szemantikai felosztásának használatát a gépi fordítás előfeldolgozásaként. Kísérletezünk egy Transformer modellel, és nagyszabású közösségi források kísérletekkel értékeljük. Az eredmények azt mutatják, hogy a hosszú mondatok folyékonyságának jelentős növekedése angol-francia nyelvű környezetben 5 millió mondatpárból álló képzéssel, miközben hasonló megfelelőséget biztosítanak. Kézi elemzést is végezünk, amely feltárja a megfelelőség és a folyékonyság közötti megkülönböztetést abban az esetben, amikor az összes mondathosszt figyelembe vesszük.</abstract_hu>
      <abstract_ka>სემონტიკური პარასტის და ტექსტის განსხვავებაზე, ჩვენ განსხვავებთ სემონტიკური პარასტის გამოყენების გამოყენების გამოყენება, როგორც მაქსინის განსხვავლებისთვის პრეპროცესი. ჩვენ რენსპერიმენტებერის მოდელზე ექსპერიმენტებით გავაკეთებთ და გამოყენებთ დიდი მანძილური crowd-sourcing ექსპერიმენტებით. შედეგი გამოჩვენება მარტივი ფრანგულისთვის განმავლობაში სიგრძნობის გაზრძელება, რომელიც მარტივი მარტივის 5M კოსტატის კოსტატის კოსტატის განმავლობაში, როცა მარტი ჩვენ ასევე ვაკეთებთ ხელსახური ანალიზაცია, რომელიც განსხვავებს შესაძლებლობა და ფუნქციის განმავლობაში, რომელიც ყველა სიტყვების განმავლობა იყოს.</abstract_ka>
      <abstract_el>Με βάση τις πρόσφατες εξελίξεις στη σημασιολογική ανάλυση και την απλοποίηση κειμένου, ερευνούμε τη χρήση της σημασιολογικής διάσπασης της πρότασης προέλευσης ως προεπεξεργασία για τη μηχανική μετάφραση. Πειραματιζόμαστε με ένα μοντέλο μετασχηματιστή και αξιολογούμε χρησιμοποιώντας πειράματα μεγάλης κλίμακας. Τα αποτελέσματα δείχνουν σημαντική αύξηση της ευκρίνειας σε μεγάλες προτάσεις σε ένα περιβάλλον αγγλικά-γαλλικού με εκπαιδευτικό σώμα από ζεύγη προτάσεων 5Μ, διατηρώντας παράλληλα συγκρίσιμη επάρκεια. Επίσης, διεξάγουμε μια χειρωνακτική ανάλυση που διερευνά το συμβιβασμό μεταξύ επάρκειας και ευκρίνειας στην περίπτωση που λαμβάνονται υπόψη όλα τα μήκη των προτάσεων.</abstract_el>
      <abstract_it>Basandoci sui recenti progressi nell'analisi semantica e nella semplificazione del testo, esaminiamo l'uso della divisione semantica della frase sorgente come preprocessing per la traduzione automatica. Sperimentiamo un modello Transformer e valutiamo utilizzando esperimenti di crowd-sourcing su larga scala. I risultati mostrano un significativo aumento della fluidità sulle frasi lunghe in un ambiente inglese-francese con un corpus di formazione di 5M coppie di frasi, pur mantenendo un'adeguatezza comparabile. Eseguiamo anche un'analisi manuale che esplora il compromesso tra adeguatezza e fluidità nel caso in cui tutte le lunghezze delle frasi siano considerate.</abstract_it>
      <abstract_lt>Remdamiesi neseniai padaryta pažanga semantinio analizavimo ir teksto supaprastinimo srityje, mes tiriame semantinio pradinio sakinio padalijimo naudojimą kaip parengiamąjį procesą mašininiam vertimui. Eksperimentuojame su Transformer modeliu ir vertiname naudojant didelio masto visuomenės išteklių eksperimentus. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy.  We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.</abstract_lt>
      <abstract_kk>Семантикалық талдау және мәтін қарапайымдастыру үшін жаңа жағдайларды қолдану үшін біз көзінің семантикалық бөлігін машина аудару үшін алдын- ала түзету үшін зерттеуді зерттеуді. Біз түрлендіру үлгісімен тәжірибе және үлкен көпшілік көпшілік көпшілікті тәжірибелерді қолдануға болады. Нәтижелер 5M мәтінінің жұмыс корпус арқылы ағылшын және французша сөздерінің ұзындық сөздерінің көбіректігін көрсетеді, салыстыруға мүмкін. Біз сондай-ақ қолмен анализ істейміз. Бүкіл сөйлеменің ұзындығын қарастыру үшін адекциялық мен жылдамдықтық арасындағы тәртіпсіздігін зерттеді.</abstract_kk>
      <abstract_mk>Користејќи се на неодамнешните напредоци во семантичното анализирање и поедноставувањето на текстот, ние ја истражуваме употребата на семантичното поделба на изворната реченица како преработка за машински превод. Експериментираме со трансформен модел и проценуваме користејќи големи експерименти за публички извори. Резултатите покажуваат значителен зголемување на течноста на долгите реченици на англиско-француско место со обука на парови од 5 милиони реченици, при што се задржува споредлива адекватност. Исто така, спроведуваме рачна анализа која ја истражува разликата помеѓу соодветноста и течноста во случајот кога се разгледуваат сите должини на речениците.</abstract_mk>
      <abstract_ml>സെമാന്റിക് പാര്‍സിങ്ങിലും ടെക്സ്റ്റ് എളുപ്പമാക്കുന്നതിലും അടുത്തുള്ള മുന്‍ഗണങ്ങള്‍ നിര്‍മ്മിക്കുന്നു, മെഷിന്‍ പരിഭാഷയ്ക്കു നമ്മള്‍ ഒരു ട്രാന്‍സ്ഫോര്‍മാറ്റര്‍ മോഡല്‍ കൊണ്ട് പരീക്ഷിക്കുകയും, വലിയ പ്രാപ്റ്റ് സോര്‍സിങ് പരീക്ഷണങ്ങള്‍ ഉപ അന്ത്യഫലങ്ങള്‍ ഒരു ഇംഗ്ലീഷില്‍ നിന്നും ഫ്രെഞ്ചില്‍ നീണ്ട വാക്കുകളില്‍ നീണ്ട വാക്കുകളില്‍ ഫ്രെഞ്ചില്‍ നീണ്ട വാക്കുകള്‍ കൂടുതല്‍ വലുതാ എല്ലാ വാക്കുകളുടെയും നീളം വിചാരിക്കുന്ന കാര്യത്തില്‍ നമ്മള്‍ ഒരു കൈകാര്യ അന്യായം പ്രവര്‍ത്തിപ്പിക്കുന്നു.</abstract_ml>
      <abstract_mn>Сүүлийн үеийн шинжлэх ухаан болон текст хялбарчлалын тулд бид эх үүсвэрийн өгүүлбэрийг машин орчуулахын тулд анхны үйлдвэрлэхийг судалж байна. Бид Трансформерийн загвартай туршилт хийж, олон нийтийн эх үүсвэрийн туршилтыг ашиглан үнэлэх болно. Үүний үр дүнд англи болон французтай холбоотой урт өгүүлбэрүүдийн тухай 5M өгүүлбэрийн холбоотой сургалтын корпус дээр ихэвчлэн ихэвчлэн байна. Мөн бид бүх өгүүлбэрийн урт нь тодорхойлогдож байгаа тохиолдлыг судлах гарын шинжилгээ хийдэг.</abstract_mn>
      <abstract_no>For å bygge på nyleg avansert i semantisk tolking og tekstforenkling, så undersøker vi bruken av semantisk deleting av kjeldesetninga som forhandtering for maskineoversettelse. Vi eksperimenterer med ein transformeringsmodell og evaluerer med stor masseskaler- eksperimenter. Resultater viser ein signifikant økning i flukt på lange setningar på ein engelsk- til- fransk innstilling med opplæringskorpus med 5M setningar, mens det beholder sammenlignbare adekvitet. Vi utfører også ein handbokanalyse som utforskar utviklinga mellom adekvitet og fluktet i tilfellet der alle setningane vert betrakte.</abstract_no>
      <abstract_pl>Opierając się na ostatnich postępach w parsowaniu semantycznym i uproszczeniu tekstu, badamy zastosowanie semantycznego podziału zdania źródłowego jako wstępnego przetwarzania do tłumaczenia maszynowego. Eksperymentujemy z modelem Transformera i oceniamy za pomocą dużych eksperymentów crowdsourcingowych. Wyniki wskazują na znaczący wzrost płynności w długich zdaniach w otoczeniu angielsko-francuskim z korpusem treningowym 5M par zdań, przy zachowaniu porównywalnej adekwatności. Przeprowadzamy również analizę ręczną, która bada kompromis między adekwatnością a płynnością w przypadku, gdy uwzględnia się wszystkie długości zdania.</abstract_pl>
      <abstract_ro>Bazându-ne pe progresele recente în analizarea semantică și simplificarea textului, investigăm utilizarea divizării semantice a propoziției sursă ca preprocesare pentru traducerea automată. Experimentăm cu un model Transformer și evaluăm utilizând experimente de crowdsourcing la scară largă. Rezultatele arată o creștere semnificativă a fluenței propozițiilor lungi într-un cadru engleză-franceză cu un corpus de formare de 5M perechi de propoziții, păstrând în același timp o adecvare comparabilă. De asemenea, efectuăm o analiză manuală care explorează compromisul dintre adecvare și fluență în cazul în care sunt luate în considerare toate lungimile propozițiilor.</abstract_ro>
      <abstract_sr>Na osnovu nedavnog napreda semantičkog analiza i pojednostavljanja teksta, istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Mi eksperimentiramo sa modelom transformera i procjenjujemo koristeći velike većine eksperimenata koji izvode gomilu. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju sa treninganskim korpusom od par rečenica od 5M, dok zadržavaju usporednu adekvatnost. Takoðe izvršavamo ruènu analizu koja istražuje trgovinu izmeðu adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.</abstract_sr>
      <abstract_so>Buildida horumarinta ugu dambeeya baaritaanka semantika iyo sahlisashada qoraalka, waxaynu baaraynaa isticmaalka kala soocminta qoraalka asalka ah oo loo baaraandegayo turjumidda machine. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments.  Midhaha la’aanta waxaa ka muuqda faa’iido aad u korodhsan dhegaha dhaadheer ee ku qoran af Ingiriis-ilaa-Faraansiis, iyadoo haysta mid u eg labada xabsi 5M. Anagu waxaynu sameynaa baaritaanka dhakhtarka, kaasoo baaraya dhibaatada u dhexeeya saxda iyo faa’iidada marka lagu tiriyo dhererka xukunka oo dhan.</abstract_so>
      <abstract_mt>Filwaqt li nibnu fuq avvanzi reċenti fl-analiżi semantika u s-simplifikazzjoni tat-test, ninvestigaw l-użu tal-qsim semantiku tas-sentenza tas-sors bħala proċessar minn qabel għat-traduzzjoni bil-magna. Aħna ninsperimentaw b’mudell ta’ Transformer u nivvalutaw bl-użu ta’ esperimenti ta’ crowd sourcing fuq skala kbira. Ir-riżultati juru żieda sinifikanti fil-fluwenza fuq sentenzi twal fuq ambjent Ingliż-Franċiż b’korpus ta’ taħriġ ta’ pari ta’ sentenzi ta’ 5M, filwaqt li tinżamm adegwatezza komparabbli. Għandna nagħmlu wkoll analiżi manwali li tesplora l-kompromess bejn l-adegwatezza u l-fluwenza fil-każ fejn it-tul kollu tas-sentenza jiġi kkunsidrat.</abstract_mt>
      <abstract_ms>Membangun pada kemajuan baru-baru ini dalam penghuraian semantik dan pemudahan teks, kami menyelidiki penggunaan pemisahan semantik kalimat sumber sebagai pemprosesan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan menilai menggunakan eksperimen crowd-sourcing skala besar. Hasil menunjukkan peningkatan yang signifikan pada kalimat panjang pada tetapan Inggeris-Perancis dengan korpus latihan pasangan kalimat 5M, sementara menyimpan keperluan yang boleh dibandingkan. Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keseluruhan dalam kes di mana semua panjang kalimat dianggap.</abstract_ms>
      <abstract_si>සෙමැන්ටික් විශ්ලේෂණය සහ පාළුව සරලේෂණය සඳහා අලුත් ප්‍රධානය සඳහා නිර්මාණය කරනවා, අපි පරීක්ෂණය කරන්නේ මුළු වාක්ෂණය අපි පරීක්ෂණය කරන්නේ ත්‍රාණ්පර් මොඩේල් එකක් සමග විශාල පරීක්ෂණය සඳහා ලොකු ප්‍රමාණයක් ප්‍රයෝජනය ප්‍රතිචාරය පෙන්වන්නේ ඉංග්‍රීසියට- ෆ්‍රෑන්සියට ප්‍රශ්නයක් 5M වාක්ෂාවක් ජෝඩියට ප්‍රශ්නයක් තියෙන්නේ ලොක අපි පුළුවන් විශ්ලේෂණයක් කරනවා ඒ වගේම සේරම වාක්ය විශ්ලේෂණයක් පරීක්ෂණය කරනවා කියලා සේරම වාක්ය විශ්</abstract_si>
      <abstract_sv>Utifrån de senaste framstegen inom semantisk tolkning och textförenkling undersöker vi användningen av semantisk uppdelning av källmeningen som förbehandling för maskinöversättning. Vi experimenterar med en Transformer modell och utvärderar med hjälp av storskaliga crowdsourcing-experiment. Resultaten visar en signifikant ökning av flytande på långa meningar i en engelsk-fransk miljö med en träningskorpus på 5M meningspar, samtidigt som jämförbar tillräcklighet bibehålls. Vi utför också en manuell analys som undersöker avvägningen mellan lämplighet och flytande i de fall där alla meningslängder beaktas.</abstract_sv>
      <abstract_ur>سیمنٹی پارسینگ اور ٹیکسٹ سادگی میں اچھی پیشرفت پر بنا رہے ہیں، ہم نے ماشین ترجمہ کے لئے پیش پردازی کے طور پر سیمنٹی پاٹینٹ کے استعمال کا تحقیق کیا ہے. ہم ایک ٹرانسفور موڈل کے ساتھ آزمائش کرتے ہیں اور بڑی اسکیل جماعت سورسینگ آزمائش کے مطابق ارزش کرتے ہیں. نتیجے ایک انگلیسی سے فرانسوی سٹینٹ پر طویل جماعت پر بہت اضافہ ہونے کے لئے 5M جماعت جوڑوں کی تدریس کورپوس کے ساتھ دکھائے جاتے ہیں، جبکہ برابری کے ساتھ قائم رہتے ہیں. ہم نے بھی ایک مہمانی تحلیل کرتا ہے جس میں ہر جماعت کی طول کی نظر کی جاتی ہے اس موقع میں کہ adequacy اور fluency کے درمیان تجارت کا تحقیق کرتا ہے.</abstract_ur>
      <abstract_ta>பெமான்டிக் பாசிங் மற்றும் உரை எளிதாக்கத்தில் சமீபத்தில் முன்னேற்றங்களை உருவாக்குதல் மூலத்தின் பிரிப்பு வாக்கியத்தின் முன் நாங்கள் ஒரு மாற்று மாதிரி முறைமையைக் கொண்டு பரிசோதிக்கிறோம் மற்றும் பெரிய அளவு கூட்டத்தின் மூல மூலம்  @ info: whatsthis நாம் ஒரு கைமுறை ஆராய்ச்சி செய்கிறோம். அது தேவையான மற்றும் விளைவுகளுக்கிடையே இடையேயுள்ள இடைவெளிப்பாட்டை தெரிய</abstract_ta>
      <abstract_uz>@ info: whatsthis Biz Transformer model bilan tizimiz qilamiz va katta ko'pchilik jamoatlar tizimini ishlatish mumkin. @ info: whatsthis Biz qoʻlbola analyzerni bajaramiz va hamma maxsus soʻzni tasavvur qilinadigan holatda yetarli narsalarni o'rganadi.</abstract_uz>
      <abstract_vi>Dựa trên những tiến bộ gần đây về phân tích ngữ pháp và việc đơn giản văn bản, chúng tôi điều tra việc sử dụng chữ thập theo ngữ pháp như việc xử lý trước phiên bản máy. Chúng tôi thử nghiệm với một mô hình transformer và đánh giá bằng cách thí nghiệm buôn lậu diện rộng. Kết quả cho thấy khả năng cao của các án dài trên một trường hợp Anh-Pháp với tập thể huấn của các cặp án 5M, đồng thời giữ mức độ phù hợp tương xứng. Chúng tôi cũng làm một phân tích bằng tay để tìm hiểu sự thỏa thuận giữa sự phù hợp và khéo léo trong trường hợp mọi độ dài các câu nói được xem xét.</abstract_vi>
      <abstract_bg>Въз основа на скорошните постижения в семантичното анализиране и опростяването на текста, изследваме използването на семантично разделяне на изходното изречение като предварителна обработка за машинен превод. Експериментираме с модел на трансформатор и оценяваме с помощта на мащабни експерименти за групово снабдяване. Резултатите показват значително увеличение на владеенето на дълги изречения в английско-френска обстановка с тренировъчен корпус от 5 милиона двойки изречения, като същевременно се запазва сравнима адекватност. Извършваме и ръчен анализ, който изследва компромиса между адекватност и плавност в случая, когато се вземат предвид всички дължини на изреченията.</abstract_bg>
      <abstract_da>Med udgangspunkt i de seneste fremskridt inden for semantisk parsing og tekstforenkling undersøger vi brugen af semantisk opdeling af kildesætningen som forbehandling til maskinoversættelse. Vi eksperimenterer med en Transformer model og evaluerer ved hjælp af store crowd-sourcing eksperimenter. Resultaterne viser en betydelig stigning i flydenhed på lange sætninger på en engelsk-fransk indstilling med et træningskorpus på 5M sætningspar, samtidig med at de bevarer tilsvarende tilstrækkelighed. Vi udfører også en manuel analyse, der undersøger afvigelsen mellem tilstrækkelighed og flydende i tilfælde, hvor alle sætningslængder tages i betragtning.</abstract_da>
      <abstract_nl>Voortbouwend op recente ontwikkelingen in semantische parsing en tekstvereenvoudiging, onderzoeken we het gebruik van semantische splitsing van de bronzin als voorbewerking voor machinevertaling. We experimenteren met een Transformer model en evalueren met behulp van grootschalige crowdsourcing experimenten. De resultaten tonen een significante toename van de vloeibaarheid van lange zinnen in een Engels-Frans setting met een trainingscorpus van 5M zinnenparen, met behoud van vergelijkbare adequaatheid. We voeren ook een handmatige analyse uit die de afweging tussen adequaatheid en vloeiendheid onderzoekt in het geval dat alle zinnenlengtes worden overwogen.</abstract_nl>
      <abstract_hr>Na temelju nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo upotrebu semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod strojeva. Eksperimentiramo s modelom Transformer a i procjenjujemo koristeći velike prometne eksperimente. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju s obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se razmatra dužin a kazne.</abstract_hr>
      <abstract_de>Aufbauend auf den jüngsten Fortschritten in der semantischen Parsing und Textvereinfachung untersuchen wir die Verwendung der semantischen Aufteilung des Ausgangssatzes als Vorverarbeitung für maschinelle Übersetzung. Wir experimentieren mit einem Transformer-Modell und evaluieren diese mithilfe von groß angelegten Crowdsourcing-Experimenten. Die Ergebnisse zeigen einen signifikanten Anstieg der Fließfähigkeit von langen Sätzen in einem Englisch-Französisch Setting mit einem Trainingskorpus aus 5M Satzpaaren bei gleichbleibender Angemessenheit. Wir führen auch eine manuelle Analyse durch, die den Kompromiss zwischen Angemessenheit und Fluency untersucht, wenn alle Satzlängen berücksichtigt werden.</abstract_de>
      <abstract_sw>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  Tunajaribu kwa mtindo wa Transformer na kutathmini kwa kutumia majaribio makubwa yanayotumiwa na vyanzo vya umma. Matokeo yanaonyesha kuongezeka kwa ufanisi mkubwa katika hukumu ndefu juu ya kitendo cha Kiingereza-hadi Kifaransa kinachotumiwa na kikundi cha mafunzo cha kifungo cha wanandoa 5M, wakati wakiendelea kuwa na usawa wa kutosha. Pia tunafanya uchambuzi wa mkono unaoelezea hali ya kutokea kati ya usawa na ufanisi katika kesi ambapo hukumu zote zinachukuliwa kwa muda mrefu.</abstract_sw>
      <abstract_ko>의미 분석과 텍스트 간소화의 최신 진전을 바탕으로 우리는 원어구의 의미 분해를 기계 번역의 예처리로 연구했다.우리는 변압기 모형을 사용하여 실험을 하고 대규모의 패키지 실험을 사용하여 평가를 한다.그 결과 영어-프랑스어 환경에서 500만 개의 문장이 맞는 훈련 어료 라이브러리를 사용하면 긴 문장의 유창도가 현저히 높아지고 상당한 충분성을 유지한 것으로 나타났다.우리는 모든 문장의 길이를 고려할 때 적절성과 유창성 간의 균형을 수동적으로 분석했다.</abstract_ko>
      <abstract_id>Berdasarkan kemajuan baru-baru ini dalam penghuraian semantis dan penyimplifikasi teks, kami menyelidiki penggunaan pemisahan semantis dari kalimat sumber sebagai persiapan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan mengevaluasi menggunakan eksperimen crowd-sourcing skala besar. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy.  Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keterlaluan dalam kasus di mana semua panjang kalimat dianggap.</abstract_id>
      <abstract_fa>بر اساس پیشرفت های اخیر در تجزیه‌سازی و ساده‌سازی متن، ما استفاده از تقسیم‌سازی از جمله منبع به عنوان پیش‌پردازی برای ترجمه‌سازی ماشین تحقیق می‌کنیم. ما با یک مدل تغییر دهنده آزمایش می کنیم و با استفاده از آزمایش‌های سرمایه‌گذاری جمعیت بزرگ ارزیابی می‌کنیم. نتیجه‌ها اضافه‌ای بزرگی بر جمله‌های طولانی در یک تنظیم انگلیسی به فرانسوی با یک جفت آموزشی از جفت‌های جمله 5M نشان می‌دهند، در حالی که قابلیت قابل مقایسه نگه می‌دارند. ما همچنین یک تحلیل دستی انجام می دهیم که تجارت بین عدالت و مایع در مورد هر طول جمله به نظر می رسد، تحقیق می کند.</abstract_fa>
      <abstract_sq>Duke u mbështetur në përparimet e fundit në analizimin semantik dhe thjeshtimin e tekstit, ne hetojmë përdorimin e ndarjes semantike të fjalës së burimit si përgatitje për përkthimin e makinave. Ne eksperimentojmë me një model Transformer dhe vlerësojmë duke përdorur eksperimente të madhe crowd-sourcing. Rezultatet tregojnë një rritje të rëndësishme në fluencën e dënimeve të gjata në një ambient anglez-në-francez me një korpus trajnimi të çifteve të dënimeve 5M, duke mbajtur përshtatshmërinë e krahasueshme. Ne kryejmë gjithashtu një analizë manuale që eksploron kompromisin midis përshtatshmërisë dhe fluencës në rastin ku të gjitha gjatësitë e dënimit konsiderohen.</abstract_sq>
      <abstract_am>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  በተመሳሳይ የብዙው የድምፅ ጉዳይ ፈተና እናረጋግጣለን፡፡ ፍጥረቶቹ በይንግልዝኛ-ወደ ፈረንሳይኛ የ5M ፍርድ ክፍል የረጅም ፈቃድ ውርደት ያሳያል፡፡ የሥርዓት ዕድሜ በሚቆጠሩበት ወቅት መካከል የሚያስፈልገውን ግጭት እናሳውቃለን፡፡</abstract_am>
      <abstract_tr>Semantik anal첵힊inde we metin bejerilmesinde 첵okary geli힊melere 첵체ze 챌yky힊 edip, ma힊yny흫 terjime 체챌in 철흫체nden i힊len첵채n semantik s철zl채ni ulanmagyny barla첵arys. Biz bir Transformer modeli bilen synany힊첵arys we uly 철l챌ekli k철p sourcing deneylerini ulanyp de흫le첵채ris. Netijenler 5M s철zlem 챌ift sanynda u흫 s철zlemler i흫lis챌e- fransuz챌a d체z체mlenme 체챌in 철r채n k철pr채k 체첵tge첵채r, me흫ze힊li 첵erlilikde durul첵ar. Biz hem el analizi yapar캇z. Bu durumda, b체t체n s철zlerin uzunlu휓u d체힊체n체len durumda, adetleik we akyllyk aras캇ndaki ticareti ke힊fetmesini 챌철zer.</abstract_tr>
      <abstract_af>By gebou van onlangse vorderings in semantiese verwerking en teks vereenvoudiging, ondersoek ons die gebruik van semantiese verdeeling van die bron seting as voorafverwerking vir masjien vertaling. Ons eksperimenteer met 'n Transformer model en evalueer met groot-skaal skaal-sourcing eksperimente. Resultate wys 'n betekende versterking in fluiditeit op lange setnings op 'n Engels- na- Frans instelling met 'n oefening korpus van 5M setnings paar, terwyl die vergelykbare adekuasie hou. Ons doen ook 'n handaandeling wat die verkrywing tussen adekuasie en fluiditeit ondersoek in die geval waar al die setlengte beskou word.</abstract_af>
      <abstract_hy>Հիմնվելով սեմանտիկ վերլուծության և տեքստի պարզեցման վերջին առաջընթացների վրա, մենք ուսումնասիրում ենք, թե ինչպես է օգտագործվում աղբյուր նախադասության սեմանտիկ բաժանելը որպես մեքենայի թարգմանման նախամշակում: Մենք փորձում ենք տրանֆորմային մոդելի միջոցով և գնահատում ենք, օգտագործելով մեծ մասշտաբով ժողովրդավար փորձեր: Արդյունքները ցույց են տալիս, որ երկար նախադասությունների ճկունության մեծ աճ է անգլերեն-ֆրանսիացի միջավայրում 5M նախադասությունների զույգերի ուսումնասիրության կորպոսի հետ, մինչդեռ համեմատությունը պահպանվում է: We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.</abstract_hy>
      <abstract_bn>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation.  আমরা একটি ট্রান্সফ্রান্সফার মডেল দিয়ে পরীক্ষা করি এবং বিশাল মানুষ-সোর্সিং পরীক্ষা ব্যবহার করে মূল্যায়ন করি। ফলাফল দেখা যাচ্ছে একটি ইংরেজি থেকে ফ্রেঞ্চ ব্যবহারের উপর দীর্ঘ শাস্তিতে প্রভাব বৃদ্ধি প্রদর্শন করা হয়েছে, যার প্রশিক্ষণ ৫ এম কারাদণ্ডের জোড় আমরা একই সাথে একটি হাতিয়াল বিশ্লেষণ করি যা যথাযথ এবং প্রভাবের মধ্যে ব্যাপারটি বিশ্লেষণ করে যেখানে সকল বাক্যের দীর্ঘ সময় বিবেচন</abstract_bn>
      <abstract_az>Semantik ayırma və metin basitləşdirməsi üçün yeni ilerləşmələri in şa etdik, maşın tercüməsi üçün ilk işləmə üçün mənbə cümləsinin semantik ayırmasını araşdırırıq. Biz bir Transformer modeli ilə təcrübə edirik və böyük ölçüdə qüvvətli təcrübələr vasitəsilə təcrübə edirik. Sonuçlar 5 M cümləlik çiftlərinin təhsil korpusu ilə İngilizə-Fransızca təhsil edilməsi üçün uzun cümlələr üzərində böyüklük artırmağı göstərər, müqayisədə uyğunluğu saxlayaraq. Biz həmçin in bütün cümlələrin uzunluğunu düşündüyü təqdirdə adeqliyyat və fərqliyyat arasındakı ticarəti keşfetən əlavə analizi çəkirik.</abstract_az>
      <abstract_bs>Na osnovu nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Eksperimentiramo sa modelom Transformer a i procjenjujemo koristeći velike gomilu-izvorenje eksperimenata. Rezultati pokazuju značajno povećanje tečnosti na dugim rečenicama na engleskom i francuskom postavljanju sa obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.</abstract_bs>
      <abstract_cs>Na základě nedávných pokroků v oblasti sémantického parsování a zjednodušení textu zkoumáme využití sémantického rozdělení zdrojové věty jako předzpracování pro strojový překlad. Experimentujeme s transformátorovým modelem a hodnotíme pomocí rozsáhlých crowdsourcingových experimentů. Výsledky ukazují výrazný nárůst plynulosti dlouhých vět v anglicko-francouzském prostředí s výcvikovým korpusem 5M větových párů při zachování srovnatelné adekvátnosti. Dále provádíme manuální analýzu, která zkoumá kompromis mezi adekvátností a plynulostí v případě, kdy jsou zohledněny všechny délky věty.</abstract_cs>
      <abstract_ca>Construïnt-nos en avanços recents en l'analització semàntica i la simplificació del text, investigam l'ús de la divisió semàntica de la frase fontcom a preparació per a la traducció automàtica. Experimentem amb un model Transformer i evaluem fent servir experiments de crowd sourcing a gran escala. Els resultats mostren un augment significatiu de fluència en frases llargues en un entorn anglès-francès amb un cos d'entrenament de parells de frases de 5M, mantenint la adequació comparable. També fem una anàlisi manual que explora el compromís entre adequació i fluïtat en el cas en què es consideren totes les llargues de frases.</abstract_ca>
      <abstract_et>Tuginedes hiljutistele edusammudele semantilises parsimises ja teksti lihtsustamises, uurime lähtelause semantilise jagamise kasutamist masintõlke eeltöötlusena. Me eksperimenteerime Transformeri mudeliga ja hindame suuremahuliste ühishankimise katsete abil. Tulemused näitavad, et pikkade lausete sujuva oskuse märkimisväärne suurenemine inglise-prantsuse keeles, kus koolituskorpus koosneb 5 miljonist lausepaarist, säilitades samas võrreldava piisavuse. Samuti teostame käsitsi analüüsi, mis uurib kompromisse piisavuse ja sujuvuse vahel juhul, kui arvestatakse kõiki lausepikkusi.</abstract_et>
      <abstract_fi>Seminttisen jäsentämisen ja tekstin yksinkertaistamisen viimeaikaisen kehityksen pohjalta tutkimme lähdelauseen semanttisen jakamisen käyttöä konekäännöksen esikäsittelyssä. Kokeilemme Transformer-mallia ja arvioimme sen laajamittaisilla joukkohankintakokeiluilla. Tulokset osoittavat, että pitkien lauseiden sujuvuus lisääntyi merkittävästi englanti-ranska-ympäristössä, kun koulutuskorpus oli 5 miljoonaa lauseparia. Teemme myös manuaalisen analyysin, jossa selvitetään riittävyyden ja sujuvuuden välistä kompromissia siinä tapauksessa, että kaikki lauseen pituudet otetaan huomioon.</abstract_fi>
      <abstract_jv>Daerah ono nggawe advances in semanti karo semanti karo perusahaan teks semanti, kita yatênggunaé perusahaan semanti nggawe aturan kelompok nggawe barang kelompok nggawe sistem tarjamahan. Awak dhéwé éntuk karo model Transformer kuwi nggawe nyimpen banter-kalaha ujaran. Pamita puteh ngomong kedhanan langkung dolanan kapan-dolanan nganggo dolanan ingkang karo- Perancis Awak dhéwé éntuk manut karo hal-manut sing bisa mlebu nggawe gerakan gambar deweke karo kapan kanggo ngilanggar kuwi kesempatan kanggo nggawe barang langgar kuwi.</abstract_jv>
      <abstract_he>בניין על התקדמות האחרונות באבחן סמנטי ופשטות טקסט, אנו חוקרים את השימוש בהחלקה סמנטית של המשפט המקורי כהתהליך לתרגום מכונות. אנו מנסים עם מודל טרנספורר ומעריכים בשימוש ניסויים במקורי קהל גדולים. התוצאות מראות עלייה משמעותית במשפטים ארוכים במצב אנגלי-צרפתי עם גוף אימון של זוגות משפטים של 5 מיליון, בזמן שמירה מתאימה שווה. אנו גם מבצעים ניתוח ידני שמחקר את ההחלטה בין התאימות לבין השקטות במקרה שבו כל אורך המשפט נחשב.</abstract_he>
      <abstract_ha>Tsarin da aka samu masu ƙara cikin parse na semantic da mai sauƙin matsayi, za'a yi ƙidãya wa amfani da cutarwa na semantic ko pre-zartar da fassarar maɓalli. Za jarraba da wani misali mai Transformer kuma tuna hakar jarrabo masu girma ga mutane-sourcen. Mataimakin na nuna significant ƙari ga furuci a kan sauran da aka daidaita na Ingiriya-zuwa-French mai daidaita da wani shirin cire-nau'in 5 M, kuma yana retain daidai. Tuna sami wani anayyar da hannun aiki wanda ke jarraba fatauci tsakanin da kuma ma'ishi idan an yi bincike da duk cire.</abstract_ha>
      <abstract_sk>Na podlagi nedavnega napredka semantičnega razčlenjanja in poenostavitve besedila raziskujemo uporabo semantičnega razdelitve izvornega stavka kot predobdelave za strojno prevajanje. Eksperimentiramo s transformatorskim modelom in ocenjujemo z uporabo obsežnih množičnih eksperimentov. Rezultati kažejo znatno povečanje tekočosti pri dolgih stavkih v angleško-francoskem okolju s korpusom usposabljanja 5 M parov stavkov, ob ohranjanju primerljive ustreznosti. Izvajamo tudi ročno analizo, ki raziskuje kompromis med ustreznostjo in tekočostjo v primeru, ko upoštevamo vse dolžine stavka.</abstract_sk>
      <abstract_bo>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. ང་ཚོས་གཞུང་བཟོ་བྱེད་པའི་མ་དབུགས་ཞིག་གིས་བརྟག་དཔྱད་བྱེད་ཀྱི་ཡོད་ཚད་ཆེན་པོ་ཞིག་གིས་ གྲུབ་འབྲས་གཞི་ལྟ་བུའི་ཚིག་རྐང་ཐག་གཅིག་ལས་དབྱིན་ཡིག་གཟུགས་འགྱུར་བ་སྐྱེལ་ཅན་ཏུ་མངོན་གསལ་གཏོང་། ང་ཚོས་དུས་མཐུན་དང་དཔྱད་དབར་གྱི་བཟོ་བཅོས་ལ་ལག་བཟོས་དཔྱད་ཞིག་བྱེད་ཀྱི་ཡོད་པ་ཞིག་གནང་བ་རེད།</abstract_bo>
      </paper>
    <paper id="10">
      <title>On the Systematicity of Probing Contextualized Word Representations : The Case of <a href="https://en.wikipedia.org/wiki/Hypernymy">Hypernymy</a> in BERT<fixed-case>BERT</fixed-case></title>
      <author><first>Abhilasha</first><last>Ravichander</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Kaheer</first><last>Suleman</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>88–102</pages>
      <abstract>Contextualized word representations have become a driving force in <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, motivating widespread interest in understanding their capabilities and the mechanisms by which they operate. Particularly intriguing is their ability to identify and encode conceptual abstractions. Past work has probed BERT representations for this competence, finding that BERT can correctly retrieve noun hypernyms in cloze tasks. In this work, we ask the question : do probing studies shed light on systematic knowledge in BERT representations? As a case study, we examine <a href="https://en.wikipedia.org/wiki/Hypernymy">hypernymy knowledge</a> encoded in BERT representations. In particular, we demonstrate through a simple consistency probe that the ability to correctly retrieve hypernyms in cloze tasks, as used in prior work, does not correspond to systematic knowledge in BERT. Our main conclusion is cautionary : even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT ‘understands’ a concept, and it can not be expected to systematically generalize across applicable contexts.<i>do probing studies shed light on systematic knowledge in BERT representations?</i> As a case study, we examine hypernymy knowledge encoded in BERT representations. In particular, we demonstrate through a simple consistency probe that the ability to correctly retrieve hypernyms in cloze tasks, as used in prior work, does not correspond to systematic knowledge in BERT. Our main conclusion is cautionary: even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT ‘understands’ a concept, and it cannot be expected to systematically generalize across applicable contexts.</abstract>
      <url hash="d5175d88">2020.starsem-1.10</url>
      <bibkey>ravichander-etal-2020-systematicity</bibkey>
      <pwccode url="https://github.com/abhilasharavichander/probe-generalization" additional="false">abhilasharavichander/probe-generalization</pwccode>
    </paper>
    <paper id="14">
      <title>PISA : A measure of Preference In Selection of Arguments to model verb argument recoverability<fixed-case>PISA</fixed-case>: A measure of Preference In Selection of Arguments to model verb argument recoverability</title>
      <author><first>Giulia</first><last>Cappelli</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>131–136</pages>
      <abstract>Our paper offers a computational model of the semantic recoverability of verb arguments, tested in particular on direct objects and Instruments. Our fully distributional model is intended to improve on older taxonomy-based models, which require a lexicon in addition to the training corpus. We computed the selectional preferences of 99 transitive verbs and 173 Instrument verbs as the mean value of the pairwise cosines between their arguments (a weighted mean between all the arguments, or an unweighted mean with the topmost k arguments). Results show that our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> can predict the recoverability of objects and Instruments, providing a similar result to that of taxonomy-based models but at a much cheaper computational cost.</abstract>
      <url hash="656f804c">2020.starsem-1.14</url>
      <bibkey>cappelli-lenci-2020-pisa</bibkey>
      <pwccode url="https://github.com/ellepannitto/pisa" additional="false">ellepannitto/pisa</pwccode>
    </paper>
    <paper id="15">
      <title>Learning Negation Scope from <a href="https://en.wikipedia.org/wiki/Syntactic_structure">Syntactic Structure</a></title>
      <author><first>Nick</first><last>McKenna</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>137–142</pages>
      <abstract>We present a <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised model</a> which learns the semantics of negation purely through <a href="https://en.wikipedia.org/wiki/Syntactic_analysis">analysis of syntactic structure</a>. Linguistic theory posits that the semantics of negation can be understood purely syntactically, though recent research relies on combining a variety of features including <a href="https://en.wikipedia.org/wiki/Part-of-speech_tagging">part-of-speech tags</a>, <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>, and semantic representations to achieve high task performance. Our simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> and <a href="https://en.wikipedia.org/wiki/Negation">semantics of negation</a>.</abstract>
      <url hash="34a7b18c">2020.starsem-1.15</url>
      <bibkey>mckenna-steedman-2020-learning</bibkey>
    </paper>
    </volume>
</collection>