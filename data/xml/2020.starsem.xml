<collection id="2020.starsem">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics</booktitle>
      <editor><first>Iryna</first><last>Gurevych</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Manaal</first><last>Faruqui</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="cb1bed58">2020.starsem-1.0</url>
      <bibkey>sem-2020-joint</bibkey>
    </frontmatter>
    <paper id="6">
      <title>Semantic Structural Decomposition for Neural Machine Translation</title>
      <author><first>Elior</first><last>Sulem</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <author><first>Ari</first><last>Rappoport</last></author>
      <pages>50&#8211;57</pages>
      <abstract>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy. We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.</abstract>
      <url hash="e26db7a4">2020.starsem-1.6</url>
      <bibkey>sulem-etal-2020-semantic</bibkey>
      <pwccode url="https://github.com/eliorsulem/semantic-structural-decomposition-for-nmt" additional="false">eliorsulem/semantic-structural-decomposition-for-nmt</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikisplit">WikiSplit</pwcdataset>
    </paper>
    <paper id="10">
      <title>On the Systematicity of Probing Contextualized Word Representations: The Case of Hypernymy in <fixed-case>BERT</fixed-case></title>
      <author><first>Abhilasha</first><last>Ravichander</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <author><first>Kaheer</first><last>Suleman</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>88&#8211;102</pages>
      <abstract>Contextualized word representations have become a driving force in NLP, motivating widespread interest in understanding their capabilities and the mechanisms by which they operate. Particularly intriguing is their ability to identify and encode conceptual abstractions. Past work has probed BERT representations for this competence, finding that BERT can correctly retrieve noun hypernyms in cloze tasks. In this work, we ask the question: <i>do probing studies shed light on systematic knowledge in BERT representations?</i> As a case study, we examine hypernymy knowledge encoded in BERT representations. In particular, we demonstrate through a simple consistency probe that the ability to correctly retrieve hypernyms in cloze tasks, as used in prior work, does not correspond to systematic knowledge in BERT. Our main conclusion is cautionary: even if BERT demonstrates high probing accuracy for a particular competence, it does not necessarily follow that BERT &#8216;understands&#8217; a concept, and it cannot be expected to systematically generalize across applicable contexts.</abstract>
      <url hash="d5175d88">2020.starsem-1.10</url>
      <bibkey>ravichander-etal-2020-systematicity</bibkey>
      <pwccode url="https://github.com/abhilasharavichander/probe-generalization" additional="false">abhilasharavichander/probe-generalization</pwccode>
    </paper>
    <paper id="14">
      <title><fixed-case>PISA</fixed-case>: A measure of Preference In Selection of Arguments to model verb argument recoverability</title>
      <author><first>Giulia</first><last>Cappelli</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>131&#8211;136</pages>
      <abstract>Our paper offers a computational model of the semantic recoverability of verb arguments, tested in particular on direct objects and Instruments. Our fully distributional model is intended to improve on older taxonomy-based models, which require a lexicon in addition to the training corpus. We computed the selectional preferences of 99 transitive verbs and 173 Instrument verbs as the mean value of the pairwise cosines between their arguments (a weighted mean between all the arguments, or an unweighted mean with the topmost k arguments). Results show that our model can predict the recoverability of objects and Instruments, providing a similar result to that of taxonomy-based models but at a much cheaper computational cost.</abstract>
      <url hash="656f804c">2020.starsem-1.14</url>
      <bibkey>cappelli-lenci-2020-pisa</bibkey>
      <pwccode url="https://github.com/ellepannitto/pisa" additional="false">ellepannitto/pisa</pwccode>
    </paper>
    <paper id="15">
      <title>Learning Negation Scope from Syntactic Structure</title>
      <author><first>Nick</first><last>McKenna</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>137&#8211;142</pages>
      <abstract>We present a semi-supervised model which learns the semantics of negation purely through analysis of syntactic structure. Linguistic theory posits that the semantics of negation can be understood purely syntactically, though recent research relies on combining a variety of features including part-of-speech tags, word embeddings, and semantic representations to achieve high task performance. Our simplified model returns to syntactic theory and achieves state-of-the-art performance on the task of Negation Scope Detection while demonstrating the tight relationship between the syntax and semantics of negation.</abstract>
      <url hash="34a7b18c">2020.starsem-1.15</url>
      <bibkey>mckenna-steedman-2020-learning</bibkey>
    </paper>
    </volume>
</collection>