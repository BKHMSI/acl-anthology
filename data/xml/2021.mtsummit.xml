<?xml version='1.0' encoding='utf-8'?>
<collection id="2021.mtsummit">
  <volume id="research" ingest-date="2021-08-14">
    <meta>
      <booktitle>Proceedings of Machine Translation Summit XVIII: Research Track</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Kevin</first><last>Duh</last></editor>
      <editor><first>Francisco</first><last>Guzmán</last></editor>
      <url hash="7b81460c">2021.mtsummit-research</url>
    </meta>
    <frontmatter>
      <url hash="d25ee171">2021.mtsummit-research.0</url>
      <bibkey>mtsummit-2021-biennial</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Learning Curricula for Multilingual Neural Machine Translation Training</title>
      <author><first>Gaurav</first><last>Kumar</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <author><first>Sanjeev</first><last>Khudanpur</last></author>
      <pages>1-9</pages>
      <url hash="d1a0e709">2021.mtsummit-research.1</url>
      <abstract>Low-resource Multilingual Neural Machine Translation (MNMT) is typically tasked with improving the <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance on one or more language pairs with the aid of high-resource language pairs. In this paper and we propose two simple search based curricula   orderings of the multilingual training data   which help improve <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance in conjunction with existing techniques such as <a href="https://en.wikipedia.org/wiki/Fine-tuning">fine-tuning</a>. Additionally and we attempt to learn a <a href="https://en.wikipedia.org/wiki/Curriculum">curriculum</a> for MNMT from scratch jointly with the training of the translation system using contextual multi-arm bandits. We show on the FLORES low-resource translation dataset that these learned curricula can provide better starting points for fine tuning and improve overall performance of the translation system.</abstract>
      <bibkey>kumar-etal-2021-learning-curricula</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/flores">FLoRes</pwcdataset>
    </paper>
    <paper id="5">
      <title>Transformers for Low-Resource Languages : Is Fidir Linn !</title>
      <author><first>Seamus</first><last>Lankford</last></author>
      <author><first>Haithem</first><last>Alfi</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>48-60</pages>
      <url hash="c2adacfa">2021.mtsummit-research.5</url>
      <abstract>The Transformer model is the state-of-the-art in <a href="https://en.wikipedia.org/wiki/Machine_translation">Machine Translation</a>. However and in general and neural translation models often under perform on language pairs with insufficient training data. As a consequence and relatively few experiments have been carried out using this <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> on low-resource language pairs. In this study and hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly and the correct choice of subword model is shown to be the biggest driver of <a href="https://en.wikipedia.org/wiki/Translation">translation</a> performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers and testing various <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization techniques</a> and evaluating the optimal number of heads for <a href="https://en.wikipedia.org/wiki/Attention">attention</a>. A generic 55k DGT corpus and an in-domain 88k public admin corpus were used for evaluation. A Transformer optimized model demonstrated a BLEU score improvement of 7.8 points when compared with a baseline <a href="https://en.wikipedia.org/wiki/Real-time_locating_system">RNN model</a>. Improvements were observed across a range of metrics and including TER and indicating a substantially reduced post editing effort for Transformer optimized models with 16k BPE subword models. Bench-marked against <a href="https://en.wikipedia.org/wiki/Google_Translate">Google Translate</a> and our translation engines demonstrated significant improvements. The question of whether or not <a href="https://en.wikipedia.org/wiki/Transformers_(toy_line)">Transformers</a> can be used effectively in a low-resource setting of English-Irish translation has been addressed. Is fidir linn-yes we can.</abstract>
      <bibkey>lankford-etal-2021-transformers</bibkey>
    </paper>
    <paper id="6">
      <title>The Effect of Domain and Diacritics in YorubaEnglish Neural Machine Translation<fixed-case>Y</fixed-case>oruba–<fixed-case>E</fixed-case>nglish Neural Machine Translation</title>
      <author><first>David</first><last>Adelani</last></author>
      <author><first>Dana</first><last>Ruiter</last></author>
      <author><first>Jesujoba</first><last>Alabi</last></author>
      <author><first>Damilola</first><last>Adebonojo</last></author>
      <author><first>Adesina</first><last>Ayeni</last></author>
      <author><first>Mofe</first><last>Adeyemi</last></author>
      <author><first>Ayodele Esther</first><last>Awokoya</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <pages>61-75</pages>
      <url hash="2a7fbaa1">2021.mtsummit-research.6</url>
      <abstract>Massively multilingual machine translation (MT) has shown impressive capabilities and including zero and few-shot translation between low-resource language pairs. However and these <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> are often evaluated on high-resource languages with the assumption that they generalize to low-resource ones. The difficulty of evaluating MT models on low-resource pairs is often due to lack of standardized evaluation datasets. In this paper and we present MENYO-20k and the first multi-domain parallel corpus with a especially curated orthography for YorubaEnglish with standardized train-test splits for benchmarking. We provide several neural MT benchmarks and compare them to the performance of popular pre-trained (massively multilingual) MT models both for the heterogeneous test set and its subdomains. Since these pre-trained models use huge amounts of data with uncertain quality and we also analyze the effect of diacritics and a major characteristic of <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a> and in the training data. We investigate how and when this training condition affects the final quality of a translation and its understandability. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">models</a> outperform massively multilingual models such as Google (+8.7 BLEU) and Facebook M2 M (+9.1) when translating to <a href="https://en.wikipedia.org/wiki/Yoruba_language">Yoruba</a> and setting a high quality benchmark for future research.<tex-math>+8.7</tex-math> BLEU) and Facebook M2M (<tex-math>+9.1</tex-math>) when translating to Yoruba and setting a high quality benchmark for future research.</abstract>
      <bibkey>adelani-etal-2021-effect</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/jw300">JW300</pwcdataset>
    </paper>
    <paper id="9">
      <title>Like Chalk and Cheese? On the Effects of Translationese in MT Training<fixed-case>MT</fixed-case> Training</title>
      <author><first>Samuel</first><last>Larkin</last></author>
      <author><first>Michel</first><last>Simard</last></author>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <pages>103-113</pages>
      <url hash="2449aac9">2021.mtsummit-research.9</url>
      <abstract>We revisit the topic of translation direction in the data used for training neural machine translation systems and focusing on a real-world scenario with known translation direction and imbalances in translation direction : the Canadian Hansard. According to automatic metrics and we observe that using parallel data that was produced in the matching translation direction (Authentic source and translationese target) improves translation quality. In cases of data imbalance in terms of translation direction and we find that tagging of translation direction can close the performance gap. We perform a human evaluation that differs slightly from the automatic metrics and but nevertheless confirms that for this French-English dataset that is known to contain high-quality translations and authentic or tagged mixed source improves over translationese source for training.</abstract>
      <bibkey>larkin-etal-2021-like</bibkey>
    </paper>
    <paper id="10">
      <title>Investigating Softmax Tempering for Training Neural Machine Translation Models</title>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>114-126</pages>
      <url hash="c2c0d716">2021.mtsummit-research.10</url>
      <abstract>Neural machine translation (NMT) models are typically trained using a softmax cross-entropy loss where the softmax distribution is compared against the gold labels. In low-resource scenarios and NMT models tend to perform poorly because the model training quickly converges to a point where the softmax distribution computed using <a href="https://en.wikipedia.org/wiki/Logit">logits</a> approaches the gold label distribution. Although label smoothing is a well-known solution to address this issue and we further propose to divide the logits by a <a href="https://en.wikipedia.org/wiki/Temperature_coefficient">temperature coefficient</a> greater than one and forcing the softmax distribution to be smoother during training. This makes it harder for the <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to quickly over-fit. In our experiments on 11 language pairs in the low-resource Asian Language Treebank dataset and we observed significant improvements in translation quality. Our analysis focuses on finding the right balance of label smoothing and softmax tempering which indicates that they are orthogonal methods. Finally and a study of softmax entropies and gradients reveal the impact of our method on the internal behavior of our NMT models.</abstract>
      <bibkey>dabre-fujita-2021-investigating</bibkey>
    </paper>
    <paper id="11">
      <title>Scrambled Translation Problem : A Problem of Denoising UNMT<fixed-case>UNMT</fixed-case></title>
      <author><first>Tamali</first><last>Banerjee</last></author>
      <author><first>Rudra</first><last>V Murthy</last></author>
      <author><first>Pushpak</first><last>Bhattacharya</last></author>
      <pages>127-138</pages>
      <url hash="92ca6c7d">2021.mtsummit-research.11</url>
      <abstract>In this paper and we identify an interesting kind of error in the output of Unsupervised Neural Machine Translation (UNMT) systems like Undreamt1. We refer to this error type as Scrambled Translation problem. We observe that UNMT models which use word shuffle noise (as in case of Undreamt) can generate correct words and but fail to stitch them together to form phrases. As a result and words of the translated sentence look scrambled and resulting in decreased <a href="https://en.wikipedia.org/wiki/BLEU">BLEU</a>. We hypothesise that the reason behind scrambled translation problem is’ shuffling noise’ which is introduced in every input sentence as a <a href="https://en.wikipedia.org/wiki/Noise_reduction">denoising strategy</a>. To test our hypothesis and we experiment by retraining UNMT models with a simple retraining strategy. We stop the training of the Denoising UNMT model after a pre-decided number of iterations and resume the training for the remaining iterations- which number is also pre-decided- using original sentence as input without adding any noise. Our proposed <a href="https://en.wikipedia.org/wiki/Solution">solution</a> achieves significant performance improvement UNMT models that train conventionally. We demonstrate these performance gains on four language pairs and viz. and English-French and English-German and English-Spanish and Hindi-Punjabi. Our qualitative and quantitative analysis shows that the retraining strategy helps achieve better alignment as observed by attention heatmap and better phrasal translation and leading to statistically significant improvement in BLEU scores.</abstract>
      <bibkey>banerjee-etal-2021-scrambled</bibkey>
    </paper>
    <paper id="14">
      <title>On nature and causes of observed MT errors<fixed-case>MT</fixed-case> errors</title>
      <author><first>Maja</first><last>Popovic</last></author>
      <pages>163-175</pages>
      <url hash="e5ca11cd">2021.mtsummit-research.14</url>
      <abstract>This work describes analysis of nature and causes of MT errors observed by different evaluators under guidance of different quality criteria : <a href="https://en.wikipedia.org/wiki/Adequality">adequacy</a> and <a href="https://en.wikipedia.org/wiki/Comprehension_(logic)">comprehension</a> and and a not specified generic mixture of <a href="https://en.wikipedia.org/wiki/Adequality">adequacy</a> and <a href="https://en.wikipedia.org/wiki/Fluency">fluency</a>. We report results for three language pairs and two domains and eleven MT systems. Our findings indicate that and despite the fact that some of the identified phenomena depend on domain and/or language and the following set of phenomena can be considered as generally challenging for modern MT systems : rephrasing groups of words and translation of ambiguous source words and translating noun phrases and and mistranslations. Furthermore and we show that the quality criterion also has impact on error perception. Our findings indicate that <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a> and adequacy can be assessed simultaneously by different evaluators and so that <a href="https://en.wikipedia.org/wiki/Sentence_processing">comprehension</a> and as an important quality criterion and can be included more often in human evaluations.</abstract>
      <bibkey>popovic-2021-nature</bibkey>
      <pwccode url="https://github.com/awslabs/sockeye" additional="false">awslabs/sockeye</pwccode>
    </paper>
    <paper id="17">
      <title>Studying The Impact Of Document-level Context On Simultaneous Neural Machine Translation</title>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Aizhan</first><last>Imankulova</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <pages>202-214</pages>
      <url hash="2c986a6a">2021.mtsummit-research.17</url>
      <abstract>In a real-time simultaneous translation setting and neural machine translation (NMT) models start generating target language tokens from incomplete source language sentences and making them harder to translate and leading to poor translation quality. Previous research has shown that document-level NMT and comprising of sentence and context encoders and a decoder and leverages context from neighboring sentences and helps improve translation quality. In simultaneous translation settings and the context from previous sentences should be even more critical. To this end and in this paper and we propose wait-k simultaneous document-level NMT where we keep the context encoder as it is and replace the source sentence encoder and target language decoder with their wait-k equivalents. We experiment with low and high resource settings using the ALT and OpenSubtitles2018 corpora and where we observe minor improvements in translation quality. We then perform an analysis of the translations obtained using our models by focusing on sentences that should benefit from the context where we found out that the model does and in fact and benefit from context but is unable to effectively leverage it and especially in a low-resource setting. This shows that there is a need for further innovation in the way useful context is identified and leveraged.</abstract>
      <bibkey>dabre-etal-2021-studying</bibkey>
    </paper>
    <paper id="18">
      <title>Attainable Text-to-Text Machine Translation vs. <a href="https://en.wikipedia.org/wiki/Translation">Translation</a> : Issues Beyond Linguistic Processing</title>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <pages>215-230</pages>
      <url hash="a0a1548f">2021.mtsummit-research.18</url>
      <abstract>Existing approaches for machine translation (MT) mostly translate given text in the source language into the target language and without explicitly referring to information indispensable for producing proper <a href="https://en.wikipedia.org/wiki/Translation">translation</a>. This includes not only information in other textual elements and modalities than texts in the same document and but also extra-document and non-linguistic information and such as <a href="https://en.wikipedia.org/wiki/Social_norm">norms</a> and <a href="https://en.wikipedia.org/wiki/Skopos">skopos</a>. To design better translation production work-flows and we need to distinguish translation issues that could be resolved by the existing text-to-text approaches and those beyond them. To this end and we conducted an analytic assessment of MT outputs and taking an English-to-Japanese news translation task as a case study. First and examples of <a href="https://en.wikipedia.org/wiki/Translation">translation issues</a> and their revisions were collected by a two-stage post-editing (PE) method : performing minimal PE to obtain <a href="https://en.wikipedia.org/wiki/Translation">translation</a> attainable based on the given textual information and further performing full PE to obtain truly acceptable <a href="https://en.wikipedia.org/wiki/Translation">translation</a> referring to any information if necessary. Then and the collected revision examples were manually analyzed. We revealed dominant issues and information indispensable for resolving them and such as fine-grained style specifications and terminology and domain-specific knowledge and and reference documents and delineating a clear distinction between <a href="https://en.wikipedia.org/wiki/Translation">translation</a> and what text-to-text MT can ultimately attain.</abstract>
      <bibkey>fujita-2021-attainable</bibkey>
      <pwccode url="https://github.com/akfujita/staged-pe" additional="false">akfujita/staged-pe</pwccode>
    </paper>
    <paper id="19">
      <title>Modeling Target-side Inflection in Placeholder Translation</title>
      <author><first>Ryokan</first><last>Ri</last></author>
      <author><first>Toshiaki</first><last>Nakazawa</last></author>
      <author><first>Yoshimasa</first><last>Tsuruoka</last></author>
      <pages>231-242</pages>
      <url hash="6bd323a3">2021.mtsummit-research.19</url>
      <abstract>Placeholder translation systems enable the users to specify how a specific phrase is translated in the output sentence. The system is trained to output special placeholder tokens and the user-specified term is injected into the output through the context-free replacement of the placeholder token. However and this approach could result in ungrammatical sentences because it is often the case that the specified term needs to be inflected according to the context of the output and which is unknown before the translation. To address this problem and we propose a novel method of placeholder translation that can inflect specified terms according to the <a href="https://en.wikipedia.org/wiki/Grammar">grammatical construction</a> of the output sentence. We extend the seq2seq architecture with a character-level decoder that takes the lemma of a user-specified term and the words generated from the word-level decoder to output a correct inflected form of the lemma. We evaluate our approach with a Japanese-to-English translation task in the scientific writing domain and and show our model can incorporate specified terms in a correct form more successfully than other comparable models.</abstract>
      <bibkey>ri-etal-2021-modeling</bibkey>
      <pwccode url="https://github.com/Ryou0634/placeholder_translation" additional="false">Ryou0634/placeholder_translation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/aspec">ASPEC</pwcdataset>
    </paper>
    <paper id="23">
      <title>Neural Machine Translation with Inflected Lexicon</title>
      <author><first>Artur</first><last>Nowakowski</last></author>
      <author><first>Krzysztof</first><last>Jassem</last></author>
      <pages>282-292</pages>
      <url hash="3e6e063b">2021.mtsummit-research.23</url>
      <abstract>The paper presents experiments in <a href="https://en.wikipedia.org/wiki/Neural_machine_translation">neural machine translation</a> with <a href="https://en.wikipedia.org/wiki/Lexical_analysis">lexical constraints</a> into a <a href="https://en.wikipedia.org/wiki/Morphological_analysis">morphologically rich language</a>. In particular and we introduce a method and based on constrained decoding and which handles the inflected forms of lexical entries and does not require any modification to the training data or model architecture. To evaluate its effectiveness and we carry out experiments in two different scenarios : general and domain-specific. We compare our <a href="https://en.wikipedia.org/wiki/Methodology">method</a> with baseline translation and i.e. translation without <a href="https://en.wikipedia.org/wiki/Lexical_item">lexical constraints</a> and in terms of translation speed and <a href="https://en.wikipedia.org/wiki/Translation">translation quality</a>. To evaluate how well the method handles the constraints and we propose new evaluation metrics which take into account the presence and placement and duplication and inflectional correctness of lexical terms in the output sentence.</abstract>
      <bibkey>nowakowski-jassem-2021-neural</bibkey>
    </paper>
    </volume>
  <volume id="asltrw" ingest-date="2021-08-19">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Automatic Spoken Language Translation in Real-World Settings (ASLTRW)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <editor><first>Claudio</first><last>Fantinuoli</last></editor>
      <url hash="7eb0fa67">2021.mtsummit-asltrw</url>
    </meta>
    <frontmatter>
      <url hash="b1f110cd">2021.mtsummit-asltrw.0</url>
      <bibkey>mtsummit-2021-automatic</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Seed Words Based Data Selection for Language Model Adaptation</title>
      <author><first>Roberto</first><last>Gretter</last></author>
      <author><first>Marco</first><last>Matassoni</last></author>
      <author><first>Daniele</first><last>Falavigna</last></author>
      <pages>1-12</pages>
      <url hash="b0308a90">2021.mtsummit-asltrw.1</url>
      <abstract>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology ; although current state-of-the-art speech recognition technology provides excellent results for generic domains, the adaptation to specialized dictionaries or glossaries is still an open issue. In this work we present an approach for automatically selecting sentences, from a <a href="https://en.wikipedia.org/wiki/Text_corpus">text corpus</a>, that match, both semantically and morphologically, a glossary of terms (words or composite words) furnished by the user. The final goal is to rapidly adapt the <a href="https://en.wikipedia.org/wiki/Language_model">language model</a> of an hybrid ASR system with a limited amount of in-domain text data in order to successfully cope with the linguistic domain at hand ; the <a href="https://en.wikipedia.org/wiki/Vocabulary">vocabulary</a> of the baseline model is expanded and tailored, reducing the resulting OOV rate. Data selection strategies based on shallow morphological seeds and semantic similarity via <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> are introduced and discussed ; the experimental setting consists in a simultaneous interpreting scenario, where ASRs in three languages are designed to recognize the domainspecific terms (i.e. dentistry). Results using different metrics (OOV rate, WER, precision and recall) show the effectiveness of the proposed techniques.</abstract>
      <bibkey>gretter-etal-2021-seed</bibkey>
    <title_es>Selección de datos basada en palabras semilla para la adaptación del modelo de lenguaje</title_es>
      <title_ar>اختيار البيانات على أساس الكلمات البذرية لتكييف نموذج اللغة</title_ar>
      <title_pt>Seleção de dados baseada em palavras-semente para adaptação do modelo de linguagem</title_pt>
      <title_hi>भाषा मॉडल अनुकूलन के लिए बीज शब्द आधारित डेटा चयन</title_hi>
      <title_ja>言語モデル適応のためのシードワードベースのデータ選択</title_ja>
      <title_zh>盖种子词语,自适数也</title_zh>
      <title_ga>Roghnú Sonraí Bunaithe ar Fhocail Síl le haghaidh Oiriúnú Samhail Teanga</title_ga>
      <title_el>Επιλογή δεδομένων βασισμένων σε λέξεις σπόρων για προσαρμογή προτύπων γλώσσας</title_el>
      <title_hu>Magszavak alapú adatok kiválasztása a nyelvi modell adaptációjához</title_hu>
      <title_ka>სახელის მოდელის ადაპტიფიკაციისთვის მონაცემების მონიშნული სიტყვები</title_ka>
      <title_it>Selezione dei dati basata sulle parole di semina per l'adattamento del modello linguistico</title_it>
      <title_kk>Тіл үлгісін адаптациялау үшін тарату сөздерінің негізгі деректерін таңдау</title_kk>
      <title_lt>Sėklos žodžiais pagrįstų duomenų parinkimas kalbos modelio pritaikymui</title_lt>
      <title_mk>Seed Words Based Data Selection for Language Model Adaptation</title_mk>
      <title_ml>ഭാഷയുടെ മോഡില്‍ ആഡാപ്റ്റേഷനുള്ള വാക്കുകള്‍ അടിസ്ഥാനമായ ഡേറ്റാ തെരഞ്ഞെടുക്കുക</title_ml>
      <title_ms>Pemilihan Data Berasas Kata Benih untuk Penyesuaian Model Bahasa</title_ms>
      <title_mt>Għażla tad-dejta bbażata fuq il-kliem taż-żerriegħa għall-Adattament tal-Mudell tal-Lingwa</title_mt>
      <title_pl>Wybór danych opartych na słowach nasiennych dla adaptacji modelu językowego</title_pl>
      <title_mn>Холын загварын загварын сонголтын үндсэн өгөгдлийн сонголт үг</title_mn>
      <title_no>Speldeord basert datautval for språk- modelletilpassing</title_no>
      <title_ro>Selectarea datelor bazate pe cuvinte de semință pentru adaptarea modelului lingvistic</title_ro>
      <title_sr>Izaber podataka na semeni reèi za adaptaciju jezičkog modela</title_sr>
      <title_si>භාෂාව මොඩේල් සැකසුම් වෙනුවෙන් සීඩ් වචන අධාරිත දත්ත තෝරණය</title_si>
      <title_so>Tilmaamaha qaabka luuqada</title_so>
      <title_sv>Seed Words Based Data Selection for Language Model Anpassning</title_sv>
      <title_ta>மொழி மாதிரி மாதிரி மாற்றத்திற்கான அடிப்படையான தரவு தேர்வுகளை தேர்ந்தெடுக்கவும்</title_ta>
      <title_ur>زبان موڈل اڈپٹیٹ کے لئے سیڈ ویروں کی بنیادی ڈاٹ انتخاب</title_ur>
      <title_uz>Tilning moduli uchun maò¥lumot bazasini tanlash uchun soò£zlarni qidirish</title_uz>
      <title_vi>Chỉ ra từ từ và từ ngữ học</title_vi>
      <title_bg>Избор на данни на базата на думи за адаптиране на езиковия модел</title_bg>
      <title_da>Seed Words Based Data Selection for Language Model Adaption</title_da>
      <title_nl>Dataselectie op basis van zaadwoorden voor taalmodel aanpassing</title_nl>
      <title_hr>Izaber podataka na osnovu sjeme za adaptaciju jezičkog modela</title_hr>
      <title_de>Seed Words Based Data Selection for Language Model Adaption</title_de>
      <title_id>Pemilihan Data Berdasarkan Kata Benih untuk Adaptasi Model Bahasa</title_id>
      <title_ko>피드 단어 기반 언어 모델 자체 적응 데이터 선택</title_ko>
      <title_fa>برگزیدن داده‌های بنیادی بر روی مدل زبان</title_fa>
      <title_tr>Dil nusgasy üçin ullan Maglumat Saýlawy</title_tr>
      <title_sw>Uchaguzi wa Data Based for Adaptation Model of Language</title_sw>
      <title_af>Sked Woord Baseerde Data Keuse vir Taal Model Aanpassering</title_af>
      <title_am>ፋይል sን መክፈት አልቻለም፦ %s፦ %s</title_am>
      <title_sq>Zgjidhja e të dhënave bazuar në fjalë për adaptimin e modelit gjuhësor</title_sq>
      <title_hy>Լեզու մոդելի հարմարեցման համար բառերի հիմնված տվյալների ընտրությունը</title_hy>
      <title_bn>ভাষার মোডেল অ্যাডাপ্টেশনের জন্য খুঁজে বের করা শব্দের ভিত্তিক তথ্য নির্বাচন</title_bn>
      <title_az>Dil Modeli Adlandırması</title_az>
      <title_bs>Izaber podataka na semeni riječi za adaptaciju jezičkog modela</title_bs>
      <title_et>Seemnesõnadel põhinevate andmete valik keelemudeli kohandamiseks</title_et>
      <title_ca>Selecció de dades basades en paraules per adaptar el model lingüístic</title_ca>
      <title_cs>Výběr dat založených na semenných slovech pro adaptaci jazykového modelu</title_cs>
      <title_fi>Siemensanapohjainen datavalinta kielimallin mukauttamista varten</title_fi>
      <title_he>בחירת נתונים מבוססת מילים לזרע עבור התאמה למודל שפה</title_he>
      <title_ha>@ action</title_ha>
      <title_jv>string" in "context_BAR_stringLink</title_jv>
      <title_sk>Izbira podatkov na osnovi semenskih besed za prilagajanje jezikovnega modela</title_sk>
      <title_bo>སྐད་རིགས་མ་དབྱིབས་བཟོ་བཅོས་ལ་ཆ་ལྟ་བུ་གཞི་རྟེན་པའི་ཡིག་ཆ་གདམ་པ</title_bo>
      <abstract_es>Abordamos el problema de la personalización del modelo de lenguaje en aplicaciones en las que el componente ASR necesita administrar terminología específica del dominio; aunque la tecnología de reconocimiento de voz de vanguardia actual proporciona excelentes resultados para dominios genéricos, la adaptación a diccionarios o glosarios especializados es sigue siendo un tema abierto. En este trabajo presentamos un enfoque para seleccionar automáticamente oraciones, de un corpus de texto, que coincidan, tanto semántica como morfológicamente, con un glosario de términos (palabras o palabras compuestas) proporcionado por el usuario. El objetivo final es adaptar rápidamente el modelo lingüístico de un sistema ASR híbrido con una cantidad limitada de datos de texto en el dominio para hacer frente con éxito al dominio lingüístico en cuestión; el vocabulario del modelo de referencia se amplía y se adapta, reduciendo la tasa de OOV resultante. Se presentan y discuten estrategias de selección de datos basadas en semillas morfológicas superficiales y similitud semántica a través de word2vec; el entorno experimental consiste en un escenario de interpretación simultánea, en el que los ASR en tres idiomas están diseñados para reconocer los términos específicos del dominio (es decir, odontología). Los resultados que utilizan diferentes métricas (tasa de OOV, WER, precisión y recuperación) muestran la eficacia de las técnicas propuestas.</abstract_es>
      <abstract_ar>نعالج مشكلة تخصيص نموذج اللغة في التطبيقات حيث يحتاج مكون ASR إلى إدارة المصطلحات الخاصة بالمجال ؛ على الرغم من أن تقنية التعرف على الكلام الحديثة توفر نتائج ممتازة للمجالات العامة ، إلا أن التكيف مع القواميس أو المعاجم المتخصصة لا يزال يمثل مشكلة مفتوحة. نقدم في هذا العمل نهجًا لاختيار الجمل تلقائيًا ، من مجموعة نصية ، تتطابق ، من الناحية اللغوية والصرفية ، مع قاموس مصطلحات (كلمات أو كلمات مركبة) قدمها المستخدم. الهدف النهائي هو التكيف السريع للنموذج اللغوي لنظام ASR الهجين بكمية محدودة من البيانات النصية في المجال من أجل التعامل بنجاح مع المجال اللغوي في متناول اليد ؛ يتم توسيع مفردات النموذج الأساسي وتصميمها ، مما يقلل من معدل OOV الناتج. يتم تقديم ومناقشة استراتيجيات اختيار البيانات على أساس البذور المورفولوجية الضحلة والتشابه الدلالي عبر word2vec ؛ يتكون الإعداد التجريبي من سيناريو ترجمة متزامنة ، حيث تم تصميم ASRs بثلاث لغات للتعرف على المصطلحات الخاصة بالمجالات (مثل طب الأسنان). تظهر النتائج باستخدام مقاييس مختلفة (معدل OOV ، WER ، الدقة والاسترجاع) فعالية التقنيات المقترحة.</abstract_ar>
      <abstract_pt>Abordamos o problema de customização do modelo de linguagem em aplicativos onde o componente ASR precisa gerenciar terminologia específica de domínio; embora a tecnologia de reconhecimento de fala de última geração forneça excelentes resultados para domínios genéricos, a adaptação a dicionários ou glossários especializados ainda é uma questão em aberto. Neste trabalho apresentamos uma abordagem para a seleção automática de frases, a partir de um corpus de texto, que correspondam, semanticamente e morfologicamente, a um glossário de termos (palavras ou palavras compostas) fornecido pelo usuário. O objetivo final é adaptar rapidamente o modelo de linguagem de um sistema ASR híbrido com uma quantidade limitada de dados de texto no domínio para lidar com sucesso com o domínio linguístico em questão; o vocabulário do modelo de linha de base é expandido e adaptado, reduzindo a taxa OOV resultante. Estratégias de seleção de dados baseadas em sementes morfológicas rasas e similaridade semântica via word2vec são apresentadas e discutidas; o cenário experimental consiste em um cenário de interpretação simultânea, onde ASRs em três idiomas são projetados para reconhecer os termos específicos do domínio (ou seja, odontologia). Resultados usando diferentes métricas (taxa OOV, WER, precisão e recall) mostram a eficácia das técnicas propostas.</abstract_pt>
      <abstract_ja>私たちは、ASRコンポーネントがドメイン固有の用語を管理する必要があるアプリケーションにおける言語モデルのカスタマイズの問題に取り組んでいます。現在の最先端の音声認識技術はジェネリックドメインに優れた結果を提供していますが、専門の辞書または用語集への適応はまだ未解決の問題です。 この研究では、テキストコーパスから、ユーザーが提供する用語（単語または複合単語）の用語集に意味的にも形態的にも一致する文章を自動的に選択するためのアプローチを提示します。 最終的な目標は、手元の言語領域にうまく対応するために、限られた量のドメイン内テキストデータを持つハイブリッドASRシステムの言語モデルを迅速に適応させることである。ベースラインモデルの語彙が拡張され、調整され、結果として生じるOOV率が低下する。 浅い形態学的シードとword 2 vecを介した意味的類似性に基づくデータ選択戦略を紹介し、議論した。実験環境は、3つの言語のASRがドメイン固有の用語（すなわち、歯学）を認識するように設計された同時通訳シナリオで構成されている。 さまざまな指標（ OOV率、WER、精度、リコール）を使用した結果は、提案されたテクニックの有効性を示しています。</abstract_ja>
      <abstract_zh>解ASR组件治特定于域术语应用程序语自定义。 虽先进语音,通用域出色,而专用词典词汇表,犹一悬而未决也。 凡此等事,从文本语料库中自择句法,语料库于语义形之上,与用户之术语表(单词或复合单词)匹。 最终目标用有限之数内文本速调混ASR系统语形,以成应手语之域。 基线模之词汇量广制度,以降其OOV率。 因word2vec引入论浅形种子与语义相似性数据选择策。 实验设同声传译场,其三语ASR旨在识域特异性术语(即牙科)。 用指标(OOV率,WER,精度召率)的结果表明术有效性。</abstract_zh>
      <abstract_hi>हम उन अनुप्रयोगों में भाषा मॉडल अनुकूलन की समस्या को संबोधित करते हैं जहां एएसआर घटक को डोमेन-विशिष्ट शब्दावली का प्रबंधन करने की आवश्यकता होती है; यद्यपि वर्तमान अत्याधुनिक भाषण मान्यता प्रौद्योगिकी जेनेरिक डोमेन के लिए उत्कृष्ट परिणाम प्रदान करती है, विशेष शब्दकोशों या शब्दावली के लिए अनुकूलन अभी भी एक खुला मुद्दा है। इस काम में हम स्वचालित रूप से वाक्यों का चयन करने के लिए एक दृष्टिकोण प्रस्तुत करते हैं, एक पाठ कॉर्पस से, जो कि शब्दार्थ और रूपात्मक रूप से दोनों से मेल खाता है, उपयोगकर्ता द्वारा प्रस्तुत शब्दों (शब्दों या समग्र शब्दों) की एक शब्दावली। अंतिम लक्ष्य तेजी से एक हाइब्रिड एएसआर सिस्टम के भाषा मॉडल को सीमित मात्रा में इन-डोमेन टेक्स्ट डेटा के साथ अनुकूलित करना है ताकि हाथ में भाषाई डोमेन का सफलतापूर्वक सामना किया जा सके; बेसलाइन मॉडल की शब्दावली का विस्तार किया जाता है और अनुरूप किया जाता है, जिसके परिणामस्वरूप ओओवी दर को कम किया जाता है। उथले रूपात्मक बीज और word2vec के माध्यम से शब्दार्थ समानता के आधार पर डेटा चयन रणनीतियों को पेश किया जाता है और चर्चा की जाती है; प्रयोगात्मक सेटिंग में एक साथ व्याख्या परिदृश्य होता है, जहां तीन भाषाओं में एएसआर को डोमेन विशिष्ट शब्दों (यानी दंत चिकित्सा) को पहचानने के लिए डिज़ाइन किया गया है। विभिन्न मैट्रिक्स (OOV दर, WER, परिशुद्धता और याद) का उपयोग करने वाले परिणाम प्रस्तावित तकनीकों की प्रभावशीलता दिखाते हैं।</abstract_hi>
      <abstract_ga>Tugaimid aghaidh ar an bhfadhb a bhaineann le saincheapadh samhaltán teanga i bhfeidhmchláir ina bhfuil gá leis an gcomhpháirt ASR chun téarmaíocht a bhaineann go sonrach le fearann a bhainistiú; Cé go soláthraíonn an teicneolaíocht aitheanta cainte úrscothach torthaí sármhaithe maidir le réimsí cineálacha, is ceist oscailte fós é an t-oiriúnú d’fhoclóirí nó do ghluaiseanna speisialaithe. Sa saothar seo cuirimid i láthair cur chuige chun abairtí a roghnú go huathoibríoch, as corpas téacs, a mheaitseálann, go séimeantach agus go moirfeolaíoch, le gluais téarmaí (focail nó focail chumaisc) a chuireann an t-úsáideoir ar fáil. Is é an sprioc deiridh an tsamhail teanga de chóras hibrideach ASR le méid teoranta sonraí téacs san fhearann a oiriúnú go tapa chun déileáil go rathúil leis an bhfearann teanga atá i gceist; déantar stór focal an mhúnla bonnlíne a leathnú agus a shaincheapadh, ag laghdú an ráta OOV mar thoradh air. tugtar isteach agus pléitear straitéisí roghnaithe sonraí atá bunaithe ar shíolta moirfeolaíocha éadomhain agus cosúlacht shéimeantach trí word2vec; Is éard atá sa suíomh turgnamhach cás ateangaireachta comhuaineach, ina bhfuil ASRanna i dtrí theanga deartha chun na téarmaí a bhaineann go sonrach leis an bhfearann a aithint (i.e. fiaclóireachta). Léiríonn torthaí a úsáideann méadrachtaí éagsúla (ráta OOV, WER, beachtas agus aisghairm) éifeachtacht na dteicníochtaí atá beartaithe.</abstract_ga>
      <abstract_ka>ჩვენ ენის მოდელის კონფიგურაციის პრობლემას გადაწყენებთ პრობლემაში, სადაც ASR კონომპონენტი უნდა მოდენის კონფიგურაციის ტერმინოლოგი თუმცა მიმდინარე სიტყვების განაცნობის ტექნოლოგია უკეთესი წარმოდგენება საერთო დომენეებისთვის, სპეციალური სიტყვებისთვის ან სიტყვებისთვის ადაპრაცია უკეთე ამ სამუშაოში ჩვენ ავტომატურად მონიშნოთ სიტყვები, ტექსტის კორპუსდან, რომელიც სამუშაოდ სიმპრანტიკურად და მორპოლოგიურად, სიტყვების სიტყვები (სიტყვები ან კომპოზიტი საბოლოო მიზეზი არის ჰიბრიტური ASR სისტემის ენის მოდელს წინასწორად აეპორტირება, რომელიც დრომის ტექსტის მონაცემების ზომის შესაძლებელად წინასწარმოადგენა, რომ წარმოადგენა ლ მუშაობის მოდელის სიტყვალის სიტყვალის გაფარდება და განზომილება, შემდეგ OOV სიტყვალის გაფარდება. მონაცემების არჩევის სტრატიგიები, რომლებიც მხოლოდ მოპოროლოგიური შვილების და სენმანტიური სიმბოლოგიის განსხვავებაზე დააყენება და განსახულება; ექსპერიმენტიური შესაძლებელია ერთადერთი ინტერპექტირების სენარიოში, სადაც ASRs სამი ენაში განაზღვრებულია, რომ კომპერიმენტიური სიტყვების მოცნობა (მაგალითად dentistry). გამოყენება განსხვავებული მეტრიკის გამოყენება (OOV rate, WER, precision and recall) გამოყენება გამოყენებული ტექნიკების ეფექტიურობა.</abstract_ka>
      <abstract_el>Αντιμετωπίζουμε το πρόβλημα της προσαρμογής γλωσσικού μοντέλου σε εφαρμογές όπου το συστατικό χρειάζεται να διαχειριστεί ορολογία συγκεκριμένου τομέα. Παρόλο που η σύγχρονη τεχνολογία αναγνώρισης ομιλίας παρέχει εξαιρετικά αποτελέσματα για γενικούς τομείς, η προσαρμογή σε εξειδικευμένα λεξικά ή γλωσσάρια εξακολουθεί να αποτελεί ανοικτό ζήτημα. Στην παρούσα εργασία παρουσιάζεται μια προσέγγιση για την αυτόματη επιλογή προτάσεων, από ένα σώμα κειμένου, που ταιριάζουν, σημασιολογικά και μορφολογικά, με ένα γλωσσάριο όρων (λέξεις ή σύνθετες λέξεις) που παρέχεται από τον χρήστη. Ο τελικός στόχος είναι η ταχεία προσαρμογή του γλωσσικού μοντέλου ενός υβριδικού συστήματος ASR με περιορισμένο αριθμό δεδομένων κειμένου εντός του τομέα, προκειμένου να αντιμετωπιστεί επιτυχώς ο συγκεκριμένος γλωσσικός τομέας. το λεξιλόγιο του μοντέλου βάσης διευρύνεται και προσαρμόζεται, μειώνοντας το ποσοστό OOV που προκύπτει. Εισάγονται και συζητούνται στρατηγικές επιλογής δεδομένων βασισμένες σε ρηχά μορφολογικά σπόρα και σημασιολογική ομοιότητα μέσω του Word2vec. το πειραματικό περιβάλλον συνίσταται σε ένα σενάριο ταυτόχρονης διερμηνείας, όπου οι ASR σε τρεις γλώσσες έχουν σχεδιαστεί για να αναγνωρίζουν τους συγκεκριμένους όρους (δηλ. οδοντιατρική). Τα αποτελέσματα που χρησιμοποιούν διαφορετικές μετρήσεις (ποσοστό OOV, WER, ακρίβεια και ανάκληση) δείχνουν την αποτελεσματικότητα των προτεινόμενων τεχνικών.</abstract_el>
      <abstract_hu>Olyan alkalmazásokban kezeljük a nyelvmodellek testreszabásának problémáját, ahol az ASR komponensnek tartományspecifikus terminológiát kell kezelnie; Bár a jelenlegi korszerű beszédfelismerő technológia kiváló eredményeket nyújt az általános tartományok számára, a speciális szótárakhoz vagy szószedetekhez való alkalmazkodás még mindig nyitott kérdés. Ebben a munkában egy olyan megközelítést mutatunk be, amelynek segítségével automatikusan kiválasztható olyan mondatok, amelyek szemantikailag és morfológiailag egyeznek a felhasználó által megadott kifejezések (szavak vagy összetett szavak) szószedetével. A végső cél egy korlátozott mennyiségű tartományonbelüli szövegadatot tartalmazó hibrid ASR rendszer nyelvi modelljének gyors módosítása annak érdekében, hogy sikeresen megbirkózzon az adott nyelvi tartománnyal; az alapvető modell szókincsét bővítik és testre szabják, csökkentve az eredményes OOV arányt. A sekély morfológiai vetőmagokon és a szemantikai hasonlóságon alapuló adatválasztási stratégiák bevezetése és megvitatása word2vec segítségével; a kísérleti környezet egy szinkrontolmácsolási forgatókönyvből áll, ahol a három nyelven megjelenő ASR-eket úgy tervezték, hogy felismerjék a területspecifikus kifejezéseket (azaz fogászatot). A különböző mutatókat használó eredmények (OOV sebesség, WER, precizitás és visszahívás) mutatják a javasolt technikák hatékonyságát.</abstract_hu>
      <abstract_it>Affrontiamo il problema della personalizzazione del modello linguistico nelle applicazioni in cui il componente ASR deve gestire la terminologia specifica del dominio; Anche se l'attuale tecnologia di riconoscimento vocale all'avanguardia fornisce ottimi risultati per i domini generici, l'adattamento a dizionari o glossari specializzati è ancora un problema aperto. In questo lavoro presentiamo un approccio per selezionare automaticamente frasi, da un corpus di testo, che corrispondono, sia semanticamente che morfologicamente, a un glossario di termini (parole o parole composite) fornito dall'utente. L'obiettivo finale è quello di adattare rapidamente il modello linguistico di un sistema ASR ibrido con una quantità limitata di dati testuali nel dominio per far fronte con successo al dominio linguistico in questione; il vocabolario del modello di base è ampliato e personalizzato, riducendo il tasso OOV risultante. Vengono introdotte e discusse strategie di selezione dei dati basate su semi morfologici superficiali e somiglianze semantiche tramite word2vec; l'ambiente sperimentale consiste in uno scenario di interpretazione simultanea, in cui le ASR in tre lingue sono progettate per riconoscere i termini specifici del settore (cioè odontoiatria). I risultati che utilizzano diverse metriche (OOV rate, WER, precisione e richiamo) mostrano l'efficacia delle tecniche proposte.</abstract_it>
      <abstract_lt>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology;  nors dabartinė naujausia kalbos pripažinimo technologija suteikia puikių rezultatų bendrosioms sritims, prisitaikymas prie specializuotų žodynų ar žodynų vis dar yra atviras klausimas. Šiame darbe pristatome metodą, kaip automatiškai pasirinkti sakinius iš teksto korpuso, kurie atitinka semantiškai ir morfologiškai naudotojo pateiktą terminų žodyną (žodžius ar sudėtinius žodžius). Galutinis tikslas – greitai pritaikyti hibridinės ASR sistemos su ribotu domeno teksto duomenų kiekiu kalbinį model į, kad būtų sėkmingai išspręsta kalbinė sritis; pradinio modelio žodynas išplėstas ir pritaikytas prie jo, mažinant gautą OOV dažnį. Įvedamos ir aptariamos duomenų atrankos strategijos, grindžiamos plokščiomis morfologinėmis sėklomis ir semantiniu panašumu žodžiu 2vec; eksperimentinį nustatymą sudaro vienu metu a i škinamasis scenarijus, kai ASR trijose kalbose yra suprojektuoti pripažinti konkrečias srities sąvokas (t. y. dantų gydytoją). Rezultatai, naudojantys skirtingus rodiklius (OOV greitis, WER, tikslumas ir atšaukimas), rodo siūlomų metodų veiksmingumą.</abstract_lt>
      <abstract_kk>ASR компонентінің доменге ерекше терминологияны басқару керек қолданбаларда тіл үлгісін баптау мәселесін шешу керек. Қолданыстағы орындалық сөздерді таңдау технологиясы жалпы домендерге әдемі нәтижелер береді, сонымен қатар өзгертілген сөздерге не сөздерге қолдану әлі ашық мәселе. Бұл жұмыс ішінде, пайдаланушының берілген сөздерді (сөздер немесе сәйкес сөздерді) автоматты түрде таңдау үшін, мәтін корпустан сәйкес келеді. Соңғы мақсат - лингвистикалық доменге сәтті шектелу үшін гибридтік ASR жүйесінің тіл үлгісін тез түрде адаптау үшін доменде мәтін деректерінің шектелген мәтін деректерінің шектелген мәтіндерін негізгі үлгісінің сөздігі кеңейтілген және өзгертілген, нәтижесінің OOV жылдамдығын азайтады. Деректерді таңдау стратегиялары, күлкін морфологиялық тарықтар мен semantiкалық ұқсас сөз 2vec арқылы ендірілген және талқылады; эксперименталдық параметрлері бір-бір түрлендіру сценариясында тұрады, бұл үш тілде ASR адамдарын домендегі ерекше терминдерді анықтау үшін құрылады (т.е. dentistry). Басқа метрикалық нәтижелері (ООВ жылдамдығы, WER, дұрыс және қайталау) қолданылатын техникалардың эффективнігін көрсетеді.</abstract_kk>
      <abstract_mk>Ние го решаваме проблемот со приспособувањето на јазичкиот модел во апликациите каде што компонентот АСР треба да управува со терминологијата специфична за домен; although current state-of-the-art speech recognition technology provides excellent results for generic domains, the adaptation to specialized dictionaries or glossaries is still an open issue.  Во оваа работа претставуваме пристап за автоматски избор на реченици, од текст корпус, кои се совпаѓаат, семантично и морфолошки, со гласар на термини (зборови или композитни зборови) обезбедени од корисникот. Конечната цел е брзо да се адаптира јазичкиот модел на хибридниот систем АСР со ограничено количество текстови податоци во доменот со цел успешно да се справи со раководниот јазички домен; резултатот на резултатот е проширен и прилагоден, намалувајќи ја резултатната стапка на OOV. Стратегии за селекција на податоци базирани на плошко морфолошко семе и семантична сличност преку word2vec се воведени и дискутирани; експерименталното поставување се состои од едновремен сценарио за интерпретација, каде што АСР на три јазици се дизајнирани за да ги препознаат доменски специфични термини (т.е. забарство). Резултатите со користење на различни метрики (стапка на ООВ, ВЕР, прецизност и повлекување) ја покажуваат ефикасноста на предложените техники.</abstract_mk>
      <abstract_ms>Kami mengatasi masalah penyesuaian model bahasa dalam aplikasi dimana komponen ASR perlu mengawal terminologi spesifik domain; walaupun teknologi pengenalan pidato yang terbaik semasa menyediakan keputusan yang baik untuk domain generik, penyesuaian kepada kamus atau glosari khusus masih isu terbuka. In this work we present an approach for automatically selecting sentences, from a text corpus, that match, both semantically and morphologically, a glossary of terms (words or composite words) furnished by the user.  The final goal is to rapidly adapt the language model of an hybrid ASR system with a limited amount of in-domain text data in order to successfully cope with the linguistic domain at hand;  vocabulari model asas dikembangkan dan disesuaikan, mengurangi kadar OOV yang berasal. Strategi pemilihan data berdasarkan benih morfologi rendah dan persamaan semantik melalui word2vec diperkenalkan dan dibahas; tetapan percubaan terdiri dalam skenario interpretasi bersamaan, di mana ASR dalam tiga bahasa direka untuk mengenali terma domain tertentu (iaitu doktor gigi). Hasil menggunakan metrik berbeza (kadar OOV, WER, ketepatan dan pengulangan) menunjukkan keefektivitas teknik yang diusulkan.</abstract_ms>
      <abstract_ml>ഞങ്ങള്‍ ഭാഷ മോഡല്‍ ഇഷ്ടപ്പെടുത്തുന്നതിന്റെ പ്രയോഗത്തില്‍ പ്രശ്നങ്ങള്‍ വിശദീകരിക്കുന്നു. ASR ഘടകം ഡൊമെയിന്‍ - പ്രത്യേക ഇപ്പോഴത്തെ സംസാരം തിരിച്ചറിയാനുള്ള സാങ്കേതികവിദ്യയ്ക്ക് നല്ല ഫലങ്ങള്‍ നല്‍കുന്നുവെങ്കിലും പ്രത്യേകിച്ച നിഘണ്ടുകള്‍ക്ക ഈ ജോലിയില്‍ നമ്മള്‍ സ്വയം വാക്കുകള്‍ തെരഞ്ഞെടുക്കുന്നതിനുള്ള ഒരു വഴിയില്‍ ഉപയോക്താവ് ഉപയോക്താവ് നല്‍കിയ വാക്കുകളില്‍ നിന്നും പൊരുതുന്ന ഒരു ടെക്സ അവസാനത്തെ ലക്ഷ്യം ഒരു ഹൈബ്രിഡ് എസ്ആര്‍ സിസ്റ്റത്തിന്റെ ഭാഷ മോഡല്‍ പെട്ടെന്ന് മാറ്റുക എന്നതാണ്. ഡൊമെയിനിലെ ടെക്സ്റ്റേറ്റ് ഡേറ്റായിര ബേസ്ലൈന്‍ മോഡലിന്റെ പദവി വോര്‍ഡ്2വെക്കിന്റെ വഴിയില്‍ തണുത്ത മോര്‍ഫോളജിക്കല്‍ വിത്രങ്ങളും സെമാന്റിക് സമമാക്കി അടിസ്ഥാനമായി ഡേറ്റാ തെരഞ്ഞെട പരീക്ഷണത്തിന്റെ സജ്ജീകരണങ്ങള്‍ ഒരേ സമയത്ത് വ്യാഖ്യാനം നടത്തുന്ന സിനാറിയില്‍ ഉണ്ട്. അവിടെ മൂന്നു ഭാഷകളില്‍ ASRകള്‍ ഡൊമൈന്‍ പ്രത്യേക വ വ്യത്യസ്ത മെട്രിക്കുകള്‍ ഉപയോഗിക്കുന്ന ഫലങ്ങള്‍</abstract_ml>
      <abstract_no>Vi adresserer problemet med å tilpassa språk- modellen i programmer der ASR- komponenten må handtera terminologien for domenespesifikk. Selv om det gjeldande tilstanden av kunstendige taleteknologien gjev utrolig resultat for generelle domene, er adaptasjonen til spesialiserte ordbokar eller glossarar fortsatt eit opna problem. I dette arbeidet viser vi ein tilnærming for å automatisk velja setningar, frå ein tekstkorpus, som passar både semantisk og morfologisk, eit ordordsamling (ord eller samansett ord) som brukaren har. Det siste målet er å raskt tilpassa språk- modellen til ein hybrid ASR- systemet med ein begrenset mengd på tekstdata i domenet for å kopla med den linguistiske domenet ved hånd. Ordbokstaven til baselinjemodellen er utvida og tilpassa, og reduserer resultatet av OOV- rate. Data-utvalsstrategiar basert på fleire morfologiske deler og semantiske likningar gjennom ord2vec vert introdusert og diskutert. Den eksperimentelle innstillinga består i e in samtidig tolkingssjenario, der ASRs i tre språk er designert for å gjenkjenna domenespesifikke leddene (t.d. dentistry). Resultat med ulike metrikar (OOV rate, WER, presisjon og rekning) viser effektiviteten av dei foreslåtte teknikka.</abstract_no>
      <abstract_pl>Rozwiązujemy problem dostosowywania modelu językowego w aplikacjach, w których komponent ASR musi zarządzać terminologią specyficzną dla domeny; Chociaż obecna najnowocześniejsza technologia rozpoznawania mowy zapewnia doskonałe rezultaty w dziedzinach ogólnych, adaptacja do specjalistycznych słowników lub słowników jest nadal otwartą kwestią. W niniejszej pracy przedstawiamy podejście do automatycznego wyboru zdań z korpusu tekstowego, które pasują zarówno semantycznie, jak i morfologicznie do słownika terminów (słów lub słów złożonych) dostarczonego przez użytkownika. Ostatecznym celem jest szybkie dostosowanie modelu językowego hybrydowego systemu ASR z ograniczoną ilością danych tekstowych w domenie w celu skutecznego poradzenia sobie z daną domeną językową; słownictwo modelu bazowego zostało rozszerzone i dostosowane, zmniejszając wynikający wskaźnik OOV. Przedstawiono i omówiono strategie selekcji danych oparte na płytkich nasionach morfologicznych oraz podobieństwie semantycznym za pomocą Word2vec; środowisko eksperymentalne polega na scenariuszu tłumaczenia symultanicznego, w którym ASR w trzech językach są zaprojektowane w celu rozpoznawania terminów specyficznych dla domeny (tj. stomatologii). Wyniki wykorzystujące różne wskaźniki (wskaźnik OOV, WER, precyzja i recall) pokazują skuteczność proponowanych technik.</abstract_pl>
      <abstract_mn>Бид хэл загварын загварын асуудлыг ASR компонентийн домены тодорхой терминологийг удирдах шаардлагатай програмын тухай ярилцдаг. Гэхдээ одоогийн урлагийн ярианы хүлээн зөвшөөрөх технологи нь ерөнхий хэсэгт гайхалтай үр дүнг гаргадаг ч, мэргэжлийн сөрөг үг эсвэл сөрөг хэлний адилтгал нь нээлттэй асуудал юм. Энэ ажлын тулд бид хэрэглэгчийн өгүүлбэрийг автоматаар сонгохын тулд өгүүлбэрийг автоматаар сонгох боломжтой арга зам өгсөн. Эцсийн зорилго бол гибрид АСР системийн хэл загварын хэл загварыг холбоотой хэмжээний хэмжээнд хязгаарлагдсан текст өгөгдлийг амжилттай холбоотой болгох юм. суурь шугам загварын үг нэмэгдэж, өөрчлөгдөж, үр дүнтэй ООВ хурдыг багасгаж байна. Өгөгдлийн сонголтын стратеги нь хэлбэрээр 2vec хэлбэрээр багасгаж өгөгдлийн морфологик үр болон семантик төстэй байдал үүсгэдэг. туршилтын тохиолдол нь нэг зэрэг тодорхойлолтын хувилбарт байдаг. Гурван хэл дээр АСР нь тодорхойлолтын тодорхойлолт (яг л шүдний эмч). Үүний үр дүнд олон метрик (ООВ хурд, WER, нарийвчлал, санах) ашиглаж байгаа техникуудын үр дүнг харуулдаг.</abstract_mn>
      <abstract_ro>Rezolvăm problema personalizării modelului lingvistic în aplicațiile în care componenta ASR trebuie să gestioneze terminologia specifică domeniului; Deși tehnologia actuală de recunoaștere a vorbirii de ultimă generație oferă rezultate excelente pentru domeniile generice, adaptarea la dicționare sau glosare specializate este încă o problemă deschisă. În această lucrare prezentăm o abordare pentru selectarea automată a propozițiilor, dintr-un corpus de text, care corespund, atât semantic, cât și morfologic, unui glosar de termeni (cuvinte sau cuvinte compuse) furnizat de utilizator. Obiectivul final este adaptarea rapidă a modelului lingvistic al unui sistem ASR hibrid cu o cantitate limitată de date text în domeniu pentru a face față cu succes domeniului lingvistic în cauză; vocabularul modelului de bază este extins și adaptat, reducând rata OOV rezultată. Sunt introduse și discutate strategiile de selecție a datelor bazate pe semințe morfologice superficiale și similaritate semantică prin word2vec; cadrul experimental constă într-un scenariu de interpretare simultană, în care ASR în trei limbi sunt concepute pentru a recunoaște termenii specifici domeniului (adică stomatologie). Rezultatele utilizând diferite metrici (rata OOV, WER, precizia și rechemarea) arată eficacitatea tehnicilor propuse.</abstract_ro>
      <abstract_si>අපි භාෂාව ප්‍රශ්නය සඳහා භාෂාව ප්‍රශ්නය සඳහා ASR ප්‍රශ්නයේ ප්‍රශ්නය සඳහා පරිස්සම් කරනවා කොහෙ ප්‍රස්තූත ස්ථානය-of-the-art කතාවක් අඳුරන් තාක්ෂණය ප්‍රවේශයක් සාමාන්‍ය ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ මේ වැඩේ අපි ස්වයංක්‍රමයෙන් වාක්ය තෝරාගන්න ස්වයංක්‍රමයෙන් පිළිබඳ වාක්ය තෝරාගන්න පුළුවන්, පාළිබඳ කොර්පස් වලින්, සෙම අන්තිම අරමුණ තමයි හයිබ්‍රිඩ් ASR පද්ධතියේ භාෂාව ප්‍රවේශයේ භාෂාව ප්‍රවේශයක් සඳහා සීමාවිත පාළුවක් තොරතුරු සඳහා පරි මූලික ප්‍රමාණයේ භාෂාවක් විස්තර කරලා තියෙන්නේ, ප්‍රතිචාරයක් විස්තර කරලා තියෙන්නේ. දත්ත තෝරාගැනීමේ සාමාන්‍ය විද්‍යාප්‍තිය සහ සෙමාන්තික සාමාන්‍ය විද්‍යාප්‍තිය සඳහා වචන 2වෙක් විද්‍යාප්‍තිය පරීක්ෂණ සැකසුම් එක්කෙනෙක් අනුවර්තනයක් තියෙනවා, කොහෙද ASRs භාෂා තුනක් තියෙන්නේ ඩෝමේන් විශේෂ වර්තුවක් අඳුර වෙනස් මෙට්‍රික්ස් භාවිත කරන්න ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රයෝජනය (OOOv rate, WER, ක්‍රියාත්මක ස</abstract_si>
      <abstract_so>Waxaannu ka sheekeynaynaa dhibaatada isticmaalka muusikada luuqada ee codsiga ay ka baahan tahay in uu maamulo terminologi gaar ah ee domain; in kastoo ay taxadirka aqoonsashada farshaxanka ah ee xaaladda la joogo ee aqoonsashada farshaxanku wuxuu helaa resulto wanaagsan oo laga helaa deegaanka geneeral, in lagu beddelo kalluuqadaha gaarka ah ama sharafta farshaxanku ay weli tahay arrin furan. Shaqadan waxaan u soo bandhignaa qaab a an si automatic ah u dooranayno xukunka qoraalka, kaas oo u eg qoraalka, kaas oo u eg xilliga iyo morphologigaas, kaas oo uu isticmaalayaasha u qoray qoraal (erayo ama erayo isbedelan). Ujeedka ugu dambeeya waa in si dhaqso ah u beddelo muusikada afka ASR oo ku qoran tirada macluumaadka qoraalka ee gudaha, si uu ugu liibaano ku habboon domain-da luuqadaha; hadalka muusikada aasaasiga ah waa la kordhiyaa oo la dabarayaa, wuxuuna hoos u dhigi karaa fasaxa OOV. Waxaa lagu soo bandhigaa oo la hadlaa qorshaha doorashada macluumaadka oo ku saleysan abuurista morfologiga ah iyo isku mid ah ee Word2vec; Xafiiska imtixaanka waxaa ku yaala barta turjumaadda islamarkaasna lagu qorayo af saddex luqadood oo ASRs lagu qorayo in lagu aqoonsado qoraalka gaarka ah (tusaale ahaan daryeelka ilkaha). Fashihiisa ku isticmaalaya metricooyinka kala duduwan (OOV rate, WER, saxda iyo xasuusta) waxay tusi kartaa shaqaalaha teknikada la soo jeeday.</abstract_so>
      <abstract_sr>Mi rješavamo problem prilagođenja jezičkih modela u aplikacijama gde ASR komponent treba da upravlja terminologijom specifičnog domena; Iako trenutna tehnologija priznanja govora predstavlja odlične rezultate za generičke domene, adaptacija specijalizovanih rečenika ili glossarija još uvijek je otvorena pitanja. U ovom poslu predstavljamo pristup automatskom odabiru rečenica, iz tekstskog korpusa, koji se uklapa, i semantički i morfološki, rečnik termina (reči ili složene reči) koji je predstavljao korisnik. Posljednji cilj je brzo prilagoditi jezički model hibridnog ASR sistema sa ograničenom količinom podataka o tekstu u domenu kako bi se uspješno suočio sa približnim jezičkim domenama; rečnik osnovnog modela se proširi i prilagodi, smanjujući rezultat stope OOV-a. Strategije selekcije podataka bazirane na plitkom morfološkom semenu i semantičkoj sličnosti putem rečeni2veka se uvede i razgovaraju o tome; eksperimentalna postavka se sastoji u istovremenom scenariju interpretacije, gde su ASR na tri jezika dizajnirani da prepoznaju specifične termine domena (tj. zubara). Rezultati koristeći različite metrike (OOV rate, WER, preciznost i sjećanje) pokazuju učinkovitost predloženih tehnika.</abstract_sr>
      <abstract_ta>நாம் மொழி மாதிரி தனிப்பயன் பயன்பாடுகளில் குறிப்பிட்ட முனையத்தை நிர்வகிக்க வேண்டும் என்பதை விளக்குகிறோம். தற்போதைய நிலையில் கலை பேச்சு அடையாளம் தொழில்நுட்பத்தை பொதுவான களங்களுக்கு சிறந்த முடிவுகள் வழங்குகிறது, சிறப்பு அகராதிகள் அல் இந்த வேலையில் நாம் தன்னியக்கமாக தேர்ந்தெடுக்க வாக்குறியீடுகளை கொண்டு வருகிறோம், ஒரு உரை குறியீடுகளிலிருந்து, அது பொருந்துகிறது, அரைப்புறையி இறுதியின் இலக்கு எஸ்ஆர் முறைமையின் மொழி மாதிரியை விரைவாக மாற்ற வேண்டும். கையில் வெற்றிகரமாக ஒத்திசைக்க முடியும் மொழி களத்தை மா அடிப்படை மாதிரியின் சொல்வளம் விரிவாக்கப்பட்டது மற்றும் வாய்ப்பாக்கப்பட்டது, முடிவு OOV விகிதத்தை குறைக் Data selection strategies based on shallow morphological seeds and semantic similarity via word2vec are introduced and discussed;  சோதனையின் அமைப்புகள் ஒரே சேர்ந்து மூன்று மொழிகளில் ASRs குறிப்பிட்ட குறிப்பிட்ட வார்த்தைகளை அறிய வடிவமைக்கப்பட்டுள்ளது. அதாவது  முடிவுகள் வெவ்வேறு மெட்ரிக்களை பயன்படுத்தி (OOV விகிதம், WER, precision and நினைவூட்டல்) திட்டமிடப்பட்ட தொழில்நுட்பத்தின் வ</abstract_ta>
      <abstract_sv>Vi tar itu med problemet med språkmodellanpassning i applikationer där ASR-komponenten behöver hantera domänspecifik terminologi; Även om dagens toppmoderna taligenkänningsteknik ger utmärkta resultat för generiska domäner är anpassningen till specialiserade ordböcker eller ordlistor fortfarande ett öppet problem. I detta arbete presenterar vi ett tillvägagångssätt för att automatiskt välja meningar, från en textkorpus, som både semantiskt och morfologiskt matchar en ordlista av termer (ord eller sammansatta ord) som tillhandahålls av användaren. Det slutliga målet är att snabbt anpassa språkmodellen för ett hybridt ASR-system med en begränsad mängd textdata inom domänen för att framgångsrikt kunna hantera den aktuella språkdomänen. Basmodellens vokabulär utökas och anpassas, vilket minskar den resulterande OOV-frekvensen. Dataurvalsstrategier baserade på grunda morfologiska frön och semantisk likhet via word2vec introduceras och diskuteras; Den experimentella miljön består av ett simultantolkningsscenario, där ASR på tre språk är utformade för att känna igen de domänspecifika termerna (dvs. tandvård). Resultat med olika mätvärden (OOV rate, WER, precision och återkallelse) visar hur effektiva de föreslagna teknikerna är.</abstract_sv>
      <abstract_ur>ہم زبان موڈل کے مسئلہ کو اضافہ کریں گے جہاں ASR کمونٹ کو ڈومین خاص ترمینلوژی کی مدیریت کی ضرورت ہے۔ اگرچہ موجود ایٹرنیٹ کی بات شناخت ٹیکنالوجی کے لئے بہترین نتیجے پیش کرتی ہیں، مخصوص صحیفوں یا لسوریوں کے ساتھ تدبیر ابھی ایک کھلی مسئلہ ہے. ہم اس کام میں ایک ایسی طریقہ پیش کرتے ہیں جو ایک ٹیکسٹ کورپوس سے اپنے ساتھ انتخاب کرنے کے لئے ایک طریقہ ہے، جس کا مطابق سامنٹی اور مورپولوژیکی طور پر ہے، ایک کلیسار (کلمات یا پیدا کلمات) جو کارساز کی طرف سے پیش کیا گیا ہے۔ آخرین مقصد یہ ہے کہ ایک ہیبراڈ آس آس آر سیستم کی زبان کی مدل کو تیز طور پر اضافہ کرنا ہے کہ اس کے ذریعہ سے ڈومین میں ایک محدود مقدار کے متعلق لکھی ہوئی ڈیٹ ڈیٹ ڈیٹ کے ساتھ موفق ہونے کے لئے۔ بنیس لین موڈل کی آواز پھیلائی جاتی ہے اور تغییر کی جاتی ہے، نتیجہ OOV رض کم کرتی ہے. ڈاٹا انتخاب استراتژی جو گہرے مورفولوژیکی بیٹوں اور سیمانٹیکی برابری پر بنی جاتی ہیں word2vec کے ذریعے معلوم اور بحث کی جاتی ہیں آزمائش تنظیمات ایک دوسری تفسیر سناریو میں ہے جہاں ASRs تین زبانوں میں طراحی کی گئی ہے کہ domainspecific terms (یعنی dentistry) پہچان سکیں۔ نتائج مختلف متریک (OOV رات, WER, دقیق اور یاد کرنا) کے مطابق پیشنهاد تکنیک کے مطابق دکھاتے ہیں.</abstract_ur>
      <abstract_mt>Aħna nindirizzaw il-problema tal-adattament tal-mudell lingwistiku fl-applikazzjonijiet fejn il-komponent ASR jeħtieġ li jimmaniġġja t-terminoloġija speċifika għad-dominju; għalkemm it-teknoloġija attwali ta’ rikonoxximent tad-diskors l-aktar avvanzata tipprovdi riżultati eċċellenti għal dominji ġeneriċi, l-adattament għal dikjararji jew glossarji speċjalizzati għadu kwistjoni miftuħa. F’dan ix-xogħol nippreżentaw approċċ għall-għa żla awtomatika tas-sentenzi, minn text corpus, li jaqblu, kemm semantikament kif ukoll morfoloġikament, glossarju ta’ termini (kliem jew kliem kompost) mogħti mill-utent. L-għan finali huwa li jiġi adattat malajr il-mudell lingwistiku ta’ sistema ASR ibrida b’ammont limitat ta’ dejta tat-test fid-dominju sabiex jiġi indirizzat b’suċċess id-dominju lingwistiku inkwistjoni; the vocabulary of the baseline model is expanded and tailored, reducing the resulting OOV rate.  L-istrateġiji tal-għażla tad-dejta bbażati fuq żrieragħ morfoloġiċi baxxi u similarità semantika permezz tal-kliem2vec huma introdotti u diskussi; the experimental setting consists in a simultaneous interpreting scenario, where ASRs in three languages are designed to recognize the domainspecific terms (i.e. dentistry).  Ir-riżultati li jużaw metriċi differenti (rata OOV, WER, preċiżjoni u ġbir lura) juru l-effettività tat-tekniki proposti.</abstract_mt>
      <abstract_uz>@ info: whatsthis Endi hozir suhbat soʻzni tasdiqlash teknologiya umumiy domene uchun juda yaxshi natijalar beradi, hozirgi shaxsiy lugʻatlarga qo'shish yoki glossalariga o'zgartirish hamda ochiq muammolar. Bu vazifani biz foydalanuvchiga qo'llanilgan so'zlarni avtomatik tanlash uchun, matn corpusdan o'xshash va oddiy soʻzlarni (so'zlar yoki bir soʻzlarni) oʻzgartirish mumkin. @ info: whatsthis tugmalar birikmasini ko'paytirish va qo'yish mumkin, natijasida OOV rate kamaytirish. Name tajribalar bir xil tarjima qiladigan bir xil tarjima holatda bo'ladi, bu yerda uchta tillarda ASR'lar domainspecific soʻzlarni aniqlashga (m'anaviy dentistri). @ info: status</abstract_uz>
      <abstract_vi>Chúng tôi giải quyết vấn đề thay đổi kiểu ngôn ngữ trong các ứng dụng mà phần phụ nằm trong nhu cầu quản lý các thuật ngữ đặc trưng miền; Mặc dù công nghệ nhận dạng ngôn ngữ hiện đại cung cấp kết quả tuyệt vời cho lĩnh vực chung, sự thích ứng với từ điển hay từ điển chuyên môn vẫn là vấn đề mở. Trong công việc này chúng tôi có một phương pháp để tự động lựa chọn các câu, từ một tập thể văn bản, khớp, theo ngữ pháp và lịch sử, từ ngữ hay từ soạn thảo được cung cấp bởi người dùng. Mục tiêu cuối cùng là phải nhanh chóng sửa đổi mô hình ngôn ngữ của một hệ thống ASR lai với một số lượng nhỏ dữ liệu văn bản nội bộ trong miền để xử lý thành công với lĩnh vực ngôn ngữ hiện tại. Vốn từ điển của mô hình cơ bản được mở rộng và tùy chỉnh, giảm tỷ lệ OOOV Kết quả. Các chiến lược chọn dữ liệu dựa trên các hạt điện tử nông cạn và nét giống nhau theo đường Word2Véc được đưa vào và thảo luận; thử nghiệm là một kịch bản diễn giải đồng thời, nơi đây các ASR (ASR) được thiết kế để nhận ra các từ nội môn đặc biệt (ví dụ như nha khoa). Kết quả sử dụng lượng tử khác nhau (tốc độ OOOV, lớp WER, độ chính xác và thu hồi) cho thấy hiệu quả của kỹ thuật được đề xuất.</abstract_vi>
      <abstract_bg>Разглеждаме проблема с персонализирането на езиковия модел в приложения, при които компонентът трябва да управлява специфичната за домейна терминология; Въпреки че съвременната технология за разпознаване на реч предоставя отлични резултати за генерични области, адаптацията към специализирани речници или речници все още е отворена тема. В тази работа е представен подход за автоматично избиране на изречения от текстов корпус, които съответстват както семантично, така и морфологично на речник от термини (думи или съставни думи), предоставен от потребителя. Крайната цел е бързо адаптиране на езиковия модел на хибридна система с ограничено количество текстови данни в областта, за да се справи успешно с езиковата област; речникът на базовия модел е разширен и адаптиран, намалявайки получената степен на OOV. Въведени са и обсъдени стратегии за подбор на данни въз основа на плитки морфологични семена и семантична сходство чрез word2vec; експерименталната обстановка се състои в сценарий на симултанен превод, при който АСР на три езика са предназначени да разпознават специфичните понятия (т.е. стоматология). Резултатите, използващи различни показатели (скорост на ОВ, прецизност и изземване) показват ефективността на предложените техники.</abstract_bg>
      <abstract_da>Vi løser problemet med tilpasning af sprogmodeller i applikationer, hvor ASR-komponenten skal administrere domænespecifik terminologi; Selvom den nuværende avancerede talegenkendelsesteknologi giver fremragende resultater for generiske domæner, er tilpasningen til specialiserede ordbøger eller ordlister stadig et åbent spørgsmål. I dette arbejde præsenterer vi en tilgang til automatisk udvælgelse af sætninger, fra et tekstkorpus, der både semantisk og morfologisk matcher en ordliste af termer (ord eller sammensatte ord) leveret af brugeren. Det endelige mål er hurtigt at tilpasse sprogmodellen for et hybridt ASR-system med en begrænset mængde tekstdata inden for domænet for at kunne klare det pågældende sprogområde. basismodellens ordforråd udvides og skræddersyes, hvilket reducerer den resulterende OOV-rate. Dataudvælgelsesstrategier baseret på lavvandede morfologiske frø og semantisk lighed via word2vec introduceres og diskuteres; Den eksperimentelle ramme består i et scenarie for simultantolkning, hvor ASR på tre sprog er designet til at genkende de domænespecifikke udtryk (dvs. tandlægehjælp). Resultater ved hjælp af forskellige målinger (OOV rate, WER, præcision og tilbagekaldelse) viser effektiviteten af de foreslåede teknikker.</abstract_da>
      <abstract_nl>We behandelen het probleem van taalmodel aanpassing in toepassingen waar de ASR component domeinspecifieke terminologie moet beheren; Hoewel de huidige state-of-the-art spraakherkenningstechnologie uitstekende resultaten biedt voor generieke domeinen, is de aanpassing aan gespecialiseerde woordenboeken of woordenlijsten nog steeds een open kwestie. In dit werk presenteren we een aanpak voor het automatisch selecteren van zinnen, uit een tekstcorpus, die zowel semantisch als morfologisch overeenkomen met een woordenlijst van termen (woorden of samengestelde woorden) die door de gebruiker wordt verstrekt. Het uiteindelijke doel is om snel het taalmodel van een hybride ASR-systeem aan te passen met een beperkte hoeveelheid in-domein tekstgegevens om succesvol te kunnen omgaan met het betreffende taaldomein; de woordenschat van het basismodel wordt uitgebreid en aangepast, waardoor het resulterende OOV-percentage wordt verminderd. Data selectie strategieën gebaseerd op ondiepe morfologische zaden en semantische gelijkenis via word2vec worden geïntroduceerd en besproken; De experimentele setting bestaat uit een simultaan tolkscenario, waarbij ASR's in drie talen zijn ontworpen om de domeinspecifieke termen (d.w.z. tandheelkunde) te herkennen. Resultaten met behulp van verschillende metrics (OOV rate, WER, precisie en recall) tonen de effectiviteit van de voorgestelde technieken aan.</abstract_nl>
      <abstract_hr>rješavamo problem prilagođenja jezičkih modela u aplikacijama u kojima ASR komponent mora upravljati terminologijom specifičnog domena; Iako trenutna tehnologija priznanja govora predstavlja odlične rezultate za generalne domene, prilagodba specijaliziranim riječima ili glossarima još uvijek je otvorena pitanja. U ovom poslu predstavljamo pristup automatskom odabiru rečenica, iz tekstnog korpusa, koji se odgovara, i semantički i morfološki, glossary termina (riječi ili složene riječi) koje je predstavio korisnik. Posljednji cilj je brzo prilagoditi jezički model hibridnog ASR sustava sa ograničenom količinom podataka o tekstu u domenu kako bi se uspješno suočio s približnim jezičkim domenom; Vječnik početnog modela se proširi i prilagođuje, smanjujući rezultat stope OOV-a. Upoznaju se i raspravljaju strategije izbora podataka na temelju plitkih morfoloških sjemena i semantičke sličnosti putem rečenica 2vec; eksperimentalna postavka sastoji se u istovremenom scenariju interpretacije, gdje su ASR na tri jezika dizajnirani kako bi prepoznali specifične termine domena (tj. zubarska). Rezultati koristeći različite metrike (stopa OOV, WER, preciznost i sjećanje) pokazuju učinkovitost predloženih tehnika.</abstract_hr>
      <abstract_id>Kami mengatasi masalah penyesuaian model bahasa dalam aplikasi dimana komponen ASR perlu mengelola terminologi spesifik domain; meskipun teknologi pengenal pidato yang terbaik saat ini menyediakan hasil yang baik untuk domain generik, adaptasi ke kamus atau glosari yang spesialisasi masih masalah terbuka. Dalam pekerjaan ini kami mempersembahkan pendekatan untuk memilih kalimat secara otomatis, dari sebuah corpus teks, yang cocok, secara semantis dan morfologis, glosari istilah (kata atau kata komposit) yang diberikan oleh pengguna. Tujuan akhir adalah dengan cepat mengadaptasi model bahasa dari sistem ASR hibrid dengan jumlah terbatas data teks dalam domain untuk berhasil menghadapi domain bahasa di tangan; vocabulari model dasar diperbesar dan disesuaikan, mengurangi kadar OOV yang berasal. Strategi pemilihan data berdasarkan benih morfologi rendah dan persamaan semantis melalui word2vec diperkenalkan dan didiskusikan; seting eksperimen terdiri dari skenario interpretasi simultan, di mana ASR dalam tiga bahasa dirancang untuk mengenali istilah domain khusus (i.e. dokter gigi). Hasil menggunakan metrik yang berbeda (kadar OOV, WER, presisi dan recall) menunjukkan efektif dari teknik yang diusulkan.</abstract_id>
      <abstract_ko>우리는 ASR 구성 요소가 특정 분야의 용어를 관리해야 하는 응용 프로그램의 언어 모델 맞춤형 문제를 해결했다.비록 현재 가장 선진적인 음성인식 기술이 통용 분야에 좋은 결과를 제공했지만 전문 사전이나 어휘표에 대한 적응은 여전히 현안으로 남아 있다.이 작업에서 우리는 텍스트 자료 라이브러리에서 자동으로 문장을 선택하는 방법을 제시했는데 이 문장들은 의미와 형태가 사용자가 제공한 용어표(단어나 복합어)와 일치한다.최종 목표는 유한한 역내 텍스트 데이터 상황에서 혼합 ASR시스템의 언어 모델을 신속하게 조정하여 수중의 언어 영역을 성공적으로 처리하는 것이다.기선모델의 어휘표는 확장과 맞춤형을 받아 최종 OOV율을 낮추었다.얕은 형태의 피드와word2vec의 의미 유사도를 바탕으로 하는 데이터 선택 전략을 소개하고 토론했다.실험 환경은 동시통역 장면을 포함하는데 이 중 세 가지 언어의 ASR은 특정 영역을 식별하는 용어(즉 치과)로 설계되었다.서로 다른 지표(OOV율, WER, 정확도와 리콜율)를 사용한 결과 제시된 기술의 유효성을 나타냈다.</abstract_ko>
      <abstract_de>Wir behandeln das Problem der Anpassung von Sprachmodellen in Anwendungen, bei denen die ASR-Komponente domänenspezifische Terminologie verwalten muss; Obwohl der aktuelle Stand der Technik der Spracherkennung hervorragende Ergebnisse für generische Domänen liefert, ist die Anpassung an spezialisierte Wörterbücher oder Glossare nach wie vor ein offenes Thema. In dieser Arbeit präsentieren wir einen Ansatz zur automatischen Auswahl von Sätzen aus einem Textkorpus, die sowohl semantisch als auch morphologisch einem vom Benutzer bereitgestellten Glossar von Begriffen (Wörter oder zusammengesetzte Wörter) entsprechen. Das endgültige Ziel ist es, das Sprachmodell eines hybriden ASR-Systems mit einer begrenzten Menge an In-Domain-Textdaten schnell anzupassen, um erfolgreich mit der jeweiligen linguistischen Domäne umgehen zu können. Der Wortschatz des Basismodells wird erweitert und angepasst, wodurch die resultierende OOV-Rate reduziert wird. Datenselektionsstrategien basierend auf flachen morphologischen Samen und semantischer Ähnlichkeit über word2vec werden vorgestellt und diskutiert; Das experimentelle Setting besteht in einem Simultandolmetschen Szenario, bei dem ASRs in drei Sprachen entworfen werden, um die domänenspezifischen Begriffe (d.h. Zahnmedizin) zu erkennen. Ergebnisse mit verschiedenen Metriken (OOV-Rate, WER, Präzision und Rückruf) zeigen die Wirksamkeit der vorgeschlagenen Techniken.</abstract_de>
      <abstract_fa>ما مشکل تنظیم مدل زبانی را در کاربردهای که بخش ASR نیاز دارد به مدیریت ترمینالوژی ویژه دارد دریافت کنیم. اگرچه تکنولوژی شناسایی سخنرانی فعلی هنری نتیجه‌های عالی برای دامنهای ژنرالی پیشنهاد می‌کند، تغییر دادن به لغوی‌های متخصص یا کلاوساری هنوز یک مسئله باز است. در این کار، ما یک روش برای انتخاب کردن جمله‌ها، از یک کورپوس متن، که همچنین، هر دو از semantically و morfologically، یک کلاسی از جمله‌ها (کلمات یا کلمات ترکیب) که توسط استفاده‌کننده ارائه داده می‌شود را پیشنهاد می‌کنیم. هدف نهایی این است که به سرعت مدل زبانی یک سیستم ASR هیبرید را با مقدار محدود از داده‌های متن در دامنه‌ی دامنه برای موفقیت با مدل زبان‌شناسی در دسترس کند. کلمات مدل پایین گسترش داده و تغییر داده می شود، با کاهش نرخ نتیجه OOV. استراتژی انتخاب داده‌ها بر اساس بیل‌های مورفولوژیکی و شبیه‌ای semantic از طریق کلمه 2vec معرفی می‌شوند و بحث می‌شوند; تنظیم آزمایشی در یک سناریو تفسیر همزمان است، جایی که ASRs در سه زبان طراحی می‌شوند تا شرایط مخصوص دامنه را شناسایی کنند (یعنی دندانشناسی). نتیجه‌های استفاده از متریک متفاوت (نرخ OOV, WER, دقیق و یادآوری) موثیت تکنیک پیشنهاد را نشان می‌دهند.</abstract_fa>
      <abstract_af>Ons adres die probleem van taal model pasmaak in toepassings waar die ASR komponent nodig om domein-spesifieke terminologie te bestuur; alhoewel die huidige staat-van-die-kunste sprekking-herkening teknologie voorsien uitgelukkige resultate vir algemene domeine, die aanpassing na spesialiseerde woordeboeke of glossarie is nog nog 'n oop probleem. In hierdie werk vertoon ons 'n toegang vir outomatiese kies van teikens, van 'n teks korpus, wat ooreenstem, beide semantiese en morfologiese,  'n glossary van terme (woorde of komponente woorde) wat deur die gebruiker verskaf word. Die eindelike doel is om vinnig die taal model van 'n hybrid ASR stelsel a an te pas met' n beperkte hoeveelheid in-domein teks data om suksesvol te kopeer met die lingvisiese domein aan die hand; Die woordeboek van die basisline model is uitgevou en vergroot, verduur die resulteerde OOV rate. Data-keuse strategies gebaseer op skaal morfologiese seede en semantiese gelykenis deur woord2vec word ingevoer en gespreek; en Die eksperimentale instelling bestaan in 'n simultanee uitleggingsscenario waar ASR in drie tale ontwerp word om die domeinspesifieke terme te herken (bv. dentistry). Resultate gebruik verskillende metries (OOV rate, WER, precision and recall) wys die effektiviteit van die voorgestelde tekniks.</abstract_af>
      <abstract_sw>Tunaongelea tatizo la utambulisho wa mifano ya lugha katika matumizi ambayo komponent ya ASR inahitaji kusimamia tamaduni maalum za ndani; Ingawa teknolojia ya sasa ya kutambua hotuba ya sanaa inatoa matokeo mazuri kwa maeneo ya kawaida, mabadiliko ya lugha maalumu au sifa bado ni suala la wazi. Katika kazi hii tunaweka mbinu ya kuchagua hukumu za kujitegemea, kutoka kwenye makampuni ya maandishi, yanayochanganya, kwa kiasi kikubwa na kifolojia, yenye msingi wa maneno (maneno au maneno yanayotengenezwa) yaliyotolewa na mtumiaji. The final goal is to rapidly adapt the language model of an hybrid ASR system with a limited amount of in-domain text data in order to successfully cope with the linguistic domain at hand;  lugha ya muundo wa msingi unaongezeka na kupunguza kiwango cha OOV kinachosababishwa. Mpango wa uchaguzi wa data unaotengenezwa na mbegu mbaya za kifolojia na usawa wa kimapenzi kupitia word2vec unaanzishwa na kujadiliwa; Mpango wa majaribio unajumuisha katika eneo la tafsiri moja kwa moja, ambapo ASRs kwa lugha tatu zinalengwa kutambua vipengele maalum (yaani daktari). Matokeo kwa kutumia mbinu tofauti (kiwango cha OOV, WER, uhakika na kumbukumbu) yanaonyesha ufanisi wa teknolojia zilizopendekezwa.</abstract_sw>
      <abstract_tr>ASR komponentiň domein häzirki terminologiýany bejermeli ýerlerde dil nusgasynyň kynçylygyny çözdiris; Häzirki sanat taýýarlanmasy teknolojisi jeneral sahypalar üçin örän netijede getirilýär, oňat sözlerniň ýa-da sözlerniň adaptasiýasy entägem açyk meseledir. Bu işde biz sözleri awtomatik saýlamak üçin bir tekst korpusdan tanyýarys. Bu sözleri hem semantik hem morfologik bilen tanyýan sözleri (sözler ýa-da kompozit sözler) ullanýar. Soňky maksady - bir hybrid ASR sisteminiň dili modelini domenyň metin maglumaty bilen ýüze çykmak üçin elinde lingwistiki domenyň üstine çykmak üçin tiz bir şekilde üýtgetmekdir; Basit nusgynyň sözleri genişletilýär we üýtgedilýär, netijeli OOV derejesini azaltýar. Veri saýlamak stratejikleri d2vek üzerinde dağ morfolojik ösümliklere ve semantik benzeri şeklinde dayanan ve tartışılan; Deneysel düzümleri bir terjime senaryýaly bolýar, üç dilde ASRlar sahypalaryň spesifik terjimelerini tanamak üçin tassyklanýar. Netijeler üýtgeşik metriklerden ullanýarlar (OOV hasaby, WER, dogrudylyk we hatyrlamak) teknikleriň etkinliýetini görkezýär.</abstract_tr>
      <abstract_az>Biz, ASR komponenti domain-specific terminologiyanı idarə etmək lazım olduğu proqramlarda dil modellərin təmizlənməsinin problemini çəkirik; Şimdiki şəkildə sanat sözlərinin tanıması teknolojisi generiki domenalar üçün mükemmel sonuçlar verir, məxluqat sözlərinə və sözlərinə uyğunlaşdırmaq hələ də açıq bir meseledir. Bu işlərdə, istifadəçinin təyin edilən sözləri, mətn korpusundan, hem semantik kimi də morfolojik ilə eşidən şəkillərin sözləri (sözlər və ya kompozit sözlərin sözləri) ilə avtomatik seçmək üçün bir yol göstəririk. Son məqsəd hibrid ASR sisteminin dil modelini müəyyən dəyişdirməkdir ki, əlində olan dil domenası ilə müvəffəqiyyətlə başa düşmək üçün dəyişdirilmiş məlumat məlumatlarının qısa dəyişdirilməsidir; Səhv modelinin sözləri genişlənir və təmizlənir, sonuçlarının OOV dərəsini azaldırır. Qısqa morfolojik əkinlərin və semantik istifadə ilə daxil edilən məlumat seçmə stratejilərini təşkil edir və mübahisə edirlər; təcrübə quruluşu, üç dildə ASR-lər domeinin müəyyən edilmiş şəkillərini tanıtmaq üçün təcrübə edilmiş bir təcrübə senaryosu i çindədir. Müxtəlif metriklərdən istifadə edilən nəticələr (OOV dərəcəsi, WER, dəqiqliyyat və yada salmaq üçün) təklif edilmiş tekniklərin etkinliğini göstərər.</abstract_az>
      <abstract_hy>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology;  չնայած, որ ներկայիս ամենաբարձր խոսքի ճանաչման տեխնոլոգիան հիանալի արդյունքներ է տալիս ընդհանուր բնագավառների համար, հատուկ բառարանների կամ խմբասարների հարմարվելը դեռևս բաց խնդիր է: Այս աշխատանքում մենք ներկայացնում ենք նախադասությունների ավտոմատ ընտրման մոտեցումը տեքստի կորպոսից, որը համապատասխանում է, սեմանտիկապես և մորֆոլոգիապես, օգտագործողի կողմից տրամադրված տերմինների (բառերի կամ կոմպոզիտային բառերի) խմբասարին: Վերջնական նպատակն է արագ հարմարեցնել հիբրիդ ASR համակարգի լեզվային մոդելը, որն ունի սահմանափակ քանակությամբ տեքստի տվյալներ տիեզերքում, որպեսզի հաջողությամբ հաղթահարվի այս լեզվական տիեզերքի հետ: հիմնական մոդելի բառախոսները ընդլայնվում են և պատրաստվում են, նվազեցնելով արդյունքում ստացված OOO արագությունը: Տվյալների ընտրության ռազմավարությունները, որոնք հիմնված են մակերեսային մորֆոլոգիական սերմերի վրա և սեմանտիկ նմանությունների միջոցով, ներկայացվում և քննարկվում են: փորձարկումները կազմված են միաժամանակային մեկնաբանական սցենարից, որտեղ ASR-ները երեք լեզուներով ստեղծված են որպեսզի ճանաչեն բնագավառի հատուկ տերմինները (այսինքն՝ ատամնաբուժությունը): Արդյունքները, որոնք օգտագործում են տարբեր չափումներ (OOO արագություն, WER, ճշգրտություն և վերադարձում) ցույց են տալիս առաջարկած մեթոդների արդյունավետությունը:</abstract_hy>
      <abstract_am>የቋንቋ ምሳሌ ማሳየትን በተጨማሪው ፕሮግራሞች ውስጥ የASR ሰንካኖቹ ዶሜን-specific ተርሚኖሎጂን ማቀናጃ ያስፈልጋቸዋል፡ የአሁኑ የቋንቋ-ቋንቋ-ቋንቋ ማውቀት ቴክኖሎጂ የgeneric ውጤቶች የሚያደርጋቸው ቢሆንም፣ የባሕላዊ መዝገብ መፍታት ወይም የክብር ማቀናቀል ግን የተከፈተ ጉዳይ ነው፡፡ በዚህ ስራ የተጠቃሚ ቃላት (ቃላት ወይም ተቃውሞ ቃላት) የተገኘውን የጽሑፍ ኮፕስ፣ የጽሑፍ ቃላትን በመምረጥ እናደርጋለን፡፡ የመጨረሻው ጉዳዩ የድምፅ ቋንቋ ምሳሌ የሆብሪክ ASR ሲስተም በተለየ የድምፅ ጽሑፍ ዳታዎችን በሙሉ ማቀናቀል ነው፤ የቋንቋው ድምፅ አካባቢ በኩል ማቀናቀል፡፡ the vocabulary of the baseline model is expanded and tailored, reducing the resulting OOV rate.  የዳታ ምርጫ strategies በመጠቀም እና በተጨማሪው የሞሮፎሎጂ ዘር እና የsemantic similarity በመጠቀም እና በተጨማሪው ነው፡፡ የፈተናው ግንኙነት በሦስት ቋንቋዎች ውስጥ የዶሞን ግንኙነት (ምናልባት ጥርስ) ለማወቅ የተፈጠረ ነው፡፡ ፍሬዎቹ የተለየ ሚትሪኮች (OOV rate, WER, precision እና ማስታወስ) የተዘጋጀውን የቴክኖክኖች ጥቅም ያሳያል፡፡</abstract_am>
      <abstract_bn>আমরা অ্যাপ্লিকেশনে ভাষার মডেল ব্যবহারের সমস্যা নিয়ে কথা বলি যেখানে ASR কম্পোনেন্টের ডোমেইন-নির্দিষ্ট ট টার্মিনোলজি  যদিও বর্তমান রাষ্ট্র-অফ-শিল্পের বক্তৃতা স্বীকৃতি প্রযুক্তি সাধারণ ডোমেনের জন্য ভাল ফলাফল প্রদান করে, তবে বিশেষ অভিভাবক বা গ্রাহ এই কাজে আমরা স্বয়ংক্রিয়ভাবে বেছে নেওয়ার জন্য একটি পদক্ষেপ উপস্থাপন করি ব্যবহারকারীর দ্বারা প্রদান করা একটি টেক্সট কোর্পাস থেকে যা মিলে যায়, যা দ্বৈতিক এব শেষ লক্ষ্য হচ্ছে একটি হাইব্রিড ASR সিস্টেমের ভাষার মডেল দ্রুত সংশোধন করার জন্য ডোমেইনের টেক্সট ডাটা সীমিত, যাতে ভাষাগত ডোমেইনের সাথে সফলভা বেসেলাইন মডেলের শব্দভাণ্ডার বিস্তৃত এবং তালিকা বৃদ্ধি এবং ফলাফল অওভি হার কমিয়ে দেয়। ওয়ার্ড২ভেকের মাধ্যমে অল্প মরোফোলিক্যাল বিজ্ঞান এবং সেমান্টিক সমতার উপর ভিত্তিক তথ্য নির্বাচন কৌশল পরিচালনা করা হয় এবং আলোচনা  এই পরীক্ষার বৈশিষ্ট্য একই সাথে একই সাথে ব্যাখ্যা করার পরীক্ষায় রয়েছে, যেখানে তিন ভাষায় আসার নির্দিষ্ট শব্দ স্বীকার করার জন্য ডোমে ফলাফল বিভিন্ন মেট্রিক ব্যবহার করে (OOV হার, WER, precision and remember) প্রস্তাবিত প্রযুক্তির কার্যক্রম প্রদর্শন করে।</abstract_bn>
      <abstract_ca>Ens ocupem del problema de la personalització del model de llenguatge en aplicacions on el component ASR necessita gestionar la terminologia específica per domini; tot i que la tecnologia actual de reconeixement de la llengua ofereix resultats excelentes per a dominis genèrics, l'adaptació a diccionaris o glossaris especialitzats encara és una qüestió oberta. En aquesta obra presentem un enfocament per seleccionar automàticament frases, d'un corpus de text, que coincideixen, tant semànticament com morfològicament, amb un glossari de termes (paraules o paraules composites) proporcionat per l'usuari. L'objectiu final és adaptar ràpidament el model de llenguatge d'un sistema ASR híbrid amb una quantitat limitada de dades de text en domini per afrontar amb èxit el domini lingüístic a mà; el vocabulari del model de base està expandit i adaptat, reduint la tasa d'OOV resultant. S'introdueixen i es discuten estratègies de selecció de dades basades en semilles morfològiques baixes i similitud semàntica a través de word2vec; l'entorn experimental consisteix en un escenari d'interpretació simultànea, on les AAS en tres llengües estan dissenyades per reconèixer els termes específics de domini (i.e. dentistes). Els resultats que utilitzen diferents mètriques (velocitat OOV, WER, precisió i recuperació) mostren l'eficacia de les tècniques proposades.</abstract_ca>
      <abstract_et>Tegeleme keelemudeli kohandamise probleemiga rakendustes, kus ASR komponent peab hallama domeenispetsiifilist terminoloogiat; Kuigi praegune kaasaegne kõnetuvastustehnoloogia annab suurepäraseid tulemusi üldistele valdkondadele, on spetsialiseeritud sõnaraamatutele või sõnastikutele kohandamine endiselt lahtiseks probleemiks. Käesolevas töös esitame lähenemisviisi tekstikorpusest automaatselt valitud lausete valimiseks, mis vastavad nii semantiliselt kui morfoloogiliselt kasutaja poolt esitatud terminite sõnastikule (sõnad või komposiitsõnad). Lõplik eesmärk on kiiresti kohandada hübriidse ASR-süsteemi keelemudelit piiratud koguse domeenisiseste tekstiandmetega, et edukalt toime tulla käesoleva keelelise valdkonnaga; baasmudeli sõnavara laiendatakse ja kohandatakse, vähendades sellest tulenevat OOV määra. Tutvustatakse ja arutatakse madalatel morfoloogilistel seemnetel ja semantilisel sarnasusel põhinevaid andmete valimise strateegiaid Word2vec kaudu; eksperimentaalne keskkond koosneb sünkroontõlke stsenaariumist, kus ASR kolmes keeles on mõeldud domainspetsiifiliste terminite (st hambaarsti) tunnustamiseks. Erinevate mõõdikute kasutamise tulemused (OOV määr, WER, täpsus ja tagasikutsumine) näitavad kavandatud meetodite tõhusust.</abstract_et>
      <abstract_bs>Mi rješavamo problem prilagođenja jezičkih modela u aplikacijama u kojima ASR komponent mora upravljati terminologijom specifičnog domena; Iako trenutna tehnologija priznanja govora predstavlja odlične rezultate za generičke domene, adaptacija specijalizovanih rečenika ili glossarija još uvijek je otvorena pitanja. U ovom poslu predstavljamo pristup automatskom odabiru rečenica, iz tekstnog korpusa, koji se odgovara, i semantički i morfološki, rečnik termina (riječi ili složene riječi) koji je predstavljao korisnik. Posljednji cilj je brzo prilagoditi jezički model hibridnog ASR sustava sa ograničenom količinom podataka o tekstu u domenu kako bi se uspješno suočio sa približnim jezičkim domenama; rečnik osnovnog modela se proširi i prilagođuje, smanjujući rezultat stope OOV-a. Upisuju i raspravljaju se strategije selekcije podataka na temelju plitkih morfoloških sjemena i semantičke sličnosti putem rečenica 2vec; eksperimentalni nastav se sastoji u istovremenom scenariju interpretacije, gdje su ASR na tri jezika dizajnirani kako bi prepoznali specifične termine domena (tj. zubara). Rezultati koristeći različite metrike (stopa OOV, WER, preciznost i sjećanje) pokazuju učinkovitost predloženih tehnika.</abstract_bs>
      <abstract_cs>Řešíme problém přizpůsobení jazykového modelu v aplikacích, kde ASR komponenta potřebuje spravovat doménově specifickou terminologii; Ačkoli současná nejmodernější technologie rozpoznávání řeči poskytuje vynikající výsledky pro generické domény, adaptace na specializované slovníky nebo slovníky je stále otevřeným problémem. V této práci představujeme přístup k automatickému výběru vět z textového korpusu, které odpovídají sémanticky i morfologicky slovníku pojmů (slova nebo složená slova) poskytnutému uživatelem. Konečným cílem je rychlé přizpůsobení jazykového modelu hybridního ASR systému s omezeným množstvím textových dat v doméně tak, aby se úspěšně vyrovnalo s danou jazykovou doménou; slovní zásoba základního modelu je rozšířena a přizpůsobena, což snižuje výslednou rychlost OOV. Jsou představeny a diskutovány strategie výběru dat založené na mělkých morfologických semenech a sémantické podobnosti prostřednictvím Word2vec; Experimentální prostředí spočívá v simultánním tlumočení scénáři, kdy jsou ASR ve třech jazycích navrženy tak, aby rozpoznaly doménově specifické termíny (tj. stomatologie). Výsledky použití různých metrik (OOV rychlost, WER, přesnost a odvolání) ukazují účinnost navržených technik.</abstract_cs>
      <abstract_fi>Käsittelemme kielimallin mukauttamisen ongelmaa sovelluksissa, joissa ASR-komponentin on hallittava verkkotunnuskohtaista terminologiaa. Vaikka nykyaikainen puheentunnistustekniikka tuottaa erinomaisia tuloksia yleismaailmallisille toimialoille, sopeutuminen erikoissanakirjoihin tai sanastoihin on edelleen avoin asia. Tässä työssä esitellään lähestymistapa lauseiden automaattiseen valintaan tekstikorpusesta, jotka vastaavat sekä semanttisesti että morfologisesti käyttäjän toimittamaa sanastoa (sanoja tai yhdistelmäsanoja). Lopullisena tavoitteena on mukauttaa nopeasti hybridi ASR-järjestelmän kielimallia, jossa on rajoitettu määrä verkkotunnuksen tekstitietoja, jotta voidaan selviytyä menestyksekkäästi käsillä olevasta kielialasta. Perusmallin sanastoa laajennetaan ja räätälöidään siten, että tuloksena oleva OOV-luku pienenee. Tiedon valintastrategioita, jotka perustuvat mataliin morfologisiin siemeniin ja semanttiseen samankaltaisuuteen word2vec-menetelmällä, esitellään ja käsitellään. Kokeellinen ympäristö koostuu simultaanitulkkausskenaariosta, jossa ASR:t kolmella kielellä on suunniteltu tunnistamaan domainspecific terms (eli hammaslääketiede). Eri mittareiden (OOV-nopeus, WER, tarkkuus ja takaisinkutsu) tulokset osoittavat ehdotettujen tekniikoiden tehokkuuden.</abstract_fi>
      <abstract_sq>Ne trajtojmë problem in e personalizimit të modelit gjuhësor në aplikime ku komponenti ASR duhet të menaxhojë terminologjinë specifike për domenin; megjithëse teknologjia aktuale e njohjes së fjalimit ofron rezultate të shkëlqyera për fushat gjenerike, përshtatja ndaj fjalorëve apo glosarëve të specializuar është ende një çështje e hapur. Në këtë punë ne paraqesim një qasje për zgjedhjen automatike të fjalëve, nga një korpus teksti, që përputhet, si semantikisht ashtu edhe morfologikisht, me një glossar të termave (fjalë apo fjalë të kompozuara) të furnizuar nga përdoruesi. Qëllimi përfundimtar është të përshtatet shpejt modeli gjuhësor i një sistemi hibridik ASR me një sasi të kufizuar të dhënash teksti në domeni me qëllim që të përballet me sukses me domenin gjuhësor në dorë; fjalorin e modelit bazë zgjerohet dhe përshtatet, duke reduktuar normën OOV që rezulton. Data selection strategies based on shallow morphological seeds and semantic similarity via word2vec are introduced and discussed;  vendosja eksperimentale përbëhet në një skenar të përkthimit të njëkohëshëm, ku ASR në tre gjuhë janë dizajnuar për të njohur termat specifike në domeni (pra, dentistri). Rezultatet duke përdorur metrika të ndryshme (norma OOV, WER, saktësia dhe tërheqja) tregojnë efektshmërinë e teknikave të propozuara.</abstract_sq>
      <abstract_sk>Obravnavamo problem prilagajanja jezikovnega modela v aplikacijah, kjer mora komponenta ASR upravljati domensko specifično terminologijo; Čeprav sodobna tehnologija prepoznavanja govora zagotavlja odlične rezultate za generične domene, je prilagoditev specializiranim slovarjem ali slovarjem še vedno odprta. V tem delu predstavljamo pristop za samodejno izbiro stavkov iz besedilnega korpusa, ki se semantično in morfološko ujemajo s slovarjem izrazov (besed ali sestavljene besede), ki jih pripravi uporabnik. Končni cilj je hitro prilagoditi jezikovni model hibridnega ASR sistema z omejeno količino domenskih besedilnih podatkov za uspešno obvladovanje jezikovne domene; besedišče osnovnega modela je razširjeno in prilagojeno, s čimer se zmanjša posledična stopnja OOV. Predstavljene so in obravnavane strategije izbire podatkov, ki temeljijo na plitvih morfoloških semenih in semantični podobnosti prek word2vec; eksperimentalno okolje je sestavljeno iz scenarija simultanega tolmačenja, kjer so ASR v treh jezikih oblikovani tako, da prepoznajo domače izraze (npr. zobozdravstvo). Rezultati z uporabo različnih meritev (stopnja OOV, WER, natančnost in odpoklic) kažejo učinkovitost predlaganih tehnik.</abstract_sk>
      <abstract_he>אנחנו מתייחסים לבעיה של התאמת מודל שפה בתוכניות שבהן הרכיב ASR צריך לנהל טמינולוגיה ספציפית לתחום; although current state-of-the-art speech recognition technology provides excellent results for generic domains, the adaptation to specialized dictionaries or glossaries is still an open issue.  בעבודה הזו אנו מציגים גישה לבחירה אוטומטית משפטים, מתוך קופוס טקסט, שמתאים, באופן סמנטי ומורפולוגי, גלוסאר של מונחים (מילים או מילים מורכבות) מרווחים על ידי המשתמש. המטרה הסופית היא להסתגל במהירות את מודל השפה של מערכת ASR היברידה עם כמות מוגבלת של נתוני טקסט בתחום המילים של המודל הבסיסי מתרחבים ומתאים במיוחד, ומפחית את קצב האוויר הנוצא. אסטרטגיות לבחירת נתונים מבוססות על זרעים מורפולוגיים שטחים וכמויות סמנטיות באמצעות מילת 2vec מוצגות ומדוברות על כך; המצב הניסיוני מורכב בתרחיש הפרשנות באותו זמן, שבו ASR בשלושה שפות מעוצבים כדי לזהות את המונחים המיוחדים בתחום (כלומר, שיניים). התוצאות באמצעות מטריות שונות (קצב OOV, WER, מדויק וחזרה) מראות את היעילות של הטכניקות המוצעות.</abstract_he>
      <abstract_jv>We Address the question of language model custom in aplications Where the ASR komputer has to control domain-special terminal; and politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé nglanggar aturan macem kanggo ijol-ijolan winih, suku kelompok teks, dadi ambekan, sematik lan modorologi, akeh sabên kelompok (awak dhéwé uga luwih apik) gagal dhéwé The last goal is to speed up the language model of an HyBridge ASR System with a limitamount of in-domain text data in order to success Cop with the language domain at hand; and structural navigation Data Kelangan Sitèrji sing basa karo nggawe modhak modhak karo semanti sampeyan karo word2vec sampeyan karo winih; punika diputaaken karo perusahaan Ndheke sampeyan panjenengan langgar sampeyan pating nggunaké Panjenengan, kawur ASRs ning telu dilangan sing dibenakno kanggo ngerasakno Kasunyatan (ta.d. Denistri). Perintah sing gambar nggambar meta (OOOOK rate, WAR, dadi ntah lan ngajar) iso nggambar efetis teknik sing bisa dianggawe</abstract_jv>
      <abstract_ha>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology;  ingawa na halin-muhimmin-maganar-sanar, ko kuma yana da matsalar masu kyaun matsayi ga jama'a guda, kuma da adaptarin da aka ƙayyade dictionaries da hanyarta masu ƙayyade, sai yana da wani masu buɗewa. Daga wannan aikin da Muke ƙayyade wani hanyoyi wa ka zãɓi maganar farat ɗaya, daga nau'in matsayi, wanda ya yi daidai da shi, a kan dubi'a da kisa da morfologi, wata hanyor maganar (maganar ko da maganar da aka haɗa) da mai amfani da shi. Gani na ƙarshen shine a sake adadin misalin harshen na'ura na wata na'urar haske na haske na tsarin matsayin cikin-Domen don ya samu da babban samun ayuka na linguistic da hannun; dictionary variant An introduce kuma aka yi musu magana Tsarin da aka samu cikin wani fassarar da ke sami, inda an design ANRs cikin harshen uku, dõmin a gane maganar da aka ƙayyade (misali, tanƙon). Mataimakin su yi amfani da wasu metrici dabam (OOV rates, WER, ƙayyade da tunãtarwa) za'a nuna aikin tufãfin da aka buƙata.</abstract_ha>
      <abstract_bo>We address the problem of language model customization in applications where the ASR component needs to manage domain-specific terminology; and ད་ལྟོའི་གནས་སྟངས ང་ཚོས་ལག་ལེན་པ་ཞིག་གིས་རང་འགུལ་གྱིས་གདམ་པའི་ཚིག་རྐང་ཞིག་འདེམས་པའི་ཐབས་ལམ་སྟོན་ན། The final goal is to rapidly adapt the language model of an hybrid ASR system with a limited amount of in-domain text data in order to successfully cope with the linguistic domain at hand;  རྨང་གཞིའི་མ་དབྱིབས་ཀྱི་བརྡ་སྤྲོད་དེ་ពង་བསྐྱེད་དང་རྗེས་ཀྱི་ནང་དུ་བཏོན་ཡོད། གནད་དོན་འགྱུར་བའི་ཆ་འཕྲིན་དང་semantic similarity་ཀྱིས་word2vec སྤྲོད་ནས་བསམ་བློ་གཏོང་། སྔོན་ལྟ་བུའི་སྒྲིག་འཛུགས་དེ་མཚུངས་གཅིག་གི་དཔེ་རྟགས་བཀོད་པའི་སྐད་རིགས་གསུམ་ནང་དུ་ཡོད། Results using different metrics (OOV rate, WER, precision and recall) show the effectiveness of the proposed techniques.</abstract_bo>
      </paper>
    </volume>
  <volume id="at4ssl" ingest-date="2021-08-19">
    <meta>
      <booktitle>Proceedings of the 1st International Workshop on Automatic Translation for Signed and Spoken Languages (AT4SSL)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Dimitar</first><last>Shterionov</last></editor>
      <url hash="8f55092e">2021.mtsummit-at4ssl</url>
    </meta>
    <frontmatter>
      <url hash="1714f5bc">2021.mtsummit-at4ssl.0</url>
      <bibkey>mtsummit-2021-international</bibkey>
    </frontmatter>
    <paper id="3">
      <title>Sign and Search : Sign Search Functionality for Sign Language Lexica</title>
      <author><first>Manolis</first><last>Fragkiadakis</last></author>
      <author><first>Peter</first><last>van der Putten</last></author>
      <pages>23-32</pages>
      <url hash="deda50c0">2021.mtsummit-at4ssl.3</url>
      <abstract>Sign language lexica are a useful resource for researchers and people learning <a href="https://en.wikipedia.org/wiki/Sign_language">sign languages</a>. Current implementations allow a user to search a sign either by its gloss or by selecting its primary features such as <a href="https://en.wikipedia.org/wiki/Handshape">handshape</a> and <a href="https://en.wikipedia.org/wiki/Location">location</a>. This study focuses on exploring a reverse search functionality where a user can sign a query sign in front of a webcam and retrieve a set of matching signs. By extracting different body joints combinations (upper body, dominant hand’s arm and wrist) using the pose estimation framework OpenPose, we compare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance metrics between 20 query signs, each performed by eight participants on a 1200 sign lexicon. The results show that UMAP and DTW can predict a matching sign with an 80 % and 71 % <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> respectively at the top-20 retrieved signs using the movement of the dominant hand arm. Using DTW and adding more sign instances from other participants in the lexicon, the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> can be raised to 90 % at the top-10 ranking. Our results suggest that our <a href="https://en.wikipedia.org/wiki/Methodology">methodology</a> can be used with no training in any sign language lexicon regardless of its size.</abstract>
      <bibkey>fragkiadakis-van-der-putten-2021-sign</bibkey>
    </paper>
    <paper id="4">
      <title>The Myth of Signing Avatars</title>
      <author><first>John C.</first><last>McDonald</last></author>
      <author><first>Rosalee</first><last>Wolfe</last></author>
      <author><first>Eleni</first><last>Efthimiou</last></author>
      <author><first>Evita</first><last>Fontinea</last></author>
      <author><first>Frankie</first><last>Picron</last></author>
      <author><first>Davy</first><last>Van Landuyt</last></author>
      <author><first>Tina</first><last>Sioen</last></author>
      <author><first>Annelies</first><last>Braffort</last></author>
      <author><first>Michael</first><last>Filhol</last></author>
      <author><first>Sarah</first><last>Ebling</last></author>
      <author><first>Thomas</first><last>Hanke</last></author>
      <author><first>Verena</first><last>Krausneker</last></author>
      <pages>33-42</pages>
      <url hash="33f694fb">2021.mtsummit-at4ssl.4</url>
      <abstract>Development of <a href="https://en.wikipedia.org/wiki/Machine_translation">automatic translation</a> between signed and spoken languages has lagged behind the development of <a href="https://en.wikipedia.org/wiki/Machine_translation">automatic translation</a> between <a href="https://en.wikipedia.org/wiki/Spoken_language">spoken languages</a>, but it is a common misperception that extending machine translation techniques to include signed languages should be a straightforward process. A contributing factor is the lack of an acceptable method for displaying <a href="https://en.wikipedia.org/wiki/Sign_language">sign language</a> apart from <a href="https://en.wikipedia.org/wiki/Language_interpretation">interpreters</a> on video. This position paper examines the challenges of displaying a <a href="https://en.wikipedia.org/wiki/Sign_language">signed language</a> as a target in <a href="https://en.wikipedia.org/wiki/Automatic_translation">automatic translation</a>, analyses the underlying causes and suggests strategies to develop display technologies that are acceptable to sign language communities.</abstract>
      <bibkey>rosalee-wolfe-etal-2021-myth</bibkey>
    </paper>
    <paper id="5">
      <title>AVASAG : A German Sign Language Translation System for Public Services (short paper)<fixed-case>AVASAG</fixed-case>: A <fixed-case>G</fixed-case>erman <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage Translation System for Public Services (short paper)</title>
      <author><first>Fabrizio</first><last>Nunnari</last></author>
      <author><first>Judith</first><last>Bauerdiek</last></author>
      <author><first>Lucas</first><last>Bernhard</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <author><first>Corinna</first><last>Jäger</last></author>
      <author><first>Amelie</first><last>Unger</last></author>
      <author><first>Kristoffer</first><last>Waldow</last></author>
      <author><first>Sonja</first><last>Wecker</last></author>
      <author><first>Elisabeth</first><last>André</last></author>
      <author><first>Stephan</first><last>Busemann</last></author>
      <author><first>Christian</first><last>Dold</last></author>
      <author><first>Arnulph</first><last>Fuhrmann</last></author>
      <author><first>Patrick</first><last>Gebhard</last></author>
      <author><first>Yasser</first><last>Hamidullah</last></author>
      <author><first>Marcel</first><last>Hauck</last></author>
      <author><first>Yvonne</first><last>Kossel</last></author>
      <author><first>Martin</first><last>Misiak</last></author>
      <author><first>Dieter</first><last>Wallach</last></author>
      <author><first>Alexander</first><last>Stricker</last></author>
      <pages>43-48</pages>
      <url hash="aaf021a0">2021.mtsummit-at4ssl.5</url>
      <abstract>This paper presents an overview of AVASAG ; an ongoing applied-research project developing a text-to-sign-language translation system for public services. We describe the scientific innovation points (geometry-based SL-description, 3D animation and video corpus, simplified annotation scheme, motion capture strategy) and the overall translation pipeline.</abstract>
      <bibkey>nunnari-etal-2021-avasag</bibkey>
    </paper>
    <paper id="7">
      <title>Approaching Sign Language Gloss Translation as a Low-Resource Machine Translation Task</title>
      <author><first>Xuan</first><last>Zhang</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>60-70</pages>
      <url hash="9b4ced03">2021.mtsummit-at4ssl.7</url>
      <abstract>A cascaded Sign Language Translation system first maps sign videos to gloss annotations and then translates <a href="https://en.wikipedia.org/wiki/Gloss_(annotation)">glosses</a> into a <a href="https://en.wikipedia.org/wiki/Spoken_language">spoken languages</a>. This work focuses on the second-stage gloss translation component, which is challenging due to the scarcity of publicly available parallel data. We approach <a href="https://en.wikipedia.org/wiki/Gloss_(annotation)">gloss translation</a> as a low-resource machine translation task and investigate two popular methods for improving translation quality : hyperparameter search and backtranslation. We discuss the potentials and pitfalls of these methods based on experiments on the RWTH-PHOENIX-Weather 2014 T dataset.</abstract>
      <bibkey>zhang-duh-2021-approaching</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/phoenix14t">PHOENIX14T</pwcdataset>
    </paper>
    <paper id="8">
      <title>Automatic generation of a 3D sign language avatar on <a href="https://en.wikipedia.org/wiki/Augmented_reality">AR glasses</a> given 2D videos of human signers<fixed-case>D</fixed-case> sign language avatar on <fixed-case>AR</fixed-case> glasses given 2<fixed-case>D</fixed-case> videos of human signers</title>
      <author><first>Lan Thao</first><last>Nguyen</last></author>
      <author><first>Florian</first><last>Schicktanz</last></author>
      <author><first>Aeneas</first><last>Stankowski</last></author>
      <author><first>Eleftherios</first><last>Avramidis</last></author>
      <pages>71-81</pages>
      <url hash="4457bbf7">2021.mtsummit-at4ssl.8</url>
      <abstract>In this paper we present a prototypical implementation of a <a href="https://en.wikipedia.org/wiki/Pipeline_(computing)">pipeline</a> that allows the automatic generation of a German Sign Language avatar from <a href="https://en.wikipedia.org/wiki/2D_computer_graphics">2D video material</a>. The presentation is accompanied by the source code. We record <a href="https://en.wikipedia.org/wiki/List_of_human_positions">human pose movements</a> during signing with <a href="https://en.wikipedia.org/wiki/Computer_vision">computer vision models</a>. The joint coordinates of hands and arms are imported as <a href="https://en.wikipedia.org/wiki/Landmark">landmarks</a> to control the skeleton of our avatar. From the anatomically independent landmarks, we create another <a href="https://en.wikipedia.org/wiki/Skeleton">skeleton</a> based on the avatar’s skeletal bone architecture to calculate the bone rotation data. This <a href="https://en.wikipedia.org/wiki/Data">data</a> is then used to control our <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">human 3D avatar</a>. The <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">avatar</a> is displayed on <a href="https://en.wikipedia.org/wiki/Augmented_reality">AR glasses</a> and can be placed virtually in the room, in a way that it can be perceived simultaneously to the verbal speaker. In further work <a href="https://en.wikipedia.org/wiki/Information_technology">it</a> is aimed to be enhanced with <a href="https://en.wikipedia.org/wiki/Speech_recognition">speech recognition</a> and <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation methods</a> for serving as a <a href="https://en.wikipedia.org/wiki/Language_interpretation">sign language interpreter</a>. The <a href="https://en.wikipedia.org/wiki/Prototype">prototype</a> has been shown to people of the deaf and hard-of-hearing community for assessing its comprehensibility. Problems emerged with the transferred hand rotations, hand gestures were hard to recognize on the <a href="https://en.wikipedia.org/wiki/Avatar_(computing)">avatar</a> due to deformations like twisted finger meshes.</abstract>
      <bibkey>nguyen-etal-2021-automatic</bibkey>
    </paper>
    <paper id="11">
      <title>Defining meaningful units. Challenges in sign segmentation and segment-meaning mapping (short paper)</title>
      <author><first>Mirella</first><last>De Sisto</last></author>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>Irene</first><last>Murtagh</last></author>
      <author><first>Myriam</first><last>Vermeerbergen</last></author>
      <author><first>Lorraine</first><last>Leeson</last></author>
      <pages>98-103</pages>
      <url hash="9d07a557">2021.mtsummit-at4ssl.11</url>
      <abstract>This paper addresses the tasks of sign segmentation and segment-meaning mapping in the context of sign language (SL) recognition. It aims to give an overview of the linguistic properties of SL, such as <a href="https://en.wikipedia.org/wiki/Coarticulation">coarticulation</a> and <a href="https://en.wikipedia.org/wiki/Simultaneity">simultaneity</a>, which make these tasks complex. A better understanding of SL structure is the necessary ground for the design and development of SL recognition and segmentation methodologies, which are fundamental for <a href="https://en.wikipedia.org/wiki/Machine_translation">machine translation</a> of these languages. Based on this preliminary exploration, a proposal for mapping segments to meaning in the form of an agglomerate of lexical and non-lexical information is introduced.</abstract>
      <bibkey>de-sisto-etal-2021-defining</bibkey>
    </paper>
  </volume>
  <volume id="up" ingest-date="2021-09-15">
    <meta>
      <booktitle>Proceedings of Machine Translation Summit XVIII: Users and Providers Track</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>Janice</first><last>Campbell</last></editor>
      <editor><first>Ben</first><last>Huyck</last></editor>
      <editor><first>Stephen</first><last>Larocca</last></editor>
      <editor><first>Jay</first><last>Marciano</last></editor>
      <editor><first>Konstantin</first><last>Savenkov</last></editor>
      <editor><first>Alex</first><last>Yanishevsky</last></editor>
      <url hash="14bd8b24">2021.mtsummit-up</url>
    </meta>
    <frontmatter>
      <url hash="fe8dce6a">2021.mtsummit-up.0</url>
      <bibkey>mtsummit-2021-machine</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Roundtable: Digital Marketing Globalization at <fixed-case>N</fixed-case>et<fixed-case>A</fixed-case>pp: A Case Study of Digital Transformation utilizing Neural Machine Translation</title>
      <author><first>Edith</first><last>Bendermacher</last></author>
      <pages>1-6</pages>
      <attachment type="presentation" hash="22162b71">2021.mtsummit-up.1.Presentation.pdf</attachment>
      <bibkey>bendermacher-2021-roundtable</bibkey>
    </paper>
    <paper id="2">
      <title>Roundtable: Neural Machine Translation at Ford Motor Company</title>
      <author><first>Nestor</first><last>Rychtyckyj</last></author>
      <pages>7-16</pages>
      <attachment type="presentation" hash="0350667e">2021.mtsummit-up.2.Presentation.pdf</attachment>
      <bibkey>rychtyckyj-2021-roundtable</bibkey>
    </paper>
    <paper id="3">
      <title>Roundtable: Salesforce <fixed-case>NMT</fixed-case> System: A Year Later</title>
      <author><first>Raffaella</first><last>Buschiazzo</last></author>
      <pages>17-28</pages>
      <attachment type="presentation" hash="95fab9ef">2021.mtsummit-up.3.Presentation.pdf</attachment>
      <bibkey>buschiazzo-2021-roundtable</bibkey>
    </paper>
    <paper id="4">
      <title>Roundtable: <fixed-case>A</fixed-case>utodesk: Neural Machine Translation – Localization and beyond</title>
      <author><first>Emanuele</first><last>Dias</last></author>
      <pages>29-37</pages>
      <attachment type="presentation" hash="2788c46f">2021.mtsummit-up.4.Presentation.pdf</attachment>
      <bibkey>dias-2021-roundtable</bibkey>
    </paper>
    <paper id="7">
      <title>From Research to Production: Fine-Grained Analysis of Terminology Integration</title>
      <author><first>Toms</first><last>Bergmanis</last></author>
      <author><first>Mārcis</first><last>Pinnis</last></author>
      <author><first>Paula</first><last>Reichenberg</last></author>
      <pages>54-77</pages>
      <abstract>Dynamic terminology integration in neural machine translation (NMT) is a sought-after feature of computer-aided translation tools among language service providers and small to medium businesses. Despite the recent surge in research on terminology integration in NMT, it still is seldom or inadequately supported in commercial machine translation solutions. In this presentation, we will share our experience of developing and deploying terminology integration capabilities for NMT systems in production. We will look at the three core tasks of terminology integration: terminology management, terminology identification, and translation with terminology. This talk will be insightful for NMT system developers, translators, terminologists, and anyone interested in translation projects.</abstract>
      <attachment type="presentation" hash="f62f6138">2021.mtsummit-up.7.Presentation.pdf</attachment>
      <bibkey>bergmanis-etal-2021-research</bibkey>
    </paper>
    <paper id="10">
      <title>A Review for Large Volumes of Post-edited Data</title>
      <author><first>Silvio</first><last>Picinini</last></author>
      <pages>98-130</pages>
      <abstract>Interested in being more confident about the quality of your post-edited data? This is a session to learn how to create a Longitudinal Review that looks at specific aspects of quality in a systematic way, for the entire content and not just for a sample. Are you a project manager for a multilingual project? The Longitudinal Review can give insights to help project management, even if you are not a speaker of the target language. And it can help you detect issues that a Sample Review may not detect. Please come learn more about this new way to look at review.</abstract>
      <attachment type="presentation" hash="07bc42b3">2021.mtsummit-up.10.Presentation.pdf</attachment>
      <bibkey>picinini-2021-review</bibkey>
    </paper>
    <paper id="11">
      <title>Accelerated Human <fixed-case>NMT</fixed-case> Evaluation Approaches for <fixed-case>NMT</fixed-case> Workflow Integration</title>
      <author><first>James</first><last>Phillips</last></author>
      <pages>131-148</pages>
      <abstract>Attendees to this session will get a clear view into how neural machine translation is leveraged in a large-scale real-life scenario to make substantial cost savings in comparison to conventional approaches without compromising quality. This will include an overview of how quality is measured, when and why quality estimation is applied, what preparations are required to do so, and what attempts are made to minimize the amount of human effort involved. It will also be outlined as to what worked well and what pitfalls are to be avoided to give pointers to others who may be considering similar strategies.</abstract>
      <attachment type="presentation" hash="82f99f54">2021.mtsummit-up.11.Presentation.pdf</attachment>
      <bibkey>phillips-2021-accelerated</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>MT</fixed-case> Human Evaluation – Insights &amp; Approaches</title>
      <author><first>Paula</first><last>Manzur</last></author>
      <pages>149-165</pages>
      <abstract>This session is designed to help companies and people in the business of translation evaluate MT output and to show how human translator feedback can be tweaked to make the process more objective and accurate. You will hear recommendations, insights, and takeaways on how to improve the procedure for human evaluation. When this is achieved, we can understand if the human eval study and machine metric result coheres. And we can think about what the future of translators looks like – the final “human touch” and automated MT review.”</abstract>
      <attachment type="presentation" hash="c2ada632">2021.mtsummit-up.12.Presentation.pdf</attachment>
      <bibkey>manzur-2021-mt</bibkey>
    </paper>
    <paper id="13">
      <title>A Rising Tide Lifts All Boats? Quality Correlation between Human Translation and Machine Assisted Translation</title>
      <author><first>Evelyn</first><last>Yang Garland</last></author>
      <author><first>Rony</first><last>Gao</last></author>
      <pages>166-174</pages>
      <abstract>Does the human who produces the best translation without Machine Translation (MT) also produce the best translation with the assistance of MT? Our empirical study has found a strong correlation between the quality of pure human translation (HT) and that of machine-assisted translation (MAT) produced by the same translator (Pearson correlation coefficient 0.85, p=0.007). Data from the study also indicates a more concentrated distribution of the MAT quality scores than that of the HT scores. Additional insights will also be discussed during the presentation. This study has two prominent features: the participation of professional translators (mostly ATA members, English-into-Chinese) as subjects, and the rigorous quality evaluation by multiple professional translators (all ATA certified) using ATA’s time-tested certification exam grading metrics. Despite a major limitation in sample size, our findings provide a strong indication of correlation between HT and MAT quality, adding to the body of evidence in support of further studies on larger scales.</abstract>
      <attachment type="presentation" hash="e0463b77">2021.mtsummit-up.13.Presentation.pdf</attachment>
      <bibkey>yang-garland-gao-2021-rising</bibkey>
    </paper>
    <paper id="14">
      <title>Bad to the Bone: Predicting the Impact of Source on <fixed-case>MT</fixed-case></title>
      <author><first>Alex</first><last>Yanishevsky</last></author>
      <pages>175-199</pages>
      <abstract>It’s a well-known truism that poorly written source has a profound negative effect on the quality of machine translation, drastically reduces the productivity of post-editors and impacts turnaround times. But what is bad and how bad is bad? Conversely, what are the features emblematic of good content and how good is good? The impact of source on MT is crucial since a lot of content is written by non-native authors, created by technical specialists for a non-technical audience and may not adhere to brand tone and voice. AI can be employed to identify these errors and predict ‘at-risk’ content prior to localization in a multitude of languages. The presentation will show how source files and even individual sentences within those source files can be analyzed for markers of complexity and readability and thus are more likely to cause mistranslations and omissions for machine translation and subsequent post-editing. Potential solutions will be explored such as rewriting the source to be in line with acceptable threshold criteria for each product and/or domain, re-routing to other machine translation engines better suited for the task at hand and building AI-based predictive models.</abstract>
      <attachment type="presentation" hash="ea3c81dc">2021.mtsummit-up.14.Presentation.pdf</attachment>
      <bibkey>yanishevsky-2021-bad</bibkey>
    </paper>
    <paper id="16">
      <title>Using Raw <fixed-case>MT</fixed-case> to make essential information available for a diverse range of potential customers</title>
      <author><first>Sabine</first><last>Peng</last></author>
      <pages>211-226</pages>
      <abstract>This presentation will share how we use raw machine translation to reach more potential customers. The attendees will learn about the raw machine strategies and workflow, how to select languages and products through data analysis, how to evaluate the overall quality of documentation with raw machine translation. The attendees will also learn about the direction we are going, that is, collecting user feedback and optimizing raw machine translation, so to build a complete and sustainable closed loop.</abstract>
      <attachment type="presentation" hash="da4a2b82">2021.mtsummit-up.16.Presentation.pdf</attachment>
      <bibkey>peng-2021-using</bibkey>
    </paper>
    <paper id="18">
      <title>A Common Machine Translation Post-Editing Training Protocol by <fixed-case>GALA</fixed-case></title>
      <author><first>Viveta</first><last>Gene</last></author>
      <author><first>Lucía</first><last>Guerrero</last></author>
      <pages>233-245</pages>
      <attachment type="presentation" hash="af11c99d">2021.mtsummit-up.18.Presentation.pdf</attachment>
      <bibkey>gene-guerrero-2021-common</bibkey>
    </paper>
    <paper id="19">
      <title>Preserving high <fixed-case>MT</fixed-case> quality for content with inline tags</title>
      <author><first>Konstantin</first><last>Savenkov</last></author>
      <author><first>Grigory</first><last>Sapunov</last></author>
      <author><first>Pavel</first><last>Stepachev</last></author>
      <pages>246-276</pages>
      <abstract>Attendees will learn about how we use machine translation to provide targeted, high MT quality for content with inline tags. We offer a new and innovative approach to inserting tags into the translated text in a way that reliably preserves their quality. This process can achieve better MT quality and lower costs, as it is MT-independent, and can be used for all languages, MT engines, and use cases.</abstract>
      <attachment type="presentation" hash="6b879691">2021.mtsummit-up.19.Presentation.pdf</attachment>
      <bibkey>savenkov-2021-preserving</bibkey>
    </paper>
    <paper id="20">
      <title>Early-stage development of the <fixed-case>S</fixed-case>ign<fixed-case>ON</fixed-case> application and open framework – challenges and opportunities</title>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>John</first><last>J O’Flaherty</last></author>
      <author><first>Edward</first><last>Keane</last></author>
      <author><first>Connor</first><last>O’Reilly</last></author>
      <author><first>Marcello</first><last>Paolo Scipioni</last></author>
      <author><first>Marco</first><last>Giovanelli</last></author>
      <author><first>Matteo</first><last>Villa</last></author>
      <pages>277-290</pages>
      <abstract>SignON is an EU Horizon 2020 Research and Innovation project, that is developing a smartphone application and an open framework to facilitate translation between different European sign, spoken and text languages. The framework will incorporate state of the art sign language recognition and presentation, speech processing technologies and, in its core, multi-modal, cross-language machine translation. The framework, dedicated to the computationally heavy tasks and distributed on the cloud powers the application – a lightweight app running on a standard mobile device. The application and framework are being researched, designed and developed through a co-creation user-centric approach with the European deaf and hard of hearing communities. In this session, the speakers will detail their progress, challenges and lessons learned in the early-stage development of the application and framework. They will also present their Agile DevOps approach and the next steps in the evolution of the SignON project.</abstract>
      <attachment type="presentation" hash="0a80bb8f">2021.mtsummit-up.20.Presentation.pdf</attachment>
      <bibkey>shterionov-2021-early</bibkey>
    </paper>
    <paper id="21">
      <title>Deploying <fixed-case>MT</fixed-case> Quality Estimation on a large scale: Lessons learned and open questions</title>
      <author><first>Aleš</first><last>Tamchyna</last></author>
      <pages>291-305</pages>
      <abstract>This talk will focus on Memsource’s experience implementing MT Quality Estimation on a large scale within a translation management system. We will cover the whole development journey: from our early experimentation and the challenges we faced adapting academic models for a real world setting, all the way through to the practical implementation. Since the launch of this feature, we’ve accumulated a significant amount of experience and feedback, which has informed our subsequent development. Lastly we will discuss several open questions regarding the future role of quality estimation in translation.</abstract>
      <attachment type="presentation" hash="3c1bef2f">2021.mtsummit-up.21.Presentation.pdf</attachment>
      <bibkey>tamchyna-2021-deploying</bibkey>
    </paper>
    <paper id="23">
      <title>Neural Translation for <fixed-case>E</fixed-case>uropean <fixed-case>U</fixed-case>nion (<fixed-case>NTEU</fixed-case>)</title>
      <author><first>Mercedes</first><last>García-Martínez</last></author>
      <author><first>Laurent</first><last>Bié</last></author>
      <author><first>Aleix</first><last>Cerdà</last></author>
      <author><first>Amando</first><last>Estela</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <author><first>Rihards</first><last>Krišlauks</last></author>
      <author><first>Maite</first><last>Melero</last></author>
      <author><first>Tony</first><last>O’Dowd</last></author>
      <author><first>Sinead</first><last>O’Gorman</last></author>
      <author><first>Marcis</first><last>Pinnis</last></author>
      <author><first>Artūrs</first><last>Stafanovič</last></author>
      <author><first>Riccardo</first><last>Superbo</last></author>
      <author><first>Artūrs</first><last>Vasiļevskis</last></author>
      <pages>316-334</pages>
      <abstract>The Neural Translation for the European Union (NTEU) engine farm enables direct machine translation for all 24 official languages of the European Union without the necessity to use a high-resourced language as a pivot. This amounts to a total of 552 translation engines for all combinations of the 24 languages. We have collected parallel data for all the language combinations publickly shared in elrc-share.eu. The translation engines have been customized to domain,for the use of the European public administrations. The delivered engines will be published in the European Language Grid. In addition to the usual automatic metrics, all the engines have been evaluated by humans based on the direct assessment methodology. For this purpose, we built an open-source platform called MTET The evaluation shows that most of the engines reach high quality and get better scores compared to an external machine translation service in a blind evaluation setup.</abstract>
      <attachment type="presentation" hash="86c35b74">2021.mtsummit-up.23.Presentation.pdf</attachment>
      <bibkey>garcia-martinez-etal-2021-neural</bibkey>
    </paper>
    <paper id="24">
      <title>A Data-Centric Approach to Real-World Custom <fixed-case>NMT</fixed-case> for <fixed-case>A</fixed-case>rabic</title>
      <author><first>Rebecca</first><last>Jonsson</last></author>
      <author><first>Ruba</first><last>Jaikat</last></author>
      <author><first>Abdallah</first><last>Nasir</last></author>
      <author><first>Nour</first><last>Al-Khdour</last></author>
      <author><first>Sara</first><last>Alisis</last></author>
      <pages>335-352</pages>
      <abstract>In this presentation, we will present our approach to taking Custom NMT to the next level by building tailor-made NMT to fit the needs of businesses seeking to scale in the Arabic-speaking world. In close collaboration with customers in the MENA region and with a deep understanding of their data, we work on building a variety of NMT models that accommodate to the unique challenges of the Arabic language. This session will provide insights into the challenges of acquiring, analyzing, and processing customer data in various sectors, as well as insights into how to best make use of this data to build high-quality Custom NMT models in English-Arabic. Feedback from usage of these models in production will be provided. Furthermore, we will show how to use our translation management system to make the most of the custom NMT, by leveraging the models, fine-tuning and continuing to improve them over time.</abstract>
      <attachment type="presentation" hash="b3ff86db">2021.mtsummit-up.24.Presentation.pdf</attachment>
      <bibkey>jonsson-jaikat-2021-data</bibkey>
    </paper>
    <paper id="25">
      <title>Building <fixed-case>MT</fixed-case> systems in low resourced languages for Public Sector users in <fixed-case>C</fixed-case>roatia, <fixed-case>I</fixed-case>celand, <fixed-case>I</fixed-case>reland, and <fixed-case>N</fixed-case>orway</title>
      <author><first>Róisín</first><last>Moran</last></author>
      <author><first>Carla</first><last>Para Escartín</last></author>
      <author><first>Akshai</first><last>Ramesh</last></author>
      <author><first>Páraic</first><last>Sheridan</last></author>
      <author><first>Jane</first><last>Dunne</last></author>
      <author><first>Federico</first><last>Gaspari</last></author>
      <author><first>Sheila</first><last>Castilho</last></author>
      <author><first>Natalia</first><last>Resende</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>353-381</pages>
      <abstract>When developing Machine Translation engines, low resourced language pairs tend to be in a disadvantaged position: less available data means that developing robust MT models can be more challenging.The EU-funded PRINCIPLE project aims at overcoming this challenge for four low resourced European languages: Norwegian, Croatian, Irish and Icelandic. This presentation will give an overview of the project, with a focus on the set of Public Sector users and their use cases for which we have developed MT solutions.We will discuss the range of language resources that have been gathered through contributions from public sector collaborators, and present the extensive evaluations that have been undertaken, including significant user evaluation of MT systems across all of the public sector participants in each of the four countries involved.</abstract>
      <attachment type="presentation" hash="961ec080">2021.mtsummit-up.25.Presentation.pdf</attachment>
      <bibkey>moran-etal-2021-building</bibkey>
    </paper>
    <paper id="26">
      <title>Using speech technology in the translation process workflow in international organizations: A quantitative and qualitative study</title>
      <author><first>Pierrette</first><last>Bouillon</last></author>
      <author><first>Jeevanthi</first><last>Liyanapathirana</last></author>
      <pages>382-395</pages>
      <abstract>In international organizations, the growing demand for translations has increased the need for post-editing. Different studies show that automatic speech recognition systems have the potential to increase the productivity of the translation process as well as the quality. In this talk, we will explore the possibilities of using speech in the translation process by conducting a post-editing experiment with three professional translators in an international organization. Our experiment consisted of comparing three translation methods: speaking the translation with MT as an inspiration (RESpeaking), post-editing the MT suggestions by typing (PE), and editing the MT suggestion using speech (SPE). BLEU and HTER scores were used to compare the three methods. Our study shows that translators did more edits under condition RES, whereas in SPE, the resulting translations were closer to the reference according to the BLEU score and required less edits. Time taken to translate was the least in SPE followed by PE, RES methods and the translators preferred using speech to typing.These results show the potential of speech when it is coupled with post-editing.To the best of our knowledge, this is the first quantitative study conducted on using post-editing and speech together in large scale international organizations.</abstract>
      <attachment type="presentation" hash="28b0a7a2">2021.mtsummit-up.26.Presentation.pdf</attachment>
      <bibkey>bouillon-liyanapathirana-2021-using</bibkey>
    </paper>
    <paper id="28">
      <title>cush<fixed-case>LEPOR</fixed-case> uses <fixed-case>LABSE</fixed-case> distilled knowledge to improve correlation with human translation evaluations</title>
      <author><first>Gleb</first><last>Erofeev</last></author>
      <author><first>Irina</first><last>Sorokina</last></author>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Serge</first><last>Gladkoff</last></author>
      <pages>421-439</pages>
      <abstract>Automatic MT evaluation metrics are indispensable for MT research. Augmented metrics such as hLEPOR include broader evaluation factors (recall and position difference penalty) in addition to the factors used in BLEU (sentence length, precision), and demonstrated higher accuracy. However, the obstacles preventing the wide use of hLEPOR were the lack of easy portable Python package and empirical weighting parameters that were tuned by manual work. This project addresses the above issues by offering a Python implementation of hLEPOR and automatic tuning of the parameters. We use existing translation memories (TM) as reference set and distillation modeling with LaBSE (Language-Agnostic BERT Sentence Embedding) to calibrate parameters for custom hLEPOR (cushLEPOR). cushLEPOR maximizes the correlation between hLEPOR and the distilling model similarity score towards reference. It can be used quickly and precisely to evaluate MT output from different engines, without need of manual weight tuning for optimization. In this session you will learn how to tune hLEPOR to obtain automatic custom-tuned cushLEPOR metric far more precise than BLEU. The method does not require costly human evaluations, existing TM is taken as a reference translation set, and cushLEPOR is created to select the best MT engine for the reference data-set.</abstract>
      <attachment type="presentation" hash="681d41a2">2021.mtsummit-up.28.Presentation.pdf</attachment>
      <bibkey>erofeev-etal-2021-cushlepor</bibkey>
    </paper>
    <paper id="29">
      <title>A Synthesis of Human and Machine: Correlating “New” Automatic Evaluation Metrics with Human Assessments</title>
      <author><first>Mara</first><last>Nunziatini</last></author>
      <author><first>Andrea</first><last>Alfieri</last></author>
      <pages>440-465</pages>
      <abstract>The session will provide an overview of some of the new Machine Translation metrics available on the market, analyze if and how these new metrics correlate at a segment level to the results of Adequacy and Fluency Human Assessments, and how they compare against TER scores and Levenshtein Distance – two of our currently preferred metrics – as well as against each of the other. The information in this session will help to get a better understanding of their strengths and weaknesses and make informed decisions when it comes to forecasting MT production.</abstract>
      <attachment type="presentation" hash="b571b885">2021.mtsummit-up.29.Presentation.pdf</attachment>
      <bibkey>nunziatini-alfieri-2021-synthesis</bibkey>
    </paper>
    <paper id="30">
      <title>Lab vs. Production: Two Approaches to Productivity Evaluation for <fixed-case>MTPE</fixed-case> for <fixed-case>LSP</fixed-case></title>
      <author><first>Elena</first><last>Murgolo</last></author>
      <pages>466-490</pages>
      <abstract>In the paper we propose both kind of tests as viable post-editing productivity evaluation solutions as they both deliver a clear overview of the difference in speed between HT and PE of the translators involved. The decision on whether to use the first approach or the second can be based on a number of factors, such as: availability of actual orders in the domain and language combination to be tested; time; availability of Post-editors in the domain and in the language combination to be tested. The aim of this paper will be to show that both methodologies can be useful in different settings for a preliminary evaluation of possible productivity gain with MTPE.</abstract>
      <attachment type="presentation" hash="fac5e41d">2021.mtsummit-up.30.Presentation.pdf</attachment>
      <bibkey>murgolo-2021-lab</bibkey>
    </paper>
  </volume>
  <volume id="loresmt" ingest-date="2021-09-26">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Technologies for MT of Low Resource Languages (LoResMT2021)</booktitle>
      <publisher>Association for Machine Translation in the Americas</publisher>
      <address>Virtual</address>
      <month>August</month>
      <year>2021</year>
      <editor><first>John</first><last>Ortega</last></editor>
      <editor><first>Atul Kr.</first><last>Ojha</last></editor>
      <editor><first>Katharina</first><last>Kann</last></editor>
      <editor><first>Chao-Hong</first><last>Liu</last></editor>
      <url hash="2510de92">2021.mtsummit-loresmt</url>
    </meta>
    <frontmatter>
      <url hash="abf10b8d">2021.mtsummit-loresmt.0</url>
      <bibkey>mtsummit-2021-technologies</bibkey>
    </frontmatter>
    </volume>
</collection>