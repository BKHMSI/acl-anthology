<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.iwpt">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</booktitle>
      <editor><first>Gosse</first><last>Bouma</last></editor>
      <editor><first>Yuji</first><last>Matsumoto</last></editor>
      <editor><first>Stephan</first><last>Oepen</last></editor>
      <editor><first>Kenji</first><last>Sagae</last></editor>
      <editor><first>Djamé</first><last>Seddah</last></editor>
      <editor><first>Weiwei</first><last>Sun</last></editor>
      <editor><first>Anders</first><last>Søgaard</last></editor>
      <editor><first>Reut</first><last>Tsarfaty</last></editor>
      <editor><first>Dan</first><last>Zeman</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="fe3f84b1">2020.iwpt-1</url>
    </meta>
    <frontmatter>
      <url hash="93260931">2020.iwpt-1.0</url>
      <bibkey>iwpt-2020-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Syntactic Parsing in Humans and Machines</title>
      <author><first>Paola</first><last>Merlo</last></author>
      <pages>1</pages>
      <abstract>To process the syntactic structures of a language in ways that are compatible with human expectations, we need computational representations of lexical and syntactic properties that form the basis of human knowledge of words and sentences. Recent neural-network-based and distributed semantics techniques have developed systems of considerable practical success and impressive performance. As has been advocated by many, however, such <a href="https://en.wikipedia.org/wiki/System">systems</a> still lack human-like properties. In particular, linguistic, psycholinguistic and neuroscientific investigations have shown that human processing of sentences is sensitive to structure and unbounded relations. In the spirit of better understanding the structure building and long-distance properties of <a href="https://en.wikipedia.org/wiki/Neural_network">neural networks</a>, I will present an overview of recent results on agreement and island effects in <a href="https://en.wikipedia.org/wiki/Syntax">syntax</a> in several languages. While certain sets of results in the literature indicate that neural language models exhibit long-distance agreement abilities, other finer-grained investigation of how these effects are calculated indicates that that the similarity spaces they define do not correlate with human experimental results on intervention similarity in long-distance dependencies. This opens the way to reflections on how to better match the <a href="https://en.wikipedia.org/wiki/Syntax">syntactic properties</a> of <a href="https://en.wikipedia.org/wiki/Natural_language">natural languages</a> in the representations of neural models.</abstract>
      <url hash="c81e0f9b">2020.iwpt-1.1</url>
      <doi>10.18653/v1/2020.iwpt-1.1</doi>
      <video href="http://slideslive.com/38929668" />
      <bibkey>merlo-2020-syntactic</bibkey>
    </paper>
    <paper id="5">
      <title>Semi-supervised Parsing with a Variational Autoencoding Parser</title>
      <author><first>Xiao</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>40–47</pages>
      <abstract>We propose an end-to-end variational autoencoding parsing (VAP) model for semi-supervised graph-based projective dependency parsing. It encodes the input using <a href="https://en.wikipedia.org/wiki/Latent_variable_model">continuous latent variables</a> in a sequential manner by <a href="https://en.wikipedia.org/wiki/Deep_learning">deep neural networks (DNN)</a> that can utilize the contextual information, and reconstruct the input using a <a href="https://en.wikipedia.org/wiki/Generative_model">generative model</a>. The VAP model admits a unified structure with different <a href="https://en.wikipedia.org/wiki/Loss_function">loss functions</a> for labeled and unlabeled data with shared parameters. We conducted experiments on the WSJ data sets, showing the proposed model can use the unlabeled data to increase the performance on a limited amount of labeled data, on a par with a recently proposed semi-supervised parser with faster inference.</abstract>
      <url hash="e7d65401">2020.iwpt-1.5</url>
      <doi>10.18653/v1/2020.iwpt-1.5</doi>
      <video href="http://slideslive.com/38929672" />
      <bibkey>zhang-goldwasser-2020-semi</bibkey>
    </paper>
    <paper id="7">
      <title>Obfuscation for Privacy-preserving Syntactic Parsing</title>
      <author><first>Zhifeng</first><last>Hu</last></author>
      <author><first>Serhii</first><last>Havrylov</last></author>
      <author><first>Ivan</first><last>Titov</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <pages>62–72</pages>
      <abstract>The goal of <a href="https://en.wikipedia.org/wiki/Homomorphic_encryption">homomorphic encryption</a> is to encrypt data such that another party can operate on it without being explicitly exposed to the content of the original data. We introduce an idea for a privacy-preserving transformation on <a href="https://en.wikipedia.org/wiki/Natural-language_understanding">natural language data</a>, inspired by <a href="https://en.wikipedia.org/wiki/Homomorphic_encryption">homomorphic encryption</a>. Our primary tool is <a href="https://en.wikipedia.org/wiki/Obfuscation">obfuscation</a>, relying on the properties of <a href="https://en.wikipedia.org/wiki/Natural_language">natural language</a>. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing <a href="https://en.wikipedia.org/wiki/Parsing">parser</a>. All of this is done without much sacrifice of <a href="https://en.wikipedia.org/wiki/Privacy">privacy</a> compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar <a href="https://en.wikipedia.org/wiki/Syntax">syntactic properties</a>, but different <a href="https://en.wikipedia.org/wiki/Semantics">semantic content</a>, compared to the original words.<i>obfuscation</i>, relying on the properties of natural language. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The model works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing parser. All of this is done without much sacrifice of privacy compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar syntactic properties, but different semantic content, compared to the original words.</abstract>
      <url hash="3d25adb8">2020.iwpt-1.7</url>
      <doi>10.18653/v1/2020.iwpt-1.7</doi>
      <video href="http://slideslive.com/38929674" />
      <bibkey>hu-etal-2020-obfuscation</bibkey>
      <pwccode url="https://github.com/ichn-hu/Parsing-Obfuscation" additional="false">ichn-hu/Parsing-Obfuscation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</pwcdataset>
    </paper>
    <paper id="8">
      <title>Tensors over Semirings for Latent-Variable Weighted Logic Programs</title>
      <author><first>Esma</first><last>Balkir</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <pages>73–90</pages>
      <abstract>Semiring parsing is an elegant <a href="https://en.wikipedia.org/wiki/Software_framework">framework</a> for describing <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a> by using semiring weighted logic programs. In this paper we present a generalization of this <a href="https://en.wikipedia.org/wiki/Concept">concept</a> : latent-variable semiring parsing. With our framework, any <a href="https://en.wikipedia.org/wiki/Semiring">semiring weighted logic program</a> can be latentified by transforming weights from scalar values of a <a href="https://en.wikipedia.org/wiki/Semiring">semiring</a> to rank-n arrays, or tensors, of <a href="https://en.wikipedia.org/wiki/Semiring">semiring values</a>, allowing the modelling of latent-variable models within the <a href="https://en.wikipedia.org/wiki/Semiring">semiring parsing framework</a>. Semiring is too strong a notion when dealing with <a href="https://en.wikipedia.org/wiki/Tensor">tensors</a>, and we have to resort to a weaker structure : a partial semiring. We prove that this <a href="https://en.wikipedia.org/wiki/Generalization">generalization</a> preserves all the desired properties of the original semiring framework while strictly increasing its expressiveness.</abstract>
      <url hash="36981a2b">2020.iwpt-1.8</url>
      <doi>10.18653/v1/2020.iwpt-1.8</doi>
      <attachment type="Dataset" hash="322b1060">2020.iwpt-1.8.Dataset.pdf</attachment>
      <video href="http://slideslive.com/38929675" />
      <bibkey>balkir-etal-2020-tensors</bibkey>
    </paper>
    <paper id="11">
      <title>Self-Training for Unsupervised Parsing with PRPN<fixed-case>PRPN</fixed-case></title>
      <author><first>Anhad</first><last>Mohananey</last></author>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>105–110</pages>
      <abstract>Neural unsupervised parsing (UP) models learn to parse without access to syntactic annotations, while being optimized for another task like <a href="https://en.wikipedia.org/wiki/Language_model">language modeling</a>. In this work, we propose self-training for neural UP models : we leverage aggregated annotations predicted by copies of our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> as supervision for future copies. To be able to use our model’s predictions during training, we extend a recent neural UP architecture, the PRPN (Shen et al., 2018a), such that it can be trained in a semi-supervised fashion. We then add examples with <a href="https://en.wikipedia.org/wiki/Parsing">parses</a> predicted by our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> to our unlabeled UP training data. Our self-trained model outperforms the PRPN by 8.1 % <a href="https://en.wikipedia.org/wiki/F-number">F1</a> and the previous state of the art by 1.6 % <a href="https://en.wikipedia.org/wiki/F-number">F1</a>. In addition, we show that our <a href="https://en.wikipedia.org/wiki/Software_architecture">architecture</a> can also be helpful for semi-supervised parsing in ultra-low-resource settings.</abstract>
      <url hash="e557f12f">2020.iwpt-1.11</url>
      <doi>10.18653/v1/2020.iwpt-1.11</doi>
      <video href="http://slideslive.com/38929678" />
      <bibkey>mohananey-etal-2020-self</bibkey>
    </paper>
    <paper id="19">
      <title>Adaptation of Multilingual Transformer Encoder for Robust Enhanced Universal Dependency Parsing<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Parsing</title>
      <author><first>Han</first><last>He</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>181–191</pages>
      <abstract>This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> using the multilingual encoder outperform ones using the language specific encoders for most languages. The ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> rank the third place on the macro-average ELAS over 17 languages.</abstract>
      <url hash="4beeb14f">2020.iwpt-1.19</url>
      <doi>10.18653/v1/2020.iwpt-1.19</doi>
      <video href="http://slideslive.com/38929686" />
      <bibkey>he-choi-2020-adaptation</bibkey>
    </paper>
    <paper id="21">
      <title>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies<fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies</title>
      <author><first>Giuseppe</first><last>Attardi</last></author>
      <author><first>Daniele</first><last>Sartiano</last></author>
      <author><first>Maria</first><last>Simi</last></author>
      <pages>206–214</pages>
      <abstract>To accomplish the shared task on <a href="https://en.wikipedia.org/wiki/Dependency_grammar">dependency parsing</a> we explore the use of a linear transition-based neural dependency parser as well as a combination of three of them by means of a linear tree combination algorithm. We train separate <a href="https://en.wikipedia.org/wiki/Mathematical_model">models</a> for each language on the shared task data. We compare our base <a href="https://en.wikipedia.org/wiki/Parsing">parser</a> with two biaffine parsers and also present an ensemble combination of all five <a href="https://en.wikipedia.org/wiki/Parsing">parsers</a>, which achieves an average UAS 1.88 point lower than the top official submission. For producing the enhanced dependencies, we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.</abstract>
      <url hash="cab821b1">2020.iwpt-1.21</url>
      <doi>10.18653/v1/2020.iwpt-1.21</doi>
      <video href="http://slideslive.com/38929688" />
      <bibkey>attardi-etal-2020-linear</bibkey>
    <title_ar>التحليل العصبي الخطي والتعزيز المختلط من أجل التبعيات العالمية المحسنة</title_ar>
      <title_fr>Analyse neuronale linéaire et amélioration hybride pour des dépendances universelles améliorées</title_fr>
      <title_pt>Análise Neural Linear e Aprimoramento Híbrido para Dependências Universais Aprimoradas</title_pt>
      <title_es>Análisis neuronal lineal y mejora híbrida para mejorar las dependencias universales</title_es>
      <title_ja>ユニバーサル依存性の強化のための線形ニューラル解析とハイブリッド強化</title_ja>
      <title_hi>रैखिक तंत्रिका पार्सिंग और हाइब्रिड एन्हांसमेंट एन्हांस्ड यूनिवर्सल निर्भरताओं के लिए</title_hi>
      <title_zh>线性神经解析和合增强功能,增强通用依赖性</title_zh>
      <title_ru>Линейный нейронный парсинг и гибридное усиление для расширенных универсальных зависимостей</title_ru>
      <title_ga>Parsáil Néarach Líneach agus Feabhsú Hibrideach le haghaidh Spleáchais Uilíocha Feabhsaithe</title_ga>
      <title_ka>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies</title_ka>
      <title_el>Γραμμική Νευρική Ανάλυση και υβριδική ενίσχυση για ενισχυμένες καθολικές εξαρτήσεις</title_el>
      <title_hu>Lineáris neurális értelmezés és hibrid fejlesztés a fokozott univerzális függőségek érdekében</title_hu>
      <title_it>Analisi neurale lineare e miglioramento ibrido per dipendenze universali migliorate</title_it>
      <title_kk>Жиналық невралды талдау және гибридтің көтерілген Universal Dependencies үшін</title_kk>
      <title_lt>Linearinis neurologinis analizavimas ir sustiprintų universaliųjų priklausomybių hibridinis gerinimas</title_lt>
      <title_mk>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies</title_mk>
      <title_ms>Penghuraian Neural Linear dan Perbaikan Hybrid untuk Dependensi Universal Tertinggi</title_ms>
      <title_ml>മെച്ചപ്പെടുത്തിയ യൂണിവര്‍ണല്‍ ആശ്രയിക്കുന്നതിനുള്ള ലൈനിയര്‍ നെയുറല്‍ പാര്‍സിങ്ങും ഹൈബ്രിഡ് മെന്‍സ</title_ml>
      <title_mt>Analiżi Newrali Lineari u Titjib Ibridu għal Dipendenzi Universali mtejba</title_mt>
      <title_mn>Шинэ мэдрэлийн шинжилгээ болон гибрид нэмэгдүүлэлт дэвшүүлэхэд</title_mn>
      <title_no>Lineær neuralanalysing og hybridforbetring for forbetra universelle avhengighet</title_no>
      <title_pl>Linear Neuroral Parsing i hybrydowe ulepszenie dla zwiększonych uniwersalnych zależności</title_pl>
      <title_ro>Analiza neurală liniară și îmbunătățirea hibridă pentru dependențe universale îmbunătățite</title_ro>
      <title_sr>Linijalno neurološko razmatranje i hibridno povećanje povećanih univerzalnih zavisnosti</title_sr>
      <title_si>Name</title_si>
      <title_so>Heshiiska naafada ee Linear and Hybrid Horumarinta Shuruudaha Jaamacadda</title_so>
      <title_ta>மேம்படுத்தப்பட்ட உலகளாவிய சார்புகளுக்கான கோடு நெயுரல் பாசிங் மற்றும் ஹைப்ரிட் மேம்படுத்தல்</title_ta>
      <title_sv>Linjär neural tolkning och hybridförbättring för förbättrade universella beroenden</title_sv>
      <title_ur>لینیر نیورال پارسینگ اور ہیبراڈ زیادہ زیادہ وابستگی کے لئے</title_ur>
      <title_uz>Name</title_uz>
      <title_vi>Chế độ phân tích thần kinh tuyến và khả năng leo trèo cho các mối quan hệ chung</title_vi>
      <title_bg>Линейно неврално анализиране и хибридно подобрение за подобрени универсални зависимости</title_bg>
      <title_nl>Lineaire neurale parsing en hybride verbetering voor verbeterde universele afhankelijkheden</title_nl>
      <title_da>Lineær neural fortolkning og hybrid forbedring for forbedret universel afhængighed</title_da>
      <title_hr>Linijsko neuroanalizanje i proširenje hibrida za poboljšane univerzalne zavisnosti</title_hr>
      <title_de>Lineare Neural Parsing und Hybrid Enhancement für verbesserte universelle Abhängigkeiten</title_de>
      <title_ko>범의존적 선형 신경 분석 및 혼합 강화 강화 강화</title_ko>
      <title_sw>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies</title_sw>
      <title_tr>Name</title_tr>
      <title_fa>تحلیل عصبی خط و افزایش Hybrid برای بستگی جهانی بیشتر</title_fa>
      <title_am>Linear Neural Parsing and Hybrid Advanced Universal Dependences</title_am>
      <title_af>Lineêre neurale verwerking en Hybride Verbetering vir Verbeter Universele Afhanklikhede</title_af>
      <title_hy>Գծային նյարդային վերլուծությունը և հիբրիդային բարելավումը բարելավված համաշխարհային կախվածությունների համար</title_hy>
      <title_az>Üniversal bağlılıqları üçün Linear Neural Parsing və Hybrid Enhancement</title_az>
      <title_id>Penjelasan Neural Linear dan Perbaikan Hybrid untuk Kekuatan Dependensi Universal</title_id>
      <title_bs>Linijska neuroanaliza i hibridno povećanje povećanih univerzalnih zavisnosti</title_bs>
      <title_bn>উন্নত বিশ্ববিদ্যালয়ের নির্ভরের জন্য লাইনের নিউরেল পার্সিং এবং হাইব্রিড উন্নয়ন</title_bn>
      <title_cs>Lineární neuronové analýzy a hybridní vylepšení pro lepší univerzální závislosti</title_cs>
      <title_et>Lineaarne neuraalne parsimine ja hübriidne täiustamine suuremate universaalsete sõltuvuste jaoks</title_et>
      <title_sq>Analizimi linear neuronal dhe përmirësimi hibridik për varësitë e përmirësuara universale</title_sq>
      <title_fi>Lineaarinen hermoparsaus ja hybridi parannus parantaa yleismaailmallisia riippuvuuksia</title_fi>
      <title_ca>Analització neuronal linear i millor híbrid per a dependències universals millorades</title_ca>
      <title_jv>structural navigation</title_jv>
      <title_he>מחקר נוירולי לינרי ושיפור היברידי עבור תלויות יוניברסליות משותפות</title_he>
      <title_ha>KCharselect unicode block name</title_ha>
      <title_bo>རྒྱ་བསྐྱེད་པའི་སྤྱི་ཚོགས་ཀྱི་ཕྱོགས་མཐོང་དང་མཐོ་བོའི་རྒྱ་བསྐྱེད་ཚད་ལ་ཡར་རྒྱས་གཏོང་བ</title_bo>
      <title_sk>Linearno razporejanje živcev in hibridna izboljšava za večjo univerzalno odvisnost</title_sk>
      <abstract_pt>Para realizar a tarefa compartilhada de análise de dependência, exploramos o uso de um analisador de dependência neural baseado em transição linear, bem como uma combinação de três deles por meio de um algoritmo de combinação de árvore linear. Treinamos modelos separados para cada idioma nos dados de tarefas compartilhadas. Comparamos nosso parser base com dois parsers biaffine e também apresentamos uma combinação de conjunto de todos os cinco parsers, que atinge um UAS médio 1,88 ponto menor do que o envio oficial superior. Para produzir as dependências aprimoradas, exploramos uma abordagem híbrida, acoplando uma transformação gráfica algorítmica da árvore de dependência com previsões feitas por um modelo de aprendizado de máquina multitarefa.</abstract_pt>
      <abstract_fr>Pour accomplir la tâche partagée sur l'analyse des dépendances, nous explorons l'utilisation d'un analyseur de dépendance neuronale basé sur la transition linéaire ainsi qu'une combinaison de trois d'entre eux au moyen d'un algorithme de combinaison d'arbres linéaires. Nous entraînons des modèles distincts pour chaque langue à partir des données de tâches partagées. Nous comparons notre analyseur de base avec deux analyseurs biaffine et présentons également une combinaison d'ensemble des cinq analyseurs, qui atteint un UAS moyen de 1,88 point inférieur à la soumission officielle la plus élevée. Pour produire les dépendances améliorées, nous exploitons une approche hybride, couplant une transformation graphique algorithmique de l'arbre de dépendance avec des prédictions réalisées par un modèle d'apprentissage automatique multitâche.</abstract_fr>
      <abstract_es>Para llevar a cabo la tarea compartida de análisis de dependencias, exploramos el uso de un analizador de dependencias neuronales basado en transición lineal, así como una combinación de tres de ellos por medio de un algoritmo de combinación de árbol lineal. Entrenamos modelos separados para cada idioma sobre los datos de tareas compartidas. Comparamos nuestro analizador base con dos analizadores biaffine y también presentamos una combinación combinada de los cinco analizadores, que logra un UAS promedio de 1,88 puntos por debajo del envío oficial superior. Para producir las dependencias mejoradas, utilizamos un enfoque híbrido, que combina una transformación gráfica algorítmica del árbol de dependencias con predicciones realizadas por un modelo de aprendizaje automático multitarea.</abstract_es>
      <abstract_ar>لإنجاز المهمة المشتركة المتعلقة بتحليل التبعية ، نستكشف استخدام محلل التبعية العصبية القائم على الانتقال الخطي بالإضافة إلى مزيج من ثلاثة منهم عن طريق خوارزمية تركيبة شجرة خطية. نقوم بتدريب نماذج منفصلة لكل لغة على بيانات المهمة المشتركة. نحن نقارن المحلل اللغوي الأساسي الخاص بنا بمحللين biaffine ونقدم أيضًا مجموعة من المحلل اللغوي الخمسة ، مما يحقق متوسط UAS 1.88 نقطة أقل من الإرسال الرسمي الأعلى. لإنتاج التبعيات المحسّنة ، نستغل نهجًا هجينًا ، يقترن تحويل الرسم البياني الحسابي لشجرة التبعية بالتنبؤات التي تم إجراؤها بواسطة نموذج التعلم الآلي متعدد المهام.</abstract_ar>
      <abstract_ja>依存性解析の共有タスクを達成するために、線形遷移ベースのニューラル依存性解析器の使用と、線形木の組み合わせアルゴリズムによるそれらのうちの3つの組み合わせを探索します。共有されたタスクデータに基づいて、各言語の個別のモデルをトレーニングします。ベースパーサーを2つのバイアフィンパーサーと比較し、5つのパーサーすべてのアンサンブルコンビネーションも提示しています。これは、トップの公式提出物よりも平均的なUAS 1.88ポイント低い値を達成します。強化された依存関係を生成するために、我々はハイブリッドアプローチを利用し、依存関係ツリーのアルゴリズム的なグラフ変換をマルチタスク機械学習モデルによって行われる予測と結合する。</abstract_ja>
      <abstract_zh>所以成赖于解析者,求用于线性者神经恃于解析器,及合线性树算法而合于三解析器。 共事数,每语练单模。 校解析器于二字母解析器,而合于五解析器,其均UAS下于官UAS1.88。 为生成增强之恃,我用混合之法,将恃其算法转换与多任务机器学模形之占合。</abstract_zh>
      <abstract_hi>निर्भरता पार्सिंग पर साझा कार्य को पूरा करने के लिए हम एक रैखिक संक्रमण-आधारित तंत्रिका निर्भरता पार्सर के उपयोग के साथ-साथ एक रैखिक पेड़ संयोजन एल्गोरिथ्म के माध्यम से उनमें से तीन के संयोजन का पता लगाते हैं। हम साझा किए गए कार्य डेटा पर प्रत्येक भाषा के लिए अलग-अलग मॉडल को प्रशिक्षित करते हैं। हम अपने बेस पार्सर की तुलना दो बायफिन पार्सर के साथ करते हैं और सभी पांच पार्सर का एक पहनावा संयोजन भी प्रस्तुत करते हैं, जो शीर्ष आधिकारिक प्रस्तुतीकरण की तुलना में औसत यूएएस 1.88 अंक कम प्राप्त करता है। बढ़ी हुई निर्भरताओं के उत्पादन के लिए, हम एक हाइब्रिड दृष्टिकोण का शोषण करते हैं, एक मल्टीटास्क मशीन लर्निंग मॉडल द्वारा की गई भविष्यवाणियों के साथ निर्भरता पेड़ के एक एल्गोरिथम ग्राफ रूपांतरण को युग्मन करते हैं।</abstract_hi>
      <abstract_ru>Для выполнения общей задачи по синтаксическому анализу зависимостей мы исследуем использование нейронного синтаксического анализатора зависимостей на основе линейного перехода, а также комбинацию трех из них с помощью алгоритма комбинации линейного дерева. Мы обучаем отдельные модели для каждого языка на общих данных задач. Мы сравниваем наш базовый парсер с двумя биаффиновыми парсерами, а также представляем ансамблевую комбинацию всех пяти парсеров, которая достигает среднего балла БАС 1,88 ниже, чем лучшее официальное представление. Для получения расширенных зависимостей мы используем гибридный подход, сочетающий алгоритмическое преобразование графа дерева зависимостей с предсказаниями, сделанными многозадачной моделью машинного обучения.</abstract_ru>
      <abstract_ga>Chun an tasc comhroinnte ar pharsáil spleáchais a chur i gcrích déanaimid iniúchadh ar úsáid parsálaí spleáchais néaraigh líneach bunaithe ar thrasdul mar aon le teaglaim de thrí cinn acu trí úsáid a bhaint as algartam líneach teaglaim crann. Cuirimid oiliúint ar mhúnlaí ar leith do gach teanga ar shonraí an taisc chomhroinnte. Déanaimid ár bparsálaí bonn a chur i gcomparáid le dhá pharsálaí biaifín agus cuirimid meascán ensemble de na cúig pharsálaí i láthair freisin, a ghnóthaíonn meánphointe UAS 1.88 níos ísle ná an barr-aighneacht oifigiúil. Chun na spleáchais fheabhsaithe a tháirgeadh, bainimid leas as cur chuige hibrideach, ag cúpláil claochlú graf algartamaigh ar an gcrann spleáchais le réamh-mheastacháin arna ndéanamh ag samhail foghlama meaisín iltasc.</abstract_ga>
      <abstract_el>Για την επίτευξη της κοινής εργασίας για την ανάλυση εξάρτησης εξερευνούμε τη χρήση ενός γραμμικού αναλυτή νευρωνικής εξάρτησης βασισμένου στη μετάβαση καθώς και ενός συνδυασμού τριών από αυτά μέσω ενός αλγόριθμου γραμμικού συνδυασμού δέντρων. Εκπαιδεύουμε ξεχωριστά μοντέλα για κάθε γλώσσα στα δεδομένα κοινής εργασίας. Συγκρίνουμε τον αναλυτή βάσης μας με δύο αναλυτές και παρουσιάζουμε επίσης έναν συνδυασμό συνόλου και των πέντε αναλυτών, ο οποίος επιτυγχάνει ένα μέσο σημείο UAS 1.88 χαμηλότερο από την κορυφαία επίσημη υποβολή. Για την παραγωγή των ενισχυμένων εξαρτήσεων, αξιοποιούμε μια υβριδική προσέγγιση, συνδέοντας έναν αλγοριθμικό μετασχηματισμό γραφήματος του δέντρου εξάρτησης με προβλέψεις που γίνονται από ένα μοντέλο μηχανικής μάθησης πολλαπλών εργασιών.</abstract_el>
      <abstract_hu>A függőség elemzésével kapcsolatos megosztott feladat elvégzéséhez egy lineáris átmeneti alapú neurális függőség elemző, valamint ezek kombinációját egy lineáris fa kombinációs algoritmus segítségével vizsgáljuk. Minden nyelvre külön modelleket készítünk a megosztott feladatadatok alapján. Összehasonlítjuk báziselemzőnket két biaffin elemzővel, és bemutatjuk mind az öt elemző együttes kombinációját is, amely átlagosan UAS 1,88 ponttal alacsonyabb, mint a legfelső hivatalos beadvány. A továbbfejlesztett függőségek előállításához hibrid megközelítést használunk ki, összekapcsoljuk a függőségfa algoritmikus gráf transzformációját egy multifeladatos gépi tanulási modell által készített előrejelzésekkel.</abstract_hu>
      <abstract_ka>ჩვენ განვითარებით განსაზღვრებულობის პარალიზაციისთვის გავაკეთებთ ნეიროლური განსაზღვრებულობის პარალიზაციის გამოყენებას და სამი განსაზღვრებულობის კომბიზაციას linear tree combination algorithm ის გამოყენებას. ჩვენ განყოფილი მოდელები ყოველ ენაზე გავარწმუნეთ დავალების მონაცემებზე. ჩვენ ჩვენი ბაზის პანსერი ორი ბიზაფინის პანსერებით შემდგენებთ და ასევე ყველა ხუთი პანსერების ანსემბლის კომბიზაციას, რომელიც საშუალოდ UAS 1.88 წერტილი უფრო ნაკლები,  გავაკეთებთ უფრო მეტად განსახულებულობების შესახებ, ჩვენ ვიკეთებთ ჰიბრიტური მიღება, ალგორიტიმური გრაფიკის გარგება შესახებ განსახულებელობის ხელის შესახებ მრავალური მაქანის სწ</abstract_ka>
      <abstract_it>Per realizzare il compito condiviso sull'analisi delle dipendenze esploriamo l'uso di un parser di dipendenza neurale basato sulla transizione lineare e di una combinazione di tre di essi per mezzo di un algoritmo di combinazione lineare di alberi. Formiamo modelli separati per ogni lingua sui dati delle attività condivise. Confrontiamo il nostro parser base con due parser biaffine e presentiamo anche una combinazione di tutti e cinque i parser, che raggiunge una media UAS di 1,88 punti inferiore rispetto alla presentazione ufficiale superiore. Per produrre le dipendenze potenziate, sfruttiamo un approccio ibrido, accoppiando una trasformazione algoritmica del grafico dell'albero delle dipendenze con previsioni fatte da un modello di machine learning multitask.</abstract_it>
      <abstract_kk>Тәуелсіздік талдау үшін ортақ тапсырманы ортақтастыру үшін, сызық ауыстыру негіздеген невралдық тәуелсіздік талдағышын және олардың үш тіркесімін сызық ағаш тіркесімдік алгоритмі арқылы қолданы Біз әрбір тіл үшін бөлек тапсырма деректерінің үлгілерін үйренеміз. Біз негізгі талдаушыларымызды екі биафин талдаушыларымызды салыстырып, сондай-ақ бұл бес талдаушылардың орташа UAS 1.88 нүктесінен төмен болады. Қосымша тәуелдіктерді өзгерту үшін біз гибрид тәсілдігін қолданып, көптеген тапсырма машинаның оқыту үлгісінің алгоритмдік график ағашының алгоритмдік түрлендірімін біріктіріп,</abstract_kk>
      <abstract_lt>Siekdami atlikti bendrą užduotį, susijusią su priklausomybės analize, tiriame linijinio pereinamojo laikotarpio nervų priklausomybės analizatoriaus naudojimą ir trijų jų derinį naudojant linijinį medžio derinio algoritmą. Kiekvienai kalbai rengiame atskirus modelius bendrais užduočių duomenimis. Palyginame savo bazinį analizatorių su dviem bifiniais analizatoriais ir taip pat pateikiame visų penkių analizatorių kompleksą, kuris pasiekia vidutinį UAS 1,88 punkto mažesnį nei aukščiausias oficialias paraiškas. Siekdami padidinti priklausomybę, naudojame hibridinį metodą, susiejant priklausomybės medžio algoritminę grafinę transformaciją su daugiafunkcinio mašininio mokymosi modelio prognozėmis.</abstract_lt>
      <abstract_mk>За да ја исполниме заедничката задача за анализирање на зависноста ние ја истражуваме употребата на линијарен анализирач на нервна зависност базиран на транзиција како и комбинација од три од нив преку линијарен алгоритм на комбинација на дрво. Тренираме одделни модели за секој јазик на заедничките податоци за задачите. Ние го споредуваме нашиот базичен анализатор со два биафински анализатори и исто така претставуваме комбинација на ансембл од сите пет анализатори, што постигнува просечен UAS 1,88 поени пониски од највисоката официјална поднесувачка. За производството на зголемените зависности, искористуваме хибриден пристап, поврзувајќи алгоритмичка трансформација на графот на дрвото на зависноста со предвидувања направени од модел на мултизадачно машинско учење.</abstract_mk>
      <abstract_ms>Untuk menyelesaikan tugas berkongsi dalam penghuraian dependensi kami mengeksplorasi penggunaan penghuraian dependensi saraf berasaskan transisi linear serta kombinasi tiga daripada mereka melalui algoritma kombinasi pokok linear. Kami melatih model terpisah untuk setiap bahasa pada data tugas berkongsi. Kita membandingkan penghurai asas kita dengan dua penghurai biaffin dan juga mempersembahkan kombinasi ensemble dari lima penghurai, yang mencapai rata-rata UAS 1.88 titik lebih rendah daripada penghantaran rasmi atas. Untuk menghasilkan dependensi yang meningkat, kita mengeksploitasi pendekatan hibrid, menyambung pengubahan graf algoritmik pokok dependensi dengan ramalan yang dibuat oleh model pembelajaran mesin berbilang tugas.</abstract_ms>
      <abstract_ml>ആശ്രയിച്ച പാര്‍ജിങ്ങിനെ പൂര്‍ത്തിയാക്കാന്‍ പങ്കുചേര്‍ത്ത ജോലി പൂര്‍ത്തിയാക്കുന്നതിനാല്‍ നമ്മള്‍ ഒരു ലൈയറിന്റെ അടിസ്ഥാനമായ ന്യൂറല്‍ ആശ്രയി പങ്കെടുത്ത ജോലിയുടെ വിവരങ്ങളില്‍ ഓരോ ഭാഷയ്ക്കും വേറെ മോഡലുകള്‍ പരിശീലിക്കുന്നു. ഞങ്ങള്‍ നമ്മുടെ ബേസ് പാര്‍സറുകളെ രണ്ട് ബിഫിന്‍ പാര്‍സരുമായി തുല്യമാക്കുകയും, അഞ്ച് പാര്‍സരുകളുടെയും ഒരു കൂട്ടത്തില്‍ കൂട്ടുകയും ചെയ്യുന്നു. അത്  മെച്ചപ്പെട്ട ആശ്രയം ഉണ്ടാക്കുന്നതിന് വേണ്ടി, ഞങ്ങള്‍ ഹൈബ്രിഡിന്‍റെ മാര്‍ഗങ്ങള്‍ ഉപയോഗിക്കുന്നു, ആല്‍ഗോരിത്മിക്ക് ഗ്രാഫ്റ്റ് മാറ്റുന്നത് ആ</abstract_ml>
      <abstract_mt>Biex twettaq il-kompitu kondiviż dwar l-analizzazzjoni tad-dipendenza nesploraw l-użu ta’ analizzatur tad-dipendenza newrali lineari bbażat fuq tranżizzjoni kif ukoll kombinazzjoni ta’ tlieta minnhom permezz ta’ algoritmu ta’ kombinazzjoni lineari tas-siġar. We train separate models for each language on the shared task data.  Aħna nqabblu l-analizzatur bażiku tagħna ma’ żewġ analizzaturi biffini u nippreżentaw ukoll kombinazzjoni ta’ ensemble tal-ħames analizzaturi kollha, li tikseb medja ta’ UAS 1.88 punt inqas mill-ogħla sottomissjoni uffiċjali. Biex nipproduċu d-dipendenzi msaħħa, nisfruttaw approċċ ibridu, li jgħaqqad trasformazzjoni algoritmika tal-grafika tas-siġar tad-dipendenza ma’ tbassir magħmul minn mudell ta’ tagħlim ta’ magni multikompiti.</abstract_mt>
      <abstract_mn>Харин хамааралтай хуваалцааны тухай хуваалцааны тулд бид шулуун шилжилт дээр суурилсан мэдрэлийн хамааралтай хуваалцааны хэрэглээ, тэдгээрийн гуравыг шулуун модны холбоотой алгоритмын аргаар холбоотой. Бид хэл бүрийн хуваалтын ажлын мэдээлэл дээр хуваалцах загваруудыг суралцаж байна. Бид суурь хуваарилцагчидтай хоёр биефин хуваарилцагчидтай харьцуулж, мөн бүх таван хуваарилцагчидтай холбогдож байна. Энэ нь дундаж UAS 1.88 цэгээс бага байдаг. Хамгийн сайхан хамааралтай байдлыг бүтээхэд бид гибрид аргыг ашиглаж, олон ажлын машин суралцах загварын алгоритмын графикийн өөрчлөлтийг холбоотой.</abstract_mn>
      <abstract_no>For å fullføra delt oppgåve på tolking av avhengighet, utforskar vi bruken av ein lineær oversikningsbasert neuralavhengighetsanalyser og kombinasjonen av tre av dei med ein lineær tre-kombinasjonalgoritme. Vi treng separate modeller for kvar språk på delte oppgåveddata. Vi samanliknar grunntolkaren vårt med to biafin-tolkare og også presenterer ein ensembelkombinasjon av alle fem tolkare, som oppnår eit gjennomsnittlig UAS 1.88 punkt mindre enn den øvste offisielle submisasjonen. For å produsere forbetre avhengigheten, bruker vi ein hybridtilnærming, og koplar ein algoritmisk grafikktransformasjon av avhengighetstrået med foregåver laga av ein multioppgåvemaskinlæringsmodell.</abstract_no>
      <abstract_pl>Aby wykonać wspólne zadanie w zakresie parsowania zależności badamy zastosowanie liniowego parsera zależności neuronowej opartego na przejściu liniowym, a także kombinacji trzech z nich za pomocą liniowego algorytmu kombinacji drzew. Szkolimy oddzielne modele dla każdego języka na podstawie współdzielonych danych zadań. Porównujemy nasz bazowy parser z dwoma parserami biafinowymi, a także prezentujemy zespół kombinacji wszystkich pięciu parserów, który osiąga średni punkt UAS 1.88 niższy od górnego oficjalnego zgłoszenia. Do tworzenia wzmocnionych zależności wykorzystujemy podejście hybrydowe, łączące algorytmiczną transformację wykresu drzewa zależności z prognozami wykonanymi przez wielozadaniowy model uczenia maszynowego.</abstract_pl>
      <abstract_ro>Pentru a realiza sarcina comună privind analizarea dependențelor explorăm utilizarea unui parser de dependență neuronală bazat pe tranziție liniară, precum și o combinație a trei dintre ele prin intermediul unui algoritm liniar de combinație a arborilor. Instruim modele separate pentru fiecare limbă pe datele de sarcină partajate. Comparăm analizorul nostru de bază cu două analizoare de biafine și prezentăm, de asemenea, o combinație de ansamblu a tuturor celor cinci analizoare, care atinge o medie UAS cu 1,88 punct mai mică decât cea de sus depusă oficială. Pentru producerea dependențelor îmbunătățite, exploatăm o abordare hibridă, cuplând o transformare algoritmică a graficului arborelui dependențelor cu predicții făcute de un model de machine learning multitask.</abstract_ro>
      <abstract_sr>Da bi postigli zajednički zadatak na analizu zavisnosti istražili smo upotrebu linearnog analizatora neuralne zavisnosti na prelazu, kao i kombinaciju troje od njih linearnim algoritmom kombinacije drveta. Treniramo odvojene modele za svaki jezik na podacima zajedničkog zadatka. Uspoređujemo naš bazni analizator sa dva parsera biafina i takođe predstavljamo kombinaciju ensemble svih pet parsera, koji postiže prosječnu UAS 1.88 tačku nižu od najvećeg zvaničnog podnošenja. Za proizvodnju poboljšanih zavisnosti, iskorištavamo hibridni pristup, povezujući algoritmsku transformaciju grafa na drvetu zavisnosti sa predviđanjem koji je napravio model učenja multitask mašine.</abstract_sr>
      <abstract_so>Si aan u dhamaado shaqada la qaybsan jardiinada ku xiran, waxaynu baaraynaa isticmaalka ku saabsan baaritaanka neurada ee qoriga ah ee ku xiran qoriga ah, sidoo kale kooxa saddex ka mid ah oo ku qoran algorithm qoriga ah. Waxaannu ku tababarinnaa tusaalooyin kala duduwan oo luuqad walba ku saabsan macluumaadka shaqada. Waxaynu isbarbardhignaa baarlamayaasheena aasaaska ah laba baaritaan oo biaffin ah islamarkaasna waxaynu keennaa isku xir ka mid ah shanta baarlamadooda oo dhan, taasoo gaadha qiimaha ugu hooseeya UAS 1.88 oo ka hoosaysa warqada rasmiga sare. Si a an u korinno kalsoonaanta, waxaynu isticmaalnaa hab-dhaqdhaqaaq ah, isbedelka qoriga algorithmic ah ee geedka ku xiran ee ku saabsan, waxaynu ka dhignaa wax horumarinta qaababka barashada machadka badan.</abstract_so>
      <abstract_sv>För att utföra den delade uppgiften om beroendetolkning undersöker vi användningen av en linjär övergångsbaserad neural beroendetolkning samt en kombination av tre av dem med hjälp av en linjär trädkombinationsalgoritm. Vi utbildar separata modeller för varje språk på de delade uppgifterna. Vi jämför vår basparser med två biaffinpolisrar och presenterar också en ensemblekombination av alla fem parsrar, vilket uppnår en genomsnittlig UAS 1,88 poäng lägre än den högsta officiella inlämningen. För att producera de förbättrade beroendena utnyttjar vi en hybrid ansats, kopplar ihop en algoritmisk grafomvandling av beroendeträdet med förutsägelser gjorda av en multi-task maskininlärningsmodell.</abstract_sv>
      <abstract_si>සාමාන්‍ය විශ්ලේෂණය සඳහා සාමාන්‍ය විශ්ලේෂණය සඳහා සාමාන්‍ය විශ්ලේෂණය සඳහා සාමාන්‍ය විශ්ලේෂණය සඳහා සාමාන්‍ය විශ්ලේෂණය සඳහා  අපි හැම භාෂාවෙන් වෙනුවෙන් පෙනුම් මොඩල් කිරීම් කරනවා සමාගත වැඩක් තොරතුරු ගැන. අපි අපේ අධාරණ පරීක්ෂකය බියාෆින් පරීක්ෂකය දෙකක් සමග සම්බන්ධ කරනවා සම්බන්ධ පහත් පරීක්ෂකයෝ සම්බන්ධ කරනවා, ඒකෙන් අධ විශේෂ විශේෂ විශ්වාස කරන්න, අපි හයිබ්‍රිඩ් විශේෂයක් ප්‍රයෝජනය කරනවා, ඇල්ගෝරිත්මික ග්‍රාෆ් එක්ක අවශ්‍ය වර්ගයේ විස්</abstract_si>
      <abstract_ta>சார்ந்த பாடல் மீது பகிர்ந்த பணியை முடிக்க நாம் கோடு மாறுதல் அடிப்படையில் சார்ந்த நரம்பர் சார்பு பரிசோதனையைப் பயன்படுத்துகிறோம் மற்றும் ஒரு வரிய நாம் ஒவ்வொரு மொழிக்கும் பங்கிடப்பட்ட பணி தரவுக்கும் தனியான மாதிரிகளை பயிற்சி செய்கிறோ நாம் எங்கள் அடிப்படையின் பகுதியை இரண்டு பைபின் பார்சர்களுடன் ஒப்பிடுகிறோம் மற்றும் அனைத்து ஐந்து பார்சர்களுக்கும் ஒரு ஒப்பிணைப்பை கொண மேம்படுத்தப்பட்ட சார்புகளை உருவாக்குவதற்கு, நாம் ஒரு ஹைப்ரிட் செயல்பாட்டை பயன்படுத்தி, சார்ந்த மரத்தின் வரைபடம் மாற்றம் சேர்க்கிறது, ஒரு பல்திருப்ப</abstract_ta>
      <abstract_ur>ان میں سے تین ترین درخت ترکیب الگوریتم کے ذریعہ سے مشترک کام پورا کرنے کے لئے ہم ایک لینیاری ترکیب کے بنیاد نیورال اعتماد پارچر کے استعمال کو دیکھتے ہیں۔ ہم ہر زبان کے لئے مختلف موڈل کی تعلیم دیتے ہیں مشترک ٹاکس ڈیٹ پر۔ ہم نے اپنے بنیاس پارچر کو دو بیفائن پارچر کے ساتھ مقایسہ کر دیا ہے اور ہم نے تمام پانچ پارچر کے ایک انسمبل پیوند کو بھی پیش کیا ہے، جو ایک متوسط UAS 1.88 پوینٹ سے زیادہ کم ہے۔ مزید اعتباری کے لئے ہم ایک ہیبراڈ طریقہ کے مطابق اضافہ کرتے ہیں، ایک الگوریٹمیک گراف کی تغییر کے ساتھ ایک متعد ٹاکس ماشین کی تعلیم مدل کے ذریعے بنائی ہوئی پیش بینی کے ساتھ ایک الگوریٹمیک گراف کی تغییر کے سات</abstract_ur>
      <abstract_vi>Để hoàn thành nhiệm vụ chia sẻ dựa trên phân tích phụ thuộc, chúng ta sẽ khám phá việc sử dụng một phân tích dây thần kinh phụ thuộc liên tiếp tuyến tính, cũng như một sự kết hợp ba trong số đó bằng thuật toán kết hợp cây tuyến. Chúng tôi đào tạo mô- đun cho mỗi ngôn ngữ trên dữ liệu tác vụ chia sẻ. Chúng tôi so sánh căn cứ của chúng tôi với hai cha xứ hai chữ dán và cũng có một kết hợp đủ của cả năm cha xứ, với một điểm trung bình UAS 1.88 thấp hơn điểm xuất bản chính thức đầu. Để tạo ra các mối quan hệ phụ thuộc nâng cao, chúng tôi sử dụng một phương pháp lai hợp, nối một biểu đồ chuyển đổi biểu đồ phân giải của cây độ phụ thuộc với dự đoán của một mô hình máy học đa nhiệm.</abstract_vi>
      <abstract_uz>Ulangan tashkilotni ishga tushirish uchun biz liney transition asosida neyrolik ishlatuvchidan foydalanamiz va ulardan uchta bir birlashtirish daraxtning algorithi orqali birlashtiramiz. Biz har bir tillar bilan bir xil vazifa maʼlumotiga bir xil modellarni o'rganamiz. Biz bizning asosiy parserlarimizni ikkita biaffin parserga kamaytirimiz va hamma besh parserdagi bir eksembli bir birlashtirishni hozir qilamiz. Bu eng sarlavha xabarga UAS 1.88 pochta yaratish mumkin. Koʻpaytirilgan qoidalarni yaratish uchun biz hybrid usulida foydalanamiz, tashkilot darajadagi algorithik grafikni o'zgartirish va bir necha mashina o'rganish modeli bilan birlashtirilgan kutilgan deb o'ylaymiz.</abstract_uz>
      <abstract_bg>За да изпълним споделената задача за анализ на зависимостта, изследваме използването на линеен преходен анализ на нервната зависимост, както и комбинация от три от тях чрез алгоритъм за линейна комбинация от дървета. Обучаваме отделни модели за всеки език на споделените данни за задачи. Сравняваме нашия базов анализатор с два биафинови анализатора и също така представяме ансамбълна комбинация от всичките пет анализатора, която постига средно 1.88 пункта по-ниско от най-официалното представяне. За създаване на подобрени зависимости използваме хибриден подход, свързващ алгоритмична графика трансформация на дървото на зависимостта с прогнози, направени от многозадачен модел на машинно обучение.</abstract_bg>
      <abstract_nl>Om de gedeelde taak over afhankelijkheidsparsen te voltooien onderzoeken we het gebruik van een lineaire transitie-gebaseerde neurale afhankelijkheidsparser, evenals een combinatie van drie daarvan door middel van een lineair boomcombinatiealgoritme. We trainen afzonderlijke modellen voor elke taal op de gedeelde taakgegevens. We vergelijken onze basis parser met twee biaffine parsers en presenteren ook een ensemble combinatie van alle vijf parsers, die een gemiddelde UAS 1.88 punt lager behaalt dan de hoogste officiële inzending. Voor het produceren van de verbeterde afhankelijkheden gebruiken we een hybride benadering, waarbij we een algoritmische grafiektransformatie van de afhankelijkheidsboom koppelen aan voorspellingen gemaakt door een multitask machine learning model.</abstract_nl>
      <abstract_da>For at udføre den fælles opgave om afhængighedsanalyse undersøger vi brugen af en lineær overgangsbaseret neural afhængighedsfortolker samt en kombination af tre af dem ved hjælp af en lineær trækombination algoritme. Vi træner separate modeller for hvert sprog på de delte opgavedata. Vi sammenligner vores base parser med to biaffine parsere og præsenterer også en ensemble kombination af alle fem parsere, som opnår et gennemsnitligt UAS 1,88 point lavere end den øverste officielle indsendelse. Til at producere de forbedrede afhængigheder udnytter vi en hybrid tilgang, der kombinerer en algoritmisk graftransformation af afhængighedstræet med forudsigelser lavet af en multi-task machine learning model.</abstract_da>
      <abstract_de>Um die gemeinsame Aufgabe zum Dependency Parsing zu erfüllen, untersuchen wir die Verwendung eines linearen Übergangs-basierten neuronalen Dependency Parsers sowie einer Kombination von drei von ihnen mittels eines linearen Baumkombinationsalgorithmus. Wir trainieren für jede Sprache separate Modelle auf den gemeinsamen Aufgabendaten. Wir vergleichen unseren Basis-Parser mit zwei Biaffin-Parsern und präsentieren auch eine Ensemble-Kombination aller fünf Parser, die einen durchschnittlichen UAS 1.88 Punkt niedriger als die oberste offizielle Einreichung erreicht. Zur Erzeugung der erweiterten Abhängigkeiten nutzen wir einen hybriden Ansatz, der eine algorithmische Graphtransformation des Abhängigkeitsbaums mit Vorhersagen eines Multitask Machine Learning Modells koppelt.</abstract_de>
      <abstract_ko>의존 해석의 공유 임무를 완성하기 위해 우리는 선형 전환을 바탕으로 하는 신경 의존 해석기의 사용과 선형 트리 조합 알고리즘을 통해 이 세 가지를 결합시켰다.우리는 임무 데이터를 공유하는 데 있어서 모든 언어를 위한 단독 모델을 훈련한다.우리는 우리의 기본 해석기와 두 개의 쌍ffine 해석기를 비교하고 모든 다섯 개의 해석기의 통합 조합을 제시했는데 그 평균 UAS는 최고 정부에서 제출한 값보다 1.88퍼센트 낮았다.강화된 의존을 형성하기 위해 우리는 혼합 방법을 채택하여 의존 트리의 알고리즘 그래프 변환과 다중 임무 기계 학습 모델의 예측을 결합시켰다.</abstract_ko>
      <abstract_id>Untuk menyelesaikan tugas bersama dalam penghuraian dependensi kami menjelajahi penggunaan penghuraian dependensi saraf berdasarkan transisi linear serta kombinasi tiga dari mereka melalui algoritma kombinasi pohon linear. Kami melatih model terpisah untuk setiap bahasa pada data tugas yang sama. Kami membandingkan parser dasar kami dengan dua parser biaffine dan juga mempersembahkan kombinasi ensemble dari lima parser, yang mencapai rata-rata UAS 1,88 titik lebih rendah dari sumpahan resmi atas. Untuk menghasilkan ketergantuan yang meningkat, kami mengeksploitasi pendekatan hibrid, menyambung transformasi grafik algoritmi pohon ketergantuan dengan prediksi yang dibuat oleh model belajar mesin multitask.</abstract_id>
      <abstract_sw>Kutimiza jukumu la kushirikiana kwa kutegemea bunge tunachunguza matumizi ya kutegemea na kutegemea na taratibu za taratibu za kisasa na pamoja na muunganiko wa watatu kati yao kwa njia ya utaratibu wa miti ya msingi. Tunafundisha mifano tofauti kwa kila lugha kwa taarifa za kazi zinazoshirikiana. Tunawalinganisha mabango yetu ya msingi na mabango mawili ya biafi na pia tunaweka muunganiko wa mbunge wote watano, ambao unafananisha kiwango cha wastani cha UAS 1.88 chini ya ujumbe wa rasmi wa juu. Kwa kutengeneza kutegemea matumaini, tunatumia mbinu za bikira, kuunganisha mabadiliko ya picha ya algorithia ya mti wa kutegemea na utabiri uliofanywa na modeli ya kujifunza mashine ya viumbe.</abstract_sw>
      <abstract_fa>برای انجام کار مشترک روی بررسی بستگی، ما استفاده از یک بررسی بستگی عصبی بر اساس تغییر خطی و ترکیب سه از آنها را به وسیله الگوریتم ترکیب درخت خطی تحقیق می کنیم. ما مدل‌های جدا را برای هر زبان روی داده‌های کار مشترک آموزش می‌دهیم. ما پایگاه پایین‌مون را با دو دستگاه‌کننده‌ی biaffine مقایسه می‌کنیم و همچنین یک ترکیب انجمن انجمن از همه پنج دستگاه‌کننده را نشان می‌دهیم که متوسط UAS 1.88 نقطه پایین‌تر از دستگاه رسمی بالا می‌رسد. برای تولید بستگی‌های بیشتر، ما یک روش hybrid را استفاده می‌کنیم، با تغییر یک گراف الگوریتم از درخت بستگی با پیش بینی‌ها که توسط یک مدل یادگیری ماشین‌های زیادی بستگی انجام می‌دهند، تغییر دهیم.</abstract_fa>
      <abstract_tr>Bağlamlık parslamasynda paylaşılan görevi başarmak üçin lineer bir geçiş baglanmasynyň yada üçiniň birleşmesini lineer bir agaç kombinatsiyası algoritmi bilen gözden geçiriyoruz. Biz her dil üçin ayrı nusgalary paylaşyk gören maglumatlarynda tren edýäris. Biz öz paýlaşçymyzy iki biafin parsöri bilen karşılaştyrýarys we hem bütin beş parsörlerin birleşmesini hem ortalama UAS 1.88 noktalary iň üst resmi süýşinden azaltýar. Günahlary gelişmek üçin, biz hybrid ýazşyny ulanýarys, multi-täblik maşynyň öwrenmek nusgasyna tarapyndan baglanylyk agajynyň algoritmik grafisiniň üýtgewini bilen çarpýarys.</abstract_tr>
      <abstract_af>Om die gedeelde taak te voldoen op afhanklikheid verwerking, ondersoek ons die gebruik van 'n lineêre oorgang-gebaseerde neurale afhanklikheidspanseerder en 'n kombinasie van drie van hulle deur 'n lineêre boom kombinasie algoritme. Ons trein skeidige modele vir elke taal op die gedeelde taak data. Ons vergelyk ons basis ontleerder met twee biaffine ontleerders en ook voorsien 'n ensemble kombinasie van alle vyf ontleerders, wat 'n gemiddelde UAS 1.88 punt onder as die bo-offisiele ondersiening bereik word. Want die verbeterde afhanklikheid te produseer, word ons 'n hybrid toegang uitgebruik en 'n algoritmiske graaftransformasie van die afhanklikheidsboom saam met voorskoude wat deur 'n multitaak masjien leer model gemaak is.</abstract_af>
      <abstract_sq>To accomplish the shared task on dependency parsing we explore the use of a linear transition-based neural dependency parser as well as a combination of three of them by means of a linear tree combination algorithm.  Ne trajnojmë modele të veçanta për çdo gjuhë në të dhënat e përbashkëta të detyrave. Ne krahasojmë analizuesin tonë bazë me dy analizuesit biafin dhe prezantojmë gjithashtu një kombinim ensemble të të pesë analizuesve, që arrin një mesatare UAS 1.88 pikë më të ulët se paraqitja zyrtare më e lartë. Për prodhimin e varësive të përmirësuara, ne shfrytëzojmë një qasje hibride, duke lidhur një transformim algoritmik grafik të pemës së varësisë me parashikime të bërë nga një model mësimi i makinave me shumë detyra.</abstract_sq>
      <abstract_hr>Za postizanje zajedničkog zadatka na analizu zavisnosti istražujemo upotrebu linearnog analizatora neuralne zavisnosti na temelju transicije, kao i kombinacije troje od njih linearnim algoritmom kombinacije drveta. Treniramo odvojene modele za svaki jezik na podacima zajedničkog zadatka. Upoređujemo naš bazni analitičar sa dva parsera biafina i također predstavljamo kombinaciju ensemble svih pet parsera, koji postigne prosječnu UAS 1.88 tačku nižu od najvišeg zvaničnog podataka. Za proizvodnju poboljšanih zavisnosti, iskorištavamo hibridni pristup, povezujući algoritmsku transformaciju grafa zavisnosti drveta sa predviđanjima koji su napravili model učenja multitask strojeva.</abstract_hr>
      <abstract_hy>Որպեսզի կախվածության վերլուծության ընդհանուր խնդիրը կատարենք, մենք ուսումնասիրում ենք գծային վերաբերյալ հիմնված նյարդային կախվածության վերլուծում օգտագործվող վերլուծում, ինչպես նաև դրանցից երեքի համադրում գծային համադրման ալգորիթմի միջոցով: Մենք յուրաքանչյուր լեզու համար առանձին մոդելներ ենք սովորեցնում ընդհանուր խնդիրների տվյալների վրա: Մենք համեմատում ենք մեր հիմնական վերլուծողը երկու բիաֆինի վերլուծողների հետ և ներկայացնում ենք նաև հինգ վերլուծողների համակցությունը, որը հասնում է միջին UAS-ի 1.88 կետին ավելի ցածր, քան վերջին պաշտոնական ներկայացումը: Մենք օգտագործում ենք հիբրիդ մոտեցումը, կապելով կախվածության ծառի ալգորիթմային փոխակերպումը բազմախնդիր մեքենայի ուսումնասիրության մոդելի կողմից արված կանխատեսումների հետ:</abstract_hy>
      <abstract_am>በተካሄደው ፓርቲ ላይ የተካፈለውን ስራ ለመፈጸም፣ የlinear የኔural ተሟጋቾችን በመጠቀም እና እነዚህን ሦስቱን በመጠቀም በአየር ዛፍ ማቀናቀል አሌጎሪትምን እናስፈልጋለን፡፡ ለቋንቋው ሁሉ የተለያየ የስራ ዳታዎችን እናስተምራለን፡፡ የቤታችንን ምርጫዎች ከሁለት ቢፊን ፓርስር ጋር እናሳያታለን እና ከአምስቱ ፓርስር ሁሉ የተለየ ጥያቄን እናደርጋለን፡፡ የበለጠ ጥያቄዎችን ለማድረግ፣ የኬብሪዲን ሥርዓት ለመፍጠር፣ የአልጎሪካዊ የግንኙነት ዛፍ ለውጥ እናስቀራለን፡፡</abstract_am>
      <abstract_bn>নির্ভরশীল পার্সিং সম্পর্কে শেয়ার করার জন্য আমরা লাইনিয়ার পরিবর্তনের ভিত্তিক নিউরেল নির্ভরশীল ব্যাপার ব্যবহার করি এবং তাদের মধ্যে তিনজনের একটি সংযুক্ত কর আমরা প্রত্যেক ভাষার জন্য বিভিন্ন মডেল প্রশিক্ষণ দেই শেয়ার করা কাজের তথ্যে। আমরা আমাদের বেস প্যারালারকে দুটি বিফিন পার্সারের সাথে তুলনা করি এবং পাঁচটি পার্সারের একটি সংযোগের সাথে উপস্থিত করি, যা সর্বোচ্চ সরকারি প্রদান বৃদ্ধির নির্ভর করার জন্য আমরা একটি হাইব্রিড পদ্ধতি ব্যবহার করি, একটি আলগরিদমিক গ্রামের নির্ভরশীল গাছের পরিবর্তন সংযুক্ত করি, একটি মাল্টিউটিক্যার মেশিন শিক</abstract_bn>
      <abstract_az>Bağımsızlıq ayırılması haqqında paylaşılan işləri yerinə yetirmək üçün linear dəyişiklik tərəfindən olan nöral bağımlılıq ayırıcısının və onlardan üçünün birləşdirilməsini linear a ğac kombinatsiyası algoritmi vasitəsilə keşfetiririk. Biz hər dil üçün ayrı modellər təhsil edirik. Biz üssü ayırıcımızı iki biafin ayırıcısı ilə qarşılaşdırırıq və həmçinin bütün beş ayırıcıların ensemble kombinatsiyasını göstəririk. Bu, ortalama UAS 1.88 noktası ən yüksək resmi təbliğdən aşağı olar. Daha yüksək bağlılıqları ürəkləndirmək üçün, bir hibrid tərzini istifadə edirik, çoxlu iş makinelərin öyrənməsi modeli ilə müvəffəqiyyət a ğacının algoritmik grafik transformasiyasını birləşdiririk.</abstract_az>
      <abstract_bs>Da bi postigli zajednički zadatak na analizu zavisnosti istražili smo upotrebu linearnog analizatora neuralne zavisnosti na prelazu, kao i kombinaciju troje od njih linearnim algoritmom kombinacije drveta. Treniramo odvojene modele za svaki jezik na podacima zajedničkog zadatka. Upoređujemo naš bazni analitičar sa dva parsera biafina i također predstavljamo kombinaciju ensemble svih pet parsera, koji postigne prosječnu UAS 1.88 tačku nižu od najvišeg zvaničnog podataka. Za proizvodnju poboljšanih zavisnosti, iskoristimo hibridni pristup, povezujući algoritmsku transformaciju grafa na drvetu zavisnosti sa predviđanjima koji su napravili model učenja multitask mašine.</abstract_bs>
      <abstract_ca>Per aconseguir la tasca compartida en l'analització de la dependencia, explorem l'ús d'un analitzador de dependencia neuronal basat en transició linear, com també una combinació de tres amb un algoritme de combinació linear d'arbres. Ensenyem models separats per cada llengua en les dades de tasca compartida. Comparem el nostre analitzador bàsic amb dos analitzadors biaffins i també presentem una combinació d'ensembles de cinc analitzadors, que aconsegueix una mitjana de UAS 1,88 punts més baixa que la suposició oficial superior. Per produir les dependències millorades, explotam un enfocament híbrid, acoplant una transformació algorítmica del gràfic del arbre de dependencia amb prediccions fetes per un model d'aprenentatge multitasca.</abstract_ca>
      <abstract_cs>Pro splnění sdíleného úkolu analyzování závislostí zkoumáme využití lineárního přechodového neuronového analyzování závislostí, stejně jako kombinaci tří z nich pomocí lineárního algoritmu kombinace stromů. Pro každý jazyk trénujeme samostatné modely na sdílených úkolech. Porovnáváme náš základní parser se dvěma biafinovými parsery a také představujeme souborovou kombinaci všech pěti parserů, která dosahuje průměrného UAS 1.88 bodu nižšího než vrcholní oficiální podání. Pro vytvoření rozšířených závislostí využíváme hybridního přístupu, který propojuje algoritmickou transformaci grafu stromu závislostí s predikcemi provedenými multiúlohovým modelem strojového učení.</abstract_cs>
      <abstract_fi>Riippuvuusparsauksen yhteisen tehtävän suorittamiseksi tutkimme lineaarisen siirtymäpohjaisen neuroriippuvuuden parsaurin käyttöä sekä niiden kolmen yhdistelmää lineaarisen puuyhdistelmäalgoritmin avulla. Koulutamme kullekin kielelle erilliset mallit jaettujen tehtävätietojen pohjalta. Vertailemme perusparseriamme kahteen biafiininparseriin ja esittelemme myös yhdistelmän kaikista viidestä parserista, joka saavuttaa keskimääräisen UAS 1,88 pistettä alemman kuin korkein virallinen toimitus. Tehostettujen riippuvuuksien tuottamiseksi hyödynnämme hybridiajattelua, joka yhdistää riippuvuuspuun algoritmisen graafimuunnoksen monitehtävän koneoppimismallin tekemiin ennusteisiin.</abstract_fi>
      <abstract_et>Sõltuvuse parsimise jagatud ülesande täitmiseks uurime lineaarse üleminekupõhise närvisõltuvuse parseri kasutamist ning nende kolme kombinatsiooni kasutamist lineaarse puukombinatsiooni algoritmi abil. Koolitame iga keele jaoks eraldi mudeleid jagatud ülesannete andmetel. Me võrdleme oma baaspartserit kahe biafiinpartseriga ja esitame ka kõigi viie parseri ansambli kombinatsiooni, mis saavutab keskmise UAS 1,88 punkti madalama kui top ametlik esitus. Täiustatud sõltuvuste tootmiseks kasutame hübriidset lähenemisviisi, ühendades sõltuvuspuu algoritmgraafilise transformatsiooni multiülesandelise masinõppe mudeli abil tehtud prognoosidega.</abstract_et>
      <abstract_jv>Ngubah nambah Genjer-Genjer Kernel Jejaring</abstract_jv>
      <abstract_sk>Za izvedbo skupne naloge razčlenjanja odvisnosti raziskujemo uporabo linearnega prehodnega razčlenjevalnika nevronske odvisnosti in kombinacijo treh izmed njih s pomočjo algoritma linearne kombinacije dreves. Usposabljamo ločene modele za vsak jezik na podatkih o skupnih opravilih. Naš osnovni parser primerjamo z dvema biafinskima parserjema in predstavljamo tudi kombinacijo ansambla vseh petih parserjev, ki doseže povprečno UAS za 1,88 točke nižje od najvišje uradne predložitve. Za izdelavo izboljšanih odvisnosti izkoristimo hibridni pristop, ki povezuje algoritmsko grafsko transformacijo drevesa odvisnosti z napovedmi, ki jih naredi model večopravilnega strojnega učenja.</abstract_sk>
      <abstract_he>כדי להשיג את המשימה המשותפת על בדיקת תלויות אנו חוקרים את השימוש של בדיקת תלויות עצביות מבוססת על מעבר לינרי כמו גם שילוב של שלושה מהם באמצעות אלגוריתם שילוב עץ לינרי. אנחנו מאמן דוגמנים נפרדים לכל שפה על נתוני המשימה המשותפים. אנחנו משווה את המחקר הבסיסי שלנו עם שני המחקרים ביאפין וגם מציגים שילוב של כל חמש המחקרים, אשר משיג UAS ממוצע 1.88 נקודה נמוכה יותר מההתביעה הרשמית העליונה. כדי לייצר את התלויות המשותפות, אנו מנצלים גישה היברידית, מחוברים שינוי גרף אלגוריתמי של עץ התלויות</abstract_he>
      <abstract_ha>To, in cika the share of the job on depend parse, we use the use of a line transitional deposition based on neural parser as also a kombine of three of them by a line line line algoritm. Tuna kõre misãlai daban-daban ga duk harshe a kan data da ke raba aiki. Tuna samfani masu bincike da parser biyu na biffine kuma munã sami komai da misalin mafakin parser, wanda ke sami gaba ga tsakanin USA 1.88 da ke ƙaranci da duk kashi. For producing the enhanced dependencies, we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.</abstract_ha>
      <abstract_bo>མཉམ་འབྲེལ་གྱི་རྟེན་འབྲེལ་མིན་སྟངས་ལས་དབྱེ་སྟངས་དང་མཉམ་དུ་ཉར་སྤྱོད་ཀྱི་དཔྱད་རིས་གཞི་བརྗོད་ཀྱི་ཕྱོགས་སྟོན་ཚོགས ང་ཚོས་སྐད ང་ཚོའི་རྨང་གཞིའི་མིག་སྒྲིག་དབྱེ་བ་དང་biaffine parsers གཉིས་ཀྱིས་བཟུང་བྱེད་ཀྱི་ཡོད། དེ་ལས་ཀྱང་ང་ཚོའི་ནང་ལྟ་བུའི་མཐུན་སྒྲིག ང་ཚོས་བློ་གཏོང་བར་གནས་ཚུལ་འདྲ་ཞིག་གིས་བཟོ་བརྩོན་བྱས་པ་ཡིན་ན།</abstract_bo>
      </paper>
    <paper id="23">
      <title>How Much of Enhanced UD Is Contained in UD?<fixed-case>UD</fixed-case> Is Contained in <fixed-case>UD</fixed-case>?</title>
      <author><first>Adam</first><last>Ek</last></author>
      <author><first>Jean-Philippe</first><last>Bernardy</last></author>
      <pages>221–226</pages>
      <abstract>In this paper, we present the submission of team CLASP to the IWPT 2020 Shared Task on parsing enhanced universal dependencies. We develop a tree-to-graph transformation algorithm based on dependency patterns. This <a href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a> can transform gold UD trees to EUD graphs with an ELAS score of 81.55 and a EULAS score of 96.70. These results show that much of the information needed to construct EUD graphs from UD trees are present in the UD trees. Coupled with a standard UD parser, the method applies to the official test data and yields and ELAS score of 67.85 and a EULAS score is 80.18.</abstract>
      <url hash="f2527a0f">2020.iwpt-1.23</url>
      <doi>10.18653/v1/2020.iwpt-1.23</doi>
      <video href="http://slideslive.com/38929690" />
      <bibkey>ek-bernardy-2020-much</bibkey>
    </paper>
    </volume>
</collection>