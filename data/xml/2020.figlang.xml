<collection id="2020.figlang">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Figurative Language Processing</booktitle>
      <editor><first>Beata Beigman</first><last>Klebanov</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <editor><first>Patricia</first><last>Lichtenstein</last></editor>
      <editor><first>Smaranda</first><last>Muresan</last></editor>
      <editor><first>Chee</first><last>Wee</last></editor>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Debanjan</first><last>Ghosh</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="5a671364">2020.figlang-1</url>
    </meta>
    <frontmatter>
      <url hash="567b9601">2020.figlang-1.0</url>
      <bibkey>fig-lang-2020-figurative</bibkey>
    </frontmatter>
    <paper id="7">
      <title>Sarcasm Detection in Tweets with <fixed-case>BERT</fixed-case> and <fixed-case>G</fixed-case>lo<fixed-case>V</fixed-case>e Embeddings</title>
      <author><first>Akshay</first><last>Khatri</last></author>
      <author><first>Pranav</first><last>P</last></author>
      <pages>56&#8211;60</pages>
      <abstract>Sarcasm is a form of communication in which the person states opposite of what he actually means. In this paper, we propose using machine learning techniques with BERT and GloVe embeddings to detect sarcasm in tweets. The dataset is preprocessed before extracting the embeddings. The proposed model also uses all of the context provided in the dataset to which the user is reacting along with his actual response.</abstract>
      <url hash="060f0261">2020.figlang-1.7</url>
      <doi>10.18653/v1/2020.figlang-1.7</doi>
      <video href="http://slideslive.com/38929697" />
      <bibkey>khatri-p-2020-sarcasm</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>C</fixed-case>-Net: Contextual Network for Sarcasm Detection</title>
      <author><first>Amit</first><last>Kumar Jena</last></author>
      <author><first>Aman</first><last>Sinha</last></author>
      <author><first>Rohit</first><last>Agarwal</last></author>
      <pages>61&#8211;66</pages>
      <abstract>Automatic Sarcasm Detection in conversations is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, C-Net, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our model showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0% F1-score on the Twitter dataset and 66.3% F1-score on Reddit dataset.</abstract>
      <url hash="5ca7edd9">2020.figlang-1.8</url>
      <doi>10.18653/v1/2020.figlang-1.8</doi>
      <video href="http://slideslive.com/38929698" />
      <bibkey>kumar-jena-etal-2020-c</bibkey>
    </paper>
    <paper id="10">
      <title>Sarcasm Identification and Detection in Conversion Context using <fixed-case>BERT</fixed-case></title>
      <author><first>Kalaivani</first><last>A.</last></author>
      <author><first>Thenmozhi</first><last>D.</last></author>
      <pages>72&#8211;76</pages>
      <abstract>Sarcasm analysis in user conversion text is automatic detection of any irony, insult, hurting, painful, caustic, humour, vulgarity that degrades an individual. It is helpful in the field of sentimental analysis and cyberbullying. As an immense growth of social media, sarcasm analysis helps to avoid insult, hurts and humour to affect someone. In this paper, we present traditional machine learning approaches, deep learning approach (LSTM -RNN) and BERT (Bidirectional Encoder Representations from Transformers) for identifying sarcasm. We have used the approaches to build the model, to identify and categorize how much conversion context or response is needed for sarcasm detection and evaluated on the two social media forums that is twitter conversation dataset and reddit conversion dataset. We compare the performance based on the approaches and obtained the best F1 scores as 0.722, 0.679 for the twitter forums and reddit forums respectively.</abstract>
      <url hash="4c82ea89">2020.figlang-1.10</url>
      <doi>10.18653/v1/2020.figlang-1.10</doi>
      <video href="http://slideslive.com/38929700" />
      <bibkey>a-d-2020-sarcasm</bibkey>
    </paper>
    <paper id="11">
      <title>Neural Sarcasm Detection using Conversation Context</title>
      <author><first>Nikhil</first><last>Jaiswal</last></author>
      <pages>77&#8211;82</pages>
      <abstract>Social media platforms and discussion forums such as Reddit, Twitter, etc. are filled with figurative languages. Sarcasm is one such category of figurative language whose presence in a conversation makes language understanding a challenging task. In this paper, we present a deep neural architecture for sarcasm detection. We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset. We experiment with a variety of PLRMs either on the twitter utterance in isolation or utilizing the contextual information along with the utterance. Our findings indicate that by taking into consideration the previous three most recent utterances, the model is more accurately able to classify a conversation as being sarcastic or not. Our best performing ensemble model achieves an overall F1 score of 0.790, which ranks us second on the leaderboard of the Sarcasm Shared Task 2020.</abstract>
      <url hash="64c8a878">2020.figlang-1.11</url>
      <doi>10.18653/v1/2020.figlang-1.11</doi>
      <video href="http://slideslive.com/38929701" />
      <bibkey>jaiswal-2020-neural</bibkey>
    </paper>
    <paper id="14">
      <title>A Novel Hierarchical <fixed-case>BERT</fixed-case> Architecture for Sarcasm Detection</title>
      <author><first>Himani</first><last>Srivastava</last></author>
      <author><first>Vaibhav</first><last>Varshney</last></author>
      <author><first>Surabhi</first><last>Kumari</last></author>
      <author><first>Saurabh</first><last>Srivastava</last></author>
      <pages>93&#8211;97</pages>
      <abstract>Online discussion platforms are often flooded with opinions from users across the world on a variety of topics. Many such posts, comments, or utterances are often sarcastic in nature, i.e., the actual intent is hidden in the sentence and is different from its literal meaning, making the detection of such utterances challenging without additional context. In this paper, we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts ina hierarchical manner. We have used datasets from two online discussion platforms - Twitter and Reddit1for our experiments. Experimental and error analysis shows that the hierarchical models can make full use of history to obtain a better representation of contexts and thus, in turn, can outperform their sequential counterparts.</abstract>
      <url hash="3be522ec">2020.figlang-1.14</url>
      <doi>10.18653/v1/2020.figlang-1.14</doi>
      <video href="http://slideslive.com/38929704" />
      <bibkey>srivastava-etal-2020-novel</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>D</fixed-case>etecting <fixed-case>S</fixed-case>arcasm in <fixed-case>C</fixed-case>onversation <fixed-case>C</fixed-case>ontext <fixed-case>U</fixed-case>sing <fixed-case>T</fixed-case>ransformer-<fixed-case>B</fixed-case>ased <fixed-case>M</fixed-case>odels</title>
      <author><first>Adithya</first><last>Avvaru</last></author>
      <author><first>Sanath</first><last>Vobilisetty</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>98&#8211;103</pages>
      <abstract>Sarcasm detection, regarded as one of the sub-problems of sentiment analysis, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting sarcasm in one single sentence and there is very limited research to detect sarcasm resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without attention to detect sarcasm in conversations. We showed that the models using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current models. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the sarcasm and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</abstract>
      <url hash="f21683bd">2020.figlang-1.15</url>
      <doi>10.18653/v1/2020.figlang-1.15</doi>
      <bibkey>avvaru-etal-2020-detecting</bibkey>
    </paper>
    <paper id="16">
      <title>Using Conceptual Norms for Metaphor Detection</title>
      <author><first>Mingyu</first><last>Wan</last></author>
      <author><first>Kathleen</first><last>Ahrens</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Menghan</first><last>Jiang</last></author>
      <author><first>Qi</first><last>Su</last></author>
      <author><first>Rong</first><last>Xiang</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <pages>104&#8211;109</pages>
      <abstract>This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate in all four phases of competition with both datasets, i.e. Verbs and AllPOS on the VUA and the TOFEL datasets. We use the modality exclusivity and embodiment norms for constructing a conceptual representation of the nodes and the context. Our system obtains an F-score of 0.652 for the VUA Verbs track, which is 5% higher than the strong baselines. The experimental results across models and datasets indicate the salient contribution of using modality exclusivity and modality shift information for predicting metaphoricity.</abstract>
      <url hash="d539dd53">2020.figlang-1.16</url>
      <doi>10.18653/v1/2020.figlang-1.16</doi>
      <video href="http://slideslive.com/38929723" />
      <bibkey>wan-etal-2020-using</bibkey>
    </paper>
    <paper id="18">
      <title>Character aware models with similarity learning for metaphor detection</title>
      <author><first>Tarun</first><last>Kumar</last></author>
      <author><first>Yashvardhan</first><last>Sharma</last></author>
      <pages>116&#8211;125</pages>
      <abstract>Recent work on automatic sequential metaphor detection has involved recurrent neural networks initialized with different pre-trained word embeddings and which are sometimes combined with hand engineered features. To capture lexical and orthographic information automatically, in this paper we propose to add character based word representation. Also, to contrast the difference between literal and contextual meaning, we utilize a similarity network. We explore these components via two different architectures - a BiLSTM model and a Transformer Encoder model similar to BERT to perform metaphor identification. We participate in the Second Shared Task on Metaphor Detection on both the VUA and TOFEL datasets with the above models. The experimental results demonstrate the effectiveness of our method as it outperforms all the systems which participated in the previous shared task.</abstract>
      <url hash="50d48c2c">2020.figlang-1.18</url>
      <doi>10.18653/v1/2020.figlang-1.18</doi>
      <video href="http://slideslive.com/38929724" />
      <bibkey>kumar-sharma-2020-character</bibkey>
    </paper>
    <paper id="20">
      <title>Recognizing Euphemisms and Dysphemisms Using Sentiment Analysis</title>
      <author><first>Christian</first><last>Felt</last></author>
      <author><first>Ellen</first><last>Riloff</last></author>
      <pages>136&#8211;145</pages>
      <abstract>This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with natural language processing. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, dysphemisms refer to sensitive topics in a harsh or rude way. For example, &#8220;passed away&#8221; and &#8220;departed&#8221; are euphemisms for death, while &#8220;croaked&#8221; and &#8220;six feet under&#8221; are dysphemisms for death. Our work explores the use of sentiment analysis to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as euphemistic, dysphemistic, or neutral using lexical sentiment cues and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this task.</abstract>
      <url hash="e06ee38a">2020.figlang-1.20</url>
      <doi>10.18653/v1/2020.figlang-1.20</doi>
      <video href="http://slideslive.com/38929717" />
      <bibkey>felt-riloff-2020-recognizing</bibkey>
    </paper>
    <paper id="23">
      <title>Generating Ethnographic Models from Communities&#8217; Online Data</title>
      <author><first>Tomek</first><last>Strzalkowski</last></author>
      <author><first>Anna</first><last>Newheiser</last></author>
      <author><first>Nathan</first><last>Kemper</last></author>
      <author><first>Ning</first><last>Sa</last></author>
      <author><first>Bharvee</first><last>Acharya</last></author>
      <author><first>Gregorios</first><last>Katsios</last></author>
      <pages>165&#8211;175</pages>
      <abstract>In this paper we describe computational ethnography study to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence. Specifically, we leverage the use of figurative language (i.e., the choice of metaphors) in online text (e.g., news media, blogs) produced by distinct communities to obtain models of community worldviews that can be shown to be distinctly biased and thus different from other communities&#8217; models. We automatically construct metaphor-based community models for two distinct scenarios: gun rights and marriage equality. We then conduct a series of experiments to validate the hypothesis that the metaphors found in each community&#8217;s online language convey the bias in the community&#8217;s worldview.</abstract>
      <url hash="10dcef0a">2020.figlang-1.23</url>
      <attachment type="Software" hash="3084e139">2020.figlang-1.23.Software.zip</attachment>
      <doi>10.18653/v1/2020.figlang-1.23</doi>
      <attachment type="Dataset" hash="5d983303">2020.figlang-1.23.Dataset.pdf</attachment>
      <video href="http://slideslive.com/38929711" />
      <bibkey>strzalkowski-etal-2020-generating</bibkey>
    </paper>
    <paper id="28">
      <title>Augmenting Neural Metaphor Detection with Concreteness</title>
      <author><first>Ghadi</first><last>Alnafesah</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <pages>204&#8211;210</pages>
      <abstract>The idea that a shift in concreteness within a sentence indicates the presence of a metaphor has been around for a while. However, recent methods of detecting metaphor that have relied on deep neural models have ignored concreteness and related psycholinguistic information. We hypothesis that this information is not available to these models and that their addition will boost the performance of these models in detecting metaphor. We test this hypothesis on the Metaphor Detection Shared Task 2020 and find that the addition of concreteness information does in fact boost deep neural models. We also run tests on data from a previous shared task and show similar results.</abstract>
      <url hash="7777f0bb">2020.figlang-1.28</url>
      <doi>10.18653/v1/2020.figlang-1.28</doi>
      <bibkey>alnafesah-etal-2020-augmenting</bibkey>
    </paper>
    <paper id="33">
      <title>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</title>
      <author><first>Jennifer</first><last>Brooks</last></author>
      <author><first>Abdou</first><last>Youssef</last></author>
      <pages>244&#8211;249</pages>
      <abstract>In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms. Some of the models were trained on all parts of speech. Each of the other models was trained on one of four categories for parts of speech: &#8220;nouns&#8221;, &#8220;verbs&#8221;, &#8220;adverbs/adjectives&#8221;, or &#8220;other&#8221;. The models were combined into voting pools and the voting pools were combined using the logical &#8220;OR&#8221; operator.</abstract>
      <url hash="f68d3dff">2020.figlang-1.33</url>
      <doi>10.18653/v1/2020.figlang-1.33</doi>
      <video href="http://slideslive.com/38929728" />
      <bibkey>brooks-youssef-2020-metaphor</bibkey>
    </paper>
    <paper id="35">
      <title>Testing the role of metadata in metaphor identification</title>
      <author><first>Egon</first><last>Stemle</last></author>
      <author><first>Alexander</first><last>Onysko</last></author>
      <pages>256&#8211;263</pages>
      <abstract>This paper describes the adaptation and application of a neural network system for the automatic detection of metaphors. The LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the metadata given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this dataset. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific metadata influence the system performance in the task of automatic metaphor identification. The system is available under the APLv2 open-source license.</abstract>
      <url hash="b5fcbc81">2020.figlang-1.35</url>
      <doi>10.18653/v1/2020.figlang-1.35</doi>
      <video href="http://slideslive.com/38929730" />
      <bibkey>stemle-onysko-2020-testing</bibkey>
    </paper>
    </volume>
</collection>