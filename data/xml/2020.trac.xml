<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.trac">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</booktitle>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Atul Kr.</first><last>Ojha</last></editor>
      <editor><first>Bornini</first><last>Lahiri</last></editor>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Vanessa</first><last>Murdock</last></editor>
      <editor><first>Daniel</first><last>Kadar</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-56-6</isbn>
    </meta>
    <frontmatter>
      <url hash="2c81684d">2020.trac-1.0</url>
      <bibkey>trac-2020-trolling</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Aggression Identification in <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a> : a Transfer Learning Based Approach</title>
      <author><first>Faneva</first><last>Ramiandrisoa</last></author>
      <author><first>Josiane</first><last>Mothe</last></author>
      <pages>26–31</pages>
      <abstract>The way people communicate have changed in many ways with the outbreak of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a>. One of the aspects of <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> is the ability for their information producers to hide, fully or partially, their identity during a discussion ; leading to <a href="https://en.wikipedia.org/wiki/Cyber-aggression">cyber-aggression</a> and interpersonal aggression. Automatically monitoring <a href="https://en.wikipedia.org/wiki/User-generated_content">user-generated content</a> in order to help moderating it is thus a very hot topic. In this paper, we propose to use the transformer based language model BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) to identify aggressive content. Our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> is also used to predict the level of <a href="https://en.wikipedia.org/wiki/Aggression">aggressiveness</a>. The evaluation part of this paper is based on the <a href="https://en.wikipedia.org/wiki/Data_set">dataset</a> provided by the TRAC shared task (Kumar et al., 2018a). When compared to the other participants of this shared task, our <a href="https://en.wikipedia.org/wiki/Mathematical_model">model</a> achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.</abstract>
      <url hash="d5ce4c07">2020.trac-1.5</url>
      <language>eng</language>
      <bibkey>ramiandrisoa-mothe-2020-aggression</bibkey>
    </paper>
    <paper id="7">
      <title>A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data<fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Code-Mixed Data</title>
      <author><first>Priya</first><last>Rani</last></author>
      <author><first>Shardul</first><last>Suryawanshi</last></author>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Theodorus</first><last>Fransen</last></author>
      <author><first>John Philip</first><last>McCrae</last></author>
      <pages>42–48</pages>
      <abstract>Hate speech detection in <a href="https://en.wikipedia.org/wiki/Social_media">social media communication</a> has become one of the primary concerns to avoid conflicts and curb undesired activities. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora. In our work, we attempt to analyze, detect and provide a comparative study of <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> in a code-mixed social media text. We also provide a Hindi-English code-mixed data set consisting of Facebook and Twitter posts and comments. Our experiments show that <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning models</a> trained on this code-mixed corpus perform better.</abstract>
      <url hash="320bed95">2020.trac-1.7</url>
      <language>eng</language>
      <bibkey>rani-etal-2020-comparative</bibkey>
    </paper>
    <paper id="9">
      <title>Bagging BERT Models for Robust Aggression Identification<fixed-case>BERT</fixed-case> Models for Robust Aggression Identification</title>
      <author><first>Julian</first><last>Risch</last></author>
      <author><first>Ralf</first><last>Krestel</last></author>
      <pages>55–61</pages>
      <abstract>Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision trees</a>. While the complex models fit training data well (low bias), they also come with an unwanted high variance. Especially when fine-tuning them on small datasets, the <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> performance varies significantly for slightly different training data. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name : Julian). Our submission is the best-performing <a href="https://en.wikipedia.org/wiki/System">system</a> for five out of six subtasks. For example, we achieve a weighted F1-score of 80.3 % for task A on the test dataset of English social media posts. In our experiments, we compare different model configurations and vary the number of models used in the <a href="https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)">ensemble</a>. We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.</abstract>
      <url hash="1d277012">2020.trac-1.9</url>
      <language>eng</language>
      <bibkey>risch-krestel-2020-bagging</bibkey>
      <pwccode url="https://github.com/julian-risch/KONVENS2019_and_LREC2020" additional="false">julian-risch/KONVENS2019_and_LREC2020</pwccode>
    </paper>
    <paper id="10">
      <title>Scmhl5 at TRAC-2 Shared Task on Aggression Identification : Bert Based Ensemble Learning Approach<fixed-case>TRAC</fixed-case>-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach</title>
      <author><first>Han</first><last>Liu</last></author>
      <author><first>Pete</first><last>Burnap</last></author>
      <author><first>Wafa</first><last>Alorainy</last></author>
      <author><first>Matthew</first><last>Williams</last></author>
      <pages>62–68</pages>
      <abstract>This paper presents a system developed during our participation (team name : scmhl5) in the TRAC-2 Shared Task on aggression identification. In particular, we participated in English Sub-task A on three-class classification (‘Overtly Aggressive’, ‘Covertly Aggressive’ and ‘Non-aggressive’) and English Sub-task B on binary classification for Misogynistic Aggression (‘gendered’ or ‘non-gendered’). For both sub-tasks, our method involves using the pre-trained Bert model for extracting the text of each instance into a 768-dimensional vector of embeddings, and then training an ensemble of <a href="https://en.wikipedia.org/wiki/Statistical_classification">classifiers</a> on the embedding features. Our method obtained <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> of 0.703 and <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted F-measure</a> of 0.664 for Sub-task A, whereas for Sub-task B the <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a> was 0.869 and <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted F-measure</a> was 0.851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.</abstract>
      <url hash="0b03f293">2020.trac-1.10</url>
      <language>eng</language>
      <bibkey>liu-etal-2020-scmhl5</bibkey>
    </paper>
    <paper id="14">
      <title>Spyder : Aggression Detection on Multilingual Tweets<fixed-case>S</fixed-case>pyder: Aggression Detection on Multilingual Tweets</title>
      <author><first>Anisha</first><last>Datta</last></author>
      <author><first>Shukrity</first><last>Si</last></author>
      <author><first>Urbi</first><last>Chakraborty</last></author>
      <author><first>Sudip Kumar</first><last>Naskar</last></author>
      <pages>87–92</pages>
      <abstract>In the last few years, <a href="https://en.wikipedia.org/wiki/Hate_speech">hate speech</a> and aggressive comments have covered almost all the social media platforms like <a href="https://en.wikipedia.org/wiki/Facebook">facebook</a>, <a href="https://en.wikipedia.org/wiki/Twitter">twitter</a> etc. As a result hatred is increasing. This paper describes our (Team name : Spyder) participation in the Shared Task on <a href="https://en.wikipedia.org/wiki/Aggression">Aggression Detection</a> organised by TRAC-2, Second Workshop on <a href="https://en.wikipedia.org/wiki/Internet_troll">Trolling</a>, <a href="https://en.wikipedia.org/wiki/Aggression">Aggression</a> and <a href="https://en.wikipedia.org/wiki/Cyberbullying">Cyberbullying</a>. The Organizers provided datasets in three languages   <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>. The task was to classify each instance of the test sets into three categories   Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-Aggressive (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and <a href="https://en.wikipedia.org/wiki/Machine_learning">machine learning based classifiers</a>. We obtained <a href="https://en.wikipedia.org/wiki/F-number">f1 score</a> of 43.10 %, 59.45 % and 44.84 % respectively for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a> and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>.<b>Team name:</b>
        <b>Spyder</b>) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages – English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories – “Overtly Aggressive” (OAG), “Covertly Aggressive” (CAG) and “Non-Aggressive” (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract>
      <url hash="f0f94f08">2020.trac-1.14</url>
      <language>eng</language>
      <bibkey>datta-etal-2020-spyder</bibkey>
    <title_es>Spyder: detección de agresiones en tuits multilingües</title_es>
      <title_ar>سبايدر: كشف العدوان على التغريدات متعددة اللغات</title_ar>
      <title_fr>Spyder : détection de l'agressivité sur les tweets multilingues</title_fr>
      <title_pt>Spyder: detecção de agressão em tweets multilíngues</title_pt>
      <title_ja>Spyder:多言語ツイートでの侵略検知</title_ja>
      <title_zh>Spyder:多言推文之攻击性检</title_zh>
      <title_hi>स्पाइडर: बहुभाषी Tweets पर आक्रामकता का पता लगाना</title_hi>
      <title_ru>Spyder: Обнаружение агрессии в многоязычных твитах</title_ru>
      <title_ga>Spyder: Brath Ionsaithe ar Tweetanna Ilteangacha</title_ga>
      <title_ka>Spyder: მრავალენგური Tweets- ში Aggression Detection</title_ka>
      <title_el>Ανίχνευση επιθετικότητας σε πολυγλωσσικά tweets</title_el>
      <title_hu>Spyder: Aggresszió észlelése többnyelvű tweeteken</title_hu>
      <title_mk>Спајдер: Детектирање на агресија на мултијазични твитови</title_mk>
      <title_ms>Spyder: Pengesanan Aggresi pada Tweet Berbahasa</title_ms>
      <title_it>Spyder: Rilevamento di aggressività sui tweet multilingui</title_it>
      <title_mt>Spyder: Sejbien ta’ Aggressjoni fuq Tweets Multilingwi</title_mt>
      <title_kk>Спидер: Көптілікті Tweets- тегінде сәйкестік анықтау</title_kk>
      <title_no>Spyder: Aggressingsoppdaging på fleirspråk tweeter</title_no>
      <title_pl>Spyder: Wykrywanie agresji na wielojęzycznych tweetach</title_pl>
      <title_lt>Spyder: Aggresijos nustatymas daugiakalbėse Tweetėse</title_lt>
      <title_sr>Spyder: Detekcija agresije na višejezičkim tweetima</title_sr>
      <title_si>ස්පායිඩර්: ගොඩක් භාෂාවක් ට්විට්ස් වල සංවේදනය හොයාගන්න</title_si>
      <title_so>Spyder: Gariirka heshiiska ee luqadaha badan Tweet</title_so>
      <title_ml>സ്പൈഡര്‍: അഗ്രാഗ്രേഷന്‍ ഡിറ്റീറ്റീഷന്‍ പല ഭാഷകളുടെ ടൂട്ടുകള്‍</title_ml>
      <title_sv>Spyder: Upptäckt av aggression på flerspråkiga tweets</title_sv>
      <title_mn>Спидер: Ихэнх хэл tweets дээр асуудлын тодорхойлолт</title_mn>
      <title_ur>اسپیڈر: Multilingual Tweets پر Aggression Detection</title_ur>
      <title_ro>Spyder: Detectarea agresiunii pe tweeturile multilingve</title_ro>
      <title_ta>Spyder: Aggression Detection on Multilingual Tweets</title_ta>
      <title_uz>Spyder: Tashkilot aniqlashni bir necha tillar foydalanish</title_uz>
      <title_vi>Gián điệp: Phát hiện xung kích trên Tweet ngôn ngữ</title_vi>
      <title_hr>Spyder: Detekcija agresije na višejezičkim Tweets</title_hr>
      <title_nl>Spyder: Aggressiedetectie op meertalige tweets</title_nl>
      <title_bg>Спайдър: Откриване на агресия при многоезични туитове</title_bg>
      <title_da>Spyder: Påvisning af aggression på flersprogede tweets</title_da>
      <title_fa>اسپایدر: شناسایی افزایش روی Tweets Multilingual</title_fa>
      <title_de>Spyder: Aggressionserkennung auf mehrsprachigen Tweets</title_de>
      <title_tr>Süpler: Çoklu dilli Tweets üzerinde küçümsel tanınması</title_tr>
      <title_id>Spyder: Aggression Detection on Multilingual Tweets</title_id>
      <title_ko>Spyder: 다국어 트위터의 공격 탐지</title_ko>
      <title_sw>Spyder: Kutambuliwa kwa Makubaliano kwa Twita za lugha nyingi</title_sw>
      <title_hy>Սպիդեր. Ագրեսիայի հայտնաբերումը բազմալեզու թվիթերի վրա</title_hy>
      <title_af>Spyder: Aggresiebeskrywing op Multilingual Tweets</title_af>
      <title_az>Spyder: Çoxlu Dil Tövetlərində Agresiya Keşfeti</title_az>
      <title_bn>Spyder: Aggression Detection on Multilingual Tweets</title_bn>
      <title_sq>Spyder: Detektimi i agresionit në Tweets shumëgjuhës</title_sq>
      <title_am>Spyder: Aggression Detection Multilingual Tweets</title_am>
      <title_ca>Spyder: Detection of Aggression on Multilingual Tweets</title_ca>
      <title_cs>Spyder: Detekce agrese na vícejazyčných tweetech</title_cs>
      <title_fi>Spyder: aggression tunnistus monikielisissä twieteissä</title_fi>
      <title_et>Spyder: Agressiooni tuvastamine mitmekeelsetes tweetides</title_et>
      <title_bs>Spyder: Detekcija agresije na višejezičkim tweetima</title_bs>
      <title_jv>Spanish</title_jv>
      <title_sk>Spyder: Zaznavanje agresije na večjezičnih Tweets</title_sk>
      <title_ha>Phonon:: MMF:: EffectFactory</title_ha>
      <title_he>ספיידר: גילוי התקף על טוויטים רבים שפותיים</title_he>
      <title_bo>སྒྲུང་ཐེངས་: སྐད་རིགས་གྱི་Tweets ཐོག་ཏུ་འཕགས་རིས་བསམ་བྱུང་།</title_bo>
      <abstract_ar>في السنوات القليلة الماضية ، غطى خطاب الكراهية والتعليقات العدوانية جميع منصات التواصل الاجتماعي تقريبًا مثل facebook و twitter وما إلى ذلك. ونتيجة لذلك ، تتزايد الكراهية. تصف هذه الورقة مشاركتنا (اسم الفريق: سبايدر) في المهمة المشتركة حول اكتشاف العدوان التي نظمتها TRAC-2 ، ورشة العمل الثانية حول التصيد والعدوان والتسلط عبر الإنترنت. قدم المنظمون مجموعات بيانات بثلاث لغات - الإنجليزية والهندية والبنغالية. كانت المهمة هي تصنيف كل حالة من مجموعات الاختبار إلى ثلاث فئات - "عدواني بشكل علني" (OAG) ، و "عدواني بشكل سري" (CAG) و "غير عدواني" (NAG). في هذه الورقة ، نقترح ثلاثة نماذج مختلفة باستخدام المصنفات القائمة على Tf-Idf وقطبية المشاعر والتعلم الآلي. حصلنا على درجة f1 بنسبة 43.10٪ و 59.45٪ و 44.84٪ على التوالي للغة الإنجليزية والهندية والبنغالية.</abstract_ar>
      <abstract_pt>Nos últimos anos, discursos de ódio e comentários agressivos cobriram quase todas as plataformas de mídia social como facebook, twitter etc. Como resultado, o ódio está aumentando. Este artigo descreve nossa participação (nome da equipe: Spyder) na Tarefa Compartilhada de Detecção de Agressão organizada pelo TRAC-2, Segundo Workshop sobre Trolling, Agressão e Cyberbullying. Os organizadores forneceram conjuntos de dados em três idiomas – inglês, hindi e bengali. A tarefa foi classificar cada instância dos conjuntos de testes em três categorias – “Abertamente Agressivo” (OAG), “Cobertamente Agressivo” (CAG) e “Não Agressivo” (NAG). Neste artigo, propomos três modelos diferentes usando Tf-Idf, polaridade de sentimento e classificadores baseados em aprendizado de máquina. Obtivemos pontuação f1 de 43,10%, 59,45% e 44,84% respectivamente para inglês, hindi e bengali.</abstract_pt>
      <abstract_es>En los últimos años, el discurso de odio y los comentarios agresivos han cubierto casi todas las plataformas de medios sociales como Facebook, Twitter, etc. Como resultado, el odio está aumentando. Este artículo describe nuestra participación (Nombre del equipo: Spyder) en la tarea compartida sobre detección de agresión organizada por TRAC-2, Segundo taller sobre trolling, agresión y ciberacoso. Los organizadores proporcionaron conjuntos de datos en tres idiomas: inglés, hindi y bengalí. La tarea consistía en clasificar cada instancia de los conjuntos de pruebas en tres categorías: «Agresiva manifiesta» (OAG), «Agresiva encubierta» (CAG) y «No agresiva» (NAG). En este artículo, proponemos tres modelos diferentes que utilizan clasificadores basados en Tf-Idf, polaridad de sentimiento y aprendizaje automático. Obtuvimos una puntuación f1 del 43,10%, 59,45% y 44,84% respectivamente para inglés, hindi y bengalí.</abstract_es>
      <abstract_fr>Au cours des dernières années, les discours haineux et les commentaires agressifs ont couvert presque toutes les plateformes de médias sociaux comme Facebook, Twitter, etc. Cet article décrit notre participation (nom de l'équipe : Spyder) à la tâche partagée sur la détection de l'agression organisée par TRAC-2, Second Workshop on Trolling, Agressivité and Cyberbullying. Les organisateurs ont fourni des ensembles de données en trois langues : anglais, hindi et bengali. La tâche consistait à classer chaque instance des ensembles de tests en trois catégories : « ouvertement agressif » (OAG), « secrètement agressif » (CAG) et « non agressif » (NAG). Dans cet article, nous proposons trois modèles différents utilisant Tf-Idf, la polarité des sentiments et des classificateurs basés sur l'apprentissage automatique. Nous avons obtenu un score f1 de 43,10 %, 59,45 % et 44,84 % respectivement pour l'anglais, l'hindi et le bengali.</abstract_fr>
      <abstract_zh>在昔数年,仇言攻击性论几覆社交媒体台,如Facebook,Twitter等。 仇方增。 本文引我(团队名:Spyder)与TRAC-2侵检之共同任务,再拖钓侵网络之研讨会。 组织者给三语数集 - 英语,印地语孟加拉语。 分试集为例为三 - "公攻击性"(OAG),"隐攻击性"(CAG)"非攻击性"(NAG)。 本文中,发用Tf-Idf,情极性与机器学分类器三者不同。 英语、印地语、孟加拉语f1得分为43.10%、59.45%、44.84%。</abstract_zh>
      <abstract_hi>पिछले कुछ वर्षों में, हेट स्पीच और आक्रामक टिप्पणियों ने फेसबुक, ट्विटर आदि जैसे लगभग सभी सोशल मीडिया प्लेटफार्मों को कवर किया है। नतीजतन नफरत बढ़ती जा रही है। यह पेपर TRAC-2, Trolling, आक्रामकता और Cyberbullying पर दूसरी कार्यशाला द्वारा आयोजित आक्रामकता का पता लगाने पर साझा कार्य में हमारी (टीम का नाम: Spyder) भागीदारी का वर्णन करता है। आयोजकों ने तीन भाषाओं - अंग्रेजी, हिंदी और बंगाली में डेटासेट प्रदान किए। कार्य परीक्षण सेट के प्रत्येक उदाहरण को तीन श्रेणियों में वर्गीकृत करना था - "अत्यधिक आक्रामक" (ओएजी), "गुप्त रूप से आक्रामक" (सीएजी) और "गैर-आक्रामक" (एनएजी)। इस पेपर में, हम Tf-Idf, भावना ध्रुवीयता और मशीन लर्निंग आधारित क्लासिफायरका उपयोग करके तीन अलग-अलग मॉडलों का प्रस्ताव करते हैं। हमने अंग्रेजी, हिंदी और बंगाली के लिए क्रमशः 43.10%, 59.45% और 44.84% का f1 स्कोर प्राप्त किया।</abstract_hi>
      <abstract_ru>За последние несколько лет ненавистнические высказывания и агрессивные комментарии охватили почти все социальные медиа-платформы, такие как facebook, Twitter и т. д. В результате ненависть усиливается. В этом документе описывается наше участие (название команды: Spyder) в Совместной задаче по обнаружению агрессии, организованной TRAC-2, Второй семинар по троллингу, агрессии и кибербуллингу. Организаторы представили наборы данных на трех языках – английском, хинди и бенгальском. Задача состояла в том, чтобы классифицировать каждый экземпляр тестовых наборов по трем категориям – «открыто агрессивные» (ОАГ), «скрыто агрессивные» (КАГ) и «неагрессивные» (НАГ). В этой статье мы предлагаем три различные модели с использованием Tf-Idf, полярности настроений и классификаторов на основе машинного обучения. Мы получили оценку f1 43,10%, 59,45% и 44,84% соответственно для английского, хинди и бенгальского языка.</abstract_ru>
      <abstract_ja>ここ数年、ヘイトスピーチや攻撃的なコメントは、facebook、twitterなどのソーシャルメディアプラットフォームのほぼすべてをカバーしています。そのため、憎悪が高まっている。この論文では、TRAC -2、トロール、アグレッション、ネットいじめに関する第2回ワークショップが主催する「侵略検出に関する共有タスク」への（チーム名： Spyder ）の参加について説明します。主催者は、英語、ヒンディー語、ベンガル語の3つの言語でデータセットを提供しました。このタスクは、テストセットの各インスタンスを、「露骨に攻撃的」（ OAG ）、「秘密裏に攻撃的」（ CAG ）、および「非攻撃的」（ NAG ）の3つのカテゴリに分類することでした。本稿では、Tf - Idf、センチメント極性、機械学習ベースの分類子を用いた3つの異なるモデルを提案する。英語、ヒンディー語、ベンガル語でそれぞれ43.10%、59.45%、44.84%のf 1スコアを得た。</abstract_ja>
      <abstract_ga>Le blianta beaga anuas, clúdaíodh fuathchaint agus tráchtaireacht ionsaitheach ar bheagnach gach ardán meán sóisialta ar nós facebook, twitter etc. Mar thoradh air sin tá an fuath ag méadú. Déanann an páipéar seo cur síos ar ár rannpháirtíocht (Ainm Foirne: Spyder) sa Tasc Comhroinnte ar Bhrath Ionsaitheach arna eagrú ag TRAC-2, an Dara Ceardlann ar Throláil, Ionsaí agus Cibearbhulaíocht. Chuir na hEagraithe tacair shonraí ar fáil i dtrí theanga – Béarla, Hiondúis agus Beangáilis. Ba é an tasc a bhí ann ná gach cás de na tacair tástála a rangú i dtrí chatagóir – “Go hOllmhargach Ionsaitheach” (OAG), “Covertly Ionsaitheach” (CAG) agus “Neamh- Ionsaitheach” (NAG). Sa pháipéar seo, molaimid trí mhúnla éagsúla a úsáideann Tf-Idf, polaraíocht meon agus aicmitheoirí atá bunaithe ar mheaisín-fhoghlaim. Fuaireamar scór f1 de 43.10%, 59.45% agus 44.84% faoi seach do Bhéarla, Hiondúis agus Beangáilis.</abstract_ga>
      <abstract_hu>Az elmúlt néhány évben a gyűlöletbeszéd és az agresszív megjegyzések szinte minden közösségi média platformra kiterjedtek, mint a facebook, a twitter stb. Ennek eredményeképpen növekszik a gyűlölet. Ez a tanulmány bemutatja (Csapatnév: Spyder) részvételünket a TRAC-2 által szervezett, a Trolling, Agresszió és Cyberbullying második workshopján. A Szervezők három nyelven – angol, hindi és bengáli nyelven – biztosítottak adatkészleteket. A feladat az volt, hogy a vizsgálati készletek minden egyes példányát három kategóriába sorolják: "Túlzottan agresszív" (OAG), "Túlzottan agresszív" (CAG) és "Nem agresszív" (NAG). Ebben a tanulmányban három különböző modellt javasolunk Tf-Idf, sentiment polarity és gépi tanulás alapú osztályozókat használva. Az angol, hindi és bengáli f1 pontszám 43,10%, 59,45%, illetve 44,84%.</abstract_hu>
      <abstract_el>Τα τελευταία χρόνια, η ρητορική μίσους και τα επιθετικά σχόλια έχουν καλύψει σχεδόν όλες τις πλατφόρμες κοινωνικής δικτύωσης όπως κλπ. Ως αποτέλεσμα το μίσος αυξάνεται. Η παρούσα εργασία περιγράφει τη συμμετοχή μας (όνομα ομάδας: κατάσκοπος) στην Κοινή Εργασία για την Ανίχνευση Επιπτώσεων που διοργανώθηκε από το Δεύτερο Εργαστήριο για το Τρόλινγκ, την Επίθεση και τον Κυβερνοβουλισμό. Οι διοργανωτές παρείχαν σύνολα δεδομένων σε τρεις γλώσσες: Αγγλικά, Χίντι και Βεγγαλικά. Το καθήκον ήταν να ταξινομηθεί κάθε περίπτωση των συνόλων δοκιμών σε τρεις κατηγορίες: "Υπερβολικά επιθετική" (OAG), "Κρυμμένα επιθετική" (CAG) και "Μη επιθετική" (NAG). Στην παρούσα εργασία, προτείνουμε τρία διαφορετικά μοντέλα χρησιμοποιώντας ταξινομητές που βασίζονται σε πολικότητα συναισθημάτων και μηχανική μάθηση. Πήραμε βαθμολογία f1 43.10%, 59.45% και 44.84% αντίστοιχα για τα Αγγλικά, τα Χίντι και τα Βεγγαλικά.</abstract_el>
      <abstract_it>Negli ultimi anni, discorsi d'odio e commenti aggressivi hanno coperto quasi tutte le piattaforme di social media come facebook, twitter ecc. Di conseguenza l'odio è in aumento. Questo articolo descrive la nostra partecipazione (Team name: Spyder) al Compito Condiviso sulla Rilevazione dell'Aggressione organizzato da TRAC-2, Secondo Workshop su Trolling, Aggressione e Cyberbullismo. Gli organizzatori hanno fornito set di dati in tre lingue - inglese, hindi e bengalese. Il compito era quello di classificare ogni istanza dei set di test in tre categorie - "Overtly Aggressive" (OAG), "Coverly Aggressive" (CAG) e "Non Aggressive" (NAG). In questo articolo, proponiamo tre diversi modelli che utilizzano Tf-Idf, polarità sentimentale e classificazione basata sull'apprendimento automatico. Abbiamo ottenuto il punteggio f1 del 43,10%, 59,45% e 44,84% rispettivamente per inglese, hindi e bengalese.</abstract_it>
      <abstract_kk>Соңғы бірнеше жылда сөйлесу және агрессивні түсініктемелер жалғастырып, Facebook, twitter және т.б. секілді жалғастырып жатыр. Бұл қағаз TRAC-2, Trolling, Aggression және Cyberbullying бойынша екінші жұмыс шоғырында ортақ тапсырмаға қатынасызды (Топ атауы: Spyder) қатынасызды таңдайды. Организаторлар үш тілде деректер қорларын - ағылшын, хинди және бенгали тілде берді. Тапсырма тексеру баптауларының әрбір инстанциясын үш санатына - 'Үлкен сұрақтық' (OAG), 'Мұқаралық сұрақтық' (CAG) және 'Сұрақтық емес' (NAG) классификациялауы болды. Бұл қағазда Tf-Idf, сезімдік поляриялық және машинаның оқыту классификаторын қолданатын үш түрлі үлгі моделдерді таңдаймыз. Біз f1 нөмірі 43,10%, 59,45% және 44,84% ағылшын, хинди және бенгали үшін алдық.</abstract_kk>
      <abstract_mk>In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing.  Овој весник го опишува нашето учество (името на тимот: Шпијдер) во заедничката задача за детекција на агресија организирана од TRAC-2, вториот работилник за тролинг, агресија и киберболитирање. Организаторите обезбедија податоци на три јазици - англиски, хинди и бенгали. Задачата беше да се класификува секоја инстанција од тестовите во три категории - „Премногу агресивно“ (OAG), „Сокриено агресивно“ (CAG) и „Неагресивно“ (NAG). Во овој весник предложуваме три различни модели кои користат Тф-Идф, поларитет на чувствата и класификатори базирани на машинско учење. Добивме оценка f1 од 43,10 отсто, 59,45 отсто и 44,84 отсто за англиски, хинди и бенгали.</abstract_mk>
      <abstract_ka>ოჲჟლვენთრვ ნწკჲლკჲ დჲეთნთ, მპაჱნთ დჲგჲპთ თ ადპვჟთგნთ კჲმვნრპთ ჟვ ჲბკპთგარ ოჲფრთ გჟთფკთ ჟჲუთალნთ მვეთწ ოლარტჲპმართ, კარჲ ტვიჟბსკ, რგთრვპ ეს დოკუნტი აღწერს ჩვენი (Team name: Spyder) დანაწილეობა საზოგადოებული დავალებაში TRAC-2, მეორე სამუშაო სამუშაო Trolling, Aggression და Cyberbullying-ზე. Organizers provided datasets in three languages - English, Hindi and Bengali. პარამეტრები იყო, რომ ტესტის სამი კატეგორიაში ყოველ ინსტანსის კლასიფიკაცია - 'ძალიან ადგრესიური' (OAG), 'სამხოლოდ ადგრესიური' (CAG) და 'არა ადგრესიური' (NAG). ამ დოკუნეში ჩვენ სამი განსხვავებული მოდელის გამოყენება Tf-Idf, სენტიმენტის პოლარიტი და მაქინის სწავლების კლასიფიკაციების გამოყენება. ჩვენ მივიღეთ f1 წერტილი 43,10%, 59,45% და 44,84% ანგლისურად, ჰინდი და ბენდალისთვის.</abstract_ka>
      <abstract_lt>Per pastaruosius kelerius metus neapykantos kalba ir agresyvios pastabos apimo beveik visas socialinės žiniasklaidos platformas, pvz., Facebook, Twitter ir t. t. Dėl to didėja neapykanta. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  Organizatoriai pateikė duomenų rinkinius trimis kalbomis - anglų, hindų ir bengalų kalbomis. Kiekvienas bandymų rinkinio atvejis buvo klasifikuojamas į tris kategorijas - "pernelyg agresyvus" (OAG), "apskritai agresyvus" (CAG) ir "nesuagresyvus" (NAG). Šiame dokumente siūlome tris skirtingus modelius, naudojančius Tf-Idf, jausmų poliarumą ir mašinų mokymosi klasifikatorius. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract_lt>
      <abstract_ms>Dalam beberapa tahun terakhir, ucapan kebencian dan komentar agresif telah menutupi hampir semua platform media sosial seperti facebook, twitter dan sebagainya kebencian meningkat. Kertas ini menggambarkan (nama pasukan: Spyder) participasi kami dalam Tugas Berkongsi untuk pengesan Aggresi yang dirancang oleh TRAC-2, Workshop Kedua tentang Trolling, Aggression dan Cyberbullying. Pengurus menyediakan set data dalam tiga bahasa - Bahasa Inggeris, Hindi dan Bengali. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  Dalam kertas ini, kami cadangkan tiga model yang berbeza menggunakan Tf-Idf, polariti perasaan dan klasifikasi pembelajaran mesin. Kami mendapat skor f1 43.10%, 59.45% dan 44.84% respectively untuk bahasa Inggeris, Hindi dan Bengali.</abstract_ms>
      <abstract_ml>കഴിഞ്ഞ കുറച്ചു വര്‍ഷങ്ങളില്‍, വെറുപ്പുകളും അക്രമമായ വാക്കുകളും മുഴുവന്‍ സാമൂഹ്യ മീഡിയ പ്ലാറ്റ്ഫോമുകളും മൂടിയിട്ടുണ്ട്. ഫെസ ഈ പത്രത്തില്‍ ഞങ്ങളുടെ (ടീം പേര്: സ്പൈഡര്‍) പങ്കെടുത്ത ജോലിയില്‍ പങ്കുചേര്‍ക്കുന്നു സംഘടനക്കാര്‍ മൂന്നു ഭാഷകളില്‍ ഡാറ്റാസറ്റുകള്‍ നല്‍കിയിരിക്കുന്നു. ഇംഗ്ലീഷ്, ഹിന്ദി, ബെങ്കാ പരീക്ഷണ സജ്ജീകരണങ്ങളുടെ ഓരോ അവസ്ഥ മൂന്നു വിഭാഗങ്ങളായി - 'മുഴുവന്‍ അഗ്രാഗ്രാസ്റ്റീവ്' (OAG), 'കോപ്റ്റ്ലി Aggressive' (CAG) അല്ലാത്ത വിഭാഗങ്ങള്‍' ( ഈ പത്രത്തില്‍ ടിഫ്-ഐഡിഫിനെ ഉപയോഗിക്കുന്ന മൂന്നു വ്യത്യസ്ത മോഡലുകള്‍ ഞങ്ങള്‍ നിര്‍ദ്ദേശിക്കുന്നു. വിചാരപൂര്‍ണ്ണമ We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract_ml>
      <abstract_mt>Fl-a ħħar ftit snin, id-diskors tal-mibegħda u l-kummenti aggressivi koprew kważi l-pjattaformi kollha tal-midja soċjali bħall-facebook, it-twitter eċċ. B’riżultat ta’ dan il-mibegħda qed tiżdied. Dan id-dokument jiddeskrivi l-parteċipazzjoni tagħna (Isem it-Tim: Spyder) fil-Kompitu Konġunt dwar id-Detezzjoni tal-Aggressjoni organizzat mit-TRAC-2, it-Tieni Workshop dwar it-Trolling, l-Aggressjoni u ċ-Ċiberbullying. L-Organizzaturi pprovdew settijiet ta’ dejta fi tliet lingwi - l-Ingliż, l-Indjan u l-Bengali. Il-kompitu kien li kull każ tas-settijiet tat-testijiet jiġi kklassifikat fi tliet kategoriji - 'Aggressivi żżejjed' (OAG), 'Aggressivi b'mod Kopert' (CAG) u 'Mhux Aggressivi' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  Kisbu punteġġ f1 ta’ 43.10%, 59.45% u 44.84% rispettivament għall-Ingliż, l-Indjan u l-Bengali.</abstract_mt>
      <abstract_pl>W ciągu ostatnich kilku lat mowa nienawiści i agresywne komentarze obejmowały prawie wszystkie platformy mediów społecznościowych, takie jak facebook, twitter itp. W rezultacie nienawiść wzrasta. Niniejszy artykuł opisuje nasz (nazwa zespołu: Spyder) udział w wspólnym zadaniu wykrywania agresji organizowanym przez TRAC-2, Drugie warsztaty na temat trollingu, agresji i cyberprzemocy. Organizatorzy dostarczyli zbiory danych w trzech językach: angielskim, hindi i bengalskim. Zadaniem było podzielenie każdej instancji zestawów testowych na trzy kategorie: nadmiernie agresywne (OAG), "tajne agresywne" (CAG) i "nieagresywne" (NAG). W niniejszym artykule proponujemy trzy różne modele wykorzystujące klasyfikatory Tf-Idf, polaryzację sentymentów oraz klasyfikatory oparte na uczeniu maszynowym. Uzyskaliśmy wynik f1 43,10%, 59,45% i 44,84% odpowiednio dla angielskiego, hindi i bengalskiego.</abstract_pl>
      <abstract_ro>În ultimii ani, discursul de ură și comentariile agresive au acoperit aproape toate platformele de social media precum facebook, twitter etc. Ca urmare ura este în creștere. Această lucrare descrie participarea noastră (numele echipei: Spyder) la activitatea comună privind detectarea agresiunii organizată de TRAC-2, al doilea atelier privind trolling, agresiune și cyberbullying. Organizatorii au furnizat seturi de date în trei limbi - engleză, hindi și bengală. Sarcina a fost de a clasifica fiecare instanță a seturilor de teste în trei categorii - "excesiv agresiv" (OAG), "excesiv agresiv" (CAG) și "non-agresiv" (NAG). În această lucrare, propunem trei modele diferite folosind Tf-Idf, polaritatea sentimentului și clasificarea bazată pe machine learning. Am obținut scorul f1 de 43,10%, 59,45% și respectiv 44,84% pentru engleză, hindi și bengali.</abstract_ro>
      <abstract_si>අන්තිම අවුරුදු කීපයක් වලින්, වෛර කරනවා කියලා සමාජික මධ්‍යමාධ්‍යම ප්‍රවෘත්තියක් වගේ ප්‍රවෘත්තියක් වගේ පැත මේ පැත්තේ අපේ සම්බන්ධ නාමය (කණ්ඩායම්: ස්පායිඩර්) සම්බන්ධ වැඩක් තියෙනවා TRAC-2, දෙවෙනි වැඩකරුව ට්‍රෝලින්, සායිබර්බුලින් වල සංයෝජනකරුවන් දත්ත සැට් තුනක් භාෂාවට දුන්නා - ඉංග්‍රීසි, හින්දි සහ බෙන්ගාලි. වැඩය තමයි පරීක්ෂණා සැකසුම් හැම සැකසුම් තුනක් වලට පරීක්ෂණය කරගන්න - 'වැඩියෙන් වැඩියි' (OAG), 'කවර්ට්ලි වැඩියි' (CAG) සහ 'වැඩියෙන්  මේ පැත්තට, අපි Tf-Idb භාවිතා වෙනස් මොඩේල් තුනක් ප්‍රයෝජනය කරන්න ප්‍රයෝජනය කරනවා, දැනුම් ප්‍රයෝජනය සහ ම අපිට අංග්‍රීසි, හින්දි සහ බෙන්ගාලි වලට f1 ප්‍රමාණයක් ලැබුනා.</abstract_si>
      <abstract_mn>Өнгөрсөн хэдэн жилийн дотор үзэн ядах яриа, хүчирхийллэг сэтгэл зүйл нь facebook, twitter гэх мэт бүх нийгмийн медиа платформуудыг харуулж байна. Үүний үр дүнд үзэн ядах нь нэмэгддэг. Энэ цаас бидний (Баг нэр: Спидер) TRAC-2, Тролинг, Агресс, Цибербулингийн хоёр дахь ажиллагааны тухай хуваалцах ажилд оролцож байна. Организагчид гурван хэл дээр өгөгдлийн сангууд - Англи, Хинди, Бенгали. Үүний шалгалтын давхар бүрийг 3 категорид хэлбэрээр хэлбэртэй (OAG), 'Мөн хэлбэртэй' (CAG) болон 'Мөн хэлбэргүй' (NAG) хэлбэрээр ангилах байсан. Энэ цаасан дээр бид Tf-Idf, сэтгэл хөдлөл, машины сургалтын үндсэн хэлбэрүүдийг ашиглан гурван өөр загварыг санал болгож байна. Бид f1 оноо 43,10%, 59,45% болон 44,84% Англи, Хинди болон Бенгали хүмүүст авсан.</abstract_mn>
      <abstract_sr>U poslednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organizovanom TRAC-2, drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio da klasifikišemo svaku instancu testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore osnovane na mašinama. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</abstract_sr>
      <abstract_so>Sannadihii ugu dambeeyey, hadalka nacayb iyo commentarada kibirka ah waxay ku qariyeen jardiinada shabakadda bulshada oo dhan sida facebook, twitter etc. sababtoo darteed nacaybku waa sii kordhayaa. Qoraalkan waxaa ku qoran (Team name: Spyder) qayb ka dhigista shaqada la sharciyey Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. Waxay qabanqaabiyaan macluumaadyo ku qoran saddex luuqadood - Ingiriis, Hindi iyo Bengali. Shaqada waxaa lagu qoray inuu u kala sooco caymis kasta oo imtixaanka lagu sameeyo saddex categor - 'Overall Aggressive' (OAG), 'Covertly Aggressive' (CAG) iyo 'Non-Aggressive' (NAG). Qoraalkan waxaan ku soo jeedaynaa saddex tusaale oo kala duduwan oo isticmaalaya Tf-Idf, qasabka fikrada iyo waxbarashada machine-ka. Af Ingiriis, Hindi iyo Bengali ayaannu helnay boqolkiiba f1 boqolkiiba 43.10, 59.45 % iyo 44.84 boqolkiiba.</abstract_so>
      <abstract_sv>Under de senaste åren har hatpropaganda och aggressiva kommentarer täckt nästan alla sociala medieplattformar som facebook, twitter etc. Som ett resultat av detta ökar hatet. Denna uppsats beskriver vårt (Team name: Spyder) deltagande i Shared Task on Aggression Detection organiserad av TRAC-2, Andra Workshop om Trolling, Aggression och Cybermobbning. Arrangörerna tillhandahöll datauppsättningar på tre språk - engelska, hindi och bengaliska. Uppgiften var att klassificera varje instans av testuppsättningarna i tre kategorier - "Övergripande" (OAG), "Coverly Aggressive" (CAG) och "Non-Aggressive" (NAG). I denna uppsats föreslår vi tre olika modeller med hjälp av Tf-Idf, sentimentpolaritet och maskininlärningsbaserade klassificerare. Vi fick f1 poäng på 43,10%, 59,45% respektive 44,84% för engelska, hindi och bengali.</abstract_sv>
      <abstract_ur>پچھلے چند سال میں، ناپسند بات اور سختی کی کمانٹیاں تقریباً تمام سوسیل میڈیا پٹرومٹیاں جیسے facebook, twitter اور اگلوں پر پورے ہوئے ہیں. نتیجہ میں نفرت بڑھتی ہے. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. سازمان کرنے والوں نے تین زبانوں میں ڈاٹ سٹ دی - انگلیسی, ہندی اور بنگالی۔ اس کا کام یہ تھا کہ ہر امتحان سٹ کو تین کاٹیوں میں تقسیم کریں - 'زیادہ گریز' (OAG), 'Covertly Aggressive' (CAG) اور 'Non-Aggressive' (NAG)۔ اس کاغذ میں ہم Tf-Idf کے استعمال سے تین مختلف موڈل پیشنهاد کرتے ہیں، احساسات آلودگی اور ماشین سیکھنے کی بنیادی کلاسیٹر کے استعمال سے۔ ہم نے 43.10%, 59.45% اور 44.84% انگلیسی, ہندی اور بنگالی کے لئے f1 سکوٹ پائی۔</abstract_ur>
      <abstract_no>I dei siste få år har hatt tale og aggressiv kommentarar dekka nesten alle sosiale mediaplattformene som facebook, twitter osv. Som resultatet er hatt økt. Denne papiret beskriver vårt (gruppenamn: Spyder) deltakast i delt oppgåve om Aggressingsoppdaging organisert av TRAC-2, andre arbeidsområde på Trolling, Aggressing og Cyberbullying. Organisatorene oppgav datasett i tre språk – engelsk, hindisk og Bengalisk. Oppgåva var å klassifisera kvar instans av testsettet inn i tre kategoriar – overAggresiv (OAG), 'Covertly Aggressive' (CAG) og 'Non-Aggressive' (NAG). I denne papiret foreslår vi tre ulike modeller med Tf-Idf, sentiment-polaritet og maskinelæring basert klassifiserar. Vi har f1 poeng med 43,10%, 59,45% og 44,84% for engelsk, hindisk og bengalisk.</abstract_no>
      <abstract_ta>கடந்த சில ஆண்டுகளில், வெறுப்பு பேச்சு மற்றும் அக்கிரமமான கருத்துக்கள் கிட்டத்தட்ட அனைத்து சமூக ஊடக முறைமைகளை மூடியிருக்கிறத இந்த காகிதத்தில் எங்கள் (குழு பெயர்: ஸ்பைட்டர்) TRAC- 2 ஆல் நிறுவப்பட்ட வேலையில் பங்கிடப்பட்டுள்ளது என்ற பணியில் பகிர்ந்து கொள்ளப்படுகிறது, ட்ரால் நிறுவனர்கள் மூன்று மொழிகளில் தகவல் அமைப்பு சோதனை அமைப்புகளின் ஒவ்வொரு நிகழ்வும் மூன்று வகுப்புகளாக வகுப்படுத்த வேண்டும் 'மேலும் Aggressive' (OAG), 'Covertly Aggressive' (CAG) மற்றும் 'Aggressive' (NAG). இந்த காகிதத்தில், Tf-Idf, உணர்வு தீவிரம் மற்றும் இயந்திரம் வகுப்பாளர் நாங்கள் ஆங்கிலத்து, ஹின்டி மற்றும் பெங்காலிக்கு நிதியாக 43.10%, 59.45% மற்றும் 44.84% கிடைத்தோம்.</abstract_ta>
      <abstract_vi>Trong những năm gần đây, lời nói căm ghét và những bình luận tích cực đã bao trùm hầu hết các nền tảng truyền thông xã hội như facebook, twitter, v.v. Kết quả là sự căm ghét đang tăng dần. Tờ giấy này mô tả sự tham gia của chúng ta (tên của nhóm: Spyder) vào "Việc Điều tra tấn công" được chia sẻ được tổ chức bởi TRAC-2, Thứ nhì "Xưởng làm việc" về tội phạm, rối loạn và nạn nhân ảo. Các tổ chức cung cấp dữ liệu bằng ba ngôn ngữ: Anh, Hindi và Bengali. Nhiệm vụ là phân loại mỗi trường hợp của các thử nghiệm thành ba loại "Tổng tấn công" khủng khiếp (OAS nhận nhận dạng A.G). và "không hung hãn" (NAG). Trong tờ giấy này, chúng tôi đề xuất ba mẫu khác nhau sử dụng các phân loại cảm xúc và các phân loại máy móc. Chúng tôi có kết quả F1 số lượng của 43.10=, 59.45=. và 44.84=. for English, Hindi và Bengali.</abstract_vi>
      <abstract_uz>Keyingi necha yil ichida, kuch aytish va aggressiv izohlar faqat facebook, twitter etc. kabi hamma jamiyat medya platformlarini qaraydi. natijada hat ko'prodi. Бу саҳифа бизнинг (Team номи: Spyder) TRAC-2, Тўғрилик, Китоб ва Кипробляция Қуйидаги ўзгартириш вазифасига шерик бўлишимизни айтиб беради. Dasturlar uch tillarda maʼlumotlar tarkibini ingliz, Hindi va Bengalcha tilida yaratadi. Name Bu qogʻozda, biz Tf-Idf, hissiyot polariyat va mashinalar asosida o'rganishga uchta boshqa modellarni rivojlanamiz. Biz ingliz, Hindi va Bengalchaga har xizmat 43.10%, 59.45% va 44.84% foizdan foydalandik.</abstract_uz>
      <abstract_bg>През последните няколко години речта на омразата и агресивните коментари обхванаха почти всички социални медийни платформи като В резултат на това омразата нараства. Настоящата статия описва нашето (име на екипа: Спайдър) участие в споделената задача за откриване на агресия, организирана от Втора работна среща по тролинг, агресия и кибертормоз. Организаторите предоставиха набори от данни на три езика - английски, хинди и бенгалски. Задачата беше да се класифицират всеки пример от тестовите групи в три категории - "прекалено агресивен" (OAG), "скрит агресивен" (CAG) и "неагресивен" (NAG). В настоящата статия предлагаме три различни модела, използващи класификатори, базирани на сентиментална полярност и машинно обучение. Получихме резултат от 43,10%, 59,45% и 44,84% съответно за английски, хинди и бенгалски.</abstract_bg>
      <abstract_hr>U posljednjih nekoliko godina, govor mržnje i agresivni komentari pokrivali su skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše sudjelovanje (Tim name: Spyder) u zajedničkom zadatku o detectivu agresije organiziranom TRAC-2, Drugi radnički rad o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svake primjere testova u tri kategorije - pretjerano agresivne (OAG), 'Prikriveno agresivne' (CAG) i 'ne agresivne' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost osjećaja i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</abstract_hr>
      <abstract_da>I løbet af de sidste par år har had tale og aggressive kommentarer dækket næsten alle sociale medier platforme som facebook, twitter osv. Som følge heraf er hadet voksende. Denne artikel beskriver vores (Team name: Spyder) deltagelse i Delt Opgave om Aggression Detection organiseret af TRAC-2, Anden Workshop om Trolling, Aggression og Cybermobbing. Arrangørerne leverede datasæt på tre sprog - engelsk, hindi og bengali. Opgaven var at klassificere hver enkelt forekomst af testsættene i tre kategorier - "Over Aggressive" (OAG), "Coverly Aggressive" (CAG) og "Non-Aggressive" (NAG). I denne artikel foreslår vi tre forskellige modeller ved hjælp af Tf-Idf, sentiment polarity og machine learning baserede klassificeringer. Vi fik f1 score på 43,10%, 59,45% og 44,84% for henholdsvis engelsk, hindi og bengali.</abstract_da>
      <abstract_de>In den letzten Jahren haben Hassrede und aggressive Kommentare fast alle Social-Media-Plattformen wie Facebook, Twitter etc. abgedeckt, wodurch Hass zunimmt. Dieses Papier beschreibt unsere (Teamname: Spyder) Teilnahme an der von TRAC-2 organisierten Shared Task on Aggression Detection, Second Workshop on Trolling, Aggression and Cybermobbing. Die Organisatoren stellten Datensätze in drei Sprachen zur Verfügung: Englisch, Hindi und Bengali. Die Aufgabe bestand darin, jede Instanz der Testsätze in drei Kategorien zu klassifizieren: Overtly Aggressive (OAG), "Covertly Aggressive" (CAG) und "Non-Aggressive" (NAG). In diesem Beitrag schlagen wir drei verschiedene Modelle vor, die Tf-Idf, Sentiment Polarity und Machine Learning basierte Klassifikatoren verwenden. Für Englisch, Hindi und Bengali erreichten wir f1 Score von 43,10%, 59,45% und 44,84% .</abstract_de>
      <abstract_nl>In de afgelopen jaren hebben hate speech en agressieve reacties bijna alle sociale media platforms zoals facebook, twitter etc. bestraald waardoor haat toeneemt. Dit artikel beschrijft onze (Teamnaam: Spyder) deelname aan de Shared Task on Aggression Detection georganiseerd door TRAC-2, Tweede Workshop over Trolling, Aggressie en Cyberpesten. De Organisatoren leverden datasets in drie talen: Engels, Hindi en Bengaals. De taak was om elke instantie van de testsets te classificeren in drie categorieën: Overtly Aggressive (OAG), 'Covertly Aggressive' (CAG) en 'Non-Aggressive' (NAG). In dit artikel stellen we drie verschillende modellen voor met behulp van Tf-Idf, sentimentpolariteit en machine learning gebaseerde classificatoren. We behaalden f1 score van respectievelijk 43,10%, 59,45% en 44,84% voor Engels, Hindi en Bengaals.</abstract_nl>
      <abstract_fa>در چند سال گذشته، از سخنرانی متنفر و توضیح‌های تجاوز تقریباً تمام platformهای رسانه‌های اجتماعی مانند facebook, twitter و غیر از آن پوشیده شده است. به نتیجه نفرت افزایش می‌یابد. این کاغذ (نام تیم: Spyder) مشارکت ما را توصیف می‌کند در کار مشترک در مورد بازرسی گروهی که توسط TRAC-2 سازمان شده است، کارگاه دوم در مورد ترولینگ، گروهی و سایبر بولینگ است. Organizers provided data sets in three languages - English, Hindi and Bengali. وظیفه این بود که هر نمونه از مجموعه‌های آزمایش را در سه گروه کلاس کنیم - 'زیادی گریز' (OAG), 'قابل گریز' (CAG) و 'ناگریز' (NAG). در این کاغذ، ما سه مدل متفاوتی را با استفاده از Tf-Idf پیشنهاد می کنیم، قطعیت احساسات و دستگاه یادگیری بر اساس مختلف راهنمایی. ما درصد f1 از 43.10%, 59.45% و 44.84% به عنوان انگلیسی, هندی و بنگالی دریافت کردیم.</abstract_fa>
      <abstract_sw>Katika miaka michache iliyopita, hotuba ya chuki na maoni ya kibaguzi yamekuwa yakitangaza karibu majukwaa ya mitandao ya kijamii kama vile Facebook, twita etc. Matokeo yake yanaongezeka chuki. Gazeti hili linaelezea (jina la timu: Spyder) kushiriki katika kazi ya kushirikiana kwenye Utafiti wa Makubaliano ulioandaliwa na TRAC-2, Warsha ya pili kuhusu Uvunjifu, Matukio na Mtandao. Waandaaji walitoa taarifa kwa lugha tatu - Kiingereza, Kihindi na Bengali. Kazi hiyo ilikuwa ni kuwadhibiti kila aina ya jaribio hilo linatengeneza katika makundi matatu - 'Kwa ujumla Aggressive' (OAG), 'Maandamano makubwa' (CAG) na 'Sio Aggressive' (NAG). Katika karatasi hii, tunapendekeza mifano mitatu tofauti kwa kutumia Tf-Idf, unyanyasaji wa hisia na kujifunza mashine yenye msingi. Tumepata vipindi vya f1 kwa asilimia 43.10, 59.45% na 44.84 kwa ajili ya Kiingereza, Hindi na Bengali.</abstract_sw>
      <abstract_ko>지난 몇 년 동안 페이스북, 트위터 등 모든 소셜미디어 플랫폼에 원한 발언과 공격적인 댓글이 덮여 있어 원한이 증가하고 있다.본고는 우리(팀명: Spyder)가TRAC-2조직의 공격검측공유임무에 참여하고 제2기 제어, 공격과 인터넷 괴롭힘에 관한 세미나를 묘사한다.조직자는 영어, 인디언, 방글라데시어 세 가지 언어의 데이터 집합을 제공했다.임무는 테스트 집합의 각 실례를'공개공격'(OAG),'은폐공격'(CAG),'비공격'(NAG) 세 종류로 나누는 것이다.본고에서 우리는 Tf-Idf, 감정의 극성과 기계 학습을 바탕으로 하는 분류기를 이용하여 세 가지 다른 모델을 제시했다.우리의 f1영어, 인디언, 방글라데시어 성적은 각각 43.10%, 59.45%와 44.84% 였다.</abstract_ko>
      <abstract_tr>Soňky ýylda ýigrenýän çykyş we agresýji terjimeler diňe facebook, twitter we şeýle ýaly sosyal medialaryň platformlaryny üýtgedýär. netijeli ýigrenýän bolsa. Bu kagyz biziň (topar adymyzy: Spyder) TRAC-2, Ilkinji Trollin, Aggresiýa we Cyberbulliýa tarapyndan çykyşymyzyň (topar ady: Spyder) bölegimizi barlaýar. Gurganlar üç dilde maglumat setirini – Iňlisçe, Hindi we Bengali ýa dilde temin etdiler. Bu hat üç kategoriýa içine synanyşan her sahypany bejerilmek üçin. - 'Üzgün Aggresiýan' (OAG), 'Covertly Aggressive' (CAG) we 'Non-Aggressive' (NAG). Bu kagyzda Tf-Idf, duýgular polaritet we maşynyň öwrenmegi tabanly klassiflerden üç dürli nusgalary teklip edýäris. Biz f1 sany 43,10%, 59,45% we 44,84% iňlisçe, Hindiler we Bengaliler üçin aldyk.</abstract_tr>
      <abstract_am>ባለፉት ጥቂት ዓመታት፣ ጥላቻን ንግግር እና ተቃውሞ አካባቢ ማኅበራዊ ሚዲያ ጦማሪያዎች እንደ ፊትቡክ፣ twitter እና ድምፅ ይጨምራሉ፡፡ This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  አጋራጆች በሦስት ቋንቋ - እንግሊዘኛ፣ ሄንዲ እና በንጋሊ ዳታተርቶችን ሰጥተዋል፡፡ ስራው ሁሉንም ምሳሌዎች በሦስት categories - 'አብዛኛውን Aggressive' (OAG), 'Covertly Aggressive' (CAG) እና 'nonAggressive' (NAG). በዚህ ካላት፣ Tf-Idf፣ የስሜት ፖርቲካ እና የመኪና ትምህርት መተማር የተለየ ሦስት የተለየ ዓይነቶች እና መደበቂያ እናደርጋለን፡፡ በእንግሊዝኛ፣ Hindi እና በጋንጋል ላይ የፊዲ ቁጥር 43.10 በመቶ፥ 59.45 በመቶ እና 44.84 በመቶ አግኝተናል።</abstract_am>
      <abstract_af>In die laaste paar jaar het haat spraak en aggressiewe kommentaar amper al die sosiale media platforme soos facebook, twitter ensfh. As 'n resultaat haat vergroei word. Hierdie papier beskrywe ons (Team name: Spyder) deelnadering in die Gedeelde Opdrag oor Aggresiedeteksie organiseer deur TRAC-2, tweede Werkshop op Trolling, Aggresie en Cyberbullying. Die Organiseerders het datastelle in drie tale verskaf - Engels, Hindi en Bengali. Die taak was om elke voorbeeld van die toets stel in drie kategorie te klassifiseer - 'Oorskynlik Aggressief' (OAG), 'Omdek Aggressive' (CAG) en 'Non- Aggressive' (NAG). In hierdie papier voorstel ons drie verskillende modele met gebruik van Tf-Idf, sentiment polariteit en masjien leer gebaseerde klassifiseerders. Ons het f1 telling van 43,10%, 59,45% en 44,84% respectively vir Engels, Hindi en Bengali ontvang.</abstract_af>
      <abstract_sq>Në vitet e fundit, fjalimi i urrejtjes dhe komentet agresive kanë mbuluar pothuajse të gjitha platformet e medias sociale si facebook, twitter etj. Si rezultat i urrejtjes po rritet. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  Organizuesit ofruan të dhëna në tre gjuhë - anglisht, hindisht dhe bengalisht. Detyra ishte të klasifikohej çdo rast i grupeve të testit në tre kategori - 'Shumë Aggresive' (OAG), 'Covertely Aggressive' (CAG) dhe 'Non-Aggressive' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract_sq>
      <abstract_hy>Վերջին մի քանի տարիների ընթացքում ատելության խոսքը և ագրեսիվ մեկնաբանությունները ծածկել են գրեթե բոլոր սոցիալական լրատվամիջոցների պլատֆորմերը, ինչպիսիք են Ֆեյսբուքը, թվիթերը և այլն, ինչի արդյունքում ատելություն Այս հոդվածը նկարագրում է մեր (Թիմի անունը՝ Սպիդեր) մասնակցությունը Ագրեսիայի հայտնագործման ընդհանուր խնդրի մեջ, որը կազմակերպել է ԹրաԿ-2, Թրոլինգի, Ագրեսիայի և Կիբերբուլիգի երկրորդ աշխատասենյակում: The Organizers provided datasets in three languages - English, Hindi and Bengali.  Հարտադրությունն էր դասակարգել փորձարկումների յուրաքանչյուր օրինակ երեք կատեգորիաների՝ չափազանց ագրեսիվ, թաքնված ագրեսիվ և ոչ ագրեսիվ: Այս թղթի մեջ մենք առաջարկում ենք երեք տարբեր մոդել, որոնք օգտագործում են Tf-IDf-ը, զգացմունքների մոտավորությունը և մեքենային ուսումնասիրության հիմնված դասակարգերը: Մենք ստացանք 43.10 տոկոսը, 59.45 տոկոսը և 44.84 տոկոսը անգլերենի, հինդի և բենգալիի համար:</abstract_hy>
      <abstract_bn>গত কয়েক বছরে ঘৃণা ভাষণ এবং অত্যাচারী মন্তব্য প্রায় সকল সামাজিক প্রচার মাধ্যমের প্লাটফর্ম ফেসবুক, টুইটার ইত্যাদি প্রকাশ করেছে, যার ফলে  এই পত্রিকাটি আমাদের (দলের নাম: স্পাইডার) অংশগ্রহণের অংশগ্রহণ করেছে ট্রাক্লিং এবং সাইবার্বালিং এর দ্বিতীয় ওয়ার্কশপের আয়োজন করেছে। সংগঠনগুলো তিনটি ভাষায় তথ্য সংগ্রহ করেছে- ইংরেজি, হিন্দি এবং বাংলায়। The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  এই কাগজটিতে আমরা টিএফ-আইডফ, আবেগের দূর্নীতি এবং মেশিন ভিত্তিক শিক্ষা ব্যবহার করে তিনটি ভিন্ন মডেল প্রস্তাব করি। আমরা ইংরেজি, হিন্দি এবং বাংলার জন্য ৪৪.</abstract_bn>
      <abstract_ca>En els últims anys, el discurs d'odi i els comentaris agressius han cobert gairebé totes les plataformes dels mitjans socials com Facebook, Twitter, etc. Com a resultat, l'odi està creixent. Aquest article descriu la nostra participació (Nom de l'equip: Spyder) en la Task Shared on Aggression Detection organitzada per TRAC-2, Segona Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages - English, Hindi and Bengali.  The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  En aquest paper, proposem tres models diferents utilitzant Tf-Idf, polaritat sentimental i classificadors basats en l'aprenentatge màquina. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract_ca>
      <abstract_az>Son bir neçə il içində nifrət sözləri və agresif şəhadətlər facebook, twitter və ya da bənzər sosyal media platformlarını bürüdülər. Sonuçta nifrət artırır. Bu kağıt TRAC-2, Trolling, Aggresyon və Cyberbullying ilə organizasyon edilmiş Aggresyon Detection işimizin paylaşılmış işimizi təsdiqləyir. Organizerlər üç dildə verilən qurğular – İngilizce, Hindi və Bengali. Gözəl hər bir sınama quruluğunu üç kategoriya ilə dəyişdirmək idi: 'Çox Agressive' (OAG), 'Cover Aggressive' (CAG) və 'Non-Aggressive' (NAG). Bu kağızda Tf-Idf, sentiment polaritāti və maşın öyrənməsi tabanlı klasifikatçıları ilə üç fərqli modeli təklif edirik. Biz f1 nöqtəsini 43,10%, 59,45% və 44,84% İngilizce, Hindi və Bengali üçün aldıq.</abstract_az>
      <abstract_cs>V posledních několika letech se nenávistná řeč a agresivní komentáře pokryly téměř všechny platformy sociálních médií jako Facebook, Twitter atd. V důsledku toho se nenávist zvyšuje. Tento článek popisuje naši (název týmu: Spyder) účast na Sdíleném úkolu detekce agrese organizovaném TRAC-2, Druhém workshopu o trollingu, agresi a kyberšikaně. Organizátoři poskytli datové sady ve třech jazycích: angličtině, hindštině a bengálštině. Úkolem bylo rozdělit každou instanci testovacích sad do tří kategorií: příliš agresivní (OAG), utajené agresivní (CAG) a neagresivní (NAG). V tomto článku navrhujeme tři různé modely používající Tf-Idf, polaritu sentimentu a klasifikátory založené na strojovém učení. Získali jsme f1 skóre 43,10%, 59,45% a 44,84% pro angličtinu, hindštinu a bengálštinu.</abstract_cs>
      <abstract_bs>U posljednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme socijalnih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organiziranom TRAC-2, Drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svakog instanca testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</abstract_bs>
      <abstract_et>Viimastel aastatel on vihakõne ja agressiivsed kommentaarid hõlmanud peaaegu kõiki sotsiaalmeedia platvorme nagu facebook, twitter jne, mille tulemusena vihkamine kasvab. Käesolevas dokumendis kirjeldatakse meie (meeskonna nimi: Spyder) osalemist TRAC-2 poolt korraldatud agressiooni tuvastamise jagatud ülesandes, mis käsitleb trollingut, agressiooni ja küberkiusamist. Korraldajad esitasid andmekogumeid kolmes keeles - inglise, hindi ja bengali keeles. Ülesanne oli klassifitseerida iga katsekogumi eksemplar kolme kategooriasse - "ülemääraselt agressiivne" (OAG), "varjatult agressiivne" (CAG) ja "mitteagressiivne" (NAG). Käesolevas töös pakume välja kolm erinevat mudelit, mis kasutavad Tf-Idf, sentimentaalse polaarsuse ja masinõppe alusel põhinevaid klassifitseerijaid. Inglise, hindi ja bengali puhul saime f1 skoori 43,10%, 59,45% ja 44,84%.</abstract_et>
      <abstract_fi>Viime vuosina vihapuhe ja aggressiiviset kommentit ovat kattaneet lähes kaikki sosiaalisen median alustat, kuten Facebook, Twitter jne. Tämän seurauksena viha kasvaa. Tässä artikkelissa kuvataan (Team name: Spyder) osallistumistamme TRAC-2:n järjestämään aggression havaitsemista koskevaan yhteiseen tehtävään, joka on toinen Trolling-, Aggression- ja Cyberbullying-työpaja. Järjestäjät toimittivat aineistoja kolmella kielellä - englanti, hindi ja bengali. Tehtävänä oli luokitella testisarjat kolmeen luokkaan: "Yliaggressiivinen" (OAG), "Salaaggressiivinen" (CAG) ja "Ei aggressiivinen" (NAG). Tässä työssä ehdotamme kolmea eri mallia käyttäen Tf-Idf-, sentiment polarity- ja koneoppimispohjaisia luokittelijoita. Englannin, hindin ja bengalin f1-pisteet olivat 43,10%, 59,45% ja 44,84%.</abstract_fi>
      <abstract_id>In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing.  This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying.  The Organizers provided datasets in three languages - English, Hindi and Bengali.  The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  Dalam kertas ini, kami mengusulkan tiga model yang berbeda menggunakan Tf-Idf, polaritas sentimen dan klasifikasi berbasis pembelajaran mesin. Kami mendapat skor f1 43,10%, 59,45% dan 44,84% respectively untuk Inggris, Hindi dan Bengali.</abstract_id>
      <abstract_ha>Daga ƙidãyayyuta kaɗan, hoton ƙiyayya da mawaƙi sun rufe kowace platforms na mitanda na jamii kamar facebook, Twitter etc. Saboda haka, ƙiyayya ta ƙara. Wannan karatun yana bayyana mana (Team name: SPAYer) shirin ya zama a cikin aikin Shared on Aggression Dictionary organized by TRac-2, Shirin Sauq na Tõrlling, Aggression and cyberbullbullbullbullbullbulling. Shirin Ayuka na bãyar da data set cikin harshe uku - Ingiriya, Hindcha da Bangali. Kayan aikin ya zama mai rarraba ko wani halin na jarraba ta cikin nau'i uku - 'Totally Aggressive' (OAG), "Deptly Aggressive' (CAG) da 'Non-Aggressive' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers.  Mun sãmi f1 score na 43.10%, 59.45% da 44.84% na Ingiriya, Hinddi da Bangali.</abstract_ha>
      <abstract_sk>V zadnjih nekaj letih so sovražni govor in agresivni komentarji pokrivali skoraj vse platforme socialnih medijev, kot so facebook, twitter itd., zaradi česar sovraštvo narašča. Ta prispevek opisuje naše sodelovanje (ime ekipe: Spyder) v skupni nalogi za odkrivanje agresije, ki jo organizira TRAC-2, Druga delavnica o trollingu, agresiji in kibernetskem ustrahovanju. Organizatorji so zagotovili nabore podatkov v treh jezikih - angleščini, hindijščini in bengalščini. Naloga je bila razvrstiti vsak primer preskusnih nizov v tri kategorije - "preveč agresivni" (OAG), "skriti agresivni" (CAG) in "neagressivni" (NAG). V prispevku predlagamo tri različne modele, ki uporabljajo klasifikatorje Tf-Idf, sentimentalno polarnost in strojno učenje. Za angleščino, hindijščino in bengalščino smo dobili oceno f1 43,10%, 59,45% oziroma 44,84%.</abstract_sk>
      <abstract_jv>Nang acara sing ditambah dumadhi, cah-cah dumadhi lan komentar sing gak bener tentang karo hal-hal sing mengko kuwi padha kaé sistem media soti kowé karo netwisu, tuwitir, njl. sebelah kuwi mau kudu dunyane kuwi mau. Perintah iki dadi ono nggawe (Group name: spyrer) sumusunoi tanggal nggawe Tarjamahan kelas nggawe barang nggawe barang TROC-2, Second Workspace nang Trill, agegress lan Ciberbullying. Organiser politenessoffpolite"), and when there is a change ("assertivepoliteness Nang paper iki, kéné supoyo model sing sampeyan telu model sing gambar tf-Idf, polarity seneng karo sistem sing basa sak kelas. Awak dhéwé luwih tangané f1 puntuan sing katênêr, denganêr, limang-limang kanggo kalah-aman kanggo inggiles, barang-arang karo Bengal.</abstract_jv>
      <abstract_bo>འདས་བའི་ལོ་ངོ་ཤས་ཀྱི་རིང་ལ་་་ ཕྱིར་ཉེན་དགའ་ཕྱོགས་དང་བསྡུར་བའི་མཆན་བཤད་ཀྱི་གྲོས་ཁྱེར་གྱི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དུ་ ཤོག་བྱང་འདིས་ང་ཚོའི་མཉམ་དུ་སྤྱི་ཚོགས་ཀྱི་མིང་། སྒྲིག་འཛུགས་པ་ཚོས་སྐད་རིགས་གསུམ་ནང་གི་གནད་སྡུད་གཞི་སྒྲིག་ཚོགས་གཅིག་གི་ནང་བྱིན་ཡོད། The task was to classify each instance of the test sets in three categories - 'Overly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་སྔོན་པ་ལ་མ་དབྱེ་བ་གསུམ་རྣམས་སྤྱོད་ཀྱི་ཐབས་ལམ་མ་འདུག Tf-Idf་དང་། སེམས་ཚོར ངེད་ཚོ་སྤྱི་ཚོགས་ཀྱི་ཨང་ཀི43.10%, 59.45% དང་། སྤྱི་ཚོགས་ཀྱི་ཨང་ཀིས་ཡིག་ཆ་གཅིག་ཙམ་གྱི་འབོར་ཡོད།</abstract_bo>
      <abstract_he>בשנים האחרונות, נאום שנאה והתגובות אגרסיביות כיסו כמעט את כל המתקנות של התקשורת החברתית כמו פייסבוק, טוויטר וכו"כ. כתוצאה מכך שנאה גדלה. העיתון הזה מתאר את השתתפות שלנו (שם צוות: ספיידר) במשימה המשותפת על גילוי התקפה מאורגנת על ידי TRAC-2, Workshop שני על טרולינג, התקפה וקייברבולינג. המארגנים סיפקו קבוצות נתונים בשלושה שפות - אנגלית, הינדית ובנגלית. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG).  בעיתון הזה, אנו מציעים שלושה דוגמנים שונים בשימוש ב-Tf-Idf, קוטביות רגשות ולמדות מכונות מסודרים. השגנו נקודת f1 של 43.10%, 59.45% ו-44.84% בהתאם לאנגלית, הינדית ובנגלית.</abstract_he>
      </paper>
    <paper id="15">
      <title>BERT of all trades, master of some<fixed-case>BERT</fixed-case> of all trades, master of some</title>
      <author><first>Denis</first><last>Gordeev</last></author>
      <author><first>Olga</first><last>Lykova</last></author>
      <pages>93–98</pages>
      <abstract>This paper describes our results for TRAC 2020 competition held together with the conference LREC 2020. Our team name was Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants’ task was to classify aggression in short texts from <a href="https://en.wikipedia.org/wiki/Social_media">social media</a> and decide whether it is gendered or not. We used a single BERT-based system with two outputs for all tasks simultaneously. Our <a href="https://en.wikipedia.org/wiki/Conceptual_model">model</a> placed first in <a href="https://en.wikipedia.org/wiki/English_language">English</a> and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.</abstract>
      <url hash="b26cb56f">2020.trac-1.15</url>
      <language>eng</language>
      <bibkey>gordeev-lykova-2020-bert</bibkey>
    </paper>
    <paper id="17">
      <title>FlorUniTo@TRAC-2 : Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection<fixed-case>F</fixed-case>lor<fixed-case>U</fixed-case>ni<fixed-case>T</fixed-case>o@<fixed-case>TRAC</fixed-case>-2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection</title>
      <author><first>Anna</first><last>Koufakou</last></author>
      <author><first>Valerio</first><last>Basile</last></author>
      <author><first>Viviana</first><last>Patti</last></author>
      <pages>106–112</pages>
      <abstract>This paper describes our participation to the TRAC-2 Shared Tasks on Aggression Identification. Our team, FlorUniTo, investigated the applicability of using an abusive lexicon to enhance word embeddings towards improving detection of aggressive language. The embeddings used in our paper are word-aligned pre-trained vectors for <a href="https://en.wikipedia.org/wiki/English_language">English</a>, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>, to reflect the languages in the shared task data sets. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations. Overall, our <a href="https://en.wikipedia.org/wiki/System">systems</a> placed toward the middle of the <a href="https://en.wikipedia.org/wiki/List_of_Formula_One_World_Drivers’_Champions">official rankings</a> based on <a href="https://en.wikipedia.org/wiki/Weighted_arithmetic_mean">weighted F1 score</a>. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.</abstract>
      <url hash="f34a5fa1">2020.trac-1.17</url>
      <language>eng</language>
      <bibkey>koufakou-etal-2020-florunito</bibkey>
    </paper>
    <paper id="19">
      <title>Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020<fixed-case>TRAC</fixed-case> 2020</title>
      <author><first>Sudhanshu</first><last>Mishra</last></author>
      <author><first>Shivangi</first><last>Prasad</last></author>
      <author><first>Shubhanshu</first><last>Mishra</last></author>
      <pages>120–125</pages>
      <abstract>We present our team ‘3Idiots’ (referred as ‘sdhanshu’ in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks. Our approach relies on fine-tuning various Transformer models on the different <a href="https://en.wikipedia.org/wiki/Data_set">datasets</a>. We also investigated the utility of task label marginalization, joint label classification, and joint training on multilingual datasets as possible improvements to our models. Our team came second in English sub-task A, a close fourth in the English sub-task B and third in the remaining 4 sub-tasks. We find the multilingual joint training approach to be the best trade-off between computational efficiency of model deployment and <a href="https://en.wikipedia.org/wiki/Statistical_model">model</a>’s evaluation performance. We open source our approach at https://github.com/socialmediaie/TRAC2020.</abstract>
      <url hash="2eb1175e">2020.trac-1.19</url>
      <language>eng</language>
      <bibkey>mishra-etal-2020-multilingual</bibkey>
      <pwccode url="https://github.com/socialmediaie/TRAC2020" additional="false">socialmediaie/TRAC2020</pwccode>
    </paper>
    <paper id="20">
      <title>Aggression and Misogyny Detection using <a href="https://en.wikipedia.org/wiki/BERT">BERT</a> : A Multi-Task Approach<fixed-case>BERT</fixed-case>: A Multi-Task Approach</title>
      <author><first>Niloofar</first><last>Safi Samghabadi</last></author>
      <author><first>Parth</first><last>Patwa</last></author>
      <author><first>Srinivas</first><last>PYKL</last></author>
      <author><first>Prerana</first><last>Mukherjee</last></author>
      <author><first>Amitava</first><last>Das</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>126–131</pages>
      <abstract>In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection. This paper presents our system for TRAC-2 shared task on Aggression Identification (sub-task A) and Misogynistic Aggression Identification (sub-task B). The data for this shared <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> is provided in three different languages-English, <a href="https://en.wikipedia.org/wiki/Hindi">Hindi</a>, and <a href="https://en.wikipedia.org/wiki/Bengali_language">Bengali</a>. Each data instance is annotated into one of the three aggression classes-Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes-Gendered and Non-Gendered. We propose an end-to-end neural model using <a href="https://en.wikipedia.org/wiki/Attention">attention</a> on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously. Our team, na14, scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task. The code and the model weights are publicly available at https://github.com/NiloofarSafi/TRAC-2. Keywords : <a href="https://en.wikipedia.org/wiki/Aggression">Aggression</a>, <a href="https://en.wikipedia.org/wiki/Misogyny">Misogyny</a>, <a href="https://en.wikipedia.org/wiki/Abusive_language">Abusive Language</a>, Hate-Speech Detection, BERT, <a href="https://en.wikipedia.org/wiki/Natural_language_processing">NLP</a>, <a href="https://en.wikipedia.org/wiki/Neural_network">Neural Networks</a>, <a href="https://en.wikipedia.org/wiki/Social_media">Social Media</a></abstract>
      <url hash="3063822a">2020.trac-1.20</url>
      <language>eng</language>
      <bibkey>safi-samghabadi-etal-2020-aggression</bibkey>
      <pwccode url="https://github.com/NiloofarSafi/TRAC-2" additional="false">NiloofarSafi/TRAC-2</pwccode>
    </paper>
    <paper id="24">
      <title>Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language</title>
      <author><first>Anna</first><last>Koufakou</last></author>
      <author><first>Jason</first><last>Scott</last></author>
      <pages>150–157</pages>
      <abstract>Detecting abusive language is a significant research topic, which has received a lot of attention recently. Our work focuses on detecting personal attacks in <a href="https://en.wikipedia.org/wiki/Online_chat">online conversations</a>. As previous research on this task has largely used <a href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a> based on <a href="https://en.wikipedia.org/wiki/Embedding">embeddings</a>, we explore the use of <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a> to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the <a href="https://en.wikipedia.org/wiki/Lexicon">lexicons</a>, in order to construct or to change embeddings that are ultimately fed into the learning model. The sentiment lexicon approaches focus on integrating <a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment information</a> (in the form of sentiment embeddings) into the <a href="https://en.wikipedia.org/wiki/Machine_learning">learning model</a>. The <a href="https://en.wikipedia.org/wiki/Semantic_lexicon">semantic lexicon approaches</a> focus on transforming the original <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a> so that they better represent relationships extracted from a <a href="https://en.wikipedia.org/wiki/Semantic_lexicon">semantic lexicon</a>. Based on our experimental results, semantic lexicon methods are superior to the rest of the <a href="https://en.wikipedia.org/wiki/Methodology">methods</a> in this paper, with at least 4 % macro-averaged F1 improvement over the baseline.</abstract>
      <url hash="793a0f46">2020.trac-1.24</url>
      <language>eng</language>
      <bibkey>koufakou-scott-2020-lexicon</bibkey>
    </paper>
    </volume>
</collection>