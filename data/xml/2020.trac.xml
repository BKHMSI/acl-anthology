<collection id="2020.trac">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</booktitle>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Atul Kr.</first><last>Ojha</last></editor>
      <editor><first>Bornini</first><last>Lahiri</last></editor>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Vanessa</first><last>Murdock</last></editor>
      <editor><first>Daniel</first><last>Kadar</last></editor>
      <publisher>European Language Resources Association (ELRA)</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-56-6</isbn>
    </meta>
    <frontmatter>
      <url hash="2c81684d">2020.trac-1.0</url>
      <bibkey>trac-2020-trolling</bibkey>
    </frontmatter>
    <paper id="5">
      <title>Aggression Identification in Social Media: a Transfer Learning Based Approach</title>
      <author><first>Faneva</first><last>Ramiandrisoa</last></author>
      <author><first>Josiane</first><last>Mothe</last></author>
      <pages>26&#8211;31</pages>
      <abstract>The way people communicate have changed in many ways with the outbreak of social media. One of the aspects of social media is the ability for their information producers to hide, fully or partially, their identity during a discussion; leading to cyber-aggression and interpersonal aggression. Automatically monitoring user-generated content in order to help moderating it is thus a very hot topic. In this paper, we propose to use the transformer based language model BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) to identify aggressive content. Our model is also used to predict the level of aggressiveness. The evaluation part of this paper is based on the dataset provided by the TRAC shared task (Kumar et al., 2018a). When compared to the other participants of this shared task, our model achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.</abstract>
      <url hash="d5ce4c07">2020.trac-1.5</url>
      <language>eng</language>
      <bibkey>ramiandrisoa-mothe-2020-aggression</bibkey>
    </paper>
    <paper id="7">
      <title>A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Code-Mixed Data</title>
      <author><first>Priya</first><last>Rani</last></author>
      <author><first>Shardul</first><last>Suryawanshi</last></author>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Theodorus</first><last>Fransen</last></author>
      <author><first>John Philip</first><last>McCrae</last></author>
      <pages>42&#8211;48</pages>
      <abstract>Hate speech detection in social media communication has become one of the primary concerns to avoid conflicts and curb undesired activities. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora. In our work, we attempt to analyze, detect and provide a comparative study of hate speech in a code-mixed social media text. We also provide a Hindi-English code-mixed data set consisting of Facebook and Twitter posts and comments. Our experiments show that deep learning models trained on this code-mixed corpus perform better.</abstract>
      <url hash="320bed95">2020.trac-1.7</url>
      <language>eng</language>
      <bibkey>rani-etal-2020-comparative</bibkey>
    </paper>
    <paper id="9">
      <title>Bagging <fixed-case>BERT</fixed-case> Models for Robust Aggression Identification</title>
      <author><first>Julian</first><last>Risch</last></author>
      <author><first>Ralf</first><last>Krestel</last></author>
      <pages>55&#8211;61</pages>
      <abstract>Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as decision trees. While the complex models fit training data well (low bias), they also come with an unwanted high variance. Especially when fine-tuning them on small datasets, the classification performance varies significantly for slightly different training data. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name: Julian). Our submission is the best-performing system for five out of six subtasks. For example, we achieve a weighted F1-score of 80.3% for task A on the test dataset of English social media posts. In our experiments, we compare different model configurations and vary the number of models used in the ensemble. We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.</abstract>
      <url hash="1d277012">2020.trac-1.9</url>
      <language>eng</language>
      <bibkey>risch-krestel-2020-bagging</bibkey>
      <pwccode url="https://github.com/julian-risch/KONVENS2019_and_LREC2020" additional="false">julian-risch/KONVENS2019_and_LREC2020</pwccode>
    </paper>
    <paper id="10">
      <title>Scmhl5 at <fixed-case>TRAC</fixed-case>-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach</title>
      <author><first>Han</first><last>Liu</last></author>
      <author><first>Pete</first><last>Burnap</last></author>
      <author><first>Wafa</first><last>Alorainy</last></author>
      <author><first>Matthew</first><last>Williams</last></author>
      <pages>62&#8211;68</pages>
      <abstract>This paper presents a system developed during our participation (team name: scmhl5) in the TRAC-2 Shared Task on aggression identification. In particular, we participated in English Sub-task A on three-class classification (&#8216;Overtly Aggressive&#8217;, &#8216;Covertly Aggressive&#8217; and &#8216;Non-aggressive&#8217;) and English Sub-task B on binary classification for Misogynistic Aggression (&#8216;gendered&#8217; or &#8216;non-gendered&#8217;). For both sub-tasks, our method involves using the pre-trained Bert model for extracting the text of each instance into a 768-dimensional vector of embeddings, and then training an ensemble of classifiers on the embedding features. Our method obtained accuracy of 0.703 and weighted F-measure of 0.664 for Sub-task A, whereas for Sub-task B the accuracy was 0.869 and weighted F-measure was 0.851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.</abstract>
      <url hash="0b03f293">2020.trac-1.10</url>
      <language>eng</language>
      <bibkey>liu-etal-2020-scmhl5</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>S</fixed-case>pyder: Aggression Detection on Multilingual Tweets</title>
      <author><first>Anisha</first><last>Datta</last></author>
      <author><first>Shukrity</first><last>Si</last></author>
      <author><first>Urbi</first><last>Chakraborty</last></author>
      <author><first>Sudip Kumar</first><last>Naskar</last></author>
      <pages>87&#8211;92</pages>
      <abstract>In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing. This paper describes our (<b>Team name:</b>
        <b>Spyder</b>) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages &#8211; English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories &#8211; &#8220;Overtly Aggressive&#8221; (OAG), &#8220;Covertly Aggressive&#8221; (CAG) and &#8220;Non-Aggressive&#8221; (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</abstract>
      <url hash="f0f94f08">2020.trac-1.14</url>
      <language>eng</language>
      <bibkey>datta-etal-2020-spyder</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>BERT</fixed-case> of all trades, master of some</title>
      <author><first>Denis</first><last>Gordeev</last></author>
      <author><first>Olga</first><last>Lykova</last></author>
      <pages>93&#8211;98</pages>
      <abstract>This paper describes our results for TRAC 2020 competition held together with the conference LREC 2020. Our team name was Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants&#8217; task was to classify aggression in short texts from social media and decide whether it is gendered or not. We used a single BERT-based system with two outputs for all tasks simultaneously. Our model placed first in English and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.</abstract>
      <url hash="b26cb56f">2020.trac-1.15</url>
      <language>eng</language>
      <bibkey>gordeev-lykova-2020-bert</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>F</fixed-case>lor<fixed-case>U</fixed-case>ni<fixed-case>T</fixed-case>o@<fixed-case>TRAC</fixed-case>-2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection</title>
      <author><first>Anna</first><last>Koufakou</last></author>
      <author><first>Valerio</first><last>Basile</last></author>
      <author><first>Viviana</first><last>Patti</last></author>
      <pages>106&#8211;112</pages>
      <abstract>This paper describes our participation to the TRAC-2 Shared Tasks on Aggression Identification. Our team, FlorUniTo, investigated the applicability of using an abusive lexicon to enhance word embeddings towards improving detection of aggressive language. The embeddings used in our paper are word-aligned pre-trained vectors for English, Hindi, and Bengali, to reflect the languages in the shared task data sets. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations. Overall, our systems placed toward the middle of the official rankings based on weighted F1 score. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.</abstract>
      <url hash="f34a5fa1">2020.trac-1.17</url>
      <language>eng</language>
      <bibkey>koufakou-etal-2020-florunito</bibkey>
    </paper>
    <paper id="19">
      <title>Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at <fixed-case>TRAC</fixed-case> 2020</title>
      <author><first>Sudhanshu</first><last>Mishra</last></author>
      <author><first>Shivangi</first><last>Prasad</last></author>
      <author><first>Shubhanshu</first><last>Mishra</last></author>
      <pages>120&#8211;125</pages>
      <abstract>We present our team &#8216;3Idiots&#8217; (referred as &#8216;sdhanshu&#8217; in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks. Our approach relies on fine-tuning various Transformer models on the different datasets. We also investigated the utility of task label marginalization, joint label classification, and joint training on multilingual datasets as possible improvements to our models. Our team came second in English sub-task A, a close fourth in the English sub-task B and third in the remaining 4 sub-tasks. We find the multilingual joint training approach to be the best trade-off between computational efficiency of model deployment and model&#8217;s evaluation performance. We open source our approach at https://github.com/socialmediaie/TRAC2020.</abstract>
      <url hash="2eb1175e">2020.trac-1.19</url>
      <language>eng</language>
      <bibkey>mishra-etal-2020-multilingual</bibkey>
      <pwccode url="https://github.com/socialmediaie/TRAC2020" additional="false">socialmediaie/TRAC2020</pwccode>
    </paper>
    <paper id="20">
      <title>Aggression and Misogyny Detection using <fixed-case>BERT</fixed-case>: A Multi-Task Approach</title>
      <author><first>Niloofar</first><last>Safi Samghabadi</last></author>
      <author><first>Parth</first><last>Patwa</last></author>
      <author><first>Srinivas</first><last>PYKL</last></author>
      <author><first>Prerana</first><last>Mukherjee</last></author>
      <author><first>Amitava</first><last>Das</last></author>
      <author><first>Thamar</first><last>Solorio</last></author>
      <pages>126&#8211;131</pages>
      <abstract>In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection.This paper presents our system for TRAC-2 shared task on &#8220;Aggression Identification&#8221; (sub-task A) and &#8220;Misogynistic Aggression Identification&#8221; (sub-task B). The data for this shared task is provided in three different languages - English, Hindi, and Bengali. Each data instance is annotated into one of the three aggression classes - Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes - Gendered and Non-Gendered. We propose an end-to-end neural model using attention on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously. Our team, &#8220;na14&#8221;, scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task. The code and the model weights are publicly available at https://github.com/NiloofarSafi/TRAC-2. Keywords: Aggression, Misogyny, Abusive Language, Hate-Speech Detection, BERT, NLP, Neural Networks, Social Media</abstract>
      <url hash="3063822a">2020.trac-1.20</url>
      <language>eng</language>
      <bibkey>safi-samghabadi-etal-2020-aggression</bibkey>
      <pwccode url="https://github.com/NiloofarSafi/TRAC-2" additional="false">NiloofarSafi/TRAC-2</pwccode>
    </paper>
    <paper id="24">
      <title>Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language</title>
      <author><first>Anna</first><last>Koufakou</last></author>
      <author><first>Jason</first><last>Scott</last></author>
      <pages>150&#8211;157</pages>
      <abstract>Detecting abusive language is a significant research topic, which has received a lot of attention recently. Our work focuses on detecting personal attacks in online conversations. As previous research on this task has largely used deep learning based on embeddings, we explore the use of lexicons to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the lexicons, in order to construct or to change embeddings that are ultimately fed into the learning model. The sentiment lexicon approaches focus on integrating sentiment information (in the form of sentiment embeddings) into the learning model. The semantic lexicon approaches focus on transforming the original word embeddings so that they better represent relationships extracted from a semantic lexicon. Based on our experimental results, semantic lexicon methods are superior to the rest of the methods in this paper, with at least 4% macro-averaged F1 improvement over the baseline.</abstract>
      <url hash="793a0f46">2020.trac-1.24</url>
      <language>eng</language>
      <bibkey>koufakou-scott-2020-lexicon</bibkey>
    </paper>
    </volume>
</collection>