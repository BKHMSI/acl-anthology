<?xml version='1.0' encoding='utf-8'?>
<collection id="2020.fever">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</booktitle>
      <editor><first>Christos</first><last>Christodoulopoulos</last></editor>
      <editor><first>James</first><last>Thorne</last></editor>
      <editor><first>Andreas</first><last>Vlachos</last></editor>
      <editor><first>Oana</first><last>Cocarascu</last></editor>
      <editor><first>Arpit</first><last>Mittal</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="ee435e98">2020.fever-1</url>
    </meta>
    <frontmatter>
      <url hash="c5f632b1">2020.fever-1.0</url>
      <bibkey>fever-2020-fact</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Simple Compounded-Label Training for Fact Extraction and Verification</title>
      <author><first>Yixin</first><last>Nie</last></author>
      <author><first>Lisa</first><last>Bauer</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>1–7</pages>
      <abstract>Automatic fact checking is an important task motivated by the need for detecting and preventing the spread of misinformation across the web. The recently released FEVER challenge provides a benchmark task that assesses systems’ capability for both the retrieval of required evidence and the identification of authentic claims. Previous approaches share a similar pipeline training paradigm that decomposes the <a href="https://en.wikipedia.org/wiki/Task_(project_management)">task</a> into three subtasks, with each component built and trained separately. Although achieving acceptable scores, these <a href="https://en.wikipedia.org/wiki/Method_(computer_programming)">methods</a> induce difficulty for practical application development due to <a href="https://en.wikipedia.org/wiki/Complexity">unnecessary complexity</a> and expensive computation. In this paper, we explore the potential of simplifying the system design and reducing training computation by proposing a joint training setup in which a single sequence matching model is trained with compounded labels that give supervision for both sentence selection and claim verification subtasks, eliminating the duplicate computation that occurs when models are designed and trained separately. Empirical results on FEVER indicate that our method : (1) outperforms the typical multi-task learning approach, and (2) gets comparable results to top performing systems with a much simpler training setup and less training computation (in terms of the amount of data consumed and the number of model parameters), facilitating future works on the automatic fact checking task and its practical usage.</abstract>
      <url hash="0472bb38">2020.fever-1.1</url>
      <doi>10.18653/v1/2020.fever-1.1</doi>
      <video href="http://slideslive.com/38929663" />
      <bibkey>nie-etal-2020-simple</bibkey>
    </paper>
    <paper id="5">
      <title>Language Models as Fact Checkers?</title>
      <author><first>Nayeon</first><last>Lee</last></author>
      <author><first>Belinda Z.</first><last>Li</last></author>
      <author><first>Sinong</first><last>Wang</last></author>
      <author><first>Wen-tau</first><last>Yih</last></author>
      <author><first>Hao</first><last>Ma</last></author>
      <author><first>Madian</first><last>Khabsa</last></author>
      <pages>36–41</pages>
      <abstract>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a <a href="https://en.wikipedia.org/wiki/Language_model">language model</a>, without any external knowledge or explicit retrieval components. While previous work on extracting knowledge from LMs have focused on the task of open-domain question answering, to the best of our knowledge, this is the first work to examine the use of language models as <a href="https://en.wikipedia.org/wiki/Fact-checking">fact checkers</a>. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</abstract>
      <url hash="fcff8bf1">2020.fever-1.5</url>
      <doi>10.18653/v1/2020.fever-1.5</doi>
      <video href="http://slideslive.com/38929662" />
      <bibkey>lee-etal-2020-language</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/lama">LAMA</pwcdataset>
    <title_es>¿Modelos de lenguaje como verificadores de datos?</title_es>
      <title_pt>Modelos de linguagem como verificadores de fatos?</title_pt>
      <title_ar>نماذج اللغة كمدقق للحقائق؟</title_ar>
      <title_ja>ファクトチェッカーとしての言語モデル？</title_ja>
      <title_hi>फैक्ट चेकर्स के रूप में भाषा मॉडल?</title_hi>
      <title_zh>语言模为实核查员?</title_zh>
      <title_ga>Múnlaí Teanga mar Seiceálaithe Fíricí?</title_ga>
      <title_hu>Nyelvi modellek, mint tény ellenőrzők?</title_hu>
      <title_ka>ენვგური მოდელები როგორც ფაქტის შემოწმება?</title_ka>
      <title_el>Γλωσσικά μοντέλα ως ελεγκτές γεγονότων;</title_el>
      <title_it>Modelli linguistici come controllori dei fatti?</title_it>
      <title_kk>Тіл үлгілері факт тексерушілері ретінде?</title_kk>
      <title_ml>ഭാഷ മോഡലുകള്‍ ഫാക്റ്റ് ചെക്കര്‍ എന്നാണോ?</title_ml>
      <title_lt>Kalbos modeliai kaip faktų tikrintojai?</title_lt>
      <title_mn>Холны загваруудыг Фактикийн Шекерүүд гэж үү?</title_mn>
      <title_ms>Model Bahasa sebagai Pemeriksa Fakta?</title_ms>
      <title_mk>Модели на јазик како проверки на факти?</title_mk>
      <title_mt>Mudelli lingwistiċi bħala Kontrollaturi tal-Fatti?</title_mt>
      <title_no>Språk- modeller som faktisksjekkarar?</title_no>
      <title_pl>Modele językowe jako sprawdzające fakty?</title_pl>
      <title_ro>Modele lingvistice ca verificători de fapte?</title_ro>
      <title_sr>Jezikovi modeli kao èinjenici?</title_sr>
      <title_si>භාෂාව ප්‍රමාණය ඇත්ත පරීක්ෂකයෙක් විදියට?</title_si>
      <title_so>Isticmaalka afka sida jardiinooyinka afka?</title_so>
      <title_sv>Språkmodeller som faktakontroller?</title_sv>
      <title_ta>மொழி மாதிரிகள் உண்மை சரிபார்ப்பார்களாக?</title_ta>
      <title_ur>Language Models as facts Checkers?</title_ur>
      <title_uz>Tilning modellari faqat tekshiruvchisi sifatida?</title_uz>
      <title_vi>Ngôn ngữ mẫu như Dịch vụ Checkers?</title_vi>
      <title_da>Sprogmodeller som fakta kontrollere?</title_da>
      <title_nl>Taalmodellen als fact Checkers?</title_nl>
      <title_hr>Jezički modeli kao provjeravači činjenica?</title_hr>
      <title_bg>Езикови модели като проверка на фактите?</title_bg>
      <title_de>Sprachmodelle als Fact Checker?</title_de>
      <title_ko>사실 검증원으로서의 언어 모델?</title_ko>
      <title_fa>مدل زباني به عنوان بررسي حقيقت؟</title_fa>
      <title_id>Model bahasa sebagai pemeriksa fakta?</title_id>
      <title_sw>Modeli za lugha kama Wachunguzi?</title_sw>
      <title_tr>Diller</title_tr>
      <title_af>Taal Modelle as Fact Checkers?</title_af>
      <title_sq>Modelet e gjuhës si Kontrollues të Fakteve?</title_sq>
      <title_hy>Լեզվի մոդելները՝ փաստերի վերահսկողները:</title_hy>
      <title_am>ቋንቋዎች</title_am>
      <title_az>Dil modell톛ri Fact Checkers kimi?</title_az>
      <title_bn>ভাষা মোডেল ফ্যাক্ট চেকার হিসেবে?</title_bn>
      <title_bs>Jezikovi modeli kao provjeravači činjenica?</title_bs>
      <title_ca>Models de llenguatgecom a Verificadors de Factes?</title_ca>
      <title_cs>Jazykové modely jako kontrola faktů?</title_cs>
      <title_et>Keelemudelid faktide kontrollijana?</title_et>
      <title_fi>Kielimallit faktojen tarkistamiseksi?</title_fi>
      <title_ha>@ action</title_ha>
      <title_sk>Jezikovni modeli za preverjanje dejstev?</title_sk>
      <title_bo>སྐད་ཡིག་གཟུགས་རིས་དེབ་ལྟ་ཞིབ་བྱེད་བཞིན་པ་ཡིན་ནམ</title_bo>
      <title_he>Language Models as Fact Checkers?</title_he>
      <title_jv>Language</title_jv>
      <abstract_ar>اقترح العمل الأخير أن نماذج اللغة (LMs) تخزن كل من الفطرة السليمة والمعرفة الواقعية المستفادة من بيانات ما قبل التدريب. في هذه الورقة ، نستفيد من هذه المعرفة الضمنية لإنشاء مدقق حقائق فعال شامل باستخدام نموذج لغة فقط ، دون أي معرفة خارجية أو مكونات استرجاع صريحة. بينما ركز العمل السابق على استخراج المعرفة من LMs على مهمة الإجابة على أسئلة المجال المفتوح ، على حد علمنا ، هذا هو العمل الأول لفحص استخدام نماذج اللغة كمدقق للحقائق. في إعداد الكتاب المغلق ، نظهر أن نهجنا LM ذي اللقطة الصفرية يتفوق على خط الأساس العشوائي في مهمة FEVER القياسية ، وأن LM المُحسَّن لدينا يُقارن بشكل إيجابي مع خطوط الأساس القياسية. على الرغم من أننا لا نتفوق في النهاية على الأساليب التي تستخدم قواعد المعرفة الواضحة ، إلا أننا نعتقد أن استكشافنا يوضح أن هذه الطريقة قابلة للتطبيق ولديها مجال كبير للاستكشاف.</abstract_ar>
      <abstract_pt>Trabalhos recentes sugeriram que os modelos de linguagem (LMs) armazenam tanto o senso comum quanto o conhecimento factual aprendido a partir de dados pré-treinamento. Neste artigo, aproveitamos esse conhecimento implícito para criar um verificador de fatos eficaz de ponta a ponta usando apenas um modelo de linguagem, sem nenhum conhecimento externo ou componentes de recuperação explícitos. Embora trabalhos anteriores sobre extração de conhecimento de LMs tenham se concentrado na tarefa de responder a perguntas de domínio aberto, até onde sabemos, este é o primeiro trabalho a examinar o uso de modelos de linguagem como verificadores de fatos. Em um ambiente fechado, mostramos que nossa abordagem LM de tiro zero supera uma linha de base aleatória na tarefa FEVER padrão e que nosso LM ajustado se compara favoravelmente com as linhas de base padrão. Embora, em última análise, não superemos os métodos que usam bases de conhecimento explícitas, acreditamos que nossa exploração mostra que esse método é viável e tem muito espaço para exploração.</abstract_pt>
      <abstract_es>Un trabajo reciente ha sugerido que los modelos de lenguaje (LM) almacenan tanto el conocimiento de sentido común como el conocimiento fáctico aprendido de los datos previos al entrenamiento. En este artículo, aprovechamos este conocimiento implícito para crear un verificador de hechos eficaz de principio a fin utilizando únicamente un modelo de lenguaje, sin ningún conocimiento externo ni componentes de recuperación explícitos. Mientras que el trabajo anterior sobre la extracción de conocimiento de los LM se ha centrado en la tarea de responder a preguntas de dominio abierto, hasta donde sabemos, este es el primer trabajo que examina el uso de modelos de lenguaje como verificadores de hechos. En un entorno a libro cerrado, demostramos que nuestro enfoque de LM de tiro cero supera a una línea de base aleatoria en la tarea FEVER estándar, y que nuestra LM ajustada se compara favorablemente con las líneas de base estándar. Aunque en última instancia no superamos a los métodos que utilizan bases de conocimiento explícitas, creemos que nuestra exploración demuestra que este método es viable y tiene mucho espacio para la exploración.</abstract_es>
      <abstract_ja>最近の研究では、言語モデル（ LM ）は、トレーニング前のデータから学んだ常識的知識と事実的知識の両方を保存することが示唆されている。本稿では、この暗黙の知識を活用して、外部知識や明示的な検索コンポーネントなしで、言語モデルのみを使用して効果的なエンドツーエンドのファクトチェッカーを作成する。LMから知識を抽出する以前の作業は、オープンドメインの質問に答える作業に焦点を当てていますが、私たちの知る限りでは、これはファクトチェッカーとしての言語モデルの使用を検討する最初の作業です。クローズドブックの設定では、ゼロショットLMアプローチが標準的な発熱タスクのランダムなベースラインを上回り、微調整されたLMが標準的なベースラインと比較して好ましいことが示されています。明示的な知識ベースを使用する方法を最終的には上回ることはありませんが、私たちの探求は、この方法が実行可能であり、探索の余地が大きいことを示していると信じています。</abstract_ja>
      <abstract_zh>近者研明,语言模样(LM)存储从训练前数中学到常识事实。 于本文之中,因隐式以创一效之端,检查器言语模样,而无外显式检组件。 虽前LM取知,皆集开放域问答之务,但据吾所知,此第一项治言语模形以为实核查器也。 夫封闭之书,明吾零次 LM 之法 FEVER 优于随机之基线,而吾之微调 LM 比基线更胜一筹。 虽终无越用显式知识库之术,然吾信吾探索之可也,且有大探索空间。</abstract_zh>
      <abstract_hi>हाल के काम ने सुझाव दिया है कि भाषा मॉडल (एलएम) पूर्व-प्रशिक्षण डेटा से सीखे गए सामान्य ज्ञान और तथ्यात्मक ज्ञान दोनों को संग्रहीत करते हैं। इस पेपर में, हम किसी भी बाहरी ज्ञान या स्पष्ट पुनर्प्राप्ति घटकों के बिना, पूरी तरह से एक भाषा मॉडल का उपयोग करके एक प्रभावी एंड-टू-एंड फैक्ट चेकर बनाने के लिए इस अंतर्निहित ज्ञान का लाभ उठाते हैं। जबकि एलएम से ज्ञान निकालने पर पिछले काम ने हमारे ज्ञान का सबसे अच्छा जवाब देने के लिए ओपन-डोमेन प्रश्न के उत्तर के कार्य पर ध्यान केंद्रित किया है, यह तथ्य परीक्षकों के रूप में भाषा मॉडल के उपयोग की जांच करने के लिए पहला काम है। एक बंद-पुस्तक सेटिंग में, हम दिखाते हैं कि हमारा शून्य-शॉट एलएम दृष्टिकोण मानक बुखार कार्य पर एक यादृच्छिक आधार रेखा को मात देता है, और यह कि हमारे महीन एलएम मानक बेसलाइन के साथ अनुकूल रूप से तुलना करता है। यद्यपि हम अंततः उन तरीकों से बेहतर प्रदर्शन नहीं करते हैं जो स्पष्ट ज्ञान के आधार का उपयोग करते हैं, हमारा मानना है कि हमारी खोज से पता चलता है कि यह विधि व्यवहार्य है और इसमें अन्वेषण के लिए बहुत जगह है।</abstract_hi>
      <abstract_ga>Tá sé tugtha le tuiscint in obair a rinneadh le déanaí go stórálann samhlacha teanga (LManna) eolas ciallmhar agus fíorasach a foghlaimíodh ó shonraí réamhoiliúna. Sa pháipéar seo, déanaimid an t-eolas intuigthe seo a ghiaráil chun seiceálaí fíorais éifeachtach ó cheann go ceann a chruthú a úsáideann múnla teanga amháin, gan aon eolas seachtrach ná comhpháirteanna aisghabhála follasacha. Cé gur dhírigh obair a rinneadh roimhe seo ar bhaint eolais ó LManna ar an tasc a bhaineann le ceisteanna oscailte a fhreagairt, chomh fada agus is eol dúinn, is é seo an chéad obair a scrúdaíodh úsáid na múnlaí teanga mar sheiceálaithe fíricí. I suíomh leabhar dúnta, léirímid go n-éiríonn lenár gcur chuige LM náid náid ná bunlíne randamach ar an ngnáth-thasc FEVER, agus go bhfuil comparáid fhabhrach idir ár LM miontiúnta agus bunlínte caighdeánacha. Cé nach n-éiríonn linn níos fearr ar deireadh le modhanna a úsáideann bunáiteanna eolais follasacha, creidimid go léiríonn ár n-iniúchadh go bhfuil an modh seo inmharthana agus go bhfuil go leor spáis ann le haghaidh taiscéalaíochta.</abstract_ga>
      <abstract_hu>A közelmúltbeli munkák azt sugallják, hogy a nyelvi modellek mind a józan észt, mind pedig a képzés előtti adatokból származó tényszerű ismereteket tárolják. Ebben a tanulmányban ezt az implicit tudást kihasználjuk egy hatékony end-to-end tény ellenőrző létrehozására, kizárólag egy nyelvi modell használatával, külső ismeretek vagy explicit visszakeresési komponensek nélkül. Míg az LMs-ekből származó tudás kinyerésével kapcsolatos korábbi munka a nyílt domain kérdések megválaszolásának feladatára összpontosított, tudásunk szerint ez az első munka, amely a nyelvi modellek tényellenőrzőként való használatát vizsgálja. Zárt könyvben megmutatjuk, hogy a nulla lövéses LM megközelítésünk felülmúlja a szabványos FEVER feladat véletlenszerű alapját, és hogy a finomhangolt LM kedvezően hasonlít össze a standard alapjaival. Bár végső soron nem teljesítjük túl a kifejezett tudásbázisokat használó módszereket, úgy véljük, hogy feltárásunk azt mutatja, hogy ez a módszer életképes és sok hely van feltárásra.</abstract_hu>
      <abstract_ka>ახალი სამუშაო მუშაობა, რომ ენის მოდელები (LMs) სამუშაო სიგრძნე და ფაქტიური ცნობილებები, რომლებიც უნდა იყოს სამუშაო სამუშაო მო ამ დომენტში ჩვენ ამ ინფლიციტური ცნობილების შექმნა ეფექტიურ დასრულებული ფაქტის შემოწმება, რომელიც მხოლოდ ენის მოდელის გამოყენებათ, არსებობით გარეშე ცნობილება ან გარეშე მიღებ თუმცა პირველი სამუშაო მსოფლიოს მოდელეების გამოყენებაზე გახსნა კითხვების დასამართლად, ჩვენი უკეთესი ცნობილებისთვის, ეს არის პირველი სამუშაო, რომელიც ენის მოდელეების გამოყენებას რო ჩვენ დახურებული წიგნის შესაძლებელად ჩვენი ნულ-სურათი LM მიღება სტანდარტული FEVER დავალების გამოსაყენება და ჩვენი წიგნილი LM-ის გამოსაყენება სტანდარტული ფესური ხაზებით. მაგრამ ჩვენ საბოლოოდ არ ვაკეთებთ გავაკეთებული მეტოვები, რომელიც გამოიყენება განსხვავებული ცნობიერების ბაზები, ჩვენ ვფიქრობთ ჩვენი განსხვავება, რომ ეს მეტოვები უფრო ცხ</abstract_ka>
      <abstract_el>Πρόσφατες εργασίες έχουν προτείνει ότι τα γλωσσικά μοντέλα (LM) αποθηκεύουν τόσο την κοινή λογική όσο και τις πραγματικές γνώσεις που αποκτήθηκαν από τα δεδομένα προ-κατάρτισης. Σε αυτή την εργασία, αξιοποιούμε αυτή τη σιωπηρή γνώση για να δημιουργήσουμε έναν αποτελεσματικό ολοκληρωμένο έλεγχο γεγονότων χρησιμοποιώντας ένα μόνο γλωσσικό μοντέλο, χωρίς καμία εξωτερική γνώση ή ρητά συστατικά ανάκτησης. Ενώ οι προηγούμενες εργασίες για την εξαγωγή γνώσεων από LM έχουν επικεντρωθεί στο έργο της απάντησης σε ερωτήσεις ανοικτού τομέα, από όσο γνωρίζουμε, αυτή είναι η πρώτη εργασία που εξετάζει τη χρήση γλωσσικών μοντέλων ως ελεγκτές γεγονότων. Σε μια ρύθμιση κλειστού βιβλίου, δείχνουμε ότι η προσέγγισή μας μηδενικής βολής ξεπερνά μια τυχαία γραμμή βάσης στην τυπική εργασία και ότι η λεπτομέτρησή μας συγκρίνεται ευνοϊκά με τις τυπικές γραμμές βάσης. Αν και τελικά δεν ξεπερνάμε τις μεθόδους που χρησιμοποιούν ρητές βάσεις γνώσης, πιστεύουμε ότι η έρευνά μας δείχνει ότι αυτή η μέθοδος είναι βιώσιμη και έχει πολύ χώρο για εξερεύνηση.</abstract_el>
      <abstract_lt>Neseniai atliktas darbas parodė, kad kalbų modeliai saugo tiek sveikos proto, tiek faktines žinias, įgytas iš ikimokymo duomenų. Šiame dokumente mes panaudojame šias netiesiogines žinias, kad sukurtume veiksmingą faktų tikrintoją, naudojančią tik kalbos model į, be jokių išorinių žinių ar aiškių surinkimo komponentų. Nors ankstesnis darbas, skirtas žinių gavimui iš LM, buvo sutelktas į užduotį atsakyti į atviros srities klausimus, kiek žinome, tai pirmasis darbas, skirtas kalbų modelių naudojimui kaip faktų tikrintojams išnagrinėti. Uždarytoje knygoje mes parodome, kad mūsų nulinis LM metodas viršija atsitiktinę bazę standartinėje FEVER užduotyje, ir kad mūsų patobulintas LM palyginamas palankiai su standartinėmis bazėmis. Nors galiausiai neatliekame metodų, kurie naudoja aiškias žinių bazes, manome, kad mūsų tyrimas rodo, kad šis metodas yra gyvybingas ir turi daug erdvės tyrimui.</abstract_lt>
      <abstract_kk>Жуырдағы жұмыс тіл үлгілері (LMs) алдыңғы оқыту деректерінен үйренген жалпы мәліметтерді және фактикалық мәліметтерді сақтауға мүмкіндік береді. Бұл қағазда біз бұл мәліметті тек тіл үлгісін, сыртқы білім немесе түсінікті алу компоненттері жоқ, ең жақсы аяқтау сәтті тексеру үшін құрамыз. Алдыңғы жұмыс LMs- ден білім тарқату үшін ашық доменге сұрақ жауап беру тапсырмасына, біздің біліміміздің ең жақсы мәліметіне, бұл тіл үлгілерін факты тексеру үшін тексеру үшін бірінші Жабылған кітаптар параметрінде, LM жағдайымыз стандартты FEVER тапсырмасындағы кездейсоқ негізгі жолды жұмыс істейді, және біздің кездейсоқ LM жағдайымыз стандартты негізгі жолдарымен салыстырылады. Біз ең соңында білім мәліметтерді қолданған әдістерді таңдамаймыз, біз зерттеулеріміздің бұл әдісті жақсы болып, зерттеулердің көп жері бар деп ойлаймыз.</abstract_kk>
      <abstract_it>Recenti lavori hanno suggerito che i modelli linguistici (LM) memorizzano sia il buon senso che le conoscenze fattuali apprese dai dati pre-formazione. In questo articolo, sfruttiamo questa conoscenza implicita per creare un efficace controllo dei fatti end-to-end utilizzando un modello esclusivamente linguistico, senza alcuna conoscenza esterna o componenti espliciti di recupero. Mentre i precedenti lavori sull'estrazione della conoscenza da LM si sono concentrati sul compito di rispondere a domande open-domain, per quanto ne sappiamo, questo è il primo lavoro ad esaminare l'uso di modelli linguistici come fact checker. In un'impostazione a libro chiuso, mostriamo che il nostro approccio LM zero-shot supera una linea di base casuale sull'attività FEVER standard e che il nostro LM perfezionato si confronta favorevolmente con le linee di base standard. Anche se alla fine non superiamo i metodi che utilizzano basi di conoscenza esplicite, crediamo che la nostra esplorazione dimostri che questo metodo è praticabile e ha molto spazio per l'esplorazione.</abstract_it>
      <abstract_mk>Неодамнешната работа покажа дека јазичките модели (ЛМ) чуваат здраво-смислено и фактично знаење научено од податоците од предобуката. Во овој весник, го искористуваме ова имплицитно знаење за да создадеме ефикасен проверувач на факти од крај до крај, користејќи само јазички модел, без никакво надворешно знаење или експлицитни компоненти за преземање. И покрај тоа што претходната работа за извлекување на знаење од ЛМ се фокусираше на задачата на отворено одговорување на прашања на домен, за најдобро од нашето знаење, ова е првата работа за испитување на употребата на јазичките модели како проверка на факти. Во затворена книга покажуваме дека нашиот пристап со нула снимка на ЛМ го надминува случајниот основен резултат на стандардната ФЕВЕР задача, и дека нашиот финетизиран ЛМ се споредува со стандардните основни резултати. Иако на крајот не ги надминуваме методите кои користат експлицитни бази на знаење, веруваме дека нашето истражување покажува дека овој метод е жив и има многу простор за истражување.</abstract_mk>
      <abstract_mn>Саяхан ажил нь хэл загварууд (LMs) нь аль хэдийн мэдлэг болон үнэндээ мэдлэг аль хэдийн сургалтын мэдээллээс сурсан гэдгийг санал болгож байна. Энэ цаасан дээр бид эдгээр мэдлэгийг эцсийн төгсгөлд нь хэл загварыг ашиглаж, гадаад мэдлэг эсвэл тодорхой алдагдах хэсэгтэй бүтээмж бий болгохын тулд ашигладаг. Хэдийгээр өмнө ажлын ажил ЛХ-ээс мэдлэг гаргах талаар нээлттэй асуулт асуултын хариултыг бидний хамгийн сайн мэдлэгтэй хүмүүст анхны ажил нь хэл загварын хэрэглээ үнэндээ шийдвэрлэгчүүдийг шийдэх анхны ажил юм. Нууцсан номын хэмжээнд бид Нэг шалтгаан LM арга нь стандарт FEVER ажил дээр санамсаргүй үндсэн шугам гаргадаг гэдгийг харуулж байна. Эцэст нь бид тодорхой мэдлэгтэй суурь ашиглаж байгаа арга хэрэглэдэггүй ч, бидний судалгаанд энэ арга нь амьдрах болон судалгаанд маш олон орон байдаг гэдэгт итгэдэг.</abstract_mn>
      <abstract_ms>Kerja baru-baru ini menyarankan bahawa model bahasa (LMs) menyimpan pengetahuan biasa dan fakta yang dipelajari dari data praselatihan. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components.  Sementara kerja sebelumnya untuk mengekstrak pengetahuan dari LMs telah fokus pada tugas menjawab soalan domain terbuka, untuk yang terbaik dari pengetahuan kita, ini adalah kerja pertama untuk memeriksa penggunaan model bahasa sebagai pemeriksa fakta. Dalam tetapan buku tertutup, kita menunjukkan bahawa pendekatan LM 0-shot kita melampaui dasar rawak pada tugas FEVER piawai, dan bahawa LM yang ditetapkan kita dibandingkan dengan baik dengan garis dasar piawai. Walaupun kita tidak akhirnya melebihi kaedah yang menggunakan dasar pengetahuan secara eksplicit, kita percaya eksplorasi kita menunjukkan bahawa kaedah ini boleh hidup dan mempunyai banyak ruang untuk eksplorasi.</abstract_ms>
      <abstract_mt>Xogħol reċenti ssuġġerixxa li l-mudelli lingwistiċi (LMs) jaħżnu kemm għarfien ta’ sens komuni kif ukoll għarfien fattwali miksub mid-dejta ta’ qabel it-taħriġ. F’dan id-dokument, nagħmlu użu minn dan l-għarfien impliċitu biex noħolqu verifikatur effettiv tal-fatti minn tarf sa tarf bl-użu ta’ mudell lingwistiku biss, mingħajr l-ebda għarfien estern jew komponenti ta’ rkupru espliċitu. Filwaqt li l-ħidma preċedenti dwar l-estrazzjoni tal-għarfien mill-LMs iffukat fuq il-kompitu tat-tweġiba għall-mistoqsijiet b’dominju miftuħ, għall-aħjar għarfien tagħna, din hija l-ewwel ħidma biex jiġi eżaminat l-użu tal-mudelli lingwistiċi bħala verifikanti tal-fatti. F’ambjent ta’ kotba magħluqa, a ħna nuru li l-approċċ tagħna ta’ LM b’ritratt żero jaqbeż linja bażi każwali fuq il-kompitu standard FEVER, u li l-LM irfinat tagħna tqabbel b’mod favorevoli mal-linji bażi standard. Għalkemm fl-aħħar mill-aħħar ma nużawx metodi li jużaw bażijiet ta’ għarfien espliċiti, aħna nemmnu li l-esplorazzjoni tagħna turi li dan il-metodu huwa vijabbli u għandu ħafna spazju għall-esplorazzjoni.</abstract_mt>
      <abstract_ml>അടുത്തുതന്നെ ജോലി പരിശീലനത്തിനുമുമ്പ് പഠിച്ച വിവരങ്ങളില്‍ നിന്നും ഭാഷ മോഡലുകള്‍ സൂക്ഷിക്കുന്നതിനായി പരിശോ In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components.  LMs-ല്‍ നിന്നും അറിവ് പുറത്തെടുക്കുന്നതിന്‍റെ മുമ്പുള്ള ജോലി നമ്മുടെ അറിവിന്‍റെ ഉത്തരം തുറന്ന ഡൊമെയിന്‍ ചോദ്യം ഉത്തരം ചെയ്യുന്നതിന്‍റ ഒരു മൂടിയ പുസ്തകത്തിന്റെ സജ്ജീകരണത്തില്‍ ഞങ്ങള്‍ കാണിച്ചുകൊടുക്കുന്നു, നമ്മുടെ പൂജ്യ-ഷോട്ട് എംഎം അടിസ്ഥാനത്തിന്റെ അടിസ്ഥാനത്തില്‍ ഒര പ്രത്യക്ഷമായ അറിവുകളുടെ അടിസ്ഥാനങ്ങള്‍ ഉപയോഗിക്കുന്ന രീതികളില്‍ നമ്മള്‍ ഒടുവില്‍ പ്രവര്‍ത്തിക്കുന്നില്ലെങ്കിലും നമ്മുടെ പരിശോ</abstract_ml>
      <abstract_no>Nyleg har arbeidet foreslått at språksmodeller (LMs) lagrar både vanleg og faktisk kunnskap lærte frå føreøvingsdata. I denne papiret leverer vi denne implisitte kunnskapen for å laga ein effektiv ende-til-slutt-faktisk sjekkar med ein berre språk-modell utan nokon eksterne kunnskap eller eksplisitt henting av komponentar. Mens det førre arbeidet på å ekstrahera kunnskap frå LMs har fokusert på oppgåva av oppgåva for å svara på oppgåva av open-domain spørsmål, til det beste av vårt kunnskap, er dette den første arbeidet å undersøke bruken av språk-modeller som faktisk kontrollere. I eit lukka bokinnstilling viser vi at LM-tilnærminga vår null-shot utfører ein tilfeldig grunnlinje på standard FEVER-oppgåva, og at vårt fine LM sammenlignar favoritt med standardsbaselinjer. Selv om vi ikkje finst utfører metodar som bruker eksplisitt kunnskapsbaser, tror vi at utforskinga vår viser at denne metoden er viktig og har mye plass for utforsking.</abstract_no>
      <abstract_pl>Ostatnie prace sugerują, że modele językowe (LM) przechowują zarówno zdrowy rozsądek, jak i wiedzę faktyczną zdobytą na podstawie danych przedszkoleniowych. W niniejszym artykule wykorzystujemy tę domniemaną wiedzę do stworzenia skutecznego kompleksowego sprawdzania faktów przy użyciu wyłącznie modelu językowego, bez żadnej zewnętrznej wiedzy lub wyraźnych komponentów pobierania. Podczas gdy poprzednie prace nad ekstrakcją wiedzy z LMs koncentrowały się na zadaniu odpowiedzi na pytania otwarte w domenie, według naszej najlepszej wiedzy, jest to pierwsza praca, która zbadała wykorzystanie modeli językowych jako sprawdzaczy faktów. W ustawieniu zamkniętej książki pokazujemy, że nasze podejście zero-shot LM przewyższa losową bazę bazową standardowego zadania FEVER, a nasze precyzyjnie dostrojone LM porównuje się korzystnie ze standardowymi liniami bazowymi. Chociaż ostatecznie nie przewyższamy metod, które wykorzystują wyraźne bazy wiedzy, wierzymy, że nasze badania pokazują, że ta metoda jest opłacalna i ma dużo miejsca do eksploracji.</abstract_pl>
      <abstract_ro>Lucrările recente au sugerat că modelele lingvistice (LM) stochează atât cunoștințele de bun simț, cât și cele de fapt învățate din datele pre-formare. În această lucrare, valorificăm aceste cunoștințe implicite pentru a crea un verificator eficient de fapt end-to-end folosind doar un model lingvistic, fără cunoștințe externe sau componente explicite de recuperare. În timp ce lucrările anterioare privind extragerea cunoștințelor din LM s-au concentrat pe sarcina de a răspunde la întrebări pe domeniu deschis, din câte știm, aceasta este prima lucrare care examinează utilizarea modelelor lingvistice ca verificatori de fapt. Într-un cadru de carte închisă, arătăm că abordarea noastră LM zero-shot depășește o linie de referință aleatorie în sarcina standard FEVER și că LM noastră finuțit se compară favorabil cu liniile de referință standard. Deși în cele din urmă nu depășim metodele care utilizează baze de cunoștințe explicite, credem că explorarea noastră arată că această metodă este viabilă și are mult spațiu pentru explorare.</abstract_ro>
      <abstract_si>අලුත් වැඩේ ප්‍රශ්නය කරලා තියෙන්නේ භාෂාව මොඩේල්ස් (LMs) සාමාන්‍ය අදහස් සහ ඇත්ත දැනගන්න පුළුවන් ප මේ පැත්තේ, අපි මේ අවශ්‍ය දැනගන්න ප්‍රශ්නයක් අවසානයෙන් අවසානයෙන් පරීක්ෂකයක් නිර්මාණය කරන්න භාෂාවක් මොඩේලයක් ප්‍රයෝජන LMs වලින් දැනගන්න ප්‍රශ්න ප්‍රශ්න ප්‍රශ්නයක් ප්‍රතික්‍රියාවට පිළිබඳ වැඩ කරන්න, අපේ දැනගන්න හොඳම වැඩට, මේක තමයි භාෂා මොඩේල්ස වහලා පොත සැකසුම් වලින්, අපි පෙන්වන්නේ අපේ ශූන්ය වෙඩි LM විදියට ප්‍රමාණය FEVER වැඩේ සාමාන්‍ය ප්‍රමාණයක් වලින් විදියට අවසාන ප්‍රමාණය අපි අන්තිම විදියට විශ්වාස කරන විදියට වැඩ කරන්නේ නැහැ නමුත් අපි විශ්වාස කරනවා අපේ පරීක්ෂණය පෙන්වනවා මේ විදියට ප්‍රතික්‍ර</abstract_si>
      <abstract_sr>Poslednji rad je predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučili od podataka pre obuke. U ovom papiru, iskorištavamo to implicitno znanje da bi stvorili efikasni provjernik činjenica na kraju koristeći samo jezički model, bez bilo kakvih spoljnih znanja ili eksplicitnih komponenta za uzdržavanje. Dok je prethodni posao o izvlačenju znanja od LMs fokusiran na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, ovo je prvi posao koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da se naš fin LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju ne izvršavamo metode koje koriste jasne baze znanja, verujemo da naša istraživanja pokazuje da je ovaj metod održiv i ima mnogo mesta za istraživanje.</abstract_sr>
      <abstract_so>Shaqoda la soo dhowaaday waxay soo jeedisay in tusaale ahaan luuqada (LMs) lagaga dhigo aqoonta caadiga ah iyo aqoonta runta ah oo laga baray macluumaadka waxbarashada ka horraysa. Warqadan waxaynu ku qornaa aqoontan saamayn ah si a an u sameyno koontarool faa’iido ah ugu dhammaadka ugu dambaysta, si aan u isticmaalno tusaale luuqad oo kaliya, cilmi dibadda ah ama qeybo qaali ah. Intii shaqadii hore oo ku saabsan soo saaridda aqoonta ee LMs waxay focus ugu yeesheen shaqada su'aalaha furan, tan ugu wanaagsan ee aqoonteenna, taasi waa shaqada ugu horeysa si aad u baaritaan isticmaalka modelalka luuqada sida hubsada xaqiiqada ah. Qoraalka qoran oo xidhan, waxaynu tusnaynaa in dhaqdhaqaalahayaga aan nuurka looga dhuftay LM uu ka muujiyo qoraal hoos ah oo ku qoran shaqada caadiga ah ee FEVER, iyo in LM-kaalmeynayo uu si fiican ugu dhigo heerarka caadiga ah. In kastoo aanan ugu dambaysta samayn hababka la soo saaray oo isticmaalaya aasaaska aqoonta cad, waxaynu aaminsanahay baaritaankeenu waxay muuqan tahay in qaabkaasu suurtagal yahay, wuxuuna leeyahay meel aad u baahan karto.</abstract_so>
      <abstract_sv>Nyligen genomförda arbeten har antytt att språkmodeller lagrar både sunt förnuft och sakkunskap som erhållits från data före utbildningen. I denna uppsats utnyttjar vi denna underförstådda kunskap för att skapa en effektiv end-to-end faktakontroll med hjälp av en enbart språkmodell, utan någon extern kunskap eller explicita hämtningskomponenter. Medan tidigare arbete med att utvinna kunskap från LM har fokuserat på uppgiften att besvara frågor med öppen domän, så vitt vi vet, är detta det första arbetet att undersöka användningen av språkmodeller som faktakontroller. I en sluten bokinställning visar vi att vår noll-shot LM-metod överträffar en slumpmässig baslinje på standard FEVER-uppgiften, och att vår finjusterade LM jämför positivt med standard baslinjer. Även om vi i slutändan inte överträffar metoder som använder explicita kunskapsbaser, tror vi att vår utforskning visar att denna metod är livskraftig och har mycket utrymme för utforskning.</abstract_sv>
      <abstract_ta>சமீபத்தில் வேலை மொழி மாதிரிகள் (LMs) பொதுவான உணர்வு மற்றும் உண்மையான அறிவை முன் பயிற்சி தரவிலிருந்து கற்று இந்த காகிதத்தில், வெளிப்புற அறிவு அல்லது வெளிப்படையான பொருள் இல்லாமல் ஒரு மொழி மாதிரி மாதிரியை உருவாக்குவதற்கு ஒரு விருப்பமான முடிவு முட LMs இலிருந்து அறிவை வெளியேற்றும் முந்தைய வேலையில், திறந்த டொமைன் கேள்விக்கு பதில் கவனம் செலுத்தப்பட்டுள்ளது, எங்கள் அறிவின் சிறந்தத்திற் ஒரு மூடிய புத்தகத்தின் அமைப்பில், எங்கள் பூஜ்ஜியமான LM முறைமையை நாம் காண்பிக்கிறோம் என்பது நிலையான FEVER பணியில் ஒரு குறிப்பிட்ட அடிப்படைய Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</abstract_ta>
      <abstract_ur>اگلے کام نے سفارش کی ہے کہ زبان مدل (LMs) دونوں عام سمجھ اور حقیقی علم کو پہلے آموزش دادہ سے سکھایا گیا ہے. اس کاغذ میں، ہم اس غیر علم کے بغیر کسی خارجی علم یا صاف صاف اٹھانے کے مطابق ایک موجود چکر بنانے کے لئے استعمال کرتے ہیں. حالانکہ پہلے کام لMs سے علم اٹھانے کے لئے کھول دینے والی سوال کے جواب کے کام پر تمرکز کیا گیا ہے، ہمارے علم سے بہترین، یہ سب سے پہلے کام ہے جو زبان مدل کے استعمال کو حقیقت چکروں کے طور پر تحقیق کرنے کے لئے ہے. ہم نے ایک بند کتاب مقرر میں دکھایا کہ ہمارا صفر-شٹ LM تقریبا استاندارد FEVER کے کام پر ناقص بنسبیلئن سے کام لیتا ہے اور ہمارے بہترین LM نے استاندارد بنسبیلئین کے ساتھ مطابق مطابق مقرر کیا ہے. اگرچہ ہم بالاخره طریقے سے کام نہیں لیتے جو صریح علم کی بنیاد استعمال کرتے ہیں، ہم یقین رکھتے ہیں کہ ہماری تحقیق دکھاتا ہے کہ یہ طریقہ قابل ہے اور تحقیق کے لئے بہت سی جگہ ہے.</abstract_ur>
      <abstract_uz>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data.  Bu qogʻozda biz faqat tilning modeli yordamida, tashqi bilmagan yoki aniqlash komponentini yordamida qo'llanmiz. LMs'dan olish uchun oldingi ishni o'rganish uchun ochiq domen savol javobga qaramadi, bizning eng yaxshi taʼlumot uchun, bu tilning foydalanishini haqiqiqiy tekshirish uchun birinchi ish. Yopilgan kitob moslamada biz hech narsa yozilgan LM tilimizni andoza FEVER vazifasidagi oddiy asosiy bazasini bajarayotganimizni ko'rsatamiz va bizning yuqori LM andoza asosiy sonlari bilan yaxshi ko'rinadi. Agar biz oxirgi ta'rif asosida foydalanuvchi usullar emas, biz ishlayapmiz, bu usulni ishlab chiqarishimiz mumkin va qidirish uchun juda ko'p joyi bor.</abstract_uz>
      <abstract_vi>Những nghiên cứu gần đây cho thấy các mô hình ngôn ngữ (LM) lưu trữ cả sự tỉnh táo và sự thật được học từ dữ liệu trước khi đào tạo. Trong tờ giấy này, chúng ta dùng kiến thức ngầm này để tạo ra một hệ thống kiểm tra thực tế hiệu quả dùng một mô hình ngôn ngữ, mà không có kiến thức bên ngoài hay các thành phần trích dẫn rõ ràng. Trong khi những nghiên cứu trước về khai thác kiến thức từ LMs đã tập trung vào nhiệm vụ trả lời câu hỏi mở miền, theo những gì chúng ta biết, đây là công việc đầu tiên để kiểm tra việc dùng các mô hình ngôn ngữ làm người kiểm tra thực tế. Trong một thiết lập kín, chúng tôi cho thấy phương pháp LM "bắn không" của chúng ta thực hiện một đường cơ sở hoàn chỉnh ngẫu nhiên trên nhiệm vụ kiểu FEL chuẩn, và LM tinh chỉnh của chúng ta được so sánh được với những đường hầm chuẩn. Mặc dù chúng ta không hoàn thành các phương pháp sử dụng những căn cứ nhận thức rõ ràng, nhưng chúng ta tin rằng cuộc thám hiểm của chúng ta cho thấy rằng phương pháp này khả thi và có nhiều phòng để thám hiểm.</abstract_vi>
      <abstract_bg>Последните изследвания показват, че езиковите модели съхраняват както здравия разум, така и фактическите знания, придобити от данни преди обучението. В тази статия ние използваме тези имплицитни знания, за да създадем ефективна проверка на фактите от край до край, използвайки единствено езиков модел, без никакви външни знания или изрични компоненти за извличане. Докато предишната работа по извличане на знания от УМ се фокусира върху задачата за отговор на въпроси с отворен домейн, доколкото знаем, това е първата работа, която изследва използването на езикови модели като проверяващи факти. В затворена книга показваме, че нашият подход с нулев изстрел надминава случайна базова линия при стандартната задача и че нашият фино настроен ЛМ се сравнява благоприятно със стандартните базови линии. Въпреки че в крайна сметка не превъзхождаме методите, които използват изрични бази от знания, ние вярваме, че нашето изследване показва, че този метод е жизнеспособен и има много място за изследване.</abstract_bg>
      <abstract_nl>Recent onderzoek heeft gesuggereerd dat taalmodellen (LMs) zowel gezond verstand als feitelijke kennis opslaan die is geleerd uit pre-training data. In dit artikel maken we gebruik van deze impliciete kennis om een effectieve end-to-end fact checker te creëren met een louter taalmodel, zonder enige externe kennis of expliciete retrieval componenten. Terwijl eerdere werkzaamheden over het extraheren van kennis uit LMs zich hebben gericht op de taak van open-domein vragen beantwoorden, is dit voor ons het eerste werk dat het gebruik van taalmodellen als fact checkers onderzoekt. In een gesloten boekinstelling laten we zien dat onze zero-shot LM-benadering beter presteert dan een willekeurige baseline op de standaard FEVER taak, en dat onze verfijnde LM zich gunstig vergelijkt met standaard baselines. Hoewel we uiteindelijk niet beter presteren dan methoden die gebruik maken van expliciete kennisbases, geloven we dat onze exploratie aantoont dat deze methode levensvatbaar is en veel ruimte heeft voor exploratie.</abstract_nl>
      <abstract_de>Jüngste Arbeiten deuten darauf hin, dass Sprachmodelle (LMs) sowohl gesundes Menschenverstand als auch sachliches Wissen speichern, das aus Daten vor dem Training gelernt wurde. In diesem Beitrag nutzen wir dieses implizite Wissen, um einen effektiven End-to-End Fact Checker zu erstellen, der ausschließlich ein Sprachmodell verwendet, ohne externe Kenntnisse oder explizite Retrieval Komponenten. Während sich frühere Arbeiten zur Extraktion von Wissen aus LMs auf die Aufgabe der offenen Fragebeantwortung konzentrierten, ist dies nach bestem Wissen die erste Arbeit, die den Einsatz von Sprachmodellen als Fact Checker untersucht. In einem geschlossenen Buch zeigen wir, dass unser Zero-Shot-LM-Ansatz eine zufällige Baseline auf der Standard-FEVER-Aufgabe übertrifft und dass unser fein abgestimmtes LM sich günstig mit Standard-Baselines vergleicht. Obwohl wir Methoden, die explizite Wissensgrundlagen verwenden, nicht letztendlich übertreffen, glauben wir, dass unsere Exploration zeigt, dass diese Methode praktikabel ist und viel Raum für Exploration bietet.</abstract_de>
      <abstract_ko>최근 연구에 따르면 언어모델(LMs)에는 훈련 전 데이터에서 배운 상식과 사실 지식이 저장돼 있다.본고에서 우리는 이러한 스텔스 지식을 이용하여 효과적인 끝에서 끝까지의 사실 검사기를 만들고 하나의 언어 모델만 사용하며 외부 지식이나 현식 검색 구성 요소가 필요하지 않다.그동안 LMs에서 지식을 추출하는 작업은 주로 개방 분야 질문에 대한 답변 임무에 집중됐지만, 언어 모델을 팩트 체크 도구로 연구하는 첫 작업으로 알려졌다.폐쇄된 책 환경에서 우리는 우리의 0박자 LM 방법이 표준 발열 임무에서 무작위 기선보다 우수하고 우리의 마이크로스피커 LM이 표준 기선에 비해 더욱 우세하다는 것을 보여 주었다.비록 우리가 최종적으로 현식 지식 라이브러리를 사용하는 방법을 초월하지는 않았지만, 우리는 우리의 탐색이 이러한 방법이 실행 가능하고 매우 큰 탐색 공간이 있음을 나타낸다고 믿는다.</abstract_ko>
      <abstract_hr>Nedavno je rad predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučene iz podataka prije obuke. U ovom papiru, iskorištavamo to implicitno znanje kako bi stvorili učinkoviti provjeravač činjenica na kraju koristeći samo jezički model, bez bilo kakvih vanjskih znanja ili jasnih komponenata za uzdržavanje. Iako je prethodni rad izvlačenja znanja iz LMs-a usredotočen na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, to je prvi rad koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da naš fin beznačajni LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju nismo nadmašili metode koje koriste jasne baze znanja, vjerujemo da naša istraživanja pokazuje da je ovaj metod održiv i ima mnogo mjesta za istraživanje.</abstract_hr>
      <abstract_da>Det seneste arbejde har antydet, at sprogmodeller gemmer både sund fornuft og faktisk viden fra data før uddannelsen. I denne artikel udnytter vi denne implicitte viden til at skabe en effektiv end-to-end fact checker ved hjælp af en udelukkende sprogmodel, uden ekstern viden eller eksplicitte hentningskomponenter. Mens tidligere arbejde med at udvinde viden fra LM'er har fokuseret på opgaven med open-domæne spørgsmål besvarelse, så vidt vi ved, er dette det første arbejde, der undersøger brugen af sprogmodeller som fact checkers. I en lukket bog-indstilling viser vi, at vores nulskud LM tilgang overgår en tilfældig baseline på standard FEVER opgave, og at vores finjusterede LM sammenligner positivt med standard baselines. Selvom vi ikke i sidste ende overgår metoder, der bruger eksplicitte vidensbaser, mener vi, at vores udforskning viser, at denne metode er levedygtig og har meget plads til udforskning.</abstract_da>
      <abstract_sw>Kazi ya hivi karibuni imependekeza kuwa mifano ya lugha (LMs) hubeba maarifa ya kawaida na maarifa ya ukweli yaliyojifunza kutoka kwa takwimu za mafunzo ya awali. Katika karatasi hii, tunatumia maarifa haya yenye ufahamu wa kutengeneza utafiti wenye ufanisi wa mwisho wa ukweli wa mwisho kwa kutumia mifano pekee ya lugha, bila ufahamu wa nje au vifaa vya wazi vya kupatikana. Wakati kazi iliyopita kuhusu kuondoa maarifa kutoka kwa LMs wamejikita kwenye kazi ya maswali ya wazi ya ndani ya kujibu, kwa ufahamu wetu bora, hii ni kazi ya kwanza ya kuchunguza matumizi ya mifano ya lugha kama utafiti wa ukweli. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines.  Ingawa hatufanyi hatua za mwisho zinazotumia misingi ya maarifa ya wazi, tunaamini utafiti wetu unaonyesha kuwa mbinu hii inafaa na ina nafasi nyingi kwa ajili ya uchunguzi.</abstract_sw>
      <abstract_id>Pekerjaan baru-baru ini menyarankan bahwa model bahasa (LMs) menyimpan pengetahuan biasa dan faktual yang dipelajari dari data prapelatihan. Dalam kertas ini, kita menggunakan pengetahuan implicit ini untuk menciptakan pemeriksa fakta yang efektif dari akhir ke akhir menggunakan hanya model bahasa, tanpa pengetahuan luar atau komponen penemuan eksplicit. Sementara pekerjaan sebelumnya untuk mengekstraksi pengetahuan dari LMs telah fokus pada tugas menjawab pertanyaan domain terbuka, untuk yang terbaik dari pengetahuan kita, ini adalah pekerjaan pertama untuk memeriksa penggunaan model bahasa sebagai pemeriksa fakta. Dalam pengaturan buku tertutup, kami menunjukkan bahwa pendekatan LM 0-shot kita melebihi dasar acak pada tugas standar FEVER, dan bahwa LM finetuned kita membandingkan dengan baik dengan dasar standar. Meskipun kita tidak akhirnya melebihi metode yang menggunakan dasar pengetahuan eksplicit, kita percaya eksplorasi kita menunjukkan bahwa metode ini bisa hidup dan memiliki banyak ruang untuk eksplorasi.</abstract_id>
      <abstract_fa>کارهای اخیرا پیشنهاد داده است که مدل زبان (LMs) از اطلاعات پیش آموزش یاد گرفته‌اند و دانش معمولی و حقیقی را فروش می‌دهند. در این کاغذ، ما این دانش غیر قابل توجه می‌کنیم تا یک بررسی‌کننده‌ی حقیقت‌های پایان و پایان موثر را با استفاده از یک مدل زبانی استفاده کنیم، بدون هیچ دانش خارجی یا بخش‌های بازیابی مشخص. در حالی که کارهای قبلی در اخراج علم از خانم‌ها روی کار جواب سوال‌های دامنی باز، به بهترین دانش‌های ما تمرکز کرده‌اند، این اولین کاری است که استفاده از مدل‌های زبان را به عنوان بررسی‌کنندگان حقیقت تحقیق می‌کند. در یک تنظیمات کتاب بسته، نشان می دهیم که دستور LM صفر-شلیک ما از یک خط بنیادی تصادفی بر روی کار FEVER استاندارد برتر است، و اینکه LM بی‌نیاز ما به طور مناسب با خط بنیادی استاندارد مقایسه می‌کند. اگرچه در نهایت ما روش‌هایی که استفاده از پایگاه‌های علمی روشن نیستیم، باور می‌کنیم که کشف‌های ما نشان می‌دهند که این روش قابل زندگی است و برای کشف‌ها جای زیادی دارد.</abstract_fa>
      <abstract_sq>Puna e fundit ka sugjeruar se modelet gjuhësore (LMs) ruajnë njohuri të zakonshme dhe faktike të mësuara nga të dhënat e paratrajnimit. Në këtë letër, ne përdorim këtë njohuri implicit për të krijuar një kontrollues efektiv të fakteve nga fundi në fund duke përdorur vetëm një model gjuhësh, pa ndonjë njohuri të jashtme apo komponente të shprehura. Ndërsa punët e mëparshme mbi nxjerrjen e njohurive nga LMs janë përqëndruar në detyrën e përgjigjes së pyetjeve në domeni të hapur, për më të mirën e njohurive tona, kjo është puna e parë për të shqyrtuar përdorimin e modeleve gjuhësore si kontrollues të fakteve. Në një përcaktim të librit të mbyllur, ne tregojmë se metoda jonë zero-shot LM kryen një bazë të rastësishme në detyrën standard FEVER, dhe se LM jonë të përshtatur krahasohet favorisht me linjat standard bazë. Megjithëse ne nuk bëjmë më së fundi metoda që përdorin baza të njohurive të qarta, ne besojmë se eksplorimi ynë tregon se ky metodë është i jetueshëm dhe ka shumë vend për eksplorim.</abstract_sq>
      <abstract_am>የቀድሞው ሥራ የቋንቋ ምሳሌዎች (LMs) ከቅድሚያ ተማሪ ዳታዎች የተማረ የውይይት እና የእውቀትን እውቀት ለማስቀመጥ ያሳያል፡፡ በዚህ ካላት፣ በውጭ እውቀት ወይም ግልፅ ማሳየት አንዳች የቋንቋ ምሳሌ ሳይኖር፣ የቋንቋ ምሳሌ መፍጠርን እናደርጋለን፡፡ የቀድሞው የLMs እውቀትን ለመውጣት የሚደረገውን ሥራ ከክፈት ዶሜን ጠያቂዎች መልስ ስራትን ያስተካክሎታል፡፡ በተዘጋጀ መጽሐፍ ውስጥ የኮሌዶችን የLM ሥርዓት የFEVER ሥርዓት ላይ የተለየ የደረጃ መሠረት እንዲያሳየው እናሳየዋለን፤ የተጠቃሚ LM ግን ከዓላማ መቀመጫዎች ጋር ያሳያል፡፡ ምንም እንኳን የግልጽ እውቀት መቀመጫን የሚጠይቁ ሥርዓቶችን ባናደርግም እንምናለን፣ ይህ ሥርዓት የሚቻልበት እና ለመመረመር ብዙ ፋንታ አለበት ብለን እናምናለን፡፡</abstract_am>
      <abstract_af>Onlangse werk het voorgestel dat taal modele (LMs) gemeenskap-sens en faktuurlike kennis geleer het van voor-oefening data. In hierdie papier, het ons hierdie inplisite kennis gebruik om 'n effektief end-to-end faktuur toets te skep deur 'n slegs 'n taal model te gebruik, sonder enige eksterne kennis of eksplisiese ontvang komponente. Terwyl die vorige werk op die uitpakking van kennis van LMs gefokus het op die taak van open-domein vraag antwoord, tot die beste van ons kennis, is dit die eerste werk om die gebruik van taal modele as feit kontroleerders te ondersoek. In 'n gesluit boek instelling, wys ons dat ons nul-skoot LM toegang uitvoer 'n willekeurige basisline op die standaard FEVER taak, en dat ons fine LM vergelyk genadig met standaard basisline. Alhoewel ons nie eindelik uitvoer metodes wat eksplisiese kennis bases gebruik nie, glo ons ons uitvoer wys dat hierdie metode beskikbaar is en het baie kamer vir uitvoer.</abstract_af>
      <abstract_tr>Ýakynda işleýän zatlar dil nusgalarynyň hem umut duýgulary hem hakyky bilgi hem öňünden öwrenip bilýän bilimleri almagyny maslahat berdi. Bu kagyzda çykyş bilen ýöne bir dil nusgasyny ýöne, ýöne daşarydaky bilim ýöne a çyk komponentleri ýöne täsirli bir netijesi barlamak üçin bu sylagy çykarýarys. LMsden bilim tapmakda öňki işiň açylyk soraglaryň jogabyny açmak üçin üns berilýär. Bilişimiziň iň gowy görä bu dil nusgalarynyň ullanyşyny barlamak üçin ilkinji işidir. Baglanmış kitap düzeninde, biziň nul-atly LM ýazşymyzyň standart FEVER işinde tesadüf üýtgeýän çyzgylygyny görkezýäris we biziň iň kiçiräk LM standart üýtgeýän çyzgymlar bilen gowy görkezýäris. Iň soňunda biz bilim baselerini ulanan yönlerden çykarmaýarys diýip pikir edýäris. Araştyrymyzyň bu yöniň ýagdaýdyr we keşif etmek üçin köp ýer bardyr diýip pikir edýäris.</abstract_tr>
      <abstract_hy>Վերջին աշխատանքները ցույց են տալիս, որ լեզվի մոդելները պահեն առողջ զգացմունքը և փաստացի գիտելիքները, որոնք սովորել են նախկին ուսումնասիրելու տվյալներից: Այս թղթի մեջ մենք օգտագործում ենք այս ենթարկված գիտելիքը, որպեսզի ստեղծենք արդյունավետ վերջ-վերջ փաստերի ստուգում, օգտագործելով միայն լեզվային մոդել, առանց որևէ արտաքին գիտելիքի կամ բացատրական վերադարձման բաղադրիչների: Մինչդեռ նախորդ աշխատանքները գիտելիքների վերացման վրա կենտրոնացել են բաց բնագավառի հարցերի պատասխանման խնդրի վրա, մեր լավագույն գիտելիքների վրա, սա առաջին աշխատանքն է լեզվի մոդելների օգտագործման որպես փաստերի ստուգում ուսումնասիրելու համար: In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines.  Չնայած մենք վերջ ի վերջո չենք արտադրում մեթոդներ, որոնք օգտագործում են բացահայտ գիտելիքների հիմքերը, մենք հավատում ենք, որ մեր ուսումնասիրությունը ցույց է տալիս, որ այս մեթոդը գոյություն ունի և շատ տեղ ունի ուսումնասիրության համար:</abstract_hy>
      <abstract_az>Son işdə dil modelləri (LMs) öyrəndiklərindən öyrəndiyi həmçinin ortaq anlayışlıq və həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həm Bu kağızda, biz bu imkansız bilgi, sadəcə dil modelini istifadə edərək, heç bir dış bilgi və yaxud a çıq bilgi komponentləri olmadan effektiv bir qiyməti təşkil etmək üçün istifadə edirik. LMs elmlərini çıxartmaq üçün əvvəlki işlər açıq-domain sual cavab verməsi üçün, elmlərimizin ən yaxşısına baxmayaraq, bu ilk işlər dil modellərin istifadəsini həqiqət təsdiqçiləri kimi təsdiqlənməkdir. Qapılmış kitab ayarlarında, sıfır-vuruş LM tərəfimizin standart FEVER işində rastgele bir tərəfli çətinlikdən üstün olduğunu göstərdik və bizim gözəl LM standart tərəfli çətinliklərlə yaxşılıq edir. Əlbəttə də biz açıq bilgi üssələrini istifadə edən metodların üstünə çıxmadığımıza inanırıq ki, araşdırmalarımız bu metodların həyat verə biləcəyini və keşif üçün çox yer var.</abstract_az>
      <abstract_bn>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data.  এই কাগজটিতে আমরা একটি ভাষার মডেল ব্যবহার করে একটি কার্যকর শেষ পরীক্ষক সৃষ্টি করার জন্য এই প্রাপ্ত জ্ঞান প্রদান করি যাতে কোন বাইরে কোন জ্ঞান নেই অথবা পুনর এলএমএস থেকে জ্ঞান বের করার পূর্ববর্তী কাজ যখন উন্মুক্ত ডোমেইন প্রশ্নের উত্তর দিয়ে মনোযোগ প্রদান করেছে, তখন আমাদের জ্ঞানের সর্বোচ্চ কাজের প্রতি এটা হচ্ একটি বন্ধ বই ব্যবস্থায়, আমরা দেখাচ্ছি যে আমাদের শূন্যগুলো এলএম-এর প্রতিযোগিতা স্ট্যান্ডার্ডার ফেভার কাজের উপর একটি বেসালাইন প্রকাশ করে, আর আমাদের সু যদিও আমরা শেষ পর্যন্ত প্রকাশ্য জ্ঞানের বেস ব্যবহার করি না কিন্তু আমরা বিশ্বাস করি আমাদের গবেষণা দেখাচ্ছে যে এই পদ্ধতি ব্যবস্থা এবং অনুসন্</abstract_bn>
      <abstract_cs>Nedávné práce naznačují, že jazykové modely (LM) ukládají jak zdravý rozum, tak faktické znalosti získané z předškolených dat. V tomto článku využíváme implicitní znalosti k vytvoření efektivního end-to-end ověřovače faktů pomocí výhradně jazykového modelu, bez jakýchkoli externích znalostí nebo explicitních složek retrievalu. Zatímco předchozí práce na extrahování znalostí z LM se zaměřila na úlohu odpovědi na otázky otevřené domény, podle našich nejlepších znalostí je to první práce, která zkoumá využití jazykových modelů jako kontroly faktů. V nastavení uzavřené knihy ukazujeme, že náš přístup s nulovým výstřelem LM překoná náhodnou základní linii standardního úkolu FEVER a že náš jemně vyladěný LM se příznivě srovnává se standardními základními liniemi. Ačkoli nakonec nepřekonáme metody, které využívají explicitní znalostní báze, věříme, že náš průzkum ukazuje, že tato metoda je životaschopná a má velký prostor pro průzkum.</abstract_cs>
      <abstract_bs>Nedavno je rad predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučene iz podataka o predobuci. U ovom papiru, iskorištavamo to implicitno znanje da bi stvorili efikasni provjeravač činjenica na kraju koristeći samo jezički model, bez bilo kakvih vanjskih znanja ili eksplicitnih komponenta povlačenja. Iako je prethodni posao o izvlačenju znanja iz LMs-a usredotočen na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, to je prvi posao koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da naš fini LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju ne izvršavamo metode koje koriste jasne baze znanja, vjerujemo da naša istraživanja pokazuje da je ovaj metod živ i ima mnogo mjesta za istraživanje.</abstract_bs>
      <abstract_fi>Viimeaikaiset tutkimukset ovat osoittaneet, että kielimallit tallentavat sekä tervettä järkeä että faktatietoa, joka on saatu esiopetuksesta. Tässä artikkelissa hyödynnämme tätä implisiittistä tietoa luodaksemme tehokkaan end-to-end faktatarkistajan käyttäen yksinomaan kielimallia, ilman ulkoista tietoa tai nimenomaisia hakukomponentteja. Vaikka aikaisempi työ tiedon poimimiseksi LM:istä on keskittynyt avoimen verkkotunnuksen kysymyksiin vastaamiseen, parhaamme mukaan tämä on ensimmäinen työ, jossa tarkastellaan kielimallien käyttöä faktojen tarkastajina. Suljetussa kirjassa osoitamme, että nolla-shot LM-lähestymistapamme suoriutuu satunnaisesti tavanomaisessa FEVER-tehtävässä ja että hienosäädetty LM-lähestymistapamme on edullisesti verrattuna tavanomaisiin perusviivoihin. Vaikka emme viime kädessä ylitä menetelmiä, jotka käyttävät eksplisiittistä tietopohjaa, uskomme tutkimuksemme osoittavan, että tämä menetelmä on toteuttamiskelpoinen ja siinä on paljon tilaa tutkia.</abstract_fi>
      <abstract_et>Hiljutised tööd on näidanud, et keelemudelid säilitavad nii terve mõistuse kui ka faktilisi teadmisi, mis on saadud koolituseelsetest andmetest. Käesolevas dokumendis kasutame neid kaudseid teadmisi, et luua tõhus lõpp-lõpuni faktide kontrollija, kasutades ainult keelemudelit, ilma väliste teadmiste või selgesõnaliste päringukomponentideta. Kuigi varasemad tööd teadmiste väljavõtmiseks LMidest on keskendunud avatud domeenile küsimustele vastamise ülesandele, on see meie parimate teadmiste kohaselt esimene töö, milles uuritakse keelemudelite kasutamist faktikontrollijatena. Suletud raamatu seadetes näitame, et meie null-shot LM lähenemine ületab juhusliku lähtejoone standardülesande FEVER puhul ja et meie täpsustatud LM võrdleb soodsalt standardsete lähtejoontega. Kuigi me ei suuda lõppkokkuvõttes ületada meetodeid, mis kasutavad selgeid teadmistebaase, usume, et meie uurimine näitab, et see meetod on elujõuline ja sellel on palju ruumi uurimiseks.</abstract_et>
      <abstract_ca>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data.  En aquest paper, aprofitem aquest coneixement implícit per crear un controlador efectiu de fets de final a final utilitzant només un model de llenguatge, sense cap coneixement extern ni components de recuperació explícita. Mentre que la feina anterior sobre l'extracció del coneixement de les ML s'ha centrat en la tasca de resposta a preguntes de domini obert, pel millor que sabem, aquesta és la primera feina per examinar l'ús de models lingüístics com a verificadors de fets. En un entorn de llibre tancat, demostram que el nostre enfocament de zero-shot LM supera una línia de referència aleatòria en la tasca standard FEVER, i que el nostre LM finat es compara favorablement amb línies de referència standard. Encara que finalment no superem els mètodes que utilitzen bases de coneixement explícites, creiem que la nostra exploració demostra que aquest mètode és viable i té molt espai d'exploració.</abstract_ca>
      <abstract_sk>Nedavna dela kažejo, da jezikovni modeli shranjujejo zdravo pamet in dejansko znanje, pridobljeno iz podatkov pred usposabljanjem. V tem prispevku uporabljamo to implicitno znanje za ustvarjanje učinkovitega preverjanja dejstev od konca do konca z uporabo izključno jezikovnega modela, brez zunanjega znanja ali eksplicitnih komponent pridobivanja. Medtem ko je bilo predhodno delo pridobivanja znanja iz LM osredotočeno na nalogo odgovarjanja na vprašanja na odprto domeno, je to po našem najboljšem znanju prvo delo, ki proučuje uporabo jezikovnih modelov kot preverjalcev dejstev. V nastavitvi zaprtih knjig pokažemo, da naš pristop LM brez strela presega naključno osnovo pri standardnem opravilu FEVER in da se naš natančno nastavljen LM primerja s standardnimi osnovnimi črtami. Čeprav na koncu ne presegamo metod, ki uporabljajo eksplicitne baze znanja, verjamemo, da naše raziskovanje kaže, da je ta metoda izvedljiva in ima veliko prostora za raziskovanje.</abstract_sk>
      <abstract_he>העבודה האחרונה הציעה שדוגמני שפה (LMs) מחסנים גם ידע שפוי וגם ידע עובד שנלמד מידע לפני האימונים. בעיתון הזה, אנו משתמשים בידע מרושע הזה כדי ליצור בדיקת עובדות יעילה סוף-סוף באמצעות מודל שפה בלבד, ללא כל ידע חיצוני או רכיבים חיצוניים. בעוד העבודה הקודמת על החולץ ידע מLMs התמקדו במשימה של עניין לשאלות בתחום פתוח, לטובת הידע שלנו, זו העבודה הראשונה לבדוק את השימוש של דוגמני שפה כמבדקת עובדות. בסיס ספר סגור, אנו מראים שגישת LM אפס-ירייה שלנו מעלית בסיס אקראי במשימת FEVER הסטנדרטית, ושLM המתאים שלנו משווה בצורה טובה עם בסיסים סטנדרטיים. למרות שאנחנו לא בסופו של דבר מתגברים על שיטות אשר משתמשות בסיסי ידע ברורים, אנו מאמינים שהחקירה שלנו מראה כי השיטה הזאת חיה ויש לה הרבה מקום לחקור.</abstract_he>
      <abstract_ha>Yin aikin da aka yanzu ya shauri cewa misãlai na harshen (LM) za'a adana duk sanin da aka sanar da su daga data na zaman shawara. Daga wannan takardan, Munã ƙarfafa wannan ilmi wanda ba ta iya sani ba dõmin ka ƙiƙiro wani mai tsaro na ƙarama zuwa ƙarami, yana amfani da wani misali na harshen kawai, ko kuma babu wani ilmi na ƙarƙashin ko da ake samun motsi mai bayyanãwa. Ko da aikin da ya gabata a sami da fitarwa da ilmi daga LM ya fokus wa aikin da za'a karɓa wa masu tambayar buɗe-Domen, zuwa mafi kyaun sani, wannan na farkon aikin ka jarraba amfani da misalin harshen kamar shirin zaɓangare. Daga wani takarda littafin da aka rufe, za mu nuna cewa hanyarmu na LM-da-shekara ba ta samar da ranar bango a kan aikin FEWR na daidaita, kuma da kuma an daidaita LM masu amfani da kwamfyutan bango. Haƙĩƙa, kuma ba mu sami ko ƙarami hanyoyin su da ke amfani da bassi masu bayyani ga ilmi, sai munã ĩmãni cewa misalinmu yana da cẽwa wannan hanyor zai iya amfani da kuma yana da wuri mai yawa ga yin fitina.</abstract_ha>
      <abstract_jv>text-tool-action Awak dhéwé ngêngé kuwi, ngêngé awak dhéwé nggawe ngerasakno iki banget nggawe barang nggawe ngubah kesempatan kanggo ngubah kesempatan kanggo ngerasakno or a ono ndaftar sêngé awak dhéwé. Nombo kamu arep nggawe kelas bebas nang ngerasahan kelas telu nggawe ing nggawe open-domain question ngomong, kanggo awake sing paling awak dhéwé, iki bukané perusahaan kanggo bisa langkung model kuwi nggawe barang. Nanging kapan-kapan buku, kita ngomong nik sesuk yatak telu-atan LM sing ngendalikne mulai supoyo barang sampek mulalah sing ngendalikne ning daerahé DEBER nggo awak dhéwé, lan saiki ono LM sing paling dhéwé nggawe barang tengahane sampek wae awak dhéwé Genjer-genjer saiki awak dhéwé ora nggawe barang nggawe sistem sing paling awak dhéwé, awak dhéwé ngerasakno kejahatan dhéwé kuwi method sing bisa diagonal iki ngono akeh basa kanggo kejahatan.</abstract_jv>
      <abstract_bo>འཕྲལ་གསོག་ཀྱི་ལས་འགན་སྤྲོད་དེ་ནི་སྐད་ཡིག་ཆའི་མིག་དཔེ་གཟུགས་རིས་མང་ཙམ་ཉར་ཚགས In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components. LMs་ལས་སྔོན་གྱི་ལས་འགན་སྤྱད་ནས་མཐུན་རྣམས་ལས་གནད་དོན་གྱིས་open-domain འདྲི་ཚིག་གནད་དོན་ལ་ང་ཚོའི་ཤེས་ཡོད་ཚད་ལྟ་བུ་ཞིབ་འཇུག་པའི་ལས་འགན་བ In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. ང་ཚོས་དང་མཐའ་མཇུག་རྫོགས་མ་ཐུབ་པར་ཕྱོགས་སྟོན་པའི་གནས་ཚུལ་གཞི་རྩལ་བ་སྤྱོད་ཐབས་མེད་ཀྱང་། ང་ཚོས་འཚོལ་ཞིབ་བཤེར</abstract_bo>
      </paper>
    </volume>
</collection>